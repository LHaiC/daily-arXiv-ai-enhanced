{"id": "2602.07907", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.07907", "abs": "https://arxiv.org/abs/2602.07907", "authors": ["Johan van Benthem"], "title": "Definability and Interpolation in Philosophy", "comment": "Final version to appear in Balder ten Cate, Jean Christoph Jung, Patrick Koopmann, Christoph Wernhard and Frank Wolter, editors. Theory and Applications of Craig Interpolation", "summary": "This paper is a historical tour of occurrences of the Craig interpolation theorem and the Beth definability theorem in philosophy since the 1950s. We identify the notion of dependence as one major red thread behind these, and include some new technical results, in particular, on logical system translations and generalized definability", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08423", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.08423", "abs": "https://arxiv.org/abs/2602.08423", "authors": ["Duc Trung Kim Nguyen", "Tuyen Van Kieu", "Khanh Van To"], "title": "SAT Encodings for Bandwidth Coloring: A Systematic Design Study", "comment": null, "summary": "The Bandwidth Coloring Problem (BCP) generalizes graph coloring by enforcing minimum separation constraints between adjacent vertices and arises in frequency assignment applications. While SAT-based approaches have shown promise for exact BCP solving, the encoding design space remains largely unexplored. This paper presents a systematic study of SAT encodings for the BCP, proposing a unified framework with six encoding methods across three categories: one-variable, two-variable, and block encodings. We evaluate the impact of key features including incremental solving and symmetry breaking. While symmetry breaking has been studied for graph coloring, it has not been systematically evaluated for SAT-based BCP solvers. Our analysis reveals significant interaction effects between encoding choices and solver configurations. The proposed framework achieves state-of-the-art performance on GEOM and MS-CAP benchmarks. Block encodings solve GEOM120b, the hardest instance, to proven optimality in approximately 1000 seconds, whereas previous methods could not solve it within a one-hour time limit.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08532", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.08532", "abs": "https://arxiv.org/abs/2602.08532", "authors": ["Philipp R\u00fcmmer"], "title": "Craig Interpolation in Program Verification", "comment": "The article will appear in Balder ten Cate, Jean Christoph Jung, Patrick Koopmann, Christoph Wernhard and Frank Wolter, editors. Theory and Applications of Craig Interpolation. Ubiquity Press, 2026", "summary": "Craig interpolation is used in program verification for automating key tasks such as the inference of loop invariants and the computation of program abstractions. This chapter covers some of the most important techniques that have been developed in this context over the last years, focusing on two aspects: the derivation of Craig interpolants modulo the theories and data types used in verification and the basic design of verification algorithms applying interpolation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08692", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08692", "abs": "https://arxiv.org/abs/2602.08692", "authors": ["Stefan Szeider"], "title": "PBLean: Pseudo-Boolean Proof Certificates for Lean 4", "comment": null, "summary": "We present PBLean, a method for importing VeriPB pseudo-Boolean (PB) proof certificates into Lean 4. Key to our approach is reflection: a Boolean checker function whose soundness is fully proved in Lean and executed as compiled native code. Our method scales to proofs with tens of thousands of steps that would exhaust memory under explicit proof-term construction. Our checker supports all VeriPB kernel rules, including cutting-plane derivations and proof-by-contradiction subproofs. In contrast to external verified checkers that produce verdicts, our integration yields Lean theorems that can serve as composable lemmas in larger formal developments. To derive theorems about the original combinatorial problems rather than about PB constraints alone, we support verified encodings. This closes the trust gap between solver output and problem semantics since the constraint translation and its correctness proof are both formalized in Lean. We demonstrate the approach on various combinatorial problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07385", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.07385", "abs": "https://arxiv.org/abs/2602.07385", "authors": ["Elad Lavi", "Hadas Shachnai", "Inbal Talgam-Cohen"], "title": "Online Contract Design", "comment": null, "summary": "We initiate the study of online contracts, which integrate the game-theoretic considerations of economic contract theory, with the algorithmic and informational challenges of online algorithm design. Our starting point is the classic online setting with preemption of Buchbinder et al. [SODA'15], in which a hiring principal faces a sequence of adversarial agent arrivals. Upon arrival, the principal must decide whether to tentatively accept the agent to their team, and whether to dismiss previous tentative choices. Dismissal is irrevocable, giving the setting its online decision-making flavor. In our setting, the agents are rational players: once the team is finalized, a game is played where the principal offers contracts (performance-based payment schemes), and each agent decides whether or not to work. Working agents reward the principal, and the goal is to choose a team that maximizes the principal's utility. Our main positive result is a 1/2-competitive algorithm when agent rewards are additive, which matches the best-possible competitive ratio. Our algorithm is randomized and this is necessary, as we show that no deterministic algorithm can attain a bounded competitive ratio. Moreover, if agent rewards are allowed to exhibit combinatorial structure known as XOS, even randomized algorithms might fail. En route to our competitive algorithm, we develop the technique of balance points, which can be useful for further exploration of online contracts in the adversarial model.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07306", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07306", "abs": "https://arxiv.org/abs/2602.07306", "authors": ["Chong Wang", "Nan Du", "Tom Gunter", "Tao Lei", "Kulin Seth", "Senyu Tong", "Jianyu Wang", "Guoli Yin", "Xiyou Zhou", "Kelvin Zou", "Ruoming Pang"], "title": "Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization", "comment": null, "summary": "Efficient large-scale inference of transformer-based large language models (LLMs) remains a fundamental systems challenge, frequently requiring multi-GPU parallelism to meet stringent latency and throughput targets. Conventional tensor parallelism decomposes matrix operations across devices but introduces substantial inter-GPU synchronization, leading to communication bottlenecks and degraded scalability. We propose the Parallel Track (PT) Transformer, a novel architectural paradigm that restructures computation to minimize cross-device dependencies. PT achieves up to a 16x reduction in synchronization operations relative to standard tensor parallelism, while maintaining competitive model quality in our experiments. We integrate PT into two widely adopted LLM serving stacks-Tensor-RT-LLM and vLLM-and report consistent improvements in serving efficiency, including up to 15-30% reduced time to first token, 2-12% reduced time per output token, and up to 31.90% increased throughput in both settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07000", "categories": ["eess.SY", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07000", "abs": "https://arxiv.org/abs/2602.07000", "authors": ["Abanoub M. Girgis", "Ibtissam Labriji", "Mehdi Bennis"], "title": "Hierarchical JEPA Meets Predictive Remote Control in Beyond 5G Networks", "comment": null, "summary": "In wireless networked control systems, ensuring timely and reliable state updates from distributed devices to remote controllers is essential for robust control performance. However, when multiple devices transmit high-dimensional states (e.g., images or video frames) over bandwidth-limited wireless networks, a critical trade-off emerges between communication efficiency and control performance. To address this challenge, we propose a Hierarchical Joint-Embedding Predictive Architecture (H-JEPA) for scalable predictive control. Instead of transmitting states, device observations are encoded into low-dimensional embeddings that preserve essential dynamics. The proposed architecture employs a three-level hierarchical prediction, with high-level, medium-level, and low-level predictors operating across different temporal resolutions, to achieve long-term prediction stability, intermediate interpolation, and fine-grained refinement, respectively. Control actions are derived within the embedding space, removing the need for state reconstruction. Simulation results on inverted cart-pole systems demonstrate that H-JEPA enables up to 42.83 % more devices to be supported under limited wireless capacity without compromising control performance.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07230", "categories": ["cs.DS", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2602.07230", "abs": "https://arxiv.org/abs/2602.07230", "authors": ["Srinwanti Debgupta", "Sarah Morell", "Martin Skutella"], "title": "Unsplittable Transshipments", "comment": null, "summary": "We introduce the Unsplittable Transshipment Problem in directed graphs with multiple sources and sinks. An unsplittable transshipment routes given supplies and demands using at most one path for each source-sink pair. Although they are a natural generalization of single source unsplittable flows, unsplittable transshipments raise interesting new challenges and require novel algorithmic techniques. As our main contribution, we give a nontrivial generalization of a seminal result of Dinitz, Garg, and Goemans (1999) by showing how to efficiently turn a given transshipment $x$ into an unsplittable transshipment $y$ with $y_a<x_a+d_{\\max}$ for all arcs $a$, where $d_{\\max}$ is the maximum demand (or supply) value. Further results include bounds on the number of rounds required to satisfy all demands, where each round consists of an unsplittable transshipment that routes a subset of the demands while respecting arc capacity constraints.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06996", "categories": ["cs.NE", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06996", "abs": "https://arxiv.org/abs/2602.06996", "authors": ["Katayoun Eshkofti", "Matthieu Barreau"], "title": "Curriculum-Learned Vanishing Stacked Residual PINNs for Hyperbolic PDE State Reconstruction", "comment": null, "summary": "Modeling distributed dynamical systems governed by hyperbolic partial differential equations (PDEs) remains challenging due to discontinuities and shocks that hinder the convergence of traditional physics-informed neural networks (PINNs). The recently proposed vanishing stacked residual PINN (VSR-PINN) embeds a vanishing-viscosity mechanism within stacked residual refinements to enable a smooth transition from the parabolic to hyperbolic regime. This paper integrates three curriculum-learning methods as primal-dual (PD) optimization, causality progression, and adaptive sampling into the VSR-PINN. The PD strategy balances physics and data losses, the causality scheme unlocks deeper stacks by respecting temporal and gradient evolution, and adaptive sampling targets high residuals. Numerical experiments on traffic reconstruction confirm that enforcing causality systematically reduces the median point-wise MSE and its variability across runs, yielding improvements of nearly one order of magnitude over non-causal training in both the baseline and PD variants.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07116", "categories": ["cond-mat.mes-hall", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07116", "abs": "https://arxiv.org/abs/2602.07116", "authors": ["Yugo Onishi", "Liang Fu"], "title": "Zero-point energy of solids from vacuum fluctuation and quantum geometric force", "comment": "5 pages, 2 figures + Ref + SM", "summary": "We show that quantum fluctuations of electromagnetic fields induce an additional zero-point energy in solids, which scales with the volume. For insulators, the zero-point energy density is proportional to quantum fluctuation of electric polarization in the many-body ground state, a fundamental quantum geometric property of solids known as the quantum weight. Although the zero-point energy does not affect the dynamics of the electromagnetic fields, when the fields are produced by a superconducting LC circuit, the zero-point energy contributes to a repulsive force between the circuit and the material. In addition, since zero-point energy depends on the circuit's capacitor, it yields a measurable static force acting on the capacitor plates, which we call quantum geometric force. The proposed effects provide direct experimental access to the many-body quantum geometry and reveal a new macroscopic quantum effect in solids induced by vacuum fluctuation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07248", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07248", "abs": "https://arxiv.org/abs/2602.07248", "authors": ["Stephanie Birkelbach", "Maria Teleki", "Peter Carragher", "Xiangjue Dong", "Nehul Bhatnagar", "James Caverlee"], "title": "SocialPulse: An Open-Source Subreddit Sensemaking Toolkit", "comment": null, "summary": "Understanding how online communities discuss and make sense of complex social issues is a central challenge in social media research, yet existing tools for large-scale discourse analysis are often closed-source, difficult to adapt, or limited to single analytical views. We present SocialPulse, an open-source subreddit sensemaking toolkit that unifies multiple complementary analyses -- topic modeling, sentiment analysis, user activity characterization, and bot detection -- within a single interactive system. SocialPulse enables users to fluidly move between aggregate trends and fine-grained content, compare highly active and long-tail contributors, and examine temporal shifts in discourse across subreddits. The demo showcases end-to-end exploratory workflows that allow researchers and practitioners to rapidly surface themes, participation patterns, and emerging dynamics in large Reddit datasets. By offering an extensible and openly available platform, SocialPulse provides a practical and reusable foundation for transparent, reproducible sensemaking of online community discourse.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06973", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06973", "abs": "https://arxiv.org/abs/2602.06973", "authors": ["Lucky Susanto", "Musa Izzanardi Wijanarko", "Khumaisa Nur'aini", "Farid Adilazuarda", "Alham Fikri Aji", "Derry Tanti Wijaya"], "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models", "comment": "Submitted to ARR January", "summary": "While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07180", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07180", "abs": "https://arxiv.org/abs/2602.07180", "authors": ["Jeremiah Lethoba", "Romain Quey", "Darren C. Pagan", "Matthew Kasemer"], "title": "Sensitivity of grain-averaged elastic strain and orientation predictions on the mesh density and boundary conditions in crystal plasticity finite element simulations", "comment": "19 pages, 16 figures", "summary": "Combined high-energy X-ray diffraction microscopy (HEDM) and crystal plasticity finite element (CPFE) modeling studies have emerged as a preferred paradigm to shed insight into the evolution of elasticity and plasticity at the intragrain scale of polycrystals. In particular, far-field HEDM measures the deformation response of upwards of thousands of individual grains simultaneously in situ during mechanical loading, though measurements are primarily limited, however, to the average state of each grain -- i.e., the grain's full strain tensor, crystallographic orientation, spatial location and volume. CPFE is utilized to shed information on the intragrain deformation response, via the sub-discretization of each grain into many finite elements, though the direct point of comparison to HEDM remains the grain-averaged response. We thus seek to find the minimum simulation conditions necessary to provide consistent grain-averaged predictions in an attempt to limit computational cost. In this study, we perform a suite of simulations and systematically study the effects of mesh density and boundary conditions, and consider different materials. We discuss these results and show that accurate prediction of grain-averaged elastic strains in a given region of interest typically requires a mesh with 250 elements per grain on average and a buffer layer of at least three grains between the region of interest and the control surfaces.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07146", "categories": ["cs.ET", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.07146", "abs": "https://arxiv.org/abs/2602.07146", "authors": ["Alexander J. Edwards", "Son T. Le", "Nicholas W. G. Smith", "Ebenezer C. Usih", "Austin Thomas", "Christopher J. K. Richardson", "Nicholas A. Blumenschein", "Aubrey T. Hanbicki", "Adam L. Friedman", "Joseph S. Friedman"], "title": "Magnetic Field-Mediated Superconducting Logic", "comment": null, "summary": "While superconductors are highly attractive for energy-efficient computing, fundamental limitations in their logic circuit integration have hindered scaling and led to increased energy consumption. We therefore propose and experimentally demonstrate a novel superconducting switching device utilizing the proximity magnetization from a spin-orbit torque-switched magnet to control the resistivity of a superconductor. We further propose a complete logic family comprised solely of these devices. This novel implementation has the potential to drastically outperform existing superconducting logic families in terms of energy efficiency and scalability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06988", "categories": ["physics.app-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.06988", "abs": "https://arxiv.org/abs/2602.06988", "authors": ["Anitesh Kumar Singh", "Rodrigo A. F. Alves", "Tapas Pal", "Sarmistha Bora", "Hugo X. Rodrigues", "Emanuel J. A. dos Santos", "Camila de L. Ribeiro", "Alysson M. A. Silva", "Luiz A. Ribeiro J\u00fanior", "Douglas S. Galv\u00e3o", "Chandra Sekhar Tiwary"], "title": "Multiscale Mechanical Response of 3D-Printed Diamondiynes: From Movable Interlocked Lattices to Architected Metamaterials", "comment": "25 pages, 11 figures", "summary": "Diamondynes are a recently synthesized three-dimensional carbon allotrope, with interlocked and movable sublattices that introduce deformation modes not present in standard architected materials. Here, we report the first multiscale mechanical assessment of Diamondiyne-derived architectures by combining quasi-static compression of 3D-printed specimens with reactive molecular dynamics simulations of the corresponding atomic-scale models. We generate four geometries (3F, 2F-SY, 4F, and 2F-USY). All structures resulted in lower density in the range of 0.20-0.38 g.cm^-3. Experiments indicate that the symmetric two-sublattice structure (2F-SY) delivers the best performance, reaching a specific yield strength of 5.91 MPa.g^-1cm^-3 and a specific energy absorption of 279 J.g^-1, whereas 2F-USY architecture yielded the lowest values, with 0.77 MPa.g^-1.cm^-3 and 16 J.g^-1. The 4F geometry provided a specific energy absorption of 254 J.g^-1. The structures deformed through geometric collapse and strut buckling, which was due to diagonal shear in 2F-USY and progressive compaction in 2F-SY and 3F. Molecular dynamics simulations also confirmed these experimental trends and revealed strong directional anisotropy due to the arrangement of interlocked sublattices, with a stiffness of 24.1 GPa along the z-direction in the case of 4F architecture. Overall, Diamondiyne-derived architectures display geometry-dominated mechanical behavior and serve as a promising platform for lightweight, energy-absorbing metamaterials.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06966", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06966", "abs": "https://arxiv.org/abs/2602.06966", "authors": ["Kai Xu", "Hang Zhao", "Ruizhen Hu", "Min Yang", "Hao Liu", "Hui Zhang", "Haibin Yu"], "title": "Embodied Intelligence for Flexible Manufacturing: A Survey", "comment": "in chinese language. ROBOT", "summary": "Driven by breakthroughs in next-generation artificial intelligence, embodied intelligence is rapidly advancing into industrial manufacturing. In flexible manufacturing, industrial embodied intelligence faces three core challenges: accurate process modeling and monitoring under limited perception, dynamic balancing between flexible adaptation and high-precision control, and the integration of general-purpose skills with specialized industrial operations. Accordingly, this survey reviews existing work from three viewpoints: Industrial Eye, Industrial Hand, and Industrial Brain. At the perception level (Industrial Eye), multimodal data fusion and real-time modeling in complex dynamic settings are examined. At the control level (Industrial Hand), flexible, adaptive, and precise manipulation for complex manufacturing processes is analyzed. At the decision level (Industrial Brain), intelligent optimization methods for process planning and line scheduling are summarized. By considering multi-level collaboration and interdisciplinary integration, this work reveals the key technological pathways of embodied intelligence for closed-loop optimization of perception-decision-execution in manufacturing systems. A three-stage evolution model for the development of embodied intelligence in flexible manufacturing scenarios, comprising cognition enhancement, skill transition, and system evolution, is proposed, and future development trends are examined, to offer both a theoretical framework and practical guidance for the interdisciplinary advancement of industrial embodied intelligence in the context of flexible manufacturing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06982", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06982", "abs": "https://arxiv.org/abs/2602.06982", "authors": ["Pujitha Mamillapalli", "Shikhar Verma", "Tiago Koketsu Rodrigues", "Abhinav Kumar"], "title": "Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks", "comment": null, "summary": "Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \\(11.3\\%\\) throughput improvement for a \\(4\\times4\\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08801", "categories": ["cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08801", "abs": "https://arxiv.org/abs/2602.08801", "authors": ["Thanh Le", "Hai Duong", "ThanhVu Nguyen", "Takeshi Matsumura"], "title": "Verifying DNN-based Semantic Communication Against Generative Adversarial Noise", "comment": "18 pages", "summary": "Safety-critical applications like autonomous vehicles and industrial IoT are adopting semantic communication (SemCom) systems using deep neural networks to reduce bandwidth and increase transmission speed by transmitting only task-relevant semantic features.\n  However, adversarial attacks against these DNN-based SemCom systems can cause catastrophic failures by manipulating transmitted semantic features.\n  Existing defense mechanisms rely on empirical approaches provide no formal guarantees against the full spectrum of adversarial perturbations.\n  We present VSCAN, a neural network verification framework that provides mathematical robustness guarantees by formulating adversarial noise generation as mixed integer programming and verifying end-to-end properties across multiple interconnected networks (encoder, decoder, and task model).\n  Our key insight is that realistic adversarial constraints (power limitations and statistical undetectability) can be encoded as logical formulae to enable efficient verification using state-of-the-art DNN verifiers.\n  Our evaluation on 600 verification properties characterizing various attacker's capabilities shows VSCAN matches attack methods in finding vulnerabilities while providing formal robustness guarantees for 44% of properties -- a significant achievement given the complexity of multi-network verification.\n  Moreover, we reveal a fundamental security-efficiency tradeoff: compact 16-dimensional latent spaces achieve 50% verified robustness compared to 64-dimensional spaces.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08452", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.08452", "abs": "https://arxiv.org/abs/2602.08452", "authors": ["Senthil Rajasekaran", "Moshe Y. Vardi"], "title": "Modeling Concurrent Multi-Agent Systems", "comment": null, "summary": "Recent work in the field of multi-agent systems has sought to use techniques and concepts from the field of formal methods to provide rigorous theoretical analysis and guarantees on complex systems where multiple agents strategically interact, leading to the creation of the field of equilibrium analysis, which studies equilibria concepts from the field of game theory through a complexity-theoretic lens. Multi-agent systems, however, are complex mathematical objects, and, therefore, defining them in a precise mathematical manner is non-trivial. As a result, researchers often considered more restrictive models that are easier to model but lack expressive power or simply omit critical complexity-theoretic results in their analysis. This paper addresses this problem by carefully analyzing and contrasting complexity-theoretic results in the explicit model, a mathematically precise formulation of the models commonly used in the literature, and the circuit-based model, a novel model that addresses the problems found in the literature. The utility of the circuit-based model is demonstrated through a comprehensive analysis that considers upper and lower bounds for the realizability and verification problems, the two most important decision problems in equilibrium analysis, for both models. By conducting this analysis, we see that problematic issues that are endemic to the explicit model and the equilibrium analysis literature as a whole are adequately handled by the circuit-based model.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07614", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07614", "abs": "https://arxiv.org/abs/2602.07614", "authors": ["Rosario Napoli", "Gabriele Morabito", "Antonio Celesti", "Massimo Villari", "Maria Fazio"], "title": "Knowledge Graphs-Driven Intelligence for Distributed Decision Systems", "comment": "Accepted to the 18th IEEE/ACM International Conference on Utility and Cloud Computing (UCC 2025)", "summary": "Modern distributed decision-making systems face significant challenges arising from data heterogeneity, dynamic environments, and the need for decentralized coordination. This paper introduces the Knowledge Sharing paradigm as an innovative approach that uses the semantic richness of Knowledge Graphs (KGs) and the representational power of Graph Embeddings (GEs) to achieve decentralized intelligence. Our architecture empowers individual nodes to locally construct semantic representations of their operational context, iteratively aggregating embeddings through neighbor-based exchanges using GraphSAGE. This iterative local aggregation process results in a dynamically evolving global semantic abstraction called Knowledge Map, enabling coordinated decision-making without centralized control. To validate our approach, we conduct extensive experiments under a distributed resource orchestration use case. We simulate different network topologies and node workloads, analyzing the local semantic drift of individual nodes. Experimental results confirm that our distributed knowledge-sharing mechanism effectively maintains semantic coherence and adaptability, making it suitable for complex and dynamic environments such as Edge Computing, IoT, and multi-agent systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07215", "categories": ["eess.SY", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07215", "abs": "https://arxiv.org/abs/2602.07215", "authors": ["Haiyuan Li", "Hari Madhukumar", "Shuangyi Yan", "Yulei Wu", "Dimitra Simeonidou"], "title": "Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks", "comment": null, "summary": "Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile edge networks emerges as a promising solution. However, it also poses new challenges, including heterogeneous multi-modal LMs with diverse resource demands and inference speeds, varied prompt/output modalities that complicate orchestration, and resource-limited infrastructure ill-suited for concurrent LM execution. In response, we propose a Multi-Agentic AI framework for latency- and fairness-aware multi-modal LM inference in mobile edge networks. Our solution includes a long-term planning agent, a short-term prompt scheduling agent, and multiple on-node LM deployment agents, all powered by foundation language models. These agents cooperatively optimize prompt routing and LM deployment through natural language reasoning over runtime telemetry and historical experience. To evaluate its performance, we further develop a city-wide testbed that supports network monitoring, containerized LM deployment, intra-server resource management, and inter-server communications. Experiments demonstrate that our solution reduces average latency by over 80% and improves fairness (Normalized Jain index) to 0.90 compared to other baselines. Moreover, our solution adapts quickly without fine-tuning, offering a generalizable solution for optimizing GenAI services in edge environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07355", "categories": ["cs.DS", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.07355", "abs": "https://arxiv.org/abs/2602.07355", "authors": ["Kanstantsin Pashkovich", "Thomas Snow"], "title": "Online Algorithm for Fractional Matchings with Edge Arrivals in Graphs of Maximum Degree Three", "comment": null, "summary": "We study online algorithms for maximum cardinality matchings with edge arrivals in graphs of low degree. Buchbinder, Segev, and Tkach showed that no online algorithm for maximum cardinality fractional matchings can achieve a competitive ratio larger than $4/(9-\\sqrt 5)\\approx 0.5914$ even for graphs of maximum degree three. The negative result of Buchbinder et al. holds even when the graph is bipartite and edges are revealed according to vertex arrivals, i.e. once a vertex arrives, all edges are revealed that include the newly arrived vertex and one of the previously arrived vertices. In this work, we complement the negative result of Buchbinder et al. by providing an online algorithm for maximum cardinality fractional matchings with a competitive ratio at least $4/(9-\\sqrt 5)\\approx 0.5914$ for graphs of maximum degree three. We also demonstrate that no online algorithm for maximum cardinality integral matchings can have the competitive guarantee $0.5807$, establishing a gap between integral and fractional matchings for graphs of maximum degree three. Note that the work of Buchbinder et al. shows that for graphs of maximum degree two, there is no such gap between fractional and integral matchings, because for both of them the best achievable competitive ratio is $2/3$. Also, our results demonstrate that for graphs of maximum degree three best possible competitive ratios for fractional matchings are the same in the vertex arrival and in the edge arrival models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07002", "categories": ["cs.NE", "cond-mat.mtrl-sci", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07002", "abs": "https://arxiv.org/abs/2602.07002", "authors": ["Masahi Okada", "Kazuki Sakai", "Hiroaki Yoshida", "Masaki Okoshi", "Tadahiro Taniguchi"], "title": "MolLIBRA: Genetic Molecular Optimization with Multi-Fingerprint Surrogates and Text-Molecule Aligned Critic", "comment": null, "summary": "We study sample-efficient molecular optimization under a limited budget of oracle evaluations. We propose MolLIBRA (MultimOdaLity and Language Integrated Bayesian and evolutionaRy optimizAtion), a genetic algorithm based framework that pre-ranks candidate molecules using multiple critics before oracle calls: (i) an ensemble of Gaussian process (GP) surrogates defined over multiple molecular fingerprints and (ii) a pretrained text-molecule aligned encoder CLAMP. The GP ensemble enables adaptive selection of task-appropriate fingerprints, while CLAMP provides a zero-shot scoring signal from task descriptions by measuring the similarity between molecular and text embeddings. On the Practical Molecular Optimization (PMO) benchmark with a budget of 1,000 evaluations (PMO-1K), MolLIBRA-L, our variant with a language-model-based candidate generator, attains the best Top-10 AUC on 14/22 tasks and the highest overall sum of Top-10 AUC across tasks among prior methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07140", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07140", "abs": "https://arxiv.org/abs/2602.07140", "authors": ["Miguel Morales C\u00f3cera", "Marta Prada", "Franz Fischer", "Gabriel Bester"], "title": "Microscopic origin of Rashba coupling from first principles: Layer-resolved orbital asymmetry in transition metal dichalcogenides", "comment": "9 pages, 6 figures", "summary": "Spin-orbit coupling in two-dimensional materials gives rise to a Rashba spin splitting when inversion and mirror symmetries are broken, yet its microscopic origin and quantitative characterization in transition metal dichalcogenides remains incomplete. Both symmetries are broken in certain bilayer structures, enabling Rashba splittings in the absence of external electric fields. We determine this zero-field offset and the Rashba parameters that dictate the spin splitting in the linear regime. Surprisingly, the splitting is substantially smaller in bilayers than in monolayers at typical fields. This is clarified within a perturbative microscopic model, revealing that the spin splitting results from a competition between internal polarization and interlayer hybridization. We further introduce the orbital polarization imbalance as an order parameter that captures the asymmetry of the valence bands and determines the spin ordering of the Rashba-split states. Our results are both quantitative and qualitative, as they clarify the nature and origin of Rashba coupling in transition metal dichalcogenides.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07573", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07573", "abs": "https://arxiv.org/abs/2602.07573", "authors": ["Ruiyi Fang", "Shuo Wang", "Ruizhi Pu", "Qiuhao Zeng", "Hao Zheng", "Ziyan Wang", "Jiale Cai", "Zhimin Mei", "Song Tang", "Charles Ling", "Boyu Wang"], "title": "Graph Domain Adaptation via Homophily-Agnostic Reconstructing Structure", "comment": "Accept by AAAI2026(oral)", "summary": "Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. However, existing GDA methods typically assume that both source and target graphs exhibit homophily, leading existing methods to perform poorly when heterophily is present. Furthermore, the lack of labels in the target graph makes it impossible to assess its homophily level beforehand. To address this challenge, we propose a novel homophily-agnostic approach that effectively transfers knowledge between graphs with varying degrees of homophily. Specifically, we adopt a divide-and-conquer strategy that first separately reconstructs highly homophilic and heterophilic variants of both the source and target graphs, and then performs knowledge alignment separately between corresponding graph variants. Extensive experiments conducted on five benchmark datasets demonstrate the superior performance of our approach, particularly highlighting its substantial advantages on heterophilic graphs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06975", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06975", "abs": "https://arxiv.org/abs/2602.06975", "authors": ["R. James Cotton", "Thomas Leonard"], "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents", "comment": null, "summary": "Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07236", "categories": ["cond-mat.mtrl-sci", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.07236", "abs": "https://arxiv.org/abs/2602.07236", "authors": ["Reshna Shrestha", "Wanyi Nie"], "title": "Impact of crystallinity on the circular and linear dichroism signals in chiral perovskite", "comment": "5 main figures and 8 supporting figures", "summary": "Chiral perovskites owing to their broken mirror symmetry exhibit selective absorption of circularly polarized light manifesting a strong circular dichroism (CD). CD spectroscopy has been a key technique to understand chiral perovskites and how these semiconductors achieve chirality at the molecular level. However, there is a debate on whether the observed CD is intrinsic to the chiral crystal structures or is modulated by extrinsic phenomena particularly linear dichroism (LD) and linear birefringence (LB) effects. This work investigates the chiroptical properties of $(R-/S-\\text{MBA})_2\\mathrm{CuCl}_4$ (MBA = Methylbenzyl ammonium) series by thoroughly studying the contribution from LD and LB to the observed CD signals. The comparison of highly oriented and randomly oriented films exhibits notable LD and LB contributions to the observed CD, which are caused by orientation-dependent electric-field interactions and local anisotropy. Both randomly and highly oriented films exhibit distinct CD responses, with LD--LB effects largely dominating the CD in highly oriented films. This has been revealed by the obvious shift in the observed CD signals to the below-absorption-edge ($\\sim 430$ nm) regime and broadening of features. Our findings demonstrate that careful consideration of crystal orientation and structural effects is necessary for appropriate interpretation of CD spectra in chiral perovskite thin films.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07518", "categories": ["cs.ET", "cs.AR", "cs.LG", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.07518", "abs": "https://arxiv.org/abs/2602.07518", "authors": ["Manuel Escudero", "Mohamadreza Zolfagharinejad", "Sjoerd van den Belt", "Nikolaos Alachiotis", "Wilfred G. van der Wiel"], "title": "Physical Analog Kolmogorov-Arnold Networks based on Reconfigurable Nonlinear-Processing Units", "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) shift neural computation from linear layers to learnable nonlinear edge functions, but implementing these nonlinearities efficiently in hardware remains an open challenge. Here we introduce a physical analog KAN architecture in which edge functions are realized in materia using reconfigurable nonlinear-processing units (RNPUs): multi-terminal nanoscale silicon devices whose input-output characteristics are tuned via control voltages. By combining multiple RNPUs into an edge processor and assembling these blocks into a reconfigurable analog KAN (aKAN) architecture with integrated mixed-signal interfacing, we establish a realistic system-level hardware implementation that enables compact KAN-style regression and classification with programmable nonlinear transformations. Using experimentally calibrated RNPU models and hardware measurements, we demonstrate accurate function approximation across increasing task complexity while requiring fewer or comparable trainable parameters than multilayer perceptrons (MLPs). System-level estimates indicate an energy per inference of $\\sim$250 pJ and an end-to-end inference latency of $\\sim$600 ns for a representative workload, corresponding to a $\\sim$10$^{2}$-10$^{3}\\times$ reduction in energy accompanied by a $\\sim$10$\\times$ reduction in area compared to a digital fixed-point MLP at similar approximation error. These results establish RNPUs as scalable, hardware-native nonlinear computing primitives and identify analog KAN architectures as a realistic silicon-based pathway toward energy-, latency-, and footprint-efficient analog neural-network hardware, particularly for edge inference.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07334", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.07334", "abs": "https://arxiv.org/abs/2602.07334", "authors": ["Eishin Nako", "Ryosho Nakane", "Mitsuru Takenaka", "Kasidit Toprasertpong", "Shinichi Takagi"], "title": "Substrate-Voltage-Controlled Temporal Nonlinearity in Ferroelectric FET-based Reservoir Computing", "comment": null, "summary": "Physical reservoir computing exploits inherent nonlinearity and short-term memory of physical dynamics to achieve efficient processing of time-series data with extremely-low training cost. In this study, we demonstrate a ferroelectric field-effect transistor (FeFET)-based reservoir computing system with augmented temporal and spatial nonlinearity by utilizing both gate and substrate terminals as inputs. The ferroelectric polarization state in the next time step can additionally be controlled by modifying the electric field distribution in the gate stack of FeFET through a substrate input, enabling more diverse internal states compared with the case where inputs are applied only to the gate. To introduce a nonlinearity in the time domain, we introduce a delay between a gate input and a substrate input, which facilitates efficient nonlinear mixing between the current and past inputs. As a result, both the short-term memory and nonlinearity of the FeFET reservoir computing system are enhanced with an improved capability of feature extraction of complex input time-series. These findings demonstrate that introducing substrate input provides an additional degree of freedom for controlling ferroelectric polarization dynamics, enabling a flexible, energy-efficient, and highly integrable FeFET-based reservoir computing platform suitable for diverse time-series processing applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06967", "categories": ["cs.RO", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06967", "abs": "https://arxiv.org/abs/2602.06967", "authors": ["Siqi Song", "Xuanbing Xie", "Zonglin Li", "Yuqiang Li", "Shijie Wang", "Biqing Qi"], "title": "Leveraging Adaptive Group Negotiation for Heterogeneous Multi-Robot Collaboration with Large Language Models", "comment": "20 pages, 12 figures, Under Review", "summary": "Multi-robot collaboration tasks often require heterogeneous robots to work together over long horizons under spatial constraints and environmental uncertainties. Although Large Language Models (LLMs) excel at reasoning and planning, their potential for coordinated control has not been fully explored. Inspired by human teamwork, we present CLiMRS (Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System), an adaptive group negotiation framework among LLMs for multi-robot collaboration. This framework pairs each robot with an LLM agent and dynamically forms subgroups through a general proposal planner. Within each subgroup, a subgroup manager leads perception-driven multi-LLM discussions to get commands for actions. Feedback is provided by both robot execution outcomes and environment changes. This grouping-planning-execution-feedback loop enables efficient planning and robust execution. To evaluate these capabilities, we introduce CLiMBench, a heterogeneous multi-robot benchmark of challenging assembly tasks. Our experiments show that CLiMRS surpasses the best baseline, achieving over 40% higher efficiency on complex tasks without sacrificing success on simpler ones. Overall, our results demonstrate that leveraging human-inspired group formation and negotiation principles significantly enhances the efficiency of heterogeneous multi-robot collaboration. Our code is available here: https://github.com/song-siqi/CLiMRS.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06983", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06983", "abs": "https://arxiv.org/abs/2602.06983", "authors": ["Alison M. Fernandes", "Hermes I. Del Monego", "Bruno S. Chang", "Anelise Munaretto", "H\u00e9lder M. Fontes", "Rui Campos"], "title": "Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing", "comment": "6 pages, 6 figures", "summary": "This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture, which integrates Inception networks responsible for hierarchical spatial feature extraction and Bidirectional Long Short-Term Memory (BiLSTM) networks that capture temporal dependencies. A Support Vector Machine (SVM) is then utilized as the final classification layer to optimize decision boundaries. The framework's efficacy was systematically validated using a public dataset across 20, 40, and 80 MHz bandwidth configurations. The model yielded accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), respectively. These results confirm a marked superiority over standalone deep learning baselines, especially in the most constrained low-bandwidth scenarios. This study underscores the utility of combining Doppler-based feature engineering with a hybrid learning architecture for reliable HAR in bandwidth-limited wireless sensing applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08081", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.08081", "abs": "https://arxiv.org/abs/2602.08081", "authors": ["Brian Rojkov", "Shubham Ranjan", "Derek Wright", "Manoj Sachdev"], "title": "Investigating Energy Bounds of Analog Compute-in-Memory with Local Normalization", "comment": null, "summary": "Modern edge AI workloads demand maximum energy efficiency, motivating the pursuit of analog Compute-in-Memory (CIM) architectures. Simultaneously, the popularity of Large-Language-Models (LLMs) drives the adoption of low-bit floating-point formats which prioritize dynamic range. However, the conventional direct-accumulation CIM accommodates floating-points by normalizing them to a shared widened fixed-point scale. Consequently, hardware resolution is dictated by the input's dynamic range rather than its precision, and energy consumption is dominated by the ADC. We address this limitation by introducing local normalization for each input, weight, and multiply-accumulate (MAC) output via a Gain-Ranging MAC (GR-MAC). Normalization overhead is handled by low-power digital logic, enabling the computationally expensive MAC operation to remain in the energy-efficient low-precision analog regime. Energy modelling shows that the addition of a gain-ranging Stage to the MAC enables a 4-bit increase in input dynamic range without increased energy consumption at a 35 dB SQNR standard. Additionally, the ADC resolution requirement becomes invariant to input distribution assumptions, allowing construction of an upper bound with a 1.5-bit reduction compared to the conventional lower bound. These results establish a pathway towards unlocking favourable energy scaling trends of analog CIM for modern AI workloads.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08846", "categories": ["cs.LO", "cs.PL", "math.CT", "math.LO"], "pdf": "https://arxiv.org/pdf/2602.08846", "abs": "https://arxiv.org/abs/2602.08846", "authors": ["Sam Speight", "Niels van der Weide"], "title": "Impredicativity in Linear Dependent Type Theory", "comment": "20 pages, 2 figures", "summary": "We construct a realizability model of linear dependent type theory from a linear combinatory algebra. Our model motivates a number of additions to the type theory. In particular, we add a universe with two decoding operations: one takes codes to cartesian types and the other takes codes to linear types. The universe is impredicative in the sense that it is closed under both large cartesian dependent products and large linear dependent products. We also add a rule for injectivity of the modality turning linear terms into cartesian terms. With all of the additions, we are able to encode (linear) inductive types. As a case study, we consider the type of lists over a linear type, and demonstrate that our encoding has the relevant uniqueness principle. The construction of the realizability model is fully formalized in the proof assistant Rocq.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08504", "categories": ["cs.GT", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08504", "abs": "https://arxiv.org/abs/2602.08504", "authors": ["Piotr Skowron"], "title": "A General Theory of Proportionality with Additive Utilities", "comment": null, "summary": "We consider a model where a subset of candidates must be selected based on voter preferences, subject to general constraints that specify which subsets are feasible. This model generalizes committee elections with diversity constraints, participatory budgeting (including constraints specifying how funds must be allocated to projects from different pools), and public decision-making. Axioms of proportionality have recently been defined for this general model, but the proposed rules apply only to approval ballots, where each voter submits a subset of candidates she finds acceptable. We propose proportional rules for cardinal ballots, where each voter assigns a numerical value to each candidate corresponding to her utility if that candidate is selected. In developing these rules, we also introduce methods that produce proportional rankings, ensuring that every prefix of the ranking satisfies proportionality.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07850", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07850", "abs": "https://arxiv.org/abs/2602.07850", "authors": ["Shanuja Sasi"], "title": "Privacy-Preserving Coding Schemes for Multi-Access Distributed Computing Models", "comment": null, "summary": "Distributed computing frameworks such as MapReduce have become essential for large-scale data processing by decomposing tasks across multiple nodes. The multi-access distributed computing (MADC) model further advances this paradigm by decoupling mapper and reducer roles: dedicated mapper nodes store data and compute intermediate values, while reducer nodes are connected to multiple mappers and aggregate results to compute final outputs. This separation reduces communication bottlenecks without requiring file replication. In this paper, we introduce privacy constraints into MADC and develop private coded schemes for two specific connectivity models. We construct new families of extended placement delivery arrays and derive corresponding coding schemes that guarantee privacy of each reducer's assigned function.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07300", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07300", "abs": "https://arxiv.org/abs/2602.07300", "authors": ["Ganghui Cao", "Xunyuan Yin"], "title": "Distributed Omniscient Observers for Multi-Agent Systems", "comment": null, "summary": "This article proposes fully distributed omniscient observers for both heterogeneous and homogeneous linear multi-agent systems, through which each agent can estimate the states of all agents. The proposed observers not only contribute to distributed Nash equilibrium seeking in multi-player games, but also provide a designable self-organization mechanism for artificial swarms to emulate biological social behaviors, including sheepdog herding and honeybee dance communication.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07394", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07394", "abs": "https://arxiv.org/abs/2602.07394", "authors": ["Pan Peng", "Yuyang Wang"], "title": "Local Computation Algorithms for (Minimum) Spanning Trees on Expander Graphs", "comment": null, "summary": "We study \\emph{local computation algorithms (LCAs)} for constructing spanning trees. In this setting, the goal is to locally determine, for each edge $ e \\in E $, whether it belongs to a spanning tree $ T $ of the input graph $ G $, where $ T $ is defined implicitly by $ G $ and the randomness of the algorithm. It is known that LCAs for spanning trees do not exist in general graphs, even for simple graph families. We identify a natural and well-studied class of graphs -- \\emph{expander graphs} -- that do admit \\emph{sublinear-time} LCAs for spanning trees. This is perhaps surprising, as previous work on expanders only succeeded in designing LCAs for \\emph{sparse spanning subgraphs}, rather than full spanning trees. We design an LCA with probe complexity $ O\\left(\\sqrt{n}\\left(\\frac{\\log^2 n}{\u03c6^2} + d\\right)\\right)$ for graphs with conductance at least $ \u03c6$ and maximum degree at most $ d $ (not necessarily constant), which is nearly optimal when $\u03c6$ and $d$ are constants, since $\u03a9(\\sqrt{n})$ probes are necessary even for expanders. Next, we show that for the natural class of \\emph{\\ER graphs} $ G(n, p) $ with $ np = n^\u03b4 $ for any constant $ \u03b4> 0 $ (which are expanders with high probability), the $ \\sqrt{n} $ lower bound can be bypassed. Specifically, we give an \\emph{average-case} LCA for such graphs with probe complexity $ \\tilde{O}(\\sqrt{n^{1 - \u03b4}})$.\n  Finally, we extend our techniques to design LCAs for the \\emph{minimum spanning tree (MST)} problem on weighted expander graphs. Specifically, given a $d$-regular unweighted graph $\\bar{G}$ with sufficiently strong expansion, we consider the weighted graph $G$ obtained by assigning to each edge an independent and uniform random weight from $\\{1,\\ldots,W\\}$, where $W = O(d)$. We show that there exists an LCA that is consistent with an exact MST of $G$, with probe complexity $\\tilde{O}(\\sqrt{n}d^2)$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07009", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07009", "abs": "https://arxiv.org/abs/2602.07009", "authors": ["MD Azizul Hakim"], "title": "Multi-Scale Temporal Homeostasis Enables Efficient and Robust Neural Networks", "comment": null, "summary": "Artificial neural networks achieve strong performance on benchmark tasks but remain fundamentally brittle under perturbations, limiting their deployment in real-world settings. In contrast, biological nervous systems sustain reliable function across decades through homeostatic regulation coordinated across multiple temporal scales. Inspired by this principle, this presents Multi-Scale Temporal Homeostasis (MSTH), a biologically grounded framework that integrates ultra-fast (5-ms), fast (2-s), medium (5-min) and slow (1-hrs) regulation into artificial networks. MSTH implements the cross-scale coordination system for artificial neural networks, providing a unified temporal hierarchy that moves beyond superficial biomimicry. The cross-scale coordination enhances computational efficiency through evolutionary-refined optimization mechanisms. Experiments across molecular, graph and image classification benchmarks show that MSTH consistently improves accuracy, eliminates catastrophic failures and enhances recovery from perturbations. Moreover, MSTH outperforms both single-scale bio-inspired models and established state-of-the-art methods, demonstrating generality across diverse domains. These findings establish cross-scale temporal coordination as a core principle for stabilizing artificial neural systems, positioning MSTH as a foundation for building robust, resilient and biologically faithful intelligence.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07332", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.07332", "abs": "https://arxiv.org/abs/2602.07332", "authors": ["Qiang Lin", "Ying-Xin Liang", "Ke He", "Zhan Cao"], "title": "Excess photon-assisted noise of Majorana and Andreev bound states", "comment": "16 pages, 10 figures", "summary": "Photon-assisted tunneling arises under an ac bias, with the drive frequency setting the photon energy. The excess photon-assisted noise is defined as the difference between the shot noise under a combined dc and ac bias and that under a dc bias alone. We investigate this quantity in tunneling into Majorana or Andreev bound states, which are of great interest in the search for topological superconductors. Under a harmonic bias $V(t)=V_\\mathrm{dc}[1-\\cos(\u03a9t)]$, the excess photon-assisted noise exhibits distinct behaviors: for Majorana or quasi-Majorana bound states, it undergoes multiple sign reversals as $V_\\mathrm{dc}$ increases and vanishes at nonzero integer values of $eV_\\mathrm{dc}/\u03a9$ (with $e$ the elementary charge), whereas for zero-energy Andreev bound states--particularly those producing nearly quantized zero-bias conductance peaks--it remains strictly negative over the entire $V_\\mathrm{dc}$ range.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07781", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07781", "abs": "https://arxiv.org/abs/2602.07781", "authors": ["Nazanin Sabri", "Ananya Malik", "Bangzhao Shu", "Jason Snyder", "Laurie Kramer", "Mai Elsherief"], "title": "\"He gets to be the fun parent\": Understanding and Supporting Burnt-Out Mothers in Online Communities", "comment": null, "summary": "Maternal burnout is a psychological phenomena with documented harms to both mother and child, requiring prompt attention. Mothers experiencing burnout might choose to turn to online anonymous platforms, such as Reddit, to share their experience, due to feelings of shame and stigmatization of mental health issues. In this work, we study how mothers use Reddit to discuss their experiences of burnout. We first identify posts written by burnt out mothers by manually annotating Reddit posts and training machine learning models on them. Focusing on posts made by this population (N = 3,244), we then investigate the issues brought up by mothers, such as the need for help, career advice, and co-parenting issues. Additionally, we investigate how the Reddit community responds to these posts through the analysis of comments. We find that commenters frequently share personal lived experiences with the poster, and provide emotional support. Finally, considering co-parenting could be a mitigating factor for parental burnout, we explore co-pareting patterns experienced by burnt out mothers, finding evidence of lack of support for and unequal expectations from mothers.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06976", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.06976", "abs": "https://arxiv.org/abs/2602.06976", "authors": ["Chen Shen", "Wei Cheng", "Jingyue Yang", "Huan Zhang", "Yuhan Wu", "Wei Hu"], "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks", "comment": null, "summary": "The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07289", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07289", "abs": "https://arxiv.org/abs/2602.07289", "authors": ["John D. Clayton"], "title": "Constitutive theory for mechanics of amorphous thermoplastic polymers under extreme dynamic loading", "comment": "66 pages, 9 figures", "summary": "A geometrically nonlinear continuum mechanical theory is formulated for deformation and failure behaviors of amorphous polymers. The model seeks to capture material response over a range of loading rates, temperatures, and stress states encompassing shock compression, inelasticity, melting, decomposition, and spallation. Thermoelasticity, viscoelasticity, viscoplasticity, ductile failure with localized shear yielding, and brittle fracture with crazing can all emerge under this ensemble of intense loading conditions. Known prior theories have considered one or more, but not all, such physical mechanisms. The present coherent formulation invokes thermodynamics with internal state variables for dynamic molecular and network configurational changes affecting viscoelasticity and plastic deformation, and it uses order parameters for more abrupt structural changes across state-dependent glass-transition and shock-decomposition thresholds. A phase-field order parameter captures material degradation from ductile or brittle fracture, including evolving porosity from crazing. The theory is applied toward polymethyl methacrylate (PMMA) under intense dynamic loading. The high-pressure equilibrium response, with shear strength and temperature over known ranges, is well represented along the principal Hugoniot to pressures far exceeding shock decomposition. Predicted release wave velocities agree with experiment. A semi-analytical solution for steady waves describes the relatively lower-pressure viscoelastic setting, providing insight into relaxation times. One-dimensional calculations assess suitability of the model for representing spall fracture strengths seen in experiments over a range of initial temperatures and loading rates.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07724", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.07724", "abs": "https://arxiv.org/abs/2602.07724", "authors": ["Yingjie Li", "Shanglin Zhou", "Caiwen Ding", "Cunxi Yu"], "title": "HoloGraph: All-Optical Graph Learning via Light Diffraction", "comment": null, "summary": "As a representative of next-generation device/circuit technology beyond CMOS, physics-based neural networks such as Diffractive Optical Neural Networks (DONNs) have demonstrated promising advantages in computational speed and energy efficiency. However, existing DONNs and other physics-based neural networks have mostly focused on exploring their machine intelligence, with limited studies in handling graph-structured tasks. Thus, we introduce HoloGraph, the first monolithic free-space all-optical graph neural network system. It proposes a novel, domain-specific message-passing mechanism with optical skip channels integrated into light propagation for the all-optical graph learning. HoloGraph enables light-speed optical message passing over graph structures with diffractive propagation and phase modulations. Our experimental results with HoloGraph, conducted using standard graph learning datasets Cora-ML and Citeseer, show competitive or even superior classification performance compared to conventional digital graph neural networks. Comprehensive ablation studies demonstrate the effectiveness of the proposed novel architecture and algorithmic methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07925", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.07925", "abs": "https://arxiv.org/abs/2602.07925", "authors": ["Zhigang Li", "Guobin Bai", "Hengwei Cui", "Wenlong Yao", "Jianfeng Gao", "Qifeng Jiang", "Junjie Li", "Junfeng Li", "Yongliang Li", "Huaxiang Yin", "Xiaolei Wang", "Jun Luo"], "title": "Physics Guided Exponential Model Design of High Ge Content SiGe Selective Epitaxy for Gate All Around Source/Drain Applications", "comment": null, "summary": "High germanium content silicon germanium (SiGe) epitaxy is critical for strain engineering in advanced gate all around (GAA) transistors. This paper demonstrates a physics guided exponential function model that quantitatively links selective epitaxial growth (SEG) parameters to Ge incorporation kinetics in nanoscale trenches. By coupling surface diffusion limited transport, gradient strain, and competitive adsorption dynamics, the model predicts optimal conditions for bottom-up filling with maximal Ge content. For trenches with widths of approximately 60 nm, the optimized process achieved a maximum Ge content of 57.93% and demonstrated 100% selectivity against silicon nitride (SiN) and silicon dioxide (SiO). Cross sectional TEM and EDS analyses reveal a graded Ge profile that minimizes interfacial defects and strain energy. Our results show that the established process physics correlation will significantly facilitate the development of GAA devices with 5nm CMOS technology nodes and beyond.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06968", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.06968", "abs": "https://arxiv.org/abs/2602.06968", "authors": ["Xubo Luo", "Zhaojin Li", "Xue Wan", "Wei Zhang", "Leizheng Shu"], "title": "Learning to Anchor Visual Odometry: KAN-Based Pose Regression for Planetary Landing", "comment": "8 pages, accepted by RA-L", "summary": "Accurate and real-time 6-DoF localization is mission-critical for autonomous lunar landing, yet existing approaches remain limited: visual odometry (VO) drifts unboundedly, while map-based absolute localization fails in texture-sparse or low-light terrain. We introduce KANLoc, a monocular localization framework that tightly couples VO with a lightweight but robust absolute pose regressor. At its core is a Kolmogorov-Arnold Network (KAN) that learns the complex mapping from image features to map coordinates, producing sparse but highly reliable global pose anchors. These anchors are fused into a bundle adjustment framework, effectively canceling drift while retaining local motion precision. KANLoc delivers three key advances: (i) a KAN-based pose regressor that achieves high accuracy with remarkable parameter efficiency, (ii) a hybrid VO-absolute localization scheme that yields globally consistent real-time trajectories (>=15 FPS), and (iii) a tailored data augmentation strategy that improves robustness to sensor occlusion. On both realistic synthetic and real lunar landing datasets, KANLoc reduces average translation and rotation error by 32% and 45%, respectively, with per-trajectory gains of up to 45%/48%, outperforming strong baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06990", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.06990", "abs": "https://arxiv.org/abs/2602.06990", "authors": ["Zhuo Li", "Shuqiang Wang"], "title": "A Pre-trained EEG-to-MEG Generative Framework for Enhancing BCI Decoding", "comment": null, "summary": "Electroencephalography (EEG) and magnetoencephalography (MEG) play important and complementary roles in non-invasive brain-computer interface (BCI) decoding. However, compared to the low cost and portability of EEG, MEG is more expensive and less portable, which severely limits the practical application of MEG in BCI systems. To overcome this limitation, this study proposes the first cross-modal generation framework based on EEG-MEG spatiotemporal coupled representations to synthesize MEG signals cost-effectively. The framework first extracts general neural activity representations through a pre-trained EEG model. Building upon these representations, the framework effectively learns the lower spatial dispersion and higher high-frequency sensitivity of MEG via the spatial focus mapping module and the broadband spectral calibration module. Experimental results demonstrate that the synthesized MEG signals show high consistency with the real MEG in both time-frequency characteristics and source space activation patterns. More importantly, downstream BCI decoding experiments demonstrate that using synthesized MEG leads to performance enhancements not only on paired EEG-MEG datasets but also on independent EEG-only datasets. Overall, this framework opens a new avenue for overcoming data bottlenecks in BCI.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08323", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08323", "abs": "https://arxiv.org/abs/2602.08323", "authors": ["Yousuf Choudhary", "Tosiron Adegbija"], "title": "Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study", "comment": "Design, Automation and Test in Europe (DATE) 2026", "summary": "Antiferromagnetic Tunnel Junctions (AFMTJs) enable picosecond switching and femtojoule writes through ultrafast sublattice dynamics. We present the first end-to-end AFMTJ simulation framework integrating multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level modeling. SPICE-based simulations show that AFMTJs achieve ~8x lower write latency and ~9x lower write energy than conventional MTJs. When integrated into an in-memory computing architecture, AFMTJs deliver 17.5x average speedup and nearly 20x energy savings versus a CPU baseline-significantly outperforming MTJ-based IMC. These results establish AFMTJs as a compelling primitive for scalable, low-power computing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07192", "categories": ["cs.LG", "cs.CE", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.07192", "abs": "https://arxiv.org/abs/2602.07192", "authors": ["Xiaolong He", "Haoyan Wei", "Wei Hu", "Henan Mao", "C. T. Wu"], "title": "Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling", "comment": null, "summary": "Deep Material Networks (DMNs) are structure-preserving, mechanistic machine learning models that embed micromechanical principles into their architectures, enabling strong extrapolation capabilities and significant potential to accelerate multiscale modeling of complex microstructures. A key advantage of these models is that they can be trained exclusively on linear elastic data and then generalized to nonlinear inelastic regimes during online prediction. Despite their growing adoption, systematic evaluations of their performance across the full offline-online pipeline remain limited. This work presents a comprehensive comparative assessment of DMNs with respect to prediction accuracy, computational efficiency, and training robustness. We investigate the effects of offline training choices, including initialization, batch size, training data size, and activation regularization on online generalization performance and uncertainty. The results demonstrate that both prediction error and variance decrease with increasing training data size, while initialization and batch size can significantly influence model performance. Moreover, activation regularization is shown to play a critical role in controlling network complexity and therefore generalization performance. Compared with the original DMN, the rotation-free Interaction-based Material Network (IMN) formulation achieves a 3.4x - 4.7x speed-up in offline training, while maintaining comparable online prediction accuracy and computational efficiency. These findings clarify key trade-offs between model expressivity and efficiency in structure-preserving material networks and provide practical guidance for their deployment in multiscale material modeling.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07092", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07092", "abs": "https://arxiv.org/abs/2602.07092", "authors": ["Haipeng Jiang", "Kailong Ren", "Zimo Yin", "Zhetao Sun", "Xin Gan", "Guangyi Lv", "Ming He", "Peng Wang", "Congli Yin", "Hong Pan", "Changwen Zhang", "Shan Tong", "Zhengyu Xu", "Zeping Chen", "Yubin Huangfu", "Yanzhi Xu", "Xing Su", "Qin Feng", "Dong An", "Jianping Fan"], "title": "Lemon Agent Technical Report", "comment": null, "summary": "Recent advanced LLM-powered agent systems have exhibited their remarkable capabilities in tackling complex, long-horizon tasks. Nevertheless, they still suffer from inherent limitations in resource efficiency, context management, and multimodal perception. Based on these observations, Lemon Agent is introduced, a multi-agent orchestrator-worker system built on a newly proposed AgentCortex framework, which formalizes the classic Planner-Executor-Memory paradigm through an adaptive task execution mechanism. Our system integrates a hierarchical self-adaptive scheduling mechanism that operates at both the overall orchestrator layer and workers layer. This mechanism can dynamically adjust computational intensity based on task complexity. It enables orchestrator to allocate one or more workers for parallel subtask execution, while workers can further improve operational efficiency by invoking tools concurrently. By virtue of this two-tier architecture, the system achieves synergistic balance between global task coordination and local task execution, thereby optimizing resource utilization and task processing efficiency in complex scenarios. To reduce context redundancy and increase information density during parallel steps, we adopt a three-tier progressive context management strategy. To make fuller use of historical information, we propose a self-evolving memory system, which can extract multi-dimensional valid information from all historical experiences to assist in completing similar tasks. Furthermore, we provide an enhanced MCP toolset. Empirical evaluations on authoritative benchmarks demonstrate that our Lemon Agent can achieve a state-of-the-art 91.36% overall accuracy on GAIA and secures the top position on the xbench-DeepSearch leaderboard with a score of 77+.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07369", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07369", "abs": "https://arxiv.org/abs/2602.07369", "authors": ["Julian Knodt", "Xifeng Gao"], "title": "Convex Primitive Decomposition for Collision Detection", "comment": null, "summary": "Creation of collision objects for 3D models is a time-consuming task, requiring modelers to manually place primitives such as bounding boxes, capsules, spheres, and other convex primitives to approximate complex meshes. While there has been work in automatic approximate convex decompositions of meshes using convex hulls, they are not practical for applications with tight performance budgets such as games due to slower collision detection and inability to manually modify the output while maintaining convexity as compared to manually placed primitives. Rather than convex decomposition with convex hulls, we devise an approach for bottom-up decomposition of an input mesh into convex primitives specifically for rigid body simulation inspired by quadric mesh simplification. This approach fits primitives to complex, real-world meshes that provide plausible simulation performance and are guaranteed to enclose the input surface. We test convex primitive decomposition on over 60 models from Sketchfab, showing the algorithm's effectiveness. On this dataset, convex primitive decomposition has lower one-way mean and median Hausdorff and Chamfer distance from the collider to the input compared to V-HACD and CoACD, with less than one-third of the complexity as measured by total bytes for each collider. On top of that, rigid-body simulation performance measured by wall-clock time is consistently improved across 24 tested models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08362", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.08362", "abs": "https://arxiv.org/abs/2602.08362", "authors": ["Chunxi Ji", "Adnan Darwiche"], "title": "Circuit Representations of Random Forests with Applications to XAI", "comment": null, "summary": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08549", "categories": ["cs.GT", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.08549", "abs": "https://arxiv.org/abs/2602.08549", "authors": ["V\u00e9ronique Bruy\u00e8re", "Emmanuel Filiot", "Christophe Grandmont", "Jean-Fran\u00e7ois Raskin"], "title": "An Automata-Based Approach to Games with $\u03c9$-Automatic Preferences", "comment": null, "summary": "This paper studies multiplayer turn-based games on graphs in which player preferences are modeled as $\u03c9$-automatic relations given by deterministic parity automata. This contrasts with most existing work, which focuses on specific reward functions. We conduct a computational analysis of these games, starting with the threshold problem in the antagonistic zero-sum case. As in classical games, we introduce the concept of value, defined here as the set of plays a player can guarantee to improve upon, relative to their preference relation. We show that this set is recognized by an alternating parity automaton APW of polynomial size. We also establish the computational complexity of several problems related to the concepts of value and optimal strategy, taking advantage of the $\u03c9$-automatic characterization of value. Next, we shift to multiplayer games and Nash equilibria, and revisit the threshold problem in this context. Based on an APW construction again, we close complexity gaps left open in the literature, and additionally show that cooperative rational synthesis is $\\mathsf{PSPACE}$-complete, while it becomes undecidable in the non-cooperative case.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08257", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08257", "abs": "https://arxiv.org/abs/2602.08257", "authors": ["Antonis Psistakis", "Burak Ocalan", "Fabien Chaix", "Ramnatthan Alagappan", "Josep Torrellas"], "title": "HEAL: Online Incremental Recovery for Leaderless Distributed Systems Across Persistency Models", "comment": null, "summary": "Ensuring resilience in distributed systems has become an acute concern. In today's environment, it is crucial to develop light-weight mechanisms that recover a distributed system from faults quickly and with only a small impact on the live-system throughput. To address this need, this paper proposes a new low-overhead, general recovery scheme for modern non-transactional leaderless distributed systems. We call our scheme HEAL. On a node failure, HEAL performs an optimized online incremental recovery. This paper presents HEAL's algorithms for settings with Linearizable consistency and different memory persistency models. We implement HEAL on a 6-node Intel cluster. Our experiments running TAOBench workloads show that HEAL is very effective. HEAL recovers the cluster in 120 milliseconds on average, while reducing the throughput of the running workload by an average of 8.7%. In contrast, a conventional recovery scheme for leaderless systems needs 360 seconds to recover, reducing the throughput of the system by 16.2%. Finally, compared to an incremental recovery scheme for a state-of-the-art leader-based system, HEAL reduces the average recovery latency by 20.7x and the throughput degradation by 62.4%.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07335", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.07335", "abs": "https://arxiv.org/abs/2602.07335", "authors": ["Minduli C. Wijayatunga", "Richard Linares", "Roberto Armellin"], "title": "Meta-Reinforcement Learning for Robust and Non-greedy Control Barrier Functions in Spacecraft Proximity Operations", "comment": null, "summary": "Autonomous spacecraft inspection and docking missions require controllers that can guarantee safety under thrust constraints and uncertainty. Input-constrained control barrier functions (ICCBFs) provide a framework for safety certification under bounded actuation; however, conventional ICCBF formulations can be overly conservative and exhibit limited robustness to uncertainty, leading to high fuel consumption and reduced mission feasibility. This paper proposes a framework in which the full hierarchy of class-$\\mathcal{K}$ functions defining the ICCBF recursion is parameterized and learned, enabling localized shaping of the safe set and reduced conservatism. A control margin is computed efficiently using differential algebra to enable the learned continuous-time ICCBFs to be implemented on time-sampled dynamical systems typical of spacecraft proximity operations. A meta-reinforcement learning scheme is developed to train a policy that generates ICCBF parameters over a distribution of hidden physical parameters and uncertainties, using both multilayer perceptron (MLP) and recurrent neural network (RNN) architectures. Simulation results on cruise control, spacecraft inspection, and docking scenarios demonstrate that the proposed approach maintains safety while reducing fuel consumption and improving feasibility relative to fixed class-$\\mathcal{K}$ ICCBFs, with the RNN showing a particularly strong advantage in the more complex inspection case.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07720", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07720", "abs": "https://arxiv.org/abs/2602.07720", "authors": ["Sharareh Alipour"], "title": "Robust Multiagent Collaboration Through Weighted Max-Min T-Joins", "comment": null, "summary": "Many multiagent tasks -- such as reviewer assignment, coalition formation, or fair resource allocation -- require selecting a group of agents such that collaboration remains effective even in the worst case. The \\emph{weighted max-min $T$-join problem} formalizes this challenge by seeking a subset of vertices whose minimum-weight matching is maximized, thereby ensuring robust outcomes against unfavorable pairings.\n  We advance the study of this problem in several directions. First, we design an algorithm that computes an upper bound for the \\emph{weighted max-min $2k$-matching problem}, where the chosen set must contain exactly $2k$ vertices. Building on this bound, we develop a general algorithm with a \\emph{$2 \\ln n$-approximation guarantee} that runs in $O(n^4)$ time. Second, using ear decompositions, we propose another upper bound for the weighted max-min $T$-join cost. We also show that the problem can be solved exactly when edge weights belong to $\\{1,2\\}$.\n  Finally, we evaluate our methods on real collaboration datasets. Experiments show that the lower bounds from our approximation algorithm and the upper bounds from the ear decomposition method are consistently close, yielding empirically small constant-factor approximations. Overall, our results highlight both the theoretical significance and practical value of weighted max-min $T$-joins as a framework for fair and robust group formation in multiagent systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07010", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07010", "abs": "https://arxiv.org/abs/2602.07010", "authors": ["Szymon Mamo\u0144", "Max Talanov", "Alessandro Crimi"], "title": "Learning Alzheimer's Disease Signatures by bridging EEG with Spiking Neural Networks and Biophysical Simulations", "comment": "11 pages ,8 figures", "summary": "As the prevalence of Alzheimer's disease (AD) rises, improving mechanistic insight from non-invasive biomarkers is increasingly critical. Recent work suggests that circuit-level brain alterations manifest as changes in electroencephalography (EEG) spectral features detectable by machine learning. However, conventional deep learning approaches for EEG-based AD detection are computationally intensive and mechanistically opaque. Spiking neural networks (SNNs) offer a biologically plausible and energy-efficient alternative, yet their application to AD diagnosis remains largely unexplored.\n  We propose a neuro-bridge framework that links data-driven learning with minimal, biophysically grounded simulations, enabling bidirectional interpretation between machine learning signatures and circuit-level mechanisms in AD. Using resting-state clinical EEG, we train an SNN classifier that achieves competitive performance (AUC = 0.839) and identifies the aperiodic 1/f slope as a key discriminative marker.\n  The 1/f slope reflects excitation-inhibition balance. To interpret this mechanistically, we construct spiking network simulations in which inhibitory-to-excitatory synaptic ratios are systematically varied to emulate healthy, mild cognitive impairment, and AD-like states. Using both membrane potential-based and synaptic current-based EEG proxies, we reproduce empirical spectral slowing and altered alpha organization.\n  Incorporating empirical functional connectivity priors into multi-subnetwork simulations further enhances spectral differentiation, demonstrating that large-scale network topology constrains EEG signatures more strongly than excitation-inhibition balance alone. Overall, this neuro-bridge approach connects SNN-based classification with interpretable circuit simulations, advancing mechanistic understanding of EEG biomarkers while enabling scalable, explainable AD detection.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07383", "categories": ["cond-mat.mes-hall", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.07383", "abs": "https://arxiv.org/abs/2602.07383", "authors": ["Koji Kudo", "Ryota Nakai", "Hiroki Isobe", "Kentaro Nomura"], "title": "Topological superconductivity on a kagome magnet coupled to a Rashba superconductor", "comment": "13 pages, 9 figures", "summary": "A quantum anomalous Hall system is predicted to realize topological superconductivity when proximity-coupled to an $s$-wave superconductor. A kagome magnet with chiral magnetic ordering exhibits the quantum anomalous Hall effect; however, superconducting proximity to an ordinary $s$-wave superconductor fails to induce pairing in the strong exchange coupling limit. In this work, we demonstrate that proximity coupling to a Rashba superconductor gives rise to topological superconducting phases characterized by odd Bogoliubov-de Gennes Chern numbers. We confirmed their consistency with the chiral central charge calculated based on the modular commutator. We also show that the magnetic ordering of kagome magnets is affected energetically by the proximity effect.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08569", "categories": ["cs.SI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08569", "abs": "https://arxiv.org/abs/2602.08569", "authors": ["Xu Min", "Zhaoxu Yang", "Kaixuan Tan", "Juan Yan", "Xunbin Xiong", "Zihao Zhu", "Kaiyu Zhu", "Fenglin Cui", "Yang Yang", "Sihua Yang", "Jianhui Bu"], "title": "Towards Reliable Social A/B Testing: Spillover-Contained Clustering with Robust Post-Experiment Analysis", "comment": null, "summary": "A/B testing is the foundation of decision-making in online platforms, yet social products often suffer from network interference: user interactions cause treatment effects to spill over into the control group. Such spillovers bias causal estimates and undermine experimental conclusions. Existing approaches face key limitations: user-level randomization ignores network structure, while cluster-based methods often rely on general-purpose clustering that is not tailored for spillover containment and has difficulty balancing unbiasedness and statistical power at scale. We propose a spillover-contained experimentation framework with two stages. In the pre-experiment stage, we build social interaction graphs and introduce a Balanced Louvain algorithm that produces stable, size-balanced clusters while minimizing cross-cluster edges, enabling reliable cluster-based randomization. In the post-experiment stage, we develop a tailored CUPAC estimator that leverages pre-experiment behavioral covariates to reduce the variance induced by cluster-level assignment, thereby improving statistical power. Together, these components provide both structural spillover containment and robust statistical inference. We validate our approach through large-scale social sharing experiments on Kuaishou, a platform serving hundreds of millions of users. Results show that our method substantially reduces spillover and yields more accurate assessments of social strategies than traditional user-level designs, establishing a reliable and scalable framework for networked A/B testing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07120", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07120", "abs": "https://arxiv.org/abs/2602.07120", "authors": ["Jacqueline He", "Jonathan Hayase", "Wen-tau Yih", "Sewoong Oh", "Luke Zettlemoyer", "Pang Wei Koh"], "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model", "comment": "51 pages, 12 figures, 16 tables. Code is publicly available at https://github.com/jacqueline-he/anchored-decoding", "summary": "Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07293", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07293", "abs": "https://arxiv.org/abs/2602.07293", "authors": ["Ayeman M. Nahin", "Jacob Pustelnik", "Jessica Dong", "Tamanna Zakia", "Mingwei Zhang"], "title": "A Low-Cost, Strong, and Ductile Single-Phase Nb-Based Refractory Complex Concentrated Alloy", "comment": null, "summary": "The development of structural materials capable of sustained operation above 1200 \u00b0C is critical for next-generation energy and aerospace systems; however, Ni-based superalloys are fundamentally constrained by their melting temperatures, while conventional Nb-based refractory alloys are limited by modest specific strength and high cost. Here, we report on the design and mechanical performance of a cost-effective, non-equiatomic refractory complex concentrated alloy (RCCA), Nb45Ta15Ti20V20, engineered to overcome these limitations. Specifically, its specific strength surpasses wrought C-103 and rivals additively manufactured (AM) C-103 at temperatures up to 1300 \u00b0C while maintaining extensive room temperature tensile ductility (>10 %). Coupled with a high melting point (~2167 \u00b0C), reduced density (8.67 g/cc), and a raw material cost of ~$130/kg compared to >$500/kg for wrought C-103 and >$2,500/kg for AM C-103, this alloy delivers superior specific strength-cost efficiency, highlighting the promise of non-equiatomic RCCAs as viable alternatives to commercial refractory alloys.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08080", "categories": ["cs.ET", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08080", "abs": "https://arxiv.org/abs/2602.08080", "authors": ["Luciano Bozzi", "Christian Celidonio", "Umberto Nuzzi", "Massimo Biagini", "Stefano Cherubin", "Asbj\u00f8rn Djupdal", "Tor Andre Haugdahl", "Andrea Aliverti", "Alessandra Angelucci", "Giovanni Agosta", "Gerardo Pelosi", "Paolo Belluco", "Samuele Polistina", "Riccardo Volpi", "Luigi Malag\u00f2", "Michael Schneider", "Florian Wieczorek", "Xabier Eguiluz"], "title": "The CAPSARII Approach to Cyber-Secure Wearable, Ultra-Low-Power Networked Sensors for Soldier Health Monitoring", "comment": null, "summary": "The European Defence Agency's revised Capability Development Plan (CDP) identifies as a priority improving ground combat capabilities by enhancing soldiers' equipment for better protection. The CAPSARII project proposes in innovative wearable system and Internet of Battlefield Things (IoBT) framework to monitor soldiers' physiological and psychological status, aiding tactical decisions and medical support. The CAPSARII system will enhance situational awareness and operational effectiveness by monitoring physiological, movement and environmental parameters, providing real-time tactical decision support through AI models deployed on edge nodes and enable data analysis and comparative studies via cloud-based analytics. CAPSARII also aims at improving usability through smart textile integration, longer battery life, reducing energy consumption through software and hardware optimizations, and address security concerns with efficient encryption and strong authentication methods. This innovative approach aims to transform military operations by providing a robust, data-driven decision support tool.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08056", "categories": ["physics.app-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08056", "abs": "https://arxiv.org/abs/2602.08056", "authors": ["Aayush Nayyar", "Ruizhe Yang", "Vashin Gautham", "Sagnik Das", "Haiqing Lin", "Andrew C. Antony", "Dean Thelen", "Mayukh Nath", "Gabriel Agnello", "Jun Liu"], "title": "Spatially and Temporally Resolved Mapping of Contact Electrification on Stand-Alone Ultrathin Glass Materials via Kelvin Probe Force Microscopy", "comment": null, "summary": "Contact electrification (CE) remains a critical challenge in advanced material technologies where uncontrolled surface charging can compromise manufacturability, reliability, and performance in practical applications. Ultrathin glass with micrometer-scale thickness is a state-of-the-art specialty oxide material for flexible touchscreens in next-generation electronic devices. Here, we visualize and quantify CE-induced surface charges on ultrathin glass using sideband-mode Kelvin probe force microscopy (KPFM). Nanoscale atomic force microscopy (AFM) probes are used to scan and induce triboelectric charges on stand-alone glass surfaces under ultra-pure N$_2$ conditions. Time-dependent measurements reveal that surface charges on a 30~$\u03bc$m-thick glass sample decay from 4.47~V to 0.37~V over 240~minutes. Furthermore, electrostatic charges are found to exhibit capacitor-like discharging behavior primarily through the bulk material, yielding a long relaxation time constant of approximately 41~minutes. This behavior differs from the lateral surface discharging observed in thermally grown SiO$2$ thin films reported previously. A self-capacitance analytical model is developed to estimate the corresponding surface charge density ($\u03c3$), yielding comparable values of 136.26~$\\pm$~16.25~$\u03bc$C/m$^2$ at 30~$\u03bc$m and 131.44~$\\pm$~28.41~$\u03bc$C/m$^2$ at 100~$\u03bc$m. Additionally, external bias applied to AFM tips can be used to enhance, suppress, or invert the intrinsic CE response of glass materials.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06969", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06969", "abs": "https://arxiv.org/abs/2602.06969", "authors": ["Roshan Kumar Chhetri", "Sarocha Jetawatthana", "Thanakorn Khamvilai"], "title": "A Survey of Medical Drones from Flight Dynamics, Guidance, Navigation, and Control Perspectives", "comment": null, "summary": "The integration of drones into the medical field has revolutionized healthcare delivery by enabling rapid transportation of medical supplies, organs, and even emergency assistance in remote or disaster-stricken areas. While other survey papers focus on the healthcare supply chain, operations, and medical emergency response aspects, this paper provides a comprehensive review of medical drones from the perspectives of flight dynamics and guidance, navigation, and control (GNC) systems. We first discuss the medical aerial delivery mission requirements and suitable uncrewed aerial system (UAS) configurations. We then address payload container design and optimization, and its effect on supplies and overall flight dynamics. We also explore the fundamental principles of GNC in the context of medical drone operations, highlighting key challenges arising from vibration, air temperature, pressure, and humidity, which affect the quality of medical supplies. The paper examines various GNC algorithms that can mitigate these challenges, as well as the algorithms' limitations. With these considerations, this survey aims to provide insights into optimizing GNC frameworks for medical drones, emphasizing research gaps and directions to improve real-world healthcare applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06997", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.06997", "abs": "https://arxiv.org/abs/2602.06997", "authors": ["Anindya Bhattacharjee", "Nittya Ananda Biswas", "K. A. Shahriar", "Adib Rahman"], "title": "Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach", "comment": null, "summary": "Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion to model temporal EEG dynamics with complementary peripheral physiological and personality features. Dedicated subnetworks are used to process EEG features and auxiliary modalities, and a shared autoencoder-based fusion module is used to learn discriminative latent representations before classification. Subject-dependent experiments conducted on the PhyMER dataset across seven emotional classes achieve an accuracy of 95.45%, surpassing previously reported results. Furthermore, temporal attention analysis provides interpretable insights into emotion-specific temporal relevance, and t-SNE visualizations demonstrate enhanced class separability, highlighting the effectiveness of the proposed approach. Finally, statistical analysis of temporal dynamics confirms that the network self-organizes into distinct functional groups with specialized fast and slow neurons, proving it independently tunes learnable time constants and memory dominance to effectively capture complex emotion artifacts.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08842", "categories": ["cs.AR", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08842", "abs": "https://arxiv.org/abs/2602.08842", "authors": ["Jean-Pierre Busch", "Lukas Ostendorf", "Guido Linden", "Lennart Reiher", "Till Beemelmanns", "Bastian Lampe", "Timo Woopen", "Lutz Eckstein"], "title": "karl. -- A Research Vehicle for Automated and Connected Driving", "comment": "8 pages; Accepted to be published as part of the 37th Intelligent Vehicles Symposium (IV), Detroit, MI, United States, June 22-25, 2026", "summary": "As highly automated driving is transitioning from single-vehicle closed-access testing to commercial deployments of public ride-hailing in selected areas (e.g., Waymo), automated driving and connected cooperative intelligent transport systems (C-ITS) remain active fields of research. Even though simulation is omnipresent in the development and validation life cycle of automated and connected driving technology, the complex nature of public road traffic and software that masters it still requires real-world integration and testing with actual vehicles. Dedicated vehicles for research and development allow testing and validation of software and hardware components under real-world conditions early on. They also enable collecting and publishing real-world datasets that let others conduct research without vehicle access, and support early demonstration of futuristic use cases. In this paper, we present karl., our new research vehicle for automated and connected driving. Apart from major corporations, few institutions worldwide have access to their own L4-capable research vehicles, restricting their ability to carry out independent research. This paper aims to help bridge that gap by sharing the reasoning, design choices, and technical details that went into making karl. a flexible and powerful platform for research, engineering, and validation in the context of automated and connected driving. More impressions of karl. are available at https://karl.ac.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07559", "categories": ["cs.AI", "cs.CC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07559", "abs": "https://arxiv.org/abs/2602.07559", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang", "Hao Li", "Muhammad Kafeel Shaheen"], "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning", "comment": "13 pages", "summary": "Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving \"verification by construction\" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07186", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07186", "abs": "https://arxiv.org/abs/2602.07186", "authors": ["Luoxi Tang", "Yuqiao Meng", "Joseph Costa", "Yingxue Zhang", "Muchao Ye", "Zhaohan Xi"], "title": "The Value of Variance: Mitigating Debate Collapse in Multi-Agent Systems via Uncertainty-Driven Policy Optimization", "comment": null, "summary": "Multi-agent debate (MAD) systems improve LLM reasoning through iterative deliberation, but remain vulnerable to debate collapse, a failure type where final agent decisions are compromised on erroneous reasoning. Existing methods lack principled mechanisms to detect or prevent such failures. To address this gap, we first propose a hierarchical metric that quantifies behavioral uncertainty at three levels: intra-agent (individual reasoning uncertainty), inter-agent (interactive uncertainty), and system-level (output uncertainty). Empirical analysis across several benchmarks reveals that our proposed uncertainty quantification reliably indicates system failures, which demonstrates the validity of using them as diagnostic metrics to indicate the system failure. Subsequently, we propose a mitigation strategy by formulating an uncertainty-driven policy optimization to penalize self-contradiction, peer conflict, and low-confidence outputs in a dynamic debating environment. Experiments demonstrate that our proposed uncertainty-driven mitigation reliably calibrates the multi-agent system by consistently improving decision accuracy while reducing system disagreement.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07687", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07687", "abs": "https://arxiv.org/abs/2602.07687", "authors": ["Yue Chang", "Peter Yichen Chen", "Eitan Grinspun", "Maurizio M. Chiaramonte"], "title": "Low-Rank Koopman Deformables with Log-Linear Time Integration", "comment": null, "summary": "We present a low-rank Koopman operator formulation for accelerating deformable subspace simulation. Using a Dynamic Mode Decomposition (DMD) parameterization of the Koopman operator, our method learns the temporal evolution of deformable dynamics and predicts future states through efficient matrix evaluations instead of sequential time integration. This yields log-linear scaling in the number of time steps and allows large portions of the trajectory to be skipped while retaining accuracy. The resulting temporal efficiency is especially advantageous for optimization tasks such as control and initial-state estimation, where the objective often depends largely on the final configuration.\n  To broaden the scope of Koopman-based reduced-order models in graphics, we introduce a discretization-agnostic extension that learns shared dynamic behavior across multiple shapes and mesh resolutions. Prior DMD-based approaches have been restricted to a single shape and discretization, which limits their usefulness for tasks involving geometry variation. Our formulation generalizes across both shape and discretization, which enables fast shape optimization that was previously impractical for DMD models. This expanded capability highlights the potential of Koopman operator learning as a practical tool for efficient deformable simulation and design.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08714", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.08714", "abs": "https://arxiv.org/abs/2602.08714", "authors": ["Aris Filos-Ratsikas", "Georgios Kalantzis", "Alexandros A. Voudouris"], "title": "Approximate-EFX Allocations with Ordinal and Limited Cardinal Information", "comment": null, "summary": "We study a discrete fair division problem where $n$ agents have additive valuation functions over a set of $m$ goods. We focus on the well-known $\u03b1$-EFX fairness criterion, according to which the envy of an agent for another agent is bounded multiplicatively by $\u03b1$, after the removal of any good from the envied agent's bundle. The vast majority of the literature has studied $\u03b1$-EFX allocations under the assumption that full knowledge of the valuation functions of the agents is available. Motivated by the established literature on the distortion in social choice, we instead consider $\u03b1$-EFX algorithms that operate under limited information on these functions. In particular, we assume that the algorithm has access to the ordinal preference rankings, and is allowed to make a small number of queries to obtain further access to the underlying values of the agents for the goods. We show (near-optimal) tradeoffs between the values of $\u03b1$ and the number of queries required to achieve those, with a particular focus on constant EFX approximations. We also consider two interesting special cases, namely instances with a constant number of agents, or with two possible values, and provide improved positive results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08271", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08271", "abs": "https://arxiv.org/abs/2602.08271", "authors": ["Antonis Psistakis", "Burak Ocalan", "Chloe Alverti", "Fabien Chaix", "Ramnatthan Alagappan", "Josep Torrellas"], "title": "Towards CXL Resilience to CPU Failures", "comment": null, "summary": "Compute Express Link (CXL) 3.0 and beyond allows the compute nodes of a cluster to share data with hardware cache coherence and at the granularity of a cache line. This enables shared-memory semantics for distributed computing, but introduces new resilience challenges: a node failure leads to the loss of the dirty data in its caches, corrupting application state. Unfortunately, the CXL specification does not consider processor failures. Moreover, when a component fails, the specification tries to isolate it and continue application execution; there is no attempt to bring the application to a consistent state. To address these limitations, this paper extends the CXL specification to be resilient to node failures, and to correctly recover the application after node failures. We call the system ReCXL. To handle the failure of nodes, ReCXL augments the coherence transaction of a write with messages that propagate the update to a small set of other nodes (i.e., Replicas). Replicas save the update in a hardware Logging Unit. Such replication ensures resilience to node failures. Then, at regular intervals, the Logging Units dump the updates to memory. Recovery involves using the logs in the Logging Units to bring the directory and memory to a correct state. Our evaluation shows that ReCXL enables fault-tolerant execution with only a 30% slowdown over the same platform with no fault-tolerance support.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07360", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07360", "abs": "https://arxiv.org/abs/2602.07360", "authors": ["Linyu Lin"], "title": "In-Context System Identification for Nonlinear Dynamics Using Large Language Models", "comment": "6 pages, 5 figures, submitted to The 10th IEEE Conference on Control Technology and Applications (CCTA) 2026", "summary": "Sparse Identification of Nonlinear Dynamics (SINDy) is a powerful method for discovering parsimonious governing equations from data, but it often requires expert tuning of candidate libraries. We propose an LLM-aided SINDy pipeline that iteratively refines candidate equations using a large language model (LLM) in the loop through in-context learning. The pipeline begins with a baseline SINDy model fit using an adaptive library and then enters a LLM-guided refinement cycle. At each iteration, the current best equations, error metrics, and domain-specific constraints are summarized in a prompt to the LLM, which suggests new equation structures. These candidate equations are parsed against a defined symbolic form and evaluated on training and test data. The pipeline uses simulation-based error as a primary metric, but also assesses structural similarity to ground truth, including matching functional forms, key terms, couplings, qualitative behavior. An iterative stopping criterion ends refinement early if test error falls below a threshold (NRMSE < 0.1) or if a maximum of 10 iterations is reached. Finally, the best model is selected, and we evaluate this LLM-aided SINDy on 63 dynamical system datasets (ODEBench) and march leuba model for boiling nuclear reactor. The results are compared against classical SINDy and show the LLM-loop consistently improves symbolic recovery with higher equation similarity to ground truth and lower test RMSE than baseline SINDy for cases with complex dynamics. This work demonstrates that an LLM can effectively guide SINDy's search through equation space, integrating data-driven error feedback with domain-inspired symbolic reasoning to discover governing equations that are not only accurate but also structurally interpretable.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07868", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07868", "abs": "https://arxiv.org/abs/2602.07868", "authors": ["Ran Duan", "Xiao Mao", "Xinkai Shu", "Longhui Yin"], "title": "A Faster Directed Single-Source Shortest Path Algorithm", "comment": null, "summary": "This paper presents a new deterministic algorithm for single-source shortest paths (SSSP) on real non-negative edge-weighted directed graphs, with running time $O(m\\sqrt{\\log n}+\\sqrt{mn\\log n\\log \\log n})$, which is $O(m\\sqrt{\\log n\\log \\log n})$ for sparse graphs. This improves the recent breakthrough result of $O(m\\log^{2/3} n)$ time for directed SSSP algorithm [Duan, Mao, Mao, Shu, Yin 2025].", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07037", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.07037", "abs": "https://arxiv.org/abs/2602.07037", "authors": ["Huannan Zheng", "Jingli Liu", "Kezhou Yang"], "title": "Stochastic Spiking Neuron Based SNN Can be Inherently Bayesian", "comment": null, "summary": "Uncertainty in biological neural systems appears to be computationally beneficial rather than detrimental. However, in neuromorphic computing systems, device variability often limits performance, including accuracy and efficiency. In this work, we propose a spiking Bayesian neural network (SBNN) framework that unifies the dynamic models of intrinsic device stochasticity (based on Magnetic Tunnel Junctions) and stochastic threshold neurons to leverage noise as a functional Bayesian resource. Experiments demonstrate that SBNN achieves high accuracy (99.16% on MNIST, 94.84% on CIFAR10) with 8-bit precision. Meanwhile rate estimation method provides a ~20-fold training speedup. Furthermore, SBNN exhibits superior robustness, showing a 67% accuracy improvement under synaptic weight noise and 12% under input noise compared to standard spiking neural networks. Crucially, hardware validation confirms that physical device implementation causes invisible accuracy and calibration loss compared to the algorithmic model. Converting device stochasticity into neuronal uncertainty offers a route to compact, energy-efficient neuromorphic computing under uncertainty.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07461", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.07461", "abs": "https://arxiv.org/abs/2602.07461", "authors": ["Zhao-Wen Miao", "Chen Zhao", "Jin-Hua Gao", "X. C. Xie"], "title": "Theory of Integer Quantum Hall Effect in Irrational Magnetic Field", "comment": "6 pages, 3 figures", "summary": "The conventional theory of the integer quantum Hall effect (IQHE) fails for irrational magnetic fields owing to the breakdown of magnetic translational symmetry. Here, based on the recently proposed incommensurate energy band (IEB) theory, we present a universal IQHE theory that does not rely on magnetic translation symmetry and is applicable to both rational and irrational magnetic fluxes. Using the square lattice as a paradigmatic example, we first show that the IEB framework provides a superior description of its energy spectrum in a magnetic field, as it explicitly reveals the momentum-space distribution of eigenstates. Key to our IQHE theory is that each gap in the IEB spectrum is intrinsically labeled by an integer pair (m,g), defined by the corresponding Bragg planes. When the Fermi energy lies within such a gap, the occupied electron states $N_{\\text{occ}}$ is determined by the k-space volume enclosed by these Bragg planes, leading to the fundamental relation $N_{\\text{occ}}/N_0 = m(\u03c6/\u03c6_0) + g$. Through St\u0159eda formula, this leads directly to the quantized Hall conductance $\u03c3_{xy} = m e^2/h$ under arbitrary magnetic fields. Our work resolves the long-standing problem of IQHE under irrational flux, and establishes a new paradigm for IQHE.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08704", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08704", "abs": "https://arxiv.org/abs/2602.08704", "authors": ["Moses Boudourides"], "title": "Friedkin-Johnsen Social Influence Dynamics on Networks: A Boundary-Value Formulation and Influenceability Measures", "comment": null, "summary": "This article presents a rigorous mathematical analysis of the Friedkin--Johnsen model of social influence on networks. We frame the opinion dynamics as a discrete boundary-value problem on a network, emphasizing the role of stubborn (boundary) and susceptible (interior) agents in shaping opinion evolution. This perspective allows for a precise analysis of how network structure, stubborn agents (boundary), and susceptible agents (interior) collectively determine the evolution of opinions. We derive the transient and steady-state solutions using two distinct but related approaches: a general resolvent-based method applicable to agents with heterogeneous susceptibilities, and a spectral method valid for the special case of homogeneous susceptibility. We further establish quantitative convergence rates to the steady state, derive explicit sensitivity formulas with respect to susceptibility parameters, and prove perturbation bounds under changes in the influence matrix. Moreover, we formally define a set of influenceability measures and prove some of their basic properties. Finally, we provide a Monte Carlo illustration on the Zachary karate club graph, showing how the proposed opinion broadcasting centralities and centralizations behave under random susceptibility profiles and how they relate to classical network centralities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07160", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07160", "abs": "https://arxiv.org/abs/2602.07160", "authors": ["Jiecheng Lu", "Shihao Yang"], "title": "Free Energy Mixer", "comment": "Camera-ready version. Accepted at ICLR 2026", "summary": "Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07295", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.07295", "abs": "https://arxiv.org/abs/2602.07295", "authors": ["Prathami Divakar Kamath", "Kristin A. Persson"], "title": "The impact of spurious imaginary phonon modes on thermal properties of Metal-organic Frameworks", "comment": null, "summary": "Metal-organic Frameworks (MOFs) have emerged as potential candidates for direct air capture (DAC) of green house gases and water. Thermal properties of MOFs, such as their heat capacity, are used to determine the energy penalty associated with the adsorbent retrieval during the Temperature Swing Adsorption process. To aid exploration of the vast experimental design space of MOFs for such applications, computational methods like Density Functional Theory (DFT) or surrogate machine learning models trained on DFT data have been developed for obtaining phonon-derived heat capacities of MOFs. However, the high cost of explicit phonon computation in large and flexible nanoporous MOFs often necessitates the use of small supercells or lower convergence criteria which decrease predictive accuracy. These approximations often result in spurious imaginary phonon modes which are commonly ignored in practice. At present, there is no clear consensus in the literature on what magnitude of negative frequency or what fraction of imaginary modes can be considered acceptable. Here, we systematically demonstrate that spurious imaginary phonon modes can introduce substantial errors in heat capacity estimates, leading to incorrect ranking of MOFs in thermal-property-based screening. We further show that benchmarking machine learning interatomic potentials (MLIPs) against DFT datasets containing spurious imaginary modes can misrepresent models that predict physically meaningful phonon spectra for dynamically stable MOFs. Finally, we introduce a simple, rapid post-processing workflow that can be applied to standard phonon calculations to effectively correct heat capacity estimates and account for spurious imaginary modes in MOFs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08269", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08269", "abs": "https://arxiv.org/abs/2602.08269", "authors": ["Lian Zhou", "Kaiwen Xue", "Amirhossein Fallah", "Lijin Liu", "Chun-Ho Lee", "Kiwon Kwon", "Clayton Cheung", "Yuan Li", "Yue Yu", "Yun-Jhu Lee", "Songlin Zhao", "Ryan Hamerly", "Edo Waks", "Dirk Englund", "Constantine Sideris", "Mengjie Yu", "Zaijun Chen"], "title": "Quantization-aware Photonic Homodyne computing for Accelerated Artificial Intelligence and Scientific Simulation", "comment": null, "summary": "Modern problems in high-performance computing, ranging from training and inferencing deep learning models in computer vision and language models to simulating complex physical systems with nonlinearly-coupled equations, require exponential growth of computational resources. Photonic analog systems are emerging with solutions of intrinsic parallelism, high bandwidth, and low propagation loss. However, their application has been hindered by the low analog accuracy due to the electro-optic distortion, material nonlinearities, and signal-to-noise ratios. Here we overcome this barrier with a quantization-aware digital-photonic mixed-precision framework across chiplets for accelerated AI processing and physical simulation. Using Lithium Niobate photonics with channel equalization techniques, we demonstrate linear multiplication (9-bit amplitude-phase decoupling) in homodyne optical logics with 6-bit precision at the clock rate of 128 giga-symbol-per-second (128 GS/s), enabling AI processing with 6 ns latency. Codesign hardware-algorithms, including iterative solvers, sparse-dense quantization, and bit-sliced matrix multiplication, explore photonic amplitude and phase coherence for complex-valued, physics-inspired computation. In electromagnetic problems, our approach yields 12-bit solutions for partial differential equations (PDEs) in scattering problems that would conventionally require up to 32-bit and often even 64-bit precision. These results preserve digital-level fidelity while leveraging the high-speed low-energy photonic hardware, establishing a pathway toward general-purpose optical acceleration for generative artificial intelligence, real-time robotics, and accurate simulation for climate challenges and biological discoveries.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08248", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.08248", "abs": "https://arxiv.org/abs/2602.08248", "authors": ["Borislav Hinkov", "Johannes Kunsch", "Werner M\u00e4ntele", "Lukasz Sterczewski", "\u00c1ngel S\u00e1nchez-Illana", "Jaume B\u00e9jar-Grimalt", "V\u00edctor Navarro-Esteve", "David Perez-Guaita", "Alexander Mittelst\u00e4dt", "Philippa Clark", "Valentino Lepro", "Sergius Janik", "Thorsten Lubinski", "Luis Felipe das Chagas e Silva de Carvalho", "Hugh James Byrne", "Filiz Korkmaz", "Michael Kaluza", "Mattia Saita", "Lars Melchior", "Alicja Dabrowska", "Georg Ramer", "Bernhard Lendl", "Nathalie Woitzik", "Klaus Gerwert", "Peter Gardner", "Hugues Tariel", "Olivier Sire", "Margaux Petay", "Elisabeth Holub", "Markus Brandstetter", "Kristina Duswald", "Verena Karl", "Florian Meirer", "Lukas Kenner", "Gabriela Flores Rangel", "Boris Mizaikoff", "Mohamed Sy", "Aamir Farooq", "Liudmila Voronina", "Marinus Huber", "Tarek Eissa", "Katharina Dietmann", "Lorenzo Gatto", "Mihaela \u017digman", "Joseph Rebel", "Frank Fleischmann", "Jakub Mnich", "Jaros\u0142aw Sotor", "Bassam Saadany", "Matthias Budden", "Thomas Gebert", "Marco Schossig", "Shankar Baliga", "Timothy Olsen", "Christopher Harrower", "Ivan Zorin", "Chiara Lindner", "Shigeki Takeuchi", "Sven Ramelow", "Paul Gattinger", "David Stark", "R\u00e9ka-Eszter Vass", "Killian Keller", "Alessio Cargioli", "Mattias Beck", "J\u00e9r\u00f4me Faist", "Robert Weih", "Josephine Nausch\u00fctz", "Julian Scheuermann", "Jordan Fordyce", "Johannes Koeth", "Ka Fai Mak", "Alexander Weigel", "Ryszard Piramidowicz", "Stanis\u0142aw Stopi\u0144ski", "Mircea Guina", "Jukka Viheri\u00e4l\u00e4", "Felix Jaeschke", "Polina Fomina", "Alexander Novikov", "Viacheslav Artyushenko", "Ivan Sinev", "Nikita Glebov", "Berkay Dagli", "Hatice Altug"], "title": "Infrared photonics for healthcare: A roadmap for proactive and predictive health management", "comment": "This manuscript has been submitted for review in Journal of Physics Photonics", "summary": "The field of infrared (IR) photonics is currently undergoing remarkable progress, moving rapidly towards practical sensing applications demanded by medical therapy and diagnostics (theranostics). The Developments can be divided into three main categories: (i) novel devices and measurement concepts including advanced updates of classical approaches that push medical sensing into the spotlight; (ii) new demonstrations of photonic integrated circuit (PIC-)based IR devices enabling highly miniaturized sensors for point-of-care application as well as medical and wellness wearables; and (iii) technologically-mature IR demonstrators that enable first medical sensing and treatment applications. This roadmap paper provides a consolidated overview of this highly dynamic and interdisciplinary research field with a focus on the major roadblocks that limit the widespread adoption of IR photonics in large-scale medical diagnostics. Special attention is given to the ambivalence between the molecular-level spectroscopic interpretation and a broader health-state assessment, highlighting the need for a common framework. Additionally, the paper discusses the critical importance of unified measurement standards, calibration protocols, and medical certification processes to ensure the validity of experimental results, reproducibility, and clinical trust, particularly when novel experimental techniques and AI algorithms are involved. Perspectives from major past and current contributors to application-oriented IR photonics will be provided.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06971", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06971", "abs": "https://arxiv.org/abs/2602.06971", "authors": ["Anastasios Manganaris", "Vittorio Giammarino", "Ahmed H. Qureshi", "Suresh Jagannathan"], "title": "Formal Methods in Robot Policy Learning and Verification: A Survey on Current Techniques and Future Directions", "comment": "19 Pages. 6 Figures. Published in Transactions on Machine Learning Research", "summary": "As hardware and software systems have grown in complexity, formal methods have been indispensable tools for rigorously specifying acceptable behaviors, synthesizing programs to meet these specifications, and validating the correctness of existing programs. In the field of robotics, a similar trend of rising complexity has emerged, driven in large part by the adoption of deep learning. While this shift has enabled the development of highly performant robot policies, their implementation as deep neural networks has posed challenges to traditional formal analysis, leading to models that are inflexible, fragile, and difficult to interpret. In response, the robotics community has introduced new formal and semi-formal methods to support the precise specification of complex objectives, guide the learning process to achieve them, and enable the verification of learned policies against them. In this survey, we provide a comprehensive overview of how formal methods have been used in recent robot learning research. We organize our discussion around two pillars: policy learning and policy verification. For both, we highlight representative techniques, compare their scalability and expressiveness, and summarize how they contribute to meaningfully improving realistic robot safety and correctness. We conclude with a discussion of remaining obstacles for achieving that goal and promising directions for advancing formal methods in robot learning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07001", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.07001", "abs": "https://arxiv.org/abs/2602.07001", "authors": ["Yueyi Yang", "Zeping Sui", "Zilong Liu", "Leila Musavian"], "title": "OTFS-based Integrated Positioning and Communication Systems with Low-Resolution ADCs", "comment": "6 pages, 6 figures, submitted to ICC Workshop", "summary": "This paper proposes a two-phase orthogonal time frequency space (OTFS)-based integrated positioning and communication (IPAC) framework under realistic low-resolution analog-to-digital converters (ADCs). In the uplink phase, the positioning signal is used to estimate channel parameters, which are subsequently used to determine the user's position. The spatial smoothing-multiple signal classification algorithm is introduced to estimate the angle-of-arrival, whereas an iterative interference cancellation scheme is conceived for the remaining parameters' estimation. The corresponding Cramer-Rao lower bounds of channel parameters and user position are also derived. During the downlink communication phase, the estimated parameters are exploited to improve beamforming at the base station. Simulation results evaluate the impact of ADC quantizer resolutions. Specifically, it is shown that enhanced downlink bit error rate performance can be achieved with improved uplink positioning, while the use of low-resolution ADCs induces noticeable performance degradation in the OTFS-IPAC system.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07032", "categories": ["cs.AI", "cs.AR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07032", "abs": "https://arxiv.org/abs/2602.07032", "authors": ["Yuheng Wu", "Berk Gokmen", "Zhouhua Xie", "Peijing Li", "Caroline Trippel", "Priyanka Raina", "Thierry Tambe"], "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation", "comment": null, "summary": "Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually constructed examples, LLM-FSM is built through a fully automated pipeline. LLM-FSM first constructs FSM with configurable state counts and constrained transition structures. It then prompts LLMs to express each FSM in a structured YAML format with an application context, and to further convert that YAML into a natural-language (NL) specification. From the same YAML, our pipeline synthesizes the reference RTL and testbench in a correct-by-construction manner. All 1,000 problems are verified using LLM-based and SAT-solver-based checks, with human review on a subset. Our experiments show that even the strongest LLMs exhibit sharply declining accuracy as FSM complexity increases. We further demonstrate that training-time scaling via supervised fine-tuning (SFT) generalizes effectively to out-of-distribution (OOD) tasks, while increasing test-time compute improves reasoning reliability. Finally, LLM-FSM remains extensible by allowing its FSM complexity to scale with future model capabilities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07603", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07603", "abs": "https://arxiv.org/abs/2602.07603", "authors": ["Woojin Cho", "Junghwan Park"], "title": "Escaping Spectral Bias without Backpropagation: Fast Implicit Neural Representations with Extreme Learning Machines", "comment": null, "summary": "Training implicit neural representations (INRs) to capture fine-scale details typically relies on iterative backpropagation and is often hindered by spectral bias when the target exhibits highly non-uniform frequency content. We propose ELM-INR, a backpropagation-free INR that decomposes the domain into overlapping subdomains and fits each local problem using an Extreme Learning Machine (ELM) in closed form, replacing iterative optimization with stable linear least-squares solutions. This design yields fast and numerically robust reconstruction by combining local predictors through a partition of unity. To understand where approximation becomes difficult under fixed local capacity, we analyze the method from a spectral Barron norm perspective, which reveals that global reconstruction error is dominated by regions with high spectral complexity. Building on this insight, we introduce BEAM, an adaptive mesh refinement strategy that balances spectral complexity across subdomains to improve reconstruction quality in capacity-constrained regimes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07777", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.07777", "abs": "https://arxiv.org/abs/2602.07777", "authors": ["Shuhui Zhu", "Yue Lin", "Shriya Kaistha", "Wenhao Li", "Baoxiang Wang", "Hongyuan Zha", "Gillian K. Hadfield", "Pascal Poupart"], "title": "Talk, Judge, Cooperate: Gossip-Driven Indirect Reciprocity in Self-Interested LLM Agents", "comment": null, "summary": "Indirect reciprocity, which means helping those who help others, is difficult to sustain among decentralized, self-interested LLM agents without reliable reputation systems. We introduce Agentic Linguistic Gossip Network (ALIGN), an automated framework where agents strategically share open-ended gossip using hierarchical tones to evaluate trustworthiness and coordinate social norms. We demonstrate that ALIGN consistently improves indirect reciprocity and resists malicious entrants by identifying and ostracizing defectors without changing intrinsic incentives. Notably, we find that stronger reasoning capabilities in LLMs lead to more incentive-aligned cooperation, whereas chat models often over-cooperate even when strategically suboptimal. These results suggest that leveraging LLM reasoning through decentralized gossip is a promising path for maintaining social welfare in agentic ecosystems. Our code is available at https://github.com/shuhui-zhu/ALIGN.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07782", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07782", "abs": "https://arxiv.org/abs/2602.07782", "authors": ["Floria Gu", "Nicholas Vining", "Alla Sheffer"], "title": "TABI: Tight and Balanced Interactive Atlas Packing", "comment": null, "summary": "Atlas packing is a key step in many computer graphics applications. Packing algorithms seek to arrange a set of charts within a fixed-size atlas with as little downscaling as possible. Many packing applications such as content creation tools, dynamic atlas generation for video games, and texture space shading require on-the-fly interactive atlas packing. Unfortunately, while many methods have been developed for generating tight high-quality packings, they are designed for offline settings and have running times two or more orders of magnitude greater than what is required for interactive performance. While real-time GPU packing methods exist, they significantly downscale packed charts compared to offline methods. We introduce a GPU packing method that targets interactive speeds, provides packing quality approaching that of offline methods, and supports flexible user control over the tradeoff between performance and quality. We observe that current real-time packing methods leave large gaps between charts and often produce asymmetric, or poorly balanced, packings. These artifacts dramatically degrade packing quality. Our Tight And Balanced method eliminates these artifacts while retaining Interactive performance. TABI generates tight packings by compacting empty space between irregularly shaped charts both horizontally and vertically, using two approximations of chart shape that support efficient parallel processing. We balance packing outputs by automatically adjusting atlas row widths and orientations to accommodate varying chart heights. We show that our method significantly reduces chart downscaling compared to existing interactive methods while remaining orders of magnitude faster than offline alternatives.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08871", "categories": ["cs.GT", "cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.08871", "abs": "https://arxiv.org/abs/2602.08871", "authors": ["Ziyi Cai", "D. D. Gao", "Prasanna Ramakrishnan", "Kangning Wang"], "title": "Distortion of Metric Voting with Bounded Randomness", "comment": null, "summary": "We study the design of voting rules in the metric distortion framework. It is known that any deterministic rule suffers distortion of at least $3$, and that randomized rules can achieve distortion strictly less than $3$, often at the cost of reduced transparency and interpretability. In this work, we explore the trade-off between these paradigms by asking whether it is possible to break the distortion barrier of $3$ using only \"bounded\" randomness. We answer in the affirmative by presenting a voting rule that (1) achieves distortion of at most $3 - \\varepsilon$ for some absolute constant $\\varepsilon > 0$, and (2) selects a winner uniformly at random from a deterministically identified list of constant size. Our analysis builds on new structural results for the distortion and approximation of Maximal Lotteries and Stable Lotteries.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08747", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08747", "abs": "https://arxiv.org/abs/2602.08747", "authors": ["Zhixin Zhao", "Yitao Hu", "Simin Chen", "Mingfang Ji", "Wei Yang", "Yuhao Zhang", "Laiping Zhao", "Wenxin Li", "Xiulong Liu", "Wenyu Qu", "Hao Wang"], "title": "PARD: Enhancing Goodput for Inference Pipeline via Proactive Request Dropping", "comment": "Accepted by EuroSys'26", "summary": "Modern deep neural network (DNN) applications integrate multiple DNN models into inference pipelines with stringent latency requirements for customized tasks. To mitigate extensive request timeouts caused by accumulation, systems for inference pipelines commonly drop a subset of requests so the remaining ones can satisfy latency constraints. Since it is commonly believed that request dropping adversely affects goodput, existing systems only drop requests when they have to, which we call reactive dropping. However, this reactive policy can not maintain high goodput, as it neither makes timely dropping decisions nor identifies the proper set of requests to drop, leading to issues of dropping requests too late or dropping the wrong set of requests.\n  We propose that the inference system should proactively drop certain requests in advance to enhance the goodput across the entire workload. To achieve this, we design an inference system PARD. It enhances goodput with timely and precise dropping decisions by integrating a proactive dropping method that decides when to drop requests using runtime information of the inference pipeline, and an adaptive request priority mechanism that selects which specific requests to drop based on remaining latency budgets and workload intensity. Evaluation on a cluster of 64 GPUs over real-world workloads shows that PARD achieves $16\\%$-$176\\%$ higher goodput than the state of the art while reducing the drop rate and wasted computation resources by $1.6\\times$-$17\\times$ and $1.5\\times$-$62\\times$ respectively.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07581", "categories": ["eess.SY", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.07581", "abs": "https://arxiv.org/abs/2602.07581", "authors": ["Thomas Beckers", "J\u00e1n Drgo\u0148a", "Truong X. Nghiem"], "title": "$\\partial$CBDs: Differentiable Causal Block Diagrams", "comment": null, "summary": "Modern cyber-physical systems (CPS) integrate physics, computation, and learning, demanding modeling frameworks that are simultaneously composable, learnable, and verifiable. Yet existing approaches treat these goals in isolation: causal block diagrams (CBDs) support modular system interconnections but lack differentiability for learning; differentiable programming (DP) enables end-to-end gradient-based optimization but provides limited correctness guarantees; while contract-based verification frameworks remain largely disconnected from data-driven model refinement. To address these limitations, we introduce differentiable causal block diagrams ($\\partial$CBDs), a unifying formalism that integrates these three perspectives. Our approach (i) retains the compositional structure and execution semantics of CBDs, (ii) incorporates assume--guarantee (A--G) contracts for modular correctness reasoning, and (iii) introduces residual-based contracts as differentiable, trajectory-level certificates compatible with automatic differentiation (AD), enabling gradient-based optimization and learning. Together, these elements enable a scalable, verifiable, and trainable modeling pipeline that preserves causality and modularity while supporting data-, physics-, and constraint-informed optimization for CPS.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08002", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.08002", "abs": "https://arxiv.org/abs/2602.08002", "authors": ["Yu-Sheng Shih", "Meng-Tsung Tsai", "Yen-Chu Tsai", "Ying-Sian Wu"], "title": "Space Complexity Dichotomies for Subgraph Finding Problems in the Streaming Model", "comment": null, "summary": "We study the space complexity of four variants of the standard subgraph finding problem in the streaming model. Specifically, given an $n$-vertex input graph and a fixed-size pattern graph, we consider two settings: undirected simple graphs, denoted by $G$ and $H$, and oriented graphs, denoted by $\\vec{G}$ and $\\vec{H}$. Depending on the setting, the task is to decide whether $G$ contains $H$ as a subgraph or as an induced subgraph, or whether $\\vec{G}$ contains $\\vec{H}$ as a subgraph or as an induced subgraph. Let Sub$(H)$, IndSub$(H)$, Sub$(\\vec{H})$, and IndSub$(\\vec{H})$ denote these four variants, respectively.\n  An oriented graph is well-oriented if it admits a bipartition in which every arc is oriented from one part to the other, and a vertex is non-well-oriented if both its in-degree and out-degree are non-zero. For each variant, we obtain a complete dichotomy theorem, briefly summarized as follows.\n  (1) Sub$(H)$ can be solved by an $\\tilde{O}(1)$-pass $n^{2-\u03a9(1)}$-space algorithm if and only if $H$ is bipartite.\n  (2) IndSub$(H)$ can be solved by an $\\tilde{O}(1)$-pass $n^{2-\u03a9(1)}$-space algorithm if and only if $H \\in \\{P_3, P_4, co\\mbox{-}P_3\\}$.\n  (3) Sub$(\\vec{H})$ can be solved by a single-pass $n^{2-\u03a9(1)}$-space algorithm if and only if every connected component of $\\vec H$ is either a well-oriented bipartite graph or a tree containing at most one non-well-oriented vertex.\n  (4) IndSub$(\\vec{H})$ can be solved by an $\\tilde{O}(1)$-pass $n^{2-\u03a9(1)}$-space algorithm if and only if the underlying undirected simple graph $H$ is a $co\\mbox{-}P_3$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07059", "categories": ["cs.NE", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07059", "abs": "https://arxiv.org/abs/2602.07059", "authors": ["Francesca Da Ros", "Tarik Za\u010diragi\u0107", "Aske Plaat", "Thomas B\u00e4ck", "Niki van Stein"], "title": "Assessing Reproducibility in Evolutionary Computation: A Case Study using Human- and LLM-based Assessment", "comment": null, "summary": "Reproducibility is an important requirement in evolutionary computation, where results largely depend on computational experiments. In practice, reproducibility relies on how algorithms, experimental protocols, and artifacts are documented and shared. Despite growing awareness, there is still limited empirical evidence on the actual reproducibility levels of published work in the field. In this paper, we study the reproducibility practices in papers published in the Evolutionary Combinatorial Optimization and Metaheuristics track of the Genetic and Evolutionary Computation Conference over a ten-year period. We introduce a structured reproducibility checklist and apply it through a systematic manual assessment of the selected corpus. In addition, we propose RECAP (REproducibility Checklist Automation Pipeline), an LLM-based system that automatically evaluates reproducibility signals from paper text and associated code repositories. Our analysis shows that papers achieve an average completeness score of 0.62, and that 36.90% of them provide additional material beyond the manuscript itself. We demonstrate that automated assessment is feasible: RECAP achieves substantial agreement with human evaluators (Cohen's k of 0.67). Together, these results highlight persistent gaps in reproducibility reporting and suggest that automated tools can effectively support large-scale, systematic monitoring of reproducibility practices.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07691", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.07691", "abs": "https://arxiv.org/abs/2602.07691", "authors": ["Mladen Kotur", "Nataliia E. Kopteva", "Dmitri R. Yakovlev", "Bekir Turedi", "Maksym V. Kovalenko", "Manfred Bayer"], "title": "Hyperfine interaction of electrons and holes with nuclei probed by optical orientation in MAPbI$_3$ perovskite crystals", "comment": "9 pages, 7 figures", "summary": "Optical orientation of electron and hole spins by circularly polarized light is investigated for MAPbI$_3$ single crystals. The Hanle and polarization recovery effects measured in transverse and longitudinal magnetic fields, respectively, evidence the hyperfine interaction with nuclear spins as the main factor determining the spin dynamics of charge carriers at cryogenic temperatures. The parameters of the nuclear spin fluctuations within the carrier localization volume are evaluated. Dynamic polarization of the nuclear spins is demonstrated by the Overhauser field reaching 5 mT for acting on the electrons and -30 mT for acting on the holes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08953", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08953", "abs": "https://arxiv.org/abs/2602.08953", "authors": ["William Guo", "Edward Xiong", "Jie Gao"], "title": "Robust Sequential Learning in Random Order Networks", "comment": "Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "In the sequential learning problem, agents in a network attempt to predict a binary ground truth, informed by both a noisy private signal and the predictions of neighboring agents before them. It is well known that social learning in this setting can be highly fragile: small changes to the action ordering, network topology, or even the strength of the agents' private signals can prevent a network from converging to the truth. We study networks that achieve random-order asymptotic truth learning, in which almost all agents learn the ground truth when the decision ordering is selected uniformly at random. We analyze the robustness of these networks, showing that those achieving random-order asymptotic truth learning are resilient to a bounded number of adversarial modifications. We characterize necessary conditions for such networks to succeed in this setting and introduce several graph constructions that learn through different mechanisms. Finally, we present a randomized polynomial-time algorithm that transforms an arbitrary network into one achieving random-order learning using minimal edge or vertex modifications, with provable approximation guarantees. Our results reveal structural properties of networks that achieve random-order learning and provide algorithmic tools for designing robust social networks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07164", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07164", "abs": "https://arxiv.org/abs/2602.07164", "authors": ["Ruimeng Ye", "Zihan Wang", "Zinan Ling", "Yang Xiao", "Manling Li", "Xiaolong Ma", "Bo Hui"], "title": "Your Language Model Secretly Contains Personality Subnetworks", "comment": "ICLR 2026", "summary": "Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07317", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.07317", "abs": "https://arxiv.org/abs/2602.07317", "authors": ["Gregory G. V. Kenning", "Remi J. Leano", "David A. Strubbe"], "title": "Analyzing Band Gaps in Ensemble Density Functional Theory using Thermodynamic Limits of Finite One-Dimensional Model Systems", "comment": "20 pages, 4 tables, 14 figures", "summary": "Ensemble Density Functional Theory (EDFT) is a promising extension to Density Functional Theory (DFT) for calculating excited states. While Kohn-Sham eigenvalue differences underestimate gaps, EDFT has been shown to provide more accurate excitation energies in atoms, molecules and isolated model systems. However, it is unclear whether EDFT is capable of calculating band gaps of periodic systems -- and what an appropriate theoretical formulation would be to describe periodic systems. We explored how EDFT could calculate band gaps by estimating the thermodynamic limit with increasingly wide finite versions of the one-dimensional Kronig-Penney (KP) periodic model. We use Octopus, an ab initio, open-source, real-space DFT code, as in our previous work [R. J. Leano et al., Electron. Struct. 6, 035003 (2024)] in which we found with \"particle in a box\" models that EDFT can provide a reasonable effective mass correction for the homogeneous electron gas. Now, we use a periodic reference that is gapped. We find that the finite systems' Kohn-Sham gap approaches the same periodic limit for each of three ways of terminating the finite system, though the appropriate states corresponding to the valence band maximum and conduction band minimum have to be carefully identified in each case. Finally, our EDFT results, using a simple ensemblized LDA approximation, have a reasonable nonzero correction to the bandgap in the periodic limit. The results indicate that EDFT is promising for periodic systems, to motivate further work on developing a suitable formalism.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08511", "categories": ["physics.app-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08511", "abs": "https://arxiv.org/abs/2602.08511", "authors": ["Kanu Mohammed", "Vaishnavi Joshi", "Pranjali Diliprao Patil", "Sandipan Mondal", "Ming-An Lee", "Subhadip Dey"], "title": "Estimation of Fish Catch Using Sentinel-2, 3 and XGBoost-Kernel-Based Kernel Ridge Regression", "comment": "Manuscript", "summary": "Oceanographic factors, such as sea surface temperature and upper-ocean dynamics, have a significant impact on fish distribution. Maintaining fisheries that contribute to global food security requires quantifying these connections. This study uses multispectral images from Sentinel-2 MSI and Sentinel-3 OLCI to estimate fish catch using an Extreme Gradient Boosting (XGBoost)-kernelized Kernel Ridge Regression (KRR) technique. According to model evaluation, the XGBoost-KRR framework achieves the strongest correlation and the lowest prediction error across both sensors, suggesting improved capacity to capture nonlinear ocean-fish connections. While Sentinel-2 MSI resolves finer-scale spatial variability, emphasizing localized ecological interactions, Sentinel-3 OLCI displays smoother spectral responses associated with poorer spatial resolution. By supporting sustainable ecosystem management and strengthening satellite-based fisheries assessment, the proposed approach advances SDGs 2 (Zero Hunger) and 14 (Life Below Water).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06974", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.06974", "abs": "https://arxiv.org/abs/2602.06974", "authors": ["Faith Johnson", "Bryan Bo Cao", "Shubham Jain", "Ashwin Ashok", "Kristin Dana"], "title": "FeudalNav: A Simple Framework for Visual Navigation", "comment": "8 Pages, 6 figures and 4 tables. arXiv admin note: substantial text overlap with arXiv:2411.09893, arXiv:2402.12498", "summary": "Visual navigation for robotics is inspired by the human ability to navigate environments using visual cues and memory, eliminating the need for detailed maps. In unseen, unmapped, or GPS-denied settings, traditional metric map-based methods fall short, prompting a shift toward learning-based approaches with minimal exploration. In this work, we develop a hierarchical framework that decomposes the navigation decision-making process into multiple levels. Our method learns to select subgoals through a simple, transferable waypoint selection network. A key component of the approach is a latent-space memory module organized solely by visual similarity, as a proxy for distance. This alternative to graph-based topological representations proves sufficient for navigation tasks, providing a compact, light-weight, simple-to-train navigator that can find its way to the goal in novel locations. We show competitive results with a suite of SOTA methods in Habitat AI environments without using any odometry in training or inference. An additional contribution leverages the interpretablility of the framework for interactive navigation. We consider the question: how much direction intervention/interaction is needed to achieve success in all trials? We demonstrate that even minimal human involvement can significantly enhance overall navigation performance.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07131", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.07131", "abs": "https://arxiv.org/abs/2602.07131", "authors": ["Javier Salazar Cavazos", "Maximillian Egan", "Krisanne Litinas", "Benjamin Hampstead", "Scott Peltier"], "title": "Behavior Score Prediction in Resting-State Functional MRI by Deep State Space Modeling", "comment": null, "summary": "Early clinical assessment of Alzheimer's disease relies on behavior scores that measure a subject's language, memory, and cognitive skills. On the medical imaging side, functional magnetic resonance imaging has provided invaluable insights into the neural pathways underlying Alzheimer's disease. While prior studies have used resting-state functional MRI by extracting functional connectivity matrices, these approaches neglect the temporal dynamics inherent in functional data. In this work, we present a deep state space modeling framework that directly leverages the blood-oxygenation-level-dependent time series to learn a sparse collection of brain regions to predict behavior scores. Our model extracts temporal features that encapsulate nuanced patterns of intrinsic brain activity, thereby enhancing predictive performance compared to traditional connectivity methods. We identify specific brain regions that are most predictive of cognitive impairment through experiments on data provided by the Michigan Alzheimer's Disease Research Center, providing new insights into the neural substrates of early Alzheimer's pathology. These findings have important implications for the possible development of risk monitoring and intervention strategies in Alzheimer's disease.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07800", "categories": ["cs.LG", "cs.NE", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07800", "abs": "https://arxiv.org/abs/2602.07800", "authors": ["Rahul Padmanabhan", "Simone Brugiapaglia"], "title": "Approximating Matrix Functions with Deep Neural Networks and Transformers", "comment": null, "summary": "Transformers have revolutionized natural language processing, but their use for numerical computation has received less attention. We study the approximation of matrix functions, which map scalar functions to matrices, using neural networks including transformers. We focus on functions mapping square matrices to square matrices of the same dimension. These types of matrix functions appear throughout scientific computing, e.g., the matrix exponential in continuous-time Markov chains and the matrix sign function in stability analysis of dynamical systems. In this paper, we make two contributions. First, we prove bounds on the width and depth of ReLU networks needed to approximate the matrix exponential to an arbitrary precision. Second, we show experimentally that a transformer encoder-decoder with suitable numerical encodings can approximate certain matrix functions at a relative error of 5% with high probability. Our study reveals that the encoding scheme strongly affects performance, with different schemes working better for different functions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08389", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08389", "abs": "https://arxiv.org/abs/2602.08389", "authors": ["Yao-hua Franck Xu", "Tayeb Lemlouma", "Arnaud Braud", "Jean-Marie Bonnin"], "title": "Altruism and Fair Objective in Mixed-Motive Markov games", "comment": null, "summary": "Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant approach to multi-agent cooperation is the utilitarian welfare which can produce efficient highly inequitable outcomes. This paper proposes a novel framework to foster fairer cooperation by replacing the standard utilitarian objective with Proportional Fairness. We introduce a fair altruistic utility for each agent, defined on the individual log-payoff space and derive the analytical conditions required to ensure cooperation in classic social dilemmas. We then extend this framework to sequential settings by defining a Fair Markov Game and deriving novel fair Actor-Critic algorithms to learn fair policies. Finally, we evaluate our method in various social dilemma environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07853", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07853", "abs": "https://arxiv.org/abs/2602.07853", "authors": ["Xiang Feng", "Yunuo Chen", "Chang Yu", "Hao Su", "Demetri Terzopoulos", "Yin Yang", "Joe Masterjohn", "Alejandro Castro", "Chenfanfu Jiang"], "title": "MPM Lite: Linear Kernels and Integration without Particles", "comment": "19 pages", "summary": "In this paper, we introduce MPM Lite, a new hybrid Lagrangian/Eulerian method that eliminates the need for particle-based quadrature at solve time. Standard MPM practices suffer from a performance bottleneck where expensive implicit solves are proportional to particle-per-cell (PPC) counts due to the the choices of particle-based quadrature and wide-stencil kernels. In contrast, MPM Lite treats particles primarily as carriers of kinematic state and material history. By conceptualizing the background Cartesian grid as a voxel hexahedral mesh, we resample particle states onto fixed-location quadrature points using efficient, compact linear kernels. This architectural shift allows force assembly and the entire time-integration process to proceed without accessing particles, making the solver complexity no longer relate to particles. At the core of our method is a novel stress transfer and stretch reconstruction strategy. To avoid non-physical averaging of deformation gradients, we resample the extensive Kirchhoff stress and derive a rotation-free deformation reference solution, which naturally supports an optimization-based incremental potential formulation. Consequently, MPM Lite can be implemented as modular resampling units coupled with an FEM-style integration module, enabling the direct use of off-the-shelf nonlinear solvers, preconditioners, and unambiguous boundary conditions. We demonstrate through extensive experiments that MPM Lite preserves the robustness and versatility of traditional MPM across diverse materials while delivering significant speedups in implicit settings and improving explicit settings at the same time. Check our project page at https://mpmlite.github.io.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08966", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.08966", "abs": "https://arxiv.org/abs/2602.08966", "authors": ["Hirota Kinoshita", "Ayumi Igarashi"], "title": "Maximin Shares with Lower Quotas", "comment": null, "summary": "We study the fair division of indivisible items among $n$ agents with heterogeneous additive valuations, subject to lower and upper quotas on the number of items allocated to each agent. Such constraints are crucial in various applications, ranging from personnel assignments to computing resource distribution. This paper focuses on the fairness criterion known as maximin shares (MMS) and its approximations. Under arbitrary lower and upper quotas, we show that a $\\left(\\frac{2n}{3n-1}\\right)$-MMS allocation of goods exists and can be computed in polynomial time, while we also present a polynomial-time algorithm for finding a $\\left(\\frac{3n-1}{2n}\\right)$-MMS allocation of chores. Furthermore, we consider the generalized scenario where items are partitioned into multiple categories, each with its own lower and upper quotas. In this setting, our algorithm computes an $\\left(\\frac{n}{2n-1}\\right)$-MMS allocation of goods or a $\\left(\\frac{2n-1}{n}\\right)$-MMS allocation of chores in polynomial time. These results extend previous work on the cardinality constraints, i.e., the special case where only upper quotas are imposed.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07684", "categories": ["eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07684", "abs": "https://arxiv.org/abs/2602.07684", "authors": ["Arslan Ahmad", "Ian Dobson"], "title": "Quantifying resilience for distribution system customers with SALEDI", "comment": null, "summary": "The impact of routine smaller outages on distribution system customers in terms of customer minutes interrupted can be tracked using conventional reliability indices. However, the customer minutes interrupted in large blackout events are extremely variable, and this makes it difficult to quantify the customer impact of these extreme events with resilience metrics. We solve this problem with the System Average Large Event Duration Index SALEDI that logarithmically transforms the customer minutes interrupted. We explain how this new resilience metric works, compare it with alternatives, quantify its statistical accuracy, and illustrate its practical use with standard outage data from five utilities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08097", "categories": ["cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08097", "abs": "https://arxiv.org/abs/2602.08097", "authors": ["Tian Zhang", "Ashwin Padaki", "Jiaming Liang", "Zack Ives", "Erik Waingarten"], "title": "Prune, Don't Rebuild: Efficiently Tuning $\u03b1$-Reachable Graphs for Nearest Neighbor Search", "comment": null, "summary": "Vector similarity search is an essential primitive in modern AI and ML applications. Most vector databases adopt graph-based approximate nearest neighbor (ANN) search algorithms, such as DiskANN (Subramanya et al., 2019), which have demonstrated state-of-the-art empirical performance. DiskANN's graph construction is governed by a reachability parameter $\u03b1$, which gives a trade-off between construction time, query time, and accuracy. However, adaptively tuning this trade-off typically requires rebuilding the index for different $\u03b1$ values, which is prohibitive at scale. In this work, we propose RP-Tuning, an efficient post-hoc routine, based on DiskANN's pruning step, to adjust the $\u03b1$ parameter without reconstructing the full index. Within the $\u03b1$-reachability framework of prior theoretical works (Indyk and Xu, 2023; Gollapudi et al., 2025), we prove that pruning an initially $\u03b1$-reachable graph with RP-Tuning preserves worst-case reachability guarantees in general metrics and improved guarantees in Euclidean metrics. Empirically, we show that RP-Tuning accelerates DiskANN tuning on four public datasets by up to $43\\times$ with negligible overhead.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07275", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.07275", "abs": "https://arxiv.org/abs/2602.07275", "authors": ["Vishesh Purnananda", "Benjamin John Wruck", "Mingyu Guo"], "title": "Evolving LLM-Derived Control Policies for Residential EV Charging and Vehicle-to-Grid Energy Optimization", "comment": null, "summary": "This research presents a novel application of Evolutionary Computation to the domain of residential electric vehicle (EV) energy management. While reinforcement learning (RL) achieves high performance in vehicle-to-grid (V2G) optimization, it typically produces opaque \"black-box\" neural networks that are difficult for consumers and regulators to audit. Addressing this interpretability gap, we propose a program search framework that leverages Large Language Models (LLMs) as intelligent mutation operators within an iterative prompt-evaluation-repair loop. Utilizing the high-fidelity EV2Gym simulation environment as a fitness function, the system undergoes successive refinement cycles to synthesize executable Python policies that balance profit maximization, user comfort, and physical safety constraints. We benchmark four prompting strategies: Imitation, Reasoning, Hybrid and Runtime, evaluating their ability to discover adaptive control logic. Results demonstrate that the Hybrid strategy produces concise, human-readable heuristics that achieve 118% of the baseline profit, effectively discovering complex behaviors like anticipatory arbitrage and hysteresis without explicit programming. This work establishes LLM-driven Evolutionary Computation as a practical approach for generating EV charging control policies that are transparent, inspectable, and suitable for real residential deployment.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07779", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07779", "abs": "https://arxiv.org/abs/2602.07779", "authors": ["Nicol\u00e1s Sigales", "Tim Kokkeler", "Gonzalo de Polsi", "Sebastian Bergeret"], "title": "Spin Splitter and Inverse Effects in Altermagnetic Hybrid Structures", "comment": "12 pages, 7 figures", "summary": "We provide a theoretical description of diffusive charge and spin transport in hybrid devices containing altermagnets. Based on recently derived drift--diffusion equations for coupled charge and spin dynamics and general boundary conditions, our approach provides a unified description of the spin-splitter effect, i.e., the conversion of charge currents into spin currents, and its inverse in terms of experimentally accessible parameters. We analyze, analytically and numerically, the spin-splitter effect, demonstrating that an injected spin accumulation generates a measurable voltage difference across the transverse direction in the altermagnet. Motivated by a recent experiment, we also analyze a nonlocal spin-valve geometry in which an altermagnetic strip injects spin into a diffusive normal metal. We derive the resulting nonlocal voltage detected by a ferromagnetic electrode as a function of the relative orientation of the N'eel vector and the ferromagnetic polarization, accounting for the main experimental findings. For this setup, we further address spin precession during diffusive transport by analyzing the spin Hanle effect. Our results provide theoretical explanations and predictions for several altermagnet hybrid structures.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08970", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08970", "abs": "https://arxiv.org/abs/2602.08970", "authors": ["Jacopo Nudo", "Eugenio Nerio Nemmi", "Edoardo Loru", "Alessandro Mei", "Walter Quattrociocchi", "Matteo Cinelli"], "title": "Hyperactive Minority Alter the Stability of Community Notes", "comment": null, "summary": "As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07176", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07176", "abs": "https://arxiv.org/abs/2602.07176", "authors": ["Mohamed El Hajji", "Tarek Ait Baha", "Aicha Dakir", "Hammou Fadili", "Youssef Es-Saady"], "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI", "comment": "19 pages, 15 figures", "summary": "Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07325", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07325", "abs": "https://arxiv.org/abs/2602.07325", "authors": ["Xiudong Wang", "Zhonglin He", "Kaiying Dou", "Ying Dai", "Baibiao Huang", "Yandong Ma"], "title": "Ordering Mixed-Q Topological Magnetism into Lattice via Moire Engineering", "comment": null, "summary": "Topological magnetic lattices offer a fertile ground for exploring fundamental physics and developing novel spintronic devices. However, current research is predominantly confined to single-Q topologies hosting uniform type of quasiparticle. The realization of exotic mixed-Q states, where distinct topological quasiparticles co-assemble into an ordered lattice, remains largely unexplored. Here, we propose a generic mechanism to order disordered mixed-Q topological magnetism into periodic lattice via moire engineering. By leveraging the synergy between spatially modulated interlayer coupling and intrinsic intralayer magnetic frustration, we demonstrate that moire potential can effectively regularize skyrmions, antiskyrmions, and magnetic bubbles into a hybrid lattice. Combining first-principles with atomistic spin simulations, we validate this mechanism in twisted bilayer CrGaTe3, identifying it as an exemplary platform for hosting these complex ordered textures. We systematically map the phase evolution as a function of twist angle and biaxial strain, unveiling the critical role of moire potential in stabilizing mixed-Q lattice. Our findings significantly advance the frontier of topological and moire spintronics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08761", "categories": ["physics.app-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08761", "abs": "https://arxiv.org/abs/2602.08761", "authors": ["A. M. Medrano", "E. Lopez", "Pablo Garcia-Linares", "J. Villa", "M. Gamel", "M. Garin", "I. Martin", "C. Canizo", "A. Datas"], "title": "Germanium Thermophotovoltaic Devices Achieving 7.3% Efficiency Under High-Temperature Emission by Empirical Calorimetry", "comment": "40 pages, 20 Figuras", "summary": "We report the first empirical efficiency measurement of germanium-based thermophotovoltaic devices under high-temperature, high-irradiance conditions using a high view-factor calorimetric setup. Two TPV cell architectures were fabricated on p-type, highly doped (10^17 cm-3) Ge substrates, differing only in rear contact configuration. A standard device with a gold rear contact achieves a peak efficiency of 7.3 % and a power density of 1.77 W/cm2 at an emitter temperature of 1480 C, while a PERC-type device reaches 6.3 % efficiency and 1.22 W/cm2 at 1426 C. The superior performance of the standard device is attributed to lower series resistance, whereas the PERC design exhibits slightly higher efficiency at lower emitter temperatures (4.0 % vs. 3.8 % at 1150 C) due to enhanced rear-surface reflectivity. A detailed TPV model has been developed and validated across both device architectures. The model identifies out-of-band optical losses as the dominant efficiency-limiting mechanism, primarily caused by strong free-carrier absorption in the highly doped Ge substrate. Using this model, we predict device performance under idealized spectral conditions commonly assumed in prior literature. For a simulated AlN/W spectrally selective emitter, efficiencies as high as 22.3 % at 1800 C are obtained, consistent with previous semi-empirical predictions. In contrast, when previously reported Ge devices are modeled under the realistic graphite emitter spectrum used here, projected efficiencies decrease to as low as 8.1 % at 1480 C. These results show that earlier projections remain valid but idealized and underscore the importance of emitter spectral engineering and substrate optimization. Finally, we present the first direct comparison of Ge and InGaAs TPV devices under identical conditions, demonstrating the superior performance of InGaAs while confirming the cost-driven competitiveness of Ge.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06977", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06977", "abs": "https://arxiv.org/abs/2602.06977", "authors": ["Shifa Sulaiman", "Francesco Schetter", "Tobias Jensen", "Simon B\u00f8gh", "Fanny Ficuciello"], "title": "Autonomous Manipulation of Hazardous Chemicals and Delicate Objects in a Self-Driving Laboratory: A Sliding Mode Approach", "comment": null, "summary": "Precise handling of chemical instruments and materials within a self-driving laboratory environment using robotic systems demands advanced and reliable control strategies. Sliding Mode Control (SMC) has emerged as a robust approach for managing uncertainties and disturbances in manipulator dynamics, providing superior control performance compared to traditional methods. This study implements a model-based SMC (MBSMC) utilizing a hyperbolic tangent function to regulate the motion of a manipulator mounted on a mobile platform operating inside a self-driving chemical laboratory. Given the manipulator's role in transporting fragile glass vessels filled with hazardous chemicals, the controller is specifically designed to minimize abrupt transitions and achieve gentle, accurate trajectory tracking. The proposed controller is benchmarked against a non-model-based SMC (NMBSMC) and a Proportional-Integral-Derivative (PID) controller using a comprehensive set of joint and Cartesian metrics. Compared to PID and NMBSMC, MBSMC achieved significantly smoother motion and up to 90% lower control effort, validating its robustness and precision for autonomous laboratory operations. Experimental trials confirmed successful execution of tasks such as vessel grasping and window operation, which failed under PID control due to its limited ability to handle nonlinear dynamics and external disturbances, resulting in substantial trajectory tracking errors. The results validate the controller's effectiveness in achieving smooth, precise, and safe manipulator motions, supporting the advancement of intelligent mobile manipulators in autonomous laboratory environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07169", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07169", "abs": "https://arxiv.org/abs/2602.07169", "authors": ["Paul Anthony Haigh"], "title": "ML-Enabled Deformable Matched Filters for Bandlimitation Compensation in Free-Space Optics", "comment": null, "summary": "This paper proposes a neural-network-assisted deformable matched filtering framework for carrier-less amplitude and phase (CAP) modulation operating under bandwidth-limited channel conditions. Instead of replacing the analytically derived CAP matched filter, the proposed receiver learns a residual deformation of the nominal matched filter based on a compact set of physically motivated signal features extracted from the received waveform. A total of 16 time-domain, frequency-domain, and memory-related features are used to provide a low-dimensional representation of bandwidth-induced pulse distortion. These features are mapped by a fully connected neural network to complex-valued matched filter coefficients, enabling adaptive pulse-shape compensation prior to symbol-rate sampling. The network is trained end-to-end using a differentiable loss function based on error vector magnitude (EVM). Experimental results obtained using a hardware-in-the-loop CAP transmission system demonstrate that the proposed deformable matched filter significantly outperforms conventional fixed matched filtering under severe bandwidth constraints, without requiring decision feedback or increasing receiver latency.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08043", "categories": ["cs.LG", "cs.AI", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08043", "abs": "https://arxiv.org/abs/2602.08043", "authors": ["Yiheng Gao", "Qin Hua", "Zizhong Chen"], "title": "V-ABFT: Variance-Based Adaptive Threshold for Fault-Tolerant Matrix Multiplication in Mixed-Precision Deep Learning", "comment": null, "summary": "Algorithm-Based Fault Tolerance (ABFT) is widely adopted to detect silent data corruptions (SDCs) in matrix multiplication, a cornerstone operation in deep learning systems. However, existing threshold determination methods face critical challenges: analytical bounds are overly conservative, while probabilistic approaches like A-ABFT yield thresholds $160$--$4200\\times$ larger than actual rounding errors. We present V-ABFT, a variance-based adaptive threshold algorithm that achieves tighter error bounds by directly modeling the verification difference. By leveraging statistical variance estimation, V-ABFT reduces the threshold-to-actual-error ratio to approximately $7$--$20\\times$ for FP32/FP64 and $48$--$158\\times$ for BF16, representing a \\textbf{6--48$\\times$ improvement} over A-ABFT while maintaining zero false positive rate across BF16, FP16, FP32, and FP64 precisions. Furthermore, we demonstrate that for fused-kernel ABFT implementations that verify before output quantization, low-precision GEMM can use FP32-level thresholds ($e_{\\max} \\approx 10^{-6}$), enabling \\textbf{$\\sim$1000$\\times$ finer detection granularity} compared to offline verification with low-precision output ($e_{\\max} \\approx 10^{-3}$). We reproduce A-ABFT's experimental setup and validate our implementation against the original paper's results. Our method requires only $O(n)$ complexity using max/min/mean statistics, compared to A-ABFT's $O(pn)$ for finding $p$ largest values. Extensive experiments on synthetic data and real model weights (LLaMA-7B, GPT-2, ViT) demonstrate V-ABFT's effectiveness across diverse distributions. V-ABFT is platform-agnostic and has been integrated into fault-tolerant GEMM implementations on both NPUs and GPUs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08529", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08529", "abs": "https://arxiv.org/abs/2602.08529", "authors": ["Ning Lin", "Haolun Li", "Mingshu Liu", "Chengyun Ruan", "Kaibo Huang", "Yukun Wei", "Zhongliang Yang", "Linna Zhou"], "title": "EvoCorps: An Evolutionary Multi-Agent Framework for Depolarizing Online Discourse", "comment": null, "summary": "Polarization in online discourse erodes social trust and accelerates misinformation, yet technical responses remain largely diagnostic and post-hoc. Current governance approaches suffer from inherent latency and static policies, struggling to counter coordinated adversarial amplification that evolves in real-time. We present EvoCorps, an evolutionary multi-agent framework for proactive depolarization. EvoCorps frames discourse governance as a dynamic social game and coordinates roles for monitoring, planning, grounded generation, and multi-identity diffusion. A retrieval-augmented collective cognition core provides factual grounding and action--outcome memory, while closed-loop evolutionary learning adapts strategies as the environment and attackers change. We implement EvoCorps on the MOSAIC social-AI simulation platform for controlled evaluation in a multi-source news stream with adversarial injection and amplification. Across emotional polarization, viewpoint extremity, and argumentative rationality, EvoCorps improves discourse outcomes over an adversarial baseline, pointing to a practical path from detection and post-hoc mitigation to in-process, closed-loop intervention. The code is available at https://github.com/ln2146/EvoCorps.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08094", "categories": ["cs.GR", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08094", "abs": "https://arxiv.org/abs/2602.08094", "authors": ["Kevin You", "Juntian Zheng", "Minchen Li"], "title": "Energy-Controllable Time Integration for Elastodynamic Contact", "comment": null, "summary": "Dynamic simulation of elastic bodies is a longstanding task in engineering and computer graphics. In graphics, numerical integrators like implicit Euler and BDF2 are preferred due to their stability at large time steps, but they tend to dissipate energy uncontrollably. In contrast, symplectic methods like implicit midpoint can conserve energy but are not unconditionally stable and fail on moderately stiff problems. To address these limitations, we propose a general class of numerical integrators for Hamiltonian problems which are symplectic on linear problems, yet have superior stability on nonlinear problems. With this, we derive a novel energy-controllable time integrator, A-search, a simple modification of implicit Euler that can follow user-specified energy targets, enabling flexible control over energy dissipation or conservation while maintaining stability and physical fidelity. Our method integrates seamlessly with barrier-type energies and allows for inversion-free and penetration-free guarantees, making it well-suited for handling large deformations and complex collisions. Extensive evaluations over a wide range of material parameters and scenes demonstrate that A-search has biases to keep energy in low frequency motion rather than dissipation, and A-search outperforms traditional methods such as BDF2 at similar total running times by maintaining energy and leading to more visually desirable simulations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07205", "categories": ["cs.LG", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07205", "abs": "https://arxiv.org/abs/2602.07205", "authors": ["Junyan Liu", "Haipeng Luo", "Zihan Zhang", "Lillian J. Ratliff"], "title": "Online Learning for Uninformed Markov Games: Empirical Nash-Value Regret and Non-Stationarity Adaptation", "comment": "36 pages", "summary": "We study online learning in two-player uninformed Markov games, where the opponent's actions and policies are unobserved. In this setting, Tian et al. (2021) show that achieving no-external-regret is impossible without incurring an exponential dependence on the episode length $H$. They then turn to the weaker notion of Nash-value regret and propose a V-learning algorithm with regret $O(K^{2/3})$ after $K$ episodes. However, their algorithm and guarantee do not adapt to the difficulty of the problem: even in the case where the opponent follows a fixed policy and thus $O(\\sqrt{K})$ external regret is well-known to be achievable, their result is still the worse rate $O(K^{2/3})$ on a weaker metric.\n  In this work, we fully address both limitations. First, we introduce empirical Nash-value regret, a new regret notion that is strictly stronger than Nash-value regret and naturally reduces to external regret when the opponent follows a fixed policy. Moreover, under this new metric, we propose a parameter-free algorithm that achieves an $O(\\min \\{\\sqrt{K} + (CK)^{1/3},\\sqrt{LK}\\})$ regret bound, where $C$ quantifies the variance of the opponent's policies and $L$ denotes the number of policy switches (both at most $O(K)$). Therefore, our results not only recover the two extremes -- $O(\\sqrt{K})$ external regret when the opponent is fixed and $O(K^{2/3})$ Nash-value regret in the worst case -- but also smoothly interpolate between these extremes by automatically adapting to the opponent's non-stationarity. We achieve so by first providing a new analysis of the epoch-based V-learning algorithm by Mao et al. (2022), establishing an $O(\u03b7C + \\sqrt{K/\u03b7})$ regret bound, where $\u03b7$ is the epoch incremental factor. Next, we show how to adaptively restart this algorithm with an appropriate $\u03b7$ in response to the potential non-stationarity of the opponent, eventually achieving our final results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07483", "categories": ["quant-ph", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07483", "abs": "https://arxiv.org/abs/2602.07483", "authors": ["Kuan-Cheng Chen", "Hiromichi Matsuyama", "Wei-hao Huang", "Yu Yamashiro"], "title": "Recursive QAOA for Interference-Aware Resource Allocation in Wireless Networks", "comment": null, "summary": "Discrete radio resource management problems in dense wireless networks are naturally cast as quadratic unconstrained binary optimization (QUBO) programs but are difficult to solve at scale. We investigate a quantum-classical approach based on the Recursive Quantum Approximate Optimization Algorithm (RQAOA), which interleaves shallow QAOA layers with variable elimination guided by measured single- and two-qubit correlators. For interference-aware channel assignment, we give a compact QUBO/Ising formulation in which pairwise interference induces same-channel couplings and one-hot constraints are enforced via quadratic penalties (or, optionally, constraint-preserving mixers). Within RQAOA, fixing high-confidence variables or relations reduces the problem dimension, stabilizes training, and concentrates measurement effort on a shrinking instance that is solved exactly once below a cutoff. On simulated instances of modest size, including a four-user, four-channel example, the method consistently returns feasible assignments and, for the demonstrated case, attains the global optimum. These results indicate that recursion can mitigate parameter growth and feasibility issues that affect plain QAOA, and suggest a viable pathway for near-term quantum heuristics in wireless resource allocation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07811", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07811", "abs": "https://arxiv.org/abs/2602.07811", "authors": ["Xiaohan Xu", "Wei Ma", "Zhiheng Shi", "Xiaotong Xu", "Bin He", "Kairui Feng"], "title": "Urban Congestion Patterns under High Electric Vehicle Penetration: A Case Study of 10 U.S. Cities", "comment": null, "summary": "With the global energy transition and the rapid penetration of electric vehicles (EVs), the widening travel cost gap between EVs and gasoline vehicles (GVs) increasingly affects commuters' route choices and may reshape urban congestion patterns. Existing research remains in its preliminary exploratory phase. On the one hand, multi-class models do not account for fixed user class scenarios, which may not align with actual commuters; on the other hand, there is a lack of systematic quantitative analysis based on real-world complex road networks across multiple cities. As a result, the congestion effects induced by heterogeneous GV-EV cost structures may be mischaracterized or substantially underestimated. To address these limitations, this paper proposes a multi-user equilibrium (MUE) assignment model for mixed GV-EV traffic, constructs a dual algorithm with convergence guarantees, and designs multi-dimensional evaluation metrics for congestion patterns. Using 10 representative U.S. cities as a case study, this research explores the evolution trends of traffic congestion under different EV penetration scenarios based on real city-level road networks and block-level commuter origin-destination (OD) demand. The results show that full EV penetration reduces average system travel time by 2.27%--10.78% across the 10 cities, with New Orleans achieving the largest reduction (10.78%) and San Francisco the smallest (2.27%), but the effectiveness of alleviating congestion exhibits urban heterogeneity. Moreover, for cities with sufficient network redundancy, benefits are primarily concentrated during the low to medium EV penetration stage (0-0.5), though cities with topological constraints (e.g., San Francisco) show more limited improvements throughout all penetration levels. This paper can provide a foundation for formulating differentiated urban planning and congestion management policies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08098", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.08098", "abs": "https://arxiv.org/abs/2602.08098", "authors": ["Mohammad Shahverdikondori", "Sepehr Elahi", "Patrick Thiran", "Negar Kiyavash"], "title": "Neighborhood-Aware Graph Labeling Problem", "comment": null, "summary": "Motivated by optimization oracles in bandits with network interference, we study the Neighborhood-Aware Graph Labeling (NAGL) problem. Given a graph $G = (V,E)$, a label set of size $L$, and local reward functions $f_v$ accessed via evaluation oracles, the objective is to assign labels to maximize $\\sum_{v \\in V} f_v(x_{N[v]})$, where each term depends on the closed neighborhood of $v$. Two vertices co-occur in some neighborhood term exactly when their distance in $G$ is at most $2$, so the dependency graph is the squared graph $G^2$ and $\\mathrm{tw}(G^2)$ governs exact algorithms and matching fine-grained lower bounds. Accordingly, we show that this dependence is inherent: NAGL is NP-hard even on star graphs with binary labels and, assuming SETH, admits no $(L-\\varepsilon)^{\\mathrm{tw}(G^2)}\\cdot n^{O(1)}$-time algorithm for any $\\varepsilon>0$. We match this with an exact dynamic program on a tree decomposition of $G^2$ running in $O\\!\\left(n\\cdot \\mathrm{tw}(G^2)\\cdot L^{\\mathrm{tw}(G^2)+1}\\right)$ time. For approximation, unless $\\mathsf{P}=\\mathsf{NP}$, for every $\\varepsilon>0$ there is no polynomial-time $n^{1-\\varepsilon}$-approximation on general graphs even under the promise $\\mathrm{OPT}>0$; without the promise $\\mathrm{OPT}>0$, no finite multiplicative approximation ratio is possible. In the nonnegative-reward regime, we give polynomial-time approximation algorithms for NAGL in two settings: (i) given a proper $q$-coloring of $G^2$, we obtain a $1/q$-approximation; and (ii) on planar graphs of bounded maximum degree, we develop a Baker-type polynomial-time approximation scheme (PTAS), which becomes an efficient PTAS (EPTAS) when $L$ is constant.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07299", "categories": ["cs.NE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07299", "abs": "https://arxiv.org/abs/2602.07299", "authors": ["Rivaaj Monsia", "Daniel Young", "Olivier Francon", "Risto Miikkulainen"], "title": "Optimizing Chlorination in Water Distribution Systems via Surrogate-assisted Neuroevolution", "comment": "14 pages, 9 figures, GECCO '26 in-review", "summary": "Ensuring the microbiological safety of large, heterogeneous water distribution systems (WDS) typically requires managing appropriate levels of disinfectant residuals including chlorine. WDS include complex fluid interactions that are nonlinear and noisy, making such maintenance a challenging problem for traditional control algorithms. This paper proposes an evolutionary framework to this problem based on neuroevolution, multi-objective optimization, and surrogate modeling. Neural networks were evolved with NEAT to inject chlorine at strategic locations in the distribution network at select times. NSGA-II was employed to optimize four objectives: minimizing the total amount of chlorine injected, keeping chlorine concentrations homogeneous across the network, ensuring that maximum concentrations did not exceed safe bounds, and distributing the injections regularly over time. Each network was evaluated against a surrogate model, i.e. a neural network trained to emulate EPANET, an industry-level hydraulic WDS simulator that is accurate but infeasible in terms of computational cost to support machine learning. The evolved controllers produced a diverse range of Pareto-optimal policies that could be implemented in practice, outperforming standard reinforcement learning methods such as PPO. The results thus suggest a pathway toward improving urban water systems, and highlight the potential of using evolution with surrogate modeling to optimize complex real-world systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08154", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08154", "abs": "https://arxiv.org/abs/2602.08154", "authors": ["George Kirczenow"], "title": "Symmetry, Disorder and Transport Through Altermagnetic Quantum Dots and Their Antiferromagnetic Twins", "comment": "9 pages, 11 figures", "summary": "Altermagnetic crystals resemble antiferromagnets in that they have no macroscopic magnetization, but unlike antiferromagnets they exhibit spin-split band structures. Here the transport properties of altermagnetic quantum dots and their antiferromagnetic twins are explored theoretically with the help of Landauer-Buttiker theory, symmetry considerations and tight-binding models. The influence of the symmetries of the quantum dots, their parent crystal lattices, their shapes and edges, lead arrangements and disorder on the anomalous Hall effect, the spin-Hall effect and spin filtering by the quantum dots are investigated.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08407", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08407", "abs": "https://arxiv.org/abs/2602.08407", "authors": ["Richard Serrano", "Baptiste Jeudy", "Charlotte Laclau", "Christine Largeron"], "title": "Drop the mask! GAMM-A Taxonomy for Graph Attributes Missing Mechanisms", "comment": null, "summary": "Exploring missing data in attributed graphs introduces unique challenges beyond those found in tabular datasets. In this work, we extend the taxonomy for missing data mechanisms to attributed graphs by proposing GAMM (Graph Attributes Missing Mechanisms), a framework that systematically links missingness probability to both node attributes and the underlying graph structure. Our taxonomy enriches the conventional definitions of masking mechanisms by introducing graph-specific dependencies. We empirically demonstrate that state-of-the-art imputation methods, while effective on traditional masks, significantly struggle when confronted with these more realistic graph-aware missingness scenarios.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07181", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07181", "abs": "https://arxiv.org/abs/2602.07181", "authors": ["Tianyu Zhao", "Siqi Li", "Yasser Shoukry", "Salma Elmalaki"], "title": "Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs", "comment": null, "summary": "User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07351", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07351", "abs": "https://arxiv.org/abs/2602.07351", "authors": ["Nayoung Kim", "Honghui Kim", "Sihyun Yu", "Minkyu Kim", "Seongsu Kim", "Sungsoo Ahn"], "title": "AtomMOF: All-Atom Flow Matching for MOF-Adsorbate Structure Prediction", "comment": "10 pages, 11 figures", "summary": "Deep generative models have shown promise for modeling metal-organic frameworks (MOFs), but existing approaches (1) rely on coarse-grained representations that assume fixed bond lengths and angles, and (2) neglect the MOF-adsorbate interactions, which are critical for downstream applications. We introduce AtomMOF, a scalable flow-based model built on an all-atom Diffusion Transformer that maps 2D molecular graphs of building blocks and adsorbates directly to equilibrium 3D structures without imposing structural constraints. We further present scaling laws for porous crystal generation, indicating predictable performance gains with increased model capacity, and introduce Feynman-Kac steering guided by machine-learned interatomic potentials to improve geometric validity and sampling stability. On the (MOF-only) BW dataset, AtomMOF increases the match rate by 35.00% and reduces RMSD by 32.64%. On the ODAC25 dataset (MOF-adsorbate), AtomMOF is substantially more sample-efficient than grand canonical Monte Carlo in recovering adsorption configurations and can identify candidates with lower adsorption energies than the reference dataset. Code is available at https://github.com/nayoung10/AtomMOF.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07400", "categories": ["cs.LG", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.07400", "abs": "https://arxiv.org/abs/2602.07400", "authors": ["Simon B\u00fchrer", "Andreas Plesner", "Aczel Till", "Roger Wattenhofer"], "title": "BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks", "comment": null, "summary": "The energy and latency costs of deep neural network inference are increasingly driven by deployment rather than training, motivating hardware-specialized alternatives to arithmetic-heavy models. Field-Programmable Gate Arrays (FPGAs) provide an attractive substrate for such specialization, yet existing FPGA-based neural approaches are fragmented and difficult to compare. We present BitLogic, a fully gradient-based, end-to-end trainable framework for FPGA-native neural networks built around Lookup Table (LUT) computation. BitLogic replaces multiply-accumulate operations with differentiable LUT nodes that map directly to FPGA primitives, enabling native binary computation, sparse connectivity, and efficient hardware realization. The framework offers a modular functional API supporting diverse architectures, along with learned encoders, hardware-aware heads, and multiple boundary-consistent LUT relaxations. An automated Register Transfer Level (RTL) export pipeline translates trained PyTorch models into synthesizable HDL, ensuring equivalence between software and hardware inference. Experiments across standard vision benchmarks and heterogeneous hardware platforms demonstrate competitive accuracy and substantial gains in FPGA efficiency, including 72.3% test accuracy on CIFAR-10 achieved with fewer than 0.3M logic gates, while attaining sub-20 ns single-sample inference using only LUT resources.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08823", "categories": ["physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.08823", "abs": "https://arxiv.org/abs/2602.08823", "authors": ["Amit Shaham", "Ariel Epstein"], "title": "Perfect all-angle asymmetric transmission via normal susceptibilities: exact spatial derivative by local meta-atoms and nonlocal metasurfaces", "comment": null, "summary": "We present a systematic methodology for realizing accurate asymmetric all-angle transmission in nonlocal metasurfaces. As a representative example, we derive closed-form susceptibility conditions for exact first-order spatial differentiation of unity numerical aperture, clarifying the role of each underlying balance. We provide rigorous and detailed designs of physically meaningful structures that directly feature such susceptibilities: a conceptual local meta-atom and a realistic nonlocal multilayered printed circuit board (PCB). Importantly, the latter leverages an intricate system of nearfield coupling beyond standard homogenization. Validated in simulations, our results provide a general and modular route to high-resolution asymmetric nonlocal metasurfaces for optical analog processing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06991", "categories": ["cs.RO", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2602.06991", "abs": "https://arxiv.org/abs/2602.06991", "authors": ["Seongbo Ha", "Sibaek Lee", "Kyungsu Kang", "Joonyeol Choi", "Seungjun Tak", "Hyeonwoo Yu"], "title": "LangGS-SLAM: Real-Time Language-Feature Gaussian Splatting SLAM", "comment": "17 pages, 4 figures", "summary": "In this paper, we propose a RGB-D SLAM system that reconstructs a language-aligned dense feature field while sustaining low-latency tracking and mapping. First, we introduce a Top-K Rendering pipeline, a high-throughput and semantic-distortion-free method for efficiently rendering high-dimensional feature maps. To address the resulting semantic-geometric discrepancy and mitigate the memory consumption, we further design a multi-criteria map management strategy that prunes redundant or inconsistent Gaussians while preserving scene integrity. Finally, a hybrid field optimization framework jointly refines the geometric and semantic fields under real-time constraints by decoupling their optimization frequencies according to field characteristics. The proposed system achieves superior geometric fidelity compared to geometric-only baselines and comparable semantic fidelity to offline approaches while operating at 15 FPS. Our results demonstrate that online SLAM with dense, uncompressed language-aligned feature fields is both feasible and effective, bridging the gap between 3D perception and language-based reasoning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07270", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07270", "abs": "https://arxiv.org/abs/2602.07270", "authors": ["Siminfar Samakoush Galougah"], "title": "Spectrum Coexistence, Network Dimensioning, and Cell-Free Architectures in 5G and 5G-Advanced Wireless Networks", "comment": null, "summary": "Fifth-generation (5G) wireless networks introduce new architectural paradigms, spectrum usage models, and optimization challenges to support enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communications. This survey provides a comprehensive overview of key technologies and design challenges in 5G systems, with a focus on spectrum coexistence and interference management, network dimensioning and planning, cell-free massive MIMO architectures, fronthaul-aware user management, and power allocation strategies. Representative analytical, simulation-based, and optimization-driven approaches are reviewed, fundamental trade-offs are highlighted, and open research challenges relevant to 5G-Advanced and beyond are identified.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08567", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08567", "abs": "https://arxiv.org/abs/2602.08567", "authors": ["Jinnuo Liu", "Chuke Liu", "Hua Shen"], "title": "ValueFlow: Measuring the Propagation of Value Perturbations in Multi-Agent LLM Systems", "comment": "Preprint. Under review. 18 pages, 9 figures", "summary": "Multi-agent large language model (LLM) systems increasingly consist of agents that observe and respond to one another's outputs. While value alignment is typically evaluated for isolated models, how value perturbations propagate through agent interactions remains poorly understood. We present ValueFlow, a perturbation-based evaluation framework for measuring and analyzing value drift in multi-agent systems. ValueFlow introduces a 56-value evaluation dataset derived from the Schwartz Value Survey and quantifies agents' value orientations during interaction using an LLM-as-a-judge protocol. Building on this measurement layer, ValueFlow decomposes value drift into agent-level response behavior and system-level structural effects, operationalized by two metrics: beta-susceptibility, which measures an agent's sensitivity to perturbed peer signals, and system susceptibility (SS), which captures how node-level perturbations affect final system outputs. Experiments across multiple model backbones, prompt personas, value dimensions, and network structures show that susceptibility varies widely across values and is strongly shaped by structural topology.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08642", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.08642", "abs": "https://arxiv.org/abs/2602.08642", "authors": ["Martin B\u00e1lint", "Corentin Sala\u00fcn", "Hans-Peter Seidel", "Karol Myszkowski"], "title": "Forget Superresolution, Sample Adaptively (when Path Tracing)", "comment": null, "summary": "Real-time path tracing increasingly operates under extremely low sampling budgets, often below one sample per pixel, as rendering complexity, resolution, and frame-rate requirements continue to rise. While super-resolution is widely used in production, it uniformly sacrifices spatial detail and cannot exploit variations in noise, reconstruction difficulty, and perceptual importance across the image. Adaptive sampling offers a compelling alternative, but existing end-to-end approaches rely on approximations that break down in sparse regimes.\n  We introduce an end-to-end adaptive sampling and denoising pipeline explicitly designed for the sub-1-spp regime. Our method uses a stochastic formulation of sample placement that enables gradient estimation despite discrete sampling decisions, allowing stable training of a neural sampler at low sampling budgets. To better align optimization with human perception, we propose a tonemapping-aware training pipeline that integrates differentiable filmic operators and a state-of-the-art perceptual loss, preventing oversampling of regions with low visual impact.\n  In addition, we introduce a gather-based pyramidal denoising filter and a learnable generalization of albedo demodulation tailored to sparse sampling. Our results show consistent improvements over uniform sparse sampling, with notably better reconstruction of perceptually critical details such as specular highlights and shadow boundaries, and demonstrate that adaptive sampling remains effective even at minimal budgets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07958", "categories": ["eess.SY", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07958", "abs": "https://arxiv.org/abs/2602.07958", "authors": ["Yumin Kim", "Hyeonsu Lyu", "Minjae Lee", "Hyun Jong Yang"], "title": "Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty", "comment": "This paper has been accepted at 2025 IEEE Globecom Workshop: WS02-GAIMC: Mutual Facilitation of Generative Artificial Intelligence and Mobile Communications", "summary": "Large language models (LLMs) offer significant potential for intelligent mobile services but are computationally intensive for resource-constrained devices. Mobile edge computing (MEC) allows such devices to offload inference tasks to edge servers (ESs), yet introduces latency due to communication and serverside queuing, especially in multi-user environments. In this work, we propose an uncertainty-aware offloading framework that dynamically decides whether to perform inference locally or offload it to the ES, based on token-level uncertainty and resource constraints. We define a margin-based token-level uncertainty metric and demonstrate its correlation with model accuracy. Leveraging this metric, we design a greedy offloading algorithm (GOA) that minimizes delay while maintaining accuracy by prioritizing offloading for highuncertainty queries. Our experiments show that GOA consistently achieves a favorable trade-off, outperforming baseline strategies in both accuracy and latency across varying user densities, and operates with practical computation time. These results establish GOA as a scalable and effective solution for LLM inference in MEC environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07836", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07836", "abs": "https://arxiv.org/abs/2602.07836", "authors": ["Jianhua Sun", "Kaihong Lu", "Xin Yu"], "title": "Convergence Analysis of Continuous-Time Distributed Stochastic Gradient Algorithms", "comment": null, "summary": "In this paper, we propose a new framework to study distributed optimization problems with stochastic gradients by employing a multi-agent system with continuous-time dynamics. Here the goal of the agents is to cooperatively minimize the sum of convex objective functions. When making decisions, each agent only has access to a stochastic gradient of its own objective function rather than the real gradient, and can exchange local state information with its immediate neighbors via a time-varying directed graph. Particularly, the stochasticity is depicted by the Brownian motion. To handle this problem, we propose a continuous-time distributed stochastic gradient algorithm based on the consensus algorithm and the gradient descent strategy. Under mild assumptions on the connectivity of the graph and objective functions, using convex analysis theory, the Lyapunov theory and Ito formula, we prove that the states of the agents asymptotically reach a common minimizer in expectation. Finally, a simulation example is worked out to demonstrate the effectiveness of our theoretical results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08471", "categories": ["cs.DS", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2602.08471", "abs": "https://arxiv.org/abs/2602.08471", "authors": ["Wojciech Gabryelski", "Zbigniew Go\u0142\u0229biewski", "Martin P\u00e9pin"], "title": "Boltzmann sampling and optimal exact-size sampling for directed acyclic graphs", "comment": null, "summary": "We propose two efficient algorithms for generating uniform random directed acyclic graphs, including an asymptotically optimal exact-size sampler that performs $\\frac{n^2}{2} + o(n^2)$ operations and requests to a random generator. This was achieved by extending the Boltzmann model for graphical generating functions and by using various decompositions of directed acyclic graphs. The presented samplers improve upon the state-of-the-art algorithms in terms of theoretical complexity and offer a significant speed-up in practice.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08513", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.08513", "abs": "https://arxiv.org/abs/2602.08513", "authors": ["Yu Xue", "Pengcheng Jiang", "Chenchen Zhu", "Yong Zhang", "Ran Cheng", "Kaizhou Gao", "Dunwei Gong"], "title": "A Multi-objective Evolutionary Algorithm Based on Bi-population with Uniform Sampling for Neural Architecture Search", "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems. Published on this https URL: https://doi.org/10.1109/TNNLS.2026.3659508", "summary": "Neural architecture search (NAS) automates neural network design, improving efficiency over manual approaches. However, efficiently discovering high-performance neural network architectures that simultaneously optimize multiple objectives remains a significant challenge in NAS. Existing methods often suffer from limited population diversity and inadequate exploration of the search space, particularly in regions with extreme complexity values. To address these challenges, we propose MOEA-BUS, an innovative multi-objective evolutionary algorithm based on bi-population with uniform sampling for neural architecture search, aimed at simultaneously optimizing both accuracy and network complexity. In MOEA-BUS, a novel uniform sampling method is proposed to initialize the population, ensuring that architectures are distributed uniformly across the objective space. Furthermore, to enhance exploration, we deploy a bi-population framework where two populations evolve synergistically, facilitating comprehensive search space coverage. Experiments on CIFAR-10 and ImageNet demonstrate MOEA-BUS's superiority, achieving top-1 accuracies of 98.39% on CIFAR-10, and 80.03% on ImageNet. Notably, it achieves 78.28% accuracy on ImageNet with only 446M MAdds. Ablation studies confirm that both uniform sampling and bi-population mechanisms enhance population diversity and performance. Additionally, in terms of the Kendall's tau coefficient, the SVM achieves an improvement of at least 0.035 compared to the other three commonly used machine learning models, and uniform sampling provided an enhancement of approximately 0.07.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08386", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08386", "abs": "https://arxiv.org/abs/2602.08386", "authors": ["Maxen Cosset-Ch\u00e9neau", "Boxuan Yang", "Bart J. van Wees"], "title": "Highly Polarized and Long Range Dissipationless Spin Transport Due to Counterflowing Electron and Hole Edge Channels", "comment": null, "summary": "The presence of edge channels in the quantum Hall regime leads to dissipationless charge transport over long distances. When graphene is interfaced with a magnetic material, the exchange interaction lifts the Landau levels spin degeneracy. This causes the presence of counterflowing edge channels with opposite spin polarization. We show theoretically that the spin-flip scattering between these edge channels enables a dissipationless spin transport with larger than 100% spin polarization of the charge current. It also allows the transport of spin over macroscopically long distances, even in the absence of an applied charge current.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08589", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08589", "abs": "https://arxiv.org/abs/2602.08589", "authors": ["Emmanouil Kariotakis", "Aritra Konar"], "title": "FairRARI: A Plug and Play Framework for Fairness-Aware PageRank", "comment": null, "summary": "PageRank (PR) is a fundamental algorithm in graph machine learning tasks. Owing to the increasing importance of algorithmic fairness, we consider the problem of computing PR vectors subject to various group-fairness criteria based on sensitive attributes of the vertices. At present, principled algorithms for this problem are lacking - some cannot guarantee that a target fairness level is achieved, while others do not feature optimality guarantees. In order to overcome these shortcomings, we put forth a unified in-processing convex optimization framework, termed FairRARI, for tackling different group-fairness criteria in a ``plug and play'' fashion. Leveraging a variational formulation of PR, the framework computes fair PR vectors by solving a strongly convex optimization problem with fairness constraints, thereby ensuring that a target fairness level is achieved. We further introduce three different fairness criteria which can be efficiently tackled using FairRARI to compute fair PR vectors with the same asymptotic time-complexity as the original PR algorithm. Extensive experiments on real-world datasets showcase that FairRARI outperforms existing methods in terms of utility, while achieving the desired fairness levels across multiple vertex groups; thereby highlighting its effectiveness.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07190", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07190", "abs": "https://arxiv.org/abs/2602.07190", "authors": ["Anagha Kulkarni", "Parin Rajesh Jhaveri", "Prasha Shrestha", "Yu Tong Han", "Reza Amini", "Behrouz Madahian"], "title": "Long-Context Long-Form Question Answering for Legal Domain", "comment": "EACL 2026", "summary": "Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07354", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07354", "abs": "https://arxiv.org/abs/2602.07354", "authors": ["Juyoung Jeong", "Veera Sundararaghavan"], "title": "ELAS3D-Xtal: An OpenMP-accelerated crystal elasticity solver with automated experiment-driven microstructure generation", "comment": null, "summary": "This paper introduces ELAS3D-Xtal, a high-performance Fortran/OpenMP upgrade of the NIST ELAS3D voxel-based finite element solver for computing 3D elastic fields in polycrystals with defects. The code supports crystal anisotropy by precomputing rotated stiffness tensors from user-specified orientations and solves the equilibrium problem with a matrix-free, OpenMP-parallel preconditioned conjugate-gradient (PCG) method using a point-block Jacobi preconditioner. On a single shared-memory multicore PC, OpenMP threading accelerates the baseline CG solver by ~10X, while the block-preconditioned CG solver achieves 53-61X speedup relative to the serial CG baseline for meshes from 100^3 to 500^3 voxels (scaling to domains up to 800^3 voxels). Accuracy is validated against the analytical Eshelby inclusion solution. ELAS3D-Xtal also integrates microstructure construction, including statistically calibrated polycrystal generation via spatial filtering and parallel voxel-to-grain assignment, direct pore insertion from XCT centroid/radius data, and texture assignment. Full-field phase, orientation, and stress outputs are written in HDF5 to enable scalable post-processing and defect-mechanics workflows. Applications are demonstrated for (i) anisotropy-controlled defect-scale stress fields and (ii) LPBF SS316L microstructures with gas, lack-of-fusion, and keyhole pore morphologies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07717", "categories": ["cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.07717", "abs": "https://arxiv.org/abs/2602.07717", "authors": ["Yingjie Li", "Daniel Robinson", "Cunxi Yu"], "title": "All-Optical Segmentation via Diffractive Neural Networks for Autonomous Driving", "comment": null, "summary": "Semantic segmentation and lane detection are crucial tasks in autonomous driving systems. Conventional approaches predominantly rely on deep neural networks (DNNs), which incur high energy costs due to extensive analog-to-digital conversions and large-scale image computations required for low-latency, real-time responses. Diffractive optical neural networks (DONNs) have shown promising advantages over conventional DNNs on digital or optoelectronic computing platforms in energy efficiency. By performing all-optical image processing via light diffraction at the speed of light, DONNs save computation energy costs while reducing the overhead associated with analog-to-digital conversions by all-optical encoding and computing. In this work, we propose a novel all-optical computing framework for RGB image segmentation and lane detection in autonomous driving applications. Our experimental results demonstrate the effectiveness of the DONN system for image segmentation on the CityScapes dataset. Additionally, we conduct case studies on lane detection using a customized indoor track dataset and simulated driving scenarios in CARLA, where we further evaluate the model's generalizability under diverse environmental conditions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07826", "categories": ["cond-mat.mtrl-sci", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.07826", "abs": "https://arxiv.org/abs/2602.07826", "authors": ["A. S. Nuradinov", "O. V. Chistyakov", "K. A. Sirenko", "I. A. Nuradinov", "D. O. Derecha"], "title": "Influence of Elastic Oscillations on Nucleation in Metals", "comment": null, "summary": "This work is devoted to establishing the mechanisms of elastic oscillation influence on nucleation processes in metal melts. The method of physical modeling with low-temperature metallic alloys (Wood and Rose) and transparent organic media (salol, camphene, diphenylamine) was used. It was established that vibration and ultrasound significantly reduce the supercooling required to initiate crystallization. The effectiveness of the influence significantly increases for samples with solid substrates. The hypotheses about the influence through changes in melt viscosity and the exclusive role of cavitation were experimentally refuted. The transition from pre-cavitation to cavitation ultrasound regime is not accompanied by qualitative changes in the influence on nucleation. The mechanism of elastic oscillation influence is substantiated, which consists in mechanical impact on adsorbed crystal nuclei on the surfaces of solid substrates. Elastic oscillations increase the nucleation rate by creating growth steps (dislocations) on the surfaces of adsorbed nuclei as a result of mechanical friction of solid substrates and cavitation erosion. The results have fundamental significance for understanding the physical nature of metal crystallization and practical application for developing technologies for controlling structure formation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06995", "categories": ["cs.RO", "cs.CV", "cs.IT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.06995", "abs": "https://arxiv.org/abs/2602.06995", "authors": ["Konstantinos Gounis", "Sotiris A. Tegos", "Dimitrios Tyrovolas", "Panagiotis D. Diamantoulakis", "George K. Karagiannidis"], "title": "When Simultaneous Localization and Mapping Meets Wireless Communications: A Survey", "comment": null, "summary": "The availability of commercial wireless communication and sensing equipment combined with the advancements in intelligent autonomous systems paves the way towards robust joint communications and simultaneous localization and mapping (SLAM). This paper surveys the state-of-the-art in the nexus of SLAM and Wireless Communications, attributing the bidirectional impact of each with a focus on visual SLAM (V-SLAM) integration. We provide an overview of key concepts related to wireless signal propagation, geometric channel modeling, and radio frequency (RF)-based localization and sensing. In addition to this, we show image processing techniques that can detect landmarks, proactively predicting optimal paths for wireless channels. Several dimensions are considered, including the prerequisites, techniques, background, and future directions and challenges of the intersection between SLAM and wireless communications. We analyze mathematical approaches such as probabilistic models, and spatial methods for signal processing, as well as key technological aspects. We expose techniques and items towards enabling a highly effective retrieval of the autonomous robot state. Among other interesting findings, we observe that monocular V-SLAM would benefit from RF relevant information, as the latter can serve as a proxy for the scale ambiguity resolution. Conversely, we find that wireless communications in the context of 5G and beyond can potentially benefit from visual odometry that is central in SLAM. Moreover, we examine other sources besides the camera for SLAM and describe the twofold relation with wireless communications. Finally, integrated solutions performing joint communications and SLAM are still in their infancy: theoretical and practical advancements are required to add higher-level localization and semantic perception capabilities to RF and multi-antenna technologies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07321", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07321", "abs": "https://arxiv.org/abs/2602.07321", "authors": ["Changyuan Zhao", "Jiacheng Wang", "Yunting Xu", "Geng Sun", "Dusit Niyato", "Zan Li", "Abbas Jamalipour", "Dong In Kim"], "title": "Wireless Context Engineering for Efficient Mobile Agentic AI and Edge General Intelligence", "comment": "7 pages, 4 figures", "summary": "Future wireless networks demand increasingly powerful intelligence to support sensing, communication, and autonomous decision-making. While scaling laws suggest improving performance by enlarging model capacity, practical edge deployments are fundamentally constrained by latency, energy, and memory, making unlimited model scaling infeasible. This creates a critical need to maximize the utility of limited inference-time inputs by filtering redundant observations and focusing on high-impact data. In large language models and generative artificial intelligence (AI), context engineering has emerged as a key paradigm to guide inference by selectively structuring and injecting task-relevant information. Inspired by this success, we extend context engineering to wireless systems, providing a systematic way to enhance edge AI performance without increasing model complexity. In dynamic environments, for example, beam prediction can benefit from augmenting instantaneous channel measurements with contextual cues such as user mobility trends or environment-aware propagation priors. We formally introduce wireless context engineering and propose a Wireless Context Communication Framework (WCCF) to adaptively orchestrate wireless context under inference-time constraints. This work provides researchers with a foundational perspective and practical design dimensions to manage the wireless context of wireless edge intelligence. An ISAC-enabled beam prediction case study illustrates the effectiveness of the proposed paradigm under constrained sensing budgets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08120", "categories": ["quant-ph", "math.NA", "q-fin.MF", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.08120", "abs": "https://arxiv.org/abs/2602.08120", "authors": ["Yihang Sun", "Guanyang Wang", "Jose Blanchet"], "title": "Optimal Quantum Speedups for Repeatedly Nested Expectation Estimation", "comment": null, "summary": "We study the estimation of repeatedly nested expectations (RNEs) with a constant horizon (number of nestings) using quantum computing. We propose a quantum algorithm that achieves $\\varepsilon$-error with cost $\\tilde O(\\varepsilon^{-1})$, up to logarithmic factors. Standard lower bounds show this scaling is essentially optimal, yielding an almost quadratic speedup over the best classical algorithm. Our results extend prior quantum speedups for single nested expectations to repeated nesting, and therefore cover a broader range of applications, including optimal stopping. This extension requires a new derandomized variant of the classical randomized Multilevel Monte Carlo (rMLMC) algorithm. Careful de-randomization is key to overcoming a variable-time issue that typically increases quantized versions of classical randomized algorithms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08938", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08938", "abs": "https://arxiv.org/abs/2602.08938", "authors": ["Tuo Zhang", "Leonardo Stella"], "title": "Teaching an Old Dynamics New Tricks: Regularization-free Last-iterate Convergence in Zero-sum Games via BNN Dynamics", "comment": null, "summary": "Zero-sum games are a fundamental setting for adversarial training and decision-making in multi-agent learning (MAL). Existing methods often ensure convergence to (approximate) Nash equilibria by introducing a form of regularization. Yet, regularization requires additional hyperparameters, which must be carefully tuned--a challenging task when the payoff structure is known, and considerably harder when the structure is unknown or subject to change. Motivated by this problem, we repurpose a classical model in evolutionary game theory, i.e., the Brown-von Neumann-Nash (BNN) dynamics, by leveraging the intrinsic convergence of this dynamics in zero-sum games without regularization, and provide last-iterate convergence guarantees in noisy normal-form games (NFGs). Importantly, to make this approach more applicable, we develop a novel framework with theoretical guarantees that integrates the BNN dynamics in extensive-form games (EFGs) through counterfactual weighting. Furthermore, we implement an algorithm that instantiates our framework with neural function approximation, enabling scalable learning in both NFGs and EFGs. Empirical results show that our method quickly adapts to nonstationarities, outperforming the state-of-the-art regularization-based approach.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07198", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07198", "abs": "https://arxiv.org/abs/2602.07198", "authors": ["Heyuan Li", "Huimin Zhang", "Yuda Qiu", "Zhengwentai Sun", "Keru Zheng", "Lingteng Qiu", "Peihao Li", "Qi Zuo", "Ce Chen", "Yujian Zheng", "Yuming Gu", "Zilong Dong", "Xiaoguang Han"], "title": "Condition Matters in Full-head 3D GANs", "comment": "Accepted by ICLR 2026. Project page: https://lhyfst.github.io/balancehead/", "summary": "Conditioning is crucial for stable training of full-head 3D GANs. Without any conditioning signal, the model suffers from severe mode collapse, making it impractical to training. However, a series of previous full-head 3D GANs conventionally choose the view angle as the conditioning input, which leads to a bias in the learned 3D full-head space along the conditional view direction. This is evident in the significant differences in generation quality and diversity between the conditional view and non-conditional views of the generated 3D heads, resulting in global incoherence across different head regions. In this work, we propose to use view-invariant semantic feature as the conditioning input, thereby decoupling the generative capability of 3D heads from the viewing direction. To construct a view-invariant semantic condition for each training image, we create a novel synthesized head image dataset. We leverage FLUX.1 Kontext to extend existing high-quality frontal face datasets to a wide range of view angles. The image clip feature extracted from the frontal view is then used as a shared semantic condition across all views in the extended images, ensuring semantic alignment while eliminating directional bias. This also allows supervision from different views of the same subject to be consolidated under a shared semantic condition, which accelerates training and enhances the global coherence of the generated 3D heads. Moreover, as GANs often experience slower improvements in diversity once the generator learns a few modes that successfully fool the discriminator, our semantic conditioning encourages the generator to follow the true semantic distribution, thereby promoting continuous learning and diverse generation. Extensive experiments on full-head synthesis and single-view GAN inversion demonstrate that our method achieves significantly higher fidelity, diversity, and generalizability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07593", "categories": ["cs.LG", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07593", "abs": "https://arxiv.org/abs/2602.07593", "authors": ["Polina Gordienko", "Christoph Jansen", "Julian Rodemann", "Georg Schollmeyer"], "title": "Beyond Arrow: From Impossibility to Possibilities in Multi-Criteria Benchmarking", "comment": null, "summary": "Modern benchmarks such as HELM MMLU account for multiple metrics like accuracy, robustness and efficiency. When trying to turn these metrics into a single ranking, natural aggregation procedures can become incoherent or unstable to changes in the model set. We formalize this aggregation as a social choice problem where each metric induces a preference ranking over models on each dataset, and a benchmark operator aggregates these votes across metrics. While prior work has focused on Arrow's impossibility result, we argue that the impossibility often originates from pathological examples and identify sufficient conditions under which these disappear, and meaningful multi-criteria benchmarking becomes possible. In particular, we deal with three restrictions on the combinations of rankings and prove that on single-peaked, group-separable and distance-restricted preferences, the benchmark operator allows for the construction of well-behaved rankings of the involved models. Empirically, we investigate several modern benchmark suites like HELM MMLU and verify which structural conditions are fulfilled on which benchmark problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08003", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08003", "abs": "https://arxiv.org/abs/2602.08003", "authors": ["Yigit Turkmen", "Baturalp Buyukates", "Melih Bastopcu"], "title": "Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection", "comment": null, "summary": "Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even with many models, we model the correlated errors of the models using Gaussian-copula and show an information-theoretic error floor for the performance of the ensemble. Motivated by these, we propose a simple greedy mutual-information selection algorithm that estimates the required information terms directly from data and iteratively builds an ensemble under a query budget. We test our approach in two question answering datasets and one binary sentiment classification dataset: MEDMCQA, MMLU, and IMDB movie reviews. Across all datasets, we observe that our method consistently outperforms strong baselines under the same query budget.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07876", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07876", "abs": "https://arxiv.org/abs/2602.07876", "authors": ["Hongzhao Zheng", "Mohamed Atia", "Halim Yanikomeroglu"], "title": "Optimized Deployment of HAPS Systems for GNSS Localization Enhancement in Urban Environments", "comment": null, "summary": "While high altitude platform stations (HAPS) have been primarily explored as network infrastructure for communication services, their advantageous characteristics also make them promising candidates for augmenting GNSS localization. This paper proposes a metaheuristic framework to jointly optimize the number and placement of HAPS for GNSS enhancement in dense urban environments, considering practical constraints such as elevation masks, altitude limits, and ray-traced visibility from 3D city models. The problem is highly nonconvex due to the discrete HAPS count and the environment-dependent 3D Cramer-Rao lower bound (CRLB). To address this, we develop a tailored version of the adaptive special-crowding distance non-dominated sorting genetic algorithm II (ASDNSGA-II). Simulations show the method successfully identifies the minimum number of HAPS needed to satisfy a CRLB threshold and selects the configuration with the lowest CRLB within that minimum, offering a cost-effective and scalable solution for future HAPS-aided positioning systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08473", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2602.08473", "abs": "https://arxiv.org/abs/2602.08473", "authors": ["Moran Feldman", "Justin Ward"], "title": "Submodular Maximization over a Matroid $k$-Intersection: Multiplicative Improvement over Greedy", "comment": "31 pages, 1 figure", "summary": "We study the problem of maximizing a non-negative monotone submodular objective $f$ subject to the intersection of $k$ arbitrary matroid constraints. The natural greedy algorithm guarantees $(k+1)$-approximation for this problem, and the state-of-the-art algorithm only improves this approximation ratio to $k$. We give a $\\frac{2k\\ln2}{1+\\ln2}+O(\\sqrt{k})<0.819k+O(\\sqrt{k})$ approximation for this problem. Our result is the first multiplicative improvement over the approximation ratio of the greedy algorithm for general $k$. We further show that our algorithm can be used to obtain roughly the same approximation ratio also for the more general problem in which the objective is not guaranteed to be monotone (the sublinear term in the approximation ratio becomes $O(k^{2/3})$ rather than $O(\\sqrt{k})$ in this case).\n  All of our results hold also when the $k$-matroid intersection constraint is replaced with a more general matroid $k$-parity constraint. Furthermore, unlike the case in many of the previous works, our algorithms run in time that is independent of $k$ and polynomial in the size of the ground set. Our algorithms are based on a hybrid greedy local search approach recently introduced by Singer and Thiery (STOC 2025) for the weighted matroid $k$-intersection problem, which is a special case of the problem we consider. Leveraging their approach in the submodular setting requires several non-trivial insights and algorithmic modifications since the marginals of a submodular function $f$, which correspond to the weights in the weighted case, are not independent of the algorithm's internal randomness. In the special weighted case studied by Singer and Thiery, our algorithms reduce to a variant of their algorithm with an improved approximation ratio of $k\\ln2+1-\\ln2<0.694k+0.307$, compared to an approximation ratio of $\\frac{k+1}{2\\ln2}\\approx0.722k+0.722$ guaranteed by Singer and Thiery.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08619", "categories": ["cs.NE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08619", "abs": "https://arxiv.org/abs/2602.08619", "authors": ["Laura-Maria Cornei", "Mihaela-Elena Breab\u0103n"], "title": "Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study", "comment": "Paper accepted to the International Conference on Applications of Evolutionary Computation (EvoApplications) 2026", "summary": "This paper investigates the impact of hybridizing a multi-modal Genetic Algorithm with a Graph Neural Network for timetabling optimization. The Graph Neural Network is designed to encapsulate general domain knowledge to improve schedule quality, while the Genetic Algorithm explores different regions of the search space and integrates the deep learning model as an enhancement operator to guide the solution search towards optimality. Initially, both components of the hybrid technique were designed, developed, and optimized independently to solve the tackled task. Multiple experiments were conducted on Staff Rostering, a well-known timetabling problem, to compare the proposed hybridization with the standalone optimized versions of the Genetic Algorithm and Graph Neural Network. The experimental results demonstrate that the proposed hybridization brings statistically significant improvements in both the time efficiency and solution quality metrics, compared to the standalone methods. To the best of our knowledge, this work proposes the first hybridization of a Genetic Algorithm with a Graph Neural Network for solving timetabling problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08468", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08468", "abs": "https://arxiv.org/abs/2602.08468", "authors": ["Tomer Alkalai", "Emily Hajigeorgiou", "Adbhut Gupta", "Tapas Senapati", "Priya Tiwari", "Chia-Tse Tai", "Siddharth Kumar Singh", "Kirk W. Baldwin", "Loren N. Pfeiffer", "Mansour Shayegan", "Mitali Banerjee", "Moty Heiblum"], "title": "Observation of e/4 charge at $\u03bd=1/2$ in GaAs", "comment": "13+8 pages, 3+4 figures", "summary": "Even-denominator fractional quantum Hall states (FQHSs) fall outside the standard Laughlin's and Jain's odd-denominator hierarchy. In this work, we study the FQHS $\u03bd=1/2$ in the lowest Landau level. The state is confined within a 70 nm-wide GaAs quantum well, where the electrons exhibit a bilayer-like charge distribution. Inter-layer interactions stabilize the $\u03bd=1/2$ FQHS, which is predicted to host quasiparticles with charge e/4 - with either Abelian or non-Abelian topological order. Here, we report on shot-noise measurements of partitioned quasiparticles at $\u03bd=1/2$, where charge partitioning is generated by a unique etch-defined quantum point contact. Our measurements were performed on two nominally identical devices, at two independent experimental setups. Analysis of shot noise in the weak-backscattering regime in each device reveals quasiparticles with charge e/4. These observations provide a clear benchmark for future studies aimed at probing the topological order of the $\u03bd=1/2$ FQHS and its quasiparticles' exchange statistics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07211", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.07211", "abs": "https://arxiv.org/abs/2602.07211", "authors": ["Ju Lin", "Jing Pan", "Ruizhi Li", "Ming Sun", "Yuzong Liu", "Alaa Hassan", "Jing Zheng", "Florian Metze"], "title": "Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities", "comment": null, "summary": "Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07424", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07424", "abs": "https://arxiv.org/abs/2602.07424", "authors": ["Kaijian Xing", "Zherui Yang", "Weiyao Zhao", "Yuefeng Yin", "Huiping Han", "Shanhu Wang", "Shifan Wang", "James Bullock", "Alastair Stacey", "James A. Belcourt", "Sergey Rubanov", "Hang Yin", "David A. Broadway", "Jean-Philippe Tetienne", "Xinmao Yin", "Liang Wu", "Dong-Chen Qi", "Michael S. Fuhrer", "Qingdong Ou", "Xiao Renshaw Wang"], "title": "Efficient and Robust p-type Transistor based on Ultra-wide-bandgap Semiconductor", "comment": "21 pages, 5 figures", "summary": "The p-type transistor is an indispensable component of semiconductor technology, enabling complementary operation with n-channel transistors for computation, storage, and communication. Achieving both high robustness and high efficiency is highly desirable but challenging for p-type transistors due to limited semiconductors with reliable hole transport and their high activation energies. Here, we achieved a robust yet efficient p-type transistor by heterogeneously integrating an ultra-wide-bandgap semiconductor and a high-k dielectric layer through van der Waals integration. The p-type transistor employs a two-dimensional hole channel on hydrogenated diamond (bandgap 5.6 eV) combined with a high-k (30.5) SrTiO3 perovskite membrane. At room temperature, the transistor exhibits stable operation with a high on-current (~200 mA/mm), low subthreshold swing (70 mV/dec), high hole mobility (566 cm^2/Vs to 572 cm^2/Vs) and high on-off ratio (~10^9). Furthermore, tuning annealing temperature allows operation in either enhancement or depletion mode. The robust p-type transistor with high efficiency holds great potential for future power electronics, UV optoelectronics, and harsh-environment electronic applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08052", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08052", "abs": "https://arxiv.org/abs/2602.08052", "authors": ["Bulent Soykan", "Sean Mondesire", "Ghaith Rabadi", "Grace Bochenek"], "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling", "comment": "11 pages, 2 figures, Winter Simulation Conference (WSC) 2025", "summary": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08772", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.08772", "abs": "https://arxiv.org/abs/2602.08772", "authors": ["Kuan-Cheng Chen", "Yongqiang Wen", "Xiaotian Xu", "Max Attwood", "Jingdong Xu", "Chen Fu", "Sami Ramadan", "Shang Yu", "Sandrine Heutz", "Mark Oxborrow"], "title": "Heterogeneous Optically-Detected Spin-Acoustic Resonance in Solid-State Molecular Thin-film", "comment": null, "summary": "We report an implementation of spin-acoustic resonance in pentacene thin films integrated on a high-quality-factor (high-Q) surface acoustic wave (SAW) resonator on a lithium niobate substrate. Heterogeneous optically detected spin-acoustic resonance (HODSAR) is an optically detected spin-resonance measurement in which the resonant drive is delivered mechanically by a surface acoustic wave (SAW). By leveraging the photo-excited triplet state of pentacene at room temperature, we demonstrate coherent spin manipulation via acoustic driving under zero externally applied magnetic field. The heterogeneously integrated device, referred to as HODSAR, utilizes spin-phonon coupling to achieve mechanically driven, zero-field spin resonance, opening avenues for room-temperature mechanically addressable spin control and device integration. We show that the high-Q multimode response of the SAW resonator enables spectrally selective acoustic addressing of triplet transitions near 105 MHz. Coherent control is evidenced by Rabi oscillations, with a Rabi frequency that increases linearly with the square root of the applied RF input power over the measured drive range, consistent with driven two-level dynamics under acoustic excitation. These results establish spin-acoustic resonance in a heterogeneously integrated molecular thin-film platform and provide a quantitative basis for benchmarking mechanically mediated spin control.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07005", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07005", "abs": "https://arxiv.org/abs/2602.07005", "authors": ["Shifa Sulaiman", "Tobias Jensen", "Francesco Schetter", "Simon B\u00f8gh"], "title": "Admittance-Based Motion Planning with Vision-Guided Initialization for Robotic Manipulators in Self-Driving Laboratories", "comment": null, "summary": "Self driving laboratories (SDLs) are highly automated research environments that leverage advanced technologies to conduct experiments and analyze data with minimal human involvement. These environments often involve delicate laboratory equipment, unpredictable environmental interactions, and occasional human intervention, making compliant and force aware control essential for ensuring safety, adaptability, and reliability. This paper introduces a motion-planning framework centered on admittance control to enable adaptive and compliant robotic manipulation. Unlike conventional schemes, the proposed approach integrates an admittance controller directly into trajectory execution, allowing the manipulator to dynamically respond to external forces during interaction. This capability enables human operators to override or redirect the robot's motion in real time. A vision algorithm based on structured planar pose estimation is employed to detect and localize textured planar objects through feature extraction, homography estimation, and depth fusion, thereby providing an initial target configuration for motion planning. The vision based initialization establishes the reference trajectory, while the embedded admittance controller ensures that trajectory execution remains safe, adaptive, and responsive to external forces or human intervention. The proposed strategy is validated using textured image detection as a proof of concept. Future work will extend the framework to SDL environments involving transparent laboratory objects where compliant motion planning can further enhance autonomy, safety, and human-robot collaboration.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07350", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07350", "abs": "https://arxiv.org/abs/2602.07350", "authors": ["Kecheng Zhang", "Weijie Yuan", "Yonghui Li"], "title": "Pulse Shaping Filter Design for Zak-OTFS", "comment": "Submitted to IEEE for possible publication", "summary": "The Zak-transform-based Orthogonal Time Frequency Space (Zak-OTFS), offers a robust framework for high-mobility communications by simplifying the input-output (I/O) relation to a twisted convolution. While this structure theoretically enables accurate channel estimation by sampling the response from one pilot symbol, practical implementation is constrained by the spreading of effective channel response induced by pulse shaping filters. To address this, we first derive the I/O relationship for discrete-time oversampled Zak-OTFS, which closely approximates the continuous-time system and facilitates analysis and numerical simulation. We show that every delay-Doppler domain symbol undergoes the same effective channel response under the discrete oversampled Zak-OTFS. We then analyze the impact of window ambiguity functions, and reveal that high sidelobes lead to wide channel spreading and degrade estimation accuracy. Building on this insight, we propose a novel pulse shaping filter design that synthesizes Prolate Spheroidal Wave Functions (PSWFs) within the Isotropic Orthogonal Transform Algorithm (IOTA) framework. Numerical simulations confirm that the proposed design achieves superior channel estimation accuracy and bit error rate (BER) performance compared to conventional root-raised-cosine and rectangular windowing schemes in the high-SNR regime.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08419", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08419", "abs": "https://arxiv.org/abs/2602.08419", "authors": ["Gnankan Landry Regis N'guessan", "Bum Jun Kim"], "title": "Radial M\u00fcntz-Sz\u00e1sz Networks: Neural Architectures with Learnable Power Bases for Multidimensional Singularities", "comment": "47 pages, 13 figures", "summary": "Radial singular fields, such as $1/r$, $\\log r$, and crack-tip profiles, are difficult to model for coordinate-separable neural architectures. We show that any $C^2$ function that is both radial and additively separable must be quadratic, establishing a fundamental obstruction for coordinate-wise power-law models. Motivated by this result, we introduce Radial M\u00fcntz-Sz\u00e1sz Networks (RMN), which represent fields as linear combinations of learnable radial powers $r^\u03bc$, including negative exponents, together with a limit-stable log-primitive for exact $\\log r$ behavior. RMN admits closed-form spatial gradients and Laplacians, enabling physics-informed learning on punctured domains. Across ten 2D and 3D benchmarks, RMN achieves 1.5$\\times$--51$\\times$ lower RMSE than MLPs and 10$\\times$--100$\\times$ lower RMSE than SIREN while using 27 parameters, compared with 33,537 for MLPs and 8,577 for SIREN. We extend RMN to angular dependence (RMN-Angular) and to multiple sources with learnable centers (RMN-MC); when optimization converges, source-center recovery errors fall below $10^{-4}$. We also report controlled failures on smooth, strongly non-radial targets to delineate RMN's operating regime.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08965", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08965", "abs": "https://arxiv.org/abs/2602.08965", "authors": ["John Gardiner", "Orlando Romero", "Brendan Tivnan", "Nicol\u00f2 Dal Fabbro", "George J. Pappas"], "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning", "comment": null, "summary": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07243", "categories": ["cs.RO", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07243", "abs": "https://arxiv.org/abs/2602.07243", "authors": ["Siddharth Singh", "Ifrah Idrees", "Abraham Dauhajre"], "title": "Realistic Synthetic Household Data Generation at Scale", "comment": "Accepted at Agentic AI Benchmarks and Applications for Enterprise Tasks workshop at AAAI 2026", "summary": "Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthetic data for long-term human-robot interactions but fail to model the bidirectional influence between human behavior and household environments. Our proposed generative framework creates household datasets at scale through loosely coupled generation of long-term human-robot interactions and environments. Human personas influence environment generation, while environment schematics and semantics shape human-robot interactions.\n  The generated 3D data includes rich static context such as object and environment semantics, and temporal context capturing human and agent behaviors over extended periods. Our flexible tool allows users to define dataset characteristics via natural language prompts, enabling configuration of environment and human activity data through natural language specifications. The tool creates variations of user-defined configurations, enabling scalable data generation.\n  We validate our framework through statistical evaluation using multi-modal embeddings and key metrics: cosine similarity, mutual information gain, intervention analysis, and iterative improvement validation. Statistical comparisons show good alignment with real-world datasets (HOMER) with cosine similarity (0.60), while synthetic datasets (Wang et al.) show moderate alignment (0.27). Intervention analysis across age, organization, and sleep pattern changes shows statistically significant effects (p < 0.001) with large effect sizes (Cohen's d = 0.51-1.12), confirming bidirectional coupling translates persona traits into measurable environmental and behavioral differences. These contributions enable development and testing of household smart devices at scale.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07921", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07921", "abs": "https://arxiv.org/abs/2602.07921", "authors": ["Najiya Fatma", "Varun Ramamohan"], "title": "Healthcare Facility Assignment Using Real-Time Length-of-Stay Predictions: Queuing-Theoretic and Simulation-driven Machine Learning Approaches", "comment": null, "summary": "Longer stays at healthcare facilities, driven by uncertain patient load, inefficient patient flow, and lack of real-time information about medical care, pose significant challenges for patients and healthcare providers. Providing patients with estimates of their expected real-time length of stay (RT-LOS), generated as a function of the operational state of the healthcare facility at their anticipated time of arrival (as opposed to estimates of average LOS), can help them make informed decisions regarding which facility to visit within a network. In this study, we develop a healthcare facility assignment (HFA) algorithm that assigns healthcare facilities to patients using RT-LOS predictions at facilities within the network of interest. We describe the generation of RT-LOS predictions via two methodologies: (a) an analytical queuing-theoretic approach, and (b) a hybrid simulation-driven machine learning approach. Because RT-LOS predictors are highly specific to the queuing system in question, we illustrate the development of RT-LOS predictors using both approaches by considering the outpatient experience at primary health centers. Via computational experiments, we compare outcomes from the implementation of the RT-HFA algorithm with both RT-LOS predictors to the case where patients visit the facility of their choice. Computational experiments also indicated that the RT-HFA algorithm substantially reduced patient wait times and LOS at congested facilities and led to more equitable utilization of medical resources at facilities across the network. Finally, we show numerically that the effectiveness of the RT-HFA algorithm in improving outcomes is contingent on the level of compliance with the assignment decision.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08542", "categories": ["cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08542", "abs": "https://arxiv.org/abs/2602.08542", "authors": ["Emilio Cruciani", "Sebastian Forster", "Antonis Skarlatos"], "title": "Incremental (k, z)-Clustering on Graphs", "comment": "Abstract shortened to meet arXiv limits", "summary": "Given a weighted undirected graph, a number of clusters $k$, and an exponent $z$, the goal in the $(k, z)$-clustering problem on graphs is to select $k$ vertices as centers that minimize the sum of the distances raised to the power $z$ of each vertex to its closest center. In the dynamic setting, the graph is subject to adversarial edge updates, and the goal is to maintain explicitly an exact $(k, z)$-clustering solution in the induced shortest-path metric.\n  While efficient dynamic $k$-center approximation algorithms on graphs exist [Cruciani et al. SODA 2024], to the best of our knowledge, no prior work provides similar results for the dynamic $(k,z)$-clustering problem. As the main result of this paper, we develop a randomized incremental $(k, z)$-clustering algorithm that maintains with high probability a constant-factor approximation in a graph undergoing edge insertions with a total update time of $\\tilde O(k m^{1+o(1)}+ k^{1+\\frac{1}\u03bb} m)$, where $\u03bb\\geq 1$ is an arbitrary fixed constant. Our incremental algorithm consists of two stages. In the first stage, we maintain a constant-factor bicriteria approximate solution of size $\\tilde{O}(k)$ with a total update time of $m^{1+o(1)}$ over all adversarial edge insertions. This first stage is an intricate adaptation of the bicriteria approximation algorithm by Mettu and Plaxton [Machine Learning 2004] to incremental graphs. One of our key technical results is that the radii in their algorithm can be assumed to be non-decreasing while the approximation ratio remains constant, a property that may be of independent interest.\n  In the second stage, we maintain a constant-factor approximate $(k,z)$-clustering solution on a dynamic weighted instance induced by the bicriteria approximate solution. For this subproblem, we employ a dynamic spanner algorithm together with a static $(k,z)$-clustering algorithm.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08825", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.08825", "abs": "https://arxiv.org/abs/2602.08825", "authors": ["Tomohiro Harada", "Enrique Alba", "Gabriel Luque"], "title": "A Methodology for Effective Surrogate Learning in Complex Optimization", "comment": null, "summary": "Solving complex problems requires continuous effort in developing theory and practice to cope with larger, more difficult scenarios. Working with surrogates is normal for creating a proxy that realistically models the problem into the computer. Thus, the question of how to best define and characterize such a surrogate model is of the utmost importance. In this paper, we introduce the PTME methodology to study deep learning surrogates by analyzing their Precision, Time, Memory, and Energy consumption. We argue that only a combination of numerical and physical performance can lead to a surrogate that is both a trusted scientific substitute for the real problem and an efficient experimental artifact for scalable studies. Here, we propose different surrogates for a real problem in optimally organizing the network of traffic lights in European cities and perform a PTME study on the surrogates' sampling methods, dataset sizes, and resource consumption. We further use the built surrogates in new optimization metaheuristics for decision-making in real cities. We offer better techniques and conclude that the PTME methodology can be used as a guideline for other applications and solvers.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08587", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08587", "abs": "https://arxiv.org/abs/2602.08587", "authors": ["J. Chen", "H. Yu", "R. Gallardo", "P. Landeros", "G. Gubbiotti"], "title": "Magnon confinement and trapping at the nanoscale", "comment": "125 pages, 55 figures", "summary": "Magnon confinement and trapping refer to the localization of magnons-quasiparticles that represent collective spin-wave excitations in magnetic materials-within specific regions or structures. This concept is essential in magnonics, a subfield of spintronics that leverages spin waves for processing and transmitting information. Compared to conventional electronics, magnonics offers lower power consumption and faster operation, making it a promising technology for future devices. Magnons can be confined using both static and dynamic methods, often relying on potential wells and barriers to restrict their free propagation and trap them in designated locations. In this review, we will explore the main strategies for magnon confinement and trapping, including: magnetic field inhomogeneities, spin textures (i.e. domain walls, vortices, skyrmions) nanostructured materials (i.e. nanowires, disks, and magnonic crystals), topological states, chiral magnons and flat band formation, induced by dipole-dipole interactions and Dzyaloshinskii-Moriya interaction. Microwave cavities and resonant magnetic fields, as well as spin-torque effects and Bose-Einstein condensation contribute to magnon localization. Furthermore, spin-wave edge and cavity modes have been observed in two-dimensional magnetic materials and twisted moir\u00e9 superlattices at a specific twist angle. Magnon trapping has broad applications in computing and data processing, particularly in the development of magnonic crystals, waveguides, and memory elements. Additionally, magnon systems are being explored for quantum computing, where confinement can enhance the coupling between magnons and other quasiparticles in hybrid quantum systems. Precision control of magnons could lead to next-generation spintronic devices, offering improved efficiency and scalability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07319", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07319", "abs": "https://arxiv.org/abs/2602.07319", "authors": ["Savan Doshi"], "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice", "comment": null, "summary": "Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07427", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.07427", "abs": "https://arxiv.org/abs/2602.07427", "authors": ["Pan Min", "Wang Yujie", "Hu Kaige", "Deng Huiqiu"], "title": "First-principles study on the high-$T_\\text{c}$ superconductivity of Mg-Ti-H ternary hydrides up to the liquid-nitrogen temperature range under high pressures", "comment": "19 pages, 13 figures, 2 tables", "summary": "Ternary hydrides have emerged as the primary focus of the new wave of research into superconducting hydrides. In this work, Mg-Ti-H ternary hydrides are explored under high pressures up to 300 GPa using the prediction method of the particle swarm optimization algorithm combined with first-principles calculations. Two new structures, $P4/nmm$-MgTiH$_6$ and $Pmm2$-Mg$_3$TiH$_6$, are identified to be thermodynamically stable at both 200 GPa and 300 GPa. Thermodynamically stable structures of Mg$_3$TiH$_{12}$ are also identified, whose space groups are $R3/m$ at 200 GPa and $Pm\\bar{3}m$ at 300 GPa, respectively. Among these Mg-Ti-H structures, $P4/nmm$-MgTiH$_6$ achieves a record-high $T_\\text{c}$ of 81.9 K at 170 GPa, exceeding the boiling point of liquid nitrogen. Such a high $T_\\text{c}$ is primarily attributed to strong electron-phonon coupling (EPC) driven by low-frequency acoustic phonon modes, with the EPC strength reaching a large value of 1.54. The $T_\\text{c}$ of $Pm\\bar{3}m$-Mg$_3$TiH$_{12}$ is predicted to be 40 K at 300 GPa. Furthermore, element substitution of Zr(Hf) for Ti achieves considerable enhancement of superconducting properties in our predicted hydrogen-rich and high-symmetric crystal structures, i.e., $P4/nmm$-MgTiH$_6$ and $Pm\\bar{3}m$-Mg$_3$TiH$_{12}$. The high pressure required for dynamical stability is lowered to 100 GPa in both $Pm\\bar{3}m$-Mg$_3$ZrH$_{12}$ and $Pm\\bar{3}m$-Mg$_3$HfH$_{12}$, and to 90 GPa and 120 GPa for $P4/nmm$-MgZrH$_6$ and $P4/nmm$-MgHfH$_6$, respectively. Particularly, the electronic structure near the Fermi level is significantly modified in the $P4/nmm$-MgHfH$_6$ phase, and pronounced softening of low-frequency acoustic phonon modes occurs. As a result, the EPC strength is enhanced to 1.72, leading to a higher $T_\\text{c}$ of 86 K.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08092", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08092", "abs": "https://arxiv.org/abs/2602.08092", "authors": ["Majid Ghasemi", "Mark Crowley"], "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities", "comment": null, "summary": "Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this \"judging the judges\" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08854", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.08854", "abs": "https://arxiv.org/abs/2602.08854", "authors": ["Danial Shafizadeh", "Misagh Ghezellou", "Viktor M. Bobal", "Lasse Vines", "Jawad Ul-Hassan", "Valdas Jokubavicius", "Nguyen T. Son", "Ivan G. Ivanov"], "title": "Spin-active chlorine-related centers in 4H-SiC with telecom-band emissions", "comment": null, "summary": "A photoluminescence (PL) and magnetic resonance investigation of a defect in chlorine-implanted 4H-SiC is presented. This Cl-related center emits light at telecom wavelengths with zero-phonon lines in the range 1350-1540 nm. Its four configurations exhibit stable PL spectra characterized by narrow zero-phonon lines. For the two configurations that emit light at the C-band, a Debye-Waller factor in the range 22-25% is estimated. Optically detected magnetic resonance confirms that the Cl-related center is spin active and stable at room temperature with the zero-field splitting in the range of 1.0-1.4 GHz. The combined optical and spin properties suggest this center to be a highly promising candidate for scalable quantum networks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07007", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07007", "abs": "https://arxiv.org/abs/2602.07007", "authors": ["Dongsheng Chen", "Yuxuan Li", "Yi Lin", "Guanhua Chen", "Jiaxin Zhang", "Xiangyu Zhao", "Lei Ma", "Xin Yao", "Xuetao Wei"], "title": "ARGOS: Automated Functional Safety Requirement Synthesis for Embodied AI via Attribute-Guided Combinatorial Reasoning", "comment": null, "summary": "Ensuring functional safety is essential for the deployment of Embodied AI in complex open-world environments. However, traditional Hazard Analysis and Risk Assessment (HARA) methods struggle to scale in this domain. While HARA relies on enumerating risks for finite and pre-defined function lists, Embodied AI operates on open-ended natural language instructions, creating a challenge of combinatorial interaction risks. Whereas Large Language Models (LLMs) have emerged as a promising solution to this scalability challenge, they often lack physical grounding, yielding semantically superficial and incoherent hazard descriptions. To overcome these limitations, we propose a new framework ARGOS (AttRibute-Guided cOmbinatorial reaSoning), which bridges the gap between open-ended user instructions and concrete physical attributes. By dynamically decomposing entities from instructions into these fine-grained properties, ARGOS grounds LLM reasoning in causal risk factors to generate physically plausible hazard scenarios. It then instantiates abstract safety standards, such as ISO 13482, into context-specific Functional Safety Requirements (FSRs) by integrating these scenarios with robot capabilities. Extensive experiments validate that ARGOS produces high-quality FSRs and outperforms baselines in identifying long-tail risks. Overall, this work paves the way for systematic and grounded functional safety requirement generation, a critical step toward the safe industrial deployment of Embodied AI.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07365", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07365", "abs": "https://arxiv.org/abs/2602.07365", "authors": ["Xiaohan Lv", "Rang Liu", "Yi Chen", "Qian Liu", "Ming Li"], "title": "Message Passing based Parameter Estimation in Cooperative MIMO-OFDM ISAC Systems", "comment": null, "summary": "In integrated sensing and communication (ISAC) networks, multiple base stations (BSs) collaboratively sense a common target, leveraging diversity from multiple observation perspectives and joint signal processing to enhance sensing performance. This paper introduces a novel message-passing (MP)-based parameter estimation framework for collaborative MIMO-OFDM ISAC systems, which jointly estimates the target's position and velocity. First, a signal propagation model is established based on geometric relationships, and a factor graph is constructed to represent the unknown parameters. The sum-product algorithm (SPA) is then applied to this factor graph to jointly estimate the multi-dimensional parameter vector. To reduce communication overhead and computational complexity, we employ a hierarchical message-passing scheme with Gaussian approximation. By adopting parameterized message distributions and layered processing, the proposed method significantly reduces both computational complexity and inter-BS communication overhead. Simulation results demonstrate the effectiveness of the proposed MP-based parameter estimation algorithm and highlight the benefits of multi-perspective observations and joint signal processing for cooperative sensing in MIMO-OFDM ISAC systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08478", "categories": ["cs.LG", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08478", "abs": "https://arxiv.org/abs/2602.08478", "authors": ["Albert Alcalde", "Markus Widhalm", "Emre Y\u0131lmaz"], "title": "Time-Delayed Transformers for Data-Driven Modeling of Low-Dimensional Dynamics", "comment": null, "summary": "We propose the time-delayed transformer (TD-TF), a simplified transformer architecture for data-driven modeling of unsteady spatio-temporal dynamics. TD-TF bridges linear operator-based methods and deep sequence models by showing that a single-layer, single-head transformer can be interpreted as a nonlinear generalization of time-delayed dynamic mode decomposition (TD-DMD). The architecture is deliberately minimal, consisting of one self-attention layer with a single query per prediction and one feedforward layer, resulting in linear computational complexity in sequence length and a small parameter count. Numerical experiments demonstrate that TD-TF matches the performance of strong linear baselines on near-linear systems, while significantly outperforming them in nonlinear and chaotic regimes, where it accurately captures long-term dynamics. Validation studies on synthetic signals, unsteady aerodynamics, the Lorenz '63 system, and a reaction-diffusion model show that TD-TF preserves the interpretability and efficiency of linear models while providing substantially enhanced expressive power for complex dynamics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07272", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07272", "abs": "https://arxiv.org/abs/2602.07272", "authors": ["Bowen Xue", "Saeed Hadadan", "Zheng Zeng", "Fabrice Rousselle", "Zahra Montazeri", "Milos Hasan"], "title": "VideoNeuMat: Neural Material Extraction from Generative Video Models", "comment": null, "summary": "Creating photorealistic materials for 3D rendering requires exceptional artistic skill. Generative models for materials could help, but are currently limited by the lack of high-quality training data. While recent video generative models effortlessly produce realistic material appearances, this knowledge remains entangled with geometry and lighting. We present VideoNeuMat, a two-stage pipeline that extracts reusable neural material assets from video diffusion models. First, we finetune a large video model (Wan 2.1 14B) to generate material sample videos under controlled camera and lighting trajectories, effectively creating a \"virtual gonioreflectometer\" that preserves the model's material realism while learning a structured measurement pattern. Second, we reconstruct compact neural materials from these videos through a Large Reconstruction Model (LRM) finetuned from a smaller Wan 1.3B video backbone. From 17 generated video frames, our LRM performs single-pass inference to predict neural material parameters that generalize to novel viewing and lighting conditions. The resulting materials exhibit realism and diversity far exceeding the limited synthetic training data, demonstrating that material knowledge can be successfully transferred from internet-scale video models into standalone, reusable neural 3D assets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08261", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.08261", "abs": "https://arxiv.org/abs/2602.08261", "authors": ["Binglin Wu", "Yingyi Zhang", "Xianneng Li", "Ruyue Deng", "Chuan Yue", "Weiru Zhang", "Xiaoyi Zeng"], "title": "Constraint-Aware Generative Auto-bidding via Pareto-Prioritized Regret Optimization", "comment": null, "summary": "Auto-bidding systems aim to maximize marketing value while satisfying strict efficiency constraints such as Target Cost-Per-Action (CPA). Although Decision Transformers provide powerful sequence modeling capabilities, applying them to this constrained setting encounters two challenges: 1) standard Return-to-Go conditioning causes state aliasing by neglecting the cost dimension, preventing precise resource pacing; and 2) standard regression forces the policy to mimic average historical behaviors, thereby limiting the capacity to optimize performance toward the constraint boundary. To address these challenges, we propose PRO-Bid, a constraint-aware generative auto-bidding framework based on two synergistic mechanisms: 1) Constraint-Decoupled Pareto Representation (CDPR) decomposes global constraints into recursive cost and value contexts to restore resource perception, while reweighting trajectories based on the Pareto frontier to focus on high-efficiency data; and 2) Counterfactual Regret Optimization (CRO) facilitates active improvement by utilizing a global outcome predictor to identify superior counterfactual actions. By treating these high-utility outcomes as weighted regression targets, the model transcends historical averages to approach the optimal constraint boundary. Extensive experiments on two public benchmarks and online A/B tests demonstrate that PRO-Bid achieves superior constraint satisfaction and value acquisition compared to state-of-the-art baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08387", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08387", "abs": "https://arxiv.org/abs/2602.08387", "authors": ["Max L\u00fcbbering", "Timm Ruland", "Richard Rutmann", "Felix Stollenwerk", "David Fitzek", "Michael Fromm", "Alexander Weber", "Rafet Sifa", "Nicolas Flores-Herr", "Joachim K\u00f6hler", "Mehdi Ali"], "title": "Modalities, a PyTorch-native Framework For Large-scale LLM Training and Research", "comment": null, "summary": "Today's LLM (pre-) training and research workflows typically allocate a significant amount of compute to large-scale ablation studies. Despite the substantial compute costs of these ablations, existing open-source frameworks provide limited tooling for these experiments, often forcing researchers to write their own wrappers and scripts. We propose Modalities, an end-to-end PyTorch-native framework that integrates data-driven LLM research with large-scale model training from two angles. Firstly, by integrating state-of-the-art parallelization strategies, it enables both efficient pretraining and systematic ablations at trillion-token and billion-parameter scale. Secondly, Modalities adopts modular design with declarative, self-contained configuration, enabling reproducibility and extensibility levels that are difficult to achieve out-of-the-box with existing LLM training frameworks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08570", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2602.08570", "abs": "https://arxiv.org/abs/2602.08570", "authors": ["Panagiotis Charalampopoulos", "Jonas Ellert", "Manal Mohamed"], "title": "Approximate Cartesian Tree Matching with Substitutions", "comment": "Full version of a work to appear in the proceedings of STACS 2026", "summary": "The Cartesian tree of a sequence captures the relative order of the sequence's elements. In recent years, Cartesian tree matching has attracted considerable attention, particularly due to its applications in time series analysis. Consider a text $T$ of length $n$ and a pattern $P$ of length $m$. In the exact Cartesian tree matching problem, the task is to find all length-$m$ fragments of $T$ whose Cartesian tree coincides with the Cartesian tree $CT(P)$ of the pattern. Although the exact version of the problem can be solved in linear time [Park et al., TCS 2020], it remains rather restrictive; for example, it is not robust to outliers in the pattern.\n  To overcome this limitation, we consider the approximate setting, where the goal is to identify all fragments of $T$ that are close to some string whose Cartesian tree matches $CT(P)$. In this work, we quantify closeness via the widely used Hamming distance metric. For a given integer parameter $k>0$, we present an algorithm that computes all fragments of $T$ that are at Hamming distance at most $k$ from a string whose Cartesian tree matches $CT(P)$. Our algorithm runs in time $\\mathcal O(n \\sqrt{m} \\cdot k^{2.5})$ for $k \\leq m^{1/5}$ and in time $\\mathcal O(nk^5)$ for $k \\geq m^{1/5}$, thereby improving upon the state-of-the-art $\\mathcal O(nmk)$-time algorithm of Kim and Han [TCS 2025] in the regime $k = o(m^{1/4})$.\n  On the way to our solution, we develop a toolbox of independent interest. First, we introduce a new notion of periodicity in Cartesian trees. Then, we lift multiple well-known combinatorial and algorithmic results for string matching and periodicity in strings to Cartesian tree matching and periodicity in Cartesian trees.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08604", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08604", "abs": "https://arxiv.org/abs/2602.08604", "authors": ["A. L. Silva Netto", "A. M. de M. Carvalho", "G. Q. Garcia", "C. Furtado"], "title": "Elastic field causing noncommutativity", "comment": "5 pages", "summary": "We study how a uniform torsion background, modeling a continuous density of screw dislocations and induces effective spatial noncommutativity and reshapes the energy spectrum of a free quantum particle. Within the geometric theory of defects, the metric yields a first-order (magnetic-like) coupling in the transverse dynamics, equivalent to an effective magnetic field $B_{eff}$ proportional to $p_z Omega$, where $Omega$ encodes the torsion strength. In the strong-coupling (Landau) regime, the planar coordinates obey [x,y] != 0 and the spectrum organizes into Landau-like levels with a slight electric-field-driven tilt and a uniform shift. Thus, increasing $Omega$ drives the system continuously toward the familiar Landau problem in flat space, with torsion setting the noncommutativity scale and controlling the approach to the Landau limit.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07338", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07338", "abs": "https://arxiv.org/abs/2602.07338", "authors": ["Geng Liu", "Fei Zhu", "Rong Feng", "Changyi Ma", "Shiqi Wang", "Gaofeng Meng"], "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation", "comment": null, "summary": "Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07462", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07462", "abs": "https://arxiv.org/abs/2602.07462", "authors": ["Murtaza Rangwala", "Adarsh Ganesan"], "title": "Spontaneous Symmetry Breaking and Collective Higgs-Goldstone Dynamics in Solid-State Phononic Frequency Combs", "comment": "8 pages, 6 figures", "summary": "We investigate the generation of phononic frequency combs arising from nonlinear coupling between Higgs-like and Goldstone-like phonon modes in hexagonal InMnO3. The Higgs-like mode, an infrared-active optical phonon, is resonantly driven by a short, high-electric field terahertz pulse, while the optically inactive Goldstone-like mode is indirectly excited through intrinsic nonlinear mode coupling. Using a nonlinear phononics model, we numerically solve the coupled equations of motion governing the lattice dynamics and analyze the resulting time- and frequency-domain responses. By systematically varying key drive and material parameters-including electric field amplitude, pulse width, driving frequency, and mode damping-we identify the conditions under which stable phononic frequency combs emerge. Our results reveal clear threshold behaviors for comb formation, tunability of comb spacing and spectral bandwidth through external control parameters, and a breakdown of coherent comb structure at high drive strengths or weak damping. These findings demonstrate how nonlinear Higgs-Goldstone interactions enable controllable phononic frequency comb generation and provide insight into ultrafast lattice dynamics in symmetry-broken materials.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08290", "categories": ["cs.LG", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08290", "abs": "https://arxiv.org/abs/2602.08290", "authors": ["Ajay Kumar Shrestha"], "title": "Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems", "comment": "To appear in the ICBTA 2025 Conference Proceedings and published as a volume of Lecture Notes in Networks and Systems by Springer", "summary": "In federated learning (FL), decentralized model training allows multi-ple participants to collaboratively improve a shared machine learning model without exchanging raw data. However, ensuring the integrity and reliability of the system is challenging due to the presence of potentially malicious or faulty nodes that can degrade the model's performance. This paper proposes a novel trust-based incentive mechanism designed to evaluate and reward the quality of contributions in FL systems. By dynamically assessing trust scores based on fac-tors such as data quality, model accuracy, consistency, and contribution fre-quency, the system encourages honest participation and penalizes unreliable or malicious behavior. These trust scores form the basis of an incentive mechanism that rewards high-trust nodes with greater participation opportunities and penal-ties for low-trust participants. We further explore the integration of blockchain technology and smart contracts to automate the trust evaluation and incentive distribution processes, ensuring transparency and decentralization. Our proposed theoretical framework aims to create a more robust, fair, and transparent FL eco-system, reducing the risks posed by untrustworthy participants.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08904", "categories": ["eess.SP", "physics.app-ph", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2602.08904", "abs": "https://arxiv.org/abs/2602.08904", "authors": ["Xingdi Tong", "Chenyu Wen"], "title": "Denoise Stepwise Signals by Diffusion Model Based Approach", "comment": null, "summary": "Stepwise signals are ubiquitous in single-molecule detections, where abrupt changes in signal levels typically correspond to molecular conformational changes or state transitions. However, these features are inevitably obscured by noise, leading to uncertainty in estimating both signal levels and transition points. Traditional frequency-domain filtering is ineffective for denoising stepwise signals, as edge-related high-frequency components strongly overlap with noise. Although Hidden Markov Model-based approaches are widely used, they rely on stationarity assumptions and are not specifically designed for signal denoising. Here, we propose a diffusion model-based algorithm for stepwise signal denoising, named the Stepwise Signal Diffusion Model (SSDM). During training, SSDM learns the statistical structure of stepwise signals via a forward diffusion process that progressively adds noise. In the following reverse process, the model reconstructs clean signals from noisy observations, integrating a multi-scale convolutional network with an attention mechanism. Training data are generated by simulating stepwise signals through a Markov process with additive Gaussian noise. Across a broad range of signal-to-noise ratios, SSDM consistently outperforms traditional methods in both signal level reconstruction and transition point detection. Its effectiveness is further demonstrated on experimental data from single-molecule Forster Resonance Energy Transfer and nanopore DNA translocation measurements. Overall, SSDM provides a general and robust framework for recovering stepwise signals in various single-molecule detections and other physical systems exhibiting discrete state transitions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07024", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07024", "abs": "https://arxiv.org/abs/2602.07024", "authors": ["Valerio Belcamino", "Nhat Minh Dinh Le", "Quan Khanh Luu", "Alessandro Carf\u00ec", "Van Anh Ho", "Fulvio Mastrogiovanni"], "title": "A Distributed Multi-Modal Sensing Approach for Human Activity Recognition in Real-Time Human-Robot Collaboration", "comment": null, "summary": "Human activity recognition (HAR) is fundamental in human-robot collaboration (HRC), enabling robots to respond to and dynamically adapt to human intentions. This paper introduces a HAR system combining a modular data glove equipped with Inertial Measurement Units and a vision-based tactile sensor to capture hand activities in contact with a robot. We tested our activity recognition approach under different conditions, including offline classification of segmented sequences, real-time classification under static conditions, and a realistic HRC scenario. The experimental results show a high accuracy for all the tasks, suggesting that multiple collaborative settings could benefit from this multi-modal approach.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07502", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07502", "abs": "https://arxiv.org/abs/2602.07502", "authors": ["Xiaotong Zhao", "Mian Li", "Ya-Feng Liu", "Qingjiang Shi", "Anthony Man-Cho So"], "title": "Optimal Low-Dimensional Structures of ISAC Beamforming: Theory and Efficient Algorithms", "comment": null, "summary": "Transmit beamforming design is a fundamental problem in integrated sensing and communication (ISAC) systems. Numerous methods have been proposed to jointly optimize key performance metrics such as the signal-to-interference-plus-noise ratio and Cram\u00e9r-Rao bound. However, the computational complexity of these methods often grows rapidly with the number of transmit antennas at the base station (BS). To tackle this challenge, we prove a fundamental structural property of the ISAC beamforming problem, i.e., there exists an optimal solution exhibiting a low-dimensional structure. This leads to an equivalent reformulation of the problem with dimension related to the number of users rather than the number of BS antennas, thereby enabling the development of low-complexity algorithms. When applying the interior-point method to the reformulated problem, we achieve up to six orders of magnitude in complexity reduction when the number of antennas exceeds the number of users by an order of magnitude. To further reduce the complexity, we develop a balanced augmented Lagrangian method to solve the reformulated problem. The proposed algorithm maintains optimality while achieving a computational complexity that scales quartically with the number of users. Our simulation results demonstrate that the proposed R-BAL method can achieve a speedup of more than 10000$\\times$ over the conventional IPM in massive MIMO scenarios.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07391", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07391", "abs": "https://arxiv.org/abs/2602.07391", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents", "comment": null, "summary": "AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring \"benign-use correctness\", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07860", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.07860", "abs": "https://arxiv.org/abs/2602.07860", "authors": ["Fei Yu", "Shudan Guo", "Shiqing Xin", "Beibei Wang", "Haisen Zhao", "Wenzheng Chen"], "title": "Recovering 3D Shapes from Ultra-Fast Motion-Blurred Images", "comment": "Accepted by 3DV 2026. Project page: https://maxmilite.github.io/rec-from-ultrafast-blur/", "summary": "We consider the problem of 3D shape recovery from ultra-fast motion-blurred images. While 3D reconstruction from static images has been extensively studied, recovering geometry from extreme motion-blurred images remains challenging. Such scenarios frequently occur in both natural and industrial settings, such as fast-moving objects in sports (e.g., balls) or rotating machinery, where rapid motion distorts object appearance and makes traditional 3D reconstruction techniques like Multi-View Stereo (MVS) ineffective.\n  In this paper, we propose a novel inverse rendering approach for shape recovery from ultra-fast motion-blurred images. While conventional rendering techniques typically synthesize blur by averaging across multiple frames, we identify a major computational bottleneck in the repeated computation of barycentric weights. To address this, we propose a fast barycentric coordinate solver, which significantly reduces computational overhead and achieves a speedup of up to 4.57x, enabling efficient and photorealistic simulation of high-speed motion. Crucially, our method is fully differentiable, allowing gradients to propagate from rendered images to the underlying 3D shape, thereby facilitating shape recovery through inverse rendering.\n  We validate our approach on two representative motion types: rapid translation and rotation. Experimental results demonstrate that our method enables efficient and realistic modeling of ultra-fast moving objects in the forward simulation. Moreover, it successfully recovers 3D shapes from 2D imagery of objects undergoing extreme translational and rotational motion, advancing the boundaries of vision-based 3D reconstruction. Project page: https://maxmilite.github.io/rec-from-ultrafast-blur/", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08446", "categories": ["cs.LG", "cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.08446", "abs": "https://arxiv.org/abs/2602.08446", "authors": ["Pouria Arefijamal", "Mahdi Ahmadlou", "Bardia Safaei", "J\u00f6rg Henkel"], "title": "RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks", "comment": "This paper has been accepted for publication in IEEE ICC 2026 and will be indexed in the IEEE Xplore Digital Library", "summary": "Federated learning (FL) is a decentralized learning paradigm widely adopted in resource-constrained Internet of Things (IoT) environments. These devices, typically relying on TinyML models, collaboratively train global models by sharing gradients with a central server while preserving data privacy. However, as data heterogeneity and task complexity increase, TinyML models often become insufficient to capture intricate patterns, especially under extreme non-IID (non-independent and identically distributed) conditions. Moreover, ensuring robustness against malicious clients and poisoned updates remains a major challenge. Accordingly, this paper introduces RIFLE - a Robust, distillation-based Federated Learning framework that replaces gradient sharing with logit-based knowledge transfer. By leveraging a knowledge distillation aggregation scheme, RIFLE enables the training of deep models such as VGG-19 and Resnet18 within constrained IoT systems. Furthermore, a Kullback-Leibler (KL) divergence-based validation mechanism quantifies the reliability of client updates without exposing raw data, achieving high trust and privacy preservation simultaneously. Experiments on three benchmark datasets (MNIST, CIFAR-10, and CIFAR-100) under heterogeneous non-IID conditions demonstrate that RIFLE reduces false-positive detections by up to 87.5%, enhances poisoning attack mitigation by 62.5%, and achieves up to 28.3% higher accuracy compared to conventional federated learning baselines within only 10 rounds. Notably, RIFLE reduces VGG19 training time from over 600 days to just 1.39 hours on typical IoT devices (0.3 GFLOPS), making deep learning practical in resource-constrained networks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07995", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07995", "abs": "https://arxiv.org/abs/2602.07995", "authors": ["Antonio Alc\u00e1ntara", "Spyros Chatzivasileiadis"], "title": "Trustworthiness Layer for Foundation Models in Power Systems: Application for N-k Contingency Assessment", "comment": null, "summary": "This work introduces for the first time, to our knowledge, a trustworthiness layer for foundation models in power systems. Using stratified conformal prediction, we devise adaptive, statistically valid confidence bounds for each output of a foundation model. For regression, this allows users to obtain an uncertainty estimate for each output; for screening, it supports conservative decisions that minimize false negatives. We demonstrate our method by enhancing GridFM, the first open-source Foundation Model for power systems, with statistically valid prediction intervals instead of heuristic error margins. We apply it for N-k contingency assessment, a combinatorial NP-Hard problem. We show that trustworthy GridFM can offer richer and more accurate information than DC Power Flow, having 2x-3x higher precision, while running up to 18x faster than AC Power Flow for systems up to 118 buses. Moving a step further, we also examine the ability of trustworthy GridFM to generalize to unseen high-order contingencies: through a rigorous analysis, we assess how a model trained on N-1 or N-2 outages extrapolates to unseen contingencies up to N-5.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08742", "categories": ["cs.DS", "cs.CG", "cs.GT", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08742", "abs": "https://arxiv.org/abs/2602.08742", "authors": ["Siddharth Barman", "Nirjhar Das", "Shivam Gupta", "Kirankumar Shiragur"], "title": "Welfarist Formulations for Diverse Similarity Search", "comment": null, "summary": "Nearest Neighbor Search (NNS) is a fundamental problem in data structures with wide-ranging applications, such as web search, recommendation systems, and, more recently, retrieval-augmented generations (RAG). In such recent applications, in addition to the relevance (similarity) of the returned neighbors, diversity among the neighbors is a central requirement. In this paper, we develop principled welfare-based formulations in NNS for realizing diversity across attributes. Our formulations are based on welfare functions -- from mathematical economics -- that satisfy central diversity (fairness) and relevance (economic efficiency) axioms. With a particular focus on Nash social welfare, we note that our welfare-based formulations provide objective functions that adaptively balance relevance and diversity in a query-dependent manner. Notably, such a balance was not present in the prior constraint-based approach, which forced a fixed level of diversity and optimized for relevance. In addition, our formulation provides a parametric way to control the trade-off between relevance and diversity, providing practitioners with flexibility to tailor search results to task-specific requirements. We develop efficient nearest neighbor algorithms with provable guarantees for the welfare-based objectives. Notably, our algorithm can be applied on top of any standard ANN method (i.e., use standard ANN method as a subroutine) to efficiently find neighbors that approximately maximize our welfare-based objectives. Experimental results demonstrate that our approach is practical and substantially improves diversity while maintaining high relevance of the retrieved neighbors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07051", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.07051", "abs": "https://arxiv.org/abs/2602.07051", "authors": ["Karthik Sivakoti"], "title": "Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning", "comment": null, "summary": "Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, and vehicle attribute extraction through a single forward pass. Our primary contribution lies in demonstrating that a fine-tuned PaliGemma 3B model, adapted via Low-Rank Adaptation (LoRA), can simultaneously answer multiple visual questions about vehicle images, achieving 92.3% plate recognition accuracy, which is a 14.1% improvement over EasyOCR and 9.9% improvement over PaddleOCR baselines. We introduce a Human-in-the-Loop (HITL) continual learning framework that incorporates user corrections while preventing catastrophic forgetting through experience replay, maintaining a 70:30 ratio of original training data to correction samples. The system achieves a mean inference latency of 152ms with an Expected Calibration Error (ECE) of 0.048, indicating well calibrated confidence estimates. Additionally, the VLM first architecture enables zero-shot generalization to auxiliary tasks including vehicle color detection (89%), seatbelt detection (82%), and occupancy counting (78%) without task specific training. Through extensive experimentation on real world toll plaza imagery, we demonstrate that unified vision language approaches represent a paradigm shift in ALPR systems, offering superior accuracy, reduced architectural complexity, and emergent multi-task capabilities that traditional pipeline approaches cannot achieve.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08622", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08622", "abs": "https://arxiv.org/abs/2602.08622", "authors": ["Masoud Shahrokhi", "Bohayra Mortazavi"], "title": "First-principles discovery of stable, anisotropic, semiconducting Sb2X2O (X = S, Se) and Janus Sb2SSeO nanosheets for optoelectronics and photocatalysis", "comment": null, "summary": "In this work, we conduct a comprehensive first-principles investigation into the design and discovery of novel antimony oxychalcogenide monolayers Sb2X2O (X = S, Se) and Janus Sb2SSeO, examining their structural stability, elastic, electronic, optoelectronic, and photocatalytic properties. Our analysis confirms their thermodynamic and dynamical stability and reveals low cleavage energies, indicating strong feasibility for mechanical exfoliation. The excellent agreement between our HSE06-predicted bandgap of bulk Sb2S2O and experimental measurements further validates the employed computational framework. EWe also find that their optoelectronic responses can be efficiently tuned via biaxial strain, providing a viable route for device-specific property engineering. Favorable band alignments, strong optical absorption, efficient carrier transport, and relatively high dielectric constants collectively support their candidacy for overall water splitting under neutral conditions.These results establish a solid theoretical foundation for the rational design of Sb-based 2D nanostructures and highlight their potential in next-generation direction-dependent optoelectronic and sustainable energy-conversion applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07361", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.07361", "abs": "https://arxiv.org/abs/2602.07361", "authors": ["Long S. T. Nguyen", "Quan M. Bui", "Tin T. Ngo", "Quynh T. N. Vo", "Dung N. H. Le", "Tho T. Quan"], "title": "ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations", "comment": "Accepted at ACIIDS 2026", "summary": "Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07471", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.07471", "abs": "https://arxiv.org/abs/2602.07471", "authors": ["M. Bonacci", "D. A. Leon", "N. Spallanzani", "E. Molinari", "D. Varsano", "A. Ferretti", "C. Cardoso"], "title": "Benchmarking the plasmon-pole and multipole approximations in the Yambo Code using the GW100 dataset", "comment": "21 pages, 8 figures, 8 tables", "summary": "Verification and validation of electronic structure codes are essential to ensure reliable and reproducible results in computational materials science. While density functional theory has been extensively benchmarked, systematic assessments of many-body perturbation theory methods such as the GW approximation have only recently emerged, most notably through the GW100 dataset. In this work, we assess the numerical accuracy and convergence behavior of the GW implementation in the yambo code using both the Godby-Needs plasmon-pole model and the recently introduced multipole approximation. Quasiparticle energies are compared against GW100 reference data to evaluate the performance, numerical stability, and consistency of these approaches.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07074", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07074", "abs": "https://arxiv.org/abs/2602.07074", "authors": ["H. Emre Tekaslan", "Ella M. Atkins"], "title": "Airspace-aware Contingency Landing Planning", "comment": null, "summary": "This paper develops a real-time, search-based aircraft contingency landing planner that minimizes traffic disruptions while accounting for ground risk. The airspace model captures dense air traffic departure and arrival flows, helicopter corridors, and prohibited zones and is demonstrated with a Washington, D.C., area case study. Historical Automatic Dependent Surveillance-Broadcast (ADS-B) data are processed to estimate air traffic density. A low-latency computational geometry algorithm generates proximity-based heatmaps around high-risk corridors and restricted regions. Airspace risk is quantified as the cumulative exposure time of a landing trajectory within congested regions, while ground risk is assessed from overflown population density to jointly guide trajectory selection. A landing site selection module further mitigates disruption to nominal air traffic operations. Benchmarking against minimum-risk Dubins solutions demonstrates that the proposed planner achieves lower joint risk and reduced airspace disruption while maintaining real-time performance. Under airspace-risk-only conditions, the planner generates trajectories within an average of 2.9 seconds on a laptop computer. Future work will incorporate dynamic air traffic updates to enable spatiotemporal contingency landing planning that minimizes the need for real-time traffic rerouting.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07515", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07515", "abs": "https://arxiv.org/abs/2602.07515", "authors": ["Hua Chen", "Zhenhao Yu", "Tuo Wu", "Wei Liu", "Maged Elkashlan", "Hyundong Shin", "Matthew C. Valenti", "Robert Schober"], "title": "Beyond $\u03bb/2$: Can Arbitrary EMVS Arrays Achieve Unambiguous NLOS Localization?", "comment": null, "summary": "Conventional radar array design mandates interelement spacing not exceeding half a wavelength ($\u03bb/2$) to avoid spatial ambiguity, fundamentally limiting array aperture and angular resolution. This paper addresses the fundamental question: Can arbitrary electromagnetic vector sensor (EMVS) arrays achieve unambiguous reconfigurable intelligent surface (RIS)-aided localization when element spacing exceeds $\u03bb/2$? We provide an affirmative answer by exploiting the multi-component structure of EMVS measurements and developing a synergistic estimation and optimization framework for non-line-of-sight (NLOS) bistatic multiple input multiple output (MIMO) radar. A third-order parallel factor (PARAFAC) model is constructed from EMVS observations, enabling natural separation of spatial, polarimetric, and propagation effects via the trilinear alternating least squares (TALS) algorithm. A novel phase-disambiguation procedure leverages rotational invariance across the six electromagnetic components of EMVSs to resolve $2\u03c0$ phase wrapping in arbitrary array geometries, allowing unambiguous joint estimation of two-dimensional (2-D) direction of departure (DOD), two-dimensional direction of arrival (DOA), and polarization parameters with automatic pairing. To support localization in NLOS environments and enhance estimation robustness, a reconfigurable intelligent surface (RIS) is incorporated and its phase shifts are optimized via semidefinite programming (SDP) relaxation to maximize received signal power, improving signal-to-noise ratio (SNR) and further suppressing spatial ambiguities through iterative refinement.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07408", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07408", "abs": "https://arxiv.org/abs/2602.07408", "authors": ["Hyomin Kim", "Sang-Yeon Hwang", "Jaechang Lim", "Yinhua Piao", "Yunhak Oh", "Woo Youn Kim", "Chanyoung Park", "Sungsoo Ahn", "Junhyeok Jeon"], "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction", "comment": "17 pages, 4 figures, 9 tables", "summary": "Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08198", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.08198", "abs": "https://arxiv.org/abs/2602.08198", "authors": ["Jingyu Hu", "Bin Hu", "Ka-Hei Hui", "Haipeng Li", "Zhengzhe Liu", "Daniel Cohen-Or", "Chi-Wing Fu"], "title": "PEGAsus: 3D Personalization of Geometry and Appearance", "comment": null, "summary": "We present PEGAsus, a new framework capable of generating Personalized 3D shapes by learning shape concepts at both Geometry and Appearance levels. First, we formulate 3D shape personalization as extracting reusable, category-agnostic geometric and appearance attributes from reference shapes, and composing these attributes with text to generate novel shapes. Second, we design a progressive optimization strategy to learn shape concepts at both the geometry and appearance levels, decoupling the shape concept learning process. Third, we extend our approach to region-wise concept learning, enabling flexible concept extraction, with context-aware and context-free losses. Extensive experimental results show that PEGAsus is able to effectively extract attributes from a wide range of reference shapes and then flexibly compose these concepts with text to synthesize new shapes. This enables fine-grained control over shape generation and supports the creation of diverse, personalized results, even in challenging cross-category scenarios. Both quantitative and qualitative experiments demonstrate that our approach outperforms existing state-of-the-art solutions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08558", "categories": ["cs.CV", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.08558", "abs": "https://arxiv.org/abs/2602.08558", "authors": ["Guan Yuan Tan", "Ngoc Tuan Vu", "Arghya Pal", "Sailaja Rajanala", "Raphael Phan C. -W.", "Mettu Srinivas", "Chee-Ming Ting"], "title": "FLAG-4D: Flow-Guided Local-Global Dual-Deformation Model for 4D Reconstruction", "comment": null, "summary": "We introduce FLAG-4D, a novel framework for generating novel views of dynamic scenes by reconstructing how 3D Gaussian primitives evolve through space and time. Existing methods typically rely on a single Multilayer Perceptron (MLP) to model temporal deformations, and they often struggle to capture complex point motions and fine-grained dynamic details consistently over time, especially from sparse input views. Our approach, FLAG-4D, overcomes this by employing a dual-deformation network that dynamically warps a canonical set of 3D Gaussians over time into new positions and anisotropic shapes. This dual-deformation network consists of an Instantaneous Deformation Network (IDN) for modeling fine-grained, local deformations and a Global Motion Network (GMN) for capturing long-range dynamics, refined through mutual learning. To ensure these deformations are both accurate and temporally smooth, FLAG-4D incorporates dense motion features from a pretrained optical flow backbone. We fuse these motion cues from adjacent timeframes and use a deformation-guided attention mechanism to align this flow information with the current state of each evolving 3D Gaussian. Extensive experiments demonstrate that FLAG-4D achieves higher-fidelity and more temporally coherent reconstructions with finer detail preservation than state-of-the-art methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08923", "categories": ["cs.LG", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.08923", "abs": "https://arxiv.org/abs/2602.08923", "authors": ["Wenchen Han", "Shay Vargaftik", "Michael Mitzenmacher", "Ran Ben Basat"], "title": "DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce", "comment": "18 pages, 18 figures", "summary": "Multi-hop all-reduce is the de facto backbone of large model training. As the training scale increases, the network often becomes a bottleneck, motivating reducing the volume of transmitted data. Accordingly, recent systems demonstrated significant acceleration of the training process using gradient quantization. However, these systems are not optimized for multi-hop aggregation, where entries are partially summed multiple times along their aggregation topology.\n  This paper presents DynamiQ, a quantization framework that bridges the gap between quantization best practices and multi-hop aggregation. DynamiQ introduces novel techniques to better represent partial sums, co-designed with a decompress-accumulate-recompress fused kernel to facilitate fast execution.\n  We extended PyTorch DDP to support DynamiQ over NCCL P2P, and across different LLMs, tasks, and scales, we demonstrate consistent improvement of up to 34.2% over the best among state-of-the-art methods such as Omni-Reduce, THC, and emerging standards such as MXFP4, MXFP6, and MXFP8. Further, DynamiQ is the only evaluated method that consistently reaches near-baseline accuracy (e.g., 99.9% of the BF16 baseline) and does so while significantly accelerating the training.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08137", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08137", "abs": "https://arxiv.org/abs/2602.08137", "authors": ["Fen Wu"], "title": "Robust and Gain-Scheduling ${\\cal H}_2$ Control Techniques for LFT Uncertain and Parameter-Dependent Systems", "comment": null, "summary": "This paper addresses the robust ${\\cal H}_2$ synthesis problem for linear fractional transformation (LFT) systems subject to structured uncertainty (parameter) and white-noise disturbances. By introducing an intermediate matrix variable, we derive convex synthesis conditions in terms of linear matrix inequalities (LMIs) that enable both robust and gain-scheduled controller design for parameter-dependent systems. The proposed framework preserves the classical white-noise and impulse-response interpretation of the ${\\cal H}_2$ criterion while providing certified robustness guarantees, thereby extending optimal ${\\cal H}_2$ control beyond the linear time-invariant setting. Numerical and application examples demonstrate that the resulting robust ${\\cal H}_2$ controllers achieve significantly reduced conservatism and improved disturbance rejection compared with conventional robust ${\\cal H}_\\infty$-based designs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07530", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07530", "abs": "https://arxiv.org/abs/2602.07530", "authors": ["Sreenivas Gollapudi", "Kostas Kollias", "Kamesh Munagala", "Aravindan Vijayaraghavan"], "title": "Compact Conformal Subgraphs", "comment": null, "summary": "Conformal prediction provides rigorous, distribution-free uncertainty guarantees, but often yields prohibitively large prediction sets in structured domains such as routing, planning, or sequential recommendation. We introduce \"graph-based conformal compression\", a framework for constructing compact subgraphs that preserve statistical validity while reducing structural complexity. We formulate compression as selecting a smallest subgraph capturing a prescribed fraction of the probability mass, and reduce to a weighted version of densest $k$-subgraphs in hypergraphs, in the regime where the subgraph has a large fraction of edges. We design efficient approximation algorithms that achieve constant factor coverage and size trade-offs. Crucially, we prove that our relaxation satisfies a monotonicity property, derived from a connection to parametric minimum cuts, which guarantees the nestedness required for valid conformal guarantees. Our results on the one hand bridge efficient conformal prediction with combinatorial graph compression via monotonicity, to provide rigorous guarantees on both statistical validity, and compression or size. On the other hand, they also highlight an algorithmic regime, distinct from classical densest-$k$-subgraph hardness settings, where the problem can be approximated efficiently. We finally validate our algorithmic approach via simulations for trip planning and navigation, and compare to natural baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07697", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.07697", "abs": "https://arxiv.org/abs/2602.07697", "authors": ["Francesco Innocenti", "El Mehdi Achour", "Rafal Bogacz"], "title": "On the Infinite Width and Depth Limits of Predictive Coding Networks", "comment": "31 pages, 27 figures", "summary": "Predictive coding (PC) is a biologically plausible alternative to standard backpropagation (BP) that minimises an energy function with respect to network activities before updating weights. Recent work has improved the training stability of deep PC networks (PCNs) by leveraging some BP-inspired reparameterisations. However, the full scalability and theoretical basis of these approaches remains unclear. To address this, we study the infinite width and depth limits of PCNs. For linear residual networks, we show that the set of width- and depth-stable feature-learning parameterisations for PC is exactly the same as for BP. Moreover, under any of these parameterisations, the PC energy with equilibrated activities converges to the BP loss in a regime where the model width is much larger than the depth, resulting in PC computing the same gradients as BP. Experiments show that these results hold in practice for deep nonlinear networks, as long as an activity equilibrium seem to be reached. Overall, this work unifies various previous theoretical and empirical results and has potentially important implications for the scaling of PCNs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08766", "categories": ["cond-mat.mes-hall", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.08766", "abs": "https://arxiv.org/abs/2602.08766", "authors": ["V. D. Esin", "D. Yu. Kazmin", "Yu. S. Barash", "A. V. Timonina", "N. N. Kolesnikov", "E. V. Deviatov"], "title": "Josephson diode and spin-valve effects on the surface of altermagnet CrSb", "comment": null, "summary": "We experimentally investigate charge transport in In-CrSb and In-CrSb-In proximity devices, which are formed as junctions between superconducting indium leads and thick single crystal flakes of altermagnet CrSb. For double In-CrSb-In junctions, the obtained $dV/dI(B)$ curves are mirrored in respect to zero field for two magnetic field sweep directions, which is characteristic behavior of a Josephson spin valve. Also, we demonstrate Josephson diode effect by direct measurement of the critical current for two opposite directions in external magnetic field. We interpret these observations as a joint effect of the spin-polarized topological surface states and the altermagnetic spin splitting of the bulk bands in CrSb. For a single In-CrSb interface, the superconducting gap oscillates in magnetic field for both field orientations, which strongly resembles the transition into the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) state. The latter is based on finite-momentum Cooper pairing against a background of the Zeeman splitting, so it is fully compatible with the requirements for the Josephson diode effect.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07374", "abs": "https://arxiv.org/abs/2602.07374", "authors": ["Nisharg Nargund", "Priyesh Shukla"], "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling", "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07516", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07516", "abs": "https://arxiv.org/abs/2602.07516", "authors": ["Yi Zhao", "Hongtao Zhang", "Qiang Li", "Xian Tang", "Guodong Cheng"], "title": "Positron annihilation lifetime and Doppler broadening spectral calculations of oxygen-doped 3C-SiC", "comment": "18 pages, 5 figures", "summary": "Based on density functional theory (DFT), the formation energies of intrinsic vacancy defects (VC, VSi, and VSi+C) and oxygen-related defects (OC, OSi, OCVSi, and OSiVC) in 3C-SiC are systematically investigated. The results indicate that all defects considered, except for OC, possess neutral or negative charge states, thereby making them suitable for detection by positron annihilation spectroscopy (PAS). Furthermore, the electron and positron density distributions and positron annihilation lifetimes for the perfect 3C-SiC supercell and various defective configurations are computed. It is found that the OSi and OSiVC complexes act as effective positron trapping centers, leading to the formation of positron trapped states and a notable increase in annihilation lifetimes at the corresponding defect sites. In addition, coincidence Doppler broadening (CDB) spectra, along with the S and W parameters, are calculated for both intrinsic and oxygen-doped point defects (OC, OSi, OCVSi, and OSiVC). The analysis reveals that electron screening effects dominate the annihilation characteristics of the OSi defect, whereas positron localization induced by the vacancy is the predominant contributor in the case of OSiVC. This distinction results in clearly different momentum distributions of these two oxygen-related defects for different charge states. Overall, the PAS is demonstrated to be a powerful technique for distinguishing intrinsic vacancy-type defects and oxygen-doped composites in 3C-SiC. Combining the analysis of electron and positron density distributions, the electron localization and positron trapping behavior in defect systems with different charge states can be comprehensively understood. These first-principles results provide a solid theoretical foundation for identifying and characterizing the defects in oxygen-doped 3C-SiC by using PAS.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08479", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08479", "abs": "https://arxiv.org/abs/2602.08479", "authors": ["Alif Rizqullah Mahdi", "Mahdi Rezaei", "Natasha Merat"], "title": "Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation", "comment": "9th International Conference on Instrumentation, Control, and Automation (ICA)", "summary": "Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four primary classes (Stop, Go, Thank & Greet, and No Gesture) and extract 76 static and dynamic features from normalised keypoints. Our analysis demonstrates that hand position and movement velocity are especially discriminative in distinguishing between gesture classes, achieving a classification accuracy score of 87%. These findings not only improve the perceptual capabilities of AV systems but also contribute to the broader understanding of pedestrian behaviour in traffic contexts.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07158", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07158", "abs": "https://arxiv.org/abs/2602.07158", "authors": ["Deniz Kerimoglu", "Ismail Uyanik"], "title": "A compliant ankle-actuated compass walker with triggering timing control", "comment": "6 figures, 6 pages", "summary": "Passive dynamic walkers are widely adopted as a mathematical model to represent biped walking. The stable locomotion of these models is limited to tilted surfaces, requiring gravitational energy. Various techniques, such as actuation through the ankle and hip joints, have been proposed to extend the applicability of these models to level ground and rough terrain with improved locomotion efficiency. However, most of these techniques rely on impulsive energy injection schemes and torsional springs, which are quite challenging to implement in a physical platform. Here, a new model is proposed, named triggering controlled ankle actuated compass gait (TC-AACG), which allows non-instantaneous compliant ankle pushoff. The proposed technique can be implemented in physical platforms via series elastic actuators (SEAs). Our systematic examination shows that the proposed approach extends the locomotion capabilities of a biped model compared to impulsive ankle pushoff approach. We provide extensive simulation analysis investigating the locomotion speed, mechanical cost of transport, and basin of attraction of the proposed model.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07527", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07527", "abs": "https://arxiv.org/abs/2602.07527", "authors": ["Yaakoub Berrouche"], "title": "Fractional Filtering and Anomaly-Guided Diagnostics: The Local Damage Mode Extractor (LDME) for Early Gear Fault Detection", "comment": null, "summary": "Early and reliable detection of gear faults in complex drivetrain systems is critical for aviation safety and operational availability. We present the Local Damage Mode Extractor (LDME), a structured, physics-informed signal processing framework that combines dual-path denoising, multiscale decomposition, fractional-domain enhancement, and statistically principled anomaly scoring to produce interpretable condition indicators without supervision. LDME is organized in three layers: (i) dual-path denoising (DWT with adaptive Savitzky-Golay smoothing) to suppress broadband noise while preserving transient fault structure; (ii) multi-scale damage enhancement using a Teager-Kaiser pre-amplifier followed by a Hadamard-Caputo fractional operator that accentuates non-sinusoidal, low-frequency fault signatures; and (iii) decision fusion, where harmonics-aware Fourier indicators are combined and scored by an unsupervised anomaly detector. Evaluation using the Case Western Reserve University (CWRU) bearing dataset, the HUMS 2023 planetary gearbox benchmark, and a controlled simulated dataset shows that LDME consistently distinguishes nominal, early-crack, and propagated-crack stages under various operating conditions. LDME identifies the primary detection event earlier (198 cycles) than HT-TSA (284 cycles) and advances maintenance recommendation time from 383 to 365 cycles. We discuss its relation to prior art, limitations, and future theoretical directions. All code and experimental configurations are documented for reproducibility.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08104", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08104", "abs": "https://arxiv.org/abs/2602.08104", "authors": ["Risal Shahriar Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems", "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains \"downstream-first\" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08540", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.08540", "abs": "https://arxiv.org/abs/2602.08540", "authors": ["He Wu", "Xia Yan", "Yanghui Xu", "Liegang Xia", "Jiazhou Chen"], "title": "TIBR4D: Tracing-Guided Iterative Boundary Refinement for Efficient 4D Gaussian Segmentation", "comment": "13 pages, 6 figures, 4 tables", "summary": "Object-level segmentation in dynamic 4D Gaussian scenes remains challenging due to complex motion, occlusions, and ambiguous boundaries. In this paper, we present an efficient learning-free 4D Gaussian segmentation framework that lifts video segmentation masks to 4D spaces, whose core is a two-stage iterative boundary refinement, TIBR4D. The first stage is an Iterative Gaussian Instance Tracing (IGIT) at the temporal segment level. It progressively refines Gaussian-to-instance probabilities through iterative tracing, and extracts corresponding Gaussian point clouds that better handle occlusions and preserve completeness of object structures compared to existing one-shot threshold-based methods. The second stage is a frame-wise Gaussian Rendering Range Control (RCC) via suppressing highly uncertain Gaussians near object boundaries while retaining their core contributions for more accurate boundaries. Furthermore, a temporal segmentation merging strategy is proposed for IGIT to balance identity consistency and dynamic awareness. Longer segments enforce stronger multi-frame constraints for stable identities, while shorter segments allow identity changes to be captured promptly. Experiments on HyperNeRF and Neu3D demonstrate that our method produces accurate object Gaussian point clouds with clearer boundaries and higher efficiency compared to SOTA methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08273", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08273", "abs": "https://arxiv.org/abs/2602.08273", "authors": ["Melone Nyoba Tchonkeu", "Soulaimane Berkane", "Tarek Hamel"], "title": "Pitot-Aided Attitude and Air Velocity Estimation with Almost Global Asymptotic Stability Guarantees", "comment": "8 pages, 8 figures. Under review in IEEE CCTA2026", "summary": "This paper investigates the problem of attitude and air velocity estimation for fixed-wing unmanned aerial vehicles (UAVs) using IMU measurements and at least one Pitot tube measurement, with almost global asymptotic stability (AGAS) guarantees. A cascade observer architecture is developed, in which a Riccati/Kalman-type filter estimates the body-fixed frame air velocity and the vehicle's tilt using IMU data as inputs and Pitot measurements as outputs. Under mild excitation conditions, the resulting air velocity and tilt estimation error dynamics are shown to be uniformly observable. The estimated tilt is then combined with magnetometer measurements in a nonlinear observer on SO(3) to recover the full attitude. Rigorous analysis establishes AGAS of the overall cascade structure under the uniform observability (UO) condition. The effectiveness of the proposed approach is demonstrated through validation on real flight data.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07732", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07732", "abs": "https://arxiv.org/abs/2602.07732", "authors": ["Joon Suk Huh"], "title": "Efficient Adaptive Data Analysis over Dense Distributions", "comment": "23 pages", "summary": "Modern data workflows are inherently adaptive, repeatedly querying the same dataset to refine and validate sequential decisions, but such adaptivity can lead to overfitting and invalid statistical inference. Adaptive Data Analysis (ADA) mechanisms address this challenge; however, there is a fundamental tension between computational efficiency and sample complexity. For $T$ rounds of adaptive analysis, computationally efficient algorithms typically incur suboptimal $O(\\sqrt{T})$ sample complexity, whereas statistically optimal $O(\\log T)$ algorithms are computationally intractable under standard cryptographic assumptions. In this work, we shed light on this trade-off by identifying a natural class of data distributions under which both computational efficiency and optimal sample complexity are achievable. We propose a computationally efficient ADA mechanism that attains optimal $O(\\log T)$ sample complexity when the data distribution is dense with respect to a known prior. This setting includes, in particular, feature--label data distributions arising in distribution-specific learning. As a consequence, our mechanism also yields a sample-efficient (i.e., $O(\\log T)$ samples) statistical query oracle in the distribution-specific setting. Moreover, although our algorithm is not based on differential privacy, it satisfies a relaxed privacy notion known as Predicate Singling Out (PSO) security (Cohen and Nissim, 2020). Our results thus reveal an inherent connection between adaptive data analysis and privacy beyond differential privacy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08844", "categories": ["cond-mat.mes-hall", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.08844", "abs": "https://arxiv.org/abs/2602.08844", "authors": ["Ipsita Mandal"], "title": "Unconventional magnetoelectric conductivity and electrochemical response from dipole-like sources of Berry curvature", "comment": "14 pages, 4 figures", "summary": "We compute longitudinal magnetoelectric conductivity ($\u03c3_{zz}$) and nonlinear electrochemical response (ECR), applying the semiclassical Boltzmann formalism, for three-dimensional nodal-ring semimetals (vortex nodal-rings and $\\mathcal P \\mathcal T$-symmetric nodal-rings) and three-band Hopf semimetals. While the nodal-curves of the former are taken to lie along the $k_z = 0$-plane, the nodal points of the latter harbour dipoles in their Berry-curvature (BC) profile, with the dipole's axis aligned along the $k_z$-axis. All these systems are topological and are unified on the aspect that their bands possess a vanishing Chern number. The linear response, $\u03c3_{zz}$, is obtained from an exact solution when the systems are subjected to collinear electric and magnetic fields applied along the anisotropy axis, viz. $\\boldsymbol{\\hat z}$. The nonlinear part involves third-rank tensors representing second-order response coefficients, relating the electrical current to the combined effects of the gradient of the chemical potential and an external electric field. We analyse the similarities of the response arising from the vortex nodal-rings and the Hopf semimetals, which can be traced to the dipole-like sources in their BC fields.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07375", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07375", "abs": "https://arxiv.org/abs/2602.07375", "authors": ["Peiqi Yu", "Jinhao Wang", "Xinyi Sui", "Nam Ling", "Wei Wang", "Wei Jiang"], "title": "Efficient Post-Training Pruning of Large Language Models with Statistical Correction", "comment": "11 pages, 2 figures, 5 tables", "summary": "Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07591", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07591", "abs": "https://arxiv.org/abs/2602.07591", "authors": ["Botong Li", "Shisong Luo", "Jaeheon Jung", "Bobby G. Duersch", "Cheng Chang", "Lucas Lau", "Zonghao Zhang", "Jianhua Li", "Hunter Ellis", "Imteaz Rahaman", "Roy Byung Kyu Chung", "Kai Fu", "Yuji Zhao"], "title": "Thermal Stability and Phase Transformation of Conductive $\u03b1$-$(\\mathrm{Al}_{x}\\mathrm{Ga}_{1-x})_{2}\\mathrm{O}_{3}/\\mathrm{Ga}_{2}\\mathrm{O}_{3}$ Heterostructures on Sapphire Substrates", "comment": "13 pages; 4 figures", "summary": "Thermal stability and phase transformation of conductive $\u03b1$-$(\\mathrm{Al}_{0.16}\\mathrm{Ga}_{0.84})_{2}\\mathrm{O}_{3}/\\mathrm{Ga}_{2}\\mathrm{O}_{3}$ heterostructures on sapphire substrates were investigated using in situ high-temperature X-ray diffraction (HT-XRD), scanning electron microscopy (SEM), and atomic force microscopy (AFM). Conductive $\u03b1$-$(\\mathrm{Al}_{0.16}\\mathrm{Ga}_{0.84})_{2}\\mathrm{O}_{3}/\\mathrm{Ga}_{2}\\mathrm{O}_{3}$ heterostructures with fluorine (F) doping were grown by mist chemical vapor deposition on sapphire substrates, achieving a Hall mobility of $28~\\mathrm{cm^{2}\\,V^{-1}\\,s^{-1}}$ and an electron concentration of $1.4\\times10^{20}~\\mathrm{cm^{-3}}$. The heterostructures exhibited thermal stability up to approximately $550$--$", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07209", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07209", "abs": "https://arxiv.org/abs/2602.07209", "authors": ["Spencer Teetaert", "Giammarco Caroleo", "Marco Pontin", "Sven Lilge", "Jessica Burgner-Kahrs", "Timothy D. Barfoot", "Perla Maiolino"], "title": "Continuum Robot Localization using Distributed Time-of-Flight Sensors", "comment": null, "summary": "Localization and mapping of an environment are crucial tasks for any robot operating in unstructured environments. Time-of-flight (ToF) sensors (e.g.,~lidar) have proven useful in mobile robotics, where high-resolution sensors can be used for simultaneous localization and mapping. In soft and continuum robotics, however, these high-resolution sensors are too large for practical use. This, combined with the deformable nature of such robots, has resulted in continuum robot (CR) localization and mapping in unstructured environments being a largely untouched area. In this work, we present a localization technique for CRs that relies on small, low-resolution ToF sensors distributed along the length of the robot. By fusing measurement information with a robot shape prior, we show that accurate localization is possible despite each sensor experiencing frequent degenerate scenarios. We achieve an average localization error of 2.5cm in position and 7.2\u00b0 in rotation across all experimental conditions with a 53cm long robot. We demonstrate that the results are repeated across multiple environments, in both simulation and real-world experiments, and study robustness in the estimation to deviations in the prior map.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07586", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07586", "abs": "https://arxiv.org/abs/2602.07586", "authors": ["Sixu Xiao", "Yong Zeng", "Haotian Rong", "Yanqun Tang"], "title": "A Scalable Cloud-Edge Collaborative CKM Construction Framework Enabled by a Foundation Prior Model", "comment": "13 pages, 11 figures", "summary": "Channel knowledge maps (CKMs) provide a site-specific, location-indexed knowledge base that supports environment-aware communications and sensing in 6G networks. In practical deployments, CKM observations are often noisy and irregular due to coverage-induced sparsity and hardware-induced linear/nonlinear degradations. Conventional end-to-end algorithms couple CKM prior information with task- and device-specific observations, and require labeled data and separate training for each construction configuration, which is expensive and therefore incompatible with scalable edge deployments. Motivated by the trends toward cloud-edge collaboration and the Artificial Intelligence - Radio Access Network (AI-RAN) paradigm, we develop a cloud-edge collaborative framework for scalable CKM construction, which enables knowledge sharing across tasks, devices, and regions by explicitly decoupling a generalizable CKM prior from the information provided by local observations. A foundation model is trained once in the cloud using unlabeled data to learn a generalizable CKM prior. During inference, edge nodes combine the shared prior with local observations. Experiments on the CKMImageNet dataset show that the proposed method achieves competitive construction accuracy while substantially reducing training cost and data requirements, mitigating negative transfer, and offering clear advantages in generalization and deployment scalability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08254", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08254", "abs": "https://arxiv.org/abs/2602.08254", "authors": ["Arman Aghaee", "Sepehr Asgarian", "Jouhyun Jeon"], "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities", "comment": "Presented in AAAI 2026 Singapore at the workshop of Health Intelligence", "summary": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08724", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.08724", "abs": "https://arxiv.org/abs/2602.08724", "authors": ["Geng Lin", "Matthias Zwicker"], "title": "Rotated Lights for Consistent and Efficient 2D Gaussians Inverse Rendering", "comment": "Project Page: https://rotlight-ir.github.io/", "summary": "Inverse rendering aims to decompose a scene into its geometry, material properties and light conditions under a certain rendering model. It has wide applications like view synthesis, relighting, and scene editing. In recent years, inverse rendering methods have been inspired by view synthesis approaches like neural radiance fields and Gaussian splatting, which are capable of efficiently decomposing a scene into its geometry and radiance. They then further estimate the material and lighting that lead to the observed scene radiance. However, the latter step is highly ambiguous and prior works suffer from inaccurate color and baked shadows in their albedo estimation albeit their regularization. To this end, we propose RotLight, a simple capturing setup, to address the ambiguity. Compared to a usual capture, RotLight only requires the object to be rotated several times during the process. We show that as few as two rotations is effective in reducing artifacts. To further improve 2DGS-based inverse rendering, we additionally introduce a proxy mesh that not only allows accurate incident light tracing, but also enables a residual constraint and improves global illumination handling. We demonstrate with both synthetic and real world datasets that our method achieves superior albedo estimation while keeping efficient computation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08303", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08303", "abs": "https://arxiv.org/abs/2602.08303", "authors": ["Shun Hirose", "Shiu Mochiyama", "Yoshihiko Susuki"], "title": "Experimental Realization of Koopman-Model Predictive Control for an AC-DC Converter", "comment": "6 pages, 5 figures, ISIE", "summary": "This paper experimentally demonstrates the Koopman-Model Predictive Control (K-MPC) for a real AC-DC converter. The converter is typically modeled with a nonlinear time-variant plant. We introduce a new dynamical approach to lifting measurable dynamics from the plant and constructing a linear time-invariant model that is consistent with control objectives of the converter. We show that the lifting approach, combined with the K-MPC controller, performs well across the full experimental system and outperforms existing control strategies in terms of both steady-state and transient responses.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08862", "categories": ["cs.LG", "cs.DS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08862", "abs": "https://arxiv.org/abs/2602.08862", "authors": ["Lunjia Hu", "Jon Schneider", "Yifan Wu"], "title": "Near-optimal Swap Regret Minimization for Convex Losses", "comment": null, "summary": "We give a randomized online algorithm that guarantees near-optimal $\\widetilde O(\\sqrt T)$ expected swap regret against any sequence of $T$ adaptively chosen Lipschitz convex losses on the unit interval. This improves the previous best bound of $\\widetilde O(T^{2/3})$ and answers an open question of Fishelson et al. [2025b]. In addition, our algorithm is efficient: it runs in $\\mathsf{poly}(T)$ time. A key technical idea we develop to obtain this result is to discretize the unit interval into bins at multiple scales of granularity and simultaneously use all scales to make randomized predictions, which we call multi-scale binning and may be of independent interest. A direct corollary of our result is an efficient online algorithm for minimizing the calibration error for general elicitable properties. This result does not require the Lipschitzness assumption of the identification function needed in prior work, making it applicable to median calibration, for which we achieve the first $\\widetilde O(\\sqrt T)$ calibration error guarantee.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07376", "abs": "https://arxiv.org/abs/2602.07376", "authors": ["Usman Naseem", "Gautam Siddharth Kashyap", "Sushant Kumar Ray", "Rafiq Ali", "Ebad Shabbir", "Abdullah Mohammad"], "title": "Do Large Language Models Reflect Demographic Pluralism in Safety?", "comment": "Accepted at EACL Findings 2026", "summary": "Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07597", "categories": ["cond-mat.mtrl-sci", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2602.07597", "abs": "https://arxiv.org/abs/2602.07597", "authors": ["J. Galiana", "J. Redondo", "R. Pic\u00f3", "V. J. S\u00e1nchez-Morcillo"], "title": "Acoustic wave scattering by spatio-temporal interfaces", "comment": "18 pages, 10 figures", "summary": "Space-time materials are obtained by modulating a physical medium with a traveling-wave perturbation of one or several of its constitutive parameters, such as the density or the bulk modulus in the case of acoustic materials. When this modulation has the form of a moving and abrupt (subwavelength) transition between two parameter values, we refer to a spatio-temporal interface, which may be considered as a building block for more complex space-time materials. This work considers the problem interaction and scattering of acoustic waves with a single spatio-temporal interface, and a sequence of two interfaces forming a slab. Several regimes defined by the relation between the sound propagation velocities and the interface velocity (namely subsonic, intersonic, and supersonic regimes) are discussed. Analytical expressions for the frequency conversions and scattering coefficients are obtained, and compared with numerical simulations based on an equivalent FTFD squeme.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07623", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07623", "abs": "https://arxiv.org/abs/2602.07623", "authors": ["Pan Tang", "Huixin Xu", "Jianhua Zhang", "Ximan Liu", "Enrui Liu", "Haiyang Miao", "Xiaodong Sun", "Wei Jiang", "Guangyi Liu"], "title": "A Tutorial on 3GPP Rel-19 Channel Modeling for 6G FR3 (7-24 GHz): From Standard Specification to Simulation Implementation", "comment": null, "summary": "The upper-mid band (7-24 GHz), designated as Frequency Range 3 (FR3), has emerged as a definitive ``golden band\" for 6G networks, strategically balancing the wide coverage of sub-6 GHz with the high capacity of mmWave. To compensate for the severe path loss inherent to this band, the deployment of Extremely Large Aperture Arrays (ELAA) is indispensable. However, the legacy 3GPP TR 38.901 channel model faces critical validity challenges when applied to 6G FR3, stemming from both the distinct propagation characteristics of this frequency band and the fundamental physical paradigm shift induced by ELAA. In response, 3GPP Release 19 (Rel-19) has validated the model through extensive new measurements and introduced significant enhancements. This tutorial provides a comprehensive guide to the Rel-19 channel model for 6G FR3, bridging the gap between standardization specifications and practical simulation implementation. First, we provide a high-level overview of the fundamental principles of the 3GPP channel modeling framework. Second, we detail the specific enhancements and modifications introduced in Rel-19, including the rationale behind the new Suburban Macro (SMa) scenario, the mathematical modeling of ELAA-driven features such as near-field and spatial non-stationarity, and the recalibration of large-scale parameters. Overall, this tutorial serves as an essential guide for researchers and engineers to master the latest 3GPP channel modeling methodology, laying a solid foundation for the accurate design and performance evaluation of future 6G FR3 networks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08435", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.08435", "abs": "https://arxiv.org/abs/2602.08435", "authors": ["Davide Tebaldi", "Roberto Zanasi"], "title": "An Approach for the Qualitative Graphical Representation of the Describing Function in Nonlinear Systems Stability Analysis", "comment": null, "summary": "The describing function method is a useful tool for the qualitative analysis of limit cycles in the stability analysis of nonlinear systems. This method is inherently approximate; therefore, it should be used for a fast qualitative analysis of the considered systems. However, plotting the exact describing function requires heavy mathematical calculations, reducing interest in this method especially from the point of view of control education. The objective of this paper is to enhance the describing function method by providing a new approach for the qualitative plotting of the describing function for piecewise nonlinearities involving discontinuities. Unlike the standard method, the proposed approach allows for a straightforward, hand-drawn plotting of the describing function using the rules introduced in this paper, simply by analyzing the shape of the nonlinearity. The proposed case studies show that the limit cycles estimation performed using the standard exact plotting of the describing function yields the same qualitative results as those obtained using the proposed qualitative method for plotting the describing function.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07491", "categories": ["cs.AI", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07491", "abs": "https://arxiv.org/abs/2602.07491", "authors": ["Isabella A. Stewart", "Tarjei Paule Hage", "Yu-Chuan Hsu", "Markus J. Buehler"], "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design", "comment": null, "summary": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07381", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07381", "abs": "https://arxiv.org/abs/2602.07381", "authors": ["Gautam Siddharth Kashyap", "Mark Dras", "Usman Naseem"], "title": "When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified", "comment": "Accepted at EACL Mains 2026", "summary": "Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07753", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07753", "abs": "https://arxiv.org/abs/2602.07753", "authors": ["Boris Slautin", "Sergei Kalinin"], "title": "Sequential versus Manifold Bayesian Optimization under Realistic Experimental Time Constraints", "comment": "17 pages, 5 figures", "summary": "Bayesian optimization (BO) is widely used for autonomous materials discovery, yet its classical sequential formulation is insufficient for design of experimental workflows that often combine parallel or batch synthesis with inherently serial characterization. Methods such as combinatorial spread libraries and printed libraries sample a defined low-D manifold in the chemical space of the system. Here, we introduce a time-aware framework for comparing sequential and manifold BO under experimentally realistic constraints. By explicitly modeling synthesis and characterization times, we define an effective experimental time metric that enables fair, time-normalized benchmarking of optimization strategies. Using numerical experiments in ternary and quaternary compositional spaces, we show that sequential BO remains optimal for short-term experiments or when batching provides no effective time advantage, whereas manifold BO becomes favorable once multiplexed synthesis enables faster accumulation of measurements. We identify a small set of physically interpretable parameters that govern the transition between these regimes. These results establish a general, experimentally grounded framework for selecting optimization strategies in self-driving laboratories and autonomous materials discovery workflows. The accompanying analysis code is publicly available at https://github.com/Slautin/2025_GP_BO_Manifolds.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07264", "categories": ["cs.RO", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07264", "abs": "https://arxiv.org/abs/2602.07264", "authors": ["Jacopo Panerati", "Sina Sajjadi", "Sina Soleymanpour", "Varunkumar Mehta", "Iraj Mantegh"], "title": "aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones", "comment": null, "summary": "Unmanned aerial vehicles are rapidly transforming multiple applications, from agricultural and infrastructure monitoring to logistics and defense. Introducing greater autonomy to these systems can simultaneously make them more effective as well as reliable. Thus, the ability to rapidly engineer and deploy autonomous aerial systems has become of strategic importance. In the 2010s, a combination of high-performance compute, data, and open-source software led to the current deep learning and AI boom, unlocking decades of prior theoretical work. Robotics is on the cusp of a similar transformation. However, physical AI faces unique hurdles, often combined under the umbrella term \"simulation-to-reality gap\". These span from modeling shortcomings to the complexity of vertically integrating the highly heterogeneous hardware and software systems typically found in field robots. To address the latter, we introduce aerial-autonomy-stack, an open-source, end-to-end framework designed to streamline the pipeline from (GPU-accelerated) perception to (flight controller-based) action. Our stack allows the development of aerial autonomy using ROS2 and provides a common interface for two of the most popular autopilots: PX4 and ArduPilot. We show that it supports over 20x faster-than-real-time, end-to-end simulation of a complete development and deployment stack -- including edge compute and networking -- significantly compressing the build-test-release cycle of perception-based autonomy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07714", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07714", "abs": "https://arxiv.org/abs/2602.07714", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "MI-ISAC: Magneto-Inductive Integrated Sensing and Communication in the Reactive Near-Field for RF-Denied Environments", "comment": null, "summary": "Radio-frequency integrated sensing and communication (RF-ISAC) is ineffective inunderground, underwater, and in-body environments where conductive media attenuate electromagnetic waves by tens of dB per meter. This article presents magneto-inductive ISAC (MI-ISAC), a paradigm that exploits the reactive near-field quasi-static coupling inherent to MI links, enabling a fundamentally different approach to ISAC in these RF-denied environments. Five foundational results are established: (i)~tri-axial coils are necessary and sufficient for identifiable joint range-and-angle estimation; (ii)~coupling strength changes sharply with range, enabling theoretical sub-millimeter accuracy at typical MI distances despite kHz-level bandwidth; (iii)~time-of-flight is ineffective under such narrow bandwidth, but the coupling gradient provides approximately six orders of magnitude finer resolution; (iv)~MI-ISAC can provide 4--10+\\,dB sensing gain over time-division baselines; and (v)~the MI-MIMO channel is geometry-invariant and well-conditioned across all orientations. Applications and a research roadmap are discussed.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08799", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08799", "abs": "https://arxiv.org/abs/2602.08799", "authors": ["Robin Dehler", "Michael Buchholz"], "title": "A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles", "comment": "8 pages, 6 figures, 2 tables, published in RA-L", "summary": "Function offloading is a promising solution to address limitations concerning computational capacity and available energy of Connected Automated Vehicles~(CAVs) or other autonomous robots by distributing computational tasks between local and remote computing devices in form of distributed services. This paper presents a generic function offloading framework that can be used to offload an arbitrary set of computational tasks with a focus on autonomous driving. To provide flexibility, the function offloading framework is designed to incorporate different offloading decision making algorithms and quality of service~(QoS) requirements that can be adjusted to different scenarios or the objectives of the CAVs. With a focus on the applicability, we propose an efficient location-based approach, where the decision whether tasks are processed locally or remotely depends on the location of the CAV. We apply the proposed framework on the use case of service-oriented trajectory planning, where we offload the trajectory planning task of CAVs to a Multi-Access Edge Computing~(MEC) server. The evaluation is conducted in both simulation and real-world application. It demonstrates the potential of the function offloading framework to guarantee the QoS for trajectory planning while improving the computational efficiency of the CAVs. Moreover, the simulation results also show the adaptability of the framework to diverse scenarios involving simultaneous offloading requests from multiple CAVs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08477", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08477", "abs": "https://arxiv.org/abs/2602.08477", "authors": ["Akbar Anbar Jafari", "Gholamreza Anbarjafari"], "title": "A Multi-physics Simulation Framework for High-power Microwave Counter-unmanned Aerial System Design and Performance Evaluation", "comment": "17 pages, 15 figures", "summary": "The proliferation of small unmanned aerial systems (sUAS) operating under autonomous guidance has created an urgent need for non-kinetic neutralization methods that are immune to conventional radio-frequency jamming. This paper presents a comprehensive multi-physics simulation framework for the design and performance evaluation of a high-power microwave (HPM) counter-UAS system operating at 2.45\\,GHz. The framework integrates electromagnetic propagation modelling, antenna pattern analysis, electromagnetic coupling to unshielded drone wiring harnesses, and a sigmoid-based semiconductor damage probability model calibrated to published CMOS latchup thresholds. A 10{,}000-trial Monte Carlo analysis incorporating stochastic variations in transmitter power, antenna pointing error, target wire orientation, polarization mismatch, and component damage thresholds yields system-level kill probabilities with 95\\% confidence intervals. For a baseline configuration of 25\\,kW continuous-wave power and a 60\\,cm parabolic reflector (21.2\\,dBi gain), the Monte Carlo simulation predicts a kill probability of $51.4\\pm1.0$\\% at 20\\,m, decreasing to $13.1\\pm0.7$\\% at 40\\,m. Pulsed operation at 500\\,kW peak power (1\\% duty cycle) extends the 90\\% kill range from approximately 18\\,m to 88\\,m. The framework further provides parametric design maps, safety exclusion zone calculations compliant with ICNIRP 2020 guidelines, thermal management requirements, and waveguide mode analysis. All simulation codes and results are provided for full reproducibility.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07897", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.07897", "abs": "https://arxiv.org/abs/2602.07897", "authors": ["Tao Jiang", "Jigang Wang", "Yong-Xin Yao"], "title": "CDW Gap Collapse and Weyl State Restoration in (TaSe4)2I via Coherent Phonons: A First-Principles Study", "comment": null, "summary": "Coherent phonon excitation offers a nonthermal route to control quantum phases of condensed matter. In this work, we employ first-principles calculations to investigate the phonon landscape of (TaSe4)2I in its charge-density-wave (CDW) phase. We identify nine symmetry-preserving Raman-active modes that can suppress the Gamma-Z direct gap to the meV scale and render the system globally gapless by generating Weyl nodes at generic k points. Among them, the 2.51 THz CDW amplitude mode A(18) directly weakens the Ta-chain tetramerization, approaching a transient restoration of the uniform-chain geometry. It is also the most efficient mode owing to its low frequency and a relatively small critical displacement dominated by Ta motions. Other Raman modes, dominated by Se vibrations, require significantly larger displacements to reach the Weyl-semimetallic regime and are generally less effective than A(18) at reducing the Ta-chain tetramerization. Furthermore, we explore nonlinear phonon-phonon interactions and find that the low-frequency infrared-active mode B3(7) (1.14 THz) exhibits strong anharmonic coupling with A(18), providing an indirect pathway to drive the system toward a Weyl-semimetallic regime. Our results provide predictive insight for ultrafast pump-probe experiments and present a generalizable framework for lattice-driven topological switching in quasi-one-dimensional quantum materials.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07382", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07382", "abs": "https://arxiv.org/abs/2602.07382", "authors": ["Debtanu Datta", "Rajdeep Mukherjee", "Adrijit Goswami", "Saptarshi Ghosh"], "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi", "comment": "19 pages, 5 figures, 8 tables", "summary": "Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07758", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07758", "abs": "https://arxiv.org/abs/2602.07758", "authors": ["Brandon Pedroza-Rojas", "David W. Facemyer", "Ariadna S\u00e1nchez-Castillo"], "title": "Bernal Stacking and Symmetry-Inequivalent Antiferromagnetism in MSi$_2$N$_4$ Heterobilayers", "comment": "15 pages, 6 figures", "summary": "Layered MA$_2$Z$_4$ compounds, structural relatives of MoS$_2$ discovered in 2020, exhibit rich magnetic behavior arising from reduced dimensionality, noncentrosymmetric lattice symmetries, and stacking-dependent exchange interactions. Here, we investigate Bernal-like stackings in H-phase MA$_2$Z$_4$ (M = Mn and Fe; A = Si; Z = N) monolayers and bilayers by combining first-principles spin-dependent relaxation energies with a localized-spin Heisenberg description. From density-functional calculations, we extract the dominant intralayer exchange couplings up to third-nearest neighbors and the leading interlayer exchanges up to second-nearest neighbors, enabling construction of an effective bilayer spin Hamiltonian. We first analyze interface-driven proximity effects within a ferromagnetic reference configuration, demonstrating how recovery of AB-type stacking and spin alignment--while varying only the transition-metal species--provides a route for selectively tuning magnetic order and symmetry breaking within the P$\\bar{6}$m2 space group. Building on this microscopic understanding of the bonding environment, we then examine antiferromagnetic ordering tendencies in the coupled layers. Exact diagonalization of the resulting bilayer Hamiltonian reveals the magnetic ground state and low-lying excitation spectrum, showing that the interlayer exchange is not merely perturbative but competes directly with intralayer interactions in stabilizing the observed spin configurations. These results establish Bernal-stacked MA$_2$Z$_4$ bilayers as a platform in which stacking geometry and exchange hierarchy jointly govern magnetic reconstruction, offering a controlled pathway toward domain selection and spin-texture engineering in low-dimensional van der Waals materials.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07322", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07322", "abs": "https://arxiv.org/abs/2602.07322", "authors": ["Jindou Jia", "Gen Li", "Xiangyu Chen", "Tuo An", "Yuxuan Hu", "Jingliang Li", "Xinying Guo", "Jianfei Yang"], "title": "Action-to-Action Flow Matching", "comment": "18 pages, 18 figures", "summary": "Diffusion-based policies have recently achieved remarkable success in robotics by formulating action prediction as a conditional denoising process. However, the standard practice of sampling from random Gaussian noise often requires multiple iterative steps to produce clean actions, leading to high inference latency that incurs a major bottleneck for real-time control. In this paper, we challenge the necessity of uninformed noise sampling and propose Action-to-Action flow matching (A2A), a novel policy paradigm that shifts from random sampling to initialization informed by the previous action. Unlike existing methods that treat proprioceptive action feedback as static conditions, A2A leverages historical proprioceptive sequences, embedding them into a high-dimensional latent space as the starting point for action generation. This design bypasses costly iterative denoising while effectively capturing the robot's physical dynamics and temporal continuity. Extensive experiments demonstrate that A2A exhibits high training efficiency, fast inference speed, and improved generalization. Notably, A2A enables high-quality action generation in as few as a single inference step (0.56 ms latency), and exhibits superior robustness to visual perturbations and enhanced generalization to unseen configurations. Lastly, we also extend A2A to video generation, demonstrating its broader versatility in temporal modeling. Project site: https://lorenzo-0-0.github.io/A2A_Flow_Matching.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07896", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07896", "abs": "https://arxiv.org/abs/2602.07896", "authors": ["Varun Sarathchandran", "Geert Leus"], "title": "Joint Simplicial Complex Learning via Binary Linear Programming", "comment": null, "summary": "Learning the topology of higher-order networks from data is a fundamental challenge in many signal processing and machine learning applications. Simplicial complexes provide a principled framework for modeling multi-way interactions, yet learning their structure is challenging due to the strong coupling across different simplicial levels imposed by the inclusion property. In this work, we propose a joint framework for simplicial complex learning that enforces the inclusion property through a linear constraint, enabling the formulation of the problem as a binary linear program. The objective function consists of a combination of smoothness measures across all considered simplicial levels, allowing for the incorporation of arbitrary smoothness criteria. This formulation enables the simultaneous estimation of edges and higher-order simplices within a single optimization problem. Experiments on simulated and real-world data demonstrate that the proposed joint approach outperforms hierarchical and greedy baselines, while more faithfully enforcing higher-order structural priors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08598", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08598", "abs": "https://arxiv.org/abs/2602.08598", "authors": ["Katharina Kaiser", "Gustavo Valverde", "Gabriela Hug"], "title": "Residential Peak Load Reduction via Direct Load Control under Limited Information", "comment": null, "summary": "Thermostatically controlled loads and electric vehicles offer flexibility to reduce power peaks in low-voltage distribution networks. This flexibility can be maximized if the devices are coordinated centrally, given some level of information about the controlled devices. In this paper, we propose novel optimization-based control schemes with prediction capabilities that utilize limited information from heat pumps, electric water heaters, and electric vehicles. The objective is to flatten the total load curve seen by the distribution transformer by restricting the times at which the available flexible loads are allowed to operate, subject to the flexibility constraints of the loads to preserve customers' comfort. The original scheme was tested in a real-world setup, considering both winter and summer days. The pilot results confirmed the technical feasibility but also informed the design of an improved version of the controller. Computer simulations using the adjusted controller show that, compared to the original formulation, the improved scheme achieves greater peak reductions in summer. Additionally, comparisons were made with an ideal controller, which assumes perfect knowledge of the inflexible load profile, the models of the controlled devices, the hot water and space heating demand, and future electric vehicle charging sessions. The proposed scheme with limited information achieves almost half of the potential average daily peak reduction that the ideal controller with perfect knowledge would achieve.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07976", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.07976", "abs": "https://arxiv.org/abs/2602.07976", "authors": ["Xinyu Chen", "Jingjing Gao", "Shuang Wu", "Zhiwei Huang", "Zhongxun Guo", "Canyu Hong", "Ruohan Chen", "Mingyan Luo", "Zhaochen Liu", "Zeyuan Sun", "Wei Ruan", "Jing Wang", "Yuanbo Zhang", "Shiwei Wu"], "title": "Unveiling the impact of anti-site defects in magnetic transitions of few-layer MnBi2Te4 by operando heating", "comment": "15 pages, 4 figures", "summary": "As the first experimentally discovered intrinsic magnetic topological insulator, MnBi2Te4 has attracted widespread attentions, providing a unique platform for the exploration of topological quantum phases, such as quantum anomalous Hall effect and axion insulator state. Despite the increasing number of potential factors affecting samples being identified, obtaining the high-quality device performance with desired topological quantum phases remains a challenge. In this work, by comparing the reflective magnetic circular dichroism (RMCD) of crystals with different defect densities that are characterized by atomically resolved scanning tunneling microscopy, we demonstrate that anti-site defects play an essential role in achieving ideal magnetic states. By measuring RMCD hysteresis loops with operando heating, we find that MnBi2Te4 few-layer samples are highly susceptible to thermal impact, even at temperature as low as 45\u00b0C. The magnetic behavior of heating-treated samples is akin to that of samples fabricated into devices, revealing the thermal impact on devices as well. Starting from few-layers with ideal layer-dependent magnetic order, thermal heating leads to the convergence of magnetization and transition fields between odd- and even-layers. The observed heating-induced magnetic evolution can serve as a valuable reference for assessing the sample quality or the density of anti-site defects. Our findings not only point out the long-standing hidden factor that arose controversies in MnBi2Te4, but also pave the way for controllably engineering the topological quantum phenomena.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07447", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07447", "abs": "https://arxiv.org/abs/2602.07447", "authors": ["Liviu P Dinu", "Ana Sabina Uban", "Bogdan Iordache", "Anca Dinu", "Simona Georgescu"], "title": "Measuring cross-language intelligibility between Romance languages with computational tools", "comment": "16 pages, 7 figures, 2 tables", "summary": "We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07791", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.07791", "abs": "https://arxiv.org/abs/2602.07791", "authors": ["Sampreeti Bhattacharya", "Jianhang Xu", "Ruiyi Zhou", "Yosuke Kanai"], "title": "Proton Quantum Effects on Electronic Excitation in Hydrogen-bonded Organic Solid: A First-Principles Green's Function Theory Study", "comment": null, "summary": "Nuclear quantum effects of protons on electronic excitations in hydrogen-bonded organic materials remains underexplored. In theoretical studies, modeling excitons in these extended systems is particularly difficult because they tend to have a large exciton binding energy and sometimes exhibit charge transfer character. We demonstrate how first-principles Green's function theory combined with the nuclear-electronic orbital method enables us to examine the nature of excitons in a prototypical organic solid of eumelanin, for which the extensive hydrogen bonds have been proposed to facilitate the formation of delocalized excitons. We investigate how the quantization of protons impacts electronic excitations. We discuss the extent to which the resulting proton quantum effects can be described as being derived from structure and how they induce molecular-level anisotropy for the excitons in the organic solid.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07326", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07326", "abs": "https://arxiv.org/abs/2602.07326", "authors": ["Edgar Lee", "Junho Choi", "Taemin Kim", "Changjoo Nam", "Seokhwan Jeong"], "title": "Why Look at It at All?: Vision-Free Multifingered Blind Grasping Using Uniaxial Fingertip Force Sensing", "comment": "Submitted to Journal (under review)", "summary": "Grasping under limited sensing remains a fundamental challenge for real-world robotic manipulation, as vision and high-resolution tactile sensors often introduce cost, fragility, and integration complexity. This work demonstrates that reliable multifingered grasping can be achieved under extremely minimal sensing by relying solely on uniaxial fingertip force feedback and joint proprioception, without vision or multi-axis/tactile sensing. To enable such blind grasping, we employ an efficient teacher-student training pipeline in which a reinforcement-learned teacher exploits privileged simulation-only observations to generate demonstrations for distilling a transformer-based student policy operating under partial observation. The student policy is trained to act using only sensing modalities available at real-world deployment. We validate the proposed approach on real hardware across 18 objects, including both in-distribution and out-of-distribution cases, achieving a 98.3~$\\%$ overall grasp success rate. These results demonstrate strong robustness and generalization beyond the simulation training distribution, while significantly reducing sensing requirements for real-world grasping systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07959", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07959", "abs": "https://arxiv.org/abs/2602.07959", "authors": ["Hyeonsu Lyu", "Yumin Kim", "Hyun Jong Yang"], "title": "End-to-End Secure Connection Probability in MultiLayer Networks with Heterogeneous Rician Fading", "comment": null, "summary": "Ensuring physical-layer security in non-terrestrial networks (NTNs) is challenging due to their global coverage and multi-hop relaying across heterogeneous network layers, where the locations and channels of potential eavesdroppers are typically unknown. In this work, we derive a tractable closedform expression of the end-to-end secure connection probability (SCP) of multi-hop relay routes under heterogeneous Rician fading. The resulting formula shares the same functional form as prior Rayleigh-based approximations but for the coefficients, thereby providing analytical support for the effectiveness of heuristic posterior coefficient calibration adopted in prior work. Numerical experiments under various conditions show that the proposed scheme estimates the SCP with an 1%p error in most cases; and doubles the accuracy compared with the conventional scheme even in the worst case. As a case study, we apply the proposed framework to real-world space-air-groundsea integrated network dataset, showing that the derived SCP accurately captures observed security trends in practical settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08633", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08633", "abs": "https://arxiv.org/abs/2602.08633", "authors": ["Wasif H. Syed", "Juan E. Machado", "Johannes Schiffer"], "title": "A Primal-Dual-Based Active Fault-Tolerant Control Scheme for Cyber-Physical Systems: Application to DC Microgrids", "comment": null, "summary": "We consider the problem of active fault-tolerant control in cyber-physical systems composed of strictly passive linear-time invariant dynamic subsystems. We cast the problem as a constrained optimization problem and propose an augmented primal-dual gradient dynamics-based fault-tolerant control framework that enforces network-level constraints and provides optimality guarantees for the post-fault steady-state operation. By suitably interconnecting the primal-dual algorithm with the cyber-physical dynamics, we provide sufficient conditions under which the resulting closed-loop system possesses a unique and exponentially stable equilibrium point that satisfies the Karush--Kuhn--Tucker (KKT) conditions of the constrained problem. The framework's effectiveness is illustrated through numerical experiments on a DC microgrid.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08183", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08183", "abs": "https://arxiv.org/abs/2602.08183", "authors": ["Nusrat Rashid", "Shurui Yang", "Galyam Sanfo", "Isabelle Ewing", "Zahra Ibrahim Albu", "Xinjuan Li", "Tianhao Wu", "Prajna Bhatt", "Mathieu Prevot", "Laurent Piccolo", "Mahmoud Zendehdel", "Robert G. Palgrave", "Caterina Ducati", "Mojtaba Abdi-Jalebi"], "title": "Boosting high-current alkaline water electrolysis and carbon dioxide reduction with novel CuNiFe-based anodes", "comment": null, "summary": "The transition to a green hydrogen economy demands robust, scalable, and sustainable anodes for alkaline water electrolysis operating at industrial current densities (>1 A/cm2). However, achieving high activity and long-term stability under such conditions remains a formidable challenge with conventional catalysts. Here, we report a novel trimetallic CuNiFe anode fabricated through a rapid, single-step electrodeposition process at room temperature without organic additives. The catalyst exhibits an exceptionally low overpotential of <270 mV at 100 mA cm(-2) and operates stably for over 500 hours at 1 A cm(-2) in 30 wt% KOH. In a practical anion exchange membrane water electrolyzer (AEM-WE), the CuNiFe anode enables a current density of 2.5 A cm(-2) at only 2.5 V, with a voltage efficiency of 66.8%. Beyond water splitting, this anode also significantly enhances CO2 electrolysis, tripling the CO2 reduction current density and steering selectivity toward valuable multi-carbon products when paired with commercial copper cathodes. A cradle-to-gate life cycle assessment confirms that the CuNiFe anode reduces the carbon footprint by an order of magnitude and decreases environmental impacts by 40-60% across multiple categories compared to benchmark IrRuO2. Our work establishes a scalable, high-performance, and environmentally benign anode technology, paving the way for cost-effective electrochemical production of green hydrogen and carbon-neutral chemicals.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07451", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07451", "abs": "https://arxiv.org/abs/2602.07451", "authors": ["Huiling Zhen", "Weizhe Lin", "Renxi Liu", "Kai Han", "Yiming Li", "Yuchuan Tian", "Hanting Chen", "Xiaoguang Li", "Xiaosong Li", "Chen Chen", "Xianzhi Yu", "Mingxuan Yuan", "Youliang Yan", "Peifeng Qin", "Jun Wang", "Yu Wang", "Dacheng Tao", "Yunhe Wang"], "title": "DLLM Agent: See Farther, Run Faster", "comment": null, "summary": "Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07363", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07363", "abs": "https://arxiv.org/abs/2602.07363", "authors": ["Zihao Xu", "Runyu Lei", "Zihao Li", "Boxi Lin", "Ce Hao", "Jin Song Dong"], "title": "UEREBot: Learning Safe Quadrupedal Locomotion under Unstructured Environments and High-Speed Dynamic Obstacles", "comment": null, "summary": "Quadruped robots are increasingly deployed in unstructured environments. Safe locomotion in these settings requires long-horizon goal progress, passability over uneven terrain and static constraints, and collision avoidance against high-speed dynamic obstacles. A single system cannot fully satisfy all three objectives simultaneously: planning-based decisions can be too slow, while purely reactive decisions can sacrifice goal progress and passability. To resolve this conflict, we propose UEREBot (Unstructured-Environment Reflexive Evasion Robot), a hierarchical framework that separates slow planning from instantaneous reflexive evasion and coordinates them during execution. UEREBot formulates the task as a constrained optimal control problem blueprint. It adopts a spatial--temporal planner that provides reference guidance toward the goal and threat signals. It then uses a threat-aware handoff to fuse navigation and reflex actions into a nominal command, and a control barrier function shield as a final execution safeguard. We evaluate UEREBot in Isaac Lab simulation and deploy it on a Unitree Go2 quadruped equipped with onboard perception. Across diverse environments with complex static structure and high-speed dynamic obstacles, UEREBot achieves higher avoidance success and more stable locomotion while maintaining goal progress than representative baselines, demonstrating improved safety--progress trade-offs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08129", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08129", "abs": "https://arxiv.org/abs/2602.08129", "authors": ["Hanjun Park", "Aleksandr D. Kuznetsov", "Ville Viikari"], "title": "Adjustment of Cluster-Then-Predict Framework for Multiport Scatterer Load Prediction", "comment": null, "summary": "Predicting interdependent load values in multiport scatterers is challenging due to high dimensionality and complex dependence between impedance and scattering ability, yet this prediction remains crucial for the design of communication and measurement systems. In this paper, we propose a two-stage cluster-then-predict framework for multiple load values prediction task in multiport scatterers. The proposed cluster-then-predict approach effectively captures the underlying functional relation between S-parameters and corresponding load impedances, achieving up to a 46% reduction in Root Mean Square Error (RMSE) compared to the baseline when applied to gradient boosting (GB). This improvement is consistent across various clustering and regression methods. Furthermore, we introduce the Real-world Unified Index (RUI), a metric for quantitative analysis of trade-offs among multiple metrics with conflicting objectives and different scales, suitable for performance assessment in realistic scenarios. Based on RUI, the combination of K-means clustering and k-nearest neighbors (KNN) is identified as the optimal setup for the analyzed multiport scatterer.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08757", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08757", "abs": "https://arxiv.org/abs/2602.08757", "authors": ["Luigi Romano", "Ole Morten Aamo", "Miroslav Krsti\u0107", "Jan \u00c5slund", "Erik Frisk"], "title": "Stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics via singular perturbation analysis", "comment": "17 pages, 9 figures. Under review at Automatica", "summary": "This paper investigates the stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics, modeled as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). Motivated by the long-standing practice of neglecting transient tire dynamics in vehicle modeling and control, a rigorous justification is provided for such simplifications using singular perturbation theory. A perturbation parameter, defined as the ratio between a characteristic rolling contact length and the vehicle's longitudinal speed, is introduced to formalize the time-scale separation between rigid-body motion and tire dynamics. For sufficiently small values of this parameter, it is demonstrated that standard finite-dimensional techniques can be applied to analyze the local stability of equilibria and to design stabilizing controllers. Both state-feedback and output-feedback designs are considered, under standard stabilizability and detectability assumptions. Whilst the proposed controllers follow classical approaches, the novelty of the work lies in establishing the first mathematical framework that rigorously connects distributed tire models with conventional vehicle dynamics. The results reconcile decades of empirical findings with a formal theoretical foundation and open new perspectives for the analysis and control of ODE-PDE systems with distributed friction in automotive applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08773", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2602.08773", "abs": "https://arxiv.org/abs/2602.08773", "authors": ["Colin Lange", "Rodrigo Jaeschke-Ubiergo", "Atasi Chakraborty", "Xanthe H. Verbeek", "Libor \u0160mejkal", "Jairo Sinova", "Alexander Mook"], "title": "Emergent altermagnetism at surfaces of antiferromagnets: full symmetry classification and material identification", "comment": null, "summary": "We demonstrate the emergence of altermagnetism at the surfaces of antiferromagnets, vastly expanding the number of material candidates with altermagnetic characteristics and establishing a route to two-dimensional altermagnetism through surface-induced symmetry breaking. We do so by developing a surface spin group formalism that fully classifies all surface magnetic states and identifies altermagnetic surface spin groups that can arise at the surfaces of antiferromagnets. We use this formalism to identify over 140 antiferromagnetic entries from the MAGNDATA database with at least one altermagnetic surface, often times with multiple such surfaces in the same material. We illustrate this emergent phenomenon in a realistic Lieb lattice-based minimal model and present ab initio calculations on two representative material candidates, NaMnP and FeGe$_2$, exhibiting $d$-wave and $g$-wave surface altermagnetism, respectively. Our theory naturally resolves the contradiction of recent experimental reports of $d$-wave ARPES measurements on metallic Lieb lattice compounds that have been shown to be antiferromagnetic in the bulk. Hence, we establish a new paradigm for generating two-dimensional altermagnetism by functionalizing the abundant material class of collinear antiferromagnets as viable platforms for controlled surface altermagnetism, creating natural materials for future hybrid device implementation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07464", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07464", "abs": "https://arxiv.org/abs/2602.07464", "authors": ["Yijie Chen", "Yijin Liu", "Fandong Meng"], "title": "SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning", "comment": "The code is publicly available at https://github.com/pppa2019/SED-SFT", "summary": "Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07831", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07831", "abs": "https://arxiv.org/abs/2602.07831", "authors": ["Takahito Takeda", "Daigo Matsubara", "Yuki K. Wakabayashi", "Kohei Yamagami", "Munetoshi Seki", "Hitoshi Tabata", "Le Duc Anh", "Masaki Kobayashi", "Masaaki Tanaka", "Shinobu Ohya"], "title": "Epitaxial lift-off of La$_{2/3}$Sr$_{1/3}$MnO$_3$ membranes enabled by BaO sacrificial layers and restoration of the Curie temperature", "comment": null, "summary": "Ultrathin complex-oxide membranes provide a powerful platform for strain engineering, interfacial control, and heterogeneous integration; however, their formation remains constrained by the availability and performance of suitable water-soluble sacrificial layers. This letter demonstrates that barium oxide (BaO) serves as a highly efficient and rapidly dissolving water-soluble sacrificial layer, enabling the epitaxial lift-off and transfer of ultrathin La$_{2/3}$Sr$_{1/3}$MnO$_3$ (LSMO) membranes onto SiO$_x$/Si substrates. LSMO membranes with a thickness of approximately 8 nm are released using a BaO sacrificial layer grown by molecular beam epitaxy, while high crystallinity is preserved and Ba interdiffusion is limited to a narrow interfacial region of approximately 0.5 nm. Post-transfer oxygen annealing at 600 ${}^\\circ$C increases the Curie temperature ($T_C$) from 342 K to 346 K by eliminating Mn$^{2+}$ states associated with oxygen vacancies generated through oxygen extraction into the BaO layer. These results show that BaO provides a fast, scalable, and compositionally simple route for complex-oxide membrane release, while brief oxygen annealing is essential to restore the optimal Mn valence state and achieve the intrinsic high $T_C$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07388", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07388", "abs": "https://arxiv.org/abs/2602.07388", "authors": ["Yuxuan Hu", "Xiangyu Chen", "Chuhao Zhou", "Yuxi Liu", "Gen Li", "Jindou Jia", "Jianfei Yang"], "title": "Trace-Focused Diffusion Policy for Multi-Modal Action Disambiguation in Long-Horizon Robotic Manipulation", "comment": null, "summary": "Generative model-based policies have shown strong performance in imitation-based robotic manipulation by learning action distributions from demonstrations. However, in long-horizon tasks, visually similar observations often recur across execution stages while requiring distinct actions, which leads to ambiguous predictions when policies are conditioned only on instantaneous observations, termed multi-modal action ambiguity (MA2). To address this challenge, we propose the Trace-Focused Diffusion Policy (TF-DP), a simple yet effective diffusion-based framework that explicitly conditions action generation on the robot's execution history. TF-DP represents historical motion as an explicit execution trace and projects it into the visual observation space, providing stage-aware context when current observations alone are insufficient. In addition, the induced trace-focused field emphasizes task-relevant regions associated with historical motion, improving robustness to background visual disturbances. We evaluate TF-DP on real-world robotic manipulation tasks exhibiting pronounced multi-modal action ambiguity and visually cluttered conditions. Experimental results show that TF-DP improves temporal consistency and robustness, outperforming the vanilla diffusion policy by 80.56 percent on tasks with multi-modal action ambiguity and by 86.11 percent under visual disturbances, while maintaining inference efficiency with only a 6.4 percent runtime increase. These results demonstrate that execution-trace conditioning offers a scalable and principled approach for robust long-horizon robotic manipulation within a single policy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08163", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08163", "abs": "https://arxiv.org/abs/2602.08163", "authors": ["Hyeon Seok Rou", "Vincent Savaux", "Zeping Sui", "Giuseppe Thadeu Freitas de Abreu", "Zilong Liu"], "title": "AFDM: Evolving OFDM Towards 6G+", "comment": "Submitted to IEEE", "summary": "As the standardization of sixth generation (6G) wireless systems accelerates, there is a growing consensus in favor of evolutionary waveforms that offer new features while maximizing compatibility with orthogonal frequency division multiplexing (OFDM), which underpins the 4G and 5G systems. This article presents affine frequency division multiplexing (AFDM) as a premier candidate for 6G, offering intrinsic robustness for both high-mobility communications and integrated sensing and communication (ISAC) in doubly dispersive channels, while maintaining a high degree of synergy with the legacy OFDM. To this end, we provide a comprehensive analysis of AFDM, starting with a generalized fractional-delay-fractional-Doppler (FDFD) channel model that accounts for practical pulse shaping filters and inter-sample coupling. We then detail the AFDM transceiver architecture, demonstrating that it reuses nearly the entire OFDM pipeline and requires only lightweight digital pre- and post-processing. We also analyze the impact of hardware impairments, such as phase noise and carrier frequency offset, and explore advanced functionalities enabled by the chirp-parameter domain, including index modulation and physical-layer security. By evaluating the reusability across the radio-frequency, physical, and higher layers, the article demonstrates that AFDM provides a low-risk, feature-rich, and efficient path toward achieving high-fidelity communications in the later versions of 6G and beyond (6G+).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08767", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08767", "abs": "https://arxiv.org/abs/2602.08767", "authors": ["Luigi Romano", "Ole Morten Aamo", "Miroslav Krsti\u0107", "Jan \u00c5slund", "Erik Frisk"], "title": "Passivity-exploiting stabilization of semilinear single-track vehicle models with distributed tire friction dynamics", "comment": "17 pages, 10 figures. Under review at Automatica", "summary": "This paper addresses the local stabilization problem for semilinear single-track vehicle models with distributed tire friction dynamics, represented as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). A passivity-exploiting backstepping design is presented, which leverages the strict dissipativity properties of the PDE subsystem to achieve exponential stabilization of the considered ODE-PDE interconnection around a prescribed equilibrium. Sufficient conditions for local well-posedness and exponential convergence are derived by constructing a Lyapunov functional combining the lumped and distributed states. Both state-feedback and output-feedback controllers are synthesized, the latter relying on a cascaded observer. The theoretical results are corroborated with numerical simulations, considering non-ideal scenarios and accounting for external disturbances and uncertainties. Simulation results confirm that the proposed control strategy can effectively and robustly stabilize oversteer vehicles at high speeds, demonstrating the relevance of the approach for improving the safety and performance in automotive applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08790", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08790", "abs": "https://arxiv.org/abs/2602.08790", "authors": ["Ersoy Sasioglu", "Ingrid Mertig", "Samir Lounis"], "title": "$d$-Wave Surface Altermagnetism in Centrosymmetric Collinear Antiferromagnets", "comment": "6 pages, 3 figures", "summary": "Broken inversion symmetry at the surfaces of centrosymmetric collinear antiferromagnets lifts the combined inversion and time-reversal symmetry ($PT$) and can generate nonrelativistic d-wave spin splitting, termed surface altermagnetism. Combining symmetry analysis with first-principles calculations, we show that surface inversion breaking, while necessary, is not sufficient for this effect. Surface altermagnetism emerges only when the surface termination simultaneously breaks both $PT$ and translation--time-reversal symmetry ($tT$), thereby inducing magnetic sublattice inequivalence between antiferromagnetically coupled surface moments. We demonstrate this mechanism explicitly for the G-type antiferromagnets V$_3$Al and BaMn$_2$Sb$_2$, and show that the same symmetry criterion applies broadly across distinct structural families of centrosymmetric antiferromagnets. These results establish a general, symmetry-based route to realizing robust, exchange-driven spin polarization at antiferromagnetic surfaces and interfaces.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07497", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07497", "abs": "https://arxiv.org/abs/2602.07497", "authors": ["Mo Wang", "Kaixuan Ren", "Pratik Jalan", "Ahmed Ashraf", "Tuong Vy Vu", "Rahul Seetharaman", "Shah Nawaz", "Usman Naseem"], "title": "From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection", "comment": "12 pages, 5 figures, Proceedings of the ACM Web Conference 2026 (WWW '26)", "summary": "Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07413", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07413", "abs": "https://arxiv.org/abs/2602.07413", "authors": ["Yunhai Han", "Linhao Bai", "Ziyu Xiao", "Zhaodong Yang", "Yogita Choudhary", "Krishna Jha", "Chuizheng Kong", "Shreyas Kousik", "Harish Ravichandar"], "title": "Going with the Flow: Koopman Behavioral Models as Implicit Planners for Visuo-Motor Dexterity", "comment": null, "summary": "There has been rapid and dramatic progress in robots' ability to learn complex visuo-motor manipulation skills from demonstrations, thanks in part to expressive policy classes that employ diffusion- and transformer-based backbones. However, these design choices require significant data and computational resources and remain far from reliable, particularly within the context of multi-fingered dexterous manipulation. Fundamentally, they model skills as reactive mappings and rely on fixed-horizon action chunking to mitigate jitter, creating a rigid trade-off between temporal coherence and reactivity. In this work, we introduce Unified Behavioral Models (UBMs), a framework that learns to represent dexterous skills as coupled dynamical systems that capture how visual features of the environment (visual flow) and proprioceptive states of the robot (action flow) co-evolve. By capturing such behavioral dynamics, UBMs can ensure temporal coherence by construction rather than by heuristic averaging. To operationalize these models, we propose Koopman-UBM, a first instantiation of UBMs that leverages Koopman Operator theory to effectively learn a unified representation in which the joint flow of latent visual and proprioceptive features is governed by a structured linear system. We demonstrate that Koopman-UBM can be viewed as an implicit planner: given an initial condition, it analytically computes the desired robot behavior while simultaneously ''imagining'' the resulting flow of visual features over the entire skill horizon. To enable reactivity and adaptation, we introduce an online replanning strategy in which the model acts as its own runtime monitor that automatically triggers replanning when predicted and observed visual flow diverge beyond a threshold. Across seven simulated tasks and two real-world tasks, we demonstrate that K-UBM matches or exceeds the performance of state-of-the-art baselines, while offering considerably faster inference, smooth execution, robustness to occlusions, and flexible replanning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08203", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08203", "abs": "https://arxiv.org/abs/2602.08203", "authors": ["Chenqing Ji", "Jiahong Liu", "Qionghui Liu", "Yifei Sun", "Chao Yu", "Rui Wang"], "title": "An Experimental Study on Fine-Grained Bistatic Sensing of UAV Trajectory via Cellular Downlink Signals", "comment": "Accepted by IEEE Wireless Communications Letters (WCL2026-0128)", "summary": "In this letter, a dual-bistatic unmanned aerial vehicles (UAVs) tracking system utilizing downlink Long-Term Evolution (LTE) signals is proposed and demonstrated. Particularly, two LTE base stations (BSs) are exploited as illumination sources. Two passive sensing receivers are deployed at different locations to detect the bistatic Doppler frequencies of the target UAV at different directions according to downlink signals transmitted from their corresponding BSs, such that the velocities of the UAV versus time can be estimated. Hence, the trajectories of the target UAV can be reconstructed. Although both the target UAV and the sensing receivers are around 200 meters away from the illuminating BSs, it is demonstrated by experiments that the tracking errors are below 50 centimeters for 90% of the complicated trajectories, when the distances between the UAV and sensing receivers are less than 30 meters. Note this accuracy is significantly better than the ranging resolution of LTE signals, high-accuracy trajectory tracking for UAV might be feasible via multi-angle bistatic Doppler measurements if the receivers are deployed with a sufficient density.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08903", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08903", "abs": "https://arxiv.org/abs/2602.08903", "authors": ["Moussa Labbadi", "Andrey Polyakov", "Denis Efimov"], "title": "Accelerated Stabilization of Switched Linear MIMO Systems using Generalized Homogeneity", "comment": null, "summary": "This paper addresses the problem of exponential and accelerated finite-time, as well as nearly fixed-time, stabilization of switched linear MIMO systems. The proposed approach relies on a generalized homogenization framework for switched linear systems and employs implicit Lyapunov functions for control design, covering both common and multiple Lyapunov function settings. Linear matrix equations and inequalities are derived to characterize the dilation generator and to synthesize the controller gains. Robustness of the resulting control laws with respect to system uncertainties and external disturbances is analyzed. The effectiveness of the proposed approach is illustrated through numerical examples.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08950", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.08950", "abs": "https://arxiv.org/abs/2602.08950", "authors": ["Benjamin A. Brereton", "Soumyarup Hait", "Ahmet Yagmur", "Christy J. Kinane", "Francesco Maccherozzi", "Michele Conroy", "Satoshi Sasaki", "Thomas A. Moore", "Sarnjeet S. Dhesi", "Sean Langridge", "Christopher H. Marrows"], "title": "Tailoring Ultrathin Magnetic Multilayers at Terraced Topologically Insulating Interfaces for Perpendicularly Magnetized Domains", "comment": null, "summary": "Topological insulators and skyrmion-hosting, chiral magnetic multilayers are two well-explored areas of modern condensed matter physics, each offering unique advantages for spintronics applications. In this paper, we demonstrate the optimization process for the growth of a Bi$_2$Se$_3$/buffer/[Pt/CoB/Ru]$_{\\times N}$ heterostructure that combines these two material classes: the Bi$_2$Se$_3$ epilayer was grown by molecular beam epitaxy before transfer under ultrahigh vacuum to a separate growth chamber where the polycrystalline metallic multilayer was sputter deposited. The structure of the samples was characterized by co-fitted X-ray and polarized neutron reflectometry measurements and scanning transmission electron microscopy. Polarized neutron models and standard magnetometry show that a buffer layer exceeding a critical thickness is required to obtain the desired uniform, perpendicular magnetic anisotropy in every magnetic layer in the multilayer. Samples with both Ta and Mo buffers were used requiring thicknesses of 1.5 and 0.9 nm respectively. In minimizing the Bi$_2$Se$_3$ terracing, buffered samples yield well-defined, out-of-plane, magnetic domains suitable for spin-orbit torque induced manipulation as determined by X-ray photoemission electron microscopy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07499", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07499", "abs": "https://arxiv.org/abs/2602.07499", "authors": ["Jingshen Zhang", "Xin Ying Qiu", "Lifang Lu", "Zhuhua Huang", "Yutao Hu", "Yuechang Wu", "JunYu Lu"], "title": "Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification", "comment": "Accepted to EACL 2026 Findings", "summary": "Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07434", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07434", "abs": "https://arxiv.org/abs/2602.07434", "authors": ["Songhua Yang", "Xuetao Li", "Xuanye Fei", "Mengde Li", "Miao Li"], "title": "Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots", "comment": null, "summary": "Effective human-robot interaction requires emotionally rich multimodal expressions, yet most humanoid robots lack coordinated speech, facial expressions, and gestures. Meanwhile, real-world deployment demands on-device solutions that can operate autonomously without continuous cloud connectivity. To bridging \\underline{\\textit{S}}peech, \\underline{\\textit{E}}motion, and \\underline{\\textit{M}}otion, we present \\textit{SeM$^2$}, a Vision Language Model-based framework that orchestrates emotionally coherent multimodal interactions through three key components: a multimodal perception module capturing user contextual cues, a Chain-of-Thought reasoning for response planning, and a novel Semantic-Sequence Aligning Mechanism (SSAM) that ensures precise temporal coordination between verbal content and physical expressions. We implement both cloud-based and \\underline{\\textit{e}}dge-deployed versions (\\textit{SeM$^2_e$}), with the latter knowledge distilled to operate efficiently on edge hardware while maintaining 95\\% of the relative performance. Comprehensive evaluations demonstrate that our approach significantly outperforms unimodal baselines in naturalness, emotional clarity, and modal coherence, advancing socially expressive humanoid robotics for diverse real-world environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08204", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08204", "abs": "https://arxiv.org/abs/2602.08204", "authors": ["Geng Wang", "Zhouyou Gu", "Shenghong Li", "Peng Cheng", "Jihong Park", "Branka Vucetic", "Yonghui Li"], "title": "LocDreamer: World Model-Based Learning for Joint Indoor Tracking and Anchor Scheduling", "comment": null, "summary": "Accurate, resource-efficient localization and tracking enables numerous location-aware services in next-generation wireless networks. However, existing machine learning-based methods often require large labeled datasets while overlooking spectrum and energy efficiencies. To fill this gap, we propose LocDreamer, a world model (WM)-based framework for joint target tracking and scheduling of localization anchors. LocDreamer learns a WM that captures the latent representation of the target motion and localization environment, thereby generating synthetic measurements to imagine arbitrary anchor deployments. These measurements enable imagination-driven training of both the tracking model and the reinforcement learning (RL)-based anchor scheduler that activates only the most informative anchors, which significantly reduce energy and signaling costs while preserving high tracking accuracy. Experiments on a real-world indoor dataset demonstrate that LocDreamer substantially improves data efficiency and generalization, outperforming conventional Bayesian filter with random scheduling by 37% in tracking accuracy, and achieving 86% of the accuracy of same model trained directly on real data.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08924", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08924", "abs": "https://arxiv.org/abs/2602.08924", "authors": ["Brycen D. Pearl", "Joshua G. Warner", "Hang Woon Lee"], "title": "Automating the Wildfire Detection and Scheduling Pipeline with Maneuverable Earth Observation Satellites", "comment": "44 pages", "summary": "Wildfires are becoming increasingly frequent, with potentially devastating consequences, including loss of life, infrastructure destruction, and severe environmental damage. Low Earth orbit satellites equipped with onboard sensors can capture critical imagery of active wildfires and enable real-time detection through machine learning algorithms applied to the acquired data. This paper presents a framework that automates the complete wildfire detection and scheduling pipeline, integrating three key components: wildfire detection in satellite imagery, statistical updating that incorporates data from repeated flyovers, and multi-satellite scheduling optimization. The framework enables wildfire detection using convolutional neural networks with sensor fusion techniques, the incorporation of subsequent flyover information using Bayesian statistics, and satellite scheduling through the state-of-the-art Reconfigurable Earth Observation Satellite Scheduling Problem. Experiments conducted using real-world wildfire events and operational Earth observation satellites demonstrate that this autonomous detection and scheduling approach effectively enhances wildfire monitoring capabilities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07546", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07546", "abs": "https://arxiv.org/abs/2602.07546", "authors": ["Zicong Cheng", "Ruixuan Jia", "Jia Li", "Guo-Wei Yang", "Meng-Hao Guo", "Shi-Min Hu"], "title": "Improving Variable-Length Generation in Diffusion Language Models via Length Regularization", "comment": "diffusion language models", "summary": "Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08113", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08113", "abs": "https://arxiv.org/abs/2602.08113", "authors": ["Shuaishuai Yuan", "Gunther G. Andersson", "Gregory F. Metha", "Zetian Mi", "Hong Guo"], "title": "Design principles for III-nitride-nanocluster photocatalysts from region-resolved electronic structure", "comment": "Main text: 14 pages, 4 figures, 2 tables. Supplementary Information: 24 pages, 8 figures, 5 tables", "summary": "Understanding how nanocluster cocatalysts modify the electronic structure of III-nitride surfaces is central to the rational design of efficient photocatalytic interfaces. Here, we establish design principles for nanocluster cocatalysts on GaN-based semiconductors by systematically analyzing the spatially resolved electronic structure of GaN-, InGaN-, and ScGaN-based slabs decorated with six-atom elemental nanoclusters. Using a region-resolved projected local density of states (PLDOS) framework, we reveal that semiconductor-nanocluster interfaces operate as laterally heterogeneous electronic systems, in which nanocluster-covered regions govern charge injection and band bending, while uncovered nitride regions retain surface states that facilitate surface activation. We further show that cocatalyst effectiveness is controlled not only by hydrogen adsorption energy, but also by interfacial electrostatics, including band alignment, metal-induced gap-state suppression, and in-plane dipoles, with the semiconductor substrate defining the baseline electronic regime. Machine-learning regression models trained on physically motivated global and region-specific descriptors quantify the relative importance of these mechanisms and their correlation with hydrogen adsorption energetics. Together, this work provides transferable design principles for nanocluster cocatalysts on III-nitrides and a generalizable first-principles framework for studying spatially heterogeneous semiconductor-nanocluster interfaces.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07439", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07439", "abs": "https://arxiv.org/abs/2602.07439", "authors": ["Weiji Xie", "Jiakun Zheng", "Jinrui Han", "Jiyuan Shi", "Weinan Zhang", "Chenjia Bai", "Xuelong Li"], "title": "TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control", "comment": "Project Page: https://text-op.github.io/", "summary": "Recent advances in humanoid whole-body motion tracking have enabled the execution of diverse and highly coordinated motions on real hardware. However, existing controllers are commonly driven either by predefined motion trajectories, which offer limited flexibility when user intent changes, or by continuous human teleoperation, which requires constant human involvement and limits autonomy. This work addresses the problem of how to drive a universal humanoid controller in a real-time and interactive manner. We present TextOp, a real-time text-driven humanoid motion generation and control framework that supports streaming language commands and on-the-fly instruction modification during execution. TextOp adopts a two-level architecture in which a high-level autoregressive motion diffusion model continuously generates short-horizon kinematic trajectories conditioned on the current text input, while a low-level motion tracking policy executes these trajectories on a physical humanoid robot. By bridging interactive motion generation with robust whole-body control, TextOp unlocks free-form intent expression and enables smooth transitions across multiple challenging behaviors such as dancing and jumping, within a single continuous motion execution. Extensive real-robot experiments and offline evaluations demonstrate instant responsiveness, smooth whole-body motion, and precise control. The project page and the open-source code are available at https://text-op.github.io/", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08225", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08225", "abs": "https://arxiv.org/abs/2602.08225", "authors": ["Siwen Li", "Jiacheng Chen", "Yunting Xu", "Shaofeng Li", "Le Yao", "Jieling Wang", "Dusit Niyato"], "title": "Riemannian Manifold Optimization for Advanced Wireless Communications: Fundamentals and Applications", "comment": null, "summary": "Next-generation wireless communications promise transformative technologies such as massive multiple-input multiple-output (MIMO), reconfigurable intelligent surfaces (RIS), integrated sensing and communication (ISAC), and fluid antenna systems (FAS). However, deploying these technologies is hindered by large-scale optimization problems with nonconvex constraints. Conventional Euclidean-space methods rely on approximations or relaxations, which degrade performance and incur substantial computational costs. Riemannian manifold optimization (RMO) offers a powerful alternative that directly operates on the manifold defined by the geometric constraints. This approach inherently satisfies the constraints at every optimization step, thereby avoiding the performance degradation and substantial computational costs. In this paper, we first elaborate on the principles of RMO, including the fundamental concepts, tools, and methods, emphasizing its effectiveness for nonconvex problems. We then introduce its applications in advanced wireless communications, showing how constrained problems are reformulated on their natural manifolds and solved using tailored RMO algorithms. Furthermore, we present a case study on secure beamforming in an FAS-assisted non-orthogonal multiple access (NOMA) system, demonstrating RMO's superiority over conventional methods in terms of both performance and computational efficiency.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08943", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08943", "abs": "https://arxiv.org/abs/2602.08943", "authors": ["Edoardo Giusti", "Krishan Kumar Tiwari", "C. J. Reddy", "Danilo Brizi", "Agostino Monorchio", "Giuseppe Caire"], "title": "Artificial Magnetic Conductor Frame to Improve Impedance Matching and Radiation Symmetry in 2$\\times$2 Array for 6G Applications", "comment": null, "summary": "An Artificial Magnetic Conductor (AMC) frame capable of improving the impedance matching of a 2$\\times$2 array for 6G applications without degrading isolation performance is presented. The proposed frame is integrated into the array without modifying the single radiating element design. By relying on accurate full-wave simulations, it results that the addition of the frame restores the impedance matching performance, achieving a bandwidth of 1.5 GHz at 28 GHz. The isolation between each port remains under -15 dB within the operating band, thanks to the vias in the rectangular patch metasurface. Moreover, the overall structure exhibits a gain of 11.81 dBi with an aperture efficiency of 69$\\%$, satisfactorily for broadband communication purposes. The proposed AMC frame represents an effective method for improving array performance without the need to alter the shape or dimensions of the single radiating element.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07594", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07594", "abs": "https://arxiv.org/abs/2602.07594", "authors": ["Yuxin Chen", "Yu Wang", "Yi Zhang", "Ziang Ye", "Zhengzhou Cai", "Yaorui Shi", "Qi Gu", "Hui Su", "Xunliang Cai", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Learning to Self-Verify Makes Language Models Better Reasoners", "comment": null, "summary": "Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07506", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07506", "abs": "https://arxiv.org/abs/2602.07506", "authors": ["Peizhen Li", "Longbing Cao", "Xiao-Ming Wu", "Yang Zhang"], "title": "VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots", "comment": "Accepted to the 2026 IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Humanoid facial expression shadowing enables robots to realistically imitate human facial expressions in real time, which is critical for lifelike, facially expressive humanoid robots and affective human-robot interaction. Existing progress in humanoid facial expression imitation remains limited, often failing to achieve either real-time performance or realistic expressiveness due to offline video-based inference designs and insufficient ability to capture and transfer subtle expression details. To address these limitations, we present VividFace, a real-time and realistic facial expression shadowing system for humanoid robots. An optimized imitation framework X2CNet++ enhances expressiveness by fine-tuning the human-to-humanoid facial motion transfer module and introducing a feature-adaptation training strategy for better alignment across different image sources. Real-time shadowing is further enabled by a video-stream-compatible inference pipeline and a streamlined workflow based on asynchronous I/O for efficient communication across devices. VividFace produces vivid humanoid faces by mimicking human facial expressions within 0.05 seconds, while generalizing across diverse facial configurations. Extensive real-world demonstrations validate its practical utility. Videos are available at: https://lipzh5.github.io/VividFace/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08260", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08260", "abs": "https://arxiv.org/abs/2602.08260", "authors": ["Yongjeong Oh", "Jihong Park", "Jinho Choi", "Yo-Seb Jeon"], "title": "Towards Optimal Semantic Communications: Reconsidering the Role of Semantic Feature Channels", "comment": null, "summary": "This paper investigates the optimization of transmitting the encoder outputs, termed semantic features (SFs), in semantic communication (SC). We begin by modeling the entire communication process from the encoder output to the decoder input, encompassing the physical channel and all transceiver operations, as the SF channel, thereby establishing an encoder-SF channel-decoder pipeline. In contrast to prior studies that assume a fixed SF channel, we note that the SF channel is configurable, as its characteristics are shaped by various transmission and reception strategies, such as power allocation. Based on this observation, we formulate the SF channel optimization problem under a mutual information constraint between the SFs and their reconstructions, and analytically derive the optimal SF channel under a linear encoder-decoder structure and Gaussian source assumption. Building upon this theoretical foundation, we propose a joint optimization framework for the encoder-decoder and SF channel, applicable to both analog and digital SCs. To realize the optimized SF channel, we also propose a physical-layer calibration strategy that enables real-time power control and adaptation to varying channel conditions. Simulation results demonstrate that the proposed SF channel optimization achieves superior task performance under various communication environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08977", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08977", "abs": "https://arxiv.org/abs/2602.08977", "authors": ["Lucca Maitan", "Lucas Toschi", "C\u00edcero Zanette", "Elisa G. Vergamini", "Leonardo F. Santos", "Thiago Boaventura"], "title": "Contraction Metric Based Safe Reinforcement Learning Force Control for a Hydraulic Actuator with Real-World Training", "comment": null, "summary": "Force control in hydraulic actuators is notoriously difficult due to strong nonlinearities, uncertainties, and the high risks associated with unsafe exploration during learning. This paper investigates safe reinforcement learning (RL) for hy draulic force control with real-world training using contraction metric certificates. A data-driven model of a hydraulic actuator, identified from experimental data, is employed for simulation based pretraining of a Soft Actor-Critic (SAC) policy that adapts the PI gains of a feedback-linearization (FL) controller. To reduce instability during online training, we propose a quadratic-programming (QP) contraction filter that leverages a learned contraction metric to enforce approximate exponential convergence of trajectories, applying minimal corrections to the policy output. The approach is validated on a hydraulic test bench, where the RL controller is trained directly on hardware and benchmarked against a simulation-trained agent and a fixed-gain baseline. Experimental results show that real-hardware training improves force-tracking performance compared to both alternatives, while the contraction filter mitigates chattering and instabilities. These findings suggest that contraction-based certificates can enable safe RL in high force hydraulic systems, though robustness at extreme operating conditions remains a challenge.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07621", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07621", "abs": "https://arxiv.org/abs/2602.07621", "authors": ["Xanh Ho", "Yun-Ang Wu", "Sunisth Kumar", "Tian Cheng Xia", "Florian Boudin", "Andre Greiner-Petter", "Akiko Aizawa"], "title": "SciClaimEval: Cross-modal Claim Verification in Scientific Papers", "comment": "12 pages; data is available at https://sciclaimeval.github.io/", "summary": "We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08195", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08195", "abs": "https://arxiv.org/abs/2602.08195", "authors": ["Pooja D. Reddy", "Zahra N. Heussen", "Kunal Mukherjee"], "title": "Epitaxial Growth of Anisotropic SnSe on GaAs(001) via Step-Edge Orientation Control", "comment": "12 pages, 5 figures", "summary": "Epitaxial growth of orthorhombic SnSe on cubic substrates is challenging due to lattice-symmetry mismatch and anisotropic bonding. Here we demonstrate that epitaxial films with sharp interfaces can be achieved for layered SnSe grown directly on on-axis and 4 degree miscut GaAs(001) substrates. The substrate miscut strongly influences the growth morphology, evolving from spirals on on-axis GaAs to a terraced structure on miscut GaAs. X-ray diffraction reveals that on-axis GaAs supports SnSe with two in-plane orientation variants, whereas the miscut substrate stabilizes a single orientation and introduces a small out-of-plane tilt. Accordingly, in-plane optical anisotropy is enhanced in the single variant film compared to the double variant, as determined by cross-polar reflectance. High-resolution TEM shows that the SnSe/GaAs interface is atomically abrupt and incoherent, characteristic of quasi-van der Waals epitaxy. We find a pronounced tendency for the zigzag edges of SnSe to align parallel to step edges on both substrates, and we show that step-skipping nucleation and layer growth on the miscut substrate leads to the additional tilt. These results establish direct SnSe/GaAs heteroepitaxy as a route to integrate anisotropic layered semiconductors with cubic platforms, and show that miscut substrates provide additional control over in-plane anisotropy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07541", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07541", "abs": "https://arxiv.org/abs/2602.07541", "authors": ["Jingyi Hou", "Leyu Zhou", "Chenchen Jing", "Jinghan Yang", "Xinbo Yu", "Wei He"], "title": "Differentiate-and-Inject: Enhancing VLAs via Functional Differentiation Induced by In-Parameter Structural Reasoning", "comment": null, "summary": "As robots are expected to perform increasingly diverse tasks, they must understand not only low-level actions but also the higher-level structure that determines how a task should unfold. Existing vision-language-action (VLA) models struggle with this form of task-level reasoning. They either depend on prompt-based in-context decomposition, which is unstable and sensitive to linguistic variations, or end-to-end long-horizon training, which requires large-scale demonstrations and entangles task-level reasoning with low-level control. We present in-parameter structured task reasoning (iSTAR), a framework for enhancing VLA models via functional differentiation induced by in-parameter structural reasoning. Instead of treating VLAs as monolithic policies, iSTAR embeds task-level semantic structure directly into model parameters, enabling differentiated task-level inference without external planners or handcrafted prompt inputs. This injected structure takes the form of implicit dynamic scene-graph knowledge that captures object relations, subtask semantics, and task-level dependencies in parameter space. Across diverse manipulation benchmarks, iSTAR achieves more reliable task decompositions and higher success rates than both in-context and end-to-end VLA baselines, demonstrating the effectiveness of parameter-space structural reasoning for functional differentiation and improved generalization across task variations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08380", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08380", "abs": "https://arxiv.org/abs/2602.08380", "authors": ["Akanksha Sneh", "Shobha Sundar Ram", "Sumit J Darak", "Aakanksha Tewari"], "title": "Beam Alignment in Multipath Environments for Integrated Sensing and Communication using Bandit Learning", "comment": "15 pages, 10 figures and 7 tables", "summary": "Prior works have explored multi-armed bandit (MAB) algorithms for the selection of optimal beams for millimeter-wave (mmW) communications between base station and mobile users. However, when the number of beams is large, the existing MAB algorithms are characterized by long exploration times, resulting in poor overall communication throughput. In this work, we propose augmenting the upper confidence bound (UCB) based MAB with integrated sensing and communication (ISAC) to address this limitation. The premise of the work is that the radar and communication functionalities share the same field-of-view and that communication mobile users are detected by the radar as mobile targets. The radar information is used for significantly reducing the number of candidate beams for the UCB, resulting in an overall reduction in the exploration time. Further, the radar information is used to estimate the realignment time in quasi-stationary scenarios. We have realized the MAB and radar signal processing algorithms on the system on chip (SoC) via hardware-software co-design (HSCD) and fixed-point analysis. We demonstrate the significant gain in execution time using accelerators. The simulations consider complex propagation channels involving direct and multipath, with simple and extended radar targets in the presence of significant static clutter. The resulting experiments show that the proposed ISAC-based MAB achieves a 35% reduction in the overall exploration time and 1.4 factor higher throughput as compared to the conventional MAB that is based only on communications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07639", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07639", "abs": "https://arxiv.org/abs/2602.07639", "authors": ["Jaewook Lee", "Alexander Scarlatos", "Simon Woodhead", "Andrew Lan"], "title": "Letting Tutor Personas \"Speak Up\" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization", "comment": null, "summary": "With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08381", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08381", "abs": "https://arxiv.org/abs/2602.08381", "authors": ["Yuxuan Jiang", "Xingkun Ning", "Renhui Liu", "Kepeng Song", "Sajjad Ali", "Haoyue Deng", "Yizhuo Li", "Biaohong Huang", "Jianhang Qiu", "Xiaofei Zhu", "Zhen Fan", "Qiankun Li", "Chengbing Qin", "Fei Xue", "Teng Yang", "Bing Li", "Gang Liu", "Weijin Hu", "Lain-Jong Li", "Zhidong Zhang"], "title": "2D ferroelectric narrow-bandgap semiconductor Wurtzite' type alpha-In2Se3 and its silicon-compatible growth", "comment": "29 pages, 5 figures, 1 table", "summary": "2D van der Waals ferroelectrics, particularly alpha-In2Se3, have emerged as an attractive building block for next-generation information storage technologies due to their moderate band gap and robust ferroelectricity stabilized by dipole locking. alpha-In2Se3 can adopt either the distorted zincblende or wurtzite structures; however, the wurtzite phase has yet to be experimental-ly validated, and its large-scale synthesis poses significant challenges. Here, we report an in-situ transport growth of centimeter-scale wurtzite type alpha-In2Se3 films directly on SiO2 substrates using a process combining pulsed laser deposition and chemical vapor deposition. We demonstrate that it is a narrow bandgap ferroelectric semiconductor, featuring a Curie tem-perature exceeding 620 K, a tunable bandgap (0.8-1.6 eV) modulated by charged domain walls, and a large optical absorption coefficient of 1.3 times 10 powers 6 per centemeter. Moreover, light absorption promotes the dynamic conductance range, linearity, and symmetry of the synapse devices, leading to a high recognition accuracy of 92.3 percent in a supervised pattern classification task for neuromorphic computing. Our findings demonstrate a ferroelectric polymorphism of In2Se3, highlighting its potential in ferroelectric synapses for neuromorphic computing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07598", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07598", "abs": "https://arxiv.org/abs/2602.07598", "authors": ["Drake Moore", "Arushi Aggarwal", "Emily Taylor", "Sarah Zhang", "Taskin Padir", "Xiang Zhi Tan"], "title": "\"Meet My Sidekick!\": Effects of Separate Identities and Control of a Single Robot in HRI", "comment": null, "summary": "The presentation of a robot's capability and identity directly influences a human collaborator's perception and implicit trust in the robot. Unlike humans, a physical robot can simultaneously present different identities and have them reside and control different parts of the robot. This paper presents a novel study that investigates how users perceive a robot where different robot control domains (head and gripper) are presented as independent robots. We conducted a mixed design study where participants experienced one of three presentations: a single robot, two agents with shared full control (co-embodiment), or two agents with split control across robot control domains (split-embodiment). Participants underwent three distinct tasks -- a mundane data entry task where the robot provides motivational support, an individual sorting task with isolated robot failures, and a collaborative arrangement task where the robot causes a failure that directly affects the human participant. Participants perceived the robot as residing in the different control domains and were able to associate robot failure with different identities. This work signals how future robots can leverage different embodiment configurations to obtain the benefit of multiple robots within a single body.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08396", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08396", "abs": "https://arxiv.org/abs/2602.08396", "authors": ["Akanksha Sneh", "Shobha Sundar Ram", "Kumar Vijay Mishra"], "title": "IEEE 802.11ad-Aided 5-D Sensing with a UAV Swarm in Urban Environment", "comment": "5 pages and 4 figures", "summary": "Aerial base stations mounted on unmanned aerial vehicles (UAVs) support next-generation wireless networks in challenging environments such as urban areas, disaster zones, and remote locations. Further, UAV swarms overcome the challenges of limited battery life and other operational constraints of a single UAV. However, tracking mobile users on the ground by each UAV and the corresponding synchronization between the UAVs is a significant issue that must be addressed before this framework can be deployed in reality. Incorporating additional sensing capabilities to facilitate this additional requirement would introduce significant overhead in terms of hardware, cost, and power to each UAV. Instead, we propose an integrated sensing and communications-enabled swarm UAV system, based on the millimeter-wave IEEE 802.11ad protocol. Further, we show that our proposed system is capable of five-dimensional (5-D) ground target sensing (range, Doppler velocity, azimuth, elevation, and polarization) in an urban environment. Numerical experiments using realistic models demonstrate and validate the performance of 5-D sensing using our proposed 802-11ad-aided UAV system.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07673", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07673", "abs": "https://arxiv.org/abs/2602.07673", "authors": ["Jiangnan Fang", "Cheng-Tse Liu", "Hanieh Deilamsalehy", "Nesreen K. Ahmed", "Puneet Mathur", "Nedim Lipka", "Franck Dernoncourt", "Ryan A. Rossi"], "title": "Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation", "comment": null, "summary": "Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08451", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08451", "abs": "https://arxiv.org/abs/2602.08451", "authors": ["Nadezhda A. Andreeva", "Cuixia Liu", "Vitaly V. Chaban"], "title": "Ozonation of Dielectric Fosters Self-Healing Efficiency in Metalized-Film Capacitors: Quantum-Chemical Simulation", "comment": null, "summary": "Metalized-film capacitors (MFCs) employ polymer organic dielectrics like polypropylene (PP) and polyimide (PI), in which self-healing is seen as a key advantage. However, the performance of self-healing depends on specific chemical mechanisms involved. The formation of semiconductive carbonaceous soot represents a critical failure risk. This study investigates how oxygen atom impregnation through ozonation of the dielectric material tunes the composition and electrical conductivity of breakdown products in the PP and PI systems with aluminum-zinc electrodes. We revealed, at the atomistic level, that oxygen atoms tend to remove a fraction of carbon atoms from the semiconductive soot by oxidizing carbon into carbon monoxide in both polymers. In PP, oxygen fraction linearly increases gas mass fraction, thereby reducing soot fraction. In PI, the gas/soot ratio effect of oxygen content is less drastic, still clearly positive. The PP soot conductivity decreases uniformly as larger fractions of oxygen atoms are added. In turn, the PI conductivity drops to ~1500 S/m quickly. The PI soot exhibits narrower band gaps compared to that of PP. The oxygen fraction non-monotonically tailors band gaps, which generally increase. To summarize, ozonation enhances MFC reliability by increasing gas species fraction and reducing soot conductivity. We hereby provide numerical molecular-level insights to rationalize self-healing performance enhancement through polymer ozonation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07629", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07629", "abs": "https://arxiv.org/abs/2602.07629", "authors": ["Nitesh Subedi", "Adam Haroon", "Samuel Tetteh", "Prajwal Koirala", "Cody Fleming", "Soumik Sarkar"], "title": "LCLA: Language-Conditioned Latent Alignment for Vision-Language Navigation", "comment": null, "summary": "We propose LCLA (Language-Conditioned Latent Alignment), a framework for vision-language navigation that learns modular perception-action interfaces by aligning sensory observations to a latent representation of an expert policy. The expert is first trained with privileged state information, inducing a latent space sufficient for control, after which its latent interface and action head are frozen. A lightweight adapter is then trained to map raw visual-language observations, via a frozen vision-language model, into the expert's latent space, reducing the problem of visuomotor learning to supervised latent alignment rather than end-to-end policy optimization. This decoupling enforces a stable contract between perception and control, enabling expert behavior to be reused across sensing modalities and environmental variations. We instantiate LCLA and evaluate it on a vision-language indoor navigation task, where aligned latent spaces yield strong in-distribution performance and robust zero-shot generalization to unseen environments, lighting conditions, and viewpoints while remaining lightweight at inference time.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08409", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08409", "abs": "https://arxiv.org/abs/2602.08409", "authors": ["Hongyun Jin", "Wenchi Cheng", "Jingqing Wang"], "title": "Movable Antenna Enabled Reconfigurable Array Topologies for Structured Beam Communications", "comment": "13 pages", "summary": "Spatially structured beams have emerged as a promising technology for enhancing spectrum efficiency (SE) in sixth-generation (6G) networks. However, structured beam schemes based on fixed-position antennas (FPAs) fail to fully exploit the array aperture, thereby limiting their topological reconfigurability and adaptability to diverse communication scenarios. To overcome these limitations, this paper proposes a novel structured beam communication framework exploiting movable antennas (MAs) to achieve reconfigurable array topologies. Specifically, we develop an MA-based geometric modeling framework to construct a variety of practical array topologies, thereby enabling the realization of diverse array configurations utilizing a unified hardware platform. Furthermore, we investigate the joint design of the array topology and the structured beamforming vector to efficiently exploit the array aperture and facilitate the multiplexing of orthogonal spatial modes. Accordingly, we formulate the corresponding beam generation and demodulation schemes and derive the channel gains under varying array topologies. We also propose an alternating optimization algorithm to jointly optimize the array topology configuration, the antenna element positions, and the structured beamforming vector, with the aim of maximizing the system SE. Numerical results demonstrate that the proposed joint design significantly enhances the SE compared to conventional FPA schemes. By synergizing the spatial multiplexing degrees of freedom (DoFs) of structured beams with the mobility DoFs of MAs within 2D planar regions, this work establishes a reconfigurable and practical framework for structured beam-based wireless communications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07173", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07173", "abs": "https://arxiv.org/abs/2602.07173", "authors": ["Tong Jian", "Tianyu Dai", "Tao Yu"], "title": "Learning Nonlinear Systems In-Context: From Synthetic Data to Real-World Motor Control", "comment": "Accepted to be presented in IEEE ICASSP 2026", "summary": "LLMs have shown strong in-context learning (ICL) abilities, but have not yet been extended to signal processing systems. Inspired by their design, we have proposed for the first time ICL using transformer models applicable to motor feedforward control, a critical task where classical PI and physics-based methods struggle with nonlinearities and complex load conditions. We propose a transformer based model architecture that separates signal representation from system behavior, enabling both few-shot finetuning and one-shot ICL. Pretrained on a large corpus of synthetic linear and nonlinear systems, the model learns to generalize to unseen system dynamics of real-world motors only with a handful of examples. In experiments, our approach generalizes across multiple motor load configurations, transforms untuned examples into accurate feedforward predictions, and outperforms PI controllers and physics-based feedforward baselines. These results demonstrate that ICL can bridge synthetic pretraining and real-world adaptability, opening new directions for data efficient control of physical systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07773", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.07773", "abs": "https://arxiv.org/abs/2602.07773", "authors": ["Chen Zhang", "Kuicai Dong", "Dexun Li", "Wenjun Li", "Qu Yang", "Wei Han", "Yong Liu"], "title": "SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents", "comment": null, "summary": "Recent deep search agents built on large reasoning models (LRMs) excel at complex question answering by iteratively planning, acting, and gathering evidence, a capability known as search-integrated reasoning. However, mainstream approaches often train this ability using only outcome-based supervision, neglecting the quality of intermediate thoughts and actions. We introduce SRR-Judge, a framework for reliable step-level assessment of reasoning and search actions. Integrated into a modified ReAct-style rate-and-refine workflow, SRR-Judge provides fine-grained guidance for search-integrated reasoning and enables efficient post-training annotation. Using SRR-annotated data, we apply an iterative rejection sampling fine-tuning procedure to enhance the deep search capability of the base agent. Empirically, SRR-Judge delivers more reliable step-level evaluations than much larger models such as DeepSeek-V3.1, with its ratings showing strong correlation with final answer correctness. Moreover, aligning the policy with SRR-Judge annotated trajectories leads to substantial performance gains, yielding over a 10 percent average absolute pass@1 improvement across challenging deep search benchmarks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08497", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08497", "abs": "https://arxiv.org/abs/2602.08497", "authors": ["Jianjian Gong", "Junsen Wang", "Junsen Xiang", "Zhaojun Mo", "Lei Zhang", "Xinyang Liu", "Xuetong He", "Lu Tian", "Zhixing Ye", "Huicai Xie", "Xucai Kan", "Xinqiang Gao", "Zhenxing Li", "Peijie Sun", "Shouguo Wang", "Wei Li", "Baogen Shen", "Jun Shen"], "title": "Giant Magnetocaloric Effect in a High-Spin Shastry-Sutherland Dipolar Magnet", "comment": null, "summary": "The Shastry-Sutherland lattice is a prototypical frustrated quantum magnet. It is notable for its exactly solvable dimer-singlet ground state and hosts a wealth of magnetic phenomena under external fields. Here, this work investigates the high-spin (S = 7/2) Eu-based magnet Eu2MgSi2O7 (EMSO) using low-temperature magnetothermal measurements and Monte Carlo simulations, revealing a giant magnetocaloric effect (MCE) in this Shastry-Sutherland compound. The entropy change peak value is found to be 55.0 J kg-1 K-1 under a field change of B = 0-4 T, approximately 1.5 times larger than the commercial Gd3Ga5O12 (GGG). Adiabatic demagnetization refrigeration achieves a lowest temperature of 151 mK, deeply into the sub-Kelvin regime. Furthermore, a distinctive cooling effect persists below about 1 T, a characteristic absent for conventional magnetic coolants. A dipolar Shastry-Sutherland model is introduced as a minimal model to describe this system; in particular, the experimentally revealed 1/3 magnetization pseudo-plateau can be ascribed to the presence of dipolar couplings between Eu2+ ions, further stabilized by the thermal fluctuations, explaining the persistent cooling effect. This work establishes EMSO as a novel platform for exploring the dipolar Shastry-Sutherland system and for sub-Kelvin adiabatic demagnetization refrigeration.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07677", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07677", "abs": "https://arxiv.org/abs/2602.07677", "authors": ["Aron Mathias", "Mohammad Ghufran", "Jack Hughes", "Hossein Rastgoftar"], "title": "Affine Transformable Unmanned Ground Vehicle", "comment": null, "summary": "This paper develops the proof of concept for a novel affine transformable unmanned ground vehicle (ATUGV) with the capability of safe and aggressive deformation while carrying multiple payloads. The ATUGV is a multi-body system with mobile robots that can be used to power the ATUGV morphable motion, powered cells to enclose the mobile robots, unpowered cells to contain payloads, and a deformable structure to integrate cells through bars and joints. The objective is that all powered and unpowered cells motion can safely track a desired affine transformation, where an affine transformation can be decomposed into translation, rigid body rotation, and deformation. To this end, the paper first uses a deep neural network to structure cell interconnection in such a way that every cell can freely move over the deformation plane, and the entire structure can reconfigurably deform to track a desired affine transformation. Then, the mobile robots, contained by the powered cells and stepper motors, regulating the connections of the powered and unpowered cells, design the proper controls so that all cells safely track the desired affine transformation. The functionality of the proposed ATUGV is validated through hardware experimentation and simulation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08415", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08415", "abs": "https://arxiv.org/abs/2602.08415", "authors": ["Aakanksha Tewari", "Samarth Sharma Bhardwaj", "Sumit J Darak", "Shobha Sundar Ram"], "title": "Reconfigurable Low-Complexity Architecture for High Resolution Doppler Velocity Estimation in Integrated Sensing and Communication System", "comment": null, "summary": "In millimeter wave integrated sensing and communication (ISAC) systems for intelligent transportation, radar and communication share spectrum and hardware in a time division manner. Radar rapidly detects and localizes mobile users (MUs), after which communication proceeds through narrow beams identified by radar. Achieving fine Doppler resolution for MU clutter discrimination requires long coherent processing intervals, reducing communication time and throughput. To address this, we propose a reconfigurable architecture for Doppler estimation realized on a system on chip using hardware software codesign. The architecture supports algorithm level reconfiguration, dynamically switching between low-complexity, high-speed FFT-based coarse estimation and high complexity ESPRIT based fine estimation. We introduce modifications to ESPRIT that achieve 6.7 times faster execution while reducing memory and multiplier usage by 79% and 63%, respectively, compared to state of the art approaches, without compromising accuracy. Additionally, the reconfigurable architecture can switch to lower slow time packets under high SNR conditions, improving latency further by 2 times with no loss in performance.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07778", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07778", "abs": "https://arxiv.org/abs/2602.07778", "authors": ["Shenglai Zeng", "Tianqi Zheng", "Chuan Tian", "Dante Everaert", "Yau-Shian Wang", "Yupin Huang", "Michael J. Morais", "Rohit Patki", "Jinjin Tian", "Xinnan Dai", "Kai Guo", "Monica Xiao Cheng", "Hui Liu"], "title": "Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs", "comment": null, "summary": "Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08516", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08516", "abs": "https://arxiv.org/abs/2602.08516", "authors": ["Chao Zhou", "Lei Hao", "Shaohua Zhang", "Yaxuan Jin", "Xianguo Jiang", "Ning Yang", "Li Zheng", "Hao Meng", "Chao Lu", "Wendeng Huang", "Yizheng Wu", "Yan Zhou", "Jia Xu"], "title": "Inverse orbital Hall effect induced terahertz emission enabled by a ferromagnet with quenched orbital moment in Fe/Pt/W trilayers", "comment": "19 pages, 4 figures", "summary": "The inverse orbital Hall effect (IOHE) has recently attracted considerable attention as an emerging mechanism for terahertz (THz) emission based on ultrafast angular-momentum-to-charge conversion. Most experimental studies have focused on materials with strong spin-orbit coupling or pronounced orbital character, where sizable orbital Hall responses are expected. Elemental ferromagnets such as Fe are generally regarded as quenched orbital sources and are not expected to exhibit orbital-dominated THz emission. Here, we report a pronounced enhancement of THz emission in Fe/Pt/W trilayer heterostructures, despite the absence of detectable orbital contributions in the corresponding Fe/Pt and Fe/W bilayers. Thickness-dependent measurements reveal long-distance signal persistence, systematic delay accumulation, and pronounced pulse broadening with increasing W thickness. These features are inconsistent with diffusive spin transport and indicate that orbital angular momentum transport in the W layer, converted into charge current via the IOHE, becomes a dominant channel for THz emission in the trilayer configuration. Our results demonstrate that strong IOHE can emerge in heterostructures incorporating a quenched orbital ferromagnet, providing an effective route to enhance spintronic THz emitters through orbital Hall physics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07736", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07736", "abs": "https://arxiv.org/abs/2602.07736", "authors": ["Omar Tahri"], "title": "Global Symmetry and Orthogonal Transformations from Geometrical Moment $n$-tuples", "comment": null, "summary": "Detecting symmetry is crucial for effective object grasping for several reasons. Recognizing symmetrical features or axes within an object helps in developing efficient grasp strategies, as grasping along these axes typically results in a more stable and balanced grip, thereby facilitating successful manipulation. This paper employs geometrical moments to identify symmetries and estimate orthogonal transformations, including rotations and mirror transformations, for objects centered at the frame origin. It provides distinctive metrics for detecting symmetries and estimating orthogonal transformations, encompassing rotations, reflections, and their combinations. A comprehensive methodology is developed to obtain these functions in n-dimensional space, specifically moment \\( n \\)-tuples. Extensive validation tests are conducted on both 2D and 3D objects to ensure the robustness and reliability of the proposed approach. The proposed method is also compared to state-of-the-art work using iterative optimization for detecting multiple planes of symmetry. The results indicate that combining our method with the iterative one yields satisfactory outcomes in terms of the number of symmetry planes detected and computation time.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08474", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08474", "abs": "https://arxiv.org/abs/2602.08474", "authors": ["Xinyu Zhang", "Alexis A. Dowhuszko", "Miguel R\u00eago", "Pedro Fonseca", "Lu\u00eds Nero Alves", "Jyri H\u00e4m\u00e4l\u00e4inen", "Risto Wichman"], "title": "Symbol Rate Maximization in Rolling-Shutter OCC: Design and Implementation Considerations", "comment": "6 pages, 8 figures, Submitted to IEEE International Conference on Communications", "summary": "Optical Camera Communication (OCC) systems can take advantage of the row-by-row scanning process of rolling-shutter cameras to capture the fast variations of light intensity coming from Visible Light Communication (VLC) LED-based transmitters. In order to study the maximum data rate that is feasible in such kind of OCC systems, this paper presents its equivalent digital communication system model in which the rolling-shutter camera is modeled as a rectangular matched-filter whose time width is equal to the exposure time of the camera, followed by a sampling process at the pixel row sweep rate of the camera. Based on the proposed rolling-shutter camera model, the maximum symbol rate that such OCC systems can support is experimentally demonstrated, and the impact of imperfect time synchronization between the VLC transmitter and the rolling-shutter OCC receiver is characterized in the form of Inter-Symbol Interference (ISI). The equivalent three-tap channel model that results from this process is experimentally validated and the generated ISI is compensated with the use of linear equalization in reception. Simulation and experimental results show a strong correlation between them, demonstrating that the proposed approach can be used to make the OCC system work at the Nyquist sampling rate, which is equivalent to the pixel row sweep rate of the rolling-shutter camera used in reception.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07794", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07794", "abs": "https://arxiv.org/abs/2602.07794", "authors": ["Ningyu Xu", "Qi Zhang", "Xipeng Qiu", "Xuanjing Huang"], "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models", "comment": "27 pages, 16 figures", "summary": "Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08525", "categories": ["cond-mat.mtrl-sci", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.08525", "abs": "https://arxiv.org/abs/2602.08525", "authors": ["Mikhael T. Sayat", "Federico Pisani", "Hin Lok Chang", "Yaroslav Zhumagulov", "Kirrily C. Rule", "Tom Fennell", "Jakob Nunnendorf", "Chee Kwan Gan", "Oleg V. Yazyev", "Ping Koy Lam", "Jian-Rui Soh"], "title": "Coupling between CaWO$_4$ phonons and Er$^{3+}$ dopants", "comment": "8 pages, 6 figures", "summary": "We investigate the lattice dynamics of CaWO$_4$, a promising host crystal for erbium-based quantum memories, using inelastic neutron scattering together with density-functional perturbation theory. The measured phonon dispersion along the (100), (001), and (101) reciprocal space direction reveals phonon bands extending up to 130 meV, with a gap between 60 and 80 meV, in good agreement with our calculations. From a symmetry analysis of the phonon eigenmodes, we identify eight Raman-active modes that can couple directly to the Er$^{3+}$ crystal-field operators, including a low-energy $B_g$ mode at 9.1 meV that is expected to play a dominant role in phonon-assisted spin-lattice relaxation. These results provide a microscopic description of the phonon bath in CaWO$_4$ and establish a basis for engineering phononic environments to mitigate the loss of stored quantum states and optimize Er-doped CaWO$_4$ for quantum-memory applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07776", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07776", "abs": "https://arxiv.org/abs/2602.07776", "authors": ["Joachim Yann Despature", "Kazuki Shibata", "Takamitsu Matsubara"], "title": "CoLF: Learning Consistent Leader-Follower Policies for Vision-Language-Guided Multi-Robot Cooperative Transport", "comment": "9 pages, 5 figures", "summary": "In this study, we address vision-language-guided multi-robot cooperative transport, where each robot grounds natural-language instructions from onboard camera observations. A key challenge in this decentralized setting is perceptual misalignment across robots, where viewpoint differences and language ambiguity can yield inconsistent interpretations and degrade cooperative transport. To mitigate this problem, we adopt a dependent leader-follower design, where one robot serves as the leader and the other as the follower. Although such a leader-follower structure appears straightforward, learning with independent and symmetric agents often yields symmetric or unstable behaviors without explicit inductive biases. To address this challenge, we propose Consistent Leader-Follower (CoLF), a multi-agent reinforcement learning (MARL) framework for stable leader-follower role differentiation. CoLF consists of two key components: (1) an asymmetric policy design that induces leader-follower role differentiation, and (2) a mutual-information-based training objective that maximizes a variational lower bound, encouraging the follower to predict the leader's action from its local observation. The leader and follower policies are jointly optimized under the centralized training and decentralized execution (CTDE) framework to balance task execution and consistent cooperative behaviors. We validate CoLF in both simulation and real-robot experiments using two quadruped robots. The demonstration video is available at https://sites.google.com/view/colf/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08495", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08495", "abs": "https://arxiv.org/abs/2602.08495", "authors": ["Akanksha Sneh", "Shobha Sundar Ram"], "title": "Radar Operating Metrics and Network Throughput for Integrated Sensing and Communications in Millimeter-wave Urban Environments", "comment": "6 pages, 7 figures", "summary": "Millimeter wave integrated sensing and communication (ISAC) systems are being researched for next-generation intelligent transportation systems. Here, radar and communication functionalities share a common spectrum and hardware resources in a time-multiplexed manner. The objective of the radar is to first scan the angular search space and detect and localize mobile users/targets in the presence of discrete clutter scatterers. Subsequently, this information is used to direct highly directional beams toward these mobile users for communication service. The choice of radar parameters such as the radar duty cycle and the corresponding beamwidth are critical for realizing high communication throughput. In this work, we use the stochastic geometry-based mathematical framework to analyze the radar operating metrics as a function of diverse radar, target, and clutter parameters and subsequently use these results to study the network throughput of the ISAC system. The results are validated through Monte Carlo simulations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07796", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07796", "abs": "https://arxiv.org/abs/2602.07796", "authors": ["Jiatong Li", "Changdae Oh", "Hyeong Kyu Choi", "Jindong Wang", "Sharon Li"], "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents", "comment": "27 pages, 19 figures", "summary": "Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08547", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08547", "abs": "https://arxiv.org/abs/2602.08547", "authors": ["Sanskar Mishra", "Nagendra Singh", "Vinod K. Gangwar", "Rajan Walia", "Jianping Sun", "Genfu Chen", "Dilip Bhoi", "Sandip Chatterjee", "Yoshiya Uwatoko", "Jinguang Cheng", "Prashant Shahi"], "title": "Pressure induced electronic band evolution and observation of superconductivity in the Dirac semimetal ZrTe5", "comment": "14 Pages, 16 Figures", "summary": "We report a comprehensive investigation of the pressure effects on the magnetotransport properties of the topological material ZrTe5 within 1 to 8 GPa pressure range. With increasing pressure, the characteristic peak (Tp) in its electrical resistivity first shifts to higher temperature and then moves quickly towards the lower temperature before disappearing eventually at 6 GPa. Beyond 6 GPa, the system exhibits metallic behavior across the entire temperature range, and superconductivity emerges below Tc = 1.8 K at 8 GPa. Based on the systematic magnetotransport measurement under pressure, we demonstrate that the superconductivity occurs following a significant electronic structure modulation possibly due to pressure induced structural changes near 6 GPa, which coincides with dramatic enhancement of the magnetoresistance (MR) reaching up to 1400 percent. Our experimental results are substantiated by density functional theory calculations as the application of pressure drastically alters the density of states near the Fermi level. Notably, multiple hole pockets emerge at the Fermi level from 4 GPa onward, and their contributions are further enhanced with increasing pressure. The combined experimental and theoretical investigation reveals a comprehensive evolution of electronic structure of Dirac semimetal ZrTe5 under pressure and suggest a possible link between the Fermi surface reconstruction in the pressure range of structural transition and emergence of superconductivity", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07837", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07837", "abs": "https://arxiv.org/abs/2602.07837", "authors": ["Hongzhi Zang", "Shu'ang Yu", "Hao Lin", "Tianxing Zhou", "Zefang Huang", "Zhen Guo", "Xin Xu", "Jiakai Zhou", "Yuze Sheng", "Shizhe Zhang", "Feng Gao", "Wenhao Tang", "Yufeng Yue", "Quanlu Zhang", "Xinlei Chen", "Chao Yu", "Yu Wang"], "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI", "comment": null, "summary": "Online policy learning directly in the physical world is a promising yet challenging direction for embodied intelligence. Unlike simulation, real-world systems cannot be arbitrarily accelerated, cheaply reset, or massively replicated, which makes scalable data collection, heterogeneous deployment, and long-horizon effective training difficult. These challenges suggest that real-world policy learning is not only an algorithmic issue but fundamentally a systems problem. We present USER, a Unified and extensible SystEm for Real-world online policy learning. USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer, enabling automatic discovery, management, and scheduling of heterogeneous robots. To address cloud-edge communication, USER introduces an adaptive communication plane with tunneling-based networking, distributed data channels for traffic localization, and streaming-multiprocessor-aware weight synchronization to regulate GPU-side overhead. On top of this infrastructure, USER organizes learning as a fully asynchronous framework with a persistent, cache-aware buffer, enabling efficient long-horizon experiments with robust crash recovery and reuse of historical data. In addition, USER provides extensible abstractions for rewards, algorithms, and policies, supporting online imitation or reinforcement learning of CNN/MLP, generative policies, and large vision-language-action (VLA) models within a unified pipeline. Results in both simulation and the real world show that USER enables multi-robot coordination, heterogeneous manipulators, edge-cloud collaboration with large models, and long-running asynchronous training, offering a unified and extensible systems foundation for real-world online policy learning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08560", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08560", "abs": "https://arxiv.org/abs/2602.08560", "authors": ["Fredrik Cumlin", "Anubhab Ghosh", "Saikat Chatterjee"], "title": "DNS: Data-driven Nonlinear Smoother for Complex Model-free Process", "comment": null, "summary": "We propose data-driven nonlinear smoother (DNS) to estimate a hidden state sequence of a complex dynamical process from a noisy, linear measurement sequence. The dynamical process is model-free, that is, we do not have any knowledge of the nonlinear dynamics of the complex process. There is no state-transition model (STM) of the process available. The proposed DNS uses a recurrent architecture that helps to provide a closed-form posterior of the hidden state sequence given the measurement sequence. DNS learns in an unsupervised manner, meaning the training dataset consists of only measurement data and no state data. We demonstrate DNS using simulations for smoothing of several stochastic dynamical processes, including a benchmark Lorenz system. Experimental results show that the DNS is significantly better than a deep Kalman smoother (DKS) and an iterative data-driven nonlinear state estimation (iDANSE) smoother.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07804", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07804", "abs": "https://arxiv.org/abs/2602.07804", "authors": ["Xuan Ding", "Pengyu Tong", "Ranjie Duan", "Yunjian Zhang", "Rui Sun", "Yao Zhu"], "title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models", "comment": "Accepted by ICLR 2026", "summary": "While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08551", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08551", "abs": "https://arxiv.org/abs/2602.08551", "authors": ["Yin Chen", "Anthony E. Phillips", "Cheng Fu", "Volodymyr Bon", "Lei Liu", "Xiaoxu Sun", "Jiahui Wang", "Na Lin", "Ruize Xie", "Guanqun Cai", "Yutong Wang", "Jing Ma", "Yuhong Liu", "Yu Han", "Stefan Kaskel"], "title": "Hidden in-plane long-range order in an amorphized crystal", "comment": null, "summary": "Solid materials are commonly classified as crystalline or amorphous based on the presence or absence of long-range order.Metal-organic frameworks (MOFs), like other solids,also display markedly different properties and functions in these two phases. Here, we identify a previously unrecognized structural state that retains long-range in-plane translational order while losing order along the stacking direction. Hypothesized since 1941 but not experimentally verified, this intermediate phase emerges in a crystalline MOFs via controlled thermal desolvation, which selectively disrupts the intrinsically weak interlayer interactions while preserving macroscopic structural coherence. Although the resulting material appears amorphous under conventional characterization, systematic synchrotron PXRD, total X-ray scattering, and low-dose high resolution TEM reveal clear in-plane periodicity. This material spontaneously delaminates in water into uniform, high-quality two-dimensional crystalline nanosheets, forming stable colloidal suspensions and exhibiting superlubricity comparable to graphene - but at less than 0.1% of the production cost. Our discovery finds a missing link within the long-standing crystalline-amorphous dichotomy, while providing an inherently scalable route to high-quality 2D crystals, and offering a conceptual and practical advance in phase engineering.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07845", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07845", "abs": "https://arxiv.org/abs/2602.07845", "authors": ["Yalcin Tur", "Jalal Naghiyev", "Haoquan Fang", "Wei-Chuan Tsai", "Jiafei Duan", "Dieter Fox", "Ranjay Krishna"], "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning", "comment": "11 Pages, Project page:https://rd-vla.github.io/", "summary": "Current Vision-Language-Action (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence. Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0 percent success) with single-iteration inference exceed 90 percent success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80x inference speedup over prior reasoning-based VLA models. Project page: https://rd-vla.github.io/", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08596", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08596", "abs": "https://arxiv.org/abs/2602.08596", "authors": ["Riya Sachdeva", "Aakanksha Tewari", "Sumit J. Darak", "Shobha Sundar Ram", "Sanat K. Biswas"], "title": "RFSoC-Based Integrated Navigation and Sensing Using NavIC", "comment": null, "summary": "Prior art has proposed a secondary application for Global Navigation Satellite System (GNSS) infrastructure for remote sensing of ground-based and maritime targets. Here, a passive radar receiver is deployed to detect uncooperative targets on Earth's surface by capturing ground-reflected satellite signals. This work demonstrates a hardware prototype of an L-band Navigation with Indian Constellation (NavIC) satellite-based remote sensing receiver system mounted on an AMD Zynq radio frequency system-on-chip (RFSoC) platform. Two synchronized receiver channels are introduced for capturing the direct signal (DS) from the satellite and ground-reflected signal (GRS) returns from targets. These signals are processed on the ARM processor and field programmable gate array (FPGA) of the RFSoC to generate delay-Doppler maps of the ground-based targets. The performance is first validated in a loop-back configuration of the RFSoC. Next, the DS and GRS signals are emulated by the output from two ports of the Keysight Arbitrary Waveform Generator (AWG) and interfaced with the RFSoC where the signals are subsequently processed to obtain the delay-Doppler maps. The performance is validated for different signal-to-noise ratios (SNR).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08058", "categories": ["cs.CV", "cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08058", "abs": "https://arxiv.org/abs/2602.08058", "authors": ["Xihang Yu", "Rajat Talak", "Lorenzo Shaikewitz", "Luca Carlone"], "title": "Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling", "comment": "15 pages", "summary": "In the presence of occlusions and measurement noise, geometrically accurate scene reconstructions -- which fit the sensor data -- can still be physically incorrect. For instance, when estimating the poses and shapes of objects in the scene and importing the resulting estimates into a simulator, small errors might translate to implausible configurations including object interpenetration or unstable equilibrium. This makes it difficult to predict the dynamic behavior of the scene using a digital twin, an important step in simulation-based planning and control of contact-rich behaviors. In this paper, we posit that object pose and shape estimation requires reasoning holistically over the scene (instead of reasoning about each object in isolation), accounting for object interactions and physical plausibility. Towards this goal, our first contribution is Picasso, a physics-constrained reconstruction pipeline that builds multi-object scene reconstructions by considering geometry, non-penetration, and physics. Picasso relies on a fast rejection sampling method that reasons over multi-object interactions, leveraging an inferred object contact graph to guide samples. Second, we propose the Picasso dataset, a collection of 10 contact-rich real-world scenes with ground truth annotations, as well as a metric to quantify physical plausibility, which we open-source as part of our benchmark. Finally, we provide an extensive evaluation of Picasso on our newly introduced dataset and on the YCB-V dataset, and show it largely outperforms the state of the art while providing reconstructions that are both physically plausible and more aligned with human intuition.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07812", "abs": "https://arxiv.org/abs/2602.07812", "authors": ["Fengting Yuchi", "Li Du", "Jason Eisner"], "title": "LLMs Know More About Numbers than They Can Say", "comment": "EACL 2026", "summary": "Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: \"Which is larger, $5.7 \\times 10^2$ or $580$?\" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08572", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08572", "abs": "https://arxiv.org/abs/2602.08572", "authors": ["Neal M. Parkes", "Kan Ma", "Ben Poole", "Chris Hardie", "Alexander J. Knowles"], "title": "Precipitation induced recrystallisation (PIX) in a Ti-Fe-Mo bcc-superalloy driven by lattice misfit", "comment": "13 pages, 5 main figures, 4 supplementary figures", "summary": "Beta-Ti bcc-superalloys, comprising an A2 beta-Ti matrix reinforced by ordered intermetallic B2 beta-prime-TiFe precipitates, exhibit an unusual recrystallisation that occurs with no externally applied strain (i.e. no thermomechanical processing). Thermal ageing at 750 degrees Celsius for 72 h results in refinement of the grain size from 364 um to 30 um. This grain refinement is driven by discontinuous precipitation of beta-prime-TiFe lamellae with the beta-Ti matrix from grain/phase boundaries, which is associated with significant misorientation and increased dislocation density, attributed as precipitation induced recrystallisation (PIX).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07846", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07846", "abs": "https://arxiv.org/abs/2602.07846", "authors": ["Ning Hu", "Maochen Li", "Senhao Cao"], "title": "System-Level Error Propagation and Tail-Risk Amplification in Reference-Based Robotic Navigation", "comment": "13 pages, 8 figures", "summary": "Image guided robotic navigation systems often rely on reference based geometric perception pipelines, where accurate spatial mapping is established through multi stage estimation processes. In biplanar X ray guided navigation, such pipelines are widely used due to their real time capability and geometric interpretability. However, navigation reliability can be constrained by an overlooked system level failure mechanism in which installation induced structural perturbations introduced at the perception stage are progressively amplified along the perception reconstruction execution chain and dominate execution level error and tail risk behavior. This paper investigates this mechanism from a system level perspective and presents a unified error propagation modeling framework that characterizes how installation induced structural perturbations propagate and couple with pixel level observation noise through biplanar imaging, projection matrix estimation, triangulation, and coordinate mapping. Using first order analytic uncertainty propagation and Monte Carlo simulations, we analyze dominant sensitivity channels and quantify worst case error behavior beyond mean accuracy metrics. The results show that rotational installation error is a primary driver of system level error amplification, while translational misalignment of comparable magnitude plays a secondary role under typical biplanar geometries. Real biplanar X ray bench top experiments further confirm that the predicted amplification trends persist under realistic imaging conditions. These findings reveal a broader structural limitation of reference based multi stage geometric perception pipelines and provide a framework for system level reliability analysis and risk aware design in safety critical robotic navigation systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08609", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08609", "abs": "https://arxiv.org/abs/2602.08609", "authors": ["Nicol\u00f2 Decarli", "Davide Dardari"], "title": "Ziv-Zakai Bound for Near-Field Localization and Sensing", "comment": null, "summary": "The increasing carrier frequencies and growing physical dimensions of antenna arrays in modern wireless systems are driving renewed interest in localization and sensing under near-field conditions. In this paper, we analyze the Ziv-Zakai Bound (ZZB) for near-field localization and sensing operated with large antenna arrays, which offers a tighter characterization of estimation accuracy compared to traditional bounds such as the Cram\u00e9r-Rao Bound (CRB), especially in low signal-to-noise ratio or threshold regions. Leveraging spherical wavefront and array geometry in the signal model, we evaluate the ZZB for distance and angle estimation, investigating the dependence of the accuracy on key signal and system parameters such as array geometry, wavelength, and target position. Our analysis highlights the transition behavior of the ZZB and underscores the fundamental limitations and opportunities for accurate near-field sensing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08328", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08328", "abs": "https://arxiv.org/abs/2602.08328", "authors": ["Yi-Hsuan Hsiao", "Quang Phuc Kieu", "Zhongtao Guan", "Suhan Kim", "Jiaze Cai", "Owen Matteson", "Jonathan P. How", "Elizabeth Farrell Helbling", "YuFeng Chen"], "title": "Controlled Flight of an Insect-Scale Flapping-Wing Robot via Integrated Onboard Sensing and Computation", "comment": "22 pages, 7 figures", "summary": "Aerial insects can effortlessly navigate dense vegetation, whereas similarly sized aerial robots typically depend on offboard sensors and computation to maintain stable flight. This disparity restricts insect-scale robots to operation within motion capture environments, substantially limiting their applicability to tasks such as search-and-rescue and precision agriculture. In this work, we present a 1.29-gram aerial robot capable of hovering and tracking trajectories with solely onboard sensing and computation. The combination of a sensor suite, estimators, and a low-level controller achieved centimeter-scale positional flight accuracy. Additionally, we developed a hierarchical controller in which a human operator provides high-level commands to direct the robot's motion. In a 30-second flight experiment conducted outside a motion capture system, the robot avoided obstacles and ultimately landed on a sunflower. This level of sensing and computational autonomy represents a significant advancement for the aerial microrobotics community, further opening opportunities to explore onboard planning and power autonomy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07839", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07839", "abs": "https://arxiv.org/abs/2602.07839", "authors": ["Jiaxi Liu", "Yanzuo Jiang", "Guibin Zhang", "Zihan Zhang", "Heng Chang", "Zhenfei Yin", "Qibing Ren", "Junchi Yan"], "title": "TodoEvolve: Learning to Architect Agent Planning Systems", "comment": null, "summary": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08627", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08627", "abs": "https://arxiv.org/abs/2602.08627", "authors": ["Andreas Opitz", "Hongwon Kim", "Dmitry Lapkin", "Gianfranco Melis", "Ainur Abukaev", "Marie Siegert", "Lennart Frohloff", "Lisa Schraut-May", "Oleg Konovalov", "Alexander Hinderhofer", "Frank Schreiber", "Jens Pflaum", "Wolfgang Br\u00fctting"], "title": "Phase behavior and electrical transport in DBTTF-HATCN donor-acceptor mixtures", "comment": null, "summary": "The formation of donor-acceptor complexes (DACs) between the electron donor Dibenzotetrathiafulvalene (DBTTF) and the acceptor Hexaaza\\-triphenylene\\-hexacarbo\\-nitrile (HATCN) results in a new phase with a distinctly different crystal structure as well as new optical absorption bands below the energy gaps of the two pristine materials. X-ray scattering and atomic force microscopy provide detailed insights into the film structure and morphology by systematic variation of the mixing ratio from pristine DBTTF to pristine HATCN. The measured electrical conductivity of thin films depends in a highly non-monotonic manner on the composition of the mixture and shows significantly improved charge transport compared to the pristine films. The temperature-dependent conductivity, charge carrier concentration, and mobility were investigated across these compositions. Surprisingly, all compositions exhibited n-type behavior, except for pristine DBTTF. This behavior is explained by the electronic structure of the mixtures, as revealed by ultraviolet photoelectron spectroscopy, which indicates that charge injection and transport occur via the lowest unoccupied molecular orbital of the DAC and HATCN. Additionally, the observed electrical conductivity is strongly influenced by morphology and structural ordering of the films. These findings offer valuable insights for the design of advanced materials with enhanced electrical performance.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07888", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07888", "abs": "https://arxiv.org/abs/2602.07888", "authors": ["Ning Hu", "Shuai Li", "Jindong Tan"], "title": "Research on a Camera Position Measurement Method based on a Parallel Perspective Error Transfer Model", "comment": "32 pages, 19 figures", "summary": "Camera pose estimation from sparse correspondences is a fundamental problem in geometric computer vision and remains particularly challenging in near-field scenarios, where strong perspective effects and heterogeneous measurement noise can significantly degrade the stability of analytic PnP solutions. In this paper, we present a geometric error propagation framework for camera pose estimation based on a parallel perspective approximation. By explicitly modeling how image measurement errors propagate through perspective geometry, we derive an error transfer model that characterizes the relationship between feature point distribution, camera depth, and pose estimation uncertainty. Building on this analysis, we develop a pose estimation method that leverages parallel perspective initialization and error-aware weighting within a Gauss-Newton optimization scheme, leading to improved robustness in proximity operations. Extensive experiments on both synthetic data and real-world images, covering diverse conditions such as strong illumination, surgical lighting, and underwater low-light environments, demonstrate that the proposed approach achieves accuracy and robustness comparable to state-of-the-art analytic and iterative PnP methods, while maintaining high computational efficiency. These results highlight the importance of explicit geometric error modeling for reliable camera pose estimation in challenging near-field settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08697", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08697", "abs": "https://arxiv.org/abs/2602.08697", "authors": ["Nikos G. Evgenidis", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "Ioannis Krikidis", "George K. Karagiannidis"], "title": "Improving Reliability of Hybrid Bit-Semantic Communications for Cellular Networks", "comment": null, "summary": "Semantic communications (SemComs) have been considered as a promising solution to reduce the amount of transmitted information, thus paving the way for more energy-and spectrum-efficient wireless networks. Nevertheless, SemComs rely heavily on the utilization of deep neural networks (DNNs) at the transceivers, which limit the accuracy between the original and reconstructed data and are challenging to implement in practice due to increased architecture complexity. Thus, hybrid cellular networks that utilize both conventional bit communications (BitComs) and SemComs have been introduced to bridge the gap between required and existing infrastructure. To facilitate such networks, in this work, we investigate reliability by deriving closed-form expressions for the outage probability of the network. Additionally, we propose a generalized outage probability through which the cell radius that achieves a desired outage threshold for a specific range of users is calculated in closed form. Additionally, to consider the practical limitations caused by the specialized dedicated hardware and the increased memory and computational resources that are required to support SemCom, a semantic utilization metric is proposed. Based on this metric, we express the probability that a specific number of users select SemCom transmission and calculate the optimal cell radius for that number in closed form. Simulation results validate the derived analytical expressions and the characterized design properties of the cell radius found through the proposed metrics, providing useful insights.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08444", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08444", "abs": "https://arxiv.org/abs/2602.08444", "authors": ["Samsaptak Ghosh", "M. Felix Orlando", "Sohom Chakrabarty"], "title": "Post-Collision Trajectory Restoration for a Single-track Ackermann Vehicle using Heuristic Steering and Tractive Force Functions", "comment": "10 pages, 6 figures", "summary": "Post-collision trajectory restoration is a safety-critical capability for autonomous vehicles, as impact-induced lateral motion and yaw transients can rapidly drive the vehicle away from the intended path. This paper proposes a structured heuristic recovery control law that jointly commands steering and tractive force for a generalized single-track Ackermann vehicle model. The formulation explicitly accounts for time-varying longitudinal velocity in the lateral-yaw dynamics and retains nonlinear steering-coupled interaction terms that are commonly simplified in the literature. Unlike approaches that assume constant longitudinal speed, the proposed design targets the transient post-impact regime where speed variations and nonlinear coupling significantly influence recovery. The method is evaluated in simulation on the proposed generalized single-track model and a standard 3DOF single-track reference model in MATLAB, demonstrating consistent post-collision restoration behaviour across representative initial post-impact conditions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07842", "abs": "https://arxiv.org/abs/2602.07842", "authors": ["Yuhan Wang", "Shiyu Ni", "Zhikai Ding", "Zihang Zhan", "Yuanzi Li", "Keping Bi"], "title": "Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers", "comment": null, "summary": "Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08752", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08752", "abs": "https://arxiv.org/abs/2602.08752", "authors": ["Fanjie Xu", "Jinyuan Hu", "Jingxiang Zou", "Junjie Wang", "Boying Huang", "Zhifeng Gao", "Xiaohong Ji", "Weinan E", "Zhong-Qun Tian", "Fujie Tang", "Jun Cheng"], "title": "Synergistic cross-modal learning for experimental NMR-based structure elucidation", "comment": "31 pages, 9 figures", "summary": "One-dimensional nuclear magnetic resonance (NMR) spectroscopy is essential for molecular structure elucidation in organic synthesis, drug discovery, natural product characterization, and metabolomics, yet its interpretation remains heavily dependent on expert knowledge and difficult to scale. Although machine learning has been applied to NMR spectrum prediction, library retrieval, and structure generation, these tasks have evolved in isolation using simulated data and incompatible spectral representations, limiting their utility under real experimental scenarios.Here we present NMRPeak, a unified cross-modal learning system that integrates these three tasks through experimentally grounded design. We curate approximately 1.8 million experimental and simulated spectra to construct the largest benchmark for NMR-based structure elucidation and systematically quantify the distribution shift between these domains. We introduce a chemically-aware adaptive tokenizer that dynamically balances discretization granularity to preserve spectral semantics while controlling vocabulary size, and an assignment-free peak-aware similarity metric that enables direct comparison between predicted and experimental spectra. Through a unified molecule-to-spectrum paradigm and synergistic coupling of prediction, retrieval, and generation modules, NMRPeak achieves transformative performance on experimental benchmarks: it overcomes the longstanding simulation-to-experiment gap in spectrum prediction while delivering over 95% top-1 accuracy in molecular retrieval and approximately 75% top-1 accuracy in stereochemistry-aware de novo structure generation. These capabilities establish a foundation for automated, high-throughput molecular structure elucidation in organic synthesis, drug discovery, and chemical biology.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07901", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07901", "abs": "https://arxiv.org/abs/2602.07901", "authors": ["Mark Griguletskii", "Danil Belov", "Pavel Osinenko"], "title": "Incremental Mapping with Measurement Synchronization & Compression", "comment": "8 pages, 4 figures, 1 table", "summary": "Modern autonomous vehicles and robots utilize versatile sensors for localization and mapping. The fidelity of these maps is paramount, as an accurate environmental representation is a prerequisite for stable and precise localization. Factor graphs provide a powerful approach for sensor fusion, enabling the estimation of the maximum a posteriori solution. However, the discrete nature of graph-based representations, combined with asynchronous sensor measurements, complicates consistent state estimation. The design of an optimal factor graph topology remains an open challenge, especially in multi-sensor systems with asynchronous data. Conventional approaches rely on a rigid graph structure, which becomes inefficient with sensors of disparate rates. Although preintegration techniques can mitigate this for high-rate sensors, their applicability is limited. To address this problem, this work introduces a novel approach that incrementally constructs connected factor graphs, ensuring the incorporation of all available sensor data by choosing the optimal graph topology based on the external evaluation criteria. The proposed methodology facilitates graph compression, reducing the number of nodes (optimized variables) by ~30% on average while maintaining map quality at a level comparable to conventional approaches.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08795", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08795", "abs": "https://arxiv.org/abs/2602.08795", "authors": ["Hao Jiang", "Xiaojun Yuan", "Qinghua Guo"], "title": "Joint Channel Sounding and Source-Channel Coding for MIMO-OFDM Systems: Deep Unified Encoding and Parallel Flow-Matching Decoding", "comment": null, "summary": "In this work, we propose a deep unified (DU) encoder that embeds source information in a codeword that contains sufficient redundancy to handle both channel and source uncertainties, without enforcing an explicit pilot-data separation. At the receiver, we design a parallel flow-matching (PFM) decoder that leverages flow-based generative priors to jointly estimate the channel and the source, yielding much more efficient inference than the existing diffusion-based approaches. To benchmark performance limits, we derive the Bayesian Cram\u00e9r-Rao bound (BCRB) for the joint channel and source estimation problem. Extensive simulations over block-fading MIMO-OFDM channels demonstrate that the proposed DU-PFM approach drastically outperforms the state-of-the-art methods in both channel estimation accuracy and source reconstruction quality.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07909", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07909", "abs": "https://arxiv.org/abs/2602.07909", "authors": ["Taolin Zhang", "Hang Guo", "Wang Lu", "Tao Dai", "Shu-Tao Xia", "Jindong Wang"], "title": "SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization", "comment": "ICLR2026", "summary": "As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$\u03c4$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07913", "categories": ["cs.RO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07913", "abs": "https://arxiv.org/abs/2602.07913", "authors": ["Ren\u00e1ta Rusn\u00e1kov\u00e1", "Martin Chovanec", "Juraj Gazda"], "title": "Multi-Agent Route Planning as a QUBO Problem", "comment": null, "summary": "Multi-Agent Route Planning considers selecting vehicles, each associated with a single predefined route, such that the spatial coverage of a road network is increased while redundant overlaps are limited. This paper gives a formal problem definition, proves NP-hardness by reduction from the Weighted Set Packing problem, and derives a Quadratic Unconstrained Binary Optimization formulation whose coefficients directly encode unique coverage rewards and pairwise overlap penalties. A single penalty parameter controls the coverage-overlap trade-off. We distinguish between a soft regime, which supports multi-objective exploration, and a hard regime, in which the penalty is strong enough to effectively enforce near-disjoint routes. We describe a practical pipeline for generating city instances, constructing candidate routes, building the QUBO matrix, and solving it with an exact mixed-integer solver (Gurobi), simulated annealing, and D-Wave hybrid quantum annealing. Experiments on Barcelona instances with up to 10 000 vehicles reveal a clear coverage-overlap knee and show that Pareto-optimal solutions are mainly obtained under the hard-penalty regime, while D-Wave hybrid solvers and Gurobi achieve essentially identical objective values with only minor differences in runtime as problem size grows.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07930", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07930", "abs": "https://arxiv.org/abs/2602.07930", "authors": ["Irina Bigoulaeva", "Jonas Rohweder", "Subhabrata Dutta", "Iryna Gurevych"], "title": "Patches of Nonlinearity: Instruction Vectors in Large Language Models", "comment": null, "summary": "Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07924", "categories": ["cs.RO", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07924", "abs": "https://arxiv.org/abs/2602.07924", "authors": ["Nur Ahmad Khatim", "Mansur Arief"], "title": "Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities", "comment": null, "summary": "Securing petroleum infrastructure requires balancing autonomous system efficiency with human judgment for threat escalation, a challenge unaddressed by classical facility location models assuming homogeneous resources. This paper formulates the Human-Robot Co-Dispatch Facility Location Problem (HRCD-FLP), a capacitated facility location variant incorporating tiered infrastructure criticality, human-robot supervision ratio constraints, and minimum utilization requirements. We evaluate command center selection across three technology maturity scenarios. Results show transitioning from conservative (1:3 human-robot supervision) to future autonomous operations (1:10) yields significant cost reduction while maintaining complete critical infrastructure coverage. For small problems, exact methods dominate in both cost and computation time; for larger problems, the proposed heuristic achieves feasible solutions in under 3 minutes with approximately 14% optimality gap where comparison is possible. From systems perspective, our work demonstrate that optimized planning for human-robot teaming is key to achieve both cost-effective and mission-reliable deployments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07444", "categories": ["cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07444", "abs": "https://arxiv.org/abs/2602.07444", "authors": ["Ondrej Hlinka", "Georg Kaniak", "Christian Kapeller"], "title": "Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction", "comment": "submitted to IET Electronics Letters", "summary": "We address the problem of reconstructing 3D surfaces from depth and surface normal maps acquired by a sensor system based on a single perspective camera. Depth and normal maps can be obtained through techniques such as structured-light scanning and photometric stereo, respectively. We propose a perspective-aware log-depth fusion approach that extends existing orthographic gradient-based depth-normals fusion methods by explicitly accounting for perspective projection, leading to metrically accurate 3D reconstructions. Additionally, the method handles missing depth measurements by leveraging available surface normal information to inpaint gaps. Experiments on the DiLiGenT-MV data set demonstrate the effectiveness of our approach and highlight the importance of perspective-aware depth-normals fusion.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07954", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07954", "abs": "https://arxiv.org/abs/2602.07954", "authors": ["Krzysztof Wr\u00f3bel", "Jan Maria Kowalski", "Jerzy Surma", "Igor Ciuciura", "Maciej Szyma\u0144ski"], "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation", "comment": null, "summary": "As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\\%) and very low false positive rate (0.63\\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\\% precision, 4.70\\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08841", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08841", "abs": "https://arxiv.org/abs/2602.08841", "authors": ["Yizhuo Li", "Kepeng Song", "Meixiong Zhu", "Xiaoqi Li", "Zhaowei Zeng", "KangMing Luo", "Yuxuan Jiang", "Zhe Zhang", "Cuihong Li", "Yujia Wang", "Bing Li", "Zhihong Wang", "Zhidong Zhang", "Weijin Hu"], "title": "Flash annealing-engineered wafer-scale relaxor antiferroelectrics for enhanced energy storage performance", "comment": "49 pages, 29 figures, 3 tables", "summary": "Dielectric capacitors are essential for energy storage systems due to their high-power density and fast operation speed. However, optimizing energy storage density with concurrent thermal stability remains a substantial challenge. Here, we develop a flash annealing process with ultrafast heating and cooling rates of 1000 oC/s, which facilitates the rapid crystallization of PbZrO3 film within a mere second, while locking its high-temperature microstructure to room temperature. This produces compact films with sub-grain boundaries fraction of 36%, nanodomains of several nanometers, and negligible lead volatilization. These contribute to relaxor antiferroelectric film with a high breakdown strength (4800 kV/cm) and large polarization (70 uC/cm2). Consequently, we have achieved a high energy storage density of 63.5 J/cm3 and outstanding thermal stability with performance degradation less than 3% up to 250 oC. Our approach is extendable to ferroelectrics like Pb(Zr0.52Ti0.48)O3 and on wafer scale, providing on-chip nonlinear dielectric energy storage solutions with industrial scalability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07932", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07932", "abs": "https://arxiv.org/abs/2602.07932", "authors": ["Ying-Sheng Luo", "Lu-Ching Wang", "Hanjaya Mandala", "Yu-Lun Chou", "Guilherme Christmann", "Yu-Chung Chen", "Yung-Shun Chan", "Chun-Yi Lee", "Wei-Chao Chen"], "title": "Feasibility-Guided Planning over Multi-Specialized Locomotion Policies", "comment": "ICRA 2026", "summary": "Planning over unstructured terrain presents a significant challenge in the field of legged robotics. Although recent works in reinforcement learning have yielded various locomotion strategies, planning over multiple experts remains a complex issue. Existing approaches encounter several constraints: traditional planners are unable to integrate skill-specific policies, whereas hierarchical learning frameworks often lose interpretability and require retraining whenever new policies are added. In this paper, we propose a feasibility-guided planning framework that successfully incorporates multiple terrain-specific policies. Each policy is paired with a Feasibility-Net, which learned to predict feasibility tensors based on the local elevation maps and task vectors. This integration allows classical planning algorithms to derive optimal paths. Through both simulated and real-world experiments, we demonstrate that our method efficiently generates reliable plans across diverse and challenging terrains, while consistently aligning with the capabilities of the underlying policies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07479", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07479", "abs": "https://arxiv.org/abs/2602.07479", "authors": ["Yihang Gao", "Vincent Y. F. Tan"], "title": "ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations", "comment": "38 pages", "summary": "Low-rank adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning method in deep transfer learning, due to its reduced number of trainable parameters and lower memory requirements enabled by Burer-Monteiro factorization on adaptation matrices. However, classical LoRA training methods treat the low-rank factor matrices individually and optimize them using standard gradient-based algorithms. Such decoupled optimization schemes are theoretically and empirically suboptimal, as they fail to fully exploit the intrinsic structure of the LoRA parameterization. In this work, we propose a novel continuous-time optimization dynamic for LoRA factor matrices in the form of an ordinary differential equation (ODE) that emulates the gradient flow of full fine-tuning on the balanced manifold. We term this approach ODELoRA. To faithfully track the trajectories of ODELoRA, we adopt well-established and theoretically grounded time-discretization schemes, including Euler and Runge--Kutta methods. Our framework provides a unified ODE-based perspective for understanding and designing LoRA training algorithms. We establish linear convergence of the proposed method under strongly convex objectives for certain discretization schemes under mild conditions, and further extend our analysis to the matrix sensing setting. Moreover, we show that ODELoRA achieves stable feature learning, a property that is crucial for training deep neural networks at different scales of problem dimensionality. Empirical results on matrix sensing tasks confirm the derived linear convergence behavior, and experiments on training physics-informed neural networks further demonstrate the superiority of ODELoRA over existing baselines, especially in the training stability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07963", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07963", "abs": "https://arxiv.org/abs/2602.07963", "authors": ["Vaibhav Shukla", "Hardik Sharma", "Adith N Reganti", "Soham Wasmatkar", "Bagesh Kumar", "Vrijendra Singh"], "title": "Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms", "comment": "Accepted at the AICS Workshop, AAAI 2026", "summary": "Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08935", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.08935", "abs": "https://arxiv.org/abs/2602.08935", "authors": ["Benjamin Colmey", "Tiarnan A. S. Doherty", "Shreshth A. Malik", "Paul A. Midgley"], "title": "The role of absorption in three-dimensional electron diffraction dynamical structure refinement", "comment": null, "summary": "The role of absorption in 3D electron diffraction is established through analytical theory, simulation, and dynamical refinement. A two-beam expression for the absorbed integrated intensity is derived, showing that for $t/\u03be_g \\ll 1$ reflections follow a uniform exponential decay set by the mean absorptive potential $U_0'$. Many-beam simulations demonstrate that neglecting absorption in dynamical refinement of integrated intensities incurs a residual that increases linearly with thickness and diverges near zone axes. Dynamical refinements were performed on CsPbBr$_3$, quartz, and borane, with the inclusion of absorption yielding an improvement in $R_{\\mathrm{obs}}$ from $6.4$ to $5.3$ \\% for CsPbBr$_3$ and negligible changes for quartz and borane. Absorption is therefore deemed negligible for routine refinement of integrated intensities except in high-$Z$ materials at thicknesses approaching $\u03be_g$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07984", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07984", "abs": "https://arxiv.org/abs/2602.07984", "authors": ["Simon Sagmeister", "Panagiotis Kounatidis", "Sven Goblirsch", "Markus Lienkamp"], "title": "Analyzing the Impact of Simulation Fidelity on the Evaluation of Autonomous Driving Motion Control", "comment": "Accepted for publication at the IEEE IV 2024", "summary": "Simulation is crucial in the development of autonomous driving software. In particular, assessing control algorithms requires an accurate vehicle dynamics simulation. However, recent publications use models with varying levels of detail. This disparity makes it difficult to compare individual control algorithms. Therefore, this paper aims to investigate the influence of the fidelity of vehicle dynamics modeling on the closed-loop behavior of trajectory-following controllers. For this purpose, we introduce a comprehensive Autoware-compatible vehicle model. By simplifying this, we derive models with varying fidelity. Evaluating over 550 simulation runs allows us to quantify each model's approximation quality compared to real-world data. Furthermore, we investigate whether the influence of model simplifications changes with varying margins to the acceleration limit of the vehicle. From this, we deduce to which degree a vehicle model can be simplified to evaluate control algorithms depending on the specific application. The real-world data used to validate the simulation environment originate from the Indy Autonomous Challenge race at the Autodromo Nazionale di Monza in June 2023. They show the fastest fully autonomous lap of TUM Autonomous Motorsport, with vehicle speeds reaching 267 kph and lateral accelerations of up to 15 mps2.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08082", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08082", "abs": "https://arxiv.org/abs/2602.08082", "authors": ["Valentin No\u00ebl"], "title": "Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology", "comment": "32 pages, 2 fgures, 18 tables", "summary": "Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method achieves 97.7\\% recall with multi-feature detection and 86.1\\% recall with 81.0\\% precision for balanced deployment, without requiring any labeled training data. Most remarkably, we discover that single layer spectral features act as near-perfect hallucination detectors: Llama L26 Smoothness achieves 98.2\\% recall (213/217 hallucinations caught) with a single threshold, and Mistral L3 Entropy achieves 94.7\\% recall. This suggests hallucination is not merely a wrong token but a thermodynamic state change: the model's attention becomes noise when it errs. Through controlled cross-model evaluation on matched domains ($N=1000$, $T=0.3$, same General domain, hallucination rates 20--22\\%), we reveal the ``Loud Liar'' phenomenon: Llama 3.1 8B's failures are spectrally catastrophic and dramatically easier to detect, while Mistral 7B achieves the best discrimination (AUC 0.900). These findings establish spectral analysis as a principled, efficient framework for agent safety.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07978", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07978", "abs": "https://arxiv.org/abs/2602.07978", "authors": ["Rui Feng", "Zhiyao Luo", "Liuyu Wu", "Wei Wang", "Yuting Song", "Yong Liu", "Kok Pin Ng", "Jianqing Li", "Xingyao Wang"], "title": "Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection", "comment": "18 pages, 7 figures, 6 tables", "summary": "Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08116", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08116", "abs": "https://arxiv.org/abs/2602.08116", "authors": ["Jiawei Xu", "Subhrajit Bhattacharya", "David Salda\u00f1a"], "title": "From Ellipsoids to Midair Control of Dynamic Hitches", "comment": null, "summary": "The ability to dynamically manipulate interaction between cables, carried by pairs of aerial vehicles attached to the ends of each cable, can greatly improve the versatility and agility of cable-assisted aerial manipulation. Such interlacing cables create hitches by winding two or more cables around each other, which can enclose payloads or can further develop into knots. Dynamic modeling and control of such hitches is key to mastering the inter-cable manipulation in context of cable-suspended aerial manipulation. This paper introduces an ellipsoid-based kinematic model to connect the geometric nature of a hitch created by two cables and the dynamics of the hitch driven by four aerial vehicles, which reveals the control-affine form of the system. As the constraint for maintaining tension of a cable is also control-affine, we design a quadratic programming-based controller that combines Control Lyapunov and High-Order Control Barrier Functions (CLF-HOCBF-QP) to precisely track a desired hitch position and system shape while enforcing safety constraints like cable tautness. We convert desired geometric reference configurations into target robot positions and introduce a composite error into the Lyapunov function to ensure a relative degree of one to the input. Numerical simulations validate our approach, demonstrating stable, high-speed tracking of dynamic references.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08768", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08768", "abs": "https://arxiv.org/abs/2602.08768", "authors": ["Chi-Sheng Chen", "Xinyu Zhang", "En-Jui Kuo", "Guan-Ying Chen", "Qiuzhe Xie", "Fan Zhang"], "title": "FreqLens: Interpretable Frequency Attribution for Time Series Forecasting", "comment": null, "summary": "Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \\textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \\textsc{FreqLens} introduces two key innovations: (1) \\emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \\emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \\textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \\pm 0.1$h, 2.5\\% error) and 12-hour half-daily cycle ($11.8 \\pm 0.1$h, 1.6\\% error) on Traffic, and weekly cycles ($10\\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07996", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07996", "abs": "https://arxiv.org/abs/2602.07996", "authors": ["Arash Marioriyad", "Omid Ghahroodi", "Ehsaneddin Asgari", "Mohammad Hossein Rohban", "Mahdieh Soleymani Baghshah"], "title": "The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation", "comment": null, "summary": "Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08167", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08167", "abs": "https://arxiv.org/abs/2602.08167", "authors": ["Milan Ganai", "Katie Luo", "Jonas Frey", "Clark Barrett", "Marco Pavone"], "title": "Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning", "comment": null, "summary": "Embodied Chain-of-Thought (CoT) reasoning has significantly enhanced Vision-Language-Action (VLA) models, yet current methods rely on rigid templates to specify reasoning primitives (e.g., objects in the scene, high-level plans, structural affordances). These templates can force policies to process irrelevant information that distracts from critical action-prediction signals. This creates a bottleneck: without successful policies, we cannot verify reasoning quality; without quality reasoning, we cannot build robust policies. We introduce R&B-EnCoRe, which enables models to bootstrap embodied reasoning from internet-scale knowledge through self-supervised refinement. By treating reasoning as a latent variable within importance-weighted variational inference, models can generate and distill a refined reasoning training dataset of embodiment-specific strategies without external rewards, verifiers, or human annotation. We validate R&B-EnCoRe across manipulation (Franka Panda in simulation, WidowX in hardware), legged navigation (bipedal, wheeled, bicycle, quadruped), and autonomous driving embodiments using various VLA architectures with 1B, 4B, 7B, and 30B parameters. Our approach achieves 28% gains in manipulation success, 101% improvement in navigation scores, and 21% reduction in collision-rate metric over models that indiscriminately reason about all available primitives. R&B-EnCoRe enables models to distill reasoning that is predictive of successful control, bypassing manual annotation engineering while grounding internet-scale knowledge in physical execution.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08005", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08005", "abs": "https://arxiv.org/abs/2602.08005", "authors": ["Jitai Hao", "Qiang Huang", "Yaowei Wang", "Min Zhang", "Jun Yu"], "title": "DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity", "comment": "preprint", "summary": "The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08189", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08189", "abs": "https://arxiv.org/abs/2602.08189", "authors": ["Seoyeon Jang", "Alex Junho Lee", "I Made Aswin Nahrendra", "Hyun Myung"], "title": "Chamelion: Reliable Change Detection for Long-Term LiDAR Mapping in Transient Environments", "comment": "8 pages, IEEE Robot. Automat. Lett. (RA-L) 2026", "summary": "Online change detection is crucial for mobile robots to efficiently navigate through dynamic environments. Detecting changes in transient settings, such as active construction sites or frequently reconfigured indoor spaces, is particularly challenging due to frequent occlusions and spatiotemporal variations. Existing approaches often struggle to detect changes and fail to update the map across different observations. To address these limitations, we propose a dual-head network designed for online change detection and long-term map maintenance. A key difficulty in this task is the collection and alignment of real-world data, as manually registering structural differences over time is both labor-intensive and often impractical. To overcome this, we develop a data augmentation strategy that synthesizes structural changes by importing elements from different scenes, enabling effective model training without the need for extensive ground-truth annotations. Experiments conducted at real-world construction sites and in indoor office environments demonstrate that our approach generalizes well across diverse scenarios, achieving efficient and accurate map updates.\\resubmit{Our source code and additional material are available at: https://chamelion-pages.github.io/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08028", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08028", "abs": "https://arxiv.org/abs/2602.08028", "authors": ["Po-Chun Chen", "Hen-Hsen Huang", "Hsin-Hsi Chen"], "title": "Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning", "comment": "Accepted to Findings of IJCNLP-AACL 2025", "summary": "To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08245", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08245", "abs": "https://arxiv.org/abs/2602.08245", "authors": ["Jinhao Li", "Yuxuan Cong", "Yingqiao Wang", "Hao Xia", "Shan Huang", "Yijia Zhang", "Ningyi Xu", "Guohao Dai"], "title": "STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction", "comment": "13 pages, 9 figures", "summary": "Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08031", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08031", "abs": "https://arxiv.org/abs/2602.08031", "authors": ["Chenwang Wu", "Yiu-ming Cheung", "Shuhai Zhang", "Bo Han", "Defu Lian"], "title": "Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection", "comment": null, "summary": "While machine-generated texts (MGTs) offer great convenience, they also pose risks such as disinformation and phishing, highlighting the need for reliable detection. Metric-based methods, which extract statistically distinguishable features of MGTs, are often more practical than complex model-based methods that are prone to overfitting. Given their diverse designs, we first place representative metric-based methods within a unified framework, enabling a clear assessment of their advantages and limitations. Our analysis identifies a core challenge across these methods: the token-level detection score is easily biased by the inherent randomness of the MGTs generation process. To address this, we theoretically and empirically reveal two relationships of context detection scores that may aid calibration: Neighbor Similarity and Initial Instability. We then propose a Markov-informed score calibration strategy that models these relationships using Markov random fields, and implements it as a lightweight component via a mean-field approximation, allowing our method to be seamlessly integrated into existing detectors. Extensive experiments in various real-world scenarios, such as cross-LLM and paraphrasing attacks, demonstrate significant gains over baselines with negligible computational overhead. The code is available at https://github.com/tmlr-group/MRF_Calibration.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08251", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08251", "abs": "https://arxiv.org/abs/2602.08251", "authors": ["Yuanzhu Zhan", "Yufei Jiang", "Muqing Cao", "Junyi Geng"], "title": "Aerial Manipulation with Contact-Aware Onboard Perception and Hybrid Control", "comment": "9 pages, 7 figures. Accepted by ICRA 2026", "summary": "Aerial manipulation (AM) promises to move Unmanned Aerial Vehicles (UAVs) beyond passive inspection to contact-rich tasks such as grasping, assembly, and in-situ maintenance. Most prior AM demonstrations rely on external motion capture (MoCap) and emphasize position control for coarse interactions, limiting deployability. We present a fully onboard perception-control pipeline for contact-rich AM that achieves accurate motion tracking and regulated contact wrenches without MoCap. The main components are (1) an augmented visual-inertial odometry (VIO) estimator with contact-consistency factors that activate only during interaction, tightening uncertainty around the contact frame and reducing drift, and (2) image-based visual servoing (IBVS) to mitigate perception-control coupling, together with a hybrid force-motion controller that regulates contact wrenches and lateral motion for stable contact. Experiments show that our approach closes the perception-to-wrench loop using only onboard sensing, yielding an velocity estimation improvement of 66.01% at contact, reliable target approach, and stable force holding-pointing toward deployable, in-the-wild aerial manipulation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08048", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08048", "abs": "https://arxiv.org/abs/2602.08048", "authors": ["Arshia Hemmat", "Philip Torr", "Yongqiang Chen", "Junchi Yu"], "title": "TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs", "comment": null, "summary": "Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07543", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07543", "abs": "https://arxiv.org/abs/2602.07543", "authors": ["Heewoong Noh", "Gyoung S. Na", "Namkyeong Lee", "Chanyoung Park"], "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning", "comment": null, "summary": "Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08266", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08266", "abs": "https://arxiv.org/abs/2602.08266", "authors": ["Seunghoon Jeong", "Eunho Lee", "Jeongyun Kim", "Ayoung Kim"], "title": "Informative Object-centric Next Best View for Object-aware 3D Gaussian Splatting in Cluttered Scenes", "comment": "9 pages, 8 figures, 4 tables, accepted to ICRA 2026", "summary": "In cluttered scenes with inevitable occlusions and incomplete observations, selecting informative viewpoints is essential for building a reliable representation. In this context, 3D Gaussian Splatting (3DGS) offers a distinct advantage, as it can explicitly guide the selection of subsequent viewpoints and then refine the representation with new observations. However, existing approaches rely solely on geometric cues, neglect manipulation-relevant semantics, and tend to prioritize exploitation over exploration. To tackle these limitations, we introduce an instance-aware Next Best View (NBV) policy that prioritizes underexplored regions by leveraging object features. Specifically, our object-aware 3DGS distills instancelevel information into one-hot object vectors, which are used to compute confidence-weighted information gain that guides the identification of regions associated with erroneous and uncertain Gaussians. Furthermore, our method can be easily adapted to an object-centric NBV, which focuses view selection on a target object, thereby improving reconstruction robustness to object placement. Experiments demonstrate that our NBV policy reduces depth error by up to 77.14% on the synthetic dataset and 34.10% on the real-world GraspNet dataset compared to baselines. Moreover, compared to targeting the entire scene, performing NBV on a specific object yields an additional reduction of 25.60% in depth error for that object. We further validate the effectiveness of our approach through real-world robotic manipulation tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08100", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08100", "abs": "https://arxiv.org/abs/2602.08100", "authors": ["Jasmine Cui", "Charles Ye"], "title": "Emergent Search and Backtracking in Latent Reasoning Models", "comment": null, "summary": "What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08278", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08278", "abs": "https://arxiv.org/abs/2602.08278", "authors": ["Ke Zhang", "Lixin Xu", "Chengyi Song", "Junzhe Xu", "Xiaoyi Lin", "Zeyu Jiang", "Renjing Xu"], "title": "DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer", "comment": null, "summary": "Dexterous manipulation remains one of the most challenging problems in robotics, requiring coherent control of high-DoF hands and arms under complex, contact-rich dynamics. A major barrier is embodiment variability: different dexterous hands exhibit distinct kinematics and dynamics, forcing prior methods to train separate policies or rely on shared action spaces with per-embodiment decoder heads. We present DexFormer, an end-to-end, dynamics-aware cross-embodiment policy built on a modified transformer backbone that conditions on historical observations. By using temporal context to infer morphology and dynamics on the fly, DexFormer adapts to diverse hand configurations and produces embodiment-appropriate control actions. Trained over a variety of procedurally generated dexterous-hand assets, DexFormer acquires a generalizable manipulation prior and exhibits strong zero-shot transfer to Leap Hand, Allegro Hand, and Rapid Hand. Our results show that a single policy can generalize across heterogeneous hand embodiments, establishing a scalable foundation for cross-embodiment dexterous manipulation. Project website: https://davidlxu.github.io/DexFormer-web/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08124", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08124", "abs": "https://arxiv.org/abs/2602.08124", "authors": ["Ke Xu", "Shera Potka", "Alex Thomo"], "title": "Gender and Race Bias in Consumer Product Recommendations by Large Language Models", "comment": "Accepted at the 39th International Conference on Advanced Information Networking and Applications (AINA 2025)", "summary": "Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08285", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08285", "abs": "https://arxiv.org/abs/2602.08285", "authors": ["Josh Pinskier", "Sarah Baldwin", "Stephen Rodan", "David Howard"], "title": "ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects", "comment": null, "summary": "Climate change, invasive species and human activities are currently damaging the world's coral reefs at unprecedented rates, threatening their vast biodiversity and fisheries, and reducing coastal protection. Solving this vast challenge requires scalable coral regeneration technologies that can breed climate-resilient species and accelerate the natural regrowth processes; actions that are impeded by the absence of safe and robust tools to handle the fragile coral. We investigate ReefFlex, a generative soft finger design methodology that explores a diverse space of soft fingers to produce a set of candidates capable of safely grasping fragile and geometrically heterogeneous coral in a cluttered environment. Our key insight is encoding heterogeneous grasping into a reduced set of motion primitives, creating a simplified, tractable multi-objective optimisation problem. To evaluate the method, we design a soft robot for reef rehabilitation, which grows and manipulates coral in onshore aquaculture facilities for future reef out-planting. We demonstrate ReefFlex increases both grasp success and grasp quality (disturbance resistance, positioning accuracy) and reduces in adverse events encountered during coral manipulation compared to reference designs. ReefFlex, offers a generalisable method to design soft end-effectors for complex handling and paves a pathway towards automation in previously unachievable domains like coral handling for restoration.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08149", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08149", "abs": "https://arxiv.org/abs/2602.08149", "authors": ["Sahana Ramnath", "Nima Chitsazan", "Mingyang Zhou", "Chia-Hsuan Lee", "Shi-Xiong Zhang", "Stephen Rawls", "Sambit Sahu", "Sangwoo Cho", "Xiang Ren", "Genta Indra Winata", "Akshaj Kumar Veldanda"], "title": "DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries", "comment": null, "summary": "Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08298", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08298", "abs": "https://arxiv.org/abs/2602.08298", "authors": ["Yuxin Zhang", "Cheng Wang", "Hubert P. H. Shum"], "title": "Benchmarking Autonomous Vehicles: A Driver Foundation Model Framework", "comment": null, "summary": "Autonomous vehicles (AVs) are poised to revolutionize global transportation systems. However, its widespread acceptance and market penetration remain significantly below expectations. This gap is primarily driven by persistent challenges in safety, comfort, commuting efficiency and energy economy when compared to the performance of experienced human drivers. We hypothesize that these challenges can be addressed through the development of a driver foundation model (DFM). Accordingly, we propose a framework for establishing DFMs to comprehensively benchmark AVs. Specifically, we describe a large-scale dataset collection strategy for training a DFM, discuss the core functionalities such a model should possess, and explore potential technical solutions to realize these functionalities. We further present the utility of the DFM across the operational spectrum, from defining human-centric safety envelopes to establishing benchmarks for energy economy. Overall, We aim to formalize the DFM concept and introduce a new paradigm for the systematic specification, verification and validation of AVs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08162", "abs": "https://arxiv.org/abs/2602.08162", "authors": ["Ricardo Campos", "Jos\u00e9 Pedro Evans", "Jos\u00e9 Miguel Isidro", "Miguel Marques", "Lu\u00eds Filipe Cunha", "Al\u00edpio Jorge", "S\u00e9rgio Nunes", "Nuno Guimar\u00e3es"], "title": "NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark", "comment": null, "summary": "Local governance meeting records are official documents, in the form of minutes or transcripts, documenting how proposals, discussions, and procedural actions unfold during institutional meetings. While generally structured, these documents are often dense, bureaucratic, and highly heterogeneous across municipalities, exhibiting significant variation in language, terminology, structure, and overall organization. This heterogeneity makes them difficult for non-experts to interpret and challenging for intelligent automated systems to process, limiting public transparency and civic engagement. To address these challenges, computational methods can be employed to structure and interpret such complex documents. In particular, Natural Language Processing (NLP) offers well-established methods that can enhance the accessibility and interpretability of governmental records. In this focus article, we review foundational NLP tasks that support the structuring of local governance meeting documents. Specifically, we review three core tasks: document segmentation, domain-specific entity extraction and automatic text summarization, which are essential for navigating lengthy deliberations, identifying political actors and personal information, and generating concise representations of complex decision-making processes. In reviewing these tasks, we discuss methodological approaches, evaluation metrics, and publicly available resources, while highlighting domain-specific challenges such as data scarcity, privacy constraints, and source variability. By synthesizing existing work across these foundational tasks, this article provides a structured overview of how NLP can enhance the structuring and accessibility of local governance meeting records.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08326", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08326", "abs": "https://arxiv.org/abs/2602.08326", "authors": ["Yongjae Lim", "Dabin Kim", "H. Jin Kim"], "title": "Personalized Autonomous Driving via Optimal Control with Clearance Constraints from Questionnaires", "comment": null, "summary": "Driving without considering the preferred separation distance from surrounding vehicles may cause discomfort for users. To address this limitation, we propose a planning framework that explicitly incorporates user preferences regarding the desired level of safe clearance from surrounding vehicles. We design a questionnaire purposefully tailored to capture user preferences relevant to our framework, while minimizing unnecessary questions. Specifically, the questionnaire considers various interaction-relevant factors, including the surrounding vehicle's size, speed, position, and maneuvers of surrounding vehicles, as well as the maneuvers of the ego vehicle. The response indicates the user-preferred clearance for the scenario defined by the question and is incorporated as constraints in the optimal control problem. However, it is impractical to account for all possible scenarios that may arise in a driving environment within a single optimal control problem, as the resulting computational complexity renders real-time implementation infeasible. To overcome this limitation, we approximate the original problem by decomposing it into multiple subproblems, each dealing with one fixed scenario. We then solve these subproblems in parallel and select one using the cost function from the original problem. To validate our work, we conduct simulations using different user responses to the questionnaire. We assess how effectively our planner reflects user preferences compared to preference-agnostic baseline planners by measuring preference alignment.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08208", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08208", "abs": "https://arxiv.org/abs/2602.08208", "authors": ["Cameron R. Jones", "Agnese Lombardi", "Kyle Mahowald", "Benjamin K. Bergen"], "title": "LLMs and people both learn to form conventions -- just not with each other", "comment": "10 pages, 4 figures", "summary": "Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08220", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08220", "abs": "https://arxiv.org/abs/2602.08220", "authors": ["Boyi Zeng", "Yiqin Hao", "He Li", "Shixiang Song", "Feichen Song", "Zitong Wang", "Siyuan Huang", "Yi Xu", "ZiWei He", "Xinbing Wang", "Zhouhan Lin"], "title": "Pretraining with Token-Level Adaptive Latent Chain-of-Thought", "comment": null, "summary": "Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08334", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08334", "abs": "https://arxiv.org/abs/2602.08334", "authors": ["Xuanjin Jin", "Yanxin Dong", "Bin Sun", "Huan Xu", "Zhihui Hao", "XianPeng Lang", "Panpan Cai"], "title": "Vec-QMDP: Vectorized POMDP Planning on CPUs for Real-Time Autonomous Driving", "comment": null, "summary": "Planning under uncertainty for real-world robotics tasks, such as autonomous driving, requires reasoning in enormous high-dimensional belief spaces, rendering the problem computationally intensive. While parallelization offers scalability, existing hybrid CPU-GPU solvers face critical bottlenecks due to host-device synchronization latency and branch divergence on SIMT architectures, limiting their utility for real-time planning and hindering real-robot deployment. We present Vec-QMDP, a CPU-native parallel planner that aligns POMDP search with modern CPUs' SIMD architecture, achieving $227\\times$--$1073\\times$ speedup over state-of-the-art serial planners. Vec-QMDP adopts a Data-Oriented Design (DOD), refactoring scattered, pointer-based data structures into contiguous, cache-efficient memory layouts. We further introduce a hierarchical parallelism scheme: distributing sub-trees across independent CPU cores and SIMD lanes, enabling fully vectorized tree expansion and collision checking. Efficiency is maximized with the help of UCB load balancing across trees and a vectorized STR-tree for coarse-level collision checking. Evaluated on large-scale autonomous driving benchmarks, Vec-QMDP achieves state-of-the-art planning performance with millisecond-level latency, establishing CPUs as a high-performance computing platform for large-scale planning under uncertainty.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08221", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08221", "abs": "https://arxiv.org/abs/2602.08221", "authors": ["Xuhua Ma", "Richong Zhang", "Zhijie Nie"], "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08370", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08370", "abs": "https://arxiv.org/abs/2602.08370", "authors": ["Yeke Chen", "Shihao Dong", "Xiaoyu Ji", "Jingkai Sun", "Zeren Luo", "Liu Zhao", "Jiahui Zhang", "Wanyue Li", "Ji Ma", "Bowen Xu", "Yimin Han", "Yudong Zhao", "Peng Lu"], "title": "Learning Human-Like Badminton Skills for Humanoid Robots", "comment": "10 pages, 4 figures", "summary": "Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware striking without compromising stylistic naturalness is non-trivial. To address this, we propose Imitation-to-Interaction, a progressive reinforcement learning framework designed to evolve a robot from a \"mimic\" to a capable \"striker.\" Our approach establishes a robust motor prior from human data, distills it into a compact, model-based state representation, and stabilizes dynamics via adversarial priors. Crucially, to overcome the sparsity of expert demonstrations, we introduce a manifold expansion strategy that generalizes discrete strike points into a dense interaction volume. We validate our framework through the mastery of diverse skills, including lifts and drop shots, in simulation. Furthermore, we demonstrate the first zero-shot sim-to-real transfer of anthropomorphic badminton skills to a humanoid robot, successfully replicating the kinetic elegance and functional precision of human athletes in the physical world.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08235", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08235", "abs": "https://arxiv.org/abs/2602.08235", "authors": ["Jaylen Jones", "Zhehao Zhang", "Yuting Ning", "Eric Fosler-Lussier", "Pierre-Luc St-Charles", "Yoshua Bengio", "Dawn Song", "Yu Su", "Huan Sun"], "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents", "comment": "Project Homepage: https://osu-nlp-group.github.io/AutoElicit/", "summary": "Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08392", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08392", "abs": "https://arxiv.org/abs/2602.08392", "authors": ["Xin Wu", "Zhixuan Liang", "Yue Ma", "Mengkang Hu", "Zhiyuan Qin", "Xiu Li"], "title": "BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models", "comment": "38 pages, 9 figures. Project page:https://bimanibench.github.io/", "summary": "Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three tiers: fundamental spatial reasoning, high-level action planning, and low-level end-effector control. Our framework isolates unique bimanual challenges, such as arm reachability and kinematic constraints, thereby distinguishing perceptual hallucinations from planning failures. Analysis of over 30 state-of-the-art models reveals that despite high-level reasoning proficiency, MLLMs struggle with dual-arm spatial grounding and control, frequently resulting in mutual interference and sequencing errors. These findings suggest the current paradigm lacks a deep understanding of mutual kinematic constraints, highlighting the need for future research to focus on inter-arm collision-avoidance and fine-grained temporal sequencing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08237", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08237", "abs": "https://arxiv.org/abs/2602.08237", "authors": ["Yao Xiao", "Lei Wang", "Yue Deng", "Guanzheng Chen", "Ziqi Jin", "Jung-jae Kim", "Xiaoli Li", "Roy Ka-wei Lee", "Lidong Bing"], "title": "Document Reconstruction Unlocks Scalable Long-Context RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08417", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08417", "abs": "https://arxiv.org/abs/2602.08417", "authors": ["Wentao Zhao", "Yihe Niu", "Zikun Chen", "Rui Li", "Yanbo Wang", "Tianchen Deng", "Jingchuan Wang"], "title": "Graph-Loc: Robust Graph-Based LiDAR Pose Tracking with Compact Structural Map Priors under Low Observability and Occlusion", "comment": "13 pages, 8 figures, 8 tables", "summary": "Map-based LiDAR pose tracking is essential for long-term autonomous operation, where onboard map priors need be compact for scalable storage and fast retrieval, while online observations are often partial, repetitive, and heavily occluded. We propose Graph-Loc, a graph-based localization framework that tracks the platform pose against compact structural map priors represented as a lightweight point-line graph. Such priors can be constructed from heterogeneous sources commonly available in practice, including polygon outlines vectorized from occupancy/grid maps and CAD/model/floor-plan layouts. For each incoming LiDAR scan, Graph-Loc extracts sparse point and line primitives to form an observation graph, retrieves a pose-conditioned visible subgraph via LiDAR ray simulation, and performs scan-to-map association through unbalanced optimal transport with a local graph-context regularizer. The unbalanced formulation relaxes mass conservation, improving robustness to missing, spurious, and fragmented structures under occlusion. To enhance stability in low-observability segments, we estimate information anisotropy from the refinement normal matrix and defer updates along weakly constrained directions until sufficient constraints reappear. Experiments on public benchmarks, controlled stress tests, and real-world deployments demonstrate accurate and stable tracking with KB-level priors from heterogeneous map sources, including under geometrically degenerate and sustained occlusion and in the presence of gradual scene changes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08238", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08238", "abs": "https://arxiv.org/abs/2602.08238", "authors": ["Nathaniel Imel", "Noga Zaslavasky"], "title": "On convexity and efficiency in semantic systems", "comment": null, "summary": "There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08421", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08421", "abs": "https://arxiv.org/abs/2602.08421", "authors": ["Farhad Keramat", "Salma Salimi", "Tomi Westerlund"], "title": "Decentralized Intent-Based Multi-Robot Task Planner with LLM Oracles on Hyperledger Fabric", "comment": null, "summary": "Large language models (LLMs) have opened new opportunities for transforming natural language user intents into executable actions. This capability enables embodied AI agents to perform complex tasks, without involvement of an expert, making human-robot interaction (HRI) more convenient. However these developments raise significant security and privacy challenges such as self-preferencing, where a single LLM service provider dominates the market and uses this power to promote their own preferences. LLM oracles have been recently proposed as a mechanism to decentralize LLMs by executing multiple LLMs from different vendors and aggregating their outputs to obtain a more reliable and trustworthy final result. However, the accuracy of these approaches highly depends on the aggregation method. The current aggregation methods mostly use semantic similarity between various LLM outputs, not suitable for robotic task planning, where the temporal order of tasks is important. To fill the gap, we propose an LLM oracle with a new aggregation method for robotic task planning. In addition, we propose a decentralized multi-robot infrastructure based on Hyperledger Fabric that can host the proposed oracle. The proposed infrastructure enables users to express their natural language intent to the system, which then can be decomposed into subtasks. These subtasks require coordinating different robots from different vendors, while enforcing fine-grained access control management on the data. To evaluate our methodology, we created the SkillChain-RTD benchmark made it publicly available. Our experimental results demonstrate the feasibility of the proposed architecture, and the proposed aggregation method outperforms other aggregation methods currently in use.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08252", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08252", "abs": "https://arxiv.org/abs/2602.08252", "authors": ["Devin R. Wright", "Justin E. Lane", "F. LeRon Shults"], "title": "Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence", "comment": "Initial submitted version", "summary": "In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08425", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08425", "abs": "https://arxiv.org/abs/2602.08425", "authors": ["Jinxian Zhou", "Ruihai Wu", "Yiwei Liu", "Yiwen Hou", "Xunzhe Zhou", "Checheng Yu", "Licheng Zhong", "Lin Shao"], "title": "Bi-Adapt: Few-shot Bimanual Adaptation for Novel Categories of 3D Objects via Semantic Correspondence", "comment": null, "summary": "Bimanual manipulation is imperative yet challenging for robots to execute complex tasks, requiring coordinated collaboration between two arms. However, existing methods for bimanual manipulation often rely on costly data collection and training, struggling to generalize to unseen objects in novel categories efficiently. In this paper, we present Bi-Adapt, a novel framework designed for efficient generalization for bimanual manipulation via semantic correspondence. Bi-Adapt achieves cross-category affordance mapping by leveraging the strong capability of vision foundation models. Fine-tuning with restricted data on novel categories, Bi-Adapt exhibits notable generalization to out-of-category objects in a zero-shot manner. Extensive experiments conducted in both simulation and real-world environments validate the effectiveness of our approach and demonstrate its high efficiency, achieving a high success rate on different benchmark tasks across novel categories with limited data. Project website: https://biadapt-project.github.io/", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08274", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08274", "abs": "https://arxiv.org/abs/2602.08274", "authors": ["Jan Philip Wahle"], "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection", "comment": "PhD dissertation, University of G\u00f6ttingen Germany, 2025. 182 pages", "summary": "Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08440", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08440", "abs": "https://arxiv.org/abs/2602.08440", "authors": ["Tian Gao", "Celine Tan", "Catherine Glossop", "Timothy Gao", "Jiankai Sun", "Kyle Stachowicz", "Shirley Wu", "Oier Mees", "Dorsa Sadigh", "Sergey Levine", "Chelsea Finn"], "title": "SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios", "comment": null, "summary": "A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded experience necessary for safe vehicle control. We posit that an effective autonomous agent should leverage the world knowledge of VLMs to guide a steerable driving policy toward robust control in driving scenarios. To this end, we propose SteerVLA, which leverages the reasoning capabilities of VLMs to produce fine-grained language instructions that steer a vision-language-action (VLA) driving policy. Key to our method is this rich language interface between the high-level VLM and low-level VLA, which allows the high-level policy to more effectively ground its reasoning in the control outputs of the low-level policy. To provide fine-grained language supervision aligned with vehicle control, we leverage a VLM to augment existing driving data with detailed language annotations, which we find to be essential for effective reasoning and steerability. We evaluate SteerVLA on a challenging closed-loop benchmark, where it outperforms state-of-the-art methods by 4.77 points in overall driving score and by 8.04 points on a long-tail subset. The project website is available at: https://steervla.github.io/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08281", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08281", "abs": "https://arxiv.org/abs/2602.08281", "authors": ["Zhilin Wang", "Yafu Li", "Shunkai Zhang", "Zhi Wang", "Haoran Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR", "comment": "15 pages", "summary": "Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($\u03c1\\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08289", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08289", "abs": "https://arxiv.org/abs/2602.08289", "authors": ["Binglin Wu", "Xianneng Li"], "title": "Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network", "comment": null, "summary": "With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08450", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08450", "abs": "https://arxiv.org/abs/2602.08450", "authors": ["Stefan Ivi\u0107", "Luka Lan\u010da", "Karlo Jakac", "Ante Sikirica", "Stella Dumen\u010di\u0107", "Matej Mali\u0161a", "Zvonimir Mrle", "Bojan Crnkovi\u0107"], "title": "UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials", "comment": null, "summary": "This paper presents the integration of flow field reconstruction, dynamic probabilistic modeling, search control, and machine vision detection in a system for autonomous maritime search operations. Field experiments conducted in Valun Bay (Cres Island, Croatia) involved real-time drifter data acquisition, surrogate flow model fitting based on computational fluid dynamics and numerical optimization, advanced multi-UAV search control and vision sensing, as well as deep learning-based object detection. The results demonstrate that a tightly coupled approach enables reliable detection of floating targets under realistic uncertainties and complex environmental conditions, providing concrete insights for future autonomous maritime search and rescue applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08294", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08294", "abs": "https://arxiv.org/abs/2602.08294", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "When Does Context Help? Error Dynamics of Contextual Information in Large Language Models", "comment": null, "summary": "Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\\%$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08466", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08466", "abs": "https://arxiv.org/abs/2602.08466", "authors": ["Ning Hu", "Senhao Cao", "Maochen Li"], "title": "Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment", "comment": "7 pages, 1 figure", "summary": "Vision-guided robotic systems are increasingly deployed in precision alignment tasks that require reliable execution under near-field and off-axis configurations. While recent advances in pose estimation have significantly improved numerical accuracy, practical robotic systems still suffer from frequent execution failures even when pose estimates appear accurate. This gap suggests that pose accuracy alone is insufficient to guarantee execution-level reliability. In this paper, we reveal that such failures arise from a deterministic geometric error amplification mechanism, in which small pose estimation errors are magnified through system structure and motion execution, leading to unstable or failed alignment. Rather than modifying pose estimation algorithms, we propose a Reliability-aware Execution Gating mechanism that operates at the execution level. The proposed approach evaluates geometric consistency and configuration risk before execution, and selectively rejects or scales high-risk pose updates. We validate the proposed method on a real UR5 robotic platform performing single-step visual alignment tasks under varying camera-target distances and off-axis configurations. Experimental results demonstrate that the proposed execution gating significantly improves task success rates, reduces execution variance, and suppresses tail-risk behavior, while leaving average pose accuracy largely unchanged. Importantly, the proposed mechanism is estimator-agnostic and can be readily integrated with both classical geometry-based and learning-based pose estimation pipelines. These results highlight the importance of execution-level reliability modeling and provide a practical solution for improving robustness in near-field vision-guided robotic systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08305", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08305", "abs": "https://arxiv.org/abs/2602.08305", "authors": ["Binglin Wu", "Yingyi Zhang", "Xiannneg Li"], "title": "JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation", "comment": null, "summary": "Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \\textit{\\textbf{J}udicial \\textbf{U}nified \\textbf{S}ynthesis \\textbf{T}hrough \\textbf{I}ntermediate \\textbf{C}onclusion \\textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\\rightarrow$ Pre-Judge $\\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08518", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08518", "abs": "https://arxiv.org/abs/2602.08518", "authors": ["Kento Kawaharazuka", "Kei Okada", "Masayuki Inaba"], "title": "Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi", "comment": "Accepted to Advanced Intelligent Systems", "summary": "Various musculoskeletal humanoids have been developed so far, and numerous studies on control mechanisms have been conducted to leverage the advantages of their biomimetic bodies. However, there has not been sufficient and unified discussion on the diverse properties inherent in these musculoskeletal structures, nor on how to manage and utilize them. Therefore, this study categorizes and analyzes the characteristics of muscles, as well as their management and utilization methods, based on the various research conducted on the musculoskeletal humanoids we have developed, Kengoro and Musashi. We classify the features of the musculoskeletal structure into five properties: Redundancy, Independency, Anisotropy, Variable Moment Arm, and Nonlinear Elasticity. We then organize the diverse advantages and disadvantages of musculoskeletal humanoids that arise from the combination of these properties. In particular, we discuss body schema learning and reflex control, along with muscle grouping and body schema adaptation. Also, we describe the implementation of movements through an integrated system and discuss future challenges and prospects.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08321", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08321", "abs": "https://arxiv.org/abs/2602.08321", "authors": ["Zijie Chen", "Zhenghao Lin", "Xiao Liu", "Zhenzhong Lan", "Yeyun Gong", "Peng Cheng"], "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models", "comment": null, "summary": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08537", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08537", "abs": "https://arxiv.org/abs/2602.08537", "authors": ["Haoming Ye", "Yunxiao Xiao", "Cewu Lu", "Panpan Cai"], "title": "UniPlan: Vision-Language Task Planning for Mobile Manipulation with Unified PDDL Formulation", "comment": null, "summary": "Integration of VLM reasoning with symbolic planning has proven to be a promising approach to real-world robot task planning. Existing work like UniDomain effectively learns symbolic manipulation domains from real-world demonstrations, described in Planning Domain Definition Language (PDDL), and has successfully applied them to real-world tasks. These domains, however, are restricted to tabletop manipulation. We propose UniPlan, a vision-language task planning system for long-horizon mobile-manipulation in large-scale indoor environments, that unifies scene topology, visuals, and robot capabilities into a holistic PDDL representation. UniPlan programmatically extends learned tabletop domains from UniDomain to support navigation, door traversal, and bimanual coordination. It operates on a visual-topological map, comprising navigation landmarks anchored with scene images. Given a language instruction, UniPlan retrieves task-relevant nodes from the map and uses a VLM to ground the anchored image into task-relevant objects and their PDDL states; next, it reconnects these nodes to a compressed, densely-connected topological map, also represented in PDDL, with connectivity and costs derived from the original map; Finally, a mobile-manipulation plan is generated using off-the-shelf PDDL solvers. Evaluated on human-raised tasks in a large-scale map with real-world imagery, UniPlan significantly outperforms VLM and LLM+PDDL planning in success rate, plan quality, and computational efficiency.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08322", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08322", "abs": "https://arxiv.org/abs/2602.08322", "authors": ["Wei Zhu"], "title": "An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling", "comment": null, "summary": "In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08557", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08557", "abs": "https://arxiv.org/abs/2602.08557", "authors": ["Marc Toussaint", "Cornelius V. Braun", "Eckart Cobo-Briesewitz", "Sayantan Auddy", "Armand Jordana", "Justin Carpentier"], "title": "Constrained Sampling to Guide Universal Manipulation RL", "comment": null, "summary": "We consider how model-based solvers can be leveraged to guide training of a universal policy to control from any feasible start state to any feasible goal in a contact-rich manipulation setting. While Reinforcement Learning (RL) has demonstrated its strength in such settings, it may struggle to sufficiently explore and discover complex manipulation strategies, especially in sparse-reward settings. Our approach is based on the idea of a lower-dimensional manifold of feasible, likely-visited states during such manipulation and to guide RL with a sampler from this manifold. We propose Sample-Guided RL, which uses model-based constraint solvers to efficiently sample feasible configurations (satisfying differentiable collision, contact, and force constraints) and leverage them to guide RL for universal (goal-conditioned) manipulation policies. We study using this data directly to bias state visitation, as well as using black-box optimization of open-loop trajectories between random configurations to impose a state bias and optionally add a behavior cloning loss. In a minimalistic double sphere manipulation setting, Sample-Guided RL discovers complex manipulation strategies and achieves high success rates in reaching any statically stable state. In a more challenging panda arm setting, our approach achieves a significant success rate over a near-zero baseline, and demonstrates a breadth of complex whole-body-contact manipulation strategies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08332", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08332", "abs": "https://arxiv.org/abs/2602.08332", "authors": ["Ido Amos", "Avi Caciularu", "Mor Geva", "Amir Globerson", "Jonathan Herzig", "Lior Shani", "Idan Szpektor"], "title": "Latent Reasoning with Supervised Thinking States", "comment": null, "summary": "Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08571", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08571", "abs": "https://arxiv.org/abs/2602.08571", "authors": ["Simon Hoffmann", "Simon Sagmeister", "Tobias Betz", "Joscha Bongard", "Sascha B\u00fcttner", "Dominic Ebner", "Daniel Esser", "Georg Jank", "Sven Goblirsch", "Alexander Langmann", "Maximilian Leitenstern", "Levent \u00d6gretmen", "Phillip Pitschi", "Ann-Kathrin Schwehn", "Cornelius Schr\u00f6der", "Marcel Weinmann", "Frederik Werner", "Boris Lohmann", "Johannes Betz", "Markus Lienkamp"], "title": "Head-to-Head autonomous racing at the limits of handling in the A2RL challenge", "comment": "Submitted to Science Robotics for possible publication", "summary": "Autonomous racing presents a complex challenge involving multi-agent interactions between vehicles operating at the limit of performance and dynamics. As such, it provides a valuable research and testing environment for advancing autonomous driving technology and improving road safety. This article presents the algorithms and deployment strategies developed by the TUM Autonomous Motorsport team for the inaugural Abu Dhabi Autonomous Racing League (A2RL). We showcase how our software emulates human driving behavior, pushing the limits of vehicle handling and multi-vehicle interactions to win the A2RL. Finally, we highlight the key enablers of our success and share our most significant learnings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08336", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08336", "abs": "https://arxiv.org/abs/2602.08336", "authors": ["Cheng Yang", "Chufan Shi", "Bo Shui", "Yaokang Wu", "Muzi Tao", "Huijuan Wang", "Ivan Yee Lee", "Yong Liu", "Xuezhe Ma", "Taylor Berg-Kirkpatrick"], "title": "UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models", "comment": "Project page: https://ureason.github.io", "summary": "To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08594", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08594", "abs": "https://arxiv.org/abs/2602.08594", "authors": ["Zhenguo Sun", "Bo-Sheng Huang", "Yibo Peng", "Xukun Li", "Jingyu Ma", "Yu Sun", "Zhe Li", "Haojun Jiang", "Biao Gao", "Zhenshan Bing", "Xinlong Wang", "Alois Knoll"], "title": "MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation", "comment": null, "summary": "Generalist humanoid motion trackers have recently achieved strong simulation metrics by scaling data and training, yet often remain brittle on hardware during sustained teleoperation due to interface- and dynamics-induced errors. We present MOSAIC, an open-source, full-stack system for humanoid motion tracking and whole-body teleoperation across multiple interfaces. MOSAIC first learns a teleoperation-oriented general motion tracker via RL on a multi-source motion bank with adaptive resampling and rewards that emphasize world-frame motion consistency, which is critical for mobile teleoperation. To bridge the sim-to-real interface gap without sacrificing generality, MOSAIC then performs rapid residual adaptation: an interface-specific policy is trained using minimal interface-specific data, and then distilled into the general tracker through an additive residual module, outperforming naive fine-tuning or continual learning. We validate MOSAIC with systematic ablations, out-of-distribution benchmarking, and real-robot experiments demonstrating robust offline motion replay and online long-horizon teleoperation under realistic latency and noise.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08367", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08367", "abs": "https://arxiv.org/abs/2602.08367", "authors": ["Zexuan Wang", "Chenghao Yang", "Yingqi Que", "Zhenzhu Yang", "Huaqing Yuan", "Yiwen Wang", "Zhengxuan Jiang", "Shengjie Fang", "Zhenhe Wu", "Zhaohui Wang", "Zhixin Yao", "Jiashuo Liu", "Jincheng Ren", "Yuzhen Li", "Yang Yang", "Jiaheng Liu", "Jian Yang", "Zaiyuan Wang", "Ge Zhang", "Zhoufutu Wen", "Wenhao Huang"], "title": "WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints", "comment": null, "summary": "Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \\textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \\textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\\% feasibility in text-only settings, which plummets to 19.33\\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08599", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08599", "abs": "https://arxiv.org/abs/2602.08599", "authors": ["Kenghou Hoi", "Yuze Wu", "Annan Ding", "Junjie Wang", "Anke Zhao", "Chengqian Zhang", "Fei Gao"], "title": "A Precise Real-Time Force-Aware Grasping System for Robust Aerial Manipulation", "comment": null, "summary": "Aerial manipulation requires force-aware capabilities to enable safe and effective grasping and physical interaction. Previous works often rely on heavy, expensive force sensors unsuitable for typical quadrotor platforms, or perform grasping without force feedback, risking damage to fragile objects. To address these limitations, we propose a novel force-aware grasping framework incorporating six low-cost, sensitive skin-like tactile sensors. We introduce a magnetic-based tactile sensing module that provides high-precision three-dimensional force measurements. We eliminate geomagnetic interference through a reference Hall sensor and simplify the calibration process compared to previous work. The proposed framework enables precise force-aware grasping control, allowing safe manipulation of fragile objects and real-time weight measurement of grasped items. The system is validated through comprehensive real-world experiments, including balloon grasping, dynamic load variation tests, and ablation studies, demonstrating its effectiveness in various aerial manipulation scenarios. Our approach achieves fully onboard operation without external motion capture systems, significantly enhancing the practicality of force-sensitive aerial manipulation. The supplementary video is available at: https://www.youtube.com/watch?v=mbcZkrJEf1I.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08371", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08371", "abs": "https://arxiv.org/abs/2602.08371", "authors": ["Hung Quang Tran", "Nam Tien Pham", "Son T. Luu", "Kiet Van Nguyen"], "title": "ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts", "comment": "Accepted as main paper at EACL 2026", "summary": "Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08602", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08602", "abs": "https://arxiv.org/abs/2602.08602", "authors": ["Renming Huang", "Chendong Zeng", "Wenjing Tang", "Jingtian Cai", "Cewu Lu", "Panpan Cai"], "title": "Mimic Intent, Not Just Trajectories", "comment": "Under review", "summary": "While imitation learning (IL) has achieved impressive success in dexterous manipulation through generative modeling and pretraining, state-of-the-art approaches like Vision-Language-Action (VLA) models still struggle with adaptation to environmental changes and skill transfer. We argue this stems from mimicking raw trajectories without understanding the underlying intent. To address this, we propose explicitly disentangling behavior intent from execution details in end-2-end IL: \\textit{``Mimic Intent, Not just Trajectories'' (MINT)}. We achieve this via \\textit{multi-scale frequency-space tokenization}, which enforces a spectral decomposition of action chunk representation. We learn action tokens with a multi-scale coarse-to-fine structure, and force the coarsest token to capture low-frequency global structure and finer tokens to encode high-frequency details. This yields an abstract \\textit{Intent token} that facilitates planning and transfer, and multi-scale \\textit{Execution tokens} that enable precise adaptation to environmental dynamics. Building on this hierarchy, our policy generates trajectories through \\textit{next-scale autoregression}, performing progressive \\textit{intent-to-execution reasoning}, thus boosting learning efficiency and generalization. Crucially, this disentanglement enables \\textit{one-shot transfer} of skills, by simply injecting the Intent token from a demonstration into the autoregressive generation process. Experiments on several manipulation benchmarks and on a real robot demonstrate state-of-the-art success rates, superior inference efficiency, robust generalization against disturbances, and effective one-shot transfer.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08382", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08382", "abs": "https://arxiv.org/abs/2602.08382", "authors": ["Zhuoen Chen", "Dongfang Li", "Meishan Zhang", "Baotian Hu", "Min Zhang"], "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning", "comment": "26 pages, 7 figures. Code and models will be released", "summary": "Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08653", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08653", "abs": "https://arxiv.org/abs/2602.08653", "authors": ["Jiarui Zhang", "Chengyong Lei", "Chengjiang Dai", "Lijie Wang", "Zhichao Han", "Fei Gao"], "title": "High-Speed Vision-Based Flight in Clutter with Safety-Shielded Reinforcement Learning", "comment": null, "summary": "Quadrotor unmanned aerial vehicles (UAVs) are increasingly deployed in complex missions that demand reliable autonomous navigation and robust obstacle avoidance. However, traditional modular pipelines often incur cumulative latency, whereas purely reinforcement learning (RL) approaches typically provide limited formal safety guarantees. To bridge this gap, we propose an end-to-end RL framework augmented with model-based safety mechanisms. We incorporate physical priors in both training and deployment. During training, we design a physics-informed reward structure that provides global navigational guidance. During deployment, we integrate a real-time safety filter that projects the policy outputs onto a provably safe set to enforce strict collision-avoidance constraints. This hybrid architecture reconciles high-speed flight with robust safety assurances. Benchmark evaluations demonstrate that our method outperforms both traditional planners and recent end-to-end obstacle avoidance approaches based on differentiable physics. Extensive experiments demonstrate strong generalization, enabling reliable high-speed navigation in dense clutter and challenging outdoor forest environments at velocities up to 7.5m/s.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08404", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08404", "abs": "https://arxiv.org/abs/2602.08404", "authors": ["Linye Wei", "Zixiang Luo", "Pingzhi Tang", "Meng Li"], "title": "TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration", "comment": null, "summary": "Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08776", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08776", "abs": "https://arxiv.org/abs/2602.08776", "authors": ["Cuijie Xu", "Shurui Zheng", "Zihao Su", "Yuanfan Xu", "Tinghao Yi", "Xudong Zhang", "Jian Wang", "Yu Wang", "Jinchen Yu"], "title": "Mind the Gap: Learning Implicit Impedance in Visuomotor Policies via Intent-Execution Mismatch", "comment": "14 pages, 9 figures, 5 tables", "summary": "Teleoperation inherently relies on the human operator acting as a closed-loop controller to actively compensate for hardware imperfections, including latency, mechanical friction, and lack of explicit force feedback. Standard Behavior Cloning (BC), by mimicking the robot's executed trajectory, fundamentally ignores this compensatory mechanism. In this work, we propose a Dual-State Conditioning framework that shifts the learning objective to \"Intent Cloning\" (master command). We posit that the Intent-Execution Mismatch, the discrepancy between master command and slave response, is not noise, but a critical signal that physically encodes implicit interaction forces and algorithmically reveals the operator's strategy for overcoming system dynamics. By predicting the master intent, our policy learns to generate a \"virtual equilibrium point\", effectively realizing implicit impedance control. Furthermore, by explicitly conditioning on the history of this mismatch, the model performs implicit system identification, perceiving tracking errors as external forces to close the control loop. To bridge the temporal gap caused by inference latency, we further formulate the policy as a trajectory inpainter to ensure continuous control. We validate our approach on a sensorless, low-cost bi-manual setup. Empirical results across tasks requiring contact-rich manipulation and dynamic tracking reveal a decisive gap: while standard execution-cloning fails due to the inability to overcome contact stiffness and tracking lag, our mismatch-aware approach achieves robust success. This presents a minimalist behavior cloning framework for low-cost hardware, enabling force perception and dynamic compensation without relying on explicit force sensing. Videos are available on the \\href{https://xucj98.github.io/mind-the-gap-page/}{project page}.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08426", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08426", "abs": "https://arxiv.org/abs/2602.08426", "authors": ["Xinghao Wang", "Pengyu Wang", "Xiaoran Liu", "Fangxu Liu", "Jason Chu", "Kai Song", "Xipeng Qiu"], "title": "Prism: Spectral-Aware Block-Sparse Attention", "comment": null, "summary": "Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\\mathbf{5.1\\times}$ speedup.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08784", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08784", "abs": "https://arxiv.org/abs/2602.08784", "authors": ["Santiago Montiel-Mar\u00edn", "Miguel Antunes-Garc\u00eda", "Fabio S\u00e1nchez-Garc\u00eda", "Angel Llamazares", "Holger Caesar", "Luis M. Bergasa"], "title": "GaussianCaR: Gaussian Splatting for Efficient Camera-Radar Fusion", "comment": "8 pages, 6 figures. Accepted to IEEE ICRA 2026", "summary": "Robust and accurate perception of dynamic objects and map elements is crucial for autonomous vehicles performing safe navigation in complex traffic scenarios. While vision-only methods have become the de facto standard due to their technical advances, they can benefit from effective and cost-efficient fusion with radar measurements. In this work, we advance fusion methods by repurposing Gaussian Splatting as an efficient universal view transformer that bridges the view disparity gap, mapping both image pixels and radar points into a common Bird's-Eye View (BEV) representation. Our main contribution is GaussianCaR, an end-to-end network for BEV segmentation that, unlike prior BEV fusion methods, leverages Gaussian Splatting to map raw sensor information into latent features for efficient camera-radar fusion. Our architecture combines multi-scale fusion with a transformer decoder to efficiently extract BEV features. Experimental results demonstrate that our approach achieves performance on par with, or even surpassing, the state of the art on BEV segmentation tasks (57.3%, 82.9%, and 50.1% IoU for vehicles, roads, and lane dividers) on the nuScenes dataset, while maintaining a 3.2x faster inference runtime. Code and project page are available online.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08437", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08437", "abs": "https://arxiv.org/abs/2602.08437", "authors": ["Ziyan wang", "Longlong Ma"], "title": "Large Language Models and Impossible Language Acquisition: \"False Promise\" or an Overturn of our Current Perspective towards AI", "comment": null, "summary": "In Chomsky's provocative critique \"The False Promise of CHATGPT,\" Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his \"rationalist-romantics\" paradigm to functionalism and empiricism in LLMs research.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08498", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08498", "abs": "https://arxiv.org/abs/2602.08498", "authors": ["Haoran Zhang", "Yafu Li", "Zhi Wang", "Zhilin Wang", "Shunkai Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "Characterizing, Evaluating, and Optimizing Complex Reasoning", "comment": "Code and data are available at \\url{https://github.com/zzzhr97/TRM}", "summary": "Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08821", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08821", "abs": "https://arxiv.org/abs/2602.08821", "authors": ["Robin Dehler", "Oliver Schumann", "Jona Ruof", "Michael Buchholz"], "title": "Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems", "comment": null, "summary": "The integration of service-oriented architectures (SOA) with function offloading for distributed, intelligent transportation systems (ITS) offers the opportunity for connected autonomous vehicles (CAVs) to extend their locally available services. One major goal of offloading a subset of functions in the processing chain of a CAV to remote devices is to reduce the overall computational complexity on the CAV. The extension of using remote services, however, requires careful safety analysis, since the remotely created data are corrupted more easily, e.g., through an attacker on the remote device or by intercepting the wireless transmission. To tackle this problem, we first analyze the concept of SOA for distributed environments. From this, we derive a safety framework that validates the reliability of remote services and the data received locally. Since it is possible for the autonomous driving task to offload multiple different services, we propose a specific multi-staged framework for safety analysis dependent on the service composition of local and remote services. For efficiency reasons, we directly include the multi-staged framework for safety analysis in our service-oriented function offloading framework (SOFOF) that we have proposed in earlier work. The evaluation compares the performance of the extended framework considering computational complexity, with energy savings being a major motivation for function offloading, and its capability to detect data from corrupted remote services.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08543", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08543", "abs": "https://arxiv.org/abs/2602.08543", "authors": ["Yutao Zhu", "Xingshuo Zhang", "Maosen Zhang", "Jiajie Jin", "Liancheng Zhang", "Xiaoshuai Song", "Kangzhi Zhao", "Wencong Zeng", "Ruiming Tang", "Han Li", "Ji-Rong Wen", "Zhicheng Dou"], "title": "GISA: A Benchmark for General Information-Seeking Assistant", "comment": null, "summary": "The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08845", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08845", "abs": "https://arxiv.org/abs/2602.08845", "authors": ["Lazaro F. Torres", "Carlos I. Aldana", "Emmanuel Nu\u00f1o", "Emmanuel Cruz-Zavala"], "title": "Finite-Time Teleoperation of Euler-Lagrange Systems via Energy-Shaping", "comment": null, "summary": "This paper proposes a family of finite-time controllers for the bilateral teleoperation of fully actuated nonlinear Euler-Lagrange systems. Based on the energy-shaping framework and under the standard assumption of passive interactions with the human and the environment, the controllers ensure that the position error and velocities globally converge to zero in the absence of time delays. In this case, the closed-loop system admits a homogeneous approximation of negative degree, and thus the control objective is achieved in finite-time. The proposed controllers are simple, continuous-time proportional-plus-damping-injection schemes, validated through both simulation and experimental results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08548", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08548", "abs": "https://arxiv.org/abs/2602.08548", "authors": ["Xuanliang Zhang", "Dingzirui Wang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che"], "title": "How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location", "comment": null, "summary": "While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08963", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08963", "abs": "https://arxiv.org/abs/2602.08963", "authors": ["Katharina Friedl", "No\u00e9mie Jaquier", "Seungyeon Kim", "Jens Lundell", "Danica Kragic"], "title": "Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics", "comment": "20 pages, 15 figures", "summary": "Model-based controllers can offer strong guarantees on stability and convergence by relying on physically accurate dynamic models. However, these are rarely available for high-dimensional mechanical systems such as deformable objects or soft robots. While neural architectures can learn to approximate complex dynamics, they are either limited to low-dimensional systems or provide only limited formal control guarantees due to a lack of embedded physical structure. This paper introduces a latent control framework based on learned structure-preserving reduced-order dynamics for high-dimensional Lagrangian systems. We derive a reduced tracking law for fully actuated systems and adopt a Riemannian perspective on projection-based model-order reduction to study the resulting latent and projected closed-loop dynamics. By quantifying the sources of modeling error, we derive interpretable conditions for stability and convergence. We extend the proposed controller and analysis to underactuated systems by introducing learned actuation patterns. Experimental results on simulated and real-world systems validate our theoretical investigation and the accuracy of our controllers.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08600", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08600", "abs": "https://arxiv.org/abs/2602.08600", "authors": ["Archchana Sindhujan", "Girish A. Koushik", "Shenbin Qian", "Diptesh Kanojia", "Constantin Or\u0103san"], "title": "Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation", "comment": "Currently this article is under review for Natural Language Processing Journal", "summary": "Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08999", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08999", "abs": "https://arxiv.org/abs/2602.08999", "authors": ["Mouad Abrini", "Mohamed Chetouani"], "title": "CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion", "comment": null, "summary": "With the increasing integration of robots into daily life, human-robot interaction has become more complex and multifaceted. A critical component of this interaction is Interactive Visual Grounding (IVG), through which robots must interpret human intentions and resolve ambiguity. Existing IVG models generally lack a mechanism to determine when to ask clarification questions, as they implicitly rely on their learned representations. CLUE addresses this gap by converting the VLM's cross-modal attention into an explicit, spatially grounded signal for deciding when to ask. We extract text to image attention maps and pass them to a lightweight CNN to detect referential ambiguity, while a LoRA fine-tuned decoder conducts the dialog and emits grounding location tokens. We train on a real-world interactive dataset for IVG, and a mixed ambiguity set for the detector. With InViG-only supervision, our model surpasses a state-of-the-art method while using parameter-efficient fine-tuning. Similarly, the ambiguity detector outperforms prior baselines. Overall, CLUE turns the internal cross-modal attention of a VLM into an explicit, spatially grounded signal for deciding when to ask. The data and code are publicly available at: mouadabrini.github.io/clue", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08607", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08607", "abs": "https://arxiv.org/abs/2602.08607", "authors": ["Ziyang Cheng", "Yuhao Wang", "Heyang Liu", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling", "comment": null, "summary": "Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\\times$--10$\\times$ decoding speedup and reduces first-chunk latency by 34\\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09002", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09002", "abs": "https://arxiv.org/abs/2602.09002", "authors": ["Zilin Fang", "Anxing Xiao", "David Hsu", "Gim Hee Lee"], "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection", "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)", "summary": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08625", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08625", "abs": "https://arxiv.org/abs/2602.08625", "authors": ["Muhammad Naufil"], "title": "Do Multilingual LLMs have specialized language heads?", "comment": null, "summary": "Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09013", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.09013", "abs": "https://arxiv.org/abs/2602.09013", "authors": ["Hongyi Chen", "Tony Dong", "Tiancheng Wu", "Liquan Wang", "Yash Jangir", "Yaru Niu", "Yufei Ye", "Homanga Bharadhwaj", "Zackory Erickson", "Jeffrey Ichnowski"], "title": "Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction", "comment": null, "summary": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08658", "abs": "https://arxiv.org/abs/2602.08658", "authors": ["Mingzi Cao", "Xingwei Tan", "Mahmud Akhter", "Marco Valentino", "Maria Liakata", "Xi Wang", "Nikolaos Aletras"], "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models", "comment": null, "summary": "Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09017", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09017", "abs": "https://arxiv.org/abs/2602.09017", "authors": ["Zichen Jeff Cui", "Omar Rayyan", "Haritheja Etukuru", "Bowen Tan", "Zavier Andrianarivo", "Zicheng Teng", "Yihang Zhou", "Krish Mehta", "Nicholas Wojno", "Kevin Yuanbo Wu", "Manan H Anjaria", "Ziyuan Wu", "Manrong Mao", "Guangxun Zhang", "Binit Shah", "Yejin Kim", "Soumith Chintala", "Lerrel Pinto", "Nur Muhammad Mahi Shafiullah"], "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models", "comment": null, "summary": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08672", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08672", "abs": "https://arxiv.org/abs/2602.08672", "authors": ["Clemencia Siro", "Pourya Aliannejadi", "Mohammad Aliannejadi"], "title": "Learning to Judge: LLMs Designing and Applying Evaluation Rubrics", "comment": "Accepted at EACL 2026 Findings", "summary": "Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09018", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09018", "abs": "https://arxiv.org/abs/2602.09018", "authors": ["Amir Mallak", "Alaa Maalouf"], "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving", "comment": null, "summary": "Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\\rightarrow$ urban and day $\\rightarrow$ night ($\\sim 31\\%$ each); actor swaps $\\sim 10\\%$, moderate rain $\\sim 7\\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\\% \\rightarrow 70.1\\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08688", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08688", "abs": "https://arxiv.org/abs/2602.08688", "authors": ["Hossein Kermani", "Fatemeh Oudlajani", "Pardis Yarahmadi", "Hamideh Mahdi Soltani", "Mohammad Makki", "Zahra HosseiniKhoo"], "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement", "comment": null, "summary": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09021", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.09021", "abs": "https://arxiv.org/abs/2602.09021", "authors": ["Checheng Yu", "Chonghao Sima", "Gangcheng Jiang", "Hai Zhang", "Haoguang Mai", "Hongyang Li", "Huijie Wang", "Jin Chen", "Kaiyang Wu", "Li Chen", "Lirui Zhao", "Modi Shi", "Ping Luo", "Qingwen Bu", "Shijia Peng", "Tianyu Li", "Yibo Yuan"], "title": "$\u03c7_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies", "comment": null, "summary": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $\u03c7_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $\u03c7_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $\u03c7_{0}$ surpasses the state-of-the-art $\u03c0_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08698", "abs": "https://arxiv.org/abs/2602.08698", "authors": ["Basudha Raje", "Sadanand Venkatraman", "Nandana TP", "Soumyadeepa Das", "Polkam Poojitha", "M. Vijaykumar", "Tanima Bagchi", "Hema A. Murthy"], "title": "Challenges in Translating Technical Lectures: Insights from the NPTEL", "comment": null, "summary": "This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09023", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.09023", "abs": "https://arxiv.org/abs/2602.09023", "authors": ["Qinwen Xu", "Jiaming Liu", "Rui Zhou", "Shaojun Shi", "Nuowei Han", "Zhuoyang Liu", "Chenyang Gu", "Shuo Gu", "Yang Yue", "Gao Huang", "Wenzhao Zheng", "Sirui Han", "Peng Jia", "Shanghang Zhang"], "title": "TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation", "comment": null, "summary": "Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08700", "categories": ["cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08700", "abs": "https://arxiv.org/abs/2602.08700", "authors": ["Clemencia Siro", "Zahra Abbasiantaeb", "Yifei Yuan", "Mohammad Aliannejadi", "Maarten de Rijke"], "title": "Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search", "comment": "Accepted at CHIIR 2025", "summary": "Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.01047", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.01047", "abs": "https://arxiv.org/abs/2512.01047", "authors": ["Tanmay Ambadkar", "\u0110or\u0111e \u017dikeli\u0107", "Abhinav Verma"], "title": "Automating the Refinement of Reinforcement Learning Specifications", "comment": null, "summary": "Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \\textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \\textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \\textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \\textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \\textsc{AutoSpec} are utilized.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08709", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08709", "abs": "https://arxiv.org/abs/2602.08709", "authors": ["Leandro Anghinoni", "Jorge Sanchez"], "title": "FactSim: Fact-Checking for Opinion Summarization", "comment": "10 pages, 4 figures", "summary": "We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08716", "abs": "https://arxiv.org/abs/2602.08716", "authors": ["Shangrui Nie", "Kian Omoomi", "Lucie Flek", "Zhixue Zhao", "Charles Welch"], "title": "PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments", "comment": "15 pages, 1 figure", "summary": "Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07101", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07101", "abs": "https://arxiv.org/abs/2602.07101", "authors": ["Zinan Lv", "Yeqian Qian", "Chen Sang", "Hao Liu", "Danping Zou", "Ming Yang"], "title": "Zero-Shot UAV Navigation in Forests via Relightable 3D Gaussian Splatting", "comment": "12 pages, 8 figures", "summary": "UAV navigation in unstructured outdoor environments using passive monocular vision is hindered by the substantial visual domain gap between simulation and reality. While 3D Gaussian Splatting enables photorealistic scene reconstruction from real-world data, existing methods inherently couple static lighting with geometry, severely limiting policy generalization to dynamic real-world illumination. In this paper, we propose a novel end-to-end reinforcement learning framework designed for effective zero-shot transfer to unstructured outdoors. Within a high-fidelity simulation grounded in real-world data, our policy is trained to map raw monocular RGB observations directly to continuous control commands. To overcome photometric limitations, we introduce Relightable 3D Gaussian Splatting, which decomposes scene components to enable explicit, physically grounded editing of environmental lighting within the neural representation. By augmenting training with diverse synthesized lighting conditions ranging from strong directional sunlight to diffuse overcast skies, we compel the policy to learn robust, illumination-invariant visual features. Extensive real-world experiments demonstrate that a lightweight quadrotor achieves robust, collision-free navigation in complex forest environments at speeds up to 10 m/s, exhibiting significant resilience to drastic lighting variations without fine-tuning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08740", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08740", "abs": "https://arxiv.org/abs/2602.08740", "authors": ["Gaifan Zhang", "Danushka Bollegala"], "title": "Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy", "comment": null, "summary": "We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07227", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07227", "abs": "https://arxiv.org/abs/2602.07227", "authors": ["Nethmi Jayasinghe", "Diana Gontero", "Spencer T. Brown", "Vinod K. Sangwan", "Mark C. Hersam", "Amit Ranjan Trivedi"], "title": "Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation", "comment": null, "summary": "Robotic policies deployed in real-world environments often encounter post-training faults, where retraining, exploration, or system identification are impractical. We introduce an inference-time, cerebellar-inspired residual control framework that augments a frozen reinforcement learning policy with online corrective actions, enabling fault recovery without modifying base policy parameters. The framework instantiates core cerebellar principles, including high-dimensional pattern separation via fixed feature expansion, parallel microzone-style residual pathways, and local error-driven plasticity with excitatory and inhibitory eligibility traces operating at distinct time scales. These mechanisms enable fast, localized correction under post-training disturbances while avoiding destabilizing global policy updates. A conservative, performance-driven meta-adaptation regulates residual authority and plasticity, preserving nominal behavior and suppressing unnecessary intervention. Experiments on MuJoCo benchmarks under actuator, dynamic, and environmental perturbations show improvements of up to $+66\\%$ on \\texttt{HalfCheetah-v5} and $+53\\%$ on \\texttt{Humanoid-v5} under moderate faults, with graceful degradation under severe shifts and complementary robustness from consolidating persistent residual corrections into policy parameters.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08793", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.08793", "abs": "https://arxiv.org/abs/2602.08793", "authors": ["Yushi Sun", "Xujia Li", "Nan Tang", "Quanqing Xu", "Chuanhui Yang", "Lei Chen"], "title": "LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation", "comment": null, "summary": "Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07339", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07339", "abs": "https://arxiv.org/abs/2602.07339", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving", "comment": null, "summary": "Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08826", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08826", "abs": "https://arxiv.org/abs/2602.08826", "authors": ["Chenghui Zou", "Ning Wang", "Tiesunlong Shen", "Luwei Xiao", "Chuan Ma", "Xiangpeng Li", "Rui Mao", "Erik Cambria"], "title": "Affective Flow Language Model for Emotional Support Conversation", "comment": "19 pages, 7 figures", "summary": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07341", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07341", "abs": "https://arxiv.org/abs/2602.07341", "authors": ["Yicheng Yang", "Ruijiao Li", "Lifeng Wang", "Shuai Zheng", "Shunzheng Ma", "Keyu Zhang", "Tuoyu Sun", "Chenyun Dai", "Jie Ding", "Zhuo Zou"], "title": "Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions", "comment": null, "summary": "This paper focuses on the scalable robot learning for manipulation in the dexterous robot arm-hand systems, where the remote human-robot interactions via augmented reality (AR) are established to collect the expert demonstration data for improving efficiency. In such a system, we present a unified framework to address the general manipulation task problem. Specifically, the proposed method consists of two phases: i) In the first phase for pretraining, the policy is created in a behavior cloning (BC) manner, through leveraging the learning data from our AR-based remote human-robot interaction system; ii) In the second phase, a contrastive learning empowered reinforcement learning (RL) method is developed to obtain more efficient and robust policy than the BC, and thus a projection head is designed to accelerate the learning progress. An event-driven augmented reward is adopted for enhancing the safety. To validate the proposed method, both the physics simulations via PyBullet and real-world experiments are carried out. The results demonstrate that compared to the classic proximal policy optimization and soft actor-critic policies, our method not only significantly speeds up the inference, but also achieves much better performance in terms of the success rate for fulfilling the manipulation tasks. By conducting the ablation study, it is confirmed that the proposed RL with contrastive learning overcomes policy collapse. Supplementary demonstrations are available at https://cyberyyc.github.io/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08829", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08829", "abs": "https://arxiv.org/abs/2602.08829", "authors": ["Hao Peng", "Yunjia Qi", "Xiaozhi Wang", "Zijun Yao", "Lei Hou", "Juanzi Li"], "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions", "comment": null, "summary": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07343", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07343", "abs": "https://arxiv.org/abs/2602.07343", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation", "comment": null, "summary": "Robust semantic segmentation of road scenes under adverse illumination, lighting, and shadow conditions remain a core challenge for autonomous driving applications. RGB-Thermal fusion is a standard approach, yet existing methods apply static fusion strategies uniformly across all conditions, allowing modality-specific noise to propagate throughout the network. Hence, we propose CLARITY that dynamically adapts its fusion strategy to the detected scene condition. Guided by vision-language model (VLM) priors, the network learns to modulate each modality's contribution based on the illumination state while leveraging object embeddings for segmentation, rather than applying a fixed fusion policy. We further introduce two mechanisms, i.e., one which preserves valid dark-object semantics that prior noise-suppression methods incorrectly discard, and a hierarchical decoder that enforces structural consistency across scales to sharpen boundaries on thin objects. Experiments on the MFNet dataset demonstrate that CLARITY establishes a new state-of-the-art (SOTA), achieving 62.3% mIoU and 77.5% mAcc.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08864", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08864", "abs": "https://arxiv.org/abs/2602.08864", "authors": ["Ibraheem Muhammad Moosa", "Suhas Lohit", "Ye Wang", "Moitreya Chatterjee", "Wenpeng Yin"], "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers", "comment": null, "summary": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07668", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07668", "abs": "https://arxiv.org/abs/2602.07668", "authors": ["Ross Greer", "Laura Fleig", "Maitrayee Keskar", "Erika Maquiling", "Giovanni Tapia Lopez", "Angel Martinez-Sanchez", "Parthib Roy", "Jake Rattigan", "Mira Sur", "Alejandra Vidrio", "Thomas Marcotte", "Mohan Trivedi"], "title": "Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making", "comment": null, "summary": "The looking-in-looking-out (LILO) framework has enabled intelligent vehicle applications that understand both the outside scene and the driver state to improve safety outcomes, with examples in smart airbag deployment, takeover time prediction in autonomous control transitions, and driver attention monitoring. In this research, we propose an augmentation to this framework, making a case for the audio modality as an additional source of information to understand the driver, and in the evolving autonomy landscape, also the passengers and those outside the vehicle. We expand LILO by incorporating audio signals, forming the looking-and-listening inside-and-outside (L-LIO) framework to enhance driver state assessment and environment understanding through multimodal sensor fusion. We evaluate three example cases where audio enhances vehicle safety: supervised learning on driver speech audio to classify potential impairment states (e.g., intoxication), collection and analysis of passenger natural language instructions (e.g., \"turn after that red building\") to motivate how spoken language can interface with planning systems through audio-aligned instruction data, and limitations of vision-only systems where audio may disambiguate the guidance and gestures of external agents. Datasets include custom-collected in-vehicle and external audio samples in real-world environments. Pilot findings show that audio yields safety-relevant insights, particularly in nuanced or context-rich scenarios where sound is critical to safe decision-making or visual signals alone are insufficient. Challenges include ambient noise interference, privacy considerations, and robustness across human subjects, motivating further work on reliability in dynamic real-world contexts. L-LIO augments driver and scene understanding through multimodal fusion of audio and visual sensing, offering new paths for safety intervention.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08872", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08872", "abs": "https://arxiv.org/abs/2602.08872", "authors": ["G. Cafferata", "T. Demarco", "K. Kalimeri", "Y. Mejova", "M. G. Beir\u00f3"], "title": "Large Language Models for Geolocation Extraction in Humanitarian Crisis Response", "comment": null, "summary": "Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07680", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07680", "abs": "https://arxiv.org/abs/2602.07680", "authors": ["Ross Greer", "Maitrayee Keskar", "Angel Martinez-Sanchez", "Parthib Roy", "Shashank Shriram", "Mohan Trivedi"], "title": "Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning", "comment": null, "summary": "Vision-language models (VLMs) have recently emerged as powerful representation learning systems that align visual observations with natural language concepts, offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates how vision-language representations support driving scene safety assessment and decision-making when integrated into perception, prediction, and planning pipelines. We study three complementary system-level use cases. First, we introduce a lightweight, category-agnostic hazard screening approach leveraging CLIP-based image-text similarity to produce a low-latency semantic hazard signal. This enables robust detection of diverse and out-of-distribution road hazards without explicit object detection or visual question answering. Second, we examine the integration of scene-level vision-language embeddings into a transformer-based trajectory planning framework using the Waymo Open Dataset. Our results show that naively conditioning planners on global embeddings does not improve trajectory accuracy, highlighting the importance of representation-task alignment and motivating the development of task-informed extraction methods for safety-critical planning. Third, we investigate natural language as an explicit behavioral constraint on motion planning using the doScenes dataset. In this setting, passenger-style instructions grounded in visual scene elements suppress rare but severe planning failures and improve safety-aligned behavior in ambiguous scenarios. Taken together, these findings demonstrate that vision-language representations hold significant promise for autonomous driving safety when used to express semantic risk, intent, and behavioral constraints. Realizing this potential is fundamentally an engineering problem requiring careful system design and structured grounding rather than direct feature injection.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08874", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08874", "abs": "https://arxiv.org/abs/2602.08874", "authors": ["Yu Fu", "Haz Sameen Shahgir", "Huanli Gong", "Zhipeng Wei", "N. Benjamin Erichson", "Yue Dong"], "title": "Is Reasoning Capability Enough for Safety in Long-Context Language Models?", "comment": "25 pages, 7 figures", "summary": "Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07938", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07938", "abs": "https://arxiv.org/abs/2602.07938", "authors": ["Rabbia Asghar", "Lukas Rummelhard", "Wenqian Liu", "Anne Spalanzani", "Christian Laugier"], "title": "Integrating Specialized and Generic Agent Motion Prediction with Dynamic Occupancy Grid Maps", "comment": "Updated version with major revisions; currently under the second round of review at IEEE Transactions on Intelligent Vehicles", "summary": "Accurate prediction of driving scene is a challenging task due to uncertainty in sensor data, the complex behaviors of agents, and the possibility of multiple feasible futures. Existing prediction methods using occupancy grid maps primarily focus on agent-agnostic scene predictions, while agent-specific predictions provide specialized behavior insights with the help of semantic information. However, both paradigms face distinct limitations: agent-agnostic models struggle to capture the behavioral complexities of dynamic actors, whereas agent-specific approaches fail to generalize to poorly perceived or unrecognized agents; combining both enables robust and safer motion forecasting. To address this, we propose a unified framework by leveraging Dynamic Occupancy Grid Maps within a streamlined temporal decoding pipeline to simultaneously predict future occupancy state grids, vehicle grids, and scene flow grids. Relying on a lightweight spatiotemporal backbone, our approach is centered on a tailored, interdependent loss function that captures inter-grid dependencies and enables diverse future predictions. By using occupancy state information to enforce flow-guided transitions, the loss function acts as a regularizer that directs occupancy evolution while accounting for obstacles and occlusions. Consequently, the model not only predicts the specific behaviors of vehicle agents, but also identifies other dynamic entities and anticipates their evolution within the complex scene. Evaluations on real-world nuScenes and Woven Planet datasets demonstrate superior prediction performances for dynamic vehicles and generic dynamic scene elements compared to baseline methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08945", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08945", "abs": "https://arxiv.org/abs/2602.08945", "authors": ["Sahajpreet Singh", "Kokil Jaidka", "Min-Yen Kan"], "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search", "comment": "18 pages, 11 figures, 7 tables", "summary": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08006", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08006", "abs": "https://arxiv.org/abs/2602.08006", "authors": ["Riya Mohan", "Juana Valeria Hurtado", "Rohit Mohan", "Abhinav Valada"], "title": "ForecastOcc: Vision-based Semantic Occupancy Forecasting", "comment": null, "summary": "Autonomous driving requires forecasting both geometry and semantics over time to effectively reason about future environment states. Existing vision-based occupancy forecasting methods focus on motion-related categories such as static and dynamic objects, while semantic information remains largely absent. Recent semantic occupancy forecasting approaches address this gap but rely on past occupancy predictions obtained from separate networks. This makes current methods sensitive to error accumulation and prevents learning spatio-temporal features directly from images. In this work, we present ForecastOcc, the first framework for vision-based semantic occupancy forecasting that jointly predicts future occupancy states and semantic categories. Our framework yields semantic occupancy forecasts for multiple horizons directly from past camera images, without relying on externally estimated maps. We evaluate ForecastOcc in two complementary settings: multi-view forecasting on the Occ3D-nuScenes dataset and monocular forecasting on SemanticKITTI, where we establish the first benchmark for this task. We introduce the first baselines by adapting two 2D forecasting modules within our framework. Importantly, we propose a novel architecture that incorporates a temporal cross-attention forecasting module, a 2D-to-3D view transformer, a 3D encoder for occupancy prediction, and a semantic occupancy head for voxel-level forecasts across multiple horizons. Extensive experiments on both datasets show that ForecastOcc consistently outperforms baselines, yielding semantically rich, future-aware predictions that capture scene dynamics and semantics critical for autonomous driving.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08951", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08951", "abs": "https://arxiv.org/abs/2602.08951", "authors": ["Rasul Dent", "Pedro Ortiz Suarez", "Thibault Cl\u00e9rice", "Beno\u00eet Sagot"], "title": "How Should We Model the Probability of a Language?", "comment": "Accepted for Vardial 2026", "summary": "Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08984", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08984", "abs": "https://arxiv.org/abs/2602.08984", "authors": ["Yuliang Liu", "Yunchong Song", "Yixuan Wang", "Kewen Ge", "Alex Lamb", "Qipeng Guo", "Kai Chen", "Bowen Zhou", "Zhouhan Lin"], "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models", "comment": null, "summary": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08995", "abs": "https://arxiv.org/abs/2602.08995", "authors": ["Yuting Ning", "Jaylen Jones", "Zhehao Zhang", "Chentao Ye", "Weitong Ruan", "Junyi Li", "Rahul Gupta", "Huan Sun"], "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents", "comment": "Project Homepage: https://osu-nlp-group.github.io/Misaligned-Action-Detection/", "summary": "Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08962", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08962", "abs": "https://arxiv.org/abs/2602.08962", "authors": ["Guangxun Zhu", "Xuan Liu", "Nicolas Pugeault", "Chongfeng Wei", "Edmond S. L. Ho"], "title": "Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting", "comment": "Accepted for IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08971", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.08971", "abs": "https://arxiv.org/abs/2602.08971", "authors": ["Yu Shang", "Zhuohang Li", "Yiding Ma", "Weikang Su", "Xin Jin", "Ziyou Wang", "Xin Zhang", "Yinzhou Tang", "Chen Gao", "Wei Wu", "Xihui Liu", "Dhruv Shah", "Zhaoxiang Zhang", "Zhibo Chen", "Jun Zhu", "Yonghong Tian", "Tat-Seng Chua", "Wenwu Zhu", "Yong Li"], "title": "WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models", "comment": null, "summary": "While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.06993", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06993", "abs": "https://arxiv.org/abs/2602.06993", "authors": ["Shashank"], "title": "Attractor Patch Networks: Reducing Catastrophic Forgetting with Routed Low-Rank Patch Experts", "comment": "9 pages. Code (APN implementation in nanoGPT transformer): https://github.com/shankch/nanoGPT-apn (baseline: https://github.com/karpathy/nanoGPT) Data prep: https://github.com/karpathy/nanoGPT/tree/master/data/shakespeare_char and https://github.com/karpathy/nanoGPT/tree/master/data/shakespeare", "summary": "Transformers achieve strong language modeling accuracy, yet their position-wise feed-forward networks (FFNs) are dense, globally shared, and typically updated end to end. These properties create two practical tensions. First, dense FFNs spend the same compute on every token regardless of context, and they allocate capacity uniformly even when language exhibits highly clustered context structure. Second, continual learning, in the sense of updating the model while serving a data stream, often produces interference because a small update touches broadly shared weights.\n  We propose Attractor Patch Networks (APN), a plug-compatible replacement for the Transformer FFN. APN is a bank of patch experts. A similarity router selects a small top-k set of patches for each token by matching the token representation to learned prototypes. Each selected patch emits a low-rank residual update conditioned on a compact code. The architecture yields conditional, context-specialized nonlinear transformations while preserving the standard Transformer interface.\n  This paper focuses on APN as an architectural primitive. We formalize APN, analyze its expressivity as a piecewise low-rank residual function class, and derive simple interference and stability arguments that make APN naturally compatible with continual learning. In experiments on character-level language modeling, APN achieves competitive perplexity (4.57 vs 4.32 PPL) while enabling dramatically better continual adaptation: when adapting to a shifted domain, APN achieves 2.6 times better retention (11.1 vs 29.4 PPL on the original domain) and 2.8 times better adaptation (6.4 vs 17.8 PPL on the new domain) compared to global fine-tuning of a dense FFN baseline.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07038", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07038", "abs": "https://arxiv.org/abs/2602.07038", "authors": ["Yifan Ji", "Zhipeng Xu", "Zhenghao Liu", "Zulong Chen", "Qian Zhang", "Zhibo Yang", "Junyang Lin", "Yu Gu", "Ge Yu", "Maosong Sun"], "title": "UNIKIE-BENCH: Benchmarking Large Multimodal Models for Key Information Extraction in Visual Documents", "comment": null, "summary": "Key Information Extraction (KIE) from real-world documents remains challenging due to substantial variations in layout structures, visual quality, and task-specific information requirements. Recent Large Multimodal Models (LMMs) have shown promising potential for performing end-to-end KIE directly from document images. To enable a comprehensive and systematic evaluation across realistic and diverse application scenarios, we introduce UNIKIE-BENCH, a unified benchmark designed to rigorously evaluate the KIE capabilities of LMMs. UNIKIE-BENCH consists of two complementary tracks: a constrained-category KIE track with scenario-predefined schemas that reflect practical application needs, and an open-category KIE track that extracts any key information that is explicitly present in the document. Experiments on 15 state-of-the-art LMMs reveal substantial performance degradation under diverse schema definitions, long-tail key fields, and complex layouts, along with pronounced performance disparities across different document types and scenarios. These findings underscore persistent challenges in grounding accuracy and layout-aware reasoning for LMM-based KIE. All codes and datasets are available at https://github.com/NEUIR/UNIKIE-BENCH.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07055", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07055", "abs": "https://arxiv.org/abs/2602.07055", "authors": ["Pingyue Zhang", "Zihan Huang", "Yue Wang", "Jieyu Zhang", "Letian Xue", "Zihan Wang", "Qineng Wang", "Keshigeyan Chandrasegaran", "Ruohan Zhang", "Yejin Choi", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?", "comment": "published at iclr 2026", "summary": "Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07106", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07106", "abs": "https://arxiv.org/abs/2602.07106", "authors": ["Haoyu Zhang", "Zhipeng Li", "Yiwen Guo", "Tianshu Yu"], "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models", "comment": null, "summary": "Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07145", "categories": ["cs.LG", "cs.CL", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07145", "abs": "https://arxiv.org/abs/2602.07145", "authors": ["Zhiqi Bu", "Shiyun Xu", "Jialin Mao"], "title": "Convex Dominance in Deep Learning I: A Scaling Law of Loss and Learning Rate", "comment": "Part of a planned series to understand and leverage the convexity in deep learning. Accepted to ICLR 2026", "summary": "Deep learning has non-convex loss landscape and its optimization dynamics is hard to analyze or control. Nevertheless, the dynamics can be empirically convex-like across various tasks, models, optimizers, hyperparameters, etc. In this work, we examine the applicability of convexity and Lipschitz continuity in deep learning, in order to precisely control the loss dynamics via the learning rate schedules. We illustrate that deep learning quickly becomes weakly convex after a short period of training, and the loss is predicable by an upper bound on the last iterate, which further informs the scaling of optimal learning rate. Through the lens of convexity, we build scaling laws of learning rates and losses that extrapolate as much as 80X across training horizons and 70X across model sizes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07253", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07253", "abs": "https://arxiv.org/abs/2602.07253", "authors": ["Litian Liu", "Reza Pourreza", "Yubing Jian", "Yao Qin", "Roland Memisevic"], "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View", "comment": null, "summary": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07267", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07267", "abs": "https://arxiv.org/abs/2602.07267", "authors": ["Fengyuan Liu", "Jay Gala", "Nilaksh", "Dzmitry Bahdanau", "Siva Reddy", "Hugo Larochelle"], "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance", "comment": null, "summary": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07276", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07276", "abs": "https://arxiv.org/abs/2602.07276", "authors": ["Pengrui Han", "Xueqiang Xu", "Keyang Xuan", "Peiyang Song", "Siru Ouyang", "Runchu Tian", "Yuqing Jiang", "Cheng Qian", "Pengcheng Jiang", "Jiashuo Sun", "Junxia Cui", "Ming Zhong", "Ge Liu", "Jiawei Han", "Jiaxuan You"], "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs", "comment": null, "summary": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07414", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07414", "abs": "https://arxiv.org/abs/2602.07414", "authors": ["Deuksin Kwon", "Kaleen Shrestha", "Bin Han", "Spencer Lin", "James Hale", "Jonathan Gratch", "Maja Matari\u0107", "Gale M. Lucas"], "title": "Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution", "comment": "AAAI 2026 (Special Track: AISI)", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises the question: Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior? To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework provides a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogues with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the use of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and validation in AI simulations before real-world use.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07425", "categories": ["cs.LG", "cs.CL", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07425", "abs": "https://arxiv.org/abs/2602.07425", "authors": ["Dingzhi Yu", "Hongyi Tao", "Yuanyu Wan", "Luo Luo", "Lijun Zhang"], "title": "Sign-Based Optimizers Are Effective Under Heavy-Tailed Noise", "comment": "Code available at https://github.com/Dingzhen230/Heavy-tailed-Noise-in-LLMs", "summary": "While adaptive gradient methods are the workhorse of modern machine learning, sign-based optimization algorithms such as Lion and Muon have recently demonstrated superior empirical performance over AdamW in training large language models (LLM). However, a theoretical understanding of why sign-based updates outperform variance-adapted methods remains elusive. In this paper, we aim to bridge the gap between theory and practice through the lens of heavy-tailed gradient noise, a phenomenon frequently observed in language modeling tasks. Theoretically, we introduce a novel generalized heavy-tailed noise condition that captures the behavior of LLMs more accurately than standard finite variance assumptions. Under this noise model, we establish sharp convergence rates of SignSGD and Lion for generalized smooth function classes, matching or surpassing previous best-known bounds. Furthermore, we extend our analysis to Muon and Muonlight, providing what is, to our knowledge, the first rigorous analysis of matrix optimization under heavy-tailed stochasticity. These results offer a strong theoretical justification for the empirical superiority of sign-based optimizers, showcasing that they are naturally suited to handle the noisy gradients associated with heavy tails. Empirically, LLM pretraining experiments validate our theoretical insights and confirm that our proposed noise models are well-aligned with practice.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07465", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07465", "abs": "https://arxiv.org/abs/2602.07465", "authors": ["Seungwoo Son", "Ingyu Seong", "Junhan Kim", "Hyemi Jang", "Yongkweon Jeon"], "title": "On the Importance of a Multi-Scale Calibration for Quantization", "comment": "ICASSP 2026", "summary": "Post-training quantization (PTQ) is a cornerstone for efficiently deploying large language models (LLMs), where a small calibration set critically affects quantization performance. However, conventional practices rely on random sequences of fixed length, overlooking the variable-length nature of LLM inputs. Input length directly influences the activation distribution and, consequently, the weight importance captured by the Hessian, which in turn affects quantization outcomes. As a result, Hessian estimates derived from fixed-length calibration may fail to represent the true importance of weights across diverse input scenarios. We propose MaCa (Matryoshka Calibration), a simple yet effective method for length-aware Hessian construction. MaCa (i) incorporates multi-scale sequence length information into Hessian estimation and (ii) regularizes each sequence as an independent sample, yielding a more stable and fruitful Hessian for accurate quantization. Experiments on state-of-the-art LLMs (e.g., Qwen3, Gemma3, LLaMA3) demonstrate that MaCa consistently improves accuracy under low bit quantization, offering a lightweight enhancement compatible with existing PTQ frameworks. To the best of our knowledge, this is the first work to systematically highlight the role of multi-scale calibration in LLM quantization.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07549", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07549", "abs": "https://arxiv.org/abs/2602.07549", "authors": ["Dayoon Ko", "Jihyuk Kim", "Sohyeon Kim", "Haeju Park", "Dahyun Lee", "Gunhee Kim", "Moontae Lee", "Kyungjae Lee"], "title": "When Is Enough Not Enough? Illusory Completion in Search Agents", "comment": null, "summary": "Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory completion frequently occurs, wherein agents believe tasks are complete despite unresolved or violated constraints, leading to underverified answers. To diagnose this behavior, we introduce the Epistemic Ledger, an evaluation framework that tracks evidential support and agents' beliefs for each constraint throughout multi-turn reasoning. Our analysis reveals four recurring failure patterns: bare assertions, overlooked refutations, stagnation, and premature exit. Motivated by these findings, we examine whether explicit constraint-state tracking during execution mitigates these failures via LiveLedger, an inference-time tracker. This simple intervention consistently improves performance, substantially reducing underverified answers (by up to 26.5%) and improving overall accuracy (by up to 11.6%) on multi-constraint problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07574", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07574", "abs": "https://arxiv.org/abs/2602.07574", "authors": ["Wenjie Liu", "Hao Wu", "Xin Qiu", "Yingqi Fan", "Yihan Zhang", "Anhao Zhao", "Yunpu Ma", "Xiaoyu Shen"], "title": "ViCA: Efficient Multimodal LLMs with Vision-Only Cross-Attention", "comment": null, "summary": "Modern multimodal large language models (MLLMs) adopt a unified self-attention design that processes visual and textual tokens at every Transformer layer, incurring substantial computational overhead. In this work, we revisit the necessity of such dense visual processing and show that projected visual embeddings are already well-aligned with the language space, while effective vision-language interaction occurs in only a small subset of layers. Based on these insights, we propose ViCA (Vision-only Cross-Attention), a minimal MLLM architecture in which visual tokens bypass all self-attention and feed-forward layers, interacting with text solely through sparse cross-attention at selected layers. Extensive evaluations across three MLLM backbones, nine multimodal benchmarks, and 26 pruning-based baselines show that ViCA preserves 98% of baseline accuracy while reducing visual-side computation to 4%, consistently achieving superior performance-efficiency trade-offs. Moreover, ViCA provides a regular, hardware-friendly inference pipeline that yields over 3.5x speedup in single-batch inference and over 10x speedup in multi-batch inference, reducing visual grounding to near-zero overhead compared with text-only LLMs. It is also orthogonal to token pruning methods and can be seamlessly combined for further efficiency gains. Our code is available at https://github.com/EIT-NLP/ViCA.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07695", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.07695", "abs": "https://arxiv.org/abs/2602.07695", "authors": ["Congcong Hu", "Yuang Shi", "Fan Huang", "Yang Xiang", "Zhou Ye", "Ming Jin", "Shiyu Wang"], "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge", "comment": null, "summary": "Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07721", "categories": ["cs.LG", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.07721", "abs": "https://arxiv.org/abs/2602.07721", "authors": ["Yanlin Qi", "Xinhang Chen", "Huiqiang Jiang", "Qitong Wang", "Botao Peng", "Themis Palpanas"], "title": "ParisKV: Fast and Drift-Robust KV-Cache Retrieval for Long-Context LLMs", "comment": "25 pages, 16 figures. Under review", "summary": "KV-cache retrieval is essential for long-context LLM inference, yet existing methods struggle with distribution drift and high latency at scale. We introduce ParisKV, a drift-robust, GPU-native KV-cache retrieval framework based on collision-based candidate selection, followed by a quantized inner-product reranking estimator. For million-token contexts, ParisKV supports CPU-offloaded KV caches via Unified Virtual Addressing (UVA), enabling on-demand top-$k$ fetching with minimal overhead. ParisKV matches or outperforms full attention quality on long-input and long-generation benchmarks. It achieves state-of-the-art long-context decoding efficiency: it matches or exceeds full attention speed even at batch size 1 for long contexts, delivers up to 2.8$\\times$ higher throughput within full attention's runnable range, and scales to million-token contexts where full attention runs out of memory. At million-token scale, ParisKV reduces decode latency by 17$\\times$ and 44$\\times$ compared to MagicPIG and PQCache, respectively, two state-of-the-art KV-cache Top-$k$ retrieval baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07824", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07824", "abs": "https://arxiv.org/abs/2602.07824", "authors": ["Yiwei Qin", "Zhen Huang", "Tiantian Mi", "Weiye Si", "Chenyang Zhou", "Qipeng Guo", "Siyuan Feng", "Pengfei Liu"], "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training", "comment": null, "summary": "Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.\n  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07833", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07833", "abs": "https://arxiv.org/abs/2602.07833", "authors": ["Weijiang Lv", "Yaoxuan Feng", "Xiaobo Xia", "Jiayu Wang", "Yan Jing", "Wenchao Chen", "Bo Chen"], "title": "SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models", "comment": "53 pages, 42 figures, 14 tables", "summary": "Chain-of-Thought reasoning is widely used to improve the interpretability of multimodal large language models (MLLMs), yet the faithfulness of the generated reasoning traces remains unclear. Prior work has mainly focused on perceptual hallucinations, leaving reasoning level unfaithfulness underexplored. To isolate faithfulness from linguistic priors, we introduce SPD-Faith Bench, a diagnostic benchmark based on fine-grained image difference reasoning that enforces explicit visual comparison. Evaluations on state-of-the-art MLLMs reveal two systematic failure modes, perceptual blindness and perception-reasoning dissociation. We trace these failures to decaying visual attention and representation shifts in the residual stream. Guided by this analysis, we propose SAGE, a train-free visual evidence-calibrated framework that improves visual routing and aligns reasoning with perception. Our results highlight the importance of explicitly evaluating faithfulness beyond response correctness. Our benchmark and codes are available at https://github.com/Johanson-colab/SPD-Faith-Bench.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07852", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07852", "abs": "https://arxiv.org/abs/2602.07852", "authors": ["Anna Soligo", "Edward Turner", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard", "comment": "Published at ICLR 2026", "summary": "Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07892", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07892", "abs": "https://arxiv.org/abs/2602.07892", "authors": ["Guanglong Sun", "Siyuan Zhang", "Liyuan Wang", "Jun Zhu", "Hang Su", "Yi Zhong"], "title": "Safety Alignment as Continual Learning: Mitigating the Alignment Tax via Orthogonal Gradient Projection", "comment": null, "summary": "Large Language Models (LLMs) often incur an alignment tax: safety post-training can reduce general utility (e.g., reasoning and coding). We argue that this tax primarily arises from continual-learning-style forgetting in sequential alignment, where distribution shift and conflicting objectives cause safety updates to overwrite pre-trained competencies. Accordingly, we cast safety alignment as a continual learning (CL) problem that must balance plasticity (acquiring safety constraints) and stability (preserving general abilities). We propose Orthogonal Gradient Projection for Safety Alignment (OGPSA), a lightweight method that mitigates interference by constraining each safety update to be orthogonal (in a first-order sense) to a learned subspace capturing general capabilities. Specifically, OGPSA estimates a low-rank capability subspace from gradients on a small reference set and projects the safety gradient onto its orthogonal complement before updating. This produces safety-directed updates that minimally perturb prior knowledge while retaining capacity for alignment. OGPSA is plug-and-play and integrates into standard post-training pipelines without large-scale replay, auxiliary objectives, or retraining. Across Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and sequential SFT$\\rightarrow$DPO settings, OGPSA consistently improves the safety--utility Pareto frontier over standard baselines. For instance, on Qwen2.5-7B-Instruct under SFT$\\rightarrow$DPO, OGPSA preserves strong safety while recovering general capability, improving SimpleQA from 0.53\\% to 3.03\\% and IFEval from 51.94\\% to 63.96\\%. Our source code is available at \\href{https://github.com/SunGL001/OGPSA}{OGPSA}", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.07983", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07983", "abs": "https://arxiv.org/abs/2602.07983", "authors": ["Jishu Sen Gupta", "Harini SI", "Somesh Kumar Singh", "Syed Mohamad Tawseeq", "Yaman Kumar Singla", "David Doermann", "Rajiv Ratn Shah", "Balaji Krishnamurthy"], "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation", "comment": null, "summary": "Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08009", "abs": "https://arxiv.org/abs/2602.08009", "authors": ["Rui Li", "Zeyu Zhang", "Xiaohe Bo", "Quanyu Dai", "Chaozhuo Li", "Feng Wen", "Xu Chen"], "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective", "comment": null, "summary": "Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08024", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08024", "abs": "https://arxiv.org/abs/2602.08024", "authors": ["Ziyang Fan", "Keyu Chen", "Ruilong Xing", "Yulin Li", "Li Jiang", "Zhuotao Tian"], "title": "FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging", "comment": "Accepted by ICLR 2026 (Oral)", "summary": "Although Video Large Language Models (VLLMs) have shown remarkable capabilities in video understanding, they are required to process high volumes of visual tokens, causing significant computational inefficiency. Existing VLLMs acceleration frameworks usually compress spatial and temporal redundancy independently, which overlooks the spatiotemporal relationships, thereby leading to suboptimal spatiotemporal compression. The highly correlated visual features are likely to change in spatial position, scale, orientation, and other attributes over time due to the dynamic nature of video. Building on this insight, we introduce FlashVID, a training-free inference acceleration framework for VLLMs. Specifically, FlashVID utilizes Attention and Diversity-based Token Selection (ADTS) to select the most representative tokens for basic video representation, then applies Tree-based Spatiotemporal Token Merging (TSTM) for fine-grained spatiotemporal redundancy elimination. Extensive experiments conducted on three representative VLLMs across five video understanding benchmarks demonstrate the effectiveness and generalization of our method. Notably, by retaining only 10% of visual tokens, FlashVID preserves 99.1% of the performance of LLaVA-OneVision. Consequently, FlashVID can serve as a training-free and plug-and-play module for extending long video frames, which enables a 10x increase in video frame input to Qwen2.5-VL, resulting in a relative improvement of 8.6% within the same computational budget. Code is available at https://github.com/Fanziyang-v/FlashVID.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08030", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08030", "abs": "https://arxiv.org/abs/2602.08030", "authors": ["Yilun Zheng", "Dongyang Ma", "Tian Liang", "Jiahao Xu", "Xinting Huang", "Lijie Chen", "Haitao Mi", "Yan Wang"], "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models", "comment": null, "summary": "Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.\n  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08041", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08041", "abs": "https://arxiv.org/abs/2602.08041", "authors": ["Boyang Xia", "Weiyou Tian", "Qingnan Ren", "Jiaqi Huang", "Jie Xiao", "Shuo Lu", "Kai Wang", "Lynn Ai", "Eric Yang", "Bill Shi"], "title": "Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments", "comment": null, "summary": "Training large language model (LLM) agents for adversarial games is often driven by episodic objectives such as win rate. In long-horizon settings, however, payoffs are shaped by latent strategic externalities that evolve over time, so myopic optimization and variation-based regret analyses can become vacuous even when the dynamics are predictable. To solve this problem, we introduce Implicit Strategic Optimization (ISO), a prediction-aware framework in which each agent forecasts the current strategic context and uses it to update its policy online. ISO combines a Strategic Reward Model (SRM) that estimates the long-run strategic value of actions with iso-grpo, a context-conditioned optimistic learning rule. We prove sublinear contextual regret and equilibrium convergence guarantees whose dominant terms scale with the number of context mispredictions; when prediction errors are bounded, our bounds recover the static-game rates obtained when strategic externalities are known. Experiments in 6-player No-Limit Texas Hold'em and competitive Pokemon show consistent improvements in long-term return over strong LLM and RL baselines, and graceful degradation under controlled prediction noise.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08064", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08064", "abs": "https://arxiv.org/abs/2602.08064", "authors": ["Tianyu Li", "Dongchen Han", "Zixuan Cao", "Haofeng Huang", "Mengyu Zhou", "Ming Chen", "Erchao Zhao", "Xiaoxi Jiang", "Guanjun Jiang", "Gao Huang"], "title": "SiameseNorm: Breaking the Barrier to Reconciling Pre/Post-Norm", "comment": null, "summary": "Modern Transformers predominantly adopt the Pre-Norm paradigm for its optimization stability, foregoing the superior potential of the unstable Post-Norm architecture. Prior attempts to combine their strengths typically lead to a stability-performance trade-off. We attribute this phenomenon to a structural incompatibility within a single-stream design: Any application of the Post-Norm operation inevitably obstructs the clean identity gradient preserved by Pre-Norm. To fundamentally reconcile these paradigms, we propose SiameseNorm, a two-stream architecture that couples Pre-Norm-like and Post-Norm-like streams with shared parameters. This design decouples the optimization dynamics of the two streams, retaining the distinct characteristics of both Pre-Norm and Post-Norm by enabling all residual blocks to receive combined gradients inherited from both paradigms, where one stream secures stability while the other enhances expressivity. Extensive pre-training experiments on 1.3B-parameter models demonstrate that SiameseNorm exhibits exceptional optimization robustness and consistently outperforms strong baselines. Code is available at https://github.com/Qwen-Applications/SiameseNorm.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08128", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08128", "abs": "https://arxiv.org/abs/2602.08128", "authors": ["Zahir Alsulaimawi"], "title": "Online Bayesian Imbalanced Learning with Bregman-Calibrated Deep Networks", "comment": null, "summary": "Class imbalance remains a fundamental challenge in machine learning, where standard classifiers exhibit severe performance degradation in minority classes. Although existing approaches address imbalance through resampling or cost-sensitive learning during training, they require retraining or access to labeled target data when class distributions shift at deployment time, a common occurrence in real-world applications such as fraud detection, medical diagnosis, and anomaly detection. We present \\textit{Online Bayesian Imbalanced Learning} (OBIL), a principled framework that decouples likelihood-ratio estimation from class-prior assumptions, enabling real-time adaptation to distribution shifts without model retraining. Our approach builds on the established connection between Bregman divergences and proper scoring rules to show that deep networks trained with such losses produce posterior probability estimates from which prior-invariant likelihood ratios can be extracted. We prove that these likelihood-ratio estimates remain valid under arbitrary changes in class priors and cost structures, requiring only a threshold adjustment for optimal Bayes decisions. We derive finite-sample regret bounds demonstrating that OBIL achieves $O(\\sqrt{T \\log T})$ regret against an oracle with perfect prior knowledge. Extensive experiments on benchmark datasets and medical diagnosis benchmarks under simulated deployment shifts demonstrate that OBIL maintains robust performance under severe distribution shifts, outperforming state-of-the-art methods in F1 Score when test distributions deviate significantly from the training conditions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08145", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08145", "abs": "https://arxiv.org/abs/2602.08145", "authors": ["Xinyu Yang", "Junlin Han", "Rishi Bommasani", "Jinqi Luo", "Wenjie Qu", "Wangchunshu Zhou", "Adel Bibi", "Xiyao Wang", "Jaehong Yoon", "Elias Stengel-Eskin", "Shengbang Tong", "Lingfeng Shen", "Rafael Rafailov", "Runjia Li", "Zhaoyang Wang", "Yiyang Zhou", "Chenhang Cui", "Yu Wang", "Wenhao Zheng", "Huichi Zhou", "Jindong Gu", "Zhaorun Chen", "Peng Xia", "Tony Lee", "Thomas Zollo", "Vikash Sehwag", "Jixuan Leng", "Jiuhai Chen", "Yuxin Wen", "Huan Zhang", "Zhun Deng", "Linjun Zhang", "Pavel Izmailov", "Pang Wei Koh", "Yulia Tsvetkov", "Andrew Wilson", "Jiaheng Zhang", "James Zou", "Cihang Xie", "Hao Wang", "Philip Torr", "Julian McAuley", "David Alvarez-Melis", "Florian Tram\u00e8r", "Kaidi Xu", "Suman Jana", "Chris Callison-Burch", "Rene Vidal", "Filippos Kokkinos", "Mohit Bansal", "Beidi Chen", "Huaxiu Yao"], "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey", "comment": "TMLR camera-ready version", "summary": "Foundation models, including Large Language Models (LLMs), Multimodal Large Language Models (MLLMs), Image Generative Models (i.e, Text-to-Image Models and Image-Editing Models), and Video Generative Models, have become essential tools with broad applications across various domains such as law, medicine, education, finance, science, and beyond. As these models see increasing real-world deployment, ensuring their reliability and responsibility has become critical for academia, industry, and government. This survey addresses the reliable and responsible development of foundation models. We explore critical issues, including bias and fairness, security and privacy, uncertainty, explainability, and distribution shift. Our research also covers model limitations, such as hallucinations, as well as methods like alignment and Artificial Intelligence-Generated Content (AIGC) detection. For each area, we review the current state of the field and outline concrete future research directions. Additionally, we discuss the intersections between these areas, highlighting their connections and shared challenges. We hope our survey fosters the development of foundation models that are not only powerful but also ethical, trustworthy, reliable, and socially responsible.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08159", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08159", "abs": "https://arxiv.org/abs/2602.08159", "authors": ["Seonglae Cho", "Zekun Wu", "Kleyton Da Costa", "Adriano Koshiyama"], "title": "The Confidence Manifold: Geometric Structure of Correctness Representations in Language Models", "comment": null, "summary": "When a language model asserts that \"the capital of Australia is Sydney,\" does it know this is wrong? We characterize the geometry of correctness representations across 9 models from 5 architecture families. The structure is simple: the discriminative signal occupies 3-8 dimensions, performance degrades with additional dimensions, and no nonlinear classifier improves over linear separation. Centroid distance in the low-dimensional subspace matches trained probe performance (0.90 AUC), enabling few-shot detection: on GPT-2, 25 labeled examples achieve 89% of full-data accuracy. We validate causally through activation steering: the learned direction produces 10.9 percentage point changes in error rates while random directions show no effect. Internal probes achieve 0.80-0.97 AUC; output-based methods (P(True), semantic entropy) achieve only 0.44-0.64 AUC. The correctness signal exists internally but is not expressed in outputs. That centroid distance matches probe performance indicates class separation is a mean shift, making detection geometric rather than learned.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08169", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08169", "abs": "https://arxiv.org/abs/2602.08169", "authors": ["Zejia You", "Chunyuan Deng", "Hanjie Chen"], "title": "Spherical Steering: Geometry-Aware Activation Rotation for Language Models", "comment": "The code is at: https://github.com/chili-lab/Spherical-Steering", "summary": "Inference-time steering has emerged as a promising paradigm for controlling language models (LMs) without the cost of retraining. However, standard approaches typically rely on activation addition, a geometric operation that inevitably alters the magnitude of hidden representations. This raises concerns about representation collapse and degradation of open-ended generation capabilities. In this work, we explore Spherical Steering, a training-free primitive that resolves this trade-off through activation rotation. Rather than shifting activations with a fixed vector, our method rotates them along a geodesic toward a target direction, guiding the activation toward the target concept while preserving the integrity of the signal. To further enhance adaptivity, we incorporate a confidence gate that dynamically modulates steering strength based on input uncertainty. Extensive experiments across multiple-choice benchmarks demonstrate that Spherical Steering significantly outperforms addition-based baselines (notably by +10% on TruthfulQA, COPA, and Storycloze), while simultaneously maintaining the model's general open-ended generation quality. This work highlights the value of geometric consistency, suggesting that norm-preserving rotation is a robust and effective primitive for precise inference-time control.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08194", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08194", "abs": "https://arxiv.org/abs/2602.08194", "authors": ["Konstantinos Mitsides", "Maxence Faldor", "Antoine Cully"], "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds", "comment": "11 pages (main text), 90 pages total. Project page: https://konstantinosmitsides.github.io/dreaming-in-code", "summary": "Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a $16\\%$ improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08213", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.08213", "abs": "https://arxiv.org/abs/2602.08213", "authors": ["Haoran Liu", "Zheni Zeng", "Yukun Yan", "Yuxuan Chen", "Yunduo Xiao"], "title": "DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning", "comment": null, "summary": "Molecule generation and optimization is a fundamental task in chemical domain. The rapid development of intelligent tools, especially large language models (LLMs) with powerful knowledge reserves and interactive capabilities, has provided new paradigms for it. Nevertheless, the intrinsic challenge for LLMs lies in the complex implicit relationship between molecular structure and pharmacological properties and the lack of corresponding labeled data. To bridge this gap, we propose DrugR, an LLM-based method that introduces explicit, step-by-step pharmacological reasoning into the optimization process. Our approach integrates domain-specific continual pretraining, supervised fine-tuning via reverse data engineering, and self-balanced multi-granular reinforcement learning. This framework enables DrugR to effectively improve key ADMET properties while preserving the original molecule's core efficacy. Experimental results demonstrate that DrugR achieves comprehensive enhancement across multiple properties without compromising structural similarity or target binding affinity. Importantly, its explicit reasoning process provides clear, interpretable rationales for each optimization step, yielding actionable design insights and advancing toward automated, knowledge-driven scientific discovery. Our code and model checkpoints are open-sourced to foster future research.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08236", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08236", "abs": "https://arxiv.org/abs/2602.08236", "authors": ["Shoubin Yu", "Yue Zhang", "Zun Wang", "Jaehong Yoon", "Huaxiu Yao", "Mingyu Ding", "Mohit Bansal"], "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning", "comment": "the first two authors are equally contributed. Project page: https://adaptive-visual-tts.github.io/", "summary": "Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination. Across spatial reasoning benchmarks (SAT, MMSI) and an embodied navigation benchmark (R2R), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08343", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08343", "abs": "https://arxiv.org/abs/2602.08343", "authors": ["Debajyoti Datta", "Trishala Neeraj", "Bibek Paudel", "Vyom Sharma", "Subhabrata Mukherjee"], "title": "ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection", "comment": "18 pages, 5 figures, 18 tables", "summary": "Long-context inference is constrained by KV-cache memory, which grows linearly with sequence length; KV-cache compression therefore hinges on reliably selecting which past tokens to retain. Most geometry-based eviction methods score keys by cosine similarity to a global centroid, but cosine is scale-invariant and can discard magnitude cues that distinguish semantically salient tokens. We propose ManifoldKV, a training-free scorer that ranks tokens by Euclidean distance to the key centroid, capturing both angular and radial deviations.\n  On the RULER benchmark, ManifoldKV achieves 95.7% accuracy at 4K-16K contexts with 20% compression; matching the best geometric baseline while improving robustness in two regimes where cosine scoring fails. First, on multi-key retrieval, ManifoldKV reduces directional collisions, achieving 92.4% vs KeyDiff's 77.0% (+15.4 points) on 3-key NIAH at 50% compression. Second, to address dilution and performance collapse of global centroids at 64K context, we introduce WindowedManifoldKV, which restores accuracy to 84.3% at 25% compression, a 49-point recovery over global L2 and +3.2 points over KeyDiff. The method requires only 3 lines of code and works across 4 architectures without tuning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08369", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08369", "abs": "https://arxiv.org/abs/2602.08369", "authors": ["Xin Zhang", "Kailai Yang", "Chenyue Li", "Hao Li", "Qiyu Wei", "Jun'ichi Tsujii", "Sophia Ananiadou"], "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval", "comment": null, "summary": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08377", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08377", "abs": "https://arxiv.org/abs/2602.08377", "authors": ["Bilgehan Sel", "Vaishakh Keshava", "Phillip Wallis", "Lukas Rutishauser", "Ming Jin", "Dingcheng Li"], "title": "Reinforcement Learning with Backtracking Feedback", "comment": "NeurIPS 2025", "summary": "Addressing the critical need for robust safety in Large Language Models (LLMs), particularly against adversarial attacks and in-distribution errors, we introduce Reinforcement Learning with Backtracking Feedback (RLBF). This framework advances upon prior methods, such as BSAFE, by primarily leveraging a Reinforcement Learning (RL) stage where models learn to dynamically correct their own generation errors. Through RL with critic feedback on the model's live outputs, LLMs are trained to identify and recover from their actual, emergent safety violations by emitting an efficient \"backtrack by x tokens\" signal, then continuing generation autoregressively. This RL process is crucial for instilling resilience against sophisticated adversarial strategies, including middle filling, Greedy Coordinate Gradient (GCG) attacks, and decoding parameter manipulations. To further support the acquisition of this backtracking capability, we also propose an enhanced Supervised Fine-Tuning (SFT) data generation strategy (BSAFE+). This method improves upon previous data creation techniques by injecting violations into coherent, originally safe text, providing more effective initial training for the backtracking mechanism. Comprehensive empirical evaluations demonstrate that RLBF significantly reduces attack success rates across diverse benchmarks and model scales, achieving superior safety outcomes while critically preserving foundational model utility.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08489", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08489", "abs": "https://arxiv.org/abs/2602.08489", "authors": ["Hyunseok Lee", "Soheil Abbasloo", "Jihoon Tack", "Jinwoo Shin"], "title": "Beyond Correctness: Learning Robust Reasoning via Transfer", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning, but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple philosophical view, robust reasoning should remain useful beyond the mind that produced it, and treat reasoning as a form of meaning transfer that must survive truncation, reinterpretation, and continuation. Building on this principle, we introduce Reinforcement Learning with Transferable Reward (RLTR), which operationalizes robustness via transfer reward that tests whether a partial reasoning prefix from one model can guide a separate model to the correct answer. This encourages LLMs to produce reasoning that is stable, interpretable, and genuinely generalizable. Our approach improves sampling consistency while improving final answer accuracy, and it reaches comparable performance in substantially fewer training steps. For example, on MATH500, RLTR achieves a +3.6%p gain in Maj@64 compared to RLVR and matches RLVR's average accuracy with roughly 2.5x fewer training steps, providing both more reliable reasoning and significantly more sample efficient.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08503", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08503", "abs": "https://arxiv.org/abs/2602.08503", "authors": ["Yi Ding", "Ziliang Qiu", "Bolian Li", "Ruqi Zhang"], "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation", "comment": "17 pages", "summary": "Self-correction is essential for solving complex reasoning problems in vision-language models (VLMs). However, existing reinforcement learning (RL) methods struggle to learn it, as effective self-correction behaviors emerge only rarely, making learning signals extremely sparse. To address this challenge, we propose correction-specific rollouts (Octopus), an RL rollout augmentation framework that synthesizes dense self-correction examples by recombining existing rollouts. This augmentation simultaneously improves sample efficiency due to rollout reuse and stabilizes RL optimization through balanced supervision. Furthermore, we introduce a response-masking strategy that decouples self-correction from direct reasoning, avoiding signal conflicts and enabling both behaviors to be learned effectively. Building on this, we introduce Octopus-8B, a reasoning VLM with controllable self-correction capability. Across 7 benchmarks, it achieves SoTA performance among open-source VLMs, outperforming the best RLVR baseline by 1.0 score while requiring only $0.72\\times$ training time per step.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08783", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08783", "abs": "https://arxiv.org/abs/2602.08783", "authors": ["Zirui Li", "Xuefeng Bai", "Kehai Chen", "Yizhi Li", "Jian Yang", "Chenghua Lin", "Min Zhang"], "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure", "comment": "22 pages", "summary": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08796", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08796", "abs": "https://arxiv.org/abs/2602.08796", "authors": ["Kevin Fan", "Jacquelyn A. Bialo", "Hongli Li"], "title": "The Use of AI Tools to Develop and Validate Q-Matrices", "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA", "summary": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08819", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08819", "abs": "https://arxiv.org/abs/2602.08819", "authors": ["Jiwoo Hong", "Shao Tang", "Zhipeng Wang"], "title": "Bayesian Preference Learning for Test-Time Steerable Reward Models", "comment": "Preprint", "summary": "Reward models are central to aligning language models with human preferences via reinforcement learning (RL). As RL is increasingly applied to settings such as verifiable rewards and multi-objective alignment, RMs are expected to encode more complex and multifaceted preference distributions. However, classifier RMs remain static once trained, limiting their adaptability at test time. We propose Variational In-Context Reward Modeling (ICRM), a novel Bayesian reward modeling objective that enables test-time steerability via in-context preference demonstrations. ICRM casts reward modeling as amortized variational inference over a latent preference probability under the Bradley-Terry model using a conjugate Beta prior. We show that ICRM adapt to unseen preference distributions at test time for both single and multi-objective settings. With more in-context demonstrations, ICRM gains 34% accuracy on SafeRLHF and 9% accuracy on RM-Bench in the single-objective setting, while widening the Pareto frontier with a 4% gain in hypervolume on helpfulness and refusal benchmarks. We further study the practical applicability of ICRM for RL training, showing that it can effectively encode verifiable rewards by outperforming a conventional RM in math reasoning. Finally, we provide theoretical guarantees that the variational objective admits a global interior optimum with finite confidence, and we analyze how KL regularization mitigates reward over-optimization.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08857", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08857", "abs": "https://arxiv.org/abs/2602.08857", "authors": ["Xinting Huang", "Aleksandra Bakalova", "Satwik Bhattamishra", "William Merrill", "Michael Hahn"], "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP", "comment": "101 pages, 92 figures", "summary": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08948", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08948", "abs": "https://arxiv.org/abs/2602.08948", "authors": ["Chen Jin", "Ryutaro Tanno", "Tom Diethe", "Philip Teare"], "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute", "comment": null, "summary": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.08964", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08964", "abs": "https://arxiv.org/abs/2602.08964", "authors": ["Raghu Arghal", "Fade Chen", "Niall Dalton", "Evgenii Kortukov", "Calum McNamara", "Angelos Nalmpantis", "Moksh Nirvaan", "Gabriele Sarti", "Mario Giulianelli"], "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents", "comment": null, "summary": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09003", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09003", "abs": "https://arxiv.org/abs/2602.09003", "authors": ["Yudong Wang", "Zixuan Fu", "Hengyu Zhao", "Chen Zhao", "Chuyue Zhou", "Xinle Lin", "Hongya Lyu", "Shuaikang Xue", "Yi Yi", "Yingjiao Wang", "Zhi Zheng", "Yuzhou Zhang", "Jie Zhou", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management", "comment": "16 pages, 3 figures, 7 tables", "summary": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.09012", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09012", "abs": "https://arxiv.org/abs/2602.09012", "authors": ["Jiacheng Liu", "Yaxin Luo", "Jiacheng Cui", "Xinyi Shang", "Xiaohan Zhao", "Zhiqiang Shen"], "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense", "comment": "Project page at https://greenoso.github.io/NextGen-CAPTCHAs_webpage/", "summary": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
