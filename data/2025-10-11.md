<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene](https://arxiv.org/abs/2510.06754)
*Christian Maurer,Snehal Jauhri,Sophie Lueth,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: UniFField是一个统一的、可感知的神经特征场，能够结合视觉、语义和几何特征，并预测每个模态的不确定性。该方法可以零样本应用于任何新环境，并通过增量集成RGB-D图像来更新不确定性估计，可用于机器人任务的鲁棒决策。


<details>
  <summary>Details</summary>
Motivation: 现有3D神经特征场方法在场景通用性和不确定性建模方面存在局限性，阻碍了机器人理解和决策能力的提升。

Method: UniFField通过结合视觉、语义和几何特征，构建统一的可泛化表示，并预测不确定性。它能零样本应用于新环境，并通过增量集成RGB-D图像来更新特征表示和不确定性估计。

Result: UniFField的不确定性估计能够准确描述场景重建和语义特征预测中的模型预测误差。在移动操作机器人主动物体搜索任务中，利用其特征预测及其不确定性，成功实现了鲁棒决策。

Conclusion: UniFField通过提供统一的、可感知的神经特征场表示，解决了现有方法的局限性，并能为机器人提供鲁棒的决策支持。

Abstract: Comprehensive visual, geometric, and semantic understanding of a 3D scene is
crucial for successful execution of robotic tasks, especially in unstructured
and complex environments. Additionally, to make robust decisions, it is
necessary for the robot to evaluate the reliability of perceived information.
While recent advances in 3D neural feature fields have enabled robots to
leverage features from pretrained foundation models for tasks such as
language-guided manipulation and navigation, existing methods suffer from two
critical limitations: (i) they are typically scene-specific, and (ii) they lack
the ability to model uncertainty in their predictions. We present UniFField, a
unified uncertainty-aware neural feature field that combines visual, semantic,
and geometric features in a single generalizable representation while also
predicting uncertainty in each modality. Our approach, which can be applied
zero shot to any new environment, incrementally integrates RGB-D images into
our voxel-based feature representation as the robot explores the scene,
simultaneously updating uncertainty estimation. We evaluate our uncertainty
estimations to accurately describe the model prediction errors in scene
reconstruction and semantic feature prediction. Furthermore, we successfully
leverage our feature predictions and their respective uncertainty for an active
object search task using a mobile manipulator robot, demonstrating the
capability for robust decision-making.

</details>
