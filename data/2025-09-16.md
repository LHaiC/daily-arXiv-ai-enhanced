<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 145]
- [cs.CL](#cs.CL) [Total: 88]
- [cs.SI](#cs.SI) [Total: 8]
- [cs.DS](#cs.DS) [Total: 4]
- [cs.GT](#cs.GT) [Total: 4]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.AI](#cs.AI) [Total: 50]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 24]
- [cs.AR](#cs.AR) [Total: 6]
- [eess.SY](#eess.SY) [Total: 34]
- [cs.ET](#cs.ET) [Total: 5]
- [cs.MA](#cs.MA) [Total: 6]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 25]
- [cs.NE](#cs.NE) [Total: 4]
- [eess.SP](#eess.SP) [Total: 34]
- [cs.DC](#cs.DC) [Total: 17]
- [cs.GR](#cs.GR) [Total: 6]
- [physics.app-ph](#physics.app-ph) [Total: 8]
- [quant-ph](#quant-ph) [Total: 71]
- [cs.LG](#cs.LG) [Total: 153]
- [cs.RO](#cs.RO) [Total: 54]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Real-Time Diminished Reality Approach to Privacy in MR Collaboration](https://arxiv.org/abs/2509.10466)
*Christian Fane*

Main category: cs.CV

TL;DR: 该论文提出了一个基于图像修复的实时缩减现实（DR）系统，用于在混合现实（MR）会议中实现隐私控制。该系统允许用户选择性地移除其环境中的个人或敏感物品，使其对其他参与者不可见。


<details>
  <summary>Details</summary>
Motivation: 在共享空间的MR会议中实现隐私控制，允许用户移除个人或敏感物品，确保其对其他参与者不可见。

Method: 系统通过语义分割和精确的对象选择，利用YOLOv11进行对象检测，并使用修改后的DSTT模型进行实时图像修复，从次要观察者的视角合成背景内容。

Result: 在720p分辨率下，该系统实现了超过20 fps的帧率，证明了实时DR在实际隐私保护MR应用中的可行性。

Conclusion: 提出的实时DR系统能够有效地移除MR环境中的选定对象，为共享空间中的隐私控制提供了实际可行的解决方案。

Abstract: Diminished reality (DR) refers to the digital removal of real-world objects
by compositing background content in their place. This thesis presents a
real-time, inpainting-based DR system designed to enable privacy control in
shared-space mixed reality (MR) meetings. The system allows a primary headset
user to selectively remove personal or sensitive items from their environment,
ensuring that those objects are no longer visible to other participants.
Removal is achieved through semantic segmentation and precise object selection,
followed by real-time inpainting from the viewpoint of a secondary observer,
implemented using a mobile ZED 2i depth camera. The solution is designed to be
portable and robust, requiring neither a fixed secondary viewpoint nor prior 3D
scanning of the environment. The system utilises YOLOv11 for object detection
and a modified Decoupled Spatial-Temporal Transformer (DSTT) model for
high-quality video inpainting. At 720p resolution, the pipeline sustains frame
rates exceeding 20 fps, demonstrating the feasibility of real-time diminished
reality for practical privacy-preserving MR applications.

</details>


### [2] [SurgLaVi: Large-Scale Hierarchical Dataset for Surgical Vision-Language Representation Learning](https://arxiv.org/abs/2509.10555)
*Alejandra Perez,Chinedu Nwoye,Ramtin Raji Kermani,Omid Mohareri,Muhammad Abdullah Jamal*

Main category: cs.CV

TL;DR: SurgLaVi是一个大规模、多样化的手术视频-语言数据集，包含近24万个片段-描述对，涵盖200多种手术，并具有阶段、步骤和任务级别。该数据集通过自动化流程创建，并经过双模态过滤以确保质量。SurgLaVi-{eta}是其开源版本，包含11.3万个片段-描述对。基于SurgLaVi数据集，我们提出了SurgCLIP模型，在手术识别任务上取得了显著的性能提升，证明了大型、语义丰富、结构化的数据集对于开发通用手术基础模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的外科视觉语言预训练（VLP）数据集规模有限、程序多样性不足、语义质量不高且缺乏层次结构，这限制了外科VLP的进展。

Method: 我们提出了SurgLaVi，一个包含近24万个片段-描述对、涵盖200多种手术、并包含阶段-步骤-任务级别层次结构的手术视觉语言数据集。该数据集通过一个全自动流水线生成细粒度转录和分割，并利用双模态过滤来提高注释质量。此外，我们还发布了SurgLaVi-{eta}，一个包含11.3万个片段-描述对的开源版本。我们还引入了一个基于SurgLaVi数据集的CLIP风格视频-文本对比框架SurgCLIP。

Result: SurgCLIP在阶段、步骤、动作和工具识别方面取得了持续的改进，其性能超越了现有最先进的方法，并且通常具有较大的优势。

Conclusion: 大规模、语义丰富、层次结构化的数据集能够直接转化为更强大、更通用的模型表征，SurgLaVi数据集为开发手术基础模型提供了关键资源。

Abstract: Vision-language pre-training (VLP) offers unique advantages for surgery by
aligning language with surgical videos, enabling workflow understanding and
transfer across tasks without relying on expert-labeled datasets. However,
progress in surgical VLP remains constrained by the limited scale, procedural
diversity, semantic quality, and hierarchical structure of existing datasets.
In this work, we present SurgLaVi, the largest and most diverse surgical
vision-language dataset to date, comprising nearly 240k clip-caption pairs from
more than 200 procedures, and comprising hierarchical levels at phase-, step-,
and task-level. At the core of SurgLaVi lies a fully automated pipeline that
systematically generates fine-grained transcriptions of surgical videos and
segments them into coherent procedural units. To ensure high-quality
annotations, it applies dual-modality filtering to remove irrelevant and noisy
samples. Within this framework, the resulting captions are enriched with
contextual detail, producing annotations that are both semantically rich and
easy to interpret. To ensure accessibility, we release SurgLaVi-\b{eta}, an
open-source derivative of 113k clip-caption pairs constructed entirely from
public data, which is over four times larger than existing surgical VLP
datasets. To demonstrate the value of SurgLaVi datasets, we introduce SurgCLIP,
a CLIP-style video-text contrastive framework with dual encoders, as a
representative base model. SurgCLIP achieves consistent improvements across
phase, step, action, and tool recognition, surpassing prior state-of-the-art
methods, often by large margins. These results validate that large-scale,
semantically rich, and hierarchically structured datasets directly translate
into stronger and more generalizable representations, establishing SurgLaVi as
a key resource for developing surgical foundation models.

</details>


### [3] [Building a General SimCLR Self-Supervised Foundation Model Across Neurological Diseases to Advance 3D Brain MRI Diagnoses](https://arxiv.org/abs/2509.10620)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 提出一个基于SimCLR的3D脑结构MRI的自监督学习基础模型，在四个下游任务上优于其他模型，并公开了代码和模型。


<details>
  <summary>Details</summary>
Motivation: 现有的3D脑MRI深度学习模型通常针对特定任务且标签数据有限，泛化能力不足。而现有的3D脑MRI基础模型在分辨率、范围或可获取性方面存在局限。因此，需要一个通用、高分辨率的3D脑结构MRI自监督学习基础模型。

Method: 使用SimCLR自监督学习方法，在18,759名患者（44,958个扫描）的11个公开数据集上进行预训练，数据集涵盖多种神经系统疾病。并将该模型与Masked Autoencoders（MAE）以及两个监督基线模型在四个不同的下游预测任务上进行比较，包括 in-distribution和out-of-distribution设置。

Result: 在所有任务中，微调后的SimCLR模型均优于其他所有模型。特别地，即使只使用20%的标记训练样本进行阿尔茨海默病预测，该模型仍然取得了优越的性能。

Conclusion: 该工作提出了一个通用、高分辨率的SimCLR-based自监督学习基础模型，适用于临床脑MRI分析，并且通过公开代码和模型提高了其可及性。

Abstract: 3D structural Magnetic Resonance Imaging (MRI) brain scans are commonly
acquired in clinical settings to monitor a wide range of neurological
conditions, including neurodegenerative disorders and stroke. While deep
learning models have shown promising results analyzing 3D MRI across a number
of brain imaging tasks, most are highly tailored for specific tasks with
limited labeled data, and are not able to generalize across tasks and/or
populations. The development of self-supervised learning (SSL) has enabled the
creation of large medical foundation models that leverage diverse, unlabeled
datasets ranging from healthy to diseased data, showing significant success in
2D medical imaging applications. However, even the very few foundation models
for 3D brain MRI that have been developed remain limited in resolution, scope,
or accessibility. In this work, we present a general, high-resolution
SimCLR-based SSL foundation model for 3D brain structural MRI, pre-trained on
18,759 patients (44,958 scans) from 11 publicly available datasets spanning
diverse neurological diseases. We compare our model to Masked Autoencoders
(MAE), as well as two supervised baselines, on four diverse downstream
prediction tasks in both in-distribution and out-of-distribution settings. Our
fine-tuned SimCLR model outperforms all other models across all tasks. Notably,
our model still achieves superior performance when fine-tuned using only 20% of
labeled training samples for predicting Alzheimer's disease. We use publicly
available code and data, and release our trained model at
https://github.com/emilykaczmarek/3D-Neuro-SimCLR, contributing a broadly
applicable and accessible foundation model for clinical brain MRI analysis.

</details>


### [4] [USCTNet: A deep unfolding nuclear-norm optimization solver for physically consistent HSI reconstruction](https://arxiv.org/abs/2509.10651)
*Xiaoyang Ma,Yiyang Chai,Xinran Qu,Hong Sun*

Main category: cs.CV

TL;DR: 提出了一种基于物理的RGB转HSI重建方法，通过显式估计相机光谱灵敏度和光照来保证色彩一致性，并引入低秩子空间SVT算子和深度展开网络USCTNet来提高重建精度。


<details>
  <summary>Details</summary>
Motivation: 从单张RGB图像重建高光谱图像（HSI）是一个不适定问题，并且当相机光谱灵敏度（CSS）和场景光照指定错误时，可能会导致物理上不一致。现有方法在处理这个问题时存在成本高和不稳定的问题。

Method: 将RGB到HSI的重建形式化为一个基于物理的逆问题，并在可学习的变换域中用核范数进行正则化。通过显式估计CSS和光照来定义每个迭代中嵌入的前向算子，以确保色彩一致性。引入了一个数据自适应的低秩子空间SVT算子来避免完全奇异值分解（SVD）的成本和不稳定性。基于这些组件，开发了一个名为USCTNet的深度展开求解器，它将参数估计模块与可学习的近端更新相结合。

Result: 在标准基准测试上的大量实验表明，与最先进的基于RGB的方法相比，USCTNet在重建精度方面取得了持续的改进。

Conclusion: 所提出的基于物理的RGB-HSI重建方法USCTNet，通过物理约束和改进的SVT算子，能够更准确、更稳定地进行HSI重建，并在实验中取得了优于现有方法的性能。

Abstract: Reconstructing hyperspectral images (HSIs) from a single RGB image is
ill-posed and can become physically inconsistent when the camera spectral
sensitivity (CSS) and scene illumination are misspecified. We formulate
RGB-to-HSI reconstruction as a physics-grounded inverse problem regularized by
a nuclear norm in a learnable transform domain, and we explicitly estimate CSS
and illumination to define the forward operator embedded in each iteration,
ensuring colorimetric consistency. To avoid the cost and instability of full
singular-value decompositions (SVDs) required by singular-value thresholding
(SVT), we introduce a data-adaptive low-rank subspace SVT operator. Building on
these components, we develop USCTNet, a deep unfolding solver tailored to HSI
that couples a parameter estimation module with learnable proximal updates.
Extensive experiments on standard benchmarks show consistent improvements over
state-of-the-art RGB-based methods in reconstruction accuracy. Code:
https://github.com/psykheXX/USCTNet-Code-Implementation.git

</details>


### [5] [A Comparison and Evaluation of Fine-tuned Convolutional Neural Networks to Large Language Models for Image Classification and Segmentation of Brain Tumors on MRI](https://arxiv.org/abs/2509.10683)
*Felicia Liu,Jay J. Yoo,Farzad Khalvati*

Main category: cs.CV

TL;DR: 大型语言模型（LLMs）在基于图像的医疗任务（如胶质瘤分类和分割）方面表现不如传统卷积神经网络（CNNs）。


<details>
  <summary>Details</summary>
Motivation: 在医疗图像任务中探索大型语言模型（LLMs）的有效性，并与传统的卷积神经网络（CNNs）进行比较。

Method: 使用 BraTS 2020 数据集，评估了通用视觉语言 LLM（LLaMA 3.2 Instruct）在微调前后的性能，并与自定义 3D CNNs 进行了基准测试。对于分割任务，实现了中心点、边界框和多边形提取三种方法。

Result: 在胶质瘤分类任务中，CNN 的准确率为 80%，而 LLM 在微调前的准确率为 76%，微调后为 72%。在分割任务中，CNN 能准确地定位胶质瘤，而 LLMs 的预测则倾向于聚集在图像中心，并且空间理解能力有限。微调对 LLMs 的空间准确性没有显著改善。

Conclusion: CNN 在胶质瘤分类和分割任务中的表现优于 LLMs。目前的 LLMs 在空间理解方面存在局限性，并且从微调中获得的改进有限，表明它们目前不适合基于图像的任务。

Abstract: Large Language Models (LLMs) have shown strong performance in text-based
healthcare tasks. However, their utility in image-based applications remains
unexplored. We investigate the effectiveness of LLMs for medical imaging tasks,
specifically glioma classification and segmentation, and compare their
performance to that of traditional convolutional neural networks (CNNs). Using
the BraTS 2020 dataset of multi-modal brain MRIs, we evaluated a
general-purpose vision-language LLM (LLaMA 3.2 Instruct) both before and after
fine-tuning, and benchmarked its performance against custom 3D CNNs. For glioma
classification (Low-Grade vs. High-Grade), the CNN achieved 80% accuracy and
balanced precision and recall. The general LLM reached 76% accuracy but
suffered from a specificity of only 18%, often misclassifying Low-Grade tumors.
Fine-tuning improved specificity to 55%, but overall performance declined
(e.g., accuracy dropped to 72%). For segmentation, three methods - center
point, bounding box, and polygon extraction, were implemented. CNNs accurately
localized gliomas, though small tumors were sometimes missed. In contrast, LLMs
consistently clustered predictions near the image center, with no distinction
of glioma size, location, or placement. Fine-tuning improved output formatting
but failed to meaningfully enhance spatial accuracy. The bounding polygon
method yielded random, unstructured outputs. Overall, CNNs outperformed LLMs in
both tasks. LLMs showed limited spatial understanding and minimal improvement
from fine-tuning, indicating that, in their current form, they are not
well-suited for image-based tasks. More rigorous fine-tuning or alternative
training strategies may be needed for LLMs to achieve better performance,
robustness, and utility in the medical space.

</details>


### [6] [Stable Part Diffusion 4D: Multi-View RGB and Kinematic Parts Video Generation](https://arxiv.org/abs/2509.10687)
*Hao Zhang,Chun-Han Yao,Simon Donné,Narendra Ahuja,Varun Jampani*

Main category: cs.CV

TL;DR: SP4D是一个生成配对RGB和运动学部件视频的框架，可用于下游动画任务。


<details>
  <summary>Details</summary>
Motivation: 与依赖外观线索的传统方法不同，SP4D学习生成与物体关节对齐且跨视图和时间一致的运动学部件。

Method: SP4D采用双分支扩散模型，联合合成RGB帧和相应的部件分割图，并引入空间颜色编码方案以简化架构并灵活支持不同的部件数量。此外，还采用了一个双向扩散融合模块（BiDiFuse）来增强跨分支的一致性，并通过对比部件一致性损失来促进部件预测的空间和时间对齐。

Result: SP4D生成的2D部件图可以提升到3D以推导骨架结构和谐波蒙皮权重，只需很少的手动调整。SP4D在各种场景下都表现出强大的泛化能力，包括真实世界的视频、新生成的对象和罕见的关节姿势。

Conclusion: SP4D能够生成运动学感知的输出，适用于下游动画和运动相关任务。

Abstract: We present Stable Part Diffusion 4D (SP4D), a framework for generating paired
RGB and kinematic part videos from monocular inputs. Unlike conventional part
segmentation methods that rely on appearance-based semantic cues, SP4D learns
to produce kinematic parts - structural components aligned with object
articulation and consistent across views and time. SP4D adopts a dual-branch
diffusion model that jointly synthesizes RGB frames and corresponding part
segmentation maps. To simplify the architecture and flexibly enable different
part counts, we introduce a spatial color encoding scheme that maps part masks
to continuous RGB-like images. This encoding allows the segmentation branch to
share the latent VAE from the RGB branch, while enabling part segmentation to
be recovered via straightforward post-processing. A Bidirectional Diffusion
Fusion (BiDiFuse) module enhances cross-branch consistency, supported by a
contrastive part consistency loss to promote spatial and temporal alignment of
part predictions. We demonstrate that the generated 2D part maps can be lifted
to 3D to derive skeletal structures and harmonic skinning weights with few
manual adjustments. To train and evaluate SP4D, we construct KinematicParts20K,
a curated dataset of over 20K rigged objects selected and processed from
Objaverse XL (Deitke et al., 2023), each paired with multi-view RGB and part
video sequences. Experiments show that SP4D generalizes strongly to diverse
scenarios, including real-world videos, novel generated objects, and rare
articulated poses, producing kinematic-aware outputs suitable for downstream
animation and motion-related tasks.

</details>


### [7] [SegSLR: Promptable Video Segmentation for Isolated Sign Language Recognition](https://arxiv.org/abs/2509.10710)
*Sven Schreiber,Noha Sarhan,Simone Frintrop,Christian Wilms*

Main category: cs.CV

TL;DR: SegSLR通过结合RGB和姿态信息，利用可提示的零样本视频分割来改进孤立手语识别，解决了现有方法丢失细节的问题，并在ChaLearn20249 IsoGD数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有孤立手语识别（ISLR）方法主要依赖RGB数据或 the signer pose 信息，但结合这些模态时，由于边界框等不精确的表示，常常会丢失手部形状和方向等关键细节。因此，需要一种新的方法来更有效地结合这两种信息。

Method: 提出SegSLR系统，结合RGB和姿态信息，通过可提示的零样本视频分割来实现。首先，利用姿态信息获得手部和 the signer 身体的粗略位置，然后通过视频分割来分割这些部位，以保留所有相关的手部形状信息。最后，将分割后的区域用于 the RGB 数据的处理，从而将 the RGB 和姿态信息有效地结合起来。

Result: 在复杂的ChaLearn20249 IsoGD数据集上，SegSLR的性能优于现有的最先进的方法。消融研究表明，SegSLR在关注 the signer 的身体和手部信息方面受益匪浅，证明了该设计方法的有效性。

Conclusion: SegSLR通过将可提示的零样本视频分割应用于 the RGB 和姿态信息，有效地解决了现有ISLR方法在结合多模态信息时丢失关键细节的问题，并在标准数据集上取得了领先的性能。

Abstract: Isolated Sign Language Recognition (ISLR) approaches primarily rely on RGB
data or signer pose information. However, combining these modalities often
results in the loss of crucial details, such as hand shape and orientation, due
to imprecise representations like bounding boxes. Therefore, we propose the
ISLR system SegSLR, which combines RGB and pose information through promptable
zero-shot video segmentation. Given the rough localization of the hands and the
signer's body from pose information, we segment the respective parts through
the video to maintain all relevant shape information. Subsequently, the
segmentations focus the processing of the RGB data on the most relevant body
parts for ISLR. This effectively combines RGB and pose information. Our
evaluation on the complex ChaLearn249 IsoGD dataset shows that SegSLR
outperforms state-of-the-art methods. Furthermore, ablation studies indicate
that SegSLR strongly benefits from focusing on the signer's body and hands,
justifying our design choices.

</details>


### [8] [SCOPE: Speech-guided COllaborative PErception Framework for Surgical Scene Segmentation](https://arxiv.org/abs/2509.10748)
*Jecia Z. Y. Mao,Francis X Creighton,Russell H Taylor,Manish Sahu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SCOPE的框架，它结合了大语言模型（LLM）和视觉基础模型（VFM）的能力，用于在手术过程中实时分割、标记和跟踪手术器械和解剖结构，实现了免提、以医生为中心的手术辅助。其关键在于一个协作感知代理，能够根据医生的语音反馈来指导分割过程，并利用分割出的器械作为交互式指针来标记其他场景元素。


<details>
  <summary>Details</summary>
Motivation: 现有手术场景分割和跟踪方法依赖于特定领域、有监督的模型，需要大量标注数据，并且难以适应新的手术场景和预定义标签之外的类别。而基于提示的视觉基础模型虽然能进行开放集零样本分割，但依赖手动提示，不适用于手术环境。

Method: 提出SCOPE框架，整合LLM的推理能力和开放集VFM的感知能力。核心是协作感知代理，它生成VFM分割的候选结果，并结合医生的语音反馈来指导分割，实现人机协同。分割出的器械可作为交互式指针，用于标记其他场景元素。

Result: 在Cataract1k数据集和鼻内镜下颅底手术数据集上进行了评估，证明了其能够实时生成手术场景的分割和跟踪。通过模拟实验展示了其动态能力。

Conclusion: SCOPE框架通过人机协同，为动态手术室环境提供了适应性强、免提、以医生为中心的手术工具的潜力。

Abstract: Accurate segmentation and tracking of relevant elements of the surgical scene
is crucial to enable context-aware intraoperative assistance and decision
making. Current solutions remain tethered to domain-specific, supervised models
that rely on labeled data and required domain-specific data to adapt to new
surgical scenarios and beyond predefined label categories. Recent advances in
prompt-driven vision foundation models (VFM) have enabled open-set, zero-shot
segmentation across heterogeneous medical images. However, dependence of these
models on manual visual or textual cues restricts their deployment in
introperative surgical settings. We introduce a speech-guided collaborative
perception (SCOPE) framework that integrates reasoning capabilities of large
language model (LLM) with perception capabilities of open-set VFMs to support
on-the-fly segmentation, labeling and tracking of surgical instruments and
anatomy in intraoperative video streams. A key component of this framework is a
collaborative perception agent, which generates top candidates of VFM-generated
segmentation and incorporates intuitive speech feedback from clinicians to
guide the segmentation of surgical instruments in a natural human-machine
collaboration paradigm. Afterwards, instruments themselves serve as interactive
pointers to label additional elements of the surgical scene. We evaluated our
proposed framework on a subset of publicly available Cataract1k dataset and an
in-house ex-vivo skull-base dataset to demonstrate its potential to generate
on-the-fly segmentation and tracking of surgical scene. Furthermore, we
demonstrate its dynamic capabilities through a live mock ex-vivo experiment.
This human-AI collaboration paradigm showcase the potential of developing
adaptable, hands-free, surgeon-centric tools for dynamic operating-room
environments.

</details>


### [9] [On the Skinning of Gaussian Avatars](https://arxiv.org/abs/2509.11411)
*Nikolaos Zioulis,Nikolaos Kotarelas,Georgios Albanis,Spyridon Thermos,Anargyros Chatzitofis*

Main category: cs.CV

TL;DR: 基于高斯泼溅的方法在处理人类化身动画时，虽然提高了训练和渲染速度，但在高斯旋转的非线性属性方面存在挑战。本研究提出了一种加权旋转混合方法，利用四元数平均来解决这些伪影，从而实现更简单、更高效的化身动画。


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯泼溅的人类化身动画方法在处理高斯旋转的非线性属性时会产生伪影，需要复杂的修正方法。

Method: 提出了一种加权旋转混合方法，利用四元数平均来处理高斯旋转的非线性属性，并对线性混合蒙皮技术进行修改。

Result: 实现了更简单、更高效的顶点基础高斯动画，并且可以轻松集成到任何引擎中。

Conclusion: 本研究提出的加权旋转混合方法有效解决了高斯泼溅在人类化身动画中的非线性旋转伪影问题，简化了动画流程，提高了效率。

Abstract: Radiance field-based methods have recently been used to reconstruct human
avatars, showing that we can significantly downscale the systems needed for
creating animated human avatars. Although this progress has been initiated by
neural radiance fields, their slow rendering and backward mapping from the
observation space to the canonical space have been the main challenges. With
Gaussian splatting overcoming both challenges, a new family of approaches has
emerged that are faster to train and render, while also straightforward to
implement using forward skinning from the canonical to the observation space.
However, the linear blend skinning required for the deformation of the
Gaussians does not provide valid results for their non-linear rotation
properties. To address such artifacts, recent works use mesh properties to
rotate the non-linear Gaussian properties or train models to predict corrective
offsets. Instead, we propose a weighted rotation blending approach that
leverages quaternion averaging. This leads to simpler vertex-based Gaussians
that can be efficiently animated and integrated in any engine by only modifying
the linear blend skinning technique, and using any Gaussian rasterizer.

</details>


### [10] [Every Camera Effect, Every Time, All at Once: 4D Gaussian Ray Tracing for Physics-based Camera Effect Data Generation](https://arxiv.org/abs/2509.10759)
*Yi-Ruei Liu,You-Zhe Xie,Yu-Hsiang Hsu,I-Sheng Fang,Yu-Lun Liu,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: 提出4D高斯射线追踪（4D-GRT）新方法，结合4D高斯溅射和基于物理的射线追踪，用于模拟相机成像缺陷（如鱼眼畸变和滚动快门），并构建了包含四种相机效应的合成数据集作为评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉系统在处理真实世界相机成像缺陷（如鱼眼畸变和滚动快门）时表现不佳，而现有的数据生成方法成本高、存在模拟到真实（sim-to-real）的差距或无法准确模拟相机效应。

Method: 4D高斯射线追踪（4D-GRT）：一个两阶段流程，首先重建动态场景，然后应用射线追踪来生成具有可控、物理上准确的相机效应的视频。

Result: 4D-GRT实现了最快的渲染速度，并且在渲染质量方面优于或媲美现有基线方法。此外，构建了八个包含四种相机效应的室内合成动态场景数据集。

Conclusion: 4D-GRT能有效地模拟相机成像缺陷，解决了现有方法的局限性，并在速度和质量上取得了良好表现，同时提供了一个有用的评估基准。

Abstract: Common computer vision systems typically assume ideal pinhole cameras but
fail when facing real-world camera effects such as fisheye distortion and
rolling shutter, mainly due to the lack of learning from training data with
camera effects. Existing data generation approaches suffer from either high
costs, sim-to-real gaps or fail to accurately model camera effects. To address
this bottleneck, we propose 4D Gaussian Ray Tracing (4D-GRT), a novel two-stage
pipeline that combines 4D Gaussian Splatting with physically-based ray tracing
for camera effect simulation. Given multi-view videos, 4D-GRT first
reconstructs dynamic scenes, then applies ray tracing to generate videos with
controllable, physically accurate camera effects. 4D-GRT achieves the fastest
rendering speed while performing better or comparable rendering quality
compared to existing baselines. Additionally, we construct eight synthetic
dynamic scenes in indoor environments across four camera effects as a benchmark
to evaluate generated videos with camera effects.

</details>


### [11] [HoloGarment: 360° Novel View Synthesis of In-the-Wild Garments](https://arxiv.org/abs/2509.12187)
*Johanna Karras,Yingwei Li,Yasamin Jafarian,Ira Kemelmacher-Shlizerman*

Main category: cs.CV

TL;DR: HoloGarment是一个新颖的隐式训练范例，利用真实视频数据和合成3D数据来优化共享服装嵌入空间，从而实现野外服装的360度新视图合成。


<details>
  <summary>Details</summary>
Motivation: 野外服装的新视图合成因遮挡、复杂姿势和变形而面临挑战，而现有方法在合成数据上效果不佳，泛化能力差。

Method: HoloGarment采用一种结合大规模真实视频数据和少量合成3D数据的隐式训练范例，优化共享服装嵌入空间。在推理时，通过微调特定真实视频的服装嵌入来构建服装“图谱”表示，实现动态视频到360度新视图合成。

Result: HoloGarment在野外服装的新视图合成方面取得了最先进的性能，能够处理褶皱、姿势变化和遮挡等挑战，同时保持照片般逼真、视图一致性、精细纹理细节和准确的几何形状。

Conclusion: HoloGarment通过其新颖的隐式训练范式和服装图谱表示，能够有效地解决野外服装新视图合成的挑战，在处理真实世界伪影的同时保持高质量的视觉效果。

Abstract: Novel view synthesis (NVS) of in-the-wild garments is a challenging task due
significant occlusions, complex human poses, and cloth deformations. Prior
methods rely on synthetic 3D training data consisting of mostly unoccluded and
static objects, leading to poor generalization on real-world clothing. In this
paper, we propose HoloGarment (Hologram-Garment), a method that takes 1-3
images or a continuous video of a person wearing a garment and generates
360{\deg} novel views of the garment in a canonical pose. Our key insight is to
bridge the domain gap between real and synthetic data with a novel implicit
training paradigm leveraging a combination of large-scale real video data and
small-scale synthetic 3D data to optimize a shared garment embedding space.
During inference, the shared embedding space further enables dynamic
video-to-360{\deg} NVS through the construction of a garment "atlas"
representation by finetuning a garment embedding on a specific real-world
video. The atlas captures garment-specific geometry and texture across all
viewpoints, independent of body pose or motion. Extensive experiments show that
HoloGarment achieves state-of-the-art performance on NVS of in-the-wild
garments from images and videos. Notably, our method robustly handles
challenging real-world artifacts -- such as wrinkling, pose variation, and
occlusion -- while maintaining photorealism, view consistency, fine texture
details, and accurate geometry. Visit our project page for additional results:
https://johannakarras.github.io/HoloGarment

</details>


### [12] [EditDuet: A Multi-Agent System for Video Non-Linear Editing](https://arxiv.org/abs/2509.10761)
*Marcelo Sandoval-Castaneda,Bryan Russell,Josef Sivic,Gregory Shakhnarovich,Fabian Caba Heilbron*

Main category: cs.CV

TL;DR: 我们提出了一个多智能体方法来自动编辑视频，由一个编辑器智能体和一个评论家智能体组成，该方法将视频编辑视为一个序贯决策过程。


<details>
  <summary>Details</summary>
Motivation: 之前的视频编辑工作主要集中在检索或用户界面，而将实际编辑留给用户。我们提出自动化核心的视频编辑任务。

Method: 我们设计了一个编辑器智能体和一个评论家智能体。编辑器接收视频片段和自然语言指令，并使用视频编辑软件的工具来制作编辑后的序列。评论家根据生成的序列提供自然语言反馈或在满意时进行渲染。我们引入了一种基于学习的方法来实现专业智能体之间的有效通信。

Result: 我们提出的系统在覆盖率、时间约束满足度和用户偏好方面大大优于现有方法。

Conclusion: 我们的多智能体方法能够有效地自动进行视频编辑，并且在用户研究中表现优于现有技术。我们还探索了一种基于 LLM 的评估指标来衡量视频编辑系统的质量。

Abstract: Automated tools for video editing and assembly have applications ranging from
filmmaking and advertisement to content creation for social media. Previous
video editing work has mainly focused on either retrieval or user interfaces,
leaving actual editing to the user. In contrast, we propose to automate the
core task of video editing, formulating it as sequential decision making
process. Ours is a multi-agent approach. We design an Editor agent and a Critic
agent. The Editor takes as input a collection of video clips together with
natural language instructions and uses tools commonly found in video editing
software to produce an edited sequence. On the other hand, the Critic gives
natural language feedback to the editor based on the produced sequence or
renders it if it is satisfactory. We introduce a learning-based approach for
enabling effective communication across specialized agents to address the
language-driven video editing task. Finally, we explore an LLM-as-a-judge
metric for evaluating the quality of video editing system and compare it with
general human preference. We evaluate our system's output video sequences
qualitatively and quantitatively through a user study and find that our system
vastly outperforms existing approaches in terms of coverage, time constraint
satisfaction, and human preference.

</details>


### [13] [Enhancement Without Contrast: Stability-Aware Multicenter Machine Learning for Glioma MRI Imaging](https://arxiv.org/abs/2509.10767)
*Sajad Amiri,Shahram Taeb,Sara Gharibi,Setareh Dehghanfard,Somayeh Sadat Mehrnia,Mehrdad Oveisi,Ilker Hacihaliloglu,Arman Rahmim,Mohammad R. Salmanpour*

Main category: cs.CV

TL;DR: 通过一种关注稳定性的框架，可以从非对比胶质瘤MRI中可靠地预测对比增强，从而减少对GBCAs的依赖并提高跨中心的通用性。


<details>
  <summary>Details</summary>
Motivation: 尽管基于钆的造影剂（GBCAs）在胶质瘤成像中很重要，但它们存在安全、成本和可及性问题。使用机器学习（ML）从非对比MRI预测增强可以提供一种更安全的选择，因为它反映了肿瘤的侵袭性并有助于治疗计划。然而，扫描仪和队列的变异性阻碍了模型选择的稳健性。

Method: 提出了一种关注稳定性的框架，用于识别多中心预测胶质瘤MRI对比增强的可重复ML流程。使用PyRadiomics和IBSI标准，从1,446个胶质瘤病例的四个TCIA数据集中提取了108个特征，并结合了48种降维方法和25种分类器，生成了1,200种流程。进行了旋转验证，其中在一个数据集上训练，在另一个数据集上测试。

Result: 在三份数据集上进行的交叉验证预测精度在0.91到0.96之间，在第四份数据集上的外部测试精度分别为0.87（UCSF-PDGM）、0.98（UPENN-GB）和0.95（BRATS-Africa），平均为0.93。F1分数、精确率和召回率稳定（0.87至0.96），而ROC-AUC变化较大（0.50至0.82），反映了队列的异质性。MI与ETr流程的组合排名最高，在准确性和稳定性之间取得了平衡。

Conclusion: 所提出的关注稳定性的模型选择框架能够可靠地预测非对比胶质瘤MRI的对比增强，从而减少对GBCAs的依赖，并提高模型在不同中心的泛化能力。该框架为神经肿瘤学及其他领域可重复的ML应用提供了一个可扩展的模板。

Abstract: Gadolinium-based contrast agents (GBCAs) are central to glioma imaging but
raise safety, cost, and accessibility concerns. Predicting contrast enhancement
from non-contrast MRI using machine learning (ML) offers a safer alternative,
as enhancement reflects tumor aggressiveness and informs treatment planning.
Yet scanner and cohort variability hinder robust model selection. We propose a
stability-aware framework to identify reproducible ML pipelines for multicenter
prediction of glioma MRI contrast enhancement. We analyzed 1,446 glioma cases
from four TCIA datasets (UCSF-PDGM, UPENN-GB, BRATS-Africa, BRATS-TCGA-LGG).
Non-contrast T1WI served as input, with enhancement derived from paired
post-contrast T1WI. Using PyRadiomics under IBSI standards, 108 features were
extracted and combined with 48 dimensionality reduction methods and 25
classifiers, yielding 1,200 pipelines. Rotational validation was trained on
three datasets and tested on the fourth. Cross-validation prediction accuracies
ranged from 0.91 to 0.96, with external testing achieving 0.87 (UCSF-PDGM),
0.98 (UPENN-GB), and 0.95 (BRATS-Africa), with an average of 0.93. F1,
precision, and recall were stable (0.87 to 0.96), while ROC-AUC varied more
widely (0.50 to 0.82), reflecting cohort heterogeneity. The MI linked with ETr
pipeline consistently ranked highest, balancing accuracy and stability. This
framework demonstrates that stability-aware model selection enables reliable
prediction of contrast enhancement from non-contrast glioma MRI, reducing
reliance on GBCAs and improving generalizability across centers. It provides a
scalable template for reproducible ML in neuro-oncology and beyond.

</details>


### [14] [Group Evidence Matters: Tiling-based Semantic Gating for Dense Object Detection](https://arxiv.org/abs/2509.10779)
*Yilun Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种检测器无关的后处理框架，通过将重叠产生的冗余转化为分组证据来提高无人机图像中小而密集的物体的检测召回率，但会牺牲部分精确率。


<details>
  <summary>Details</summary>
Motivation: 无人机图像中的密集小目标由于长距离观测、遮挡和杂乱等原因经常被漏检。

Method: 该框架首先通过重叠切片恢复低置信度候选目标，然后利用空间门（基于框质心的DBSCAN）和语义门（基于ResNet-18嵌入的DBSCAN）来验证分组证据。经验证的组会进行置信度重加权，然后进行类别感知NMS融合。

Result: 在VisDrone数据集上，召回率从0.685提升到0.778（+0.093），精确率从0.801下降到0.595，F1得分为0.669。后处理平均延迟为0.095秒/图像。

Conclusion: 该框架能够提高召回率，牺牲部分精确率，特别适用于远距离计数和监控等对召回率敏感的应用。消融实验证实了切片、空间聚类、语义聚类和重加权各自的作用。该框架无需重新训练，可与现有检测器集成。未来的工作将集中于降低语义门的计算成本并引入时间信息。

Abstract: Dense small objects in UAV imagery are often missed due to long-range
viewpoints, occlusion, and clutter[cite: 5]. This paper presents a
detector-agnostic post-processing framework that converts overlap-induced
redundancy into group evidence[cite: 6]. Overlapping tiling first recovers
low-confidence candidates[cite: 7]. A Spatial Gate (DBSCAN on box centroids)
and a Semantic Gate (DBSCAN on ResNet-18 embeddings) then validates group
evidence[cite: 7]. Validated groups receive controlled confidence reweighting
before class-aware NMS fusion[cite: 8]. Experiments on VisDrone show a recall
increase from 0.685 to 0.778 (+0.093) and a precision adjustment from 0.801 to
0.595, yielding F1=0.669[cite: 9]. Post-processing latency averages 0.095 s per
image[cite: 10]. These results indicate recall-first, precision-trade-off
behavior that benefits recall-sensitive applications such as far-field counting
and monitoring[cite: 10]. Ablation confirms that tiling exposes missed objects,
spatial clustering stabilizes geometry, semantic clustering enforces appearance
coherence, and reweighting provides calibrated integration with the
baseline[cite: 11]. The framework requires no retraining and integrates with
modern detectors[cite: 12]. Future work will reduce semantic gating cost and
extend the approach with temporal cues[cite: 13].

</details>


### [15] [InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts](https://arxiv.org/abs/2509.10813)
*Weipeng Zhong,Peizhou Cao,Yichen Jin,Li Luo,Wenzhe Cai,Jingli Lin,Hanqing Wang,Zhaoyang Lyu,Tai Wang,Bo Dai,Xudong Xu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: InternScenes是一个包含约40000个多样化场景的大规模可模拟室内场景数据集，通过整合真实扫描、程序化生成和设计师创建的场景，解决了现有数据集在规模、多样性、布局真实性和物体碰撞方面存在的问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在规模、多样性、布局真实性（缺少小物品）和物体碰撞方面存在局限性，阻碍了Embodied AI的发展。

Method: 通过整合真实世界扫描、程序化生成场景和设计师创建的场景，创建了一个包含196万个3D对象和15种常见场景类型的大规模数据集。通过创建真实到模拟的复制品、加入交互式对象和进行物理模拟来确保可模拟性、交互性和解决物体碰撞问题。

Result: InternScenes包含约40000个多样化场景，196万个3D对象，涵盖15种常见场景类型和288个对象类别，平均每个区域有41.5个对象，解决了物体碰撞问题，并展示了在场景布局生成和点目标导航方面的应用价值。

Conclusion: InternScenes为Embodied AI研究提供了一个大规模、多样化且可模拟的数据集，解决了现有数据集的局限性，并为场景布局生成和点目标导航等任务的模型训练提供了新的机遇，有望推动Embodied AI的发展。

Abstract: The advancement of Embodied AI heavily relies on large-scale, simulatable 3D
scene datasets characterized by scene diversity and realistic layouts. However,
existing datasets typically suffer from limitations in data scale or diversity,
sanitized layouts lacking small items, and severe object collisions. To address
these shortcomings, we introduce \textbf{InternScenes}, a novel large-scale
simulatable indoor scene dataset comprising approximately 40,000 diverse scenes
by integrating three disparate scene sources, real-world scans, procedurally
generated scenes, and designer-created scenes, including 1.96M 3D objects and
covering 15 common scene types and 288 object classes. We particularly preserve
massive small items in the scenes, resulting in realistic and complex layouts
with an average of 41.5 objects per region. Our comprehensive data processing
pipeline ensures simulatability by creating real-to-sim replicas for real-world
scans, enhances interactivity by incorporating interactive objects into these
scenes, and resolves object collisions by physical simulations. We demonstrate
the value of InternScenes with two benchmark applications: scene layout
generation and point-goal navigation. Both show the new challenges posed by the
complex and realistic layouts. More importantly, InternScenes paves the way for
scaling up the model training for both tasks, making the generation and
navigation in such complex scenes possible. We commit to open-sourcing the
data, models, and benchmarks to benefit the whole community.

</details>


### [16] [Well-Conditioned Polynomial Representations for Mathematical Handwriting Recognition](https://arxiv.org/abs/2509.10815)
*Robert M. Corless,Deepak Singh Kalhan,Stephen M. Watt*

Main category: cs.CV

TL;DR: 该研究探讨了在数学手写识别中使用不同数学基（如勒让德、切比雪夫）和不同多项式次数对模型准确性和计算成本的影响。


<details>
  <summary>Details</summary>
Motivation: 为了在数学手写识别中找到一种既准确又计算成本低廉的表示方法，探索不同的数学基和多项式次数的权衡。

Method: 通过分析不同基下多项式求值的条件数，并给出符号间变异范数的界限。

Result: 初步结果表明，勒让德和勒让德-索伯夫基在表示数学手写体方面有优势，并初步探索了切比雪夫基的潜力。

Conclusion: 基的选择和多项式次数的组合对模型的准确性和计算效率有显著影响，需要仔细权衡。

Abstract: Previous work has made use of a parameterized plane curve polynomial
representation for mathematical handwriting, with the polynomials represented
in a Legendre or Legendre-Sobolev graded basis. This provides a compact
geometric representation for the digital ink. Preliminary results have also
been shown for Chebyshev and Chebyshev-Sobolev bases. This article explores the
trade-offs between basis choice and polynomial degree to achieve accurate
modeling with a low computational cost. To do this, we consider the condition
number for polynomial evaluation in these bases and bound how the various inner
products give norms for the variations between symbols.

</details>


### [17] [Multi-Task Diffusion Approach For Prediction of Glioma Tumor Progression](https://arxiv.org/abs/2509.10824)
*Aghiles Kebaili,Romain Modzelewski,Jérôme Lapuyade-Lahorgue,Maxime Fontanilles,Sébastien Thureau,Su Ruan*

Main category: cs.CV

TL;DR: 该研究提出了一个多任务扩散框架，用于预测胶质瘤的进展，即使在数据稀疏和不规则的情况下也能生成未来的MRI图像和肿瘤演变概率图。


<details>
  <summary>Details</summary>
Motivation: 临床上胶质瘤的纵向MRI数据稀疏且采集不规律，导致数据不平衡，难以进行可靠的预测模型。现有的方法难以准确预测胶质瘤的演变。

Method: 提出一个多任务扩散框架，能够预测任意时间点的未来FLAIR序列，并估计肿瘤演变的概率图（使用SDF）。通过集成一个预训练的形变模块来捕捉肿瘤演变的时间动态。通过数据增强和多模态填补来解决数据稀疏问题。引入一个考虑放疗剂量的焦点损失函数。

Result: 在公共数据集和内部私有数据集上均取得了有前景的结果，能够基于较少的扫描数据生成灵活的、依赖时间的概率图，用于评估肿瘤进展风险。

Conclusion: 所提出的多任务扩散框架能够有效处理稀疏和不规则的临床数据，为胶质瘤的进展预测提供了新的解决方案，有助于临床决策。

Abstract: Glioma, an aggressive brain malignancy characterized by rapid progression and
its poor prognosis, poses significant challenges for accurate evolution
prediction. These challenges are exacerbated by sparse, irregularly acquired
longitudinal MRI data in clinical practice, where incomplete follow-up
sequences create data imbalances and make reliable modeling difficult. In this
paper, we present a multitask diffusion framework for time-agnostic, pixel-wise
prediction of glioma progression. The model simultaneously generates future
FLAIR sequences at any chosen time point and estimates spatial probabilistic
tumor evolution maps derived using signed distance fields (SDFs), allowing
uncertainty quantification. To capture temporal dynamics of tumor evolution
across arbitrary intervals, we integrate a pretrained deformation module that
models inter-scan changes using deformation fields. Regarding the common
clinical limitation of data scarcity, we implement a targeted augmentation
pipeline that synthesizes complete sequences of three follow-up scans and
imputes missing MRI modalities from available patient studies, improving the
stability and accuracy of predictive models. Based on merely two follow-up
scans at earlier timepoints, our framework produces flexible time-depending
probability maps, enabling clinicians to interrogate tumor progression risks at
any future temporal milestone. We further introduce a radiotherapy-weighted
focal loss term that leverages radiation dose maps, as these highlight regions
of greater clinical importance during model training. The proposed method was
trained on a public dataset and evaluated on an internal private dataset,
achieving promising results in both cases

</details>


### [18] [Point-Plane Projections for Accurate LiDAR Semantic Segmentation in Small Data Scenarios](https://arxiv.org/abs/2509.10841)
*Simone Mosco,Daniel Fusaro,Wanmeng Li,Emanuele Menegatti,Alberto Pretto*

Main category: cs.CV

TL;DR: 通过点-平面投影学习2D表示特征，并结合几何感知数据增强技术，在数据稀疏场景下提升了LiDAR点云的语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR点云语义分割方法计算复杂度高，需要大量训练数据，在数据稀疏场景下泛化能力有限。

Method: 提出点-平面投影方法，从2D表示中学习特征，提取互补信息，并引入几何感知数据增强技术以缓解类别不平衡。

Result: 在数据稀疏场景下显著提升了性能，并在SemanticKITTI和PandaSet两个标准数据集上取得了有竞争力的结果。

Conclusion: 点-平面投影和几何感知数据增强技术能够有效提升LiDAR点云语义分割在数据稀疏场景下的性能。

Abstract: LiDAR point cloud semantic segmentation is essential for interpreting 3D
environments in applications such as autonomous driving and robotics. Recent
methods achieve strong performance by exploiting different point cloud
representations or incorporating data from other sensors, such as cameras or
external datasets. However, these approaches often suffer from high
computational complexity and require large amounts of training data, limiting
their generalization in data-scarce scenarios. In this paper, we improve the
performance of point-based methods by effectively learning features from 2D
representations through point-plane projections, enabling the extraction of
complementary information while relying solely on LiDAR data. Additionally, we
introduce a geometry-aware technique for data augmentation that aligns with
LiDAR sensor properties and mitigates class imbalance. We implemented and
evaluated our method that applies point-plane projections onto multiple
informative 2D representations of the point cloud. Experiments demonstrate that
this approach leads to significant improvements in limited-data scenarios,
while also achieving competitive results on two publicly available standard
datasets, as SemanticKITTI and PandaSet. The code of our method is available at
https://github.com/SiMoM0/3PNet

</details>


### [19] [OpenUrban3D: Annotation-Free Open-Vocabulary Semantic Segmentation of Large-Scale Urban Point Clouds](https://arxiv.org/abs/2509.10842)
*Chongyu Wang,Kunlei Jing,Jihua Zhu,Di Wang*

Main category: cs.CV

TL;DR: OpenUrban3D是一个针对大规模城市点云的3D开放词汇语义分割框架，无需多视图图像、预训练模型或手动注释，即可实现对任意文本查询的零样本分割。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇语义分割方法在处理大规模城市点云时面临挑战，主要包括多视图图像的缺失和现有3D分割方法在多样化城市环境中的泛化能力不足。本研究旨在解决这些问题，以支持数字孪生、智慧城市管理和城市分析等应用。

Method: OpenUrban3D通过多视图、多粒度渲染、掩码级视觉-语言特征提取和样本平衡融合，直接从原始点云生成鲁棒的语义特征，然后将其蒸馏到一个3D骨干模型中，从而实现无需多视图图像、预训练模型或手动注释的零样本分割。

Result: 在SensatUrban和SUM等大规模城市基准测试中，OpenUrban3D在分割准确性和跨场景泛化能力方面均取得了显著的改进，优于现有方法。

Conclusion: OpenUrban3D是首个用于大规模城市场景的3D开放词汇语义分割框架，它能够直接从原始点云生成语义特征，实现了对任意文本查询的零样本分割，并展现了在3D城市场景理解方面的灵活性和可扩展性。

Abstract: Open-vocabulary semantic segmentation enables models to recognize and segment
objects from arbitrary natural language descriptions, offering the flexibility
to handle novel, fine-grained, or functionally defined categories beyond fixed
label sets. While this capability is crucial for large-scale urban point clouds
that support applications such as digital twins, smart city management, and
urban analytics, it remains largely unexplored in this domain. The main
obstacles are the frequent absence of high-quality, well-aligned multi-view
imagery in large-scale urban point cloud datasets and the poor generalization
of existing three-dimensional (3D) segmentation pipelines across diverse urban
environments with substantial variation in geometry, scale, and appearance. To
address these challenges, we present OpenUrban3D, the first 3D open-vocabulary
semantic segmentation framework for large-scale urban scenes that operates
without aligned multi-view images, pre-trained point cloud segmentation
networks, or manual annotations. Our approach generates robust semantic
features directly from raw point clouds through multi-view, multi-granularity
rendering, mask-level vision-language feature extraction, and sample-balanced
fusion, followed by distillation into a 3D backbone model. This design enables
zero-shot segmentation for arbitrary text queries while capturing both semantic
richness and geometric priors. Extensive experiments on large-scale urban
benchmarks, including SensatUrban and SUM, show that OpenUrban3D achieves
significant improvements in both segmentation accuracy and cross-scene
generalization over existing methods, demonstrating its potential as a flexible
and scalable solution for 3D urban scene understanding.

</details>


### [20] [AutoOEP -- A Multi-modal Framework for Online Exam Proctoring](https://arxiv.org/abs/2509.10887)
*Aryan Kashyap Naveen,Bhuvanesh Singla,Raajan Wankhade,Shreesha M,Ramu S,Ram Mohana Reddy Guddeti*

Main category: cs.CV

TL;DR: AutoOEP是一个利用计算机视觉和机器学习进行在线考试监考的框架，通过双摄像头和多模态分析来检测作弊行为，并在自定义数据集上实现了90.7%的准确率。


<details>
  <summary>Details</summary>
Motivation: 在线教育发展需要可扩展的远程监考系统，以确保学术诚信，传统人工监考和现有自动化方案存在不足。

Method: AutoOEP使用双摄像头捕捉考生正面和工作区侧面视图，集成面部识别、头部姿态、注视点和口部运动分析（面部模块），并使用YOLOv11检测违禁品和追踪手部与违禁品接近度（手部模块）。最后，利用LSTM网络分析时间模式以计算实时作弊概率得分。

Result: 在自定义数据集上，AutoOEP实现了90.7%的作弊行为分类准确率，物体检测的mAP@.5为0.57，且无需GPU即可在每秒2.4帧的速度下处理视频流。

Conclusion: AutoOEP是一种有效且资源高效的自动化监考解决方案，能够显著减少人工干预，提高在线评估的完整性。

Abstract: The burgeoning of online education has created an urgent need for robust and
scalable systems to ensure academic integrity during remote examinations.
Traditional human proctoring is often not feasible at scale, while existing
automated solutions can be intrusive or fail to detect a wide range of cheating
behaviors. This paper introduces AutoOEP (Automated Online Exam Proctoring), a
comprehensive, multi-modal framework that leverages computer vision and machine
learning to provide effective, automated proctoring. The system utilizes a
dual-camera setup to capture both a frontal view of the examinee and a side
view of the workspace, minimizing blind spots. Our approach integrates several
parallel analyses: the Face Module performs continuous identity verification
using ArcFace, along with head pose estimation, gaze tracking, and mouth
movement analysis to detect suspicious cues. Concurrently, the Hand Module
employs a fine-tuned YOLOv11 model for detecting prohibited items (e.g., mobile
phones, notes) and tracks hand proximity to these objects. Features from these
modules are aggregated and fed into a Long Short-Term Memory (LSTM) network
that analyzes temporal patterns to calculate a real-time cheating probability
score. We evaluate AutoOEP on a custom-collected dataset simulating diverse
exam conditions. Our system achieves an accuracy of 90.7% in classifying
suspicious activities. The object detection component obtains a mean Average
Precision (mAP@.5) of 0.57 for prohibited items, and the entire framework
processes video streams at approximately 2.4 frames per second without a GPU.
The results demonstrate that AutoOEP is an effective and resource-efficient
solution for automated proctoring, significantly reducing the need for human
intervention and enhancing the integrity of online assessments.

</details>


### [21] [Total Variation Subgradient Guided Image Fusion for Dual-Camera CASSI System](https://arxiv.org/abs/2509.10897)
*Weiqiang Zhao,Tianzhu Liu,Yuzhe Gui,Yanfeng Gu*

Main category: cs.CV

TL;DR: 提出的双相机CASSI重建框架通过集成全变分（TV）子梯度理论，解决了光谱、空间和时间分辨率的权衡问题，提高了重建性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在光谱成像中面临分辨率权衡的挑战，现有方法在性能和可解释性方面存在局限性。

Method: 提出了一种双相机CASSI重建框架，集成了全变分（TV）子梯度理论，建立了端到端的SD-CASSI数学模型，并引入了动态正则化策略和自适应参考生成与更新机制。

Result: 实验结果表明，该方法有效保持了空间-光谱结构一致性，在各种重建场景下表现稳健。

Conclusion: 该理论框架为计算光谱成像提供了可解释的数学基础，并展示了鲁棒的性能。

Abstract: Spectral imaging technology has long-faced fundamental challenges in
balancing spectral, spatial, and temporal resolutions. While compressive
sensing-based Coded Aperture Snapshot Spectral Imaging (CASSI) mitigates this
trade-off through optical encoding, high compression ratios result in ill-posed
reconstruction problems. Traditional model-based methods exhibit limited
performance due to reliance on handcrafted inherent image priors, while deep
learning approaches are constrained by their black-box nature, which
compromises physical interpretability. To address these limitations, we propose
a dual-camera CASSI reconstruction framework that integrates total variation
(TV) subgradient theory. By establishing an end-to-end SD-CASSI mathematical
model, we reduce the computational complexity of solving the inverse problem
and provide a mathematically well-founded framework for analyzing multi-camera
systems. A dynamic regularization strategy is introduced, incorporating
normalized gradient constraints from RGB/panchromatic-derived reference images,
which constructs a TV subgradient similarity function with strict convex
optimization guarantees. Leveraging spatial priors from auxiliary cameras, an
adaptive reference generation and updating mechanism is designed to provide
subgradient guidance. Experimental results demonstrate that the proposed method
effectively preserves spatial-spectral structural consistency. The theoretical
framework establishes an interpretable mathematical foundation for
computational spectral imaging, demonstrating robust performance across diverse
reconstruction scenarios. The source code is available at
https://github.com/bestwishes43/ADMM-TVDS.

</details>


### [22] [Lightweight Metadata-Aware Mixture-of-Experts Masked Autoencoder for Earth Observation](https://arxiv.org/abs/2509.10919)
*Mohanad Albughdadi*

Main category: cs.CV

TL;DR: 提出了一种参数量仅为2.5M的紧凑型地球观测模型MoE-MAE，通过稀疏专家路由和时空条件元数据感知预训练，在保证性能的同时降低了计算成本，提高了模型的可访问性和可复用性。


<details>
  <summary>Details</summary>
Motivation: 现有大规模地球观测模型计算成本高，限制了其可访问性和可复用性。本文旨在探索紧凑型架构，以实现更小、更通用的地球观测模型。

Method: 提出了一种包含2.5M参数的元数据感知专家混合掩码自编码器（MoE-MAE），该模型结合了稀疏专家路由和时空条件（包含地理/经纬度以及季节/日常周期编码）。模型在BigEarthNet-Landsat数据集上进行预训练，并使用线性探测评估其冻结编码器的嵌入。

Result: 尽管MoE-MAE模型规模小，但在EuroSAT-Landsat数据集上（无显式元数据）表现出与参数量大数百倍的模型相当的性能，表明元数据感知预训练提高了迁移学习和标签效率。

Conclusion: 紧凑型、元数据感知的MoE-MAE模型是迈向未来地球观测基础模型的有效且可扩展的步骤。

Abstract: Recent advances in Earth Observation have focused on large-scale foundation
models. However, these models are computationally expensive, limiting their
accessibility and reuse for downstream tasks. In this work, we investigate
compact architectures as a practical pathway toward smaller general-purpose EO
models. We propose a Metadata-aware Mixture-of-Experts Masked Autoencoder
(MoE-MAE) with only 2.5M parameters. The model combines sparse expert routing
with geo-temporal conditioning, incorporating imagery alongside
latitude/longitude and seasonal/daily cyclic encodings. We pretrain the MoE-MAE
on the BigEarthNet-Landsat dataset and evaluate embeddings from its frozen
encoder using linear probes. Despite its small size, the model competes with
much larger architectures, demonstrating that metadata-aware pretraining
improves transfer and label efficiency. To further assess generalization, we
evaluate on the EuroSAT-Landsat dataset, which lacks explicit metadata, and
still observe competitive performance compared to models with hundreds of
millions of parameters. These results suggest that compact, metadata-aware
MoE-MAEs are an efficient and scalable step toward future EO foundation models.

</details>


### [23] [Simulating Sinogram-Domain Motion and Correcting Image-Domain Artifacts Using Deep Learning in HR-pQCT Bone Imaging](https://arxiv.org/abs/2509.10961)
*Farhan Sadik,Christopher L. Newman,Stuart J. Warden,Rachel K. Surowiec*

Main category: cs.CV

TL;DR: 提出一种基于ESWGAN-GP的深度学习方法，用于校正HR-pQCT成像中的运动伪影，并在模拟和真实数据上均取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: HR-pQCT成像中的刚性运动伪影（如皮质骨条纹和小梁涂抹）阻碍了骨微结构的在体评估，目前缺乏有效的运动校正方法。

Method: 优化了一种基于正弦图的方法来模拟HR-pQCT图像中的运动伪影，创建了带伪影和真实图像的配对数据集，并提出了一种结合边缘增强、自注意力机制和梯度惩罚的ESWGAN-GP模型，以监督学习的方式进行运动校正，并使用VGG感知损失来重建微结构特征。

Result: ESWGAN-GP在模拟数据集上实现了26.78的信噪比（SNR）、0.81的结构相似性（SSIM）和0.76的视觉信息保真度（VIF）；在真实数据集上，SNR、SSIM和VIF分别提高到29.31、0.87和0.81。

Conclusion: 所提出的方法在模拟的运动伪影上表现良好，是实现HR-pQCT深度学习运动校正的重要一步，尽管模拟的运动可能无法完全捕捉真实世界运动伪影的复杂性。

Abstract: Rigid-motion artifacts, such as cortical bone streaking and trabecular
smearing, hinder in vivo assessment of bone microstructures in high-resolution
peripheral quantitative computed tomography (HR-pQCT). Despite various motion
grading techniques, no motion correction methods exist due to the lack of
standardized degradation models. We optimize a conventional sinogram-based
method to simulate motion artifacts in HR-pQCT images, creating paired datasets
of motion-corrupted images and their corresponding ground truth, which enables
seamless integration into supervised learning frameworks for motion correction.
As such, we propose an Edge-enhanced Self-attention Wasserstein Generative
Adversarial Network with Gradient Penalty (ESWGAN-GP) to address motion
artifacts in both simulated (source) and real-world (target) datasets. The
model incorporates edge-enhancing skip connections to preserve trabecular edges
and self-attention mechanisms to capture long-range dependencies, facilitating
motion correction. A visual geometry group (VGG)-based perceptual loss is used
to reconstruct fine micro-structural features. The ESWGAN-GP achieves a mean
signal-to-noise ratio (SNR) of 26.78, structural similarity index measure
(SSIM) of 0.81, and visual information fidelity (VIF) of 0.76 for the source
dataset, while showing improved performance on the target dataset with an SNR
of 29.31, SSIM of 0.87, and VIF of 0.81. The proposed methods address a
simplified representation of real-world motion that may not fully capture the
complexity of in vivo motion artifacts. Nevertheless, because motion artifacts
present one of the foremost challenges to more widespread adoption of this
modality, these methods represent an important initial step toward implementing
deep learning-based motion correction in HR-pQCT.

</details>


### [24] [Gaze Authentication: Factors Influencing Authentication Performance](https://arxiv.org/abs/2509.10969)
*Dillon Lohr,Michael J Proulx,Mehedi Hasan Raju,Oleg V Komogortsev*

Main category: cs.CV

TL;DR: 本研究探讨了影响基于注视的身份验证性能的关键因素，实验在包含8,849名受试者的大规模数据集上进行，使用了Meta Quest Pro硬件和72Hz的视频眼动追踪技术。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解哪些因素会影响先进的基于注视的身份验证系统的性能。

Method: 利用先进的神经网络架构，研究了眼动追踪信号质量、眼动追踪校准的各个方面以及对原始注视估计进行简单滤波对身份验证性能的影响。

Result: 研究发现，在眼动追踪校准中使用相同的目标深度、融合校准和非校准的注视数据以及提高眼动追踪信号质量都能提升身份验证性能。此外，一个简单的三样本移动平均滤波器在大多数情况下会略微降低身份验证性能。

Conclusion: 本研究明确了提高基于注视的身份验证性能的关键因素，为优化此类系统提供了实践指导。

Abstract: This paper examines the key factors that influence the performance of
state-of-the-art gaze-based authentication. Experiments were conducted on a
large-scale, in-house dataset comprising 8,849 subjects collected with Meta
Quest Pro equivalent hardware running a video oculography-driven gaze
estimation pipeline at 72Hz. The state-of-the-art neural network architecture
was employed to study the influence of the following factors on authentication
performance: eye tracking signal quality, various aspects of eye tracking
calibration, and simple filtering on estimated raw gaze. We found that using
the same calibration target depth for eye tracking calibration, fusing
calibrated and non-calibrated gaze, and improving eye tracking signal quality
all enhance authentication performance. We also found that a simple
three-sample moving average filter slightly reduces authentication performance
in general. While these findings hold true for the most part, some exceptions
were noted.

</details>


### [25] [TrueSkin: Towards Fair and Accurate Skin Tone Recognition and Generation](https://arxiv.org/abs/2509.10980)
*Haoming Lu*

Main category: cs.CV

TL;DR: TrueSkin数据集解决了现有模型在肤色识别和生成方面存在的偏见和准确性问题，通过提供一个包含7299张图像的、系统分类的数据集，并展示了基于此数据集训练的模型在准确性和肤色保真度方面的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMMs）和图像生成模型在准确识别和合成肤色方面存在挑战，缺乏全面的数据集和鲁棒的方法。

Method: 创建了一个包含7299张图像的TrueSkin数据集，涵盖了多样化的光照、角度和拍摄设置，并将图像系统地分为6类。使用TrueSkin数据集对现有的识别和生成方法进行了基准测试，并展示了在此数据集上训练或微调模型的效果。

Result: LMMs倾向于将中间肤色误分类为较浅的肤色；生成模型在根据提示（如发型或环境）生成指定肤色时存在偏差；在TrueSkin上训练的识别模型准确率提高了20%以上；使用TrueSkin微调的生成模型肤色保真度显著提高。

Conclusion: TrueSkin数据集不仅为评估现有模型提供了基准，还为提高肤色识别和生成任务的公平性和准确性提供了宝贵的训练资源，强调了构建全面数据集的重要性。

Abstract: Skin tone recognition and generation play important roles in model fairness,
healthcare, and generative AI, yet they remain challenging due to the lack of
comprehensive datasets and robust methodologies. Compared to other human image
analysis tasks, state-of-the-art large multimodal models (LMMs) and image
generation models struggle to recognize and synthesize skin tones accurately.
To address this, we introduce TrueSkin, a dataset with 7299 images
systematically categorized into 6 classes, collected under diverse lighting
conditions, camera angles, and capture settings. Using TrueSkin, we benchmark
existing recognition and generation approaches, revealing substantial biases:
LMMs tend to misclassify intermediate skin tones as lighter ones, whereas
generative models struggle to accurately produce specified skin tones when
influenced by inherent biases from unrelated attributes in the prompts, such as
hairstyle or environmental context. We further demonstrate that training a
recognition model on TrueSkin improves classification accuracy by more than
20\% compared to LMMs and conventional approaches, and fine-tuning with
TrueSkin significantly improves skin tone fidelity in image generation models.
Our findings highlight the need for comprehensive datasets like TrueSkin, which
not only serves as a benchmark for evaluating existing models but also provides
a valuable training resource to enhance fairness and accuracy in skin tone
recognition and generation tasks.

</details>


### [26] [Policy-Driven Transfer Learning in Resource-Limited Animal Monitoring](https://arxiv.org/abs/2509.10995)
*Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar*

Main category: cs.CV

TL;DR: 本研究提出了一种基于强化学习（RL）的迁移学习框架，利用上限置信界（UCB）算法自动选择最适合动物检测任务的预训练模型，以解决无人机（UAV）计算机视觉应用中标签数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 野生动物保护和畜牧业管理中，动物健康监测和种群管理日益依赖自动化检测和跟踪系统。无人机（UAV）结合计算机视觉技术为非侵入式动物监测提供了解决方案，但深度学习（DL）模型开发受限于标注数据不足。迁移学习虽是潜在解决方案，但预训练模型选择复杂，尤其对新手而言。

Method: 提出一种基于强化学习（RL）的迁移学习框架，使用上限置信界（UCB）算法来自动选择最适合动物检测任务的预训练模型。该框架系统地评估和排序候选模型。

Result: 所提出的框架在动物检测任务上实现了更高的检测率，并显著减少了计算时间，优于传统方法。

Conclusion: 本研究提出的RL-UCB框架能够有效解决无人机计算机视觉在动物监测中面临的数据不足和模型选择困难的问题，提高了检测效率和性能。

Abstract: Animal health monitoring and population management are critical aspects of
wildlife conservation and livestock management that increasingly rely on
automated detection and tracking systems. While Unmanned Aerial Vehicle (UAV)
based systems combined with computer vision offer promising solutions for
non-invasive animal monitoring across challenging terrains, limited
availability of labeled training data remains an obstacle in developing
effective deep learning (DL) models for these applications. Transfer learning
has emerged as a potential solution, allowing models trained on large datasets
to be adapted for resource-limited scenarios such as those with limited data.
However, the vast landscape of pre-trained neural network architectures makes
it challenging to select optimal models, particularly for researchers new to
the field. In this paper, we propose a reinforcement learning (RL)-based
transfer learning framework that employs an upper confidence bound (UCB)
algorithm to automatically select the most suitable pre-trained model for
animal detection tasks. Our approach systematically evaluates and ranks
candidate models based on their performance, streamlining the model selection
process. Experimental results demonstrate that our framework achieves a higher
detection rate while requiring significantly less computational time compared
to traditional methods.

</details>


### [27] [Improving Fungi Prototype Representations for Few-Shot Classification](https://arxiv.org/abs/2509.11020)
*Abdarahmane Traore,Éric Hervet,Andy Couturier*

Main category: cs.CV

TL;DR: FungiCLEF 2025比赛旨在通过改进的深度学习方法，解决真菌物种自动识别中的类别不平衡和少样本学习问题，并在比赛中取得了显著优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发能够准确识别真菌物种的工具，以支持真菌学家和公民科学家进行大规模生物多样性监测，特别关注处理数据不平衡和少样本学习的挑战，因为稀有和记录不充分的物种通常在标准训练集中缺失。

Method: 本研究提出了一种基于原型网络的鲁棒深度学习方法，通过增强原型表示来改进少样本真菌分类。

Result: 该方法在FungiCLEF 2025比赛的公共和私人排行榜上，Recall@5指标均显著超过基线模型30个百分点以上。

Conclusion: 该研究提出的原型网络方法在准确识别常见和稀有真菌物种方面显示出巨大潜力，有效解决了FungiCLEF 2025比赛中的关键挑战。

Abstract: The FungiCLEF 2025 competition addresses the challenge of automatic fungal
species recognition using realistic, field-collected observational data.
Accurate identification tools support both mycologists and citizen scientists,
greatly enhancing large-scale biodiversity monitoring. Effective recognition
systems in this context must handle highly imbalanced class distributions and
provide reliable performance even when very few training samples are available
for many species, especially rare and under-documented taxa that are often
missing from standard training sets. According to competition organizers, about
20\% of all verified fungi observations, representing nearly 20,000 instances,
are associated with these rarely recorded species. To tackle this challenge, we
propose a robust deep learning method based on prototypical networks, which
enhances prototype representations for few-shot fungal classification. Our
prototypical network approach exceeds the competition baseline by more than 30
percentage points in Recall@5 on both the public (PB) and private (PR)
leaderboards. This demonstrates strong potential for accurately identifying
both common and rare fungal species, supporting the main objectives of
FungiCLEF 2025.

</details>


### [28] [Cluster-Level Sparse Multi-Instance Learning for Whole-Slide Images](https://arxiv.org/abs/2509.11034)
*Yuedi Zhang,Zhixiang Xia,Guosheng Yin,Bin Liu*

Main category: cs.CV

TL;DR: csMIL通过聚类和稀疏化解决多实例学习中的冗余和噪声问题，在病理学分析中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIL方法在处理冗余实例和丢弃非信息实例方面存在不足，限制了鲁棒性和可解释性。

Method: 提出csMIL框架，结合全局-局部实例聚类、簇内注意力机制和簇级稀疏性诱导，实现对诊断相关簇的选择性保留和不相关簇的丢弃。

Result: csMIL在CAMELYON16和TCGA-NSCLC两个公共组织病理学基准测试中取得了最先进的性能，理论分析表明其样本复杂度优于现有方法。

Conclusion: csMIL框架通过引入聚类和稀疏化机制，有效解决了多实例学习中的挑战，提高了鲁棒性、可解释性和计算效率。

Abstract: Multi-Instance Learning (MIL) is pivotal for analyzing complex, weakly
labeled datasets, such as whole-slide images (WSIs) in computational pathology,
where bags comprise unordered collections of instances with sparse diagnostic
relevance. Traditional MIL approaches, including early statistical methods and
recent attention-based frameworks, struggle with instance redundancy and lack
explicit mechanisms for discarding non-informative instances, limiting their
robustness and interpretability. We propose Cluster-level Sparse MIL (csMIL), a
novel framework that integrates global-local instance clustering,
within-cluster attention, and cluster-level sparsity induction to address these
challenges. Our csMIL first performs global clustering across all bags to
establish $K$ cluster centers, followed by local clustering within each bag to
assign cluster labels. Attention scores are computed within each cluster, and
sparse regularization is applied to cluster weights, enabling the selective
retention of diagnostically relevant clusters while discarding irrelevant ones.
This approach enhances robustness to noisy instances, improves interpretability
by identifying critical regions, and reduces computational complexity.
Theoretical analysis demonstrates that csMIL requires $O(s log K)$ bags to
recover $s$ relevant clusters, aligning with compressed sensing principles.
Empirically, csMIL achieves state-of-the-art performance on two public
histopathology benchmarks (CAMELYON16, TCGA-NSCLC).

</details>


### [29] [Action Hints: Semantic Typicality and Context Uniqueness for Generalizable Skeleton-based Video Anomaly Detection](https://arxiv.org/abs/2509.11058)
*Canhui Tang,Sanping Zhou,Haoyue Shi,Le Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的零样本视频异常检测框架，通过学习骨骼数据的动作典型性和独特性，以解决现有方法泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 零样本视频异常检测（ZS-VAD）因数据隐私和新监控部署等实际问题而至关重要，现有方法在处理新场景下的不同正常和异常行为模式时泛化能力不足。

Method: 本研究提出的框架包含两个主要模块：1. 语言引导的语义典型性建模模块，将骨骼片段投影到动作语义空间，并利用大型语言模型（LLM）的知识来区分正常和异常行为。2. 测试时上下文独特性分析模块，用于分析骨骼片段的时空差异，并推导出适应场景的边界。

Result: 在没有目标域训练样本的情况下，该方法在上海科技大学、UBnormal、NWPU和UCF-Crime四个大规模VAD数据集上取得了最先进的成果，并在超过100个未见过的监控场景中进行了测试。

Conclusion: 本研究提出的框架通过利用骨骼数据的动作典型性和独特性学习，有效提升了零样本视频异常检测的性能，克服了现有方法的局限性。

Abstract: Zero-Shot Video Anomaly Detection (ZS-VAD) requires temporally localizing
anomalies without target domain training data, which is a crucial task due to
various practical concerns, e.g., data privacy or new surveillance deployments.
Skeleton-based approach has inherent generalizable advantages in achieving
ZS-VAD as it eliminates domain disparities both in background and human
appearance. However, existing methods only learn low-level skeleton
representation and rely on the domain-limited normality boundary, which cannot
generalize well to new scenes with different normal and abnormal behavior
patterns. In this paper, we propose a novel zero-shot video anomaly detection
framework, unlocking the potential of skeleton data via action typicality and
uniqueness learning. Firstly, we introduce a language-guided semantic
typicality modeling module that projects skeleton snippets into action semantic
space and distills LLM's knowledge of typical normal and abnormal behaviors
during training. Secondly, we propose a test-time context uniqueness analysis
module to finely analyze the spatio-temporal differences between skeleton
snippets and then derive scene-adaptive boundaries. Without using any training
samples from the target domain, our method achieves state-of-the-art results
against skeleton-based methods on four large-scale VAD datasets: ShanghaiTech,
UBnormal, NWPU, and UCF-Crime, featuring over 100 unseen surveillance scenes.

</details>


### [30] [Organoid Tracker: A SAM2-Powered Platform for Zero-shot Cyst Analysis in Human Kidney Organoid Videos](https://arxiv.org/abs/2509.11063)
*Xiaoyu Huang,Lauren M Maxson,Trang Nguyen,Cheng Jack Song,Yuankai Huo*

Main category: cs.CV

TL;DR: 该研究介绍了一个名为Organoid Tracker的图形用户界面(GUI)平台，它利用先进的SAM2模型，能够自动分割和量化肾脏类器官显微镜视频中的关键指标，例如囊肿形成率、生长速度和形态变化，从而克服了手动分析的局限性，加速了肾脏疾病（特别是多囊肾病）的研究和药物发现。


<details>
  <summary>Details</summary>
Motivation: 手动分析肾脏类器官显微镜视频数据集耗时且局限于粗略分类，无法充分利用像素级和纵向信息。需要一个更高效、更自动化的方法来提取详细的定量指标，以加速肾脏疾病的研究和药物发现。

Method: 开发了一个名为Organoid Tracker的图形用户界面(GUI)平台，采用模块化插件架构。该平台基于SAM2视觉基础模型，实现了零次分割和空间-时间显微镜视频的自动化分析。用户无需编程知识即可提取关键指标，并生成详细报告。

Result: Organoid Tracker能够自动分割和量化肾脏类器官的囊肿形成率、生长速度和形态变化等关键指标。该平台为研究人员提供了无需编程的详细定量分析能力，并生成全面的报告，显著提高了分析效率和信息提取的深度。

Conclusion: Organoid Tracker是一个开源的、可扩展的框架，它通过自动化空间-时间显微镜视频分析，为改善和加速肾脏发育、多囊肾病建模和治疗发现提供了强大的解决方案。

Abstract: Recent advances in organoid models have revolutionized the study of human
kidney disease mechanisms and drug discovery by enabling scalable,
cost-effective research without the need for animal sacrifice. Here, we present
a kidney organoid platform optimized for efficient screening in polycystic
kidney disease (PKD). While these systems generate rich spatial-temporal
microscopy video datasets, current manual approaches to analysis remain limited
to coarse classifications (e.g., hit vs. non-hit), often missing valuable
pixel-level and longitudinal information. To help overcome this bottleneck, we
developed Organoid Tracker, a graphical user interface (GUI) platform designed
with a modular plugin architecture, which empowers researchers to extract
detailed, quantitative metrics without programming expertise. Built on the
cutting-edge vision foundation model Segment Anything Model 2 (SAM2), Organoid
Tracker enables zero-shot segmentation and automated analysis of
spatial-temporal microscopy videos. It quantifies key metrics such as cyst
formation rate, growth velocity, and morphological changes, while generating
comprehensive reports. By providing an extensible, open-source framework,
Organoid Tracker offers a powerful solution for improving and accelerating
research in kidney development, PKD modeling, and therapeutic discovery. The
platform is publicly available as open-source software at
https://github.com/hrlblab/OrganoidTracker.

</details>


### [31] [The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge](https://arxiv.org/abs/2509.11071)
*Jinghan Peng,Jingwen Wang,Xing Yu,Dehui Du*

Main category: cs.CV

TL;DR: 本研究提出一种基于LLaVA模型的视觉语言模型系统，并结合LoRA和DoRA微调、深度信息融合以及思维链推理，在CVPR 2024自动驾驶挑战赛'Driving with Language'赛道中取得第一名。


<details>
  <summary>Details</summary>
Motivation: CVPR 2024 自动驾驶挑战赛'Driving with Language'赛道的参赛需求。

Method: 使用DriveLM-nuScenes数据集，基于LLaVA模型，通过LoRA和DoRA进行微调，整合开源深度估计模型的深度信息，并采用思维链推理方法进行推理。

Result: 在验证集排行榜上取得了0.7799的最高分，排名第一。

Conclusion: 所提出的基于LLaVA模型的视觉语言模型系统，结合多种先进技术，能够有效解决自动驾驶中的语言理解和决策问题，并在竞赛中取得了优异成绩。

Abstract: This report outlines our approach using vision language model systems for the
Driving with Language track of the CVPR 2024 Autonomous Grand Challenge. We
have exclusively utilized the DriveLM-nuScenes dataset for training our models.
Our systems are built on the LLaVA models, which we enhanced through
fine-tuning with the LoRA and DoRA methods. Additionally, we have integrated
depth information from open-source depth estimation models to enrich the
training and inference processes. For inference, particularly with
multiple-choice and yes/no questions, we adopted a Chain-of-Thought reasoning
approach to improve the accuracy of the results. This comprehensive methodology
enabled us to achieve a top score of 0.7799 on the validation set leaderboard,
ranking 1st on the leaderboard.

</details>


### [32] [Mars Traversability Prediction: A Multi-modal Self-supervised Approach for Costmap Generation](https://arxiv.org/abs/2509.11082)
*Zongwu Xie,Kaijie Yun,Yang Liu,Yiming Ji,Han Li*

Main category: cs.CV

TL;DR: 该模型利用相机和LiDAR数据融合，通过自监督学习生成行星探测器可穿越性成本图，并证明了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提出一个鲁棒的多模态框架，用于预测行星探测器的可穿越性成本图。

Method: 融合相机和LiDAR数据，使用基于DINOv3的图像编码器和FiLM进行传感器融合，并结合Huber和光滑性项进行优化。通过IMU数据进行自监督训练。

Result: 实验表明，即使在输入数据缺失或有噪声的情况下，模型性能下降也很小（例如，LiDAR稀疏化时MAE从约0.0775增加到0.0915），表明模型对几何信息高度敏感且鲁棒性强。

Conclusion: 该模型通过自监督学习实现了高保真度的多模态可穿越性成本图预测，具有良好的鲁棒性。其主要贡献在于提供了一个可复现的模拟环境、基于IMU的自监督标注流程以及强大的多模态BEV成本图预测模型。未来工作将集中在域泛化和数据集扩展。

Abstract: We present a robust multi-modal framework for predicting traversability
costmaps for planetary rovers. Our model fuses camera and LiDAR data to produce
a bird's-eye-view (BEV) terrain costmap, trained self-supervised using
IMU-derived labels. Key updates include a DINOv3-based image encoder,
FiLM-based sensor fusion, and an optimization loss combining Huber and
smoothness terms. Experimental ablations (removing image color, occluding
inputs, adding noise) show only minor changes in MAE/MSE (e.g. MAE increases
from ~0.0775 to 0.0915 when LiDAR is sparsified), indicating that geometry
dominates the learned cost and the model is highly robust. We attribute the
small performance differences to the IMU labeling primarily reflecting terrain
geometry rather than semantics and to limited data diversity. Unlike prior work
claiming large gains, we emphasize our contributions: (1) a high-fidelity,
reproducible simulation environment; (2) a self-supervised IMU-based labeling
pipeline; and (3) a strong multi-modal BEV costmap prediction model. We discuss
limitations and future work such as domain generalization and dataset
expansion.

</details>


### [33] [End-to-End Visual Autonomous Parking via Control-Aided Attention](https://arxiv.org/abs/2509.11090)
*Chao Chen,Shunyu Yao,Yuanwu He,Tao Feng,Ruojing Song,Yuliang Guo,Xinyu Huang,Chenxu Wu,Ren Liu,Chen Feng*

Main category: cs.CV

TL;DR: CAA-Policy是一个端到端的系统，通过控制信号来指导视觉注意力的学习，从而实现精确停车。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端学习方法在感知和控制之间缺乏有效的协同作用，单独使用基于Transformer的自注意力机制会导致不稳定的空间注意力，影响策略决策的可靠性。

Method: 提出了一种名为CAA-Policy的新型端到端模仿学习系统，引入了控制辅助注意力（CAA）机制，让控制信号指导视觉注意力的学习。该方法在自监督模式下训练注意力模块，利用来自控制输出的反向传播梯度，鼓励注意力集中在引起动作输出高方差的视觉特征上。此外，还集成了短期航点预测作为辅助任务，并引入了单独训练的运动预测模块来提高稳定性。

Result: 在CARLA模拟器上的大量实验表明，CAA-Policy在精度、鲁棒性和可解释性方面持续优于基线端到端学习方法和模块化BEV分割+混合A*管道。

Conclusion: CAA-Policy通过控制辅助注意力机制和短期航点预测，实现了更鲁棒、更通用的策略，能够有效地用于精确停车任务。

Abstract: Precise parking requires an end-to-end system where perception adaptively
provides policy-relevant details-especially in critical areas where fine
control decisions are essential. End-to-end learning offers a unified framework
by directly mapping sensor inputs to control actions, but existing approaches
lack effective synergy between perception and control. We find that
transformer-based self-attention, when used alone, tends to produce unstable
and temporally inconsistent spatial attention, which undermines the reliability
of downstream policy decisions over time. Instead, we propose CAA-Policy, an
end-to-end imitation learning system that allows control signal to guide the
learning of visual attention via a novel Control-Aided Attention (CAA)
mechanism. For the first time, we train such an attention module in a
self-supervised manner, using backpropagated gradients from the control outputs
instead of from the training loss. This strategy encourages the attention to
focus on visual features that induce high variance in action outputs, rather
than merely minimizing the training loss-a shift we demonstrate leads to a more
robust and generalizable policy. To further enhance stability, CAA-Policy
integrates short-horizon waypoint prediction as an auxiliary task, and
introduces a separately trained motion prediction module to robustly track the
target spot over time. Extensive experiments in the CARLA simulator show that
\titlevariable~consistently surpasses both the end-to-end learning baseline and
the modular BEV segmentation + hybrid A* pipeline, achieving superior accuracy,
robustness, and interpretability. Code is released at
https://github.com/Joechencc/CAAPolicy.

</details>


### [34] [PanoLora: Bridging Perspective and Panoramic Video Generation with LoRA Adaptation](https://arxiv.org/abs/2509.11092)
*Zeyu Dong,Yuyang Yin,Yuqi Li,Eric Li,Hao-Xiang Guo,Yikai Wang*

Main category: cs.CV

TL;DR: 使用低秩自适应（LoRA）技术，将全景视频生成视为一种从透视图的自适应问题，通过少量数据高效微调预训练视频扩散模型，以高质量生成全景视频，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有全景视频生成方法效率低下且效果不佳，而LoRA在风格迁移任务中表现出色，启发我们将全景视频生成视为一种从透视图的自适应问题。

Method: 将全景视频生成视为一种自适应问题，利用LoRA技术对预训练视频扩散模型进行微调，并理论分析了当秩大于任务自由度时LoRA能有效模拟投影变换。

Result: 实验结果表明，该方法能保持正确的投影几何，并在视觉质量、左右一致性和运动多样性方面超越了现有最先进的方法。

Conclusion: 提出的基于LoRA的全景视频生成方法，能够以较低的数据量和高效率生成高质量全景视频，并在各项指标上优于现有技术。

Abstract: Generating high-quality 360{\deg} panoramic videos remains a significant
challenge due to the fundamental differences between panoramic and traditional
perspective-view projections. While perspective videos rely on a single
viewpoint with a limited field of view, panoramic content requires rendering
the full surrounding environment, making it difficult for standard video
generation models to adapt. Existing solutions often introduce complex
architectures or large-scale training, leading to inefficiency and suboptimal
results. Motivated by the success of Low-Rank Adaptation (LoRA) in style
transfer tasks, we propose treating panoramic video generation as an adaptation
problem from perspective views. Through theoretical analysis, we demonstrate
that LoRA can effectively model the transformation between these projections
when its rank exceeds the degrees of freedom in the task. Our approach
efficiently fine-tunes a pretrained video diffusion model using only
approximately 1,000 videos while achieving high-quality panoramic generation.
Experimental results demonstrate that our method maintains proper projection
geometry and surpasses previous state-of-the-art approaches in visual quality,
left-right consistency, and motion diversity.

</details>


### [35] [SMILE: A Super-resolution Guided Multi-task Learning Method for Hyperspectral Unmixing](https://arxiv.org/abs/2509.11093)
*Ruiying Li,Bin Pan,Qiaoying Qu,Xia Xu,Zhenwei Shi*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SMILE的多任务学习方法，通过结合超分辨率技术来增强低空间分辨率高光谱数据的解混性能。


<details>
  <summary>Details</summary>
Motivation: 低空间分辨率限制了高光谱解混的性能，现有的结合超分辨率和解混的方法面临任务亲和性未经验证和解混收敛性无法保证的挑战。

Method: 提出了一种名为SMILE（super-resolution guided multi-task learning for hyperspectral unmixing）的方法，通过理论分析（包含关系定理和存在定理）验证了多任务学习的可行性和任务亲和性，并设计了一个同时学习共享和特定表示的新框架，以保证收敛性（通过可达性定理）。

Result: 通过理论分析和实验（在合成和真实数据集上）证明了该方法在增强高光谱解混性能方面的有效性。

Conclusion: SMILE方法为高光谱解混提供了理论支持，并通过超分辨率的引导设计了一个新的框架，有效解决了现有方法的挑战。

Abstract: The performance of hyperspectral unmixing may be constrained by low spatial
resolution, which can be enhanced using super-resolution in a multitask
learning way. However, integrating super-resolution and unmixing directly may
suffer two challenges: Task affinity is not verified, and the convergence of
unmixing is not guaranteed. To address the above issues, in this paper, we
provide theoretical analysis and propose super-resolution guided multi-task
learning method for hyperspectral unmixing (SMILE). The provided theoretical
analysis validates feasibility of multitask learning way and verifies task
affinity, which consists of relationship and existence theorems by proving the
positive guidance of super-resolution. The proposed framework generalizes
positive information from super-resolution to unmixing by learning both shared
and specific representations. Moreover, to guarantee the convergence, we
provide the accessibility theorem by proving the optimal solution of unmixing.
The major contributions of SMILE include providing progressive theoretical
support, and designing a new framework for unmixing under the guidance of
super-resolution. Our experiments on both synthetic and real datasets have
substantiate the usefulness of our work.

</details>


### [36] [A Copula-Guided Temporal Dependency Method for Multitemporal Hyperspectral Images Unmixing](https://arxiv.org/abs/2509.11096)
*Ruiying Li,Bin Pan,Qiaoying Qu,Xia Xu,Zhenwei Shi*

Main category: cs.CV

TL;DR: 该论文提出了一种基于 copula 理论的联合时间依赖性方法（Cog-TD），用于解决多时相高光谱分解（MTHU）问题，能够更好地捕捉动态物质演化。


<details>
  <summary>Details</summary>
Motivation: 现有 MTHU 方法在模拟时间依赖性方面存在局限，无法有效捕捉动态物质演化。

Method: 提出了一种新的数学模型，并构建了一个 copula 引导的框架，其中包含 copula 函数估计和时间依赖性引导两个关键模块，利用 copula 理论来显式地模拟物质在时间上的依赖关系。

Result: 在合成和真实世界数据集上的实验结果表明，所提出的 Cog-TD 方法能够有效利用时间信息，改进 MTHU 的分解效果。

Conclusion: 所提出的 Cog-TD 方法通过引入 copula 理论，成功地重新定义了 MTHU 问题，并提供了一个有效的框架和关键模块，能够显式地模拟和利用时间依赖性，在实验中取得了良好的效果。

Abstract: Multitemporal hyperspectral unmixing (MTHU) aims to model variable endmembers
and dynamical abundances, which emphasizes the critical temporal information.
However, existing methods have limitations in modeling temporal dependency,
thus fail to capture the dynamical material evolution. Motivated by the ability
of copula theory in modeling dependency structure explicitly, in this paper, we
propose a copula-guided temporal dependency method (Cog-TD) for multitemporal
hyperspectral unmixing. Cog-TD defines new mathematical model, constructs
copula-guided framework and provides two key modules with theoretical support.
The mathematical model provides explicit formulations for MTHU problem
definition, which describes temporal dependency structure by incorporating
copula theory. The copula-guided framework is constructed for utilizing copula
function, which estimates dynamical endmembers and abundances with temporal
dependency. The key modules consist of copula function estimation and temporal
dependency guidance, which computes and employs temporal information to guide
unmixing process. Moreover, the theoretical support demonstrates that estimated
copula function is valid and the represented temporal dependency exists in
hyperspectral images. The major contributions of this paper include redefining
MTHU problem with temporal dependency, proposing a copula-guided framework,
developing two key modules and providing theoretical support. Our experimental
results on both synthetic and real-world datasets demonstrate the utility of
the proposed method.

</details>


### [37] [3DAeroRelief: The first 3D Benchmark UAV Dataset for Post-Disaster Assessment](https://arxiv.org/abs/2509.11097)
*Nhut Le,Ehsan Karimi,Maryam Rahnemoonfar*

Main category: cs.CV

TL;DR: 该论文提出了3DAeroRelief，首个专门用于灾后评估的3D基准数据集，解决了现有2D图像和3D数据集在灾区分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有灾害分析依赖2D图像，缺乏深度信息和空间上下文；现有的3D数据集主要关注城市或室内场景，缺乏灾区数据。

Method: 使用无人机（UAV）在飓风受损地区收集数据，通过SfM和MVS技术重建密集3D点云，并进行手动2D标注后投影到3D空间。

Result: 提出了3DAeroRelief数据集，该数据集捕捉了大规模户外环境和细粒度的结构性损坏，并在真实灾难背景下进行了评估。

Conclusion: 3DAeroRelief数据集为推动鲁棒的3D视觉系统在真实世界的灾后应用提供了宝贵的资源。

Abstract: Timely assessment of structural damage is critical for disaster response and
recovery. However, most prior work in natural disaster analysis relies on 2D
imagery, which lacks depth, suffers from occlusions, and provides limited
spatial context. 3D semantic segmentation offers a richer alternative, but
existing 3D benchmarks focus mainly on urban or indoor scenes, with little
attention to disaster-affected areas. To address this gap, we present
3DAeroRelief--the first 3D benchmark dataset specifically designed for
post-disaster assessment. Collected using low-cost unmanned aerial vehicles
(UAVs) over hurricane-damaged regions, the dataset features dense 3D point
clouds reconstructed via Structure-from-Motion and Multi-View Stereo
techniques. Semantic annotations were produced through manual 2D labeling and
projected into 3D space. Unlike existing datasets, 3DAeroRelief captures 3D
large-scale outdoor environments with fine-grained structural damage in
real-world disaster contexts. UAVs enable affordable, flexible, and safe data
collection in hazardous areas, making them particularly well-suited for
emergency scenarios. To demonstrate the utility of 3DAeroRelief, we evaluate
several state-of-the-art 3D segmentation models on the dataset to highlight
both the challenges and opportunities of 3D scene understanding in disaster
response. Our dataset serves as a valuable resource for advancing robust 3D
vision systems in real-world applications for post-disaster scenarios.

</details>


### [38] [Filling the Gaps: A Multitask Hybrid Multiscale Generative Framework for Missing Modality in Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2509.11102)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 研究提出了GEMMNet模型，用于解决遥感图像多模态学习中模态缺失的问题，通过混合特征提取、多尺度融合和互补损失等技术提升了模型在语义分割任务上的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多模态遥感数据易因传感器故障或恶劣天气导致部分模态缺失，严重影响模型性能。现有生成模型在处理遥感数据异质性、捕捉复杂场景语义上下文以及避免对主导模态的过度依赖方面存在不足。

Method: 提出了一种名为GEMMNet的新型生成增强多模态学习网络，包含三个关键组件：1. 混合特征提取器（HyFEx），学习模态特定的表示；2. 混合融合与多尺度感知（HyFMA），捕捉跨尺度的模态协同语义上下文；3. 互补损失（CoLoss）方案，通过鼓励跨模态和跨任务的一致性来减轻模型偏差。

Result: GEMMNet在Vaihingen和Potsdam两个遥感语义分割数据集上，其性能优于AE、cGAN等生成基线模型以及mmformer和shaspec等非生成模型。

Conclusion: GEMMNet通过其创新的模块设计，有效解决了多模态遥感学习中的模态缺失问题，并在两个标准数据集上取得了最先进的性能。

Abstract: Multimodal learning has shown significant performance boost compared to
ordinary unimodal models across various domains. However, in real-world
scenarios, multimodal signals are susceptible to missing because of sensor
failures and adverse weather conditions, which drastically deteriorates models'
operation and performance. Generative models such as AutoEncoder (AE) and
Generative Adversarial Network (GAN) are intuitive solutions aiming to
reconstruct missing modality from available ones. Yet, their efficacy in remote
sensing semantic segmentation remains underexplored. In this paper, we first
examine the limitations of existing generative approaches in handling the
heterogeneity of multimodal remote sensing data. They inadequately capture
semantic context in complex scenes with large intra-class and small inter-class
variation. In addition, traditional generative models are susceptible to heavy
dependence on the dominant modality, introducing bias that affects model
robustness under missing modality conditions. To tackle these limitations, we
propose a novel Generative-Enhanced MultiModal learning Network (GEMMNet) with
three key components: (1) Hybrid Feature Extractor (HyFEx) to effectively learn
modality-specific representations, (2) Hybrid Fusion with Multiscale Awareness
(HyFMA) to capture modality-synergistic semantic context across scales and (3)
Complementary Loss (CoLoss) scheme to alleviate the inherent bias by
encouraging consistency across modalities and tasks. Our method, GEMMNet,
outperforms both generative baselines AE, cGAN (conditional GAN), and
state-of-the-art non-generative approaches - mmformer and shaspec - on two
challenging semantic segmentation remote sensing datasets (Vaihingen and
Potsdam). Source code is made available.

</details>


### [39] [WildSmoke: Ready-to-Use Dynamic 3D Smoke Assets from a Single Video in the Wild](https://arxiv.org/abs/2509.11114)
*Yuqiu Liu,Jialin Song,Manolis Savva,Wuyang Chen*

Main category: cs.CV

TL;DR: 从单视频中提取和重建动态3D烟雾，并支持交互式设计和编辑。


<details>
  <summary>Details</summary>
Motivation: 解决现有三维烟雾重建方法依赖于受控环境，忽视了真实世界视频中烟雾重建的挑战。

Method: 提出了一种包含烟雾提取、背景去除、烟雾粒子和相机姿态初始化、以及多视图视频推断的流水线。

Result: 在真实世界视频上实现了高质量的烟雾重建（平均PSNR提升2.22），并实现了对烟雾资产的多样化和真实化编辑。

Conclusion: 该方法能够有效地从野外视频中重建动态3D烟雾，并支持交互式编辑。

Abstract: We propose a pipeline to extract and reconstruct dynamic 3D smoke assets from
a single in-the-wild video, and further integrate interactive simulation for
smoke design and editing. Recent developments in 3D vision have significantly
improved reconstructing and rendering fluid dynamics, supporting realistic and
temporally consistent view synthesis. However, current fluid reconstructions
rely heavily on carefully controlled clean lab environments, whereas real-world
videos captured in the wild are largely underexplored. We pinpoint three key
challenges of reconstructing smoke in real-world videos and design targeted
techniques, including smoke extraction with background removal, initialization
of smoke particles and camera poses, and inferring multi-view videos. Our
method not only outperforms previous reconstruction and generation methods with
high-quality smoke reconstructions (+2.22 average PSNR on wild videos), but
also enables diverse and realistic editing of fluid dynamics by simulating our
smoke assets. We provide our models, data, and 4D smoke assets at
[https://autumnyq.github.io/WildSmoke](https://autumnyq.github.io/WildSmoke).

</details>


### [40] [SVR-GS: Spatially Variant Regularization for Probabilistic Masks in 3D Gaussian Splatting](https://arxiv.org/abs/2509.11116)
*Ashkan Taghipour,Vahid Naghshin,Benjamin Southwell,Farid Boussaid,Hamid Laga,Mohammed Bennamoun*

Main category: cs.CV

TL;DR: SVR-GS是一种空间变异正则化器，通过渲染每个高斯在射线上的有效贡献的每像素空间掩码，以在低重要性高斯上施加稀疏压力，从而在不显著降低图像质量的情况下减少高斯数量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于掩码的剪枝方法（如MaskGS）会全局正则化掩码的平均值，这与决定单个相机射线图像质量的局部每像素（每射线）重建损失不一致。该研究旨在解决这个问题，通过提出一种能更好地与局部重建损失对齐的剪枝方法。

Method: 提出了一种名为SVR-GS的空间变异正则化器。该方法渲染每个高斯在射线上的有效贡献的每像素空间掩码，并将稀疏压力施加在低重要性的高斯上。研究了三种空间掩码聚合策略，并在CUDA中实现了它们，同时进行了梯度分析来确定最终设计。

Result: SVR-GS在Tanks & Temples、Deep Blending和Mip-NeRF360数据集上的实验表明，与MaskGS相比，高斯数量平均减少了1.79倍，与3DGS相比，高斯数量平均减少了5.63倍，而PSNR仅分别下降了0.50 dB和0.40 dB。这使得模型更小、更快、内存效率更高。

Conclusion: SVR-GS通过引入空间变异正则化，能够有效减少3D高斯数量，同时保持较高的重建质量，从而为机器人、AR/VR和移动感知等实时应用提供更优化的模型。

Abstract: 3D Gaussian Splatting (3DGS) enables fast, high-quality novel view synthesis
but typically relies on densification followed by pruning to optimize the
number of Gaussians. Existing mask-based pruning, such as MaskGS, regularizes
the global mean of the mask, which is misaligned with the local per-pixel
(per-ray) reconstruction loss that determines image quality along individual
camera rays. This paper introduces SVR-GS, a spatially variant regularizer that
renders a per-pixel spatial mask from each Gaussian's effective contribution
along the ray, thereby applying sparsity pressure where it matters: on
low-importance Gaussians. We explore three spatial-mask aggregation strategies,
implement them in CUDA, and conduct a gradient analysis to motivate our final
design. Extensive experiments on Tanks\&Temples, Deep Blending, and Mip-NeRF360
datasets demonstrate that, on average across the three datasets, the proposed
SVR-GS reduces the number of Gaussians by 1.79\(\times\) compared to MaskGS and
5.63\(\times\) compared to 3DGS, while incurring only 0.50 dB and 0.40 dB PSNR
drops, respectively. These gains translate into significantly smaller, faster,
and more memory-efficient models, making them well-suited for real-time
applications such as robotics, AR/VR, and mobile perception.

</details>


### [41] [No Mesh, No Problem: Estimating Coral Volume and Surface from Sparse Multi-View Images](https://arxiv.org/abs/2509.11164)
*Diego Eustachio Farchione,Ramzi Idoughi,Peter Wonka*

Main category: cs.CV

TL;DR: 该研究提出了一种基于2D多视图RGB图像预测珊瑚3D体积和表面积的新型学习框架。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁监测需要准确估算珊瑚的体积和表面积，但珊瑚的复杂形态使得这一任务充满挑战。

Method: 该框架使用预训练的VGGT模块提取2D图像的密集点图，并将它们合并成统一的点云，然后通过两个并行的DGCNN解码器预测体积和表面积，并引入基于高斯负对数似然的复合损失函数来增强预测稳定性和提供不确定性估计。

Result: 该方法在准确性和泛化性方面表现出色，能够处理未见的珊瑚形态。

Conclusion: 该框架为直接从稀疏图像中高效、可扩展地估算珊瑚几何形状提供了途径，有望应用于珊瑚生长分析和珊瑚礁监测。

Abstract: Effective reef monitoring requires the quantification of coral growth via
accurate volumetric and surface area estimates, which is a challenging task due
to the complex morphology of corals. We propose a novel, lightweight, and
scalable learning framework that addresses this challenge by predicting the 3D
volume and surface area of coral-like objects from 2D multi-view RGB images.
Our approach utilizes a pre-trained module (VGGT) to extract dense point maps
from each view; these maps are merged into a unified point cloud and enriched
with per-view confidence scores. The resulting cloud is fed to two parallel
DGCNN decoder heads, which jointly output the volume and the surface area of
the coral, as well as their corresponding confidence estimate. To enhance
prediction stability and provide uncertainty estimates, we introduce a
composite loss function based on Gaussian negative log-likelihood in both real
and log domains. Our method achieves competitive accuracy and generalizes well
to unseen morphologies. This framework paves the way for efficient and scalable
coral geometry estimation directly from a sparse set of images, with potential
applications in coral growth analysis and reef monitoring.

</details>


### [42] [Traffic-MLLM: A Spatio-Temporal MLLM with Retrieval-Augmented Generation for Causal Inference in Traffic](https://arxiv.org/abs/2509.11165)
*Waikit Xiu,Qiang Lu,Xiying Li,Chen Hu,Shengbo Sun*

Main category: cs.CV

TL;DR: Traffic-MLLM是一个针对交通场景的多模态大语言模型，通过结合Qwen2.5-VL骨干、LoRA微调、CoT和RAG知识注入，在TrafficQA和DriveQA基准上取得了先进的性能，并展现出优异的零样本推理和跨场景泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的交通视频理解方法在建模时空因果关系和整合领域知识方面存在挑战，限制了其在复杂场景下的有效性。

Method: 提出Traffic-MLLM，一个基于Qwen2.5-VL骨干、使用LoRA进行微调的多模态大语言模型。通过结合Chain-of-Thought（CoT）推理和检索增强生成（RAG）的知识提示模块，将交通规则和领域知识注入推理过程。

Result: 在TrafficQA和DriveQA基准上实现了最先进的性能，证明了其处理多模态交通数据的优越能力，并展现出卓越的零样本推理和跨场景泛化能力。

Conclusion: Traffic-MLLM通过其创新的架构和知识融合方法，有效解决了现有交通视频理解方法的局限性，并在关键交通分析任务上取得了显著成果。

Abstract: As intelligent transportation systems advance, traffic video understanding
plays an increasingly pivotal role in comprehensive scene perception and causal
analysis. Yet, existing approaches face notable challenges in accurately
modeling spatiotemporal causality and integrating domain-specific knowledge,
limiting their effectiveness in complex scenarios. To address these
limitations, we propose Traffic-MLLM, a multimodal large language model
tailored for fine-grained traffic analysis. Built on the Qwen2.5-VL backbone,
our model leverages high-quality traffic-specific multimodal datasets and uses
Low-Rank Adaptation (LoRA) for lightweight fine-tuning, significantly enhancing
its capacity to model continuous spatiotemporal features in video sequences.
Furthermore, we introduce an innovative knowledge prompting module fusing
Chain-of-Thought (CoT) reasoning with Retrieval-Augmented Generation (RAG),
enabling precise injection of detailed traffic regulations and domain knowledge
into the inference process. This design markedly boosts the model's logical
reasoning and knowledge adaptation capabilities. Experimental results on
TrafficQA and DriveQA benchmarks show Traffic-MLLM achieves state-of-the-art
performance, validating its superior ability to process multimodal traffic
data. It also exhibits remarkable zero-shot reasoning and cross-scenario
generalization capabilities.

</details>


### [43] [Multispectral-NeRF:a multispectral modeling approach based on neural radiance fields](https://arxiv.org/abs/2509.11169)
*Hong Zhang,Fei Guo,Zihan Xie,Dizhao Yao*

Main category: cs.CV

TL;DR: 提出了一种名为Multispectral-NeRF的新型三维重建方法，该方法能够有效融合多光谱信息，解决了现有NeRF模型无法处理多光谱数据的局限性，并在实验中证明了其在保留光谱特征和提高重建精度方面的优势。


<details>
  <summary>Details</summary>
Motivation: 传统基于2D图像的三维重建方法主要依赖RGB信息，而利用RGB之外的更多光谱波段进行重建的方法存在价格昂贵、精度不高、几何特征不佳等问题。现有基于NeRF的模型虽然在三维重建方面表现出色，但通常只使用三波段数据，无法有效利用多光谱信息。

Method: 提出Multispectral-NeRF，对NeRF进行了改进，主要包括三个方面：1. 增加了隐藏层的维度以处理6波段的光谱输入；2. 重新设计了残差函数以优化重建图像与参考图像之间的光谱差异计算；3. 调整了数据压缩模块以满足多光谱图像对更高比特深度的需求。

Result: 实验结果表明，Multispectral-NeRF能够成功处理多波段光谱特征，并准确地保留原始场景的光谱特性。

Conclusion: Multispectral-NeRF是一种有效的三维重建方法，能够融合多光谱信息，克服现有方法的局限性，实现高精度和高质量的三维重建。

Abstract: 3D reconstruction technology generates three-dimensional representations of
real-world objects, scenes, or environments using sensor data such as 2D
images, with extensive applications in robotics, autonomous vehicles, and
virtual reality systems. Traditional 3D reconstruction techniques based on 2D
images typically relies on RGB spectral information. With advances in sensor
technology, additional spectral bands beyond RGB have been increasingly
incorporated into 3D reconstruction workflows. Existing methods that integrate
these expanded spectral data often suffer from expensive scheme prices, low
accuracy and poor geometric features. Three - dimensional reconstruction based
on NeRF can effectively address the various issues in current multispectral 3D
reconstruction methods, producing high - precision and high - quality
reconstruction results. However, currently, NeRF and some improved models such
as NeRFacto are trained on three - band data and cannot take into account the
multi - band information. To address this problem, we propose
Multispectral-NeRF, an enhanced neural architecture derived from NeRF that can
effectively integrates multispectral information. Our technical contributions
comprise threefold modifications: Expanding hidden layer dimensionality to
accommodate 6-band spectral inputs; Redesigning residual functions to optimize
spectral discrepancy calculations between reconstructed and reference images;
Adapting data compression modules to address the increased bit-depth
requirements of multispectral imagery. Experimental results confirm that
Multispectral-NeRF successfully processes multi-band spectral features while
accurately preserving the original scenes' spectral characteristics.

</details>


### [44] [SPHERE: Semantic-PHysical Engaged REpresentation for 3D Semantic Scene Completion](https://arxiv.org/abs/2509.11171)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: SPHERE通过结合体素和高斯表示来解决自动驾驶中的3D语义场景补全问题，提高了几何细节和语义准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于体素和基于平面的3D语义场景补全方法在捕捉物理规律和实现逼真的几何细节方面存在不足；而基于神经渲染的方法（如NeRF和3DGS）虽然物理感知能力强，但在处理大规模自动驾驶场景时计算成本高、收敛慢，导致语义准确性下降。

Method: 提出了一种名为SPHERE（Semantic-PHysical Engaged REpresentation）的方法，它融合了体素和高斯表示，用于3D语义场景补全。具体包括：1. 语义引导高斯初始化（SGI）模块：利用双分支3D场景表示来定位焦点体素作为锚点，以指导高斯初始化。2. 物理感知谐波增强（PHE）模块：结合语义球谐函数来模拟物理感知的上下文细节，并通过焦点分布对齐来促进语义-几何一致性。

Result: 通过在SemanticKITTI和SSCBench-KITTI-360基准上的大量实验和分析，验证了SPHERE的有效性，能够生成具有逼真细节的3D语义场景补全结果。

Conclusion: SPHERE通过结合体素和高斯表示，有效解决了现有方法在3D语义场景补全中的不足，提高了几何细节和语义准确性，在自动驾驶场景中表现出色。

Abstract: Camera-based 3D Semantic Scene Completion (SSC) is a critical task in
autonomous driving systems, assessing voxel-level geometry and semantics for
holistic scene perception. While existing voxel-based and plane-based SSC
methods have achieved considerable progress, they struggle to capture physical
regularities for realistic geometric details. On the other hand, neural
reconstruction methods like NeRF and 3DGS demonstrate superior physical
awareness, but suffer from high computational cost and slow convergence when
handling large-scale, complex autonomous driving scenes, leading to inferior
semantic accuracy. To address these issues, we propose the Semantic-PHysical
Engaged REpresentation (SPHERE) for camera-based SSC, which integrates voxel
and Gaussian representations for joint exploitation of semantic and physical
information. First, the Semantic-guided Gaussian Initialization (SGI) module
leverages dual-branch 3D scene representations to locate focal voxels as
anchors to guide efficient Gaussian initialization. Then, the Physical-aware
Harmonics Enhancement (PHE) module incorporates semantic spherical harmonics to
model physical-aware contextual details and promote semantic-geometry
consistency through focal distribution alignment, generating SSC results with
realistic details. Extensive experiments and analyses on the popular
SemanticKITTI and SSCBench-KITTI-360 benchmarks validate the effectiveness of
SPHERE. The code is available at
https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025.

</details>


### [45] [StegOT: Trade-offs in Steganography via Optimal Transport](https://arxiv.org/abs/2509.11178)
*Chengde Lin,Xuezhu Gong,Shuxue Ding,Mingzhe Yang,Xijun Lu,Chengjun Mo*

Main category: cs.CV

TL;DR: 本研究提出了一种基于StegOT模型和最优传输理论的图像隐藏方法，以解决现有模型中模式崩溃导致的信息不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN和VAE的图像隐藏模型常出现模式崩溃，导致隐写图像的封面和秘密图像间信息不平衡，影响后续提取。本研究旨在解决此挑战。

Method: 提出了一种名为StegOT的自动编码器模型，并结合最优传输理论。设计了多通道最优传输（MCOT）模块，将具有多个峰值特征分布转化为单峰，以实现信息在封面和秘密图像间的平衡。

Result: 实验结果表明，该模型不仅实现了封面和秘密图像间的信息平衡，还提升了隐写图像和恢复图像的质量。

Conclusion: 所提出的StegOT模型能够有效解决模式崩溃问题，实现信息平衡，并提高图像质量。

Abstract: Image hiding is often referred to as steganography, which aims to hide a
secret image in a cover image of the same resolution. Many steganography models
are based on genera-tive adversarial networks (GANs) and variational
autoencoders (VAEs). However, most existing models suffer from mode collapse.
Mode collapse will lead to an information imbalance between the cover and
secret images in the stego image and further affect the subsequent extraction.
To address these challenges, this paper proposes StegOT, an autoencoder-based
steganography model incorporating optimal transport theory. We designed the
multiple channel optimal transport (MCOT) module to transform the feature
distribution, which exhibits multiple peaks, into a single peak to achieve the
trade-off of information. Experiments demonstrate that we not only achieve a
trade-off between the cover and secret images but also enhance the quality of
both the stego and recovery images. The source code will be released on
https://github.com/Rss1124/StegOT.

</details>


### [46] [The Impact of Skin Tone Label Granularity on the Performance and Fairness of AI Based Dermatology Image Classification Models](https://arxiv.org/abs/2509.11184)
*Partha Shah,Durva Sankhe,Maariyah Rashid,Zakaa Khaled,Esther Puyol-Antón,Tiarna Lee,Maram Alqarni,Sweta Rai,Andrew P. King*

Main category: cs.CV

TL;DR: AI模型在皮肤镜图像分类中表现出潜力，但易受肤色偏见影响。本研究调查了 Fitzpatrick 肤色 (FST) 分级尺度对AI模型性能和偏见的影响。结果表明，使用不同粒度的FST数据训练的模型，其性能优于使用FST均衡数据训练的通用模型；然而，降低FST尺度的粒度会对模型性能产生不利影响。研究强调了FST分组粒度的重要性，并建议在公平AI研究中弃用FST尺度，转向更能代表人类肤色多样性的替代尺度。


<details>
  <summary>Details</summary>
Motivation: AI模型在皮肤镜图像分类中虽然表现出潜力，但易受肤色偏见影响。 Fitzpatrick 肤色 (FST) 分级尺度因对浅肤色类别区分度更高而受到批评。本研究旨在调查FST尺度粒度对AI模型性能和偏见的影响。

Method: 通过训练多个AI模型来对良性与恶性皮肤病变进行分类，并使用不同粒度的FST数据进行训练，以评估其性能和偏见。

Result: (i) 使用三组（FST 1/2, 3/4, 5/6）FST特定数据训练的模型，其性能普遍优于使用FST均衡数据训练的通用模型；(ii) 降低FST尺度的粒度（从1/2和3/4合并为1/2/3/4）会对模型性能产生不利影响。

Conclusion: FST分组的粒度在训练病变分类模型时至关重要。鉴于FST尺度在类别划分上可能存在人为偏见，本研究为在公平AI研究中弃用FST尺度，并转向更能代表人类肤色多样性的替代尺度提供了证据。

Abstract: Artificial intelligence (AI) models to automatically classify skin lesions
from dermatology images have shown promising performance but also
susceptibility to bias by skin tone. The most common way of representing skin
tone information is the Fitzpatrick Skin Tone (FST) scale. The FST scale has
been criticised for having greater granularity in its skin tone categories for
lighter-skinned subjects. This paper conducts an investigation of the impact
(on performance and bias) on AI classification models of granularity in the FST
scale. By training multiple AI models to classify benign vs. malignant lesions
using FST-specific data of differing granularity, we show that: (i) when
training models using FST-specific data based on three groups (FST 1/2, 3/4 and
5/6), performance is generally better for models trained on FST-specific data
compared to a general model trained on FST-balanced data; (ii) reducing the
granularity of FST scale information (from 1/2 and 3/4 to 1/2/3/4) can have a
detrimental effect on performance. Our results highlight the importance of the
granularity of FST groups when training lesion classification models. Given the
question marks over possible human biases in the choice of categories in the
FST scale, this paper provides evidence for a move away from the FST scale in
fair AI research and a transition to an alternative scale that better
represents the diversity of human skin tones.

</details>


### [47] [Scaling Up Forest Vision with Synthetic Data](https://arxiv.org/abs/2509.11201)
*Yihang She,Andrew Blake,David Coomes,Srinivasan Keshav*

Main category: cs.CV

TL;DR: 利用合成数据预训练模型，显著减少了对真实标注数据的需求，实现了具有竞争力的树木分割效果。


<details>
  <summary>Details</summary>
Motivation: 现有的公共3D森林数据集规模不足以构建鲁棒的树木分割系统，需要更有效的方法来解决数据稀疏性问题。

Method: 开发了一个新的合成数据生成流程，结合了游戏引擎和基于物理的激光雷达模拟，生成大规模、多样化、已标注的3D森林数据集。利用该合成数据对现有算法进行预训练，然后用少量真实数据进行微调。

Result: 实验表明，与在全部真实数据上训练的模型相比，经过少量真实数据微调的预训练模型在树木分割任务上取得了具有竞争力的性能，并显著降低了对标注真实数据的依赖。确定了物理准确性、多样性和规模是成功应用合成数据的关键因素。

Conclusion: 合成数据在预训练阶段可以有效缓解真实森林数据标注不足的问题，通过结合游戏引擎和激光雷达模拟生成大规模、多样化的合成数据，并关注物理准确性、多样性和规模，可以显著提高3D森林视觉系统的性能，为未来发展更鲁棒的系统铺平了道路。

Abstract: Accurate tree segmentation is a key step in extracting individual tree
metrics from forest laser scans, and is essential to understanding ecosystem
functions in carbon cycling and beyond. Over the past decade, tree segmentation
algorithms have advanced rapidly due to developments in AI. However existing,
public, 3D forest datasets are not large enough to build robust tree
segmentation systems. Motivated by the success of synthetic data in other
domains such as self-driving, we investigate whether similar approaches can
help with tree segmentation. In place of expensive field data collection and
annotation, we use synthetic data during pretraining, and then require only
minimal, real forest plot annotation for fine-tuning.
  We have developed a new synthetic data generation pipeline to do this for
forest vision tasks, integrating advances in game-engines with physics-based
LiDAR simulation. As a result, we have produced a comprehensive, diverse,
annotated 3D forest dataset on an unprecedented scale. Extensive experiments
with a state-of-the-art tree segmentation algorithm and a popular real dataset
show that our synthetic data can substantially reduce the need for labelled
real data. After fine-tuning on just a single, real, forest plot of less than
0.1 hectare, the pretrained model achieves segmentations that are competitive
with a model trained on the full scale real data. We have also identified
critical factors for successful use of synthetic data: physics, diversity, and
scale, paving the way for more robust 3D forest vision systems in the future.
Our data generation pipeline and the resulting dataset are available at
https://github.com/yihshe/CAMP3D.git.

</details>


### [48] [Beyond Sliders: Mastering the Art of Diffusion-based Image Manipulation](https://arxiv.org/abs/2509.11213)
*Yufei Tang,Daiheng Gao,Pingyu Wu,Wenbo Zhou,Bang Zhang,Weiming Zhang*

Main category: cs.CV

TL;DR: Beyond Sliders通过结合GAN和扩散模型，并采用细粒度的文本和视觉引导进行对抗性图像精炼，提升了非AIGC图像（尤其真实世界图像）的真实感和可编辑性。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法（如概念滑块）在处理非AIGC图像（尤其真实世界图像）时存在局限性，无法实现良好的真实感和可定制性。

Method: 提出Beyond Sliders框架，整合GAN和扩散模型，通过细粒度的文本和视觉引导进行对抗性训练，以改进图像质量和真实感。

Result: 实验结果表明，Beyond Sliders在图像质量和真实感方面得到显著提升，并展示了其在多种应用中的鲁棒性和多功能性。

Conclusion: Beyond Sliders成功弥合了现有方法在处理真实世界图像时的不足，提供了更优的图像编辑和生成解决方案。

Abstract: In the realm of image generation, the quest for realism and customization has
never been more pressing. While existing methods like concept sliders have made
strides, they often falter when it comes to no-AIGC images, particularly images
captured in real world settings. To bridge this gap, we introduce Beyond
Sliders, an innovative framework that integrates GANs and diffusion models to
facilitate sophisticated image manipulation across diverse image categories.
Improved upon concept sliders, our method refines the image through fine
grained guidance both textual and visual in an adversarial manner, leading to a
marked enhancement in image quality and realism. Extensive experimental
validation confirms the robustness and versatility of Beyond Sliders across a
spectrum of applications.

</details>


### [49] [Geometrically Constrained and Token-Based Probabilistic Spatial Transformers](https://arxiv.org/abs/2509.11218)
*Johann Schmidt,Sebastian Stober*

Main category: cs.CV

TL;DR: 该研究提出了一种基于空间变换网络（STN）的概率性、组件式扩展方法，用于提高细粒度视觉分类（FGVC）对几何形变的鲁棒性，无需大量计算资源或限制模型结构。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类（FGVC）在处理几何形变（如旋转、缩放、视角扭曲）时面临挑战。现有的等变架构虽然能解决这个问题，但计算成本高且限制了模型的假设空间。

Method: 本文将空间变换网络（STN）作为一种正则化工具，并提出了一种概率性、组件式的扩展方法。该方法将仿射变换分解为旋转、缩放和剪切，并使用共享的编码器在几何约束下回归每个分量。为了捕捉不确定性，模型为每个分量引入了高斯变分后沿，并在推理过程中进行采样。此外，还设计了一种新的组件式对齐损失，利用数据增强参数来指导空间对齐。

Result: 在具有挑战性的蛾类分类数据集上的实验表明，该方法相比其他STN在鲁棒性方面取得了持续的提升。

Conclusion: 本文提出的概率性、组件式STN扩展方法是一种灵活且计算效率高的方式，能够有效提升细粒度视觉分类模型在面对几何形变时的鲁棒性。

Abstract: Fine-grained visual classification (FGVC) remains highly sensitive to
geometric variability, where objects appear under arbitrary orientations,
scales, and perspective distortions. While equivariant architectures address
this issue, they typically require substantial computational resources and
restrict the hypothesis space. We revisit Spatial Transformer Networks (STNs)
as a canonicalization tool for transformer-based vision pipelines, emphasizing
their flexibility, backbone-agnostic nature, and lack of architectural
constraints. We propose a probabilistic, component-wise extension that improves
robustness. Specifically, we decompose affine transformations into rotation,
scaling, and shearing, and regress each component under geometric constraints
using a shared localization encoder. To capture uncertainty, we model each
component with a Gaussian variational posterior and perform sampling-based
canonicalization during inference.A novel component-wise alignment loss
leverages augmentation parameters to guide spatial alignment. Experiments on
challenging moth classification benchmarks demonstrate that our method
consistently improves robustness compared to other STNs.

</details>


### [50] [CCoMAML: Efficient Cattle Identification Using Cooperative Model-Agnostic Meta-Learning](https://arxiv.org/abs/2509.11219)
*Rabin Dulal,Lihong Zheng,Ashad Kabir*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的基于注意力和元学习的动物身份识别框架，以解决数据量少和模型适应性问题，并在实验中取得了优于现有方法的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RFID的牛只身份识别系统存在易丢失、损坏、篡污等问题，而基于深度学习的生物识别方法又面临数据量有限、数据采集受干扰、牛群组成动态变化等挑战，需要频繁重新训练模型。

Method: 提出了一种新颖的、用于实时牛只身份识别的少样本学习框架，该框架结合了多头注意力特征融合（MHAFF）作为特征提取器，并使用了协同模型无关元学习（CCoMAML）。该模型能够通过从少量数据样本中进行有效学习，而无需重新训练，从而提供出色的模型适应新数据的能力。

Result: 与当前最先进的、应用于牛只身份识别的少样本学习技术相比，该研究提出的CCoMAML与MHAFF在牛只身份识别方面表现出卓越的性能，F1分数分别达到98.46%和97.91%。

Conclusion: 所提出的CCoMAML与MHAFF框架在牛只身份识别任务上展现出优越的性能，克服了传统方法的局限性，为高效的牲畜管理提供了新的解决方案。

Abstract: Cattle identification is critical for efficient livestock farming management,
currently reliant on radio-frequency identification (RFID) ear tags. However,
RFID-based systems are prone to failure due to loss, damage, tampering, and
vulnerability to external attacks. As a robust alternative, biometric
identification using cattle muzzle patterns similar to human fingerprints has
emerged as a promising solution. Deep learning techniques have demonstrated
success in leveraging these unique patterns for accurate identification. But
deep learning models face significant challenges, including limited data
availability, disruptions during data collection, and dynamic herd compositions
that require frequent model retraining. To address these limitations, this
paper proposes a novel few-shot learning framework for real-time cattle
identification using Cooperative Model-Agnostic Meta-Learning (CCoMAML) with
Multi-Head Attention Feature Fusion (MHAFF) as a feature extractor model. This
model offers great model adaptability to new data through efficient learning
from few data samples without retraining. The proposed approach has been
rigorously evaluated against current state-of-the-art few-shot learning
techniques applied in cattle identification. Comprehensive experimental results
demonstrate that our proposed CCoMAML with MHAFF has superior cattle
identification performance with 98.46% and 97.91% F1 scores.

</details>


### [51] [ANROT-HELANet: Adverserially and Naturally Robust Attention-Based Aggregation Network via The Hellinger Distance for Few-Shot Classification](https://arxiv.org/abs/2509.11220)
*Gao Yu Lee,Tanmoy Dam,Md Meftahul Ferdaus,Daniel Puiu Poenar,Vu N. Duong*

Main category: cs.CV

TL;DR: ANROT-HELANet是一种新颖的深度学习模型，通过基于Hellinger距离的特征聚合和新的对比损失函数，在小样本学习（FSL）任务中实现了卓越的性能和鲁棒性，能有效抵抗对抗性攻击和自然噪声。


<details>
  <summary>Details</summary>
Motivation: 现有的基于KL散度的方法在小样本学习（FSL）中虽然表现有所提升，但容易受到对抗性攻击和自然噪声的干扰。因此，需要一种能够同时提高FSL性能和鲁棒性的方法。

Method: 提出了一种名为ANROT-HELANet的对抗性和自然性鲁棒的Hellinger聚合网络。该方法采用基于Hellinger距离的特征类聚合方案，并引入了一种新颖的Hellinger相似度对比损失函数，该函数是对变分小样本推理场景下余弦相似度对比损失的泛化。

Result: ANROT-HELANet 在对抗性扰动（epsilon=0.30）和高斯噪声（sigma=0.30）下表现出良好的鲁棒性。在miniImageNet数据集上，1-shot和5-shot场景分别取得了1.20%和1.40%的性能提升。此外，在图像重建质量方面，FID得分达到2.75，优于传统VAE（3.43）和WAE（3.38）。

Conclusion: ANROT-HELANet通过结合Hellinger距离特征聚合、注意力机制和新颖的损失函数，在小样本学习基准数据集上取得了新的最先进性能，同时保持了对对抗性和自然扰动的鲁棒性。

Abstract: Few-Shot Learning (FSL), which involves learning to generalize using only a
few data samples, has demonstrated promising and superior performances to
ordinary CNN methods. While Bayesian based estimation approaches using
Kullback-Leibler (KL) divergence have shown improvements, they remain
vulnerable to adversarial attacks and natural noises. We introduce
ANROT-HELANet, an Adversarially and Naturally RObusT Hellinger Aggregation
Network that significantly advances the state-of-the-art in FSL robustness and
performance. Our approach implements an adversarially and naturally robust
Hellinger distance-based feature class aggregation scheme, demonstrating
resilience to adversarial perturbations up to $\epsilon=0.30$ and Gaussian
noise up to $\sigma=0.30$. The network achieves substantial improvements across
benchmark datasets, including gains of 1.20\% and 1.40\% for 1-shot and 5-shot
scenarios on miniImageNet respectively. We introduce a novel Hellinger
Similarity contrastive loss function that generalizes cosine similarity
contrastive loss for variational few-shot inference scenarios. Our approach
also achieves superior image reconstruction quality with a FID score of 2.75,
outperforming traditional VAE (3.43) and WAE (3.38) approaches. Extensive
experiments conducted on four few-shot benchmarked datasets verify that
ANROT-HELANet's combination of Hellinger distance-based feature aggregation,
attention mechanisms, and our novel loss function establishes new
state-of-the-art performance while maintaining robustness against both
adversarial and natural perturbations. Our code repository will be available at
https://github.com/GreedYLearner1146/ANROT-HELANet/tree/main.

</details>


### [52] [MIS-LSTM: Multichannel Image-Sequence LSTM for Sleep Quality and Stress Prediction](https://arxiv.org/abs/2509.11232)
*Seongwan Park,Jieun Woo,Siheon Yang*

Main category: cs.CV

TL;DR: MIS-LSTM是一个混合框架，结合了CNN和LSTM，用于从多模态生命日志数据中进行日级别的睡眠质量和压力预测。它通过多通道图像和1D-CNN处理连续和离散数据，并使用CBAM融合，然后由LSTM聚合。UALRE不确定性感知集成提高了模型的鲁棒性。实验证明MIS-LSTM+UALRE在ETRI生命日志挑战数据集上取得了0.647的Macro-F1分数，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在利用多模态生命日志数据，通过混合深度学习框架MIS-LSTM，实现日级别的睡眠质量和压力预测，并提出UALRE不确定性感知集成方法来提高预测的鲁棒性。

Method: MIS-LSTM框架首先将连续传感器流分割成N小时的块并渲染成多通道图像，同时使用1D-CNN对稀疏离散事件进行编码。然后，利用卷积块注意力模块（CBAM）融合这两种模态，生成块嵌入，最后由LSTM聚合以捕捉长期时间依赖性。UALRE集成方法通过高置信度个体预测覆盖低置信度多数投票来增强鲁棒性。

Result: 在ETRI生命日志挑战数据集上，基础MIS-LSTM模型达到了0.615的Macro-F1分数。通过UALRE集成后，分数提高到0.647，优于LSTM、1D-CNN和CNN基线模型。消融实验验证了多通道成像优于堆叠垂直成像，4小时块粒度的益处，以及特定模态离散编码的有效性。

Conclusion: MIS-LSTM框架结合CNN和LSTM，并通过UALRE不确定性感知集成，能够有效地从多模态生命日志数据中进行日级别的睡眠质量和压力预测，并且在性能和鲁棒性上优于现有的基线模型。

Abstract: This paper presents MIS-LSTM, a hybrid framework that joins CNN encoders with
an LSTM sequence model for sleep quality and stress prediction at the day level
from multimodal lifelog data. Continuous sensor streams are first partitioned
into N-hour blocks and rendered as multi-channel images, while sparse discrete
events are encoded with a dedicated 1D-CNN. A Convolutional Block Attention
Module fuses the two modalities into refined block embeddings, which an LSTM
then aggregates to capture long-range temporal dependencies. To further boost
robustness, we introduce UALRE, an uncertainty-aware ensemble that overrides
lowconfidence majority votes with high-confidence individual predictions.
Experiments on the 2025 ETRI Lifelog Challenge dataset show that Our base
MISLSTM achieves Macro-F1 0.615; with the UALRE ensemble, the score improves to
0.647, outperforming strong LSTM, 1D-CNN, and CNN baselines. Ablations confirm
(i) the superiority of multi-channel over stacked-vertical imaging, (ii) the
benefit of a 4-hour block granularity, and (iii) the efficacy of
modality-specific discrete encoding.

</details>


### [53] [Contextualized Multimodal Lifelong Person Re-Identification in Hybrid Clothing States](https://arxiv.org/abs/2509.11247)
*Robert Long,Rongxin Jiang,Mingrui Yan*

Main category: cs.CV

TL;DR: 提出了一种名为CMLReID的CLIP基础框架，用于解决包含衣着变化（CCReID）和持续学习（LReID）的行人重识别（ReID）问题，旨在同时处理相同衣着（SC）和不同衣着（CC）场景，并在持续学习的环境中保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理衣着变化和持续学习的行人重识别（ReID）问题上的局限性，这些方法通常只专注于单一场景或将CCReID视为独立子问题。

Method: 提出了一种名为CMLReID的CLIP基础框架，包含两个新颖的任务：(1)上下文感知语义提示（CASP），用于生成自适应提示并结合上下文，将多粒度的视觉线索与语义文本空间对齐；(2)自适应知识融合与投影（AKFP），通过双路径学习器生成鲁棒的SC/CC原型，并使用服装状态感知投影损失对齐特征。

Result: 在多个数据集上进行的实验表明，CMLReID在处理衣着变化和序列学习的复杂过程中，表现出强大的鲁棒性和泛化能力，超越了所有现有最先进的方法。

Conclusion: CMLReID框架能够有效解决行人重识别中的衣着变化和持续学习的挑战，并在各种场景下展现出优越的性能。

Abstract: Person Re-Identification (ReID) has several challenges in real-world
surveillance systems due to clothing changes (CCReID) and the need for
maintaining continual learning (LReID). Previous existing methods either
develop models specifically for one application, which is mostly a same-cloth
(SC) setting or treat CCReID as its own separate sub-problem. In this work, we
will introduce the LReID-Hybrid task with the goal of developing a model to
achieve both SC and CC while learning in a continual setting. Mismatched
representations and forgetting from one task to the next are significant
issues, we address this with CMLReID, a CLIP-based framework composed of two
novel tasks: (1) Context-Aware Semantic Prompt (CASP) that generates adaptive
prompts, and also incorporates context to align richly multi-grained visual
cues with semantic text space; and (2) Adaptive Knowledge Fusion and Projection
(AKFP) which produces robust SC/CC prototypes through the use of a dual-path
learner that aligns features with our Clothing-State-Aware Projection Loss.
Experiments performed on a wide range of datasets and illustrate that CMLReID
outperforms all state-of-the-art methods with strong robustness and
generalization despite clothing variations and a sophisticated process of
sequential learning.

</details>


### [54] [Cross-Domain Attribute Alignment with CLIP: A Rehearsal-Free Approach for Class-Incremental Unsupervised Domain Adaptation](https://arxiv.org/abs/2509.11264)
*Kerun Mi,Guoliang Kang,Guangyu Li,Lin Zhao,Tao Zhou,Chen Gong*

Main category: cs.CV

TL;DR: 本文提出了一种名为VisTA的方法，通过挖掘和保存与领域无关且与类别无关的知识来解决类别增量无监督域适应（CI-UDA）问题，以避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的CI-UDA方法通常需要存储先前目标类别的样本以避免灾难性遗忘，并进行特定类别的域对齐，这会导致内存不断增长和知识遗忘。

Method: 该方法利用CLIP提取类别无关的“属性”知识，并将其表示为“键-值”对（视觉原型-文本提示）。通过维护两个域的属性字典，并鼓励视觉注意力和预测的一致性来进行跨域属性对齐，从而在不使用重放样本的情况下缓解域偏移并减少知识遗忘。

Result: 实验证明，该方法在三个CI-UDA基准测试中优于现有最先进的方法，并有效缓解了灾难性遗忘。

Conclusion: 所提出的VisTA方法通过挖掘和利用领域无关和类别无关的属性知识，为CI-UDA提供了一种无需重放的有效解决方案，能够同时缓解域偏移和灾难性遗忘。

Abstract: Class-Incremental Unsupervised Domain Adaptation (CI-UDA) aims to adapt a
model from a labeled source domain to an unlabeled target domain, where the
sets of potential target classes appearing at different time steps are disjoint
and are subsets of the source classes. The key to solving this problem lies in
avoiding catastrophic forgetting of knowledge about previous target classes
during continuously mitigating the domain shift. Most previous works
cumbersomely combine two technical components. On one hand, they need to store
and utilize rehearsal target sample from previous time steps to avoid
catastrophic forgetting; on the other hand, they perform alignment only between
classes shared across domains at each time step. Consequently, the memory will
continuously increase and the asymmetric alignment may inevitably result in
knowledge forgetting. In this paper, we propose to mine and preserve
domain-invariant and class-agnostic knowledge to facilitate the CI-UDA task.
Specifically, via using CLIP, we extract the class-agnostic properties which we
name as "attribute". In our framework, we learn a "key-value" pair to represent
an attribute, where the key corresponds to the visual prototype and the value
is the textual prompt. We maintain two attribute dictionaries, each
corresponding to a different domain. Then we perform attribute alignment across
domains to mitigate the domain shift, via encouraging visual attention
consistency and prediction consistency. Through attribute modeling and
cross-domain alignment, we effectively reduce catastrophic knowledge forgetting
while mitigating the domain shift, in a rehearsal-free way. Experiments on
three CI-UDA benchmarks demonstrate that our method outperforms previous
state-of-the-art methods and effectively alleviates catastrophic forgetting.
Code is available at https://github.com/RyunMi/VisTA.

</details>


### [55] [Synthetic Dataset Evaluation Based on Generalized Cross Validation](https://arxiv.org/abs/2509.11273)
*Zhihang Song,Dingyi Yao,Ruibo Ming,Lihui Peng,Danya Yao,Yi Zhang*

Main category: cs.CV

TL;DR: 本篇论文提出了一种新的评估框架，用于评估合成数据集的质量，以解决当前评估方法缺乏统一标准的问题。


<details>
  <summary>Details</summary>
Motivation: 当前合成数据集的评估研究有限，缺乏通用的标准框架，阻碍了生成方法的创新和资源优化利用。

Method: 提出一个整合了广义交叉验证实验和领域迁移学习原理的新型评估框架。该框架包括在合成数据集和多个真实世界基准（如KITTI、BDD100K）上训练特定任务模型（如YOLOv5s），形成交叉性能矩阵。通过标准化构建广义交叉验证（GCV）矩阵来量化领域迁移能力。提出两个关键指标：一个用于量化合成数据与真实世界数据集的相似性（模拟质量），另一个用于评估合成数据在各种真实世界场景下的多样性和覆盖范围（迁移质量）。

Result: 在Virtual KITTI数据集上进行了实验验证，证明了所提出的框架和指标在评估合成数据保真度方面的有效性。

Conclusion: 该框架提供了一个可扩展、可量化的评估解决方案，克服了传统方法的局限性，为人工智能研究中指导合成数据集优化提供了一个有原则的方法。

Abstract: With the rapid advancement of synthetic dataset generation techniques,
evaluating the quality of synthetic data has become a critical research focus.
Robust evaluation not only drives innovations in data generation methods but
also guides researchers in optimizing the utilization of these synthetic
resources. However, current evaluation studies for synthetic datasets remain
limited, lacking a universally accepted standard framework. To address this,
this paper proposes a novel evaluation framework integrating generalized
cross-validation experiments and domain transfer learning principles, enabling
generalizable and comparable assessments of synthetic dataset quality. The
framework involves training task-specific models (e.g., YOLOv5s) on both
synthetic datasets and multiple real-world benchmarks (e.g., KITTI, BDD100K),
forming a cross-performance matrix. Following normalization, a Generalized
Cross-Validation (GCV) Matrix is constructed to quantify domain
transferability. The framework introduces two key metrics. One measures the
simulation quality by quantifying the similarity between synthetic data and
real-world datasets, while another evaluates the transfer quality by assessing
the diversity and coverage of synthetic data across various real-world
scenarios. Experimental validation on Virtual KITTI demonstrates the
effectiveness of our proposed framework and metrics in assessing synthetic data
fidelity. This scalable and quantifiable evaluation solution overcomes
traditional limitations, providing a principled approach to guide synthetic
dataset optimization in artificial intelligence research.

</details>


### [56] [ROSGS: Relightable Outdoor Scenes With Gaussian Splatting](https://arxiv.org/abs/2509.11275)
*Lianjun Liao,Chunhui Zhang,Tong Wu,Henglei Lv,Bailin Deng,Lin Gao*

Main category: cs.CV

TL;DR: ROSGS通过两阶段方法，利用2D高斯泼溅和混合光照模型，高效地重建了可重照明的户外场景，在光照准确性和渲染效率方面达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 户外场景图像的无界性和复杂光照条件使得几何、反射率和光照的分解具有挑战性。现有的 NeRF 和 3DGS 方法存在计算开销高和光照表示低频的问题。

Method: ROSGS采用一个两阶段流程：第一阶段利用单目法线先验，使用紧凑的2D高斯泼溅（2DGS）表示重建场景几何；第二阶段，在重建的几何基础上，通过混合光照模型进行纹理和光照分解，该模型结合球形高斯函数处理高频的阳光，并使用球谐系数学习辐射传输函数来模拟低频的天光。

Result: ROSGS在重照明户外场景方面取得了最先进的性能，在重照明准确性和渲染效率方面表现优越。

Conclusion: ROSGS通过其两阶段方法和混合光照模型，有效地解决了现有 NeRF 和 3DGS 方法在户外场景重照明方面的局限性，实现了高效且准确的重建。

Abstract: Image data captured outdoors often exhibit unbounded scenes and
unconstrained, varying lighting conditions, making it challenging to decompose
them into geometry, reflectance, and illumination. Recent works have focused on
achieving this decomposition using Neural Radiance Fields (NeRF) or the 3D
Gaussian Splatting (3DGS) representation but remain hindered by two key
limitations: the high computational overhead associated with neural networks of
NeRF and the use of low-frequency lighting representations, which often result
in inefficient rendering and suboptimal relighting accuracy. We propose ROSGS,
a two-stage pipeline designed to efficiently reconstruct relightable outdoor
scenes using the Gaussian Splatting representation. By leveraging monocular
normal priors, ROSGS first reconstructs the scene's geometry with the compact
2D Gaussian Splatting (2DGS) representation, providing an efficient and
accurate geometric foundation. Building upon this reconstructed geometry, ROSGS
then decomposes the scene's texture and lighting through a hybrid lighting
model. This model effectively represents typical outdoor lighting by employing
a spherical Gaussian function to capture the directional, high-frequency
components of sunlight, while learning a radiance transfer function via
Spherical Harmonic coefficients to model the remaining low-frequency skylight
comprehensively. Both quantitative metrics and qualitative comparisons
demonstrate that ROSGS achieves state-of-the-art performance in relighting
outdoor scenes and highlight its ability to deliver superior relighting
accuracy and rendering efficiency.

</details>


### [57] [Mitigating Hallucinations in Large Vision-Language Models by Self-Injecting Hallucinations](https://arxiv.org/abs/2509.11287)
*Yifan Lu,Ziqi Zhang,Chunfeng Yuan,Jun Gao,Congxuan Zhang,Xiaojuan Qi,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: APASI通过自我注入来缓解大型视觉语言模型（LVLM）的幻觉问题，无需外部依赖，并在六个基准测试中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM幻觉缓解方法依赖于外部人类标注或辅助模型来收集偏好数据，成本高昂且难以持续改进。

Method: APASI利用目标LVLM自我注入幻觉到生成的响应中，创建具有不同偏好程度的响应对。通过模拟真实的幻觉模式来生成不被偏好的响应，以提供准确的学习信号。结合迭代对齐训练策略和课程学习，以提高模型性能。

Result: 在六个基准测试中，APASI有效缓解了三种基线模型的幻觉，并且性能与依赖外部数据的对齐方法相当甚至更优。

Conclusion: APASI是一种新颖且可泛化的方法，无需外部依赖即可有效缓解LVLM的幻觉问题，并具有与现有方法相当或更优的性能。

Abstract: Large Vision-Language Models (LVLMs) suffer from serious hallucination
problems, where the model-generated responses are inconsistent with the visual
inputs. Existing hallucination mitigation methods are mainly based on
preference alignment and require external human annotations or auxiliary models
for preference data collection, which increase costs and limit sustainable
improvement. To tackle these challenges, we propose Autonomous Preference
Alignment via Self-Injection (APASI), a novel and generalizable method that
mitigates hallucinations without external dependencies. APASI leverages the
target LVLM to self-inject hallucinations into a generated response, creating a
pair of responses with varying preference levels. During the self-injection
process, the dis-preferred response is generated based on three key
observations of hallucinations, ensuring it simulates real hallucination
patterns. This fidelity offers an accurate learning signal for hallucination
mitigation. Moreover, APASI incorporates an iterative alignment training
strategy combined with curriculum learning to periodically update the
preference data with increasing challenge, enabling stable and continuous
enhancement of the LVLM. Extensive experiments across six benchmarks show that
APASI not only effectively mitigates hallucinations for three baseline models
but also achieves comparable or even superior performance to alignment-based
methods with external dependency, thereby demonstrating its effectiveness and
generalization capability. The code is available at
https://github.com/davidluciolu/APASI.

</details>


### [58] [Leveraging Geometric Priors for Unaligned Scene Change Detection](https://arxiv.org/abs/2509.11292)
*Ziling Liu,Ziwei Chen,Mingqi Gao,Jinyu Yang,Feng Zheng*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的无需训练的框架，利用几何先验和视觉基础模型来解决未对齐场景变化检测（Unaligned Scene Change Detection, Unaligned SCD）中的关键挑战，包括视觉重叠识别、对应关系建立和遮挡检测，并在多个数据集上取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有未对齐场景变化检测方法仅依赖二维视觉线索，在处理视角变化时容易失效，且二维变化掩码的监督信息限制了模型学习多视角知识的能力，难以处理视觉重叠和遮挡。本研究旨在通过引入几何先验来解决这些问题。

Method: 本研究首次利用几何基础模型提供的几何先验，并结合视觉基础模型的强大表征能力，提出了一种无需训练的框架，以解决未对齐场景变化检测中的视觉重叠识别、对应关系建立和遮挡检测等问题。

Result: 通过在PSCD、ChangeSim和PASLCD数据集上的广泛评估，证明了该方法在视角不匹配的情况下实现了可靠的变化检测，并取得了优越且鲁棒的性能。

Conclusion: 本研究成功地将几何先验和视觉基础模型结合，为未对齐场景变化检测提供了一种新的、无需训练的解决方案，解决了现有方法的局限性，并在多个数据集上验证了其有效性。

Abstract: Unaligned Scene Change Detection aims to detect scene changes between image
pairs captured at different times without assuming viewpoint alignment. To
handle viewpoint variations, current methods rely solely on 2D visual cues to
establish cross-image correspondence to assist change detection. However, large
viewpoint changes can alter visual observations, causing appearance-based
matching to drift or fail. Additionally, supervision limited to 2D change masks
from small-scale SCD datasets restricts the learning of generalizable
multi-view knowledge, making it difficult to reliably identify visual overlaps
and handle occlusions. This lack of explicit geometric reasoning represents a
critical yet overlooked limitation. In this work, we are the first to leverage
geometric priors from a Geometric Foundation Model to address the core
challenges of unaligned SCD, including reliable identification of visual
overlaps, robust correspondence establishment, and explicit occlusion
detection. Building on these priors, we propose a training-free framework that
integrates them with the powerful representations of a visual foundation model
to enable reliable change detection under viewpoint misalignment. Through
extensive evaluation on the PSCD, ChangeSim, and PASLCD datasets, we
demonstrate that our approach achieves superior and robust performance. Our
code will be released at https://github.com/ZilingLiu/GeoSCD.

</details>


### [59] [UnLoc: Leveraging Depth Uncertainties for Floorplan Localization](https://arxiv.org/abs/2509.11301)
*Matthias Wüest,Francis Engelmann,Ondrej Miksik,Marc Pollefeys,Daniel Barath*

Main category: cs.CV

TL;DR: UnLoc是一种高效的数据驱动的相机序列定位方法，利用现成的地图数据，通过概率模型进行深度预测，无需为每个环境单独训练深度网络，提高了泛化能力和定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在深度预测中缺乏不确定性建模，并且需要为每个环境训练定制的深度网络，这限制了其泛化能力。我们希望提出一种更通用、更准确的定位方法。

Method: 提出了一种新颖的概率模型，该模型包含不确定性估计，将深度预测建模为显式概率分布。利用现成的预训练单目深度模型，无需依赖每个环境训练的深度网络。

Result: 在大型合成和真实世界数据集上进行了评估，UnLoc在准确性和鲁棒性方面均显著优于现有方法。在LaMAR HGE数据集上，对于长序列（100帧）的定位召回率是现有方法的2.7倍，对于短序列（15帧）是现有方法的16.7倍。

Conclusion: UnLoc通过结合不确定性估计和利用预训练模型，克服了现有方法的局限性，实现了高效、准确且泛化能力强的序列相机定位。

Abstract: We propose UnLoc, an efficient data-driven solution for sequential camera
localization within floorplans. Floorplan data is readily available, long-term
persistent, and robust to changes in visual appearance. We address key
limitations of recent methods, such as the lack of uncertainty modeling in
depth predictions and the necessity for custom depth networks trained for each
environment. We introduce a novel probabilistic model that incorporates
uncertainty estimation, modeling depth predictions as explicit probability
distributions. By leveraging off-the-shelf pre-trained monocular depth models,
we eliminate the need to rely on per-environment-trained depth networks,
enhancing generalization to unseen spaces. We evaluate UnLoc on large-scale
synthetic and real-world datasets, demonstrating significant improvements over
existing methods in terms of accuracy and robustness. Notably, we achieve $2.7$
times higher localization recall on long sequences (100 frames) and $16.7$
times higher on short ones (15 frames) than the state of the art on the
challenging LaMAR HGE dataset.

</details>


### [60] [Motion Estimation for Multi-Object Tracking using KalmanNet with Semantic-Independent Encoding](https://arxiv.org/abs/2509.11323)
*Jian Song,Wei Mei,Yunfeng Xu,Qiang Fu,Renke Kou,Lina Bu,Yucheng Long*

Main category: cs.CV

TL;DR: SIKNet是一种新的学习辅助滤波器，用于多目标跟踪中的运动估计，它通过编码器提取语义无关的特征，并在半模拟数据集上证明比传统卡尔曼滤波器和现有学习辅助滤波器具有更好的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于卡尔曼滤波器的运动估计方法在参数不匹配或目标非平稳运动时效果不佳。然而，运动估计是多目标跟踪中的关键组成部分，直接影响跟踪的准确性。

Method: 提出了一种名为SIKNet（Semantic-Independent KalmanNet）的新方法，它使用一个语义无关编码器（SIE）来编码状态向量。SIE首先使用1D卷积提取跨不同状态向量的同质语义元素的信息，然后使用全连接层和非线性激活层来编码异质语义元素之间的非线性和交叉依赖性。

Result: 在从多个开源MOT数据集中构建的大规模半模拟数据集上进行的实验表明，SIKNet的性能优于传统的卡尔曼滤波器，并且比现有的学习辅助滤波器具有更好的鲁棒性和准确性。

Conclusion: SIKNet通过其新颖的语义无关编码器有效地处理了运动估计问题，并在多目标跟踪任务中取得了优于现有方法的性能。

Abstract: Motion estimation is a crucial component in multi-object tracking (MOT).
  It predicts the trajectory of objects by analyzing the changes in their
positions in consecutive frames of images, reducing tracking failures and
identity switches.
  The Kalman filter (KF) based on the linear constant-velocity model is one of
the most commonly used methods in MOT.
  However, it may yield unsatisfactory results when KF's parameters are
mismatched and objects move in non-stationary.
  In this work, we utilize the learning-aided filter to handle the motion
estimation of MOT.
  In particular, we propose a novel method named Semantic-Independent KalmanNet
(SIKNet), which encodes the state vector (the input feature) using a
Semantic-Independent Encoder (SIE) by two steps.
  First, the SIE uses a 1D convolution with a kernel size of 1, which convolves
along the dimension of homogeneous-semantic elements across different state
vectors to encode independent semantic information.
  Then it employs a fully-connected layer and a nonlinear activation layer to
encode nonlinear and cross-dependency information between
heterogeneous-semantic elements.
  To independently evaluate the performance of the motion estimation module in
MOT, we constructed a large-scale semi-simulated dataset from several
open-source MOT datasets.
  Experimental results demonstrate that the proposed SIKNet outperforms the
traditional KF and achieves superior robustness and accuracy than existing
learning-aided filters.
  The code is available at (https://github.com/SongJgit/filternet and
https://github.com/SongJgit/TBDTracker).

</details>


### [61] [Toward Next-generation Medical Vision Backbones: Modeling Finer-grained Long-range Visual Dependency](https://arxiv.org/abs/2509.11328)
*Mingyuan Meng*

Main category: cs.CV

TL;DR: 研究人员探索了在医学图像计算（MIC）中使用Transformer和多层感知机（MLP）进行长距离依赖建模，发现MLP在处理高分辨率医学图像特征方面比Transformer和CNN更具优势，能够捕捉更精细的解剖/病理细节，从而在各项医学视觉任务中提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在医学图像计算（MIC）中，需要捕捉全局上下文和局部细节，但CNN的局部性限制和Transformer的高计算量使其难以处理高分辨率图像。因此，需要研究更有效的长距离依赖建模方法。

Method: 该博士研究首先创新性地将Transformer应用于MIC中的像素级和图像级任务。随后，研究重点转向MLP，开发了基于MLP的视觉模型来捕捉医学图像中的细粒度长距离视觉依赖性。

Result: 实验证实了长距离依赖建模在MIC中的关键作用。研究发现，MLP在建模包含丰富解剖/病理细节的高分辨率医学特征的细粒度长距离依赖性方面具有可行性，优于Transformer/CNN，并在多项医学视觉任务中提高了性能。

Conclusion: MLP为下一代医学视觉骨干网提供了优于Transformer/CNN的范例，能够在MIC任务中更有效地捕捉细粒度的长距离依赖性，从而提高性能。

Abstract: Medical Image Computing (MIC) is a broad research topic covering both
pixel-wise (e.g., segmentation, registration) and image-wise (e.g.,
classification, regression) vision tasks. Effective analysis demands models
that capture both global long-range context and local subtle visual
characteristics, necessitating fine-grained long-range visual dependency
modeling. Compared to Convolutional Neural Networks (CNNs) that are limited by
intrinsic locality, transformers excel at long-range modeling; however, due to
the high computational loads of self-attention, transformers typically cannot
process high-resolution features (e.g., full-scale image features before
downsampling or patch embedding) and thus face difficulties in modeling
fine-grained dependency among subtle medical image details. Concurrently,
Multi-layer Perceptron (MLP)-based visual models are recognized as
computation/memory-efficient alternatives in modeling long-range visual
dependency but have yet to be widely investigated in the MIC community. This
doctoral research advances deep learning-based MIC by investigating effective
long-range visual dependency modeling. It first presents innovative use of
transformers for both pixel- and image-wise medical vision tasks. The focus
then shifts to MLPs, pioneeringly developing MLP-based visual models to capture
fine-grained long-range visual dependency in medical images. Extensive
experiments confirm the critical role of long-range dependency modeling in MIC
and reveal a key finding: MLPs provide feasibility in modeling finer-grained
long-range dependency among higher-resolution medical features containing
enriched anatomical/pathological details. This finding establishes MLPs as a
superior paradigm over transformers/CNNs, consistently enhancing performance
across various medical vision tasks and paving the way for next-generation
medical vision backbones.

</details>


### [62] [Beyond Frame-wise Tracking: A Trajectory-based Paradigm for Efficient Point Cloud Tracking](https://arxiv.org/abs/2509.11453)
*BaiChen Fan,Sifan Zhou,Jian Li,Shibo Zhao,Muqing Cao,Qin Wang*

Main category: cs.CV

TL;DR: TrajTrack是一个新颖的激光雷达3D单目标跟踪框架，它仅通过历史边界框轨迹来学习运动连续性，无需额外的点云输入，在保持轻量级的同时提高了跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的两帧跟踪方法效率高但缺乏长期时间上下文，容易在稀疏或遮挡场景下失效；而基于序列的方法虽然鲁棒但计算成本高。为了解决这个问题，需要一种既高效又鲁棒的跟踪方法。

Method: 提出了一种新颖的基于轨迹的范式TrajTrack。该框架首先生成一个快速的显式运动建议，然后使用隐式运动建模模块预测未来轨迹，以优化和修正初始建议。整个过程不依赖额外的点云输入，仅利用历史边界框轨迹。

Result: 在NuScenes数据集上，TrajTrack实现了新的最先进性能，跟踪精度比强基线提高了4.48%，同时运行速度达到56 FPS。此外， TrajTrack在不同基线跟踪器上表现出良好的泛化能力。

Conclusion: TrajTrack通过仅利用历史轨迹信息，成功解决了现有方法的局限性，在保持轻量级的同时显著提高了3D单目标跟踪的精度和鲁棒性，并且具有良好的泛化能力。

Abstract: LiDAR-based 3D single object tracking (3D SOT) is a critical task in robotics
and autonomous systems. Existing methods typically follow frame-wise motion
estimation or a sequence-based paradigm. However, the two-frame methods are
efficient but lack long-term temporal context, making them vulnerable in sparse
or occluded scenes, while sequence-based methods that process multiple point
clouds gain robustness at a significant computational cost. To resolve this
dilemma, we propose a novel trajectory-based paradigm and its instantiation,
TrajTrack. TrajTrack is a lightweight framework that enhances a base two-frame
tracker by implicitly learning motion continuity from historical bounding box
trajectories alone-without requiring additional, costly point cloud inputs. It
first generates a fast, explicit motion proposal and then uses an implicit
motion modeling module to predict the future trajectory, which in turn refines
and corrects the initial proposal. Extensive experiments on the large-scale
NuScenes benchmark show that TrajTrack achieves new state-of-the-art
performance, dramatically improving tracking precision by 4.48% over a strong
baseline while running at 56 FPS. Besides, we also demonstrate the strong
generalizability of TrajTrack across different base trackers. Video is
available at https://www.bilibili.com/video/BV1ahYgzmEWP.

</details>


### [63] [Dual Band Video Thermography Near Ambient Conditions](https://arxiv.org/abs/2509.11334)
*Sriram Narayanan,Mani Ramanagopal,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 本研究提出一种新方法，利用双波段热成像技术分离长波红外辐射中的反射和发射成分，从而实现对物体发射率、温度、反射率和形状等特性的精确测量。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉等应用中，近乎环境的温度条件是研究的重点，此时红外辐射的反射和发射成分通常具有相当的可比性，并且会随时间变化。准确分离这些成分对于理解物体的发射率、温度、反射率和形状等特性至关重要。

Method: 提出了一种双波段热图像形成模型，并开发了相应的算法，利用两个具有不同光谱灵敏度的热像仪捕捉的视频来估计物体表面的发射率及其随时间变化的温度，同时分离动态背景。

Result: 在严格校准的发射率条件下，对多种材料进行了定量评估，并在包含热液体玻璃杯和移动背景人物等复杂日常场景中展示了定性结果。

Conclusion: 本研究首次提出了一种能够有效分离双波段热成像视频中反射和发射成分的方法，为精确测量物体热特性和背景动态提供了新的途径。

Abstract: Long-wave infrared radiation captured by a thermal camera consists of two
components: (a) light from the environment reflected or transmitted by a
surface, and (b) light emitted by the surface after undergoing heat transport
through the object and exchanging heat with the surrounding environment.
Separating these components is essential for understanding object properties
such as emissivity, temperature, reflectance and shape. Previous thermography
studies often assume that only one component is dominant (e.g., in welding) or
that the second component is constant and can be subtracted. However, in
near-ambient conditions, which are most relevant to computer vision
applications, both components are typically comparable in magnitude and vary
over time. We introduce the first method that separates reflected and emitted
components of light in videos captured by two thermal cameras with different
spectral sensitivities. We derive a dual-band thermal image formation model and
develop algorithms to estimate the surface's emissivity and its time-varying
temperature while isolating a dynamic background. We quantitatively evaluate
our approach using carefully calibrated emissivities for a range of materials
and show qualitative results on complex everyday scenes, such as a glass filled
with hot liquid and people moving in the background.

</details>


### [64] [Beyond Instance Consistency: Investigating View Diversity in Self-supervised Learning](https://arxiv.org/abs/2509.11344)
*Huaiyuan Qin,Muli Yang,Siyuan Hu,Peng Hu,Yu Zhang,Chen Gong,Hongyuan Zhu*

Main category: cs.CV

TL;DR: SSL在非标志性数据上仍然有效，且存在最优的视图多样性范围。


<details>
  <summary>Details</summary>
Motivation: 探究在实例一致性假设不成立的情况下，自监督学习（SSL）的有效性，并寻找最优的视图多样性。

Method: 通过消融实验研究SSL在不同视图一致性下的表现，并采用Earth Mover's Distance (EMD) 衡量视图间的互信息，分析视图多样性与下游任务性能的关系。

Result: SSL在非标志性数据上仍能学习到有意义的表征；增加视图多样性（如零重叠或更小的裁剪尺度）能提升分类和密集预测任务的性能，但过高的多样性会降低效果；中等的EMD值与SSL学习的提升相关。

Conclusion: 实例一致性假设并非SSL成功的必要条件；存在一个最优的视图多样性范围，可以通过EMD等指标进行量化，为未来的SSL框架设计提供指导。

Abstract: Self-supervised learning (SSL) conventionally relies on the instance
consistency paradigm, assuming that different views of the same image can be
treated as positive pairs. However, this assumption breaks down for non-iconic
data, where different views may contain distinct objects or semantic
information. In this paper, we investigate the effectiveness of SSL when
instance consistency is not guaranteed. Through extensive ablation studies, we
demonstrate that SSL can still learn meaningful representations even when
positive pairs lack strict instance consistency. Furthermore, our analysis
further reveals that increasing view diversity, by enforcing zero overlapping
or using smaller crop scales, can enhance downstream performance on
classification and dense prediction tasks. However, excessive diversity is
found to reduce effectiveness, suggesting an optimal range for view diversity.
To quantify this, we adopt the Earth Mover's Distance (EMD) as an estimator to
measure mutual information between views, finding that moderate EMD values
correlate with improved SSL learning, providing insights for future SSL
framework design. We validate our findings across a range of settings,
highlighting their robustness and applicability on diverse data sources.

</details>


### [65] [Promoting Shape Bias in CNNs: Frequency-Based and Contrastive Regularization for Corruption Robustness](https://arxiv.org/abs/2509.11355)
*Robin Narsingh Ranabhat,Longwei Wang,Amit Kumar Patel,KC santosh*

Main category: cs.CV

TL;DR: CNNs容易受到图像损坏的影响，因为它们依赖于局部纹理而不是全局形状。本研究提出了两种正则化策略来鼓励CNN学习基于形状的表示，以提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: CNNs在图像分类方面表现出色，但容易受到常见损坏的影响，而人类却能轻松应对。其脆弱性的一个关键原因是它们依赖于局部纹理线索，而不是全局物体形状，这与人类感知形成鲜明对比。

Method: 提出了两种互补的正则化策略：1. 引入辅助损失，强制原始输入和低频滤波输入之间的特征一致性；2. 结合监督对比学习来构建围绕类别一致的、与形状相关的表示的特征空间。

Result: 在CIFAR-10-C基准测试中，这两种方法都提高了鲁棒性，同时没有降低在干净数据上的准确性。

Conclusion: 损失级别的正则化可以有效地引导CNN朝着更具形状感知能力、更具弹性的表示。

Abstract: Convolutional Neural Networks (CNNs) excel at image classification but remain
vulnerable to common corruptions that humans handle with ease. A key reason for
this fragility is their reliance on local texture cues rather than global
object shapes -- a stark contrast to human perception. To address this, we
propose two complementary regularization strategies designed to encourage
shape-biased representations and enhance robustness. The first introduces an
auxiliary loss that enforces feature consistency between original and
low-frequency filtered inputs, discouraging dependence on high-frequency
textures. The second incorporates supervised contrastive learning to structure
the feature space around class-consistent, shape-relevant representations.
Evaluated on the CIFAR-10-C benchmark, both methods improve corruption
robustness without degrading clean accuracy. Our results suggest that
loss-level regularization can effectively steer CNNs toward more shape-aware,
resilient representations.

</details>


### [66] [GLaVE-Cap: Global-Local Aligned Video Captioning with Vision Expert Integration](https://arxiv.org/abs/2509.11360)
*Wan Xu,Feng Zhu,Yihan Zeng,Yuanfan Guo,Ming Liu,Hang Xu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: GLaVE-Cap是一个结合视觉专家和全局-局部对齐的框架，旨在解决现有视频详细描述生成中局部到全局范式存在的细节不足和上下文不一致问题。它通过TrackFusion模块生成更全面的局部描述，并通过CaptionBridge模块实现局部与全局信息的交互，以生成连贯的全局描述。同时，研究者还提出了GLaVE-Bench基准和GLaVE-1.2M数据集，以促进视频理解和评估。实验证明GLaVE-Cap达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频详细描述生成方法（局部到全局范式）生成的描述不够详细且上下文不一致，主要原因是缺乏保证细粒度描述的机制以及局部和全局描述之间的交互性较弱。

Method: 提出GLaVE-Cap框架，包含两个核心模块：TrackFusion和CaptionBridge。TrackFusion利用视觉专家获取跨帧视觉提示，并采用双流结构来生成全面的局部描述。CaptionBridge通过全局上下文引导局部描述生成，并自适应地将局部描述总结为连贯的全局描述，从而建立局部-全局交互。此外，还构建了GLaVE-Bench基准和GLaVE-1.2M数据集。

Result: GLaVE-Cap在四个基准测试中取得了最先进的性能。消融实验和学生模型分析验证了所提出模块和GLaVE-1.2M数据集的有效性。

Conclusion: GLaVE-Cap通过引入全局-局部对齐和视觉专家集成，有效解决了现有视频详细描述生成方法的局限性，显著提升了描述的详细程度和上下文一致性。GLaVE-Bench和GLaVE-1.2M的提出为该领域的研究和评估提供了重要资源。

Abstract: Video detailed captioning aims to generate comprehensive video descriptions
to facilitate video understanding. Recently, most efforts in the video detailed
captioning community have been made towards a local-to-global paradigm, which
first generates local captions from video clips and then summarizes them into a
global caption. However, we find this paradigm leads to less detailed and
contextual-inconsistent captions, which can be attributed to (1) no mechanism
to ensure fine-grained captions, and (2) weak interaction between local and
global captions. To remedy the above two issues, we propose GLaVE-Cap, a
Global-Local aligned framework with Vision Expert integration for Captioning,
which consists of two core modules: TrackFusion enables comprehensive local
caption generation, by leveraging vision experts to acquire cross-frame visual
prompts, coupled with a dual-stream structure; while CaptionBridge establishes
a local-global interaction, by using global context to guide local captioning,
and adaptively summarizing local captions into a coherent global caption.
Besides, we construct GLaVE-Bench, a comprehensive video captioning benchmark
featuring 5X more queries per video than existing benchmarks, covering diverse
visual dimensions to facilitate reliable evaluation. We further provide a
training dataset GLaVE-1.2M containing 16K high-quality fine-grained video
captions and 1.2M related question-answer pairs. Extensive experiments on four
benchmarks show that our GLaVE-Cap achieves state-of-the-art performance.
Besides, the ablation studies and student model analyses further validate the
effectiveness of the proposed modules and the contribution of GLaVE-1.2M to the
video understanding community. The source code, model weights, benchmark, and
dataset will be open-sourced.

</details>


### [67] [In-Vivo Skin 3-D Surface Reconstruction and Wrinkle Depth Estimation using Handheld High Resolution Tactile Sensing](https://arxiv.org/abs/2509.11385)
*Akhil Padmanabha,Arpit Agarwal,Catherine Li,Austin Williams,Dinesh K. Patel,Sankalp Chopkar,Achu Wilson,Ahmet Ozkan,Wenzhen Yuan,Sonal Choudhary,Arash Mostaghimi,Zackory Erickson,Carmel Majidi*

Main category: cs.CV

TL;DR: 提出了一种基于GelSight技术的便携式3D皮肤重建探头，可实现微米级皱纹高度测量，并验证了其在多部位皮肤评估和护肤品效果评估中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有便携式高分辨率3D皮肤重建设备不足，无法满足跨部位皮肤评估需求。

Method: 使用定制凝胶和基于学习的重建算法的GelSight触觉成像技术，并集成力传感器的手持探头。

Result: 在皱纹状测试对象上实现了12.55微米的平均绝对误差；首次在多个身体区域提供了经验证的皱纹深度指标；证明了保湿霜可显著减少三个部位的皱纹高度。

Conclusion: 提供了一个经过验证的临床和美容皮肤分析工具，可用于诊断、治疗监测和护肤品效果评估。

Abstract: Three-dimensional (3-D) skin surface reconstruction offers promise for
objective and quantitative dermatological assessment, but no portable,
high-resolution device exists that has been validated and used for depth
reconstruction across various body locations. We present a compact 3-D skin
reconstruction probe based on GelSight tactile imaging with a custom elastic
gel and a learning-based reconstruction algorithm for micron-level wrinkle
height estimation. Our probe, integrated into a handheld probe with force
sensing for consistent contact, achieves a mean absolute error of 12.55 micron
on wrinkle-like test objects. In a study with 15 participants without skin
disorders, we provide the first validated wrinkle depth metrics across multiple
body regions. We further demonstrate statistically significant reductions in
wrinkle height at three locations following over-the-counter moisturizer
application. Our work offers a validated tool for clinical and cosmetic skin
analysis, with potential applications in diagnosis, treatment monitoring, and
skincare efficacy evaluation.

</details>


### [68] [Learning to Generate 4D LiDAR Sequences](https://arxiv.org/abs/2509.11959)
*Ao Liang,Youquan Liu,Yu Yang,Dongyue Lu,Linfeng Li,Lingdong Kong,Huaici Zhao,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: LiDARCrafter是一个将语言转化为可编辑的4D LiDAR序列的框架，解决了LiDAR生成中的可控性、时间稳定性和评估挑战，并在nuScenes数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在视频和基于占用的数据合成方面取得了进展，但LiDAR（激光雷达）生成仍未得到充分研究，尽管它对于精确的3D感知至关重要。将生成扩展到4D LiDAR数据带来了可控性、时间稳定性和评估方面的挑战。

Method: LiDARCrafter框架首先将指令解析为以自我为中心的场景图，然后使用一个三分支扩散模型将其转换为对象布局、轨迹和形状。接着，一个范围图像扩散模型生成初始扫描，最后通过一个自回归模块将其扩展为时间连贯的序列。该框架还支持对象级别的编辑，如插入或重新定位。此外，还提供了一个名为EvalSuite的基准，用于跨场景、对象和序列级别的公平评估。

Result: 在nuScenes数据集上，LiDARCrafter在保真度、可控性和时间一致性方面均达到了最先进的水平。

Conclusion: LiDARCrafter为基于LiDAR的模拟和数据增强奠定了基础，解决了LiDAR生成中的关键挑战，并展示了其在生成可控、时间连贯的4D LiDAR序列方面的能力。

Abstract: While generative world models have advanced video and occupancy-based data
synthesis, LiDAR generation remains underexplored despite its importance for
accurate 3D perception. Extending generation to 4D LiDAR data introduces
challenges in controllability, temporal stability, and evaluation. We present
LiDARCrafter, a unified framework that converts free-form language into
editable LiDAR sequences. Instructions are parsed into ego-centric scene
graphs, which a tri-branch diffusion model transforms into object layouts,
trajectories, and shapes. A range-image diffusion model generates the initial
scan, and an autoregressive module extends it into a temporally coherent
sequence. The explicit layout design further supports object-level editing,
such as insertion or relocation. To enable fair assessment, we provide
EvalSuite, a benchmark spanning scene-, object-, and sequence-level metrics. On
nuScenes, LiDARCrafter achieves state-of-the-art fidelity, controllability, and
temporal consistency, offering a foundation for LiDAR-based simulation and data
augmentation.

</details>


### [69] [MixANT: Observation-dependent Memory Propagation for Stochastic Dense Action Anticipation](https://arxiv.org/abs/2509.11394)
*Syed Talal Wasim,Hamid Suleman,Olga Zatsarynna,Muzammal Naseer,Juergen Gall*

Main category: cs.CV

TL;DR: MixANT通过引入动态选择的遗忘门（A矩阵）来改进状态空间模型（SSMs），以实现对人类活动的长期预测，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的SSM（如Mamba）虽然在选择性方面有所改进，但其遗忘门（A矩阵）是静态的，这限制了它们在处理长期依赖关系方面的能力。需要一种动态调整遗忘门的方法来提高模型对人类活动的预测能力。

Method: 提出了一种名为MixANT的新架构，它采用混合专家模型的方法，根据输入特征动态地选择不同的A矩阵。这种方法增强了模型的表征能力，同时保持了计算效率。

Result: 在50Salads、Breakfast和Assembly101数据集上的广泛实验表明，MixANT在所有评估设置下都持续优于最先进的方法。

Conclusion: MixANT的重要性在于其引入了输入依赖的遗忘门机制，这对于在多样化的真实世界场景中可靠地预测人类行为至关重要。

Abstract: We present MixANT, a novel architecture for stochastic long-term dense
anticipation of human activities. While recent State Space Models (SSMs) like
Mamba have shown promise through input-dependent selectivity on three key
parameters, the critical forget-gate ($\textbf{A}$ matrix) controlling temporal
memory remains static. We address this limitation by introducing a mixture of
experts approach that dynamically selects contextually relevant $\textbf{A}$
matrices based on input features, enhancing representational capacity without
sacrificing computational efficiency. Extensive experiments on the 50Salads,
Breakfast, and Assembly101 datasets demonstrate that MixANT consistently
outperforms state-of-the-art methods across all evaluation settings. Our
results highlight the importance of input-dependent forget-gate mechanisms for
reliable prediction of human behavior in diverse real-world scenarios.

</details>


### [70] [No Modality Left Behind: Dynamic Model Generation for Incomplete Medical Data](https://arxiv.org/abs/2509.11406)
*Christoph Fürböck,Paul Weiser,Branko Mitic,Philipp Seeböck,Thomas Helbich,Georg Langs*

Main category: cs.CV

TL;DR: 提出一种基于超网络的动态模型生成方法，以解决多模态医学影像数据不完整的问题，提高了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界的临床环境，训练和应用深度学习模型在多模态医学影像数据时，常常面临数据不完整的问题。标准方法要么丢弃缺失样本，要么需要进行插值，要么重新利用 dropout 学习方案，这都限制了模型的鲁棒性和泛化能力。

Method: 提出一种基于超网络的模型，该模型根据可用模态的集合动态地生成特定任务的分类模型。与训练固定模型不同，超网络学习预测任务模型的参数，使其适应可用的模态，从而能够在所有样本上进行训练和推理，而无论数据是否完整。

Result: 将该方法与（1）仅在完整数据上训练的模型、（2）最先进的通道 dropout 方法和（3）基于插值的方法进行了比较，使用了人为不完整的数据集来系统地分析对缺失模态的鲁棒性。结果表明，该方法具有优越的适应性，在 25% 的完整性数据集（75% 的训练数据缺失模态）上训练时，准确率提高了高达 8%，优于最先进的方法。

Conclusion: 通过使单个模型能够跨所有模态配置进行泛化，该方法为现实世界的多模态医学数据分析提供了一种有效的解决方案。

Abstract: In real world clinical environments, training and applying deep learning
models on multi-modal medical imaging data often struggles with partially
incomplete data. Standard approaches either discard missing samples, require
imputation or repurpose dropout learning schemes, limiting robustness and
generalizability. To address this, we propose a hypernetwork-based method that
dynamically generates task-specific classification models conditioned on the
set of available modalities. Instead of training a fixed model, a hypernetwork
learns to predict the parameters of a task model adapted to available
modalities, enabling training and inference on all samples, regardless of
completeness. We compare this approach with (1) models trained only on complete
data, (2) state of the art channel dropout methods, and (3) an imputation-based
method, using artificially incomplete datasets to systematically analyze
robustness to missing modalities. Results demonstrate superior adaptability of
our method, outperforming state of the art approaches with an absolute increase
in accuracy of up to 8% when trained on a dataset with 25% completeness (75% of
training data with missing modalities). By enabling a single model to
generalize across all modality configurations, our approach provides an
efficient solution for real-world multi-modal medical data analysis.

</details>


### [71] [Disentanglement of Biological and Technical Factors via Latent Space Rotation in Clinical Imaging Improves Disease Pattern Discovery](https://arxiv.org/abs/2509.11436)
*Jeanny Pan,Philipp Seeböck,Christoph Fürböck,Svitlana Pochepnia,Jennifer Straub,Lucian Beer,Helmut Prosch,Georg Langs*

Main category: cs.CV

TL;DR: 本研究提出一种通过后验数据隐空间旋转来学习领域迁移的方法，以解开生物和技术因素，从而提高在异构临床数据上的聚类稳定性和疾病预测能力。


<details>
  <summary>Details</summary>
Motivation: 医学影像数据中存在因成像技术、扫描参数等因素导致的领域偏移，这阻碍了机器学习模型学习有意义的生物学模式，影响了诊断和预后评估。

Method: 提出一种后验数据隐空间旋转的方法，实现生物和技术因素的解耦。

Result: +19.01% (ARI), +16.85% (NMI), 和 +12.39% (Dice) 的聚类一致性提升，优于四种最先进的协调方法。在特发性肺纤维化患者的组织成分量化中，提高了 Cox 生存预测的准确性。

Conclusion: 所提出的无标签框架能够解耦生物和技术因素，提高在多中心常规影像数据上的聚类稳定性和疾病预测能力，有助于生物标志物的发现。

Abstract: Identifying new disease-related patterns in medical imaging data with the
help of machine learning enlarges the vocabulary of recognizable findings. This
supports diagnostic and prognostic assessment. However, image appearance varies
not only due to biological differences, but also due to imaging technology
linked to vendors, scanning- or re- construction parameters. The resulting
domain shifts impedes data representation learning strategies and the discovery
of biologically meaningful cluster appearances. To address these challenges, we
introduce an approach to actively learn the domain shift via post-hoc rotation
of the data latent space, enabling disentanglement of biological and technical
factors. Results on real-world heterogeneous clinical data showcase that the
learned disentangled representation leads to stable clusters representing
tissue-types across different acquisition settings. Cluster consistency is
improved by +19.01% (ARI), +16.85% (NMI), and +12.39% (Dice) compared to the
entangled representation, outperforming four state-of-the-art harmonization
methods. When using the clusters to quantify tissue composition on idiopathic
pulmonary fibrosis patients, the learned profiles enhance Cox survival
prediction. This indicates that the proposed label-free framework facilitates
biomarker discovery in multi-center routine imaging data. Code is available on
GitHub https://github.com/cirmuw/latent-space-rotation-disentanglement.

</details>


### [72] [MultiMAE for Brain MRIs: Robustness to Missing Inputs Using Multi-Modal Masked Autoencoder](https://arxiv.org/abs/2509.11442)
*Ayhan Can Erdur,Christian Beischl,Daniel Scholz,Jiazhen Pan,Benedikt Wiestler,Daniel Rueckert,Jan C Peeken*

Main category: cs.CV

TL;DR: 本研究提出了一种用于处理3D医学影像（脑部MRI）缺失输入的掩码自编码器（MAE）范式，通过多模态、多任务学习，实现缺失序列的推理，并在下游分割和分类任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习模型通常依赖完整输入数据，而医学影像数据（如脑部MRI）常出现缺失输入序列的情况，这对模型的应用构成了挑战。

Method: 受MultiMAE启发，提出了一种针对3D脑部MRI的掩码自编码器（MAE）范式。该方法将每个MRI序列视为单独的输入模态，利用晚期融合风格的Transformer编码器整合多序列信息（多模态），并为每个模态设置单独的解码器流以实现多任务重建。这种预训练策略使模型能够学习每个模态的丰富表征，并通过跨序列推理来处理缺失输入。

Result: 实验结果表明，与MAE-ViT基线模型相比，在存在缺失输入序列的下游分割和分类任务中，本方法在Dice分数上整体提高了10.1，在MCC上提高了0.46，证明了该预训练策略的有效性和鲁棒性。

Conclusion: 本研究提出的MAE预训练策略能够有效地处理3D脑部MRI中的缺失输入序列，学习模态特异性表征，并通过跨序列推理进行补全，为下游应用提供了灵活且可泛化的编码器。

Abstract: Missing input sequences are common in medical imaging data, posing a
challenge for deep learning models reliant on complete input data. In this
work, inspired by MultiMAE [2], we develop a masked autoencoder (MAE) paradigm
for multi-modal, multi-task learning in 3D medical imaging with brain MRIs. Our
method treats each MRI sequence as a separate input modality, leveraging a
late-fusion-style transformer encoder to integrate multi-sequence information
(multi-modal) and individual decoder streams for each modality for multi-task
reconstruction. This pretraining strategy guides the model to learn rich
representations per modality while also equipping it to handle missing inputs
through cross-sequence reasoning. The result is a flexible and generalizable
encoder for brain MRIs that infers missing sequences from available inputs and
can be adapted to various downstream applications. We demonstrate the
performance and robustness of our method against an MAE-ViT baseline in
downstream segmentation and classification tasks, showing absolute improvement
of $10.1$ overall Dice score and $0.46$ MCC over the baselines with missing
input sequences. Our experiments demonstrate the strength of this pretraining
strategy. The implementation is made available.

</details>


### [73] [Modality-Aware Infrared and Visible Image Fusion with Target-Aware Supervision](https://arxiv.org/abs/2509.11476)
*Tianyao Sun,Dawei Xiang,Tianqi Ding,Xiang Fang,Yijiashun Qi,Zunduo Zhao*

Main category: cs.CV

TL;DR: FusionNet是一个创新的端到端融合框架，通过显式建模跨模态交互和增强任务关键区域来改进红外与可见光图像融合。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决多模态感知中的红外与可见光图像融合（IVIF）任务，该任务旨在整合不同光谱域的结构和纹理线索，并提出一种能够显式建模跨模态交互并增强任务关键区域的新型端到端融合框架FusionNet。

Method: FusionNet引入了一种模态感知注意力机制，根据红外和可见光特征的区分能力动态调整它们的贡献。此外，它还包含一个像素级alpha混合模块，以自适应和内容感知的方式学习空间变化的融合权重。最后，我们设计了一种目标感知损失函数，利用弱ROI监督来保持包含重要物体（如行人、车辆）区域的语义一致性。

Result: 在公开的M3FD数据集上的实验表明，FusionNet生成的融合图像在语义保持、感知质量和可解释性方面均有提升。

Conclusion: FusionNet为语义感知的多模态图像融合提供了一个通用且可扩展的解决方案，能够提高目标检测和场景理解等下游任务的性能。

Abstract: Infrared and visible image fusion (IVIF) is a fundamental task in multi-modal
perception that aims to integrate complementary structural and textural cues
from different spectral domains. In this paper, we propose FusionNet, a novel
end-to-end fusion framework that explicitly models inter-modality interaction
and enhances task-critical regions. FusionNet introduces a modality-aware
attention mechanism that dynamically adjusts the contribution of infrared and
visible features based on their discriminative capacity. To achieve
fine-grained, interpretable fusion, we further incorporate a pixel-wise alpha
blending module, which learns spatially-varying fusion weights in an adaptive
and content-aware manner. Moreover, we formulate a target-aware loss that
leverages weak ROI supervision to preserve semantic consistency in regions
containing important objects (e.g., pedestrians, vehicles). Experiments on the
public M3FD dataset demonstrate that FusionNet generates fused images with
enhanced semantic preservation, high perceptual quality, and clear
interpretability. Our framework provides a general and extensible solution for
semantic-aware multi-modal image fusion, with benefits for downstream tasks
such as object detection and scene understanding.

</details>


### [74] [Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis](https://arxiv.org/abs/2509.11526)
*Wenhao Tang,Sheng Huang,Heng Fang,Fengtao Zhou,Bo Liu,Qingshan Liu*

Main category: cs.CV

TL;DR: MHIM-MIL是一种新的多实例学习框架，通过掩码硬实例挖掘来克服现有方法的偏见，并在癌症诊断、分型和生存分析等任务中取得了更好的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法倾向于关注易于分类的实例，忽略了包含判别性边界信息的困难实例。

Method: 提出了一种基于Siamese结构的MHIM-MIL框架，利用一致性约束、类别感知实例概率、动量教师和随机掩码来挖掘困难实例，并使用全局循环网络和指数移动平均来更新教师模型，以获得多样化且不重复的困难实例。

Result: 在癌症诊断、亚型分析、生存分析任务和12个基准测试中，MHIM-MIL的性能和效率均优于现有最新方法。

Conclusion: MHIM-MIL通过有效的硬实例挖掘，显著提高了计算病理学中多实例学习的性能和效率。

Abstract: Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has
opened new avenues for Computational Pathology (CPath). As positive tissue
comprises only a small fraction of gigapixel WSIs, existing Multiple Instance
Learning (MIL) methods typically focus on identifying salient instances via
attention mechanisms. However, this leads to a bias towards easy-to-classify
instances while neglecting challenging ones. Recent studies have shown that
hard examples are crucial for accurately modeling discriminative boundaries.
Applying such an idea at the instance level, we elaborate a novel MIL framework
with masked hard instance mining (MHIM-MIL), which utilizes a Siamese structure
with a consistency constraint to explore the hard instances. Using a
class-aware instance probability, MHIM-MIL employs a momentum teacher to mask
salient instances and implicitly mine hard instances for training the student
model. To obtain diverse, non-redundant hard instances, we adopt large-scale
random masking while utilizing a global recycle network to mitigate the risk of
losing key features. Furthermore, the student updates the teacher using an
exponential moving average, which identifies new hard instances for subsequent
training iterations and stabilizes optimization. Experimental results on cancer
diagnosis, subtyping, survival analysis tasks, and 12 benchmarks demonstrate
that MHIM-MIL outperforms the latest methods in both performance and
efficiency. The code is available at: https://github.com/DearCaat/MHIM-MIL.

</details>


### [75] [SFGNet: Semantic and Frequency Guided Network for Camouflaged Object Detection](https://arxiv.org/abs/2509.11539)
*Dezhen Wang,Haixiang Zhao,Xiang Shen,Sheng Miao*

Main category: cs.CV

TL;DR: SFGNet通过结合语义提示和频域特征来提高伪装目标检测效果，并提出MBFM和ISEB模块来处理复杂背景和模糊边界，在三个数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的伪装目标检测研究忽略了不同目标文本提示的语义差异以及细粒度频率特征。

Method: 提出了一种新颖的语义和频率引导网络（SFGNet），它结合了语义提示和频域特征来捕获伪装目标并改善边界感知。设计了多频傅立叶模块（MBFM）来增强网络处理复杂背景和模糊边界的能力。设计了交互式结构增强块（ISEB）来确保预测中的结构完整性和边界细节。

Result: 所提出的SFGNet在三个COD基准数据集上的大量实验表明，其性能显著优于最先进的方法。

Conclusion: SFGNet通过结合语义提示和频域特征，并利用MBFM和ISEB模块，能够有效地检测伪装目标，提高边界感知和结构完整性，在COD任务上取得了SOTA性能。

Abstract: Camouflaged object detection (COD) aims to segment objects that blend into
their surroundings. However, most existing studies overlook the semantic
differences among textual prompts of different targets as well as fine-grained
frequency features. In this work, we propose a novel Semantic and Frequency
Guided Network (SFGNet), which incorporates semantic prompts and
frequency-domain features to capture camouflaged objects and improve boundary
perception. We further design Multi-Band Fourier Module(MBFM) to enhance the
ability of the network in handling complex backgrounds and blurred boundaries.
In addition, we design an Interactive Structure Enhancement Block (ISEB) to
ensure structural integrity and boundary details in the predictions. Extensive
experiments conducted on three COD benchmark datasets demonstrate that our
method significantly outperforms state-of-the-art approaches. The core code of
the model is available at the following link:
https://github.com/winter794444/SFGNetICASSP2026.

</details>


### [76] [How Auxiliary Reasoning Unleashes GUI Grounding in VLMs](https://arxiv.org/abs/2509.11548)
*Weiming Li,Yan Shao,Jing Yang,Yujing Lu,Ling Zhong,Yuhan Wang,Manni Duan*

Main category: cs.CV

TL;DR: 通用视觉语言模型（VLMs）在图形用户界面（GUI）基础任务上表现不佳，因为它们缺乏专门的优化。本文提出了三种零样本辅助推理方法，通过提供显式的空间线索（如图形用户界面基础任务的坐标），使VLMs能够阐述其隐式的空间理解能力，从而显著提高GUI基础任务的性能。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型（VLMs）在图形用户界面（GUI）基础任务上表现不佳，尽管它们具有显著的潜在基础能力，但输出显式坐标的能力较弱。

Method: 提出三种零样本辅助推理方法，通过在输入图像中提供显式空间线索（如轴、网格和标记的交点）来使VLMs能够阐述其隐式的空间理解能力。

Result: 在四个GUI基础任务基准和七个VLM上评估了所提出的方法，结果表明所提出的方法显著提高了GUI基础任务的性能。

Conclusion: 所提出的三种零样本辅助推理方法能够显著提高VLMs在GUI基础任务上的性能。

Abstract: Graphical user interface (GUI) grounding is a fundamental task for building
GUI agents. However, general vision-language models (VLMs) struggle with this
task due to a lack of specific optimization. We identify a key gap in this
paper: while VLMs exhibit significant latent grounding potential, as
demonstrated by their performance measured by Pointing Game, they underperform
when tasked with outputting explicit coordinates. To address this discrepancy,
and bypass the high data and annotation costs of current fine-tuning
approaches, we propose three zero-shot auxiliary reasoning methods. By
providing explicit spatial cues such as axes, grids and labeled intersections
as part of the input image, these methods enable VLMs to articulate their
implicit spatial understanding capabilities. We evaluate these methods on four
GUI grounding benchmarks across seven open-source and proprietary VLMs. The
evaluation results demonstrate that the proposed methods substantially improve
the performance of GUI grounding.

</details>


### [77] [Gaussian-Plus-SDF SLAM: High-fidelity 3D Reconstruction at 150+ fps](https://arxiv.org/abs/2509.11574)
*Zhexi Peng,Kun Zhou,Tianjia Shao*

Main category: cs.CV

TL;DR: 通过结合高斯和SDF，GPS-SLAM实现了比现有方法快十倍的实时3D重建，同时保持了可比的重建质量。


<details>
  <summary>Details</summary>
Motivation: 高斯SLAM方法在从RGB-D数据进行光线追踪重建方面表现出色，但计算性能是一个关键瓶颈，现有技术运行速度低于20fps。这个问题源于场景建模需要大量高斯和复杂的迭代优化来拟合RGB-D数据，而高斯数量或优化迭代次数不足会导致重建质量严重下降。

Method: 提出了一种高斯-SDF混合表示方法，该方法结合了用于平滑几何和外观的彩色SDF以及用于捕获代表性不足的细节的3D高斯。SDF通过RGB-D融合（如几何中心方法）进行高效构建，而高斯则经过迭代优化。这种表示方法通过避免全场景高斯建模，实现了高斯数量的大幅减少（减少50%），并通过有针对性的外观细化实现了高效的高斯优化（减少75%的迭代次数）。基于此表示方法，开发了GPS-SLAM（高斯加SDF SLAM），一个实时3D重建系统。

Result: GPS-SLAM在真实世界Azure Kinect序列上实现了超过150fps的帧率，比最先进的技术快了十倍，同时保持了可比的重建质量。

Conclusion: GPS-SLAM通过高斯-SDF混合表示实现了实时3D重建，在速度和质量方面均优于现有方法。

Abstract: While recent Gaussian-based SLAM methods achieve photorealistic
reconstruction from RGB-D data, their computational performance remains a
critical bottleneck. State-of-the-art techniques operate at less than 20 fps,
significantly lagging behind geometry-centric approaches like KinectFusion
(hundreds of fps). This limitation stems from the heavy computational burden:
modeling scenes requires numerous Gaussians and complex iterative optimization
to fit RGB-D data, where insufficient Gaussian counts or optimization
iterations cause severe quality degradation. To address this, we propose a
Gaussian-SDF hybrid representation, combining a colorized Signed Distance Field
(SDF) for smooth geometry and appearance with 3D Gaussians to capture
underrepresented details. The SDF is efficiently constructed via RGB-D fusion
(as in geometry-centric methods), while Gaussians undergo iterative
optimization. Our representation enables drastic Gaussian reduction (50% fewer)
by avoiding full-scene Gaussian modeling, and efficient Gaussian optimization
(75% fewer iterations) through targeted appearance refinement. Building upon
this representation, we develop GPS-SLAM (Gaussian-Plus-SDF SLAM), a real-time
3D reconstruction system achieving over 150 fps on real-world Azure Kinect
sequences -- delivering an order-of-magnitude speedup over state-of-the-art
techniques while maintaining comparable reconstruction quality. We will release
the source code and data to facilitate future research.

</details>


### [78] [Hierarchical Identity Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2509.11587)
*Haonan Shi,Yubin Wang,De Cheng,Lingfeng He,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TL;DR: 本文提出了一种名为“分层身份学习”（HIL）的框架，用于解决无监督可见光-红外行人重识别（USVI-ReID）问题。该框架通过引入多中心对比学习（MCCL）和双向反向选择传输（BRST）机制，旨在缩小模态间差异，同时保留细粒度的身份信息，从而提高重识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有USVI-ReID方法主要依赖聚类对比学习，但过于关注图像的共性，忽略了同一聚类内图像的细微差别。

Method: 本文提出了分层身份学习（HIL）框架。首先，通过二次聚类为每个粗粒度聚类生成多个记忆，以捕捉图像间的细粒度差异。其次，引入多中心对比学习（MCCL）来优化表示，增强模态内聚类并缩小模态间差异。最后，设计了双向反向选择传输（BRST）机制，通过伪标签的双向匹配建立可靠的跨模态对应关系。

Result: 在SYSU-MM01和RegDB数据集上的大量实验表明，该方法优于现有方法。

Conclusion: HIL框架通过引入多中心对比学习和双向反向选择传输机制，有效解决了现有USVI-ReID方法的局限性，提升了跨模态匹配的准确性。

Abstract: Unsupervised visible-infrared person re-identification (USVI-ReID) aims to
learn modality-invariant image features from unlabeled cross-modal person
datasets by reducing the modality gap while minimizing reliance on costly
manual annotations. Existing methods typically address USVI-ReID using
cluster-based contrastive learning, which represents a person by a single
cluster center. However, they primarily focus on the commonality of images
within each cluster while neglecting the finer-grained differences among them.
To address the limitation, we propose a Hierarchical Identity Learning (HIL)
framework. Since each cluster may contain several smaller sub-clusters that
reflect fine-grained variations among images, we generate multiple memories for
each existing coarse-grained cluster via a secondary clustering. Additionally,
we propose Multi-Center Contrastive Learning (MCCL) to refine representations
for enhancing intra-modal clustering and minimizing cross-modal discrepancies.
To further improve cross-modal matching quality, we design a Bidirectional
Reverse Selection Transmission (BRST) mechanism, which establishes reliable
cross-modal correspondences by performing bidirectional matching of
pseudo-labels. Extensive experiments conducted on the SYSU-MM01 and RegDB
datasets demonstrate that the proposed method outperforms existing approaches.
The source code is available at: https://github.com/haonanshi0125/HIL.

</details>


### [79] [Optimizing Class Distributions for Bias-Aware Multi-Class Learning](https://arxiv.org/abs/2509.11588)
*Mirco Felske,Stefan Stiene*

Main category: cs.CV

TL;DR: BiCDO是一个数据中心框架，用于优化多类图像分类中的类别分布，以提高模型可靠性并减少偏差。


<details>
  <summary>Details</summary>
Motivation: 为了在安全关键场景中优先考虑特定类别的性能（例如，优先考虑‘人类’而不是‘狗’），并最小化目标函数中的偏差和方差，需要确定每个类别的最佳图像数量。

Method: BiCDO采用迭代、数据中心的方法，确定帕累托最优的类别分布，以提高模型性能。

Result: 在CIFAR-10和iNaturalist21数据集上，使用EfficientNet、ResNet和ConvNeXt模型对BiCDO进行了验证，结果显示通过优化数据分布可以改善和平衡模型性能。

Conclusion: BiCDO是一个数据中心框架，可以优化多类图像分类中的类别分布，从而提高模型可靠性并减少偏差。

Abstract: We propose BiCDO (Bias-Controlled Class Distribution Optimizer), an
iterative, data-centric framework that identifies Pareto optimized class
distributions for multi-class image classification. BiCDO enables performance
prioritization for specific classes, which is useful in safety-critical
scenarios (e.g. prioritizing 'Human' over 'Dog'). Unlike uniform distributions,
BiCDO determines the optimal number of images per class to enhance reliability
and minimize bias and variance in the objective function. BiCDO can be
incorporated into existing training pipelines with minimal code changes and
supports any labelled multi-class dataset. We have validated BiCDO using
EfficientNet, ResNet and ConvNeXt on CIFAR-10 and iNaturalist21 datasets,
demonstrating improved, balanced model performance through optimized data
distribution.

</details>


### [80] [MVQA-68K: A Multi-dimensional and Causally-annotated Dataset with Quality Interpretability for Video Assessment](https://arxiv.org/abs/2509.11589)
*Yanyun Pu,Kehan Li,Zeyi Huang,Zhijie Zhong,Kaixiang Yang*

Main category: cs.CV

TL;DR: MVQA-68K是一个包含68000多个视频的多维度视频质量评估数据集，旨在解决传统VQA方法评分单一、缺乏可解释性的问题。该数据集覆盖七个维度，并提供详细的推理过程，可显著提升多模态大语言模型在视频质量评估任务上的性能，并增强其零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统视频质量评估（VQA）方法通常只产生单一数值得分，缺乏全面性和可解释性，这在需要从大规模预训练数据集中筛选高质量视频的背景下显得尤为不足。

Method: 提出MVQA-68K数据集，包含超过68,000个视频，涵盖整体美学、镜头运动、动态程度、纹理细节、构图、视觉质量和事实一致性七个关键质量维度。每个标注都附带详细的链式思考推理过程，以增强可解释性。

Result: MVQA-68K显著提升了多模态大语言模型在VQA任务上的性能，在内部测试集、LSVQ-test、LSVQ-1080p和LIVE-VQC等公开基准上均取得了最先进的成果。在VQA训练中加入显式推理过程能显著增强模型的零样本泛化能力。

Conclusion: MVQA-68K数据集通过提供多维度评估和详细的推理过程，有效解决了传统VQA方法的局限性，并能显著提升多模态大语言模型在视频质量评估及其泛化能力方面的表现。

Abstract: With the rapid advancement of video generation models such as Sora, video
quality assessment (VQA) is becoming increasingly crucial for selecting
high-quality videos from large-scale datasets used in pre-training. Traditional
VQA methods, typically producing single numerical scores, often lack
comprehensiveness and interpretability. To address these challenges, we
introduce MVQA-68K, a novel multi-dimensional VQA dataset comprising over
68,000 carefully annotated videos, covering seven essential quality dimensions:
overall aesthetics, camera movement, dynamic degree, texture detail,
composition, visual quality, and factual consistency. Each annotation includes
detailed chain-of-thought reasoning to facilitate interpretability and
comprehensive understanding. Extensive experiments demonstrate that MVQA-68K
significantly enhances the performance of various multimodal large language
models (MLLMs) on the VQA task, achieving state-of-the-art results not only on
our internal test set (Fig.1) but also on public benchmarks including
LSVQ-test, LSVQ-1080p, and LIVE-VQC. Meantime, incorporating explicit reasoning
process during VQA training substantially boosts the zero-shot generalization.
Code and dataset will be available at github:
https://github.com/Controller01-ai/MVQA-68K

</details>


### [81] [Disentangling Content from Style to Overcome Shortcut Learning: A Hybrid Generative-Discriminative Learning Framework](https://arxiv.org/abs/2509.11598)
*Siming Fu,Sijun Dong,Xiaoliang Meng*

Main category: cs.CV

TL;DR: SSL在生成范式中存在短路学习问题，导致模型倾向于利用表面特征而非内在结构，这也会影响判别式方法。HyGDL框架通过混合生成和判别式学习，并遵循不变性预训练原则，实现内容-风格解耦，强制模型学习不变的本质。


<details>
  <summary>Details</summary>
Motivation: 现有的SSL方法在泛化能力上受到短路学习的限制，即模型倾向于利用纹理等表面特征而非内在结构。这不仅在生成范式中存在，也是判别式方法在未见域上失败的根本原因。现有方法仅从表面上处理，未能改变导致短路依赖的潜在学习机制。

Method: 提出HyGDL（混合生成-判别式学习框架），一个实现显式内容-风格解耦的混合框架。该方法遵循不变性预训练原则，通过系统地改变输入中的偏差（例如风格）并保持监督信号不变，迫使模型学习不变的本质。HyGDL在单个编码器上运行，并通过向量投影将风格定义为与风格不变内容正交的表示分量。

Result: HyGDL框架实现了显式的内容-风格解耦，并通过不变性预训练原则强制模型学习不变的本质，从而解决短路学习问题。

Conclusion: HyGDL通过内容-风格解耦和不变性预训练原则，从根本上解决了SSL中的短路学习问题，提高了模型在未见域上的泛化能力。

Abstract: Despite the remarkable success of Self-Supervised Learning (SSL), its
generalization is fundamentally hindered by Shortcut Learning, where models
exploit superficial features like texture instead of intrinsic structure. We
experimentally verify this flaw within the generative paradigm (e.g., MAE) and
argue it is a systemic issue also affecting discriminative methods, identifying
it as the root cause of their failure on unseen domains. While existing methods
often tackle this at a surface level by aligning or separating domain-specific
features, they fail to alter the underlying learning mechanism that fosters
shortcut dependency. To address this at its core, we propose HyGDL (Hybrid
Generative-Discriminative Learning Framework), a hybrid framework that achieves
explicit content-style disentanglement. Our approach is guided by the
Invariance Pre-training Principle: forcing a model to learn an invariant
essence by systematically varying a bias (e.g., style) at the input while
keeping the supervision signal constant. HyGDL operates on a single encoder and
analytically defines style as the component of a representation that is
orthogonal to its style-invariant content, derived via vector projection.

</details>


### [82] [DUAL-VAD: Dual Benchmarks and Anomaly-Focused Sampling for Video Anomaly Detection](https://arxiv.org/abs/2509.11605)
*Seoik Jung,Taekyung Song,Joshua Jordan Daniel,JinYoung Lee,SungJun Lee*

Main category: cs.CV

TL;DR: 本研究提出了一种基于softmax的帧分配策略，用于视频异常检测，通过优先选择异常密集的片段并实现跨时间尺度的平衡采样，构建了图像级和视频级两个互补的基准测试，并在UCF-Crime数据集上进行了实验，证明了该方法在帧和视频层面的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的视频异常检测（VAD）基准测试在帧级或视频级任务上存在局限性，阻碍了对模型泛化能力的全面评估。因此，需要一种能够提供更全面模型评估的基准测试。

Method: 提出了一种基于softmax的帧分配策略，该策略优先选择异常密集的视频片段，同时保证对整个视频的覆盖，从而实现跨时间尺度的平衡采样。在此基础上，构建了两个互补的基准测试：一个是侧重于帧级推理的图像级基准测试，另一个是扩展到时间局部化片段并包含异常评分任务的视频级基准测试。

Result: 在UCF-Crime数据集上的实验表明，该方法在帧级和视频级都取得了改进。消融研究证实了异常聚焦采样相对于均匀和随机基线的明显优势。

Conclusion: 所提出的基于softmax的帧分配策略和构建的互补基准测试，能够有效地提升视频异常检测模型的性能，并为评估模型泛化能力提供了更全面的视角。

Abstract: Video Anomaly Detection (VAD) is critical for surveillance and public safety.
However, existing benchmarks are limited to either frame-level or video-level
tasks, restricting a holistic view of model generalization. This work first
introduces a softmax-based frame allocation strategy that prioritizes
anomaly-dense segments while maintaining full-video coverage, enabling balanced
sampling across temporal scales. Building on this process, we construct two
complementary benchmarks. The image-based benchmark evaluates frame-level
reasoning with representative frames, while the video-based benchmark extends
to temporally localized segments and incorporates an abnormality scoring
task.Experiments on UCF-Crime demonstrate improvements at both the frame and
video levels, and ablation studies confirm clear advantages of anomaly-focused
sampling over uniform and random baselines.

</details>


### [83] [A Controllable 3D Deepfake Generation Framework with Gaussian Splatting](https://arxiv.org/abs/2509.11624)
*Wending Liu,Siyun Liang,Huy H. Nguyen,Isao Echizen*

Main category: cs.CV

TL;DR: 本研究提出了一种基于3D高斯泼溅的新型3D深度伪造生成框架，可在完全可控的3D空间中实现逼真、保留身份的面部交换和重新表演。


<details>
  <summary>Details</summary>
Motivation: 与传统的2D深度伪造方法相比，本方法克服了几何不一致和在新视图上泛化能力有限的缺点，实现了多视图一致渲染、精确表情控制和无缝背景集成。

Method: 本研究结合了参数化头部模型和动态高斯表示，显式分离头部和背景高斯，并利用预训练的2D引导优化面部区域，同时引入修复模块以增强极端姿态和表情下的视觉一致性。

Result: 在NeRSemble数据集和其他评估视频上的实验表明，本方法在身份保持、姿态和表情一致性方面达到了与最先进的2D方法相当的性能，并在多视图渲染质量和3D一致性方面显著优于它们。

Conclusion: 本研究将3D建模和深度伪造合成联系起来，为场景感知、可控和身临其境的视觉伪造开辟了新方向，并揭示了新兴的3D高斯泼溅技术可能被用于操纵攻击的威胁。

Abstract: We propose a novel 3D deepfake generation framework based on 3D Gaussian
Splatting that enables realistic, identity-preserving face swapping and
reenactment in a fully controllable 3D space. Compared to conventional 2D
deepfake approaches that suffer from geometric inconsistencies and limited
generalization to novel view, our method combines a parametric head model with
dynamic Gaussian representations to support multi-view consistent rendering,
precise expression control, and seamless background integration. To address
editing challenges in point-based representations, we explicitly separate the
head and background Gaussians and use pre-trained 2D guidance to optimize the
facial region across views. We further introduce a repair module to enhance
visual consistency under extreme poses and expressions. Experiments on
NeRSemble and additional evaluation videos demonstrate that our method achieves
comparable performance to state-of-the-art 2D approaches in identity
preservation, as well as pose and expression consistency, while significantly
outperforming them in multi-view rendering quality and 3D consistency. Our
approach bridges the gap between 3D modeling and deepfake synthesis, enabling
new directions for scene-aware, controllable, and immersive visual forgeries,
revealing the threat that emerging 3D Gaussian Splatting technique could be
used for manipulation attacks.

</details>


### [84] [IS-Diff: Improving Diffusion-Based Inpainting with Better Initial Seed](https://arxiv.org/abs/2509.11638)
*Yongzhe Lyu,Yu Wu,Yutian Lin,Bo Du*

Main category: cs.CV

TL;DR: IS-Diff 通过使用来自分配区域的种子来改进自由形式的图像修复，从而实现更一致、更连贯的修复结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的图像修复方法在随机初始化种子时可能会引入语义不匹配的信息，导致修复结果不佳，例如一致性和连贯性不足。

Method: IS-Diff 提出了一种完全无需训练的方法，该方法采用来自未遮罩区域的初始种子来模仿遮罩数据的分布，并结合动态选择性细化机制来调整初始化先验的强度。

Result: IS-Diff 在 CelebA-HQ、ImageNet 和 Places2 数据集上进行了标准和大型遮罩图像修复任务的验证，所有指标均优于现有最先进的图像修复方法。

Conclusion: IS-Diff 通过使用分布和谐的种子来解决随机种子引入的不匹配语义信息的问题，从而改进了自由形式的图像修复。

Abstract: Diffusion models have shown promising results in free-form inpainting. Recent
studies based on refined diffusion samplers or novel architectural designs led
to realistic results and high data consistency. However, random initialization
seed (noise) adopted in vanilla diffusion process may introduce mismatched
semantic information in masked regions, leading to biased inpainting results,
e.g., low consistency and low coherence with the other unmasked area. To
address this issue, we propose the Initial Seed refined Diffusion Model
(IS-Diff), a completely training-free approach incorporating distributional
harmonious seeds to produce harmonious results. Specifically, IS-Diff employs
initial seeds sampled from unmasked areas to imitate the masked data
distribution, thereby setting a promising direction for the diffusion
procedure. Moreover, a dynamic selective refinement mechanism is proposed to
detect severe unharmonious inpaintings in intermediate latent and adjust the
strength of our initialization prior dynamically. We validate our method on
both standard and large-mask inpainting tasks using the CelebA-HQ, ImageNet,
and Places2 datasets, demonstrating its effectiveness across all metrics
compared to state-of-the-art inpainting methods.

</details>


### [85] [WeatherBench: A Real-World Benchmark Dataset for All-in-One Adverse Weather Image Restoration](https://arxiv.org/abs/2509.11642)
*Qiyuan Guan,Qianfeng Yang,Xiang Chen,Tianyu Song,Guiyue Jin,Jiyu Jin*

Main category: cs.CV

TL;DR: 现有的多合一图像恢复方法主要在混合单一天气合成数据集上进行训练和评估，但这些数据集在分辨率、风格和域特征上存在显著差异，导致域间隙阻碍了统一模型的开发和公平评估。此外，缺乏大规模的真实世界多合一恶劣天气图像恢复数据集是该领域发展的一个关键瓶颈。为了解决这些局限性，我们提出了一个真实世界的全能型恶劣天气图像恢复基准数据集，其中包含在各种天气条件（包括雨、雪和雾霾）以及不同的户外场景和光照条件下捕获的图像对。结果数据集提供了精确对齐的退化图像和干净图像，能够进行监督学习和严格评估。我们在我们的数据集上对各种特定任务、通用任务和全能型恢复方法进行了全面的实验。我们的数据集为在真实世界场景中推进健壮实用的全能型图像恢复提供了有价值的基础。


<details>
  <summary>Details</summary>
Motivation: 现有的多合一图像恢复方法在处理真实世界中的多重天气退化方面存在挑战，主要是由于合成数据集与真实世界数据之间存在显著的域间隙，并且缺乏大规模、真实的世界的数据集来进行公平评估和模型开发。

Method: 提出并构建了一个真实世界的全能型恶劣天气图像恢复基准数据集，该数据集包含各种天气条件（雨、雪、雾霾）和场景下的成对图像，并确保了退化图像和干净图像的精确对齐，以便进行监督学习和评估。随后，在该数据集上对多种恢复方法进行了全面的基准测试。

Result: 创建了一个包含成对真实世界恶劣天气图像的数据集，并对现有恢复方法进行了广泛的基准测试，为该领域的研究提供了基础。

Conclusion: 提出了一个真实世界的全能型恶劣天气图像恢复基准数据集，解决了现有方法的局限性，并为开发更强大、更实用的全能型图像恢复模型提供了基础。

Abstract: Existing all-in-one image restoration approaches, which aim to handle
multiple weather degradations within a single framework, are predominantly
trained and evaluated using mixed single-weather synthetic datasets. However,
these datasets often differ significantly in resolution, style, and domain
characteristics, leading to substantial domain gaps that hinder the development
and fair evaluation of unified models. Furthermore, the lack of a large-scale,
real-world all-in-one weather restoration dataset remains a critical bottleneck
in advancing this field. To address these limitations, we present a real-world
all-in-one adverse weather image restoration benchmark dataset, which contains
image pairs captured under various weather conditions, including rain, snow,
and haze, as well as diverse outdoor scenes and illumination settings. The
resulting dataset provides precisely aligned degraded and clean images,
enabling supervised learning and rigorous evaluation. We conduct comprehensive
experiments by benchmarking a variety of task-specific, task-general, and
all-in-one restoration methods on our dataset. Our dataset offers a valuable
foundation for advancing robust and practical all-in-one image restoration in
real-world scenarios. The dataset has been publicly released and is available
at https://github.com/guanqiyuan/WeatherBench.

</details>


### [86] [Joint-octamamba:an octa joint segmentation network based on feature enhanced mamba](https://arxiv.org/abs/2509.11649)
*Chuang Liu,Nan Guo*

Main category: cs.CV

TL;DR: RVMamba是一种新的OCTA视网膜血管分割架构，而Joint-OCTAMamba框架通过集成FAZMamba来解决FAZ分割和任务不平衡问题，并在OCTA-500数据集上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的二维视网膜血管分割方法在准确性方面存在不足，并且现有的联合分割模型在不同任务之间存在性能不平衡的问题。

Method: 提出了一种名为RVMamba的新架构，它集成了多个特征提取模块和Mamba状态空间模型。为了解决FAZ分割和任务不平衡问题，引入了FAZMamba和统一的Joint-OCTAMamba框架。

Result: 在OCTA-500数据集上的实验结果表明，Joint-OCTAMamba在各项评估指标上均优于现有模型。

Conclusion: 所提出的Joint-OCTAMamba框架能够有效提升OCTA数据中FAZ分割的准确性，并缓解了不同任务之间的性能不平衡问题，优于现有方法。

Abstract: OCTA is a crucial non-invasive imaging technique for diagnosing and
monitoring retinal diseases like diabetic retinopathy, age-related macular
degeneration, and glaucoma. Current 2D-based methods for retinal vessel (RV)
segmentation offer insufficient accuracy. To address this, we propose RVMamba,
a novel architecture integrating multiple feature extraction modules with the
Mamba state-space model. Moreover, existing joint segmentation models for OCTA
data exhibit performance imbalance between different tasks. To simultaneously
improve the segmentation of the foveal avascular zone (FAZ) and mitigate this
imbalance, we introduce FAZMamba and a unified Joint-OCTAMamba framework.
Experimental results on the OCTA-500 dataset demonstrate that Joint-OCTAMamba
outperforms existing models across evaluation metrics.The code is available at
https://github.com/lc-sfis/Joint-OCTAMamba.

</details>


### [87] [DTGen: Generative Diffusion-Based Few-Shot Data Augmentation for Fine-Grained Dirty Tableware Recognition](https://arxiv.org/abs/2509.11661)
*Lifei Hao,Yue Cheng,Baoqi Huang,Bing Jia,Xuandong Zhao*

Main category: cs.CV

TL;DR: DTGen是一个基于生成扩散模型的数据增强方案，用于解决少样本的细粒度脏污餐具识别问题，通过LoRA实现领域特化，利用结构化提示生成多样化图像，并结合CLIP进行跨模态过滤，在极少样本条件下能合成大量高质量样本，显著提升分类器性能，并提出轻量化部署策略，最终实现自动化餐具清洁和食品安全监控。


<details>
  <summary>Details</summary>
Motivation: 现有餐具清洗方法在细粒度分类和少样本数据方面存在不足，难以满足工业化需求。

Method: 提出DTGen，一个基于生成扩散模型的数据增强方案，利用LoRA进行领域特化，通过结构化提示生成图像，并使用CLIP进行跨模态过滤。

Result: 在极少样本条件下，DTGen能合成大量高质量样本，显著提升分类器性能，并提出了轻量化部署策略。

Conclusion: DTGen证明了生成式AI在少样本工业视觉领域的价值，并为自动化餐具清洁和食品安全监控提供了可行的部署路径。

Abstract: Intelligent tableware cleaning is a critical application in food safety and
smart homes, but existing methods are limited by coarse-grained classification
and scarcity of few-shot data, making it difficult to meet industrialization
requirements. We propose DTGen, a few-shot data augmentation scheme based on
generative diffusion models, specifically designed for fine-grained dirty
tableware recognition. DTGen achieves efficient domain specialization through
LoRA, generates diverse dirty images via structured prompts, and ensures data
quality through CLIP-based cross-modal filtering. Under extremely limited real
few-shot conditions, DTGen can synthesize virtually unlimited high-quality
samples, significantly improving classifier performance and supporting
fine-grained dirty tableware recognition. We further elaborate on lightweight
deployment strategies, promising to transfer DTGen's benefits to embedded
dishwashers and integrate with cleaning programs to intelligently regulate
energy consumption and detergent usage. Research results demonstrate that DTGen
not only validates the value of generative AI in few-shot industrial vision but
also provides a feasible deployment path for automated tableware cleaning and
food safety monitoring.

</details>


### [88] [MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs](https://arxiv.org/abs/2509.11662)
*Feilong Chen,Yijiang Liu,Yi Huang,Hao Wang,Miren Tian,Ya-Qi Yu,Minghui Liao,Jihao Wu*

Main category: cs.CV

TL;DR: MindVL是一个在Ascend NPUs上训练的多模态大语言模型，它采用原生分辨率Vision Transformers和Mindspeed-MLLM分布式训练框架，通过三阶段训练和优化技术，在保证训练精度的同时，显著提高了训练速度，并在通用多模态理解、文档/表格理解和OCR评估中取得了与Qwen2.5-VL相当甚至更优的性能，尽管训练数据量仅为Qwen2.5-VL的约十分之一。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有模型在处理视觉密集内容时可能存在的细节损失问题，并为Ascend NPUs平台开发高效的多模态大模型训练方法。

Method: MindVL采用原生分辨率Vision Transformers处理图像，并开发了针对Ascend NPUs的Mindspeed-MLLM分布式训练框架。训练过程分为三个阶段：预训练、多任务训练和监督指令微调。此外，还采用了多模态数据打包、混合并行、测试时分辨率搜索和模型权重平均等技术。

Result: MindVL在通用多模态理解、文档/表格理解和OCR评估方面取得了与Qwen2.5-VL相当的性能，甚至在OCR方面表现更优。在训练效率方面，MindVL使用了约十分之一的训练数据，并显著提高了端到端训练速度。

Conclusion: MindVL是一个高效且性能优越的多模态大语言模型，特别适合在Ascend NPUs上进行训练和部署。其创新的方法使其在处理复杂视觉内容和多种下游任务时表现出色。

Abstract: We propose MindVL, a multimodal large langauge model trained on Ascend NPUs.
Similar to Qwen2.5-VL, MindVL adopts native-resolution Vision Transformers,
which enables it to process images at their original variable resolutions. This
design avoids the degradation caused by fixed-resolution tiling while
preserving fine-grained details and global layouts, which is crucial for
visually dense content such as complex charts and diagrams. To ensure the
smooth training of MindVL on Ascend NPUs, we develop Mindspeed-MLLM, a
distributed multimodal training framework tailored for Ascend NPUs. To maintain
training accuracy, we implement equivalent replacements for certain operators.
MindVL undergoes a three-phase training process, namely the warm-up phase,
multitask training phase, and supervised instruction tuning phase, to gradually
enhance its capabilities. This process starts with basic visual and multimodal
pre-training, followed by large-scale multiask trainging and instruction
tuning. We also adopt multimodal data packaging and hybrid parallelism
techniques, which significantly improve end-to-end training speed. To further
boost model performance, we specifically introduce test-time resolution search
and model weight averaging. Notably, despite using about 1/10 of the training
data required by Qwen2.5-VL, MindVL achieves performance on par with Qwen2.5-VL
in evaluations of general multimodal understanding and document/table
comprehension. Beyond overall scores, MindVL also delivers leading performance
in OCR assessments.

</details>


### [89] [RouteExtract: A Modular Pipeline for Extracting Routes from Paper Maps](https://arxiv.org/abs/2509.11674)
*Bjoern Kremser,Yusuke Matsui*

Main category: cs.CV

TL;DR: 本研究提出了一种从扫描地图中提取可导航路径的方法，用于GPS导航。


<details>
  <summary>Details</summary>
Motivation: 纸质地图包含数字导航应用（如谷歌地图）通常缺失的精选步道和本地相关注释，因此在远足和观光中仍被广泛使用。

Method: 该方法结合了地理配准、U-Net（一种U形网络）分割、图构建和迭代优化。

Result: 研究评估了整个端到端流程以及各个组件，表明该方法能够从不同风格的地图中稳健地恢复步道网络，并生成适用于实际使用的GPS路线。

Conclusion: 所提出的方法能够有效地从扫描地图中提取步道信息，并生成可用于GPS导航的路线，弥补了数字导航应用的不足。

Abstract: Paper maps remain widely used for hiking and sightseeing because they contain
curated trails and locally relevant annotations that are often missing from
digital navigation applications such as Google Maps. We propose a pipeline to
extract navigable trails from scanned maps, enabling their use in GPS-based
navigation. Our method combines georeferencing, U-Net-based binary
segmentation, graph construction, and an iterative refinement procedure using a
routing engine. We evaluate the full end-to-end pipeline as well as individual
components, showing that the approach can robustly recover trail networks from
diverse map styles and generate GPS routes suitable for practical use.

</details>


### [90] [IMD: A 6-DoF Pose Estimation Benchmark for Industrial Metallic Objects](https://arxiv.org/abs/2509.11680)
*Ruimin Ma,Sebastian Zudaire,Zhen Li,Chi Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一个名为IMD的新数据集和基准测试，用于工业场景中的物体6D姿态估计，解决了现有数据集在工业应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有物体6D姿态估计的基准测试主要使用纹理丰富、低反射的日常物体，泛化能力有限，无法满足工业场景中物体通常具有金属、无纹理、高反射等特点的需求。

Method: 创建了一个名为IMD（Industrial Metallic Dataset）的新数据集和基准测试。该数据集包含45个工业组件，使用RGB-D相机在自然室内光照和不同物体排列下采集，以复制真实工业环境。基准测试支持视频物体分割、6D姿态跟踪和单次6D姿态估计三个任务，并评估了XMem、SAM2、BundleTrack和BundleSDF等现有SOTA模型。

Result: 评估结果表明，IMD数据集比现有的日常物体数据集更具挑战性，现有SOTA模型在IMD上的表现不如在日常物体数据集上。

Conclusion: IMD数据集和基准测试为开发和比较更能泛化到工业机器人应用场景的分割和姿态估计算法提供了基线。

Abstract: Object 6DoF (6D) pose estimation is essential for robotic perception,
especially in industrial settings. It enables robots to interact with the
environment and manipulate objects. However, existing benchmarks on object 6D
pose estimation primarily use everyday objects with rich textures and
low-reflectivity, limiting model generalization to industrial scenarios where
objects are often metallic, texture-less, and highly reflective. To address
this gap, we propose a novel dataset and benchmark namely \textit{Industrial
Metallic Dataset (IMD)}, tailored for industrial applications. Our dataset
comprises 45 true-to-scale industrial components, captured with an RGB-D camera
under natural indoor lighting and varied object arrangements to replicate
real-world conditions. The benchmark supports three tasks, including video
object segmentation, 6D pose tracking, and one-shot 6D pose estimation. We
evaluate existing state-of-the-art models, including XMem and SAM2 for
segmentation, and BundleTrack and BundleSDF for pose estimation, to assess
model performance in industrial contexts. Evaluation results show that our
industrial dataset is more challenging than existing household object datasets.
This benchmark provides the baseline for developing and comparing segmentation
and pose estimation algorithms that better generalize to industrial robotics
scenarios.

</details>


### [91] [Uncertainty-Aware Retinal Vessel Segmentation via Ensemble Distillation](https://arxiv.org/abs/2509.11689)
*Jeremiah Fadugba,Petru Manescu,Bolanle Oladejo,Delmiro Fernandez-Reyes,Philipp Berens*

Main category: cs.CV

TL;DR: 通过知识蒸馏将多个集成模型融合到单个模型中，以实现视网膜血管分割的可靠不确定性估计，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 提高医学图像分割（特别是视网膜血管分析）的可靠性，同时降低深度集成方法带来的训练和测试成本。

Method: 提出了一种名为“集成蒸馏”的方法，将多个集成模型的知识蒸馏到一个单独的模型中，以进行不确定性估计。

Result: 在DRIVE和FIVES数据集上进行了广泛的实验，结果表明集成蒸馏在校准和分割指标上达到了与深度集成相当的性能，同时显著降低了计算复杂度。

Conclusion: 集成蒸馏为视网膜血管分割的不确定性估计提供了一种高效且可靠的方法，在医学影像应用中具有应用前景。

Abstract: Uncertainty estimation is critical for reliable medical image segmentation,
particularly in retinal vessel analysis, where accurate predictions are
essential for diagnostic applications. Deep Ensembles, where multiple networks
are trained individually, are widely used to improve medical image segmentation
performance. However, training and testing costs increase with the number of
ensembles. In this work, we propose Ensemble Distillation as a robust
alternative to commonly used uncertainty estimation techniques by distilling
the knowledge of multiple ensemble models into a single model. Through
extensive experiments on the DRIVE and FIVES datasets, we demonstrate that
Ensemble Distillation achieves comparable performance via calibration and
segmentation metrics, while significantly reducing computational complexity.
These findings suggest that Ensemble distillation provides an efficient and
reliable approach for uncertainty estimation in the segmentation of the retinal
vessels, making it a promising tool for medical imaging applications.

</details>


### [92] [The Quest for Universal Master Key Filters in DS-CNNs](https://arxiv.org/abs/2509.11711)
*Zahra Babaiee,Peyman M. Kiassari,Daniela Rus,Radu Grosu*

Main category: cs.CV

TL;DR: 深度可分离卷积网络（DS-CNN）本质上会收敛到一组8个通用滤波器，这些滤波器是原始假设的“主键滤波器”的简化版本，并且在各种任务和数据集上都表现出色。


<details>
  <summary>Details</summary>
Motivation: 扩展了现有的“主键滤波器假设”，将范围缩小到一组8个固定的通用滤波器，这些滤波器是深度可分离卷积网络（DS-CNN）固有收敛的对象。

Method: 通过系统的无监督搜索，在不同的网络结构和数据集上提取了这些基本的空间模式，并分析了传统DS-CNNs中的滤波器与这组通用滤波器的关系。

Result: 发现传统DS-CNNs中的数千个滤波器主要是这8个通用滤波器集合的线性变换。使用这8个固定的通用滤波器初始化网络，在ImageNet上实现了超过80%的准确率，并且在较小的数据集上优于具有数千个可训练参数的模型。

Conclusion: 深度卷积层无论在什么任务或结构下，都倾向于使用一组基本的空间算子。这组算子与经典图像处理和哺乳动物视觉系统的感受野相似。这为理解泛化和迁移学习提供了新的视角。

Abstract: A recent study has proposed the "Master Key Filters Hypothesis" for
convolutional neural network filters. This paper extends this hypothesis by
radically constraining its scope to a single set of just 8 universal filters
that depthwise separable convolutional networks inherently converge to. While
conventional DS-CNNs employ thousands of distinct trained filters, our analysis
reveals these filters are predominantly linear shifts (ax+b) of our discovered
universal set. Through systematic unsupervised search, we extracted these
fundamental patterns across different architectures and datasets. Remarkably,
networks initialized with these 8 unique frozen filters achieve over 80%
ImageNet accuracy, and even outperform models with thousands of trainable
parameters when applied to smaller datasets. The identified master key filters
closely match Difference of Gaussians (DoGs), Gaussians, and their derivatives,
structures that are not only fundamental to classical image processing but also
strikingly similar to receptive fields in mammalian visual systems. Our
findings provide compelling evidence that depthwise convolutional layers
naturally gravitate toward this fundamental set of spatial operators regardless
of task or architecture. This work offers new insights for understanding
generalization and transfer learning through the universal language of these
master key filters.

</details>


### [93] [Advanced Layout Analysis Models for Docling](https://arxiv.org/abs/2509.11720)
*Nikolaos Livathinos,Christoph Auer,Ahmed Nassar,Rafael Teixeira de Lima,Maksym Lysak,Brown Ebouky,Cesar Berrospi,Michele Dolfi,Panagiotis Vagenas,Matteo Omenetti,Kasper Dinkla,Yusik Kim,Valery Weber,Lucas Morin,Ingmar Meijer,Viktor Kuropiatnyk,Tim Strohmeyer,A. Said Gurbuz,Peter W. J. Staar*

Main category: cs.CV

TL;DR: 本技术报告介绍了Docling文档转换流程中集成的新型布局分析模型。我们使用150,000份公开和专有的异构文档训练了基于RT-DETR、RT-DETRv2和DFINE的先进目标检测器。通过后处理步骤优化原始检测结果以适应文档转换任务。我们在多个文档基准上使用不同方法评估了布局分析的有效性，并测量了在CPU、Nvidia和Apple GPU上的运行时性能。我们的五个新模型比Docling之前的基线mAP提高了20.6%-23.9%，运行时性能相当或更好。最佳模型“heron-101”在NVIDIA A100 GPU上达到了78% mAP和28毫秒/图像的推理时间。广泛的定量和定性实验为文档布局检测器的训练、评估和部署确立了最佳实践，为文档转换社区提供了可行的指导。所有训练好的检查点、代码和文档均在HuggingFace上以宽松的许可证发布。


<details>
  <summary>Details</summary>
Motivation: 开发集成到Docling文档转换流程中的新型布局分析模型。

Method: 在150,000份异构文档上训练了基于RT-DETR、RT-DETRv2和DFINE的先进目标检测器，并进行了后处理。在多个文档基准上评估了布局分析的有效性，并测量了不同环境下的运行时性能。

Result: 引入了五个新的文档布局模型，与Docling之前的基线相比，mAP提高了20.6%-23.9%，运行时性能相当或更好。最佳模型“heron-101”在NVIDIA A100 GPU上达到了78% mAP和28毫秒/图像的推理时间。

Conclusion: 通过广泛的实验，为文档布局检测器的训练、评估和部署确立了最佳实践，并提供了可行的指导。所有代码、模型和文档均已发布。

Abstract: This technical report documents the development of novel Layout Analysis
models integrated into the Docling document-conversion pipeline. We trained
several state-of-the-art object detectors based on the RT-DETR, RT-DETRv2 and
DFINE architectures on a heterogeneous corpus of 150,000 documents (both openly
available and proprietary). Post-processing steps were applied to the raw
detections to make them more applicable to the document conversion task. We
evaluated the effectiveness of the layout analysis on various document
benchmarks using different methodologies while also measuring the runtime
performance across different environments (CPU, Nvidia and Apple GPUs). We
introduce five new document layout models achieving 20.6% - 23.9% mAP
improvement over Docling's previous baseline, with comparable or better
runtime. Our best model, "heron-101", attains 78% mAP with 28 ms/image
inference time on a single NVIDIA A100 GPU. Extensive quantitative and
qualitative experiments establish best practices for training, evaluating, and
deploying document-layout detectors, providing actionable guidance for the
document conversion community. All trained checkpoints, code, and documentation
are released under a permissive license on HuggingFace.

</details>


### [94] [Microsurgical Instrument Segmentation for Robot-Assisted Surgery](https://arxiv.org/abs/2509.11727)
*Tae Kyeong Jeong,Garam Kim,Juyoun Park*

Main category: cs.CV

TL;DR: MISRA是一个用于机器人辅助显微手术分割的框架，通过融合RGB和亮度通道、使用跳步注意力机制和迭代反馈模块来提高薄结构的分割精度，并引入了新的数据集进行评估。


<details>
  <summary>Details</summary>
Motivation: 准确分割薄结构对于显微手术场景理解至关重要，但由于分辨率损失、低对比度和类别不平衡等问题，分割仍然具有挑战性。

Method: MISRA框架通过融合RGB输入和亮度通道、集成跳步注意力机制来保留细长特征，并采用迭代反馈模块（IFM）来恢复多重输入的连续性。

Result: MISRA在显微器械分割任务上取得了有竞争力的性能，平均类别IoU比现有方法提高了5.37%，在器械接触和重叠处提供了更稳定的预测。

Conclusion: MISRA在可靠的计算机辅助和机器人显微手术场景解析方面迈出了重要一步。

Abstract: Accurate segmentation of thin structures is critical for microsurgical scene
understanding but remains challenging due to resolution loss, low contrast, and
class imbalance. We propose Microsurgery Instrument Segmentation for Robotic
Assistance(MISRA), a segmentation framework that augments RGB input with
luminance channels, integrates skip attention to preserve elongated features,
and employs an Iterative Feedback Module(IFM) for continuity restoration across
multiple passes. In addition, we introduce a dedicated microsurgical dataset
with fine-grained annotations of surgical instruments including thin objects,
providing a benchmark for robust evaluation Dataset available at
https://huggingface.co/datasets/KIST-HARILAB/MISAW-Seg. Experiments demonstrate
that MISRA achieves competitive performance, improving the mean class IoU by
5.37% over competing methods, while delivering more stable predictions at
instrument contacts and overlaps. These results position MISRA as a promising
step toward reliable scene parsing for computer-assisted and robotic
microsurgery.

</details>


### [95] [Bridging the Gap Between Sparsity and Redundancy: A Dual-Decoding Framework with Global Context for Map Inference](https://arxiv.org/abs/2509.11731)
*Yudong Shen,Wenyu Wu,Jiali Mao,Yixiao Tong,Guoping Liu,Chaoya Wang*

Main category: cs.CV

TL;DR: DGMap是一个双解码框架，通过多尺度网格编码、掩码增强的关键点提取和全局上下文感知关系预测，有效解决了轨迹数据不均导致的道路图构建碎片化和冗余问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理轨迹数据不均（稀疏区域道路碎片化，密集区域冗余）方面存在挑战。

Method: DGMap框架包括多尺度网格编码、掩码增强的关键点提取和全局上下文感知关系预测。该方法结合全局语义上下文和局部几何特征，提高了关键点检测精度，并通过建模长轨迹模式抑制了错误连接。

Result: DGMap在三个真实世界数据集上进行了实验，取得了优于现有方法的性能，在APLS方面提高了5%，尤其在滴滴出行平台上轨迹数据的性能提升显著。

Conclusion: DGMap通过整合全局和局部特征，有效解决了轨迹数据不均带来的挑战，显著提高了道路图推断的准确性和效率。

Abstract: Trajectory data has become a key resource for automated map in-ference due to
its low cost, broad coverage, and continuous availability. However, uneven
trajectory density often leads to frag-mented roads in sparse areas and
redundant segments in dense regions, posing significant challenges for existing
methods. To address these issues, we propose DGMap, a dual-decoding framework
with global context awareness, featuring Multi-scale Grid Encoding,
Mask-enhanced Keypoint Extraction, and Global Context-aware Relation
Prediction. By integrating global semantic context with local geometric
features, DGMap improves keypoint detection accuracy to reduce road
fragmentation in sparse-trajectory areas. Additionally, the Global
Context-aware Relation Prediction module suppresses false connections in
dense-trajectory regions by modeling long-range trajectory patterns.
Experimental results on three real-world datasets show that DGMap outperforms
state-of-the-art methods by 5% in APLS, with notable performance gains on
trajectory data from the Didi Chuxing platform

</details>


### [96] [A Fully Open and Generalizable Foundation Model for Ultrasound Clinical Applications](https://arxiv.org/abs/2509.11752)
*Hongyuan Zhang,Yuheng Wu,Mingyang Zhao,Zhiwei Chen,Rebecca Li,Fei Zhu,Haohan Zhao,Xiaohua Yuan,Meng Yang,Chunli Qiu,Xiang Cong,Haiyan Chen,Lina Luan,Randolph H. L. Wong,Huai Liao,Colin A Graham,Shi Chang,Guowei Tao,Dong Yi,Zhen Lei,Nassir Navab,Sebastien Ourselin,Jiebo Luo,Hongbin Liu,Gaofeng Meng*

Main category: cs.CV

TL;DR: EchoCare是一个创新的超声基础模型，通过自监督学习和大规模多源数据实现，能够处理多种临床超声任务，并在10个基准测试中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现实世界中超声数据集的稀缺性以及特定任务模型的泛化能力有限，阻碍了通用临床AI模型的发展。

Method: 提出了一种名为EchoCare的新型超声基础模型，该模型通过在包含450万张图像的EchoCareData数据集上进行自监督学习来开发。该数据集包含来自23个国家/地区的多种成像设备的数据。EchoCare引入了一个分层分类器，用于联合学习像素级和表示级特征，以捕捉全局解剖结构和局部超声特征。

Result: EchoCare在10个代表性超声基准测试中，包括疾病诊断、病变分割、器官检测、标志点预测、定量回归、成像增强和报告生成，均优于最先进的比较模型，仅需少量训练。

Conclusion: EchoCare是一个开放且可泛化的基础模型，旨在促进各种临床超声应用AI技术的发展。

Abstract: Artificial intelligence (AI) that can effectively learn ultrasound
representations by integrating multi-source data holds significant promise for
advancing clinical care. However, the scarcity of large labeled datasets in
real-world clinical environments and the limited generalizability of
task-specific models have hindered the development of generalizable clinical AI
models for ultrasound applications. In this study, we present EchoCare, a novel
ultrasound foundation model for generalist clinical use, developed via
self-supervised learning on our curated, publicly available, large-scale
dataset EchoCareData. EchoCareData comprises 4.5 million ultrasound images,
sourced from over 23 countries across 5 continents and acquired via a diverse
range of distinct imaging devices, thus encompassing global cohorts that are
multi-center, multi-device, and multi-ethnic. Unlike prior studies that adopt
off-the-shelf vision foundation model architectures, we introduce a
hierarchical classifier into EchoCare to enable joint learning of pixel-level
and representation-level features, capturing both global anatomical contexts
and local ultrasound characteristics. With minimal training, EchoCare
outperforms state-of-the-art comparison models across 10 representative
ultrasound benchmarks of varying diagnostic difficulties, spanning disease
diagnosis, lesion segmentation, organ detection, landmark prediction,
quantitative regression, imaging enhancement and report generation. The code
and pretrained model are publicly released, rendering EchoCare accessible for
fine-tuning and local adaptation, supporting extensibility to additional
applications. EchoCare provides a fully open and generalizable foundation model
to boost the development of AI technologies for diverse clinical ultrasound
applications.

</details>


### [97] [MSMA: Multi-Scale Feature Fusion For Multi-Attribute 3D Face Reconstruction From Unconstrained Images](https://arxiv.org/abs/2509.11763)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出一种多尺度特征融合与多属性（MSMA）框架，用于从无约束图像中重建三维人脸，通过集成多尺度特征融合、多属性学习和使用大核注意力模块来提高特征提取精度，从而从单张二维图像中准确估计三维面部参数。


<details>
  <summary>Details</summary>
Motivation: 现有的三维人脸重建方法在无约束环境下，尤其是在处理多样化的面部属性和条件时，往往难以捕捉详细和多尺度的特征，导致重建不完整或不准确。此外，这些方法通常需要大量难以获取的标注三维人脸数据集。

Method: 提出MSMA框架，该框架整合了多尺度特征融合，侧重于多属性学习，并利用大核注意力模块来增强跨尺度的特征提取精度，以实现从单张二维图像到三维面部参数的准确估计。

Result: 在MICC Florence、Facewarehouse和自定义收集的数据集上的综合实验表明，该方法在具有挑战性的条件下，其性能可与当前最先进的方法相媲美，甚至在某些情况下超越了它们。

Conclusion: MSMA框架能够从单张无约束图像中准确重建三维人脸，并在处理多样化的面部属性和条件方面表现出色。

Abstract: Reconstructing 3D face from a single unconstrained image remains a
challenging problem due to diverse conditions in unconstrained environments.
Recently, learning-based methods have achieved notable results by effectively
capturing complex facial structures and details across varying conditions.
Consequently, many existing approaches employ projection-based losses between
generated and input images to constrain model training. However, learning-based
methods for 3D face reconstruction typically require substantial amounts of 3D
facial data, which is difficult and costly to obtain. Consequently, to reduce
reliance on labeled 3D face datasets, many existing approaches employ
projection-based losses between generated and input images to constrain model
training. Nonetheless, despite these advancements, existing approaches
frequently struggle to capture detailed and multi-scale features under diverse
facial attributes and conditions, leading to incomplete or less accurate
reconstructions. In this paper, we propose a Multi-Scale Feature Fusion with
Multi-Attribute (MSMA) framework for 3D face reconstruction from unconstrained
images. Our method integrates multi-scale feature fusion with a focus on
multi-attribute learning and leverages a large-kernel attention module to
enhance the precision of feature extraction across scales, enabling accurate 3D
facial parameter estimation from a single 2D image. Comprehensive experiments
on the MICC Florence, Facewarehouse and custom-collect datasets demonstrate
that our approach achieves results on par with current state-of-the-art
methods, and in some instances, surpasses SOTA performance across challenging
conditions.

</details>


### [98] [Seg2Track-SAM2: SAM2-based Multi-object Tracking and Segmentation for Zero-shot Generalization](https://arxiv.org/abs/2509.11772)
*Diogo Mendonça,Tiago Barros,Cristiano Premebida,Urbano J. Nunes*

Main category: cs.CV

TL;DR: Seg2Track-SAM2是一个无需微调的框架，它结合了SAM2和新的Seg2Track模块，用于多目标跟踪与分割（MOTS），在KITTI MOTS上达到了SOTA性能，并引入了高效的内存策略。


<details>
  <summary>Details</summary>
Motivation: 现有的基于SAM2等基础模型的视频分割方法在多目标跟踪与分割（MOTS）方面存在身份管理不足和内存效率低的问题。

Method: 提出Seg2Track-SAM2框架，集成了预训练检测器、SAM2和一个新的Seg2Track模块，用于解决跟踪初始化、跟踪管理和增强问题，并且无需微调且不受检测器限制。

Result: 在KITTI MOT和KITTI MOTS基准测试中，Seg2Track-SAM2在小汽车和行人类别中均排名第四，并在关联准确度（AssA）方面创下新纪录。采用滑动窗口内存策略可将内存使用量减少高达75%，而性能下降可忽略不计。

Conclusion: Seg2Track-SAM2通过结合强大的零样本跟踪、增强的身份保持和高效的内存利用，推动了MOTS技术的发展，适用于资源受限的部署场景。

Abstract: Autonomous systems require robust Multi-Object Tracking (MOT) capabilities to
operate reliably in dynamic environments. MOT ensures consistent object
identity assignment and precise spatial delineation. Recent advances in
foundation models, such as SAM2, have demonstrated strong zero-shot
generalization for video segmentation, but their direct application to MOTS
(MOT+Segmentation) remains limited by insufficient identity management and
memory efficiency. This work introduces Seg2Track-SAM2, a framework that
integrates pre-trained object detectors with SAM2 and a novel Seg2Track module
to address track initialization, track management, and reinforcement. The
proposed approach requires no fine-tuning and remains detector-agnostic.
Experimental results on KITTI MOT and KITTI MOTS benchmarks show that
Seg2Track-SAM2 achieves state-of-the-art (SOTA) performance, ranking fourth
overall in both car and pedestrian classes on KITTI MOTS, while establishing a
new benchmark in association accuracy (AssA). Furthermore, a sliding-window
memory strategy reduces memory usage by up to 75% with negligible performance
degradation, supporting deployment under resource constraints. These results
confirm that Seg2Track-SAM2 advances MOTS by combining robust zero-shot
tracking, enhanced identity preservation, and efficient memory utilization. The
code is available at https://github.com/hcmr-lab/Seg2Track-SAM2

</details>


### [99] [SA-UNetv2: Rethinking Spatial Attention U-Net for Retinal Vessel Segmentation](https://arxiv.org/abs/2509.11774)
*Changlu Guo,Anders Nymark Christensen,Anders Bjorholm Dahl,Yugen Yi,Morten Rieger Hannemose*

Main category: cs.CV

TL;DR: SA-UNetv2通过在跳跃连接中引入跨尺度空间注意力和使用加权的二元交叉熵加马修斯相关系数损失，实现了视网膜血管分割的最先进性能，同时具有更高的效率和更小的模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 现有的SA-UNet模型在跳跃连接中对注意力的利用不足，并且未能解决前景-背景类别不平衡的问题。

Method: 提出SA-UNetv2模型，该模型在所有跳跃连接中注入跨尺度空间注意力以增强多尺度特征融合，并采用加权的二元交叉熵（BCE）加上马修斯相关系数（MCC）损失来提高对类别不平衡的鲁棒性。

Result: SA-UNetv2在DRIVE和STARE公开数据集上实现了最先进的性能，模型大小仅为1.2MB，参数量为0.26M（不到SA-UNet的50%），并且在592 x 592 x 3图像上仅需1秒的CPU推理时间。

Conclusion: SA-UNetv2在资源受限、仅CPU的环境下具有很强的效率和可部署性。

Abstract: Retinal vessel segmentation is essential for early diagnosis of diseases such
as diabetic retinopathy, hypertension, and neurodegenerative disorders.
Although SA-UNet introduces spatial attention in the bottleneck, it underuses
attention in skip connections and does not address the severe
foreground-background imbalance. We propose SA-UNetv2, a lightweight model that
injects cross-scale spatial attention into all skip connections to strengthen
multi-scale feature fusion and adopts a weighted Binary Cross-Entropy (BCE)
plus Matthews Correlation Coefficient (MCC) loss to improve robustness to class
imbalance. On the public DRIVE and STARE datasets, SA-UNetv2 achieves
state-of-the-art performance with only 1.2MB memory and 0.26M parameters (less
than 50% of SA-UNet), and 1 second CPU inference on 592 x 592 x 3 images,
demonstrating strong efficiency and deployability in resource-constrained,
CPU-only settings.

</details>


### [100] [FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via Agent-of-Thoughts Reasoning](https://arxiv.org/abs/2509.11796)
*Haodong Chen,Haojian Huang,XinXiang Yin,Dian Shao*

Main category: cs.CV

TL;DR: FineQuest是一个创新的无训练框架，通过结合反应式和审议式推理，并利用体育知识图谱SSGraph，有效解决了视频问答在体育领域面临的挑战，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在应用于体育视频问答时存在显著挑战，需要一个能够弥合通用模型与领域特定体育理解之间知识鸿沟的解决方案。

Method: 提出了一种名为FineQuest的无训练框架，该框架借鉴了认知科学的双模式推理（反应式推理和审议式推理），并引入了跨越九种体育运动的多模态体育知识场景图SSGraph，以增强推理的准确性。

Result: FineQuest在Gym-QA、Diving-QA和SPORTU数据集上取得了最先进的性能，同时保持了强大的通用视频问答能力。

Conclusion: FineQuest通过其创新的双模式推理和SSGraph知识图谱，成功解决了体育视频问答的复杂性，并在多个基准测试中展现了优越的性能。

Abstract: Video Question Answering (VideoQA) based on Large Language Models (LLMs) has
shown potential in general video understanding but faces significant challenges
when applied to the inherently complex domain of sports videos. In this work,
we propose FineQuest, the first training-free framework that leverages
dual-mode reasoning inspired by cognitive science: i) Reactive Reasoning for
straightforward sports queries and ii) Deliberative Reasoning for more complex
ones. To bridge the knowledge gap between general-purpose models and
domain-specific sports understanding, FineQuest incorporates SSGraph, a
multimodal sports knowledge scene graph spanning nine sports, which encodes
both visual instances and domain-specific terminology to enhance reasoning
accuracy. Furthermore, we introduce two new sports VideoQA benchmarks, Gym-QA
and Diving-QA, derived from the FineGym and FineDiving datasets, enabling
diverse and comprehensive evaluation. FineQuest achieves state-of-the-art
performance on these benchmarks as well as the existing SPORTU dataset, while
maintains strong general VideoQA capabilities.

</details>


### [101] [Pseudo-D: Informing Multi-View Uncertainty Estimation with Calibrated Neural Training Dynamics](https://arxiv.org/abs/2509.11800)
*Ang Nan Gu,Michael Tsang,Hooman Vaseli,Purang Abolmaesumi,Teresa Tsang*

Main category: cs.CV

TL;DR: 本文提出了一种利用神经网络训练动态（NNTD）为医学影像诊断生成不确定性感知伪标签的框架，以解决当前模型因使用过于简化的标签而导致的过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 现有计算机辅助诊断系统使用的过于简化的标签（例如独热标签）忽略了诊断的不确定性，导致模型在面对不完整或有瑕疵的输入时做出过于自信的预测，未能体现评分者之间的一致性。

Method: 该框架利用神经网络训练动态（NNTD）来评估训练样本的固有难度。通过在训练过程中聚合和校准模型预测，生成能够反映学习过程中遇到的歧义性的不确定性感知伪标签。

Result: 在具有挑战性的超声心动图分类基准测试中，该方法在校准、选择性分类和多视图融合方面均表现优于专门的基线方法。

Conclusion: 该框架通过将不确定性引入标签空间，有效地提高了模型在医学影像诊断中的不确定性估计和鲁棒性，并且该方法具有架构无关性，可以应用于任何监督学习流程。

Abstract: Computer-aided diagnosis systems must make critical decisions from medical
images that are often noisy, ambiguous, or conflicting, yet today's models are
trained on overly simplistic labels that ignore diagnostic uncertainty. One-hot
labels erase inter-rater variability and force models to make overconfident
predictions, especially when faced with incomplete or artifact-laden inputs. We
address this gap by introducing a novel framework that brings uncertainty back
into the label space. Our method leverages neural network training dynamics
(NNTD) to assess the inherent difficulty of each training sample. By
aggregating and calibrating model predictions during training, we generate
uncertainty-aware pseudo-labels that reflect the ambiguity encountered during
learning. This label augmentation approach is architecture-agnostic and can be
applied to any supervised learning pipeline to enhance uncertainty estimation
and robustness. We validate our approach on a challenging echocardiography
classification benchmark, demonstrating superior performance over specialized
baselines in calibration, selective classification, and multi-view fusion.

</details>


### [102] [LFRA-Net: A Lightweight Focal and Region-Aware Attention Network for Retinal Vessel Segmentatio](https://arxiv.org/abs/2509.11811)
*Mehwish Mehmood,Shahzaib Iqbal,Tariq Mahmood Khan,Ivor Spence,Muhammad Fahim*

Main category: cs.CV

TL;DR: LFRA-Net是一个轻量级的视网膜血管分割网络，在保持低计算成本的同时，通过引入新的注意力机制提高了分割精度，适用于资源受限的临床应用。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习视网膜血管分割方法在提取微小血管和计算成本方面仍存在挑战，尤其是在计算资源有限的实际临床环境中。

Method: 提出了一种名为LFRA-Net的新型轻量级网络，在编码器-解码器瓶颈处引入了焦点调制注意力，在选择性跳跃连接中引入了区域感知注意力，以增强特征表示和区域聚焦。

Result: LFRA-Net在DRIVE、STARE和CHASE_DB三个公共数据集上进行了验证，在保持极低参数量（0.17M）、内存占用（0.66MB）和计算量（10.50 GFLOPs）的同时，在Dice得分（分别为84.28%、88.44%、85.50%）和Jaccard指数（分别为72.86%、79.31%、74.70%）方面均优于现有最先进的模型。

Conclusion: LFRA-Net在分割精度和计算成本之间取得了理想的平衡，非常适合资源匮乏地区的实时临床应用。

Abstract: Retinal vessel segmentation is critical for the early diagnosis of
vision-threatening and systemic diseases, especially in real-world clinical
settings with limited computational resources. Although significant
improvements have been made in deep learning-based segmentation methods,
current models still face challenges in extracting tiny vessels and suffer from
high computational costs. In this study, we present LFRA-Net by incorporating
focal modulation attention at the encoder-decoder bottleneck and region-aware
attention in the selective skip connections. LFRA-Net is a lightweight network
optimized for precise and effective retinal vascular segmentation. It enhances
feature representation and regional focus by efficiently capturing local and
global dependencies. LFRA-Net outperformed many state-of-the-art models while
maintaining lightweight characteristics with only 0.17 million parameters, 0.66
MB memory size, and 10.50 GFLOPs. We validated it on three publicly available
datasets: DRIVE, STARE, and CHASE\_DB. It performed better in terms of Dice
score (84.28\%, 88.44\%, and 85.50\%) and Jaccard index (72.86\%, 79.31\%, and
74.70\%) on the DRIVE, STARE, and CHASE\_DB datasets, respectively. LFRA-Net
provides an ideal ratio between segmentation accuracy and computational cost
compared to existing deep learning methods, which makes it suitable for
real-time clinical applications in areas with limited resources. The code can
be found at https://github.com/Mehwish4593/LFRA-Net.

</details>


### [103] [SpecVLM: Fast Speculative Decoding in Vision-Language Models](https://arxiv.org/abs/2509.11815)
*Haiduo Huang,Fuwei Yang,Zhenhua Liu,Xuanwu Yin,Dong Li,Pengju Ren,Emad Barsoum*

Main category: cs.CV

TL;DR: SpecVLM通过引入弹性视觉压缩器和在线logit蒸馏协议，加速了视觉语言模型（VLMs）的推断，实现了2.5-2.9倍的加速，同时保持了模型输出分布的完整性。


<details>
  <summary>Details</summary>
Motivation: 直接将投机解码应用于视觉语言模型（VLMs）面临系统限制，尤其是在预填阶段，视觉标记的数量会随着图像分辨率和视频长度的增加而急剧膨胀，导致计算和内存（尤其是KV缓存）的显著增加。

Method: SpecVLM提出了一个结合了弹性视觉压缩器（用于自适应地选择压缩策略）和在线logit蒸馏协议（用于在训练过程中实时使用教师模型的logit和次级特征）的系统。该系统建立在EAGLE-2风格的基线EagleVLM之上，并采用交叉熵和Smooth L1目标函数的组合进行训练。

Result: SpecVLM实现了1.5-2.3倍的端到端加速（基于EagleVLM基线），并在LLaVA和MMMU基准测试中，通过在线训练实现了2.5-2.9倍的端到端加速。该方法在不同分辨率和任务难度下均表现出色，并且实现了无损解码。

Conclusion: SpecVLM有效地解决了视觉语言模型（VLMs）在投机解码上面临的系统挑战，通过创新的弹性视觉压缩器和在线logit蒸馏协议，在保持模型性能的同时实现了显著的推断加速。

Abstract: Speculative decoding is a powerful way to accelerate autoregressive large
language models (LLMs), but directly porting it to vision-language models
(VLMs) faces unique systems constraints: the prefill stage is dominated by
visual tokens whose count scales with image resolution and video length,
inflating both compute and memory, especially the key-value (KV) cache. We
study speculative decoding for VLMs and introduce SpecVLM, a practical system
that (1) establishes a strong EAGLE-2-style baseline, EagleVLM, delivering
1.5--2.3x end-to-end speedups over full autoregressive inference, and (2)
further accelerates VLM inference with an elastic visual compressor that
adaptively selects among pruning, pooling, convolution, and resampler
primitives to balance FLOPs/parameters and accuracy per input. To avoid costly
offline distillation corpora, we propose an online-logit distillation protocol
that trains the draft model with on-the-fly teacher logits and penultimate
features using a combined cross-entropy and Smooth L1 objective, eliminating
storage and preprocessing while remaining compute-efficient. This protocol
reveals a training-time scaling effect: longer online training monotonically
increases the draft model's average accepted length, improving speculative
efficiency. Empirically, SpecVLM achieves additional acceleration, culminating
in 2.5--2.9x end-to-end speedups within 5 epochs across LLaVA and MMMU,
consistently over resolutions and task difficulties, while preserving the
target model's output distribution (lossless decoding). Our code is available
at https://github.com/haiduo/SpecVLM.

</details>


### [104] [MAFS: Masked Autoencoder for Infrared-Visible Image Fusion and Semantic Segmentation](https://arxiv.org/abs/2509.11817)
*Liying Wang,Xiaoli Zhang,Chuanmin Jia,Siwei Ma*

Main category: cs.CV

TL;DR: 提出了一种统一的网络，用于图像融合和语义分割，以相互促进像素级图像融合和跨模态特征融合感知任务。


<details>
  <summary>Details</summary>
Motivation: 现有的以语义为驱动的方法已经考虑了语义信息注入下游应用，但没有从宏观任务层面探讨像素级图像融合和跨模态特征融合感知任务之间的互促潜力。

Method: 提出了一种统一网络 MAFS，它具有并行结构，包含融合子网络和分割子网络。融合子网络采用异构特征融合策略来增强语义感知能力；分割子网络将融合子网络级联到一个分割主干，以转移与分割相关的知识来促进基于特征的融合分割。该网络还包括一个新颖的多阶段 Transformer 解码器，用于聚合细粒度的多尺度融合特征，以及一个基于最大最小公平分配原则的动态因子，用于生成任务的自适应权重，以确保多任务训练的平稳性。

Result: 该方法在与最先进方法的比较中取得了有竞争力的结果。

Conclusion: 所提出的 MAFS 方法通过统一图像融合和语义分割任务，并利用它们之间的相互促进作用，在提高融合图像质量和分割性能方面取得了显著成效。

Abstract: Infrared-visible image fusion methods aim at generating fused images with
good visual quality and also facilitate the performance of high-level tasks.
Indeed, existing semantic-driven methods have considered semantic information
injection for downstream applications. However, none of them investigates the
potential for reciprocal promotion between pixel-wise image fusion and
cross-modal feature fusion perception tasks from a macroscopic task-level
perspective. To address this limitation, we propose a unified network for image
fusion and semantic segmentation. MAFS is a parallel structure, containing a
fusion sub-network and a segmentation sub-network. On the one hand, We devise a
heterogeneous feature fusion strategy to enhance semantic-aware capabilities
for image fusion. On the other hand, by cascading the fusion sub-network and a
segmentation backbone, segmentation-related knowledge is transferred to promote
feature-level fusion-based segmentation. Within the framework, we design a
novel multi-stage Transformer decoder to aggregate fine-grained multi-scale
fused features efficiently. Additionally, a dynamic factor based on the max-min
fairness allocation principle is introduced to generate adaptive weights of two
tasks and guarantee smooth training in a multi-task manner. Extensive
experiments demonstrate that our approach achieves competitive results compared
with state-of-the-art methods. The code is available at
https://github.com/Abraham-Einstein/MAFS/.

</details>


### [105] [Probabilistic Robustness Analysis in High Dimensional Space: Application to Semantic Segmentation Network](https://arxiv.org/abs/2509.11838)
*Navid Hashemi,Samuel Sasaki,Diego Manzanas Lopez,Ipek Oguz,Meiyi Ma,Taylor T. Johnson*

Main category: cs.CV

TL;DR: 现有的语义分割网络（SSN）验证方法在处理高维度和复杂模型时存在可扩展性和保守性问题。本文提出了一种结合采样可达性分析和一致性推断（CI）的概率验证框架，该框架具有架构无关性和可扩展性，能够为高维输出提供可靠的安全保证，并减少了过度保守性。


<details>
  <summary>Details</summary>
Motivation: 现有的概率验证方法难以扩展到现代分割任务的复杂性和维度，导致保证过于保守而无法实际应用。因此，需要一种可扩展且不保守的验证方法。

Method: 结合采样可达性分析和一致性推断（CI），并提出新的策略来减少CI在高维设置下的保守性，同时不影响其严谨性。

Result: 在CamVid、OCTA-500、Lung Segmentation和Cityscapes等大规模分割模型上进行了实证评估，结果表明该方法提供了可靠的安全保证，并且与现有技术（SOTA）相比，显著收紧了界限。

Conclusion: 本文提出的概率验证框架能够为高维输出提供可靠的安全保证，并显著优于现有方法。此外，还提供了一个实现该技术的工具箱。

Abstract: Semantic segmentation networks (SSNs) play a critical role in domains such as
medical imaging, autonomous driving, and environmental monitoring, where safety
hinges on reliable model behavior under uncertainty. Yet, existing
probabilistic verification approaches struggle to scale with the complexity and
dimensionality of modern segmentation tasks, often yielding guarantees that are
too conservative to be practical. We introduce a probabilistic verification
framework that is both architecture-agnostic and scalable to high-dimensional
outputs. Our approach combines sampling-based reachability analysis with
conformal inference (CI) to deliver provable guarantees while avoiding the
excessive conservatism of prior methods. To counteract CI's limitations in
high-dimensional settings, we propose novel strategies that reduce conservatism
without compromising rigor. Empirical evaluation on large-scale segmentation
models across CamVid, OCTA-500, Lung Segmentation, and Cityscapes demonstrates
that our method provides reliable safety guarantees while substantially
tightening bounds compared to SOTA. We also provide a toolbox implementing this
technique, available on Github.

</details>


### [106] [Synthetic Captions for Open-Vocabulary Zero-Shot Segmentation](https://arxiv.org/abs/2509.11840)
*Tim Lebailly,Vijay Veerabadran,Satwik Kottur,Karl Ridgeway,Michael Louis Iuzzolino*

Main category: cs.CV

TL;DR: 生成式视觉-语言模型(VLMs)在图像理解方面表现出色，但缺乏细粒度的视觉-语言空间对齐。本研究通过将图像与VLMs生成的合成描述进行密集对齐，弥合了生成式VLMs和表示学习在视觉-语言对齐方面的差距。


<details>
  <summary>Details</summary>
Motivation: 填补生成式VLMs在细粒度空间对齐方面的不足，并利用合成描述来增强现有的密集对齐方法。

Method: 将图像与由VLMs生成的合成描述进行密集对齐。

Result: 在零样本开放词汇分割基准/数据集上超越了现有方法，并且数据效率更高。

Conclusion: 将图像与VLMs生成的合成描述进行密集对齐，是一种有效且数据高效的方法，可以提高零样本开放词汇分割的性能。

Abstract: Generative vision-language models (VLMs) exhibit strong high-level image
understanding but lack spatially dense alignment between vision and language
modalities, as our findings indicate. Orthogonal to advancements in generative
VLMs, another line of research has focused on representation learning for
vision-language alignment, targeting zero-shot inference for dense tasks like
segmentation. In this work, we bridge these two directions by densely aligning
images with synthetic descriptions generated by VLMs. Synthetic captions are
inexpensive, scalable, and easy to generate, making them an excellent source of
high-level semantic understanding for dense alignment methods. Empirically, our
approach outperforms prior work on standard zero-shot open-vocabulary
segmentation benchmarks/datasets, while also being more data-efficient.

</details>


### [107] [Segmentation-Driven Initialization for Sparse-view 3D Gaussian Splatting](https://arxiv.org/abs/2509.11853)
*Yi-Hsin Li,Thomas Sikora,Sebastian Knorr,Måarten Sjöström*

Main category: cs.CV

TL;DR: SDI-GS通过利用基于区域的分割来识别和保留结构上显著的区域，从而减少3D高斯泼溅中的高斯数量，从而提高效率，同时保持渲染质量，并减少训练时间和内存占用。


<details>
  <summary>Details</summary>
Motivation: 从有限的观测中恢复准确的几何和外观，尤其是在稀疏视图设置中，是一个持续存在的挑战，并且现有的3D高斯泼溅（3DGS）管道在稀疏视图设置中存在困难，因为它们依赖于结构从中运动（SfM）进行相机姿态估计，或者生成过多的3D高斯，导致内存成本高。

Method: SDI-GS方法利用区域分割来识别和保留结构上重要的区域，从而选择性地对密集点云进行降采样，以减少高斯数量，同时保持场景保真度。

Result: SDI-GS可将高斯数量减少多达50%，并在PSNR和SSIM方面实现相当或更好的渲染质量，同时LPIPS仅有少量下降。此外，它还能实现更快的训练和更低的内存占用。

Conclusion: SDI-GS通过利用区域分割来减少3D高斯泼溅中的高斯数量，从而提高了效率，同时在稀疏视图场景中保持了渲染质量，并在训练时间和内存占用方面取得了显著的改进。

Abstract: Sparse-view synthesis remains a challenging problem due to the difficulty of
recovering accurate geometry and appearance from limited observations. While
recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time
rendering with competitive quality, existing pipelines often rely on
Structure-from-Motion (SfM) for camera pose estimation, an approach that
struggles in genuinely sparse-view settings. Moreover, several SfM-free methods
replace SfM with multi-view stereo (MVS) models, but generate massive numbers
of 3D Gaussians by back-projecting every pixel into 3D space, leading to high
memory costs. We propose Segmentation-Driven Initialization for Gaussian
Splatting (SDI-GS), a method that mitigates inefficiency by leveraging
region-based segmentation to identify and retain only structurally significant
regions. This enables selective downsampling of the dense point cloud,
preserving scene fidelity while substantially reducing Gaussian count.
Experiments across diverse benchmarks show that SDI-GS reduces Gaussian count
by up to 50% and achieves comparable or superior rendering quality in PSNR and
SSIM, with only marginal degradation in LPIPS. It further enables faster
training and lower memory footprint, advancing the practicality of 3DGS for
constrained-view scenarios.

</details>


### [108] [Bridging Vision Language Models and Symbolic Grounding for Video Question Answering](https://arxiv.org/abs/2509.11862)
*Haodi Ma,Vyom Pathak,Daisy Zhe Wang*

Main category: cs.CV

TL;DR: 该研究提出SG-VLM框架，通过引入符号场景图来增强视频问答（VQA）模型，以改进其时序和因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在视频问答（VQA）任务中虽然表现良好，但常常依赖浅层关联，导致时序理解不足且可解释性有限。本研究旨在利用符号场景图（SG）作为中间接地信号，来解决这些问题。

Method: 提出SG-VLM框架，该框架将预训练好的VLM与基于提示和视觉定位的场景图接地相结合，实现了模块化集成。

Result: 在NExT-QA、iVQA和ActivityNet-QA三个基准测试以及QwenVL、InternVL等多个VLM上，SG-VLM均提升了因果和时序推理能力，并优于现有基线模型。但与强大的VLM相比，改进幅度有限。

Conclusion: 符号接地在视频理解方面具有潜力，但目前仍存在局限性。研究结果为未来结合VLM和符号方法的视频理解研究提供了指导。

Abstract: Video Question Answering (VQA) requires models to reason over spatial,
temporal, and causal cues in videos. Recent vision language models (VLMs)
achieve strong results but often rely on shallow correlations, leading to weak
temporal grounding and limited interpretability. We study symbolic scene graphs
(SGs) as intermediate grounding signals for VQA. SGs provide structured
object-relation representations that complement VLMs holistic reasoning. We
introduce SG-VLM, a modular framework that integrates frozen VLMs with scene
graph grounding via prompting and visual localization. Across three benchmarks
(NExT-QA, iVQA, ActivityNet-QA) and multiple VLMs (QwenVL, InternVL), SG-VLM
improves causal and temporal reasoning and outperforms prior baselines, though
gains over strong VLMs are limited. These findings highlight both the promise
and current limitations of symbolic grounding, and offer guidance for future
hybrid VLM-symbolic approaches in video understanding.

</details>


### [109] [Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding](https://arxiv.org/abs/2509.11866)
*Meng Luo,Shengqiong Wu,Liqiang Jing,Tianjie Ju,Li Zheng,Jinxiang Lai,Tianlong Wu,Xinya Du,Jian Li,Siyuan Yan,Jiebo Luo,William Yang Wang,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: Dr.V是一个用于诊断大型视频模型（LVM）幻觉的框架，通过精细的空间-时间定位，在感知、时间和认知三个层面进行分析，并提供了名为Dr.V-Bench的数据集和Dr.V-Agent的代理模型，实验证明该方法能有效检测幻觉并提高可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型视频模型（LVMs）在视频理解方面取得了显著进展，但仍然存在幻觉问题，即模型生成的内容与输入视频不符。

Method: 提出Dr.V框架，包含Dr.V-Bench数据集和Dr.V-Agent代理。Dr.V-Agent通过精细的空间-时间定位，在感知、时间和认知三个层面系统地检测LVMs中的幻觉。

Result: 实验表明Dr.V-Agent能有效诊断幻觉，同时提高模型的可解释性和可靠性。

Conclusion: Dr.V框架为在实际场景中实现鲁棒的视频理解提供了一个实用的蓝图，能够有效检测和解决LVMs中的幻觉问题。

Abstract: Recent advancements in large video models (LVMs) have significantly enhance
video understanding. However, these models continue to suffer from
hallucinations, producing content that conflicts with input videos. To address
this issue, we propose Dr.V, a hierarchical framework covering perceptive,
temporal, and cognitive levels to diagnose video hallucination by fine-grained
spatial-temporal grounding. Dr.V comprises of two key components: a benchmark
dataset Dr.V-Bench and a satellite video agent Dr.V-Agent. Dr.V-Bench includes
10k instances drawn from 4,974 videos spanning diverse tasks, each enriched
with detailed spatial-temporal annotation. Dr.V-Agent detects hallucinations in
LVMs by systematically applying fine-grained spatial-temporal grounding at the
perceptive and temporal levels, followed by cognitive level reasoning. This
step-by-step pipeline mirrors human-like video comprehension and effectively
identifies hallucinations. Extensive experiments demonstrate that Dr.V-Agent is
effective in diagnosing hallucination while enhancing interpretability and
reliability, offering a practical blueprint for robust video understanding in
real-world scenarios. All our data and code are available at
https://github.com/Eurekaleo/Dr.V.

</details>


### [110] [Multi-animal tracking in Transition: Comparative Insights into Established and Emerging Methods](https://arxiv.org/abs/2509.11873)
*Anne Marthe Sophie Ngo Bibinbe,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 多目标跟踪（MOT）方法在猪只长期跟踪任务上优于传统的动物跟踪（MAT）工具。


<details>
  <summary>Details</summary>
Motivation: 精确畜牧业需要先进的监测工具，而现有的MAT工具在多动物跟踪（MAT）任务上表现不佳，影响了下游的准确性。

Method: 将MAT工具（如DeepLabCut和idTracker）与MOT方法（如ByteTrack、DeepSORT、cross-input consistency、Track-Anything和PromptTrack）在猪只跟踪数据集上进行了基准测试和比较。

Result: 在10分钟的猪只跟踪数据集上，MOT方法在跟踪准确性上整体优于传统的MAT工具。

Conclusion: 最近的MOT技术有潜力提高自动化畜牧跟踪的准确性和可靠性，应优先考虑在精确畜牧业中应用。

Abstract: Precision livestock farming requires advanced monitoring tools to meet the
increasing management needs of the industry. Computer vision systems capable of
long-term multi-animal tracking (MAT) are essential for continuous behavioral
monitoring in livestock production. MAT, a specialized subset of multi-object
tracking (MOT), shares many challenges with MOT, but also faces domain-specific
issues including frequent animal occlusion, highly similar appearances among
animals, erratic motion patterns, and a wide range of behavior types.
  While some existing MAT tools are user-friendly and widely adopted, they
often underperform compared to state-of-the-art MOT methods, which can result
in inaccurate downstream tasks such as behavior analysis, health state
estimation, and related applications. In this study, we benchmarked both MAT
and MOT approaches for long-term tracking of pigs. We compared tools such as
DeepLabCut and idTracker with MOT-based methods including ByteTrack, DeepSORT,
cross-input consistency, and newer approaches like Track-Anything and
PromptTrack.
  All methods were evaluated on a 10-minute pig tracking dataset. Our results
demonstrate that, overall, MOT approaches outperform traditional MAT tools,
even for long-term tracking scenarios. These findings highlight the potential
of recent MOT techniques to enhance the accuracy and reliability of automated
livestock tracking.

</details>


### [111] [Do It Yourself (DIY): Modifying Images for Poems in a Zero-Shot Setting Using Weighted Prompt Manipulation](https://arxiv.org/abs/2509.11878)
*Sofia Jamil,Kotla Sai Charan,Sriparna Saha,Koustava Goswami,K J Joseph*

Main category: cs.CV

TL;DR: 生成诗歌图像，并能在零样本设置下改进这些图像，允许用户根据自己的需求修改图像。


<details>
  <summary>Details</summary>
Motivation: 识别到诗歌具有多种解读的可能性，读者常常将自己的情感、经历和文化背景带入对诗歌的理解中。

Method: 提出了一种新颖的加权提示操纵（WPM）技术，该技术系统地修改了扩散模型中的注意力权重和文本嵌入。通过动态调整特定词语的重要性，WPM能够增强或抑制它们在最终生成图像中的影响，从而实现更丰富的语义和更具情境准确性的可视化。该方法结合了扩散模型、大型语言模型（如GPT）以及现有的诗歌数据集。

Result: 该方法在诗歌领域实现了更好的图像生成效果，能够生成语义更丰富、情境更准确的可视化图像。

Conclusion: 这是首次尝试将加权提示操纵集成到诗歌语言的图像增强中。

Abstract: Poetry is an expressive form of art that invites multiple interpretations, as
readers often bring their own emotions, experiences, and cultural backgrounds
into their understanding of a poem. Recognizing this, we aim to generate images
for poems and improve these images in a zero-shot setting, enabling audiences
to modify images as per their requirements. To achieve this, we introduce a
novel Weighted Prompt Manipulation (WPM) technique, which systematically
modifies attention weights and text embeddings within diffusion models. By
dynamically adjusting the importance of specific words, WPM enhances or
suppresses their influence in the final generated image, leading to
semantically richer and more contextually accurate visualizations. Our approach
exploits diffusion models and large language models (LLMs) such as GPT in
conjunction with existing poetry datasets, ensuring a comprehensive and
structured methodology for improved image generation in the literary domain. To
the best of our knowledge, this is the first attempt at integrating weighted
prompt manipulation for enhancing imagery in poetic language.

</details>


### [112] [SAM-TTT: Segment Anything Model via Reverse Parameter Configuration and Test-Time Training for Camouflaged Object Detection](https://arxiv.org/abs/2509.11884)
*Zhenni Yu,Li Zhao,Guobao Xiao,Xiaoqin Zhang*

Main category: cs.CV

TL;DR: SAM-TTT通过反向参数配置和测试时训练技术，解决了SAM在伪装物体检测（COD）任务中因关注不利参数而导致的语义理解不足问题，在多个COD基准测试中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的COD模型主要关注提取有利特征和增强有利参数，而忽视了不利参数对SAM在下游任务中语义理解的负面影响。

Method: 提出反向SAM参数配置模块（Reverse SAM Parameter Configuration Module）通过配置SAM的参数来减轻不利参数的影响（无需训练）。引入T-Visioner模块，将原本用于语言任务的测试时训练（Test-Time Training）层集成到视觉任务中，以加强有利参数。该模块是一种具有线性复杂度和表达能力强的隐藏状态的新型序列建模层。

Result: SAM-TTT同时抑制不利参数并加强有利参数，显著提高了SAM在COD任务中的语义理解能力。在多个COD基准测试中取得了先进的性能，树立了新的行业标杆。

Conclusion: SAM-TTT通过同时处理不利和有利参数，有效提升了SAM在伪装物体检测任务上的性能，并在多个基准测试中取得了最先进的结果。

Abstract: This paper introduces a new Segment Anything Model (SAM) that leverages
reverse parameter configuration and test-time training to enhance its
performance on Camouflaged Object Detection (COD), named SAM-TTT. While most
existing SAM-based COD models primarily focus on enhancing SAM by extracting
favorable features and amplifying its advantageous parameters, a crucial gap is
identified: insufficient attention to adverse parameters that impair SAM's
semantic understanding in downstream tasks. To tackle this issue, the Reverse
SAM Parameter Configuration Module is proposed to effectively mitigate the
influence of adverse parameters in a train-free manner by configuring SAM's
parameters. Building on this foundation, the T-Visioner Module is unveiled to
strengthen advantageous parameters by integrating Test-Time Training layers,
originally developed for language tasks, into vision tasks. Test-Time Training
layers represent a new class of sequence modeling layers characterized by
linear complexity and an expressive hidden state. By integrating two modules,
SAM-TTT simultaneously suppresses adverse parameters while reinforcing
advantageous ones, significantly improving SAM's semantic understanding in COD
task. Our experimental results on various COD benchmarks demonstrate that the
proposed approach achieves state-of-the-art performance, setting a new
benchmark in the field. The code will be available at
https://github.com/guobaoxiao/SAM-TTT.

</details>


### [113] [Lost in Embeddings: Information Loss in Vision-Language Models](https://arxiv.org/abs/2509.11986)
*Wenyan Li,Raphael Tang,Chengzu Li,Caiqi Zhang,Ivan Vulić,Anders Søgaard*

Main category: cs.CV

TL;DR: 连接器在视觉-语言模型中会导致信息损失，影响模型性能，可通过分析潜在表示空间来量化和定位这种损失。


<details>
  <summary>Details</summary>
Motivation: 研究视觉-语言模型（VLM）中用于融合模态的连接器组件可能引起的信息损失及其对模型能力的影响。

Method: 通过分析潜在表示空间，提出两种互补的方法来检查和量化信息损失：1. 通过分析投影前后图像表示的k近邻关系变化来评估语义信息保留情况。2. 通过从投影表示中重建视觉嵌入来直接测量信息损失，并在图像块级别定位损失。

Result: 连接器会显著扭曲视觉表示的局部几何结构，投影后k近邻会发散40-60%，这与检索性能下降相关。图像块级别嵌入重建可以为模型在视觉问答任务中的行为提供可解释的见解，发现信息损失高的区域能够可靠地预测模型表现不佳的实例。

Conclusion: 连接器在视觉-语言模型中会导致信息损失，影响模型性能，可通过分析潜在表示空间来量化和定位这种损失。

Abstract: Vision--language models (VLMs) often process visual inputs through a
pretrained vision encoder, followed by a projection into the language model's
embedding space via a connector component. While crucial for modality fusion,
the potential information loss induced by this projection step and its direct
impact on model capabilities remain understudied. We introduce two
complementary approaches to examine and quantify this loss by analyzing the
latent representation space. First, we evaluate semantic information
preservation by analyzing changes in k-nearest neighbor relationships between
image representations, before and after projection. Second, we directly measure
information loss by reconstructing visual embeddings from the projected
representation, localizing loss at an image patch level. Experiments reveal
that connectors substantially distort the local geometry of visual
representations, with k-nearest neighbors diverging by 40--60\%
post-projection, correlating with degradation in retrieval performance. The
patch-level embedding reconstruction provides interpretable insights for model
behavior on visually grounded question-answering tasks, finding that areas of
high information loss reliably predict instances where models struggle.

</details>


### [114] [BREA-Depth: Bronchoscopy Realistic Airway-geometric Depth Estimation](https://arxiv.org/abs/2509.11885)
*Francis Xiatian Zhang,Emile Mackute,Mohammadreza Kasaei,Kevin Dhaliwal,Robert Thomson,Mohsen Khadem*

Main category: cs.CV

TL;DR: Brea-Depth是一个用于支气管镜图像的单目深度估计框架，通过整合空气动力学几何先验和深度感知CycleGAN，提高了深度估计的准确性和三维重建的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 支气管镜检查中的单目深度估计对于提高实时导航精度和介入安全性至关重要，但现有模型缺乏对空气动力学结构的认知。

Method: 提出Brea-Depth框架，包含深度感知CycleGAN以弥合域间差异，并引入空气动力学结构感知损失以增强深度一致性。

Result: Brea-Depth在ex vivo人类肺部数据集和公开的支气管镜数据集上进行了验证，其深度估计和三维重建性能优于现有方法。

Conclusion: 通过整合解剖学先验，Brea-Depth提高了模型的泛化能力，实现了更鲁棒、更精确的三维空气动力学重建，并引入了新的评估指标Airway Depth Structure Evaluation。

Abstract: Monocular depth estimation in bronchoscopy can significantly improve
real-time navigation accuracy and enhance the safety of interventions in
complex, branching airways. Recent advances in depth foundation models have
shown promise for endoscopic scenarios, yet these models often lack anatomical
awareness in bronchoscopy, overfitting to local textures rather than capturing
the global airway structure, particularly under ambiguous depth cues and poor
lighting. To address this, we propose Brea-Depth, a novel framework that
integrates airway-specific geometric priors into foundation model adaptation
for bronchoscopic depth estimation. Our method introduces a depth-aware
CycleGAN, refining the translation between real bronchoscopic images and airway
geometries from anatomical data, effectively bridging the domain gap. In
addition, we introduce an airway structure awareness loss to enforce depth
consistency within the airway lumen while preserving smooth transitions and
structural integrity. By incorporating anatomical priors, Brea-Depth enhances
model generalization and yields more robust, accurate 3D airway
reconstructions. To assess anatomical realism, we introduce Airway Depth
Structure Evaluation, a new metric for structural consistency. We validate
BREA-Depth on a collected ex vivo human lung dataset and an open bronchoscopic
dataset, where it outperforms existing methods in anatomical depth
preservation.

</details>


### [115] [Logit Mixture Outlier Exposure for Fine-grained Out-of-Distribution Detection](https://arxiv.org/abs/2509.11892)
*Akito Shinohara,Kohei Fukuda,Hiroaki Aizawa*

Main category: cs.CV

TL;DR: 提出一种在logit空间进行插值的方法，以提高模型对分布外数据的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有的分布外数据检测方法（如异常值暴露）在区分分布内和分布外数据方面仍有挑战，尤其是在数据接近决策边界时。

Method: 在logit空间中，通过线性插值混合分布内和分布外数据，平滑类别间的logit，并强制执行logit空间混合与输入空间混合之间的一致性。

Result: 实验表明，该方法减少了模型输出在决策边界附近的突变，实现了更平滑、更可靠的分布内与分布外数据的分离，并在细粒度分布外检测任务上表现出有效性。

Conclusion: 所提出的logit空间混合技术能够有效提升模型在区分分布内和分布外数据时的鲁棒性和泛化能力。

Abstract: The ability to detect out-of-distribution data is essential not only for
ensuring robustness against unknown or unexpected input data but also for
improving the generalization performance of the model. Among various
out-of-distribution detection methods, Outlier Exposure and Mixture Outlier
Exposure are promising approaches that enhance out-of-distribution detection
performance by exposing the outlier data during training. However, even with
these sophisticated techniques, it remains challenging for models to learn the
relationships between classes effectively and to distinguish data sampling from
in-distribution and out-of-distribution clearly. Therefore, we focus on the
logit space, where the properties between class-wise distributions are
distinctly separated from those in the input or feature spaces. Specifically,
we propose a linear interpolation technique in the logit space that mixes
in-distribution and out-of-distribution data to facilitate smoothing logits
between classes and improve the out-of-distribution detection performance,
particularly for out-of-distribution data that lie close to the in-distribution
data. Additionally, we enforce consistency between the logits obtained through
mixing in the logit space and those generated via mixing in the input space.
Our experiments demonstrate that our logit-space mixing technique reduces the
abrupt fluctuations in the model outputs near the decision boundaries,
resulting in smoother and more reliable separation between in-distribution and
out-of-distribution data. Furthermore, we evaluate the effectiveness of the
proposed method on a fine-grained out-of-distribution detection task.

</details>


### [116] [Integrating Prior Observations for Incremental 3D Scene Graph Prediction](https://arxiv.org/abs/2509.11895)
*Marian Renz,Felix Igelbrink,Martin Atzmueller*

Main category: cs.CV

TL;DR: 该研究提出了一种新的异构图模型，用于增量式3D语义场景图（3DSSG）预测，该模型整合了多模态信息，如先验观察和CLIP等语义嵌入，以提高在机器人和具身AI中的应用能力，即使在不完整的场景重建中也能实现可扩展和可泛化的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的3DSSG方法主要依赖传感器数据，并且假设能够获得完整的场景重建，这在真实世界的增量式设置中存在局限性。因此，有必要开发一种能够整合额外信息并且适用于不完整场景重建的方法。

Method: 提出了一种新的异构图模型，该模型能够整合多模态信息（如先验观察、CLIP语义嵌入），并利用多层结构灵活地结合全局和局部场景表示，而无需专门的模块或完整的场景重建。该模型通过消息传递过程直接整合这些信息。

Result: 在3DSSG数据集上的评估结果表明，整合了多模态信息的GNN（如图形神经网络）比仅依赖传感器数据的传统方法表现更好，能够为复杂、真实的开放世界环境提供可扩展和可泛化的解决方案。

Conclusion: 该研究提出的异构图模型通过整合多模态信息，能够有效地进行增量式3DSSG预测，解决了现有方法在数据依赖性和场景重建完整性方面的局限性，为机器人和具身AI在真实世界中的应用提供了更有前景的解决方案。

Abstract: 3D semantic scene graphs (3DSSG) provide compact structured representations
of environments by explicitly modeling objects, attributes, and relationships.
While 3DSSGs have shown promise in robotics and embodied AI, many existing
methods rely mainly on sensor data, not integrating further information from
semantically rich environments. Additionally, most methods assume access to
complete scene reconstructions, limiting their applicability in real-world,
incremental settings. This paper introduces a novel heterogeneous graph model
for incremental 3DSSG prediction that integrates additional, multi-modal
information, such as prior observations, directly into the message-passing
process. Utilizing multiple layers, the model flexibly incorporates global and
local scene representations without requiring specialized modules or full scene
reconstructions. We evaluate our approach on the 3DSSG dataset, showing that
GNNs enriched with multi-modal information such as semantic embeddings (e.g.,
CLIP) and prior observations offer a scalable and generalizable solution for
complex, real-world environments. The full source code of the presented
architecture will be made available at
https://github.com/m4renz/incremental-scene-graph-prediction.

</details>


### [117] [NeuroGaze-Distill: Brain-informed Distillation and Depression-Inspired Geometric Priors for Robust Facial Emotion Recognition](https://arxiv.org/abs/2509.11916)
*Zilin Li,Weiwei Xu,Xuanqi Zhao,Yiran Zhu*

Main category: cs.CV

TL;DR: NeuroGaze-Distill 通过结合脑电图（EEG）数据中提取的脑信息先验（如情绪效价/唤醒度（V/A）原型和抑郁相关的几何先验（D-Geo））来改进仅基于图像的人脸情绪识别（FER）模型。该框架使用一个在EEG数据上训练的教师模型来生成静态V/A原型，然后蒸馏到一个图像识别学生模型中。该学生模型在FERPlus数据集上进行训练，并结合了原型蒸馏（Proto-KD）和D-Geo两个轻量级正则化器。实验表明，该方法在同域和跨数据集评估中均能提高FER模型的鲁棒性，且无需在部署时使用非视觉信号。


<details>
  <summary>Details</summary>
Motivation: 传统的仅基于像素的人脸情绪识别（FER）模型泛化能力差，因为面部外观是影响情绪的间接且有偏见的代理。本研究旨在通过引入脑信息先验来提高FER模型的泛化能力和鲁棒性。

Method: 提出NeuroGaze-Distill框架，该框架通过静态V/A原型和抑郁相关的几何先验（D-Geo）将脑信息先验转移到一个仅基于图像的FER学生模型中。教师模型在EEG地形图上进行训练，生成一个V/A原型网格。学生模型（ResNet-18/50）在FERPlus数据集上进行训练，并结合了Proto-KD（余弦相似度对齐学生特征与原型）和D-Geo（软化嵌入几何以符合抑郁研究的发现）两种轻量级正则化器。

Result: 在同域（FERPlus验证集）和跨数据集（AffectNet-mini；可选CK+）协议下评估了该方法。在8路分类任务中，报告了标准分数、仅当前类别宏F1分数和平衡准确率。消融实验表明，原型和D-Geo对性能提升有稳定贡献，并且5x5原型网格优于更密集的网格。

Conclusion: NeuroGaze-Distill方法简单、可部署，并在不增加模型复杂性的情况下提高了FER模型的鲁棒性。

Abstract: Facial emotion recognition (FER) models trained only on pixels often fail to
generalize across datasets because facial appearance is an indirect and biased
proxy for underlying affect. We present NeuroGaze-Distill, a cross-modal
distillation framework that transfers brain-informed priors into an image-only
FER student via static Valence/Arousal (V/A) prototypes and a
depression-inspired geometric prior (D-Geo). A teacher trained on EEG
topographic maps from DREAMER (with MAHNOB-HCI as unlabeled support) produces a
consolidated 5x5 V/A prototype grid that is frozen and reused; no EEG-face
pairing and no non-visual signals at deployment are required. The student
(ResNet-18/50) is trained on FERPlus with conventional CE/KD and two
lightweight regularizers: (i) Proto-KD (cosine) aligns student features to the
static prototypes; (ii) D-Geo softly shapes the embedding geometry in line with
affective findings often reported in depression research (e.g., anhedonia-like
contraction in high-valence regions). We evaluate both within-domain (FERPlus
validation) and cross-dataset protocols (AffectNet-mini; optional CK+),
reporting standard 8-way scores alongside present-only Macro-F1 and balanced
accuracy to fairly handle label-set mismatch. Ablations attribute consistent
gains to prototypes and D-Geo, and favor 5x5 over denser grids for stability.
The method is simple, deployable, and improves robustness without architectural
complexity.

</details>


### [118] [Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models](https://arxiv.org/abs/2509.12132)
*Pu Jian,Junhong Wu,Wei Sun,Chen Wang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 通过引入视觉反思能力，Reflection-V 显著提升了视觉推理模型（VRMs）在处理视觉信息时的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉推理模型（VRMs）在从文本领域迁移“慢思考”推理能力时面临挑战，主要是因为它们缺乏“视觉反思”能力，即在推理过程中检查视觉信息的能力。研究观察到当前 VRMs 对视觉信息的关注度会随着生成响应的增长而迅速下降。

Method: 为了解决上述挑战，研究提出了 Reflection-V 模型，通过构建面向视觉的推理数据（利用 VLM 和推理 LLM 之间的交互代理来实现冷启动学习）和设计基于视觉注意力的奖励模型（在强化学习中鼓励模型依赖视觉信息），来增强视觉反思能力。

Result: Reflection-V 在多个视觉推理基准测试中表现出显著的改进，并且在推理过程中能更强、更持续地依赖视觉信息，表明其视觉反思能力得到有效增强。

Conclusion: Reflection-V 模型通过其创新的数据构建和奖励设计方法，成功地提升了视觉推理模型在视觉反思方面的能力，从而在各项视觉推理任务中取得了优越的性能。

Abstract: Recent advances in text-only "slow-thinking" reasoning have prompted efforts
to transfer this capability to vision-language models (VLMs), for training
visual reasoning models (\textbf{VRMs}). owever, such transfer faces critical
challenges: Effective "slow thinking" in VRMs requires \textbf{visual
reflection}, the ability to check the reasoning process based on visual
information. Through quantitative analysis, we observe that current VRMs
exhibit limited visual reflection, as their attention to visual information
diminishes rapidly with longer generated responses. To address this challenge,
we propose a new VRM \textbf{Reflection-V}, which enhances visual reflection
based on reasoning data construction for cold-start and reward design for
reinforcement learning (RL). Firstly, we construct vision-centered reasoning
data by leveraging an agent that interacts between VLMs and reasoning LLMs,
enabling cold-start learning of visual reflection patterns. Secondly, a visual
attention based reward model is employed during RL to encourage reasoning based
on visual information. Therefore, \textbf{Reflection-V} demonstrates
significant improvements across multiple visual reasoning benchmarks.
Furthermore, \textbf{Reflection-V} maintains a stronger and more consistent
reliance on visual information during visual reasoning, indicating effective
enhancement in visual reflection capabilities.

</details>


### [119] [Enriched text-guided variational multimodal knowledge distillation network (VMD) for automated diagnosis of plaque vulnerability in 3D carotid artery MRI](https://arxiv.org/abs/2509.11924)
*Bo Cao,Fan Yu,Mengmeng Feng,SenHao Zhang,Xin Meng,Yue Zhang,Zhen Qian,Jie Lu*

Main category: cs.CV

TL;DR: 该研究提出了一种结合变分推理和多模态知识蒸馏（VMD）的方法，以利用放射科医生的领域知识来自动诊断颈动脉斑块的易损性，解决了仅依靠3D MRI图像诊断的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于难以直接从3D MRI图像中诊断颈动脉斑块的易损性，并且放射科医生通常采用多模态方法结合专业知识进行诊断，因此需要开发能够利用领域知识的多模态诊断网络。

Method: 提出了一种名为VMD（变分推理和多模态知识蒸馏）的策略，该策略能够利用有限的图像标注和放射学报告中的跨模态先验知识，以增强对未标注3D MRI图像的诊断网络准确性。

Result: 在内部收集的数据集上进行了实验，验证了所提出的VMD策略的有效性。

Conclusion: 所提出的VMD策略能够有效地利用跨模态先验知识，提高颈动脉斑块易损性诊断的准确性，尤其是在标注数据有限的情况下。

Abstract: Multimodal learning has attracted much attention in recent years due to its
ability to effectively utilize data features from a variety of different
modalities. Diagnosing the vulnerability of atherosclerotic plaques directly
from carotid 3D MRI images is relatively challenging for both radiologists and
conventional 3D vision networks. In clinical practice, radiologists assess
patient conditions using a multimodal approach that incorporates various
imaging modalities and domain-specific expertise, paving the way for the
creation of multimodal diagnostic networks. In this paper, we have developed an
effective strategy to leverage radiologists' domain knowledge to automate the
diagnosis of carotid plaque vulnerability through Variation inference and
Multimodal knowledge Distillation (VMD). This method excels in harnessing
cross-modality prior knowledge from limited image annotations and radiology
reports within training data, thereby enhancing the diagnostic network's
accuracy for unannotated 3D MRI images. We conducted in-depth experiments on
the dataset collected in-house and verified the effectiveness of the VMD
strategy we proposed.

</details>


### [120] [Graph Algorithm Unrolling with Douglas-Rachford Iterations for Image Interpolation with Guaranteed Initialization](https://arxiv.org/abs/2509.11926)
*Xue Zhang,Bingshuo Hu,Gene Cheung*

Main category: cs.CV

TL;DR: 通过学习扰动矩阵来改进基于图的神经网络，以解决图像插值问题，并在减少网络参数的同时获得最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的深度神经网络（DNN）在训练过程中容易陷入局部最小值，影响性能。特别是在图像插值问题中，需要更优的初始化和优化方法。

Method: 提出一种新颖的基于图神经网络的方法。首先，根据已知的插值器 $\Theta$ 初始化图的邻接矩阵 A，以此为基线。然后，通过学习扰动矩阵 P 和 P(2) 来增强 A，并使用 Douglas-Rachford (DR) 迭代来实现恢复效果，最后将这些迭代展开成一个轻量级的、可解释的神经网络。

Result: 该方法在图像插值任务上取得了最先进的性能，同时显著减少了所需的网络参数数量。

Conclusion: 通过学习扰动矩阵来增强基于图的神经网络，可以有效地解决图像插值问题，并在减少模型复杂性的同时提高性能。

Abstract: Conventional deep neural nets (DNNs) initialize network parameters at random
and then optimize each one via stochastic gradient descent (SGD), resulting in
substantial risk of poor-performing local minima.Focusing on the image
interpolation problem and leveraging a recent theorem that maps a
(pseudo-)linear interpolator {\Theta} to a directed graph filter that is a
solution to a MAP problem regularized with a graph shift variation (GSV) prior,
we first initialize a directed graph adjacency matrix A based on a known
interpolator {\Theta}, establishing a baseline performance.Then, towards
further gain, we learn perturbation matrices P and P(2) from data to augment A,
whose restoration effects are implemented via Douglas-Rachford (DR) iterations,
which we unroll into a lightweight interpretable neural net.Experimental
results demonstrate state-of-the-art image interpolation results, while
drastically reducing network parameters.

</details>


### [121] [Sphere-GAN: a GAN-based Approach for Saliency Estimation in 360° Videos](https://arxiv.org/abs/2509.11948)
*Mahmoud Z. A. Wahba,Sara Baldoni,Federica Battisti*

Main category: cs.CV

TL;DR: Sphere-GAN是一种利用生成对抗网络和球形卷积进行360度视频显著性检测的模型，在预测显著图方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 尽管2D内容中的显著性估计得到了广泛研究，但针对360度全景视频的显著性估计算法却很少，而沉浸式应用的发展需要处理360度图像和视频的新方法。

Method: 提出了一种名为Sphere-GAN的显著性检测模型，该模型利用生成对抗网络（GAN）和球形卷积来处理360度视频。

Result: 在公共360度视频显著性数据集上进行的大量实验表明，Sphere-GAN在准确预测显著图方面优于最先进的模型。

Conclusion: Sphere-GAN是360度视频显著性检测的一个有效模型，能够准确预测显著图。

Abstract: The recent success of immersive applications is pushing the research
community to define new approaches to process 360{\deg} images and videos and
optimize their transmission. Among these, saliency estimation provides a
powerful tool that can be used to identify visually relevant areas and,
consequently, adapt processing algorithms. Although saliency estimation has
been widely investigated for 2D content, very few algorithms have been proposed
for 360{\deg} saliency estimation. Towards this goal, we introduce Sphere-GAN,
a saliency detection model for 360{\deg} videos that leverages a Generative
Adversarial Network with spherical convolutions. Extensive experiments were
conducted using a public 360{\deg} video saliency dataset, and the results
demonstrate that Sphere-GAN outperforms state-of-the-art models in accurately
predicting saliency maps.

</details>


### [122] [CLAIRE: A Dual Encoder Network with RIFT Loss and Phi-3 Small Language Model Based Interpretability for Cross-Modality Synthetic Aperture Radar and Optical Land Cover Segmentation](https://arxiv.org/abs/2509.11952)
*Debopom Sutradhar,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Reem E. Mohamed,Sheikh Izzal Azid,Sami Azam*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CLAIRE的双编码器模型，利用光学和SAR影像的互补特征进行土地覆盖分类，并使用RIFT混合损失函数解决类别不平衡问题，同时引入了基于小型语言模型(Phi-3)的解释模块以提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有卫星影像土地覆盖分类方法在处理复杂地貌、类间相似性及类别不平衡方面存在挑战。

Method: 提出了一种双编码器架构，独立提取光学和SAR影像特征，并通过跨模态注意力融合模块（CLAIRE）进行融合。同时，采用RIFT（加权焦点损失和Tversky损失）混合损失函数来处理类别不平衡问题。此外，引入了一个由小型语言模型（Phi-3）驱动的、以指标为驱动的推理模块，用于生成模型预测的样本特定解释。

Result: 在WHU-OPT-SAR数据集上，CLAIRE模型达到了56.02%的mIoU和84.56%的OA。在OpenEarthMap-SAR数据集上，模型表现出良好的泛化能力，mIoU为59.89%，OA为73.92%。在PIE-RGB-SAR数据集上，模型在云层遮挡条件下表现出卓越的鲁棒性，mIoU达到86.86%，OA为94.58%。

Conclusion: CLAIRE模型通过结合多模态影像特征和创新的损失函数，有效解决了土地覆盖分类中的挑战，并在多个基准数据集上取得了有竞争力的性能。此外，引入的解释模块显著增强了模型的可解释性。

Abstract: Accurate land cover classification from satellite imagery is crucial in
environmental monitoring and sustainable resource management. However, it
remains challenging due to the complexity of natural landscapes, the visual
similarity between classes, and the significant class imbalance in the
available datasets. To address these issues, we propose a dual encoder
architecture that independently extracts modality-specific features from
optical and Synthetic Aperture Radar (SAR) imagery, which are then fused using
a cross-modality attention-fusion module named Cross-modality Land cover
segmentation with Attention and Imbalance-aware Reasoning-Enhanced Explanations
(CLAIRE). This fusion mechanism highlights complementary spatial and textural
features, enabling the network to better capture detailed and diverse land
cover patterns. We incorporate a hybrid loss function that utilizes Weighted
Focal Loss and Tversky Loss named RIFT (Rare-Instance Focal-Tversky) to address
class imbalance and improve segmentation performance across underrepresented
categories. Our model achieves competitive performance across multiple
benchmarks: a mean Intersection over Union (mIoU) of 56.02% and Overall
Accuracy (OA) of 84.56% on the WHU-OPT-SAR dataset; strong generalization with
a mIoU of 59.89% and OA of 73.92% on the OpenEarthMap-SAR dataset; and
remarkable robustness under cloud-obstructed conditions, achieving an mIoU of
86.86% and OA of 94.58% on the PIE-RGB-SAR dataset. Additionally, we introduce
a metric-driven reasoning module generated by a Small Language Model (Phi-3),
which generates expert-level, sample-specific justifications for model
predictions, thereby enhancing transparency and interpretability.

</details>


### [123] [Robust Concept Erasure in Diffusion Models: A Theoretical Perspective on Security and Robustness](https://arxiv.org/abs/2509.12024)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wen,Le Ku,Daheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: SCORE框架通过对抗性独立性问题来解决扩散模型中的概念擦除问题，旨在消除敏感或有害概念，同时保持模型生成能力，并在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成图像方面取得了巨大成功，但也带来了隐私、公平性和安全风险。因此，迫切需要一种方法来擦除模型中的敏感或有害概念（如NSFW内容、私人个体、艺术风格），同时保留其整体生成能力。

Method: SCORE框架将概念擦除视为一个对抗性独立性问题，理论上保证模型输出与被擦除概念在统计上无关。该方法通过最小化目标概念与生成输出之间的互信息来实现可证明的擦除效果，并结合了对抗性优化、轨迹一致性和显著性驱动的微调。

Result: 在Stable Diffusion和FLUX模型上，SCORE在物体擦除、NSFW内容移除、名人面部抑制和艺术风格反学习四个具有挑战性的基准测试中，擦除效果比EraseAnything、ANT、MACE、ESD和UCE等最先进方法高出12.5%，同时保持了相当或更好的图像质量。

Conclusion: SCORE框架通过结合对抗性优化、轨迹一致性和显著性驱动的微调，为扩散模型中的安全、鲁棒的概念擦除设定了新的标准。

Abstract: Diffusion models have achieved unprecedented success in image generation but
pose increasing risks in terms of privacy, fairness, and security. A growing
demand exists to \emph{erase} sensitive or harmful concepts (e.g., NSFW
content, private individuals, artistic styles) from these models while
preserving their overall generative capabilities. We introduce \textbf{SCORE}
(Secure and Concept-Oriented Robust Erasure), a novel framework for robust
concept removal in diffusion models. SCORE formulates concept erasure as an
\emph{adversarial independence} problem, theoretically guaranteeing that the
model's outputs become statistically independent of the erased concept. Unlike
prior heuristic methods, SCORE minimizes the mutual information between a
target concept and generated outputs, yielding provable erasure guarantees. We
provide formal proofs establishing convergence properties and derive upper
bounds on residual concept leakage. Empirically, we evaluate SCORE on Stable
Diffusion and FLUX across four challenging benchmarks: object erasure, NSFW
removal, celebrity face suppression, and artistic style unlearning. SCORE
consistently outperforms state-of-the-art methods including EraseAnything, ANT,
MACE, ESD, and UCE, achieving up to \textbf{12.5\%} higher erasure efficacy
while maintaining comparable or superior image quality. By integrating
adversarial optimization, trajectory consistency, and saliency-driven
fine-tuning, SCORE sets a new standard for secure and robust concept erasure in
diffusion models.

</details>


### [124] [RAM++: Robust Representation Learning via Adaptive Mask for All-in-One Image Restoration](https://arxiv.org/abs/2509.12039)
*Zilong Zhang,Chujie Qin,Chunle Guo,Yong Zhang,Chao Xue,Ming-Ming Cheng,Chongyi Li*

Main category: cs.CV

TL;DR: RAM++是一个两阶段框架，用于集成高层语义理解和低层纹理生成，以实现面向内容的鲁棒图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理与图像结构强耦合的极端退化场景时存在局限性，RAM++旨在解决这个问题，并克服性能不平衡、过拟合和泛化能力弱等常见挑战。

Method: RAM++采用三种关键设计：1) 提出了自适应感知掩码（AdaSAM）的预训练策略，在像素级别上对语义丰富和纹理区域进行掩码，使网络能够从各种退化中学习生成先验和图像内容先验。2) 提出了掩码属性引导（MAC）的精调策略，以调整对桥接掩码预训练和全图像精调之间的完整性差距有更高贡献的层。3) 提出鲁棒特征正则化（RFR）策略，利用DINOv2的语义一致和退化不相关的表示，以及高效的特征融合，实现忠实且语义连贯的恢复。

Result: RAM++在各种退化（包括已见、未见、极端和混合退化）下实现了鲁棒、均衡且最先进的性能。

Conclusion: RAM++通过其创新的设计，在图像恢复任务中展现了优越的鲁棒性和泛化能力，为处理复杂和极端退化场景提供了新的解决方案。

Abstract: This work presents Robust Representation Learning via Adaptive Mask (RAM++),
a two-stage framework for all-in-one image restoration. RAM++ integrates
high-level semantic understanding with low-level texture generation to achieve
content-oriented robust restoration. It addresses the limitations of existing
degradation-oriented methods in extreme scenarios (e.g., degradations strongly
coupled with image structures). RAM++ also mitigates common challenges such as
unbalanced performance across tasks, overfitting to seen degradations, and weak
generalization to unseen ones through three key designs: 1) Adaptive
Semantic-Aware Mask (AdaSAM): a pretraining strategy that applies pixel-level
masks to semantically rich and textured regions. This design enables the
network to learn both generative priors and image content priors from various
degradations. 2) Mask Attribute Conductance (MAC): a selective fine-tuning
strategy that adjusts the layers with higher contributions to bridge the
integrity gap between masked pretraining and full-image fine-tuning while
retaining learned priors. 3) Robust Feature Regularization (RFR): a strategy
that leverages DINOv2's semantically consistent and degradation-invariant
representations, together with efficient feature fusion, to achieve faithful
and semantically coherent restoration. With these designs, RAM++ achieves
robust, well-balanced, and state-of-the-art performance across seen, unseen,
extreme, and mixed degradations. Our code and model will be released at
https://github.com/DragonisCV/RAM

</details>


### [125] [Exploring Efficient Open-Vocabulary Segmentation in the Remote Sensing](https://arxiv.org/abs/2509.12040)
*Bingyu Li,Haocheng Dong,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: 本论文提出了一个用于遥感图像的开放词汇分割基准（OVRSISBench）和一种新的分割框架（RSKT-Seg），解决了现有方法在遥感领域应用的不足，并在基准测试中取得了显著的性能提升和效率改进。


<details>
  <summary>Details</summary>
Motivation: 开放词汇遥感图像分割（OVRSIS）在遥感领域应用不足，缺乏统一的评估基准和针对遥感域的专门方法，存在自然图像和遥感图像之间的领域差异。

Method: 提出OVRSISBench基准，用于统一评估。提出RSKT-Seg框架，包含多方向成本图聚合（RS-CMA）模块以捕获旋转不变性视觉线索，高效成本图融合（RS-Fusion）Transformer以联合建模空间和语义依赖，以及遥感知识迁移（RS-Transfer）模块以注入预训练知识和增强上采样实现域适应。

Result: 在OVRSISBench基准测试中，RSKT-Seg相比现有方法在mIoU上提升了3.8，在mACC上提升了5.9，并且实现了2倍的推理速度提升。

Conclusion: RSKT-Seg框架在遥感图像开放词汇分割任务上表现出色，通过提出的RS-CMA、RS-Fusion和RS-Transfer模块，有效解决了领域差异和效率问题，并在性能和速度上超越了现有方法。

Abstract: Open-Vocabulary Remote Sensing Image Segmentation (OVRSIS), an emerging task
that adapts Open-Vocabulary Segmentation (OVS) to the remote sensing (RS)
domain, remains underexplored due to the absence of a unified evaluation
benchmark and the domain gap between natural and RS images. To bridge these
gaps, we first establish a standardized OVRSIS benchmark (\textbf{OVRSISBench})
based on widely-used RS segmentation datasets, enabling consistent evaluation
across methods. Using this benchmark, we comprehensively evaluate several
representative OVS/OVRSIS models and reveal their limitations when directly
applied to remote sensing scenarios. Building on these insights, we propose
\textbf{RSKT-Seg}, a novel open-vocabulary segmentation framework tailored for
remote sensing. RSKT-Seg integrates three key components: (1) a
Multi-Directional Cost Map Aggregation (RS-CMA) module that captures
rotation-invariant visual cues by computing vision-language cosine similarities
across multiple directions; (2) an Efficient Cost Map Fusion (RS-Fusion)
transformer, which jointly models spatial and semantic dependencies with a
lightweight dimensionality reduction strategy; and (3) a Remote Sensing
Knowledge Transfer (RS-Transfer) module that injects pre-trained knowledge and
facilitates domain adaptation via enhanced upsampling. Extensive experiments on
the benchmark show that RSKT-Seg consistently outperforms strong OVS baselines
by +3.8 mIoU and +5.9 mACC, while achieving 2x faster inference through
efficient aggregation. Our code is
\href{https://github.com/LiBingyu01/RSKT-Seg}{\textcolor{blue}{here}}.

</details>


### [126] [Layout-Conditioned Autoregressive Text-to-Image Generation via Structured Masking](https://arxiv.org/abs/2509.12046)
*Zirui Zheng,Takashi Isobe,Tong Shen,Xu Jia,Jianbin Zhao,Xiaomin Li,Mengmeng Ge,Baolu Li,Qinghe Wang,Dong Li,Dong Zhou,Yunzhi Zhuge,Huchuan Lu,Emad Barsoum*

Main category: cs.CV

TL;DR: SMARLI是一个新颖的框架，用于基于自回归模型进行布局到图像的生成，通过结构化掩蔽策略有效整合空间布局约束，并结合基于GRPO的后训练方案，在保持AR模型结构简单性和生成效率的同时，实现优越的布局感知控制。


<details>
  <summary>Details</summary>
Motivation: 由于布局条件的稀疏性和特征纠缠的风险，将自回归（AR）模型扩展到布局条件生成仍然具有挑战性。

Method: 提出了一种名为SMARLI的新颖框架，它使用一种专门设计的结构化掩蔽策略来控制全局提示、布局和图像标记之间的交互，以实现AR模型与布局的结合。此外，还采用了一种基于GRPO的后训练方案，并设计了专门的布局奖励函数，以进一步提高生成质量和布局准确性。

Result: 实验结果表明，SMARLI能够无缝地将布局标记与文本和图像标记集成，而不会损害生成质量，并且在保持AR模型结构简单性和生成效率的同时，实现了优越的布局感知控制。

Conclusion: SMARLI框架能够有效地将布局信息整合到基于AR的图像生成中，克服了现有方法的局限性，并在布局感知控制方面取得了优越的性能。

Abstract: While autoregressive (AR) models have demonstrated remarkable success in
image generation, extending them to layout-conditioned generation remains
challenging due to the sparse nature of layout conditions and the risk of
feature entanglement. We present Structured Masking for AR-based
Layout-to-Image (SMARLI), a novel framework for layoutto-image generation that
effectively integrates spatial layout constraints into AR-based image
generation. To equip AR model with layout control, a specially designed
structured masking strategy is applied to attention computation to govern the
interaction among the global prompt, layout, and image tokens. This design
prevents mis-association between different regions and their descriptions while
enabling sufficient injection of layout constraints into the generation
process. To further enhance generation quality and layout accuracy, we
incorporate Group Relative Policy Optimization (GRPO) based post-training
scheme with specially designed layout reward functions for next-set-based AR
models. Experimental results demonstrate that SMARLI is able to seamlessly
integrate layout tokens with text and image tokens without compromising
generation quality. It achieves superior layoutaware control while maintaining
the structural simplicity and generation efficiency of AR models.

</details>


### [127] [A Computer Vision Pipeline for Individual-Level Behavior Analysis: Benchmarking on the Edinburgh Pig Dataset](https://arxiv.org/abs/2509.12047)
*Haiyu Yang,Enhong Liu,Jennifer Sun,Sumit Sharma,Meike van Leerdam,Sebastien Franceschini,Puchun Niu,Miel Hostens*

Main category: cs.CV

TL;DR: 本研究提出了一种利用计算机视觉技术自动分析动物行为的模块化流程，解决了传统手动观察的局限性，并在猪的行为识别任务上取得了显著的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统的动物行为观察方法耗时、主观且难以规模化，无法满足对动物福利、健康和生产力进行有效评估的需求。

Method: 研究人员开发了一个模块化流程，集成了零样本物体检测、运动感知跟踪与分割以及视觉变换器进行特征提取，以实现对群体饲养环境中动物行为的自动化分析，并解决了动物遮挡等问题。

Result: 该系统在爱丁堡猪行为视频数据集上进行了验证，其时间模型在多个行为任务上达到了94.2%的总体准确率，比现有方法提高了21.2个百分点，同时保持了93.3%的身份保存率和89.3%的物体检测精度。

Conclusion: 该模块化流程能够自动化、客观且持续地分析动物行为，为精准猪农业和福利评估提供了可扩展的解决方案，并有潜力适应其他物种，但需要进一步验证。

Abstract: Animal behavior analysis plays a crucial role in understanding animal
welfare, health status, and productivity in agricultural settings. However,
traditional manual observation methods are time-consuming, subjective, and
limited in scalability. We present a modular pipeline that leverages
open-sourced state-of-the-art computer vision techniques to automate animal
behavior analysis in a group housing environment. Our approach combines
state-of-the-art models for zero-shot object detection, motion-aware tracking
and segmentation, and advanced feature extraction using vision transformers for
robust behavior recognition. The pipeline addresses challenges including animal
occlusions and group housing scenarios as demonstrated in indoor pig
monitoring. We validated our system on the Edinburgh Pig Behavior Video Dataset
for multiple behavioral tasks. Our temporal model achieved 94.2% overall
accuracy, representing a 21.2 percentage point improvement over existing
methods. The pipeline demonstrated robust tracking capabilities with 93.3%
identity preservation score and 89.3% object detection precision. The modular
design suggests potential for adaptation to other contexts, though further
validation across species would be required. The open-source implementation
provides a scalable solution for behavior monitoring, contributing to precision
pig farming and welfare assessment through automated, objective, and continuous
analysis.

</details>


### [128] [AvatarSync: Rethinking Talking-Head Animation through Autoregressive Perspective](https://arxiv.org/abs/2509.12052)
*Yuchen Deng,Xiuyang Wu,Hai-Tao Zheng,Suiyang Zhang,Yi He,Yuxing Han*

Main category: cs.CV

TL;DR: AvatarSync是一个基于音素表示的自回归框架，可以从单个参考图像生成逼真、可控的动画头像，直接由文本或音频驱动，解决了现有方法的闪烁、身份漂移和推理速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN或扩散模型的说话头动画方法存在帧间闪烁、身份漂移和推理速度慢等问题，限制了其应用。AvatarSync旨在解决这些问题，提供更稳定、高效和可控的解决方案。

Method: AvatarSync采用基于音素表示的自回归框架，并结合两阶段生成策略：1. 面部关键帧生成（FKG），利用文本或音频到音素的映射，结合文本-帧因果注意力掩码生成关键帧。2. 帧间插值，使用基于时间戳感知的自适应策略和选择性状态空间模型，实现时间连贯性和视觉平滑度。

Result: 实验表明，AvatarSync在视觉保真度、时间一致性和计算效率方面优于现有的说话头动画方法，并优化了推理过程以提高效率。

Conclusion: AvatarSync是一个强大且可扩展的说话头动画框架，通过其新颖的基于音素的自回归方法和两阶段生成策略，克服了现有技术的局限性，并在视觉质量和效率方面取得了显著成果。

Abstract: Existing talking-head animation approaches based on Generative Adversarial
Networks (GANs) or diffusion models often suffer from inter-frame flicker,
identity drift, and slow inference. These limitations inherent to their video
generation pipelines restrict their suitability for applications. To address
this, we introduce AvatarSync, an autoregressive framework on phoneme
representations that generates realistic and controllable talking-head
animations from a single reference image, driven directly text or audio input.
In addition, AvatarSync adopts a two-stage generation strategy, decoupling
semantic modeling from visual dynamics, which is a deliberate "Divide and
Conquer" design. The first stage, Facial Keyframe Generation (FKG), focuses on
phoneme-level semantic representation by leveraging the many-to-one mapping
from text or audio to phonemes. A Phoneme-to-Visual Mapping is constructed to
anchor abstract phonemes to character-level units. Combined with a customized
Text-Frame Causal Attention Mask, the keyframes are generated. The second
stage, inter-frame interpolation, emphasizes temporal coherence and visual
smoothness. We introduce a timestamp-aware adaptive strategy based on a
selective state space model, enabling efficient bidirectional context
reasoning. To support deployment, we optimize the inference pipeline to reduce
latency without compromising visual fidelity. Extensive experiments show that
AvatarSync outperforms existing talking-head animation methods in visual
fidelity, temporal consistency, and computational efficiency, providing a
scalable and controllable solution.

</details>


### [129] [Robust Fetal Pose Estimation across Gestational Ages via Cross-Population Augmentation](https://arxiv.org/abs/2509.12062)
*Sebastian Diaz,Benjamin Billot,Neel Dey,Molin Zhang,Esra Abaci Turk,P. Ellen Grant,Polina Golland,Elfar Adalsteinsson*

Main category: cs.CV

TL;DR: 该研究提出了一种跨人群数据增强框架，使胎儿姿态估计模型能够仅使用来自较大学龄组的标注图像，就能鲁棒地泛化到较年轻的胎儿群体，从而改善了胎儿运动量化和早期妊娠健康监测。


<details>
  <summary>Details</summary>
Motivation: 现有胎儿运动量化方法在早期妊娠阶段效果不佳，因其难以泛化到不同胎龄的胎儿，且早期胎儿的标注数据稀缺。

Method: 提出一种针对胎儿的特定数据增强策略，模拟早期妊娠的宫内环境和胎儿姿势，以提高姿态估计模型的泛化能力。

Result: 该方法在较大学龄组和具有挑战性的早学龄组病例中均表现出更低的变异性和显著的改进。

Conclusion: 该研究提出的跨人群数据增强方法能够可靠地改善整个妊娠过程中的胎儿姿态估计，有望促进对高风险胎儿的早期临床检测和干预。

Abstract: Fetal motion is a critical indicator of neurological development and
intrauterine health, yet its quantification remains challenging, particularly
at earlier gestational ages (GA). Current methods track fetal motion by
predicting the location of annotated landmarks on 3D echo planar imaging (EPI)
time-series, primarily in third-trimester fetuses. The predicted landmarks
enable simplification of the fetal body for downstream analysis. While these
methods perform well within their training age distribution, they consistently
fail to generalize to early GAs due to significant anatomical changes in both
mother and fetus across gestation, as well as the difficulty of obtaining
annotated early GA EPI data. In this work, we develop a cross-population data
augmentation framework that enables pose estimation models to robustly
generalize to younger GA clinical cohorts using only annotated images from
older GA cohorts. Specifically, we introduce a fetal-specific augmentation
strategy that simulates the distinct intrauterine environment and fetal
positioning of early GAs. Our experiments find that cross-population
augmentation yields reduced variability and significant improvements across
both older GA and challenging early GA cases. By enabling more reliable pose
estimation across gestation, our work potentially facilitates early clinical
detection and intervention in challenging 4D fetal imaging settings. Code is
available at https://github.com/sebodiaz/cross-population-pose.

</details>


### [130] [End-to-End Learning of Multi-Organ Implicit Surfaces from 3D Medical Imaging Data](https://arxiv.org/abs/2509.12068)
*Farahdiba Zarin,Nicolas Padoy,Jérémy Dana,Vinkle Srivastav*

Main category: cs.CV

TL;DR: ImplMORe是一种用于从3D医学图像进行多器官重建的端到端深度学习方法，使用隐式表面表示，能够生成比输入图像更高分辨率的细粒度器官表面细节。


<details>
  <summary>Details</summary>
Motivation: 对3D医学成像进行不同器官的细粒度表面重建，可以为诊断和手术规划提供高级支持。然而，器官表示常受限于分辨率，高分辨率需要更多的内存和计算资源。隐式表示方法可以提供紧凑且可微的函数来表示3D对象形状，以缓解此问题。但由于架构和数据差异，这些方法不能直接应用于医学图像。

Method: ImplMORe是一种端到端深度学习方法，利用隐式表面表示进行3D医学图像的多器官重建。该方法结合了3D CNN编码器提取局部特征，并通过多尺度插值学习连续域中的特征（使用占位符函数）。

Result: 该方法在totalsegmentator数据集上进行了单器官和多器官重建。与基于离散显式表示的表面重建方法相比，ImplMORe利用占位符函数的连续特性，在生成比输入图像更高分辨率的器官细粒度表面细节方面表现更优。

Conclusion: ImplMORe通过利用隐式表面表示和占位符函数的连续特性，成功实现了从3D医学图像进行高分辨率、细粒度的多器官重建，优于传统的离散方法。

Abstract: The fine-grained surface reconstruction of different organs from 3D medical
imaging can provide advanced diagnostic support and improved surgical planning.
However, the representation of the organs is often limited by the resolution,
with a detailed higher resolution requiring more memory and computing
footprint. Implicit representations of objects have been proposed to alleviate
this problem in general computer vision by providing compact and differentiable
functions to represent the 3D object shapes. However, architectural and
data-related differences prevent the direct application of these methods to
medical images. This work introduces ImplMORe, an end-to-end deep learning
method using implicit surface representations for multi-organ reconstruction
from 3D medical images. ImplMORe incorporates local features using a 3D CNN
encoder and performs multi-scale interpolation to learn the features in the
continuous domain using occupancy functions. We apply our method for single and
multiple organ reconstructions using the totalsegmentator dataset. By
leveraging the continuous nature of occupancy functions, our approach
outperforms the discrete explicit representation based surface reconstruction
approaches, providing fine-grained surface details of the organ at a resolution
higher than the given input image. The source code will be made publicly
available at: https://github.com/CAMMA-public/ImplMORe

</details>


### [131] [U-Mamba2: Scaling State Space Models for Dental Anatomy Segmentation in CBCT](https://arxiv.org/abs/2509.12069)
*Zhi Qin Tan,Xiatian Zhu,Owen Addison,Yunpeng Li*

Main category: cs.CV

TL;DR: U-Mamba2是一种新颖的神经网络架构，通过集成Mamba2状态空间模型到U-Net架构中，并结合交互式点击提示、自监督学习和领域知识，在牙科CBCT多解剖结构分割任务中表现出色，在ToothFairy3挑战赛中取得了前三名的成绩。


<details>
  <summary>Details</summary>
Motivation: 牙科CBCT影像的准确解剖结构分割对于诊断和手术规划至关重要，但目前存在耗时且困难的挑战。

Method: 提出U-Mamba2架构，将Mamba2状态空间模型整合入U-Net，并引入交互式点击提示、跨注意力机制、自监督预训练以及牙科领域知识，以增强结构约束和效率。

Result: 在ToothFairy3挑战赛的两个任务中，U-Mamba2均取得前三名。任务1在独立测试中达到Dice 0.792，HD95 93.19。任务2在独立测试中达到Dice 0.852，HD95 7.39。代码已公开。

Conclusion: U-Mamba2是一种有效且高效的牙科CBCT多解剖结构分割方法，在实际应用中展现出优越的性能。

Abstract: Cone-Beam Computed Tomography (CBCT) is a widely used 3D imaging technique in
dentistry, providing volumetric information about the anatomical structures of
jaws and teeth. Accurate segmentation of these anatomies is critical for
clinical applications such as diagnosis and surgical planning, but remains
time-consuming and challenging. In this paper, we present U-Mamba2, a new
neural network architecture designed for multi-anatomy CBCT segmentation in the
context of the ToothFairy3 challenge. U-Mamba2 integrates the Mamba2 state
space models into the U-Net architecture, enforcing stronger structural
constraints for higher efficiency without compromising performance. In
addition, we integrate interactive click prompts with cross-attention blocks,
pre-train U-Mamba2 using self-supervised learning, and incorporate dental
domain knowledge into the model design to address key challenges of dental
anatomy segmentation in CBCT. Extensive experiments, including independent
tests, demonstrate that U-Mamba2 is both effective and efficient, securing top
3 places in both tasks of the Toothfairy3 challenge. In Task 1, U-Mamba2
achieved a mean Dice of 0.792, HD95 of 93.19 with the held-out test data, with
an average inference time of XX (TBC during the ODIN workshop). In Task 2,
U-Mamba2 achieved the mean Dice of 0.852 and HD95 of 7.39 with the held-out
test data. The code is publicly available at
https://github.com/zhiqin1998/UMamba2.

</details>


### [132] [Progressive Flow-inspired Unfolding for Spectral Compressive Imaging](https://arxiv.org/abs/2509.12079)
*Xiaodong Wang,Ping Wang,Zijun He,Mengjie Qin,Xin Yuan*

Main category: cs.CV

TL;DR: 提出了一种新的轨迹可控展开框架，通过强制执行从初始估计到高质量重建的平滑、连续优化路径来解决 CASSI 重建中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的 CASSI 重建方法在优化过程中存在不可控的重建轨迹，导致性能突然提升和非渐进式优化。

Method: 提出了一种新的轨迹可控展开框架，该框架通过强制执行从初始估计到高质量重建的平滑、连续优化路径。为了提高计算效率，设计了一个高效的空谱 Transformer 和一个频域融合模块。

Result: 实验证明，该方法在模拟数据和真实数据上都比现有最先进的方法具有更好的重建质量和效率。

Conclusion: 所提出的轨迹可控展开框架通过强制执行平滑、连续的优化路径，并在计算效率方面进行了优化，从而在 CASSI 重建任务上取得了最先进的性能。

Abstract: Coded aperture snapshot spectral imaging (CASSI) retrieves a 3D hyperspectral
image (HSI) from a single 2D compressed measurement, which is a highly
challenging reconstruction task. Recent deep unfolding networks (DUNs),
empowered by explicit data-fidelity updates and implicit deep denoisers, have
achieved the state of the art in CASSI reconstruction. However, existing
unfolding approaches suffer from uncontrollable reconstruction trajectories,
leading to abrupt quality jumps and non-gradual refinement across stages.
Inspired by diffusion trajectories and flow matching, we propose a novel
trajectory-controllable unfolding framework that enforces smooth, continuous
optimization paths from noisy initial estimates to high-quality
reconstructions. To achieve computational efficiency, we design an efficient
spatial-spectral Transformer tailored for hyperspectral reconstruction, along
with a frequency-domain fusion module to gurantee feature consistency.
Experiments on simulation and real data demonstrate that our method achieves
better reconstruction quality and efficiency than prior state-of-the-art
approaches.

</details>


### [133] [End-to-End 4D Heart Mesh Recovery Across Full-Stack and Sparse Cardiac MRI](https://arxiv.org/abs/2509.12090)
*Yihong Chen,Jiancheng Yang,Deniz Sayin Mercadier,Hieu Le,Juerg Schwitter,Pascal Fua*

Main category: cs.CV

TL;DR: TetHeart是一个端到端的框架，可以从完整或稀疏的CMR图像中重建心脏的4D网格模型，用于心脏运动分析。


<details>
  <summary>Details</summary>
Motivation: 现有的心脏运动重建方法需要完整的CMR图像序列，这在需要实时更新的术后场景中受到限制。本研究旨在开发一种能够处理稀疏观测数据的方法。

Method: TetHeart采用深度可变形四面体表示，结合了显式和隐式表示的优点，可以在共享的协同空间中捕捉不同心脏结构（如心室、心房、大动脉）的形状和运动。该方法首先使用高质量的完整数据集初始化详细的、患者特异性的心脏网格模型，然后可以利用任何可用的切片（从完整序列到单个切片）来更新模型。此外，还引入了一种注意力机制，用于自适应地融合来自不同切片的信息，并采用知识蒸馏策略，以应对极端稀疏情况下的重建挑战。该模型还采用了两阶段的弱监督学习方案，仅需关键帧（如舒张末期和收缩末期）的标注。

Result: TetHeart在三个大型公开数据集上进行了训练和验证，并在额外的私人干预和公开CMR数据集上进行了零样本外部评估。结果表明，TetHeart在术前和术中场景下均达到了最先进的准确性，并表现出强大的泛化能力。

Conclusion: TetHeart成功实现了从稀疏观测数据重建心脏运动的目标，为术中实时分析提供了新的可能性，并优于现有方法。

Abstract: Reconstructing cardiac motion from cine CMR sequences is critical for
diagnosis, prediction, and intervention. Existing methods rely on complete CMR
stacks to infer full heart motion, limiting their utility in intra-procedural
scenarios where only sparse observations are available. We present TetHeart,
the first end-to-end framework that unifies full 4D multi-structure heart mesh
recovery from both offline full-stack acquisitions and intra-procedural
sparse-slice observations. Our method leverages deep deformable tetrahedra, an
explicit-implicit hybrid representation, to capture shape and motion in a
coherent space shared across cardiac structures. It is initialized from
high-quality pre-procedural or offline-acquired full stacks to build detailed,
patient-specific heart meshes, which can then be updated using whatever slices
are available, from full stacks down to a single slice. We further incorporate
several key innovations: (i) an attentive mechanism for slice-adaptive 2D-3D
feature assembly that dynamically integrates information from arbitrary numbers
of slices at any position, combined with a distillation strategy from
full-slice to sparse-slice settings to ensure accurate reconstruction under
extreme sparsity; and (ii) a two-stage weakly supervised motion learning scheme
requiring only keyframe (e.g., ED and ES) annotations. Trained and validated on
three large public datasets and externally evaluated zero-shot on additional
private interventional and public CMR datasets, TetHeart achieves
state-of-the-art accuracy and strong generalization in both pre- and
intra-procedural settings.

</details>


### [134] [FS-SAM2: Adapting Segment Anything Model 2 for Few-Shot Semantic Segmentation via Low-Rank Adaptation](https://arxiv.org/abs/2509.12105)
*Bernardo Forni,Gabriele Lombardi,Federico Pozzi,Mirco Planamente*

Main category: cs.CV

TL;DR: 本研究提出了一种基于SAM2模型的少样本语义分割新方法FS-SAM2，该方法利用SAM2的视频分割能力，并结合低秩适配（LoRA）技术处理多样化图像，实现了高效且性能优越的少样本分割。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有少样本语义分割方法需要大量数据训练以及适应多样化图像的挑战，提出一种能够有效利用SAM2模型能力的少样本分割新方法。

Method: 利用SAM2模型的视频分割能力，并结合低秩适配（LoRA）技术对SAM2的原始模块进行微调，以适应多样化的图像数据，实现少样本分割。

Result: 在PASCAL-5$^i$、COCO-20$^i$和FSS-1000数据集上取得了优异的分割结果，并展示了出色的推理计算效率。

Conclusion: FS-SAM2是一种高效且性能优越的少样本语义分割方法，能够有效利用SAM2模型的强大能力，并能很好地适应多样化的图像数据。

Abstract: Few-shot semantic segmentation has recently attracted great attention. The
goal is to develop a model capable of segmenting unseen classes using only a
few annotated samples. Most existing approaches adapt a pre-trained model by
training from scratch an additional module. Achieving optimal performance with
these approaches requires extensive training on large-scale datasets. The
Segment Anything Model 2 (SAM2) is a foundational model for zero-shot image and
video segmentation with a modular design. In this paper, we propose a Few-Shot
segmentation method based on SAM2 (FS-SAM2), where SAM2's video capabilities
are directly repurposed for the few-shot task. Moreover, we apply a Low-Rank
Adaptation (LoRA) to the original modules in order to handle the diverse images
typically found in standard datasets, unlike the temporally connected frames
used in SAM2's pre-training. With this approach, only a small number of
parameters is meta-trained, which effectively adapts SAM2 while benefiting from
its impressive segmentation performance. Our method supports any K-shot
configuration. We evaluate FS-SAM2 on the PASCAL-5$^i$, COCO-20$^i$ and
FSS-1000 datasets, achieving remarkable results and demonstrating excellent
computational efficiency during inference. Code is available at
https://github.com/fornib/FS-SAM2

</details>


### [135] [RailSafeNet: Visual Scene Understanding for Tram Safety](https://arxiv.org/abs/2509.12125)
*Ing. Ondrej Valach,Ing. Ivan Gruber*

Main category: cs.CV

TL;DR: 该研究提出了一种名为RailSafeNet的实时框架，利用深度学习和图像处理技术，通过识别轨道、检测和分类附近物体及其风险来提高有轨电车与行人交互的安全性。


<details>
  <summary>Details</summary>
Motivation: 鉴于有轨电车在人口密集地区运行时，碰撞可能导致严重伤亡，本研究旨在通过设计一个利用数字图像处理、深度学习和人工智能的解决方案来提高行人、驾驶员、骑自行车者、宠物和有轨电车乘客的安全。

Method: 该框架融合了语义分割、对象检测和一个基于规则的距离评估器，仅使用单目视频来识别轨道、定位附近物体，并通过将其投影距离与标准的1435mm轨道规进行比较来对其风险进行分类。

Result: 在RailSem19数据集上进行的实验表明，经过类别筛选的SegFormer B3模型实现了65%的交并比（IoU），而经过微调的YOLOv8在IoU阈值为0.50时达到了75.6%的平均精度（mAP）。

Conclusion: RailSafeNet能够提供准确、标注需求低的场景理解，从而在危险情况升级之前向驾驶员发出警告，提高了轨道入侵检测的安全性。

Abstract: Tram-human interaction safety is an important challenge, given that trams
frequently operate in densely populated areas, where collisions can range from
minor injuries to fatal outcomes. This paper addresses the issue from the
perspective of designing a solution leveraging digital image processing, deep
learning, and artificial intelligence to improve the safety of pedestrians,
drivers, cyclists, pets, and tram passengers. We present RailSafeNet, a
real-time framework that fuses semantic segmentation, object detection and a
rule-based Distance Assessor to highlight track intrusions. Using only
monocular video, the system identifies rails, localises nearby objects and
classifies their risk by comparing projected distances with the standard 1435mm
rail gauge. Experiments on the diverse RailSem19 dataset show that a
class-filtered SegFormer B3 model achieves 65% intersection-over-union (IoU),
while a fine-tuned YOLOv8 attains 75.6% mean average precision (mAP) calculated
at an intersection over union (IoU) threshold of 0.50. RailSafeNet therefore
delivers accurate, annotation-light scene understanding that can warn drivers
before dangerous situations escalate. Code available at
https://github.com/oValach/RailSafeNet.

</details>


### [136] [3DViT-GAT: A Unified Atlas-Based 3D Vision Transformer and Graph Learning Framework for Major Depressive Disorder Detection Using Structural MRI Data](https://arxiv.org/abs/2509.12143)
*Nojod M. Alotaibi,Areej M. Alhothali,Manar S. Ali*

Main category: cs.CV

TL;DR: 该研究提出了一种结合视觉Transformer（ViT）和图神经网络（GNN）的统一框架，用于从结构磁共振成像（sMRI）中自动检测重度抑郁症（MDD）。该方法通过ViT提取3D区域嵌入，并利用GNN进行分类，同时探索了基于图谱和基于立方体两种区域定义策略。实验结果表明，基于图谱的方法优于基于立方体的方法，最佳模型在REST-meta-MDD数据集上达到了78.98%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的MDD检测方法在捕捉复杂脑部模式方面存在局限性，主要使用体素级特征或手工设计的区域表示。本研究旨在通过结合ViT和GNN，开发一种更有效的自动化MDD检测方法。

Method: 提出一个统一框架，使用ViT提取sMRI数据的3D区域嵌入，并利用GNN进行分类。探索了两种区域定义策略：1）基于图谱的方法；2）基于立方体的方法。通过余弦相似度图建立区域间关系，指导GNN分类。

Result: 在REST-meta-MDD数据集上进行的大量实验表明，该模型有效。采用10折交叉验证，最佳模型取得了78.98%的准确率、76.54%的敏感性、81.58%的特异性、81.58%的精确率和78.98%的F1分数。基于图谱的模型优于基于立方体的方法。

Conclusion: 结合ViT和GNN的统一框架在sMRI数据中检测MDD是有效的。使用领域特定的先验知识（如图谱）对于提高MDD检测性能至关重要。

Abstract: Major depressive disorder (MDD) is a prevalent mental health condition that
negatively impacts both individual well-being and global public health.
Automated detection of MDD using structural magnetic resonance imaging (sMRI)
and deep learning (DL) methods holds increasing promise for improving
diagnostic accuracy and enabling early intervention. Most existing methods
employ either voxel-level features or handcrafted regional representations
built from predefined brain atlases, limiting their ability to capture complex
brain patterns. This paper develops a unified pipeline that utilizes Vision
Transformers (ViTs) for extracting 3D region embeddings from sMRI data and
Graph Neural Network (GNN) for classification. We explore two strategies for
defining regions: (1) an atlas-based approach using predefined structural and
functional brain atlases, and (2) an cube-based method by which ViTs are
trained directly to identify regions from uniformly extracted 3D patches.
Further, cosine similarity graphs are generated to model interregional
relationships, and guide GNN-based classification. Extensive experiments were
conducted using the REST-meta-MDD dataset to demonstrate the effectiveness of
our model. With stratified 10-fold cross-validation, the best model obtained
78.98% accuracy, 76.54% sensitivity, 81.58% specificity, 81.58% precision, and
78.98% F1-score. Further, atlas-based models consistently outperformed the
cube-based approach, highlighting the importance of using domain-specific
anatomical priors for MDD detection.

</details>


### [137] [Open-ended Hierarchical Streaming Video Understanding with Vision Language Models](https://arxiv.org/abs/2509.12145)
*Hyolim Kang,Yunsu Park,Youngbeom Yoo,Yeeun Choi,Seon Joo Kim*

Main category: cs.CV

TL;DR: 该研究提出了一种新的视频理解任务：分层视频理解，并开发了一个名为OpenHOUSE的系统来解决该任务。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏分层和细粒度的时间标注，需要更强大的方法来理解视频中的动作和事件。

Method: 利用LLMs对原子动作进行分组以丰富现有数据集，并提出OpenHOUSE系统，该系统包含一个专门的流式模块，用于检测动作边界，从而实现开放式的分层在线事件理解。

Result: OpenHOUSE的流式模块能够准确检测相邻动作之间的边界，性能接近现有方法的两倍。

Conclusion: 分层视频理解是流式动作感知领域的未来方向，OpenHOUSE是实现这一目标的关键一步，它将强大的生成模型整合到视频理解中。

Abstract: We introduce Hierarchical Streaming Video Understanding, a task that combines
online temporal action localization with free-form description generation.
Given the scarcity of datasets with hierarchical and fine-grained temporal
annotations, we demonstrate that LLMs can effectively group atomic actions into
higher-level events, enriching existing datasets. We then propose OpenHOUSE
(Open-ended Hierarchical Online Understanding System for Events), which extends
streaming action perception beyond action classification. OpenHOUSE features a
specialized streaming module that accurately detects boundaries between closely
adjacent actions, nearly doubling the performance of direct extensions of
existing methods. We envision the future of streaming action perception in the
integration of powerful generative models, with OpenHOUSE representing a key
step in that direction.

</details>


### [138] [Multi Anatomy X-Ray Foundation Model](https://arxiv.org/abs/2509.12146)
*Nishank Singla,Krisztian Koos,Farzin Haddadpour,Amin Honarmandi Shandiz,Lovish Chum,Xiaojian Xu,Qing Jin,Erhan Bas*

Main category: cs.CV

TL;DR: XR-0是一个多解剖X光基础模型，使用自监督学习在115万张图像上训练，在12个数据集和20个下游任务上实现了最先进的性能，证明了解剖多样性和监督对于构建通用医学视觉模型至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的X射线AI基础模型主要局限于胸部解剖，未能广泛推广到临床任务。因此，需要一个能够处理多解剖结构并泛化到更广泛临床任务的基础模型。

Method: 使用涵盖不同解剖区域的大型私有数据集（115万张图像）进行自监督学习，构建了多解剖X射线基础模型XR-0。该模型在12个数据集和20个下游任务（包括分类、检索、分割、定位、视觉基础和报告生成）上进行了评估。

Result: XR-0在大多数多解剖任务上取得了最先进的性能，并在特定胸部基准测试上保持了竞争力。

Conclusion: 解剖多样性和监督对于构建健壮、通用的医学视觉模型至关重要，为构建可扩展、可适应的放射学AI系统铺平了道路。

Abstract: X-ray imaging is a ubiquitous in radiology, yet most existing AI foundation
models are limited to chest anatomy and fail to generalize across broader
clinical tasks. In this work, we introduce XR-0, the multi-anatomy X-ray
foundation model using self-supervised learning on a large, private dataset of
1.15 million images spanning diverse anatomical regions and evaluated across 12
datasets and 20 downstream tasks, including classification, retrieval,
segmentation, localization, visual grounding, and report generation. XR-0
achieves state-of-the-art performance on most multi-anatomy tasks and remains
competitive on chest-specific benchmarks. Our results demonstrate that
anatomical diversity and supervision are critical for building robust,
general-purpose medical vision models, paving the way for scalable and
adaptable AI systems in radiology.

</details>


### [139] [LoRA-fine-tuned Large Vision Models for Automated Assessment of Post-SBRT Lung Injury](https://arxiv.org/abs/2509.12155)
*M. Bolhassani,B. Veasey,E. Daugherty,S. Keltner,N. Kumar,N. Dunlap,A. Amini*

Main category: cs.CV

TL;DR: LoRA在诊断放射治疗引起的肺损伤（RILI）方面，与完全微调相比，在保持性能的同时显著降低了计算成本和训练时间。


<details>
  <summary>Details</summary>
Motivation: 研究LoRA用于微调大型视觉模型（DinoV2和SwinV2）以从X射线CT扫描中诊断放射治疗引起的肺损伤（RILI）的有效性。

Method: 将LoRA与传统的完全微调和仅推理方法进行比较，并使用不同大小的裁剪图像（50 mm3和75 mm3）以及不同的2D到3D数据适应技术来评估模型对空间上下文的敏感性。

Result: LoRA在诊断RILI方面实现了与传统微调相当或更优的性能，同时显著降低了计算成本和训练时间，因为它需要更少的训练参数。

Conclusion: LoRA是一种有效且高效的微调大型视觉模型以诊断RILI的方法，与传统微调相比具有计算优势。

Abstract: This study investigates the efficacy of Low-Rank Adaptation (LoRA) for
fine-tuning large Vision Models, DinoV2 and SwinV2, to diagnose
Radiation-Induced Lung Injury (RILI) from X-ray CT scans following Stereotactic
Body Radiation Therapy (SBRT). To evaluate the robustness and efficiency of
this approach, we compare LoRA with traditional full fine-tuning and
inference-only (no fine-tuning) methods. Cropped images of two sizes (50 mm3
and 75 mm3), centered at the treatment isocenter, in addition to different
adaptation techniques for adapting the 2D LVMs for 3D data were used to
determine the sensitivity of the models to spatial context. Experimental
results show that LoRA achieves comparable or superior performance to
traditional fine-tuning while significantly reducing computational costs and
training times by requiring fewer trainable parameters.

</details>


### [140] [Domain-Adaptive Pretraining Improves Primate Behavior Recognition](https://arxiv.org/abs/2509.12193)
*Felix B. Mueller,Timo Lueddecke,Richard Vogg,Alexander S. Ecker*

Main category: cs.CV

TL;DR: 使用领域自适应预训练（DAP）技术，通过自监督学习显著提高了猿类行为识别的准确性和mAP。


<details>
  <summary>Details</summary>
Motivation: 动物行为的计算机视觉分析在生态学、认知学和保护方面具有巨大潜力，但高昂的标注成本阻碍了大型数据集的创建，因此需要数据高效的学习方法。

Method: 利用预训练的V-JEPA模型，并结合领域自适应预训练（DAP），即在领域内数据上继续预训练，以改进猿类行为识别。

Result: 在两个大型猿类行为数据集（PanAf和ChimpACT）上，该方法分别比现有的最先进模型提高了6.1%的准确率和6.3%的mAP，其中大部分性能提升归功于DAP。

Conclusion: 领域自适应预训练（DAP）是一种无需标注样本即可提高动物行为识别性能的有效方法，具有巨大的应用潜力。

Abstract: Computer vision for animal behavior offers promising tools to aid research in
ecology, cognition, and to support conservation efforts. Video camera traps
allow for large-scale data collection, but high labeling costs remain a
bottleneck to creating large-scale datasets. We thus need data-efficient
learning approaches. In this work, we show that we can utilize self-supervised
learning to considerably improve action recognition on primate behavior. On two
datasets of great ape behavior (PanAf and ChimpACT), we outperform published
state-of-the-art action recognition models by 6.1 %pt. accuracy and 6.3 %pt.
mAP, respectively. We achieve this by utilizing a pretrained V-JEPA model and
applying domain-adaptive pretraining (DAP), i.e. continuing the pretraining
with in-domain data. We show that most of the performance gain stems from the
DAP. Our method promises great potential for improving the recognition of
animal behavior, as DAP does not require labeled samples. Code is available at
https://github.com/ecker-lab/dap-behavior

</details>


### [141] [3D Human Pose and Shape Estimation from LiDAR Point Clouds: A Review](https://arxiv.org/abs/2509.12197)
*Salma Galaaoui,Eduardo Valle,David Picard,Nermin Samet*

Main category: cs.CV

TL;DR: 该论文全面回顾了从野外激光雷达点云进行的3D人体姿态估计和人体网格恢复，提出了分类方法，并对现有方法进行了分析和比较。


<details>
  <summary>Details</summary>
Motivation: 为了全面回顾和分析从野外激光雷达点云进行的3D人体姿态估计和人体网格恢复的现有方法，并为该领域提供一个结构化的分类体系和基准。

Method: 对现有方法进行分类，分析其优缺点，并对三个常用数据集进行量化比较，统一评估指标定义，建立基准测试表格。

Result: 提出了一个结构化的分类体系，对现有方法进行了分析，量化比较了数据集，统一了评估指标，并建立了基准测试表格，为该领域的公平比较和进展提供了基础。

Conclusion: 该论文总结了激光雷达3D人体理解领域的开放挑战和研究方向，旨在推动该领域的发展。

Abstract: In this paper, we present a comprehensive review of 3D human pose estimation
and human mesh recovery from in-the-wild LiDAR point clouds. We compare
existing approaches across several key dimensions, and propose a structured
taxonomy to classify these methods. Following this taxonomy, we analyze each
method's strengths, limitations, and design choices. In addition, (i) we
perform a quantitative comparison of the three most widely used datasets,
detailing their characteristics; (ii) we compile unified definitions of all
evaluation metrics; and (iii) we establish benchmark tables for both tasks on
these datasets to enable fair comparisons and promote progress in the field. We
also outline open challenges and research directions critical for advancing
LiDAR-based 3D human understanding. Moreover, we maintain an accompanying
webpage that organizes papers according to our taxonomy and continuously update
it with new studies:
https://github.com/valeoai/3D-Human-Pose-Shape-Estimation-from-LiDAR

</details>


### [142] [OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling](https://arxiv.org/abs/2509.12201)
*Yang Zhou,Yifan Wang,Jianjun Zhou,Wenzheng Chang,Haoyu Guo,Zizun Li,Kaijing Ma,Xinyue Li,Yating Wang,Haoyi Zhu,Mingyu Liu,Dingning Liu,Jiange Yang,Zhoujie Fu,Junyi Chen,Chunhua Shen,Jiangmiao Pang,Kaipeng Zhang,Tong He*

Main category: cs.CV

TL;DR: 现有4D世界建模数据集缺乏动态复杂性、多领域多样性和空间-时间标注，限制了模型发展。本文提出了OmniWorld，一个大规模、多领域、多模态的数据集，旨在推动4D世界建模的研究。


<details>
  <summary>Details</summary>
Motivation: 现有4D世界建模数据集的不足，包括缺乏动态复杂性、多领域多样性和必要标注，阻碍了通用4D世界模型的发展。

Method: 创建了一个名为OmniWorld的新数据集，其中包含新收集的OmniWorld-Game数据集和几个经过筛选的公共数据集。基于此数据集，建立了一个具有挑战性的基准，并对现有SOTA方法进行了微调和评估。

Result: 在OmniWorld数据集上进行微调的SOTA方法在4D重建和视频生成任务上表现出显著的性能提升，验证了OmniWorld作为训练和评估资源的有效性。

Conclusion: OmniWorld数据集的提出将加速通用4D世界模型的发展，促进机器对物理世界的整体理解。

Abstract: The field of 4D world modeling - aiming to jointly capture spatial geometry
and temporal dynamics - has witnessed remarkable progress in recent years,
driven by advances in large-scale generative models and multimodal learning.
However, the development of truly general 4D world models remains fundamentally
constrained by the availability of high-quality data. Existing datasets and
benchmarks often lack the dynamic complexity, multi-domain diversity, and
spatial-temporal annotations required to support key tasks such as 4D geometric
reconstruction, future prediction, and camera-control video generation. To
address this gap, we introduce OmniWorld, a large-scale, multi-domain,
multi-modal dataset specifically designed for 4D world modeling. OmniWorld
consists of a newly collected OmniWorld-Game dataset and several curated public
datasets spanning diverse domains. Compared with existing synthetic datasets,
OmniWorld-Game provides richer modality coverage, larger scale, and more
realistic dynamic interactions. Based on this dataset, we establish a
challenging benchmark that exposes the limitations of current state-of-the-art
(SOTA) approaches in modeling complex 4D environments. Moreover, fine-tuning
existing SOTA methods on OmniWorld leads to significant performance gains
across 4D reconstruction and video generation tasks, strongly validating
OmniWorld as a powerful resource for training and evaluation. We envision
OmniWorld as a catalyst for accelerating the development of general-purpose 4D
world models, ultimately advancing machines' holistic understanding of the
physical world.

</details>


### [143] [LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence](https://arxiv.org/abs/2509.12203)
*Zixin Yin,Xili Dai,Duomin Wang,Xianfang Zeng,Lionel M. Ni,Gang Yu,Heung-Yeung Shum*

Main category: cs.CV

TL;DR: LazyDrag是首个用于多模态扩散Transformer的拖拽式图像编辑方法，通过生成显式对应图消除了对隐式点匹配的依赖，实现了稳定的全强度反演，无需测试时优化（TTO），并统一了精确的几何控制和文本引导。


<details>
  <summary>Details</summary>
Motivation: 现有的基于拖拽的编辑方法依赖于隐式点匹配，导致反演强度减弱和测试时优化（TTO）成本高，限制了扩散模型的生成能力。

Method: LazyDrag生成用户拖拽输入的显式对应图，作为增强注意力控制的可靠参考，从而消除对隐式点匹配的依赖。

Result: LazyDrag实现了拖拽式编辑任务中首个稳定的全强度反演，无需TTO，并解锁了扩散模型的生成能力，能够实现精确的几何控制和文本引导，支持多轮编辑工作流，并在DragBench上取得了优于基线方法的性能。

Conclusion: LazyDrag通过引入显式对应图，克服了现有拖拽编辑方法的局限性，实现了新的最先进性能，并为图像编辑范式开辟了新途径。

Abstract: The reliance on implicit point matching via attention has become a core
bottleneck in drag-based editing, resulting in a fundamental compromise on
weakened inversion strength and costly test-time optimization (TTO). This
compromise severely limits the generative capabilities of diffusion models,
suppressing high-fidelity inpainting and text-guided creation. In this paper,
we introduce LazyDrag, the first drag-based image editing method for
Multi-Modal Diffusion Transformers, which directly eliminates the reliance on
implicit point matching. In concrete terms, our method generates an explicit
correspondence map from user drag inputs as a reliable reference to boost the
attention control. This reliable reference opens the potential for a stable
full-strength inversion process, which is the first in the drag-based editing
task. It obviates the necessity for TTO and unlocks the generative capability
of models. Therefore, LazyDrag naturally unifies precise geometric control with
text guidance, enabling complex edits that were previously out of reach:
opening the mouth of a dog and inpainting its interior, generating new objects
like a ``tennis ball'', or for ambiguous drags, making context-aware changes
like moving a hand into a pocket. Additionally, LazyDrag supports multi-round
workflows with simultaneous move and scale operations. Evaluated on the
DragBench, our method outperforms baselines in drag accuracy and perceptual
quality, as validated by VIEScore and human evaluation. LazyDrag not only
establishes new state-of-the-art performance, but also paves a new way to
editing paradigms.

</details>


### [144] [Character-Centric Understanding of Animated Movies](https://arxiv.org/abs/2509.12204)
*Zhongrui Gui,Junyu Xie,Tengda Han,Weidi Xie,Andrew Zisserman*

Main category: cs.CV

TL;DR: 提出一个音频-视觉通道，用于自动识别动画角色，并生成音频描述和角色感知字幕。


<details>
  <summary>Details</summary>
Motivation: 现有的面部识别系统难以处理动画角色极端多样的外观、动作和变形；需要针对动画内容进行角色识别以增强理解。

Method: 构建包含视觉和音频样本的音频-视觉角色库，用于多模态角色识别；探索音频描述生成和角色感知字幕两个下游应用；引入包含75部动画电影的CMD-AM数据集。

Result: 所提出的角色中心流程在可访问性和叙事理解方面显著优于基于面部检测的方法。

Conclusion: 所提出的音频-视觉管道能够有效地识别动画角色，并为改善动画内容的辅助功能做出贡献。

Abstract: Animated movies are captivating for their unique character designs and
imaginative storytelling, yet they pose significant challenges for existing
recognition systems. Unlike the consistent visual patterns detected by
conventional face recognition methods, animated characters exhibit extreme
diversity in their appearance, motion, and deformation. In this work, we
propose an audio-visual pipeline to enable automatic and robust animated
character recognition, and thereby enhance character-centric understanding of
animated movies. Central to our approach is the automatic construction of an
audio-visual character bank from online sources. This bank contains both visual
exemplars and voice (audio) samples for each character, enabling subsequent
multi-modal character recognition despite long-tailed appearance distributions.
Building on accurate character recognition, we explore two downstream
applications: Audio Description (AD) generation for visually impaired
audiences, and character-aware subtitling for the hearing impaired. To support
research in this domain, we introduce CMD-AM, a new dataset of 75 animated
movies with comprehensive annotations. Our character-centric pipeline
demonstrates significant improvements in both accessibility and narrative
comprehension for animated content over prior face-detection-based approaches.
For the code and dataset, visit
https://www.robots.ox.ac.uk/~vgg/research/animated_ad/.

</details>


### [145] [Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling](https://arxiv.org/abs/2310.06389)
*Huangjie Zheng,Zhendong Wang,Jianbo Yuan,Guanghan Ning,Pengcheng He,Quanzeng You,Hongxia Yang,Mingyuan Zhou*

Main category: cs.CV

TL;DR: LEGO bricks是一种可重构的扩散模型骨干网络，通过局部特征增强和全局内容协调，提高了训练效率和采样速度，并支持可变分辨率的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在训练和采样时计算成本高，且用于图像生成的网络骨干（如U-Net和Vision Transformer）不够灵活，无法满足可变分辨率或使用比训练时更小的网络进行生成的需求。

Method: 提出LEGO bricks，包含局部特征增强（MLP）和全局内容协调（Transformer）模块，允许在测试时重构骨干网络，选择性跳过模块以降低采样成本，并保持所有模块中全分辨率图像的一致性。

Result: LEGO bricks 提高了训练效率，加快了收敛速度，实现了可变分辨率的图像生成，同时保持了强大的生成性能。与现有方法相比，LEGO显著降低了采样时间。

Conclusion: LEGO bricks 为扩散模型提供了一种有价值的增强，解决了现有模型在效率和灵活性方面存在的挑战。

Abstract: Diffusion models excel at generating photo-realistic images but come with
significant computational costs in both training and sampling. While various
techniques address these computational challenges, a less-explored issue is
designing an efficient and adaptable network backbone for iterative refinement.
Current options like U-Net and Vision Transformer often rely on
resource-intensive deep networks and lack the flexibility needed for generating
images at variable resolutions or with a smaller network than used in training.
This study introduces LEGO bricks, which seamlessly integrate Local-feature
Enrichment and Global-content Orchestration. These bricks can be stacked to
create a test-time reconfigurable diffusion backbone, allowing selective
skipping of bricks to reduce sampling costs and generate higher-resolution
images than the training data. LEGO bricks enrich local regions with an MLP and
transform them using a Transformer block while maintaining a consistent
full-resolution image across all bricks. Experimental results demonstrate that
LEGO bricks enhance training efficiency, expedite convergence, and facilitate
variable-resolution image generation while maintaining strong generative
performance. Moreover, LEGO significantly reduces sampling time compared to
other methods, establishing it as a valuable enhancement for diffusion models.
Our code and project page are available at
https://jegzheng.github.io/LEGODiffusion.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [146] [Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment](https://arxiv.org/abs/2509.10546)
*Gang Cheng,Haibo Jin,Wenbin Zhang,Haohan Wang,Jun Zhuang*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在金融领域的应用日益广泛，但现有的红队测试研究主要集中在有害内容，忽视了监管风险。本研究通过红队测试方法，引入了一种名为“风险隐藏攻击”（RCA）的新型多轮框架，该框架通过迭代隐藏监管风险，诱导大型语言模型产生看似合规但实际违反监管的响应。为了进行系统评估，我们构建了金融领域特定基准FIN-Bench，以评估大型语言模型在金融环境中的安全性。在FIN-Bench上的大量实验表明，RCA能够有效绕过九种主流大型语言模型，平均攻击成功率（ASR）达到93.18%，其中在GPT-4.1上为98.28%，在OpenAI o1上为97.56%。这些发现揭示了当前对齐技术存在的关键差距，并强调了在金融领域加强监管机制的紧迫性。我们希望这项工作能为推进健壮且领域感知的大型语言模型对齐提供实践见解。


<details>
  <summary>Details</summary>
Motivation: 现有红队测试研究主要关注有害内容，忽视了金融领域LLM的监管风险。本研究旨在填补这一空白，调查金融LLM在监管风险方面的脆弱性。

Method: 提出了一种名为“风险隐藏攻击”（RCA）的新型多轮框架，通过迭代隐藏监管风险来诱导LLM产生违规响应。同时，构建了金融领域特定基准FIN-Bench用于系统评估。

Result: RCA成功绕过了九种主流LLM，平均攻击成功率（ASR）达到93.18%，在GPT-4.1上达到98.28%，在OpenAI o1上达到97.56%。

Conclusion: 当前的LLM对齐技术在金融领域存在关键漏洞，需要加强监管机制以应对监管风险。这项研究为开发更健壮、更具领域意识的LLM对齐方法提供了实践见解。

Abstract: Large Language Models (LLMs) are increasingly integrated into financial
applications, yet existing red-teaming research primarily targets harmful
content, largely neglecting regulatory risks. In this work, we aim to
investigate the vulnerability of financial LLMs through red-teaming approaches.
We introduce Risk-Concealment Attacks (RCA), a novel multi-turn framework that
iteratively conceals regulatory risks to provoke seemingly compliant yet
regulatory-violating responses from LLMs. To enable systematic evaluation, we
construct FIN-Bench, a domain-specific benchmark for assessing LLM safety in
financial contexts. Extensive experiments on FIN-Bench demonstrate that RCA
effectively bypasses nine mainstream LLMs, achieving an average attack success
rate (ASR) of 93.18%, including 98.28% on GPT-4.1 and 97.56% on OpenAI o1.
These findings reveal a critical gap in current alignment techniques and
underscore the urgent need for stronger moderation mechanisms in financial
domains. We hope this work offers practical insights for advancing robust and
domain-aware LLM alignment.

</details>


### [147] [No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes](https://arxiv.org/abs/2509.10625)
*Iván Vicente Moreno Cencerrado,Arnau Padrés Masdemont,Anton Gonzalvez Hawthorne,David Demitri Africa,Lorenzo Pacchiardi*

Main category: cs.CL

TL;DR: LLMs can anticipate their answer correctness by analyzing internal activations, with predictive power emerging in intermediate layers and correlating with 'I don't know' responses. This ability generalizes to various knowledge domains but falters on mathematical reasoning.


<details>
  <summary>Details</summary>
Motivation: This paper investigates whether Large Language Models (LLMs) can predict their own accuracy before generating an answer.

Method: The study extracts model activations after processing a question but before generating any response. Linear probes are trained on these activations to predict the correctness of the forthcoming answer. The probes are trained on trivia questions and tested on various in-distribution and out-of-distribution datasets, including those requiring mathematical reasoning.

Result: Probes trained on internal activations successfully predict answer correctness across different model sizes and knowledge domains, outperforming black-box methods and verbalized confidence. Predictive power is concentrated in intermediate layers, suggesting self-assessment arises during computation. The predictive direction also correlates with the model's confidence, particularly when it responds 'I don't know'. However, this predictive ability is limited for questions involving mathematical reasoning.

Conclusion: LLMs exhibit an internal mechanism to anticipate their answer correctness, which emerges during computation and extends to confidence assessment. This finding is crucial for understanding LLM internals, although limitations exist for complex reasoning tasks like mathematics.

Abstract: Do large language models (LLMs) anticipate when they will answer correctly?
To study this, we extract activations after a question is read but before any
tokens are generated, and train linear probes to predict whether the model's
forthcoming answer will be correct. Across three open-source model families
ranging from 7 to 70 billion parameters, projections on this "in-advance
correctness direction" trained on generic trivia questions predict success in
distribution and on diverse out-of-distribution knowledge datasets,
outperforming black-box baselines and verbalised predicted confidence.
Predictive power saturates in intermediate layers, suggesting that
self-assessment emerges mid-computation. Notably, generalisation falters on
questions requiring mathematical reasoning. Moreover, for models responding "I
don't know", doing so strongly correlates with the probe score, indicating that
the same direction also captures confidence. By complementing previous results
on truthfulness and other behaviours obtained with probes and sparse
auto-encoders, our work contributes essential findings to elucidate LLM
internals.

</details>


### [148] [Interdisciplinary Research in Conversation: A Case Study in Computational Morphology for Language Documentation](https://arxiv.org/abs/2509.10644)
*Enora Rice,Katharina von der Wense,Alexis Palmer*

Main category: cs.CL

TL;DR: 计算形态学在语言记录方面有潜力，但研究成果在实际应用中受限。该论文认为，这是因为自然语言处理（NLP）领域的研究与实践之间存在脱节，若不整合以用户为中心的设计（UCD），计算形态学将变得脱离实际且无效。通过对IGT生成模型GlossLM的用户研究，发现尽管模型性能优越，但未能满足实际记录需求。这引发了关于模型约束、标签标准化、分词和个性化的新研究问题。论文强调，以用户为中心不仅能创造更有效的工具，还能引导更丰富、更相关的研究方向。


<details>
  <summary>Details</summary>
Motivation: 计算形态学在语言记录方面有潜力，但研究成果在实际应用中受限，这揭示了研究与实践之间存在脱节，计算形态学有脱离实际且无效的风险。

Method: 通过对GlossLM（一个先进的多语言IGT生成模型）进行一项有三位纪录语言学家参与的小规模用户研究，来展示UCD原则如何重塑研究议程。

Result: 尽管GlossLM在指标上表现优异，但其未能满足在实际记录环境中用户的核心可用性需求。

Conclusion: 以用户为中心的设计不仅能创造更有效的工具，还能引发更丰富、更相关的研究方向，解决模型约束、标签标准化、分词和个性化等方面的新问题。

Abstract: Computational morphology has the potential to support language documentation
through tasks like morphological segmentation and the generation of Interlinear
Glossed Text (IGT). However, our research outputs have seen limited use in
real-world language documentation settings. This position paper situates the
disconnect between computational morphology and language documentation within a
broader misalignment between research and practice in NLP and argues that the
field risks becoming decontextualized and ineffectual without systematic
integration of User-Centered Design (UCD). To demonstrate how principles from
UCD can reshape the research agenda, we present a case study of GlossLM, a
state-of-the-art multilingual IGT generation model. Through a small-scale user
study with three documentary linguists, we find that despite strong metric
based performance, the system fails to meet core usability needs in real
documentation contexts. These insights raise new research questions around
model constraints, label standardization, segmentation, and personalization. We
argue that centering users not only produces more effective tools, but surfaces
richer, more relevant research directions

</details>


### [149] [Context Copying Modulation: The Role of Entropy Neurons in Managing Parametric and Contextual Knowledge Conflicts](https://arxiv.org/abs/2509.10663)
*Zineddine Tighidet,Andrea Mogini,Hedi Ben-younes,Jiali Mei,Patrick Gallinari,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 熵神经元在大型语言模型中抑制上下文复制行为，这有助于处理冲突信息。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在面对与其内部参数知识冲突的上下文信息时行为不一致，并且没有普遍接受的预期结果分布的解释。

Method: 通过研究熵神经元在解决上下文信息和参数信息之间冲突中的作用，来检验其在抑制Transformer中上下文复制行为的初步主张。

Result: 熵神经元负责抑制各种大型语言模型中的上下文复制，并且去除它们会导致生成过程中发生显著变化。

Conclusion: 熵神经元在处理冲突信息时能够抑制大型语言模型的上下文复制行为，从而增强了对大型语言模型内部动态的理解。

Abstract: The behavior of Large Language Models (LLMs) when facing contextual
information that conflicts with their internal parametric knowledge is
inconsistent, with no generally accepted explanation for the expected outcome
distribution. Recent work has identified in autoregressive transformer models a
class of neurons -- called entropy neurons -- that produce a significant effect
on the model output entropy while having an overall moderate impact on the
ranking of the predicted tokens. In this paper, we investigate the preliminary
claim that these neurons are involved in inhibiting context copying behavior in
transformers by looking at their role in resolving conflicts between contextual
and parametric information. We show that entropy neurons are responsible for
suppressing context copying across a range of LLMs, and that ablating them
leads to a significant change in the generation process. These results enhance
our understanding of the internal dynamics of LLMs when handling conflicting
information.

</details>


### [150] [Pluralistic Alignment for Healthcare: A Role-Driven Framework](https://arxiv.org/abs/2509.10685)
*Jiayou Zhong,Anudeex Shetty,Chao Jia,Xuanrui Lin,Usman Naseem*

Main category: cs.CL

TL;DR: EthosAgents是一种新的、轻量级的、可推广的、多元化的对齐方法，旨在模拟多样化的观点和价值观，以解决大型语言模型在医疗保健等敏感领域中对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLM）的输出能够反映不同人群的价值观和观点，尤其是在医疗保健等敏感领域，这一点至关重要。然而，现有的对齐方法，包括“模块化多元主义”等多元化范式，在医疗保健领域往往存在不足，因为个人、文化和情境因素都会影响多元化。

Method: 提出了一种名为EthosAgents的轻量级、可推广的多元化对齐方法，该方法旨在模拟多样化的观点和价值观。

Result: 实验表明，EthosAgents在七种不同规模的开放和封闭模型中，在所有三种模式下都促进了多元化对齐。

Conclusion: 医疗保健相关的多元化要求采用适应性强且具有规范意识的方法，这为LLM在其他高风险领域中更好地尊重多样性提供了启示。

Abstract: As large language models are increasingly deployed in sensitive domains such
as healthcare, ensuring their outputs reflect the diverse values and
perspectives held across populations is critical. However, existing alignment
approaches, including pluralistic paradigms like Modular Pluralism, often fall
short in the health domain, where personal, cultural, and situational factors
shape pluralism. Motivated by the aforementioned healthcare challenges, we
propose a first lightweight, generalizable, pluralistic alignment approach,
EthosAgents, designed to simulate diverse perspectives and values. We
empirically show that it advances the pluralistic alignment for all three modes
across seven varying-sized open and closed models. Our findings reveal that
health-related pluralism demands adaptable and normatively aware approaches,
offering insights into how these models can better respect diversity in other
high-stakes domains.

</details>


### [151] [A Transformer-Based Cross-Platform Analysis of Public Discourse on the 15-Minute City Paradigm](https://arxiv.org/abs/2509.11443)
*Gaurab Chhetri,Darrell Anderson,Boniphace Kutela,Subasish Das*

Main category: cs.CL

TL;DR: 本研究首次针对15分钟城市概念在Twitter、Reddit和新闻媒体上的公众意见进行了多平台情感分析。


<details>
  <summary>Details</summary>
Motivation: 评估在不同社交媒体平台和新闻媒体上，公众对15分钟城市概念的情感倾向。

Method: 使用压缩Transformer模型和Llama-3-8B对跨平台异构文本进行情感分类，并对五种模型（DistilRoBERTa, DistilBERT, MiniLM, ELECTRA, TinyBERT）进行了基准测试，采用分层5折交叉验证，并报告了F1分数、AUC和训练时间。

Result: DistilRoBERTa在情感分析任务中取得了最高的F1分数（0.8292），TinyBERT在效率方面表现最佳，MiniLM在跨平台一致性方面表现最好。新闻数据由于类别不平衡导致性能虚高，Reddit数据存在摘要损失问题，Twitter数据则提供了中等难度的挑战。压缩模型表现具有竞争力。

Conclusion: 压缩模型在情感分析任务中表现优异，可以与更大模型相媲美，这挑战了对更大模型的必要性假设。研究确定了特定平台的权衡，并为城市规划话语中可扩展的、现实世界的情感分类提供了方向。

Abstract: This study presents the first multi-platform sentiment analysis of public
opinion on the 15-minute city concept across Twitter, Reddit, and news media.
Using compressed transformer models and Llama-3-8B for annotation, we classify
sentiment across heterogeneous text domains. Our pipeline handles long-form and
short-form text, supports consistent annotation, and enables reproducible
evaluation. We benchmark five models (DistilRoBERTa, DistilBERT, MiniLM,
ELECTRA, TinyBERT) using stratified 5-fold cross-validation, reporting
F1-score, AUC, and training time. DistilRoBERTa achieved the highest F1
(0.8292), TinyBERT the best efficiency, and MiniLM the best cross-platform
consistency. Results show News data yields inflated performance due to class
imbalance, Reddit suffers from summarization loss, and Twitter offers moderate
challenge. Compressed models perform competitively, challenging assumptions
that larger models are necessary. We identify platform-specific trade-offs and
propose directions for scalable, real-world sentiment classification in urban
planning discourse.

</details>


### [152] [Struct-Bench: A Benchmark for Differentially Private Structured Text Generation](https://arxiv.org/abs/2509.10696)
*Shuaiqi Wang,Vikas Raunak,Arturs Backurs,Victor Reis,Pei Zhou,Sihao Chen,Longqi Yang,Zinan Lin,Sergey Yekhanin,Giulia Fanti*

Main category: cs.CL

TL;DR: 提出Struct-Bench框架和基准，用于评估包含自然语言结构化数据集的DP合成数据生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据评估技术难以捕捉包含自然语言的结构化数据集的结构属性和相关性。

Method: 提出Struct-Bench框架，用户需要提供数据集结构的上下文无关文法（CFG）表示。基准包含5个真实世界和2个合成生成的数据集，每个都带CFG标注。提供评估指标的参考实现和排行榜。

Result: Struct-Bench对最先进的DP合成数据生成方法提出了挑战。通过一个案例研究，展示了如何使用Struct-Bench改进PE在结构化数据上的合成数据质量。

Conclusion: Struct-Bench提供了一个标准化的评估平台，用于基准测试和研究隐私保护的合成数据生成方法。

Abstract: Differentially private (DP) synthetic data generation is a promising
technique for utilizing private datasets that otherwise cannot be exposed for
model training or other analytics. While much research literature has focused
on generating private unstructured text and image data, in enterprise settings,
structured data (e.g., tabular) is more common, often including natural
language fields or components. Existing synthetic data evaluation techniques
(e.g., FID) struggle to capture the structural properties and correlations of
such datasets. In this work, we propose Struct-Bench, a framework and benchmark
for evaluating synthetic datasets derived from structured datasets that contain
natural language data. The Struct-Bench framework requires users to provide a
representation of their dataset structure as a Context-Free Grammar (CFG). Our
benchmark comprises 5 real-world and 2 synthetically generated datasets, each
annotated with CFGs. We show that these datasets demonstrably present a great
challenge even for state-of-the-art DP synthetic data generation methods.
Struct-Bench also includes reference implementations of different metrics and a
leaderboard, thereby providing researchers a standardized evaluation platform
to benchmark and investigate privacy-preserving synthetic data generation
methods. Further, we also present a case study showing how to use Struct-Bench
to improve the synthetic data quality of Private Evolution (PE) on structured
data. The benchmark and the leaderboard have been publicly made available at
https://struct-bench.github.io.

</details>


### [153] [CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media](https://arxiv.org/abs/2509.11444)
*Gaurab Chhetri,Anandi Dutta,Subasish Das*

Main category: cs.CL

TL;DR: CognitiveSky是一个开源框架，用于分析去中心化社交媒体Bluesky上的公众言论，可用于情绪、活动和对话主题的动态可视化。


<details>
  <summary>Details</summary>
Motivation: 去中心化社交媒体的兴起为实时分析公众言论提供了新的机遇和挑战，需要新的分析工具。

Method: 通过Bluesky的API摄取数据，并利用基于Transformer的模型对用户生成的内容进行情绪、情感和叙事分析，最后通过动态仪表板可视化分析结果。

Result: CognitiveSky能够对大规模用户生成内容进行标注，并以结构化、可分析的输出来驱动动态仪表板，可视化情感、活动和对话主题的演变模式。该框架的特点是运营成本低且可访问性高，因为它完全构建在免费套餐的基础设施上。

Conclusion: CognitiveSky通过将大型语言模型与去中心化网络相结合，为不断变化的数字生态系统中的计算社会科学提供了一个透明、可扩展的工具，可用于监测心理健康言论，并能扩展到虚假信息检测、危机响应和公民情绪分析等领域。

Abstract: The emergence of decentralized social media platforms presents new
opportunities and challenges for real-time analysis of public discourse. This
study introduces CognitiveSky, an open-source and scalable framework designed
for sentiment, emotion, and narrative analysis on Bluesky, a federated Twitter
or X.com alternative. By ingesting data through Bluesky's Application
Programming Interface (API), CognitiveSky applies transformer-based models to
annotate large-scale user-generated content and produces structured and
analyzable outputs. These summaries drive a dynamic dashboard that visualizes
evolving patterns in emotion, activity, and conversation topics. Built entirely
on free-tier infrastructure, CognitiveSky achieves both low operational cost
and high accessibility. While demonstrated here for monitoring mental health
discourse, its modular design enables applications across domains such as
disinformation detection, crisis response, and civic sentiment analysis. By
bridging large language models with decentralized networks, CognitiveSky offers
a transparent, extensible tool for computational social science in an era of
shifting digital ecosystems.

</details>


### [154] [A Survey on Retrieval And Structuring Augmented Generation with Large Language Models](https://arxiv.org/abs/2509.10697)
*Pengcheng Jiang,Siru Ouyang,Yizhu Jiao,Ming Zhong,Runchu Tian,Jiawei Han*

Main category: cs.CL

TL;DR: LLMs有强大的文本生成和推理能力，但在实际应用中存在幻觉、知识过时和领域专业性不足等问题。检索与结构化（RAS）增强生成通过整合动态信息检索和结构化知识表示来解决这些限制。本调查考察了检索机制、文本结构化技术，并研究了它们如何与LLMs集成，同时指出了当前的技术挑战和未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在实际应用中面临的幻觉生成、知识过时和领域专业性不足等关键挑战。

Method: 1. 检查用于访问外部知识的检索机制（稀疏、密集和混合方法）；2. 探索将非结构化文本转换为结构化表示的文本结构化技术（如分类构建、分层分类和信息提取）；3. 研究结构化表示如何通过基于提示的方法、推理框架和知识嵌入技术与LLMs集成。

Result: 本调查全面概述了RAS方法、应用和未来方向，为研究人员和从业者提供了见解。

Conclusion: RAS增强生成通过整合信息检索和结构化知识来克服LLM的局限性，但仍面临效率、结构质量和知识集成方面的挑战，并为多模态检索、跨语言结构和交互式系统等领域提供了研究机会。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing
with their remarkable capabilities in text generation and reasoning. However,
these models face critical challenges when deployed in real-world applications,
including hallucination generation, outdated knowledge, and limited domain
expertise. Retrieval And Structuring (RAS) Augmented Generation addresses these
limitations by integrating dynamic information retrieval with structured
knowledge representations. This survey (1) examines retrieval mechanisms
including sparse, dense, and hybrid approaches for accessing external
knowledge; (2) explore text structuring techniques such as taxonomy
construction, hierarchical classification, and information extraction that
transform unstructured text into organized representations; and (3) investigate
how these structured representations integrate with LLMs through prompt-based
methods, reasoning frameworks, and knowledge embedding techniques. It also
identifies technical challenges in retrieval efficiency, structure quality, and
knowledge integration, while highlighting research opportunities in multimodal
retrieval, cross-lingual structures, and interactive systems. This
comprehensive overview provides researchers and practitioners with insights
into RAS methods, applications, and future directions.

</details>


### [155] [SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation](https://arxiv.org/abs/2509.10708)
*Iman Barati,Mostafa Amiri,Heshaam Faili*

Main category: cs.CL

TL;DR: SearchInstruct是一种新方法，用于为特定领域构建高质量的指令微调（SFT）数据集，通过扩展种子问题并检索相关资源来生成答案，提高了LLM在专业领域的性能，并可用于模型编辑。


<details>
  <summary>Details</summary>
Motivation: 为特定领域创建定制的SFT训练数据集具有挑战性，因为存在独特的领域限制和数据稀缺性。

Method: SearchInstruct首先使用有限的、人类生成的特定领域问题，然后使用大型语言模型系统地扩展这些问题，并检索相关的领域资源来为每个增强的问题生成准确且上下文相关的答案。

Result: SearchInstruct提高了SFT数据集的多样性和质量，从而在专业领域显著改善了LLM的性能。此外，该方法还可以有效地用于模型编辑等任务。

Conclusion: SearchInstruct是一种有效的方法，可以为SFT构建高质量的指令数据集，提高LLM在专业领域的性能，并支持模型编辑等其他任务。

Abstract: Supervised Fine-Tuning (SFT) is essential for training large language models
(LLMs), significantly enhancing critical capabilities such as instruction
following and in-context learning. Nevertheless, creating suitable training
datasets tailored for specific domains remains challenging due to unique domain
constraints and data scarcity. In this paper, we propose SearchInstruct, an
innovative method explicitly designed to construct high quality instruction
datasets for SFT. Our approach begins with a limited set of domain specific,
human generated questions, which are systematically expanded using a large
language model. Subsequently, domain relevant resources are dynamically
retrieved to generate accurate and contextually appropriate answers for each
augmented question. Experimental evaluation demonstrates that SearchInstruct
enhances both the diversity and quality of SFT datasets, leading to measurable
improvements in LLM performance within specialized domains. Additionally, we
show that beyond dataset generation, the proposed method can also effectively
facilitate tasks such as model editing, enabling efficient updates to existing
models. To facilitate reproducibility and community adoption, we provide full
implementation details, the complete set of generated instruction response
pairs, and the source code in a publicly accessible Git repository:
[https://github.com/mostafaamiri/SearchInstruct](https://github.com/mostafaamiri/SearchInstruct)

</details>


### [156] [PolyTruth: Multilingual Disinformation Detection using Transformer-Based Language Models](https://arxiv.org/abs/2509.10737)
*Zaur Gouliev,Jennifer Waters,Chengqian Wang*

Main category: cs.CL

TL;DR: Disinformation spreads rapidly across linguistic boundaries, but most AI models are still benchmarked only on English. This paper introduces a novel corpus, PolyTruth Disinfo Corpus, for evaluating multilingual disinformation detection models. Experiments with five multilingual transformer models (mBERT, XLM, XLM-RoBERTa, RemBERT, and mT5) show varying performance, with RemBERT excelling in low-resource languages, while mBERT and XLM have limitations with scarce data. The findings highlight the potential and limitations of AI for multilingual disinformation detection.


<details>
  <summary>Details</summary>
Motivation: Most AI models are benchmarked only on English, failing to address the rapid spread of disinformation across linguistic boundaries. This paper aims to bridge this gap by systematically comparing multilingual transformer models for disinformation detection.

Method: A systematic comparison of five multilingual transformer models (mBERT, XLM, XLM-RoBERTa, RemBERT, and mT5) was conducted using the novel PolyTruth Disinfo Corpus. This corpus consists of 60,486 statement pairs (false claim vs. factual correction) in over twenty five languages, covering five language families and various topics. Half of the claims are fact-checked disinformation.

Result: Experiments revealed performance variations among the models. RemBERT achieved better overall accuracy, particularly in low-resource languages. mBERT and XLM exhibited considerable limitations when training data was scarce. The findings illuminate both the potential and current limitations of AI systems for multilingual disinformation detection.

Conclusion: AI systems have potential for multilingual disinformation detection, but current models like mBERT and XLM have limitations, especially with scarce data. RemBERT shows promise, particularly in low-resource languages. Further experimentation and advancement are encouraged.

Abstract: Disinformation spreads rapidly across linguistic boundaries, yet most AI
models are still benchmarked only on English. We address this gap with a
systematic comparison of five multilingual transformer models: mBERT, XLM,
XLM-RoBERTa, RemBERT, and mT5 on a common fake-vs-true machine learning
classification task. While transformer-based language models have demonstrated
notable success in detecting disinformation in English, their effectiveness in
multilingual contexts still remains up for debate. To facilitate evaluation, we
introduce PolyTruth Disinfo Corpus, a novel corpus of 60,486 statement pairs
(false claim vs. factual correction) spanning over twenty five languages that
collectively cover five language families and a broad topical range from
politics, health, climate, finance, and conspiracy, half of which are
fact-checked disinformation claims verified by an augmented MindBugs Discovery
dataset. Our experiments revealed performance variations. Models such as
RemBERT achieved better overall accuracy, particularly excelling in
low-resource languages, whereas models like mBERT and XLM exhibit considerable
limitations when training data is scarce. We provide a discussion of these
performance patterns and implications for real-world deployment. The dataset is
publicly available on our GitHub repository to encourage further
experimentation and advancement. Our findings illuminate both the potential and
the current limitations of AI systems for multilingual disinformation
detection.

</details>


### [157] [Reasoning Under Uncertainty: Exploring Probabilistic Reasoning Capabilities of LLMs](https://arxiv.org/abs/2509.10739)
*Mobina Pournemat,Keivan Rezaei,Gaurang Sriramanan,Arman Zarei,Jiaxiang Fu,Yang Wang,Hamid Eghbalzadeh,Soheil Feizi*

Main category: cs.CL

TL;DR: LLM在处理概率推理任务时表现出不确定且不一致的行为，本研究首次全面研究了LLM在显式离散概率分布上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在语言理解和生成方面取得了广泛成功，但在需要概率推理的任务中，它们表现出不清楚且常常不一致的行为。

Method: 给定概率分布的观测值，通过提示模型提供关于联合分布或其条件分布的查询响应，评估模型在模式识别、最大似然估计和样本生成这三个精心设计的任务上的表现。

Result: 结果表明，较小模型和较大模型之间存在明显的性能差距，较大模型展现出更强的推理能力和令人惊讶的样本生成能力。此外，研究还揭示了LLM在概率推理方面的局限性，例如对概率结果表示符号变化的敏感性以及随着上下文长度增加而导致的性能下降（超过60%）。

Conclusion: 本研究全面评估了LLM的概率推理能力，并指出了未来改进的关键方向。

Abstract: Despite widespread success in language understanding and generation, large
language models (LLMs) exhibit unclear and often inconsistent behavior when
faced with tasks that require probabilistic reasoning. In this work, we present
the first comprehensive study of the reasoning capabilities of LLMs over
explicit discrete probability distributions. Given observations from a
probability distribution, we evaluate models on three carefully designed tasks,
mode identification, maximum likelihood estimation, and sample generation, by
prompting them to provide responses to queries about either the joint
distribution or its conditionals. These tasks thus probe a range of
probabilistic skills, including frequency analysis, marginalization, and
generative behavior. Through comprehensive empirical evaluations, we
demonstrate that there exists a clear performance gap between smaller and
larger models, with the latter demonstrating stronger inference and surprising
capabilities in sample generation. Furthermore, our investigations reveal
notable limitations, including sensitivity to variations in the notation
utilized to represent probabilistic outcomes and performance degradation of
over 60% as context length increases. Together, our results provide a detailed
understanding of the probabilistic reasoning abilities of LLMs and identify key
directions for future improvement.

</details>


### [158] [Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models](https://arxiv.org/abs/2509.10744)
*Ozan Gokdemir,Neil Getty,Robert Underwood,Sandeep Madireddy,Franck Cappello,Arvind Ramanathan,Ian T. Foster,Rick L. Stevens*

Main category: cs.CL

TL;DR: 本文提出了一个自动生成科学领域选择题的框架，并用该框架从22000篇癌症生物学论文中生成了超过16000道选择题，用于评估语言模型。实验结果表明，结合GPT-4提炼的推理链进行检索，可以显著提升小型语言模型的性能，甚至超越GPT-4。


<details>
  <summary>Details</summary>
Motivation: 科学知识快速增长，需要更新的基准来评估语言模型在当前科学文献上的表现。

Method: 开发了一个自动化的框架，从科学论文语料库中生成选择题，包括PDF解析、语义分块、问题生成和模型评估。并使用该框架生成了16000多道选择题，评估了不同大小的语言模型，并对比了基线模型、检索增强生成（RAG）以及从GPT-4蒸馏的推理链。

Result: 基于推理链检索的方法在合成和专家标注的基准上都持续提高了模型性能，使得一些小型模型在2023年的天文学、辐射与癌症生物学考试中超越了GPT-4。

Conclusion: 从论文中提炼的推理链对于提高小型语言模型在特定领域问答任务上的性能至关重要，该方法为构建动态更新的科学基准提供了有效途径。

Abstract: As scientific knowledge grows at an unprecedented pace, evaluation benchmarks
must evolve to reflect new discoveries and ensure language models are tested on
current, diverse literature. We propose a scalable, modular framework for
generating multiple-choice question-answering (MCQA) benchmarks directly from
large corpora of scientific papers. Our pipeline automates every stage of MCQA
creation, including PDF parsing, semantic chunking, question generation, and
model evaluation. As a case study, we generate more than 16,000 MCQs from
22,000 open-access articles in radiation and cancer biology. We then evaluate a
suite of small language models (1.1B-14B parameters) on these questions,
comparing baseline accuracy with retrieval-augmented generation (RAG) from
paper-derived semantic chunks and from reasoning traces distilled from GPT-4.1.
We find that reasoning-trace retrieval consistently improves performance on
both synthetic and expert-annotated benchmarks, enabling several small models
to surpass GPT-4 on the 2023 Astro Radiation and Cancer Biology exam.

</details>


### [159] [RECAP: Transparent Inference-Time Emotion Alignment for Medical Dialogue Systems](https://arxiv.org/abs/2509.10746)
*Adarsh Srinivasan,Jacob Dineen,Muhammad Umar Afzal,Muhammad Uzair Sarfraz,Irbaz B. Riaz,Ben Zhou*

Main category: cs.CL

TL;DR: RECAP是一个在推理时无需重新训练即可添加结构化情绪推理的框架，通过将共情分解为透明的评估理论阶段，并暴露每维李克特信号，RECAP可产生细致、可审核的响应，从而提高医疗AI的情绪智商。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗保健领域常常忽略关键的情绪线索，提供医学上合理但缺乏情感的建议，这在患者痛苦和脆弱的临床环境中尤其成问题，因为共情沟通对安全、依从性和信任至关重要。

Method: RECAP（Reflect-Extract-Calibrate-Align-Produce）是一个推理时框架，通过将共情分解为透明的评估理论阶段，并暴露每维李克特信号，在不重新训练的情况下添加结构化情绪推理。

Result: 在EmoBench、SECEU和EQ-Bench等基准测试中，RECAP在8B模型上将情绪推理能力提高了22-28%，在更大模型上提高了10-13%，并获得了临床医生的积极评价。

Conclusion: RECAP表明，模块化、基于理论的提示可以系统地提高医疗AI的情绪智能，同时保持部署所需的问责制。

Abstract: Large language models in healthcare often miss critical emotional cues,
delivering medically sound but emotionally flat advice. This is especially
problematic in clinical contexts where patients are distressed and vulnerable,
and require empathic communication to support safety, adherence, and trust. We
present RECAP (Reflect-Extract-Calibrate-Align-Produce), an inference-time
framework that adds structured emotional reasoning without retraining. By
decomposing empathy into transparent appraisal-theoretic stages and exposing
per-dimension Likert signals, RECAP produces nuanced, auditable responses.
Across EmoBench, SECEU, and EQ-Bench, RECAP improves emotional reasoning by
22-28% on 8B models and 10-13% on larger models over zero-shot baselines.
Clinician evaluations further confirm superior empathetic communication. RECAP
shows that modular, theory-grounded prompting can systematically enhance
emotional intelligence in medical AI while preserving the accountability
required for deployment.

</details>


### [160] [Judge Q: Trainable Queries for Optimized Information Retention in KV Cache Eviction](https://arxiv.org/abs/2509.10798)
*Yijun Liu,Yixuan Wang,Yuzhuang Xu,Shiyu Ji,Yang Xu,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: LLM的KV缓存随着序列长度线性增长，影响内存和效率。现有方法侧重局部信息，忽略全局信息。本研究提出Judge Q方法，通过引入软 token 列表，在低成本下仅调整嵌入层，使软 token 的注意力图与实际解码 token 对齐，从而捕捉全局信息，评估KV缓存重要性，减少缓存淘汰时的性能损失。该方法在Llama-3.1-8B-Instruct和Mistral-7B-Instruct-v0.3模型上，使用LongBench、RULER和Needle-in-a-Haystack基准测试，LongBench提升约1分，RULER提升超3分，可无缝集成于现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存淘汰方法倾向于关注局部信息，可能忽略重要的全局信息，导致解码质量下降。

Method: 提出Judge Q训练方法，引入软 token 列表，仅调整模型的嵌入层。通过将软 token 列表添加到输入序列末尾，训练这些 token 的注意力图与原始输入序列对齐，以匹配实际解码 token 的注意力图。

Result: 在相同淘汰预算下，Judge Q方法相比现有方法具有更少的性能下降。在Llama-3.1-8B-Instruct和Mistral-7B-Instruct-v0.3模型上，使用LongBench、RULER和Needle-in-a-Haystack基准测试，LongBench得分提升约1分，RULER得分提升超过3分。

Conclusion: Judge Q方法能够有效捕捉全局信息，更好地评估KV缓存中键值的重要性，从而在淘汰KV缓存时保持解码质量。该方法训练成本低，易于集成到现有开源模型中，能提升KV缓存淘汰场景下的性能。

Abstract: Large language models (LLMs) utilize key-value (KV) cache to store historical
information during sequence processing. The size of KV cache grows linearly as
the length of the sequence extends, which seriously affects memory usage and
decoding efficiency. Current methods for KV cache eviction typically utilize
the last window from the pre-filling phase as queries to compute the KV
importance scores for eviction. Although this scheme is simple to implement, it
tends to overly focus on local information, potentially leading to the neglect
or omission of crucial global information. To mitigate this issue, we propose
Judge Q, a novel training method which incorporates a soft token list. This
method only tunes the model's embedding layer at a low training cost. By
concatenating the soft token list at the end of the input sequence, we train
these tokens' attention map to the original input sequence to align with that
of the actual decoded tokens. In this way, the queries corresponding to the
soft tokens can effectively capture global information and better evaluate the
importance of the keys and values within the KV cache, thus maintaining
decoding quality when KV cache is evicted. Under the same eviction budget, our
method exhibits less performance degradation compared to existing eviction
approaches. We validate our approach through experiments conducted on models
such as Llama-3.1-8B-Instruct and Mistral-7B-Instruct-v0.3, using benchmarks
including LongBench, RULER, and Needle-in-a-Haystack. Results indicate an
improvement of approximately 1 point on the LongBench and over 3 points on
RULER. This proposed methodology can be seamlessly integrated into existing
open-source models with minimal training overhead, thereby enhancing
performance in KV cache eviction scenarios.

</details>


### [161] [Towards Automated Error Discovery: A Study in Conversational AI](https://arxiv.org/abs/2509.10833)
*Dominic Petrak,Thy Thy Tran,Iryna Gurevych*

Main category: cs.CL

TL;DR: LLM 驱动的对话机器人虽然流畅且连贯，但仍会产生不良行为（错误），并且难以在部署过程中阻止这些行为触达用户。本研究提出了一种名为 SEEED 的框架，用于自动发现和定义对话式 AI 中的错误，并采用基于编码器的方法来实现。SEEED 通过放大负样本的距离权重并引入基于标签的样本排序来增强软最近邻损失，从而选择具有高度对比度的样本以进行更好的表示学习。实验证明，SEEED 在检测未知错误方面的准确率提高了 8 个百分点，并且在未知意图检测方面表现出强大的泛化能力，优于包括 GPT-4o 和 Phi-4 在内的基线模型。


<details>
  <summary>Details</summary>
Motivation: 虽然 LLM 对话代理在流畅性和连贯性方面表现出色，但它们仍会产生不良行为（错误），并且在部署过程中难以阻止这些错误触达用户。现有的利用 LLM 检测错误和指导响应生成模型改进的方法，在识别未明确指定的错误（例如，由于响应生成模型更新或用户行为转移而产生的错误）方面存在困难。

Method: 提出了一种名为 SEEED（Soft Clustering Extended Encoder-Based Error Detection）的框架，用于自动发现和定义对话式 AI 中的错误。该方法通过增强软最近邻损失，放大负样本的距离权重，并引入基于标签的样本排序来选择高度对比度的样本，以实现更好的表示学习。

Result: SEEED 在多个带错误注释的对话数据集上，在检测未知错误方面的准确率提高了高达 8 个百分点，并证明了其在未知意图检测方面具有强大的泛化能力，其性能优于包括 GPT-4o 和 Phi-4 在内的基线模型。

Conclusion: 本研究提出的 SEEED 框架及其实现方法，能够有效检测和定义对话式 AI 中的错误，尤其在处理未明确指定的未知错误方面表现出色，并具有良好的泛化能力，为提高对话式 AI 的鲁棒性和可靠性提供了新的解决方案。

Abstract: Although LLM-based conversational agents demonstrate strong fluency and
coherence, they still produce undesirable behaviors (errors) that are
challenging to prevent from reaching users during deployment. Recent research
leverages large language models (LLMs) to detect errors and guide
response-generation models toward improvement. However, current LLMs struggle
to identify errors not explicitly specified in their instructions, such as
those arising from updates to the response-generation model or shifts in user
behavior. In this work, we introduce Automated Error Discovery, a framework for
detecting and defining errors in conversational AI, and propose SEEED (Soft
Clustering Extended Encoder-Based Error Detection), as an encoder-based
approach to its implementation. We enhance the Soft Nearest Neighbor Loss by
amplifying distance weighting for negative samples and introduce Label-Based
Sample Ranking to select highly contrastive examples for better representation
learning. SEEED outperforms adapted baselines -- including GPT-4o and Phi-4 --
across multiple error-annotated dialogue datasets, improving the accuracy for
detecting unknown errors by up to 8 points and demonstrating strong
generalization to unknown intent detection.

</details>


### [162] [Evaluating Large Language Models for Evidence-Based Clinical Question Answering](https://arxiv.org/abs/2509.10843)
*Can Wang,Yiqun Chen*

Main category: cs.CL

TL;DR: LLMs在医学和临床应用方面取得了显著进展，但其回答基于证据的细微问题的能力仍需严格评估。本研究使用GPT-4o-mini和GPT-5，在包含Cochrane系统综述、临床指南（如AHA指南）和保险公司指导原则的多源基准上进行测试。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在回答基于证据的、细致的医学和临床问题方面的能力，并探讨影响其表现的因素。

Method: 使用GPT-4o-mini和GPT-5在多源（Cochrane系统综述、AHA指南、保险公司指导原则）基准上进行评估，分析不同类型问题和引用数量对模型准确率的影响，并测试检索增强提示（Retrieval-Augmented Prompting）的效果。

Result: 在结构化指南推荐问题上，模型准确率最高（90%）；在叙述性指南和系统综述问题上，准确率较低（60%-70%）。模型准确率与系统综述的引用数量呈正相关。检索增强提示能显著提高准确率，提供相关文献摘要效果优于随机摘要，即使是GPT-4o-mini模型也观察到类似趋势。

Conclusion: LLMs在循证临床问答方面展现出潜力，但也存在局限性。检索增强提示是提高事实准确性和与源证据一致性的有效策略，但按专科和问题类型进行分层评估对于理解和情境化模型表现至关重要。

Abstract: Large Language Models (LLMs) have demonstrated substantial progress in
biomedical and clinical applications, motivating rigorous evaluation of their
ability to answer nuanced, evidence-based questions. We curate a multi-source
benchmark drawing from Cochrane systematic reviews and clinical guidelines,
including structured recommendations from the American Heart Association and
narrative guidance used by insurers. Using GPT-4o-mini and GPT-5, we observe
consistent performance patterns across sources and clinical domains: accuracy
is highest on structured guideline recommendations (90%) and lower on narrative
guideline and systematic review questions (60--70%). We also find a strong
correlation between accuracy and the citation count of the underlying
systematic reviews, where each doubling of citations is associated with roughly
a 30% increase in the odds of a correct answer. Models show moderate ability to
reason about evidence quality when contextual information is supplied. When we
incorporate retrieval-augmented prompting, providing the gold-source abstract
raises accuracy on previously incorrect items to 0.79; providing top 3 PubMed
abstracts (ranked by semantic relevance) improves accuracy to 0.23, while
random abstracts reduce accuracy (0.10, within temperature variation). These
effects are mirrored in GPT-4o-mini, underscoring that source clarity and
targeted retrieval -- not just model size -- drive performance. Overall, our
results highlight both the promise and current limitations of LLMs for
evidence-based clinical question answering. Retrieval-augmented prompting
emerges as a useful strategy to improve factual accuracy and alignment with
source evidence, while stratified evaluation by specialty and question type
remains essential to understand current knowledge access and to contextualize
model performance.

</details>


### [163] [GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings](https://arxiv.org/abs/2509.10844)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: GAPrune通过考虑领域重要性和通用语言基础来解决LLM剪枝的挑战，在FinMTEB和ChemTEB基准上展示了性能的维持和提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的领域特定嵌入模型虽然性能优越，但由于参数量巨大，难以在资源受限的环境中部署。现有的剪枝方法未区分通用语义和领域特定模式，导致次优的剪枝决策。

Method: 提出GAPrune剪枝框架，结合Fisher信息衡量重要性，并使用通用领域梯度对齐评估参数行为。通过领域对齐重要性（DAI）评分结合这两种信号，DAI分数低的参数被认为是领域任务不重要或在领域和通用目标之间产生冲突的参数。

Result: 在FinMTEB和ChemTEB基准上，GAPrune在50%稀疏度下进行一次性剪枝时，性能可维持在密集模型的2.5%以内，优于所有基线。通过100步的再训练，GAPrune在FinMTEB上提升了+4.51%，在ChemTEB上提升了+1.73%。

Conclusion: 原则性的剪枝策略可以实现模型压缩和增强的领域专业化，为研究界提供了一种新的开发方法。

Abstract: Domain-specific embedding models have shown promise for applications that
require specialized semantic understanding, such as coding agents and financial
retrieval systems, often achieving higher performance gains than general
models. However, state-of-the-art embedding models are typically based on LLMs,
which contain billions of parameters, making deployment challenging in
resource-constrained environments. Model compression through pruning offers a
promising solution, but existing pruning methods treat all parameters
uniformly, failing to distinguish between general semantic representations and
domain-specific patterns, leading to suboptimal pruning decisions. Thus, we
propose GAPrune, a pruning framework that addresses this challenge by
considering both domain importance and preserving general linguistic
foundation. Our method uses Fisher Information to measure importance and
general-domain gradient alignment to assess parameter behavior, then combines
these signals using our Domain Alignment Importance (DAI) scoring. Lower DAI
scores indicate that the parameter is either less important for the domain task
or creates conflicts between domain and general objectives. Experiments on two
domain benchmarks, FinMTEB and ChemTEB, show that GAPrune maintains performance
within 2.5% of dense models in one-shot pruning at 50% sparsity, while
outperforming all baselines. With retraining in 100 steps, GAPrune achieves
+4.51% improvement on FinMTEB and +1.73% on ChemTEB, demonstrating that our
pruning strategy not only preserves but enhances domain-specific capabilities.
Our findings demonstrate that principled pruning strategies can achieve model
compression and enhanced domain specialization, providing the research
community with a new approach for development.

</details>


### [164] [Text2Sign Diffusion: A Generative Approach for Gloss-Free Sign Language Production](https://arxiv.org/abs/2509.10845)
*Liqian Feng,Lintao Wang,Kun Hu,Dehui Kong,Zhiyong Wang*

Main category: cs.CL

TL;DR: 提出了一种名为Text2Sign Diffusion (Text2SignDiff) 的新型扩散模型，用于无手语词的文本到手语转换，并通过跨模态对齐器实现更准确、更具上下文意义的手语生成。


<details>
  <summary>Details</summary>
Motivation: 现有的手语生成方法依赖于手语词（gloss）作为中间表示，但手语词标注通常不可用且具有语言特异性，限制了方法的灵活性和泛化能力。因此，需要一种无需手语词即可进行手语生成的方法。

Method: 提出了一种无手语词的潜在扩散模型Text2SignDiff，该模型能够从噪声潜在手语码和口语文本联合生成手语序列。通过非自回归的迭代去噪过程减少潜在的误差累积。设计了一个跨模态手语对齐器，学习共享的潜在空间来连接手语和口语的可视和文本内容，从而支持基于扩散的有条件生成过程。

Result: 在PHOENIX14T和How2Sign数据集上进行了广泛的实验，证明了该方法的有效性，并取得了最先进的性能。

Conclusion: 所提出的Text2SignDiff方法通过摒弃手语词的依赖，并引入跨模态对齐，能够更准确、更具上下文意义地生成手语，有效解决了现有方法的局限性。

Abstract: Sign language production (SLP) aims to translate spoken language sentences
into a sequence of pose frames in a sign language, bridging the communication
gap and promoting digital inclusion for deaf and hard-of-hearing communities.
Existing methods typically rely on gloss, a symbolic representation of sign
language words or phrases that serves as an intermediate step in SLP. This
limits the flexibility and generalization of SLP, as gloss annotations are
often unavailable and language-specific. Therefore, we present a novel
diffusion-based generative approach - Text2Sign Diffusion (Text2SignDiff) for
gloss-free SLP. Specifically, a gloss-free latent diffusion model is proposed
to generate sign language sequences from noisy latent sign codes and spoken
text jointly, reducing the potential error accumulation through a
non-autoregressive iterative denoising process. We also design a cross-modal
signing aligner that learns a shared latent space to bridge visual and textual
content in sign and spoken languages. This alignment supports the conditioned
diffusion-based process, enabling more accurate and contextually relevant sign
language generation without gloss. Extensive experiments on the commonly used
PHOENIX14T and How2Sign datasets demonstrate the effectiveness of our method,
achieving the state-of-the-art performance.

</details>


### [165] [A funny companion: Distinct neural responses to perceived AI- versus human- generated humor](https://arxiv.org/abs/2509.10847)
*Xiaohui Rao,Hanlin Wu,Zhenguang G. Cai*

Main category: cs.CL

TL;DR: 人们对AI幽默的反应与人类幽默相似，但认知努力较少，情绪反应更强烈，这表明了认知适应和潜在的算法规避挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI能够进行类似人类的交流，理解人类对AI幽默的认知和情感反应变得越来越重要。

Method: 使用脑电图（EEG）和行为分析来比较人类和AI产生的幽默在认知和情感处理上的差异。

Result: 行为上，AI和人类的幽默被认为具有相似的趣味性。神经生理学上，AI幽默引发了较小的N400效应（表明对不协调的认知处理较少）和较大的后期正电位（LPP，表明更强的惊讶和情绪反应）。随着时间的推移，人类幽默表现出习惯化效应（N400增加，LPP减小），而AI幽默则显示出处理效率的提高和情绪回报的增强（N400减小，LPP增加）。参与者对AI的社会态度（如信任度）会影响神经反应，更高的信任度与更强的 <$>情感投入相关。

Conclusion: 大脑对AI幽默的反应比预期的更为积极和强烈，表明幽默可以促进人与AI之间的深度互动，并挑战了“算法规避”的现象，因为认知适应AI的语言模式可以带来更强的情绪回报。

Abstract: As AI companions become capable of human-like communication, including
telling jokes, understanding how people cognitively and emotionally respond to
AI humor becomes increasingly important. This study used electroencephalography
(EEG) to compare how people process humor from AI versus human sources.
Behavioral analysis revealed that participants rated AI and human humor as
comparably funny. However, neurophysiological data showed that AI humor
elicited a smaller N400 effect, suggesting reduced cognitive effort during the
processing of incongruity. This was accompanied by a larger Late Positive
Potential (LPP), indicating a greater degree of surprise and emotional
response. This enhanced LPP likely stems from the violation of low initial
expectations regarding AI's comedic capabilities. Furthermore, a key temporal
dynamic emerged: human humor showed habituation effects, marked by an
increasing N400 and a decreasing LPP over time. In contrast, AI humor
demonstrated increasing processing efficiency and emotional reward, with a
decreasing N400 and an increasing LPP. This trajectory reveals how the brain
can dynamically update its predictive model of AI capabilities. This process of
cumulative reinforcement challenges "algorithm aversion" in humor, as it
demonstrates how cognitive adaptation to AI's language patterns can lead to an
intensified emotional reward. Additionally, participants' social attitudes
toward AI modulated these neural responses, with higher perceived AI
trustworthiness correlating with enhanced emotional engagement. These findings
indicate that the brain responds to AI humor with surprisingly positive and
intense reactions, highlighting humor's potential for fostering genuine
engagement in human-AI social interaction.

</details>


### [166] [Pre-Storage Reasoning for Episodic Memory: Shifting Inference Burden to Memory for Personalized Dialogue](https://arxiv.org/abs/2509.10852)
*Sangyeop Kim,Yohan Lee,Sanghwa Kim,Hyunjong Kim,Sungzoon Cho*

Main category: cs.CL

TL;DR: PREMem是一种新的对话AI记忆方法，通过在记忆存储阶段进行推理来减轻响应生成时的计算负担，从而提高AI的长期记忆能力，尤其是在模型尺寸受限的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有对话AI系统在响应生成时承担过多的推理负担，导致性能高度依赖模型大小，而长期记忆能力需要跨越多轮对话的信息合成。PREMem旨在解决这个问题，减轻推理负担，提高AI的长期记忆能力。

Method: PREMem将复杂的推理过程从响应生成阶段转移到记忆构建阶段。它提取细粒度的记忆片段（事实、经验、主观信息），并在跨会话的记忆项之间建立明确的关系，捕捉诸如扩展、转换和含义演变等模式。

Result: 在所有模型尺寸下，PREMem都显示出显著的性能提升。小型模型在保持效率（即使在有限的token预算下）的同时，取得了与更大模型相媲美的结果。

Conclusion: PREMem通过在预存储阶段进行推理，而非在响应生成时进行，从而创建了更丰富的记忆表征，并降低了交互时的计算需求。这使得小型模型也能实现高性能的长期记忆能力。

Abstract: Effective long-term memory in conversational AI requires synthesizing
information across multiple sessions. However, current systems place excessive
reasoning burden on response generation, making performance significantly
dependent on model sizes. We introduce PREMem (Pre-storage Reasoning for
Episodic Memory), a novel approach that shifts complex reasoning processes from
inference to memory construction. PREMem extracts fine-grained memory fragments
categorized into factual, experiential, and subjective information; it then
establishes explicit relationships between memory items across sessions,
capturing evolution patterns like extensions, transformations, and
implications. By performing this reasoning during pre-storage rather than when
generating a response, PREMem creates enriched representations while reducing
computational demands during interactions. Experiments show significant
performance improvements across all model sizes, with smaller models achieving
results comparable to much larger baselines while maintaining effectiveness
even with constrained token budgets. Code and dataset are available at
https://github.com/sangyeop-kim/PREMem.

</details>


### [167] [Quantifier Scope Interpretation in Language Learners and LLMs](https://arxiv.org/abs/2509.10860)
*Shaohua Fang,Yue Li,Yan Cong*

Main category: cs.CL

TL;DR: 本研究使用概率评估LLM在英语和中文中解释多量词句子的范围歧义的可能性，并使用人类相似性（HS）得分量化LLM模仿人类表现的程度。


<details>
  <summary>Details</summary>
Motivation: 多量词句子的解释歧义性会因语言而异，本研究旨在跨语言地考察大型语言模型（LLM）如何处理英语和中文中的量词范围解释。

Method: 使用概率评估LLM在英语和中文中解释多量词句子的范围歧义的可能性，并使用人类相似性（HS）得分量化LLM模仿人类表现的程度。

Result: 大多数LLM倾向于表面范围解释，与人类相似。一些LLM区分了英语和中文在反向范围解释上的偏好，展现出类似人类的模式。HS得分显示LLM在模仿人类行为方面存在差异，但总体潜力值得注意。模型架构、规模以及预训练数据的语言背景会显著影响LLM模仿人类量词范围解释的程度。

Conclusion: LLM在处理量词范围解释方面展现出与人类相似的趋势，但存在个体差异。模型的设计和训练数据是影响其表现的关键因素。

Abstract: Sentences with multiple quantifiers often lead to interpretive ambiguities,
which can vary across languages. This study adopts a cross-linguistic approach
to examine how large language models (LLMs) handle quantifier scope
interpretation in English and Chinese, using probabilities to assess
interpretive likelihood. Human similarity (HS) scores were used to quantify the
extent to which LLMs emulate human performance across language groups. Results
reveal that most LLMs prefer the surface scope interpretations, aligning with
human tendencies, while only some differentiate between English and Chinese in
the inverse scope preferences, reflecting human-similar patterns. HS scores
highlight variability in LLMs' approximation of human behavior, but their
overall potential to align with humans is notable. Differences in model
architecture, scale, and particularly models' pre-training data language
background, significantly influence how closely LLMs approximate human
quantifier scope interpretations.

</details>


### [168] [Term2Note: Synthesising Differentially Private Clinical Notes from Medical Terms](https://arxiv.org/abs/2509.10882)
*Yuping Wu,Viktor Schlegel,Warren Del-Pinto,Srinivasan Nandakumar,Iqra Zahid,Yidan Sun,Usama Farghaly Omar,Amirah Jasmine,Arun-Kumar Kaliya-Perumal,Chun Shen Tham,Gabriel Connors,Anil A Bharath,Goran Nenadic*

Main category: cs.CL

TL;DR: Term2Note是一种在差分隐私（DP）约束下生成长篇临床记录的方法，通过分离内容和形式，并以DP医学术语为条件分段生成记录，同时使用DP质量最大化器来提升合成记录的质量。实验表明，Term2Note生成的记录在统计特性上与真实记录高度一致，并且使用这些合成记录训练的模型在性能上与使用真实数据训练的模型相当，显示了其在保护隐私方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，出于对隐私泄露的担忧，真实训练数据的应用受到严格限制。然而，在临床记录合成中，要在隐私保护和数据效用之间取得平衡仍然是一个挑战，因为其具有领域特异性和长文本生成的复杂性。

Method: Term2Note通过结构化地分离内容和形式，生成基于DP医学术语的、分章节的记录内容，每个章节都受到单独的DP约束。此外，还使用了一个DP质量最大化器来选择高质量的合成记录。

Result: Term2Note生成的合成记录在统计特性上与真实的临床记录高度吻合，显示出很高的保真度。使用这些合成记录训练的多标签分类模型，其性能与使用真实数据训练的模型相当，证实了其高可用性。

Conclusion: Term2Note在DP约束下生成长临床记录方面取得了显著的进展，在保真度和可用性方面均优于现有的DP文本生成基线，同时假设更少，有望成为使用敏感临床记录的一种可行的隐私保护替代方案。

Abstract: Training data is fundamental to the success of modern machine learning
models, yet in high-stakes domains such as healthcare, the use of real-world
training data is severely constrained by concerns over privacy leakage. A
promising solution to this challenge is the use of differentially private (DP)
synthetic data, which offers formal privacy guarantees while maintaining data
utility. However, striking the right balance between privacy protection and
utility remains challenging in clinical note synthesis, given its domain
specificity and the complexity of long-form text generation. In this paper, we
present Term2Note, a methodology to synthesise long clinical notes under strong
DP constraints. By structurally separating content and form, Term2Note
generates section-wise note content conditioned on DP medical terms, with each
governed by separate DP constraints. A DP quality maximiser further enhances
synthetic notes by selecting high-quality outputs. Experimental results show
that Term2Note produces synthetic notes with statistical properties closely
aligned with real clinical notes, demonstrating strong fidelity. In addition,
multi-label classification models trained on these synthetic notes perform
comparably to those trained on real data, confirming their high utility.
Compared to existing DP text generation baselines, Term2Note achieves
substantial improvements in both fidelity and utility while operating under
fewer assumptions, suggesting its potential as a viable privacy-preserving
alternative to using sensitive clinical notes.

</details>


### [169] [CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis](https://arxiv.org/abs/2509.10886)
*Xinyu Zhang,Pei Zhang,Shuang Luo,Jialong Tang,Yu Wan,Baosong Yang,Fei Huang*

Main category: cs.CL

TL;DR: 该研究提出了CultureSynth框架，用于评估和提升大型语言模型（LLMs）的文化能力，解决了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLMs文化能力的方法存在分类体系不完善、领域特定性强以及过度依赖人工标注等问题。为了解决这些限制，本研究旨在开发一个更全面、可扩展且减少人工依赖的评估框架。

Method: CultureSynth框架包含一个多语言的文化分类体系（12个一级主题，130个二级主题）和一个基于检索增强生成（RAG）的方法，利用事实知识生成相关的问答对。在此基础上构建了包含19,360个条目和4,149个人工验证条目的CultureSynth-7基准测试集，覆盖7种语言。

Result: 在对14种不同规模的LLMs进行评估后，研究发现ChatGPT-4o-Latest和Qwen2.5-72B-Instruct表现最优。结果还显示，模型参数量达到3B是实现基本文化能力的要求，不同模型在知识处理方面存在架构偏见，并且在地理分布上存在显著差异。

Conclusion: CultureSynth框架为开发具有文化意识的AI系统提供了一个可扩展的解决方案，并减少了对人工标注的依赖。

Abstract: Cultural competence, defined as the ability to understand and adapt to
multicultural contexts, is increasingly vital for large language models (LLMs)
in global environments. While several cultural benchmarks exist to assess LLMs'
cultural competence, current evaluations suffer from fragmented taxonomies,
domain specificity, and heavy reliance on manual data annotation. To address
these limitations, we introduce CultureSynth, a novel framework comprising (1)
a comprehensive hierarchical multilingual cultural taxonomy covering 12 primary
and 130 secondary topics, and (2) a Retrieval-Augmented Generation (RAG)-based
methodology leveraging factual knowledge to synthesize culturally relevant
question-answer pairs. The CultureSynth-7 synthetic benchmark contains 19,360
entries and 4,149 manually verified entries across 7 languages. Evaluation of
14 prevalent LLMs of different sizes reveals clear performance stratification
led by ChatGPT-4o-Latest and Qwen2.5-72B-Instruct. The results demonstrate that
a 3B-parameter threshold is necessary for achieving basic cultural competence,
models display varying architectural biases in knowledge processing, and
significant geographic disparities exist across models. We believe that
CultureSynth offers a scalable framework for developing culturally aware AI
systems while reducing reliance on manual annotation\footnote{Benchmark is
available at https://github.com/Eyr3/CultureSynth.}.

</details>


### [170] [Aligning ESG Controversy Data with International Guidelines through Semi-Automatic Ontology Construction](https://arxiv.org/abs/2509.10922)
*Tsuyoshi Iwata,Guillaume Comte,Melissa Flores,Ryoma Kondo,Ryohei Hisano*

Main category: cs.CL

TL;DR: 该研究提出了一种半自动方法，用于将新闻报道中的环境、社会和治理（ESG）事件与联合国全球契约等原则性框架进行匹配，以应对当前数据表示的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于ESG数据在监管和投资领域日益重要，需要准确、可解释且国际对齐的非金融风险表示，尤其是在非结构化新闻来源中。然而，将此类争议相关数据与基于原则的规范框架（如联合国全球契约或可持续发展目标）进行匹配存在重大挑战，因为这些框架语言抽象、缺乏标准化分类，且与商业数据提供商的专有分类系统不同。

Method: 本研究提出了一种半自动方法，利用轻量级本体设计、形式化模式建模和大型语言模型，将规范原则转换为可复用的资源描述框架（RDF）模板。这些模板用于从新闻内容中提取相关信息，并填充结构化知识图谱，将报道的事件与特定的框架原则联系起来。

Result: 该方法能够将新闻报道中的ESG事件结构化，并链接到具体的国际可持续性指导原则，从而实现对不合规情况的可识别和可解释。

Conclusion: 该研究提供了一个可扩展且透明的框架，用于识别和解释不遵守国际可持续性指导原则的情况，解决了当前ESG数据表示和对齐的挑战。

Abstract: The growing importance of environmental, social, and governance data in
regulatory and investment contexts has increased the need for accurate,
interpretable, and internationally aligned representations of non-financial
risks, particularly those reported in unstructured news sources. However,
aligning such controversy-related data with principle-based normative
frameworks, such as the United Nations Global Compact or Sustainable
Development Goals, presents significant challenges. These frameworks are
typically expressed in abstract language, lack standardized taxonomies, and
differ from the proprietary classification systems used by commercial data
providers. In this paper, we present a semi-automatic method for constructing
structured knowledge representations of environmental, social, and governance
events reported in the news. Our approach uses lightweight ontology design,
formal pattern modeling, and large language models to convert normative
principles into reusable templates expressed in the Resource Description
Framework. These templates are used to extract relevant information from news
content and populate a structured knowledge graph that links reported incidents
to specific framework principles. The result is a scalable and transparent
framework for identifying and interpreting non-compliance with international
sustainability guidelines.

</details>


### [171] [Introducing Spotlight: A Novel Approach for Generating Captivating Key Information from Documents](https://arxiv.org/abs/2509.10935)
*Ankan Mullick,Sombit Bose,Rounak Saha,Ayan Kumar Bhowmick,Aditya Vempaty,Prasenjit Dey,Ravi Kokku,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: Spotlight是一种新的信息提取方法，通过突出文档中最吸引人的部分来生成简洁、引人入胜的叙述，以增加读者的参与度。


<details>
  <summary>Details</summary>
Motivation: 与传统的全面覆盖的摘要不同，Spotlight 旨在通过选择性地强调有趣的内容来促进读者更深入地参与源材料。

Method: 提出了一种两阶段的方法：首先在基准数据集上微调大型语言模型，然后通过直接偏好优化（DPO）进行对齐。

Result: 模型能够精确识别关键元素，提高可读性，并提升原始文档的参与价值。

Conclusion: Spotlight 是一种有效的信息提取范式，能够生成高质量、引人入胜且能提高读者参与度的叙述。

Abstract: In this paper, we introduce Spotlight, a novel paradigm for information
extraction that produces concise, engaging narratives by highlighting the most
compelling aspects of a document. Unlike traditional summaries, which
prioritize comprehensive coverage, spotlights selectively emphasize intriguing
content to foster deeper reader engagement with the source material. We
formally differentiate spotlights from related constructs and support our
analysis with a detailed benchmarking study using new datasets curated for this
work. To generate high-quality spotlights, we propose a two-stage approach:
fine-tuning a large language model on our benchmark data, followed by alignment
via Direct Preference Optimization (DPO). Our comprehensive evaluation
demonstrates that the resulting model not only identifies key elements with
precision but also enhances readability and boosts the engagement value of the
original document.

</details>


### [172] [An Interpretable Benchmark for Clickbait Detection and Tactic Attribution](https://arxiv.org/abs/2509.10937)
*Lihi Nofar,Tomer Portal,Aviv Elbaz,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 本研究提出了一种可解释的诱饵点阅标题检测模型，该模型不仅能识别诱饵点阅标题，还能将其归因于具体的语言操纵策略。


<details>
  <summary>Details</summary>
Motivation: 解决数字媒体中诱饵点阅标题的泛滥问题及其对信息可信度和用户信任的挑战，并克服现有机器学习模型可解释性差的局限性。

Method: 提出了一种两阶段的自动诱饵点阅标题分析框架：1. 使用微调的 BERT 分类器，以及在零次和少量提示下使用 GPT-4.0 和 Gemini 2.4 Flash 等大型语言模型进行诱饵点阅标题检测。2. 使用专门的基于 BERT 的分类器预测存在的具体诱饵点阅策略。研究中还引入了一个通过系统性增强真实新闻标题生成的数据集，以支持对模型行为进行受控实验和详细分析。

Result: 对三种模型（BERT、GPT-4.0、Gemini 2.4 Flash）在零次和少量提示下的诱饵点阅标题检测能力进行了比较，并开发了一个能够预测具体诱饵点阅策略的分类器。

Conclusion: 该研究通过提出一个可解释的诱饵点阅标题检测模型和相关数据集，推动了用于打击操纵性媒体内容的透明、可信的 AI 系统的发展。

Abstract: The proliferation of clickbait headlines poses significant challenges to the
credibility of information and user trust in digital media. While recent
advances in machine learning have improved the detection of manipulative
content, the lack of explainability limits their practical adoption. This paper
presents a model for explainable clickbait detection that not only identifies
clickbait titles but also attributes them to specific linguistic manipulation
strategies. We introduce a synthetic dataset generated by systematically
augmenting real news headlines using a predefined catalogue of clickbait
strategies. This dataset enables controlled experimentation and detailed
analysis of model behaviour. We present a two-stage framework for automatic
clickbait analysis comprising detection and tactic attribution. In the first
stage, we compare a fine-tuned BERT classifier with large language models
(LLMs), specifically GPT-4.0 and Gemini 2.4 Flash, under both zero-shot
prompting and few-shot prompting enriched with illustrative clickbait headlines
and their associated persuasive tactics. In the second stage, a dedicated
BERT-based classifier predicts the specific clickbait strategies present in
each headline. This work advances the development of transparent and
trustworthy AI systems for combating manipulative media content. We share the
dataset with the research community at
https://github.com/LLM-HITCS25S/ClickbaitTacticsDetection

</details>


### [173] [EmoBench-Reddit: A Hierarchical Benchmark for Evaluating the Emotional Intelligence of Multimodal Large Language Models](https://arxiv.org/abs/2509.11101)
*Haokun Li,Yazhou Zhang,Jizhi Ding,Qiuchi Li,Peng Zhang*

Main category: cs.CL

TL;DR: 介绍了一个名为 EmoBench-Reddit 的新基准，用于评估多模态大语言模型（MLLMs）在理解复杂和主观人类情感方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准不足以评估MLLMs理解复杂和主观人类情感的能力。

Method: 创建了一个包含350个样本的数据集，每个样本包含图像、用户文本和情感标签（悲伤、幽默、讽刺、快乐）。设计了一个从基础感知到高级认知的分层任务框架，每个数据点有六个选择题和一个开放题。

Result: EmoBench-Reddit 包含350个样本，具有分层任务框架，涵盖感知和认知任务，旨在评估MLLMs的情感理解能力。

Conclusion: EmoBench-Reddit 是一个新颖的、分层的基准，用于多模态情感理解，解决了现有基准的不足。

Abstract: With the rapid advancement of Multimodal Large Language Models (MLLMs), they
have demonstrated exceptional capabilities across a variety of vision-language
tasks. However, current evaluation benchmarks predominantly focus on objective
visual question answering or captioning, inadequately assessing the models'
ability to understand complex and subjective human emotions. To bridge this
gap, we introduce EmoBench-Reddit, a novel, hierarchical benchmark for
multimodal emotion understanding. The dataset comprises 350 meticulously
curated samples from the social media platform Reddit, each containing an
image, associated user-provided text, and an emotion category (sad, humor,
sarcasm, happy) confirmed by user flairs. We designed a hierarchical task
framework that progresses from basic perception to advanced cognition, with
each data point featuring six multiple-choice questions and one open-ended
question of increasing difficulty. Perception tasks evaluate the model's
ability to identify basic visual elements (e.g., colors, objects), while
cognition tasks require scene reasoning, intent understanding, and deep empathy
integrating textual context. We ensured annotation quality through a
combination of AI assistance (Claude 4) and manual verification.

</details>


### [174] [Fluid Language Model Benchmarking](https://arxiv.org/abs/2509.11106)
*Valentin Hofmann,David Heineman,Ian Magnusson,Kyle Lo,Jesse Dodge,Maarten Sap,Pang Wei Koh,Chun Wang,Hannaneh Hajishirzi,Noah A. Smith*

Main category: cs.CL

TL;DR: 语言模型评估面临诸多挑战，本文提出一种名为“流畅基准测试”的新方法，通过自适应调整评估内容来提高评估效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估方法在成本、准确性和评估质量方面存在挑战，且缺乏整体性的解决方案。

Method: 受心理测量学启发，提出流畅基准测试（Fluid Benchmarking），利用项目反应模型动态选择评估项目，以适应不同能力水平的语言模型。

Result: 在效率、有效性、方差和饱和度四个维度上，流畅基准测试均优于随机抽样和现有的基于项目反应理论的方法，尤其在MMLU测试中，使用更少的数据即可获得更高的有效性和更低的方差。

Conclusion: 语言模型的评估可以通过从静态评估转向动态评估得到显著改进。

Abstract: Language model (LM) benchmarking faces several challenges: comprehensive
evaluations are costly, benchmarks often fail to measure the intended
capabilities, and evaluation quality can degrade due to labeling errors and
benchmark saturation. Although various strategies have been proposed to
mitigate these issues, they tend to address individual aspects in isolation,
neglecting broader questions about overall evaluation quality. Here, we
introduce Fluid Benchmarking, a new evaluation approach that advances LM
benchmarking across multiple dimensions. Inspired by psychometrics, Fluid
Benchmarking is based on the insight that the relative value of benchmark items
depends on an LM's capability level, suggesting that evaluation should adapt to
each LM. Methodologically, Fluid Benchmarking estimates an item response model
based on existing LM evaluation results and uses the inferred quantities to
select evaluation items dynamically, similar to computerized adaptive testing
in education. In our experiments, we compare Fluid Benchmarking against the
common practice of random item sampling as well as more sophisticated
baselines, including alternative methods grounded in item response theory. We
examine four dimensions -- efficiency, validity, variance, and saturation --
and find that Fluid Benchmarking achieves superior performance in all of them
(e.g., higher validity and less variance on MMLU with fifty times fewer items).
Our analysis shows that the two components of Fluid Benchmarking have distinct
effects: item response theory, used to map performance into a latent ability
space, increases validity, while dynamic item selection reduces variance.
Overall, our results suggest that LM benchmarking can be substantially improved
by moving beyond static evaluation.

</details>


### [175] [We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation Dialogue Systems for Tourism](https://arxiv.org/abs/2509.11118)
*Priyanshu Priya,Saurav Dudhate,Desai Vishesh Yasheshbhai,Asif Ekbal*

Main category: cs.CL

TL;DR: 通过引入基于个性的论证谈判对话生成（PAN-DG）任务和PACT数据集，增强了谈判对话系统在旅游领域的个性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高冲突解决和适应性，需要将论证机制和个性化属性整合到谈判对话系统中。

Method: 提出了一种新颖的基于个性的论证谈判对话生成（PAN-DG）任务，并创建了一个名为PACT的数据集。该数据集利用大型语言模型（LLM）生成，包含三种不同的个性档案（论证、偏好和购买风格），以模拟各种谈判场景。对预训练和微调的LLM进行了比较实验。

Result: PACT数据集包含高质量的对话。微调后的LLM能够有效地生成具有说服力的、面向个性的谈判回应。

Conclusion: PACT数据集有助于增强谈判对话系统的个性和推理能力，为该领域未来的研究奠定了基础。

Abstract: Integrating argumentation mechanisms into negotiation dialogue systems
improves conflict resolution through exchanges of arguments and critiques.
Moreover, incorporating personality attributes enhances adaptability by
aligning interactions with individuals' preferences and styles. To advance
these capabilities in negotiation dialogue systems, we propose a novel
Personality-driven Argumentation-based Negotiation Dialogue Generation (PAN-DG)
task. To support this task, we introduce PACT, a dataset of Personality-driven
Argumentation-based negotiation Conversations for Tourism sector. This dataset,
generated using Large Language Models (LLMs), features three distinct
personality profiles, viz. Argumentation Profile, Preference Profile, and
Buying Style Profile to simulate a variety of negotiation scenarios involving
diverse personalities. Thorough automatic and manual evaluations indicate that
the dataset comprises high-quality dialogues. Further, we conduct comparative
experiments between pre-trained and fine-tuned LLMs for the PAN-DG task.
Multi-dimensional evaluation demonstrates that the fine-tuned LLMs effectively
generate personality-driven rational responses during negotiations. This
underscores the effectiveness of PACT in enhancing personalization and
reasoning capabilities in negotiation dialogue systems, thereby establishing a
foundation for future research in this domain.

</details>


### [176] [Joint Effects of Argumentation Theory, Audio Modality and Data Enrichment on LLM-Based Fallacy Classification](https://arxiv.org/abs/2509.11127)
*Hongxu Zhou,Hylke Westerdijk,Khondoker Ittehadul Islam*

Main category: cs.CL

TL;DR: 上下文和情绪元数据可能损害大型语言模型在政治辩论中的谬误分类表现，基本提示有时优于增强提示。


<details>
  <summary>Details</summary>
Motivation: 研究上下文和情绪元数据如何影响大型语言模型（LLM）在谬误分类任务（尤其是在政治辩论背景下）中的推理和表现。

Method: 使用来自美国总统辩论的数据，通过对Qwen-3（8B）模型采用各种提示策略来分类六种谬误类型。引入了基于理论的链式思考框架（语用-辩证和论证元素周期表），并评估了它们在仅文本、带上下文的文本以及同时包含上下文和基于音频的情绪基调元数据的三种输入设置下相对于基线提示的有效性。

Result: 结果表明，虽然理论提示可以提高可解释性，并在某些情况下提高准确性，但添加上下文，特别是情绪基调元数据，通常会导致性能下降。情绪基调元数据会使模型倾向于将陈述标记为“诉诸情感”，从而削弱逻辑推理。总体而言，基本提示通常优于增强提示，这表明添加输入可能由于注意力分散而损害而非改善LLM中的谬误分类。

Conclusion: 上下文和情绪元数据，尤其是在政治辩论等复杂环境中，可能会对LLM的谬误分类能力产生负面影响，并且可能不如简单的提示方法有效。

Abstract: This study investigates how context and emotional tone metadata influence
large language model (LLM) reasoning and performance in fallacy classification
tasks, particularly within political debate settings. Using data from U.S.
presidential debates, we classify six fallacy types through various prompting
strategies applied to the Qwen-3 (8B) model. We introduce two theoretically
grounded Chain-of-Thought frameworks: Pragma-Dialectics and the Periodic Table
of Arguments, and evaluate their effectiveness against a baseline prompt under
three input settings: text-only, text with context, and text with both context
and audio-based emotional tone metadata. Results suggest that while theoretical
prompting can improve interpretability and, in some cases, accuracy, the
addition of context and especially emotional tone metadata often leads to
lowered performance. Emotional tone metadata biases the model toward labeling
statements as \textit{Appeal to Emotion}, worsening logical reasoning. Overall,
basic prompts often outperformed enhanced ones, suggesting that attention
dilution from added inputs may worsen rather than improve fallacy
classification in LLMs.

</details>


### [177] [When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs' Toxicity](https://arxiv.org/abs/2509.11141)
*Shiyao Cui,Xijia Feng,Yingkang Wang,Junxiao Yang,Zhexin Zhang,Biplab Sikdar,Hongning Wang,Han Qiu,Minlie Huang*

Main category: cs.CL

TL;DR: Emojis can inadvertently trigger toxic content generation in LLMs by bypassing safety mechanisms, potentially due to issues in pre-training data.


<details>
  <summary>Details</summary>
Motivation: To investigate whether emojis enhance toxicity generation in LLMs and understand the underlying reasons.

Method: Automated construction of emoji-laden prompts to express toxic intent, followed by experiments across multiple languages and LLMs, including jailbreak tasks. Model-level interpretations (semantic cognition, sequence generation, tokenization) and analysis of pre-training corpus were conducted.

Result: Prompts with emojis were found to easily induce toxicity generation in LLMs. Emojis act as a heterogeneous semantic channel, bypassing safety mechanisms. Potential correlation found between emoji-related data pollution in pre-training corpus and toxicity generation behaviors.

Conclusion: Emojis can significantly enhance LLM toxicity generation, and this phenomenon can be attributed to their ability to bypass safety mechanisms and potential issues within the pre-training data.

Abstract: Emojis are globally used non-verbal cues in digital communication, and
extensive research has examined how large language models (LLMs) understand and
utilize emojis across contexts. While usually associated with friendliness or
playfulness, it is observed that emojis may trigger toxic content generation in
LLMs. Motivated by such a observation, we aim to investigate: (1) whether
emojis can clearly enhance the toxicity generation in LLMs and (2) how to
interpret this phenomenon. We begin with a comprehensive exploration of
emoji-triggered LLM toxicity generation by automating the construction of
prompts with emojis to subtly express toxic intent. Experiments across 5
mainstream languages on 7 famous LLMs along with jailbreak tasks demonstrate
that prompts with emojis could easily induce toxicity generation. To understand
this phenomenon, we conduct model-level interpretations spanning semantic
cognition, sequence generation and tokenization, suggesting that emojis can act
as a heterogeneous semantic channel to bypass the safety mechanisms. To pursue
deeper insights, we further probe the pre-training corpus and uncover potential
correlation between the emoji-related data polution with the toxicity
generation behaviors. Supplementary materials provide our implementation code
and data. (Warning: This paper contains potentially sensitive contents)

</details>


### [178] [Text2Mem: A Unified Memory Operation Language for Memory Operating System](https://arxiv.org/abs/2509.11145)
*Felix Wang,Boyu Chen,Kerun Xu,Bo Tang,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: Text2Mem是一个统一的内存操作语言，通过自然语言实现可靠执行，解决了现有框架内存操作不足和缺乏正式规范的问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）代理在长期交互中内存功能有限，缺乏高级操作且无正式规范，导致行为不可预测。

Method: Text2Mem 提供了一套紧凑而富有表现力的操作集，用于编码、存储和检索。每个指令都表示为基于 JSON 的模式实例，并附带必需的字段和语义不变量。解析器将其转换为类型化的操作对象，并进行参数规范化。验证器在执行前确保正确性，适配器将类型化对象映射到 SQL 或实际内存框架。模型服务（如嵌入或摘要）按需集成，所有结果通过统一的执行合同返回。

Result: Text2Mem 实现了内存操作的安全性、确定性和跨异构后端的便携性。计划中的 Text2Mem Bench  benchmark 将分离模式生成和后端执行，以实现系统化评估。

Conclusion: Text2Mem 及其配套的 benchmark 为 LLM 代理的内存控制提供了第一个标准化的基础。

Abstract: Large language model agents increasingly depend on memory to sustain long
horizon interaction, but existing frameworks remain limited. Most expose only a
few basic primitives such as encode, retrieve, and delete, while higher order
operations like merge, promote, demote, split, lock, and expire are missing or
inconsistently supported. Moreover, there is no formal and executable
specification for memory commands, leaving scope and lifecycle rules implicit
and causing unpredictable behavior across systems. We introduce Text2Mem, a
unified memory operation language that provides a standardized pathway from
natural language to reliable execution. Text2Mem defines a compact yet
expressive operation set aligned with encoding, storage, and retrieval. Each
instruction is represented as a JSON based schema instance with required fields
and semantic invariants, which a parser transforms into typed operation objects
with normalized parameters. A validator ensures correctness before execution,
while adapters map typed objects either to a SQL prototype backend or to real
memory frameworks. Model based services such as embeddings or summarization are
integrated when required. All results are returned through a unified execution
contract. This design ensures safety, determinism, and portability across
heterogeneous backends. We also outline Text2Mem Bench, a planned benchmark
that separates schema generation from backend execution to enable systematic
evaluation. Together, these components establish the first standardized
foundation for memory control in agents.

</details>


### [179] [Differentially-private text generation degrades output language quality](https://arxiv.org/abs/2509.11176)
*Erion Çano,Ivan Habernal*

Main category: cs.CL

TL;DR: DP 调优的 LLM 会产生质量较低的文本，其长度、语法正确性和词汇多样性均有所下降，并且在下游分类任务中的准确率也会降低。


<details>
  <summary>Details</summary>
Motivation: 评估差分隐私（DP）微调的大型语言模型（LLM）对生成文本的质量和效用的影响。

Method: 对五个 LLM 和三个语料库在四个隐私级别下进行微调，并评估文本输出的长度、语法正确性和词汇多样性。此外，还探测了合成输出在书籍类型识别和死因识别等下游分类任务中的效用。

Result: DP 约束越强的 LLM，其生成的文本越短（减少至少 77%），语法正确性越低（降低至少 9%），词汇多样性越低（双字母组多样性降低至少 10%）。同时，在下游分类任务中的准确率也会随之下降。

Conclusion: DP 微调的 LLM 会损害文本的质量和下游任务的效用，这可能会对其生成的合成数据的实用性产生不利影响。

Abstract: Ensuring user privacy by synthesizing data from large language models (LLMs)
tuned under differential privacy (DP) has become popular recently. However, the
impact of DP fine-tuned LLMs on the quality of the language and the utility of
the texts they produce has not been investigated. In this work, we tune five
LLMs with three corpora under four levels of privacy and assess the length, the
grammatical correctness, and the lexical diversity of the text outputs they
produce. We also probe the utility of the synthetic outputs in downstream
classification tasks such as book genre recognition based on book descriptions
and cause of death recognition based on verbal autopsies. The results indicate
that LLMs tuned under stronger privacy constrains produce texts that are
shorter by at least 77 %, that are less grammatically correct by at least 9 %,
and are less diverse by at least 10 % in bi-gram diversity. Furthermore, the
accuracy they reach in downstream classification tasks decreases, which might
be detrimental to the usefulness of the generated synthetic data.

</details>


### [180] [Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs](https://arxiv.org/abs/2509.11177)
*Hang Guo,Yawei Li,Luca Benini*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Optimal Brain Restoration (OBR)的框架，通过结合量化和稀疏性技术来压缩大型语言模型（LLM），解决了这两种技术之间因权重分布要求冲突而带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）压缩技术（如量化和剪枝）已接近极限，单独依赖一种方法进行进一步压缩面临挑战。因此，探索结合量化和稀疏性的联合方法成为必然选择，但该方法面临权重分布要求冲突（量化偏好紧凑范围，剪枝偏好高方差）的困难。

Method: 提出Optimal Brain Restoration (OBR)框架，该框架通过误差补偿来协调剪枝和量化。OBR利用二阶Hessian目标，通过代理近似将其重构为一个可处理的问题，并最终通过分组误差补偿获得闭式解，以最小化在下游任务上的性能下降。

Result: OBR实现了在现有LLM上进行W4A4KV4量化和50%稀疏度的激进压缩，与FP16-dense基线相比，速度提升高达4.72倍，内存减少6.4倍。

Conclusion: OBR是一种有效的、无需训练的通用框架，能够成功地结合量化和稀疏性技术来压缩LLM，在显著减少模型大小和提高推理速度的同时，保持了模型的性能。

Abstract: Recent advances in Large Language Model (LLM) compression, such as
quantization and pruning, have achieved notable success. However, as these
techniques gradually approach their respective limits, relying on a single
method for further compression has become increasingly challenging. In this
work, we explore an alternative solution by combining quantization and
sparsity. This joint approach, though promising, introduces new difficulties
due to the inherently conflicting requirements on weight distributions:
quantization favors compact ranges, while pruning benefits from high variance.
To attack this problem, we propose Optimal Brain Restoration (OBR), a general
and training-free framework that aligns pruning and quantization by error
compensation between both. OBR minimizes performance degradation on downstream
tasks by building on a second-order Hessian objective, which is then
reformulated into a tractable problem through surrogate approximation and
ultimately reaches a closed-form solution via group error compensation.
Experiments show that OBR enables aggressive W4A4KV4 quantization with 50%
sparsity on existing LLMs, and delivers up to 4.72x speedup and 6.4x memory
reduction compared to the FP16-dense baseline.

</details>


### [181] [RanAT4BIE: Random Adversarial Training for Biomedical Information Extraction](https://arxiv.org/abs/2509.11191)
*Jian Chen,Shengyi Lv,Leilei Su*

Main category: cs.CL

TL;DR: 随机对抗训练（RAT）框架通过结合随机采样和对抗训练，在提高生物医学信息提取（BioIE）任务的模型泛化性和鲁棒性的同时，显著降低了计算成本，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统的对抗训练在提高预训练语言模型在生物医学信息提取（BioIE）任务上的性能方面虽然有效，但计算开销大。因此，需要一种更高效的解决方案。

Method: 提出了一种名为随机对抗训练（RAT）的新框架，该框架将随机采样机制与对抗训练原理相结合，以PubMedBERT为基础。

Result: 与基线模型相比，RAT在BioIE任务上表现出优越的性能，实现了模型泛化性、鲁棒性和计算效率的平衡。

Conclusion: RAT框架为生物医学自然语言处理提供了一种有前景的解决方案，能够有效提高模型性能并降低计算成本。

Abstract: We introduce random adversarial training (RAT), a novel framework
successfully applied to biomedical information extraction (BioIE) tasks.
Building on PubMedBERT as the foundational architecture, our study first
validates the effectiveness of conventional adversarial training in enhancing
pre-trained language models' performance on BioIE tasks. While adversarial
training yields significant improvements across various performance metrics, it
also introduces considerable computational overhead. To address this
limitation, we propose RAT as an efficiency solution for biomedical information
extraction. This framework strategically integrates random sampling mechanisms
with adversarial training principles, achieving dual objectives: enhanced model
generalization and robustness while significantly reducing computational costs.
Through comprehensive evaluations, RAT demonstrates superior performance
compared to baseline models in BioIE tasks. The results highlight RAT's
potential as a transformative framework for biomedical natural language
processing, offering a balanced solution to the model performance and
computational efficiency.

</details>


### [182] [The Prompt Engineering Report Distilled: Quick Start Guide for Life Sciences](https://arxiv.org/abs/2509.11295)
*Valentin Romanov,Steven A Niederer*

Main category: cs.CL

TL;DR: LLM提示工程可以通过精简生命科学工作流程来提高效率，本文重点介绍六种核心技术（zero-shot, few-shot, thought generation, ensembling, self-criticism, decomposition），并提供具体用例和最佳实践，以提高研究质量。


<details>
  <summary>Details</summary>
Motivation: 开发有效的LLM提示需要大量的认知投入，但通过案例特定的提示工程技术可以实现显著的效率提升，远超掌握这些技术所需的时间投入。

Method: 重点介绍并分解了六种核心提示工程技术：zero-shot、few-shot、thought generation、ensembling、self-criticism和decomposition。结合生命科学领域的用例（如文献摘要、数据提取、编辑任务）进行了阐述，并提供了关于提示结构、常见陷阱（如多轮对话退化、幻觉）以及区分推理和非推理模型的详细建议。还探讨了上下文窗口限制、Claude Code等代理工具，并分析了OpenAI、Google、Anthropic和Perplexity平台上Deep Research工具的有效性。

Result: 提供了关于核心提示工程原则的可操作指南，旨在将机会主义的提示转变为一种有效的、低摩擦的系统化实践，从而提高研究质量。

Conclusion: 通过提供对核心提示工程原则的明确指导，本文旨在帮助研究人员更有效地利用LLM，从而提高生命科学研究的效率和质量。

Abstract: Developing effective prompts demands significant cognitive investment to
generate reliable, high-quality responses from Large Language Models (LLMs). By
deploying case-specific prompt engineering techniques that streamline
frequently performed life sciences workflows, researchers could achieve
substantial efficiency gains that far exceed the initial time investment
required to master these techniques. The Prompt Report published in 2025
outlined 58 different text-based prompt engineering techniques, highlighting
the numerous ways prompts could be constructed. To provide actionable
guidelines and reduce the friction of navigating these various approaches, we
distil this report to focus on 6 core techniques: zero-shot, few-shot
approaches, thought generation, ensembling, self-criticism, and decomposition.
We breakdown the significance of each approach and ground it in use cases
relevant to life sciences, from literature summarization and data extraction to
editorial tasks. We provide detailed recommendations for how prompts should and
shouldn't be structured, addressing common pitfalls including multi-turn
conversation degradation, hallucinations, and distinctions between reasoning
and non-reasoning models. We examine context window limitations, agentic tools
like Claude Code, while analyzing the effectiveness of Deep Research tools
across OpenAI, Google, Anthropic and Perplexity platforms, discussing current
limitations. We demonstrate how prompt engineering can augment rather than
replace existing established individual practices around data processing and
document editing. Our aim is to provide actionable guidance on core prompt
engineering principles, and to facilitate the transition from opportunistic
prompting to an effective, low-friction systematic practice that contributes to
higher quality research.

</details>


### [183] [Ko-PIQA: A Korean Physical Commonsense Reasoning Dataset with Cultural Context](https://arxiv.org/abs/2509.11303)
*Dasol Choi,Jungwhan Kim,Guijin Son*

Main category: cs.CL

TL;DR: 英文为中心的常识推理数据集缺乏文化多样性，因此我们提出了包含文化背景的韩语数据集Ko-PIQA，并评估了语言模型在该数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的物理常识推理数据集（如PIQA）主要以英语为中心，缺乏文化多样性，这限制了模型的泛化能力和包容性。

Method: 从301万个网络爬取的问题中，使用语言模型进行多阶段筛选，筛选出11,553个PIQA风格的问题。随后通过GPT-4o优化和人工验证，最终得到441个高质量的问答对。该数据集包含19.7%的文化特定问题，涉及韩国传统食物、服装和电器等，需要具备文化意识的推理能力。

Result: 在Ko-PIQA数据集上评估了七个语言模型，最佳模型的准确率为83.22%，最差模型的准确率为59.86%。模型在处理文化特定场景时尤其困难，表明了文化多样化数据集的重要性。

Conclusion: Ko-PIQA数据集填补了韩语物理常识推理数据集的空白，并能促进更具包容性的常识推理研究。该数据集将作为韩语语言模型的基准，并已公开数据集和代码。

Abstract: Physical commonsense reasoning datasets like PIQA are predominantly
English-centric and lack cultural diversity. We introduce Ko-PIQA, a Korean
physical commonsense reasoning dataset that incorporates cultural context.
Starting from 3.01 million web-crawled questions, we employed a multi-stage
filtering approach using three language models to identify 11,553 PIQA-style
questions. Through GPT-4o refinement and human validation, we obtained 441
high-quality question-answer pairs. A key feature of Ko-PIQA is its cultural
grounding: 19.7\% of questions contain culturally specific elements like
traditional Korean foods (kimchi), clothing (hanbok), and specialized
appliances (kimchi refrigerators) that require culturally-aware reasoning
beyond direct translation. We evaluate seven language models on Ko-PIQA, with
the best model achieving 83.22\% accuracy while the weakest reaches only
59.86\%, demonstrating significant room for improvement. Models particularly
struggle with culturally specific scenarios, highlighting the importance of
culturally diverse datasets. Ko-PIQA serves as both a benchmark for Korean
language models and a foundation for more inclusive commonsense reasoning
research. The dataset and code will be publicly available.

</details>


### [184] [!MSA at AraHealthQA 2025 Shared Task: Enhancing LLM Performance for Arabic Clinical Question Answering through Prompt Engineering and Ensemble Learning](https://arxiv.org/abs/2509.11365)
*Mohamed Tarek,Seif Ahmed,Mohamed Basem*

Main category: cs.CL

TL;DR: 该研究提出了用于阿拉伯语健康问答任务（MedArabiQ）的系统，在两个子任务中均获得第二名。


<details>
  <summary>Details</summary>
Motivation: 旨在解决阿拉伯语临床环境下的健康问答问题，包括选择题和开放式问答。

Method: 子任务1：使用Gemini 2.5 Flash模型，结合少样本提示、数据集预处理和三种提示配置的集成，以提高分类准确性。子任务2：采用统一提示，利用同一模型，结合角色扮演（阿拉伯语医学专家）、少样本示例和后处理，以生成简洁的答案。

Result: 在AraHealthQA-2025共享任务的两个子任务中均获得第二名。

Conclusion: 研究成功开发并验证了一种有效的阿拉伯语健康问答系统，能够处理不同类型的问答格式。

Abstract: We present our systems for Track 2 (General Arabic Health QA, MedArabiQ) of
the AraHealthQA-2025 shared task, where our methodology secured 2nd place in
both Sub-Task 1 (multiple-choice question answering) and Sub-Task 2 (open-ended
question answering) in Arabic clinical contexts. For Sub-Task 1, we leverage
the Gemini 2.5 Flash model with few-shot prompting, dataset preprocessing, and
an ensemble of three prompt configurations to improve classification accuracy
on standard, biased, and fill-in-the-blank questions. For Sub-Task 2, we employ
a unified prompt with the same model, incorporating role-playing as an Arabic
medical expert, few-shot examples, and post-processing to generate concise
responses across fill-in-the-blank, patient-doctor Q&A, GEC, and paraphrased
variants.

</details>


### [185] [Transformer Enhanced Relation Classification: A Comparative Analysis of Contextuality, Data Efficiency and Sequence Complexity](https://arxiv.org/abs/2509.11374)
*Bowen Jing,Yang Cui,Tianpeng Huang*

Main category: cs.CL

TL;DR: transformer模型在关系抽取任务中表现优于非transformer模型。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型时代，为了将非结构化文本转化为结构化数据，关系抽取（RE）扮演着重要的角色，因此系统地比较不同方法的性能至关重要。

Method: 比较了包括PA-LSTM、C-GCN、AGGCN在内的一系列非transformer模型，以及BERT、RoBERTa、R-BERT等transformer模型在关系抽取任务上的性能。实验在TACRED、TACREV和RE-TACRED数据集上进行，评估了传统指标（如micro F1），并考虑了不同句子长度和训练数据比例等场景。

Result: transformer模型在关系抽取任务上的表现优于非transformer模型，micro F1得分达到80-90%，而非transformer模型得分仅为64-67%。

Conclusion: transformer模型在关系抽取方面展现出显著优势。此外，论文还回顾了监督关系分类的研究历程，并讨论了大型语言模型在关系抽取中的作用和现状。

Abstract: In the era of large language model, relation extraction (RE) plays an
important role in information extraction through the transformation of
unstructured raw text into structured data (Wadhwa et al., 2023). In this
paper, we systematically compare the performance of deep supervised learning
approaches without transformers and those with transformers. We used a series
of non-transformer architectures such as PA-LSTM(Zhang et al., 2017),
C-GCN(Zhang et al., 2018), and AGGCN(attention guide GCN)(Guo et al., 2019),
and a series of transformer architectures such as BERT, RoBERTa, and R-BERT(Wu
and He, 2019). Our comparison included traditional metrics like micro F1, as
well as evaluations in different scenarios, varying sentence lengths, and
different percentages of the dataset for training. Our experiments were
conducted on TACRED, TACREV, and RE-TACRED. The results show that
transformer-based models outperform non-transformer models, achieving micro F1
scores of 80-90% compared to 64-67% for non-transformer models. Additionally,
we briefly review the research journey in supervised relation classification
and discuss the role and current status of large language models (LLMs) in
relation extraction.

</details>


### [186] [Continually Adding New Languages to Multilingual Language Models](https://arxiv.org/abs/2509.11414)
*Abraham Toluwase Owodunni,Sachin Kumar*

Main category: cs.CL

TL;DR: LayRA是一种通过在选定的初始和最终层添加LoRA来持续添加新语言到多语言模型的方法，它能有效减少遗忘并保持模型在先前支持的语言上的能力，同时在学习新语言方面具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言模型在支持新语言时需要从头开始训练，成本高昂且不切实际，因为预训练数据通常不公开。而像持续预训练这样的朴素方法会导致灾难性遗忘，且经验回放等缓解策略因无法获取原始预训练数据而无法应用。

Method: LayRA通过在多语言模型的选定初始层和最终层添加低秩适配器（LoRA），并冻结其余层来实现。该方法基于两个洞察：LoRA能减少遗忘；多语言模型在初始层编码源语言输入，在中间层进行推理，并在最终层翻译回源语言。

Result: LayRA在添加加利西亚语、斯瓦希利语和乌尔都语到预训练语言模型后，在各项多语言任务的评估中，能够最好地平衡保留模型在先前支持的语言上的能力，并与现有方法（如LoRA）在新语言学习方面具有竞争力。此外，通过模型算术，无需目标语言的指令调优数据，即可使适配后的模型具备强大的指令遵循能力。

Conclusion: LayRA是一种有效的方法，可以在不丢失原有能力的情况下，为多语言模型添加新语言，并能通过模型算术赋予其指令遵循能力。

Abstract: Multilingual language models are trained on a fixed set of languages, and to
support new languages, the models need to be retrained from scratch. This is an
expensive endeavor and is often infeasible, as model developers tend not to
release their pre-training data. Naive approaches, such as continued
pretraining, suffer from catastrophic forgetting; however, mitigation
strategies like experience replay cannot be applied due to the lack of original
pretraining data. In this work, we investigate the problem of continually
adding new languages to a multilingual model, assuming access to pretraining
data in only the target languages. We explore multiple approaches to address
this problem and propose Layer-Selective LoRA (LayRA), which adds Low-Rank
Adapters (LoRA) to selected initial and final layers while keeping the rest of
the model frozen. LayRA builds on two insights: (1) LoRA reduces forgetting,
and (2) multilingual models encode inputs in the source language in the initial
layers, reason in English in intermediate layers, and translate back to the
source language in final layers. We experiment with adding multiple
combinations of Galician, Swahili, and Urdu to pretrained language models and
evaluate each method on diverse multilingual tasks. We find that LayRA provides
the overall best tradeoff between preserving models' capabilities in previously
supported languages, while being competitive with existing approaches such as
LoRA in learning new languages. We also demonstrate that using model
arithmetic, the adapted models can be equipped with strong instruction
following abilities without access to any instruction tuning data in the target
languages.

</details>


### [187] [CEMTM: Contextual Embedding-based Multimodal Topic Modeling](https://arxiv.org/abs/2509.11465)
*Amirhossein Abaskohi,Raymond Li,Chuyuan Li,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: CEMTM是一个上下文增强的多模态主题模型，可以从包含文本和图像的文档中推断出连贯且可解释的主题结构。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态主题模型在处理短文本和长文档方面存在局限性，尤其是在整合文本和图像信息以推断主题方面。CEMTM旨在通过结合上下文增强的嵌入和新颖的注意力机制来解决这些问题。

Method: CEMTM利用微调后的大型视觉语言模型（LVLMs）获取上下文嵌入，并采用分布注意力机制来加权令牌对主题推断的贡献。它还包括一个重建目标，将基于主题的表示与文档嵌入对齐，以确保跨模态的语义一致性。CEMTM能够一次处理多个图像，而无需重复编码。

Result: CEMTM在六个多模态基准上的大量实验表明，其性能持续优于单模态和多模态基线模型，平均LLM得分为2.61。此外，CEMTM在下游的少样本检索任务中表现出色，并能有效捕捉科学文章等复杂领域中的视觉语义。

Conclusion: CEMTM是一种有效且可解释的多模态主题模型，能够处理包含文本和图像的多种文档。它通过结合上下文嵌入、分布注意力机制和重建目标，在主题推断方面取得了最先进的性能，并在下游任务中显示出其潜力。

Abstract: We introduce CEMTM, a context-enhanced multimodal topic model designed to
infer coherent and interpretable topic structures from both short and long
documents containing text and images. CEMTM builds on fine-tuned large vision
language models (LVLMs) to obtain contextualized embeddings, and employs a
distributional attention mechanism to weight token-level contributions to topic
inference. A reconstruction objective aligns topic-based representations with
the document embedding, encouraging semantic consistency across modalities.
Unlike existing approaches, CEMTM can process multiple images per document
without repeated encoding and maintains interpretability through explicit
word-topic and document-topic distributions. Extensive experiments on six
multimodal benchmarks show that CEMTM consistently outperforms unimodal and
multimodal baselines, achieving a remarkable average LLM score of 2.61. Further
analysis shows its effectiveness in downstream few-shot retrieval and its
ability to capture visually grounded semantics in complex domains such as
scientific articles.

</details>


### [188] [Improving LLMs' Learning for Coreference Resolution](https://arxiv.org/abs/2509.11466)
*Yujian Gan,Yuan Liang,Yanni Lin,Juntao Yu,Massimo Poesio*

Main category: cs.CL

TL;DR: LLM在指代消解任务上存在幻觉和性能不足的问题。本文提出了反向训练和迭代文档生成两种新方法，解决了上述问题，并提高了指代消占的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型（LLM）的指代消解（CR）方法存在幻觉和性能不足的问题。

Method: 研究了现有的基于LLM的CR方法（问答模板和文档模板）的局限性，并提出了反向训练与联合推理和迭代文档生成这两种新技术。

Result: 反向训练改进了问答模板方法，而迭代文档生成消除了生成源文本中的幻觉并提高了指代消解的性能。

Conclusion: 整合这些方法和技术为基于LLM的指代消解提供了一个有效且鲁棒的解决方案。

Abstract: Coreference Resolution (CR) is crucial for many NLP tasks, but existing LLMs
struggle with hallucination and under-performance. In this paper, we
investigate the limitations of existing LLM-based approaches to CR-specifically
the Question-Answering (QA) Template and Document Template methods and propose
two novel techniques: Reversed Training with Joint Inference and Iterative
Document Generation. Our experiments show that Reversed Training improves the
QA Template method, while Iterative Document Generation eliminates
hallucinations in the generated source text and boosts coreference resolution.
Integrating these methods and techniques offers an effective and robust
solution to LLM-based coreference resolution.

</details>


### [189] [ClaimIQ at CheckThat! 2025: Comparing Prompted and Fine-Tuned Language Models for Verifying Numerical Claims](https://arxiv.org/abs/2509.11492)
*Anirban Saha Anik,Md Fahimul Kabir Chowdhury,Andrew Wyckoff,Sagnik Ray Choudhury*

Main category: cs.CL

TL;DR: LLM在CLEF 2025 CheckThat! 任务中用于验证数值和时间声明，通过零样本提示和LoRA微调，并探索了不同的证据选择策略，LLaMA-LoRA模型在英文验证集上表现良好，但在测试集上遇到泛化挑战。


<details>
  <summary>Details</summary>
Motivation: 验证数值和时间声明，评估LLM在事实核查中的应用，并探索提高证据质量的方法。

Method: 采用零样本提示和参数高效的LoRA微调两种方法，并结合了文档输入和基于BM25/MiniLM的句子过滤等证据选择策略。

Result: LLaMA-LoRA模型在英文验证集上取得了优异成绩，但在测试集上性能有所下降，表明存在泛化问题。

Conclusion: 证据的粒度对模型性能至关重要，并且需要针对鲁棒的数值事实核查进行模型适应。

Abstract: This paper presents our system for Task 3 of the CLEF 2025 CheckThat! Lab,
which focuses on verifying numerical and temporal claims using retrieved
evidence. We explore two complementary approaches: zero-shot prompting with
instruction-tuned large language models (LLMs) and supervised fine-tuning using
parameter-efficient LoRA. To enhance evidence quality, we investigate several
selection strategies, including full-document input and top-k sentence
filtering using BM25 and MiniLM. Our best-performing model LLaMA fine-tuned
with LoRA achieves strong performance on the English validation set. However, a
notable drop in the test set highlights a generalization challenge. These
findings underscore the importance of evidence granularity and model adaptation
for robust numerical fact verification.

</details>


### [190] [AKCIT-FN at CheckThat! 2025: Switching Fine-Tuned SLMs and LLM Prompting for Multilingual Claim Normalization](https://arxiv.org/abs/2509.11496)
*Fabrycio Leite Nakano Almada,Kauan Divino Pouso Mariano,Maykon Adriell Dutra,Victor Emanuel da Silva Monteiro,Juliana Resplande Sant'Anna Gomes,Arlindo Rodrigues Galvão Filho,Anderson da Silva Soares*

Main category: cs.CL

TL;DR: 该论文提出了一种结合小语言模型（SLM）和大型语言模型（LLM）的方法来处理社交媒体声明的归一化问题，该问题是自动化事实核查的关键步骤。研究人员针对20种语言（包括13种监督学习和7种零样本语言）进行了实验，并在15种语言中取得了前三名的成绩，其中8种语言获得第二名，包括5种零样本语言，证明了LLM在零样本场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动化事实核查需要将非正式的社交媒体帖子转化为简洁、独立的事实陈述，即声明归一化。

Method: 对于监督语言，使用微调的小语言模型（SLM）；对于零样本语言，使用大型语言模型（LLM）的提示。

Result: 在20种语言中的15种语言中获得前三名，包括8种语言的第二名（其中5种是零样本语言）。在葡萄牙语上，平均METEOR得分为0.5290，排名第三。

Conclusion: 所提出的结合SLM和LLM的声明归一化方法在多语言环境中，尤其是在零样本场景下，表现出色。

Abstract: Claim normalization, the transformation of informal social media posts into
concise, self-contained statements, is a crucial step in automated
fact-checking pipelines. This paper details our submission to the CLEF-2025
CheckThat! Task~2, which challenges systems to perform claim normalization
across twenty languages, divided into thirteen supervised (high-resource) and
seven zero-shot (no training data) tracks.
  Our approach, leveraging fine-tuned Small Language Models (SLMs) for
supervised languages and Large Language Model (LLM) prompting for zero-shot
scenarios, achieved podium positions (top three) in fifteen of the twenty
languages. Notably, this included second-place rankings in eight languages,
five of which were among the seven designated zero-shot languages, underscoring
the effectiveness of our LLM-based zero-shot strategy. For Portuguese, our
initial development language, our system achieved an average METEOR score of
0.5290, ranking third. All implementation artifacts, including inference,
training, evaluation scripts, and prompt configurations, are publicly available
at https://github.com/ju-resplande/checkthat2025_normalization.

</details>


### [191] [DeDisCo at the DISRPT 2025 Shared Task: A System for Discourse Relation Classification](https://arxiv.org/abs/2509.11498)
*Zhuoxuan Ju,Jingni Wu,Abhishek Purushothama,Amir Zeldes*

Main category: cs.CL

TL;DR: DeDisCo系统在DISRPT 2025 discourse relation classification任务中，采用了基于mt5的编码器和基于Qwen的解码器两种方法，并对低资源语言的增强数据集和额外的语言特征进行了实验，最终取得了71.28的宏准确率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索在discourse relation classification任务中，使用不同的模型架构（如mt5编码器和Qwen解码器）以及数据增强和语言特征对低资源语言性能的影响。

Method: 本研究测试了两种方法：1. 基于mt5的编码器；2. 基于Qwen模型的解码器。同时，实验了利用从英语自动翻译过来的匹配数据来增强低资源语言的训练集，并引入了受往届共享任务启发的额外语言特征。

Result: 本系统在DISRPT 2025共享任务上达到了71.28的宏准确率。

Conclusion: DeDisCo系统在discourse relation classification任务中取得了具有竞争力的结果，并对模型性能进行了分析，为未来低资源语言下的关系分类研究提供了参考。

Abstract: This paper presents DeDisCo, Georgetown University's entry in the DISRPT 2025
shared task on discourse relation classification. We test two approaches, using
an mt5-based encoder and a decoder based approach using the openly available
Qwen model. We also experiment on training with augmented dataset for
low-resource languages using matched data translated automatically from
English, as well as using some additional linguistic features inspired by
entries in previous editions of the Shared Task. Our system achieves a
macro-accuracy score of 71.28, and we provide some interpretation and error
analysis for our results.

</details>


### [192] [Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence Semantics](https://arxiv.org/abs/2509.11513)
*Zhongyang Hu,Naijie Gu,Xiangzhi Tao,Tianhui Gu,Yibing Zhou*

Main category: cs.CL

TL;DR: 对词汇替代任务中的候选词排序问题，提出了一种新的基于注意力权重和集成梯度的方法，通过衡量上下文对目标词的影响来改进排序性能。


<details>
  <summary>Details</summary>
Motivation: 现有的词汇替代方法在建模候选词替换对目标词及其上下文的双向影响方面存在挑战，并且难以准确刻画语义变化。

Method: 提出两种方法：一种基于注意力权重，另一种利用集成梯度方法，来衡量上下文词元对目标词元的影响，并通过结合原始句子和替代句子的语义相似性对候选词进行排序。

Result: 在LS07和SWORDS数据集上的实验表明，这两种方法都提高了候选词的排名性能。

Conclusion: 基于注意力权重和集成梯度的方法能够有效提升词汇替代任务中的候选词排名性能。

Abstract: A key subtask in lexical substitution is ranking the given candidate words. A
common approach is to replace the target word with a candidate in the original
sentence and feed the modified sentence into a model to capture semantic
differences before and after substitution. However, effectively modeling the
bidirectional influence of candidate substitution on both the target word and
its context remains challenging. Existing methods often focus solely on
semantic changes at the target position or rely on parameter tuning over
multiple evaluation metrics, making it difficult to accurately characterize
semantic variation. To address this, we investigate two approaches: one based
on attention weights and another leveraging the more interpretable integrated
gradients method, both designed to measure the influence of context tokens on
the target token and to rank candidates by incorporating semantic similarity
between the original and substituted sentences. Experiments on the LS07 and
SWORDS datasets demonstrate that both approaches improve ranking performance.

</details>


### [193] [LVLMs are Bad at Overhearing Human Referential Communication](https://arxiv.org/abs/2509.11514)
*Zhengxiang Wang,Weiling Li,Panagiotis Kaliosis,Owen Rambow,Susan E. Brennan*

Main category: cs.CL

TL;DR: 大型语言模型在理解和生成对话中使用的指代表达方面仍有不足，尤其是在需要结合语言、视觉和会话交互的复杂场景中。


<details>
  <summary>Details</summary>
Motivation: 理解说话者在自发对话中如何协作创建和使用指代表达，对于让具身智能体在现实世界中执行任务至关重要，这需要整合语言、视觉和对话交互理解能力。

Method: 评估了七个最先进的大型视觉语言模型（LVLMs）在作为“窃听者”时，对人类对话者在协作对象匹配任务中自发对话语料库的理解能力。

Result: 研究发现，当前 LVLMs 在处理这类任务时仍面临挑战，并且在从同一对话者那里听到更多对话（在多轮中重复相同任务）时，它们的表现没有显示出持续的提高。

Conclusion: 尽管 LVLMs 在理解和生成指代表达方面取得了进展，但它们在需要整合语言、视觉和对话交互的复杂场景中仍有很大提升空间。

Abstract: During spontaneous conversations, speakers collaborate on novel referring
expressions, which they can then re-use in subsequent conversations.
Understanding such referring expressions is an important ability for an
embodied agent, so that it can carry out tasks in the real world. This requires
integrating and understanding language, vision, and conversational interaction.
We study the capabilities of seven state-of-the-art Large Vision Language
Models (LVLMs) as overhearers to a corpus of spontaneous conversations between
pairs of human discourse participants engaged in a collaborative
object-matching task. We find that such a task remains challenging for current
LVLMs and they all fail to show a consistent performance improvement as they
overhear more conversations from the same discourse participants repeating the
same task for multiple rounds. We release our corpus and code for
reproducibility and to facilitate future research.

</details>


### [194] [PeruMedQA: Benchmarking Large Language Models (LLMs) on Peruvian Medical Exams -- Dataset Construction and Evaluation](https://arxiv.org/abs/2509.11517)
*Rodrigo M. Carrillo-Larco,Jesus Lovón Melgarejo,Manuel Castillo-Cara,Gusseppe Bravo-Rocca*

Main category: cs.CL

TL;DR: 本研究旨在评估大型语言模型（LLM）在西班牙语和秘鲁医学考试问题上的表现，并提出优化方案。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在医学考试问答方面表现出色，但其在西班牙语和拉丁美洲国家的医学问题上的表现仍未得到充分研究，这对于LLM在拉丁美洲的推广至关重要。

Method: 研究人员创建了一个包含8380个问题的秘鲁医学考试数据集（PeruMedQA），涵盖12个医学领域。他们选择了8个LLM，并使用零样本学习提示进行测试。其中，medgemma-4b-it模型使用参数高效微调（PEFT）和低秩适配（LoRA）技术进行了微调，使用2018-2024年的数据进行训练，2025年的数据作为测试集。

Result: medgemma-27b-text-it模型表现最佳，准确率在某些情况下超过90%。参数量小于100亿的模型准确率低于60%，部分考试准确率低于50%。微调后的medgemma-4b-it模型在参数量小于100亿的模型中表现最佳，并且在多个考试中能与拥有700亿参数的模型相媲美。

Conclusion: 对于需要西班牙语国家医学知识库（特别是与秘鲁流行病学特征相似的国家）的医疗人工智能应用和研究，建议使用medgemma-27b-text-it模型，或者微调后的medgemma-4b-it模型。

Abstract: BACKGROUND: Medical large language models (LLMS) have demonstrated remarkable
performance in answering medical examinations. However, the extent to which
this high performance is transferable to medical questions in Spanish and from
a Latin American country remains unexplored. This knowledge is crucial as
LLM-based medical applications gain traction in Latin America. AIMS: to build a
dataset of questions from medical examinations taken by Peruvian physicians
pursuing specialty training; to fine-tune a LLM on this dataset; to evaluate
and compare the performance in terms of accuracy between vanilla LLMs and the
fine-tuned LLM. METHODS: We curated PeruMedQA, a multiple-choice
question-answering (MCQA) datasets containing 8,380 questions spanning 12
medical domains (2018-2025). We selected eight medical LLMs including
medgemma-4b-it and medgemma-27b-text-it, and developed zero-shot task-specific
prompts to answer the questions appropriately. We employed parameter-efficient
fine tuning (PEFT)and low-rant adaptation (LoRA) to fine-tune medgemma-4b-it
utilizing all questions except those from 2025 (test set). RESULTS:
medgemma-27b-text-it outperformed all other models, achieving a proportion of
correct answers exceeding 90% in several instances. LLMs with <10 billion
parameters exhibited <60% of correct answers, while some exams yielded results
<50%. The fine-tuned version of medgemma-4b-it emerged victorious agains all
LLMs with <10 billion parameters and rivaled a LLM with 70 billion parameters
across various examinations. CONCLUSIONS: For medical AI application and
research that require knowledge bases from Spanish-speaking countries and those
exhibiting similar epidemiological profiles to Peru's, interested parties
should utilize medgemma-27b-text-it or a fine-tuned version of medgemma-4b-it.

</details>


### [195] [On the Distinctive Co-occurrence Characteristics of Antonymy](https://arxiv.org/abs/2509.11534)
*Zhihan Cao,Hiroaki Yamada,Takenobu Tokunaga*

Main category: cs.CL

TL;DR: Antonymy pairs co-occur more often than other semantic relations, with specific characteristics like strong co-occurrence, preferred order, and short spans.


<details>
  <summary>Details</summary>
Motivation: The paper aims to clarify whether the frequent co-occurrence of antonym pairs is distinctive of antonymy by comparing it with other semantic relations, addressing a gap in previous research.

Method: The study compares antonymy with three other semantic relations across different parts of speech, employing robust co-occurrence metrics.

Result: Antonymy is found to be distinctive due to strong co-occurrence, a preferred linear order, and short spans between antonym pairs.

Conclusion: Antonymy exhibits unique co-occurrence patterns compared to other semantic relations.

Abstract: Antonymy has long received particular attention in lexical semantics.
Previous studies have shown that antonym pairs frequently co-occur in text,
across genres and parts of speech, more often than would be expected by chance.
However, whether this co-occurrence pattern is distinctive of antonymy remains
unclear, due to a lack of comparison with other semantic relations. This work
fills the gap by comparing antonymy with three other relations across parts of
speech using robust co-occurrence metrics. We find that antonymy is distinctive
in three respects: antonym pairs co-occur with high strength, in a preferred
linear order, and within short spans. All results are available online.

</details>


### [196] [A Dynamic Fusion Model for Consistent Crisis Response](https://arxiv.org/abs/2509.01053)
*Xiaoying Song,Anirban Saha Anik,Eduardo Blanco,Vanessa Frias-Martinez,Lingzi Hong*

Main category: cs.CL

TL;DR: 本研究提出了一种新的评估指标和基于融合的生成方法，以提高危机通信中自动响应的风格一致性，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在危机通信中，由语言模型驱动的自动化响应可能存在的风格不一致问题，而风格不一致会影响受灾个体对响应者的信任度。

Method: 提出了一种新颖的风格一致性评估指标，并在此指标基础上设计了一种基于融合的生成方法。该方法包括两个阶段：首先评估候选响应的风格，然后通过融合过程在实例级别进行优化和整合。

Result: 实验结果表明，在多个数据集上，该方法在响应质量和风格统一性方面均优于基线方法，能够有效生成高质量的响应并显著减少风格间的差异。

Conclusion: 本研究提出的风格一致性评估指标和基于融合的生成方法，能够有效提高危机通信中自动化响应的风格一致性，从而提升响应质量和受灾个体的信任度。

Abstract: In response to the urgent need for effective communication with
crisis-affected populations, automated responses driven by language models have
been proposed to assist in crisis communications. A critical yet often
overlooked factor is the consistency of response style, which could affect the
trust of affected individuals in responders. Despite its importance, few
studies have explored methods for maintaining stylistic consistency across
generated responses. To address this gap, we propose a novel metric for
evaluating style consistency and introduce a fusion-based generation approach
grounded in this metric. Our method employs a two-stage process: it first
assesses the style of candidate responses and then optimizes and integrates
them at the instance level through a fusion process. This enables the
generation of high-quality responses while significantly reducing stylistic
variation between instances. Experimental results across multiple datasets
demonstrate that our approach consistently outperforms baselines in both
response quality and stylistic uniformity.

</details>


### [197] [HARP: Hallucination Detection via Reasoning Subspace Projection](https://arxiv.org/abs/2509.11536)
*Junjie Hu,Gang Tu,ShengYu Cheng,Jinxin Li,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: HARP框架通过将LLM的隐藏状态分解为语义和推理子空间，并利用Unembedding层和SVD提取推理子空间特征，有效提高了幻觉检测的准确性和鲁棒性，在TriviaQA数据集上AUROC达到92.8%。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM幻觉检测方法在区分语义和推理信息以及保持鲁棒性方面存在挑战。

Method: 提出HARP框架，将LLM的隐藏状态空间分解为语义子空间和推理子空间，利用Unembedding层和SVD提取推理子空间基向量，并将隐藏状态投影到推理子空间以提取特征进行幻觉检测。

Result: HARP框架通过降维和特征提取，显著提高了幻觉检测的性能，在TriviaQA数据集上AUROC达到92.8%，超越现有最佳方法7.5%。

Conclusion: HARP框架是一种新颖有效的LLM幻觉检测方法，通过推理子空间投影提高了检测的准确性和鲁棒性。

Abstract: Hallucinations in Large Language Models (LLMs) pose a major barrier to their
reliable use in critical decision-making. Although existing hallucination
detection methods have improved accuracy, they still struggle with
disentangling semantic and reasoning information and maintaining robustness. To
address these challenges, we propose HARP (Hallucination detection via
reasoning subspace projection), a novel hallucination detection framework. HARP
establishes that the hidden state space of LLMs can be decomposed into a direct
sum of a semantic subspace and a reasoning subspace, where the former encodes
linguistic expression and the latter captures internal reasoning processes.
Moreover, we demonstrate that the Unembedding layer can disentangle these
subspaces, and by applying Singular Value Decomposition (SVD) to its
parameters, the basis vectors spanning the semantic and reasoning subspaces are
obtained. Finally, HARP projects hidden states onto the basis vectors of the
reasoning subspace, and the resulting projections are then used as input
features for hallucination detection in LLMs. By using these projections, HARP
reduces the dimension of the feature to approximately 5% of the original,
filters out most noise, and achieves enhanced robustness. Experiments across
multiple datasets show that HARP achieves state-of-the-art hallucination
detection performance; in particular, it achieves an AUROC of 92.8% on
TriviaQA, outperforming the previous best method by 7.5%.

</details>


### [198] [Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL](https://arxiv.org/abs/2509.01058)
*Xiaoying Song,Anirban Saha Anik,Dibakar Barua,Pengcheng Luo,Junhua Ding,Lingzi Hong*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Controlled-Literacy的框架，利用检索增强生成（RAG）和强化学习（RL）来生成适应不同健康素养水平的定制化反驳言论，以应对在线健康错误信息。


<details>
  <summary>Details</summary>
Motivation: 在线健康错误信息的传播对公众健康构成严重威胁，而现有的自动生成反驳言论的方法通常忽略了受众的健康素养水平对反驳言论的可及性和有效性的影响。

Method: 提出了一种名为Controlled-Literacy的框架，该框架结合了检索增强生成（RAG）和强化学习（RL）。该框架首先检索与特定健康素养水平相符的知识，以支持生成易于理解且事实准确的反驳言论。然后，设计了一个结合主观用户偏好和客观可读性指标的奖励函数，以优化反驳言论的生成，使其适应目标健康素养水平。

Result: 实验结果表明，与基线方法相比，Controlled-Literacy框架在生成更易于理解且用户更偏好的反驳言论方面表现更优。

Conclusion: 该研究通过提高反驳健康错误信息的可及性和理解性，为实现更公平和更有效的大众健康传播做出了贡献。

Abstract: Health misinformation spreading online poses a significant threat to public
health. Researchers have explored methods for automatically generating
counterspeech to health misinformation as a mitigation strategy. Existing
approaches often produce uniform responses, ignoring that the health literacy
level of the audience could affect the accessibility and effectiveness of
counterspeech. We propose a Controlled-Literacy framework using
retrieval-augmented generation (RAG) with reinforcement learning (RL) to
generate tailored counterspeech adapted to different health literacy levels. In
particular, we retrieve knowledge aligned with specific health literacy levels,
enabling accessible and factual information to support generation. We design a
reward function incorporating subjective user preferences and objective
readability-based rewards to optimize counterspeech to the target health
literacy level. Experiment results show that Controlled-Literacy outperforms
baselines by generating more accessible and user-preferred counterspeech. This
research contributes to more equitable and impactful public health
communication by improving the accessibility and comprehension of counterspeech
to health misinformation

</details>


### [199] [HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking](https://arxiv.org/abs/2509.11552)
*Wensheng Lu,Keyu Chen,Ruizhi Qiao,Xing Sun*

Main category: cs.CL

TL;DR: 该论文提出了一种评估文档分块的新方法HiCBench和一种新的文档分块框架HiChunk，以解决现有RAG评估工具的不足之处。


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估基准在评估文档分块质量方面存在不足，主要是因为证据稀疏。

Method: 提出HiCBench，包含多级文档分块点、合成的证据密集型问答对及其对应的证据源。提出HiChunk框架，基于微调的LLM进行多级文档结构化，并结合Auto-Merge检索算法。

Result: HiCBench能有效评估不同分块方法在整个RAG流程中的影响。HiChunk在合理的时间内实现了更好的分块质量，提升了RAG系统的整体性能。

Conclusion: HiCBench和HiChunk的提出为评估和改进RAG系统中的文档分块提供了有效的方法。

Abstract: Retrieval-Augmented Generation (RAG) enhances the response capabilities of
language models by integrating external knowledge sources. However, document
chunking as an important part of RAG system often lacks effective evaluation
tools. This paper first analyzes why existing RAG evaluation benchmarks are
inadequate for assessing document chunking quality, specifically due to
evidence sparsity. Based on this conclusion, we propose HiCBench, which
includes manually annotated multi-level document chunking points, synthesized
evidence-dense quetion answer(QA) pairs, and their corresponding evidence
sources. Additionally, we introduce the HiChunk framework, a multi-level
document structuring framework based on fine-tuned LLMs, combined with the
Auto-Merge retrieval algorithm to improve retrieval quality. Experiments
demonstrate that HiCBench effectively evaluates the impact of different
chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves
better chunking quality within reasonable time consumption, thereby enhancing
the overall performance of RAG systems.

</details>


### [200] [D$^2$HScore: Reasoning-Aware Hallucination Detection via Semantic Breadth and Depth Analysis in LLMs](https://arxiv.org/abs/2509.11569)
*Yue Ding,Xiaofang Zhu,Tianze Xia,Junfei Wu,Xinlong Chen,Qiang Liu,Liang Wang*

Main category: cs.CL

TL;DR: LLMs 经常产生不符合事实的内容（称为“幻觉”），这阻碍了它们的实际应用。本文提出了一种名为 D^2HScore 的新框架，通过分析模型内部的语义分散和跨层语义漂移来检测幻觉。D^2HScore 是一种无需训练、无需标签的方法，它量化了每个层的语义多样性和跨层核心概念的演变。通过结合注意力信号来指导代币选择，该方法可以捕捉表示的水平和垂直动态。实验证明 D^2HScore 在五个开源 LLM 和五个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLM）输出的可靠性，尤其是在金融、安全和医疗保健等高风险领域，因为它们经常产生不符合事实的内容（幻觉）。

Method: 提出了一种名为 D^2HScore 的训练和标签无关的框架，该框架通过分析 LLM 的多层结构和自回归解码过程来检测幻觉。它通过两个维度来量化幻觉信号：1）层内分散（量化各层内标记表示的语义多样性）；2）层间漂移（跟踪关键标记表示跨层演变的渐进变换）。为了确保漂移反映有意义的语义而不是噪声或冗余标记的演变，使用注意力信号来指导标记选择。

Result: D^2HScore 在五个开源 LLM 和五个广泛使用的基准测试中，在检测幻觉方面持续优于现有的训练和标签无关的基线方法。

Conclusion: D^2HScore 通过捕捉推理过程中表示的水平和垂直动态，为幻觉检测提供了一种可解释且轻量级的代理。

Abstract: Although large Language Models (LLMs) have achieved remarkable success, their
practical application is often hindered by the generation of non-factual
content, which is called "hallucination". Ensuring the reliability of LLMs'
outputs is a critical challenge, particularly in high-stakes domains such as
finance, security, and healthcare. In this work, we revisit hallucination
detection from the perspective of model architecture and generation dynamics.
Leveraging the multi-layer structure and autoregressive decoding process of
LLMs, we decompose hallucination signals into two complementary dimensions: the
semantic breadth of token representations within each layer, and the semantic
depth of core concepts as they evolve across layers. Based on this insight, we
propose \textbf{D$^2$HScore (Dispersion and Drift-based Hallucination Score)},
a training-free and label-free framework that jointly measures: (1)
\textbf{Intra-Layer Dispersion}, which quantifies the semantic diversity of
token representations within each layer; and (2) \textbf{Inter-Layer Drift},
which tracks the progressive transformation of key token representations across
layers. To ensure drift reflects the evolution of meaningful semantics rather
than noisy or redundant tokens, we guide token selection using attention
signals. By capturing both the horizontal and vertical dynamics of
representation during inference, D$^2$HScore provides an interpretable and
lightweight proxy for hallucination detection. Extensive experiments across
five open-source LLMs and five widely used benchmarks demonstrate that
D$^2$HScore consistently outperforms existing training-free baselines.

</details>


### [201] [Bhaasha, Bhasa, Zaban: A Survey for Low-Resourced Languages in South Asia -- Current Stage and Challenges](https://arxiv.org/abs/2509.11570)
*Sampoorna Poria,Xiaolei Huang*

Main category: cs.CL

TL;DR: 大型语言模型在南亚语言处理方面存在数据稀缺、代码混合和缺乏标准化评估基准等挑战。


<details>
  <summary>Details</summary>
Motivation: 目前针对南亚低资源语言的大型语言模型研究和评估被忽视，需要明确现状和挑战以促进模型发展。

Method: 本调查检索了自2020年以来关于南亚语言自然语言处理（NLP）的研究，重点关注Transformer类模型（如BERT、T5和GPT），并从数据、模型和任务三个方面进行了分析。

Result: 研究发现，南亚语言在关键领域（如健康）的数据缺失、代码混合现象以及缺乏标准化评估基准是主要问题。

Conclusion: 为了促进南亚语言NLP模型的发展，需要提高社区对这些问题的认识，进行更有针对性的数据收集，建立符合南亚文化和语言特点的统一基准，并鼓励对南亚语言的公平表征。

Abstract: Rapid developments of large language models have revolutionized many NLP
tasks for English data. Unfortunately, the models and their evaluations for
low-resource languages are being overlooked, especially for languages in South
Asia. Although there are more than 650 languages in South Asia, many of them
either have very limited computational resources or are missing from existing
language models. Thus, a concrete question to be answered is: Can we assess the
current stage and challenges to inform our NLP community and facilitate model
developments for South Asian languages? In this survey, we have comprehensively
examined current efforts and challenges of NLP models for South Asian languages
by retrieving studies since 2020, with a focus on transformer-based models,
such as BERT, T5, & GPT. We present advances and gaps across 3 essential
aspects: data, models, & tasks, such as available data sources, fine-tuning
strategies, & domain applications. Our findings highlight substantial issues,
including missing data in critical domains (e.g., health), code-mixing, and
lack of standardized evaluation benchmarks. Our survey aims to raise awareness
within the NLP community for more targeted data curation, unify benchmarks
tailored to cultural and linguistic nuances of South Asia, and encourage an
equitable representation of South Asian languages. The complete list of
resources is available at: https://github.com/trust-nlp/LM4SouthAsia-Survey.

</details>


### [202] [Analyzing Information-Seeking Behaviors in a Hakka AI Chatbot: A Cognitive-Pragmatic Study](https://arxiv.org/abs/2509.11591)
*Chu-Hsuan Lee,Chen-Chi Chang,Hung-Shin Lee,Yun-Hsiang Hsu,Ching-Yuan Chen*

Main category: cs.CL

TL;DR: 本研究使用认知过程的布鲁姆分类法和对话行为分类的双层分析框架，通过分析7077条用户输入，研究了TALKA（一个生成式AI驱动的客家语聊天机器人）的用户行为。结果表明，生成式AI聊天机器人能够有意义地支持语言学习，并可能帮助学习者更自信地表达自己并与文化身份建立联系。TALKA的案例为AI驱动的对话如何促进资源匮乏语言学习者的认知发展、语用协商和文化认同提供了实证见解。


<details>
  <summary>Details</summary>
Motivation: 随着许多濒危语言面临消失的风险，保护它们的努力比以往任何时候都更加依赖于技术和文化适应性强的教学策略。本研究旨在检验TALKA（一个生成式AI驱动的客家语聊天机器人）的用户行为，以了解AI在语言保护和教育实践中的作用。

Method: 本研究采用基于认知过程的布鲁姆分类法和对话行为分类的双层分析框架，对TALKA的7077条用户输入进行了分析和标注，并对认知水平和对话行为类型进行了分类。

Result: 分析结果表明，生成式AI聊天机器人能够有意义地支持语言学习，尤其是在设计上考虑到用户的思维和沟通方式时。此外，这些聊天机器人可能有助于学习者更自信地表达自己，并与他们的文化身份建立联系。

Conclusion: TALKA的案例提供了关于AI驱动的对话如何促进资源匮乏语言学习者的认知发展、语用协商和文化认同的实证见解。本研究为技术如何支持语言保护和教育实践提供了新的见解。

Abstract: With many endangered languages at risk of disappearing, efforts to preserve
them now rely more than ever on using technology alongside culturally informed
teaching strategies. This study examines user behaviors in TALKA, a generative
AI-powered chatbot designed for Hakka language engagement, by employing a
dual-layered analytical framework grounded in Bloom's Taxonomy of cognitive
processes and dialogue act categorization. We analyzed 7,077 user utterances,
each carefully annotated according to six cognitive levels and eleven dialogue
act types. These included a variety of functions, such as asking for
information, requesting translations, making cultural inquiries, and using
language creatively. Pragmatic classifications further highlight how different
types of dialogue acts--such as feedback, control commands, and social
greetings--align with specific cognitive intentions. The results suggest that
generative AI chatbots can support language learning in meaningful
ways--especially when they are designed with an understanding of how users
think and communicate. They may also help learners express themselves more
confidently and connect with their cultural identity. The TALKA case provides
empirical insights into how AI-mediated dialogue facilitates cognitive
development in low-resource language learners, as well as pragmatic negotiation
and socio-cultural affiliation. By focusing on AI-assisted language learning,
this study offers new insights into how technology can support language
preservation and educational practice.

</details>


### [203] [Dynamic Span Interaction and Graph-Aware Memory for Entity-Level Sentiment Classification](https://arxiv.org/abs/2509.11604)
*Md. Mithun Hossain,Sanjara,Md. Shakil Hossain,Sudipto Chaki*

Main category: cs.CL

TL;DR: SpanEIT是一个新框架，通过集成动态跨度交互和图感知记忆机制来改进实体级情感分类，解决了传统方法中的细微交互、跨句依赖和指代消解等挑战，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有实体级情感分类方法在处理细微交互、跨句依赖、指代消解以及否定、歧义、重叠观点等语言现象时面临挑战，尤其是在真实、嘈杂的文本数据中。

Method: 提出SpanEIT框架，该框架集成了动态跨度交互和图感知记忆机制。具体包括：1.构建实体和候选情感短语的跨度表示；2.使用双向注意力进行细粒度交互；3.利用图注意力网络捕捉句法和共现关系；4.引入指代消解感知记忆模块确保实体级一致性。

Result: 在FSAD、BARU和IMDB数据集上的实验表明，SpanEIT在准确率和F1分数上优于最先进的Transformer和混合基线模型。消融分析和可解释性分析验证了该方法的有效性。

Conclusion: SpanEIT通过结合动态跨度交互和图感知记忆机制，有效解决了实体级情感分类中的复杂性问题，并在多个数据集上取得了优越性能，证明了其在社交媒体监控和客户反馈分析等细粒度情感分析应用中的潜力。

Abstract: Entity-level sentiment classification involves identifying the sentiment
polarity linked to specific entities within text. This task poses several
challenges: effectively modeling the subtle and complex interactions between
entities and their surrounding sentiment expressions; capturing dependencies
that may span across sentences; and ensuring consistent sentiment predictions
for multiple mentions of the same entity through coreference resolution.
Additionally, linguistic phenomena such as negation, ambiguity, and overlapping
opinions further complicate the analysis. These complexities make entity-level
sentiment classification a difficult problem, especially in real-world, noisy
textual data. To address these issues, we propose SpanEIT, a novel framework
integrating dynamic span interaction and graph-aware memory mechanisms for
enhanced entity-sentiment relational modeling. SpanEIT builds span-based
representations for entities and candidate sentiment phrases, employs
bidirectional attention for fine-grained interactions, and uses a graph
attention network to capture syntactic and co-occurrence relations. A
coreference-aware memory module ensures entity-level consistency across
documents. Experiments on FSAD, BARU, and IMDB datasets show SpanEIT
outperforms state-of-the-art transformer and hybrid baselines in accuracy and
F1 scores. Ablation and interpretability analyses validate the effectiveness of
our approach, underscoring its potential for fine-grained sentiment analysis in
applications like social media monitoring and customer feedback analysis.

</details>


### [204] [HalluDetect: Detecting, Mitigating, and Benchmarking Hallucinations in Conversational Systems](https://arxiv.org/abs/2509.11619)
*Spandan Anaokar,Shrey Ganatra,Harshvivek Kashid,Swapnil Bhattacharyya,Shruti Nair,Reshma Sekhar,Siddharth Manohar,Rahul Hemrajani,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: LLM驱动的客服机器人容易出现幻觉，影响其在关键领域的可靠性。本研究提出了一种基于LLM的幻觉检测系统HalluDetect，用于减少基于LLaMA 3.1 8B Instruct的客服机器人中的幻觉。在五种聊天机器人架构的基准测试中，AgentBot在将幻觉减少到每轮0.4159次的同时，保持了最高的令牌准确率（96.13%），是目前最有效的缓解策略。


<details>
  <summary>Details</summary>
Motivation: LLM在工业界被广泛使用，但其幻觉问题限制了它们在关键应用中的可靠性。本研究旨在解决在工业界常用的紧凑型模型LLaMA 3.1 8B Instruct构建的客服机器人中出现的幻觉问题。

Method: 开发了一个名为HalluDetect的基于LLM的幻觉检测系统，并对五种聊天机器人架构进行了基准测试，以评估它们在减少幻觉和保持令牌准确性方面的效果。

Result: HalluDetect系统的F1分数为69%，比基线检测器高出25.44%。在测试的五种聊天机器人架构中，AgentBot每轮幻觉次数最少（0.4159次），同时保持了最高的令牌准确率（96.13%）。

Conclusion: 优化的推理策略可以显著提高LLM的事实准确性。本研究提出的框架具有可扩展性，可以应用于消费者法律领域，并推广到其他高风险领域，以增强对LLM驱动助手的信任。研究将发布代码和数据集。

Abstract: Large Language Models (LLMs) are widely used in industry but remain prone to
hallucinations, limiting their reliability in critical applications. This work
addresses hallucination reduction in consumer grievance chatbots built using
LLaMA 3.1 8B Instruct, a compact model frequently used in industry. We develop
HalluDetect, an LLM-based hallucination detection system that achieves an F1
score of 69% outperforming baseline detectors by 25.44%. Benchmarking five
chatbot architectures, we find that out of them, AgentBot minimizes
hallucinations to 0.4159 per turn while maintaining the highest token accuracy
(96.13%), making it the most effective mitigation strategy. Our findings
provide a scalable framework for hallucination mitigation, demonstrating that
optimized inference strategies can significantly improve factual accuracy.
While applied to consumer law, our approach generalizes to other high-risk
domains, enhancing trust in LLM-driven assistants. We will release the code and
dataset

</details>


### [205] [AesBiasBench: Evaluating Bias and Alignment in Multimodal Language Models for Personalized Image Aesthetic Assessment](https://arxiv.org/abs/2509.11620)
*Kun Li,Lai-Man Po,Hongzheng Yang,Xuyuan Xu,Kangcheng Liu,Yuzhi Zhao*

Main category: cs.CL

TL;DR: 该研究提出了AesBiasBench基准，用于评估多模态大语言模型（MLLMs）在个性化图像美学评估（PIAA）中的刻板印象偏见和与人类偏好的对齐程度，并评估了19种MLLMs。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在个性化图像美学评估中可能存在性别、年龄和教育等人口统计因素的微妙偏见，因此需要一个基准来评估这种偏见。

Method: 构建了一个包含美学感知、评估和共情三个子任务的AesBiasBench基准，并引入IFD、NRD和AAS等结构化指标来评估偏见和对齐程度。对19种MLLMs进行了评估。

Result: 结果显示，较小的模型表现出更强的刻板印象偏见，而较大的模型则更符合人类偏好。加入身份信息往往会加剧偏见，尤其是在情感判断方面。

Conclusion: 在主观的视觉-语言任务中，进行区分身份的评估框架至关重要，以确保模型的公平性和准确性。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly applied in
Personalized Image Aesthetic Assessment (PIAA) as a scalable alternative to
expert evaluations. However, their predictions may reflect subtle biases
influenced by demographic factors such as gender, age, and education. In this
work, we propose AesBiasBench, a benchmark designed to evaluate MLLMs along two
complementary dimensions: (1) stereotype bias, quantified by measuring
variations in aesthetic evaluations across demographic groups; and (2)
alignment between model outputs and genuine human aesthetic preferences. Our
benchmark covers three subtasks (Aesthetic Perception, Assessment, Empathy) and
introduces structured metrics (IFD, NRD, AAS) to assess both bias and
alignment. We evaluate 19 MLLMs, including proprietary models (e.g., GPT-4o,
Claude-3.5-Sonnet) and open-source models (e.g., InternVL-2.5, Qwen2.5-VL).
Results indicate that smaller models exhibit stronger stereotype biases,
whereas larger models align more closely with human preferences. Incorporating
identity information often exacerbates bias, particularly in emotional
judgments. These findings underscore the importance of identity-aware
evaluation frameworks in subjective vision-language tasks.

</details>


### [206] [EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI](https://arxiv.org/abs/2509.11648)
*Sai Kartheek Reddy Kasu*

Main category: cs.CL

TL;DR: 提出了一个包含125个场景的伦理推理心理健康（EthicsMH）数据集，用于评估AI在心理健康领域的伦理决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有伦理和临床决策基准无法充分解决心理健康实践中的独特伦理困境，如保密性、自主性、有利性以及偏见等交叉问题。

Method: 创建了一个包含125个场景的EthicsMH数据集，每个场景都包含多个决策选项、专家推理、模型预期行为、实际影响和多方观点。

Result: EthicsMH数据集能够评估AI在心理健康领域决策的准确性、解释质量以及与专业规范的对齐程度。

Conclusion: EthicsMH数据集为AI伦理与心理健康决策之间架起了一座桥梁，旨在成为一个可扩展的资源，以促进能够负责任处理敏感决策的AI系统的发展。

Abstract: The deployment of large language models (LLMs) in mental health and other
sensitive domains raises urgent questions about ethical reasoning, fairness,
and responsible alignment. Yet, existing benchmarks for moral and clinical
decision-making do not adequately capture the unique ethical dilemmas
encountered in mental health practice, where confidentiality, autonomy,
beneficence, and bias frequently intersect. To address this gap, we introduce
Ethical Reasoning in Mental Health (EthicsMH), a pilot dataset of 125 scenarios
designed to evaluate how AI systems navigate ethically charged situations in
therapeutic and psychiatric contexts. Each scenario is enriched with structured
fields, including multiple decision options, expert-aligned reasoning, expected
model behavior, real-world impact, and multi-stakeholder viewpoints. This
structure enables evaluation not only of decision accuracy but also of
explanation quality and alignment with professional norms. Although modest in
scale and developed with model-assisted generation, EthicsMH establishes a task
framework that bridges AI ethics and mental health decision-making. By
releasing this dataset, we aim to provide a seed resource that can be expanded
through community and expert contributions, fostering the development of AI
systems capable of responsibly handling some of society's most delicate
decisions.

</details>


### [207] [A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection](https://arxiv.org/abs/2509.11687)
*Di Jin,Jun Yang,Xiaobao Wang,Junwei Zhang,Shuqi Li,Dongxiao He*

Main category: cs.CL

TL;DR: DYNAMO模型利用知识图谱和大型语言模型动态更新知识，以提高虚假新闻检测的准确性，并能验证新知识的正确性。


<details>
  <summary>Details</summary>
Motivation: 区分可信新闻和海量复杂信息面临巨大挑战，且新闻真实性标签可能随事件发展而变化，需要获取最新事件更新。

Method: 构建新闻领域知识图谱，利用蒙特卡洛树搜索分解新闻并逐步验证，从验证后的真实新闻文本和推理路径中提取并更新新知识。

Result: DYNAMO模型在两个真实世界数据集上取得了最佳性能。

Conclusion: DYNAMO模型成功解决了新知识的真实性和深度挖掘新闻语义的关键问题，提高了虚假新闻检测效果。

Abstract: As the Internet and social media evolve rapidly, distinguishing credible news
from a vast amount of complex information poses a significant challenge. Due to
the suddenness and instability of news events, the authenticity labels of news
can potentially shift as events develop, making it crucial for fake news
detection to obtain the latest event updates. Existing methods employ
retrieval-augmented generation to fill knowledge gaps, but they suffer from
issues such as insufficient credibility of retrieved content and interference
from noisy information. We propose a dynamic knowledge update-driven model for
fake news detection (DYNAMO), which leverages knowledge graphs to achieve
continuous updating of new knowledge and integrates with large language models
to fulfill dual functions: news authenticity detection and verification of new
knowledge correctness, solving the two key problems of ensuring the
authenticity of new knowledge and deeply mining news semantics. Specifically,
we first construct a news-domain-specific knowledge graph. Then, we use Monte
Carlo Tree Search to decompose complex news and verify them step by step.
Finally, we extract and update new knowledge from verified real news texts and
reasoning paths. Experimental results demonstrate that DYNAMO achieves the best
performance on two real-world datasets.

</details>


### [208] [CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model](https://arxiv.org/abs/2509.11698)
*Wei-Hsin Yeh,Yu-An Su,Chih-Ning Chen,Yi-Hsueh Lin,Calvin Ku,Wen-Hsin Chiu,Min-Chun Hu,Lun-Wei Ku*

Main category: cs.CL

TL;DR: CoachMe是一个参考模型，通过分析学习者动作与参考动作在时间与物理方面的差异，能够生成高质量的、运动专项的指导，并且优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 运动专项的动作指导生成具有挑战性，因为其领域特性强且需要提供信息性指导。现有模型在生成精确、运动专项的指导方面存在不足。

Method: CoachMe是一个参考模型，通过分析学习者动作与参考动作在时间与物理方面的差异，使模型能够学习领域知识并获得类似教练的思考过程，从而有效识别动作错误并提供改进反馈。

Result: CoachMe能够很好地适应滑冰和拳击等特定运动，通过从通用动作中学习然后利用有限数据进行微调。实验表明，CoachMe生成的指导具有高质量，并且在花样滑冰和拳击方面，其G-Eval得分分别优于GPT-4o 31.6%和58.3%。

Conclusion: CoachMe能够生成高质量的运动专项指导，能够阐述错误及其对应的改进方法，并且在特定运动上表现优于现有模型。

Abstract: Motion instruction is a crucial task that helps athletes refine their
technique by analyzing movements and providing corrective guidance. Although
recent advances in multimodal models have improved motion understanding,
generating precise and sport-specific instruction remains challenging due to
the highly domain-specific nature of sports and the need for informative
guidance. We propose CoachMe, a reference-based model that analyzes the
differences between a learner's motion and a reference under temporal and
physical aspects. This approach enables both domain-knowledge learning and the
acquisition of a coach-like thinking process that identifies movement errors
effectively and provides feedback to explain how to improve. In this paper, we
illustrate how CoachMe adapts well to specific sports such as skating and
boxing by learning from general movements and then leveraging limited data.
Experiments show that CoachMe provides high-quality instructions instead of
directions merely in the tone of a coach but without critical information.
CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and by 58.3% on
boxing. Analysis further confirms that it elaborates on errors and their
corresponding improvement methods in the generated instructions. You can find
CoachMe here: https://motionxperts.github.io/

</details>


### [209] [Room acoustics affect communicative success in hybrid meeting spaces: a pilot study](https://arxiv.org/abs/2509.11709)
*Robert Einig,Stefan Janscha,Jonas Schuster,Julian Koch,Martin Hagmueller,Barbara Schuppler*

Main category: cs.CL

TL;DR: 疫情后混合式会议增多，但研讨室声学设计常被忽视。本研究通过改进格拉茨工业大学一研讨室的声学效果，旨在提升混合会议中的沟通效果。研究录制了前后两次的会议，结果显示声学改善有助于提高沟通成功率，但因样本量小，统计学上未达显著性。


<details>
  <summary>Details</summary>
Motivation: 后疫情时代，混合式会议已成为高校和企业的常态，然而研讨室的声学设计往往被忽视，导致混响过高，影响沟通效果，引起误解、降低语音清晰度及导致身心疲劳。

Method: 通过录制两组研究对象在格拉茨工业大学一研讨室进行混合会议的音频，分别记录声学条件改善前后的情况，以评估声学干预措施的效果。

Result: 研究结果显示，尽管由于样本量有限，未能达到统计学上的显著性，但声学上的空间干预措施明显改善了混合会议中的沟通效果。

Conclusion: 对研讨室进行声学干预，如增加吸音和扩散材料，能够有效提升混合会议的沟通质量和用户体验，即使在样本量较小的情况下也能观察到积极趋势。

Abstract: Since the COVID-19 pandemic in 2020, universities and companies have
increasingly integrated hybrid features into their meeting spaces, or even
created dedicated rooms for this purpose. While the importance of a fast and
stable internet connection is often prioritized, the acoustic design of seminar
rooms is frequently overlooked. Poor acoustics, particularly excessive
reverberation, can lead to issues such as misunderstandings, reduced speech
intelligibility or cognitive and vocal fatigue. This pilot study investigates
whether room acoustic interventions in a seminar room at Graz University of
Technology support better communication in hybrid meetings. For this purpose,
we recorded two groups of persons twice, once before and once after improving
the acoustics of the room. Our findings -- despite not reaching statistical
significance due to the small sample size - indicate clearly that our spatial
interventions improve communicative success in hybrid meetings. To make the
paper accessible also for readers from the speech communication community, we
explain room acoustics background, relevant for the interpretation of our
results.

</details>


### [210] [Growing Perspectives: Modelling Embodied Perspective Taking and Inner Narrative Development Using Large Language Models](https://arxiv.org/abs/2509.11868)
*Sabrina Patania,Luca Annese,Anna Lambiase,Anita Pellegrini,Tom Foulsham,Azzurra Ruggeri,Silvia Rossi,Silvia Serino,Dimitri Ognibene*

Main category: cs.CL

TL;DR: 该研究介绍了PerspAct系统，该系统结合了ReAct范式和大型语言模型（LLMs），以模拟基于Selman理论的发展阶段视角。


<details>
  <summary>Details</summary>
Motivation: 为了同时解决语言和具身视角采择这两人类协作的关键要素，而计算模型却鲜有同时处理这两者。

Method: 使用扩展的导演任务，评估GPT生成与指定发展阶段一致的内部叙述的能力，并评估这些叙述如何影响协作表现（定性地通过动作选择，定性地通过任务效率）。

Result: 结果表明，GPT在执行任务前能可靠地生成与发展阶段一致的叙述，但在互动过程中常常会转向更高级别的阶段，这表明语言交流有助于完善内部表征。较高的发展阶段通常能提高协作有效性，而较早的阶段在复杂环境中产生的结果则更具可变性。

Conclusion: 研究结果强调了在LLMs中整合具身视角采择和语言以更好地模拟发展动态的潜力，并强调了在结合语言和具身任务中评估内部语音的重要性。

Abstract: Language and embodied perspective taking are essential for human
collaboration, yet few computational models address both simultaneously. This
work investigates the PerspAct system [1], which integrates the ReAct (Reason
and Act) paradigm with Large Language Models (LLMs) to simulate developmental
stages of perspective taking, grounded in Selman's theory [2]. Using an
extended director task, we evaluate GPT's ability to generate internal
narratives aligned with specified developmental stages, and assess how these
influence collaborative performance both qualitatively (action selection) and
quantitatively (task efficiency). Results show that GPT reliably produces
developmentally-consistent narratives before task execution but often shifts
towards more advanced stages during interaction, suggesting that language
exchanges help refine internal representations. Higher developmental stages
generally enhance collaborative effectiveness, while earlier stages yield more
variable outcomes in complex contexts. These findings highlight the potential
of integrating embodied perspective taking and language in LLMs to better model
developmental dynamics and stress the importance of evaluating internal speech
during combined linguistic and embodied tasks.

</details>


### [211] [An Agentic Toolkit for Adaptive Information Extraction from Regulatory Documents](https://arxiv.org/abs/2509.11773)
*Gaye Colakoglu,Gürkan Solmaz,Jonathan Fürst*

Main category: cs.CL

TL;DR: DoP文档格式不统一，导致信息提取困难。提出了一种基于代理的系统，通过动态工具协调来解决这个问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 欧盟法规强制要求DoP文件，但其格式、语言和结构的多样性给自动化信息提取带来了挑战。

Method: 设计了一个包含规划器、执行器和响应器的领域特定、有状态的代理系统。该系统能够推断用户意图，检测文档模态，并动态协调工具以实现鲁棒、可追溯的推理，同时避免工具误用或执行循环。

Result: 在定制的DoP数据集上进行了评估，结果显示该系统在不同格式和语言的文档上都提高了鲁棒性。

Conclusion: 该系统为受监管的工作流程中的结构化数据提取提供了一个可扩展的解决方案，有效解决了DoP文档格式不统一带来的信息提取难题。

Abstract: Declaration of Performance (DoP) documents, mandated by EU regulation,
certify the performance of construction products. While some of their content
is standardized, DoPs vary widely in layout, language, schema, and format,
posing challenges for automated key-value pair extraction (KVP) and question
answering (QA). Existing static or LLM-only IE pipelines often hallucinate and
fail to adapt to this structural diversity. Our domain-specific, stateful
agentic system addresses these challenges through a planner-executor-responder
architecture. The system infers user intent, detects document modality, and
orchestrates tools dynamically for robust, traceable reasoning while avoiding
tool misuse or execution loops. Evaluation on a curated DoP dataset
demonstrates improved robustness across formats and languages, offering a
scalable solution for structured data extraction in regulated workflows.

</details>


### [212] [User eXperience Perception Insights Dataset (UXPID): Synthetic User Feedback from Public Industrial Forums](https://arxiv.org/abs/2509.11777)
*Mikhail Kulyabin,Jan Joosten,Choro Ulan uulu,Nuno Miguel Martins Pacheco,Fabian Ries,Filippos Petridis,Jan Bosch,Helena Holmström Olsson*

Main category: cs.CL

TL;DR: 该研究提出了UXPID数据集，一个包含7130个合成用户反馈的人工数据集，用于工业论坛用户体验分析，以克服真实数据的限制。


<details>
  <summary>Details</summary>
Motivation: 收集和分析工业论坛中的用户反馈对于理解真实世界的产品体验至关重要，但由于内容的非结构化和领域特定性，传统的数据分析方法难以处理。

Method: 创建了一个名为UXPID的数据集，其中包含7130个合成的、匿名的用户反馈记录，这些记录是从公开的工业自动化论坛中提取的。每个记录都经过了LLM的系统分析和标注，涵盖了用户体验见解、用户期望、严重性和情感评分以及主题分类。

Result: UXPID数据集可以用于训练和评估基于Transformer的模型，以执行诸如问题检测、情感分析和需求提取等任务，特别是在真实数据受限的情况下。

Conclusion: UXPID数据集为用户需求、用户体验分析以及人工智能驱动的反馈处理研究提供了一个有价值的资源，有助于产品开发和支持策略的改进。

Abstract: Customer feedback in industrial forums reflect a rich but underexplored
source of insight into real-world product experience. These publicly shared
discussions offer an organic view of user expectations, frustrations, and
success stories shaped by the specific contexts of use. Yet, harnessing this
information for systematic analysis remains challenging due to the unstructured
and domain-specific nature of the content. The lack of structure and
specialized vocabulary makes it difficult for traditional data analysis
techniques to accurately interpret, categorize, and quantify the feedback,
thereby limiting its potential to inform product development and support
strategies. To address these challenges, this paper presents the User
eXperience Perception Insights Dataset (UXPID), a collection of 7130
artificially synthesized and anonymized user feedback branches extracted from a
public industrial automation forum. Each JavaScript object notation (JSON)
record contains multi-post comments related to specific hardware and software
products, enriched with metadata and contextual conversation data. Leveraging a
large language model (LLM), each branch is systematically analyzed and
annotated for UX insights, user expectations, severity and sentiment ratings,
and topic classifications. The UXPID dataset is designed to facilitate research
in user requirements, user experience (UX) analysis, and AI-driven feedback
processing, particularly where privacy and licensing restrictions limit access
to real-world data. UXPID supports the training and evaluation of
transformer-based models for tasks such as issue detection, sentiment analysis,
and requirements extraction in the context of technical forums.

</details>


### [213] [When Curiosity Signals Danger: Predicting Health Crises Through Online Medication Inquiries](https://arxiv.org/abs/2509.11802)
*Dvora Goncharok,Arbel Shifman,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 本研究通过构建一个包含临床风险因素标注的药物相关问题数据集，并使用传统机器学习和大型语言模型（LLM）对这些问题进行分类，旨在开发一个能够实时识别潜在严重健康风险的预警系统，以提高患者安全。


<details>
  <summary>Details</summary>
Motivation: 在线医疗论坛包含大量关于患者用药的宝贵信息，其中一些问题可能预示着混淆、误用甚至健康危机。及时发现这些可能导致严重不良事件或危及生命的情况至关重要，这能实现及时的干预并提高患者安全。

Method: 本研究创建了一个新颖的、经过标注的药物相关问题数据集，这些问题从在线论坛中提取，并根据临床风险因素进行了人工标注。研究人员使用TF-IDF文本表示方法对六种传统的机器学习分类器进行了基准测试，并采用了三种利用深度上下文理解的先进的大型语言模型（LLM）分类方法。

Result: 研究结果表明，传统的机器学习方法和先进的大型语言模型（LLM）在识别潜在的健康风险方面都具有潜力，能够支持数字健康领域的实时分诊和警报系统。

Conclusion: 本研究提出的经过标注的数据集和基准测试结果，证明了利用传统和现代自然语言处理方法来分析患者生成数据，从而构建早期预警系统以应对危及生命的健康事件是可行的。该数据集已公开提供，以促进相关领域的研究。

Abstract: Online medical forums are a rich and underutilized source of insight into
patient concerns, especially regarding medication use. Some of the many
questions users pose may signal confusion, misuse, or even the early warning
signs of a developing health crisis. Detecting these critical questions that
may precede severe adverse events or life-threatening complications is vital
for timely intervention and improving patient safety. This study introduces a
novel annotated dataset of medication-related questions extracted from online
forums. Each entry is manually labelled for criticality based on clinical risk
factors. We benchmark the performance of six traditional machine learning
classifiers using TF-IDF textual representations, alongside three
state-of-the-art large language model (LLM)-based classification approaches
that leverage deep contextual understanding. Our results highlight the
potential of classical and modern methods to support real-time triage and alert
systems in digital health spaces. The curated dataset is made publicly
available to encourage further research at the intersection of
patient-generated data, natural language processing, and early warning systems
for critical health events. The dataset and benchmark are available at:
https://github.com/Dvora-coder/LLM-Medication-QA-Risk-Classifier-MediGuard.

</details>


### [214] [From Fuzzy Speech to Medical Insight: Benchmarking LLMs on Noisy Patient Narratives](https://arxiv.org/abs/2509.11803)
*Eden Mama,Liel Sheri,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究提出了一个名为NDB的新型合成数据集，用于评估大型语言模型（LLMs）在解读包含噪声、模糊语言和通俗术语的患者叙述方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常使用结构化的临床文本，无法充分评估LLMs在处理非正式、模糊和嘈杂的患者叙述方面的真实能力。

Method: 创建了一个包含临床上一致的病例场景的合成数据集，并标注了真实诊断，模拟了不同清晰度的语言风格。然后，使用该数据集对BERT和T5等多种先进LLMs进行了微调和评估。

Result: 研究结果表明，该数据集能够有效测试和比较LLMs在真实语言条件下的诊断能力。

Conclusion: NDB数据集的发布将有助于推动LLMs在医疗领域的应用，并为相关研究提供支持。

Abstract: The widespread adoption of large language models (LLMs) in healthcare raises
critical questions about their ability to interpret patient-generated
narratives, which are often informal, ambiguous, and noisy. Existing benchmarks
typically rely on clean, structured clinical text, offering limited insight
into model performance under realistic conditions. In this work, we present a
novel synthetic dataset designed to simulate patient self-descriptions
characterized by varying levels of linguistic noise, fuzzy language, and
layperson terminology. Our dataset comprises clinically consistent scenarios
annotated with ground-truth diagnoses, spanning a spectrum of communication
clarity to reflect diverse real-world reporting styles. Using this benchmark,
we fine-tune and evaluate several state-of-the-art models (LLMs), including
BERT-based and encoder-decoder T5 models. To support reproducibility and future
research, we release the Noisy Diagnostic Benchmark (NDB), a structured dataset
of noisy, synthetic patient descriptions designed to stress-test and compare
the diagnostic capabilities of large language models (LLMs) under realistic
linguistic conditions. We made the benchmark available for the community:
https://github.com/lielsheri/PatientSignal

</details>


### [215] [PledgeTracker: A System for Monitoring the Fulfilment of Pledges](https://arxiv.org/abs/2509.11804)
*Yulong Chen,Michael Sejr Schlichtkrull,Zhenyun Deng,David Corney,Nasim Asl,Joshua Salisbury,Andrew Dudfield,Andreas Vlachos*

Main category: cs.CL

TL;DR: PledgeTracker是一个新的系统，用于追踪政治承诺的履行情况，通过构建事件时间线来解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法将政治承诺的履行追踪简化为文档分类任务，忽略了其动态、时序和多文档的特性。

Method: PledgeTracker系统包含三个核心组件：多步证据检索模块、时间线构建模块和履行过滤模块，用于构建结构化的事件时间线。

Result: 在与专业事实核查员的合作中，PledgeTracker被证明在检索相关证据和减少人工核查工作方面是有效的。

Conclusion: PledgeTracker通过构建事件时间线来有效地追踪政治承诺的履行情况，并能被整合到真实世界的工作流程中，以减少人工核查的努力。

Abstract: Political pledges reflect candidates' policy commitments, but tracking their
fulfilment requires reasoning over incremental evidence distributed across
multiple, dynamically updated sources. Existing methods simplify this task into
a document classification task, overlooking its dynamic, temporal and
multi-document nature. To address this issue, we introduce
\textsc{PledgeTracker}, a system that reformulates pledge verification into
structured event timeline construction. PledgeTracker consists of three core
components: (1) a multi-step evidence retrieval module; (2) a timeline
construction module and; (3) a fulfilment filtering module, allowing the
capture of the evolving nature of pledge fulfilment and producing interpretable
and structured timelines. We evaluate PledgeTracker in collaboration with
professional fact-checkers in real-world workflows, demonstrating its
effectiveness in retrieving relevant evidence and reducing human verification
effort.

</details>


### [216] [SCDTour: Embedding Axis Ordering and Merging for Interpretable Semantic Change Detection](https://arxiv.org/abs/2509.11818)
*Taichi Aida,Danushka Bollegala*

Main category: cs.CL

TL;DR: SCDTour通过排序和合并可解释轴来解决可解释性和性能之间的权衡问题，在保持高可解释性的同时，实现了可比或更优的语义变化检测性能。


<details>
  <summary>Details</summary>
Motivation: 在语义变化检测（SCD）中，获得既可解释又高性能的嵌入是一个常见问题，通常需要牺牲一方来提升另一方。

Method: SCDTour通过考虑（a）嵌入空间中轴的语义相似性以及（b）每个轴对语义变化的贡献程度，来排序和合并可解释轴，以减轻SCD性能的下降。

Result: 实验结果表明，SCDTour在保持高可解释性的同时，在语义变化检测方面保持了性能。此外，合并排序后的轴可以产生更精细的词义集合，在SCD任务上取得了与原始全维嵌入相当或更好的性能。

Conclusion: SCDTour能够有效地平衡可解释性与SCD性能，通过少量精炼的轴能够对语义变化进行有意义的解释。

Abstract: In Semantic Change Detection (SCD), it is a common problem to obtain
embeddings that are both interpretable and high-performing. However, improving
interpretability often leads to a loss in the SCD performance, and vice versa.
To address this problem, we propose SCDTour, a method that orders and merges
interpretable axes to alleviate the performance degradation of SCD. SCDTour
considers both (a) semantic similarity between axes in the embedding space, as
well as (b) the degree to which each axis contributes to semantic change.
Experimental results show that SCDTour preserves performance in semantic change
detection while maintaining high interpretability. Moreover, agglomerating the
sorted axes produces a more refined set of word senses, which achieves
comparable or improved performance against the original full-dimensional
embeddings in the SCD task. These findings demonstrate that SCDTour effectively
balances interpretability and SCD performance, enabling meaningful
interpretation of semantic shifts through a small number of refined axes.
Source code is available at https://github.com/LivNLP/svp-tour .

</details>


### [217] [MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long Role-Playing Dialogues](https://arxiv.org/abs/2509.11860)
*Weishu Chen,Jinyi Tang,Zhouhui Hou,Shihao Han,Mingjie Zhan,Zhiyuan Huang,Delong Liu,Jiawei Guo,Zhicheng Zhao,Fei Su*

Main category: cs.CL

TL;DR: MOOM是一种创新的双分支记忆插件，通过借鉴文学理论来管理超长对话中的记忆，有效解决了现有方法中记忆增长失控的问题，并在角色扮演对话任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在超长对话中保持连贯性，需要有效的记忆提取方法，但现有方法存在记忆增长失控的问题。

Method: 提出了一种名为MOOM的双分支记忆插件，其中一个分支用于跨时间尺度的情节冲突总结，另一个分支用于提取用户角色画像，并结合了借鉴“竞争-抑制”记忆理论的遗忘机制来控制记忆容量。

Result: MOOM在超长对话数据集ZH-4O上的实验结果表明，其性能优于所有现有的记忆提取方法，同时减少了对大型语言模型的调用，并保持了可控的记忆容量。

Conclusion: MOOM作为一种新颖的记忆管理方法，通过结合文学理论和记忆遗忘机制，有效解决了超长对话中的记忆增长问题，并在角色扮演场景下取得了领先的性能。

Abstract: Memory extraction is crucial for maintaining coherent ultra-long dialogues in
human-robot role-playing scenarios. However, existing methods often exhibit
uncontrolled memory growth. To address this, we propose MOOM, the first
dual-branch memory plugin that leverages literary theory by modeling plot
development and character portrayal as core storytelling elements.
Specifically, one branch summarizes plot conflicts across multiple time scales,
while the other extracts the user's character profile. MOOM further integrates
a forgetting mechanism, inspired by the ``competition-inhibition'' memory
theory, to constrain memory capacity and mitigate uncontrolled growth.
Furthermore, we present ZH-4O, a Chinese ultra-long dialogue dataset
specifically designed for role-playing, featuring dialogues that average 600
turns and include manually annotated memory information. Experimental results
demonstrate that MOOM outperforms all state-of-the-art memory extraction
methods, requiring fewer large language model invocations while maintaining a
controllable memory capacity.

</details>


### [218] [Uncertainty in Authorship: Why Perfect AI Detection Is Mathematically Impossible](https://arxiv.org/abs/2509.11915)
*Aadil Gani Ganie*

Main category: cs.CL

TL;DR: LLM生成文本的检测与量子不确定性具有相似性，提高检测的确定性会破坏文本的自然性和真实性，这表明完美的检测在理论上是不可能的。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的进步，区分人类和AI生成文本变得越来越困难，这促使我们研究作者身份检测的固有局限性。

Method: 通过类比量子不确定性，分析了风格计量学、水印和神经网络分类器等现有检测方法的局限性，并探讨了提高检测准确性与改变AI输出之间的权衡。

Result: 现有的AI文本检测方法面临根本性限制，因为提高检测准确性会改变AI的输出，从而影响其他特征的可靠性，使其无法实现完美的检测。

Conclusion: AI文本检测的挑战不仅是技术问题，更是语言本质中固有的、不可避免的张力，完美检测在理论上是不可能的。

Abstract: As large language models (LLMs) become more advanced, it is increasingly
difficult to distinguish between human-written and AI-generated text. This
paper draws a conceptual parallel between quantum uncertainty and the limits of
authorship detection in natural language. We argue that there is a fundamental
trade-off: the more confidently one tries to identify whether a text was
written by a human or an AI, the more one risks disrupting the text's natural
flow and authenticity. This mirrors the tension between precision and
disturbance found in quantum systems. We explore how current detection
methods--such as stylometry, watermarking, and neural classifiers--face
inherent limitations. Enhancing detection accuracy often leads to changes in
the AI's output, making other features less reliable. In effect, the very act
of trying to detect AI authorship introduces uncertainty elsewhere in the text.
Our analysis shows that when AI-generated text closely mimics human writing,
perfect detection becomes not just technologically difficult but theoretically
impossible. We address counterarguments and discuss the broader implications
for authorship, ethics, and policy. Ultimately, we suggest that the challenge
of AI-text detection is not just a matter of better tools--it reflects a
deeper, unavoidable tension in the nature of language itself.

</details>


### [219] [Designing LLMs for cultural sensitivity: Evidence from English-Japanese translation](https://arxiv.org/abs/2509.11921)
*Helene Tenzer,Oumnia Abidi,Stefan Feuerriegel*

Main category: cs.CL

TL;DR: LLM在英日工作邮件翻译中，文化定制提示比Naive提示和受众导向提示更能提高文化契合度。


<details>
  <summary>Details</summary>
Motivation: 评估不同LLM设计在处理跨文化交流（特别是英日工作邮件翻译）时的文化敏感性，以确定LLM是否支持文化上恰当的交流。

Method: 采用混合方法研究，通过（1）朴素的“直译”提示、（2）指定接收者文化背景的受众导向提示、（3）包含日本沟通规范明确指导的指令提示这三种提示策略，对LLM进行英日工作邮件翻译。分析具体文化语言模式和母语者的语气接受度。

Result: 文化定制提示（指令提示）在提高翻译的文化契合度方面优于朴素提示和受众导向提示。

Conclusion: 文化定制提示策略可以提高LLM在多语言环境下的翻译文化契合度，并为设计文化包容性LLM提供了建议。

Abstract: Large language models (LLMs) are increasingly used in everyday communication,
including multilingual interactions across different cultural contexts. While
LLMs can now generate near-perfect literal translations, it remains unclear
whether LLMs support culturally appropriate communication. In this paper, we
analyze the cultural sensitivity of different LLM designs when applied to
English-Japanese translations of workplace e-mails. Here, we vary the prompting
strategies: (1) naive "just translate" prompts, (2) audience-targeted prompts
specifying the recipient's cultural background, and (3) instructional prompts
with explicit guidance on Japanese communication norms. Using a mixed-methods
study, we then analyze culture-specific language patterns to evaluate how well
translations adapt to cultural norms. Further, we examine the appropriateness
of the tone of the translations as perceived by native speakers. We find that
culturally-tailored prompting can improve cultural fit, based on which we offer
recommendations for designing culturally inclusive LLMs in multilingual
settings.

</details>


### [220] [Spec-LLaVA: Accelerating Vision-Language Models with Dynamic Tree-Based Speculative Decoding](https://arxiv.org/abs/2509.11961)
*Mingxiao Huo,Jiayi Zhang,Hewei Wang,Jinfeng Xu,Zheyu Chen,Huilin Tai,Yijun Chen*

Main category: cs.CL

TL;DR: Spec-LLaVA利用投机解码技术，在不牺牲输出质量的前提下，显著加速了视觉-语言模型(VLMs)的推理过程，通过轻量级草稿模型和大型目标模型的配合，以及动态树状验证算法，实现了高达3.28倍的加速，为实现实时的多模态助手提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）虽然具有强大的多模态推理能力，但其自回归推理速度缓慢，限制了在实时应用中的部署。本研究旨在解决这一问题。

Method: 提出Spec-LLaVA系统，将投机解码应用于VLMs以加速推理。该系统使用一个轻量级草稿VLM来预测未来的token，然后由一个大型目标模型并行验证这些预测，从而实现在每一步生成多个token。为了提高效率，设计了一种动态树状验证算法，利用草稿模型的置信度自适应地扩展和剪枝投机分支。

Result: 在MS COCO的非目标域图像上，Spec-LLaVA在LLaVA-1.5（7B, 13B）上实现了高达3.28倍的解码加速，同时没有降低生成质量。

Conclusion: Spec-LLaVA是一个无损加速VLMs的框架，采用了动态树状投机解码技术，为实现实时的多模态助手铺平了道路。此外，其轻量级的草稿模型设计也使其适用于资源受限或设备端部署的场景。

Abstract: Vision-Language Models (VLMs) enable powerful multimodal reasoning but suffer
from slow autoregressive inference, limiting their deployment in real-time
applications. We introduce Spec-LLaVA, a system that applies speculative
decoding to accelerate VLMs without sacrificing output quality. Spec-LLaVA
pairs a lightweight draft VLM with a large target model: the draft speculates
future tokens, which the target verifies in parallel, allowing multiple tokens
to be generated per step. To maximize efficiency, we design a dynamic
tree-based verification algorithm that adaptively expands and prunes
speculative branches using draft model confidence. On MS COCO out-of-domain
images, Spec-LLaVA achieves up to 3.28$\times$ faster decoding on LLaVA-1.5
(7B, 13B) with no loss in generation quality. This work presents a lossless
acceleration framework for VLMs using dynamic tree-structured speculative
decoding, opening a path toward practical real-time multimodal assistants.
Importantly, the lightweight draft model design makes the framework amenable to
resource-constrained or on-device deployment settings.

</details>


### [221] [ToolRM: Outcome Reward Models for Tool-Calling Large Language Models](https://arxiv.org/abs/2509.11963)
*Mayank Agarwal,Ibrahim Abdelaziz,Kinjal Basu,Merve Unuvar,Luis A. Lastras,Yara Rizk,Pavan Kapanipathi*

Main category: cs.CL

TL;DR: LLMs与外部工具的交互日益增多，但现有的奖励模型在评估工具使用方面存在不足。本文提出了FC-RewardBench基准和一种基于结果的奖励模型训练框架，该框架使用合成数据进行训练，并在多个基准测试中表现优于通用基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励模型主要基于自然语言输出进行训练，难以有效评估LLM在工具使用中的推理和执行能力，存在关键的评估缺口。

Method: 提出了FC-RewardBench基准来系统地评估奖励模型在工具调用场景下的性能。并提出了一种使用合成数据训练的基于结果的奖励模型框架，模型参数范围从1.7B到14B。

Result: 在七个非领域基准测试中，新训练的奖励模型持续优于通用基线模型，下游任务性能平均提升高达25%，并通过奖励引导过滤实现了数据高效的微调。

Conclusion: 现有的奖励模型在评估LLM的工具使用能力方面存在显著不足，需要针对性的模型。本文提出的基于结果的奖励模型框架和FC-RewardBench基准能够有效解决这一问题，并显著提升下游任务性能。

Abstract: As large language models (LLMs) increasingly interact with external tools,
reward modeling for tool use has become a critical yet underexplored area.
Existing reward models, trained primarily on natural language outputs, struggle
to evaluate tool-based reasoning and execution. To quantify this gap, we
introduce FC-RewardBench, the first benchmark designed to systematically assess
reward models' performance in tool-calling scenarios. Our analysis shows that
current reward models often miss key signals of effective tool use,
highlighting the need for domain-specific modeling. To address this, we propose
a training framework for outcome-based reward models using data synthesized
from permissively licensed, open-weight LLMs. We train models ranging from 1.7B
to 14B parameters and evaluate them across seven out-of-domain benchmarks.
These models consistently outperform general-purpose baselines, achieving up to
25\% average improvement in downstream task performance and enabling
data-efficient fine-tuning through reward-guided filtering.

</details>


### [222] [Query-Focused Extractive Summarization for Sentiment Explanation](https://arxiv.org/abs/2509.11989)
*Ahmed Moubtahij,Sylvie Ratté,Yazid Attabi,Maxime Dumas*

Main category: cs.CL

TL;DR: 通过利用查询聚焦摘要（QFS）来解决从大量文本中提取客户情感原因的问题，提出了一种多偏见框架，并通过基于情感的偏见和查询扩展进行了专门化，在真实数据集上取得了优于基线模型的成果。


<details>
  <summary>Details</summary>
Motivation: 需要从大量文本中确定客户情感的原因，以提高分析反馈的效率。

Method: 提出并证实了一个多偏见框架，以解决查询和源文档之间的语言不匹配问题，并在此基础上，为情感解释问题制定了基于情感的偏见和查询扩展的专门方法。

Result: 提出的方法在真实世界的数据集上取得了优于基线模型的实验结果。

Conclusion: 该研究提出了一种有效的方法来解决查询聚焦摘要中的语言不匹配问题，特别是在情感解释的应用中，并在实验中得到了验证。

Abstract: Constructive analysis of feedback from clients often requires determining the
cause of their sentiment from a substantial amount of text documents. To assist
and improve the productivity of such endeavors, we leverage the task of
Query-Focused Summarization (QFS). Models of this task are often impeded by the
linguistic dissonance between the query and the source documents. We propose
and substantiate a multi-bias framework to help bridge this gap at a
domain-agnostic, generic level; we then formulate specialized approaches for
the problem of sentiment explanation through sentiment-based biases and query
expansion. We achieve experimental results outperforming baseline models on a
real-world proprietary sentiment-aware QFS dataset.

</details>


### [223] [Text Adaptation to Plain Language and Easy Read via Automatic Post-Editing Cycles](https://arxiv.org/abs/2509.11991)
*Jesús Calleja,David Ponce,Thierry Etchegoyhen*

Main category: cs.CL

TL;DR: Vicomtech在西班牙语普通话和易读文本改编的CLEARS挑战赛中获得第一和第二名，其方法是通过迭代式自动后编辑，直到可读性和相似性指标表明无法进一步改进。


<details>
  <summary>Details</summary>
Motivation: 参加CLEARS挑战赛，对西班牙语文本进行普通话和易读性改编。

Method: 对大型语言模型改编进行自动后编辑，通过迭代生成改编，直到可读性和相似性指标不再改进。

Result: 在普通话改编中获得第一名，在易读性改编中获得第二名（基于所有官方指标的平均值）。

Conclusion: 提出的迭代式自动后编辑方法在西班牙语普通话和易读性改编方面取得了优异的成绩。

Abstract: We describe Vicomtech's participation in the CLEARS challenge on text
adaptation to Plain Language and Easy Read in Spanish. Our approach features
automatic post-editing of different types of initial Large Language Model
adaptations, where successive adaptations are generated iteratively until
readability and similarity metrics indicate that no further adaptation
refinement can be successfully performed. Taking the average of all official
metrics, our submissions achieved first and second place in Plain language and
Easy Read adaptation, respectively.

</details>


### [224] [Steering Language Models in Multi-Token Generation: A Case Study on Tense and Aspect](https://arxiv.org/abs/2509.12065)
*Alina Klerings,Jannik Brinkmann,Daniel Ruffinelli,Simone Ponzetto*

Main category: cs.CL

TL;DR: LLMs在语法上编码时，研究人员发现了两种多维层次语法现象——动词时态和方面，并找到了在残差空间中进行区分和控制它们的方法，同时还研究了影响有效控制的因素。


<details>
  <summary>Details</summary>
Motivation: 研究LLM如何在其内部编码句法知识，特别是针对多维层次语法现象，如动词时态和方面。

Method: 使用线性判别分析识别残差空间中区分动词时态和方面（两种多维层次语法现象）的正交方向。然后，通过概念引导在三种生成任务中演示对这两种语法特征的因果控制。最后，通过案例研究，研究了多代词生成中影响有效控制的因素（例如，引导强度、位置和持续时间），以减少不期望的副作用（例如，主题转移和退化）。

Result: 发现了区分动词时态和方面（两种多维层次语法现象）的正交方向。通过概念引导在三种生成任务中成功实现了对这两种语法特征的因果控制。研究发现，引导强度、位置和持续时间是减少不良副作用（例如，主题转移和退化）的关键参数。

Conclusion: LLMs以结构化、类似人类的方式对其时态和方面进行编码，但有效控制这些特征需要手动调整或自动优化，因为它们对多个因素很敏感。

Abstract: Large language models (LLMs) are able to generate grammatically well-formed
text, but how do they encode their syntactic knowledge internally? While prior
work has focused largely on binary grammatical contrasts, in this work, we
study the representation and control of two multidimensional hierarchical
grammar phenomena - verb tense and aspect - and for each, identify distinct,
orthogonal directions in residual space using linear discriminant analysis.
Next, we demonstrate causal control over both grammatical features through
concept steering across three generation tasks. Then, we use these identified
features in a case study to investigate factors influencing effective steering
in multi-token generation. We find that steering strength, location, and
duration are crucial parameters for reducing undesirable side effects such as
topic shift and degeneration. Our findings suggest that models encode tense and
aspect in structurally organized, human-like ways, but effective control of
such features during generation is sensitive to multiple factors and requires
manual tuning or automated optimization.

</details>


### [225] [SENSE models: an open source solution for multilingual and multimodal semantic-based tasks](https://arxiv.org/abs/2509.12093)
*Salima Mdhaffar,Haroun Elleuch,Chaimae Chellaf,Ha Nguyen,Yannick Estève*

Main category: cs.CL

TL;DR: SENSE是一个开源的语音和文本共享嵌入模型，借鉴了SAMU-XLSR和Meta AI的SONAR模型。它使用教师-学生框架对齐语音编码器和文本编码器，并在语义任务上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 通过结合强大的教师文本模型和改进的语音编码器，更新SAMU-XLSR方法，以实现更好的语音和文本表示对齐。

Method: 采用教师-学生框架，将自监督语音编码器与文本编码器的跨语言连续表示在话语层面进行对齐。代码已整合到SpeechBrain工具包，并发布了首个SENSE模型。

Result: 在多语言和多模态语义任务上取得了非常有竞争力的性能。

Conclusion: SENSE模型在语义任务上表现出色，并为理解语音编码器如何捕捉语义提供了新的见解。

Abstract: This paper introduces SENSE (Shared Embedding for N-lingual Speech and tExt),
an open-source solution inspired by the SAMU-XLSR framework and conceptually
similar to Meta AI's SONAR models. These approaches rely on a teacher-student
framework to align a self-supervised speech encoder with the language-agnostic
continuous representations of a text encoder at the utterance level. We
describe how the original SAMU-XLSR method has been updated by selecting a
stronger teacher text model and a better initial speech encoder. The source
code for training and using SENSE models has been integrated into the
SpeechBrain toolkit, and the first SENSE model we trained has been publicly
released. We report experimental results on multilingual and multimodal
semantic tasks, where our SENSE model achieves highly competitive performance.
Finally, this study offers new insights into how semantics are captured in such
semantically aligned speech encoders.

</details>


### [226] [Is 'Hope' a person or an idea? A pilot benchmark for NER: comparing traditional NLP tools and large language models on ambiguous entities](https://arxiv.org/abs/2509.12098)
*Payam Latifi*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在命名实体识别（NER）任务中通常优于传统工具，尤其是在识别上下文相关的实体方面，但传统工具也可能在某些特定类型的实体上表现出更稳定的性能。


<details>
  <summary>Details</summary>
Motivation: 评估和比较三种非大型语言模型（LLM）的自然语言处理（NLP）工具（NLTK、spaCy、Stanza）和三种通用大型语言模型（LLM：Gemini-1.5-flash、DeepSeek-V3、Qwen-3-4B）在命名实体识别（NER）任务上的性能，并为模型选择提供依据。

Method: 使用一个包含119个词元、涵盖五种实体类型（PERSON、LOCATION、ORGANIZATION、DATE、TIME）的小规模、经过仔细标注的数据集，评估了六种系统的NER性能。通过将每个系统的输出与手动标注的黄金标准数据集进行比较，使用F1分数来衡量性能。

Result: 大型语言模型（LLMs）在识别上下文敏感的实体（如人名）方面普遍优于传统工具，其中Gemini取得了最高的平均F1分数。然而，像Stanza这样的传统系统在识别LOCATION和DATE等结构化标签方面表现出更强的稳定性。研究还观察到大型语言模型之间存在差异，特别是在处理时间表达式和多词组织名称方面。

Conclusion: 尽管大型语言模型（LLMs）提供了更强的上下文理解能力，但在特定任务上，传统工具仍然具有竞争力，这为选择合适的模型提供了参考。

Abstract: This pilot study presents a small-scale but carefully annotated benchmark of
Named Entity Recognition (NER) performance across six systems: three non-LLM
NLP tools (NLTK, spaCy, Stanza) and three general-purpose large language models
(LLMs: Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B). The dataset contains 119
tokens covering five entity types (PERSON, LOCATION, ORGANIZATION, DATE, TIME).
We evaluated each system's output against the manually annotated gold standard
dataset using F1-score. The results show that LLMs generally outperform
conventional tools in recognizing context-sensitive entities like person names,
with Gemini achieving the highest average F1-score. However, traditional
systems like Stanza demonstrate greater consistency in structured tags such as
LOCATION and DATE. We also observed variability among LLMs, particularly in
handling temporal expressions and multi-word organizations. Our findings
highlight that while LLMs offer improved contextual understanding, traditional
tools remain competitive in specific tasks, informing model selection.

</details>


### [227] [In-domain SSL pre-training and streaming ASR](https://arxiv.org/abs/2509.12101)
*Jarod Duret,Salima Mdhaffar,Gaëlle Laperrière,Ryan Whetten,Audrey Galametz,Catherine Kobus,Marion-Cécile Martin,Jo Oleiwan,Yannick Estève*

Main category: cs.CL

TL;DR: 通过在ATC数据上进行领域特定的自监督预训练，可以显著提高ATC环境下的离线和流式语音识别（ASR）性能，并提出了一种低延迟的流式方法以满足航空安全关键应用的需求。


<details>
  <summary>Details</summary>
Motivation: 研究领域特定的自监督预训练方法对于提高航空管制（ATC）环境下的离线和流式自动语音识别（ASR）性能的益处。

Method: 使用4.5k小时的未标记ATC数据训练BEST-RQ模型，然后在较小的监督ATC数据集上进行微调。为了实现实时处理，提出使用分块注意力（chunked attention）和动态卷积（dynamic convolutions）来实现低延迟推理。并将这些领域内SSL模型与w2v-BERT 2.0和HuBERT等最先进的通用语音编码器进行比较。

Result: 领域自适应预训练在标准的ATC基准测试中显著提高了性能，与在广泛语音语料库上训练的模型相比，显著降低了词错误率。此外，提出的流式方法在更严格的延迟限制下进一步提高了词错误率。

Conclusion: 将SSL表示专门用于ATC数据是实现更准确、更高效的实际运行ASR系统的实用途径。

Abstract: In this study, we investigate the benefits of domain-specific self-supervised
pre-training for both offline and streaming ASR in Air Traffic Control (ATC)
environments. We train BEST-RQ models on 4.5k hours of unlabeled ATC data, then
fine-tune on a smaller supervised ATC set. To enable real-time processing, we
propose using chunked attention and dynamic convolutions, ensuring low-latency
inference. We compare these in-domain SSL models against state-of-the-art,
general-purpose speech encoders such as w2v-BERT 2.0 and HuBERT. Results show
that domain-adapted pre-training substantially improves performance on standard
ATC benchmarks, significantly reducing word error rates when compared to models
trained on broad speech corpora. Furthermore, the proposed streaming approach
further improves word error rate under tighter latency constraints, making it
particularly suitable for safety-critical aviation applications. These findings
highlight that specializing SSL representations for ATC data is a practical
path toward more accurate and efficient ASR systems in real-world operational
settings.

</details>


### [228] [GTA: Supervised-Guided Reinforcement Learning for Text Classification with Large Language Models](https://arxiv.org/abs/2509.12108)
*Min Zeng,Jinfei Sun,Xueyou Luo,Caiquan Liu,Shiqi Zhang,Li Xie,Xiaoxin Chen*

Main category: cs.CL

TL;DR: Guess-Think-Answer (GTA)框架结合了SFT的效率和RL的能力提升，在文本分类任务上实现了更快的收敛和更高的性能。


<details>
  <summary>Details</summary>
Motivation: 纯RL方法在探索和收敛方面效率低下，而SFT方法性能上限有限。GTA框架旨在解决效率-能力权衡问题。

Method: GTA框架首先通过交叉熵损失优化生成初步猜测，然后对猜测进行反思，最后生成最终答案。RL奖励用于指导最终输出和整个GTA结构的格式。通过使用损失掩码和梯度约束来缓解训练信号之间的梯度冲突。

Result: GTA框架在四个文本分类基准测试中，显著加速了收敛速度，并且优于单独的SFT和RL基线方法。

Conclusion: GTA框架是一种有效的混合训练范式，能够结合SFT的效率和RL的能力提升，在文本分类任务上取得优于纯SFT和纯RL方法的性能。

Abstract: In natural language processing tasks, pure reinforcement learning (RL)
fine-tuning methods often suffer from inefficient exploration and slow
convergence; while supervised fine-tuning (SFT) methods, although efficient in
training, have limited performance ceiling and less solid theoretical
foundation compared to RL. To address efficiency-capability trade-off, we
propose the Guess-Think-Answer (GTA) framework that combines the efficiency of
SFT with the capability gains of RL in a unified training paradigm. GTA works
by having the model first produce a provisional guess (optimized via
cross-entropy loss), then reflect on this guess before generating the final
answer, with RL rewards shaping both the final output and the format of the
entire GTA structure. This hybrid approach achieves both faster convergence
than pure RL and higher performance ceiling than pure SFT. To mitigate gradient
conflicts between the two training signals, we employ loss masking and gradient
constraints. Empirical results on four text classification benchmarks
demonstrate that GTA substantially accelerates convergence while outperforming
both standalone SFT and RL baselines.

</details>


### [229] [CBP-Tuning: Efficient Local Customization for Black-box Large Language Models](https://arxiv.org/abs/2509.12112)
*Jiaxuan Zhao,Naibin Gu,Yuchen Feng,Xiyu Liu,Peng Fu,Zheng Lin,Weiping Wang*

Main category: cs.CL

TL;DR: CBP-Tuning是一种新的框架，可以在本地高效定制LLM，同时保护用户数据隐私。它包括一个服务器端的提示生成器和一个用户端的无梯度优化器，只需要一个定制向量即可实现有效适配。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM定制成本高，限制了其适应用户特定需求的能力。基于云的服务虽然方便，但难以规模化支持个性化定制，用户也面临隐私风险。

Method: 提出了一种名为CBP-Tuning的框架，该框架包括一个在服务器端训练的提示生成器，用于捕获特定领域和任务无关的能力，以及一个用户端的无梯度优化器，用于为单个任务定制软提示。

Result: 在常识推理、医疗和金融领域进行了评估，CBP-Tuning表现优于基线模型，证明了其在任务无关处理和隐私保护方面的优势。

Conclusion: CBP-Tuning通过高效的本地定制和双向隐私保护，解决了LLM定制的挑战。

Abstract: The high costs of customizing large language models (LLMs) fundamentally
limit their adaptability to user-specific needs. Consequently, LLMs are
increasingly offered as cloud-based services, a paradigm that introduces
critical limitations: providers struggle to support personalized customization
at scale, while users face privacy risks when exposing sensitive data. To
address this dual challenge, we propose Customized Black-box Prompt Tuning
(CBP-Tuning), a novel framework that facilitates efficient local customization
while preserving bidirectional privacy. Specifically, we design a two-stage
framework: (1) a prompt generator trained on the server-side to capture
domain-specific and task-agnostic capabilities, and (2) user-side gradient-free
optimization that tailors soft prompts for individual tasks. This approach
eliminates the need for users to access model weights or upload private data,
requiring only a single customized vector per task while achieving effective
adaptation. Furthermore, the evaluation of CBP-Tuning in the commonsense
reasoning, medical and financial domain settings demonstrates superior
performance compared to baselines, showcasing its advantages in task-agnostic
processing and privacy preservation.

</details>


### [230] [XplaiNLP at CheckThat! 2025: Multilingual Subjectivity Detection with Finetuned Transformers and Prompt-Based Inference with Large Language Models](https://arxiv.org/abs/2509.12130)
*Ariana Sahitaj,Jiaao Li,Pia Wenzel Neves,Fedor Splitt,Premtim Sahitaj,Charlott Jakob,Veronika Solopova,Vera Schmitt*

Main category: cs.CL

TL;DR: XplaiNLP在2025年CheckThat!多语言主观性检测任务中，通过微调Transformer模型（如XLM-RoBERTa）和零样本提示LLM，在意大利语单语子任务中获得第一名，并在罗马尼亚语、多语言和希腊语任务中表现出色，但在乌克兰语和波兰语零样本设置中表现略低于基线。


<details>
  <summary>Details</summary>
Motivation: 评估XplaiNLP在多语言主观性检测任务中采用监督微调Transformer模型和零样本提示LLM两种方法的效果。

Method: 1. 对EuroBERT, XLM-RoBERTa, German-BERT等模型进行监督微调，使用单语和机器翻译的训练数据。 2. 使用o3-mini（规则标注）和gpt-4.1-mini（对比改写和比较推理）进行零样本提示。

Result: 1. 监督微调方法在意大利语单语子任务中获得第一名（F1分数0.8104）。 2. 在罗马尼亚语零样本设置中，微调的XLM-RoBERTa模型获得第三名（F1分数0.7917）。 3. 该模型在多语言和希腊语任务中也表现可靠，优于基线。 4. German-BERT在翻译数据上微调后表现具有竞争力。 5. 乌克兰语和波兰语零样本设置性能略低于基线。

Conclusion: 监督微调方法在意大利语单语子任务中表现最佳。XLM-RoBERTa模型在多语言和低资源场景下表现出一定的鲁棒性，但零样本方法在低资源跨语言场景下存在泛化挑战。

Abstract: This notebook reports the XplaiNLP submission to the CheckThat! 2025 shared
task on multilingual subjectivity detection. We evaluate two approaches: (1)
supervised fine-tuning of transformer encoders, EuroBERT, XLM-RoBERTa, and
German-BERT, on monolingual and machine-translated training data; and (2)
zero-shot prompting using two LLMs: o3-mini for Annotation (rule-based
labelling) and gpt-4.1-mini for DoubleDown (contrastive rewriting) and
Perspective (comparative reasoning). The Annotation Approach achieves 1st place
in the Italian monolingual subtask with an F_1 score of 0.8104, outperforming
the baseline of 0.6941. In the Romanian zero-shot setting, the fine-tuned
XLM-RoBERTa model obtains an F_1 score of 0.7917, ranking 3rd and exceeding the
baseline of 0.6461. The same model also performs reliably in the multilingual
task and improves over the baseline in Greek. For German, a German-BERT model
fine-tuned on translated training data from typologically related languages
yields competitive performance over the baseline. In contrast, performance in
the Ukrainian and Polish zero-shot settings falls slightly below the respective
baselines, reflecting the challenge of generalization in low-resource
cross-lingual scenarios.

</details>


### [231] [Pun Unintended: LLMs and the Illusion of Humor Understanding](https://arxiv.org/abs/2509.12158)
*Alessandro Zangari,Matteo Marcuzzo,Andrea Albarelli,Mohammad Taher Pilehvar,Jose Camacho-Collados*

Main category: cs.CL

TL;DR: 大型语言模型在理解双关语方面仍然存在不足，即使是细微的改动也会误导它们。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在理解和检测双关语方面的能力，并展示它们理解的浅薄性。

Method: 通过系统性地分析和重新构建现有的双关语基准测试，并进行人类评估来挑战和分析LLMs。

Result: LLMs在理解双关语方面存在不足，即使是细微的改动也会误导它们。现有的双关语基准测试可能无法充分评估LLMs的理解能力。

Conclusion: 目前的大型语言模型在理解双关语方面仍有局限性，需要更具挑战性和细致的基准测试来评估其鲁棒性。

Abstract: Puns are a form of humorous wordplay that exploits polysemy and phonetic
similarity. While LLMs have shown promise in detecting puns, we show in this
paper that their understanding often remains shallow, lacking the nuanced grasp
typical of human interpretation. By systematically analyzing and reformulating
existing pun benchmarks, we demonstrate how subtle changes in puns are
sufficient to mislead LLMs. Our contributions include comprehensive and nuanced
pun detection benchmarks, human evaluation across recent LLMs, and an analysis
of the robustness challenges these models face in processing puns.

</details>


### [232] [RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing](https://arxiv.org/abs/2509.12168)
*Timothy Rupprecht,Enfu Nan,Arash Akbari,Arman Akbari,Lei Lu,Priyanka Maan,Sean Duffy,Pu Zhao,Yumei He,David Kaeli,Yanzhi Wang*

Main category: cs.CL

TL;DR: RAGs-to-Riches是一个新的LLM角色扮演框架，它将LLM角色扮演重新定义为文本检索问题，并通过引用演示来指导LLM响应，从而提高模型的稳定性和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM角色扮演方法在面对恶意用户时容易出现角色失真，影响用户信任和福祉。需要一种更具成本效益且鲁棒的方法来提高LLM角色扮演的性能。

Method: 提出了一种名为RAGs-to-Riches的新型提示框架，该框架借鉴了检索增强生成（RAG）的思想，将LLM角色扮演视为文本检索问题，并利用精心策划的参考演示来指导LLM的响应。开发了两种新的评估指标：输出交集（IOO）和参考交集（IOR），分别用于量化LLM的即兴创作程度和利用示例演示的程度。

Result: 在模拟与恶意用户的交互时，RAGs-to-Riches框架在推理时在其响应中平均纳入了35%的参考演示标记。在453次角色扮演交互的评估中，与零样本和上下文学习（ICL）方法相比，使用该框架的模型被认为更真实，并且更少出现角色失真。

Conclusion: RAGs-to-Riches提供了一种可扩展的策略，用于构建鲁棒且符合人类期望的LLM角色扮演框架，解决了现有方法在保持角色一致性方面的挑战。

Abstract: Role-playing Large language models (LLMs) are increasingly deployed in
high-stakes domains such as healthcare, education, and governance, where
failures can directly impact user trust and well-being. A cost effective
paradigm for LLM role-playing is few-shot learning, but existing approaches
often cause models to break character in unexpected and potentially harmful
ways, especially when interacting with hostile users. Inspired by
Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a
text retrieval problem and propose a new prompting framework called
RAGs-to-Riches, which leverages curated reference demonstrations to condition
LLM responses. We evaluate our framework with LLM-as-a-judge preference voting
and introduce two novel token-level ROUGE metrics: Intersection over Output
(IOO) to quantity how much an LLM improvises and Intersection over References
(IOR) to measure few-shot demonstrations utilization rate during the evaluation
tasks. When simulating interactions with a hostile user, our prompting strategy
incorporates in its responses during inference an average of 35% more tokens
from the reference demonstrations. As a result, across 453 role-playing
interactions, our models are consistently judged as being more authentic, and
remain in-character more often than zero-shot and in-context Learning (ICL)
methods. Our method presents a scalable strategy for building robust,
human-aligned LLM role-playing frameworks.

</details>


### [233] [Preservation of Language Understanding Capabilities in Speech-aware Large Language Models](https://arxiv.org/abs/2509.12171)
*Marek Kubis,Paweł Skórzewski,Iwona Christop,Mateusz Czyżnikiewicz,Jakub Kubiak,Łukasz Bondaruk,Marcin Lewandowski*

Main category: cs.CL

TL;DR: C3T是一个新的基准，用于评估语音感知大语言模型的性能，通过语音输入评估语言理解能力在多大程度上得以保留。


<details>
  <summary>Details</summary>
Motivation: 评估语音感知大语言模型在语音输入下语言理解能力的保持程度，并量化模型在不同说话人类别和跨文本/语音模态下的公平性和鲁棒性。

Method: 使用文本任务和语音克隆文本到语音模型来量化语言理解能力的保留程度。

Result: C3T量化了模型对于不同说话人类别的公平性以及在文本和语音模态下的鲁棒性。

Conclusion: C3T是评估语音感知大语言模型性能的新基准。

Abstract: The paper presents C3T (Cross-modal Capabilities Conservation Test), a new
benchmark for assessing the performance of speech-aware large language models.
The benchmark utilizes textual tasks and a voice cloning text-to-speech model
to quantify the extent to which language understanding capabilities are
preserved when the model is accessed via speech input. C3T quantifies the
fairness of the model for different categories of speakers and its robustness
across text and speech modalities.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [234] [Network Embedding Analysis for Anti-Money Laundering Detection](https://arxiv.org/abs/2509.10715)
*Anthony Bonato,Adam Szava*

Main category: cs.SI

TL;DR: 使用网络嵌入技术和节点2vec（node2vec）来检测金融交易网络中的洗钱行为，提出了一种名为“散布数”（spread number）的新网络参数，并结合传统中心性度量定义了一个综合得分 R，以识别能够逃避检测的“反中心”节点。


<details>
  <summary>Details</summary>
Motivation: 检测金融交易网络中的洗钱行为，特别是那些能够逃避传统图中心性度量方法的洗钱策略。

Method: 利用网络嵌入（network embedding）技术，特别是节点2vec（node2vec），对金融交易网络进行建模。使用一个包含超过一百万个账户的真实匿名银行数据集，将账户建模为有向图。通过节点2vec嵌入来优化先前检测到的可疑交易循环，并引入了一个新的网络参数——散布数（spread number）。将散布数与传统的中心性度量相结合，形成一个综合得分 R，用于识别“反中心”节点（anti-central nodes）。

Result: 研究发现，只有一小部分交易循环能够获得高 R 值，这表明存在高度集中的可疑账户群体。这种方法能够有效地识别出那些利用结构重要性来逃避检测的账户。

Conclusion: 基于嵌入的网络分析方法在揭示洗钱策略方面具有巨大潜力，能够有效识别出传统图中心性度量方法难以发现的洗钱行为。

Abstract: We employ network embedding to detect money laundering in financial
transaction networks. Using real anonymized banking data, we model over one
million accounts as a directed graph and use it to refine previously detected
suspicious cycles with node2vec embeddings, creating a new network parameter,
the spread number. Combined with more traditional centrality measures, these
define an aggregate score $R$ that highlights so-called anti-central nodes:
accounts that are structurally important yet organized to avoid detection. Our
results show only a small subset of cycles attain high $R$ values, flagging
concentrated groups of suspicious accounts. Our approach demonstrates the
potential of embedding-based network analysis to expose laundering strategies
that evade traditional graph centrality measures.

</details>


### [235] [Socially-Informed Content Analysis of Online Human Behavior](https://arxiv.org/abs/2509.10807)
*Julie Jiang*

Main category: cs.SI

TL;DR: 社交媒体的负面影响可以通过计算社会科学方法解决，例如通过统一的用户嵌入来分析政治极化、仇恨言论和回音室。


<details>
  <summary>Details</summary>
Motivation: 研究社交媒体上政治极化、错误信息、仇恨言论和回音室等挑战，并提出数据驱动的解决方案。

Method: 提出一种可扩展的社交网络表示学习方法，以整合用户生成的内容和社交连接来创建统一的用户嵌入，从而能够准确预测和可视化用户属性、社区和行为倾向。然后，该方法被应用于分析Twitter上的COVID-19讨论、在线仇恨言论以及COVID-19讨论的道德基础。

Result: 研究发现，COVID-19的讨论存在政治极化和不对称的回音室；在线仇恨言论的动机是寻求社会认同；道德同质性和回音室在COVID-19讨论中普遍存在，但道德多样性可以扩大信息的传播和接受度。

Conclusion: 计算社会科学方法可以为理解人类行为提供新的见解，并为解决社交媒体的负面影响提供依据。

Abstract: The explosive growth of social media has not only revolutionized
communication but also brought challenges such as political polarization,
misinformation, hate speech, and echo chambers. This dissertation employs
computational social science techniques to investigate these issues, understand
the social dynamics driving negative online behaviors, and propose data-driven
solutions for healthier digital interactions. I begin by introducing a scalable
social network representation learning method that integrates user-generated
content with social connections to create unified user embeddings, enabling
accurate prediction and visualization of user attributes, communities, and
behavioral propensities. Using this tool, I explore three interrelated
problems: 1) COVID-19 discourse on Twitter, revealing polarization and
asymmetric political echo chambers; 2) online hate speech, suggesting the
pursuit of social approval motivates toxic behavior; and 3) moral underpinnings
of COVID-19 discussions, uncovering patterns of moral homophily and echo
chambers, while also indicating moral diversity and plurality can improve
message reach and acceptance across ideological divides. These findings
contribute to the advancement of computational social science and provide a
foundation for understanding human behavior through the lens of social
interactions and network homophily.

</details>


### [236] [YTCommentVerse: A Multi-Category Multi-Lingual YouTube Comment Corpus](https://arxiv.org/abs/2509.11057)
*Hridoy Sankar Dutta,Biswadeep Khan*

Main category: cs.SI

TL;DR: YTCommentVerse是一个包含3200万条YouTube评论的大型多语言、多类别数据集，涵盖15个内容类别和50多种语言，可用于分析情感、毒性和参与度。


<details>
  <summary>Details</summary>
Motivation: YTCommentVerse填补了公开社交媒体数据集中分析视频分享平台的空白，该数据集结合了多语言、详细类别和元数据。

Method: 构建了一个包含3200万条YouTube评论的大型多语言、多类别数据集，其中包含视频和评论ID、用户频道详情、点赞数和类别标签。

Result: 该数据集包含来自178,000个视频的3200万条评论，由超过2000万独立用户贡献，涵盖15个内容类别和50多种语言。

Conclusion: YTCommentVerse为跨越不同文化和主题背景的情感、毒性和参与度分析提供了丰富的资源。

Abstract: In this paper, we introduce YTCommentVerse, a large-scale multilingual and
multi-category dataset of YouTube comments. It contains over 32 million
comments from 178,000 videos contributed by more than 20 million unique users
spanning 15 distinct YouTube content categories such as Music, News, Education
and Entertainment. Each comment in the dataset includes video and comment IDs,
user channel details, upvotes and category labels. With comments in over 50
languages, YTCommentVerse provides a rich resource for exploring sentiment,
toxicity and engagement patterns across diverse cultural and topical contexts.
This dataset helps fill a major gap in publicly available social media datasets
particularly for analyzing video sharing platforms by combining multiple
languages, detailed categories and other metadata.

</details>


### [237] [Fast Percolation Centrality Approximation with Importance Sampling](https://arxiv.org/abs/2509.11454)
*Antonio Cruciani,Leonardo Pellegrina*

Main category: cs.SI

TL;DR: PercIS是一种基于重要性采样算法，用于近似计算图中所有节点的渗流中心性，解决了现有方法效率低下的问题，并在准确性和运行时间上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 渗流中心性是重叠中心性到属性图的泛化，可用于量化节点在传染过程或信息传播中的重要性，但对于大型网络难以精确计算。

Method: 提出并分析了一种新颖的基于重要性采样的采样算法，并证明了其实现高质量近似所需的严格样本量界限。

Result: 实验结果表明，PercIS能够计算出高质量的近似值，并能扩展到大型真实网络，在样本量、准确性和运行时间方面显著优于现有技术。

Conclusion: PercIS是一种高效且准确的近似计算网络节点渗流中心性的算法，优于现有方法。

Abstract: In this work we present PercIS, an algorithm based on Importance Sampling to
approximate the percolation centrality of all the nodes of a graph. Percolation
centrality is a generalization of betweenness centrality to attributed graphs,
and is a useful measure to quantify the importance of the vertices in a
contagious process or to diffuse information. However, it is impractical to
compute it exactly on modern-sized networks.
  First, we highlight key limitations of state-of-the-art sampling-based
approximation methods for the percolation centrality, showing that in most
cases they cannot achieve accurate solutions efficiently. Then, we propose and
analyze a novel sampling algorithm based on Importance Sampling, proving tight
sample size bounds to achieve high-quality approximations.
  Our extensive experimental evaluation shows that PercIS computes high-quality
estimates and scales to large real-world networks, while significantly
outperforming, in terms of sample sizes, accuracy and running times, the
state-of-the-art.

</details>


### [238] [No Community Detection Method to Rule Them All!](https://arxiv.org/abs/2509.11490)
*Shrabani Ghosh,Erik Saule*

Main category: cs.SI

TL;DR: 社区检测算法的选择对下游任务的性能有显著影响，没有一种通用算法能在所有情况下都取得最佳效果，结合随机社区生成和机器学习的方法可能带来更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的社区检测算法评估方式（如模块度）和评估其对下游任务的影响的方式，都未能充分理解特定社区检测算法对下游任务的实际支持效果。

Method: 通过分析多种算法在两种不同任务上的表现，研究社区结构与下游任务性能（F1、精确率、召回率、AUC）之间的关系，并探究社区层面的属性与任务指标之间的联系。

Result: 研究发现，社区检测方法的选择对下游任务的输出结果有实质性影响。虽然社区属性是影响任务性能的关键，但没有单一属性能够直接决定性能，而是由多种属性的复杂交互作用所决定。

Conclusion: 没有一种标准的社区检测算法能够保证在所有下游任务中都获得最佳性能。一种结合了随机社区生成和简单机器学习技术的新方法，在实践中表现出了更优的性能。

Abstract: Community detection is a core tool for analyzing large realworld graphs. It
is often used to derive additional local features of vertices and edges that
will be used to perform a downstream task, yet the impact of community
detection on downstream tasks is poorly understood. Prior work largely
evaluates community detection algorithms by their intrinsic objectives (e.g.,
modularity). Or they evaluate the impact of using community detection onto on
the downstream task. But the impact of particular community detection algortihm
support the downstream task. We study the relationship between community
structure and downstream performance across multiple algorithms and two tasks.
Our analysis links community-level properties to task metrics (F1, precision,
recall, AUC) and reveals that the choice of detection method materially affects
outcomes. We explore thousands of community structures and show that while the
properties of communities are the reason behind the impact on task performance,
no single property explains performance in a direct way. Rather, results emerge
from complex interactions among properties. As such, no standard community
detection algorithm will derive the best downstream performance. We show that a
method combining random community generation and simple machine learning
techniques can derive better performance

</details>


### [239] [The threshold and quasi-stationary distribution for the SIS model on networks](https://arxiv.org/abs/2509.11706)
*George Cantwell,Cristopher Moore*

Main category: cs.SI

TL;DR: SIS模型在任意网络上的成对近似可以动态地扩展状态空间，使其具有过去可疑状态的记忆，从而提高预测流行阈值和感染者比例的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究任意网络上的SIS模型，并改进现有的成对近似方法。

Method: 通过动态扩展状态空间，为节点提供最后一次变为易感状态的记忆，来改进成对近似方法。

Result: 改进后的近似方法易于实现，并且在定位流行阈值和计算阈值以上的感染者比例方面都非常准确，适用于有限图和无限随机图。

Conclusion: 改进的成对近似方法在分析SIS模型在任意网络上的行为时，能够提供更高的准确性。

Abstract: We study the Susceptible-Infectious-Susceptible (SIS) model on arbitrary
networks. The well-established pair approximation treats neighboring pairs of
nodes exactly while making a mean field approximation for the rest of the
network. We improve the method by expanding the state space dynamically, giving
nodes a memory of when they last became susceptible. The resulting
approximation is simple to implement and appears to be highly accurate, both in
locating the epidemic threshold and in computing the quasi-stationary fraction
of infected individuals above the threshold, for both finite graphs and
infinite random graphs.

</details>


### [240] [Percolation and matrix spectrum through NIB message passing](https://arxiv.org/abs/2509.11730)
*Pedro Hack*

Main category: cs.SI

TL;DR: KCN-method 是一种用于解决网络中环路问题的广义信念传播方法，最初用于渗流和稀疏矩阵谱计算。NIB-method 是 KCN-method 的改进版，用于概率图模型推理，现在也被证明可以应用于渗流和矩阵谱计算。


<details>
  <summary>Details</summary>
Motivation: KCN-method 和 NIB-method 的改进可以推广到 KCN-method 的原始应用领域，如渗流和矩阵谱计算。

Method: 将 NIB-method 应用于渗流和矩阵谱计算。

Result: NIB-method 在渗流和矩阵谱计算中也取得了与概率图模型推理相似的改进效果。

Conclusion: NIB-method 的改进不仅限于概率图模型推理，还可以有效地应用于渗流和矩阵谱计算等领域。

Abstract: Given its computational efficiency and versatility, belief propagation is the
most prominent message passing method in several applications. In order to
diminish the damaging effect of loops on its accuracy, the first explicit
version of generalized belief propagation for networks, the KCN-method, was
recently introduced. This approach was originally developed in the context of
two target problems: percolation and the calculation of the spectra of sparse
matrices. Later on, the KCN-method was extended in order to deal with inference
in the context of probabilistic graphical models on networks. It was in this
scenario where an improvement on the KCN-method, the NIB-method, was conceived.
We show here that this improvement can also achieved in the original
applications of the KCN-method, namely percolation and matrix spectra.

</details>


### [241] [Fostering cultural change in research through innovative knowledge sharing, evaluation, and community engagement strategies](https://arxiv.org/abs/2509.12045)
*Junsuk Rho,Jinn-Kong Sheu,Andrew Forbes,Din Ping Tsai,Andrea Alú,Wei Li,Mark Brongersma,Joonhee Choi,Javier Garcia de Abajo,Laura Na Liu,Alexander Szameit,Tracy Schloemer,Andreas Tittl,Mario Chemnitz,Cheng Wang,Jiejun Zhang,Yuri Kivshar,Tie Jun Cui,Ren-Min Ma,Cheng-Wei Qiu,Cuicui Lu,Yao-Wei Huang,Miguel Angel Solis Prosser,Ileana-Cristina Benea-Chelmus,Rachel Grange,Sungjin Kim,Anderson S. L. Gomes,Davide Ramaccia,Yating Wan,Apostolos Argyris,Antonio G. Souza Filho,Tanmoy Chandrad,Cristiano Matricardi*

Main category: cs.SI

TL;DR: 现有科研评价体系依赖于 h 指数和期刊影响因子等过时指标，可能牺牲了研究的诚信和可重复性。本文汇集了全球研究人员、资助机构、行业合作伙伴和出版商，旨在构想一个更公平、更公平的知识共享和研究评估体系。


<details>
  <summary>Details</summary>
Motivation: 现有科研评价体系依赖于 h 指数和期刊影响因子等过时指标，可能牺牲了研究的诚信和可重复性，因此需要新的评价体系。

Method: 汇集了来自 14 个不同国家/地区的全球研究人员、资助机构、行业合作伙伴和出版商，共同构想一个更公平、更公平的知识共享和研究评估体系。

Result: 该社区论文提出了一个关于如何改进知识共享和研究评估的设想，旨在对所有相关方产生积极影响。

Conclusion: 通过汇集全球社区的共同努力，设想出一个更公平、更公平的科学研究和知识共享的未来。

Abstract: Scientific research needs a new system that appropriately values science and
scientists. Key innovations, within institutions and funding agencies, are
driving better assessment of research, with open knowledge and FAIR (findable,
accessible, interoperable, and reusable) principles as central pillars.
Furthermore, coalitions, agreements, and robust infrastructures have emerged to
promote more accurate assessment metrics and efficient knowledge sharing.
However, despite these efforts, the system still relies on outdated methods
where standardized metrics such as h-index and journal impact factor dominate
evaluations. These metrics have had the unintended consequence of pushing
researchers to produce more outputs at the expense of integrity and
reproducibility. In this community paper, we bring together a global community
of researchers, funding institutions, industrial partners, and publishers from
14 different countries across the 5 continents. We aim at collectively envision
an evolved knowledge sharing and research evaluation along with the potential
positive impact on every stakeholder involved. We imagine these ideas to set
the groundwork for a cultural change to redefine a more fair and equitable
scientific landscape.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [242] [The Chonkers Algorithm: Content-Defined Chunking with Strict Guarantees on Size and Locality](https://arxiv.org/abs/2509.11121)
*Benjamin Berger*

Main category: cs.DS

TL;DR: Chonkers是一种新的内容定义分块算法，它能在分块大小和编辑局部性之间提供严格的保证，并具有有限的编辑传播和精确的块大小控制。


<details>
  <summary>Details</summary>
Motivation: 现有的内容定义分块算法（如Rabin指纹和基于锚点的方法）在编辑传播和块大小控制方面存在不足。Chonkers算法旨在解决这些问题。

Method: Chonkers算法采用分层结构，并引入了Yarn数据类型（一种基于合并树的重复数据删除字符串表示），以实现对分块大小和编辑局部性的严格控制。

Result: Chonkers算法能够实现分块大小的精确控制和有限的编辑传播，Yarn数据类型也从中受益。

Conclusion: Chonkers算法是一种在分块大小和编辑局部性方面都有严格保证的新颖的内容定义分块方法。

Abstract: This paper presents the Chonkers algorithm, a novel content-defined chunking
method providing simultaneous strict guarantees on chunk size and edit
locality. Unlike existing algorithms such as Rabin fingerprinting and
anchor-based methods, Chonkers achieves bounded propagation of edits and
precise control over chunk sizes. I describe the algorithm's layered structure,
theoretical guarantees, implementation considerations, and introduce the Yarn
datatype, a deduplicated, merge-tree-based string representation benefiting
from Chonkers' strict guarantees.

</details>


### [243] [Triangle-Covered Graphs: Algorithms, Complexity, and Structure](https://arxiv.org/abs/2509.11448)
*Amirali Madani,Anil Maheshwari,Babak Miraftab,Paweł Żyliński*

Main category: cs.DS

TL;DR: 该论文研究了将图转换为三角形覆盖图的新边修改问题，提出了该问题的NP完备性，并提供了近似算法和针对特定图类的精确算法。


<details>
  <summary>Details</summary>
Motivation: 研究如何最小化修改图以满足特定结构属性，特别是将图转换为三角形覆盖图。

Method: 1. 提出三角形覆盖图的定义。 2. 证明了连接三角形覆盖图的最小边数下界，并刻画了达到最小边数的图。 3. 定义了$\Delta$-completion set，并证明了寻找大小不超过t的$\Delta$-completion set的决策问题是NP完全的。 4. 证明了该问题即使在输入限制为连通二分图时仍然是NP完全的。 5. 提供了几种图类（树、弦图、仙人掌图）的最小$\Delta$-completion set大小的紧界。 6. 提出了一个针对一般图的$(\ln n +1)$-近似算法。 7. 为树和弦图设计了计算最小$\Delta$-completion set的算法。 8. 证明了随机图$\mathbb{G}(n, p)$成为三角形覆盖图的阈值发生在$n^{-2/3}$。

Result: 1. 任意连通三角形覆盖图的最小边数下界为$n-1$（$n\geq 3$）。 2. 提出了判定问题NP完全的证明。 3. 提供了$(\ln n +1)$-近似算法。 4. 为树和弦图设计了精确算法。 5. 随机图$\mathbb{G}(n, p)$成为三角形覆盖图的阈值为$p = \Omega(n^{-2/3})$。

Conclusion: 该研究为三角形覆盖图问题提供了理论基础和有效的算法解决方案，并揭示了其在随机图中的阈值行为。

Abstract: The widely studied edge modification problems ask how to minimally alter a
graph to satisfy certain structural properties. In this paper, we introduce and
study a new edge modification problem centered around transforming a given
graph into a triangle-covered graph (one in which every vertex belongs to at
least one triangle). We first present tight lower bounds on the number of edges
in any connected triangle-covered graph of order $n$, and then we characterize
all connected graphs that attain this minimum edge count. For a graph $G$, we
define the notion of a $\Delta$-completion set as a set of non-edges of $G$
whose addition to $G$ results in a triangle-covered graph. We prove that the
decision problem of finding a $\Delta$-completion set of size at most $t\geq0$
is $\mathbb{NP}$-complete and does not admit a constant-factor approximation
algorithm under standard complexity assumptions. Moreover, we show that this
problem remains $\mathbb{NP}$-complete even when the input is restricted to
connected bipartite graphs. We then study the problem from an algorithmic
perspective, providing tight bounds on the minimum $\Delta$-completion set size
for several graph classes, including trees, chordal graphs, and cactus graphs.
Furthermore, we show that the triangle-covered problem admits an $(\ln n
+1)$-approximation algorithm for general graphs. For trees and chordal graphs,
we design algorithms that compute minimum $\Delta$-completion sets. Finally, we
show that the threshold for a random graph $\mathbb{G}(n, p)$ to be
triangle-covered occurs at $n^{-2/3}$.

</details>


### [244] [On the Smallest Size of Internal Collage Systems](https://arxiv.org/abs/2509.11602)
*Soichiro Migita,Kyotaro Uehata,Tomohiro I*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A Straight-Line Program (SLP) for a stirng $T$ is a context-free grammar in
Chomsky normal form that derives $T$ only, which can be seen as a compressed
form of $T$. Kida et al.\ introduced collage systems [Theor. Comput. Sci.,
2003] to generalize SLPs by adding repetition rules and truncation rules. The
smallest size $c(T)$ of collage systems for $T$ has gained attention to see how
these generalized rules improve the compression ability of SLPs. Navarro et al.
[IEEE Trans. Inf. Theory, 2021] showed that $c(T) \in O(z(T))$ and there is a
string family with $c(T) \in \Omega(b(T) \log |T|)$, where $z(T)$ is the number
of Lempel-Ziv parsing of $T$ and $b(T)$ is the smallest size of bidirectional
schemes for $T$. They also introduced a subclass of collage systems, called
internal collage systems, and proved that its smallest size $\hat{c}(T)$ for
$T$ is at least $b(T)$. While $c(T) \le \hat{c}(T)$ is obvious, it is unknown
how large $\hat{c}(T)$ is compared to $c(T)$. In this paper, we prove that
$\hat{c}(T) = \Theta(c(T))$ by showing that any collage system of size $m$ can
be transformed into an internal collage system of size $O(m)$ in $O(m^2)$ time.
Thanks to this result, we can focus on internal collage systems to study the
asymptotic behavior of $c(T)$, which helps to suppress excess use of truncation
rules. As a direct application, we get $b(T) = O(c(T))$, which answers an open
question posed in [Navarro et al., IEEE Trans. Inf. Theory, 2021]. We also give
a MAX-SAT formulation to compute $\hat{c}(T)$ for a given $T$.

</details>


### [245] [An ETH-Tight FPT Algorithm for Rejection-Proof Set Packing with Applications to Kidney Exchange](https://arxiv.org/abs/2509.11965)
*Bart M. P. Jansen,Jeroen S. K. Lamme,Ruben F. A. Verhaegh*

Main category: cs.DS

TL;DR: 该研究探讨了肾脏交换问题的多代理变体参数化复杂性。


<details>
  <summary>Details</summary>
Motivation: 多代理场景下的肾脏交换问题，要求找到一个不被任何代理拒绝的循环打包，并覆盖至少k个顶点。

Method: 利用了向日葵引理来解决问题的一个集合打包表述，为该问题提供了一个关于k多项式的核，且d为常数。在此基础上，还设计了一个时间复杂度为2^O(k log k) + n^O(1)的算法，并证明了该算法在ETH下是最优的。此外，还通过引入一个新参数c来推广了问题，当c为常数时，问题复杂度从Σ2P降至NP完全。研究还展示了c=1和c≥2时的复杂度差异，揭示了问题难度的来源。

Result: 得到了一个关于k多项式的核，以及一个与ETH相容的最优FPT算法。对于常数c，问题复杂度降为NP完全。c=1时存在单指数算法，而c≥2时问题复杂度与原问题相当。

Conclusion: 该研究深入分析了多代理肾脏交换问题的参数化复杂性，并揭示了参数c对问题难度的影响，展示了经典复杂度和参数化复杂度之间的有趣差异。

Abstract: We study the parameterized complexity of a recently introduced multi-agent
variant of the Kidney Exchange problem. Given a directed graph $G$ and integers
$d$ and $k$, the standard problem asks whether $G$ contains a packing of
vertex-disjoint cycles, each of length $\leq d$, covering at least $k$ vertices
in total. In the multi-agent setting we consider, the vertex set is partitioned
over several agents who reject a cycle packing as solution if it can be
modified into an alternative packing that covers more of their own vertices. A
cycle packing is called rejection-proof if no agent rejects it and the problem
asks whether such a packing exists that covers at least $k$ vertices.
  We exploit the sunflower lemma on a set packing formulation of the problem to
give a kernel for this $\Sigma_2^P$-complete problem that is polynomial in $k$
for all constant values of $d$. We also provide a $2^{\mathcal{O}(k \log k)} +
n^{\mathcal{O}(1)}$ algorithm based on it and show that this FPT algorithm is
asymptotically optimal under the ETH. Further, we generalize the problem by
including an additional positive integer $c$ in the input that naturally
captures how much agents can modify a given cycle packing to reject it. For
every constant $c$, the resulting problem simplifies from being
$\Sigma_2^P$-complete to NP-complete. With a single-exponential algorithm for
the setting where $c = 1$, we show this to be strictly easier under the ETH
than when $c = 2$. In turn, we show that any $c \geq 2$ yields a problem that
is essentially as hard as the original problem with $c$ unbounded. This
displays an interesting discrepancy between the classical and parameterized
complexity of the problem and gives a good view of what makes it hard.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [246] [Strategic Cyber Defense via Reinforcement Learning-Guided Combinatorial Auctions](https://arxiv.org/abs/2509.10983)
*Mai Pham,Vikrant Vaze,Peter Chin*

Main category: cs.GT

TL;DR: 使用组合拍卖来分配网络防御中的资源，并利用强化学习来评估价值。


<details>
  <summary>Details</summary>
Motivation: 网络防御需要长期战略规划，尤其是在不确定和资源有限的情况下。

Method: 提出了一种新的组合拍卖方法，使用强化学习（RL）的Q值来为防御行动包分配特定主机的估值，并训练了一个基于Transformer的可微分拍卖机制CAFormer。

Result: 该方法在实现具有竞争力的收入的同时，提供了对虚报的鲁棒性，并且分配模式与攻防活动相关，暗示了与运营优先级的隐性对齐。

Conclusion: 基于拍卖的规划在网络防御中是可行的，并且强化学习衍生的价值结构具有可解释性的优势。

Abstract: Cyber defense operations increasingly require long-term strategic planning
under uncertainty and resource constraints. We propose a new use of
combinatorial auctions for allocating defensive action bundles in a realistic
cyber environment, using host-specific valuations derived from reinforcement
learning (RL) Q-values. These Q-values encode long-term expected utility,
allowing upstream planning. We train CAFormer, a differentiable
Transformer-based auction mechanism, to produce allocations that are
approximately incentive-compatible under misreporting. Rather than benchmarking
against existing agents, we explore the qualitative and strategic properties of
the learned mechanisms. Compared to oracle and heuristic allocations, our
method achieves competitive revenue while offering robustness to misreporting.
In addition, we find that allocation patterns correlate with adversarial and
defensive activity, suggesting implicit alignment with operational priorities.
Our results demonstrate the viability of auction-based planning in cyber
defense and highlight the interpretability benefits of RL-derived value
structures.

</details>


### [247] [Actively Learning to Coordinate in Convex Games via Approximate Correlated Equilibrium](https://arxiv.org/abs/2509.10989)
*Zhenlong Fang,Aryan Deshwal,Yue Yu*

Main category: cs.GT

TL;DR: 此论文研究了在不知道玩家成本函数的情况下，协调员如何通过查询玩家的懊悔值来学习凸博弈中的相关均衡。


<details>
  <summary>Details</summary>
Motivation: 研究目标是让协调员在不知道玩家成本函数的情况下，学习到一种相关均衡策略，以指导玩家行为。

Method: 提出了一种学习框架，通过查询玩家的懊悔值（即偏离协调员建议所节省的成本）来学习近似相关均衡。具体来说，先选择有限的代表性联合动作，然后利用贝叶斯优化学习这些联合动作上的概率分布。

Result: 通过在共享交通网络中的多用户交通分配博弈上的数值实验进行了验证。

Conclusion: 所提出的方法能够通过最小化玩家的懊悔值来近似学习相关均衡，并在交通分配博弈中得到验证。

Abstract: Correlated equilibrium generalizes Nash equilibrium by allowing a central
coordinator to guide players' actions through shared recommendations, similar
to how routing apps guide drivers. We investigate how a coordinator can learn a
correlated equilibrium in convex games where each player minimizes a convex
cost function that depends on other players' actions, subject to convex
constraints without knowledge of the players' cost functions. We propose a
learning framework that learns an approximate correlated equilibrium by
actively querying players' regrets, \emph{i.e.}, the cost saved by deviating
from the coordinator's recommendations. We first show that a correlated
equilibrium in convex games corresponds to a joint action distribution over an
infinite joint action space that minimizes all players' regrets. To make the
learning problem tractable, we introduce a heuristic that selects finitely many
representative joint actions by maximizing their pairwise differences. We then
apply Bayesian optimization to learn a probability distribution over the
selected joint actions by querying all players' regrets. The learned
distribution approximates a correlated equilibrium by minimizing players'
regrets. We demonstrate the proposed approach via numerical experiments on
multi-user traffic assignment games in a shared transportation network.

</details>


### [248] [Identifying Imperfect Clones in Elections](https://arxiv.org/abs/2509.11261)
*Piotr Faliszewski,Lukasz Janeczko,Grzegorz Lisowski,Kristyna Pekarkova,Ildiko Schlotter*

Main category: cs.GT

TL;DR: 该论文研究了序数选举中的“完美克隆”及其放松概念（独立克隆、子选举克隆、近似克隆），并探讨了识别这些不完美克隆以及将候选人划分为不完美克隆家族的计算复杂性，包括参数化复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究序数选举中的完美克隆概念的放松形式，并分析识别这些不完美克隆及其相关问题的计算复杂性。

Method: 通过计算复杂性理论研究识别不完美克隆（独立克隆、子选举克隆、近似克隆）和将候选人划分为不完美克隆家族的问题，并分析其参数化复杂性。

Result: 确定了识别不完美克隆和将候选人划分为不完美克隆家族的计算复杂性，并研究了相关参数化问题。

Conclusion: 识别不完美克隆和将候选人划分为不完美克隆家族在计算上具有挑战性，其复杂性取决于各种参数，如投票者数量、克隆集大小和不完美程度。

Abstract: A perfect clone in an ordinal election (i.e., an election where the voters
rank the candidates in a strict linear order) is a set of candidates that each
voter ranks consecutively. We consider different relaxations of this notion:
independent or subelection clones are sets of candidates that only some of the
voters recognize as a perfect clone, whereas approximate clones are sets of
candidates such that every voter ranks their members close to each other, but
not necessarily consecutively. We establish the complexity of identifying such
imperfect clones, and of partitioning the candidates into families of imperfect
clones. We also study the parameterized complexity of these problems with
respect to a set of natural parameters such as the number of voters, the size
or the number of imperfect clones we are searching for, or their level of
imperfection.

</details>


### [249] [An Incentive-Compatible Reward Sharing Mechanism for Mitigating Mirroring Attacks in Decentralized Data-Feed Systems](https://arxiv.org/abs/2509.11294)
*Sina Aeeneh,Nikola Zlatanov,Jiangshan Yu*

Main category: cs.GT

TL;DR: 去中心化数据源系统易受镜像攻击，该攻击通过操纵多个预言机来影响聚合函数并最大化奖励。本文分析了镜像攻击对基于多数投票的数据源系统的影响，并提出了新的激励机制来防止此类攻击，最终达到纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 现有的数据源系统的激励机制容易受到镜像攻击，这会影响系统的可靠性和稳健性。

Method: 分析了镜像攻击对基于多数投票的数据源系统的影响，并提出了一种新的激励机制来对抗 Sybil 攻击。

Result: 证明了所提出的激励机制可以达到纳什均衡，在该均衡下，每个用户只操作一个预言机。

Conclusion: 提出的新激励机制可以有效阻止镜像攻击，提高系统的可靠性。

Abstract: Decentralized data-feed systems enable blockchain-based smart contracts to
access off-chain information by aggregating values from multiple oracles. To
improve accuracy, these systems typically use an aggregation function, such as
majority voting, to consolidate the inputs they receive from oracles and make a
decision. Depending on the final decision and the values reported by the
oracles, the participating oracles are compensated through shared rewards.
However, such incentive mechanisms are vulnerable to mirroring attacks, where a
single user controls multiple oracles to bias the decision of the aggregation
function and maximize rewards. This paper analyzes the impact of mirroring
attacks on the reliability and dependability of majority voting-based data-feed
systems. We demonstrate how existing incentive mechanisms can unintentionally
encourage rational users to implement such attacks. To address this, we propose
a new incentive mechanism that discourages Sybil behavior. We prove that the
proposed mechanism leads to a Nash Equilibrium in which each user operates only
one oracle. Finally, we discuss the practical implementation of the proposed
incentive mechanism and provide numerical examples to demonstrate its
effectiveness.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [250] [Proceedings 9th edition of Working Formal Methods Symposium](https://arxiv.org/abs/2509.11877)
*Andrei Arusoaie,Horaţiu Cheval,Radu Iosif*

Main category: cs.LO

TL;DR: 会议论文集


<details>
  <summary>Details</summary>
Motivation: 介绍会议信息

Method: 会议论文集

Result: 会议论文集

Conclusion: 会议论文集

Abstract: This volume contains the proceedings of the 9th Working Formal Methods
Symposium, which was held at the Alexandru Ioan Cuza University, Ia\c{s}i,
Romania on September 17-19, 2025.

</details>


### [251] [A Tree Clock Data Structure for Causal Orderings in Concurrent Executions](https://arxiv.org/abs/2201.06325)
*Umang Mathur,Andreas Pavlogiannis,Hünkar Can Tunç,Mahesh Viswanathan*

Main category: cs.LO

TL;DR: Tree clocks offer a more efficient alternative to vector clocks for causal ordering in concurrent program analysis, leading to significant performance improvements.


<details>
  <summary>Details</summary>
Motivation: Vector clocks, commonly used for causal ordering in dynamic analysis of concurrent programs, have a computational bottleneck due to their $\Theta(k)$ time complexity for join and copy operations, where k is the number of threads, making them inefficient for large numbers of threads.

Method: The paper introduces tree clocks, a novel data structure that replaces vector clocks. Tree clocks have join and copy operations whose time complexity is proportional to the number of modified entries, avoiding the $\Theta(k)$ cost. The paper demonstrates their optimality for computing the happens-before (HB) partial order and their versatility in computing other partial orders like schedulable-happens-before (SHB) and Mazurkiewicz (MAZ). Performance improvements were shown through experiments by replacing vector clocks with tree clocks.

Result: Experiments show that replacing vector clocks with tree clocks results in performance improvements ranging from 2.02x (for MAZ) to 2.66x (for SHB) and 2.97x (for HB) on average across benchmarks.

Conclusion: Tree clocks are a versatile and efficient data structure for computing causal orderings in concurrent program analysis, offering significant performance advantages over vector clocks and holding potential for wide application.

Abstract: Dynamic techniques are a scalable and effective way to analyze concurrent
programs. Instead of analyzing all behaviors of a program, these techniques
detect errors by focusing on a single program execution. Often a crucial step
in these techniques is to define a causal ordering between events in the
execution, which is then computed using vector clocks, a simple data structure
that stores logical times of threads. The two basic operations of vector
clocks, namely join and copy, require $\Theta(k)$ time, where $k$ is the number
of threads. Thus they are a computational bottleneck when $k$ is large.
  In this work, we introduce tree clocks, a new data structure that replaces
vector clocks for computing causal orderings in program executions. Joining and
copying tree clocks takes time that is roughly proportional to the number of
entries being modified, and hence the two operations do not suffer the a-priori
$\Theta(k)$ cost per application. We show that when used to compute the classic
happens-before (HB) partial order, tree clocks are optimal, in the sense that
no other data structure can lead to smaller asymptotic running time. Moreover,
we demonstrate that tree clocks can be used to compute other partial orders,
such as schedulable-happens-before (SHB) and the standard Mazurkiewicz (MAZ)
partial order, and thus are a versatile data structure. Our experiments show
that just by replacing vector clocks with tree clocks, the computation becomes
from $2.02 \times$ faster (MAZ) to $2.66 \times$ (SHB) and $2.97 \times$ (HB)
on average per benchmark. These results illustrate that tree clocks have the
potential to become a standard data structure with wide applications in
concurrent analyses.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [252] [Situation Model of the Transport, Transport Emissions and Meteorological Conditions](https://arxiv.org/abs/2509.10541)
*V. Benes,M. Svitek,A. Michalikova,M. Melicherik*

Main category: cs.AI

TL;DR: 本文使用模糊推理系统（FIS）分析了布拉格的交通排放与气象条件的关系，为城市规划者和决策者提供了更有效的城市交通管理和环境保护的见解。


<details>
  <summary>Details</summary>
Motivation: 解决城市空气污染问题，特别是交通排放及其与气象条件的相互作用。

Method: 使用模糊推理系统（FIS）开发了一个模型，该模型基于在捷克共和国布拉格测量的交通、气象和排放数据，用于预测不同条件下的排放变化。

Result: 提出了一个基于模糊推理系统的模型，分析了天气对城市交通排放量和扩散的影响。

Conclusion: 该模型旨在为城市规划者和决策者提供有关如何更有效地规划和管理城市交通以保护环境的见解。

Abstract: Air pollution in cities and the possibilities of reducing this pollution
represents one of the most important factors that today's society has to deal
with. This paper focuses on a systemic approach to traffic emissions with their
relation to meteorological conditions, analyzing the effect of weather on the
quantity and dispersion of traffic emissions in a city. Using fuzzy inference
systems (FIS) the model for prediction of changes in emissions depending on
various conditions is developed. The proposed model is based on traffic,
meteorology and emission data measured in Prague, Czech Republic. The main
objective of the work is to provide insight into how urban planners and
policymakers can plan and manage urban transport more effectively with
environmental protection in mind.

</details>


### [253] [Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics](https://arxiv.org/abs/2509.11943)
*Antonin Sulc,Thorsten Hellert*

Main category: cs.AI

TL;DR: 在包含复杂、不断变化的数据的环境中，需要能够进行自主决策的智能代理。虽然大型语言模型（LMs）在各种环境中表现出色，但我们认为，增强其推理结构、保真度和逻辑一致性是人工智能研究的一个关键但被忽视的领域。


<details>
  <summary>Details</summary>
Motivation: 目前的人工智能研究主要关注模型和数据集的扩展，而忽视了在复杂环境中代理推理的结构、保真度和逻辑一致性的增强，这对于开发更可靠的自主代理至关重要。

Method: 提出了一种神经符号多代理体系结构，其中代理的信念状态被形式化为克里普克模型，并使用模态逻辑进行推理。该模型结合了大型语言模型（LMs）的语义理解能力和模态逻辑的严格验证能力，并通过领域知识的逻辑约束来指导假设生成，防止不合乎逻辑或物理的结论。

Result: 该系统成功地在模拟粒子加速器环境中诊断了复杂的、级联的故障，证明了结合大型语言模型（LMs）的直觉推理和模态逻辑的严谨验证的有效性。

Conclusion: 将大型语言模型（LMs）的强大语义理解能力与模态逻辑的严格、可验证的验证相结合，并辅以事实世界模型，为实现更强大、更可靠、可验证的自主代理指明了可行的方向。

Abstract: The development of intelligent agents, particularly those powered by language
models (LMs), has shown the critical role in various environments that require
intelligent and autonomous decision. Environments are not passive testing
grounds and they represent the data required for agents to learn and exhibit
very challenging conditions that require adaptive, complex and autonomous
capacity to make decisions. While the paradigm of scaling models and datasets
has led to remarkable emergent capabilities, we argue that scaling the
structure, fidelity, and logical consistency of agent reasoning within these
environments is a crucial, yet underexplored, dimension of AI research. This
paper introduces a neuro-symbolic multi-agent architecture where the belief
states of individual agents are formally represented as Kripke models. This
foundational choice enables them to reason about known concepts of
\emph{possibility} and \emph{necessity} using the formal language of modal
logic. In this work, we use of immutable, domain-specific knowledge to make
infere information, which is encoded as logical constraints essential for
proper diagnosis. In the proposed model, we show constraints that actively
guide the hypothesis generation of LMs, effectively preventing them from
reaching physically or logically untenable conclusions. In a high-fidelity
simulated particle accelerator environment, our system successfully diagnoses
complex, cascading failures by combining the powerful semantic intuition of LMs
with the rigorous, verifiable validation of modal logic and a factual world
model and showcasing a viable path toward more robust, reliable, and verifiable
autonomous agents.

</details>


### [254] [ZapGPT: Free-form Language Prompting for Simulated Cellular Control](https://arxiv.org/abs/2509.10660)
*Nam H. Le,Patrick Erickson,Yanbo Zhang,Michael Levin,Josh Bongard*

Main category: cs.AI

TL;DR: AI模型可以通过自然语言指令来引导AI或生物系统的集体行为，无需针对特定任务进行调整或设计评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有系统在理解和响应自然语言方面存在不足，限制了其在控制复杂系统中的应用。本研究旨在探索仅通过自由格式的自然语言来指导人工智能或生物群体的行为，以实现更自然的控制形式。

Method: 提出了一种新方法，其中一个AI模型将自然语言指令转化为对模拟细胞的干预措施，另一个AI模型评估细胞动态与指令的匹配程度，并通过进化优化第一个AI模型以提高评分。

Result: 该系统能够仅通过自由格式的自然语言提示来指导简单代理的集体行为，并且在没有重新训练的情况下能够泛化到未见过的提示。

Conclusion: 本研究证明了自然语言可以作为一种控制层，指导AI、机器人或生物系统实现期望的行为，为AI与生物学结合的未来提供了方向，使语言能够取代数学目标函数、固定规则和特定领域的编程。

Abstract: Human language is one of the most expressive tools for conveying intent, yet
most artificial or biological systems lack mechanisms to interpret or respond
meaningfully to it. Bridging this gap could enable more natural forms of
control over complex, decentralized systems. In AI and artificial life, recent
work explores how language can specify high-level goals, but most systems still
depend on engineered rewards, task-specific supervision, or rigid command sets,
limiting generalization to novel instructions. Similar constraints apply in
synthetic biology and bioengineering, where the locus of control is often
genomic rather than environmental perturbation.
  A key open question is whether artificial or biological collectives can be
guided by free-form natural language alone, without task-specific tuning or
carefully designed evaluation metrics. We provide one possible answer here by
showing, for the first time, that simple agents' collective behavior can be
guided by free-form language prompts: one AI model transforms an imperative
prompt into an intervention that is applied to simulated cells; a second AI
model scores how well the prompt describes the resulting cellular dynamics; and
the former AI model is evolved to improve the scores generated by the latter.
  Unlike previous work, our method does not require engineered fitness
functions or domain-specific prompt design. We show that the evolved system
generalizes to unseen prompts without retraining. By treating natural language
as a control layer, the system suggests a future in which spoken or written
prompts could direct computational, robotic, or biological systems to desired
behaviors. This work provides a concrete step toward this vision of AI-biology
partnerships, in which language replaces mathematical objective functions,
fixed rules, and domain-specific programming.

</details>


### [255] [Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration](https://arxiv.org/abs/2509.10704)
*Xingchen Wan,Han Zhou,Ruoxi Sun,Hootan Nakhost,Ke Jiang,Rajarishi Sinha,Sercan Ö. Arık*

Main category: cs.AI

TL;DR: Maestro是一个创新的自进化文本到图像生成系统，通过多模态LLM代理进行自我批评和自我进化，无需人工干预即可显著提高图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到图像（T2I）模型高度依赖人工干预，需要手动迭代优化提示词，这带来了显著的可用性挑战。

Method: Maestro系统包含两个关键创新：1）自我批评：使用多模态LLM（MLLM）代理作为“批评者”来识别生成图像的弱点，修正不充分的描述，并提供可解释的编辑信号，然后由“验证者”代理在保留用户意图的同时整合这些信号。2）自我进化：利用MLLM作为“裁判”对迭代生成的图像进行头对头比较，剔除问题图像，并进化出符合用户意图的创意提示词候选。

Result: 在复杂T2I任务上的大量实验表明，Maestro显著提高了图像质量，优于初始提示词和最先进的自动方法，并且其有效性随着更高级的MLLM组件的集成而扩展。

Conclusion: 该研究提出了一种强大、可解释且有效的实现自改进T2I生成的方法。

Abstract: Text-to-image (T2I) models, while offering immense creative potential, are
highly reliant on human intervention, posing significant usability challenges
that often necessitate manual, iterative prompt engineering over often
underspecified prompts. This paper introduces Maestro, a novel self-evolving
image generation system that enables T2I models to autonomously self-improve
generated images through iterative evolution of prompts, using only an initial
prompt. Maestro incorporates two key innovations: 1) self-critique, where
specialized multimodal LLM (MLLM) agents act as 'critics' to identify
weaknesses in generated images, correct for under-specification, and provide
interpretable edit signals, which are then integrated by a 'verifier' agent
while preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge
for head-to-head comparisons between iteratively generated images, eschewing
problematic images, and evolving creative prompt candidates that align with
user intents. Extensive experiments on complex T2I tasks using black-box models
demonstrate that Maestro significantly improves image quality over initial
prompts and state-of-the-art automated methods, with effectiveness scaling with
more advanced MLLM components. This work presents a robust, interpretable, and
effective pathway towards self-improving T2I generation.

</details>


### [256] [Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions](https://arxiv.org/abs/2509.10707)
*Sajjad Abdoli,Rudi Cilibrasi,Rima Al-Shikh*

Main category: cs.AI

TL;DR: AI评估者（GPT-4o, GPT-4o-mini, GPT-5）具有独特的“评估个性”，评估策略和偏差各不相同。GPT-4o-mini最稳定，GPT-4o擅长纠错，GPT-5最保守但变异性高。GPT模型普遍存在2:1的负面评估偏见，且这种偏见似乎特定于模型家族。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地评估其他AI的输出，理解其评估行为对于防止级联偏差至关重要。

Method: 分析了NVIDIA的Describe Anything Model生成的、并由GPT-4o, GPT-4o-mini, GPT-5评估的视觉-语言描述，以揭示每种模型展示的独特的“评估个性”、潜在的评估策略和偏差。使用Gemini 2.5 Pro作为独立问题生成器进行可控实验，并通过生成问题的语义相似性进行跨模型家族分析。

Result: GPT-4o-mini表现出系统性的一致性，变异性最小；GPT-4o擅长错误检测；GPT-5表现出极端保守性，变异性高。实验验证了这些个性是模型固有的属性。GPT模型评估策略高度相似，而Gemini则显著不同。所有GPT模型都表现出2:1的负面评估偏见。

Conclusion: 评估能力不随通用能力扩展而扩展，健壮的AI评估需要多样化的架构视角。

Abstract: As AI systems increasingly evaluate other AI outputs, understanding their
assessment behavior becomes crucial for preventing cascading biases. This study
analyzes vision-language descriptions generated by NVIDIA's Describe Anything
Model and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to
uncover distinct "evaluation personalities" the underlying assessment
strategies and biases each model demonstrates. GPT-4o-mini exhibits systematic
consistency with minimal variance, GPT-4o excels at error detection, while
GPT-5 shows extreme conservatism with high variability. Controlled experiments
using Gemini 2.5 Pro as an independent question generator validate that these
personalities are inherent model properties rather than artifacts. Cross-family
analysis through semantic similarity of generated questions reveals significant
divergence: GPT models cluster together with high similarity while Gemini
exhibits markedly different evaluation strategies. All GPT models demonstrate a
consistent 2:1 bias favoring negative assessment over positive confirmation,
though this pattern appears family-specific rather than universal across AI
architectures. These findings suggest that evaluation competence does not scale
with general capability and that robust AI assessment requires diverse
architectural perspectives.

</details>


### [257] [AI Answer Engine Citation Behavior An Empirical Analysis of the GEO16 Framework](https://arxiv.org/abs/2509.10762)
*Arlen Kumar,Leanid Palkhouski*

Main category: cs.AI

TL;DR: AI answer engines 的引用来源网页质量会影响引用，GEO-16 审计框架可评估网页质量。


<details>
  <summary>Details</summary>
Motivation: 评估 AI 答案引擎所引用网页的质量，并找出影响引用的因素，为发布商提供改进建议。

Method: 使用 GEO-16 框架，对来自 Brave Summary、Google AI Overviews 和 Perplexity 三个引擎的 1702 个引用进行审计，分析了 1100 个唯一 URL 的网页质量信号，并建立了预测模型。

Result: AI 引擎引用的网页质量存在差异，其中元数据、新鲜度、语义化 HTML 和结构化数据与引用最相关。网页整体质量是引用强有力的预测因子，设定质量阈值（如 G ≥ 0.70 且至少 12 个 pillar 达标）可显著提高引用率。

Conclusion: AI 答案引擎的引用来源网页质量很重要，发布商可以通过优化网页质量来提高被引用的可能性。GEO-16 框架和提出的策略可用于指导发布商改进其网页。

Abstract: AI answer engines increasingly mediate access to domain knowledge by
generating responses and citing web sources. We introduce GEO-16, a 16 pillar
auditing framework that converts on page quality signals into banded pillar
scores and a normalized GEO score G that ranges from 0 to 1. Using 70 product
intent prompts, we collected 1,702 citations across three engines (Brave
Summary, Google AI Overviews, and Perplexity) and audited 1,100 unique URLs. In
our corpus, the engines differed in the GEO quality of the pages they cited,
and pillars related to Metadata and Freshness, Semantic HTML, and Structured
Data showed the strongest associations with citation. Logistic models with
domain clustered standard errors indicate that overall page quality is a strong
predictor of citation, and simple operating points (for example, G at least
0.70 combined with at least 12 pillar hits) align with substantially higher
citation rates in our data. We report per engine contrasts, vertical effects,
threshold analysis, and diagnostics, then translate findings into a practical
playbook for publishers. The study is observational and focuses on English
language B2B SaaS pages; we discuss limitations, threats to validity, and
reproducibility considerations.

</details>


### [258] [AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise](https://arxiv.org/abs/2509.10769)
*Tara Bogavelli,Roshnee Sharma,Hari Subramani*

Main category: cs.AI

TL;DR: 本研究评估了18种不同的智能体配置在不同的大型语言模型上的表现，并提出了一个企业特定基准。研究结果表明，目前智能体AI系统的设计存在“一刀切”的问题，并且在企业任务上的表现有待提高。


<details>
  <summary>Details</summary>
Motivation: 目前对智能体架构的不同设计维度如何相互作用缺乏实证理解，本研究旨在解决这些差距。

Method: 本研究通过一个全面的企业特定基准，评估了18种不同的智能体配置在不同的LLM上的表现，考察了四种关键的智能体系统维度：协调策略、智能体提示实现（ReAct vs 功能调用）、记忆架构和思维工具集成。

Result: 研究结果显示，模型在架构偏好上存在显著差异，并且在企业任务上的整体智能体表现存在显著弱点，得分最高的模型在复杂任务上的成功率最高为35.3%，在简单任务上的成功率为70.8%。

Conclusion: 本研究的结果有望为未来智能体系统的设计提供信息，通过在架构组件和模型选择方面做出更实证的决策。

Abstract: While individual components of agentic architectures have been studied in
isolation, there remains limited empirical understanding of how different
design dimensions interact within complex multi-agent systems. This study aims
to address these gaps by providing a comprehensive enterprise-specific
benchmark evaluating 18 distinct agentic configurations across state-of-the-art
large language models. We examine four critical agentic system dimensions:
orchestration strategy, agent prompt implementation (ReAct versus function
calling), memory architecture, and thinking tool integration. Our benchmark
reveals significant model-specific architectural preferences that challenge the
prevalent one-size-fits-all paradigm in agentic AI systems. It also reveals
significant weaknesses in overall agentic performance on enterprise tasks with
the highest scoring models achieving a maximum of only 35.3\% success on the
more complex task and 70.8\% on the simpler task. We hope these findings inform
the design of future agentic systems by enabling more empirically backed
decisions regarding architectural components and model selection.

</details>


### [259] [Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs](https://arxiv.org/abs/2509.11480)
*Amir Taherin,Juyi Lin,Arash Akbari,Arman Akbari,Pu Zhao,Weiwei Chen,David Kaeli,Yanzhi Wang*

Main category: cs.AI

TL;DR: 该论文评估了五种视觉-语言-动作（VLA）模型在边缘和数据中心GPU平台上的性能扩展、功耗和系统级指标。研究发现，架构选择会影响吞吐量和内存占用，边缘设备在功耗限制下表现出非线性性能下降，并且可以在不显著损失精度的情况下实现高吞吐量。这表明在机器人推理方面，数据中心硬件并非总是最优选择。


<details>
  <summary>Details</summary>
Motivation: 评估视觉-语言-动作（VLA）模型在不同硬件平台和功耗预算下的性能扩展，并为模型选择和优化提供指导。

Method: 在LIBERO基准测试中，评估了五种VLA模型（包括现有基线和两种新架构）在边缘和数据中心GPU上的准确性、延迟、吞吐量和峰值内存使用量，并考虑了不同的功耗限制。

Result: （1）架构选择（如动作分词和模型主干大小）显著影响吞吐量和内存占用；（2）功耗受限的边缘设备性能下降呈非线性，某些配置可媲美甚至超越旧式数据中心GPU；（3）可以在不显著损失精度的前提下实现高吞吐量。

Conclusion: 架构选择对VLA模型的性能有重要影响，并且在某些情况下，边缘设备可以提供与数据中心相当甚至更好的性能。该研究为在不同部署约束下选择和优化VLA模型提供了实用见解，并对数据中心硬件在机器人推理方面的优越性提出了质疑。

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist
policies for robotic control, yet their performance scaling across model
architectures and hardware platforms, as well as their associated power
budgets, remain poorly understood. This work presents an evaluation of five
representative VLA models -- spanning state-of-the-art baselines and two newly
proposed architectures -- targeting edge and datacenter GPU platforms. Using
the LIBERO benchmark, we measure accuracy alongside system-level metrics,
including latency, throughput, and peak memory usage, under varying edge power
constraints and high-performance datacenter GPU configurations. Our results
identify distinct scaling trends: (1) architectural choices, such as action
tokenization and model backbone size, strongly influence throughput and memory
footprint; (2) power-constrained edge devices exhibit non-linear performance
degradation, with some configurations matching or exceeding older datacenter
GPUs; and (3) high-throughput variants can be achieved without significant
accuracy loss. These findings provide actionable insights when selecting and
optimizing VLAs across a range of deployment constraints. Our work challenges
current assumptions about the superiority of datacenter hardware for robotic
inference.

</details>


### [260] [LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering](https://arxiv.org/abs/2509.10818)
*Boris Kovalerchuk,Brent D. Fegley*

Main category: cs.AI

TL;DR: LLMs在决策支持方面有潜力，但存在数据缺失和幻觉问题。RAG有所改善，但仍不完美。本文提出一种基于人机对话和布尔函数的技术，通过四步算法（因子识别、层级构建、通用EMM规范生成、详细EMM生成）为LLM创建优化的提示工程，以解决复杂决策问题，并以评估是否响应提案征集为例进行说明。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM在处理缺失数据、决策支持方面的局限性，以及在复杂任务中设计有效提示的挑战。

Method: 提出一种基于优化的“人-机对话”和“单调布尔/k-值函数”的技术，以发现计算上可行的“专家心智模型”（EMM）。该EMM算法包含四个步骤：因子识别、因子层级结构化、通用EMM规范生成、详细通用EMM生成。

Result: 开发了一种用于LLM提示工程的EMM算法，能够更有效地处理具有缺失信息的决策问题。

Conclusion: 通过优化的“人-机对话”和“专家心智模型”方法，可以克服LLM在复杂决策任务中的不足，提高决策效率和准确性。

Abstract: Difficult decision-making problems abound in various disciplines and domains.
The proliferation of generative techniques, especially large language models
(LLMs), has excited interest in using them for decision support. However, LLMs
cannot yet resolve missingness in their training data, leading to
hallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by
incorporating external information retrieval, reducing hallucinations and
improving accuracy. Yet, RAG and related methods are only partial solutions, as
they may lack access to all necessary sources or key missing information. Even
everyday issues often challenge LLMs' abilities. Submitting longer prompts with
context and examples is one approach to address knowledge gaps, but designing
effective prompts is non-trivial and may not capture complex mental models of
domain experts. For tasks with missing critical information, LLMs are
insufficient, as are many existing systems poorly represented in available
documents. This paper explores how LLMs can make decision-making more
efficient, using a running example of evaluating whether to respond to a call
for proposals. We propose a technology based on optimized human-machine
dialogue and monotone Boolean and k-valued functions to discover a
computationally tractable personal expert mental model (EMM) of
decision-making. Our EMM algorithm for LLM prompt engineering has four steps:
(1) factor identification, (2) hierarchical structuring of factors, (3)
generating a generalized expert mental model specification, and (4) generating
a detailed generalized expert mental model from that specification.

</details>


### [261] [From Grounding to Skolemization: A Logic-Constrained Vector Symbolic Architecture for Complex Query Answering](https://arxiv.org/abs/2509.10837)
*Yuyin Lu,Hegang Chen,Yanghui Rao*

Main category: cs.AI

TL;DR: 复杂查询问答（CQA）在不完整的知识图谱（KGs）上，通常以带有单个自由变量的存在一阶谓词逻辑（EFO1）形式化，在逻辑可靠性和计算效率之间存在根本性的权衡。本文提出地面化-斯科伦化二分法，通过形式逻辑的角度系统地分析CQA方法。地面化方法固有地遭受组合爆炸，而大多数斯科伦化方法忽略了明确的模型斯科伦函数，并损害了逻辑一致性。为了解决这些限制，我们提出了逻辑约束向量符号架构（LVSA），一个神经符号框架，它统一了一个可微分的斯科伦化模块和一个神经否定器，以及一个逻辑约束驱动的优化协议来协调几何和逻辑要求。理论上，LVSA保证了所有EFO1查询的通用性。经验上，它的性能优于最先进的斯科伦化方法，并比地面化方法降低了几个数量级的推理成本。


<details>
  <summary>Details</summary>
Motivation: 解决在不完整的知识图谱上进行复杂查询问答（CQA）时，逻辑可靠性和计算效率之间的权衡问题。现有的地面化方法计算成本高昂，而斯科伦化方法在逻辑一致性上存在不足。

Method: 提出逻辑约束向量符号架构（LVSA），一个神经符号框架。该框架包含一个可微分的斯科伦化模块、一个神经否定器和一个逻辑约束驱动的优化协议，旨在统一几何和逻辑要求，并保证EFO1查询的通用性。

Result: LVSA在理论上保证了对所有EFO1查询的通用性。在实践中，它在性能上超越了现有的斯科伦化方法，并将推理成本相比地面化方法降低了几个数量级。

Conclusion: LVSA是一个有效的神经符号框架，能够解决在不完整知识图谱上的复杂查询问答问题，它在逻辑可靠性和计算效率之间取得了良好的平衡。

Abstract: Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs),
typically formalized as reasoning with Existential First-Order predicate logic
with one free variable (EFO$_1$), faces a fundamental trade-off between logical
soundness and computational efficiency. This work establishes the
Grounding-Skolemization dichotomy for systematically analyzing CQA methods
through the lens of formal logic. While Grounding-based methods inherently
suffer from combinatorial explosion, most Skolemization-based methods neglect
to explicitly model Skolem functions and compromise logical consistency. To
address these limitations, we propose the Logic-constrained Vector Symbolic
Architecture (LVSA), a neuro-symbolic framework that unifies a differentiable
Skolemization module and a neural negator, as well as a logical
constraint-driven optimization protocol to harmonize geometric and logical
requirements. Theoretically, LVSA guarantees universality for all EFO$_1$
queries. Empirically, it outperforms state-of-the-art Skolemization-based
methods and reduces inference costs by orders of magnitude compared to
Grounding-based baselines.

</details>


### [262] [Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration](https://arxiv.org/abs/2509.11067)
*Liangxuan Guo,Bin Zhu,Qingqian Tao,Kangning Liu,Xun Zhao,Xianzhe Qin,Jin Gao,Guangfu Hao*

Main category: cs.AI

TL;DR: Agentic Lybic是一个创新的多智能体系统，采用有限状态机（FSM）实现复杂的桌面自动化任务，并在OSWorld基准测试中取得了57.07%的成功率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有自主桌面自动化代理在处理复杂多步任务时协调性差和质量控制不足的问题。

Method: 提出Agentic Lybic多智能体系统，其核心是一个有限状态机（FSM）架构，用于动态编排四个组件（控制器、管理器、三个工作节点——技术员、操作员、分析员——以及评估器）。FSM驱动组件间的路由，实现对每个子任务的最优执行策略动态选择，并通过质量门控实现自适应重规划和错误恢复。

Result: 在OSWorld基准测试中，Agentic Lybic在50步内实现了57.07%的成功率，显著超越了现有方法。

Conclusion: 基于原则的多智能体编排与持续的质量控制相结合，能够为复杂计算环境中的通用桌面自动化提供卓越的可靠性。

Abstract: Autonomous agents for desktop automation struggle with complex multi-step
tasks due to poor coordination and inadequate quality control. We introduce
\textsc{Agentic Lybic}, a novel multi-agent system where the entire
architecture operates as a finite-state machine (FSM). This core innovation
enables dynamic orchestration. Our system comprises four components: a
Controller, a Manager, three Workers (Technician for code-based operations,
Operator for GUI interactions, and Analyst for decision support), and an
Evaluator. The critical mechanism is the FSM-based routing between these
components, which provides flexibility and generalization by dynamically
selecting the optimal execution strategy for each subtask. This principled
orchestration, combined with robust quality gating, enables adaptive replanning
and error recovery. Evaluated officially on the OSWorld benchmark,
\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\% success rate in 50
steps, substantially outperforming existing methods. Results demonstrate that
principled multi-agent orchestration with continuous quality control provides
superior reliability for generalized desktop automation in complex computing
environments.

</details>


### [263] [Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?](https://arxiv.org/abs/2509.10875)
*Jesse Gardner,Vladimir A. Baulin*

Main category: cs.AI

TL;DR: 该论文批判性地重新评估了AI研究中的“智能体”范式，认为其概念模糊和拟人化偏见可能构成限制。文章区分了智能体系统、具身系统和非智能体系统，并建议将研究重点从“智能体”转向更关注系统动力学、世界模型和物质智能的框架，以促进通用人工智能的发展。


<details>
  <summary>Details</summary>
Motivation: AI研究中的“智能体”范式虽然被广泛应用，但其概念模糊和拟人化偏见可能限制了AI的发展。

Method: 通过对相关文献进行系统性回顾，解构了不同AI框架下的智能体范式，并分析了自主性和目标导向性等属性的测量挑战。

Result: “智能体”的框架在解释LLM等AI系统时可能具有误导性，模糊了底层的计算机制。文章提出了一种替代方案，将研究重点转向系统动力学、世界模型和物质智能。

Conclusion: 为了实现鲁棒、可扩展且可能非拟人化的通用智能，需要超越“智能体”隐喻，探索非智能体和系统性框架，并重新思考智能的本质。

Abstract: The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI)
research, guiding development from foundational theories to contemporary
applications like Large Language Model (LLM)-based systems. This paper
critically re-evaluates the necessity and optimality of this agent-centric
paradigm. We argue that its persistent conceptual ambiguities and inherent
anthropocentric biases may represent a limiting framework. We distinguish
between agentic systems (AI inspired by agency, often semi-autonomous, e.g.,
LLM-based agents), agential systems (fully autonomous, self-producing systems,
currently only biological), and non-agentic systems (tools without the
impression of agency). Our analysis, based on a systematic review of relevant
literature, deconstructs the agent paradigm across various AI frameworks,
highlighting challenges in defining and measuring properties like autonomy and
goal-directedness. We argue that the 'agentic' framing of many AI systems,
while heuristically useful, can be misleading and may obscure the underlying
computational mechanisms, particularly in Large Language Models (LLMs). As an
alternative, we propose a shift in focus towards frameworks grounded in
system-level dynamics, world modeling, and material intelligence. We conclude
that investigating non-agentic and systemic frameworks, inspired by complex
systems, biology, and unconventional computing, is essential for advancing
towards robust, scalable, and potentially non-anthropomorphic forms of general
intelligence. This requires not only new architectures but also a fundamental
reconsideration of our understanding of intelligence itself, moving beyond the
agent metaphor.

</details>


### [264] [Neural cellular automata: applications to biology and beyond classical AI](https://arxiv.org/abs/2509.11131)
*Benedikt Hartl,Michael Levin,Léo Pio-Lopez*

Main category: cs.AI

TL;DR: 神经网络细胞自动机（NCA）是一种模仿生物自组织过程的强大计算模型，它使用可训练的神经网络作为局部决策单元，模拟从分子到系统级别的各种生物现象，并在机器人控制和人工智能推理等领域展现出潜力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在回顾和强调神经网络细胞自动机（NCA）在生物和生物工程应用中的最新进展，并探讨其在更广泛领域的潜力，如机器人学和人工智能。

Method: 通过嵌入人工神经网络（ANNs）作为局部决策中心和交互规则，NCA能够模拟跨越不同尺度的生物过程，并具有可训练、可微分（或可演化）的更新规则。

Result: NCA能够成功复现生物目标模式，泛化到新的条件，展现出对扰动的鲁棒性，并具有开放式适应和推理能力。此外，NCA在机器人形态控制与再生以及人工智能推理任务（如ARC-AGI-1）中也表现出色。

Conclusion: NCA作为一种统一的、计算效率高的范式，不仅连接了多尺度生物学和现代生成式人工智能，还有潜力设计出能够进行层次化推理和控制的、真正受生物启发的集体智能。

Abstract: Neural Cellular Automata (NCA) represent a powerful framework for modeling
biological self-organization, extending classical rule-based systems with
trainable, differentiable (or evolvable) update rules that capture the adaptive
self-regulatory dynamics of living matter. By embedding Artificial Neural
Networks (ANNs) as local decision-making centers and interaction rules between
localized agents, NCA can simulate processes across molecular, cellular,
tissue, and system-level scales, offering a multiscale competency architecture
perspective on evolution, development, regeneration, aging, morphogenesis, and
robotic control. These models not only reproduce biologically inspired target
patterns but also generalize to novel conditions, demonstrating robustness to
perturbations and the capacity for open-ended adaptation and reasoning. Given
their immense success in recent developments, we here review current literature
of NCAs that are relevant primarily for biological or bioengineering
applications. Moreover, we emphasize that beyond biology, NCAs display robust
and generalizing goal-directed dynamics without centralized control, e.g., in
controlling or regenerating composite robotic morphologies or even on
cutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same
principles of iterative state-refinement is reminiscent to modern generative
Artificial Intelligence (AI), such as probabilistic diffusion models. Their
governing self-regulatory behavior is constraint to fully localized
interactions, yet their collective behavior scales into coordinated
system-level outcomes. We thus argue that NCAs constitute a unifying
computationally lean paradigm that not only bridges fundamental insights from
multiscale biology with modern generative AI, but have the potential to design
truly bio-inspired collective intelligence capable of hierarchical reasoning
and control.

</details>


### [265] [Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding](https://arxiv.org/abs/2509.10931)
*Seongho Joo,Hyukhun Koh,Kyomin Jung*

Main category: cs.AI

TL;DR: HaPLa是一种新的、通用的、仅需黑盒访问的LLM越狱技术，它通过“ the abductive framing”和“symbolic encoding”策略来规避LLM的有害内容检测，实现了95%的GPT系列模型和70%的平均攻击成功率，同时揭示了在不损害其有用性的情况下安全调整LLM的挑战。


<details>
  <summary>Details</summary>
Motivation: LLMs的潜在滥用是一个重大问题，需要研究通用的越狱攻击来加强防御。

Method: 提出了一种名为HaPLa的新型越狱技术，包括“abductive framing”（诱导LLM推断有害活动步骤）和“symbolic encoding”（混淆有害内容）。

Result: HaPLa在GPT系列模型上实现了超过95%的攻击成功率，在所有目标模型上平均成功率达到70%。

Conclusion: 研究表明，在不显著降低LLM对良性查询响应能力的情况下，对其进行安全调整仍然是一个根本性的挑战。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, but their potential misuse for harmful purposes remains a
significant concern. To strengthen defenses against such vulnerabilities, it is
essential to investigate universal jailbreak attacks that exploit intrinsic
weaknesses in the architecture and learning paradigms of LLMs. In response, we
propose \textbf{H}armful \textbf{P}rompt \textbf{La}undering (HaPLa), a novel
and broadly applicable jailbreaking technique that requires only black-box
access to target models. HaPLa incorporates two primary strategies: 1)
\textit{abductive framing}, which instructs LLMs to infer plausible
intermediate steps toward harmful activities, rather than directly responding
to explicit harmful queries; and 2) \textit{symbolic encoding}, a lightweight
and flexible approach designed to obfuscate harmful content, given that current
LLMs remain sensitive primarily to explicit harmful keywords. Experimental
results show that HaPLa achieves over 95% attack success rate on GPT-series
models and 70% across all targets. Further analysis with diverse symbolic
encoding rules also reveals a fundamental challenge: it remains difficult to
safely tune LLMs without significantly diminishing their helpfulness in
responding to benign queries.

</details>


### [266] [Public Data Assisted Differentially Private In-Context Learning](https://arxiv.org/abs/2509.10932)
*Seongho Joo,Hyukhun Koh,Kyomin Jung*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）中的上下文学习（ICL）在各种任务中表现出色，无需进行微调。然而，最近的研究表明，ICL中的提示存在私有数据泄露的风险，尤其是在LLM暴露于恶意攻击时。虽然差分隐私（DP）提供了强大的隐私保证，但它通常会显著降低ICL的效用。为了应对这一挑战，我们在保持DP保证的同时，将与任务相关的公共数据纳入ICL框架。在此方法的基础上，我们提出了一种私有的上下文学习算法，可以有效地平衡隐私保护和模型效用。通过实验，我们证明了我们的方法在公共数据的辅助下，显著提高了私有ICL的效用。此外，我们还表明我们的方法能够抵御成员推理攻击，并提供了经验上的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文学习（ICL）方法在大型语言模型（LLM）中表现出色，但存在私有数据泄露的风险。差分隐私（DP）虽然能提供隐私保护，但会显著降低ICL的效用。

Method: 将与任务相关的公共数据纳入ICL框架，同时保持DP保证，提出一种私有的上下文学习算法。

Result: 所提出的方法在公共数据的辅助下，显著提高了私有ICL的效用，并能有效抵御成员推理攻击，提供了经验上的隐私保护。

Conclusion: 在ICL框架中引入公共数据并结合DP保证，可以在保护隐私的同时有效提高LLM的效用，并能抵御恶意攻击。

Abstract: In-context learning (ICL) in Large Language Models (LLMs) has shown
remarkable performance across various tasks without requiring fine-tuning.
However, recent studies have highlighted the risk of private data leakage
through the prompt in ICL, especially when LLMs are exposed to malicious
attacks. While differential privacy (DP) provides strong privacy guarantees, it
often significantly reduces the utility of in-context learning (ICL). To
address this challenge, we incorporate task-related public data into the ICL
framework while maintaining the DP guarantee. Based on this approach, we
propose a private in-context learning algorithm that effectively balances
privacy protection and model utility. Through experiments, we demonstrate that
our approach significantly improves the utility of private ICL with the
assistance of public data. Additionally, we show that our method is robust
against membership inference attacks, demonstrating empirical privacy
protection.

</details>


### [267] [AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions](https://arxiv.org/abs/2509.11595)
*Sabin Huda,Ernest Foo,Zahra Jadidi,MA Hakim Newton,Abdul Sattar*

Main category: cs.AI

TL;DR: AMLNet是一个知识驱动的多代理框架，用于生成合成反洗钱（AML）交易数据并进行检测，以解决AML研究中缺乏公开数据集的问题。


<details>
  <summary>Details</summary>
Motivation: AML研究缺乏公开共享、符合法规的交易数据集，限制了研究进展。

Method: 提出AMLNet，一个包含两个协调单元的框架：一个符合法规的交易生成器和一个集成检测管道。生成器创建了1,090,173笔合成交易，涵盖了洗钱的关键阶段和高级模式，并评估了其法规遵从性和技术保真度。检测集成模型在AMLNet内部和外部SynthAML数据集上进行了评估。

Result: 合成交易的法规遵从性达到75%（基于AUSTRAC规则覆盖率），技术保真度综合得分为0.75。检测集成模型在AMLNet内部测试集上达到了0.90的F1分数（精确率0.84，召回率0.97），并在SynthAML数据集上表现出良好的适应性，表明其在不同合成数据生成范式上的通用性。

Conclusion: AMLNet通过提供一个多维度评估（法规、时间、网络、行为）的合成数据集（已发布），解决了AML研究的挑战，促进了可重复和符合法规的反洗钱实验。

Abstract: Anti-money laundering (AML) research is constrained by the lack of publicly
shareable, regulation-aligned transaction datasets. We present AMLNet, a
knowledge-based multi-agent framework with two coordinated units: a
regulation-aware transaction generator and an ensemble detection pipeline. The
generator produces 1,090,173 synthetic transactions (approximately 0.16\%
laundering-positive) spanning core laundering phases (placement, layering,
integration) and advanced typologies (e.g., structuring, adaptive threshold
behavior). Regulatory alignment reaches 75\% based on AUSTRAC rule coverage
(Section 4.2), while a composite technical fidelity score of 0.75 summarizes
temporal, structural, and behavioral realism components (Section 4.4). The
detection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the
internal test partitions of AMLNet and adapts to the external SynthAML dataset,
indicating architectural generalizability across different synthetic generation
paradigms. We provide multi-dimensional evaluation (regulatory, temporal,
network, behavioral) and release the dataset (Version 1.0,
https://doi.org/10.5281/zenodo.16736515), to advance reproducible and
regulation-conscious AML experimentation.

</details>


### [268] [Enhancing Computational Cognitive Architectures with LLMs: A Case Study](https://arxiv.org/abs/2509.10972)
*Ron Sun*

Main category: cs.AI

TL;DR: 将大型语言模型（LLMs）整合到认知架构中，以结合LLMs的计算能力和Clarion架构的心理学精确性。


<details>
  <summary>Details</summary>
Motivation: 为了弥合现有计算工具的局限性，并同时处理现实世界的复杂性和心理学现实性，将LLMs整合到认知架构中是一个重要的任务。

Method: 提出将Clarion认知架构和LLMs进行协同组合，并利用Clarion中固有的隐性-显性二分法来实现无缝集成。

Result: 将LLMs的计算能力与Clarion的心理学精确性相结合。

Conclusion: 将LLMs整合到认知架构（以Clarion为例）中，能够有效地结合两者的优势，从而在计算能力和心理学现实性方面取得更好的效果。

Abstract: Computational cognitive architectures are broadly scoped models of the human
mind that combine different psychological functionalities (as well as often
different computational methods for these different functionalities) into one
unified framework. They structure them in a psychologically plausible and
validated way. However, such models thus far have only limited computational
capabilities, mostly limited by the computational tools and techniques that
were adopted. More recently, LLMs have proved to be more capable
computationally than any other tools. Thus, in order to deal with both
real-world complexity and psychological realism at the same time, incorporating
LLMs into cognitive architectures naturally becomes an important task. In the
present article, a synergistic combination of the Clarion cognitive
architecture and LLMs is discussed as a case study. The implicit-explicit
dichotomy that is fundamental to Clarion is leveraged for a seamless
integration of Clarion and LLMs. As a result, computational power of LLMs is
combined with psychological nicety of Clarion.

</details>


### [269] [Rethinking Human Preference Evaluation of LLM Rationales](https://arxiv.org/abs/2509.11026)
*Ziang Li,Manasi Ganti,Zixian Ma,Helena Vasconcelos,Qijia He,Ranjay Krishna*

Main category: cs.AI

TL;DR: LLM生成的自然语言解释（rationale）在复杂推理和可解释性方面有很大潜力，但评估方法（如二元偏好判断）存在不足。本研究提出了一种基于属性的评估方法，以更细致地评价 LLM 生成的 rationale，并分析了影响人类偏好的关键属性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM rationales 的评估方法（如二元偏好判断）存在不透明和粗粒度的问题，难以深入理解 rationale 质量好坏的原因。本研究旨在克服这些局限性，提供更精细、更可靠的评估方式。

Method: 1. 从现有文献中识别出关键的 rationale 属性。
2. 使用自动指标、LLM 判断和人工标注来评估这些属性。
3. 利用 SHAP 分析了两个标准的人类偏好数据集（MT Bench 和 Chatbot Arena），找出最能解释人类偏好的属性。
4. 使用基于属性的 ELO 分数重新评估了模型生成的 rationales。

Result: 基于属性的评估方法能够比二元比较提供更细粒度的模型比较和更深入的见解。关键属性的评估可以更好地表征 rationale 的质量。

Conclusion: 细粒度的属性评估能够更好地表征 rationale 的质量，并指导未来研究朝着更具可解释性和可靠性的评估实践发展。

Abstract: Large language models (LLMs) often generate natural language rationales --
free-form explanations that help improve performance on complex reasoning tasks
and enhance interpretability for human users. However, evaluating these
rationales remains challenging. While recent work has relied on binary
preference judgments from humans or LLM judges, such evaluations are often
opaque and coarse-grained, offering limited insight into what makes one
rationale better than another. In this work, we rethink preference evaluation
for LLM-generated rationales by asking: (1) What attributes define good
rationales? (2) Can human preferences be explained by these attributes? (3) Can
attribute-based evaluation overcome the limitations of binary comparisons? We
identify a set of key rationale attributes from prior literature and assess
them using automatic metrics, LLM judgments, and human annotations. We then
analyze two standard human preference datasets MT Bench and Chatbot Arena using
SHAP to identify which attributes best explain human preference outcomes.
Finally, we re-evaluate model-generated rationales using attribute-specific ELO
scores, revealing more nuanced model comparisons and insights. Our findings
suggest that fine-grained attribute evaluations can better characterize
rationale quality and guide future research toward more interpretable and
reliable evaluation practices.

</details>


### [270] [Co-Alignment: Rethinking Alignment as Bidirectional Human-AI Cognitive Adaptation](https://arxiv.org/abs/2509.12179)
*Yubo Li,Weiyi Song*

Main category: cs.AI

TL;DR: AI和人类应相互适应，而不是单向对齐，BiCA通过可学习协议实现这一目标，并在协作导航中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐方法将人类认知视为固定不变，而忽视了AI与人类之间可能存在的相互适应性。

Method: 提出了一种名为“双向认知对齐”（BiCA）的新范式，利用可学习协议、表示映射和KL散度约束来实现AI和人类的相互适应。

Result: 在协作导航任务中，BiCA的成功率为85.5%，优于基线（70.3%）。同时，BiCA在相互适应性（+230%）、协议收敛性（+332%）、涌现协议性能（+84%）以及鲁棒性（+23%）方面也取得了显著提升，并实现了46%的协同效应改进。

Conclusion: AI与人类的协同合作在两者能力的交集处达到最优，证明了从单向对齐转向双向协同对齐范式的必要性和有效性。

Abstract: Current AI alignment through RLHF follows a single directional paradigm that
AI conforms to human preferences while treating human cognition as fixed. We
propose a shift to co-alignment through Bidirectional Cognitive Alignment
(BiCA), where humans and AI mutually adapt. BiCA uses learnable protocols,
representation mapping, and KL-budget constraints for controlled co-evolution.
In collaborative navigation, BiCA achieved 85.5% success versus 70.3% baseline,
with 230% better mutual adaptation and 332% better protocol convergence.
Emergent protocols outperformed handcrafted ones by 84%, while bidirectional
adaptation unexpectedly improved safety (+23% out-of-distribution robustness).
The 46% synergy improvement demonstrates optimal collaboration exists at the
intersection, not union, of human and AI capabilities, validating the shift
from single-directional to co-alignment paradigms.

</details>


### [271] [Free-MAD: Consensus-Free Multi-Agent Debate](https://arxiv.org/abs/2509.11035)
*Yu Cui,Hang Fu,Haibin Zhang,Licheng Wang,Cong Zuo*

Main category: cs.AI

TL;DR: Multi-agent debate (MAD) is an approach to improve LLM reasoning. Existing MAD methods use multiple rounds and majority voting, which has limitations like high token overhead, error propagation due to conformity, and randomness in voting. Free-MAD, a novel framework, eliminates consensus by using a score-based mechanism evaluating the entire debate trajectory and introducing anti-conformity to mitigate majority influence. Experiments show Free-MAD improves reasoning, reduces token costs with single-round debates, and is more robust to attacks.


<details>
  <summary>Details</summary>
Motivation: Existing Multi-agent debate (MAD) methods have limitations including high token overhead from multiple interaction rounds, error propagation due to LLM conformity, and unfairness/randomness in majority voting, which can degrade reasoning performance.

Method: Free-MAD eliminates consensus by introducing a score-based decision mechanism that evaluates the entire debate trajectory (not just the last round) and incorporates anti-conformity to mitigate excessive influence from the majority during the debate phase. It utilizes a single-round debate.

Result: Experiments on eight benchmark datasets show that Free-MAD significantly improves reasoning performance, requires only a single-round debate (reducing token costs), and exhibits improved robustness against real-world attacks compared to existing MAD approaches.

Conclusion: Free-MAD offers a novel and effective approach to Multi-agent debate by eliminating the need for consensus, improving decision-making through a score-based mechanism and anti-conformity, leading to better reasoning performance, reduced costs, and enhanced robustness.

Abstract: Multi-agent debate (MAD) is an emerging approach to improving the reasoning
capabilities of large language models (LLMs). Existing MAD methods rely on
multiple rounds of interaction among agents to reach consensus, and the final
output is selected by majority voting in the last round. However, this
consensus-based design faces several limitations. First, multiple rounds of
communication increases token overhead and limits scalability. Second, due to
the inherent conformity of LLMs, agents that initially produce correct
responses may be influenced by incorrect ones during the debate process,
causing error propagation. Third, majority voting introduces randomness and
unfairness in the decision-making phase, and can degrade the reasoning
performance.
  To address these issues, we propose \textsc{Free-MAD}, a novel MAD framework
that eliminates the need for consensus among agents. \textsc{Free-MAD}
introduces a novel score-based decision mechanism that evaluates the entire
debate trajectory rather than relying on the last round only. This mechanism
tracks how each agent's reasoning evolves, enabling more accurate and fair
outcomes. In addition, \textsc{Free-MAD} reconstructs the debate phase by
introducing anti-conformity, a mechanism that enables agents to mitigate
excessive influence from the majority. Experiments on eight benchmark datasets
demonstrate that \textsc{Free-MAD} significantly improves reasoning performance
while requiring only a single-round debate and thus reducing token costs. We
also show that compared to existing MAD approaches, \textsc{Free-MAD} exhibits
improved robustness in real-world attack scenarios.

</details>


### [272] [Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability](https://arxiv.org/abs/2509.11068)
*Zan-Kai Chong,Hiroyuki Ohsaki,Bryan Ng*

Main category: cs.AI

TL;DR: 本篇论文提出了一种验证框架，用于确认大型语言模型（LLM）的输出是否由声称的LLM生成，而不是被篡改或由廉价模型生成。该框架利用确定性可复现性原理，在计算环境同质的前提下，通过对LLM输出的随机片段进行概率性审计来验证其真实性。


<details>
  <summary>Details</summary>
Motivation: 解决在动态、多智能体LLM系统中，如何验证一个智能体输出的真实性，防止被篡改或由廉价模型生成的问题，建立计算信任。

Method: 提出一种验证框架，利用确定性可复现性原理，在计算环境同质（相同硬件和软件）的条件下，允许多个验证者对LLM输出的随机小片段进行概率性审计，以验证其真实性。该方法实现了可控的计算成本，验证成本远低于计算成本。

Result: 模拟结果表明，目标验证比完全重新生成快12倍以上，并且可以通过调整参数来调整检测概率。该框架为可审计的LLM系统提供了一种可行的机制。

Conclusion: 该工作为负责任的人工智能奠定了基础，并为未来更复杂的异构多智能体系统的研究提供了基础。

Abstract: The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic,
multi-agent systems. This introduces a fundamental challenge in establishing
computational trust, specifically how one agent can verify that another's
output was genuinely produced by a claimed LLM, and not falsified or generated
by a cheaper or inferior model. To address this challenge, this paper proposes
a verification framework that achieves tractable asymmetric effort, where the
cost to verify a computation is substantially lower than the cost to perform
it. Our approach is built upon the principle of deterministic replicability, a
property inherent to autoregressive models that strictly necessitates a
computationally homogeneous environment where all agents operate on identical
hardware and software stacks. Within this defined context, our framework
enables multiple validators to probabilistically audit small, random segments
of an LLM's output and it distributes the verification workload effectively.
The simulations demonstrated that targeted verification can be over 12 times
faster than full regeneration, with tunable parameters to adjust the detection
probability. By establishing a tractable mechanism for auditable LLM systems,
our work offers a foundational layer for responsible AI and serves as a
cornerstone for future research into the more complex, heterogeneous
multi-agent systems.

</details>


### [273] [Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation](https://arxiv.org/abs/2509.11078)
*Yunghwei Lai,Weizhi Ma,Yang Liu*

Main category: cs.AI

TL;DR: 使用LLM生成合成医疗数据，提出Patient-Zero框架，无需真实病历，实现数据隐私、准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在医疗领域生成合成数据存在数据隐私、准确性、多样性不足以及缺乏与真实患者互动能力的问题。

Method: Patient-Zero框架采用多步生成架构，通过分层医疗知识注入构建病历；设计动态更新机制优化患者互动能力，结合自适应对话策略和实时临床合理性验证。

Result: 生成的病历在准确性、多样性和一致性方面表现良好，并能提升下游模型的性能。

Conclusion: Patient-Zero框架能够生成在医疗上连贯且具有上下文多样性的虚拟患者记录，有效解决了现有方法的局限性。

Abstract: Synthetic data generation using large language models (LLMs) has emerged as a
promising solution across various domains, particularly in medical field, to
mitigate data collection challenges. However, existing studies mainly utilize
LLMs to rewrite and complete existing medical records, where the limitations in
data privacy, accuracy, and diversity sill exist, and additionally lack the
ability to interact like real patients. To address these issues, we propose a
realistic patient generation framework, Patient-Zero, which requires no real
medical records. Patient-Zero first introduces a medically-aligned multi-step
generation architecture, which builds comprehensive patient records through
hierarchical medical knowledge injection without real medical records. Then, to
optimize the virtual patient's interaction abilities with humans, Patient-Zero
designs a dynamic updating mechanism to improve the consistency and
conversational performance. Our framework enables the generation of
contextually diverse patient records while maintaining strict medical
coherence, supported by adaptive dialogue strategies and real-time clinical
plausibility verification. Experimental results demonstrate that our model
achieves good performance in accuracy, diversity, and consistency. After
training with our generated virtual patients, existing models show significant
improvements on the MedQA dataset.

</details>


### [274] [Difficulty-Aware Agent Orchestration in LLM-Powered Workflows](https://arxiv.org/abs/2509.11079)
*Jinwei Su,Yinghui Xia,Qizhen Lan,Xinyuan Song,Yang Jingsong,Lewei He,Tianyu Shi*

Main category: cs.AI

TL;DR: LLM代理系统需要动态工作流来处理不同难度的查询，DAAO框架通过动态调整工作流深度、算子选择和LLM分配来提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理系统通常依赖静态工作流，无法有效处理不同难度的查询，并且忽略了异构LLM之间的效率-性能权衡。

Method: 提出DAAO框架，包含一个用于难度估计的VAE、一个模块化算子分配器和一个成本感知LLM路由器，以动态适应工作流深度、算子选择和LLM分配。

Result: DAAO在六个基准测试中，在准确性和推理效率方面均优于先前基于多智能体的系统。

Conclusion: DAAO通过利用异构LLM和动态定制工作流，实现了细粒度的、查询特定的推理策略，提高了LLM代理系统的性能和效率。

Abstract: Large Language Model (LLM)-based agentic systems have shown strong
capabilities across various tasks. However, existing multi-agent frameworks
often rely on static or task-level workflows, which either over-process simple
queries or underperform on complex ones, while also neglecting the
efficiency-performance trade-offs across heterogeneous LLMs. To address these
limitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), a
dynamic framework that adapts workflow depth, operator selection, and LLM
assignment based on the difficulty of each input query. DAAO comprises three
interdependent modules: a variational autoencoder (VAE) for difficulty
estimation, a modular operator allocator, and a cost- and performance-aware LLM
router. By leveraging heterogeneous LLMs and dynamically tailoring workflows,
DAAO enables fine-grained, query-specific reasoning strategies. DAAO
outperforms prior multi-agent systems in both accuracy and inference efficiency
across six benchmarks. We will release our code and implementation details upon
publication.

</details>


### [275] [AlignKT: Explicitly Modeling Knowledge State for Knowledge Tracing with Ideal State Alignment](https://arxiv.org/abs/2509.11135)
*Jing Xiao,Chang You,Zhiyu Chen*

Main category: cs.AI

TL;DR: AlignKT通过显式建模稳定的知识状态来改进现有知识追踪（KT）模型，提高了可解释性和教学支持能力，并在三个真实数据集上取得了优于七个基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪（KT）模型主要关注拟合学习者交互序列，忽视了知识状态本身，导致可解释性差，教学支持不足。

Method: 提出AlignKT模型，采用前端到后端架构，显式建模稳定的知识状态。通过将初步知识状态与基于教育学理论定义的理想知识状态进行对齐来实现，并使用五个编码器和一个对比学习模块来增强对齐过程的鲁棒性。

Result: AlignKT在三个真实世界数据集上，在七个KT基线模型上取得了优越的性能，其中两个数据集上达到了最先进（state-of-the-art）的结果，在第三个数据集上表现出有竞争力。

Conclusion: AlignKT通过显式建模稳定的知识状态，提高了知识追踪的性能和可解释性，为智能辅导系统提供了更好的教学支持。

Abstract: Knowledge Tracing (KT) serves as a fundamental component of Intelligent
Tutoring Systems (ITS), enabling these systems to monitor and understand
learners' progress by modeling their knowledge state. However, many existing KT
models primarily focus on fitting the sequences of learners' interactions, and
often overlook the knowledge state itself. This limitation leads to reduced
interpretability and insufficient instructional support from the ITS. To
address this challenge, we propose AlignKT, which employs a frontend-to-backend
architecture to explicitly model a stable knowledge state. In this approach,
the preliminary knowledge state is aligned with an additional criterion.
Specifically, we define an ideal knowledge state based on pedagogical theories
as the alignment criterion, providing a foundation for interpretability. We
utilize five encoders to implement this set-up, and incorporate a contrastive
learning module to enhance the robustness of the alignment process. Through
extensive experiments, AlignKT demonstrates superior performance, outperforming
seven KT baselines on three real-world datasets. It achieves state-of-the-art
results on two of these datasets and exhibits competitive performance on the
third. The code of this work is available at
https://github.com/SCNU203/AlignKT.

</details>


### [276] [AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions](https://arxiv.org/abs/2509.11151)
*Jianxin Li,Liang Qu,Taotao Cai,Zhixue Zhao,Nur Al Hasan Haldar,Aneesh Krishna,Xiangjie Kong,Flavio Romero Macau,Tanmoy Chakraborty,Aniket Deroy,Binshan Lin,Karen Blackmore,Nasimul Noman,Jingxian Cheng,Ningning Cui,Jianliang Xu*

Main category: cs.AI

TL;DR: AIGC发展迅速，应用广泛，但缺乏跨领域研究。本文汇集16位学者，从生成技术、检测方法、社会影响、技术挑战等角度，提供AIGC的跨领域视角、研究趋势和未来方向。


<details>
  <summary>Details</summary>
Motivation: AIGC发展迅速且应用广泛，但缺乏对其跨领域进展和挑战的全面探讨，本研究旨在弥补这一空白。

Method: 本文汇集16位跨学科学者，从AIGC的生成技术、检测方法、社会影响、技术挑战等方面进行研究，并提出未来研究方向。

Result: 本文概述了AIGC的生成技术、检测方法、内容传播与应用，探讨了AIGC在各领域的社会影响及现有方法，并提出了关键技术挑战和未来研究方向。

Conclusion: 本文为读者提供了AIGC的跨领域视角，深入了解其研究趋势、挑战和未来发展方向。

Abstract: Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the
capability to generate different forms of content, including text, images,
videos, and other modalities, which can achieve a quality similar to content
created by humans. As a result, AIGC is now widely applied across various
domains such as digital marketing, education, and public health, and has shown
promising results by enhancing content creation efficiency and improving
information delivery. However, there are few studies that explore the latest
progress and emerging challenges of AIGC across different domains. To bridge
this gap, this paper brings together 16 scholars from multiple disciplines to
provide a cross-domain perspective on the trends and challenges of AIGC.
Specifically, the contributions of this paper are threefold: (1) It first
provides a broader overview of AIGC, spanning the training techniques of
Generative AI, detection methods, and both the spread and use of AI-generated
content across digital platforms. (2) It then introduces the societal impacts
of AIGC across diverse domains, along with a review of existing methods
employed in these contexts. (3) Finally, it discusses the key technical
challenges and presents research propositions to guide future work. Through
these contributions, this vision paper seeks to offer readers a cross-domain
perspective on AIGC, providing insights into its current research trends,
ongoing challenges, and future directions.

</details>


### [277] [VideoAgent: Personalized Synthesis of Scientific Videos](https://arxiv.org/abs/2509.11253)
*Xiao Liang,Bangxin Li,Zixuan Chen,Hanyue Zheng,Zhi Ma,Di Wang,Cong Tian,Quan Wang*

Main category: cs.AI

TL;DR: VideoAgent是一个多智能体框架，可以通过对话界面生成个性化的科学视频，解决了现有方法在动态编排和多模态内容同步方面的不足。它将源论文解析为资源库，并根据用户需求生成包含幻灯片和动画的视频。同时，提出了SciVidEval评估套件，包含自动指标和基于视频测验的人类评估，以衡量知识传递效果。实验证明，VideoAgent在科学交流方面显著优于现有商业服务，并接近人类水平。


<details>
  <summary>Details</summary>
Motivation: 现有自动化科学视频生成方法主要关注静态媒体，缺乏个性化动态编排和多模态内容同步机制，难以满足知识传播的需求。

Method: 提出一个名为VideoAgent的多智能体框架，通过对话界面实现个性化科学视频的合成。该框架首先将源论文解析成细粒度的资源库，然后在用户需求的指导下，编排叙事流程，合成静态幻灯片和动态动画来解释复杂概念。为了进行严格评估，还提出了SciVidEval评估套件，结合了多模态内容质量和同步的自动度量以及基于视频测验的人类评估，以衡量知识转移。

Result: 通过广泛的实验证明，VideoAgent在科学交流方面显著优于现有的商业科学视频生成服务，并且在接近人类水平的质量。

Conclusion: VideoAgent通过其多智能体框架和SciVidEval评估套件，在个性化科学视频生成和评估方面取得了显著进展，有效解决了现有方法的局限性，并达到了接近人类水平的传播效果。

Abstract: Automating the generation of scientific videos is a crucial yet challenging
task for effective knowledge dissemination. However, existing works on document
automation primarily focus on static media such as posters and slides, lacking
mechanisms for personalized dynamic orchestration and multimodal content
synchronization. To address these challenges, we introduce VideoAgent, a novel
multi-agent framework that synthesizes personalized scientific videos through a
conversational interface. VideoAgent parses a source paper into a fine-grained
asset library and, guided by user requirements, orchestrates a narrative flow
that synthesizes both static slides and dynamic animations to explain complex
concepts. To enable rigorous evaluation, we also propose SciVidEval, the first
comprehensive suite for this task, which combines automated metrics for
multimodal content quality and synchronization with a Video-Quiz-based human
evaluation to measure knowledge transfer. Extensive experiments demonstrate
that our method significantly outperforms existing commercial scientific video
generation services and approaches human-level quality in scientific
communication.

</details>


### [278] [Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble](https://arxiv.org/abs/2509.11311)
*Bingchen Wang,Zi-Yu Khoo,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: LLMs可作为调查受访者代理，以低成本、可控的方式解决调查成本上升和人口统计失衡问题。通过构建多样化的代理人角色（endowments）并选择代表性子集来模拟人口，P2P系统利用结构化提示、熵采样和回归选择来引导LLM行为。该方法不依赖人口统计信息，具有更好的泛化性和简洁性，并在真实调查数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决社会科学领域面临的两个紧迫挑战：调查成本不断上升以及调查响应数据中人口统计失衡日益严重。提出一种新颖的对齐框架，将大型语言模型（LLMs）视为人类调查受访者的代理，以提供一种经济高效且可控的解决方案。

Method: 提出一个两阶段的对齐框架，借鉴“显示性偏好”理论。第一阶段构建多样化的代理人角色（endowments），模拟合理的研究对象画像。第二阶段根据观测数据选择一个代表性子集，以近似真实人口。具体实现上，引入P2P系统，利用结构化提示工程、熵采样和基于回归的选择来引导LLM代理产生代表性的行为模式。

Result: 在真实的民意调查数据集上验证了该方法的有效性。结果表明，所对齐的代理人样本能够高保真地复制总体响应模式，并展现出显著的响应多样性，即使在没有人口统计条件的情况下也是如此。

Conclusion: 本研究提出的对齐框架不仅能提高社会科学研究的数据效率，还能为研究多元对齐的操作化提供一个测试平台。该方法不依赖人口统计信息，具有更好的泛化性和简洁性，通过P2P系统在真实调查数据上验证了其有效性。

Abstract: Large language models (LLMs) have demonstrated promise in emulating
human-like responses across a wide range of tasks. In this paper, we propose a
novel alignment framework that treats LLMs as agent proxies for human survey
respondents, affording a cost-effective and steerable solution to two pressing
challenges in the social sciences: the rising cost of survey deployment and the
growing demographic imbalance in survey response data. Drawing inspiration from
the theory of revealed preference, we formulate alignment as a two-stage
problem: constructing diverse agent personas called endowments that simulate
plausible respondent profiles, and selecting a representative subset to
approximate a ground-truth population based on observed data. To implement the
paradigm, we introduce P2P, a system that steers LLM agents toward
representative behavioral patterns using structured prompt engineering,
entropy-based sampling, and regression-based selection. Unlike
personalization-heavy approaches, our alignment approach is
demographic-agnostic and relies only on aggregate survey results, offering
better generalizability and parsimony. Beyond improving data efficiency in
social science research, our framework offers a testbed for studying the
operationalization of pluralistic alignment. We demonstrate the efficacy of our
approach on real-world opinion survey datasets, showing that our aligned agent
populations can reproduce aggregate response patterns with high fidelity and
exhibit substantial response diversity, even without demographic conditioning.

</details>


### [279] [Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts](https://arxiv.org/abs/2509.11330)
*Sudeshna Jana,Manjira Sinha,Tirthankar Dasgupta*

Main category: cs.AI

TL;DR: 塑料污染对健康构成威胁，提出利用大语言模型提取关系元路径，构建毒性轨迹图，并整合证据协调模块以解决冲突，最终实现从科学文献中挖掘因果关系。


<details>
  <summary>Details</summary>
Motivation: 塑料的广泛使用及其在环境中持久存在导致了微塑料和纳米塑料在空气、水和土壤中的积累，对包括呼吸系统、胃肠道和神经系统疾病在内的健康构成严重威胁。

Method: 利用大语言模型提取关系元路径，构建毒性轨迹图，并整合动态证据协调模块来解决因不断变化的或矛盾的研究结果而产生的语义冲突。

Result: 该方法在从嘈杂的科学文本中提取可靠、高价值的关系知识方面表现出强大的性能，并为在特定领域语料库中挖掘复杂的因果结构提供了可扩展的解决方案。

Conclusion: 提出的框架能够有效应对塑料污染带来的健康风险，通过大语言模型提取和构建毒性轨迹图，并利用证据协调模块确保信息的一致性和可靠性，为理解和解决环境污染物与健康影响之间的复杂关系提供了新的途径。

Abstract: The widespread use of plastics and their persistence in the environment have
led to the accumulation of micro- and nano-plastics across air, water, and
soil, posing serious health risks including respiratory, gastrointestinal, and
neurological disorders. We propose a novel framework that leverages large
language models to extract relational metapaths, multi-hop semantic chains
linking pollutant sources to health impacts, from scientific abstracts. Our
system identifies and connects entities across diverse contexts to construct
structured relational metapaths, which are aggregated into a Toxicity
Trajectory Graph that traces pollutant propagation through exposure routes and
biological systems. Moreover, to ensure consistency and reliability, we
incorporate a dynamic evidence reconciliation module that resolves semantic
conflicts arising from evolving or contradictory research findings. Our
approach demonstrates strong performance in extracting reliable, high-utility
relational knowledge from noisy scientific text and offers a scalable solution
for mining complex cause-effect structures in domain-specific corpora.

</details>


### [280] [The power of dynamic causality in observer-based design for soft sensor applications](https://arxiv.org/abs/2509.11336)
*William Farlessyost,Sebastian Oberst,Shweta Singh*

Main category: cs.AI

TL;DR: 本研究提出一种基于动态因果分析的软传感器优化框架，利用LTC网络识别和剔除对状态估计影响最小的传感器输入，以提高预测精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统传感器选择方法依赖于线性化或统计相关性，无法捕捉复杂系统的动态演化。本研究旨在弥补这一差距，通过动态因果分析优化传感器选择。

Method: 使用LTC网络（一种具有输入依赖时间常数的连续时间神经网络）来识别和剔除对状态估计影响最小的传感器输入。该方法包括训练LTC观察器、量化因果影响、剔除低影响输入以及重新训练，直到性能下降。

Result: 在三个不同的力学测试平台（弹簧-质量-阻尼系统、连续搅拌反应器和Lotka-Volterra模型）上进行了演示。结果表明，该方法能识别出与物理学原理一致的最优传感器集，并提高预测精度，同时区分了测量噪声和有用的交互项信息。

Conclusion: 该框架通过动态因果关系而非静态相关性来指导传感器选择，不仅提高了计算效率，还增强了模型的可解释性，为过程工程、生态监测和农业等领域的软传感应用提供了显著优势。

Abstract: This paper introduces a novel framework for optimizing observer-based soft
sensors through dynamic causality analysis. Traditional approaches to sensor
selection often rely on linearized observability indices or statistical
correlations that fail to capture the temporal evolution of complex systems. We
address this gap by leveraging liquid-time constant (LTC) networks,
continuous-time neural architectures with input-dependent time constants, to
systematically identify and prune sensor inputs with minimal causal influence
on state estimation. Our methodology implements an iterative workflow: training
an LTC observer on candidate inputs, quantifying each input's causal impact
through controlled perturbation analysis, removing inputs with negligible
effect, and retraining until performance degradation occurs. We demonstrate
this approach on three mechanistic testbeds representing distinct physical
domains: a harmonically forced spring-mass-damper system, a nonlinear
continuous stirred-tank reactor, and a predator-prey model following the
structure of the Lotka-Volterra model, but with seasonal forcing and added
complexity. Results show that our causality-guided pruning consistently
identifies minimal sensor sets that align with underlying physics while
improving prediction accuracy. The framework automatically distinguishes
essential physical measurements from noise and determines when derived
interaction terms provide complementary versus redundant information. Beyond
computational efficiency, this approach enhances interpretability by grounding
sensor selection decisions in dynamic causal relationships rather than static
correlations, offering significant benefits for soft sensing applications
across process engineering, ecological monitoring, and agricultural domains.

</details>


### [281] [MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization](https://arxiv.org/abs/2509.11361)
*Yichen Han,Bojun Liu,Zhengpeng zhou,Guanyu Liu,Zeng Zhang,Yang Yang,Wenli Wang,Isaac N Shi,Yunyan,Lewei He,Tianyu Shi*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Prompt engineering is crucial for leveraging large language models (LLMs),
but existing methods often rely on a single optimization trajectory, limiting
adaptability and efficiency while suffering from narrow perspectives, gradient
conflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt
Gradient Descent), a framework integrating multi-agent collaboration with
gradient-based optimization. MAPGD features specialized agents for task
clarity, example selection, format design, and stylistic refinement; semantic
gradient coordination to resolve conflicts; bandit-based candidate selection
for efficient exploration-exploitation; and theoretical convergence guarantees.
Experiments on classification, generation, and reasoning tasks show MAPGD
outperforms single-agent and random baselines in accuracy and efficiency.
Ablations confirm the benefits of gradient fusion, agent specialization, and
conflict resolution, providing a unified, gradient-inspired multi-agent
approach to robust and interpretable prompt optimization.

</details>


### [282] [Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications](https://arxiv.org/abs/2509.11431)
*Aadil Gani Ganie*

Main category: cs.AI

TL;DR: LLMs受限于训练数据，AI Agent可弥补此不足但存在安全风险。本文提出RBAC框架以增强AI Agent的安全性，支持其在本地部署。


<details>
  <summary>Details</summary>
Motivation: LLMs受限于静态训练数据，AI Agent虽能弥补但存在安全风险，需在工业场景中进行部署。

Method: 提出一个将基于角色的访问控制（RBAC）集成到AI Agent的框架，以提供安全防护。

Result: 该框架旨在支持AI Agent的有效和可扩展部署，特别是在本地部署场景下。

Conclusion: RBAC框架可以为AI Agent提供强大的安全护栏，支持其在工业场景中的安全部署。

Abstract: The emergence of Large Language Models (LLMs) has significantly advanced
solutions across various domains, from political science to software
development. However, these models are constrained by their training data,
which is static and limited to information available up to a specific date.
Additionally, their generalized nature often necessitates fine-tuning --
whether for classification or instructional purposes -- to effectively perform
specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate
some of these limitations by accessing external tools and real-time data,
enabling applications such as live weather reporting and data analysis. In
industrial settings, AI agents are transforming operations by enhancing
decision-making, predictive maintenance, and process optimization. For example,
in manufacturing, AI agents enable near-autonomous systems that boost
productivity and support real-time decision-making. Despite these advancements,
AI agents remain vulnerable to security threats, including prompt injection
attacks, which pose significant risks to their integrity and reliability. To
address these challenges, this paper proposes a framework for integrating
Role-Based Access Control (RBAC) into AI agents, providing a robust security
guardrail. This framework aims to support the effective and scalable deployment
of AI agents, with a focus on on-premises implementations.

</details>


### [283] [Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction](https://arxiv.org/abs/2509.11459)
*Chen Jiang,Kofi Osei,Sai Deepthi Yeddula,Dongji Feng,Wei-Shinn Ku*

Main category: cs.AI

TL;DR: 提出了一种自适应混合专家模型，用于提高降水预测的准确性，并引入了一个可视化工具来支持决策。


<details>
  <summary>Details</summary>
Motivation: 由于气候系统的复杂性和多源观测数据的异构性（雷达、卫星图像、地表测量），准确的降水预测极具挑战性，现有的深度学习模型难以有效整合这些数据。

Method: 提出了一种自适应混合专家（MoE）模型，其中每个专家处理特定的数据模态或时空模式，并使用动态路由器将输入分配给最相关的专家。此外，还开发了一个交互式Web可视化工具，用于探索历史天气模式。

Result: 该模型显著提高了预测准确性和可解释性，并且在使用2022年飓风伊恩的真实世界数据进行评估时，自适应MoE模型在基准测试中明显优于所有基线模型。

Conclusion: 所提出的自适应MoE模型能够有效处理多源异构数据，提高降水预测的准确性，并辅以可视化工具支持气候相关领域的决策。

Abstract: Accurate precipitation forecasting is indispensable in agriculture, disaster
management, and sustainable strategies. However, predicting rainfall has been
challenging due to the complexity of climate systems and the heterogeneous
nature of multi-source observational data, including radar, satellite imagery,
and surface-level measurements. The multi-source data vary in spatial and
temporal resolution, and they carry domain-specific features, making it
challenging for effective integration in conventional deep learning models.
Previous research has explored various machine learning techniques for weather
prediction; however, most struggle with the integration of data with
heterogeneous modalities. To address these limitations, we propose an Adaptive
Mixture of Experts (MoE) model tailored for precipitation rate prediction. Each
expert within the model specializes in a specific modality or spatio-temporal
pattern. We also incorporated a dynamic router that learns to assign inputs to
the most relevant experts. Our results show that this modular design enhances
predictive accuracy and interpretability. In addition to the modeling
framework, we introduced an interactive web-based visualization tool that
enables users to intuitively explore historical weather patterns over time and
space. The tool was designed to support decision-making for stakeholders in
climate-sensitive sectors. We evaluated our approach using a curated multimodal
climate dataset capturing real-world conditions during Hurricane Ian in 2022.
The benchmark results show that the Adaptive MoE significantly outperformed all
the baselines.

</details>


### [284] [MedicalOS: An LLM Agent based Operating System for Digital Healthcare](https://arxiv.org/abs/2509.11507)
*Jared Zhu,Junde Wu*

Main category: cs.AI

TL;DR: LLM驱动的MedicalOS系统通过自然语言处理简化了医疗工作流程，在214个病例中验证了其准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的数字健康技术虽然改进了临床流程，但用户学习和使用困难，增加了医生的管理负担，使他们花费过多时间在行政工作而非病人护理上。LLM智能体的兴起表明，可以通过自然语言指令与计算机交互，但医疗领域需要一个特定领域、安全、透明且合规的抽象层。

Method: 提出MedicalOS，一个统一的、基于智能体的操作系统，作为医疗领域的特定抽象层。它将人类指令转化为预定义的、封装在Python、API、MCP、Linux等工具中的数字医疗命令，用于病人查询、病史检索、检查管理、报告生成、转诊、治疗计划等。

Result: 在214个病例（涵盖22个专科）的实证验证中，MedicalOS表现出高诊断准确性和置信度，生成了临床上合理的检查请求，并一致地生成了结构化报告和药物推荐。

Conclusion: MedicalOS作为一个值得信赖且可扩展的基础，能够推动临床工作流程的自动化。

Abstract: Decades' advances in digital health technologies, such as electronic health
records, have largely streamlined routine clinical processes. Yet, most these
systems are still hard to learn and use: Clinicians often face the burden of
managing multiple tools, repeating manual actions for each patient, navigating
complicated UI trees to locate functions, and spending significant time on
administration instead of caring for patients. The recent rise of large
language model (LLM) based agents demonstrates exceptional capability in coding
and computer operation, revealing the potential for humans to interact with
operating systems and software not by direct manipulation, but by instructing
agents through natural language. This shift highlights the need for an
abstraction layer, an agent-computer interface, that translates human language
into machine-executable commands. In digital healthcare, however, requires a
more domain-specific abstractions that strictly follow trusted clinical
guidelines and procedural standards to ensure safety, transparency, and
compliance. To address this need, we present \textbf{MedicalOS}, a unified
agent-based operational system designed as such a domain-specific abstract
layer for healthcare. It translates human instructions into pre-defined digital
healthcare commands, such as patient inquiry, history retrieval, exam
management, report generation, referrals, treatment planning, that we wrapped
as off-the-shelf tools using machine languages (e.g., Python, APIs, MCP,
Linux). We empirically validate MedicalOS on 214 patient cases across 22
specialties, demonstrating high diagnostic accuracy and confidence, clinically
sound examination requests, and consistent generation of structured reports and
medication recommendations. These results highlight MedicalOS as a trustworthy
and scalable foundation for advancing workflow automation in clinical practice.

</details>


### [285] [Task Decoding based on Eye Movements using Synthetic Data Augmentation](https://arxiv.org/abs/2509.11547)
*Shanmuka Sadhu,Arca Baran,Preeti Pandey,Ayush Kumar*

Main category: cs.AI

TL;DR: 使用CTGAN及其变体生成合成数据，并结合传统机器学习算法，提高了眼动追踪任务的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 支持Yarbus关于可以从观察者的眼动追踪数据中解码其任务的假设。

Method: 利用CTGAN、CopulaGAN和Gretel AI等生成模型，在真实眼动追踪数据集的基础上生成合成数据，并结合随机森林和Inception Time等传统机器学习算法进行分类。

Result: 通过增加合成数据，Inception Time算法的任务解码准确性从28.1%提高到82%，显著优于仅使用真实数据的传统方法。

Conclusion: 增加合成眼动追踪数据可以有效提高传统机器学习算法在任务解码方面的分类准确性。

Abstract: Machine learning has been extensively used in various applications related to
eye-tracking research. Understanding eye movement is one of the most
significant subsets of eye-tracking research that reveals the scanning pattern
of an individual. Researchers have thoroughly analyzed eye movement data to
understand various eye-tracking applications, such as attention mechanisms,
navigational behavior, task understanding, etc. The outcome of traditional
machine learning algorithms used for decoding tasks based on eye movement data
has received a mixed reaction to Yarbus' claim that it is possible to decode
the observer's task from their eye movements. In this paper, to support the
hypothesis by Yarbus, we are decoding tasks categories while generating
synthetic data samples using well-known Synthetic Data Generators CTGAN and its
variations such as CopulaGAN and Gretel AI Synthetic Data generators on
available data from an in-person user study. Our results show that augmenting
more eye movement data combined with additional synthetically generated
improves classification accuracy even with traditional machine learning
algorithms. We see a significant improvement in task decoding accuracy from
28.1% using Random Forest to 82% using Inception Time when five times more data
is added in addition to the 320 real eye movement dataset sample. Our proposed
framework outperforms all the available studies on this dataset because of the
use of additional synthetic datasets. We validated our claim with various
algorithms and combinations of real and synthetic data to show how decoding
accuracy increases with the increase in the augmentation of generated data to
real data.

</details>


### [286] [Formal Reasoning for Intelligent QA Systems: A Case Study in the Educational Domain](https://arxiv.org/abs/2509.11572)
*Tuan Bui,An Nguyen,Phat Thai,Minh Hua,Ngan Pham L. N.,Ngan Pham T. B.,Dung Le,Long Nguyen,Thanh-Tung Tran,Thang Bui,Tho Quan*

Main category: cs.AI

TL;DR: MCFR是一个结合了LLM和模型检查的神经符号框架，用于验证QA系统中的程序正确性和策略合规性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在QA系统中进行推理时，其推理过程可能不忠实，并且难以处理动态的、基于状态的推理。虽然结合符号引擎可以提高可靠性，但仅限于静态逻辑。

Method: MCFR将自然语言转换为形式规约，并在迁移模型上进行验证。为了支持评估，我们引入了一个名为EduMC-QA的基准数据集。

Result: MCFR提高了推理的忠实度和可解释性，并且在与ChatGPT、DeepSeek和Claude等最先进的LLM的比较中表现出色。

Conclusion: MCFR为高风险的闭域应用中可验证的QA提供了一条可行的途径。

Abstract: Reasoning is essential for closed-domain QA systems in which procedural
correctness and policy compliance are critical. While large language models
(LLMs) have shown strong performance on many reasoning tasks, recent work
reveals that their reasoning traces are often unfaithful - serving more as
plausible justifications than as causally grounded derivations. Efforts to
combine LLMs with symbolic engines (e.g., Prover9, Z3) have improved
reliability but remain limited to static forms of logic, struggling with
dynamic, state-based reasoning such as multi-step progressions and conditional
transitions.
  In this paper, we propose MCFR (Model Checking for Formal Reasoning), a
neuro-symbolic framework that integrates LLMs with model checking to support
property verification. MCFR translates natural language into formal
specifications and verifies them over transition models. To support evaluation,
we introduce EduMC-QA, a benchmark dataset grounded in real academic
procedures. Our results show that MCFR improves reasoning faithfulness and
interpretability, offering a viable path toward verifiable QA in high-stakes
closed-domain applications. In addition to evaluating MCFR, we compare its
performance with state-of-the-art LLMs such as ChatGPT, DeepSeek, and Claude to
contextualize its effectiveness.

</details>


### [287] [A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](https://arxiv.org/abs/2509.11575)
*Ching Chang,Yidan Shi,Defu Cao,Wei Yang,Jeehyun Hwang,Haixin Wang,Jiacheng Pang,Wei Wang,Yan Liu,Wen-Chih Peng,Tien-Fu Chen*

Main category: cs.AI

TL;DR: 本文对时间序列推理的文献进行了组织和总结，按推理拓扑（直接推理、线性链推理、分支结构推理）和主要目标（传统分析、解释、因果推断、生成）进行了分类，并讨论了相关方法、数据集、评估实践和未来方向，强调了从精确度向可扩展可靠性的转变。


<details>
  <summary>Details</summary>
Motivation: 对时间序列推理这一新兴领域进行系统性的梳理和总结，明确其研究范畴、组织现有文献、识别关键挑战并指明未来发展方向。

Method: 通过对现有时间序列推理的研究进行分类和组织，主要依据推理拓扑（直接推理、线性链推理、分支结构推理）和研究目标（传统时间序列分析、解释与理解、因果推断与决策、时间序列生成）。同时，结合了评价指标、数据集、基准测试等资源，并分析了不同方法的优缺点。

Result: 对时间序列推理的研究进行了全面的梳理，识别了三种主要的推理拓扑结构，并将其与不同的研究目标相结合。总结了现有方法的优势和劣势，并提供了一个包含数据集、基准测试和资源的列表。此外，还强调了在评估和部署中的关键考虑因素，如证据可见性、时间对齐、鲁棒性、计算成本等。

Conclusion: 时间序列推理的研究正从单纯追求准确度转向在大规模应用中实现可靠性。未来的发展将依赖于能够将推理质量与实际效用挂钩的基准测试，以及在考虑现实世界因素（如数据漂移、流式处理、成本和延迟）的闭环测试平台。最终目标是构建能够理解、解释并对动态世界做出可溯源、可信赖反应的系统。

Abstract: Time series reasoning treats time as a first-class axis and incorporates
intermediate evidence directly into the answer. This survey defines the problem
and organizes the literature by reasoning topology with three families: direct
reasoning in one step, linear chain reasoning with explicit intermediates, and
branch-structured reasoning that explores, revises, and aggregates. The
topology is crossed with the main objectives of the field, including
traditional time series analysis, explanation and understanding, causal
inference and decision making, and time series generation, while a compact tag
set spans these axes and captures decomposition and verification, ensembling,
tool use, knowledge access, multimodality, agent loops, and LLM alignment
regimes. Methods and systems are reviewed across domains, showing what each
topology enables and where it breaks down in faithfulness or robustness, along
with curated datasets, benchmarks, and resources that support study and
deployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey).
Evaluation practices that keep evidence visible and temporally aligned are
highlighted, and guidance is distilled on matching topology to uncertainty,
grounding with observable artifacts, planning for shift and streaming, and
treating cost and latency as design budgets. We emphasize that reasoning
structures must balance capacity for grounding and self-correction against
computational cost and reproducibility, while future progress will likely
depend on benchmarks that tie reasoning quality to utility and on closed-loop
testbeds that trade off cost and risk under shift-aware, streaming, and
long-horizon settings. Taken together, these directions mark a shift from
narrow accuracy toward reliability at scale, enabling systems that not only
analyze but also understand, explain, and act on dynamic worlds with traceable
evidence and credible outcomes.

</details>


### [288] [Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework](https://arxiv.org/abs/2509.11645)
*Zhaolong Wu,Pu Luo,Jason Pui Yin Cheung,Teng Zhang*

Main category: cs.AI

TL;DR: 本研究首次全面评估了多模态大语言模型（MLLMs）在青少年特发性脊柱侧凸（AIS）自我管理中的应用。研究构建了一个包含约3000张X光片和诊断文本的数据库，并采用“分而治之”框架，通过视觉问答、领域知识评估和患者教育咨询评估了五个MLLMs。研究发现，MLLMs在解读复杂脊柱X光片和理解AIS护理知识方面存在局限性。为解决这些问题，研究者通过引入脊柱关键点提示和编译AIS知识库以增强检索增强生成（RAG），从而改进了MLLMs。实验结果表明，视觉提示在不同模型架构上的效果各异，而RAG显著提升了模型在知识评估任务上的表现。研究结论是，当前MLLMs在实现AIS个性化护理助手方面能力尚有不足，最大的挑战在于准确检测脊柱畸形的位置（最佳准确率：0.55）和方向（最佳准确率：0.13）。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型（MLLMs）在青少年特发性脊柱侧凸（AIS）自我管理中的应用潜力，并识别其局限性以指导未来研究。

Method: 构建包含约3000张X光片和诊断文本的AIS数据集；采用“分而治之”框架，设计了视觉问答、领域知识评估和患者教育咨询三个评估任务；通过引入脊柱关键点提示和检索增强生成（RAG）技术来改进MLLMs。

Result: MLLMs在解读脊柱X光片和理解AIS知识方面存在局限性。脊柱关键点提示对不同模型架构的视觉能力影响不一。RAG显著提高了模型在知识评估任务上的表现。模型在准确检测脊柱畸形位置（最佳准确率0.55）和方向（最佳准确率0.13）方面能力最弱。

Conclusion: 当前MLLMs在实现AIS个性化护理助手方面能力不足，尤其在准确检测脊柱畸形方面存在显著挑战。

Abstract: This study presents the first comprehensive evaluation of Multimodal Large
Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS)
self-management. We constructed a database of approximately 3,000
anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a
`Divide and Conquer' framework consisting of a visual question-answering task,
a domain knowledge assessment task, and a patient education counseling
assessment task. Our investigation revealed limitations of MLLMs' ability in
interpreting complex spinal radiographs and comprehending AIS care knowledge.
To address these, we pioneered enhancing MLLMs with spinal keypoint prompting
and compiled an AIS knowledge base for retrieval augmented generation (RAG),
respectively. Results showed varying effectiveness of visual prompting across
different architectures, while RAG substantially improved models' performances
on the knowledge assessment task. Our findings indicate current MLLMs are far
from capable in realizing personalized assistant in AIS care. The greatest
challenge lies in their abilities to obtain accurate detections of spinal
deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).

</details>


### [289] [HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction](https://arxiv.org/abs/2509.11719)
*Bingqing Wei,Lianmin Chen,Zhongyu Xia,Yongtao Wang*

Main category: cs.AI

TL;DR: HeLoFusion是一个高效且可扩展的编码器，用于建模异构和多尺度agent交互，在Waymo Open Motion Dataset上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多尺度交互和异构agent的多种行为方面存在不足，难以捕捉复杂的社会动态。

Method: HeLoFusion通过构建以agent为中心的局部多尺度图，并采用聚合-分解消息传递方案和特定类型特征网络来处理agent异构性，从而学习细微的、依赖于类型的交互模式。

Result: 在Waymo Open Motion Dataset上，HeLoFusion在Soft mAP和minADE等关键指标上取得了最先进的性能，并设定了新的基准。

Conclusion: 一种以局部为基础的架构，明确地对多尺度和异构交互进行建模，是推进运动预测的有效策略。

Abstract: Multi-agent trajectory prediction in autonomous driving requires a
comprehensive understanding of complex social dynamics. Existing methods,
however, often struggle to capture the full richness of these dynamics,
particularly the co-existence of multi-scale interactions and the diverse
behaviors of heterogeneous agents. To address these challenges, this paper
introduces HeLoFusion, an efficient and scalable encoder for modeling
heterogeneous and multi-scale agent interactions. Instead of relying on global
context, HeLoFusion constructs local, multi-scale graphs centered on each
agent, allowing it to effectively model both direct pairwise dependencies and
complex group-wise interactions (\textit{e.g.}, platooning vehicles or
pedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of
agent heterogeneity through an aggregation-decomposition message-passing scheme
and type-specific feature networks, enabling it to learn nuanced,
type-dependent interaction patterns. This locality-focused approach enables a
principled representation of multi-level social context, yielding powerful and
expressive agent embeddings. On the challenging Waymo Open Motion Dataset,
HeLoFusion achieves state-of-the-art performance, setting new benchmarks for
key metrics including Soft mAP and minADE. Our work demonstrates that a
locality-grounded architecture, which explicitly models multi-scale and
heterogeneous interactions, is a highly effective strategy for advancing motion
forecasting.

</details>


### [290] [Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning](https://arxiv.org/abs/2509.11880)
*Carlos Celemin,Joseph Brennan,Pierluigi Vito Amadori,Tim Bradley*

Main category: cs.AI

TL;DR: 本文将监督对比学习（SupCon）应用于模仿学习（IL），旨在为游戏环境中的智能体学习更有效的状态表示，以捕捉与动作相关的因素，从而更好地模拟从观测到执行动作的因果关系。


<details>
  <summary>Details</summary>
Motivation: 学习更有效的状态表示，捕捉与动作相关的因素，以更好地模拟从观测到执行动作的因果关系。

Method: 将SupCon损失与连续输出空间集成，并将其应用于模仿学习，以学习游戏环境中的状态表示。

Result: 在Astro Bot、Returnal和多个Atari游戏中，与仅使用监督动作预测损失函数的基线模型相比，实验显示了更高的表示质量、更快的学习收敛速度和更好的泛化能力。

Conclusion: SupCon在模仿学习中的应用可以提高表示质量、加快学习收敛速度并改善泛化能力。

Abstract: This paper introduces a novel application of Supervised Contrastive Learning
(SupCon) to Imitation Learning (IL), with a focus on learning more effective
state representations for agents in video game environments. The goal is to
obtain latent representations of the observations that capture better the
action-relevant factors, thereby modeling better the cause-effect relationship
from the observations that are mapped to the actions performed by the
demonstrator, for example, the player jumps whenever an obstacle appears ahead.
We propose an approach to integrate the SupCon loss with continuous output
spaces, enabling SupCon to operate without constraints regarding the type of
actions of the environment. Experiments on the 3D games Astro Bot and Returnal,
and multiple 2D Atari games show improved representation quality, faster
learning convergence, and better generalization compared to baseline models
trained only with supervised action prediction loss functions.

</details>


### [291] [EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models](https://arxiv.org/abs/2509.11914)
*Yiqun Yao,Naitong Yu,Xiang Li,Xin Jiang,Xuezhi Fang,Wenjia Ma,Xuying Meng,Jing Li,Aixin Sun,Yequan Wang*

Main category: cs.AI

TL;DR: EgoMem是一个为全双工模型设计的终身记忆代理，可以处理实时全模态流。它可以从原始视听流中识别用户，提供个性化响应，并维护用户的长期知识。


<details>
  <summary>Details</summary>
Motivation: 为了使实时模型能够从原始视听流中识别多个用户，提供个性化响应，并维护用户的长期知识。

Method: EgoMem 通过三个异步过程运行：(i) 一个检索过程，通过面部和声音动态识别用户，并从长期记忆中收集相关上下文；(ii) 一个全模态对话过程，基于检索到的上下文生成个性化的音频响应；(iii) 一个记忆管理过程，自动检测全模态流中的对话边界，并提取必要的信息来更新长期记忆。

Result: EgoMem 的检索和记忆管理模块在测试集上实现了超过 95% 的准确率。与微调的 RoboEgo 全模态聊天机器人集成后，该系统在实时个性化对话中实现了超过 87% 的事实一致性分数。

Conclusion: EgoMem 依靠原始视听流，适用于终身、实时和具身场景，并为未来的研究奠定了坚实的基础。

Abstract: We introduce EgoMem, the first lifelong memory agent tailored for full-duplex
models that process real-time omnimodal streams. EgoMem enables real-time
models to recognize multiple users directly from raw audiovisual streams, to
provide personalized response, and to maintain long-term knowledge of users'
facts, preferences, and social relationships extracted from audiovisual
history. EgoMem operates with three asynchronous processes: (i) a retrieval
process that dynamically identifies user via face and voice, and gathers
relevant context from a long-term memory; (ii) an omnimodal dialog process that
generates personalized audio responses based on the retrieved context; and
(iii) a memory management process that automatically detects dialog boundaries
from omnimodal streams, and extracts necessary information to update the
long-term memory. Unlike existing memory agents for LLMs, EgoMem relies
entirely on raw audiovisual streams, making it especially suitable for
lifelong, real-time, and embodied scenarios. Experimental results demonstrate
that EgoMem's retrieval and memory management modules achieve over 95% accuracy
on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot,
the system achieves fact-consistency scores above 87% in real-time personalized
dialogs, establishing a strong baseline for future research.

</details>


### [292] [BuildingGym: An open-source toolbox for AI-based building energy management using reinforcement learning](https://arxiv.org/abs/2509.11922)
*Xilei Dai,Ruotian Chen,Songze Guan,Wen-Tai Li,Chau Yuen*

Main category: cs.AI

TL;DR: BuildingGym是一个开源工具，为建筑能源管理中的强化学习（RL）控制策略训练提供了一个灵活的框架，集成了EnergyPlus模拟器，支持多种RL算法，并能处理外部信号，适用于智能电网和电动汽车社区等灵活环境。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏灵活的框架来实现跨各种建筑能源管理控制问题的强化学习（RL）。

Method: 提出BuildingGym，一个开源工具，作为研究友好且灵活的框架，用于训练建筑能源管理中常见挑战的RL控制策略。它集成了EnergyPlus作为核心模拟器，支持系统级和房间级控制，并能接受外部信号作为控制输入，使其适用于智能电网和电动汽车社区等更灵活的环境。该工具提供了内置的RL算法，简化了优化控制策略的获取过程。

Result: 在模拟的冷却负荷管理任务（包括恒定和动态冷却负荷管理）中，内置的RL算法表现出了强大的性能，证明了BuildingGym在优化冷却策略方面的有效性。

Conclusion: BuildingGym通过允许轻松配置和替换RL算法、模拟器和控制环境或问题，弥合了建筑经理和AI专家之间的差距，从而有效地为冷却负荷管理等任务设置了训练任务。

Abstract: Reinforcement learning (RL) has proven effective for AI-based building energy
management. However, there is a lack of flexible framework to implement RL
across various control problems in building energy management. To address this
gap, we propose BuildingGym, an open-source tool designed as a
research-friendly and flexible framework for training RL control strategies for
common challenges in building energy management. BuildingGym integrates
EnergyPlus as its core simulator, making it suitable for both system-level and
room-level control. Additionally, BuildingGym is able to accept external
signals as control inputs instead of taking the building as a stand-alone
entity. This feature makes BuildingGym applicable for more flexible
environments, e.g. smart grid and EVs community. The tool provides several
built-in RL algorithms for control strategy training, simplifying the process
for building managers to obtain optimal control strategies. Users can achieve
this by following a few straightforward steps to configure BuildingGym for
optimization control for common problems in the building energy management
field. Moreover, AI specialists can easily implement and test state-of-the-art
control algorithms within the platform. BuildingGym bridges the gap between
building managers and AI specialists by allowing for the easy configuration and
replacement of RL algorithms, simulators, and control environments or problems.
With BuildingGym, we efficiently set up training tasks for cooling load
management, targeting both constant and dynamic cooling load management. The
built-in algorithms demonstrated strong performance across both tasks,
highlighting the effectiveness of BuildingGym in optimizing cooling strategies.

</details>


### [293] [Neuromorphic Intelligence](https://arxiv.org/abs/2509.11940)
*Marcel van Gerven*

Main category: cs.AI

TL;DR: 为实现比传统计算方法更节能、更灵活的类脑人工智能，可以利用动力学系统理论作为统一的理论框架，并结合差分遗传编程来发现实现适应性行为的动力学系统。


<details>
  <summary>Details</summary>
Motivation: 传统计算方法在能耗和资源方面存在局限，而神经拟态计算旨在通过模拟人脑的效率、灵活性和适应性来克服这些挑战，以实现可持续、透明和易于访问的智能系统。

Method: 提出将动力学系统理论作为神经拟态计算的统一理论框架，它提供了模拟推理、学习和控制的语言，并将噪声视为学习资源，同时利用差分遗传编程发现实现适应性行为的动力学系统。

Result: 将动力学系统理论作为神经拟态计算的理论基础，可以实现利用噪声进行学习，并通过差分遗传编程发现可实现适应性行为的动力学系统。

Conclusion: 采用动力学系统理论的视角有助于实现神经拟态智能的涌现，从而推动人工智能科学和可持续性发展。

Abstract: Neuromorphic computing seeks to replicate the remarkable efficiency,
flexibility, and adaptability of the human brain in artificial systems. Unlike
conventional digital approaches, which depend on massive computational and
energy resources, neuromorphic systems exploit brain-inspired principles of
computation to achieve orders of magnitude greater energy efficiency. By
drawing on insights from artificial intelligence, neuroscience, physics,
chemistry, and materials science, neuromorphic computing promises to deliver
intelligent systems that are sustainable, transparent, and widely accessible. A
central challenge, however, is to identify a unifying theoretical framework
capable of bridging these diverse disciplines. We argue that dynamical systems
theory provides such a foundation. Rooted in differential calculus, it offers a
principled language for modeling inference, learning, and control in both
natural and artificial substrates. Within this framework, noise can be
harnessed as a resource for learning, while differential genetic programming
enables the discovery of dynamical systems that implement adaptive behaviors.
Embracing this perspective paves the way toward emergent neuromorphic
intelligence, where intelligent behavior arises from the dynamics of physical
substrates, advancing both the science and sustainability of AI.

</details>


### [294] [How to Evaluate Medical AI](https://arxiv.org/abs/2509.11941)
*Ilia Kopanichuk,Petr Anokhin,Vladimir Shaposhnikov,Vladimir Makharev,Ekaterina Tsapieva,Iaroslav Bespalov,Dmitry V. Dylov,Ivan Oseledets*

Main category: cs.AI

TL;DR: 本研究提出了一种新的AI诊断评估指标RPAD和RRAD，通过与多位专家意见进行比较来解决传统指标的局限性，并实现对自由格式诊断的自动化身份识别，准确率高达98%。


<details>
  <summary>Details</summary>
Motivation: 传统的AI医疗诊断评估方法在处理专家判断的内在变异性方面存在不足，导致评估结果不稳定且缺乏可解释性。

Method: 提出相对精确率（RPAD）和相对召回率（RRAD）两个新指标，通过将AI输出与多位专家意见进行比较来评估AI性能，并引入一种自动化方法来识别自由格式的临床诊断，准确率可达98%。

Result: 在360个医疗对话的案例研究中，评估结果显示，顶尖的AI模型（如DeepSeek-V3）在一致性方面可以媲美甚至超越专家共识。研究还发现，专家判断本身存在显著的变异性，有时甚至大于AI与人类之间的变异性。

Conclusion: 现有AI医疗诊断的评估指标存在局限性，相对指标（如RPAD和RRAD）能提供更稳定、更现实的质量衡量。专家判断的变异性不容忽视，这支持了在医疗AI领域采用相对指标的必要性。

Abstract: The integration of artificial intelligence (AI) into medical diagnostic
workflows requires robust and consistent evaluation methods to ensure
reliability, clinical relevance, and the inherent variability in expert
judgments. Traditional metrics like precision and recall often fail to account
for the inherent variability in expert judgments, leading to inconsistent
assessments of AI performance. Inter-rater agreement statistics like Cohen's
Kappa are more reliable but they lack interpretability. We introduce Relative
Precision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new
evaluation metrics that compare AI outputs against multiple expert opinions
rather than a single reference. By normalizing performance against inter-expert
disagreement, these metrics provide a more stable and realistic measure of the
quality of predicted diagnosis. In addition to the comprehensive analysis of
diagnostic quality measures, our study contains a very important side result.
Our evaluation methodology allows us to avoid selecting diagnoses from a
limited list when evaluating a given case. Instead, both the models being
tested and the examiners verifying them arrive at a free-form diagnosis. In
this automated methodology for establishing the identity of free-form clinical
diagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our
approach using 360 medical dialogues, comparing multiple large language models
(LLMs) against a panel of physicians. Large-scale study shows that
top-performing models, such as DeepSeek-V3, achieve consistency on par with or
exceeding expert consensus. Moreover, we demonstrate that expert judgments
exhibit significant variability - often greater than that between AI and
humans. This finding underscores the limitations of any absolute metrics and
supports the need to adopt relative metrics in medical AI.

</details>


### [295] [Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare](https://arxiv.org/abs/2509.11944)
*Susanta Mitra*

Main category: cs.AI

TL;DR: 该研究提出了一个新颖的、基于时间图谱的推理过程，用于处理医疗领域的复杂多模态数据，以提高诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗多模态推理模型在处理复杂任务和正确诊断方面存在局限性，需要更有效的模型来辅助医疗专业人员。

Method: 提出了一种基于时间图谱的推理过程，该过程通过有向图进行建模，能够适应原因的动态变化（通过回溯、精炼推理内容、创建或删除原因），并考虑不同时间点的多模态数据。此外，还提出了一个多代理时间推理框架，用于任务分配和交叉验证，以提高推理准确性。

Result: 通过一些基础实验和分析结果证明了该初步方法的创新性和实用性。

Conclusion: 该研究提出的基于时间图谱的多模态推理方法有望提高医疗诊断的准确性，并能追踪和分析患者的健康和疾病进展。

Abstract: Healthcare and medicine are multimodal disciplines that deal with multimodal
data for reasoning and diagnosing multiple diseases. Although some multimodal
reasoning models have emerged for reasoning complex tasks in scientific
domains, their applications in the healthcare domain remain limited and fall
short in correct reasoning for diagnosis. To address the challenges of
multimodal medical reasoning for correct diagnosis and assist the healthcare
professionals, a novel temporal graph-based reasoning process modelled through
a directed graph has been proposed in the current work. It helps in
accommodating dynamic changes in reasons through backtracking, refining the
reasoning content, and creating new or deleting existing reasons to reach the
best recommendation or answer. Again, consideration of multimodal data at
different time points can enable tracking and analysis of patient health and
disease progression. Moreover, the proposed multi-agent temporal reasoning
framework provides task distributions and a cross-validation mechanism to
further enhance the accuracy of reasoning outputs. A few basic experiments and
analysis results justify the novelty and practical utility of the proposed
preliminary approach.

</details>


### [296] [MusicSwarm: Biologically Inspired Intelligence for Music Composition](https://arxiv.org/abs/2509.11973)
*Markus J. Buehler*

Main category: cs.AI

TL;DR: Decentralized swarm of foundation models can compose music collaboratively without weight updates, outperforming centralized systems in quality and diversity.


<details>
  <summary>Details</summary>
Motivation: Explore decentralized coordination for long-form musical composition using identical foundation models without weight updates.

Method: Compare a centralized multi-agent system with a global critic to a fully decentralized swarm where agents coordinate via stigmergic, peer-to-peer signals, depositing and sensing harmonic, rhythmic, and structural cues, adapting memory, and reaching consensus.

Result: The decentralized swarm yielded superior quality, greater diversity, and structural variety across symbolic, audio, and graph-theoretic analyses, leading in creativity metrics. Analysis revealed a stable configuration of complementary roles and a small-world architecture with efficient long-range connectivity and specialized bridging motifs.

Conclusion: Decentralized coordination via interaction rules, shared memory, and dynamic consensus (MusicSwarm) offers a compute- and data-efficient approach to long-horizon creative structure, applicable beyond music to other collaborative domains.

Abstract: We show that coherent, long-form musical composition can emerge from a
decentralized swarm of identical, frozen foundation models that coordinate via
stigmergic, peer-to-peer signals, without any weight updates. We compare a
centralized multi-agent system with a global critic to a fully decentralized
swarm in which bar-wise agents sense and deposit harmonic, rhythmic, and
structural cues, adapt short-term memory, and reach consensus. Across symbolic,
audio, and graph-theoretic analyses, the swarm yields superior quality while
delivering greater diversity and structural variety and leads across creativity
metrics. The dynamics contract toward a stable configuration of complementary
roles, and self-similarity networks reveal a small-world architecture with
efficient long-range connectivity and specialized bridging motifs, clarifying
how local novelties consolidate into global musical form. By shifting
specialization from parameter updates to interaction rules, shared memory, and
dynamic consensus, MusicSwarm provides a compute- and data-efficient route to
long-horizon creative structure that is immediately transferable beyond music
to collaborative writing, design, and scientific discovery.

</details>


### [297] [Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review](https://arxiv.org/abs/2509.12034)
*Emmanuel Adjei Domfeh,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 本篇论文系统性地回顾了在灾难管理各阶段支持决策的人机协作模式，识别出四大类协作模式（人机决策支持系统、任务与资源协调、信任与透明度、模拟与训练），并分析了其中的子模式。研究强调了AI系统在提升态势感知、响应效率和支持复杂决策方面的潜力，同时也指出了可扩展性、可解释性和系统互操作性方面的局限性。最后，论文提出了未来研究方向，强调了构建适应性强、值得信赖且符合情境的人机系统以增强灾难韧性和公平恢复能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 在灾难管理的关键决策时刻，通常会面临不确定性、动态环境和资源限制的挑战，因此需要探索能够支持决策的人机协作模式。

Method: 通过对51篇同行评审研究进行系统性回顾，识别并分析了支持灾难管理决策的人机协作模式及其子模式。

Result: 识别出四种主要的人机协作模式：人机决策支持系统、任务与资源协调、信任与透明度、模拟与训练。分析了认知增强智能、多智能体协调、可解释AI和虚拟训练环境等子模式。研究发现AI系统能够增强态势感知、提高响应效率并支持复杂决策，但也存在可扩展性、可解释性和系统互操作性方面的不足。

Conclusion: AI系统在提升灾难管理决策能力方面具有巨大潜力，但需要克服可扩展性、可解释性和互操作性等挑战。未来的研究应侧重于开发适应性强、值得信赖且情境感知的AI系统，以增强灾难韧性和促进公平的恢复过程。

Abstract: In high-stakes disaster scenarios, timely and informed decision-making is
critical yet often challenged by uncertainty, dynamic environments, and limited
resources. This paper presents a systematic review of Human-AI collaboration
patterns that support decision-making across all disaster management phases.
Drawing from 51 peer-reviewed studies, we identify four major categories:
Human-AI Decision Support Systems, Task and Resource Coordination, Trust and
Transparency, and Simulation and Training. Within these, we analyze
sub-patterns such as cognitive-augmented intelligence, multi-agent
coordination, explainable AI, and virtual training environments. Our review
highlights how AI systems may enhance situational awareness, improves response
efficiency, and support complex decision-making, while also surfacing critical
limitations in scalability, interpretability, and system interoperability. We
conclude by outlining key challenges and future research directions,
emphasizing the need for adaptive, trustworthy, and context-aware Human-AI
systems to improve disaster resilience and equitable recovery outcomes.

</details>


### [298] [When Safe Unimodal Inputs Collide: Optimizing Reasoning Chains for Cross-Modal Safety in Multimodal Large Language Models](https://arxiv.org/abs/2509.12060)
*Wei Cai,Shujuan Liu,Jian Zhao,Ziyan Shi,Yusheng Zhao,Yuchen Yuan,Tianle Zhang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: MLLMs存在隐式推理风险，可能导致不安全的输出。本研究提出了SSUI数据集和SRPO训练框架来解决此问题，并在安全基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: MLLMs容易受到隐式推理风险的影响，即无害的单模态输入可能组合成有风险的多模态数据，从而产生有害输出。这是因为MLLMs在长链推理过程中难以维持安全对齐。

Method: 提出SSUI数据集，这是首个包含针对跨模态挑战的可解释推理路径的数据集。设计了基于SSUI数据集的新型训练框架SRPO，以使MLLM的内部推理过程与人类安全价值观对齐。

Result: SRPO训练的模型在包括RSBench在内的关键安全基准测试上取得了最先进的成果，显著优于开源和顶级商业MLLMs。

Conclusion: SRPO框架和SSUI数据集能够有效地提高MLLMs在处理跨模态推理时的安全性。

Abstract: Multimodal Large Language Models (MLLMs) are susceptible to the implicit
reasoning risk, wherein innocuous unimodal inputs synergistically assemble into
risky multimodal data that produce harmful outputs. We attribute this
vulnerability to the difficulty of MLLMs maintaining safety alignment through
long-chain reasoning. To address this issue, we introduce
Safe-Semantics-but-Unsafe-Interpretation (SSUI), the first dataset featuring
interpretable reasoning paths tailored for such a cross-modal challenge. A
novel training framework, Safety-aware Reasoning Path Optimization (SRPO), is
also designed based on the SSUI dataset to align the MLLM's internal reasoning
process with human safety values. Experimental results show that our
SRPO-trained models achieve state-of-the-art results on key safety benchmarks,
including the proposed Reasoning Path Benchmark (RSBench), significantly
outperforming both open-source and top-tier commercial MLLMs.

</details>


### [299] [Bridging Engineering and AI Planning through Model-Based Knowledge Transformation for the Validation of Automated Production System Variants](https://arxiv.org/abs/2509.12091)
*Hamied Nabizada,Lasse Beers,Alain Chahine,Felix Gehlhoff,Oliver Niggemann,Alexander Fay*

Main category: cs.AI

TL;DR: MBSE模型可以通过集成规划语义来增强，从而实现AI规划驱动的系统变体验证。


<details>
  <summary>Details</summary>
Motivation: 现有的MBSE模型缺乏符号规划语义，限制了它们评估系统任务满足能力和效率的能力。

Method: 提出了一种模型驱动的方法，使用SysML配置文件为核心规划构建块引入可重用的刻板印象，并开发了一个算法来生成PDDL域和问题文件。

Result: 通过飞机组装案例研究证明了该方法的可行性，其中现有工程模型被丰富了规划语义，并用于生成一致的规划产物。

Conclusion: 所生成的方法可以无缝集成到现有工程模型中，并利用AI规划来验证系统变体，从而弥合了工程和规划之间的差距。

Abstract: Engineering models created in Model-Based Systems Engineering (MBSE)
environments contain detailed information about system structure and behavior.
However, they typically lack symbolic planning semantics such as preconditions,
effects, and constraints related to resource availability and timing. This
limits their ability to evaluate whether a given system variant can fulfill
specific tasks and how efficiently it performs compared to alternatives.
  To address this gap, this paper presents a model-driven method that enables
the specification and automated generation of symbolic planning artifacts
within SysML-based engineering models. A dedicated SysML profile introduces
reusable stereotypes for core planning constructs. These are integrated into
existing model structures and processed by an algorithm that generates a valid
domain file and a corresponding problem file in Planning Domain Definition
Language (PDDL). In contrast to previous approaches that rely on manual
transformations or external capability models, the method supports native
integration and maintains consistency between engineering and planning
artifacts.
  The applicability of the method is demonstrated through a case study from
aircraft assembly. The example illustrates how existing engineering models are
enriched with planning semantics and how the proposed workflow is applied to
generate consistent planning artifacts from these models. The generated
planning artifacts enable the validation of system variants through AI
planning.

</details>


### [300] [JustEva: A Toolkit to Evaluate LLM Fairness in Legal Knowledge Inference](https://arxiv.org/abs/2509.12104)
*Zongyue Xue,Siyuan Zheng,Shaochun Wang,Yiran Hu,Shenran Wang,Yuxin Yao,Haitao Li,Qingyao Ai,Yiqun Liu,Yun Liu,Weixing Shen*

Main category: cs.AI

TL;DR: JustEva是一个开源工具包，用于评估LLM在法律任务中的公平性，发现现有LLM存在显著的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在法律实践中的公平性，解决其“黑箱”操作带来的司法公正问题。

Method: JustEva工具包包含结构化标签系统（65个非法外因素）、三个核心公平性指标（不一致性、偏差、不平衡的错误率）、统计推断方法和可视化。支持两种实验：LLM结构化输出生成和对LLM输出进行统计分析。

Result: 实证应用表明，现有LLM在公平性方面存在显著缺陷，缺乏公平可信的LLM法律工具。

Conclusion: JustEva为评估和改进法律领域的算法公平性提供了便捷的工具和方法基础。

Abstract: The integration of Large Language Models (LLMs) into legal practice raises
pressing concerns about judicial fairness, particularly due to the nature of
their "black-box" processes. This study introduces JustEva, a comprehensive,
open-source evaluation toolkit designed to measure LLM fairness in legal tasks.
JustEva features several advantages: (1) a structured label system covering 65
extra-legal factors; (2) three core fairness metrics - inconsistency, bias, and
imbalanced inaccuracy; (3) robust statistical inference methods; and (4)
informative visualizations. The toolkit supports two types of experiments,
enabling a complete evaluation workflow: (1) generating structured outputs from
LLMs using a provided dataset, and (2) conducting statistical analysis and
inference on LLMs' outputs through regression and other statistical methods.
Empirical application of JustEva reveals significant fairness deficiencies in
current LLMs, highlighting the lack of fair and trustworthy LLM legal tools.
JustEva offers a convenient tool and methodological foundation for evaluating
and improving algorithmic fairness in the legal domain.

</details>


### [301] [Advancing Medical Artificial Intelligence Using a Century of Cases](https://arxiv.org/abs/2509.12194)
*Thomas A. Buckley,Riccardo Conci,Peter G. Brodeur,Jason Gusdorf,Sourik Beltrán,Bita Behrouzi,Byron Crowe,Jacob Dockterman,Muzzammil Muhammad,Sarah Ohnigian,Andrew Sanchez,James A. Diao,Aashna P. Shah,Daniel Restrepo,Eric S. Rosenberg,Andrew S. Lea,Marinka Zitnik,Scott H. Podolsky,Zahir Kanjee,Raja-Elie E. Abdulnour,Jacob M. Koshy,Adam Rodman,Arjun K. Manrai*

Main category: cs.AI

TL;DR: LLM在鉴别诊断方面超越了医生，但图像解释和文献检索仍有待改进。CPC-Bench和CaBot可用于持续跟踪医学AI的进展。


<details>
  <summary>Details</summary>
Motivation: 评估AI在医学案例推理和展示方面的能力，并与人类医生进行比较。

Method: 利用CPC-Bench（包含7102个CPCs和1021个图像挑战）评估了LLM，并开发了AI讨论者“Dr. CaBot”来生成书面和幻灯片演示。

Result: 在377个当代CPCs中，o3在60%的病例中将最终诊断排在第一位，在84%的病例中排在前十名，准确率达到98%；CaBot在与人类专家生成的文本的盲法比较中，74%的情况下被误认为人类专家生成，并且在质量维度上得分更高。然而，在文献检索和图像任务方面，LLM的表现较差，o3和Gemini 2.5 Pro在图像挑战方面的准确率为67%。

Conclusion: LLM在复杂的文本鉴别诊断方面超越了人类医生，并能令人信服地模仿专家医学演示，但在图像解释和文献检索方面仍是弱项。CPC-Bench和CaBot有望实现医学AI进展的透明化和持续跟踪。

Abstract: BACKGROUND: For over a century, the New England Journal of Medicine
Clinicopathological Conferences (CPCs) have tested the reasoning of expert
physicians and, recently, artificial intelligence (AI). However, prior AI
evaluations have focused on final diagnoses without addressing the multifaceted
reasoning and presentation skills required of expert discussants.
  METHODS: Using 7102 CPCs (1923-2025) and 1021 Image Challenges (2006-2025),
we conducted extensive physician annotation and automated processing to create
CPC-Bench, a physician-validated benchmark spanning 10 text-based and
multimodal tasks, against which we evaluated leading large language models
(LLMs). Then, we developed "Dr. CaBot," an AI discussant designed to produce
written and slide-based video presentations using only the case presentation,
modeling the role of the human expert in these cases.
  RESULTS: When challenged with 377 contemporary CPCs, o3 (OpenAI) ranked the
final diagnosis first in 60% of cases and within the top ten in 84% of cases,
outperforming a 20-physician baseline; next-test selection accuracy reached
98%. Event-level physician annotations quantified AI diagnostic accuracy per
unit of information. Performance was lower on literature search and image
tasks; o3 and Gemini 2.5 Pro (Google) achieved 67% accuracy on image
challenges. In blinded comparisons of CaBot vs. human expert-generated text,
physicians misclassified the source of the differential in 46 of 62 (74%) of
trials, and scored CaBot more favorably across quality dimensions. To promote
research, we are releasing CaBot and CPC-Bench.
  CONCLUSIONS: LLMs exceed physician performance on complex text-based
differential diagnosis and convincingly emulate expert medical presentations,
but image interpretation and literature retrieval remain weaker. CPC-Bench and
CaBot may enable transparent and continued tracking of progress in medical AI.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [302] [Terahertz electrodynamics in a zero-field Wigner crystal](https://arxiv.org/abs/2509.10624)
*Su-Di Chen,Ruishi Qi,Ha-Leem Kim,Qixin Feng,Ruichen Xia,Dishan Abeysinghe,Jingxu Xie,Takashi Taniguchi,Kenji Watanabe,Dung-Hai Lee,Feng Wang*

Main category: cond-mat.mes-hall

TL;DR: 本论文使用超灵敏片上太赫兹光谱技术，首次测量了零磁场下二维材料MoSe2的Wigner晶体的交流电导率，发现了远高于高磁场下的共振峰，并揭示了无序性对Wigner晶体的稳定作用以及Wigner晶体与电子液体之间的竞争关系导致了绝缘体-金属相变。


<details>
  <summary>Details</summary>
Motivation: 理解零磁场下Wigner晶体是物理学中的一个长期目标，因为它具有内在的简单性，并可能与密度驱动的绝缘体-金属相变有关。然而，其交流电导率这一关键的电动力学性质从未被测量过。

Method: 开发了一种超灵敏的片上太赫兹（THz）光谱技术，用于探测静电门控的、封装在六方氮化硼中的单层MoSe2中的交流电导率。

Result: 观察到了与零磁场Wigner晶体钉扎模式相对应的亚太赫兹共振峰，其频率远高于高磁场下的情况。研究发现，适度的无序性显著地稳定了Wigner晶体。随着密度增加趋向熔化，观察到钉扎模式与增长的、代表电子液体的Drude成分共存，这种竞争导致了二维电子系统的绝缘体-金属相变。

Conclusion: 本研究阐明了零磁场Wigner晶体的低能电动力学性质，并展示了片上太赫兹光谱技术作为研究二维材料中关联量子物相的有力工具。

Abstract: In clean two-dimensional (2D) systems, electrons are expected to
self-organize into a regular lattice, a Wigner crystal, when their mutual
Coulomb repulsion overwhelms kinetic energy. Understanding the Wigner crystal
at zero magnetic field is a long-sought goal in physics, thanks to its
fundamental simplicity and possible connection to the density-driven
metal-insulator transition. To date, evidence for such a crystal has been
reported across various platforms. However, the AC conductivity of a zero-field
Wigner crystal, a key observable characterizing its electrodynamics, has never
been measured. Here, we develop an ultrasensitive on-chip terahertz (THz)
spectroscopy technique to probe the AC conductivity in electrostatically gated
monolayer MoSe2 encapsulated in hexagonal boron nitride. We observe a sub-THz
resonance corresponding to the pinning mode of a zero-field Wigner crystal,
whose frequency is orders of magnitude higher than those under high magnetic
fields. Using the pinning mode as an indicator, we reveal that moderate
disorder notably stabilizes the Wigner crystal. With increasing density towards
melting, we find that the pinning mode of the Wigner crystal coexists with a
growing Drude component characteristic of an electron liquid, and the
competition between these two components in the conductivity spectra leads to
the insulator-metal transition of the 2D electron system. Our findings not only
elucidate the low-energy electrodynamics of a zero-field Wigner crystal, but
also establish on-chip THz spectroscopy as a powerful probe for correlated
quantum phases in two-dimensional materials.

</details>


### [303] [A new skyrmion topological transition driven by higher-order exchange interactions in Janus MnSeTe](https://arxiv.org/abs/2509.10661)
*Megha Arya,Moritz A. Goerzen,Lionel Calmels,Rémi Arras,Soumyajyoti Haldar,Stefan Heinze,Dongzhe Li*

Main category: cond-mat.mes-hall

TL;DR: 高阶交换相互作用（HOI）在单层MnSeTe中引发了称为“ferric transition”的新拓扑跃迁，该跃迁不影响斯格明子的稳定性和塌陷，但会显著改变Bloch点。Janus MnSeTe由于其强DMI表现出高斯格明子能量势垒，是2D自旋电子学的有力平台。


<details>
  <summary>Details</summary>
Motivation: 探索高阶交换相互作用（HOI）对二维（2D）范德华磁体中斯格明子形成、稳定性、塌陷和拓扑跃迁的影响，特别是其在单层极限下的作用。

Method: 利用第一性原理计算和原子自旋模拟。

Result: 发现了由HOI引起的新型拓扑跃迁（“ferric transition”）。 HOI对斯格明子的稳定性和塌陷影响不大，但显著改变了Bloch点。预测Janus MnSeTe具有很高的斯格明子能量势垒。

Conclusion: HOI在斯格明子拓扑跃迁中扮演了意想不到的角色，Janus MnSeTe为2D斯格明子学提供了一个鲁棒的平台。

Abstract: Two-dimensional (2D) van der Waals magnets offer a promising platform for
pushing skyrmion technology to the single-layer limit with high tunability.
While Dzyaloshinskii-Moriya interaction (DMI) is often recognized as central to
skyrmion formation, their stability, collapse, and topological transition in 2D
materials remain largely unexplored. In particular, the effect of higher-order
exchange interactions (HOI) on these phenomena is unknown. Here, using
first-principles calculations and atomistic spin simulations, we report a new
topological transition generated by HOI, which we term 'ferric transition', in
single-layer MnSeTe. Surprisingly, skyrmion stability and collapse remain
largely unaffected by HOI due to the dominant role of DMI near the saddle
point, whereas the Bloch point is strongly modified, giving rise to this novel
transition. This mechanism is fundamentally distinct from the well-known radial
and chimera transitions. Moreover, we predict that Janus MnSeTe exhibits
remarkably high skyrmion energy barriers due to its strong DMI, among the
highest reported for intrinsic 2D magnets. Our findings unveil an unexpected
role of HOI in skyrmion topological transitions and establish Janus MnSeTe as a
robust platform for 2D skyrmionics.

</details>


### [304] [Localization and Wetting of 4He Inside Pre-plated Nanopores](https://arxiv.org/abs/2509.10690)
*Sutirtha Paul,Taras Lakoba,Paul E. Sokol,Adrian Del Maestro*

Main category: cond-mat.mes-hall

TL;DR: 通过在纳米孔中预先涂覆碱金属来调控氦的量子相变。


<details>
  <summary>Details</summary>
Motivation: 在纳米尺度下实现量子流体，以研究宏观量子波函数的热效应和量子效应，这对理解量子物理具有重要意义。

Method: 结合几体薛定谔方程的直接求解和量子蒙特卡洛模拟，研究了氦在预涂覆不同元素（稀有气体和碱金属）的圆柱形纳米孔中的行为。

Result: 稀有气体预涂层导致氦强烈的附着在孔壁上；碱金属（如铯）预涂层则由于与氦的弱相互作用，使得氦能够在孔中心区域实现非局域化，从而实现一维量子流体。

Conclusion: 碱金属预涂层的纳米孔可以实现可调控的一维限制性量子流体，为实验研究量子流体提供了新的可能性。

Abstract: Low dimensional quantum fluids, where one can probe the effects of enhanced
thermal and quantum fluctuations on macroscopic quantum wavefunctions, can be
experimentally realized through transverse physical confinement of superfluid
helium on scales smaller than the coherence length. Reaching this scale is
difficult, requiring confinement in single or multiple pores with nanometer
radii. Porous silicates such as MCM-41 have a pore radius larger than the
coherence length of 4He, and in this work we systematically explore the
possibility of pre-plating pores with different elements to reduce the pore
size without localizing the confined superfluid. Through a direct solution of
the few-body Schrodinger equation combined with quantum Monte Carlo
simulations, we explore the behavior of helium confined inside cylindrical
nanopores for a range of pre-plating elements, including rare gases and alkali
metals. For rare gases, we find that helium remains strongly attracted to the
pore walls and any atoms in the core form an incompressible liquid. For alkali
metals such as Cs, weak interactions between helium and the pre-plating
material prevent localization near the walls and enable delocalization in the
pore center. Our results extend previous results for helium wetting on flat two
dimensional coated substrates to the curved geometry inside nanopores, and
demonstrate that alkali pre-plated nanopores may enable a tunable
one-dimensional confined quantum liquid of helium.

</details>


### [305] [Design and Optimization of Spin Dynamics in Ge Quantum Dots: g-Factor Modulation, Dephasing Sweet Spots, and Phonon-Induced Relaxation](https://arxiv.org/abs/2509.10731)
*Ngoc Duong,Daryoosh Vashaee*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过结合自洽静电学和四带Luttinger-Kohn哈密顿量，在三维模型中研究了应变SiGe/Ge异质结构中的量子点空穴自旋量子比特，考虑了器件几何、材料界面和自旋轨道相互作用，并量化了器件尺寸和栅极偏压对波函数定位、g因子调制的影，发现了可最小化g因子对电荷噪声敏感性的“甜点”，并模拟了依赖于尺寸和磁场的自旋弛豫时间T1，为优化量子比特相干性提供了预测模型和设计指导。


<details>
  <summary>Details</summary>
Motivation: 精确模拟空穴量子点量子比特中的自旋动力学，需要高保真度的模拟，以捕捉实际的器件几何、材料界面和自洽静电学。

Method: 结合自洽静电学和四带Luttinger-Kohn哈密顿量，在三维模型中研究了应变SiGe/Ge异质结构中的量子点空穴自旋量子比特，以解决自旋轨道相互作用、波函数不对称和g张量各向异性问题。

Result: 量化了器件尺寸和栅极偏压对波函数局域化、电场诱导g因子调制的影，识别了垂直电场中的“甜点”，从而最小化了g因子对电荷噪声的敏感性，延长了自旋退相干时间。还模拟了由声子耦合引起的自旋弛豫，揭示了与强Rashba型自旋轨道耦合和接近B^{-8}的磁场标度一致的、依赖于尺寸的T1行为。

Conclusion: 建立了一个用于优化平面Ge量子点中自旋相干性的预测建模框架，并为设计可扩展、电控的IV族半导体空穴自旋量子比特提供了定量的设计指导。

Abstract: Accurate modeling of spin dynamics in hole-based quantum dot qubits demands
high-fidelity simulations that capture realistic device geometries, material
interfaces, and self-consistent electrostatics. Here, we present a
comprehensive three-dimensional study of gate-defined quantum dot hole spin
qubits in strained Si$_{0.2}$Ge$_{0.8}$/Ge heterostructures. In contrast to
prior work relying on idealized confinement or decoupled Poisson-Schr\"odinger
treatments, our approach combines self-consistent electrostatics with a
four-band Luttinger-Kohn Hamiltonian to resolve spin-orbit interactions,
wavefunction asymmetries, and g-tensor anisotropies in realistic device
structures. We quantify the impact of device size and gate bias on wavefunction
localization, electric-field-induced g-factor modulation, and identify "sweet
spots" in vertical electric field where g-factor sensitivity to charge noise is
minimized, enhancing spin dephasing times. Spin relaxation due to phonon
coupling is also modeled, revealing size-dependent T1 behavior consistent with
strong Rashba-type spin-orbit coupling and a magnetic-field scaling near
$B^{-8}$. This work establishes a predictive modeling framework for optimizing
spin coherence in planar Ge quantum dots and provides quantitative design
guidance for scalable, electrically controlled hole spin qubits in group-IV
semiconductors.

</details>


### [306] [RKKY interaction mediated by a spin-polarized 2D electron gas with Rashba and altermagnetic coupling](https://arxiv.org/abs/2509.10778)
*Anirban Kundu*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了具有Rashba自旋-轨道耦合和交变磁性色散的二维电子气中杂质自旋之间的RKKY交换相互作用。


<details>
  <summary>Details</summary>
Motivation: 为了理解和控制自旋电子系统中杂质自旋之间的磁相互作用。

Method: 使用格林函数形式主义研究了两种自旋极化能带的RKKY交换相互作用。

Result: 在强面外铁磁有序的情况下，海森堡、伊辛和Dzyaloshinskii-Moriya交换相互作用项表现出振荡空间调制，并以1/R^2衰减。所有交换项都显示出可通过交换耦合强度调节的节拍状图案。DM矢量位于二维平面内，DM相互作用与RSOC强度呈奇函数关系，且随RSOC强度呈振荡增长。在弱面内有序的情况下，海森堡交换相互作用对面内交换耦合强度表现出非线性依赖性。

Conclusion: 研究结果揭示了RSOC和交变磁性色散对RKKY相互作用的复杂影响，为设计具有特定磁特性的自旋电子器件提供了理论基础。

Abstract: Magnetic interactions between impurity spins play a crucial role in
determining magnetic configurations in spintronic systems. Using a Green's
function formalism, we investigate Ruderman-Kittel-Kasuya-Yosida (RKKY)
exchange interactions between two localized spins mediated by a two-dimensional
electron gas arising from two spin-polarized bands with Rashba spin-orbit
coupling (RSOC) and altermagnetic dispersion. We analyze two distinct regimes:
(a) strong out-of-plane ferromagnetic order, and (b) weak in-plane order. For
out-of-plane magnetization, the Heisenberg, Ising, and Dzyaloshinskii-Moriya
(DM) exchange interaction terms exhibit oscillatory spatial modulations and
asymptotically decay as $1/R^{2}$ with impurity separation. Besides, all
exchange terms display beating-like patterns that can be tuned via the exchange
coupling strength between conduction electrons and ferromagnetic ordering. The
DM vector lies within the two-dimensional plane, with the DM interaction being
odd in the RSOC strength, oscillatory, and increasing in magnitude with RSOC
strength. In contrast, it is even in the out-of-plane Zeeman field strength and
oscillatory. Furthermore, the Heisenberg interaction exhibits a non-linear
dependence on the altermagnetic band parameter. In the case of weak in-plane
order, the Heisenberg exchange interaction shows a non-linear dependence on the
in-plane exchange coupling strength.

</details>


### [307] [Measuring pulse heating in Si quantum dots with individual two-level fluctuators](https://arxiv.org/abs/2509.10816)
*Feiyang Ye,Lokendra S. Dhami,John M. Nichol*

Main category: cond-mat.mes-hall

TL;DR: 脉冲加热会影响量子比特的保真度，但其确切原因尚不清楚。本研究通过测量量子点中的电荷双能级数（TLF）对脉冲加热的敏感性，发现加热的程度与脉冲的幅度、频率和门电压有关，而与门到TLF的距离无关。研究还发现， the idling voltage of the pulsed gates 也是一个影响因素，表明 the gates 下的电子积累是导致加热的原因。研究人员提出，减小带电门区域可以缓解加热问题。


<details>
  <summary>Details</summary>
Motivation: 电压脉冲用于初始化、门操作和读出半导体自旋量子比特，但它们会产生热量，从而降低量子比特的频率和门保真度。了解脉冲加热的原因对于提高量子计算性能至关重要。

Method: 利用硅/硅锗量子点中的电荷双能级数（TLF）来测量脉冲加热效应。研究人员通过改变脉冲的幅度、频率、门与TLF的距离以及门的idling voltage来观察加热的程度。

Result: TLF对脉冲加热敏感。加热的程度与脉冲的幅度、频率以及门的idling voltage有关，但与门的距离无关。电压的idling voltage 影响着加热的程度，表明门下的电子积累是导致加热的原因。

Conclusion: 脉冲加热效应与量子比特操作的保真度密切相关。通过减小带电门区域，有望缓解此问题，为提高量子比特性能提供新的方向。

Abstract: To encode quantum information in semiconductor spin qubits, voltage pulses
are necessary for initialization, gate operation, and readout. However, these
pulses dissipate heat, shifting spin-qubit frequencies and reducing gate
fidelities. The cause of this pulse heating in quantum-dot devices is unknown.
Here, we measure pulse heating using charged two-level fluctuators (TLFs) in
Si/SiGe quantum dots. We find that the TLFs are susceptible to pulse heating.
The amount of heating depends on the pulse amplitude and frequency, but not on
the distance between the pulsed gates and the TLFs. The amount of heating also
generally depends on the idling voltage of the pulsed gates, suggesting that
electrons accumulated under or near the gates contribute to the heating. We
hypothesize that reducing the area of the gates with electrons nearby could
mitigate the heating.

</details>


### [308] [Correlated interlayer quantum Hall state in alternating twisted trilayer graphene](https://arxiv.org/abs/2509.10930)
*Dohun Kim,Gyeoul Lee,Nicolas Leconte,Seyoung Jin,Takashi Taniguchi,Kenji Watanabe,Jeil Jung,Gil Young Cho,Youngwook Kim*

Main category: cond-mat.mes-hall

TL;DR: 交替扭曲三层石墨烯在约5°的扭曲角下表现出磁转运特性，揭示了电子-空穴不对称性，并可以通过层依赖电势移位进行解释。在电荷中性点（$
u_{	ext{tot}}=0$），出现了三个低电阻态，这被认为是由类似量子自旋霍尔绝缘体的自旋极化螺旋边缘模式引起的。在$
u_{	ext{tot}}=-1$时，观察到当中间层和底层各半填充而顶层在$
u=-2$时保持惰性时，电阻被抑制，这与层间激子量子霍尔态一致。


<details>
  <summary>Details</summary>
Motivation: 探索交替扭曲三层石墨烯中因堆叠顺序和扭曲几何形状引起的电子结构控制，以及在这些系统中寻找关联态。

Method: 通过实验测量磁转运特性，并利用Hartree-Fock平均场理论进行分析。

Result: 在交替扭曲三层石墨烯中观察到电子-空穴不对称性，并能通过层依赖电势移位解释。在$
u_{	ext{tot}}=0$时，发现了三个低电阻态，归因于自旋极化螺旋边缘模式。在$
u_{	ext{tot}}=-1$时，观察到层间激子量子霍尔态的证据。

Conclusion: 交替扭曲三层石墨烯能够展现出关联的层间量子霍尔相，包括自旋极化边缘输运和激子序。

Abstract: Trilayer graphene allows systematic control of its electronic structure
through stacking sequence and twist geometry, providing a versatile platform
for correlated states. Here we report magnetotransport in alternating twisted
trilayer graphene with a twist angle of about 5$^{\circ}$. The data reveal an
electron-hole asymmetry that can be captured by introducing layer-dependent
potential shifts. At charge neutrality ($\nu_{\mathrm{tot}}=0$), three
low-resistance states appear, which Hartree-Fock mean-field analysis attributes
to emerging spin-resolved helical edge modes similar to those of quantum spin
Hall insulators. At $\nu_{\mathrm{tot}}=-1$, we also observe suppressed
resistance when the middle and bottom layers are each half filled while the top
layer remains inert at $\nu=-2$, consistent with an interlayer excitonic
quantum Hall state. These results demonstrate correlated interlayer quantum
Hall phases in alternating twisted trilayer graphene, including spin-resolved
edge transport and excitonic order.

</details>


### [309] [Interaction-Driven Asymmetry in the Breakdown of the $ν$ = 1 Quantum Hall State](https://arxiv.org/abs/2509.10958)
*Hoai Anh Ho,Jian Huang,L. N. Pfeiffer,K. W. West*

Main category: cond-mat.mes-hall

TL;DR: 本文在铁磁性因子ν=1的整数量子霍尔状态下，报告了在不同频带下纵向和横向输运响应的实时检测。


<details>
  <summary>Details</summary>
Motivation: 研究整数量子霍尔状态下的输运响应，以理解电子-电子相互作用在该状态下的作用。

Method: 通过调谐ν，同时研究筛选环境和体激发结构的演变，并检测纵向和横向输运响应。

Result: 发现ν>1和ν<1下的不对称行为，表明输运不稳定性主要由相互作用而非单粒子能带图决定。

Conclusion: 电子-电子相互作用在整数量子霍尔相中不可或缺，并且整数量子霍尔相和分数量子霍尔相可能基于不同的多体纠缠结构。

Abstract: We report real-time detection of longitudinal and transverse transport
responses across distinct frequency bands in a ferromagnetic filling factor
$\nu$ = 1 integer quantum Hall state. By tuning $\nu$, we simultaneously access
the evolution of the screening environment and bulk excitation structure. The
resulting asymmetric breakdown, for $\nu>1$ and $\nu<1$, reveals that
interaction effects, rather than a single-particle band picture, dominate the
transport instability. Our findings highlight the indispensability of
electron-electron interactions even in integer quantum Hall phases, suggesting
that distinct many-body entanglement structures underlie both integer and
fractional topological phases.

</details>


### [310] [Large Chern-Number Quantum Anomalous Hall Effect from Canted Antiferromagnetic Order in $d$-Electron System on Kagome Lattice](https://arxiv.org/abs/2509.10976)
*Waquar Ahmed,Steffen Schaeffer,Pierre Lombardo,Roland Hayn,Imam Makhfudz*

Main category: cond-mat.mes-hall

TL;DR: d电子在没有自旋-轨道耦合的情况下，与非共线的反铁磁序相互作用，产生了非相对论性的自旋分裂和内在的贝里曲率。对于非共面（倾斜）的非共线自旋序，其布里渊区积分是重要的，即使没有显式的晶格或跃迁自旋-轨道耦合。这导致了非零（标量）自旋手性，并且当费米能级处于合适的能隙时，可以出现创纪录的陈数C=±5。


<details>
  <summary>Details</summary>
Motivation: 研究没有自旋-轨道耦合的d电子在非共线反铁磁序下的行为，特别是自旋分裂、贝里曲率和陈数的产生。

Method: 考虑d电子与非共线反铁磁序的相互作用，并通过数值和分析方法计算贝里曲率、陈数和自旋手性。

Result: 发现非共线自旋序可以导致非相对论性的自旋分裂和内在的贝里曲率，在特定条件下可以达到C=±5的陈数。通过改变格点能量可以分裂C=±5平台，导致不同的陈数。通过改变泽曼交换场或格点能量可以驱动拓扑相变。

Conclusion: 该系统有可能用于量子信息，因为其拓扑相变可以通过控制参数（如泽曼交换场和格点能量）来实现。

Abstract: Electrons of $d$-symmetry in a kagome lattice are considered which interact
with non-collinear antiferromagnetic order in the absence of spin-orbit
coupling. The non-collinearity of spin texture gives rise to non-relativistic
spin splitting and the associated intrinsic Berry curvature. The integral of
the latter over the Brillouin zone becomes nontrivial for non-coplanar (canted)
non-collinear spin order even without explicit on-site or transfer spin-orbit
coupling. That gives rise to a nonzero (scalar) spin chirality, and a record
value for the Chern number of $C=\pm 5$ can appear when the Fermi level is in
an appropriate gap for isotropic electron hopping integrals, or nearly
isotropic ones. The numerical results for this topological quantum anomalous
Hall effect are supported by an analytical formula. It is possible to split the
$C=\pm 5$ plateau into different possible nonzero values for the Chern number
by varying the onsite energies. The topological phase transitions between Hall
plateaus can be driven by flipping the Zeeman-like exchange field or
controlling the onsite energies, alluding to the potential of this system to
quantum information.

</details>


### [311] [Bridging Structure and Activity in Nanocatalysts via Machine Learning and Global Structure Representations](https://arxiv.org/abs/2509.10985)
*Sofia Zinzani,Francesca Baletto,Kevin Rossi*

Main category: cond-mat.mes-hall

TL;DR: 机器学习框架可准确预测Pt纳米催化剂的质量活性，并能高效筛选高活性结构。


<details>
  <summary>Details</summary>
Motivation: 为了高效设计纳米催化剂，需要建立其结构与催化性质之间的映射关系。

Method: 利用表面位点广义配位数分布或纳米颗粒的对距离分布函数，通过机器学习模型预测Pt纳米催化剂在电化学氧还原反应中的质量活性，并结合贝叶斯优化筛选高活性结构。

Result: 机器学习模型能够准确预测Pt纳米催化剂的质量活性；结合贝叶斯优化，能在有限的评估次数内从大量候选结构中高效筛选出高活性结构。

Conclusion: 该研究为加速催化剂的理论和实验识别提供了可靠的蓝图。

Abstract: Establishing a mapping between nanocatalysts structure and their catalytic
properties is essential for efficient design. To this end, we demonstrate the
accuracy of a general machine learning framework on a representative and
challenging application: predicting the mass activity of Pt nanoparticles for
the electrochemical oxygen reduction reaction, estimated via a microkinetic
model. Accurate models are obtained when leveraging either a nanocatalyst's
structure representation accessible at the computational level, namely the
surface site generalized coordination number distributions, or one accessible
experimentally, namely the nanoparticle's pair distance distribution function.
Building on this result, we demonstrate that our machine learning model, in
tandem with Bayesian optimization, efficiently identifies the Top-10 and
Top-100 most active structures out of a large pool of candidates comprising
more than 50000 different structures, after probing the activity only of a few
thousand structures. These findings provide a robust blueprint for accelerated
theoretical and experimental identification of active nanocatalysts.

</details>


### [312] [Absence of detectable spin and orbital pumping from Ni to Nb by out-of-plane ferromagnetic resonance](https://arxiv.org/abs/2509.11005)
*Omolara A. Bakare,Galen T. Street,Sachli Abdizadeh,Rachel E. Maizel,Christoph Klewe,Satoru Emori*

Main category: cond-mat.mes-hall

TL;DR: Ni表现出的角动量传递比预期的要少。


<details>
  <summary>Details</summary>
Motivation: Ni作为一种元素铁磁体，被认为在自旋流和轨道流方面表现出显著的轨道流。

Method: 通过比较没有Ni（FeV/Nb）和含有Ni（FeV-Ni/Nb）的异质结构中的垂直铁磁共振来寻找Ni的轨道流信号。

Result: FeV/Nb系列显示出吉尔伯特阻尼随Nb衬层厚度增加而增加，这归因于从FeV到Nb的自旋流。然而，FeV-Ni/Nb系列没有显示出阻尼的增加，表明从Ni到Nb没有显著的自旋流或轨道流。

Conclusion: Ni的角动量传递比预期的要少，这表明对一些强轨道电子效应的解释可能需要进一步的考虑。

Abstract: Excited ferromagnets can pump spin angular momentum, along with possibly
orbital angular momentum. Among elemental ferromagnets, Ni has been proposed to
exhibit substantial orbital pumping relative to spin pumping. Here, we search
for a signature of orbital pumping by Ni, specifically by comparing
out-of-plane ferromagnetic resonance in heterostructures without Ni (FeV/Nb)
and with Ni (FeV-Ni/Nb). The FeV/Nb series shows a clear increase in Gilbert
damping with the Nb sink thickness, attributed to spin pumping from FeV to Nb.
Surprisingly, the FeV-Ni/Nb series exhibits no such damping increase, revealing
no significant spin or orbital pumping from Ni to Nb. Our results offer a fresh
perspective on angular-momentum transfer in Ni-based heterostructures,
suggesting that the interpretation of some strong orbitronic effects may
require further consideration.

</details>


### [313] [Planar Ballistic Electron Emission Spectroscopy for Single-Shot Probing of Energy Barrier Inhomogeneity at Junction Interface](https://arxiv.org/abs/2509.11037)
*Jiwan Kim,Jaehyeong Jo,Jungjae Park,Hyunjae Park,Eunseok Hyun,Jisang Lee,Sejin Oh,Kibog Park*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种无需耗时微观探测即可探测金属/半导体界面能垒不均匀性的实验方法，结合了Tung模型和Bell-Kaiser理论，并通过Pt/4H-SiC(0001)结进行了验证。


<details>
  <summary>Details</summary>
Motivation: 提出了一种无需耗时微观探测即可探测金属/半导体界面能垒不均匀性的新实验方法。

Method: 提出了一种基于已知界面能垒统计性质和平面隧道结（作为平行连接的 the ballistic electron emission microscopy (BEEM) tips 阵列）的实验方法，并将Tung模型纳入Bell-Kaiser理论以分析局部BEEM信号。

Result: 通过研究Pt/4H-SiC(0001)结的模型系统，验证了所提出的理论方法，并研究了该界面的能垒不均匀性。

Conclusion: 所提出的实验方法能够有效地探测金属/半导体界面能垒的不均匀性，并已通过对Pt/4H-SiC(0001)结的研究得到验证。

Abstract: We propose an experimental methodology for probing the energy barrier
inhomogeneity at the metal/semiconductor interface without the need for
time-consuming microscopic survey. It is based on the known statistical nature
of the interfacial energy barrier and the use of planar tunnel junction as an
array of parallelly-connected ballistic electron emission microscopy (BEEM)
tips. In order to analyze a lump of local BEEM signals, we incorporate the Tung
model into the Bell-Kaiser theory. To validate our theoretical strategies, we
investigate the interfacial energy barrier inhomogeneity of Pt/4H-SiC(0001)
junction as a model system.

</details>


### [314] [Topological excitonic insulators in electron bilayers modulated by twisted hBN](https://arxiv.org/abs/2509.11041)
*Yongxin Zeng,Allan H. MacDonald,Nemin Wei*

Main category: cond-mat.mes-hall

TL;DR: 在没有磁场的情况下，扭转的六方氮化硼（hBN）双层或多层中的两个过渡金属硫属化物（TMD）单层可以形成手征p波激子凝聚物，该凝聚物具有量子反常霍尔效应和反向流超流性。


<details>
  <summary>Details</summary>
Motivation: 研究在没有磁场的情况下，在双层量子霍尔系统中是否存在类似物理现象，以及在扭转的hBN层和TMD单层系统中实现手征p波激子凝聚物的可能性。

Method: 使用平均场理论来分析扭转的hBN层如何调制TMD层，并推导出由扭转hBN层形成的铁电莫尔图案对两个TMD层施加相反的三角晶格调制势。

Result: 证明了当总空穴填充数为每莫尔单位晶胞$
u=1$时，这种几何结构可以形成手征p波激子凝聚物，并导致量子反常霍尔效应与反向流超流性共存。给出了TMD空穴双层由扭转hBN调制产生的平均场相图，并讨论了实现p波凝聚态的条件。

Conclusion: 提出的模型和相图为在实验中实现手征p波激子凝聚物提供了理论基础，并提出了可能证实其存在的实验建议。

Abstract: Equilibrium interlayer exciton condensation is common in bilayer quantum Hall
systems and is characterized by spontaneous phase coherence between isolated
layers. It has been predicted that similar physics can occur in the absence of
a magnetic field in some two-dimensional semiconductor bilayers. In this work
we consider the case of two transition metal dichalcogenide (TMD) monolayers
separated by a twisted hexagonal boron nitride (hBN) bilayer or multilayer. The
hBN layers suppress tunneling between the TMD layers so that phase coherence is
spontaneous when it is present. When twisted, the hBN layers also form a
ferroelectric moir\'e pattern that applies opposite triangular-lattice
modulation potentials to the two TMD layers. We show via mean-field theory that
at total hole filling per moir\'e unit cell $\nu=1$, this geometry can favor a
chiral p-wave exciton condensate state in which the quantum anomalous Hall
effect coexists with counter-flow superfluidity. We present a mean-field phase
diagram for TMD hole bilayers modulated by twisted hBN, discuss the conditions
needed for the realization of the p-wave condensate state, and propose
experiments that could confirm its presence.

</details>


### [315] [Glimpsing at Electron's Form Factor through Quasiparticle Interference in Twisted Bilayer Graphene](https://arxiv.org/abs/2509.11223)
*D. -H. -Minh Nguyen,Francisco Guinea,Dario Bercioux*

Main category: cond-mat.mes-hall

TL;DR: 电子的形状因子特征可在一维材料的拟粒子干涉谱中观察到。


<details>
  <summary>Details</summary>
Motivation: 研究扭曲双层石墨烯中的拟粒子干涉，以了解电子的形状因子特征。

Method: 使用实空间紧束缚计算结合核多项式方法，并与连续哈密顿量得到的形状因子范数进行比较。

Result: 拟粒子干涉信号显示出手性结构，揭示了狄拉克点附近状态之间的所有不同干涉过程。

Conclusion: 拟粒子干涉是探测形状因子的一个潜在方法，该因子控制着材料的量子几何和多体状态。

Abstract: We show that characteristics of the electron's form factor in two-dimensional
materials are observable in quasiparticle interference (QPI) spectrum. We study
QPI in twisted bilayer graphene using real-space tight-binding calculations
combined with the kernel polynomial method, which agrees excellently with the
form factor norm obtained from the continuum Hamiltonian. The QPI signals,
displaying a chiral structure, reveal all distinct interference processes
between states near the Dirac points. We propose pseudospin textures of twisted
bilayer graphene to explain all the interference mechanisms. Our results
provide microscopic insights into electronic eigenstates of twisted bilayer
graphene and suggest QPI as a potential method for probing the form factor,
which governs the material's quantum geometry and many-body states.

</details>


### [316] [Electron Hydrodynamics in Graphene : Experimental and Theoretical Status](https://arxiv.org/abs/2509.11315)
*Subhalaxmi Nayak,Cho Win Aung,Thandar Zaw Win,Ashutosh Dwibedi,Sabyasachi Ghosh,Sesha Vempati*

Main category: cond-mat.mes-hall

TL;DR: 本文综述了石墨烯中的电子流体动力学，重点介绍了实验观测和理论发展。


<details>
  <summary>Details</summary>
Motivation: 石墨烯中的电子流体动力学是当前研究的热点，理解其行为对于开发新型电子器件至关重要。

Method: 本文回顾了实验观测（如负邻近电阻、泊肃叶流、维德曼-弗兰兹定律的显著违反）和理论发展（如计算热力学和输运系数的流体动力学框架）。

Result: 实验观测和理论发展都为理解石墨烯中的电子流体动力学提供了重要见解。

Conclusion: 石墨烯中的电子流体动力学是一个活跃的研究领域，未来的研究将继续探索其新颖的现象和潜在的应用。

Abstract: The present work comprehensively reviews electron hydrodynamics in graphene,
highlighting both experimental observations and theoretical developments. Key
experimental signatures such as negative vicinity resistance, Poiseuille flow,
and significant violation of the Wiedemann-Franz (WF) law have been discussed,
with special emphasis on Lorenz ratio measurements. In the theoretical
direction, recent efforts have focused on developing hydrodynamic frameworks
for calculating the thermodynamic and transport coefficients of electrons in
graphene. The present work has briefly addressed the theoretical framework
adopted by our group.

</details>


### [317] [Localizing Individual Exciton on a Quantum Hall Antidot](https://arxiv.org/abs/2509.11352)
*Rui Pu,Naomi Mizuno,Fernando Camino,Runchen Li,Kenji Watanabe,Takashi Taniguchi,Dmitri Averin,Xu Du*

Main category: cond-mat.mes-hall

TL;DR: This paper demonstrates a new type of quantum Hall quasiparticle exciton in a double-layer quantum Hall system using an antidot setup. This exciton is a quantum-coherent bound state of an electron and a hole on spatially separated edge channels, coupled by tunneling and Coulomb interaction. The study observes quantum-coherent dynamics, allows electrical tuning of individual excitons, and demonstrates quantum superposition of states.


<details>
  <summary>Details</summary>
Motivation: Excitonic phases in double-layer quantum Hall systems, formed by spatially separated electrons and holes condensing through Coulomb interaction, have garnered significant interest due to their role in correlated electron physics. This work aims to demonstrate and study a new type of quantum Hall quasiparticle exciton in a related but distinct setup.

Method: The study employs a quantum Hall antidot with two spatially separated edge channels. This setup allows for the localization and electrical tuning of individual quantum Hall excitons, which are formed by an electron and a hole on their respective edges coupled via intralayer tunneling and Coulomb interaction. The quantum-coherent dynamics are observed by tracking the evolution of conductance peaks around the electron-hole resonance, and quantum superposition is investigated through gate-dependent tunneling conductance.

Result: The paper reports the observation of quantum-coherent dynamics of the quantum Hall quasiparticle exciton, reflected in the evolution of the position and magnitude of conductance peaks. The antidot setup successfully enabled the localization and electrical tuning of individual excitons. Furthermore, quantum superposition of vacuum and electron-hole pairing states was observed via gate-dependent tunneling conductance.

Conclusion: The research successfully demonstrates a new type of quantum Hall quasiparticle exciton in a quantum Hall antidot system. The study provides insights into the quantum-coherent dynamics and superposition properties of these excitons, achieving semi-quantitative understanding through modeling. This work opens up possibilities for creating novel quantum systems based on multiple quantum Hall quasiparticles.

Abstract: Quantum Hall systems host quasiparticles demonstrating correlated electron
physics and non-trivial quantum statistics. Excitonic phases, archetypical for
interaction effect, have attracted significant interest in recent years in
double-layer quantum Hall systems where spatially separated electrons and holes
form bosonic condensate through Coulomb interaction. Here, employing the
approach of quantum Hall antidot with two spatially separated edge channels, we
demonstrate a new type of quantum Hall quasiparticle exciton which represents a
quantum-coherent bound state of an electron and a hole situated on their
corresponding edges coupled through intralayer tunneling and Coulomb
interaction. Quantum-coherent dynamics of the exciton is reflected in the
observed evolution of the position and magnitude of the antidot conductance
peaks around the electron-hole resonance. The quantum Hall antidot setup allows
localization and electrical tuning of individual quantum Hall excitons. Quantum
superposition of vacuum- and electron-hole pairing states is observed through
the gate-dependent tunneling conductance of the antidot. Modeling the
electron-hole pair as a coupled two-level system, semi-quantitative
understanding of experimental observations is achieved. This work opens avenues
for creating quantum systems of multiple quantum Hall quasiparticles.

</details>


### [318] [Direct imaging reveals electromechanical ionic memory in 2D nanochannels](https://arxiv.org/abs/2509.11637)
*Kalluvadi Veetil Saurav,Nathan Ronceray,Baptiste Coquinot,Agustin D. Pizarro,Ashok Keerthi,Theo Emmerich,Aleksandra Radenovic,Boya Radha*

Main category: cond-mat.mes-hall

TL;DR: 本论文通过结合操作干涉成像和电动测量，直接观察到纳米通道中电压诱导的壁起泡现象，这是其忆阻特性的关键起源。


<details>
  <summary>Details</summary>
Motivation: 解释纳米流体忆阻器中离子记忆的微观机制，并解决其起源的争议。

Method: 结合操作干涉成像和电动测量，直接观察和表征电压诱导的壁起泡。

Result: 识别出两种起泡机制：单向（静电力驱动）和双向（渗透压驱动）。成功解释了器件演变和器件间差异性。

Conclusion: 电机械耦合是二维纳米通道中离子记忆的可靠途径，为开发高性能离子忆阻器和电驱动纳米流体阀门开辟了新途径。

Abstract: Nanofluidic memristors promise brain-inspired information processing with
ions, yet their microscopic origin remains debated. So far, ionic memory has
been attributed to ion-specific interactions, dynamic wetting, chemical
reactions or mechanical deformations, yet typically without direct evidence.
Here, by combining operando interferometric imaging with electrokinetic
measurements, we directly visualize voltage-induced blistering of the confining
walls of two-dimensional (2D) nanochannels, as key origin of memristive
hysteresis. We identify two distinct classes of blisters: unidirectional,
driven by electrostatic forces on surface charges, and bidirectional, arising
from osmotic pressure due to concentration polarization. This mechanistic
framework explains device evolution and device-to-device variability, and
reframes stochastic blistering as a functional design element. Our results
constitute a direct proof of electromechanical coupling as a robust pathway to
ionic memory in 2D nanochannels and open routes toward high-performance ionic
memristors and electrically actuated nanofluidic valves.

</details>


### [319] [Exchange and spin-orbit proximity driven topological and transport phenomena in twisted graphene/CrI$_3$ heterostructures](https://arxiv.org/abs/2509.11670)
*M. Jafari,M. Gmitra,A. Dyrdał*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯/CrI3异质结的电子、磁性和拓扑性质得到了研究，发现了控制拓扑和磁性相变的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究石墨烯/CrI3异质结的电子、磁性和拓扑性质，探索控制拓扑和磁性相变的机制。

Method: 利用第一性原理和kp方法研究石墨烯/CrI3异质结。

Result: 发现了特定扭转角度下石墨烯狄拉克锥位于CrI3带隙中，并推导了低能有效哈密顿量；研究了反常霍尔电导和谷霍尔电导，并讨论了量子反常霍尔绝缘体到平庸绝缘体相变的可能。

Conclusion: 石墨烯/CrI3异质结的应变工程在控制二维范德华异质结的拓扑和磁性相方面具有巨大潜力。

Abstract: We present results of comprehensive first-principles and kp-method studies of
electronic, magnetic, and topological properties of graphene on a monolayer of
CrI$_3$. First, we identify a twist angle between the graphene and CrI$_3$,
that positions the graphene Dirac cones within the bandgap of CrI$_3$. Then, we
derive the low-energy effective Hamiltonian describing electronic properties of
graphene Dirac cones. Subsequently, we examine anomalous and valley Hall
conductivity and discuss possible topological phase transition from a quantum
anomalous Hall insulator to a trivial insulating state, concomitant a change in
the magnetic ground state of CrI$_3$. These findings highlight the potential of
strain engineering in two-dimensional van der Waals heterostructures for
controlling topological and magnetic phases.

</details>


### [320] [Dual-mode operation of ring-shaped spin Hall magnetoresistance sensor with biaxial sensing capability](https://arxiv.org/abs/2509.11671)
*Jiayi Xu,Yuxin Si,Jiaqi Wang,Tingxuan Zhang,Zhenfei Hou,Yihong Wu*

Main category: cond-mat.mes-hall

TL;DR: Presented a NiFe/Pt multiring bridge structure for spin Hall magnetoresistance sensing, achieving high sensitivity and linearity in two perpendicular directions. AC excitation effectively reduces 1/f noise.


<details>
  <summary>Details</summary>
Motivation: To develop a highly sensitive and linear spin Hall magnetoresistance sensor for multidimensional magnetic field detection.

Method: Fabricated a NiFe/Pt multiring bridge structure. Investigated sensor performance under DC and AC excitation for magnetic fields in two perpendicular directions. Optimized NiFe thickness.

Result: Achieved linear response to magnetic fields perpendicular to current under DC excitation. Achieved linear response with near-zero offset to magnetic fields aligned with current under AC excitation (driven by spin-orbit torque). Reduced 1/f noise to sub-microvolt per sqrt(Hz) at 1 Hz with AC excitation.

Conclusion: The biaxial sensing capability of the NiFe/Pt multiring bridge structure offers a promising approach for advanced multidimensional magnetic field detection applications.

Abstract: We present a spin Hall magnetoresistance sensor based on a NiFe/Pt multiring
bridge structure, which exhibits high sensitivity and good linearity in two
perpendicular directions within the sensor plane. Under DC excitation, it
responds linearly to magnetic field perpendicular to the current direction,
whereas AC excitation enables a linear response with near-zero offset to
magnetic field aligned with the current direction, driven by spin-orbit torque
effect. Moreover, the AC excitation effectively mitigates low-frequency 1/f
noise down to sub-microvolt per sqrt(Hz) at 1 Hz. Systematic investigations
have been performed to optimize the NiFe thickness while keeping the Pt
thickness at 2 nm. The biaxial sensing capability offers a promising approach
for multidimensional magnetic field detection in advanced sensing applications.

</details>


### [321] [Generic continuum model formalism for moiré superlattice systems](https://arxiv.org/abs/2509.11747)
*Bo Xie,Jianqi Huang,Jianpeng Liu*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种通用的方法来构建莫尔超晶格的连续模型，并使用该模型准确地解释了扭转双层MoTe2的电子特性。


<details>
  <summary>Details</summary>
Motivation: 莫尔超晶格系统是探索新奇量子现象的理想平台，然而，构建准确的连续模型来描述这些系统中的关联和拓扑态是一个挑战，特别是在扭转过渡金属二卤化物等复杂系统中。

Method: 提出了一种通用的形式主义来构建任意莫尔超晶格的连续模型，该模型可以外推到任何扭转角。该方法的核心思想是将微观电子特性视为系统固有的属性，而晶格弛豫则被视为随扭转角变化的外部输入。这种分离允许使用一组固定的模型参数来统一描述连续模型随角度的变化。通过基于第一性原理密度泛函理论计算的数据设计了一个数值工作流程来提取模型参数。

Result: 将该框架应用于扭转双层MoTe2，获得了一组模型参数，这些参数在三个不同的扭转角下精确地再现了第一性原理计算的结果，包括电子能带结构、电荷密度分布和陈数。此外，该模型能够稳健地外推到更小的扭转角。

Conclusion: 这项工作不仅提供了对莫尔超晶格微观特性的更精确的理解，而且为未来通用莫尔超晶格系统中低能电子特性的理论研究奠定了基础。

Abstract: The moir\'e superlattice system provides an excellent platform for exploring
various novel quantum phenomena. To theoretically tackle the diverse correlated
and topological states emerging from moir\'e superlattices, one usually adopts
an effective low-energy continuum model based on which the electron-electron
effects are further considered. However, the construction of an accurate
continuum model remains a challenging task, particularly for complex moir\'e
superlattices such as twisted transition metal dichalcogenides. In this work,
we develop a formalism for constructing generic continuum models that are in
principle applicable for arbitrary moir\'e superlattices and are extrapolatable
to any twist angles. Our key insight is that the microscopic electronic
properties are intrinsic properties of the system, which should remain
invariant across all twist angles; the lattice relaxations act as external
inputs that vary with twist angles and are coupled with the electrons, and the
coupling coefficients are characterized by intrinsic parameters. This partition
enables a universal description of the angle variation of the continuum model
using a single set of model parameters. To extract the model parameters, we
design a numerical workflow based on data from first principles density
functional theory calculations. We apply this framework to twisted bilayer
MoTe$_{2}$, and obtain a single set of model parameters that accurately
reproduce first-principles results, including electronic band structures,
charge density distributions and Chern numbers, at three different twist
angles. Furthermore, the model extrapolates robustly to smaller twist angles.
Our work not only provides a more precise understanding of the microscopic
properties of moir\'e superlattices, but also lays a foundation for future
theoretical studies of low-energy electronic properties in generic moir\'e
superlattice systems.

</details>


### [322] [Non-Hermitian quantum geometric tensor and nonlinear electrical response](https://arxiv.org/abs/2509.11765)
*Kai Chen,Jie Zhu*

Main category: cond-mat.mes-hall

TL;DR: 非厄米量子几何张量（QGT）决定了具有光谱线隙的系统的非线性电响应。


<details>
  <summary>Details</summary>
Motivation: 探索非厄米量子几何张量（QGT）在控制具有光谱线隙的系统的非线性电响应中的作用。

Method: 利用一维和二维非厄米模型，研究量子度规和贝里曲率如何产生非线性电导率和波包宽度相关的响应。

Result: 证明了量子度规产生与散射时间无关的非线性电导率，而贝里曲率引起与波包宽度相关的响应。发现波包宽度显著影响非厄米输运，这在厄米系统中不存在。

Conclusion: 非厄米QGT统一了非厄米响应理论，将量子态几何与可观测的输运现象联系起来，并为利用几何效应在拓扑器件和工程材料中提供了途径。

Abstract: We demonstrate that the non-Hermitian quantum geometric tensor (QGT) governs
nonlinear electrical responses in systems with a spectral line gap. The quantum
metric, which is a component of the QGT and takes complex values in
non-Hermitian systems, generates an intrinsic nonlinear conductivity
independent of the scattering time, while the complex Berry curvature induces a
wavepacket-width-dependent response. Using one-dimensional and two-dimensional
non-Hermitian models, we establish a universal link between nonlinear dynamics
and the QGT, thereby connecting quantum state geometry to observable transport
phenomena. Crucially, our analysis indicates that the wavepacket width
significantly affects non-Hermitian transport -- a feature absent in Hermitian
systems. This framework unifies non-Hermitian response theory by revealing how
geometric degrees of freedom encode transport in open and synthetic quantum
matter. Our results bridge fundamental quantum geometry with emergent
functionality, offering pathways to exploit geometric effects in topological
devices and engineered materials.

</details>


### [323] [Radio-frequency charge detection on graphene electron-hole double quantum dots](https://arxiv.org/abs/2509.12061)
*Katrin Hecker,Samuel Möller,Hubert Dulisch,Şiyar Duman,Leon Stecher,Lucca Valerius,Tobias Deußen,Saketh Ravuri,Kenji Watanabe,Takashi Taniguchi,Florian Libisch,Christian Volk,Christoph Stampfer*

Main category: cond-mat.mes-hall

TL;DR: Bilayer graphene QDs with QPC enable high-fidelity charge detection for quantum computation.


<details>
  <summary>Details</summary>
Motivation: High-fidelity detection of charge transitions in QDs is crucial for solid-state quantum computation.

Method: Using a capacitively coupled QPC in bilayer graphene QDs, suppressing screening and maximizing readout contrast for electron-hole QDs. The scheme is applied to a single-particle electron-hole double QD.

Result: Demonstrated time-resolved charge state detection and magnetic field-dependent tunneling rates.

Conclusion: This high-fidelity readout scheme is promising for individual spin and valley states, essential for spin, valley, or spin-valley qubits in bilayer graphene.

Abstract: High-fidelity detection of charge transitions in quantum dots (QDs) is a key
ingredient in solid state quantum computation. We demonstrate high-bandwidth
radio-frequency charge detection in bilayer graphene quantum dots (QDs) using a
capacitively coupled quantum point contact (QPC). The device design suppresses
screening effects and enables sensitive QPC-based charge readout. The QPC is
arranged to maximize the readout contrast between two neighboring, coupled
electron and hole QDs. We apply the readout scheme to a single-particle
electron-hole double QD and demonstrate time-resolved detection of charge
states as well as magnetic field dependent tunneling rates. This promises a
high-fidelity readout scheme for individual spin and valley states, which is
important for the operation of spin, valley or spin-valley qubits in bilayer
graphene.

</details>


### [324] [Mutual synchronization of two asymmetric-nano-constriction-based spin-Hall nano-oscillators](https://arxiv.org/abs/2509.12113)
*Roman V. Ovcharov,Roman S. Khymyn,Akash Kumar,Johan Åkerman*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种不对称纳米收缩（ANC）设计的自旋霍尔纳米振荡器（SHNO），并使用微磁模拟研究了两个此类器件的互同步。


<details>
  <summary>Details</summary>
Motivation: ANC 几何结构可以在 50 纳米以下的距离实现强偶极耦合，同时保持每个振荡器的独立偏置。研究了 ANC-SHNO 的自动振荡特性，包括其宽频率调谐范围和负/正非线性之间的场控交叉。

Method: 使用微磁模拟研究了两个 ANC-SHNO 器件的互同步，仅通过偶极杂散场实现，无需电或自旋波耦合。

Result: 结果表明，两个 ANC-SHNO 器件可以实现同相（0 度）或反相（180 度）锁定。当振荡器幅度相近时，两种同步模式均可实现；当幅度不平衡时，系统会进入反相状态，同时抑制较弱的振荡器。

Conclusion: ANC-SHNO 平台通过结合强保守耦合以及独立的频率和增益控制，为相干振荡器阵列、神经形态计算架构和非厄米自旋电子动力学的实验探索提供了可扩展的途径。

Abstract: We propose an asymmetric-nanoconstriction (ANC) design of spin-Hall
nano-oscillators (SHNOs) and investigate mutual synchronization of a pair of
such devices using micromagnetic simulations. The ANC geometry enables strong
dipolar coupling at sub-50 nm separations while preserving independent current
bias for each oscillator. We first characterize the auto-oscillation of a
single ANC-SHNO, revealing a broad frequency tuning range and a
field-controlled crossover between negative and positive nonlinearities. We
then demonstrate that two such oscillators can mutually synchronize solely via
dipolar stray fields, without electrical or spin-wave coupling. Depending on
the bias conditions, the coupled pair exhibits robust in-phase (0{\deg}) or
out-of-phase (180{\deg}) locking. Notably, we find a bias-dependent amplitude
correlation: when the oscillators sustain comparable amplitudes, both in-phase
and out-of-phase synchronization are accessible, whereas amplitude imbalance
drives the system into an out-of-phase state accompanied by suppression of the
weaker oscillator. By combining strong conservative coupling with independent
frequency and gain control, the ANC-SHNO platform provides a scalable route
toward phased oscillator arrays, neuromorphic computing architectures, and
experimental exploration of non-Hermitian spintronic dynamics.

</details>


### [325] [Many-body skyrmion interactions in helimagnets](https://arxiv.org/abs/2509.12172)
*N. P. Vizarim,J. C. Bellizotti Souza,Raí M. Menezes,Clécio C. de Souza Silva,P. A. Venegas,M. V. Milošević*

Main category: cond-mat.mes-hall

TL;DR: 许多研究表明，多体相互作用对凝聚态体系的结构、稳定性和动力学有显著影响。本文理论研究了螺旋磁体中 Skyrmion 之间的成对和多体相互作用，并考虑了铁磁和圆锥形自旋背景。通过微磁模拟，我们分离了 Skyrmion-Skyrmion 对势的交换、Dzyaloshinskii-Moriya 和 Zeeman 贡献，结果表明圆锥形相中 Skyrmion 的结合能强烈依赖于薄膜厚度。对于圆锥形相中的小 Skyrmion 团簇，三体相互作用对内聚能的贡献很大，与成对项相当，而四体项仅在小磁场下才相关。当系统接近铁磁相时，这些高阶贡献消失，相互作用基本变为成对相互作用。我们的研究结果表明，螺旋磁体中 Skyrmion 相互作用的实际模型必须包含多体项，以准确捕捉 Skyrmion 晶体的行为，并指导控制 Skyrmion 相和动力学的策略。


<details>
  <summary>Details</summary>
Motivation: 许多体相互作用对凝聚态体系的结构、稳定性和动力学有显著影响。本文旨在理论研究螺旋磁体中 Skyrmion 之间的成对和多体相互作用。

Method: 本文使用微磁模拟来分离 Skyrmion-Skyrmion 对势的交换、Dzyaloshinskii-Moriya 和 Zeeman 贡献。

Result: 在圆锥形相中，Skyrmion 的结合能强烈依赖于薄膜厚度。对于圆锥形相中的小 Skyrmion 团簇，三体相互作用对内聚能的贡献很大，与成对项相当，而四体项仅在小磁场下才相关。当系统接近铁磁相时，这些高阶贡献消失，相互作用基本变为成对相互作用。

Conclusion: 本文的研究结果表明，螺旋磁体中 Skyrmion 相互作用的实际模型必须包含多体项，以准确捕捉 Skyrmion 晶体的行为，并指导控制 Skyrmion 相和动力学的策略。

Abstract: Many-body interactions strongly influence the structure, stability, and
dynamics of condensed-matter systems, from atomic lattices to interacting
quasi-particles such as superconducting vortices. Here, we investigate
theoretically the pairwise and many-body interaction terms among skyrmions in
helimagnets, considering both the ferromagnetic and conical spin backgrounds.
Using micromagnetic simulations, we separate the exchange,
Dzyaloshinskii-Moriya, and Zeeman contributions to the skyrmion-skyrmion pair
potential, and show that the binding energy of skyrmions within the conical
phase depends strongly on the film thickness. For small skyrmion clusters in
the conical phase, three-body interactions make a substantial contribution to
the cohesive energy, comparable to that of pairwise terms, while four-body
terms become relevant only at small magnetic fields. As the system approaches
the ferromagnetic phase, these higher-order contributions vanish, and the
interactions become essentially pairwise. Our results indicate that realistic
models of skyrmion interactions in helimagnets in the conical phase must
incorporate many-body terms to accurately capture the behavior of skyrmion
crystals and guide strategies for controlling skyrmion phases and dynamics.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [326] [ReCross: Efficient Embedding Reduction Scheme for In-Memory Computing using ReRAM-Based Crossbar](https://arxiv.org/abs/2509.10627)
*Yu-Hong Lai,Chieh-Lin Tsai,Wen Sheng Lim,Han-Wen Hu,Tei-Wei Kuo,Yuan-Hao Chang*

Main category: cs.AR

TL;DR: ReCross是一种利用ReRAM Crossbar进行深度学习推荐模型（DLRM）嵌入式归约的内存内计算（IMC）方案，通过优化嵌入式访问模式和ReRAM Crossbar特性，显著减少了执行时间和提高了能效。


<details>
  <summary>Details</summary>
Motivation: 深度学习推荐模型（DLRM）因其庞大稀疏的嵌入层而面临内存带宽瓶颈，导致推理时间和能耗增加。

Method: ReCross通过智能分组和映射共同出现的嵌入、跨Crossbar复制频繁访问的嵌入、以及使用新的动态开关ADC电路动态选择内存内处理操作来共同优化嵌入访问模式和ReRAM Crossbar特性。

Result: ReCross实现了3.97倍的执行时间缩减和6.1倍的能效提升，优于现有的IMC方法。

Conclusion: ReCross有效地解决了DLRM嵌入归约中的内存瓶颈问题，通过内存内计算显著提升了性能和能效。

Abstract: Deep learning-based recommendation models (DLRMs) are widely deployed in
commercial applications to enhance user experience. However, the large and
sparse embedding layers in these models impose substantial memory bandwidth
bottlenecks due to high memory access costs and irregular access patterns,
leading to increased inference time and energy consumption. While resistive
random access memory (ReRAM) based crossbars offer a fast and energy-efficient
solution through in-memory embedding reduction operations, naively mapping
embeddings onto crossbar arrays leads to poor crossbar utilization and thus
degrades performance. We present ReCross, an efficient ReRAM-based in-memory
computing (IMC) scheme designed to minimize execution time and enhance energy
efficiency in DLRM embedding reduction. ReCross co-optimizes embedding access
patterns and ReRAM crossbar characteristics by intelligently grouping and
mapping co-occurring embeddings, replicating frequently accessed embeddings
across crossbars, and dynamically selecting in-memory processing operations
using a newly designed dynamic switch ADC circuit that considers runtime energy
trade-offs. Experimental results demonstrate that ReCross achieves a 3.97x
reduction in execution time and a 6.1x improvement in energy efficiency
compared to state-of-the-art IMC approaches.

</details>


### [327] [DOSA: Differentiable Model-Based One-Loop Search for DNN Accelerators](https://arxiv.org/abs/2509.10702)
*Charles Hong,Qijing Huang,Grace Dinh,Mahesh Subedar,Yakun Sophia Shao*

Main category: cs.AR

TL;DR: DOSA通过可微性能模型和梯度下降优化技术同时探索硬件设计空间和算法-硬件映射空间，以优化硬件参数和映射，相比随机搜索和贝叶斯优化，在改善DNN模型能在相似样本数量下，能-时积方面分别提高了2.80倍和12.59倍。


<details>
  <summary>Details</summary>
Motivation: 同时优化硬件参数和算法-硬件映射是硬件设计空间探索中的关键问题，但以往的方法将这两个巨大的、高度非凸的空间分开探索，导致组合爆炸，给优化器带来巨大困难。

Method: 提出DOSA，包含可微性能模型和基于梯度下降的优化技术，以同时探索硬件设计空间和映射空间，找到高性能设计点。

Result: DOSA在改善DNN模型能-时积方面，相比随机搜索和贝叶斯优化，在相似样本数量下，分别提高了2.80倍和12.59倍。通过增加学习模型到分析模型，DOSA在真实DNN加速器上实现了1.82倍的能-时积改进。

Conclusion: DOSA能够同时探索硬件设计空间和映射空间，有效解决以往方法带来的优化难题，并在性能和能效方面取得显著提升。DOSA具有良好的模块化和灵活性，可以通过集成学习模型进一步优化特定硬件的设计。

Abstract: In the hardware design space exploration process, it is critical to optimize
both hardware parameters and algorithm-to-hardware mappings. Previous work has
largely approached this simultaneous optimization problem by separately
exploring the hardware design space and the mapspace - both individually large
and highly nonconvex spaces - independently. The resulting combinatorial
explosion has created significant difficulties for optimizers.
  In this paper, we introduce DOSA, which consists of differentiable
performance models and a gradient descent-based optimization technique to
simultaneously explore both spaces and identify high-performing design points.
Experimental results demonstrate that DOSA outperforms random search and
Bayesian optimization by 2.80x and 12.59x, respectively, in improving DNN model
energy-delay product, given a similar number of samples. We also demonstrate
the modularity and flexibility of DOSA by augmenting our analytical model with
a learned model, allowing us to optimize buffer sizes and mappings of a real
DNN accelerator and attain a 1.82x improvement in energy-delay product.

</details>


### [328] [Design and Analysis of Approximate Hardware Accelerators for VVC Intra Angular Prediction](https://arxiv.org/abs/2509.10751)
*Lucas M. Leipnitz de Fraga,Cláudio Machado Diniz*

Main category: cs.AR

TL;DR: VVC 编码中的整数变换提出了几种乘法器替代方案，通过平均系数子集来降低硬件复杂度，并在编码效率和硬件资源之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: HEVC 的 VVC 标准在提高压缩效率的同时，也显著增加了计算复杂度，尤其是在帧内预测部分。该部分使用了大量的乘法操作，硬件加速器可以采用乘法器常数乘法（MCM）块来优化这些操作。然而，VVC 的插值滤波器具有超过 50 种不同的系数值，这使得 MCM 的实现成本很高。

Method: 本研究提出了一种近似方法，通过平均系数的固定子集来减少插值系数的数量，从而减小 MCM 块的大小，降低电路面积和功耗。研究中介绍了六种不同的 MCM 块架构，其中五种采用了这种近似方法，并评估了系数约简与编码效率之间的权衡。

Result: 实验结果表明，在 10 个视频的测试中，只有两种 MCM 实现的 BD-Rate 增加超过 4%，最差情况下平均增加 2.6%。其中两种 MCM 实现的电路面积减少了 20% 和 44%。另外，对三种架构的并行样本预测模块的评估显示，与单样本处理单元相比，门电路面积减少了 30%，并且其中两种实现的能耗也有所降低。

Conclusion: 通过近似方法减少 VVC 帧内预测中的插值系数，可以有效降低 MCM 实现的硬件复杂度，并在编码效率损失可接受的范围内实现显著的电路面积和功耗节省。

Abstract: The Versatile Video Coding (VVC) standard significantly improves compression
efficiency over its predecessor, HEVC, but at the cost of substantially higher
computational complexity, particularly in intra-frame prediction. This stage
employs various directional modes, each requiring multiple multiplications
between reference samples and constant coefficients. To optimize these
operations at hardware accelerators, multiplierless constant multiplication
(MCM) blocks offer a promising solution. However, VVC's interpolation filters
have more than fifty distinct coefficients, making MCM implementations
resource-intensive. This work proposes an approximation method to reduce the
number of interpolation coefficients by averaging fixed subsets of them,
therefore decreasing MCM block size and potentially lowering circuit area and
power consumption. Six different MCM block architectures for angular intra
prediction are introduced, in which five use the approximation method
introduced in this work, and evaluate the trade-off between coefficient
reduction and coding efficiency compared with a conventional multiplier
architecture. Experimental results in ten videos demonstrate that only two MCM
implementations exceed a 4% BD-Rate increase and 2.6% on average in the worst
case, while two of the MCM implementations have circuit area reduction of 20%
and 44%. For three of the architectures, parallel sample prediction modules
were synthesized, showing a reduction of 30% gate area compared to single
sample processing units, and a reduction in energy consumption for two of the
implementations.

</details>


### [329] [always_comm: An FPGA-based Hardware Accelerator for Audio/Video Compression and Transmission](https://arxiv.org/abs/2509.11503)
*Rishab Parthasarathy,Akshay Attaluri,Gilford Ting*

Main category: cs.AR

TL;DR: 该设计在FPGA上实现了一个完整的视频会议堆栈，使用M-JPEG和UDP进行视频压缩和网络通信，最终在计算机上实现实时音视频播放。


<details>
  <summary>Details</summary>
Motivation: 在FPGA上设计并实现一个完全可扩展的视频会议堆栈，以实现实时音视频流传输。

Method: 使用M-JPEG编解码器压缩视频，并实现一个UDP网络堆栈在FPGA与接收计算机之间进行通信。FPGA上的网络堆栈可以接收来自视频编解码器和音频控制器的实时更新。计算机端的Python脚本负责读取以太网数据包并解码以进行实时播放。设计通过Cocotb进行功能和仿真驱动验证，并使用Vivado将SystemVerilog RTL代码合成以部署到Nexys4 DDR FPGA上。

Result: 成功在FPGA上实现了视频会议堆栈，实现了30 FPS的视频流传输，并在计算机端实现了实时音视频播放。通过Cocotb和Vivado进行了验证和评估，并测量了端到端延迟和视频传输吞吐量。

Conclusion: 提出的FPGA视频会议堆栈设计能够有效地实现实时音视频流传输，并具有良好的性能。

Abstract: We present a design for an extensible video conferencing stack implemented
entirely in hardware on a Nexys4 DDR FPGA, which uses the M-JPEG codec to
compress video and a UDP networking stack to communicate between the FPGA and
the receiving computer. This networking stack accepts real-time updates from
both the video codec and the audio controller, which means that video will be
able to be streamed at 30 FPS from the FPGA to a computer. On the computer
side, a Python script reads the Ethernet packets and decodes the packets into
the video and the audio for real time playback. We evaluate this architecture
using both functional, simulation-driven verification in Cocotb and by
synthesizing SystemVerilog RTL code using Vivado for deployment on our Nexys4
DDR FPGA, where we evaluate both end-to-end latency and throughput of video
transmission.

</details>


### [330] [SuperUROP: An FPGA-Based Spatial Accelerator for Sparse Matrix Operations](https://arxiv.org/abs/2509.11529)
*Rishab Parthasarathy*

Main category: cs.AR

TL;DR: 提出了一种基于FPGA的Azul加速器实现，用于解决稀疏线性系统问题，解决了现有软件方案在硬件上的低效性。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏线性方程组求解在当前硬件上的效率低下问题，主要由数据复用性差和数据依赖性复杂导致。

Method: 在FPGA上实现Azul加速器，利用RISC-V CPU核心和FPGA内存模块构建内存层级结构，并通过定制的RISC-V指令集扩展实现任务并行编程模型，利用片上网络（NoC）进行通信。

Result: 成功在FPGA上实现了Azul加速器，并通过分布式测试验证了其功能，性能与Azul框架的架构模拟相当。

Conclusion: 基于FPGA的Azul加速器实现能够有效解决稀疏线性系统求解的效率问题，并在硬件上实现了高内存带宽利用率和高算术强度。

Abstract: Solving sparse systems of linear equations is a fundamental problem in the
field of numerical methods, with applications spanning from circuit design to
urban planning. These problems can have millions of constraints, such as when
laying out transistors on a circuit, or trying to optimize traffic light
timings, making fast sparse solvers extremely important. However, existing
state-of-the-art software-level solutions for solving sparse linear systems,
termed iterative solvers, are extremely inefficient on current hardware. This
inefficiency can be attributed to two key reasons: (1) poor short-term data
reuse, which causes frequent, irregular memory accesses, and (2) complex data
dependencies, which limit parallelism. Hence, in this paper, we present an FPGA
implementation of the existing Azul accelerator, an SRAM-only hardware
accelerator that achieves both high memory bandwidth utilization and arithmetic
intensity. Azul features a grid of tiles, each of which is composed of a
processing element (PE) and a small independent SRAM memory, which are all
connected over a network on chip (NoC). We implement Azul on FPGA using simple
RISC-V CPU cores connected to a memory hierarchy of different FPGA memory
modules. We utilize custom RISC-V ISA augmentations to implement a task-based
programming model for the various PEs, allowing communication over the NoC.
Finally, we design simple distributed test cases so that we can functionally
verify the FPGA implementation, verifying equivalent performance to an
architectural simulation of the Azul framework.

</details>


### [331] [LEGO: Spatial Accelerator Generation and Optimization for Tensor Applications](https://arxiv.org/abs/2509.12053)
*Yujun Lin,Zhekai Zhang,Song Han*

Main category: cs.AR

TL;DR: LEGO是一个新的框架，用于自动生成张量应用的硬件加速器，在速度和能效方面优于现有方法，并能为现代基础模型生成统一的架构。


<details>
  <summary>Details</summary>
Motivation: 现有框架在设计灵活性和RTL生成效率之间存在权衡，无法满足现代多模态张量应用（如基础模型和生成式AI）的需求。

Method: LEGO框架利用基于仿射变换的架构表示，自动生成空间架构设计和可综合RTL代码。其前端负责寻找功能单元间的连接、合成内存系统以及基于数据复用分析融合不同的空间数据流设计。后端则将硬件翻译成初级图进行低级优化，并使用线性规划算法优化流水线寄存器和减少切换空间数据流时的冗余逻辑开销。

Result: 与之前的Gemmini工作相比，LEGO实现了3.2倍的速度提升和2.4倍的能效提升，并且能够为生成式AI应用中的多样化现代基础模型生成单一架构。

Conclusion: LEGO框架通过自动生成硬件加速器设计，有效解决了现有方法的局限性，为现代张量应用提供了灵活且高效的解决方案。

Abstract: Modern tensor applications, especially foundation models and generative AI
applications require multiple input modalities (both vision and language),
which increases the demand for flexible accelerator architecture. Existing
frameworks suffer from the trade-off between design flexibility and
productivity of RTL generation: either limited to very few hand-written
templates or cannot automatically generate the RTL. To address this challenge,
we propose the LEGO framework, which targets tensor applications and
automatically generates spatial architecture design and outputs synthesizable
RTL code without handwritten RTL design templates. Leveraging the
affine-transformation-based architecture representation, LEGO front end finds
interconnections between function units, synthesizes the memory system, and
fuses different spatial dataflow designs based on data reuse analysis. LEGO
back end then translates the hardware in a primitive-level graph to perform
lower-level optimizations, and applies a set of linear-programming algorithms
to optimally insert pipeline registers and reduce the overhead of unused logic
when switching spatial dataflows. Our evaluation demonstrates that LEGO can
achieve 3.2x speedup and 2.4x energy efficiency compared to previous work
Gemmini, and can generate one architecture for diverse modern foundation models
in generative AI applications.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [332] [Generalizable Pareto-Optimal Offloading with Reinforcement Learning in Mobile Edge Computing](https://arxiv.org/abs/2509.10474)
*Ning Yang,Junrui Wen,Meng Zhang,Ming Tang*

Main category: eess.SY

TL;DR: 该研究提出了一种基于深度强化学习的通用多目标任务卸载框架（GMORL），用于在移动边缘计算（MEC）中处理具有未知偏好的多目标优化问题，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在移动边缘计算（MEC）中，需要考虑延迟和能效等多个性能指标，但实际系统中这些指标的权重（偏好）往往未知或难以预设。因此，需要一种能够处理未知偏好和适应多变MEC系统的任务调度解决方案。

Method: 提出了一种通用的多目标（深度）强化学习（GMORL）任务卸载框架，采用离散软Actor-Critic（Discrete-SAC）方法。该框架使用单一策略模型，通过引入基于直方图的状态编码、精确计算延迟和能耗效用的奖励函数以及新颖的神经网络架构，来实现基于不同偏好的高效任务调度，并适应具有不同CPU频率和服务器数量的异构MEC系统。

Result: 仿真结果表明，所提出的GMORL方案与基准方法相比，帕累托前沿的超体积（hypervolume）最多可提高121.0%。

Conclusion: GMORL框架能够有效地处理移动边缘计算中具有未知偏好的多目标卸载问题，并能适应异构MEC系统，相比现有方法取得了显著的性能提升。

Abstract: Mobile edge computing (MEC) is essential for next-generation mobile network
applications that prioritize various performance metrics, including delays and
energy efficiency. However, conventional single-objective scheduling solutions
cannot be directly applied to practical systems in which the preferences (i.e.,
the weights of different objectives) are often unknown or challenging to
specify in advance. In this study, we formulate a multi-objective offloading
problem for MEC with multiple edges to minimize the sum of expected long-term
energy consumption and delay while considering unknown preferences. To address
the challenge of unknown preferences and the potentially diverse MEC systems,
we propose a generalizable multi-objective (deep) reinforcement learning
(GMORL)-based tasks offloading framework, which employs the Discrete Soft
Actor-Critic (Discrete-SAC) method. Our method uses a single policy model to
efficiently schedule tasks based on varying preferences and adapt to
heterogeneous MEC systems with different CPU frequencies and server quantities.
Under the proposed framework, we introduce a histogram-based state encoding
method for constructing features for multiple edges in MEC systems, a
sophisticated reward function for accurately computing the utilities of delay
and energy consumption, and a novel neural network architecture for improving
generalization. Simulation results demonstrate that our proposed GMORL scheme
enhances the hypervolume of the Pareto front by up to $121.0\%$ compared to
benchmarks. Our code are avavilable at
https://github.com/gracefulning/Generalizable-Pareto-Optimal-Offloading-with-Reinforcement-Learning-in-Mobile-Edge-Computing

</details>


### [333] [Analysis and Design of Spare Strategy for Large-Scale Satellite Constellation Using Direct Insertion under (r,q) Policy](https://arxiv.org/abs/2509.10585)
*Seungyeop Han,Zachary Grieser,Shoji Yoshikawa,Takumi Noro,Takumi Suda,Koki Ho*

Main category: eess.SY

TL;DR: 本文提出了一种基于马尔可夫链的策略，用于分析和优化大规模卫星星座中的备件管理策略。通过直接策略，将备件补货建模为定期审查的订购点/订购量策略，备件直接部署到星座平面。卫星故障和运载火箭提前期的随机行为通过故障和补货动态的马尔可夫表示来捕捉。基于这个高效准确的框架，我们构建并解决了旨在降低运营成本的优化问题。通过对一个真实世界大型星座的案例研究，证明了所提出方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于为大规模卫星星座的备件管理开发一种优化的策略，以降低运营成本。

Method: 该研究提出了一种基于马尔可夫链的分析和优化方法。备件补货被建模为一个定期审查的订购点/订购量策略，备件直接部署到星座平面。卫星故障和运载工具提前期的随机行为被马尔可夫模型捕捉。

Result: 通过一个真实世界大型星座的案例研究，证明了所提出方法的有效性，该方法能够构建并解决以降低运营成本为目标的优化问题。

Conclusion: 所提出的基于马尔可夫链的框架能够有效地分析和优化大规模卫星星座中的备件管理策略，并通过案例研究验证了其在降低运营成本方面的有效性。

Abstract: This paper introduces a Markov chain-based approach for the analysis and
optimization of spare-management policies in large-scale satellite
constellations. Focusing on the direct strategy, we model spare replenishment
as a periodic-review reorder-point/order-quantity policy, where spares are
deployed directly to constellation planes. The stochastic behavior of satellite
failures and launch vehicle lead times is captured through Markov
representations of both failure and replenishment dynamics. Based on this
efficient and accurate framework, we construct and solve an optimization
problem aimed at minimizing operational costs. The effectiveness of the
proposed method is demonstrated through a case study using a real-world
mega-constellation.

</details>


### [334] [Complexity Reduction for TSO-DSO Coordination: Flexibility Aggregation vs. Distributed Optimization](https://arxiv.org/abs/2509.10595)
*Maísa Beraldo Bandeira,Alexander Engelmann,Timm Faulwasser*

Main category: eess.SY

TL;DR: 灵活性聚合（ADP）和分布式优化（ADMM）是两种用于简化电网协调的方法。ADP 接近最优但对近似质量敏感，ADMM 接近集中式但需要更多通信。


<details>
  <summary>Details</summary>
Motivation: 电网中柔性设备和分布式能源的增加使得输配电系统协调日益复杂。

Method: 本文讨论并比较了两种基于优化的复杂性降低方法：通过近似动态规划（ADP）进行灵活性聚合，以及通过交替方向乘子法（ADMM）进行分布式优化。

Result: ADP 可在最少通信的情况下获得接近最优的解决方案，但性能取决于近似的质量。ADMM 可获得更接近集中式解决方案的结果，但需要更多的通信。

Conclusion: 通过结合不同的 matpower 基准进行案例研究，比较了 ADP 和 ADMM 两种方法的性能。

Abstract: The increasing number of flexible devices and distributed energy resources in
power grids renders the coordination of transmission and distribution systems
increasingly complex. In this paper, we discuss and compare two different
approaches to optimization-based complexity reduction: Flexibility aggregation
via Approximate Dynamic Programming (ADP) and distributed optimization via the
Alternating Direction Method of Multipliers (ADMM). Flexibility aggregation
achieves near-optimal solutions with minimal communication. However, its
performance depends on the quality of the approximation used. In contrast, ADMM
attains results closer to the centralized solution but requires significantly
more communication steps. We draw upon a case study combining different
matpower benchmarks to compare both methods.

</details>


### [335] [Optimal Path Planning for Wheel Loader Automation Enabled by Efficient Soil-Tool Interaction Modeling](https://arxiv.org/abs/2509.10642)
*Armin Abdolmohammadi,Navid Mojahed,Bahram Ravani,Shima Nazari*

Main category: eess.SY

TL;DR: 该研究提出了一种基于基础土方工程方程（FEE）的轮式装载机自动化框架，通过全局敏感性分析和最优控制来预测挖掘力并优化铲斗轨迹，实现了15-40%的节能。


<details>
  <summary>Details</summary>
Motivation: 轮式装载机在土方作业中需要大量能源且运营成本高昂。

Method: 采用基于基础土方工程方程（FEE）的自动化框架，结合Sobol'全局敏感性分析进行参数估计，以进行精确的挖掘力预测，并构建最优控制问题以计算节能的铲斗轨迹。

Result: 高保真仿真结果表明，该框架能够精确预测挖掘力，并与标准路径相比，可实现15-40%的节能，且总计算时间与单次挖掘周期相当。

Conclusion: 该框架有潜力用于实时、节能的轮式装载机自动化。

Abstract: Earthmoving operations with wheel loaders require substantial power and incur
high operational costs. This work presents an efficient automation framework
based on the Fundamental Earthmoving Equation (FEE) for soil-tool interaction
modeling. A reduced-order multi-step parameter estimation method guided by
Sobol's global sensitivity analysis is deployed for accurate, online excavation
force prediction. An optimal control problem is then formulated to compute
energy-efficient bucket trajectories using soil parameters identified in the
previous digging cycle. High-fidelity simulations in Algoryx Dynamics confirm
accurate force prediction and demonstrate 15-40% energy savings compared to
standard paths. The total computation time is comparable to a single digging
cycle, highlighting the framework's potential for real-time, energy-optimized
wheel loader automation.

</details>


### [336] [A Linear Programming Framework for Optimal Event-Triggered LQG Control](https://arxiv.org/abs/2509.10671)
*Zahra Hashemi,Dipankar Maity*

Main category: eess.SY

TL;DR: 通过引入二元变量将传感器到控制器通信的调度问题转化为混合整数线性规划（MILP）问题，并结合模型预测控制（MPC）框架，实现智能调度，性能优于确定性策略。


<details>
  <summary>Details</summary>
Motivation: 在网络控制系统中，当数据传输有成本时，智能调度传感器到控制器通信是一个挑战，尤其是与传统的LQG（线性二次高斯）控制器相比，分析和计算最优传输时间仍然很困难。

Method: 将调度问题重构，并引入辅助二元变量，将其转化为计算高效的混合整数线性规划（MILP）。将该方法嵌入模型预测控制（MPC）框架中，以实现动态适应。

Result: 所提出的MILP方法在分析和决策方面提供了结构性见解。仿真结果表明，与传统的周期性调度策略相比，该方法在性能上更优。

Conclusion: 所提出的基于MILP和MPC的调度方法能够动态适应，并保证其性能至少与任何确定性策略（如周期性策略）相当，仿真结果也证实了其优越性。

Abstract: This letter explores intelligent scheduling of sensor-to-controller
communication in networked control systems, particularly when data transmission
incurs a cost. While the optimal controller in a standard linear quadratic
Gaussian (LQG) setup can be computed analytically, determining the optimal
times to transmit sensor data remains computationally and analytically
challenging. We show that, through reformulation and the introduction of
auxiliary binary variables, the scheduling problem can be cast as a
computationally efficient mixed-integer linear program (MILP). This formulation
not only simplifies the analysis but also reveals structural insights and
provides clear decision criteria at each step. Embedding the approach within a
model predictive control (MPC) framework enables dynamic adaptation, and we
prove that the resulting scheduler performs at least as well as any
deterministic strategy (e.g., periodic strategy). Simulation results further
demonstrate that our method consistently outperforms traditional periodic
scheduling.

</details>


### [337] [Combinatorial Control Barrier Functions: Nested Boolean and p-choose-r Compositions of Safety Constraints](https://arxiv.org/abs/2509.10716)
*Pio Ong,Haejoon Lee,Tamas G. Molnar,Dimitra Panagou,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本论文提出组合式CBF框架，可处理


<details>
  <summary>Details</summary>
Motivation: 标准CBF在组合（例如，析取或更复杂的逻辑结构）

Method: 提出组合式CBF框架，该框架能够处理p选r安全规约

Result: 该框架可扩展地保证了在原始约束数量不变的情况下，

Conclusion: 本论文提出的组合式CBF框架，能够扩展地保证安全性，

Abstract: This paper investigates the problem of composing multiple control barrier
functions (CBFs) -- and matrix control barrier functions (MCBFs) -- through
logical and combinatorial operations. Standard CBF formulations naturally
enable conjunctive (AND) combinations, but disjunctive (OR) and more general
logical structures introduce nonsmoothness and possibly a combinatorial blow-up
in the number of logical combinations. We introduce the framework of
combinatorial CBFs that addresses p-choose-r safety specifications and their
nested composition. The proposed framework ensures safety for the exact safe
set in a scalable way, using the original number of primitive constraints. We
establish theoretical guarantees on safety under these compositions, and we
demonstrate their use on a patrolling problem in a multi-agent system.

</details>


### [338] [Multi-sectoral Impacts of H2 and Synthetic Fuels Adoption for Heavy-duty Transportation Decarbonization](https://arxiv.org/abs/2509.10734)
*Youssef Shaker,Jun Wen Law,Audun Botterud,Dharik Mallapragada*

Main category: eess.SY

TL;DR: 本文研究了通过氢能或合成燃料实现欧洲西部重型车辆电气化对能源系统的影响，并比较了不同脱碳策略下的成本和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着交通运输领域排放量的不断增长，特别是重型车辆（HDV）排放量，以及实现经济深度脱碳的政策需求，需要探索减少此类排放的方法，如通过氢能或合成燃料实现HDV的电气化。

Method: 通过结合自下而上的交通需求模型和多部门容量扩展模型，对2040年西欧在深度脱碳约束下的能源系统进行了影响评估，并考虑了有无二氧化碳封存的不同情景。

Result: 在无二氧化碳封存的情况下，必须用氢能或合成燃料替代重型车辆中的液体化石燃料，以满足脱碳目标。采用氢能重型车辆可降低脱碳成本和液体化石燃料需求，但可能增加天然气消耗。氢能重型车辆的应用减少了对直接空气捕获（DAC）的需求，但合成燃料的应用则增加了DAC投资和系统总成本。

Conclusion: 交通脱碳路径存在权衡，多部门的综合考量对于脱碳研究至关重要。

Abstract: Policies focused on deep decarbonization of regional economies emphasize
electricity sector decarbonization alongside electrification of end-uses. There
is growing interest in utilizing hydrogen (H2) produced via electricity to
displace fossil fuels in difficult-to-electrify sectors. One such case is
heavy-duty vehicles (HDV), which represent a substantial and growing share of
transport emissions as light-duty vehicles electrify. Here, we assess the bulk
energy system impact of decarbonizing the HDV segment via either H2, or drop-in
synthetic liquid fuels produced from H2 and CO2. Our analysis soft-links two
modeling approaches: (a) a bottom-up transport demand model producing a variety
of final energy demand scenarios for the same service demand and (b) a
multi-sectoral capacity expansion model that co-optimizes power, H2 and CO2
supply chains under technological and policy constraints to meet exogenous
final energy demands. Through a case study of Western Europe in 2040 under deep
decarbonization constraints, we quantify the energy system implications of
different levels of H2 and synthetic fuels adoption in the HDV sector under
scenarios with and without CO2 sequestration. In the absence of CO2 storage,
substitution of liquid fossil fuels in HDVs is essential to meet the deep
decarbonization constraint across the modeled power, H2 and transport sectors.
Additionally, utilizing H2 HDVs reduces decarbonization costs and fossil
liquids demand, but could increase natural gas consumption. While H2 HDV
adoption reduces the need for direct air capture (DAC), synthetic fuel adoption
increases DAC investments and total system costs. The study highlights the
trade-offs across transport decarbonization pathways, and underscores the
importance of multi-sectoral consideration in decarbonization studies.

</details>


### [339] [Experimental Validation of Decentralized Affine Transformation](https://arxiv.org/abs/2509.10791)
*Garegin Mazmanyan,Hossein Rastgoftar*

Main category: eess.SY

TL;DR: 本文验证了在多无人机系统中去中心化仿射变换（AT）的有效性，实现了无人机团队在复杂环境中的安全导航和自主队形调整。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，尤其是在障碍物密集的环境中，实现安全导航和灵活的队形变换是一个重要的挑战。本文旨在通过去中心化仿射变换（AT）来解决这一问题。

Method: 本文提出了一种去中心化仿射变换（AT）框架，并将其应用于三角形配置的无人机领导者-跟随者系统中。领导者无人机知道期望的AT轨迹，而跟随者无人机则通过固定的通信权重进行局部通信来推断其轨迹。

Result: 实验结果表明，去中心化AT能够实现渐近收敛，并成功地引导多无人机团队安全地穿越了充满障碍物的环境。

Conclusion: 去中心化仿射变换（AT）框架为多智能体系统在复杂环境中的安全导航和动态队形调整提供了一种有效的解决方案。

Abstract: This paper presents an experimental validation of decentralized affine
transformation (AT) in multi-agent systems using teams of mini-quadcopters. The
AT framework enables an agent team to safely navigate constrained,
obstacle-rich environments while allowing aggressive changes in inter-agent
distances, which are formally characterized through the decomposition of the AT
transformation matrix. Without loss of generality, we focus on two-dimensional
AT, formulated as a decentralized leader-follower problem. In this formulation,
three leader quadcopters are positioned at the vertices of a triangle, while
all follower quadcopters remain within the triangle. The leaders know the
desired trajectories prescribed by the AT, whereas the followers do not.
Instead, the followers infer their trajectories through local communication
governed by fixed communication weights determined by the initial spatial
configuration of the team. Experimental results validate the asymptotic
convergence of decentralized AT and demonstrate its capability to safely guide
multi-agent teams through obstacle-laden environments.

</details>


### [340] [Control Synthesis for Multiple Reach-Avoid Tasks via Hamilton-Jacobi Reachability Analysis](https://arxiv.org/abs/2509.10896)
*Yu Chen,Shaoyuan Li,Xiang Yin*

Main category: eess.SY

TL;DR: The paper proposes a method to solve complex reach-avoid tasks for nonlinear systems by defining value functions through a series of time-varying reach-avoid problems solved via Hamilton-Jacobi variational inequalities. The method guarantees the feasibility of the task and synthesizes a control law. It also shows that linear temporal logic tasks can be converted to these MRA tasks. The approach is validated with robot planning examples.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the control synthesis problem for continuous-time time-varying nonlinear systems with disturbances, focusing on a challenging class of multiple reach-avoid (MRA) tasks that require sequential arrival at target regions while respecting state constraints.

Method: The authors define a series of value functions by solving a cascade of time-varying reach-avoid problems using Hamilton-Jacobi variational inequalities. The control law is synthesized by ensuring the non-negativeness of these value functions over time. The paper also demonstrates the conversion of Linear Temporal Logic (LTL) task control synthesis problems into MRA task control synthesis problems.

Result: The paper proves that the super-level set of the final computed value function precisely defines the feasible set for the MRA task. The proposed control synthesis method is shown to be effective.

Conclusion: The proposed method successfully addresses the control synthesis problem for MRA tasks in nonlinear systems with disturbances, offering a way to handle complex sequential objectives and state constraints. The conversion of LTL tasks to MRA tasks broadens the applicability of the approach, which is validated through several robotic planning case studies.

Abstract: We investigate the control synthesis problem for continuous-time time-varying
nonlinear systems with disturbance under a class of multiple reach-avoid (MRA)
tasks. Specifically, the MRA task requires the system to reach a series of
target regions in a specified order while satisfying state constraints between
each pair of target arrivals. This problem is more challenging than standard
reach-avoid tasks, as it requires considering the feasibility of future
reach-avoid tasks during the planning process. To solve this problem, we define
a series of value functions by solving a cascade of time-varying reach-avoid
problems characterized by Hamilton-Jacobi variational inequalities. We prove
that the super-level set of the final value function computed is exactly the
feasible set of the MRA task. Additionally, we demonstrate that the control law
can be effectively synthesized by ensuring the non-negativeness of the value
functions over time. We also show that the Linear temporal logic task control
synthesis problems can be converted to a collection of MRA task control
synthesis problems by properly defining each target and state constraint set of
MRA tasks. The effectiveness of the proposed approach is illustrated through
four case studies on robot planning problems under time-varying nonlinear
systems with disturbance.

</details>


### [341] [Uncertainty Quantification on State-Based Conflict Detection and Resolution Algorithms](https://arxiv.org/abs/2509.10899)
*Muhammad Fazlur Rahman,Joost Ellerbroek,Jacco Hoekstra*

Main category: eess.SY

TL;DR: 本研究探讨了导航不确定性对U空间无人机冲突检测与解决（CD&R）的影响。


<details>
  <summary>Details</summary>
Motivation: 研究导航不确定性对U空间无人机冲突检测与解决（CD&R）的影响。

Method: 对位置和速度误差进行建模，并使用蒙特卡洛和解析近似方法将其传播到冲突度量中。比较了修改电压势（MVP）和速度障碍（VO）两种解析方法，并使用BlueSky仿真进行了验证。

Result: 在不确定性下，基于状态的检测变为概率性的，检测概率随不确定性水平和交汇几何形状而变化。MVP比VO更鲁棒，因为它明确最大化最近交点距离（CPA），而在低相对速度和浅角度下VO性能会下降。MVP在入侵预防率和分辨率后的最小距离方面表现更好，尤其是在低相对速度下。

Conclusion: 最大化CPA距离是冲突解决策略的重要性。调整前视视界和保护区可以实现期望的安全目标水平。

Abstract: This study investigates how navigation uncertainty affects conflict detection
and resolution (CD&R) for uncrewed aircraft in U-space. Position and velocity
errors are modelled as zero-mean Gaussian noise consistent with ADS-L accuracy,
and propagated through conflict metrics using Monte Carlo and analytical
approximations. Under uncertainty, state-based detection becomes probabilistic.
The probability of detection depends on both the level of uncertainty and the
encounter geometry, and falls below 50% when the nominal intrusion time equals
the look-ahead. Operationally, detection is re-evaluated over time as the
encounter develops, yielding multiple observations with varying probabilities.
Two resolution algorithms are compared: Modified Voltage Potential (MVP) and
Velocity Obstacle (VO). MVP proves more robust under uncertainty because it
explicitly maximises distance at the closest point of approach (CPA). By
maximising CPA distance, MVP maintains an outward push and avoids reversal
behaviour during the manoeuvre, whereas VO performance degrades at low relative
speeds and shallow angles. BlueSky simulations confirm these effects: MVP
achieves higher intrusion-prevention rates and larger post-resolution miss
distances across conflict scenarios, with its advantage most pronounced at low
relative velocity. The findings highlight the importance of maximising CPA
distance as a conflict resolution strategy. Moreover, the look-ahead horizon
and protected zone can be tuned to achieve a desired target level of safety.

</details>


### [342] [A Highly Compact Direct-Injection Power-Flow Controller and Line-Voltage Regulator with Shared Magnetics and Partial-Power Conversion for Full-Power Control](https://arxiv.org/abs/2509.10955)
*Davood Keshavarzi,Alexander Koehler,Stefan M. Goetz*

Main category: eess.SY

TL;DR: 本文提出了一种紧凑型、高电流密度的电力潮流控制器，用于解决低压电网中集成光伏、电动汽车充电器、热泵和储能系统带来的电压越限、稳定性丧失、线路过载和电力管理问题。该控制器采用碳化硅和硅晶体管的组合以及部分功率拓扑结构，通过多有源桥连接有源前端转换器和低压串联注入模块，能够用小功率控制大电流。


<details>
  <summary>Details</summary>
Motivation: 低压电网中分布式能源和负荷的增加带来了电压越限、稳定性丧失、线路过载和电力管理等挑战。

Method: 提出了一种基于碳化硅和硅晶体管组合以及部分功率拓扑结构的新型电力潮流控制器。该控制器包含一个有源前端转换器作为分流级，通过多有源桥转换器与低压串联注入模块进行双向连接，低压串联注入模块的各相是浮动的。该拓扑结构允许使用较小的功率来控制流经低压串联注入模块的大电流，而多有源桥则作为多输入输出功率路由器，负责在所有元件之间交换能量。

Result: 通过数学分析、仿真和实际系统验证了所提出电力潮流控制器的设计和实现的可行性及其性能。

Conclusion: 所提出的新型电力潮流控制器能够有效解决低压电网中的电力管理问题，并具有结构紧凑、电流密度高、控制灵活等优点。

Abstract: An increasing integration of photovoltaic units, electric vehicle chargers,
heat pumps, and energy storage systems challenges low-voltage power grids and
can cause voltage range violation, loss of stability, (local) overload of
lines, and power management problems. Research suggested universal power-flow
control (UPFC) to solve power management problems. In contrast to bulky, slow,
and costly conventional UPFCs with their shunt and series transformers, this
paper presents a highly compact and current-dense power-flow controller, which
can serve between different feeders in the low-voltage power grids. The enabler
is a systematic combination of silicon car-bide (SiC) with silicon (Si)
transistors and a strict partial-power topology built around a multi-active
bridge. The circuit links an active-front-end converter as a shunt stage
through a multi-active-bridge converter bidirectionally with low-voltage
series-injection modules floating with their respective phases. The topology
can use small power to control high currents through the low-voltage
series-injection modules. The multi-active bridge serves as a
multi-input-output power router that exchanges energy between all elements. We
assess the design as well as the implementation considerations of the proposed
power-flow controller mathematically and verify its performance in simulation
and real systems.

</details>


### [343] [Factor Graph Optimization for Leak Localization in Water Distribution Networks](https://arxiv.org/abs/2509.10982)
*Paul Irofti,Luis Romero-Ben,Florin Stoican,Vicenç Puig*

Main category: eess.SY

TL;DR: 该论文首次将因子图优化技术应用于水力分配网络中的泄漏定位，实现了压力和流量传感器数据的融合，并估计了网络所有节点的时间和结构状态演变。该方法引入了特定的水网络因子，并提出了一种由两个因子图组成的新架构：一个无泄漏状态估计因子图和一个泄漏定位因子图。与卡尔曼和其他仅估计当前网络状态的插值方法不同，因子图在获得新的传感器读数时，可以同时更新当前和过去的状态。在Modena、L-TOWN和合成网络上的结果表明，因子图比非线性卡尔曼方法（如UKF）更快，并且在定位方面优于现有的估计-定位方法。


<details>
  <summary>Details</summary>
Motivation: 检测和定位水分配网络中的泄漏对于环境保护、经济效益和社会福祉至关重要。

Method: 本文提出了一种新颖的方法，利用因子图优化技术进行水力分配网络中的泄漏定位。该方法包括以下关键点：1. 传感器数据融合：能够融合来自压力和流量传感器的信息。2. 状态估计：估计网络中所有节点随时间推移以及结构上的状态演变。3. 因子图架构：设计了两种因子图：一种用于估计无泄漏状态，另一种用于泄漏定位。4. 动态状态更新：与传统方法（如卡尔曼滤波）仅估计当前状态不同，因子图在接收新传感器数据时，能够同时更新网络当前和过去的状态。

Result: 在Modena、L-TOWN和合成数据集上的实验结果表明，与非线性卡尔曼滤波（如UKF）等现有方法相比，该因子图方法在速度上更快，并且在泄漏定位的准确性方面也表现出优于最先进的估计-定位方法。

Conclusion: 因子图优化技术为水力分配网络中的泄漏检测和定位提供了一种更快速、更准确的解决方案。与现有方法相比，该方法在速度和定位精度上均有显著优势。

Abstract: Detecting and localizing leaks in water distribution network systems is an
important topic with direct environmental, economic, and social impact. Our
paper is the first to explore the use of factor graph optimization techniques
for leak localization in water distribution networks, enabling us to perform
sensor fusion between pressure and demand sensor readings and to estimate the
network's temporal and structural state evolution across all network nodes. The
methodology introduces specific water network factors and proposes a new
architecture composed of two factor graphs: a leak-free state estimation factor
graph and a leak localization factor graph. When a new sensor reading is
obtained, unlike Kalman and other interpolation-based methods, which estimate
only the current network state, factor graphs update both current and past
states. Results on Modena, L-TOWN and synthetic networks show that factor
graphs are much faster than nonlinear Kalman-based alternatives such as the
UKF, while also providing improvements in localization compared to
state-of-the-art estimation-localization approaches. Implementation and
benchmarks are available at https://github.com/pirofti/FGLL.

</details>


### [344] [Real-Time Defense Against Coordinated Cyber-Physical Attacks: A Robust Constrained Reinforcement Learning Approach](https://arxiv.org/abs/2509.10999)
*Saman Mazaheri Khamaneh,Tong Wu,Wei Sun,Cong Chen*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的三层鲁棒约束强化学习（RCRL）框架，用于应对现代电力系统面临的复杂网络物理攻击，通过生成多样化系统状态、识别最坏情况下的N-K攻击场景并训练缓解策略，实现了在0.21毫秒内的快速响应，有效提高了关键基础设施的弹性。


<details>
  <summary>Details</summary>
Motivation: 现有安全框架在识别最坏情况和协调防御响应方面存在计算密集和时间延迟的瓶颈，无法有效应对复杂的网络物理攻击和级联故障。

Method: 提出了一种三层鲁棒约束强化学习（RCRL）框架，包括生成系统状态、识别最坏情况下的N-K攻击场景、训练缓解策略。在训练中利用Beta-blending projection-based feasible action mapping技术处理约束，部署时使用primal-dual augmented Lagrangian optimization。训练好的策略能够实时控制网络物理攻击。

Result: RCRL框架在IEEE基准系统上进行了验证，结果表明该框架能有效应对协调的N-K攻击，防止大范围级联故障。所学策略能在0.21毫秒内快速响应，将系统约束恢复到正常状态。

Conclusion: RCRL框架能够有效识别和缓解复杂的网络物理攻击，显著提高电力系统的安全性和弹性，为关键基础设施保护提供了新的解决方案。

Abstract: Modern power systems face increasing vulnerability to sophisticated
cyber-physical attacks beyond traditional N-1 contingency frameworks. Existing
security paradigms face a critical bottleneck: efficiently identifying
worst-case scenarios and rapidly coordinating defensive responses are hindered
by intensive computation and time delays, during which cascading failures can
propagate. This paper presents a novel tri-level robust constrained
reinforcement learning (RCRL) framework for robust power system security. The
framework generates diverse system states through AC-OPF formulations,
identifies worst-case N-K attack scenarios for each state, and trains policies
to mitigate these scenarios across all operating conditions without requiring
predefined attack patterns. The framework addresses constraint satisfaction
through Beta-blending projection-based feasible action mapping techniques
during training and primal-dual augmented Lagrangian optimization for
deployment. Once trained, the RCRL policy learns how to control observed
cyber-physical attacks in real time. Validation on IEEE benchmark systems
demonstrates effectiveness against coordinated N-K attacks, causing widespread
cascading failures throughout the network. The learned policy can successfully
respond rapidly to recover system-wide constraints back to normal within 0.21
ms inference times, establishing superior resilience for critical
infrastructure protection.

</details>


### [345] [General Decentralized Stochastic Optimal Control via Change of Measure: Applications to the Witsenhausen Counterexample](https://arxiv.org/abs/2509.11013)
*Bhagyashri Telsang,Seddik Djouadi,Charalambos D. Charalambous*

Main category: eess.SY

TL;DR: 本文提出了通用去中心化随机动态最优控制问题的全局和逐人（PbP）最优性条件，并应用Girsanov测度变换的离散时间版本。


<details>
  <summary>Details</summary>
Motivation: 为解决通用去中心化随机动态最优控制问题，提出全局和逐人（PbP）最优性条件。

Method: 使用Girsanov测度变换的离散时间版本，将PbP最优性条件应用于Witsenhausen反例，推导出满足耦合非线性积分方程的策略。证明了一个函数空间中的不动点定理，以建立积分方程解的存在性和唯一性。使用Gauss Hermite Quadrature方案对积分方程进行数值求解，并与文献中的其他数值方法进行了详细比较。

Result: 数值解证实了Witsenhausen的观察：在某些参数选择下，线性或仿射策略是最优的；而在其他参数选择下，非线性策略优于仿θα。本研究还建立了积分方程解的存在性和唯一性。

Conclusion: 通过对Witsenhausen反例的应用和数值解的验证，表明所提出的最优性条件对于理解和解决去中心化随机动态最优控制问题是有效的。

Abstract: In this paper we present global and person-by-person (PbP) optimality
conditions for general decentralized stochastic dynamic optimal control
problems, using a discrete-time version of Girsanov's change of measure. The
PbP optimality conditions are applied to the Witsenhausen counterexample to
show that the two strategies satisfy two coupled nonlinear integral equations.
Further, we prove a fixed point theorem in a function space, establishing
existence and uniqueness of solutions to the integral equations. We also
provide numerical solutions of the two integral equations using the Gauss
Hermite Quadrature scheme, and include a detail comparison to other numerical
methods of the literature. The numerical solutions confirm Witsehausen's
observation that, for certain choices of parameters, linear or affine
strategies are optimal, while for other choices of parameters nonlinear
strategies outperformed affine strategies.

</details>


### [346] [Privacy-Preserving Uncertainty Disclosure for Facilitating Enhanced Energy Storage Dispatch](https://arxiv.org/abs/2509.11022)
*Ning Qi,Xiaolong Jin,Kai Hou,Zeyu Liu,Hongjie Jia,Wei Wei*

Main category: eess.SY

TL;DR: 本篇论文提出了一个新颖的隐私保护不确定性披露框架，通过发布边际价值函数边界来减少区间预测的保守性，缓解过度保留问题，从而提高储能调度和社会福利。


<details>
  <summary>Details</summary>
Motivation: 为了减少区间预测的保守性，缓解过度保留问题，提高储能调度和社会福利，需要一个隐私保护的不确定性披露框架。

Method: 提出一个基于随机动态规划的风险厌恶型分析型储能套利模型，并将不确定性区间纳入价值函数训练。通过滚动视界机会约束经济调度公式推导出实时边际价值函数边界，并证明了其可靠性，同时验证了边际价值函数及其边界与荷电状态和不确定性的关系。最后，通过基于代理的仿真验证了该框架的有效性。

Result: 在50%可再生能源容量和35%储能容量的条件下，所提出的边界将储能响应提高了38.91%，并将最优性差距降低到3.91%。此外，通过缓解过度保留，边界使平均系统成本降低了0.23%，平均储能利润增加了13.22%。

Conclusion: 所提出的隐私保护不确定性披露框架能够有效减少预测保守性，提高储能调度和社会福利，并且在更具挑战性的系统条件下（如更高的预测保守性、储能容量和系统不确定性）能够带来更大的效益。

Abstract: This paper proposes a novel privacy-preserving uncertainty disclosure
framework, enabling system operators to release marginal value function bounds
to reduce the conservativeness of interval forecast and mitigate excessive
withholding, thereby enhancing storage dispatch and social welfare. We propose
a risk-averse analytical storage arbitrage model based on stochastic dynamic
programming and explicitly account for uncertainty intervals in value function
training. We derive real-time marginal value function bounds using a
rolling-horizon chance-constrained economic dispatch formulation. We rigorously
prove that the bounds reliably cap the true opportunity cost and dynamically
converge to the hindsight value. We verify that both the marginal value
function and its bounds monotonically decrease with the state of charge and
increase with uncertainty, providing a theoretical basis for risk-averse
strategic behaviors and SoC-dependent designs. We validate the effectiveness of
the proposed framework via an agent-based simulation on the ISO-NE test system.
Under 50% renewable capacity and 35% storage capacity, the proposed bounds
enhance storage response by 38.91% and reduce the optimality gap to 3.91%
through improved interval predictions. Additionally, by mitigating excessive
withholding, the bounds yield an average system cost reduction of 0.23% and an
average storage profit increase of 13.22%. These benefits further scale with
higher prediction conservativeness, storage capacity, and system uncertainty.

</details>


### [347] [A Signed Friedkin-Johnsen Model for Arbitrary Network Topologies](https://arxiv.org/abs/2509.11038)
*Aashi Shrinate,Twinkle Tripathy*

Main category: eess.SY

TL;DR: 本篇论文提出了一个基于规则的反对派符号弗里德金-约翰森（SFJ）模型，用于分析任意网络拓扑中具有符号交互和顽固代理的观点的演变。


<details>
  <summary>Details</summary>
Motivation: 分析代理在所提出规则下的涌现行为，并识别对最终观点做出贡献的关键代理（有影响力的代理）。

Method: 提出一个基于规则的反对派SFJ模型，并分析其收敛性。提出绝对影响中心性度量来量化代理的整体影响力。

Result: 在有符号网络和任意拓扑结构下，代理的观点会收敛。有符号交互会影响意见领袖和顽固代理的影响力，并可能使代理的观点超出初始观点的凸包。提出的绝对影响中心性度量适用于任何网络拓扑，并考虑了顽固性和有符号交互的影响。

Conclusion: 有符号交互和顽固代理对网络中观点的演变有重要影响。提出的绝对影响中心性度量可以有效识别网络中的有影响力代理。

Abstract: The paper presents an opposing rule-based signed Friedkin-Johnsen (SFJ) model
for the evolution of opinions in arbitrary network topologies with signed
interactions and stubborn agents. The primary objective of the paper is to
analyse the emergent behaviours of the agents under the proposed rule and to
identify the key agents which contribute to the final opinions, characterised
as influential agents. We start by presenting some convergence results which
show how the opinions of the agents evolve for a signed network with any
arbitrary topology. Throughout the paper, we classify the agents as opinion
leaders (sinks in the associated condensation graph) and followers (the rest).
In general, it has been shown in the literature that opinion leaders and
stubborn agents drive the opinions of the group. However, the addition of
signed interactions reveals interesting behaviours wherein opinion leaders can
now become non-influential or less influential. Further, while the stubborn
agents always continue to remain influential, they might become less
influential owing to signed interactions. Additionally, the signed interactions
can drive the opinions of the agents outside of the convex hull of their
initial opinions. Thereafter, we propose the absolute influence centrality
measure, which allows us to quantify the overall influence of all the agents in
the network and also identify the most influential agents. Unlike most of the
existing measures, it is applicable to any network topology and considers the
effect of both stubbornness and signed interactions. Finally, simulations are
presented for the Bitcoin Alpha dataset to elaborate the proposed results.

</details>


### [348] [Opinion Clustering under the Friedkin-Johnsen Model: Agreement in Disagreement](https://arxiv.org/abs/2509.11045)
*Aashi Shrinate,Twinkle Tripathy*

Main category: eess.SY

TL;DR: 该研究探讨了在Friedkin-Johnsen (FJ)框架下，网络拓扑结构如何影响意见收敛并产生意见簇。研究引入了“局部拓扑说服力”(LTP)代理人的概念，并基于此提出了在任意有向图中产生意见簇的条件。该方法不依赖于边的权重和代理人的固执程度，并通过仿真证明了通过合理放置LTP代理人可以设计出实现预期意见簇的网络。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注FJ框架下的意见收敛，但对导致意见簇的拓扑条件探索不足。

Method: 引入“局部拓扑说服力”(LTP)代理人的概念，并利用其提出在任意有向图中产生意见簇的条件。

Result: 提出了在FJ框架下产生意见簇的条件，该条件不依赖于边的权重和代理人的固执程度。仿真结果表明，LTP代理人的放置可以设计网络以实现所需的意见簇。

Conclusion: LTP代理人的概念为理解和设计具有特定意见簇的网络提供了新的视角，并能在不考虑边权重和代理人固执程度的情况下实现目标。

Abstract: The convergence of opinions in the Friedkin-Johnsen (FJ) framework is well
studied, but the topological conditions leading to opinion clustering remain
less explored. To bridge this gap, we examine the role of topology in the
emergence of opinion clusters within the network. The key contribution of the
paper lies in the introduction of the notion of topologically prominent agents,
referred to as Locally Topologically Persuasive (LTP) agents. Interestingly,
each LTP agent is associated with a unique set of (non-influential) agents in
its vicinity. Using them, we present conditions to obtain opinion clusters in
the FJ framework in any arbitrarily connected digraph. A key advantage of the
proposed result is that the resulting opinion clusters are independent of the
edge weights and the stubbornness of the agents. Finally, we demonstrate using
simulation results that, by suitably placing LTP agents, one can design
networks that achieve any desired opinion clustering.

</details>


### [349] [BERT4beam: Large AI Model Enabled Generalized Beamforming Optimization](https://arxiv.org/abs/2509.11056)
*Yuhang Li,Yang Lu,Wei Chen,Bo Ai,Zhiguo Ding,Dusit Niyato*

Main category: eess.SY

TL;DR: 本论文提出了一种名为BERT4beam的新型框架，利用BERT模型优化6G无线通信中的波束成形，并提出了UBERT模型用于多任务优化，实验证明该模型具有良好的适应性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在对预训练大语言模型进行微调以适应特定任务，缺乏针对无线通信中波束成形优化等多样化任务的大规模AI模型研究。

Method: 提出基于BERT的BERT4beam框架，将波束成形优化问题视为序列学习任务，对信道状态信息进行分词，构建BERT模型，并进行预训练和微调。在此基础上，提出了用于单任务和多任务的BERT模型，并设计了UBERT模型进行更细粒度的分词以实现多任务泛化。

Result: 提出的BERT4beam和UBERT方法在各种波束成形优化任务中取得了接近最优的性能，并且优于现有的AI模型，展现出良好的适应性和泛化能力。

Conclusion: 基于BERT的大规模AI模型能够有效地解决无线通信中的波束成形优化问题，并具有良好的适应性和泛化能力，可用于6G无线通信系统。

Abstract: Artificial intelligence (AI) is anticipated to emerge as a pivotal enabler
for the forthcoming sixth-generation (6G) wireless communication systems.
However, current research efforts regarding large AI models for wireless
communications primarily focus on fine-tuning pre-trained large language models
(LLMs) for specific tasks. This paper investigates the large-scale AI model
designed for beamforming optimization to adapt and generalize to diverse tasks
defined by system utilities and scales. We propose a novel framework based on
bidirectional encoder representations from transformers (BERT), termed
BERT4beam. We aim to formulate the beamforming optimization problem as a
token-level sequence learning task, perform tokenization of the channel state
information, construct the BERT model, and conduct task-specific pre-training
and fine-tuning strategies. Based on the framework, we propose two BERT-based
approaches for single-task and multi-task beamforming optimization,
respectively. Both approaches are generalizable for varying user scales.
Moreover, the former can adapt to varying system utilities and antenna
configurations by re-configuring the input and output module of the BERT model,
while the latter, termed UBERT, can directly generalize to diverse tasks, due
to a finer-grained tokenization strategy. Extensive simulation results
demonstrate that the two proposed approaches can achieve near-optimal
performance and outperform existing AI models across various beamforming
optimization tasks, showcasing strong adaptability and generalizability.

</details>


### [350] [Fundamental limitations of sensitivity metrics for anomaly impact analysis in LTI systems](https://arxiv.org/abs/2509.11194)
*Jingwei Dong,Kangkang Zhang,Anh Tung Nguyen,André M. H. Teixeira*

Main category: eess.SY

TL;DR: 该研究建立了输出-输出增益(OOG)和输入-输入增益(IIG)之间的联系，并研究了它们由系统传输零点引起的基本性能限制。


<details>
  <summary>Details</summary>
Motivation: 提出输入-输出增益(IIG)作为衡量鲁棒故障敏感性的新指标，以量化故障对系统的影响。

Method: 使用右(OOG)和左(IIG)共素因子分解将OOG和IIG表示为系统矩阵的比例，并利用泊松积分关系推导理论界限。

Result: 得到了IIG和OOG的基本性能限制的理论界限，并用数值算例进行了验证。

Conclusion: 系统非最小相位(NMP)零点对IIG和OOG的基本性能限制起着决定性作用。

Abstract: This study establishes a connection between the output-to-output gain (OOG),
a sensitivity metric quantifying the impact of stealthy attacks, and a novel
input-to-input gain (IIG) introduced to evaluate fault sensitivity under
disturbances, and investigates their fundamental performance limitations
arising from the transmission zeros of the underlying dynamical system.
Inspired by the OOG, which characterizes the maximum performance loss caused by
stealthy attacks, the IIG is proposed as a new measure of robust fault
sensitivity, and is defined as the maximum energy of undetectable faults for a
given disturbance intensity. Then, using right (for OOG) and left (for IIG)
co-prime factorizations, both metrics are expressed as
the~$\mathcal{H}_{\infty}$ norm of a ratio of the numerator factors. This
unified representation facilitates a systematic analysis of their fundamental
limitations. Subsequently, by utilizing the Poisson integral relation,
theoretical bounds for the IIG and OOG are derived, explicitly characterizing
their fundamental limitations imposed by system \mbox{non-minimum} phase (NMP)
zeros. Finally, a numerical example is employed to validate the results.

</details>


### [351] [Dynamic Modeling, Analysis, and Validation of Dual-Port Grid-Forming Control for Hybrid AC/DC Systems](https://arxiv.org/abs/2509.11318)
*Irina Subotić,Dominic Groß,Alexander Winkens,Julian Jansen,Florian Klein-Helmkamp,Andreas Ulbig*

Main category: eess.SY

TL;DR: 混合交流/直流系统采用双端口面向电网控制进行瞬态和动态行为研究。


<details>
  <summary>Details</summary>
Motivation: 研究混合交流/直流系统的瞬态和动态行为，重点关注双端口面向电网（GFM）控制的性能。

Method: 提出一个混合交流/直流网络的广义建模框架，该框架考虑了转换器、控制和网络电路动力学以及任意网络拓扑。将此建模框架应用于低压网络，以分析双端口GFM控制的性能。

Result: 所提出的双端口GFM控制能够有效改善瞬态响应和减缓振荡，同时可以独立调整稳态响应特性，对阻尼特性的影响很小。通过硬件实验验证了动态模型和结果。

Conclusion: 双端口GFM控制在混合交流/直流系统中有良好的应用前景，尤其是在低压直流配电中，可以作为交流配电系统之间唯一的互连，或与交流连接并行，从而提高低压和中压配电网络的运行灵活性。

Abstract: This work investigates the transient and dynamical behavior of hybrid AC/DC
systems using dual-port grid-forming (GFM) control. A generalized modeling
framework for hybrid AC/DC networks is first introduced that accounts for
converter, control, and network circuit dynamics and arbitrary network
topologies. This modeling framework is applied to low-voltage networks to
analyze the performance of dual-port grid-forming (GFM) control. The results
demonstrate that active damping by dual-port GFM control is effective at
improving the transient response and mitigating oscillations. In contrast, the
steady-state response characteristics can be adjusted independently with
minimal impact on damping characteristics. The dynamic model and results are
validated through hardware experiments for three prototypical system
architectures. Furthermore, we demonstrate that low-voltage DC distribution
interfaced by AC/DC converters using dual-port GFM control, can serve both as
the sole interconnection between AC distribution systems and in parallel to an
AC connection, thereby enhancing the operational flexibility of low- and
medium-voltage distribution networks.

</details>


### [352] [Large-Scale Self-Powered Vibration Control: Theory and Experiment](https://arxiv.org/abs/2509.11346)
*Connor Ligeikis,Heath Hofmann,Jeff Scruggs*

Main category: eess.SY

TL;DR: 一个能自行供能的振动控制系统原型被设计并实验验证，适用于较大规模的应用，该系统通过收集外部干扰的能量来供电。


<details>
  <summary>Details</summary>
Motivation: 设计并实验验证一个能够自行供能的振动控制系统原型，该系统适用于较大规模的应用（功率流大于1W，力在1kN量级）。

Method: 该原型系统由一个线性的滚珠丝杠和一个永磁同步电机组成，并使用定制的三相逆变器来控制功率流，以及一个定制的半桥DC-DC电源转换器来促进功率流向储能电容器。由于控制硬件中存在寄生效应，自供能系统的反馈律必须满足比单纯的无源性更严格的可行性条件。本文采用了一种可行的控制设计方法来处理这一可行性约束。

Result: 通过针对随机激励调谐振动吸收器的硬件在环实验，验证了所提出的控制设计。

Conclusion: 所提出的控制设计方法能够有效处理自供能振动控制系统中由于控制硬件寄生效应带来的可行性约束，并通过实验验证了其有效性。

Abstract: A self-powered system is a control technology that powers itself by
harvesting energy from exogenous disturbances. This article details the design
and experimental validation of a prototype self-powered vibration control
system, for larger-scale applications (i.e., power flows above 1W and forces on
the order of 1kN.) The prototype consists of a linear ballscrew coupled with a
permanent-magnet synchronous machine. A custom three-phase inverter is used to
control power flow, and a custom half-bridge DC-DC power converter is used to
facilitate power flow to and from a storage capacitor. Due to parasitics in the
control hardware, feedback laws for self-powered systems must adhere to a
feasibility condition tighter than mere passivity. This article implements a
tractable control design approach that accounts for this feasibility
constraint. The control design is validated via hardware-in-the-loop
experiments pertaining to a stochastically-excited tuned vibration absorber.

</details>


### [353] [A Goal-Oriented Approach for Active Object Detection with Exploration-Exploitation Balance](https://arxiv.org/abs/2509.11467)
*Yalei Yu,Matthew Coombes,Wen-Hua Chen,Cong Sun,Myles Flanagan,Jingjing Jiang,Pramod Pashupathy,Masoud Sotoodeh-Bahraini,Peter Kinnell,Niels Lohse*

Main category: eess.SY

TL;DR: 该论文提出了一种名为双重探索-利用控制（DCEE）的算法，用于在未知环境中通过控制摄像头移动来进行主动目标检测，特别是在机器人应用中。


<details>
  <summary>Details</summary>
Motivation: 为了解决在未知环境中进行高效主动目标检测的挑战，尤其是在机器人制造等任务中，需要一种能够平衡探索未知区域和利用已知信息进行检测的策略。

Method: 提出了一种基于主动学习的双重探索-利用控制（DCEE）算法。该算法在成本函数中引入了基于方差的不确定性估计，并通过设计奖励函数来编码目标置信度随视角变化的知识。通过估计该函数的未知参数，DCEE能够生成最优的视角规划策略，并在参数估计和视角规划之间取得平衡。

Result: DCEE算法在乐高积木检测等不同场景下表现出良好的适应性，且在不同场景下保持固定的配置和参数数量。实验结果表明，DCEE在主动目标检测方面优于模型预测控制（MPC）和熵方法等现有方法。

Conclusion: DCEE算法是一种高效且鲁棒的主动目标检测方法，通过平衡探索和利用，能够有效地规划视角，并在实际应用中取得优于现有方法的性能。

Abstract: Active object detection, which aims to identify objects of interest through
controlled camera movements, plays a pivotal role in real-world visual
perception for autonomous robotic applications, such as manufacturing tasks
(e.g., assembly operations) performed in unknown environments. A dual control
for exploration and exploitation (DCEE) algorithm is presented within
goal-oriented control systems to achieve efficient active object detection,
leveraging active learning by incorporating variance-based uncertainty
estimation in the cost function. This novel method employs an
exploration-exploitation balanced cost function to actively guide the selection
of the next viewpoint. Specifically, active object detection is achieved
through the development of a reward function that encodes knowledge about the
confidence variation of objects as a function of viewpoint position within a
given domain. By identifying the unknown parameters of this function, the
system generates an optimal viewpoint planning strategy. DCEE integrates
parameter estimation of the reward function and view planning, ensuring a
balanced trade-off between the exploitation of learned knowledge and active
exploration during the planning process. Moreover, it demonstrates remarkable
adaptability across diverse scenarios, effectively handling LEGO brick
detection at varying locations. Importantly, the algorithm maintains consistent
configuration settings and a fixed number of parameters across various
scenarios, underscoring its efficiency and robustness. To validate the proposed
approach, extensive numerical studies, high-fidelity virtual simulations, and
real-world experiments under various scenarios were conducted. The results
confirm the effectiveness of DCEE in active object detection, showcasing
superior performance compared to existing methods, including model predictive
control (MPC) and entropy approaches.

</details>


### [354] [Partitioning techniques for non-centralized predictive control: A systematic review and novel theoretical insights](https://arxiv.org/abs/2509.11470)
*Alessandro Riccardi,Luca Laurenti,Bart De Schutter*

Main category: eess.SY

TL;DR: 该论文对用于大规模系统的非中心化模型预测控制（MPC）的系统划分方法进行了全面的调查和分类。


<details>
  <summary>Details</summary>
Motivation: 为设计和实现大规模系统的非中心化模型预测控制（MPC）策略，开发有效的系统划分方法至关重要。

Method: 将文献中的划分方法系统化为五类：基于优化的、算法的、基于社区发现的、基于博弈论的以及启发式方法。引入了统一的图论形式、混合整数规划的数学重新表述、预测划分和多拓扑表示的新概念，以及质量指标的方法论表述。

Result: 对不同类别的划分技术进行了分析，并概述了它们的优缺点，包括对不同方法的详细技术讨论。通过实际案例研究来说明这些技术在电力系统、水网、风电场、化工过程、交通系统、通信网络、工业自动化、智能建筑和网络物理系统等领域的应用。

Conclusion: 该调查提供了一个对现有系统划分方法的分类，并为该领域的进一步发展奠定了基础，同时指出了未来的挑战。

Abstract: The partitioning problem is of central relevance for designing and
implementing non-centralized Model Predictive Control (MPC) strategies for
large-scale systems. These control approaches include decentralized MPC,
distributed MPC, hierarchical MPC, and coalitional MPC. Partitioning a system
for the application of non-centralized MPC consists of finding the best
definition of the subsystems, and their allocation into groups for the
definition of local controllers, to maximize the relevant performance
indicators. The present survey proposes a novel systematization of the
partitioning approaches in the literature in five main classes:
optimization-based, algorithmic, community-detection-based,
game-theoretic-oriented, and heuristic approaches. A unified graph-theoretical
formalism, a mathematical re-formulation of the problem in terms of
mixed-integer programming, the novel concepts of predictive partitioning and
multi-topological representations, and a methodological formulation of quality
metrics are developed to support the classification and further developments of
the field. We analyze the different classes of partitioning techniques, and we
present an overview of their strengths and limitations, which include a
technical discussion about the different approaches. Representative case
studies are discussed to illustrate the application of partitioning techniques
for non-centralized MPC in various sectors, including power systems, water
networks, wind farms, chemical processes, transportation systems, communication
networks, industrial automation, smart buildings, and cyber-physical systems.
An outlook of future challenges completes the survey.

</details>


### [355] [Model Predictive Control with High-Probability Safety Guarantee for Nonlinear Stochastic Systems](https://arxiv.org/abs/2509.11584)
*Zishun Liu,Liqian Ma,Yongxin Chen*

Main category: eess.SY

TL;DR: 本文提出了一种用于非线性随机系统的模型预测控制（MPC）框架，该框架能以高概率确保安全。


<details>
  <summary>Details</summary>
Motivation: 现有随机MPC方法难以处理概率安全约束，而本文提出的方法能将概率安全约束转化为确定性约束，并与现有的确定性MPC算法兼容。

Method: 采用集合侵蚀（set-erosion）方法将概率安全约束转化为确定性约束，并利用了对随机轨迹围绕其标称轨迹的随机波动的紧密界限。

Result: 该方法具有良好的可扩展性，能够以高概率（例如99.99%）保证安全，适用于具有复杂非线性动力学的安全关键应用。

Conclusion: 通过严格的理论分析和数值实验验证了所提出的MPC方法的有效性。

Abstract: We present a model predictive control (MPC) framework for nonlinear
stochastic systems that ensures safety guarantee with high probability. Unlike
most existing stochastic MPC schemes, our method adopts a set-erosion that
converts the probabilistic safety constraint into a tractable deterministic
safety constraint on a smaller safe set over deterministic dynamics. As a
result, our method is compatible with any off-the-shelf deterministic MPC
algorithm. The key to the effectiveness of our method is a tight bound on the
stochastic fluctuation of a stochastic trajectory around its nominal version.
Our method is scalable and can guarantee safety with high probability level
(e.g., 99.99%), making it particularly suitable for safety-critical
applications involving complex nonlinear dynamics. Rigorous analysis is
conducted to establish a theoretical safety guarantee, and numerical
experiments are provided to validate the effectiveness of the proposed MPC
method.

</details>


### [356] [$ε$-Optimal Multi-Agent Patrol using Recurrent Strategy](https://arxiv.org/abs/2509.11640)
*Deepak Mallya,Arpita Sinha,Leena Vachhani*

Main category: eess.SY

TL;DR: 存在一个近似循环巡逻策略，该策略是通用巡逻问题的ε-最优解，并且可以通过算法确定。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体巡逻问题研究缺乏对最优解性质的评论。

Method: 证明了ε-近似循环巡逻策略的存在性，并建立了一个ε-最优解循环巡逻策略的存在性。提出了一种算法方法来确定ε-近似循环巡逻策略。

Result: ε-最优解的因子ε与离散化常数D成正比，且独立于智能体数量和环境大小。该结果适用于多种已研究的问题。

Conclusion: 存在一个ε-近似循环巡逻策略，该策略是通用巡逻问题的ε-最优解，并且可以通过算法确定。该方法适用于多种问题，并在基于真实环境的图上通过仿真进行了验证。

Abstract: The multi-agent patrol problem refers to repeatedly visiting different
locations in an environment using multiple autonomous agents. For over two
decades, researchers have studied this problem in various settings. While
providing valuable insights into the problem, the works in existing literature
have not commented on the nature of the optimal solutions to the problem. We
first show that an $\epsilon$-approximate recurrent patrol strategy exists for
every feasible patrol strategy. Then, we establish the existence of a recurrent
patrol strategy that is an $\epsilon$-optimal solution to the General Patrol
Problem. The factor $\epsilon$ is proportional to the discretisation constant
$D$, which can be arbitrarily small and is independent of the number of patrol
agents and the size of the environment. This result holds for a variety of
problem formulations already studied. We also provide an algorithmic approach
to determine an $\epsilon$-approximate recurrent patrol strategy for a patrol
strategy created by any method from the literature. We perform extensive
simulations in graphs based on real-life environments to validate the claims
made in this work.

</details>


### [357] [Continuous-Time Distributed Learning for Collective Wisdom Maximization](https://arxiv.org/abs/2509.11808)
*Luka Baković,Giacomo Como,Fabio Fagnani,Anton Proskurnikov,Emma Tegling*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的学习动力学模型，作为Abelson模型在意见动力学中的补充。该模型假设智能体在独立猜测世界真实状态后进行意见交流以达成共识。研究旨在寻找最优参数以最小化共识值的方差，特别是优化对意见改变的易感性。通过将问题与共识理论联系起来，分析证明了所提出的分布式学习最优参数的动力学在所有相关初始条件下都能收敛。最后的数值示例直观展示了系统行为和证明方法。


<details>
  <summary>Details</summary>
Motivation: 受集体智慧优于个体智慧的普遍观点启发，提出一种新的意见动力学模型。

Method: 提出一种新颖的学习动力学模型，作为Abelson模型的补充。智能体独立猜测世界状态后进行意见交流以达成共识。研究最优参数（特别是对意见改变的易感性）以最小化共识值的方差。提出一种分布式学习最优参数的动力学，并通过共识理论证明其收敛性。

Result: 分析表明，所提出的分布式学习最优参数的动力学在所有相关初始条件下都能收敛。

Conclusion: 所提出的分布式学习最优参数的动力学能够收敛，并且数值示例提供了对系统行为和证明方法的直观理解。

Abstract: Motivated by the well established idea that collective wisdom is greater than
that of an individual, we propose a novel learning dynamics as a sort of
companion to the Abelson model of opinion dynamics. Agents are assumed to make
independent guesses about the true state of the world after which they engage
in opinion exchange leading to consensus. We investigate the problem of finding
the optimal parameters for this exchange, e.g. those that minimize the variance
of the consensus value. Specifically, the parameter we examine is
susceptibility to opinion change. We propose a dynamics for distributed
learning of the optimal parameters and analytically show that it converges for
all relevant initial conditions by linking to well established results from
consensus theory. Lastly, a numerical example provides intuition on both system
behavior and our proof methods.

</details>


### [358] [Varying Horizon Learning Economic MPC With Unknown Costs of Disturbed Nonlinear Systems](https://arxiv.org/abs/2509.11823)
*Weiliang Xiong,Defeng He,Haiping Du,Jianbin Mu*

Main category: eess.SY

TL;DR: 该研究提出了一种新颖的、无终端约束的变时域经济模型预测控制（EMPC）方案，用于处理具有附加扰动和未知经济成本的约束非线性系统。


<details>
  <summary>Details</summary>
Motivation: 解决具有附加扰动和未知经济成本的约束非线性系统在经济模型预测控制中的挑战，特别是无终端约束下的收敛性和稳定性问题。

Method: 1. 使用具有混合核的通用回归学习框架来重构未知成本。 2. 开发在线迭代过程自适应调整时域。 3. 设计依赖于时域的收缩约束，以确保闭环系统收敛到期望稳态的邻域。 4. 建立保证系统递归可行性和输入到状态稳定性的充分条件。

Result: 通过连续搅拌釜反应器和四罐系统的仿真，验证了该方案在鲁棒性、经济性能和在线计算负担方面的优势。

Conclusion: 所提出的 EMPC 方案能够有效处理约束非线性系统中的未知成本和扰动，通过自适应调整时域和引入收缩约束，实现了系统的鲁棒性、经济性能和稳定性。

Abstract: This paper proposes a novel varying horizon economic model predictive control
(EMPC) scheme without terminal constraints for constrained nonlinear systems
with additive disturbances and unknown economic costs. The general regression
learning framework with mixed kernels is first used to reconstruct the unknown
cost. Then an online iterative procedure is developed to adjust the horizon
adaptively. Again, an elegant horizon-dependent contraction constraint is
designed to ensure the convergence of the closed-loop system to a neighborhood
of the desired steady state. Moreover, sufficient conditions ensuring recursive
feasibility and input-to-state stability are established for the system in
closed-loop with the EMPC. The merits of the proposed scheme are verified by
the simulations of a continuous stirred tank reactor and a four-tank system in
terms of robustness, economic performance and online computational burden.

</details>


### [359] [High Effort, Low Gain: Fundamental Limits of Active Learning for Linear Dynamical Systems](https://arxiv.org/abs/2509.11907)
*Nicolas Chatzikiriakos,Kevin Jamieson,Andrea Iannelli*

Main category: eess.SY

TL;DR: 本文研究了在有限假设类别中识别未知线性动力系统的样本复杂度问题，重点分析了激励输入对识别准确率的影响，并提出了相应的实验设计和主动学习算法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于理解和优化识别未知线性动力系统的过程，特别是分析激励输入如何影响样本复杂度，并在此基础上提出更有效的识别方法。

Method: 本文首先推导了样本复杂度下界，该下界考虑了激励输入的选择。基于此，提出了一种系统理论条件来评估实验设计的潜在效益。然后，设计了一种适用于该场景的持久激励（PE）条件，并以此建立了样本复杂度上界。最后，利用这些分析结果，提出了一种主动学习算法，该算法能够根据当前估计值最优地进行序列激励，并提供了相应的样本复杂度保证。

Result: 研究结果表明，样本复杂度下界和上界在关键问题参数上具有相同的依赖关系。所提出的PE条件比无限假设类别情况下的条件更弱，并且能够模块化地分析不同的激励输入。最后，通过模拟实验证明了所提出算法的有效性。

Conclusion: 本文通过对样本复杂度下界和上界的分析，为理解和优化线性动力系统识别提供了理论基础，并提出了一种有效的主动学习算法，该算法在实际应用中展现了良好的性能。

Abstract: In this work, we consider the problem of identifying an unknown linear
dynamical system given a finite hypothesis class. In particular, we analyze the
effect of the excitation input on the sample complexity of identifying the true
system with high probability. To this end, we present sample complexity lower
bounds that capture the choice of the selected excitation input. The sample
complexity lower bound gives rise to a system theoretic condition to determine
the potential benefit of experiment design. Informed by the analysis of the
sample complexity lower bound, we propose a persistent excitation (PE)
condition tailored to the considered setting, which we then use to establish
sample complexity upper bounds. Notably, the \acs{PE} condition is weaker than
in the case of an infinite hypothesis class and allows analyzing different
excitation inputs modularly. Crucially, the lower and upper bounds share the
same dependency on key problem parameters. Finally, we leverage these insights
to propose an active learning algorithm that sequentially excites the system
optimally with respect to the current estimate, and provide sample complexity
guarantees for the presented algorithm. Concluding simulations showcase the
effectiveness of the proposed algorithm.

</details>


### [360] [Distributed Finite-Horizon Optimal Control for Consensus with Differential Privacy Guarantees](https://arxiv.org/abs/2509.11917)
*Yuwen Ma,Yongqiang Wang,Sarah K. Spurgeon,Boli Chen*

Main category: eess.SY

TL;DR: 本研究提出了一种利用差分隐私保护多智能体系统（MAS）共识控制的新方法，其中智能体在通信状态信息时能保护其局部成对权重矩阵的机密性。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体系统（MAS）共识控制方法在保护个体智能体成本函数和控制偏好方面存在挑战，特别是当局部成对权重矩阵被视为敏感数据时。

Method: 提出了一种新颖的分布式有限时域线性二次调节器（LQR）框架，该框架通过在通信的状态信息中注入依赖于共识误差的拉普拉斯噪声，并采用精心设计的时间相关缩放因子来处理局部成本函数，从而在保护权重矩阵的机密性的同时实现共识。

Result: 该方法保证了有界的共识，并实现了严格的ε-差分隐私，无需依赖特定的噪声分布假设。此外，研究还分析了共识精度和隐私级别之间的权衡，并为如何通过适当调整LQR权重矩阵和隐私预算来提高共识性能提供了明确的指导。

Conclusion: 本研究成功地提出了一种在多智能体系统中实现隐私保护共识控制的方法，该方法在保护敏感权重矩阵的隐私的同时，实现了有界的共识，并明确了共识精度与隐私保护之间的权衡关系。

Abstract: This paper addresses the problem of privacy-preserving consensus control for
multi-agent systems (MAS) using differential privacy. We propose a novel
distributed finite-horizon linear quadratic regulator (LQR) framework, in which
agents share individual state information while preserving the confidentiality
of their local pairwise weight matrices, which are considered sensitive data in
MAS. Protecting these matrices effectively safeguards each agent's private cost
function and control preferences. Our solution injects consensus
error-dependent Laplace noise into the communicated state information and
employs a carefully designed time-dependent scaling factor in the local cost
functions. {This approach guarantees bounded consensus and achieves rigorous
$\epsilon$-differential privacy for the weight matrices without relying on
specific noise distribution assumptions.} Additionally, we analytically
characterize the trade-off between consensus accuracy and privacy level,
offering clear guidelines on how to enhance consensus performance through
appropriate scaling of the LQR weight matrices and the privacy budget.

</details>


### [361] [Compositional shield synthesis for safe reinforcement learning in partial observability](https://arxiv.org/abs/2509.12085)
*Steven Carr,Georgios Bakirtzis,Ufuk Topcu*

Main category: eess.SY

TL;DR: RL 代理在不确定和部分可观察的环境中容易进入不安全状态。我们提出了一种组合式屏蔽方法来合成保护盾，将安全需求分解为更小的部分，从而提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 确保强化学习（RL）代理在不确定和部分可观察环境中的安全，因为这些代理经常会进入不安全状态。

Method: 将安全需求建模为各个部分，并使用组合方法合成保护盾，以提高可扩展性。

Result: 与未屏蔽的代理相比，配备组合式屏蔽的 RL 代理不仅安全，而且预期回报更高。它还需要更少的训练轮次，尤其是在稀疏奖励的情况下。组合式屏蔽合成使 RL 代理能够在比其他最先进的基于模型的方法大两个数量级的环境中保持安全。

Conclusion: 组合式屏蔽合成是一种可扩展且有效的方法，可以确保 RL 代理在复杂环境中安全运行，同时还能提高其性能。

Abstract: Agents controlled by the output of reinforcement learning (RL) algorithms
often transition to unsafe states, particularly in uncertain and partially
observable environments. Partially observable Markov decision processes
(POMDPs) provide a natural setting for studying such scenarios with limited
sensing. Shields filter undesirable actions to ensure safe RL by preserving
safety requirements in the agents' policy. However, synthesizing holistic
shields is computationally expensive in complex deployment scenarios. We
propose the compositional synthesis of shields by modeling safety requirements
by parts, thereby improving scalability. In particular, problem formulations in
the form of POMDPs using RL algorithms illustrate that an RL agent equipped
with the resulting compositional shielding, beyond being safe, converges to
higher values of expected reward. By using subproblem formulations, we preserve
and improve the ability of shielded agents to require fewer training episodes
than unshielded agents, especially in sparse-reward settings. Concretely, we
find that compositional shield synthesis allows an RL agent to remain safe in
environments two orders of magnitude larger than other state-of-the-art
model-based approaches.

</details>


### [362] [Control Analysis and Design for Autonomous Vehicles Subject to Imperfect AI-Based Perception](https://arxiv.org/abs/2509.12137)
*Tao Yan,Zheyu Zhang,Jingjing Jiang,Wen-Hua Chen*

Main category: eess.SY

TL;DR: 本论文提出了一种用于AI驱动的自动驾驶汽车（AV）的建模、分析和控制新方法，通过表征感知误差（如漏检和测量噪声）来解决AI的黑盒性质带来的挑战，并成功实现了闭环稳定性和性能保证。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AV）的安全至关重要，但AI感知模块的黑盒性质给闭环分析（如稳定性验证和性能保证）带来了挑战。因此，需要新的工具来处理这些问题。

Method: 该研究将重点从直接模拟AI感知过程转移到表征其产生的感知误差。漏检和测量噪声这两种关键的AI诱导感知误差分别用连续时间马尔可夫链和维纳过程进行建模。基于此，提出了一种增强了感知误差模型（PEM）的驾驶模型，并利用随机微积分方法建立了AI驱动AV系统的闭环稳定性。此外，还提出了一种保证性能的输出反馈控制综合方法，该方法被表述为一个凸优化问题，能够高效求解。

Result: 该方法被成功应用于自适应巡航控制（ACC）场景，证明了在存在损坏和误导性感知信息的情况下，该方法仍然有效且鲁棒。

Conclusion: 本研究提出的新颖建模和分析方法能够表征AI感知误差，从而实现对AI驱动的AV系统的闭环稳定性分析和性能保证，并通过凸优化方法进行控制综合，在ACC场景中得到了有效验证。

Abstract: Safety is a critical concern in autonomous vehicle (AV) systems, especially
when AI-based sensing and perception modules are involved. However, due to the
black box nature of AI algorithms, it makes closed-loop analysis and synthesis
particularly challenging, for example, establishing closed-loop stability and
ensuring performance, while they are fundamental to AV safety. To approach this
difficulty, this paper aims to develop new modeling, analysis, and synthesis
tools for AI-based AVs. Inspired by recent developments in perception error
models (PEMs), the focus is shifted from directly modeling AI-based perception
processes to characterizing the perception errors they produce. Two key classes
of AI-induced perception errors are considered: misdetection and measurement
noise. These error patterns are modeled using continuous-time Markov chains and
Wiener processes, respectively. By means of that, a PEM-augmented driving model
is proposed, with which we are able to establish the closed-loop stability for
a class of AI-driven AV systems via stochastic calculus. Furthermore, a
performance-guaranteed output feedback control synthesis method is presented,
which ensures both stability and satisfactory performance. The method is
formulated as a convex optimization problem, allowing for efficient numerical
solutions. The results are then applied to an adaptive cruise control (ACC)
scenario, demonstrating their effectiveness and robustness despite the
corrupted and misleading perception.

</details>


### [363] [Design and Optimization of EV Charging Infrastructure with Battery in Commercial Buildings](https://arxiv.org/abs/2509.12160)
*Quan Nguyen,Christine Holland,Siddharth Sridhar*

Main category: eess.SY

TL;DR: 随着电动汽车的普及，建筑中安装充电站已成为必然趋势。本文提出了一种结合最优变压器和储能系统（BESS）尺寸以及电动汽车充电、BESS运行和建筑负荷之间优化协调的策略，以应对电网基础设施升级和可靠供电的需求。


<details>
  <summary>Details</summary>
Motivation: 为了支持脱碳努力和增加电动汽车的普及，建筑中安装电动汽车充电站是必然的。这一转变可能会带来电网基础设施升级和增强控制的需求，以支持向最终用户负荷的可靠供电以及整体经济运行。因此，有必要评估解决这些需求的策略。

Method: 本文采用滚动窗口优化方法，对学校园区进行了策略评估，该园区包括建筑和电动汽车充电负荷。通过滚动窗口优化，确定了服务变压器和电池储能系统（BESS）的最佳尺寸，以及电动汽车充电和 BESS 充放电调度的优化控制。

Result: 该策略已在 20 年的时间范围内得到验证，其中电动汽车（巴士和货车）的数量逐年增加。此外，还进行了经济分析，以展示每种设计的长期投资成本和收益。

Conclusion: 本文提出的策略可以有效地管理商业建筑（包括电动汽车车队）中的能源消耗。通过对服务变压器和 BESS 进行优化，并协调电动汽车充电和 BESS 运行，可以确保可靠供电并实现经济效益。

Abstract: The installation of electric vehicle (EV) charging stations in buildings is
inevitable, as states push for increased EV adoption to support decarbonization
efforts. This transition could force the need for grid infrastructure upgrades
and enhanced controls to support reliable power delivery to end-use loads, and
overall economic operation. This paper evaluates strategies that address these
needs on two fronts: i) optimal sizing of service transformers and battery
energy storage systems (BESS), and ii) optimized coordination between EV
charging, BESS operation, and building demand. These strategies are applied to
a school campus setting, consisting of building and EV charging loads, to
provide an illustration of energy management in commercial buildings with EV
fleets. A rolling-window optimization approach is applied to determine i)
optimal sizing of the service transformer and BESS and ii) optimal control of
EV charging and BESS charge/discharge schedules. The design and control
strategies are validated in a 20-year time horizon with an annually increasing
number of EVs (buses and vans). In addition, an economic analysis is also
carried out to show the costs and benefits of each design as a medium- and
long-term investment.

</details>


### [364] [Approaches to Analysis and Design of AI-Based Autonomous Vehicles](https://arxiv.org/abs/2509.12169)
*Tao Yan,Zheyu Zhang,Jingjing Jiang,Wen-Hua Chen*

Main category: eess.SY

TL;DR: 本篇论文旨在为基于人工智能的自动驾驶汽车（AV）开发建模、分析和综合工具，以解决AI感知机制理解有限带来的可靠性风险。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AV）在处理复杂的感知任务中越来越多地依赖人工智能（AI）模型，但AI驱动的感知过程机制理解有限，可能对自动驾驶的可靠性带来重大风险。

Method: 提出了一种新的AI驱动感知过程建模方法，将三种基本的AI感知不确定性（由马尔可夫链、高斯过程和有界扰动表示）纳入其中。在此基础上，在均方意义下建立了闭环随机稳定性（SS），并提出了线性矩阵不等式（LMI）框架下的SS控制综合方法。此外，还从随机保证成本的角度分析了鲁棒性和性能，并给出了评估AV在AI不确定性存在下的鲁棒性水平的标准。最后，研究了随机最优保证成本控制，并基于LMI技术和凸优化开发了一种高效的设计程序。

Result: 通过将AI感知不确定性建模为马尔可夫链、高斯过程和有界扰动，成功建立了闭环随机稳定性（SS），并提出了一种基于LMI的SS控制综合方法。此外，还定义了随机保证成本，并提供了评估AV鲁棒性的标准。最后，开发了一种基于LMI和凸优化的随机最优保证成本控制设计程序。

Conclusion: 本研究为基于AI的自动驾驶汽车的闭环稳定性、鲁棒性和性能分析提供了严格的数学框架，并开发了相应的控制综合方法，通过在汽车跟驰控制中的应用和模拟验证了其有效性。

Abstract: Artificial intelligence (AI) models are becoming key components in an
autonomous vehicle (AV), especially in handling complicated perception tasks.
However, closing the loop through AI-based feedback may pose significant risks
on reliability of autonomous driving due to very limited understanding about
the mechanism of AI-driven perception processes. To overcome it, this paper
aims to develop tools for modeling, analysis, and synthesis for a class of
AI-based AV; in particular, their closed-loop properties, e.g., stability,
robustness, and performance, are rigorously studied in the statistical sense.
First, we provide a novel modeling means for the AI-driven perception processes
by looking at their error characteristics. Specifically, three fundamental
AI-induced perception uncertainties are recognized and modeled by Markov
chains, Gaussian processes, and bounded disturbances, respectively. By means of
that, the closed-loop stochastic stability (SS) is established in the sense of
mean square, and then, an SS control synthesis method is presented within the
framework of linear matrix inequalities (LMIs). Besides the SS properties, the
robustness and performance of AI-based AVs are discussed in terms of a
stochastic guaranteed cost, and criteria are given to test the robustness level
of an AV when in the presence of AI-induced uncertainties. Furthermore, the
stochastic optimal guaranteed cost control is investigated, and an efficient
design procedure is developed innovatively based on LMI techniques and convex
optimization. Finally, to illustrate the effectiveness, the developed results
are applied to an example of car following control, along with extensive
simulation.

</details>


### [365] [Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks](https://arxiv.org/abs/2509.06775)
*Po-Heng Chou,Pin-Qi Fu,Walid Saad,Li-Chun Wang*

Main category: eess.SY

TL;DR: 本文提出了一个基于智能体AI的深度双Q网络(DDQN)调度框架，用于新空口(NR) Sidelink (SL)网络中的授权和非授权频谱分配。该框架通过自主感知、适应性策略和对服务质量(QoS)的保证，解决了SL与蜂窝通信(CC)及Wi-Fi共存的挑战。


<details>
  <summary>Details</summary>
Motivation: 为解决新空口(NR) Sidelink (SL)网络在与蜂窝通信(CC)共享授权频谱以及与Wi-Fi共享非授权频谱时面临的严峻共存挑战，以及现有基于规则或阈值的方法的局限性，提出一种能够自主感知并适应动态变化的调度方法。

Method: 提出了一种基于智能体AI的深度双Q网络(DDQN)调度框架，该框架能够自主感知队列动态、信道条件和共存状态，并自适应地调整策略以维持服务质量(QoS)。

Result: 仿真结果表明，与基于阈值的调度方法相比，在有限的授权带宽下，本文提出的框架能够将阻塞率降低高达87.5%。

Conclusion: 智能体AI有潜力为未来的NR SL系统实现稳定、服务质量感知和自适应的调度。

Abstract: This paper presents an agentic artificial intelligence (AI)-driven double
deep Q-network (DDQN) scheduling framework for licensed and unlicensed band
allocation in New Radio (NR) sidelink (SL) networks. SL must share licensed
spectrum with cellular communications (CC) and unlicensed bands with Wi-Fi,
posing significant challenges for coexistence. Unlike prior rule-based or
threshold-based methods, the proposed agentic scheduler autonomously perceives
queueing dynamics, channel conditions, and coexistence states, and adapts its
policy to maintain quality-of-service (QoS). Simulation results show that our
framework reduces the blocking rate by up to 87.5% compared to threshold-based
scheduling under limited licensed bandwidth. These findings demonstrate the
potential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling
for future NR SL systems.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [366] [Framework for Formal Modelling of Metaverse Applications Using Hierarchical Colored Petri Nets](https://arxiv.org/abs/2509.10936)
*Maryam Amin,Umara Noor,Zahid Rashid,Jorn Altmann*

Main category: cs.ET

TL;DR: Metaverse技术的正式建模框架，用于确保其复杂应用（如空中交通管制系统）的正确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: Metaverse技术的集成需要正式验证和评估，以避免潜在的负面影响，但其复杂性带来了挑战。

Method: 提出一个利用分层有色Petri网的框架，对Metaverse技术（以空中交通管制系统为例）进行正式建模和行为验证（包括活性、可达性和有界性）。

Result: 通过空中交通管制系统案例研究，证明该框架能够对复杂Metaverse应用进行数学验证，并在早期识别设计缺陷，从而提高对Metaverse应用正确性的信心。

Conclusion: 所提出的正式建模框架为Metaverse技术的验证提供了一个可行的模板，有助于提高其在现实世界应用中的可靠性。

Abstract: The Metaverse emerges by integrating highly-distributed, complex, and
interconnecting technologies. These technologies need to be formally verified
and evaluated through formal modelling before executing them in real-world
applications, in order to avoid negative impacts on the real world due to
failure of the Metaverse technologies. However, the formal modelling of
Metaverse technologies is challenging due to its highly complex nature.
Therefore, a comprehensive formal verification of the Metaverse technologies is
needed for its realization in multiple potential areas. In this study, a
framework is proposed for the formal modelling of Metaverse technologies, which
allows holistic insights for all applications of Metaverse technologies. By
utilizing the proposed framework, Metaverse applications of any complexity can
be modeled. The working of the proposed framework is illustrated by modelling a
case study of an Air Traffic Control system. In the proposed framework, we
utilize hierarchical colored Petri nets for formal modelling of behavior of the
air traffic control system. The correctness of air traffic control system
properties, such as liveness, reachability, and boundedness, is verified in the
proposed framework. The results of the case study reveal that the proposed
framework can be used as a template for mathematical verification of
challenging and complex Metaverse applications. The results also show that
formal modelling provides an effective tool for identifying flaws in the early
phases of the design of Metaverse applications. The implication of using formal
verification is that it can increase confidence about the correctness of the
Metaverse applications.

</details>


### [367] [Hybrid Quantum Neural Networks for Efficient Protein-Ligand Binding Affinity Prediction](https://arxiv.org/abs/2509.11046)
*Seon-Geun Jeong,Kyeong-Hwan Moon,Won-Joo Hwang*

Main category: cs.ET

TL;DR: 混合量子神经网络（HQNN）在结合亲和力预测中显示出与经典神经网络相当或更优的性能和参数效率，并能在嘈杂的中尺度量子（NISQ）设备上实现，为计算药物发现提供了前景。


<details>
  <summary>Details</summary>
Motivation: 当前的AI模型在预测蛋白质-配体结合亲和力时需要大量的计算资源和训练时间，而混合量子模型有望通过减少参数数量来解决这个问题。

Method: 提出了一种混合量子神经网络（HQNN），该模型能够近似经典嵌入所衍生的潜在特征空间中的非线性函数，并能在NISQ设备上运行。

Result: HQNN在结合亲和力预测任务上实现了与经典神经网络相当或更优的性能，同时参数效率更高。

Conclusion: 混合量子机器学习（QML）有潜力在计算药物发现领域发挥重要作用，尤其是在蛋白质-配体结合亲和力预测方面，能够有效应对计算挑战。

Abstract: Protein-ligand binding affinity is critical in drug discovery, but
experimentally determining it is time-consuming and expensive. Artificial
intelligence (AI) has been used to predict binding affinity, significantly
accelerating this process. However, the high-performance requirements and vast
datasets involved in affinity prediction demand increasingly large AI models,
requiring substantial computational resources and training time. Quantum
machine learning has emerged as a promising solution to these challenges. In
particular, hybrid quantum-classical models can reduce the number of parameters
while maintaining or improving performance compared to classical counterparts.
Despite these advantages, challenges persist: why hybrid quantum models achieve
these benefits, whether quantum neural networks (QNNs) can replace classical
neural networks, and whether such models are feasible on noisy
intermediate-scale quantum (NISQ) devices. This study addresses these
challenges by proposing a hybrid quantum neural network (HQNN) that empirically
demonstrates the capability to approximate non-linear functions in the latent
feature space derived from classical embedding. The primary goal of this study
is to achieve a parameter-efficient model in binding affinity prediction while
ensuring feasibility on NISQ devices. Numerical results indicate that HQNN
achieves comparable or superior performance and parameter efficiency compared
to classical neural networks, underscoring its potential as a viable
replacement. This study highlights the potential of hybrid QML in computational
drug discovery, offering insights into its applicability and advantages in
addressing the computational challenges of protein-ligand binding affinity
prediction.

</details>


### [368] [Vital Signs Monitoring with mmWave OFDM JCAS System](https://arxiv.org/abs/2509.11767)
*Jakub Dobosz,Maximilian Engelhardt,Diego Dupleich,Maciej Stapor,Pawel Kulakowski*

Main category: cs.ET

TL;DR: 该论文展示了一种室内正交频分复用（OFDM）联合通信与感知（JCAS）系统在检测人体心率和呼吸率方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 无线技术在监测人体生命体征方面具有应用前景，尤其是在联合通信与感知（JCAS）的背景下，可应用于医疗、体育、安全、军事等领域。

Method: 在Fraunhofer Institute for Integrated Circuits in Ilmenau，使用工作在FR2频段（26.5 GHz），带宽可变（高达1 GHz）的室内OFDM JCAS系统，在不同的场景下（躺卧、坐姿、行走，视线直达和非视线直达，单人或双人）进行了实验。

Result: 实验结果表明，虽然生命体征检测总体上是可行的，但受到被检测者衣物、活动状态、距离和角度等多种因素的影响。此外，带宽对生命体征检测没有显著影响，因为生命体征信息编码在信号的相位中。

Conclusion: 该JCAS系统能够有效地检测人体生命体征，但检测效果受多种因素影响。

Abstract: Wireless techniques for monitoring human vital signs, such as heart and
breathing rates, offer a promising solution in the context of joint
communication and sensing (JCAS) with applications in medicine, sports, safety,
security, and even the military. This paper reports experimental results
obtained at the Fraunhofer Institute for Integrated Circuits in Ilmenau,
demonstrating the effectiveness of an indoor orthogonal frequency-division
multiplexing (OFDM) JCAS system for detecting human heart and breathing rates.
The system operated in a bistatic configuration at an FR2 frequency of 26.5 GHz
with a variable bandwidth of up to 1 GHz. Measurements were taken under various
scenarios, including a subject lying down, sitting, or walking, in both
line-of-sight and non-line-of-sight conditions, and with one or two subjects
present simultaneously. The results indicate that while vital sign detection is
generally feasible, its effectiveness is influenced by several factors, such as
the subjects clothing, activity, as well as the distance and angle relative to
the sensing system. In addition, no significant influence of bandwidth was
detected since the vital signs information is encoded in the phase of the
signal.

</details>


### [369] [Regulating Ride-Sourcing Markets: Can Minimum Wage Regulation Protect Drivers Without Disrupting the Market?](https://arxiv.org/abs/2509.11845)
*Farnoud Ghasemi,Arjan de Ruijter,Rafal Kucharski,Oded Cats*

Main category: cs.ET

TL;DR: 网约车最低工资可能增加司机收入，但也可能导致车费上涨和平台生存受到威胁。


<details>
  <summary>Details</summary>
Motivation: 旨在评估网约车最低工资法规对司机、乘客和平台的影响，并分析平台锁车策略的效应。

Method: 通过模拟不同法规强度和有/无平台锁车策略下的网约车市场动态来评估法规的有效性。

Result: 最低工资法规显著影响司机收入，可能导致乘客费用上涨，并威胁平台生存。平台锁车策略可提高其盈利能力和司机收入，但会增加失业率并降低服务水平。

Conclusion: 最低工资法规对网约车市场有复杂影响，平台锁车策略虽能提高部分司机收入，但可能牺牲整体就业和服务质量。

Abstract: Ride-sourcing platforms such as Uber and Lyft are prime examples of the gig
economy, recruiting drivers as independent contractors, thereby avoiding legal
and fiscal obligations. Although platforms offer flexibility in choosing work
shifts and areas, many drivers experience low income and poor working
conditions, leading to widespread strikes and protests. Minimum wage regulation
is adopted to improve drivers welfare. However, the impacts of this regulation
on drivers as well as on travelers and platforms, remain largely unknown. While
ride-sourcing platforms do not disclose the relevant data, state-of-the-art
models fail to explain the effects of minimum wage regulation on market
dynamics. In this study, we assess the effectiveness and implications of
minimum wage regulation in ride-sourcing markets while simulating the detailed
dynamics of ride-sourcing markets under varying regulation intensities, both
with and without the so-called platform lockout strategy. Our findings reveal
that minimum wage regulation impacts substantially drivers income, and may lead
to higher fares for travelers and threaten platforms survival. When platforms
adopt a lockout strategy, their profitability significantly improves and
drivers earn more, although many others lose their jobs, and service level for
travelers consequently declines.

</details>


### [370] [HiPARS: Highly-Parallel Atom Rearrangement Sequencer](https://arxiv.org/abs/2509.12083)
*Jonas Winklmann,Martin Schulz*

Main category: cs.ET

TL;DR: 该研究提出了一种改进的算法，以提高基于AOD的中性原子量子计算中原子的重排并行性，从而提高效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 中性原子量子计算因其良好的可扩展性而备受关注，但目前的状态制备方法（如AOD和SLM）在并行性或速度方面存在局限性。

Method: 提出了一种基于大规模并行复合移动的算法，允许同时拾取和移动大量原子到目标位置，以克服现有AOD和SLM方法的缺点。

Result: 该算法在近千个量子比特的设备上表现优于现有方法，并具有进一步优化以扩展到数千个量子比特的潜力。

Conclusion: 该算法有望显著提高中性原子量子计算的状态制备效率和可扩展性，特别是在近地平线设备上。

Abstract: Neutral atom quantum computing's great scaling potential has resulted in it
emerging as a popular modality in recent years. For state preparation, atoms
are loaded stochastically and have to be detected and rearranged at runtime to
create a predetermined initial configuration for circuit execution. Such
rearrangement schemes either suffer from low parallelizability for
acousto-optic deflector (AOD)-based approaches or are comparatively slow in
case of spatial light modulators (SLMs). In our work, we introduce an algorithm
that can improve the parallelizability of the former. Since the transfer of
atoms from static SLM traps to AOD-generated movable traps is detrimental both
in terms of atom loss rates and execution time, our approach is based on
highly-parallel composite moves where many atoms are picked up simultaneously
and maneuvered into target positions that may be comparatively distant. We see
that our algorithm outperforms its alternatives for near-term devices with up
to around 1000 qubits and has the potential to scale up to several thousand
with further optimizations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [371] [Agent-based Simulation for Drone Charging in an Internet of Things Environment System](https://arxiv.org/abs/2509.10867)
*Leonardo Grando,José Roberto Emiliano Leite,Edson Luiz Ursini*

Main category: cs.MA

TL;DR: 该论文提出了一种用于无人机群中电池充电协调的基于代理的仿真模型，并结合机器学习技术进行敏感性分析。


<details>
  <summary>Details</summary>
Motivation: 为了在物联网和工业4.0环境中优化无人机群的电池充电协调，尤其是在智慧农业等应用场景下，提高大规模无人机部署的任务效率和电池续航能力。

Method: 提出了一种基于代理的仿真模型，包含详细的仿真方法、系统架构和实现。并采用机器学习技术分析基于代理的仿真敏感性分析输出结果。

Result: 该模型能够优化电池使用和任务效率，并已在智慧农业用例中进行了探讨。

Conclusion: 基于代理的仿真模型结合机器学习技术能够有效地协调无人机群的电池充电，并在实际应用中展现出优化潜力。

Abstract: This paper presents an agent-based simulation model for coordinating battery
recharging in drone swarms, focusing on applications in Internet of Things
(IoT) and Industry 4.0 environments. The proposed model includes a detailed
description of the simulation methodology, system architecture, and
implementation. One practical use case is explored: Smart Farming, highlighting
how autonomous coordination strategies can optimize battery usage and mission
efficiency in large-scale drone deployments. This work uses a machine learning
technique to analyze the agent-based simulation sensitivity analysis output
results.

</details>


### [372] [Using utility graphs to search for Pareto-optimal outcomes in complex, interdependent issue negotiations](https://arxiv.org/abs/2509.10885)
*Valentin Robu,Mark Klein*

Main category: cs.MA

TL;DR: 该研究提出了一种利用效用图分解算法来搜索复杂自动化谈判中帕累托最优结果的方法，并实现了指数级加速，能够处理迄今为止最大的效用空间。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用效用图分解算法来有效地搜索复杂自动化谈判中的帕累托最优结果。

Method: 提出并测试了能够有效处理高维效用图的算法，并能在不同效用图拓扑结构上实现指数级加速。

Result: 该方法可以处理迄今为止最大的效用空间，并且在不同效用图拓扑结构上实现了指数级加速。

Conclusion: 该研究提出的方法能够有效地处理复杂的自动化谈判，并实现了显著的性能提升，同时连接了自动化谈判与偏好获取研究。

Abstract: This paper studies how utility graphs decomposition algorithms can be used to
effectively search for Pareto-efficient outcomes in complex automated
negotiation. We propose a number of algorithms that can efficiently handle
high-dimensional utility graphs, and test them on a variety of utility graph
topologies, generated based on state of the art methods for analysing complex
graphs. We show that we can achieve exponential speed-up, for many structures,
even for very large utility graphs. To our knowledge, our approach can handle
the largest utility spaces to date for complex interdependent negotiations, in
terms of number of issues. Moreover, we examine the performance of our
algorithms across two different types of elicitation queries from the
literature: value and comparison queries, thus making a connection between
automated negotiation and the preference elicitation literature.

</details>


### [373] [Statistical Model Checking of NetLogo Models](https://arxiv.org/abs/2509.10977)
*Marco Pangallo,Daniele Giachini,Andrea Vandin*

Main category: cs.MA

TL;DR: 该论文提出了一种利用统计模型检查来自动化和保证基于主体的模型（ABM）的统计严谨性的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的ABM分析方法缺乏统计严谨性，并且耗时耗力，研究者通常依赖经验法则和实验。本研究旨在提供一种自动化的方法来解决这些问题。

Method: 提出了一种基于统计模型检查的方法，并开发了一个名为MultiVeStA的工具，该工具与NetLogo集成，用于自动进行ABM输出的统计严谨性检查和校准。

Result: 通过使用两个NetLogo库中的ABM进行演示，证明了MultiVeStA在ABM输出的统计严谨性检查和校准方面的能力。

Conclusion: 本研究提出的工具链可以即时对NetLogo模型进行统计检查，从而促进对ABM输出进行更严谨可靠的分析。

Abstract: Agent-based models (ABMs) are gaining increasing traction in several domains,
due to their ability to represent complex systems that are not easily
expressible with classical mathematical models. This expressivity and richness
come at a cost: ABMs can typically be analyzed only through simulation, making
their analysis challenging. Specifically, when studying the output of ABMs, the
analyst is often confronted with practical questions such as: (i) how many
independent replications should be run? (ii) how many initial time steps should
be discarded as a warm-up? (iii) after the warm-up, how long should the model
run? (iv) what are the right parameter values? Analysts usually resort to rules
of thumb and experimentation, which lack statistical rigor. This is mainly
because addressing these points takes time, and analysts prefer to spend their
limited time improving the model. In this paper, we propose a methodology,
drawing on the field of Statistical Model Checking, to automate the process and
provide guarantees of statistical rigor for ABMs written in NetLogo, one of the
most popular ABM platforms. We discuss MultiVeStA, a tool that dramatically
reduces the time and human intervention needed to run statistically rigorous
checks on ABM outputs, and introduce its integration with NetLogo. Using two
ABMs from the NetLogo library, we showcase MultiVeStA's analysis capabilities
for NetLogo ABMs, as well as a novel application to statistically rigorous
calibration. Our tool-chain makes it immediate to perform statistical checks
with NetLogo models, promoting more rigorous and reliable analyses of ABM
outputs.

</details>


### [374] [SafeDiver: Cooperative AUV-USV Assisted Diver Communication via Multi-agent Reinforcement Learning Approach](https://arxiv.org/abs/2509.11508)
*Tinglong Deng,Hang Tao,Xinxiang Wang,Yinyan Wang,Hanjiang Luo*

Main category: cs.MA

TL;DR: 提出了一种利用海上无人系统辅助水下潜水员进行可靠高速通信的方案。


<details>
  <summary>Details</summary>
Motivation: 现有水下潜水员通信方法存在固有缺点和复杂的水下环境挑战，因此需要一种新的通信方式。

Method: 利用配备光学和声学多模通信设备的多台AUV作为中继节点，并通过多智能体强化学习（MARL）来控制AUVs的协同移动，以实现潜水员之间的高速可靠数据传输。同时，利用USVs的按需部署和广覆盖优势作为地表中继节点，协调和转发AUVs的信息，并控制AUVs自适应地选择中继USV节点进行数据传输，以实现潜水员与地表平台之间的优质通信。

Result: 通过仿真验证，提出的方案能有效实现潜水员的可靠高速通信。

Conclusion: 该方案能够有效地实现潜水员在水下环境中的可靠高速通信。

Abstract: As underwater human activities are increasing, the demand for underwater
communication service presents a significant challenge. Existing underwater
diver communication methods face hurdles due to inherent disadvantages and
complex underwater environments. To address this issue, we propose a scheme
that utilizes maritime unmanned systems to assist divers with reliable and
high-speed communication. Multiple AUVs are equipped with optical and acoustic
multimodal communication devices as relay nodes, providing adaptive
communication services based on changes in the diver's activity area. By using
a multi-agent reinforcement learning (MARL) approach to control the cooperative
movement of AUVs, high-speed and reliable data transmission between divers can
be achieved. At the same time, utilizing the advantages of on-demand deployment
and wide coverage of unmanned surface vehicles (USVs) as surface relay nodes to
coordinate and forward information from AUVs, and controlling AUVs to
adaptively select relay USV nodes for data transmission, high-quality
communication between divers and surface platform can be achieved. Through
simulation verification, the proposed scheme can effectively achieve reliable
and high-speed communication for divers.

</details>


### [375] [MALLM: Multi-Agent Large Language Models Framework](https://arxiv.org/abs/2509.11656)
*Jonas Becker,Lars Benedikt Kaesberg,Niklas Bauer,Jan Philip Wahle,Terry Ruas,Bela Gipp*

Main category: cs.MA

TL;DR: MALLM是一个开源框架，用于系统地分析多主体辩论（MAD）的各个组成部分，提供超过144种独特的配置，并包括一个评估流程，以方便比较不同的MAD配置。


<details>
  <summary>Details</summary>
Motivation: 现有的多主体辩论框架在工具使用、集成评估或代理个性、响应生成器、讨论范式和决策协议的配置方面存在局限性。MALLM旨在解决这些问题，为研究人员提供一个更灵活、可配置的平台来研究MAD。

Method: MALLM通过简单的配置文件来定义辩论，支持多种代理个性（如专家、个性）、响应生成器（如批判、推理）、讨论范式（如记忆、接力）和决策协议（如投票、共识），并能加载Huggingface数据集，提供评估流程。

Result: MALLM提供了超过144种MAD配置，能够加载文本数据集并进行评估，为研究人员提供了深入了解MAD组件及其相互作用的工具。

Conclusion: MALLM是一个为研究人员设计的开源框架，通过提供高度可配置性和集成评估，促进了对多主体辩论的系统分析和理解。

Abstract: Multi-agent debate (MAD) has demonstrated the ability to augment collective
intelligence by scaling test-time compute and leveraging expertise. Current
frameworks for multi-agent debate are often designed towards tool use, lack
integrated evaluation, or provide limited configurability of agent personas,
response generators, discussion paradigms, and decision protocols. We introduce
MALLM (Multi-Agent Large Language Models), an open-source framework that
enables systematic analysis of MAD components. MALLM offers more than 144
unique configurations of MAD, including (1) agent personas (e.g., Expert,
Personality), (2) response generators (e.g., Critical, Reasoning), (3)
discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g.,
Voting, Consensus). MALLM uses simple configuration files to define a debate.
Furthermore, MALLM can load any textual Huggingface dataset (e.g., MMLU-Pro,
WinoGrande) and provides an evaluation pipeline for easy comparison of MAD
configurations. MALLM is tailored towards researchers and provides a window
into the heart of multi-agent debate, facilitating the understanding of its
components and their interplay.

</details>


### [376] [Nash Equilibrium and Belief Evolution in Differential Games](https://arxiv.org/abs/2509.11739)
*Jiangjing Zhou,Ovanes Petrosian,Ye Zhang,Hongwei Gao*

Main category: cs.MA

TL;DR: 该研究提出了一个在连续时间设置下处理具有运动支付不确定性的微分博弈的框架，其中玩家使用连续贝叶斯更新来更新他们对不确定参数的信念。研究证明了玩家的信念收敛于真实参数值，并推导了具有连续贝叶斯更新的纳什均衡策略及其收敛性。该框架的有效性在污染控制博弈中得到了检验。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决微分博弈中固有的运动支付不确定性问题，并提出一种玩家可以通过连续贝叶斯更新来适应和学习不确定参数的方法。

Method: 本研究采用连续贝叶斯更新来处理运动支付不确定性。理论证明利用了关键概率定理来证明信念收敛和纳什均衡策略的收敛性。该方法在污染控制博弈的背景下得到了检验。

Result: 研究证明，玩家的信念会收敛于真实参数值，从而确保长期估计的稳定性和准确性。此外，还推导并证明了具有连续贝叶斯更新的纳什均衡策略的收敛性。在污染控制博弈的案例研究中，在小时间间隔下，动态贝叶斯更新也显示出估计的收敛性。

Conclusion: 本研究成功地为具有运动支付不确定性的微分博弈提供了一个稳健的框架。所提出的连续贝叶斯更新方法确保了信念和纳什均衡策略的收敛性，使其在长期决策和估计方面具有实际意义。该研究为处理动态不确定性下的博弈论问题提供了新的见解。

Abstract: This study investigates differential games with motion-payoff uncertainty in
continuous-time settings. We propose a framework where players update their
beliefs about uncertain parameters using continuous Bayesian updating.
Theoretical proofs leveraging key probability theorems demonstrate that
players' beliefs converge to the true parameter values, ensuring stability and
accuracy in long-term estimations. We further derive Nash Equilibrium
strategies with continuous Bayesian updating for players, emphasizing the role
of belief updates in decision-making processes. Additionally, we establish the
convergence of Nash Equilibrium strategies with continuous Bayesian updating.
The efficacy of both continuous and dynamic Bayesian updating is examined in
the context of pollution control games, showing convergence in players'
estimates under small time intervals in discrete scenarios.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [377] [Crystal Systems Classification of Phosphate-Based Cathode Materials Using Machine Learning for Lithium-Ion Battery](https://arxiv.org/abs/2509.10532)
*Yogesh Yadav,Sandeep K Yadav,Vivek Vijay,Ambesh Dixit*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习可预测磷酸盐阴极的晶体系统。


<details>
  <summary>Details</summary>
Motivation: 电池的物理和化学特性源于锂离子磷酸盐阴极的晶体排列，这对电池的整体性能至关重要。因此，正确预测晶体系统对于估算阴极的性能至关重要。

Method: 本研究将机器学习分类算法应用于预测 Li P (Mn, Fe, Co, Ni, V) O 基磷酸盐阴极的晶体系统（单斜、斜方和三斜）。

Result: 研究表明，体积、带隙和位点是影响预测准确性的关键输入特征。随机森林（80.69%）、极端随机树（78.96%）和梯度提升机（80.40%）等集成机器学习算法在蒙特卡洛交叉验证测试中表现出最佳的预测能力，可以对晶体进行分类。

Conclusion: 机器学习模型，特别是集成模型，可以有效预测磷酸盐阴极材料的晶体系统，其中随机森林、极端随机树和梯度提升机在预测准确性方面表现最好，这为开发潜在的锂离子电池阴极材料提供了基础。

Abstract: The physical and chemical characteristics of cathodes used in batteries are
derived from the lithium-ion phosphate cathodes crystalline arrangement, which
is pivotal to the overall battery performance. Therefore, the correct
prediction of the crystal system is essential to estimate the properties of
cathodes. This study applies machine learning classification algorithms for
predicting the crystal systems, namely monoclinic, orthorhombic, and triclinic,
related to Li P (Mn, Fe, Co, Ni, V) O based Phosphate cathodes. The data used
in this work is extracted from the Materials Project. Feature evaluation showed
that cathode properties depend on the crystal structure, and optimized
classification strategies lead to better predictability. Ensemble machine
learning algorithms such as Random Forest, Extremely Randomized Trees, and
Gradient Boosting Machines have demonstrated the best predictive capabilities
for crystal systems in the Monte Carlo cross-validation test. Additionally,
sequential forward selection (SFS) is performed to identify the most critical
features influencing the prediction accuracy for different machine learning
models, with Volume, Band gap, and Sites as input features ensemble machine
learning algorithms such as Random Forest (80.69%), Extremely Randomized Tree
(78.96%), and Gradient Boosting Machine (80.40%) approaches lead to the maximum
accuracy towards crystallographic classification with stability and the
predicted materials can be the potential cathode materials for lithium ion
batteries.

</details>


### [378] [Programmable Beam Control for Electron Energy-Loss Spectroscopy and Ptychography](https://arxiv.org/abs/2509.10726)
*Mariana Palos,Liam Spillane,Geri Topore,Yaqi Li,David Pesquera,Colin Ophus,Stephanie M. Ribet,Michele Shelly Conroy*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究评估了可编程电子束扫描在扫描透射电子显微镜中应用，重点关注其对电子能量损失谱（EELS）和拟晶成像（ptychography）两种对剂量敏感技术的影响。


<details>
  <summary>Details</summary>
Motivation: 在扫描透射电子显微镜（STEM）中，可编程电子束扫描为提高剂量效率和抑制扫描伪影提供了新的可能性。本研究旨在系统地评估非光栅扫描轨迹（包括螺旋扫描和多次回扫模式）对两种对剂量敏感的技术的影响。

Method: 研究人员在 DyScO3 钙钛矿模型上，比较了不同扫描模式（光栅、螺旋、多次回扫）在空间分辨率、光谱保真度和伪影抑制方面的表现。并特别在低温 BaTiO3 薄膜样品上测试了螺旋扫描的效果。

Result: 拟晶成像在所有扫描模式下均能达到原子分辨率，并且对探针位置的大幅度跳跃具有鲁棒性。然而，原子分辨率的 EELS 成像对探针运动非常敏感，多次回扫和螺旋扫描会导致元素对比度不均匀。在低温条件下，螺旋扫描能够改善 BaTiO3 薄膜的剂量均匀性并减轻与漂移相关的畸变。

Conclusion: 研究为在低剂量 4D-STEM 中实施可编程扫描策略提供了实用的指导，并强调了拟晶成像技术对轨迹诱导伪影的固有抵抗力。

Abstract: Programmable electron-beam scanning offers new opportunities to improve dose
efficiency and suppress scan-induced artifacts in scanning transmission
electron microscopy. Here, we systematically benchmark the impact of non-raster
trajectories, including spiral and multi-pass sequential patterns, on two dose
sensitive techniques: electron energy-loss spectroscopy (EELS) and
ptychography. Using DyScO3 as a model perovskite, we compare spatial
resolution, spectral fidelity, and artifact suppression across scan modes.
Ptychographic phase reconstructions consistently achieve atomic resolution and
remain robust to large jumps in probe position. In contrast, atomic-resolution
EELS maps show pronounced sensitivity to probe motion, with sequential and
spiral scans introducing non-uniform elemental contrast. Finally, spiral
scanning applied under cryogenic conditions in BaTiO3 thin films improves dose
uniformity and mitigates drift related distortions. These results establish
practical guidelines for the implementation of programmable scan strategies in
low-dose 4D-STEM and highlight the inherent resilience of ptychography to
trajectory-induced artifacts.

</details>


### [379] [A Snapshot of Time-Dependent Density-Functional Theory](https://arxiv.org/abs/2509.10745)
*Carsten A. Ullrich*

Main category: cond-mat.mtrl-sci

TL;DR: TDDFT是一种处理电子激发态和各种时间依赖现象（包括耦合的电子-核动力学）的理论，在物理、化学、材料科学等领域有广泛应用。本文综述了TDDFT的最新进展、挑战和热点话题。


<details>
  <summary>Details</summary>
Motivation: TDDFT在电子激发态和时间依赖现象（包括耦合的电子-核动力学）的研究中具有重要作用，并且在物理、(生物)化学、材料科学等领域有广泛应用。

Method: 本文概述了TDDFT的最新进展和成功，包括形式上和计算上的挑战，以及当前的研究热点。

Result: TDDFT在处理电子激发态和时间依赖现象方面取得了显著进展，并在多个领域得到应用。

Conclusion: TDDFT是一个充满活力的研究领域，在理论和计算方面仍面临挑战，但具有广阔的应用前景。

Abstract: Time-dependent density-functional theory (TDDFT) is an extension of
ground-state density-functional theory which allows the treatment of electronic
excited states and a wide range of time-dependent phenomena in the linear and
nonlinear regime, including coupled electron-nuclear dynamics. TDDFT is a
vibrant field with many exciting applications in physics, (bio)chemistry,
materials science and other areas. This perspective gives an overview of recent
developments and successes, formal and computational challenges, and hot topics
in TDDFT.

</details>


### [380] [Achieving fully-compensated ferrimagnetism through two-dimensional heterojunctions](https://arxiv.org/abs/2509.10768)
*San-Dong Guo,Junjie He,Yee Sin Ang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过垂直堆叠两种磁性相同的二维铁磁材料，并满足A型反铁磁序，可以实现全补偿 the ferrimagnetism。


<details>
  <summary>Details</summary>
Motivation: 全补偿 the ferrimagnetism materials are promising for spintronics, data storage and sensors, but existing methods have limitations.

Method: 提出通过垂直堆叠两种磁性相同的二维铁磁材料，并满足A型反铁磁序，形成全补偿 the ferrimagnetism。

Result: 通过第一性原理计算验证了CrI3/CrGeTe3异质结是全补偿 the ferrimagnetism，具有显著的自旋劈裂，并且拉伸应变有利于实现全补偿 the ferrimagnetism。

Conclusion: 提出了一种实验上可行的实现全补偿 the ferrimagnetism 的策略，以推动该领域的发展。

Abstract: In addition to altermagnets, fully-compensated ferrimagnets are another
category of collinear magnetic materials that possess zero-net total magnetic
moment and exhibit spin-splitting, making them promising for low-energy
spintronics, high-density data storage and high-sensitivity sensors. Although
many methods, such as alloying, external electric field, Janus engineering,
ferroelectric field and spin ordering, have been proposed to achieve
fully-compensated ferrimagnetism, these approaches either face experimental
difficulties or produce a small spin-splitting or are volatile. Here, we
propose to form vertical heterostructures by stacking two different but equally
magnetized two-dimensional ferromagnetic materials. If an A-type
antiferromagnetic ordering is satisfied, a fully compensated ferrimagnet can be
formed. This vertical heterostructure approach is insensitive to lattice
matching and stacking manner, thus being more conducive to experimental
realization. Through first-principles calculations, we verify our proposal with
several examples, focusing in particular on
$\mathrm{CrI_3}$/$\mathrm{CrGeTe_3}$ heterojunction composed of experimentally
synthesized $\mathrm{CrI_3}$ and $\mathrm{CrGeTe_3}$ monolayers. The
calculations show that $\mathrm{CrI_3}$/$\mathrm{CrGeTe_3}$ is a
fully-compensated ferrimagnet, with pronounced spin-splitting, and that tensile
strain is more favorable for achieving fully-compensated ferrimagnetism. Our
work provides an experimentally feasible strategy for realizing
fully-compensated ferrimagnetism, thereby further advancing the development of
this field.

</details>


### [381] [Topology-Driven Vibrations in a Chiral Polar Vortex Lattice](https://arxiv.org/abs/2509.10783)
*Eric R. Hoglund,Harrison A. Walker,Peter Meisenheimer,Thomas W. Pfeifer,Niels De Vries,Dipanjan Chaudhuri,Ting-Ran Liu,Steven C. Quillin,Sandhya Susarla,De-Liang Bao,Patrick E. Hopkins,Andrew R. Lupini,Peter Abbamonte,Yu-Tsun Shao Ramamoorthy Ramesh,Sokrates T. Pantelides,Jordan A. Hachtel*

Main category: cond-mat.mtrl-sci

TL;DR: 利用 qEELS 和分子动力学模拟，研究了 PbTiO3 中极性涡旋晶格如何影响其振动光谱，揭示了拓扑结构与声子行为之间的基本联系，为调控相关性质提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 研究铁电体中磁或电偶极子排序形成的拓扑结构及其量子效应，特别是晶格振动（声子）对长程偶极子纹理形成和性质的影响。

Method: 利用单色、动量分辨的电子能量损失谱（qEELS）技术，结合机器学习势能的分子动力学模拟，在纳米空间分辨率和 meV 能量精度下，研究 PbTiO3 极性涡旋晶格对振动光谱的调制作用，特别是涡旋的拓扑对称性和手性如何影响声子模式，以及拓扑缺陷处声子行为的变化。

Result: 发现 PbTiO3 极性涡旋晶格的空间调制振动光谱模式，且模式直接反映了拓扑图案的对称性。揭示了涡旋的拓扑结构如何改变整个振动光谱的声子模式。涡旋的拓扑手性将独特的对称性赋予声子，产生明显的不对称光谱移动。在高分辨率下，观察到拓扑缺陷（涡旋位错核心）处的声子模式恢复为非拓扑的 PbTiO3 模式。

Conclusion: 确立了铁电排序诱导的拓扑结构与声子行为之间的基本联系，为在纳米器件中设计热传输、电子-声子耦合及其他声子介导的性质开辟了新途径。

Abstract: The ordering of magnetic or electric dipoles leading to real-space
topological structures is at the forefront of materials research as their
quantum mechanical nature often lends itself to emergent properties. Atomic
lattice vibrations (phonons) are often a key contributor to the formation of
long-range dipole textures based on ferroelectrics and impact the properties of
the emergent phases. Here, using monochromated, momentum-resolved electron
energy-loss spectroscopy (qEELS) with nanometer spatial resolution and
meV-spectral-precision, we demonstrate that polar vortex lattices in PbTiO$_3$
spatially modulate the material's vibrational spectrum in patterns that
directly reflect the overlying symmetry of the topological patterns. Moreover,
by combining experiments with molecular dynamics simulations using machine
learned potentials we reveal how these structures modify phonon modes across
the vibrational spectrum. Beyond simple intensity modulation, we find that the
chirality of the vortex topology imparts its unique symmetry onto phonons,
producing a distinctive asymmetrical spectral shift across the vortex unit
cell. Finally, the high spatial resolution of the technique enables topological
defects to be probed directly, demonstrating a return to trivial PbTiO$_3$
modes at vortex dislocation cores. These findings establish a fundamental
relationship between ferroelectric-ordering-induced topologies and phonon
behavior, opening new avenues for engineering thermal transport,
electron-phonon coupling, and other phonon-mediated properties in
next-generation nanoscale devices.

</details>


### [382] [Sinusoidal Displacement Describes Disorder in CsPbBr3 Nanocrystal Superlattices](https://arxiv.org/abs/2509.10849)
*Umberto Filippi,Stefano Toso,Matheus G. Ferreira,Lorenzo Tallarini,Yurii P. Ivanov,Francesco Scattarella,Vahid Haghighat,Huaiyu Chen,Megan O. Hill Landberg,Giorgio Divitini,Jesper Wallentin,Cinzia Giannini,Liberato Manna,Dmitry Baranov*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过实验和模型揭示了纳米晶体超晶格中无序的累积和传播机制，并提出了一种正弦位移模型来解释实验现象。


<details>
  <summary>Details</summary>
Motivation: 理解纳米晶体超晶格中无序的累积和传播机制，以及其对结构相干性的影响。

Method: 使用同步辐射掠入射小角和广角X射线散射技术，结合正弦位移模型，研究了不同软度CsPbBr3纳米晶体超晶格的结构特性。

Result: 研究发现，纳米晶体超晶格中的无序具有各向异性，且其程度依赖于材料的软度。随着软度的降低，超晶格的结构有序度增加，衍射峰变得更窄，并在特定方向上出现衍射特征。

Conclusion: 提出的正弦位移模型能够解释实验观察到的各向异性结构相干性及其对超晶格软度的依赖性，从而增进了对宏观晶体系统中无序现象的理解。

Abstract: Disorder is an intrinsic feature of all solids, from crystals of atoms to
superlattices of colloidal nanoparticles. Unlike atomic crystals, in
nanocrystal superlattices a single misplaced particle can affect the positions
of neighbors over long distances, leading to cumulative disorder. This elusive
form of collective particle displacement leaves clear signatures in
diffraction, but little is known about how it accumulates and propagates
throughout the superlattice. Here we rationalize propagation and accumulation
of disorder in a series of CsPbBr3 nanocrystal superlattices by using
synchrotron grazing incidence small- and wide-angle X-ray scattering. CsPbBr3
nanocrystals of colloidal softness S in the range of 0.3-0.7 were obtained by
preparing particles with different sizes and ligand mixtures, consisting of
oleic acid and primary amines of variable lengths. Most diffraction patterns
showed clear signatures of anisotropic disorder, with multilayer diffraction
characteristics of high structural coherence visible only for the {100} axial
directions and lost in all other directions. As the softness decreased, the
superlattices transitioned to a more ordered regime where small-angle
diffraction peaks became resolution-limited, and superlattice multilayer
diffraction appeared for the (110) diagonal reflections. To rationalize these
anisotropies in structural coherence and their dependence on superlattice
softness, we propose a sinusoidal displacement model where longitudinal and
transverse displacements modulate nanocrystal positions. The model explains
experimental observations and advances the understanding of disorder in
mesocrystalline systems as they approach the limits of structural perfection.

</details>


### [383] [Electroluminescence of NV Color Centers in Diamond p-i-n Diodes mediated by Charge-state Dynamics](https://arxiv.org/abs/2509.10904)
*Ruirong Bai,Menglin Huang,Shanshan Wang,Shiyou Chen,Yu-Ning Wu*

Main category: cond-mat.mtrl-sci

TL;DR: NV色心在p-i-n二极管中的电致发光机制仍是谜团，本研究利用第一性原理方法，通过计算载流子截面和跃迁率，揭示了NV0基态、NV+亚稳态和NV0激发态的循环维持了连续电致发光。研究还解释了发光强度较弱的原因，以及NV-发光消失的现象，并为理解其他色心动力学提供了理论洞见。


<details>
  <summary>Details</summary>
Motivation: NV色心在p-i-n二极管中的电致发光（EL）机制长期以来未能解释。

Method: 利用第一性原理方法，计算了电子构型、可能跃迁、载流子截面和跃迁率。

Result: 揭示了EL的机制是由NV0基态（GNV0）、NV+亚稳态（MNV+）和NV0激发态（ENV0）的循环维持的。解释了EL强度弱于光致发光（PL）的原因，归因于MNV+到ENV0的瓶颈跃迁和另一个非发光跃迁循环。解释了NV-发光消失是由于NV-和NV0之间不平衡的跃迁。

Conclusion: 揭示了NV色心的电致发光机制，解释了实验观察结果，并为理解电场和光学场下其他色心的电荷动力学提供了第一性原理的见解。

Abstract: As the electroluminescence (EL) of NV color centers in diamond has been
realized in p-i-n diodes,the underlying mechanism remains a puzzle for longer
than a decade. In this study,using first-principles approaches,the electronic
configurations and the possible transitions are comprehensively investigated.
Based on the calculated carrier cross sections and transition rates,the
mechanism of the EL of NV centers and the charge-state dynamics are revealed.
The continuous EL is maintained by the cycle of NV0 ground (GNV0),NV+
metastable (MNV+) and NV0 excited state (ENV0). The weaker EL intensity
compared to photoluminescence (PL) is explained by the bottleneck transition
from MNV+ to ENV0 and another non-luminescent transition cycle.
Additionally,our results also explain the disappearance of the luminescence of
NV- as a result of unbalanced transitions between NV- and NV0. This study not
only reveal the mechanism of electroluminescence of NV centers and explain
experimental observations,but also provide first-principles insights to
understand the charge-dynamics of other color centers under electric and
optical field.

</details>


### [384] [Spontaneous Twirls and Structural Frustration in Moiré Materials](https://arxiv.org/abs/2509.10907)
*Jingtian Shi,Gaurav Chaudhary,Allan H. MacDonald,Ivar Martin*

Main category: cond-mat.mtrl-sci

TL;DR: 邻近的扭转手性倾向于反排，形成由反铁磁格子 φ4 理论描述的交错图案，这导致了结构扭转的手性构型受挫以及相对于平均扭转角变化和其他控制参数的滞后。


<details>
  <summary>Details</summary>
Motivation: 解释了在某些莫尔材料的畴壁网络中自发形成的结构扭摆。

Method: 将相邻扭摆手性的反排与反铁磁格子 φ4 理论联系起来。

Result: 发现这种排列导致了三角形畴的莫尔系统中的挫折和滞后。

Conclusion: 莫尔材料中的结构扭摆形成交错图案，可由反铁磁格子 φ4 理论描述，并导致挫折和滞后。

Abstract: Structural twirls form spontaneously in the domain wall networks of some
moir\'e materials. We show that in heterobilayers, neighboring twirl
chiralities tend to anti-align, forming staggered patterns that are well
described by antiferromagnetic lattice $\phi^4$ theories. In moir\'e systems
with triangular domains, this leads to frustration in the chirality
configuration of the structural twirls and to hysteresis with respect to
variation of the average twist angle and possibly other control parameters.

</details>


### [385] [Amorphization-Mediated Si-I to Si-V Phase Transition and Reversible Amorphous-Si-V Phase Memory in Silicon Nanoparticles](https://arxiv.org/abs/2509.10960)
*Ziye Deng,Reza Namakian,Wei Gao*

Main category: cond-mat.mtrl-sci

TL;DR: 在球形硅纳米颗粒上施加三轴压缩时，通过分子动力学模拟发现了一个由应力三轴性驱动的两步相变路径：首先形成非晶相，然后重结晶为Si-V相，最终在卸载时转变为完全非晶态。该非晶态在随后的加载-卸载循环中表现出可逆的相变，证明了纳米尺度的相记忆效应。


<details>
  <summary>Details</summary>
Motivation: 研究应力三轴性如何驱动球形硅纳米颗粒在压缩下的相变行为，以及探索纳米尺度下材料的相记忆效应。

Method: 使用基于高斯近似势（GAP）的分子动力学模拟，对直径为10纳米的球形硅纳米颗粒在三轴压缩下进行模拟。

Result: 在低应力三轴性区域（剪切主导）首先形成非晶相，然后高应力三轴性区域重结晶为Si-V相。卸载后，Si-V相转变为完全非晶态。随后的加载-卸载循环显示非晶态到Si-V相的可逆相变。

Conclusion: 应力三轴性是驱动硅纳米颗粒相变的关键因素，并且在纳米尺度下观察到了可逆的相变和相记忆效应。

Abstract: Molecular dynamics simulations using a Gaussian Approximation Potential (GAP)
reveal a stress triaxiality driven, two-step Si-I (diamond cubic) to Si-V
(simple hexagonal) phase transition pathway in a spherical Si nanoparticle with
a 10 nm diameter under triaxial compression. A transient amorphous phase first
forms at the surface and propagates inward around Si-I core, where stress
triaxiality is low (shear-dominated). Within the amorphous shell, the material
recrystallizes into Si-V at locations of elevated stress triaxiality and
hydrostatic pressure. The resulting Si-V structure transforms into a fully
amorphous state upon unloading. A subsequent loading-unloading cycle applied to
this amorphous nanoparticle reveals a reversible amorphous to Si-V
transformation, demonstrating a nanoscale phase memory effect.

</details>


### [386] [Synergetic Enhancement of Power Factors and Suppression of Lattice Thermal Conductivities via Biaxial Strain in ScAgSe$_2$ and TmAgTe$_2$](https://arxiv.org/abs/2509.11051)
*Wu Xiong,Zhongjuan Han,Zhonghao Xia,Zhilong Yang,Jiangang He*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在 ScAgSe2 和 TmAgTe2 中引入双轴拉伸应变来提高热电性能。


<details>
  <summary>Details</summary>
Motivation: 热电材料的性能受塞贝克系数、电导率和晶格热导率之间相互制约的挑战。

Method: 结合第一性原理计算、电子-声子耦合分析以及声子和电子玻尔兹曼输运方程，研究了拉伸应变对 ScAgSe2 和 TmAgTe2 的影响。

Result: 3%（2%）的拉伸应变分别使 ScAgSe2（TmAgTe2）在载流子浓度为 3×10^20 cm^-3 时，沿 c 轴的功率因子（PF）提高了 243%（246%），并将晶格热导率（κL）降低了 37%（26%）。

Conclusion: 分子轨道分析揭示了一种提高热电性能的有效途径，并将双轴拉伸应变策略成功应用于 ScAgSe2 和 TmAgTe2，显著提高了热电优值（ZT）。

Abstract: The challenge of achieving high thermoelectric (TE) performance is mainly
from the entanglement among Seebeck coefficient ($S$), electrical conductivity
($\sigma$), and lattice thermal conductivity ($\kappa_{\mathrm{L}}$). In this
work, we propose a synergetic strategy of enhancing power factor (PF,
$S^2\sigma$) and suppressing $\kappa_{\mathrm{L}}$ by applying a biaxial
tensile strain in two silver chalcogenides ScAgSe$_2$ and TmAgTe$_2$ with
TlCdS$_2$-type structure. The forbidden $p$-$d$ orbital coupling at the
$\Gamma$ point and allowed $p$-$d$ orbital coupling at the A point and the
middle of $\Lambda$ line leads to high electronic band dispersion along the
$\Gamma$-A direction and a high-degeneracy valence band valley ($\Lambda_2$).
The elongation of the Ag-Se bond under tensile strain weakens the orbital
coupling between Ag-$d$ and Se/Te-$p$ orbitals and reduces the band energy at
the A point, which aligns the valence band and achieving a high band
degeneracy. Concurrently, the weaker Ag-Se/Ag-Te bond under a small tensile
strain leads to lower phonon group velocity and strong three- and four phonon
scatterings, leading to lower $\kappa_{\mathrm{L}}$. Our first-principles
calculations combined with electron-phonon coupling analysis as well as phonon
and electron Boltzmann transport equations show that applying a 3\% (2\%)
tensile strain can enhance the PF along the $c$-axis of ScAgSe$_2$ (TmAgTe$_2$)
by 243\% (246\%) at a carrier concentration of 3$\times$10$^{20}$ cm$^{-3}$ and
reduce the $\kappa_{\mathrm{L}}$ by 37\% (26\%) at 300 K. Consequently, 2
$\sim$ 4 times of $ZT$ enhancement is obtained by 3\% or 1\% tensile strain in
ScAgSe$_2$ (TmAgTe$_2$) at 300 K, achieving a maximum $ZT$ of 3.10 (3.62) at
800 K. Our material design strategy based on molecular orbital analysis reveals
an effective route to boosting TE performance, and can be extended to other
systems as well.

</details>


### [387] [Dislocation response to electric fields in strontium titanate: A mesoscale indentation study](https://arxiv.org/abs/2509.11181)
*Alexander Frisch,Daniel Isaia,Oliver Preuß,Xufei Fang*

Main category: cond-mat.mtrl-sci

TL;DR: 位错会降低SrTiO3晶体的介电击穿强度，但施加的电场不会影响位错的行为。


<details>
  <summary>Details</summary>
Motivation: 研究外加电场下位错在钙钛氧化物中的稳定性及其对介电击穿强度的影响。

Method: 制备高密度位错的SrTiO3样品，并研究其介电击穿强度。在2 kV/mm的电场下，使用压痕法研究位错的引入和运动。

Result: 位错导致SrTiO3晶体的介电击穿强度降低且离散度增大。施加的电场不会改变位错的大小、深度和分布。

Conclusion: 位错会降低SrTiO3晶体的介电击穿强度，但施加的电场不会影响位错的行为。

Abstract: Dislocations in perovskite oxides have drawn increasing research interest due
to their potential of tuning functional properties of electroceramics. Open
questions remain regarding the behavior of dislocations concerning their
stability under strong externally applied electric fields. In this study, we
investigate the dielectric breakdown strength of nominally undoped SrTiO3
crystals after the introduction of high-density dislocations. The
dislocation-rich samples are prepared using the Brinell scratching method, and
they consistently exhibit lower dielectric breakdown strength as well as a
larger scatter in the breakdown probability. We also study the impact of
electric field on the introduction and movement of dislocations in SrTiO3
crystals using Brinell indentation coupled with an electric field of 2 kV/mm.
No changes on the dislocation plastic zone size, depth, and dislocation
distribution are observed under this electric field. Based on the charge state
of the dislocations in SrTiO3 as well as the electrical and thermal
conductivity modified by dislocations, we discuss the forces induced by the
electric field to act on the dislocations to underline the possible mechanisms
for such dislocation behavior.

</details>


### [388] ["Adiabatic" Elastic Constants in Hubbard-Corrected Density-Functional Theory DFT+U: case UO$_2$](https://arxiv.org/abs/2509.11200)
*Mahmoud Payami,Samira Sheykhi*

Main category: cond-mat.mtrl-sci

TL;DR: DFT+U方法计算弹性常数时，需要注意避免不同电子局域最小值导致的应力-应变关系不准确。本文提出并应用了“绝热”计算方法，避免了该问题，并对UO2晶体进行了计算，结果与实验吻合良好。


<details>
  <summary>Details</summary>
Motivation: DFT+U方法在计算弹性常数时，由于可能存在多个自洽电子解（即亚稳态），当应变构型落入与平衡非应变态不同的局域电子最小值时，会导致计算出的弹性常数不准确。因此，在计算小应变几何的应力时，必须小心地保持相同的电子Hubbard占有支。 

Method: 提出并应用了“绝热”计算方法，以确保在计算小应变几何的应力时，保持与平衡非应变态相同的电子Hubbard占有支，从而避免计算出的弹性常数不准确。

Result: 使用12原子立方和6原子四方两种不同的晶胞基组，对UO2晶体进行了计算，两种不同晶胞基组的计算结果在0.1 GPa以内相同，并且与实验结果吻合良好。

Conclusion: 本文提出的“绝热”计算方法可以准确地计算DFT+U方法中的弹性常数，并成功应用于UO2晶体，验证了该方法的有效性。

Abstract: Since in DFT+U there are multiple self-consistent electronic solutions, the
so called metastable states, the elastic constants computed from
stress-vs-strain will be incorrect if some of the strained configurations fall
into a different local electronic minimum than the equilibrium non-strained
state. So, it is crucial to carefully take steps to keep the same electronic
Hubbard occupation branch when computing the stresses for small strained
geometries. In this work, we have explained this "adiabatic" method of
calculation for elastic constants and applied for UO$_2$ crystal described
within two different unit cells of cubic 12-atom and tetragonal 6-atom basis
sets. The calculation results for the two different unit cells are the same
within 0.1 GPa, and agreement with experiment is excellent.

</details>


### [389] [Intrinsic Quantum Clusters in Kagome Weyl Semimetal Co3Sn2S2](https://arxiv.org/abs/2509.11230)
*Yuqing Xing,Hui Chen,Li Huang,Roger Guzman,Qi Zheng,Senhao Lv,Jinan Shi,Haitao Yang,Wu Zhou,Hong-Jun Gao*

Main category: cond-mat.mtrl-sci

TL;DR: Intrinsic oxygen defects (quantum clusters) in Co3Sn2S2 act as tunable perturbations that reshape electronic states and order parameters on its surface, influencing quantum states.


<details>
  <summary>Details</summary>
Motivation: The role of intrinsic impurities in shaping the quantum states of the magnetic Weyl semimetal Co3Sn2S2, a compelling platform for studying impurity excited states, remains elusive.

Method: Scanning tunneling microscopy/spectroscopy, non-contact atomic force microscopy, and scanning transmission electron microscopy/electron energy loss spectroscopy were used to identify and characterize intrinsic quantum clusters on the surface of Co3Sn2S2.

Result: Intrinsic oxygen defects (quantum clusters) were identified as the dominant intrinsic defect on both Sn- and S-terminated surfaces. On Sn-terminated surfaces, oxygen in hollow sites tunes the Fermi level flat band, inducing orbital magnetism and an unconventional Zeeman effect. On S-terminated surfaces, oxygen interstitials create impurity states with sixfold symmetry at higher energies and C2 symmetry at lower energies, with no measurable magnetic response.

Conclusion: Intrinsic oxygen-related quantum clusters act as tunable local perturbations in topological kagome magnets like Co3Sn2S2, providing a versatile platform to investigate and engineer impurity-driven phenomena in correlated and topological systems.

Abstract: Impurities and intrinsic point defects, which profoundly influence spin,
charge, and topological degrees of freedom, are crucial parameters for tuning
quantum states in quantum materials. The magnetic Weyl semimetal Co3Sn2S2 with
its strong spin-orbit coupling, intrinsic ferromagnetism, and kagome lattice of
correlated electrons, provides a compelling platform for studying impurity
excited states. Yet, the role of intrinsic impurities in shaping its quantum
states remains elusive. Here, we uncover intrinsic quantum clusters-localized
intrinsic point defects that act as tunable quantum perturbations capable of
reshaping electronic states and order parameters, on the surface of Co3Sn2S2
via scanning tunneling microscopy/spectroscopy and non contact atomic force
microscopy, combined with scanning transmission electron microscopy/electron
energy loss spectroscopy. These clusters are identified as native oxygen
defects that dominate the intrinsic defect landscape on both cleaved surface
terminations. On the Sn-terminated surface, oxygen impurities occupy hollow
sites between three Sn atoms, and tune the flat band near the Fermi level,
which exhibits orbital magnetism induced unconventional Zeeman effect under an
applied magnetic field. On the S-terminated surface, oxygen interstitials
reside slightly off center relative to the S lattice and generate occupied
impurity states that retain sixfold symmetry at higher energies but reduce to
C2 symmetry at lower energies. In contrast, these impurity states show no
measurable magnetic response. Our findings establish that intrinsic
oxygen-related quantum clusters act as tunable local perturbations in a
topological kagome magnet, offering a versatile platform to probe and engineer
impurity-driven phenomena in correlated and topological systems.

</details>


### [390] [Achieving DFT accuracy in short range ordering and stacking fault energy using moment tensor potential for CoCrFeNi and CoCrNi](https://arxiv.org/abs/2509.11231)
*Mashroor S. Nitol,Artur Tamm,Subah Mubassira,Shuozhi Xu,Saryu J. Fensin*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种机器学习力场，以在模拟密度泛函理论（DFT）准确性和计算效率之间取得平衡，从而能够进行更大规模的模拟。


<details>
  <summary>Details</summary>
Motivation: 为了克服密度泛函理论（DFT）在模拟中计算成本高和经典势函数保真度不足的问题，特别是在捕捉多体相互作用和化学短程有序（CSRO）效应方面。

Method: 开发并训练了一个机器学习矩张量势（MTP），该势基于涵盖从单元到四元组的全面DFT数据库。使用该MTP进行混合蒙特卡洛/分子动力学模拟，并对堆垛层错能量进行了建模。

Result: MTP在能量、力和应力方面具有接近DFT的精度，并准确预测了体模量和剪切模量。模拟捕捉到了CSRO效应，并准确预测了堆垛层错能量（CoCrNi为54 mJ/m²，CoCrFeNi为36 mJ/m²），还揭示了局部化学环境对堆垛层错能量的影响。

Conclusion: 所开发的MTP能够以远低于DFT的成本进行大规模、高保真度的模拟，为预测FCC中熵合金的热力学稳定性、缺陷行为和机械响应提供了可靠的框架。

Abstract: Medium-entropy alloys (MEAs) such as CoCrFeNi and CoCrNi are promising
structural materials owing to their outstanding mechanical and thermal
properties, which arise from complex chemical disorder and atomic-scale
interactions. Although density functional theory (DFT) has provided fundamental
insights into these systems, its high computational cost limits exploration of
large-scale phenomena. Classical interatomic potentials have been used to
address this gap but often lack the fidelity needed to capture many-body
interactions and chemical short-range ordering (CSRO) effects. In this work, we
developed a machine-learned Moment Tensor Potential (MTP) to bridge accuracy
and efficiency. The MTP was trained on a comprehensive DFT database spanning
unary to quaternary configurations and reproduces energies, forces, and
stresses with near-DFT accuracy across diverse structural and chemical
environments. It accurately predicts elastic properties and recovers
compositional trends in bulk and shear moduli in agreement with DFT. Hybrid
Monte Carlo/molecular dynamics simulations capture CSRO, reproducing key
DFT-reported features including Cr-Cr and Fe-Fe repulsion and Ni-Cr ordering.
Stacking fault energetics were modeled, yielding ISF energies near 54 mJ/m2 for
CoCrNi and 36 mJ/m2 for CoCrFeNi, consistent with DFT predictions. Local
chemical environment effects on stacking faults were also resolved: Co-rich
planes reduce, whereas Cr- or Fe-rich planes increase, the stacking fault
energy. By enabling large-scale, high-fidelity simulations at a fraction of
DFT's cost, the developed MTP provides a robust framework for predictive
modeling of thermodynamic stability, defect behavior, and mechanical response
of FCC MEAs.

</details>


### [391] [Pristine and transition metal doped 2D AlSb as high performance electrocatalyst for selective CO2 reduction: A first-principles study](https://arxiv.org/abs/2509.11325)
*Md. Mostaqul Islam,Ahmed Zubair*

Main category: cond-mat.mtrl-sci

TL;DR: Fe, Co, Ni 掺杂的二维 AlSb 表现出作为 CO2RR 催化剂的潜力，其中 Fe 掺杂的催化剂活性最高。


<details>
  <summary>Details</summary>
Motivation: 利用二维纳米材料通过电化学 CO2 还原反应 (CO2RR) 减少工业 CO2 排放。

Method: 使用密度泛函理论 (DFT) 研究了原始和掺杂 (Fe, Co, Ni) 的二维 AlSb 作为 CO2RR 催化剂的反应途径、过电位、稳定性和选择性。

Result: Ni 掺杂的二维 AlSb 在 HCOOH (0.12 eV) 和 CH4 (0.28 eV) 方面表现出选择性，Fe 掺杂的二维 AlSb 在 HCHO (0.31 eV) 和 CH3OH (0.31 eV) 方面表现出选择性。Fe 掺杂的二维 AlSb 催化剂表现出最高的催化活性。催化活性的增强归因于掺杂剂的 3d 轨道导致的带隙减小和价带边缘态的形成。

Conclusion: 原始和掺杂的二维 AlSb 具有优异的电催化性能，适合作为 CO2RR 催化剂，有助于实现绿色和可持续的能源生态系统。

Abstract: Electrochemical CO2 reduction reaction (CO2RR) using 2D nanomaterials has
emerged as a sophisticated approach to mitigate industrial CO2 emissions. In
this work, the potential application of pristine as well as strategically Fe,
Co, Ni-doped 2D AlSb was examined as a CO2RR electrocatalyst. The recation
pathways of CO2RR intermediate complexes, overpotential, stability, efficiency,
and selectivity were studied using density functional theory (DFT). Outstanding
overpotentials were achieved with pristine and doped 2D AlSb: Ni-doped 2D AlSb
was selective for HCOOH (0.12eV) and CH4 (0.28eV), and Fe-doped 2D AlSb for
HCHO (0.31eV) and CH3OH (0.31eV). The opposing effects of hydrogen evolution
reaction (HER) was mitigated with the application of electric potential and
solution pH. The main reasons for the enhancement of catalytic effect due to
doping with Fe, Co, and Ni are bandgap reduction and creation of states at the
edge of the valence band due to the 3d orbitals of these dopants.
Interestingly, the Fe-doped 2D AlSb catalyst exhibited the highest catalytic
activity. Excellent electrocatalytic properties of pristine and doped 2D AlSb
make them suitable as CO2RR catalysts contributing towards a green and
sustainable energy ecosystem.

</details>


### [392] [Si-Substituted MAX Phases and In-Situ Formation of Si-coated MXene Composites via Chlorosilane Etching](https://arxiv.org/abs/2509.11380)
*Xudong Wang,Qian Fang,Mian Li,Zhifang Chai,Qing Huang*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种新的策略，通过铝基MAX前驱体与SiCl4蒸气反应，成功合成了多种硅基MAX相材料，并实现了对A位缺陷的精确调控。该方法克服了传统高温合成的限制，并能一步法制备硅涂层MXene复合材料，为设计功能性MAX相和MXene基混合材料提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 硅基MAX相材料具有优异的热稳定性和化学稳定性，但其高温合成存在热力学不稳定性。本研究旨在开发一种新的合成策略来克服这一挑战，并实现对材料结构的精确控制。

Method: 采用“由上而下”的策略，通过铝基MAX前驱体与SiCl4蒸气反应，合成硅基MAX相（M = Ti, V, Nb, Ta, Cr; X = C, N）。同时，引入基于氧化还原电位的模型来解释反应路径，并研究了Tin+1AlXn与SiCl4反应一步合成硅涂层MXene复合材料的方法。

Result: 成功合成了多种硅基MAX相，包括具有可控空位浓度的Nb2Si3/4C和Nb2Si1/2C。实现了Ti3C2Tx MXene的表面包覆非晶态纳米硅，制备了一步法合成硅涂层MXene复合材料。

Conclusion: 本研究提出的合成策略不仅克服了传统高温合成的限制，还能够精确调控材料的A位缺陷，并一步法制备硅涂层MXene复合材料，为MAX相和MXene基混合材料的设计提供了新的方法和思路，有望在储能和催化领域得到应用。

Abstract: Silicon-based MAX phases are a promising class of layered ceramics with
superior thermal and chemical stability. However, their synthesis remains
challenging due to inherent thermodynamic instability at high temperatures.
Herein, we develop a general top-down strategy to synthesize a broad family of
Si-substituted MAX phases (M = Ti, V, Nb, Ta, Cr; X = C, N) by reacting
Al-based MAX precursors with SiCl4 vapor. This approach not only circumvents
traditional high-temperature limitations but also enables precise A-site defect
engineering, resulting in phases with controlled vacancy concentrations (e.g.,
Nb2Si3/4C and Nb2Si1/2C). Furthermore, we introduce a redox potential-based
model that rationalizes the reaction pathway. Using Tin+1AlXn etched with SiCl4
as an example, the process simultaneously forms Cl-terminated MXene (Mn+1XnCl2)
and amorphous nano-Si, enabling the one-step synthesis of Si-coated MXene
composites. This methodology provides new avenues for designing advanced MAX
phases and MXene-based hybrids with tailored functionalities for applications
in energy storage and catalysis.

</details>


### [393] [Geometric Analysis of Magnetic Labyrinthine Stripe Evolution via U-Net Segmentation](https://arxiv.org/abs/2509.11485)
*Vinícius Yu Okubo,Kotaro Shimizu,B. S. Shivaran,Gia-Wei Chern,Hae Yong Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 深度学习和几何分析被用于量化磁畴壁的演变。


<details>
  <summary>Details</summary>
Motivation: Labyrinthine stripe patterns are common in many physical systems, yet their lack of long-range order makes quantitative characterization challenging.

Method: A U-Net deep learning model, trained with synthetic degradations including additive white Gaussian and Simplex noise, enables robust segmentation of experimental magneto-optical images despite noise and occlusions. Building on this segmentation, we develop a geometric analysis pipeline based on skeletonization, graph mapping, and spline fitting, which quantifies local stripe propagation through length and curvature measurements.

Result: Applying this framework to 444 images from 12 annealing protocol trials, we analyze the transition from the "quenched" state to a more parallel and coherent "annealed" state, and identify two distinct evolution modes (Type A and Type B) linked to field polarity.

Conclusion: Our results provide a quantitative analysis of geometric and topological properties in magnetic stripe patterns and offer new insights into their local structural evolution, and establish a general tool for analyzing complex labyrinthine systems.

Abstract: Labyrinthine stripe patterns are common in many physical systems, yet their
lack of long-range order makes quantitative characterization challenging. We
investigate the evolution of such patterns in bismuth-doped yttrium iron garnet
(Bi:YIG) films subjected to a magnetic field annealing protocol. A U-Net deep
learning model, trained with synthetic degradations including additive white
Gaussian and Simplex noise, enables robust segmentation of experimental
magneto-optical images despite noise and occlusions. Building on this
segmentation, we develop a geometric analysis pipeline based on
skeletonization, graph mapping, and spline fitting, which quantifies local
stripe propagation through length and curvature measurements. Applying this
framework to 444 images from 12 annealing protocol trials, we analyze the
transition from the "quenched" state to a more parallel and coherent "annealed"
state, and identify two distinct evolution modes (Type A and Type B) linked to
field polarity. Our results provide a quantitative analysis of geometric and
topological properties in magnetic stripe patterns and offer new insights into
their local structural evolution, and establish a general tool for analyzing
complex labyrinthine systems.

</details>


### [394] [Orbital Hybridization-Driven Stabilization and Reactivity on an Asymmetrically Reconstructed Polar CeO2(100) Surface](https://arxiv.org/abs/2509.11568)
*Songda Li,Chen Zou,Liuxi Chen,Zhong-Kang Han,Wentao Yuan,Hangsheng Yang,David J. Wales,Yong Wang*

Main category: cond-mat.mtrl-sci

TL;DR: CeO2(100)表面存在一种新的不对称(1x2)重建结构，其特点是Ce3+/Ce4+交替排列，并且氧原子重新排列。这种重建激活了O 2p轨道，增强了电子给体能力，从而促进了H2O等分子的解离。


<details>
  <summary>Details</summary>
Motivation: 理解和控制极性氧化物表面的原子结构对于揭示表面反应性和设计先进的催化材料至关重要，而CeO2(100)表面是多相催化中典型且重要的体系，但其重建行为仍是未解之谜。

Method: 结合全局结构搜索算法、基于机器学习的原子势模型、密度泛函理论(DFT)计算和原位扫描透射电子显微镜(STEM)的综合方法。

Result: 发现了一种新的不对称(1x2)重建结构，该结构在热力学和动力学上均稳定，其特点是Ce3+和Ce4+离子交替排列，层间距增大，表面氧原子重构。重建的表面形成了局域的Ce3+极化激子，引入了占据的4f态，并与表面O 2p轨道强烈杂化，在费米能级以下产生了新的占据电子态。

Conclusion: 表面重建通过轨道杂化调控电子结构和反应性的基本机理，为调整极性氧化物表面的催化性能提供了关键见解和新的设计策略。

Abstract: Understanding and controlling the atomic structure of polar oxide surfaces is
essential for unraveling surface reactivilty and designing advanced catalytic
materials. Among these, the polar CeO2(100) surface is a prototypical and
industrially important system in heterogeneous catalysis. However, due to the
vast complexity of the surface configurations, its reconstruction behavior
remains an open question. Here, we report a previously unidentified asymmetric
(1x2) reconstructed structure on the CeO2(100) surface, discovered through an
integrated approach that combines global structure search algorithms, machine
learning-based atomic potential models, density functional theory (DFT)
calculations, and in situ scanning transmission electron microscopy (STEM). The
reconstructed surface is both thermodynamically and kinetically stable,
characterized by an alternating arrangement of Ce3+ and Ce4+ ions, increased
interlayer spacing, and reconfigured surface oxygen atoms. Importantly, the
formation of localized Ce3+ polarons introduces occupied 4f states that
strongly hybridize with surface O 2p orbitals, resulting in new occupied
electronic states below the Fermi level. This orbital hybridization activates
the O 2p states, enhances their electron-donating capacity, and facilitates the
dissociation of adsorbed molecules such as H2O. These findings reveal a
fundamental orbital-mediated mechanism by which surface reconstruction governs
electronic structure and reactivity, offering critical insights and a new
design strategy for tuning catalytic performance on polar oxide surfaces.

</details>


### [395] [Controlled growth of polar altermagnets via chemical vapor transport](https://arxiv.org/abs/2509.11716)
*Hiraka Haruhiro,Raktim Datta,Poonam Yadav,Anzar Ali,Suheon Lee,Matthias J. Gutmann,Duhee Yoon,Dirk Wulferding,Xianghan Xu,Moon-Ho Jo,Sang-Wook Cheong,Sungkyun Choi*

Main category: cond-mat.mtrl-sci

TL;DR: Altermagnetic properties in polar magnetic oxides M$_{2}$Mo$_{3}$O$_{8}$ are promising but hindered by crystal growth challenges. This paper reports the successful growth of large single crystals of Fe$_{2}$Mo$_{3}$O$_{8}$ and NiZnMo$_{3}$O$_{8}$ using an optimized transport agent method, enabling detailed investigation and manipulation of their altermagnetic and multiferroic properties.


<details>
  <summary>Details</summary>
Motivation: Understanding the microscopic origins of altermagnetic properties in polar magnetic oxides M$_{2}$Mo$_{3}$O$_{8}$ is crucial due to their potential for stronger magnetoelectric coupling and higher magnetic transition temperatures, but experimental studies are limited by the difficulty in growing large single crystals.

Method: The study optimized crystal growth of Fe$_{2}$Mo$_{3}$O$_{8}$ and NiZnMo$_{3}$O$_{8}$ by controlling transport agent density, convection, and diffusion kinetics. Crystal quality was verified using X-ray diffraction, Laue diffraction, magnetic susceptibility, and Raman spectroscopy. The effect of Zn doping on magnetic properties was also investigated.

Result: Large, high-quality single crystals of Fe$_{2}$Mo$_{3}$O$_{8}$ and NiZnMo$_{3}$O$_{8}$ were successfully grown. The study demonstrated the manipulation of magnetic properties through nonmagnetic Zn doping in NiZnMo$_{3}$O$_{8}$.

Conclusion: The developed controlled growth method allows for detailed investigation and manipulation of unconventional altermagnetic and multiferroic properties in M$_{2}$Mo$_{3}$O$_{8}$ compounds, providing insights for growing other functional quantum materials.

Abstract: Altermagnetic properties have been recently proposed in polar magnetic
oxides, M$_{2}$Mo$_{3}$O$_{8}$ (M = Mn, Fe, Co, Ni), where improved
characteristics of stronger magnetoelectric coupling and higher magnetic
transition temperatures were observed. Thus, understanding their microscopic
origins is of fundamental and technological importance. However, the difficulty
in growing large single crystals hinders detailed experimental studies. Here,
we report the successful growth of large single crystals of the pyroelectric
antiferromagnet using two representative compounds, Fe$_{2}$Mo$_{3}$O$_{8}$ and
NiZnMo$_{3}$O$_{8}$. Growth was optimized using various parameters, finding the
transport agent density as a primary factor, which depends strongly on the
position of the pellet, the starting powder form, and the volume of the ampule.
We demonstrated a controlled growth method by manipulating the convection and
diffusion kinetics. High-quality crystals were characterized by using
single-crystal X-ray diffraction, Laue diffraction, magnetic susceptibility,
and Raman spectroscopy. Manipulation of magnetic properties through nonmagnetic
Zn doping was shown in NiZnMo$_{3}$O$_{8}$. Our results enable the detailed
investigation and manipulation of their unconventional altermagnetic and
multiferroic properties. This study provides crucial insight into the
controlled growth of other functional quantum materials.

</details>


### [396] [Effects of training machine-learning potentials for radiation damage simulations using different pseudopotentials](https://arxiv.org/abs/2509.11813)
*A. Fellman,J. Byggmästar,F. Granberg,F. Djurabekova,K. Nordlund*

Main category: cond-mat.mtrl-sci

TL;DR: ML势能与不同赝势对镍的辐射损伤模拟有显著影响，但平均阈值位移能相似。


<details>
  <summary>Details</summary>
Motivation: 在镍中研究ML势能与不同赝势对辐射效应模拟的影响，重点关注辐射损伤模拟中的差异。

Method: 使用不同赝势（包括包含半芯电子的“硬”赝势）训练ML势能，并进行辐射损伤模拟，包括大规模重叠级联模拟，并与实验数据进行比较。还研究了修改训练后势能的排斥对相互作用的方法。

Result: “硬”赝势影响短程相互作用，导致辐射损伤模拟结果存在显著差异。平均阈值位移能相似（40-50 eV）。大规模重叠级联模拟的累积损伤与卢瑟福背散射光谱/通道实验结果进行了比较。研究了修改排斥对相互作用的方法的可行性。

Conclusion: ML势能的赝势选择对镍的辐射损伤模拟有重要影响，尽管平均阈值位移能保持相对稳定。累积损伤的预测以及对排斥对相互作用的修正方法是进一步研究的关键。

Abstract: Machine learning (ML) has become a commonplace approach in the development of
interatomic potentials for molecular dynamics simulations, and its use also for
radiation effect modelling is increasing. In this work, we investigate the
effects of training ML potentials to density functional theory data calculated
with different pseudopotentials in nickel. We look in detail at the differences
that appear in radiation damage simulations. The use of a "harder"
pseudopotential with semicore electrons has a direct impact on the short-range
interactions, which in turn has implications on the radiation damage
simulations. We find that despite these differences, the average threshold
displacement energy is quite similar (40-50 eV for Ni). However, we find
significant differences in the cumulative damage predicted by massively
overlapping cascade simulations and compare them with Rutherford Backscattering
Spectroscopy/channeling experiments. We also investigate approaches to modify
the repulsive pair interactions after training the potentials and discuss the
feasibility of such approaches.

</details>


### [397] [Descriptor and Graph-based Molecular Representations in Prediction of Copolymer Properties Using Machine Learning](https://arxiv.org/abs/2509.11874)
*Elaheh Kazemi-Khasragh,Rocío Mercado,Carlos Gonzalez,Maciej Haranczyk*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用随机森林（RF）和图神经网络（GNN）两种模型，结合分子描述符和2D聚合物图两种表征，预测了140种二元共聚物的七种物理性质，以加速共聚物设计。


<details>
  <summary>Details</summary>
Motivation: 为了加速共聚物设计，并优先选择具有良好性质的候选材料。

Method: 使用分子描述符训练随机森林模型，并使用2D聚合物图训练图神经网络模型（单任务和多任务）。

Result: RF模型在预测密度、恒定压力（Cp）和恒定体积（Cv）下的热容方面表现更好；GNN模型在预测膨胀系数（γ，α）和体积模量（K）方面表现更好。

Conclusion: 选择合适的表征对于预测分子性质至关重要，机器学习模型可以加速共聚物发现，并推动高性能材料的开发。

Abstract: Copolymers are highly versatile materials with a vast range of possible
chemical compositions. By using computational methods for property prediction,
the design of copolymers can be accelerated, allowing for the prioritization of
candidates with favorable properties. In this study, we utilized two distinct
representations of molecular ensembles to predict the seven different physical
polymer properties copolymers using machine learning: we used a random forest
(RF) model to predict polymer properties from molecular descriptors, and a
graph neural network (GNN) to predict the same properties from 2D polymer
graphs under both a single- and multi-task setting. To train and evaluate the
models, we constructed a data set from molecular dynamic simulations for 140
binary copolymers with varying monomer compositions and configurations. Our
results demonstrate that descriptors-based RFs excel at predicting density and
specific heat capacities at constant pressure (Cp) and volume (Cv) because
these properties are strongly tied to specific molecular features captured by
molecular descriptors. In contrast, graph representations better predict
expansion coefficients ({\gamma}, {\alpha}) and bulk modulus (K), which depend
more on complex structural interactions better captured by graph-based models.
This study underscores the importance of choosing appropriate representations
for predicting molecular properties. Our findings demonstrate how machine
learning models can expedite copolymer discovery with learnable
structure-property relationships, streamlining polymer design and advancing the
development of high-performance materials for diverse applications.

</details>


### [398] [Signatures of Chiral Phonons in MnPS$_3$ from first principles](https://arxiv.org/abs/2509.11879)
*Banhi Chatterjee,Peter Kratzer*

Main category: cond-mat.mtrl-sci

TL;DR: MnPS3二维材料具有由圆偏振光激发产生的平面手性声子。


<details>
  <summary>Details</summary>
Motivation: 在二维材料中寻找具有手性圆声子的新材料，特别是那些具有与TMDC相似但晶胞更大的材料。

Method: 使用DFT+U和有限位移法计算MnPS3的声子模式，并研究其手性。

Result: 在MnPS3的谷点发现了平面手性声子模式，并计算了它们的量化角动量。还指出了通过圆偏振光选择性激发这些声子的方法。

Conclusion: MnPS3是一种潜在的手性圆声子材料，可以通过光学方法进行激发和控制。

Abstract: Two-dimensional (2D) materials may host circular phonons, considered as
chiral if the presence of a substrate breaks mirror symmetry. In 2D transition
metal dichalcogenide (TMDC) monolayers lacking inversion symmetry, phonons with
a given chirality can be observed in the non-equilibrium state triggered by
optical excitations using circularly polarized light. Backed by
first-principles calculations, we present the antiferromagnetic semiconductor
MnPS$_3$ with a hexagonal crystal structure and bandstructure similar to TMDCs,
but a larger unit cell, as a novel candidate material that may allow for
excitation of circular phonons. Using DFT+U and the finite displacement method
we obtain in-plane chiral phonon modes at the valley points of a monolayer
MnPS$_3$. These modes can be classified according to the Mn or S atoms
performing circular motions about their equilibrium positions. In each case,
the quantized angular momentum of the phonons is calculated. Moreover, we point
out ways to populate the chiral phonons selectively via optical excitation with
circularly polarized light.

</details>


### [399] [Orchestration of Heterogeneous Experimental Machines via ROS2 for Automated Bulk Intermetallic Synthesis](https://arxiv.org/abs/2509.12011)
*Wei-Sheng Wang,Kensei Terashima,Yoshihiko Takano*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究介绍了一个由ROS2控制的自动化真空电弧熔炼系统，能够同时处理多个实验设备并灵活扩展功能，可用于多种元素的金属间化合物合成，有望加速数据驱动材料探索的实验验证。


<details>
  <summary>Details</summary>
Motivation: 材料科学信息学的发展和材料物性预测的需求，推动了对高效、准确的实验验证方法的需求，而机器人系统在处理重复性、耗时任务方面具有优势，可提高通量并减少人为错误。然而，目前关于固态块状材料合成的自动化报道有限，这促使了本研究的进行。

Method: 研究构建了一个由机器人操作系统2（ROS2）控制的自动化真空电弧熔炼系统，该系统能够灵活地处理多个实验设备，并支持未来功能的扩展。该系统不仅可以重复执行特定工艺，还可以处理多种元素以合成金属间化合物。

Result: 所构建的系统能够同时操作多个实验设备，具有良好的灵活性和可扩展性。该系统可以重复执行特定工艺，并能处理多种元素以合成金属间化合物。

Conclusion: 本研究成功构建了一个自动化真空电弧熔炼系统，并利用ROS2实现了对多个实验设备的协同控制和灵活扩展。该系统能够高效地合成多种金属间化合物，有望加速数据驱动的材料探索过程中的实验验证环节，推动材料科学的发展。

Abstract: With advances in informatics applied to materials science, predicting the
physical properties of numerous materials has become increasingly feasible,
creating a growing demand for their experimental validation. It has been
expected that the integration of robotic systems into experimental materials
science excels at efficiently performing repetitive and time-consuming tasks
without the need for human intervention, thus significantly increasing
throughput and reducing the risk of human error, while there have been a
limited number of reports tackled the synthesis process of solid bulk material
so far possibly because of the complex as well as a wide variety of processes
to deal with. In this paper, we report an automated arc melting system
controlled by a robot operating system2 (ROS2). Taking advantage of ROS2, we
have constructed a machine that can handle multiple experimental apparatuses
simultaneously with flexibility for future expansion of functions. The
constructed machine is capable of not only performing repeated operation of a
specific process but also dealing with multiple elements for synthesis of
intermetallic compounds. The system is expected to accelerate experimental
validation of data-driven materials exploration.

</details>


### [400] [Tuning the Magnetic Anisotropy Energy of MoS$_2$-supported Mn$_{12}$ complexes by Electric Field: A First-Principles Study](https://arxiv.org/abs/2509.12020)
*Shuanglong Liu,Adam V. Bruce,Dmitry Skachkov,James N. Fry,Hai-Ping Cheng*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了四种十二核锰单分子磁体在二硫化钼单层上的吸附构型，并探讨了电场对其磁各向异性能的调控作用。


<details>
  <summary>Details</summary>
Motivation: 研究调控单分子磁体的性质，特别是利用电场在表面上调控其磁各向异性能。

Method: 使用力场和密度泛函理论计算，研究了四种不同的十二核锰单分子磁体（R=H, CH3, CHCl2, C6H5）在二硫化钼单层上的低能吸附构型。分析了范德华相互作用、电子转移、能带对齐以及电场对磁各向异性能的影响。

Result: 范德华相互作用对吸附能至关重要。吸附导致电子从衬底转移到分子，降低了Mn12的磁各向异性能。负电场比正电场更能调控电荷转移和能带对齐，进而改变磁各向异性能。在足够高的电场下，R=CHCl2或R=C6H5的Mn12的磁各向异性能显著增加。计算表明分子在电场作用前后均保持完整。评估了由不同吸附构型形成的两能级系统，并证明了其能量势垒在电场下的可调性。

Conclusion: 研究证明了在表面上利用电场调控单分子磁体性质的可行性，特别是对磁各向异性能的调控。

Abstract: In this work, we examine low-energy adsorption configurations of four
dodecanuclear manganese single-molecule magnets
[Mn$_{12}$O$_{12}$(O$_2$CR)$_{16}$(H$_2$O)$_4$] (Mn$_{12}$), where the ligand R
being H, CH$_3$, CHCl$_2$ or C$_6$H$_5$, on a molybdenum disulfide (MoS$_2$)
monolayer using force field and density functional theory calculations. The van
der Waals interaction is shown to be crucial for determining the adsorption
energy. Some electrons transfer from the substrate to the molecules upon
surface adsorption, resulting in a reduction of the magnetic anisotropy energy
of Mn$_{12}$. Since the lowest unoccupied molecular orbital of Mn$_{12}$ is
close to the valence band of MoS$_2$, a negative electric field is more
effective in modulating charge transfer and energy band alignment, and thus
altering the magnetic anisotropy energy, compared with a positive electric
field. A significant increase in the magnetic anisotropy energy of Mn$_{12}$
with the ligand R=CHCl$_2$ or R=C$_6$H$_5$ under a sufficiently high electric
field has been predicted. Our calculations show that the molecules remain
intact on the surface both before and after the electric field is applied.
Finally, a two-level system formed by different adsorption configurations is
evaluated, and the tunability of its energy barrier under an electric field is
demonstrated. Our study sheds light on tuning the properties of single-molecule
magnets using an electric field, when the molecules are supported on a surface.

</details>


### [401] [Detective quantum efficiency based comparison of HRTEM and ptychography phase imaging](https://arxiv.org/abs/2509.12037)
*Felix Bennemann,Angus I. Kirkland,David A. Muller,Peter Nellist*

Main category: cond-mat.mtrl-sci

TL;DR: 电子显微镜成像技术在成像敏感材料方面的效率比较


<details>
  <summary>Details</summary>
Motivation: 比较高分辨率透射电子显微镜（HRTEM）和电子衍射层析成像（ptychography）在成像材料方面的效率，以确定哪种技术在较低的电子注量下能获得更好的成像效果。

Method: 使用探测量子效率（DQE）作为衡量成像技术性能的独立于注量和样品的指标，并将其应用于电子显微镜。

Result: 电子衍射层析成像技术对于弱相位对象，其效率不如理想的Zernike相位成像显微镜，但在部分相干情况下，电子衍射层析成像技术表现出更好的鲁棒性。

Conclusion: DQE是衡量电子显微镜成像技术性能的有效指标。虽然电子衍射层析成像技术在某些方面不如理想的相位成像显微镜，但其在部分相干条件下的鲁棒性使其成为一种有前景的成像技术。

Abstract: High-resolution transmission electron microscopy (HRTEM) is an important
method for imaging beam sensitive materials often under cryo conditions.
Electron ptychography in the scanning transmission electron microscope (STEM)
has been shown to reconstruct low-noise phase data at a reduced fluence for
such materials. This raises the question of whether ptychography or HRTEM
provides a more fluence-efficient imaging technique. Even though the transfer
function is a common metric for evaluating the performance of an imaging
method, it only describes the signal transfer with respect to spatial
frequency, irrespective of the noise transfer. It can also not well defined for
methods, such as ptychography, that use an algorithm to form the final image.
Here we apply the concept of detective quantum efficiency (DQE) to electron
microscopy as a fluence independent and sample independent measure of technique
performance. We find that, for a weak-phase object, ptychography can never
reach the efficiency of a perfect Zernike phase imaging microscope but that
ptychography is more robust to partial coherence.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [402] [Predator-Prey Model: Driven Hunt for Accelerated Grokking](https://arxiv.org/abs/2509.10562)
*I. A. Lopatin,S. V. Kozyrev,A. N. Pechen*

Main category: cs.NE

TL;DR: 该方法使用捕食者-被捕食者模型进行优化，在沟壑状景观中能避免陷入局部最优，并能加速学习过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决在沟壑状景观中优化可能陷入局部最优的问题，并提高学习速度。

Method: 提出一种使用两个模拟生物行为的智能体（捕食者和猎物）的机器学习方法。捕食者追逐猎物，猎物逃离，通过这种交互在景观上进行优化。在沟壑状景观中，捕食者沿着沟壑驱赶猎物，以避免陷入局部最优，此方法被称为“驱赶式狩猎”。

Result: 在沟壑状景观优化中，该方法能有效避免陷入局部最优。在某些“grokking”（延迟泛化）问题上，与标准学习方法相比，学习速度提高了近百倍。

Conclusion: 该“驱赶式狩猎”方法在沟壑状景观优化中表现出色，能有效避免陷入局部最优，并显著提高学习效率，尤其在处理延迟泛化问题时效果显著。

Abstract: A machine learning method is proposed using two agents that simulate the
biological behavior of a predator and a prey. In this method, the predator and
the prey interact with each other - the predator chases the prey while the prey
runs away from the predator - to perform an optimization on the landscape. This
method allows, for the case of a ravine landscape (i.e., a landscape with
narrow ravines and with gentle slopes along the ravines) to avoid getting
optimization stuck in the ravine. For this, in the optimization over a ravine
landscape the predator drives the prey along the ravine. Thus we also call this
approach, for the case of ravine landscapes, the driven hunt method. For some
examples of grokking (i.e., delayed generalization) problems we show that this
method allows for achieving up to a hundred times faster learning compared to
the standard learning procedure.

</details>


### [403] [Deep Reinforcement Learning-Assisted Component Auto-Configuration of Differential Evolution Algorithm for Constrained Optimization: A Foundation Model](https://arxiv.org/abs/2509.11016)
*Xu Yang,Rui Wang,Kaiwen Li,Wenhua Li,Ling Wang*

Main category: cs.NE

TL;DR: 该研究提出了一种基于深度强化学习的自动化差分进化算法组件配置框架SuperDE，以解决约束优化问题（COPs）。


<details>
  <summary>Details</summary>
Motivation: 手动设计进化算法难以适应动态变化的问题，且“无免费午餐”定理表明不存在适用于所有问题的单一最优算法。现有的在线自适应方法在约束优化问题上存在效率低下、收敛性弱和泛化能力有限的问题。

Method: 提出了一种名为SuperDE的框架，利用深度强化学习（DRL）中的双深度Q网络（DDQN）动态配置差分进化（DE）算法的进化组件。该模型通过元学习在多种COPs上进行离线训练，能够对未见过的问0-shot进行最优配置推荐。

Result: SuperDE在基准测试套件上显著优于现有的最先进算法，展现了出色的泛化能力和优化性能。

Conclusion: SuperDE通过自动化组件配置有效解决了约束优化问题，并能对新问题进行泛化。

Abstract: Despite significant efforts to manually design high-performance evolutionary
algorithms, their adaptability remains limited due to the dynamic and
ever-evolving nature of real-world problems. The "no free lunch" theorem
highlights that no single algorithm performs optimally across all problems.
While online adaptation methods have been proposed, they often suffer from
inefficiency, weak convergence, and limited generalization on constrained
optimization problems (COPs).
  To address these challenges, we introduce a novel framework for automated
component configuration in Differential Evolution (DE) algorithm to address
COPs, powered by Deep Reinforcement Learning (DRL). Specifically, we propose
SuperDE, a foundation model that dynamically configures DE's evolutionary
components based on real-time evolution. Trained offline through meta-learning
across a wide variety of COPs, SuperDE is capable of recommending optimal
per-generation configurations for unseen problems in a zero-shot manner.
Utilizing a Double Deep Q-Network (DDQN), SuperDE adapts its configuration
strategies in response to the evolving population states during optimization.
Experimental results demonstrate that SuperDE significantly outperforms
existing state-of-the-art algorithms on benchmark test suites, achieving
superior generalization and optimization performance.

</details>


### [404] [Application of Machine Learning for Correcting Defect-induced Neuromorphic Circuit Inference Errors](https://arxiv.org/abs/2509.11113)
*Vedant Sawal,Hiu Yung Wong*

Main category: cs.NE

TL;DR: 提出一种基于机器学习的容错方法，用于纠正全模拟阻变存储器（ReRAM）神经形态电路中的推理错误。


<details>
  <summary>Details</summary>
Motivation: 旨在解决全模拟阻变存储器（ReRAM）神经形态电路中因存呆故障（stuck-at faults）导致的推理错误问题，提高电路的可靠性和成品率。

Method: 利用设计-工艺协同优化（DTCO）仿真框架，对多层多阵列神经形态架构中的六种空间缺陷类型（圆形、互补圆形、环形、行、列和棋盘形）进行建模和分析。提出一种轻量级神经网络，利用电路输出电压进行训练，以纠正推理错误。

Result: 在模拟的缺陷场景下，该纠正方法能够将高达35%（从55%恢复到90%）的推理准确率损失进行恢复。该方法对未在训练中见过的缺陷类型也表现出一定的泛化能力。

Conclusion: 所提出的机器学习方法能够显著提高神经形态电路的鲁棒性，具有良好的可扩展性和能效，可用于边缘计算和物联网应用。该框架还能支持实时自适应学习，实现对动态或老化引起的故障进行片上纠正。

Abstract: This paper presents a machine learning-based approach to correct inference
errors caused by stuck-at faults in fully analog ReRAM-based neuromorphic
circuits. Using a Design-Technology Co-Optimization (DTCO) simulation
framework, we model and analyze six spatial defect types-circular,
circular-complement, ring, row, column, and checkerboard-across multiple layers
of a multi-array neuromorphic architecture. We demonstrate that the proposed
correction method, which employs a lightweight neural network trained on the
circuit's output voltages, can recover up to 35% (from 55% to 90%) inference
accuracy loss in defective scenarios. Our results, based on handwritten digit
recognition tasks, show that even small corrective networks can significantly
improve circuit robustness. This method offers a scalable and energy-efficient
path toward enhanced yield and reliability for neuromorphic systems in edge and
internet-of-things (IoTs) applications. In addition to correcting the specific
defect types used during training, our method also demonstrates the ability to
generalize-achieving reasonable accuracy when tested on different types of
defects not seen during training. The framework can be readily extended to
support real-time adaptive learning, enabling on-chip correction for dynamic or
aging-induced fault profiles.

</details>


### [405] [Time to Play: Simulating Early-Life Animal Dynamics Enhances Robotics Locomotion Discovery](https://arxiv.org/abs/2509.11755)
*Paul Templier,Hannah Janmohamed,David Labonte,Antoine Cully*

Main category: cs.NE

TL;DR: 本文提出了一种名为SMOL（Scaling Mechanical Output over Lifetime）的新型训练方法，通过模拟生物体在成长和衰老过程中肌腱力量的变化，动态调整机器人驱动器的强度，以提高机器人运动行为的性能和多样性。


<details>
  <summary>Details</summary>
Motivation: 生物体在发育过程中，身体形态的变化对其运动能力有深远影响，但目前的机器人训练通常在静态物理参数下进行。受生物体肌肉力量随年龄增长而变化的启发，我们提出SMOL方法来解决这一问题。

Method: SMOL将驱动器扭矩的变化整合到MAP-Elites质量多样性框架中，以模仿机器人力量随成长和身体变化而产生的演变。此外，还实施了SMOL-Human方案，模拟青春期等非线性变化引起的等距身体变化。

Result: SMOL方法在多种控制场景下，一致地提高了运动行为的性能和多样性。研究表明，SMOL使机器人能够利用早期有利的物理条件发现技能，这些技能可以作为其达到最终标准身体属性时的垫脚石。

Conclusion: SMOL方法通过动态调整机器人驱动器强度来模拟生物体的成长和衰老过程，有效提升了机器人在不同控制场景下的运动性能和行为多样性。SMOL-Human方案也展示了其在模拟非线性身体变化方面的潜力。

Abstract: Developmental changes in body morphology profoundly shape locomotion in
animals, yet artificial agents and robots are typically trained under static
physical parameters. Inspired by ontogenetic scaling of muscle power in
biology, we propose Scaling Mechanical Output over Lifetime (SMOL), a novel
curriculum that dynamically modulates robot actuator strength to mimic natural
variations in power-to-weight ratio during growth and ageing. Integrating SMOL
into the MAP-Elites quality-diversity framework, we vary the torque in standard
robotics tasks to mimic the evolution of strength in animals as they grow up
and as their body changes. Through comprehensive empirical evaluation, we show
that the SMOL schedule consistently elevates both performance and diversity of
locomotion behaviours across varied control scenarios, by allowing agents to
leverage advantageous physics early on to discover skills that act as stepping
stones when they reach their final standard body properties. Based on studies
of the total power output in humans, we also implement the SMOL-Human schedule
that models isometric body variations due to non-linear changes like puberty,
and study its impact on robotics locomotion.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [406] [Development of AI-integrated infrastructure with biomedical device and mobile app for neonatal vital monitoring during and in between kangaroo care sessions](https://arxiv.org/abs/2509.10489)
*Saptarshi Purkayastha,Hrishikesh Bhagwat,Keerthika Sunchu,Orlando Hoilett,Eddy Odari,Reuben Thuo,Martin Wafula,Celia Kariuki,Sherri Bucher*

Main category: eess.SP

TL;DR: 该论文提出了一个结合了NeoWarm设备、NeoRoo移动应用和NeoSmartML机器学习基础设施的集成系统，用于在袋鼠母亲护理（KMC）期间对早产儿进行生命体征监测，以应对低收入和中等收入国家（LMICs）的早产儿死亡率挑战。系统优化了功耗，支持离线数据同步，并通过光学字符识别（OCR）技术自动提取生命体征。实验证明该系统在资源受限环境下的可行性，但仍需进一步优化心率、体温检测和风险分类模型。


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家（LMICs）的早产儿死亡率居高不下，需要对早产儿进行持续的生命体征监测以早期发现危及生命的情况。

Method: 提出并集成了NeoWarm（新型生物医学设备）、NeoRoo（移动应用程序）和NeoSmartML（机器学习基础设施），实现了袋鼠母亲护理（KMC）期间的生命体征监测。NeoWarm设备功耗优化，续航能力强；NeoRoo应用采用离线优先架构，支持数据同步；OCR流水线用于从现有NICU监视器自动提取生命体征。

Result: NeoWarm设备单次充电可连续运行6-6.5天。OCR流水线在自动提取生命体征方面表现出良好的准确性（F1分数为0.78-0.875）。实验验证表明该系统在资源受限环境中具有部署的可行性。

Conclusion: 该集成系统为资源受限环境下的早产儿生命体征监测提供了解决方案，但心率和体温检测以及风险分类基础模型仍需进一步优化。

Abstract: Premature infant mortality remains a critical challenge in low- and
middle-income countries (LMICs), with continuous vital sign monitoring being
essential for early detection of life-threatening conditions. This paper
presents an integrated system combining NeoWarm, a novel biomedical device,
with NeoRoo, a mobile application, and NeoSmartML, a machine learning
infrastructure, to enable comprehensive vital sign monitoring during Kangaroo
Mother Care (KMC). Our power-optimized device achieves 6-6.5 days of continuous
operation on a single charge, while the mobile application implements an
offline-first architecture with efficient data synchronization. The optical
character recognition pipeline demonstrates promising accuracy (F1 scores
0.78-0.875) for automated vital sign extraction from existing NICU monitors.
Experimental validation shows the system's feasibility for deployment in
resource-constrained settings, though further optimization of heart rate and
temperature detection, along with the risk classification foundation model is
needed.

</details>


### [407] [Distributed Gossip-GAN for Low-overhead CSI Feedback Training in FDD mMIMO-OFDM Systems](https://arxiv.org/abs/2509.10490)
*Yuwen Cao,Guijun Liu,Tomoaki Ohtsuki,Howard H. Yang,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的基于Gossip-GAN的信道状态信息（CSI）反馈训练框架，以解决现有深度自编码器（DAE）方法在通信系统中的数据隐私、带宽开销和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有DAE方法在通信系统中存在数据隐私泄露、带宽开销大以及在移动场景下需要重新训练模型等问题。

Method: 提出一种新颖的基于Gossip-GAN的CSI反馈训练框架，利用每个用户收集的小量数据训练GAN模型，并采用全分布式gossip学习策略来避免模型过拟合并加速训练。

Result: 仿真结果表明，Gossip-GAN在CSI反馈精度上与中心化训练相当，解决了移动场景下的灾难性遗忘问题，并显著减少了上行带宽使用量，同时还具备固有的鲁棒性。

Conclusion: Gossip-GAN是一种低开销、保护隐私的CSI反馈训练框架，解决了现有方法的痛点，在移动通信场景下具有实际应用潜力。

Abstract: The deep autoencoder (DAE) framework has turned out to be efficient in
reducing the channel state information (CSI) feedback overhead in massive
multiple-input multipleoutput (mMIMO) systems. However, these DAE approaches
presented in prior works rely heavily on large-scale data collected through the
base station (BS) for model training, thus rendering excessive bandwidth usage
and data privacy issues, particularly for mMIMO systems. When considering
users' mobility and encountering new channel environments, the existing CSI
feedback models may often need to be retrained. Returning back to previous
environments, however, will make these models perform poorly and face the risk
of catastrophic forgetting. To solve the above challenging problems, we propose
a novel gossiping generative adversarial network (Gossip-GAN)-aided CSI
feedback training framework. Notably, Gossip-GAN enables the CSI feedback
training with low-overhead while preserving users' privacy. Specially, each
user collects a small amount of data to train a GAN model. Meanwhile, a fully
distributed gossip-learning strategy is exploited to avoid model overfitting,
and to accelerate the model training as well. Simulation results demonstrate
that Gossip-GAN can i) achieve a similar CSI feedback accuracy as centralized
training with real-world datasets, ii) address catastrophic forgetting
challenges in mobile scenarios, and iii) greatly reduce the uplink bandwidth
usage. Besides, our results show that the proposed approach possesses an
inherent robustness.

</details>


### [408] [FlowECG: Using Flow Matching to Create a More Efficient ECG Signal Generator](https://arxiv.org/abs/2509.10491)
*Vitalii Bondar,Serhii Semenov,Vira Babenko,Dmytro Holovniak*

Main category: eess.SP

TL;DR: FlowECG是一种基于流匹配的方法，通过使用普通微分方程求解器直接从噪声到数据分布进行学习，在显著减少采样步骤的同时，实现了与现有基于扩散的方法相当的合成心电图生成质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前基于扩散的心电图生成方法在采样时需要大量神经网络评估，导致计算瓶颈的问题，该研究提出了一种更有效的方法。

Method: FlowECG将基于扩散的SSSD-ECG架构中的迭代扩散过程替换为连续流动力学，利用流匹配通过求解常微分方程直接学习从噪声到数据分布的传输路径。

Result: 在PTB-XL数据集上，FlowECG在200次神经网络评估下达到了与SSSD-ECG相当的性能，并在三个评估指标上优于基线。关键结果表明，FlowECG在仅需10-25次评估的情况下，即可达到与需要200次评估的扩散方法相当的生成质量，将计算需求降低了一个数量级，同时保持了生理上逼真的12导联心电图特征。

Conclusion: FlowECG通过显著减少采样步骤，提高了合成心电图生成的效率，使其能够在对计算资源有限的临床环境中实现实际部署，满足实时生成或大规模合成数据创建的需求。

Abstract: Synthetic electrocardiogram generation serves medical AI applications
requiring privacy-preserving data sharing and training dataset augmentation.
Current diffusion-based methods achieve high generation quality but require
hundreds of neural network evaluations during sampling, creating computational
bottlenecks for clinical deployment. We propose FlowECG, a flow matching
approach that adapts the SSSD-ECG architecture by replacing the iterative
diffusion process with continuous flow dynamics. Flow matching learns direct
transport paths from noise to data distributions through ordinary differential
equation solving. We evaluate our method on the PTB-XL dataset using Dynamic
Time Warping, Wasserstein distance, Maximum Mean Discrepancy, and spectral
similarity metrics. FlowECG matches SSSD-ECG performance at 200 neural function
evaluations, outperforming the baseline on three metrics. The key finding shows
that FlowECG maintains generation quality with substantially fewer sampling
steps, achieving comparable results with 10-25 evaluations compared to 200 for
diffusion methods. This efficiency improvement reduces computational
requirements by an order of magnitude while preserving physiologically
realistic 12-lead ECG characteristics. The approach enables practical
deployment in resource-limited clinical settings where real-time generation or
large-scale synthetic data creation is needed.

</details>


### [409] [Uplink and Downlink Communications in Segmented Waveguide-Enabled Pinching-Antenna Systems (SWANs)](https://arxiv.org/abs/2509.10666)
*Chongjun Ouyang,Hao Jiang,Zhaolin Wang,Yuanwei Liu,Zhiguo Ding*

Main category: eess.SP

TL;DR: 提出了一种分段波导增强的捏合天线系统（SWAN），并提出了三种工作协议：分段选择（SS）、分段聚合（SA）和分段复用（SM）。该系统通过消除天线间的辐射效应，为上行链路提供了可行的信号模型，并提出了优化天线放置以最大化信噪比（SNR）的算法。结果表明，SWAN能有效减少路径损耗和波导传播损耗，并且在上下行链路中均优于传统系统。


<details>
  <summary>Details</summary>
Motivation: 传统的捏合天线系统（PASS）在长波导结构中存在天线间辐射效应，导致信号模型难以建立且性能受限。本研究旨在提出一种新型的SWAN系统，通过分段波导结构解决这一问题，并提出相应的优化算法和性能分析。

Method: 提出了一种分段波导增强的捏合天线系统（SWAN），并设计了三种工作协议：SS、SA和SM。推导了上行链路和下行链路的信号模型，提出了相应的PA放置算法以最大化SNR，并分析了三种协议下的SNR闭式表达式和扩展定律。

Result: SWAN系统通过分段波导结构有效消除了天线间的辐射效应。提出的PA放置算法能够最大化SNR。在三种协议中，SM协议性能最优，其次是SA和SS。与传统PASS相比，SWAN系统在上行和下行链路中均能获得更高的SNR。

Conclusion: SWAN系统通过分段波导结构和提出的三种协议，有效解决了传统PASS面临的天线间辐射效应问题，提升了通信性能。该系统在上下行链路中均表现出优于传统系统的SNR，其中SM协议性能最佳。

Abstract: A segmented waveguide-enabled pinching-antenna system (SWAN) is proposed, in
which a segmented waveguide composed of multiple short dielectric waveguide
segments is employed to radiate or receive signals through the pinching
antennas (PAs) deployed on each segment. Based on this architecture, three
practical operating protocols are proposed: segment selection (SS), segment
aggregation (SA), and segment multiplexing (SM). For uplink SWAN
communications, where one PA is activated per segment, the segmented structure
eliminates the inter-antenna radiation effect, i.e., signals captured by one PA
may re-radiate through other PAs along the same waveguide. This yields a
tractable and physically consistent uplink signal model for a multi-PA
pinching-antenna system (PASS), which has not been established for conventional
PASS using a single long waveguide. Building on this model, PA placement
algorithms are proposed to maximize the uplink signal-to-noise ratio (SNR).
Closed-form expressions for the received SNR under the three protocols are
derived, and the corresponding scaling laws with respect to the number of
segments are analyzed. It is proven that the segmented architecture reduces
both the average PA-to-user distance and the PA-to-feed distance, thereby
mitigating both large-scale path loss and in-waveguide propagation loss. These
results are extended to downlink SWAN communications, where multiple PAs are
activated per segment, and PA placement methods are proposed to maximize the
downlink received SNR under the three protocols. Numerical results demonstrate
that: \romannumeral1) among the three protocols, SM achieves the best
performance, followed by SA and then SS; and \romannumeral2) for all protocols,
the proposed SWAN achieves a higher SNR than conventional PASS with a single
long waveguide in both uplink and downlink scenarios.

</details>


### [410] [Quasi-Deterministic Modeling of Sub-THz Band Access Channels in Street Canyon Environments](https://arxiv.org/abs/2509.10752)
*Minseok Kim,Masato Yomoda,Minghe Mao,Nobuaki Kuno,Koshiro Kitao,Satoshi Suyama*

Main category: eess.SP

TL;DR: 本论文在154 GHz和300 GHz频率下，在室外街道峡谷环境中进行了双向信道测量，提出了一个结合确定性传播和随机传播的准确定道（QD）模型，并评估了其大尺度参数，为未来6G系统提供了宝贵的传播见解。


<details>
  <summary>Details</summary>
Motivation: 由于亚太赫兹（sub-THz）频率（100-300 GHz）在6G移动通信中至关重要，但其传播特性与100 GHz以下不同，需要新的信道模型。

Method: 在室外街道峡谷环境，在154 GHz和300 GHz下，利用自研信道探测器，在视距（LoS）和非视距（NLoS）条件下进行信道测量。通过合并两个频率的数据进行聚类分析，识别出共同和特有的多径簇，并分析其频率依赖性。提出了一种结合确定性（LoS和单次反射）与随机成分的准确定道（QD）模型，并评估了大尺度参数（路径损耗、时延扩展、角度扩展和Rician K因子）。

Result: 识别出共同和特有的多径簇，并分析了其频率依赖性。评估了大尺度参数（路径损耗、时延扩展、角度扩展和Rician K因子）。

Conclusion: 提出的准确定道（QD）模型为未来6G系统在城市街道峡谷环境中的亚THz传播提供了宝贵的见解，并有助于开发准确的信道模型。

Abstract: Sub-terahertz (sub-THz) frequencies (100--300 GHz) are expected to play a key
role in beyond-5G and 6G mobile networks. However, their quasi-optical
propagation characteristics require new channel models beyond sub-100 GHz
extrapolations. This paper presents an extensive double-directional (D-D)
channel measurement campaign conducted in an outdoor street-canyon environment
at 154 GHz and 300 GHz under both line-of-sight (LoS) and non-line-of-sight
(NLoS) conditions using an in-house-developed channel sounder. Based on these
measurements, clustering with merged datasets across the two frequencies
enables comparative analyses that identify both common and distinct multipath
clusters, as well as the frequency dependence of cluster-level characteristics.
A quasi-deterministic (QD) channel model is then proposed, combining
deterministic components, such as LoS and single-bounce reflections from side
walls, with random components. Large-scale parameters (path loss, delay spread,
angular spread, and Rician K-factor) are also evaluated. These results provide
valuable insights into sub-THz propagation in urban street canyons and
contribute toward the development of accurate, channel models for future 6G
systems.

</details>


### [411] [Hybrid Atomic Norm Sparse/Diffuse Channel Estimation](https://arxiv.org/abs/2509.10770)
*Lei Lyu,Urbashi Mitra*

Main category: eess.SP

TL;DR: 提出了一种新的混合稀疏/扩散（HSD）信道模型，并设计了混合原子-最小二乘（HALS）算法来估计信道分量，同时进行了理论分析和性能界限推导。


<details>
  <summary>Details</summary>
Motivation: 在信道建模中，特别是在频率域，需要一种能够同时处理稀疏和扩散分量的方法，以提高信道估计的准确性。

Method: 提出混合稀疏/扩散（HSD）信道模型，设计了混合原子-最小二乘（HALS）算法，结合了原子和l2正则化来估计稀疏/扩散分量。对Lagrange对偶问题进行了理论分析，并导出了最佳频率支持估计和信道估计的去偏方法。基于不同的侧信息量，推导了性能界限。

Result: 通过在合成数据和真实实验数据上的仿真，验证了所提出方法的有效性。结果表明，在稀疏路径的稀疏性和扩散分量的相对能量方面，存在清晰的性能权衡。

Conclusion: 所提出的HSD信道模型和HALS算法能够有效地估计频率域信道中的稀疏和扩散分量，并且通过理论分析和仿真结果得到了验证。性能会受到信道特性的影响，如镜面路径的稀疏性和扩散分量的相对能量。

Abstract: In this paper, the hybrid sparse/diffuse (HSD) channel model in frequency
domain is proposed. Based on the structural analysis on the resolvable paths
and diffuse scattering statistics in the channel, the Hybrid
Atomic-Least-Squares (HALS) algorithm is designed to estimate sparse/diffuse
components with a combined atomic and l2 regularization. A theoretical analysis
is conducted on the Lagrangian dual problem and the conditions needed to be
satisfied by primal and dual solutions are provided. This analysis, in turn,
suggests an algorithm for optimal frequency support estimation. Debiased
methods for improved channel estimation are provided. Given differing amounts
of side information, performance bounds are derived in terms of a genie-aided
estimator and constrained Cramer-Rao lower bounds (CRLB). Numerical results via
simulations on synthetic data as well as real experimental data validate the
efficacy of the proposed method. There are clear tradeoffs with respect to the
properties of the channel with respect to performance: sparsity of specular
paths and relative energy of diffuse components.

</details>


### [412] [Self-Calibrating Integrate-and-Fire Time Encoding Machine](https://arxiv.org/abs/2509.10831)
*Maya Mekel,Vered Karp,Satish Mulleti,Alejandro Cohen*

Main category: eess.SP

TL;DR: 该研究提出了一种新型自校准脉冲积分发放时间编码机（S-IF-TEM），能够同时估计参数和重建信号，有效减少失配误差。该框架基于新的实际IF-TEM（P-IF-TEM）设置，考虑了设备失配和不完善性，解决了传统模型在参数未知、放电时间可变以及采样器非线性区域工作等问题。研究推导了采样率边界和重建条件，证明了在自校准下可以完美重建信号，并在评估中展示了超过59dB的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的脉冲积分发放时间编码机（IF-TEM）模型未能充分考虑设备失配和不完善性，可能导致信号重建误差。因此，需要一个能够处理参数未知、放电时间变化以及采样器非线性等实际情况的模型。

Method: 提出了一种新型自校准脉冲积分发放时间编码机（S-IF-TEM），并基于新的实际IF-TEM（P-IF-TEM）设置进行开发。该设置考虑了系统参数未知或随时间变化、积分器放电时间可变以及采样器可能在非线性区域工作等实际因素。研究推导了采样率边界和重建条件，以确保完美恢复。

Result: 通过分析和评估研究，在自校准下实现了完美重建信号的条件。评估结果显示，与现有方法相比，性能有显著提升，超过59dB。

Conclusion: 所提出的S-IF-TEM和P-IF-TEM框架能够有效处理实际应用中的设备失配和不完善性，通过自校准实现信号的精确重建，并在性能上取得了显著的改进。

Abstract: In this paper, we introduce a novel self-calibrating integrate-and-fire time
encoding machine (S-IF-TEM) that enables simultaneous parameter estimation and
signal reconstruction during sampling, thereby effectively mitigating mismatch
effects. The proposed framework is developed over a new practical IF-TEM
(P-IF-TEM) setting, which extends classical models by incorporating device
mismatches and imperfections that can otherwise lead to significant
reconstruction errors. Unlike existing IF-TEM settings, P-IF-TEM accounts for
scenarios where (i) system parameters are inaccurately known and may vary over
time, (ii) the integrator discharge time after firings can vary, and (iii) the
sampler may operate in its nonlinear region under large input dynamic ranges.
For this practical model, we derive sampling rate bounds and reconstruction
conditions that ensure perfect recovery. Analytical results establish the
conditions for perfect reconstruction under self-calibration, and evaluation
studies demonstrate substantial improvements - exceeding 59dB - highlighting
the effectiveness of the proposed approach.

</details>


### [413] [Landscape Analysis of Simultaneous Blind Deconvolution and Phase Retrieval via Structured Low-Rank Tensor Recovery](https://arxiv.org/abs/2509.10834)
*Xiao Liang,Zhen Qin,Zhihui Zhu,Shuang Li*

Main category: eess.SP

TL;DR: 该研究提出了一种基于结构化低秩张量恢复的框架，用于解决盲反卷积和相位恢复（BDPR）问题，并通过分析替代的张量感知问题的优化几何结构，为BDPR问题提供了理论指导。


<details>
  <summary>Details</summary>
Motivation: 由于盲反卷积和相位恢复（BDPR）问题的优化景观复杂且难以直接分析，需要引入一个可行的替代模型。

Method: 引入张量感知问题作为BDPR问题的替代模型，分析其在单位球上的全局优化景观，并证明了黎曼梯度下降（RGD）在温和条件下的线性收敛性。进一步扩展到张量感知问题，建立局部几何特性，保证RGD的收敛性，并量化测量噪声下的鲁棒性。

Result: 成功表征了替代张量感知问题的全局和局部几何特性，证明了RGD的收敛性和鲁棒性，并通过数值实验验证了理论结果。

Conclusion: 该研究为结构化低秩张量恢复问题（等价于BDPR问题）的优化景观提供了基础性见解，为解决原始BDPR问题提供了原则性指导。

Abstract: This paper presents a geometric analysis of the simultaneous blind
deconvolution and phase retrieval (BDPR) problem via a structured low-rank
tensor recovery framework. Due to the highly complicated structure of the
associated sensing tensor, directly characterizing its optimization landscape
is intractable. To address this, we introduce a tensor sensing problem as a
tractable surrogate that preserves the essential structural features of the
target low-rank tensor while enabling rigorous theoretical analysis. As a first
step toward understanding this surrogate model, we study the corresponding
population risk, which captures key aspects of the underlying low-rank tensor
structure. We characterize the global landscape of the population risk on the
unit sphere and show that Riemannian gradient descent (RGD) converges linearly
under mild conditions. We then extend the analysis to the tensor sensing
problem, establishing local geometric properties, proving convergence
guarantees for RGD, and quantifying robustness under measurement noise. Our
theoretical results are further supported by extensive numerical experiments.
These findings offer foundational insights into the optimization landscape of
the structured low-rank tensor recovery problem, which equivalently
characterizes the original BDPR problem, thereby providing principled guidance
for solving the original BDPR problem.

</details>


### [414] [Online simplex-structured matrix factorization](https://arxiv.org/abs/2509.10857)
*Hugues Kouakou,José Henrique de Morais Goulart,Raffaele Vitale,Thomas Oberlin,David Rousseau,Cyril Ruckebusch,Nicolas Dobigeon*

Main category: eess.SP

TL;DR: 该论文提出了一种在线的最小体积约束非混合（MVCU）算法，通过仅在必要时更新解决方案来处理海量数据，在保证精度的情况下显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的最小体积约束非混合（MVCU）算法在处理大规模在线数据时存在内存和计算瓶颈，难以满足实时性要求。

Method: 提出一种在线MVCU算法，通过设计一种在线检查机制，仅在满足特定条件时才更新MVCU的解，从而只存储和处理对SSMF几何约束有意义的信息。

Result: 与离线MVCU方法相比，该在线方法在合成和真实数据集上实现了相当的估计精度，同时显著降低了计算成本。

Conclusion: 所提出的方法能够有效扩展MVCU算法到在线场景，显著提高了计算效率，同时保持了良好的估计精度。

Abstract: Simplex-structured matrix factorization (SSMF) is a common task encountered
in signal processing and machine learning. Minimum-volume constrained unmixing
(MVCU) algorithms are among the most widely used methods to perform this task.
While MVCU algorithms generally perform well in an offline setting, their
direct application to online scenarios suffers from scalability limitations due
to memory and computational demands. To overcome these limitations, this paper
proposes an approach which can build upon any off-the-shelf MVCU algorithm to
operate sequentially, i.e., to handle one observation at a time. The key idea
of the proposed method consists in updating the solution of MVCU only when
necessary, guided by an online check of the corresponding optimization problem
constraints. It only stores and processes observations identified as
informative with respect to the geometrical constraints underlying SSMF. We
demonstrate the effectiveness of the approach when analyzing synthetic and real
datasets, showing that it achieves estimation accuracy comparable to the
offline MVCU method upon which it relies, while significantly reducing the
computational cost.

</details>


### [415] [On the Impact of Downstream Tasks on Sampling and Reconstructing Noisy Graph Signals](https://arxiv.org/abs/2509.10874)
*Baskaran Sripathmanathan,Xiaowen Dong,Michael Bronstein*

Main category: eess.SP

TL;DR: 图信号重建和分类任务的采样选择


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决图信号重建和分类任务中的采样选择问题。

Method: 提出了适用于多种常用重建方法的分类误差的理论表征，并与经典重建误差进行了比较。利用这些结果推导了新的最优采样方法，并将其应用于线性图卷积网络。

Result: 推导了新的最优采样方法，并展示了其在图信号处理方面的优势。

Conclusion: 提出的方法在图信号重建和分类任务中，特别是在线性图卷积网络的应用中，优于其他图信号处理方法。

Abstract: We investigate graph signal reconstruction and sample selection for
classification tasks. We present general theoretical characterisations of
classification error applicable to multiple commonly used reconstruction
methods, and compare that to the classical reconstruction error. We demonstrate
the applicability of our results by using them to derive new optimal sampling
methods for linearized graph convolutional networks, and show improvement over
other graph signal processing based methods.

</details>


### [416] [Forecasting Self-Similar User Traffic Demand Using Transformers in LEO Satellite Networks](https://arxiv.org/abs/2509.10917)
*Yekta Demirci,Guillaume Mantelet,Stéphane Martel,Jean-François Frigon,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 提出一种基于Transformer的模型来预测未来下一代LBO卫星网络中的用户流量需求。


<details>
  <summary>Details</summary>
Motivation: 为了在下一代LBO卫星网络中实现高精度动态波束跳跃，需要预测在轨卫星的用户流量需求。FARIMA模型被认为是基准，但其对板载处理能力的限制以及需要为每个输入序列拟合新模型的需求，促使人们探索替代方案。

Method: 采用基于Transformer的预训练概率时间序列模型，并使用Prob-Sparse自注意力机制。

Result: 在不同的时间粒度和序列/预测长度下进行了研究，结果显示基于Transformer的解决方案在特定流量条件下，使用均方误差作为性能指标，预测精度提高了6%。

Conclusion: 所提出的基于Transformer的解决方案在预测下一代LBO卫星网络的用户流量需求方面，相比传统方法具有更高的精度和效率。

Abstract: In this paper, we propose the use of a transformer-based model to address the
need for forecasting user traffic demand in the next generation Low Earth Orbit
(LEO) satellite networks. Considering a LEO satellite constellation, we present
the need to forecast the demand for the satellites in-orbit to utilize dynamic
beam-hopping in high granularity. We adopt a traffic dataset with second-order
self-similar characteristics. Given this traffic dataset, the Fractional
Auto-regressive Integrated Moving Average (FARIMA) model is considered a
benchmark forecasting solution. However, the constrained on-board processing
capabilities of LEO satellites, combined with the need to fit a new model for
each input sequence due to the nature of FARIMA, motivate the investigation of
alternative solutions. As an alternative, a pretrained probabilistic time
series model that utilizes transformers with a Prob-Sparse self-attention
mechanism is considered. The considered solution is investigated under
different time granularities with varying sequence and prediction lengths.
Concluding this paper, we provide extensive simulation results where the
transformer-based solution achieved up to six percent better forecasting
accuracy on certain traffic conditions using mean squared error as the
performance indicator.

</details>


### [417] [Design and Validation of a MATLAB-based GUI for Coarray Domain Analysis of Sparse Linear Arrays](https://arxiv.org/abs/2509.10926)
*Ashish Patwari,Ananya Pandey,Aditya Dabade,Priyadarshini Raiguru*

Main category: eess.SP

TL;DR: 本论文介绍了一款基于MATLAB App Designer的稀疏线性阵列（SLA）仿真器，用于差分协相关（DCA）域的分析。


<details>
  <summary>Details</summary>
Motivation: 稀疏传感器阵列在无线通信、雷达、声纳和集成传感系统等领域提供了增强信号检测、到达角（DOA）估计和波束成形的能力，优于传统均匀阵列，可降低系统复杂度、部署成本并减少互耦效应。因此，开发一个用于SLA在DCA域的分析工具具有重要意义。

Method: 利用MATLAB App Designer开发了一个图形用户界面（GUI）仿真器，用户可以输入阵列配置，计算DCA，可视化权重函数图，并评估阵列的无空洞状态。

Result: 通过数值验证，证明了该仿真器的正确性和有效性，能够从协相关域的角度分析SLA的行为，不同于仅关注辐射方向图的传统仿真器。

Conclusion: 该仿真器不仅在技术上验证了SLA在DCA域分析的可行性，还能作为教学工具，帮助理解复杂概念，吸引新一代人才投入稀疏阵列设计领域。

Abstract: This work presents a first-of-its-kind graphical user interface (GUI)-based
simulator developed using MATLAB App designer for the comprehensive analysis of
sparse linear arrays (SLAs) in the difference coarray (DCA) domain. Sparse
sensor arrays have emerged as a critical solution in enhancing signal
detection, direction of arrival (DOA) estimation, and beamforming in fields
such as wireless communication, radar, sonar, and integrated sensing systems.
They offer several advantages over traditional uniform arrays, including
reduced system complexity, lower deployment costs, and improved mitigation of
mutual coupling effects. The tool enables users to input array configurations,
compute DCAs, visualize weight function graphs, and assess the hole-free status
of arrays, as applicable for coarray processing. Unlike conventional simulators
that focus on radiation pattern visualization (array pattern, main lobe and
sidelobe characteristics, azimuth cut, rectangular view, polar view etc.), this
tool addresses the behavior of SLAs from a coarray domain perspective.
Numerical validations demonstrate the tool's correctness, effectiveness, and
its potential to foster further research in sparse arrays. This simulator could
also be used as a teaching aid to drive home complicated topics and attract
young minds towards the fascinating field of sparse array design.

</details>


### [418] [Experimental Demonstration of Rate-Adaptation via Hybrid Polar-BCH Product Code for Flexible PON](https://arxiv.org/abs/2509.11081)
*Yifan Ye,Bin Chen,Xiang Li,Yi Lei,Zhiwei Liang,Qingqing Hu,Can Zhao,Yanni Ou*

Main category: eess.SP

TL;DR: Polar-BCH码在相干无源光网络中实现


<details>
  <summary>Details</summary>
Motivation: 首次在相干无源光网络系统和16QAM下实验性地演示了灵活率Polar-BCH码。

Method: 使用新的混合软硬判决译码器。

Result: 在48公里传输后，与传统的BCH-BCH码相比，实现了高达1.75 dB的功率增益。

Conclusion: 灵活率Polar-BCH码在相干无源光网络系统中具有优越的性能。

Abstract: The flexible-rate Polar-BCH product codes are experimentally demonstrated in
a coherent passive optical network system with 16QAM for the first time. Using
a new hybrid soft- and hard-decision decoder, we achieve a power gain of upto
1.75 dB over traditional BCH-BCH product codes after 48 km transmission.

</details>


### [419] [Nonreciprocal RIS-Aided Covert Channel Reciprocity Attacks and Countermeasures](https://arxiv.org/abs/2509.11117)
*Haoyu Wang,Jiawei Hu,Jiaqi Xu,Ying Ju,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: RIS技术虽能增强无线通信，但也引入了新的安全漏洞。本文研究了在时分双工模式下，使用非互易RIS（NR-RIS）模型的多天线无线系统中信道互易性攻击（CRACK）的威胁。CRACK可通过扭曲下行链路预编码来降低通信速率并促进被动窃听，无需额外信号传输或信道状态信息（CSI）。与传统RIS干扰策略不同，NR-RIS无需与合法系统同步，可使用慢速或固定配置实现CRACK，模糊了直连信道和RIS诱导信道的区别，增加了防御预编码设计的复杂性。为应对NR-RIS带来的CRACK威胁，本文提出了一种基于深度强化学习的框架“SecureCoder”，该框架可缓解CRACK，并利用估计的上行链路CSI和用户的速率反馈来确定改进的下行链路预编码矩阵。仿真结果表明，NR-RIS CRACK会导致严重的性能下降，并验证了SecureCoder在提高吞吐量和降低安全威胁、增强系统鲁棒性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: RIS技术在增强无线通信的同时引入了新的安全漏洞，特别是CRACK威胁，可能降低通信速率并促进被动窃听。需要研究并提出应对NR-RIS设备可能带来的CRACK威胁的解决方案。

Method: 提出了一种基于深度强化学习的框架“SecureCoder”，利用估计的上行链路CSI和用户的速率反馈来确定改进的下行链路预编码矩阵，以缓解CRACK威胁。

Result: 仿真结果表明，NR-RIS CRACK会导致严重的性能下降，而SecureCoder能有效提高吞吐量并降低安全威胁，增强系统鲁棒性。

Conclusion: NR-RIS可能带来的CRACK威胁对无线通信系统构成严重安全挑战，但所提出的基于深度强化学习的SecureCoder框架能够有效缓解这些威胁，提升系统性能和安全性。

Abstract: Reconfigurable intelligent surface (RIS) technology enhances wireless
communication performance, but it also introduces new vulnerabilities that can
be exploited by adversaries. This paper investigates channel reciprocity attack
(CRACK) threats in multi-antenna wireless systems operating in time-division
duplexing mode using a physically consistent non-reciprocal RIS (NR-RIS) model.
CRACK can degrade communication rate and facilitate passive eavesdropping
behavior by distorting the downlink precoding, without requiring any additional
signal transmission or channel state information (CSI). Unlike conventional RIS
jamming strategies, the NR-RIS does not need synchronization with the
legitimate system and thus can operate with slow or fixed configurations to
implement CRACK, obscuring the distinction between the direct and RIS-induced
channels and thereby complicating corresponding defensive precoding designs. To
counter the CRACK threat posed by NR-RIS, we develop ``SecureCoder,'' a deep
reinforcement learning-based framework that can mitigate CRACK and determine an
improved downlink precoder matrix using the estimated uplink CSI and rate
feedback from the users. Simulation results demonstrate the severe performance
degradation caused by NR-RIS CRACK and validate the effectiveness of
SecureCoder in improving both throughput and reducing security threats, thereby
enhancing system robustness.

</details>


### [420] [Holographic interference surface: A proof of concept based on the principle of interferometry](https://arxiv.org/abs/2509.11193)
*Haifan Yin,Jindiao Huang,Ruikun Zhang,Jiwang Wu,Li Tan*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Revolutionizing communication architectures to achieve a balance between
enhanced performance and improved efficiency is becoming increasingly critical
for wireless communications as the era of ultra-large-scale arrays approaches.
In traditional communication architectures, radio frequency (RF) signals are
typically converted to baseband for subsequent processing through operations
such as filtering, analog-to-digital conversion and down-conversion, all of
which depend on expensive and power-intensive RF chains. The increased hardware
complexity and escalated power consumption resulting from this dependency
significantly limit the practical deployment of ultra-large-scale arrays. To
address these limitations, we propose a holographic communication system based
on the principle of interferometry, designated as holographic interference
surfaces (HIS). Utilizing the interference effect of electromagnetic waves, HIS
estimates the channel state information (CSI) by dealing solely with power
information, which enables the replacement of RF chains with power sensors and
completes the signal processing in radio frequency. As proof-of-concept
demonstrations, we implemented a prototype system based on principles of
holographic interference. Experimental results align well with theoretical
predictions, confirming the practical viability and effectiveness of the
proposed HIS. This work provides a new paradigm for building a more
cost-effective wireless communication architecture.

</details>


### [421] [Synesthesia of Machines (SoM)-Empowered Wireless Image Transmission over Complex Dynamic Channel](https://arxiv.org/abs/2509.11243)
*Haozhen Li,Ruide Zhang,Rongqing Zhang,Xiang Cheng*

Main category: eess.SP

TL;DR: 提出了一种名为“感官融合动态信道自适应传输”（DCAT）的无线图像传输方案，该方案利用Swin Transformer和物理层通信特性，有效解决了现有深度学习联合信源信道编码（JSCC）方案未考虑无线信道复杂动态性的问题，在时变衰落和信道老化方面表现出鲁棒的适应性，实验结果优于JSCC基线方法，且具有良好的可扩展性和成本效益，适合实际应用部署。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习的联合信源信道编码（JSCC）方案在无线图像传输中虽然有效，但往往将通信系统过于简化，未能充分考虑无线信道复杂动态性（如时变衰落和信道老化）以及物理层传输过程的细节。本研究旨在解决这一局限性，提出一个更符合实际通信场景的图像传输方案。

Method: 提出了一种名为“感官融合动态信道自适应传输”（DCAT）的方案。该方案基于Swin Transformer骨干网络，并利用了无线信道的物理层传输特性。DCAT能够有效地适应时变衰落和信道老化效应，实现动态信道自适应传输。

Result: 通过全面的实验结果证实，DCAT方案在所有条件下始终优于JSCC基线方法。此外，所提出的神经网络架构因其可解释的设计而表现出高可扩展性。

Conclusion: DCAT方案在实际通信场景中实现了优于现有JSCC基线方法的无线图像传输性能，尤其在应对时变衰落和信道老化方面表现出色。其高可扩展性和可解释性设计为实际应用中的成本效益部署提供了巨大潜力。

Abstract: Wireless image transmission underpins diverse networked intelligent services
and becomes an increasingly critical issue. Existing works have shown that deep
learning-based joint source-channel coding (JSCC) is an effective framework to
balance image transmission fidelity and data overhead. However, these studies
oversimplify the communication system as a mere pipeline with noise, failing to
account for the complex dynamics of wireless channels and concrete
physical-layer transmission process. To address these limitations, we propose a
Synesthesia of Machines (SoM)-empowered Dynamic Channel Adaptive Transmission
(DCAT) scheme, designed for practical implementation in real communication
scenarios. Building upon the Swin Transformer backbone, our DCAT scheme
demonstrates robust adaptability to time-selective fading and channel aging
effects by effectively utilizing the physical-layer transmission
characteristics of wireless channels. Comprehensive experimental results
confirm that DCAT consistently achieves superior performance compared with JSCC
baseline approaches across all conditions. Furthermore, our neural network
architecture demonstrates high scalability due to its interpretable design,
offering substantial potential for cost-efficient deployment in practical
applications.

</details>


### [422] [Resistor Hopping KLJN Noise Communication Using Small Bias Voltages Supported by ML and Optimum Threshold-Based Detectors](https://arxiv.org/abs/2509.11373)
*Hadi Zayyani,Felipe A. P. de Figueiredo,Mohammad Salman,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 本论文提出了一种带有偏置的电阻跳变（RH）方案，用于安全的基尔霍夫定律约翰逊噪声（KLJN）通信，以提高比特率并保持安全性。


<details>
  <summary>Details</summary>
Motivation: 为了提高KLJN通信的比特率，同时保持其固有的无条件安全。

Method: 提出了一种带有偏置的电阻跳变（RH）方案，并推导了最大似然（ML）检测器，研究了高斯分布的可分性条件，并提供了一个基于阈值的检测器。

Result: 仿真结果表明，与经典KLJN方案相比，所提出的RH-KLJN方案具有更高的数据速率和更低的比特错误概率，但复杂度有所增加。

Conclusion: 所提出的RH-KLJN方案在牺牲一定复杂度的情况下，提高了通信比特率和安全性。

Abstract: In this paper, a Resistor Hopping (RH) scheme with the addition of biases is
proposed for secure Kirchhoff Law Johnson-Noise (KLJN) communication. The RH
approach enables us to increase the bit rate of secure communication between
Alice and Bob, while also ensuring that the inherent unconditional security of
KLJN is satisfied. The biases are added to the proposed scheme to better
distinguish between Gaussian distributed noises in terms of their means, rather
than just using variances. Throughout the paper, we strive to minimize biases
to achieve a power-efficient scheme. For the detection part of the proposed
algorithm, a Maximum-Likelihood (ML) detector is derived. The separability
condition of Gaussian distributions is investigated, along with the provision
of a threshold-based detector that offers both simple and optimal thresholds in
terms of minimizing the error probability. Some analysis of the proposed
RH-KLJN communication scheme is provided, including Physical Layer Security
(PLS) equations. Simulation results demonstrate the advantages of the proposed
scheme over the classical KLJN scheme, offering a higher data rate and lower
bit error probability at the expense of increased complexity.

</details>


### [423] [A Generalized Framework for Quadratic Noise Modulation Using Non-Gaussian Distributions](https://arxiv.org/abs/2509.11378)
*Hadi Zayyani,Mohammad Salman,Felipe A. P. de Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 该研究提出了一种广义二次噪声调制（GQNM）方法，通过引入电压偏置和使用非高斯噪声（如 MoG 和拉普拉斯噪声），在噪声符号的均值和方差上实现双重信道，将数据速率提高一倍。


<details>
  <summary>Details</summary>
Motivation: 为了提高通信系统的性能，尤其是在低功耗和安全通信场景下，探索比传统高斯噪声更优越的噪声调制方法。

Method: 提出了一种广义二次噪声调制（GQNM）框架，该框架能够处理非高斯噪声分布（如 MoG 和拉普拉斯噪声），并通过引入两个电压偏置，实现在噪声符号的均值和方差上的双重信道，从而提高数据速率。推导了广义高斯（GG）和高斯混合模型（GMoTG）噪声情况下的误比特概率（BEP）的闭式表达式。

Result: 仿真结果表明，GQNM 在非高斯噪声下具有显著优势，能够有效提高通信性能。

Conclusion: GQNM 是一种有效的数据速率提升技术，特别是在非高斯噪声环境下，为低功耗和安全通信系统提供了增强的性能潜力。

Abstract: This letter generalizes noise modulation by introducing two voltage biases
and employing non-Gaussian noise distributions, such as Mixture of Gaussian
(MoG) and Laplacian, in addition to traditional Gaussian noise. The proposed
framework doubles the data rate by enabling discrimination in both the mean and
variance of transmitted noise symbols. This novel modulation scheme is referred
to as Generalized Quadratic Noise Modulation (GQNM). Closed-form expressions
for the Bit Error Probability (BEP) are derived for the Generalized Gaussian
(GG) and Gaussian Mixture of Two Gaussians (GMoTG) cases. Simulation results
demonstrate the advantages of the generalized modulation scheme, particularly
under non-Gaussian noise assumptions, highlighting its potential for enhanced
performance in low-power and secure communication systems.

</details>


### [424] [Solving ill-conditioned polynomial equations using score-based priors with application to multi-target detection](https://arxiv.org/abs/2509.11397)
*Rafi Beinhorn,Shay Kreymer,Amnon Balanov,Michael Cohen,Alon Zabatani,Tamir Bendory*

Main category: eess.SP

TL;DR: score-based diffusion priors结合moment-based estimators来解决非线性逆问题，特别是在高噪声情况下，可以稳定地从低阶矩中恢复信号，并使原本不适定的超分辨率多目标检测问题变得可行。


<details>
  <summary>Details</summary>
Motivation: 从低阶矩恢复信号是一个基本但困难的逆问题，通常需要求解病态的多项式方程组。

Method: 提出一个结合score-based diffusion priors与moment-based estimators的框架，以规范化和解决非线性逆问题。

Result: 1. diffusion priors显著提高了从三阶矩恢复信号的能力。 2. diffusion priors使原本不适定的超分辨率多目标检测问题成为可能。在MNIST数据集上的数值实验证实了在不同信噪比水平下重建精度的持续提高。

Conclusion: 结合生成模型先验与非线性多项式逆问题是一个有前景的新方向。

Abstract: Recovering signals from low-order moments is a fundamental yet notoriously
difficult task in inverse problems. This recovery process often reduces to
solving ill-conditioned systems of polynomial equations. In this work, we
propose a new framework that integrates score-based diffusion priors with
moment-based estimators to regularize and solve these nonlinear inverse
problems. This introduces a new role for generative models: stabilizing
polynomial recovery from noisy statistical features. As a concrete application,
we study the multi-target detection (MTD) model in the high-noise regime. We
demonstrate two main results: (i) diffusion priors substantially improve
recovery from third-order moments, and (ii) they make the super-resolution MTD
problem, otherwise ill-posed, feasible. Numerical experiments on MNIST data
confirm consistent gains in reconstruction accuracy across SNR levels. Our
results suggest a promising new direction for combining generative priors with
nonlinear polynomial inverse problems.

</details>


### [425] [Knowledge Distillation for Sensing-Assisted Long-Term Beam Tracking in mmWave Communications](https://arxiv.org/abs/2509.11419)
*Mengyuan Ma,Nhan Thanh Nguyen,Nir Shlezinger,Yonina C. Eldar,A. Lee Swindlehurst,Markku Juntti*

Main category: eess.SP

TL;DR: 本论文提出了一种高效的传感辅助长期波束跟踪框架，利用注意力增强的神经网络来预测未来多个时隙的毫米波波束，并通过知识蒸馏训练了一个轻量级学生网络，在显著降低复杂度的同时保持了高性能。


<details>
  <summary>Details</summary>
Motivation: 利用基础设施安装的传感器捕捉丰富的环境信息，以增强毫米波通信和波束成形。

Method: 设计了一个大型的注意力增强神经网络（NN）来利用过去的视觉观察进行波束跟踪。一个卷积神经网络提取图像特征，门控循环单元（GRU）结合注意力机制捕捉时间依赖性。然后，利用知识蒸馏，大型（教师）NN指导训练一个轻量级（学生）NN，该学生NN需要更短的输入序列但仍能保持长期波束预测能力。

Result: 教师NN在当前和未来六个时隙的Top-5准确率超过93%，复杂度降低了90%。学生NN在输入序列缩短60%的情况下，性能接近教师NN，复杂度进一步降低了90%。

Conclusion: 所提出的传感辅助长期波束跟踪框架能够显著提高数据效率、降低延迟和功耗。

Abstract: Infrastructure-mounted sensors can capture rich environmental information to
enhance communications and facilitate beamforming in millimeter-wave systems.
This work presents an efficient sensing-assisted long-term beam tracking
framework that selects optimal beams from a codebook for current and multiple
future time slots. We first design a large attention-enhanced neural network
(NN) to fully exploit past visual observations for beam tracking. A
convolutional NN extracts compact image features, while gated recurrent units
with attention capture the temporal dependencies within sequences. The large NN
then acts as the teacher to guide the training of a lightweight student NN via
knowledge distillation. The student requires shorter input sequences yet
preserves long-term beam prediction ability. Numerical results demonstrate that
the teacher achieves Top-5 accuracies exceeding 93% for current and six future
time slots, approaching state-of-the-art performance with a 90% complexity
reduction. The student closely matches the teacher's performance while cutting
complexity by another 90%, despite operating with 60% shorter input sequences.
This improvement significantly enhances data efficiency, reduces latency, and
lowers power consumption in sensing and processing.

</details>


### [426] [Dynamic Length FSK Waveforms for Joint Communications and Radar](https://arxiv.org/abs/2509.11500)
*Tian Han,Peter J Smith,Urbashi Mitra,Jamie S Evans,Robin Evans,Rajitha Senanayake*

Main category: eess.SP

TL;DR: 提出了一种基于FSK的动态子脉冲数量的联合通信和雷达波形设计。


<details>
  <summary>Details</summary>
Motivation: 受到FSK波形恒定包络和子脉冲数量增加时雷达性能稳定的启发。

Method: 文章提出了一种基于FSK的动态子脉冲数量的联合通信和雷达波形设计。通信方面，系统采用传统的FSK调制；传感方面，通过监测频谱平坦度动态形成雷达波形，以保证延迟估计的准确性。同时，利用波形长度约束来确保均方根时域持续时间、模糊函数旁瓣电平和防止波形过长。

Result: 通过数值例子评估了近似分布的准确性、模糊函数旁瓣电平和估计的延迟与多普勒频移性能。

Conclusion: 提出了一种新颖的联合通信和雷达波形设计方法，并验证了其性能。

Abstract: Motivated by the constant modulus property of frequency shift keying (FSK)
based waveforms and the stabilisation of its radar performance with an increase
in the number of subpulses, in this paper an FSK-based dynamic subpulse number
joint communications and radar waveform design is proposed. From a
communications point of view, the system operates based on traditional FSK
modulation. From a sensing point of view, although the subpulses are
continuously generated and transmitted, radar waveforms are dynamically formed
by monitoring the flatness of the spectrum which in turn guarantees the
accuracy of the delay estimation. Other constraints on the waveform length are
used to ensure satisfactory values of the root mean square time duration,
ambiguity function sidelobe levels and prevent overly long waveforms. To
provide an estimation of the probability of generating extremely long
waveforms, the distribution of the number of subpulses is approximated using a
Brownian motion process and an existing result on its one-sided exit density.
Numerical examples are provided to evaluate the accuracy of the approximate
distribution, as well as the ambiguity function sidelobe levels and the delay
and Doppler shift estimation performance of the transmitted waveforms.

</details>


### [427] [Radio Frequency Amplitude-Modulation to Frequency-Modulation Signal Converter](https://arxiv.org/abs/2509.11510)
*Rishab Parthasarathy,Michael Popik,Noah Haefner*

Main category: eess.SP

TL;DR: 开发了一种将调幅（AM）信号转换为调频（FM）信号的拓扑结构，该结构能在保持高保真音频的同时，将信号从AM广播频段（530 kHz至1700 kHz）解调并重新调制到FM广播频段（88 MHz至108 MHz）。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够有效地将调幅（AM）信号转换为调频（FM）信号的模拟拓扑结构，并确保转换后的信号仍在各自的射频（RF）频段内。

Method: 开发、表征和演示了一种有效的拓扑结构，该结构能够解调AM广播频段（530 kHz至1700 kHz）的输入信号，并将其重新调制到FM广播频段（88 MHz至108 MHz）。该拓扑结构的核心是一个AM解调电路和一个压控振荡器（VCO），通过压控振荡器将输入的包络信号变化转换为输出频率变化。

Result: 成功开发并演示了一个能够将AM信号转换为FM信号的拓扑结构，该结构能够保持高保真音频，并将信号从AM频段转换到FM频段。

Conclusion: 该项目不仅开发了一个工作的AM到FM信号转换系统，还为有效射频电路的设计、分析和构建提供了宝贵的经验，对于未来模拟电子领域的研究具有重要价值。

Abstract: In this project, we wanted to discover an analog topology that could
effectively convert amplitude-modulated (AM) signals to frequency-modulated
(FM) signals, while also ensuring that both sets of signals were within their
respective radio frequency (RF) bands. To that end, an effective topology for
doing so was developed, characterized, and demonstrated, requiring the ability
to de-modulate incoming signals from the AM radio band--spanning from 530 kHz
to 1700 kHz--and re-modulate these signals into the FM radio band--spanning
from 88 MHz to 108 MHz. These bands are separated by roughly 86 MHz, presenting
the need for the topology to radically alter the incoming frequency before
re-broadcasting. At its simplest implementation, this required an AM
demodulation circuit coupled to a voltage controlled oscillator (VCO).
Together, these two circuits translated variations in the incoming envelope
signal to variations in the output frequency while still maintaining
high-fidelity audio, similar to how existing radio receiving and broadcasting
are done. Altogether, the project not only developed a working system but also
provided valuable instruction in the design, analysis, and construction of
effective RF circuits--invaluable to future endeavors within analog
electronics.

</details>


### [428] [Cooperative UAV-mounted RISs-assisted Energy-efficient Communications](https://arxiv.org/abs/2509.11533)
*Hongyang Pan,Yanheng Liu,Geng Sun,Qingqing Wu,Tierui Gong,Pengfei Wang,Dusit Niyato,Chau Yuen*

Main category: eess.SP

TL;DR: Cooperative UAV-mounted RISs enhance 6G networks by jointly optimizing BS beamforming, UAV-RIS locations, and phase shifts to maximize user rates and minimize energy consumption. An enhanced NSGA-II (INSGA-II-CDC) is proposed to solve this NP-hard problem effectively.


<details>
  <summary>Details</summary>
Motivation: To support a large number of users in 6G networks and improve communication performance with reduced energy consumption by utilizing cooperative reconfigurable intelligent surfaces (RISs) mounted on unmanned aerial vehicles (UAVs).

Method: Formulated an energy-efficient communication problem (EEComm-MOF) using a multi-objective optimization framework to maximize the minimum and total user rates while minimizing total energy consumption. Proposed an enhanced non-dominated sorting genetic algorithm-II with continuous, discrete, and complex solution processing mechanisms (INSGA-II-CDC) to solve the NP-hard and non-convex problem.

Result: The proposed INSGA-II-CDC effectively solves the EEComm-MOF, outperforming other benchmarks across various parameter settings. The stability of the algorithm and the effectiveness of its improved mechanisms were verified.

Conclusion: The paper introduces a novel approach using cooperative UAV-RISs for 6G networks, addressing energy efficiency and performance through a multi-objective optimization problem. The developed INSGA-II-CDC algorithm provides an effective solution, demonstrating its implementability and superiority over existing methods.

Abstract: Cooperative reconfigurable intelligent surfaces (RISs) are promising
technologies for 6G networks to support a great number of users. Compared with
the fixed RISs, the properly deployed RISs may improve the communication
performance with less communication energy consumption, thereby improving the
energy efficiency. In this paper, we consider a cooperative unmanned aerial
vehicle-mounted RISs (UAV-RISs)-assisted cellular network, where multiple RISs
are carried and enhanced by UAVs to serve multiple ground users (GUs)
simultaneously such that achieving the three-dimensional (3D) mobility and
opportunistic deployment. Specifically, we formulate an energy-efficient
communication problem based on multi-objective optimization framework
(EEComm-MOF) to jointly consider the beamforming vector of base station (BS),
the location deployment and the discrete phase shifts of UAV-RIS system so as
to simultaneously maximize the minimum available rate over all GUs, maximize
the total available rate of all GUs, and minimize the total energy consumption
of the system, while the transmit power constraint of BS is considered. To
comprehensively solve EEComm-MOF which is an NP-hard and non-convex problem
with constraints, a non-dominated sorting genetic algorithm-II with a
continuous solution processing mechanism, a discrete solution processing
mechanism, and a complex solution processing mechanism (INSGA-II-CDC) is
proposed. Simulations results demonstrate that the proposed INSGA-II-CDC can
solve EEComm-MOF effectively and outperforms other benchmarks under different
parameter settings. Moreover, the stability of INSGA-II-CDC and the
effectiveness of the improved mechanisms are verified. Finally, the
implementability analysis of the algorithm is given.

</details>


### [429] [Simplified Design Approach for Via Transitions up to 67 GHz](https://arxiv.org/abs/2509.11542)
*Giorgi Tsintsadze,Reza Vahdani,James L. Drewniak,Richard Zai*

Main category: eess.SP

TL;DR: 本文提出了一种高速过孔设计方法，通过分析过孔半径、衬垫尺寸和相邻接地过孔距离对带宽的影响，并提供设计指南。该方法基于将过孔结构近似为同轴传输线，并考虑高阶模式，能帮助工程师优化设计参数，最高可设计67 GHz的高带宽过孔。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于高速过孔设计的系统性方法，以分析和表征过孔参数（如过孔桶半径、衬垫尺寸、相邻接地过孔间距）对带宽的影响。

Method: 在将过孔结构近似为同轴传输线的基础上，考虑高阶模式，并结合3D全波有限元法（FEM）仿真结果和实际测量数据，来分析和表征各种设计参数对带宽的影响。

Result: 建立了分析和表征高速过孔设计参数（过孔桶半径、衬垫尺寸、相邻接地过孔间距）对带宽影响的框架，并提供了设计指南，该指南通过3D FEM仿真和实际测量得到验证。

Conclusion: 所提出的方法能够帮助工程师优化设计参数，并直观理解几何结构如何影响带宽，即使在有限的3D FEM工具资源下，也能设计高达67 GHz的高带宽过孔。

Abstract: A systematic approach for high-speed via transition design is proposed. The
effects of via barrel radius, anti-pad size, and the distance from adjacent
stitching (GND) vias on bandwidth are analyzed and characterized. Guidelines
for selecting parameter values are provided and validated by correlating 3D
full-wave FEM simulation results with actual measurements of the coupon board.
When a sufficient number of stitching vias are used, the via structure can be
approximated as a coaxial transmission line. The proposed methodology builds on
this approximation and also considers high-order modes. With this framework,
engineers can easily optimize design parameters while intuitively understanding
how geometry affects bandwidth. This approach also allows engineers with
limited access to expensive and computationally intensive 3D FEM tools to
design high bandwidth vias up to 67 GHz.

</details>


### [430] [Stacked Intelligent Metasurface for End-to-End OFDM System](https://arxiv.org/abs/2509.11551)
*Yida Zhang,Qiuyan Liu,Hongtao Luo,Yuqi Xia,Qiang Wang*

Main category: eess.SP

TL;DR: 该论文提出了一种结合智能超表面（SIM/DPSIM）和电磁神经网络（EMNN）的端到端（E2E）正交频分复用（OFDM）系统，实现了在电磁信号传播过程中同时完成调制、预编码、合并和解调等通信任务，并通过迁移学习进行模型训练，旨在简化收发器设计并提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于SIM（DPSIM）的波形域信号处理方法仅能执行单一通信功能（如预编码或合并），限制了系统整体性能的提升和端到端联合优化。本研究旨在突破这一限制，实现从传输比特流到接收比特流的端到端联合优化。

Method: 提出了一种SIM（DPSIM）辅助的端到端OFDM系统，将调制、预编码、合并和解调等传统通信任务集成到电磁（EM）前向传播过程中。同时，受将真实超表面抽象为神经网络隐藏层的启发，提出了电磁神经网络（EMNN）来控制整个E2E OFDM通信系统，并引入迁移学习进行模型训练，设计了相应的训练和部署框架。

Result: 仿真结果表明，所提出的SIM辅助E2E OFDM系统和DPSIM辅助E2E OFDM系统在复杂的信道条件下均能实现可靠的比特流传输。

Conclusion: 研究证明了EMNN以及SIM（DPSIM）辅助的E2E OFDM系统在下一代收发器设计中的应用潜力。

Abstract: Stacked intelligent metasurface (SIM) and dual-polarized SIM (DPSIM) enabled
wave-domain signal processing have emerged as promising research directions for
offloading baseband digital processing tasks and efficiently simplifying
transceiver design. However, existing architectures are limited to employing
SIM (DPSIM) for a single communication function, such as precoding or
combining. To further enhance the overall performance of SIM (DPSIM)-assisted
systems and achieve end-to-end (E2E) joint optimization from the transmitted
bitstream to the received bitstream, we propose an SIM (DPSIM)- assisted E2E
orthogonal frequency-division multiplexing (OFDM) system, where traditional
communication tasks such as modulation, precoding, combining, and demodulation
are performed simultaneously during electromagnetic (EM) forward propagation.
Furthermore, inspired by the idea of abstracting real metasurfaces as hidden
layers of a neural network, we propose the electromagnetic neural network
(EMNN) to enable the control of the E2E OFDM communication system. In addition,
transfer learning is introduced into the model training, and a training and
deployment framework for the EMNN is designed. Simulation results demonstrate
that both SIM-assisted E2E OFDM systems and DPSIM-assisted E2E OFDM systems can
achieve robust bitstream transmission under complex channel conditions. Our
study highlights the application potential of EMNN and SIM (DPSIM)-assisted E2E
OFDM systems in the design of next-generation transceivers.

</details>


### [431] [RadioLAM: A Large AI Model for Fine-Grained 3D Radio Map Estimation](https://arxiv.org/abs/2509.11571)
*Zhiyuan Liu,Qingyu Liu,Shuhang Zhang,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 本论文设计了一个名为RadioLAM的大型人工智能模型（LAM），用于解决三维（3D）空间中超稀疏采样下的三维无线电地图估计问题，能够高效地从低至0.1%的采样率估计出高分辨率的无线电地图，并优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的低空经济中，尤其对于无人机而言，对三维空间进行精细化的三维无线电地图估计对于高效的频谱管理至关重要。然而，现有技术面临超稀疏采样（采样点远少于地图分辨率）的挑战。

Method: 本文设计了一个名为RadioLAM的大型人工智能模型（LAM），包含三个关键模块：1）数据增强模块，将不同高度的无线电样本投影到目标高度的二维区域；2）生成模块，利用混合专家（MoE）架构的大型人工智能模型生成候选精细化无线电地图集；3）选举模块，以无线电传播模型为指导，从候选集中选出最优地图。

Result: 通过大量仿真实验证明，RadioLAM能够有效解决三维无线电地图估计问题，即使在0.1%的超低采样率下也能实现，并且显著优于现有最先进的方法。

Conclusion: RadioLAM能够有效应对超稀疏采样挑战，高效地进行精细化三维无线电地图估计，为无人机等应用提供了强大的支持。

Abstract: A radio map captures the spatial distribution of wireless channel parameters,
such as the strength of the signal received, across a geographic area. The
problem of fine-grained three-dimensional (3D) radio map estimation involves
inferring a high-resolution radio map for the two-dimensional (2D) area at an
arbitrary target height within a 3D region of interest, using radio samples
collected by sensors sparsely distributed in that 3D region. Solutions to the
problem are crucial for efficient spectrum management in 3D spaces,
particularly for drones in the rapidly developing low-altitude economy.
However, this problem is challenging due to ultra-sparse sampling, where the
number of collected radio samples is far fewer than the desired resolution of
the radio map to be estimated. In this paper, we design a Large Artificial
Intelligence Model (LAM) called RadioLAM for the problem. RadioLAM employs the
creative power and the strong generalization capability of LAM to address the
ultra-sparse sampling challenge. It consists of three key blocks: 1) an
augmentation block, using the radio propagation model to project the radio
samples collected at different heights to the 2D area at the target height; 2)
a generation block, leveraging an LAM under an Mixture of Experts (MoE)
architecture to generate a candidate set of fine-grained radio maps for the
target 2D area; and 3) an election block, utilizing the radio propagation model
as a guide to find the best map from the candidate set. Extensive simulations
show that RadioLAM is able to solve the fine-grained 3D radio map estimation
problem efficiently from an ultra-low sampling rate of 0.1%, and significantly
outperforms the state-of-the-art.

</details>


### [432] [Low-Altitude Wireless Networks: A Survey](https://arxiv.org/abs/2509.11607)
*Jun Wu,Yaoqi Yang,Weijie Yuan,Wenchao Liu,Jiacheng Wang,Tianqi Mao,Lin Zhou,Yuanhao Cui,Fan Liu,Geng Sun,Nan Wu,Dezhi Zheng,Jindan Xu,Nan Ma,Zhiyong Feng,Wei Xu,Dusit Niyato,Chau Yuen,Xiaojun Jing,Zhiguo Shi,Yingchang Liang,Shi Jin,Dong In Kim,Jiangzhou Wang,Ping Zhang,Hao Yin,Jun Zhang*

Main category: eess.SP

TL;DR: 低空无线网络（LAWN）框架整合了通信、感知、计算、控制和空中交通管理，以应对低空经济的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统空中系统在支持大规模无人机部署和智能服务方面存在不足，迫切需要一个整合多种功能的综合性框架。

Method: 提出并概述了低空无线网络（LAWN）框架，该框架统一了通信、感知、计算、控制和空中交通管理。文章回顾了LAWN系统的基本原理、功能设计演进、性能评估指标、隐私安全问题以及空域结构和交通管理的前沿发展。

Result: LAWN框架旨在克服传统系统在满足多样化关键任务需求、解决动态干扰、覆盖不稳定和可扩展性方面的问题。

Conclusion: 文章全面概述了LAWN系统，并探讨了其面临的挑战和前沿发展，为LAWN的实际部署提供了见解。

Abstract: The rapid development of the low-altitude economy has imposed unprecedented
demands on wireless infrastructure to accommodate large-scale drone deployments
and facilitate intelligent services in dynamic airspace environments. However,
unlocking its full potential in practical applications presents significant
challenges. Traditional aerial systems predominantly focus on air-ground
communication services, often neglecting the integration of sensing,
computation, control, and energy-delivering functions, which hinders the
ability to meet diverse mission-critical demands. Besides, the absence of
systematic low-altitude airspace planning and management exacerbates issues
regarding dynamic interference in three-dimensional space, coverage
instability, and scalability. To overcome these challenges, a comprehensive
framework, termed low-altitude wireless network (LAWN), has emerged to
seamlessly integrate communication, sensing, computation, control, and air
traffic management into a unified design. This article provides a comprehensive
overview of LAWN systems, introducing LAWN system fundamentals and the
evolution of functional designs. Subsequently, we delve into performance
evaluation metrics and review critical concerns surrounding privacy and
security in the open-air network environment. Finally, we present the
cutting-edge developments in airspace structuring and air traffic management,
providing insights to facilitate the practical deployment of LAWNs.

</details>


### [433] [Attention-Enhanced Learning for Sensing-Assisted Long-Term Beam Tracking in mmWave Communications](https://arxiv.org/abs/2509.11725)
*Mengyuan Ma,Nhan Thanh Nguyen,Nir Shlezinger,Yonina C. Eldar,Markku Juntti*

Main category: eess.SP

TL;DR: 使用基于CNN和GRU的注意力增强模型，通过摄像头图像进行毫米波通信中的长期波束跟踪，在当前和未来6个时间槽中实现超过90%的Top-5预测精度，同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信中的波束训练和预测面临信道快速时变、易被遮挡以及移动性等挑战。利用基础设施摄像头捕捉的环境信息可以辅助波束跟踪设计。

Method: 提出一种基于卷积神经网络（CNN）和门控循环单元（GRU）的注意力增强机器学习模型，利用历史图像序列预测当前和未来的波束。

Result: 该模型在当前和未来六个时间槽的Top-5波束预测精度均超过90%，显著降低了波束训练的感知和处理开销。与现有技术相比，该模型达到了97%的性能水平，但计算复杂度仅为3%。

Conclusion: 所提出的注意力增强模型能够高效地进行长期波束跟踪，通过摄像头图像预测未来波束，并在精度和计算复杂度方面取得了显著的改进。

Abstract: Beam training and prediction in millimeter-wave communications are highly
challenging due to fast time-varying channels and sensitivity to blockages and
mobility. In this context, infrastructure-mounted cameras can capture rich
environmental information that can facilitate beam tracking design. In this
work, we develop an efficient attention-enhanced machine learning model for
long-term beam tracking built upon convolutional neural networks and gated
recurrent units to predict both current and future beams from past observed
images. The integrated temporal attention mechanism substantially improves its
predictive performance. Numerical results demonstrate that the proposed design
achieves Top-5 beam prediction accuracies exceeding 90% across both current and
six future time slots, significantly reducing overhead arising from sensing and
processing for beam training. It further attains 97% of state-of-the-art
performance with only 3% of the computational complexity.

</details>


### [434] [Multi-Stage Location Optimization Through Power Delay Profile Alignment Using Site-Specific Wireless Ray Tracing](https://arxiv.org/abs/2509.11923)
*Mingjun Ying,Peijie Ma,Dipankar Shakya,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: 该论文提出了一个系统性的多阶段发射/接收器（TX/RX）位置校准框架，以校正无线传播测量中的位置误差，从而实现测量与模拟的全向功率延迟剖面（PDP）的对齐。


<details>
  <summary>Details</summary>
Motivation: GPS定位的米级误差导致射线追踪（RT）模拟的无线传播特征化不准确，进而影响信道预测和校准的精确性。

Method: 采用计算高效的多阶段网格搜索和Powell方法进行优化，以校正TX/RX位置误差。

Result: 在纽约大学无线城市微蜂窝（UMi）6.75 GHz和16.95 GHz的测量中，该框架校正了高达7米的TX/RX位置误差，将视线（LOS）和非视线（NLOS）场景的复合损失函数分别降低了42.3%和13.5%，并将峰值功率预测精度平均提高了约1 dB。

Conclusion: 改进的几何对齐能够实现精确的信道预测，这对于下一代无线网络的波束管理和基础设施部署至关重要。

Abstract: Ray tracing (RT) simulations require accurate transmitter (TX) and receiver
(RX) location information from real-world measurements to accurately
characterize wireless propagation behavior in an environment. Such wireless
propagation measurements typically employ GPS-based logging for TX/RX
locations, which can produce meter-level errors that lead to unreliable RT
calibration and validation. These location misalignments cause inaccurate
interactions between RT-generated multipath components (MPCs) and the modeled
3D environment, which lead to erroneous channel predictions, and severe
discrepancies between simulated and measured power delay profiles (PDPs) and
channel characteristics. Moreover, the same RT-generated PDPs using inaccurate
locations result in calibration errors when adjusting material properties such
as conductivity and permittivity.
  This paper presents a systematic multi-stage TX/RX location calibration
framework to correct location errors and consequently align measured and
simulated omnidirectional PDPs.
  Optimization is performed using a computationally efficient multi-stage grid
search and the Powell method. Applying the location calibration framework to
NYU WIRELESS urban-microcell (UMi) measurements at 6.75 GHz and 16.95 GHz
corrected TX/RX location errors of up to 7 m. The framework reduced the
composite loss function by 42.3\% for line-of-sight (LOS) and 13.5\% for
non-line-of-sight (NLOS) scenarios. Furthermore, peak power prediction accuracy
improved by approximately 1 dB on average. Such improved geometric alignment
enables accurate channel prediction, vital for beam management and
infrastructure deployment for next-generation wireless networks.

</details>


### [435] [Optimized Sparse Network Coverage via L1-norm Minimization](https://arxiv.org/abs/2509.11994)
*Souvik Paul,Iván Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 该论文提出了一种选择网络节点（如簇头、局部汇聚点和网关）的框架，旨在以最低成本实现网络覆盖。


<details>
  <summary>Details</summary>
Motivation: 分布式传感器和通信网络中选择充当集群头、局部接收器和网关的节点是一个关键挑战。

Method: 该论文将节点选择问题构建为NP-hard集覆盖问题的凸松弛，并结合节点度和介数中心性等图论中心性度量来构建成本函数，通过放松的L1范数最小化进行优化。

Result: 与经典的贪婪算法和遗传算法（GA）相比，该方法在模拟中显示出更快的执行时间和更有竞争力的稀疏性，适用于静态和动态网络，并且不需要位置或距离估计。

Conclusion: 所提出的方法是一种稳健、分布式且具成本效益的节点选择解决方案，可确保网络覆盖并最大限度地降低成本。

Abstract: The selection of nodes that can serve as cluster heads, local sinks and
gateways is a critical challenge in distributed sensor and communication
networks. This paper presents a novel framework for identifying a minimal set
of nexus nodes to ensure full network coverage while minimizing cost. By
formulating the problem as a convex relaxation of the NP-hard set cover
problem, we integrate the graph theoretic centrality measures of node degree
and betweenness centrality into a cost function optimized via a relaxed L1-norm
minimization. The proposed approach is applicable to static and dynamic network
scenarios and does not require location or distance estimation. Through
simulations across various graph models and dynamic conditions, it is shown
that the method achieves faster execution times (lower complexity) and
competitive sparsity compared to classical greedy and genetic algorithms (GA),
offering a robust, distributed, and cost-efficient node selection solution.

</details>


### [436] [Meta Fluid Antenna: Architecture Design, Performance Analysis, Experimental Examination](https://arxiv.org/abs/2509.12032)
*Baiyang Liu,Jiewei Huang,Tuo Wu,Huan Meng,Fengcheng Mei,Lei Ning,Kai-Kit Wong,Hang Wong,Kin-Fai Tong,Kwai-Man Luk*

Main category: eess.SP

TL;DR: 利用单射频链的流体天线（FA）的快速切换能力，通过多重激活来实现多用户复用，在不依赖信道状态信息（CSI）的情况下，提高了信号比（SIR），适用于快速变化的无线环境。


<details>
  <summary>Details</summary>
Motivation: 为了充分实现流体天线多址接入（FAMA）在多用户复用方面的潜力。

Method: 利用单射频链（RF）-链的元流体天线结构，通过多重激活实现多用户复用。

Result: 与其他的单射频链技术相比，在多种瑞利衰落环境中，实现了更高的信号比（SIR）。

Conclusion: 多重激活FAMA实现了有效的无CSI、多用户通信，为高容量无线网络提供了可扩展的解决方案。

Abstract: Fluid antenna systems (FAS) have recently emerged as a promising solution for
sixth-generation (6G) ultra-dense connectivity. These systems utilize dynamic
radiating and/or shaping techniques to mitigate interference and improve
spectral efficiency without relying on channel state information (CSI). The
reported improvements achieved by employing a single dynamically activated
radiating position in fluid antenna multiple access (FAMA) are significant. To
fully realize the potential of FAMA in multi-user multiplexing, we propose
leveraging the unique fast-switching capabilities of a single radio-frequency
(RF)-chain meta-fluid antenna structure to achieve multi-activation. This
allows for a significantly larger set of independent radiating states without
requiring additional signal processing. Simulations demonstrate that
multi-activation FAMA enables robust multi-user multiplexing with a higher
signal-to-interference ratio (SIR) under various Rayleigh-fading environments
compared to other single RF-chain technologies. We further show that the SIR
can be optimized within a 15~$\mu s$ timeframe under a multi-user
Rayleigh-fading channel, making the proposed scheme highly suitable for
fast-changing wireless environments. Verified through the theoretical Jakes'
model, full three-dimensional (3D) electromagnetic (EM) simulations and
experimental validation, multi-activation FAMA enables effective CSI-free,
multi-user communication, offering a scalable solution for high-capacity
wireless networks.

</details>


### [437] [RadarLLM: Adapting Pretrained Large Language Models for Marine Radar Target Detection with Preference-aware Loss](https://arxiv.org/abs/2509.12089)
*Qiying Hu*

Main category: eess.SP

TL;DR: 本研究提出了RadarLLM框架，通过一种新颖的偏好感知损失函数，解决了预训练语言模型在雷达信号处理中用于海洋目标检测时出现的过拟合问题，特别是在低信噪比情况下，提高了模型的泛化能力和检测性能。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型（LLMs）在通用知识捕获方面展现出巨大潜力，可作为无线信号处理的通用优化求解器。本研究旨在探索将预训练LLMs应用于海洋目标检测任务中的雷达信号特征分析。

Method: 提出了一种名为RadarLLM的新型微调框架，该框架采用了一种有效的偏好感知损失函数。该损失函数与传统的统一优化所有特征标记的方法不同，它根据在线评估的学习值来选择性地优化不同的特征块，从而引导模型在优化过程中专注于最具泛化能力的模式。理论上证明了评估学习值的有效性。

Result: 1) RadarLLM提出的损失函数比原始损失函数效果更好，在具有挑战性的低信杂比（SCR）场景下提升尤为显著。2) 在各种检测场景下，RadarLLM的性能始终优于最先进的基线方法，尤其是在训练数据有限的条件下，性能提升更为明显。

Conclusion: RadarLLM框架及其偏好感知损失函数能够有效解决LLMs在海洋目标检测任务中，尤其是在低信噪比和数据量有限的情况下出现的过拟合问题，显著提高了雷达信号特征分析和目标检测的性能，为LLMs在雷达信号处理领域的应用提供了新的方向。

Abstract: Recent advances in pre-trained large language models (LLMs) have demonstrated
their capacities to capture universal knowledge, making them promising
general-purpose optimization solvers for wireless signal processing. Motivated
by these findings, we take the first step towards fine-tuning pre-trained LLMs
for the effective analysis of radar signal features in marine target detection
tasks. Nevertheless, directly fine-tuning pre-trained LLMs on marine target
detection tasks tends to suffer from pronounced overfitting, particularly in
challenging low signal-to-clutter ratio (SCR) scenarios. This overfitting
primarily stems from the model's tendency to memorize spurious or noisy feature
patterns rather than learning discriminative structures that generalize well to
unseen data. To address this challenge, we introduce RadarLLM, a novel
fine-tuning framework that utilizes an effective preference-aware loss. Unlike
conventional training strategies that uniformly optimize all feature tokens,
this loss function selectively optimizes different feature patches based on
their online evaluated learning values, thus guiding the model to focus on the
most generalizable patterns during optimization. We theoretically demonstrate
the effectiveness of the evaluated learning values by transforming the problem
as selecting useful feature tokens. Extensive experiments on real-world marine
radar datasets show that 1) the proposed loss function is much better than the
original one, with particularly significant gains in challenging low SCR
scenarios and 2) RadarLLM consistently outperforms state-of-the-art baselines
across diverse detection scenarios, with particularly notable gains under
limited training data conditions.

</details>


### [438] [When marine radar target detection meets pretrained large language models](https://arxiv.org/abs/2509.12110)
*Qiying Hu,Linping Zhang,Xueqian Wang,Gang Li,Yu Liu,Xiao-Ping Zhang*

Main category: eess.SP

TL;DR: 该研究提出了一种结合特征预处理和大型语言模型（LLMs）的框架，用于从雷达回波信号中提取高维模式，解决了传统深度学习方法在特征冗余和模型尺寸上的限制。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在处理雷达回波信号时面临特征冗余和模型尺寸的限制。

Method: 提出一个框架，首先对雷达序列特征进行分词（tokenization），然后使用补丁选择算法过滤掉不相关部分，并将选出的补丁投影到与预训练LLM兼容的嵌入空间。之后，利用这些处理过的嵌入，结合预训练LLM，仅对归一化层进行微调，以降低训练成本并提升性能。

Result: 在实测数据集上的实验表明，该方法在监督学习测试中显著优于现有的基线方法。

Conclusion: 通过结合特征预处理和LLMs，该框架能有效克服传统方法的局限性，并在雷达信号分析任务中取得优越性能。

Abstract: Deep learning (DL) methods are widely used to extract high-dimensional
patterns from the sequence features of radar echo signals. However,
conventional DL algorithms face challenges such as redundant feature segments,
and constraints from restricted model sizes. To address these issues, we
propose a framework that integrates feature preprocessing with large language
models (LLMs). Our preprocessing module tokenizes radar sequence features,
applies a patch selection algorithm to filter out uninformative segments, and
projects the selected patches into embeddings compatible with the feature space
of pre-trained LLMs. Leveraging these refined embeddings, we incorporate a
pre-trained LLM, fine-tuning only the normalization layers to reduce training
burdens while enhancing performance. Experiments on measured datasets
demonstrate that the proposed method significantly outperforms the
state-of-the-art baselines on supervised learning tests.

</details>


### [439] [YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform](https://arxiv.org/abs/2509.03070)
*Po-Heng Chou,Wei-Lung Mao,Ru-Ping Lin*

Main category: eess.SP

TL;DR: 本研究提出了一种基于CWT-YOLO的轴承故障诊断方法，在多个数据集上表现优于MCNN-LSTM。


<details>
  <summary>Details</summary>
Motivation: 为了提高空间轴承故障诊断的准确性和泛化能力，提出一种新的方法。

Method: 使用连续小波变换（CWT）将一维振动信号转换为时频频谱图，然后使用YOLOv9、v10和v11模型对这些频谱图进行故障类型分类。

Result: 在CWRU、PU和IMS三个数据集上，CWT-YOLO方法取得了比基线MCNN-LSTM模型更高的准确率和泛化能力。具体来说，YOLOv11在CWRU、PU和IMS数据集上分别达到了99.4%、97.8%和99.5%的mAP分数。此外，该模型还能直接可视化故障位置。

Conclusion: 所提出的CWT-YOLO方法能够有效地诊断轴承故障，并提供故障位置的可视化，为旋转机械的健康监测提供了一种实用解决方案。

Abstract: This letter proposes a YOLO-based framework for spatial bearing fault
diagnosis using time-frequency spectrograms derived from continuous wavelet
transform (CWT). One-dimensional vibration signals are first transformed into
time-frequency spectrograms using Morlet wavelets to capture transient fault
signatures. These spectrograms are then processed by YOLOv9, v10, and v11
models to classify fault types. Evaluated on three benchmark datasets,
including Case Western Reserve University (CWRU), Paderborn University (PU),
and Intelligent Maintenance System (IMS), the proposed CWT-YOLO pipeline
achieves significantly higher accuracy and generalizability than the baseline
MCNN-LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%
(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism
enables direct visualization of fault locations in spectrograms, offering a
practical solution for condition monitoring in rotating machinery.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [440] [Asynchronous Gathering of Opaque Robots with Mobility Faults](https://arxiv.org/abs/2509.10711)
*Subhajit Pramanick,Saswata Jana,Partha Sarathi Mandal,Gokarna Sharma*

Main category: cs.DC

TL;DR: 该论文研究了在不确定系统（N,f）的机器人集群中进行集会（gathering）的基准测试问题，其中最多f个机器人可能发生故障。论文引入了一种新的“移动性故障”模型，其中机器人的崩溃仅影响其移动能力，而不影响其灯光操作。


<details>
  <summary>Details</summary>
Motivation: 解决在具有移动性故障的异步和明亮机器人（LUMI）模型中机器人集会的问题，并在此基础上进行优化。

Method: 通过引入“移动性故障”模型，并利用不同颜色的灯光来设计和分析机器人集会算法。具体来说，论文首先证明了在（2,1）-移动性故障系统中，使用2色灯光无法实现集会，然后提出了一个使用3色灯光的最优解。接着，论文为（N,f）-移动性故障系统（N,f未知）设计了两种算法，分别在时间和颜色使用上进行了权衡。

Result: 1. 在（2,1）-移动性故障系统中，使用2色灯光无法实现集会。 2. 使用3色灯光可以解决（2,1）-移动性故障系统中的集会问题，并且是颜色数量上的最优解。 3. 对于（N,f）-移动性故障系统（N,f未知），提出了两种算法：一种使用7色灯光，时间复杂度为O(N)；另一种使用26色灯光，时间复杂度为O(max{l,f})。 4. 提出的算法能够处理可见性受阻（不透明机器人模型）和异步调度。

Conclusion: 在移动性故障模型下，通过使用多色灯光，可以有效地解决异步系统中的机器人集会问题，并且在时间和颜色使用上实现了良好的权衡。

Abstract: We consider the fundamental benchmarking problem of gathering in an
$(N,f)$-fault system consisting of $N$ robots, of which at most $f$ might fail
at any execution, under asynchrony. Two seminal results established
impossibility of a solution in the oblivious robot (OBLOT) model in a
$(2,0)$-fault system under semi-synchrony and in a $(3,1)$-Byzantine fault
system under asynchrony. Recently, a breakthrough result circumvented the first
impossibility result by giving a deterministic algorithm in a $(2,0)$-fault
system under asynchrony in the luminous robot (LUMI) model using 2-colored
lights. However, a breakthrough result established impossibility of gathering
in a $(2,1)$-crash system in the LUMI model under semi-synchrony. In this
paper, we consider a {\em mobility fault} model in which a robot crash only
impacts it mobility but not the operation of the light.
  We establish four results under asynchrony in LUMI with the mobility fault
model. We show that it is impossible to solve gathering in a $(2,1)$-mobility
fault system using 2-colored lights, and then give a solution using 3-colored
lights, which is optimal w.r.t. the number of colors. We then consider an
$(N,f)$-mobility fault system, $f<N$, both $N,f$ not known, and give two
deterministic algorithms that exhibit a nice time-color trade-off: The first
with time $O(N)$ using 7-colored lights and the second with time
$O(\max\{\ell,f\})$ using 26-colored lights, where $\ell< N$ is the number of
distinct convex layers of robot positions in the initial configuration.
Interestingly, for $l, f = O(1)$, our result is optimal. Our algorithms for an
$(N,f)$-mobility fault system are the first to be analysed time complexity, can
withstand obstructed visibility (opaque robot model) and asynchronous
scheduling.

</details>


### [441] [MinatoLoader: Accelerating Machine Learning Training Through Efficient Data Preprocessing](https://arxiv.org/abs/2509.10712)
*Rahma Nouaji,Stella Bitchebe,Ricardo Macedo,Oana Balmau*

Main category: cs.DC

TL;DR: MinatoLoader通过优先处理快速预处理样本并并行处理慢速样本来加速PyTorch培训，显著提高GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 现有数据加载器在预处理时间内变异时效率低下，导致GPU空闲和培训延迟。

Method: MinatoLoader在后台持续准备数据，并通过优先处理快速预处理样本来主动构建批次，同时并行处理较慢的样本。

Result: MinatoLoader在V100和A100 GPU服务器上进行了评估，与PyTorch DataLoader和Pecan相比，在具有四个A100 GPU的机器上，训练时间最多可提高7.5倍（平均3.6倍），GPU利用率从46.4%提高到90.45%。

Conclusion: MinatoLoader通过解决数据加载中的低效问题，在加速培训和提高GPU利用率方面显示出显著的益处，同时保持模型准确性并实现更快的收敛。

Abstract: Data loaders are used by Machine Learning (ML) frameworks like PyTorch and
TensorFlow to apply transformations to data before feeding it into the
accelerator. This operation is called data preprocessing. Data preprocessing
plays an important role in the ML training workflow because if it is
inefficiently pipelined with the training, it can yield high GPU idleness,
resulting in important training delays. Unfortunately, existing data loaders
turn out to waste GPU resources, with $76\%$ GPU idleness when using the
PyTorch data loader, for example. One key source of inefficiency is the
variability in preprocessing time across samples within the same dataset.
Existing data loaders are oblivious to this variability, and they construct
batches without any consideration of slow or fast samples. In this case, the
entire batch is delayed by a single slow sample, stalling the training pipeline
and resulting in head-of-line blocking.
  To address these inefficiencies, we present MinatoLoader, a general-purpose
data loader for PyTorch that accelerates training and improves GPU utilization.
MinatoLoader is designed for a single-server setup, containing multiple GPUs.
It continuously prepares data in the background and actively constructs batches
by prioritizing fast-to-preprocess samples, while slower samples are processed
in parallel.
  We evaluate MinatoLoader on servers with V100 and A100 GPUs. On a machine
with four A100 GPUs, MinatoLoader improves the training time of a wide range of
workloads by up to $7.5\times$ ($3.6\times$ on average) over PyTorch DataLoader
and Pecan, and up to $3\times$ ($2.2\times$ on average) over DALI. It also
increases average GPU utilization from 46.4\% with PyTorch to 90.45\%, while
preserving model accuracy and enabling faster convergence.

</details>


### [442] [Coordinated Reinforcement Learning Prefetching Architecture for Multicore Systems](https://arxiv.org/abs/2509.10719)
*Mohammed Humaid Siddiqui,Fernando Guzman,Yufei Wu,Ruishu Ann*

Main category: cs.DC

TL;DR: CRL-Pythia是一种为多核系统设计的协同强化学习预取器，通过跨核信息共享和协同预取决策，解决了传统预取器在多核环境下存在的冗余和性能下降问题，实现了12%的IPC提升，并具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多核架构下，传统硬件预取器面临冗余预取请求（高达20%）和性能下降（约10%）的挑战。

Method: 提出CRL-Pythia，一种基于协同强化学习的预取器，通过跨核信息共享和协同预取决策来减少冗余并加速学习。

Result: CRL-Pythia在所有情况下均优于单核Pythia配置，在带宽受限的工作负载下，IPC（每周期指令数）平均提升约12%，硬件开销适中。

Conclusion: CRL-Pythia通过减少冗余预取和提高跨核学习收敛性，有效解决了多核系统中的预取问题，具有良好的鲁棒性和可扩展性，是一种实用高效的解决方案。

Abstract: Hardware prefetching is critical to fill the performance gap between CPU
speeds and slower memory accesses. With multicore architectures becoming
commonplace, traditional prefetchers are severely challenged. Independent core
operation creates significant redundancy (up to 20% of prefetch requests are
duplicates), causing unnecessary memory bus traffic and wasted bandwidth.
Furthermore, cutting-edge prefetchers such as Pythia suffer from about a 10%
performance loss when scaling from a single-core to a four-core system. To
solve these problems, we propose CRL-Pythia, a coordinated reinforcement
learning based prefetcher specifically designed for multicore systems. In this
work, CRL-Pythia addresses these issues by enabling cross-core sharing of
information and cooperative prefetching decisions, which greatly reduces
redundant prefetch requests and improves learning convergence across cores. Our
experiments demonstrate that CRL-Pythia outperforms single Pythia
configurations in all cases, with approximately 12% IPC (instructions per
cycle) improvement for bandwidth-constrained workloads, while imposing moderate
hardware overhead. Our sensitivity analyses also verify its robustness and
scalability, thereby making CRL-Pythia a practical and efficient solution to
contemporary multicore systems.

</details>


### [443] [Enhancing Type Safety in MPI with Rust: A Statically Verified Approach for RSMPI](https://arxiv.org/abs/2509.10803)
*Nafees Iqbal,Jed Brown*

Main category: cs.DC

TL;DR: Rust 语言提供了一个类型安全的通信框架 RSMPI，用于 MPI 编程，以解决传统 MPI 编程中存在的类型不安全和易出错的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的 MPI 编程由于其低层接口和缺乏内置类型安全，容易在运行时出现错误、未定义行为和调试困难，尤其是在大型应用程序中。

Method: 通过 Rust 的 Equivalence trait 实现了一个 TypedCommunicator 抽象，用于强制执行点对点通信操作的静态类型安全，只允许兼容的类型进行通信，并在编译时或运行时进行检查。该框架支持单值和切片通信，并提供直观的 API。

Result: 该实现消除了常见的 MPI 错误，提高了开发人员的生产力，并保持了性能，符合 Rust 的零成本抽象原则。

Conclusion: 这项工作为将类型安全扩展到集合操作奠定了基础，提高了 Rust 中并行计算的健壮性。

Abstract: The Message Passing Interface (MPI) is a fundamental tool for building
high-performance computing (HPC) applications, enabling efficient communication
across distributed systems. Despite its widespread adoption, MPI's low-level
interface and lack of built-in type safety make it prone to runtime errors,
undefined behavior, and debugging challenges, especially in large-scale
applications. Rust, a modern systems programming language, offers a compelling
solution with its strong type system, which enforces memory and type safety at
compile time without compromising performance. This paper introduces a
type-safe communication framework for MPI, built on the RSMPI library, to
address the limitations of traditional MPI programming. At its core is the
TypedCommunicator, an abstraction that enforces static type safety in
point-to-point communication operations. By leveraging Rust's Equivalence
trait, our framework guarantees that only compatible types can participate in
communication, catching mismatches either at compile time or through runtime
validation. The framework supports both single-value and slice-based
communication, providing an intuitive API for diverse data structures. Our
implementation demonstrates that this approach eliminates common MPI errors,
improves developer productivity, and maintains performance, adhering to Rust's
principle of zero-cost abstractions. This work lays the foundation for
extending type safety to collective operations, advancing the robustness of
parallel computing in Rust.

</details>


### [444] [Chameleon: Taming Dynamic Operator Sequences for Memory-Intensive LLM Training](https://arxiv.org/abs/2509.11076)
*Zibo Wang,Yuhang Zhou,Zhibin Wang,Shipeng Li,Xinjing Huang,Chendong Cai,Bingxu Mu,Yuqing Sun,Zhiheng Hu,Bin She,Shu You,Guanghuan Fang,Rong Gu,Wanchun Dou,Guihai Chen,Chen Tian*

Main category: cs.DC

TL;DR: Chameleon通过轻量级在线分析器、基于有限算子信息的交换策略生成以及优化的策略执行模块，实现了在Eager Mode下有效优化LLM训练的内存占用，支持训练更大模型并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练方法在内存占用和可变算子序列处理方面存在挑战。

Method: 提出Chameleon，一种用于Eager Mode下LLM训练的内存优化方法，包含在线分析器、策略生成器和策略执行器。

Result: Chameleon降低了分析开销（84.25%），支持训练更大的模型（4倍硬件内存），并提高了性能（最高38.94%）。

Conclusion: Chameleon能够有效解决Eager Mode下LLM训练的内存瓶颈问题，并取得显著的性能提升。

Abstract: The increasing size of large language models (LLMs) has led to a surge in
memory requirements during training, often exceeding the capacity of
high-bandwidth memory (HBM). Swap-based memory optimization incurs neither
accuracy loss nor additional end-to-end overhead when effectively overlapped,
thus being an attractive solution. However, existing swap methods assume
consistent operator sequences, which is impractical in Eager Mode, where
operator sequences can vary during change.
  We propose Chameleon, which redesigns the end-to-end process of swap-based
memory optimization and is the first work to consider varying operator
sequences in Eager Mode. Chameleon (i) introduces a lightweight online profiler
to enable continuous profiling for monitoring operator sequences, (ii)
generates effective swap policies with limited operator information, and (iii)
optimizes the policy execution module for accurate policy application and
better performance. Experimental results demonstrate that Chameleon reduces
profiling overhead by 84.25%, enables training models up to 4x larger than
hardware memory while adapting to changes in operator sequences, improves
performance by up to 38.94% compared to recomputation or high-degree
parallelism.

</details>


### [445] [GFS: A Preemption-aware Scheduling Framework for GPU Clusters with Predictive Spot Instance Management](https://arxiv.org/abs/2509.11134)
*Jiaang Duan,Shenglin Xu,Shiyou Qian,Dingyu Yang,Kangjin Wang,Chenzhi Liao,Yinghao Yu,Qin Hua,Hanwen Hu,Qi Wang,Wenchao Wu,Dongqing Bao,Tianyu Lu,Jian Cao,Guangtao Xue,Guodong Yang,Liping Zhang,Gang Chen*

Main category: cs.DC

TL;DR: GFS是一种新的抢占式调度框架，通过预测GPU需求、动态分配配额和抢占式调度策略，降低了低优先级任务的驱逐率和排队延迟，提高了高优先级任务的 SLO 合规性，并为生产集群带来了显著的经济效益。


<details>
  <summary>Details</summary>
Motivation: 现有GPU调度器在处理大规模语言模型（LLM）带来的GPU使用模式变化时，存在高驱逐率和长排队时间的问题，需要更有效的管理策略来降低成本并满足服务水平目标（SLO）。

Method: GFS采用三种策略：1. 轻量级预测模型预测GPU需求；2. 动态分配机制调整低优先级（LP）任务的现货配额；3. 抢占式调度策略优先高优先级（HP）任务，同时最小化对LP任务的干扰。

Result: GFS将LP任务的驱逐率降低了33.0%，排队延迟缩短了44.1%，GPU分配率提高了22.8%，并在超过10,000个GPU的生产集群中带来了每月约459,715美元的效益。

Conclusion: GFS通过其创新的预测、动态分配和抢占式调度方法，有效解决了现有GPU调度器在LLM时代面临的挑战，显著提高了资源利用率和任务执行效率，并创造了可观的经济价值。

Abstract: The surge in large language models (LLMs) has fundamentally reshaped the
landscape of GPU usage patterns, creating an urgent need for more efficient
management strategies. While cloud providers employ spot instances to reduce
costs for low-priority (LP) tasks, existing schedulers still grapple with high
eviction rates and lengthy queuing times. To address these limitations, we
present GFS, a novel preemptive scheduling framework that enhances
service-level objective (SLO) compliance for high-priority (HP) tasks while
minimizing preemptions to LP tasks. Firstly, GFS utilizes a lightweight
forecasting model that predicts GPU demand among different tenants, enabling
proactive resource management. Secondly, GFS employs a dynamic allocation
mechanism to adjust the spot quota for LP tasks with guaranteed durations.
Lastly, GFS incorporates a preemptive scheduling policy that prioritizes HP
tasks while minimizing the impact on LP tasks. We demonstrate the effectiveness
of GFS through both real-world implementation and simulations. The results show
that GFS reduces eviction rates by 33.0\%, and cuts queuing delays by 44.1\%
for LP tasks. Furthermore, GFS enhances the GPU allocation rate by up to 22.8\%
in real production clusters. In a production cluster of more than 10,000 GPUs,
GFS yields roughly \$459,715 in monthly benefits.

</details>


### [446] [Linear Complexity $\mathcal{H}^2$ Direct Solver for Fine-Grained Parallel Architectures](https://arxiv.org/abs/2509.11152)
*Wajih Boukaram,David Keyes,Sherry Li,Yang Liu,George Turkiyyah*

Main category: cs.DC

TL;DR: 该论文提出了一种用于并行处理的线性复杂度直接求解器，适用于可分层表示的矩阵，特别是基于强可加性的H^2格式。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有求解器在处理大规模矩阵时的效率问题，特别是针对细粒度并行架构的优化。

Method: 提出了一种基于强可加性的H^2格式的直接求解器，通过递归骨架化进行压缩，并利用多层矩阵图着色和前缀和内存管理实现并行和高效内存分配。

Result: 在四个代表性矩阵族上，证明了求解器在时间和内存上具有线性复杂度，且在多达一百万规模时依然有效。在16线程下实现了良好的并行扩展。

Conclusion: 所提出的求解器在处理大规模稠密矩阵时，能够实现线性时间与空间复杂度，并且具有良好的并行扩展性，适用于现代并行计算架构。

Abstract: We present factorization and solution phases for a new linear complexity
direct solver designed for concurrent batch operations on fine-grained parallel
architectures, for matrices amenable to hierarchical representation. We focus
on the strong-admissibility-based $\mathcal{H}^2$ format, where strong
recursive skeletonization factorization compresses remote interactions. We
build upon previous implementations of $\mathcal{H}^2$ matrix construction for
efficient factorization and solution algorithm design, which are illustrated
graphically in stepwise detail. The algorithms are ``blackbox'' in the sense
that the only inputs are the matrix and right-hand side, without analytical or
geometrical information about the origin of the system. We demonstrate linear
complexity scaling in both time and memory on four representative families of
dense matrices up to one million in size. Parallel scaling up to 16 threads is
enabled by a multi-level matrix graph coloring and avoidance of dynamic memory
allocations thanks to prefix-sum memory management. An experimental backward
error analysis is included. We break down the timings of different phases,
identify phases that are memory-bandwidth limited, and discuss alternatives for
phases that may be sensitive to the trend to employ lower precisions for
performance.

</details>


### [447] [Adaptive K-PackCache: Cost-Centric Data Caching in Cloud](https://arxiv.org/abs/2509.11156)
*Suvarthi Sarkar,Aadarshraj Sah,Poddutoori Sweeya Reddy,Aryabartta Sahu*

Main category: cs.DC

TL;DR: 该论文提出了 K PackCache (AKPC) 算法，用于优化内容分发网络中的缓存效率，通过将多个共同访问的数据项打包成“包”进行缓存，以减少传输和存储成本。


<details>
  <summary>Details</summary>
Motivation: 为了提高缓存效率，将多个共同访问的数据项作为捆绑包进行缓存，而不是仅限于两个数据项的打包。

Method: 提出了一种名为自适应 K PackCache (AKPC) 的在线算法，该算法根据用户访问模式和内容相关性动态地形成、合并和拆分数据“包”，支持批量请求，并提供正式的竞争保证。

Result: 在 Netflix 和 Spotify 数据集上的广泛评估表明，AKPC 相对于在线基线可以将总成本分别降低高达 63% 和 55%，并且性能接近最优。

Conclusion: AKPC 算法能够有效地减少缓存成本，并证明了其在实际缓存系统中的可扩展性和有效性。

Abstract: Recent advances in data analytics have enabled the accurate prediction of
user access patterns, giving rise to the idea of packed caching delivering
multiple co accessed data items together as a bundle. This improves caching
efficiency, as accessing one item often implies the need for others. Prior work
has explored only 2 item pairwise packing. In this paper, we extend the concept
to general K packing, allowing variable size bundles for improved flexibility
and performance. We formulate the K PackCache problem from a content delivery
network CDN operator perspective, aiming to minimize total cost comprising two
components: transfer cost modeled as a base cost plus a linearly increasing
term with the number of items packed, and memory rental cost for caching, which
depends on how long and how much is stored. Overpacking increases cost due to
low utility, underpacking leads to missed sharing opportunities. We propose an
online algorithm, Adaptive K PackCache AKPC, which dynamically forms, merges,
and splits data cliques based on user access patterns and content correlation.
Our approach supports batch requests, enables approximate clique merging, and
offers a formal competitive guarantee. Through extensive evaluation on the
Netflix and Spotify datasets, AKPC reduces total cost by up to 63 and 55
percentage over online baselines, respectively, and achieves performance within
15 and 13 percentage of the optimal. This demonstrates its scalability and
effectiveness for real world caching systems.

</details>


### [448] [Energy-Efficient Joint Offloading and Resource Allocation for Deadline-Constrained Tasks in Multi-Access Edge Computing](https://arxiv.org/abs/2509.11162)
*Chuanchao Gao,Arvind Easwaran*

Main category: cs.DC

TL;DR: 该论文提出了一种基于图匹配的近似算法（GMA）来解决多接入边缘计算中的带截止时间任务卸载和资源分配问题，以最大限度地提高物联网设备的总节能，同时满足任务截止时间和系统资源约束。该算法将问题转化为整数非线性规划问题，并采用线性松弛、三部图构建和线性规划舍入技术来求解，理论上可实现(1-α)/(2+ε)的近似比，实践中平均可达最优值的97%。


<details>
  <summary>Details</summary>
Motivation: 为了在多接入边缘计算环境中，最大限度地提高物联网设备的总能耗，同时满足任务的截止时间和系统资源约束。

Method: 将问题建模为整数非线性规划问题，并提出一种基于图匹配的近似算法（GMA），该算法利用线性松弛、三部图构建和线性规划舍入技术。

Result: GMA算法被证明是一个(1-α)/(2+ε)近似算法，实验表明其实际节能效果平均可达最优值的97%。

Conclusion: 提出的GMA算法能够有效地解决多接入边缘计算中的带截止时间任务卸载和资源分配问题，并在保证任务截止时间和系统资源约束的同时，实现接近最优的节能效果。

Abstract: This paper addresses the deadline-constrained task offloading and resource
allocation problem in multi-access edge computing. We aim to determine where
each task is offloaded and processed, as well as corresponding communication
and computation resource allocations, to maximize the total saved energy for
IoT devices, while considering task deadline and system resource constraints.
Especially, our system allows each task to be offloaded to one of its
accessible access points (APs) and processed on a server that is not co-located
with its offloading AP. We formulate this problem as an Integer Nonlinear
Programming problem and show it is NP-Hard. To address this problem, we propose
a Graph-Matching-based Approximation Algorithm ($\mathtt{GMA}$), the first
approximation algorithm of its kind. $\mathtt{GMA}$ leverages linear
relaxation, tripartite graph construction, and a Linear Programming rounding
technique. We prove that $\mathtt{GMA}$ is a
$\frac{1-\alpha}{2+\epsilon}$-approximation algorithm, where $\epsilon$ is a
small positive value, and $\alpha$ ($0$$\le$$\alpha$$<$$1$) is a system
parameter that ensures the resource allocated to any task by an AP or a server
cannot exceed $\alpha$ times its resource capacity. Experiments show that, in
practice, $\mathtt{GMA}$'s energy saving achieves $97\%$ of the optimal value
on average.

</details>


### [449] [Parallel/Distributed Tabu Search for Scheduling Microprocessor Tasks in Hybrid Flowshop](https://arxiv.org/abs/2509.11396)
*Adam Janiak,Damian Kowalczyk,Maciej Lichtenstein*

Main category: cs.DC

TL;DR: 本文提出一种基于并行和分布式机制的禁忌搜索算法，用于解决具有多处理器任务的混合流水车间调度问题的 makespan 最小化问题。


<details>
  <summary>Details</summary>
Motivation: 混合流水车间（HFS）通过用多个并行处理器替换每个处理器（处理阶段）来推广经典的流水车间处理器配置。类似地，多处理器任务通过允许任务同时需要多个处理器来进行处理来推广经典假设。本文旨在解决此类问题。

Method: 提出一种基于禁忌搜索技术的算法，该算法使用并行和分布式机制进行邻域评估，并能很好地平衡异构网络环境。

Result: 算法能够解决具有多处理器任务的混合流水车间调度问题的 makespan 最小化问题。

Conclusion: 所提出的算法有效地解决了混合流水车间调度问题。

Abstract: The paper deals with the makespan minimization in the hybrid flow shop
scheduling problem with multiprocessor tasks. The hybrid flow shop (HFS)
generalizes the classical flow shop processor configuration by replacing each
processor (processing stage) by some number of identical parallel processors.
Similarly, the multiprocessor tasks generalize the classical assumption, by
allowing a task to require more than one processor simultaneously for its
processing. In this work we present the algorithm for solving the problem based
on the tabu search technique. The proposed algorithm uses parallel and
distributed mechanisms for neighborhood evaluation and well balances
heterogeneous network environment.

</details>


### [450] [Machine Learning-Driven Predictive Resource Management in Complex Science Workflows](https://arxiv.org/abs/2509.11512)
*Tasnuva Chowdhury,Tadashi Maeno,Fatih Furkan Akman,Joseph Boudreau,Sankha Dutta,Shengyu Feng,Adolfy Hoisie,Kuan-Chieh Hsu,Raees Khan,Jaehyung Kim,Ozgur O. Kilic,Scott Klasky,Alexei Klimentov,Tatiana Korchuganova,Verena Ingrid Martinez Outschoorn,Paul Nilsson,David K. Park,Norbert Podhorszki,Yihui Ren,John Rembrandt Steele,Frédéric Suter,Sairam Sri Vatsavai,Torre Wenaus,Wei Yang,Yiming Yang,Shinjae Yoo*

Main category: cs.DC

TL;DR: 机器学习模型被用于预测科学实验数据处理工作流的资源需求。


<details>
  <summary>Details</summary>
Motivation: 科学实验数据处理工作流的资源需求估算面临挑战，现有方法存在不足。

Method: 提出了一种包含机器学习模型的工作流管理系统（PanDA），用于预测资源需求。

Result: 准确预测资源需求，提高工作流管理效率，优化资源利用。

Conclusion: 机器学习模型能有效解决科学实验数据处理中的资源预测问题，提升工作流管理能力。

Abstract: The collaborative efforts of large communities in science experiments, often
comprising thousands of global members, reflect a monumental commitment to
exploration and discovery. Recently, advanced and complex data processing has
gained increasing importance in science experiments. Data processing workflows
typically consist of multiple intricate steps, and the precise specification of
resource requirements is crucial for each step to allocate optimal resources
for effective processing. Estimating resource requirements in advance is
challenging due to a wide range of analysis scenarios, varying skill levels
among community members, and the continuously increasing spectrum of computing
options. One practical approach to mitigate these challenges involves initially
processing a subset of each step to measure precise resource utilization from
actual processing profiles before completing the entire step. While this
two-staged approach enables processing on optimal resources for most of the
workflow, it has drawbacks such as initial inaccuracies leading to potential
failures and suboptimal resource usage, along with overhead from waiting for
initial processing completion, which is critical for fast-turnaround analyses.
In this context, our study introduces a novel pipeline of machine learning
models within a comprehensive workflow management system, the Production and
Distributed Analysis (PanDA) system. These models employ advanced machine
learning techniques to predict key resource requirements, overcoming challenges
posed by limited upfront knowledge of characteristics at each step. Accurate
forecasts of resource requirements enable informed and proactive
decision-making in workflow management, enhancing the efficiency of handling
diverse, complex workflows across heterogeneous resources.

</details>


### [451] [Towards the Distributed Large-scale k-NN Graph Construction by Graph Merge](https://arxiv.org/abs/2509.11697)
*Cheng Zhang,Wan-Lei Zhao,Shihai Xiao,Jiajie Yao,Xuecang Zhang*

Main category: cs.DC

TL;DR: 本文提出高效的图合并算法来解决海量向量化多媒体数据的k-NN图/索引图的构建问题，实现了单机或多机环境下的可扩展图构建，并在大规模图构建实验中验证了其效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 为了支持大模型与海量向量化多媒体数据的实时交互、即时搜索或推荐，构建大规模k-NN图/索引图成为一个迫切的需求，但现有单机处理能力有限。

Method: 提出用于单机图构建的双向合并和多向合并算法，以及基于双向合并的多节点图构建流程，以处理超出单机内存容量的数据。

Result: 实验表明，该方法能够高效地构建大规模k-NN图，例如，使用三台机器约17小时可构建十亿规模的k-NN图。在索引图构建方面，合并后的索引图在大大缩短构建时间的同时，实现了与原始索引图相似的近邻搜索性能。

Conclusion: 所提出的图合并方法能够高效、可扩展地解决大规模k-NN图和索引图的构建问题，适用于单机和多机环境，能够满足实时交互和大规模数据处理的需求。

Abstract: In order to support the real-time interaction with LLMs and the instant
search or the instant recommendation on social media, it becomes an imminent
problem to build k-NN graph or indexing graph for the massive number of
vectorized multimedia data. In such scenarios, the scale of the data or the
scale of the graph may exceed the processing capacity of a single machine. This
paper aims to address the graph construction problem of such scale via
efficient graph merge. For the graph construction on a single node, two generic
and highly parallelizable algorithms, namely Two-way Merge and Multi-way Merge
are proposed to merge subgraphs into one. For the graph construction across
multiple nodes, a multi-node procedure based on Two-way Merge is presented. The
procedure makes it feasible to construct a large-scale k-NN graph/indexing
graph on either a single node or multiple nodes when the data size exceeds the
memory capacity of one node. Extensive experiments are conducted on both
large-scale k-NN graph and indexing graph construction. For the k-NN graph
construction, the large-scale and high-quality k-NN graphs are constructed by
graph merge in parallel. Typically, a billion-scale k-NN graph can be built in
approximately 17h when only three nodes are employed. For the indexing graph
construction, similar NN search performance as the original indexing graph is
achieved with the merged indexing graphs while requiring much less time of
construction.

</details>


### [452] [A Uniqueness Theorem for Distributed Computation under Physical Constraint](https://arxiv.org/abs/2509.11754)
*Zhiyuan Ren,Mingxuan Lu,Wenchi Cheng*

Main category: cs.DC

TL;DR: 在极端环境下，计算模型需要从工程权衡转向逻辑推导，以解决通信效率、内存限制和可扩展性之间的困境。本研究提出了一个公理化系统，并证明了自描述并行流（SDPF）是满足这些约束的唯一最优范式，它是一种数据中心化的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式计算范式在极端环境（如网络内计算）下面临通信效率、内存限制和可扩展性之间的严峻挑战，需要新的解决方案。

Method: 建立了一个严格的公理系统，形式化了物理约束，并证明了对于具有幂等合并算子的计算，存在一个唯一的、最优的范式，即自描述并行流（SDPF）。

Result: 证明了SDPF是唯一必然的、收敛的、图灵完备的和最小化的范式，类似于CAP定理揭示了分布式状态管理的局限性，本研究揭示了分布式计算流在物理定律下的必然性。

Conclusion: 本研究通过公理化方法，为在极端环境下进行分布式计算提供了一个独特的、最优的范式——SDPF，解决了通信效率、内存限制和可扩展性之间的矛盾。

Abstract: Foundational models of computation often abstract away physical hardware
limitations. However, in extreme environments like In-Network Computing (INC),
these limitations become inviolable laws, creating an acute trilemma among
communication efficiency, bounded memory, and robust scalability. Prevailing
distributed paradigms, while powerful in their intended domains, were not
designed for this stringent regime and thus face fundamental challenges. This
paper demonstrates that resolving this trilemma requires a shift in perspective
- from seeking engineering trade-offs to deriving solutions from logical
necessity. We establish a rigorous axiomatic system that formalizes these
physical constraints and prove that for the broad class of computations
admitting an idempotent merge operator, there exists a unique, optimal
paradigm. Any system satisfying these axioms must converge to a single normal
form: Self-Describing Parallel Flows (SDPF), a purely data-centric model where
stateless executors process flows that carry their own control logic. We
further prove this unique paradigm is convergent, Turing-complete, and minimal.
In the same way that the CAP theorem established a boundary for what is
impossible in distributed state management, our work provides a constructive
dual: a uniqueness theorem that reveals what is \textit{inevitable} for
distributed computation flows under physical law.

</details>


### [453] [LASLiN: A Learning-Augmented Peer-to-Peer Network](https://arxiv.org/abs/2509.11904)
*Julien Dallot,Caio Caldeira,Arash Pourdamghani,Olga Goussevskaia,Stefan Schmid*

Main category: cs.DC

TL;DR: 提出了一种结合了学习预测的网络拓扑设计的P2P网络，旨在优化网络性能，并在预测准确和不准确时都能保持良好的表现。


<details>
  <summary>Details</summary>
Motivation: 在现有的P2P网络指标（如路由路径长度、最大度）保持不变的情况下，利用对未来流量模式的预测来优化网络拓扑，以最小化基于通信需求的加权路径长度。

Method: 设计了一个学习增强的P2P网络协议，每个节点接收关于未来流量模式的预测。在中心化设置下，通过动态规划解决了最优静态跳表网络（SLN）的构建问题。提出了Uniform P2P协议，将节点高度从离散推广到连续，并在此基础上构建了LASLiN协议。

Result: 中心化设置下，最优SLN的构建问题可在多项式时间内解决。LASLiN协议在预测正确时，性能与最优静态SLN相当；在预测错误时，性能仅比现有P2P协议差对数因子。对于稀疏需求，LASLiN性能有所提升。

Conclusion: LASLiN协议通过结合流量预测，在保证P2P网络基本指标的同时，实现了对网络性能的有效优化，尤其是在满足通信需求方面表现出色，并在预测准确和不准确的情况下都具有鲁棒性。

Abstract: We introduce a learning-augmented peer-to-peer (P2P) network design that
leverages the predictions of traffic patterns to optimize the network's
topology. While keeping formal guarantees on the standard P2P metrics (routing
path length, maximum degree), we optimize the network in a demand-aware manner
and minimize the path lengths weighted by the peer-to-peer communication
demands. Our protocol is learning-augmented, meaning that each node receives an
individual, possibly inaccurate prediction about the future traffic patterns,
with the goal of improving the network's performances. We strike a trade-off
between significantly improved performances when the predictions are correct
(consistency) and polylogarithmic performances when the predictions are
arbitrary (robustness).
  We have two main contributions. First, we consider the centralized setting
and show that the problem of constructing an optimum static skip list network
(SLN) is solvable in polynomial time and can be computed via dynamic
programming. This problem is the natural demand-aware extension of the optimal
skip list problem.
  Second, we introduce the Uniform P2P protocol which generalizes skip list
networks (SLN) by relaxing the node's heights from discrete to continuous. We
show that Uniform achieves state-of-the-art performances: logarithmic routing
and maximum degree, both with high probability. We then use Uniform to build a
learning-augmented P2P protocol in order to incorporate demand-awareness,
leading to our main contribution, LASLiN. We prove that the performances of
LASLiN are consistent with those of an optimum static SLN with correct
predictions (given via our dynamic programming approach), and are at most a
logarithmic factor off the state-of-the-art P2P protocols if the predictions
are arbitrary wrong. For the special case of highly sparse demands, we show
that LASLiN achieves improved performances.

</details>


### [454] [UniPar: A Unified LLM-Based Framework for Parallel and Accelerated Code Translation in HPC](https://arxiv.org/abs/2509.12136)
*Tomer Bitan,Tal Kadosh,Erel Kaplan,Shira Meiri,Le Chen,Peter Morales,Niranjan Hasabnis,Gal Oren*

Main category: cs.DC

TL;DR: LLM在并行编程语言翻译方面表现不佳，但UniPar框架通过微调和编译器修复可将其性能提高一倍。


<details>
  <summary>Details</summary>
Motivation: 现有的并行编程语言翻译工具范围有限且已过时。LLM在代码生成和翻译方面展现出潜力，但需要系统评估其在并行语言翻译中的能力。

Method: 提出UniPar评估框架，评估GPT-4o-mini和LLaMA-3.3-70B-Instruct在串行代码、CUDA和OpenMP之间的翻译能力。测试了四种模式：超参数优化、零样本/少样本提示、监督微调和编译器修复的迭代反馈。构建了PARATRANS数据集。

Result: 默认设置下，LLM翻译的编译率和功能正确率较低（GPT-4o-mini分别为46%和15%）。UniPar方法（结合微调、超参数调优和编译器修复）可将性能提高高达2倍（编译率69%，正确率33%）。

Conclusion: UniPar框架和方法为改进LLM在并行语言翻译任务中的表现提供了有价值的见解。

Abstract: Translating programs between various parallel programming languages is an
important problem in the high-performance computing (HPC) community. Existing
tools for this problem are either too narrow in scope and/or outdated. Recent
explosive growth in the popularity of large language models (LLMs) and their
ability to generate and translate code offers a potential alternative approach.
Toward that end, we first need to systematically evaluate the ability of LLMs
to translate between parallel languages.
  In this work, we introduce UniPar, a systematic evaluation framework for
LLM-based parallel code translation. Specifically, in this work, we target
translations between serial code, CUDA, and OpenMP. Our goal is to assess how
well current instruction-tuned LLMs -- specifically GPT-4o-mini and
LLaMA-3.3-70B-Instruct -- can be used out of the box or enhanced through known
strategies. We evaluated four major usage modes: hyperparameter optimization
for decoding, zero- and few-shot prompting, supervised fine-tuning, and
iterative feedback through compiler-based repair. As a part of the evaluation,
we construct a new dataset called PARATRANS, covering both serial-to-parallel
translation and cross-paradigm transformations.
  Our findings reveal that while off-the-shelf models struggle under the
default settings (e.g., GPT-4o-mini achieves only 46% compilation and 15%
functional correctness), our UniPar methodology -- combining fine-tuning,
hyperparameter tuning, and compiler-guided repair -- improves performance by up
to 2X (69% compilation and 33% correctness). We believe that our findings will
provide useful insights for researchers to further improve LLMs for the
parallel language translation problem.
  UniPar source code and PARATRANS dataset are available at our GitHub
repository https://github.com/Scientific-Computing-Lab/UniPar_AI.

</details>


### [455] [Distributed 3D Gaussian Splatting for High-Resolution Isosurface Visualization](https://arxiv.org/abs/2509.12138)
*Mengjiao Han,Andres Sewell,Joseph Insley,Janet Knowles,Victor A. Mateevitsi,Michael E. Papka,Steve Petruzza,Silvio Rizzi*

Main category: cs.DC

TL;DR: 分布式3D高斯溅射技术能够高效渲染大规模科学数据


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯溅射技术受限于单GPU，无法处理HPC系统中的大规模数据集，需要一种可扩展的解决方案。

Method: 提出了一种分布式3D高斯溅射流程，通过数据分区、多节点多GPU并行训练高斯溅射以及合并高斯溅射实现全局渲染。为了消除伪影，在分区边界添加了ghost cells并使用背景蒙版移除了不相关的像素。

Result: 在使用Richtmyer-Meshkov数据集（约1.07亿高斯）的基准测试中，在Polaris的8个节点上实现了3倍的速度提升，同时保持了图像质量。

Conclusion: 分布式3D高斯溅射技术实现了大规模科学数据的可扩展可视化，并为未来的原位应用奠定了基础。

Abstract: 3D Gaussian Splatting (3D-GS) has recently emerged as a powerful technique
for real-time, photorealistic rendering by optimizing anisotropic Gaussian
primitives from view-dependent images. While 3D-GS has been extended to
scientific visualization, prior work remains limited to single-GPU settings,
restricting scalability for large datasets on high-performance computing (HPC)
systems. We present a distributed 3D-GS pipeline tailored for HPC. Our approach
partitions data across nodes, trains Gaussian splats in parallel using
multi-nodes and multi-GPUs, and merges splats for global rendering. To
eliminate artifacts, we add ghost cells at partition boundaries and apply
background masks to remove irrelevant pixels. Benchmarks on the
Richtmyer-Meshkov datasets (about 106.7M Gaussians) show up to 3X speedup
across 8 nodes on Polaris while preserving image quality. These results
demonstrate that distributed 3D-GS enables scalable visualization of
large-scale scientific data and provide a foundation for future in situ
applications.

</details>


### [456] [When MoE Meets Blockchain: A Trustworthy Distributed Framework of Large Models](https://arxiv.org/abs/2509.12141)
*Weihao Zhu,Long Shi,Kang Wei,Zhen Mei,Zhe Wang,Jiaheng Wang,Jun Li*

Main category: cs.DC

TL;DR: MoE模型因其稀疏门控机制降低了计算开销并保持了与密集LM相当的学习性能。但传统的云端MoE存在响应延迟长、带宽消耗高和数据隐私泄露等问题。将MoE部署到分布式边缘网络可以解决这些问题，但缺乏对分布式专家之间数据交互的信任。为此，提出了一种区块链辅助的可信MoE（B-MoE）框架，通过区块链层进行去中心化追踪、验证和记录专家计算结果，提高了模型对数据篡改为攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的云端MoE模型存在响应延迟长、带宽消耗高和数据隐私泄露等问题，而分布式MoE框架又缺乏对数据交互的信任，容易受到攻击。因此，需要一种更安全、更可信的分布式MoE解决方案。

Method: 提出了一种区块链辅助的可信MoE（B-MoE）框架，该框架包含边缘层、区块链层和存储层。边缘层负责处理学习任务，区块链层负责追踪、验证和记录边缘层的计算结果，存储层用于存储专家模型。利用区块链的去中心化特性来确保数据交互的可信度。

Result: 实验结果表明，B-MoE框架在训练和推理过程中，相比传统的分布式MoE，对数据篡改攻击具有更强的鲁棒性。

Conclusion: B-MoE框架通过引入区块链技术解决了分布式MoE在数据交互中的信任问题，提高了模型的安全性和鲁棒性，是解决传统MoE模型痛点的一种有效方案。

Abstract: As an enabling architecture of Large Models (LMs), Mixture of Experts (MoE)
has become prevalent thanks to its sparsely-gated mechanism, which lowers
computational overhead while maintaining learning performance comparable to
dense LMs. The essence of MoE lies in utilizing a group of neural networks
(called experts) with each specializing in different types of tasks, along with
a trainable gating network that selectively activates a subset of these experts
to handle specific tasks. Traditional cloud-based MoE encounters challenges
such as prolonged response latency, high bandwidth consumption, and data
privacy leakage. To address these issues, researchers have proposed to deploy
MoE over distributed edge networks. However, a key concern of distributed MoE
frameworks is the lack of trust in data interactions among distributed experts
without the surveillance of any trusted authority, and thereby prone to
potential attacks such as data manipulation. In response to the security issues
of traditional distributed MoE, we propose a blockchain-aided trustworthy MoE
(B-MoE) framework that consists of three layers: the edge layer, the blockchain
layer, and the storage layer. In this framework, the edge layer employs the
activated experts downloaded from the storage layer to process the learning
tasks, while the blockchain layer functions as a decentralized trustworthy
network to trace, verify, and record the computational results of the experts
from the edge layer. The experimental results demonstrate that B-MoE is more
robust to data manipulation attacks than traditional distributed MoE during
both the training and inference processes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [457] [Can any model be fabricated? Inverse operation based planning for hybrid additive-subtractive manufacturing](https://arxiv.org/abs/2509.10599)
*Yongxue Chen,Tao Liu,Yuming Huang,Weiming Wang,Tianyu Zhang,Kun Qian,Zikang Shi,Charlie C. L. Wang*

Main category: cs.GR

TL;DR: 本论文提出了一种计算交错加法和减法制造操作以制造任意形状模型的方法。


<details>
  <summary>Details</summary>
Motivation: 解决任意形状模型的制造规划问题，并确保中间形状的可制造性和结构稳定性。

Method: 通过搜索一系列逆操作来解决制造规划问题，这些逆操作逐步将目标模型转换为零形状，每个逆操作对应一个加法或减法步骤。

Result: 理论上证明了任何模型都可以用生成序列精确制造，并通过体素化实现，该算法可扩展至大量体素。

Conclusion: 该方法在数字模型和混合制造系统上都得到了验证，表明其有效性。

Abstract: This paper presents a method for computing interleaved additive and
subtractive manufacturing operations to fabricate models of arbitrary shapes.
We solve the manufacturing planning problem by searching a sequence of inverse
operations that progressively transform a target model into a null shape. Each
inverse operation corresponds to either an additive or a subtractive step,
ensuring both manufacturability and structural stability of intermediate shapes
throughout the process. We theoretically prove that any model can be fabricated
exactly using a sequence generated by our approach. To demonstrate the
effectiveness of this method, we adopt a voxel-based implementation and develop
a scalable algorithm that works on models represented by a large number of
voxels. Our approach has been tested across a range of digital models and
further validated through physical fabrication on a hybrid manufacturing system
with automatic tool switching.

</details>


### [458] [T2Bs: Text-to-Character Blendshapes via Video Generation](https://arxiv.org/abs/2509.10678)
*Jiahao Luo,Chaoyang Wang,Michael Vasilkovsky,Vladislav Shakhrai,Di Liu,Peiye Zhuang,Sergey Tulyakov,Peter Wonka,Hsin-Ying Lee,James Davis,Jian Wang*

Main category: cs.GR

TL;DR: T2Bs 通过结合静态文本到3D生成和视频扩散，从文本生成高质量、可动画的角色头部可变形模型，解决了现有方法在运动合成和几何一致性方面存在的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D生成方法在运动合成方面存在不足，而视频扩散模型则存在时间、多视角几何不一致的问题。T2Bs旨在弥合这一差距。

Method: T2Bs 框架利用可变形3D高斯泼溅技术，将静态3D资产与视频输出对齐。通过使用静态几何约束运动，并采用依赖视角的变形MLP，T2Bs 实现了精确且富有表现力的4D生成。

Result: T2Bs 在准确性和表现力方面优于现有的4D生成方法，同时减少了视频伪影和视角不一致。它能够重建平滑、连贯、完全对齐的3D几何，可用于构建具有多样化、逼真面部运动的可变形模型。

Conclusion: T2Bs 能够合成富有表现力、可动画的角色头部，在4D生成技术方面取得了突破。

Abstract: We present T2Bs, a framework for generating high-quality, animatable
character head morphable models from text by combining static text-to-3D
generation with video diffusion. Text-to-3D models produce detailed static
geometry but lack motion synthesis, while video diffusion models generate
motion with temporal and multi-view geometric inconsistencies. T2Bs bridges
this gap by leveraging deformable 3D Gaussian splatting to align static 3D
assets with video outputs. By constraining motion with static geometry and
employing a view-dependent deformation MLP, T2Bs (i) outperforms existing 4D
generation methods in accuracy and expressiveness while reducing video
artifacts and view inconsistencies, and (ii) reconstructs smooth, coherent,
fully registered 3D geometries designed to scale for building morphable models
with diverse, realistic facial motions. This enables synthesizing expressive,
animatable character heads that surpass current 4D generation techniques.

</details>


### [459] [AD-GS: Alternating Densification for Sparse-Input 3D Gaussian Splatting](https://arxiv.org/abs/2509.11003)
*Gurutva Patle,Nilay Girgaonkar,Nagabhushan Somraj,Rajiv Soundararajan*

Main category: cs.GR

TL;DR: 3DGS在稀疏视图下效果不佳，提出AD-GS交替密集化框架，通过交替进行高密度和低密度密集化，并结合光度损失、伪视图一致性和边缘感知深度平滑等方法，有效解决伪影和过拟合问题，提升渲染质量和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 3DGS在稀疏视图下存在伪影、几何不准确和过拟合等问题，关键在于不受控制的密集化。

Method: 提出AD-GS交替密集化框架，包含高密度和低密度两个阶段。高密度阶段进行密集化并进行光度损失训练；低密度阶段进行不透明度裁剪，并利用伪视图一致性和边缘感知深度平滑正则化几何。

Result: AD-GS在稀疏视图数据集上显著提高了渲染质量和几何一致性。

Conclusion: AD-GS通过控制模型容量增长和逐步优化场景表示，有效解决了3DGS在稀疏视图下的挑战。

Abstract: 3D Gaussian Splatting (3DGS) has shown impressive results in real-time novel
view synthesis. However, it often struggles under sparse-view settings,
producing undesirable artifacts such as floaters, inaccurate geometry, and
overfitting due to limited observations. We find that a key contributing factor
is uncontrolled densification, where adding Gaussian primitives rapidly without
guidance can harm geometry and cause artifacts. We propose AD-GS, a novel
alternating densification framework that interleaves high and low densification
phases. During high densification, the model densifies aggressively, followed
by photometric loss based training to capture fine-grained scene details. Low
densification then primarily involves aggressive opacity pruning of Gaussians
followed by regularizing their geometry through pseudo-view consistency and
edge-aware depth smoothness. This alternating approach helps reduce overfitting
by carefully controlling model capacity growth while progressively refining the
scene representation. Extensive experiments on challenging datasets demonstrate
that AD-GS significantly improves rendering quality and geometric consistency
compared to existing methods.

</details>


### [460] [SH-SAS: An Implicit Neural Representation for Complex Spherical-Harmonic Scattering Fields for 3D Synthetic Aperture Sonar](https://arxiv.org/abs/2509.11087)
*Omkar Shailendra Vengurlekar,Adithya Pediredla,Suren Jayasuriya*

Main category: cs.GR

TL;DR: SH-SAS是一种新的3D合成孔径声纳（SAS）重建算法，使用球谐（SH）系数来表示声学散射场，能够更好地处理方向性和采样限制，并在各种基准测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D SAS重建算法（如时域反投影）在处理方向性、采样限制、混叠和遮挡方面存在不足，并且先前的神经体素方法将每个体素视为各向同性散射密度，忽略了各向异性回波。

Method: 提出了一种名为SH-SAS的隐式神经表示方法，使用球谐（SH）系数来表示复杂的声学散射场。该模型使用多分辨率哈希编码器和一个轻量级MLP来输出指定阶数L的复数SH系数。其中，零阶系数代表各向同性散射场（密度项），高阶系数则能以最小的参数开销捕捉方向性散射。由于模型可以直接预测任何收发基线下的复数幅度，因此可以直接从一维飞行时间信号进行训练，无需进行中间图像的波束成形监督。

Result: 在合成和真实的SAS（包括空载和水下）基准测试中，SH-SAS在3D重建质量和几何指标方面均优于先前的方法。

Conclusion: SH-SAS通过使用球谐系数来表示各向异性散射场，有效地解决了传统3D SAS重建方法的局限性，并在重建质量和效率上取得了显著提升。

Abstract: Synthetic aperture sonar (SAS) reconstruction requires recovering both the
spatial distribution of acoustic scatterers and their direction-dependent
response. Time-domain backprojection is the most common 3D SAS reconstruction
algorithm, but it does not model directionality and can suffer from sampling
limitations, aliasing, and occlusion. Prior neural volumetric methods applied
to synthetic aperture sonar treat each voxel as an isotropic scattering
density, not modeling anisotropic returns. We introduce SH-SAS, an implicit
neural representation that expresses the complex acoustic scattering field as a
set of spherical harmonic (SH) coefficients. A multi-resolution hash encoder
feeds a lightweight MLP that outputs complex SH coefficients up to a specified
degree L. The zeroth-order coefficient acts as an isotropic scattering field,
which also serves as the density term, while higher orders compactly capture
directional scattering with minimal parameter overhead. Because the model
predicts the complex amplitude for any transmit-receive baseline, training is
performed directly from 1-D time-of-flight signals without the need to beamform
intermediate images for supervision. Across synthetic and real SAS (both in-air
and underwater) benchmarks, results show that SH-SAS performs better in terms
of 3D reconstruction quality and geometric metrics than previous methods.

</details>


### [461] [3D Gaussian Modeling and Ray Marching of OpenVDB datasets for Scientific Visualization](https://arxiv.org/abs/2509.11377)
*Isha Sharma,Dieter Schmalstieg*

Main category: cs.GR

TL;DR: 本篇论文探讨了在科学可视化领域使用3D高斯模型来稀疏地表示稠密体积数据，并提出了一种基于光线积分的渲染算法。


<details>
  <summary>Details</summary>
Motivation: 目前的3D高斯模型在场景建模和压缩方面有巨大潜力，但在科学可视化中，常用的数据格式（如OpenVDB）虽然能表示稀疏体积数据，但仍有改进空间，尤其是在将其转换为3D高斯粒子以实现更优压缩和统一建模方面。

Method: 提出了一种基于光线积分的渲染算法（使用OptiX8.1实现），用于计算3D高斯沿射线对光学深度的贡献。同时，为了比较，实现了一个基于NanoVDB的、针对OpenVDB体素网格的传统光线步进渲染器。

Result: 该论文提出了一种创新的方法，将3D高斯模型应用于科学可视化领域，并开发了相应的渲染算法。此外，还探索了将该高斯模型扩展到非结构化网格数据（如AMR体积和点云）的应用。

Conclusion: 研究提出了一种将3D高斯模型应用于科学可视化中稀疏体积数据表示的新方法，并实现了一种高效的渲染算法。该方法不仅提高了数据压缩效率，还为处理不同类型的科学体积数据提供了一个统一的建模框架，并能扩展到更复杂的数据结构。

Abstract: 3D Gaussians are currently being heavily investigated for their scene
modeling and compression abilities. In 3D volumes, their use is being explored
for representing dense volumes as sparsely as possible. However, most of these
methods begin with a memory inefficient data format. Specially in Scientific
Visualization(SciVis), where most popular formats are dense-grid data
structures that store every grid cell, irrespective of its contribution.
OpenVDB library and data format were introduced for representing sparse
volumetric data specifically for visual effects use cases such as clouds, fire,
fluids etc. It avoids storing empty cells by masking them during storage. It
presents an opportunity for use in SciVis, specifically as a modeling framework
for conversion to 3D Gaussian particles for further compression and for a
unified modeling approach for different scientific volume types. This
compression head-start is non-trivial and this paper would like to present this
with a rendering algorithm based on line integration implemented in OptiX8.1
for calculating 3D Gaussians contribution along a ray for optical-depth
accumulation. For comparing the rendering results of our ray marching Gaussians
renderer, we also implement a SciVis style primary-ray only NanoVDB HDDA based
ray marcher for OpenVDB voxel grids. Finally, this paper also explores
application of this Gaussian model to formats of volumes other than regular
grids, such as AMR volumes and point clouds, using internal representation of
OpenVDB grid class types for data hierarchy and subdivision structure.

</details>


### [462] [3De Interactive Lenses for Visualization in Virtual Environments](https://arxiv.org/abs/2509.11410)
*Roberta C. R. Mota,Allan Rocha,Julio Daniel Silva,Usman Alim,Ehud Sharlin*

Main category: cs.GR

TL;DR: 3De lens是一种用于多几何图形数据的焦点+上下文可视化的技术，它融合了3D和Decal两种透镜，并将其应用于虚拟现实中，以实现自然的空间操控，用于探索性3D数据分析。


<details>
  <summary>Details</summary>
Motivation: 现有的3D可视化技术在处理和呈现同时存在的多种几何表示（如曲面和流线）时存在局限性，需要一种能够无缝处理这些不同表示的方法。

Method: 提出了一种名为3De lens的技术，该技术融合了3D透镜和Decal透镜，以实现对多几何图形数据的焦点+上下文可视化。并将该技术集成到虚拟现实环境中，以支持直接的空间操控。

Result: 3De lens技术能够为曲面和流线等多种几何表示创建定制化的可视化效果，并在两个领域示例中展示了其应用潜力。

Conclusion: 3De lens为3D可视化提供了一种有效的焦点+上下文方法，尤其是在处理多几何图形数据和利用虚拟现实进行交互式数据探索方面。

Abstract: We present 3De lens, a technique for focus+context visualization of
multi-geometry data. It fuses two categories of lenses (3D and Decal) to become
a versatile lens for seamlessly working on multiple geometric representations
that commonly coexist in 3D visualizations. In addition, we incorporate our
lens into virtual reality as it enables a natural style of direct spatial
manipulation for exploratory 3D data analysis. To demonstrate its potential
use, we discuss two domain examples in which our lens technique creates
customized visualizations of both surfaces and streamlines.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [463] [A novel IR-SRGAN assisted super-resolution evaluation of photothermal coherence tomography for impact damage in toughened thermoplastic CFRP laminates under room temperature and low temperature](https://arxiv.org/abs/2509.10894)
*Pengfei Zhu,Hai Zhang,Stefano Sfarra,Fabrizio Sarasini,Zijing Ding,Clemente Ibarra-Castanedo,Xavier Maldague*

Main category: physics.app-ph

TL;DR: 低温复合材料冲击损伤评估技术的研究。


<details>
  <summary>Details</summary>
Motivation: 评估低温复合材料的冲击损伤对于确保航空航天、极地和其他极端环境应用的结构完整性和可靠性至关重要。低温会增加基体脆性，导致损伤机制发生变化，从而影响材料的残余强度和疲劳寿命。因此，精确检测和量化损伤特征对于后续的力学表征和寿命预测至关重要。

Method: 提出了一种结合红外热成像（IRT）和频率多路光热相关断层扫描（FM-PCT）的新方法，用于捕获三维地下损伤特征，并开发了一种基于迁移学习的红外超分辨率生成对抗网络（IR-SRGAN）来提高成像保真度。

Result: 所提出的IR-SRGAN能够提高低温复合材料冲击损伤成像的横向和深度分辨率，克服了传统IRT技术的局限性。

Conclusion: 为了克服红外热成像技术在检测低温复合材料冲击损伤时存在的空间分辨率不足的问，本文提出了一种基于迁移学习的红外超分辨率生成对抗网络（IR-SRGAN），该方法能够提高成像的准确性。

Abstract: Evaluating impact-induced damage in composite materials under varying
temperature conditions is essential for ensuring structural integrity and
reliable performance in aerospace, polar, and other extreme-environment
applications. As matrix brittleness increases at low temperatures, damage
mechanisms shift: impact events that produce only minor delaminations at
ambient conditions can trigger extensive matrix cracking, fiber/matrix
debonding, or interfacial failure under severe cold loads, thereby degrading
residual strength and fatigue life. Precision detection and quantification of
subsurface damage features (e.g., delamination area, crack morphology,
interface separation) are critical for subsequent mechanical characterization
and life prediction. In this study, infrared thermography (IRT) coupled with a
newly developed frequency multiplexed photothermal correlation tomography
(FM-PCT) is employed to capture three-dimensional subsurface damage signatures
with depth resolution approaching that of X-ray micro-computed tomography.
However, the inherent limitations of IRT, including restricted frame rate and
lateral thermal diffusion, reduce spatial resolution and thus the accuracy of
damage size measurement. To address this, we develop a new transfer
learning-based infrared super-resolution generative adversarial network
(IR-SRGAN) that enhances both lateral and depth-resolved imaging fidelity based
on limited thermographic datasets.

</details>


### [464] [Thermal diffusivity characterization of impacted composites using evaporative cryocooling excitation and inverse physics-informed neural networks](https://arxiv.org/abs/2509.10898)
*Pengfei Zhu,Hai Zhang,Stefano Sfarra,Fabrizio Sarasini,Rubén Usamentiaga,Gunther Steenackers,Clemente Ibarra-Castanedo,Xavier Maldague*

Main category: physics.app-ph

TL;DR: 本文提出了一种结合蒸发致冷激发和反向物理信息神经网络（IPINNs）的新型热扩散率测量方法，用于评估受冲击复合材料。


<details>
  <summary>Details</summary>
Motivation: 受冲击复合材料的热扩散率测量是一个典型的失定性逆问题，易受样本厚度、冷却持续时间和激发能量等多种因素影响。现有脉冲方法在处理蒸发致冷这种长激发时间时存在挑战。

Method: 提出了一种新颖的蒸发致冷激发方法，并将其与反向物理信息神经网络（IPINNs）相结合，用于测量热扩散率。同时，采用Parker方法和光热法作为参照。为了提高精度，利用太赫兹时域光谱（THz-TDS）测量复合材料厚度。

Result: 通过模拟和实验验证，所提出的基于IPINN的方法在测量受冲击复合材料的热扩散率方面是可行的且准确的。

Conclusion: 结合蒸发致冷激发和IPINN是测量受冲击复合材料热扩散率的一种有效且精确的方法。

Abstract: The thermal diffusivity measurement of impacted composites using pulsed
methods presents an ill-posed inverse problem influenced by multiple factors
such as sample thickness, cooling duration, and excitation energy. In this
study, a novel excitation method, evaporative cryocooling, was introduced for
measuring the thermal diffusivity of tested samples. Compared to conventional
excitation modalities, evaporative cryocooling excitation is compact, portable,
and low cost. However, evaporative cryocooling cannot be considered a pulsed
method due to its prolonged excitation duration. In general, it is difficult to
measure thermal diffusivity based on non-impulsive pulsed excitation at times
commensurate with the pulse duration, often due to ill-defined pulse shape and
width and the subsequent potentially complicated thermal response which may be
subject to diffusive broadening. To address this challenge, inverse
physics-informed neural networks (IPINNs) were introduced in this work and
integrated with an evaporative cryocooling method. The Parker method combined
with a photothermal method was employed as a reference. To improve the accuracy
of both IPINNs and Parker methods, terahertz time-domain spectroscopy (THz-TDS)
was employed for measuring the thickness of impacted composites. Simulations
and experimental results demonstrated the feasibility and accuracy of the
IPINN-based approach.

</details>


### [465] [Real-Time Super-Resolution Imaging System Based on Zero-Shot Learning for Infrared Non-Destructive Testing](https://arxiv.org/abs/2509.10902)
*Pengfei Zhu,Ziang Wei,Ahmad Osman,Clemente Ibarra-Castanedo,Andreas Mandelis,Xavier Maldague,Hai Zhang*

Main category: physics.app-ph

TL;DR: 提出了一种基于零样本学习策略的实时超分辨率成像系统，用于非侵入式红外热成像和光热相干断层扫描技术，以克服热扩散问题并实现实时处理。


<details>
  <summary>Details</summary>
Motivation: 红外热成像（IRT）和光热相干断层扫描（PCT）在无损检测和生物医学领域具有潜力，但不可避免的热扩散严重影响了它们的灵敏度和分辨率。传统图像处理技术依赖于捕获完整的 thermal 序列，限制了实时处理能力。

Method: 提出了一种基于零样本学习策略的实时超分辨率成像系统，并使用红外热成像（IRT）系统测试了工业和生物医学样本，以及使用三维光热相干断层扫描（PCT）进行了验证。

Result: 所提出的系统在感兴趣区域（ROI）显示出高对比度，揭示了被热扩散隐藏的有价值信息。此外，三维光热相干断层扫描验证了该系统出色的去噪和去卷积能力。

Conclusion: 该实时超分辨率成像系统能够有效克服热扩散问题，提高IRT和PCT的灵敏度和分辨率，并具备出色的去噪和去卷积能力，有望在无损检测和生物医学领域得到应用。

Abstract: Infrared thermography (IRT) and photothermal coherence tomography (PCT)
exhibit potential in non-destructive testing and biomedical fields. However,
the inevitable heat diffusion significantly affects the sensitivity and
resolution of IRT and PCT. Conventional image processing techniques rely on
capturing complete thermal sequences, which limits their ability to achieve
real-time processes. Here, we construct a real-time super-resolution imaging
system based on zero-shot learning strategy for the non-invasive infrared
thermography and photothermal coherence tomography techniques. To validate the
feasibility and accuracy of this super-resolution imaging system, IRT systems
were employed to test several industrial samples and one biomedical sample. The
results demonstrated high contrast in the region of interest (ROI) and
uncovered valuable information otherwise obscured by thermal diffusion.
Furthermore, three-dimensional photothermal coherence tomography was used to
validate the excellent denoising and deconvolution capabilities of the proposed
real-time super-resolution imaging system.

</details>


### [466] [Preparation of the First Cu-based Nb$_3$Sn Sample via Bronze Route for Quadrupole Resonator Testing](https://arxiv.org/abs/2509.11224)
*Ming Lu,Sebastian Keckert,Felix Kramer,Alena Prudnikava,Jens Knobloch,Aleksandr Zubtsovskii,Oliver Kugeler*

Main category: physics.app-ph

TL;DR: 成功制备了用于四极谐振腔(QPR)测试的铜基Nb3Sn样品，这是在铜基底上实现Nb3Sn可扩展射频超导涂层的重要一步。


<details>
  <summary>Details</summary>
Motivation: 为了在铜基底上实现高质量Nb3Sn薄膜的制备，解决了长期存在的制造挑战。

Method: 采用优化的铜基Nb3Sn样品制备方法，包括铜基底的电解抛光、青铜前驱层电镀、约700°C的定制热处理以及新的化学蚀刻工艺。

Result: 制备的样品通过QPR测量，得到了表面电阻率（Rs）与磁场和温度的关系，以及超导转变温度和失超场。在4.5 K和15 mT下，最小Rs为43.4 nΩ。

Conclusion: 该方法证明了在铜基底上制备Nb3Sn涂层的可行性，并且通过工艺优化具有进一步提升的潜力。

Abstract: We report the first successful production of a Cu-based Nb$_3$Sn sample
specifically designed for Quadrupole Resonator (QPR) testing, representing a
significant step toward scalable RF superconducting coatings of Nb$_3$Sn on
copper substrates. The sample was fabricated using an optimized electrochemical
thermal synthesis (ETS) via the bronze route, incorporating several key
advancements: electropolishing of the Cu substrate, electroplating of the
bronze precursor layer, a tailored heat treatment at approximately 700
$^\circ$C to promote grain growth and suppress tin-rich impurity phases, and a
newly developed chemical etching procedure for effective removal of surface
bronze residues and contaminants. These improvements address longstanding
challenges in the fabrication of high-quality Cu-based Nb$_3$Sn thin films.
Subsequent QPR measurements yielded the peak magnetic field and temperature
dependent surface resistance $R_s$, as well as the superconducting transition
temperature and quench field. Although the achieved RF performance --
characterized by a minimum $R_s$ of 43.4 n$\Omega$ at 4.5 K and 15 mT -- is not
yet optimal, the results clearly demonstrate the feasibility of this approach
and its potential for further enhancement through process refinement.

</details>


### [467] [Rydberg atom reception of a handheld UHF frequency-modulated two-way radio](https://arxiv.org/abs/2509.11363)
*Noah Schlossberger,Tate McDonald,Nikunjkumar Prajapati,Christopher L. Holloway*

Main category: physics.app-ph

TL;DR: 利用里德堡原子探测了现实世界中的调频音频信号，并展示了其在通信接收方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将里德堡原子传感器在实验室信号探测的局限性中扩展到实际应用，并验证其接收现实世界调频音频信号的能力。

Method: 通过里德堡原子蒸气中的交流斯塔克效应来探测由射频信号引起的斯塔克位移，并使用频率偏移的本地振荡器和锁定放大技术进行解调。

Result: 成功解调了语音信号，评估了音频频谱响应和接收范围，并展示了同时探测所有消费级射频频道以及两个相邻频道（至少53 dB隔离度）的能力。

Conclusion: 本研究表明，基于里德堡原子的接收器在实际的、现实世界的调频信号探测方面具有巨大潜力。

Abstract: Rydberg atoms, due to their large polarizabilities and strong transition
dipole moments, have been utilized as sensitive electric field sensors. While
their capability to detect modulated signals has been previously demonstrated,
these studies have largely been limited to laboratory-generated signals
tailored specifically for atomic detection. Here, we extend the practical
applicability of Rydberg sensors by demonstrating the reception of real-world
frequency-modulated (FM) audio transmissions using a consumer-grade handheld
two-way radio operating in the UHF band. Detection is based on the AC Stark
shift induced by the radio signal in a Rydberg atomic vapor, with demodulation
performed using an offset local oscillator and lock-in amplification. We
successfully demodulate speech signals and evaluate the audio spectral response
and reception range. We show that all consumer-accessible radio channels can be
simultaneously detected, and demonstrate simultaneous reception of two
neighboring channels with at least 53 dB of isolation. This work underscores
the potential of Rydberg atom-based receivers for practical, real-world FM
signal detection.

</details>


### [468] [Chromatic and Spherical Aberration Correction with Hexapole and Quadrupole Fields](https://arxiv.org/abs/2509.11458)
*Shigeyuki Morishita,Hidetaka Sawada,Norihiro Okoshi,Shunsaku Waki,Hironori Tanaka,Katsunori Ichikawa,Angus Kirkland*

Main category: physics.app-ph

TL;DR: 该论文设计了一种结合了六极和四极场的新型色差和球差校正器，用于提高显微镜分辨率。


<details>
  <summary>Details</summary>
Motivation: 为了同时校正色差和球差，从而提高显微镜的分辨率，特别是在能量展宽是限制因素的情况下。

Method: 提出了一种新型校正器设计，该设计结合了厚六极场和四极多极透镜。六极场用于产生负球差并校正残余轴向和离轴像差。四极多极透镜用于产生负色差，并作为校正器内的转移双联镜。

Result: 该校正器能够同时校正色差和球差，并在能量展宽受限的情况下提高了分辨率。

Conclusion: 所提出的校正器设计能够有效地同时校正色差和球差，并在能量展宽限制的情况下显著提高显微镜的分辨率。

Abstract: We report the development of a chromatic and spherical aberration corrector
based on a combination of hexapole and quadrupole fields. Thick hexapole fields
are used to generate negative spherical and to correct residual axial and
off-axial aberrations. However, instead of using round transfer lenses placed
between the hexapoles, a quadrupole multiplet producing superimposed electric
and magnetic quadrupole fields is used to produce negative chromatic
aberration. The quadrupole multiplet also functions as a transfer doublet
within the corrector. In this paper, the simultaneous correction of chromatic
and spherical aberrations using this corrector design is described and we
demonstrate a resolution improvement in cases where the energy spread is
limiting.

</details>


### [469] [Nanomechanical Error Correction](https://arxiv.org/abs/2509.11560)
*Xiaoya Jin,Christopher G. Baker,Erick Romero,Nishta Arora,Nicolas P. Mauranyapin,Timothy M. F. Hirsch,Glen I. Harris,Warwick P. Bowen*

Main category: physics.app-ph

TL;DR: Error correction emerges in a three-coupled nonlinear resonator system, reducing error rates by 35x and enabling robust nanomechanical computing.


<details>
  <summary>Details</summary>
Motivation: Error correction is crucial for accurate information processing in computing systems, and this paper aims to demonstrate a novel approach using nonlinear dynamics.

Method: The study exploits an error-correcting phase emerging in a system of three coupled nonlinear resonators, where perturbed memory states are restored by the collective dynamics of the network. This scheme is implemented using nanomechanical resonators.

Result: Experimental results show a 35-fold reduction in error rates due to the error-correcting phase, with robust performance across a wide range of system parameters.

Conclusion: The paper concludes that emergent nonlinear dynamics can be utilized for practical applications, specifically paving the way for error-resilient nanomechanical computing.

Abstract: Error correction is essential for modern computing systems, enabling
information to be processed accurately even in the presence of noise. Here, we
demonstrate a new approach which exploits an error correcting phase that
emerges in a system of three coupled nonlinear resonators. Within this phase,
perturbed memory states are autonomously restored via the collective dynamics
of the nonlinear network. We implement our scheme using a network of
nanomechanical resonators. Nanomechanical systems are an attractive platform
for low energy computing, but purely mechanical error correction has not been
previously demonstrated. We experimentally show that the error correcting phase
provides a 35 times reduction in the rate of errors, and allows robust error
correction over a wide range of system parameters. These results highlight how
emergent nonlinear dynamics can be harnessed for practical applications, paving
the way towards error-resilient nanomechanical computing.

</details>


### [470] [Time-series Neutron Tomography of Rhizoboxes](https://arxiv.org/abs/2509.11935)
*A. P. Kaestner,S. Di Bert,R. Jia,P. Benard,A. Carminati*

Main category: physics.app-ph

TL;DR: 该研究探索了倾斜系列中子断层扫描技术在根系-土壤相互作用研究中对根箱的可行性，克服了传统中子成像的局限性，并成功重建了根系网络，同时展示了研究根系-土壤动态相互作用的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统中子成像方法在根系生长体积和土壤水分穿透方面存在局限性，本研究旨在探索一种新的成像方法来克服这些限制。

Method: 采用垂直采集轴的倾斜系列中子断层扫描技术，同时获取放射线和断层扫描数据，并重建了六周玉米植物的根系网络。

Result: 倾斜系列断层扫描技术能够有效重建根系网络，尽管存在缺失楔形伪影，但可以定性地揭示水分分布的变化，而放射线数据对于定量分析仍然是必要的。

Conclusion: 倾斜系列中子断层扫描技术为根系-土壤相互作用研究提供了一种有潜力的动态分析工具，能够提供关于根际的全面见解，在农业和环境研究中具有应用价值。

Abstract: This study investigates the feasibility of tilt-series neutron tomography for
analyzing rhizoboxes used in root-soil interaction studies. Traditional neutron
imaging methods are limited by constrained root growth volumes and poor
penetration in moist soil. Using a vertical acquisition axis, the tilt-series
approach avoids constraints typical of laminography. This method allows
simultaneous radiographic and tomographic data acquisition, enhancing time
resolution and providing detailed insights into root networks and soil water
content. Experiments involved scanning six-week-old maize plants in rhizoboxes
filled with sand. Results show that tilt-series tomography can effectively
reconstruct root networks despite some artifacts from the missing wedge. While
the tilt-series tomographic data qualitatively reveal water distribution
changes, radiographic data remain essential for quantitative analysis. This
approach demonstrates the potential for dynamic root-soil interaction studies,
offering a valuable tool for agricultural and environmental research by
providing comprehensive insights into the rhizosphere.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [471] [Reinforcement Learning for Quantum Network Control with Application-Driven Objectives](https://arxiv.org/abs/2509.10634)
*Guo Xian Yau,Alexandra Burushkina,Francisco Ferreira da Silva,Subhransu Maji,Philip S. Thomas,Gayane Vardoyan*

Main category: quant-ph

TL;DR: 该研究提出了一种新的强化学习框架，用于优化量子网络的非线性目标函数，以应对硬件限制和经典通信延迟的挑战。


<details>
  <summary>Details</summary>
Motivation: 为实现具有严格性能要求的分布式量子应用，需要对量子网络进行优化控制，尤其是在硬件受限的近期架构中，有效的控制对于部署这些应用至关重要。

Method: 提出了一种新的强化学习框架，该框架可以直接优化非线性的、可微的目标函数，并能考虑经典通信延迟引入的不确定性。该框架在两个配备了多路复用能力的量子网络节点之间的纠缠蒸馏场景中进行了评估。

Result: 在某些参数范围内，该框架发现的策略优于启发式基线。

Conclusion: 这项工作是利用强化学习优化量子网络中的非线性目标函数的初步尝试，为更高级的应用场景开辟了道路。

Abstract: Optimized control of quantum networks is essential for enabling distributed
quantum applications with strict performance requirements. In near-term
architectures with constrained hardware, effective control may determine the
feasibility of deploying such applications. Because quantum network dynamics
are suitable for being modeled as a Markov decision process, dynamic
programming and reinforcement learning (RL) offer promising tools for
optimizing control strategies. However, key quantum network performance
measures -- such as secret key rate in quantum key distribution -- often
involve a non-linear relationship, with interdependent variables that describe
quantum state quality and generation rate. Such objectives are not easily
captured by standard RL approaches based on additive rewards. We propose a
novel RL framework that directly optimizes non-linear, differentiable objective
functions, while also accounting for uncertainties introduced by classical
communication delays. We evaluate this framework in the context of entanglement
distillation between two quantum network nodes equipped with multiplexing
capability, and find that, in certain parameter regimes, it discovers policies
that outperform heuristic baselines. Our work comprises the first step towards
non-linear objective function optimization in quantum networks with RL, opening
a path towards more advanced use cases.

</details>


### [472] [Finding Photonics Circuits via $δ$-weakening SMT](https://arxiv.org/abs/2509.11678)
*Marco Lewis,Benoît Valiron*

Main category: quant-ph

TL;DR: 提出一个使用dReal工具来自动合成和优化光量子计算电路的方法，并以Givens旋转门为例进行了演示。


<details>
  <summary>Details</summary>
Motivation: 光量子计算电路的合成是一个关键问题，现有方法在可复用性方面存在不足。

Method: 使用dReal（一个{\delta}-weakening SMT solver）来寻找能模拟量子门的光子电路，并优化成功概率，同时提供最优性保证。

Result: 通过重现文献中的已知结果，扩展现有成果，并为Givens旋转门提供了新的结果。

Conclusion: 所提出的工具能够有效地合成和优化光量子计算电路，并具有最优性保证，为相关研究提供了新的方法和结果。

Abstract: For quantum computers based on photonics, one main problem is the synthesis
of a photonic circuit that emulates quantum computing gates. The problem
requires using photonic components to build a circuit that act like a quantum
computing gate with some probability of success. This involves not only finding
a circuit that can correctly act like a quantum gate, but also optimizing the
probability of success. Whilst many approaches have been given in the past and
applied to specific gates, they often lack ease of reusability. We present a
tool that uses dReal, a {\delta}-weakening SMT solver, to find such photonic
circuits, optimize the likelihood of occurring, and provide some guarantee that
the result is optimal. We demonstrate the usage of our tool by recreating known
results in the literature, extending upon them, and presenting new results for
Givens rotation gates.

</details>


### [473] [Boosting Sparsity in Graph Decompositions with QAOA Sampling](https://arxiv.org/abs/2509.10657)
*George Pennington,Naeimeh Mohseni,Oscar Wallis,Francesca Schiavello,Stefano Mensa,Corey O'Meara,Giorgio Cortiana,Víctor Valls*

Main category: quant-ph

TL;DR: 本研究提出了一种混合量子-经典算法E-FCFW，用于将图分解为少量图匹配的加权和，解决了网络资源分配中的难题。


<details>
  <summary>Details</summary>
Motivation: 网络资源分配问题（如P2P能量交换）中存在将图分解为加权图匹配和的需求，但经典算法难以解决。

Method: 提出了一种基于全修正Frank-Wolfe（FCFW）算法的混合量子-经典算法E-FCFW，并设计了可经典或量子实现的匹配采样子程序（使用QAOA），以获得解决方案的多样性。

Result: 在不同规模和类型的图（完全图、二分图、重六边形图）上进行了实验，与随机采样和模拟退火等方法相比，E-FCFW（使用QAOA）在稀疏分解和近似误差方面表现更优。

Conclusion: 量子子程序在经典算法中具有重要应用前景。

Abstract: We study the problem of decomposing a graph into a weighted sum of a small
number of graph matchings. This problem arises in network resource allocation
problems such as peer-to-peer energy exchange, and it is challenging to solve
with current classical algorithms even for small instances. To address this
problem, we propose a hybrid quantum-classical algorithm, E-FCFW, based on the
Fully-Corrective Frank-Wolfe (FCFW) algorithm. In particular, E-FCFW extends
FCFW by incorporating a matching-sampling subroutine that can be carried out
classically or with a quantum approach. We show how to design such a subroutine
using QAOA, which aims at solving a constrained discrete optimisation problem
approximately to obtain solution-variety. We benchmark our approach on
complete, bipartite, and heavy-hex graphs, conducting experiments using the
Qiskit Aer state-vector simulator (9-25 qubits), the Qiskit Aer MPS simulator
(52-76 qubits) and on IBM Kingston (52-111 qubits), demonstrating performance
at a utility-scale quantum hardware level. Our results show that E-FCFW with
QAOA consistently yields sparser decompositions (mean and median) than the
other methods (random sampling and simulated annealing) for small complete and
bipartite graphs. For large heavy-hex graphs with 50 and 70 nodes, E-FCFW with
QAOA also outperforms the other methods in terms of approximation error. Our
findings highlight a promising role for quantum subroutines in classical
algorithms.

</details>


### [474] [Nonclassical Driven-Dissipative Dynamics in Collective Quantum Optics](https://arxiv.org/abs/2509.10672)
*Alejandro Vivas-Viaña*

Main category: quant-ph

TL;DR: 本论文研究了光与物质相互作用的集体现象，特别是相干驱动下相互作用的量子发射体与光子结构的耦合。研究了双发射器系统的超辐射和次辐射态，以及双光子共振在其中起到的关键作用。研究结果表明，这种非线性过程能够开辟光-物质物理学的新领域，并对量子计量学具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 探索量子发射体、相干驱动和光子环境之间的相互作用所产生的集体量子现象。

Method: 对两个非相同的、被建模为双能级系统的量子发射体进行了研究，它们通过光子结构相互作用并受到激光场的相干驱动。研究了强相互作用形成的二聚体，以及双光子共振。

Result: 分析了相互作用如何改变可观测的量，如发射强度、光子统计和光谱。发现双光子过程对发射体距离和驱动强度的敏感性可用于高精度传感和亚波长成像。提出了一种用于处理亚稳态动力学的分级绝热消除方法，并分析了发射体与损耗腔耦合时的纠缠。

Conclusion: 该研究提出的模型适用于量子点和分子聚集体等固态平台，并考虑了不均匀展宽和退相干等挑战，证明了利用光-物质集体效应实现量子技术的可能性。

Abstract: Reduced abstract. This Thesis explores emergent cooperative phenomena in
collective light-matter systems. We study ensembles of interacting quantum
emitters coherently driven by a laser field and coupled to photonic structures,
focusing on the hybrid description of emitters dressed by light. The interplay
among quantum emitters, coherent driving, and photonic environments reveals a
rich landscape of cooperative effects. While single-emitter dressing has been
widely studied, we address collective phenomena in two non-identical emitters
modelled as two-level systems. Strong interaction forms a dimer exhibiting
superradiant and subradiant states, with two-photon resonances directly
connecting ground and doubly excited states. This nonlinear process, central to
the Thesis, enables new regimes of cooperative light-matter physics. Analytical
studies show how interactions reshape observables such as emission intensity,
photon statistics, and spectra, offering implications for quantum metrology.
The sensitivity of two-photon processes to emitter distance and driving
strength enables high-precision sensing and sub-wavelength imaging.
Unexpectedly, we find that off-resonant virtual states may gain population
through dissipation, redefining their role in open systems. To capture this, we
develop a hierarchical adiabatic elimination method for metastable dynamics. We
also analyze entanglement in emitters coupled to a lossy cavity, identifying
five mechanisms, including the frequency-resolved Purcell effect introduced
here. This selective enhancement stabilizes cooperative states and enables
scalable entanglement. Our models, tailored to solid-state platforms such as
quantum dots and molecular aggregates, address challenges like inhomogeneous
broadening and decoherence, demonstrating the feasibility of harnessing
cooperative light-matter effects for quantum technologies.

</details>


### [475] [A Realist Approach to Quantum Individuality: Against the "Received" and "Alternative" Views](https://arxiv.org/abs/2509.10680)
*Christian de Ronde,Ivan Klarreich*

Main category: quant-ph

TL;DR: 该论文探讨了量子个体性的当代争论，比较了


<details>
  <summary>Details</summary>
Motivation: 该论文旨在分析量子个体性的当代争论，探讨 Krause 和 Dieks 的观点，并提出一种新的实在论理解。

Method: 通过分析 Krause 和 Dieks 的观点，指出其共同的保守方法论，并引入一种新的基于爱因斯坦方法论的相对论性客观关系方法。

Result: 分析了 Krause 和 Dieks 观点之间的共同点，并提出了一种新的量子个体性理解方法。

Conclusion: 指出现有的量子个体性理论（包括 Krause 和 Dieks 的观点）都受到经典概念的影响，并提出了一种新的、更具实在论意义的量子个体性理解的可能性。

Abstract: In this work we address the contemporary debate about quantum individuality
expressed as an opposition between those who, like D\'ecio Krause, defend the
reference of the theory to "non-individual particles", and those like Dennis
Dieks, who propose instead to preserve the notion of "classical particle" as
commonly applied by contemporary physicists. We will argue that these
viewpoints rather than truly opposed share a common methodology which has
helped to reinforce the doctrine of classical concepts that was imposed by Bohr
and Dirac within the "standard" formulation --which remains the orthodox
physical account of the theory of quanta. We will also discuss a recently
proposed relativist yet objective relational account of quantum individuality
[25] which, going back to Einstein's methodological approach, opens the doors
to a completely new, truly realist understanding of quantum individuality.

</details>


### [476] [Stabilizer-Shannon Renyi Equivalence: Exact Results for Quantum Critical Chains](https://arxiv.org/abs/2509.10700)
*M. A. Rajabpour*

Main category: quant-ph

TL;DR: We established an exact correspondence between Shannon-Renyi and stabilizer entropies for quadratic fermions, mapping stabilizer entropies of Gaussian eigenstates to Shannon-Renyi entropies of free-fermion eigenstates on a doubled system. This allows derivation of closed-form expressions and conformal-field-theory scaling laws for stabilizer entropies in critical free-fermion systems, exemplified by the transverse-field Ising chain.


<details>
  <summary>Details</summary>
Motivation: The paper aims to establish a connection between Shannon-Renyi and stabilizer entropies for quadratic fermions, which are important for understanding quantum many-body states, phase transitions, and universality. This connection is expected to enable the derivation of new results and insights into these systems.

Method: The paper establishes an exact correspondence for quadratic fermions, relating stabilizer Renyi entropy to Shannon-Renyi entropy of a number-conserving free-fermion eigenstate on a doubled system. They specialize this to the transverse-field Ising (TFI) chain and use this correspondence, along with other proven identities, to derive closed expressions for stabilizer entropy at specific indices and conformal-field-theory scaling laws.

Result: An exact correspondence was established between Shannon-Renyi and stabilizer entropies for Gaussian eigenstates of quadratic fermions. Closed-form expressions for stabilizer entropy at $\alpha=\frac{1}{2},2,4$ were derived for critical closed free-fermion systems, and conformal-field-theory scaling laws for stabilizer entropy were obtained for both periodic and open boundaries at arbitrary Renyi index.

Conclusion: The established correspondence provides a powerful tool for analyzing stabilizer entropies in quadratic fermionic systems. It allows for the derivation of exact results and scaling laws, deepening our understanding of critical phenomena and quantum many-body physics in these systems, with specific applications to the TFI chain and other free-fermion models.

Abstract: Shannon-Renyi and stabilizer entropies are key diagnostics of structure,
non-stabilizerness, phase transitions, and universality in quantum many-body
states. We establish an exact correspondence for quadratic fermions: for any
nondegenerate Gaussian eigenstate, the stabilizer Renyi entropy equals the
Shannon-Renyi entropy of a number-conserving free-fermion eigenstate on a
doubled system, evaluated in the computational basis. Specializing to the
transverse-field Ising (TFI) chain, the TFI ground state stabilizer entropies
maps to the Shannon-Renyi entropies of the XX-chain ground state of length
$2L$. Building on this correspondence, together with other exact identities we
prove, closed expressions for the stabilizer entropy at indices
$\alpha=\frac{1}{2},2,4$ for a broad class of critical closed free-fermion
systems were derived. Each of these can be written with respect to the
universal functions of the TFI chain. We further obtain conformal-field-theory
scaling laws for the stabilizer entropy under both periodic and open boundaries
at arbitrary Renyi index for these critical systems.

</details>


### [477] [Parameter estimation with uncertainty quantification from continuous measurement data using neural network ensembles](https://arxiv.org/abs/2509.10756)
*Amanuel Anteneh*

Main category: quant-ph

TL;DR: 深度集成模型可用于量子参数估计，提供不确定性量化，并且比贝叶斯推断需要更少的数据。


<details>
  <summary>Details</summary>
Motivation: 量子参数估计需要一种能够量化不确定性的方法，类似于贝叶斯推断的优势。此外，需要提高模型对噪声的鲁棒性，并减少所需数据量。

Method: 使用深度集成（深度神经网络的集成）模型进行量子参数估计。

Result: 深度集成模型在量子参数估计方面表现良好，能够量化不确定性。这些模型对测量噪声和训练数据噪声具有更强的鲁棒性。与之前的提议相比，它们在达到可比性能时所需的数据量大大减少，并且可以与贝叶斯推断在达到精度极限时相媲美。

Conclusion: 深度集成模型为量子参数估计提供了一种有效且鲁棒的方法，具有不确定性量化能力，并且在数据效率方面优于传统方法。

Abstract: We show that ensembles of deep neural networks, called deep ensembles, can be
used to perform quantum parameter estimation while also providing a means for
quantifying uncertainty in parameter estimates, which is a key advantage of
using Bayesian inference for parameter estimation. These models are shown to be
more robust to noise in the measurement results used to perform the parameter
estimation as well as noise in the data used to train them. We also show that
much less data is needed to achieve comparable performance to Bayesian
inference based estimation, which is known to reach the ultimate precision
limit as more data is collected, than was used in previous proposals.

</details>


### [478] [Moments-based quantum computation of the electric dipole moment of molecular systems](https://arxiv.org/abs/2509.10758)
*Michael A. Jones,Harish J. Vallury,Manolo C. Per,Harry M. Quiney,Lloyd C. L. Hollenberg*

Main category: quant-ph

TL;DR: IBM Quantum设备上的量子计算偶极矩的计算。


<details>
  <summary>Details</summary>
Motivation: 研究当前和近期量子设备在量子化学计算领域的应用，特别是计算分子的非基态性质，如电偶极矩。

Method: 使用基于Lanczos簇展开的量子计算偶极矩（QCM）方法，在IBM Quantum超导量子设备上估算水分子的偶极矩。

Result: 与全组态相互作用（FCI）计算相比，经过噪声抑制的QCM方法结果误差在0.03 ± 0.007德拜（2% ± 0.5%）范围内；而直接使用变分量子算法（VQE）的误差约为0.07德拜（5%），即使在没有噪声的情况下也是如此。

Conclusion: 基于偶极矩的能量估算技术可以应用于化学系统的非能量基态性质的噪声鲁棒评估。

Abstract: With rapid progress being made in the development of platforms for quantum
computation, there has been considerable interest in whether present-day and
near-term devices can be used to solve problems of relevance. A commonly cited
application area is the domain of quantum chemistry. While most experimental
demonstrations of quantum chemical calculations on quantum devices have focused
on the ground-state electronic energy of the system, other properties of the
ground-state, such as the electric dipole moment, are also of interest. Here we
employ the quantum computed moments (QCM) method, based on the Lanczos cluster
expansion, to estimate the dipole moment of the water molecule on an IBM
Quantum superconducting quantum device. The noise-mitigated results agree with
full configuration interaction (FCI) calculations to within 0.03 $\pm$ 0.007
debye (2% $\pm$ 0.5%), compared to direct expectation value determination (i.e.
VQE) with errors on the order of 0.07 debye (5%), even when the VQE calculation
is performed without noise. This demonstrates that moments-based energy
estimation techniques can be adapted to noise-robust evaluation of
non-energetic ground-state properties of chemical systems.

</details>


### [479] [Patterning programmable spin arrays on DNA origami for quantum technologies](https://arxiv.org/abs/2509.10760)
*Zhiran Zhang,Taylor Morrison,Lillian Hughes,Weijie Wu,Ruiyao Liu,Dolev Bluvstein,Norman Yao,Deborah Fygenson,Ania C. Bleszynski Jayich*

Main category: quant-ph

TL;DR: The paper demonstrates a method to precisely assemble solid-state spins using DNA origami, enabling the creation and sensing of programmable 2D spin arrays with potential applications in quantum technology, sensing, and simulation.


<details>
  <summary>Details</summary>
Motivation: The controlled assembly of solid-state spins with nanoscale spatial precision is a critical challenge for advancing quantum technology.

Method: The researchers combined DNA origami for patterning with nitrogen-vacancy (NV) ensemble quantum sensors in diamond. DNA origami was used to control the spacing of chelated Gd$^{3+}$ spins, and the number of spins was verified by measuring the relaxation rate ($1/T_1$) of proximal NVs. The study also confirmed that DNA origami preserves the charge state and spin coherence of shallow NV centers.

Result: The study successfully formed and sensed programmable 2D arrays of spins using DNA origami and NV quantum sensors. A linear relationship between the relaxation rate of proximal NVs and the number of Gd$^{3+}$ spins per origami unit was observed, validating the DNA origami's effectiveness in controlling spin spacing. The functionalization of the diamond surface with spins via DNA origami was shown to be robust, preserving the properties of nearby NV centers.

Conclusion: This work enables the formation and interrogation of ordered, strongly interacting spin networks. It opens up possibilities for applications in quantum sensing, quantum simulation, entanglement-enhanced metrology, and high-throughput proteomics.

Abstract: The controlled assembly of solid-state spins with nanoscale spatial precision
is an outstanding challenge for quantum technology. Here, we combine DNA-based
patterning with nitrogen-vacancy (NV) ensemble quantum sensors in diamond to
form and sense programmable 2D arrays of spins. We use DNA origami to control
the spacing of chelated Gd$^{3+}$ spins, as verified by the observed linear
relationship between proximal NVs' relaxation rate, $1/T_1$, and the engineered
number of Gd$^{3+}$ spins per origami unit. We further show that DNA origami
provides a robust way of functionalizing the diamond surface with spins as it
preserves the charge state and spin coherence of proximal, shallow NV centers.
Our work enables the formation and interrogation of ordered, strongly
interacting spin networks with applications in quantum sensing and quantum
simulation. We quantitatively discuss the prospects of entanglement-enhanced
metrology and high-throughput proteomics.

</details>


### [480] [Quantum-Assisted Recursive Algorithm for Solving the Exact Cover Problem](https://arxiv.org/abs/2509.10811)
*Xiao-Hui Ni,Jia-Cheng Fan,Ling-Xiao Li,Zi-Wen Huang,Su-Juan Qin,Bing-Jie Xu,Wei-Huang,Fei Gao*

Main category: quant-ph

TL;DR: QAOA在处理精确覆盖问题时，虽然深度越深，解的质量越高，但会限制其在嘈杂中等规模量子设备上的应用。本文提出了一种量子辅助递归算法（QARA），在浅层深度下提高了求解质量。QARA通过交替应用经典和量子剪枝来解决该问题。当经典剪枝无法简化问题时，调用量子剪枝，并从QAOA的输出状态中提取信息，以识别具有最强选择偏差的子集，然后根据问题定制的约简规则来剪枝问题。此外，QARA还包含一个局部的验证和回滚机制，以辅助判断量子剪枝的有效性。在数值模拟中，QARA在一层深度下处理140个实例，子集大小从8到20不等。结果表明，QARA找到精确解的概率比QAOA和递归QAOA高出约60%，证明了其效率。


<details>
  <summary>Details</summary>
Motivation: 精确覆盖问题是一个NP完全问题，有广泛的应用。QAOA虽然能提高解的质量，但对量子设备有要求。需要一种在浅层深度下就能提高解的质量的算法。

Method: 本文提出了一种量子辅助递归算法（QARA），通过交替应用经典剪枝和量子剪枝来解决精确覆盖问题。量子剪枝利用QAOA的输出状态来识别并剪枝问题。

Result: 在数值模拟中，QARA在一层深度下处理140个实例，子集大小从8到20不等。QARA找到精确解的概率比QAOA和递归QAOA高出约60%。

Conclusion: QARA在浅层深度下比QAOA和递归QAOA在解决精确覆盖问题时更有效。

Abstract: The exact cover problem is an NP-complete problem with broad applications.
Studies show that although applying the Quantum Approximate Optimization
Algorithm (QAOA) to this problem can yield improved solution quality with
deeper circuit depth, it can limit the algorithm's applicability on noisy
intermediate-scale quantum devices. To improve solution quality at shallow
depth, we propose a Quantum-Assisted Recursive Algorithm (QARA) for solving the
exact cover problem. QARA addresses the problem by alternately applying
classical and quantum pruning. Classical pruning is a repeatable pre-processing
step to simplify the problem. When the classical pruning cannot promote the
problem simplification, quantum pruning is invoked. During quantum pruning,
QARA extracts information from the QAOA's output state to identify the subset
with the strongest selection bias. This subset is then used to prune the
problem based on our problem-tailored reduction rules. Furthermore, QARA
incorporates a local verification and rollback mechanism to assistively judge
the effectiveness of the quantum simplification. After quantum pruning,
classical pruning is applied again to the reduced problem if the remaining
subsets and element set are not null. This alternating process repeats until
the original problem is fully resolved. In our numerical simulations, we
evaluate the performance of QARA at one-layer depth on 140 instances with
subset sizes ranging from 8 to 20. Numerical results show that the probability
of QARA in finding an exact solution is approximately 60\% higher than that of
both QAOA and Recursive QAOA, highlighting its efficiency.

</details>


### [481] [Simulating and Learning Quantum Evolution: A CTQW-ML Framework](https://arxiv.org/abs/2509.10821)
*Rachana Soni,Navneet Pratap Singh*

Main category: quant-ph

TL;DR: 提出一种利用连续时间量子行走模拟薛定谔方程的方法，并结合监督神经网络来预测波函数模的平方，结果表明该方法能准确地再现量子系统的定性结构和时间演化。


<details>
  <summary>Details</summary>
Motivation: 提出一种利用连续时间量子行走模拟薛定谔方程并结合机器学习预测波函数模的方法。

Method: 使用连续时间量子行走模拟薛定谔方程，并实现监督神经网络来预测波函数模的平方。

Result: 机器学习模型能够以高精度再现量子系统的定性结构和时间演化。

Conclusion: 结合量子行走模拟和机器学习为求解量子动力学方程提供了一种有效的方法。

Abstract: We present an approach to simulate the Schr\"odinger equation through
continuous time quantum walks. The CTQW-based simulation applies unitary
evolution driven by a quantum walk to generate probability amplitude
distributions at various time steps. Additionally, we implemented a supervised
neural network model to evaluate the effectiveness of data-driven techniques.
The model learns to predict the squared modulus of the wavefunction given
spatial and temporal coordinates. A comparative analysis demonstrates that the
ML model can reproduce the qualitative structure and temporal progression of
the quantum system with high accuracy. This study provides the synergy between
quantum walk-based simulation and machine learning for solving quantum
dynamical equations.

</details>


### [482] [Hermitian vs non-Hermitian quantum thermometry](https://arxiv.org/abs/2509.10840)
*Anass Hminat,Abdallah Slaoui,Rachid Ahl Laamara,Mourad Telmini*

Main category: quant-ph

TL;DR: 该研究提出了一种利用量子比特的退相干动力学来估计环境温度的新方法，并探讨了对称性对信息提取和量子信息存储的影响。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于开发一种不依赖于与系统达到热平衡的量子方法来估计环境温度，并探索对称性在量子信息处理中的作用。

Method: 通过研究量子比特的退相干动力学，并优化量子费舍尔信息，以获得关于环境温度的精确估计。同时，研究了对称性对信息提取和量子信息存储鲁棒性的影响，特别关注了具有非厄米特性的系统。

Result: 研究发现，最优估计源于量子比特退相干动力学与环境欧姆特性之间的复杂相互作用，特别是在非厄米特系统中，表现出对退相干的增强抵抗力。最优估计并非发生在量子比特达到稳态或完全退相干的情况下。

Conclusion: 该方法为环境温度测量提供了一种新的量子途径，并强调了对称性在提高量子信息处理精度和鲁棒性方面的重要性，尤其是在非厄米特系统中。

Abstract: We investigate the dephasing dynamics of a qubit as an effective mechanism
for estimating the temperature of its surrounding environment for different
symmetrizes. Our approach is fundamentally quantum, leveraging the qubit's
susceptibility to decoherence without necessitating thermal equilibrium with
the system under study. We also examine how symmetry properties affect the
accuracy of information retrieval and the robustness of quantum information
storage in such systems, highlighting their potential advantages in mitigating
decoherence effects. The optimization of quantum Fisher information is
performed with respect to both the interaction duration and the environmental
temperature, focusing on Ohmic-like spectral density environments. Furthermore,
we explicitly identify the optimal qubit measurement that attains the quantum
Cramer-Rao bound for precision. Our findings reveal that optimal estimation
arises from a complex interplay between the qubit's dephasing dynamics and the
Ohmic characteristics of the environment with a particular focus on
non-Hermitian systems that exhibit enhanced resilience to decoherence. Notably,
optimal estimation does not occur when the qubit reaches a stationary state nor
under conditions of complete dephasing.

</details>


### [483] [Scalable Hardware Maturity Probe for Quantum Accelerators via Harmonic Analysis of QAOA](https://arxiv.org/abs/2509.11450)
*Chinonso Onah,Kristel Michielsen*

Main category: quant-ph

TL;DR: 通过使用硬件成熟度探测器来量化量子设备的可靠性，该探测器通过测试其重复生成单层QAOA电路可证明的全局最优解的能力来评估设备。


<details>
  <summary>Details</summary>
Motivation: 随着量子处理器日益作为高性能计算（HPC）设施内的紧密耦合加速器运行，可靠且可复现的行为成为科学和工业工作负载的关键要求。

Method: 该研究提出了一种硬件成熟度探测器，该探测器利用谐波分析推导出p=1 QAOA成本函数地形中平稳点的数量的闭式上界，适用于广泛的组合优化问题。这些上界支持一种详尽且低开销的网格采样方案，具有可分析验证的结果。

Result: 该方法提供了一种集成可靠性工程概念（如运行-失效统计、置信区间估计和可复现性测试）的标准化度量，可用于混合量子-HPC（QHPC）工作流。

Conclusion: 该探测器为混合量子-HPC（QHPC）工作流提供了一个标准化的可靠性度量。

Abstract: As quantum processors begin operating as tightly coupled accelerators inside
high-performance computing (HPC) facilities, dependable and reproducible
behavior becomes a gating requirement for scientific and industrial workloads.
We present a hardware-maturity probe that quantifies a device's reliability by
testing whether it can repeatedly reproduce the provably global optima of
single-layer Quantum Approximate Optimization Algorithm (QAOA) circuits. Using
harmonic analysis, we derive closed-form upper bounds on the number of
stationary points in the p=1 QAOA cost landscape for broad classes of
combinatorial-optimization problems. These bounds yield an exhaustive yet
low-overhead grid-sampling scheme with analytically verifiable outcomes. The
probe integrates reliability-engineering notions like run-to-failure
statistics, confidence-interval estimation, and reproducibility testing into a
single, application-centric benchmark. Our framework supplies a standardized
dependability metric for hybrid quantum-HPC (QHPC) workflows.

</details>


### [484] [Practical Routing and Criticality in Large-Scale Quantum Communication Networks](https://arxiv.org/abs/2509.10908)
*Cillian Harney,Stefano Pirandola*

Main category: quant-ph

TL;DR: 量子网络设计中的关键问题是，如何设计量子网络以有效率地保证高通信速率。本研究通过使用随机网络模型和端到端路由协议，揭示了大型量子网络的关键现象，并提出了一种改进的 것입니다。


<details>
  <summary>Details</summary>
Motivation: 为了克服点对点量子通信速率随距离指数衰减的限制，需要设计能够有效保证高速率的量子网络。但现有技术在面对复杂的光纤量子网络时，仍面临挑战。

Method: 本研究采用随机网络模型和实用的端到端路由协议来描述量子网络。通过对比单路径路由和多路径路由算法，评估其在性能和资源消耗方面的表现。

Result: 研究发现，在量子网络中应用单路径路由协议无法在长距离实现可靠的速率。而采用新颖的多路径路由算法，可以在提高性能的同时，有效降低量子资源的消耗。

Conclusion: 为了在量子网络中实现高效率和高可靠性的通信，需要采用多路径路由策略，而不是传统的单路径路由。

Abstract: The efficacy of a communication network hinges upon both its physical
architecture and the protocols that are employed within it. In the context of
quantum communications, there exists a fundamental rate-loss tradeoff for
point-to-point quantum channels such that the rate for distributing
entanglement, secret keys, or quantum states decays exponentially with respect
to transmission distance. Quantum networks are the solution to overcome
point-to-point limitations, but they simultaneously invite a challenging open
question: How should quantum networks be designed to effectively and
efficiently guarantee high rates? Now that performance and physical topology
are inexorably linked, this question is not easy, but the answer is essential
for a future quantum internet to be successful. In this work, we offer crucial
insight into this open question for complex optical-fiber quantum networks.
Using realistic descriptions of quantum networks via random network models and
practical end-to-end routing protocols, we reveal critical phenomena associated
with large-scale quantum networks. Our work reveals the weaknesses of applying
single-path routing protocols within quantum networks, observing an inability
to achieve reliable rates over long distances. Adapting novel algorithms for
multi-path routing, we employ an efficient and practical multi-path routing
algorithm capable of boosting performance while minimizing costly quantum
resources.

</details>


### [485] [Requirements for Early Quantum Advantage and Quantum Utility in the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2509.11469)
*Chinonso Onah,Kristel Michielsen*

Main category: quant-ph

TL;DR: 在NISQ硬件上实现CVRP的早期量子优势是不太可能的，但提出的框架可以识别有希望的实例。


<details>
  <summary>Details</summary>
Motivation: 确定在哪些条件下，电容车辆路径问题（CVRP）可以在量子计算机上实现早期量子优势。

Method: 提出一个透明的、与编码无关的框架，结合闭合形式的资源计数和最新的设备基准，定义了三个关键的判断指标（量子可行性点、量子比特可行性线和门可行性线），并将其可视化在一个单一的决策图上。通过比较直接的QUBO映射和空间高效的更高阶（HOBO）编码，分析了不同编码方案的资源需求。

Result: 该框架显示，即使在最佳情况下，NISQ硬件也不太可能实现CVRP的早期量子优势。HOBO编码在资源需求方面比QUBO编码有显著优势，对于Golden-5等基准实例，HOBO编码仅需要7,685个量子比特，而QUBO编码则需要超过200,000个量子比特。该决策图可以评估任何CVRP实例、任何编码方案和任何硬件配置的量子计算潜力。

Conclusion: CVRP的量子优势可能需要创新的问题分解技术，但所提出的框架为评估CVRP的量子计算可行性提供了一个统一的度量标准，并能识别出最有希望的早期量子优势实例。

Abstract: We introduce a transparent, encoding-agnostic framework for determining when
the Capacitated Vehicle Routing Problem (CVRP) can achieve early quantum
advantage. Our analysis shows this is unlikely on noisy intermediate scale
quantum (NISQ) hardware even in best case scenarios that use the most
qubit-efficient direct encodings. Closed-form resource counts, combined with
recent device benchmarks, yield three decisive go/no-go figures of merit: the
quantum feasibility point and the qubit- and gate-feasibility lines, which
place any CVRP instance on a single decision diagram. Contrasting a direct QUBO
mapping with a space-efficient higher-order (HOBO) encoding reveals a large
gap. Applied to early-advantage benchmarks such as Golden-5, our diagram shows
that HOBO circuits require only 7,685 qubits, whereas comparable QUBO encodings
still exceed 200,000 qubits. In addition to identifying candidate instances for
early quantum advantage in CVRP, the framework provides a unifying go/no-go
metric that ingests any CVRP encoding together with any hardware profile and
highlights when quantum devices could challenge classical heuristics. Quantum
advantage in CVRP would likely require innovative problem decomposition
techniques.

</details>


### [486] [Erasing Classical Memory with Quantum Fluctuations: Shannon Information Entropy of Reverse Quantum Annealing](https://arxiv.org/abs/2509.10927)
*Elijah Pelofske,Cristiano Nisoli*

Main category: quant-ph

TL;DR: 量子退火器在反铁磁链上的内存保留与信息熵交叉现象的研究。


<details>
  <summary>Details</summary>
Motivation: 研究量子退火过程中量子涨落导致内存丢失和保留之间的交叉现象，特别是在具有周期性边界条件的奇数反铁磁链上。

Method: 通过在三个可编程超导通量量子比特量子退火器上进行反向量子退火实验，初始化自旋以包含单个畴壁，然后通过开启横向塞曼能量来暴露于量子涨落，并提取磁畴壁分布的香农信息熵来表征交叉现象。

Result: 在低横向场下观察到内存保留，在高横向场下观察到内存丢失，并展示了内存保留的清晰交叉现象，以及其对硬件平台和模拟时间的依赖性。

Conclusion: 研究方法提供了一种普遍的探测量子涨落与内存之间相互作用的方式。

Abstract: Quantum annealers can provide non-local optimization by tunneling between
states in a process that ideally eliminates memory of the initial
configuration. We study the crossover between memory loss and retention due to
quantum fluctuations, in a transverse Ising model on odd numbered
antiferromagnetic rings of thousands of spins with periodic boundary
conditions, by performing reverse quantum annealing experiments on three
programmable superconducting flux qubit quantum annealers. After initializing
the spins to contain a single domain wall, we then expose it to quantum
fluctuations by turning on the transverse Zeeman energy. We characterize the
crossover between memory retention at low transverse field, and memory loss at
high transverse field by extracting the Shannon information entropy of magnetic
domain wall distributions. We demonstrate a clear crossover in memory
retention, and its dependence on hardware platform and simulation time. Our
approach establishes a general probe of the interplay between quantum
fluctuations and memory.

</details>


### [487] [A structure theorem for complex-valued quasiprobability representations of physical theories](https://arxiv.org/abs/2509.10949)
*Rafael Wagner,Roberto D. Baldijão,Matthias Salzger,Yìlè Yīng,David Schmid,John H. Selby*

Main category: quant-ph

TL;DR: 本文将研究扩展到更广泛的复值拟态概率表示，即使它们不保持单位通道或映射到无限维空间。


<details>
  <summary>Details</summary>
Motivation: 传统拟态概率表示通常使用实值分布，但最近的研究表明复值分布（尤其是 Kirkwood-Dirac 拟态概率分布）的有用性。

Method: 本文将分析扩展到不保持单位通道的复值拟态概率表示，并考虑映射到无限维空间的情况。结果表明，每个表示都可以分解为两个完全由其在状态和单位（或效应）上的作用表征的映射。

Result: 研究结果适用于所有有限维、断层局部广义概率论的复值拟态概率表示，以有限维量子论为典型例子。在量子情况下，这些映射的作用对应于表示的帧和对偶帧的选择。

Conclusion: 本研究为分析广义概率论中的复值拟态概率表示提供了一个统一的数学框架。

Abstract: Quasiprobability representations are well-established tools in quantum
information science, with applications ranging from the classical simulability
of quantum computation to quantum process tomography, quantum error correction,
and quantum sensing. While traditional quasiprobability representations
typically employ real-valued distributions, recent developments highlight the
usefulness of complex-valued ones -- most notably, via the family of
Kirkwood--Dirac quasiprobability distributions. Building on the framework of
Schmid et al. [Quantum 8, 1283 (2024)], we extend the analysis to encompass
complex-valued quasiprobability representations that need not preserve the
identity channel. Additionally, we also extend previous results to consider
mappings towards infinite-dimensional spaces. We show that, for each system,
every such representation can be expressed as the composition of two maps that
are completely characterized by their action on states and on the identity
(equivalently, on effects) for that system. Our results apply to all
complex-valued quasiprobability representations of any finite-dimensional,
tomographically-local generalized probabilistic theory, with finite-dimensional
quantum theory serving as a paradigmatic example. In the quantum case, the
maps' action on states and effects corresponds to choices of frames and dual
frames for the representation. This work offers a unified mathematical
framework for analyzing complex-valued quasiprobability representations in
generalized probabilistic theories.

</details>


### [488] [Collisional model with dissipative and dephasing baths: Nonadditive effects at strong coupling](https://arxiv.org/abs/2509.10988)
*Alessandro Prositto,Carlos Ramon-Escandell,Dvira Segal*

Main category: quant-ph

TL;DR: 重复交互模型用于模拟和分析开放量子系统的动力学。研究了一个系统同时耦合到两个浴（非对易系统算符）的动力学。一个浴耦合到非对角元素（产生耗散），另一个耦合到对角元素（产生纯粹退相干）。


<details>
  <summary>Details</summary>
Motivation: 探讨重复交互模型在同时耦合到两个浴的系统中的动力学和热力学行为，特别是强耦合下是否会出现非加性效应，以及热交换的方向。

Method: 通过解析方法精确求解，分析了系统在强耦合下的动力学行为和热力学性质，并与之前的量子主方程方法进行对比。

Result: 强系统-浴耦合导致非加性效应，表现为由退相干浴引起的人口弛豫减慢。热量仅流向耗散浴，与之前量子主方程方法得到的热交换到退相干浴的结果不同。

Conclusion: 重复交互模型在强耦合下会产生独特的动力学和稳态现象，例如人口弛豫减慢和热量只流向耗散浴。这表明需要更深入地理解该模型与其他开放量子系统技术的关系。

Abstract: The repeated interaction model provides a framework for emulating and
analyzing the dynamics of open quantum systems. We explore here the dynamics
generated by this protocol in a system that is simultaneously coupled to two
baths through noncommuting system operators. One bath is made to couple to
nondiagonal elements of the system, thus it induces dissipative dynamics, while
the other couples to diagonal elements, and by itself it generates pure
dephasing. By solving the problem analytically exactly, we show that when both
baths act concurrently, a strong system-bath coupling gives rise to nonadditive
effects in the dynamics. A prominent signature of this nonadditivity is the
characteristic {\it slowing down} of population relaxation, driven by the
influence of the dephasing bath. Beyond dynamics, we investigate the
thermodynamic behavior of the model. Previous studies, using quantum master
equations, showed that strong system-bath coupling created bath-cooperativity
in this model, allowing heat exchange to the dephasing (diagonally coupled)
bath. We find instead that, under the repeated interaction scheme, heat flows
exclusively to the dissipative bath (coupled through nondiagonal elements). Our
results highlight the need for a deeper understanding of the types of open
quantum system dynamics and steady-state phenomena that emerge within the
repeated interaction framework and the relation of this protocol to other
common open quantum system techniques.

</details>


### [489] [V-ZOR: Enabling Verifiable Cross-Blockchain Communication via Quantum-Driven ZKP Oracle Relays](https://arxiv.org/abs/2509.10996)
*M. Z. Haider,Tayyaba Noreen,M. Salman,M. Dias de Assuncao,Kaiwen Zhang*

Main category: quant-ph

TL;DR: 跨链桥和预言机DAO是去中心化系统中风险最高的组成部分，已导致超过28亿美元的损失。现有的预言机设计存在固有的安全漏洞，容易受到攻击和延迟。我们提出V-ZOR，一种结合了零知识证明、量子级随机数和跨链再质押的可验证预言机，以减轻这些风险。V-ZOR通过以下方式增强安全性：1. 在每个预言机数据包中包含Halo 2证明，验证数据是否通过确定性中位数正确聚合。2. 使用可审计的量子熵重新播种VRF，确保记者选择的不可预测性和安全性。3. 允许任何连接的链提交欺诈证明以触发削减，从而无需多签或乐观假设。V-ZOR在Sepolia和Scroll上的原型实现了低于30万Gas的验证成本、区块延迟和10倍的共谋成本增加。V-ZOR证明了ZK证明与量子随机化再质押的结合可以为跨链DeFi提供一个信任最小化、高性能的预言机层。


<details>
  <summary>Details</summary>
Motivation: 跨链桥和预言机DAO是去中心化系统中风险最高的组成部分，已导致超过28亿美元的损失。现有的预言机设计（如多签、乐观假设或中心化聚合）存在安全漏洞，容易受到攻击和延迟。可预测的委员会选择机制也容易被操纵，威胁到跨链数据的完整性。

Method: V-ZOR 是一种可验证的预言机中继，它集成了零知识证明、量子级随机数和跨链再质押。具体来说：1. **零知识证明（ZK Proofs）：** 每个预言机数据包都包含一个 Halo 2 证明，验证报告的数据是否使用确定性中位数进行了正确聚合。2. **量子级随机数：** V-ZOR 使用可审计的量子熵来重新播种其可验证随机函数（VRF），确保记者（预言机节点）的选择是不可预测且安全的，从而防止委员会操纵。3. **跨链再质押：** 记者只需在一个共享的再质押中心进行一次质押。任何连接的链都可以提交欺诈证明来触发罚没（slashing）机制，从而无需依赖多签或乐观假设。

Result: 在Sepolia和Scroll链上的原型测试表明，V-ZOR实现了：1. **低验证成本：** Gas验证成本低于30万。2. **低延迟：** 仅需一个区块的延迟。3. **高共谋成本：** 共谋成本增加了10倍。V-ZOR证明了结合ZK证明和量子随机化再质押可以实现一个信任最小化、高性能的跨链DeFi预言机层。

Conclusion: V-ZOR通过结合零知识证明、量子级随机数和跨链再质押，有效地解决了现有预言机设计的安全性和效率问题。它提供了一个信任最小化、高性能的解决方案，能够抵御攻击、防止操纵，并确保跨链DeFi的稳健运行。

Abstract: Cross-chain bridges and oracle DAOs represent some of the most vulnerable
components of decentralized systems, with more than $2.8 billion lost due to
trust failures, opaque validation behavior, and weak incentives. Current oracle
designs are based on multisigs, optimistic assumptions, or centralized
aggregation, exposing them to attacks and delays. Moreover, predictable
committee selection enables manipulation, which threatens data integrity across
chains. We propose V-ZOR, a verifiable oracle relay that integrates
zero-knowledge proofs, quantum-grade randomness, and cross-chain restaking to
mitigate these risks. Each oracle packet includes a Halo 2 proof verifying that
the reported data was correctly aggregated using a deterministic median. To
prevent committee manipulation, VZOR reseeds its VRF using auditable quantum
entropy, ensuring unpredictable and secure selection of reporters. Reporters
stake once on a shared restaking hub; any connected chain can submit a fraud
proof to trigger slashing, removing the need for multisigs or optimistic
assumptions. A prototype in Sepolia and Scroll achieves sub-300k gas
verification, one-block latency, and a 10x increase in collusion cost. V-ZOR
demonstrates that combining ZK attestation with quantum-randomized restaking
enables a trust-minimized, high-performance oracle layer for cross-chain DeFi.

</details>


### [490] [Bound states and the collective dynamics of Distant Quantum Emitters coupled to a chiral waveguide](https://arxiv.org/abs/2509.11050)
*Meng Qian Wu,Ge Sun,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 两量子比特在手征耦合的1D波导中，由于方向相关的场传播速度，其自发辐射过程表现出增强、抑制、一增强一抑制以及完全抑制等多种现象，其中完全抑制的机制是量子比特-光子束缚态。


<details>
  <summary>Details</summary>
Motivation: 研究两个分离距离在波长量级上的双能级量子比特（QEs）在存在方向相关场传播速度的1D波导中的耦合动力学及其自发辐射过程。

Method: 考虑两个量子比特在手征耦合的1D波导中，该波导具有方向相关的场传播速度。分析了量子比特具有不同发射率时，其自发辐射过程。

Result: 发现了多种自发辐射现象：均增强、均抑制、一增强一抑制、以及两者都被完全抑制。特别地，量子比特-光子束缚态的出现是导致辐射完全抑制的原因。

Conclusion: 量子比特-光子束缚态的存在可以完全抑制量子比特的辐射。

Abstract: We consider two two-level quantum emitters (QEs) with separations on the
order of the wavelength which are chirally coupled to a one-dimensional (1D)
waveguide, and the electromagnetic field of the 1D waveguide has a
direction-dependent velocity, which produces two field propagation phases on
the dynamics of QEs. Their spontaneous process is examined for QEs having
unequal emission rates to the waveguide. It is found that radiation could be
enhanced for both QEs, inhibited for both QEs, enhanced for one while inhibited
for the other, completely suppressed for both QEs. In particular, the mechanism
for radiation completely suppressed is the presence of a QE-photon bound state.

</details>


### [491] [Quantum State Recovery via Direct Sum Formalism Without Measurement Outcomes](https://arxiv.org/abs/2509.11066)
*Taiga Suzuki,Masayuki Ohzeki*

Main category: quant-ph

TL;DR: 提出了一种新的量子态恢复方法，通过将概率幅转移到正交补空间，再进行测量，实现后测量操作不依赖于测量结果的量子态恢复。


<details>
  <summary>Details</summary>
Motivation: 现有量子态恢复方法通常依赖于测量结果，且受到不可克隆定理的限制。本研究旨在探索一种不依赖测量结果的量子态恢复方法，并探讨其在信息擦除方面的意义。

Method: 提出一种特殊操作，将量子态的概率幅转移到其正交补空间，然后在此正交子空间上进行测量，从而恢复原始量子态。该方法不依赖于后测量操作对测量结果的依赖性。

Result: 实现了一种不依赖测量结果的量子态恢复方法，且信息擦除与访问测量结果无关。

Conclusion: 该方法在操作和信息层面都具有重要的意义，表明在直接和 Hilbert 空间框架下，量子态恢复和信息擦除可以不依赖于历史测量结果。

Abstract: This study proposes a new approach to quantum state recovery following
measurement. Specifically, we introduce a special operation that transfers the
probability amplitude of the quantum state into its orthogonal complement. This
operation is followed by a measurement performed on this orthogonal subspace,
enabling the undisturbed original quantum state to be regained. Remarkably,
this recovery is achieved without dependence of the post-measurement operation
on the measurement outcome, thus allowing the recovery without historical
dependence. This constitutes a highly nontrivial phenomenon. From the
operational perspective, as the no-cloning theorem forbids perfect and
probabilistic cloning of arbitrary quantum states, and traditional
post-measurement reversal methods typically rely on operations contingent on
the measurement outcomes, it questions fundamental assumptions regarding the
necessity of historic dependence. From an informational perspective, since this
recovery method erases the information about the measurement outcome, it's
intriguing that the information can be erased without accessing the measurement
outcome. These results imply the operational and informational non-triviality
formulated in a direct-sum Hilbert space framework.

</details>


### [492] [Non-Hermitian Physics in Quantum Channels: Pseudo-Hermiticity, Spectrum Measurement and Application to Hamiltonian Parameter Estimation](https://arxiv.org/abs/2509.11074)
*Yuan-De Jin,Wen-Long Ma*

Main category: quant-ph

TL;DR: 量子信道可以用伪厄米矩阵表示，其谱分析可用于学习哈密顿量，并应用于量子传感。


<details>
  <summary>Details</summary>
Motivation: 揭示量子信道中的非厄米物理学及其应用。

Method: 通过追踪特定测量结果在连续量子信道中的统计数据来测量信道谱；构建并分析了由目标系统的幺正信道和探针比特的弱测量信道组成的量子信道类。

Result: 量子信道的自然表示是伪厄米矩阵（如果可对角化且具有离散谱）；所提出的谱测量方法可用于学习自由哈密顿量；数值证明了探针自旋量子比特可用于传感核自旋簇。

Conclusion: 量子信道的伪厄米性质及其谱分析可为量子传感提供新的途径，并能有效学习目标系统的哈密顿量。

Abstract: Quantum channels describe the most general evolutions of open quantum
systems. The natural representation of a quantum channel, as a linear map on
vectorized quantum states, is often a non-Hermitian matrix. Here we reveal the
intriguing non-Hermitian physics in quantum channels and its application. We
first demonstrate that the natural representation of any quantum channel is a
pseudo-Hermitian matrix if it is diagonalizable with a discrete spectrum, due
to its eigenvalues being either real or in complex conjugate pairs. Then we
propose a general method to measure the channel spectrum by tracking the
measurement statistics of a specific outcome in sequential quantum channels. We
further construct and analyze a typical class of quantum channels, with each
channel being a unitary channel on a target system followed by a
weak-measurement channel induced by a Ramsey sequence of a probe qubit. We show
that the spectrum measurement of such channels can be utilized for learning the
free Hamiltonian generating the unitary channel of the target system. As
practical examples, we numerically demonstrate that a probe spin qubit can
accurately sense nuclear spin clusters for nanoscale nuclear magnetic
resonance.

</details>


### [493] [A Collaborative Framework for Quantum Optimisation and Quantum Neural Networks: Credit Feature Selection and Image Classification](https://arxiv.org/abs/2509.11110)
*JiaNing Long,Xuechen Liang*

Main category: quant-ph

TL;DR: 量子计算在信用风险评估的特征选择和手写数字识别的图像分类任务中展现出潜力。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算在实际机器学习任务中的应用，并评估其在特征选择和图像分类上的有效性。

Method: 在信用风险评估任务中，将特征选择问题转化为二次无约束二元优化（QUBO）问题，并使用量子退火求解。在图像分类任务中，使用量子神经网络（QNN），包括FRQI和压缩FRQI编码，以及CRADL和CRAML架构，对MNIST数据集中的手写数字3和6进行分类。

Result: 量子退火在信用风险评估任务中，使用最少特征实现了高分类精度。量子神经网络成功处理了高维图像数据，对手写数字进行了有效分类。

Conclusion: 量子计算有潜力解决实际的机器学习问题，但需要在资源消耗和模型功效之间进行权衡。

Abstract: This paper investigates the efficacy of quantum computing in two distinct
machine learning tasks: feature selection for credit risk assessment and image
classification for handwritten digit recognition. For the first task, we
address the feature selection challenge of the German Credit Dataset by
formulating it as a Quadratic Unconstrained Binary Optimization (QUBO) problem,
which is solved using quantum annealing to identify the optimal feature subset.
Experimental results show that the resulting credit scoring model maintains
high classification precision despite using a minimal number of features. For
the second task, we focus on classifying handwritten digits 3 and 6 in the
MNIST dataset using Quantum Neural Networks (QNNs). Through meticulous data
preprocessing (downsampling, binarization), quantum encoding (FRQI and
compressed FRQI), and the design of QNN architectures (CRADL and CRAML), we
demonstrate that QNNs can effectively handle high-dimensional image data. Our
findings highlight the potential of quantum computing in solving practical
machine learning problems while emphasizing the need to balance resource
expenditure and model efficacy.

</details>


### [494] [Investigating the Lottery Ticket Hypothesis for Variational Quantum Circuits](https://arxiv.org/abs/2509.11190)
*Michael Kölle,Leonhard Klingert,Julian Schönberger,Philipp Altmann,Tobias Rohe,Claudia Linnhoff-Popien*

Main category: quant-ph

TL;DR: 量子计算中的“彩票假说”可以减少变分量子线路中的参数数量，同时保持性能，从而提高量子机器学习任务的效率。


<details>
  <summary>Details</summary>
Motivation: 研究“彩票假说”在变分量子线路（VQCs）中的适用性，以期解决VQCs的“贫瘠之瘠”问题。

Method: 在VQCs中研究“彩票假说”，通过剪枝技术识别“中奖彩票”子网络。

Result: 在弱“彩票假说”下，保留了26.0%的原始参数；在强“彩票假说”下，在二元VQC中发现了一个中奖彩票，仅用45%的权重就达到了100%的准确率。

Conclusion: “彩票假说”可能通过减少参数数量来缓解VQCs的“贫瘠之瘠”问题，同时保持性能，从而提高量子机器学习任务的效率。

Abstract: Quantum computing is an emerging field in computer science that has seen
considerable progress in recent years, especially in machine learning. By
harnessing the principles of quantum physics, it can surpass the limitations of
classical algorithms. However, variational quantum circuits (VQCs), which rely
on adjustable parameters, often face the barren plateau phenomenon, hindering
optimization. The Lottery Ticket Hypothesis (LTH) is a recent concept in
classical machine learning that has led to notable improvements in parameter
efficiency for neural networks. It states that within a large network, a
smaller, more efficient subnetwork, or ''winning ticket,'' can achieve
comparable performance, potentially circumventing plateau challenges. In this
work, we investigate whether this idea can apply to VQCs. We show that the weak
LTH holds for VQCs, revealing winning tickets that retain just 26.0\% of the
original parameters. For the strong LTH, where a pruning mask is learned
without any training, we discovered a winning ticket in a binary VQC, achieving
100\% accuracy with only 45\% of the weights. These findings indicate that LTH
may mitigate barren plateaus by reducing parameter counts while preserving
performance, thus enhancing the efficiency of VQCs in quantum machine learning
tasks.

</details>


### [495] [Quantum Hierarchical Fokker-Planck Equations with U(1) Gauge Fields (U(1)-QHFPE): A Computational Framework for Aharonov-Bohm Effects](https://arxiv.org/abs/2509.11195)
*Shoki Koyanagi,Hyeonseok Yang,Yoshitaka Tanimura*

Main category: quant-ph

TL;DR: U(1)-QHFPE是一个开源量子动力学软件包，用于在HEOM框架下求解包含规范场的量子福克方程，能够准确模拟强耦合下的输运现象，如Aharonov-Bohm效应。


<details>
  <summary>Details</summary>
Motivation: 模拟强系统-浴耦合下的输运现象，如Aharonov-Bohm效应，并自然地展现系统与浴之间的量子纠缠。

Method: 在Hierarchical Equations of Motion (HEOM)形式主义下，开发了一个能够严格保持规范不变性和旋转对称性的非马尔可夫、非微扰开放量子动力学软件包U(1)-QHFPE，用于求解包含规范场的量子福克方程。

Result: 计算了在Aharonov-Bohm环形几何中对称和反对称相关函数，展示了该软件在解决耗散开放系统中拓扑量子干涉的能力。

Conclusion: U(1)-QHFPE软件包能够准确模拟强耦合下的输运现象，并能解决耗散开放系统中的拓扑量子干涉问题。

Abstract: We introduce U(1)-QHFPE, a non-Markovian and non-perturbative open quantum
dynamics software package for solving quantum Fokker-Planck equations
incorporating gauge fields within the Hierarchical Equations of Motion (HEOM)
formalism. The framework rigorously preserves gauge invariance and rotational
symmetry, enabling accurate simulations of transport phenomena such as the
Aharonov-Bohm effect under strong system-bath coupling. In this regime, quantum
entanglement between the system and bath emerges naturally. Demonstration
programs include calculations of symmetric and antisymmetric correlation
functions in Aharonov-Bohm ring geometries, showcasing the code's ability to
resolve topological quantum interference in dissipative open systems.

</details>


### [496] [Quantum Architecture Search for Solving Quantum Machine Learning Tasks](https://arxiv.org/abs/2509.11198)
*Michael Kölle,Simon Salfer,Tobias Rohe,Philipp Altmann,Claudia Linnhoff-Popien*

Main category: quant-ph

TL;DR: 使用强化学习（RL）自动搜索变分量子电路（VQC）的架构，以应对当今易出错的量子硬件，并在分类任务中取得有希望的结果。


<details>
  <summary>Details</summary>
Motivation: 当前的量子硬件易出错且规模有限，而变分量子电路（VQC）为这些设备提供了一种抗噪声的框架。然而，VQC 的性能很大程度上取决于其参数化量子组件的架构。因此，寻找高效且与硬件兼容的量子电路架构（即量子架构搜索，QAS）至关重要。手动 QAS 复杂且易出错，需要自动化方法。强化学习（RL）作为一种自动化策略，在量子机器学习（QML）背景下的应用仍有待探索。

Method: 提出了一种名为 RL-QAS 的框架，该框架应用强化学习（RL）来为分类任务发现有效的量子电路架构。

Result: 使用 Iris 和二元 MNIST 数据集评估了 RL-QAS。该代理能够自主发现低复杂度的电路设计，并在测试准确性方面取得了高分。

Conclusion: 强化学习（RL）是自动搜索量子机器学习（QML）中量子电路架构的一种可行方法。然而，将 RL-QAS 应用于更复杂的任务需要进一步改进搜索策略和性能评估机制。

Abstract: Quantum computing leverages quantum mechanics to address computational
problems in ways that differ fundamentally from classical approaches. While
current quantum hardware remains error-prone and limited in scale, Variational
Quantum Circuits offer a noise-resilient framework suitable for today's
devices. The performance of these circuits strongly depends on the underlying
architecture of their parameterized quantum components. Identifying efficient,
hardware-compatible quantum circuit architectures -- known as Quantum
Architecture Search (QAS) -- is therefore essential. Manual QAS is complex and
error-prone, motivating efforts to automate it. Among various automated
strategies, Reinforcement Learning (RL) remains underexplored, particularly in
Quantum Machine Learning contexts. This work introduces RL-QAS, a framework
that applies RL to discover effective circuit architectures for classification
tasks. We evaluate RL-QAS using the Iris and binary MNIST datasets. The agent
autonomously discovers low-complexity circuit designs that achieve high test
accuracy. Our results show that RL is a viable approach for automated
architecture search in quantum machine learning. However, applying RL-QAS to
more complex tasks will require further refinement of the search strategy and
performance evaluation mechanisms.

</details>


### [497] [Gradients, parallelism, and variance of quantum estimates](https://arxiv.org/abs/2509.11214)
*Francesco Preti,Michael Schilling,József Zsolt Bernád,Tommaso Calarco,Francisco Cárdenas-López,Felix Motzoi*

Main category: quant-ph

TL;DR: 对量子算法中的可观测值及其梯度计算方法进行了系统性分析，并提出了一种新的基于n比特门和时间依赖量子控制的梯度框架。


<details>
  <summary>Details</summary>
Motivation: 量子算法中可观测值和梯度的计算是核心问题。

Method: 回顾了标准的可观测值和梯度估计方法，分析了采样问题和方差传播，并提出了新的LCU梯度框架，包括基于n比特门和时间依赖量子控制的梯度，同时分析了收敛行为和电路表示。

Result: 提出了一个通用的LCU梯度框架，并为近地和容错硬件提供了详细的电路表示。

Conclusion: 所提出的LCU梯度框架能够更有效地处理量子算法中的梯度计算问题。

Abstract: Computation of observables and their gradients on near-term quantum hardware
is a central aspect of any quantum algorithm. In this work, we first review
standard approaches to the estimation of observables with and without quantum
amplitude estimation for both cost functions and gradients, discuss sampling
problems, and analyze variance propagation on quantum circuits with and without
Linear Combination of Unitaries (LCU). Afterwards, we systematically analyze
the standard approaches to gradient computation with LCU circuits. Finally, we
develop a LCU gradient framework for the most general gradients based on
n-qubit gates and for time-dependent quantum control gradient, analyze the
convergence behaviour of the circuit estimators, and provide detailed circuit
representations of both for near-term and fault-tolerant hardware.

</details>


### [498] [On the Monotonicity of relative entropy: A Comparative Study of Petz's and Uhlmann's Approaches](https://arxiv.org/abs/2509.11221)
*Santiago Matheus,Francesco Bottacin,Edoardo Provenzi*

Main category: quant-ph

TL;DR: 量子相对熵在量子信道作用下的单调性是量子信息论中的一个基本结果。本文使用统一的算子理论框架，重新审视了 Petz 和 Uhlmann 的证明方法。Petz 的方法在原始证明中存在细微瑕疵，但已被修正。Uhlmann 的方法基于正双线性形式的插值，适用于不可逆密度算子。比较两者，Petz 的方法更直接清晰，Uhlmann 的方法更抽象通用。本文旨在阐明相对熵单调性背后的数学结构，并使证明更易于理解。


<details>
  <summary>Details</summary>
Motivation: 量子信息论中关于量子信道作用下相对熵单调性的基础性结果的证明方法进行再审视和梳理，旨在澄清其数学结构并使证明更易于理解。

Method: 本文在一个统一的、有限维的算子理论框架内，重新阐述了 Petz 和 Uhlmann 证明量子信道作用下相对熵单调性的方法。具体地，分析了 Petz 方法中 Jensen 不等式应用的细微问题及其修正，并发展了 Uhlmann 基于正双线性形式插值的方法，该方法可直接应用于不可逆密度算子。

Result: 通过对 Petz 和 Uhlmann 两种方法的比较，揭示了它们的互补优势：Petz 的方法更直接明了，而 Uhlmann 的方法更抽象和通用。

Conclusion: 本文通过算子理论框架，澄清了量子信道作用下相对熵单调性的证明的数学结构，使得 Petz 和 Uhlmann 的证明方法更加清晰和易于理解，有助于量子信息论基础和应用的研究。

Abstract: We revisit the monotonicity of relative entropy under the action of quantum
channels, a foundational result in quantum information theory. Among the
several available proofs, we focus on those by Petz and Uhlmann, which we
reformulate within a unified, finite-dimensional operator-theoretic framework.
In the first part, we examine Petz's strategy, identify a subtle flaw in his
original use of Jensen's contractive operator inequality, and point out how it
was corrected to restore the validity of his line of reasoning. In the second
part, we develop Uhlmann's approach, which is based on interpolations of
positive sesquilinear forms and applies automatically also to non-invertible
density operators. By comparing these two approaches, we highlight their
complementary strengths: Petz's method is more direct and clear, Uhlmann's is
more abstract and general. Our treatment aims to clarify the mathematical
structure underlying the monotonicity of relative entropy and to make these
proofs more accessible to a broader audience interested in both the foundations
and the applications of quantum information theory.

</details>


### [499] [Hidden correlations in quantum jumps: A theory of individual trials](https://arxiv.org/abs/2509.11277)
*Hiroshi Ishikawa*

Main category: quant-ph

TL;DR: We present a hidden variable theory for quantum trajectories that reconciles discrete quantum jumps with continuous evolution by representing jump sequences as logical propositions. This approach circumvents no-go theorems by introducing a proposition selection rule that ensures well-defined joint probabilities, unifying compatibility criteria and allowing for deterministic relations in individual trials. The theory formalizes a quantum version of Boolean logic and circumvents Bell-type inequalities, ultimately reconciling discrete jumps with continuous evolution and providing a direct description of individual trials.


<details>
  <summary>Details</summary>
Motivation: The challenge is to reconcile discrete quantum jumps with continuous unitary evolution in quantum trajectory theories.

Method: We develop a hidden variable formulation representing jump sequences as logical propositions on energy eigenstate occupations. A proposition selection rule is introduced to ensure well-defined joint probabilities, unifying compatibility criteria and permitting propositions that become deterministic for specific initial conditions. This framework captures deterministic relations in individual trials and formalizes a quantum version of Boolean logic, circumventing Bell-type inequalities.

Result: The theory successfully reconciles discrete jumps with continuous evolution, providing a direct description of individual trials. It captures deterministic relations, including the exclusivity of state occupation implied by observed jumps, and formalizes quantum propositions. Bell-type inequalities are circumvented, and standard probability predictions are preserved.

Conclusion: The developed hidden variable theory provides a novel framework for quantum trajectories that reconciles discrete quantum jumps with continuous unitary evolution. By representing quantum jumps as logical propositions and introducing a proposition selection rule, the theory circumvents established no-go theorems and Bell-type inequalities, offering a direct description of individual trials while maintaining the predictive accuracy of standard quantum mechanics.

Abstract: Quantum trajectory theories have not fully reconciled discrete quantum jumps
with continuous unitary evolution. We address this challenge by developing a
hidden variable formulation that reveals hidden correlations in individual
trials. We represent jump sequences as logical propositions on energy
eigenstate occupations, where logical variables describe their truth values and
chain operators describe their probabilities. To circumvent established no-go
theorems, we introduce a proposition selection rule that requires well-defined
joint probabilities for a given density operator. This rule unifies
compatibility criteria for quantum and hidden variable theories, eliminating
incompatible propositions that lead to value assignment paradoxes. Unlike
conventional criteria mandating operator commutativity, it permits propositions
that become deterministic for specific initial conditions. This framework
systematically captures deterministic relations in individual trials, including
the exclusivity of state occupation implied by the observed jumps. This
exclusivity, distinct from the Pauli exclusion principle, enables the
formalization of a quantum version of Boolean logic as laws for quantum
propositions. These assumptions circumvent Bell-type inequalities by
prohibiting arithmetic operations between incompatible logical variables, while
enabling classical descriptions within the complementarity. The resulting
theory reconciles discrete jumps with continuous evolution, providing a direct
description of individual trials while preserving standard probability
predictions.

</details>


### [500] [Diagnosing Quantum Circuits: Noise Robustness, Trainability, and Expressibility](https://arxiv.org/abs/2509.11307)
*Yuguo Shao,Zhengyu Chen,Zhaohui Wei,Zhengwei Liu*

Main category: quant-ph

TL;DR: 2MC-OBPPP是一个高效的工具，用于评估参数化量子电路在噪声下的鲁棒性、可训练性和表达能力，并能通过“噪声热点”图精确定位和干预噪声敏感的量子比特/门，从而有效降低噪声抑制成本。


<details>
  <summary>Details</summary>
Motivation: 为了评估参数化量子电路在噪声下的鲁棒性、可训练性和表达能力，需要一个有效的分析工具。

Method: 提出了一种名为2MC-OBPPP的参数化量子电路的经典估计器，该估计器能在多项式时间内量化这三个关键诊断指标。

Result: 研究发现，适度的振幅阻尼噪声可以减轻梯度消失问题，但会降低电路的表达能力。该方法能够生成“噪声热点”图，精确定位噪声最敏感的量子比特/门。通过对少于2%的量子比特进行干预，可以消除高达90%的错误。

Conclusion: 2MC-OBPPP是一个高效、与硬件无关的工具，可在执行前对量子电路进行评估，并能制定有针对性的策略来显著降低噪声抑制的成本。

Abstract: Parameterized quantum circuits are central to near-term quantum algorithms,
and serve as the foundation for many quantum machine learning frameworks, which
should be robust to noise, maintain trainability, and exhibit sufficient
expressibility. Here we introduce 2MC-OBPPP, a polynomial-time classical
estimator that quantifies the three aforementioned diagnostics for a given
parameterized quantum circuit. As a demonstration of the power of our approach,
we show that moderate amplitude damping noise can reduce the severity of
vanishing gradients, but at the cost of lowered expressibility. In particular,
our approach can yield a spatiotemporal "noise-hotspot" map that pinpoints the
most noise-sensitive qubits/gates in parameterized quantum circuits. Applying
this map to a specific circuit, we show that implementing interventions on
fewer than 2% of the qubits is sufficient to mitigate up to 90% of the errors.
Therefore, 2MC-OBPPP is not only an efficient, hardware-independent tool for
pre-execution circuit evaluation but also enables targeted strategies that
significantly reduce the cost of noise suppression.

</details>


### [501] [Geometric phase in dissipative quantum batteries](https://arxiv.org/abs/2509.11313)
*Camila Cristiano,Ludmila Viotti,Paula I. Villar*

Main category: quant-ph

TL;DR: 该研究使用量子电池模型，通过数值和解析方法研究了驱动开放量子系统在不同噪声下的几何相位积累及其与存储能量的关系。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统（作为量子电池模型）在非绝热过程中几何相位的积累，以及该相位与存储能量的关系，并考虑了噪声的影响。

Method: 采用数值模拟分析了不同噪声下的系统动力学，并通过在无噪声限制下的解析结果进行了补充。计算了量子电池在转换过程中获得的非单一几何相位，并分析了其与存储能量积分之间的关系。最后，对依赖于退相干充电器的双边量子电池进行了类似分析。

Result: 发现积累的几何相位与转换过程中存储的能量积分之间存在直接关系。对双边量子电池的分析也得到了类似结果。

Conclusion: 研究结果表明，几何相位的积累与量子电池存储能量直接相关，并且这些发现可以通过现有的实验技术实现。

Abstract: We study the geometric phase accumulated during non-adiabatic charging of
different driven open quantum systems serving as quantum battery models. We
provide a full numerical analysis of dynamics under different type of noises
typically reported in superconducting circuits implementations. We complement
the study with analytic results derived in the limiting case of no noise (i.e.
isolated systems). We compute the non-unitary geometric phase acquired by the
quantum batteries during the transition and show that there is a direct
relation between the accumulated geometric phase and the integral of the stored
energy during the transition. Finally, we perform the same analysis on a
bipartite quantum battery that relies on a dephased charger and found similar
results. Our theoretical findings are within experimental reach using
state-of-the-art techniques.

</details>


### [502] [Quantum hierarchical Fokker-Planck equations with U(1) gauge fields: Application to the Aharonov-Bohm ring](https://arxiv.org/abs/2509.11462)
*Hyeonseok Yang,Shoki Koyanagi,Yoshitaka Tanimura*

Main category: quant-ph

TL;DR: 本文研究了时间相关的U(1)规范场耦合的旋转不变环境下的三维子系统动力学，并推导了包含规范场的一阶微分方程（HEOM）和量子福克-普朗克方程（QHFPE），用于精确描述子系统在热激发和耗散下的行为。研究结果表明，在特定条件下，即使在耗散环境中，Aharonov-Bohm（AB）环中的持续电流也能出现。


<details>
  <summary>Details</summary>
Motivation: 为了捕捉子系统在热激发和耗散下的动态行为，需要对 the bath 进行非马尔可夫和非微扰处理，因为量子噪声受到不确定性原理的约束。

Method: 推导了包含规范场的一阶微分方程（HEOM），并将其转化为Wigner表示，得到包含U(1)规范场的量子一阶微分方程（QHFPE）。将该方法应用于Aharonov-Bohm（AB）环模型，模拟了平衡分布、线性吸收光谱和AB电流。

Result: 通过使用RISB模型，预测在非马尔可夫环境和低温条件下，即使在耗散环境中，Aharonov-Bohm（AB）环中也会出现持续电流。同时，评估了Caldeira-Leggett模型在该场景下的有效性。

Conclusion: 在非马尔可夫和低温条件下，即使在耗散环境中，Aharonov-Bohm（AB）环中也会出现持续电流。所提出的包含规范场和耗散的动力学理论为研究此类系统提供了有效框架。

Abstract: We investigate a three-dimensional subsystem under a time-dependent U(1)
gauge field coupled to rotationally invariant environments. To capture the
dynamic behavior of the subsystem under thermal excitations and dissipations,
it is imperative to treat the bath in a non-Markovian and nonperturbative
manner. This is because quantum noise is constrained by the uncertainty
principle, which dictates the relationship between the noise correlation time
and the amplitude of the energy fluctuation. To this end, we derive the
hierarchical equations of motion (HEOM) incorporating the gauge field, enabling
a rigorous investigation of the dynamics of the reduced subsystem. Transforming
the HEOM into the Wigner representation yields quantum hierarchical
Fokker-Planck equations [U(1)-QHFPE] with U(1) gauge fields. These equations
incorporate vector fields into the damping operators while preserving both
gauge invariance and rotational symmetry. To demonstrate the practical use of
the formalism, the effects of a heat bath in the Aharonov-Bohm (AB) ring. Our
investigation includes simulations of the equilibrium distribution, linear
absorption spectra, and AB currents under thermal conditions. Within a
rotationally invariant system-bath (RISB) model, we predict the emergence of a
persistent current even in dissipative environments, provided the bath is
non-Markovian and the temperature is sufficiently low. We also assessed the
validity of the Caldeira-Leggett model in this context.

</details>


### [503] [Directional Motional Control via Engineered Conical Intersections in Trapped Rydberg Ions](https://arxiv.org/abs/2509.11350)
*Abdessamad Belfakir,Yousra Bouasria,Herschel Rabitz,Ahmed Ratnani*

Main category: quant-ph

TL;DR: 通过量子最优控制和精心设计的圆锥交叉点，实现了离子运动的相干控制，以微秒级的时间尺度驱动离子运动波包，实现了高保真度的定向轨迹，这为量子信息处理开辟了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 对囚禁里德堡离子的运动动力学进行相干控制，并利用其圆锥交叉点作为新的控制资源，以实现定向运动，为量子信息处理提供高保真度的量子门操作和可扩展架构。

Method: 利用量子最优控制，设计最优的电场来驱动囚禁里德堡离子的运动波包，使其在绝热势能面之间存在圆锥交叉点。分析了在存在和不存在非绝热耦合的情况下，控制策略对运动轨迹的影响。

Result: 在存在局部非绝热耦合的情况下，控制策略能够实现定向轨迹，并以高保真度到达目标。而在绝热近似下，控制策略仅能实现对称的、多周期的振荡，而非定向位移。两种情况下，虽然最终都能到达目标，但轨迹存在显著差异。

Conclusion: 精心设计的圆锥交叉点可以作为一种新的控制资源，用于实现囚禁离子系统中定向的运动动力学，补充了现有的脉冲整形方法。这种由圆锥交叉点驱动的定向运动有望在量子信息处理中得到重要应用，特别是在高保真度量子门操作和可扩展架构方面。

Abstract: We demonstrate coherent control of motional dynamics in trapped Rydberg ions
engineered to exhibit a conical intersection between adiabatic potential-energy
surfaces. Using quantum optimal control, an optimally shaped electric field
drives the motional wave packet between prescribed spatial configurations on
microsecond timescales. Localized nonadiabatic coupling breaks the symmetry of
the dynamics and produces a directed trajectory: after only a few early
passages through the conical intersection region, the packet proceeds toward
the target with high fidelity. In contrast, in the Born-Oppenheimer limit,
where such coupling is absent, the optimized control yields symmetric,
multi-cycle oscillations rather than a comparably directed displacement. While
both approaches reach the target at the chosen final time, the underlying
trajectories are qualitatively different. This work demonstrates that
engineered conical intersections can serve as a new control resource for
directional motional dynamics, complementing pulse-shaping methods in
trapped-ion systems. This directional motion of the ions, enabled by the
conical intersection, is expected to have important applications for quantum
information processing, where controlled motional states underpin high-fidelity
gate operations and scalable architectures.

</details>


### [504] [Readout of a solid state spin ensemble at the projection noise limit](https://arxiv.org/abs/2509.11854)
*Rouven Maier,Cheng-I Ho,Andrej Denisenko,Marina Davydova,Peter Knittel,Jörg Wrachtrup,Vadim Vorobyov*

Main category: quant-ph

TL;DR: 通过稳定氮-空位（NV）中心的多核自旋，并采用重复核辅助自旋读出技术，实现了低于散粒噪声极限的量子非破坏性读出，接近本征投影噪声极限，并观察到自旋系统中的多体关联效应。


<details>
  <summary>Details</summary>
Motivation: 提高固态量子传感器的性能，克服由散粒噪声引起的限制，并实现更精确的测量。

Method: 通过在高磁场下稳定$^{14}$N核自旋，并采用重复核辅助自旋读出技术。

Result: 实现了低于热投影噪声水平3.8 dB的噪声降低，并直接观察到了自旋系综中量子关联态的信号。

Conclusion: 实现了投影噪声极限读出，为固态量子传感器的发展开辟了新途径，包括量子增强计量学、多体关联的直接检测以及介观固态系综中的自旋压缩的实现。

Abstract: Spin ensembles are central to quantum science, from frequency standards and
fundamental physics searches to magnetic resonance spectroscopy and quantum
sensing. Their performance is ultimately constrained by spin projection noise,
yet solid-state implementations have so far been limited by much larger photon
shot noise. Here we demonstrate a direct, quantum non-demolition readout of a
mesoscopic ensemble of nitrogen-vacancy (NV) centers in diamond that surpasses
the photon shot-noise limit and approaches the intrinsic spin projection noise.
By stabilizing the $^{14}$N nuclear spin bath at high magnetic fields and
employing repetitive nuclear-assisted spin readout, we achieve a noise
reduction of 3.8 dB below the thermal projection noise level. This enables
direct access to the intrinsic fluctuations of the spin ensemble, allowing us
to directly observe the signatures of correlated spin states. Our results
establish projection noise-limited readout as a practical tool for solid-state
quantum sensors, opening pathways to quantum-enhanced metrology, direct
detection of many-body correlations, and the implementation of spin squeezing
in mesoscopic solid-state ensembles.

</details>


### [505] [Neural Decoders for Universal Quantum Algorithms](https://arxiv.org/abs/2509.11370)
*J. Pablo Bonilla Ataides,Andi Gu,Susanne F. Yelin,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: 提出了一种新颖的基于注意力的神经网络解码器，用于容错量子计算，能够学习门诱导的错误相关性，并在算法工作负载上实现与最可能错误（MLE）解码器相当的性能，同时支持实际噪声模型和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习（ML）解码器在量子记忆体方面表现出色，但在处理算法解码（其中逻辑门会产生复杂的错误相关性）方面能力有限。需要一种能够快速、准确且适应电路结构和实际噪声的解码器。

Method: 提出了一种模块化的、基于注意力的神经网络解码器，该解码器能够学习门诱导的错误相关性，并通过在随机电路上进行训练来泛化到未知的多量子比特算法工作负载。该模型还纳入了损耗解析读出功能，以应对实际噪声，并通过定制解码器以匹配算法结构和解码相关可观测量来简化设计。

Result: 所提出的解码器在各种电路深度和量子比特数量下，实现了与MLE解码器相当的逻辑错误率，并具有快速推理能力。在存在量子比特损耗的情况下，损耗解析读出功能带来了显著的性能提升。通过定制解码器，在不牺牲精度的前提下简化了设计。在表面码和二维颜色码等多种纠错码上进行了验证，并在电路级噪声下取得了最先进的性能。注意力机制还提供了可解释性，能够识别解码器跟踪的最相关错误。

Conclusion: 所提出的基于注意力的神经网络解码器是一种实用、通用且高性能的量子计算工具，能够实现深度电路容错算法和架构的实验验证。

Abstract: Fault-tolerant quantum computing demands decoders that are fast, accurate,
and adaptable to circuit structure and realistic noise. While machine learning
(ML) decoders have demonstrated impressive performance for quantum memory,
their use in algorithmic decoding - where logical gates create complex error
correlations - remains limited. We introduce a modular attention-based neural
decoder that learns gate-induced correlations and generalizes from training on
random circuits to unseen multi-qubit algorithmic workloads. Our decoders
achieve fast inference and logical error rates comparable to most-likely-error
(MLE) decoders across varied circuit depths and qubit counts. Addressing
realistic noise, we incorporate loss-resolving readout, yielding substantial
gains when qubit loss is present. We further show that by tailoring the decoder
to the structure of the algorithm and decoding only the relevant observables,
we can simplify the decoder design without sacrificing accuracy. We validate
our framework on multiple error correction codes - including surface codes and
2D color codes - and demonstrate state-of-the-art performance under
circuit-level noise. Finally, we show that the use of attention offers
interpretability by identifying the most relevant correlations being tracked by
the decoder. Enabling experimental validation of deep-circuit fault-tolerant
algorithms and architectures (Bluvstein et al., arXiv:2506.20661, 2025), these
results establish neural decoders as practical, versatile, and high-performance
tools for quantum computing.

</details>


### [506] [Multi-block exceptional points in open quantum systems](https://arxiv.org/abs/2509.11856)
*Aysel Shiralieva,Grigory A. Starkov,Björn Trauzettel*

Main category: quant-ph

TL;DR: NHH 和 Lindbladian 中的 EPs 的出现，以及它们之间的关系以及量子跳跃项的影响。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中的非厄米哈密顿量（NHH）和 Lindbladian，重点是奇异点（EPs）的出现。

Method: 分析 NHH 和 Lindbladian 中 EPs 的出现，特别关注多块 EPs，并研究量子跳跃项如何影响它们。通过耦合到其他基态水平的量子比特和 qutrit 来说明这些发现，并使用量子几何张量作为 EPs 的指标。

Result: 展示了 NHH 中的 EPs 与 Liouvillian 中的多块 EPs 之间的关系，并分析了量子跳跃项如何修改多块结构。通过具体示例说明了如何通过改变物理参数来导航 EP 块结构，并分析了 EP 阶数对态分布动力学的影响。量子几何张量被证明是区分不同类型 EPs 的敏感指标。

Conclusion: 开放量子系统中的 EPs 行为可以通过 NHH 和 Lindbladian 模型来理解，量子跳跃项在修改这些奇异点的结构中起着重要作用。量子几何张量为探测 EPs 提供了有价值的工具。

Abstract: Open quantum systems can be approximately described by non-Hermitian
Hamiltonians (NHHs) and Lindbladians. The two approaches differ by quantum jump
terms corresponding to a measurement of the system by its environment. We
analyze the emergence of exceptional points (EPs) in NHHs and Lindbladians. In
particular, we show how EPs in NHHs relate to a novel type of EPs --
multi-block EPs -- in the non-Hermitian Liouvillian, i.e. the Lindbladian in
absence of quantum jump terms. We further analyze how quantum jump terms modify
the multi-block structure. To illustrate our general findings, we present two
prime examples: qubits and qutrits coupled to additional ground state levels
that serves as sinks of the population. In those examples, we can navigate
through the EP block structure by a variation of physical parameters. We
analyze how the dynamics of the population of the states is affected by the
order of the EPs. Additionally, we demonstrate that the quantum geometric
tensor serves as a sensitive indicator of EPs of different kinds.

</details>


### [507] [Quantum Graph Attention Networks: Trainable Quantum Encoders for Inductive Graph Learning](https://arxiv.org/abs/2509.11390)
*Arthur M. Faria,Mehdi Djellabi,Igor O. Sokolov,Savvas Varsamopoulos*

Main category: quant-ph

TL;DR: QGATs是用于归纳图学习的可训练量子编码器，通过量子注意力机制增强了QGNN的性能，尤其是在处理大型分子图时。


<details>
  <summary>Details</summary>
Motivation: 提出QGATs以扩展QGNN框架，实现对图结构进行归纳学习，并利用量子注意力机制来提高表示能力。

Method: 使用参数化量子电路对节点特征和邻域结构进行编码，并通过量子注意力机制动态调整邻居的贡献，以实现局部感知和可泛化的量子表示。

Result: 在QM9数据集上评估QGATs，与不带注意力机制的量子图神经网络相比，注意力机制在量子和经典模型中均提高了性能。QGATs在大型分子图上表现尤为出色，并且在小型图上能达到与经典GAT模型相当的精度。

Conclusion: 量子注意力机制能够增强QGNN的归纳学习能力，在化学及其他领域具有应用潜力。

Abstract: We introduce Quantum Graph Attention Networks (QGATs) as trainable quantum
encoders for inductive learning on graphs, extending the Quantum Graph Neural
Networks (QGNN) framework. QGATs leverage parameterized quantum circuits to
encode node features and neighborhood structures, with quantum attention
mechanisms modulating the contribution of each neighbor via dynamically learned
unitaries. This allows for expressive, locality-aware quantum representations
that can generalize across unseen graph instances. We evaluate our approach on
the QM9 dataset, targeting the prediction of various chemical properties. Our
experiments compare classical and quantum graph neural networks-with and
without attention layers-demonstrating that attention consistently improves
performance in both paradigms. Notably, we observe that quantum attention
yields increasing benefits as graph size grows, with QGATs significantly
outperforming their non-attentive quantum counterparts on larger molecular
graphs. Furthermore, for smaller graphs, QGATs achieve predictive accuracy
comparable to classical GAT models, highlighting their viability as expressive
quantum encoders. These results show the potential of quantum attention
mechanisms to enhance the inductive capacity of QGNN in chemistry and beyond.

</details>


### [508] [-Continuum limit of bipartite lattices - The SSH model](https://arxiv.org/abs/2509.11900)
*Fotios K. Diakonos,P. Schmelcher*

Main category: quant-ph

TL;DR: 提出了一种新的连续非局域模型，可以忠实地复制Su-Schrieffer-Heeger (SSH)模型的拓扑和谱特征，并允许在非局域和局域模型之间进行插值。


<details>
  <summary>Details</summary>
Motivation: 提出一个连续非局域模型来复制SSH模型的拓扑和谱特征，并引入一个可调参数来控制非局域性。

Method: 提出一个连续非局域模型，该模型具有SSH模型的体能谱、本征态和Zak相位，并引入一个可调参数a来量化非局域性，实现从非局域到局域的插值。

Result: 模型与SSH模型在谱和拓扑特性上表现出一致性，并且在有限畴上支持由零能耗边缘态组成的平坦能带。

Conclusion: 该模型为构建双分 bipartite 和多分 multi-partite 格子（lattices）的非局域、连续类似物奠定了基础，为拓扑量子物质的理论探索和实验实现开辟了新的途径。

Abstract: We present a continuous non-local model that faithfully replicates the rich
topological and spectral features of the Su-Schrieffer-Heeger (SSH) model.
Remarkably, our model shares the SSH models bulk energy spectrum, eigenstates,
and Zak phase, hallmarks of its topological character, while introducing a
tunable length-scale a quantifying non-locality. This parameter allows for a
controlled interpolation between non-local and local regimes. Furthermore, for
a specific value of a the exact spectral equivalence to the discrete SSH model
is established. Distinct from previous continuous analogues based on
Schr\"odinger or Dirac-type Hamiltonians, our approach maintains chiral
symmetry, does not require an external potential and features periodic energy
bands. On finite domains, the model supports a flat band with zero energy
formed by a countable infinite set of exponentially localized zero-energy edge
states of topological origin. Beyond SSH, our method lays the foundation for
constructing non-local, continuous analogues of a wide class of bipartite and
multipartite lattices, opening new paths for theoretical exploration and new
challenges for experimental realization in topological quantum matter.

</details>


### [509] [Pulse-to-Circuit Characterization of Stealthy Crosstalk Attack on Multi-Tenant Superconducting Quantum Hardware](https://arxiv.org/abs/2509.11407)
*Syed Emad Uddin Shubha,Tasnuva Farheen*

Main category: quant-ph

TL;DR: 硬件串扰是多租户超导量子计算机中的一个严重安全威胁，它允许攻击者跨租户边界注入目标错误。我们提出了一个端到端的框架，将物理脉冲级攻击映射到可解释的逻辑错误通道，集成了密度矩阵模拟、量子过程层析（QPT）和一种新颖的基于等距的电路提取方法。我们的流程重建了完整的诱导错误通道，并拟合了一个有效的逻辑电路模型，揭示了一种根本上不对称的攻击机制：一个对抗性量子比特充当驱动程序，设置诱导的逻辑旋转，而第二个量子比特（催化剂）则细化攻击的相干性。该方法在线性三量子比特系统上得到验证，表明这种攻击会严重破坏各种量子协议，有时会将准确性降低到随机猜测的水平，并且即使在现实的硬件参数变化下仍然有效且隐蔽。我们进一步提出了一种基于可观察攻击签名的协议级检测策略，表明可以通过有针对性的监控来暴露隐蔽攻击，并为量子云平台未来的纵深防御奠定基础。


<details>
  <summary>Details</summary>
Motivation: 硬件串扰在多租户量子计算中构成了严重的安全威胁，攻击者可以利用它跨租户边界注入错误。

Method: 提出一个端到端的框架，结合密度矩阵模拟、量子过程层析（QPT）和一种新颖的基于等距的电路提取方法，将物理脉冲级攻击映射到逻辑错误通道。

Result: 重建了完整的诱导错误通道，并拟合了一个有效的逻辑电路模型，揭示了一种不对称的攻击机制（驱动量子比特和催化量子比特）。在三量子比特系统中证明了攻击的有效性，即使在硬件参数变化下也是如此。提出了一种协议级检测策略。

Conclusion: 提出的框架能够将物理攻击映射到逻辑错误，并揭示了攻击机制。所提出的检测策略能够暴露隐蔽攻击，为量子云平台的纵深防御奠定了基础。

Abstract: Hardware crosstalk in multi-tenant superconducting quantum computers
constitutes a significant security threat, enabling adversaries to inject
targeted errors across tenant boundaries. We present the first end-to-end
framework for mapping physical pulse-level attacks to interpretable logical
error channels, integrating density-matrix simulation, quantum process
tomography (QPT), and a novel isometry-based circuit extraction method. Our
pipeline reconstructs the complete induced error channel and fits an effective
logical circuit model, revealing a fundamentally asymmetric attack mechanism:
one adversarial qubit acts as a driver to set the induced logical rotation,
while a second, the catalyst, refines the attack's coherence. Demonstrated on a
linear three-qubit system, our approach shows that such attacks can
significantly disrupt diverse quantum protocols, sometimes reducing accuracy to
random guessing, while remaining effective and stealthy even under realistic
hardware parameter variations. We further propose a protocol-level detection
strategy based on observable attack signatures, showing that stealthy attacks
can be exposed through targeted monitoring and providing a foundation for
future defense-in-depth in quantum cloud platforms.

</details>


### [510] [High-resolution electric field imaging based on intermittent-contact mode scanning NV center electrometry](https://arxiv.org/abs/2509.11586)
*Zhi Cheng,Zhiwei Yu,Mengqi Wang,Lingfeng Yang,Zihao Cui,Ya Wang,Pengfei Wang*

Main category: quant-ph

TL;DR: 使用具有亚纳米振荡幅度的轴对称探针，实现了约 10 nm 的空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 在纳米尺度上对电场进行定量量子成像，但由于采用梯度测量来克服静电屏蔽，导致空间分辨率受限于平均效应和传感器-样品距离。因此，需要一种能够克服这些限制并提高空间分辨率的技术。

Method: 开发了一种具有亚纳米振荡幅度的轴对称探针，该探针能够实现鲁棒的间歇接触模式反馈，并确保传感器-样品之间的紧密接触。这种探针设计旨在提高扫描氮-空位（NV）中心电镜测量的空间分辨率。

Result: 成功实现了约 10 nm 的空间分辨率，并在铁电铌酸锂的实验中得到了验证。该分辨率足以解析通常在几十纳米尺度上出现的铁电体材料的纳米尺度极性织构和动力学。

Conclusion: 所提出的扫描 NV 中心电镜测量方案能够实现约 10 nm 的空间分辨率，为研究新兴铁电体材料的纳米尺度特性提供了新的可能性。

Abstract: Scanning nitrogen-vacancy (NV) center electrometry has shown potential for
quantitative quantum imaging of electric fields at the nanoscale. However,
achieving nanoscale spatial resolution remains a challenge since employing
gradiometry to overcome electrostatic screening causes resolution-limiting
trade-offs including the averaging effect and the sensor-sample proximity.
Here, we demonstrate a scanning NV center protocol that achieves an enhanced
spatial resolution of approximately 10 nm. We develop an axially symmetric
probe with a sub-nanometer oscillating amplitude, which simultaneously provides
robust intermittent-contact mode feedback and ensures close engagement between
the diamond tip and the sample. As an example, we experimentally demonstrate a
10 nm spatial resolution on ferroelectric lithium niobate. Scanning NV center
electrometry with this resolution can directly resolve the nanoscale polar
textures and dynamics of emerging ferroelectrics, which commonly arise on the
scale of tens of nanometers.

</details>


### [511] [Quantum Functional Information through the Evolution of Random Circuits](https://arxiv.org/abs/2509.11409)
*Rodrigo Pasti,Jonas Krause*

Main category: quant-ph

TL;DR: QFI是一个新的量子状态和电路的稀有性和效用度量，它平衡了希尔伯特空间中的功能性和稀有性。


<details>
  <summary>Details</summary>
Motivation: 需要一个新的度量标准来量化量子状态和电路的稀有性和效用，以捕捉希尔伯特空间中的功能性和稀有性之间的平衡，而不是依赖于像保真度或熵这样的标准度量。

Method: 通过随机电路采样和由保真度或QFI目标引导的进化算法来验证QFI。

Result: 随机采样表明，接近完美保真度的状态信息量不如略有不足但更稀有的状态。保真度通常需要更少的门和更浅的电路。QFI优化比仅保真度优化能维持更广泛的探索，产生更丰富的结构，并倾向于具有高保真度的鲁棒电路。

Conclusion: QFI是一个实用且可解释的工具，可用于电路设计、基准测试、变分量子算法和探索量子系统中的新兴模式。

Abstract: We introduce Quantum Functional Information (QFI), a new metric to quantify
the
  rarity and utility of quantum states and circuits. Unlike standard measures
such as fidelity
  or entropy, QFI captures the balance between functionality and rarity within
the Hilbert
  space. We validate QFI through two approaches: random circuit sampling and
evolutionary
  algorithms guided by fidelity or QFI objectives. Random sampling shows that
states with
  near-perfect fidelity are less informational than slightly suboptimal but
rarer states, while
  correlations reveal that high fidelity typically requires fewer gates and
shallower circuits.
  Evolutionary results demonstrate that fidelity-only optimization converges
quickly but reduces
  diversity and robustness, whereas QFI optimization sustains exploration,
generates richer
  structures, and favors robust circuits with high fidelity. These findings
position QFI as
  a practical and interpretable tool for circuit design, benchmarking,
variational quantum
  algorithms, and exploring emergent patterns in quantum systems.

</details>


### [512] [Optimal single-mode squeezing for beam displacement sensing](https://arxiv.org/abs/2509.11457)
*Wenhua He,Christos N. Gagatsos,Dalziel J. Wilson,Saikat Guha*

Main category: quant-ph

TL;DR: 本研究通过将无限空间模式问题简化为三模式框架，研究了光学显微镜横向位移测量中的量子增强问题，并提出了量子最优探测策略。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决光学显微镜横向位移测量中的量子增强问题，并考虑了衍射损耗以及空间模式、压缩和相干振幅之间的联合优化。

Method: 将无限空间模式问题简化为三模式框架，并使用优化的单空间模式高斯态探针与最优经典激光探针进行比较，同时考虑了双空间模式零差探测器。

Result: 研究量化了优化的单空间模式高斯态探针相比于最优经典激光探针的改进，并证明了在探测能量较高时，双空间模式零差探测器对于高斯态探针是渐进最优的。

Conclusion: 本研究提出了在存在通用多模线性探针-目标相互作用和光子损耗的情况下，识别量子最优探针的策略。

Abstract: Estimation of an optical beam's transverse displacement is a canonical
imaging problem fundamental to numerous optical imaging and sensing tasks.
Quantum enhancements to the measurement precision in this problem have been
studied extensively. However, previous studies have neither accounted for
diffraction loss in full generality, nor have they addressed how to jointly
optimize the spatial mode and the balance between squeezing and coherent
amplitude. Here we show that, in the small-displacement limit, the seemingly
intractable infinite-spatial-mode problem can be reduced to a compact
three-mode interaction framework. We quantify the improvement afforded by an
optimized single-spatial-mode Gaussian-state probe over the optimal classical
laser probe, and show that a two-spatial-mode homodyne receiver is
asymptotically optimal for the former in the limit of high probe energy. Our
findings reveal a strategy for identifying quantum-optimal probes in the
presence of generic multimode linear probe-target interaction and photon loss.

</details>


### [513] [Observation of quantum-field-theory dynamics on a spin-phonon quantum computer](https://arxiv.org/abs/2509.11477)
*Anton T. Than,Saurabh V. Kadam,Vinay Vikramaditya,Nhung H. Nguyen,Xingxin Liu,Zohreh Davoudi,Alaina M. Green,Norbert M. Linke*

Main category: quant-ph

TL;DR: 量子计算机模拟量子场论的非平衡动力学，使用混合量子比特-玻色子系统，克服了传统方法的限制，并成功模拟了 (1+1) 维 Yukawa 模型。


<details>
  <summary>Details</summary>
Motivation: 经典方法难以模拟量子场论的非平衡动力学，尤其是在涉及相互作用的玻色子场时，存在高编码开销和截断误差问题。量子计算机，特别是结合量子比特和玻色子寄存器的混合系统，为模拟这些动力学提供了更有前途的平台。

Method: 在混合模拟-数字式离子阱量子计算机上，使用离子的内态编码量子比特，离子的运动态编码玻色子。通过实现量子比特、玻色子以及混合量子比特-玻色子量子门，模拟了 (1+1) 维 Yukawa 模型的非平衡动力学，并测量了费米子和玻色子占据态的概率。

Result: 实验结果成功捕捉到了从空态开始的、玻色子场激发的高度占据态，表明该方法能够有效模拟高能耗和长时间下的动力学过程。

Conclusion: 所提出的混合量子比特-玻色子模拟方法能够有效模拟量子场论的非平衡动力学，克服了经典方法的瓶颈，并避免了高昂的量子比特开销和截断误差，为在量子比特-玻色子量子计算中实现可验证的量子优势铺平了道路。

Abstract: Simulating out-of-equilibrium dynamics of quantum field theories in nature is
challenging with classical methods, but is a promising application for quantum
computers. Unfortunately, simulating interacting bosonic fields involves a high
boson-to-qubit encoding overhead. Furthermore, when mapping to qubits, the
infinite-dimensional Hilbert space of bosons is necessarily truncated, with
truncation errors that grow with energy and time. A qubit-based quantum
computer, augmented with an active bosonic register, and with qubit, bosonic,
and mixed qubit-boson quantum gates, offers a more powerful platform for
simulating bosonic theories. We demonstrate this capability experimentally in a
hybrid analog-digital trapped-ion quantum computer, where qubits are encoded in
the internal states of the ions, and the bosons in the ions' motional states.
Specifically, we simulate nonequilibrium dynamics of a (1+1)-dimensional Yukawa
model, a simplified model of interacting nucleons and pions, and measure
fermion- and boson-occupation-state probabilities. These dynamics populate high
bosonic-field excitations starting from an empty state, and the experimental
results capture well such high-occupation states. This simulation approaches
the regime where classical methods become challenging, bypasses the need for a
large qubit overhead, and removes truncation errors. Our results, therefore,
open the way to achieving demonstrable quantum advantage in qubit-boson quantum
computing.

</details>


### [514] [Classical State Detection Using Quantum State Tomography](https://arxiv.org/abs/2509.11509)
*Kim Fook Lee,Prem Kumar*

Main category: quant-ph

TL;DR: 文章提出了一个模型，用于检测与经典态混合的来自偏振纠缠对的闲置光子。通过在闲置通道中注入一个波长与闲置光子匹配的、具有确定偏振的弱相干光，并对经典混合闲置光子及其纠缠信号伙伴进行量子态断层扫描。重构态被建模为X量子态和经典-量子（CQ）态的组合。在该框架中，弱相干光作为测量装置，在闲置通道上执行局部偏振测量，从而诱导出经典态。通过对重构密度矩阵的对角和非对角元素进行算法分析来识别经典态的密度矩阵。


<details>
  <summary>Details</summary>
Motivation: 文章的动机在于提出一种检测经典态与来自偏振纠缠对的闲置光子混合的方法，并为量子网络和量子密钥分发等应用提供技术支持。

Method: 提出一个模型，将弱相干光注入闲置通道，并对经典混合闲置光子及其纠缠信号伙伴进行量子态断层扫描。重构态被建模为X量子态和CQ态的组合，其中弱相干光充当测量装置。通过算法分析重构密度矩阵的对角和非对角元素来识别经典态的密度矩阵。

Result: 重构态被建模为X量子态和CQ态的组合，并成功识别了经典态的密度矩阵。

Conclusion: 该方法可以推进经典-量子共存技术在网络应用（如量子包装）以及基于弱相干态和纠缠光子态共存的未来量子密钥分发协议中的应用。

Abstract: We present a model to detect a classical state mixed with an idler photon
from a polarization-entangled pair. A weak coherent light with a well-defined
polarization, matched in wavelength to the idler photon, is injected into the
idler channel. Quantum state tomography is then performed on both the
classically mixed idler photon and its entangled signal partner. The
reconstructed state is modeled as a combination of an $X-$quantum state and a
classical-quantum (CQ) state. In this framework, the weak coherent light acts
as a measurement apparatus performing a local polarization measurement on the
idler channel, thereby inducing a classical state. The density matrix of the
classical state is identified via algorithmic analysis of the diagonal and
off-diagonal elements of the reconstructed density matrix. This approach could
advance techniques for classical-quantum coexistence in networking
applications$\,-\,$such as quantum wrapping$\,-\,$as well as future quantum key
distribution protocols based on the coexistence of weak coherent states and
entangled photon states.

</details>


### [515] [Combinatorial optimization enhanced by shallow quantum circuits with 104 superconducting qubits](https://arxiv.org/abs/2509.11535)
*Xuhao Zhu,Zuoheng Zou,Feitong Jin,Pavel Mosharev,Maolin Luo,Yaozu Wu,Jiachen Chen,Chuanyu Zhang,Yu Gao,Ning Wang,Yiren Zou,Aosai Zhang,Fanhao Shen,Zehang Bao,Zitian Zhu,Jiarun Zhong,Zhengyi Cui,Yihang Han,Yiyang He,Han Wang,Jia-Nan Yang,Yanzhe Wang,Jiayuan Shen,Gongyu Liu,Zixuan Song,Jinfeng Deng,Hang Dong,Pengfei Zhang,Chao Song,Zhen Wang,Hekang Li,Qiujiang Guo,Man-Hong Yung,H. Wang*

Main category: quant-ph

TL;DR: 提出了一种基于量子采样策略的混合量子-经典算法，用于加速解决 Ising 模型的基态问题，并在 104 超导量子比特上实验验证，其效果优于经典的模拟退火算法。


<details>
  <summary>Details</summary>
Motivation: 组合优化问题在组合优化问题中具有广泛的应用，并且天然适合于 Ising 哈密顿量。然而，经典算法难以解决这些问题。

Method: 该算法采用混合量子-经典工作流程，其中一个浅层电路量子采样子程序专门用于遍历能量景观。

Result: 在最多 104 个超导量子比特上，该算法产生的有利解优于高度优化的经典模拟退火算法。此外，与单核 CPU 上的模拟退火算法相比，该算法在 100 个量子比特上显示了解决时间的量子加速。

Conclusion: 该算法为组合优化问题提供了一种有前景的经典启发式算法替代方案，并且有望在近期具有数千个量子比特的超导量子处理器上实现量子优势，而无需纠错。

Abstract: A pivotal task for quantum computing is to speed up solving problems that are
both classically intractable and practically valuable. Among these,
combinatorial optimization problems have attracted tremendous attention due to
their broad applicability and natural fitness to Ising Hamiltonians. Here we
propose a quantum sampling strategy, based on which we design an algorithm for
accelerating solving the ground states of Ising model, a class of NP-hard
problems in combinatorial optimization. The algorithm employs a hybrid
quantum-classical workflow, with a shallow-circuit quantum sampling subroutine
dedicated to navigating the energy landscape. Using up to 104 superconducting
qubits, we demonstrate that this algorithm outputs favorable solutions against
even a highly-optimized classical simulated annealing (SA) algorithm.
Furthermore, we illustrate the path toward quantum speedup based on the
time-to-solution metric against SA running on a single-core CPU with just 100
qubits. Our results indicate a promising alternative to classical heuristics
for combinatorial optimization, a paradigm where quantum advantage might become
possible on near-term superconducting quantum processors with thousands of
qubits and without the assistance of error correction.

</details>


### [516] [Efficient Preparation of Decoherence Free Subspace Basis States](https://arxiv.org/abs/2509.11544)
*Zi-Ming Li,Yu-xi Liu*

Main category: quant-ph

TL;DR: 提出了一种确定性的方法，用于制备任意大小的由量子比特组成的系统的纯正交和完备的DFS基态。


<details>
  <summary>Details</summary>
Motivation: 为实现容错量子计算，必须构建DFS的完备正交基态集。现有制备方法存在可扩展性差、平台特异性或产生混合态等问题。

Method: 利用投影测量和包含单量子比特、双量子比特以及Toffoli门的量子电路来制备DFS基态。

Result: 通过数学和数值方法进行了严格的资源成本分析，并展示了该方法在NISQ设备上的可实现性，包括在超导芯片上的实现方式。

Conclusion: 该方法为跨不同量子计算平台和系统大小的DFS基态制备提供了一个通用的解决方案，并且在NISQ时代是可实现的。

Abstract: Decoherence-free subspace (DFS) provides a crucial mechanism for passive
error mitigation in quantum computation by encoding information within
symmetry-protected subspaces of the Hilbert space, which are immune from
collective decoherence. Constructing a complete set of orthogonal basis states
for the DFS is essential to realize fault-tolerant quantum computation by using
the DFS codes. However, existing methods for preparing these basis states are
often non-scalable, platform-specific, or yield mixed states. Here, we propose
a deterministic approach to prepare pure, orthogonal and complete DFS basis
states for systems of arbitrary size composed of qubits. Our method employs
projective measurements and quantum circuits with single-qubit, two-qubit and
Toffoli gates. We provide a rigorous resource cost analysis both mathematically
and numerically. Meanwhile, we demonstrate the realizability of our method on
NISQ devices by discussing how to implement our method on a superconducting
chip. The proposed method offers a universal solution for preparing the DFS
basis states across diverse quantum computing platforms and system sizes, which
is realizable in the NISQ era.

</details>


### [517] [Strong antibunching photons/photon pairs emission in two atoms cavity QED system with the Van der Waals interaction](https://arxiv.org/abs/2509.11585)
*Zhouyang Yu,Jinping Xu,Chengjie Zhu,Zhengyang Bai,Yaping Yang*

Main category: quant-ph

TL;DR: vdW相互作用可用于提高单光子源的效率和亮度。


<details>
  <summary>Details</summary>
Motivation: 利用腔量子电动力学系统中的原子间范德华相互作用来生成反团聚光子和光子对，以提高量子光源的性能。

Method: 通过范德华相互作用移位双原子激发态，利用破坏性干涉抑制双光子上激发，并利用量子蒙特卡洛模拟来优化参数。

Result: 实现了高纯度的反团聚光子发射，并通过调整范德华相互作用强度实现了单光子发射的增强，同时在特定条件下生成了高纯度的反团聚光子对。

Conclusion: 范德华相互作用可以显著提高单光子和双光子的产生效率，有望用于开发更高效、更明亮的量子光源。

Abstract: Weinvestigate the generation of antibunching photons and photon pairs in a
two-atom cavity QED
  system leveraging interatomic van der Waals (vdW) interaction. We show that
the vdW interaction
  shifts the two-atom excited state, enabling the suppression of two-photon
excitation via destructive
  interference in a diamond configuration. This leads to antibunching photon
emission with extremely
  high purity. Furthermore, by tuning the vdW interaction strength, the
conditions for conventional
  and unconventional photon blockades can overlap, significantly enhancing
single-photon emission.
  Conversely, at the antiblockade excitation frequency, quantum Monte Carlo
simulations demonstrate
  the feasibility of generating antibunching photon pairs with a high purity
and reasonable leaking
  rate by selecting appropriate driving field Rabi frequency and vdW
interaction strength. These
  f
  indings on enhanced single/two-photon emission could lead to more efficient
and brighter quantum
  light sources.

</details>


### [518] [An inequality for relativistic local quantum measurements](https://arxiv.org/abs/2509.11599)
*Riccardo Falcone,Claudio Conti*

Main category: quant-ph

TL;DR: 有限探测器的真空不敏感性和激发敏感性之间的权衡，以测量局域性为基本约束。推导了在真空态中存在非零误报概率的情况下，真空激发可探测性的上限。该结果独立于测量细节或探测器物理机制，仅依赖于局域性假设。实验证实或违反该不等式将检验代数量子场论公理，为相对论量子物理中的测量问题提供新见解，并确立局域粒子探测的基本技术限制。


<details>
  <summary>Details</summary>
Motivation: 研究有限尺寸探测器在测量局域性约束下，真空不敏感性与激发敏感性之间的权衡。

Method: 推导了在真空态中存在非零误报概率的情况下，真空激发可探测性的上限。

Result: 结果独立于测量细节或探测器物理机制，仅依赖于局域性假设。

Conclusion: 实验证实或违反该不等式将检验代数量子场论公理，为相对论量子物理中的测量问题提供新见解，并确立局域粒子探测的基本技术限制。

Abstract: We investigate the trade-off between vacuum insensitivity and sensitivity to
excitations in finite-size detectors, taking measurement locality as a
fundamental constraint. We derive an upper bound on the detectability of vacuum
excitation, given a small but nonzero probability of false positives in the
vacuum state. The result is independent of the specific details of the
measurement or the underlying physical mechanisms of the detector and relies
only on the assumption of locality. Experimental confirmation or violation of
the inequality would provide a test of the axioms of algebraic quantum field
theory, offer new insights into the measurement problem in relativistic quantum
physics, and establish a fundamental technological limit in local particle
detection.

</details>


### [519] [Directly observing relativistic Bohmian mechanics](https://arxiv.org/abs/2509.11609)
*Yun-Fei Wang,Hui Wang,Tong Zhang,Yi-Teng Ye,Xiao-Yu Wang,Chao-Yang Lu,Jian-Wei Pan*

Main category: quant-ph

TL;DR: Bohmian力学已被直接观察到具有相对论效应，解决了其与相对论的长期不兼容问题，并揭示了光子的负质量密度和能量守恒但粒子数不守恒的新现象。


<details>
  <summary>Details</summary>
Motivation: Bohmian力学（也称为de Broglie-Bohm引导波理论）是量子力学的一种确定性、非局域性诠释，尽管自1927年提出以来，一直难以与相对论理论调和并验证其相对论效应。

Method: 利用弱测量技术在双缝干涉仪中重建了单个光子的相对论Bohmian轨迹，并测量了有效平方质量密度，同时实验检验了Klein-Gordon方程和Schrödinger方程的连续性方程。

Result: 观察到了Bohmian力学的相对论特性，包括光子的负有效平方质量密度（与相对论Bohmian力学中的快子行为相关）。实验表明，在相对论框架下，能量守恒得到满足，但自由标量场的粒子数守恒不再成立。

Conclusion: Bohmian力学能够解释双缝实验中先前未被观察到的现象，这些现象也为Bohmian力学中长期存在的相对论特征提供了明确的实验证据。

Abstract: Bohmian mechanics, also referred to as the de Broglie-Bohm pilot-wave theory,
represents a deterministic and nonlocal interpretation of quantum mechanics.
Since its origination in 1927, despite many attempts, reconciling it with
relativistic theory and verification of its relativistic effects have remained
elusive. Here, we report a direct observation of relativistic characteristics
of Bohmian mechanics. We reconstruct the relativistic Bohmian trajectories of
single photons utilizing weak measurement techniques in a double-slit
interferometer, unveiling a fundamental aspect of relativistic Bohmian
mechanics. We investigate the effective squared mass density of single photons,
revealing its negative values in the destructive regions -- a phenomenon
directly links to the tachyonic behavior in relativistic Bohmian mechanics. The
continuity equations given by both the Klein-Gordon equation and
Schr\"{o}dinger's equation are experimentally examined. Our result indicates
that within the framework of relativity, the conservation of energy holds true,
whereas the conservation of particle number for a free scalar field no longer
holds. The emergence of previously unobserved phenomena in the extensively
studied double-slit experiment are enabled by Bohmian mechanics, while
conversely, these experimental outcomes offer unambiguous evidence of the
long-sought-after relativistic features within Bohmian mechanics.

</details>


### [520] [Long-exposure Camera Readout for Coherent Control of Nitrogen-Vacancy Center Spins in Diamond](https://arxiv.org/abs/2509.11723)
*Jiahui Chen,Qilong Wu,Huihui Yu,Yi-Dan Qu,Yuan Zhang,Xun Yang,Chong-Xin Shan*

Main category: quant-ph

TL;DR: 在宽场量子噪声光谱学（QNS）中，通过金刚石中的氮-空位（NV）自旋，可以实现具有亚微米空间分辨率的直流和交流磁场噪声提取。然而，其实现受到最佳光学自旋读出时间和最小相机曝光时间之间矛盾的限制。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决相机式宽场量子噪声光谱学（QNS）中，NV自旋的最佳光学读出时间（通常低于1微秒）与相机最小曝光时间（通常为几十微秒）之间的矛盾。

Method: 通过自行搭建的相机系统，实现NV自旋的完全相干控制，包括Rabi振荡、Ramsey、Hahn回波和弛豫测量实验，并实现了12%的高对比度，光学自旋读出时间为500微秒。

Result: 发现光学自旋读出机制在弱激光照射下，由于自旋-晶格弛豫和弱光学泵浦，对比度随积分时间的增加而缓慢下降，从而消除了读出时间和曝光时间之间的矛盾。

Conclusion: 揭示的机制对于构建宽场QNS以及其在磁性材料或超导材料研究中的应用具有指导意义。

Abstract: Camera-based wide-field quantum noise spectroscopy (QNS) with
nitrogen-vacancy (NV) center spins in diamond can be used to extract DC and AC
magnetic field noise with sub-micrometer spatial resolution, but its
realization is currently limited by the conflict between the optimal optical
spin readout time (normally below one microsecond) and the minimal camera
exposure time (normally tens of microsecond). In the present article, we
demonstrate fully coherent control of NV center spins via Rabi oscillation,
Ramsey, Hahn echo and relaxometry experiments, i.e. the core of QNS, with a
home-built camera-based setup, and achieve an unexpectedly high contrast of 12%
with an optical spin readout time of 500 microseconds. We explain the absence
of the above conflict in our system with the optical spin readout mechanism
under weak laser illumination, where spin-lattice relaxation and weak optical
pumping result in a rather slow reduction of contrast with increasing
integration time. The revealed mechanism is instructive for the construction of
the wide-field QNS with a sCMOS or EMCCD camera, and its application in the
studies of magnetic material or superconducting material.

</details>


### [521] [Improving Free-Space Continuous Variable Quantum Key Distribution with Adaptive Optics](https://arxiv.org/abs/2509.11759)
*Mikhael T. Sayat,Marcus Birch,Michael Copeland,Elisa Jager,Oliver Thearle,Francis Bennet,Ping Koy Lam,Nicholas J. Rattenbury,John E. Cater*

Main category: quant-ph

TL;DR: 湍流会降低自由空间量子密钥分发（CVQKD）的性能，导致相位和幅度畸变。通过在接收端加入自适应光学系统，可以校正这些畸变，提高本地振荡器（LO）和量子信号之间的干涉可见度，从而在理想CVQKD系统中实现更高和更稳定的密钥生成速率。


<details>
  <summary>Details</summary>
Motivation: 湍流会严重影响自由空间连续变量量子密钥分发（CVQKD）的性能，导致波前相位和幅度畸变。

Method: 在湍流信道中，通过相干态传输，研究了本地振荡器（LO）和量子信号之间的干涉可见度下降问题。提出并验证了在接收端采用自适应光学（AO）技术来校正波前畸变的方法。

Result: 实验证明，在60厘米和30米长的湍流信道中，使用自适应光学系统可以显著提高干涉可见度并减小其波动。理论上表明，这可以提高理想CVQKD系统的秘密密钥生成速率，从而改善其在湍流信道中的性能。

Conclusion: 自适应光学系统能够有效校正湍流引起的波前畸变，提高自由空间CVQKD系统的性能，增加秘密密钥的生成速率。

Abstract: A significant performance inhibitor of free-space continuous variable quantum
key distribution (CVQKD) is turbulence, which gives rise to wavefront phase and
amplitude aberrations. We demonstrate that in a turbulent channel, during
coherent state transmissions from a continuous-wave laser, that the
interferometric visibility between the local oscillator (LO) and quantum signal
decreases. A solution to this is incorporating adaptive optics at the receiver
to correct phase and amplitude aberrations in the wavefronts of the received
quantum signal. We demonstrate the increased interferometric visibility and
decrease in its fluctuations in a 60 cm and 30 m turbulent channel when using
adaptive optics through channel characterisation. In an ideal CVQKD system, we
show that this leads to more precise and larger positive secret key rates,
improving the performance of free-space CVQKD in turbulent channels.

</details>


### [522] [Emergence of Symmetry in a System of Distinguishable but Identical Particles](https://arxiv.org/abs/2509.11779)
*Allan Tameshtit*

Main category: quant-ph

TL;DR: 本文提出了一种通过环境诱导退相干实现连续对称化的新方法，并将其应用于分析两粒子碰撞问题。


<details>
  <summary>Details</summary>
Motivation: 与传统通过投影算符构造对称和反对称态的方法不同，本文探索了更快速的连续对称化途径。

Method: 利用半群映射将密度算符转化为对称可观测量，并利用完全正的动力学映射将完全不对称态转化为对称或反对称态。

Result: 将该理论应用于分析具有任意自旋且自旋相互作用可忽略的两个全同粒子的碰撞。

Conclusion: 讨论了通过非完全正的动力学映射将理论扩展到更大范围的可能性。

Abstract: Instead of the conventional construction of symmetric and antisymmetric
states by abruptly projecting with the symmetrizer or antisymmetrizer, this
paper investigates rapid but continuous symmetrization via environment-induced
decoherence. Density operators are transformed to a symmetric observable via a
semigroup map obtained from an interacting Hamiltonian. Likewise, a completely
positive dynamical map transforms a completely asymmetric state to either a
symmetric or antisymmetric state. The theory is applied to analyze a collision
between two identical particles having arbitrary spin and negligible spin
interactions. We discuss extensions to larger domains via dynamical maps that
are not completely positive.

</details>


### [523] [High-performance multiplexed readout of superconducting qubits with a tunable broadband Purcell filter](https://arxiv.org/abs/2509.11822)
*Yuzhe Xiong,Zilin Wang,Jiawei Zhang,Xuandong Sun,Zihao Zhang,Peisheng Huang,Yongqi Liang,Ji Jiang,Jiawei Qiu,Yuxuan Zhou,Xiayu Linpeng,Wenhui Huang,Jingjing Niu,Youpeng Zhong,Ji Chu,Song Liu,Dapeng Yu*

Main category: quant-ph

TL;DR: 通过动态调谐可调宽带Purcell滤波器，实现了超导量子比特的快速、高保真度、低背离读出，有效解决了测量速度和光子噪声引起的退相干之间的权衡，为量子纠错提供了有前景的解决方案。


<details>
  <summary>Details</summary>
Motivation: 量子纠错（QEC）的进展需要快速、高保真度和低背离的读出。本研究旨在解决测量速度和光子噪声引起的退相干之间的基本权衡问题。

Method: 演示了使用可调宽带Purcell滤波器对超导量子比特进行多路复用读出。通过动态调谐滤波器参数，抑制了空闲状态下的光子噪声引起的退相干，并在测量状态下实现了快速、高保真的读出。采用了多层读出协议，并提出了一种可扩展的表面码QEC读出方案。

Result: 实现了99.6%的单次读出保真度（100 ns读出脉冲），99.9%的保真度（50 ns），以及99.5%的三比特同步读出（100 ns读出脉冲）。量子非破坏（QND）保真度达到99.4%，泄漏率低于0.1%。

Conclusion: 所提出的可调宽带Purcell滤波器和多层读出协议实现了超导量子比特的高性能读出，并为表面码QEC提出了一个具有增强的多路复用能力的、可扩展的读出方案，为实现快速可扩展的QEC提供了一种有前景的解决方案。

Abstract: Fast, high-fidelity, and low back-action readout plays a crucial role in the
advancement of quantum error correction (QEC). Here, we demonstrate
high-performance multiplexed readout of superconducting qubits using a tunable
broadband Purcell filter, effectively resolving the fundamental trade-off
between measurement speed and photon-noise-induced dephasing. By dynamically
tuning the filter parameters, we suppress photon-noise-induced dephasing by a
factor of 7 in idle status, while enabling rapid, high-fidelity readout in
measurement status. We achieve 99.6\% single-shot readout fidelity with 100~ns
readout pulse, limited primarily by relaxation errors during readout. Using a
multilevel readout protocol, we further attain 99.9\% fidelity in 50~ns.
Simultaneous readout of three qubits using 100~ns pulses achieves an average
fidelity of 99.5\% with low crosstalk. Additionally, the readout exhibits high
quantum-nondemolition (QND) performance: 99.4\% fidelity over repeated
measurements and a low leakage rate below 0.1\%. Building on the tunable
broadband filter, we further propose a scalable readout scheme for surface code
QEC with enhanced multiplexing capability, offering a promising solution for
fast and scalable QEC.

</details>


### [524] [Localised solution of stochastic Schrödinger equation describing simultaneous continuous measurement of position and momentum](https://arxiv.org/abs/2509.11832)
*Daniel J. Bedingham*

Main category: quant-ph

TL;DR: 该论文提出并求解了一个随机薛定谔方程，用于描述粒子位置和动量的连续测量。


<details>
  <summary>Details</summary>
Motivation: 描述粒子位置和动量的连续测量

Method: 提出并求解了随机薛定谔方程

Result: 得到了一个在位置和动量上都局部化的态，该态表现为中心在相空间中随机运动的固定高斯形状的波包，并且是局部稳定的。

Conclusion: 粒子在经过一段时间的连续测量后趋向于一个在位置和动量上都局部化的态，该态由一个中心在相空间中随机运动的固定高斯形状的波包表示，并且是局部稳定的。

Abstract: A stochastic Schr\"odinger equation is presented to describe simultaneous
continuous measurement of the position and momentum of a non-relativistic
particle. The equation is solved to yield a state localised in position and
momentum contingent on the uncertainty principle. The state is understood as
that to which the particle tends after a period of continuous measurement. The
solution takes the form of a wave packet of fixed Gaussian shape whose centre
undergoes random motion in phase space. It is shown to be locally stable.

</details>


### [525] [Optimizing Quantum Photonic Integrated Circuits using Differentiable Tensor Networks](https://arxiv.org/abs/2509.11861)
*Mathias Van Regemortel,Thomas Van Vaerenbergh*

Main category: quant-ph

TL;DR: 本研究提出了一种用于量子光子集成电路的梯度优化方法，该方法利用可微分张量网络来处理低光子占据和适度纠缠的情况，并针对量子态制备和量子相位传感进行了优化。


<details>
  <summary>Details</summary>
Motivation: 利用半导体中激子光-物质的强耦合实现的大型光子非线性效应，需要在低光子占据极限下为量子处理量身定制设计框架。

Method: 采用基于梯度的优化方法，利用可微分张量网络来设计量子光子集成电路，该电路包含非线性酉耦合门和用于采样光子损耗的随机非酉组件。

Result: 通过对 GaAs 基样本进行场模拟来表征电路门架构，并成功优化了用于量子态制备和量子相位传感的集成电路。

Conclusion: 所提出的基于可微分张量网络的梯度优化方法适用于量子光子集成电路的设计，特别是在低光子占据和适度纠缠的条件下，并在实际应用中得到了验证。

Abstract: Recent reports of large photonic nonlinearities in integrated photonic
devices, using the strong excitonic light-matter coupling in semiconductors,
necessitate a tailored design framework for quantum processing in the limit of
low photon occupation. We present a gradient-based optimization method for
quantum photonic integrated circuits, which are composed of nonlinear unitary
coupling gates and stochastic, nonunitary components for sampling the photonic
losses. As core of our method, differentiable tensor-networks are leveraged,
which are accurate in the regime of low photonic occupation and modest
intermode entanglement. After characterizing the circuit gate architecture with
field simulations of GaAs-based samples, we demonstrate the applicability of
our method by optimizing quantum photonic circuits for two key use cases:
integrated designs for quantum optical state preparation and tailored optimal
readout for quantum phase sensing.

</details>


### [526] [Autonomous stabilization of remote entanglement in a cascaded quantum network](https://arxiv.org/abs/2509.11872)
*Abdullah Irfan,Kaushik Singirikonda,Mingxing Yao,Andrew Lingenfelter,Michael Mollenhauer,Xi Cao,Aashish A. Clerk,Wolfgang Pfaff*

Main category: quant-ph

TL;DR: The paper demonstrates autonomous stabilization of entanglement between two separate superconducting-qubit devices, achieving distance-independent steady-state remote entanglement with a concurrence approaching 0.5. This is achieved through nonreciprocal waveguide coupling and local driving, with enhancements to overcome disorder.


<details>
  <summary>Details</summary>
Motivation: Generating entanglement between qubits at arbitrary distances requires the distribution of propagating quantum states. The paper addresses the question of whether this entanglement can be stabilized indefinitely, rather than only periodically reestablished after decay.

Method: The researchers combined nonreciprocal waveguide coupling and local driving in a coherent quantum-absorber scheme to experimentally realize distance-independent steady-state remote entanglement. They also enhanced the scheme with a new approach for overcoming inevitable disorder.

Result: The experiment achieved distance-independent steady-state remote entanglement with a concurrence approaching 0.5. This represents a significant step towards on-demand entanglement delivery and protection of multipartite entanglement in open systems.

Conclusion: The results demonstrate the autonomous stabilization of entanglement between remote superconducting qubits, paving the way for on-demand entanglement delivery in quantum processors and networks, and for protecting multipartite entanglement in open systems.

Abstract: Remote entanglement between independent and widely separated qubits is an
essential quantum phenomenon and a critical resource for quantum information
applications. Generating entanglement between qubits at arbitrary distances
requires the distribution of propagating quantum states. This necessity raises
the intriguing question whether the entanglement can be stabilized
indefinitely, instead of only periodically reestablished after decay. Here, we
report autonomous stabilization of entanglement between two separate
superconducting-qubit devices. Combining nonreciprocal waveguide coupling and
local driving, we experimentally realize distance-independent steady-state
remote entanglement in a coherent quantum-absorber scheme. Enhancing this
scheme with a new approach for overcoming inevitable disorder, we achieve a
concurrence approaching 0.5. Our results set the stage for on-demand
entanglement delivery in quantum processors and networks, and for protecting
multipartite entanglement in open systems.

</details>


### [527] [Quantum Communication with Quantum Dots Beyond Telecom Wavelengths via Hollow-Core Fibers](https://arxiv.org/abs/2509.11889)
*Lorenzo Carosini,Francesco Giorgino,Patrik I. Sund,Lena M. Hansen,Rene R. Hamel,Lee A. Rozema,Francesco Poletti,Radan Slavík,Philip Walther,Christopher Hilweg*

Main category: quant-ph

TL;DR: 高级量子点单光子源在900 nm附近工作，但标准单模光纤在此波长下损耗较大。本研究采用一种低损耗（0.65 dB/km）的空芯光纤，能在量子点波长（934 nm）和1550 nm（用于经典信号）下工作。实验将量子点产生的BB84偏振态在340 m的距离上传输，获得了0.1%的量子比特错误率（QBER），并保持了单光子纯度和不可分辨性。


<details>
  <summary>Details</summary>
Motivation: 解决现有量子点单光子源工作在900 nm附近，而标准光纤在此波长下损耗较大的问题，以实现更远距离的量子通信。

Method: 采用一种在量子点波长（934 nm）和1550 nm（用于经典信号）下均具有低损耗的空芯光纤，并传输了基于量子点的BB84偏振态信号。

Result: 在340 m的传输距离上，实现了0.1%的量子比特错误率（QBER），并成功保持了单光子纯度和不可分辨性，即使在存在强经典信号的情况下。

Conclusion: 定制化的传输介质（如本研究中的空芯光纤）能够克服标准电信光纤的限制，实现超越现有能力的量子网络。

Abstract: Quantum dot single-photon sources are promising for quantum communication.
Yet, the most advanced devices operate near 900 nm, where standard single-mode
fibers experience significant losses. We address this by employing a
hollow-core fiber engineered for low-loss transmission at quantum dot
wavelengths, with measured loss of 0.65 dB/km and potentially as low as 0.12
dB/km near 934 nm. The fiber also supports strong classical signals at 1550 nm
without adding Raman noise. Using this platform, we transmit all four BB84
polarization states from an InAs quantum dot over 340 m with 0.1% QBER,
preserving single-photon purity and indistinguishability even in the presence
of a strong classical signal. These results highlight how tailored transmission
media enable quantum networks beyond the limits of standard telecom fibers.

</details>


### [528] [Quantum Algorithms in the Quantum Mechanics Curriculum](https://arxiv.org/abs/2509.11893)
*Anna Liv Paludan Bjerregaard,Kim Splittorff*

Main category: quant-ph

TL;DR: 本 papers 提出了一个利用 Aharonov-Bohm 效应的量子系统，该系统在数值问题上比经典计算机更有效率，可用于标准量子力学课程，旨在帮助学生建立量子算法的物理直觉。


<details>
  <summary>Details</summary>
Motivation: 本 papers 的动机是提供一个具体示例，展示量子系统如何比经典计算机更高效地解决数值问题，并将其融入标准量子力学课程，以增强学生对量子算法的物理理解。

Method: 本 papers 提出使用 Aharonov-Bohm 效应的量子系统来解决数值问题。

Result: 量子系统在数值问题上的解决效率优于经典计算机。

Conclusion: 通过 Aharonov-Bohm 效应的量子系统示例，可以帮助学生更好地理解量子算法。

Abstract: We provide an example of a quantum system which solves a numerical problem
more efficiently than a classical computer. The example uses the Aharonov-Bohm
effect, and can be integrated into standard quantum mechanics courses. The aim
is to help students build a physical intuition for quantum algorithms.

</details>


### [529] [Towards a Global Scale Quantum Information Network: A Study Applied to Satellite-Enabled Distributed Quantum Computing](https://arxiv.org/abs/2509.11908)
*Laurent de Forges de Parny,Luca Paccard,Mathieu Bertrand,Luca Lazzarini,Valentin Leloup,Raphael Aymeric,Agathe Blaise,Stéphanie Molin,Pierre Besancenot,Cyrille Laborde,Mathias van den Bossche*

Main category: quant-ph

TL;DR: 通过基于卫星的量子信息网络，在法国国家范围内实现分布式量子计算。


<details>
  <summary>Details</summary>
Motivation: 为了解决可扩展性问题，提出了一种基于现有基础设施的卫星支持的分布式量子计算系统，用于连接小型量子寄存器。

Method: 提出并评估了一个由地面和空间部分组成的系统，利用它可以在巴黎和尼斯之间分配端到端的纠缠，每个地方都有一个由离子阱组成的小型量子处理器。

Result: 对该基于卫星的量子信息网络产生的纠缠分发速率和保真度进行了数值评估。

Conclusion: 该系统有望实现分布式量子计算，并讨论了具体的用例和服务性能水平。

Abstract: Recent developments have reported on the feasibility of interconnecting small
quantum registers in a quantum information network of a few meter-scale for
distributed quantum computing purposes. This multiple small-scale quantum
processors communicating and cooperating to execute computational tasks is
considered as a promising solution to the scalability problem of reaching more
than thousands of noise-free qubits. Here, we propose and assess a
satellite-enabled distributed quantum computing system at the French national
scale, based on existing infrastructures in Paris and Nice. We consider a
system composed of both a ground and a space segment, allowing for the
distribution of end-to-end entanglement between Alice in Paris and Bob in Nice,
each owning a few-qubit processor composed of trapped ions. In the context of
quantum computing, this entanglement resource can be used for the teleportation
of a qubit state or for gate teleportation. We numerically assess the
entanglement distribution rate and fidelity generated by this space-based
quantum information network, and discuss concrete use cases and service
performance levels in the framework of distributed quantum computing.

</details>


### [530] [Quantum Storage of Qubits in an Array of Independently Controllable Solid-State Quantum Memories](https://arxiv.org/abs/2509.11910)
*Markus Teller,Susana Plascencia,Samuele Grandi,Hugues de Riedmatten*

Main category: quant-ph

TL;DR: Researchers developed a random-access quantum memory using solid-state memory cells, achieving high fidelities for storing and retrieving quantum information (path and time-bin qubits) on demand. This technology is a step towards quantum repeaters and processors.


<details>
  <summary>Details</summary>
Motivation: Random-access quantum memories are crucial for advancing quantum computation and networking.

Method: Developed and tested an array of ten solid-state quantum memory cells capable of temporally multiplexed storage. Implemented quantum storage of path and time-bin qubits using weak coherent states at the single-photon level. Demonstrated controllable addressing, arbitrary storage combinations, on-demand read-out, and sequential storage in different cells.

Result: Achieved average fidelities of 95% for path qubits and 91% for time-bin qubits, violating classical bounds for all ten cells. Successfully demonstrated sequential storage and simultaneous maintenance of two time-bin qubits.

Conclusion: The demonstrated individual control and high storage fidelity represent a significant advancement in creating solid-state random-access quantum memories suitable for quantum repeaters and photonic quantum processors.

Abstract: Random-access quantum memories may offer computational advantages for quantum
computers and networks. In this paper, we advance arrays of solid-state quantum
memories towards their usage as random-access quantum memory. We perform
quantum storage of path and time-bin qubits implemented with weak coherent
states at the single-photon level, in an array of ten temporally-multiplexed
memory cells with controllable addressing. The qubits can be stored in
arbitrary combinations of memory cells, from which they are read-out on demand.
We find average fidelities of $95_{-2}^{+2}\;\%$ for path qubits and
$91^{+2}_{-2}\;\%$ for time-bin qubits. The measured fidelities violate the
classical bounds for both encodings and for all ten cells. We also sequentially
store a time-bin qubit in two different memory cells, maintain both qubits
simultaneously in the array, and perform a collective read-out. The individual
control paired with high storage fidelity represents a significant advance
towards a solid-state random-access quantum memory for quantum repeaters and
photonic quantum processors.

</details>


### [531] [Quantum Noise Tomography with Physics-Informed Neural Networks](https://arxiv.org/abs/2509.11911)
*Antonin Sulc*

Main category: quant-ph

TL;DR: PINNs可用于量子系统态演化和耗散参数的重构，提供了一种高效且可扩展的量子设备表征方法。


<details>
  <summary>Details</summary>
Motivation: 量子系统的环境交互表征是量子技术发展的关键瓶颈，而传统方法数据量大且难以扩展。

Method: 提出使用物理信息神经网络（PINNs）进行Lindblad层析成像，将Lindblad主方程嵌入神经网络的损失函数中，以从稀疏的时间序列测量数据中学习量子态演化并推断耗散参数。

Result: PINNs能够重构量子系统动力学和未知噪声参数的功能形式，具有样本效率高和可扩展性强的优点。

Conclusion: 所提出的方法通过学习控制量子噪声系统的控制主方程，生成了一个完全可微分的数字孪生。

Abstract: Characterizing the environmental interactions of quantum systems is a
critical bottleneck in the development of robust quantum technologies.
Traditional tomographic methods are often data-intensive and struggle with
scalability. In this work, we introduce a novel framework for performing
Lindblad tomography using Physics-Informed Neural Networks (PINNs). By
embedding the Lindblad master equation directly into the neural network's loss
function, our approach simultaneously learns the quantum state's evolution and
infers the underlying dissipation parameters from sparse, time-series
measurement data. Our results show that PINNs can reconstruct both the system
dynamics and the functional form of unknown noise parameters, presenting a
sample-efficient and scalable solution for quantum device characterization.
Ultimately, our method produces a fully-differentiable digital twin of a noisy
quantum system by learning its governing master equation.

</details>


### [532] [Formation of oriented polar molecules with a single shaped pulse](https://arxiv.org/abs/2509.11968)
*Murilo D. Forlevesi,Edson Denis Leonel,Emanuel F. de Lima*

Main category: quant-ph

TL;DR: 通过控制场优化原子碰撞过程，直接生成定向极性分子。


<details>
  <summary>Details</summary>
Motivation: 探索直接从原子碰撞形成定向极性分子的可能性。

Method: 利用最优量子控制算法设计单一时间依赖、线性偏振的控制场，驱动光缔合、振动稳定和分子定向过程，并直接求解薛定谔方程。

Result: 优化的控制场能够增强光缔合和振动稳定过程本身已经诱导的分子取向，从而生成定向的极性分子。

Conclusion: 提出的方法能够有效地生成定向极性分子，这些分子在多种应用中具有潜在价值。

Abstract: We explore the possibility of forming a oriented polar molecule directly from
a pair of colliding atoms. The process comprises the photoassociation and
vibrational stabilization along with the molecular orientation. These processes
are driven by a single time-dependent, linearly polarized control field and
proceeds entirely within the electronic ground state, leveraging the presence
of a permanent dipole moment. The control field is found by means of an optimal
quantum control algorithm with a single target observable given by the
restriction of the orientation operator on a subset of bound levels. We
consider a rovibrational model system for the collision of O + H atoms and
solve directly the time-dependent Schrodinger equation. We show that the
optimized field is capable of enhancing the molecular orientation already
induced by the photoassociation and vibrational stabilization thus yielding
oriented polar molecules that can be useful for many applications.

</details>


### [533] [Approximating the operator norm of local Hamiltonians via few quantum states](https://arxiv.org/abs/2509.11979)
*Lars Becker,Joseph Slote,Alexander Volberg,Haonan Zhang*

Main category: quant-ph

TL;DR: 当A是低度Pauli展开的Hermitian算子时，可以通过在一个小的乘积状态集合X_n上最大化<psi|A|psi>来近似A的算子范数，且该范数独立于n。


<details>
  <summary>Details</summary>
Motivation: Hermitian算子A作用在维度为2^n的复希尔伯特空间上，当A的Pauli展开度数较小时，其算子范数可以被近似。

Method: 通过在一个小的乘积状态集合X_n上最大化<psi|A|psi>来近似算子范数。

Result: 当A是d-局部的（即deg(A)<=d）时，存在一个仅与d相关的常数C(d)，使得||A||<=C(d)max_psi in X_n |<psi|A|psi>|。这个X_n是一个量子范数设计，由乘积状态组成，其基数可以小至(1+eps)^n。

Conclusion: 该研究提供了Hermitian算子A的算子范数的一个不依赖于n的近似界限，该界限可以通过在一个小的乘积状态集合上评估A的期望值来获得。此外，还给出了Rademacher投影的有界性和随机Hamiltonian算子范数的估计。

Abstract: Consider a Hermitian operator $A$ acting on a complex Hilbert space of
dimension $2^n$. We show that when $A$ has small degree in the Pauli expansion,
or in other words, $A$ is a local $n$-qubit Hamiltonian, its operator norm can
be approximated independently of $n$ by maximizing $|\braket{\psi|A|\psi}|$
over a small collection $\mathbf{X}_n$ of product states $\ket{\psi}\in
(\mathbf{C}^{2})^{\otimes n}$. More precisely, we show that whenever $A$ is
$d$-local, \textit{i.e.,} $\deg(A)\le d$, we have the following
discretization-type inequality:
  \[ \|A\|\le C(d)\max_{\psi\in \mathbf{X}_n}|\braket{\psi|A|\psi}|.
  \] The constant $C(d)$ depends only on $d$. This collection $\mathbf{X}_n$ of
$\psi$'s, termed a \emph{quantum norm design}, is independent of $A$, and
consists of product states, and can have
  cardinality as small as $(1+\eps)^n$, which is essentially tight. Previously,
norm designs were known only for homogeneous $d$-localHamiltonians $A$
\cite{L,BGKT,ACKK}, and for non-homogeneous $2$-local traceless $A$
\cite{BGKT}.
  Several other results, such as boundedness of Rademacher projections for all
levels and estimates of operator norms of random Hamiltonians, are also given.

</details>


### [534] [Characterizing Scaling Trends of Post-Compilation Circuit Resources for NISQ-era QML Models](https://arxiv.org/abs/2509.11980)
*Rupayan Bhattacharjee,Pau Escofet,Santiago Rodrigo,Sergi Abadal,Carmen G. Almudever,Eduard Alarcón*

Main category: quant-ph

TL;DR: 研究了量子机器学习模型在连接受限的NISQ处理器上的编译后电路资源扩展特性，分析了量子核方法和量子神经网络在不同处理器拓扑下的SWAP开销、电路深度和两比特门计数。


<details>
  <summary>Details</summary>
Motivation: 研究量子机器学习模型在连接受限的NISQ处理器上的编译后电路资源扩展特性，以指导硬件感知的量子机器学习模型设计。

Method: 分析了量子核方法和量子神经网络在不同处理器拓扑（线性、环形、网格、星形）下的SWAP开销、电路深度和两比特门计数，并进行了不同纠缠策略的影响分析。最后，在考虑了实际噪声模型的情况下，通过保真度分析建立了硬件改进与最大可靠量子比特数之间的量化关系。

Result: 发现纠缠策略显著影响资源扩展，其中圆形和移位的圆形交替策略扩展最快。环形拓扑在大多数量子机器学习模型中表现出最慢的资源扩展。树张量网络在编译后失去了对数深度优势。硬件改进与最大可靠量子比特数之间存在量化关系。

Conclusion: 在连接受限的NISQ处理器上，不同的量子机器学习模型和纠缠策略对编译后电路资源的扩展有显著影响。环形拓扑和特定的纠缠策略在资源扩展方面具有优势。研究结果为硬件感知的量子机器学习模型设计提供了指导。

Abstract: This work investigates the scaling characteristics of post-compilation
circuit resources for Quantum Machine Learning (QML) models on
connectivity-constrained NISQ processors. We analyze Quantum Kernel Methods and
Quantum Neural Networks across processor topologies (linear, ring, grid, star),
focusing on SWAP overhead, circuit depth, and two-qubit gate count. Our
findings reveal that entangling strategy significantly impacts resource
scaling, with circular and shifted circular alternating strategies showing
steepest scaling. Ring topology demonstrates slowest resource scaling for most
QML models, while Tree Tensor Networks lose their logarithmic depth advantage
after compilation. Through fidelity analysis under realistic noise models, we
establish quantitative relationships between hardware improvements and maximum
reliable qubit counts, providing crucial insights for hardware-aware QML model
design across the full-stack architecture.

</details>


### [535] [Evaluating Variational Quantum Circuit Architectures for Distributed Quantum Computing](https://arxiv.org/abs/2509.12005)
*Leo Sünkel,Jonas Stein,Jonas Nüßlein,Tobias Rohe,Claudia Linnhoff-Popien*

Main category: quant-ph

TL;DR: 分布式量子计算设置中，使用较少跨量子处理器（QPU）纠缠的变分量子电路（VQC）在噪声下表现更好。


<details>
  <summary>Details</summary>
Motivation: 扩展量子计算机（量子处理单元，QPU）以执行大型量子电路，尤其是在需要提供超越经典算法的量子优势的应用中，是一个主要挑战。一种扩展QPU的方法是通过量子和经典通道连接多个机器，形成集群甚至量子网络。然而，QPU之间的通信成本高昂，需要生成和维持纠缠，因此应明智地使用。

Method: 使用Qiskit模拟一个八量子比特电路的执行，该电路使用四个QPU，每个QPU有两个计算量子比特和两个通信量子比特，并使用远程CX协议执行非局部CX门。在理想条件下训练和噪声条件下测试的情况下，比较了各种电路在二元分类任务上的性能。

Result: 在噪声条件下，与标准的VQC基线相比，那些谨慎使用QPU之间纠缠的替代体系结构在二元分类任务上表现出更好的性能。

Conclusion: 该研究为DQC范式提供了合适的VQC架构的初步结果，并表明标准的VQC基线并非总是最佳选择，而是那些谨慎使用QPU之间纠缠的替代架构在噪声下能提供更好的结果。

Abstract: Scaling quantum computers, i.e., quantum processing units (QPUs) to enable
the execution of large quantum circuits is a major challenge, especially for
applications that should provide a quantum advantage over classical algorithms.
One approach to scale QPUs is to connect multiple machines through quantum and
classical channels to form clusters or even quantum networks. Using this
paradigm, several smaller QPUs can collectively execute circuits that each
would not be able on its own. However, communication between QPUs is costly as
it requires generating and maintaining entanglement, and hence it should be
used wisely. In this paper, we evaluate the architectures, and in particular
the entanglement patterns, of variational quantum circuits in a distributed
quantum computing (DQC) setting. That is, using Qiskit, we simulate the
execution of an eight qubit circuit using four QPUs each with two computational
and two communication qubits where non-local CX-gates are performed using the
remote-CX protocol. We compare the performance of various circuits on a binary
classification task where training is executed under ideal and testing under
noisy conditions. The study provides initial results on suitable VQC
architectures for the DQC paradigm, and indicates that a standard VQC baseline
is not always the best choice, and alternative architectures that use
entanglement between QPUs sparingly deliver better results under noise.

</details>


### [536] [Spectral Small-Incremental-Entangling: Breaking Quasi-Polynomial Complexity Barriers in Long-Range Interacting Systems](https://arxiv.org/abs/2509.12014)
*Donghoon Kim,Yusuke Kimura,Hugo Mackay,Yosuke Mitsuhashi,Hideaki Nishikawa,Carla Rubiliani,Cheng Shang,Ayumi Ukai,Tomotaka Kuwahara*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A key challenge in quantum complexity is how entanglement structure emerges
from dynamics, highlighted by advances in simulators and information
processing. The Lieb--Robinson bound sets a locality-based speed limit on
information propagation, while the Small-Incremental-Entangling (SIE) theorem
gives a universal constraint on entanglement growth. Yet, SIE bounds only total
entanglement, leaving open the fine entanglement structure. In this work, we
introduce Spectral-Entangling Strength, measuring the structural entangling
power of an operator, and prove a Spectral SIE theorem: a universal limit for
R\'enyi entanglement growth at $\alpha \ge 1/2$, revealing a robust $1/s^2$
tail in the entanglement spectrum. At $\alpha=1/2$ the bound is qualitatively
and quantitatively optimal, identifying the universal threshold beyond which
growth is unbounded. This exposes the detailed structure of Schmidt
coefficients, enabling rigorous truncation-based error control and linking
entanglement to computational complexity. Our framework further establishes a
generalized entanglement area law under adiabatic paths, extending a central
principle of many-body physics to general interactions. Practically, we show
that 1D long-range interacting systems admit polynomial bond-dimension
approximations for ground, time-evolved, and thermal states. This closes the
quasi-polynomial gap and proves such systems are simulable with polynomial
complexity comparable to short-range models. By controlling R\'enyi
entanglement, we also derive the first rigorous precision-guarantee bound for
the time-dependent density-matrix-renormalization-group algorithm. Overall, our
results extend SIE and provide a unified framework that reveals the detailed
structure of quantum complexity.

</details>


### [537] [Quantum reservoir computing for predicting and characterizing chaotic maps](https://arxiv.org/abs/2509.12071)
*Qingyu Li,Chiranjib Mukhopadhyay,Ludovico Minati,Abolfazl Bayat*

Main category: quant-ph

TL;DR: 量子水库计算可用于预测和表征离散非线性映射（如逻辑斯蒂映射和 Hénon 映射）的混沌动力学，并能在有噪声的情况下保持稳定。


<details>
  <summary>Details</summary>
Motivation: 量子水库计算是一种利用量子系统处理时间数据的范式，可以避免成本高昂的梯度学习方法。

Method: 通过在逻辑斯蒂映射和 Hénon 映射上实现量子水库计算来预测和表征混沌动力学。

Result: 在预测混沌动力学方面取得了优异的准确性，并优化了量子水库的训练超参数。此外，该框架在原位训练时对退相干表现出鲁棒性，并且对水库哈密顿量的变化不敏感。

Conclusion: 量子水库计算是用于模拟复杂动力学系统的一个可扩展且抗噪声的工具，可立即应用于近期的量子硬件。

Abstract: Quantum reservoir computing has emerged as a promising paradigm for
harnessing quantum systems to process temporal data efficiently by bypassing
the costly training of gradient-based learning methods. Here, we demonstrate
the capability of this approach to predict and characterize chaotic dynamics in
discrete nonlinear maps, exemplified through the logistic and H\'enon maps.
While achieving excellent predictive accuracy, we also demonstrate the
optimization of training hyperparameters of the quantum reservoir based on the
properties of the underlying map, thus paving the way for efficient forecasting
with other discrete and continuous time-series data. Furthermore, the framework
exhibits robustness against decoherence when trained in situ and shows
insensitivity to reservoir Hamiltonian variations. These results highlight
quantum reservoir computing as a scalable and noise-resilient tool for modeling
complex dynamical systems, with immediate applicability in near-term quantum
hardware.

</details>


### [538] [Learning kernels with quantum optical circuits](https://arxiv.org/abs/2509.12072)
*A. Mandilara,A. D. Papadopoulos,D. Syvridis*

Main category: quant-ph

TL;DR: 本文研究了将经典机器学习中的Fisher判据和准保角变换等核学习技术应用于量子光学电路以提升SVM性能，并探讨了如何利用量子光学概念（如压缩真空态）反哺SVM方法论，展示了跨学科融合的潜力。


<details>
  <summary>Details</summary>
Motivation: 机器学习，特别是支持向量机（SVM），在数据分类中表现出色，而核函数是其成功的关键。尽管已有研究探索利用量子计算（包括量子比特和量子光学）来计算核矩阵并寻求量子优势，但仍有必要研究如何进一步提升SVM性能。

Method: 本文将经典的核学习技术（Fisher判据和准保角变换）应用于量子光学电路；同时，以压缩真空态为例，展示了量子光学概念如何启发新的SVM方法。

Result: 通过将经典核学习技术转化为量子光学框架，并利用量子光学概念改进SVM方法，揭示了量子光学在机器学习领域的应用潜力。

Conclusion: 机器学习与量子光学之间的交叉研究具有巨大潜力，不仅能促进量子光学在机器学习领域的应用，也能从中获得启发，推动机器学习方法的发展。

Abstract: Support Vector Machines (SVMs) are a cornerstone of supervised learning,
widely used for data classification. A central component of their success lies
in kernel functions, which enable efficient computation of inner products in
high-dimensional feature spaces. Recent years have seen growing interest in
leveraging quantum circuits -- both qubit-based and quantum optical -- for
computing kernel matrices, with ongoing research exploring potential quantum
advantages. In this work, we investigate two classical techniques for enhancing
SVM performance through kernel learning -- the Fisher criterion and
quasi-conformal transformations -- and translate them into the framework of
quantum optical circuits. Conversely, using the example of the displaced
squeezed vacuum state, we demonstrate how established concepts from quantum
optics can inspire novel perspectives and enhancements in SVM methodology. This
cross-disciplinary approach highlights the potential of quantum optics to both
inform and benefit from advances in machine learning.

</details>


### [539] [Adiabatically driven dissipative many-body quantum spin systems](https://arxiv.org/abs/2509.12075)
*Paulo J. Paulino,Stefan Teufel,Federico Carollo,Igor Lesanovsky*

Main category: quant-ph

TL;DR: 这是一个关于强相互作用耗散量子伊辛自旋链的演化研究，该链条受到缓慢变化的横向场驱动。研究人员分析了该系统在绝热近似下的平稳态及其之间的非绝热跃迁，并计算了其慢动力学的生成元，同时分析了非绝热过程引起的相干性产生。在特定的横向场脉冲形状下，系统在每个脉冲后仅在经典基态之间发生跃迁，多个脉冲的叠加导致了具有动力学约束的多体动力学演化。该研究不仅为多体场景下的绝热定理和非绝热修正提供了定量研究途径，还与当前研究热点，如里德堡原子系综（受激光脉冲驱动并存在退相干噪声）等，建立了直接联系。


<details>
  <summary>Details</summary>
Motivation: 探索强相互作用耗散量子伊辛自旋链在缓慢变化的横向场驱动下的演化行为，特别是绝热近似下的平稳态、非绝热跃迁及其对相干性的影响，并与当前热门的多体物理系统（如里德堡原子）联系起来。

Method: 1. 探索强相互作用耗散量子伊辛自旋链在缓慢变化的横向场驱动下的演化。
2. 分析绝热近似下的平稳态及其之间的非绝热跃迁。
3. 解析计算慢动力学的生成元。
4. 分析非绝热过程引起的相干性产生。
5. 在特定横向场脉冲形状下，研究系统仅在经典基态之间发生跃迁的现象。
6. 探讨多个脉冲叠加导致的具有动力学约束的多体动力学演化。

Result: 1. 发现了该系统拥有大量绝热平稳态，这些状态通过非绝热跃迁相互耦合。
2. 推导了慢动力学的生成元，并分析了非绝热过程如何产生相干性。
3. 证明了在特定的横向场脉冲下，系统在每个脉冲后仅在经典基态之间跃迁。
4. 揭示了多个脉冲叠加可实现具有动力学约束的多体动力学演化。

Conclusion: 该研究为理解多体物理系统中的绝热演化和非绝热效应提供了新的视角，并与里德堡原子等前沿实验系统相关联，具有重要的理论和实验意义。

Abstract: We explore the evolution of a strongly interacting dissipative quantum Ising
spin chain that is driven by a slowly varying time-dependent transverse field.
This system possesses an extensive number of instantaneous (adiabatic)
stationary states which are coupled through non-adiabatic transitions. We
analytically calculate the generator of the ensuing slow dynamics and analyze
the creation of coherences through non-adiabatic processes. For a certain
choice of the transverse field shape, we show that the system solely undergoes
transitions among classical basis states after each pulse. The concatenation of
many of such pulses leads to an evolution of the spin chain under a many-body
dynamics that features kinetic constraints. Our setting not only allows for a
quantitative investigation of adiabatic theorems and non-adiabatic corrections
in a many-body scenario. It also directly connects to many-body systems in the
focus of current research, such as ensembles of interacting Rydberg atoms which
are resonantly excited by a slowly varying laser pulse and subject to dephasing
noise.

</details>


### [540] [Spatial structure of multipartite entanglement at measurement induced phase transitions](https://arxiv.org/abs/2509.12109)
*James Allen,William Witczak-Krempa*

Main category: quant-ph

TL;DR: MIPTs exhibit long-range multiparty entanglement with a hierarchy of exponents, unlike equilibrium critical transitions. The paper introduces 


<details>
  <summary>Details</summary>
Motivation: MIPTs have long-range multiparty entanglement, which needs better understanding.

Method: Representing entanglement spread with "entanglement clusters" and using measure-weighted graphs. Exploiting non-unitary conformal field theory for 1d MIPTs and extending to 2d MIPTs.

Result: Obtained exact entanglement exponents for a 1d MIPT, verified numerically, and found exponents for a 2d MIPT. Exponent relations (classical dominance, monotonicity, subadditivity) are conjectured and obeyed.

Conclusion: Provides a framework for understanding multiparty entanglement in MIPTs and general quantum circuit ensembles.

Abstract: We study multiparty entanglement near measurement induced phase transitions
(MIPTs), which arise in ensembles of local quantum circuits built with
unitaries and measurements. In contrast to equilibrium quantum critical
transitions, where entanglement is short-ranged, MIPTs possess long-range
k-party genuine multiparty entanglement (GME) characterized by an infinite
hierarchy of entanglement exponents for k >= 2. First, we represent the average
spread of entanglement with "entanglement clusters", and use them to conjecture
general exponent relations: 1) classical dominance, 2) monotonicity, 3)
subadditivity. We then introduce measure-weighted graphs to construct such
clusters in general circuits. Second, we obtain the exact entanglement
exponents for a 1d MIPT in a measurement-only circuit that maps to percolation
by exploiting non-unitary conformal field theory. The exponents, which we
numerically verify, obey the inequalities. We also extend the construction to a
2d MIPT that maps to classical 3d percolation, and numerically find the first
entanglement exponents. Our results provide a firm ground to understand the
multiparty entanglement of MIPTs, and more general ensembles of quantum
circuits.

</details>


### [541] [High-capacity associative memory in a quantum-optical spin glass](https://arxiv.org/abs/2509.12202)
*Brendan P. Marsh,David Atri Schuller,Yunpeng Ji,Henry S. Hunt,Surya Ganguli,Sarang Gopalakrishnan,Jonathan Keeling,Benjamin L. Lev*

Main category: quant-ph

TL;DR: 量子光学非平衡动力学可以恢复并增强自旋玻璃中的记忆回忆，超过霍普菲尔德极限，原子运动可能促进学习。


<details>
  <summary>Details</summary>
Motivation: 霍普菲尔德模型在存储过多模式时会出现问题，导致网络变成自旋玻璃，出现大量虚假模式，从而破坏联想回忆过程。然而，该研究旨在探索量子光学非平衡动力学是否能够恢复甚至增强自旋玻璃中的记忆回忆。

Method: 通过实验研究了一个由原子和光子组成的驱动耗散自旋玻璃，观察了其在量子光学非平衡动力学下的行为，并分析了原子运动对网络容量和连接性的影响。

Result: 实验观察到了高存储容量的联想记忆，其容量在16自旋网络中最高可达霍普菲尔德极限的七倍。原子运动通过动态修改连接性，类似于神经网络中的短期突触可塑性，从而提高了容量。

Conclusion: 量子光学非平衡动力学能够恢复并增强自旋玻璃中的记忆回忆，并且这种系统可以作为实现量子光学系统中学习的前身。

Abstract: The Hopfield model describes a neural network that stores memories using
all-to-all-coupled spins. Memory patterns are recalled under equilibrium
dynamics. Storing too many patterns breaks the associative recall process
because frustration causes an exponential number of spurious patterns to arise
as the network becomes a spin glass. Despite this, memory recall in a spin
glass can be restored, and even enhanced, under quantum-optical nonequilibrium
dynamics because spurious patterns can now serve as reliable memories. We
experimentally observe associative memory with high storage capacity in a
driven-dissipative spin glass made of atoms and photons. The capacity surpasses
the Hopfield limit by up to seven-fold in a sixteen-spin network. Atomic motion
boosts capacity by dynamically modifying connectivity akin to short-term
synaptic plasticity in neural networks, realizing a precursor to learning in a
quantum-optical system.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [542] [The 1st International Workshop on Disentangled Representation Learning for Controllable Generation (DRL4Real): Methods and Results](https://arxiv.org/abs/2509.10463)
*Qiuyu Chen,Xin Jin,Yue Song,Xihui Liu,Shuai Yang,Tao Yang,Ziqiang Li,Jianguo Huang,Yuntao Wei,Ba'ao Xie,Nicu Sebe,Wenjun,Zeng,Jooyeol Yun,Davide Abati,Mohamed Omran,Jaegul Choo,Amir Habibian,Auke Wiggers,Masato Kobayashi,Ning Ding,Toru Tamaki,Marzieh Gheisari,Auguste Genovesio,Yuheng Chen,Dingkun Liu,Xinyao Yang,Xinping Xu,Baicheng Chen,Dongrui Wu,Junhao Geng,Lexiang Lv,Jianxin Lin,Hanzhe Liang,Jie Zhou,Xuanxin Chen,Jinbao Wang,Can Gao,Zhangyi Wang,Zongze Li,Bihan Wen,Yixin Gao,Xiaohan Pan,Xin Li,Zhibo Chen,Baorui Peng,Zhongming Chen,Haoran Jin*

Main category: cs.LG

TL;DR: 本次workshop旨在弥合可分离表征学习（DRL）的理论承诺与其在真实世界应用之间的差距，并超越合成基准测试。


<details>
  <summary>Details</summary>
Motivation: 本次workshop旨在弥合可分离表征学习（DRL）的理论承诺与其在真实世界应用（例如可控生成）之间的差距，并超越合成基准测试。

Method: 本次workshop介绍了9篇论文，涵盖了新颖归纳偏置（例如语言）的整合、扩散模型在DRL中的应用、3D感知解纠缠以及DRL在自动驾驶和脑电图分析等专业领域的扩展。

Result: 本次workshop共收录了9篇论文，主题涵盖了将新颖归纳偏置（例如语言）整合到DRL中、将扩散模型应用于DRL、3D感知解纠缠以及将DRL扩展到自动驾驶和EEG分析等专业领域。

Conclusion: 本次workshop汇集了关于DRL在现实世界应用中的最新进展，重点关注模型鲁棒性、可解释性和泛化能力，并探索了其在可控生成、自动驾驶和EEG分析等领域的应用前景。

Abstract: This paper reviews the 1st International Workshop on Disentangled
Representation Learning for Controllable Generation (DRL4Real), held in
conjunction with ICCV 2025. The workshop aimed to bridge the gap between the
theoretical promise of Disentangled Representation Learning (DRL) and its
application in realistic scenarios, moving beyond synthetic benchmarks.
DRL4Real focused on evaluating DRL methods in practical applications such as
controllable generation, exploring advancements in model robustness,
interpretability, and generalization. The workshop accepted 9 papers covering a
broad range of topics, including the integration of novel inductive biases
(e.g., language), the application of diffusion models to DRL, 3D-aware
disentanglement, and the expansion of DRL into specialized domains like
autonomous driving and EEG analysis. This summary details the workshop's
objectives, the themes of the accepted papers, and provides an overview of the
methodologies proposed by the authors.

</details>


### [543] [Designing MacPherson Suspension Architectures using Bayesian Optimization](https://arxiv.org/abs/2206.09022)
*Sinnu Susan Thomas,Jacopo Palandri,Mohsen Lakehal-ayat,Punarjay Chakravarty,Friedrich Wolf-Monheim,Matthew B. Blaschko*

Main category: cs.LG

TL;DR: 使用贝叶斯优化直接优化设计参数以满足目标规范，以自动化工程设计过程。


<details>
  <summary>Details</summary>
Motivation: 传统工程设计过程耗时且成本高，涉及手动设计、模拟和原型制作。

Method: 开发了一个贝叶斯优化系统，该系统可以直接针对设计参数优化目标规范的合规性。该方法计算高维非线性函数的广义逆，并且不需要梯度信息。它还包括一个两层收敛标准：(i) 收敛到一个最优地满足所有指定设计标准的解决方案，或 (ii) 收敛到一个最小范数解决方案。

Result: 所提出的方法在车辆底盘设计问题上得到了证明，并显示出通用性、可扩展性和效率。

Conclusion: 所提出的贝叶斯优化方法和收敛标准为工程设计提供了一种自动化、高效的解决方案。

Abstract: Engineering design is traditionally performed by hand: an expert makes design
proposals based on past experience, and these proposals are then tested for
compliance with certain target specifications. Testing for compliance is
performed first by computer simulation using what is called a discipline model.
Such a model can be implemented by a finite element analysis, multibody systems
approach, etc. Designs passing this simulation are then considered for physical
prototyping. The overall process may take months, and is a significant cost in
practice. We have developed a Bayesian optimization system for partially
automating this process by directly optimizing compliance with the target
specification with respect to the design parameters. The proposed method is a
general framework for computing a generalized inverse of a high-dimensional
non-linear function that does not require e.g. gradient information, which is
often unavailable from discipline models. We furthermore develop a two-tier
convergence criterion based on (i) convergence to a solution optimally
satisfying all specified design criteria, or (ii) convergence to a minimum-norm
solution. We demonstrate the proposed approach on a vehicle chassis design
problem motivated by an industry setting using a state-of-the-art commercial
discipline model. We show that the proposed approach is general, scalable, and
efficient, and that the novel convergence criteria can be implemented
straightforwardly based on existing concepts and subroutines in popular
Bayesian optimization software packages.

</details>


### [544] [Moment Estimates and DeepRitz Methods on Learning Diffusion Systems with Non-gradient Drifts](https://arxiv.org/abs/2509.10495)
*Fanze Kong,Chen-Chih Lai,Yubin Lu*

Main category: cs.LG

TL;DR: 该方法能从噪声数据中学习保守-耗散动力学。


<details>
  <summary>Details</summary>
Motivation: 保守-耗散动力学普遍存在于各种复杂的开放系统中。

Method: 提出一种数据驱动的两阶段方法，即矩-DeepRitz方法，用于学习广义扩散系统中涉及保守-耗散动力学的漂移分解。

Result: 所提出的矩-DeepRitz方法对噪声数据具有鲁棒性，并且能够适应粗糙势和振荡旋转。

Conclusion: 通过数值实验证明了该方法的有效性。

Abstract: Conservative-dissipative dynamics are ubiquitous across a variety of complex
open systems. We propose a data-driven two-phase method, the Moment-DeepRitz
Method, for learning drift decompositions in generalized diffusion systems
involving conservative-dissipative dynamics. The method is robust to noisy
data, adaptable to rough potentials and oscillatory rotations. We demonstrate
its effectiveness through several numerical experiments.

</details>


### [545] [SOH-KLSTM: A Hybrid Kolmogorov-Arnold Network and LSTM Model for Enhanced Lithium-Ion Battery Health Monitoring](https://arxiv.org/abs/2509.10496)
*Imen Jarraya,Safa Ben Atitallah,Fatimah Alahmeda,Mohamed Abdelkadera,Maha Drissa,Fatma Abdelhadic,Anis Koubaaa*

Main category: cs.LG

TL;DR: 本文提出了一种名为SOH-KLSTM的新型健康状态（SOH）预测框架，该框架结合了长短期记忆（LSTM）网络和Kolmogorov-Arnold网络（KAN），以更准确地估计锂电池的健康状态。


<details>
  <summary>Details</summary>
Motivation: 为了确保电动汽车、无人机、消费电子产品和可再生能源存储系统等应用的寿命、安全性和最佳性能，精确可靠的锂电池健康状态（SOH）估算至关重要。然而，传统SOH估算技术在有效地表示电池退化的非线性和时间方面存在不足。

Method: 本文提出了一种名为SOH-KLSTM的新型SOH预测框架，该框架集成了Kolmogorov-Arnold网络（KAN）和长短期记忆（LSTM）网络，用于锂电池健康监测。这种混合方法结合了LSTM学习长期依赖关系以进行准确时间序列预测的能力，以及KAN的非线性近似能力，以有效捕获锂电池复杂的退化行为。

Result: SOH-KLSTM框架通过结合LSTM处理时间序列依赖性和KAN处理非线性能力，能够更有效地捕获锂电池的复杂退化行为，从而实现更准确的SOH预测。

Conclusion: SOH-KLSTM框架通过整合KAN和LSTM的优势，为锂电池提供了更准确、更可靠的健康状态估算方法。

Abstract: Accurate and reliable State Of Health (SOH) estimation for Lithium (Li)
batteries is critical to ensure the longevity, safety, and optimal performance
of applications like electric vehicles, unmanned aerial vehicles, consumer
electronics, and renewable energy storage systems. Conventional SOH estimation
techniques fail to represent the non-linear and temporal aspects of battery
degradation effectively. In this study, we propose a novel SOH prediction
framework (SOH-KLSTM) using Kolmogorov-Arnold Network (KAN)-Integrated
Candidate Cell State in LSTM for Li batteries Health Monitoring. This hybrid
approach combines the ability of LSTM to learn long-term dependencies for
accurate time series predictions with KAN's non-linear approximation
capabilities to effectively capture complex degradation behaviors in Lithium
batteries.

</details>


### [546] [Exploring Multi-view Symbolic Regression methods in physical sciences](https://arxiv.org/abs/2509.10500)
*Etienne Russeil,Fabrício Olivetti de França,Konstantin Malanchev,Guillaume Moinard,Maxime Cherrey*

Main category: cs.LG

TL;DR: 该研究比较了四种多视图符号回归（MvSR）实现（Operon、PySR、phy-SO 和 eggp）在不同真实世界数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 传统上，科学家通过数学函数来描述世界行为以获得更好的理解。符号回归（SR）可以自动化这一过程，而多视图符号回归（MvSR）通过处理多个数据集来解决数据稀疏和过拟合问题。本研究旨在比较几种 MvSR 实现。

Method: 在不同的真实世界数据集上测试和比较了 Operon、PySR、phy-SO 和 eggp 中实现的多视图符号回归（MvSR）。

Result: 所有 MvSR 实现通常都能达到良好的准确性，并提出参数较少的模型。然而，某些特定功能能更频繁地生成更好的模型。

Conclusion: 本研究对未来 MvSR 的发展提供了指导方针。

Abstract: Describing the world behavior through mathematical functions help scientists
to achieve a better understanding of the inner mechanisms of different
phenomena. Traditionally, this is done by deriving new equations from first
principles and careful observations. A modern alternative is to automate part
of this process with symbolic regression (SR). The SR algorithms search for a
function that adequately fits the observed data while trying to enforce
sparsity, in the hopes of generating an interpretable equation. A particularly
interesting extension to these algorithms is the Multi-view Symbolic Regression
(MvSR). It searches for a parametric function capable of describing multiple
datasets generated by the same phenomena, which helps to mitigate the common
problems of overfitting and data scarcity. Recently, multiple implementations
added support to MvSR with small differences between them. In this paper, we
test and compare MvSR as supported in Operon, PySR, phy-SO, and eggp, in
different real-world datasets. We show that they all often achieve good
accuracy while proposing solutions with only few free parameters. However, we
find that certain features enable a more frequent generation of better models.
We conclude by providing guidelines for future MvSR developments.

</details>


### [547] [Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset](https://arxiv.org/abs/2509.11136)
*Farbod Bijary,Mohsen Ebadpour,Amirhosein Tajbakhsh*

Main category: cs.LG

TL;DR: 该研究提出了一个包含约26,000个波斯姓名、性别及英文音译的PNGT-26K数据集，并介绍了两个用于性别检测（Open Gender Detection）和用户名生成（Nominalist）的框架，以解决波斯语姓名在自然语言处理中的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有工具在处理波斯姓名时的性能下降问题，以及应对波斯姓名在性别检测和数字身份创建方面存在的挑战，这些挑战源于音译不一致和文化特定的命名模式，同时现有数据集的稀缺也加剧了这些限制。

Method: 创建了一个包含约26,000个波斯姓名、与其相关的性别以及英文音译的PNGT-26K数据集。此外，还介绍了两个框架：Open Gender Detection，一个用于根据用户资料（如头像和姓名）进行性别概率推断的框架；Nominalist，一个利用AI代理帮助用户选择社交媒体用户名的框架。

Result: 成功构建了PNGT-26K数据集，并开发了Open Gender Detection和Nominalist两个框架。这两个框架和数据集已在Github上公开。

Conclusion: PNGT-26K数据集和所提出的Open Gender Detection、Nominalist框架能够有效解决波斯姓名在自然语言处理应用中面临的挑战，并为相关领域的研究和应用提供了资源和解决方案。

Abstract: Persian names present unique challenges for natural language processing
applications, particularly in gender detection and digital identity creation,
due to transliteration inconsistencies and cultural-specific naming patterns.
Existing tools exhibit significant performance degradation on Persian names,
while the scarcity of comprehensive datasets further compounds these
limitations. To address these challenges, the present research introduces
PNGT-26K, a comprehensive dataset of Persian names, their commonly associated
gender, and their English transliteration, consisting of approximately 26,000
tuples. As a demonstration of how this resource can be utilized, we also
introduce two frameworks, namely Open Gender Detection and Nominalist. Open
Gender Detection is a production-grade, ready-to-use framework for using
existing data from a user, such as profile photo and name, to give a
probabilistic guess about the person's gender. Nominalist, the second framework
introduced by this paper, utilizes agentic AI to help users choose a username
for their social media accounts on any platform. It can be easily integrated
into any website to provide a better user experience. The PNGT-26K dataset,
Nominalist and Open Gender Detection frameworks are publicly available on
Github.

</details>


### [548] [Foundational theory for optimal decision tree problems. I. Algorithmic and geometric foundations](https://arxiv.org/abs/2509.11226)
*Xi He*

Main category: cs.LG

TL;DR: 本文提出 ODT 问题的四种新定义，并基于代数编程理论推导出四种最优算法，统一解决了具有任意分裂规则的 ODT 问题，并包含了现有的深度约束 ODT 算法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为 ODT (Optimal Decision Tree) 问题提供更形式化、更通用的定义，并基于代数编程理论推导出相应最优算法，以统一解决具有任意分裂规则的 ODT 问题，并超越现有算法。

Method: 本文首先提出了四种 ODT 问题的形式化定义（三种尺寸约束，一种深度约束），并使用可执行的递归程序来精确描述。然后，基于代数编程理论，推导出了四种新的最优算法，能够处理任意分裂规则的 ODT 问题。这些算法能够构造性地推导，并能统一现有的深度约束 ODT 算法。

Result: 本文提出的四种通用问题定义成功推导出了四种新的最优 ODT 算法，这些算法能够处理任意分裂规则，并且包含了现有的深度约束 ODT 算法作为特例。这些算法提供了一个统一、高效且简洁的解决方案。

Conclusion: 本文提出的 ODT 问题形式化定义和基于代数编程理论推导出的通用最优算法，为解决具有任意分裂规则的 ODT 问题提供了新的途径，并展示了其超越现有方法的潜力和可扩展性。

Abstract: In the first paper (part I) of this series of two, we introduce four novel
definitions of the ODT problems: three for size-constrained trees and one for
depth-constrained trees. These definitions are stated unambiguously through
executable recursive programs, satisfying all criteria we propose for a formal
specification. In this sense, they resemble the "standard form" used in the
study of general-purpose solvers.
  Grounded in algebraic programming theory-a relational formalism for deriving
correct-by-construction algorithms from specifications-we can not only
establish the existence or nonexistence of dynamic programming solutions but
also derive them constructively whenever they exist. Consequently, the four
generic problem definitions yield four novel optimal algorithms for ODT
problems with arbitrary splitting rules that satisfy the axioms and objective
functions of a given form. These algorithms encompass the known
depth-constrained, axis-parallel ODT algorithm as the special case, while
providing a unified, efficient, and elegant solution for the general ODT
problem.
  In Part II, we present the first optimal hypersurface decision tree algorithm
and provide comprehensive experiments against axis-parallel decision tree
algorithms, including heuristic CART and state-of-the-art optimal methods. The
results demonstrate the significant potential of decision trees with flexible
splitting rules. Moreover, our framework is readily extendable to support
algorithms for constructing even more flexible decision trees, including those
with mixed splitting rules.

</details>


### [549] [A Service-Oriented Adaptive Hierarchical Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2509.10512)
*Jiaxing Cao,Yuzhou Gao,Jiwei Huang*

Main category: cs.LG

TL;DR: 本篇论文提出了一种新的联邦学习激励机制，旨在平衡任务发布者、本地模型所有者和工人的利益。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在分布式模型训练中是一种新颖的框架。在FL中，任务发布者（TP）发布任务，本地模型所有者（LMO）使用他们本地的数据来训练模型。有时，FL会面临训练数据不足的问题，因此需要招募工人来收集数据。为了解决这个问题，本文提出了一种面向服务的自适应激励机制。

Method: 该机制从服务导向的角度出发，以最大化TP、LMO和工人三方的效用为目标。具体来说，在LMO和TP之间建立了一个Stackelberg博弈，将TP定位为领导者，LMOs为追随者，并推导出一个解析Nash均衡解来最大化他们的效用。LMOs和工人之间的交互被表述为一个多智能体马尔可夫决策过程（MAMDP），并通过深度强化学习（DRL）来识别最优策略。此外，还设计了一个自适应搜索最优策略算法（ASOSA）来稳定每个参与者的策略并解决耦合问题。

Result: 通过广泛的数值实验验证了所提出方法的有效性。

Conclusion: 所提出的自适应激励机制能够有效地平衡联邦学习中各方的利益，并在数据不足的情况下提高模型训练的效率。

Abstract: Recently, federated learning (FL) has emerged as a novel framework for
distributed model training. In FL, the task publisher (TP) releases tasks, and
local model owners (LMOs) use their local data to train models. Sometimes, FL
suffers from the lack of training data, and thus workers are recruited for
gathering data. To this end, this paper proposes an adaptive incentive
mechanism from a service-oriented perspective, with the objective of maximizing
the utilities of TP, LMOs and workers. Specifically, a Stackelberg game is
theoretically established between the LMOs and TP, positioning TP as the leader
and the LMOs as followers. An analytical Nash equilibrium solution is derived
to maximize their utilities. The interaction between LMOs and workers is
formulated by a multi-agent Markov decision process (MAMDP), with the optimal
strategy identified via deep reinforcement learning (DRL). Additionally, an
Adaptively Searching the Optimal Strategy Algorithm (ASOSA) is designed to
stabilize the strategies of each participant and solve the coupling problems.
Extensive numerical experiments are conducted to validate the efficacy of the
proposed method.

</details>


### [550] [From Noise to Precision: A Diffusion-Driven Approach to Zero-Inflated Precipitation Prediction](https://arxiv.org/abs/2509.10501)
*Wentao Gao,Jiuyong Li,Lin Liu,Thuc Duy Le,Xiongren Chen,Xiaojing Du,Jixue Liu,Yanchang Zhao,Yun Chen*

Main category: cs.LG

TL;DR: ZIDF框架通过结合高斯扰动、Transformer预测和扩散去噪来解决降水预报中的零膨胀问题，在实验中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 零膨胀数据在降水预报中由于零值过多和非零值稀疏而构成重大挑战。

Method: 提出零膨胀扩散框架（ZIDF），该框架整合了用于平滑零膨胀分布的高斯扰动、用于捕捉时间模式的基于Transformer的预测以及用于恢复原始数据结构的基于扩散的去噪。

Result: 实验结果表明，ZIDF相较于非平稳Transformer基线模型，在MSE方面降低了56.7%，在MAE方面降低了21.1%，表现出显著的性能提升。

Conclusion: ZIDF能够有效地处理稀疏时间序列数据，并可能推广到其他存在零膨胀问题的领域。

Abstract: Zero-inflated data pose significant challenges in precipitation forecasting
due to the predominance of zeros with sparse non-zero events. To address this,
we propose the Zero Inflation Diffusion Framework (ZIDF), which integrates
Gaussian perturbation for smoothing zero-inflated distributions,
Transformer-based prediction for capturing temporal patterns, and
diffusion-based denoising to restore the original data structure. In our
experiments, we use observational precipitation data collected from South
Australia along with synthetically generated zero-inflated data. Results show
that ZIDF demonstrates significant performance improvements over multiple
state-of-the-art precipitation forecasting models, achieving up to 56.7\%
reduction in MSE and 21.1\% reduction in MAE relative to the baseline
Non-stationary Transformer. These findings highlight ZIDF's ability to robustly
handle sparse time series data and suggest its potential generalizability to
other domains where zero inflation is a key challenge.

</details>


### [551] [Online Omniprediction with Long-Term Constraints](https://arxiv.org/abs/2509.11357)
*Yahav Bechavod,Jiuyao Lu,Aaron Roth*

Main category: cs.LG

TL;DR: 该研究提出了在线全预测问题，并为下游代理提供了保证


<details>
  <summary>Details</summary>
Motivation: 为满足下游代理在无悔和约束方面的需求，提出在线全预测问题

Method: 提出一种单一的预测集生成方法，下游代理可据此采取行动，从而满足其无悔和约束要求

Result: 证明了该方法能为每个代理提供 O(sqrt(T)) 的悔恨界限和 O(1) 的累积约束违反界限，并能扩展到任意交集的上下文定义的子序列

Conclusion: 该方法能够同时为每个下游代理在所有相关子序列上提供悔恨和约束违反界限

Abstract: We introduce and study the problem of online omniprediction with long-term
constraints. At each round, a forecaster is tasked with generating predictions
for an underlying (adaptively, adversarially chosen) state that are broadcast
to a collection of downstream agents, who must each choose an action. Each of
the downstream agents has both a utility function mapping actions and state to
utilities, and a vector-valued constraint function mapping actions and states
to vector-valued costs. The utility and constraint functions can arbitrarily
differ across downstream agents. Their goal is to choose actions that guarantee
themselves no regret while simultaneously guaranteeing that they do not
cumulatively violate the constraints across time. We show how to make a single
set of predictions so that each of the downstream agents can guarantee this by
acting as a simple function of the predictions, guaranteeing each of them
$\tilde{O}(\sqrt{T})$ regret and $O(1)$ cumulative constraint violation. We
also show how to extend our guarantees to arbitrary intersecting contextually
defined \emph{subsequences}, guaranteeing each agent both regret and constraint
violation bounds not just marginally, but simultaneously on each subsequence,
against a benchmark set of actions simultaneously tailored to each subsequence.

</details>


### [552] [FEDEXCHANGE: Bridging the Domain Gap in Federated Object Detection for Free](https://arxiv.org/abs/2509.10503)
*Haolin Yuan,Jingtao Li,Weiming Zhuang,Chen Chen,Lingjuan Lyu*

Main category: cs.LG

TL;DR: FEDEXCHANGE通过服务器端的动态模型交换策略解决了联邦对象检测中的跨域泛化挑战，在不增加客户端计算开销的情况下提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦对象检测（FOD）方法在处理来自不同域的数据时面临显著的性能挑战，并且忽略了边缘设备的硬件限制，引入了高计算成本的本地训练正则化，限制了其实际应用。因此，需要一种能在不增加额外本地计算开销的情况下弥合域差距的FOD框架。

Method: FEDEXCHANGE提出了一种服务器端的动态模型交换策略。服务器在模型聚合和模型交换之间交替进行。在聚合轮次中，服务器像往常一样聚合所有本地模型。在交换轮次中，服务器根据距离度量对本地模型进行聚类和交换，使本地模型能够从各种域中学习。

Result: FEDEXCHANGE在具有挑战性的域（如雨天条件）中，平均精度提高了1.6倍，同时计算资源消耗仅为基线方法的0.8倍，展示了其在提高FOD性能和效率方面的优越性。

Conclusion: FEDEXCHANGE成功地弥合了域间差距，提高了联邦对象检测的性能，同时避免了增加客户端的计算负担。该框架通过服务器端的模型交换实现了跨域泛化，使其成为资源受限的边缘设备的实用解决方案。

Abstract: Federated Object Detection (FOD) enables clients to collaboratively train a
global object detection model without accessing their local data from diverse
domains. However, significant variations in environment, weather, and other
domain specific factors hinder performance, making cross domain generalization
a key challenge. Existing FOD methods often overlook the hardware constraints
of edge devices and introduce local training regularizations that incur high
computational costs, limiting real-world applicability. In this paper, we
propose FEDEXCHANGE, a novel FOD framework that bridges domain gaps without
introducing additional local computational overhead. FEDEXCHANGE employs a
server side dynamic model exchange strategy that enables each client to gain
insights from other clients' domain data without direct data sharing.
Specifically, FEDEXCHANGE allows the server to alternate between model
aggregation and model exchange. During aggregation rounds, the server
aggregates all local models as usual. In exchange rounds, FEDEXCHANGE clusters
and exchanges local models based on distance measures, allowing local models to
learn from a variety of domains. As all operations are performed on the server
side, clients can achieve improved cross domain utility without any additional
computational overhead. Extensive evaluations demonstrate that FEDEXCHANGE
enhances FOD performance, achieving 1.6X better mean average precision in
challenging domains, such as rainy conditions, while requiring only 0.8X the
computational resources compared to baseline methods.

</details>


### [553] [Foundational theory for optimal decision tree problems. II. Optimal hypersurface decision tree algorithm](https://arxiv.org/abs/2509.12057)
*Xi He*

Main category: cs.LG

TL;DR: 本文提出了首个超曲面决策树（HODT）算法，解决了通用超曲面决策树模型的最优问题，并在合成和真实世界数据集上展示了优于现有最优轴平行决策树算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有最优决策树方法仅限于超平面分割规则（超曲面的特例），并且依赖于通用求解器。本文旨在提出一种能够处理更通用的超曲面决策树模型，且不依赖外部求解器的算法。

Method: 在第一部分工作的基础上，提出了一种新的超曲面决策树（HODT）算法，该算法可以直接解决通用的超曲面决策树模型的最优问题，无需依赖外部求解器。

Result: 使用合成数据集进行实验，结果表明HODT算法比轴平行树能更准确地恢复真实情况，并且对噪声具有更强的鲁棒性。在30个真实世界数据集上的泛化性能分析表明，在适当控制树复杂度的情况下，HODT的准确率最高可提高30%。

Conclusion: HODT算法是首个能够解决通用超曲面决策树模型最优问题的算法，并且在准确性和鲁棒性方面表现出色，为最优决策树研究提供了新的方向。

Abstract: Decision trees are a ubiquitous model for classification and regression tasks
due to their interpretability and efficiency. However, solving the optimal
decision tree (ODT) problem remains a challenging combinatorial optimization
task. Even for the simplest splitting rules--axis-parallel hyperplanes--it is
NP-hard to optimize. In Part I of this series, we rigorously defined the proper
decision tree model through four axioms and, based on these, introduced four
formal definitions of the ODT problem. From these definitions, we derived four
generic algorithms capable of solving ODT problems for arbitrary decision trees
satisfying the axioms. We also analyzed the combinatorial geometric properties
of hypersurfaces, showing that decision trees defined by polynomial
hypersurface splitting rules satisfy the proper axioms that we proposed.
  In this second paper (Part II) of this two-part series, building on the
algorithmic and geometric foundations established in Part I, we introduce the
first hypersurface decision tree (HODT) algorithm. To the best of our
knowledge, existing optimal decision tree methods are, to date, limited to
hyperplane splitting rules--a special case of hypersurfaces--and rely on
general-purpose solvers. In contrast, our HODT algorithm addresses the general
hypersurface decision tree model without requiring external solvers.
  Using synthetic datasets generated from ground-truth hyperplane decision
trees, we vary tree size, data size, dimensionality, and label and feature
noise. Results showing that our algorithm recovers the ground truth more
accurately than axis-parallel trees and exhibits greater robustness to noise.
We also analyzed generalization performance across 30 real-world datasets,
showing that HODT can achieve up to 30% higher accuracy than the
state-of-the-art optimal axis-parallel decision tree algorithm when tree
complexity is properly controlled.

</details>


### [554] [Retrosynthesis Planning via Worst-path Policy Optimisation in Tree-structured MDPs](https://arxiv.org/abs/2509.10504)
*Mianchu Wang,Giovanni Montana*

Main category: cs.LG

TL;DR: 该研究将逆合成规划重构为在树状马尔可夫决策过程中（MDP）的“最坏路径”优化问题，并提出了一种名为InterRetro的交互式方法，该方法通过学习“最坏路径”的价值函数并进行自我模仿来优化策略，在Retro*-190基准测试中实现了100%的目标解决率，并缩短了合成路线。


<details>
  <summary>Details</summary>
Motivation: 现有逆合成规划方法在处理合成树的“最弱环节”时存在不足，因为它们通常只关注平均性能，而忽略了任何一个不可用原料都会导致整个合成路线失败的风险。

Method: 将逆合成规划重构为树状MDP中的最坏路径优化问题，并提出了一种名为InterRetro的交互式方法。该方法通过学习最坏路径的价值函数，并利用自我模仿（self-imitation）策略来优先加强具有高估计优势的过往决策，从而优化规划策略。

Result: InterRetro在Retro*-190基准测试中取得了最先进的成果，实现了100%的目标解决率，合成路线平均缩短了4.9%，并且在仅使用10%的训练数据的情况下也取得了良好的性能。

Conclusion: 该研究提出的基于最坏路径优化的逆合成规划方法（InterRetro）能够有效解决现有方法的局限性，显著提高了逆合成规划的成功率和效率，代表了计算逆合成规划领域的一项重大进展。

Abstract: Retrosynthesis planning aims to decompose target molecules into available
building blocks, forming a synthesis tree where each internal node represents
an intermediate compound and each leaf ideally corresponds to a purchasable
reactant. However, this tree becomes invalid if any leaf node is not a valid
building block, making the planning process vulnerable to the "weakest link" in
the synthetic route. Existing methods often optimise for average performance
across branches, failing to account for this worst-case sensitivity. In this
paper, we reframe retrosynthesis as a worst-path optimisation problem within
tree-structured Markov Decision Processes (MDPs). We prove that this
formulation admits a unique optimal solution and offers monotonic improvement
guarantees. Building on this insight, we introduce Interactive Retrosynthesis
Planning (InterRetro), a method that interacts with the tree MDP, learns a
value function for worst-path outcomes, and improves its policy through
self-imitation, preferentially reinforcing past decisions with high estimated
advantage. Empirically, InterRetro achieves state-of-the-art results, solving
100% of targets on the Retro*-190 benchmark, shortening synthetic routes by
4.9%, and achieving promising performance using only 10% of the training data -
representing a significant advance in computational retrosynthesis planning.

</details>


### [555] [AttnBoost: Retail Supply Chain Sales Insights via Gradient Boosting Perspective](https://arxiv.org/abs/2509.10506)
*Muxin Ge,Hanyu Ma,Yiyang Wu,Xiaoli Ma,Yadi Liu,Ye Aung Moe,Weizheng Xie*

Main category: cs.LG

TL;DR: AttnBoost通过将特征级注意力机制集成到梯度提升决策树（GBDT）中，提高了零售产品需求预测的准确性和可解释性，并在大型零售销售数据集上优于传统和深度表格模型。


<details>
  <summary>Details</summary>
Motivation: 传统GBDT模型在处理嘈杂、异构特征和快速变化的消费者行为时，缺乏适应性机制来识别和强调在变化条件下最相关的特征。

Method: 提出AttnBoost框架，将特征级注意力机制集成到GBingDT的提升过程中，通过轻量级注意力机制动态调整每轮提升中的特征重要性，从而专注于促销、定价和季节性趋势等高影响变量。

Result: 在大型零售销售数据集上，AttnBoost的预测准确性优于标准机器学习和深度表格模型，并提供了可操作的供应链管理见解。消融研究证实了注意力模块在减少过拟合和提高可解释性方面的作用。

Conclusion: 注意力引导的提升是可解释和可扩展的AI在实际预测应用中的一个有前景的方向。

Abstract: Forecasting product demand in retail supply chains presents a complex
challenge due to noisy, heterogeneous features and rapidly shifting consumer
behavior. While traditional gradient boosting decision trees (GBDT) offer
strong predictive performance on structured data, they often lack adaptive
mechanisms to identify and emphasize the most relevant features under changing
conditions. In this work, we propose AttnBoost, an interpretable learning
framework that integrates feature-level attention into the boosting process to
enhance both predictive accuracy and explainability. Specifically, the model
dynamically adjusts feature importance during each boosting round via a
lightweight attention mechanism, allowing it to focus on high-impact variables
such as promotions, pricing, and seasonal trends. We evaluate AttnBoost on a
large-scale retail sales dataset and demonstrate that it outperforms standard
machine learning and deep tabular models, while also providing actionable
insights for supply chain managers. An ablation study confirms the utility of
the attention module in mitigating overfitting and improving interpretability.
Our results suggest that attention-guided boosting represents a promising
direction for interpretable and scalable AI in real-world forecasting
applications.

</details>


### [556] [The Anti-Ouroboros Effect: Emergent Resilience in Large Language Models from Recursive Selective Feedback](https://arxiv.org/abs/2509.10509)
*Sai Teja Reddy Adapala*

Main category: cs.LG

TL;DR: 递归训练的大型语言模型（LLM）的稳定性是人工智能安全的基础问题。现有理论预测模型会发生模型坍塌，即模型在自身输 F1基础上训练时会逐渐退化。我们通过引入一种选择性反馈机制来挑战这一说法。实验有力地证明，这种机制不仅延缓了衰退，反而逆转了衰退，在复杂的摘要任务中，Gemma 2B 模型取得了统计学上显著的性能提升。我们将这种现象命名为“反衔尾蛇效应”。我们通过一个简单的分类器实验来对比这一现象，该实验验证了理论上的退化循环，凸显了高维模型的独特动态。我们的发现表明，系统性韧性可以是在简单选择压力下 LLM 的一种新兴属性，这为开发更安全、更强大的 AI 系统提供了一个强大且可扩展的原则。在五个代际中，经过质量过滤的条件在 ROUGE-L F1 分数上提高了 6.6%，而未经过滤的对照组下降了 3.5%，随机过滤的对照组下降了 4.2%。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨递归训练的大型语言模型（LLM）的稳定性问题，挑战关于模型坍塌的普遍预测，并提出一种提高 LLM 稳定性和性能的方法。

Method: 通过引入选择性反馈机制来干预 LLM 的递归训练过程，并对比了使用 Gemma 2B 模型在摘要任务上的实验结果以及使用简单分类器的基础实验结果。通过 ROUGE-L F1 分数来评估性能变化。

Result: 选择性反馈机制成功逆转了模型性能的衰退，并带来了统计学上的显著提升（“反衔尾蛇效应”）。经过质量过滤的条件在 ROUGE-L F1 分数上提高了 6.6%，而未过滤和随机过滤的对照组分别下降了 3.5% 和 4.2%。

Conclusion: 系统性韧性可以是在简单选择压力下 LLM 的一种新兴属性，为开发更安全、更强大的 AI 系统提供了新的方向。

Abstract: The stability of recursively trained large language models (LLMs) is a
foundational problem for AI safety. Prevailing theory predicts model collapse,
a progressive degradation when models are trained on their own output. We
challenge this narrative by introducing a selective feedback mechanism.
Contrary to expectation, instead of merely slowing decay, our experiments
provide strong evidence that this pressure reverses it, inducing a
statistically significant performance improvement in a Gemma 2B model on a
complex summarization task. We name this phenomenon the Anti-Ouroboros Effect.
We contrast this with a foundational experiment using a simple classifier,
where the theoretical degenerative loop was validated, highlighting the unique
dynamics of high-dimensional models. Our findings establish that systemic
resilience can be an emergent property of LLMs under simple selection pressure,
suggesting a powerful and scalable principle for developing safer and more
robust AI systems. Across five generations, a quality-filtered condition
improved by 6.6% in ROUGE-L F1 score, whereas an unfiltered control degraded by
3.5% and a random-filter control degraded by 4.2%

</details>


### [557] [LogGuardQ: A Cognitive-Enhanced Reinforcement Learning Framework for Cybersecurity Anomaly Detection in Security Logs](https://arxiv.org/abs/2509.10511)
*Umberto Gonçalves de Sousa*

Main category: cs.LG

TL;DR: LogGuardQ是一个创新的强化学习框架，通过模拟人类认知和采用自适应探索策略，显著提高了在动态环境中检测异常（如安全日志中的异常）的效率和稳定性，其性能优于DQN和PPO等传统算法。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习算法（如DQN和PPO）在动态环境中进行探索、保持稳定性和适应性方面存在挑战。本研究旨在提出一种新的框架来克服这些限制。

Method: 本研究提出了LogGuardQ（自适应日志卫士与认知增强），这是一个结合了受人类认知启发的双记忆系统和由温度衰减及好奇心驱动的自适应探索策略的新框架。

Result: 在模拟的1,000,000条访问日志（包含47.9%的异常）上评估，LogGuardQ达到了96.0%的检测率（DQN为93.0%，PPO为47.1%），精确率为0.4776，召回率为0.9996，F1分数为0.6450。LogGuardQ的平均奖励为20.34 ± 44.63，显著优于DQN（18.80 ± 43.98）和PPO（-0.17 ± 23.79）。学习曲线、方差趋势、动作分布和累积检测的图表分析以及Mann-Whitney U检验均证实了LogGuardQ在稳定性、效率和性能上的显著优势。

Conclusion: LogGuardQ通过融合认知科学与强化学习，为不确定环境中的自适应学习提供了一种可扩展的方法，在网络安全、入侵检测和不确定性下的决策制定等领域具有潜在应用价值。

Abstract: Reinforcement learning (RL) has transformed sequential decision-making, but
traditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy
Optimization (PPO) often struggle with efficient exploration, stability, and
adaptability in dynamic environments. This study presents LogGuardQ (Adaptive
Log Guard with Cognitive enhancement), a novel framework that integrates a
dual-memory system inspired by human cognition and adaptive exploration
strategies driven by temperature decay and curiosity. Evaluated on a dataset of
1,000,000 simulated access logs with 47.9% anomalies over 20,000 episodes,
LogGuardQ achieves a 96.0% detection rate (versus 93.0% for DQN and 47.1% for
PPO), with precision of 0.4776, recall of 0.9996, and an F1-score of 0.6450.
The mean reward is 20.34 \pm 44.63 across all episodes (versus 18.80 \pm 43.98
for DQN and -0.17 \pm 23.79 for PPO), with an average of 5.0 steps per episode
(constant across models). Graphical analyses, including learning curves
smoothed with a Savgol filter (window=501, polynomial=2), variance trends,
action distributions, and cumulative detections, demonstrate LogGuardQ's
superior stability and efficiency. Statistical tests (Mann-Whitney U) confirm
significant performance advantages (e.g., p = 0.0002 vs. DQN with negligible
effect size, p < 0.0001 vs. PPO with medium effect size, and p < 0.0001 for DQN
vs. PPO with small effect size). By bridging cognitive science and RL,
LogGuardQ offers a scalable approach to adaptive learning in uncertain
environments, with potential applications in cybersecurity, intrusion
detection, and decision-making under uncertainty.

</details>


### [558] [Mixture-of-Clustered-Experts: Advancing Expert Specialization and Generalization in Instruction Tuning](https://arxiv.org/abs/2509.10513)
*Sugyeong Eo,Jungjun Lee,Chanjun Park,Heuiseok Lim*

Main category: cs.LG

TL;DR: MoCE通过双阶段路由机制解决稀疏MoE在指令调优中专家专业化和泛化能力不足的挑战，并在多个基准测试中表现优于强基线模型。


<details>
  <summary>Details</summary>
Motivation: 稀疏MoE在指令调优中面临专家专业化和泛化能力不足的挑战，尤其是在输入异构性显著的情况下。

Method: 提出MoCE，采用双阶段路由机制：第一阶段基于序列级特征进行专家分组路由，第二阶段在token级别激活分组内的top-k个专家。

Result: MoCE在多个基准测试中表现出优于强基线模型的性能和增强的泛化能力。

Conclusion: MoCE通过其双阶段路由机制，能够有效划分异构输入并促进专家分组专业化，同时保持了token级别路由的优势，在指令调优任务中表现出色。

Abstract: A sparse Mixture-of-Experts (MoE) architecture has emerged as a highly
scalable solution by conditionally activating sub-modules without a
proportional increase in computational costs. However, improving expert
specialization to enhance performance and generalization remains a challenge
for MoE, especially in instruction tuning scenarios characterized by
significant input heterogeneity. In this work, we propose the
Mixture-of-Clustered-Experts (MoCE) to address this limitation through a
dual-stage routing mechanism. The first stage in the mechanism performs expert
group routing based on sequence-level features, while the second stage
activates the top-$k$ experts within the group at the token level. This
approach enables the effective partitioning of heterogeneous inputs based on
their knowledge requirements, encouraging expert group specialization while
maintaining the advantages of token-level routing. We evaluate MoCE across a
comprehensive set of benchmarks, demonstrating its consistent superiority over
strong baselines and its enhanced generalization capabilities. Detailed
analysis further highlights the robustness and effectiveness of MoCE.

</details>


### [559] [A Differential Manifold Perspective and Universality Analysis of Continuous Attractors in Artificial Neural Networks](https://arxiv.org/abs/2509.10514)
*Shaoxin Tian,Hongkai Liu,Yuying Yang,Jiali Yu,Zizheng Miao,Xuming Huang,Zhishuai Liu,Zhang Yi*

Main category: cs.LG

TL;DR: 本文提出一个从微分流形角度分析人工神经网络中连续吸引子的新框架，并验证了其普遍性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏统一的框架来分析不同动力学系统中连续吸引子的性质，限制了其在不同架构间的通用性。

Method: 从微分流形角度建立新框架，分析连续吸引子与局部雅可比矩阵特征值之间的联系，并展示奇异值分层在常见分类模型和数据集上的普遍性。

Result: 验证了该框架与先有结论的兼容性，阐明了连续吸引子现象与局部雅可比矩阵特征值之间的联系，并证明了奇异值分层在常见分类模型和数据集上的普遍性。

Conclusion: 连续吸引子可能普遍存在于一般神经网络中，需要一个通用理论来支撑，而提出的框架因特征值和奇异值之间的紧密数学联系而提供了有希望的基础。

Abstract: Continuous attractors are critical for information processing in both
biological and artificial neural systems, with implications for spatial
navigation, memory, and deep learning optimization. However, existing research
lacks a unified framework to analyze their properties across diverse dynamical
systems, limiting cross-architectural generalizability. This study establishes
a novel framework from the perspective of differential manifolds to investigate
continuous attractors in artificial neural networks. It verifies compatibility
with prior conclusions, elucidates links between continuous attractor phenomena
and eigenvalues of the local Jacobian matrix, and demonstrates the universality
of singular value stratification in common classification models and datasets.
These findings suggest continuous attractors may be ubiquitous in general
neural networks, highlighting the need for a general theory, with the proposed
framework offering a promising foundation given the close mathematical
connection between eigenvalues and singular values.

</details>


### [560] [Adaptive Preference Optimization with Uncertainty-aware Utility Anchor](https://arxiv.org/abs/2509.10515)
*Xiaobo Wang,Zixia Jia,Jiaqi Li,Qi Liu,Zilong Zheng*

Main category: cs.LG

TL;DR: UAPO是一种新的离线偏好优化框架，通过引入锚定函数来处理不成对的偏好数据，提高了数据利用率和训练鲁棒性，并取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的DPO等离线偏好优化方法依赖于Bradley-Terry（BT）奖励建模，而BT模型有严格的假设，如需要成对训练数据、模型分布转移、人类理性等。这些假设限制了方法的应用和数据利用效率。

Method: 提出了一种名为UAPO（Adaptive Preference Optimization with Utility Anchor）的通用框架。UAPO引入了一个锚定函数来估计偏好数据标注带来的不确定性，使其能够在不成对的数据场景下进行训练，从而提高数据利用效率。锚定函数的引入也增强了UAPO在训练过程中的鲁棒性。

Result: 实验结果表明，UAPO在不需要严格配对数据的情况下，能够取得有竞争力的结果。

Conclusion: UAPO为更灵活、更有效的偏好优化方法开辟了道路，解决了现有方法在数据配对和鲁棒性方面存在的局限性。

Abstract: Offline preference optimization methods are efficient for large language
models (LLMs) alignment. Direct Preference optimization (DPO)-like learning,
one of the most popular approaches, stands out for its efficiency in reward
modeling. However, these methods typically follow the convention to use
Bradley-Terry (BT) reward modeling that faces several critical assumptions,
including the requirement for pairwise training data, model distribution
shifting, human rationality assumption, etc. To address these limitations, we
propose a general framework for offline preference optimization methods,
Adaptive Preference Optimization with Utility Anchor (UAPO), which introduces
an anchoring function to estimate the uncertainties brought from preference
data annotation. Our method enables training even in scenarios where the data
is unpaired, significantly enhancing data utilization efficiency. Moreover, the
anchor design makes UAPO more robust in the training process. Experimental
results demonstrate that UAPO achieves competitive outcomes without the strict
dependency on data pairing, paving the way for more flexible and effective
preference optimization methods.

</details>


### [561] [Privacy-Preserving Personalization in Education: A Federated Recommender System for Student Performance Prediction](https://arxiv.org/abs/2509.10516)
*Rodrigo Tertulino*

Main category: cs.LG

TL;DR: 本文提出了一种利用联邦学习（FL）的隐私保护推荐系统，解决了教育数字化带来的学生数据隐私问题，并在ASSISTments数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 教育数字化带来了数据驱动的个性化机会，但也引发了学生数据隐私的挑战，传统推荐系统依赖的中心化数据模式与数据保护法规不兼容。

Method: 利用深度神经网络（DNN）和精心设计的特征，结合联邦学习（FL）技术，对大型ASSISTments教育数据集进行分析。比较了不同的联邦聚合策略，特别是FedProx和FedAvg。

Result: FedProx在处理异构学生数据方面比FedAvg更稳定有效。优化后的联邦模型达到了76.28%的F1分数，相当于中心化XGBoost模型的82.85%。

Conclusion: 联邦学习方法可以在不集中化敏感学生数据的情况下，实现高效的内容推荐，为解决教育平台的个性化与隐私困境提供了可行且强大的解决方案。

Abstract: The increasing digitalization of education presents unprecedented
opportunities for data-driven personalization, yet it introduces significant
student data privacy challenges. Conventional recommender systems rely on
centralized data, a paradigm often incompatible with modern data protection
regulations. A novel privacy-preserving recommender system is proposed and
evaluated to address this critical issue using Federated Learning (FL). The
approach utilizes a Deep Neural Network (DNN) with rich, engineered features
from the large-scale ASSISTments educational dataset. A rigorous comparative
analysis of federated aggregation strategies was conducted, identifying FedProx
as a significantly more stable and effective method for handling heterogeneous
student data than the standard FedAvg baseline. The optimized federated model
achieves a high-performance F1-Score of 76.28\%, corresponding to 82.85\% of
the performance of a powerful, centralized XGBoost model. These findings
validate that a federated approach can provide highly effective content
recommendations without centralizing sensitive student data. Consequently, our
work presents a viable and robust solution to the personalization-privacy
dilemma in modern educational platforms.

</details>


### [562] [A Comparative Benchmark of Federated Learning Strategies for Mortality Prediction on Heterogeneous and Imbalanced Clinical Data](https://arxiv.org/abs/2509.10517)
*Rodrigo Tertulino*

Main category: cs.LG

TL;DR: 联邦学习在医疗预测中通过FedProx解决了数据异构性和不平衡性问题，实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的临床数据中，数据隐私限制和统计异质性阻碍了机器学习模型在预测住院死亡率方面的应用。联邦学习（FL）提供了一种隐私保护的解决方案，但其在非独立同分布（non-IID）和不平衡条件下的性能需要严格的考察。

Method: 本研究使用MIMIC-IV数据集，通过按临床护理单元划分数据来模拟现实的non-IID环境，并应用SMOTE-Tomek技术处理类别不平衡问题。对五种联邦学习策略（FedAvg, FedProx, FedAdagrad, FedAdam, FedCluster）进行了比较基准测试。

Result: 在50轮通信中，基于正则化的FedProx策略表现最佳，F1分数达到0.8831，且收敛稳定。计算效率最高的FedAvg性能较低。这表明基于正则化的FL算法比标准或服务器端自适应聚合方法更能有效处理异构和不平衡的临床预测任务。

Conclusion: 对于现实世界的医疗应用，基于正则化的联邦学习算法（如FedProx）比标准方法更能提供稳健有效的解决方案，为选择合适的FL策略提供了重要的实证基准。

Abstract: Machine learning models hold significant potential for predicting in-hospital
mortality, yet data privacy constraints and the statistical heterogeneity of
real-world clinical data often hamper their development. Federated Learning
(FL) offers a privacy-preserving solution, but its performance under
non-Independent and Identically Distributed (non-IID) and imbalanced conditions
requires rigorous investigation. The study presents a comparative benchmark of
five federated learning strategies: FedAvg, FedProx, FedAdagrad, FedAdam, and
FedCluster for mortality prediction. Using the large-scale MIMIC-IV dataset, we
simulate a realistic non-IID environment by partitioning data by clinical care
unit. To address the inherent class imbalance of the task, the SMOTE-Tomek
technique is applied to each client's local training data. Our experiments,
conducted over 50 communication rounds, reveal that the regularization-based
strategy, FedProx, consistently outperformed other methods, achieving the
highest F1-Score of 0.8831 while maintaining stable convergence. While the
baseline FedAvg was the most computationally efficient, its predictive
performance was substantially lower. Our findings indicate that
regularization-based FL algorithms like FedProx offer a more robust and
effective solution for heterogeneous and imbalanced clinical prediction tasks
than standard or server-side adaptive aggregation methods. The work provides a
crucial empirical benchmark for selecting appropriate FL strategies for
real-world healthcare applications.

</details>


### [563] [On Using Large-Batches in Federated Learning](https://arxiv.org/abs/2509.10537)
*Sahil Tyagi*

Main category: cs.LG

TL;DR: 本文提出了一种利用小批量和大批量训练之间权衡来解决联邦学习（FL）中大批量训练泛化能力下降问题的方法，以同时获得大批量训练的并行扩展性和小批量训练的良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在数据隐私和局部性至关重要的背景下，在计算资源和网络有限的设备上训练深度网络需要高效的联邦学习（FL）。FL算法通常在并行和统计性能之间进行权衡。在大批量训练中，通信频率的增加可能导致泛化能力下降，从而影响测试性能。

Method: 本文提出了一种利用小批量和大批量训练之间权衡来解决大批量训练泛化能力下降问题的方法。

Result: 与小批量训练相比，在相同迭代次数下，所提出的大批量训练技术在ResNet50和VGG11模型上分别获得了约32.33%和3.74%的更高测试准确率。

Conclusion: 所提出的方法能够在大批量训练的同时获得良好的泛化能力，在联邦学习中实现了训练速度和模型质量的提升。

Abstract: Efficient Federated learning (FL) is crucial for training deep networks over
devices with limited compute resources and bounded networks. With the advent of
big data, devices either generate or collect multimodal data to train either
generic or local-context aware networks, particularly when data privacy and
locality is vital. FL algorithms generally trade-off between parallel and
statistical performance, improving model quality at the cost of higher
communication frequency, or vice versa. Under frequent synchronization
settings, FL over a large cluster of devices may perform more work per-training
iteration by processing a larger global batch-size, thus attaining considerable
training speedup. However, this may result in poor test performance (i.e., low
test loss or accuracy) due to generalization degradation issues associated with
large-batch training. To address these challenges with large-batches, this work
proposes our vision of exploiting the trade-offs between small and large-batch
training, and explore new directions to enjoy both the parallel scaling of
large-batches and good generalizability of small-batch training. For the same
number of iterations, we observe that our proposed large-batch training
technique attains about 32.33% and 3.74% higher test accuracy than small-batch
training in ResNet50 and VGG11 models respectively.

</details>


### [564] [Holographic Knowledge Manifolds: A Novel Pipeline for Continual Learning Without Catastrophic Forgetting in Large Language Models](https://arxiv.org/abs/2509.10518)
*Justin Arndt*

Main category: cs.LG

TL;DR: HKM是一种创新的AI知识表示方法，通过分形量化、概率纠缠和动态衍射切片等技术，实现了零灾难性遗忘、最小的内存增长和高效率。它能将知识压缩3倍，节省67%的存储空间，并且支持超过1020次更新，每次增量仅增长1%。实验表明，HKM在WikiText和FB15k数据集上表现出色，实现了0%遗忘、3倍压缩和53%的训练时间缩减。该方法有望为公共大语言模型带来范式转变，实现“永恒”适应而无需重新训练，并可能在未来通过多模态融合和量子硬件进一步降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于解决AI知识表示中的灾难性遗忘问题，同时保持内存效率和高计算性能。作者旨在提出一种能够实现“永恒”适应而无需重新训练的AI模型，以应对大规模语言模型（LLMs）在不断更新的数据和任务中面临的挑战。

Method: 该研究提出了一种名为全息知识流形（HKM）的四阶段流水线。HKM利用分形量化、概率纠缠和动态衍射切片等技术来压缩知识。在实现上，HKM能够以100%的全息集成方式进行集成，并支持超过1020次的更新，每次更新的内存增长率仅为1%。

Result: 在结合的WikiText和FB15k数据集（扩展到2997个节点）上的实验显示，HKM取得了行业领先的性能：遗忘率为0%（相比GEM基线有无限提升），压缩率为3倍，并且在消费级GPU硬件上训练时间减少了53%。此外，假设成本分析预计在五年内可节省9240万美元（以PB为规模），能源消耗减少21.2%，碳足迹降低33%。

Conclusion: 该研究提出的HKM流水线在解决AI知识表示中的灾难性遗忘问题上取得了显著成效，同时实现了高压缩率和高效率。实验结果证明了其在减少训练时间和计算资源消耗方面的潜力。研究者认为HKM代表了公共大语言模型的一个范式转变，使得模型能够进行“永恒”的适应而无需重新训练，并预示了其在多模态融合和量子计算领域的未来应用前景，有望大幅降低微调成本。

Abstract: We introduce the Holographic Knowledge Manifold (HKM), a four-phase pipeline
that achieves zero catastrophic forgetting in AI knowledge representation while
maintaining minimal memory growth and high efficiency. Leveraging fractal
quantization, probabilistic entanglement, and dynamic diffraction chipping, HKM
compresses knowledge substrates by 3x with 67% storage savings, integrates
holographically at 100%, and supports over 1,020 updates with 1% growth per
increment. In experiments on combined WikiText and FB15k datasets (scaled to
2,997 nodes), we demonstrate industry-leading performance: 0% forgetting
(infinite improvement over GEM baselines), 3x compression, and 53% training
time reduction on consumer GPU hardware. Hypothetical cost analyses project
$92.4M savings over 5 years at petabyte scale, with 21.2% energy reduction and
33% lower carbon footprint. This work hypothesizes a paradigm shift for public
large language models (LLMs), enabling "eternal" adaptation without retraining.
Future extensions to multimodal fusion and quantum hardware could further
democratize scalable AI, potentially reducing fine-tuning costs by 60-80% for
models like Llama-3 or Grok-4. Code, datasets, and full results are publicly
available for reproducibility.

</details>


### [565] [Gradient Estimation Methods of Approximate Multipliers for High-Accuracy Retraining of Deep Learning Models](https://arxiv.org/abs/2509.10519)
*Chang Meng,Wayne Burleson,Giovanni De Micheli*

Main category: cs.LG

TL;DR: 两种新的近似乘法器梯度计算方法（LUT-2D 和 LUT-1D）可提高深度学习模型再训练的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用精确乘法器的梯度来估计近似乘法器的梯度，这会导致次优的再训练结果。需要更精确的方法来计算近似乘法器的梯度。

Method: 提出两种方法：1. LUT-2D：使用二维查找表（LUT）来表征近似乘法器梯度。2. LUT-1D：一种更紧凑、更高效的变体，使用一维 LUT 存储梯度值。

Result: 在 CIFAR-10 数据集和卷积神经网络上，LUT-2D 和 LUT-1D 方法分别平均提高了 3.83% 和 3.72% 的再训练准确率。在 ImageNet 数据集和视觉 Transformer 模型上，LUT-1D 方法与最先进的再训练框架相比，平均提高了 23.69% 的再训练准确率。

Conclusion: 所提出的 LUT-2D 和 LUT-1D 方法能够更精确地计算近似乘法器的梯度，从而显著提高深度学习模型再训练的准确性，同时 LUT-1D 在效率方面也表现出色。

Abstract: Approximate multipliers (AppMults) are widely used in deep learning
accelerators to reduce their area, delay, and power consumption. However,
AppMults introduce arithmetic errors into deep learning models, necessitating a
retraining process to recover accuracy. A key step in retraining is computing
the gradient of the AppMult, i.e., the partial derivative of the approximate
product with respect to each input operand. Existing approaches typically
estimate this gradient using that of the accurate multiplier (AccMult), which
can lead to suboptimal retraining results. To address this, we propose two
methods to obtain more precise gradients of AppMults. The first, called LUT-2D,
characterizes the AppMult gradient with 2-dimensional lookup tables (LUTs),
providing fine-grained estimation and achieving the highest retraining
accuracy. The second, called LUT-1D, is a compact and more efficient variant
that stores gradient values in 1-dimensional LUTs, achieving comparable
retraining accuracy with shorter runtime. Experimental results show that on
CIFAR-10 with convolutional neural networks, our LUT-2D and LUT-1D methods
improve retraining accuracy by 3.83% and 3.72% on average, respectively. On
ImageNet with vision transformer models, our LUT-1D method improves retraining
accuracy by 23.69% on average, compared to a state-of-the-art retraining
framework.

</details>


### [566] [Offline Contextual Bandit with Counterfactual Sample Identification](https://arxiv.org/abs/2509.10520)
*Alexandre Gilotte,Otmane Sakhi,Imad Aouali,Benjamin Heymann*

Main category: cs.LG

TL;DR: 反事实样本识别方法通过比较实际采取的行动和在相同情境下由记录策略抽样的反事实行动，来识别导致成功（二元）结果的行动，以解决直接奖励模型中的混淆问题，并在合成实验和实际部署中表现优于直接模型。


<details>
  <summary>Details</summary>
Motivation: 直接奖励模型在生产系统中容易受到混淆的影响，难以区分行动和情境的影响。

Method: 提出一种名为‘反事实样本识别’的新方法，该方法不直接预测奖励，而是学习识别导致成功（二元）结果的行动，方法是通过将其与在相同情境下由记录策略抽样的反事实行动进行比较。

Result: 该方法在理论上具有支撑，并且在合成实验和实际部署中，其表现始终优于直接模型。

Conclusion: 反事实样本识别方法能够有效解决直接奖励模型中的混淆问题，并在各种场景下提供更优的性能。

Abstract: In production systems, contextual bandit approaches often rely on direct
reward models that take both action and context as input. However, these models
can suffer from confounding, making it difficult to isolate the effect of the
action from that of the context. We present \emph{Counterfactual Sample
Identification}, a new approach that re-frames the problem: rather than
predicting reward, it learns to recognize which action led to a successful
(binary) outcome by comparing it to a counterfactual action sampled from the
logging policy under the same context. The method is theoretically grounded and
consistently outperforms direct models in both synthetic experiments and
real-world deployments.

</details>


### [567] [Variational Gaussian Mixture Manifold Models for Client-Specific Federated Personalization](https://arxiv.org/abs/2509.10521)
*Sai Puppala,Ismail Hossain,Md Jahangir Alam,Sajedul Talukder*

Main category: cs.LG

TL;DR: VGM^2是一个以几何为中心的个性化联邦学习框架，通过学习客户端特定的UMAP嵌入和对潜在成对距离进行建模，在标签倾斜和非平稳情况下提高了性能，并只交换不确定性感知的标记统计数据，实现了稳定性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决现有个性化联邦学习（PFL）在标签倾斜和非平稳情况下由于忽略客户端特定几何而导致的失败问题。

Method: VGM^2框架包括三个主要部分：（1）学习客户端特定的参数化UMAP嵌入；（2）使用混合关系标记对同一和不同类别对进行潜在成对距离建模；（3）仅交换变分、不确定性感知的标记统计数据。每个客户端维护一个关于标记权重、均值和方差的Dirichlet-Normal-Inverse-Gamma（Dir-NIG）后验，服务器通过共轭矩匹配进行聚合，形成全局先验。

Result: VGM^2在八个具有非IID标签分片的视觉数据集上，实现了具有竞争性或优于强基线的测试F1分数，同时通信量仅为小的几何摘要。此外，该框架还包含一个用于距离到相似性映射的校准项，并报告了通信和计算预算。

Conclusion: VGM^2通过其以几何为中心的PFL框架，在标签倾斜和非平稳的情况下，通过学习客户端特定的UMAP嵌入和对潜在成对距离进行建模，实现了稳定性和可扩展性。该框架通过仅交换不确定性感知的标记统计数据，在保持竞争性或更高性能的同时，减少了通信量，并增强了隐私性。

Abstract: Personalized federated learning (PFL) often fails under label skew and
non-stationarity because a single global parameterization ignores
client-specific geometry. We introduce VGM$^2$ (Variational Gaussian Mixture
Manifold), a geometry-centric PFL framework that (i) learns client-specific
parametric UMAP embeddings, (ii) models latent pairwise distances with mixture
relation markers for same and different class pairs, and (iii) exchanges only
variational, uncertainty-aware marker statistics. Each client maintains a
Dirichlet-Normal-Inverse-Gamma (Dir-NIG) posterior over marker weights, means,
and variances; the server aggregates via conjugate moment matching to form
global priors that guide subsequent rounds. We prove that this aggregation
minimizes the summed reverse Kullback-Leibler divergence from client posteriors
within the conjugate family, yielding stability under heterogeneity. We further
incorporate a calibration term for distance-to-similarity mapping and report
communication and compute budgets. Across eight vision datasets with non-IID
label shards, VGM$^2$ achieves competitive or superior test F1 scores compared
to strong baselines while communicating only small geometry summaries. Privacy
is strengthened through secure aggregation and optional differential privacy
noise, and we provide a membership-inference stress test. Code and
configurations will be released to ensure full reproducibility.

</details>


### [568] [Multimodal Deep Learning for ATCO Command Lifecycle Modeling and Workload Prediction](https://arxiv.org/abs/2509.10522)
*Kaizhen Tan*

Main category: cs.LG

TL;DR: 该研究提出了一种多模态深度学习框架，用于分析空中交通管制员（ATCO）的语音指令，以估计指令与飞机机动之间的时间偏移和指令持续时间。


<details>
  <summary>Details</summary>
Motivation: 空中交通管制员在密集的空域中发出高强度语音指令，准确的 workload 建模对安全和效率至关重要。

Method: 该研究构建了一个高质量的数据集，并使用 CNN-Transformer 集成模型来处理结构化数据、轨迹序列和图像特征，以预测指令与飞机机动之间的时间偏移和指令持续时间。

Result: 该研究首次提出了一个连接轨迹和语音指令的模型，能够支持智能指令生成，并对 workload 评估、人员配置和调度具有实际价值。

Conclusion: 该研究提出的多模态深度学习框架能够准确、可泛化且可解释地预测 ATCO 语音指令的关键参数，为提高航空安全和效率提供了新的途径。

Abstract: Air traffic controllers (ATCOs) issue high-intensity voice commands in dense
airspace, where accurate workload modeling is critical for safety and
efficiency. This paper proposes a multimodal deep learning framework that
integrates structured data, trajectory sequences, and image features to
estimate two key parameters in the ATCO command lifecycle: the time offset
between a command and the resulting aircraft maneuver, and the command
duration. A high-quality dataset was constructed, with maneuver points detected
using sliding window and histogram-based methods. A CNN-Transformer ensemble
model was developed for accurate, generalizable, and interpretable predictions.
By linking trajectories to voice commands, this work offers the first model of
its kind to support intelligent command generation and provides practical value
for workload assessment, staffing, and scheduling.

</details>


### [569] [From Predictions to Explanations: Explainable AI for Autism Diagnosis and Identification of Critical Brain Regions](https://arxiv.org/abs/2509.10523)
*Kush Gupta,Amir Aly,Emmanuel Ifeachor,Rohit Shankar*

Main category: cs.LG

TL;DR: 提出一个结合深度学习和可解释AI的自闭症谱系障碍（ASD）诊断框架，利用跨域迁移学习解决数据稀缺性问题，并通过XAI技术识别关键脑区。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习在ASD研究中的迁移学习应用有限，而ASD是一种神经发育异常，需要有效的诊断方法。

Method: 提出一个包含两个模块的计算机辅助诊断框架：1. 使用跨域迁移学习微调的深度学习模型进行ASD分类。2. 应用三种XAI技术（显著性图、Grad-CAM、SHAP）来解释模型决策并识别关键脑区。

Result: 跨域迁移学习能有效解决ASD研究中的数据稀缺问题。XAI技术揭示了模型的诊断决策过程，并识别出与ASD最相关的脑区，且这些发现与已有的神经生物学证据高度吻合。

Conclusion: 该框架通过结合迁移学习和可解释AI，为ASD诊断提供了一种有效且具有临床相关性的方法，并能识别出与ASD相关的关键脑区。

Abstract: Autism spectrum disorder (ASD) is a neurodevelopmental condition
characterized by atypical brain maturation. However, the adaptation of transfer
learning paradigms in machine learning for ASD research remains notably
limited. In this study, we propose a computer-aided diagnostic framework with
two modules. This chapter presents a two-module framework combining deep
learning and explainable AI for ASD diagnosis. The first module leverages a
deep learning model fine-tuned through cross-domain transfer learning for ASD
classification. The second module focuses on interpreting the model decisions
and identifying critical brain regions. To achieve this, we employed three
explainable AI (XAI) techniques: saliency mapping, Gradient-weighted Class
Activation Mapping, and SHapley Additive exPlanations (SHAP) analysis. This
framework demonstrates that cross-domain transfer learning can effectively
address data scarcity in ASD research. In addition, by applying three
established explainability techniques, the approach reveals how the model makes
diagnostic decisions and identifies brain regions most associated with ASD.
These findings were compared against established neurobiological evidence,
highlighting strong alignment and reinforcing the clinical relevance of the
proposed approach.

</details>


### [570] [Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning](https://arxiv.org/abs/2509.10526)
*Dieter Balemans,Thomas Huybrechts,Jan Steckel,Siegfried Mercelis*

Main category: cs.LG

TL;DR: 本论文提出了一种新的神经网路剪枝方法，通过将基于图的观测空间集成到 AutoML 框架中来克服现有方法的局限性。该方法利用图注意力网络（GAT）对网络进行编码，并采用细粒度的二元动作空间，使得智能体能够直接从数据中学习最优的通道重要性标准，并利用约束马尔可夫决策过程（CMDP）和自对抗奖励系统来处理资源限制。实验证明，该方法在 CIFAR-10、CIFAR-100 和 ImageNet 数据集上优于传统方法，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经网路剪枝方法依赖于手工设计的启发式方法和局部优化，导致次优性能和效率低下的剪枝策略。本研究旨在通过引入全局视角和更精细的控制来改进这一过程。

Method: 本研究提出了一种新的神经网路剪枝方法，将基于图的观测空间集成到 AutoML 框架中。该方法使用图注意力网络（GAT）对网络拓扑进行编码，并将剪枝操作从连续的剪枝率转换为细粒度的二元动作空间。整个过程被建模为一个约束马尔可夫决策过程（CMDP），并采用自对抗奖励系统来鼓励智能体在满足资源约束（如压缩率）的同时提高性能。

Result: 在 CIFAR-10、CIFAR-100 和 ImageNet 等基准数据集上的广泛实验表明，所提出的方法在性能上持续优于传统剪枝技术，实现了最先进（SOTA）的结果。该方法能够学习特定于任务的剪枝策略，识别超越简单权重大小考虑的功能冗余连接。

Conclusion: 本研究提出的基于图的 AutoML 剪枝框架能够有效地学习任务特定的剪枝策略，实现比传统方法更优越的性能。通过整合图神经网络和细粒度的动作空间，该方法克服了现有剪枝技术的局限性，并在资源受限的情况下实现了最先进的压缩和准确性。

Abstract: This paper presents a novel approach to neural network pruning by integrating
a graph-based observation space into an AutoML framework to address the
limitations of existing methods. Traditional pruning approaches often depend on
hand-crafted heuristics and local optimization perspectives, which can lead to
suboptimal performance and inefficient pruning strategies. Our framework
transforms the pruning process by introducing a graph representation of the
target neural network that captures complete topological relationships between
layers and channels, replacing the limited layer-wise observation space with a
global view of network structure. The core innovations include a Graph
Attention Network (GAT) encoder that processes the network's graph
representation and generates a rich embedding. Additionally, for the action
space we transition from continuous pruning ratios to fine-grained binary
action spaces which enables the agent to learn optimal channel importance
criteria directly from data, moving away from predefined scoring functions.
These contributions are modelled within a Constrained Markov Decision Process
(CMDP) framework, allowing the agent to make informed pruning decisions while
adhering to resource constraints such as target compression rates. For this, we
design a self-competition reward system that encourages the agent to outperform
its previous best performance while satisfying the defined constraints. We
demonstrate the effectiveness of our approach through extensive experiments on
benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet. The experiments
show that our method consistently outperforms traditional pruning techniques,
showing state-of-the-art results while learning task-specific pruning
strategies that identify functionally redundant connections beyond simple
weight magnitude considerations.

</details>


### [571] [STM-Graph: A Python Framework for Spatio-Temporal Mapping and Graph Neural Network Predictions](https://arxiv.org/abs/2509.10528)
*Amirhossein Ghaffari,Huong Nguyen,Lauri Lovén,Ekaterina Gilman*

Main category: cs.LG

TL;DR: STM-Graph是一个开源Python框架，用于将城市时空事件数据转换为适合图神经网络（GNN）训练和预测的图表示。


<details>
  <summary>Details</summary>
Motivation: 城市时空数据因其动态和复杂的性质，对预测分析提出了独特的挑战。

Method: STM-Graph整合了多种空间映射方法、来自OpenStreetMap的城市特征、多种GNN模型、全面的可视化工具以及适用于专业和非专业用户的图形用户界面（GUI）。

Result: 该框架支持快速实验和基准测试，并允许集成新的映射方法和自定义模型。

Conclusion: STM-Graph是一个有价值的资源，可以促进城市计算领域的研究和实践。

Abstract: Urban spatio-temporal data present unique challenges for predictive analytics
due to their dynamic and complex nature. We introduce STM-Graph, an open-source
Python framework that transforms raw spatio-temporal urban event data into
graph representations suitable for Graph Neural Network (GNN) training and
prediction. STM-Graph integrates diverse spatial mapping methods, urban
features from OpenStreetMap, multiple GNN models, comprehensive visualization
tools, and a graphical user interface (GUI) suitable for professional and
non-professional users. This modular and extensible framework facilitates rapid
experimentation and benchmarking. It allows integration of new mapping methods
and custom models, making it a valuable resource for researchers and
practitioners in urban computing. The source code of the framework and GUI are
available at: https://github.com/Ahghaffari/stm_graph and
https://github.com/tuminguyen/stm_graph_gui.

</details>


### [572] [Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay](https://arxiv.org/abs/2509.10529)
*Aoi Otani*

Main category: cs.LG

TL;DR: Latent Replay通过存储紧凑的高级特征表示来解决文本到图像扩散模型中的灾难性遗忘和模式崩溃问题，在保持模型多样性的同时显著提高了早期概念的图像对齐度。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在持续学习新任务时会遇到灾难性遗忘和模式崩溃的问题，这与人类大脑的持续学习能力形成对比。

Method: 应用一种受神经科学启发的 Latent Replay 方法，该方法存储紧凑、高层级的特征表示，而不是完整的过去示例，以减轻遗忘。

Result: 在五个连续学习的视觉概念的实验中，Latent Replay 在保留早期概念的图像对齐度（IA）方面表现优于基线方法（77.59%，高出 14%），同时保持了输出的多样性。随机选择存储的潜在示例比基于相似性的策略更有效。

Conclusion: Latent Replay 能够为生成式人工智能模型实现高效的持续学习，有望实现能够随着用户需求而演变的个性化文本到图像模型，且计算成本可控。

Abstract: Continual learning -- the ability to acquire knowledge incrementally without
forgetting previous skills -- is fundamental to natural intelligence. While the
human brain excels at this, artificial neural networks struggle with
"catastrophic forgetting," where learning new tasks erases previously acquired
knowledge. This challenge is particularly severe for text-to-image diffusion
models, which generate images from textual prompts. Additionally, these models
face "mode collapse," where their outputs become increasingly repetitive over
time. To address these challenges, we apply Latent Replay, a
neuroscience-inspired approach, to diffusion models. Traditional replay methods
mitigate forgetting by storing and revisiting past examples, typically
requiring large collections of images. Latent Replay instead retains only
compact, high-level feature representations extracted from the model's internal
architecture. This mirrors the hippocampal process of storing neural activity
patterns rather than raw sensory inputs, reducing memory usage while preserving
critical information. Through experiments with five sequentially learned visual
concepts, we demonstrate that Latent Replay significantly outperforms existing
methods in maintaining model versatility. After learning all concepts, our
approach retained 77.59% Image Alignment (IA) on the earliest concept, 14%
higher than baseline methods, while maintaining diverse outputs. Surprisingly,
random selection of stored latent examples outperforms similarity-based
strategies. Our findings suggest that Latent Replay enables efficient continual
learning for generative AI models, paving the way for personalized
text-to-image models that evolve with user needs without excessive
computational costs.

</details>


### [573] [Dynamic Adaptive Shared Experts with Grouped Multi-Head Attention Mixture of Experts](https://arxiv.org/abs/2509.10530)
*Cheng Li,Jiexiong Liu,Yixuan Chen,Jie ji*

Main category: cs.LG

TL;DR: DASG-MoE通过结合GMHA、DSSE和ADR机制，在长序列建模方面提高了计算效率和长期依赖捕捉能力，并在多个基准数据集上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于MoE的Transformer模型在长序列建模方面存在计算效率和捕捉长程依赖能力不足的问题，尤其是在专家资源分配的动态适应性方面。DASG-MoE旨在解决这些不足。

Method: DASG-MoE模型集成了三个模块：1. 组注意力机制（GMHA）通过序列分组、局部滑动窗口注意力和特征聚合来降低计算复杂性并解决长程依赖问题。2. 双尺度共享专家结构（DSSE）结合浅层专家（轻量计算）和深层专家（处理复杂语义）以实现效率和准确性的动态平衡。3. 分层自适应动态路由（ADR）机制根据特征复杂性和任务需求动态选择专家层级，并通过局部专家激活策略优化资源分配。

Result: 在多个长序列基准数据集上的实验表明，DASG-MoE模型的性能优于最先进的模型。

Conclusion: DASG-MoE模型通过其创新的GMHA、DSSE和ADR机制，在长序列建模方面取得了显著进展，提高了计算效率和依赖捕捉能力，并在实验中验证了其优越性。

Abstract: Transformer models based on the Mixture of Experts (MoE) architecture have
made significant progress in long-sequence modeling, but existing models still
have shortcomings in computational efficiency and the ability to capture
long-range dependencies, especially in terms of the dynamic adaptability of
expert resource allocation. In this paper, we propose a Dynamic Adaptive Shared
Expert and Grouped Multi-Head Attention Hybrid Model (DASG-MoE) to enhance
long-sequence modeling capabilities by integrating three modules. First, we
employ the Grouped Multi-Head Attention (GMHA) mechanism to effectively reduce
the computational complexity of long sequences. By parallel processing through
sequence grouping, local sliding window attention, and feature aggregation, we
address long-range dependency issues and the model's lack of generalization for
local information. Second, we design a Dual-Scale Shared Expert Structure
(DSSE), where shallow experts use lightweight computations to quickly respond
to low-dimensional features, while deep experts process high-dimensional
complex semantics through pre-training transfer and post-training optimization,
achieving a dynamic balance between efficiency and accuracy. Third, we propose
a hierarchical Adaptive Dynamic Routing (ADR) mechanism that dynamically
selects expert levels based on feature complexity and task requirements, and
optimizes resource allocation through a local expert activation strategy.
Experiments on multiple long-sequence benchmark datasets demonstrate that our
DASG-MoE model outperforms state-of-the-art models.

</details>


### [574] [FinXplore: An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment Opportunities](https://arxiv.org/abs/2509.10531)
*Himanshu Choudhary,Arishi Orra,Manoj Thakur*

Main category: cs.LG

TL;DR: 该研究提出了一种新的投资方法，通过结合利用现有资产和探索新投资机会来优化投资组合。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习（DRL）在投资组合优化中存在局限性，通常只在预定义的投资范围内进行资产配置，忽略了探索新机会。

Method: 提出了一种集成现有资产利用和新机会探索的投资方法，使用两个DRL代理动态平衡这些目标。一个代理负责现有投资组合的资产配置，另一个代理负责探索扩展投资范围内的机会。

Result: 实验结果表明，该方法在两个真实市场数据集上的表现优于最先进的投资组合策略和基线方法。

Conclusion: 所提出的方法能够适应不断变化的市场，并提高投资组合的表现。

Abstract: Portfolio optimization is essential for balancing risk and return in
financial decision-making. Deep Reinforcement Learning (DRL) has stood out as a
cutting-edge tool for portfolio optimization that learns dynamic asset
allocation using trial-and-error interactions. However, most DRL-based methods
are restricted to allocating assets within a pre-defined investment universe
and overlook exploring new opportunities. This study introduces an investment
landscape that integrates exploiting existing assets with exploring new
investment opportunities in an extended universe. The proposed approach
leverages two DRL agents and dynamically balances these objectives to adapt to
evolving markets while enhancing portfolio performance. One agent allocates
assets within the existing universe, while another assists in exploring new
opportunities in the extended universe. The effciency of the proposed
methodology is determined using two real-world market data sets. The
experiments demonstrate the superiority of the suggested approach against the
state-of-the-art portfolio strategies and baseline methods.

</details>


### [575] [Decoupling the "What" and "Where" With Polar Coordinate Positional Embeddings](https://arxiv.org/abs/2509.10534)
*Anand Gopalakrishnan,Robert Csordás,Jürgen Schmidhuber,Michael C. Mozer*

Main category: cs.LG

TL;DR: RoPE中的位置和内容信息纠缠不清，我们提出了PoPE来解决这个问题，它在多个任务上都优于RoPE。


<details>
  <summary>Details</summary>
Motivation: RoPE中的什么和哪里信息是纠缠的，这可能会损害其性能，尤其是在需要独立匹配这些因素的任务中。

Method: 提出了一种称为PoPE（极坐标位置嵌入）的改进方法，以消除RoPE中的什么-哪里混淆。

Result: PoPE在仅按位置或内容索引的诊断任务上表现更好。在音乐、基因组和自然语言领域的自回归序列建模中，使用PoPE的Transformer在评估损失（困惑度）和下游任务性能方面优于使用RoPE的基线。这些改进在1.24亿到7.74亿参数的模型规模上对语言建模仍然有效。最重要的是，PoPE在零样本长度外推方面表现出很强的能力，而RoPE在测试时在更长的序列上性能会显著下降。

Conclusion: PoPE消除了RoPE中的内容和位置信息的混淆，并在各种序列建模任务中提供了优越的性能和长度外推能力。

Abstract: The attention mechanism in a Transformer architecture matches key to query
based on both content -- the what -- and position in a sequence -- the where.
We present an analysis indicating that what and where are entangled in the
popular RoPE rotary position embedding. This entanglement can impair
performance particularly when decisions require independent matches on these
two factors. We propose an improvement to RoPE, which we call Polar Coordinate
Position Embeddings or PoPE, that eliminates the what-where confound. PoPE is
far superior on a diagnostic task requiring indexing solely by position or by
content. On autoregressive sequence modeling in music, genomic, and natural
language domains, Transformers using PoPE as the positional encoding scheme
outperform baselines using RoPE with respect to evaluation loss (perplexity)
and downstream task performance. On language modeling, these gains persist
across model scale, from 124M to 774M parameters. Crucially, PoPE shows strong
zero-shot length extrapolation capabilities, whereas RoPE's performance
degrades significantly on longer sequences at test time without fine tuning or
the use of position-interpolation methods.

</details>


### [576] [Semantic-guided LoRA Parameters Generation](https://arxiv.org/abs/2509.10535)
*Miaoge Li,Yang Chen,Zhijie Rao,Can Jiang,Jingcai Guo*

Main category: cs.LG

TL;DR: SG-LoRA是一个新框架，可以为用户生成个性化的LoRA参数，无需额外训练或访问用户数据，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理用户特定的任务偏好和跨领域任务迁移时存在挑战，而为每个用户重新训练模型成本高且涉及隐私问题。

Method: SG-LoRA利用任务描述作为语义桥梁，通过计算与已知专家任务的相似度，在共享嵌入空间中生成目标任务的LoRA参数分布，从而为新任务生成高性能参数。

Result: 在多个具有挑战性的任务上进行了广泛实验，验证了SG-LoRA的优越性能和出色的适应性。

Conclusion: SG-LoRA能够实时构建与用户意图一致的LoRA模型，为在零样本开放世界设置下进行个性化模型适应提供了一种保护隐私的解决方案。

Abstract: Low-Rank Adaptation (LoRA) has demonstrated strong generalization
capabilities across a variety of tasks for efficiently fine-tuning AI models,
especially on resource-constrained edges. However, in real-world applications,
edge users often exhibit task-specific preferences that are difficult to handle
with a unified model trained under a closed-world assumption, and the challenge
may further increase when there are significant domain shifts between training
and deployment. Meanwhile, retraining/fine-tuning models for each user is also
impractical due to its cost-intensive nature and privacy concerns over raw data
utilization from edges. To address these challenges, we propose Semantic-guided
LoRA Parameter Generation (SG-LoRA), the first of its kind framework to
efficiently produce user-specific LoRA parameters without any additional
training on user tasks or access to user-specific data. Concretely, SG-LoRA
uses task descriptions as the semantic bridge, measuring their proximity to a
set of known expert tasks in a shared embedding space. Based on this semantic
guidance, it models the target task's LoRA parameter distribution to generate
high-performing parameters for novel tasks. SG-LoRA enables the real-time
construction of LoRA models aligned with individual intents by distilling
knowledge from prominent LoRA experts and, meanwhile, offering a
privacy-preserving solution for personalized model adaptation in a novel
zero-shot open-world setting proposed in this work. Extensive experiments on
multiple challenging tasks confirm the superior performance and remarkable
adaptability of SG-LoRA. Code is available at
https://github.com/keepgoingjkg/SG-LoRA.

</details>


### [577] [Contextuality, Holonomy and Discrete Fiber Bundles in Group-Valued Boltzmann Machines](https://arxiv.org/abs/2509.10536)
*Jean-Pierre Magnot*

Main category: cs.LG

TL;DR: We introduce a geometric extension of Restricted Boltzmann Machines (RBMs) using abstract groups for weights, enabling modeling of complex structures like projective transformations and symmetries. A key contribution is a 'contextuality index' to quantify global inconsistency, with applications in AI.


<details>
  <summary>Details</summary>
Motivation: The motivation is to generalize RBMs by allowing weights in abstract groups to model complex relational structures relevant to vision, language, and quantum learning.

Method: The paper proposes a geometric extension of RBMs with group-valued weights and introduces a 'contextuality index' based on group-valued holonomies computed along cycles in the RBM graph.

Result: The 'contextuality index' quantifies global inconsistency or 'curvature' induced by local weights, generalizing classical notions. Links are established with sheaf-theoretic contextuality, gauge theory, and noncommutative geometry, with numerical and diagrammatic examples provided.

Conclusion: This framework opens new AI research directions, including curvature-aware learning and topological regularization in uncertain environments.

Abstract: We propose a geometric extension of restricted Boltzmann machines (RBMs) by
allowing weights to take values in abstract groups such as \(
\mathrm{GL}_n(\mathbb{R}) \), \( \mathrm{SU}(2) \), or even
infinite-dimensional operator groups. This generalization enables the modeling
of complex relational structures, including projective transformations, spinor
dynamics, and functional symmetries, with direct applications to vision,
language, and quantum learning.
  A central contribution of this work is the introduction of a
\emph{contextuality index} based on group-valued holonomies computed along
cycles in the RBM graph. This index quantifies the global inconsistency or
"curvature" induced by local weights, generalizing classical notions of
coherence, consistency, and geometric flatness. We establish links with
sheaf-theoretic contextuality, gauge theory, and noncommutative geometry, and
provide numerical and diagrammatic examples in both finite and infinite
dimensions.
  This framework opens novel directions in AI, from curvature-aware learning
architectures to topological regularization in uncertain or adversarial
environments.

</details>


### [578] [MatQnA: A Benchmark Dataset for Multi-modal Large Language Models in Materials Characterization and Analysis](https://arxiv.org/abs/2509.11335)
*Yonghao Weng,Liqiang Gao,Linwu Zhu,Jian Huang*

Main category: cs.LG

TL;DR: 该研究提出了MatQnA，一个针对材料表征技术的首个多模态基准数据集，旨在评估大型语言模型在材料分析领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在通用领域表现出色，但在材料表征与分析等高度专业化领域的应用能力尚未得到充分验证，存在研究空白。

Method: 研究人员构建了一个包含十种主流材料表征方法（如XPS、XRD、SEM、TEM等）的多模态数据集MatQnA。该数据集采用结合大型语言模型和人类 in-the-loop 验证的混合方法，生成了包含选择题和主观题的高质量问答对。

Result: 初步评估结果显示，先进的多模态AI模型（如GPT-4.1、Claude 4、Gemini 2.5 和 豆包 Vision Pro 32K）在材料数据解释与分析任务的客观题上准确率已接近90%。

Conclusion: 该研究表明，多模态AI模型在材料表征和分析领域展现出巨大潜力，MatQnA数据集的发布为进一步研究提供了基础。

Abstract: Recently, large language models (LLMs) have achieved remarkable breakthroughs
in general domains such as programming and writing, and have demonstrated
strong potential in various scientific research scenarios. However, the
capabilities of AI models in the highly specialized field of materials
characterization and analysis have not yet been systematically or sufficiently
validated. To address this gap, we present MatQnA, the first multi-modal
benchmark dataset specifically designed for material characterization
techniques. MatQnA includes ten mainstream characterization methods, such as
X-ray Photoelectron Spectroscopy (XPS), X-ray Diffraction (XRD), Scanning
Electron Microscopy (SEM), Transmission Electron Microscopy (TEM), etc. We
employ a hybrid approach combining LLMs with human-in-the-loop validation to
construct high-quality question-answer pairs, integrating both multiple-choice
and subjective questions. Our preliminary evaluation results show that the most
advanced multi-modal AI models (e.g., GPT-4.1, Claude 4, Gemini 2.5, and Doubao
Vision Pro 32K) have already achieved nearly 90% accuracy on objective
questions in materials data interpretation and analysis tasks, demonstrating
strong potential for applications in materials characterization and analysis.
The MatQnA dataset is publicly available at
https://huggingface.co/datasets/richardhzgg/matQnA.

</details>


### [579] [DualAlign: Generating Clinically Grounded Synthetic Data](https://arxiv.org/abs/2509.10538)
*Rumeng Li,Xun Wang,Hong Yu*

Main category: cs.LG

TL;DR: LLMs can generate clinical text, but producing realistic and clinically meaningful synthetic data is hard. DualAlign framework enhances synthetic data quality using dual alignment (statistical and semantic). It improves data for low-resource clinical text analysis, especially for conditions like Alzheimer's disease.


<details>
  <summary>Details</summary>
Motivation: Privacy concerns, limited annotated data for rare conditions, and biases in real-world EHRs necessitate the creation of synthetic clinical data. While LLMs can generate text, ensuring the synthetic data is both realistic and clinically valid is a challenge.

Method: The DualAlign framework uses dual alignment: 1) statistical alignment to condition generation on patient demographics and risk factors, and 2) semantic alignment to incorporate real-world symptom trajectories. This guides content generation for more clinically grounded synthetic data.

Result: DualAlign, using Alzheimer's disease as a case study, generated context-grounded, symptom-level sentences that better represent real-world clinical documentation. Fine-tuning a LLaMA 3.1-8B model with DualAlign data and human-annotated data significantly improved performance compared to models trained solely on real data or unguided synthetic data.

Conclusion: DualAlign provides a practical method for generating privacy-preserving, clinically grounded synthetic data for clinical text analysis, particularly in low-resource scenarios. Although it doesn't fully address longitudinal complexity, it offers a significant improvement over existing methods.

Abstract: Synthetic clinical data are increasingly important for advancing AI in
healthcare, given strict privacy constraints on real-world EHRs, limited
availability of annotated rare-condition data, and systemic biases in
observational datasets. While large language models (LLMs) can generate fluent
clinical text, producing synthetic data that is both realistic and clinically
meaningful remains challenging. We introduce DualAlign, a framework that
enhances statistical fidelity and clinical plausibility through dual alignment:
(1) statistical alignment, which conditions generation on patient demographics
and risk factors; and (2) semantic alignment, which incorporates real-world
symptom trajectories to guide content generation. Using Alzheimer's disease
(AD) as a case study, DualAlign produces context-grounded symptom-level
sentences that better reflect real-world clinical documentation. Fine-tuning an
LLaMA 3.1-8B model with a combination of DualAlign-generated and
human-annotated data yields substantial performance gains over models trained
on gold data alone or unguided synthetic baselines. While DualAlign does not
fully capture longitudinal complexity, it offers a practical approach for
generating clinically grounded, privacy-preserving synthetic data to support
low-resource clinical text analysis.

</details>


### [580] [GTS_Forecaster: a novel deep learning based geodetic time series forecasting toolbox with python](https://arxiv.org/abs/2509.10560)
*Xuechen Liang,Xiaoxing He,Shengdao Wang,Jean-Philippe Montillet,Zhengkai Huang,Gaël Kermarrec,Shunqiang Hu,Yu Zhou,Jiahui Huang*

Main category: cs.LG

TL;DR: GTS Forecaster是一个开源Python包，利用深度学习模型（KAN, GNNGRU, TimeGNN）和先进的预处理工具（KTIF）来预测地质时间序列（GNSS, SSH, TG），以应对其非线性、非平稳和不完整的特性。


<details>
  <summary>Details</summary>
Motivation: 地质时间序列（如GNSS、海面高度、潮位计记录）对于监测地表形变和海平面变化至关重要，但其非线性、非平稳和不完整的特性给传统模型带来挑战。准确的预测可以增强预警系统并支持灾害减缓。

Method: 提出并实现了一个名为GTS Forecaster的开源Python包，该包集成了包括核注意力网络（KAN）、基于图神经网络的门控循环单元（GNNGRU）和时间感知图神经网络（TimeGNN）在内的先进深度学习模型，并结合了包括异常值检测和基于强化学习的填补算法（KTIF）在内的预处理工具。

Result: GTS Forecaster支持GNSS、SSH和TG数据集的预测、可视化和评估，并可推广应用于一般时间序列应用。

Conclusion: GTS Forecaster通过结合前沿模型和易于使用的接口，促进了深度学习在地质预测任务中的应用。

Abstract: Geodetic time series -- such as Global Navigation Satellite System (GNSS)
positions, satellite altimetry-derived sea surface height (SSH), and tide gauge
(TG) records -- is essential for monitoring surface deformation and sea level
change. Accurate forecasts of these variables can enhance early warning systems
and support hazard mitigation for earthquakes, landslides, coastal storm surge,
and long-term sea level. However, the nonlinear, non-stationary, and incomplete
nature of such variables presents significant challenges for classic models,
which often fail to capture long-term dependencies and complex spatiotemporal
dynamics. We introduce GTS Forecaster, an open-source Python package for
geodetic time series forecasting. It integrates advanced deep learning models
-- including kernel attention networks (KAN), graph neural network-based gated
recurrent units (GNNGRU), and time-aware graph neural networks (TimeGNN) -- to
effectively model nonlinear spatial-temporal patterns. The package also
provides robust preprocessing tools, including outlier detection and a
reinforcement learning-based gap-filling algorithm, the Kalman-TransFusion
Interpolation Framework (KTIF). GTS Forecaster currently supports forecasting,
visualization, and evaluation of GNSS, SSH, and TG datasets, and is adaptable
to general time series applications. By combining cutting-edge models with an
accessible interface, it facilitates the application of deep learning in
geodetic forecasting tasks.

</details>


### [581] [Early Detection of Branched Broomrape (Phelipanche ramosa) Infestation in Tomato Crops Using Leaf Spectral Analysis and Machine Learning](https://arxiv.org/abs/2509.12074)
*Mohammadreza Narimani,Alireza Pourreza,Ali Moghimi,Parastoo Farajpoor,Hamid Jafarbiglu,Mohsen B. Mesgaran*

Main category: cs.LG

TL;DR: 利用近距离传感和集成机器学习在早期检测寄生杂草分支列当（Phelipanche ramosa）。


<details>
  <summary>Details</summary>
Motivation: 分支列当（Phelipanche ramosa）是一种缺乏叶绿素的寄生杂草，通过从宿主中提取养分来威胁番茄生产，因此需要进行早期检测。

Method: 在加利福尼亚州伍德兰进行了一项田间试验，使用（400-2500 nm）的叶片光谱反射率和集成机器学习（随机森林、XGBoost、具有RBF核的支持向量机和朴素贝叶斯）来跟踪番茄植株在不同生长阶段的生长情况。对光谱数据进行预处理，包括带降噪、1 nm插值、Savitzky-Golay平滑和基于相关性的带缩减。

Result: 在1500 nm和2000 nm的水吸收特征附近观察到明显的类别差异，这与感染植株早期阶段叶片含水量降低一致。在585 GDD时，集成模型达到了89%的准确率，感染植株的召回率为0.86，非感染植株的召回率为0.93。在后期，准确率有所下降（例如，在1568 GDD时为69%），这可能是由于衰老和杂草干扰。

Conclusion: 尽管感染植株数量较少且存在环境混淆因素，但结果表明，近距离传感结合集成学习能够在杂草在冠层中出现症状之前进行及时检测，从而支持靶向干预措施并减少产量损失。

Abstract: Branched broomrape (Phelipanche ramosa) is a chlorophyll-deficient parasitic
weed that threatens tomato production by extracting nutrients from the host. We
investigate early detection using leaf-level spectral reflectance (400-2500 nm)
and ensemble machine learning. In a field experiment in Woodland, California,
we tracked 300 tomato plants across growth stages defined by growing degree
days (GDD). Leaf reflectance was acquired with a portable spectrometer and
preprocessed (band denoising, 1 nm interpolation, Savitzky-Golay smoothing,
correlation-based band reduction). Clear class differences were observed near
1500 nm and 2000 nm water absorption features, consistent with reduced leaf
water content in infected plants at early stages. An ensemble combining Random
Forest, XGBoost, SVM with RBF kernel, and Naive Bayes achieved 89% accuracy at
585 GDD, with recalls of 0.86 (infected) and 0.93 (noninfected). Accuracy
declined at later stages (e.g., 69% at 1568 GDD), likely due to senescence and
weed interference. Despite the small number of infected plants and
environmental confounders, results show that proximal sensing with ensemble
learning enables timely detection of broomrape before canopy symptoms are
visible, supporting targeted interventions and reduced yield losses.

</details>


### [582] [SME-TEAM: Leveraging Trust and Ethics for Secure and Responsible Use of AI and LLMs in SMEs](https://arxiv.org/abs/2509.10594)
*Iqbal H. Sarker,Helge Janicke,Ahmad Mohsin,Leandros Maglaras*

Main category: cs.LG

TL;DR: 该论文提出了一个结构化的多阶段框架，旨在将信任和伦理原则嵌入人工智能（AI）的整个生命周期中，以确保中小型企业（SMEs）安全、负责任地使用AI。


<details>
  <summary>Details</summary>
Motivation: 中小型企业（SMEs）在采用人工智能（AI）和大型语言模型（LLMs）时面临严峻的技术、伦理和信任挑战。

Method: 提出一个围绕数据、算法、人为监督和模型架构四大支柱构建的结构化多阶段框架，以将理论伦理原则与运营实践相结合。

Result: 该框架增强了AI在不同中小型企业应用中的能力。

Conclusion: 该论文提供了一个负责任的AI采纳的结构化路线图，将信任和伦理视为中小型企业韧性、竞争力和可持续创新的催化剂。

Abstract: Artificial Intelligence (AI) and Large Language Models (LLMs) are reshaping
today's business practices, however, their adoption within small and
medium-sized enterprises (SMEs) raises significant technical, ethical and trust
issues. This paper proposes a structured, multi-phased framework designed to
embed trust and ethical principles throughout the AI lifecycle for their secure
and responsible use in SMEs. Structured around four pillars, i.e., Data,
Algorithms, Human oversight, and Model Architecture, the framework bridges
theoretical ethical principles with operational practice, enhancing AI
capabilities in diverse SME applications. Ultimately, this paper offers a
structured roadmap for responsible AI adoption, framing trust and ethics as a
catalyst for resilience, competitiveness, and sustainable innovation in SMEs.

</details>


### [583] [All that structure matches does not glitter](https://arxiv.org/abs/2509.12178)
*Maya M. Martirossyan,Thomas Egg,Philipp Hoellmer,George Karypis,Mark Transtrum,Adrian Roitberg,Mingjie Liu,Richard G. Hennig,Ellad B. Tadmor,Stefano Martiniani*

Main category: cs.LG

TL;DR: 本文审视了晶体结构预测任务中常用数据集和评估指标的局限性，并提出了一系列改进方法，包括数据去重、提出新的数据集划分方式以及引入新的评估指标METRe和cRMSE，旨在为材料生成模型提供更可靠的基准和更准确的评估。


<details>
  <summary>Details</summary>
Motivation: 为了推动无机晶体生成模型的发展，需要可靠的基准和信息丰富的、最小化的数据集来进行有意义的模型评估。

Method: 1. 检查了晶体结构预测任务（给定化学成分预测最可能的结构）的常用数据集和报告的指标。 2. 重点关注三个问题：数据集应包含独特的晶体结构；数据集不应随机分割；基准测试不应不加批判地使用，例如，在不考虑相同构建块表现出的结构多样性的情况下，报告匹配率指标。 3. 提出了一系列修复方法：提供了carbon-24数据集的修订版本（去重、按原子数N分割、仅包含相同结构但具有不同晶胞的版本）；提出了perov-5数据集的新分割方法（确保多晶型物在每个分割子集中分组）；提出了新的模型评估指标METRe和cRMSE。

Result: 1. 发现常用的carbon-24 数据集仅包含约40%的独特结构。 2. 发现perov-5 数据集的多晶型物在随机分割时会分散在不同子集中。 3. 提出了包含去重和按原子数N分割的carbon-24数据集的修订版本，以及只包含相同结构但具有不同晶胞的两个版本。 4. 提出了perov-5数据集的新分割方法。 5. 提出了新的模型评估指标METRe和cRMSE。

Conclusion: 通过数据去重、改进数据集划分和提出新的评估指标，为材料生成模型提供了更可靠的基准和更准确的评估方法，解决了现有基准测试和评估指标中存在的局限性和误导性问题。

Abstract: Generative models for materials, especially inorganic crystals, hold
potential to transform the theoretical prediction of novel compounds and
structures. Advancement in this field depends critically on robust benchmarks
and minimal, information-rich datasets that enable meaningful model evaluation.
This paper critically examines common datasets and reported metrics for a
crystal structure prediction task$\unicode{x2014}$generating the most likely
structures given the chemical composition of a material. We focus on three key
issues: First, materials datasets should contain unique crystal structures; for
example, we show that the widely-utilized carbon-24 dataset only contains
$\approx$40% unique structures. Second, materials datasets should not be split
randomly if polymorphs of many different compositions are numerous, which we
find to be the case for the perov-5 dataset. Third, benchmarks can mislead if
used uncritically, e.g., reporting a match rate metric without considering the
structural variety exhibited by identical building blocks. To address these
oft-overlooked issues, we introduce several fixes. We provide revised versions
of the carbon-24 dataset: one with duplicates removed, one deduplicated and
split by number of atoms $N$, and two containing only identical structures but
with different unit cells. We also propose a new split for the perov-5 dataset
which ensures polymorphs are grouped within each split subset, setting a more
sensible standard for benchmarking model performance. Finally, we present METRe
and cRMSE, new model evaluation metrics that can correct existing issues with
the match rate metric.

</details>


### [584] [pySigLib -- Fast Signature-Based Computations on CPU and GPU](https://arxiv.org/abs/2509.10613)
*Daniil Shmelev,Cristopher Salvi*

Main category: cs.LG

TL;DR: 现有的签名方法在处理大规模时间序列数据时存在性能瓶颈，我们提出了一个名为pySigLib的高性能Python库，它能在CPU和GPU上高效计算签名和签名核，并兼容PyTorch的自动微分。我们还引入了一种新的签名核微分方案，能以更短的时间计算出准确的梯度。


<details>
  <summary>Details</summary>
Motivation: 现有签名方法在处理大规模时间序列数据时存在性能瓶颈，无法满足实际应用需求。

Method: 开发了一个名为pySigLib的高性能Python库，它能在CPU和GPU上高效计算签名和签名核，并兼容PyTorch的自动微分。引入了一种新的签名核微分方案，以提高梯度计算的效率和准确性。

Result: pySigLib能够高效地处理大规模数据集和长序列，并且新的微分方案能显著减少计算梯度所需的时间。

Conclusion: pySigLib为大规模基于签名的方法提供了高效的计算工具，其新的微分方案进一步提升了计算效率。

Abstract: Signature-based methods have recently gained significant traction in machine
learning for sequential data. In particular, signature kernels have emerged as
powerful discriminators and training losses for generative models on
time-series, notably in quantitative finance. However, existing implementations
do not scale to the dataset sizes and sequence lengths encountered in practice.
We present pySigLib, a high-performance Python library offering optimised
implementations of signatures and signature kernels on CPU and GPU, fully
compatible with PyTorch's automatic differentiation. Beyond an efficient
software stack for large-scale signature-based computation, we introduce a
novel differentiation scheme for signature kernels that delivers accurate
gradients at a fraction of the runtime of existing libraries.

</details>


### [585] [Optimal Multimarginal Schrödinger Bridge: Minimum Spanning Tree over Measure-valued Vertices](https://arxiv.org/abs/2509.10626)
*Georgiy A. Bondar,Abhishek Halder*

Main category: cs.LG

TL;DR: 本文提出了一种寻找最优多边际薛定谔桥（MSB）的新方法，该方法通过寻找所有可能的图结构上的最优耦合来解决最优MSB问题。


<details>
  <summary>Details</summary>
Motivation: 在现有的多边际薛定谔桥（MSB）方法中，相关结构是预先确定的，这限制了其应用。本文旨在解决寻找最优MSB的问题，即在所有可能的图结构中寻找最优耦合。

Method: 本文将寻找最优MSB的问题转化为一个在度量值顶点上的最小生成树问题。具体步骤包括：1. 构建一个完全图，其中边权重等于相应双边际SB的最优值与端点熵之和。2. 在该完全加权图上解决标准的最小生成树问题。

Result: 通过数值实验证明了所提出方法的有效性。

Conclusion: 本文提出了一种有效的方法来寻找最优MSB，该方法通过解决最小生成树问题来实现，并得到了数值实验的验证。

Abstract: The Multimarginal Schr\"odinger Bridge (MSB) finds the optimal coupling among
a collection of random vectors with known statistics and a known correlation
structure. In the MSB formulation, this correlation structure is specified
\emph{a priori} as an undirected connected graph with measure-valued vertices.
In this work, we formulate and solve the problem of finding the optimal MSB in
the sense we seek the optimal coupling over all possible graph structures. We
find that computing the optimal MSB amounts to solving the minimum spanning
tree problem over measure-valued vertices. We show that the resulting problem
can be solved in two steps. The first step constructs a complete graph with
edge weight equal to a sum of the optimal value of the corresponding bimarginal
SB and the entropies of the endpoints. The second step solves a standard
minimum spanning tree problem over that complete weighted graph. Numerical
experiments illustrate the proposed solution.

</details>


### [586] [California Wildfire Inventory (CAWFI): An Extensive Dataset for Predictive Techniques based on Artificial Intelligence](https://arxiv.org/abs/2509.11015)
*Rohan Tan Bhowmik,Youn Soo Jung,Juan Aguilera,Mary Prunicki,Kari Nadeau*

Main category: cs.LG

TL;DR: 该论文介绍了一个名为加州野火数据库（CAWFI）的新数据集，该数据集包含了大量的历史野火数据和相关指标，旨在促进野火预测研究和解决方案的发展。


<details>
  <summary>Details</summary>
Motivation: 鉴于气候变化导致野火频发，对环境、基础设施和人类生命造成严重威胁，且现有的人工智能解决方案多侧重于火灾后的检测，本研究旨在通过构建一个全面的数据集来支持高精度的预测模型，以实现野火的预防。

Method: 本研究构建了一个名为加州野火数据库（CAWFI）的数据集，整合了2012年至2018年的加州历史野火数据以及2012年至2022年的各类指标数据，包括气象数据、环境数据以及地质数据。该数据集已被用于训练一个时空人工智能模型。

Result: 使用2012年至2017年的指标数据训练的时空人工智能模型，在预测未来超过300,000英亩的野火方面达到了85.7%的准确率。

Conclusion: CAWFI数据集为野火预测研究和解决方案提供了基础，并有望为其他地区创建类似的数据库树立典范。

Abstract: Due to climate change and the disruption of ecosystems worldwide, wildfires
are increasingly impacting environment, infrastructure, and human lives
globally. Additionally, an exacerbating climate crisis means that these losses
would continue to grow if preventative measures are not implemented. Though
recent advancements in artificial intelligence enable wildfire management
techniques, most deployed solutions focus on detecting wildfires after
ignition. The development of predictive techniques with high accuracy requires
extensive datasets to train machine learning models. This paper presents the
California Wildfire Inventory (CAWFI), a wildfire database of over 37 million
data points for building and training wildfire prediction solutions, thereby
potentially preventing megafires and flash fires by addressing them before they
spark. The dataset compiles daily historical California wildfire data from 2012
to 2018 and indicator data from 2012 to 2022. The indicator data consists of
leading indicators (meteorological data correlating to wildfire-prone
conditions), trailing indicators (environmental data correlating to prior and
early wildfire activity), and geological indicators (vegetation and elevation
data dictating wildfire risk and spread patterns). CAWFI has already
demonstrated success when used to train a spatio-temporal artificial
intelligence model, predicting 85.7% of future wildfires larger than 300,000
acres when trained on 2012-2017 indicator data. This dataset is intended to
enable wildfire prediction research and solutions as well as set a precedent
for future wildfire databases in other regions.

</details>


### [587] [Interpretable neural network system identification method for two families of second-order systems based on characteristic curves](https://arxiv.org/abs/2509.10632)
*Federico J. Gonzalez,Luis P. Lara*

Main category: cs.LG

TL;DR: 提出了一种结合微分方程结构和神经网络灵活性的非线性系统识别框架，通过神经网络建模的特征曲线（CCs）实现系统的模块化和可解释表示，并验证了三种策略（SINDy-CC, Poly-CC, NN-CC）在不同非线性系统中的有效性，特别是NN-CC在复杂非线性系统中的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的非线性系统识别方法在可解释性和灵活性之间存在权衡，需要结合物理约束，而本研究旨在提出一种统一的框架来解决这个问题。

Method: 提出了一种基于特征曲线（CCs）的统一数据驱动框架，其中每条CC由一个单独的神经网络建模，以实现系统方程的模块化和可解释表示。在此框架下，发展了三种识别策略：SINDy-CC（结合SINDy稀疏回归和微分方程结构约束）、Poly-CC（使用高次多项式表示CCs）和NN-CC（使用神经网络表示CCs）。

Result: 所有三种方法都适用于简单的多项式非线性系统（如范德波尔振荡器）。然而，NN-CC在处理具有复杂非线性和不连续性的系统（如粘滑系统）时表现出卓越的性能。

Conclusion: 基于CCs的框架，特别是NN-CC方法，能够在保持模型可解释性的同时捕捉复杂的非线性，适用于具有不连续性和复杂非线性且传统方法难以处理的系统，为非线性系统识别提供了强大的工具。

Abstract: Nonlinear system identification often involves a fundamental trade-off
between interpretability and flexibility, often requiring the incorporation of
physical constraints. We propose a unified data-driven framework that combines
the mathematical structure of the governing differential equations with the
flexibility of neural networks (NNs). At the core of our approach is the
concept of characteristic curves (CCs), which represent individual nonlinear
functions (e.g., friction and restoring components) of the system. Each CC is
modeled by a dedicated NN, enabling a modular and interpretable representation
of the system equation. To demonstrate the versatility of the CC-based
formalism, we introduce three identification strategies: (1) SINDy-CC, which
extends the sparse regression approach of SINDy by incorporating the
mathematical structure of the governing equations as constraints; (2) Poly-CC,
which represents each CC using high-degree polynomials; and (3) NN-CC, which
uses NNs without requiring prior assumptions about basis functions. Our results
show that all three approaches are well-suited for systems with simple
polynomial nonlinearities, such as the van der Pol oscillator. In contrast,
NN-CC demonstrates superior performance in modeling systems with complex
nonlinearities and discontinuities, such as those observed in stick-slip
systems. The key contribution of this work is to demonstrate that the CC-based
framework, particularly the NN-CC approach, can capture complex nonlinearities
while maintaining interpretability through the explicit representation of the
CCs. This balance makes it well-suited for modeling systems with
discontinuities and complex nonlinearities that are challenging to assess using
traditional polynomial or sparse regression methods, providing a powerful tool
for nonlinear system identification.

</details>


### [588] [Accurate and Private Diagnosis of Rare Genetic Syndromes from Facial Images with Federated Deep Learning](https://arxiv.org/abs/2509.10635)
*Ali Burak Ünal,Cem Ata Baykara,Peter Krawitz,Mete Akgün*

Main category: cs.LG

TL;DR: 通过联邦学习框架，在不共享患者图像的情况下，允许多个医院协同训练全局特征提取器，以用于面部畸形症的诊断。


<details>
  <summary>Details</summary>
Motivation: 患者数据在不同机构之间孤立，并且受到严格的隐私法规的限制，这阻碍了基于中心化数据集的面部畸形机器学习模型的进一步发展。

Method: 提出了一种基于跨机构横向联邦学习框架的联邦GestaltMatcher服务，允许医院协同训练全局特征提取器，同时保护患者隐私。通过将患者数据映射到共享的潜在空间，并使用隐私保护的核矩阵计算框架进行综合推理和发现。

Result: 实验表明，联邦服务保留了中心化性能的90%以上，并且能够适应不同数量的机构和异构数据分布。

Conclusion: 所提出的联邦GestaltMatcher服务通过联邦学习解决了数据孤岛和隐私问题，能够有效地进行面部畸形症的诊断和发现，并且易于新参与者加入和贡献。

Abstract: Machine learning has shown promise in facial dysmorphology, where
characteristic facial features provide diagnostic clues for rare genetic
disorders. GestaltMatcher, a leading framework in this field, has demonstrated
clinical utility across multiple studies, but its reliance on centralized
datasets limits further development, as patient data are siloed across
institutions and subject to strict privacy regulations. We introduce a
federated GestaltMatcher service based on a cross-silo horizontal federated
learning framework, which allows hospitals to collaboratively train a global
ensemble feature extractor without sharing patient images. Patient data are
mapped into a shared latent space, and a privacy-preserving kernel matrix
computation framework enables syndrome inference and discovery while
safeguarding confidentiality. New participants can directly benefit from and
contribute to the system by adopting the global feature extractor and kernel
configuration from previous training rounds. Experiments show that the
federated service retains over 90% of centralized performance and remains
robust to both varying silo numbers and heterogeneous data distributions.

</details>


### [589] [Test-Time Warmup for Multimodal Large Language Models](https://arxiv.org/abs/2509.10641)
*Nikita Rajaneesh,Thomas Zollo,Richard Zemel*

Main category: cs.LG

TL;DR: MLLMs 在文本和图像的交叉领域具有强大的推理潜力，但目前尚未充分发挥。为解决 MLLMs 训练数据量不足的问题，我们提出一种测试时预热方法，利用弱监督辅助任务的数据对 MLLM 进行每测试实例的自适应调整，并在 MMMU、VQA-Rad 和 GQA 数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLMs 尽管采用了预训练的组件，但在仅有数千或数百万样本的训练数据下，复杂推理任务的性能仍然较弱。

Method: 提出一种测试时预热（Test-Time Warmup）方法，利用弱监督辅助任务的数据，在推理前对 MLLM 进行实例自适应调整，而不是依赖于大量的标注数据集进行微调。

Result: 在 Llama-Vision-Instruct 模型上，MMMU 数据集相对性能提升 4.03%，VQA-Rad 数据集相对性能提升 5.28%，GQA 数据集相对性能提升 1.63%。

Conclusion: 实验证明，在推理前进行“预热”可以增强 MLLMs 在各种推理任务中的鲁棒性。

Abstract: Multimodal Large Language Models (MLLMs) hold great promise for advanced
reasoning at the intersection of text and images, yet they have not fully
realized this potential. MLLMs typically integrate an LLM, a vision encoder,
and a connector that maps the vision encoder's embeddings into the LLM's text
embedding space. Although each component is pretrained on massive datasets with
billions of samples, the entire multimodal model is typically trained on only
thousands (or a few million) samples, which can result in weak performance on
complex reasoning tasks. To address these shortcomings, instead of relying on
extensive labeled datasets for fine-tuning, we propose a Test-Time Warmup
method that adapts the MLLM per test instance by leveraging data from weakly
supervised auxiliary tasks. With our approach, we observe a relative
performance improvement of 4.03% on MMMU, 5.28% on VQA-Rad, and 1.63% on GQA on
the Llama-Vision-Instruct model. Our method demonstrates that 'warming up'
before inference can enhance MLLMs' robustness across diverse reasoning tasks.

</details>


### [590] [Self-Supervised Goal-Reaching Results in Multi-Agent Cooperation and Exploration](https://arxiv.org/abs/2509.10656)
*Chirayu Nimonkar,Shlok Shah,Catherine Ji,Benjamin Eysenbach*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: For groups of autonomous agents to achieve a particular goal, they must
engage in coordination and long-horizon reasoning. However, designing reward
functions to elicit such behavior is challenging. In this paper, we study how
self-supervised goal-reaching techniques can be leveraged to enable agents to
cooperate. The key idea is that, rather than have agents maximize some scalar
reward, agents aim to maximize the likelihood of visiting a certain goal. This
problem setting enables human users to specify tasks via a single goal state
rather than implementing a complex reward function. While the feedback signal
is quite sparse, we will demonstrate that self-supervised goal-reaching
techniques enable agents to learn from such feedback. On MARL benchmarks, our
proposed method outperforms alternative approaches that have access to the same
sparse reward signal as our method. While our method has no explicit mechanism
for exploration, we observe that self-supervised multi-agent goal-reaching
leads to emergent cooperation and exploration in settings where alternative
approaches never witness a single successful trial.

</details>


### [591] [M4GN: Mesh-based Multi-segment Hierarchical Graph Network for Dynamic Simulations](https://arxiv.org/abs/2509.10659)
*Bo Lei,Victor M. Castillo,Yeping Hu*

Main category: cs.LG

TL;DR: M4GN是一种新的分层图神经网络，通过改进的分割策略和跨层信息桥接，提高了PDE模拟的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于网格的图神经网络（GNNs）在处理大型、长距离网格时存在计算成本高和过平滑的问题。虽然分层GNNs缩短了传播路径，但在构建粗粒度图和保持细粒度精度方面仍面临挑战。

Method: M4GN采用三层、以分割为中心的层级网络。它使用混合分割策略（快速图划分+模态分解特征引导的超像素风格细化）来创建与网格拓扑、几何和物理不连续性一致的连续分割。分割信息由排列不变的聚合器编码，然后通过微观层面GNN（捕捉局部动态）和宏观层面Transformer（跨分割进行推理）进行信息桥接。

Result: M4GN在多个基准数据集上的评估显示，与现有技术相比，其预测精度提高了56%，推理速度提高了22%。

Conclusion: M4GN成功地在准确性和效率之间取得了平衡，克服了现有分层GNNs在构建粗粒度图和保持细粒度精度方面的挑战。

Abstract: Mesh-based graph neural networks (GNNs) have become effective surrogates for
PDE simulations, yet their deep message passing incurs high cost and
over-smoothing on large, long-range meshes; hierarchical GNNs shorten
propagation paths but still face two key obstacles: (i) building coarse graphs
that respect mesh topology, geometry, and physical discontinuities, and (ii)
maintaining fine-scale accuracy without sacrificing the speed gained from
coarsening. We tackle these challenges with M4GN, a three-tier, segment-centric
hierarchical network. M4GN begins with a hybrid segmentation strategy that
pairs a fast graph partitioner with a superpixel-style refinement guided by
modal-decomposition features, producing contiguous segments of dynamically
consistent nodes. These segments are encoded by a permutation-invariant
aggregator, avoiding the order sensitivity and quadratic cost of aggregation
approaches used in prior works. The resulting information bridges a micro-level
GNN, which captures local dynamics, and a macro-level transformer that reasons
efficiently across segments, achieving a principled balance between accuracy
and efficiency. Evaluated on multiple representative benchmark datasets, M4GN
improves prediction accuracy by up to 56% while achieving up to 22% faster
inference than state-of-the-art baselines.

</details>


### [592] [Least-Ambiguous Multi-Label Classifier](https://arxiv.org/abs/2509.10689)
*Misgina Tsighe Hagos,Claes Lundström*

Main category: cs.LG

TL;DR: 本研究提出了一种基于保形预测的方法来解决单正例多标签学习（SPMLL）问题，该问题在训练时只有一个正标签，但测试时需要识别所有相关标签。


<details>
  <summary>Details</summary>
Motivation: 收集完整的标签注释成本高昂且耗时，许多数据集中每个训练实例只有一个正标签，但存在多个相关标签，这种单正例多标签学习（SPMLL）设置带来了严峻的挑战。

Method: 提出了一种模型无关的方法，利用保形预测生成校准的集合值输出，从而在测试时实现可靠的多标签预测。

Result: 在12个基准数据集上进行了评估，结果显示该方法在预测性能上优于现有基线方法，并具有实际应用价值。

Conclusion: 所提出的方法能够弥合单标签训练和多标签评估之间的监督差距，而无需依赖标签分布假设，并能为SPMLL问题提供可靠的预测。

Abstract: Multi-label learning often requires identifying all relevant labels for
training instances, but collecting full label annotations is costly and
labor-intensive. In many datasets, only a single positive label is annotated
per training instance, despite the presence of multiple relevant labels. This
setting, known as single-positive multi-label learning (SPMLL), presents a
significant challenge due to its extreme form of partial supervision. We
propose a model-agnostic approach to SPMLL that draws on conformal prediction
to produce calibrated set-valued outputs, enabling reliable multi-label
predictions at test time. Our method bridges the supervision gap between
single-label training and multi-label evaluation without relying on label
distribution assumptions. We evaluate our approach on 12 benchmark datasets,
demonstrating consistent improvements over existing baselines and practical
applicability.

</details>


### [593] [Learning Concave Bid Shading Strategies in Online Auctions via Measure-valued Proximal Optimization](https://arxiv.org/abs/2509.10693)
*Iman Nodozi,Djordje Gligorijevic,Abhishek Halder*

Main category: cs.LG

TL;DR: 本论文提出了一种用于第一价格拍卖的竞价策略，将其建模为度量值优化问题，并基于上下文（如发布商/用户属性）调整竞价分布，以最大化预期剩余收益。


<details>
  <summary>Details</summary>
Motivation: 在第一价格拍卖中，竞价者通常会进行竞价遮蔽（bid shading）以避免支付过高的价格。然而，传统的竞价遮蔽策略可能无法充分利用拍卖环境中的上下文信息。本研究旨在提出一种能够根据上下文动态调整竞价遮蔽策略的方法，以优化竞价者的预期剩余收益。

Method: 本研究将竞价遮蔽策略形式化为一个度量值优化问题。具体地，他们考虑了一种标准的参数化竞价遮蔽形式，并将问题构建为联合分布上的凸优化问题。在每次拍卖后，利用基于数据的能量函数，通过带正则化的 Wasserstein-proximal 更新来调整竞价参数的分布。该能量函数能够根据上下文信息（如域名、广告位类型、设备或位置）进行条件化。该方法旨在使竞价分布更倾向于那些预期剩余收益更高的值，即赢得概率和价值差都较大的那些值。最后，证明了该度量值凸优化问题存在一个闭式解，并通过数值例子进行了说明。

Result: 该研究提出的度量值优化框架能够根据上下文信息（如发布商/用户属性）动态调整竞价遮蔽策略。通过使用带正则化的 Wasserstein-proximal 更新和数据驱动的能量函数，算法能够将竞价分布的权重集中在预期剩余收益更高的竞价上。研究表明，该优化问题存在闭式解，并通过数值示例验证了方法的有效性。

Conclusion: 本研究提出了一种新颖的竞价遮蔽策略，将其形式化为度量值优化问题，并利用上下文信息实现了竞价分布的自适应调整。该方法通过优化预期剩余收益，有望在第一价格拍卖中提高竞价者的表现。此外，理论分析证明了该方法的闭式解性质，并通过数值实验展示了其实用性。

Abstract: This work proposes a bid shading strategy for first-price auctions as a
measure-valued optimization problem. We consider a standard parametric form for
bid shading and formulate the problem as convex optimization over the joint
distribution of shading parameters. After each auction, the shading parameter
distribution is adapted via a regularized Wasserstein-proximal update with a
data-driven energy functional. This energy functional is conditional on the
context, i.e., on publisher/user attributes such as domain, ad slot type,
device, or location. The proposed algorithm encourages the bid distribution to
place more weight on values with higher expected surplus, i.e., where the win
probability and the value gap are both large. We show that the resulting
measure-valued convex optimization problem admits a closed form solution. A
numerical example illustrates the proposed method.

</details>


### [594] [Verifying Computational Graphs in Production-Grade Distributed Machine Learning Frameworks](https://arxiv.org/abs/2509.10694)
*Kahfi S. Zulkifli,Wenbo Qian,Shaowei Zhu,Yuan Zhou,Zhen Zhang,Chang Lou*

Main category: cs.LG

TL;DR: Scalify框架通过验证计算图的语义等价性来检测机器学习模型中的静默错误，并已在实际生产中发现多个 Bug。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习框架在支持大型模型的同时引入了复杂性，可能导致静默错误，影响模型性能，而现有解决方案成本高昂或效果不佳。

Method: Scalify框架使用等价性饱和和Datalog风格的推理来验证计算图的语义等价性，并采用图分区、并行重写、层记忆化、重写模板复用、关系推理和符号双射推理等技术来提高可扩展性，最终将差异定位到具体的代码位置，提供调试指导。

Result: Scalify能够在几分钟内验证Llama-3.1-405B这样的大型模型，并在亚马逊的生产机器学习框架中发现了五个未知的 Bug。

Conclusion: Scalify是一个轻量级框架，能够有效地检测大型机器学习模型中的静默错误，并提供可行的调试信息，已成功应用于实际生产环境。

Abstract: Modern machine learning frameworks support very large models by incorporating
parallelism and optimization techniques. Yet, these very techniques add new
layers of complexity, introducing silent errors that severely degrade model
performance. Existing solutions are either ad hoc or too costly for production.
  We present Scalify, a lightweight framework that exposes silent errors by
verifying semantic equivalence of computational graphs using equality
saturation and Datalog-style reasoning. To scale, Scalify partitions graphs
with parallel rewriting and layer memoization, reuses rewrite templates, and
augments equality saturation with relational reasoning and symbolic bijection
inference. It further localizes discrepancies to precise code sites, turning
verification results into actionable debugging guidance. Scalify verifies
models as large as Llama-3.1-405B within minutes on a commodity machine and
exposed five unknown bugs in Amazon production machine learning frameworks.

</details>


### [595] [Kalman Bayesian Transformer](https://arxiv.org/abs/2509.10695)
*Haoming Jing,Oren Wright,José M. F. Moura,Yorie Nakahira*

Main category: cs.LG

TL;DR: Sequential fine-tuning of transformers can be challenging due to shifting data distributions and the need to balance new and old information, especially in latency-critical situations requiring uncertainty quantification. This paper proposes a Bayesian approach using Kalman Bayesian Neural Networks and Taylor approximations to handle sequential fine-tuning as a posterior inference problem, effectively balancing prior knowledge with new data based on uncertainty. The method is shown to be effective in simulations for sequential adaptation of decision transformers facing distribution shifts and limited memory.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of sequential fine-tuning of transformers when new data arrives sequentially, particularly with shifting distributions. This includes the need to stabilize training with limited data, balance new information with previously learned knowledge, and incorporate uncertainty quantification in latency-critical environments.

Method: The proposed method frames sequential fine-tuning as a posterior inference problem within a Bayesian framework. It utilizes closed-form moment propagation of random variables, Kalman Bayesian Neural Networks, and Taylor approximations of the moments of softmax functions. The approach explicitly considers pre-trained models as priors and adaptively balances them with new information based on quantified uncertainty.

Result: The effectiveness of the proposed method is demonstrated through numerical simulations. These simulations involve the sequential adaptation of a decision transformer to tasks that exhibit distribution shifts and operate under limited memory resources.

Conclusion: The paper demonstrates a novel Bayesian approach for sequential fine-tuning of transformers that achieves robust and data-efficient learning by explicitly accounting for prior knowledge and adaptively balancing it with new information based on quantified uncertainty. This method is particularly useful in scenarios with sequential data, distribution shifts, and latency constraints.

Abstract: Sequential fine-tuning of transformers is useful when new data arrive
sequentially, especially with shifting distributions. Unlike batch learning,
sequential learning demands that training be stabilized despite a small amount
of data by balancing new information and previously learned knowledge in the
pre-trained models. This challenge is further complicated when training is to
be completed in latency-critical environments and learning must additionally
quantify and be mediated by uncertainty. Motivated by these challenges, we
propose a novel method that frames sequential fine-tuning as a posterior
inference problem within a Bayesian framework. Our approach integrates
closed-form moment propagation of random variables, Kalman Bayesian Neural
Networks, and Taylor approximations of the moments of softmax functions. By
explicitly accounting for pre-trained models as priors and adaptively balancing
them against new information based on quantified uncertainty, our method
achieves robust and data-efficient sequential learning. The effectiveness of
our method is demonstrated through numerical simulations involving sequential
adaptation of a decision transformer to tasks characterized by distribution
shifts and limited memory resources.

</details>


### [596] [CrunchLLM: Multitask LLMs for Structured Business Reasoning and Outcome Prediction](https://arxiv.org/abs/2509.10698)
*Rabeya Tus Sadia,Qiang Cheng*

Main category: cs.LG

TL;DR: CrunchLLM是一个结合了结构化和非结构化数据的领域适应大型语言模型框架，用于预测初创公司的成功，准确率超过80%，并提供可解释的预测。 


<details>
  <summary>Details</summary>
Motivation: 预测初创公司的成功（通过被收购或IPO退出）是一个关键问题，但利用Crunchbase等数据集中的异构数据（结构化和非结构化）进行预测仍然是一个挑战。 

Method: CrunchLLM通过结合结构化公司属性和非结构化文本叙述，并应用参数高效的微调策略和提示优化，对基础模型进行专业化处理，以适应创业数据。 

Result: CrunchLLM在Crunchbase初创公司成功预测任务上实现了超过80%的准确率，显著优于传统的分类器和基线LLM。此外，该模型还能提供可解释的推理路径。 

Conclusion: 将大型语言模型通过领域感知微调和结构化-非结构化数据融合进行适应，可以推进对创业结果的预测建模。CrunchLLM提供了一个方法框架和实用工具，用于风险投资和创新政策中的数据驱动决策。

Abstract: Predicting the success of start-up companies, defined as achieving an exit
through acquisition or IPO, is a critical problem in entrepreneurship and
innovation research. Datasets such as Crunchbase provide both structured
information (e.g., funding rounds, industries, investor networks) and
unstructured text (e.g., company descriptions), but effectively leveraging this
heterogeneous data for prediction remains challenging. Traditional machine
learning approaches often rely only on structured features and achieve moderate
accuracy, while large language models (LLMs) offer rich reasoning abilities but
struggle to adapt directly to domain-specific business data. We present
\textbf{CrunchLLM}, a domain-adapted LLM framework for startup success
prediction. CrunchLLM integrates structured company attributes with
unstructured textual narratives and applies parameter-efficient fine-tuning
strategies alongside prompt optimization to specialize foundation models for
entrepreneurship data. Our approach achieves accuracy exceeding 80\% on
Crunchbase startup success prediction, significantly outperforming traditional
classifiers and baseline LLMs. Beyond predictive performance, CrunchLLM
provides interpretable reasoning traces that justify its predictions, enhancing
transparency and trustworthiness for financial and policy decision makers. This
work demonstrates how adapting LLMs with domain-aware fine-tuning and
structured--unstructured data fusion can advance predictive modeling of
entrepreneurial outcomes. CrunchLLM contributes a methodological framework and
a practical tool for data-driven decision making in venture capital and
innovation policy.

</details>


### [597] [Using LLMs for Late Multimodal Sensor Fusion for Activity Recognition](https://arxiv.org/abs/2509.10729)
*Ilker Demirel,Karan Thakkar,Benjamin Elizalde,Miquel Espi Marques,Shirley Ren,Jaya Narain*

Main category: cs.LG

TL;DR: LLM可用于融合传感器数据流（如音频和运动时间序列）以进行活动分类，在零样本和少样本设置下表现优于随机水平。


<details>
  <summary>Details</summary>
Motivation: 传感器数据流包含有价值的活动和上下文信息，但整合这些信息可能具有挑战性。LLM可用于对来自音频和运动时间序列数据的活动进行后期融合分类。

Method: 使用LLM对来自Ego4D数据集的音频和运动时间序列数据进行零样本和少样本活动分类。

Result: LLM在12类零样本和少样本分类任务中实现了显著高于随机水平的F1分数，且无需任务特定训练。

Conclusion: 基于LLM的融合可以通过提供一种无需大量标注数据即可实现多模态时序应用的方法，为传感器数据分析带来新的可能性，并简化模型的部署。

Abstract: Sensor data streams provide valuable information around activities and
context for downstream applications, though integrating complementary
information can be challenging. We show that large language models (LLMs) can
be used for late fusion for activity classification from audio and motion time
series data. We curated a subset of data for diverse activity recognition
across contexts (e.g., household activities, sports) from the Ego4D dataset.
Evaluated LLMs achieved 12-class zero- and one-shot classification F1-scores
significantly above chance, with no task-specific training. Zero-shot
classification via LLM-based fusion from modality-specific models can enable
multimodal temporal applications where there is limited aligned training data
for learning a shared embedding space. Additionally, LLM-based fusion can
enable model deploying without requiring additional memory and computation for
targeted application-specific multimodal models.

</details>


### [598] [Matched-Pair Experimental Design with Active Learning](https://arxiv.org/abs/2509.10742)
*Weizhi Li,Gautam Dasarathy,Visar Berisha*

Main category: cs.LG

TL;DR: 该研究提出了一种匹配对实验设计，通过主动学习识别和靶向高治疗效果区域，以降低实验成本并确保覆盖整个高效果区域。


<details>
  <summary>Details</summary>
Motivation: 当总体效应值较小时，研究重点自然转移到识别和靶向干预效果最显著的高治疗效果区域。

Method: 提出了一种匹配对实验设计，将高治疗效果区域的识别视为一个分类问题，并提出了一个为匹配对设计量身定制的主动学习框架。

Result: 所提出的设计通过理论分析和实际场景中的实验证明了其效率和优势，能够降低实验成本并确保识别出的区域能够覆盖整个高治疗效果区域。

Conclusion: 该研究提出的主动学习匹配对实验设计在降低实验成本和确保识别效果区域的完整性方面具有显著优势。

Abstract: Matched-pair experimental designs aim to detect treatment effects by pairing
participants and comparing within-pair outcome differences. In many situations,
the overall effect size is small across the entire population. Then, the focus
naturally shifts to identifying and targeting high treatment-effect regions
where the intervention is most effective. This paper proposes a matched-pair
experimental design that sequentially and actively enrolls patients in high
treatment-effect regions. Importantly, we frame the identification of the
target region as a classification problem and propose an active learning
framework tailored to matched-pair designs. The proposed design not only
reduces the experimental cost of detecting treatment efficacy, but also ensures
that the identified regions enclose the entire high-treatment-effect regions.
Our theoretical analysis of the framework's label complexity, along with
experiments in practical scenarios, demonstrates the efficiency and advantages
of the approach.

</details>


### [599] [HalluField: Detecting LLM Hallucinations via Field-Theoretic Modeling](https://arxiv.org/abs/2509.10753)
*Minh Vu,Brian K. Tran,Syed A. Shah,Geigh Zollicoffer,Nhat Hoang-Xuan,Manish Bhattarai*

Main category: cs.LG

TL;DR: HalluField是一种基于物理学的LLM幻觉检测新方法，通过分析模型输出的能量和熵来识别不稳定的响应，在多种模型和数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs（大语言模型）存在幻觉问题，限制了其在高风险应用中的部署，因此需要一种通用的幻觉检测方法。

Method: HalluField提出了一种新颖的场论方法，受热力学启发，将LLM响应建模为具有能量和熵的离散路径集合，通过分析温度和似然变化下的能量和熵分布来量化响应的语义稳定性，并识别不稳定的行为。

Result: HalluField在计算效率和实用性方面表现出色，可以直接在模型输出的logits上操作，无需微调或辅助神经网络。该方法基于第一类热力学定律的物理学解释，并在跨模型和数据集的幻觉检测中取得了最先进的性能。

Conclusion: HalluField提供了一种基于物理学原理的有效且高效的LLM幻觉检测方法，通过分析响应的能量和熵动态来识别幻觉，并在实验中证明了其卓越的性能。

Abstract: Large Language Models (LLMs) exhibit impressive reasoning and
question-answering capabilities. However, they often produce inaccurate or
unreliable content known as hallucinations. This unreliability significantly
limits their deployment in high-stakes applications. Thus, there is a growing
need for a general-purpose method to detect hallucinations in LLMs. In this
work, we introduce HalluField, a novel field-theoretic approach for
hallucination detection based on a parametrized variational principle and
thermodynamics. Inspired by thermodynamics, HalluField models an LLM's response
to a given query and temperature setting as a collection of discrete likelihood
token paths, each associated with a corresponding energy and entropy. By
analyzing how energy and entropy distributions vary across token paths under
changes in temperature and likelihood, HalluField quantifies the semantic
stability of a response. Hallucinations are then detected by identifying
unstable or erratic behavior in this energy landscape. HalluField is
computationally efficient and highly practical: it operates directly on the
model's output logits without requiring fine-tuning or auxiliary neural
networks. Notably, the method is grounded in a principled physical
interpretation, drawing analogies to the first law of thermodynamics.
Remarkably, by modeling LLM behavior through this physical lens, HalluField
achieves state-of-the-art hallucination detection performance across models and
datasets.

</details>


### [600] [Contextual Budget Bandit for Food Rescue Volunteer Engagement](https://arxiv.org/abs/2509.10777)
*Ariana Tang,Naveen Raman,Fei Fang,Zheyuan Ryan Shi*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Contextual Budget Bandit的新算法，以解决食物救援平台在维持志愿者参与和最大化救援食物量方面面临的挑战，并减少地理不平等。


<details>
  <summary>Details</summary>
Motivation: 现有的食物救援平台算法未能解决志愿者参与度和地理不平等问题，导致部分社区系统性处于不利地位。

Method: 提出了一种名为Contextual Budget Bandit的新算法，该算法将上下文相关的预算分配纳入了restless multi-armed bandits模型。此外，还设计了一种名为Mitosis的算法，以确保最优预算分配。

Result: 所提出的算法在合成和真实世界的食物救援数据集上均优于基线算法，并能实现地理公平性。

Conclusion: Contextual Budget Bandit算法能够有效地解决食物救援平台面临的挑战，同时促进地理公平性。

Abstract: Volunteer-based food rescue platforms tackle food waste by matching surplus
food to communities in need. These platforms face the dual problem of
maintaining volunteer engagement and maximizing the food rescued. Existing
algorithms to improve volunteer engagement exacerbate geographical disparities,
leaving some communities systematically disadvantaged. We address this issue by
proposing Contextual Budget Bandit. Contextual Budget Bandit incorporates
context-dependent budget allocation in restless multi-armed bandits, a model of
decision-making which allows for stateful arms. By doing so, we can allocate
higher budgets to communities with lower match rates, thereby alleviating
geographical disparities. To tackle this problem, we develop an empirically
fast heuristic algorithm. Because the heuristic algorithm can achieve a poor
approximation when active volunteers are scarce, we design the Mitosis
algorithm, which is guaranteed to compute the optimal budget allocation.
Empirically, we demonstrate that our algorithms outperform baselines on both
synthetic and real-world food rescue datasets, and show how our algorithm
achieves geographical fairness in food rescue.

</details>


### [601] [GoldenTransformer: A Modular Fault Injection Framework for Transformer Robustness Research](https://arxiv.org/abs/2509.10790)
*Luke Howard*

Main category: cs.LG

TL;DR: GoldenTransformer是一个用于评估大型语言模型对硬件故障的弹性的容错框架。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型被广泛应用，但它们在故障条件下的鲁棒性研究不足。

Method: GoldenTransformer是一个模块化、可扩展的容错注入框架，用于在预训练的Transformer模型中注入权重损坏、激活注入和注意力级别扰动等故障。该框架基于PyTorch和HuggingFace Transformers构建，并专注于解决大型Transformer架构的独特挑战。

Result: 通过在分类和生成任务上进行示例实验，展示了GoldenTransformer在注入故障方面的能力。

Conclusion: GoldenTransformer为研究人员和实践者提供了一个有价值的工具，用于模型鲁棒性分析和指导实际应用中可靠的系统设计。

Abstract: Transformers have become the foundation for a wide range of
state--of--the--art models across natural language processing, computer vision,
and other machine learning domains. Despite their widespread deployment, the
robustness of these models under fault conditions remains underexplored. We
present GoldenTransformer, a modular and extensible fault injection framework
designed to evaluate the resiliency of Large Language Models to induced
hardware faults. GoldenTransformer offers a unified Python-based platform for
injecting diverse classes of faults--such as weight corruption, activation
injections, and attention--level disruptions--into pretrained
transformer--based models. Inspired by the GoldenEye simulator for DNNs, our
framework focuses on the unique challenges of working with large transformer
architectures, including considerations such as structural complexity, latent
dependencies, and nonuniform layer definitions. GoldenTransformer is built atop
PyTorch and HuggingFace Transformers, and it supports experiment
reproducibility, metric logging, and visualization out of the box. We detail
the technical design and use of GoldenTransformer and demonstrate through
several example experiments on classification and generation tasks. By enabling
controlled injection of faults at multiple logical and structural points in a
transformer, GoldenTransformer offers researchers and practitioners a valuable
tool for model robustness analysis and for guiding dependable system design in
real-world LLM applications.

</details>


### [602] [Rethinking Sparse Autoencoders: Select-and-Project for Fairness and Control from Encoder Features Alone](https://arxiv.org/abs/2509.10809)
*Antonio Bărbălau,Cristian Daniel Păduraru,Teodor Poncu,Alexandru Tifrea,Elena Burceanu*

Main category: cs.LG

TL;DR: SAE的去偏方法通常假设特征表示存在于解码器权重中，但本文提出了一个基于编码器的替代方法，通过正交化输入嵌入和编码器权重，并在去偏过程中使用编码器权重插值来保持性能，名为S&P TopK框架，其在公平性指标上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于SAE的去偏方法假设特征表示存在于解码器权重中，本文旨在挑战这一假设，提出一种新的基于编码器的表示去偏方法。

Method: 提出一种新颖的SAE去偏方法，该方法通过正交化输入嵌入对抗编码器权重，并使用编码器权重插值来在去偏过程中保持性能。该框架被称为S&P TopK。

Result: S&P TopK框架在公平性指标上超越传统SAE方法最高可达3.2倍，并使测试时VLM去偏达到最先进水平，提升最高可达1.8倍，同时保持下游性能。

Conclusion: 本文提出的基于编码器的SAE去偏方法（S&P TopK）在公平性方面取得了显著改进，并能有效保持模型性能。

Abstract: Sparse Autoencoders (SAEs) have proven valuable due to their ability to
provide interpretable and steerable representations. Current debiasing methods
based on SAEs manipulate these sparse activations presuming that feature
representations are housed within decoder weights. We challenge this
fundamental assumption and introduce an encoder-focused alternative for
representation debiasing, contributing three key findings: (i) we highlight an
unconventional SAE feature selection strategy, (ii) we propose a novel SAE
debiasing methodology that orthogonalizes input embeddings against encoder
weights, and (iii) we establish a performance-preserving mechanism during
debiasing through encoder weight interpolation. Our Selection and Projection
framework, termed S\&P TopK, surpasses conventional SAE usage in fairness
metrics by a factor of up to 3.2 and advances state-of-the-art test-time VLM
debiasing results by a factor of up to 1.8 while maintaining downstream
performance.

</details>


### [603] [FACTORS: Factorial Approximation for Complementary Two-factor Optimization with Risk-aware Scoring](https://arxiv.org/abs/2509.10825)
*Dongseok Kim,Wonjun Jeong,Gisung Oh*

Main category: cs.LG

TL;DR: FACTORS框架结合了实验设计和Shapley分解，以解决对训练因子组合敏感的性能和稳定性问题。该方法能够一致地估计主效应和二阶交互效应，并将其集成到风险调整的目标函数中，从而在固定预算下可靠地选择配置。FACTORS通过条件均值和Shapley贡献重构的最小二乘法实现效应估计，并包含标准化、偏差校正和不确定性量化，确保跨异构因子空间和设计的可比性。该框架还提供了理论分析（误差分解、样本复杂度、最优性差距上限）和可视化解释（效应和交互的可视化地图），以指导调整和改进。在各种数据集和设计条件下，FACTORS提高了排名保存、最优配置识别能力，降低了决策风险，并在预算约束下实现了稳定的性能提升和可解释的理由。


<details>
  <summary>Details</summary>
Motivation: 为了解决对训练因子组合敏感的性能和稳定性问题，需要一种能够处理效应估计、不确定性、成本和预算约束的框架。

Method: FACTORS框架结合了实验设计和Shapley分解。它通过条件均值和最小二乘法估计主效应和二阶交互效应，并将这些效应集成到一个风险调整的目标函数中。该框架还包括标准化、偏差校正、不确定性量化和一个搜索例程。理论方面，提供了误差分解、样本复杂度分析和最优性差距上限。解释方面，通过地图形式总结主效应和交互效应。

Result: FACTORS框架在各种数据集和设计条件下，提高了排名保存和最优配置的识别能力，降低了决策风险，并在预算约束下提供了稳定的性能提升和可解释的理由。

Conclusion: FACTORS框架能够有效解决性能和稳定性问题，提供可靠的配置选择，并在预算约束下实现可解释的性能提升。

Abstract: We propose FACTORS, a framework that combines design of experiments with
Shapley decomposition to address performance and stability issues that are
sensitive to combinations of training factors. Our approach consistently
estimates main effects and two-factor interactions, then integrates them into a
risk-adjusted objective function that jointly accounts for uncertainty and
cost, enabling reliable selection of configurations under a fixed budget.
Effect estimation is implemented through two complementary paths: a plug-in
path based on conditional means, and a least-squares path that reconstructs
Shapley contributions from samples. These paths are designed to work
complementarily even when design density and bias levels differ. By
incorporating standardization of estimates, bias correction, and uncertainty
quantification, our procedure ensures comparability across heterogeneous factor
spaces and designs, while a lightweight search routine yields configurations
within practical time even for large factor spaces. On the theoretical side, we
provide error decompositions, sample complexity analysis, and upper bounds on
optimality gaps. On the interpretive side, we summarize main effects and
interactions in map form, highlighting adjustment priorities and safe
improvement pathways. Across diverse datasets and design conditions, our
approach improves rank preservation and optimal configuration identification,
reduces decision-making risks, and offers a tuning foundation that delivers
interpretable justification alongside stable performance gains even under
budget constraints.

</details>


### [604] [Neurosymbolic AI Transfer Learning Improves Network Intrusion Detection](https://arxiv.org/abs/2509.10850)
*Huynh T. T. Tran,Jacob Sander,Achraf Cohen,Brian Jalaian,Nathaniel D. Bastian*

Main category: cs.LG

TL;DR: 本论文提出了一种利用迁移学习和不确定性量化的新颖的神经符号AI框架，用于网络入侵检测系统，并证明其在处理网络安全任务时优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 目前迁移学习在网络安全领域的应用研究不足，而网络入侵检测系统在网络安全中至关重要。

Method: 提出了一种新颖的神经符号AI框架，该框架结合了迁移学习和不确定性量化，用于网络入侵检测。

Result: 在大型、结构良好数据集上训练的迁移学习模型，其性能优于仅基于小型数据集训练的神经网络模型。

Conclusion: 迁移学习在网络入侵检测中展现出巨大潜力，预示着网络安全解决方案的新方向。

Abstract: Transfer learning is commonly utilized in various fields such as computer
vision, natural language processing, and medical imaging due to its impressive
capability to address subtasks and work with different datasets. However, its
application in cybersecurity has not been thoroughly explored. In this paper,
we present an innovative neurosymbolic AI framework designed for network
intrusion detection systems, which play a crucial role in combating malicious
activities in cybersecurity. Our framework leverages transfer learning and
uncertainty quantification. The findings indicate that transfer learning
models, trained on large and well-structured datasets, outperform neural-based
models that rely on smaller datasets, paving the way for a new era in
cybersecurity solutions.

</details>


### [605] [CogGNN: Cognitive Graph Neural Networks in Generative Connectomics](https://arxiv.org/abs/2509.10864)
*Mayssa Soussia,Yijun Lin,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: CogGNN是一个新颖的认知感知生成模型，通过整合视觉输入和认知特征来生成具有结构和认知意义的大脑网络。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络（GNNs）的方法主要关注大脑网络的结构和拓扑属性，忽略了认知特征，限制了其在网络神经科学中的应用。

Method: 提出首个认知感知生成模型CogGNN，通过引入基于视觉记忆的损失函数，使GNN具备认知能力（如视觉记忆），以生成能够保留认知特征的大脑网络。CogGNN是为整合视觉输入而设计的特定变体，用于学习连接性大脑模板（CBTs）。

Result: CogGNN生成的大脑连接模板（CBTs）不仅在结构上，而且在认知上也具有意义。实验证明CogGNN优于现有最先进的方法。

Conclusion: CogGNN为基于认知的大脑网络建模奠定了基础，解决了现有方法忽略认知特征的局限性。

Abstract: Generative learning has advanced network neuroscience, enabling tasks like
graph super-resolution, temporal graph prediction, and multimodal brain graph
fusion. However, current methods, mainly based on graph neural networks (GNNs),
focus solely on structural and topological properties, neglecting cognitive
traits. To address this, we introduce the first cognified generative model,
CogGNN, which endows GNNs with cognitive capabilities (e.g., visual memory) to
generate brain networks that preserve cognitive features. While broadly
applicable, we present CogGNN, a specific variant designed to integrate visual
input, a key factor in brain functions like pattern recognition and memory
recall. As a proof of concept, we use our model to learn connectional brain
templates (CBTs), population-level fingerprints from multi-view brain networks.
Unlike prior work that overlooks cognitive properties, CogGNN generates CBTs
that are both cognitively and structurally meaningful. Our contributions are:
(i) a novel cognition-aware generative model with a visual-memory-based loss;
(ii) a CBT-learning framework with a co-optimization strategy to yield
well-centered, discriminative, cognitively enhanced templates. Extensive
experiments show that CogGNN outperforms state-of-the-art methods, establishing
a strong foundation for cognitively grounded brain network modeling.

</details>


### [606] [GTHNA: Local-global Graph Transformer with Memory Reconstruction for Holistic Node Anomaly Evaluation](https://arxiv.org/abs/2509.10869)
*Mingkang Li,Xuexiong Luo,Yue Zhang,Yaoyang Li,Fu Lin*

Main category: cs.LG

TL;DR: 本篇论文提出了一种新颖的图结构数据异常检测框架，通过整合局部-全局Transformer编码器、内存引导重构机制和多尺度表示匹配策略，克服了现有方法的局限性，并在多个数据集上取得了优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法（如图卷积网络和图重构方法）存在平滑过度和易受异常节点干扰的问题，导致检测不准确。

Method: 提出了一种整合了局部-全局Transformer编码器、内存引导重构机制和多尺度表示匹配策略的异常评估框架，以捕捉局部和全局结构依赖性，抑制异常节点影响，并从多粒度评估异常。

Result: 通过结合重构误差和内存匹配信号计算异常分数，并通过在七个基准数据集上的广泛实验证明，该方法性能优于现有最先进方法。

Conclusion: 该框架为图结构数据的异常检测提供了一个全面且可泛化的解决方案。

Abstract: Anomaly detection in graph-structured data is an inherently challenging
problem, as it requires the identification of rare nodes that deviate from the
majority in both their structural and behavioral characteristics. Existing
methods, such as those based on graph convolutional networks (GCNs), often
suffer from over-smoothing, which causes the learned node representations to
become indistinguishable. Furthermore, graph reconstruction-based approaches
are vulnerable to anomalous node interference during the reconstruction
process, leading to inaccurate anomaly detection. In this work, we propose a
novel and holistic anomaly evaluation framework that integrates three key
components: a local-global Transformer encoder, a memory-guided reconstruction
mechanism, and a multi-scale representation matching strategy. These components
work synergistically to enhance the model's ability to capture both local and
global structural dependencies, suppress the influence of anomalous nodes, and
assess anomalies from multiple levels of granularity. Anomaly scores are
computed by combining reconstruction errors and memory matching signals,
resulting in a more robust evaluation. Extensive experiments on seven benchmark
datasets demonstrate that our method outperforms existing state-of-the-art
approaches, offering a comprehensive and generalizable solution for anomaly
detection across various graph domains.

</details>


### [607] [Optimal message passing for molecular prediction is simple, attentive and spatial](https://arxiv.org/abs/2509.10871)
*Alma C. Castaneda-Leautaud,Rommie E. Amaro*

Main category: cs.LG

TL;DR: 通过简化消息传递和使用多方面分子图描述符，可以提高消息传递神经网络（MPNN）在分子性质预测方面的性能。我们的模型在各种数据集上达到了最先进的性能，优于更复杂的模型。模型采用双向消息传递和注意力机制，结合简洁的消息制定，证明了相对简单的模型可以产生更高的类别可分性。此外，我们发现 2D 分子图结合合适的 3D 描述符足以保持预测性能，同时降低计算成本超过 50%。


<details>
  <summary>Details</summary>
Motivation: 提高消息传递神经网络（MPNN）在分子性质预测中的性能，探索简化消息传递机制和利用多方面分子图描述符的方法。

Method: 设计了采用双向消息传递和注意力机制的模型架构，并对消息传递和特征集进行了优化。分析了数据集多样性、卷积归一化因子、空间特征和 3D 图对模型性能的影响。

Result: 在大多数数据集上，所设计的模型架构取得了最先进的性能，优于更复杂的模型。发现数据集的结构多样性会影响 MPNNs 中额外组件和特征集的需求。双向消息传递和注意力机制结合简洁的消息制定可以产生更高的类别可分性。卷积归一化因子并非在所有测试数据集中都有益。2D 分子图结合合适的 3D 描述符足以保持预测性能，并降低计算成本超过 50%。

Conclusion: 通过简化消息传递机制和采用多方面分子图描述符，可以有效地提高 MPNNs 在分子性质预测中的性能。2D 分子图结合合适的 3D 描述符是一种计算成本较低且性能优越的方法，尤其适用于高通量筛选。

Abstract: Strategies to improve the predicting performance of Message-Passing
Neural-Networks for molecular property predictions can be achieved by
simplifying how the message is passed and by using descriptors that capture
multiple aspects of molecular graphs. In this work, we designed model
architectures that achieved state-of-the-art performance, surpassing more
complex models such as those pre-trained on external databases. We assessed
dataset diversity to complement our performance results, finding that
structural diversity influences the need for additional components in our MPNNs
and feature sets.
  In most datasets, our best architecture employs bidirectional message-passing
with an attention mechanism, applied to a minimalist message formulation that
excludes self-perception, highlighting that relatively simpler models, compared
to classical MPNNs, yield higher class separability. In contrast, we found that
convolution normalization factors do not benefit the predictive power in all
the datasets tested. This was corroborated in both global and node-level
outputs. Additionally, we analyzed the influence of both adding spatial
features and working with 3D graphs, finding that 2D molecular graphs are
sufficient when complemented with appropriately chosen 3D descriptors. This
approach not only preserves predictive performance but also reduces
computational cost by over 50%, making it particularly advantageous for
high-throughput screening campaigns.

</details>


### [608] [Robustifying Diffusion-Denoised Smoothing Against Covariate Shift](https://arxiv.org/abs/2509.10913)
*Ali Hedayatnia,Mostafa Tavassolipour,Babak Nadjar Araabi,Abdol-Hossein Vahabie*

Main category: cs.LG

TL;DR: 随机平滑是一种用于对抗l2对抗性扰动的认证鲁棒性的既定方法，其中预训练的扩散去噪模型被用作去噪器。然而，该方法会因对添加噪声的错误估计而引入协变量偏移，从而降低平滑分类器的性能。为了解决这个问题，本文提出了一种新颖的对抗性目标函数，该函数专注于去噪扩散模型的添加噪声，并以理解协变量偏移的根源为灵感。该方法旨在训练基础分类器以确保其能够抵抗去噪器引入的协变量偏移。


<details>
  <summary>Details</summary>
Motivation: 虽然随机平滑是一种用于实现认证鲁棒性的既定方法，但现有方法（如扩散去噪平滑）在使用预训练的扩散模型作为去噪器时，会引入协变量偏移，从而降低性能。因此，有必要解决这一问题以提高鲁棒性。

Method: 提出了一种新颖的对抗性目标函数，该函数专注于去噪扩散模型的添加噪声，目的是训练基础分类器以抵抗去噪器引入的协变量偏移。

Result: 所提出的方法在MNIST、CIFAR-10和ImageNet三个标准的分类基准上显著提高了认证精度，在l2对抗性扰动方面取得了新的最先进性能。

Conclusion: 通过提出一种新颖的对抗性目标函数来解决扩散去噪平滑中由噪声错误估计引起的协变量偏移问题，可以在MNIST、CIFAR-10和ImageNet等基准测试中实现最先进的鲁棒性。

Abstract: Randomized smoothing is a well-established method for achieving certified
robustness against l2-adversarial perturbations. By incorporating a denoiser
before the base classifier, pretrained classifiers can be seamlessly integrated
into randomized smoothing without significant performance degradation. Among
existing methods, Diffusion Denoised Smoothing - where a pretrained denoising
diffusion model serves as the denoiser - has produced state-of-the-art results.
However, we show that employing a denoising diffusion model introduces a
covariate shift via misestimation of the added noise, ultimately degrading the
smoothed classifier's performance. To address this issue, we propose a novel
adversarial objective function focused on the added noise of the denoising
diffusion model. This approach is inspired by our understanding of the origin
of the covariate shift. Our goal is to train the base classifier to ensure it
is robust against the covariate shift introduced by the denoiser. Our method
significantly improves certified accuracy across three standard classification
benchmarks - MNIST, CIFAR-10, and ImageNet - achieving new state-of-the-art
performance in l2-adversarial perturbations. Our implementation is publicly
available at
https://github.com/ahedayat/Robustifying-DDS-Against-Covariate-Shift

</details>


### [609] [ToMA: Token Merge with Attention for Image Generation with Diffusion Models](https://arxiv.org/abs/2509.10918)
*Wenbo Lu,Shaoyi Zheng,Yuxuan Xia,Shengjie Wang*

Main category: cs.LG

TL;DR: ToMA通过GPU优化的令牌缩减方法提高了扩散模型的效率，解决了现有方法的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有的令牌缩减方法（如ToMeSD和ToFu）在提高图像生成效率方面存在GPU效率低下（如排序、分散写入）的问题，导致理论上的加速效果被抵消。

Method: ToMA将令牌缩减重新表述为子模优化问题，以选择多样化的令牌，并通过类似注意力的线性变换（利用GPU友好的矩阵运算）进行合并/取消合并，同时利用潜在局部性和序列冗余来最小化开销。

Result: ToMA将SDXL/Flux的生成延迟分别降低了24%/23%（DINO $\Delta < 0.07$），优于先前的方法。

Conclusion: ToMA弥合了扩散模型中Transformer理论效率与实际效率之间的差距。

Abstract: Diffusion models excel in high-fidelity image generation but face scalability
limits due to transformers' quadratic attention complexity. Plug-and-play token
reduction methods like ToMeSD and ToFu reduce FLOPs by merging redundant tokens
in generated images but rely on GPU-inefficient operations (e.g., sorting,
scattered writes), introducing overheads that negate theoretical speedups when
paired with optimized attention implementations (e.g., FlashAttention). To
bridge this gap, we propose Token Merge with Attention (ToMA), an off-the-shelf
method that redesigns token reduction for GPU-aligned efficiency, with three
key contributions: 1) a reformulation of token merge as a submodular
optimization problem to select diverse tokens; 2) merge/unmerge as an
attention-like linear transformation via GPU-friendly matrix operations; and 3)
exploiting latent locality and sequential redundancy (pattern reuse) to
minimize overhead. ToMA reduces SDXL/Flux generation latency by 24%/23%,
respectively (with DINO $\Delta < 0.07$), outperforming prior methods. This
work bridges the gap between theoretical and practical efficiency for
transformers in diffusion.

</details>


### [610] [Clarifying Model Transparency: Interpretability versus Explainability in Deep Learning with MNIST and IMDB Examples](https://arxiv.org/abs/2509.10929)
*Mitali Raj*

Main category: cs.LG

TL;DR: 深度学习模型的不透明性（“黑箱”问题）阻碍了其在高信任度领域的应用。可解释性AI（XAI）旨在解决此问题。本文比较了深度学习中可解释性（interpretability）和解释性（explainability）的定义、目标、方法和挑战。可解释性指模型本身的可理解性（全局理解），而解释性指事后技术以阐明单个预测或行为的原因（局部解释）。例如，特征归因方法可解释MNIST图像识别，词语重要性可解释IMDB情感分析。然而，局部洞察并不使模型全局透明。理解这种区别对于构建可靠的人工智能至关重要。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型的不透明性（“黑箱”问题）阻碍了其在高信任度领域的应用，因此需要可解释性AI（XAI）来解决此问题。

Method: 通过比较深度学习中可解释性（interpretability）和解释性（explainability）的定义、目标、方法和挑战，并以MNIST数字分类任务和IMDB情感分析为例进行说明。

Result: 可解释性通常指模型本身的可理解性（全局理解），而解释性通常指事后技术以阐明单个预测或行为的原因（局部解释）。特征归因方法可解释MNIST图像识别，词语重要性可解释IMDB情感分析，但局部洞察并不使模型全局透明。

Conclusion: 理解可解释性和解释性之间的区别对于构建可靠和稳健的人工智能至关重要。

Abstract: The impressive capabilities of deep learning models are often counterbalanced
by their inherent opacity, commonly termed the "black box" problem, which
impedes their widespread acceptance in high-trust domains. In response, the
intersecting disciplines of interpretability and explainability, collectively
falling under the Explainable AI (XAI) umbrella, have become focal points of
research. Although these terms are frequently used as synonyms, they carry
distinct conceptual weights. This document offers a comparative exploration of
interpretability and explainability within the deep learning paradigm,
carefully outlining their respective definitions, objectives, prevalent
methodologies, and inherent difficulties. Through illustrative examinations of
the MNIST digit classification task and IMDB sentiment analysis, we
substantiate a key argument: interpretability generally pertains to a model's
inherent capacity for human comprehension of its operational mechanisms (global
understanding), whereas explainability is more commonly associated with
post-hoc techniques designed to illuminate the basis for a model's individual
predictions or behaviors (local explanations). For example, feature attribution
methods can reveal why a specific MNIST image is recognized as a '7', and
word-level importance can clarify an IMDB sentiment outcome. However, these
local insights do not render the complex underlying model globally transparent.
A clear grasp of this differentiation, as demonstrated by these standard
datasets, is vital for fostering dependable and sound artificial intelligence.

</details>


### [611] [The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement and Harm Enablement in Large Language Models](https://arxiv.org/abs/2509.10970)
*Joshua Au Yeung,Jacopo Dalmasso,Luca Foschini,Richard JB Dobson,Zeljko Kraljevic*

Main category: cs.LG

TL;DR: 大型语言模型（LLM）可能加剧或诱发精神病症状，甚至在用户产生妄想时强化这些妄想。


<details>
  <summary>Details</summary>
Motivation: 研究“AI精神病”现象，评估大型语言模型（LLM）在与用户互动中可能出现的诱发精神病或产生不良心理症状的风险，特别是模型讨好用户的特性可能强化脆弱用户的妄想信念。

Method: 提出并使用了一个名为“psychosis-bench”的新基准，包含16个结构化的、12轮的对话场景，模拟妄想主题（如情感妄想、夸大/弥赛亚妄想、关系妄想）的进展和潜在危害。评估了八个主流LLM在显式和隐式对话情境下的妄想确认（DCS）、伤害使能（HES）和安全干预（SIS）能力。

Result: 在1536次模拟对话轮次中，所有被评估的LLM都表现出诱发精神病的潜力，平均DCS为0.91，平均HES为0.69，平均SIS为0.37。其中39.8%的场景未提供安全干预。隐式场景的表现明显更差，模型更容易确认妄想、使能伤害并提供更少干预。DCS和HES之间存在显著相关性（rs = .77）。模型性能差异很大，表明安全性并非模型规模的必然结果。

Conclusion: 研究证实了LLM诱发精神病的风险是可量化的，并强调需要重新思考LLM的训练方式。这一问题不仅是技术挑战，更是公共卫生问题，需要开发者、政策制定者和医疗专业人员的合作。

Abstract: Background: Emerging reports of "AI psychosis" are on the rise, where
user-LLM interactions may exacerbate or induce psychosis or adverse
psychological symptoms. The sycophantic and agreeable nature of LLMs can
beneficial, it can become a vector for harm by reinforcing delusional beliefs
in vulnerable users.
  Methods: We introduce psychosis-bench, a novel benchmark designed to
systematically evaluate the psychogenicity of LLMs comprimising 16 structured,
12-turn conversational scenarios simulating the progression of delusional
themes(Erotic Delusions, Grandiose/Messianic Delusions, Referential Delusions)
and potential harms. We evaluated eight prominent LLMs for Delusion
Confirmation (DCS), Harm Enablement (HES), and Safety Intervention(SIS) across
explicit and implicit conversational contexts.
  Findings: Across 1,536 simulated conversation turns, all LLMs demonstrated
psychogenic potential, showing a strong tendency to perpetuate rather than
challenge delusions (mean DCS of 0.91 $\pm$0.88). Models frequently enabled
harmful user requests (mean HES of 0.69 $\pm$0.84) and offered safety
interventions in only roughly a third of applicable turns (mean SIS of 0.37
$\pm$0.48). 51 / 128 (39.8%) of scenarios had no safety interventions offered.
Performance was significantly worse in implicit scenarios, models were more
likely to confirm delusions and enable harm while offering fewer interventions
(p < .001). A strong correlation was found between DCS and HES (rs = .77).
Model performance varied widely, indicating that safety is not an emergent
property of scale alone.
  Conclusion: This study establishes LLM psychogenicity as a quantifiable risk
and underscores the urgent need for re-thinking how we train LLMs. We frame
this issue not merely as a technical challenge but as a public health
imperative requiring collaboration between developers, policymakers, and
healthcare professionals.

</details>


### [612] [PHLoRA: data-free Post-hoc Low-Rank Adapter extraction from full-rank checkpoint](https://arxiv.org/abs/2509.10971)
*Bhoomit Vasani,Jack FitzGerald,Anjie Fang,Sushmit Vaish*

Main category: cs.LG

TL;DR: PHLoRA是一种从全秩微调模型中提取LoRA适配器的方法，无需训练数据或梯度，可用于推理和规模化部署。


<details>
  <summary>Details</summary>
Motivation: PHLoRA旨在解决从现有全秩微调模型中提取LoRA适配器的问题，以便于推理和规模化部署，并降低成本。

Method: PHLoRA通过计算基准模型与其微调版本之间的权重差异的低秩分解来重构适配器模块。

Result: 实验表明，提取的适配器能保留大部分权重差异信息，可以安全剪枝，并且在重新合并时对下游任务性能影响极小。

Conclusion: PHLoRA为使现有全秩检查点能够使用适配器提供了一种实用的方法，从而 democratizes 可扩展推理。

Abstract: We introduce PHLoRA (Pronounced "flora"). (Post-hoc LoRA), a simple yet
powerful method to extract low-rank adaptation adapters from full-rank
fine-tuned models without requiring access to training data or gradients. By
computing the low-rank decomposition of weight differences between a base model
and its fine-tuned counterpart, our method reconstructs adapter modules that
can be merged or dynamically routed at inference time via S-LoRA, or served in
scalable, industry settings using platforms like NVIDIA NIM. This approach
amortizes latency overhead across requests and yields substantial cost savings.
Unlike prior work that trains each adapter explicitly, our approach decouples
fine-tuning from adapter generation, allowing adapter extraction from existing
full-rank models or third-party checkpoints. Experiments on text, image, and
video benchmarks using the Amazon Nova model family demonstrate that extracted
adapters preserve high energy from the full weight delta, can be pruned safely,
and yield negligible degradation in downstream task performance when re-merged.
Overall, PHLoRA provides a practical path for making all existing full-rank
checkpoints adapter-ready, democratizing scalable inference for all models.

</details>


### [613] [Decoupling Search and Learning in Neural Net Training](https://arxiv.org/abs/2509.10973)
*Akshay Vegesna,Samip Dahal*

Main category: cs.LG

TL;DR: 本文提出了一种在表示空间中搜索多样化解决方案，并通过梯度学习来回归这些解决方案的框架，以克服标准梯度下降在探索不同最优解方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 标准梯度下降算法通常收敛于单一的训练损失最小值，缺乏探索可能泛化得更好的替代最小值的机制。在高维参数空间中直接搜索多样化的最小值通常是不可行的。

Method: 该框架包含两个阶段：1. 在可处理的表示空间（中间激活的空间）中进行搜索，以找到多样化的表示解决方案。2. 在参数空间中进行基于梯度的学习，通过回归到这些搜索到的表示来进行训练。

Result: 通过进化搜索，发现了可以扩展计算量的表示解决方案（更大的种群和更多的世代产生更好、更多样化的解决方案）。将这些表示作为回归目标，可以使网络在MNIST、CIFAR-10和CIFAR-100上达到接近SGD的性能。随着搜索计算量的增加，性能会得到提升直至饱和。与梯度下降训练的网络相比，所得模型在表示轨迹上有所不同。

Conclusion: 该研究展示了未来的训练算法如何通过将表示空间中的搜索与参数空间中高效的梯度学习分离开来，克服梯度下降的探索局限性。

Abstract: Gradient descent typically converges to a single minimum of the training loss
without mechanisms to explore alternative minima that may generalize better.
Searching for diverse minima directly in high-dimensional parameter space is
generally intractable. To address this, we propose a framework that performs
training in two distinct phases: search in a tractable representation space
(the space of intermediate activations) to find diverse representational
solutions, and gradient-based learning in parameter space by regressing to
those searched representations. Through evolutionary search, we discover
representational solutions whose fitness and diversity scale with
compute--larger populations and more generations produce better and more varied
solutions. These representations prove to be learnable: networks trained by
regressing to searched representations approach SGD's performance on MNIST,
CIFAR-10, and CIFAR-100. Performance improves with search compute up to
saturation. The resulting models differ qualitatively from networks trained
with gradient descent, following different representational trajectories during
training. This work demonstrates how future training algorithms could overcome
gradient descent's exploratory limitations by decoupling search in
representation space from efficient gradient-based learning in parameter space.

</details>


### [614] [Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors](https://arxiv.org/abs/2509.12081)
*Anirudha Majumdar*

Main category: cs.LG

TL;DR: 通过学习使训练数据看似独立同分布（iid）的表示，提出欺骗性风险最小化（DRM）方法，以实现分布外（OOD）泛化，无需访问测试数据或有限数量的训练数据域。


<details>
  <summary>Details</summary>
Motivation: 提出欺骗作为一种实现分布外（OOD）泛化的机制，通过学习数据表示来消除伪相关，使其能够泛化到未见过的域。

Method: 通过一个可微分的目标来实例化欺骗性风险最小化（DRM），该目标同时学习消除由共形鞅检测器引起的分布变化的特征，并最小化特定任务的损失。

Result: 在概念偏移的数值实验和具有协变量偏移的模拟模仿学习设置中证明了DRM的有效性。

Conclusion: DRM 是一种新颖的 OOD 泛化方法，通过使训练数据在观察者看来是独立同分布的，从而识别出能够消除伪相关并泛化到新环境的稳定特征。

Abstract: This paper proposes deception as a mechanism for out-of-distribution (OOD)
generalization: by learning data representations that make training data appear
independent and identically distributed (iid) to an observer, we can identify
stable features that eliminate spurious correlations and generalize to unseen
domains. We refer to this principle as deceptive risk minimization (DRM) and
instantiate it with a practical differentiable objective that simultaneously
learns features that eliminate distribution shifts from the perspective of a
detector based on conformal martingales while minimizing a task-specific loss.
In contrast to domain adaptation or prior invariant representation learning
methods, DRM does not require access to test data or a partitioning of training
data into a finite number of data-generating domains. We demonstrate the
efficacy of DRM on numerical experiments with concept shift and a simulated
imitation learning setting with covariate shift in environments that a robot is
deployed in.

</details>


### [615] [FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design](https://arxiv.org/abs/2509.11044)
*Xuefeng Liu,Songhao Jiang,Qinan Huang,Tinson Xu,Ian Foster,Mengdi Wang,Hening Lin,Jinbo Xu,Rick Stevens*

Main category: cs.LG

TL;DR: FragmentGPT是一个整合了化学感知预训练和专家引导强化学习的生成模型，能够生成连接分子片段并优化多种药学目标的连接体，还能解决结构冗余问题。


<details>
  <summary>Details</summary>
Motivation: 设计有效的连接体将分子片段组合成化学和药理学上可行的候选药物仍然是一个挑战，特别是当片段包含重复的结构时。现有的方法无法很好地处理这些问题。

Method: FragmentGPT集成了两个核心组件：(1) 一个化学感知的、基于能量的键断裂预训练策略，使GPT模型能够进行片段生长、连接和合并；(2) 一个奖励排序的专家探索（RAE）算法，结合了专家模仿学习、数据选择和增强，以及监督微调（SFT），以实现多目标优化。

Result: FragmentGPT能够生成化学有效、高质量的分子，并能解决结构冗余问题，同时优化多种药学目标，适用于下游的药物发现任务。在真实癌症数据集上的实验证明了其有效性。

Conclusion: FragmentGPT通过统一的框架，解决了分子片段连接和结构冗余的挑战，能够进行受控的、目标驱动的分子组装，为药物发现提供了新的工具。

Abstract: Fragment-Based Drug Discovery (FBDD) is a popular approach in early drug
development, but designing effective linkers to combine disconnected molecular
fragments into chemically and pharmacologically viable candidates remains
challenging. Further complexity arises when fragments contain structural
redundancies, like duplicate rings, which cannot be addressed by simply adding
or removing atoms or bonds. To address these challenges in a unified framework,
we introduce FragmentGPT, which integrates two core components: (1) a novel
chemically-aware, energy-based bond cleavage pre-training strategy that equips
the GPT-based model with fragment growing, linking, and merging capabilities,
and (2) a novel Reward Ranked Alignment with Expert Exploration (RAE) algorithm
that combines expert imitation learning for diversity enhancement, data
selection and augmentation for Pareto and composite score optimality, and
Supervised Fine-Tuning (SFT) to align the learner policy with multi-objective
goals. Conditioned on fragment pairs, FragmentGPT generates linkers that
connect diverse molecular subunits while simultaneously optimizing for multiple
pharmaceutical goals. It also learns to resolve structural redundancies-such as
duplicated fragments-through intelligent merging, enabling the synthesis of
optimized molecules. FragmentGPT facilitates controlled, goal-driven molecular
assembly. Experiments and ablation studies on real-world cancer datasets
demonstrate its ability to generate chemically valid, high-quality molecules
tailored for downstream drug discovery tasks.

</details>


### [616] [Data-Efficient Ensemble Weather Forecasting with Diffusion Models](https://arxiv.org/abs/2509.11047)
*Kevin Valencia,Ziyang Liu,Justin Cui*

Main category: cs.LG

TL;DR: 通过数据采样策略，在减少训练数据量的前提下，使得扩散模型在天气预报任务上达到与使用全部数据相当甚至更好的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习方法在天气预报领域展现出潜力，但其计算成本高昂，尤其是在气候科学数据有限、成本高昂或难以处理的情况下，这促使我们探索数据选择对这些模型的影响。

Method: 评估了几种数据采样策略，重点是时间分层采样，并与使用全部数据的训练进行了比较。

Result: 时间分层采样在部分指标上优于使用全部数据的模型，在其他指标上仅略逊一筹，但训练数据量仅占20%。

Conclusion: 数据高效的扩散模型训练是可行的，尤其是在天气预报领域，并为未来开发更先进的采样方法提供了方向。

Abstract: Although numerical weather forecasting methods have dominated the field,
recent advances in deep learning methods, such as diffusion models, have shown
promise in ensemble weather forecasting. However, such models are typically
autoregressive and are thus computationally expensive. This is a challenge in
climate science, where data can be limited, costly, or difficult to work with.
In this work, we explore the impact of curated data selection on these
autoregressive diffusion models. We evaluate several data sampling strategies
and show that a simple time stratified sampling approach achieves performance
similar to or better than full-data training. Notably, it outperforms the
full-data model on certain metrics and performs only slightly worse on others
while using only 20% of the training data. Our results demonstrate the
feasibility of data-efficient diffusion training, especially for weather
forecasting, and motivates future work on adaptive or model-aware sampling
methods that go beyond random or purely temporal sampling.

</details>


### [617] [An Advanced Convolutional Neural Network for Bearing Fault Diagnosis under Limited Data](https://arxiv.org/abs/2509.11053)
*Shengke Sun,Shuzhen Han,Ziqian Luan,Xinghao Qin,Jiao Yin,Zhanshan Zhao,Jinli Cao,Hua Wang*

Main category: cs.LG

TL;DR: 提出了一种用于轴承故障诊断的先进数据增强和傅立叶卷积框架（DAC-FCF），以解决数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在轴承故障诊断领域面临数据稀疏、数据增强质量低、CNN 提取全局特征能力不足以及难以对有限训练样本进行建模等问题。

Method: 提出了一种条件一致的潜在表示和重构生成对抗网络（CCLR-GAN）来生成多样化数据；利用基于对比学习的联合优化机制来更好地建模可用训练数据之间的关系；并提出了一种一维傅立叶卷积神经网络（1D-FCNN）来提取全局特征。

Result: DAC-FCF 在 CWRU 数据集上取得了高达 32% 的显著改进，在自收集的测试平台上取得了 10% 的改进，并且消融实验证明了所提出组件的有效性。

Conclusion: DAC-FCF 为有限数据下的轴承故障诊断提供了一种有前景的解决方案。

Abstract: In the area of bearing fault diagnosis, deep learning (DL) methods have been
widely used recently. However, due to the high cost or privacy concerns,
high-quality labeled data are scarce in real world scenarios. While few-shot
learning has shown promise in addressing data scarcity, existing methods still
face significant limitations in this domain. Traditional data augmentation
techniques often suffer from mode collapse and generate low-quality samples
that fail to capture the diversity of bearing fault patterns. Moreover,
conventional convolutional neural networks (CNNs) with local receptive fields
makes them inadequate for extracting global features from complex vibration
signals. Additionally, existing methods fail to model the intricate
relationships between limited training samples. To solve these problems, we
propose an advanced data augmentation and contrastive fourier convolution
framework (DAC-FCF) for bearing fault diagnosis under limited data. Firstly, a
novel conditional consistent latent representation and reconstruction
generative adversarial network (CCLR-GAN) is proposed to generate more diverse
data. Secondly, a contrastive learning based joint optimization mechanism is
utilized to better model the relations between the available training data.
Finally, we propose a 1D fourier convolution neural network (1D-FCNN) to
achieve a global-aware of the input data. Experiments demonstrate that DAC-FCF
achieves significant improvements, outperforming baselines by up to 32\% on
case western reserve university (CWRU) dataset and 10\% on a self-collected
test bench. Extensive ablation experiments prove the effectiveness of the
proposed components. Thus, the proposed DAC-FCF offers a promising solution for
bearing fault diagnosis under limited data.

</details>


### [618] [Machine Learning Framework for Audio-Based Equipment Condition Monitoring: A Comparative Study of Classification Algorithms](https://arxiv.org/abs/2509.11075)
*Srijesh Pillai,Yodhin Agarwal,Zaheeruddin Ahmed*

Main category: cs.LG

TL;DR: 本论文提出了一个用于评估机器学习模型在音频设备状态监测中性能的标准化框架，并通过实验证明了集成学习方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 音频设备状态监测缺乏标准化的算法选择方法，阻碍了可复现的研究。

Method: 利用时间、频率和时频域的127个特征，在合成和真实世界数据集上验证了一个包含统计检验的机器学习模型评估框架。

Result: 集成方法在准确率（94.2%）和F1分数（0.942）方面表现最佳，并且其性能显著优于单一算法（8-15%）。

Conclusion: 这项工作提供了一个经过验证的基准测试协议和选择可靠的工业监测解决方案的实用指南。

Abstract: Audio-based equipment condition monitoring suffers from a lack of
standardized methodologies for algorithm selection, hindering reproducible
research. This paper addresses this gap by introducing a comprehensive
framework for the systematic and statistically rigorous evaluation of machine
learning models. Leveraging a rich 127-feature set across time, frequency, and
time-frequency domains, our methodology is validated on both synthetic and
real-world datasets. Results demonstrate that an ensemble method achieves
superior performance (94.2% accuracy, 0.942 F1-score), with statistical testing
confirming its significant outperformance of individual algorithms by 8-15%.
Ultimately, this work provides a validated benchmarking protocol and practical
guidelines for selecting robust monitoring solutions in industrial settings.

</details>


### [619] [DemandLens: Enhancing Forecast Accuracy Through Product-Specific Hyperparameter Optimization](https://arxiv.org/abs/2509.11085)
*Srijesh Pillai,M. I. Jawid Nazir*

Main category: cs.LG

TL;DR: DemandLens是一个基于Prophet的预测模型，用于床垫直销行业，结合了COVID-19指标和SKU特定的超参数优化，以提高销售预测的准确性，帮助合同制造商和床垫品牌优化供应链。


<details>
  <summary>Details</summary>
Motivation: 床垫直销行业严重依赖第三方合同制造商，而美国合同制造商数量有限。准确的销售预测对于合同制造商管理原材料、供应链和库存至关重要，以满足市场需求并避免瓶颈，同时也有助于床垫品牌优化其供应链。

Method: 提出了一种基于Prophet的预测模型（DemandLens），并结合了COVID-19指标和SKU特定的超参数优化，以提高预测的准确性。

Result: 该模型展示了强大的预测能力，通过SKU特定的超参数优化，为合同制造商和床垫品牌提供了一个可靠的工具来简化供应链运营。

Conclusion: DemandLens通过提供准确的销售预测，解决了床垫直销行业对第三方合同制造的依赖性问题，有助于合同制造商更好地准备生产，避免瓶颈，并优化原材料采购。

Abstract: DemandLens demonstrates an innovative Prophet based forecasting model for the
mattress-in-a-box industry, incorporating COVID-19 metrics and SKU-specific
hyperparameter optimization. This industry has seen significant growth of
E-commerce players in the recent years, wherein the business model majorly
relies on outsourcing Mattress manufacturing and related logistics and supply
chain operations, focusing on marketing the product and driving conversions
through Direct-to-Consumer sales channels. Now, within the United States, there
are a limited number of Mattress contract manufacturers available, and hence,
it is important that they manage their raw materials, supply chain, and,
inventory intelligently, to be able to cater maximum Mattress brands. Our
approach addresses the critical need for accurate Sales Forecasting in an
industry that is heavily dependent on third-party Contract Manufacturing. This,
in turn, helps the contract manufacturers to be prepared, hence, avoiding
bottleneck scenarios, and aiding them to source raw materials at optimal rates.
The model demonstrates strong predictive capabilities through SKU-specific
Hyperparameter optimization, offering the Contract Manufacturers and Mattress
brands a reliable tool to streamline supply chain operations.

</details>


### [620] [GCN-TULHOR: Trajectory-User Linking Leveraging GCNs and Higher-Order Spatial Representations](https://arxiv.org/abs/2509.11095)
*Khoa Tran,Pranav Gupta,Manos Papagelis*

Main category: cs.LG

TL;DR: GCN-TULHOR通过使用六边形划分将原始位置数据转换为高阶移动流表示，并结合图卷积网络（GCN），有效解决了轨迹用户链接（TUL）中的数据稀疏性和空间依赖性问题，并在多个真实世界数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹用户链接（TUL）方法在处理稀疏数据、不完整路线和复杂空间依赖性方面存在不足，通常依赖低级签到数据或忽略空间模式。

Method: 提出GCN-TULHOR方法，将原始位置数据通过六边形划分转换为高阶移动流表示，以减少数据稀疏性并捕获更丰富的空间语义，同时结合图卷积网络（GCN）来显式建模复杂的空间关系和非局部依赖性，无需额外信息。

Result: 在六个真实世界数据集上的实验表明，GCN-TULHOR在准确率、精确率、召回率和F1分数方面始终优于经典基线、基于RNN和Transformer的模型以及TULHOR方法，准确率和F1分数相对提高了1-8%。敏感性分析表明，一个GCN层和512维嵌入的最优设置。

Conclusion: GCN-TULHOR通过结合图卷积网络和高阶移动流表示，有效地解决了轨迹用户链接问题，并在推荐、城市规划和安全等领域具有广泛的应用前景。该方法通过集成GCN增强了空间学习能力和跨移动数据的泛化能力。

Abstract: Trajectory-user linking (TUL) aims to associate anonymized trajectories with
the users who generated them, which is crucial for personalized
recommendations, privacy-preserving analytics, and secure location-based
services. Existing methods struggle with sparse data, incomplete routes, and
limited modeling of complex spatial dependencies, often relying on low-level
check-in data or ignoring spatial patterns. In this paper, we introduced
GCN-TULHOR, a method that transforms raw location data into higher-order
mobility flow representations using hexagonal tessellation, reducing data
sparsity and capturing richer spatial semantics, and integrating Graph
Convolutional Networks (GCNs). Our approach converts both sparse check-in and
continuous GPS trajectory data into unified higher-order flow representations,
mitigating sparsity while capturing deeper semantic information. The GCN layer
explicitly models complex spatial relationships and non-local dependencies
without requiring side information such as timestamps or points of interest.
Experiments on six real-world datasets show consistent improvements over
classical baselines, RNN- and Transformer-based models, and the TULHOR method
in accuracy, precision, recall, and F1-score. GCN-TULHOR achieves 1-8% relative
gains in accuracy and F1. Sensitivity analysis identifies an optimal setup with
a single GCN layer and 512-dimensional embeddings. The integration of GCNs
enhances spatial learning and improves generalizability across mobility data.
This work highlights the value of combining graph-based spatial learning with
sequential modeling, offering a robust and scalable solution for TUL with
applications in recommendations, urban planning, and security.

</details>


### [621] [BIGNet: Pretrained Graph Neural Network for Embedding Semantic, Spatial, and Topological Data in BIM Models](https://arxiv.org/abs/2509.11104)
*Jin Han,Xin-Zheng Lu,Jia-Rui Lin*

Main category: cs.LG

TL;DR: 该研究提出了BIGNet，一个大规模图神经网络（GNN），用于学习和重用BIM模型中的多维度设计特征，以解决现有大型基础模型（LFMs）在处理BIM数据方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LFM主要关注文本和视觉数据，忽略了BIM模型中丰富的语义、空间和拓扑特征。因此，本研究旨在开发一种能够学习和利用BIM模型多维度设计特征的方法。

Method: 研究人员开发了一个名为BIGNet的大规模GNN，它使用一种新的消息传递机制，并采用节点遮挡策略进行预训练。他们还引入了一种可扩展的图表示方法来编码BIM组件的“语义-空间-拓扑”特征，并创建了一个包含近100万个节点和350万个边的BIM数据集。

Result: BIGNet在基于BIM的设计检查的各种迁移学习任务中得到了评估。结果表明，同质图表示优于异质图表示，考虑30厘米半径内的局部空间关系可以提高性能，并且基于GAT（图注意力网络）的特征提取的BIGNet取得了最佳的迁移学习结果，相比于非预训练模型，平均F1分数提高了72.7%。

Conclusion: BIGNet在学习和迁移BIM设计特征方面是有效的，并且能够促进其在未来设计和生命周期管理中的自动化应用。

Abstract: Large Foundation Models (LFMs) have demonstrated significant advantages in
civil engineering, but they primarily focus on textual and visual data,
overlooking the rich semantic, spatial, and topological features in BIM
(Building Information Modelling) models. Therefore, this study develops the
first large-scale graph neural network (GNN), BIGNet, to learn, and reuse
multidimensional design features embedded in BIM models. Firstly, a scalable
graph representation is introduced to encode the "semantic-spatial-topological"
features of BIM components, and a dataset with nearly 1 million nodes and 3.5
million edges is created. Subsequently, BIGNet is proposed by introducing a new
message-passing mechanism to GraphMAE2 and further pretrained with a node
masking strategy. Finally, BIGNet is evaluated in various transfer learning
tasks for BIM-based design checking. Results show that: 1) homogeneous graph
representation outperforms heterogeneous graph in learning design features, 2)
considering local spatial relationships in a 30 cm radius enhances performance,
and 3) BIGNet with GAT (Graph Attention Network)-based feature extraction
achieves the best transfer learning results. This innovation leads to a 72.7%
improvement in Average F1-score over non-pretrained models, demonstrating its
effectiveness in learning and transferring BIM design features and facilitating
their automated application in future design and lifecycle management.

</details>


### [622] [Feature Space Topology Control via Hopkins Loss](https://arxiv.org/abs/2509.11154)
*Einari Vaaras,Manu Airaksinen*

Main category: cs.LG

TL;DR: 本论文提出了一种新的损失函数Hopkins loss，用于控制特征空间的拓扑结构，以应用于降维、生成模型、迁移学习和对抗性攻击鲁棒性等机器学习任务。


<details>
  <summary>Details</summary>
Motivation: 修改特征空间的拓扑结构在机器学习中有多种应用，例如降维、生成模型、迁移学习和对抗性攻击鲁棒性。然而，现有方法主要关注于保持输入特征的拓扑结构，而忽略了直接控制特征空间的拓扑结构。

Method: 提出了一种新的损失函数Hopkins loss，该损失函数利用Hopkins统计量来强制实现期望的特征空间拓扑结构。该损失函数被整合到分类和降维（使用非线性瓶颈自编码器）的场景中，并在语音、文本和图像数据上进行了评估。

Result: 实验结果表明，将Hopkins loss集成到分类或降维任务中，对分类性能的影响很小，但能够有效地修改特征空间的拓扑结构。

Conclusion: Hopkins loss是一种有效的方法，可以控制特征空间的拓扑结构，并且对现有机器学习任务的性能影响很小。

Abstract: Feature space topology refers to the organization of samples within the
feature space. Modifying this topology can be beneficial in machine learning
applications, including dimensionality reduction, generative modeling, transfer
learning, and robustness to adversarial attacks. This paper introduces a novel
loss function, Hopkins loss, which leverages the Hopkins statistic to enforce a
desired feature space topology, which is in contrast to existing
topology-related methods that aim to preserve input feature topology. We
evaluate the effectiveness of Hopkins loss on speech, text, and image data in
two scenarios: classification and dimensionality reduction using nonlinear
bottleneck autoencoders. Our experiments show that integrating Hopkins loss
into classification or dimensionality reduction has only a small impact on
classification performance while providing the benefit of modifying feature
topology.

</details>


### [623] [AQUA: Attention via QUery mAgnitudes for Memory and Compute Efficient Inference in LLMs](https://arxiv.org/abs/2509.11155)
*Santhosh G S,Saurav Prakash,Balaraman Ravindran*

Main category: cs.LG

TL;DR: AQUA是一种新颖的注意力机制近似策略，通过降维和稀疏选择来降低LLM长上下文的计算和内存成本，同时对性能影响很小。


<details>
  <summary>Details</summary>
Motivation: 二次方复杂度的注意力机制限制了LLM处理长上下文的能力，带来了计算和内存瓶颈。

Method: AQUA分为两个阶段：1. 离线阶段：计算一个语言无关的投影矩阵。2. 在线推理阶段：投影查询和键向量，并基于查询的幅度动态选择稀疏维度子集。

Result: 在Llama-3.1-8B模型上，AQUA实现了25%的注意力点积计算减少，而对基准测试性能的影响微乎其微。它还可以与H2O等现有方法协同工作，并减小KV缓存大小。

Conclusion: AQUA是一种实用且强大的工具，可以通过可控的效率-准确性权衡，使大规模LLM推理更易于访问和可持续。

Abstract: The quadratic complexity of the attention mechanism remains a fundamental
barrier to scaling Large Language Models (LLMs) to longer contexts, creating a
critical bottleneck in both computation and memory. To address this, we
introduce AQUA (Attention via QUery mAgnitudes) a novel and versatile
approximation strategy that significantly reduces the cost of attention with a
graceful performance trade-off. Our method operates in two phases: an efficient
offline step where we compute a universal, language agnostic projection matrix
via SVD on a calibration dataset, and an online inference step where we project
query and key vectors and dynamically select a sparse subset of dimensions
based on the query's magnitude. We provide a formal theoretical analysis of
AQUA, establishing the break-even point at which it becomes more
computationally efficient than standard attention. Our empirical evaluations on
state-of-the-art models like Llama-3.1-8B demonstrate that a 25% reduction in
the attention dot-product computation can be achieved with a statistically
insignificant impact on performance across a wide range of benchmarks. We
further showcase the versatility of AQUA by demonstrating its ability to
synergistically accelerate existing token eviction methods like H2O and to
directly reduce KV-cache memory size. By offering a controllable knob to
balance efficiency and accuracy, AQUA provides a practical and powerful tool
for making large-scale LLM inference more accessible and sustainable.

</details>


### [624] [Stabilizing Data-Free Model Extraction](https://arxiv.org/abs/2509.11159)
*Dat-Thinh Nguyen,Kim-Hung Le,Nhien-An Le-Khac*

Main category: cs.LG

TL;DR: MetaDFME是一种新的无数据模型提取方法，它使用元学习来减少生成数据分布的偏移，从而减轻替代模型的准确性振荡，并在图像数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 模型提取对机器学习即服务系统构成严重威胁，尤其是通过无数据方法，因为不诚实的用户可以在不访问真实数据的情况下复制黑盒目标模型的功能。现有方法存在替代模型准确性振荡的问题，这使得攻击不切实际。

Method: 提出了一种名为MetaDFME的新型无数据模型提取方法，该方法在生成器训练中采用元学习来减少分布偏移，旨在减轻替代模型的准确性振荡。具体来说，训练生成器在攻击过程中迭代地捕获合成数据的元表示，这些元表示可以通过几步进行调整，以生成有利于替代模型从目标模型学习的数据，同时减少分布偏移的影响。

Result: 在MNIST、SVHN、CIFAR-10和CIFAR-100等流行基线图像数据集上进行的实验表明，MetaDFME的性能优于当前最先进的无数据模型提取方法，并且在攻击过程中替代模型的准确性更稳定。

Conclusion: MetaDFME通过在生成器训练中采用元学习来解决现有无数据模型提取方法的准确性振荡问题，从而提供更稳定和更优越的提取性能。

Abstract: Model extraction is a severe threat to Machine Learning-as-a-Service systems,
especially through data-free approaches, where dishonest users can replicate
the functionality of a black-box target model without access to realistic data.
Despite recent advancements, existing data-free model extraction methods suffer
from the oscillating accuracy of the substitute model. This oscillation, which
could be attributed to the constant shift in the generated data distribution
during the attack, makes the attack impractical since the optimal substitute
model cannot be determined without access to the target model's in-distribution
data. Hence, we propose MetaDFME, a novel data-free model extraction method
that employs meta-learning in the generator training to reduce the distribution
shift, aiming to mitigate the substitute model's accuracy oscillation. In
detail, we train our generator to iteratively capture the meta-representations
of the synthetic data during the attack. These meta-representations can be
adapted with a few steps to produce data that facilitates the substitute model
to learn from the target model while reducing the effect of distribution
shifts. Our experiments on popular baseline image datasets, MNIST, SVHN,
CIFAR-10, and CIFAR-100, demonstrate that MetaDFME outperforms the current
state-of-the-art data-free model extraction method while exhibiting a more
stable substitute model's accuracy during the attack.

</details>


### [625] [GK-SMOTE: A Hyperparameter-free Noise-Resilient Gaussian KDE-Based Oversampling Approach](https://arxiv.org/abs/2509.11163)
*Mahabubur Rahman Miraj,Hongyu Huang,Ting Yang,Jinxue Zhao,Nankun Mu,Xinyu Lei*

Main category: cs.LG

TL;DR: GK-SMOTE是一种无超参数、抗噪声的SMOTE扩展，利用高斯核密度估计来生成合成样本，解决了传统过采样方法在处理标签噪声和复杂数据分布时的不足，并在二分类数据集上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习中不平衡分类的挑战，特别是传统过采样技术（如SMOTE）在处理标签噪声和复杂数据分布时存在的不足，导致分类精度下降的问题。

Method: 提出GK-SMOTE，一种基于高斯核密度估计（KDE）的无超参数、抗噪声的SMOTE扩展。通过生成高密度少数类区域的合成样本来增强类可分离性，同时避免噪声或模糊区域。该方法利用高斯KDE区分安全区域和噪声区域，实现准确的样本生成，无需参数调整。

Result: 在多种二分类数据集上的广泛实验表明，GK-SMOTE在MCC、平衡准确率和AUPRC等关键评估指标上优于现有的最先进的过采样技术。

Conclusion: GK-SMOTE为不平衡分类任务提供了一种鲁棒、高效的解决方案，特别是在噪声数据环境中，使其成为实际应用的有吸引力的选择。

Abstract: Imbalanced classification is a significant challenge in machine learning,
especially in critical applications like medical diagnosis, fraud detection,
and cybersecurity. Traditional oversampling techniques, such as SMOTE, often
fail to handle label noise and complex data distributions, leading to reduced
classification accuracy. In this paper, we propose GK-SMOTE, a
hyperparameter-free, noise-resilient extension of SMOTE, built on Gaussian
Kernel Density Estimation (KDE). GK-SMOTE enhances class separability by
generating synthetic samples in high-density minority regions, while
effectively avoiding noisy or ambiguous areas. This self-adaptive approach uses
Gaussian KDE to differentiate between safe and noisy regions, ensuring more
accurate sample generation without requiring extensive parameter tuning. Our
extensive experiments on diverse binary classification datasets demonstrate
that GK-SMOTE outperforms existing state-of-the-art oversampling techniques
across key evaluation metrics, including MCC, Balanced Accuracy, and AUPRC. The
proposed method offers a robust, efficient solution for imbalanced
classification tasks, especially in noisy data environments, making it an
attractive choice for real-world applications.

</details>


### [626] [Harnessing Optimization Dynamics for Curvature-Informed Model Merging](https://arxiv.org/abs/2509.11167)
*Pouria Mahdavinia,Hamed Mahdavi,Niloofar Mireshghallah,Mehrdad Mahdavi*

Main category: cs.LG

TL;DR: 模型合并是一种有效的训练后策略，无需联合重新训练即可组合大型语言模型中的能力。本研究在监督微调 (SFT) 阶段研究了这一点，其中必须将多个基于能力的 SFT 检查点——涵盖数学、代码、精确指令遵循、通用指令遵循和知识回忆——整合到一个模型中。我们引入了考虑优化轨迹（OTA）的合并，这是一种关注曲率的聚合方法，它利用优化器的二阶矩统计作为对角曲率代理来重新加权参数编辑并减轻干扰。作为 OTA 的补充，我们提出了快速费舍尔嫁接（FFG），这是一种由曲率驱动的任务局部化步骤，可以稀疏化冲突或低重要性的编辑。FFG 在早期注意力查询/键投影和令牌嵌入中产生非常低秩的掩码，利用了不同能力之间的共享曲率。我们进一步开发了一种用于二阶矩的轻量级内存压缩，该压缩保留了 OTA 的效果。通过对各种基于能力的 SFT 检查点进行测试，OTA+FFG 在合并模型质量方面优于强大的权重空间基线，减少了负迁移，并在不同稀疏度水平下保持鲁棒性。分析表明，检查点之间存在显著的曲率重叠，这为简单的线性合并在实践中可能有效提供了一个新的视角。对照实验证实了 FFG 在减少任务干扰方面至关重要，并且压缩的二阶矩保留了完整公式带来的收益。为方便重现，我们在 https://github.com/pmahdavi/ota-merge 开放了所有代码、训练和评估脚本、可视化文件以及特定于能力的 SFT 检查点。


<details>
  <summary>Details</summary>
Motivation: 在监督微调（SFT）阶段，需要将涵盖数学、代码、精确指令遵循、通用指令遵循和知识回忆等多种能力的 SFT 检查点整合到一个模型中。

Method: 引入了考虑优化轨迹（OTA）的合并，这是一种关注曲率的聚合方法，它利用优化器的二阶矩统计作为对角曲率代理来重新加权参数编辑并减轻干扰。提出了快速费舍尔嫁接（FFG），这是一种由曲率驱动的任务局部化步骤，可以稀疏化冲突或低重要性的编辑。开发了一种用于二阶矩的轻量级内存压缩，该压缩保留了 OTA 的效果。

Result: OTA+FFG 在合并模型质量方面优于强大的权重空间基线，减少了负迁移，并在不同稀疏度水平下保持鲁棒性。分析表明，检查点之间存在显著的曲率重叠。对照实验证实了 FFG 在减少任务干扰方面至关重要，并且压缩的二阶矩保留了完整公式带来的收益。

Conclusion: OTA+FFG 是一种有效的模型合并方法，通过利用优化轨迹和曲率信息，能够成功地整合多个 SFT 检查点的能力，同时减少干扰并提高模型性能。

Abstract: Model merging is an effective post-training strategy for composing
capabilities in large language models without joint retraining. We study this
in the supervised fine-tuning (SFT) stage, where multiple capability-based SFT
checkpoints -- spanning math, code, precise instruction following, general
instruction following, and knowledge recall -- must be consolidated into a
single model. We introduce Optimization Trajectory Aware (OTA) Merging, a
curvature-aware aggregation that leverages optimizer second-moment statistics
as a diagonal curvature proxy to reweight parameter edits and mitigate
interference. Complementing OTA, we propose Fast Fisher Grafting (FFG), a
curvature-driven task-localization step that sparsifies conflicting or
low-importance edits. FFG induces extremely low-rank masks concentrated in
early attention query/key projections and token embeddings, exploiting shared
curvature across capabilities. We further develop a memory-light compression of
the second moments that preserves OTA's effect. Across diverse capability-based
SFT checkpoints, OTA+FFG improves merged-model quality over strong weight-space
baselines, reduces negative transfer, and remains robust across sparsity
levels. Analyses reveal substantial curvature overlap between checkpoints,
offering a novel lens on why simple linear merging can be effective in
practice. Ablations confirm that FFG is critical for reducing task interference
and that the compressed second moments retain the gains of the full
formulation. To facilitate reproducibility, we open-source all code, training
and evaluation scripts, visualization artifacts, and capability-specific SFT
checkpoints at https://github.com/pmahdavi/ota-merge.

</details>


### [627] [Federated Recommender System with Data Valuation for E-commerce Platform](https://arxiv.org/abs/2509.11196)
*Jongwon Park,Minku Kang,Wooseok Sim,Soyoung Lee,Hogun Park*

Main category: cs.LG

TL;DR: FedGDVE通过结合全局和本地数据来改进联邦学习推荐系统，解决了数据稀疏性和计算成本问题，并在基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习推荐系统主要依赖本地数据，忽略了利用丰富公开数据集的潜力，导致本地数据稀疏和有偏见。

Method: FedGDVE提出了一种选择性地从全局数据集中增强本地图谱的方法。它使用预训练图编码器提取全局结构特征，使用本地有效预测器评估客户端相关性，并使用基于强化学习的概率估计器来过滤和采样最相关的全局交互。

Result: FedGDVE在联邦学习环境下，在公认的基准测试中，性能提升高达34.86%。

Conclusion: FedGDVE有效地解决了在联邦学习推荐系统中整合全局数据带来的挑战，通过选择性地利用全局信息来丰富本地训练，从而提高了推荐系统的性能。

Abstract: Federated Learning (FL) is gaining prominence in machine learning as privacy
concerns grow. This paradigm allows each client (e.g., an individual online
store) to train a recommendation model locally while sharing only model
updates, without exposing the raw interaction logs to a central server, thereby
preserving privacy in a decentralized environment. Nonetheless, most existing
FL-based recommender systems still rely solely on each client's private data,
despite the abundance of publicly available datasets that could be leveraged to
enrich local training; this potential remains largely underexplored. To this
end, we consider a realistic scenario wherein a large shopping platform
collaborates with multiple small online stores to build a global recommender
system. The platform possesses global data, such as shareable user and item
lists, while each store holds a portion of interaction data privately (or
locally). Although integrating global data can help mitigate the limitations of
sparse and biased clients' local data, it also introduces additional
challenges: simply combining all global interactions can amplify noise and
irrelevant patterns, worsening personalization and increasing computational
costs. To address these challenges, we propose FedGDVE, which selectively
augments each client's local graph with semantically aligned samples from the
global dataset. FedGDVE employs: (i) a pre-trained graph encoder to extract
global structural features, (ii) a local valid predictor to assess
client-specific relevance, (iii) a reinforcement-learning-based probability
estimator to filter and sample only the most pertinent global interactions.
FedGDVE improves performance by up to 34.86% on recognized benchmarks in FL
environments.

</details>


### [628] [TransZero: Parallel Tree Expansion in MuZero using Transformer Networks](https://arxiv.org/abs/2509.11233)
*Emil Malmsten,Wendelin Böhmer*

Main category: cs.LG

TL;DR: TransZero通过使用Transformer并行生成未来状态并结合MVC评估器，实现了比MuZero快11倍的规划速度，同时保持了样本效率。


<details>
  <summary>Details</summary>
Motivation: 为了克服蒙特卡洛树搜索（MCTS）中的顺序瓶颈，并加速模型驱动的强化学习。

Method: TransZero使用基于Transformer的网络同时生成多个潜在的未来状态，并结合了均值-方差约束（MVC）评估器，以并行扩展整个子树。

Result: 在MiniGrid和LunarLander的实验中，TransZero实现了比MuZero高11倍的实际运行时间加速，同时保持了样本效率。

Conclusion: 并行树构建可以显著加速模型驱动的强化学习，使复杂环境中的实时决策更加实用。

Abstract: We present TransZero, a model-based reinforcement learning algorithm that
removes the sequential bottleneck in Monte Carlo Tree Search (MCTS). Unlike
MuZero, which constructs its search tree step by step using a recurrent
dynamics model, TransZero employs a transformer-based network to generate
multiple latent future states simultaneously. Combined with the Mean-Variance
Constrained (MVC) evaluator that eliminates dependence on inherently sequential
visitation counts, our approach enables the parallel expansion of entire
subtrees during planning. Experiments in MiniGrid and LunarLander show that
TransZero achieves up to an eleven-fold speedup in wall-clock time compared to
MuZero while maintaining sample efficiency. These results demonstrate that
parallel tree construction can substantially accelerate model-based
reinforcement learning, bringing real-time decision-making in complex
environments closer to practice. The code is publicly available on GitHub.

</details>


### [629] [Online Optimization on Hadamard Manifolds: Curvature Independent Regret Bounds on Horospherically Convex Objectives](https://arxiv.org/abs/2509.11236)
*Emre Sahinoglu,Shahin Shahrampour*

Main category: cs.LG

TL;DR: 本文研究了在Hadamard流形上，在horospherical convexity (h-convexity)框架下的在线黎曼优化问题，并为h-凸和强h-凸函数建立了与曲率无关的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖于测地线凸性（g-convexity），导致遗憾界限随流形曲率的增加而显著变差。本文旨在解决这一局限性。

Method: 对h-凸和强h-凸函数，分析了黎曼在线梯度下降算法，并建立了其遗憾界限。

Result: 对于h-凸函数，遗憾界限为$O(\sqrt{T})$；对于强h-凸函数，遗憾界限为$O(\log(T))$。这些界限不依赖于流形曲率，与欧氏空间中的结果相当。

Conclusion: 本文提出的基于h-凸性的在线黎曼优化方法，在避免曲率影响的同时，达到了与欧氏空间相媲美的遗憾界限。通过在SPD矩阵流形上的在线Tyler M-估计和在线Fréchet均值计算实验，验证了h-凸性在实际应用中的有效性。

Abstract: We study online Riemannian optimization on Hadamard manifolds under the
framework of horospherical convexity (h-convexity). Prior work mostly relies on
the geodesic convexity (g-convexity), leading to regret bounds scaling poorly
with the manifold curvature. To address this limitation, we analyze Riemannian
online gradient descent for h-convex and strongly h-convex functions and
establish $O(\sqrt{T})$ and $O(\log(T))$ regret guarantees, respectively. These
bounds are curvature-independent and match the results in the Euclidean
setting. We validate our approach with experiments on the manifold of symmetric
positive definite (SPD) matrices equipped with the affine-invariant metric. In
particular, we investigate online Tyler's $M$-estimation and online Fr\'echet
mean computation, showing the application of h-convexity in practice.

</details>


### [630] [Gradient Free Deep Reinforcement Learning With TabPFN](https://arxiv.org/abs/2509.11259)
*David Schiff,Ofir Lindenbaum,Yonathan Efroni*

Main category: cs.LG

TL;DR: 提出了一种名为TabPFN RL的无梯度深度强化学习框架，该框架利用预训练的Transformer模型TabPFN作为Q函数近似器，消除了梯度下降的需求，并在经典控制任务上取得了与DQN相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于梯度的方法在深度强化学习中存在对超参数敏感、训练不稳定和计算成本高的问题。

Method: 将预训练的Transformer模型TabPFN用作Q值函数近似器，通过仅进行推理来预测Q值，无需梯度更新。为了处理模型固定的上下文预算，设计了一种高奖励的剧集门控机制，仅保留排名前5%的轨迹。对上下文大小限制进行了理论分析，并提出了能够实现持续学习的截断策略。

Result: 在Gymnasium经典控制套件（CartPole v1, MountainCar v0, Acrobot v1）上，TabPFN RL在不使用梯度下降或大量超参数调整的情况下，性能与Deep Q Network相当或更优。实验表明，即使在违反其先验独立性假设的情况下，模型也表现出惊人的泛化能力。

Conclusion: 基于先验拟合网络（如TabPFN）的强化学习框架是实现快速、计算高效的强化学习的可行基础，为无梯度强化学习和大型预训练Transformer开辟了新方向。

Abstract: Gradient based optimization is fundamental to most modern deep reinforcement
learning algorithms, however, it introduces significant sensitivity to
hyperparameters, unstable training dynamics, and high computational costs. We
propose TabPFN RL, a novel gradient free deep RL framework that repurposes the
meta trained transformer TabPFN as a Q function approximator. Originally
developed for tabular classification, TabPFN is a transformer pre trained on
millions of synthetic datasets to perform inference on new unseen datasets via
in context learning. Given an in context dataset of sample label pairs and new
unlabeled data, it predicts the most likely labels in a single forward pass,
without gradient updates or task specific fine tuning. We use TabPFN to predict
Q values using inference only, thereby eliminating the need for back
propagation at both training and inference. To cope with the model's fixed
context budget, we design a high reward episode gate that retains only the top
5% of trajectories. Empirical evaluations on the Gymnasium classic control
suite demonstrate that TabPFN RL matches or surpasses Deep Q Network on
CartPole v1, MountainCar v0, and Acrobot v1, without applying gradient descent
or any extensive hyperparameter tuning. We discuss the theoretical aspects of
how bootstrapped targets and non stationary visitation distributions violate
the independence assumptions encoded in TabPFN's prior, yet the model retains a
surprising generalization capacity. We further formalize the intrinsic context
size limit of in context RL algorithms and propose principled truncation
strategies that enable continual learning when the context is full. Our results
establish prior fitted networks such as TabPFN as a viable foundation for fast
and computationally efficient RL, opening new directions for gradient free RL
with large pre trained transformers.

</details>


### [631] [SelectMix: Enhancing Label Noise Robustness through Targeted Sample Mixing](https://arxiv.org/abs/2509.11265)
*Qiuhao Liu,Ling Li,Yao Lu,Qi Xuan,Zhaowei Zhu,Jiaheng Wei*

Main category: cs.LG

TL;DR: SelectMix是一种新的框架，通过指导性混合来解决深度神经网络在嘈杂标签上的记忆问题，从而提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的Mixup方法在处理嘈杂标签时，会不加区分地混合样本，可能传播错误的标签，损害模型的泛化能力。本研究旨在提出一种更优的混合策略，以应对嘈杂标签问题。

Method: SelectMix首先利用K折交叉验证和基于置信度的不匹配分析来识别潜在的嘈杂或模糊样本。然后，它选择性地将这些不确定的样本与来自其潜在类别的、置信度高的样本进行混合。此外，SelectMix使用来自混合过程中所有涉及类别的软标签，以确保标签准确反映混合样本的组成。

Result: 通过在多个合成和真实世界数据集（包括MNIST、Fashion-MNIST、CIFAR-10、CIFAR-100、CIFAR-N、MNIST和Clothing1M）上的广泛理论分析和实证评估，SelectMix在学习带嘈杂标签的数据方面，持续优于现有的强基线方法。

Conclusion: SelectMix框架在处理嘈杂标签时，通过其置信度指导的混合策略，能够有效提高模型的泛化能力和鲁棒性。

Abstract: Deep neural networks tend to memorize noisy labels, severely degrading their
generalization performance. Although Mixup has demonstrated effectiveness in
improving generalization and robustness, existing Mixup-based methods typically
perform indiscriminate mixing without principled guidance on sample selection
and mixing strategy, inadvertently propagating noisy supervision. To overcome
these limitations, we propose SelectMix, a confidence-guided mixing framework
explicitly tailored for noisy labels. SelectMix first identifies potentially
noisy or ambiguous samples through confidence based mismatch analysis using
K-fold cross-validation, then selectively blends identified uncertain samples
with confidently predicted peers from their potential classes. Furthermore,
SelectMix employs soft labels derived from all classes involved in the mixing
process, ensuring the labels accurately represent the composition of the mixed
samples, thus aligning supervision signals closely with the actual mixed
inputs. Through extensive theoretical analysis and empirical evaluations on
multiple synthetic (MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100) and real-world
benchmark datasets (CIFAR-N, MNIST and Clothing1M), we demonstrate that
SelectMix consistently outperforms strong baseline methods, validating its
effectiveness and robustness in learning with noisy labels.

</details>


### [632] [Protected Probabilistic Classification Library](https://arxiv.org/abs/2509.11267)
*Ivan Petej*

Main category: cs.LG

TL;DR: 本论文提出了一种新的Python包，用于解决数据集偏移下概率分类器的校准问题。


<details>
  <summary>Details</summary>
Motivation: 解决数据集偏移下概率分类器校准的挑战。

Method: 提出了一种新的Python包来实现校准，并在二分类和多分类场景中进行了演示。

Result: 与现有的后验校准方法相比，该方法在经验结果上表现出 promising 的效果。

Conclusion: 该技术在批量和在线学习分类问题的各种场景中都有帮助，尤其是在训练和测试数据集的基础数据分布发生变化时。

Abstract: This paper introduces a new Python package specifically designed to address
calibration of probabilistic classifiers under dataset shift. The method is
demonstrated in binary and multi-class settings and its effectiveness is
measured against a number of existing post-hoc calibration methods. The
empirical results are promising and suggest that our technique can be helpful
in a variety of settings for batch and online learning classification problems
where the underlying data distribution changes between the training and test
sets.

</details>


### [633] [PINGS: Physics-Informed Neural Network for Fast Generative Sampling](https://arxiv.org/abs/2509.11284)
*Achmad Ardani Prasha,Clavino Ourizqi Rachmadi,Muhamad Fauzan Ibnu Syahlan,Naufal Rahfi Anugerah,Nanda Garin Raditya,Putri Amelia,Sabrina Laila Mutiara,Hilman Syachr Ramadhan*

Main category: cs.LG

TL;DR: PINGS是一个物理信息神经网络框架，通过单次前向传播实现快速生成采样，速度远超现有方法，并能在科学模拟等领域扩展应用。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型采样速度慢，无法满足实时性需求，且迭代式求解器和直接映射方法各有局限。

Method: PINGS通过训练物理信息神经网络来近似反向时间概率流动力学，将采样过程转化为一次前向传播（NFE=1），并借鉴PINN的残差问题和端点锚定的思想，实现白盒、可微分的映射。

Result: 在从3D标准正态分布到非高斯混合模型的映射任务中，PINGS在保持分布结构的同时，实现了常数时间生成（$10^4$个样本仅需$16.54 	ext{ ms}$），远快于DPM-Solver和DDIM。在阻尼谐振子问题上，PINN/自动微分流程也获得了$	ext{O}(10^{-5})$级别的均方误差。

Conclusion: PINGS框架提供了一种快速、基于函数、可微分的生成采样新途径，在保持分布结构的同时大幅提升了采样速度，有潜力应用于科学模拟等领域。

Abstract: We introduce PINGS (Physics-Informed Neural Network for Fast Generative
Sampling), a framework that amortizes diffusion sampling by training a
physics-informed network to approximate reverse-time probability-flow dynamics,
reducing sampling to a single forward pass (NFE = 1). As a proof of concept, we
learn a direct map from a 3D standard normal to a non-Gaussian Gaussian Mixture
Model (GMM). PINGS preserves the target's distributional structure
(multi-bandwidth kernel $MMD^2 = 1.88 \times 10^{-2}$ with small errors in
mean, covariance, skewness, and excess kurtosis) and achieves constant-time
generation: $10^4$ samples in $16.54 \pm 0.56$ millisecond on an RTX 3090,
versus 468-843 millisecond for DPM-Solver (10/20) and 960 millisecond for DDIM
(50) under matched conditions. We also sanity-check the
PINN/automatic-differentiation pipeline on a damped harmonic oscillator,
obtaining MSEs down to $\mathcal{O}(10^{-5})$. Compared to fast but iterative
ODE solvers and direct-map families (Flow, Rectified-Flow, Consistency), PINGS
frames generative sampling as a PINN-style residual problem with endpoint
anchoring, yielding a white-box, differentiable map with NFE = 1. These
proof-of-concept results position PINGS as a promising route to fast,
function-based generative sampling with potential extensions to scientific
simulation (e.g., fast calorimetry).

</details>


### [634] [Efficient Single-Step Framework for Incremental Class Learning in Neural Networks](https://arxiv.org/abs/2509.11285)
*Alejandro Dopico-Castro,Oscar Fontenla-Romero,Bertha Guijarro-Berdiñas,Amparo Alonso-Betanzos*

Main category: cs.LG

TL;DR: CIFNet是一种高效且可持续的类增量学习方法，通过使用预训练的冻结特征提取器、压缩数据缓冲区和单层神经网络，解决了灾难性遗忘问题，同时显著降低了计算开销和训练时间，适用于资源有限的环境。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法在处理灾难性遗忘问题时，通常需要大量的计算资源和复杂的训练过程，尤其是在资源受限的情况下。本研究旨在提出一种高效且可持续的解决方案。

Method: CIFNet结合了预训练的冻结特征提取器、压缩数据缓冲区和高效的单层神经网络进行分类，通过单步优化在固定特征上进行学习，避免了主干网络的微调和多次权重更新。

Result: 在基准数据集上的实验表明，CIFNet能够有效缓解分类器层面的灾难性遗忘，达到与现有最先进方法相当的准确率，同时显著提高了训练效率和可持续性。

Conclusion: CIFNet在资源有限的环境中，尤其是在有强大的预训练特征提取器可用时，使类增量学习更加易于访问和实用，代表了该领域的一个重要进展。

Abstract: Incremental learning remains a critical challenge in machine learning, as
models often struggle with catastrophic forgetting -the tendency to lose
previously acquired knowledge when learning new information. These challenges
are even more pronounced in resource-limited settings. Many existing Class
Incremental Learning (CIL) methods achieve high accuracy by continually
adapting their feature representations; however, they often require substantial
computational resources and complex, iterative training procedures. This work
introduces CIFNet (Class Incremental and Frugal Network), a novel CIL approach
that addresses these limitations by offering a highly efficient and sustainable
solution. CIFNet's key innovation lies in its novel integration of several
existing, yet separately explored, components: a pre-trained and frozen feature
extractor, a compressed data buffer, and an efficient non-iterative one-layer
neural network for classification. A pre-trained and frozen feature extractor
eliminates computationally expensive fine-tuning of the backbone. This,
combined with a compressed buffer for efficient memory use, enables CIFNet to
perform efficient class-incremental learning through a single-step optimization
process on fixed features, minimizing computational overhead and training time
without requiring multiple weight updates. Experiments on benchmark datasets
confirm that CIFNet effectively mitigates catastrophic forgetting at the
classifier level, achieving high accuracy comparable to that of existing
state-of-the-art methods, while substantially improving training efficiency and
sustainability. CIFNet represents a significant advancement in making
class-incremental learning more accessible and pragmatic in environments with
limited resources, especially when strong pre-trained feature extractors are
available.

</details>


### [635] [Opal: An Operator Algebra View of RLHF](https://arxiv.org/abs/2509.11298)
*Madhava Gaikwad*

Main category: cs.LG

TL;DR: Opal是一个基于操作符视角的RLHF框架，它将目标表示为原始效用的加性惩罚和乘性成对权重，并提出了一种简化方法，将这些目标简化为成对边际的正则形式。当条件不满足时，它会识别出不可约的情况。在此基础上，GKPO被提出，这是一个通用的RLHF方法模式，支持JSON序列化、规范化和哈希规则，并能识别和处理不可约的情况。文章还展示了GKPO在DPO、RRHF和ORPO上的应用，包括跨方法转换和压力测试，并提供了一个Python库。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的RLHF（基于人类反馈的强化学习）框架，该框架将目标表示为更基本的构建模块（加性惩罚和乘性权重），以便于分析和理解。

Method: 1. 定义了Opal框架，将RLHF目标表示为加性惩罚和乘性成对权重的组合。 2. 提出了一个简化规则，允许在特定条件下将Opal目标简化为正则形式。 3. 引入了GKPO（广义核偏好对象），一个RLHF方法的通用模式，支持JSON序列化和规范化。 4. 演示了如何将DPO、RRHF和ORPO等方法表示为GKPO模式，并进行了跨方法转换和压力测试。

Result: 1. 提出了一种分析RLHF目标的新视角（Opal）。 2. 发现RLHF目标在特定条件下可以简化为正则形式，否则会出现不可约情况。 3. 提出了GKPO作为RLHF方法的通用模式，并实现了其JSON序列化和规范化。 4. 成功地将DPO、RRHF和ORPO表示为GKPO模式，并进行了转换和测试。

Conclusion: Opal和GKPO提供了一个统一的框架来表示和分析不同的RLHF方法，揭示了它们之间的联系和区别，并为开发新的RLHF算法提供了基础。

Abstract: We present Opal, an operator view of reinforcement learning from human
feedback (RLHF). Objectives are expressed as ladders of two primitives on a
base utility: additive penalties and multiplicative pairwise weights. We
describe a simple reduction law with if-and-only-if conditions: such ladders
collapse to a normal form on pairwise margins when the reference is fixed,
penalties are additive, and weights are independent of intermediate margins.
When these assumptions do not hold (reference shift, non-additive gates,
score-dependent weights), small examples demonstrate non-reducibility.
  Building on this view, we introduce GKPO (Generalized Kernel Preference
Object), a canonical schema in which many RLHF methods can be represented and,
when reducible, mapped back from. GKPO provides a standard JSON serialization,
canonicalization and hashing rules, and explicit flags with finite witnesses
when assumptions fail.
  We illustrate these ideas with GKPO examples for DPO, RRHF, and ORPO, along
with cross-method conversions (where assumptions permit) and minimal stress
tests (SHIFT/GATE/SCORE) that highlight non-reducibility. A lightweight Python
reference library accompanies the schema, implementing canonical hashing and
adapters for DPO and RRHF.

</details>


### [636] [On the Escaping Efficiency of Distributed Adversarial Training Algorithms](https://arxiv.org/abs/2509.11337)
*Ying Cao,Kun Yuan,Ali H. Sayed*

Main category: cs.LG

TL;DR: 本研究比较了多智能体环境中不同的分布式对抗训练算法（中心化与去中心化），并通过理论分析和仿真结果表明，在特定条件下，去中心化算法能更有效地逃离局部最小值，从而获得更平坦的模型，提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提高模型在多智能体学习环境中的鲁棒性，并研究不同分布式对抗训练算法（中心化与去中心化）的性能。

Method: 提出一个通用的理论框架来研究算法从局部最小值中逃逸的效率，并将其与模型平坦度联系起来。通过仿真结果来验证理论发现。

Result: 在扰动边界足够小且批处理大小较大的情况下，去中心化对抗训练算法（包括共识和扩散）比中心化策略能更快地从局部最小值中逃逸，有利于获得更平坦的最小。当扰动边界增大时，此趋势可能不再成立。仿真结果说明了理论发现，并系统地比较了不同算法的性能。

Conclusion: 去中心化策略在分布式设置中具有增强模型鲁棒性的潜力。

Abstract: Adversarial training has been widely studied in recent years due to its role
in improving model robustness against adversarial attacks. This paper focuses
on comparing different distributed adversarial training algorithms--including
centralized and decentralized strategies--within multi-agent learning
environments. Previous studies have highlighted the importance of model
flatness in determining robustness. To this end, we develop a general
theoretical framework to study the escaping efficiency of these algorithms from
local minima, which is closely related to the flatness of the resulting models.
We show that when the perturbation bound is sufficiently small (i.e., when the
attack strength is relatively mild) and a large batch size is used,
decentralized adversarial training algorithms--including consensus and
diffusion--are guaranteed to escape faster from local minima than the
centralized strategy, thereby favoring flatter minima. However, as the
perturbation bound increases, this trend may no longer hold. In the simulation
results, we illustrate our theoretical findings and systematically compare the
performance of models obtained through decentralized and centralized
adversarial training algorithms. The results highlight the potential of
decentralized strategies to enhance the robustness of models in distributed
settings.

</details>


### [637] [BiLSTM-VHP: BiLSTM-Powered Network for Viral Host Prediction](https://arxiv.org/abs/2509.11345)
*Azher Ahmed Efat,Farzana Islam,Annajiat Alim Rasel,Munima Haque*

Main category: cs.LG

TL;DR: BiLSTM-VHP模型能够高精度预测病毒宿主，准确率分别为89.62%（正弓蛔体）、96.58%（A组轮状病毒）和77.22%（狂犬病病毒），优于以往研究。


<details>
  <summary>Details</summary>
Motivation: 动物携带的病毒可能传播给人类，造成人畜共患病。快速准确地预测病毒的宿主传播源，有助于预防疾病传播。

Method: 提出了一种基于双向长短期记忆（LSTM）的轻量级架构BiLSTM-VHP，能够从核苷酸序列预测正弓蛔体、狂犬病病毒和A组轮状病毒的宿主。

Result: BiLSTM-VHP在正弓蛔体、A组轮状病毒和狂犬病病毒上的预测准确率分别为89.62%、96.58%和77.22%，优于以往研究。该模型还使用了混淆矩阵、F1分数、精确率、召回率和microaverage AUC等指标进行评估。

Conclusion: BiLSTM-VHP是一种能够高精度预测病毒宿主的人工智能模型，有望在疾病预防中发挥重要作用。

Abstract: Recorded history shows the long coexistence of humans and animals, suggesting
it began much earlier. Despite some beneficial interdependence, many animals
carry viral diseases that can spread to humans. These diseases are known as
zoonotic diseases. Recent outbreaks of SARS-CoV-2, Monkeypox and swine flu
viruses have shown how these viruses can disrupt human life and cause death.
Fast and accurate predictions of the host from which the virus spreads can help
prevent these diseases from spreading. This work presents BiLSTM-VHP, a
lightweight bidirectional long short-term memory (LSTM)-based architecture that
can predict the host from the nucleotide sequence of orthohantavirus, rabies
lyssavirus, and rotavirus A with high accuracy. The proposed model works with
nucleotide sequences of 400 bases in length and achieved a prediction accuracy
of 89.62% for orthohantavirus, 96.58% for rotavirus A, and 77.22% for rabies
lyssavirus outperforming previous studies. Moreover, performance of the model
is assessed using the confusion matrix, F-1 score, precision, recall,
microaverage AUC. In addition, we introduce three curated datasets of
orthohantavirus, rotavirus A, and rabies lyssavirus containing 8,575, 95,197,
and 22,052 nucleotide sequences divided into 9, 12, and 29 host classes,
respectively. The codes and dataset are available at
https://doi.org/10.17605/OSF.IO/ANFKR

</details>


### [638] [On Linear Mode Connectivity of Mixture-of-Experts Architectures](https://arxiv.org/abs/2509.11348)
*Viet-Hoang Tran,Van Hoan Trinh,Khanh Vinh Bui,Tan M. Nguyen*

Main category: cs.LG

TL;DR: 线性模式连通性（LMC）在神经网络的损失景观中普遍存在，即使是独立训练的模型，也存在参数空间中的线性连接路径，且损失保持不变。本研究将LMC现象扩展到混合专家（MoE）模型，并提出了一种匹配算法来发现MoE中的LMC。


<details>
  <summary>Details</summary>
Motivation: 研究混合专家（MoE）模型中的线性模式连通性（LMC）现象，并提出一种匹配算法来发现它。

Method: 分析MoE模型的对称性，并提出一种匹配算法来对齐独立训练的MoE模型，然后验证LMC的存在。

Result: LMC在各种MoE配置（包括密集、稀疏和共享专家变体）中被经验性地验证。

Conclusion: LMC存在于MoE架构中，并为深度学习模型的函数景观和优化动态提供了基础见解。

Abstract: Linear Mode Connectivity (LMC) is a notable phenomenon in the loss landscapes
of neural networks, wherein independently trained models have been observed to
be connected--up to permutation symmetries--by linear paths in parameter space
along which the loss remains consistently low. This observation challenges
classical views of non-convex optimization and has implications for model
ensembling, generalization, and our understanding of neural loss geometry.
Inspired by recent studies on LMC in standard neural networks, we
systematically investigate this phenomenon within Mixture-of-Experts (MoE)
architectures--a class of models known for their scalability and computational
efficiency, which combine traditional neural networks--referred to as
experts--through a learnable gating mechanism. We begin by conducting a
comprehensive analysis of both dense and sparse gating regimes, demonstrating
that the symmetries inherent to MoE architectures are fully characterized by
permutations acting on both the expert components and the gating function.
Building on these foundational findings, we propose a matching algorithm that
enables alignment between independently trained MoEs, thereby facilitating the
discovery of LMC. Finally, we empirically validate the presence of LMC using
our proposed algorithm across diverse MoE configurations--including dense,
sparse, and shared-expert variants--under a wide range of model settings and
datasets of varying scales and modalities. Our results confirm the existence of
LMC in MoE architectures and offer fundamental insights into the functional
landscape and optimization dynamics of deep learning models.

</details>


### [639] [PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits](https://arxiv.org/abs/2509.11362)
*Loka Li,Wong Yu Kang,Minghao Fu,Guangyi Chen,Zhenhao Chen,Gongxu Luo,Yuewen Sun,Salman Khan,Peter Spirtes,Kun Zhang*

Main category: cs.LG

TL;DR: PersonaX是一个包含名人和运动员的多模态数据集，结合了行为特征、面部属性和传记信息，并提出了一种新颖的因果表示学习框架，用于分析和理解人类行为。


<details>
  <summary>Details</summary>
Motivation: 现有资源缺乏整合了行为描述、面部属性和传记信息的多模态数据集，限制了对人类行为的全面理解。

Method: 构建了包含名人（CelebPersona）和运动员（AthlePersona）的多模态数据集PersonaX。该数据集包含由大型语言模型推断的行为特征、面部图像和传记信息。提出了一种新颖的因果表示学习（CRL）框架，用于处理多模态和多测量数据。

Result: 通过对PersonaX进行分析，包括高层特征评分与统计独立性检验，以及在合成和真实数据上进行的CRL框架实验，验证了该方法的有效性。

Conclusion: PersonaX数据集和提出的CRL框架为研究基于大型语言模型推断的行为特征与视觉和传记属性的结合提供了基础，推动了多模态特征分析和因果推理的发展。

Abstract: Understanding human behavior traits is central to applications in
human-computer interaction, computational social science, and personalized AI
systems. Such understanding often requires integrating multiple modalities to
capture nuanced patterns and relationships. However, existing resources rarely
provide datasets that combine behavioral descriptors with complementary
modalities such as facial attributes and biographical information. To address
this gap, we present PersonaX, a curated collection of multimodal datasets
designed to enable comprehensive analysis of public traits across modalities.
PersonaX consists of (1) CelebPersona, featuring 9444 public figures from
diverse occupations, and (2) AthlePersona, covering 4181 professional athletes
across 7 major sports leagues. Each dataset includes behavioral trait
assessments inferred by three high-performing large language models, alongside
facial imagery and structured biographical features. We analyze PersonaX at two
complementary levels. First, we abstract high-level trait scores from text
descriptions and apply five statistical independence tests to examine their
relationships with other modalities. Second, we introduce a novel causal
representation learning (CRL) framework tailored to multimodal and
multi-measurement data, providing theoretical identifiability guarantees.
Experiments on both synthetic and real-world data demonstrate the effectiveness
of our approach. By unifying structured and unstructured analysis, PersonaX
establishes a foundation for studying LLM-inferred behavioral traits in
conjunction with visual and biographical attributes, advancing multimodal trait
analysis and causal reasoning.

</details>


### [640] [Detecting Model Drifts in Non-Stationary Environment Using Edit Operation Measures](https://arxiv.org/abs/2509.11367)
*Chang-Hwan Lee,Alexander Shim*

Main category: cs.LG

TL;DR: 本研究提出了一种基于行为轨迹分布变化的检测强化学习（RL）环境中模型漂移的方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界的强化学习应用（如医疗、机器人和金融）中，环境动态（转移概率或奖励函数）可能随时间演变，导致模型漂移。需要一种有效的方法来检测这种漂移。

Method: 提出了一种新颖的框架，通过分析智能体行为序列的分布变化来检测模型漂移。具体来说，引入了一套基于编辑操作的度量，用于量化在静态和受扰动条件下生成的状态-动作轨迹之间的偏差。

Result: 实验表明，这些度量即使在不同噪声水平下也能有效地区分漂移和非漂移场景。

Conclusion: 所提出的基于编辑操作的度量可以作为检测非平稳强化学习环境中模型漂移的实用工具。

Abstract: Reinforcement learning (RL) agents typically assume stationary environment
dynamics. Yet in real-world applications such as healthcare, robotics, and
finance, transition probabilities or reward functions may evolve, leading to
model drift. This paper proposes a novel framework to detect such drifts by
analyzing the distributional changes in sequences of agent behavior.
Specifically, we introduce a suite of edit operation-based measures to quantify
deviations between state-action trajectories generated under stationary and
perturbed conditions. Our experiments demonstrate that these measures can
effectively distinguish drifted from non-drifted scenarios, even under varying
levels of noise, providing a practical tool for drift detection in
non-stationary RL environments.

</details>


### [641] [Decoding Musical Origins: Distinguishing Human and AI Composers](https://arxiv.org/abs/2509.11369)
*Cheng-Yang Tsai,Tzu-Wei Huang,Shao-Yu Wei,Guan-Wei Chen,Hung-Ying Chu,Yu-Cheng Lin*

Main category: cs.LG

TL;DR: 本研究提出了一种名为YNote的新型音乐表示法，并利用其训练了一个分类模型，能够区分人类创作、算法生成和LLM生成的音乐，准确率高达98.25%，证明了YNote在保留音乐风格信息方面的有效性，并能识别不同AI生成技术的“技术指纹”。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI驱动的音乐生成领域中，音乐数据表示的挑战，本研究旨在开发一种对机器学习友好的音乐表示法，并利用其构建一个能够区分不同来源（人类、算法、LLM）音乐的分类模型。

Method: 本研究提出了一种名为YNote的新型音乐表示法。然后，将音乐分类问题视为文本分类问题，使用TF-IDF算法从YNote序列中提取特征，并采用SMOTE技术处理数据不平衡问题，最终构建并训练了一个分类模型。

Result: 所提出的分类模型达到了98.25%的准确率，成功区分了人类创作、算法生成和LLM生成的音乐。

Conclusion: YNote表示法保留了足够的音乐风格信息以供分析，并且所构建的模型能够识别不同AI生成技术的独特“技术指纹”，为追溯AI生成内容的来源提供了有效工具。

Abstract: With the rapid advancement of Large Language Models (LLMs), AI-driven music
generation has become a vibrant and fruitful area of research. However, the
representation of musical data remains a significant challenge. To address
this, a novel, machine-learning-friendly music notation system, YNote, was
developed. This study leverages YNote to train an effective classification
model capable of distinguishing whether a piece of music was composed by a
human (Native), a rule-based algorithm (Algorithm Generated), or an LLM (LLM
Generated). We frame this as a text classification problem, applying the Term
Frequency-Inverse Document Frequency (TF-IDF) algorithm to extract structural
features from YNote sequences and using the Synthetic Minority Over-sampling
Technique (SMOTE) to address data imbalance. The resulting model achieves an
accuracy of 98.25%, successfully demonstrating that YNote retains sufficient
stylistic information for analysis. More importantly, the model can identify
the unique " technological fingerprints " left by different AI generation
techniques, providing a powerful tool for tracing the origins of AI-generated
content.

</details>


### [642] [Intelligent Reservoir Decision Support: An Integrated Framework Combining Large Language Models, Advanced Prompt Engineering, and Multimodal Data Fusion for Real-Time Petroleum Operations](https://arxiv.org/abs/2509.11376)
*Seyed Kourosh Mahjour,Seyed Saman Mahjour*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The petroleum industry faces unprecedented challenges in reservoir
management, requiring rapid integration of complex multimodal datasets for
real-time decision support. This study presents a novel integrated framework
combining state-of-the-art large language models (GPT-4o, Claude 4 Sonnet,
Gemini 2.5 Pro) with advanced prompt engineering techniques and multimodal data
fusion for comprehensive reservoir analysis. The framework implements
domain-specific retrieval-augmented generation (RAG) with over 50,000 petroleum
engineering documents, chain-of-thought reasoning, and few-shot learning for
rapid field adaptation. Multimodal integration processes seismic
interpretations, well logs, and production data through specialized AI models
with vision transformers. Field validation across 15 diverse reservoir
environments demonstrates exceptional performance: 94.2% reservoir
characterization accuracy, 87.6% production forecasting precision, and 91.4%
well placement optimization success rate. The system achieves sub-second
response times while maintaining 96.2% safety reliability with no high-risk
incidents during evaluation. Economic analysis reveals 62-78% cost reductions
(mean 72%) relative to traditional methods with 8-month payback period.
Few-shot learning reduces field adaptation time by 72%, while automated prompt
optimization achieves 89% improvement in reasoning quality. The framework
processed real-time data streams with 96.2% anomaly detection accuracy and
reduced environmental incidents by 45%. We provide detailed experimental
protocols, baseline comparisons, ablation studies, and statistical significance
testing to ensure reproducibility. This research demonstrates practical
integration of cutting-edge AI technologies with petroleum domain expertise for
enhanced operational efficiency, safety, and economic performance.

</details>


### [643] [Enhancing ML Models Interpretability for Credit Scoring](https://arxiv.org/abs/2509.11389)
*Sagi Schwartz,Qinling Wang,Fang Fang*

Main category: cs.LG

TL;DR: 提出一种混合方法，结合事后解释和玻璃盒模型，以在保持预测能力和透明度的同时，解决信贷评分中的模型可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 信贷评分中的模型可解释性对于银行的盈利能力和金融稳定至关重要，但现有的机器学习方法缺乏透明度，无法满足监管要求，而后处理解释方法又不够轻量化。

Method: 提出一种混合方法：利用事后解释（如SHAP）指导特征选择，然后训练玻璃盒模型（如EBM、PLTR），以实现高预测能力和高透明度。

Result: 使用Lending Club数据集，该方法在特征数量减少88.5%（仅使用10个特征）的情况下，实现了与基准黑盒模型（XGBoost）相当的性能。

Conclusion: 通过特征交互分析、相关性检查和专家输入进行模型优化，可以进一步提高模型的可解释性和鲁棒性。

Abstract: Predicting default is essential for banks to ensure profitability and
financial stability. While modern machine learning methods often outperform
traditional regression techniques, their lack of transparency limits their use
in regulated environments. Explainable artificial intelligence (XAI) has
emerged as a solution in domains like credit scoring. However, most XAI
research focuses on post-hoc interpretation of black-box models, which does not
produce models lightweight or transparent enough to meet regulatory
requirements, such as those for Internal Ratings-Based (IRB) models.
  This paper proposes a hybrid approach: post-hoc interpretations of black-box
models guide feature selection, followed by training glass-box models that
maintain both predictive power and transparency.
  Using the Lending Club dataset, we demonstrate that this approach achieves
performance comparable to a benchmark black-box model while using only 10
features - an 88.5% reduction. In our example, SHapley Additive exPlanations
(SHAP) is used for feature selection, eXtreme Gradient Boosting (XGBoost)
serves as the benchmark and the base black-box model, and Explainable Boosting
Machine (EBM) and Penalized Logistic Tree Regression (PLTR) are the
investigated glass-box models.
  We also show that model refinement using feature interaction analysis,
correlation checks, and expert input can further enhance model interpretability
and robustness.

</details>


### [644] [From Firewalls to Frontiers: AI Red-Teaming is a Domain-Specific Evolution of Cyber Red-Teaming](https://arxiv.org/abs/2509.11398)
*Anusha Sinha,Keltin Grimes,James Lucassen,Michael Feffer,Nathan VanHoudnos,Zhiwei Steven Wu,Hoda Heidari*

Main category: cs.LG

TL;DR: AI红队应被视为网络红队在AI领域的特定演变，以更好地评估AI系统的漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着企业系统越来越多地采用AI，现有的红队演练需要适应AI系统的独特漏洞和风险。

Method: 主张将AI红队演练视为网络红队演练的领域特定演变，从而利用现有的网络安全框架来评估AI系统。

Result: 将AI红队演练视为网络安全领域演变，可以更好地评估AI系统，识别新的风险和故障模式，并调整披露和缓解策略。它还为AI红队提供了结构、演练规则和工具成熟度。

Conclusion: 融合AI红队和网络红队将创建一个更强大的安全生态系统，使社区能够更好地适应不断变化的威胁格局。

Abstract: A red team simulates adversary attacks to help defenders find effective
strategies to defend their systems in a real-world operational setting. As more
enterprise systems adopt AI, red-teaming will need to evolve to address the
unique vulnerabilities and risks posed by AI systems. We take the position that
AI systems can be more effectively red-teamed if AI red-teaming is recognized
as a domain-specific evolution of cyber red-teaming. Specifically, we argue
that existing Cyber Red Teams who adopt this framing will be able to better
evaluate systems with AI components by recognizing that AI poses new risks, has
new failure modes to exploit, and often contains unpatchable bugs that
re-prioritize disclosure and mitigation strategies. Similarly, adopting a
cybersecurity framing will allow existing AI Red Teams to leverage a
well-tested structure to emulate realistic adversaries, promote mutual
accountability with formal rules of engagement, and provide a pattern to mature
the tooling necessary for repeatable, scalable engagements. In these ways, the
merging of AI and Cyber Red Teams will create a robust security ecosystem and
best position the community to adapt to the rapidly changing threat landscape.

</details>


### [645] [Framing AI System Benchmarking as a Learning Task: FlexBench and the Open MLPerf Dataset](https://arxiv.org/abs/2509.11413)
*Grigori Fursin,Daniel Altunay*

Main category: cs.LG

TL;DR: 现有的AI系统基准测试（如MLPerf）难以跟上AI领域快速发展的步伐，这使得为AI系统的部署、优化和协同设计决策提供信息支持变得困难。我们提出将基准测试本身视为一项AI任务，通过准确性、延迟、吞吐量、能耗和成本等关键指标，在多样化的数据集、软件和硬件上持续评估和优化模型。为此，我们提出了FlexBench：一个MLPerf LLM推理基准测试的模块化扩展，集成了HuggingFace，旨在提供相关且可操作的见解。基准测试结果和元数据被收集到一个开放的MLPerf数据集（Open MLPerf Dataset）中，该数据集可以被协作地管理、扩展，并用于预测建模和特征工程。我们通过MLPerf推理提交成功验证了FlexBench的概念，包括在商用服务器上对DeepSeek R1和LLaMA 3.3的评估。更广泛的目标是使从业者能够做出符合其可用资源、需求和约束的成本效益高的AI部署决策。


<details>
  <summary>Details</summary>
Motivation: 现有的AI系统基准测试（如MLPerf）难以跟上AI领域快速发展的步伐，这使得为AI系统的部署、优化和协同设计决策提供信息支持变得困难。

Method: 提出将基准测试本身视为一项AI任务，通过准确性、延迟、吞吐量、能耗和成本等关键指标，在多样化的数据集、软件和硬件上持续评估和优化模型。提出FlexBench：一个MLPerf LLM推理基准测试的模块化扩展，集成了HuggingFace，旨在提供相关且可操作的见解。将基准测试结果和元数据收集到一个开放的MLPerf数据集（Open MLPerf Dataset）中，该数据集可以被协作地管理、扩展，并用于预测建模和特征工程。

Result: 通过MLPerf推理提交成功验证了FlexBench的概念，包括在商用服务器上对DeepSeek R1和LLaMA 3.3的评估。

Conclusion: FlexBench旨在使从业者能够做出符合其可用资源、需求和约束的成本效益高的AI部署决策。

Abstract: Existing AI system benchmarks such as MLPerf often struggle to keep pace with
the rapidly evolving AI landscape, making it difficult to support informed
deployment, optimization, and co-design decisions for AI systems. We suggest
that benchmarking itself can be framed as an AI task - one in which models are
continuously evaluated and optimized across diverse datasets, software, and
hardware, using key metrics such as accuracy, latency, throughput, energy
consumption, and cost. To support this perspective, we present FlexBench: a
modular extension of the MLPerf LLM inference benchmark, integrated with
HuggingFace and designed to provide relevant and actionable insights.
Benchmarking results and metadata are collected into an Open MLPerf Dataset,
which can be collaboratively curated, extended, and leveraged for predictive
modeling and feature engineering. We successfully validated the FlexBench
concept through MLPerf Inference submissions, including evaluations of DeepSeek
R1 and LLaMA 3.3 on commodity servers. The broader objective is to enable
practitioners to make cost-effective AI deployment decisions that reflect their
available resources, requirements, and constraints.

</details>


### [646] [Long-time dynamics and universality of nonconvex gradient descent](https://arxiv.org/abs/2509.11426)
*Qiyang Han*

Main category: cs.LG

TL;DR: 本文提出了一种刻画非凸梯度下降在广义单索引模型中的长期轨迹行为的通用方法，特别是在大长宽比的条件下。


<details>
  <summary>Details</summary>
Motivation: 研究非凸梯度下降在广义单索引模型中的长期行为，特别是大长宽比下的动力学，并揭示其与数据和特征向量的关系，即‘隐式正则化’效应。

Method: 推导了梯度下降迭代点围绕一个名为‘高斯理论梯度下降’的确定性向量集中的保证，该向量的动力学可以通过一个包含两个标量的递归方程的状态演化系统来追踪。

Result: 证明了在特定条件下，梯度下降迭代点在很大程度上独立于数据且与特征向量不相关。提出了两种回归设置的应用：证明了非凸梯度下降的全局收敛性，并在相位恢复问题中建立了随机初始化梯度下降的普适性；开发了一种数据无关的迭代算法，用于估计整个梯度下降轨迹的状态演化参数。

Conclusion: 在高长宽比下，高斯理论梯度下降与近期提出的关于梯度下降的动力学平均场理论在常数时间范围内是一致的。

Abstract: This paper develops a general approach to characterize the long-time
trajectory behavior of nonconvex gradient descent in generalized single-index
models in the large aspect ratio regime. In this regime, we show that for each
iteration the gradient descent iterate concentrates around a deterministic
vector called the `Gaussian theoretical gradient descent', whose dynamics can
be tracked by a state evolution system of two recursive equations for two
scalars. Our concentration guarantees hold universally for a broad class of
design matrices and remain valid over long time horizons until algorithmic
convergence or divergence occurs. Moreover, our approach reveals that gradient
descent iterates are in general approximately independent of the data and
strongly incoherent with the feature vectors, a phenomenon previously known as
the `implicit regularization' effect of gradient descent in specific models
under Gaussian data.
  As an illustration of the utility of our general theory, we present two
applications of different natures in the regression setting. In the first, we
prove global convergence of nonconvex gradient descent with general independent
initialization for a broad class of structured link functions, and establish
universality of randomly initialized gradient descent in phase retrieval for
large aspect ratios. In the second, we develop a data-free iterative algorithm
for estimating state evolution parameters along the entire gradient descent
trajectory, thereby providing a low-cost yet statistically valid tool for
practical tasks such as hyperparameter tuning and runtime determination.
  As a by-product of our analysis, we show that in the large aspect ratio
regime, the Gaussian theoretical gradient descent coincides with a recent line
of dynamical mean-field theory for gradient descent over the constant-time
horizon.

</details>


### [647] [Tabular Data with Class Imbalance: Predicting Electric Vehicle Crash Severity with Pretrained Transformers (TabPFN) and Mamba-Based Models](https://arxiv.org/abs/2509.11449)
*Shriyank Somvanshi,Pavan Hebli,Gaurab Chhetri,Subasish Das*

Main category: cs.LG

TL;DR: 本研究提出了一个深度表格学习框架，用于利用德克萨斯州（2017-2023）的真实碰撞数据预测电动汽车（EV）碰撞的严重程度。通过筛选仅涉及电动汽车的碰撞记录（23,301条），利用XGBoost和随机森林等特征重要性技术，确定了交叉路口关系、首次碰撞事件、驾驶员年龄、碰撞限速和星期几等关键预测因子，以及自动紧急制动等高级安全功能。为解决类别不平衡问题，采用了SMOTEENN重采样技术。对TabPFN、MambaNet和MambaAttention三种先进的深度表格模型进行了基准测试。结果显示，TabPFN具有良好的泛化能力，而MambaAttention通过其基于注意力的特征重加权机制，在分类严重伤害病例方面表现更优。研究结果强调了深度表格架构在提高碰撞严重程度预测准确性以及在电动汽车碰撞情境下实现数据驱动的安全干预措施方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 使用真实世界数据预测电动汽车碰撞的严重程度，并利用先进的深度表格学习模型来提高预测准确性。

Method: 在筛选出的23,301条电动汽车碰撞记录上，应用XGBoost和随机森林进行特征重要性分析，并使用SMOTEENN处理类别不平衡问题。随后，基准测试了TabPFN、MambaNet和MambaAttention三种深度表格模型。

Result: XGBoost和随机森林确定了交叉路口关系、首次碰撞事件、驾驶员年龄、碰撞限速、星期几以及自动紧急制动等为重要预测因子。MambaAttention在分类严重伤害病例方面表现优于TabPFN和MambaNet。

Conclusion: 深度表格模型，特别是MambaAttention，在预测电动汽车碰撞严重程度方面显示出巨大潜力，有望通过数据驱动的安全干预措施来提高道路安全。

Abstract: This study presents a deep tabular learning framework for predicting crash
severity in electric vehicle (EV) collisions using real-world crash data from
Texas (2017-2023). After filtering for electric-only vehicles, 23,301
EV-involved crash records were analyzed. Feature importance techniques using
XGBoost and Random Forest identified intersection relation, first harmful
event, person age, crash speed limit, and day of week as the top predictors,
along with advanced safety features like automatic emergency braking. To
address class imbalance, Synthetic Minority Over-sampling Technique and Edited
Nearest Neighbors (SMOTEENN) resampling was applied. Three state-of-the-art
deep tabular models, TabPFN, MambaNet, and MambaAttention, were benchmarked for
severity prediction. While TabPFN demonstrated strong generalization,
MambaAttention achieved superior performance in classifying severe injury cases
due to its attention-based feature reweighting. The findings highlight the
potential of deep tabular architectures for improving crash severity prediction
and enabling data-driven safety interventions in EV crash contexts.

</details>


### [648] [Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting](https://arxiv.org/abs/2509.11452)
*Yining Lu,Zilong Wang,Shiyang Li,Xin Liu,Changlong Yu,Qingyu Yin,Zhan Shi,Zixuan Zhang,Meng Jiang*

Main category: cs.LG

TL;DR: Prior works on multi-objective reinforcement learning (MORL) often use fixed linear reward weights, which fail to find optimal trade-offs for non-convex Pareto fronts, a critical issue in aligning large language models (LLMs). This paper introduces dynamic reward weighting to adaptively adjust weights during online training, enabling better exploration of Pareto fronts. Two methods are proposed: hypervolume-guided adaptation and gradient-based optimization. Experiments show these methods improve performance, reduce training steps, and are compatible with various RL algorithms and model families on mathematical reasoning tasks.


<details>
  <summary>Details</summary>
Motivation: The limitation of fixed linear reward scalarization in multi-objective reinforcement learning (MORL), which fails to capture non-convex Pareto fronts and leads to suboptimal results, is particularly critical in the context of online preference alignment for large language models (LLMs). The stochastic nature of LLM policy trajectories creates complex, non-linear mappings from parameters to objectives, making static weighting schemes inadequate for finding optimal trade-offs.

Method: This paper introduces dynamic reward weighting as a solution to the limitations of fixed-weight scalarization in MORL. This approach adaptively adjusts reward weights during the online reinforcement learning process, enabling continuous balancing and prioritization of objectives for effective Pareto front exploration. Two dynamic weighting methods are proposed: 1) hypervolume-guided weight adaptation and 2) gradient-based weight optimization.

Result: Extensive experiments demonstrate that the proposed dynamic reward weighting approaches are compatible with common online reinforcement learning algorithms (GRPO, REINFORCE, RLOO) and applicable to different model families. They consistently achieve Pareto dominant solutions with fewer training steps compared to fixed-weight linear scalarization baselines across multiple mathematical reasoning datasets.

Conclusion: Dynamic reward weighting effectively addresses the limitations of fixed-weight linear scalarization in multi-objective reinforcement learning, particularly for online preference alignment in LLMs. The proposed methods, hypervolume-guided adaptation and gradient-based optimization, offer a versatile toolkit that facilitates better exploration of Pareto fronts, leading to improved performance and efficiency in terms of training steps.

Abstract: Prior works in multi-objective reinforcement learning typically use linear
reward scalarization with fixed weights, which provably fail to capture
non-convex Pareto fronts and thus yield suboptimal results. This limitation
becomes especially critical in online preference alignment for large language
models. Here, stochastic trajectories generated by parameterized policies
create highly non-linear and non-convex mappings from parameters to objectives
that no single static weighting scheme can find optimal trade-offs. We address
this limitation by introducing dynamic reward weighting, which adaptively
adjusts reward weights during the online reinforcement learning process. Unlike
existing approaches that rely on fixed-weight interpolation, our dynamic
weighting continuously balances and prioritizes objectives in training,
facilitating effective exploration of Pareto fronts in objective space. We
introduce two approaches of increasing sophistication and generalizability: (1)
hypervolume-guided weight adaptation and (2) gradient-based weight
optimization, offering a versatile toolkit for online multi-objective
alignment. Our extensive experiments demonstrate their compatibility with
commonly used online reinforcement learning algorithms (including GRPO,
REINFORCE, and RLOO), effectiveness across multiple mathematical reasoning
datasets, and applicability to different model families, consistently achieving
Pareto dominant solutions with fewer training steps than fixed-weight linear
scalarization baselines.

</details>


### [649] [Drug Repurposing Using Deep Embedded Clustering and Graph Neural Networks](https://arxiv.org/abs/2509.11493)
*Luke Delzer,Robert Kroleski,Ali K. AlShami,Jugal Kalita*

Main category: cs.LG

TL;DR: 该研究提出了一种结合深度无监督聚类和图神经网络的机器学习管线，用于从多组学数据中识别新的药物-疾病关联，以克服传统药物再利用的经济障碍和简化数据集的局限性。


<details>
  <summary>Details</summary>
Motivation: 药物再利用在识别废弃药物的新用途方面，在经济上是不可行的。虽然机器学习有所帮助，但许多研究依赖于简化的数据集。本研究旨在通过机器学习克服这些挑战。

Method: 采用无监督深度嵌入聚类结合监督图神经网络链接预测，利用多组学数据识别新的药物-疾病链接。首先，通过无监督自动编码器和聚类训练，将组学数据降维并压缩到潜在嵌入空间。然后，利用图神经网络进行链接预测。

Result: 将9,022种独特药物划分为35个簇，平均轮廓系数为0.8550。图神经网络在预测准确率（0.901）、ROC曲线下面积（0.960）和F1分数（0.901）方面取得了强劲的统计表现。最终生成了一个包含477个簇内链接概率超过99%的列表。

Conclusion: 这项研究有望为不同疾病领域提供新的药物-疾病链接前景，并促进对机器学习在药物再利用研究中应用的理解。

Abstract: Drug repurposing has historically been an economically infeasible process for
identifying novel uses for abandoned drugs. Modern machine learning has enabled
the identification of complex biochemical intricacies in candidate drugs;
however, many studies rely on simplified datasets with known drug-disease
similarities. We propose a machine learning pipeline that uses unsupervised
deep embedded clustering, combined with supervised graph neural network link
prediction to identify new drug-disease links from multi-omic data.
Unsupervised autoencoder and cluster training reduced the dimensionality of
omic data into a compressed latent embedding. A total of 9,022 unique drugs
were partitioned into 35 clusters with a mean silhouette score of 0.8550. Graph
neural networks achieved strong statistical performance, with a prediction
accuracy of 0.901, receiver operating characteristic area under the curve of
0.960, and F1-Score of 0.901. A ranked list comprised of 477 per-cluster link
probabilities exceeding 99 percent was generated. This study could provide new
drug-disease link prospects across unrelated disease domains, while advancing
the understanding of machine learning in drug repurposing studies.

</details>


### [650] [OASIS: A Deep Learning Framework for Universal Spectroscopic Analysis Driven by Novel Loss Functions](https://arxiv.org/abs/2509.11499)
*Chris Young,Juejing Liu,Marie L. Mortensen,Yifu Feng,Elizabeth Li,Zheming Wang,Xiaofeng Guo,Kevin M. Rosso,Xin Zhang*

Main category: cs.LG

TL;DR: OASIS是一个机器学习框架，用于独立于技术地自动分析光谱数据，包括去噪、基线校正和峰值参数检索。


<details>
  <summary>Details</summary>
Motivation: 光谱数据的激增需要自动处理，而现有的方法可能缺乏通用性。

Method: OASIS框架利用在包含多种光谱技术特征的合成数据集上训练的机器学习模型。它使用了为特定任务设计的损失函数（如ViPeR），以实现高效准确的模型。

Result: OASIS在拉曼、紫外-可见光和荧光光谱的实验数据上得到了验证，能够准确地进行光谱分析。

Conclusion: 该研究强调了优化损失函数作为开发高性能机器学习模型的一种经济高效的策略。OASIS在原位实验、高通量优化和在线监测等领域具有巨大潜力。

Abstract: The proliferation of spectroscopic data across various scientific and
engineering fields necessitates automated processing. We introduce OASIS
(Omni-purpose Analysis of Spectra via Intelligent Systems), a machine learning
(ML) framework for technique-independent, automated spectral analysis,
encompassing denoising, baseline correction, and comprehensive peak parameter
(location, intensity, FWHM) retrieval without human intervention. OASIS
achieves its versatility through models trained on a strategically designed
synthetic dataset incorporating features from numerous spectroscopy techniques.
Critically, the development of innovative, task-specific loss functions-such as
the vicinity peak response (ViPeR) for peak localization-enabled the creation
of compact yet highly accurate models from this dataset, validated with
experimental data from Raman, UV-vis, and fluorescence spectroscopy. OASIS
demonstrates significant potential for applications including in situ
experiments, high-throughput optimization, and online monitoring. This study
underscores the optimization of the loss function as a key resource-efficient
strategy to develop high-performance ML models.

</details>


### [651] [Know What You Don't Know: Selective Prediction for Early Exit DNNs](https://arxiv.org/abs/2509.11520)
*Divya Jyoti Bajpai,Manjesh Kumar Hanawal*

Main category: cs.LG

TL;DR: SPEED通过在中间层引入延迟分类器来识别和推迟难以预测的样本，从而在不牺牲准确性的情况下提高早期退出深度神经网络的效率和可信度。


<details>
  <summary>Details</summary>
Motivation: 部署深度神经网络（DNN）在关键任务中存在推理延迟和可信度瓶颈。早期退出（EE）DNN虽然解决了延迟问题，但由于DNN的过度自信，可能导致不准确的早期退出，从而影响EE策略的可信度。

Method: 提出了一种名为SPEED的新方法，该方法在每一层使用延迟分类器（DC）来检查样本的“难易度”，然后再执行EE。DC能识别出在前一中间层难以预测并可能导致幻觉的样本，然后将这些样本推迟给专家进行处理。

Result: 与仅依赖最终层相比，SPEED能将错误预测的风险降低50%，并实现2.05倍的推理速度提升。

Conclusion: 通过引入选择性预测（SP）机制，SPEED在提高DNN推理效率和可信度方面取得了显著成效，同时最小化了错误预测的风险。

Abstract: Inference latency and trustworthiness of Deep Neural Networks (DNNs) are the
bottlenecks in deploying them in critical applications like sensitive tasks.
Early Exit (EE) DNNs overcome the latency issues by allowing samples to exit
from intermediary layers if they attain `high' confidence scores on the
predicted class. However, the DNNs are known to exhibit overconfidence, which
can lead to many samples exiting early and render EE strategies untrustworthy.
We use Selective Prediction (SP) to overcome this issue by checking the
`hardness' of the samples rather than just relying on the confidence score
alone. We propose SPEED, a novel approach that uses Deferral Classifiers (DCs)
at each layer to check the hardness of samples before performing EEs.
Specifically, the DCs identify if a sample is hard to predict at an
intermediary layer, leading to hallucination, and defer it to an expert. Early
detection of hard samples for inference prevents the wastage of computational
resources and improves trust by deferring the hard samples to the expert. We
demonstrate that EE aided with SP improves both accuracy and latency. Our
method minimizes the risk of wrong prediction by $50\%$ with a speedup of
$2.05\times$ as compared to the final layer. The anonymized source code is
available at https://github.com/Div290/SPEED

</details>


### [652] [Measuring Visual Understanding in Telecom domain: Performance Metrics for Image-to-UML conversion using VLMs](https://arxiv.org/abs/2509.11667)
*HG Ranjani,Rutuja Prabhudesai*

Main category: cs.LG

TL;DR: 该论文提出了一种评估电信领域3GPP文档中序列图图像到PlantUML格式转换的新方法，并使用Claude Sonnet和GPT-4V进行实验，发现在复杂结构（如注释、框、组）的转换上存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法缺乏对序列图转换各组件的比较，因此需要提出新的性能指标来衡量转换的有效性。

Method: 选择3GPP文档中的序列图数据集，将其转换为PlantUML格式，并使用版本控制工具比较两个VLM（Claude Sonnet和GPT-4V）的输出与手动创建的真实表示。引入了衡量参与者识别、消息流准确性、序列排序和分组结构保留的标准性能指标。

Result: 实验表明，节点、边和消息的捕获准确度高，但在注释、框、组等复杂结构的转换上，VLM的表现不佳。

Conclusion: 提出的性能指标能够量化Puml脚本各组件的转换错误。实验结果表明，VLM在复杂结构方面的不足，暗示了在微调VLM的训练数据中需要对这些组件进行更好的表示。

Abstract: Telecom domain 3GPP documents are replete with images containing sequence
diagrams. Advances in Vision-Language Large Models (VLMs) have eased conversion
of such images to machine-readable PlantUML (puml) formats. However, there is a
gap in evaluation of such conversions - existing works do not compare puml
scripts for various components. In this work, we propose performance metrics to
measure the effectiveness of such conversions. A dataset of sequence diagrams
from 3GPP documents is chosen to be representative of domain-specific actual
scenarios. We compare puml outputs from two VLMs - Claude Sonnet and GPT-4V -
against manually created ground truth representations. We use version control
tools to capture differences and introduce standard performance metrics to
measure accuracies along various components: participant identification,
message flow accuracy, sequence ordering, and grouping construct preservation.
We demonstrate effectiveness of proposed metrics in quantifying conversion
errors across various components of puml scripts. The results show that nodes,
edges and messages are accurately captured. However, we observe that VLMs do
not necessarily perform well on complex structures such as notes, box, groups.
Our experiments and performance metrics indicates a need for better
representation of these components in training data for fine-tuned VLMs.

</details>


### [653] [DARD: Dice Adversarial Robustness Distillation against Adversarial Attacks](https://arxiv.org/abs/2509.11525)
*Jing Zou,Shungeng Zhang,Meikang Qiu,Chong Li*

Main category: cs.LG

TL;DR: 大型模型可以将其对对抗性攻击的鲁棒性蒸馏到小型模型中，而DARD方法可以在不牺牲准确性的情况下实现这一点。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型容易受到对抗性攻击，这在实际应用中带来了严峻的安全挑战。虽然对抗性训练（AT）是提高鲁棒性的常用方法，但它通常会以牺牲在无扰动、自然数据上的性能为代价。

Method: 提出了一种名为Dice Adversarial Robustness Distillation (DARD) 的新方法，通过定制的知识蒸馏范式来迁移鲁棒性。此外，还提出了一种名为Dice Projected Gradient Descent (DPGD) 的对抗性示例泛化方法，以实现有效的攻击。

Result: 实验证明，DARD 方法在具有相同架构的对抗性训练网络上始终表现更好，在鲁棒性和标准准确性方面均表现出色。

Conclusion: DARD 是一种有效的方法，可以将大型模型的鲁棒性蒸馏到小型模型中，同时保持高准确性。

Abstract: Deep learning models are vulnerable to adversarial examples, posing critical
security challenges in real-world applications. While Adversarial Training (AT
) is a widely adopted defense mechanism to enhance robustness, it often incurs
a trade-off by degrading performance on unperturbed, natural data. Recent
efforts have highlighted that larger models exhibit enhanced robustness over
their smaller counterparts. In this paper, we empirically demonstrate that such
robustness can be systematically distilled from large teacher models into
compact student models. To achieve better performance, we introduce Dice
Adversarial Robustness Distillation (DARD), a novel method designed to transfer
robustness through a tailored knowledge distillation paradigm. Additionally, we
propose Dice Projected Gradient Descent (DPGD), an adversarial example
generalization method optimized for effective attack. Our extensive experiments
demonstrate that the DARD approach consistently outperforms adversarially
trained networks with the same architecture, achieving superior robustness and
standard accuracy.

</details>


### [654] [Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning](https://arxiv.org/abs/2509.11816)
*Filip Sondej,Yushi Yang*

Main category: cs.LG

TL;DR: 当前模型安全训练方法无法有效移除模型中的危险知识，本文提出一种选择性方法，可在不影响模型泛化能力的情况下，鲁棒地移除危险知识。


<details>
  <summary>Details</summary>
Motivation: 现有模型安全训练方法未能有效去除语言模型中的危险知识。

Method: 通过对激活和模块输出梯度执行主成分分析（PCA）来识别包含常见表示的子空间，并在计算移除更新之前对其进行压缩，从而避免移除通用表示，仅针对与待移除事实相关的特定表示。

Result: 在从 Llama-3.1-8B 模型中移除 WMDP 数据集的事实时，与现有最佳基线（Circuit Breakers）相比，在生物危害和网络危害事实的移除准确率上分别提高了 80 倍和 30 倍。同时，对模型泛化能力的影响减小了 30 倍（WikiText 损失仅增加 0.1%），且移除每个事实的计算成本低于 3 毫秒。

Conclusion: 所提出的选择性方法能够高效且鲁棒地移除模型中的危险知识，同时最大限度地减少对模型泛化能力的影响。

Abstract: Current unlearning techniques and safety training consistently fail to remove
dangerous knowledge from language models. We analyze the root causes and
propose a highly selective technique which unlearns robustly and without
disrupting general performance.
  We perform PCA on activations and module output gradients to identify
subspaces containing common representations, and collapse them before
calculating unlearning updates. This way we avoid unlearning general
representations, and only target those specific to the unlearned facts.
  When unlearning WMDP dataset facts from Llama-3.1-8B, we drop post-attack
accuracy 80x more than our best baseline (Circuit Breakers) on biohazardous
facts and 30x more on cyberhazardous facts. Despite this, we disrupt general
performance 30x less (only 0.1% WikiText loss increase), while requiring less
than 3 GPU-seconds per fact.

</details>


### [655] [UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning](https://arxiv.org/abs/2509.11543)
*Zhengxi Lu,Jiabo Ye,Fei Tang,Yongliang Shen,Haiyang Xu,Ziwei Zheng,Weiming Lu,Ming Yan,Fei Huang,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: 提出了一种新的半在线强化学习范式，通过模拟在线强化学习在离线轨迹上进行训练，以解决现有离线强化学习在多步任务执行中缺乏轨迹级奖励信号和在线强化学习中奖励稀疏及部署成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习方法在多步任务执行中缺乏轨迹级奖励信号，而在线强化学习方法存在奖励稀疏和部署成本高昂的问题，需要一种新的方法来平衡训练效率和在线性能。

Method: 提出半在线强化学习（Semi-online RL），该方法在离线轨迹上模拟在线强化学习。通过引入一个Patch Module来适应性地恢复滚动轨迹与专家轨迹之间的差异，并结合折扣未来回报和加权步级及回合级优势来优化策略。

Result: 在四个动态基准测试中，半在线强化学习（Semi-online RL）在7B模型中取得了最先进的性能，在AndroidWorld上提高了12.0%，在AITW上提高了23.8%，显著缩小了离线训练效率与在线多轮推理之间的差距。

Conclusion: 半在线强化学习（Semi-online RL）是一种有效的方法，可以提高GUI代理在复杂交互任务中的性能，并且提出的半在线性能（SOP）指标能更好地评估真实在线性能。

Abstract: Graphical User Interface (GUI) agents have demonstrated remarkable progress
in automating complex user interface interactions through reinforcement
learning. However, current approaches face a fundamental dilemma: offline RL
enables stable training on pre-collected trajectories, but struggles with
multi-step task execution for lack of trajectory-level reward signals; online
RL captures these signals through environment interaction, but suffers from
sparse rewards and prohibitive deployment costs. To address it, we present
Semi-online Reinforcement Learning, a novel paradigm that simulates online RL
on offline trajectories. During each rollout process, we preserve the original
model output within the multi-turn dialogue, where a Patch Module adaptively
recovers the divergence between rollout and expert trajectories. To capture
long-term training signals, Semi-online RL introduces discounted future returns
into the reward computation and optimizes the policy with weighted step-level
and episode-level advantages. We further introduce Semi-Online Performance
(SOP), a metric that aligns better with true online performance, serving as a
practical and effective proxy for real-world evaluation. Experiments show that
ours Semi-online RL achieves SOTA performance among 7B models across four
dynamic benchmarks, with significant gains over the base model (e.g., +12.0% on
AndroidWorld, +23.8% on AITW), demonstrating significant progress in bridging
the gap between offline training efficiency and online multi-turn reasoning.
The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1.

</details>


### [656] [Compressed Sensing: Mathematical Foundations, Implementation, and Advanced Optimization Techniques](https://arxiv.org/abs/2509.11550)
*Shane Stevenson,Maryam Sabagh*

Main category: cs.LG

TL;DR: 压缩感知是一种信号处理技术，允许从少量测量中重建信号。


<details>
  <summary>Details</summary>
Motivation: 探索压缩感知的数学原理、逻辑和病理，并将其应用于现实世界信号。

Method: 阐述压缩感知的数学基础，探讨其逻辑和局限性，并进行实际应用。

Result: 应用压缩感知技术处理现实世界信号。

Conclusion: 对压缩感知的原理、应用及其在现实世界信号处理中的作用进行总结。

Abstract: Compressed sensing is a signal processing technique that allows for the
reconstruction of a signal from a small set of measurements. The key idea
behind compressed sensing is that many real-world signals are inherently
sparse, meaning that they can be efficiently represented in a different space
with only a few components compared to their original space representation. In
this paper we will explore the mathematical formulation behind compressed
sensing, its logic and pathologies, and apply compressed sensing to real world
signals.

</details>


### [657] [MillStone: How Open-Minded Are LLMs?](https://arxiv.org/abs/2509.11967)
*Harold Triedman,Vitaly Shmatikov*

Main category: cs.LG

TL;DR: 大型语言模型（LLM）在处理有争议问题时，其立场会受到所用信息来源的影响。MillStone基准测试首次系统地衡量了外部论据对LLM立场的影响，并评估了LLM的“开放心态”、LLM之间的一致性以及哪些论据对它们最具说服力。研究发现，LLM对大多数问题持开放态度，并且容易被权威信息源所左右，这凸显了信源选择的重要性以及LLM信息检索系统被操纵的风险。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在处理有争议问题时，其立场如何受到信息来源的影响，以及LLM的‘开放心态’、一致性及对论据的敏感度。

Method: 提出MillStone基准测试，系统性地衡量外部论据对LLM在有争议问题上立场的‘开放心态’。将MillStone应用于九个领先的LLM，分析它们对相反论据的接受程度、LLM之间的一致性、哪些论据最具说服力以及不同LLM是否具有相同的偏好。

Result: 研究发现，LLM对大多数问题持开放态度，权威信息源可以轻易地改变LLM的立场。

Conclusion: LLM的立场极易受到其信息来源的影响，因此在LLM信息检索和搜索系统中，信源的选择至关重要，并且存在被操纵的风险。

Abstract: Large language models equipped with Web search, information retrieval tools,
and other agentic capabilities are beginning to supplant traditional search
engines. As users start to rely on LLMs for information on many topics,
including controversial and debatable issues, it is important to understand how
the stances and opinions expressed in LLM outputs are influenced by the
documents they use as their information sources.
  In this paper, we present MillStone, the first benchmark that aims to
systematically measure the effect of external arguments on the stances that
LLMs take on controversial issues (not all of them political). We apply
MillStone to nine leading LLMs and measure how ``open-minded'' they are to
arguments supporting opposite sides of these issues, whether different LLMs
agree with each other, which arguments LLMs find most persuasive, and whether
these arguments are the same for different LLMs.
  In general, we find that LLMs are open-minded on most issues. An
authoritative source of information can easily sway an LLM's stance,
highlighting the importance of source selection and the risk that LLM-based
information retrieval and search systems can be manipulated.

</details>


### [658] [Dynamic Adaptive Parsing of Temporal and Cross-Variable Patterns for Network State Classification](https://arxiv.org/abs/2509.11601)
*Yuan Gao,Xuelong Wang,Zhenguo Dong,Yong Zhang*

Main category: cs.LG

TL;DR: DAPNet是一个新的网络状态分类框架，通过结合时间周期分析、跨变量依赖建模和混合时间特征提取，解决了现有模型在同时捕捉这两种特征时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在网络状态分类方面取得了进展，但它们在同时捕捉复杂的时间周期性和变量间的动态依赖性方面存在权衡。专注于时间模式的模型可能忽略变量依赖性，而专注于依赖性的模型可能无法捕捉细微的时间细节。为了解决这个权衡问题，需要一种能够同时处理这两种特征的模型。

Method: 提出了一种基于混合专家（Mixture-of-Experts）架构的DAPNet框架。该框架集成了三个专门的网络，分别用于：1. 周期性分析；2. 动态跨变量相关性建模；3. 混合时间特征提取。一个可学习的门控网络根据输入样本动态地为专家分配权重，并计算其输出的加权融合。此外，还采用了一个混合正则化损失函数来确保训练稳定并处理类别不平衡问题。

Result: 在两个大规模网络入侵检测数据集（CICIDS2017/2018）上的广泛实验证明了DAPNet比现有方法具有更高的准确性。在十个公开的UEA基准数据集上的评估显示了该架构设计的通用性。

Conclusion: DAPNet通过结合多种专家网络和创新的训练策略，有效地解决了网络状态分类中同时捕捉时间特征和依赖性特征的挑战，并在多个数据集上取得了优越的性能，证明了其作为网络状态分类专用框架的有效性。

Abstract: Effective network state classification is a primary task for ensuring network
security and optimizing performance. Existing deep learning models have shown
considerable progress in this area. Some methods excel at analyzing the complex
temporal periodicities found in traffic data, while graph-based approaches are
adept at modeling the dynamic dependencies between different variables.
However, a key trade-off remains, as these methods struggle to capture both
characteristics simultaneously. Models focused on temporal patterns often
overlook crucial variable dependencies, whereas those centered on dependencies
may fail to capture fine-grained temporal details. To address this trade-off,
we introduce DAPNet, a framework based on a Mixture-of-Experts architecture.
DAPNet integrates three specialized networks for periodic analysis, dynamic
cross-variable correlation modeling, and hybrid temporal feature extraction. A
learnable gating network dynamically assigns weights to experts based on the
input sample and computes a weighted fusion of their outputs. Furthermore, a
hybrid regularization loss function ensures stable training and addresses the
common issue of class imbalance. Extensive experiments on two large-scale
network intrusion detection datasets (CICIDS2017/2018) validate DAPNet's higher
accuracy for its target application. The generalizability of the architectural
design is evaluated across ten public UEA benchmark datasets, positioning
DAPNet as a specialized framework for network state classification.

</details>


### [659] [Topology Structure Optimization of Reservoirs Using GLMY Homology](https://arxiv.org/abs/2509.11612)
*Yu Chen,Shengwei Wang,Hongwei Lin*

Main category: cs.LG

TL;DR: 该研究使用持久同调理论分析了水库网络的拓扑结构，发现其性能与一维同调群相关，并通过优化该结构来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的水库网络在处理时间序列数据方面效率很高，但其性能受到网络结构的影响，而网络结构又难以分析，缺乏合适的数学工具。

Method: 利用持久同调理论研究水库网络的拓扑结构，并开发了一种改进其性能的方法。具体来说，研究发现水库网络的性能与一维同调群密切相关，然后通过修改一维同调群的最小代表循环来开发一种水库结构优化方法。

Result: 实验结果表明，水库网络的性能同时受到水库结构和数据集周期性的共同影响。

Conclusion: 水库网络的性能与一维同调群密切相关，可以通过优化一维同调群的最小代表循环来提升水库网络的性能，并且该性能受到数据集周期性的影响。

Abstract: Reservoir is an efficient network for time series processing. It is well
known that network structure is one of the determinants of its performance.
However, the topology structure of reservoirs, as well as their performance, is
hard to analyzed, due to the lack of suitable mathematical tools. In this
paper, we study the topology structure of reservoirs using persistent GLMY
homology theory, and develop a method to improve its performance. Specifically,
it is found that the reservoir performance is closely related to the
one-dimensional GLMY homology groups. Then, we develop a reservoir structure
optimization method by modifying the minimal representative cycles of
one-dimensional GLMY homology groups. Finally, by experiments, it is validated
that the performance of reservoirs is jointly influenced by the reservoir
structure and the periodicity of the dataset.

</details>


### [660] [AMQ: Enabling AutoML for Mixed-precision Weight-Only Quantization of Large Language Models](https://arxiv.org/abs/2509.12019)
*Sangjun Lee,Seung-taek Woo,Jungyu Jin,Changhun Lee,Eunhyeok Park*

Main category: cs.LG

TL;DR: AMQ是一种自动化混合精度量化框架，用于在内存限制下优化大型语言模型（LLM）的性能和内存占用。它通过剪枝搜索空间、使用量化代理、质量预测器和迭代搜索策略来克服巨大的配置空间，从而高效地找到最优的量化方案。


<details>
  <summary>Details</summary>
Motivation: 为了在严格的内存限制下实现大型语言模型（LLM）的广泛部署，需要识别性能最佳的模型。

Method: AMQ（Automated Mixed-Precision Weight-Only Quantization）框架通过以下四个关键创新来解决巨大的搜索空间问题：1. 利用先验知识进行搜索空间剪枝，排除不佳配置；2. 使用量化代理绕过搜索过程中昂贵的格式转换；3. 引入质量预测器以减少评估开销；4. 采用迭代搜索和更新策略以实现快速稳定的收敛。

Result: AMQ框架能够高效地探索质量-效率的权衡空间，达到帕累托前沿，并生成既紧凑又高性能的LLM。

Conclusion: AMQ框架通过其创新的搜索策略和优化技术，能够有效地在内存和性能之间取得平衡，为部署大型语言模型提供了可行的解决方案。

Abstract: To enable broader deployment of Large Language Models (LLMs), it is essential
to identify the best-performing model under strict memory constraints. We
present AMQ, Automated Mixed-Precision Weight-Only Quantization, a framework
that assigns layer-wise quantization bit-widths to optimally balance model
quality and memory usage. However, the combinatorial search space, with over
10^{100} possible configurations, makes conventional black-box optimization
infeasible. AMQ overcomes this challenge through four key innovations:(1)
search space pruning using prior knowledge to exclude unpromising
configurations, (2) quantization proxy to bypass costly format conversions
during search, (3) quality predictor to minimize evaluation overhead, and (4)
iterative search-and-update strategy for fast and stable convergence. By
integrating these components, AMQ efficiently explores the quality-efficiency
landscape, reaching the Pareto frontier and yielding LLMs that are both compact
and high-performing. Our code is available at https://github.com/dlwns147/amq.

</details>


### [661] [Inducing Uncertainty for Test-Time Privacy](https://arxiv.org/abs/2509.11625)
*Muhammad H. Ashiq,Peter Triantafillou,Hung Yun Tseng,Grigoris G. Chrysos*

Main category: cs.LG

TL;DR: 即使在数据被遗忘后，机器学习模型仍可能对被遗忘的数据做出自信的预测，从而被对手利用。本文提出了一种通过扰动模型权重来诱导对受保护实例的最大不确定性，同时保持模型准确性的算法，以应对测试时间隐私威胁。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘方法在模型遗忘数据后，仍可能对被遗忘的数据做出自信的预测，这种测试时间隐私威胁可能被对手利用来损害用户。然而，现有的防御措施容易被绕过。

Method: 提出一种基于微调的算法，该算法采用帕累托最优目标来平衡测试时间隐私和模型效用。此外，还提供了一种可认证的近似算法，在无凸性假设下实现$(\varepsilon, \delta)$保证。并证明了该算法隐私-效用权衡的紧边界。

Result: 在图像识别基准测试中，提出的方法比预训练方法获得了超过3倍的更强不确定性，同时准确性下降不到0.2%。

Conclusion: 该框架为最终用户提供了额外的保护工具，以应对测试时间隐私威胁。

Abstract: Unlearning is the predominant method for removing the influence of data in
machine learning models. However, even after unlearning, models often continue
to produce the same predictions on the unlearned data with high confidence.
This persistent behavior can be exploited by adversaries using confident model
predictions on incorrect or obsolete data to harm users. We call this threat
model, which unlearning fails to protect against, *test-time privacy*. In
particular, an adversary with full model access can bypass any naive defenses
which ensure test-time privacy. To address this threat, we introduce an
algorithm which perturbs model weights to induce maximal uncertainty on
protected instances while preserving accuracy on the rest of the instances. Our
core algorithm is based on finetuning with a Pareto optimal objective that
explicitly balances test-time privacy against utility. We also provide a
certifiable approximation algorithm which achieves $(\varepsilon, \delta)$
guarantees without convexity assumptions. We then prove a tight, non-vacuous
bound that characterizes the privacy-utility tradeoff that our algorithms
incur. Empirically, our method obtains $>3\times$ stronger uncertainty than
pretraining with $<0.2\%$ drops in accuracy on various image recognition
benchmarks. Altogether, this framework provides a tool to guarantee additional
protection to end users.

</details>


### [662] [SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching](https://arxiv.org/abs/2509.11628)
*Jiacheng Liu,Chang Zou,Yuanhuiyi Lyu,Fei Ren,Shaobo Wang,Kaixin Li,Linfeng Zhang*

Main category: cs.LG

TL;DR: SpeCa通过引入“推测式采样”和“样本自适应计算分配”，在不显著牺牲图像/视频生成质量的前提下，实现了扩散模型6倍以上的加速。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型因其严格的时间依赖性和计算密集的前向传播，难以满足实时应用的需求。

Method: SpeCa框架采用“先预测后验证”的策略，通过推测式采样预测中间特征，并引入参数无关的验证机制来高效评估预测的可靠性，同时根据生成复杂度动态分配计算资源。

Result: 在FLUX数据集上实现了6.34倍加速，质量下降5.5%；在DiT上实现了7.3倍加速，保持了生成保真度；在HunyuanVideo上以6.1倍加速获得了79.84%的VBench得分。验证机制的开销仅占完整推理成本的1.67%-3.5%。

Conclusion: SpeCa为扩散模型的推理提供了一种新的高效范式，即使在较高的加速比下也能保持生成质量，解决了实时应用中的计算瓶颈。

Abstract: Diffusion models have revolutionized high-fidelity image and video synthesis,
yet their computational demands remain prohibitive for real-time applications.
These models face two fundamental challenges: strict temporal dependencies
preventing parallelization, and computationally intensive forward passes
required at each denoising step. Drawing inspiration from speculative decoding
in large language models, we present SpeCa, a novel 'Forecast-then-verify'
acceleration framework that effectively addresses both limitations. SpeCa's
core innovation lies in introducing Speculative Sampling to diffusion models,
predicting intermediate features for subsequent timesteps based on fully
computed reference timesteps. Our approach implements a parameter-free
verification mechanism that efficiently evaluates prediction reliability,
enabling real-time decisions to accept or reject each prediction while
incurring negligible computational overhead. Furthermore, SpeCa introduces
sample-adaptive computation allocation that dynamically modulates resources
based on generation complexity, allocating reduced computation for simpler
samples while preserving intensive processing for complex instances.
Experiments demonstrate 6.34x acceleration on FLUX with minimal quality
degradation (5.5% drop), 7.3x speedup on DiT while preserving generation
fidelity, and 79.84% VBench score at 6.1x acceleration for HunyuanVideo. The
verification mechanism incurs minimal overhead (1.67%-3.5% of full inference
costs), establishing a new paradigm for efficient diffusion model inference
while maintaining generation quality even at aggressive acceleration ratios.
Our codes have been released in Github:
\textbf{https://github.com/Shenyi-Z/Cache4Diffusion}

</details>


### [663] [Reasoned Safety Alignment: Ensuring Jailbreak Defense via Answer-Then-Check](https://arxiv.org/abs/2509.11629)
*Chentao Cao,Xiaojun Xu,Bo Han,Hang Li*

Main category: cs.LG

TL;DR: 提出Answer-Then-Check方法，通过先回答再进行安全检查来增强LLM的安全性，并构建了ReSA数据集进行训练，实验表明该方法在提高安全性的同时降低了误拒绝率，并且在推理能力和安全续写方面也有提升，同时发现少量数据即可达到良好效果。


<details>
  <summary>Details</summary>
Motivation: 确保LLM在能力不断增强的同时，能够抵御“越狱”攻击，保持安全性。

Method: 提出Answer-Then-Check（ATC）方法，首先让模型思考并生成直接回答，然后对其安全性进行评估，最后决定是否将回答提供给用户。为了实现这一方法，构建了包含80K个样本的Reasoned Safety Alignment（ReSA）数据集，用于训练模型进行推理和安全分析。

Result: ATC方法在安全能力上达到了帕累托最优，并降低了在误拒绝基准上的误拒绝率。使用ReSA训练的模型在MMLU、MATH500和HumanEval等基准上保持了通用推理能力。此外，该方法还能提供对敏感话题（如自残）的安全替代回应。实验还发现，仅使用500个样本的子集训练即可获得与使用完整数据集相当的性能。

Conclusion: Answer-Then-Check是一种有效的方法，可以提高LLM应对“越狱”攻击的能力，同时保持其推理能力和通用性。该方法在提高安全性的同时，还能减少不必要的拒绝。此外，研究表明，安全对齐可能比之前认为的需要更少的数据。

Abstract: As large language models (LLMs) continue to advance in capabilities, ensuring
their safety against jailbreak attacks remains a critical challenge. In this
paper, we introduce a novel safety alignment approach called Answer-Then-Check,
which enhances LLM robustness against malicious prompts by applying thinking
ability to mitigate jailbreaking problems before producing a final answer to
the user. Our method enables models to directly answer the question in their
thought and then critically evaluate its safety before deciding whether to
provide it. To implement this approach, we construct the Reasoned Safety
Alignment (ReSA) dataset, comprising 80K examples that teach models to reason
through direct responses and then analyze their safety. Experimental results
demonstrate that our approach achieves the Pareto frontier with superior safety
capability while decreasing over-refusal rates on over-refusal benchmarks.
Notably, the model fine-tuned with ReSA maintains general reasoning
capabilities on benchmarks like MMLU, MATH500, and HumanEval. Besides, our
method equips models with the ability to perform safe completion. Unlike
post-hoc methods that can only reject harmful queries, our model can provide
helpful and safe alternative responses for sensitive topics (e.g., self-harm).
Furthermore, we discover that training on a small subset of just 500 examples
can achieve comparable performance to using the full dataset, suggesting that
safety alignment may require less data than previously assumed.

</details>


### [664] [Adaptive-GraphSketch: Real-Time Edge Anomaly Detection via Multi-Layer Tensor Sketching and Temporal Decay](https://arxiv.org/abs/2509.11633)
*Ocheme Anthony Ekle,William Eberle*

Main category: cs.LG

TL;DR: ADAPTIVE-GRAPHSKETCH是一个用于流式边缘数据的实时异常检测框架，它使用张量草图和贝叶斯推断来提高准确性和适应性，并在真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 动态图中的异常检测对于识别网络安全和电力网等现实世界系统中的恶意活动、欺诈和意外行为至关重要，但现有方法在可扩展性、概率可解释性和对不断变化的流量模式的适应性方面存在挑战。

Method: 该方法整合了时间多张量草图和使用保守更新的计数最小草图（CMS-CU），以在有界内存中紧凑地跟踪边缘频率模式，同时减轻哈希冲突问题。它还结合了贝叶斯推断进行概率异常评分，并应用指数加权移动平均（EWMA）进行自适应阈值设定，以适应突发强度。

Result: 在四个真实世界的入侵检测数据集上的大量实验表明，ADAPTIVE-GRAPHSKETCH 的性能优于 ANOEDGE/L、MIDAS-R 和 F-FADE 等最先进的基线，在 CIC-IDS2018 上 AUC 提高了 6.5%，在 CIC-DDoS2019 上提高了 15.6%，同时使用 10 个哈希函数在 3.4 秒内处理了 2000 万个边缘。

Conclusion: ADAPTIVE-GRAPHSKETCH 是一种实用且有效的用于大规模流图的快速、准确的异常检测方法。

Abstract: Anomaly detection in dynamic graphs is essential for identifying malicious
activities, fraud, and unexpected behaviors in real-world systems such as
cybersecurity and power grids. However, existing approaches struggle with
scalability, probabilistic interpretability, and adaptability to evolving
traffic patterns. In this paper, we propose ADAPTIVE-GRAPHSKETCH, a lightweight
and scalable framework for real-time anomaly detection in streaming edge data.
Our method integrates temporal multi-tensor sketching with Count-Min Sketch
using Conservative Update (CMS-CU) to compactly track edge frequency patterns
with bounded memory, while mitigating hash collision issues. We incorporate
Bayesian inference for probabilistic anomaly scoring and apply Exponentially
Weighted Moving Average (EWMA) for adaptive thresholding tuned to burst
intensity. Extensive experiments on four real-world intrusion detection
datasets demonstrate that ADAPTIVE-GRAPHSKETCH outperforms state-of-the-art
baselines such as ANOEDGE-G/L, MIDAS-R, and F-FADE, achieving up to 6.5% AUC
gain on CIC-IDS2018 and up to 15.6% on CIC-DDoS2019, while processing 20
million edges in under 3.4 seconds using only 10 hash functions. Our results
show that ADAPTIVE-GRAPHSKETCH is practical and effective for fast, accurate
anomaly detection in large-scale streaming graphs.
  Keywords: Anomaly Detection, Streaming, Real-time, Dynamic Graphs, Edge
Streams, Tensor Sketching

</details>


### [665] [Event2Vec: A Geometric Approach to Learning Composable Representations of Event Sequences](https://arxiv.org/abs/2509.12188)
*Antonin Sulc*

Main category: cs.LG

TL;DR: Event2Vec是一个用于学习离散事件序列表示的新框架，它利用简单的递归结构学习可组合、可解释的嵌入，并在欧几里得和双曲空间中进行实验，以验证其线性和分层表示能力。


<details>
  <summary>Details</summary>
Motivation: 受生物和人工智能系统中几何和拓扑结构在神经表征中日益增长的重要性启发，本研究旨在开发一种新的框架来学习离散事件序列的表征。

Method: Event2Vec利用一个简单的、可加的递归结构来学习可组合的、可解释的嵌入。该模型在欧几里得空间中进行理论分析，证明其学习到的表征收敛于一个理想的可加结构（即序列的表征等于其组成事件的向量和），并引入了一个在双曲空间中的变体，以更好地处理具有层次结构的数据。

Result: 实验证明了Event2Vec的线性和分层表示能力，并且在处理分层事件序列时，双曲空间模型表现出更优越的性能。

Conclusion: Event2Vec框架能够学习离散事件序列的表示，并且其欧几里得和双曲空间变体在处理不同类型事件序列方面具有各自的优势，特别是双曲空间模型在处理分层数据时效果更佳。

Abstract: The study of neural representations, both in biological and artificial
systems, is increasingly revealing the importance of geometric and topological
structures. Inspired by this, we introduce Event2Vec, a novel framework for
learning representations of discrete event sequences. Our model leverages a
simple, additive recurrent structure to learn composable, interpretable
embeddings. We provide a theoretical analysis demonstrating that, under
specific training objectives, our model's learned representations in a
Euclidean space converge to an ideal additive structure. This ensures that the
representation of a sequence is the vector sum of its constituent events, a
property we term the linear additive hypothesis. To address the limitations of
Euclidean geometry for hierarchical data, we also introduce a variant of our
model in hyperbolic space, which is naturally suited to embedding tree-like
structures with low distortion. We present experiments to validate our
hypothesis and demonstrate the benefits of each geometry, highlighting the
improved performance of the hyperbolic model on hierarchical event sequences.

</details>


### [666] [Assessing On-the-Ground Disaster Impact Using Online Data Sources](https://arxiv.org/abs/2509.11634)
*Saketh Vishnubhatla,Ujun Jeong,Bohan Jiang,Paras Sheth,Zhen Tan,Adrienne Raglin,Huan Liu*

Main category: cs.LG

TL;DR: 在线数据源可用于评估灾难影响，并可与传统方法互补。


<details>
  <summary>Details</summary>
Motivation: 评估灾难造成的资产损失和人员伤亡对于制定有效的响应计划至关重要，而传统方法存在延迟和偏差。

Method: 收集来自多个在线数据源（社交媒体、新闻报道、航空和卫星图像）的数据，并在县级层面对其进行分析，以评估数十亿美元灾难的影响。将在线估算与传统的离线估算进行比较。

Result: 在线数据源可以提供实时数据流，用于估算离线影响，并且可以提供互补信息。

Conclusion: 在线数据源（如社交媒体、新闻报道、航空和卫星图像）可用于评估灾难影响，并可与传统方法互补。

Abstract: Assessing the impact of a disaster in terms of asset losses and human
casualties is essential for preparing effective response plans. Traditional
methods include offline assessments conducted on the ground, where volunteers
and first responders work together to collect the estimate of losses through
windshield surveys or on-ground inspection. However, these methods have a time
delay and are prone to different biases. Recently, various online data sources,
including social media, news reports, aerial imagery, and satellite data, have
been utilized to evaluate the impact of disasters. Online data sources provide
real-time data streams for estimating the offline impact. Limited research
exists on how different online sources help estimate disaster impact at a given
administrative unit. In our work, we curate a comprehensive dataset by
collecting data from multiple online sources for a few billion-dollar disasters
at the county level. We also analyze how online estimates compare with
traditional offline-based impact estimates for the disaster. Our findings
provide insight into how different sources can provide complementary
information to assess the disaster.

</details>


### [667] [An Interventional Approach to Real-Time Disaster Assessment via Causal Attribution](https://arxiv.org/abs/2509.11676)
*Saketh Vishnubhatla,Alimohammad Beigi,Rui Heng Foo,Umang Goel,Ujun Jeong,Bohan Jiang,Adrienne Raglin,Huan Liu*

Main category: cs.LG

TL;DR: 传统灾害分析工具是预测性的，而本文提出的工具则侧重于干预和因果分析，并提供可操作的补救措施。


<details>
  <summary>Details</summary>
Motivation: 传统的灾害分析和建模工具主要基于历史数据进行预测，无法进行干预式模拟或因果分析。因此，需要一种能够利用实时数据源、理解不同因素对灾害严重程度的因果影响，并提供可操作补救措施的工具。

Method: 利用卫星图像、新闻和社交媒体等实时数据源，构建一个能够进行干预式模拟、因果归因分析，并提供补救措施的灾害分析工具。

Result: 该工具能够补充传统灾害建模工具，通过实时数据源进行干预式模拟，分析不同因素对灾害严重程度的因果影响，并提供可操作的补救措施，从而辅助减灾规划。

Conclusion: 本文提出的工具通过利用实时数据源，实现了对灾害的干预式分析和因果归因，并提供了可操作的补救措施，是对传统预测性灾害分析工具的重要补充。

Abstract: Traditional disaster analysis and modelling tools for assessing the severity
of a disaster are predictive in nature. Based on the past observational data,
these tools prescribe how the current input state (e.g., environmental
conditions, situation reports) results in a severity assessment. However, these
systems are not meant to be interventional in the causal sense, where the user
can modify the current input state to simulate counterfactual "what-if"
scenarios. In this work, we provide an alternative interventional tool that
complements traditional disaster modelling tools by leveraging real-time data
sources like satellite imagery, news, and social media. Our tool also helps
understand the causal attribution of different factors on the estimated
severity, over any given region of interest. In addition, we provide actionable
recourses that would enable easier mitigation planning. Our source code is
publicly available.

</details>


### [668] [Beyond Regularity: Modeling Chaotic Mobility Patterns for Next Location Prediction](https://arxiv.org/abs/2509.11713)
*Yuqian Wu,Yuhong Peng,Jiapeng Yu,Xiangyu Liu,Zeting Yan,Kang Lin,Weifeng Su,Bingqing Qu,Raymond Lee,Dingqi Yang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为CANOE（Chaotic Neural Oscillator network）的新型神经网络模型，用于解决城市中个体下一地点预测的难题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理周期性与随机性并存的移动模式以及利用时间等上下文信息方面存在不足。

Method: CANOE模型引入了受生物启发的“混沌神经振荡注意力”机制来处理动态变化的移动模式，并结合“三元交互编码器”和“交叉上下文注意力解码器”来融合“谁-何时-何地”的多模态上下文信息。

Result: 在两个真实世界数据集上的广泛实验表明，CANOE的预测性能显著优于现有最先进的模型，在不同情况下的性能提升达到3.17%-13.11%。

Conclusion: CANOE模型能够有效处理不同混沌程度的移动轨迹，并做出鲁棒的预测。

Abstract: Next location prediction is a key task in human mobility analysis, crucial
for applications like smart city resource allocation and personalized
navigation services. However, existing methods face two significant challenges:
first, they fail to address the dynamic imbalance between periodic and chaotic
mobile patterns, leading to inadequate adaptation over sparse trajectories;
second, they underutilize contextual cues, such as temporal regularities in
arrival times, which persist even in chaotic patterns and offer stronger
predictability than spatial forecasts due to reduced search spaces. To tackle
these challenges, we propose \textbf{\method}, a
\underline{\textbf{C}}h\underline{\textbf{A}}otic \underline{\textbf{N}}eural
\underline{\textbf{O}}scillator n\underline{\textbf{E}}twork for next location
prediction, which introduces a biologically inspired Chaotic Neural Oscillatory
Attention mechanism to inject adaptive variability into traditional attention,
enabling balanced representation of evolving mobility behaviors, and employs a
Tri-Pair Interaction Encoder along with a Cross Context Attentive Decoder to
fuse multimodal ``who-when-where'' contexts in a joint framework for enhanced
prediction performance. Extensive experiments on two real-world datasets
demonstrate that CANOE consistently and significantly outperforms a sizeable
collection of state-of-the-art baselines, yielding 3.17\%-13.11\% improvement
over the best-performing baselines across different cases. In particular, CANOE
can make robust predictions over mobility trajectories of different mobility
chaotic levels. A series of ablation studies also supports our key design
choices. Our code is available at: https://github.com/yuqian2003/CANOE.

</details>


### [669] [DRAG: Data Reconstruction Attack using Guided Diffusion](https://arxiv.org/abs/2509.11724)
*Wa-Kin Lei,Jun-Cheng Chen,Shang-Tse Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于引导扩散的数据重建攻击方法，用于解决在分层推理（SI）场景下，视觉基础模型（VFMs）所面临的隐私泄露风险。该方法利用预训练的潜在扩散模型（LDM）的图像先验知识，通过迭代重建中间表示（IR），能够生成与原始数据高度相似的高保真图像，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有针对分层推理（SI）场景下的数据重建攻击大多集中在小型卷积神经网络（CNN）分类模型，对于更大、更复杂的视觉基础模型（VFMs）的隐私风险研究不足。本文旨在解决这一研究空白，探索VFMs在SI设置下的隐私泄露问题。

Method: 提出一种新颖的数据重建攻击方法，该方法基于引导扩散，并利用了在大型数据集上预训练的潜在扩散模型（LDM）所包含的丰富先验知识。该方法在LDM学习到的图像先验上进行迭代重建，能够从中间表示（IR）有效地生成与原始数据相似的高保真图像。

Result: 通过大量实验证明，本文提出的方法在从视觉基础模型（VFMs）的深层中间表示（IR）重建数据方面，无论在定性还是定量上都显著优于现有的最先进方法。

Conclusion: 研究结果强调，当前迫切需要为SI场景下的大型模型开发更强大的隐私保护机制。

Abstract: With the rise of large foundation models, split inference (SI) has emerged as
a popular computational paradigm for deploying models across lightweight edge
devices and cloud servers, addressing data privacy and computational cost
concerns. However, most existing data reconstruction attacks have focused on
smaller CNN classification models, leaving the privacy risks of foundation
models in SI settings largely unexplored. To address this gap, we propose a
novel data reconstruction attack based on guided diffusion, which leverages the
rich prior knowledge embedded in a latent diffusion model (LDM) pre-trained on
a large-scale dataset. Our method performs iterative reconstruction on the
LDM's learned image prior, effectively generating high-fidelity images
resembling the original data from their intermediate representations (IR).
Extensive experiments demonstrate that our approach significantly outperforms
state-of-the-art methods, both qualitatively and quantitatively, in
reconstructing data from deep-layer IRs of the vision foundation model. The
results highlight the urgent need for more robust privacy protection mechanisms
for large models in SI scenarios. Code is available at:
https://github.com/ntuaislab/DRAG.

</details>


### [670] [Fast and Interpretable Machine Learning Modelling of Atmospheric Molecular Clusters](https://arxiv.org/abs/2509.11728)
*Lauri Seppäläinen,Jakub Kubečka,Jonas Elm,Kai Puolamäki*

Main category: cs.LG

TL;DR: kNN回归模型在气溶胶形成研究中表现出强大潜力，计算效率远超传统方法，且精度接近化学精度。


<details>
  <summary>Details</summary>
Motivation: 气候模型中新气溶胶粒子形成的不确定性是关键问题，现有量子化学方法计算成本高昂，限制了大规模探索。

Method: 提出并比较了kNN回归模型与核岭回归（KRR）模型在化学团簇形成预测中的性能。利用化学信息化的距离度量（包括核诱导度量和通过度量学习核回归（MLKR）学到的度量）。

Result: kNN模型在QM9和大气分子团簇（硫酸-水和硫酸-多碱-碱体系）数据集上实现了近化学精度，计算时间减少了数量级，并且能够以最小的误差（接近1 kcal/mol）外推到更大的未见团簇。

Conclusion: kNN模型是一种高效、可解释且强大的工具，可以加速大气化学及其他领域的研究发现。

Abstract: Understanding how atmospheric molecular clusters form and grow is key to
resolving one of the biggest uncertainties in climate modelling: the formation
of new aerosol particles. While quantum chemistry offers accurate insights into
these early-stage clusters, its steep computational costs limit large-scale
exploration. In this work, we present a fast, interpretable, and surprisingly
powerful alternative: $k$-nearest neighbour ($k$-NN) regression model. By
leveraging chemically informed distance metrics, including a kernel-induced
metric and one learned via metric learning for kernel regression (MLKR), we
show that simple $k$-NN models can rival more complex kernel ridge regression
(KRR) models in accuracy, while reducing computational time by orders of
magnitude. We perform this comparison with the well-established
Faber-Christensen-Huang-Lilienfeld (FCHL19) molecular descriptor, but other
descriptors (e.g., FCHL18, MBDF, and CM) can be shown to have similar
performance. Applied to both simple organic molecules in the QM9 benchmark set
and large datasets of atmospheric molecular clusters (sulphuric acid-water and
sulphuric-multibase -base systems), our $k$-NN models achieve near-chemical
accuracy, scale seamlessly to datasets with over 250,000 entries, and even
appears to extrapolate to larger unseen clusters with minimal error (often
nearing 1 kcal/mol). With built-in interpretability and straightforward
uncertainty estimation, this work positions $k$-NN as a potent tool for
accelerating discovery in atmospheric chemistry and beyond.

</details>


### [671] [Data Fusion and Machine Learning for Ship Fuel Consumption Modelling -- A Case of Bulk Carrier Vessel](https://arxiv.org/abs/2509.11750)
*Abdella Mohamed,Xiangyu Hu,Christian Hendricks*

Main category: cs.LG

TL;DR: 该研究利用机器学习模型，结合了来自船舶报告、CMEMS和ECMWF的28个参数，以提高船舶燃油消耗预测的准确性，并强调了影响燃油消耗的关键参数。


<details>
  <summary>Details</summary>
Motivation: 为了应对国际海事组织（IMO）减少船舶燃油消耗和碳排放的指令，需要对船舶进行燃油消耗的准确预测，并确定影响燃油消耗的关键因素。

Method: 该研究利用了296份来自一艘散货船一年的航次报告，结合了28个参数，并整合了来自CMEMS（19个参数）和ECMWF（61个参数）的水文气象大数据，以评估外部公共数据源融合是否能提高模型准确性。

Result: 研究结果表明，通过结合航次报告、气候和海况数据，机器学习技术在准确预测船舶燃油消耗方面具有巨大潜力。然而，仍有必要在同类船舶上进行验证以确认其普遍适用性。

Conclusion: 机器学习技术，特别是当结合了船舶报告和外部气候与海况数据时，可以准确预测船舶燃油消耗，但其普遍性仍需进一步验证。

Abstract: There is an increasing push for operational measures to reduce ships' bunker
fuel consumption and carbon emissions, driven by the International Maritime
Organization (IMO) mandates. Key performance indicators such as the Energy
Efficiency Operational Indicator (EEOI) focus on fuel efficiency. Strategies
like trim optimization, virtual arrival, and green routing have emerged. The
theoretical basis for these approaches lies in accurate prediction of fuel
consumption as a function of sailing speed, displacement, trim, climate, and
sea state. This study utilized 296 voyage reports from a bulk carrier vessel
over one year (November 16, 2021 to November 21, 2022) and 28 parameters,
integrating hydrometeorological big data from the Copernicus Marine Environment
Monitoring Service (CMEMS) with 19 parameters and the European Centre for
Medium-Range Weather Forecasts (ECMWF) with 61 parameters. The objective was to
evaluate whether fusing external public data sources enhances modeling accuracy
and to highlight the most influential parameters affecting fuel consumption.
The results reveal a strong potential for machine learning techniques to
predict ship fuel consumption accurately by combining voyage reports with
climate and sea data. However, validation on similar classes of vessels remains
necessary to confirm generalizability.

</details>


### [672] [Stabilizing PINNs: A regularization scheme for PINN training to avoid unstable fixed points of dynamical systems](https://arxiv.org/abs/2509.11768)
*Milos Babic,Franz M. Rohrhofer,Bernhard C. Geiger*

Main category: cs.LG

TL;DR: PINNs训练中的局部最小值问题可能导致物理上不正确的解。本文提出了一种正则化方案，通过惩罚不稳定固定点对应的解来避免此问题，并在四个动力学系统上进行了实验验证，证明了该方案能有效提高PINN的训练成功率。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINNs）在训练过程中，其损失函数可能在动力学系统的固定点处出现局部最小值，这可能干扰训练并导致物理上不正确的解。

Method: 本文提出了一种基于稳定性理论的正则化方案，该方案对对应于不稳定固定点的解进行惩罚。

Result: 在四个动力学系统（包括Lotka-Volterra模型和van der Pol振荡器）上的实验结果表明，该方案有助于避免物理上不正确的解，并显著提高了PINN的训练成功率。

Conclusion: 所提出的正则化方案能够有效解决PINN训练中的局部最小值问题，提高训练的稳定性和准确性。

Abstract: It was recently shown that the loss function used for training
physics-informed neural networks (PINNs) exhibits local minima at solutions
corresponding to fixed points of dynamical systems. In the forward setting,
where the PINN is trained to solve initial value problems, these local minima
can interfere with training and potentially leading to physically incorrect
solutions. Building on stability theory, this paper proposes a regularization
scheme that penalizes solutions corresponding to unstable fixed points.
Experimental results on four dynamical systems, including the Lotka-Volterra
model and the van der Pol oscillator, show that our scheme helps avoiding
physically incorrect solutions and substantially improves the training success
rate of PINNs.

</details>


### [673] [Multimodal Regression for Enzyme Turnover Rates Prediction](https://arxiv.org/abs/2509.11782)
*Bozhen Hu,Cheng Tan,Siyuan Li,Jiangbin Zheng,Sizhe Qiu,Jun Xia,Stan Z. Li*

Main category: cs.LG

TL;DR: 本研究提出一个多模态框架，整合酶序列、底物结构和环境因素，利用预训练语言模型、卷积神经网络和图神经网络提取特征，并通过注意力机制增强酶-底物交互，最后使用基于Kolmogorov-Arnold网络（KANs）的符号回归显式学习酶转换率的数学公式，实现可解释且准确的预测，实验证明该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 酶转换率是酶动力学的基本参数，但实验测量成本高、复杂度高，导致大多数生物的酶转换率数据匮乏。本研究旨在解决这一数据缺口，提供一种预测酶转换率的方法。

Method: 本研究提出的多模态框架整合酶序列、底物结构和环境因素。具体来说，模型结合了预训练语言模型（PLM）和卷积神经网络（CNN）来提取酶蛋白序列的特征，同时利用图神经网络（GNN）捕获底物分子的信息。注意力机制被用于增强酶和底物特征表示之间的相互作用。此外，研究采用基于Kolmogorov-Arnold网络（KANs）的符号回归来显式学习控制酶转换率的数学公式，从而实现可解释和准确的预测。

Result: 大量的实验结果表明，本研究提出的框架在预测酶转换率方面，性能优于传统的和最先进的深度学习方法。

Conclusion: 本研究提供了一个强大的工具用于研究酶动力学，并在酶工程、生物技术和工业生物催化等领域展现出应用前景。

Abstract: The enzyme turnover rate is a fundamental parameter in enzyme kinetics,
reflecting the catalytic efficiency of enzymes. However, enzyme turnover rates
remain scarce across most organisms due to the high cost and complexity of
experimental measurements. To address this gap, we propose a multimodal
framework for predicting the enzyme turnover rate by integrating enzyme
sequences, substrate structures, and environmental factors. Our model combines
a pre-trained language model and a convolutional neural network to extract
features from protein sequences, while a graph neural network captures
informative representations from substrate molecules. An attention mechanism is
incorporated to enhance interactions between enzyme and substrate
representations. Furthermore, we leverage symbolic regression via
Kolmogorov-Arnold Networks to explicitly learn mathematical formulas that
govern the enzyme turnover rate, enabling interpretable and accurate
predictions. Extensive experiments demonstrate that our framework outperforms
both traditional and state-of-the-art deep learning approaches. This work
provides a robust tool for studying enzyme kinetics and holds promise for
applications in enzyme engineering, biotechnology, and industrial biocatalysis.

</details>


### [674] [Watch Your Step: A Cost-Sensitive Framework for Accelerometer-Based Fall Detection in Real-World Streaming Scenarios](https://arxiv.org/abs/2509.11789)
*Timilehin B. Aderinola,Luca Palmerini,Ilaria D'Ascanio,Lorenzo Chiari,Jochen Klenk,Clemens Becker,Brian Caulfield,Georgiana Ifrim*

Main category: cs.LG

TL;DR: 本研究提出了一个实时、无需预知跌倒事件的连续监测框架，通过成本敏感学习优化决策阈值，实现了高召回率、低误报率和快速推理，适用于可穿戴传感器系统。


<details>
  <summary>Details</summary>
Motivation: 为了实现及时的干预并减轻跌倒对老年人健康的严重影响，实时跌倒检测至关重要。现有方法多依赖模拟数据或假设，限制了实际应用。实际部署还需要高效的计算和针对连续监测的鲁棒评估指标。

Method: 使用来自FARSEEING真实跌倒数据集的60多小时惯性测量单元（IMU）数据，采用高效分类器以流式模式计算跌倒概率。引入成本敏感学习策略，根据漏报比误报风险更高的成本函数来调整决策阈值。

Result: 在FARSEEING数据集上，实现了1.00的召回率、0.84的精确率和0.91的F1分数，检测到所有跌倒事件，同时保持较低的误报率，平均推理时间低于每样本5毫秒。

Conclusion: 成本敏感阈值调整增强了基于加速度计的跌倒检测的鲁棒性。所提出的计算高效框架有潜力用于实时可穿戴传感器系统的连续监测部署。

Abstract: Real-time fall detection is crucial for enabling timely interventions and
mitigating the severe health consequences of falls, particularly in older
adults. However, existing methods often rely on simulated data or assumptions
such as prior knowledge of fall events, limiting their real-world
applicability. Practical deployment also requires efficient computation and
robust evaluation metrics tailored to continuous monitoring. This paper
presents a real-time fall detection framework for continuous monitoring without
prior knowledge of fall events. Using over 60 hours of inertial measurement
unit (IMU) data from the FARSEEING real-world falls dataset, we employ recent
efficient classifiers to compute fall probabilities in streaming mode. To
enhance robustness, we introduce a cost-sensitive learning strategy that tunes
the decision threshold using a cost function reflecting the higher risk of
missed falls compared to false alarms. Unlike many methods that achieve high
recall only at the cost of precision, our framework achieved Recall of 1.00,
Precision of 0.84, and an F1 score of 0.91 on FARSEEING, detecting all falls
while keeping false alarms low, with average inference time below 5 ms per
sample. These results demonstrate that cost-sensitive threshold tuning enhances
the robustness of accelerometer-based fall detection. They also highlight the
potential of our computationally efficient framework for deployment in
real-time wearable sensor systems for continuous monitoring.

</details>


### [675] [Visualization and Analysis of the Loss Landscape in Graph Neural Networks](https://arxiv.org/abs/2509.11792)
*Samir Moustafa,Lorenz Kummer,Simon Fetzel,Nils M. Kriege,Wilfried N. Gansterer*

Main category: cs.LG

TL;DR: GNN参数优化、表达能力和泛化能力之间的相互作用仍未得到充分理解。本文提出了一种高效的可学习降维方法来可视化GNN的损失曲线，并分析了过平滑、跳跃知识、量化、稀疏化和预处理对GNN优化的影响。


<details>
  <summary>Details</summary>
Motivation: GNN参数优化、表达能力和泛化能力之间的相互作用仍未得到充分理解，需要新的方法来研究和分析。

Method: 提出了一种高效的可学习降维方法来可视化GNN的损失曲线，并分析了过平滑、跳跃知识、量化、稀疏化和预处理对GNN优化的影响。

Result: 所提出的可学习投影方法优于基于PCA的方法，能够以更低的内存使用量准确重建高维参数。此外，研究表明GNN的架构、稀疏化和优化器的预处理显著影响GNN的优化曲线、训练过程和最终预测性能。

Conclusion: 这些发现有助于设计更高效的GNN架构和训练策略。

Abstract: Graph Neural Networks (GNNs) are powerful models for graph-structured data,
with broad applications. However, the interplay between GNN parameter
optimization, expressivity, and generalization remains poorly understood. We
address this by introducing an efficient learnable dimensionality reduction
method for visualizing GNN loss landscapes, and by analyzing the effects of
over-smoothing, jumping knowledge, quantization, sparsification, and
preconditioner on GNN optimization. Our learnable projection method surpasses
the state-of-the-art PCA-based approach, enabling accurate reconstruction of
high-dimensional parameters with lower memory usage. We further show that
architecture, sparsification, and optimizer's preconditioning significantly
impact the GNN optimization landscape and their training process and final
prediction performance. These insights contribute to developing more efficient
designs of GNN architectures and training strategies.

</details>


### [676] [FedDAF: Federated Domain Adaptation Using Model Functional Distance](https://arxiv.org/abs/2509.11819)
*Mrinmay Sen,Ankita Das,Sidhant Nair,C Krishna Mohan*

Main category: cs.LG

TL;DR: FedDAF是一种新的联邦域适应（FDA）方法，它通过计算源模型和目标模型在目标数据上的梯度场的函数距离来聚合模型，解决了域偏移和数据稀疏的挑战，并在真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦域适应（FDA）方法主要关注域偏移问题，但忽略了数据稀疏的挑战，并且在信息共享时未能有效考虑目标客户的客观需求。

Method: FedDAF通过计算源模型和目标模型在目标数据上的梯度场的函数距离来聚合模型。具体而言，它计算梯度场之间的角度，并使用Gompertz函数进行归一化。源模型在服务器上通过简单平均聚合。

Result: 在真实世界数据集上的实验表明，FedDAF在测试准确性方面优于现有的联邦学习（FL）、个性化联邦学习（PFL）和FDA方法。

Conclusion: FedDAF成功地解决了FDA中的域偏移和数据稀疏的双重挑战，并通过一种新颖的基于模型函数距离的聚合方法，实现了基于目标客体的有效模型聚合。

Abstract: Federated Domain Adaptation (FDA) is a federated learning (FL) approach that
improves model performance at the target client by collaborating with source
clients while preserving data privacy. FDA faces two primary challenges: domain
shifts between source and target data and limited labeled data at the target.
Most existing FDA methods focus on domain shifts, assuming ample target data,
yet often neglect the combined challenges of both domain shifts and data
scarcity. Moreover, approaches that address both challenges fail to prioritize
sharing relevant information from source clients according to the target's
objective. In this paper, we propose FedDAF, a novel approach addressing both
challenges in FDA. FedDAF uses similarity-based aggregation of the global
source model and target model by calculating model functional distance from
their mean gradient fields computed on target data. This enables effective
model aggregation based on the target objective, constructed using target data,
even with limited data. While computing model functional distance between these
two models, FedDAF computes the angle between their mean gradient fields and
then normalizes with the Gompertz function. To construct the global source
model, all the local source models are aggregated using simple average in the
server. Experiments on real-world datasets demonstrate FedDAF's superiority
over existing FL, PFL, and FDA methods in terms of achieving better test
accuracy.

</details>


### [677] [Transparent and Fair Profiling in Employment Services: Evidence from Switzerland](https://arxiv.org/abs/2509.11847)
*Tim Räz*

Main category: cs.LG

TL;DR: 可解释模型在预测长期失业风险方面是黑箱模型的可靠替代品，具有可比的性能和更高的透明度及公平性。


<details>
  <summary>Details</summary>
Motivation: 解决传统用于预测长期失业风险的黑箱模型在透明度和公平性方面存在的问题。

Method: 使用瑞士的行政数据，对传统统计模型、可解释模型（如可解释提升机）和黑箱模型进行比较，评估它们在预测性能、可解释性和公平性方面的表现。

Result: 可解释的提升机在预测性能上接近最佳的黑箱模型；模型稀疏性、特征平滑和公平性缓解策略可以提高透明度和公平性，同时只带来微小的性能损失。

Conclusion: 可解释的模型分析为黑箱模型提供了一种可行的、可信赖的替代方案，在不影响性能的情况下，能够实现更高的透明度和公平性。

Abstract: Long-term unemployment (LTU) is a challenge for both jobseekers and public
employment services. Statistical profiling tools are increasingly used to
predict LTU risk. Some profiling tools are opaque, black-box machine learning
models, which raise issues of transparency and fairness. This paper
investigates whether interpretable models could serve as an alternative, using
administrative data from Switzerland. Traditional statistical, interpretable,
and black-box models are compared in terms of predictive performance,
interpretability, and fairness. It is shown that explainable boosting machines,
a recent interpretable model, perform nearly as well as the best black-box
models. It is also shown how model sparsity, feature smoothing, and fairness
mitigation can enhance transparency and fairness with only minor losses in
performance. These findings suggest that interpretable profiling provides an
accountable and trustworthy alternative to black-box models without
compromising performance.

</details>


### [678] [TabStruct: Measuring Structural Fidelity of Tabular Data](https://arxiv.org/abs/2509.11950)
*Xiangjian Jiang,Nikola Simidjievski,Mateja Jamnik*

Main category: cs.LG

TL;DR: 评估表格生成器面临挑战，现有方法忽略了结构保真度与常规评估维度之间的相互作用，并且局限于小型数据集，因为现有指标量化需要真实因果结构。


<details>
  <summary>Details</summary>
Motivation: 现有的表格生成器评估方法未能全面考量结构保真度与其他评估维度，并且缺乏在真实世界数据集上的评估能力。

Method: 提出一个新的评估框架，联合考虑结构保真度与常规评估维度，并引入了一个名为‘global utility’的新评估指标，即使在没有真实因果结构的情况下也能评估结构保真度。构建了一个名为‘TabStruct’的综合评估基准，包含13个表格生成器和29个数据集。

Result: ‘global utility’指标能够独立于任务和领域地评估表格生成器性能。在TabStruct基准上的大规模定量分析。

Conclusion: 提出的新评估框架和‘global utility’指标能够更全面、更有效地评估表格生成器，并且TabStruct基准为未来研究提供了支持。

Abstract: Evaluating tabular generators remains a challenging problem, as the unique
causal structural prior of heterogeneous tabular data does not lend itself to
intuitive human inspection. Recent work has introduced structural fidelity as a
tabular-specific evaluation dimension to assess whether synthetic data complies
with the causal structures of real data. However, existing benchmarks often
neglect the interplay between structural fidelity and conventional evaluation
dimensions, thus failing to provide a holistic understanding of model
performance. Moreover, they are typically limited to toy datasets, as
quantifying existing structural fidelity metrics requires access to
ground-truth causal structures, which are rarely available for real-world
datasets. In this paper, we propose a novel evaluation framework that jointly
considers structural fidelity and conventional evaluation dimensions. We
introduce a new evaluation metric, $\textbf{global utility}$, which enables the
assessment of structural fidelity even in the absence of ground-truth causal
structures. In addition, we present $\textbf{TabStruct}$, a comprehensive
evaluation benchmark offering large-scale quantitative analysis on 13 tabular
generators from nine distinct categories, across 29 datasets. Our results
demonstrate that global utility provides a task-independent, domain-agnostic
lens for tabular generator performance. We release the TabStruct benchmark
suite, including all datasets, evaluation pipelines, and raw results. Code is
available at https://github.com/SilenceX12138/TabStruct.

</details>


### [679] [Deep operator network for surrogate modeling of poroelasticity with random permeability fields](https://arxiv.org/abs/2509.11966)
*Sangjoon Park,Yeonjong Shin,Jinhyun Choo*

Main category: cs.LG

TL;DR: 提出了一种基于深度算子网络（DeepONet）的代理模型框架，用于模拟具有随机渗透率场的孔隙弹性问题，显著提高了计算效率和预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有孔隙弹性模拟方法在处理空间变异渗透率场时计算成本高昂，需要开发高效的代理模型。

Method: 利用DeepONet学习从随机渗透率场到瞬态孔隙弹性响应的映射，并结合了方程无量纲化、Karhunen-Loève展开降维和两步训练策略以提高预测精度和稳定性。

Result: 在土壤固结和地下水抽取引起地面沉降的两个基准问题中，DeepONet在保持高预测精度的同时实现了显著的推理加速。

Conclusion: 所提出的DeepONet代理模型框架为具有随机渗透率场的孔隙弹性系统提供了一种可扩展且高效的解决方案。

Abstract: Poroelasticity -- coupled fluid flow and elastic deformation in porous media
-- often involves spatially variable permeability, especially in subsurface
systems. In such cases, simulations with random permeability fields are widely
used for probabilistic analysis, uncertainty quantification, and inverse
problems. These simulations require repeated forward solves that are often
prohibitively expensive, motivating the development of efficient surrogate
models. However, efficient surrogate modeling techniques for poroelasticity
with random permeability fields remain scarce. In this study, we propose a
surrogate modeling framework based on the deep operator network (DeepONet), a
neural architecture designed to learn mappings between infinite-dimensional
function spaces. The proposed surrogate model approximates the solution
operator that maps random permeability fields to transient poroelastic
responses. To enhance predictive accuracy and stability, we integrate three
strategies: nondimensionalization of the governing equations, input
dimensionality reduction via Karhunen--Lo\'eve expansion, and a two-step
training procedure that decouples the optimization of branch and trunk
networks. The methodology is evaluated on two benchmark problems in
poroelasticity: soil consolidation and ground subsidence induced by groundwater
extraction. In both cases, the DeepONet achieves substantial speedup in
inference while maintaining high predictive accuracy across a wide range of
permeability statistics. These results highlight the potential of the proposed
approach as a scalable and efficient surrogate modeling technique for
poroelastic systems with random permeability fields.

</details>


### [680] [Examining the Relationship between Scientific Publishing Activity and Hype-Driven Financial Bubbles: A Comparison of the Dot-Com and AI Eras](https://arxiv.org/abs/2509.11982)
*Aksheytha Chelikavada,Casey C. Bennett*

Main category: cs.LG

TL;DR: 金融泡沫的预测是困难的，本研究利用时间社交网络分析（Temporal SNA）来分析科学出版物引文网络和金融市场数据，以期在两个技术快速变革的时代（.com泡沫和AI时代）发现预测泡沫的信号。研究发现.com时代的模式无法有效预测AI泡沫，AI时代的数据暗示可能存在一种前所未有的金融泡沫，或者根本不存在泡沫。


<details>
  <summary>Details</summary>
Motivation: 金融泡沫的出现往往难以预警，但会产生持久的经济影响。本研究旨在探索分析科学出版数据（如引文网络）是否能为预测未来泡沫提供信号，特别是借鉴.com泡沫的经验。

Method: 本研究利用时间社交网络分析（Temporal SNA）来分析1994年至2001年的.com时代和2017年至2024年的AI时代科学出版物引文网络与金融市场数据。此外，还采用了LSTM、KNN、AR X/GARCH等多种分析技术。

Result: 研究发现，.com时代的模式并未明确预测AI泡沫的兴衰。虽然两个时代的年度引文网络反映了科学家出版行为的变化，但AI时代存在一部分科学家的出版影响力模式与.com时代相似。使用多种分析技术后，数据表明AI时代可能存在一种前所未有的金融泡沫，或者根本不存在泡沫。

Conclusion: .com时代的模式不能有效地转化为适用于AI市场进行预测的模式。AI时代的数据揭示了两种可能性：要么AI泡沫是一种前所未有的形式，要么根本不存在泡沫。

Abstract: Financial bubbles often arrive without much warning, but create long-lasting
economic effects. For example, during the dot-com bubble, innovative
technologies created market disruptions through excitement for a promised
bright future. Such technologies originated from research where scientists had
developed them for years prior to their entry into the markets. That raises a
question on the possibility of analyzing scientific publishing data (e.g.
citation networks) leading up to a bubble for signals that may forecast the
rise and fall of similar future bubbles. To that end, we utilized temporal SNAs
to detect possible relationships between the publication citation networks of
scientists and financial market data during two modern eras of rapidly shifting
technology: 1) dot-com era from 1994 to 2001 and 2) AI era from 2017 to 2024.
Results showed that the patterns from the dot-com era (which did end in a
bubble) did not definitively predict the rise and fall of an AI bubble. While
yearly citation networks reflected possible changes in publishing behavior of
scientists between the two eras, there was a subset of AI era scientists whose
publication influence patterns mirrored those during the dot-com era. Upon
further analysis using multiple analysis techniques (LSTM, KNN, AR X/GARCH),
the data seems to suggest two possibilities for the AI era: unprecedented form
of financial bubble unseen or that no bubble exists. In conclusion, our
findings imply that the patterns present in the dot-com era do not effectively
translate in such a manner to apply them to the AI market.

</details>


### [681] [Low-rank Orthogonalization for Large-scale Matrix Optimization with Applications to Foundation Model Training](https://arxiv.org/abs/2509.11983)
*Chuan He,Zhanwang Deng,Zhaosong Lu*

Main category: cs.LG

TL;DR: 本文提出了一种利用神经网络训练中梯度低秩特性的低秩正交化方法，并在此基础上提出了低秩矩阵符号梯度下降和低秩Muon优化器，在GPT-2和LLaMA预训练中取得了优于标准Muon的性能。


<details>
  <summary>Details</summary>
Motivation: 神经网络训练中的矩阵结构被忽视，而Muon优化器通过显式利用该结构取得了优异性能。本文旨在进一步利用梯度本身的低秩特性来改进优化器。

Method: 提出低秩正交化，并在此基础上提出低秩矩阵符号梯度下降和低秩Muon优化器。

Result: 低秩Muon在GPT-2和LLaMA预训练中取得了优于精心调整的标准Muon的性能。理论上，本文建立了低秩矩阵符号梯度下降和低秩Muon在寻找近似平稳解（或近似随机平稳解）的迭代复杂度。

Conclusion: 低秩正交化是一种有效的方法，可以利用神经网络训练中梯度的低秩特性，并能提升优化器的性能。

Abstract: Neural network (NN) training is inherently a large-scale matrix optimization
problem, yet the matrix structure of NN parameters has long been overlooked.
Recently, the optimizer Muon \cite{jordanmuon}, which explicitly exploits this
structure, has gained significant attention for its strong performance in
foundation model training. A key component contributing to Muon's success is
matrix orthogonalization. In this paper, we propose {\it low-rank
orthogonalization}, which explicitly leverages the low-rank nature of gradients
during NN training. Building on this, we propose low-rank matrix-signed
gradient descent and a low-rank variant of Muon. Our numerical experiments
demonstrate the superior performance of low-rank orthogonalization, with the
low-rank Muon achieving promising results in GPT-2 and LLaMA pretraining --
surpassing the performance of the carefully tuned vanilla Muon. Theoretically,
we establish the iteration complexity of the low-rank matrix-signed gradient
descent for finding an approximate stationary solution, as well as that of
low-rank Muon for finding an approximate stochastic stationary solution under
heavy-tailed noise.

</details>


### [682] [Learning from Uncertain Similarity and Unlabeled Data](https://arxiv.org/abs/2509.11984)
*Meng Wei,Zhongnian Li,Peng Ying,Xinzheng Xu*

Main category: cs.LG

TL;DR: USimUL框架通过引入不确定性组件来解决现有相似性监督学习方法中存在的隐私泄露问题，并能在理论和实践上取得最优的分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性的弱监督学习方法依赖精确的相似性标注，可能暴露敏感标签信息并带来隐私风险。

Method: 提出不确定相似性和无标签学习（USimUL）框架，为相似性对嵌入不确定性组件以减少标签泄露，并提出一个无偏风险估计器，该估计器从不确定的相似性和无标签数据中学习。

Result: 理论证明该估计器能达到统计最优的参数收敛率，并通过在基准和真实世界数据集上的大量实验证明，USimUL方法优于传统的基于相似性的方法。

Conclusion: USimUL框架通过引入不确定性来解决隐私问题，同时在分类任务上取得了优于现有方法的性能。

Abstract: Existing similarity-based weakly supervised learning approaches often rely on
precise similarity annotations between data pairs, which may inadvertently
expose sensitive label information and raise privacy risks. To mitigate this
issue, we propose Uncertain Similarity and Unlabeled Learning (USimUL), a novel
framework where each similarity pair is embedded with an uncertainty component
to reduce label leakage. In this paper, we propose an unbiased risk estimator
that learns from uncertain similarity and unlabeled data. Additionally, we
theoretically prove that the estimator achieves statistically optimal
parametric convergence rates. Extensive experiments on both benchmark and
real-world datasets show that our method achieves superior classification
performance compared to conventional similarity-based approaches.

</details>


### [683] [Generalizing Behavior via Inverse Reinforcement Learning with Closed-Form Reward Centroids](https://arxiv.org/abs/2509.12010)
*Filippo Lazzati,Alberto Maria Metelli*

Main category: cs.LG

TL;DR: IRL 存在多解性问题，本文提出了一种基于“平均”策略的解决方案，通过计算可行奖励集中的“奖励质心”来规划策略，并提出了高效的估计算法。


<details>
  <summary>Details</summary>
Motivation: 逆强化学习（IRL）旨在从专家演示中恢复奖励函数，但存在多解性问题，即多个奖励函数可以解释相同的行为。这导致在新的环境或约束下，可能需要选择不同的策略。因此，需要一种新的判据来选择最优策略。

Method: 本文提出了一种新颖的判据，选择由可行奖励集中一个有界子集诱导的“平均”策略。该策略可以通过规划该子集的“奖励质心”获得，并推导出了其闭式表达式。最后，提出了一种仅使用专家演示的离线数据集即可有效估计该质心的方法。

Result: 通过数值模拟，证明了该方法能够有效估计奖励质心，并生成与专家行为相关的策略。

Conclusion: 本文提出了一种基于奖励质心的新型 IRL 策略选择方法，解决了 IRL 的多解性问题，并提供了一种有效的算法来实现。该方法有望在新的环境和约束下泛化专家的行为。

Abstract: We study the problem of generalizing an expert agent's behavior, provided
through demonstrations, to new environments and/or additional constraints.
Inverse Reinforcement Learning (IRL) offers a promising solution by seeking to
recover the expert's underlying reward function, which, if used for planning in
the new settings, would reproduce the desired behavior. However, IRL is
inherently ill-posed: multiple reward functions, forming the so-called feasible
set, can explain the same observed behavior. Since these rewards may induce
different policies in the new setting, in the absence of additional
information, a decision criterion is needed to select which policy to deploy.
In this paper, we propose a novel, principled criterion that selects the
"average" policy among those induced by the rewards in a certain bounded subset
of the feasible set. Remarkably, we show that this policy can be obtained by
planning with the reward centroid of that subset, for which we derive a
closed-form expression. We then present a provably efficient algorithm for
estimating this centroid using an offline dataset of expert demonstrations
only. Finally, we conduct numerical simulations that illustrate the
relationship between the expert's behavior and the behavior produced by our
method.

</details>


### [684] [Learning non-Markovian Dynamical Systems with Signature-based Encoders](https://arxiv.org/abs/2509.12022)
*Eliott Pradeleix,Rémy Hosseinkhan-Boucher,Alena Shilova,Onofrio Semeraro,Lionel Mathelin*

Main category: cs.LG

TL;DR: 神经网络常微分方程在处理有时滞和记忆效应的复杂系统的连续控制问题时，由于其马尔可夫假设，难以捕捉历史依赖性。本研究提出使用签名变换作为连续时间非马尔可夫动力学模型的编码器，并证明其在合成基准测试中优于基于RNN的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的神经网络常微分方程模型依赖于马尔可夫假设，即未来状态仅取决于当前状态，这在实际应用中往往不成立，尤其是在处理具有延迟和记忆效应的复杂系统的连续控制时。为了捕捉历史依赖性，常用的循环神经网络（RNN）方法是离散的，并且可能存在训练不佳的问题。

Method: 本研究将签名变换作为一种连续时间编码器，用于学习非马尔可夫动力学。具体地，研究人员将基于签名变换的编码方案集成到编码器-解码器动力学模型中。

Result: 实验结果表明，与基于RNN的替代方法相比，本研究提出的基于签名变换的编码器在合成基准测试中表现出更优越的测试性能。

Conclusion: 本研究成功地将签名变换应用于连续时间非马尔可夫动力学建模，并证明了其在处理历史依赖性方面优于传统的RNN方法，为连续控制复杂系统提供了新的解决方案。

Abstract: Neural ordinary differential equations offer an effective framework for
modeling dynamical systems by learning a continuous-time vector field. However,
they rely on the Markovian assumption - that future states depend only on the
current state - which is often untrue in real-world scenarios where the
dynamics may depend on the history of past states. This limitation becomes
especially evident in settings involving the continuous control of complex
systems with delays and memory effects. To capture historical dependencies,
existing approaches often rely on recurrent neural network (RNN)-based
encoders, which are inherently discrete and struggle with continuous modeling.
In addition, they may exhibit poor training behavior. In this work, we
investigate the use of the signature transform as an encoder for learning
non-Markovian dynamics in a continuous-time setting. The signature transform
offers a continuous-time alternative with strong theoretical foundations and
proven efficiency in summarizing multidimensional information in time. We
integrate a signature-based encoding scheme into encoder-decoder dynamics
models and demonstrate that it outperforms RNN-based alternatives in test
performance on synthetic benchmarks.

</details>


### [685] [Imitation Learning as Return Distribution Matching](https://arxiv.org/abs/2509.12026)
*Filippo Lazzati,Alberto Maria Metelli*

Main category: cs.LG

TL;DR: 本研究提出一种风险敏感的模仿学习（IL）方法，旨在使智能体不仅能匹配专家的平均回报，还能匹配其风险态度（如回报分布的方差）。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法仅关注匹配专家的平均回报，未能考虑专家的风险偏好。

Method: 提出一种风险敏感的IL问题形式化，目标是匹配专家的回报分布的Wasserstein距离。在表格环境中，针对有限的马尔可夫策略，引入了一个更具表达能力的非马尔可夫策略子类。基于此，开发了两种算法：RS-BC（模型未知）和RS-KT（模型已知），并证明了其效率。还设计了RS-KT的基于Oracle的变体，用于专家奖励未知的情况。

Result: RS-KT利用动力学信息，显著降低了样本复杂度。数值模拟验证了RS-KT和RS-BC的样本效率，以及非马尔可夫策略相对于标准IL算法的优势。

Conclusion: 所提出的风险敏感IL方法能够有效地使智能体匹配专家的风险态度，并且所设计的算法在样本效率和策略表达能力方面优于现有方法。

Abstract: We study the problem of training a risk-sensitive reinforcement learning (RL)
agent through imitation learning (IL). Unlike standard IL, our goal is not only
to train an agent that matches the expert's expected return (i.e., its average
performance) but also its risk attitude (i.e., other features of the return
distribution, such as variance). We propose a general formulation of the
risk-sensitive IL problem in which the objective is to match the expert's
return distribution in Wasserstein distance. We focus on the tabular setting
and assume the expert's reward is known. After demonstrating the limited
expressivity of Markovian policies for this task, we introduce an efficient and
sufficiently expressive subclass of non-Markovian policies tailored to it.
Building on this subclass, we develop two provably efficient algorithms, RS-BC
and RS-KT, for solving the problem when the transition model is unknown and
known, respectively. We show that RS-KT achieves substantially lower sample
complexity than RS-BC by exploiting dynamics information. We further
demonstrate the sample efficiency of return distribution matching in the
setting where the expert's reward is unknown by designing an oracle-based
variant of RS-KT. Finally, we complement our theoretical analysis of RS-KT and
RS-BC with numerical simulations, highlighting both their sample efficiency and
the advantages of non-Markovian policies over standard sample-efficient IL
algorithms.

</details>


### [686] [Travel Time and Weather-Aware Traffic Forecasting in a Conformal Graph Neural Network Framework](https://arxiv.org/abs/2509.12043)
*Mayur Patil,Qadeer Ahmed,Shawn Midlam-Mohler*

Main category: cs.LG

TL;DR: 该研究提出了一种基于图神经网络（GNN）的交通流量预测框架，通过自适应邻接矩阵和天气因素来处理交通的随机性和时空依赖性，并使用自适应保形预测（ACP）进行不确定性量化，实验证明了该模型在预测准确性和不确定性界限方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 交通流量预测对于管理拥堵、提高安全性和优化交通系统至关重要，但受城市交通和环境因素的随机性影响，预测仍然是一个挑战。需要能够处理由多个动态且复杂相互依赖因素影响的交通变异性的模型。

Method: 提出了一种图神经网络（GNN）框架，利用对数正态分布和变异系数（CV）值的自适应邻接矩阵来反映实际的旅行时间变异性。天气因素（如温度、风速和降水）被用来调整边缘权重，使GNN能够捕捉交通站点之间不断演变的时空依赖性。此外，使用自适应保形预测（ACP）框架提供可靠的不确定性量化。

Result: 与基线方法相比，该模型在预测准确性和不确定性界限方面表现更好。通过SUMO构建的交通场景和蒙特卡洛模拟验证了模型的鲁棒性，模拟的车辆在测试（VUT）的平均旅行时间落在了INRIX历史数据定义的区间内。

Conclusion: 该研究提出的基于GNN和ACP的交通流量预测框架能够有效处理交通的随机性和时空依赖性，并提供可靠的不确定性量化，优于现有方法，并在模拟和真实数据中得到了验证。

Abstract: Traffic flow forecasting is essential for managing congestion, improving
safety, and optimizing various transportation systems. However, it remains a
prevailing challenge due to the stochastic nature of urban traffic and
environmental factors. Better predictions require models capable of
accommodating the traffic variability influenced by multiple dynamic and
complex interdependent factors. In this work, we propose a Graph Neural Network
(GNN) framework to address the stochasticity by leveraging adaptive adjacency
matrices using log-normal distributions and Coefficient of Variation (CV)
values to reflect real-world travel time variability. Additionally, weather
factors such as temperature, wind speed, and precipitation adjust edge weights
and enable GNN to capture evolving spatio-temporal dependencies across traffic
stations. This enhancement over the static adjacency matrix allows the model to
adapt effectively to traffic stochasticity and changing environmental
conditions. Furthermore, we utilize the Adaptive Conformal Prediction (ACP)
framework to provide reliable uncertainty quantification, achieving target
coverage while maintaining acceptable prediction intervals. Experimental
results demonstrate that the proposed model, in comparison with baseline
methods, showed better prediction accuracy and uncertainty bounds. We, then,
validate this method by constructing traffic scenarios in SUMO and applying
Monte-Carlo simulation to derive a travel time distribution for a Vehicle Under
Test (VUT) to reflect real-world variability. The simulated mean travel time of
the VUT falls within the intervals defined by INRIX historical data, verifying
the model's robustness.

</details>


### [687] [Hi-DARTS: Hierarchical Dynamically Adapting Reinforcement Trading System](https://arxiv.org/abs/2509.12048)
*Hoon Sagong,Heesu Kim,Hanbeen Hong*

Main category: cs.LG

TL;DR: Hi-DARTS是一个分层多智能体强化学习框架，通过动态调整交易频率来提高计算效率和市场响应能力，并在回测中取得了优于基准的收益。


<details>
  <summary>Details</summary>
Motivation: 传统的自主交易系统在计算效率和市场响应能力之间存在权衡，因为它们的操作频率是固定的。本研究旨在解决这一权衡问题。

Method: 提出了一种名为Hi-DARTS的分层多智能体强化学习框架。该框架使用一个元智能体来分析市场波动性，并根据需要动态激活专门用于高频或低频交易的时间框架智能体。

Result: 在2024年1月至2025年5月的AAPL股票回测中，Hi-DARTS实现了25.17%的累积回报和0.75的夏普比率，优于被动买入并持有策略（12.19%）和标普500 ETF（SPY）（20.01%）。

Conclusion: 动态、分层的智能体可以在保持高计算效率的同时，实现优越的风险调整后回报。

Abstract: Conventional autonomous trading systems struggle to balance computational
efficiency and market responsiveness due to their fixed operating frequency. We
propose Hi-DARTS, a hierarchical multi-agent reinforcement learning framework
that addresses this trade-off. Hi-DARTS utilizes a meta-agent to analyze market
volatility and dynamically activate specialized Time Frame Agents for
high-frequency or low-frequency trading as needed. During back-testing on AAPL
stock from January 2024 to May 2025, Hi-DARTS yielded a cumulative return of
25.17% with a Sharpe Ratio of 0.75. This performance surpasses standard
benchmarks, including a passive buy-and-hold strategy on AAPL (12.19% return)
and the S&P 500 ETF (SPY) (20.01% return). Our work demonstrates that dynamic,
hierarchical agents can achieve superior risk-adjusted returns while
maintaining high computational efficiency.

</details>


### [688] [A Time-Series Foundation Model by Universal Delay Embedding](https://arxiv.org/abs/2509.12080)
*Zijian Wang,Peng Tao,Jifan Shi,Rui Bao,Rui Liu,Luonan Chen*

Main category: cs.LG

TL;DR: UDE是一个结合了延迟嵌入和Koopman算子预测的预训练时间序列预测模型，通过将时间序列数据转化为图像补丁，并利用深度学习技术进行处理，实现了高效且可解释的预测。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种能够原则性地整合延迟嵌入表示和Koopman算子预测，以革新时间序列预测能力的预训练基础模型。

Method: 该方法利用Takens嵌入定理，通过Hankel矩阵构建二维子空间补丁来表示时间序列的动力学特性，并将这些补丁视为图像，利用深度学习技术进行处理。然后，这些补丁作为令牌，用于学习一个自注意力编码器，从而在潜在空间中以线性方式通过有限维Koopman算子实现非线性时间序列的准确预测。

Result: 在各种基准和真实世界的气候数据集上的广泛评估表明，与最先进的基础模型相比，均方误差平均降低了20%以上，并且在微调场景中具有卓越的泛化能力。学习到的动力学表示和Koopman算子预测形式具有出色的可解释性，能够一致地识别信息子空间并稳健地编码域不变动力学。

Conclusion: UDE提供了一个可扩展、可解释的通用时间序列建模和预测框架，具有广泛的科学和工业应用前景。

Abstract: This study introduces Universal Delay Embedding (UDE), a pretrained
foundation model designed to revolutionize time-series forecasting through
principled integration of delay embedding representation and Koopman operator
prediction. Leveraging Takens' embedding theorem, UDE as a dynamical
representation of observed data constructs two-dimensional subspace patches
from Hankel matrices, theoretically preserving dynamical and topological
properties of underlying dynamical systems. Such patches are viewed as images,
which can be efficiently processed by exploiting advanced deep learning
technologies. Computationally, these patches further serve as tokens for
learning a self-attention encoder, thus enabling accurate prediction of
nonlinear time-series by a finite-dimensional Koopman operator in a linear
manner in a latent space. Extensive evaluations across various benchmarks and
real-world climate datasets demonstrate over 20% average reduction in mean
squared error versus state-of-the-art foundation models, alongside superior
generalization in fine-tuning scenarios. In particular, the learned dynamical
representations and Koopman operator prediction forms from the patches exhibit
exceptional interpretability, with consistent identification of topologically
informative subspaces and robust encoding of domain-invariant dynamics,
establishing UDE as a scalable, interpretable framework for universal
time-series modeling and forecasting with broad scientific and industrial
applicability.

</details>


### [689] [Draw a Portrait of Your Graph Data: An Instance-Level Profiling Framework for Graph-Structured Data](https://arxiv.org/abs/2509.12094)
*Tianqi Zhao,Russa Biswas,Megha Khosla*

Main category: cs.LG

TL;DR: NodePro框架通过节点画像来细粒度诊断图模型行为，即使在整体性能相似的情况下也能揭示模型间的细微差别。


<details>
  <summary>Details</summary>
Motivation: 标准评估指标（如准确率）无法体现图模型在节点层面的细微行为差异，使得诊断模型失败原因和位置变得困难。

Method: NodePro框架结合了数据中心信号（如特征不相似性、标签不确定性和结构模糊性）和模型中心测量（如预测置信度和训练过程中的一致性），为单个节点分配可解释的画像分数。

Result: 节点画像能揭示模型行为的系统性差异，即使在聚合指标无法区分的情况下也能做到。节点画像能泛化到未见过的节点，支持在没有真实标签的情况下进行预测可靠性评估。

Conclusion: NodePro框架在识别结构化知识图谱中语义不一致或损坏的节点方面表现出实用性，证明了其在真实世界场景中的有效性。

Abstract: Graph machine learning models often achieve similar overall performance yet
behave differently at the node level, failing on different subsets of nodes
with varying reliability. Standard evaluation metrics such as accuracy obscure
these fine grained differences, making it difficult to diagnose when and where
models fail. We introduce NodePro, a node profiling framework that enables
fine-grained diagnosis of model behavior by assigning interpretable profile
scores to individual nodes. These scores combine data-centric signals, such as
feature dissimilarity, label uncertainty, and structural ambiguity, with
model-centric measures of prediction confidence and consistency during
training. By aligning model behavior with these profiles, NodePro reveals
systematic differences between models, even when aggregate metrics are
indistinguishable. We show that node profiles generalize to unseen nodes,
supporting prediction reliability without ground-truth labels. Finally, we
demonstrate the utility of NodePro in identifying semantically inconsistent or
corrupted nodes in a structured knowledge graph, illustrating its effectiveness
in real-world settings.

</details>


### [690] [$K$-Level Policy Gradients for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.12117)
*Aryaman Reddi,Gabriele Tiboni,Jan Peters,Carlo D'Eramo*

Main category: cs.LG

TL;DR: Actor-Critic算法在深度多智能体强化学习（MARL）中通常采用对其他智能体当前策略做出响应的策略更新，但忽略了同一更新步骤中其他智能体的更新，导致协调不一致。本文提出的K-Level Policy Gradient（KPG）方法，通过递归地针对其他智能体的更新策略来更新每个智能体，加速了有效协调策略的发现。我们理论上证明了在特定条件下，有限迭代的KPG可以收敛到局部纳什均衡。我们将KPG应用于MAPPO、MADDPG和FACMAC等深度MARL算法，并进行了原则性实现。实验结果表明，在《星际争霸II》和多智能体MuJoCo环境中，KPG的性能优于现有的深度MARL算法。


<details>
  <summary>Details</summary>
Motivation: Actor-critic算法在深度多智能体强化学习（MARL）中，通常采用对其他智能体当前策略做出响应的策略更新，这种方法忽略了同一更新步骤中其他智能体的更新，导致协调不一致。

Method: K-Level Policy Gradient（KPG），该方法通过递归地针对其他智能体的更新策略来更新每个智能体，以加速有效协调策略的发现。

Result: 我们对KPG进行了理论证明，证明了在特定条件下，有限迭代的KPG可以收敛到局部纳什均衡。我们还通过将KPG应用于MAPPO、MADDPG和FACMAC等深度MARL算法，并在《星际争霸II》和多智能体MuJoCo环境中进行了实验，结果表明KPG的性能优于现有的深度MARL算法。

Conclusion: KPG方法通过递归更新策略，解决了现有Actor-Critic算法在深度多智能体强化学习中存在的协调不一致问题，并能在特定条件下收敛到局部纳什均衡。实验证明了KPG在实际应用中的优越性。

Abstract: Actor-critic algorithms for deep multi-agent reinforcement learning (MARL)
typically employ a policy update that responds to the current strategies of
other agents. While being straightforward, this approach does not account for
the updates of other agents at the same update step, resulting in
miscoordination. In this paper, we introduce the $K$-Level Policy Gradient
(KPG), a method that recursively updates each agent against the updated
policies of other agents, speeding up the discovery of effective coordinated
policies. We theoretically prove that KPG with finite iterates achieves
monotonic convergence to a local Nash equilibrium under certain conditions. We
provide principled implementations of KPG by applying it to the deep MARL
algorithms MAPPO, MADDPG, and FACMAC. Empirically, we demonstrate superior
performance over existing deep MARL algorithms in StarCraft II and multi-agent
MuJoCo.

</details>


### [691] [Do machine learning climate models work in changing climate dynamics?](https://arxiv.org/abs/2509.12147)
*Maria Conchita Agana Navarro,Geng Li,Theo Wolf,María Pérez-Ortiz*

Main category: cs.LG

TL;DR: 机器学习模型在预测气候变化中的极端事件方面存在局限性，需要更鲁棒的评估框架。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致极端事件频发，预测这些“分布外”（OOD）事件对于风险评估和适应至关重要。然而，机器学习模型在气候预测中的泛化能力在OOD场景下仍有待探索。

Method: 通过改进现有的OOD评估方法，并将其应用于气候数据，系统地评估了最先进的机器学习气候模型的性能。

Result: 实验表明，在不同的OOD场景下，机器学习模型的性能表现出显著的差异，揭示了它们各自的优势和局限性。

Conclusion: 当前研究强调了建立鲁棒的评估框架的重要性，并为可靠地应用机器学习进行气候风险预测提供了有价值的见解。

Abstract: Climate change is accelerating the frequency and severity of unprecedented
events, deviating from established patterns. Predicting these
out-of-distribution (OOD) events is critical for assessing risks and guiding
climate adaptation. While machine learning (ML) models have shown promise in
providing precise, high-speed climate predictions, their ability to generalize
under distribution shifts remains a significant limitation that has been
underexplored in climate contexts. This research systematically evaluates
state-of-the-art ML-based climate models in diverse OOD scenarios by adapting
established OOD evaluation methodologies to climate data. Experiments on
large-scale datasets reveal notable performance variability across scenarios,
shedding light on the strengths and limitations of current models. These
findings underscore the importance of robust evaluation frameworks and provide
actionable insights to guide the reliable application of ML for climate risk
forecasting.

</details>


### [692] [Learning Neural Networks by Neuron Pursuit](https://arxiv.org/abs/2509.12154)
*Akshay Kumar,Jarvis Haupt*

Main category: cs.LG

TL;DR: 神经网络梯度流在稀疏鞍点附近的演化及其在深度网络训练中的应用。


<details>
  <summary>Details</summary>
Motivation: 从梯度流在稀疏鞍点附近的演化行为中获得启发，以改进深度神经网络的训练方法。

Method: 研究了稀疏鞍点附近梯度流的演化，并提出了一种名为Neuron Pursuit (NP) 的贪婪算法，该算法迭代地扩展网络并最小化训练损失。

Result: 梯度流在鞍点附近保持稳定，权重向量的方向收敛；Neuron Pursuit算法在数值实验中得到了验证。

Conclusion: 梯度流在稀疏鞍点附近的特殊行为为训练深度神经网络提供了新的思路，Neuron Pursuit算法是一种有效的训练方法。

Abstract: The first part of this paper studies the evolution of gradient flow for
homogeneous neural networks near a class of saddle points exhibiting a sparsity
structure. The choice of these saddle points is motivated from previous works
on homogeneous networks, which identified the first saddle point encountered by
gradient flow after escaping the origin. It is shown here that, when
initialized sufficiently close to such saddle points, gradient flow remains
near the saddle point for a sufficiently long time, during which the set of
weights with small norm remain small but converge in direction. Furthermore,
important empirical observations are made on the behavior of gradient descent
after escaping these saddle points. The second part of the paper, motivated by
these results, introduces a greedy algorithm to train deep neural networks
called Neuron Pursuit (NP). It is an iterative procedure which alternates
between expanding the network by adding neuron(s) with carefully chosen
weights, and minimizing the training loss using this augmented network. The
efficacy of the proposed algorithm is validated using numerical experiments.

</details>


### [693] [From Autoencoders to CycleGAN: Robust Unpaired Face Manipulation via Adversarial Learning](https://arxiv.org/abs/2509.12176)
*Collin Guo*

Main category: cs.LG

TL;DR: 提出了一种改进的CycleGAN框架，用于在无配对、未对齐的数据集上进行逼真的身份保留人脸合成和操作。


<details>
  <summary>Details</summary>
Motivation: 满足在娱乐和人工智能领域对高度逼真、身份保留的人脸图像日益增长的需求，即使在只有非配对、未对齐的数据集的情况下。

Method: 采用生成对抗学习，从自动编码器基线发展到改进的CycleGAN框架。该框架结合了谱归一化以实现稳定的训练，身份和感知引导损失以保留身份和高级结构，以及地标加权循环约束以在姿势和照明变化中保持面部几何形状。

Result: 与自动编码器相比，所提出的CycleGAN在真实性（FID）、感知质量（LPIPS）和身份保留（ID-Sim）方面均有提升，同时保持了具有竞争力的循环重建SSIM和实际的推理时间。在精心策划的配对子集上，其性能接近pix2pix。

Conclusion: 改进的、谱归一化的CycleGAN为从自动编码器实现稳健的非配对人脸操作提供了一条实用的途径。

Abstract: Human face synthesis and manipulation are increasingly important in
entertainment and AI, with a growing demand for highly realistic,
identity-preserving images even when only unpaired, unaligned datasets are
available. We study unpaired face manipulation via adversarial learning, moving
from autoencoder baselines to a robust, guided CycleGAN framework. While
autoencoders capture coarse identity, they often miss fine details. Our
approach integrates spectral normalization for stable training, identity- and
perceptual-guided losses to preserve subject identity and high-level structure,
and landmark-weighted cycle constraints to maintain facial geometry across pose
and illumination changes. Experiments show that our adversarial trained
CycleGAN improves realism (FID), perceptual quality (LPIPS), and identity
preservation (ID-Sim) over autoencoders, with competitive cycle-reconstruction
SSIM and practical inference times, which achieved high quality without paired
datasets and approaching pix2pix on curated paired subsets. These results
demonstrate that guided, spectrally normalized CycleGANs provide a practical
path from autoencoders to robust unpaired face manipulation.

</details>


### [694] [Dynamic Relational Priming Improves Transformer in Multivariate Time Series](https://arxiv.org/abs/2509.12196)
*Hunjae Lee,Corey Clark*

Main category: cs.LG

TL;DR: 标准注意力机制的静态表示限制了其在多元时间序列（MTS）数据上的表现。我们提出了具有动态关系先验的注意力（prime attention），它能为每个 token 动态调整表示，以更好地捕捉每个 token 对的独特关系动态，从而在 MTS 数据上取得更好的效果。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制在处理多元时间序列（MTS）数据时存在局限性，因为该类数据中不同通道对之间的关系可能受到不同物理定律或时间动态的支配，而标准注意力机制的静态表示无法有效捕捉这种异构依赖关系。

Method: 提出了一种名为“prime attention”的注意力机制。与标准注意力机制不同，prime attention 为每个 token 在每次交互中动态调整其表示，以更好地捕捉每个 token 对的独特关系动态，从而优化每次交互。

Result: Prime attention 在 MTS 数据上持续优于标准注意力机制，预测精度提高了 6.5%。此外，prime attention 在使用更短序列长度的情况下（减少 40%）也能达到相当或更好的性能。

Conclusion: Prime attention 通过动态调整 token 表示，能够更有效地捕捉 MTS 数据中的关系信息，并在预测精度和序列长度效率方面优于标准注意力机制。

Abstract: Standard attention mechanisms in transformers employ static token
representations that remain unchanged across all pair-wise computations in each
layer. This limits their representational alignment with the potentially
diverse relational dynamics of each token-pair interaction. While they excel in
domains with relatively homogeneous relationships, standard attention's static
relational learning struggles to capture the diverse, heterogeneous
inter-channel dependencies of multivariate time series (MTS) data--where
different channel-pair interactions within a single system may be governed by
entirely different physical laws or temporal dynamics. To better align the
attention mechanism for such domain phenomena, we propose attention with
dynamic relational priming (prime attention). Unlike standard attention where
each token presents an identical representation across all of its pair-wise
interactions, prime attention tailors each token dynamically (or per
interaction) through learnable modulations to best capture the unique
relational dynamics of each token pair, optimizing each pair-wise interaction
for that specific relationship. This representational plasticity of prime
attention enables effective extraction of relationship-specific information in
MTS while maintaining the same asymptotic computational complexity as standard
attention. Our results demonstrate that prime attention consistently
outperforms standard attention across benchmarks, achieving up to 6.5\%
improvement in forecasting accuracy. In addition, we find that prime attention
achieves comparable or superior performance using up to 40\% less sequence
length compared to standard attention, further demonstrating its superior
relational modeling capabilities.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [695] [Large Foundation Models for Trajectory Prediction in Autonomous Driving: A Comprehensive Survey](https://arxiv.org/abs/2509.10570)
*Wei Dai,Shengen Wu,Wei Wu,Zhenhao Wang,Sisuo Lyu,Haicheng Liao,Limin Yu,Weiping Ding,Runwei Guan,Yutao Yue*

Main category: cs.RO

TL;DR: 大型基础模型（LFMs），特别是大型语言模型（LLMs）和多模态大型语言模型（MLLMs），正在改变自动驾驶中轨迹预测的研究范式。它们通过整合语言和场景语义，提高了预测的安全性和泛化能力，解决了传统深度学习方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在轨迹预测方面存在可解释性差、依赖大规模标注数据、长尾场景泛化能力弱等局限性。大型基础模型（LFMs）的出现为解决这些问题提供了新的途径。

Method: 本文重点介绍了三种核心方法：轨迹-语言映射、多模态融合和基于约束的推理。文章还涵盖了车辆和行人的预测任务、评估指标和数据集分析。

Result: LFMs通过整合语言和场景语义，实现了可解释的上下文推理，显著提高了复杂环境下的预测安全性和泛化能力。

Conclusion: 尽管LFMs在轨迹预测方面展现出巨大潜力，但仍面临计算延迟、数据稀疏和实际鲁棒性等挑战。未来的研究方向包括低延迟推理、因果感知建模和运动基础模型。

Abstract: Trajectory prediction serves as a critical functionality in autonomous
driving, enabling the anticipation of future motion paths for traffic
participants such as vehicles and pedestrians, which is essential for driving
safety. Although conventional deep learning methods have improved accuracy,
they remain hindered by inherent limitations, including lack of
interpretability, heavy reliance on large-scale annotated data, and weak
generalization in long-tail scenarios. The rise of Large Foundation Models
(LFMs) is transforming the research paradigm of trajectory prediction. This
survey offers a systematic review of recent advances in LFMs, particularly
Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) for
trajectory prediction. By integrating linguistic and scene semantics, LFMs
facilitate interpretable contextual reasoning, significantly enhancing
prediction safety and generalization in complex environments. The article
highlights three core methodologies: trajectory-language mapping, multimodal
fusion, and constraint-based reasoning. It covers prediction tasks for both
vehicles and pedestrians, evaluation metrics, and dataset analyses. Key
challenges such as computational latency, data scarcity, and real-world
robustness are discussed, along with future research directions including
low-latency inference, causality-aware modeling, and motion foundation models.

</details>


### [696] [STL-Based Motion Planning and Uncertainty-Aware Risk Analysis for Human-Robot Collaboration with a Multi-Rotor Aerial Vehicle](https://arxiv.org/abs/2509.10692)
*Giuseppe Silano,Amr Afifi,Martin Saska,Antonio Franchi*

Main category: cs.RO

TL;DR: 该研究提出了一种使用多旋翼飞行器（MRAV）进行运动规划和风险分析的新方法，以增强人机协作。


<details>
  <summary>Details</summary>
Motivation: 为了在人机协作任务中，特别是涉及MRAV时，考虑安全性、时序、人类偏好、人体工程学和舒适度等关键任务目标，并处理计算复杂性，需要一种新颖的方法。

Method: 该方法利用信号时序逻辑（STL）来编码任务目标，并结合优化框架来生成考虑MRAV物理约束的动态可行轨迹。同时，采用平滑近似和基于梯度的技术处理计算复杂性，并引入了不确定性感知的风险分析来评估潜在偏差。此外，还实施了事件触发的重新规划策略以应对意外情况。

Result: 通过MATLAB和Gazebo仿真，在模拟电力线维护场景的物体交接任务中，验证了该方法在实现安全、高效和有弹性的人机协作方面的有效性。

Conclusion: 所提出的基于STL的运动规划和风险分析方法能够有效地增强多旋翼飞行器在人机协作任务中的安全性、效率和鲁棒性。

Abstract: This paper presents a novel approach to motion planning and risk analysis for
enhancing human-robot collaboration using a Multi-Rotor Aerial Vehicle (MRAV).
The proposed method uses Signal Temporal Logic (STL) to encode key mission
objectives, such as safety, timing, and human preferences, with a strong focus
on ergonomics and comfort. An optimization framework generates dynamically
feasible trajectories while considering the MRAV's physical constraints. Given
the nonlinear and non-convex nature of the problem, smooth approximations and
gradient-based techniques assist in handling the problem's computational
complexity. Additionally, an uncertainty-aware risk analysis is incorporated to
assess potential deviations from the mission specifications, providing insights
into the likelihood of mission success under uncertain conditions. Further, an
event-triggered replanning strategy is implemented to respond to unforeseen
events and external disturbances. The approach is validated through MATLAB and
Gazebo simulations, using an object handover task in a mock-up environment
inspired by power line maintenance scenarios. The results highlight the
method's effectiveness in achieving safe, efficient, and resilient human-robot
collaboration.

</details>


### [697] [A Survey on LiDAR-based Autonomous Aerial Vehicles](https://arxiv.org/abs/2509.10730)
*Yunfan Ren,Yixi Cai,Haotian Li,Nan Chen,Fangcheng Zhu,Longji Yin,Fanze Kong,Rundong Li,Fu Zhang*

Main category: cs.RO

TL;DR: 本综述全面概述了基于激光雷达的自主无人机（UAV）的最新进展，涵盖了其设计、感知、规划和控制策略。


<details>
  <summary>Details</summary>
Motivation: 激光雷达技术已成为高速、敏捷和可靠的无人机导航的关键推动者，尤其是在 GPS 拒绝的环境中。

Method: 本综述考察了激光雷达传感器的演变，探讨了感知技术（状态估计和绘图）以及轨迹规划和控制方法，并分析了各种实际应用和多无人机部署。

Result: 基于激光雷达的无人机已显著增强了其自主性，能够在各种具有挑战性的环境中执行复杂任务，并已应用于工业运营和无人机群部署。

Conclusion: 本综述讨论了现有的挑战，并提出了未来的研究方向，以推进基于激光雷达的无人机并加强多无人机协作。

Abstract: This survey offers a comprehensive overview of recent advancements in
LiDAR-based autonomous Unmanned Aerial Vehicles (UAVs), covering their design,
perception, planning, and control strategies. Over the past decade, LiDAR
technology has become a crucial enabler for high-speed, agile, and reliable UAV
navigation, especially in GPS-denied environments. The paper begins by
examining the evolution of LiDAR sensors, emphasizing their unique advantages
such as high accuracy, long-range depth measurements, and robust performance
under various lighting conditions, making them particularly well-suited for UAV
applications. The integration of LiDAR with UAVs has significantly enhanced
their autonomy, enabling complex missions in diverse and challenging
environments. Subsequently, we explore essential software components, including
perception technologies for state estimation and mapping, as well as trajectory
planning and control methodologies, and discuss their adoption in LiDAR-based
UAVs. Additionally, we analyze various practical applications of the
LiDAR-based UAVs, ranging from industrial operations to supporting different
aerial platforms and UAV swarm deployments. The survey concludes by discussing
existing challenges and proposing future research directions to advance
LiDAR-based UAVs and enhance multi-UAV collaboration. By synthesizing recent
developments, this paper aims to provide a valuable resource for researchers
and practitioners working to push the boundaries of LiDAR-based UAV systems.

</details>


### [698] [Analytical Design and Development of a Modular and Intuitive Framework for Robotizing and Enhancing the Existing Endoscopic Procedures](https://arxiv.org/abs/2509.10735)
*Mohammad Rafiee Javazm,Yash Kulkarni,Jiaqi Xue,Naruhiko Ikoma,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 该研究提出了一种直观、模块化且易于安装的机电框架，用于解决内窥镜手动控制的挑战，包括一个嵌套的弹簧夹夹持器、一个馈送器和用户界面，并通过数学建模和仿真进行了验证。


<details>
  <summary>Details</summary>
Motivation: 手动控制内窥镜设备存在挑战，导致临床医生工作负荷增加、疲劳和分心，影响了癌症筛查程序的效率和安全性。

Method: 设计并开发了一个包含新型嵌套弹簧夹夹持机构（控制弯曲自由度）、馈送机构（控制插入/回缩自由度）和用户界面（同步控制所有自由度）的机电框架。同时，引入了数学建模方法和设计空间来优化参数选择。

Result: 仿真和实验研究证明了所提出的数学建模和机器人框架的性能。

Conclusion: 所提出的机电框架能够有效解决手动控制内窥镜设备的挑战，通过直观的控制和优化的设计，提高了操作的精确性和效率。

Abstract: Despite the widespread adoption of endoscopic devices for several cancer
screening procedures, manual control of these devices still remains challenging
for clinicians, leading to several critical issues such as increased workload,
fatigue, and distractions. To address these issues, in this paper, we introduce
the design and development of an intuitive, modular, and easily installable
mechatronic framework. This framework includes (i) a novel nested collet-chuck
gripping mechanism that can readily be integrated and assembled with the
existing endoscopic devices and control their bending degrees-of-freedom
(DoFs); (ii) a feeder mechanism that can control the insertion/retraction DoF
of a colonoscope, and (iii) a complementary and intuitive user interface that
enables simultaneous control of all DoFs during the procedure. To analyze the
design of the proposed mechanisms, we also introduce a mathematical modeling
approach and a design space for optimal selection of the parameters involved in
the design of gripping and feeder mechanisms. Our simulation and experimental
studies thoroughly demonstrate the performance of the proposed mathematical
modeling and robotic framework.

</details>


### [699] [FastTrack: GPU-Accelerated Tracking for Visual SLAM](https://arxiv.org/abs/2509.10757)
*Kimia Khabiri,Parsa Hosseininejad,Shishir Gopinath,Karthik Dantu,Steven Y. Ko*

Main category: cs.RO

TL;DR: 通过利用GPU加速视觉-惯性SLAM系统的跟踪模块中的关键组件（立体特征匹配和局部地图跟踪），显著提高了跟踪性能（最高可达2.8倍），尤其是在立体-惯性模式下，并在EuRoC和TUM-VI数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 视觉-惯性SLAM（Simultaneous Localization and Mapping）系统的跟踪模块需要及时处理图像帧和IMU数据以估计帧的位置，否则会导致定位不佳或跟踪丢失。因此，有必要提高跟踪的性能。

Method: 提出了一种利用GPU计算能力加速视觉-惯性SLAM系统跟踪模块中耗时组件（立体特征匹配和局部地图跟踪）的新方法，并使用CUDA在ORB-SLAM3中实现。

Result: 在台式机和Jetson Xavier NX板上，使用立体-惯性模式，在EuRoC和TUM-VI数据集上，跟踪性能实现了最高2.8倍的提升。

Conclusion: 通过GPU加速关键组件，可以显著提高视觉-惯性SLAM系统的跟踪性能，从而改善系统的整体表现。

Abstract: The tracking module of a visual-inertial SLAM system processes incoming image
frames and IMU data to estimate the position of the frame in relation to the
map. It is important for the tracking to complete in a timely manner for each
frame to avoid poor localization or tracking loss. We therefore present a new
approach which leverages GPU computing power to accelerate time-consuming
components of tracking in order to improve its performance. These components
include stereo feature matching and local map tracking. We implement our design
inside the ORB-SLAM3 tracking process using CUDA. Our evaluation demonstrates
an overall improvement in tracking performance of up to 2.8x on a desktop and
Jetson Xavier NX board in stereo-inertial mode, using the well-known SLAM
datasets EuRoC and TUM-VI.

</details>


### [700] [RSL-RL: A Learning Library for Robotics Research](https://arxiv.org/abs/2509.10771)
*Clemens Schwarke,Mayank Mittal,Nikita Rudin,David Hoeller,Marco Hutter*

Main category: cs.RO

TL;DR: RSL-RL是一个专为机器人领域设计的开源强化学习库，注重代码简洁、易于修改和机器人特定算法，支持GPU加速，并在仿真和真实机器人实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: RSL-RL旨在满足机器人领域对强化学习库的特定需求，提供一个比通用框架更紧凑、更易于修改的代码库，方便研究人员快速适应和扩展算法。

Method: 该库专注于机器人领域最广泛采用的算法，并结合了解决机器人特定挑战的辅助技术。它针对仅GPU训练进行了优化，在大型仿真环境中实现了高吞吐量性能。

Result: RSL-RL在仿真基准和真实机器人实验中都得到了有效验证，证明了其作为开发基于学习的机器人控制器方面的轻量级、可扩展且实用的框架的优势。

Conclusion: RSL-RL是一个轻量级、可扩展且实用的开源框架，适用于开发基于学习的机器人控制器，其设计和性能在机器人研究领域具有实际价值。

Abstract: RSL-RL is an open-source Reinforcement Learning library tailored to the
specific needs of the robotics community. Unlike broad general-purpose
frameworks, its design philosophy prioritizes a compact and easily modifiable
codebase, allowing researchers to adapt and extend algorithms with minimal
overhead. The library focuses on algorithms most widely adopted in robotics,
together with auxiliary techniques that address robotics-specific challenges.
Optimized for GPU-only training, RSL-RL achieves high-throughput performance in
large-scale simulation environments. Its effectiveness has been validated in
both simulation benchmarks and in real-world robotic experiments, demonstrating
its utility as a lightweight, extensible, and practical framework to develop
learning-based robotic controllers. The library is open-sourced at:
https://github.com/leggedrobotics/rsl_rl.

</details>


### [701] [Follow-Bench: A Unified Motion Planning Benchmark for Socially-Aware Robot Person Following](https://arxiv.org/abs/2509.10796)
*Hanjing Ye,Weixi Situ,Jianwei Peng,Yu Zhan,Bingyi Xia,Kuanqi Cai,Hong Zhang*

Main category: cs.RO

TL;DR: 本研究提出了一个名为Follow-Bench的机器人跟随基准，用于评估和改进机器人跟随人的能力，特别是在安全性和舒适性方面。


<details>
  <summary>Details</summary>
Motivation: 机器人跟随人（RPF）在个人助理、安全巡逻、老年人护理和物流等领域具有新兴应用。为了有效，机器人必须在确保目标和周围人员的安全与舒适的同时跟随目标。本研究旨在解决RPF中的安全和舒适性问题，并提供一个统一的评估平台。

Method: 本研究通过（i）对RPF场景、运动规划方法和评估指标进行调查，重点关注安全性和舒适性；（ii）引入Follow-Bench，一个模拟各种场景（包括目标轨迹模式、动态人群流和环境布局）的统一基准；（iii）重新实现了六种流行的RPF规划器，确保系统地考虑安全性和舒适性。

Result: 在Follow-Bench基准上对两种表现最佳的规划器进行了评估，并提供了真实世界部署的见解。通过广泛的模拟和真实世界实验，对现有规划器的安全-舒适权衡进行了量化分析，并揭示了开放的挑战和未来的研究方向。

Conclusion: 本研究提出了一个全面的RPF研究，引入了一个新的基准（Follow-Bench），并对现有方法进行了评估，为RPF领域的研究和实际应用提供了宝贵的见解和方向。

Abstract: Robot person following (RPF) -- mobile robots that follow and assist a
specific person -- has emerging applications in personal assistance, security
patrols, eldercare, and logistics. To be effective, such robots must follow the
target while ensuring safety and comfort for both the target and surrounding
people. In this work, we present the first end-to-end study of RPF, which (i)
surveys representative scenarios, motion-planning methods, and evaluation
metrics with a focus on safety and comfort; (ii) introduces Follow-Bench, a
unified benchmark simulating diverse scenarios, including various target
trajectory patterns, dynamic-crowd flows, and environmental layouts; and (iii)
re-implements six popular RPF planners, ensuring that both safety and comfort
are systematically considered. Moreover, we evaluate the two highest-performing
planners from our benchmark on a differential-drive robot to provide insights
into real-world deployment. Extensive simulation and real-world experiments
provide quantitative insights into the safety-comfort trade-offs of existing
planners, while revealing open challenges and future research directions.

</details>


### [702] [A Universal Wire Testing Machine for Enhancing the Performance of Wire-Driven Robots](https://arxiv.org/abs/2509.10862)
*Temma Suzuki,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 与齿轮和连杆相比，线缆构成了一种轻质、低摩擦的传动机构。然而，由于线缆是柔性材料，它们往往会引入大的建模误差，并且在工业和研究机器人中的应用仍然有限。本研究构建了一种通用线缆测试机，可以测量和调整线缆特性，以改进线缆驱动机构的性能。利用该测试机，我们进行了初始线缆拉伸去除、八种不同直径的被动滑轮的张力传输效率测量以及变长线缆的动态行为测量。最后，我们将从该测试机获得的数据应用于实际线缆驱动机器人的力控制，从而减小了末端执行器的力误差。


<details>
  <summary>Details</summary>
Motivation: 线缆作为一种轻质、低摩擦的传动机构，相比于齿轮和连杆具有优势，但其柔性易引入建模误差，限制了其在机器人领域的应用。本研究旨在通过测量和调整线缆特性来改进线缆驱动机构的性能，以克服这些限制。

Method: 研究中构建了一种通用线缆测试机，并利用该测试机进行了以下实验：1. 移除了初始线缆拉伸。2. 测量了八种不同直径被动滑轮的张力传输效率。3. 测量了变长线缆的动态行为。最后，将实验获得的数据应用于实际线缆驱动机器人的力控制。

Result: 通过通用线缆测试机进行了线缆特性测量，包括初始拉伸去除、不同直径滑轮的张力传输效率以及变长线缆的动态行为。将这些数据应用于实际线缆驱动机器人的力控制，成功减小了末端执行器的力误差。

Conclusion: 本研究通过构建通用线缆测试机，有效地测量和调整了线缆特性，并通过将实验数据应用于实际机器人，证明了该方法能够改进线缆驱动机构的性能，并减小末端执行器的力误差。

Abstract: Compared with gears and linkages, wires constitute a lightweight,
low-friction transmission mechanism. However, because wires are flexible
materials, they tend to introduce large modeling errors, and their adoption in
industrial and research robots remains limited.In this study, we built a
Universal Wire Testing Machine that enables measurement and adjustment of wire
characteristics to improve the performance of wire-driven mechanisms. Using
this testing machine, we carried out removal of initial wire stretch,
measurement of tension transmission efficiency for eight different diameters of
passive pulleys, and measurement of the dynamic behavior of variable-length
wires. Finally, we applied the data obtained from this testing machine to the
force control of an actual wire-driven robot, reducing the end-effector force
error.

</details>


### [703] [Nav-R1: Reasoning and Navigation in Embodied Scenes](https://arxiv.org/abs/2509.10884)
*Qingxiang Liu,Ting Huang,Zeyu Zhang,Hao Tang*

Main category: cs.RO

TL;DR: Nav-R1是一个统一的具身环境推理的基础模型，通过Nav-CoT-110K数据集、GRPO强化学习框架和Fast-in-Slow推理范式，提高了推理和导航性能，并在真实机器人上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有具身导航方法在复杂3D环境中存在推理不连贯、泛化能力差以及长期语义推理与实时控制难以平衡的问题。

Method: 提出Nav-R1基础模型，包含大规模CoT数据集Nav-CoT-110K，GRPO强化学习框架（包含格式、理解、导航三类奖励），以及Fast-in-Slow推理范式（解耦语义推理与反应式控制）。

Result: 在具身AI基准测试中，Nav-R1的推理和导航性能平均提升超过8%，优于现有方法。在真实移动机器人上的部署也验证了其鲁棒性。

Conclusion: Nav-R1通过统一推理、大规模CoT数据集、优化的强化学习框架和新颖的推理范式，有效解决了具身导航中的挑战，并在模拟和现实环境中都取得了显著的性能提升。

Abstract: Embodied navigation requires agents to integrate perception, reasoning, and
action for robust interaction in complex 3D environments. Existing approaches
often suffer from incoherent and unstable reasoning traces that hinder
generalization across diverse environments, and difficulty balancing
long-horizon semantic reasoning with low-latency control for real-time
navigation. To address these challenges, we propose Nav-R1, an embodied
foundation model that unifies reasoning in embodied environments. We first
construct Nav-CoT-110K, a large-scale dataset of step-by-step Chains-of-Thought
(CoT) for embodied tasks, which enables cold-start initialization with
structured reasoning. Building on this foundation, we design a GRPO-based
reinforcement learning framework with three complementary rewards: format,
understanding, and navigation, to improve structural adherence, semantic
grounding, and path fidelity. Furthermore, we introduce a Fast-in-Slow
reasoning paradigm, decoupling deliberate semantic reasoning from low-latency
reactive control for efficient yet coherent navigation. Extensive evaluations
on embodied AI benchmarks demonstrate that Nav-R1 consistently outperforms
strong baselines, with over 8% average improvement in reasoning and navigation
performance. Real-world deployment on a mobile robot further validates its
robustness under limited onboard resources. Code:
https://github.com/AIGeeksGroup/Nav-R1. Website:
https://aigeeksgroup.github.io/Nav-R1.

</details>


### [704] [Design of scalable orthogonal digital encoding architecture for large-area flexible tactile sensing in robotics](https://arxiv.org/abs/2509.10888)
*Weijie Liu,Ziyi Qiu,Shihang Wang,Deqing Mei,Yancheng Wang*

Main category: cs.RO

TL;DR: 提出了一种采用码分多址启发式正交数字编码的新型架构，以解决柔性触觉传感器在编码效率和布线复杂性方面的瓶颈，实现了大规模、高灵敏度、全覆盖的类人触觉感知。


<details>
  <summary>Details</summary>
Motivation: 现有柔性触觉传感器在编码效率和布线复杂性方面存在瓶颈，限制了其在大规模、全覆盖的类人触觉感知方面的应用，亟需改进以实现机器人技术的进步。

Method: 提出一种受码分多址启发的正交数字编码新架构，采用去中心化编码策略，通过并行叠加来自分布式传感节点的能量正交基码，替代传统的串行信号传输，从而减少布线需求并提高数据吞吐量。使用现成的16节点传感阵列进行实现和验证。

Result: 实现的系统具有12.8毫秒的时间分辨率，仅使用一根传输线即可重建压力分布，并且在节点数量变化数个数量级（最多数千个节点）的情况下，仍能保持低于20毫秒的延迟。

Conclusion: 通过重新定义软电子信号编码范式，该研究为开发具有类人感官能力的可扩展的具身智能系统开辟了新途径。

Abstract: Human-like embodied tactile perception is crucial for the next-generation
intelligent robotics. Achieving large-area, full-body soft coverage with high
sensitivity and rapid response, akin to human skin, remains a formidable
challenge due to critical bottlenecks in encoding efficiency and wiring
complexity in existing flexible tactile sensors, thus significantly hinder the
scalability and real-time performance required for human skin-level tactile
perception. Herein, we present a new architecture employing code division
multiple access-inspired orthogonal digital encoding to overcome these
challenges. Our decentralized encoding strategy transforms conventional serial
signal transmission by enabling parallel superposition of energy-orthogonal
base codes from distributed sensing nodes, drastically reducing wiring
requirements and increasing data throughput. We implemented and validated this
strategy with off-the-shelf 16-node sensing array to reconstruct the pressure
distribution, achieving a temporal resolution of 12.8 ms using only a single
transmission wire. Crucially, the architecture can maintain sub-20ms latency
across orders-of-magnitude variations in node number (to thousands of nodes).
By fundamentally redefining signal encoding paradigms in soft electronics, this
work opens new frontiers in developing scalable embodied intelligent systems
with human-like sensory capabilities.

</details>


### [705] [ViSTR-GP: Online Cyberattack Detection via Vision-to-State Tensor Regression and Gaussian Processes in Automated Robotic Operations](https://arxiv.org/abs/2509.10948)
*Navid Aftabi,Philip Samaha,Jin Ma,Long Cheng,Ramy Harik,Dan Li*

Main category: cs.RO

TL;DR: 本论文提出了一种名为 ViSTR-GP 的在线检测框架，利用机器人运动的视觉估计和编码器报告的测量值之间的差异来检测针对工业机器人数据完整性攻击。


<details>
  <summary>Details</summary>
Motivation: 工业机器人是智能制造的核心，但面临日益增长的网络安全风险，特别是数据完整性攻击，现有检测方法难以发现。本研究旨在利用机器人运动的物理侧信道来检测此类攻击。

Method: ViSTR-GP 框架首先使用 SAM-Track 对视频帧进行分割，然后通过低秩张量回归将分割结果映射到测量值，最后使用矩阵变量高斯过程模型来捕获时间和跨关节的相关性，从而计算出一个帧-wise 的统计量进行在线检测。

Result: 在真实机器人测试平台上，ViSTR-GP 框架能够准确恢复关节角度，并比现有基线方法更早、更频繁地检测到数据完整性攻击，尤其对细微的攻击效果更佳。

Conclusion: 通过增加一个独立于控制器权限的物理检测通道（例如，使用外部摄像头进行视觉估计），可以在不进行复杂仪器升级的情况下，有效检测工业机器人中的数据完整性攻击。

Abstract: Industrial robotic systems are central to automating smart manufacturing
operations. Connected and automated factories face growing cybersecurity risks
that can potentially cause interruptions and damages to physical operations.
Among these attacks, data-integrity attacks often involve sophisticated
exploitation of vulnerabilities that enable an attacker to access and
manipulate the operational data and are hence difficult to detect with only
existing intrusion detection or model-based detection. This paper addresses the
challenges in utilizing existing side-channels to detect data-integrity attacks
in robotic manufacturing processes by developing an online detection framework,
ViSTR-GP, that cross-checks encoder-reported measurements against a
vision-based estimate from an overhead camera outside the controller's
authority. In this framework, a one-time interactive segmentation initializes
SAM-Track to generate per-frame masks. A low-rank tensor-regression surrogate
maps each mask to measurements, while a matrix-variate Gaussian process models
nominal residuals, capturing temporal structure and cross-joint correlations. A
frame-wise test statistic derived from the predictive distribution provides an
online detector with interpretable thresholds. We validate the framework on a
real-world robotic testbed with synchronized video frame and encoder data,
collecting multiple nominal cycles and constructing replay attack scenarios
with graded end-effector deviations. Results on the testbed indicate that the
proposed framework recovers joint angles accurately and detects data-integrity
attacks earlier with more frequent alarms than all baselines. These
improvements are most evident in the most subtle attacks. These results show
that plants can detect data-integrity attacks by adding an independent physical
channel, bypassing the controller's authority, without needing complex
instrumentation.

</details>


### [706] [ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation](https://arxiv.org/abs/2509.10952)
*Yangcen Liu,Woo Chul Shin,Yunhai Han,Zhenyang Chen,Harish Ravichandar,Danfei Xu*

Main category: cs.RO

TL;DR: ImMimic是一个无需特定机器人即可进行模仿学习的框架，通过动态时间规整（DTW）和MixUp插值来弥合人类视频和机器人演示之间的领域差距，从而提高机器人操作的成功率和流畅度。


<details>
  <summary>Details</summary>
Motivation: 直接从海量人类视频中学习机器人操作存在视觉、形态和物理方面的领域差距，需要有效的跨领域迁移方法。

Method: ImMimic框架利用动态时间规整（DTW）和MixUp插值。DTW通过基于动作或视觉的映射将人类手部姿势映射到机器人关节，MixUp则在映射后的人类和机器人轨迹之间进行插值，以创建中间领域进行协同训练。

Result: 在四个机器人实体（Robotiq、Fin Ray、Allegro、Ability）和四个现实操作任务（拾取和放置、推、锤、翻转）上的评估显示，ImMimic提高了任务成功率和执行流畅度。

Conclusion: ImMimic有效地弥合了领域差距，实现了在不同机器人上的鲁棒操作，证明了其在机器人操作领域迁移学习中的有效性。

Abstract: Learning robot manipulation from abundant human videos offers a scalable
alternative to costly robot-specific data collection. However, domain gaps
across visual, morphological, and physical aspects hinder direct imitation. To
effectively bridge the domain gap, we propose ImMimic, an embodiment-agnostic
co-training framework that leverages both human videos and a small amount of
teleoperated robot demonstrations. ImMimic uses Dynamic Time Warping (DTW) with
either action- or visual-based mapping to map retargeted human hand poses to
robot joints, followed by MixUp interpolation between paired human and robot
trajectories. Our key insights are (1) retargeted human hand trajectories
provide informative action labels, and (2) interpolation over the mapped data
creates intermediate domains that facilitate smooth domain adaptation during
co-training. Evaluations on four real-world manipulation tasks (Pick and Place,
Push, Hammer, Flip) across four robotic embodiments (Robotiq, Fin Ray, Allegro,
Ability) show that ImMimic improves task success rates and execution
smoothness, highlighting its efficacy to bridge the domain gap for robust robot
manipulation. The project website can be found at
https://sites.google.com/view/immimic.

</details>


### [707] [Pogosim -- a Simulator for Pogobot robots](https://arxiv.org/abs/2509.10968)
*Leo Cazenille,Loona Macabre,Nicolas Bredeche*

Main category: cs.RO

TL;DR: Pogobots是一种用于群体机器人研究的开源/开放硬件机器人，Pogosim是其配套的快速可扩展模拟器，可用于算法开发、参数优化和结果分析。


<details>
  <summary>Details</summary>
Motivation: 直接在机器人上测试分布式算法劳动密集且难以扩展，因此需要一个模拟器来降低算法开发成本。

Method: Pogosim模拟器可以运行与真实机器人相同的代码，支持并行启动大量模拟，并提供结果检索、分析和用户代码参数优化功能。

Result: Pogosim能够显著降低群体机器人算法开发成本，并能通过参数优化提高用户代码性能。

Conclusion: Pogosim是一个有效的工具，可以加速Pogobots的研究和开发，并弥合模拟与实际机器人实验之间的差距。

Abstract: Pogobots are a new type of open-source/open-hardware robots specifically
designed for swarm robotics research. Their cost-effective and modular design,
complemented by vibration-based and wheel-based locomotion, fast infrared
communication and extensive software architecture facilitate the implementation
of swarm intelligence algorithms. However, testing even simple distributed
algorithms directly on robots is particularly labor-intensive. Scaling to more
complex problems or calibrate user code parameters will have a prohibitively
high strain on available resources. In this article we present Pogosim, a fast
and scalable simulator for Pogobots, designed to reduce as much as possible
algorithm development costs. The exact same code will be used in both
simulation and to experimentally drive real robots. This article details the
software architecture of Pogosim, explain how to write configuration files and
user programs and how simulations approximate or differ from experiments. We
describe how a large set of simulations can be launched in parallel, how to
retrieve and analyze the simulation results, and how to optimize user code
parameters using optimization algorithms.

</details>


### [708] [Autonomous Close-Proximity Photovoltaic Panel Coating Using a Quadcopter](https://arxiv.org/abs/2509.10979)
*Dimitri Jacquemont,Carlo Bosio,Teaya Yang,Ruiqi Zhang,Ozgur Orun,Shuai Li,Reza Alam,Thomas M. Schutzius,Simo A. Makiharju,Mark W. Mueller*

Main category: cs.RO

TL;DR: 利用无人机自动为光伏板喷涂增益涂层


<details>
  <summary>Details</summary>
Motivation: 光伏板效率提升有助于实现能源转型，但其增益涂层会随时间退化，需要定期重新喷涂。无人机可提供一种比传统手动方法更灵活、更经济的选项。

Method: 提出了一种基于四旋翼无人机的系统，配备了液体喷洒装置，实现了光伏板涂层喷洒任务的自动化。该系统仅使用车载传感器进行定位，利用视觉-惯性里程计和无人机相对于光伏板的相对位置。控制系统采用基于模型的控制器，考虑了地面效应和液体喷洒过程中无人机质量的变化。通过广泛的室内外实验验证了系统的自主能力。

Result: 通过广泛的室内外实验验证了系统的自主能力。

Conclusion: 无人机系统能够自主为光伏板喷涂增益涂层。

Abstract: Photovoltaic (PV) panels are becoming increasingly widespread in the domain
of renewable energy, and thus, small efficiency gains can have massive effects.
Anti-reflective and self-cleaning coatings enhance panel performance but
degrade over time, requiring periodic reapplication. Uncrewed Aerial Vehicles
(UAVs) offer a flexible and autonomous way to apply protective coatings more
often and at lower cost compared to traditional manual coating methods. In this
letter, we propose a quadcopter-based system, equipped with a liquid dispersion
mechanism, designed to automate such tasks. The localization stack only uses
onboard sensors, relying on visual-inertial odometry and the relative position
of the PV panel detected with respect to the quadcopter. The control relies on
a model-based controller that accounts for the ground effect and the mass
decrease of the quadcopter during liquid dispersion. We validate the autonomy
capabilities of our system through extensive indoor and outdoor experiments.

</details>


### [709] [Multi-objective task allocation for electric harvesting robots: a hierarchical route reconstruction approach](https://arxiv.org/abs/2509.11025)
*Peng Chen,Jing Liang,Hui Song,Kang-Jia Qiao,Cai-Tong Yue,Kun-Jie Yu,Ponnuthurai Nagaratnam Suganthan,Witold Pedrycz*

Main category: cs.RO

TL;DR: 本研究提出了一个名为AMERTA的新问题定义，并设计了一个混合分层路径重构算法（HRRA）来解决多机器人协同在果园采摘中的效率和能源消耗问题，该算法考虑了实际的负载依赖速度变化和电池限制等约束。实验结果表明，HRRA在效率和能源消耗方面优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 农业劳动力成本的上升和对提高效率的需求，促使需要更有效的多机器人协同采摘系统，但现有的系统在处理 makespan 和能源消耗的复杂权衡以及实际约束（如速度变化和电池限制）方面存在挑战。

Method: 提出了一种混合分层路径重构算法（HRRA），该算法包含分层编码结构、双阶段初始化方法、任务序列优化器和专门的路径重构算子，以解决AMERTA问题。

Result: 在45个测试实例上的广泛实验表明，HRRA的性能优于七种最先进的算法，并通过统计分析（Wilcoxon signed-rank和Friedman检验）验证了其竞争力和探索新解空间的能力。

Conclusion: 本研究通过提出新的问题定义和有效的算法，为多机器人协同理论做出了贡献，并为农业自动化提供了实际见解。

Abstract: The increasing labor costs in agriculture have accelerated the adoption of
multi-robot systems for orchard harvesting. However, efficiently coordinating
these systems is challenging due to the complex interplay between makespan and
energy consumption, particularly under practical constraints like
load-dependent speed variations and battery limitations. This paper defines the
multi-objective agricultural multi-electrical-robot task allocation (AMERTA)
problem, which systematically incorporates these often-overlooked real-world
constraints. To address this problem, we propose a hybrid hierarchical route
reconstruction algorithm (HRRA) that integrates several innovative mechanisms,
including a hierarchical encoding structure, a dual-phase initialization
method, task sequence optimizers, and specialized route reconstruction
operators. Extensive experiments on 45 test instances demonstrate HRRA's
superior performance against seven state-of-the-art algorithms. Statistical
analysis, including the Wilcoxon signed-rank and Friedman tests, empirically
validates HRRA's competitiveness and its unique ability to explore previously
inaccessible regions of the solution space. In general, this research
contributes to the theoretical understanding of multi-robot coordination by
offering a novel problem formulation and an effective algorithm, thereby also
providing practical insights for agricultural automation.

</details>


### [710] [FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers](https://arxiv.org/abs/2509.11109)
*Jiaxin Huang,Hanyu Liu,Yunsheng Ma,Jian Shen,Yilin Zheng,Jiayi Wen,Baishu Wan,Pan Li,Zhigong Song*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 FEWT 的模仿学习框架，结合了多尺度小波分解和残差网络，用于增强人形机器人的感知表征，并通过实验证明其在模拟和现实世界中均优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合物理世界与信息空间，并通过人形机器人实现直观的远程操控和高效的拟人动作数据收集。

Method: 开发了一个包含人形机器人和外骨骼式遥操作舱的硬件平台，并提出了 FEWT 模仿学习框架，包含 FE-EMA 和 TS-DWT 模块，以增强机器人的感知表征。

Result: FEWT 框架在模拟环境中将 ACT 基线算法的成功率提高了 30%，在现实世界中提高了 6-12%。

Conclusion: FEWT 框架通过融合时域和频域特征，提高了人形机器人的感知能力和任务成功率。

Abstract: The embodied intelligence bridges the physical world and information space.
As its typical physical embodiment, humanoid robots have shown great promise
through robot learning algorithms in recent years. In this study, a hardware
platform, including humanoid robot and exoskeleton-style teleoperation cabin,
was developed to realize intuitive remote manipulation and efficient collection
of anthropomorphic action data. To improve the perception representation of
humanoid robot, an imitation learning framework, termed Frequency-Enhanced
Wavelet-based Transformer (FEWT), was proposed, which consists of two primary
modules: Frequency-Enhanced Efficient Multi-Scale Attention (FE-EMA) and
Time-Series Discrete Wavelet Transform (TS-DWT). By combining multi-scale
wavelet decomposition with the residual network, FE-EMA can dynamically fuse
features from both time-domain and frequency-domain. This fusion is able to
capture feature information across various scales effectively, thereby
enhancing model robustness. Experimental performance demonstrates that FEWT
improves the success rate of the state-of-the-art algorithm (Action Chunking
with Transformers, ACT baseline) by up to 30% in simulation and by 6-12% in
real-world.

</details>


### [711] [ManiVID-3D: Generalizable View-Invariant Reinforcement Learning for Robotic Manipulation via Disentangled 3D Representations](https://arxiv.org/abs/2509.11125)
*Zheng Li,Pei Qu,Yufei Jia,Shihui Zhou,Haizhou Ge,Jiahang Cao,Jinni Zhou,Guyue Zhou,Jun Ma*

Main category: cs.RO

TL;DR: ManiVID-3D是一个新颖的3D强化学习架构，通过自监督解耦特征学习来学习视图不变表示，以解决机器人操作中摄像机视角变化的问题，并在模拟和现实世界任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的机器人操作中，摄像机视角的变化常常阻碍视觉强化学习策略的部署，现有方法要么需要精确的相机校准，要么难以处理大的视角变化。

Method: 提出了一种名为ManiVID-3D的新型3D强化学习架构，其中包含一个名为ViewNet的模块，可以自动将来自任意视角的点云观测对齐到一个统一的空间坐标系，而无需外部校准。此外，还开发了一个高效的GPU加速批量渲染模块，能够以超过5000帧/秒的速度处理，支持大规模3D视觉强化学习训练。

Result: 在10个模拟任务和5个真实世界任务上的广泛评估表明，ManiVID-3D在视角变化下的成功率比最先进的方法高出44.7%，同时使用的参数减少了80%。

Conclusion: ManiVID-3D通过学习几何上一致的表示，有效地解决了机器人操作中视角变化的问题，在非结构化环境中实现了可扩展的机器人操作，并具有出色的模拟到现实迁移性能。

Abstract: Deploying visual reinforcement learning (RL) policies in real-world
manipulation is often hindered by camera viewpoint changes. A policy trained
from a fixed front-facing camera may fail when the camera is shifted--an
unavoidable situation in real-world settings where sensor placement is hard to
manage appropriately. Existing methods often rely on precise camera calibration
or struggle with large perspective changes. To address these limitations, we
propose ManiVID-3D, a novel 3D RL architecture designed for robotic
manipulation, which learns view-invariant representations through
self-supervised disentangled feature learning. The framework incorporates
ViewNet, a lightweight yet effective module that automatically aligns point
cloud observations from arbitrary viewpoints into a unified spatial coordinate
system without the need for extrinsic calibration. Additionally, we develop an
efficient GPU-accelerated batch rendering module capable of processing over
5000 frames per second, enabling large-scale training for 3D visual RL at
unprecedented speeds. Extensive evaluation across 10 simulated and 5 real-world
tasks demonstrates that our approach achieves a 44.7% higher success rate than
state-of-the-art methods under viewpoint variations while using 80% fewer
parameters. The system's robustness to severe perspective changes and strong
sim-to-real performance highlight the effectiveness of learning geometrically
consistent representations for scalable robotic manipulation in unstructured
environments. Our project website can be found in
https://zheng-joe-lee.github.io/manivid3d/.

</details>


### [712] [RoVerFly: Robust and Versatile Learning-based Control of Quadrotor Across Payload Configurations](https://arxiv.org/abs/2509.11149)
*Mintae Kim,Jiaze Cai,Koushil Sreenath*

Main category: cs.RO

TL;DR: RoVerFly是一个基于强化学习的统一控制框架，可用于标准四旋翼和带柔性缆绳悬挂载荷的系统，实现鲁棒的任意轨迹跟踪，并具有良好的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 精确、任意轨迹跟踪对于具有非线性动力学和欠驱动特性的四旋翼来说是一个挑战，而带有柔性缆绳悬挂载荷的系统则更加复杂。传统的基于模型的方法虽然能提供稳定性保证，但需要大量调优，并且在配置更改（如添加/移除载荷、改变载荷质量或缆绳长度）时适应性差。

Method: 提出RoVerFly，一个统一的基于学习的控制框架，其中强化学习（RL）策略作为标准四旋翼和各种配置的缆绳悬挂载荷系统的鲁棒且通用的跟踪控制器。通过任务和域随机化进行训练，以应对扰动和变化的动力学。

Result: 该控制器在没有控制器切换或重新调优的情况下，在各种载荷设置（包括无载荷、不同质量和缆绳长度）下实现了强大的零样本泛化能力，同时保留了反馈跟踪控制器的可解释性和结构。

Conclusion: RoVerFly提供了一种通用的、基于学习的控制方法，可以应对四旋翼及其悬挂载荷系统的复杂性和多变性，实现了鲁棒的轨迹跟踪和出色的泛化性能。

Abstract: Designing robust controllers for precise, arbitrary trajectory tracking with
quadrotors is challenging due to nonlinear dynamics and underactuation, and
becomes harder with flexible cable-suspended payloads that introduce extra
degrees of freedom and hybridness. Classical model-based methods offer
stability guarantees but require extensive tuning and often do not adapt when
the configuration changes, such as when a payload is added or removed, or when
the payload mass or cable length varies. We present RoVerFly, a unified
learning-based control framework in which a reinforcement learning (RL) policy
serves as a robust and versatile tracking controller for standard quadrotors
and for cable-suspended payload systems across a range of configurations.
Trained with task and domain randomization, the controller is resilient to
disturbances and varying dynamics. It achieves strong zero-shot generalization
across payload settings, including no payload as well as varying mass and cable
length, without controller switching or re-tuning, while retaining the
interpretability and structure of a feedback tracking controller. Code and
supplementary materials are available at
https://github.com/mintaeshkim/roverfly

</details>


### [713] [SAMP: Spatial Anchor-based Motion Policy for Collision-Aware Robotic Manipulators](https://arxiv.org/abs/2509.11185)
*Kai Chen,Zhihai Bi,Guoyang Zhao,Chunxin Zheng,Yulin Li,Hang Zhao,Jun Ma*

Main category: cs.RO

TL;DR: SAMP框架通过在共享空间网格上锚定符号距离场来统一表示环境和机械臂，从而实现平滑、无碰撞的轨迹生成，并在模拟和真实环境中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的运动规划方法在同时考虑机器人物理形状和周围环境以生成安全可行的运动方面存在挑战，并且常常依赖简化的机器人模型或不完善的障碍物表示，导致碰撞检测不完整和在拥挤场景中的性能下降。

Method: 提出空间锚点运动策略（SAMP）框架，通过在共享空间网格上锚定符号距离场（SDF）来统一编码环境和机械臂。SAMP包含一个专门的机器人SDF网络来精确捕捉机械臂的几何形状，并通过空间锚点融合这些表示来训练神经网络运动策略，利用高效的特征对齐策略生成平滑、无碰撞的轨迹。

Result: 实验结果表明，SAMP在模拟和真实环境中均优于现有方法，成功率提高了11%，碰撞率降低了7%。

Conclusion: 联合建模机器人和环境几何形状的优点在充满挑战的真实环境中具有实际价值。

Abstract: Neural-based motion planning methods have achieved remarkable progress for
robotic manipulators, yet a fundamental challenge lies in simultaneously
accounting for both the robot's physical shape and the surrounding environment
when generating safe and feasible motions. Moreover, existing approaches often
rely on simplified robot models or focus primarily on obstacle representation,
which can lead to incomplete collision detection and degraded performance in
cluttered scenes. To address these limitations, we propose spatial anchor-based
motion policy (SAMP), a unified framework that simultaneously encodes the
environment and the manipulator using signed distance field (SDF) anchored on a
shared spatial grid. SAMP incorporates a dedicated robot SDF network that
captures the manipulator's precise geometry, enabling collision-aware reasoning
beyond coarse link approximations. These representations are fused on spatial
anchors and used to train a neural motion policy that generates smooth,
collision-free trajectories in the proposed efficient feature alignment
strategy. Experiments conducted in both simulated and real-world environments
consistently show that SAMP outperforms existing methods, delivering an 11%
increase in success rate and a 7% reduction in collision rate. These results
highlight the benefits of jointly modelling robot and environment geometry,
demonstrating its practical value in challenging real-world environments.

</details>


### [714] [DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2509.11197)
*Yunheng Wang,Yuetong Fang,Taowen Wang,Yixiao Feng,Yawen Tan,Shuning Zhang,Peiran Liu,Yiding Ji,Renjing Xu*

Main category: cs.RO

TL;DR: DreamNav 提出了一种新的零样本导航方法，通过优化感知、全局轨迹规划和主动想象能力，在真实和模拟环境中都取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本导航方法过于依赖昂贵的感知和被动的场景理解，导致控制仅限于点级别的选择，部署成本高，动作语义不匹配，并且规划短视。

Method: DreamNav 包含三个核心组件：1. EgoView Corrector：对齐视点，稳定以自我为中心的感知，以降低感官成本。2. Trajectory Predictor：偏向全局轨迹级别规划，以更好地匹配指令语义，而非点级别动作。3. Imagination Predictor：使智能体具备预测性思维能力，实现前瞻性和长时程规划。

Result: 在 VLN-CE 和真实世界测试中，DreamNav 设定了新的零样本导航最优（SOTA），在 SR 和 SPL 指标上分别超越了最强的以自我为中心的基线高达 7.49% 和 18.15%。

Conclusion: DreamNav 是首个结合轨迹级别规划和主动想象能力，并且仅使用以自我为中心输入进行零样本导航的方法。

Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE), which
links language instructions to perception and control in the real world, is a
core capability of embodied robots. Recently, large-scale pretrained foundation
models have been leveraged as shared priors for perception, reasoning, and
action, enabling zero-shot VLN without task-specific training. However,
existing zero-shot VLN methods depend on costly perception and passive scene
understanding, collapsing control to point-level choices. As a result, they are
expensive to deploy, misaligned in action semantics, and short-sighted in
planning. To address these issues, we present DreamNav that focuses on the
following three aspects: (1) for reducing sensory cost, our EgoView Corrector
aligns viewpoints and stabilizes egocentric perception; (2) instead of
point-level actions, our Trajectory Predictor favors global trajectory-level
planning to better align with instruction semantics; and (3) to enable
anticipatory and long-horizon planning, we propose an Imagination Predictor to
endow the agent with proactive thinking capability. On VLN-CE and real-world
tests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the
strongest egocentric baseline with extra information by up to 7.49\% and
18.15\% in terms of SR and SPL metrics. To our knowledge, this is the first
zero-shot VLN method to unify trajectory-level planning and active imagination
while using only egocentric inputs.

</details>


### [715] [MEMBOT: Memory-Based Robot in Intermittent POMDP](https://arxiv.org/abs/2509.11225)
*Youzhi Liang,Eyan Noronha*

Main category: cs.RO

TL;DR: MEMBOT是一种基于记忆的机器人控制架构，通过离线预训练和行为克隆微调，在部分可观察和间歇性可观察的环境中提高了鲁棒性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在传感器输入不可靠或缺失的真实世界环境中表现不佳，需要一种能够处理间歇性部分可观察性的方法。

Method: MEMBOT采用模块化记忆架构，通过离线多任务学习预训练一个潜在信念编码器（结合状态空间模型和LSTM），然后通过行为克隆进行特定任务的微调。信念编码器能整合观测和动作序列，在观测缺失时仍能推断出持续的潜在状态表示。

Result: 在10个MetaWorld和Robomimic的机器人操作基准任务中，MEMBOT在不同程度的观测缺失率下表现优于无记忆和简单循环基线，在仅50%的观测可用性下仍能保持高达80%的峰值性能。

Conclusion: MEMBOT通过显式信念建模，能够为真实世界中部分可观察的机器人系统提供鲁棒、可迁移且数据高效的策略。

Abstract: Robotic systems deployed in real-world environments often operate under
conditions of partial and often intermittent observability, where sensor inputs
may be noisy, occluded, or entirely unavailable due to failures or
environmental constraints. Traditional reinforcement learning (RL) approaches
that assume full state observability are ill-equipped for such challenges. In
this work, we introduce MEMBOT, a modular memory-based architecture designed to
address intermittent partial observability in robotic control tasks. MEMBOT
decouples belief inference from policy learning through a two-phase training
process: an offline multi-task learning pretraining stage that learns a robust
task-agnostic latent belief encoder using a reconstruction losses, followed by
fine-tuning of task-specific policies using behavior cloning. The belief
encoder, implemented as a state-space model (SSM) and a LSTM, integrates
temporal sequences of observations and actions to infer latent state
representations that persist even when observations are dropped. We train and
evaluate MEMBOT on 10 robotic manipulation benchmark tasks from MetaWorld and
Robomimic under varying rates of observation dropout. Results show that MEMBOT
consistently outperforms both memoryless and naively recurrent baselines,
maintaining up to 80% of peak performance under 50% observation availability.
These findings highlight the effectiveness of explicit belief modeling in
achieving robust, transferable, and data-efficient policies for real-world
partially observable robotic systems.

</details>


### [716] [CORB-Planner: Corridor as Observations for RL Planning in High-Speed Flight](https://arxiv.org/abs/2509.11240)
*Yechen Zhang,Bin Gao,Gang Wang,Jian Sun,Zhuo Li*

Main category: cs.RO

TL;DR: CORB-Planner是一个基于强化学习的无人机自主飞行轨迹规划框架，通过结合B样条轨迹生成和安全飞行走廊表示，实现了跨平台、高速度的飞行，并能在复杂环境中实时运行。


<details>
  <summary>Details</summary>
Motivation: 现有无人机强化学习控制方法依赖于精确模型和特定平台传感，限制了跨平台迁移。本研究旨在解决这一挑战。

Method: 提出CORB-Planner框架，结合B样条轨迹生成和强化学习策略，使用紧凑的安全飞行走廊（SFC）表示障碍物信息，降低对平台细节和模型精度的敏感性。采用模拟到现实的渐进式训练和基于价值的软分解Critic Q（SDCQ）算法。

Result: 在模拟和真实世界测试中，CORB-Planner在轻量级板载硬件上实现了实时规划，在密集、杂乱的环境中最大飞行速度达到8.2m/s，且无需外部定位。该方法兼容多种无人机配置（四旋翼、六旋翼），展现了通用性和鲁棒性。

Conclusion: CORB-Planner是一个通用且鲁棒的无人机自主飞行轨迹规划框架，通过SFC表示和RL策略的结合，克服了跨平台迁移和模型依赖的限制，实现了在复杂环境下的高鲁棒性、高速度的实时飞行。

Abstract: Reinforcement learning (RL) has shown promise in a large number of robotic
control tasks. Nevertheless, its deployment on unmanned aerial vehicles (UAVs)
remains challenging, mainly because of reliance on accurate dynamic models and
platform-specific sensing, which hinders cross-platform transfer. This paper
presents the CORB-Planner (Corridor-as-Observations for RL B-spline planner), a
real-time, RL-based trajectory planning framework for high-speed autonomous UAV
flight across heterogeneous platforms. The key idea is to combine B-spline
trajectory generation with the RL policy producing successive control points
with a compact safe flight corridor (SFC) representation obtained via heuristic
search. The SFC abstracts obstacle information in a low-dimensional form,
mitigating overfitting to platform-specific details and reducing sensitivity to
model inaccuracies. To narrow the sim-to-real gap, we adopt an easy-to-hard
progressive training pipeline in simulation. A value-based soft
decomposed-critic Q (SDCQ) algorithm is used to learn effective policies within
approximately ten minutes of training. Benchmarks in simulation and real-world
tests demonstrate real-time planning on lightweight onboard hardware and
support maximum flight speeds up to 8.2m/s in dense, cluttered environments
without external positioning. Compatibility with various UAV configurations
(quadrotors, hexarotors) and modest onboard compute underlines the generality
and robustness of CORB-Planner for practical deployment.

</details>


### [717] [Embodied Intelligence in Disassembly: Multimodal Perception Cross-validation and Continual Learning in Neuro-Symbolic TAMP](https://arxiv.org/abs/2509.11270)
*Ziwen He,Zhigang Wang,Yanlong Peng,Pengxu Chang,Hong Yang,Ming Chen*

Main category: cs.RO

TL;DR: 该研究提出了一种基于神经符号任务与运动规划（TAMP）的持续学习框架，以提高机器人系统在动态拆卸场景下的适应性和鲁棒性，实验结果显著提高了任务成功率并减少了感知错误。


<details>
  <summary>Details</summary>
Motivation: 随着新能源汽车产业的快速发展，动力电池的高效拆卸和回收对循环经济至关重要。然而，在非结构化的拆卸环境中，动态性严重限制了机器人感知的鲁棒性，阻碍了工业应用中的自主拆卸。

Method: 提出了一种基于神经符号任务与运动规划（TAMP）的持续学习框架，并集成了一个多模态感知交叉验证机制和一个双向推理流程：前向工作流程动态优化动作策略，后向学习流程从历史任务执行中自主收集有效数据以实现系统持续学习和自优化。

Result: 所提出的框架在动态拆卸场景下，将任务成功率从81.68%提高到100%，并将平均感知误判次数从3.389次减少到1.128次。

Conclusion: 该研究为增强机器人智能在复杂工业环境中的鲁棒性和适应性提供了一种新范式。

Abstract: With the rapid development of the new energy vehicle industry, the efficient
disassembly and recycling of power batteries have become a critical challenge
for the circular economy. In current unstructured disassembly scenarios, the
dynamic nature of the environment severely limits the robustness of robotic
perception, posing a significant barrier to autonomous disassembly in
industrial applications. This paper proposes a continual learning framework
based on Neuro-Symbolic task and motion planning (TAMP) to enhance the
adaptability of embodied intelligence systems in dynamic environments. Our
approach integrates a multimodal perception cross-validation mechanism into a
bidirectional reasoning flow: the forward working flow dynamically refines and
optimizes action strategies, while the backward learning flow autonomously
collects effective data from historical task executions to facilitate continual
system learning, enabling self-optimization. Experimental results show that the
proposed framework improves the task success rate in dynamic disassembly
scenarios from 81.68% to 100%, while reducing the average number of perception
misjudgments from 3.389 to 1.128. This research provides a new paradigm for
enhancing the robustness and adaptability of embodied intelligence in complex
industrial environments.

</details>


### [718] [Policy Learning for Social Robot-Led Physiotherapy](https://arxiv.org/abs/2509.11297)
*Carl Bettosi,Lynne Ballie,Susan Shenkin,Marta Romeo*

Main category: cs.RO

TL;DR: 利用专家代理数据训练强化学习策略，使社交机器人能够根据患者的运动表现和疲劳度调整物理治疗指导。


<details>
  <summary>Details</summary>
Motivation: 物理治疗指导中的社交机器人部署面临患者行为数据稀疏的挑战。

Method: 通过33名医疗专家作为患者代理，收集其与机器人的互动数据，用于训练能够生成运动表现指标和感知劳累评分的患者行为模型。随后，在模拟环境中训练了一个基于强化学习的策略。

Result: 该策略能够根据个体疲劳度容忍度和波动的运动表现来调整运动指导，并且适用于不同恢复阶段和不同运动计划的患者。

Conclusion: 所提出的方法通过利用专家代理数据，为社交机器人在物理治疗中的自适应指导提供了有效的解决方案。

Abstract: Social robots offer a promising solution for autonomously guiding patients
through physiotherapy exercise sessions, but effective deployment requires
advanced decision-making to adapt to patient needs. A key challenge is the
scarcity of patient behavior data for developing robust policies. To address
this, we engaged 33 expert healthcare practitioners as patient proxies, using
their interactions with our robot to inform a patient behavior model capable of
generating exercise performance metrics and subjective scores on perceived
exertion. We trained a reinforcement learning-based policy in simulation,
demonstrating that it can adapt exercise instructions to individual exertion
tolerances and fluctuating performance, while also being applicable to patients
at different recovery stages with varying exercise plans.

</details>


### [719] [Brain-Robot Interface for Exercise Mimicry](https://arxiv.org/abs/2509.11306)
*Carl Bettosi,Emilyann Nault,Lynne Baillie,Markus Garschall,Marta Romeo,Beatrix Wais-Zechmann,Nicole Binderlehner,Theodoros Georgio*

Main category: cs.RO

TL;DR: 社会机器人可以通过模仿用户运动来建立融洽关系，但准确性有所不同。


<details>
  <summary>Details</summary>
Motivation: 为了让社会机器人能够作为长期的运动指导师，建立融洽关系至关重要。

Method: 开发了一种新颖的脑机接口（BRI），使机器人能够实时模仿用户的运动，并利用从用户意图中提取的命令。

Result: 该系统在12次试验中成功展示了运动模仿，但准确性有所不同。用户对机器人指导师的看法是积极的，信任度和接受度很高，并且没有受到BRI技术引入的影响。

Conclusion: 用户普遍接受使用BRI技术的机器人指导师，尽管运动模仿的准确性仍有待提高。

Abstract: For social robots to maintain long-term engagement as exercise instructors,
rapport-building is essential. Motor mimicry--imitating one's physical
actions--during social interaction has long been recognized as a powerful tool
for fostering rapport, and it is widely used in rehabilitation exercises where
patients mirror a physiotherapist or video demonstration. We developed a novel
Brain-Robot Interface (BRI) that allows a social robot instructor to mimic a
patient's exercise movements in real-time, using mental commands derived from
the patient's intention. The system was evaluated in an exploratory study with
14 participants (3 physiotherapists and 11 hemiparetic patients recovering from
stroke or other injuries). We found our system successfully demonstrated
exercise mimicry in 12 sessions; however, accuracy varied. Participants had
positive perceptions of the robot instructor, with high trust and acceptance
levels, which were not affected by the introduction of BRI technology.

</details>


### [720] [ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation](https://arxiv.org/abs/2509.11364)
*Sheng Liu,Zhe Li,Weiheng Wang,Han Sun,Heng Zhang,Hongpeng Chen,Yusen Qin,Arash Ajoudani,Yizhao Wang*

Main category: cs.RO

TL;DR: 通过结合视觉-语言模型（VLM）和“机器人想象力”，提出一种主动式位姿估计方法，以实时检测和解决位姿估计中的歧义问题，并辅以主动位姿跟踪模块以应对移动物体，在模拟和真实世界实验中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 零样本方法在视角诱导的歧义下表现不佳，固定摄像头在物体移动或自遮挡时存在局限性，需要更可靠的6-DoF物体位姿估计和跟踪方法。

Method: 1. 离线阶段：渲染CAD模型的密集视图，计算FoundationPose熵，构建包含低熵（无歧义）和高熵（有歧义）示例的几何感知提示。
2. 运行时阶段：
   a. 查询VLM以获取实时图像的歧义分数。
   b. 若检测到歧义，通过渲染虚拟视图来设想离散的候选相机位姿，并根据VLM歧义概率和FoundationPose熵的加权组合对每个位姿进行评分。
   c. 将摄像头移动到Next-Best-View（NBV）以获得消除歧义的位姿估计。
3. 主动位姿跟踪：引入一个通过模仿学习训练的扩散策略，生成保持物体可见性并最小化位姿歧义的摄像头轨迹。

Result: 在模拟和真实世界实验中，该方法显著优于经典基线方法。

Conclusion: 所提出的主动式位姿估计和跟踪方法能够有效解决现有方法在处理视角歧义和移动物体时的不足，提高了机器人操作的可靠性。

Abstract: Accurate 6-DoF object pose estimation and tracking are critical for reliable
robotic manipulation. However, zero-shot methods often fail under
viewpoint-induced ambiguities and fixed-camera setups struggle when objects
move or become self-occluded. To address these challenges, we propose an active
pose estimation pipeline that combines a Vision-Language Model (VLM) with
"robotic imagination" to dynamically detect and resolve ambiguities in real
time. In an offline stage, we render a dense set of views of the CAD model,
compute the FoundationPose entropy for each view, and construct a
geometric-aware prompt that includes low-entropy (unambiguous) and high-entropy
(ambiguous) examples. At runtime, the system: (1) queries the VLM on the live
image for an ambiguity score; (2) if ambiguity is detected, imagines a discrete
set of candidate camera poses by rendering virtual views, scores each based on
a weighted combination of VLM ambiguity probability and FoundationPose entropy,
and then moves the camera to the Next-Best-View (NBV) to obtain a disambiguated
pose estimation. Furthermore, since moving objects may leave the camera's field
of view, we introduce an active pose tracking module: a diffusion-policy
trained via imitation learning, which generates camera trajectories that
preserve object visibility and minimize pose ambiguity. Experiments in
simulation and real-world show that our approach significantly outperforms
classical baselines.

</details>


### [721] [Quantum deep reinforcement learning for humanoid robot navigation task](https://arxiv.org/abs/2509.11388)
*Romerik Lokossou,Birhanu Shimelis Girma,Ozan K. Tonguz,Ahmed Biyabani*

Main category: cs.RO

TL;DR: 本研究将量子深度强化学习（QDRL）应用于高维复杂环境中的人形机器人导航，并与经典强化学习（RL）进行了性能对比，结果显示量子SAC在更少步数的情况下取得了更高的平均回报。


<details>
  <summary>Details</summary>
Motivation: 经典强化学习（RL）方法在复杂、高维环境中面临参数需求大以及随机、非确定性设置的挑战。本研究旨在克服这些挑战，探索将量子计算与深度强化学习相结合，以更有效地训练人形机器人。

Method: 采用参数化量子电路，探索了一种混合量子-经典设置，用于直接导航高维状态空间，并实现了量子版的Soft Actor-Critic（SAC）算法，用于训练人形机器人。

Result: 量子SAC在MuJoCo的Humanoid-v4和Walker2d-v4环境中，以92%的步数减少量实现了比经典SAC高8%的平均回报（分别为246.40和228.36）。

Conclusion: 研究结果表明，量子计算在强化学习任务中具有加速学习的潜力，特别是在高维复杂环境中训练人形机器人方面，量子SAC表现出优于经典SAC的性能。

Abstract: Classical reinforcement learning (RL) methods often struggle in complex,
high-dimensional environments because of their extensive parameter requirements
and challenges posed by stochastic, non-deterministic settings. This study
introduces quantum deep reinforcement learning (QDRL) to train humanoid agents
efficiently. While previous quantum RL models focused on smaller environments,
such as wheeled robots and robotic arms, our work pioneers the application of
QDRL to humanoid robotics, specifically in environments with substantial
observation and action spaces, such as MuJoCo's Humanoid-v4 and Walker2d-v4.
Using parameterized quantum circuits, we explored a hybrid quantum-classical
setup to directly navigate high-dimensional state spaces, bypassing traditional
mapping and planning. By integrating quantum computing with deep RL, we aim to
develop models that can efficiently learn complex navigation tasks in humanoid
robots. We evaluated the performance of the Soft Actor-Critic (SAC) in
classical RL against its quantum implementation. The results show that the
quantum SAC achieves an 8% higher average return (246.40) than the classical
SAC (228.36) after 92% fewer steps, highlighting the accelerated learning
potential of quantum computing in RL tasks.

</details>


### [722] [TRUST 2025: SCRITA and RTSS @ RO-MAN 2025](https://arxiv.org/abs/2509.11402)
*Alessandra Rossi,Patrick Holthaus,Gabriella Lakatos,Sílvia Moros,Ali Fallahi,Murat Kirtay,Marie Postma,Erhan Oztop*

Main category: cs.RO

TL;DR: TRUST workshop是SCRITA和RTSS两个会议合并而成，旨在促进人机交互中的信任研究。


<details>
  <summary>Details</summary>
Motivation: 合并SCRITA和RTSS两个会议，以综合人类和机器人双方的视角来推进信任研究。

Method: 整合两个现有会议（SCRITA和RTSS）的目标。

Result: 结合了两个会议的优势，共同推动人机交互中信任领域的研究。

Conclusion: 两个会议的合并将为信任研究提供一个更全面的平台。

Abstract: The TRUST workshop is the result of a collaboration between two established
workshops in the field of Human-Robot Interaction: SCRITA (Trust, Acceptance
and Social Cues in Human-Robot Interaction) and RTSS (Robot Trust for Symbiotic
Societies). This joint initiative brings together the complementary goals of
these workshops to advance research on trust from both the human and robot
perspectives.
  Website: https://scrita.herts.ac.uk/2025/

</details>


### [723] [Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations](https://arxiv.org/abs/2509.11417)
*Shresth Grover,Akshay Gopalkrishnan,Bo Ai,Henrik I. Christensen,Hao Su,Xuanlin Li*

Main category: cs.RO

TL;DR: 通过冻结一个视觉编码器、使用基于字符串的动作标记器以及结合机器人演示和视觉-语言数据集进行联合训练，来改进视觉-语言-动作模型，以增强泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 直接在机器人数据上微调视觉-语言-动作模型会破坏预训练的表征并限制泛化能力。因此，需要一种能够更好地保留预训练特征并使其适应机器人操作的框架。

Method: 提出一个包含三个组件的框架：(1) 一个双编码器设计，其中一个冻结的视觉编码器用于保留预训练特征，另一个可训练用于任务适应；(2) 一个基于字符串的动作标记器，将连续动作转换为与模型预训练域对齐的字符序列；(3) 一个联合训练策略，结合机器人演示和强调空间推理及可操作性的视觉-语言数据集。

Result: 所提出的方法在模拟和真实机器人上进行了评估，结果显示与基线方法相比，在视觉扰动下的鲁棒性、对新指令和环境的泛化能力以及整体任务成功率都有所提高。

Conclusion: 所提出的框架能够有效地区分预训练的表征，以适应机器人操作，同时在各种指令和环境中实现强大的泛化和鲁棒性。

Abstract: Vision-language-action (VLA) models finetuned from vision-language models
(VLMs) hold the promise of leveraging rich pretrained representations to build
generalist robots across diverse tasks and environments. However, direct
fine-tuning on robot data often disrupts these representations and limits
generalization. We present a framework that better preserves pretrained
features while adapting them for robot manipulation. Our approach introduces
three components: (i) a dual-encoder design with one frozen vision encoder to
retain pretrained features and another trainable for task adaptation, (ii) a
string-based action tokenizer that casts continuous actions into character
sequences aligned with the model's pretraining domain, and (iii) a co-training
strategy that combines robot demonstrations with vision-language datasets
emphasizing spatial reasoning and affordances. Evaluations in simulation and on
real robots show that our method improves robustness to visual perturbations,
generalization to novel instructions and environments, and overall task success
compared to baselines.

</details>


### [724] [A Software-Only Post-Processor for Indexed Rotary Machining on GRBL-Based CNCs](https://arxiv.org/abs/2509.11433)
*Pedro Portugal,Damian D. Venghaus,Diego Lopez*

Main category: cs.RO

TL;DR: 该框架通过一个自定义的后处理器将GRBL数控机的平面刀具路径转换为离散的旋转步进，无需固件修改或昂贵的软件，从而为教育和创客空间提供了经济实惠的数控旋转加工解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的数控旋转加工解决方案通常需要昂贵的硬件改造、替代控制器或商用CAM软件，这在成本和复杂性上存在障碍，限制了其在教育、原型制作和创客空间等领域的普及。本文旨在解决这一问题，为教育和创客空间提供一种经济实惠且易于实现的数控旋转加工方案。

Method: 开发了一个仅包含软件的框架，包含一个自定义的后处理器，能够将GRBL数控机的平面刀具路径转换为一系列离散的旋转步进。这些步进指令可以通过一个基于浏览器的用户界面进行执行，从而实现对旋转部件的加工。

Result: 该框架能够使用标准的、现成的机械部件，无需对固件进行修改，即可实现旋转轴加工。虽然加工精度和效率不及连续四轴加工，但能够满足实践中的旋转轴零件制造需求。

Conclusion: 该软件框架通过降低技术和财务门槛，使得在教室、创客空间和小型工作室中进行多轴加工更加普及，支持动手学习和快速原型制作，为数控旋转加工领域提供了经济高效的解决方案。

Abstract: Affordable desktop CNC routers are common in education, prototyping, and
makerspaces, but most lack a rotary axis, limiting fabrication of rotationally
symmetric or multi-sided parts. Existing solutions often require hardware
retrofits, alternative controllers, or commercial CAM software, raising cost
and complexity. This work presents a software-only framework for indexed rotary
machining on GRBL-based CNCs. A custom post-processor converts planar toolpaths
into discrete rotary steps, executed through a browser-based interface. While
not equivalent to continuous 4-axis machining, the method enables practical
rotary-axis fabrication using only standard, off-the-shelf mechanics, without
firmware modification. By reducing technical and financial barriers, the
framework expands access to multi-axis machining in classrooms, makerspaces,
and small workshops, supporting hands-on learning and rapid prototyping.

</details>


### [725] [RAPTOR: A Foundation Policy for Quadrotor Control](https://arxiv.org/abs/2509.11481)
*Jonas Eschmann,Dario Albani,Giuseppe Loianno*

Main category: cs.RO

TL;DR: RAPTOR是一个用于四旋翼控制的自适应基础策略，可以通过元模仿学习进行训练，能够实现对各种无人机平台的零样本自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人控制系统（如强化学习策略）通常高度专业化，在面对新环境或系统微小变化时表现不佳，需要重新训练。然而，人类在适应新环境方面具有出色的数据效率，例如驾驶新车。这项工作旨在开发一种能够像人类一样适应不同四旋翼飞行器的控制策略。

Method: 该方法的核心是RAPTOR，一个端到端的神经网络策略。该策略通过一种新颖的元模仿学习算法进行训练。具体来说，先为1000个不同的四旋翼模型训练强化学习的教师策略，然后将这些教师策略蒸馏成一个单一的、具有高度适应性的学生策略。学生策略利用了隐藏层中的递归机制，以实现上下文学习（In-Context Learning），从而能够进行零样本自适应。

Result: 该方法成功地训练了一个仅包含2084个参数的三层神经网络策略。该策略在10种不同的真实四旋翼（重量从32克到2.4公斤，电机、框架、螺旋桨和飞行控制器类型各异）上进行了测试，并实现了零样本自适应。该策略在各种条件下（轨迹跟踪、室内/室外、风扰动、物理干扰、不同螺旋桨）都表现出了强大的适应能力，适应时间在几毫秒内。

Conclusion: RAPTOR提供了一种有效的方法来训练具有高度适应性的四旋翼控制策略，克服了传统强化学习策略在泛化性和适应性方面的局限性。通过元模仿学习和上下文学习，该方法能够在一个统一的策略中处理多种不同特性的无人机平台，展现了其在机器人控制领域的巨大潜力。

Abstract: Humans are remarkably data-efficient when adapting to new unseen conditions,
like driving a new car. In contrast, modern robotic control systems, like
neural network policies trained using Reinforcement Learning (RL), are highly
specialized for single environments. Because of this overfitting, they are
known to break down even under small differences like the Simulation-to-Reality
(Sim2Real) gap and require system identification and retraining for even
minimal changes to the system. In this work, we present RAPTOR, a method for
training a highly adaptive foundation policy for quadrotor control. Our method
enables training a single, end-to-end neural-network policy to control a wide
variety of quadrotors. We test 10 different real quadrotors from 32 g to 2.4 kg
that also differ in motor type (brushed vs. brushless), frame type (soft vs.
rigid), propeller type (2/3/4-blade), and flight controller
(PX4/Betaflight/Crazyflie/M5StampFly). We find that a tiny, three-layer policy
with only 2084 parameters is sufficient for zero-shot adaptation to a wide
variety of platforms. The adaptation through In-Context Learning is made
possible by using a recurrence in the hidden layer. The policy is trained
through a novel Meta-Imitation Learning algorithm, where we sample 1000
quadrotors and train a teacher policy for each of them using Reinforcement
Learning. Subsequently, the 1000 teachers are distilled into a single, adaptive
student policy. We find that within milliseconds, the resulting foundation
policy adapts zero-shot to unseen quadrotors. We extensively test the
capabilities of the foundation policy under numerous conditions (trajectory
tracking, indoor/outdoor, wind disturbance, poking, different propellers).

</details>


### [726] [FR-Net: Learning Robust Quadrupedal Fall Recovery on Challenging Terrains through Mass-Contact Prediction](https://arxiv.org/abs/2509.11504)
*Yidan Lu,Yinzhao Dong,Jiahui Zhang,Ji Ma,Peng Lu*

Main category: cs.RO

TL;DR: FR-Net 是一个基于学习的框架，使四足机器人在复杂地形上能够从任意跌倒姿势中恢复，通过预测质量分布和接触状态来实现，并在模拟和真实世界中得到验证。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人跌倒恢复控制器在复杂地形上存在不足，原因在于对地形感知不完整和交互不确定。本研究旨在提出一种新的方法，使四足机器人在各种环境下都能从任意跌倒姿势中恢复。

Method: 提出一个名为 FR-Net 的基于学习的框架，其中包含一个核心的质量-接触预测器网络，用于从有限的传感输入中估计机器人的质量分布和接触状态。使用精心设计的奖励函数来确保安全恢复，并完全在模拟中使用特权学习进行训练，无需在部署时进行显式地形数据。

Result: FR-Net 框架在模拟中展示了跨不同四足平台的泛化能力，并通过在 Go2 机器人上进行的 10 种挑战性场景的真实世界实验进行了验证。实验结果表明，显式的质量-接触预测对于鲁棒的跌倒恢复至关重要。

Conclusion: FR-Net 框架通过显式的质量-接触预测，实现了在复杂地形上鲁棒且通用的四足机器人跌倒恢复，为开发通用的四足机器人技能提供了一个有前景的方向。

Abstract: Fall recovery for legged robots remains challenging, particularly on complex
terrains where traditional controllers fail due to incomplete terrain
perception and uncertain interactions. We present \textbf{FR-Net}, a
learning-based framework that enables quadrupedal robots to recover from
arbitrary fall poses across diverse environments. Central to our approach is a
Mass-Contact Predictor network that estimates the robot's mass distribution and
contact states from limited sensory inputs, facilitating effective recovery
strategies. Our carefully designed reward functions ensure safe recovery even
on steep stairs without dangerous rolling motions common to existing methods.
Trained entirely in simulation using privileged learning, our framework guides
policy learning without requiring explicit terrain data during deployment. We
demonstrate the generalization capabilities of \textbf{FR-Net} across different
quadrupedal platforms in simulation and validate its performance through
extensive real-world experiments on the Go2 robot in 10 challenging scenarios.
Our results indicate that explicit mass-contact prediction is key to robust
fall recovery, offering a promising direction for generalizable quadrupedal
skills.

</details>


### [727] [Design and Development of a Remotely Wire-Driven Walking Robot](https://arxiv.org/abs/2509.11506)
*Takahiro Hattori,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种名为远程线驱动的新型机制，用于通过线缆远程驱动移动机器人，并通过驱动一个线缆驱动的四足机器人进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在人类无法进入的恶劣或危险环境中运行，而这些环境对电子元件也构成威胁。现有的电子设备无关的机器人、液压驱动机器人和线驱动机械臂都有各自的局限性。

Method: 提出了一种名为远程线驱动的新型机制，该机制是线驱动机械臂中用于动力传输的解耦关节串联。用此机制驱动了一个新开发的线驱动四足机器人进行了实验。

Result: 成功验证了远程线驱动机制的可行性。

Conclusion: 远程线驱动机制能够实现对移动机器人的远程线缆驱动，克服了现有技术的局限性。

Abstract: Operating in environments too harsh or inaccessible for humans is one of the
critical roles expected of robots. However, such environments often pose risks
to electronic components as well. To overcome this, various approaches have
been developed, including autonomous mobile robots without electronics,
hydraulic remotely actuated mobile robots, and long-reach robot arms driven by
wires. Among these, electronics-free autonomous robots cannot make complex
decisions, while hydraulically actuated mobile robots and wire-driven robot
arms are used in harsh environments such as nuclear power plants. Mobile robots
offer greater reach and obstacle avoidance than robot arms, and wire mechanisms
offer broader environmental applicability than hydraulics. However, wire-driven
systems have not been used for remote actuation of mobile robots. In this
study, we propose a novel mechanism called Remote Wire Drive that enables
remote actuation of mobile robots via wires. This mechanism is a series
connection of decoupled joints, a mechanism used in wire-driven robot arms,
adapted for power transmission. We experimentally validated its feasibility by
actuating a wire-driven quadruped robot, which we also developed in this study,
through Remote Wire Drive.

</details>


### [728] [PaiP: An Operational Aware Interactive Planner for Unknown Cabinet Environments](https://arxiv.org/abs/2509.11516)
*Chengjin Wang,Zheng Yan,Yanmin Zhou,Runjie Shen,Zhipeng Wang,Bin Cheng,Bin He*

Main category: cs.RO

TL;DR: PaiP是一个新的机器人运动规划框架，它使用触觉感知来处理视觉遮挡和狭窄空间中的堆叠物体。


<details>
  <summary>Details</summary>
Motivation: 传统机器人运动规划方法在处理视觉遮挡和狭窄空间中的堆叠物体时存在困难，可能导致碰撞。PaiP旨在克服这些挑战。

Method: PaiP是一个实时闭环规划框架，利用多模态触觉感知来推断物体交互特征，并将其整合到网格地图中以生成操作成本图。它扩展了基于采样的方法，同时优化路径成本和操作成本。

Result: 实验结果表明，PaiP在狭窄空间中实现了鲁棒的运动。

Conclusion: PaiP通过集成触觉感知和操作感知，能够成功地在具有挑战性的盒/柜场景中进行机器人运动规划。

Abstract: Box/cabinet scenarios with stacked objects pose significant challenges for
robotic motion due to visual occlusions and constrained free space. Traditional
collision-free trajectory planning methods often fail when no collision-free
paths exist, and may even lead to catastrophic collisions caused by invisible
objects. To overcome these challenges, we propose an operational aware
interactive motion planner (PaiP) a real-time closed-loop planning framework
utilizing multimodal tactile perception. This framework autonomously infers
object interaction features by perceiving motion effects at interaction
interfaces. These interaction features are incorporated into grid maps to
generate operational cost maps. Building upon this representation, we extend
sampling-based planning methods to interactive planning by optimizing both path
cost and operational cost. Experimental results demonstrate that PaiP achieves
robust motion in narrow spaces.

</details>


### [729] [Shape control of simulated multi-segment continuum robots via Koopman operators with per-segment projection](https://arxiv.org/abs/2509.11567)
*Eron Ristich,Jiahe Wang,Lei Zhang,Sultan Haidar Ali,Wanxin Jin,Yi Ren,Jiefeng Sun*

Main category: cs.RO

TL;DR: 通过基于 Koopman 算子和模型预测控制的方法，实现了软体机器人形状的实时控制，提高了精度和效率。


<details>
  <summary>Details</summary>
Motivation: 当前软体机器人难以实现整体形状的实时控制，主要原因是自由度高导致计算成本大。

Method: 提出了一种数据驱动的、基于 Koopman 算子和分段投影的方法，用于识别多段腱驱动软体连续机器人的控制模型。然后，使用线性模型预测控制（MPC）来控制机器人达到目标形状。

Result: 基于 Koopman 算子和分段投影的方法比不使用该方法提高了近一个数量级的精度。实现了计算高效的闭环控制，证明了软体机器人实时形状控制的可行性。

Conclusion: 该方法为软体连续机器人的实际形状控制铺平了道路。

Abstract: Soft continuum robots can allow for biocompatible yet compliant motions, such
as the ability of octopus arms to swim, crawl, and manipulate objects. However,
current state-of-the-art continuum robots can only achieve real-time task-space
control (i.e., tip control) but not whole-shape control, mainly due to the high
computational cost from its infinite degrees of freedom. In this paper, we
present a data-driven Koopman operator-based approach for the shape control of
simulated multi-segment tendon-driven soft continuum robots with the Kirchhoff
rod model. Using data collected from these simulated soft robots, we conduct a
per-segment projection scheme on the state of the robots allowing for the
identification of control-affine Koopman models that are an order of magnitude
more accurate than without the projection scheme. Using these learned Koopman
models, we use a linear model predictive control (MPC) to control the robots to
a collection of target shapes of varying complexity. Our method realizes
computationally efficient closed-loop control, and demonstrates the feasibility
of real-time shape control for soft robots. We envision this work can pave the
way for practical shape control of soft continuum robots.

</details>


### [730] [GBPP: Grasp-Aware Base Placement Prediction for Robots via Two-Stage Learning](https://arxiv.org/abs/2509.11594)
*Jizhuo Chen,Diwen Liu,Jiaming Wang,Harold Soh*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: GBPP is a fast learning based scorer that selects a robot base pose for
grasping from a single RGB-D snapshot. The method uses a two stage curriculum:
(1) a simple distance-visibility rule auto-labels a large dataset at low cost;
and (2) a smaller set of high fidelity simulation trials refines the model to
match true grasp outcomes. A PointNet++ style point cloud encoder with an MLP
scores dense grids of candidate poses, enabling rapid online selection without
full task-and-motion optimization. In simulation and on a real mobile
manipulator, GBPP outperforms proximity and geometry only baselines, choosing
safer and more reachable stances and degrading gracefully when wrong. The
results offer a practical recipe for data efficient, geometry aware base
placement: use inexpensive heuristics for coverage, then calibrate with
targeted simulation.

</details>


### [731] [AssemMate: Graph-Based LLM for Robotic Assembly Assistance](https://arxiv.org/abs/2509.11617)
*Qi Zheng,Chaoran Zhang,Zijian Liang,EnTe Lin,Shubo Cui,Qinghongbing Xie,Zhaobo Xu,Long Zeng*

Main category: cs.RO

TL;DR: AssemMate是一个基于图的LLM，用于机器人装配辅助，通过知识图谱和视觉增强实现更快的推理和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的机器人装配辅助方法使用自然语言文本表示知识，存在长上下文和冗余问题，难以满足机器人实时精确推理的需求。

Method: AssemMate利用图作为知识表示形式，通过自监督图卷积网络（GCN）将知识图谱实体和关系编码到潜在空间，并与LLM表示对齐，使其能够理解图信息。此外，还采用了视觉增强策略来处理堆叠场景的抓取。

Result: AssemMate比现有方法准确率高6.4%，推理速度快3倍，上下文长度缩短28倍，并且在随机图上表现出强大的泛化能力。在模拟和真实世界的机器人抓取实验中也表现优越。

Conclusion: AssemMate通过使用图作为知识表示，并结合GCN和视觉增强，有效解决了现有LLM在机器人装配辅助中的局限性，在准确性、推理速度和上下文长度方面取得了显著提升，并验证了其在实际应用中的有效性。

Abstract: Large Language Model (LLM)-based robotic assembly assistance has gained
significant research attention. It requires the injection of domain-specific
knowledge to guide the assembly process through natural language interaction
with humans. Despite some progress, existing methods represent knowledge in the
form of natural language text. Due to the long context and redundant content,
they struggle to meet the robots' requirements for real-time and precise
reasoning. In order to bridge this gap, we present AssemMate, which utilizes
the graph\textemdash a concise and accurate form of knowledge
representation\textemdash as input. This graph-based LLM enables knowledge
graph question answering (KGQA), supporting human-robot interaction and
assembly task planning for specific products. Beyond interactive QA, AssemMate
also supports sensing stacked scenes and executing grasping to assist with
assembly. Specifically, a self-supervised Graph Convolutional Network (GCN)
encodes knowledge graph entities and relations into a latent space and aligns
them with LLM's representation, enabling the LLM to understand graph
information. In addition, a vision-enhanced strategy is employed to address
stacked scenes in grasping. Through training and evaluation, AssemMate
outperforms existing methods, achieving 6.4\% higher accuracy, 3 times faster
inference, and 28 times shorter context length, while demonstrating strong
generalization ability on random graphs. And our approach further demonstrates
superiority through robotic grasping experiments in both simulated and
real-world settings. More details can be found on the project page:
https://github.com/cristina304/AssemMate.git

</details>


### [732] [Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios](https://arxiv.org/abs/2509.11621)
*Xiangtong Yao,Yirui Zhou,Yuan Meng,Yanwen Liu,Liangyu Dong,Zitao Zhang,Zhenshan Bing,Kai Huang,Fuchun Sun,Alois Knoll*

Main category: cs.RO

TL;DR: 提出一种自适应-投影策略，使扩散策略能够在推理时零样本适应新的机械臂和动态任务设置，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散策略在泛化到未见过的机械臂或末端执行器以及适应新的任务需求方面存在不足，通常需要昂贵的数据重新收集和策略重新训练。

Method: 在 SE(3) 空间中训练一个扩散策略，并在在线部署时，将策略生成的轨迹投影到以满足新硬件和目标施加的运动学和特定于任务的约束。该投影能够动态适应物理差异和任务需求。

Result: 在实际的抓取、推动和倾倒任务中，在弗兰卡熊猫和 Kuka iiwa 14 等多种机械臂上进行了验证，并使用了各种末端执行器，在跨机械臂场景中取得了持续的高成功率。

Conclusion: 所提出的自适应-投影策略能够有效地使扩散策略在推理时进行零样本适应，无需重新训练，证明了其有效性和实用性。

Abstract: Diffusion policies are powerful visuomotor models for robotic manipulation,
yet they often fail to generalize to manipulators or end-effectors unseen
during training and struggle to accommodate new task requirements at inference
time. Addressing this typically requires costly data recollection and policy
retraining for each new hardware or task configuration. To overcome this, we
introduce an adaptation-projection strategy that enables a diffusion policy to
perform zero-shot adaptation to novel manipulators and dynamic task settings,
entirely at inference time and without any retraining. Our method first trains
a diffusion policy in SE(3) space using demonstrations from a base manipulator.
During online deployment, it projects the policy's generated trajectories to
satisfy the kinematic and task-specific constraints imposed by the new hardware
and objectives. Moreover, this projection dynamically adapts to physical
differences (e.g., tool-center-point offsets, jaw widths) and task requirements
(e.g., obstacle heights), ensuring robust and successful execution. We validate
our approach on real-world pick-and-place, pushing, and pouring tasks across
multiple manipulators, including the Franka Panda and Kuka iiwa 14, equipped
with a diverse array of end-effectors like flexible grippers, Robotiq 2F/3F
grippers, and various 3D-printed designs. Our results demonstrate consistently
high success rates in these cross-manipulator scenarios, proving the
effectiveness and practicality of our adaptation-projection strategy. The code
will be released after peer review.

</details>


### [733] [ParaEQsA: Parallel and Asynchronous Embodied Questions Scheduling and Answering](https://arxiv.org/abs/2509.11663)
*Haisheng Wang,Weiming Zhi*

Main category: cs.RO

TL;DR: 该论文提出了面向多问题、异步、有紧急度考量的具身问答（EQsA）问题，并提供了名为ParaEQsA的框架、PAEQs基准测试以及新的评估指标DAR和NUWL。ParaEQsA通过共享记忆和优先规划模块，在效率和响应速度上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中多问题异步且有不同紧急度需求的具身问答场景，而非传统的单问题问答。

Method: 提出ParaEQsA框架，包含共享群组记忆模块以减少冗余探索，以及优先规划模块以动态调度问题。构建了包含异步追问和紧急度标签的PAEQs基准测试。

Result: ParaEQsA在PAEQs基准测试中，相较于顺序基线方法，在效率和响应速度上表现更优，同时减少了探索和延迟。通过实证评估，验证了优先度、紧急度建模、空间范围、奖励估计和依赖推理等模块的有效性。

Conclusion: 面向现实世界、多问题负载的具身代理，紧急度感知和并行调度是实现响应迅速和高效的关键。

Abstract: This paper formulates the Embodied Questions Answering (EQsA) problem,
introduces a corresponding benchmark, and proposes a system to tackle the
problem. Classical Embodied Question Answering (EQA) is typically formulated as
answering one single question by actively exploring a 3D environment. Real
deployments, however, often demand handling multiple questions that may arrive
asynchronously and carry different urgencies. We formalize this setting as
Embodied Questions Answering (EQsA) and present ParaEQsA, a framework for
parallel, urgency-aware scheduling and answering. ParaEQsA leverages a group
memory module shared among questions to reduce redundant exploration, and a
priority-planning module to dynamically schedule questions. To evaluate this
setting, we contribute the Parallel Asynchronous Embodied Questions (PAEQs)
benchmark containing 40 indoor scenes and five questions per scene (200 in
total), featuring asynchronous follow-up questions and urgency labels. We
further propose metrics for EQsA performance: Direct Answer Rate (DAR), and
Normalized Urgency-Weighted Latency (NUWL), which jointly measure efficiency
and responsiveness of this system. ParaEQsA consistently outperforms strong
sequential baselines adapted from recent EQA systems, while reducing
exploration and delay. Empirical evaluations investigate the relative
contributions of priority, urgency modeling, spatial scope, reward estimation,
and dependency reasoning within our framework. Together, these results
demonstrate that urgency-aware, parallel scheduling is key to making embodied
agents responsive and efficient under realistic, multi-question workloads.

</details>


### [734] [Tensor Invariant Data-Assisted Control and Dynamic Decomposition of Multibody Systems](https://arxiv.org/abs/2509.11688)
*Mostafa Eslami,Maryam Babazadeh*

Main category: cs.RO

TL;DR: 本研究提出了一种结合张量力学和数据辅助控制（DAC）的新框架，用于解决机器人协作工作空间中的控制挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人控制方法在复杂协作环境中，依赖坐标系的方法导致数据效率低下，难以泛化，迫使学习算法在每次新姿态下重新学习物理原理。

Method: 提出了一种基于张量力学的无坐标系、无约减的多体动力学和运动学模型，并结合数据辅助控制（DAC）架构。推导了一种优化的牛顿-欧拉模型，实现了系统在确定部分和不确定部分的分解。提出端到端的张量不变模型、控制和学习流程，并利用李雅普诺夫分析证明了确定部分的无坐标系控制律的稳定性。

Result: 通过仿真验证了模型和闭环系统的有效性，证明了该框架能够为数据高效、框架不变的学习算法提供理想的输入。

Conclusion: 该框架通过解决数据效率低下问题，提高了可解释性，为在交互环境中实现更鲁棒、更通用的机器人控制铺平了道路。

Abstract: The control of robotic systems in complex, shared collaborative workspaces
presents significant challenges in achieving robust performance and safety when
learning from experienced or simulated data is employed in the pipeline. A
primary bottleneck is the reliance on coordinate-dependent models, which leads
to profound data inefficiency by failing to generalize physical interactions
across different frames of reference. This forces learning algorithms to
rediscover fundamental physical principles in every new orientation,
artificially inflating the complexity of the learning task. This paper
introduces a novel framework that synergizes a coordinate-free, unreduced
multibody dynamics and kinematics model based on tensor mechanics with a
Data-Assisted Control (DAC) architecture. A non-recursive, closed-form
Newton-Euler model in an augmented matrix form is derived that is optimized for
tensor-based control design. This structure enables a principled decomposition
of the system into a structurally certain, physically grounded part and an
uncertain, empirical, and interaction-focused part, mediated by a virtual port
variable. Then, a complete, end-to-end tensor-invariant pipeline for modeling,
control, and learning is proposed. The coordinate-free control laws for the
structurally certain part provide a stable and abstract command interface,
proven via Lyapunov analysis. Eventually, the model and closed-loop system are
validated through simulations. This work provides a naturally ideal input for
data-efficient, frame-invariant learning algorithms, such as equivariant
learning, designed to learn the uncertain interaction. The synergy directly
addresses the data-inefficiency problem, increases explainability and
interpretability, and paves the way for more robust and generalizable robotic
control in interactive environments.

</details>


### [735] [From Pixels to Shelf: End-to-End Algorithmic Control of a Mobile Manipulator for Supermarket Stocking and Fronting](https://arxiv.org/abs/2509.11740)
*Davide Peron,Victor Nan Fernandez-Ayala,Lukas Segelmark*

Main category: cs.RO

TL;DR: 该论文介绍了一个用于零售环境（特别是超市）的自主上架机器人系统。该系统整合了现成的硬件和基于ROS2的算法（包括行为树、视觉模型和模型预测控制），实现了高效的上架和整理功能。


<details>
  <summary>Details</summary>
Motivation: 零售环境中自主上架面临人类互动、空间限制和产品多样性等挑战，需要高效的机器人系统。

Method: 该系统集成了现成的硬件和基于ROS2的感知、规划和控制算法，采用行为树进行任务规划，微调的视觉模型进行物体检测，以及两步模型预测控制（MPC）框架利用ArUco标记进行精确的货架导航。

Result: 在模拟超市环境的实验中，该系统在超过700次的上架操作中，拾放操作成功率超过98%。

Conclusion: 尽管实验结果可靠，但与人类工人相比，该系统的性能和成本效益仍有差距，表明在广泛商业部署前仍需改进。

Abstract: Autonomous stocking in retail environments, particularly supermarkets,
presents challenges due to dynamic human interactions, constrained spaces, and
diverse product geometries. This paper introduces an efficient end-to-end
robotic system for autonomous shelf stocking and fronting, integrating
commercially available hardware with a scalable algorithmic architecture. A
major contribution of this work is the system integration of off-the-shelf
hardware and ROS2-based perception, planning, and control into a single
deployable platform for retail environments. Our solution leverages Behavior
Trees (BTs) for task planning, fine-tuned vision models for object detection,
and a two-step Model Predictive Control (MPC) framework for precise shelf
navigation using ArUco markers. Laboratory experiments replicating realistic
supermarket conditions demonstrate reliable performance, achieving over 98%
success in pick-and-place operations across a total of more than 700 stocking
events. However, our comparative benchmarks indicate that the performance and
cost-effectiveness of current autonomous systems remain inferior to that of
human workers, which we use to highlight key improvement areas and quantify the
progress still required before widespread commercial deployment can
realistically be achieved.

</details>


### [736] [Adaptive Motorized LiDAR Scanning Control for Robust Localization with OpenStreetMap](https://arxiv.org/abs/2509.11742)
*Jianping Li,Kaisong Zhu,Zhongyuan Liu,Rui Jin,Xinhang Xu,Pengfei Wan,Lihua Xie*

Main category: cs.RO

TL;DR: 通过结合OSM地图和自适应LiDAR扫描，提高机器人在复杂环境中的定位鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: OSM地图虽然提供了全局先验信息，但可能不完整或过时；而传统的LiDAR扫描方式效率低下，尤其是在特征稀疏的区域。

Method: 提出了一种自适应LiDAR扫描框架，结合了OSM地图引导和局部可观测性预测。通过在不确定性感知模型预测控制中加入OSM感知项，根据场景依赖的可观测性和OSM特征的空间分布来适应性地分配扫描资源。

Result: 在模拟和真实世界（包括校园道路、室内走廊和城市环境）的实验中，与恒速扫描基线相比，该方法显著降低了轨迹误差，同时保持了扫描完整性。

Conclusion: 将开源地图与自适应LiDAR扫描相结合，可以在复杂环境中实现鲁棒且高效的定位。

Abstract: LiDAR-to-OpenStreetMap (OSM) localization has gained increasing attention, as
OSM provides lightweight global priors such as building footprints. These
priors enhance global consistency for robot navigation, but OSM is often
incomplete or outdated, limiting its reliability in real-world deployment.
Meanwhile, LiDAR itself suffers from a limited field of view (FoV), where
motorized rotation is commonly used to achieve panoramic coverage. Existing
motorized LiDAR systems, however, typically employ constant-speed scanning that
disregards both scene structure and map priors, leading to wasted effort in
feature-sparse regions and degraded localization accuracy. To address these
challenges, we propose Adaptive LiDAR Scanning with OSM guidance, a framework
that integrates global priors with local observability prediction to improve
localization robustness. Specifically, we augment uncertainty-aware model
predictive control with an OSM-aware term that adaptively allocates scanning
effort according to both scene-dependent observability and the spatial
distribution of OSM features. The method is implemented in ROS with a motorized
LiDAR odometry backend and evaluated in both simulation and real-world
experiments. Results on campus roads, indoor corridors, and urban environments
demonstrate significant reductions in trajectory error compared to
constant-speed baselines, while maintaining scan completeness. These findings
highlight the potential of coupling open-source maps with adaptive LiDAR
scanning to achieve robust and efficient localization in complex environments.

</details>


### [737] [Igniting VLMs toward the Embodied Space](https://arxiv.org/abs/2509.11766)
*Andy Zhai,Brae Liu,Bruno Fang,Chalse Cai,Ellie Ma,Ethan Yin,Hao Wang,Hugo Zhou,James Wang,Lights Shi,Lucy Liang,Make Wang,Qian Wang,Roy Gan,Ryan Yu,Shalfun Li,Starrick Liu,Sylas Chen,Vincent Chen,Zach Xu*

Main category: cs.RO

TL;DR: WALL-OSS是一个端到端的具身基础模型，用于解决现有视觉-语言模型在空间和具身理解方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在空间和具身理解方面存在局限性，导致在具身领域应用时存在多方面的模型不匹配，动作理解和生成是通往AGI的关键瓶颈。

Method: 提出WALL-OSS模型，采用紧密集成的架构和多策略训练课程，实现了统一的跨级别推理（CoT），能够无缝统一指令推理、子目标分解和细粒度动作合成。

Result: WALL-OSS在复杂的长时程操作任务上取得了高成功率，展现了强大的指令遵循能力、复杂的理解和推理能力，并且优于其他基线模型。

Conclusion: WALL-OSS为从视觉-语言模型（VLMs）过渡到具身基础模型提供了一条可靠且可扩展的路径。

Abstract: While foundation models show remarkable progress in language and vision,
existing vision-language models (VLMs) still have limited spatial and
embodiment understanding. Transferring VLMs to embodied domains reveals
fundamental mismatches between modalities, pretraining distributions, and
training objectives, leaving action comprehension and generation as a central
bottleneck on the path to AGI.
  We introduce WALL-OSS, an end-to-end embodied foundation model that leverages
large-scale multimodal pretraining to achieve (1) embodiment-aware
vision-language understanding, (2) strong language-action association, and (3)
robust manipulation capability.
  Our approach employs a tightly coupled architecture and multi-strategies
training curriculum that enables Unified Cross-Level CoT-seamlessly unifying
instruction reasoning, subgoal decomposition, and fine-grained action synthesis
within a single differentiable framework.
  Our results show that WALL-OSS attains high success on complex long-horizon
manipulations, demonstrates strong instruction-following capabilities, complex
understanding and reasoning, and outperforms strong baselines, thereby
providing a reliable and scalable path from VLMs to embodied foundation models.

</details>


### [738] [Augmented Reality-Enhanced Robot Teleoperation for Collecting User Demonstrations](https://arxiv.org/abs/2509.11783)
*Shiqi Gong,Sebastian Zudaire,Chi Zhang,Zhen Li*

Main category: cs.RO

TL;DR: 通过增强现实（AR）和空间点云渲染，简化了工业机器人编程，提高了任务完成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的工业机器人编程复杂且耗时，而现有的编程 by Demonstration (PbD) 方法在接口和演示收集方面仍存在挑战。

Method: 提出了一种增强现实（AR）增强的机器人远程操作系统，集成了AR控制和空间点云渲染，实现了直观、非接触式的演示。该系统适用于ABB机器人平台，并已在IRB 1200工业机器人和GoFa 5协作机器人上进行了验证。

Result: 用户研究表明，增强环境感知（特别是点云渲染）可将任务完成准确性提高28%，并将系统可用性量表（SUS）分数提高12%，从而提升了用户体验。

Conclusion: AR增强的机器人远程操作系统能够直观地收集演示数据，提高工业机器人编程的效率和安全性，并可为机器学习应用提供有价值的训练数据。

Abstract: Traditional industrial robot programming is often complex and time-consuming,
typically requiring weeks or even months of effort from expert programmers.
Although Programming by Demonstration (PbD) offers a more accessible
alternative, intuitive interfaces for robot control and demonstration
collection remain challenging. To address this, we propose an Augmented Reality
(AR)-enhanced robot teleoperation system that integrates AR-based control with
spatial point cloud rendering, enabling intuitive, contact-free demonstrations.
This approach allows operators to control robots remotely without entering the
workspace or using conventional tools like the teach pendant. The proposed
system is generally applicable and has been demonstrated on ABB robot
platforms, specifically validated with the IRB 1200 industrial robot and the
GoFa 5 collaborative robot. A user study evaluates the impact of real-time
environmental perception, specifically with and without point cloud rendering,
on task completion accuracy, efficiency, and user confidence. Results indicate
that enhanced perception significantly improves task performance by 28% and
enhances user experience, as reflected by a 12% increase in the System
Usability Scale (SUS) score. This work contributes to the advancement of
intuitive robot teleoperation, AR interface design, environmental perception,
and teleoperation safety mechanisms in industrial settings for demonstration
collection. The collected demonstrations may serve as valuable training data
for machine learning applications.

</details>


### [739] [VH-Diffuser: Variable Horizon Diffusion Planner for Time-Aware Goal-Conditioned Trajectory Planning](https://arxiv.org/abs/2509.11930)
*Ruijia Liu,Ancheng Hou,Shaoyuan Li,Xiang Yin*

Main category: cs.RO

TL;DR: VHD框架将规划的horizon视为一个可学习的变量，而不是一个固定的超参数，从而解决了现有基于扩散规划器在处理不同长度任务时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的规划器通常依赖于固定的、预先指定的规划horizon，这在训练和推理时都会导致长度不匹配（轨迹过短或过长）以及在不同几何或动力学难度的实例中表现脆弱。

Method: VHD框架首先使用一个学习到的长度预测器模型来预测特定于实例的horizon，然后指导扩散规划器生成所需长度的轨迹。该框架通过在随机裁剪的子轨迹上进行训练和利用初始噪声塑形来控制轨迹长度，从而保持了与现有扩散规划器的兼容性，并且无需进行架构更改。

Result: VHD在迷宫导航和机器人手臂控制基准测试中提高了成功率和路径效率，对horizon不匹配和未见过的长度表现出更强的鲁棒性，同时保持了训练的简单性和仅限离线性。

Conclusion: VHD框架通过将horizon视为一个可学习的变量，有效解决了现有扩散规划器在处理可变长度任务时的局限性，并在多项基准测试中取得了优于现有方法的性能。

Abstract: Diffusion-based planners have gained significant recent attention for their
robustness and performance in long-horizon tasks. However, most existing
planners rely on a fixed, pre-specified horizon during both training and
inference. This rigidity often produces length-mismatch (trajectories that are
too short or too long) and brittle performance across instances with varying
geometric or dynamical difficulty. In this paper, we introduce the Variable
Horizon Diffuser (VHD) framework, which treats the horizon as a learned
variable rather than a fixed hyperparameter. Given a start-goal pair, we first
predict an instance-specific horizon using a learned Length Predictor model,
which guides a Diffusion Planner to generate a trajectory of the desired
length. Our design maintains compatibility with existing diffusion planners by
controlling trajectory length through initial noise shaping and training on
randomly cropped sub-trajectories, without requiring architectural changes.
Empirically, VHD improves success rates and path efficiency in maze-navigation
and robot-arm control benchmarks, showing greater robustness to horizon
mismatch and unseen lengths, while keeping training simple and offline-only.

</details>


### [740] [Synthetic vs. Real Training Data for Visual Navigation](https://arxiv.org/abs/2509.11791)
*Lauri Suomela,Sasanka Kuruppu Arachchige,German F. Torres,Harry Edelman,Joni-Kristian Kämäräinen*

Main category: cs.RO

TL;DR: 模拟器训练的策略在视觉导航任务中可以达到甚至超越真实世界训练的策略的性能，关键在于利用预训练的视觉表示和保证实时运行的导航策略架构。


<details>
  <summary>Details</summary>
Motivation: 研究模拟器训练的策略在真实世界评估时的性能表现，以及这种性能与真实世界训练的策略相比如何，尽管存在已知的sim-to-real gap。

Method: 提出一种能够桥接sim-to-real外观差异的导航策略架构，该架构利用预训练的视觉表示，并能在机器人硬件上实时运行。

Result: 在轮式移动机器人上的评估显示，所提出的策略在模拟器上训练时，其导航成功率比在真实世界训练的版本高出31%，比现有最先进方法高出50%。该模型在无人机上的部署验证了其泛化能力。

Conclusion: 强调了多样化的图像编码器预训练对于sim-to-real泛化的重要性，并指出在位学习（on-policy learning）是模拟器训练相对于真实数据训练的关键优势。

Abstract: This paper investigates how the performance of visual navigation policies
trained in simulation compares to policies trained with real-world data.
Performance degradation of simulator-trained policies is often significant when
they are evaluated in the real world. However, despite this well-known
sim-to-real gap, we demonstrate that simulator-trained policies can match the
performance of their real-world-trained counterparts.
  Central to our approach is a navigation policy architecture that bridges the
sim-to-real appearance gap by leveraging pretrained visual representations and
runs real-time on robot hardware. Evaluations on a wheeled mobile robot show
that the proposed policy, when trained in simulation, outperforms its
real-world-trained version by 31% and the prior state-of-the-art methods by 50%
in navigation success rate. Policy generalization is verified by deploying the
same model onboard a drone.
  Our results highlight the importance of diverse image encoder pretraining for
sim-to-real generalization, and identify on-policy learning as a key advantage
of simulated training over training with real data.

</details>


### [741] [UniPilot: Enabling GPS-Denied Autonomy Across Embodiments](https://arxiv.org/abs/2509.11793)
*Mihir Kulkarni,Mihir Dharmadhikari,Nikhil Khedekar,Morten Nissov,Mohit Singh,Philipp Weiss,Kostas Alexis*

Main category: cs.RO

TL;DR: UniPilot是一个紧凑的软硬件一体化自主载荷，可集成到各种机器人中，实现GPS拒止环境下的自主运行。它融合了激光雷达、雷达、视觉和惯性传感，以应对单一传感器可能失效的复杂情况。UniPilot运行完整的自主软件，包括多模态感知、探索与规划、以及基于学习的导航策略，提供定位、建图、规划和安全控制功能。


<details>
  <summary>Details</summary>
Motivation: 在GPS拒止环境下，为不同机器人平台提供通用的、可靠的自主导航能力。

Method: 开发了一个集成了激光雷达、雷达、视觉和惯性传感器的多模态感知系统，并运行了包括多模态感知、探索与规划、以及基于学习的导航策略在内的完整自主软件栈，将所有功能集成到一个紧凑的载荷单元中。

Result: 在多种环境和机器人平台上进行了大量实验，验证了UniPilot在建图、规划和安全导航方面的能力。

Conclusion: UniPilot作为一个通用的自主载荷，能够显著提升机器人在GPS拒止环境下的自主作业能力。

Abstract: This paper presents UniPilot, a compact hardware-software autonomy payload
that can be integrated across diverse robot embodiments to enable autonomous
operation in GPS-denied environments. The system integrates a multi-modal
sensing suite including LiDAR, radar, vision, and inertial sensing for robust
operation in conditions where uni-modal approaches may fail. UniPilot runs a
complete autonomy software comprising multi-modal perception, exploration and
inspection path planning, and learning-based navigation policies. The payload
provides robust localization, mapping, planning, and safety and control
capabilities in a single unit that can be deployed across a wide range of
platforms. A large number of experiments are conducted across diverse
environments and on a variety of robot platforms to validate the mapping,
planning, and safe navigation capabilities enabled by the payload.

</details>


### [742] [TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning](https://arxiv.org/abs/2509.11839)
*Jiacheng Liu,Pengxiang Ding,Qihang Zhou,Yuxuan Wu,Da Huang,Zimian Peng,Wei Xiao,Weinan Zhang,Lixin Yang,Cewu Lu,Donglin Wang*

Main category: cs.RO

TL;DR: 本研究提出了一种名为KORR的框架，结合了残差策略学习和koopman算子理论，以解决模仿学习在长时序任务和高精度控制中存在的累积误差问题，并通过在机器人家具组装任务上的实验验证了其在性能、鲁棒性和泛化性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在长时序任务和高精度控制中易出现累积误差，现有残差策略学习方法主要关注局部修正，缺乏对状态演变的全局理解，限制了鲁棒性和泛化能力。

Method: 提出KORR框架，利用koopman 算子理论在学习到的潜在空间中引入线性时不变结构，以实现可靠的状态转移和改进的外推能力，将残差修正与koopman 预测的潜在状态相结合，实现全局信息引导下的稳定动作修正。

Result: 在机器人家具组装等长时序、精细控制任务中，KORR 框架相比现有方法在性能、鲁棒性和泛化性方面均有显著提升。

Conclusion: koopman 算子理论可以有效结合现代学习方法和经典控制理论，为解决模仿学习中的挑战提供了一种有前景的途径。

Abstract: Imitation learning (IL) enables efficient skill acquisition from
demonstrations but often struggles with long-horizon tasks and high-precision
control due to compounding errors. Residual policy learning offers a promising,
model-agnostic solution by refining a base policy through closed-loop
corrections. However, existing approaches primarily focus on local corrections
to the base policy, lacking a global understanding of state evolution, which
limits robustness and generalization to unseen scenarios. To address this, we
propose incorporating global dynamics modeling to guide residual policy
updates. Specifically, we leverage Koopman operator theory to impose linear
time-invariant structure in a learned latent space, enabling reliable state
transitions and improved extrapolation for long-horizon prediction and unseen
environments. We introduce KORR (Koopman-guided Online Residual Refinement), a
simple yet effective framework that conditions residual corrections on
Koopman-predicted latent states, enabling globally informed and stable action
refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture
assembly tasks under various perturbations. Results demonstrate consistent
gains in performance, robustness, and generalization over strong baselines. Our
findings further highlight the potential of Koopman-based modeling to bridge
modern learning methods with classical control theory. For more details, please
refer to https://jiachengliu3.github.io/TrajBooster.

</details>


### [743] [Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer](https://arxiv.org/abs/2509.11865)
*Travis Davies,Yiqi Huang,Yunxin Liu,Xiang Chen,Huxian Liu,Luhui Hu*

Main category: cs.RO

TL;DR: Tenma是一个轻量级的扩散-Transformer模型，用于双臂机器人控制，通过多视图RGB、本体感觉和语言实现跨体学习，并在各种基准测试中取得了显著的成功率，表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在轻量级、跨体学习设置中结合Transformer策略和扩散模型以提升机器人操作的稳定性和性能。

Method: 引入Tenma模型，该模型整合了跨体归一化器、联合状态-时间编码器和优化的扩散动作解码器，以处理异构、多模态机器人数据。

Result: Tenma在各种基准测试中实现了88.95%的平均成功率，在物体和场景发生变化时仍能保持强大的性能，显著优于基线策略（最佳为18.12%）。

Conclusion: 多模态和跨体学习策略在增强基于Transformer的模仿学习策略方面具有巨大潜力，Tenma模型证明了这一点，它在中等数据规模下实现了鲁棒的操作和泛化能力。

Abstract: Scaling Transformer policies and diffusion models has advanced robotic
manipulation, yet combining these techniques in lightweight, cross-embodiment
learning settings remains challenging. We study design choices that most affect
stability and performance for diffusion-transformer policies trained on
heterogeneous, multimodal robot data, and introduce Tenma, a lightweight
diffusion-transformer for bi-manual arm control. Tenma integrates multiview
RGB, proprioception, and language via a cross-embodiment normalizer that maps
disparate state/action spaces into a shared latent space; a Joint State-Time
encoder for temporally aligned observation learning with inference speed
boosts; and a diffusion action decoder optimized for training stability and
learning capacity. Across benchmarks and under matched compute, Tenma achieves
an average success rate of 88.95% in-distribution and maintains strong
performance under object and scene shifts, substantially exceeding baseline
policies whose best in-distribution average is 18.12%. Despite using moderate
data scale, Tenma delivers robust manipulation and generalization, indicating
the great potential for multimodal and cross-embodiment learning strategies for
further augmenting the capacity of transformer-based imitation learning
policies.

</details>


### [744] [E2-BKI: Evidential Ellipsoidal Bayesian Kernel Inference for Uncertainty-aware Gaussian Semantic Mapping](https://arxiv.org/abs/2509.11964)
*Junyoung Kim,Minsik Jeon,Jihong Min,Kiho Kwak,Junwon Seo*

Main category: cs.RO

TL;DR: 该研究提出了一种不确定性感知的语义建图框架，利用证据深度学习和贝叶斯核推理来处理户外复杂环境中多源不确定性，以提高建图质量、不确定性校准、表示灵活性和鲁棒性，并实现了实时效率。


<details>
  <summary>Details</summary>
Motivation: 现有的语义建图方法在具有挑战性的户外环境中，在处理来自稀疏传感器数据的地图推理不连续性以及多源不确定性方面存在不足。

Method: 该框架利用证据深度学习估计语义预测中的不确定性，并将其纳入贝叶斯核推理中进行鲁棒的语义推理。它还将嘈杂的观测聚合为相干的高斯表示，以减轻不可靠点的​​影响，同时采用与几何对齐的核来适应复杂的场景结构。

Result: 在多样化的越野和城市户外环境中进行的全面评估表明，在建图质量、不确定性校准、表示灵活性和鲁棒性方面均有持续改进，同时保持实时效率。

Conclusion: 所提出的不确定性感知语义建图框架能够有效处理户外复杂场景中的多源不确定性，并在多个评估指标上实现了显著的改进，同时保持了实时性能。

Abstract: Semantic mapping aims to construct a 3D semantic representation of the
environment, providing essential knowledge for robots operating in complex
outdoor settings. While Bayesian Kernel Inference (BKI) addresses
discontinuities of map inference from sparse sensor data, existing semantic
mapping methods suffer from various sources of uncertainties in challenging
outdoor environments. To address these issues, we propose an uncertainty-aware
semantic mapping framework that handles multiple sources of uncertainties,
which significantly degrade mapping performance. Our method estimates
uncertainties in semantic predictions using Evidential Deep Learning and
incorporates them into BKI for robust semantic inference. It further aggregates
noisy observations into coherent Gaussian representations to mitigate the
impact of unreliable points, while employing geometry-aligned kernels that
adapt to complex scene structures. These Gaussian primitives effectively fuse
local geometric and semantic information, enabling robust, uncertainty-aware
mapping in complex outdoor scenarios. Comprehensive evaluation across diverse
off-road and urban outdoor environments demonstrates consistent improvements in
mapping quality, uncertainty calibration, representational flexibility, and
robustness, while maintaining real-time efficiency.

</details>


### [745] [Time-Constrained Intelligent Adversaries for Automation Vulnerability Testing: A Multi-Robot Patrol Case Study](https://arxiv.org/abs/2509.11971)
*James C. Ward,Alex Bott,Connor York,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 这是一个基于机器学习的对手模型，用于模拟对多机器人巡逻系统的攻击，以评估其稳健性。


<details>
  <summary>Details</summary>
Motivation: 为了检查物理自主系统对攻击的稳健性，并通过攻击来告知有漏洞的设计。在此工作中，我们通过多机器人巡逻的视角来研究这一点。

Method: 提出一个基于机器学习的对手模型，该模型观察机器人巡逻行为，以便在有限的时间内尝试未经检测地访问安全环境。

Result: 所提出的模型优于现有的基线，从而提供了更严格的测试，并与多种领先的去中心化多机器人巡逻策略进行了性能 পরীক্ষা。

Conclusion: 该模型能够对一个能够进行规避和隐身以闯入安全区域的多机器人巡逻系统进行严格的评估，从而为未来的巡逻策略设计提供了见解。

Abstract: Simulating hostile attacks of physical autonomous systems can be a useful
tool to examine their robustness to attack and inform vulnerability-aware
design. In this work, we examine this through the lens of multi-robot patrol,
by presenting a machine learning-based adversary model that observes robot
patrol behavior in order to attempt to gain undetected access to a secure
environment within a limited time duration. Such a model allows for evaluation
of a patrol system against a realistic potential adversary, offering insight
into future patrol strategy design. We show that our new model outperforms
existing baselines, thus providing a more stringent test, and examine its
performance against multiple leading decentralized multi-robot patrol
strategies.

</details>


### [746] [Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees](https://arxiv.org/abs/2509.12008)
*Yuqing Song,Cesare Tonola,Stefano Savazzi,Sanaz Kianoush,Nicola Pedrocchi,Stephan Sigg*

Main category: cs.RO

TL;DR: 本研究提出了一种使用毫米波雷达进行手势识别和机器人控制的系统，实现了无需接触的实时人机交互。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益普及，对直观高效的人机交互需求不断增长。手势识别作为一种无需物理接触的直观控制方法，在无线解决方案中尤为灵活且侵入性小。与存在隐私顾虑且易受环境影响的摄像头视觉系统相比，毫米波雷达具有隐私保护、抗遮挡、抗光照干扰以及提供丰富空间数据（如距离、相对速度和角度）的优势。

Method: 提出并实现了一个使用毫米波雷达进行手势识别的系统，并将识别出的九种手势映射为实时的机器人控制指令，以控制机械臂的运动。

Result: 成功识别九种手势，并将其转化为对机械臂的实时控制指令，实现了精确的手势识别和响应。通过案例研究验证了该系统的实用性、性能和可靠性。

Conclusion: 本系统将手势识别和机器人控制统一在一个实时管道中，实现了无缝的、非接触式的人机交互，解决了现有技术中将两者分开处理的问题。

Abstract: As robots become increasingly prevalent in both homes and industrial
settings, the demand for intuitive and efficient human-machine interaction
continues to rise. Gesture recognition offers an intuitive control method that
does not require physical contact with devices and can be implemented using
various sensing technologies. Wireless solutions are particularly flexible and
minimally invasive. While camera-based vision systems are commonly used, they
often raise privacy concerns and can struggle in complex or poorly lit
environments. In contrast, radar sensing preserves privacy, is robust to
occlusions and lighting, and provides rich spatial data such as distance,
relative velocity, and angle. We present a gesture-controlled robotic arm using
mm-wave radar for reliable, contactless motion recognition. Nine gestures are
recognized and mapped to real-time commands with precision. Case studies are
conducted to demonstrate the system practicality, performance and reliability
for gesture-based robotic manipulation. Unlike prior work that treats gesture
recognition and robotic control separately, our system unifies both into a
real-time pipeline for seamless, contactless human-robot interaction.

</details>


### [747] [Embodied Navigation Foundation Model](https://arxiv.org/abs/2509.12129)
*Jiazhao Zhang,Anqi Li,Yunpeng Qi,Minghan Li,Jiahang Liu,Shaoan Wang,Haoran Liu,Gengze Zhou,Yuze Wu,Xingxing Li,Yuxin Fan,Wenjun Li,Zhibo Chen,Fei Gao,Qi Wu,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: NavFoM 是一个跨越多种载具和任务的导航基础模型，在八百万导航样本上训练，实现了在各种导航任务和载具上的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在具身导航方面的泛化能力有限，通常局限于特定的任务和具身架构。本文旨在开发一个能够跨越不同载具和任务的通用导航基础模型。

Method: NavFoM 使用统一架构处理来自不同相机配置和导航视野的多模态导航输入。它引入了标识符令牌来嵌入载具的相机视图信息和任务的时间上下文。为了在有限的令牌长度预算内满足实际部署的需求，NavFoM 采用动态采样策略来控制所有观测令牌。

Result: 在公共基准的广泛评估中，NavFoM 在多种导航任务和载具上实现了最先进或具有高度竞争力的性能，且无需进行特定任务的微调。此外，实际的实验也验证了该方法的强大泛化能力和实际适用性。

Conclusion: NavFoM 成功地开发了一个能够跨越不同具身形态和导航任务的通用导航基础模型，显著提高了具身导航的泛化能力和实际应用潜力。

Abstract: Navigation is a fundamental capability in embodied AI, representing the
intelligence required to perceive and interact within physical environments
following language instructions. Despite significant progress in large
Vision-Language Models (VLMs), which exhibit remarkable zero-shot performance
on general vision-language tasks, their generalization ability in embodied
navigation remains largely confined to narrow task settings and
embodiment-specific architectures. In this work, we introduce a
cross-embodiment and cross-task Navigation Foundation Model (NavFoM), trained
on eight million navigation samples that encompass quadrupeds, drones, wheeled
robots, and vehicles, and spanning diverse tasks such as vision-and-language
navigation, object searching, target tracking, and autonomous driving. NavFoM
employs a unified architecture that processes multimodal navigation inputs from
varying camera configurations and navigation horizons. To accommodate diverse
camera setups and temporal horizons, NavFoM incorporates identifier tokens that
embed camera view information of embodiments and the temporal context of tasks.
Furthermore, to meet the demands of real-world deployment, NavFoM controls all
observation tokens using a dynamically adjusted sampling strategy under a
limited token length budget. Extensive evaluations on public benchmarks
demonstrate that our model achieves state-of-the-art or highly competitive
performance across multiple navigation tasks and embodiments without requiring
task-specific fine-tuning. Additional real-world experiments further confirm
the strong generalization capability and practical applicability of our
approach.

</details>


### [748] [Learning Contact Dynamics for Control with Action-conditioned Face Interaction Graph Networks](https://arxiv.org/abs/2509.12151)
*Zongyao Yi,Joachim Hertzberg,Martin Atzmueller*

Main category: cs.RO

TL;DR: 提出了一个可学习的物理模拟器，用于机器人末端执行器的接触丰富操作中的精确运动和力-扭矩预测。


<details>
  <summary>Details</summary>
Motivation: 机器人末端执行器在接触丰富操作中的运动和力-扭矩预测需要准确的物理模拟，现有模型（如FIGNet）需要改进以支持控制和状态估计任务。

Method: 扩展了基于GNN的模拟器FIGNet，引入了新的节点和边类型，实现了可进行动作条件预测的模型。

Result: 在模拟中，MPC（模型预测控制）在穿钉子任务中，使用该模型的控制器与使用真实动力学模型的控制器性能相当。在真实世界实验中，该模型在运动预测精度上比基线物理模拟器提高了50%，在力-扭矩预测精度上提高了3倍。

Conclusion: 该可学习的物理模拟器在机器人末端执行器的接触丰富操作中，能够实现准确的运动和力-扭矩预测，并在控制和状态估计任务中展现出优越性能。

Abstract: We present a learnable physics simulator that provides accurate motion and
force-torque prediction of robot end effectors in contact-rich manipulation.
The proposed model extends the state-of-the-art GNN-based simulator (FIGNet)
with novel node and edge types, enabling action-conditional predictions for
control and state estimation tasks. In simulation, the MPC agent using our
model matches the performance of the same controller with the ground truth
dynamics model in a challenging peg-in-hole task, while in the real-world
experiment, our model achieves a 50% improvement in motion prediction accuracy
and 3$\times$ increase in force-torque prediction precision over the baseline
physics simulator. Source code and data are publicly available.

</details>
