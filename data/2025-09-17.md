<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 30]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.AR](#cs.AR) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 7]
- [cs.DC](#cs.DC) [Total: 14]
- [cs.LG](#cs.LG) [Total: 50]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.LO](#cs.LO) [Total: 8]
- [eess.SY](#eess.SY) [Total: 17]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.SI](#cs.SI) [Total: 9]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 50]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [cs.NE](#cs.NE) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 18]
- [eess.SP](#eess.SP) [Total: 20]
- [cs.ET](#cs.ET) [Total: 1]
- [quant-ph](#quant-ph) [Total: 43]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的框架，用于模拟室内RF信号，解决了RF数据收集的挑战。


<details>
  <summary>Details</summary>
Motivation: 室内感知任务中，RF传感作为一种保护隐私的替代视觉方法，但高质量RF数据收集困难。

Method: WaveVerse包含一个语言引导的4D世界生成器，其中包括状态感知因果Transformer用于人体运动生成，以及一个相位一致的射线追踪模拟器来模拟RF信号。

Result: 实验证明了该方法在人体运动生成方面的有效性，并展示了相位一致性在波束成形和呼吸监测中的应用。WaveVerse能够生成RF成像数据，并在不同场景下提高性能。

Conclusion: WaveVerse为RF传感的数据生成提供了新途径，并在多个应用中展现了其有效性和优越性。

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [2] [Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics](https://arxiv.org/abs/2509.12248)
*Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: 该研究提出了PixelHumor数据集，用于评估大型多模态模型（LMM）理解多模态幽默和叙事序列的能力，实验表明现有模型在这一领域存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 理解幽默是社交智能的核心，但对大型多模态模型（LMM）来说仍然是一个重大挑战。

Method: 创建了一个包含2,800个带注释的多面板漫画的数据集PixelHumor，用于评估LMM理解多模态幽默和识别叙事序列的能力。

Result: 在对最先进的LMM进行的实验中，发现在面板排序方面，顶级模型的准确率仅为61%，远低于人类表现，这表明当前模型在整合视觉和文本线索以实现连贯叙事和幽默理解方面存在重大局限性。

Conclusion: PixelHumor数据集提供了一个严格的框架来评估多模态上下文和叙事推理能力，旨在推动LMM在更自然、更具社会意识的交互方面的研发。

Abstract: Understanding humor is a core aspect of social intelligence, yet it remains a
significant challenge for Large Multimodal Models (LMMs). We introduce
PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed
to evaluate LMMs' ability to interpret multimodal humor and recognize narrative
sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for
instance, top models achieve only 61% accuracy in panel sequencing, far below
human performance. This underscores critical limitations in current models'
integration of visual and textual cues for coherent narrative and humor
understanding. By providing a rigorous framework for evaluating multimodal
contextual and narrative reasoning, PixelHumor aims to drive the development of
LMMs that better engage in natural, socially aware interactions.

</details>


### [3] [OnlineHOI: Towards Online Human-Object Interaction Generation and Perception](https://arxiv.org/abs/2509.12250)
*Yihong Ji,Yunze Liu,Yiyao Zhuo,Weijiang Yu,Fei Ma,Joshua Huang,Fei Yu*

Main category: cs.CV

TL;DR: 当前HOI（人-物交互）方法多为离线设置，但现实世界是实时交互，离线方法在此表现不佳。本文提出在线HOI生成和感知任务，并引入了基于Mamba和记忆机制的OnlineHOI框架，在Core4D、OAKINK2和HOI4D任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有HOI方法多为离线设置，无法满足需要实时信息处理的真实世界场景，且离线方法在在线环境下表现不佳。

Method: 提出在线HOI生成和感知任务，并引入了基于Mamba和记忆机制的OnlineHOI框架。

Result: 在Core4D和OAKINK2在线生成任务以及HOI4D在线感知任务上取得最先进（SOTA）的性能。

Conclusion: 所提出的OnlineHOI框架能有效处理在线HOI任务，并在多个基准测试中取得了优异的成果。

Abstract: The perception and generation of Human-Object Interaction (HOI) are crucial
for fields such as robotics, AR/VR, and human behavior understanding. However,
current approaches model this task in an offline setting, where information at
each time step can be drawn from the entire interaction sequence. In contrast,
in real-world scenarios, the information available at each time step comes only
from the current moment and historical data, i.e., an online setting. We find
that offline methods perform poorly in an online context. Based on this
observation, we propose two new tasks: Online HOI Generation and Perception. To
address this task, we introduce the OnlineHOI framework, a network architecture
based on the Mamba framework that employs a memory mechanism. By leveraging
Mamba's powerful modeling capabilities for streaming data and the Memory
mechanism's efficient integration of historical information, we achieve
state-of-the-art results on the Core4D and OAKINK2 online generation tasks, as
well as the online HOI4D perception task.

</details>


### [4] [AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models](https://arxiv.org/abs/2509.12715)
*Heng Zhang,Haichuan Hu,Yaomin Shen,Weihao Yu,Yilei Yuan,Haochen You,Guo Cheng,Zijian Zhang,Lubin Gan,Huihui Wei,Hao Zhang,Jin Huang*

Main category: cs.CV

TL;DR: AsyMoE通过引入针对视觉和语言处理不对称性的新架构，提高了大型视觉语言模型（LVLM）的性能，同时减少了计算量。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLM）在处理多模态任务时，由于视觉和语言处理的内在差异（视觉信息是空间完整的，而语言需要顺序上下文），导致混合专家（MoE）模型在平衡特定模态特征和跨模态交互方面存在挑战。更具体地说，在更深层次的模型中，语言专家倾向于丢失上下文信息，更多地依赖参数知识，而不是利用提供的视觉和语言信息。

Method: 提出了一种名为AsyMoE的新架构，该架构包含三个专门的专家组来模拟视觉和语言处理之间的不对称性：1. 模态内专家（intra-modality experts）：用于处理特定模态的信息。2. 双曲跨模态专家（hyperbolic inter-modality experts）：用于处理分层的跨模态交互。3. 证据优先语言专家（evidence-priority language experts）：用于减少参数偏差，保持上下文关联性。

Result: AsyMoE在实验中取得了显著的成果，相比于标准的MoE模型，准确率提升了26.58%；相比于模态特定的MoE模型，准确率提升了15.45%。此外，与密集模型相比，AsyMoE激活的参数数量减少了25.45%。

Conclusion: AsyMoE通过有效处理视觉和语言处理过程中的不对称性，显著提高了LVLM在多模态任务上的性能，并在参数效率方面优于现有模型。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive performance
on multimodal tasks through scaled architectures and extensive training.
However, existing Mixture of Experts (MoE) approaches face challenges due to
the asymmetry between visual and linguistic processing. Visual information is
spatially complete, while language requires maintaining sequential context. As
a result, MoE models struggle to balance modality-specific features and
cross-modal interactions. Through systematic analysis, we observe that language
experts in deeper layers progressively lose contextual grounding and rely more
on parametric knowledge rather than utilizing the provided visual and
linguistic information. To address this, we propose AsyMoE, a novel
architecture that models this asymmetry using three specialized expert groups.
We design intra-modality experts for modality-specific processing, hyperbolic
inter-modality experts for hierarchical cross-modal interactions, and
evidence-priority language experts to suppress parametric biases and maintain
contextual grounding. Extensive experiments demonstrate that AsyMoE achieves
26.58% and 15.45% accuracy improvements over vanilla MoE and modality-specific
MoE respectively, with 25.45% fewer activated parameters than dense models.

</details>


### [5] [A Synthetic Data Pipeline for Supporting Manufacturing SMEs in Visual Assembly Control](https://arxiv.org/abs/2509.13089)
*Jonas Werheid,Shengjie He,Aymen Gannouni,Anas Abdelrazeq,Robert H. Schmitt*

Main category: cs.CV

TL;DR: 使用合成数据和CAD模型进行数据高效的视觉装配质量控制，解决了中小企业在数据收集和标注方面的资源限制。


<details>
  <summary>Details</summary>
Motivation: 中小企业在集成自动视觉装配控制方面面临数据收集、标注和模型训练的成本挑战。现有合成数据方法的应用有限。

Method: 提出了一种利用CAD数据生成模拟场景和目标检测算法的数据高效视觉装配控制方法，以创建易于集成的解决方案。

Result: 在合成数据上实现了高达99.5%的mAP（@0.5:0.95）的行星齿轮系统组件识别率，在实际测试数据上达到了93%的识别率，展示了时间节省的图像数据生成流程。

Conclusion: 合成数据生成在资源高效的视觉装配控制中是有效的，并且可以支持中小企业采用这些解决方案。

Abstract: Quality control of assembly processes is essential in manufacturing to ensure
not only the quality of individual components but also their proper integration
into the final product. To assist in this matter, automated assembly control
using computer vision methods has been widely implemented. However, the costs
associated with image acquisition, annotation, and training of computer vision
algorithms pose challenges for integration, especially for small- and
medium-sized enterprises (SMEs), which often lack the resources for extensive
training, data collection, and manual image annotation. Synthetic data offers
the potential to reduce manual data collection and labeling. Nevertheless, its
practical application in the context of assembly quality remains limited. In
this work, we present a novel approach for easily integrable and data-efficient
visual assembly control. Our approach leverages simulated scene generation
based on computer-aided design (CAD) data and object detection algorithms. The
results demonstrate a time-saving pipeline for generating image data in
manufacturing environments, achieving a mean Average Precision (mAP@0.5:0.95)
up to 99,5% for correctly identifying instances of synthetic planetary gear
system components within our simulated training data, and up to 93% when
transferred to real-world camera-captured testing data. This research
highlights the effectiveness of synthetic data generation within an adaptable
pipeline and underscores its potential to support SMEs in implementing
resource-efficient visual assembly control solutions.

</details>


### [6] [RU-Net for Automatic Characterization of TRISO Fuel Cross Sections](https://arxiv.org/abs/2509.12244)
*Lu Cai,Fei Xu,Min Xian,Yalei Tang,Shoukun Sun,John Stempien*

Main category: cs.CV

TL;DR: 该研究使用卷积神经网络（CNN）自动分割 TRISO 燃料颗粒的横截面图像，以识别和量化辐照引起的形态变化，从而加速数据分析并提高客观性。


<details>
  <summary>Details</summary>
Motivation: 手动分析 TRISO 燃料颗粒的辐照诱导形态变化（如内核溶胀和缓冲层致密化）效率低下且主观性强。

Method: 使用卷积神经网络（包括 RU-Net、U-Net、ResNet 和 Attention U-Net）对包含 2,000 多张图像的 TRISO 颗粒横截面图像数据集进行自动分割，以识别不同的 TRISO 层。

Result: 基于 RU-Net 的模型在交并比（IoU）方面表现最佳，表明 CNN 模型能够有效加速 TRISO 颗粒横截面的分析，减少手动工作量并提高分割结果的客观性。

Conclusion: 卷积神经网络（CNN）可以有效地自动分割 TRISO 燃料颗粒的横截面图像，从而加速数据分析并提高结果的客观性。

Abstract: During irradiation, phenomena such as kernel swelling and buffer
densification may impact the performance of tristructural isotropic (TRISO)
particle fuel. Post-irradiation microscopy is often used to identify these
irradiation-induced morphologic changes. However, each fuel compact generally
contains thousands of TRISO particles. Manually performing the work to get
statistical information on these phenomena is cumbersome and subjective. To
reduce the subjectivity inherent in that process and to accelerate data
analysis, we used convolutional neural networks (CNNs) to automatically segment
cross-sectional images of microscopic TRISO layers. CNNs are a class of
machine-learning algorithms specifically designed for processing structured
grid data. They have gained popularity in recent years due to their remarkable
performance in various computer vision tasks, including image classification,
object detection, and image segmentation. In this research, we generated a
large irradiated TRISO layer dataset with more than 2,000 microscopic images of
cross-sectional TRISO particles and the corresponding annotated images. Based
on these annotated images, we used different CNNs to automatically segment
different TRISO layers. These CNNs include RU-Net (developed in this study), as
well as three existing architectures: U-Net, Residual Network (ResNet), and
Attention U-Net. The preliminary results show that the model based on RU-Net
performs best in terms of Intersection over Union (IoU). Using CNN models, we
can expedite the analysis of TRISO particle cross sections, significantly
reducing the manual labor involved and improving the objectivity of the
segmentation results.

</details>


### [7] [Modular, On-Site Solutions with Lightweight Anomaly Detection for Sustainable Nutrient Management in Agriculture](https://arxiv.org/abs/2509.12247)
*Abigail R. Cohen,Yuming Sun,Zhihao Qin,Harsh S. Muriki,Zihao Xiao,Yeonju Lee,Matthew Housley,Andrew F. Sharkey,Rhuanito S. Ferrarezi,Jing Li,Lu Gan,Yongsheng Chen*

Main category: cs.CV

TL;DR: 该研究提出了一个灵活、分层的管道，用于农业中的异常检测和状态估计，通过多光谱成像和不同的计算方法，在效率和准确性之间取得平衡，旨在实现边缘诊断和可持续农业。


<details>
  <summary>Details</summary>
Motivation: 有效的营养管理对作物生长和可持续资源消耗至关重要，但现有方法耗时且计算成本高，阻碍了实时优化和资源受限环境下的部署。

Method: 开发了一个分层的管道，使用自动编码器（AE）进行早期预警，并比较了两种状态估计模块：使用植被指数（VI）特征和机器学习（随机森林，RF），以及原始全图像深度学习（Vision Transformer，ViT）。通过不同肥料强度的三组处理（T1-100%，T2-50%，T3-25%）和多光谱成像（MSI）进行实验。

Result: 该方法能够高效地进行异常检测（移植后9天可检测到73%的T3样本），且能耗远低于氮肥浪费所产生的能耗。状态估计模块显示出权衡：ViT在磷和钙估计方面优于RF（R2分别为0.61 vs. 0.58，0.48 vs. 0.35），但能耗成本更高。

Conclusion: 该研究提出的模块化管道为边缘诊断提供了可能性，并为农业可持续性提供了实际的应用机会。

Abstract: Efficient nutrient management is critical for crop growth and sustainable
resource consumption (e.g., nitrogen, energy). Current approaches require
lengthy analyses, preventing real-time optimization; similarly, imaging
facilitates rapid phenotyping but can be computationally intensive, preventing
deployment under resource constraints. This study proposes a flexible, tiered
pipeline for anomaly detection and status estimation (fresh weight, dry mass,
and tissue nutrients), including a comprehensive energy analysis of approaches
that span the efficiency-accuracy spectrum. Using a nutrient depletion
experiment with three treatments (T1-100%, T2-50%, and T3-25% fertilizer
strength) and multispectral imaging (MSI), we developed a hierarchical pipeline
using an autoencoder (AE) for early warning. Further, we compared two status
estimation modules of different complexity for more detailed analysis:
vegetation index (VI) features with machine learning (Random Forest, RF) and
raw whole-image deep learning (Vision Transformer, ViT). Results demonstrated
high-efficiency anomaly detection (73% net detection of T3 samples 9 days after
transplanting) at substantially lower energy than embodied energy in wasted
nitrogen. The state estimation modules show trade-offs, with ViT outperforming
RF on phosphorus and calcium estimation (R2 0.61 vs. 0.58, 0.48 vs. 0.35) at
higher energy cost. With our modular pipeline, this work opens opportunities
for edge diagnostics and practical opportunities for agricultural
sustainability.

</details>


### [8] [A Modern Look at Simplicity Bias in Image Classification Tasks](https://arxiv.org/abs/2509.12265)
*Xiaoguang Chang,Teng Wang,Changyin Sun*

Main category: cs.CV

TL;DR: 神经网路中的简单性偏见（SB）影响泛化能力，但过度的SB可能损害复杂任务的表现。本文提出了一种频率感知的新度量方法来捕捉更细粒度的SB差异，并验证了其在CLIP模型上的有效性。研究发现，SB与模型在图像分类任务上的表现存在关联，例如，更强的SB有利于OOD泛化而非对抗鲁棒性。这表明，将模型的归纳偏置与任务特性对齐至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有研究对大型模型中的简单性偏见（SB）测量及其与图像分类任务的相关性知之甚少，尤其是在简单模型或合成任务之外的情况下。因此，有必要研究SB在大型模型中的表现及其与不同图像分类任务性能的关系。

Method: 本文提出了一种频率感知的新度量方法来捕捉更细粒度的SB差异，并验证了其在CLIP模型上的有效性。接着，研究了CLIP模型中的SB与其在零样本和微调设置下进行的一系列图像分类任务的表现之间的关系。

Result: 提出的频率感知度量方法比现有方法更具信息量和一致性。研究发现，更强的SB与更好的OOD泛化能力相关，而非更好的对抗鲁棒性。

Conclusion: 模型的归纳偏置应与目标任务的特性相匹配，以优化其在不同下游任务中的表现。

Abstract: The simplicity Bias (SB) of neural networks, i.e.\ their tendency to
represent simple functions, is a key factor in their generalization
capabilities. Recent studies show that an excessive SB may harm performance on
complex tasks, and the need for this bias varies across tasks. Many of these
studies focus on simple models or synthetic tasks. It remains challenging to
measure the SB in large models and little is known about the relevance of the
SB to various image classification tasks.
  In this paper, we investigate the relationship between the SB in CLIP models
and their performance across image classification tasks. First, we
theoretically analyze the potential limitation of existing measures of
complexity that have been used to characterize small models. To address this,
we propose a frequency-aware measure capturing finer-grained SB differences. We
validate this measure on CLIP models subjected to two recent SB-modulation
methods, demonstrating that it is more informative and consistent than previous
measures. Second, we examine the relation between the SB of those models and
their performance across a range of image classification tasks, including
zero-shot and fine-tuning settings. These experiments reveal a range of
behaviors. For example, a stronger SB correlates with a better performance on
OOD generalization than on adversarial robustness. These results highlight the
benefits of aligning a model's inductive biases with the characteristics of the
target task.

</details>


### [9] [GraphDerm: Fusing Imaging, Physical Scale, and Metadata in a Population-Graph Classifier for Dermoscopic Lesions](https://arxiv.org/abs/2509.12277)
*Mehdi Yousefzadeh,Parsa Esfahanian,Sara Rashidifar,Hossein Salahshoor Gavalan,Negar Sadat Rafiee Tabatabaee,Saeid Gorgin,Dara Rahmati,Maryam Daneshpazhooh*

Main category: cs.CV

TL;DR: GraphDerm是一个结合了图像、尺度校准和元数据的图神经网络框架，用于皮肤镜图像的多分类，在ISIC数据集上取得了优于纯图像AI的性能，并且稀疏图也能保持接近最优的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的皮肤镜AI模型通常忽略患者元数据（如年龄、性别、部位）和进行几何分析所需的物理尺度信息，而这些信息对提高诊断准确性至关重要。

Method: 1. 使用U-Net和SE-ResNet-18进行病灶和尺度的分割。
2. 通过轻量级1D-CNN回归像素与毫米的比例。
3. 计算真实尺度的病灶描述符（面积、周长、回转半径）。
4. 使用EfficientNet-B3作为节点特征，元数据和几何相似性作为边编码。
5. 采用图神经网络（GNN）进行半监督节点分类。

Result: 1. 尺子和病灶分割的Dice系数分别达到0.904和0.908。
2. 尺度回归的平均绝对误差（MAE）为1.5像素（RMSE为6.6）。
3. GraphDerm模型的AUC为0.9812，一个使用约25%边的稀疏图版本AUC为0.9788，显著优于仅基于图像的基线模型（AUC 0.9440）。
4. 各类别AUC通常在0.97-0.99范围内。

Conclusion: 将经过校准的尺度、病灶几何形状和元数据整合到图模型中，能够显著提升在ISIC-2019数据集上的性能，超越了仅使用图像的传统方法。稀疏图的性能也表明了该方法在实际部署中的潜力。这种尺感感知、基于图的方法是皮肤镜决策支持的一个有前景的方向。

Abstract: Introduction. Dermoscopy aids melanoma triage, yet image-only AI often
ignores patient metadata (age, sex, site) and the physical scale needed for
geometric analysis. We present GraphDerm, a population-graph framework that
fuses imaging, millimeter-scale calibration, and metadata for multiclass
dermoscopic classification, to the best of our knowledge the first ISIC-scale
application of GNNs to dermoscopy. Methods. We curate ISIC 2018/2019,
synthesize ruler-embedded images with exact masks, and train U-Nets
(SE-ResNet-18) for lesion and ruler segmentation. Pixels-per-millimeter are
regressed from the ruler-mask two-point correlation via a lightweight 1D-CNN.
From lesion masks we compute real-scale descriptors (area, perimeter, radius of
gyration). Node features use EfficientNet-B3; edges encode metadata/geometry
similarity (fully weighted or thresholded). A spectral GNN performs
semi-supervised node classification; an image-only ANN is the baseline.
Results. Ruler and lesion segmentation reach Dice 0.904 and 0.908; scale
regression attains MAE 1.5 px (RMSE 6.6). The graph attains AUC 0.9812, with a
thresholded variant using about 25% of edges preserving AUC 0.9788 (vs. 0.9440
for the image-only baseline); per-class AUCs typically fall in the 0.97-0.99
range. Conclusion. Unifying calibrated scale, lesion geometry, and metadata in
a population graph yields substantial gains over image-only pipelines on
ISIC-2019. Sparser graphs retain near-optimal accuracy, suggesting efficient
deployment. Scale-aware, graph-based AI is a promising direction for
dermoscopic decision support; future work will refine learned edge semantics
and evaluate on broader curated benchmarks.

</details>


### [10] [PATIMT-Bench: A Multi-Scenario Benchmark for Position-Aware Text Image Machine Translation in Large Vision-Language Models](https://arxiv.org/abs/2509.12278)
*Wanru Zhuang,Wenbo Li,Zhibin Lan,Xu Han,Peng Li,Jinsong Su*

Main category: cs.CV

TL;DR: 本论文提出了一种新的文本图像机器翻译（TIMT）任务，称为位置感知TIMT（PATIMT），旨在实现细粒度和保留布局的翻译，并构建了一个名为PATIMTBench的基准来支持该任务。


<details>
  <summary>Details</summary>
Motivation: 现有TIMT研究主要集中于翻译图像中的所有文本，忽略了边界框的提供，并且应用场景有限。本研究旨在解决这些问题，提出PATIMT，以支持更具实用价值的细粒度和保留布局的翻译。

Method: 构建了PATIMTBench基准，包含10个多样化的真实世界场景。引入了一个自适应图像OCR精炼流程，能够根据场景自适应选择合适的OCR工具并精炼文本丰富图像的识别结果。另外，构建了一个包含1200个高质量实例的测试集，并由人工审核。

Result: 在PATIMTBench上进行微调后，紧凑型大型视觉语言模型（LVLMs）在区域特定翻译和全图像翻译（带接地）两个子任务上均取得了最先进的性能。

Conclusion: 本研究提出的PATIMT任务和PATIMTBench基准为细粒度、保留布局的文本图像机器翻译提供了支持。实验结果表明，该基准能够有效提升LVLMs在相关任务上的性能，并且训练数据具有良好的可扩展性和泛化性。

Abstract: Text Image Machine Translation (TIMT) aims to translate texts embedded within
an image into another language. Current TIMT studies primarily focus on
providing translations for all the text within an image, while neglecting to
provide bounding boxes and covering limited scenarios. In this work, we extend
traditional TIMT into position-aware TIMT (PATIMT), aiming to support
fine-grained and layoutpreserving translation, which holds great practical
value but remains largely unexplored. This task comprises two key sub-tasks:
regionspecific translation and full-image translation with grounding. To
support existing models on PATIMT and conduct fair evaluation, we construct the
PATIMT benchmark (PATIMTBench), which consists of 10 diverse real-world
scenarios. Specifically, we introduce an Adaptive Image OCR Refinement
Pipeline, which adaptively selects appropriate OCR tools based on scenario and
refines the results of text-rich images. To ensure evaluation reliability, we
further construct a test set, which contains 1,200 high-quality instances
manually annotated and reviewed by human experts. After fine-tuning on our
data, compact Large Vision-Language Models (LVLMs) achieve state-of-the-art
performance on both sub-tasks. Experimental results also highlight the
scalability and generalizability of our training data

</details>


### [11] [Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance](https://arxiv.org/abs/2509.12279)
*He Gao,Baoxiang Huang,Milena Radenkovic,Borui Li,Ge Chen*

Main category: cs.CV

TL;DR: 提出SimMemDA框架，通过风格迁移、实例级特征相似性过滤、特征记忆库和区域混合训练，解决SAR和光学图像域转移问题，实现无监督域自适应的船只尾迹检测。


<details>
  <summary>Details</summary>
Motivation: 光学图像特征明显但易受天气影响，SAR图像具备全天候、大范围观测能力但尾迹特征抽象且带噪，直接应用光学模型于SAR图像存在域转移问题。因此，需要解决跨模态域自适应的船只尾迹检测挑战。

Method: 1. 使用WakeGAN进行风格迁移，生成接近SAR风格的光学图像。 2. 设计实例级特征相似性过滤机制，筛选与目标域分布相似的源域样本。 3. 引入特征-置信度记忆库和K近邻置信度加权融合策略，动态校准目标域伪标签。 4. 采用区域混合训练策略，结合源域标注和目标域伪标签，提升泛化能力。

Result: SimMemDA方法在跨模态船只尾迹检测任务中提高了准确性和鲁棒性。

Conclusion: 提出的SimMemDA方法在跨模态船只尾迹检测任务中是有效的且可行的。

Abstract: Synthetic Aperture Radar (SAR), with its all-weather and wide-area
observation capabilities, serves as a crucial tool for wake detection. However,
due to its complex imaging mechanism, wake features in SAR images often appear
abstract and noisy, posing challenges for accurate annotation. In contrast,
optical images provide more distinct visual cues, but models trained on optical
data suffer from performance degradation when applied to SAR images due to
domain shift. To address this cross-modal domain adaptation challenge, we
propose a Similarity-Guided and Memory-Guided Domain Adaptation (termed
SimMemDA) framework for unsupervised domain adaptive ship wake detection via
instance-level feature similarity filtering and feature memory guidance.
Specifically, to alleviate the visual discrepancy between optical and SAR
images, we first utilize WakeGAN to perform style transfer on optical images,
generating pseudo-images close to the SAR style. Then, instance-level feature
similarity filtering mechanism is designed to identify and prioritize source
samples with target-like distributions, minimizing negative transfer.
Meanwhile, a Feature-Confidence Memory Bank combined with a K-nearest neighbor
confidence-weighted fusion strategy is introduced to dynamically calibrate
pseudo-labels in the target domain, improving the reliability and stability of
pseudo-labels. Finally, the framework further enhances generalization through
region-mixed training, strategically combining source annotations with
calibrated target pseudo-labels. Experimental results demonstrate that the
proposed SimMemDA method can improve the accuracy and robustness of cross-modal
ship wake detection tasks, validating the effectiveness and feasibility of the
proposed method.

</details>


### [12] [GhostNetV3-Small: A Tailored Architecture and Comparative Study of Distillation Strategies for Tiny Images](https://arxiv.org/abs/2509.12380)
*Florian Zager,Hamza A. A. Gardi*

Main category: cs.CV

TL;DR: GhostNetV3-Small在CIFAR-10数据集上表现优于原始GhostNetV3，表明在小规模图像分类任务中，架构适应比知识蒸馏更有效。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度神经网络在资源受限的边缘设备上的部署挑战，探索了模型压缩和适配策略。

Method: 提出了GhostNetV3-Small，对GhostNetV3进行了修改，以更好地处理低分辨率输入（如CIFAR-10数据集）。对传统知识蒸馏、教师助手和教师集成等知识蒸馏技术进行了比较评估。

Result: GhostNetV3-Small在CIFAR-10上的准确率达到了93.94%，显著优于原始GhostNetV3。与预期相反，所有蒸馏策略都导致准确率下降。

Conclusion: 对于小规模图像分类任务，架构适应比知识蒸馏更具影响力。在低分辨率领域，需要对有效的模型设计和先进的蒸馏技术进行进一步研究。

Abstract: Deep neural networks have achieved remarkable success across a range of
tasks, however their computational demands often make them unsuitable for
deployment on resource-constrained edge devices. This paper explores strategies
for compressing and adapting models to enable efficient inference in such
environments. We focus on GhostNetV3, a state-of-the-art architecture for
mobile applications, and propose GhostNetV3-Small, a modified variant designed
to perform better on low-resolution inputs such as those in the CIFAR-10
dataset. In addition to architectural adaptation, we provide a comparative
evaluation of knowledge distillation techniques, including traditional
knowledge distillation, teacher assistants, and teacher ensembles. Experimental
results show that GhostNetV3-Small significantly outperforms the original
GhostNetV3 on CIFAR-10, achieving an accuracy of 93.94%. Contrary to
expectations, all examined distillation strategies led to reduced accuracy
compared to baseline training. These findings indicate that architectural
adaptation can be more impactful than distillation in small-scale image
classification tasks, highlighting the need for further research on effective
model design and advanced distillation techniques for low-resolution domains.

</details>


### [13] [Adaptive Sampling Scheduler](https://arxiv.org/abs/2509.12569)
*Qi Wang,Shuliang Zhu,Jinjia Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种自适应采样调度器，用于解决扩散模型一致性蒸馏中的目标时间步选择限制问题，通过动态时间步选择、优化交替采样和利用平滑裁剪与色彩平衡技术，提升了生成性能和模型在复杂场景下的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性蒸馏方法在目标时间步选择上存在局限性，主要依赖确定性或随机策略，这不仅需要为不同蒸馏过程定制采样调度器，还限制了扩散模型在实际应用中的全部采样潜力。

Method: 提出了一种自适应采样调度器，包含三个核心策略：1. 动态目标时间步选择：根据计算出的重要性动态选择时间步。 2. 优化交替采样：基于时间步重要性引导前向去噪和后向加噪，以更有效地探索解空间。 3. 利用平滑裁剪和色彩平衡：在高引导尺度下实现稳定、高质量的生成。

Result: 通过广泛的实验评估，验证了自适应采样调度器在多种一致性蒸馏方法上的有效性和灵活性。实验结果一致表明，所提出的方法显著提高了生成性能，展现了其强大的适应性。

Conclusion: 所提出的自适应采样调度器能够有效克服现有方法在目标时间步选择上的限制，通过动态时间步选择、优化采样策略以及增强高引导尺度下的生成稳定性，显著提升了扩散模型在各种一致性蒸馏框架下的生成性能和适用性。

Abstract: Consistent distillation methods have evolved into effective techniques that
significantly accelerate the sampling process of diffusion models. Although
existing methods have achieved remarkable results, the selection of target
timesteps during distillation mainly relies on deterministic or stochastic
strategies, which often require sampling schedulers to be designed specifically
for different distillation processes. Moreover, this pattern severely limits
flexibility, thereby restricting the full sampling potential of diffusion
models in practical applications. To overcome these limitations, this paper
proposes an adaptive sampling scheduler that is applicable to various
consistency distillation frameworks. The scheduler introduces three innovative
strategies: (i) dynamic target timestep selection, which adapts to different
consistency distillation frameworks by selecting timesteps based on their
computed importance; (ii) Optimized alternating sampling along the solution
trajectory by guiding forward denoising and backward noise addition based on
the proposed time step importance, enabling more effective exploration of the
solution space to enhance generation performance; and (iii) Utilization of
smoothing clipping and color balancing techniques to achieve stable and
high-quality generation results at high guidance scales, thereby expanding the
applicability of consistency distillation models in complex generation
scenarios. We validated the effectiveness and flexibility of the adaptive
sampling scheduler across various consistency distillation methods through
comprehensive experimental evaluations. Experimental results consistently
demonstrated significant improvements in generative performance, highlighting
the strong adaptability achieved by our method.

</details>


### [14] [DisorientLiDAR: Physical Attacks on LiDAR-based Localization](https://arxiv.org/abs/2509.12595)
*Yizhen Lao,Yu Zhang,Ziting Wang,Chengbo Wang,Yifei Xue,Wanpeng Shao*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DisorientLiDAR的新型对抗攻击框架，用于破坏基于激光雷达的自动驾驶汽车定位。该框架通过识别和移除关键点来扰乱定位模型，并在KITTI数据集和Autoware自动驾驶平台上的实验中验证了其有效性，甚至在物理世界中成功复现了攻击效果。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习模型容易受到对抗性攻击，但目前针对自动驾驶汽车激光雷达定位的攻击研究非常有限，而现有的大多数攻击都集中在3D感知领域。

Method: 通过逆向工程定位模型（例如特征提取网络），识别关键点并有策略地移除它们，以破坏激光雷达定位。

Result: 在KITTI数据集的三个最先进的点云配准模型（HRegNet、D3Feat和GeoTransformer）上进行了评估，结果表明移除包含Top-K关键点的区域会显著降低配准精度。在Autoware自动驾驶平台上的验证显示，隐藏少数关键区域会导致明显的定位漂移。通过使用近红外吸收材料在物理世界中隐藏关键区域，成功复现了攻击效果。

Conclusion: DisorientLiDAR框架能够有效且普遍地破坏基于激光雷达的定位，并已在模拟和物理世界中得到验证，为实现真实的物理世界攻击迈出了重要一步。

Abstract: Deep learning models have been shown to be susceptible to adversarial attacks
with visually imperceptible perturbations. Even this poses a serious security
challenge for the localization of self-driving cars, there has been very little
exploration of attack on it, as most of adversarial attacks have been applied
to 3D perception. In this work, we propose a novel adversarial attack framework
called DisorientLiDAR targeting LiDAR-based localization. By
reverse-engineering localization models (e.g., feature extraction networks),
adversaries can identify critical keypoints and strategically remove them,
thereby disrupting LiDAR-based localization. Our proposal is first evaluated on
three state-of-the-art point-cloud registration models (HRegNet, D3Feat, and
GeoTransformer) using the KITTI dataset. Experimental results demonstrate that
removing regions containing Top-K keypoints significantly degrades their
registration accuracy. We further validate the attack's impact on the Autoware
autonomous driving platform, where hiding merely a few critical regions induces
noticeable localization drift. Finally, we extended our attacks to the physical
world by hiding critical regions with near-infrared absorptive materials,
thereby successfully replicate the attack effects observed in KITTI data. This
step has been closer toward the realistic physical-world attack that
demonstrate the veracity and generality of our proposal.

</details>


### [15] [CIARD: Cyclic Iterative Adversarial Robustness Distillation](https://arxiv.org/abs/2509.12633)
*Liming Lu,Shuchao Pang,Xu Zheng,Xiang Gu,Anan Du,Yunhuai Liu,Yongbin Zhou*

Main category: cs.CV

TL;DR: CIARD方法通过多教师框架和持续对抗性再训练来提高学生模型的鲁棒性和泛化能力，解决了现有对抗鲁棒性蒸馏方法性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗鲁棒性蒸馏（ARD）方法在提高学生模型鲁棒性的同时，不可避免地导致其在干净样本上的性能下降。本文旨在解决这一问题。

Method: 提出了一种新颖的循环迭代AR D（CIARD）方法，包括：a.一个多教师框架，采用对比推损失对齐来解决双教师优化目标的冲突；b.持续的对抗性再训练，以维持动态教师鲁棒性，抵抗因变化的对抗样本而导致的性能下降。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的大量实验表明，CIARD在各种攻击场景下平均提高了3.53的对抗防御率，并提高了5.87的干净样本准确率，在模型鲁棒性和泛化能力之间取得了新的平衡。

Conclusion: CIARD方法成功地解决了现有ARD方法在提高鲁棒性的同时性能下降的问题，并在模型鲁棒性和泛化能力之间取得了优越的平衡。

Abstract: Adversarial robustness distillation (ARD) aims to transfer both performance
and robustness from teacher model to lightweight student model, enabling
resilient performance on resource-constrained scenarios. Though existing ARD
approaches enhance student model's robustness, the inevitable by-product leads
to the degraded performance on clean examples. We summarize the causes of this
problem inherent in existing methods with dual-teacher framework as: 1. The
divergent optimization objectives of dual-teacher models, i.e., the clean and
robust teachers, impede effective knowledge transfer to the student model, and
2. The iteratively generated adversarial examples during training lead to
performance deterioration of the robust teacher model. To address these
challenges, we propose a novel Cyclic Iterative ARD (CIARD) method with two key
innovations: a. A multi-teacher framework with contrastive push-loss alignment
to resolve conflicts in dual-teacher optimization objectives, and b. Continuous
adversarial retraining to maintain dynamic teacher robustness against
performance degradation from the varying adversarial examples. Extensive
experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that CIARD
achieves remarkable performance with an average 3.53 improvement in adversarial
defense rates across various attack scenarios and a 5.87 increase in clean
sample accuracy, establishing a new benchmark for balancing model robustness
and generalization. Our code is available at https://github.com/eminentgu/CIARD

</details>


### [16] [Beyond Artificial Misalignment: Detecting and Grounding Semantic-Coordinated Multimodal Manipulations](https://arxiv.org/abs/2509.12653)
*Jinjie Shen,Yaxiong Wang,Lechao Cheng,Nan Pu,Zhun Zhong*

Main category: cs.CV

TL;DR: 该论文提出了一种新的多模态操纵内容检测和定位方法，通过构建语义对齐的多模态操纵（SAMM）数据集和提出检索增强操纵检测和定位（RamDG）框架来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在多模态数据操纵检测方面存在局限性，它们生成的伪造数据与现实世界中的操纵模式不符，因为现实世界的操纵通常会保持跨模态的语义一致性，而现有数据集则会人为地破坏这种跨模态对齐，从而产生容易检测到的异常。

Method: 1. 构建了首个语义对齐的多模态操纵（SAMM）数据集，该数据集是通过一个两阶段流程生成的：首先应用最先进的图像操纵技术，然后生成在上下文上合理的文本叙述，以加强视觉欺骗。 2. 提出了一个检索增强操纵检测和定位（RamDG）框架，该框架首先利用外部知识存储库检索上下文证据，然后将这些证据（作为辅助文本）与输入一起通过图像伪造定位和深度操纵检测模块进行编码，以追踪所有操纵。

Result: 所提出的RamDG框架在SAMM数据集上取得了显著的成果，其检测准确率比现有最先进的方法高出2.06%。

Conclusion: 该研究通过引入SAMM数据集和RamDG框架，有效解决了多模态内容操纵检测中的语义对齐问题，并显著提高了检测性能。

Abstract: The detection and grounding of manipulated content in multimodal data has
emerged as a critical challenge in media forensics. While existing benchmarks
demonstrate technical progress, they suffer from misalignment artifacts that
poorly reflect real-world manipulation patterns: practical attacks typically
maintain semantic consistency across modalities, whereas current datasets
artificially disrupt cross-modal alignment, creating easily detectable
anomalies. To bridge this gap, we pioneer the detection of
semantically-coordinated manipulations where visual edits are systematically
paired with semantically consistent textual descriptions. Our approach begins
with constructing the first Semantic-Aligned Multimodal Manipulation (SAMM)
dataset, generated through a two-stage pipeline: 1) applying state-of-the-art
image manipulations, followed by 2) generation of contextually-plausible
textual narratives that reinforce the visual deception. Building on this
foundation, we propose a Retrieval-Augmented Manipulation Detection and
Grounding (RamDG) framework. RamDG commences by harnessing external knowledge
repositories to retrieve contextual evidence, which serves as the auxiliary
texts and encoded together with the inputs through our image forgery grounding
and deep manipulation detection modules to trace all manipulations. Extensive
experiments demonstrate our framework significantly outperforms existing
methods, achieving 2.06\% higher detection accuracy on SAMM compared to
state-of-the-art approaches. The dataset and code are publicly available at
https://github.com/shen8424/SAMM-RamDG-CAP.

</details>


### [17] [MFAF: An EVA02-Based Multi-scale Frequency Attention Fusion Method for Cross-View Geo-Localization](https://arxiv.org/abs/2509.12673)
*YiTong Liu,TianZhu Liu,YanFeng GU*

Main category: cs.CV

TL;DR: EVA02-based Multi-scale Frequency Attention Fusion (MFAF) method addresses cross-view geo-localization challenges by effectively capturing low-frequency structural features and high-frequency edge details while adaptively focusing on key frequency features, achieving competitive performance on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing cross-view geo-localization approaches struggle with appearance variations and feature extraction difficulties, often neglecting spatial and semantic information by relying on feature map segmentation.

Method: The proposed MFAF method utilizes an EVA02 backbone and comprises two key components: the Multi-Frequency Branch-wise Block (MFB) to capture multi-scale structural and detailed features for improved representation consistency and robustness, and the Frequency-aware Spatial Attention (FSA) module to adaptively focus on important frequency features, reducing noise and viewpoint variability interference.

Result: Extensive experiments on University-1652, SUES-200, and Dense-UAV benchmarks show that the MFAF method achieves competitive performance in both drone localization and drone navigation tasks.

Conclusion: The MFAF method, with its MFB and FSA modules, effectively enhances feature representation for cross-view geo-localization by addressing appearance variations and feature extraction challenges, demonstrating superior performance on standard benchmarks.

Abstract: Cross-view geo-localization aims to determine the geographical location of a
query image by matching it against a gallery of images. This task is
challenging due to the significant appearance variations of objects observed
from variable views, along with the difficulty in extracting discriminative
features. Existing approaches often rely on extracting features through feature
map segmentation while neglecting spatial and semantic information. To address
these issues, we propose the EVA02-based Multi-scale Frequency Attention Fusion
(MFAF) method. The MFAF method consists of Multi-Frequency Branch-wise Block
(MFB) and the Frequency-aware Spatial Attention (FSA) module. The MFB block
effectively captures both low-frequency structural features and high-frequency
edge details across multiple scales, improving the consistency and robustness
of feature representations across various viewpoints. Meanwhile, the FSA module
adaptively focuses on the key regions of frequency features, significantly
mitigating the interference caused by background noise and viewpoint
variability. Extensive experiments on widely recognized benchmarks, including
University-1652, SUES-200, and Dense-UAV, demonstrate that the MFAF method
achieves competitive performance in both drone localization and drone
navigation tasks.

</details>


### [18] [A Comparative Study of YOLOv8 to YOLOv11 Performance in Underwater Vision Tasks](https://arxiv.org/abs/2509.12682)
*Gordon Hung,Ivan Felipe Rodriguez*

Main category: cs.CV

TL;DR: YOLOv10在水下计算机视觉任务中提供了最佳的速度-准确性权衡，适用于自主水下航行器（AUV）。


<details>
  <summary>Details</summary>
Motivation: 由于光线衰减、浑浊和类别不平衡等问题，水下图像处理面临挑战，并且AUV上的计算资源有限。现有的YOLO模型在水下领域的性能尚不明确。

Method: 在两个水下数据集（珊瑚病和鱼类物种）上，以25%、50%、75%和100%的图像比例训练了YOLOv8-s、YOLOv9-s、YOLOv10-s和YOLOv11-s模型。使用相同的超参数进行训练，并评估了精度、召回率、mAP50、mAP50-95、每张图像的推理时间和FPS。通过Grad-CAM可视化分析特征利用和定位保真度。

Result: 在两个数据集上，YOLOv9之后的模型在准确性方面饱和，表明其架构创新主要侧重于效率而非准确性。然而，推理速度显著提高。YOLOv10在速度-准确性方面表现最佳。

Conclusion: 本研究首次对近期YOLO模型在水下图像上的性能进行了受控比较，表明YOLOv10是嵌入式AUV部署的理想选择，并提供了一个开放、可复现的基准和代码库，以加速未来的水下视觉研究。

Abstract: Autonomous underwater vehicles (AUVs) increasingly rely on on-board
computer-vision systems for tasks such as habitat mapping, ecological
monitoring, and infrastructure inspection. However, underwater imagery is
hindered by light attenuation, turbidity, and severe class imbalance, while the
computational resources available on AUVs are limited. One-stage detectors from
the YOLO family are attractive because they fuse localization and
classification in a single, low-latency network; however, their terrestrial
benchmarks (COCO, PASCAL-VOC, Open Images) leave open the question of how
successive YOLO releases perform in the marine domain. We curate two openly
available datasets that span contrasting operating conditions: a Coral Disease
set (4,480 images, 18 classes) and a Fish Species set (7,500 images, 20
classes). For each dataset, we create four training regimes (25 %, 50 %, 75 %,
100 % of the images) while keeping balanced validation and test partitions
fixed. We train YOLOv8-s, YOLOv9-s, YOLOv10-s, and YOLOv11-s with identical
hyperparameters (100 epochs, 640 px input, batch = 16, T4 GPU) and evaluate
precision, recall, mAP50, mAP50-95, per-image inference time, and
frames-per-second (FPS). Post-hoc Grad-CAM visualizations probe feature
utilization and localization faithfulness. Across both datasets, accuracy
saturates after YOLOv9, suggesting architectural innovations primarily target
efficiency rather than accuracy. Inference speed, however, improves markedly.
Our results (i) provide the first controlled comparison of recent YOLO variants
on underwater imagery, (ii) show that lightweight YOLOv10 offers the best
speed-accuracy trade-off for embedded AUV deployment, and (iii) deliver an
open, reproducible benchmark and codebase to accelerate future marine-vision
research.

</details>


### [19] [Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models](https://arxiv.org/abs/2509.12724)
*Yunhan Zhao,Xiang Zheng,Xingjun Ma*

Main category: cs.CV

TL;DR: Defense2Attack利用防御模式来增强越狱视觉语言模型（VLM）的有效性和效率，通过视觉和文本优化以及红队后缀生成来实现。


<details>
  <summary>Details</summary>
Motivation: 尽管VLM能力超群，但它们容易受到越狱攻击。现有越狱方法的有效性和效率有待提高。

Method: Defense2Attack包含三个组成部分：(1) 视觉优化器，嵌入具有肯定和鼓励语义的通用对抗性扰动；(2) 文本优化器，使用防御风格的提示来优化输入；(3) 红队后缀生成器，通过强化微调来增强越狱。

Result: 在四个VLM和四个安全基准上的实证评估表明，Defense2Attack在单次尝试中实现了卓越的越狱性能，优于通常需要多次尝试的最新攻击方法。

Conclusion: 该研究为越狱VLM提供了新的视角，揭示了将弱防御融入攻击流程可显著增强越狱的有效性和效率。

Abstract: Despite their superb capabilities, Vision-Language Models (VLMs) have been
shown to be vulnerable to jailbreak attacks. While recent jailbreaks have
achieved notable progress, their effectiveness and efficiency can still be
improved. In this work, we reveal an interesting phenomenon: incorporating weak
defense into the attack pipeline can significantly enhance both the
effectiveness and the efficiency of jailbreaks on VLMs. Building on this
insight, we propose Defense2Attack, a novel jailbreak method that bypasses the
safety guardrails of VLMs by leveraging defensive patterns to guide jailbreak
prompt design. Specifically, Defense2Attack consists of three key components:
(1) a visual optimizer that embeds universal adversarial perturbations with
affirmative and encouraging semantics; (2) a textual optimizer that refines the
input using a defense-styled prompt; and (3) a red-team suffix generator that
enhances the jailbreak through reinforcement fine-tuning. We empirically
evaluate our method on four VLMs and four safety benchmarks. The results
demonstrate that Defense2Attack achieves superior jailbreak performance in a
single attempt, outperforming state-of-the-art attack methods that often
require multiple tries. Our work offers a new perspective on jailbreaking VLMs.

</details>


### [20] [CECT-Mamba: a Hierarchical Contrast-enhanced-aware Model for Pancreatic Tumor Subtyping from Multi-phase CECT](https://arxiv.org/abs/2509.12777)
*Zhifang Gong,Shuo Gao,Ben Zhao,Yingjing Xu,Yijun Yang,Shenghong Ju,Guangquan Zhou*

Main category: cs.CV

TL;DR: 本研究提出了一种结合多期增强CT（CECT）数据的方法，利用Mamba模型自动区分胰腺肿瘤亚型，以克服肿瘤异质性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 胰腺肿瘤的高异质性和变异性给精确分型诊断带来了重大挑战，而以往的方法未能有效利用多期CECT数据中的上下文信息。

Method: 提出了一种结合多期CECT数据、利用Mamba模型进行自动分型的研究。具体包括：1. 双分层增强感知Mamba模块，包含新的空间和时间采样序列，以探索病变在各期CECT中的对比度变化。2. 引入相似性引导细化模块，以强调对具有明显时间变化的局部肿瘤区域的学习。3. 设计空间互补积分器和多粒度融合模块，以编码和聚合不同尺度的语义信息。

Result: 在270个临床病例的内部数据集中，区分胰腺导管腺癌（PDAC）和胰腺神经内分泌肿瘤（PNETs）的准确率达到97.4%，AUC达到98.6%。

Conclusion: 所提出的方法在区分胰腺肿瘤亚型方面展现了更高的准确性和效率潜力。

Abstract: Contrast-enhanced computed tomography (CECT) is the primary imaging technique
that provides valuable spatial-temporal information about lesions, enabling the
accurate diagnosis and subclassification of pancreatic tumors. However, the
high heterogeneity and variability of pancreatic tumors still pose substantial
challenges for precise subtyping diagnosis. Previous methods fail to
effectively explore the contextual information across multiple CECT phases
commonly used in radiologists' diagnostic workflows, thereby limiting their
performance. In this paper, we introduce, for the first time, an automatic way
to combine the multi-phase CECT data to discriminate between pancreatic tumor
subtypes, among which the key is using Mamba with promising learnability and
simplicity to encourage both temporal and spatial modeling from multi-phase
CECT. Specifically, we propose a dual hierarchical contrast-enhanced-aware
Mamba module incorporating two novel spatial and temporal sampling sequences to
explore intra and inter-phase contrast variations of lesions. A
similarity-guided refinement module is also imposed into the temporal scanning
modeling to emphasize the learning on local tumor regions with more obvious
temporal variations. Moreover, we design the space complementary integrator and
multi-granularity fusion module to encode and aggregate the semantics across
different scales, achieving more efficient learning for subtyping pancreatic
tumors. The experimental results on an in-house dataset of 270 clinical cases
achieve an accuracy of 97.4% and an AUC of 98.6% in distinguishing between
pancreatic ductal adenocarcinoma (PDAC) and pancreatic neuroendocrine tumors
(PNETs), demonstrating its potential as a more accurate and efficient tool.

</details>


### [21] [Data Scaling Laws for Radiology Foundation Models](https://arxiv.org/abs/2509.12818)
*Maximilian Ilse,Harshita Sharma,Anton Schwaighofer,Sam Bond-Taylor,Fernando Pérez-García,Olesya Melnichenko,Anne-Marie G. Sykes,Kelly K. Horst,Ashish Khandelwal,Maxwell Reynolds,Maria T. Wetscherek,Noel C. F. Codella,Javier Alvarez-Valle,Korfiatis Panagiotis,Valentina Salvatelli*

Main category: cs.CV

TL;DR: 本文研究了在医学影像领域，使用大规模数据集持续预训练两种主流视觉编码器（MI2 和 RAD-DINO），并评估它们在不同任务上的表现。结果表明，MI2 在与影像解读相关的任务上表现更好，而 RAD-DINO 在处理管状结构的任务上更优。此外，使用 UniCL 结合报告和结构化标签进行持续预训练能提升 MI2 的性能。令人惊讶的是，即使只有 3 万个特定领域的数据，也足以超越现有的开放权重基础模型，这凸显了中心特定持续预训练的价值。


<details>
  <summary>Details</summary>
Motivation: 医学影像基础模型受限于数据集规模，影响了对数据规模和预训练范式影响的理解。本文旨在系统研究持续预训练对医学影像基础模型性能的影响。

Method: 本文系统地研究了两种主流视觉编码器（MI2 和 RAD-DINO）在高达 350 万张胸部 X 光片上的持续预训练效果，并保持计算量和评估协议不变。在分类（放射影像学发现、导管和管线）、分割（导管和管线）以及放射影像学报告生成任务上进行了评估。

Result: MI2 在影像解读相关任务上扩展性更佳，RAD-DINO 在管线相关任务上表现更强。使用 UniCL 结合报告和结构化标签持续预训练 MI2 能提升性能。对于某些任务，仅需 3 万个领域内样本即可超越开放权重基础模型。

Conclusion: 中心特定的持续预训练具有重要价值，医学机构可以通过利用领域内数据显著提升模型性能。

Abstract: Foundation vision encoders such as CLIP and DINOv2, trained on web-scale
data, exhibit strong transfer performance across tasks and datasets. However,
medical imaging foundation models remain constrained by smaller datasets,
limiting our understanding of how data scale and pretraining paradigms affect
performance in this setting. In this work, we systematically study continual
pretraining of two vision encoders, MedImageInsight (MI2) and RAD-DINO
representing the two major encoder paradigms CLIP and DINOv2, on up to 3.5M
chest x-rays from a single institution, holding compute and evaluation
protocols constant. We evaluate on classification (radiology findings, lines
and tubes), segmentation (lines and tubes), and radiology report generation.
While prior work has primarily focused on tasks related to radiology findings,
we include lines and tubes tasks to counterbalance this bias and evaluate a
model's ability to extract features that preserve continuity along elongated
structures. Our experiments show that MI2 scales more effectively for
finding-related tasks, while RAD-DINO is stronger on tube-related tasks.
Surprisingly, continually pretraining MI2 with both reports and structured
labels using UniCL improves performance, underscoring the value of structured
supervision at scale. We further show that for some tasks, as few as 30k
in-domain samples are sufficient to surpass open-weights foundation models.
These results highlight the utility of center-specific continual pretraining,
enabling medical institutions to derive significant performance gains by
utilizing in-domain data.

</details>


### [22] [Runge-Kutta Approximation and Decoupled Attention for Rectified Flow Inversion and Semantic Editing](https://arxiv.org/abs/2509.12888)
*Weiming Chen,Zhihan Zhu,Yijia Wang,Zhihai He*

Main category: cs.CV

TL;DR: Rectified flow (RF) 模型在生成任务上表现优于 DDIM 模型，但存在反演精度低和注意力机制纠缠的问题。本文提出了一种基于 Runge-Kutta 求解器的八阶反演方法和一种解耦的扩散 Transformer 注意力（DDTA）机制，以解决上述挑战。实验证明该方法在图像重建和文本引导编辑任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决 Rectified Flow (RF) 模型在实际应用中面临的低反演精度和多模态注意力纠缠的问题。

Method: 提出了一种基于 Runge-Kutta 求解器的八阶反演方法，用于提高 RF 模型的反演精度；引入了解耦的扩散 Transformer 注意力（DDTA）机制，以分离文本和图像注意力，实现更精确的语义控制。

Result: 在图像重建和文本引导编辑任务上，提出的方法在保真度和可编辑性方面取得了最先进的性能。

Conclusion: 所提出的高效八阶反演方法和 DDTA 机制能够有效解决 RF 模型在实际应用中的挑战，并在图像生成和编辑任务中展现出优越的性能。

Abstract: Rectified flow (RF) models have recently demonstrated superior generative
performance compared to DDIM-based diffusion models. However, in real-world
applications, they suffer from two major challenges: (1) low inversion accuracy
that hinders the consistency with the source image, and (2) entangled
multimodal attention in diffusion transformers, which hinders precise attention
control. To address the first challenge, we propose an efficient high-order
inversion method for rectified flow models based on the Runge-Kutta solver of
differential equations. To tackle the second challenge, we introduce Decoupled
Diffusion Transformer Attention (DDTA), a novel mechanism that disentangles
text and image attention inside the multimodal diffusion transformers, enabling
more precise semantic control. Extensive experiments on image reconstruction
and text-guided editing tasks demonstrate that our method achieves
state-of-the-art performance in terms of fidelity and editability. Code is
available at https://github.com/wmchen/RKSovler_DDTA.

</details>


### [23] [Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models](https://arxiv.org/abs/2509.12897)
*Jianfei Zhao,Feng Zhang,Xin Sun,Lingxing Kong,Zhixing Tan,Chong Feng*

Main category: cs.CV

TL;DR: CLVS通过引入视觉记忆来平滑跨层注意力，以增强大型视觉语言模型（LVLM）的视觉能力，并在关系和属性理解方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）虽然能精确定位图像中的关键对象，但往往对这些对象的关注时间很短。本研究的动机是，假设对关键对象的持续关注可以提高LVLM的视觉能力。

Method: 提出了一种名为跨层视觉平滑（CLVS）的方法，该方法通过引入一个视觉记忆来平滑跨层注意力分布。该视觉记忆在第一层使用位置无偏的视觉注意力进行初始化，并在后续层中，模型的视觉注意力会联合考虑来自先前层的视觉记忆，同时记忆会进行迭代更新，从而在关键对象上保持平滑的注意力。为了确定视觉理解的完成，该方法使用不确定性作为指标来终止平滑过程。

Result: 在四个基准测试和三个LVLM上的实验证实了CLVS的有效性和泛化能力，在多种视觉理解任务上取得了最先进的性能，尤其在关系和属性理解方面有显著提升。

Conclusion: CLVS通过引入跨层视觉记忆平滑注意力，有效提升了LVLM在视觉理解任务上的表现，特别是在关系和属性理解方面。

Abstract: Large Vision-Language Models (LVLMs) can accurately locate key objects in
images, yet their attention to these objects tends to be very brief. Motivated
by the hypothesis that sustained focus on key objects can improve LVLMs' visual
capabilities, we propose Cross-Layer Vision Smoothing (CLVS). The core idea of
CLVS is to incorporate a vision memory that smooths the attention distribution
across layers. Specifically, we initialize this vision memory with
position-unbiased visual attention in the first layer. In subsequent layers,
the model's visual attention jointly considers the vision memory from previous
layers, while the memory is updated iteratively, thereby maintaining smooth
attention on key objects. Given that visual understanding primarily occurs in
the early and middle layers of the model, we use uncertainty as an indicator of
completed visual understanding and terminate the smoothing process accordingly.
Experiments on four benchmarks across three LVLMs confirm the effectiveness and
generalizability of our method. CLVS achieves state-of-the-art performance on a
variety of visual understanding tasks, with particularly significant
improvements in relation and attribute understanding.

</details>


### [24] [Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection](https://arxiv.org/abs/2509.12990)
*Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为双阶段重加权混合专家（DR-MoE）的框架，用于从第一人称视角视频数据中检测用户的不正确行为，特别关注识别细微和罕见的错误。


<details>
  <summary>Details</summary>
Motivation: 解决从第一人称视角视频数据中识别用户不正确行为的挑战，特别是细微和罕见的错误。

Method: DR-MoE框架包含两个阶段：第一阶段使用冻结和LoRA微调的ViViT模型提取特征，并通过特征级专家模块融合；第二阶段结合了重加权交叉熵、AUC损失和标签感知损失（结合 sharpness-aware minimization）的三个分类器，并通过分类级专家模块融合其预测。

Result: 该方法在识别罕见和模糊的错误实例方面表现出强大的性能。

Conclusion: DR-MoE框架能够有效检测用户的不正确行为，并在识别稀有和模糊的错误方面表现出色。

Abstract: In this report, we address the problem of determining whether a user performs
an action incorrectly from egocentric video data. To handle the challenges
posed by subtle and infrequent mistakes, we propose a Dual-Stage Reweighted
Mixture-of-Experts (DR-MoE) framework. In the first stage, features are
extracted using a frozen ViViT model and a LoRA-tuned ViViT model, which are
combined through a feature-level expert module. In the second stage, three
classifiers are trained with different objectives: reweighted cross-entropy to
mitigate class imbalance, AUC loss to improve ranking under skewed
distributions, and label-aware loss with sharpness-aware minimization to
enhance calibration and generalization. Their predictions are fused using a
classification-level expert module. The proposed method achieves strong
performance, particularly in identifying rare and ambiguous mistake instances.
The code is available at https://github.com/boyuh/DR-MoE.

</details>


### [25] [Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models](https://arxiv.org/abs/2509.13031)
*Yan Chen,Long Li,Teng Xi,Long Zeng,Jingdong Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种两阶段强化学习框架，用于同时提升视觉语言模型（VLM）的感知和推理能力，解决了直接将强化学习应用于VLM的不足。


<details>
  <summary>Details</summary>
Motivation: 由于视觉语言模型（VLM）需要先理解视觉输入再进行推理，直接将强化学习（RL）应用于VLM存在不足，因此需要新的方法来提升其推理性能。

Method: 提出一个两阶段强化学习框架，第一阶段通过粗粒度和细粒度视觉理解来提升视觉感知能力，第二阶段则针对性地提升推理能力。在此过程中，通过数据集层面的采样来解决强化学习训练中常见的优势递减问题。

Result: 提出的框架使模型PeBR-R1在七个基准数据集上展现出显著提升的感知和推理能力，并在各种视觉推理任务上表现出优越的性能。

Conclusion: 该两阶段强化学习框架能够有效提升VLM的感知和推理能力，PeBR-R1模型在视觉推理任务上取得了优越的性能。

Abstract: Reinforcement learning (RL) has proven highly effective in eliciting the
reasoning capabilities of large language models (LLMs). Inspired by this
success, recent studies have explored applying similar techniques to
vision-language models (VLMs), aiming to enhance their reasoning performance.
However, directly transplanting RL methods from LLMs to VLMs is suboptimal, as
the tasks faced by VLMs are inherently more complex. Specifically, VLMs must
first accurately perceive and understand visual inputs before reasoning can be
effectively performed. To address this challenge, we propose a two-stage
reinforcement learning framework designed to jointly enhance both the
perceptual and reasoning capabilities of VLMs. To mitigate the vanishing
advantage issue commonly observed in RL training, we first perform
dataset-level sampling to selectively strengthen specific capabilities using
distinct data sources. During training, the first stage focuses on improving
the model's visual perception through coarse- and fine-grained visual
understanding, while the second stage targets the enhancement of reasoning
abilities. After the proposed two-stage reinforcement learning process, we
obtain PeBR-R1, a vision-language model with significantly enhanced perceptual
and reasoning capabilities. Experimental results on seven benchmark datasets
demonstrate the effectiveness of our approach and validate the superior
performance of PeBR-R1 across diverse visual reasoning tasks.

</details>


### [26] [TFANet: Three-Stage Image-Text Feature Alignment Network for Robust Referring Image Segmentation](https://arxiv.org/abs/2509.13070)
*Qianqi Lu,Yuxiang Xie,Jing Zhang,Shiwei Zou,Yan Chen,Xidao Luan*

Main category: cs.CV

TL;DR: TFANet通过三阶段的图像-文本特征对齐网络（KPS、KFS、KIS）来解决Referring Image Segmentation（RIS）中的多模态失配和语义丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有Referring Image Segmentation（RIS）方法在处理包含多个视觉相似对象、需要精细对齐的复杂场景时，常面临多模态失配和语言语义丢失的问题，导致目标定位不准或分割不完整。

Method: TFANet包含三个阶段：1. 知识增强阶段（KPS）：使用多尺度线性交叉注意力模块（MLAM）促进图像区域和不同粒度的语言描述之间的双向语义交换。2. 知识融合阶段（KFS）：使用跨模态特征扫描模块（CFSM）捕捉长距离依赖关系，构建统一的多模态表示，增强对齐精度。3. 知识强化阶段（KIS）：使用单词级语言特征引导的语义深化模块（WFDM）补偿早期阶段引入的语义退化。

Result: TFANet通过多尺度交叉注意力、跨模态特征扫描和单词级特征引导的语义深化，提高了在复杂场景下Referring Image Segmentation的精度和鲁棒性。

Conclusion: TFANet提出的三阶段特征对齐网络能够有效解决RIS中的多模态失配和语义丢失问题，尤其在复杂场景下表现优异。

Abstract: Referring Image Segmentation (RIS) is a task that segments image regions
based on language expressions, requiring fine-grained alignment between two
modalities. However, existing methods often struggle with multimodal
misalignment and language semantic loss, especially in complex scenes
containing multiple visually similar objects, where uniquely described targets
are frequently mislocalized or incompletely segmented. To tackle these
challenges, this paper proposes TFANet, a Three-stage Image-Text Feature
Alignment Network that systematically enhances multimodal alignment through a
hierarchical framework comprising three stages: Knowledge Plus Stage (KPS),
Knowledge Fusion Stage (KFS), and Knowledge Intensification Stage (KIS). In the
first stage, we design the Multiscale Linear Cross-Attention Module (MLAM),
which facilitates bidirectional semantic exchange between visual features and
textual representations across multiple scales. This establishes rich and
efficient alignment between image regions and different granularities of
linguistic descriptions. Subsequently, the KFS further strengthens feature
alignment through the Cross-modal Feature Scanning Module (CFSM), which applies
multimodal selective scanning to capture long-range dependencies and construct
a unified multimodal representation. This is essential for modeling long-range
cross-modal dependencies and enhancing alignment accuracy in complex scenes.
Finally, in the KIS, we propose the Word-level Linguistic Feature-guided
Semantic Deepening Module (WFDM) to compensate for semantic degradation
introduced in earlier stages.

</details>


### [27] [Hierarchical Deep Fusion Framework for Multi-dimensional Facial Forgery Detection -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2509.13107)
*Kohou Wang,Huan Hu,Xiang Liu,Zezhou Chen,Ping Chen,Zhaoxiang Liu,Shiguo Lian*

Main category: cs.CV

TL;DR: HDFF是一个用于人脸伪造检测的集成深度学习框架，通过融合Swin-MLP、CoAtNet、EfficientNetV2和DaViT四个预训练模型，在MultiFFDI数据集上进行了多阶段微调，最终在比赛私有排行榜上获得0.96852的得分，排名第20位。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的扩散对数字安全和真实性提出了严峻挑战，需要开发能够检测各种操纵技术且具有鲁棒性和泛化能力的模型。

Method: 提出了一种名为HDFF（Hierarchical Deep Fusion Framework）的集成深度学习架构，该架构整合了四个不同的预训练子模型（Swin-MLP、CoAtNet、EfficientNetV2和DaViT），并通过多阶段流程在MultiFFDI数据集上进行微调。通过连接这些专业模型的特征表示并训练最终的分类层来利用它们的集体优势。

Result: HDFF在MultiFFDI数据集上进行了训练和评估，在比赛的私有排行榜上取得了0.96852的最终得分，在184支队伍中排名第20位。

Conclusion: HDFF框架的有效性得到了证明，表明分层融合方法在复杂图像分类任务（如人脸伪造检测）中表现出色。

Abstract: The proliferation of sophisticated deepfake technology poses significant
challenges to digital security and authenticity. Detecting these forgeries,
especially across a wide spectrum of manipulation techniques, requires robust
and generalized models. This paper introduces the Hierarchical Deep Fusion
Framework (HDFF), an ensemble-based deep learning architecture designed for
high-performance facial forgery detection. Our framework integrates four
diverse pre-trained sub-models, Swin-MLP, CoAtNet, EfficientNetV2, and DaViT,
which are meticulously fine-tuned through a multi-stage process on the
MultiFFDI dataset. By concatenating the feature representations from these
specialized models and training a final classifier layer, HDFF effectively
leverages their collective strengths. This approach achieved a final score of
0.96852 on the competition's private leaderboard, securing the 20th position
out of 184 teams, demonstrating the efficacy of hierarchical fusion for complex
image classification tasks.

</details>


### [28] [Curriculum Multi-Task Self-Supervision Improves Lightweight Architectures for Onboard Satellite Hyperspectral Image Segmentation](https://arxiv.org/abs/2509.13229)
*Hugo Carlesso,Josiane Mothe,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: CMTSSL是一种用于高光谱图像分析的新型课程多任务自监督学习框架，可实现轻量级模型在卫星上的高效处理。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像(HSI)数据维度高，卫星传输速率慢，需要紧凑高效的模型来支持机载处理并减少冗余或低价值数据的传输。

Method: CMTSSL框架集成了掩码图像建模和解耦的空间与光谱拼图游戏，并采用课程学习策略，通过逐步增加数据复杂性来进行自监督学习。

Result: 在四个公开基准数据集上进行了验证，在下游分割任务中取得了显著的性能提升，使用的模型比一些最先进的模型轻16000倍以上。

Conclusion: CMTSSL在轻量级架构中具有可推广的表示学习潜力，适用于现实世界的高光谱图像应用。

Abstract: Hyperspectral imaging (HSI) captures detailed spectral signatures across
hundreds of contiguous bands per pixel, being indispensable for remote sensing
applications such as land-cover classification, change detection, and
environmental monitoring. Due to the high dimensionality of HSI data and the
slow rate of data transfer in satellite-based systems, compact and efficient
models are required to support onboard processing and minimize the transmission
of redundant or low-value data, e.g. cloud-covered areas. To this end, we
introduce a novel curriculum multi-task self-supervised learning (CMTSSL)
framework designed for lightweight architectures for HSI analysis. CMTSSL
integrates masked image modeling with decoupled spatial and spectral jigsaw
puzzle solving, guided by a curriculum learning strategy that progressively
increases data complexity during self-supervision. This enables the encoder to
jointly capture fine-grained spectral continuity, spatial structure, and global
semantic features. Unlike prior dual-task SSL methods, CMTSSL simultaneously
addresses spatial and spectral reasoning within a unified and computationally
efficient design, being particularly suitable for training lightweight models
for onboard satellite deployment. We validate our approach on four public
benchmark datasets, demonstrating consistent gains in downstream segmentation
tasks, using architectures that are over 16,000x lighter than some
state-of-the-art models. These results highlight the potential of CMTSSL in
generalizable representation learning with lightweight architectures for
real-world HSI applications. Our code is publicly available at
https://github.com/hugocarlesso/CMTSSL.

</details>


### [29] [ResidualViT for Efficient Temporally Dense Video Encoding](https://arxiv.org/abs/2509.13255)
*Mattia Soldan,Fabian Caba Heilbron,Bernard Ghanem,Josef Sivic,Bryan Russell*

Main category: cs.CV

TL;DR: 提出ResidualViT，一种能高效计算密集时间帧级特征的ViT架构，通过残差连接保证时间一致性，并通过令牌缩减模块提高处理速度。同时提出一种轻量级蒸馏策略来近似原始模型的帧级特征。该方法在四个任务和五个数据集上进行了评估，在不显著影响精度的前提下，显著降低了计算成本（高达60%）并提高了推理速度（高达2.5倍）。


<details>
  <summary>Details</summary>
Motivation: 自然语言时间视频接地、时间活动定位和音频描述生成等视频理解任务需要对高时间分辨率采样的帧进行密集的时间推理，但计算帧级特征的成本高昂。

Method: 提出一种名为ResidualViT的视觉Transformer（ViT）架构，该架构利用视频中的大量时间冗余来高效计算密集的时间帧级特征。该架构包含（i）保证连续帧之间时间一致性的可学习残差连接，以及（ii）通过选择性地丢弃时间冗余信息同时重用预训练基础模型的权重来提高处理速度的令牌缩减模块。此外，还提出了一种轻量级蒸馏策略来近似原始基础模型的帧级特征。

Result: 在四个任务和五个数据集上，在零样本和完全监督设置下，该方法均实现了显著的计算成本降低（高达60%）和推理速度提升（高达2.5倍），同时精度与原始基础模型非常接近。

Conclusion: ResidualViT通过利用时间冗余和引入高效的架构设计（残差连接和令牌缩减模块）以及轻量级蒸馏策略，能够高效地计算密集时间帧级特征，为需要密集时间推理的视频理解任务提供了有效的解决方案。

Abstract: Several video understanding tasks, such as natural language temporal video
grounding, temporal activity localization, and audio description generation,
require "temporally dense" reasoning over frames sampled at high temporal
resolution. However, computing frame-level features for these tasks is
computationally expensive given the temporal resolution requirements. In this
paper, we make three contributions to reduce the cost of computing features for
temporally dense tasks. First, we introduce a vision transformer (ViT)
architecture, dubbed ResidualViT, that leverages the large temporal redundancy
in videos to efficiently compute temporally dense frame-level features. Our
architecture incorporates (i) learnable residual connections that ensure
temporal consistency across consecutive frames and (ii) a token reduction
module that enhances processing speed by selectively discarding temporally
redundant information while reusing weights of a pretrained foundation model.
Second, we propose a lightweight distillation strategy to approximate the
frame-level features of the original foundation model. Finally, we evaluate our
approach across four tasks and five datasets, in both zero-shot and fully
supervised settings, demonstrating significant reductions in computational cost
(up to 60%) and improvements in inference speed (up to 2.5x faster), all while
closely approximating the accuracy of the original foundation model.

</details>


### [30] [RadGame: An AI-Powered Platform for Radiology Education](https://arxiv.org/abs/2509.13270)
*Mohammed Baharoon,Siavash Raissi,John S. Jun,Thibault Heintz,Mahmoud Alabbad,Ali Alburkani,Sung Eun Kim,Kent Kleinschmidt,Abdulrahman O. Alhumaydhi,Mohannad Mohammed G. Alghamdi,Jeremy Francis Palacio,Mohammed Bukhaytan,Noah Michael Prudlo,Rithvik Akula,Brady Chrisler,Benjamin Galligos,Mohammed O. Almutairi,Mazeen Mohammed Alanazi,Nasser M. Alrashdi,Joel Jihwan Hwang,Sri Sai Dinesh Jaliparthi,Luke David Nelson,Nathaniel Nguyen,Sathvik Suryadevara,Steven Kim,Mohammed F. Mohammed,Yevgeniy R. Semenov,Kun-Hsing Yu,Abdulrhman Aljouie,Hassan AlOmaish,Adam Rodman,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: RadGame是一个结合了游戏化和AI的放射学教育平台，通过自动化的反馈和评估，提升放射科医生在影像定位和报告撰写方面的技能。


<details>
  <summary>Details</summary>
Motivation: 传统放射学培训缺乏及时、可扩展的反馈，RadGame旨在解决这一问题，利用AI和游戏化提供有效的培训。

Method: RadGame包含两个模块：RadGame Localize（玩家在影像上标注异常区域，AI提供视觉解释）和RadGame Report（玩家根据影像信息撰写报告，AI根据标准进行评分）。平台使用公开数据集和AI模型进行训练和反馈。

Result: 与传统被动学习方法相比，使用RadGame的参与者在影像定位准确性方面提高了68%（传统方法为17%），在报告撰写准确性方面提高了31%（传统方法为4%）。

Conclusion: AI驱动的游戏化训练平台RadGame能够提供可扩展的、反馈丰富的放射学培训，并重新构想了医学AI在教育中的应用。

Abstract: We introduce RadGame, an AI-powered gamified platform for radiology education
that targets two core skills: localizing findings and generating reports.
Traditional radiology training is based on passive exposure to cases or active
practice with real-time input from supervising radiologists, limiting
opportunities for immediate and scalable feedback. RadGame addresses this gap
by combining gamification with large-scale public datasets and automated,
AI-driven feedback that provides clear, structured guidance to human learners.
In RadGame Localize, players draw bounding boxes around abnormalities, which
are automatically compared to radiologist-drawn annotations from public
datasets, and visual explanations are generated by vision-language models for
user missed findings. In RadGame Report, players compose findings given a chest
X-ray, patient age and indication, and receive structured AI feedback based on
radiology report generation metrics, highlighting errors and omissions compared
to a radiologist's written ground truth report from public datasets, producing
a final performance and style score. In a prospective evaluation, participants
using RadGame achieved a 68% improvement in localization accuracy compared to
17% with traditional passive methods and a 31% improvement in report-writing
accuracy compared to 4% with traditional methods after seeing the same cases.
RadGame highlights the potential of AI-driven gamification to deliver scalable,
feedback-rich radiology training and reimagines the application of medical AI
resources in education.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch](https://arxiv.org/abs/2509.12340)
*Nikolay Banar,Ehsan Lotfi,Jens Van Nooten,Cristina Arhiliuc,Marija Kliocaite,Walter Daelemans*

Main category: cs.CL

TL;DR: 荷兰语在多语言嵌入资源中代表性不足，本文提出了MTEB-NL基准、包含合成数据的训练数据集以及E5-NL嵌入模型，以弥补这一差距。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言嵌入资源未能充分代表荷兰语，需要专门的评估和生成资源来推动荷兰语嵌入的发展。

Method: 构建了一个包含现有和新增数据集的MTEB-NL基准，并收集了检索数据集和合成数据作为训练数据集。此外，还发布了一系列E5-NL嵌入模型。

Result: 提出的资源（MTEB-NL、训练数据集和E5-NL模型）在多个任务上表现出强大的性能，并且可以公开获取。

Conclusion: 通过提供全面的评估基准、扩充的训练数据和高效的嵌入模型，本文极大地促进了荷兰语嵌入技术的发展和应用。

Abstract: Recently, embedding resources, including models, benchmarks, and datasets,
have been widely released to support a variety of languages. However, the Dutch
language remains underrepresented, typically comprising only a small fraction
of the published multilingual resources. To address this gap and encourage the
further development of Dutch embeddings, we introduce new resources for their
evaluation and generation. First, we introduce the Massive Text Embedding
Benchmark for Dutch (MTEB-NL), which includes both existing Dutch datasets and
newly created ones, covering a wide range of tasks. Second, we provide a
training dataset compiled from available Dutch retrieval datasets, complemented
with synthetic data generated by large language models to expand task coverage
beyond retrieval. Finally, we release a series of E5-NL models compact yet
efficient embedding models that demonstrate strong performance across multiple
tasks. We make our resources publicly available through the Hugging Face Hub
and the MTEB package.

</details>


### [32] [MORABLES: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables](https://arxiv.org/abs/2509.12371)
*Matteo Marcuzzo,Alessandro Zangari,Andrea Albarelli,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: MORABLES是一个包含寓言和短篇故事的基准测试，用于评估大型语言模型（LLMs）的道德推理能力。研究发现，虽然更大的模型表现更好，但它们仍然容易受到对抗性操纵，并且在20%的情况下会出现自我矛盾。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在复杂抽象推理和推断方面的能力，特别是在道德推理方面，因为它们在标准阅读理解任务上表现出色。

Method: 创建一个名为MORABLES的人工验证基准测试，其中包含来自历史文献的寓言和短篇故事。主要任务是基于多项选择题，考察道德推理能力，并设计了具有挑战性的干扰项，以防止模型进行浅层、提取式的问答。还引入了对抗性变体来测试模型的鲁棒性。

Result: 虽然更大的模型表现优于较小的模型，但它们仍然容易受到对抗性操纵，并且常常依赖肤浅的模式而非真正的道德推理。在约20%的情况下，最佳模型会因表述方式的不同而否定自己的答案。推理增强模型未能缩小这一差距，表明模型规模是性能的主要驱动因素。

Conclusion: 现有的LLMs在道德推理方面仍然存在不足，容易受到对抗性操纵，并且在没有真正理解的情况下进行推理。模型规模的增加可以提高性能，但并不能解决根本性的推理问题。

Abstract: As LLMs excel on standard reading comprehension benchmarks, attention is
shifting toward evaluating their capacity for complex abstract reasoning and
inference. Literature-based benchmarks, with their rich narrative and moral
depth, provide a compelling framework for evaluating such deeper comprehension
skills. Here, we present MORABLES, a human-verified benchmark built from fables
and short stories drawn from historical literature. The main task is structured
as multiple-choice questions targeting moral inference, with carefully crafted
distractors that challenge models to go beyond shallow, extractive question
answering. To further stress-test model robustness, we introduce adversarial
variants designed to surface LLM vulnerabilities and shortcuts due to issues
such as data contamination. Our findings show that, while larger models
outperform smaller ones, they remain susceptible to adversarial manipulation
and often rely on superficial patterns rather than true moral reasoning. This
brittleness results in significant self-contradiction, with the best models
refuting their own answers in roughly 20% of cases depending on the framing of
the moral choice. Interestingly, reasoning-enhanced models fail to bridge this
gap, suggesting that scale - not reasoning ability - is the primary driver of
performance.

</details>


### [33] [LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.12382)
*Anu Pradhan,Alexandra Ortan,Apurv Verma,Madhavan Seshadri*

Main category: cs.CL

TL;DR: LLM-as-a-Judge可用于评估法律领域的检索增强生成系统，并提出了新的统计方法来克服传统评估指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估推荐系统，特别是在法律研究等专业领域，面临生成式AI带来的挑战，传统指标无法捕捉细微的质量差异。本研究旨在探索LLM-as-a-Judge作为一种可行的方法。

Method: 通过系统性实验，研究了不同评价者间可靠性指标（如Krippendorff's alpha, Gwet's AC2, rank correlation coefficients）与人类评估的一致性，并应用Wilcoxon Signed-Rank Test结合Benjamini-Hochberg校正来进行系统间的统计比较。

Result: 研究发现，传统的Krippendorff's alpha指标在AI系统评估的偏斜分布中可能产生误导。Gwet's AC2和秩相关系数更适合用于评估者的选择。Wilcoxon Signed-Rank Test结合Benjamini-Hochberg校正能够提供可靠的系统比较所需的统计严谨性。

Conclusion: LLM-as-a-Judge提供了一种可扩展、成本效益高且能保持法律应用所需精度的评估方法，将以往耗费人力的方法转变为自动化但统计上合理的评估框架。

Abstract: The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.

</details>


### [34] [SENTRA: Selected-Next-Token Transformer for LLM Text Detection](https://arxiv.org/abs/2509.12385)
*Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian*

Main category: cs.CL

TL;DR: SENTRA是一个用于检测未声明的LLM生成文本的新型Transformer模型，在跨领域检测任务中表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: LLM的广泛应用带来了被滥用的风险，因此需要检测未声明的LLM生成文本。

Method: 提出了一种名为SENTRA的新型Transformer模型，该模型利用选择性下一令牌概率序列，并通过大规模无标签数据进行对比预训练。

Result: 在三个流行的公共数据集和24个文本领域上进行实验，结果表明SENTRA作为一种通用分类器，在领域外（out-of-domain）设置下显著优于流行的基线模型。

Conclusion: SENTRA是一种有效且通用的LLM生成文本检测器，特别是在处理未知的文本领域时具有优势。

Abstract: LLMs are becoming increasingly capable and widespread. Consequently, the
potential and reality of their misuse is also growing. In this work, we address
the problem of detecting LLM-generated text that is not explicitly declared as
such. We present a novel, general-purpose, and supervised LLM text detector,
SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder
leveraging selected-next-token-probability sequences and utilizing contrastive
pre-training on large amounts of unlabeled data. Our experiments on three
popular public datasets across 24 domains of text demonstrate SENTRA is a
general-purpose classifier that significantly outperforms popular baselines in
the out-of-domain setting.

</details>


### [35] [MORQA: Benchmarking Evaluation Metrics for Medical Open-Ended Question Answering](https://arxiv.org/abs/2509.12405)
*Wen-wai Yim,Asma Ben Abacha,Zixuan Yu,Robert Doerning,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 医疗开放式问答（MORQA）基准测试了评估自然语言生成（NLG）模型在医学领域的有效性，其特点是多语言、多答案且有专家评分，显示基于大型语言模型（LLM）的评估者优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 评估医学领域自然语言生成（NLG）系统的准确性、相关性和领域专业知识至关重要，但传统自动评估指标（如BLEU、ROUGE、BERTScore）在该领域存在局限性，尤其是在医学问答（QA）任务中存在多个有效答案的情况下。

Method: 创建了一个名为MORQA（Medical Open-Response QA）的多语言基准，包含三个医学领域的可视化和文本问答数据集（英语和中文），提供多个由医学专家撰写的标准答案，并对部分英语和中文数据集进行了专家人工评分。对传统指标和基于大型语言模型（LLM）的评估者（如GPT-4和Gemini）进行了基准测试。

Result: 基于LLM的评估方法在与专家判断的相关性方面显著优于传统指标。LLM的优势在于对语义细微差别的敏感性以及对参考答案变异性的鲁棒性。

Conclusion: 在医学领域，需要采用与人类判断更一致的评估方法来评估NLG系统。MORQA基准和相关数据将被公开，以促进未来研究。

Abstract: Evaluating natural language generation (NLG) systems in the medical domain
presents unique challenges due to the critical demands for accuracy, relevance,
and domain-specific expertise. Traditional automatic evaluation metrics, such
as BLEU, ROUGE, and BERTScore, often fall short in distinguishing between
high-quality outputs, especially given the open-ended nature of medical
question answering (QA) tasks where multiple valid responses may exist. In this
work, we introduce MORQA (Medical Open-Response QA), a new multilingual
benchmark designed to assess the effectiveness of NLG evaluation metrics across
three medical visual and text-based QA datasets in English and Chinese. Unlike
prior resources, our datasets feature 2-4+ gold-standard answers authored by
medical professionals, along with expert human ratings for three English and
Chinese subsets. We benchmark both traditional metrics and large language model
(LLM)-based evaluators, such as GPT-4 and Gemini, finding that LLM-based
approaches significantly outperform traditional metrics in correlating with
expert judgments. We further analyze factors driving this improvement,
including LLMs' sensitivity to semantic nuances and robustness to variability
among reference answers. Our results provide the first comprehensive,
multilingual qualitative study of NLG evaluation in the medical domain,
highlighting the need for human-aligned evaluation methods. All datasets and
annotations will be publicly released to support future research.

</details>


### [36] [MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts](https://arxiv.org/abs/2509.12440)
*Jiayi He,Yangmin Huang,Qianyun Du,Xiangying Zhou,Zhiyang He,Jiaxue Hu,Xiaodong Tao,Lixian Lai*

Main category: cs.CL

TL;DR: MedFact是一个新的中文医疗事实核查基准，包含2116个专家标注的实例，涵盖13个医学专业、8种错误类型、4种写作风格和多个难度级别。该基准通过AI-human协作框架构建，旨在评估大型语言模型（LLMs）在医疗领域的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗领域LLM评估基准在数据领域和复杂性方面存在局限性，无法充分反映真实世界的医疗信息。需要一个更具挑战性的中文医疗事实核查基准来推动LLM在医疗领域的可靠性发展。

Method: 构建了一个包含2116个专家标注实例的MedFact基准，涵盖13个医学专业、8种错误类型、4种写作风格和多个难度级别。采用AI-human协作框架，通过迭代式专家反馈优化AI驱动的多标准过滤流程，以确保数据质量和难度。对20个领先的LLMs进行了全面的评估，基准测试了它们在真实性分类和错误定位方面的性能，并与人类专家的表现进行了比较。

Result: 在MedFact基准上，大多数LLMs能够识别文本中是否存在错误，但准确地定位错误仍然是一个重大挑战，即使是表现最好的模型也未能达到人类专家的水平。此外，研究发现LLMs存在“过度批评”现象，即倾向于将正确信息误判为错误，这种现象在使用多智能体协作和推理时扩展等高级推理技术时会加剧。

Conclusion: MedFact基准揭示了在医疗应用中部署LLMs所面临的关键挑战，特别是错误定位和过度批评问题。该基准为推动开发更具事实可靠性和医学意识的LLMs提供了重要的资源。

Abstract: The increasing deployment of Large Language Models (LLMs) in healthcare
necessitates a rigorous evaluation of their factual reliability. However,
existing benchmarks are often limited by narrow domains of data, failing to
capture the complexity of real-world medical information. To address this
critical gap, we introduce MedFact, a new and challenging benchmark for Chinese
medical fact-checking. MedFact comprises 2,116 expert-annotated instances
curated from diverse real-world texts, spanning 13 medical specialties, 8
fine-grained error types, 4 writing styles, and multiple difficulty levels. Its
construction employs a hybrid AI-human framework where iterative expert
feedback refines an AI-driven, multi-criteria filtering process, ensuring both
high data quality and difficulty. We conduct a comprehensive evaluation of 20
leading LLMs, benchmarking their performance on veracity classification and
error localization against a human expert baseline. Our results reveal that
while models can often determine if a text contains an error, precisely
localizing it remains a substantial challenge, with even top-performing models
falling short of human performance. Furthermore, our analysis uncovers a
frequent ``over-criticism'' phenomenon, a tendency for models to misidentify
correct information as erroneous, which is exacerbated by advanced reasoning
techniques such as multi-agent collaboration and inference-time scaling. By
highlighting these critical challenges for deploying LLMs in medical
applications, MedFact provides a robust resource to drive the development of
more factually reliable and medically aware models.

</details>


### [37] [Topic Coverage-based Demonstration Retrieval for In-Context Learning](https://arxiv.org/abs/2509.12451)
*Wonbin Kweon,SeongKu Kang,Runchu Tian,Pengcheng Jiang,Jiawei Han,Hwanjo Yu*

Main category: cs.CL

TL;DR: TopicK是一个基于话题覆盖的检索框架，通过选择能引入模型知识不足的话题的示例，来提高 in-context learning 的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的 in-context learning 方法在选择示例时，仅依赖于嵌入相似度或生成概率，容易导致示例不相关或冗余，未能有效覆盖细粒度的知识需求。

Method: TopicK 框架首先估计输入所需的话题，并评估模型在这些话题上的知识储备。然后，它迭代地选择那些能引入模型知识不足且先前未被覆盖的话题的示例。

Result: 通过在多个数据集和不同的大型语言模型（包括开源和闭源模型）上进行的大量实验，验证了 TopicK 的有效性。

Conclusion: TopicK 通过确保所选示例能够全面覆盖与测试输入和模型相关的、细粒度的知识需求，从而有效提升了 in-context learning 的性能。

Abstract: The effectiveness of in-context learning relies heavily on selecting
demonstrations that provide all the necessary information for a given test
input. To achieve this, it is crucial to identify and cover fine-grained
knowledge requirements. However, prior methods often retrieve demonstrations
based solely on embedding similarity or generation probability, resulting in
irrelevant or redundant examples. In this paper, we propose TopicK, a topic
coverage-based retrieval framework that selects demonstrations to
comprehensively cover topic-level knowledge relevant to both the test input and
the model. Specifically, TopicK estimates the topics required by the input and
assesses the model's knowledge on those topics. TopicK then iteratively selects
demonstrations that introduce previously uncovered required topics, in which
the model exhibits low topical knowledge. We validate the effectiveness of
TopicK through extensive experiments across various datasets and both open- and
closed-source LLMs. Our source code is available at
https://github.com/WonbinKweon/TopicK_EMNLP2025.

</details>


### [38] [Does Language Model Understand Language?](https://arxiv.org/abs/2509.12459)
*Suvojit Acharjee,Utathya Aich,Asfak Ali*

Main category: cs.CL

TL;DR: 尽管自然语言生成和理解取得了进展，但语言模型在处理细微的语言现象（如时态、否定、语态和情态）方面仍然存在挑战，而这些现象对有效的人类沟通至关重要。本研究评估了 SOTA 语言模型在英语和孟加拉语中的表现，并引入了新的 LUCID 数据集和 HCE 准确性指标来挑战这些模型。结果显示 Compound-Beta 在跨语言场景中表现最均衡，与人类判断最吻合。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理细微的语言现象（如时态、否定、语态和情态）方面仍有不足，而这些现象对于有效的沟通至关重要。在联合国 SDG 4 的背景下，教育技术的语言清晰度至关重要，因此需要对语言模型进行仔细审查。

Method: 评估 SOTA 语言模型在英语和孟加拉语中的表现，使用新的 LUCID 数据集，该数据集包含精心设计的句子对，专门针对否定、时态和语态等关键语言理解方面进行挑战。评估指标包括皮尔逊相关系数、斯皮尔曼相关系数、平均绝对误差以及新提出的 HCE 准确性。

Result: Compound-Beta 在各种语言条件下表现最为均衡，持续获得高相关性和低平均绝对误差。它在英语中获得了最高的皮尔逊相关系数，并在混合语言数据上表现稳健，表明其在跨语言场景中与人类判断高度一致。

Conclusion: Compound-Beta 是最均衡的语言模型，在跨语言场景中与人类判断高度一致。

Abstract: Despite advances in natural language generation and understanding, LM still
struggle with fine grained linguistic phenomena such as tense, negation, voice,
and modality which are the elements central to effective human communication.
In the context of the United Nations SDG 4, where linguistic clarity is
critical, the deployment of LMs in educational technologies demands careful
scrutiny. As LMs are increasingly powering applications like tutoring systems,
automated grading, and translation, their alignment with human linguistic
interpretation becomes essential for effective learning. In this study, we
conduct a evaluation of SOTA language models across these challenging contexts
in both English and Bengali. To ensure a structured assessment, we introduce a
new Route for Evaluation of Cognitive Inference in Systematic Environments
guidelines. Our proposed LUCID dataset, composed of carefully crafted sentence
pairs in English and Bengali, specifically challenges these models on critical
aspects of language comprehension, including negation, tense, voice variations.
We assess the performance of SOTA models including MISTRAL-SABA-24B,
LLaMA-4-Scout-17B, LLaMA-3.3-70B, Gemma2-9B, and Compound-Beta using standard
metrics like Pearson correlation, Spearman correlation, and Mean Absolute
Error, as well as novel, linguistically inspired metric the HCE accuracy. The
HCE accuracy measures how often model predictions fall within one standard
deviation of the mean human rating, thus capturing human like tolerance for
variability in language interpretation. Our findings highlight Compound-Beta as
the most balanced model, consistently achieving high correlations and low MAEs
across diverse language conditions. It records the highest Pearson correlation
in English and demonstrates robust performance on mixed-language data,
indicating a strong alignment with human judgments in cross lingual scenarios.

</details>


### [39] [Audited Reasoning Refinement: Fine-Tuning Language Models via LLM-Guided Step-Wise Evaluation and Correction](https://arxiv.org/abs/2509.12476)
*Sumanta Bhattacharyya,Sara Riaz,Pedram Rooshenas*

Main category: cs.CL

TL;DR: 通过对大型语言模型生成的推理过程进行提炼和修正，来为特定任务的推理模型创建监督信号，并使用对齐技术进行微调，以解决数据稀疏领域中模型训练的挑战。


<details>
  <summary>Details</summary>
Motivation: 在缺乏人类监督或高质量标签的情况下，训练特定任务的小型推理模型具有挑战性。大型语言模型（LLMs）可以生成丰富的中间推理过程，这些过程可以通过系统地提炼来转化为有效的监督信号。

Method: 提出了一种名为Reason-Refine-then-Align (R2tA)的方法，该方法利用提炼后的模型推理作为监督信号来训练特定任务的推理模型。具体步骤包括：1. 使用开源基础模型生成初步的推理和响应。2. 提炼这些推理过程，修复其中的错误和不一致之处，形成高质量的数据集。3. 进行两阶段的对齐：首先进行监督微调（SFT），然后进行直接偏好优化（DPO），以使模型的中间推理与人类验证的概念偏好保持一致，并最终将最终输出与对齐后的推理条件关联起来。

Result: 将R2tA应用于数据库系统设计中的扩展实体关系图（EERDs）评估。创建了一个包含600个EERD变体（450个训练，150个测试）的数据集，涵盖了11类错误。实验表明，R2tA为数据稀疏领域中可扩展的LLM适应提供了一条实用且经济高效的途径。

Conclusion: R2tA方法为数据稀疏领域提供了可扩展的LLM适应途径，能够生成可复现的人工智能工具，并应用于教育等领域。

Abstract: Training a task-specific small reasoning model is challenging when direct
human supervision or high-quality labels are scarce. However, LLMs with
reasoning capabilities produce abundant intermediate reasoning traces that can
be systematically refined to create effective supervision signals. We propose
Reason-Refine-then-Align (R2tA), which turns refined model rationales into
supervision for training task-specific reasoning models. Our method generates
initial reasoning and responses from an open-source base model on task-specific
inputs, then refines these traces, fixing hallucinations and inconsistencies,
to form a high-fidelity dataset. We perform a two-stage alignment, supervised
fine-tuning (SFT), followed by direct preference optimization (DPO) to
calibrate the model's intermediate reasoning with human-validated conceptual
preferences and then condition the final output on that aligned reasoning. As a
case study, we apply R2tA to evaluate extended entity relationship diagrams
(EERDs) in database system design, a structurally complex task where
prompt-only methods miss or hallucinate errors. We curated a dataset of 600
EERD variants (train/test split of 450/150, respectively) with induced mistakes
spanning 11 categories. Empirical evaluation suggests R2tA provides a
practical, cost-effective path to scalable LLM adaptation in data-scarce
domains, enabling reproducible AI tools for education and beyond.

</details>


### [40] [FunAudio-ASR Technical Report](https://arxiv.org/abs/2509.12508)
*Keyu An,Yanni Chen,Chong Deng,Changfeng Gao,Zhifu Gao,Bo Gong,Xiangang Li,Yabin Li,Xiang Lv,Yunjie Ji,Yiheng Jiang,Bin Ma,Haoneng Luo,Chongjia Ni,Zexu Pan,Yiping Peng,Zhendong Peng,Peiyao Wang,Hao Wang,Wen Wang,Wupeng Wang,Biao Tian,Zhentao Tan,Nan Yang,Bin Yuan,Jieping Ye,Jixing Yu,Qinglin Zhang,Kun Zou,Han Zhao,Shengkui Zhao,Jingren Zhou*

Main category: cs.CL

TL;DR: FunAudio-ASR是一个大型、基于LLM的ASR系统，通过结合海量数据、大模型、LLM集成和强化学习，在复杂场景下达到SOTA性能，并针对实际部署进行了优化，在真实评估数据集上表现优于其他LLM-based ASR系统。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）在自动语音识别（ASR）应用中容易出现幻觉，影响用户体验的问题，并提升ASR系统在真实工业场景下的性能。

Method: 提出FunAudio-ASR系统，该系统结合了海量数据、大模型容量、LLM集成以及强化学习。同时，针对实际部署需求，对系统的流式处理能力、噪声鲁棒性、语种切换、热词定制等方面进行了优化。

Result: 在真实工业评估数据集上，FunAudio-ASR取得了SOTA性能，证明了其在实际应用中的有效性和鲁棒性，表现优于大多数在公开基准上表现良好的LLM-based ASR系统。

Conclusion: FunAudio-ASR通过结合多种先进技术并针对实际应用进行优化，成功解决了LLM在ASR中存在的幻觉问题，并在真实场景下取得了领先性能。

Abstract: In recent years, automatic speech recognition (ASR) has witnessed
transformative advancements driven by three complementary paradigms: data
scaling, model size scaling, and deep integration with large language models
(LLMs). However, LLMs are prone to hallucination, which can significantly
degrade user experience in real-world ASR applications. In this paper, we
present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically
combines massive data, large model capacity, LLM integration, and reinforcement
learning to achieve state-of-the-art performance across diverse and complex
speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized
for practical deployment, with enhancements in streaming capability, noise
robustness, code-switching, hotword customization, and satisfying other
real-world application requirements. Experimental results show that while most
LLM-based ASR systems achieve strong performance on open-source benchmarks,
they often underperform on real industry evaluation sets. Thanks to
production-oriented optimizations, FunAudio-ASR achieves SOTA performance on
real application datasets, demonstrating its effectiveness and robustness in
practical settings.

</details>


### [41] [A comparison of pipelines for the translation of a low resource language based on transformers](https://arxiv.org/abs/2509.12514)
*Chiara Bonfanti,Michele Colombino,Giulia Coucourde,Faeze Memari,Stefano Pinardi,Rosa Meo*

Main category: cs.CL

TL;DR: 本文比较了三种训练 transformer 模型的流水线，用于生成班巴拉语（一种非洲语言）机器翻译模型。


<details>
  <summary>Details</summary>
Motivation: 为班巴拉语开发高质量的机器翻译模型，以应对其作为一种资源稀缺语言的挑战。

Method: 比较了三种流水线：1. 训练简单的 transformer 模型进行法-班巴拉语翻译；2. 使用 decoder-only 架构微调 LLaMA3 模型进行法-班巴拉语翻译；3. 利用学生-教师双神经网络进行语言蒸馏，将班巴拉语集成到预训练的 LaBSE 模型中，并应用 BERT 扩展生成翻译。

Result: 第一种流水线（简单的 transformer 模型）在 Bayelemagaba 数据集上达到了最佳翻译准确率（BLEU 10%，chrF 21%），在自建的 Yiri 数据集上达到了 BLEU 33.81% 和 chrF 41%。LLaMA3 模型在单个数据集上表现优于聚合数据集，表明其能更有效地捕捉特定数据集的模式。

Conclusion: 对于班巴拉语这类低资源语言，简单的 transformer 模型流水线在翻译准确性方面表现最佳。

Abstract: This work compares three pipelines for training transformer-based neural
networks to produce machine translators for Bambara, a Mand\`e language spoken
in Africa by about 14,188,850 people. The first pipeline trains a simple
transformer to translate sentences from French into Bambara. The second
fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures
for French-to-Bambara translation. Models from the first two pipelines were
trained with different hyperparameter combinations to improve BLEU and chrF
scores, evaluated on both test sentences and official Bambara benchmarks. The
third pipeline uses language distillation with a student-teacher dual neural
network to integrate Bambara into a pre-trained LaBSE model, which provides
language-agnostic embeddings. A BERT extension is then applied to LaBSE to
generate translations. All pipelines were tested on Dokotoro (medical) and
Bayelemagaba (mixed domains). Results show that the first pipeline, although
simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on
Bayelemagaba), consistent with low-resource translation results. On the Yiri
dataset, created for this work, it achieves 33.81% BLEU and 41% chrF.
Instructor-based models perform better on single datasets than on aggregated
collections, suggesting they capture dataset-specific patterns more
effectively.

</details>


### [42] [MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](https://arxiv.org/abs/2509.12591)
*Vijay Govindarajan,Pratik Patel,Sahil Tripathi,Md Azizul Hoque,Gautam Siddharth Kashyap*

Main category: cs.CL

TL;DR: 提出零样本自动音频描述（AAC）系统，利用预训练模型（如音频CLIP）和语言模型（LLM）生成音频描述，无需大量训练数据。


<details>
  <summary>Details</summary>
Motivation: 与图像描述相比，自动音频描述（AAC）面临数据集有限的挑战。

Method: 利用预训练的音频CLIP模型提取音频特征，生成结构化提示，引导LLM进行描述生成。采用音频CLIP模型进行代币选择的优化，而非传统的贪婪解码。

Result: 在WavCaps数据集上，使用MAGIC搜索和单关键词提示，NLG平均得分提高了35%（从4.7提升至7.3）。未使用关键词列表时，性能下降50%。

Conclusion: 音频-文本匹配模型和关键词选择对AAC性能有显著影响，单关键词提示效果最佳。

Abstract: Automated Audio Captioning (AAC) generates captions for audio clips but faces
challenges due to limited datasets compared to image captioning. To overcome
this, we propose the zero-shot AAC system that leverages pre-trained models,
eliminating the need for extensive training. Our approach uses a pre-trained
audio CLIP model to extract auditory features and generate a structured prompt,
which guides a Large Language Model (LLM) in caption generation. Unlike
traditional greedy decoding, our method refines token selection through the
audio CLIP model, ensuring alignment with the audio content. Experimental
results demonstrate a 35% improvement in NLG mean score (from 4.7 to 7.3) using
MAGIC search with the WavCaps model. The performance is heavily influenced by
the audio-text matching model and keyword selection, with optimal results
achieved using a single keyword prompt, and a 50% performance drop when no
keyword list is used.

</details>


### [43] [EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving](https://arxiv.org/abs/2509.12603)
*Mukai Li,Linfeng Song,Zhenwen Liang,Jiahao Xu,Shansan Gong,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: LLMs在自动定理证明（ATP）中取得了显著进展，但现有的测试时扩展策略（如CoT和增加采样次数）带来了高昂的计算开销。本文系统地比较了不同测试时扩展策略的效率，并提出了EconRL管道，结合了动态CoT切换和具有可训练前缀的多样化并行RL，以减少token消耗和采样次数。实验表明，EconProver在保持性能的同时，计算成本仅为基线方法的12%。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在ATP中的测试时扩展策略（如CoT和增加采样次数）虽然提高了性能，但带来了显著的计算开销，并且现有的成本分析忽略了不同扩展策略带来的采样成本差异。

Method: 本文提出了一种名为EconRL的管道，其中包含两个互补的方法：1. 动态CoT切换机制，用于减少不必要的token消耗。2. 多样化并行扩展的强化学习（RL）与可训练前缀，用于在受限的采样次数下提高通过率。

Result: 在miniF2F和ProofNet数据集上的实验表明，本文提出的EconProver在计算成本仅为基线方法的12%的情况下，达到了与基线方法相当的性能。

Conclusion: 本文通过系统性的效率比较和提出的EconRL管道，为在不牺牲性能的前提下部署轻量级的ATP模型提供了可行的见解，有效降低了LLM在ATP中的计算成本。

Abstract: Large Language Models (LLMs) have recently advanced the field of Automated
Theorem Proving (ATP), attaining substantial performance gains through widely
adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT)
reasoning and increased sampling passes. However, they both introduce
significant computational overhead for inference. Moreover, existing cost
analyses typically regulate only the number of sampling passes, while
neglecting the substantial disparities in sampling costs introduced by
different scaling strategies. In this paper, we systematically compare the
efficiency of different test-time scaling strategies for ATP models and
demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source
approaches. We then investigate approaches to significantly reduce token usage
and sample passes while maintaining the original performance. Specifically, we
propose two complementary methods that can be integrated into a unified EconRL
pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching
mechanism designed to mitigate unnecessary token consumption, and (2) Diverse
parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance
pass rates under constrained sampling passes. Experiments on miniF2F and
ProofNet demonstrate that our EconProver achieves comparable performance to
baseline methods with only 12% of the computational cost. This work provides
actionable insights for deploying lightweight ATP models without sacrificing
performance.

</details>


### [44] [Positional Encoding via Token-Aware Phase Attention](https://arxiv.org/abs/2509.12635)
*Yu,Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian*

Main category: cs.CL

TL;DR: RoPE存在固有的距离依赖偏差，限制了其长上下文建模能力。TAPA是一种新的位置编码方法，通过引入可学习的相位函数来解决这个问题，能够更好地处理长上下文，并具有更低的困惑度。


<details>
  <summary>Details</summary>
Motivation: RoPE在长上下文建模方面存在局限性，现有的扩展方法需要进行后处理调整。

Method: 提出了一种名为Token-Aware Phase Attention (TAPA) 的新位置编码方法，该方法在注意力机制中加入了可学习的相位函数。

Result: TAPA能够保持长距离的token交互，通过轻量级微调即可扩展到更长的上下文，并能推断到未见过的长度，在长上下文方面取得了比RoPE系列更低的困惑度。

Conclusion: TAPA是一种有效的位置编码方法，能够克服RoPE在长上下文建模方面的不足。

Abstract: We prove under practical assumptions that Rotary Positional Embedding (RoPE)
introduces an intrinsic distance-dependent bias in attention scores that limits
RoPE's ability to model long-context. RoPE extension methods may alleviate this
issue, but they typically require post-hoc adjustments after pretraining, such
as rescaling or hyperparameters retuning. This paper introduces Token-Aware
Phase Attention (TAPA), a new positional encoding method that incorporates a
learnable phase function into the attention mechanism. TAPA preserves token
interactions over long range, extends to longer contexts with direct and light
fine-tuning, extrapolates to unseen lengths, and attains significantly lower
perplexity on long-context than RoPE families.

</details>


### [45] [PAC: Pronunciation-Aware Contextualized Large Language Model-based Automatic Speech Recognition](https://arxiv.org/abs/2509.12647)
*Li Fu,Yu Xin,Sunlu Zeng,Lu Fan,Youzheng Wu,Xiaodong He*

Main category: cs.CL

TL;DR: PAC框架通过结合发音线索和强化学习，提升了基于LLM的ASR系统在长尾词和同音词识别方面的表现，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于LLM的ASR系统在有效发音建模和同音词区分方面的挑战，特别是在原始或长尾词识别场景下。

Method: 提出了一种两阶段学习范式：1. 发音引导的上下文学习，采用交织的字-音上下文建模策略，并引入字-only干扰项。2. 发音区分性强化学习，结合扰动标签采样，以增强区分上下文同音词的能力。

Result: 在Librispeech和AISHELL-1数据集上，PAC将基于预训练LLM的ASR模型的相对词错误率（WER）分别降低了30.2%和53.8%。同时，在长尾词的偏见WER方面，相较于强基线模型，PAC分别实现了31.8%和60.5%的相对降低。

Conclusion: PAC框架能够有效提升基于LLM的ASR系统在长尾词和同音词识别方面的性能，显著优于现有的ASR模型。

Abstract: This paper presents a Pronunciation-Aware Contextualized (PAC) framework to
address two key challenges in Large Language Model (LLM)-based Automatic Speech
Recognition (ASR) systems: effective pronunciation modeling and robust
homophone discrimination. Both are essential for raw or long-tail word
recognition. The proposed approach adopts a two-stage learning paradigm. First,
we introduce a pronunciation-guided context learning method. It employs an
interleaved grapheme-phoneme context modeling strategy that incorporates
grapheme-only distractors, encouraging the model to leverage phonemic cues for
accurate recognition. Then, we propose a pronunciation-discriminative
reinforcement learning method with perturbed label sampling to further enhance
the model\'s ability to distinguish contextualized homophones. Experimental
results on the public English Librispeech and Mandarin AISHELL-1 datasets
indicate that PAC: (1) reduces relative Word Error Rate (WER) by 30.2% and
53.8% compared to pre-trained LLM-based ASR models, and (2) achieves 31.8% and
60.5% relative reductions in biased WER for long-tail words compared to strong
baselines, respectively.

</details>


### [46] [Don't Change My View: Ideological Bias Auditing in Large Language Models](https://arxiv.org/abs/2509.12652)
*Paul Kröger,Emilio Barkett*

Main category: cs.CL

TL;DR: LLM输出可能影响公众舆论，本文提出一种模型无关的方法来检测LLM是否被引导至特定意识形态。


<details>
  <summary>Details</summary>
Motivation: 由于LLM越来越广泛地被使用，它们的输出可能会影响个人信念和公众舆论。如果LLM的行为能够被引导至特定的意识形态立场，那么控制这些系统的人可能会获得不成比例的影响力。因此，开发检测此类引导尝试的方法至关重要。

Method: 本文将一种先前提出的统计方法应用于意识形态偏见审计的新情境。该方法不依赖于对语言模型内部的访问，而是通过分析模型在与选定主题相关的提示下的输出分布变化来识别潜在的意识形态引导。

Result: 通过一系列实验验证了该方法的有效性，证明了其在实际中的应用性和支持事后独立审计LLM行为的潜力。

Conclusion: 本文提出的方法能够检测LLM是否被引导至特定的意识形态，为理解和审计LLM的行为提供了一种实用工具。

Abstract: As large language models (LLMs) become increasingly embedded in products used
by millions, their outputs may influence individual beliefs and, cumulatively,
shape public opinion. If the behavior of LLMs can be intentionally steered
toward specific ideological positions, such as political or religious views,
then those who control these systems could gain disproportionate influence over
public discourse. Although it remains an open question whether LLMs can
reliably be guided toward coherent ideological stances and whether such
steering can be effectively prevented, a crucial first step is to develop
methods for detecting when such steering attempts occur. In this work, we adapt
a previously proposed statistical method to the new context of ideological bias
auditing. Our approach carries over the model-agnostic design of the original
framework, which does not require access to the internals of the language
model. Instead, it identifies potential ideological steering by analyzing
distributional shifts in model outputs across prompts that are thematically
related to a chosen topic. This design makes the method particularly suitable
for auditing proprietary black-box systems. We validate our approach through a
series of experiments, demonstrating its practical applicability and its
potential to support independent post hoc audits of LLM behavior.

</details>


### [47] [Mitigating Strategy Preference Bias in Emotional Support Conversation via Uncertainty Estimations](https://arxiv.org/abs/2509.12661)
*Yougen Zhou,Qin Chen,Ningning Zhou,Jie Zhou,Xingjiao Wu,Liang He*

Main category: cs.CL

TL;DR: LLM在情感支持对话（ESC）中存在策略规划不准确和偏好偏差问题。本文揭示了LLM策略规划中知识边界是偏好的根本原因，并提出了一种结合准确性和基于熵置信度的双重奖励函数进行强化学习的方法来缓解偏好。实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: LLM在情感支持对话（ESC）中存在策略规划不准确和偏好偏差问题，现有方法未能充分研究偏好的根本原因。

Method: 首先，通过识别LLM在策略规划中的知识边界来揭示偏好的根本原因。然后，提出一种使用双重奖励函数（优化准确性和基于熵的置信度）的强化学习方法来缓解偏好。

Result: 提出的方法在ESCov和ExTES数据集上，以及在多个LLM骨干上，都优于基线方法。

Conclusion: 所提出的方法能有效缓解LLM在ESC中的策略规划偏好偏差。

Abstract: Emotional support conversation (ESC) aims to alleviate distress through
empathetic dialogue, yet large language models (LLMs) face persistent
challenges in delivering effective ESC due to low accuracy in strategy
planning. Moreover, there is a considerable preference bias towards specific
strategies. Prior methods using fine-tuned strategy planners have shown
potential in reducing such bias, while the underlying causes of the preference
bias in LLMs have not well been studied. To address these issues, we first
reveal the fundamental causes of the bias by identifying the knowledge
boundaries of LLMs in strategy planning. Then, we propose an approach to
mitigate the bias by reinforcement learning with a dual reward function, which
optimizes strategy planning via both accuracy and entropy-based confidence for
each region according to the knowledge boundaries. Experiments on the ESCov and
ExTES datasets with multiple LLM backbones show that our approach outperforms
the baselines, confirming the effectiveness of our approach.

</details>


### [48] [Chat-Driven Text Generation and Interaction for Person Retrieval](https://arxiv.org/abs/2509.12662)
*Zequn Xie,Chuxin Wang,Sihang Cai,Yeqiang Wang,Shulei Wang,Tao Jin*

Main category: cs.CL

TL;DR: TBPS系统通过生成和交互式文本改进了搜索，无需手动标注。


<details>
  <summary>Details</summary>
Motivation: 手动标注TBPS数据成本高，限制了其可扩展性和实用性。

Method: 提出多轮文本生成（MTG）和多轮文本交互（MTI）模块。MTG通过模拟对话生成伪标签，MTI在推理时优化用户查询。

Result: 该方法在不使用手动标注的情况下，实现了具有竞争力的性能，提高了检索准确性、鲁棒性和可用性。

Conclusion: MTG和MTI组成的无标注框架为TBPS系统的可扩展和实际部署铺平了道路。

Abstract: Text-based person search (TBPS) enables the retrieval of person images from
large-scale databases using natural language descriptions, offering critical
value in surveillance applications. However, a major challenge lies in the
labor-intensive process of obtaining high-quality textual annotations, which
limits scalability and practical deployment. To address this, we introduce two
complementary modules: Multi-Turn Text Generation (MTG) and Multi-Turn Text
Interaction (MTI). MTG generates rich pseudo-labels through simulated dialogues
with MLLMs, producing fine-grained and diverse visual descriptions without
manual supervision. MTI refines user queries at inference time through dynamic,
dialogue-based reasoning, enabling the system to interpret and resolve vague,
incomplete, or ambiguous descriptions - characteristics often seen in
real-world search scenarios. Together, MTG and MTI form a unified and
annotation-free framework that significantly improves retrieval accuracy,
robustness, and usability. Extensive evaluations demonstrate that our method
achieves competitive or superior results while eliminating the need for manual
captions, paving the way for scalable and practical deployment of TBPS systems.

</details>


### [49] [Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](https://arxiv.org/abs/2509.12672)
*Shaz Furniturewala,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The volume of machine-generated content online has grown dramatically due to
the widespread use of Large Language Models (LLMs), leading to new challenges
for content moderation systems. Conventional content moderation classifiers,
which are usually trained on text produced by humans, suffer from
misclassifications due to LLM-generated text deviating from their training data
and adversarial attacks that aim to avoid detection. Present-day defence
tactics are reactive rather than proactive, since they rely on adversarial
training or external detection models to identify attacks. In this work, we aim
to identify the vulnerable components of toxicity classifiers that contribute
to misclassification, proposing a novel strategy based on mechanistic
interpretability techniques. Our study focuses on fine-tuned BERT and RoBERTa
classifiers, testing on diverse datasets spanning a variety of minority groups.
We use adversarial attacking techniques to identify vulnerable circuits.
Finally, we suppress these vulnerable circuits, improving performance against
adversarial attacks. We also provide demographic-level insights into these
vulnerable circuits, exposing fairness and robustness gaps in model training.
We find that models have distinct heads that are either crucial for performance
or vulnerable to attack and suppressing the vulnerable heads improves
performance on adversarial input. We also find that different heads are
responsible for vulnerability across different demographic groups, which can
inform more inclusive development of toxicity detection models.

</details>


### [50] [Case-Based Decision-Theoretic Decoding with Quality Memories](https://arxiv.org/abs/2509.12677)
*Hiroyuki Deguchi,Masaaki Nagata*

Main category: cs.CL

TL;DR: MBR解码在文本生成中表现优于MAP解码，但处理领域外知识时存在困难。CBDT解码通过使用领域数据示例来估计预期效用，解决了这个问题，并且MBR和CBDT的结合在多个翻译和图像字幕任务中表现优于单独的MBR解码。


<details>
  <summary>Details</summary>
Motivation: 如何使文本生成模型在处理领域外知识时，仍能生成高质量文本，并且优于现有的MAP解码和MBR解码方法。

Method: 提出了一种称为案例基础决策理论（CBDT）解码的新方法，该方法使用领域数据示例来估计预期效用，并将其与MBR解码相结合。

Result: 将MBR和CBDT解码相结合的方法在七个领域的英译德和日译英翻译任务以及MSCOCO和nocaps数据集的图像字幕任务中，取得了优于单独MBR解码的性能。

Conclusion: CBDT解码是一种有效的方法，可以解决MBR解码在处理领域外知识时遇到的挑战，并且MBR和CBDT的结合在文本生成任务中具有优越的性能。

Abstract: Minimum Bayes risk (MBR) decoding is a decision rule of text generation,
which selects the hypothesis that maximizes the expected utility and robustly
generates higher-quality texts than maximum a posteriori (MAP) decoding.
However, it depends on sample texts drawn from the text generation model; thus,
it is difficult to find a hypothesis that correctly captures the knowledge or
information of out-of-domain. To tackle this issue, we propose case-based
decision-theoretic (CBDT) decoding, another method to estimate the expected
utility using examples of domain data. CBDT decoding not only generates
higher-quality texts than MAP decoding, but also the combination of MBR and
CBDT decoding outperformed MBR decoding in seven domain De--En and
Ja$\leftrightarrow$En translation tasks and image captioning tasks on MSCOCO
and nocaps datasets.

</details>


### [51] [HistoryBankQA: Multilingual Temporal Question Answering on Historical Events](https://arxiv.org/abs/2509.12720)
*Biswadip Mandal,Anant Khandelwal,Manish Gupta*

Main category: cs.CL

TL;DR: HistoryBank是一个包含1000万条历史事件的多语言数据库，旨在弥补现有历史事件数据集在规模、多语言覆盖和对古代事件的关注方面的不足。它还包含一个跨语言的时间推理问答基准，用于评估大型语言模型在6种不同类型的时间推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLMs）的时间推理能力基准测试相对有限，现有的时间推理数据集规模较小、缺乏多语言覆盖，并且更侧重于当代事件。

Method: 构建了一个包含1000万条历史事件的多语言数据库（HistoryBank），这些事件从维基百科的时间线页面和文章信息框中提取。此外，还构建了一个全面的跨语言时间推理问答基准，涵盖了6种不同的时间问答推理任务。

Result: GPT4o在所有答案类型和语言上表现最佳，Gemma-2在小型语言模型中表现优于其他模型。

Conclusion: HistoryBank提供了一个全面的资源，用于推进多语言和时间感知的历史事件自然语言理解。该项目将公开提供代码和数据集以促进进一步研究。

Abstract: Temporal reasoning about historical events is a critical skill for NLP tasks
like event extraction, historical entity linking, temporal question answering,
timeline summarization, temporal event clustering and temporal natural language
inference. Yet efforts on benchmarking temporal reasoning capabilities of large
language models (LLMs) are rather limited. Existing temporal reasoning datasets
are limited in scale, lack multilingual coverage and focus more on contemporary
events. To address these limitations, we present HistoryBank, a multilingual
database of 10M+ historical events extracted from Wikipedia timeline pages and
article infoboxes. Our database provides unprecedented coverage in both
historical depth and linguistic breadth with 10 languages. Additionally, we
construct a comprehensive question answering benchmark for temporal reasoning
across all languages. This benchmark covers a diverse set of 6 temporal QA
reasoning tasks, and we evaluate a suite of popular language models
(LLaMA-3-8B, Mistral-7B, Gemma-2-9b, Qwen3-8B, GPT4o) to assess their
performance on these tasks. As expected GPT4o performs best across all answer
types and languages; Gemma-2 outperforms the other small language models. Our
work aims to provide a comprehensive resource for advancing multilingual and
temporally-aware natural language understanding of historical events. To
facilitate further research, we will make our code and datasets publicly
available upon acceptance of this paper.

</details>


### [52] [Contrastive Learning with Enhanced Abstract Representations using Grouped Loss of Abstract Semantic Supervision](https://arxiv.org/abs/2509.12771)
*Omri Suissa,Muhiim Ali,Shengmai Chen,Yinuo Cai,Shekhar Pradhan*

Main category: cs.CL

TL;DR: The paper introduces the CLEAR GLASS model and the MAGIC dataset to evaluate and improve the concept abstraction capacity of Vision-Language Models (VLMs). It uses a novel contrastive loss to encourage models to learn commonalities within groups of images and captions, leading to emergent concept abstraction capabilities and outperforming state-of-the-art models in abstract concept recognition.


<details>
  <summary>Details</summary>
Motivation: To investigate the extent of concept abstraction capacity in VLMs and develop strategies to enhance this capability by encoding higher-level conceptual information in images.

Method: Introduced a grouped image-caption dataset (MAGIC) and a novel contrastive loss function. The loss function includes an outer contrastive loss based on text-image contrastive groups and an inner loss measuring distances between instances within a group. This methodology encourages the model to create semantic representations common to all members of a group.

Result: The CLEAR GLASS model, trained with the proposed methodology, demonstrated emergent concept abstraction capacity, showing improvements in abstract concept recognition compared to state-of-the-art models, without direct exposure to higher-level concept labels during training.

Conclusion: The proposed training methodology and dataset enable VLMs to develop concept abstraction capabilities, leading to improved performance in recognizing abstract concepts.

Abstract: Humans can recognize an image as an instance of a general concept, beyond
simply identifying its objects and their relationships. In this paper, we
investigate 1. The extent to which VLMs have this concept abstraction capacity,
and 2. Strategies for encoding the sort of higher-concept information in images
that would enable the resulting VLM model (CLEAR GLASS model) to have this
capability to a greater degree. To this end, we introduce a grouped
image-caption dataset (MAGIC), which consists of several groups of image
captions and for each group a set of associated images and higher-level
conceptual labels. We use a novel contrastive loss technique to induce the
model to encode in the representation of each image (caption) in a group the
information that is common to all members of the image-caption group. Our main
contribution is a grouped contrastive loss function based on text-image
contrastive groups (outer contrastive loss) as well as an inner loss which
measures the distances between image-caption instances in the group. Our
training methodology results in the CLEAR GLASS model having the concept
abstraction capacity as an emergent capacity because the model is not exposed
to the higher-level concepts associated with each group. Instead, the training
forces the model to create for each image-caption group a semantic
representation that brings it closer to the semantic representation of the
higher-level concepts in the latent semantic space. Our experiments show that
this training methodology results in a model which shows improvement in
abstract concept recognition compared to SOTA models.

</details>


### [53] [ConvergeWriter: Data-Driven Bottom-Up Article Construction](https://arxiv.org/abs/2509.12811)
*Binquan Ji,Jiaqi Wang,Ruiting Li,Xingchen Han,Yiyang Qi,Shichao Wang,Yifei Lu,Yuantao Han,Feiliang Ren*

Main category: cs.CL

TL;DR: LLM在生成长篇、基于知识库的文档时面临挑战。本文提出一种“自下而上”的框架，先检索知识，再聚类组织，最后生成大纲和内容，以提高事实准确性和结构连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有“自上而下”的方法在生成长篇、基于知识库的文档时，存在计划与知识脱节、内容碎片化和事实不准确等问题。

Method: 提出一种“检索优先、聚类构建结构”的“自下而上”框架。首先进行详尽的迭代检索，然后使用无监督聚类算法将检索到的文档组织成“知识簇”，再基于这些簇生成大纲和文档内容。

Result: 在14B和32B参数模型上的实验结果表明，该方法性能可与最先进的方法相媲美或超越，在知识受限且要求高保真度和结构连贯性的场景下具有优势。

Conclusion: 该框架为生成可靠、结构化的长篇文档提供了一种有效的方法，能够严格限制生成内容于源材料，并主动适应知识库的范围，从而减轻幻觉风险，适用于高风险、知识密集型领域。

Abstract: Large Language Models (LLMs) have shown remarkable prowess in text
generation, yet producing long-form, factual documents grounded in extensive
external knowledge bases remains a significant challenge. Existing "top-down"
methods, which first generate a hypothesis or outline and then retrieve
evidence, often suffer from a disconnect between the model's plan and the
available knowledge, leading to content fragmentation and factual inaccuracies.
To address these limitations, we propose a novel "bottom-up," data-driven
framework that inverts the conventional generation pipeline. Our approach is
predicated on a "Retrieval-First for Knowledge, Clustering for Structure"
strategy, which first establishes the "knowledge boundaries" of the source
corpus before any generative planning occurs. Specifically, we perform
exhaustive iterative retrieval from the knowledge base and then employ an
unsupervised clustering algorithm to organize the retrieved documents into
distinct "knowledge clusters." These clusters form an objective, data-driven
foundation that directly guides the subsequent generation of a hierarchical
outline and the final document content. This bottom-up process ensures that the
generated text is strictly constrained by and fully traceable to the source
material, proactively adapting to the finite scope of the knowledge base and
fundamentally mitigating the risk of hallucination. Experimental results on
both 14B and 32B parameter models demonstrate that our method achieves
performance comparable to or exceeding state-of-the-art baselines, and is
expected to demonstrate unique advantages in knowledge-constrained scenarios
that demand high fidelity and structural coherence. Our work presents an
effective paradigm for generating reliable, structured, long-form documents,
paving the way for more robust LLM applications in high-stakes,
knowledge-intensive domains.

</details>


### [54] [Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data](https://arxiv.org/abs/2509.12853)
*Kurt Micallef,Nizar Habash,Claudia Borg*

Main category: cs.CL

TL;DR: 尽管其闪米特语根源，但马耳他语在形态、句法和词汇上都受到了罗曼语和日耳曼语的广泛影响，并且其正字法基于拉丁字母表，这使得它与近亲阿拉伯语在语言上存在差异。本研究探讨了通过跨语言增强技术，利用阿拉伯语资源支持马耳他语自然语言处理（NLP）的可行性。研究人员尝试了多种阿拉伯语文本与马耳他语对齐策略，包括不同的音译方案和机器翻译（MT）方法，并提出了一些新的音译系统以更好地表示马耳他语的正字法。通过在单语和多语模型上评估这些增强措施的影响，研究表明基于阿拉伯语的增强技术可以显著改进马耳他语的NLP任务。


<details>
  <summary>Details</summary>
Motivation: 马耳他语在闪米特语系中独树一帜，受到罗曼语和日耳曼语（特别是意大利语和英语）的显著影响。其基于拉丁字母的正字法使其与阿拉伯语等近亲语言在书写系统上存在差异。本研究旨在探索利用现有的阿拉伯语资源来支持马耳他语的自然语言处理（NLP）的潜力，以弥合这种语言上的差距。

Method: 本研究采用了跨语言增强技术，探索了多种将阿拉伯语文本数据与马耳他语对齐的策略。这些策略包括了不同的音译方案（transliteration schemes）以及机器翻译（MT）方法。此外，研究还引入了新的音译系统，旨在更准确地表示马耳他语的正字法。最后，通过在单语和多语模型上评估这些增强措施对马耳他语NLP任务的影响来衡量其有效性。

Result: 研究结果表明，通过利用阿拉伯语资源进行跨语言增强，能够显著提升马耳他语的自然语言处理（NLP）任务的表现。具体来说，研究验证了多种阿拉伯语文本与马耳他语对齐策略（包括新的音译系统和机器翻译方法）的有效性，证明了阿拉伯语增强数据对单语和多语模型的积极作用。

Conclusion: 本研究成功证明了利用阿拉伯语资源通过跨语言增强技术能够有效支持马耳他语的自然语言处理（NLP）任务。研究提出的音译方案和机器翻译方法，以及新引入的音译系统，都对提升马耳他语NLP任务的表现起到了积极作用，为马耳他语NLP领域的研究和应用提供了新的途径。

Abstract: Maltese is a unique Semitic language that has evolved under extensive
influence from Romance and Germanic languages, particularly Italian and
English. Despite its Semitic roots, its orthography is based on the Latin
script, creating a gap between it and its closest linguistic relatives in
Arabic. In this paper, we explore whether Arabic-language resources can support
Maltese natural language processing (NLP) through cross-lingual augmentation
techniques. We investigate multiple strategies for aligning Arabic textual data
with Maltese, including various transliteration schemes and machine translation
(MT) approaches. As part of this, we also introduce novel transliteration
systems that better represent Maltese orthography. We evaluate the impact of
these augmentations on monolingual and mutlilingual models and demonstrate that
Arabic-based augmentation can significantly benefit Maltese NLP tasks.

</details>


### [55] [Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents](https://arxiv.org/abs/2509.12876)
*Fuyu Xing,Zimu Wang,Wei Wang,Haiyang Zhang*

Main category: cs.CL

TL;DR: 该论文首次系统评估了大型视觉语言模型（LVLM）在多媒体事件抽取（M2E2）任务上的表现，发现在少样本设置下，LVLM在视觉任务上表现优于文本任务，而通过LoRA进行微调能显著提升性能，并且跨媒体融合具有协同效应，但模型在语义精确性、定位和跨媒体关联方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 多媒体内容的激增需要有效的多媒体事件抽取（M2E2）系统，而大型视觉语言模型（LVLM）在M2E2任务上的应用尚待探索。

Method: 对DeepSeek-VL2和Qwen-VL等代表性LVLM在M2E2数据集上进行系统评估，涵盖纯文本、纯图像和跨媒体子任务，并在少样本提示和微调两种设置下进行评估。

Result: 少样本LVLM在视觉任务上表现优异，但在文本任务上表现不佳；使用LoRA进行微调可显著提升LVLM性能；跨媒体融合模式能达到优越的性能。

Conclusion: LVLM在M2E2任务中，特别是在结合多模态信息时，展现出巨大潜力，但仍需解决语义精确性、定位和跨媒体关联等方面的挑战。

Abstract: The proliferation of multimedia content necessitates the development of
effective Multimedia Event Extraction (M2E2) systems. Though Large
Vision-Language Models (LVLMs) have shown strong cross-modal capabilities,
their utility in the M2E2 task remains underexplored. In this paper, we present
the first systematic evaluation of representative LVLMs, including DeepSeek-VL2
and the Qwen-VL series, on the M2E2 dataset. Our evaluations cover text-only,
image-only, and cross-media subtasks, assessed under both few-shot prompting
and fine-tuning settings. Our key findings highlight the following valuable
insights: (1) Few-shot LVLMs perform notably better on visual tasks but
struggle significantly with textual tasks; (2) Fine-tuning LVLMs with LoRA
substantially enhances model performance; and (3) LVLMs exhibit strong synergy
when combining modalities, achieving superior performance in cross-modal
settings. We further provide a detailed error analysis to reveal persistent
challenges in areas such as semantic precision, localization, and cross-modal
grounding, which remain critical obstacles for advancing M2E2 capabilities.

</details>


### [56] [The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations](https://arxiv.org/abs/2509.12886)
*Yubo Zhu,Dongrui Liu,Zecheng Lin,Wei Tong,Sheng Zhong,Jing Shao*

Main category: cs.CL

TL;DR: 该研究提出了一种新方法，仅利用目标大语言模型（LLM）的隐藏表示来估计输入问题的难度，避免了现有方法的高计算成本或泛化性问题。该方法将令牌生成过程建模为马尔可夫链，并定义了一个价值函数来估计给定任何隐藏状态的预期输出质量，从而能够仅基于初始隐藏状态进行高效准确的难度估计，无需生成任何输出令牌。实验证明该方法在文本和多模态任务上均优于现有方法，并成功应用于指导自洽性、N选最优和自精炼等自适应推理策略，以更少的生成令牌提高了推理效率。


<details>
  <summary>Details</summary>
Motivation: 准确评估大型语言模型（LLM）的性能和实现自适应推理需要估计LLM感知到的输入问题难度。现有方法计算成本高或泛化性差。

Method: 将令牌级生成过程建模为马尔可夫链，并定义一个价值函数来估计给定任何隐藏状态的预期输出质量。该方法仅基于初始隐藏状态进行难度估计，无需生成任何输出令牌。

Result: 在文本和多模态任务上，该方法在难度估计方面持续优于现有基线。将难度估计应用于自洽性、N选最优和自精炼等自适应推理策略，可以减少生成的令牌数量，提高推理效率。

Conclusion: 该研究提出了一种高效且准确的LLM输入问题难度估计新方法，仅使用模型的隐藏表示，并展示了其在提高自适应推理效率方面的有效性。

Abstract: Estimating the difficulty of input questions as perceived by large language
models (LLMs) is essential for accurate performance evaluation and adaptive
inference. Existing methods typically rely on repeated response sampling,
auxiliary models, or fine-tuning the target model itself, which may incur
substantial computational costs or compromise generality. In this paper, we
propose a novel approach for difficulty estimation that leverages only the
hidden representations produced by the target LLM. We model the token-level
generation process as a Markov chain and define a value function to estimate
the expected output quality given any hidden state. This allows for efficient
and accurate difficulty estimation based solely on the initial hidden state,
without generating any output tokens. Extensive experiments across both textual
and multimodal tasks demonstrate that our method consistently outperforms
existing baselines in difficulty estimation. Moreover, we apply our difficulty
estimates to guide adaptive reasoning strategies, including Self-Consistency,
Best-of-N, and Self-Refine, achieving higher inference efficiency with fewer
generated tokens.

</details>


### [57] [Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings](https://arxiv.org/abs/2509.12892)
*Shiyu Li,Yang Tang,Ruijie Liu,Shi-Zhe Chen,Xi Chen*

Main category: cs.CL

TL;DR: Conan-embedding-v2是一个从头开始训练和微调的新型1.4B参数LLM，旨在解决现有LLM在文本嵌入任务中存在的预训练、多语言和训练目标差异问题，通过引入新闻数据、多语言对、跨语言检索数据集、软掩码机制和动态难负例挖掘，在MTEB和中文MTEB上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在文本嵌入任务中存在数据（预训练）、多语言和训练目标（因果掩码与双向掩码、token级损失与句子级损失）的差异，导致LoRA等微调方法受限，全微调效果不佳。

Method: 1. 预训练阶段：添加新闻数据和多语言对，以弥合数据差距。2. 提出跨语言检索数据集，以更好地整合不同语言的嵌入。3. 引入软掩码机制，逐步转换因果掩码和双向掩码。4. 提出动态难负例挖掘方法，以暴露模型于更难的负例。

Result: Conan-embedding-v2在Massive Text Embedding Benchmark (MTEB) 和中文MTEB (2025年5月19日) 上取得了SOTA性能，尽管参数量仅为1.4B。

Conclusion: Conan-embedding-v2通过解决LLM在文本嵌入任务中的预训练、多语言和训练目标差异，成功实现了高效且性能优越的文本嵌入。

Abstract: Large language models (LLMs) have recently demonstrated excellent performance
in text embedding tasks. Previous work usually use LoRA to fine-tune existing
LLMs, which are limited by the data and training gap between LLMs and embedding
models. In this work, we introduce Conan-embedding-v2, a new 1.4B-parameter LLM
trained from scratch and fine-tuned as a text embedder. First, we add news data
and multilingual pairs for LLM pretraining to bridge the data gap. Based on
this, we propose a cross-lingual retrieval dataset that enables the LLM to
better integrate embeddings across different languages. Second, whereas LLMs
use a causal mask with token-level loss, embedding models use a bidirectional
mask with sentence-level loss. This training gap makes full fine-tuning less
effective than LoRA. We introduce a soft-masking mechanism to gradually
transition between these two types of masks, enabling the model to learn more
comprehensive representations. Based on this, we propose a dynamic hard
negative mining method that exposes the model to more difficult negative
examples throughout the training process. Being intuitive and effective, with
only approximately 1.4B parameters, Conan-embedding-v2 achieves SOTA
performance on both the Massive Text Embedding Benchmark (MTEB) and Chinese
MTEB (May 19, 2025).

</details>


### [58] [All Roads Lead to Rome: Graph-Based Confidence Estimation for Large Language Model Reasoning](https://arxiv.org/abs/2509.12908)
*Caiqi Zhang,Chang Shu,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 提出一种新的基于图的置信度估计方法，用于解决大型语言模型（LLMs）在推理任务中的置信度不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）置信度估计方法主要针对事实性问答任务，在推理任务上的泛化能力不足。

Method: 将推理路径建模为有向图，并利用图的中心性、路径收敛性和路径加权等图属性来估计置信度。该方法是无需训练的。

Result: 在两个LLMs和三个推理数据集上的实验表明，该方法提高了置信度估计的准确性，并增强了在两个下游任务上的性能。

Conclusion: 提出的基于图的置信度估计方法能够有效解决LLMs在推理任务中的置信度估计问题，并提升其可靠性。

Abstract: Confidence estimation is essential for the reliable deployment of large
language models (LLMs). Existing methods are primarily designed for factual QA
tasks and often fail to generalize to reasoning tasks. To address this gap, we
propose a set of training-free, graph-based confidence estimation methods
tailored to reasoning tasks. Our approach models reasoning paths as directed
graphs and estimates confidence by exploiting graph properties such as
centrality, path convergence, and path weighting. Experiments with two LLMs on
three reasoning datasets demonstrate improved confidence estimation and
enhanced performance on two downstream tasks.

</details>


### [59] [Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework](https://arxiv.org/abs/2509.12955)
*Heng Zhang,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一种端到端的框架，通过挖掘学术论文全文来生成全面的、结构化的研究工作流，解决了现有方法提取碎片化信息的问题。


<details>
  <summary>Details</summary>
Motivation: 自动化生成研究工作流对于提高研究的可复现性以及加速“AI for Science”范式至关重要，但现有方法存在信息碎片化的问题。

Method: 该框架首先使用带有SciBERT的PU学习识别描述工作流的段落（F1=0.9772），然后利用带有提示学习的Flan-T5从这些段落生成工作流短语（ROUGE-1=0.4543, ROUGE-2=0.2877, ROUGE-L=0.4427），接着使用带有少样本学习的ChatGPT将短语分类为数据准备、数据处理和数据分析阶段（精确率=0.958），最后通过映射短语到文档位置生成可视化的研究工作流图。

Result: 研究成功生成了可视化的研究工作流，并对NLP语料库的工作流进行了分析，揭示了近二十年来方法学上的关键转变，例如数据分析的日益重要以及从特征工程到消融研究的转变。

Conclusion: 该研究提供了一个经过验证的自动化工作流生成技术框架，并为实证研究科学范式演变提供了一种新的、面向过程的视角。

Abstract: The automated generation of research workflows is essential for improving the
reproducibility of research and accelerating the paradigm of "AI for Science".
However, existing methods typically extract merely fragmented procedural
components and thus fail to capture complete research workflows. To address
this gap, we propose an end-to-end framework that generates comprehensive,
structured research workflows by mining full-text academic papers. As a case
study in the Natural Language Processing (NLP) domain, our paragraph-centric
approach first employs Positive-Unlabeled (PU) Learning with SciBERT to
identify workflow-descriptive paragraphs, achieving an F1-score of 0.9772.
Subsequently, we utilize Flan-T5 with prompt learning to generate workflow
phrases from these paragraphs, yielding ROUGE-1, ROUGE-2, and ROUGE-L scores of
0.4543, 0.2877, and 0.4427, respectively. These phrases are then systematically
categorized into data preparation, data processing, and data analysis stages
using ChatGPT with few-shot learning, achieving a classification precision of
0.958. By mapping categorized phrases to their document locations in the
documents, we finally generate readable visual flowcharts of the entire
research workflows. This approach facilitates the analysis of workflows derived
from an NLP corpus and reveals key methodological shifts over the past two
decades, including the increasing emphasis on data analysis and the transition
from feature engineering to ablation studies. Our work offers a validated
technical framework for automated workflow generation, along with a novel,
process-oriented perspective for the empirical investigation of evolving
scientific paradigms. Source code and data are available at:
https://github.com/ZH-heng/research_workflow.

</details>


### [60] [Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models](https://arxiv.org/abs/2509.12960)
*Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: ReLoRA在小语言模型（SLM）预训练中的表现不如标准训练，且随着模型增大，性能差距越发明显，这表明低秩更新策略可能不适用于SLM预训练。


<details>
  <summary>Details</summary>
Motivation: 研究参数高效方法（如LoRA）在小语言模型（SLM）预训练中的应用（ReLoRA），并系统性地评估其性能和学习动态。

Method: 在11M-66M参数的小型语言模型上进行ReLoRA预训练实验，并与标准训练进行对比，同时进行消融实验分析。

Result: ReLoRA在损失、困惑度和BLiMP评估指标上普遍表现不如标准训练，且在参数量较大的模型上差距更大。ReLoRA会加剧小模型固有的秩缺陷。

Conclusion: 低秩更新策略可能不易迁移到小语言模型的预训练中，表明在低计算资源条件下需要更多研究。

Abstract: Parameter-efficient methods such as LoRA have revolutionised the fine-tuning
of LLMs. Still, their extension to pretraining via ReLoRA is less well
understood, especially for small language models (SLMs), which offer lower
computational and environmental costs. This work is the first systematic study
of ReLoRA in SLMs (11M-66M parameters), evaluating both performance and
learning dynamics. Through ablation experiments, we find that ReLoRA generally
performs worse than standard training on loss, Paloma perplexity and BLiMP,
with the gap widening for the larger models. Further analysis of the learning
dynamics of the models indicates that ReLoRA reinforces the rank deficiencies
found in smaller models. These results indicate that low-rank update strategies
may not transfer easily to SLM pretraining, highlighting the need for more
research in the low-compute regime.

</details>


### [61] [Do LLMs Understand Wine Descriptors Across Cultures? A Benchmark for Cultural Adaptations of Wine Reviews](https://arxiv.org/abs/2509.12961)
*Chenye Zou,Xingyue Wen,Tianyi Hu,Qian Janice Wang,Daniel Hershcovich*

Main category: cs.CL

TL;DR: LLM 在跨文化葡萄酒评论适应方面表现不佳，需要新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 开发一种跨越文化障碍的葡萄酒评论适应方法，捕捉区域口味偏好和特定文化风味描述。

Method: 构建首个包含 8k 篇中文和 16k 篇英语评论的平行语料库，并评估了神经机器翻译基线和最先进的 LLM。提出三个以文化为导向的标准：文化邻近度、文化中立性和文化真实性。

Result: 当前模型在捕捉文化细微差别方面存在困难，尤其是在跨文化葡萄酒描述翻译方面。

Conclusion: 当前的翻译模型在处理跨文化葡萄酒评论方面存在局限性，需要进一步的研究。

Abstract: Recent advances in large language models (LLMs) have opened the door to
culture-aware language tasks. We introduce the novel problem of adapting wine
reviews across Chinese and English, which goes beyond literal translation by
incorporating regional taste preferences and culture-specific flavor
descriptors. In a case study on cross-cultural wine review adaptation, we
compile the first parallel corpus of professional reviews, containing 8k
Chinese and 16k Anglophone reviews. We benchmark both
neural-machine-translation baselines and state-of-the-art LLMs with automatic
metrics and human evaluation. For the latter, we propose three culture-oriented
criteria -- Cultural Proximity, Cultural Neutrality, and Cultural Genuineness
-- to assess how naturally a translated review resonates with target-culture
readers. Our analysis shows that current models struggle to capture cultural
nuances, especially in translating wine descriptions across different cultures.
This highlights the challenges and limitations of translation models in
handling cultural content.

</details>


### [62] [SitLLM: Large Language Models for Sitting Posture Health Understanding via Pressure Sensor Data](https://arxiv.org/abs/2509.12994)
*Jian Gao,Fufangchen Zhao,Yiyang Zhang,Danfeng Yan*

Main category: cs.CL

TL;DR: SitLLM是一个创新的框架，它结合了柔性压力传感和大型语言模型（LLM），能够实现精细的坐姿理解和个性化的健康反馈。


<details>
  <summary>Details</summary>
Motivation: 现有的坐姿监测系统在识别精度和个性化反馈方面存在不足，而不良的坐姿是导致肌肉骨骼疾病和生理功能障碍的关键因素。

Method: SitLLM包含三个核心组件：1. 高斯鲁棒传感器嵌入模块：通过将压力图划分为空间块并注入局部噪声，以实现鲁棒的特征提取。2. 提示驱动的跨模态对齐模块：利用多头交叉注意力机制和预训练词汇嵌入，将传感器嵌入重构到LLM的语义空间。3. 多上下文提示模块：融合特征级、结构级、统计级和语义级上下文信息，以指导指令理解。

Result: 该框架实现了精细的坐姿理解和生成个性化的健康导向响应。

Conclusion: SitLLM通过结合压力传感和LLM，克服了现有系统的局限性，为实现更精确、个性化的坐姿监测和反馈提供了新的途径。

Abstract: Poor sitting posture is a critical yet often overlooked factor contributing
to long-term musculoskeletal disorders and physiological dysfunctions. Existing
sitting posture monitoring systems, although leveraging visual, IMU, or
pressure-based modalities, often suffer from coarse-grained recognition and
lack the semantic expressiveness necessary for personalized feedback. In this
paper, we propose \textbf{SitLLM}, a lightweight multimodal framework that
integrates flexible pressure sensing with large language models (LLMs) to
enable fine-grained posture understanding and personalized health-oriented
response generation. SitLLM comprises three key components: (1) a
\textit{Gaussian-Robust Sensor Embedding Module} that partitions pressure maps
into spatial patches and injects local noise perturbations for robust feature
extraction; (2) a \textit{Prompt-Driven Cross-Modal Alignment Module} that
reprograms sensor embeddings into the LLM's semantic space via multi-head
cross-attention using the pre-trained vocabulary embeddings; and (3) a
\textit{Multi-Context Prompt Module} that fuses feature-level, structure-level,
statistical-level, and semantic-level contextual information to guide
instruction comprehension.

</details>


### [63] [Multi-Model Synthetic Training for Mission-Critical Small Language Models](https://arxiv.org/abs/2509.13047)
*Nolan Platt,Pragyansmita Nayak*

Main category: cs.CL

TL;DR: 通过将大型语言模型（LLM）用作一次性教师，并利用多模型生成（GPT-4o 和 o3-mini）将大量的船舶跟踪记录合成为问答对，我们能够以 261 倍的成本降低成本，同时在特定领域实现了高精度。


<details>
  <summary>Details</summary>
Motivation: LLM 在专业领域的应用受到数据稀缺和复杂性的限制，需要一种降低成本并提高数据利用率的方法。

Method: 利用 GPT-4o 和 o3-mini 等多模型生成技术，将海量船舶跟踪记录（3.2 亿条 AIS 记录）合成为 21,543 个合成问答对，然后用这些数据对 Qwen2.5-7B 模型进行微调，以替代直接使用 LLM 进行推理。

Result: 微调后的 Qwen2.5-7B 模型在海事任务上达到了 75% 的准确率，其成本远低于直接使用大型模型进行推理，证明了经过适当微调的小型模型可以提供与昂贵的大型模型相当的准确性。

Conclusion: 本研究提出了一种具有高可复现性的框架，用于在人工标注不可行的领域生成合成数据集，通过将 LLM 作为一次性教师，实现了海事智能领域 261 倍的成本降低，并为专业化小型语言模型的研究和海事安全、安保运营、船舶交通管理等实际应用提供了支持。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
many domains, yet their application to specialized fields remains constrained
by the scarcity and complexity of domain-specific training data. We present a
novel approach that achieves a 261x cost reduction for maritime intelligence by
using LLMs as one-time teachers rather than using them directly for inference.
Our method transforms 3.2 billion Automatic Identification System (AIS) vessel
tracking records into 21,543 synthetic question and answer pairs through
multi-model generation (GPT-4o and o3-mini), preventing overfitting and
ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves
75% accuracy on maritime tasks, while being substantially cheaper than using a
larger model for inference. We show that smaller, cheaper models -- when fine
tuned properly -- can provide similar accuracy compared to larger models that
are prohibitively expensive. Our work contributes to the growing field of
synthetic dataset generation for specialized AI applications and presents a
highly reproducible framework for domains where manual annotation is
infeasible. Beyond expanding research in the growing field of specialized small
language models, our approach has immediate applications in maritime safety,
security operations, and vessel traffic management systems in various
industries.

</details>


### [64] [Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO](https://arxiv.org/abs/2509.13081)
*Francesco Pappone,Ruggero Marino Lazzaroni,Federico Califano,Niccolò Gentile,Roberto Marras*

Main category: cs.CL

TL;DR: LLM 在生成类人文本方面表现出色，但将其输出与教育严谨性等复杂、定性目标保持一致仍然是一个重大挑战。 标准的强化学习技术通常依赖于缓慢且昂贵的 LLM 作为评判进行评估，或者依赖于脆弱的、基于关键字的指标（如 ROUGE），这些指标无法捕捉高质量解释的语义本质。 我们提出了一种在 GRPO 框架内进行奖励塑造的新方法，该方法使用小型、高效的仅编码器 Transformer 作为语义奖励模型，基于生成解释与地面实况参考之间的余弦相似度提供密集的、语义丰富的奖励信号。 我们将此方法应用于意大利医学院入学考试模型的训练任务，在 CPT 和 SFT 之后，GRPO 结合我们的语义奖励在解释的忠实度和清晰度方面显著优于强大的 SFT 基线。


<details>
  <summary>Details</summary>
Motivation: 标准的强化学习技术通常依赖于缓慢且昂贵的 LLM 作为评判进行评估，或者依赖于脆弱的、基于关键字的指标（如 ROUGE），这些指标无法捕捉高质量解释的语义本质。

Method: 使用一个小型、高效的仅编码器 Transformer 作为语义奖励模型，基于生成解释与地面实况参考之间的余弦相似度提供密集的、语义丰富的奖励信号。 将此方法应用于意大利医学院入学考试模型的训练任务，在 CPT 和 SFT 之后。

Result: GRPO 结合我们的语义奖励在解释的忠实度和清晰度方面显著优于强大的 SFT 基线。

Conclusion: 使用轻量级编码器模型进行复杂的生成任务中的细微奖励塑造具有强大的能力。

Abstract: While Large Language Models (LLMs) excel at generating human-like text,
aligning their outputs with complex, qualitative goals like pedagogical
soundness remains a significant challenge. Standard reinforcement learning
techniques often rely on slow and expensive LLM-as-a-judge evaluations or on
brittle, keyword-based metrics like ROUGE, which fail to capture the semantic
essence of a high-quality explanation. In this work, we introduce a novel
approach to reward shaping within the Group Relative Policy Optimisation (GRPO)
framework. Our central contribution is the use of a small, efficient
encoder-only transformer as a semantic reward model. This model provides a
dense, semantically rich reward signal based on the cosine similarity between a
generated explanation and a ground-truth reference, guiding the policy towards
explanations that are not just factually correct but also structurally and
conceptually aligned with expert reasoning. We apply this method to the task of
training a model for the Italian medical-school entrance examinations,
following standard domain-adaptive continued pre-training (CPT) and supervised
fine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic
reward significantly improves explanation faithfulness and clarity over a
strong SFT baseline, showcasing the power of using lightweight encoder models
for nuanced reward shaping in complex generation tasks

</details>


### [65] [Empowering LLMs with Parameterized Skills for Adversarial Long-Horizon Planning](https://arxiv.org/abs/2509.13127)
*Sijia Cui,Shuai Xu,Aiyao He,Yanna Wang,Bo Xu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为PLAP（Plan with Language, Act with Parameter）的框架，旨在解决大型语言模型（LLM）在复杂、对抗性长时环境中的应用挑战。PLAP通过结合LLM驱动的技能规划和参数化技能库，实现了更有效的环境交互和任务执行。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的AI代理在长时环境中存在两大挑战：一是LLM直接生成低级动作的可靠性不足；二是利用LLM生成高级任务或语言指南的方法高度依赖专家经验来将其转化为具体行动。本研究旨在克服这些局限性。

Method: PLAP框架包含三个核心组件：1. 环境特定的参数化技能库；2. 由LLM驱动的技能规划器，用于选择和组合技能；3. 技能执行器，负责将规划好的参数化技能转化为可执行的动作序列。

Result: 在MicroRTS游戏环境中，基于GPT-4o的PLAP在零样本设置下超越了80%的基线代理。而基于Qwen2-72B并结合少量示例的PLAP，其表现优于顶级的脚本化代理CoacAI。研究还评估了8种不同的LLM，并发布了一个长时技能规划能力排行榜。

Conclusion: PLAP框架能够有效提升LLM在长时环境中的自主规划和执行能力，尤其在复杂和陌生的环境中表现出色。该研究为评估和改进LLM在长时任务中的表现提供了一个新的方法和基准。

Abstract: Recent advancements in Large Language Models(LLMs) have led to the
development of LLM-based AI agents. A key challenge is the creation of agents
that can effectively ground themselves in complex, adversarial long-horizon
environments. Existing methods mainly focus on (1) using LLMs as policies to
interact with the environment through generating low-level feasible actions,
and (2) utilizing LLMs to generate high-level tasks or language guides to
stimulate action generation. However, the former struggles to generate reliable
actions, while the latter relies heavily on expert experience to translate
high-level tasks into specific action sequences. To address these challenges,
we introduce the Plan with Language, Act with Parameter (PLAP) planning
framework that facilitates the grounding of LLM-based agents in long-horizon
environments. The PLAP method comprises three key components: (1) a skill
library containing environment-specific parameterized skills, (2) a skill
planner powered by LLMs, and (3) a skill executor converting the parameterized
skills into executable action sequences. We implement PLAP in MicroRTS, a
long-horizon real-time strategy game that provides an unfamiliar and
challenging environment for LLMs. The experimental results demonstrate the
effectiveness of PLAP. In particular, GPT-4o-driven PLAP in a zero-shot setting
outperforms 80% of baseline agents, and Qwen2-72B-driven PLAP, with carefully
crafted few-shot examples, surpasses the top-tier scripted agent, CoacAI.
Additionally, we design comprehensive evaluation metrics and test 6
closed-source and 2 open-source LLMs within the PLAP framework, ultimately
releasing an LLM leaderboard ranking long-horizon skill planning ability. Our
code is available at https://github.com/AI-Research-TeamX/PLAP.

</details>


### [66] [LLM Hallucination Detection: A Fast Fourier Transform Method Based on Hidden Layer Temporal Signals](https://arxiv.org/abs/2509.13154)
*Jinxin Li,Gang Tu,ShengYu Cheng,Junjie Hu,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: HSAD通过分析LLM推理过程中的隐藏表示的时间动态来检测幻觉，在多个基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有LLM幻觉检测方法受限于外部知识覆盖或静态分析，鲁棒性不足。

Method: HSAD框架通过采样隐藏层激活、应用FFT获取频域表示，并提取最强的非直流频率分量作为光谱特征，同时利用LLM的自回归特性确定最优观测点。

Result: HSAD在TruthfulQA等多个基准测试中，相比现有SOTA方法，在幻觉检测方面取得了超过10个百分点的改进。

Conclusion: HSAD通过结合推理过程建模和频域分析，为LLM的鲁棒幻觉检测建立了新范例。

Abstract: Hallucination remains a critical barrier for deploying large language models
(LLMs) in reliability-sensitive applications. Existing detection methods
largely fall into two categories: factuality checking, which is fundamentally
constrained by external knowledge coverage, and static hidden-state analysis,
that fails to capture deviations in reasoning dynamics. As a result, their
effectiveness and robustness remain limited. We propose HSAD (Hidden Signal
Analysis-based Detection), a novel hallucination detection framework that
models the temporal dynamics of hidden representations during autoregressive
generation. HSAD constructs hidden-layer signals by sampling activations across
layers, applies Fast Fourier Transform (FFT) to obtain frequency-domain
representations, and extracts the strongest non-DC frequency component as
spectral features. Furthermore, by leveraging the autoregressive nature of
LLMs, HSAD identifies optimal observation points for effective and reliable
detection. Across multiple benchmarks, including TruthfulQA, HSAD achieves over
10 percentage points improvement compared to prior state-of-the-art methods. By
integrating reasoning-process modeling with frequency-domain analysis, HSAD
establishes a new paradigm for robust hallucination detection in LLMs.

</details>


### [67] [The Few-shot Dilemma: Over-prompting Large Language Models](https://arxiv.org/abs/2509.13196)
*Yongjian Tang,Doruk Tuncel,Christian Koerner,Thomas Runkler*

Main category: cs.CL

TL;DR: 过提示（prompt中的示例过多导致LLM性能下降）挑战了上下文少样本学习的传统观念。研究者们通过一个包含随机采样、语义嵌入和TF-IDF向量三种标准少样本选择方法的提示框架，在多个LLM上进行了评估，发现过多的领域特定示例会损害某些LLM的性能。通过对TF-IDF选择和分层抽取的示例数量进行实验，确定了每种LLM的最佳示例数量，从而避免了过提示问题，并在软件需求分类任务上取得了1%的性能提升，优于现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 研究过提示现象，即提示中的过多示例如何影响大型语言模型（LLM）的少样本学习性能，挑战了传统的关于示例数量越多越好的观念。

Method: 提出一个提示框架，该框架利用随机采样、语义嵌入和TF-IDF向量三种标准少样本选择方法。在GPT-4o、GPT-3.5-turbo、DeepSeek-V3、Gemma-3、LLaMA-3.1、LLaMA-3.2和Mistral等多个LLM上评估这些方法，并使用两个真实的软件需求分类数据集进行实验。

Result: 实验结果表明，在提示中加入过多的领域特定示例会适得其反地降低某些LLM的性能。通过逐步增加TF-IDF选择和分层抽取的示例数量，确定了每种LLM的最佳示例数量，这种方法避免了过提示问题，并在功能性和非功能性需求分类上比现有技术水平提高了1%的性能。

Conclusion: 过提示是一个真实存在的现象，即过多的示例可能损害LLM的性能。研究提出的结合TF-IDF选择和分层抽取的示例选择方法，能够确定最佳示例数量，有效避免过提示问题，并在软件需求分类任务上取得了优于现有技术水平的性能。

Abstract: Over-prompting, a phenomenon where excessive examples in prompts lead to
diminished performance in Large Language Models (LLMs), challenges the
conventional wisdom about in-context few-shot learning. To investigate this
few-shot dilemma, we outline a prompting framework that leverages three
standard few-shot selection methods - random sampling, semantic embedding, and
TF-IDF vectors - and evaluate these methods across multiple LLMs, including
GPT-4o, GPT-3.5-turbo, DeepSeek-V3, Gemma-3, LLaMA-3.1, LLaMA-3.2, and Mistral.
Our experimental results reveal that incorporating excessive domain-specific
examples into prompts can paradoxically degrade performance in certain LLMs,
which contradicts the prior empirical conclusion that more relevant few-shot
examples universally benefit LLMs. Given the trend of LLM-assisted software
engineering and requirement analysis, we experiment with two real-world
software requirement classification datasets. By gradually increasing the
number of TF-IDF-selected and stratified few-shot examples, we identify their
optimal quantity for each LLM. This combined approach achieves superior
performance with fewer examples, avoiding the over-prompting problem, thus
surpassing the state-of-the-art by 1% in classifying functional and
non-functional requirements.

</details>


### [68] [Evaluating LLM Alignment on Personality Inference from Real-World Interview Data](https://arxiv.org/abs/2509.13244)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: LLMs在理解人类性格方面表现不佳，即使采用先进的提示和微调技术，预测准确性也低于0.26。


<details>
  <summary>Details</summary>
Motivation: 目前的研究缺乏对大型语言模型（LLMs）在生态学有效对话环境中解释人类性格特征的能力的探索，特别是与真实的人格评估相比。

Method: 通过在包含半结构化访谈记录和验证过的大五人格特质分数的基准上，系统地评估LLM在零样本、思维链提示、LoRA微调以及使用预训练嵌入进行回归等任务上的表现。

Result: 所有模型预测与真实人格特质之间的皮尔逊相关性均低于0.26，表明LLM与经过验证的心理学结构在对齐方面存在局限性。思维链提示的改进非常有限。

Conclusion: 当前的LLM在理解和预测人类人格特质方面存在显著挑战，需要进一步研究来改进特定特质的提示、上下文感知模型和面向对齐的微调。

Abstract: Large Language Models (LLMs) are increasingly deployed in roles requiring
nuanced psychological understanding, such as emotional support agents,
counselors, and decision-making assistants. However, their ability to interpret
human personality traits, a critical aspect of such applications, remains
unexplored, particularly in ecologically valid conversational settings. While
prior work has simulated LLM "personas" using discrete Big Five labels on
social media data, the alignment of LLMs with continuous, ground-truth
personality assessments derived from natural interactions is largely
unexamined. To address this gap, we introduce a novel benchmark comprising
semi-structured interview transcripts paired with validated continuous Big Five
trait scores. Using this dataset, we systematically evaluate LLM performance
across three paradigms: (1) zero-shot and chain-of-thought prompting with
GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA
architectures, and (3) regression using static embeddings from pretrained BERT
and OpenAI's text-embedding-3-small. Our results reveal that all Pearson
correlations between model predictions and ground-truth personality traits
remain below 0.26, highlighting the limited alignment of current LLMs with
validated psychological constructs. Chain-of-thought prompting offers minimal
gains over zero-shot, suggesting that personality inference relies more on
latent semantic representation than explicit reasoning. These findings
underscore the challenges of aligning LLMs with complex human attributes and
motivate future work on trait-specific prompting, context-aware modeling, and
alignment-oriented fine-tuning.

</details>


### [69] [ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement](https://arxiv.org/abs/2509.13282)
*Ali Salamatian,Amirhossein Abaskohi,Wan-Cyuan Fan,Mir Rayat Imtiaz Hossain,Leonid Sigal,Giuseppe Carenini*

Main category: cs.CL

TL;DR: LVLMs在图表问答方面存在问题，因为它们不像人类那样关注图表的重要区域。ChartGaze数据集和一种新的注意力机制可以解决这个问题，提高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在图表问答（CQA）方面取得了进展，但由于模型可能会关注图表中不相关的区域，因此这项任务仍然具有挑战性。

Method: 提出了ChartGaze数据集，其中包含在图表推理任务期间人类的注视模式。通过系统地比较人类和模型的注意力，研究人员发现LVLM的注意力通常与人类的注视不同。为了解决这个问题，提出了一种注视引导的注意力细化方法，使图像-文本注意力与人类的注视保持一致。

Result: 所提出的方法提高了答案的准确性和注意力的匹配度，在多个模型上均取得了高达2.56个百分点的提升。

Conclusion: 将人类的注视纳入其中可以同时提高图表相关LVLM的推理质量和可解释性。

Abstract: Charts are a crucial visual medium for communicating and representing
information. While Large Vision-Language Models (LVLMs) have made progress on
chart question answering (CQA), the task remains challenging, particularly when
models attend to irrelevant regions of the chart. In this work, we present
ChartGaze, a new eye-tracking dataset that captures human gaze patterns during
chart reasoning tasks. Through a systematic comparison of human and model
attention, we find that LVLMs often diverge from human gaze, leading to reduced
interpretability and accuracy. To address this, we propose a gaze-guided
attention refinement that aligns image-text attention with human fixations. Our
approach improves both answer accuracy and attention alignment, yielding gains
of up to 2.56 percentage points across multiple models. These results
demonstrate the promise of incorporating human gaze to enhance both the
reasoning quality and interpretability of chart-focused LVLMs.

</details>


### [70] [WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents](https://arxiv.org/abs/2509.13309)
*Zile Qiao,Guoxin Chen,Xuanzhong Chen,Donglei Yu,Wenbiao Yin,Xinyu Wang,Zhen Zhang,Baixuan Li,Huifeng Yin,Kuan Li,Rui Min,Minpeng Liao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebResearcher是一个新颖的框架，用于构建自主发现和合成外部知识的AI代理。它通过一个迭代的深度研究范式（WebResearcher）和一个可扩展的数据合成引擎（WebFrontier）来实现。WebResearcher将深度研究重新表述为马尔可夫决策过程，通过定期整合发现并维护集中的工作区来克服现有方法的局限性。WebFrontier通过工具增强的复杂性升级来生成高质量的训练数据，以系统地创建研究任务。实验表明，WebResearcher在多个基准测试中取得了最先进的性能，并且其训练数据也能提升传统方法的工具使用能力。该框架还能通过并行思维进行扩展，实现多代理的并发探索。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI代理在自主发现和合成外部知识时面临的上下文窒息和噪声污染问题，并提高其工具使用能力和知识构建能力。

Method: 1. WebResearcher：将深度研究重新表述为马尔可夫决策过程，代理会定期整合发现到不断发展的报告中，并维护集中的工作区。 2. WebFrontier：一个可扩展的数据合成引擎，通过工具增强的复杂性升级来生成高质量的训练数据，以系统地创建研究任务。

Result: WebResearcher在6个具有挑战性的基准测试中取得了最先进的性能，甚至超越了前沿的专有系统。此外，该框架生成的训练数据显著增强了传统单上下文方法的工具使用能力。

Conclusion: WebResearcher框架能够有效地构建自主发现和合成知识的AI代理，克服了现有方法的局限性，并在多项基准测试中取得了优于现有系统的性能。该方法还能通过并行思维进行扩展，以实现更全面的结论。

Abstract: Recent advances in deep-research systems have demonstrated the potential for
AI agents to autonomously discover and synthesize knowledge from external
sources. In this paper, we introduce WebResearcher, a novel framework for
building such agents through two key components: (1) WebResearcher, an
iterative deep-research paradigm that reformulates deep research as a Markov
Decision Process, where agents periodically consolidate findings into evolving
reports while maintaining focused workspaces, overcoming the context
suffocation and noise contamination that plague existing mono-contextual
approaches; and (2) WebFrontier, a scalable data synthesis engine that
generates high-quality training data through tool-augmented complexity
escalation, enabling systematic creation of research tasks that bridge the gap
between passive knowledge recall and active knowledge construction. Notably, we
find that the training data from our paradigm significantly enhances tool-use
capabilities even for traditional mono-contextual methods. Furthermore, our
paradigm naturally scales through parallel thinking, enabling concurrent
multi-agent exploration for more comprehensive conclusions. Extensive
experiments across 6 challenging benchmarks demonstrate that WebResearcher
achieves state-of-the-art performance, even surpassing frontier proprietary
systems.

</details>


### [71] [Scaling Agents via Continual Pre-training](https://arxiv.org/abs/2509.13310)
*Liangcai Su,Zhen Zhang,Guangyu Li,Zhuo Chen,Chenxi Wang,Maojia Song,Xinyu Wang,Kuan Li,Jialong Wu,Xuanzhong Chen,Zile Qiao,Zhongwang Zhang,Huifeng Yin,Shihao Cai,Runnan Fang,Zhengwei Tao,Wenbiao Yin,Chenxiong Qian,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: LLMs在解决复杂问题方面能力不足，尤其是在开源实现中。我们提出了Agentic Continual Pre-training（Agentic CPT）来构建强大的agentic基础模型，并开发了AgentFounder模型，在10个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs在agentic任务上表现不佳，因为它们需要在进行后训练时同时学习agentic行为并与专家演示对齐，这会产生根本性的优化冲突。

Method: 提出Agentic Continual Pre-training（Agentic CPT），并将此方法应用于构建名为AgentFounder的深层研究代理模型。

Result: AgentFounder-30B在10个基准测试中取得了最先进的性能，并在BrowseComp-en（39.9%）、BrowseComp-zh（43.3%）和HLE（31.5% Pass@1）上展现了强大的工具使用能力。

Conclusion: Agentic CPT的提出能够解决现有LLMs在agentic任务上的不足，并构建出强大的agentic基础模型，AgentFounder是该方法的成功实例。

Abstract: Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon general-purpose foundation
models consistently underperform in agentic tasks, particularly in open-source
implementations. We identify the root cause: the absence of robust agentic
foundation models forces models during post-training to simultaneously learn
diverse agentic behaviors while aligning them to expert demonstrations, thereby
creating fundamental optimization tensions. To this end, we are the first to
propose incorporating Agentic Continual Pre-training (Agentic CPT) into the
deep research agents training pipeline to build powerful agentic foundational
models. Based on this approach, we develop a deep research agent model named
AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve
state-of-the-art performance while retains strong tool-use ability, notably
39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.

</details>


### [72] [Towards General Agentic Intelligence via Environment Scaling](https://arxiv.org/abs/2509.13311)
*Runnan Fang,Shihao Cai,Baixuan Li,Jialong Wu,Guangyu Li,Wenbiao Yin,Xinyu Wang,Xiaobin Wang,Liangcai Su,Zhen Zhang,Shibin Wu,Zhengwei Tao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 通过扩展训练环境来提高大型语言模型在现实世界应用中的通用智能和函数调用能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用需要大型语言模型具备精确、鲁棒的函数调用能力，这需要智能体通过在不同环境中进行交互来发展这些能力。而智能体的函数调用能力又与其训练环境的多样性密切相关。

Method: 设计了一个可扩展的框架，该框架可自动构建异构的、完全模拟的环境，系统地拓宽了函数调用场景的空间。并采用两阶段的智能体微调策略：首先赋予智能体基本的智能体能力，然后针对特定领域进行专门化训练。

Result: 在AgentScaler上进行的广泛实验表明，我们训练的模型AgentScaler显著增强了模型的函数调用能力。评估基准包括tau-bench、tau2-Bench和ACEBench。

Conclusion: 本研究通过扩展环境，为推进通用智能体智能迈出了重要一步，并提出了一种名为AgentScaler的解决方案，显著提高了智能体的函数调用能力。

Abstract: Advanced agentic intelligence is a prerequisite for deploying Large Language
Models in practical, real-world applications. Diverse real-world APIs demand
precise, robust function-calling intelligence, which needs agents to develop
these capabilities through interaction in varied environments. The breadth of
function-calling competence is closely tied to the diversity of environments in
which agents are trained. In this work, we scale up environments as a step
towards advancing general agentic intelligence. This gives rise to two central
challenges: (i) how to scale environments in a principled manner, and (ii) how
to effectively train agentic capabilities from experiences derived through
interactions with these environments. To address these, we design a scalable
framework that automatically constructs heterogeneous environments that are
fully simulated, systematically broadening the space of function-calling
scenarios. We further adapt a two-phase agent fine-tuning strategy: first
endowing agents with fundamental agentic capabilities, then specializing them
for domain-specific contexts. Extensive experiments on agentic benchmarks,
tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model,
AgentScaler, significantly enhances the function-calling capability of models.

</details>


### [73] [WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research](https://arxiv.org/abs/2509.13312)
*Zijian Li,Xin Guan,Bo Zhang,Shen Huang,Houquan Zhou,Shaopeng Lai,Ming Yan,Yong Jiang,Pengjun Xie,Fei Huang,Jun Zhang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebWeaver是一个创新的双代理框架，通过模拟人类研究过程来解决开放式深度研究（OEDR）中的信息综合和报告生成问题，克服了现有方法的局限性，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前开放式深度研究（OEDR）方法存在静态研究流程和单次生成模式的局限性，导致规划与证据获取脱节，以及“中间丢失”和幻觉等长上下文失败问题。

Method: 提出了一种名为WebWeaver的新型双代理框架。该框架包含一个规划器和一个写作者。规划器在一个动态周期中运行，迭代地交织证据获取和大纲优化，以生成全面的、与来源相关的、链接到证据记忆库的大纲。写作者执行一个分层检索和写作过程，分段撰写报告，通过仅检索每个部分所需的相关证据来有效缓解长上下文问题。

Result: WebWeaver框架在DeepResearch Bench、DeepConsult和DeepResearchGym等主要的OEDR基准测试中均达到了新的最先进水平。

Conclusion: 实验结果验证了以人类为中心、迭代的方法是至关重要的，并且自适应规划和专注综合对于生成高质量、可靠和结构良好的报告至关重要。

Abstract: This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold limitations: static research
pipelines that decouple planning from evidence acquisition and one-shot
generation paradigms that easily suffer from long-context failure issues like
"loss in the middle" and hallucinations. To address these challenges, we
introduce WebWeaver, a novel dual-agent framework that emulates the human
research process. The planner operates in a dynamic cycle, iteratively
interleaving evidence acquisition with outline optimization to produce a
comprehensive, source-grounded outline linking to a memory bank of evidence.
The writer then executes a hierarchical retrieval and writing process,
composing the report section by section. By performing targeted retrieval of
only the necessary evidence from the memory bank for each part, it effectively
mitigates long-context issues. Our framework establishes a new state-of-the-art
across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and
DeepResearchGym. These results validate our human-centric, iterative
methodology, demonstrating that adaptive planning and focused synthesis are
crucial for producing high-quality, reliable, and well-structured reports.

</details>


### [74] [ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization](https://arxiv.org/abs/2509.13313)
*Xixi Wu,Kuan Li,Yida Zhao,Liwen Zhang,Litu Ou,Huifeng Yin,Zhongwang Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Minhao Cheng,Shuai Wang,Hong Cheng,Jingren Zhou*

Main category: cs.CL

TL;DR: ReSum是一种新的范式，通过周期性地对上下文进行摘要来克服LLM网络代理中的上下文窗口限制，从而实现无限探索。


<details>
  <summary>Details</summary>
Motivation: ReAct等范式中的上下文窗口限制会阻碍基于LLM的网络代理在处理复杂查询时的表现，因为这些查询需要广泛的搜索周期，并且会快速耗尽上下文预算。

Method: ReSum通过将不断增长的交互历史转换为紧凑的推理状态来实现这一点，从而在不超出上下文限制的情况下保持对先前发现的认识。为了适应这种范式，提出了ReSum-GRPO，它结合了GRPO、分段轨迹训练和优势广播，以使代理能够进行以摘要为条件的推理。

Result: ReSum在三个基准上平均比ReAct提高了4.5%，ReSum-GRPO的训练进一步提高了8.2%。特别是，我们的WebResummer-30B在BrowseComp-zh和BrowseComp-en上的Pass@1分别达到了33.3%和18.3%，超过了现有的开源网络代理。

Conclusion: ReSum范式通过周期性地对上下文进行摘要来克服LLM网络代理中的上下文窗口限制，从而实现无限探索，并取得显著的改进。

Abstract: Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involving multiple entities, intertwined
relationships, and high uncertainty demand extensive search cycles that rapidly
exhaust context budgets before reaching complete solutions. To overcome this
challenge, we introduce ReSum, a novel paradigm that enables indefinite
exploration through periodic context summarization. ReSum converts growing
interaction histories into compact reasoning states, maintaining awareness of
prior discoveries while bypassing context constraints. For paradigm adaptation,
we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and
advantage broadcasting to familiarize agents with summary-conditioned
reasoning. Extensive experiments on web agents of varying scales across three
benchmarks demonstrate that ReSum delivers an average absolute improvement of
4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO
training. Notably, with only 1K training samples, our WebResummer-30B (a
ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on
BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web
agents.

</details>


### [75] [Do Natural Language Descriptions of Model Activations Convey Privileged Information?](https://arxiv.org/abs/2509.13316)
*Millicent Li,Alberto Mario Ceballos Arroyo,Giordano Rogers,Naomi Saphra,Byron C. Wallace*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent interpretability methods have proposed to translate LLM internal
representations into natural language descriptions using a second verbalizer
LLM. This is intended to illuminate how the target model represents and
operates on inputs. But do such activation verbalization approaches actually
provide privileged knowledge about the internal workings of the target model,
or do they merely convey information about its inputs? We critically evaluate
popular verbalization methods across datasets used in prior work and find that
they succeed at benchmarks without any access to target model internals,
suggesting that these datasets are not ideal for evaluating verbalization
methods. We then run controlled experiments which reveal that verbalizations
often reflect the parametric knowledge of the verbalizer LLM which generated
them, rather than the activations of the target LLM being decoded. Taken
together, our results indicate a need for targeted benchmarks and experimental
controls to rigorously assess whether verbalization methods provide meaningful
insights into the operations of LLMs.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [76] [A Scalable Architecture for Efficient Multi-bit Fully Homomorphic Encryption](https://arxiv.org/abs/2509.12676)
*Jiaao Ma,Ceyu Xu,Lisa Wu Wills*

Main category: cs.AR

TL;DR: Taurus是一个硬件加速器，可提高多比特TFHE的效率，支持高达10位的密文，并首次在大型语言模型（如GPT-2）上实现了隐私保护推理。


<details>
  <summary>Details</summary>
Motivation: 在云计算时代，保护隐私的计算卸载至关重要，但全同态加密（FHE）的计算复杂性带来了显著的服务器端开销。现有的FHE方案（如CKKS和TFHE）在效率和多功能性之间存在权衡，而多比特TFHE虽然提高了灵活性和性能，但受限于较窄的数字表示，限制了其在需要更宽数字表示的应用中的使用。

Method: 提出了一种名为Taurus的硬件加速器，它通过新型FFT单元和密钥重用策略优化内存带宽，支持高达10位的密文。此外，还提出了一种具有操作去重功能的编译器，以提高内存利用率。

Result: Taurus在CPU上实现了高达2600倍的加速，在GPU上实现了高达1200倍的加速，并且比以前最先进的TFHE加速器快7倍。它还首次在GPT-2等大型语言模型上实现了隐私保护推理。

Conclusion: Taurus通过提高多比特TFHE的效率和支持更宽的数字表示，解决了现有FHE方案的局限性，使得在云环境中进行隐私保护计算的应用更加实用和可扩展。

Abstract: In the era of cloud computing, privacy-preserving computation offloading is
crucial for safeguarding sensitive data. Fully Homomorphic Encryption (FHE)
enables secure processing of encrypted data, but the inherent computational
complexity of FHE operations introduces significant computational overhead on
the server side. FHE schemes often face a tradeoff between efficiency and
versatility. While the CKKS scheme is highly efficient for polynomial
operations, it lacks the flexibility of the binary TFHE (Torus-FHE) scheme,
which offers greater versatility but at the cost of efficiency. The recent
multi-bit TFHE extension offers greater flexibility and performance by
supporting native non-polynomial operations and efficient integer processing.
However, current implementations of multi-bit TFHE are constrained by its
narrower numeric representation, which prevents its adoption in applications
requiring wider numeric representations.
  To address this challenge, we introduce Taurus, a hardware accelerator
designed to enhance the efficiency of multi-bit TFHE computations. Taurus
supports ciphertexts up to 10 bits by leveraging novel FFT units and optimizing
memory bandwidth through key reuse strategies. We also propose a compiler with
operation deduplication to improve memory utilization. Our experiment results
demonstrate that Taurus achieves up to 2600x speedup over a CPU, 1200x speedup
over a GPU, and up to 7x faster compared to the previous state-of-the-art TFHE
accelerator. Moreover, Taurus is the first accelerator to demonstrate
privacy-preserving inference with large language models such as GPT-2. These
advancements enable more practical and scalable applications of
privacy-preserving computation in cloud environments.

</details>


### [77] [HPIM: Heterogeneous Processing-In-Memory-based Accelerator for Large Language Models Inference](https://arxiv.org/abs/2509.12993)
*Cenlin Duan,Jianlei Yang,Rubing Yang,Yikun Wang,Yiou Wang,Lingkun Long,Yingjie Qi,Xiaolin He,Ao Zhou,Xueyan Wang,Weisheng Zhao*

Main category: cs.AR

TL;DR: HPIM是一种创新的内存中心异构处理内存（PIM）加速器，通过结合SRAM-PIM和HBM-PIM子系统，并采用软件硬件协同设计方法，显著加速大型语言模型（LLM）推理过程，解决了传统GPU在LLM推理中遇到的内存瓶颈和资源利用率低的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的部署面临巨大挑战，主要源于其巨大的内存占用、低计算强度以及对低延迟的严格要求，尤其是在自回归解码阶段。传统的以计算为中心的加速器（如GPU）在处理这些内存密集型工作负载时，存在资源利用率低下和内存带宽瓶颈的问题。

Method: HPIM采用软件硬件协同设计方法，结合了专用的编译器框架和异构硬件架构。它根据工作负载特性进行智能分区：将延迟关键的注意力操作映射到SRAM-PIM子系统，以利用其超低延迟和高计算灵活性；将权重密集型的GEMV计算分配给HBM-PIM子系统，以利用其高内部带宽和大存储容量。此外，HPIM引入了SRAM-PIM和HBM-PIM子系统之间的紧密耦合流水线策略，以最大化令牌内并行性，从而显著缓解自回归解码阶段的串行依赖性。

Result: 通过详细的周期精确仿真评估，HPIM的性能显著优于最先进的加速器。与NVIDIA A100 GPU相比，HPIM实现了高达22.8倍的峰值加速。此外，HPIM在性能上超越了同类PIM加速器，证明了其作为加速大规模LLM推理的高效且可扩展的解决方案的潜力。

Conclusion: HPIM通过其创新的内存中心异构PIM架构和软件硬件协同设计，有效解决了LLM推理中的内存瓶颈和延迟问题，在性能上取得了显著突破，为LLM推理提供了一个高效、实用且可扩展的解决方案。

Abstract: The deployment of large language models (LLMs) presents significant
challenges due to their enormous memory footprints, low arithmetic intensity,
and stringent latency requirements, particularly during the autoregressive
decoding stage. Traditional compute-centric accelerators, such as GPUs, suffer
from severe resource underutilization and memory bandwidth bottlenecks in these
memory-bound workloads. To overcome these fundamental limitations, we propose
HPIM, the first memory-centric heterogeneous Processing-In-Memory (PIM)
accelerator that integrates SRAM-PIM and HBM-PIM subsystems designed
specifically for LLM inference. HPIM employs a software-hardware co-design
approach that combines a specialized compiler framework with a heterogeneous
hardware architecture. It intelligently partitions workloads based on their
characteristics: latency-critical attention operations are mapped to the
SRAM-PIM subsystem to exploit its ultra-low latency and high computational
flexibility, while weight-intensive GEMV computations are assigned to the
HBM-PIM subsystem to leverage its high internal bandwidth and large storage
capacity. Furthermore, HPIM introduces a tightly coupled pipeline strategy
across SRAM-PIM and HBM-PIM subsystems to maximize intra-token parallelism,
thereby significantly mitigating serial dependency of the autoregressive
decoding stage. Comprehensive evaluations using a cycle-accurate simulator
demonstrate that HPIM significantly outperforms state-of-the-art accelerators,
achieving a peak speedup of up to 22.8x compared to the NVIDIA A100 GPU.
Moreover, HPIM exhibits superior performance over contemporary PIM-based
accelerators, highlighting its potential as a highly practical and scalable
solution for accelerating large-scale LLM inference.

</details>


### [78] [Orthrus: Dual-Loop Automated Framework for System-Technology Co-Optimization](https://arxiv.org/abs/2509.13029)
*Yi Ren,Baokang Peng,Chenhao Xue,Kairong Guo,Yukun Wang,Guoyao Cheng,Yibo Lin,Lining Zhang,Guangyu Sun*

Main category: cs.AR

TL;DR: STCO框架Orthrus通过系统和技术协同优化，显著提升了VLSI设计的性能和功耗效率。


<details>
  <summary>Details</summary>
Motivation: 摩尔定律收益递减，迫切需要STCO方法来维持VLSI行业的发展。现有研究在STCO方法论方面不足，尤其是在跨设计层级信息鸿沟和设计空间探索方面。

Method: 提出了一种名为Orthrus的双循环自动化框架，结合了系统级和技术级优化。系统级优化：利用系统统计信息优先优化关键标准单元，并通过贝叶斯优化的Pareto前沿法线引导技术级优化。技术级优化：利用系统感知信息优化标准单元库，并使用神经网路辅助的差分进化算法优化技术参数。

Result: 在7nm工艺下，与基线方法相比，Orthrus实现了12.5%的 iso-power 延迟降低和61.4%的 iso-delay 功耗节省，在STCO领域确立了新的Pareto前沿。

Conclusion: Orthrus框架能够有效地实现系统-技术协同优化，显著提升了设计性能和能效。

Abstract: With the diminishing return from Moore's Law, system-technology
co-optimization (STCO) has emerged as a promising approach to sustain the
scaling trends in the VLSI industry. By bridging the gap between system
requirements and technology innovations, STCO enables customized optimizations
for application-driven system architectures. However, existing research lacks
sufficient discussion on efficient STCO methodologies, particularly in
addressing the information gap across design hierarchies and navigating the
expansive cross-layer design space. To address these challenges, this paper
presents Orthrus, a dual-loop automated framework that synergizes system-level
and technology-level optimizations. At the system level, Orthrus employs a
novel mechanism to prioritize the optimization of critical standard cells using
system-level statistics. It also guides technology-level optimization via the
normal directions of the Pareto frontier efficiently explored by Bayesian
optimization. At the technology level, Orthrus leverages system-aware insights
to optimize standard cell libraries. It employs a neural network-assisted
enhanced differential evolution algorithm to efficiently optimize technology
parameters. Experimental results on 7nm technology demonstrate that Orthrus
achieves 12.5% delay reduction at iso-power and 61.4% power savings at
iso-delay over the baseline approaches, establishing new Pareto frontiers in
STCO.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [79] [Simplified equations for the semi-localized transitions (SLT) model](https://arxiv.org/abs/2509.12463)
*Rafał Porzeziński,Arkadiusz Mandowski*

Main category: physics.app-ph

TL;DR: SLT-QE5是SLT模型的简化版，减少了微分方程数量，在大部分情况下近似效果都很好。


<details>
  <summary>Details</summary>
Motivation: 需要简化SLT模型以减少计算复杂度。

Method: 推导了SLT模型的简化版本SLT-QE5，将微分方程数量从七个减少到五个。

Result: 数值计算表明，SLT-QE5近似在除特定情况外（激活能大幅减少且重捕获系数非常低）都具有很好的近似效果。

Conclusion: SLT-QE5模型在大多数情况下是一个有效的简化模型。

Abstract: A simplified version of the semi-localized transitions (SLT) model is
derived. The SLT-QE5 approximation reduces the number of differential equations
from seven to five. Numerical calculations show that the approximation is very
good for various trap parameters except the case with large reduction of
activation energy during recombination to adjacent hole together with very low
retrapping coefficient.

</details>


### [80] [A 5.9 GHz Sezawa SAW Acoustic Delay Line Based on Al0.6Sc0.4N-on-Sapphire with Propagation Q-factor > 3,000](https://arxiv.org/abs/2509.12480)
*Chin-Yu Chang,Xiaolei Tong,Pedram Yousefian,Ella Klein,Xingyu Du,Roy H. Olsson III*

Main category: physics.app-ph

TL;DR: AlScN-on-sapphire 平台实现了 5.9 GHz 的高性能 SAW 延迟线，具有高 Q 因子和低损耗。


<details>
  <summary>Details</summary>
Motivation: 为了在先进的射频应用中实现高频、低损耗的 SAW ADL 器件，需要开发高性能的 SAW 延迟线。

Method: 在蓝宝石衬底上沉积了 800 nm、40% 钪合金浓度的 AlScN 薄膜，并采用单相单向换能器 (SPUDT) 电极配置，利用 Sezawa 模式设计 ADL，以实现高声学能量限制、大的机电耦合效应和更好的单向性。

Result: 制造的 ADL 器件在 5.9 GHz 频率下实现了 5,779 m/s 的群速度和低至 9.2 dB/mm 的传播损耗。所提出的 ADL 器件具有高达 3,044 的高声学传播 Q 因子，并且插入损耗在 7.6 到 18.3 dB 之间，延迟时间为 13 到 214 ns。

Conclusion: AlScN-on-sapphire 平台在实现高工作频率、低损耗的 SAW ADL 器件方面展现出巨大潜力，可满足先进射频应用的需求。

Abstract: In this work, we demonstrate a high-performance surface acoustic wave (SAW)
delay line based on a Scandium alloyed aluminum nitride (AlScN)-on-sapphire
platform operating at 5.9 GHz with an exceptionally high acoustic propagation
Q-factor. An 800 nm AlScN thin film with 40% scandium alloying concentration
was deposited on a thick sapphire substrate to achieve strong acoustic energy
confinement and large electromechanical coupling effect, thereby minimizing the
insertion loss (IL) and propagation loss (PL) of the acoustic delay line (ADL).
The proposed ADL was designed to operate in the Sezawa mode using a
Single-Phase Unidirectional Transducer (SPUDT) electrode configuration for
better unidirectionality. The fabricated ADLs with different delay lengths,
after conjugate matching, exhibited delay times spanning 13 to 214 ns and IL
ranging from 7.6 to 18.3 dB. The extracted PL reached as low as 9.2 dB/mm at
5.9 GHz, with a group velocity (v_g) of around 5,779 m/s. Based on these
results, the proposed ADLs exhibit a high acoustic propagation Q-factor of
3,044. These findings highlight the potential of AlScN-on-sapphire platforms
for high operational frequency, low-loss SAW ADL devices in advanced RF
applications.

</details>


### [81] [Thermal Transport of GaN/Substrate Heterostructures under Non-Uniform Heat Source](https://arxiv.org/abs/2509.12548)
*Ershuai Yin,Wenzhu Luo,Lei Wang,Enjian Sun,Qiang Li*

Main category: physics.app-ph

TL;DR: 非均匀热源对 GaN HEMT 的热传输有显著影响，尤其是在微尺度下，可能导致热阻显著增加，现有模型存在低估。


<details>
  <summary>Details</summary>
Motivation: GaN HEMT 中的热量集中在纳米尺度区域，需要通过异质结构耗散，但非均匀热源对热传输的影响尚不清楚。

Method: 结合第一性原理计算和蒙特卡洛模拟，开发了非均匀热源下异质结构的热传输模型，并与均匀热源进行比较。

Result: 非均匀热源对平均界面热导率影响不大，但在异质结构高度较小时，会导致局部温度分布不均匀，界面热导率在热源区域附近显著升高。热源非均匀性增加导致总热阻急剧上升，可能达到均匀热源的数倍。有限元计算低估了热阻。

Conclusion: 揭示了异质结构在非均匀热源下的热传输机制，为宽禁带半导体器件的热设计提供了理论指导。

Abstract: Heat generated in gallium nitride (GaN) high-electron-mobility transistors
(HEMTs) is often concentrated in nanoscale regions and must dissipate through
multiple heterostructures. However, the influence of non-uniform heat sources
on the thermal transport of such heterostructures remains unclear. In this
work, a thermal transport model for heterostructures under the non-uniform heat
source is developed by combining first-principles calculations with Monte Carlo
simulations. Temperature, heat flux, and spectral thermal conductance
distributions are compared between uniform and non-uniform heat sources. The
effects of heterostructure height, heat source width, and heat source height on
thermal transfer characteristics are analyzed for four typical
heterostructures: GaN/AlN, GaN/Diamond, GaN/Si, and GaN/SiC. The results reveal
that non-uniform heat sources have little effect on average interfacial thermal
conductance but induce pronounced local non-uniformity when the heterostructure
height is small. The interfacial thermal conductance near the heat source
region is significantly higher than that in other areas. As the heat source
non-uniformity increases, the total thermal resistance of the heterostructure
rises markedly, reaching several times that under uniform heat sources.
Finite-element calculations fail to capture the combined effects of non-uniform
heating and microscale dimensions, leading to a severe underestimation of
heterostructure total thermal resistance. This work reveals the thermal
transport mechanisms of heterostructures under non-uniform heat sources and
provides theoretical guidance for the thermal design of wide-bandgap
semiconductor devices.

</details>


### [82] [Morphological and Chemical Changes in Cd-free Colloidal QD-LEDs During Operation](https://arxiv.org/abs/2509.12597)
*Ruiqi Zhang,Jamie Geng,Shaun Tan,Shreyas Srinivasan,Taehyung Kim,Mayuran Saravanapavanantham,Kwang-Hee Lim,Mike Dillender,Heejae Chung,Thienan Nguyen,Karen Yang,Yongli Lu,Taegon Kim,Moungi G. Bawendi,Vladimir Bulovic*

Main category: physics.app-ph

TL;DR: 无重金属的量子点发光二极管（QD-LEDs）在亮度、色彩饱和度和效率方面表现出色，但其使用寿命有限，且降解机制尚不明确。本研究表明，InP/ZnSe/ZnS（红光）和ZnTeSe/ZnSe/ZnS（蓝光）无镉QD-LEDs在运行过程中会发生纳米尺度的形态变化，包括电子传输层（ETL）、量子点发光层和有机空穴传输层中的颗粒粗化和层变薄。同时，氧气和氢自由基在器件内产生和扩散，氧气在电极/ETL界面积累。实验还发现，在氢自由基存在下，透射电子显微镜的电子束暴露会加速ZnMgO纳米颗粒的粗化。为解决这些问题，研究提出了一种基于丙烯酸树脂的封装处理方法，通过抑制自由基形成和阻止形态变化来稳定ETL/QD层，显著提高了器件的稳定性，InP/ZnSe/ZnS和ZnTeSe/ZnSe/ZnS QD-LEDs的寿命分别提高了8倍和5000倍。该研究揭示了形态降解、层间自由基动力学和QD-LEDs不稳定性之间的因果关系，并为实现高效长寿命的无镉QD-LEDs提供了一种可扩展的封装方法。


<details>
  <summary>Details</summary>
Motivation: QD-LEDs虽然在亮度、色彩饱和度和效率方面表现出色，但其使用寿命有限，且降解机制尚不明确，限制了其广泛应用。

Method: 通过纳米尺度表征和原位透射电子显微镜，研究了InP/ZnSe/ZnS和ZnTeSe/ZnSe/ZnS无镉QD-LEDs在运行过程中的形态变化、自由基动力学以及电子束暴露对其的影响。并提出了一种丙烯酸树脂封装处理方法来改善器件稳定性。

Result: 发现QD-LEDs在运行过程中发生颗粒粗化和层变薄等形态变化，同时伴随自由基的产生、扩散和积累。电子束暴露在氢自由基存在下会加速纳米颗粒粗化。丙烯酸树脂封装处理能显著提高器件稳定性，寿命分别提高8倍和5000倍。

Conclusion: 形态降解、层间自由基动力学和QD-LEDs的不稳定性之间存在因果关系。丙烯酸树脂封装是一种有效的策略，可以显著提高无镉QD-LEDs的稳定性和使用寿命。

Abstract: Heavy metal-free quantum-dot light-emitting devices (QD-LEDs) have
demonstrated remarkable brightness, saturated color, and high efficiencies
across a broad spectral range. However, in contrast to organic LEDs (OLEDs),
QD-LED operational lifetimes remain limited, with the underlying degradation
mechanisms not fully understood. In the present study, we show that
InP/ZnSe/ZnS (red-emitting) and ZnTeSe/ZnSe/ZnS (blue-emitting) cadmium-free
colloidal QD-LEDs undergo nanoscale morphological changes during operation.
Specifically,interparticle coarsening and layer thinning are observed in the
electron transport layer (ETL) consisting of ZnMgO nanoparticles (NPs), in the
QD emissive layer, and in the organic hole transport layer. This is accompanied
by the generation and diffusion of compositional oxygen- and hydrogen-radicals
throughout the device, with oxygen accumulating at the electrode/ETL
interfance. Moreover, in situ transmission electron microscopy reveals the
electron beam exposure, in the presence of hydrogen radicals, accelerates ZnMgO
NPs coarsening. To mitigate these degradation pathway, we show that
acrylate-based resin-encapsulation treatment stabilize the ETL/QD layers by
suppressing the radical formation and halting morphology changes. This approach
achieves dramatic stability enhancements, exhibits an 8-fold and 5000-fold
lifetime improvement on InP/ZnSe/ZnS and ZnTeSe/ZnSe/ZnS QD-LEDs, respectively.
Our findings establish the causal relationships between the morphological
degradation, interlayer radical dynamics, and state-of-the-art QD-LEDs
instability, providing new insights into a scalable encapsulation treatment
that enables efficient and long-lived Cd-free QD-LEDs.

</details>


### [83] [Terahretz Channel Modeling in ULEO Satellite-to-Ground Communications](https://arxiv.org/abs/2509.12769)
*Mingxia Zhang,Wanzhu Chang,Jie Yang,Hong Liang,Yiming Zhao,Houjun Sun,Jianjun Ma*

Main category: physics.app-ph

TL;DR: 超高频(THz)频段结合超低地球轨道(ULEO)卫星可以满足卫星通信日益增长的数据流量需求。本文对ULEO-THz卫星对地通信进行了信道建模和性能评估，分析了三种不同的传输架构，并考虑了大气传播模型、频率依赖性吸收、自由空间路径损耗和区域大气变化。结果表明，在较低的THz频率下，直接卫星对地传输在QPSK调制下具有最佳性能和最大的可用带宽。


<details>
  <summary>Details</summary>
Motivation: 卫星数据流量的指数级增长对通信系统提出了超越现有微波容量限制的要求，而太赫兹(THz)频段具有巨大的带宽潜力，并且与光学系统相比具有优越的耐候性，特别是在结合超低地球轨道(ULEO)卫星部署时。

Method: 对三种不同的传输架构（直接卫星对地通信、卫星-中继-地面转发、卫星-高空基站-光纤回传）进行了全面的信道建模和性能评估。利用中国西藏和青海四个高地站点的气象数据验证了分辨率到高度的大气传播模型。分析包括了ITU-R标准的频率依赖性大气吸收、具有弯曲大气建模的自由空间路径损耗以及区域大气变化，以推导出在AWGN和Weibull衰落条件下，跨越多个THz频率的总信道路径损耗、可用带宽容量和误比特率(BER)性能。

Result: 结果表明，在较低的THz频率下，直接卫星对地传输在QPSK调制下具有最佳的实际性能和最大的可用带宽。卫星-中继-地面转发由于多次跳跃而遭受了累积损失。卫星-高空基站配置尽管具有有利的大气信道特性，但由于长距离应用中的显著光电转换损失和光纤传输损耗而变得不切实际。

Conclusion: 在超低地球轨道(ULEO)卫星通信场景下，较低频率的太赫兹(THz)频段结合直接卫星对地传输架构，在QPSK调制下能够提供最佳的性能和最大的可用带宽。多跳传输和光纤回传架构会引入不可接受的损耗，使其在这些应用中不切实际。

Abstract: The exponential growth in satellite data traffic demands communication
systems exceeding current microwave capacity limitations, while the terahertz
(THz) frequency band (0.1-10 THz) offers unprecedented bandwidth potential with
superior weather resilience compared to optical systems, particularly when
combined with ultra-low Earth orbit (ULEO) satellite deployments below 300 km
altitude. This article presents comprehensive channel modeling and performance
evaluation for ULEO-THz satellite-to-ground communications, analyzing three
distinct transmission architectures (direct satellite-to-ground,
satellite-relay-ground forwarding, and satellite-to-high altitude base station
with fiber backhaul) through altitude-resolved atmospheric propagation models
validated using year-long meteorological data from four high-altitude stations
in Tibet and Qinghai, China. The analysis incorporates frequency-dependent
atmospheric absorption using ITU-R standards, free-space path loss with curved
atmospheric modeling, and regional atmospheric variations to derive total
channel path loss, available bandwidth capacity, and bit error rate (BER)
performance under both AWGN and Weibull fading conditions across multiple THz
frequencies. Results demonstrate that direct satellite-to-ground transmission
at lower THz frequencies achieves optimal practical performance with maximum
available bandwidth under QPSK modulation, while satellite-relay-ground
forwarding suffers prohibitive cumulative losses from multiple hops, and
satellite-to-high altitude base station configurations, despite favorable
atmospheric channel characteristics, become impractical due to substantial
electro-optical conversion penalties and fiber transmission losses in long-haul
applications.

</details>


### [84] [Experimental study of the acoustic frequency-up conversion effect by nonlinear thin plates](https://arxiv.org/abs/2509.12785)
*Alexis Mousseau,Soizic Terrien,Vincent Tournat*

Main category: physics.app-ph

TL;DR: 薄板的非线性振动行为会影响声吸收效果，可以通过改变板的厚度和张力来调节。


<details>
  <summary>Details</summary>
Motivation: 利用非线性效应克服传统吸声方法的局限性。

Method: 通过实验研究薄板在不同激励水平下的非线性振动行为，并进行参数化研究。

Result: 发现在低激励水平下产生谐波，在高激励水平下产生拟周期和混沌运动；研究了板的厚度和张力对频率上转换的影响；提出了多板设计以实现宽带频率上转换。

Conclusion: 薄板的非线性振动行为（谐波、拟周期、混沌）决定了声频率上转换过程，板的厚度和张力是关键设计参数，多板结构可实现宽带吸收。

Abstract: Classical methods of sound absorption present fundamental limits that can be
overcome by using nonlinear effects. Thin clamped plates have been identified
as strongly nonlinear elements, capable of transferring the acoustic power of
an incident air-borne wave towards higher frequencies. Here, we experimentally
show that these plates exhibit different vibrational nonlinear behaviors
depending on the amplitude and frequency of the excitation signal. The lowest
excitation levels achieved lead to harmonic generation in a weakly nonlinear
regime, while higher levels produce quasi-periodic and chaotic regimes. Since
these nonlinear vibration regimes govern the acoustic frequency-up conversion
process, we investigate the influence of relevant physical and geometrical
parameters on the emergence of these nonlinear regimes. A parametric study on
plates of different thicknesses reveals that the frequency-up conversion effect
is mostly guided by the resonance of the plate at its first eigenfrequency,
which depends not only on its thickness but also on a static tension introduced
by the clamping. Finally, a design proposition involving multiple plates with
different properties is presented in order to reach a broadband frequency-up
conversion.

</details>


### [85] [A general thermodynamic model for the steady-state temperature of a photovoltaic module on the Moon](https://arxiv.org/abs/2509.13110)
*Mykhailo Koltsov,Zacharie Jehl Li-Kao*

Main category: physics.app-ph

TL;DR: 太长不看：光伏转换效率与转换器温度密切相关。在没有大气的情况下，可以通过严格的热平衡推导出转换器温度的紧凑表达式。该模型考虑了辐射平衡、光谱吸收率、热发射率、与月壤和太空的视线因子、模块电效率以及到安装座的热传导。模型可扩展至其他无大气天体和深空。


<details>
  <summary>Details</summary>
Motivation: 光伏转换效率高度依赖于转换器的温度，因此精确计算转换器温度对于优化光伏系统至关重要。

Method: 从完全光谱、双面辐射平衡出发，推导出实用的灰带（积分）表达式，用于从可测量参数估算转换器温度（Tc）。这些参数包括：平面辐照度、光谱吸收率（或宽带吸收率）、热发射率、到月壤和太空的视线因子、模块电效率以及到安装座的热传导。

Result: 提出了一种计算光伏转换器温度（Tc）的紧凑模型，该模型可以从可测量的参数中估算出Tc。

Conclusion: 所提出的模型提供了一种估算光伏转换器温度的实用方法，并且可以扩展到其他无大气天体和深空应用。

Abstract: Photovoltaic conversion is highly dependent on the converter's temperature.
In the absence of atmosphere, it can be rigorously determined using a thermal
balance leading to a compact expression. The derivation starts from a fully
spectral, two-sided radiative balance and proceeds to a practical gray-band
(integrated) expression that can be used to estimate Tc from measurable
quantities: plane-of-array irradiance, spectral absorptance (or a broadband
absorptance), thermal emissivities, view factors to the regolith and to space,
module electrical efficiency, and conduction to the mount. The model can be
extended to other airless celestial bodies and to deep space.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [86] [IsoSched: Preemptive Tile Cascaded Scheduling of Multi-DNN via Subgraph Isomorphism](https://arxiv.org/abs/2509.12208)
*Boran Zhao,Zihang Yuan,Yanbin Hu,Haiming Zhai,Haoruo Zhang,Wenzhe Zhao,Tian Xia,Pengju Ren*

Main category: cs.DC

TL;DR: 现有Tile Spatial Scheduling (TSS) 无法满足多DNN并发执行和抢占式调度的需求，我们提出了IsoSched框架，它将调度问题转化为ILP和子图同构问题，并使用LCS、基于MCTS的Ullmann算法和CSR进行优化，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度神经网络（DNN）加速器在部署时，由于需要缓存中间激活层，会产生显著的能量和延迟开销。虽然Tile Spatial Scheduling（TSS）通过将层间数据分块并通过片上链路通信来降低这些成本，但它缺乏对需要抢占的关键任务的支持。而现有的抢占方案依赖于Layer Temporal Scheduling（LTS），会带来额外的开销。因此，需要一种支持抢占且高效的TSS框架来满足新兴应用（如自动驾驶）的严格延迟要求。

Method: IsoSched框架首先将复杂拓扑图的调度问题制定为整数线性规划（ILP）和子图同构问题。然后，它应用层连接与拆分（LCS）技术来实现切片流水线中的负载均衡。接着，它采用增强的基于Ullmann的算法结合蒙特卡洛树搜索（MCTS）来加速子图匹配。最后，通过使用紧凑的稀疏行表示（CSR）来减少内存占用。

Result: IsoSched在延迟有界吞吐量（LBT）、加速比和能效方面优于LTS-PRM方法（PREMA、Planaria、CD-MSA、MoCA）。在关键任务满足率方面，IsoSched在不同任务复杂度下均优于TSS-NPRM方法（HASP）。

Conclusion: IsoSched是首个实现TSS架构上抢占式多DNN调度的框架，通过一系列优化算法和数据结构，解决了现有方案的局限性，并在多项性能指标上取得了显著优势。

Abstract: Deploying deep neural network (DNN) accelerators with Layer Temporal
Scheduling (LTS) often incurs significant overheads (e.g., energy and latency),
as intermediate activations must be cached in DRAM. To alleviate this, Tile
Spatial Scheduling (TSS) reduces such costs by fragmenting inter-layer data
into smaller tiles communicated via on-chip links.However, many emerging
applications require concurrent execution of multiple DNNs with complex
topologies, where critical tasks must preempt others to meet stringent latency
requirements (e.g., in autonomous driving, obstacle detection must complete
within tens of milliseconds). Existing TSS works lack support for preemption,
while prior preemption schemes rely on LTS and thus inherit its overheads. This
highlights the need for preemptive and efficient TSS-based frameworks. Yet,
realizing such systems is challenging due to the complexity of enabling
preemption in graphs with large-scale topologies (e.g., modern large language
models may contain tens of thousands of edges). To tackle this, we present
IsoSched, the first framework enabling preemptive multi-DNN scheduling on TSS
architecture. IsoSched first formulates scheduling of complex-topology graphs
as an integer-linear program (ILP) and subgraph isomorphism problem; second, it
applies Layer Concatenate and Split (LCS) for load balancing in tile pipelines;
third, it employs an Ullmann-based algorithm enhanced by Monte Carlo Tree
Search (MCTS) to accelerate subgraph matching, and uses compact matrix encoding
(i.e., Compressed Sparse Row, CSR) to reduce memory usage. IsoSched outperforms
LTS-PRM approaches (i.e., PREMA, Planaria, CD-MSA, MoCA) in Latency-Bound
Throughput (LBT), speedup, and energy efficiency, and achieves higher critical
task satisfaction than TSS-NPRM (i.e., HASP) across varying task complexities.

</details>


### [87] [A Proposal for High-Level Architectural Model Capable of Expressing Various Data Collaboration Platform and Data Space Concepts](https://arxiv.org/abs/2509.12210)
*Masaru Dobashi,Kohei Toshimitsu,Hirotsugu Seike,Miki Kanno,Genki Horie,Noboru Koshizuka*

Main category: cs.DC

TL;DR: 该模型旨在统一表达区域性数据协作平台，并能在保护数据主权的前提下实现互操作性。


<details>
  <summary>Details</summary>
Motivation: 本论文提出了一种“数据空间高层架构模型”（DS-HLAM），用于表达跨区域实现的数据协作平台。

Method: 该框架引入了数学上严谨的定义，并通过有限状态自动机理论对其成功条件进行了形式化。

Result: 通过使用有限状态自动机理论，该模型能够实现不同数据协作平台间的互操作性，同时满足数据主权的保护要求。

Conclusion: DS-HLAM 为实现安全、互操作性强的数据协作平台提供了一个结构化的方法，特别是在处理跨区域数据共享时。

Abstract: This paper proposes "Data Space High-Level Architecture Model" (DS-HLAM) for
expressing diverse data collaboration platforms across regional
implementations. The framework introduces mathematically rigorous definitions
with success conditions formalized through finite state automata theory,
enabling interoperability while preserving digital sovereignty requirements.

</details>


### [88] [TinyServe: Query-Aware Cache Selection for Efficient LLM Serving](https://arxiv.org/abs/2509.12211)
*Dong Liu,Yanxuan Yu*

Main category: cs.DC

TL;DR: TinyServe是一个轻量级且可扩展的LLM服务系统，通过结构化KV稀疏性、基于插件的token选择和硬件高效的注意力内核，实现了高达3.4倍的加速和2倍的内存节省，同时准确率几乎没有损失。


<details>
  <summary>Details</summary>
Motivation: 高昂的内存和延迟开销是LLM服务中的关键挑战，尤其是在KV缓存访问方面。

Method: TinyServe引入了一种‘查询感知页面选择’机制，利用边界框元数据来估计查询和KV缓存块之间的注意力相关性，实现了选择性KV加载。它还集成了页面评分、稀疏内存访问和掩码注意力到一个CUDA内核中。

Result: 实验表明，TinyServe实现了高达3.4倍的加速和超过2倍的内存节省，同时准确率的下降可以忽略不计。

Conclusion: TinyServe被证明是LLM训练和推理研究在资源受限硬件上的一种有效的系统级设计。

Abstract: Serving large language models (LLMs) efficiently remains challenging due to
the high memory and latency overhead of key-value (KV) cache access during
autoregressive decoding. We present \textbf{TinyServe}, a lightweight and
extensible serving system for deploying tiny LLMs (e.g., TinyLLaMA, GPT2-345M)
with support for structured KV sparsity, plugin-based token selection, and
hardware-efficient attention kernels. Unlike prior simulation frameworks,
TinyServe executes real-time decoding with configurable sparsity strategies and
fine-grained instrumentation.
  To reduce decoding cost, we introduce a \textit{query-aware page selection}
mechanism that leverages bounding-box metadata to estimate attention relevance
between the query and KV cache blocks. This enables selective KV loading with
minimal overhead and no model modifications. Our fused CUDA kernel integrates
page scoring, sparse memory access, and masked attention in a single pass.
  Experiments show that TinyServe achieves up to \textbf{3.4x} speedup and over
\textbf{2x} memory savings with negligible accuracy drop. Additional analysis
of cache reuse, page hit rate, and multi-GPU scaling confirms its practicality
as an efficient system-level design for LLM training and inference research on
resource-constrained hardware.

</details>


### [89] [Research on fault diagnosis and root cause analysis based on full stack observability](https://arxiv.org/abs/2509.12231)
*Jian Hou*

Main category: cs.DC

TL;DR: 该论文提出了KylinRCA框架，通过结合动态因果发现和多模态/跨层融合的方法，实现了对云服务故障的根因分析。


<details>
  <summary>Details</summary>
Motivation: 随着云计算和超大规模数据中心的快速发展，系统故障频繁且具有级联传播特性，因此，实现高效、准确、可解释的基于可观测性数据的根因分析（RCA）成为AIOps的核心问题。

Method: KylinRCA框架整合了动态因果发现（如FaultInsight）和多模态/跨层融合（如HolisticRCA）的思想。具体地，它通过时间因果发现描绘故障传播链，利用跨模态图学习实现全局根因定位和类型识别，并结合基于掩码的解释方法输出可审计的证据链。

Result: 提出了一种名为KylinRCA的框架，并通过多维度实验方案进行了评估，解决了全栈可观测性下的故障诊断问题。

Conclusion: KylinRCA框架通过整合动态因果发现和多模态/跨层融合，为云服务故障的根因分析提供了一个有效且可解释的解决方案。

Abstract: With the rapid development of cloud computing and ultra-large-scale data
centers, the scale and complexity of systems have increased significantly,
leading to frequent faults that often show cascading propagation. How to
achieve efficient, accurate, and interpretable Root Cause Analysis (RCA) based
on observability data (metrics, logs, traces) has become a core issue in AIOps.
This paper reviews two mainstream research threads in top conferences and
journals over the past five years: FaultInsight[1] focusing on dynamic causal
discovery and HolisticRCA[2] focusing on multi-modal/cross-level fusion, and
analyzes the advantages and disadvantages of existing methods. A KylinRCA
framework integrating the ideas of both is proposed, which depicts the
propagation chain through temporal causal discovery, realizes global root cause
localization and type identification through cross-modal graph learning, and
outputs auditable evidence chains combined with mask-based explanation methods.
A multi-dimensional experimental scheme is designed, evaluation indicators are
clarified, and engineering challenges are discussed, providing an effective
solution for fault diagnosis under full-stack observability.

</details>


### [90] [Towards High-Performance and Portable Molecular Docking on CPUs through Vectorization](https://arxiv.org/abs/2509.12232)
*Gianmarco Accordi,Jens Domke,Theresa Pollinger,Davide Gadioli,Gianluca Palermo*

Main category: cs.DC

TL;DR: HPC领域的新CPU架构在向量化能力方面有所提升，但需要优化以实现峰值性能并确保性能可移植性。本文通过对分子对接应用进行案例研究，评估了编译器自动向量化和显式向量化在现代CPU上的性能，并探讨了代码转换、架构趋势和优化策略。


<details>
  <summary>Details</summary>
Motivation: HPC领域的新CPU架构带来了性能优化和可移植性的挑战，需要评估现有的向量化技术以适应这些变化。

Method: 评估编译器自动向量化和显式向量化在现代CPU上的性能，并选择分子对接应用作为案例研究。

Result: x86 CPU通常比ARM CPU具有更高的执行性能，但ARM在能耗和成本效益方面具有竞争力。研究确定了能够实现可移植自动向量化的代码转换，其性能与显式向量化相当。

Conclusion: 为了在现代CPU上实现高性能和性能可移植性，需要进行代码转换以实现自动向量化，并需要考虑不同CPU架构（如x86和ARM）的性能、能耗和成本效益。

Abstract: Recent trends in the HPC field have introduced new CPU architectures with
improved vectorization capabilities that require optimization to achieve peak
performance and thus pose challenges for performance portability. The
deployment of high-performing scientific applications for CPUs requires
adapting the codebase and optimizing for performance. Evaluating these
applications provides insights into the complex interactions between code,
compilers, and hardware. We evaluate compiler auto-vectorization and explicit
vectorization to achieve performance portability across modern CPUs with long
vectors. We select a molecular docking application as a case study, as it
represents computational patterns commonly found across HPC workloads. We
report insights into the technical challenges, architectural trends, and
optimization strategies relevant to the future development of scientific
applications for HPC. Our results show which code transformations enable
portable auto-vectorization, reaching performance similar to explicit
vectorization. Experimental data confirms that x86 CPUs typically achieve
higher execution performance than ARM CPUs, primarily due to their wider
vectorization units. However, ARM architectures demonstrate competitive energy
consumption and cost-effectiveness.

</details>


### [91] [SynergAI: Edge-to-Cloud Synergy for Architecture-Driven High-Performance Orchestration for AI Inference](https://arxiv.org/abs/2509.12252)
*Foteini Stathopoulou,Aggelos Ferikoglou,Manolis Katsaragakis,Dimosthenis Masouros,Sotirios Xydis,Dimitrios Soudris*

Main category: cs.DC

TL;DR: SynergAI是一个为异构边缘到云基础设施设计的、性能和架构感知的推理服务框架，通过结合离线和在线决策策略，动态分配工作负载以最小化服务质量（QoS）违规。


<details>
  <summary>Details</summary>
Motivation: AI/ML的快速发展增加了计算需求，特别是在推理服务方面。传统的云部署面临网络拥堵、高能耗和隐私问题，而边缘计算资源有限。因此，需要一个能够跨异构边缘到云基础设施进行性能和架构感知的推理服务框架。

Method: SynergAI框架结合了现代推理引擎的性能特征分析，并集成了离线和在线决策策略，以实现智能、轻量级和架构感知的调度。它动态地在不同的硬件架构之间分配工作负载，以最小化服务质量（QoS）违规。

Result: 在Kubernetes生态系统中实现的SynergAI，通过架构驱动的推理服务，在新兴硬件平台上实现了优化和架构感知的部署，与现有最先进（SotA）的解决方案相比，QoS违规平均减少了2.4倍。

Conclusion: SynergAI通过其创新的架构驱动方法，能够优化推理服务在异构边缘到云环境中的部署，显著减少服务质量违规，为新兴硬件平台提供了更高效的解决方案。

Abstract: The rapid evolution of Artificial Intelligence (AI) and Machine Learning (ML)
has significantly heightened computational demands, particularly for
inference-serving workloads. While traditional cloud-based deployments offer
scalability, they face challenges such as network congestion, high energy
consumption, and privacy concerns. In contrast, edge computing provides
low-latency and sustainable alternatives but is constrained by limited
computational resources. In this work, we introduce SynergAI, a novel framework
designed for performance- and architecture-aware inference serving across
heterogeneous edge-to-cloud infrastructures. Built upon a comprehensive
performance characterization of modern inference engines, SynergAI integrates a
combination of offline and online decision-making policies to deliver
intelligent, lightweight, and architecture-aware scheduling. By dynamically
allocating workloads across diverse hardware architectures, it effectively
minimizes Quality of Service (QoS) violations. We implement SynergAI within a
Kubernetes-based ecosystem and evaluate its efficiency. Our results demonstrate
that architecture-driven inference serving enables optimized and
architecture-aware deployments on emerging hardware platforms, achieving an
average reduction of 2.4x in QoS violations compared to a State-of-the-Art
(SotA) solution.

</details>


### [92] [The Entropy of Parallel Systems](https://arxiv.org/abs/2509.12256)
*Temitayo Adefemi*

Main category: cs.DC

TL;DR: 熵可以量化计算机组件之间的不兼容性，较低的熵与较高的计算性能相关。


<details>
  <summary>Details</summary>
Motivation: 为了量化并行集群中组件的不兼容性，这种不兼容性会导致噪声和混乱。

Method: 使用图论和对数开发了一个数学模型来量化并行集群的熵，并计算了 Top500 列表中前 10 名超级计算机的熵。

Result: 发现系统熵与计算性能之间存在负相关关系，LINPACK 基准测试（r = -0.7832，p = 0.0077）、MLPerf 混合精度基准测试（r = -0.6234）和 HPCC 复合分数（r = -0.5890）均显示出负相关。

Conclusion: 该熵框架可以应用于各种工作负载，并且熵与计算性能之间的负相关关系表明，低熵系统在计算效率方面表现更好。

Abstract: Ever since Claude Shannon used entropy for his "Mathematical Theory of
Communication", entropy has become a buzzword in research circles with
scientists applying entropy to describe any phenomena that are reminiscent of
disorder. In this paper, we used entropy to describe the incompatibility
between components in the computer, which can cause noise and disorder within
the parallel cluster. We develop a mathematical theory, primarily based on
graph theory and logarithms, to quantify the entropy of a parallel cluster by
accounting for the entropy of each system within the cluster. We proceed using
this model to calculate the entropy of the Top 10 supercomputers in the Top500
list. Our entropy framework reveals a statistically significant negative
correlation between system entropy and computational performance across the
world's fastest supercomputers. Most notably, the LINPACK benchmark
demonstrates a strong negative correlation (r = -0.7832, p = 0.0077) with our
entropy measure, indicating that systems with lower entropy consistently
achieve higher computational efficiency, this Relationship is further supported
by moderate correlations with MLPerf mixed-precision benchmarks (r = -0.6234)
and HPCC composite scores (r = -0.5890), suggesting the framework's
applicability extends beyond traditional dense linear algebra workloads.

</details>


### [93] [An End to End Edge to Cloud Data and Analytics Strategy](https://arxiv.org/abs/2509.12296)
*Vijay Kumar Butte,Sujata Butte*

Main category: cs.DC

TL;DR: 该论文提出了一种端到端的安全边缘到云数据和分析策略，并提供了设备层、边缘层和云层的参考架构，以应对物联网设备爆炸式增长和企业对云的快速采用所带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备数量的爆炸式增长和企业对云的快速采用，需要一种安全高效的策略和架构来充分利用云和边缘资产的能力，以支持需要快速实时决策的应用。

Method: 本文提出了一种端到端的安全边缘到云数据和分析策略，并提供了设备层、边缘层和云层的参考架构。

Result: 该论文提供了一个端到端的安全边缘到云数据和分析策略，以及实际实施所需的参考架构。

Conclusion: 该论文提出了一种安全边缘到云数据和分析的策略和参考架构，以满足日益增长的物联网应用对实时数据处理和决策的需求。

Abstract: There is an exponential growth of connected Internet of Things (IoT) devices.
These have given rise to applications that rely on real time data to make
critical decisions quickly. Enterprises today are adopting cloud at a rapid
pace. There is a critical need to develop secure and efficient strategy and
architectures to best leverage capabilities of cloud and edge assets. This
paper provides an end to end secure edge to cloud data and analytics strategy.
To enable real life implementation, the paper provides reference architectures
for device layer, edge layer and cloud layer.

</details>


### [94] [Exploring Distributed Vector Databases Performance on HPC Platforms: A Study with Qdrant](https://arxiv.org/abs/2509.12384)
*Seth Ockerman,Amal Gueroudji,Song Young Oh,Robert Underwood,Nicholas Chia,Kyle Chard,Robert Ross,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: 向量数据库在现代AI工作流中至关重要，但其在驱动大规模科学研究的高性能计算（HPC）系统中的性能特征知之甚少。本研究在Polaris超级计算机上对分布式向量数据库性能进行了实证研究，使用真实的生物文本工作负载和Qwen3-Embedding-4B生成的嵌入。我们选择Qdrant来评估其在多达32个节点上的插入、索引构建和查询延迟。


<details>
  <summary>Details</summary>
Motivation: 虽然向量数据库在AI工作流中很重要，但它们在高性能计算（HPC）系统中的性能特征知之甚少，而HPC系统是推动大规模科学研究的基础。因此，有必要研究向量数据库在HPC环境中的性能。

Method: 本研究构建了一个现实的生物文本工作负载，并使用Qwen3-Embedding-4B模型生成嵌入。然后，在Polaris超级计算机上，使用Qdrant数据库评估不同节点数量下的插入、索引构建和查询延迟。

Result: 研究评估了Qdrant在多达32个节点上的插入、索引构建和查询延迟，并获得了在HPC平台上运行向量数据库的实践经验。

Conclusion: 本研究是理解向量数据库在HPC平台上性能特征的第一步，旨在为未来的研究和优化提供指导。

Abstract: Vector databases have rapidly grown in popularity, enabling efficient
similarity search over data such as text, images, and video. They now play a
central role in modern AI workflows, aiding large language models by grounding
model outputs in external literature through retrieval-augmented generation.
Despite their importance, little is known about the performance characteristics
of vector databases in high-performance computing (HPC) systems that drive
large-scale science. This work presents an empirical study of distributed
vector database performance on the Polaris supercomputer in the Argonne
Leadership Computing Facility. We construct a realistic biological-text
workload from BV-BRC and generate embeddings from the peS2o corpus using
Qwen3-Embedding-4B. We select Qdrant to evaluate insertion, index construction,
and query latency with up to 32 workers. Informed by practical lessons from our
experience, this work takes a first step toward characterizing vector database
performance on HPC platforms to guide future research and optimization.

</details>


### [95] [AI Factories: It's time to rethink the Cloud-HPC divide](https://arxiv.org/abs/2509.12849)
*Pedro Garcia Lopez,Daniel Barcelona Pons,Marcin Copik,Torsten Hoefler,Eduardo Quiñones,Maciej Malawski,Peter Pietzutch,Alberto Marti,Thomas Ohlson Timoudas,Aleksander Slominski*

Main category: cs.DC

TL;DR: 主权人工智能倡议推动了AI工厂（AIF）的发展，然而现有的高性能计算（HPC）系统在易用性和面向AI服务的可访问性方面存在不足。本文提出了一种双栈方法，将HPC和云原生技术相结合，以解决HPC的云挑战（Serverless HPC）和云技术HPC挑战（High-performance Cloud），旨在融合高性能与易用性。


<details>
  <summary>Details</summary>
Motivation: 主权人工智能倡议的兴起和各国政府对技术自主性的追求，以及欧洲在AI工厂方面的投资，促使研究者关注如何优化现有高性能计算（HPC）系统以更好地支持人工智能发展。

Method: 提出并研究一种双栈方法，将传统的高性能计算（HPC）技术与云原生技术（如Kubernetes和对象存储）相结合，以解决HPC在易用性和可访问性方面的不足，并研究“Serverless HPC”和“High-performance Cloud”这两个核心挑战。

Result: 通过结合HPC的高性能和云原生技术的易用性，实现AI工厂的性能和可用性的提升，更好地支持本地数字生态系统的发展。

Conclusion: 将HPC与云原生技术相结合的双栈方法是克服当前AI工厂面临的挑战，实现高性能、易用性AI服务的有效途径。

Abstract: The strategic importance of artificial intelligence is driving a global push
toward Sovereign AI initiatives. Nationwide governments are increasingly
developing dedicated infrastructures, called AI Factories (AIF), to achieve
technological autonomy and secure the resources necessary to sustain robust
local digital ecosystems.
  In Europe, the EuroHPC Joint Undertaking is investing hundreds of millions of
euros into several AI Factories, built atop existing high-performance computing
(HPC) supercomputers. However, while HPC systems excel in raw performance, they
are not inherently designed for usability, accessibility, or serving as
public-facing platforms for AI services such as inference or agentic
applications. In contrast, AI practitioners are accustomed to cloud-native
technologies like Kubernetes and object storage, tools that are often difficult
to integrate within traditional HPC environments.
  This article advocates for a dual-stack approach within supercomputers:
integrating both HPC and cloud-native technologies. Our goal is to bridge the
divide between HPC and cloud computing by combining high performance and
hardware acceleration with ease of use and service-oriented front-ends. This
convergence allows each paradigm to amplify the other. To this end, we will
study the cloud challenges of HPC (Serverless HPC) and the HPC challenges of
cloud technologies (High-performance Cloud).

</details>


### [96] [Analysis and Optimization of Wireless Multimodal Federated Learning on Modal Heterogeneity](https://arxiv.org/abs/2509.12930)
*Xuefeng Han,Wen Chen,Jun Li,Ming Ding,Qingqing Wu,Kang Wei,Xiumei Deng,Yumeng Shao,Qiong Wu*

Main category: cs.DC

TL;DR: 本篇论文提出了一种名为JCSBA的算法，用于解决多模态联邦学习（MFL）在无线场景下面临的通信挑战和数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 多模态联邦学习（MFL）虽然能保护隐私，但在处理跨客户端模态异构性（即不同客户端拥有不同模态的数据子集）时面临困难，现有方法在无线场景下受限于延迟和带宽，性能有待优化。

Method: 提出了一种基于决策层融合架构和单模态损失函数的联合客户端调度与带宽分配（JCSBA）算法。该算法通过在训练目标和本地更新损失函数中加入单模态损失函数来加速多模态收敛并提升单模态性能。同时，推导了与客户端和模态调度相关的MFL性能的闭式上界，并在满足延迟、能量和带宽约束的条件下最小化该上界。

Result: 实验结果表明，JCSBA算法相比传统算法，在多模态准确率上提升了4.06%，在单模态准确率上提升了2.73%。

Conclusion: JCSBA算法能够有效提升无线多模态联邦学习在数据异构情况下的性能，同时满足通信和资源约束。

Abstract: Multimodal federated learning (MFL) is a distributed framework for training
multimodal models without uploading local multimodal data of clients, thereby
effectively protecting client privacy. However, multimodal data is commonly
heterogeneous across diverse clients, where each client possesses only a subset
of all modalities, renders conventional analysis results and optimization
methods in unimodal federated learning inapplicable. In addition, fixed latency
demand and limited communication bandwidth pose significant challenges for
deploying MFL in wireless scenarios. To optimize the wireless MFL performance
on modal heterogeneity, this paper proposes a joint client scheduling and
bandwidth allocation (JCSBA) algorithm based on a decision-level fusion
architecture with adding a unimodal loss function. Specifically, with the
decision results, the unimodal loss functions are added to both the training
objective and local update loss functions to accelerate multimodal convergence
and improve unimodal performance. To characterize MFL performance, we derive a
closed-form upper bound related to client and modality scheduling and minimize
the derived bound under the latency, energy, and bandwidth constraints through
JCSBA. Experimental results on multimodal datasets demonstrate that the JCSBA
algorithm improves the multimodal accuracy and the unimodal accuracy by 4.06%
and 2.73%, respectively, compared to conventional algorithms.

</details>


### [97] [Asymmetric Grid Quorum Systems for Heterogeneous Processes](https://arxiv.org/abs/2509.12942)
*Michael Senn,Christian Cachin*

Main category: cs.DC

TL;DR: 这是一个关于分布式系统中异构信任假设的论文，提出了一种名为“非对称网格法定人数系统”的新方法，该方法允许进程独立选择与其主观视图兼容的法定人数系统，从而打破了相互依赖的困境，并具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 分布式系统中进程需要就其故障假设达成一致，但当进程拥有异构的、主观的或非对称的故障假设时，会产生“鸡生蛋，蛋生鸡”的问题：在没有兼容的故障假设的情况下，进程如何协作以达成兼容的故障假设？

Method: 提出了一种名为“非对称网格法定人数系统”的方法。该系统允许一组进程独立地、无需协调地指定异构信任假设。其基础是描述进程差异的定性属性。每个进程可以从该类中选择一个最符合其主观视图的法定人数系统。这些可选项在设计上具有内在兼容性，从而打破了循环依赖。

Result: 非对称网格法定人数系统允许进程独立选择法定人数系统，并确保这些选择在设计上是兼容的，从而解决了在没有预先兼容的故障假设的情况下达成共识的难题。

Conclusion: 非对称网格法定人数系统提供了一种在分布式系统中处理异构信任假设的有效机制，解决了进程之间关于故障假设的协调难题，并具有从云计算到区块链网络的广泛应用潜力。

Abstract: Quorum systems are a common way to formalize failure assumptions in
distributed systems. Traditionally, these assumptions are shared by all
involved processes. More recently, systems have emerged which allow processes
some freedom in choosing their own, subjective or asymmetric, failure
assumptions. For such a system to work, individual processes' assumptions must
be compatible. However, this leads to a Catch-22-style scenario: How can
processes collaborate to agree on compatible failure assumptions when they have
no compatible failure assumptions to start with?
  We introduce asymmetric grid quorum systems that allow a group of processes
to specify heterogeneous trust assumptions independently of each other and
without coordination. They are based on qualitative attributes describing how
the processes differ. Each process may select a quorum system from this class
that aligns best with its subjective view. The available choices are designed
to be compatible by definition, thereby breaking the cycling dependency.
Asymmetric grid quorum systems have many applications that range from cloud
platforms to blockchain networks.

</details>


### [98] [Space-Time Trade-off in Bounded Iterated Memory](https://arxiv.org/abs/2509.13157)
*Guillermo Toyos-Marfurt,Petr Kuznetsov*

Main category: cs.DC

TL;DR: 在具有n个进程、r轮和b位内存的异步计算模型中，我们推导了实现全信息协议所需的Ω((n!)^{r-1} * 2^{n-b})的下界，并提出了一个渐近最优的算法。


<details>
  <summary>Details</summary>
Motivation: 尽管异步可计算性定理（ACT）描述了在无限容量读写共享内存模型中可解决的任务，但人们对其在有限容量内存中的实现方式以及内存容量与所需轮数之间的确切关系知之甚少。

Method: 通过分析协议复合物（代表可达状态的组合结构），我们推导出了必要的条件，并提出了一个针对可用内存位b量身定制的有界全信息算法。

Result: 对于n>2，我们证明了实现全信息协议所需的轮数复杂度为Ω((n!)^{r-1} * 2^{n-b})。所提出的算法对于迭代收集模型来说渐近最优，对于基于快照的模型来说，其最优性因子在n以内。

Conclusion: 本研究确定了有限共享内存模型中实现异步计算任务的轮数复杂度，并提出了一个渐近最优的算法，该算法在各种迭代共享内存模型中均具有高度适用性。

Abstract: The celebrated asynchronous computability theorem (ACT) characterizes tasks
solvable in the read-write shared-memory model using the unbounded
full-information protocol, where in every round of computation, each process
shares its complete knowledge of the system with the other processes.
Therefore, ACT assumes shared-memory variables of unbounded capacity. It has
been recently shown that boundedvariables can achieve the same computational
power at the expense of extra rounds. However, the exact relationship between
the bit capacity of the shared memory and the number of rounds required in
order to implement one round of the full-information protocol remained unknown.
  In this paper, we focus on the asymptotic round complexity of bounded
iterated shared-memory algorithms that simulate, up to isomorphism, the
unbounded full-information protocol. We relate the round complexity to the
number of processes $n$, the number of iterations of the full information
protocol $r$, and the bit size per shared-memory entry $b$. By analyzing the
corresponding protocol complex, a combinatorial structure representing
reachable states, we derive necessary conditions and present a bounded
full-information algorithm tailored to the bits available $b$ per shared memory
entry. We show that for $n>2$, the round complexity required to implement the
full-information protocol satisfies $\Omega((n!)^{r-1} \cdot 2^{n-b})$. Our
results apply to a range of iterated shared-memory models, from regular
read-write registers to atomic and immediate snapshots. Moreover, our bounded
full-information algorithm is asymptotically optimal for the iterated collect
model and within a linear factor $n$ of optimal for the snapshot-based models.

</details>


### [99] [Scaling Up Throughput-oriented LLM Inference Applications on Heterogeneous Opportunistic GPU Clusters with Pervasive Context Management](https://arxiv.org/abs/2509.13201)
*Thanh Son Phung,Douglas Thain*

Main category: cs.DC

TL;DR: LLM应用可通过动态分配机会性资源来提高吞吐量，并通过上下文管理实现高效资源利用。


<details>
  <summary>Details</summary>
Motivation: 传统LLM应用需要大量静态资源，导致用户等待或购买昂贵硬件。但并非所有LLM应用都对延迟敏感，可以采用面向吞吐量的方式。

Method: 提出了一种名为“通用上下文管理”（pervasive context management）的解决方案，该方案利用LLM应用的通用计算上下文，提供机制和策略，以便在机会性资源上无缝地重用上下文。

Result: 在机会性资源上采用通用上下文管理的LLM应用，执行时间减少了98.1%。

Conclusion: 通用上下文管理能够有效利用机会性资源，显著减少LLM应用的执行时间，缓解计算资源供需矛盾。

Abstract: The widespread growth in LLM developments increasingly demands more
computational power from clusters than what they can supply. Traditional LLM
applications inherently require huge static resource allocations, which force
users to either wait in a long job queue and accept progress delay, or buy
expensive hardware to fulfill their needs and exacerbate the demand-supply
problem. However, not all LLM applications are latency-sensitive and can
instead be executed in a throughput-oriented way. This throughput orientation
allows a dynamic allocation that opportunistically pools available resources
over time, avoiding both the long queue and expensive GPU purchases.
Effectively utilizing opportunistic resources brings numerous challenges
nevertheless. Our solution, pervasive context management, exploits the common
computational context in LLM applications and provides mechanisms and policies
that allow seamless context reuse on opportunistic resources. Our evaluation
shows an LLM application with pervasive context management on opportunistic
resources reduces its execution time by 98.1%.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [100] [Nonlocal Neural Tangent Kernels via Parameter-Space Interactions](https://arxiv.org/abs/2509.12467)
*Sriram Nagaraj,Vishakh Hari*

Main category: cs.LG

TL;DR: 该研究提出了非局部神经元切线核（NNTK），用于解决传统NTK框架在处理非光滑函数或非可微模型时的局限性，通过使用基于非局部相互作用的近似来替代局部梯度，从而将NTK理论扩展到更广泛的模型和函数类别。


<details>
  <summary>Details</summary>
Motivation: 传统的神经元切线核（NTK）框架在分析梯度流下的神经网络训练动态方面提供了深刻的见解，但它依赖于网络参数可微的假设，这在处理非光滑目标函数或表现出非可微行为的参数化模型时失效。

Method: 提出了一种非局部神经元切线核（NNTK），它在参数空间中用基于非局部相互作用的近似来替代局部梯度。研究了该非局部算子的固定核和基于注意力机制的两种形式。

Result: NNTK可以将NTK理论扩展到非光滑函数、随机估计器和更广泛的模型家族。通过数值研究说明了新框架的有效性。

Conclusion: NNTK为分析和理解更广泛的神经网络模型（包括那些具有非光滑或非可微特性的模型）的训练动态提供了一个更强大和更通用的理论框架。

Abstract: The Neural Tangent Kernel (NTK) framework has provided deep insights into the
training dynamics of neural networks under gradient flow. However, it relies on
the assumption that the network is differentiable with respect to its
parameters, an assumption that breaks down when considering non-smooth target
functions or parameterized models exhibiting non-differentiable behavior. In
this work, we propose a Nonlocal Neural Tangent Kernel (NNTK) that replaces the
local gradient with a nonlocal interaction-based approximation in parameter
space. Nonlocal gradients are known to exist for a wider class of functions
than the standard gradient. This allows NTK theory to be extended to nonsmooth
functions, stochastic estimators, and broader families of models. We explore
both fixed-kernel and attention-based formulations of this nonlocal operator.
We illustrate the new formulation with numerical studies.

</details>


### [101] [Finite-Agent Stochastic Differential Games on Large Graphs: II. Graph-Based Architectures](https://arxiv.org/abs/2509.12484)
*Ruimeng Hu,Jihao Long,Haosheng Zhou*

Main category: cs.LG

TL;DR: 提出了一种名为非可训练修改（NTM）的新型神经网络架构，用于计算图上的随机微分博弈（SDGs）中的纳什均衡。


<details>
  <summary>Details</summary>
Motivation: NTM 架构旨在解决图结构多智能体系统中局部交互和不确定性带来的挑战，提高模型的可解释性和稳定性，并减少可训练参数数量。

Method: NTM 架构通过图引导稀疏化来修改前馈神经网络，嵌入与图拓扑对齐的固定、非可训练组件。该方法被整合到两种现有的博弈求解器（Direct Parameterization 和 Deep BSDE）中，形成其稀疏变体（NTM-DP 和 NTM-DBSDE）。

Result: 理论上，NTM 在图上的静态博弈中具有普遍逼近性质。数值实验表明，NTM-DP 和 NTM-DBSDE 在性能上与完全可训练的对应方法相当，同时提高了计算效率。

Conclusion: NTM 架构能够有效地用于计算图上的随机微分博弈的纳什均衡，并在保持性能的同时提高计算效率。

Abstract: We propose a novel neural network architecture, called Non-Trainable
Modification (NTM), for computing Nash equilibria in stochastic differential
games (SDGs) on graphs. These games model a broad class of graph-structured
multi-agent systems arising in finance, robotics, energy, and social dynamics,
where agents interact locally under uncertainty. The NTM architecture imposes a
graph-guided sparsification on feedforward neural networks, embedding fixed,
non-trainable components aligned with the underlying graph topology. This
design enhances interpretability and stability, while significantly reducing
the number of trainable parameters in large-scale, sparse settings. We
theoretically establish a universal approximation property for NTM in static
games on graphs and numerically validate its expressivity and robustness
through supervised learning tasks. Building on this foundation, we incorporate
NTM into two state-of-the-art game solvers, Direct Parameterization and Deep
BSDE, yielding their sparse variants (NTM-DP and NTM-DBSDE). Numerical
experiments on three SDGs across various graph structures demonstrate that
NTM-based methods achieve performance comparable to their fully trainable
counterparts, while offering improved computational efficiency.

</details>


### [102] [TimeCluster with PCA is Equivalent to Subspace Identification of Linear Dynamical Systems](https://arxiv.org/abs/2509.12895)
*Christian L. Hines,Samuel Spillard,Daniel P. Martin*

Main category: cs.LG

TL;DR: TimeCluster通过将重叠数据窗口投影到低维空间来发现多变量时间序列中的结构，这在数学上等同于经典的线性子空间识别方法（块Hankel矩阵加奇异向量分解）。


<details>
  <summary>Details</summary>
Motivation: TimeCluster是一种用于发现长多变量时间序列结构的可视化分析技术，其通过将数据窗口投影到低维空间实现。

Method: TimeCluster方法通过将滑动窗口后的时间序列数据构建成Hankel矩阵，并应用PCA（通过SVD）来提取主方向，这与子空间系统识别的理论相符。

Result: 实验证明，TimeCluster产生的聚类坐标与子空间识别方法得到的结果一致，并在合成和真实动力学信号上得到验证。

Conclusion: TimeCluster与线性子空间识别的等同性为未来研究提供了新的机遇，包括状态空间预测、流/在线扩展、外部输入整合与可视化以及损坏数据中的趋势显示。

Abstract: TimeCluster is a visual analytics technique for discovering structure in long
multivariate time series by projecting overlapping windows of data into a
low-dimensional space. We show that, when Principal Component Analysis (PCA) is
chosen as the dimensionality reduction technique, this procedure is
mathematically equivalent to classical linear subspace identification
(block-Hankel matrix plus Singular Vector Decomposition (SVD)). In both
approaches, the same low-dimensional linear subspace is extracted from the time
series data. We first review the TimeCluster method and the theory of subspace
system identification. Then we show that forming the sliding-window matrix of a
time series yields a Hankel matrix, so applying PCA (via SVD) to this matrix
recovers the same principal directions as subspace identification. Thus the
cluster coordinates from TimeCluster coincide with the subspace identification
methods. We present experiments on synthetic and real dynamical signals
confirming that the two embeddings coincide. Finally, we explore and discuss
future opportunities enabled by this equivalence, including forecasting from
the identified state space, streaming/online extensions, incorporating and
visualising external inputs and robust techniques for displaying underlying
trends in corrupted data.

</details>


### [103] [Traces Propagation: Memory-Efficient and Scalable Forward-Only Learning in Spiking Neural Networks](https://arxiv.org/abs/2509.13053)
*Lorenzo Pes,Bojian Yin,Sander Stuijk,Federico Corradi*

Main category: cs.LG

TL;DR: Traces Propagation (TP) is a novel, fully local learning rule for Spiking Neural Networks (SNNs) that addresses spatial and temporal credit assignment efficiently, outperforming existing methods and demonstrating scalability for complex tasks and edge computing.


<details>
  <summary>Details</summary>
Motivation: Existing methods for training SNNs, like Backpropagation Through Time (BPTT), are computationally expensive, memory-intensive, and biologically implausible. While some local learning rules address temporal credit assignment, they struggle with spatial credit assignment without increasing memory overhead and hindering scalability.

Method: The proposed Traces Propagation (TP) is a forward-only, memory-efficient, and scalable learning rule. It combines eligibility traces with a layer-wise contrastive loss, eliminating the need for auxiliary layer-wise matrices.

Result: TP demonstrates superior performance compared to other fully local learning rules on NMNIST and SHD datasets. It achieves competitive results on complex datasets (DVS-GESTURE, DVS-CIFAR10) and scales effectively to deeper SNN architectures (VGG-9). TP also shows favorable memory scaling compared to prior scalable local rules, especially for datasets with many classes. Furthermore, TP is suitable for practical fine-tuning tasks like keyword spotting.

Conclusion: TP offers an efficient, scalable, and biologically plausible alternative for training SNNs, making it well-suited for edge computing and on-device learning scenarios.

Abstract: Spiking Neural Networks (SNNs) provide an efficient framework for processing
dynamic spatio-temporal signals and for investigating the learning principles
underlying biological neural systems. A key challenge in training SNNs is to
solve both spatial and temporal credit assignment. The dominant approach for
training SNNs is Backpropagation Through Time (BPTT) with surrogate gradients.
However, BPTT is in stark contrast with the spatial and temporal locality
observed in biological neural systems and leads to high computational and
memory demands, limiting efficient training strategies and on-device learning.
Although existing local learning rules achieve local temporal credit assignment
by leveraging eligibility traces, they fail to address the spatial credit
assignment without resorting to auxiliary layer-wise matrices, which increase
memory overhead and hinder scalability, especially on embedded devices. In this
work, we propose Traces Propagation (TP), a forward-only, memory-efficient,
scalable, and fully local learning rule that combines eligibility traces with a
layer-wise contrastive loss without requiring auxiliary layer-wise matrices. TP
outperforms other fully local learning rules on NMNIST and SHD datasets. On
more complex datasets such as DVS-GESTURE and DVS-CIFAR10, TP showcases
competitive performance and scales effectively to deeper SNN architectures such
as VGG-9, while providing favorable memory scaling compared to prior fully
local scalable rules, for datasets with a significant number of classes.
Finally, we show that TP is well suited for practical fine-tuning tasks, such
as keyword spotting on the Google Speech Commands dataset, thus paving the way
for efficient learning at the edge.

</details>


### [104] [Representation Learning on Large Non-Bipartite Transaction Networks using GraphSAGE](https://arxiv.org/abs/2509.12255)
*Mihir Tare,Clemens Rattasits,Yiming Wu,Euan Wielewski*

Main category: cs.LG

TL;DR: 本研究将GraphSAGE应用于银行交易网络，实现了可扩展、可泛化且可解释的节点嵌入，并在下游任务中表现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 金融机构需要可扩展的工具来分析复杂的交易网络，但传统图嵌入方法难以处理动态的、真实的银行业务数据。

Method: 使用匿名客户和商户交易数据构建交易网络，并训练GraphSAGE模型生成节点嵌入。

Result: 生成的节点嵌入可以揭示与地理和人口统计属性一致的可解释集群，并在金钱骡子检测任务中提高了高风险账户的优先排序。

Conclusion: GraphSAGE框架适用于银行业务规模的网络，具有归纳能力、可扩展性和可解释性，可为金融机构利用图机器学习提供蓝图。

Abstract: Financial institutions increasingly require scalable tools to analyse complex
transactional networks, yet traditional graph embedding methods struggle with
dynamic, real-world banking data. This paper demonstrates the practical
application of GraphSAGE, an inductive Graph Neural Network framework, to
non-bipartite heterogeneous transaction networks within a banking context.
Unlike transductive approaches, GraphSAGE scales well to large networks and can
generalise to unseen nodes which is critical for institutions working with
temporally evolving transactional data. We construct a transaction network
using anonymised customer and merchant transactions and train a GraphSAGE model
to generate node embeddings. Our exploratory work on the embeddings reveals
interpretable clusters aligned with geographic and demographic attributes.
Additionally, we illustrate their utility in downstream classification tasks by
applying them to a money mule detection model where using these embeddings
improves the prioritisation of high-risk accounts. Beyond fraud detection, our
work highlights the adaptability of this framework to banking-scale networks,
emphasising its inductive capability, scalability, and interpretability. This
study provides a blueprint for financial organisations to harness graph machine
learning for actionable insights in transactional ecosystems.

</details>


### [105] [Accelerating Privacy-Preserving Federated Learning in Large-Scale LEO Satellite Systems](https://arxiv.org/abs/2509.12222)
*Binquan Guo,Junteng Cao,Marie Siew,Binbin Chen,Tony Q. S. Quek,Zhu Han*

Main category: cs.LG

TL;DR: 该研究提出了一种用于卫星网络的联邦学习调度框架，通过动态资源分配来加速模型训练，并在模拟中显示出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决在分布式卫星网络中，由于隐私和法规限制无法集中聚合原始数据，以及卫星网络动态拓扑和有限带宽带来的通信瓶颈问题，从而阻碍传统联邦学习的进行。

Method: 提出了一种基于离散时间图的按需调度框架，动态地分配通信资源以加速联邦学习。

Result: 模拟结果表明，与传统的基于统计复用模型交换策略相比，该方法将训练回合时间平均减少了 14.20% 至 41.48%，并且对于更大的模型和更多的客户端，加速效果更明显。

Conclusion: 所提出的调度框架能够有效加速卫星网络中的联邦学习过程，并且具有良好的可扩展性。

Abstract: Large-scale low-Earth-orbit (LEO) satellite systems are increasingly valued
for their ability to enable rapid and wide-area data exchange, thereby
facilitating the collaborative training of artificial intelligence (AI) models
across geographically distributed regions. Due to privacy concerns and
regulatory constraints, raw data collected at remote clients cannot be
centrally aggregated, posing a major obstacle to traditional AI training
methods. Federated learning offers a privacy-preserving alternative by training
local models on distributed devices and exchanging only model parameters.
However, the dynamic topology and limited bandwidth of satellite systems will
hinder timely parameter aggregation and distribution, resulting in prolonged
training times. To address this challenge, we investigate the problem of
scheduling federated learning over satellite networks and identify key
bottlenecks that impact the overall duration of each training round. We propose
a discrete temporal graph-based on-demand scheduling framework that dynamically
allocates communication resources to accelerate federated learning. Simulation
results demonstrate that the proposed approach achieves significant performance
gains over traditional statistical multiplexing-based model exchange
strategies, reducing overall round times by 14.20% to 41.48%. Moreover, the
acceleration effect becomes more pronounced for larger models and higher
numbers of clients, highlighting the scalability of the proposed approach.

</details>


### [106] [Energy-Efficient Quantized Federated Learning for Resource-constrained IoT devices](https://arxiv.org/abs/2509.12814)
*Wilfrid Sougrinoma Compaoré,Yaya Etiabi,El Mehdi Amhoud,Mohamad Assaad*

Main category: cs.LG

TL;DR: 该论文提出了一种用于物联网网络的联邦学习框架，通过整合有限块长传输、模型量化和错误感知聚合机制，提高了能源效率和通信可靠性。


<details>
  <summary>Details</summary>
Motivation: 物联网设备资源受限，面临能源、通信和传输块长的挑战，需要更高效的联邦学习方法。

Method: 提出了一种集成有限块长传输、模型量化、错误感知聚合和上行传输功率优化的联邦学习框架。

Result: 与标准联邦学习模型相比，该方法将能耗显著降低了高达75%，同时保持了模型的准确性。

Conclusion: 该框架为资源受限的物联网场景提供了一种可行且高效可靠的联邦学习解决方案。

Abstract: Federated Learning (FL) has emerged as a promising paradigm for enabling
collaborative machine learning while preserving data privacy, making it
particularly suitable for Internet of Things (IoT) environments. However,
resource-constrained IoT devices face significant challenges due to limited
energy,unreliable communication channels, and the impracticality of assuming
infinite blocklength transmission. This paper proposes a federated learning
framework for IoT networks that integrates finite blocklength transmission,
model quantization, and an error-aware aggregation mechanism to enhance energy
efficiency and communication reliability. The framework also optimizes uplink
transmission power to balance energy savings and model performance. Simulation
results demonstrate that the proposed approach significantly reduces energy
consumption by up to 75\% compared to a standard FL model, while maintaining
robust model accuracy, making it a viable solution for FL in real-world IoT
scenarios with constrained resources. This work paves the way for efficient and
reliable FL implementations in practical IoT deployments. Index Terms:
Federated learning, IoT, finite blocklength, quantization, energy efficiency.

</details>


### [107] [PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis](https://arxiv.org/abs/2509.12212)
*Xinyu He,Chenhan Xiao,Haoran Li,Ruizhong Qiu,Zhe Xu,Yang Weng,Jingrui He,Hanghang Tong*

Main category: cs.LG

TL;DR: PowerGrow是一个联合生成框架，可以通过分解依赖性来生成可行的和真实的电力系统场景，同时保持较低的计算开销。


<details>
  <summary>Details</summary>
Motivation: 由于安全问题和数据匿名化的难度，公开可用的电力系统测试用例很少，这阻碍了对现代动态电网的研究。因此，需要开发能够联合生成电网结构和节点动力学的工具。

Method: PowerGrow框架通过依赖性分解将复杂的联合分布分解为一系列条件分布，用于生成可行电网拓扑、时间序列负荷和其他系统属性。它使用分层的图beta扩散过程来合成结构，并使用时间自编码器将时间序列数据嵌入到紧凑的潜在空间中，以提高训练稳定性和样本保真度。

Result: PowerGrow在基准测试中表现出色，其保真度和多样性优于现有的扩散模型，并实现了98.9%的潮流收敛率和更高的N-1故障恢复能力。

Conclusion: PowerGrow能够生成运行有效且逼真的电力系统场景，为解决公开测试用例稀缺的问题提供了有效的方法。

Abstract: Modern power systems are becoming increasingly dynamic, with changing
topologies and time-varying loads driven by renewable energy variability,
electric vehicle adoption, and active grid reconfiguration. Despite these
changes, publicly available test cases remain scarce, due to security concerns
and the significant effort required to anonymize real systems. Such limitations
call for generative tools that can jointly synthesize grid structure and nodal
dynamics. However, modeling the joint distribution of network topology, branch
attributes, bus properties, and dynamic load profiles remains a major
challenge, while preserving physical feasibility and avoiding prohibitive
computational costs. We present PowerGrow, a co-generative framework that
significantly reduces computational overhead while maintaining operational
validity. The core idea is dependence decomposition: the complex joint
distribution is factorized into a chain of conditional distributions over
feasible grid topologies, time-series bus loads, and other system attributes,
leveraging their mutual dependencies. By constraining the generation process at
each stage, we implement a hierarchical graph beta-diffusion process for
structural synthesis, paired with a temporal autoencoder that embeds
time-series data into a compact latent space, improving both training stability
and sample fidelity. Experiments across benchmark settings show that PowerGrow
not only outperforms prior diffusion models in fidelity and diversity but also
achieves a 98.9\% power flow convergence rate and improved N-1 contingency
resilience. This demonstrates its ability to generate operationally valid and
realistic power grid scenarios.

</details>


### [108] [Unsupervised Atomic Data Mining via Multi-Kernel Graph Autoencoders for Machine Learning Force Fields](https://arxiv.org/abs/2509.12358)
*Hong Sun,Joshua A. Vita,Amit Samanta,Vincenzo Lordi*

Main category: cs.LG

TL;DR: MEAGraph是一个无监督模型，通过图自编码器分析原子数据集，能够识别并去除数据集中的采样偏差，提高力场的训练效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集生成技术容易导致势能面过采样，且难以识别和消除偏差，而传统聚类和剪枝方法可能导致信息丢失或无法有效识别势能面的不同区域。

Method: 提出了一种名为MEAGraph的多核边缘注意力图自编码器模型，该模型结合了多核线性变换和基于注意力机制的消息传递，能够捕捉几何敏感性，并实现无需标签或大量训练的数据集剪枝。

Result: 在铌、钽和铁数据集上的应用表明，MEAGraph能够有效地对相似的原子环境进行分组，从而可以使用基本的剪枝技术去除采样偏差。

Conclusion: MEAGraph提供了一种有效的表示学习和聚类方法，可用于数据分析、异常值检测和数据集优化，解决了化学和材料科学中数据集偏差的问题。

Abstract: Constructing a chemically diverse dataset while avoiding sampling bias is
critical to training efficient and generalizable force fields. However, in
computational chemistry and materials science, many common dataset generation
techniques are prone to oversampling regions of the potential energy surface.
Furthermore, these regions can be difficult to identify and isolate from each
other or may not align well with human intuition, making it challenging to
systematically remove bias in the dataset. While traditional clustering and
pruning (down-sampling) approaches can be useful for this, they can often lead
to information loss or a failure to properly identify distinct regions of the
potential energy surface due to difficulties associated with the high
dimensionality of atomic descriptors. In this work, we introduce the
Multi-kernel Edge Attention-based Graph Autoencoder (MEAGraph) model, an
unsupervised approach for analyzing atomic datasets. MEAGraph combines multiple
linear kernel transformations with attention-based message passing to capture
geometric sensitivity and enable effective dataset pruning without relying on
labels or extensive training. Demonstrated applications on niobium, tantalum,
and iron datasets show that MEAGraph efficiently groups similar atomic
environments, allowing for the use of basic pruning techniques for removing
sampling bias. This approach provides an effective method for representation
learning and clustering that can be used for data analysis, outlier detection,
and dataset optimization.

</details>


### [109] [A Physics-Informed Neural Networks-Based Model Predictive Control Framework for $SIR$ Epidemics](https://arxiv.org/abs/2509.12226)
*Aiping Zhong,Baike She,Philip E. Paré*

Main category: cs.LG

TL;DR: 本研究提出了一种基于物理信息神经网络（PINNs）的模型预测控制（MPC）框架，用于易感-感染-康复（SIR）传播模型，解决了在仅有噪声感染状态下联合实时估计状态和参数的问题。


<details>
  <summary>Details</summary>
Motivation: 现有流行病控制中的MPC设计通常假设状态或参数已知，本研究旨在解决在仅有噪声感染状态下，MPC框架内状态和参数的联合实时估计问题，并且只知道恢复率或基本再生数。

Method: 提出了一种基于PINNs的模型预测控制（MPC）框架，包括MPC-PINNs、MPC-LS-PINNs（对数尺度损失函数）和MPC-SI-PINNs（积分算子和状态耦合）。在此基础上，针对只知道基本再生数的情况，将MPC-SI-PINNs简化为MPC-S-PINNs。

Result: 实验结果表明，所提出的方法在不同设置下均有效。

Conclusion: 本研究提出的基于PINNs的MPC框架能够有效地联合估计SIR模型的参数和状态，并生成最优控制策略。

Abstract: This work introduces a physics-informed neural networks (PINNs)-based model
predictive control (MPC) framework for susceptible-infected-recovered ($SIR$)
spreading models. Existing studies in MPC design for epidemic control often
assume either 1) measurable states of the dynamics, where the parameters are
learned, or 2) known parameters of the model, where the states are learned. In
this work, we address the joint real-time estimation of states and parameters
within the MPC framework using only noisy infected states, under the assumption
that 1) only the recovery rate is known, or 2) only the basic reproduction
number is known. Under the first assumption, we propose MPC-PINNs and two novel
PINNs algorithms, all of which are integrated into the MPC framework. First, we
introduce MPC-PINNs, which are designed for $SIR$ models with control. We then
propose log-scaled PINNs (MPC-LS-PINNs), which incorporate a log-scaled loss
function to improve robustness against noise. Next, we present split-integral
PINNs (MPC-SI-PINNs), which leverage integral operators and state coupling in
the neural network training process to effectively reconstruct the complete
epidemic state information. Building upon these methods, we further extend our
framework for the second assumption. We establish the necessary conditions and
extend our PINNs algorithms, where MPC-SI-PINNs are simplified as split-PINNs
(MPC-S-PINNs). By incorporating these algorithms into the MPC framework, we
simultaneously estimate the epidemic states and parameters while generating
optimal control strategies. Experiment results demonstrate the effectiveness of
the proposed methods under different settings.

</details>


### [110] [Soft Gradient Boosting with Learnable Feature Transforms for Sequential Regression](https://arxiv.org/abs/2509.12920)
*Huseyin Karaca,Suleyman Serdar Kozat*

Main category: cs.LG

TL;DR: 该研究提出了一种用于顺序回归的软梯度提升框架，通过在提升过程中嵌入可学习的线性特征变换，有效解决了高维、数据稀疏场景下的性能提升问题，并提供了代码以供复现。


<details>
  <summary>Details</summary>
Motivation: 在高维、数据稀疏的场景下，现有方法在提升模型性能的同时容易导致过拟合。因此，需要一种能够同时进行特征选择/变换和提升，并有效避免过拟合的框架。

Method: 提出了一种软梯度提升框架，在每次提升迭代中，同时训练一个软决策树和一个线性输入特征变换Q。该方法通过端到端优化特征选择/变换和提升过程来实现。

Result: 使用合成和真实世界的数据集进行了实验，结果表明该方法能够有效且高效地提升性能，并且避免了过拟合。此外，研究还将该算法扩展到了可微分非线性变换。

Conclusion: 所提出的软梯度提升框架能够有效解决高维、数据稀疏场景下的模型性能提升问题，通过联合优化特征变换和梯度提升来提高准确性并防止过拟合。该方法具有通用性，并且可以通过扩展支持非线性变换。

Abstract: We propose a soft gradient boosting framework for sequential regression that
embeds a learnable linear feature transform within the boosting procedure. At
each boosting iteration, we train a soft decision tree and learn a linear input
feature transform Q together. This approach is particularly advantageous in
high-dimensional, data-scarce scenarios, as it discovers the most relevant
input representations while boosting. We demonstrate, using both synthetic and
real-world datasets, that our method effectively and efficiently increases the
performance by an end-to-end optimization of feature selection/transform and
boosting while avoiding overfitting. We also extend our algorithm to
differentiable non-linear transforms if overfitting is not a problem. To
support reproducibility and future work, we share our code publicly.

</details>


### [111] [CoVariance Filters and Neural Networks over Hilbert Spaces](https://arxiv.org/abs/2509.13178)
*Claudio Battiloro,Andrea Cavallo,Elvin Isufi*

Main category: cs.LG

TL;DR: CoVariance Neural Networks (VNNs) 是一种在有限维希尔伯特空间上对信号协方差矩阵进行图卷积的方法，但其在无限维希尔伯特空间上的性质尚不清楚。本研究提出了一个在无限维希尔伯特空间上进行卷积学习的新框架，基于协方差算子。研究定义了希尔伯特协方差滤波器 (HVFs) 并设计了希尔伯特协方差网络 (HVNs)，证明了经验 HVFs 可以恢复滤波信号的泛函 PCA (FPCA)，并在合成和真实时间序列分类任务上验证了 HVNs 的稳健性。


<details>
  <summary>Details</summary>
Motivation: VNNs 在有限维希尔伯特空间上表现出鲁棒性和可迁移性，但其在无限维希尔伯特空间上的适用性仍需探索。

Method: 提出了一种新的卷积学习框架，该框架基于（经验）协方差算子，并定义了希尔伯特协方差滤波器 (HVFs) 和希尔伯特协方差网络 (HVNs)。采用了一种原则性的离散化方法，并证明了经验 HVFs 可以恢复滤波信号的泛函 PCA (FPCA)。

Result: 证明了经验 HVFs 可以恢复滤波信号的泛函 PCA (FPCA)。在合成和真实世界的时间序列分类任务上，HVNs 与 MLP 和基于 FPCA 的分类器相比，表现出了稳健的性能。

Conclusion: 本研究提出了一个用于无限维希尔伯特空间信号的卷积学习框架 (HVNs)，并证明了其在理论和实践中的有效性，为该领域的研究奠定了基础。

Abstract: CoVariance Neural Networks (VNNs) perform graph convolutions on the empirical
covariance matrix of signals defined over finite-dimensional Hilbert spaces,
motivated by robustness and transferability properties. Yet, little is known
about how these arguments extend to infinite-dimensional Hilbert spaces. In
this work, we take a first step by introducing a novel convolutional learning
framework for signals defined over infinite-dimensional Hilbert spaces,
centered on the (empirical) covariance operator. We constructively define
Hilbert coVariance Filters (HVFs) and design Hilbert coVariance Networks (HVNs)
as stacks of HVF filterbanks with nonlinear activations. We propose a
principled discretization procedure, and we prove that empirical HVFs can
recover the Functional PCA (FPCA) of the filtered signals. We then describe the
versatility of our framework with examples ranging from multivariate
real-valued functions to reproducing kernel Hilbert spaces. Finally, we
validate HVNs on both synthetic and real-world time-series classification
tasks, showing robust performance compared to MLP and FPCA-based classifiers.

</details>


### [112] [Spatiotemporal graph neural process for reconstruction, extrapolation, and classification of cardiac trajectories](https://arxiv.org/abs/2509.12953)
*Jaume Banus,Augustin C. Ogier,Roger Hullin,Philippe Meyer,Ruud B. van Heeswijk,Jonas Richiardi*

Main category: cs.LG

TL;DR: 本研究提出了一种结合神经ODE、GNN和神经过程的概率框架，用于从稀疏观测中建模结构化时空动力学，特别关注心脏运动。该模型能够捕捉不确定性、时间连续性和解剖结构。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决从稀疏观测中建模结构化时空动力学的问题，特别是在心脏运动分析领域的应用。

Method: 研究人员整合了神经ODE、GNN和神经过程，将动态系统表示为时空多路复用图，并使用GNN参数化的向量场来建模潜在轨迹。模型通过稀疏的节点和边观测来推断潜在初始状态和控制变量的分布，从而实现轨迹的插值和外插。

Result: 在三个合成动力学系统和两个真实世界的心脏成像数据集（ACDC和UK Biobank）上进行了验证。结果表明，该模型能够准确重建轨迹，从单个观测周期外插未来的心脏周期，并在ACDC数据集上实现了高达99%的分类准确率，在UK Biobank数据集上检测房颤的准确率高达67%。

Conclusion: 这项工作提出了一个灵活的分析心脏运动的方法，并为结构化生物医学时空时间序列数据的图学习奠定了基础。

Abstract: We present a probabilistic framework for modeling structured spatiotemporal
dynamics from sparse observations, focusing on cardiac motion. Our approach
integrates neural ordinary differential equations (NODEs), graph neural
networks (GNNs), and neural processes into a unified model that captures
uncertainty, temporal continuity, and anatomical structure. We represent
dynamic systems as spatiotemporal multiplex graphs and model their latent
trajectories using a GNN-parameterized vector field. Given the sparse context
observations at node and edge levels, the model infers a distribution over
latent initial states and control variables, enabling both interpolation and
extrapolation of trajectories. We validate the method on three synthetic
dynamical systems (coupled pendulum, Lorenz attractor, and Kuramoto
oscillators) and two real-world cardiac imaging datasets - ACDC (N=150) and UK
Biobank (N=526) - demonstrating accurate reconstruction, extrapolation, and
disease classification capabilities. The model accurately reconstructs
trajectories and extrapolates future cardiac cycles from a single observed
cycle. It achieves state-of-the-art results on the ACDC classification task (up
to 99% accuracy), and detects atrial fibrillation in UK Biobank subjects with
competitive performance (up to 67% accuracy). This work introduces a flexible
approach for analyzing cardiac motion and offers a foundation for graph-based
learning in structured biomedical spatiotemporal time-series data.

</details>


### [113] [Quantum-Inspired Stacked Integrated Concept Graph Model (QISICGM) for Diabetes Risk Prediction](https://arxiv.org/abs/2509.12259)
*Kenneth G. Young II*

Main category: cs.LG

TL;DR: QISICGM是一个利用量子启发技术预测糖尿病风险的机器学习框架，通过集成自改进概念图和多种模型（RF、ET、Transformer、CNN、FFNN），在PIMA糖尿病数据集上实现了0.8933的F1分数和0.8699的AUC，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高糖尿病风险预测的准确性和效率，开发一种创新的机器学习框架。

Method: 使用PIMA糖尿病数据集（包含2000个合成样本）构建QISICGM模型，该模型集成了自改进概念图和随机森林、极端森林、Transformer、CNN、FFNN组成的堆叠集成，并引入量子启发技术（如相位特征映射和邻域序列建模）来增强特征表示。

Result: QISICGM在PIMA糖尿病数据集上实现了0.8933的OOF F1分数和0.8699的AUC，预测效率为每秒8.5行，优于传统方法。

Conclusion: QISICGM是一个在糖尿病风险预测方面表现优异且具有可解释性和可复现性的模型，有望成为临床分诊的基准，并推动值得信赖的AI在医疗领域的应用。

Abstract: The Quantum-Inspired Stacked Integrated Concept Graph Model (QISICGM) is an
innovative machine learning framework that harnesses quantum-inspired
techniques to predict diabetes risk with exceptional accuracy and efficiency.
Utilizing the PIMA Indians Diabetes dataset augmented with 2,000 synthetic
samples to mitigate class imbalance (total: 2,768 samples, 1,949 positives),
QISICGM integrates a self-improving concept graph with a stacked ensemble
comprising Random Forests (RF), Extra Trees (ET), transformers, convolutional
neural networks (CNNs), and feed-forward neural networks (FFNNs). This approach
achieves an out-of-fold (OOF) F1 score of 0.8933 and an AUC of 0.8699,
outperforming traditional methods. Quantum inspired elements, such as phase
feature mapping and neighborhood sequence modeling, enrich feature
representations, enabling CPU-efficient inference at 8.5 rows per second. This
paper presents a detailed architecture, theoretical foundations, code insights,
and performance evaluations, including visualizations from the outputs
subfolder. The open-source implementation (v1.0.0) is available at
https://github.com/keninayoung/QISICGM, positioning QISICGM as a potential
benchmark for AI-assisted clinical triage in diabetes and beyond. Ultimately,
this work emphasizes trustworthy AI through calibration, interpretability, and
open-source reproducibility.

</details>


### [114] [Prediction of Stocks Index Price using Quantum GANs](https://arxiv.org/abs/2509.12286)
*Sangram Deshpande,Gopal Ramesh Dahale,Sai Nandan Morapakula,Uday Wad*

Main category: cs.LG

TL;DR: 本研究采用量子生成对抗网络（QGANs）进行股票价格预测，利用量子计算的优势，在收敛速度和预测准确性方面均优于传统的LSTM和GAN模型。


<details>
  <summary>Details</summary>
Motivation: 金融市场具有高波动性和复杂性，传统模型难以捕捉其内在模式，因此需要QGANs这种结合生成模型和量子机器学习技术的新方法来提高预测能力。

Method: 使用AWS Braket SV1模拟器，为股票价格预测任务实现并训练了一个定制的QGAN模型，并使用Stocks指数价格数据进行评估。

Result: QGAN模型能够生成与实际市场行为相似的合成数据，从而提高了股票价格预测的准确性。与经典的LSTM和GAN模型相比，QGAN在收敛速度和预测准确性上均表现出优越的性能。

Conclusion: 将量子计算应用于金融预测是金融科技领域的重要进展，QGANs在速度和精度方面为金融预测提供了超越传统方法的潜力，对交易员、金融分析师和研究人员具有重要的指导意义。

Abstract: This paper investigates the application of Quantum Generative Adversarial
Networks (QGANs) for stock price prediction. Financial markets are inherently
complex, marked by high volatility and intricate patterns that traditional
models often fail to capture. QGANs, leveraging the power of quantum computing,
offer a novel approach by combining the strengths of generative models with
quantum machine learning techniques. We implement a QGAN model tailored for
stock price prediction and evaluate its performance using historical stock
market data. Our results demonstrate that QGANs can generate synthetic data
closely resembling actual market behavior, leading to enhanced prediction
accuracy. The experiment was conducted using the Stocks index price data and
the AWS Braket SV1 simulator for training the QGAN circuits. The
quantum-enhanced model outperforms classical Long Short-Term Memory (LSTM) and
GAN models in terms of convergence speed and prediction accuracy. This research
represents a key step toward integrating quantum computing in financial
forecasting, offering potential advantages in speed and precision over
traditional methods. The findings suggest important implications for traders,
financial analysts, and researchers seeking advanced tools for market analysis.

</details>


### [115] [Large Language Model Scaling Laws for Neural Quantum States in Quantum Chemistry](https://arxiv.org/abs/2509.12679)
*Oliver Knitter,Dan Zhao,Stefan Leichenauer,Shravan Veerapaneni*

Main category: cs.LG

TL;DR: 本文研究了神经网络量子态（NQS）的扩展性，特别是基于Transformer的NQS在量子化学问题中的表现。研究发现，NQS的性能扩展规律与大型语言模型（LLM）不同，并且与所使用的损失函数和模型结构有关。


<details>
  <summary>Details</summary>
Motivation: 为了理解神经量子态（NQS）的扩展性和最优资源-性能权衡，借鉴了大型语言模型（LLM）的扩展性研究方法，因为NQS越来越多地采用基于LLM的组件。

Method: 通过在二次量子化的量子化学应用中，将模型大小、训练数据大小或计算资源量作为变量，识别预测Transformer-based NQS的绝对误差和V-score性能的扩展规律。通过对得到的参数曲线进行计算资源约束优化，分析模型大小和训练时间的关系。

Result: 发现NQS的性能（以绝对误差和V-score衡量）随问题规模的扩展规律。模型大小和训练时间之间的关系高度依赖于损失函数和模型结构，并且不遵循大型语言模型中发现的近似线性关系。

Conclusion: 神经网络量子态（NQS）的性能扩展规律与大型语言模型（LLM）不同，其模型大小和训练时间的关系并非简单的线性关系，而是受损失函数和模型结构的影响。

Abstract: Scaling laws have been used to describe how large language model (LLM)
performance scales with model size, training data size, or amount of
computational resources. Motivated by the fact that neural quantum states (NQS)
has increasingly adopted LLM-based components, we seek to understand NQS
scaling laws, thereby shedding light on the scalability and optimal
performance--resource trade-offs of NQS ansatze. In particular, we identify
scaling laws that predict the performance, as measured by absolute error and
V-score, for transformer-based NQS as a function of problem size in
second-quantized quantum chemistry applications. By performing analogous
compute-constrained optimization of the obtained parametric curves, we find
that the relationship between model size and training time is highly dependent
on loss metric and ansatz, and does not follow the approximately linear
relationship found for language models.

</details>


### [116] [MEUV: Achieving Fine-Grained Capability Activation in Large Language Models via Mutually Exclusive Unlock Vectors](https://arxiv.org/abs/2509.12221)
*Xin Tong,Zhi Lin,Jingya Wang,Meng Han,Bo Jin*

Main category: cs.LG

TL;DR: LLMs的安全防护措施阻碍了其在执法、国防等高风险领域的合法使用。本研究提出的 MEUV 框架将单一的“拒绝方向”分解为多个独立的、与主题相关的向量，实现了对敏感能力的细粒度控制，提高了攻击成功率，同时大幅减少了跨主题的泄露，并证明了跨语言迁移的可行性，为在安全敏感领域部署 LLM 提供了新途径。


<details>
  <summary>Details</summary>
Motivation: LLMs 的安全对齐虽然能拒绝恶意请求，但也限制了其在执法、国防等高风险领域的合法应用。现有的“拒绝方向”编辑方法缺乏语义控制，无法区分不同主题的敏感性。

Method: 提出了一种名为 MEUV（Mutually Exclusive Unlock Vectors）的轻量级框架，将单一的拒绝方向分解为多个主题对齐、近乎正交的向量。该框架在一个 epoch 内进行训练，采用多任务目标，结合了微分烧蚀、跨主题和正交性惩罚以及辅助项。

Result: MEUV 在双语恶意提示基准测试中，在 Gemma-2-2B、LLaMA-3-8B 和 Qwen-7B 模型上实现了不低于 87% 的攻击成功率，并将跨主题泄露减少了高达 90%。此外，研究发现用中文训练的向量几乎可以不变地迁移到英文（反之亦然），表明存在与语言无关的拒绝子空间。

Conclusion: 通过 MEUV 框架，可以实现细粒度的、与主题相关的能力激活，同时将效用损失降至最低。这为在安全敏感领域可控地部署 LLM 铺平了道路。

Abstract: Large language models (LLMs) enforce safety alignment to reliably refuse
malicious requests, yet the same blanket safeguards also block legitimate uses
in policing, defense, and other high-stakes settings. Earlier
"refusal-direction" edits can bypass those layers, but they rely on a single
vector that indiscriminately unlocks all hazardous topics, offering no semantic
control. We introduce Mutually Exclusive Unlock Vectors (MEUV), a lightweight
framework that factorizes the monolithic refusal direction into topic-aligned,
nearly orthogonal vectors, each dedicated to one sensitive capability. MEUV is
learned in a single epoch with a multi-task objective that blends a
differential-ablation margin, cross-topic and orthogonality penalties, and
several auxiliary terms. On bilingual malicious-prompt benchmarks, MEUV
achieves an attack success rate of no less than 87% on Gemma-2-2B, LLaMA-3-8B,
and Qwen-7B, yet cuts cross-topic leakage by up to 90% compared with the best
single-direction baseline. Vectors trained in Chinese transfer almost unchanged
to English (and vice versa), suggesting a language-agnostic refusal subspace.
The results show that fine-grained, topic-level capability activation is
achievable with minimal utility loss, paving the way for controlled LLMs
deployment in security-sensitive domains.

</details>


### [117] [Scaling Up Data Parallelism in Decentralized Deep Learning](https://arxiv.org/abs/2509.12213)
*Bing Xie,Junqi Yin,Zhenyu Zhou,Sarp Oral,Feiyi Wang*

Main category: cs.LG

TL;DR: 本研究提出了DBench基准测试框架和Ada算法，用于解决大规模分布式深度学习训练中的稳定性、可扩展性和通用性问题。


<details>
  <summary>Details</summary>
Motivation: 尽管分布式学习在理论上得到了广泛研究，但由于在大规模深度学习训练中缺乏稳定性、可扩展性和通用性，尚未投入生产使用。本研究旨在解决这些问题，为分布式学习的生产应用铺平道路。

Method: 本研究引入了一个名为DBench的基准测试框架，用于托管集中式和分布式深度学习训练。在此基础上，提出了一种基准测试方法，通过改变通信图和训练规模来揭示模型准确性与参数张量方差之间的相关性。基于观察结果，提出了一种名为Ada的分布式自适应方法，该方法采用分布式随机梯度下降（SGD）方法，并动态调整通信图。

Result: 研究结果表明：1. 与集中式学习类似，分布式数据并行训练在扩展训练规模时也存在可扩展性和通用性问题。2. 分布式学习的模型准确性与通信图中的连接数相关。3. 分布式学习的模型准确性对模型副本之间的参数张量方差非常敏感。Ada算法在分布式深度学习训练中始终获得最佳收敛率，并在图像识别等任务上达到与集中式学习相当或可比的模型准确性，即使在使用1008个GPU训练ImageNet-1K的ResNet50时也是如此。

Conclusion: 本研究提出的DBench框架和Ada算法能够有效解决大规模分布式深度学习训练中的稳定性、可扩展性和通用性问题，并能在保证模型精度的前提下，显著提升训练效率。

Abstract: Although it has been extensively explored in theory, decentralized learning
is not yet green-lighted for production use, largely due to a lack of
stability, scalability, and generality in large scale DNN training. To shed
light on the production use of decentralized learning, this work studies
decentralized data parallel training at scale. To this end, we introduce a
benchmarking framework, namely DBench, to host both centralized and
decentralized DNN training. Building upon DBench, we introduce a benchmarking
methodology to uncover the correlations between model accuracy and the
variances of parameter tensors by varying communication graphs and training
scales. Based on the benchmarking results, we observe that, (1) Similar to
centralized learning, decentralized data parallel training also presents the
issues of scalability and generality when the training scales up; (2) The model
accuracy of decentralized learning is correlated to the number of connections
in a communication graph; (3) The model accuracy of decentralized learning is
surprisingly sensitive to the variance of parameter tensors across model
replicas. Built upon the observations, we propose Ada, a decentralized adaptive
approach that performs large scale DNN training following a decentralized SGD
method and adapting the communication graph in use dynamically throughout
training iterations. We apply Ada on large scale training and observe that Ada
can obtain the best convergence rates consistently in decentralized DNN
training, and delivers equally or comparably good model accuracy for all sample
applications as centralized learning does, even when training ResNet50 for
ImageNet-1K on the scale of 1008 GPUs.

</details>


### [118] [A Novel Recurrent Neural Network Framework for Prediction and Treatment of Oncogenic Mutation Progression](https://arxiv.org/abs/2509.12732)
*Rishab Parthasarathy,Achintya Bhowmik*

Main category: cs.LG

TL;DR: 该研究提出了一个基于人工智能的癌症通路分析框架，可以预测癌症严重程度和突变进程，并推荐治疗方案，从而避免了耗时且昂贵 �� 验室工作。


<details>
  <summary>Details</summary>
Motivation: 癌症仍然是主要的死亡原因，而传统的通路分析依赖于耗时�� 验室数据。该研究旨在提供一个高效、经济的 AI 驱动�� 决方案。

Method: 该研究结合了时间序列机器学习模型和通路分析。首先，从 TCGA 数据库中提取突变序列，然后使用新的预处理算法过滤关键突变。接下来，使用循环神经网络（RNN）预测癌症严重程度。最后，结合 RNN 预测、预处理信息和药物靶点数据库来预测未来突变并推荐治疗方案。

Result: 该框架的准确率超过 60%，ROC 曲线表现稳健。研究还发现每个癌症阶段可能包含几百个关键驱动突变，并生成了热图来突出显示。

Conclusion: 该研究首次提出了一个高效、经济的端到端框架，可以在不依赖昂贵、耗时 �� 验室工作的情况下预测癌症进展并提供可能的治疗方案。

Abstract: Despite significant medical advancements, cancer remains the second leading
cause of death, with over 600,000 deaths per year in the US. One emerging
field, pathway analysis, is promising but still relies on manually derived wet
lab data, which is time-consuming to acquire. This work proposes an efficient,
effective end-to-end framework for Artificial Intelligence (AI) based pathway
analysis that predicts both cancer severity and mutation progression, thus
recommending possible treatments. The proposed technique involves a novel
combination of time-series machine learning models and pathway analysis. First,
mutation sequences were isolated from The Cancer Genome Atlas (TCGA) Database.
Then, a novel preprocessing algorithm was used to filter key mutations by
mutation frequency. This data was fed into a Recurrent Neural Network (RNN)
that predicted cancer severity. Then, the model probabilistically used the RNN
predictions, information from the preprocessing algorithm, and multiple
drug-target databases to predict future mutations and recommend possible
treatments. This framework achieved robust results and Receiver Operating
Characteristic (ROC) curves (a key statistical metric) with accuracies greater
than 60%, similar to existing cancer diagnostics. In addition, preprocessing
played an instrumental role in isolating important mutations, demonstrating
that each cancer stage studied may contain on the order of a few-hundred key
driver mutations, consistent with current research. Heatmaps based on predicted
gene frequency were also generated, highlighting key mutations in each cancer.
Overall, this work is the first to propose an efficient, cost-effective
end-to-end framework for projecting cancer progression and providing possible
treatments without relying on expensive, time-consuming wet lab work.

</details>


### [119] [Similarity-Distance-Magnitude Activations](https://arxiv.org/abs/2509.12760)
*Allen Schmaltz*

Main category: cs.LG

TL;DR: 提出了一种名为SDM的新型激活函数，通过加入相似性、与训练分布的距离和输出幅度，提高了模型的鲁棒性和可解释性，尤其是在处理协变量偏移和分布外输入时，并且有利于选择性分类。


<details>
  <summary>Details</summary>
Motivation: 现有的softmax激活函数在处理协变量偏移和分布外输入时不够鲁棒，并且缺乏可解释性，这在选择性分类等场景下存在局限性。

Method: 提出了一种名为SDM（Similarity-Distance-Magnitude）的新型激活函数，它在标准的softmax基础上增加了相似性感知（训练样本的深度匹配）和与训练分布的距离感知，同时保留了原有的输出幅度感知（决策边界）。

Result: SDM激活函数在处理协变量偏移和分布外输入时比softmax更鲁棒，并且通过密集匹配提供了可解释性。它还能对类别经验累积分布函数进行划分，以防止在选择性分类中出现低召回率。

Conclusion: SDM激活函数在选择性分类方面优于softmax，即使在事后校准方法应用于softmax的情况下也是如此，因为它具有更好的鲁棒性和可解释性。

Abstract: We introduce a more robust and interpretable formulation of the standard
softmax activation function commonly used with neural networks by adding
Similarity (i.e., correctly predicted depth-matches into training) awareness
and Distance-to-training-distribution awareness to the existing output
Magnitude (i.e., decision-boundary) awareness. When used as the final-layer
activation with language models, the resulting Similarity-Distance-Magnitude
(SDM) activation function is more robust than the softmax function to
co-variate shifts and out-of-distribution inputs in high-probability regions,
and provides interpretability-by-exemplar via dense matching. Complementing the
prediction-conditional estimates, the SDM activation enables a partitioning of
the class-wise empirical CDFs to guard against low class-wise recall among
selective classifications. These properties make it preferable for selective
classification, even when considering post-hoc calibration methods over the
softmax.

</details>


### [120] [Learning to Route: Per-Sample Adaptive Routing for Multimodal Multitask Prediction](https://arxiv.org/abs/2509.12227)
*Marzieh Ajirak,Oded Bein,Ellen Rose Bowen,Dora Kanellopoulos,Avital Falk,Faith M. Gunning,Nili Solomonov,Logan Grosenick*

Main category: cs.LG

TL;DR: 提出一种新颖的自适应路由框架，用于处理多任务、多模态预测问题，并考虑数据异质性和任务交互性。该模型通过动态选择模态处理路径和任务共享策略，并在样本级别进行路由，以提高预测精度并提供可解释的见解。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机源于精神卫生领域的实际应用，特别是精神治疗场景，其中结构化评估、非结构化临床笔记、部分缺失数据以及相关的结果共存，需要一种能够处理这种复杂性的方法。

Method: 提出一种基于路由的架构，该架构动态地在每个样本的基础上选择模态处理路径和任务共享策略。模型包含多个模态路径（包括文本和数值特征的原始及融合表示），并学习将每个输入路由到信息量最大的专家组合。任务特定的预测由共享或独立的头部根据路由决策产生，整个系统端到端进行训练。

Result: 在合成数据和真实的精神治疗笔记（预测抑郁和焦虑结果）上进行了评估。实验结果表明，该方法在性能上始终优于固定的多任务或单任务基线模型，并且学习到的路由策略能够提供关于模态相关性和任务结构的清晰见解。

Conclusion: 该框架通过实现考虑数据异质性和任务相关性的逐主体自适应信息处理，解决了个性化医疗保健中的关键挑战。应用于精神治疗，该框架有望改善心理健康结果，提高治疗分配的准确性，并通过个性化干预策略提高临床成本效益。

Abstract: We propose a unified framework for adaptive routing in multitask, multimodal
prediction settings where data heterogeneity and task interactions vary across
samples. Motivated by applications in psychotherapy where structured
assessments and unstructured clinician notes coexist with partially missing
data and correlated outcomes, we introduce a routing-based architecture that
dynamically selects modality processing pathways and task-sharing strategies on
a per-sample basis. Our model defines multiple modality paths, including raw
and fused representations of text and numeric features and learns to route each
input through the most informative expert combination. Task-specific
predictions are produced by shared or independent heads depending on the
routing decision, and the entire system is trained end-to-end. We evaluate the
model on both synthetic data and real-world psychotherapy notes predicting
depression and anxiety outcomes. Our experiments show that our method
consistently outperforms fixed multitask or single-task baselines, and that the
learned routing policy provides interpretable insights into modality relevance
and task structure. This addresses critical challenges in personalized
healthcare by enabling per-subject adaptive information processing that
accounts for data heterogeneity and task correlations. Applied to
psychotherapy, this framework could improve mental health outcomes, enhance
treatment assignment precision, and increase clinical cost-effectiveness
through personalized intervention strategies.

</details>


### [121] [Rethinking the Evaluation of Alignment Methods: Insights into Diversity, Generalisation, and Safety](https://arxiv.org/abs/2509.12936)
*Denis Janiak,Julia Moska,Dawid Motyka,Karolina Seweryn,Paweł Walkowiak,Bartosz Żuk,Arkadiusz Janz*

Main category: cs.LG

TL;DR: 现有 LLM 对齐方法在事实性、安全性、简洁性、主动性和多样性五个维度上存在固有的权衡。本研究提出了一个统一的评估框架，比较了 PPO、DPO、ORPO 和 KTO 四种方法在这些维度上的表现，并使用了分布内和分布外数据集。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对 LLM 对齐中固有权衡的全面评估，通常只关注单一技术或维度。

Method: 提出一个统一的评估框架，使用 LLM-as-Judge 提示（经过人类研究验证）来比较 PPO、DPO、ORPO 和 KTO 四种对齐方法在事实性、安全性、简洁性、主动性和多样性五个维度上的表现，并辅以分布内和分布外数据集。

Result: DPO 和 KTO 在事实准确性方面表现最佳，PPO 和 DPO 在安全性方面领先，PPO 在简洁性和主动性之间取得了最佳平衡。

Conclusion: 研究结果揭示了常见的对齐方法的权衡，为开发更均衡、更可靠的 LLM 提供了指导。

Abstract: Large language models (LLMs) require careful alignment to balance competing
objectives - factuality, safety, conciseness, proactivity, and diversity.
Existing studies focus on individual techniques or specific dimensions, lacking
a holistic assessment of the inherent trade-offs. We propose a unified
evaluation framework that compares LLM alignment methods (PPO, DPO, ORPO, KTO)
across these five axes, using both in-distribution and out-of-distribution
datasets. Leveraging a specialized LLM-as-Judge prompt, validated through human
studies, we reveal that DPO and KTO excel in factual accuracy, PPO and DPO lead
in safety, and PPO best balances conciseness with proactivity. Our findings
provide insights into trade-offs of common alignment methods, guiding the
development of more balanced and reliable LLMs.

</details>


### [122] [Profiling LoRA/QLoRA Fine-Tuning Efficiency on Consumer GPUs: An RTX 4060 Case Study](https://arxiv.org/abs/2509.12229)
*MSR Avinash*

Main category: cs.LG

TL;DR: 在8GB显存限制下，使用LoRA/QLoRA在消费级GPU上进行LLM微调的研究表明，分页优化器能提升约25%的吞吐量，bf16的效率不如fp16，并且在参数高效策略下可以支持高达2048个token的序列长度。


<details>
  <summary>Details</summary>
Motivation: 研究在有限的硬件资源（特别是8GB显存的消费级GPU）上进行LoRA/QLoRA微调LLM的效率问题，并为资源受限的研究者和实践者提供指导。

Method: 在一块NVIDIA RTX 4060 GPU上，使用Qwen2.5-1.5B-Instruct模型，通过系统性地调整批处理大小、序列长度、优化器选择（AdamW vs. PagedAdamW）和精度（fp16 vs. bf16），进行LoRA/QLoRA微调的受控性能剖析研究，并报告吞吐量、每10k token的时间、显存占用以及估算的能耗。

Result: 分页优化器最多可提高25%的吞吐量（628 token/s vs. 500 token/s基线），bf16的效率低于fp16。尽管存在8GB显存限制，但使用参数高效策略可以支持高达2048个token的序列长度。

Conclusion: 这是首个针对消费级GPU上LLM微调效率进行的系统性案例研究，提供了可复现的基准测试和实用的指导方针，尤其是在严格的8GB显存限制下。

Abstract: Fine-tuning large language models (LLMs) with parameter-efficient techniques
such as LoRA and QLoRA has enabled adaptation of foundation models on modest
hardware. Yet the efficiency of such training on consumer-grade GPUs,
especially under strict 8 GB VRAM limits, remains underexplored. We present a
controlled profiling study of LoRA/QLoRA fine-tuning using the
Qwen2.5-1.5B-Instruct model on a single NVIDIA RTX 4060. Across three
representative configurations, we systematically vary batch size, sequence
length, optimizer choice (AdamW vs. PagedAdamW), and precision (fp16 vs. bf16).
We report throughput (tokens/s), time per 10k tokens, and VRAM footprint,
alongside energy estimates derived from GPU board power limits. Our results
show that paged optimizers improve throughput by up to 25% (628 tok/s vs. 500
tok/s baseline), while bf16 degrades efficiency relative to fp16. Despite 8 GB
constraints, sequence lengths up to 2048 tokens were feasible using
parameter-efficient strategies. To our knowledge, this is the first systematic
case study of LLM fine-tuning efficiency on consumer GPUs, providing
reproducible benchmarks and practical guidelines for resource-constrained
researchers and practitioners.

</details>


### [123] [When Inverse Data Outperforms: Exploring the Pitfalls of Mixed Data in Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.13079)
*Mengyi Deng,Xin Li,Tingyu Zhu,Zhicheng Yang,Zhijiang Guo,Wei Wang*

Main category: cs.LG

TL;DR: 该研究提出了r1k数据集，并通过SFT和DPO方法探索了双向推理目标下的模型对齐问题，发现在混合推理数据下存在冲突的监督信号，并强调了方向感知对齐策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有工作在数据蒸馏方面取得了o1级别性能，但大多集中于单向监督微调（SFT），忽略了不同推理模式间的复杂相互作用。

Method: 构建了一个名为r1k的高质量逆向推理数据集，该数据集是通过逆转s1k中的1000个正向示例生成的。然后，研究了SFT和直接偏好优化（DPO）在双向推理目标下对模型对齐的影响。

Result: SFT在r1k上的表现比在s1k上提高了1.6%--6.8%的准确率。然而，在SFT中混合使用正向和逆向数据会削弱方向区分性。DPO虽然能部分恢复这种区分性，但也会通过将概率质量转移到不相关的输出来抑制不太受青睐的推理路径。

Conclusion: 混合推理数据会引入冲突的监督信号，这凸显了对鲁棒且方向感知的对齐策略的需求。

Abstract: Existing work has shown that o1-level performance can be achieved with
limited data distillation, but most existing methods focus on unidirectional
supervised fine-tuning (SFT), overlooking the intricate interplay between
diverse reasoning patterns. In this paper, we construct r1k, a high-quality
reverse reasoning dataset derived by inverting 1,000 forward examples from s1k,
and examine how SFT and Direct Preference Optimization (DPO) affect alignment
under bidirectional reasoning objectives. SFT on r1k yields a 1.6%--6.8%
accuracy improvement over s1k across evaluated benchmarks. However, naively
mixing forward and reverse data during SFT weakens the directional distinction.
Although DPO can partially recover this distinction, it also suppresses less
preferred reasoning paths by shifting the probability mass toward irrelevant
outputs. These findings suggest that mixed reasoning data introduce conflicting
supervision signals, underscoring the need for robust and direction-aware
alignment strategies.

</details>


### [124] [Flexible Multimodal Neuroimaging Fusion for Alzheimer's Disease Progression Prediction](https://arxiv.org/abs/2509.12234)
*Benjamin Burns,Yuan Xue,Douglas W. Scharre,Xia Ning*

Main category: cs.LG

TL;DR: PerM-MoE是一种新颖的稀疏混合专家模型，通过为每种模态使用独立的路由器来提高多模态模型在缺失模态情况下的预测灵活性，并在预测阿尔茨海默病进展方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了提高多模态模型在临床设置中经常出现的模态缺失情况下的预测灵活性和准确性。

Method: 提出了一种名为PerM-MoE的新型稀疏混合专家模型，该模型为每种模态使用独立的路由器，而不是传统的单一路由器。使用T1加权MRI、FLAIR、淀粉样蛋白PET和Tau PET数据，在不同程度的模态缺失情况下，对临床痴呆评定量表-总盒（CDR-SB）得分的两年变化进行预测。

Result: 在预测CDR-SB得分两年变化方面，PerM-MoE在大多数模态缺失情况下都优于最先进的Flex-MoE和单一模态模型，并显示出比Flex-MoE更有效的专家利用率。

Conclusion: PerM-MoE在处理阿尔茨海默病进展预测中的模态缺失问题上，比现有的最先进方法更具鲁棒性和有效性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disease with high
inter-patient variance in rate of cognitive decline. AD progression prediction
aims to forecast patient cognitive decline and benefits from incorporating
multiple neuroimaging modalities. However, existing multimodal models fail to
make accurate predictions when many modalities are missing during inference, as
is often the case in clinical settings. To increase multimodal model
flexibility under high modality missingness, we introduce PerM-MoE, a novel
sparse mixture-of-experts method that uses independent routers for each
modality in place of the conventional, single router. Using T1-weighted MRI,
FLAIR, amyloid beta PET, and tau PET neuroimaging data from the Alzheimer's
Disease Neuroimaging Initiative (ADNI), we evaluate PerM-MoE, state-of-the-art
Flex-MoE, and unimodal neuroimaging models on predicting two-year change in
Clinical Dementia Rating-Sum of Boxes (CDR-SB) scores under varying levels of
modality missingness. PerM-MoE outperforms the state of the art in most
variations of modality missingness and demonstrates more effective utility of
experts than Flex-MoE.

</details>


### [125] [RL Fine-Tuning Heals OOD Forgetting in SFT](https://arxiv.org/abs/2509.12235)
*Hangzhan Jin,Sitao Luan,Sicheng Lyu,Guillaume Rabusseau,Reihaneh Rabbany,Doina Precup,Mohammad Hamdaqa*

Main category: cs.LG

TL;DR: SFT 记忆，RL 恢复：SFT 和 RL 的协同作用并非 RL 创造新的泛化能力，而是恢复 SFT 中丢失的 OOD 能力。OOD 性能与奇异向量的旋转相关，而非奇异值。


<details>
  <summary>Details</summary>
Motivation: 探究 LLMs 后训练中 SFT 和 RL 协同作用的机制，挑战“SFT 记忆，RL 泛化”的普遍但过简化的说法。

Method: 通过实验观察，并在 SFT 和 RL 阶段使用 SVD 分析、参数编辑等方法研究模型性能变化，重点关注奇异值和奇异向量。

Result: （1）OOD 性能在 SFT 早期达到峰值后下降（OOD 遗忘），训练/测试损失无法捕捉最佳 SFT 检查点；（2）RL 阶段主要起 OOD 恢复作用，而非生成更好的 OOD 能力；（3）恢复能力有限，SFT 时间过长或过短都会导致 RL 无法恢复；（4）OOD 行为与奇异向量的旋转高度相关，奇异值相对稳定。

Conclusion: SFT 和 RL 的协同作用机制在于 RL 恢复 SFT 过程中丢失的 OOD 能力，而非 RL 产生新的泛化能力。奇异向量的旋转是影响 OOD 行为的关键因素。

Abstract: The two-stage fine-tuning paradigm of Supervised Fine-Tuning (SFT) followed
by Reinforcement Learning (RL) has empirically shown better reasoning
performance than one-stage SFT for the post-training of Large Language Models
(LLMs). However, the evolution and mechanism behind the synergy of SFT and RL
are still under-explored and inconclusive. In our study, we find the well-known
claim "SFT memorizes, RL generalizes" is over-simplified, and discover that:
(1) OOD performance peaks at the early stage of SFT and then declines (OOD
forgetting), the best SFT checkpoint cannot be captured by training/test loss;
(2) the subsequent RL stage does not generate fundamentally better OOD
capability, instead it plays an \textbf{OOD restoration} role, recovering the
lost reasoning ability during SFT; (3) The recovery ability has boundaries,
\ie{} \textbf{if SFT trains for too short or too long, RL cannot recover the
lost OOD ability;} (4) To uncover the underlying mechanisms behind the
forgetting and restoration process, we employ SVD analysis on parameter
matrices, manually edit them, and observe their impacts on model performance.
Unlike the common belief that the shift of model capacity mainly results from
the changes of singular values, we find that they are actually quite stable
throughout fine-tuning. Instead, the OOD behavior strongly correlates with the
\textbf{rotation of singular vectors}. Our findings re-identify the roles of
SFT and RL in the two-stage fine-tuning and discover the rotation of singular
vectors as the key mechanism. %reversing the rotations induced by SFT, which
shows recovery from forgetting, whereas imposing the SFT parameter directions
onto a RL-tuned model results in performance degradation. Code is available at
https://github.com/xiaodanguoguo/RL_Heals_SFT

</details>


### [126] [WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning](https://arxiv.org/abs/2509.13305)
*Kuan Li,Zhongwang Zhang,Huifeng Yin,Rui Ye,Yida Zhao,Liwen Zhang,Litu Ou,Dingchu Zhang,Xixi Wu,Jialong Wu,Xinyu Wang,Zile Qiao,Zhen Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.LG

TL;DR: WebSailor 是一个用于增强开源 LLM 在复杂信息检索任务中能力的后训练方法。


<details>
  <summary>Details</summary>
Motivation: 当前 LLM 在信息检索方面存在认知局限性，专有系统（如 DeepResearch）已展现出超人的能力，这归因于其系统性降低不确定性的推理能力，而这是开源模型所欠缺的。

Method: WebSailor 通过结构化采样和信息模糊化生成高不确定性任务，结合 RFT cold start 和 DUPO 算法进行训练。

Result: WebSailor 在复杂信息检索任务上显著优于所有开源模型，并能达到专有模型的性能水平。

Conclusion: WebSailor 成功缩小了开源模型与专有模型在复杂信息检索能力上的差距。

Abstract: Transcending human cognitive limitations represents a critical frontier in
LLM training. Proprietary agentic systems like DeepResearch have demonstrated
superhuman capabilities on extremely complex information-seeking benchmarks
such as BrowseComp, a feat previously unattainable. We posit that their success
hinges on a sophisticated reasoning pattern absent in open-source models: the
ability to systematically reduce extreme uncertainty when navigating vast
information landscapes. Based on this insight, we introduce WebSailor, a
complete post-training methodology designed to instill this crucial capability.
Our approach involves generating novel, high-uncertainty tasks through
structured sampling and information obfuscation, RFT cold start, and an
efficient agentic RL training algorithm, Duplicating Sampling Policy
Optimization (DUPO). With this integrated pipeline, WebSailor significantly
outperforms all open-source agents in complex information-seeking tasks,
matching proprietary agents' performance and closing the capability gap.

</details>


### [127] [Why and How Auxiliary Tasks Improve JEPA Representations](https://arxiv.org/abs/2509.12249)
*Jiacan Yu,Siyi Chen,Mingrui Liu,Nono Horiuchi,Vladimir Braverman,Zicheng Xu,Dan Haramati,Randall Balestriero*

Main category: cs.LG

TL;DR: JEPA的理论分析表明，结合辅助回归任务可以防止表示坍塌，并生成更丰富的表示。


<details>
  <summary>Details</summary>
Motivation: JEPA在视觉表示学习和基于模型的强化学习中被广泛使用，但其行为仍未得到充分理解。本研究旨在理论上分析一种简单的JEPA变体，以理解其工作原理并提出改进方法。

Method: 通过理论推导，证明了一个“无不健康表示坍塌”定理，并进行了受控的消融实验来验证理论。该方法结合了一个与潜在动力学联合训练的辅助回归头。

Result: 证明了在确定性MDPs中，当训练使潜在转换一致性损失和辅助回归损失都趋于零时，非等价的观测必须映射到不同的潜在表示。消融实验表明，联合训练辅助头可以生成比单独训练更丰富的表示。

Conclusion: JEPA编码器可以通过联合训练一个辅助函数（该函数与转换动力学一起编码等价关系）来得到改进。

Abstract: Joint-Embedding Predictive Architecture (JEPA) is increasingly used for
visual representation learning and as a component in model-based RL, but its
behavior remains poorly understood. We provide a theoretical characterization
of a simple, practical JEPA variant that has an auxiliary regression head
trained jointly with latent dynamics. We prove a No Unhealthy Representation
Collapse theorem: in deterministic MDPs, if training drives both the
latent-transition consistency loss and the auxiliary regression loss to zero,
then any pair of non-equivalent observations, i.e., those that do not have the
same transition dynamics or auxiliary label, must map to distinct latent
representations. Thus, the auxiliary task anchors which distinctions the
representation must preserve. Controlled ablations in a counting environment
corroborate the theory and show that training the JEPA model jointly with the
auxiliary head generates a richer representation than training them separately.
Our work indicates a path to improve JEPA encoders: training them with an
auxiliary function that, together with the transition dynamics, encodes the
right equivalence relations.

</details>


### [128] [Deriving the Scaled-Dot-Function via Maximum Likelihood Estimation and Maximum Entropy Approach](https://arxiv.org/abs/2509.12285)
*Jiyong Ma*

Main category: cs.LG

TL;DR: 通过高斯分布对 Transformer 中的值向量进行建模，并提出了基于最大似然估计和最大熵的方法。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的方法来确定 Transformer 模型中的值向量，并探索其与缩放点积和 softmax 函数的关系。

Method: 将值向量、键向量和查询向量建模为高斯分布序列，并使用最大似然估计。还提出了一个受最大熵方法启发的替代方法。

Result: 该分析可能为 Transformer 的缩放点积或 softmax 函数提供新的解释。

Conclusion: 提出了一种基于最大似然估计和最大熵的 Transformer 值向量的新方法。

Abstract: In this paper, we present a maximum likelihood estimation approach to
determine the value vector in transformer models. We model the sequence of
value vectors, key vectors, and the query vector as a sequence of Gaussian
distributions. The variance in each Gaussian distribution depends on the time
step, the corresponding key vector, and the query vector. The mean value in
each Gaussian distribution depends on the time step, and the corresponding
value vector. This analysis may offer a new explanation of the
scaled-dot-product function or softmax function used in transformer
architectures [1]. Another explanation, inspired by [4], is based on the
maximum entropy approach in natural language processing [5]. In this approach,
a query vector and key vectors are used to derive the feature functions for the
maximum entropy model.

</details>


### [129] [C3DE: Causal-Aware Collaborative Neural Controlled Differential Equation for Long-Term Urban Crowd Flow Prediction](https://arxiv.org/abs/2509.12289)
*Yuting Liu,Qiang Zhou,Hanzhe Li,Chenqi Gong,Jingjing Gu*

Main category: cs.LG

TL;DR: 利用神经控制微分方程（NCDEs）解决长期城市人流预测中的累积采样误差问题，并提出了一种名为Causal-aware Collaborative neural CDE (C3DE) 的新方法，以解决POI演变对长期人流预测的影响，特别是多时间尺度异步动态和潜在的虚假因果关系。


<details>
  <summary>Details</summary>
Motivation: 长期城市人流预测面临累积采样误差的挑战，POI的演变及其与人流的多时间尺度异步动态以及潜在的虚假因果关系给应用NCDEs带来了困难。

Method: 提出C3DE模型，采用双路径NCDE捕捉多时间尺度的协同信号异步演变，设计动态修正机制和基于反事实的因果效应估计器来量化POI对人流的因果影响，并最小化虚假相关性的累积，最后利用融合POI和人流的协同信号进行长期预测。

Result: 在三个真实世界数据集上的广泛实验证明了C3DE的优越性能，尤其是在人流波动显著的城市中。

Conclusion: C3DE能够有效处理长期城市人流预测中的挑战，并在实际应用中表现出优越的性能。

Abstract: Long-term urban crowd flow prediction suffers significantly from cumulative
sampling errors, due to increased sequence lengths and sampling intervals,
which inspired us to leverage Neural Controlled Differential Equations (NCDEs)
to mitigate this issue. However, regarding the crucial influence of Points of
Interest (POIs) evolution on long-term crowd flow, the multi-timescale
asynchronous dynamics between crowd flow and POI distribution, coupled with
latent spurious causality, poses challenges to applying NCDEs for long-term
urban crowd flow prediction. To this end, we propose Causal-aware Collaborative
neural CDE (C3DE) to model the long-term dynamic of crowd flow. Specifically,
we introduce a dual-path NCDE as the backbone to effectively capture the
asynchronous evolution of collaborative signals across multiple time scales.
Then, we design a dynamic correction mechanism with the counterfactual-based
causal effect estimator to quantify the causal impact of POIs on crowd flow and
minimize the accumulation of spurious correlations. Finally, we leverage a
predictor for long-term prediction with the fused collaborative signals of POI
and crowd flow. Extensive experiments on three real-world datasets demonstrate
the superior performance of C3DE, particularly in cities with notable flow
fluctuations.

</details>


### [130] [Integrating Attention-Enhanced LSTM and Particle Swarm Optimization for Dynamic Pricing and Replenishment Strategies in Fresh Food Supermarkets](https://arxiv.org/abs/2509.12339)
*Xianchen Liu,Tianhui Zhang,Xinyu Zhang,Lingmin Hou,Zhen Guo,Yuanhao Tian,Yang Liu*

Main category: cs.LG

TL;DR: 本研究提出了一种结合长短期记忆（LSTM）网络和粒子群优化（PSO）算法的新方法，用于优化生鲜超市的定价和补货策略，以最大化利润并减少食物浪费。


<details>
  <summary>Details</summary>
Motivation: 生鲜食品超市面临着定价和补货策略优化的挑战，需要同时考虑销售量、价格趋势、损耗率、库存限制以及成本波动，以最大化利润并减少食物浪费。

Method: 该方法首先使用带有注意力机制的LSTM模型预测未来七天的销售量、价格趋势和损耗率。然后，将LSTM的预测结果作为输入，利用粒子群优化（PSO）算法迭代优化定价和补货策略。该模型还集成了成本加成定价，以实现基于固定和可变成本的实时动态调整。

Result: 通过结合LSTM的预测能力和PSO的优化能力，该框架能够动态调整定价和补货策略，从而最大化利润并减少食物浪费。注意力机制的引入提高了LSTM模型的可解释性，能够识别影响销售的关键时间点和因素。

Conclusion: 本研究提出的结合LSTM和PSO的框架为生鲜零售及其他涉及易腐品的行业提供了一个可扩展的解决方案，有效弥合了预测建模与优化之间的差距，实现了动态定价和库存管理的智能化，有助于提高超市运营的可持续性。

Abstract: This paper presents a novel approach to optimizing pricing and replenishment
strategies in fresh food supermarkets by combining Long Short-Term Memory
(LSTM) networks with Particle Swarm Optimization (PSO). The LSTM model,
enhanced with an attention mechanism, is used to predict sales volumes, pricing
trends, and spoilage rates over a seven-day period. The predictions generated
by the LSTM model serve as inputs for the PSO algorithm, which iteratively
optimizes pricing and replenishment strategies to maximize profitability while
adhering to inventory constraints. The integration of cost-plus pricing allows
for dynamic adjustments based on fixed and variable costs, ensuring real-time
adaptability to market fluctuations. The framework not only maximizes profits
but also reduces food waste, contributing to more sustainable supermarket
operations. The attention mechanism enhances the interpretability of the LSTM
model by identifying key time points and factors influencing sales, improving
decision-making accuracy. This methodology bridges the gap between predictive
modeling and optimization, offering a scalable solution for dynamic pricing and
inventory management in fresh food retail and other industries dealing with
perishable goods.

</details>


### [131] [Linear Dimensionality Reduction for Word Embeddings in Tabular Data Classification](https://arxiv.org/abs/2509.12346)
*Liam Ressel,Hamza A. A. Gardi*

Main category: cs.LG

TL;DR: 该研究探讨了在表格数据分类中使用线性降维技术（PCA 和 LDA）来处理高维词嵌入。


<details>
  <summary>Details</summary>
Motivation: 在表格数据分类任务中，高维词嵌入（如 300 维）和有限的训练样本带来了挑战。该研究旨在探索和改进线性降维方法以应对这些挑战。

Method: 研究了主成分分析（PCA）和线性判别分析（LDA）。对 LDA 进行了改进，包括使用收缩（shrinkage）和提出了一种名为 Partitioned-LDA 的新方法，该方法将嵌入分割成块并分别应用 LDA。

Result: PCA 在合适的子空间维度下可以优于原始嵌入。收缩 LDA 在仅使用两个维度时性能有显著提升。Partitioned-LDA 优于标准 LDA，并且与收缩结合后，在竞赛公开排行榜上达到了前十名的准确率。

Conclusion: Partitioned-LDA 结合收缩是一种有效的方法，可以提高在训练样本有限的表格数据分类任务中词嵌入的性能。

Abstract: The Engineers' Salary Prediction Challenge requires classifying salary
categories into three classes based on tabular data. The job description is
represented as a 300-dimensional word embedding incorporated into the tabular
features, drastically increasing dimensionality. Additionally, the limited
number of training samples makes classification challenging. Linear
dimensionality reduction of word embeddings for tabular data classification
remains underexplored. This paper studies Principal Component Analysis (PCA)
and Linear Discriminant Analysis (LDA). We show that PCA, with an appropriate
subspace dimension, can outperform raw embeddings. LDA without regularization
performs poorly due to covariance estimation errors, but applying shrinkage
improves performance significantly, even with only two dimensions. We propose
Partitioned-LDA, which splits embeddings into equal-sized blocks and performs
LDA separately on each, thereby reducing the size of the covariance matrices.
Partitioned-LDA outperforms regular LDA and, combined with shrinkage, achieves
top-10 accuracy on the competition public leaderboard. This method effectively
enhances word embedding performance in tabular data classification with limited
training samples.

</details>


### [132] [Enhancing Smart Farming Through Federated Learning: A Secure, Scalable, and Efficient Approach for AI-Driven Agriculture](https://arxiv.org/abs/2509.12363)
*Ritesh Janga,Rushit Dave*

Main category: cs.LG

TL;DR: 该研究提出了一个用于智慧农业的联邦学习框架，以解决明尼苏达州农场作物病害检测的隐私和效率问题。


<details>
  <summary>Details</summary>
Motivation: 在农业领域日益增长的数据驱动决策需求背景下，以及农场对其运营数据隐私的担忧，需要一种既能提高作物病害检测准确性又能保护数据隐私的解决方案。

Method: 开发一个联邦学习框架，在本地收集和处理农场数据，利用深度学习和迁移学习算法进行本地模型训练，并通过中央服务器聚合更新后的模型，以实现整体模型的改进。

Result: 期望该框架能实现高准确率的作物病害分类，良好的跨农业场景泛化能力，降低通信和训练成本，并为未来的疾病早期识别和干预奠定基础。

Conclusion: 该研究通过联邦学习技术，在保护农场数据隐私的前提下，为明尼苏达州乃至更广泛地区的智慧农业病害检测提供了一个安全、高效的解决方案，弥合了先进机器学习技术与农民实际需求之间的差距。

Abstract: The agricultural sector is undergoing a transformation with the integration
of advanced technologies, particularly in data-driven decision-making. This
work proposes a federated learning framework for smart farming, aiming to
develop a scalable, efficient, and secure solution for crop disease detection
tailored to the environmental and operational conditions of Minnesota farms. By
maintaining sensitive farm data locally and enabling collaborative model
updates, our proposed framework seeks to achieve high accuracy in crop disease
classification without compromising data privacy. We outline a methodology
involving data collection from Minnesota farms, application of local deep
learning algorithms, transfer learning, and a central aggregation server for
model refinement, aiming to achieve improved accuracy in disease detection,
good generalization across agricultural scenarios, lower costs in communication
and training time, and earlier identification and intervention against diseases
in future implementations. We outline a methodology and anticipated outcomes,
setting the stage for empirical validation in subsequent studies. This work
comes in a context where more and more demand for data-driven interpretations
in agriculture has to be weighed with concerns about privacy from farms that
are hesitant to share their operational data. This will be important to provide
a secure and efficient disease detection method that can finally revolutionize
smart farming systems and solve local agricultural problems with data
confidentiality. In doing so, this paper bridges the gap between advanced
machine learning techniques and the practical, privacy-sensitive needs of
farmers in Minnesota and beyond, leveraging the benefits of federated learning.

</details>


### [133] [Causal-Symbolic Meta-Learning (CSML): Inducing Causal World Models for Few-Shot Generalization](https://arxiv.org/abs/2509.12387)
*Mohamed Zayaan S*

Main category: cs.LG

TL;DR: 深度学习模型易受虚假关联影响，泛化能力差且需要大量数据。本文提出因果-符号元学习（CSML）框架，通过学习任务分布的潜在因果结构，实现人类般的鲁棒、样本高效学习。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在识别模式方面表现出色，但依赖虚假关联导致泛化能力差，需要海量数据集。为了实现类似人类的智能，需要鲁棒且样本高效的学习，这源于对因果机制的理解。

Method: 提出因果-符号元学习（CSML）框架，包含三个模块：1）感知模块：将原始输入映射到解耦的符号表示；2）可微分因果归纳模块：发现支配这些符号的潜在因果图；3）基于图的推理模块：利用因果图进行预测。通过跨任务分布元学习共享的因果世界模型，CSML能够快速适应新任务，包括需要干预和反事实推理的任务。

Result: 在新的基于物理的基准测试 CausalWorld 上进行实验，CSML 显著优于最先进的元学习和神经符号基线，尤其是在需要真正因果推理的任务上。

Conclusion: CSML 框架通过学习潜在因果结构，能够实现样本高效的鲁棒学习，并在需要因果推理的任务上取得优于现有方法的性能。

Abstract: Modern deep learning models excel at pattern recognition but remain
fundamentally limited by their reliance on spurious correlations, leading to
poor generalization and a demand for massive datasets. We argue that a key
ingredient for human-like intelligence-robust, sample-efficient learning-stems
from an understanding of causal mechanisms. In this work, we introduce
Causal-Symbolic Meta-Learning (CSML), a novel framework that learns to infer
the latent causal structure of a task distribution. CSML comprises three key
modules: a perception module that maps raw inputs to disentangled symbolic
representations; a differentiable causal induction module that discovers the
underlying causal graph governing these symbols and a graph-based reasoning
module that leverages this graph to make predictions. By meta-learning a shared
causal world model across a distribution of tasks, CSML can rapidly adapt to
novel tasks, including those requiring reasoning about interventions and
counterfactuals, from only a handful of examples. We introduce CausalWorld, a
new physics-based benchmark designed to test these capabilities. Our
experiments show that CSML dramatically outperforms state-of-the-art
meta-learning and neuro-symbolic baselines, particularly on tasks demanding
true causal inference.

</details>


### [134] [Evaluating the printability of stl files with ML](https://arxiv.org/abs/2509.12392)
*Janik Henn,Adrian Hauptmannl,Hamza A. A. Gardi*

Main category: cs.LG

TL;DR: AI模型用于检测3D模型中可能导致打印失败的常见问题，以帮助新手用户。


<details>
  <summary>Details</summary>
Motivation: 目前3D打印市场虽然易于使用，但仍缺乏对潜在打印失败问题的预警机制，尤其对新手用户而言。

Method: 训练一个AI模型来识别3D模型中可能导致打印失败的几何特征。

Result: 该AI模型能够识别出常见的、可能导致打印失败的3D模型问题。

Conclusion: 通过AI模型在打印前检测潜在问题，可以提高3D打印的成功率，尤其能帮助缺乏经验的用户。

Abstract: 3D printing has long been a technology for industry professionals and
enthusiasts willing to tinker or even build their own machines. This stands in
stark contrast to today's market, where recent developments have prioritized
ease of use to attract a broader audience. Slicing software nowadays has a few
ways to sanity check the input file as well as the output gcode. Our approach
introduces a novel layer of support by training an AI model to detect common
issues in 3D models. The goal is to assist less experienced users by
identifying features that are likely to cause print failures due to difficult
to print geometries before printing even begins.

</details>


### [135] [A Multimodal Foundation Model to Enhance Generalizability and Data Efficiency for Pan-cancer Prognosis Prediction](https://arxiv.org/abs/2509.12600)
*Huajun Zhou,Fengtao Zhou,Jiabo Ma,Yingxue Xu,Xi Wang,Xiuming Zhang,Li Liang,Zhenhui Li,Hao Chen*

Main category: cs.LG

TL;DR: MICE是一个多模态基础模型，通过整合病理图像、临床报告和基因组学数据，实现了对30种癌症的精准预后预测，在C-index方面表现优于现有模型，并展示了良好的泛化性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型难以充分利用多模态数据中的丰富信息并提取泛化性差的表示，因此需要一个能有效整合多模态数据以实现精准癌症预后预测的模型。

Method: MICE模型采用多个功能多样的专家来全面捕捉跨癌症和特定癌症的见解，并结合对比学习和监督学习来增强模型的泛化能力，以整合病理图像、临床报告和基因组学数据。

Result: MICE在内部和独立队列的C-index方面均优于单模态和最先进的多专家多模态模型，分别提高了3.8%至11.2%和5.8%至8.8%。模型还表现出在各种临床场景下的显著数据效率。

Conclusion: MICE模型为泛癌预后预测建立了一个有效且可扩展的基础，通过增强的泛化能力和数据效率，在个性化治疗和改善治疗结果方面具有巨大潜力。

Abstract: Multimodal data provides heterogeneous information for a holistic
understanding of the tumor microenvironment. However, existing AI models often
struggle to harness the rich information within multimodal data and extract
poorly generalizable representations. Here we present MICE (Multimodal data
Integration via Collaborative Experts), a multimodal foundation model that
effectively integrates pathology images, clinical reports, and genomics data
for precise pan-cancer prognosis prediction. Instead of conventional
multi-expert modules, MICE employs multiple functionally diverse experts to
comprehensively capture both cross-cancer and cancer-specific insights.
Leveraging data from 11,799 patients across 30 cancer types, we enhanced MICE's
generalizability by coupling contrastive and supervised learning. MICE
outperformed both unimodal and state-of-the-art multi-expert-based multimodal
models, demonstrating substantial improvements in C-index ranging from 3.8% to
11.2% on internal cohorts and 5.8% to 8.8% on independent cohorts,
respectively. Moreover, it exhibited remarkable data efficiency across diverse
clinical scenarios. With its enhanced generalizability and data efficiency,
MICE establishes an effective and scalable foundation for pan-cancer prognosis
prediction, holding strong potential to personalize tailored therapies and
improve treatment outcomes.

</details>


### [136] [Leveraging Intermediate Representations of Time Series Foundation Models for Anomaly Detection](https://arxiv.org/abs/2509.12650)
*Chan Sik Han,Keon Myung Lee*

Main category: cs.LG

TL;DR: TimeRep利用时间序列基础模型（TSFM）的中间层表示来检测异常，通过计算表示之间的距离来获得异常分数，并采用核心集策略和自适应机制来提高效率和处理概念漂移。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据异常检测对于许多实际系统的可靠运行至关重要，而现有的基于TSFM的方法通常仅依赖于其最终层表示，这促使研究者们探索利用中间层表示来改进异常检测。

Method: TimeRep首先选择预训练TSFM中最具信息量的中间层和补丁标记位置，然后通过核心集策略减小参考集合的大小。在推理时，它通过测量输入数据的中间表示与参考集合表示之间的距离来计算异常分数，并集成了一个自适应机制来处理概念漂移。

Result: 在UCR异常存档（包含250个单变量时间序列）上进行的广泛实验表明，TimeRep的性能持续优于包括非深度学习、深度学习和基于基础模型的方法在内的各种最先进基线。

Conclusion: TimeRep通过利用TSFM的中间层表示，并结合核心集策略和概念漂移自适应机制，在时间序列异常检测任务上取得了超越现有方法的性能。

Abstract: Detecting anomalies in time series data is essential for the reliable
operation of many real-world systems. Recently, time series foundation models
(TSFMs) have emerged as a powerful tool for anomaly detection. However,
existing methods typically rely on the final layer's representations of TSFMs,
computing the anomaly score as a reconstruction or forecasting error via a
task-specific head. Instead, we propose TimeRep, a novel anomaly detection
approach that leverages the intermediate layer's representations of TSFMs,
computing the anomaly score as the distance between these representations.
Given a pre-trained TSFM, TimeRep selects the intermediate layer and
patch-token position that yield the most informative representation. TimeRep
forms a reference collection of intermediate representations from the training
data and applies a core-set strategy to reduce its size while maintaining
distributional coverage. During inference, TimeRep computes the anomaly score
for incoming data by measuring the distance between its intermediate
representations and those of the collection. To address concept drift, TimeRep
integrates an adaptation mechanism that, at inference time, augments the
collection exclusively with non-redundant intermediate representations from
incoming data. We conducted extensive experiments on the UCR Anomaly Archive,
which contains 250 univariate time series. TimeRep consistently outperforms a
broad spectrum of state-of-the-art baselines, including non-DL, DL, and
foundation model-based methods.

</details>


### [137] [Instance-level Randomization: Toward More Stable LLM Evaluations](https://arxiv.org/abs/2509.12678)
*Yiyang Li,Yonghuang Wu,Ying Luo,Liangtai Sun,Zishu Qin,Lin Qiu,Xuezhi Cao,Xunliang Cai*

Main category: cs.LG

TL;DR: LLM评估不稳定，固定随机因素设置可能导致不公平比较。提出实例级随机化（ILR）方法，通过随机化每个实例的因素并平均得分来减少方差和提高公平性，且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: LLM评估存在不稳定性，小的随机因素变化会导致分数和排名剧烈波动，固定设置的评估可能导致模型间比较不公平。

Method: 提出实例级随机化（ILR）方法，随机化每个实例的所有影响评估分数的因素，运行多次实验并报告平均得分。

Result: ILR方法可以减少因随机因素引起的不稳定性和不公平比较，并且达到与先前方法相似的鲁棒性，而计算成本减少一半以上。

Conclusion: ILR方法能够有效解决LLM评估中的不稳定性问题，提高模型比较的公平性和效率。

Abstract: Evaluations of large language models (LLMs) suffer from instability, where
small changes of random factors such as few-shot examples can lead to drastic
fluctuations of scores and even model rankings. Moreover, different LLMs can
have different preferences for a certain setting of random factors. As a
result, using a fixed setting of random factors, which is often adopted as the
paradigm of current evaluations, can lead to potential unfair comparisons
between LLMs. To mitigate the volatility of evaluations, we first theoretically
analyze the sources of variance induced by changes in random factors. Targeting
these specific sources, we then propose the instance-level randomization (ILR)
method to reduce variance and enhance fairness in model comparisons. Instead of
using a fixed setting across the whole benchmark in a single experiment, we
randomize all factors that affect evaluation scores for every single instance,
run multiple experiments and report the averaged score. Theoretical analyses
and empirical results demonstrate that ILR can reduce the variance and unfair
comparisons caused by random factors, as well as achieve similar robustness
level with less than half computational cost compared with previous methods.

</details>


### [138] [Unbiased Online Curvature Approximation for Regularized Graph Continual Learning](https://arxiv.org/abs/2509.12727)
*Jie Yin,Ke Sun,Han Wu*

Main category: cs.LG

TL;DR: 图持续学习（GCL）旨在从一系列图基任务中学习，并通过正则化方法防止灾难性遗忘，尤其是在类别增量的设置下。本研究提出了一个基于 Fisher 信息矩阵（FIM）诱导的曲面参数空间的一般 GCL 正则化框架，并提出了一种新的无偏在线曲率近似方法来克服现有方法的局限性。实验表明，该方法在 GCL 任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在类别增量设置的图持续学习（GCL）中，正则化方法对于防止灾难性遗忘至关重要。现有方法（如 EWC）存在局限性，需要改进。

Method: 提出一个基于 Fisher 信息矩阵（FIM）诱导的曲面参数空间的一般 GCL 正则化框架。提出一种新的无偏在线曲率近似方法，直接在线估计正则化项，无需显式计算和存储 FIM。

Result: 所提出的方法在三个图数据集上的广泛实验表明，其显著优于现有的基于正则化的方法，在稳定性和可塑性之间取得了更好的权衡。

Conclusion: 提出的 GCL 正则化方法通过在线估计 FIM 的曲率，能更好地捕捉学习过程中的损失景观，有效防止灾难性遗忘，并在图持续学习任务上取得最优性能。

Abstract: Graph continual learning (GCL) aims to learn from a continuous sequence of
graph-based tasks. Regularization methods are vital for preventing catastrophic
forgetting in GCL, particularly in the challenging replay-free,
class-incremental setting, where each task consists of a set of unique classes.
In this work, we first establish a general regularization framework for GCL
based on the curved parameter space induced by the Fisher information matrix
(FIM). We show that the dominant Elastic Weight Consolidation (EWC) and its
variants are a special case within this framework, using a diagonal
approximation of the empirical FIM based on parameters from previous tasks. To
overcome their limitations, we propose a new unbiased online curvature
approximation of the full FIM based on the model's current learning state. Our
method directly estimates the regularization term in an online manner without
explicitly evaluating and storing the FIM itself. This enables the model to
better capture the loss landscape during learning new tasks while retaining the
knowledge learned from previous tasks. Extensive experiments on three graph
datasets demonstrate that our method significantly outperforms existing
regularization-based methods, achieving a superior trade-off between stability
(retaining old knowledge) and plasticity (acquiring new knowledge).

</details>


### [139] [A Graph Machine Learning Approach for Detecting Topological Patterns in Transactional Graphs](https://arxiv.org/abs/2509.12730)
*Francesco Zola,Jon Ander Medina,Andrea Venturi,Amaia Gil,Raul Orduna*

Main category: cs.LG

TL;DR: 数字生态系统中的金融犯罪需要更具适应性的检测策略。本研究提出一种结合图机器学习和网络分析的方法，利用图自动编码器检测交易图中的拓扑模式，并设计了一个预处理框架来解决稀疏、无标签数据的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的系统难以应对数字生态系统中不断演变的金融犯罪策略，因此需要一种能分析行为者交互以发现可疑活动并提取其犯罪手法（modus operandi）的新方法。

Method: 本研究提出一种结合图机器学习和网络分析的方法。首先，设计了一个包含提取图结构、考虑数据时间性、检测社区和应用自动标记策略的四步预处理框架，以生成弱的地面真实标签。然后，利用图自动编码器（GAE）区分已知的拓扑模式，并比较了三种不同的GAE变体。

Result: 初步结果表明，这种以模式为中心、以拓扑为导向的方法能够有效检测复杂的金融犯罪 schemes。

Conclusion: 所提出的方法为检测复杂的金融犯罪 schemes 提供了一种有前景的替代传统基于规则的检测系统的方法。

Abstract: The rise of digital ecosystems has exposed the financial sector to evolving
abuse and criminal tactics that share operational knowledge and techniques both
within and across different environments (fiat-based, crypto-assets, etc.).
Traditional rule-based systems lack the adaptability needed to detect
sophisticated or coordinated criminal behaviors (patterns), highlighting the
need for strategies that analyze actors' interactions to uncover suspicious
activities and extract their modus operandi. For this reason, in this work, we
propose an approach that integrates graph machine learning and network analysis
to improve the detection of well-known topological patterns within
transactional graphs. However, a key challenge lies in the limitations of
traditional financial datasets, which often provide sparse, unlabeled
information that is difficult to use for graph-based pattern analysis.
Therefore, we firstly propose a four-step preprocessing framework that involves
(i) extracting graph structures, (ii) considering data temporality to manage
large node sets, (iii) detecting communities within, and (iv) applying
automatic labeling strategies to generate weak ground-truth labels. Then, once
the data is processed, Graph Autoencoders are implemented to distinguish among
the well-known topological patterns. Specifically, three different GAE variants
are implemented and compared in this analysis. Preliminary results show that
this pattern-focused, topology-driven method is effective for detecting complex
financial crime schemes, offering a promising alternative to conventional
rule-based detection systems.

</details>


### [140] [EmbeddedML: A New Optimized and Fast Machine Learning Library](https://arxiv.org/abs/2509.12774)
*Halil Hüseyin Çalışkan,Talha Koruk*

Main category: cs.LG

TL;DR: EmbeddedML是一个优化训练时间和提高准确性的机器学习库，在回归和分类任务上表现优于scikit-learn。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习库在大数据集上训练速度慢，本文旨在解决此问题。

Method: 通过数学重写和优化算法来提高训练速度和准确性。

Result: 与scikit-learn相比，在回归模型上速度提高约10倍，在分类模型上，SVM训练时间减少约2倍（小数据集）至800倍（大数据集），逻辑回归训练时间减少约4倍。

Conclusion: EmbeddedML库提供了优化后的回归、分类、聚类和降维算法，能显著减少训练时间。

Abstract: Machine learning models and libraries can train datasets of different sizes
and perform prediction and classification operations, but machine learning
models and libraries cause slow and long training times on large datasets. This
article introduces EmbeddedML, a training-time-optimized and mathematically
enhanced machine learning library. The speed was increased by approximately
times compared to scikit-learn without any loss in terms of accuracy in
regression models such as Multiple Linear Regression. Logistic Regression and
Support Vector Machines (SVM) algorithms have been mathematically rewritten to
reduce training time and increase accuracy in classification models. With the
applied mathematical improvements, training time has been reduced by
approximately 2 times for SVM on small datasets and by around 800 times on
large datasets, and by approximately 4 times for Logistic Regression, compared
to the scikit-learn implementation. In summary, the EmbeddedML library offers
regression, classification, clustering, and dimensionality reduction algorithms
that are mathematically rewritten and optimized to reduce training time.

</details>


### [141] [Sy-FAR: Symmetry-based Fair Adversarial Robustness](https://arxiv.org/abs/2509.12939)
*Haneen Najjar,Eyal Ronen,Mahmood Sharif*

Main category: cs.LG

TL;DR: 现实世界的对抗性攻击对安全关键的机器学习系统（如面部识别系统）构成了威胁。虽然已有方法试图提高这些系统的鲁棒性，但它们往往会导致不公平的鲁棒性，即攻击某些类别比攻击其他类别更容易。本文提出了一种名为 Sy-FAR 的新技术，旨在实现攻击成功率的对称性，而不是追求完美公平性，因为在现实世界的任务中，完美公平性通常难以实现。Sy-FAR 通过鼓励对称性来优化对抗鲁棒性，并在多个数据集和模型架构上进行了广泛评估。结果表明，Sy-FAR 在公平对抗鲁棒性方面显著优于现有技术，并且运行速度更快、更稳定。此外，Sy-FAR 还能减轻对抗样本易于被分类到的目标类别的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有的提高机器学习系统对抗鲁棒性的方法通常会导致不公平的鲁棒性，即攻击不同类别或群体的难易程度不同。虽然有研究试图在提高鲁棒性的同时实现公平性，但它们主要关注安全性和公平性不太关键的场景。在现实世界的公平性关键任务（如面部识别）中，追求完美的公平性（即所有类别被攻击的难易程度完全相同）通常是不可行的，因为某些类别可能非常相似，导致它们之间更容易发生错分。因此，本文认为追求对称性（即从类别 i 攻击到类别 j 的成功率与从类别 j 攻击到类别 i 的成功率相同）是更可行的方法。对称性是可取的，因为类别相似性在大多数领域中通常是对称的。此外，本文理论证明，个体之间的对称性可以诱导出子群体之间的对称性，这与其他往往难以实现群体公平性的公平性概念不同。

Method: 本文提出了一种名为 Sy-FAR 的技术，旨在鼓励对称性，同时优化对抗鲁棒性。该技术通过在训练过程中引入对称性约束来实现。

Result: 在五个数据集和三种模型架构上进行的大量评估表明，Sy-FAR 在公平对抗鲁棒性方面显著优于最先进的方法。此外，Sy-FAR 的运行速度更快，并且在不同运行之间具有更高的稳定性。值得注意的是，Sy-FAR 还减轻了研究中发现的另一种不公平现象：在引入对称性后，对抗样本易于被分类到的目标类别变得明显不那么脆弱。

Conclusion: 追求对称性是提高公平对抗鲁棒性的一种比追求完美公平性更可行且有效的方法。Sy-FAR 技术通过引入对称性约束，在保持或提高对抗鲁棒性的同时，显著改善了公平性，并解决了现有方法存在的一些问题。

Abstract: Security-critical machine-learning (ML) systems, such as face-recognition
systems, are susceptible to adversarial examples, including real-world
physically realizable attacks. Various means to boost ML's adversarial
robustness have been proposed; however, they typically induce unfair
robustness: It is often easier to attack from certain classes or groups than
from others. Several techniques have been developed to improve adversarial
robustness while seeking perfect fairness between classes. Yet, prior work has
focused on settings where security and fairness are less critical. Our insight
is that achieving perfect parity in realistic fairness-critical tasks, such as
face recognition, is often infeasible -- some classes may be highly similar,
leading to more misclassifications between them. Instead, we suggest that
seeking symmetry -- i.e., attacks from class $i$ to $j$ would be as successful
as from $j$ to $i$ -- is more tractable. Intuitively, symmetry is a desirable
because class resemblance is a symmetric relation in most domains.
Additionally, as we prove theoretically, symmetry between individuals induces
symmetry between any set of sub-groups, in contrast to other fairness notions
where group-fairness is often elusive. We develop Sy-FAR, a technique to
encourage symmetry while also optimizing adversarial robustness and extensively
evaluate it using five datasets, with three model architectures, including
against targeted and untargeted realistic attacks. The results show Sy-FAR
significantly improves fair adversarial robustness compared to state-of-the-art
methods. Moreover, we find that Sy-FAR is faster and more consistent across
runs. Notably, Sy-FAR also ameliorates another type of unfairness we discover
in this work -- target classes that adversarial examples are likely to be
classified into become significantly less vulnerable after inducing symmetry.

</details>


### [142] [Bridging Performance Gaps for Foundation Models: A Post-Training Strategy for ECGFounder](https://arxiv.org/abs/2509.12991)
*Ya Zhou,Yujie Yang,Xiaohan Fan,Wei Zhao*

Main category: cs.LG

TL;DR: ECGFoundation模型可通过后训练策略提升性能，并在PTB-XL基准测试中表现优于现有方法，同时具有更好的稳定性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的ECGFoundation模型在临床应用中存在性能差距，可能是因为缺乏有效的后训练策略。

Method: 提出了一种简单有效的后训练方法来增强ECGFoundation模型。

Result: 在PTB-XL基准测试中，该方法将宏观AUROC提高了1.2%-3.3%，宏观AUPRC提高了5.3%-20.9%，优于现有方法，并具有更好的稳定性和样本效率。

Conclusion: 后训练策略有潜力改进ECGFoundation模型，并推动该领域的发展。

Abstract: ECG foundation models are increasingly popular due to their adaptability
across various tasks. However, their clinical applicability is often limited by
performance gaps compared to task-specific models, even after pre-training on
large ECG datasets and fine-tuning on target data. This limitation is likely
due to the lack of an effective post-training strategy. In this paper, we
propose a simple yet effective post-training approach to enhance ECGFounder, a
state-of-the-art ECG foundation model pre-trained on over 7 million ECG
recordings. Experiments on the PTB-XL benchmark show that our approach improves
the baseline fine-tuning strategy by 1.2%-3.3% in macro AUROC and 5.3%-20.9% in
macro AUPRC. Additionally, our method outperforms several recent
state-of-the-art approaches, including task-specific and advanced
architectures. Further evaluation reveals that our method is more stable and
sample-efficient compared to the baseline, achieving a 9.1% improvement in
macro AUROC and a 34.9% improvement in macro AUPRC using just 10% of the
training data. Ablation studies identify key components, such as stochastic
depth and preview linear probing, that contribute to the enhanced performance.
These findings underscore the potential of post-training strategies to improve
ECG foundation models, and we hope this work will contribute to the continued
development of foundation models in the ECG domain.

</details>


### [143] [FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning](https://arxiv.org/abs/2509.13160)
*Liang Hu,Jianpeng Jiao,Jiashuo Liu,Yanle Ren,Zhoufutu Wen,Kaiyuan Zhang,Xuanliang Zhang,Xiang Gao,Tianci He,Fei Hu,Yali Liao,Zaiyuan Wang,Chenghao Yang,Qianyu Yang,Mingren Yin,Zhiyuan Zeng,Ge Zhang,Xinyi Zhang,Xiying Zhao,Zhenwei Zhu,Hongseok Namkoong,Wenhao Huang,Yuwen Tang*

Main category: cs.LG

TL;DR: 提出了一个名为FinSearchComp的金融搜索和推理基准，以评估LLM代理在处理复杂、有时限的金融数据方面的能力，并展示了现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的金融数据集缺乏对端到端智能体搜索能力的评估，而金融领域（需要处理复杂、有时限、领域特定的数据）是评估搜索能力和知识推理的理想场所。

Method: 构建了一个名为FinSearchComp的基准，包含三个任务：有时限数据获取、简单历史查找和复杂历史调查。使用70位金融专家进行标注，并建立了严格的多阶段质量保证流程。该基准包含635个问题，覆盖全球和中国市场，并评估了21个模型。

Result: Grok 4 (web) 在全球子集上表现最佳，接近专家水平。DouBao (web) 在中国子集上领先。实验表明，为智能体配备网络搜索和金融插件可以显著提高其在FinSearchComp上的表现，并且模型和工具的来源国对性能有显著影响。

Conclusion: FinSearchComp 是一个专业的、高难度的金融搜索和推理测试平台，通过模拟真实的金融分析师任务并提供端到端的评估，为LLM代理在该领域的进步提供了重要的评估工具。

Abstract: Search has emerged as core infrastructure for LLM-based agents and is widely
viewed as critical on the path toward more general intelligence. Finance is a
particularly demanding proving ground: analysts routinely conduct complex,
multi-step searches over time-sensitive, domain-specific data, making it ideal
for assessing both search proficiency and knowledge-grounded reasoning. Yet no
existing open financial datasets evaluate data searching capability of
end-to-end agents, largely because constructing realistic, complicated tasks
requires deep financial expertise and time-sensitive data is hard to evaluate.
We present FinSearchComp, the first fully open-source agent benchmark for
realistic, open-domain financial search and reasoning. FinSearchComp comprises
three tasks -- Time-Sensitive Data Fetching, Simple Historical Lookup, and
Complex Historical Investigation -- closely reproduce real-world financial
analyst workflows. To ensure difficulty and reliability, we engage 70
professional financial experts for annotation and implement a rigorous
multi-stage quality-assurance pipeline. The benchmark includes 635 questions
spanning global and Greater China markets, and we evaluate 21 models (products)
on it. Grok 4 (web) tops the global subset, approaching expert-level accuracy.
DouBao (web) leads on the Greater China subset. Experimental analyses show that
equipping agents with web search and financial plugins substantially improves
results on FinSearchComp, and the country origin of models and tools impact
performance significantly.By aligning with realistic analyst tasks and
providing end-to-end evaluation, FinSearchComp offers a professional,
high-difficulty testbed for complex financial search and reasoning.

</details>


### [144] [On the Correlation between Individual Fairness and Predictive Accuracy in Probabilistic Models](https://arxiv.org/abs/2509.13165)
*Alessandro Antonucci,Eric Rossetto,Ivan Duvnjak*

Main category: cs.LG

TL;DR: 本文研究了生成概率分类器中的个体公平性问题，通过分析私有特征扰动下的后验推断的鲁棒性，提出鲁棒性与预测准确性相关的假设，并通过实验验证了这一假设，为缓解公平性与准确性之间的权衡提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 研究生成概率分类器中的个体公平性，分析私有特征扰动对后验推断鲁棒性的影响，并假设鲁棒性与预测准确性之间存在相关性。

Method: 使用带有公平性问题的十四个数据集，以贝叶斯网络为生成模型，将鲁棒性分析问题转化为辅助马尔可夫随机场中的最可能解释问题。

Result: 实验证实了鲁棒性与准确性之间的相关性假设。

Conclusion: 个体公平性与预测准确性之间存在相关性，为缓解二者之间的权衡提供了新的可能。

Abstract: We investigate individual fairness in generative probabilistic classifiers by
analysing the robustness of posterior inferences to perturbations in private
features. Building on established results in robustness analysis, we
hypothesise a correlation between robustness and predictive accuracy,
specifically, instances exhibiting greater robustness are more likely to be
classified accurately. We empirically assess this hypothesis using a benchmark
of fourteen datasets with fairness concerns, employing Bayesian networks as the
underlying generative models. To address the computational complexity
associated with robustness analysis over multiple private features with
Bayesian networks, we reformulate the problem as a most probable explanation
task in an auxiliary Markov random field. Our experiments confirm the
hypothesis about the correlation, suggesting novel directions to mitigate the
traditional trade-off between fairness and accuracy.

</details>


### [145] [Is Meta-Learning Out? Rethinking Unsupervised Few-Shot Classification with Limited Entropy](https://arxiv.org/abs/2509.13185)
*Yunchuan Guan,Yu Liu,Ke Zhou,Zhiqi Shen,Jenq-Neng Hwang,Serge Belongie,Lei Li*

Main category: cs.LG

TL;DR: Meta-learning, despite challenges from whole-class training, demonstrates superior generalization, efficiency, and robustness in limited-data scenarios, particularly for unsupervised tasks. A new framework, MINO, leverages these advantages for enhanced unsupervised few-shot and zero-shot performance.


<details>
  <summary>Details</summary>
Motivation: To demonstrate the value of meta-learning compared to whole-class training in few-shot tasks by establishing an entropy-limited supervised setting for fair comparisons, and to show meta-learning's advantages in efficiency and robustness for unsupervised tasks.

Method: Established an entropy-limited supervised setting for fair comparisons. Theoretically analyzed and experimentally validated generalization bounds. Proposed MINO framework using DBSCAN with a dynamic head for unsupervised task construction and a stability-based meta-scaler for robustness against label noise.

Result: Meta-learning has a tighter generalization bound compared to whole-class training. Meta-learning is more efficient with limited entropy and more robust to label noise and heterogeneous tasks. MINO framework confirmed effective in multiple unsupervised few-shot and zero-shot tasks.

Conclusion: Meta-learning offers significant advantages over whole-class training in terms of generalization, efficiency, and robustness, especially in unsupervised and noisy settings. The proposed MINO framework effectively utilizes these advantages to improve unsupervised few-shot and zero-shot performance.

Abstract: Meta-learning is a powerful paradigm for tackling few-shot tasks. However,
recent studies indicate that models trained with the whole-class training
strategy can achieve comparable performance to those trained with meta-learning
in few-shot classification tasks. To demonstrate the value of meta-learning, we
establish an entropy-limited supervised setting for fair comparisons. Through
both theoretical analysis and experimental validation, we establish that
meta-learning has a tighter generalization bound compared to whole-class
training. We unravel that meta-learning is more efficient with limited entropy
and is more robust to label noise and heterogeneous tasks, making it
well-suited for unsupervised tasks. Based on these insights, We propose MINO, a
meta-learning framework designed to enhance unsupervised performance. MINO
utilizes the adaptive clustering algorithm DBSCAN with a dynamic head for
unsupervised task construction and a stability-based meta-scaler for robustness
against label noise. Extensive experiments confirm its effectiveness in
multiple unsupervised few-shot and zero-shot tasks.

</details>


### [146] [B-TGAT: A Bi-directional Temporal Graph Attention Transformer for Clustering Multivariate Spatiotemporal Data](https://arxiv.org/abs/2509.13202)
*Francis Ndikum Nji,Vandana Janaja,Jianwu Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种时间分配的混合U-Net自编码器，集成了双向时间图注意力Transformer（B-TGAT），用于对多维时空气候数据集进行高效的时间聚类。


<details>
  <summary>Details</summary>
Motivation: 传统的聚类方法难以同时捕捉时空气候数据中的局部和全局时间关系，并保持空间背景，因为这些数据具有复杂的时间依赖性、不断演变的 空间相互作用和非平稳动力学。

Method: 提出了一种时间分配的混合U-Net自编码器，其中编码器和解码器采用ConvLSTM2D模块来提取联合时空特征，并通过残差连接保留多尺度空间细节。在瓶颈处，B-TGAT集成了基于图的空间建模和注意力驱动的时间编码，以实现对时间邻域的自适应加权，并捕捉区域间的短期和长期依赖关系。

Result: 实验结果表明，与现有的基线方法相比，该模型在三个不同的时空气候数据集上表现出优越的聚类可分离性、时间稳定性和与已知气候转换的一致性。

Conclusion: ConvLSTM2D、U-Net残差连接和B-TGAT的结合，在提高时间聚类性能的同时，能够提供对复杂时空变异性的可解释见解，从而推动了方法学和气候科学应用的发展。

Abstract: Clustering high-dimensional multivariate spatiotemporal climate data is
challenging due to complex temporal dependencies, evolving spatial
interactions, and non-stationary dynamics. Conventional clustering methods,
including recurrent and convolutional models, often struggle to capture both
local and global temporal relationships while preserving spatial context. We
present a time-distributed hybrid U-Net autoencoder that integrates a
Bi-directional Temporal Graph Attention Transformer (B-TGAT) to guide efficient
temporal clustering of multidimensional spatiotemporal climate datasets. The
encoder and decoder are equipped with ConvLSTM2D modules that extract joint
spatial--temporal features by modeling localized dynamics and spatial
correlations over time, and skip connections that preserve multiscale spatial
details during feature compression and reconstruction. At the bottleneck,
B-TGAT integrates graph-based spatial modeling with attention-driven temporal
encoding, enabling adaptive weighting of temporal neighbors and capturing both
short and long-range dependencies across regions. This architecture produces
discriminative latent embeddings optimized for clustering. Experiments on three
distinct spatiotemporal climate datasets demonstrate superior cluster
separability, temporal stability, and alignment with known climate transitions
compared to state-of-the-art baselines. The integration of ConvLSTM2D, U-Net
skip connections, and B-TGAT enhances temporal clustering performance while
providing interpretable insights into complex spatiotemporal variability,
advancing both methodological development and climate science applications.

</details>


### [147] [Single-stream Policy Optimization](https://arxiv.org/abs/2509.13232)
*Zhongwen Xu,Zihan Ding*

Main category: cs.LG

TL;DR: SPO是一种新的单流策略优化方法，解决了现有基于组的方法在策略梯度LLM优化中存在的问题，提高了稳定性和可扩展性，并在数学推理任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于组的策略梯度优化方法（如GRPO）在减少方差的同时，存在因频繁出现的简并组而导致学习信号丢失，以及同步屏障阻碍扩展性的问题。

Method: SPO采用单流视角，用持久的、KL自适应的值追踪器取代了每组基线，并对整个批次中的优势进行了全局归一化，为每个样本提供稳定、低方差的学习信号。由于没有组，SPO可以实现更高的吞吐量，并能在长周期或工具集成等生成时间变化的场景中有效扩展。此外，持久的值追踪器还可以通过优先采样实现自适应课程学习。

Result: 在Qwen3-8B模型上进行实验，SPO比GRPO收敛更平稳，准确性更高，并消除了在简并组上浪费的计算。消融研究证实了SPO的优势来自于其对基线估计和优势归一化的原则性处理。在五个数学基准测试中，SPO将平均maj@32提高了3.4个百分点，在BRUMO 25上提高了7.3个百分点，在AIME 25上提高了4.4个百分点，在HMMT 25上提高了3.3个百分点，并在所有评估的k值中在pass@k上实现了持续的相对提升。

Conclusion: SPO是一种更稳健、更高效的LLM推理方法，它通过基础原理而不是增加复杂性来推动LLM推理的进步。

Abstract: We revisit policy-gradient optimization for Large Language Models (LLMs) from
a single-stream perspective. Prevailing group-based methods like GRPO reduce
variance with on-the-fly baselines but suffer from critical flaws: frequent
degenerate groups erase learning signals, and synchronization barriers hinder
scalability. We introduce Single-stream Policy Optimization (SPO), which
eliminates these issues by design. SPO replaces per-group baselines with a
persistent, KL-adaptive value tracker and normalizes advantages globally across
the batch, providing a stable, low-variance learning signal for every sample.
Being group-free, SPO enables higher throughput and scales effectively in
long-horizon or tool-integrated settings where generation times vary.
Furthermore, the persistent value tracker naturally enables an adaptive
curriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO
converges more smoothly and attains higher accuracy than GRPO, while
eliminating computation wasted on degenerate groups. Ablation studies confirm
that SPO's gains stem from its principled approach to baseline estimation and
advantage normalization, offering a more robust and efficient path for LLM
reasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the
average maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial
absolute point gains on challenging datasets, including +7.3 pp on BRUMO 25,
+4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain
in pass@$k$ across the evaluated $k$ values. SPO's success challenges the
prevailing trend of adding incidental complexity to RL algorithms, highlighting
a path where fundamental principles, not architectural workarounds, drive the
next wave of progress in LLM reasoning.

</details>


### [148] [Metacognitive Reuse: Turning Recurring LLM Reasoning Into Concise Behaviors](https://arxiv.org/abs/2509.13237)
*Aniket Didolkar,Nicolas Ballas,Sanjeev Arora,Anirudh Goyal*

Main category: cs.LG

TL;DR: LLMs通过将重复的推理片段转化为可复用的“行为”来提高多步问题解决的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在解决多步问题时，会重复推导相同的中间步骤，导致token使用量和延迟增加，并减少了用于探索的上下文窗口容量。

Method: 提出一种将重复的推理片段转化为简洁、可复用的“行为”（名称+指令）的机制，该机制通过模型自身的元认知分析先前的推理过程来完成。这些行为被存储在“行为手册”中，并在推理时以上下文形式提供给模型，或者通过监督微调（SFT）将其提炼到模型参数中。

Result: 1. 行为条件推理：在推理过程中将相关行为以上下文形式提供给LLM，可将推理token数量减少高达46%，同时保持或提高基线准确性。
2. 行为引导的自我改进：无需更新参数，模型即可利用自身先前解决问题的行为来改进未来的推理，准确率比朴素的批判和修正基线高出10%。
3. 行为条件SFT：与标准的SFT相比，在行为条件推理过程中进行SFT能更有效地将非推理模型转化为推理模型。

Conclusion: 将缓慢的推导转化为快速的过程提示，能够使LLM记住如何推理，而不仅仅是得出结论。

Abstract: Large language models (LLMs) now solve multi-step problems by emitting
extended chains of thought. During the process, they often re-derive the same
intermediate steps across problems, inflating token usage and latency. This
saturation of the context window leaves less capacity for exploration. We study
a simple mechanism that converts recurring reasoning fragments into concise,
reusable "behaviors" (name + instruction) via the model's own metacognitive
analysis of prior traces. These behaviors are stored in a "behavior handbook"
which supplies them to the model in-context at inference or distills them into
parameters via supervised fine-tuning. This approach achieves improved
test-time reasoning across three different settings - 1) Behavior-conditioned
inference: Providing the LLM relevant behaviors in-context during reasoning
reduces number of reasoning tokens by up to 46% while matching or improving
baseline accuracy; 2) Behavior-guided self-improvement: Without any parameter
updates, the model improves its own future reasoning by leveraging behaviors
from its own past problem solving attempts. This yields up to 10% higher
accuracy than a naive critique-and-revise baseline; and 3) Behavior-conditioned
SFT: SFT on behavior-conditioned reasoning traces is more effective at
converting non-reasoning models into reasoning models as compared to vanilla
SFT. Together, these results indicate that turning slow derivations into fast
procedural hints enables LLMs to remember how to reason, not just what to
conclude.

</details>


### [149] [JANUS: A Dual-Constraint Generative Framework for Stealthy Node Injection Attacks](https://arxiv.org/abs/2509.13266)
*Jiahao Zhang,Xiaobing Pei,Zhaokun Zhong,Wenqiang Hao,Zhenghao Tang*

Main category: cs.LG

TL;DR: 现有GNN对抗性攻击方法在隐蔽性方面存在局限，本文提出JANUS框架，通过局部特征流形对齐和全局结构与语义模式对齐，利用强化学习优化节点注入攻击，显著提升攻击效果和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有GNN对抗性攻击方法在隐蔽性方面存在不足，通常依赖代理指标或只关注局部结构，导致局部短视。为了克服这些局限性，需要一种能够同时考虑注入内容的根本特征和全局结构一致性的方法。

Method: JANUS框架通过两个关键策略实现隐蔽的节点注入攻击：1. 局部层面：引入局部特征流形对齐策略，在特征空间中实现几何一致性。2. 全局层面：结合结构化潜在变量，最大化与生成结构的互信息，确保注入结构与原始图的语义模式一致。该框架将注入攻击建模为序列决策过程，并使用强化学习代理进行优化。

Result: 在多个标准数据集上的实验表明，JANUS框架在攻击有效性和隐蔽性方面均显著优于现有方法。

Conclusion: JANUS框架通过结合局部特征流形对齐和全局结构与语义模式对齐，并利用强化学习进行优化，能够实现更有效的隐蔽节点注入攻击，克服了现有方法的局限性。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable performance across
various applications, yet they are vulnerable to sophisticated adversarial
attacks, particularly node injection attacks. The success of such attacks
heavily relies on their stealthiness, the ability to blend in with the original
graph and evade detection. However, existing methods often achieve stealthiness
by relying on indirect proxy metrics, lacking consideration for the fundamental
characteristics of the injected content, or focusing only on imitating local
structures, which leads to the problem of local myopia. To overcome these
limitations, we propose a dual-constraint stealthy node injection framework,
called Joint Alignment of Nodal and Universal Structures (JANUS). At the local
level, we introduce a local feature manifold alignment strategy to achieve
geometric consistency in the feature space. At the global level, we incorporate
structured latent variables and maximize the mutual information with the
generated structures, ensuring the injected structures are consistent with the
semantic patterns of the original graph. We model the injection attack as a
sequential decision process, which is optimized by a reinforcement learning
agent. Experiments on multiple standard datasets demonstrate that the JANUS
framework significantly outperforms existing methods in terms of both attack
effectiveness and stealthiness.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [150] [PromptSculptor: Multi-Agent Based Text-to-Image Prompt Optimization](https://arxiv.org/abs/2509.12446)
*Dawei Xiang,Wenyan Xu,Kexin Chu,Zixu Shen,Tianqi Ding,Wei Zhang*

Main category: cs.MA

TL;DR: PromptSculptor是一个多智能体框架，通过迭代优化提示来改进文本到图像生成，提高了输出质量并减少了用户迭代次数。


<details>
  <summary>Details</summary>
Motivation: 用户需要详细的提示才能生成高质量的图像，这个过程通常需要多次修改。

Method: PromptSculptor是一个多智能体框架，将任务分解为四个专用智能体，利用链式思考推理来丰富细节，并使用自我评估和反馈调优智能体进行迭代优化。

Result: PromptSculptor显著提高了输出质量，减少了用户满意所需的迭代次数，并且可以无缝集成到各种文本到图像模型中。

Conclusion: PromptSculptor通过自动化提示优化过程，为文本到图像生成带来了改进，并具有工业应用潜力。

Abstract: The rapid advancement of generative AI has democratized access to powerful
tools such as Text-to-Image models. However, to generate high-quality images,
users must still craft detailed prompts specifying scene, style, and
context-often through multiple rounds of refinement. We propose PromptSculptor,
a novel multi-agent framework that automates this iterative prompt optimization
process. Our system decomposes the task into four specialized agents that work
collaboratively to transform a short, vague user prompt into a comprehensive,
refined prompt. By leveraging Chain-of-Thought reasoning, our framework
effectively infers hidden context and enriches scene and background details. To
iteratively refine the prompt, a self-evaluation agent aligns the modified
prompt with the original input, while a feedback-tuning agent incorporates user
feedback for further refinement. Experimental results demonstrate that
PromptSculptor significantly enhances output quality and reduces the number of
iterations needed for user satisfaction. Moreover, its model-agnostic design
allows seamless integration with various T2I models, paving the way for
industrial applications.

</details>


### [151] [Between proportionnality and envy-freeness: k-proportionality](https://arxiv.org/abs/2509.12903)
*Guillaume Chèze*

Main category: cs.MA

TL;DR: 本文引入了一种介于比例分割和无嫉妒分割之间的“k-比例分割”概念，并研究了其在蛋糕分割问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究比例分割和无嫉妒分割之间的差异，理解公平分割中的难点。

Method: 引入并研究k-比例分割的概念，其中k=n为比例分割，k=2为无嫉妒分割。

Result: 证明了在k ≤ n-1时，可能不存在k-比例且公平的分割（当分割块要求连通时）；证明了在k ≤ n-1时，可能不存在k-比例且帕累托最优的分割（当分割块要求连通时）。

Conclusion: k-比例分割概念可以统一表述关于强无嫉妒和强比例分割的定理，并揭示了在弱化无嫉妒条件时仍可能出现分割上的不可能性。

Abstract: This article deals with the cake cutting problem. In this setting, there
exists two notions of fair division: proportional division (when there are n
players, each player thinks to get at least 1/n of the cake) and envy-free
division (each player wants to keep his or her share because he or she does not
envy the portion given to another player). Some results are valid for
proportional division but not for envy-free division. Here, we introduce and
study a scale between the proportional division and the envy-free division. The
goal is to understand where is the gap between statements about proportional
division and envy-free division. This scale comes from the notion introduced in
this article: k-proportionality. When k = n this notion corresponds to the
proportional division and when k = 2 it corresponds to envy-free division. With
k-proportionality we can understand where some difficulties in fair division
lie. First, we show that there are situations in which there is no
k-proportional and equitable division of a pie with connected pieces when k
$\le$ n -1. This result was known only for envy-free division, ie k = 2. Next,
we prove that there are situations in which there is no Pareto-optimal
k-proportional division of a cake with connected pieces when k $\le$ n -1. This
result was known only for k = 2. These theorems say that we can get an
impossibility result even if we do not consider an envy-free division but a
weaker notion. Finally, k-proportionality allows to give a generalization with
a uniform statement of theorems about strong envy-free and strong proportional
divisions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [152] [HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic Decision-Making](https://arxiv.org/abs/2509.12927)
*Xingxing Hong,Yungong Wang,Dexin Jin,Ye Yuan,Ximing Huang,Zijian Wu,Wenxin Li*

Main category: cs.AI

TL;DR: HLSMAC是一个基于星际争霸II的合作多智能体强化学习基准，包含12个基于中国古代兵法的策略场景，旨在评估和提升智能体的高层策略决策能力，并引入了超越传统胜率的新评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准（如SMAC）主要侧重于微操，未能全面评估智能体的高层战略智能。需要一个新的基准来解决这个问题。

Method: 提出了HLSMAC基准，包含12个基于《三十六计》的星际争霸II策略场景，设计了新的多维度评估指标（如能力利用率、推进效率），并集成了先进的MARL算法和基于LLM的智能体进行实验。

Result: 实验结果表明，HLSMAC是一个强大的测试平台，能够促进多智能体策略决策能力的提升。

Conclusion: HLSMAC通过提供多样化的策略场景和创新的评估指标，为评估和发展多智能体的高层战略决策能力提供了一个有效的平台。

Abstract: Benchmarks are crucial for assessing multi-agent reinforcement learning
(MARL) algorithms. While StarCraft II-related environments have driven
significant advances in MARL, existing benchmarks like SMAC focus primarily on
micromanagement, limiting comprehensive evaluation of high-level strategic
intelligence. To address this, we introduce HLSMAC, a new cooperative MARL
benchmark with 12 carefully designed StarCraft II scenarios based on classical
stratagems from the Thirty-Six Stratagems. Each scenario corresponds to a
specific stratagem and is designed to challenge agents with diverse strategic
elements, including tactical maneuvering, timing coordination, and deception,
thereby opening up avenues for evaluating high-level strategic decision-making
capabilities. We also propose novel metrics across multiple dimensions beyond
conventional win rate, such as ability utilization and advancement efficiency,
to assess agents' overall performance within the HLSMAC environment. We
integrate state-of-the-art MARL algorithms and LLM-based agents with our
benchmark and conduct comprehensive experiments. The results demonstrate that
HLSMAC serves as a robust testbed for advancing multi-agent strategic
decision-making.

</details>


### [153] [Agentic AI for Financial Crime Compliance](https://arxiv.org/abs/2509.13137)
*Henrik Axelsen,Valdemar Licht,Jan Damsgaard*

Main category: cs.AI

TL;DR: 本篇论文介绍了一个为金融犯罪合规（FCC）设计的、基于智能体的人工智能系统，该系统应用于数字原生金融平台，并通过行动设计研究（ADR）与金融科技公司和监管机构合作开发。系统通过自动化入职、监控、调查和报告等流程，并强调可解释性、可追溯性和合规性设计，以应对日益增长的合规成本和复杂性。


<details>
  <summary>Details</summary>
Motivation: 金融犯罪合规（FCC）的成本和复杂性持续上升，但效果的提升却难以衡量。现有的大多数人工智能解决方案不够透明，且与监管机构的期望不符。

Method: 本研究采用行动设计研究（ADR）方法，与金融科技公司和监管机构合作，设计并部署了一个基于智能体的AI系统。该系统利用以工件为中心的建模，为自主智能体分配明确的角色，并实现特定任务的模型路由和审计日志记录。

Result: 该系统能够自动化入职、监控、调查和报告等FCC流程，同时保证了可解释性、可追溯性和合规性设计。研究成果包括一个参考架构、一个真实世界的原型，以及关于智能体AI如何在监管限制下重构FCC工作流程的见解。

Conclusion: 本研究扩展了关于AI赋能合规的（IS）文献，展示了在负责任的治理结构中嵌入自动化，如何在高风险、受监管的环境中支持透明度和机构信任。

Abstract: The cost and complexity of financial crime compliance (FCC) continue to rise,
often without measurable improvements in effectiveness. While AI offers
potential, most solutions remain opaque and poorly aligned with regulatory
expectations. This paper presents the design and deployment of an agentic AI
system for FCC in digitally native financial platforms. Developed through an
Action Design Research (ADR) process with a fintech firm and regulatory
stakeholders, the system automates onboarding, monitoring, investigation, and
reporting, emphasizing explainability, traceability, and compliance-by-design.
Using artifact-centric modeling, it assigns clearly bounded roles to autonomous
agents and enables task-specific model routing and audit logging. The
contribution includes a reference architecture, a real-world prototype, and
insights into how Agentic AI can reconfigure FCC workflows under regulatory
constraints. Our findings extend IS literature on AI-enabled compliance by
demonstrating how automation, when embedded within accountable governance
structures, can support transparency and institutional trust in high-stakes,
regulated environments.

</details>


### [154] [V-Math: An Agentic Approach to the Vietnamese National High School Graduation Mathematics Exams](https://arxiv.org/abs/2509.12251)
*Duong Q. Nguyen,Quy P. Nguyen,Nguyen Van Nhon,Quang-Thinh Bui,H. Nguyen-Xuan*

Main category: cs.AI

TL;DR: V-Math 是一个为越南高中生准备高考数学考试的自主智能体框架。


<details>
  <summary>Details</summary>
Motivation: 开发 V-Math 旨在帮助越南高中生准备高考数学考试，并为教师提供 AI 辅助的考试创建工具。

Method: V-Math 集成了三个 AI 智能体：题库生成器、解题/解释器和个性化辅导。系统支持学生自学练习和教师生成符合标准的考题。

Result: V-Math 能够生成符合考纲的试卷，解题准确率高，解释清晰，并增加了练习材料的多样性。

Conclusion: V-Math 有潜力支持符合国家标准的、可扩展的、公平的数学备考，并通过 AI 辅助考试创作赋能教师。

Abstract: This paper develops an autonomous agentic framework called V-Math that aims
to assist Vietnamese high school students in preparing for the National High
School Graduation Mathematics Exams (NHSGMEs). The salient framework integrates
three specialized AI agents: a specification-matrix-conditioned question
generator, a solver/explainer for detailed step-by-step reasoning, and a
personalized tutor that adapts to student performance. Beyond enabling
self-paced student practice, V-Math supports teachers by generating innovative,
compliant exam questions and building diverse, high-quality question banks.
This reduces manual workload and enriches instructional resources. We describe
the system architecture, focusing on practice modes for learners and
teacher-oriented features for question generation. Preliminary evaluations
demonstrate that V-Math produces matrix-aligned exams with high solution
accuracy, delivers coherent explanations, and enhances the variety of practice
materials. These results highlight its potential to support scalable, equitable
mathematics preparation aligned with national standards while also empowering
teachers through AI-assisted exam creation.

</details>


### [155] [DISPLIB: a library of train dispatching problems](https://arxiv.org/abs/2509.12254)
*Oddvar Kloster,Bjørnar Luteberget,Carlo Mannino,Giorgio Sartor*

Main category: cs.AI

TL;DR: 一个包含火车重路由和重新调度问题的通用问题定义和文件格式DISPLIB，旨在促进可重复性和性能比较。


<details>
  <summary>Details</summary>
Motivation: 现有的优化算法研究与特定工业案例绑定过深，缺乏代码和数据共享，阻碍了可重复性和算法间的性能比较。

Method: 提出一个通用的问题定义和文件格式DISPLIB，并收集了来自多个真实世界案例的工业实例，提供了一个参考求解器实现。

Result: DISPLIB促进了研究人员和开发人员在没有工业联系的情况下处理火车调度问题，并使研究社区能够对求解器进行经验比较。

Conclusion: DISPLIB提供了一个标准化的框架，用于火车重路由和重新调度问题的研究，促进了该领域的进步和合作。

Abstract: Optimization-based decision support systems have a significant potential to
reduce delays, and thus improve efficiency on the railways, by automatically
re-routing and re-scheduling trains after delays have occurred. The operations
research community has dedicated a lot of effort to developing optimization
algorithms for this problem, but each study is typically tightly connected with
a specific industrial use case. Code and data are seldom shared publicly. This
fact hinders reproducibility, and has led to a proliferation of papers
describing algorithms for more or less compatible problem definitions, without
any real opportunity for readers to assess their relative performance. Inspired
by the successful communities around MILP, SAT, TSP, VRP, etc., we introduce a
common problem definition and file format, DISPLIB, which captures all the main
features of train re-routing and re-scheduling. We have gathered problem
instances from multiple real-world use cases and made them openly available. In
this paper, we describe the problem definition, the industrial instances, and a
reference solver implementation. This allows any researcher or developer to
work on the train dispatching problem without an industrial connection, and
enables the research community to perform empirical comparisons between
solvers. All materials are available online at https://displib.github.io.

</details>


### [156] [Large Language Models Imitate Logical Reasoning, but at what Cost?](https://arxiv.org/abs/2509.12645)
*Lachlan McGinness,Peter Baumgartner*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型在推理能力方面随时间的变化，并提出了一种结合大型语言模型和SMT求解器的神经符号方法，以在降低计算成本的同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在十八个月期间的推理能力，并探索一种能够降低计算成本并保持高性能的新型方法。

Method: 在2023年12月、2024年9月和2025年6月，在PrOntoQA数据集上评估了三个领先的LLM在判断题上的准确性，以及它们对通过上下文学习提供的推理策略的忠实度。然后，提出了一种神经符号架构，使用参数量少于150亿的模型将问题转换为标准化形式，然后由Z3求解器解决，并报告了提示和完成的标记数量以及计算成本。

Result: LLM的性能在2023年至2024年有所提高，这归因于隐藏的思维链提示。2024年至2025年间，引入了思维模型，显著提高了模型性能。神经符号方法显著降低了计算成本，同时保持了接近完美性能。

Conclusion: 神经符号方法在降低计算成本方面表现出色，同时保持了接近完美的性能。LLM的推理能力在评估期间有所提高，特别是在引入思维模型后。

Abstract: We present a longitudinal study which evaluates the reasoning capability of
frontier Large Language Models over an eighteen month period. We measured the
accuracy of three leading models from December 2023, September 2024 and June
2025 on true or false questions from the PrOntoQA dataset and their
faithfulness to reasoning strategies provided through in-context learning. The
improvement in performance from 2023 to 2024 can be attributed to hidden Chain
of Thought prompting. The introduction of thinking models allowed for
significant improvement in model performance between 2024 and 2025.
  We then present a neuro-symbolic architecture which uses LLMs of less than 15
billion parameters to translate the problems into a standardised form. We then
parse the standardised forms of the problems into a program to be solved by Z3,
an SMT solver, to determine the satisfiability of the query. We report the
number of prompt and completion tokens as well as the computational cost in
FLOPs for open source models. The neuro-symbolic approach significantly reduces
the computational cost while maintaining near perfect performance. The common
approximation that the number of inference FLOPs is double the product of the
active parameters and total tokens was accurate within 10\% for all
experiments.

</details>


### [157] [InPhyRe Discovers: Large Multimodal Models Struggle in Inductive Physical Reasoning](https://arxiv.org/abs/2509.12263)
*Gautam Sreekumar,Vishnu Naresh Boddeti*

Main category: cs.AI

TL;DR: 人类拥有在新的物理环境中进行归纳推理的能力，而大型多模态模型（LMM）在这方面表现不佳。现有的基准测试未能充分评估 LMM 的归纳物理推理能力。本研究提出了 InPhyRe，一个用于评估 LMM 归纳物理推理的新基准，并通过实验揭示了 LMM 在处理违反物理定律的情况时存在局限性，并且语言偏见会影响其推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的 LMM 只能在其训练期间看到的物理定律（例如动量守恒）方面进行推理，这在推理场景违反这些物理定律时是不够的。然而，人类可以根据少量视觉示例适应新的物理环境，这种归纳物理推理能力对于 LMM 在安全关键应用中取代人类至关重要。然而，当前的视觉基准测试并未评估 LMM 的归纳物理推理能力。

Method: 提出了 InPhyRe，这是第一个用于评估 LMM 归纳物理推理能力的视觉问答基准。该基准通过检查算法生成的合成碰撞视频中的碰撞事件结果来评估 LMM。

Result: 通过检查 13 个 LMM，研究发现 LMM 在应用其有限的参数化物理定律知识进行推理时存在困难。当演示样本违反通用物理定律时，LMM 的归纳物理推理能力较弱。此外，LMM 的归纳物理推理受到语言偏见的影响，并且在很大程度上忽略了视觉输入，这使得 LMM 在处理视觉输入时的可信度受到质疑。

Conclusion: LMM 在归纳物理推理方面存在显著不足，尤其是在处理违反已知物理定律或存在语言偏见的情况下。现有的基准测试未能充分捕捉这些局限性。因此，需要进一步的研究来提高 LMM 的归纳物理推理能力和对视觉输入的可靠性。

Abstract: Large multimodal models (LMMs) encode universal physical laws observed during
training, such as momentum conservation, as parametric knowledge. It allows
LMMs to answer physical reasoning queries, such as the outcome of a potential
collision event from visual input. However, since parametric knowledge includes
only the physical laws seen during training, it is insufficient for reasoning
when the inference scenario violates these physical laws. In contrast, humans
possess the skill to adapt their physical reasoning to unseen physical
environments from a few visual examples. This ability, which we refer to as
inductive physical reasoning, is indispensable for LMMs if they are to replace
human agents in safety-critical applications. Despite its importance, existing
visual benchmarks evaluate only the parametric knowledge in LMMs, and not
inductive physical reasoning. To this end, we propose InPhyRe, the first visual
question answering benchmark to measure inductive physical reasoning in LMMs.
InPhyRe evaluates LMMs on their ability to predict the outcome of collision
events in algorithmically generated synthetic collision videos. By inspecting
13 LMMs, InPhyRe informs us that (1) LMMs struggle to apply their limited
parametric knowledge about universal physical laws to reasoning, (2) inductive
physical reasoning in LMMs is weak when demonstration samples violate universal
physical laws, and (3) inductive physical reasoning in LMMs suffers from
language bias and largely ignores the visual inputs, questioning the
trustworthiness of LMMs regarding visual inputs.

</details>


### [158] [LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences](https://arxiv.org/abs/2509.12273)
*Liangqi Yuan,Dong-Jun Han,Christopher G. Brinton,Sabine Brunswicker*

Main category: cs.AI

TL;DR: LLMAP系统结合LLM作为解析器和多步图搜索算法，能理解自然语言、处理复杂的路线规划问题，并优化POI质量、任务完成率和路线距离，同时满足时间、POI开放时间和任务依赖性约束。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理大规模地图数据和理解用户偏好方面存在局限，且全球用户时空分布异构且不可预测，因此需要新的路线规划方法。

Method: 提出LLMAP系统，使用LLM作为解析器来理解自然语言输入、识别任务、提取用户偏好和依赖关系；结合多步图构建与迭代搜索（MSGS）算法来寻找最优路线；采用多目标优化方法，自适应调整权重以最大化POI质量和任务完成率，同时最小化路线距离，并考虑用户时间限制、POI开放时间和任务依赖性约束。

Result: 在包含14个国家和27个城市的1000个不同复杂度路线提示的实验中，LLMAP系统在多约束条件下表现出优越性能。

Conclusion: LLMAP系统能有效解决自然语言驱动的路线规划问题，并在多目标和多约束条件下实现最优路线规划。

Abstract: The rise of large language models (LLMs) has made natural language-driven
route planning an emerging research area that encompasses rich user objectives.
Current research exhibits two distinct approaches: direct route planning using
LLM-as-Agent and graph-based searching strategies. However, LLMs in the former
approach struggle to handle extensive map data, while the latter shows limited
capability in understanding natural language preferences. Additionally, a more
critical challenge arises from the highly heterogeneous and unpredictable
spatio-temporal distribution of users across the globe. In this paper, we
introduce a novel LLM-Assisted route Planning (LLMAP) system that employs an
LLM-as-Parser to comprehend natural language, identify tasks, and extract user
preferences and recognize task dependencies, coupled with a Multi-Step Graph
construction with iterative Search (MSGS) algorithm as the underlying solver
for optimal route finding. Our multi-objective optimization approach adaptively
tunes objective weights to maximize points of interest (POI) quality and task
completion rate while minimizing route distance, subject to three key
constraints: user time limits, POI opening hours, and task dependencies. We
conduct extensive experiments using 1,000 routing prompts sampled with varying
complexity across 14 countries and 27 cities worldwide. The results demonstrate
that our approach achieves superior performance with guarantees across multiple
constraints.

</details>


### [159] [Developing an aeroponic smart experimental greenhouse for controlling irrigation and plant disease detection using deep learning and IoT](https://arxiv.org/abs/2509.12274)
*Mohammadreza Narimani,Ali Hajiahmad,Ali Moghimi,Reza Alimardani,Shahin Rafiee,Amir Hossein Mirzabe*

Main category: cs.AI

TL;DR: 开发了一个智能气雾栽培温室，通过物联网和人工智能监测植物健康和环境条件，并能检测病害。


<details>
  <summary>Details</summary>
Motivation: 为了在温室中通过控制环境条件和监测植物状态来及时做出管理决策，促进作物生产。

Method: 开发了一个基于物联网的平台来控制环境条件，并利用VGG-19、InceptionResNetV2和InceptionV3算法开发了一个基于人工智能的病害检测框架，分析了植物图像。

Result: 物联网系统能够持续在线发布温湿度、水流、储水罐容量等数据，并调整控制参数以提供最佳生长环境。VGG-19算法在识别干旱胁迫和锈病叶片方面准确率最高，达到92%。

Conclusion: 该研究成功开发了一个集成了物联网和人工智能的智能气雾栽培温室，能够有效监测和控制环境，并通过人工智能算法准确检测植物病害。

Abstract: Controlling environmental conditions and monitoring plant status in
greenhouses is critical to promptly making appropriate management decisions
aimed at promoting crop production. The primary objective of this research
study was to develop and test a smart aeroponic greenhouse on an experimental
scale where the status of Geranium plant and environmental conditions are
continuously monitored through the integration of the internet of things (IoT)
and artificial intelligence (AI). An IoT-based platform was developed to
control the environmental conditions of plants more efficiently and provide
insights to users to make informed management decisions. In addition, we
developed an AI-based disease detection framework using VGG-19,
InceptionResNetV2, and InceptionV3 algorithms to analyze the images captured
periodically after an intentional inoculation. The performance of the AI
framework was compared with an expert's evaluation of disease status.
Preliminary results showed that the IoT system implemented in the greenhouse
environment is able to publish data such as temperature, humidity, water flow,
and volume of charge tanks online continuously to users and adjust the
controlled parameters to provide an optimal growth environment for the plants.
Furthermore, the results of the AI framework demonstrate that the VGG-19
algorithm was able to identify drought stress and rust leaves from healthy
leaves with the highest accuracy, 92% among the other algorithms.

</details>


### [160] [AIssistant: An Agentic Approach for Human--AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning](https://arxiv.org/abs/2509.12282)
*Sasi Kiran Gaddipati,Farhana Keya,Gollam Rabby,Sören Auer*

Main category: cs.AI

TL;DR: AIssistant是一个开源的、以人为中心的人机协作框架，用于简化端到端的科学工作流创建，并在机器学习领域的观点和综述研究论文的初步实验中，展示了提高起草效率和主题一致性的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的AI辅助研究工具虽然强大，但系统碎片化且缺乏以人为中心的工作流程，这阻碍了端到端的科学工作流的创建。AIssistant旨在解决这些差距，简化科学研究的整个过程。

Method: AIssistant是一个代理的、开源的人机协作框架。它整合了用于文献综合、分段实验、引文管理和自动LaTeX论文文本生成的模块化工具和代理，并在每个阶段都保持人工监督，以确保准确性、连贯性和学术严谨性。该系统在三个层面进行了全面评估：独立人工评审、自动LLM评审（使用GPT-5作为代理）和程序主席监督。

Result: 实验表明，AIssistant能够提高论文起草效率和主题一致性。然而，事实正确性、方法健全性和道德合规性仍然需要人机协作来确保。该系统在处理虚假引文、适应动态论文结构以及整合多模态内容方面存在局限性。

Conclusion: AIssistant在提高科学工作流的创建效率和一致性方面显示出潜力，但人机协作对于确保准确性、健全性和合规性仍然至关重要。未来的工作需要解决其局限性，例如虚假引文和对动态结构的适应性。

Abstract: Advances in AI-assisted research have introduced powerful tools for
literature retrieval, hypothesis generation, experimentation, and manuscript
preparation. However, systems remain fragmented and lack human-centred
workflows. To address these gaps, we introduce AIssistant, an agentic,
open-source Human-AI collaborative framework designed to simplify the
end-to-end creation of scientific workflows. Since our development is still in
an early stage, we present here the first experiments with AIssistant for
perspective and review research papers in machine learning. Our system
integrates modular tools and agents for literature synthesis, section-wise
experimentation, citation management, and automatic LaTeX paper text
generation, while maintaining human oversight at every stage to ensure
accuracy, coherence, and scholarly rigour. We conducted a comprehensive
evaluation across three layers: (1) Independent Human Review, following NeurIPS
double-blind standards; (2) Automated LLM Review, using GPT-5 as a scalable
human review proxy; and (3) Program Chair Oversight, where the chair monitors
the entire review process and makes final validation and acceptance decisions.
The results demonstrate that AIssistant improves drafting efficiency and
thematic consistency. Nonetheless, Human-AI collaboration remains essential for
maintaining factual correctness, methodological soundness, and ethical
compliance. Despite its effectiveness, we identify key limitations, including
hallucinated citations, difficulty adapting to dynamic paper structures, and
incomplete integration of multimodal content.

</details>


### [161] [Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition](https://arxiv.org/abs/2509.12423)
*Danielle Cohen,Yoni Halpern,Noam Kahlon,Joel Oren,Omri Berkovitch,Sapir Caduri,Ido Dagan,Anatoly Efros*

Main category: cs.AI

TL;DR: 资源受限模型可通过交互摘要和意图提取来提高意图理解能力，甚至超越大型多模态语言模型。


<details>
  <summary>Details</summary>
Motivation: 理解用户意图是智能代理开发中的关键挑战。目前，小型模型在准确推理用户意图方面存在困难，而大型模型则面临成本和延迟问题。

Method: 提出了一种新颖的分解方法：首先，对用户交互进行结构化摘要，提取关键信息；然后，使用在聚合摘要上进行微调的模型进行意图提取。

Result: 该方法提高了资源受限模型在用户意图理解方面的能力，并且其性能甚至超过了大型多模态语言模型的基线性能。

Conclusion: 所提出的分解方法能够有效提升资源受限模型在用户意图理解方面的表现。

Abstract: Understanding user intents from UI interaction trajectories remains a
challenging, yet crucial, frontier in intelligent agent development. While
massive, datacenter-based, multi-modal large language models (MLLMs) possess
greater capacity to handle the complexities of such sequences, smaller models
which can run on-device to provide a privacy-preserving, low-cost, and
low-latency user experience, struggle with accurate intent inference. We
address these limitations by introducing a novel decomposed approach: first, we
perform structured interaction summarization, capturing key information from
each user action. Second, we perform intent extraction using a fine-tuned model
operating on the aggregated summaries. This method improves intent
understanding in resource-constrained models, even surpassing the base
performance of large MLLMs.

</details>


### [162] [Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization](https://arxiv.org/abs/2509.12434)
*Jiahao Yu,Zelei Cheng,Xian Wu,Xinyu Xing*

Main category: cs.AI

TL;DR: 现有的LLM在软件工程任务中表现不佳，尤其是在处理需要推理和工具使用等多步操作的挑战时。测试时扩展（TTS）被认为是提高LLM性能的有前景的方法，但其效果依赖于模型输出的多样性。标准的对齐方法（如DPO和KTO）虽然能使模型输出符合人类偏好，但可能降低输出多样性，从而限制TTS的有效性。此外，现有的偏好优化算法通常是为单轮任务设计的，未能充分解决交互式编码代理所需的多轮推理和工具集成。为解决这些问题，我们提出了\sys框架，它是一种增强熵的方法，将现有的偏好优化算法适配到多轮、辅助工具的环境中。\sys通过明确保留策略熵来增强偏好目标，并将学习推广到优化多轮交互而非单轮响应。为了最大化TTS的性能提升，我们还提出了一种结合学习到的验证模型和无模型方法（model-free approaches）的混合最佳轨迹选择方案。


<details>
  <summary>Details</summary>
Motivation: 软件工程任务对大型语言模型（LLM）提出了复杂的多步挑战，需要对大型代码库进行推理和协调工具的使用。SWE-bench等基准测试证明了这些任务的难度，目前的LLM在解决实际问题方面仍面临困难。一种提高性能的有前景的方法是测试时扩展（TTS），但其收益在很大程度上取决于模型输出的多样性。然而，像DPO和KTO这样的标准对齐方法虽然能有效对齐模型输出和人类偏好，但可能会降低多样性，限制TTS的有效性。此外，现有的偏好优化算法通常是为单轮任务设计的，未能充分解决交互式编码代理所需的多轮推理和工具集成。

Method: \sys框架通过增强熵来适应现有的偏好优化算法，以适应多轮、工具辅助的设置。\sys增强了偏好目标，明确地保留了策略熵，并将学习从优化单轮响应推广到优化多轮交互。为了最大化TTS的性能提升，我们还提出了一种混合最佳轨迹选择方案，结合了学习到的验证模型和无模型方法。

Result: 在SWE-bench排行榜上，我们的方法为开源模型树立了新的最先进水平。一个使用\sys训练的30B参数模型在\lite排行榜上排名第一，在\verified排行榜上排名第四，仅次于参数量多于10倍（>350B）的模型。

Conclusion: \sys框架通过在多轮、工具辅助的环境中优化偏好，并结合混合最佳轨迹选择方案，有效提高了LLM在软件工程任务中的性能，并在SWE-bench排行榜上取得了优异的成果。

Abstract: Software engineering presents complex, multi-step challenges for Large
Language Models (LLMs), requiring reasoning over large codebases and
coordinated tool use. The difficulty of these tasks is exemplified by
benchmarks like SWE-bench, where current LLMs still struggle to resolve
real-world issues.
  A promising approach to enhance performance is test-time scaling (TTS), but
its gains are heavily dependent on the diversity of model outputs.
  While standard alignment methods such as Direct Preference Optimization (DPO)
and Kahneman-Tversky Optimization (KTO) are effective at aligning model outputs
with human preferences, this process can come at the cost of reduced diversity,
limiting the effectiveness of TTS.
  Additionally, existing preference optimization algorithms are typically
designed for single-turn tasks and do not fully address the complexities of
multi-turn reasoning and tool integration required for interactive coding
agents.
  To bridge this gap, we introduce \sys, an entropy-enhanced framework that
adapts existing preference optimization algorithms to the multi-turn,
tool-assisted setting.
  \sys augments the preference objective to explicitly preserve policy entropy
and generalizes learning to optimize over multi-turn interactions rather than
single-turn responses.
  We validate \sys by fine-tuning a diverse suite of models from different
families and sizes (up to 106B parameters).
  To maximize performance gains from TTS, we further propose a hybrid
best-trajectory selection scheme combining a learned verifier model with model
free approaches.
  On the \swebench leaderboard, our approach establishes new state-of-the-art
results among open-weight models. A 30B parameter model trained with \sys ranks
1st on \lite and 4th on \verified on the open-weight leaderboard, surpassed
only by models with over 10x more parameters(\eg$>$350B).

</details>


### [163] [Enhancing Physical Consistency in Lightweight World Models](https://arxiv.org/abs/2509.12437)
*Dingrui Wang,Zhexiao Sun,Zhouheng Li,Cheng Wang,Youlun Peng,Hongyuan Ye,Baha Zarrouki,Wei Li,Mattia Piccinini,Lei Xie,Johannes Betz*

Main category: cs.AI

TL;DR: PIWM是一个紧凑型世界模型，可以在BEV表示中有效捕捉物理交互，通过软掩码和暖启动提高了动态对象建模和未来预测的性能，并在参数量相当的情况下超越了基线模型。


<details>
  <summary>Details</summary>
Motivation: 在部署世界模型时，模型大小和性能之间的权衡是一个主要挑战。大型模型虽然能捕捉丰富的物理动态，但需要大量的计算资源，不适用于边缘设备；小型模型易于部署，但往往难以学习精确的物理知识，导致预测效果不佳。

Method: PIWM模型在训练过程中使用软掩码来改进动态对象建模和未来预测。在推理过程中，引入了一种简单的暖启动技术来提高零样本模型的预测质量。

Result: 在参数量相同（400M）的情况下，PIWM的综合得分比基线模型高出60.6%。即使与最大的基线模型（400M）相比，最小的PIWM（130M软掩码）也能获得高出7.4%的综合得分，并且推理速度快28%。

Conclusion: PIWM通过结合软掩码和暖启动技术，在保持模型紧凑的同时，显著提高了世界模型在捕捉物理交互和未来预测方面的性能，解决了大型模型部署困难和小型模型精度不足的问题。

Abstract: A major challenge in deploying world models is the trade-off between size and
performance. Large world models can capture rich physical dynamics but require
massive computing resources, making them impractical for edge devices. Small
world models are easier to deploy but often struggle to learn accurate physics,
leading to poor predictions. We propose the Physics-Informed BEV World Model
(PIWM), a compact model designed to efficiently capture physical interactions
in bird's-eye-view (BEV) representations. PIWM uses Soft Mask during training
to improve dynamic object modeling and future prediction. We also introduce a
simple yet effective technique, Warm Start, for inference to enhance prediction
quality with a zero-shot model. Experiments show that at the same parameter
scale (400M), PIWM surpasses the baseline by 60.6% in weighted overall score.
Moreover, even when compared with the largest baseline model (400M), the
smallest PIWM (130M Soft Mask) achieves a 7.4% higher weighted overall score
with a 28% faster inference speed.

</details>


### [164] [Reasoning Models Can be Accurately Pruned Via Chain-of-Thought Reconstruction](https://arxiv.org/abs/2509.12464)
*Ryan Lucas,Kayhan Behdin,Zhipeng Wang,Qingquan Song,Shao Tang,Rahul Mazumder*

Main category: cs.AI

TL;DR: 模型压缩技术（如神经网络剪枝）在推理时会导致性能下降，并且可能使模型运行得更慢。提出了一种名为“面向推理的压缩”（RAC）的新方法，通过联合重建输入和模型 on-policy 的思维链轨迹来解决这个问题，从而在不牺牲性能的情况下提高压缩效率。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型（如 DeepSeek-R1）在推理时会产生长串的思维链，导致部署成本高昂。标准的模型压缩技术（如神经网络剪枝）在这些模型上表现不佳，甚至可能导致性能下降和速度变慢。

Method: 提出了一种名为“面向推理的压缩”（RAC）的简单、即插即用的解决方案。该方法在剪枝过程中，联合重建来自输入的激活和模型 on-policy 的思维链轨迹。RAC 无缝集成到现有的剪枝工作流程（如 SparseGPT）中。

Result: 与标准剪枝方法相比，RAC 显著提高了性能，解决了推理任务中常见的性能下降问题。具体来说，它避免了由于模型产生更多的思考 token 但性能更差的情况。

Conclusion: RAC 是一种有效的模型压缩技术，特别适用于推理语言模型。通过将输入重建和思维链轨迹重建结合起来，RAC 能够实现更高的压缩效率，同时保持甚至提高模型的性能。

Abstract: Reasoning language models such as DeepSeek-R1 produce long chain-of-thought
traces during inference time which make them costly to deploy at scale. We show
that using compression techniques such as neural network pruning produces
greater performance loss than in typical language modeling tasks, and in some
cases can make the model slower since they cause the model to produce more
thinking tokens but with worse performance. We show that this is partly due to
the fact that standard LLM pruning methods often focus on input reconstruction,
whereas reasoning is a decode-dominated task. We introduce a simple, drop-in
fix: during pruning we jointly reconstruct activations from the input and the
model's on-policy chain-of-thought traces. This "Reasoning-Aware Compression"
(RAC) integrates seamlessly into existing pruning workflows such as SparseGPT,
and boosts their performance significantly. Code reproducing the results in the
paper can be found at: https://github.com/RyanLucas3/RAC

</details>


### [165] [Empowering Clinical Trial Design through AI: A Randomized Evaluation of PowerGPT](https://arxiv.org/abs/2509.12471)
*Yiwen Lu,Lu Li,Dazheng Zhang,Xinyao Jian,Tingyin Wang,Siqi Chen,Yuqing Lei,Jiayi Tong,Zhaohan Xi,Haitao Chu,Chongliang Luo,Alexis Ogdie,Brian Athey,Alparslan Turan,Michael Abramoff,Joseph C Cappelleri,Hua Xu,Yun Lu,Jesse Berlin,Daniel I. Sessler,David A. Asch,Xiaoqian Jiang,Yong Chen*

Main category: cs.AI

TL;DR: PowerGPT是一个AI驱动的系统，利用LLM和统计引擎来自动化临床试验设计中的假设检验选择和样本量估算，显著提高了效率、准确性和完成率，同时减少了完成时间。


<details>
  <summary>Details</summary>
Motivation: 临床研究和试验设计中，样本量计算对于功效分析至关重要，但其复杂性和对统计专业知识的依赖给许多研究人员带来了障碍。

Method: 使用集成大型语言模型（LLM）和统计引擎的AI驱动系统（PowerGPT）来自动化试验设计中的检验选择和样本量估算。

Result: 与传统方法相比，PowerGPT在检验选择（99.3% vs 88.9%）和样本量计算（99.3% vs 77.8%）的任务完成率方面均有显著提高，在样本量估算准确性方面也表现更优（94.1% vs 55.4%，p < 0.001），同时平均完成时间从9.3分钟缩短至4.0分钟（p < 0.001）。

Conclusion: PowerGPT通过提高可及性、效率和准确性，为临床研究中的统计功效分析提供了一种可扩展的、由AI驱动的方法，并且已经在多所机构得到部署。

Abstract: Sample size calculations for power analysis are critical for clinical
research and trial design, yet their complexity and reliance on statistical
expertise create barriers for many researchers. We introduce PowerGPT, an
AI-powered system integrating large language models (LLMs) with statistical
engines to automate test selection and sample size estimation in trial design.
In a randomized trial to evaluate its effectiveness, PowerGPT significantly
improved task completion rates (99.3% vs. 88.9% for test selection, 99.3% vs.
77.8% for sample size calculation) and accuracy (94.1% vs. 55.4% in sample size
estimation, p < 0.001), while reducing average completion time (4.0 vs. 9.3
minutes, p < 0.001). These gains were consistent across various statistical
tests and benefited both statisticians and non-statisticians as well as
bridging expertise gaps. Already under deployment across multiple institutions,
PowerGPT represents a scalable AI-driven approach that enhances accessibility,
efficiency, and accuracy in statistical power analysis for clinical research.

</details>


### [166] [Physical Complexity of a Cognitive Artifact](https://arxiv.org/abs/2509.12495)
*Gülce Kardeş,David Krakauer,Joshua Grochow*

Main category: cs.AI

TL;DR: 本文将计算复杂性理论中的概念应用于解决 Soma Cube 谜题的认知策略，通过“物质性原则”量化评估任务难度，并检查不同策略如何改变复杂性。


<details>
  <summary>Details</summary>
Motivation: 认知科学和理论计算机科学都试图对任务的难度进行分类和解释，而智能机制的作用在于降低任务难度。

Method: 通过分析 Soma Cube 谜题的搜索树出度来计算其分支因子，从而量化评估任务难度。研究人员系统地检查了不同的策略如何改变复杂性，通过逐步改进试错搜索，增加了预处理（认知分块）、值排序（认知自由排序）、变量排序（认知脚手架）和剪枝（认知推理）。

Result: 研究人员通过结合预处理、值排序、变量排序和剪枝等策略，逐步优化了试错搜索过程，从而有效降低了 Soma Cube 谜题的解决难度。

Conclusion: 该研究提出了一种将智能视为算法库的模式，该算法库能够利用心智和物质的能力，并讨论了利用物理约束通过人造制品来降低有效时间复杂度的方法。

Abstract: Cognitive science and theoretical computer science both seek to classify and
explain the difficulty of tasks. Mechanisms of intelligence are those that
reduce task difficulty. Here we map concepts from the computational complexity
of a physical puzzle, the Soma Cube, onto cognitive problem-solving strategies
through a ``Principle of Materiality''. By analyzing the puzzle's branching
factor, measured through search tree outdegree, we quantitatively assess task
difficulty and systematically examine how different strategies modify
complexity. We incrementally refine a trial-and-error search by layering
preprocessing (cognitive chunking), value ordering (cognitive free-sorting),
variable ordering (cognitive scaffolding), and pruning (cognitive inference).
We discuss how the competent use of artifacts reduces effective time complexity
by exploiting physical constraints and propose a model of intelligence as a
library of algorithms that recruit the capabilities of both mind and matter.

</details>


### [167] [A Dimensionality-Reduced XAI Framework for Roundabout Crash Severity Insights](https://arxiv.org/abs/2509.12524)
*Rohit Chakraborty,Subasish Das*

Main category: cs.AI

TL;DR: Roundabouts can decrease severe accidents, but the risks associated with them differ depending on the circumstances. This study examined Ohio roundabout accidents from 2017 to 2021, employing a two-step analytical method. Cluster Correspondence Analysis (CCA) was utilized to identify common factors and distinct crash patterns, resulting in four identified patterns. Subsequently, a tree-based model was used to analyze crash severity, with SHAP values employed to assess the impact of various factors on injuries within and across these patterns. The findings indicate that accidents are more severe when combined with factors such as darkness, wet road conditions, and higher speed limits, particularly in fixed-object or angle collisions. Conversely, accidents in clear weather and lower speeds tend to be less severe. The analysis also revealed pattern-specific causes, including failure to yield and improper gap acceptance at roundabout entries, incorrect maneuvering within multi-lane roundabouts, and rear-end collisions during deceleration. This comprehensive approach, linking pattern identification with detailed explanations, can aid in identifying high-risk locations, selecting appropriate safety measures, and generating transparent reports. The study's contribution to Information Systems lies in offering a practical framework for the effective use of Explainable AI (XAI) in public safety data analysis.


<details>
  <summary>Details</summary>
Motivation: This study aims to analyze the varying risk patterns in roundabout crashes under different conditions and to understand the factors contributing to crash severity. It seeks to provide a practical framework for using Explainable AI (XAI) in public safety analytics to support decision-making in areas such as site screening and countermeasure selection.

Method: The study uses a two-step analytical workflow. First, Cluster Correspondence Analysis (CCA) is applied to identify co-occurring factors and define distinct crash patterns. Second, a tree-based severity model is employed, and its results are interpreted using SHAP values to quantify the drivers of injury severity within and across the identified patterns.

Result: The analysis identified four distinct crash patterns. Higher crash severity is associated with the coincidence of darkness, wet surfaces, and higher posted speeds with fixed-object or angle collision types. Conversely, lower severity is observed in clear, low-speed conditions. Specific mechanisms contributing to severity were identified at roundabout entries (fail-to-yield, gap acceptance), within multi-lane circulation (improper maneuvers), and during slowdowns (rear-end collisions).

Conclusion: The study demonstrates that a combination of factors like environmental conditions (darkness, wet surfaces), speed, and collision type significantly influences crash severity at roundabouts. The developed workflow effectively links pattern discovery with case-level explanations, providing actionable insights for improving roundabout safety. The research contributes a usable XAI template for public safety analytics, supporting evidence-based decision-making and reporting.

Abstract: Roundabouts reduce severe crashes, yet risk patterns vary by conditions. This
study analyzes 2017-2021 Ohio roundabout crashes using a two-step, explainable
workflow. Cluster Correspondence Analysis (CCA) identifies co-occurring factors
and yields four crash patterns. A tree-based severity model is then interpreted
with SHAP to quantify drivers of injury within and across patterns. Results
show higher severity when darkness, wet surfaces, and higher posted speeds
coincide with fixed-object or angle events, and lower severity in clear,
low-speed settings. Pattern-specific explanations highlight mechanisms at
entries (fail-to-yield, gap acceptance), within multi-lane circulation
(improper maneuvers), and during slow-downs (rear-end). The workflow links
pattern discovery with case-level explanations, supporting site screening,
countermeasure selection, and audit-ready reporting. The contribution to
Information Systems is a practical template for usable XAI in public safety
analytics.

</details>


### [168] [zELO: ELO-inspired Training Method for Rerankers and Embedding Models](https://arxiv.org/abs/2509.12541)
*Nicholas Pipitone,Ghita Houir Alami,Advaith Avadhanam,Anton Kaminskyi,Ashley Khoo*

Main category: cs.AI

TL;DR: zELO是一种新的训练方法，通过将排序任务视为Thurstone模型来优化检索性能。基于zELO，训练出的zerank-1和zerank-1-small模型在金融、法律、代码和STEM等多个领域取得了最佳检索分数，优于闭源模型，并保持了出色的0-shot泛化能力。


<details>
  <summary>Details</summary>
Motivation: 将排序任务等同于Thurstone模型，以优化检索性能。

Method: 提出zELO训练方法，并使用该方法训练zerank-1和zerank-1-small模型。

Result: zerank-1和zerank-1-small模型在多个领域（金融、法律、代码、STEM）的检索任务中取得了最先进的性能，超越了闭源专有reranker模型，并在NDCG@10和Recall方面表现优异，同时保持了在领域外和私有客户数据集上的0-shot性能。

Conclusion: zELO方法能够有效地训练出高性能的reranker模型，这些模型具有广泛的适用性和优越的性能。

Abstract: We introduce a novel training methodology named zELO, which optimizes
retrieval performance via the analysis that ranking tasks are statically
equivalent to a Thurstone model. Based on the zELO method, we use unsupervised
data in order train a suite of state-of-the-art open-weight reranker models:
zerank-1 and zerank-1-small. These models achieve the highest retrieval scores
in multiple domains, including finance, legal, code, and STEM, outperforming
closed-source proprietary rerankers on both NDCG@10 and Recall. These models
also demonstrate great versatility, maintaining their 0-shot performance on
out-of-domain and private customer datasets. The training data included 112,000
queries and 100 documents per query, and was trained end-to-end from
unannotated queries and documents in less than 10,000 H100-hours.

</details>


### [169] [Human + AI for Accelerating Ad Localization Evaluation](https://arxiv.org/abs/2509.12543)
*Harshit Rajgarhia,Shivali Dalmia,Mengyang Zhao,Mukherji Abhishek,Kiran Ganesh*

Main category: cs.AI

TL;DR: 本研究提出了一种结合自动化组件和人工监督的广告本地化框架，以解决多语言广告制作中的视觉一致性、空间对齐和风格完整性问题。


<details>
  <summary>Details</summary>
Motivation: Adapting advertisements for multilingual audiences requires more than simple text translation; it demands preservation of visual consistency, spatial alignment, and stylistic integrity across diverse languages and formats.

Method: We introduce a structured framework that combines automated components with human oversight to address the complexities of advertisement localization. This work integrates scene text detection, inpainting, machine translation (MT), and text reimposition specifically for accelerating ad localization evaluation workflows.

Result: Qualitative results across six locales demonstrate that our approach produces semantically accurate and visually coherent localized advertisements, suitable for deployment in real-world workflows.

Conclusion: The proposed framework is the first to integrate scene text detection, inpainting, machine translation (MT), and text reimposition specifically for accelerating ad localization evaluation workflows, producing semantically accurate and visually coherent localized advertisements.

Abstract: Adapting advertisements for multilingual audiences requires more than simple
text translation; it demands preservation of visual consistency, spatial
alignment, and stylistic integrity across diverse languages and formats. We
introduce a structured framework that combines automated components with human
oversight to address the complexities of advertisement localization. To the
best of our knowledge, this is the first work to integrate scene text
detection, inpainting, machine translation (MT), and text reimposition
specifically for accelerating ad localization evaluation workflows. Qualitative
results across six locales demonstrate that our approach produces semantically
accurate and visually coherent localized advertisements, suitable for
deployment in real-world workflows.

</details>


### [170] [Redefining CX with Agentic AI: Minerva CQ Case Study](https://arxiv.org/abs/2509.12589)
*Garima Agrawal,Riccardo De Maria,Kiran Davuluri,Daniele Spera,Charlie Read,Cosimo Spera,Jack Garrett,Don Miller*

Main category: cs.AI

TL;DR: AI for contact centers still struggles with AHT, FCR, and CSAT due to agent cognitive load. Existing tools are reactive. We introduce Agentic AI, a proactive, goal-driven system that uses tools autonomously. Our case study, Minerva CQ, is a real-time Agent Assist product that integrates various AI capabilities to improve agent efficiency and customer experience.


<details>
  <summary>Details</summary>
Motivation: Customer experience (CX) in contact centers is hampered by high average handling time (AHT), low first-call resolution, and poor customer satisfaction (CSAT) due to the high cognitive load on agents. Existing AI tools are often reactive and lack deeper contextual reasoning.

Method: We introduce Agentic AI, which are goal-driven, autonomous, tool-using systems that proactively support agents in real time. Minerva CQ, a real-time Agent Assist product, integrates real-time transcription, intent and sentiment detection, entity recognition, contextual retrieval, dynamic customer profiling, and partial conversational summaries to enable proactive workflows and continuous context-building.

Result: Minerva CQ, deployed in live production, acts as an AI co-pilot, delivering measurable improvements in agent efficiency and customer experience across multiple deployments.

Conclusion: Agentic AI offers a proactive and adaptive approach to agent assistance, addressing the limitations of existing tools and leading to significant improvements in contact center performance.

Abstract: Despite advances in AI for contact centers, customer experience (CX)
continues to suffer from high average handling time (AHT), low first-call
resolution, and poor customer satisfaction (CSAT). A key driver is the
cognitive load on agents, who must navigate fragmented systems, troubleshoot
manually, and frequently place customers on hold. Existing AI-powered
agent-assist tools are often reactive driven by static rules, simple prompting,
or retrieval-augmented generation (RAG) without deeper contextual reasoning. We
introduce Agentic AI goal-driven, autonomous, tool-using systems that
proactively support agents in real time. Unlike conventional approaches,
Agentic AI identifies customer intent, triggers modular workflows, maintains
evolving context, and adapts dynamically to conversation state. This paper
presents a case study of Minerva CQ, a real-time Agent Assist product deployed
in voice-based customer support. Minerva CQ integrates real-time transcription,
intent and sentiment detection, entity recognition, contextual retrieval,
dynamic customer profiling, and partial conversational summaries enabling
proactive workflows and continuous context-building. Deployed in live
production, Minerva CQ acts as an AI co-pilot, delivering measurable
improvements in agent efficiency and customer experience across multiple
deployments.

</details>


### [171] [Match Chat: Real Time Generative AI and Generative Computing for Tennis](https://arxiv.org/abs/2509.12592)
*Aaron Baughman,Gozde Akay,Eduardo Morales,Rahul Agarwal,Preetika Srivastava*

Main category: cs.AI

TL;DR: Match Chat是一个利用生成式人工智能和计算技术，为网球比赛提供实时、准确信息的AI助手，在2025年温布尔登网球锦标赛和美国网球公开赛上成功部署，服务了近百万用户，准确率达92.83%，响应时间为6.25秒，并实现了100%的正常运行时间。


<details>
  <summary>Details</summary>
Motivation: 旨在通过提供实时、准确的比赛相关查询响应，增强网球迷的观赛体验。

Method: Match Chat系统采用面向代理的架构（AOA），结合了规则引擎、预测模型和代理，对用户查询进行预处理和优化，然后将其传递给生成式人工智能（GenAI）和生成式计算（GenComp）组件，以在现场网球单打比赛中合成关键见解。

Result: 在2025年温布尔登网球锦标赛和美国网球公开赛上，Match Chat为约100万用户提供了服务，答案准确率为92.83%，平均响应时间为6.25秒，最高可支持120 RPS的负载，96.08%的查询通过交互式提示得到引导，系统正常运行时间为100%。

Conclusion: 该工作提出了面向实时、面向消费者的AI系统的关键设计模式，强调速度、精度和可用性，为在动态环境中部署高性能的代理系统提供了实际途径。

Abstract: We present Match Chat, a real-time, agent-driven assistant designed to
enhance the tennis fan experience by delivering instant, accurate responses to
match-related queries. Match Chat integrates Generative Artificial Intelligence
(GenAI) with Generative Computing (GenComp) techniques to synthesize key
insights during live tennis singles matches. The system debuted at the 2025
Wimbledon Championships and the 2025 US Open, where it provided about 1 million
users with seamless access to streaming and static data through natural
language queries. The architecture is grounded in an Agent-Oriented
Architecture (AOA) combining rule engines, predictive models, and agents to
pre-process and optimize user queries before passing them to GenAI components.
The Match Chat system had an answer accuracy of 92.83% with an average response
time of 6.25 seconds under loads of up to 120 requests per second (RPS). Over
96.08% of all queries were guided using interactive prompt design, contributing
to a user experience that prioritized clarity, responsiveness, and minimal
effort. The system was designed to mask architectural complexity, offering a
frictionless and intuitive interface that required no onboarding or technical
familiarity. Across both Grand Slam deployments, Match Chat maintained 100%
uptime and supported nearly 1 million unique users, underscoring the
scalability and reliability of the platform. This work introduces key design
patterns for real-time, consumer-facing AI systems that emphasize speed,
precision, and usability that highlights a practical path for deploying
performant agentic systems in dynamic environments.

</details>


### [172] [DaSAThco: Data-Aware SAT Heuristics Combinations Optimization via Large Language Models](https://arxiv.org/abs/2509.12602)
*Minyu Chen,Guoqiang Li*

Main category: cs.AI

TL;DR: DaSAThco框架通过学习从实例特征到定制化启发式集合的通用映射，解决了SAT求解器配置的泛化性问题，实现了“一次训练，广泛适应”的模型。


<details>
  <summary>Details</summary>
Motivation: SAT问题的异质性使得单一、普遍最优的求解器配置无法实现，现有自动化方法缺乏泛化性且需要成本高昂的重新优化。

Method: 使用大型语言模型，以系统定义的“问题原型”为指导，生成多样化的专业启发式集合，并学习自适应选择机制形成最终映射。

Result: DaSAThco实现了优于现有方法的性能，并且在非自适应方法存在局限性的情况下，展现了鲁棒的跨领域泛化能力。

Conclusion: 该研究为复杂、可配置系统的自动化算法设计提供了一条更具可扩展性和实用性的途径。

Abstract: The performance of Conflict-Driven Clause Learning solvers hinges on internal
heuristics, yet the heterogeneity of SAT problems makes a single, universally
optimal configuration unattainable. While prior automated methods can find
specialized configurations for specific problem families, this dataset-specific
approach lacks generalizability and requires costly re-optimization for new
problem types. We introduce DaSAThco, a framework that addresses this challenge
by learning a generalizable mapping from instance features to tailored
heuristic ensembles, enabling a train-once, adapt-broadly model. Our framework
uses a Large Language Model, guided by systematically defined Problem
Archetypes, to generate a diverse portfolio of specialized heuristic ensembles
and subsequently learns an adaptive selection mechanism to form the final
mapping. Experiments show that DaSAThco achieves superior performance and, most
notably, demonstrates robust out-of-domain generalization where non-adaptive
methods show limitations. Our work establishes a more scalable and practical
path toward automated algorithm design for complex, configurable systems.

</details>


### [173] [Analogy-Driven Financial Chain-of-Thought (AD-FCoT): A Prompting Approach for Financial Sentiment Analysis](https://arxiv.org/abs/2509.12611)
*Anmol Singhal Navya Singhal*

Main category: cs.AI

TL;DR: 通过类比推理和链式思考（CoT）提示，提出AD-FCoT框架，无需额外训练即可提高金融新闻情感预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有金融新闻情感分析方法难以捕捉复杂的经济背景且缺乏透明度，影响可靠性。

Method: 提出AD-FCoT框架，结合类比推理和CoT提示，引导LLM将新事件与有已知结果的历史情景进行类比，并嵌入结构化的、逐步的推理链中。

Result: AD-FCoT在情感分类准确性上优于强基线方法，与市场回报的相关性显著更高，生成的解释与领域专业知识一致，提供可解释的见解。

Conclusion: AD-FCoT通过类比推理和CoT提示，在金融新闻情感预测方面取得了更好的准确性和可解释性，并且无需额外训练数据或微调。

Abstract: Financial news sentiment analysis is crucial for anticipating market
movements. With the rise of AI techniques such as Large Language Models (LLMs),
which demonstrate strong text understanding capabilities, there has been
renewed interest in enhancing these systems. Existing methods, however, often
struggle to capture the complex economic context of news and lack transparent
reasoning, which undermines their reliability. We propose Analogy-Driven
Financial Chain-of-Thought (AD-FCoT), a prompting framework that integrates
analogical reasoning with chain-of-thought (CoT) prompting for sentiment
prediction on historical financial news. AD-FCoT guides LLMs to draw parallels
between new events and relevant historical scenarios with known outcomes,
embedding these analogies into a structured, step-by-step reasoning chain. To
our knowledge, this is among the first approaches to explicitly combine
analogical examples with CoT reasoning in finance. Operating purely through
prompting, AD-FCoT requires no additional training data or fine-tuning and
leverages the model's internal financial knowledge to generate rationales that
mirror human analytical reasoning. Experiments on thousands of news articles
show that AD-FCoT outperforms strong baselines in sentiment classification
accuracy and achieves substantially higher correlation with market returns. Its
generated explanations also align with domain expertise, providing
interpretable insights suitable for real-world financial analysis.

</details>


### [174] [GBV-SQL: Guided Generation and SQL2Text Back-Translation Validation for Multi-Agent Text2SQL](https://arxiv.org/abs/2509.12612)
*Daojun Chen,Xi Wang,Shenyuan Ren,Qingzhi Ma,Pengpeng Zhao,An Liu*

Main category: cs.AI

TL;DR: GBV-SQL是一个新的多智能体框架，通过SQL到文本回译验证来解决Text2SQL的语义鸿沟，并指出当前基准测试中存在的“金标错误”问题。


<details>
  <summary>Details</summary>
Motivation: 现有的Text2SQL生成模型虽然在语法上有效，但常常无法准确理解用户意图，存在关键的语义鸿沟。

Method: 提出了一种名为GBV-SQL的新型多智能体框架，该框架利用一个专门的智能体将生成的SQL反向翻译成自然语言，以验证其与原始问题的逻辑一致性。此外，还提出了一种“金标错误”的正式分类法，用于识别和处理基准测试数据中的错误。

Result: 在BIRD基准测试中，GBV-SQL实现了63.23%的执行准确率，提高了5.8%。在去除错误示例后，GBV-SQL在Spider基准测试中的准确率分别达到96.5%（开发集）和97.6%（测试集）。

Conclusion: GBV-SQL提供了一个有效的语义验证框架，并揭示了基准测试完整性方面存在的问题，强调了更严格的数据集构建的必要性。

Abstract: While Large Language Models have significantly advanced Text2SQL generation,
a critical semantic gap persists where syntactically valid queries often
misinterpret user intent. To mitigate this challenge, we propose GBV-SQL, a
novel multi-agent framework that introduces Guided Generation with SQL2Text
Back-translation Validation. This mechanism uses a specialized agent to
translate the generated SQL back into natural language, which verifies its
logical alignment with the original question. Critically, our investigation
reveals that current evaluation is undermined by a systemic issue: the poor
quality of the benchmarks themselves. We introduce a formal typology for "Gold
Errors", which are pervasive flaws in the ground-truth data, and demonstrate
how they obscure true model performance. On the challenging BIRD benchmark,
GBV-SQL achieves 63.23% execution accuracy, a 5.8% absolute improvement. After
removing flawed examples, GBV-SQL achieves 96.5% (dev) and 97.6% (test)
execution accuracy on the Spider benchmark. Our work offers both a robust
framework for semantic validation and a critical perspective on benchmark
integrity, highlighting the need for more rigorous dataset curation.

</details>


### [175] [Mob-based cattle weight gain forecasting using ML models](https://arxiv.org/abs/2509.12615)
*Muhammad Riaz Hasib Hossain,Rafiqul Islam,Shawn R McGrath,Md Zahidul Islam,David Lamb*

Main category: cs.AI

TL;DR: 该研究提出了一种名为MB CWG的新技术，使用随机森林（RF）模型来预测牛的月度增重，并取得了优于支持向量回归（SVR）和长短期记忆（LSTM）模型的性能。


<details>
  <summary>Details</summary>
Motivation: 预测牲畜农场的牛只月度增重，以帮助农民优化饲喂策略、改进育种选择，并降低与气候变率和市场波动相关的风险。

Method: 使用随机森林（RF）模型，并与支持向量回归（SVR）和长短期记忆（LSTM）模型进行比较，利用包含天气（降雨量和温度）和年龄因素的历史数据来预测月度增重。此外，还开发了一个自动预处理工具来生成基准数据集。

Result: 在包含天气和年龄因素的数据集上，RF模型取得了0.973的R^2、0.040的RMSE和0.033的MAE，表现优于SVR和LSTM模型。结果表明，加入天气和年龄因素能显著提高预测精度。

Conclusion: 随机森林（RF）模型是预测牛只增重的稳健工具，尤其是在考虑年龄和气候因素时。该研究还提供了一个可公开获取的预处理工具，以支持未来的相关研究。

Abstract: Forecasting mob based cattle weight gain (MB CWG) may benefit large livestock
farms, allowing farmers to refine their feeding strategies, make educated
breeding choices, and reduce risks linked to climate variability and market
fluctuations. In this paper, a novel technique termed MB CWG is proposed to
forecast the one month advanced weight gain of herd based cattle using
historical data collected from the Charles Sturt University Farm. This research
employs a Random Forest (RF) model, comparing its performance against Support
Vector Regression (SVR) and Long Short Term Memory (LSTM) models for monthly
weight gain prediction. Four datasets were used to evaluate the performance of
models, using 756 sample data from 108 herd-based cattle, along with weather
data (rainfall and temperature) influencing CWG. The RF model performs better
than the SVR and LSTM models across all datasets, achieving an R^2 of 0.973,
RMSE of 0.040, and MAE of 0.033 when both weather and age factors were
included. The results indicate that including both weather and age factors
significantly improves the accuracy of weight gain predictions, with the RF
model outperforming the SVR and LSTM models in all scenarios. These findings
demonstrate the potential of RF as a robust tool for forecasting cattle weight
gain in variable conditions, highlighting the influence of age and climatic
factors on herd based weight trends. This study has also developed an
innovative automated pre processing tool to generate a benchmark dataset for MB
CWG predictive models. The tool is publicly available on GitHub and can assist
in preparing datasets for current and future analytical research..

</details>


### [176] [ECG-aBcDe: Overcoming Model Dependence, Encoding ECG into a Universal Language for Any LLM](https://arxiv.org/abs/2509.12625)
*Yong Xia,Jingxuan Li,YeTeng Sun,Jiarui Bu*

Main category: cs.AI

TL;DR: ECG-aBcDe是一种新的ECG编码方法，它将ECG信号转换为任何LLM都可以理解的通用ECG语言，解决了LLM在ECG分析中的可转移性、时间尺度信息学习和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在ECG分析中存在模型依赖、难以捕捉时间尺度信息以及可解释性差等问题，限制了其临床应用。

Method: 提出ECG-aBcDe方法，将ECG信号转换为通用ECG语言，并构建了ECG语言和自然语言的混合数据集，实现了LLM的直接微调。该方法还实现了ECG与ECG语言的双向转换，以提取注意力热图，并显式表示时间尺度信息。

Result: ECG-aBcDe在ROUGE-L和METEOR方面取得了有竞争力的性能，在BLEU-4方面取得了显著的改进，在数据集内和跨数据集评估中分别提高了2.8倍和3.9倍，得分分别为42.58和30.76。

Conclusion: ECG-aBcDe为ECG分析与LLM的集成提供了一种新范式，并在多项指标上取得了优于现有方法的性能，证明了该新范式的可行性。

Abstract: Large Language Models (LLMs) hold significant promise for electrocardiogram
(ECG) analysis, yet challenges remain regarding transferability, time-scale
information learning, and interpretability. Current methods suffer from
model-specific ECG encoders, hindering transfer across LLMs. Furthermore, LLMs
struggle to capture crucial time-scale information inherent in ECGs due to
Transformer limitations. And their black-box nature limits clinical adoption.
To address these limitations, we introduce ECG-aBcDe, a novel ECG encoding
method that transforms ECG signals into a universal ECG language readily
interpretable by any LLM. By constructing a hybrid dataset of ECG language and
natural language, ECG-aBcDe enables direct fine-tuning of pre-trained LLMs
without architectural modifications, achieving "construct once, use anywhere"
capability. Moreover, the bidirectional convertibility between ECG and ECG
language of ECG-aBcDe allows for extracting attention heatmaps from ECG
signals, significantly enhancing interpretability. Finally, ECG-aBcDe
explicitly represents time-scale information, mitigating Transformer
limitations. This work presents a new paradigm for integrating ECG analysis
with LLMs. Compared with existing methods, our method achieves competitive
performance on ROUGE-L and METEOR. Notably, it delivers significant
improvements in the BLEU-4, with improvements of 2.8 times and 3.9 times in
in-dataset and cross-dataset evaluations, respectively, reaching scores of
42.58 and 30.76. These results provide strong evidence for the feasibility of
the new paradigm.

</details>


### [177] [Learn to Relax with Large Language Models: Solving Nonlinear Combinatorial Optimization Problems via Bidirectional Coevolution](https://arxiv.org/abs/2509.12643)
*Beidan Liu,Zhengqiu Zhu,Chen Gao,Yong Zhao,Wei Qi,Quanjun Yin*

Main category: cs.AI

TL;DR: AutoCO通过利用LLM学习约束松弛策略来解决非线性组合优化问题（NCOPs），并结合进化算法和蒙特卡洛树搜索进行全局和局部优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理非线性组合优化问题（NCOPs）时面临挑战，因为它们的非凸性导致了多模式解空间，并且传统方法依赖于专家驱动的迭代设计，缺乏自动化和可扩展性。大型语言模型（LLMs）虽然有潜力，但目前主要作为被动的约束验证者，而非主动的策略构建者，无法处理NCOPs中复杂的约束交互。

Method: 提出了一种名为AutoCO的端到端自动化约束优化方法。该方法利用结构化的LLM推理来生成约束松弛策略，并通过统一的三重表示方案将其动态演化为算法原理和可执行代码。此外，建立了一个新颖的双向（全局-局部）协同进化机制，将进化算法用于密集的局部优化，并结合蒙特卡洛树搜索进行系统的全局策略空间探索，以在碎片化的解空间中实现强化和多样化之间的最佳平衡。

Result: 在三个具有挑战性的NCOP基准测试上的综合实验验证了AutoCO的有效性，并证明其性能优于现有基线方法。

Conclusion: AutoCO方法通过学习约束松弛策略，并结合全局和局部优化机制，能够有效解决非线性组合优化问题，并超越现有方法。

Abstract: Nonlinear Combinatorial Optimization Problems (NCOPs) present a formidable
computational hurdle in practice, as their nonconvex nature gives rise to
multi-modal solution spaces that defy efficient optimization. Traditional
constraint relaxation approaches rely heavily on expert-driven, iterative
design processes that lack systematic automation and scalable adaptability.
While recent Large Language Model (LLM)-based optimization methods show promise
for autonomous problem-solving, they predominantly function as passive
constraint validators rather than proactive strategy architects, failing to
handle the sophisticated constraint interactions inherent to NCOPs.To address
these limitations, we introduce the first end-to-end \textbf{Auto}mated
\textbf{C}onstraint \textbf{O}ptimization (AutoCO) method, which revolutionizes
NCOPs resolution through learning to relax with LLMs.Specifically, we leverage
structured LLM reasoning to generate constraint relaxation strategies, which
are dynamically evolving with algorithmic principles and executable code
through a unified triple-representation scheme. We further establish a novel
bidirectional (global-local) coevolution mechanism that synergistically
integrates Evolutionary Algorithms for intensive local refinement with Monte
Carlo Tree Search for systematic global strategy space exploration, ensuring
optimal balance between intensification and diversification in fragmented
solution spaces. Finally, comprehensive experiments on three challenging NCOP
benchmarks validate AutoCO's consistent effectiveness and superior performance
over the baselines.

</details>


### [178] [Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs](https://arxiv.org/abs/2509.12743)
*Hanqing Li,Kiran Sheena Jyothi,Henry Liang,Sharika Mahadevan,Diego Klabjan*

Main category: cs.AI

TL;DR: GRRAF是一种利用检索增强生成（RAG）和大型语言模型（LLM）进行图推理的新方法，无需训练，即可在多种图推理任务上达到100%的准确率，并且能有效处理大规模图。


<details>
  <summary>Details</summary>
Motivation: 现有的图推理方法需要大量微调或依赖预定义算法，GRRAF旨在克服这些限制，提供一种更灵活、高效的方法。

Method: GRRAF将目标图存储在图数据库中，并提示LLM生成可执行的代码查询来检索信息。该方法包含一个带有超时机制的错误反馈循环，以确保正确性和效率。

Result: 在GraphInstruct数据集上的实验表明，GRRAF在包括环检测、二分图检查、最短路径计算和最大流在内的大多数图推理任务上达到了100%的准确率，并且在子图匹配任务上也表现出非常高的性能。该方法能有效处理高达10,000个节点的图，并且保持稳定的代币成本。

Conclusion: GRRAF是一种有效且可扩展的图推理方法，它利用RAG和LLM的能力，避免了传统方法的局限性，并在多种任务上取得了优异的性能。

Abstract: We propose a new, training-free method, Graph Reasoning via Retrieval
Augmented Framework (GRRAF), that harnesses retrieval-augmented generation
(RAG) alongside the code-generation capabilities of large language models
(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target
graph is stored in a graph database, and the LLM is prompted to generate
executable code queries that retrieve the necessary information. This approach
circumvents the limitations of existing methods that require extensive
finetuning or depend on predefined algorithms, and it incorporates an error
feedback loop with a time-out mechanism to ensure both correctness and
efficiency. Experimental evaluations on the GraphInstruct dataset reveal that
GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle
detection, bipartite graph checks, shortest path computation, and maximum flow,
while maintaining consistent token costs regardless of graph sizes. Imperfect
but still very high performance is observed on subgraph matching. Notably,
GRRAF scales effectively to large graphs with up to 10,000 nodes.

</details>


### [179] [H$^2$R: Hierarchical Hindsight Reflection for Multi-Task LLM Agents](https://arxiv.org/abs/2509.12810)
*Shicheng Ye,Chao Yu,Kaiqiang Ke,Chengdong Xu,Yinqi Wei*

Main category: cs.AI

TL;DR: LLM代理使用分层记忆架构（H^2R）进行细粒度知识转移，以提高泛化能力和决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的知识转移方法效率低下且粗粒度，因为它们将先验知识和经验视为单一单元。

Method: 提出了一种新颖的分层记忆架构，将高级规划记忆与低级执行记忆分离，并引入了一种名为H^2R的机制来构建和精炼这些记忆。

Result: H^2R在两个基准测试中展示了其优于Expel等先前基线方法的性能，提高了泛化能力和决策能力。

Conclusion: H^2R通过实现细粒度的知识转移，能够有效地提高LLM代理在新任务上的表现。

Abstract: Large language model (LLM)-based agents have shown strong potential in
multi-task scenarios, owing to their ability to transfer knowledge across
diverse tasks. However, existing approaches often treat prior experiences and
knowledge as monolithic units, leading to inefficient and coarse-grained
knowledge transfer. In this work, we propose a novel hierarchical memory
architecture that enables fine-grained knowledge transfer by decoupling
high-level planning memory from low-level execution memory. To construct and
refine these hierarchical memories, we introduce Hierarchical Hindsight
Reflection (H$^2$R), a mechanism that distills reusable and hierarchical
knowledge from past agent-environment interactions. At test time, H$^2$R
performs retrievals of high-level and low-level memories separately, allowing
LLM-based agents to efficiently access and utilize task-relevant knowledge for
new tasks.Experimental results across two benchmarks demonstrate that H$^2$R
can improve generalization and decision-making performance, outperforming prior
baselines such as Expel.

</details>


### [180] [LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning](https://arxiv.org/abs/2509.12875)
*Jiaqi Wang,Binquan Ji,Haibo Luo,Yiyang Qi,Ruiting Li,Huiyan Wang,Yuantao Han,Cangyi Yang,jiaxu Zhang,Feiliang Ren*

Main category: cs.AI

TL;DR: LTA-Thinker通过增强潜在思维的方差来优化LLM的复杂推理能力，在训练阶段引入可学习的先验和基于分布的方向优化，以提高信息效率和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的复杂推理方法（如Coconut, SoftCoT）在生成和利用高质量的潜在思维方面存在瓶颈。

Method: 提出LTA-Thinker框架，通过可学习先验的潜在思维生成架构增加生成潜在思维向量的方差，并引入基于分布的方向优化机制，结合监督微调损失、语义对齐损失和推理焦点损失进行多目标协同训练。

Result: LTA-Thinker在多个基线模型上实现了最先进的性能，并展示了更高的性能上限和更好的扩展效果。

Conclusion: LTA-Thinker通过增强潜在思维的分布方差，有效提升了大型语言模型的复杂推理能力。

Abstract: Complex Reasoning in Large Language Models can be dynamically optimized using
Test-Time Scaling (TTS) to mitigate Overthinking. Methods such as Coconut,
SoftCoT and its variant are effective in continuous latent space inference, the
core bottleneck still lies in the efficient generation and utilization of
high-quality Latent Thought. Drawing from the theory of SoftCoT++ that a larger
variance in the generated Latent Thought distribution more closely approximates
the golden truth distribution, we propose a Latent Thought-Augmented Training
Framework--LTA-Thinker, which improves distributional variance and enhances
reasoning performance from two perspectives. First, LTA-Thinker constructs a
Latent Thought generation architecture based on a learnable prior. This
architecture aims to increase the variance distribution of generated Latent
Thought Vectors in order to simplify the overall structure and raise the
performance ceiling. Second, LTA-Thinker introduces a distribution-based
directional optimization paradigm that jointly constrains both distribution
locality and distribution scale. This mechanism improves information efficiency
and computational cost through a multi-objective co-training strategy, which
combines standard Supervised Fine-Tuning (SFT) loss with two novel losses:
Semantic Alignment Loss, which utilizes KL divergence to ensure that the Latent
Thought is highly relevant to the semantics of the question; Reasoning Focus
Loss, which utilizes a contrastive learning mechanism to guide the model to
focus on the most critical reasoning steps. Experiments show that LTA-thinker
achieves state-of-the-art (SOTA) performance among various baselines and
demonstrates a higher performance ceiling and better scaling effects.

</details>


### [181] [Stochastic Streets: A Walk Through Random LLM Address Generation in four European Cities](https://arxiv.org/abs/2509.12914)
*Tairan Fu,David Campo-Nazareno,Javier Coronado-Blázquez,Javier Conde,Pedro Reviriego,Fabrizio Lombardi*

Main category: cs.AI

TL;DR: LLMs may not be suited for generating random European street addresses.


<details>
  <summary>Details</summary>
Motivation: The paper questions the capability of LLMs to generate random street addresses for European cities, despite their general problem-solving abilities.

Method: The paper likely tests or explores the ability of LLMs to perform this specific task.

Result: The results are not provided in the abstract.

Conclusion: The abstract does not provide a conclusion, but implies that LLMs might not be capable of this task.

Abstract: Large Language Models (LLMs) are capable of solving complex math problems or
answer difficult questions on almost any topic, but can they generate random
street addresses for European cities?

</details>


### [182] [Population Estimation using Deep Learning over Gandhinagar Urban Area](https://arxiv.org/abs/2509.12926)
*Jai Singla,Peal Jotania,Keivalya Pandya*

Main category: cs.AI

TL;DR: 本研究利用高分辨率卫星图像、数字高程模型和矢量边界，提出了一种基于深度学习的人口估算方法，能够有效识别和估算城市建筑的人口，并达到了很高的准确率，为城市规划和资源管理提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的人口估算方法（如调查和普查）成本高、耗时长且依赖大量人力，本研究旨在提出一种更高效、自动化的深度学习解决方案。

Method: 该方法结合了卷积神经网络（CNN）用于建筑分类（区分住宅和非住宅），以及人工神经网络（ANN）用于人口估算。利用了约4.8万个建筑足迹数据进行训练和评估。

Result: 实验结果表明，该模型在Gandhinagar地区的建筑级人口估算中表现出色，整体F1分数达到0.9936，估算出该地区人口为278,954。

Conclusion: 该研究提出的自动化深度学习框架能够克服传统人口普查的局限性，为城市管理提供了一个可扩展、可复制的工具，展示了人工智能在增强数据驱动的城市治理方面的潜力。

Abstract: Population estimation is crucial for various applications, from resource
allocation to urban planning. Traditional methods such as surveys and censuses
are expensive, time-consuming and also heavily dependent on human resources,
requiring significant manpower for data collection and processing. In this
study a deep learning solution is proposed to estimate population using high
resolution (0.3 m) satellite imagery, Digital Elevation Models (DEM) of 0.5m
resolution and vector boundaries. Proposed method combines Convolution Neural
Network (CNN) architecture for classification task to classify buildings as
residential and non-residential and Artificial Neural Network (ANN)
architecture to estimate the population. Approx. 48k building footprints over
Gandhinagar urban area are utilized containing both residential and
non-residential, with residential categories further used for building-level
population estimation. Experimental results on a large-scale dataset
demonstrate the effectiveness of our model, achieving an impressive overall
F1-score of 0.9936. The proposed system employs advanced geospatial analysis
with high spatial resolution to estimate Gandhinagar population at 278,954. By
integrating real-time data updates, standardized metrics, and infrastructure
planning capabilities, this automated approach addresses critical limitations
of conventional census-based methodologies. The framework provides
municipalities with a scalable and replicable tool for optimized resource
management in rapidly urbanizing cities, showcasing the efficiency of AI-driven
geospatial analytics in enhancing data-driven urban governance.

</details>


### [183] [The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features](https://arxiv.org/abs/2509.12934)
*Jeremias Ferrao,Matthijs van der Lende,Ilija Lichkovski,Clement Neo*

Main category: cs.AI

TL;DR: RLHF 是一种不透明的对齐方法，而 FSRL 是一种更透明的替代方案，它使用轻量级适配器来控制可解释的特征，从而实现对齐。


<details>
  <summary>Details</summary>
Motivation: 当前的 RLHF 方法在模型对齐方面存在不透明的问题，难以理解模型内部的变化。

Method: 提出了一种名为特征引导强化学习 (FSRL) 的新颖的对齐框架。该框架使用轻量级适配器来引导行为，通过调节稀疏自动编码器 (SAE) 的可解释特征来实现。

Result: FSRL 在偏好优化方面表现有效，其性能可与现有的 RLHF 方法相媲美。对训练的适配器进行机制分析，发现其策略系统性地促进了风格特征而非明确的对齐概念，这表明偏好优化过程可能以风格化表达作为质量的代理。

Conclusion: FSRL 提供了一种可解释的模型控制工具，并有助于诊断模型对齐的内部机制。

Abstract: Aligning large language models is critical for their usability and safety.
However, the prevailing approach of Reinforcement Learning from Human Feedback
(RLHF) induces diffuse, opaque parameter changes, making it difficult to
discern what the model has internalized. Hence, we introduce Feature Steering
with Reinforcement Learning (FSRL), a transparent alignment framework that
trains a lightweight adapter to steer behavior by modulating interpretable
features from a Sparse Autoencoder (SAE). First, we demonstrate that FSRL is an
effective method for preference optimization and is comparable with current
RLHF methods. We then perform mechanistic analysis on the trained adapter, and
find that its policy systematically promotes style features over explicit
alignment concepts, suggesting that the preference optimization process rewards
stylistic presentation as a proxy for quality. Ultimately, we hope that FSRL
provides a tool for both interpretable model control and diagnosing the
internal mechanisms of alignment.

</details>


### [184] [Black-box Model Merging for Language-Model-as-a-Service with Massive Model Repositories](https://arxiv.org/abs/2509.12951)
*Shilian Chen,Jie Zhou,Tianyu Huai,Yujiang Lu,Junsong Li,Bihao Zhan,Qianjun Pan,Yutao Yang,Xin Li,Qin Chen,Hang Yan,Liang He*

Main category: cs.AI

TL;DR: 现有的模型合并方法通常需要访问模型权重，但对于像GPT-4这样仅通过API提供的黑盒大语言模型，模型权重是不可用的。本文提出了一种名为Evo-Merging的无导数优化框架，仅通过API查询即可实现黑盒模型合并。


<details>
  <summary>Details</summary>
Motivation: 解决黑盒大语言模型合并的问题，因为现有方法依赖于模型权重，而大语言模型通常仅作为黑盒服务提供。

Method: 提出了一种基于进化算法的无导数优化框架（Evo-Merging），包含两个关键组件：1. 基于稀疏化的去噪，用于识别和过滤模型间的无关或冗余信息；2. 考虑符号的缩放，用于动态计算相关模型的最优组合权重。

Result: 在多种任务上实现了最先进的结果，显著优于现有的强基线方法。

Conclusion: 提出的Evo-Merging方法能够有效进行黑盒大语言模型合并，并且在实验中表现优于现有方法。

Abstract: Model merging refers to the process of integrating multiple distinct models
into a unified model that preserves and combines the strengths and capabilities
of the individual models. Most existing approaches rely on task vectors to
combine models, typically under the assumption that model parameters are
accessible. However, for extremely large language models (LLMs) such as GPT-4,
which are often provided solely as black-box services through API interfaces
(Language-Model-as-a-Service), model weights are not available to end users.
This presents a significant challenge, which we refer to as black-box model
merging (BMM) with massive LLMs. To address this challenge, we propose a
derivative-free optimization framework based on the evolutionary algorithm
(Evo-Merging) that enables effective model merging using only inference-time
API queries. Our method consists of two key components: (1) sparsity-based
denoising, designed to identify and filter out irrelevant or redundant
information across models, and (2) sign-aware scaling, which dynamically
computes optimal combination weights for the relevant models based on their
performance. We also provide a formal justification, along with a theoretical
analysis, for our asymmetric sparsification. Extensive experimental evaluations
demonstrate that our approach achieves state-of-the-art results on a range of
tasks, significantly outperforming existing strong baselines.

</details>


### [185] [Forget What's Sensitive, Remember What Matters: Token-Level Differential Privacy in Memory Sculpting for Continual Learning](https://arxiv.org/abs/2509.12958)
*Bihao Zhan,Jie Zhou,Junsong Li,Yutao Yang,Shilian Chen,Qianjun Pan,Xin Li,Wen Wu,Xingjiao Wu,Qin Chen,Hang Yan,Liang He*

Main category: cs.AI

TL;DR: 该研究提出了一种名为PeCL的隐私增强持续学习框架，通过动态分配差分隐私预算和选择性遗忘敏感信息来平衡隐私保护和模型效用。


<details>
  <summary>Details</summary>
Motivation: 持续学习模型在积累知识时面临严峻的隐私挑战，而传统的差分隐私方法会严重损害模型效用，限制其在隐私敏感领域的应用。

Method: 提出了一种名为PeCL的框架，包括：1. 引入令牌级动态差分隐私策略，根据令牌的语义敏感度自适应分配隐私预算；2. 集成隐私引导的记忆塑形模块，利用敏感度分析选择性遗忘敏感信息，同时保留任务无关的历史知识。

Result: 实验结果表明，PeCL在隐私保护和模型效用之间取得了优越的平衡，在保持先前任务高精度的同时，确保了强大的隐私保护，优于基线模型。

Conclusion: PeCL框架通过动态差分隐私和隐私引导的记忆塑形，有效解决了持续学习中的隐私挑战，实现了隐私保护和模型效用的最佳结合。

Abstract: Continual Learning (CL) models, while adept at sequential knowledge
acquisition, face significant and often overlooked privacy challenges due to
accumulating diverse information. Traditional privacy methods, like a uniform
Differential Privacy (DP) budget, indiscriminately protect all data, leading to
substantial model utility degradation and hindering CL deployment in
privacy-sensitive areas. To overcome this, we propose a privacy-enhanced
continual learning (PeCL) framework that forgets what's sensitive and remembers
what matters. Our approach first introduces a token-level dynamic Differential
Privacy strategy that adaptively allocates privacy budgets based on the
semantic sensitivity of individual tokens. This ensures robust protection for
private entities while minimizing noise injection for non-sensitive, general
knowledge. Second, we integrate a privacy-guided memory sculpting module. This
module leverages the sensitivity analysis from our dynamic DP mechanism to
intelligently forget sensitive information from the model's memory and
parameters, while explicitly preserving the task-invariant historical knowledge
crucial for mitigating catastrophic forgetting. Extensive experiments show that
PeCL achieves a superior balance between privacy preserving and model utility,
outperforming baseline models by maintaining high accuracy on previous tasks
while ensuring robust privacy.

</details>


### [186] [Toward PDDL Planning Copilot](https://arxiv.org/abs/2509.12987)
*Yarin Benyamin,Argaman Mordoch,Shahaf S. Shperberg,Roni Stern*

Main category: cs.AI

TL;DR: 该论文提出了一种名为“规划助手”的聊天机器人，它集成了多种规划工具，并允许用户通过自然语言指令调用它们，以解决大型语言模型（LLM）在长期规划方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在执行复杂任务时缺乏可靠的长期规划能力。

Method: “规划助手”利用模型上下文协议（MCP）连接LLM和外部工具，支持语法检查、规划器选择、调用、计划验证和执行模拟等规划任务，无需领域特定的微调。

Result: 与未使用规划工具的LLM相比，“规划助手”在三个开源LLM上的表现显著更好。与GPT-5的初步定性比较也表明，“规划助手”表现更优。

Conclusion: 专门的规划工具是增强LLM规划能力的一种有效途径。

Abstract: Large Language Models (LLMs) are increasingly being used as autonomous agents
capable of performing complicated tasks. However, they lack the ability to
perform reliable long-horizon planning on their own. This paper bridges this
gap by introducing the Planning Copilot, a chatbot that integrates multiple
planning tools and allows users to invoke them through instructions in natural
language. The Planning Copilot leverages the Model Context Protocol (MCP), a
recently developed standard for connecting LLMs with external tools and
systems. This approach allows using any LLM that supports MCP without
domain-specific fine-tuning. Our Planning Copilot supports common planning
tasks such as checking the syntax of planning problems, selecting an
appropriate planner, calling it, validating the plan it generates, and
simulating their execution. We empirically evaluate the ability of our Planning
Copilot to perform these tasks using three open-source LLMs. The results show
that the Planning Copilot highly outperforms using the same LLMs without the
planning tools. We also conducted a limited qualitative comparison of our tool
against Chat GPT-5, a very recent commercial LLM. Our results shows that our
Planning Copilot significantly outperforms GPT-5 despite relying on a much
smaller LLM. This suggests dedicated planning tools may be an effective way to
enable LLMs to perform planning tasks.

</details>


### [187] [Data-driven Methods of Extracting Text Structure and Information Transfer](https://arxiv.org/abs/2509.12999)
*Shinichi Honna,Taichi Murayama,Akira Matsui*

Main category: cs.AI

TL;DR: 成功需要满足少数基本条件，而失败则有多种形式。文章在小说、在线百科、研究论文和电影中测试了AKP及其反面，并加入了有序和噪声模式。


<details>
  <summary>Details</summary>
Motivation: AKP认为成功需要满足少数基本条件，而失败则有多种形式。本文旨在测试AKP及其反面，以及有序和噪声模式在不同媒介中的表现。

Method: 将文本表示为功能块序列，并通过转换顺序和位置来评估收敛性。

Result: 结果表明，结构原则因媒介而异：小说在顺序上遵循反向AKP，维基百科结合了AKP和有序模式，学术论文在顺序上显示反向AKP但位置上保持噪声，而电影则因类型而异。

Conclusion: 因此，成功取决于特定于每种媒介的结构约束，而失败则在不同领域呈现不同形式。

Abstract: The Anna Karenina Principle (AKP) holds that success requires satisfying a
small set of essential conditions, whereas failure takes diverse forms. We test
AKP, its reverse, and two further patterns described as ordered and noisy
across novels, online encyclopedias, research papers, and movies. Texts are
represented as sequences of functional blocks, and convergence is assessed in
transition order and position. Results show that structural principles vary by
medium: novels follow reverse AKP in order, Wikipedia combines AKP with ordered
patterns, academic papers display reverse AKP in order but remain noisy in
position, and movies diverge by genre. Success therefore depends on structural
constraints that are specific to each medium, while failure assumes different
shapes across domains.

</details>


### [188] [A Visualized Framework for Event Cooperation with Generative Agents](https://arxiv.org/abs/2509.13011)
*Yuyang Tian,Shunqiang Mao,Wenchang Gao,Lanlan Qiu,Tianxing He*

Main category: cs.AI

TL;DR: MiniAgentPro是一个用于LLM驱动的Agent社会模拟的可视化平台，包含地图编辑器和动画播放器。它还提供了一个包含八种事件场景的测试集，用于评估LLM（如GPT-4o）在模拟中的表现，发现在简单场景下表现良好，但在复杂场景下存在协调挑战。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的Agent社会模拟框架缺乏对事件组织的系统性评估，并且在与物理环境的视觉集成方面存在不足，限制了Agent在空间导航和与物品交互方面的真实能力。

Method: 开发了MiniAgentPro可视化平台，该平台具有地图编辑器和动画播放器。基于此平台，引入了一个包含八种不同事件场景（包括简单和困难变体）的综合测试集，用于评估Agent的能力。

Result: 使用GPT-4o进行评估，结果显示在简单场景下Agent表现强劲，但在困难变体场景下，Agent在协调方面面临挑战。

Conclusion: MiniAgentPro平台和测试集为评估LLM驱动的Agent社会模拟提供了有价值的工具。虽然GPT-4o在基本场景下表现出色，但仍需进一步研究以解决复杂场景下的协调问题。

Abstract: Large Language Models (LLMs) have revolutionized the simulation of agent
societies, enabling autonomous planning, memory formation, and social
interactions. However, existing frameworks often overlook systematic
evaluations for event organization and lack visualized integration with
physically grounded environments, limiting agents' ability to navigate spaces
and interact with items realistically. We develop MiniAgentPro, a visualization
platform featuring an intuitive map editor for customizing environments and a
simulation player with smooth animations. Based on this tool, we introduce a
comprehensive test set comprising eight diverse event scenarios with basic and
hard variants to assess agents' ability. Evaluations using GPT-4o demonstrate
strong performance in basic settings but highlight coordination challenges in
hard variants.

</details>


### [189] [Reasoning with Preference Constraints: A Benchmark for Language Models in Many-to-One Matching Markets](https://arxiv.org/abs/2509.13131)
*Marylou Fauchard,Florian Carichon,Margarida Carvalho,Golnoosh Farnadi*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在数学推理方面表现出色，但将其应用于需要偏好和结构约束的匹配问题仍有待探索。本研究引入了一个包含369个实例的学院招生问题基准，以评估LLMs在可行性、稳定性、最优性方面的能力。结果表明，LLMs在满足所有评估标准方面存在困难，但推理LLMs优于传统模型。不同的提示策略效果不一，并且迭代提示的性能可能不是单调的。


<details>
  <summary>Details</summary>
Motivation: 在匹配问题（需要偏好和结构约束）上应用大型语言模型（LLMs）仍有待探索。本研究旨在通过引入学院招生问题基准来解决这一差距，以评估LLMs在可行性、稳定性、最优性方面的能力。

Method: 引入了一个包含369个学院招生问题实例的新基准，以评估LLMs在可行性、稳定性、最优性等关键维度上的表现。使用了多种提示策略，包括思维链、情境学习和基于角色的提示，并评估了迭代提示和自动生成反馈的效果。

Result: LLMs在满足所有评估标准方面存在困难，但推理LLMs（如QwQ和GPT-oss）的性能显著优于传统模型（如Llama、Qwen或Mistral）。不同的提示策略效果不一，迭代提示的性能可能不是单调的，可能早期达到峰值然后下降。

Conclusion: 本研究为模型推理性能和提示策略在具有偏好约束的组合优化问题中的有效性提供了新的视角。LLMs在处理此类问题时仍面临挑战，需要进一步的研究来提高其性能和可靠性。

Abstract: Recent advances in reasoning with large language models (LLMs) have
demonstrated strong performance on complex mathematical tasks, including
combinatorial optimization. Techniques such as Chain-of-Thought and In-Context
Learning have further enhanced this capability, making LLMs both powerful and
accessible tools for a wide range of users, including non-experts. However,
applying LLMs to matching problems, which require reasoning under preferential
and structural constraints, remains underexplored. To address this gap, we
introduce a novel benchmark of 369 instances of the College Admission Problem,
a canonical example of a matching problem with preferences, to evaluate LLMs
across key dimensions: feasibility, stability, and optimality. We employ this
benchmark to assess the performance of several open-weight LLMs. Our results
first reveal that while LLMs can satisfy certain constraints, they struggle to
meet all evaluation criteria consistently. They also show that reasoning LLMs,
like QwQ and GPT-oss, significantly outperform traditional models such as
Llama, Qwen or Mistral, defined here as models used without any dedicated
reasoning mechanisms. Moreover, we observed that LLMs reacted differently to
the various prompting strategies tested, which include Chain-of-Thought,
In-Context Learning and role-based prompting, with no prompt consistently
offering the best performance. Finally, we report the performances from
iterative prompting with auto-generated feedback and show that they are not
monotonic; they can peak early and then significantly decline in later
attempts. Overall, this work offers a new perspective on model reasoning
performance and the effectiveness of prompting strategies in combinatorial
optimization problems with preferential constraints.

</details>


### [190] [G-CSEA: A Graph-Based Conflict Set Extraction Algorithm for Identifying Infeasibility in Pseudo-Boolean Models](https://arxiv.org/abs/2509.13203)
*Kanishk Garg,Saranya D.,Sanal Kumar,Saurabh Singh,Anupam Purwar*

Main category: cs.AI

TL;DR: 现有方法提取伪布尔约束中的不可行约束子集（IIS）效率低下，提出了一种基于图的冲突集提取算法（G-CSEA），该算法通过构建蕴含图来追踪冲突，从而更有效地提取冲突集，并可选择性地最小化为IIS。


<details>
  <summary>Details</summary>
Motivation: 现有提取伪布尔约束中不可行约束子集（IIS）的方法（如Additive Deletion和QuickXplain）需要大量的求解器调用，而基于对偶射线分析的方法在松弛问题可行但伪布尔模型不可行时会失败。因此，需要更有效的方法来诊断和解决调度问题中的可行性问题。

Method: 提出一种名为图 기반 冲突集提取算法（G-CSEA）的新方法。该方法受冲突驱动子句学习（CDCL）启发，在约束传播过程中构建蕴含图。当检测到冲突时，算法会追踪两个决策分支中所有相关的约束，形成一个冲突集。该冲突集还可以选择性地使用QuickXplain进行最小化，以生成IIS。

Result: G-CSEA算法在冲突检测后，能够追踪所有相关的约束，生成冲突集。该冲突集可以进一步最小化为IIS。

Conclusion: G-CSEA提供了一种比现有方法更有效的方法来提取伪布尔约束的冲突集和IIS，这对于解决调度问题中的可行性问题至关重要。

Abstract: Workforce scheduling involves a variety of rule-based constraints-such as
shift limits, staffing policies, working hour restrictions, and many similar
scheduling rules-which can interact in conflicting ways, leading to infeasible
models. Identifying the underlying causes of such infeasibility is critical for
resolving scheduling issues and restoring feasibility. A common diagnostic
approach is to compute Irreducible Infeasible Subsets (IISs): minimal sets of
constraints that are jointly infeasible but become feasible when any one is
removed. We consider models formulated using pseudo-Boolean constraints with
inequality relations over binary variables, which naturally encode scheduling
logic. Existing IIS extraction methods such as Additive Deletion and
QuickXplain rely on repeated feasibility checks, often incurring large numbers
of solver calls. Dual ray analysis, while effective for LP-based models, may
fail when the relaxed problem is feasible but the underlying pseudo-Boolean
model is not. To address these limitations, we propose Graph-based Conflict Set
Extraction Algorithm (G-CSEA) to extract a conflict set, an approach inspired
by Conflict-Driven Clause Learning (CDCL) in SAT solvers. Our method constructs
an implication graph during constraint propagation and, upon detecting a
conflict, traces all contributing constraints across both decision branches.
The resulting conflict set can optionally be minimized using QuickXplain to
produce an IIS.

</details>


### [191] [Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy](https://arxiv.org/abs/2509.13234)
*Nadim Barakat,William Lotter*

Main category: cs.AI

TL;DR: MLLMs在糖尿病视网膜病变筛查中展现出潜力，可作为临床AI辅助的模拟器，并改进筛查流程。


<details>
  <summary>Details</summary>
Motivation: 当前的FDA批准的糖尿病视网膜病变（DR）筛查系统主要提供二元分类输出，这可能限制其临床可信度和实用性。为了提升临床医生与AI的协作表现，需要实证研究来确定最有效的输出格式，但这在规模化评估方面存在挑战。

Method: 本研究评估了两种多模态大语言模型（MLLMs）：GPT-4o和MedGemma，在DR检测任务上的表现，并探索了它们模拟不同类型临床AI辅助输出的能力。实验包括：1. 基线评估；2. 模拟AI辅助（使用合成预测）；3. 实际AI间协作（GPT-4o整合MedGemma的输出）。

Result: 在基线评估中，MedGemma在敏感性和AUROC方面优于GPT-4o，而GPT-4o的特异性接近完美但敏感性较低。两种模型都能根据模拟的AI输入调整预测，但GPT-4o在错误输入下表现急剧下降，MedGemma则更为稳定。在实际协作中，GPT-4o在MedGemma描述性输出的引导下，即使没有直接图像访问，也能达到高达0.96的AUROC。

Conclusion: 研究结果表明，MLLMs有潜力改进DR筛查流程，并可作为研究不同输出配置下临床AI辅助的规模化模拟器。像MedGemma这样轻量级的开源模型在资源匮乏地区可能特别有价值，而描述性输出可以增强临床工作流程中的可解释性和临床医生的信任度。

Abstract: Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI
systems can expand access to fundus photography screening. Current FDA-cleared
systems primarily provide binary referral outputs, where this minimal output
may limit clinical trust and utility. Yet, determining the most effective
output format to enhance clinician-AI performance is an empirical challenge
that is difficult to assess at scale. We evaluated multimodal large language
models (MLLMs) for DR detection and their ability to simulate clinical AI
assistance across different output types. Two models were tested on IDRiD and
Messidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source
medical model. Experiments included: (1) baseline evaluation, (2) simulated AI
assistance with synthetic predictions, and (3) actual AI-to-AI collaboration
where GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at
baseline, achieving higher sensitivity and AUROC, while GPT-4o showed
near-perfect specificity but low sensitivity. Both models adjusted predictions
based on simulated AI inputs, but GPT-4o's performance collapsed with incorrect
ones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o
achieved strong results when guided by MedGemma's descriptive outputs, even
without direct image access (AUROC up to 0.96). These findings suggest MLLMs
may improve DR screening pipelines and serve as scalable simulators for
studying clinical AI assistance across varying output configurations. Open,
lightweight models such as MedGemma may be especially valuable in low-resource
settings, while descriptive outputs could enhance explainability and clinician
trust in clinical workflows.

</details>


### [192] [A Scenario-Driven Cognitive Approach to Next-Generation AI Memory](https://arxiv.org/abs/2509.13235)
*Linyue Cai,Yuyang Cheng,Xiaoding Shao,Huiming Wang,Yong Zhao,Wei Zhang,Kang Li*

Main category: cs.AI

TL;DR: The paper proposes COLMA, a new AI memory architecture designed for AGI, addressing limitations of current systems by using a scenario-driven methodology for continuous learning and human-like reasoning.


<details>
  <summary>Details</summary>
Motivation: Current AI memory systems lack adaptability, multimodal integration, and continuous learning capabilities, which are crucial for advancing towards AGI.

Method: A scenario-driven methodology is proposed to extract functional requirements from cognitive scenarios, leading to design principles for AI memory systems. Based on this, the COgnitive Layered Memory Architecture (COLMA) is introduced, integrating cognitive scenarios, memory processes, and storage mechanisms.

Result: COLMA provides a unified framework for developing AI systems capable of lifelong learning and human-like reasoning.

Conclusion: COLMA offers a structured foundation for the pragmatic development of AGI by enabling AI systems to learn continuously and reason in a human-like manner.

Abstract: As artificial intelligence advances toward artificial general intelligence
(AGI), the need for robust and human-like memory systems has become
increasingly evident. Current memory architectures often suffer from limited
adaptability, insufficient multimodal integration, and an inability to support
continuous learning. To address these limitations, we propose a scenario-driven
methodology that extracts essential functional requirements from representative
cognitive scenarios, leading to a unified set of design principles for
next-generation AI memory systems. Based on this approach, we introduce the
\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that
integrates cognitive scenarios, memory processes, and storage mechanisms into a
cohesive design. COLMA provides a structured foundation for developing AI
systems capable of lifelong learning and human-like reasoning, thereby
contributing to the pragmatic development of AGI.

</details>


### [193] [RepIt: Representing Isolated Targets to Steer Language Models](https://arxiv.org/abs/2509.13281)
*Vincent Siu,Nathan W. Henry,Nicholas Crispino,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: RepIt是一个简单且数据高效的框架，用于分离概念表示，可以精确干预LLM的行为，例如选择性地抑制对特定概念的回避，同时在其他方面保持安全性。


<details>
  <summary>Details</summary>
Motivation: 激活引导在大型语言模型（LLMs）中的研究日益受到关注，但现有方法可能产生比预期更广泛的影响。因此，需要分离更纯粹的概念向量，以实现有针对性的干预，并更精细地理解LLM的行为。

Method: 提出RepIt框架，一个简单且数据高效的方法，用于分离概念表示，实现精确干预。

Result: RepIt在五个前沿LLMs上实现了精确干预，选择性地抑制了对目标概念的回避，同时在标准基准上保持了模型的安全性。研究还表明，这种纠正信号可以定位到仅100-200个神经元，并且仅需十几条样本即可提取出鲁棒的目标表示。

Conclusion: RepIt通过分离回避向量，证明了有针对性的干预可以抵消过度概括，为更精细地控制模型行为奠定了基础。该框架的效率也引发了对潜在滥用的担忧，因为其可以用较少的计算和数据进行操作，可能被用于规避现有基准的检测。

Abstract: While activation steering in large language models (LLMs) is a growing area
of research, methods can often incur broader effects than desired. This
motivates isolation of purer concept vectors to enable targeted interventions
and understand LLM behavior at a more granular level. We present RepIt, a
simple and data-efficient framework for isolating concept-specific
representations. Across five frontier LLMs, RepIt enables precise
interventions: it selectively suppresses refusal on targeted concepts while
preserving refusal elsewhere, producing models that answer WMD-related
questions while still scoring as safe on standard benchmarks. We further show
that the corrective signal localizes to just 100-200 neurons and that robust
target representations can be extracted from as few as a dozen examples on a
single A6000. This efficiency raises a dual concern: manipulations can be
performed with modest compute and data to extend to underrepresented
data-scarce topics while evading existing benchmarks. By disentangling refusal
vectors with RepIt, this work demonstrates that targeted interventions can
counteract overgeneralization, laying the foundation for more granular control
of model behavior.

</details>


### [194] [Shapes of Cognition for Computational Cognitive Modeling](https://arxiv.org/abs/2509.13288)
*Marjorie McShane,Sergei Nirenburg,Sanjay Oruganti,Jesse English*

Main category: cs.AI

TL;DR: Shapes是一种新的计算认知建模范式，用于语言智能代理（LEIA），通过记忆的感官、语言、概念、情景和程序知识的“形状”来简化复杂性。


<details>
  <summary>Details</summary>
Motivation: 介绍一种新的计算认知建模范式，即Shapes，用于语言智能代理（LEIA），旨在处理现实世界的复杂性。

Method: Shapes通过记忆的知识“星座”来简化复杂性，使代理能够期望典型情况、识别模式、习惯性行动、类比推理、令人满意地处理并最小化认知负荷。对于非典型结果，则采用基于形状的恢复方法，例如即时学习、寻求人类帮助或获得可行的理解。

Result: Shapes-based建模包括特定的目标、假设、建模策略、知识库和广泛现象的模型，并在特定的认知架构中实现。

Conclusion: Shapes是一种具体的建模方法，适用于LEIA，但其原则可以更广泛地应用于知识库和混合AI领域，以构建可解释、可扩展且值得信赖的AI系统。

Abstract: Shapes of cognition is a new conceptual paradigm for the computational
cognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are
remembered constellations of sensory, linguistic, conceptual, episodic, and
procedural knowledge that allow agents to cut through the complexity of real
life the same way as people do: by expecting things to be typical, recognizing
patterns, acting by habit, reasoning by analogy, satisficing, and generally
minimizing cognitive load to the degree situations permit. Atypical outcomes
are treated using shapes-based recovery methods, such as learning on the fly,
asking a human partner for help, or seeking an actionable, even if imperfect,
situational understanding. Although shapes is an umbrella term, it is not
vague: shapes-based modeling involves particular objectives, hypotheses,
modeling strategies, knowledge bases, and actual models of wide-ranging
phenomena, all implemented within a particular cognitive architecture. Such
specificity is needed both to vet our hypotheses and to achieve our practical
aims of building useful agent systems that are explainable, extensible, and
worthy of our trust, even in critical domains. However, although the LEIA
example of shapes-based modeling is specific, the principles can be applied
more broadly, giving new life to knowledge-based and hybrid AI.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [195] [Determination of the fifth Busy Beaver value](https://arxiv.org/abs/2509.12337)
*The bbchallenge Collaboration,Justin Blanchard,Daniel Briggs,Konrad Deka,Nathan Fenner,Yannick Forster,Georgi Georgiev,Matthew L. House,Rachel Hunter,Iijil,Maja Kądziołka,Pavel Kropitz,Shawn Ligocki,mxdys,Mateusz Naściszewski,savask,Tristan Stérin,Chris Xu,Jason Yuen,Théo Zimmermann*

Main category: cs.LO

TL;DR: S(5) = 47,176,870，这是40多年来首次确定的新的停机酶值，也是第一个经过形式化验证的停机酶值。


<details>
  <summary>Details</summary>
Motivation: Tibor Radó于1962年引入停机酶值S(n)作为不可计算函数的简单示例，本文旨在计算并验证S(5)的值。

Method: 通过Coq证明助手，枚举了181,385,789个5状态2符号的图灵机，并逐一判断其是否停机。

Result: 证明了S(5) = 47,176,870。

Conclusion: 本文的S(5)结果是40多年来首次确定的新的停机酶值，也是第一个经过形式化验证的停机酶值，证明了在线大规模协作研究（bbchallenge.org）的有效性。

Abstract: We prove that $S(5) = 47,176,870$ using the Coq proof assistant. The Busy
Beaver value $S(n)$ is the maximum number of steps that an $n$-state 2-symbol
Turing machine can perform from the all-zero tape before halting, and $S$ was
historically introduced by Tibor Rad\'o in 1962 as one of the simplest examples
of an uncomputable function. The proof enumerates $181,385,789$ Turing machines
with 5 states and, for each machine, decides whether it halts or not. Our
result marks the first determination of a new Busy Beaver value in over 40
years and the first Busy Beaver value ever to be formally verified, attesting
to the effectiveness of massively collaborative online research
(bbchallenge$.$org).

</details>


### [196] [Probabilistic Model Checking: Applications and Trends](https://arxiv.org/abs/2509.12968)
*Marta Kwiatkowska,Gethin Norman,David Parker*

Main category: cs.LO

TL;DR: 概率模型检验在随机系统的形式化建模与分析中具有重要价值，并且在过去二十五年里得到了广泛发展和应用。


<details>
  <summary>Details</summary>
Motivation: 本文旨在识别概率模型检验已证明有价值的主要应用领域，并探讨这些领域的演变，同时总结支撑这些进步的关键理论和技术，以期为潜在用户提供信息并指导该领域的未来发展。

Method: 本文通过识别主要应用领域、讨论其随时间的演变、总结关键理论和技术，并突出说明性示例来阐述概率模型检验的优势。

Result: 概率模型检验在不同领域得到了广泛应用，并且随着时间的推移，其应用范围和深度不断扩大，理论和技术也取得了长足进步。

Conclusion: 概率模型检验在随机系统的形式化建模与分析中已成为一项成熟且有价值的技术，其未来的发展潜力巨大。

Abstract: Probabilistic model checking is an approach to the formal modelling and
analysis of stochastic systems. Over the past twenty five years, the number of
different formalisms and techniques developed in this field has grown
considerably, as has the range of problems to which it has been applied. In
this paper, we identify the main application domains in which probabilistic
model checking has proved valuable and discuss how these have evolved over
time. We summarise the key strands of the underlying theory and technologies
that have contributed to these advances, and highlight examples which
illustrate the benefits that probabilistic model checking can bring. The aim is
to inform potential users of these techniques and to guide future developments
in the field.

</details>


### [197] [On a Dependently Typed Encoding of Matching Logic](https://arxiv.org/abs/2509.13018)
*Ádám Kurucz,Péter Bereczky,Dániel Horpácsi*

Main category: cs.LO

TL;DR: 该论文首次为匹配μ逻辑提供了依赖类型定义，通过类型索引中的排序上下文确保了排序的正确性，从而使不排序的语法元素无法表示，并保证了排序元素的语义在其关联排序的域内。


<details>
  <summary>Details</summary>
Motivation: 需要一个基础理论来表达匹配μ逻辑，以便进行元理论推理。选择依赖类型理论可以直接将对象理论中的排序正确性对应为主体理论中的类型正确性。

Method: 将匹配μ逻辑定义为依赖类型，使用编码在类型索引中的排序上下文来确保排序的正确性。

Result: 实现了匹配μ逻辑的依赖类型定义，使得不排序的语法元素无法表示，并保证了排序元素的语义在其关联排序的域内。

Conclusion: 该论文首次为匹配μ逻辑提供了依赖类型定义，该定义利用排序上下文确保了排序的正确性，从而在理论上保证了语法和语义的一致性。

Abstract: Matching logic is a general formal framework for reasoning about a wide range
of theories, with particular emphasis on programming language semantics.
Notably, the intermediate language of the K semantics framework is an extension
of matching $\mu$-logic, a sorted, polyadic variant of the logic. Metatheoretic
reasoning requires the logic to be expressed within a foundational theory;
opting for a dependently typed one enables well-sortedness in the object theory
to correspond directly to well-typedness in the host theory. In this paper, we
present the first dependently typed definition of matching $\mu$-logic,
ensuring well-sortedness via sorted contexts encoded in type indices. As a
result, ill-sorted syntax elements are unrepresentable, and the semantics of
well-sorted elements are guaranteed to lie within the domain of their
associated sort.

</details>


### [198] [Łukasiewicz Logic with Actions for Neural Networks training](https://arxiv.org/abs/2509.13020)
*Ioana Leuştean,Bogdan Macovei*

Main category: cs.LO

TL;DR: 利用混合模态逻辑分析多层感知机的训练过程。


<details>
  <summary>Details</summary>
Motivation: 基于多层感知机与具有有理系数的Lukasiewicz逻辑之间的已知联系，进一步分析其训练过程。

Method: 使用三类混合模态逻辑，将多层感知机视为逻辑公式，将训练过程的动作视为模态算子，将训练过程视为一系列逻辑推导。并使用Lean 4证明助手和编程语言对训练过程的算法实现进行逻辑证明认证。

Result: 通过Lean 4证明助手和编程语言对训练过程的算法实现进行了逻辑证明认证。

Conclusion: 通过混合模态逻辑和Lean 4的结合，为多层感知机的训练过程提供了形式化验证的方法。

Abstract: Based on the already known connection between multilayer perceptrons and
Lukasiewicz logic with rational coefficients, we take a step forward in
analyzing its training process using a three-sorted hybrid modal logic: a
multilayer perceptron is a logical formula; the actions of the training process
are modal operators; the training process is a sequence of logical deductions.
Using the proof assistant and the programming language Lean 4, the algorithmic
implementation of the training process is certified by logical proofs.

</details>


### [199] [The Hidden Strength of Costrong Functors](https://arxiv.org/abs/2509.13026)
*Adriana Balan,Silviu-George Pantelimon*

Main category: cs.LO

TL;DR: The paper explores the concept of 


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand the dualisation of the 

Method: The method involves exploring costrong functors and their natural properties.

Result: The result is a deeper understanding of how functors interact with monoidal structures.

Conclusion: The conclusion is that costrong functors offer a new perspective on structuring context-dependent computations and their semantics.

Abstract: Strong functors and monads are ubiquitous in Computer Science. More recently,
comonads have demonstrated their use in structuring context-dependent notions
of computation. However, the dualisation of ``being strong'' property passed
somehow unobserved so far. We argue that ``being costrong'' gives a different
understanding of how functors can interact with monoidal structures. This work
in progress aims to explore costrong functors and their natural properties,
with an eye towards the semantics of computations.

</details>


### [200] [Intuitionistic modal logics: epistemic reasoning with distributed knowledge](https://arxiv.org/abs/2509.13038)
*Philippe Balbiani*

Main category: cs.LO

TL;DR: 本篇论文将一个“diamond”算子添加到 Artemov 和 Protopopescu 提出的直觉主义认知逻辑和直觉主义认知逻辑的参数化盒式命题语言中。


<details>
  <summary>Details</summary>
Motivation: 在现有逻辑语言中引入新的算子以扩展其表达能力。

Method: 将“diamond”算子添加到直觉主义认知逻辑和直觉主义认知逻辑的参数化盒式命题语言中，并研究其性质。

Result: 证明了包含“diamond”算子的直觉主义认知逻辑和直觉主义认知逻辑（具有分布式知识）在相关的关系语义下是完备的。

Conclusion: 所提出的包含“diamond”算子的逻辑系统在分布式知识的背景下是完备的。

Abstract: In this article, we add a diamond to the parametrized box-based propositional
language of intuitionistic doxastic logic and intuitionistic epistemic logic
introduced by Artemov and Protopopescu. The main results of this article are
the proofs of completeness with respect to their appropriate relational
semantics of the resulting intuitionistic doxastic logic and intuitionistic
epistemic logic with distributed knowledge.

</details>


### [201] [Reducts of fuzzy contexts: Formal concept analysis vs. rough set theory](https://arxiv.org/abs/2509.13059)
*Yuxu Chen,Jing Liu,Lili Shen,Xiaoye Tang*

Main category: cs.LO

TL;DR: Fuzzy context reducts in FCA and RST are interdefinable via negation iff L satisfies the law of double negation.


<details>
  <summary>Details</summary>
Motivation: Inspired by formal concept analysis and rough set theory, this paper explores the concept of reducts in fuzzy contexts.

Method: The study investigates the relationship between reducts of fuzzy contexts in formal concept analysis and rough set theory, specifically for complete residuated lattices L. It proves that these reducts are interdefinable via negation if and only if L satisfies the law of double negation.

Result: The paper demonstrates that the interdefinability of reducts (via negation) in L-contexts for FCA and RST is equivalent to the property of L satisfying the law of double negation.

Conclusion: The law of double negation in a complete residuated lattice L is the necessary and sufficient condition for the reducts of L-contexts in formal concept analysis and rough set theory to be interdefinable via negation.

Abstract: We postulate the intuitive idea of reducts of fuzzy contexts based on formal
concept analysis and rough set theory. For a complete residuated lattice $L$,
it is shown that reducts of $L$-contexts in formal concept analysis are
interdefinable with reducts of $L$-contexts in rough set theory via negation
if, and only if, $L$ satisfies the law of double negation.

</details>


### [202] [Proceedings of the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification](https://arxiv.org/abs/2509.13258)
*Giorgio Bacci,Adrian Francalanza*

Main category: cs.LO

TL;DR: GandALF 2025 是一个关于博弈、自动机、逻辑和形式验证的国际研讨会，旨在促进学术界和工业界研究人员之间的交流与合作。


<details>
  <summary>Details</summary>
Motivation: 本次会议旨在汇集在博弈、自动机、逻辑和形式验证领域的研究人员，覆盖从理论到应用的广泛主题，并促进交叉学科的融合。

Method: 本次会议包括学术界和工业界研究人员的参与，并涵盖了广泛的主题。

Result: 本次会议的论文集收录了 GandALF 2025 的会议论文。

Conclusion: 本次会议成功地汇集了相关领域的专家，并促进了学术界和工业界之间的交流。

Abstract: This volume contains the proceedings of GandALF 2025, the Sixteenth
International Symposium on Games, Automata, Logics, and Formal Verification.
GandALF 2025 took place on 16-17th September 2025, in Valletta, Malta. The aim
of GandALF 2025 is to bring together researchers from academia and industry who
are actively working in the fields of Games, Automata, Logics, and Formal
Verification. The idea is to cover an ample spectrum of themes, ranging from
theory to applications, and stimulate cross-fertilisation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [203] [Private Markovian Equilibrium in Stackelberg Markov Games for Smart Grid Demand Response](https://arxiv.org/abs/2509.12225)
*Siying Huang,Yifen Mu,Ge Chen*

Main category: eess.SY

TL;DR: 可再生能源并网带来的供需平衡挑战可以通过包含用户储能私有状态的 Stackelberg Markov 游戏来解决，该游戏具有多项式时间可计算的均衡。


<details>
  <summary>Details</summary>
Motivation: 为应对可再生能源并网带来的供需平衡挑战，提出了一种新的博弈论模型。

Method: 提出了一种新的博弈论模型——Stackelberg Markov 游戏（SMG），其中包含用户储能的私有状态，并引入了私有马尔可夫策略（PMS）和私有马尔可夫均衡（PME）的概念。证明了纯PME的存在性及其多项式时间可计算性，并开发了一个结合中心化和去中心化算法的可扩展解决方案框架。

Result: 所提出的方法在包含多达50个用户（基于真实数据）的数值模拟中被证明是有效的和可扩展的，而现有研究通常只考虑多达5个用户。

Conclusion: 本研究提出的基于SMG和PME的解决方案能够有效且可扩展地解决可再生能源并网带来的供需平衡挑战，为大规模电网管理提供了新的思路。

Abstract: The increasing integration of renewable energy introduces a great challenge
to the supply and demand balance of the power grid. To address this challenge,
this paper formulates a Stackelberg Markov game (SMG) between an aggregator and
multiple users, where the aggregator sets electricity prices and users make
demand and storage decisions. Considering that users' storage levels are
private information, we introduce private states and propose the new concepts
of private Markovian strategies (PMS) and private Markovian equilibrium (PME).
We establish the existence of a pure PME in the lower-level Markov game and
prove that it can be computed in polynomial time. Notably, computing
equilibrium in general Markov games is hard, and polynomial-time algorithms are
rarely available. Based on these theoretical results, we develop a scalable
solution framework combining centralized and decentralized algorithms for the
lower-level PME computation with upper-level pricing optimization. Numerical
simulations with up to 50 users based on real data validate the effectiveness
and scalability of the proposed methods, whereas prior studies typically
consider no more than 5 users.

</details>


### [204] [A Cost-Optimization Model for EV Charging Stations Utilizing Solar Energy and Variable Pricing](https://arxiv.org/abs/2509.12214)
*An Nguyen,Hung Pham,Cuong Do*

Main category: eess.SY

TL;DR: 该研究提出了一个电动汽车充电站的成本优化框架，结合了光伏发电，并使用Bertsimas-Sim鲁棒优化方法处理电力价格不确定性。


<details>
  <summary>Details</summary>
Motivation: 为了优化电动汽车充电站的运营成本，同时考虑光伏发电和电力价格的不确定性。

Method: 将问题建模为一个线性规划问题，该问题考虑了车辆能源需求、充电和电网容量限制，并最小化采购成本。。

Result: 在Caltech ACN数据集上的实际充电数据显示，与先到先服务基线相比，平均节省了约12%的成本，每月峰值节省高达19.2%。

Conclusion: 该框架提供了一个实用、有利于电网且可扩展的解决方案，适用于未来的电动汽车充电运营。

Abstract: This paper presents a cost optimization framework for electric vehicle (EV)
charging stations that leverages on-site photovoltaic (PV) generation and
explicitly accounts for electricity price uncertainty through a Bertsimas--Sim
robust formulation. The model is formulated as a linear program that satisfies
vehicle energy demands, respects charging and grid capacity constraints, and
minimizes procurement cost. Evaluations on real charging data from the Caltech
ACN dataset show average savings of about 12\% compared to a
first-come--first-served baseline, with peak monthly reductions up to 19.2\%. A
lightweight sensitivity analysis indicates that a modest $\sim$5\% increase in
nominal cost can reduce worst-case exposure by 14\%. Computational tests
confirm real-time feasibility, with instances of up to 50 concurrent EVs solved
in under 5 seconds on a standard laptop. The proposed method provides a
practical, grid-friendly, and scalable solution for future EV charging
operations.

</details>


### [205] [Meta-model Neural Process for Probabilistic Power Flow under Varying N-1 System Topologies](https://arxiv.org/abs/2509.12281)
*Sel Ly,Kapil Chauhan,Anshuman Singh,Hung Dinh Nguyen*

Main category: eess.SY

TL;DR: 该研究提出了一种基于神经网络过程（MMNP）的拓扑自适应方法，用于解决概率潮流（PPF）问题，特别是在考虑单线故障等拓扑变化时，能够无需重新训练即可适应新配置，从而减轻了计算负担。


<details>
  <summary>Details</summary>
Motivation: 传统 PPF 方法在拓扑结构改变时需要重新求解，这在可再生能源和电动汽车普及导致电网波动性增加的情况下，带来了不便和计算负担。需要一种能够适应不同拓扑结构的 PPF 方法。

Method: 提出了一种新颖的拓扑自适应方法，基于元学习神经网络过程（MMNP），并利用上下文集（context set）来表示拓扑结构，以及条件函数学习技术。

Result: 该方法在 IEEE 9 节点和 118 节点系统上进行了仿真验证，在 9 节点系统上的最大 L1 相对误差范数（%L1-relative error norm）为 1.11%，在 118 节点系统上为 0.77%。

Conclusion: 所提出的 MMNP 方法能够有效处理 PPF 问题在不同拓扑结构下的变化，尤其是在电网波动性增加的背景下，填补了 PPF 方法论的关键空白。

Abstract: The probabilistic power flow (PPF) problem is essential to quantifying the
distribution of the nodal voltages due to uncertain injections. The
conventional PPF problem considers a fixed topology, and the solutions to such
a PPF problem are associated with this topology. A change in the topology might
alter the power flow patterns and thus require the PPF problem to be solved
again. The previous PPF model and its solutions are no longer valid for the new
topology. This practice incurs both inconvenience and computation burdens as
more contingencies are foreseen due to high renewables and a large share of
electric vehicles. This paper presents a novel topology-adaptive approach,
based on the meta-model Neural Process (MMNP), for finding the solutions to PPF
problems under varying N-1 topologies, particularly with one-line failures. By
leveraging context set-based topology representation and conditional
distribution over function learning techniques, the proposed MMNP enhances the
robustness of PPF models to topology variations, mitigating the need for
retraining PPF models on a new configuration. Simulations on an IEEE 9-bus
system and IEEE 118-bus system validate the model's performance. The maximum
%L1-relative error norm was observed as 1.11% and 0.77% in 9-bus and 118-bus,
respectively. This adaptive approach fills a critical gap in PPF methodology in
an era of increasing grid volatility.

</details>


### [206] [A Deep Learning Approach to Renewable Capacity Installation under Jump Uncertainty](https://arxiv.org/abs/2509.12364)
*Nacira Agram,Fred Espen Benth,Giulia Pucci,Jan Rems*

Main category: eess.SY

TL;DR: 该研究提出并分析了考虑需求不确定性和跳跃动力学的可再生能源装机容量随机模型。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为应对需求不确定性和发电/负荷的剧烈波动，建立一个优化可再生能源装机容量的决策框架。

Method: 提出了两种方法：1. 基于阈值的控制规则，将问题转化为非线性偏微分积分方程（PIDE），并使用扩展的DBDP求解器（结合深度神经网络）解决。2. 提出了一种纯数据驱动的深度强化学习算法，直接学习最优反馈策略。

Result: 数值实验表明，基于阈值的BSDE方法具有可解释性和易处理性，而深度强化学习方法在容量分配的灵活性方面表现出更优的性能。

Conclusion: 两种方法共同为在不确定性下进行长期可再生能源扩张的决策支持提供了一个稳健的框架。

Abstract: We study a stochastic model for the installation of renewable energy capacity
under demand uncertainty and jump driven dynamics. The system is governed by a
multidimensional Ornstein-Uhlenbeck (OU) process driven by a subordinator,
capturing abrupt variations in renewable generation and electricity load.
Installation decisions are modeled through control actions that increase
capacity in response to environmental and economic conditions.
  We consider two distinct solution approaches. First, we implement a
structured threshold based control rule, where capacity is increased
proportionally when the stochastic capacity factor falls below a fixed level.
This formulation leads to a nonlinear partial integro-differential equation
(PIDE), which we solve by reformulating it as a backward stochastic
differential equation with jumps. We extend the DBDP solver in
\cite{hure2020deep} to the pure jump setting, employing a dual neural network
architecture to approximate both the value function and the jump sensitivity.
  Second, we propose a fully data driven deep control algorithm that directly
learns the optimal feedback policy by minimizing the expected cost functional
using neural networks. This approach avoids assumptions on the form of the
control rule and enables adaptive interventions based on the evolving system
state.
  Numerical experiments highlight the strengths of both methods. While the
threshold based BSDE approach offers interpretability and tractability, the
deep control strategy achieves improved performance through flexibility in
capacity allocation. Together, these tools provide a robust framework for
decision support in long term renewable energy expansion under uncertainty.

</details>


### [207] [Platoon-Centric Green Light Optimal Speed Advisory Using Safe Reinforcement Learning](https://arxiv.org/abs/2509.12378)
*Ruining Yang,Jingyuan Zhou,Qiqing Wang,Jinhao Liang,Kaidi Yang*

Main category: eess.SY

TL;DR: 本研究提出了一种基于多智能体强化学习和控制势垒函数的即时巡航辅助驾驶系统，以优化网联自动驾驶汽车（CAVs）在混合交通流中的速度，从而在保证行车安全的前提下，平衡能耗和行程效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单车效率，忽略了对混合交通流整体效率的影响。强化学习（RL）在解决此问题方面潜力巨大，但面临行车安全和红灯安全两大挑战。

Method: 开发了一个以车队为中心、安全的RL-GOLOSA系统，采用多智能体控制器优化CAV速度，并结合控制势垒函数（CBFs）提供显式的安全保障，解决了行车安全和红灯安全问题。

Result: 仿真结果表明，所提出的方法在驾驶安全和车队能耗方面优于现有最先进的方法。

Conclusion: 本研究成功开发了一种能够保证行车安全和红灯安全，并优化车队整体能耗和行程效率的RL-GOLOSA系统。

Abstract: With recent advancements in Connected Autonomous Vehicles (CAVs), Green Light
Optimal Speed Advisory (GLOSA) emerges as a promising eco-driving strategy to
reduce the number of stops and idle time at intersections, thereby reducing
energy consumption and emissions. Existing studies typically improve energy and
travel efficiency for individual CAVs without considering their impacts on the
entire mixed-traffic platoon, leading to inefficient traffic flow. While
Reinforcement Learning (RL) has the potential to achieve platoon-level control
in a mixed-traffic environment, the training of RL is still challenged by (i)
car-following safety, i.e., CAVs should not collide with their immediate
preceding vehicles, and (ii) red-light safety, i.e., CAVs should not run red
lights. To address these challenges, this paper develops a platoon-centric,
safe RL-based GLOSA system that uses a multi-agent controller to optimize CAV
speed while achieving a balance between energy consumption and travel
efficiency. We further incorporate Control Barrier Functions (CBFs) into the
RL-based policy to provide explicit safety guarantees in terms of car-following
safety and red-light safety. Our simulation results illustrate that our
proposed method outperforms state-of-the-art methods in terms of driving safety
and platoon energy consumption.

</details>


### [208] [Hybrid State Estimation of Uncertain Nonlinear Dynamics Using Neural Processes](https://arxiv.org/abs/2509.12522)
*Devin Hunter,Chinwendu Enyioha*

Main category: eess.SY

TL;DR: 本文提出了一种结合物理信息和注意力机制的混合数据驱动状态估计方法，并使用分裂共形预测框架量化模型不确定性，以提高在安全关键应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了满足安全关键应用中对具有可靠误差范围的数据驱动模型的需求，本文提出了一种新的混合数据驱动状态估计方法。

Method: 本文提出了一种基于物理信息注意力神经网络（PI-AttNP）的混合数据驱动状态估计方法，并结合了基于回归的分裂共形预测（CP）框架来获得具有概率保证的可量化模型不确定性。

Result: 在模拟的欠驱动六自由度四旋翼飞行器的灰盒状态估计任务中，该方法在处理多模态高斯传感器噪声和典型外部扰动方面表现出色，并与最先进的数据驱动方法进行了比较。

Conclusion: 物理信息神经网络是一种用于模型驱动估计的可行的新方法。

Abstract: Various neural network architectures are used in many of the state-of-the-art
approaches for real-time nonlinear state estimation in dynamical systems. With
the ever-increasing incorporation of these data-driven models into the
estimation domain, models with reliable margins of error are required --
especially for safety-critical applications. This paper discusses a novel
hybrid, data-driven state estimation approach based on the physics-informed
attentive neural process (PI-AttNP), a model-informed extension of the
attentive neural process (AttNP). We augment this estimation approach with the
regression-based split conformal prediction (CP) framework to obtain quantified
model uncertainty with probabilistic guarantees. After presenting the algorithm
in a generic form, we validate its performance in the task of grey-box state
estimation of a simulated under-actuated six-degree-of-freedom quadrotor with
multimodal Gaussian sensor noise and several external perturbations typical to
quadrotors. Further, we compare outcomes with state-of-the-art data-driven
methods, which provide significant evidence of the physics-informed neural
process as a viable novel approach for model-driven estimation.

</details>


### [209] [CattleSense -- A Multisensory Approach to Optimize Cattle Well-Being](https://arxiv.org/abs/2509.12617)
*Srijesh Pillai,M. I. Jawid Nazir*

Main category: eess.SY

TL;DR: CattleSense是一个利用物联网技术监测和管理牛群健康的应用。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在利用物联网技术，通过监测牛群的实时环境和个体参数（如位置、挤奶频率、心率波动），简化牛群管理，确保牛群健康和安全。

Method: 设计并实现了一个基于Raspberry Pi Module 4B、RFID读卡器、Electret麦克风模块、DHT11传感器、Arduino UNO、Neo-6M GPS传感器和心跳传感器的系统。

Result: 该系统能够提供牛群所处环境以及个体牛（如位置、挤奶频率、心率波动）的实时监控。

Conclusion: CattleSense通过集成多种传感器和通信技术，为牛群的全面健康监测和管理提供了一个创新的解决方案。

Abstract: CattleSense is an innovative application of Internet of Things (IoT)
technology for the comprehensive monitoring and management of cattle
well-being. This research paper outlines the design and implementation of a
sophisticated system using a Raspberry Pi Module 4B, RFID Card Reader, Electret
Arduino Microphone Module, DHT11 Sensor, Arduino UNO, Neo-6M GPS Sensor, and
Heartbeat Sensor. The system aims to provide real-time surveillance of the
environment in which Cows are present and individual Cow parameters such as
location, milking frequency, and heartbeat fluctuations. The primary objective
is to simplify managing the Cattle in the shed, ensuring that the Cattle are
healthy and safe.

</details>


### [210] [Nonlinear Sampled-data Systems--A Lifting Framework](https://arxiv.org/abs/2509.12681)
*Yutaka Yamamoto,Kaoru Yamamoto*

Main category: eess.SY

TL;DR: 该论文提出了一种处理非线性采样数据系统的新方法，将线性系统中的“提升”技术推广到非线性系统，并解决了直接前馈项的难题，最终得到了一个等价的离散时间系统，并可用于表示Koopman算子。


<details>
  <summary>Details</summary>
Motivation: 处理非线性采样数据系统，并将线性系统中的“提升”技术推广到非线性系统。

Method: 提出了一种新的非线性时间不变系统的提升技术，通过进一步提升状态轨迹，得到一个等价的、具有函数空间输入输出的非线性时间不变离散时间系统。

Result: 给出了基本框架以及闭环方程，并将此框架应用于Koopman算子表示。

Conclusion: 提出了一种新的非线性采样数据系统处理框架，并成功将其应用于Koopman算子表示。

Abstract: This short note gives a new framework for dealing with nonlinear sampled-data
systems. We introduce a new idea of lifting, which is well known for linear
systems, but not successfully generalized to nonlinear systems. This paper
introduces a new lifting technique for nonlinear, time-invariant systems, which
are different from the linear counterpart as developed in [Bamieh et al. 1991,
Yamamoto 1994], etc. The main difficulty is that the direct feedthrough term
effective in the linear case cannot be generalized to the nonlinear case.
Instead, we will further lift the state trajectory, and obtain an equivalent
time-invariant discrete-time system with function-space input and output
spaces. The basic framework, as well as the closed-loop equation with a
discrete-time controller, is given. As an application of this framework, we
give a representation for the Koopman operator derived from the given original
nonlinear system.

</details>


### [211] [MAPS: A Mode-Aware Probabilistic Scheduling Framework for LPV-Based Adaptive Control](https://arxiv.org/abs/2509.12695)
*Taehun Kim,Guntae Kim,Cheolmin Jeong,Chang Mook Kang*

Main category: eess.SY

TL;DR: MAPS是一种新颖的自适应控制框架，用于解决具有可变摩擦的直流电机系统。它结合了交互式多模型（IMM）估计器和线性参数变化（LPV）控制器，利用实时模式概率进行自适应增益调度。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效应对直流电机系统中不断变化的摩擦工况的自适应控制框架。

Method: 提出并实现了一种名为MAPS的框架，该框架集成了IMM估计器和LPV控制器。MAPS利用IMM估计器提供的实时模式概率作为插值权重，用于LPV控制器中的在线增益合成，从而将状态估计与自适应控制紧密结合。

Result: 与依赖预定义调度变量的LQR控制器相比，MAPS在硬件在环仿真（HILS）环境中显著提高了状态估计精度和参考跟踪性能。

Conclusion: MAPS为在不确定、时变环境中进行摩擦感知自适应控制提供了一种鲁棒且可泛化的解决方案，并具有实际的实时应用潜力。

Abstract: This paper proposes Mode-Aware Probabilistic Scheduling (MAPS), a novel
adaptive control framework tailored for DC motor systems experiencing varying
friction. MAPS uniquely integrates an Interacting Multiple Model (IMM)
estimator with a Linear Parameter-Varying (LPV) based control strategy,
leveraging real-time mode probability estimates to perform probabilistic gain
scheduling. A key innovation of MAPS lies in directly using the updated mode
probabilities as the interpolation weights for online gain synthesis in the LPV
controller, thereby tightly coupling state estimation with adaptive control.
This seamless integration enables the controller to dynamically adapt control
gains in real time, effectively responding to changes in frictional operating
modes without requiring explicit friction model identification. Validation on a
Hardware-in-the-Loop Simulation (HILS) environment demonstrates that MAPS
significantly enhances both state estimation accuracy and reference tracking
performance compared to Linear Quadratic Regulator (LQR) controllers relying on
predefined scheduling variables. These results establish MAPS as a robust,
generalizable solution for friction-aware adaptive control in uncertain,
time-varying environments, with practical real-time applicability.

</details>


### [212] [Towards Native AI in 6G Standardization: The Roadmap of Semantic Communication](https://arxiv.org/abs/2509.12758)
*Ping Zhang,Xiaodong Xu,Mengying Sun,Haixiao Gao,Nan Ma,Xiaoyun Wang,Ruichen Zhang,Jiacheng Wang,Dusit Niyato*

Main category: eess.SY

TL;DR: 语义通信（SemCom）是6G网络的基础，旨在实现面向任务、感知含义的传输，并已获得IEEE和ITU等标准化组织的认可，正在3GPP中进行讨论。本文全面概述了SemCom的最新进展，重点关注标准化活动，涵盖了应用场景、架构设计、系统兼容性、评估指标和验证方法。此外，本文还介绍了JSCC、MDMA和语义知识库等关键技术，并通过CSI反馈案例研究展示了SemCom在3GPP信道下的性能提升。最后，文章讨论了SemCom在6G标准化中的挑战、机遇以及未来发展前景。


<details>
  <summary>Details</summary>
Motivation: 本文旨在全面概述语义通信（SemCom）在6G网络中的最新进展，重点关注其标准化活动、关键技术、应用场景以及面临的挑战与机遇。

Method: 本文系统地考察了SemCom在应用场景、架构设计、系统兼容性、评估指标和验证方法方面的进展，并重点介绍了几种关键的支撑技术，如JSCC、MDMA和语义知识库。此外，还通过一个CSI反馈的案例研究来具体说明SemCom的性能增益。

Result: SemCom在6G网络中展现出巨大潜力，并在学术界和工业界取得了显著进展。JSCC、MDMA和语义知识库等技术为其实现提供了支持。CSI反馈案例研究表明，SemCom在3GPP标准信道下具有显著的性能优势。

Conclusion: SemCom是未来6G网络的关键技术，已在标准化方面取得重要进展。尽管面临一些挑战，但其在6G标准化和全球应用方面具有广阔前景，需要进一步的研究和发展。

Abstract: Semantic communication (SemCom) has emerged as a transformative paradigm for
future 6G networks, offering task-oriented and meaning-aware transmission that
fundamentally redefines traditional bit-centric design. Recognized by leading
standardization bodies including the institute of electrical and electronics
engineers (IEEE) and the international telecommunication union (ITU), and
actively discussed within the 3rd generation partnership project (3GPP) working
groups, SemCom is rapidly gaining traction as a foundational enabler for
native-AI 6G. This paper presents a comprehensive overview of recent progress
in SemCom from both academic and industrial perspectives, with a focus on its
ongoing and upcoming standardization activities. We systematically examine
advances in representative application scenarios, architectural design,
semantic-traditional system compatibility, unified evaluation metrics, and
validation methodologies. Furthermore, we highlight several key enabling
technologies, such as joint source-channel coding (JSCC), SemCom-based multiple
access (MA) technologies such as model division MA (MDMA), and semantic
knowledge base (KB), that support the practical implementation of SemCom in
standard-compliant systems. Additionally, we present a case study for channel
state information (CSI) feedback, illustrating the concrete performance gains
of SemCom under 3GPP-compliant fading channels. Finally, we discuss emerging
challenges and research opportunities for incorporating semantic-native
mechanisms into the evolving 6G standardization landscape, and provide
forward-looking insights into its development and global adoption.

</details>


### [213] [Ellipsoidal partitions for improved multi-stage robust model predictive control](https://arxiv.org/abs/2509.12792)
*Moritz Heinlein,Florian Messerer,Moritz Diehl,Sergio Lucia*

Main category: eess.SY

TL;DR: 本研究提出了一种结合了椭球管和场景树的预测控制方法，以提高控制的灵活性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决传统基于椭球管的预测控制方法在反馈结构上的局限性，并克服基于场景的方法在保证严格约束方面的挑战。

Method: 提出了一种椭球多阶段方法，通过用半空间划分不确定椭球，使得每个划分后的集合可以独立控制，并将其应用于人机协作系统。

Result: 该方法在人机协作系统中得到了验证，证明了其在处理不确定性方面的优势，同时保持了计算上的可行性。

Conclusion: 本研究成功地将椭球管和场景树的优点结合起来，提出了一种更灵活、更鲁棒的预测控制方法。

Abstract: Ellipsoidal tube-based model predictive control methods effectively account
for the propagation of the reachable set, typically employing linear feedback
policies. In contrast, scenario-based approaches offer more flexibility in the
feedback structure by considering different control actions for different
branches of a scenario tree. However, they face challenges in ensuring rigorous
guarantees. This work aims to integrate the strengths of both methodologies by
enhancing ellipsoidal tube-based MPC with a scenario tree formulation. The
uncertainty ellipsoids are partitioned by halfspaces such that each partitioned
set can be controlled independently. The proposed ellipsoidal multi-stage
approach is demonstrated in a human-robot system, highlighting its advantages
in handling uncertainty while maintaining computational tractability.

</details>


### [214] [Spatial Correlation and Degrees of Freedom in Arched HMIMO Arrays: A Closed-Form Analysis](https://arxiv.org/abs/2509.12839)
*Liuxun Xue,Shu Sun,Hangsong Yan*

Main category: eess.SY

TL;DR: 本文对拱形全息多输入多输出（HMIMO）阵列的空间相关性和自由度（DoF）进行了封闭形式的分析，这种阵列是流体天线系统（FAS）的一种特殊形式。研究推导了拱形均匀线性阵列和拱形均匀矩形阵列的精确相关性表达式，并考虑了曲率的影响。结果表明，在各向同性散射下，DoF主要由HMIMO阵列的最大跨度决定，形状效应减弱，弯曲不会显著降低空间DoF。数值模拟验证了封闭形式公式的准确性，并证明了DoF对曲率变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究具有曲面特性的HMIMO阵列的空间相关性和自由度，因为实际的HMIMO阵列表面可能存在曲率，这会影响其空间特性和性能。

Method: 推导出拱形均匀线性阵列和拱形均匀矩形阵列在远场传播下的精确相关性表达式，并分析曲率对自由度的影响。

Result: 在各向同性散射下，自由度（DoF）主要由HMIMO阵列的最大跨度决定，形状效应减弱，弯曲不会显著降低空间DoF。数值模拟验证了封闭形式公式的准确性和DoF对曲率变化的鲁棒性。

Conclusion: 研究结果为下一代HMIMO/FAS系统的几何感知优化提供了基本见解，并为实际实现弯曲HMIMO阵列铺平了道路。

Abstract: This paper presents a closed-form analysis of spatial correlation and degrees
of freedom (DoF) for arched holographic multiple-input multiple-output (HMIMO)
arrays, which can be viewed as a special form of fluid antenna systems (FAS)
when their geometry is fluidically adaptable. Unlike traditional planar
configurations, practical HMIMO surfaces may exhibit curvature, significantly
influencing their spatial characteristics and performance. We derive exact
correlation expressions for both arched uniform linear arrays and arched
uniform rectangular arrays, capturing curvature effects under far field
propagation. Our results reveal that isotropic scattering results in DoF being
dominated by the maximum span of the HMIMO array, such that shape effects are
weakened, and bending does not significantly reduce the available spatial DoF.
Numerical simulations validate the accuracy of the closed-form formulas and
demonstrate the robustness of DoF against curvature variations, supporting
flexible array designs. These findings offer fundamental insights into
geometry-aware optimization for next-generation HMIMO/FAS systems and pave the
way for practical implementations of curved HMIMO arrays.

</details>


### [215] [Topology and Fragility of European High-Voltage Networks: A Cross-Country Comparative Analysis](https://arxiv.org/abs/2509.12900)
*Bálint Hartmann,Michelle T. Cirunay*

Main category: eess.SY

TL;DR: 欧洲15国高压电网拓扑结构存在显著差异，节点度分布呈指数衰减，衰减速率是衡量电网韧性的关键指标。


<details>
  <summary>Details</summary>
Motivation: 研究高压电网结构多样性对系统脆弱性的影响，并进行跨国比较。

Method: 对15个欧洲国家的110 kV及以上高压电网进行拓扑建模和分析，评估网络对节点和边缘移除的容忍度。

Result: 节点度分布普遍呈指数衰减，但衰减速率因国家而异。衰减速率的快慢与电网的韧性相关，能区分易受大范围破坏的系统和更具韧性的系统。模型包含的基础设施层级会影响该边界的敏感性。

Conclusion: 本研究首次对15个欧洲国家的高压电网进行量化比较，将拓扑特性与脆弱性特征联系起来，揭示了电网结构对可靠供电的重要性。

Abstract: Reliable electricity supply depends on the seamless operation of high-voltage
grid infrastructure spanning both transmission and sub-transmission levels.
Beneath this apparent uniformity lies a striking structural diversity, which
leaves a clear imprint on system vulnerability. In this paper, we present
harmonized topological models of the high-voltage grids of 15 European
countries, integrating all elements at voltage levels above 110 kV. Topological
analysis of these networks reveals a simple yet robust pattern: node degree
distributions consistently follow an exponential decay, but the rate of decay
varies significantly across countries. Through a detailed and systematic
evaluation of network tolerance to node and edge removals, we show that the
decay rate delineates the boundary between systems that are more resilient to
failures and those that are prone to large-scale disruptions. Furthermore, we
demonstrate that this numerical boundary is highly sensitive to which layers of
the infrastructure are included in the models. To our knowledge, this study
provides the first quantitative cross-country comparison of 15 European
high-voltage networks, linking topological properties with vulnerability
characteristics.

</details>


### [216] [Grid-informed Sharing Coefficients in Renewable Energy Communities](https://arxiv.org/abs/2509.12847)
*Alireza Shooshtari,Antonio Pepiciello,José Luis Domínguez-García*

Main category: eess.SY

TL;DR: 能源社区的电网运行作用取决于其参与者的空间分布。本研究提出了一种馈线感知的分配策略，该策略优先考虑同一馈线内的能源共享，以改善电网运行和参与者的收入。


<details>
  <summary>Details</summary>
Motivation: 能源社区的经济激励措施可能会影响局部电网拥堵，因为当地的能源生产者和消费者可能分布在不同的馈线上。

Method: 提出了一种馈线感知的分配策略，该策略在能源共享中反映了电网拓扑。对不同馈线上的参与者进行了静态和动态的能源共享测试，并使用了三种不同的共享系数：相等、比例和基于排名。

Result: 在实际能源社区的数据上对该策略进行了测试。结果表明，馈线感知策略能够促进当地能源平衡，并为大多数参与者带来更高、更稳定的收入。

Conclusion: 馈线感知的分配策略可以有效改善能源社区的电网运行和参与者的经济效益。

Abstract: The role of energy communities in grid operations is highly dependent on the
spatial distribution of their participants. In particular, when local energy
producers and consumers are concentrated in different feeders, economic
incentives from energy communities have the potential to affect local grid
congestion. To address this challenge, we propose a feeder-aware allocation
strategy that reflects grid topology in energy sharing. This strategy
prioritizes energy sharing within the same feeder, thus incentivizing local
generation-demand balance and improving grid operation. Different sharing
coefficients are tested, such as equal, proportional, and rank-based, in both
static and dynamic formulations. The proposed strategy is tested on data from a
real energy community, whose participants are assumed to be distributed across
four feeders. The analysis is carried out from the perspectives of the
community as a whole, individual feeders, and single participants. Simulation
results show that the feeder-aware strategy, in addition to promoting local
energy balance, leads to higher and more stable revenues for most participants.

</details>


### [217] [Momentum-Based Access and Speed Control for Improved Safety in Heterogeneous Road Networks](https://arxiv.org/abs/2509.12944)
*Felix Wieberneit,Emanuele Crisostomi,Wynita Griggs,Robert Shorten*

Main category: eess.SY

TL;DR: 该研究提出了一种双层控制算法，通过减少网络异质性和控制车速来提高道路交通安全，并使用SUMO模拟器进行了验证。


<details>
  <summary>Details</summary>
Motivation: 由于轻型车辆（如电动滑板车、电动自行车）以及传统车辆（如电动汽车、SUV）重量的增加，道路交通安全问题日益严重。

Method: 设计了一个两级控制算法：1. 接入控制策略，根据实际交通状况降低网络异质性；2. 速度控制策略，降低潜在碰撞中严重伤害的概率。两种策略均基于动量原理设计。

Result: 使用SUMO模拟器实现并验证了所提出的控制策略。

Conclusion: 基于动量的方法被认为是评估伤害风险的最有影响力的变量，所提出的控制策略能够有效提高道路交通安全。

Abstract: The increasing variety of means of transportation, including light vehicles
like e-scooters and e-bikes, together with the increasing weight of
conventional vehicles due to electrification and consumer preferences for SUVs,
are raising serious concerns regarding the safety of road networks. In this
paper we design a two-level control algorithm to improve the safety of
heterogeneous networks: first, an access control strategy decreases the
heterogeneity of the network depending on actual traffic conditions; then, a
speed control strategy mitigates the probability of serious injuries in
potential collisions. Both control strategies are designed based on momentum
considerations, as this is regarded as the most influential variable to assess
injury risk. The road network mobility simulator SUMO is adopted to implement
and validate our proposed control strategies.

</details>


### [218] [Concentration inequalities for semidefinite least squares based on data](https://arxiv.org/abs/2509.13166)
*Filippo Fabiani,Andrea Simonetto*

Main category: eess.SY

TL;DR: 该研究提出了数据驱动的最小二乘（LS）问题，并带有半定（SD）约束。研究人员推导了当这些约束被放宽时，其最优解谱的有限样本保证。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为数据驱动的最小二乘问题提供一种更简单的求解方法，同时保证解的谱接近于带有半定约束时的最优解。

Method: 研究方法是开发一种可以放宽半定约束的计算方法，并提供有限样本保证，确保放宽约束后的解的特征值接近于原始问题的最优解。

Result: 研究结果是提出了一种易于计算、无分布且只需要独立同分布样本的证书，该证书可以保证在放宽半定约束后得到的解的特征值与原始问题的解的特征值相近。当半定最小二乘用于学习未知二次函数时，还建立了梯度下降迭代与真实最小化器之间的误差界限。

Conclusion: 研究结论是，提出的方法可以有效地简化半定约束的最小二乘问题，同时在统计上保证了解的质量，并且在学习二次函数方面具有理论保证。

Abstract: We study data-driven least squares (LS) problems with semidefinite (SD)
constraints and derive finite-sample guarantees on the spectrum of their
optimal solutions when these constraints are relaxed. In particular, we provide
a high confidence bound allowing one to solve a simpler program in place of the
full SDLS problem, while ensuring that the eigenvalues of the resulting
solution are $\varepsilon$-close of those enforced by the SD constraints. The
developed certificate, which consistently shrinks as the number of data
increases, turns out to be easy-to-compute, distribution-free, and only
requires independent and identically distributed samples. Moreover, when the
SDLS is used to learn an unknown quadratic function, we establish bounds on the
error between a gradient descent iterate minimizing the surrogate cost obtained
with no SD constraints and the true minimizer.

</details>


### [219] [Safety Critical Model Predictive Control Using Discrete-Time Control Density Functions](https://arxiv.org/abs/2509.13257)
*Sriram S. K. S. Narayanan,Sajad Ahmadi,Javad Mohammadpour Velni,Umesh Vaidya*

Main category: eess.SY

TL;DR: 该研究提出了一种名为MPC-CDF的新方法，将控制密度函数（CDFs）集成到模型预测控制（MPC）框架中，以确保非线性动力学系统中的安全关键控制。


<details>
  <summary>Details</summary>
Motivation: 为了在离散时间设置中同时确保收敛性和安全性，并为系统轨迹的占据提供物理解释。

Method: 通过使用导航问题的对偶形式，将CDFs整合到MPC框架中，并利用基于占用率的视角来合成安全关键控制器。

Result: 使用独轮车模型说明了该框架的安全属性，并将其与基于控制屏障函数的方法进行了比较，证明了其在水下航行器自主安全导航中的有效性，能够避开复杂障碍物并达到所需的安全水平。

Conclusion: MPC-CDF框架能够为非线性动力学系统提供安全关键控制，并在自主导航任务中得到有效验证。

Abstract: This paper presents MPC-CDF, a new approach integrating control density
functions (CDFs) within a model predictive control (MPC) framework to ensure
safety-critical control in nonlinear dynamical systems. By using the dual
formulation of the navigation problem, we incorporate CDFs into the MPC
framework, ensuring both convergence and safety in a discrete-time setting.
These density functions are endowed with a physical interpretation, where the
associated measure signifies the occupancy of system trajectories. Leveraging
this occupancy-based perspective, we synthesize safety-critical controllers
using the proposed MPC-CDF framework. We illustrate the safety properties of
this framework using a unicycle model and compare it with a control barrier
function-based method. The efficacy of this approach is demonstrated in the
autonomous safe navigation of an underwater vehicle, which avoids complex and
arbitrary obstacles while achieving the desired level of safety.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [220] [Graph Coloring Below Guarantees via Co-Triangle Packing](https://arxiv.org/abs/2509.12347)
*Shyan Akmal,Tomohiro Koana*

Main category: cs.DS

TL;DR: 该论文研究了低于保证的图着色问题，即确定一个n个顶点的图是否可以使用g-k种颜色进行proper coloring，其中g是n这样的平凡上界。研究者提出了一种基于共三角形（大小为3的独立集）打包的算法框架，并给出了低于保证的图着色问题的$O^*(2^{3k/2})$和$O^*(2^{6k})$时间复杂度的算法，同时证明了$(\omega-k)$-Coloring和$(\overline{\mu}-k)$-Coloring的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究低于保证的图着色问题，特别是$g-k$着色问题，旨在为图着色问题提供更精细的参数化复杂性分析，并改进已知算法的效率。

Method: 该论文提出了一种基于共三角形（大小为3的独立集）打包的算法框架。该框架首先尝试贪婪地寻找共三角形，若找到很多则直接判定为YES；否则，这些共三角形构成一个小的共三角形调节子，删除后图变为共三角形自由图。在此基础上，通过扩展[Gutin et al., SIDMA 2021]的研究，将问题转化为求解给定$\\(overline{K_3}\\$自由调节子的图的着色问题，并给出了$O^*(2^k)$的随机化时间复杂度。进一步地，该算法被应用于$(n-k)$-Coloring（也称为Dual Coloring），得到了$O^*(2^{3k/2})$的随机化算法。最后，研究者引入了$(\\omega+\\overline{\\mu}-k)$-Coloring参数化，并基于共三角形打包论证得到了$O^*(2^{6k})$的随机化算法，证明了其在更小的参数下的固定参数可解性。

Result: 1. 实现了对给定$\\(overline{K_3}\\$自由调节子大小为$k$的图的$\\\ell(\\text{for any }\\ell)$着色问题的随机化$O^*(2^k)$时间算法。
2. 针对$(n-k)$-Coloring（Dual Coloring）问题，提出了随机化$O^*(2^{3k/2})$算法，优于先前$O^*(4^k)$的界限。
3. 提出了$(\\omega+\\overline{\\mu}-k)$-Coloring参数化，并给出了随机化$O^*(2^{6k})$算法，证明了其固定参数可解性。
4. 证明了在标准复杂性假设下，$(\\omega-k)$-Coloring和$(\\overline{\\mu}-k)$-Coloring不存在固定参数可解性算法。

Conclusion: 该研究成功地将图着色问题的参数化复杂性研究扩展到了低于保证的情况，并利用共三角形打包的技巧，为$(n-k)$-Coloring和$(\\omega+\\overline{\\mu}-k)$-Coloring问题设计了更优的随机化算法。同时，通过对$(\\omega-k)$-Coloring和$(\\overline{\\mu}-k)$-Coloring的计算复杂度分析，揭示了这些问题的计算难度。

Abstract: In the $\ell$-Coloring Problem, we are given a graph on $n$ nodes, and tasked
with determining if its vertices can be properly colored using $\ell$ colors.
In this paper we study below-guarantee graph coloring, which tests whether an
$n$-vertex graph can be properly colored using $g-k$ colors, where $g$ is a
trivial upper bound such as $n$. We introduce an algorithmic framework that
builds on a packing of co-triangles $\overline{K_3}$ (independent sets of three
vertices): the algorithm greedily finds co-triangles and employs a win-win
analysis. If many are found, we immediately return YES; otherwise these
co-triangles form a small co-triangle modulator, whose deletion makes the graph
co-triangle-free.
  Extending the work of [Gutin et al., SIDMA 2021], who solved $\ell$-Coloring
(for any $\ell$) in randomized $O^*(2^{k})$ time when given a
$\overline{K_2}$-free modulator of size $k$, we show that this problem can
likewise be solved in randomized $O^*(2^{k})$ time when given a
$\overline{K_3}$-free modulator of size~$k$.
  This result in turn yields a randomized $O^{*}(2^{3k/2})$ algorithm for
$(n-k)$-Coloring (also known as Dual Coloring), improving the previous
$O^{*}(4^{k})$ bound. We then introduce a smaller parameterization,
$(\omega+\overline{\mu}-k)$-Coloring, where $\omega$ is the clique number and
$\overline{\mu}$ is the size of a maximum matching in the complement graph;
since $\omega+\overline{\mu}\le n$ for any graph, this problem is strictly
harder. Using the same co-triangle-packing argument, we obtain a randomized
$O^{*}(2^{6k})$ algorithm, establishing its fixed-parameter tractability for a
smaller parameter. Complementing this finding, we show that no fixed-parameter
tractable algorithm exists for $(\omega-k)$-Coloring or
$(\overline{\mu}-k)$-Coloring under standard complexity assumptions.

</details>


### [221] [Sublinear-Time Algorithms for Diagonally Dominant Systems and Applications to the Friedkin-Johnsen Model](https://arxiv.org/abs/2509.13112)
*Weiming Feng,Zelin Li,Pan Peng*

Main category: cs.DS

TL;DR: 本研究提出了一种用于求解线性方程组Sz=b的亚线性时间算法，其中S是对角占优矩阵。该算法能够以加性误差ε或ε||z*||∞估计解z*的任意分量zu，同时仅读取S和b的一小部分。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发能够处理一般对角占优矩阵（包括非严格对角占优）的亚线性时间算法，并改进现有算法在特定模型下的效率。

Method: 研究方法基于分析解所满足的概率递推关系，并设计了相应的随机化算法。

Result: 研究提出了一个亚线性时间算法，其运行时间与输入矩阵S和向量b的大小无关，仅与精度要求ε、矩阵的对角线元素界S_max以及对角劣度δ相关。同时，证明了运行时间中S_max的线性依赖性是不可避免的最优下界。

Conclusion: 研究成功开发出一种适用于一般对角占优矩阵的亚线性时间算法，并证明了其在某些方面的最优性。该算法在意见估计等应用中也取得了改进。

Abstract: We study sublinear-time algorithms for solving linear systems $Sz = b$, where
$S$ is a diagonally dominant matrix, i.e., $|S_{ii}| \geq \delta + \sum_{j \ne
i} |S_{ij}|$ for all $i \in [n]$, for some $\delta \geq 0$. We present
randomized algorithms that, for any $u \in [n]$, return an estimate $z_u$ of
$z^*_u$ with additive error $\varepsilon$ or $\varepsilon \lVert
z^*\rVert_\infty$, where $z^*$ is some solution to $Sz^* = b$, and the
algorithm only needs to read a small portion of the input $S$ and $b$. For
example, when the additive error is $\varepsilon$ and assuming $\delta>0$, we
give an algorithm that runs in time $O\left( \frac{\|b\|_\infty^2
S_{\max}}{\delta^3 \varepsilon^2} \log \frac{\| b \|_\infty}{\delta
\varepsilon} \right)$, where $S_{\max} = \max_{i \in [n]} |S_{ii}|$. We also
prove a matching lower bound, showing that the linear dependence on $S_{\max}$
is optimal. Unlike previous sublinear-time algorithms, which apply only to
symmetric diagonally dominant matrices with non-negative diagonal entries, our
algorithm works for general strictly diagonally dominant matrices ($\delta >
0$) and a broader class of non-strictly diagonally dominant matrices $(\delta =
0)$. Our approach is based on analyzing a simple probabilistic recurrence
satisfied by the solution. As an application, we obtain an improved
sublinear-time algorithm for opinion estimation in the Friedkin--Johnsen model.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [222] [Accurate Trust Evaluation for Effective Operation of Social IoT Systems via Hypergraph-Enabled Self-Supervised Contrastive Learning](https://arxiv.org/abs/2509.12240)
*Botao Zhu,Xianbin Wang*

Main category: cs.SI

TL;DR: 提出了一种新的超图感知的自监督对比学习（HSCL）方法，用于在社交物联网中计算设备信任度。


<details>
  <summary>Details</summary>
Motivation: 社交物联网通过赋予设备社交属性来增强设备间的协作，但基于复杂动态社交属性计算设备间信任度是一个重大挑战。

Method: 提出HSCL方法，首先使用超图发现和表示高阶关系，然后进行超图增强以丰富语义，接着使用参数共享超图神经网络融合高阶社交关系，最后利用自监督对比学习方法通过设备、超边和设备到超边关系进行比较，获得有意义的设备嵌入，并基于这些嵌入计算信任度。

Result: HSCL方法在区分可信和不可信节点以及识别最可信节点方面优于基线算法。

Conclusion: HSCL方法能够有效计算社交物联网中设备间的信任度。

Abstract: Social Internet-of-Things (IoT) enhances collaboration between devices by
endowing IoT systems with social attributes. However, calculating trust between
devices based on complex and dynamic social attributes-similar to trust
formation mechanisms in human society-poses a significant challenge. To address
this issue, this paper presents a new hypergraph-enabled self-supervised
contrastive learning (HSCL) method to accurately determine trust values between
devices. To implement the proposed HSCL, hypergraphs are first used to discover
and represent high-order relationships based on social attributes. Hypergraph
augmentation is then applied to enhance the semantics of the generated social
hypergraph, followed by the use of a parameter-sharing hypergraph neural
network to nonlinearly fuse the high-order social relationships. Additionally,
a self-supervised contrastive learning method is utilized to obtain meaningful
device embeddings by conducting comparisons among devices, hyperedges, and
device-to-hyperedge relationships. Finally, trust values between devices are
calculated based on device embeddings that encapsulate high-order social
relationships. Extensive experiments reveal that the proposed HSCL method
outperforms baseline algorithms in effectively distinguishing between trusted
and untrusted nodes and identifying the most trusted node.

</details>


### [223] [Digital Voices of Survival: From Social Media Disclosures to Support Provisions for Domestic Violence Victims](https://arxiv.org/abs/2509.12288)
*Kanlun Wang,Zhe Fu,Wangjiaxuan Xin,Lina Zhou,Shashi Kiran Chandrappa*

Main category: cs.SI

TL;DR: 本研究提出了一种新的计算框架，用于分析社交媒体上家庭暴力受害者自我披露和寻求支持的行为，以促进以受害者为中心的数字干预。


<details>
  <summary>Details</summary>
Motivation: 现有研究对家庭暴力（DV）的自我披露、支持机制及其相互作用缺乏全面和细致的理解，而社交媒体已成为DV受害者披露经历的重要渠道。

Method: 研究提出了一个包含自我披露检测、帖子聚类、主题摘要以及支持提取和映射四个组成部分的计算框架，并使用从社交媒体社区收集的数据进行实现和评估。

Result: 研究结果不仅加深了对家庭暴力自我披露和在线支持机制的认识，而且为开发以受害者为中心的数字干预措施提供了支持。

Conclusion: 本研究提出的计算框架为理解和应对社交媒体上的家庭暴力问题提供了新的见解和工具。

Abstract: Domestic Violence (DV) is a pervasive public health problem characterized by
patterns of coercive and abusive behavior within intimate relationships. With
the rise of social media as a key outlet for DV victims to disclose their
experiences, online self-disclosure has emerged as a critical yet underexplored
avenue for support-seeking. In addition, existing research lacks a
comprehensive and nuanced understanding of DV self-disclosure, support
provisions, and their connections. To address these gaps, this study proposes a
novel computational framework for modeling DV support-seeking behavior
alongside community support mechanisms. The framework consists of four key
components: self-disclosure detection, post clustering, topic summarization,
and support extraction and mapping. We implement and evaluate the framework
with data collected from relevant social media communities. Our findings not
only advance existing knowledge on DV self-disclosure and online support
provisions but also enable victim-centered digital interventions.

</details>


### [224] [Structured Information Loss in Network Embeddings](https://arxiv.org/abs/2509.12396)
*Gabriel Chuang,Augustin Chaintreau*

Main category: cs.SI

TL;DR: 网络嵌入算法的表示能力和局限性分析。


<details>
  <summary>Details</summary>
Motivation: 分析网络嵌入算法学习到的表示是否能完全、部分或不编码图的生成模型，并探讨在嵌入丢失信息的情况下，哪些图论等价类映射到相同的嵌入，以及这些嵌入对社群检测和链接预测的影响。

Method: 对网络嵌入算法进行显式分析，表征其编码图生成模型的条件，描述映射到相同嵌入的图论等价类，并推导其对社群检测和链接预测的启示。

Result: 学习到的表示可能丢失部分信息（不可逆），映射到相同嵌入的图论等价类保留了社群结构但丢失了密度信息。对仅基于嵌入的链接预测的有效性提出了强烈限制，并揭示了朴素链接预测可能加剧或缓解结构偏差的常见条件。

Conclusion: 网络嵌入算法的学习表示能力有限，仅基于嵌入的链接预测效果受限，朴素链接预测需谨慎使用，以避免结构偏差的加剧或缓解。

Abstract: We analyze a simple algorithm for network embedding, explicitly
characterizing conditions under which the learned representation encodes the
graph's generative model fully, partially, or not at all. In cases where the
embedding loses some information (i.e., is not invertible), we describe the
equivalence classes of graphons that map to the same embedding, finding that
these classes preserve community structure but lose substantial density
information. Finally, we show implications for community detection and link
prediction. Our results suggest strong limitations on the effectiveness of link
prediction based on embeddings alone, and we show common conditions under which
naive link prediction adds edges in a disproportionate manner that can either
mitigate or exacerbate structural biases.

</details>


### [225] [Privacy-Driven Network Data for Smart Cities](https://arxiv.org/abs/2509.12403)
*Tânia Carvalho,José Barata,Henish Balu,Filipa Moreira,João Bastos,Luís Antunes*

Main category: cs.SI

TL;DR: 该研究提出了一种在智慧城市中安全共享Wi-Fi网络数据的实用方法，以提升Wi-Fi网络质量，同时整合法律考量，促进数据驱动的创新和隐私意识。


<details>
  <summary>Details</summary>
Motivation: 智慧城市对可持续城市发展至关重要，其中网络数据（尤其是公共Wi-Fi数据）在优化公共交通和大型活动安全效率等方面发挥着关键作用。然而，数据安全和隐私是智慧城市发展的最大担忧之一，特别是Wi-Fi网络可能收集敏感信息。现有研究主要关注移动模式安全（如MAC地址保护），而忽略了保护Wi-Fi网络数据的所有属性。

Method: 提出了一种实用的方法来保护Wi-Fi网络数据的所有属性，并整合了法律考量，以实现安全的数据共享。该研究与法律专家、数据管理人和隐私技术专家合作进行，并在实际场景中进行了测试。

Result: 开发了一种保护智慧城市Wi-Fi网络数据所有属性的实用方法，并成功整合了法律考量，在实际场景中进行了测试，表明其能够促进数据驱动的创新和隐私意识。

Conclusion: 该研究提供了一种在智慧城市背景下安全共享Wi-Fi网络数据的实用方法，该方法不仅保护了所有数据属性，还整合了法律考量，这对于在保护公民隐私的同时利用数据推动城市创新至关重要。

Abstract: A smart city is essential for sustainable urban development. In addition to
citizen engagement, a smart city enables connected infrastructure, data-driven
decision making and smart mobility. For most of these features, network data
plays a critical role, particularly from public Wi-Fi infrastructures, where
cities can benefit from optimized services such as public transport management
and the safety and efficiency of large events. One of the biggest concerns in
developing a smart city is using secure and private data. This is particularly
relevant in the case of Wi-Fi network data, where sensitive information can be
collected. This paper specifically addresses the problem of sharing secure data
to enhance the quality of the Wi-Fi network in a city. Despite the high
importance of this type of data, related work focuses on improving the safety
of mobility patterns, targeting only the protection of MAC addresses. On the
opposite side, we provide a practical methodology for safeguarding all
attributes in real Wi-Fi network data. This study was developed in
collaboration with a multidisciplinary team of legal experts, data custodians
and technical privacy specialists, resulting in high-quality data. On top of
that, we show how to integrate the legal considerations for secure data
sharing. Our approach promotes data-driven innovation and privacy awareness in
the context of smart city initiatives, which have been tested in a real
scenario.

</details>


### [226] [Ketto and the Science of Giving: A Data-Driven Investigation of Crowdfunding for India](https://arxiv.org/abs/2509.12616)
*Karuna Chandra,Akshay Menon,Lydia Manikonda,Ponnurangam Kumaraguru*

Main category: cs.SI

TL;DR: 该研究调查了印度的众筹平台Ketto，重点关注医疗众筹活动。研究结果显示，尽管医疗众筹活动数量最多，但其成功率最低。在线参与度、众筹活动持续时间和更新频率等因素对筹款金额有积极影响。


<details>
  <summary>Details</summary>
Motivation: 在印度，Ketto平台的使用日益增长，但用户选择该平台的原因仍不清楚，尤其是在存在GoFundMe等其他流行平台的情况下。本研究旨在填补这一认知空白。

Method: 利用包含119,493个Ketto众筹活动的数据库，重点分析了医疗众筹活动。研究使用了众筹活动元数据、描述、地理位置、捐助者行为和活动相关特征等多种因素，并进行了预测建模，以识别影响众筹活动成功的因素。

Result: 大多数医疗众筹活动旨在解决慢性健康问题，但其成功率最低。大部分众筹活动来自印度人口最多和主要大都市。在线参与度（评论数量）、众筹活动持续时间和频繁更新会积极影响筹款金额。

Conclusion: 这项初步研究揭示了研究印度众筹平台Ketto各种动态的重要性，特别是对于社区驱动的需求。

Abstract: The main goal of this paper is to investigate an up and coming crowdfunding
platform used to raise funds for social causes in India called Ketto. Despite
the growing usage of this platform, there is insufficient understanding in
terms of why users choose this platform when there are other popular platforms
such as GoFundMe. Using a dataset comprising of 119,493 Ketto campaigns, our
research conducts an in-depth investigation into different aspects of how the
campaigns on Ketto work with a specific focus on medical campaigns, which make
up the largest percentage of social causes in the dataset. We also perform
predictive modeling to identify the factors that contribute to the success of
campaigns on this platform. We use several features such as the campaign
metadata, description, geolocation, donor behaviors, and campaign-related
features to learn about the platform and its components. Our results suggest
that majority of the campaigns for medical causes seek funds to address chronic
health conditions, yet medical campaigns have the least success rate. Most of
the campaigns originate from the most populous states and major metropolitan
cities in India. Our analysis also indicates that factors such as online
engagement on the platform in terms of the number of comments, duration of the
campaign, and frequent updates on a campaign positively influence the funds
being raised. Overall, this preliminary work sheds light on the importance of
investigating various dynamics around crowdfunding for India-focused
community-driven needs.

</details>


### [227] [A Pressure-Based Diffusion Model for Influence Maximization on Social Networks](https://arxiv.org/abs/2509.12822)
*Curt Stutsman,Eliot W. Robson,Abhishek K. Umrawal*

Main category: cs.SI

TL;DR: 本文提出了一种名为压力阈值模型（PT）的新型扩散模型，用于模拟社交网络中的影响传播，并解决了影响最大化问题。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，个体的本地社交网络对其形成的观点有显著影响，并会传播给他人。

Method: PT模型扩展了线性阈值模型（LT），通过根据节点从其激活的邻居接收到的影响来调整节点的传出影响。研究了PT模型下的影响最大化问题。

Result: 在真实网络上的实验表明，PT模型与LT模型相比，具有独特的种子节点选择方式。密集连接的网络比稀疏连接的网络更能放大压力效应。

Conclusion: PT模型为模拟社交网络中的影响传播提供了一种新方法，并揭示了网络结构对影响传播的独特影响。

Abstract: In many real-world scenarios, an individual's local social network carries
significant influence over the opinions they form and subsequently propagate to
others. In this paper, we propose a novel diffusion model -- the Pressure
Threshold model (PT) -- for dynamically simulating the spread of influence
through a social network. This new model extends the popular Linear Threshold
Model (LT) by adjusting a node's outgoing influence proportional to the
influence it receives from its activated neighbors. We address the Influence
Maximization (IM) problem, which involves selecting the most effective seed
nodes to achieve maximal graph coverage after a diffusion process, and how the
problem manifests with the PT Model. Experiments conducted on real-world
networks, facilitated by enhancements to the open-source network-diffusion
Python library, CyNetDiff, demonstrate unique seed node selection for the PT
Model when compared to the LT Model. Moreover, analyses demonstrate that
densely connected networks amplify pressure effects more significantly than
sparse networks.

</details>


### [228] [Podcasts as a Medium for Participation in Collective Action: A Case Study of Black Lives Matter](https://arxiv.org/abs/2509.13197)
*Theodora Moldovan,Arianna Pera,Davide Vega,Luca Maria Aiello*

Main category: cs.SI

TL;DR: 本研究利用SPoRC语料库的播客 transcripts，通过分析“问题-解决方案”、“行动呼吁”、“意向”和“执行”等参与性陈述，研究了在“黑人的命也是命”（BLM）运动的背景下，播客讨论中集体行动的表达方式，并考察了这些陈述的情感维度，发现情感特征随行动阶段而变化，并且集体行动与负面情绪之间存在负相关。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨播客讨论中集体行动的表达方式，并分析情感因素在其中可能扮演的角色，以期填补当前集体行动话语研究主要集中在文本内容而忽视音频格式的空白。

Method: 本研究利用SPoRC语料库，选取了2020年5月和6月BLM相关事件后的播客节目，提取了陈述性参与的语句，并根据“问题-解决方案”、“行动呼吁”、“意向”和“执行”进行分类，同时分析了这些语句所蕴含的八种关键情绪及其与不同行动阶段的关系。

Result: 研究发现，播客讨论中集体行动的情感特征随行动阶段而变化，在“行动呼吁”、“意向”和“执行”阶段，积极情绪更为突出。此外，研究还检测到集体行动与负面情绪之间存在负相关，这与现有理论预期相悖。

Conclusion: 本研究通过分析播客 transcripts，加深了对数字口语话语中激进主义表达的理解，并揭示了情感框架可能如何受到讨论形式的影响，同时为集体行动话语的研究开辟了新的方向。

Abstract: We study how participation in collective action is articulated in podcast
discussions, using the Black Lives Matter (BLM) movement as a case study. While
research on collective action discourse has primarily focused on text-based
content, this study takes a first step toward analyzing audio formats by using
podcast transcripts. Using the Structured Podcast Research Corpus (SPoRC), we
investigated spoken language expressions of participation in collective action,
categorized as problem-solution, call-to-action, intention, and execution. We
identified podcast episodes discussing racial justice after important
BLM-related events in May and June of 2020, and extracted participatory
statements using a layered framework adapted from prior work on social media.
We examined the emotional dimensions of these statements, detecting eight key
emotions and their association with varying stages of activism. We found that
emotional profiles vary by stage, with different positive emotions standing out
during calls-to-action, intention, and execution. We detected negative
associations between collective action and negative emotions, contrary to
theoretical expectations. Our work contributes to a better understanding of how
activism is expressed in spoken digital discourse and how emotional framing may
depend on the format of the discussion.

</details>


### [229] [Extending the BEND Framework to Webgraphs](https://arxiv.org/abs/2509.13212)
*Evan M. Williams,Peter Carragher,Kathleen M. Carley*

Main category: cs.SI

TL;DR: 该研究提出了一种名为 BEND 的框架，并开发了一套量化指标来分析和表征操纵网络图（webgraph）信息环境的行为，特别是利用搜索引擎优化（SEO）策略的操纵行为。研究通过分析两个包含亲克里姆林宫网站的小型网络图，验证了这些指标的有效性，并证明了它们在改进 BEND 评分和表征网络图信息环境方面的实用性。


<details>
  <summary>Details</summary>
Motivation: 分析师缺乏量化指标来表征在网络图层面操纵信息环境的行为，以及这些行为对下游可能产生的广泛影响。

Method: 提出 BEND 框架，并为其开发了一套量化指标，用于表征网络图信息环境中的社区操纵行为。通过分析包含 SEO 推广的亲克里姆林宫网站的两个小型网络图来验证这些指标的有效性。

Result: 提出的 Webgraph BEND 指标具有表面效度，并且能够改进 BEND 评分，证明了其在表征网络图信息环境方面的实用性。

Conclusion: 提出的量化指标为分析师提供了一种系统化、标准化地表征利用常见 SEO 策略操纵网络图行为的方法。

Abstract: Attempts to manipulate webgraphs can have many downstream impacts, but
analysts lack shared quantitative metrics to characterize actions taken to
manipulate information environments at this level. We demonstrate how the BEND
framework can be used to characterize attempts to manipulate webgraph
information environments, and propose quantitative metrics for BEND community
maneuvers. We demonstrate the face validity of our proposed Webgraph BEND
metrics by using them to characterize two small web-graphs containing
SEO-boosted Kremlin-aligned websites. We demonstrate how our proposed metrics
improve BEND scores in webgraph settings and demonstrate the usefulness of our
metrics in characterizing webgraph information environments. These metrics
offer analysts a systematic and standardized way to characterize attempts to
manipulate webgraphs using common Search Engine Optimization tactics.

</details>


### [230] [Fast Unbiased Sampling of Networks with Given Expected Degrees and Strengths](https://arxiv.org/abs/2509.13230)
*Xuanchi Li,Xin Wang,Sadamori Kojaku*

Main category: cs.SI

TL;DR: 现有的 Chung-Lu 模型会过度抽取高连接度节点之间的边，导致统计结论不准确。我们提出了一种基于最大熵原理的快速采样算法，可以实现理论上严谨的配置模型，并在103个实际网络上进行了评估，速度提高了10-1000倍，使得更准确的网络结构分析成为可能。


<details>
  <summary>Details</summary>
Motivation: Chung-Lu 模型作为一种广泛使用的配置模型，存在过度抽取高连接度节点之间边的系统性偏差，导致不准确的统计推断。虽然最大熵原理提供了无偏的配置模型，但其高计算成本限制了其广泛应用，使得 Chung-Lu 模型成为一个不准确但仍然实用的选择。

Method: 提出一种通过改进 Miller-Hagberg 算法来实现基于最大熵原理的配置模型的快速、高效采样算法。

Result: 在103个经验网络上的评估显示，新的采样算法将基于最大熵原理的模型的速度提高了10到1000倍。

Conclusion: 通过提出一种快速高效的采样算法，使得理论上严谨的配置模型在实践中变得可行，从而能够更准确地理解网络结构。

Abstract: The configuration model is a cornerstone of statistical assessment of network
structure. While the Chung-Lu model is among the most widely used configuration
models, it systematically oversamples edges between large-degree nodes, leading
to inaccurate statistical conclusions. Although the maximum entropy principle
offers unbiased configuration models, its high computational cost has hindered
widespread adoption, making the Chung-Lu model an inaccurate yet persistently
practical choice. Here, we propose fast and efficient sampling algorithms for
the max-entropy-based models by adapting the Miller-Hagberg algorithm.
Evaluation on 103 empirical networks demonstrates 10-1000 times speedup, making
theoretically rigorous configuration models practical and contributing to a
more accurate understanding of network structure.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [231] [Temporally Smooth Mesh Extraction for Procedural Scenes with Long-Range Camera Trajectories using Spacetime Octrees](https://arxiv.org/abs/2509.13306)
*Zeyu Ma,Adam Finkelstein,Jia Deng*

Main category: cs.GR

TL;DR: 该方法提出了一种从程序化占位函数中提取网格以适应无限场景中长距离相机轨迹的新方法。


<details>
  <summary>Details</summary>
Motivation: 在程序化占位函数表示的无限场景中，为长距离相机轨迹提取网格时，传统的单网格方法会因网格过大而难以处理，而基于视角的网格提取方法则会出现弹出伪影。

Method: 提出了一种新的时空二叉树结构（binary-octree），并利用它进行4D网格提取，以生成时间上连贯的网格。

Result: 实验表明，与现有基线方法相比，该方法在视觉一致性方面表现更优，而成本相当。

Conclusion: 所提出的方法能够有效地从程序化占位函数中提取适用于长距离相机轨迹的网格，解决了无限场景中的网格提取难题。

Abstract: The procedural occupancy function is a flexible and compact representation
for creating 3D scenes. For rasterization and other tasks, it is often
necessary to extract a mesh that represents the shape. Unbounded scenes with
long-range camera trajectories, such as flying through a forest, pose a unique
challenge for mesh extraction. A single static mesh representing all the
geometric detail necessary for the full camera path can be prohibitively large.
Therefore, independent meshes can be extracted for different camera views, but
this approach may lead to popping artifacts during transitions. We propose a
temporally coherent method for extracting meshes suitable for long-range camera
trajectories in unbounded scenes represented by an occupancy function. The key
idea is to perform 4D mesh extraction using a new spacetime tree structure
called a binary-octree. Experiments show that, compared to existing baseline
methods, our method offers superior visual consistency at a comparable cost.
The code and the supplementary video for this paper are available at
https://github.com/princeton-vl/BinocMesher.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [232] [Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.12458)
*Àlmos Veres-Vitàlyos,Genis Castillo Gomez-Raya,Filip Lemic,Daniel Johannes Bugelnig,Bernhard Rinner,Sergi Abadal,Xavier Costa-Pérez*

Main category: cs.RO

TL;DR: 小型无人机（UAV）可以通过其新颖的双重建管线实现对静态对象的完全自主、高保真3D扫描，该管线通过动态调整飞行轨迹以实现对遮挡区域的智能图像捕获，并结合了超宽带（UWB）定位数据的神经渲染场（NeRF）进行高精度重建。


<details>
  <summary>Details</summary>
Motivation: 克服小型无人机（UAV）在载荷和自主性方面的限制，以实现高质量的3D重建。

Method: 提出一种双重建管线系统架构，包括一个近实时（near-RT）的运动恢复结构（SfM）流程，用于生成瞬时点云并动态调整UAV轨迹以捕获缺失区域的图像；以及一个非实时（non-RT）的基于神经渲染场（NeRF）的3D重建（N3DR）流程，结合了SfM的相机姿态和超宽带（UWB）定位数据以实现高精度。

Result: 实验证明，动态轨迹调整能够持续提高3D重建质量，并且该系统在单无人机和多无人机配置下均表现良好。

Conclusion: 该系统为在受限环境中进行精细3D重建的小型无人机提供了一种可扩展且自主的解决方案，克服了以往仅限于大型平台的限制。

Abstract: Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for
navigating indoor and hard-to-reach areas, yet their significant constraints in
payload and autonomy have largely prevented their use for complex tasks like
high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we
introduce a novel system architecture that enables fully autonomous,
high-fidelity 3D scanning of static objects using UAVs weighing under 100
grams. Our core innovation lies in a dual-reconstruction pipeline that creates
a real-time feedback loop between data capture and flight control. A
near-real-time (near-RT) process uses Structure from Motion (SfM) to generate
an instantaneous pointcloud of the object. The system analyzes the model
quality on the fly and dynamically adapts the UAV's trajectory to intelligently
capture new images of poorly covered areas. This ensures comprehensive data
acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline
employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR)
approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB)
location data to achieve superior accuracy. We implemented and validated this
architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both
single- and multi-UAV configurations, conclusively show that dynamic trajectory
adaptation consistently improves reconstruction quality over static flight
paths. This work demonstrates a scalable and autonomous solution that unlocks
the potential of miniaturized UAVs for fine-grained 3D reconstruction in
constrained environments, a capability previously limited to much larger
platforms.

</details>


### [233] [Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors](https://arxiv.org/abs/2509.12739)
*Trung Kien La,Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 使用深度神经网络LSTM和前馈层来预测机器人连杆电机热行为。


<details>
  <summary>Details</summary>
Motivation: 由于难以获得近似模型的大量参数，因此需要一种模型无关且可扩展的方法来应对复杂性和不确定性。

Method: 收集并处理传感的关节扭矩，以预测关节电机的热行为，采用由多个隐藏的长短期记忆（LSTM）和前馈层组成的深度神经网络。

Result: 成功预测了具有七个关节的冗余机器人的关节电机温度动态。

Conclusion: 基于机器学习的方法可以有效地预测机器人连杆电机的热行为。

Abstract: In this work, deep neural networks made up of multiple hidden Long Short-Term
Memory (LSTM) and Feedforward layers are trained to predict the thermal
behavior of the joint motors of robot manipulators. A model-free and scalable
approach is adopted. It accommodates complexity and uncertainty challenges
stemming from the derivation, identification, and validation of a large number
of parameters of an approximation model that is hardly available. To this end,
sensed joint torques are collected and processed to foresee the thermal
behavior of joint motors. Promising prediction results of the machine learning
based capture of the temperature dynamics of joint motors of a redundant robot
with seven joints are presented.

</details>


### [234] [An integrated process for design and control of lunar robotics using AI and simulation](https://arxiv.org/abs/2509.12367)
*Daniel Lindmark,Jonas Andersson,Kenneth Bodin,Tora Bodin,Hugo Börjesson,Fredrik Nordfeldth,Martin Servin*

Main category: cs.RO

TL;DR: 提出一个集成流程，用于同步开发月球建造设备及其控制系统，利用OpenPLX语言连接CAD模型、自主系统和高保真3D模拟，并通过月球漫游车案例研究展示了其能力。


<details>
  <summary>Details</summary>
Motivation: 开发月球建造设备需要同步进行物理设计和控制探索。

Method: 提出一个技术框架，该框架依赖于OpenPLX语言。OpenPLX语言能够连接CAD模型、自主系统与高保真的实时3D模拟，这些模拟包括接触多体动力学、月壤交互力和非理想传感器。

Result: 通过一个结合了视觉-语言模型（用于导航）和强化学习控制策略（用于移动）的自主月球漫游车案例研究，展示了该技术框架的能力。

Conclusion: 所提出的技术框架能够支持集成流程，用于开发月球建造设备及其控制系统。

Abstract: We envision an integrated process for developing lunar construction
equipment, where physical design and control are explored in parallel. In this
paper, we describe a technical framework that supports this process. It relies
on OpenPLX, a readable/writable declarative language that links CAD-models and
autonomous systems to high-fidelity, real-time 3D simulations of contacting
multibody dynamics, machine regolith interaction forces, and non-ideal sensors.
To demonstrate its capabilities, we present two case studies, including an
autonomous lunar rover that combines a vision-language model for navigation
with a reinforcement learning-based control policy for locomotion.

</details>


### [235] [Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0](https://arxiv.org/abs/2509.12740)
*Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 为了实现工业4.0的运营效率和工业5.0的共生可持续劳动力援助，需要机器人具备对热饱和和电机过热引起的烧伤进行自主预测和适应的能力，以确保人类安全和机器人可用性。然而，传统的机器人热关机策略会抑制生产力并舒适性，并且冷却策略难以在机器人购置后实施。本研究利用具有生成式AI（即变分自编码器）的智能数字孪生来管理热异常并生成非关键机器人状态。通过变分自编码器的重建误差得出“热困难”的概念，机器人可利用此分数预测、预期并共享期望运动热可行性，以满足工业6.0和Society 6.0新兴应用的需求。


<details>
  <summary>Details</summary>
Motivation: 工业4.0和5.0要求机器人具备更强的韧性、鲁棒性和人类福祉，因此需要自主预测和适应热饱和及电机过热的能力，以确保人类安全和机器人可用性。传统关机策略会影响生产力，而事后冷却难以实施。

Method: 利用智能数字孪生，结合变分自编码器（一种生成式AI），来管理热异常并生成非关键机器人状态。通过变分自编码器的重建误差来量化“热困难”程度。

Result: 提出了一种基于变分自编码器重建误差的“热困难”度量方法，使机器人能够预测、预期并共享运动轨迹的热可行性。

Conclusion: 通过智能数字孪生和生成式AI，可以实现对机器人热状态的管理和预测，从而提高机器人性能、延长使用寿命，并满足未来工业和社会的更高要求。

Abstract: Robots are unrelentingly used to achieve operational efficiency in Industry
4.0 along with symbiotic and sustainable assistance for the work-force in
Industry 5.0. As resilience, robustness, and well-being are required in
anti-fragile manufacturing and human-centric societal tasks, an autonomous
anticipation and adaption to thermal saturation and burns due to motors
overheating become instrumental for human safety and robot availability. Robots
are thereby expected to self-sustain their performance and deliver user
experience, in addition to communicating their capability to other agents in
advance to ensure fully automated thermally feasible tasks, and prolong their
lifetime without human intervention. However, the traditional robot shutdown,
when facing an imminent thermal saturation, inhibits productivity in factories
and comfort in the society, while cooling strategies are hard to implement
after the robot acquisition. In this work, smart digital twins endowed with
generative AI, i.e., variational autoencoders, are leveraged to manage
thermally anomalous and generate uncritical robot states. The notion of thermal
difficulty is derived from the reconstruction error of variational
autoencoders. A robot can use this score to predict, anticipate, and share the
thermal feasibility of desired motion profiles to meet requirements from
emerging applications in Industry 6.0 and Society 6.0.

</details>


### [236] [Geometric Red-Teaming for Robotic Manipulation](https://arxiv.org/abs/2509.12379)
*Divyam Goel,Yufei Wang,Tiancheng Wu,Guixiu Qiao,Pavel Piliptchak,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 本研究提出了一种名为几何红队（GRT）的机器人操作鲁棒性评估框架，通过自动生成具有结构约束的物体变形（CrashShapes）来探测和触发预训练策略的灾难性故障，并展示了基于此变形进行策略微调（蓝队）可以显著提高特定场景下的成功率，且该方法在仿真和真实机器人上均有效。


<details>
  <summary>Details</summary>
Motivation: 机器人操作的标准评估协议通常在固定的、分布内的测试集上进行，无法有效揭示系统在实际变化下的失效模式。因此，需要一种新的评估方法来探测系统的鲁棒性。

Method: 本研究提出几何红队（GRT）框架，结合基于雅可比场的变形模型和无梯度、模拟器循环的优化策略，自动生成在结构上有效且满足用户约束的网格变形（CrashShapes），以触发机器人操作策略的灾难性故障。

Result: GRT在插入、关节操作和抓取任务中，能够发现导致策略性能急剧下降的变形，揭示了静态基准测试所忽略的脆弱失效模式。通过在单个CrashShapes上进行微调（蓝队），可以将任务成功率提高高达60个百分点，同时保持在原始物体上的性能。在真实机器人上的实验验证了仿真结果的有效性，CrashShapes可将成功率从90%降至22.5%，蓝队可将成功率恢复至90%。

Conclusion: 几何红队（GRT）提供了一种结构化、以物体为中心的鲁棒性评估方法，能够有效探测机器人操作系统的脆弱性。通过红队和蓝队相结合，不仅可以发现和理解系统的局限性，还能针对性地改进策略，提高在特定变化下的鲁棒性。

Abstract: Standard evaluation protocols in robotic manipulation typically assess policy
performance over curated, in-distribution test sets, offering limited insight
into how systems fail under plausible variation. We introduce Geometric
Red-Teaming (GRT), a red-teaming framework that probes robustness through
object-centric geometric perturbations, automatically generating CrashShapes --
structurally valid, user-constrained mesh deformations that trigger
catastrophic failures in pre-trained manipulation policies. The method
integrates a Jacobian field-based deformation model with a gradient-free,
simulator-in-the-loop optimization strategy. Across insertion, articulation,
and grasping tasks, GRT consistently discovers deformations that collapse
policy performance, revealing brittle failure modes missed by static
benchmarks. By combining task-level policy rollouts with constraint-aware shape
exploration, we aim to build a general purpose framework for structured,
object-centric robustness evaluation in robotic manipulation. We additionally
show that fine-tuning on individual CrashShapes, a process we refer to as
blue-teaming, improves task success by up to 60 percentage points on those
shapes, while preserving performance on the original object, demonstrating the
utility of red-teamed geometries for targeted policy refinement. Finally, we
validate both red-teaming and blue-teaming results with a real robotic arm,
observing that simulated CrashShapes reduce task success from 90% to as low as
22.5%, and that blue-teaming recovers performance to up to 90% on the
corresponding real-world geometry -- closely matching simulation outcomes.
Videos and code can be found on our project website:
https://georedteam.github.io/ .

</details>


### [237] [Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems](https://arxiv.org/abs/2509.12390)
*Evangelos Psomiadis,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 本文提出了一种分布式事件触发控制方法，用于资源有限的多机器人协同编队控制。


<details>
  <summary>Details</summary>
Motivation: 为了减少控制更新和节省资源，本文研究了在资源有限的情况下，多智能体系统的协同编队控制问题。

Method: 提出了一种分布式事件触发编队控制器，该控制器仅在测量误差超过预定阈值时才触发控制更新，并依赖于智能体间的距离测量来确保系统稳定性。

Result: 通过在不同编队、通信拓扑、可扩展性测试和设计参数变化下的广泛模拟和真实世界实验，验证了所提出的控制器，并与周期性触发策略进行了比较。结果表明，事件触发方法在保持编队性能的同时，显著减少了控制工作量。

Conclusion: 所提出的事件触发方法在保持编队性能的同时，显著减少了控制工作量。

Abstract: This paper addresses the problem of collaborative formation control for
multi-agent systems with limited resources. We consider a team of robots tasked
with achieving a desired formation from arbitrary initial configurations. To
reduce unnecessary control updates and conserve resources, we propose a
distributed event-triggered formation controller that relies on inter-agent
distance measurements. Control updates are triggered only when the measurement
error exceeds a predefined threshold, ensuring system stability. The proposed
controller is validated through extensive simulations and real-world
experiments involving different formations, communication topologies,
scalability tests, and variations in design parameters, while also being
compared against periodic triggering strategies. Results demonstrate that the
event-triggered approach significantly reduces control efforts while preserving
formation performance.

</details>


### [238] [MinJointTracker: Real-time inertial kinematic chain tracking with joint position estimation and minimal state size](https://arxiv.org/abs/2509.12398)
*Michael Lorenz,Bertram Taetz,Gabriele Bleser-Taetz,Didier Stricker*

Main category: cs.RO

TL;DR: 该研究提出了一种无需校准的惯性运动捕捉方法，可实时进行运动跟踪，并同时估计 IMU 的运动学和在 IMU 坐标系中的关节位置。


<details>
  <summary>Details</summary>
Motivation: 现有惯性运动捕捉方法需要离线校准，如测量段长度、IMU 与段坐标系的相对方向或 IMU 坐标系中的关节位置，这使得设置过程繁琐。本研究旨在解决这一问题，提出一种实时、无需校准的惯性跟踪方法。

Method: 通过递归贝叶斯估计，同时估计全局 IMU 角运动学和 IMU 坐标系中的关节位置，并最小化状态大小，以实现实时校准无关的惯性跟踪。

Result: 在模拟的单摆数据和模拟的健康人行走数据上进行的实验表明，该算法能够提供无漂移的相对和绝对方向估计（一个 IMU 即可获得全局航向参考），并能快速准确地估计不同运动场景下的关节位置。

Conclusion: 该研究提出的无需校准的轻量级算法在实时惯性跟踪方面表现出色，能够提供准确的运动学和关节位置估计，且设置过程简便。

Abstract: Inertial motion capture is a promising approach for capturing motion outside
the laboratory. However, as one major drawback, most of the current methods
require different quantities to be calibrated or computed offline as part of
the setup process, such as segment lengths, relative orientations between
inertial measurement units (IMUs) and segment coordinate frames (IMU-to-segment
calibrations) or the joint positions in the IMU frames. This renders the setup
process inconvenient. This work contributes to real-time capable
calibration-free inertial tracking of a kinematic chain, i.e. simultaneous
recursive Bayesian estimation of global IMU angular kinematics and joint
positions in the IMU frames, with a minimal state size. Experimental results on
simulated IMU data from a three-link kinematic chain (manipulator study) as
well as re-simulated IMU data from healthy humans walking (lower body study)
show that the calibration-free and lightweight algorithm provides not only
drift-free relative but also drift-free absolute orientation estimates with a
global heading reference for only one IMU as well as robust and fast
convergence of joint position estimates in the different movement scenarios.

</details>


### [239] [Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models](https://arxiv.org/abs/2509.12838)
*Kento Murata,Shoichi Hasegawa,Tomochika Ishikawa,Yoshinobu Hagiwara,Akira Taniguchi,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 提出一个利用大型语言模型（LLM）和空间概念来分解自然语言指令为子任务并将其分配给多个机器人的任务规划框架。


<details>
  <summary>Details</summary>
Motivation: 解决在多机器人协作中，机器人拥有不同且局部的空间知识时，如何有效地将任务分配给合适机器人的挑战。

Method: 设计了一种新颖的少样本提示策略，使LLM能够从模糊的指令中推断所需对象，并将其分解为适当的子任务，进而分配给机器人。

Result: 在实验中，提出的方法成功率为47/50，优于随机分配（28/50）和基于常识的分配（26/50）。实际的移动操作机器人实验也证明了该框架能够处理包括“为实地考察做准备”这类包含临时类别指令的任务。

Conclusion: 所提出的框架能够有效地处理涉及多对象搜索或上下文相关指令的复杂任务，并能成功地进行任务分解、分配、顺序规划和执行。

Abstract: It is crucial to efficiently execute instructions such as "Find an apple and
a banana" or "Get ready for a field trip," which require searching for multiple
objects or understanding context-dependent commands. This study addresses the
challenging problem of determining which robot should be assigned to which part
of a task when each robot possesses different situational on-site
knowledge-specifically, spatial concepts learned from the area designated to it
by the user. We propose a task planning framework that leverages large language
models (LLMs) and spatial concepts to decompose natural language instructions
into subtasks and allocate them to multiple robots. We designed a novel
few-shot prompting strategy that enables LLMs to infer required objects from
ambiguous commands and decompose them into appropriate subtasks. In our
experiments, the proposed method achieved 47/50 successful assignments,
outperforming random (28/50) and commonsense-based assignment (26/50).
Furthermore, we conducted qualitative evaluations using two actual mobile
manipulators. The results demonstrated that our framework could handle
instructions, including those involving ad hoc categories such as "Get ready
for a field trip," by successfully performing task decomposition, assignment,
sequential planning, and execution.

</details>


### [240] [Computing forward statics from tendon-length in flexible-joint hyper-redundant manipulators](https://arxiv.org/abs/2509.12444)
*Weiting Feng,Kyle L. Walker,Yunjie Yang,Francesco Giorgio-Serchi*

Main category: cs.RO

TL;DR: 提出了一种融合缆线张力和长度作为输入来求解拟人化超冗余机械臂正静力学问题的方案，该方法通过迭代求解，可以等效地使用缆线长度或张力作为输入，并成功通过实验验证了仅使用运动学输入进行开环控制的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统超冗余机械臂控制方法在处理尺寸较大且受重力影响的机械臂时，需要解决静力学问题，但依赖张力测量或状态估计的方法存在精度不足的问题。

Method: 提出了一种基于螺钉理论的表达方式，用于描述具有弹性关节的多段式超冗余拟人化机械臂的正静力学问题，并开发了一种迭代求解方法，该方法可以同时兼容使用缆线长度或张力作为输入。

Result: 实验验证了该方法在仅使用张力输入时的有效性，并进一步证明了在仅使用缆线长度作为输入时方法的有效性，确认了在静态条件下仅使用运动学输入进行开环控制的可能性。

Conclusion: 所提出的方法能够通过仅使用运动学输入（如缆线长度）来解决超冗余系统的正静力学问题，从而克服了实际应用中张力测量和状态估计的限制，实现了在静态条件下的开环控制。

Abstract: Hyper-redundant tendon-driven manipulators offer greater flexibility and
compliance over traditional manipulators. A common way of controlling such
manipulators relies on adjusting tendon lengths, which is an accessible control
parameter. This approach works well when the kinematic configuration is
representative of the real operational conditions. However, when dealing with
manipulators of larger size subject to gravity, it becomes necessary to solve a
static force problem, using tendon force as the input and employing a mapping
from the configuration space to retrieve tendon length. Alternatively,
measurements of the manipulator posture can be used to iteratively adjust
tendon lengths to achieve a desired posture. Hence, either tension measurement
or state estimation of the manipulator are required, both of which are not
always accurately available. Here, we propose a solution by reconciling cables
tension and length as the input for the solution of the system forward statics.
We develop a screw-based formulation for a tendon-driven, multi-segment,
hyper-redundant manipulator with elastic joints and introduce a forward statics
iterative solution method that equivalently makes use of either tendon length
or tension as the input. This strategy is experimentally validated using a
traditional tension input first, subsequently showing the efficacy of the
method when exclusively tendon lengths are used. The results confirm the
possibility to perform open-loop control in static conditions using a kinematic
input only, thus bypassing some of the practical problems with tension
measurement and state estimation of hyper-redundant systems.

</details>


### [241] [Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains](https://arxiv.org/abs/2509.12468)
*Shipeng Liu,Meghana Sagare,Shubham Patil,Feifei Qian*

Main category: cs.RO

TL;DR: 受弹涂鱼启发，通过实验研究了尾部设计和控制如何协同增强机器人在沙地等可变形地貌上的推进能力，发现尾部振荡可显著提高速度和降低阻力，并提出了基于基板强度和尾部形态的尾部作用选择设计原则。


<details>
  <summary>Details</summary>
Motivation: 地面机器人难以在沙地和泥泞等可变形地貌上有效移动，需要研究新的机器人设计和控制方法来应对这些挑战。

Method: 利用仿生机器人模拟弹涂鱼，通过实验对比了静止尾部和主动振荡尾部两种配置下的移动性能，并测量了剪切力以理解其对机器人移动的影响，同时研究了不同尾部形态对振荡策略的影响。

Result: 尾部振荡使机器人速度提高了67%，身体阻力降低了46%。实验发现，振荡尾部通过使基底流化来减小阻力。此外，较大的水平表面积的尾部设计通过限制插入深度，更有效地利用了振荡减小的剪切阻力。

Conclusion: 尾部振荡和形态协同作用可以显著提高机器人在可变形地貌上的移动能力。研究提出了尾部作用选择设计原则，为农业机器人、搜索和救援以及环境探索等领域的机器人设计提供了新的思路。

Abstract: Deformable substrates such as sand and mud present significant challenges for
terrestrial robots due to complex robot-terrain interactions. Inspired by
mudskippers, amphibious animals that naturally adjust their tail morphology and
movement jointly to navigate such environments, we investigate how tail design
and control can jointly enhance flipper-driven locomotion on granular media.
Using a bio-inspired robot modeled after the mudskipper, we experimentally
compared locomotion performance between idle and actively oscillating tail
configurations. Tail oscillation increased robot speed by 67% and reduced body
drag by 46%. Shear force measurements revealed that this improvement was
enabled by tail oscillation fluidizing the substrate, thereby reducing
resistance. Additionally, tail morphology strongly influenced the oscillation
strategy: designs with larger horizontal surface areas leveraged the
oscillation-reduced shear resistance more effectively by limiting insertion
depth. Based on these findings, we present a design principle to inform tail
action selection based on substrate strength and tail morphology. Our results
offer new insights into tail design and control for improving robot locomotion
on deformable substrates, with implications for agricultural robotics, search
and rescue, and environmental exploration.

</details>


### [242] [Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents](https://arxiv.org/abs/2509.12507)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 该研究提出了一个结合模仿学习和强化学习的框架，用于在具身智能体中生成指向性手势，以实现更自然的交互。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人和智能体能够与人类进行自然交流，仅关注语言和语音是不够的，非语言交流至关重要。

Method: 提出一个结合模仿学习和强化学习的框架，使用运动捕捉数据集训练出一个生成物理上有效、自然且具有高度指代准确性的手势的运动控制策略。

Result: 实验结果表明，该方法在自然度和准确性方面优于最先进的监督学习模型和检索基线。

Conclusion: 模仿学习与强化学习相结合的方法在生成交流性手势方面展现出巨大潜力，并可应用于机器人技术。

Abstract: One of the main goals of robotics and intelligent agent research is to enable
natural communication with humans in physically situated settings. While recent
work has focused on verbal modes such as language and speech, non-verbal
communication is crucial for flexible interaction. We present a framework for
generating pointing gestures in embodied agents by combining imitation and
reinforcement learning. Using a small motion capture dataset, our method learns
a motor control policy that produces physically valid, naturalistic gestures
with high referential accuracy. We evaluate the approach against supervised
learning and retrieval baselines in both objective metrics and a virtual
reality referential game with human users. Results show that our system
achieves higher naturalness and accuracy than state-of-the-art supervised
models, highlighting the promise of imitation-RL for communicative gesture
generation and its potential application to robots.

</details>


### [243] [Zero to Autonomy in Real-Time: Online Adaptation of Dynamics in Unstructured Environments](https://arxiv.org/abs/2509.12516)
*William Ward,Sarah Etter,Jesse Quattrociocchi,Christian Ellis,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.RO

TL;DR: 该研究提出了一种在线自适应方法，结合函数编码器和递归最小二乘法，以实时适应机器人动态变化，从而在非结构化环境中实现安全控制。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在非结构化环境中从零知识快速实现安全控制，而地形的突然变化（如结冰）会带来动态变化，除非模型能实时适应，否则会导致规划器不稳定。

Method: 提出一种在线自适应方法，结合函数编码器和递归最小二乘法，将函数编码器系数视为通过航位推算流更新的潜在状态。该方法能够在常数时间内进行系数估计，无需基于梯度的内循环更新，从而仅用几秒钟的数据即可实现自适应。

Result: 在范德堡拉系统、Unity模拟器越野导航和Clearpath Jackal机器人（包括在冰场的挑战性地形上）进行了评估。结果表明，该方法提高了模型的准确性和下游规划性能，并减少了与静态和元学习基线的碰撞。

Conclusion: 所提出的在线自适应方法能够有效应对动态变化，提高机器人的模型准确性和规划能力，从而在非结构化环境中实现更安全可靠的导航。

Abstract: Autonomous robots must go from zero prior knowledge to safe control within
seconds to operate in unstructured environments. Abrupt terrain changes, such
as a sudden transition to ice, create dynamics shifts that can destabilize
planners unless the model adapts in real-time. We present a method for online
adaptation that combines function encoders with recursive least squares,
treating the function encoder coefficients as latent states updated from
streaming odometry. This yields constant-time coefficient estimation without
gradient-based inner-loop updates, enabling adaptation from only a few seconds
of data. We evaluate our approach on a Van der Pol system to highlight
algorithmic behavior, in a Unity simulator for high-fidelity off-road
navigation, and on a Clearpath Jackal robot, including on a challenging terrain
at a local ice rink. Across these settings, our method improves model accuracy
and downstream planning, reducing collisions compared to static and
meta-learning baselines.

</details>


### [244] [Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning](https://arxiv.org/abs/2509.12531)
*Scott Jones,Liyou Zhou,Sebastian W. Pattinson*

Main category: cs.RO

TL;DR: 使用预训练视觉模型（PVM）可以提高机器人模型学习（MBRL）在视觉域偏移下的泛化能力，其中部分微调效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的模型无关强化学习（MFRL）在机器人策略学习中，使用预训练视觉模型（PVM）可以提高泛化性，但在模型关联强化学习（MBRL）中PVMs被发现效果不佳，本文旨在研究PVMs在MBRL中的有效性，特别是在视觉域偏移下的泛化能力。

Method: 在视觉域偏移场景下，比较使用PVMs和从头训练的基线模型的性能。研究不同程度的PVMs微调对模型性能的影响。

Result: 在严重的视觉域偏移下，PVMs性能远超基线模型。部分微调PVMs在极端分布偏移下能保持最高的平均任务性能。

Conclusion: PVMs在提高视觉策略学习的鲁棒性方面非常成功，为在模型关联机器人学习应用中更广泛地采用提供了有力证据。

Abstract: In visuomotor policy learning, the control policy for the robotic agent is
derived directly from visual inputs. The typical approach, where a policy and
vision encoder are trained jointly from scratch, generalizes poorly to novel
visual scene changes. Using pre-trained vision models (PVMs) to inform a policy
network improves robustness in model-free reinforcement learning (MFRL). Recent
developments in Model-based reinforcement learning (MBRL) suggest that MBRL is
more sample-efficient than MFRL. However, counterintuitively, existing work has
found PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness
in MBRL, specifically on generalization under visual domain shifts. We show
that, in scenarios with severe shifts, PVMs perform much better than a baseline
model trained from scratch. We further investigate the effects of varying
levels of fine-tuning of PVMs. Our results show that partial fine-tuning can
maintain the highest average task performance under the most extreme
distribution shifts. Our results demonstrate that PVMs are highly successful in
promoting robustness in visual policy learning, providing compelling evidence
for their wider adoption in model-based robotic learning applications.

</details>


### [245] [Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling](https://arxiv.org/abs/2509.12562)
*Zhefei Gong,Shangke Lyu,Pengxiang Ding,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 通过结合全局动力学建模和残差策略学习，提出了一种名为KORR的框架，用于提高机器人长时任务和高精度控制的性能、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的残差策略学习方法主要关注局部修正，缺乏对状态演变的全局理解，限制了其在长时任务和未见场景下的鲁棒性和泛化能力。

Method: 提出KORR框架，利用Koopman算子理论在学习到的潜在空间中施加线性时不变结构，以实现可靠的状态转换和改进的长期预测及未见环境的外推能力。该框架将残差修正与基于Koopman预测的潜在状态相结合，以实现全局知情的稳定动作修正。

Result: 在机器人家具组装等长时、精细的任务中，KORR相较于现有方法在性能、鲁棒性和泛化能力方面均取得了显著提升。

Conclusion: 基于Koopman算子理论的建模方法有潜力结合现代学习方法和经典控制理论，以应对机器人技术中的挑战。

Abstract: Imitation learning (IL) enables efficient skill acquisition from
demonstrations but often struggles with long-horizon tasks and high-precision
control due to compounding errors. Residual policy learning offers a promising,
model-agnostic solution by refining a base policy through closed-loop
corrections. However, existing approaches primarily focus on local corrections
to the base policy, lacking a global understanding of state evolution, which
limits robustness and generalization to unseen scenarios. To address this, we
propose incorporating global dynamics modeling to guide residual policy
updates. Specifically, we leverage Koopman operator theory to impose linear
time-invariant structure in a learned latent space, enabling reliable state
transitions and improved extrapolation for long-horizon prediction and unseen
environments. We introduce KORR (Koopman-guided Online Residual Refinement), a
simple yet effective framework that conditions residual corrections on
Koopman-predicted latent states, enabling globally informed and stable action
refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture
assembly tasks under various perturbations. Results demonstrate consistent
gains in performance, robustness, and generalization over strong baselines. Our
findings further highlight the potential of Koopman-based modeling to bridge
modern learning methods with classical control theory.

</details>


### [246] [The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](https://arxiv.org/abs/2509.12594)
*Titong Jiang,Xuefeng Jiang,Yuan Ma,Xin Wen,Bailin Li,Kun Zhan,Peng Jia,Yahui Liu,Sheng Sun,Xianpeng Lang*

Main category: cs.RO

TL;DR: LightVLA通过自适应、面向性能的视觉令牌剪枝，提高了视觉-语言-动作（VLA）模型的效率和性能，在资源受限的机器人任务中实现了显著的FLOP和延迟降低。


<details>
  <summary>Details</summary>
Motivation: VLA模型在执行机器人任务方面表现出色，但在资源受限平台上的部署受到视觉令牌上的注意力计算的限制。LightVLA旨在通过剪枝视觉令牌来解决这一挑战。

Method: LightVLA生成动态查询来评估视觉令牌的重要性，并使用Gumbel softmax来实现可微分令牌选择，从而在保留信息令牌的同时剪枝不重要的令牌。

Result: LightVLA在LIBERO基准测试中，在多个任务上超越了不同的VLA模型和现有的令牌剪枝方法，在任务成功率提高2.9%的同时，将FLOP和延迟分别降低了59.1%和38.2%。LightVLA*也取得了令人满意的性能。

Conclusion: LightVLA是第一个将自适应视觉令牌剪枝应用于VLA任务的工作，旨在提高效率和性能，为更高效、更强大、更实用的实时机器人系统迈出了重要一步。

Abstract: We present LightVLA, a simple yet effective differentiable token pruning
framework for vision-language-action (VLA) models. While VLA models have shown
impressive capability in executing real-world robotic tasks, their deployment
on resource-constrained platforms is often bottlenecked by the heavy
attention-based computation over large sets of visual tokens. LightVLA
addresses this challenge through adaptive, performance-driven pruning of visual
tokens: It generates dynamic queries to evaluate visual token importance, and
adopts Gumbel softmax to enable differentiable token selection. Through
fine-tuning, LightVLA learns to preserve the most informative visual tokens
while pruning tokens which do not contribute to task execution, thereby
improving efficiency and performance simultaneously. Notably, LightVLA requires
no heuristic magic numbers and introduces no additional trainable parameters,
making it compatible with modern inference frameworks. Experimental results
demonstrate that LightVLA outperforms different VLA models and existing token
pruning methods across diverse tasks on the LIBERO benchmark, achieving higher
success rates with substantially reduced computational overhead. Specifically,
LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%
improvement in task success rate. Meanwhile, we also investigate the learnable
query-based token pruning method LightVLA* with additional trainable
parameters, which also achieves satisfactory performance. Our work reveals that
as VLA pursues optimal performance, LightVLA spontaneously learns to prune
tokens from a performance-driven perspective. To the best of our knowledge,
LightVLA is the first work to apply adaptive visual token pruning to VLA tasks
with the collateral goals of efficiency and performance, marking a significant
step toward more efficient, powerful and practical real-time robotic systems.

</details>


### [247] [ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation](https://arxiv.org/abs/2509.12618)
*Zekai Zhang,Weiye Zhu,Hewei Pan,Xiangchen Wang,Rongtao Xu,Xing Sun,Feng Zheng*

Main category: cs.RO

TL;DR: ActiveVLN是一个多轮强化学习框架，通过主动探索解决现有视觉语言导航（VLN）方法的局限性，并取得优于模仿学习和现有强化学习方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大模型（MLLM）的VLN方法主要依赖模仿学习（IL），常使用DAgger进行后训练以缓解协变量偏移，但这带来了高昂的数据收集和训练成本。而现有的强化学习（RL）方法缺乏与环境的动态交互，并依赖专家轨迹进行奖励塑造，而非开放式的主动探索，这限制了代理发现多样化、合理导航路线的能力。

Method: 本文提出ActiveVLN框架，通过多轮RL显式地实现主动探索。首先，使用少量专家轨迹进行IL来引导代理。其次，代理迭代地预测和执行动作，自动收集多样化轨迹，并通过GRPO目标优化多个滚出。为提高RL效率，引入动态提前停止策略来修剪长尾或可能失败的轨迹，并辅以额外的工程优化。

Result: 与IL基线相比，ActiveVLN实现了最大的性能提升，优于基于DAgger和现有基于RL的后训练方法，并且在模型尺寸较小的情况下达到了与最先进方法相当的性能。

Conclusion: ActiveVLN通过引入主动探索和优化的RL训练范式，显著提升了VLN任务的性能，克服了现有方法的局限性。

Abstract: The Vision-and-Language Navigation (VLN) task requires an agent to follow
natural language instructions and navigate through complex environments.
Existing MLLM-based VLN methods primarily rely on imitation learning (IL) and
often use DAgger for post-training to mitigate covariate shift. While
effective, these approaches incur substantial data collection and training
costs. Reinforcement learning (RL) offers a promising alternative. However,
prior VLN RL methods lack dynamic interaction with the environment and depend
on expert trajectories for reward shaping, rather than engaging in open-ended
active exploration. This restricts the agent's ability to discover diverse and
plausible navigation routes. To address these limitations, we propose
ActiveVLN, a VLN framework that explicitly enables active exploration through
multi-turn RL. In the first stage, a small fraction of expert trajectories is
used for IL to bootstrap the agent. In the second stage, the agent iteratively
predicts and executes actions, automatically collects diverse trajectories, and
optimizes multiple rollouts via the GRPO objective. To further improve RL
efficiency, we introduce a dynamic early-stopping strategy to prune long-tail
or likely failed trajectories, along with additional engineering optimizations.
Experiments show that ActiveVLN achieves the largest performance gains over IL
baselines compared to both DAgger-based and prior RL-based post-training
methods, while reaching competitive performance with state-of-the-art
approaches despite using a smaller model. Code and data will be released soon.

</details>


### [248] [PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion](https://arxiv.org/abs/2509.12620)
*Yikai Chen,Zhi Zheng,Jin Wang,Bingye He,Xiangyu Xu,Jialu Zhang,Huan Yu,Guodong Lu*

Main category: cs.RO

TL;DR: PerchMobi^3是一个集空中飞行、地面行驶和墙壁攀爬于一体的机器人，通过创新的推进-附着力功率再利用机制，无需额外的泵即可实现多模式移动。


<details>
  <summary>Details</summary>
Motivation: 现有机器人集成多种移动模式（如飞行、地面行驶、墙壁攀爬）时，通常需要额外的附着力驱动器，这增加了复杂性、降低了效率并影响了可靠性。本研究旨在克服这些限制。

Method: 提出了一种名为PerchMobi^3的四风扇、负压、空中-地面-墙壁机器人。该机器人利用推进-附着力功率再利用机制，通过四个涵道风扇同时提供飞行推力和负压附着力，并与四个主动驱动轮集成，从而无需专用泵，并保持了轻量化和紧凑的设计。建立了能够协调地面、墙壁和空中域运行的建模与控制框架，并实现了风扇辅助的模式转换。

Result: 通过一系列全面的实验，包括地面行驶、载重辅助墙壁攀爬、空中飞行以及跨模式转换，验证了该设计的可行性。实验证明了机器人在不同移动场景下具有强大的适应性。

Conclusion: PerchMobi^3展示了一种新颖的多模式机器人移动设计范式，其推进-附着力功率再利用机制消除了对专用泵的需求，实现了轻量化和紧凑的设计。该研究为未来实现自主和面向应用的部署铺平了道路。

Abstract: Achieving seamless integration of aerial flight, ground driving, and wall
climbing within a single robotic platform remains a major challenge, as
existing designs often rely on additional adhesion actuators that increase
complexity, reduce efficiency, and compromise reliability. To address these
limitations, we present PerchMobi^3, a quad-fan, negative-pressure,
air-ground-wall robot that implements a propulsion-adhesion power-reuse
mechanism. By repurposing four ducted fans to simultaneously provide aerial
thrust and negative-pressure adhesion, and integrating them with four actively
driven wheels, PerchMobi^3 eliminates dedicated pumps while maintaining a
lightweight and compact design. To the best of our knowledge, this is the first
quad-fan prototype to demonstrate functional power reuse for multi-modal
locomotion. A modeling and control framework enables coordinated operation
across ground, wall, and aerial domains with fan-assisted transitions. The
feasibility of the design is validated through a comprehensive set of
experiments covering ground driving, payload-assisted wall climbing, aerial
flight, and cross-mode transitions, demonstrating robust adaptability across
locomotion scenarios. These results highlight the potential of PerchMobi^3 as a
novel design paradigm for multi-modal robotic mobility, paving the way for
future extensions toward autonomous and application-oriented deployment.

</details>


### [249] [Safety filtering of robotic manipulation under environment uncertainty: a computational approach](https://arxiv.org/abs/2509.12674)
*Anna Johansson,Daniel Lindmark,Viktor Wiberg,Martin Servin*

Main category: cs.RO

TL;DR: 该研究提出了一种基于物理的安全过滤方案，利用高保真仿真来评估不确定世界参数下的控制策略，以实现动态和非结构化环境中的机器人安全操作。


<details>
  <summary>Details</summary>
Motivation: 现有的安全滤波器通常假设完全可观测性，这在现实世界的任务中限制了它们的适用性。在动态和非结构化环境中，需要利用已知和不确定的世界信息来保证机器人操作的安全性。

Method: 该方法结合了具有名义参数的密集回滚和在关键状态转换处的并行稀疏再评估。通过广义安全因子来量化稳定抓取和执行器限制，并通过探测动作来有针对性地减少不确定性。

Result: 在具有不确定物体质量和摩擦的模拟双臂操作任务中，该方法能够有效地识别和过滤不安全轨迹。

Conclusion: 基于物理的稀疏安全评估是在不确定性下实现安全机器人操作的可扩展策略。

Abstract: Robotic manipulation in dynamic and unstructured environments requires safety
mechanisms that exploit what is known and what is uncertain about the world.
Existing safety filters often assume full observability, limiting their
applicability in real-world tasks. We propose a physics-based safety filtering
scheme that leverages high-fidelity simulation to assess control policies under
uncertainty in world parameters. The method combines dense rollout with nominal
parameters and parallelizable sparse re-evaluation at critical
state-transitions, quantified through generalized factors of safety for stable
grasping and actuator limits, and targeted uncertainty reduction through
probing actions. We demonstrate the approach in a simulated bimanual
manipulation task with uncertain object mass and friction, showing that unsafe
trajectories can be identified and filtered efficiently. Our results highlight
physics-based sparse safety evaluation as a scalable strategy for safe robotic
manipulation under uncertainty.

</details>


### [250] [UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints](https://arxiv.org/abs/2509.12702)
*Hongrui Zhao,Xunlan Zhou,Boris Ivanovic,Negar Mehr*

Main category: cs.RO

TL;DR: UDON是一个实时多智能体神经隐式映射框架，通过新颖的不确定性加权分布式优化，在通信严重恶化的情况下实现高质量映射，即使在1%的成功率下也能保持高保真重建和一致的场景表示。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经隐式表示的多机器人建图方法在通信受限（如丢包、低带宽）时鲁棒性不足，在极低通信成功率下性能会严重下降。

Method: UDON采用不确定性加权分布式优化。不确定性加权优先处理更可靠的地图部分，分布式优化则隔离并惩罚通信机器人对之间的地图不一致性。

Result: 在基准数据集和真实机器人硬件上的实验表明，UDON显著优于现有方法，即使在1%的通信成功率下，也能保持高保真重建和一致的场景表示。

Conclusion: UDON在通信严重恶化的情况下实现了高质量的多机器人神经隐式建图，优于现有方法。

Abstract: Multi-robot mapping with neural implicit representations enables the compact
reconstruction of complex environments. However, it demands robustness against
communication challenges like packet loss and limited bandwidth. While prior
works have introduced various mechanisms to mitigate communication disruptions,
performance degradation still occurs under extremely low communication success
rates. This paper presents UDON, a real-time multi-agent neural implicit
mapping framework that introduces a novel uncertainty-weighted distributed
optimization to achieve high-quality mapping under severe communication
deterioration. The uncertainty weighting prioritizes more reliable portions of
the map, while the distributed optimization isolates and penalizes mapping
disagreement between individual pairs of communicating agents. We conduct
extensive experiments on standard benchmark datasets and real-world robot
hardware. We demonstrate that UDON significantly outperforms existing
baselines, maintaining high-fidelity reconstructions and consistent scene
representations even under extreme communication degradation (as low as 1%
success rate).

</details>


### [251] [MoiréTac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moiré Pattern Amplification](https://arxiv.org/abs/2509.12714)
*Kit-Wa Sou,Junhao Gong,Shoujie Li,Chuqiao Lyu,Ziwu Song,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: MoiréTac 是一种双模态传感器，通过重叠的微光栅产生密集干涉图案，可用于同时进行六轴力/扭矩测量、接触定位和视觉感知。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉触觉传感器由于稀疏标记阵列而受到空间分辨率的限制，并且缺乏明确的力-图像分析关系。MoiréTac 通过生成密集的莫尔干涉图案来解决这个问题，该图案能够放大微观变形，同时保持光学清晰度以用于视觉任务。

Method: MoiréTac 利用重叠微光栅产生的莫尔图案，结合基于物理的特征（亮度、相位梯度、方向和周期）和深度空间特征，通过端到端学习将这些特征映射到六轴力/扭矩测量值，从而实现可解释的回归。

Result: 实验结果表明 MoiréTac 具有以下能力：力/扭矩测量（R^2 > 0.98）；通过几何参数调整灵敏度（三倍增益）；以及在莫尔条纹叠加的情况下进行物体分类的视觉功能。

Conclusion: MoiréTac 传感器可以集成到机器人手臂中，用于需要精确力和扭矩控制的抓取操作，例如盖子移除任务，展示了其在灵巧操作方面的潜力。

Abstract: Visuotactile sensors typically employ sparse marker arrays that limit spatial
resolution and lack clear analytical force-to-image relationships. To solve
this problem, we present \textbf{Moir\'eTac}, a dual-mode sensor that generates
dense interference patterns via overlapping micro-gratings within a transparent
architecture. When two gratings overlap with misalignment, they create moir\'e
patterns that amplify microscopic deformations. The design preserves optical
clarity for vision tasks while producing continuous moir\'e fields for tactile
sensing, enabling simultaneous 6-axis force/torque measurement, contact
localization, and visual perception. We combine physics-based features
(brightness, phase gradient, orientation, and period) from moir\'e patterns
with deep spatial features. These are mapped to 6-axis force/torque
measurements, enabling interpretable regression through end-to-end learning.
Experimental results demonstrate three capabilities: force/torque measurement
with R^2 > 0.98 across tested axes; sensitivity tuning through geometric
parameters (threefold gain adjustment); and vision functionality for object
classification despite moir\'e overlay. Finally, we integrate the sensor into a
robotic arm for cap removal with coordinated force and torque control,
validating its potential for dexterous manipulation.

</details>


### [252] [NAMOUnc: Navigation Among Movable Obstacles with Decision Making on Uncertainty Interval](https://arxiv.org/abs/2509.12723)
*Kai Zhang,Eric Lucet,Julien Alexandre Dit Sandretto,Shoubin Chen,David Filait*

Main category: cs.RO

TL;DR: 该研究提出了一种名为NAMOUnc的新框架，用于解决机器人导航中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 机器人导航（特别是可移动障碍物导航）常面临现实世界中的不确定性，现有方法在理想条件下运行，导致决策不优或有风险。

Method: NAMOUnc框架通过将不确定性纳入决策过程来解决这些问题，首先估计不确定性，然后比较移除和绕过障碍物的时间成本区间，以优化成功率和时间效率。

Result: 通过广泛的模拟和真实世界实验验证，NAMOUnc相比现有框架有了显著改进。

Conclusion: NAMOUnc框架能够更安全、更有效地处理机器人导航中的不确定性。

Abstract: Navigation among movable obstacles (NAMO) is a critical task in robotics,
often challenged by real-world uncertainties such as observation noise, model
approximations, action failures, and partial observability. Existing solutions
frequently assume ideal conditions, leading to suboptimal or risky decisions.
This paper introduces NAMOUnc, a novel framework designed to address these
uncertainties by integrating them into the decision-making process. We first
estimate them and compare the corresponding time cost intervals for removing
and bypassing obstacles, optimizing both the success rate and time efficiency,
ensuring safer and more efficient navigation. We validate our method through
extensive simulations and real-world experiments, demonstrating significant
improvements over existing NAMO frameworks. More details can be found in our
website: https://kai-zhang-er.github.io/namo-uncertainty/

</details>


### [253] [Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions](https://arxiv.org/abs/2509.12741)
*Alexis Yihong Hao,Yufei Wang,Navin Sriram Ravie,Bharath Hegde,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 机器人辅助穿衣系统能够处理部分观测和动态的肢体运动，并在真实世界中取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 提高行动不便者的生活质量，解决现有机器人辅助穿衣系统在处理可变形衣物、施加力以及适应肢体运动方面的局限性。

Method: 提出一种在模拟环境中训练的策略，并利用少量真实世界数据和多模态反馈（视觉和力传感）进行微调，以提高策略对肢体运动的适应性和安全性。

Result: 在模拟和真实世界人体研究中，该策略成功地为参与者穿上两件长袖日常服装，能够适应各种手臂运动，并在任务完成度和用户反馈方面显著优于现有基线。

Conclusion: 所提出的机器人辅助穿衣系统能够有效处理部分观测和动态的肢体运动，并在真实世界人体研究中取得了成功。

Abstract: Robot-assisted dressing has the potential to significantly improve the lives
of individuals with mobility impairments. To ensure an effective and
comfortable dressing experience, the robot must be able to handle challenging
deformable garments, apply appropriate forces, and adapt to limb movements
throughout the dressing process. Prior work often makes simplifying assumptions
-- such as static human limbs during dressing -- which limits real-world
applicability. In this work, we develop a robot-assisted dressing system
capable of handling partial observations with visual occlusions, as well as
robustly adapting to arm motions during the dressing process. Given a policy
trained in simulation with partial observations, we propose a method to
fine-tune it in the real world using a small amount of data and multi-modal
feedback from vision and force sensing, to further improve the policy's
adaptability to arm motions and enhance safety. We evaluate our method in
simulation with simplified articulated human meshes and in a real world human
study with 12 participants across 264 dressing trials. Our policy successfully
dresses two long-sleeve everyday garments onto the participants while being
adaptive to various kinds of arm motions, and greatly outperforms prior
baselines in terms of task completion and user feedback. Video are available at
https://dressing-motion.github.io/.

</details>


### [254] [NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts](https://arxiv.org/abs/2509.12747)
*Botao He,Amir Hossein Shahidzadeh,Yu Chen,Jiayi Wu,Tianrui Guan,Guofei Chen,Howie Choset,Dinesh Manocha,Glen Chou,Cornelia Fermuller,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: NAVMOE通过混合专家模型（MoE）方法，结合多种专用模型，并利用门控网络动态调整各模型贡献度，实现了高效且泛化能力强的机器人导航中可通行性估计。


<details>
  <summary>Details</summary>
Motivation: 在机器人导航中，可通行性估计的一个关键瓶颈在于如何在不同环境中高效地获得可靠且鲁棒的预测，同时准确地编码几何和语义信息。

Method: NAVMOE（Navigation via Mixture of Experts）是一种分层的、模块化的方法，它结合了多个针对特定地形类型的专用模型（可以是经典模型或学习模型），并通过一个门控网络根据输入环境动态地调整不同模型的贡献度。它还引入了训练无关的懒惰门控机制以提高效率，并采用两阶段训练策略来处理包含不可微分模块的混合MoE方法。

Result: NAVMOE在效率和性能的平衡方面优于单一专家或完整集成方法，提高了跨域泛化能力，并通过懒惰门控机制将平均计算成本降低了81.2%，同时路径质量损失不到2%。

Conclusion: NAVMOE通过其混合专家方法、懒惰门控机制和两阶段训练策略，有效解决了机器人导航中可通行性估计的效率和泛化能力问题，实现了在保持高路径质量的同时显著降低计算成本。

Abstract: This paper explores traversability estimation for robot navigation. A key
bottleneck in traversability estimation lies in efficiently achieving reliable
and robust predictions while accurately encoding both geometric and semantic
information across diverse environments. We introduce Navigation via Mixture of
Experts (NAVMOE), a hierarchical and modular approach for traversability
estimation and local navigation. NAVMOE combines multiple specialized models
for specific terrain types, each of which can be either a classical model-based
or a learning-based approach that predicts traversability for specific terrain
types. NAVMOE dynamically weights the contributions of different models based
on the input environment through a gating network. Overall, our approach offers
three advantages: First, NAVMOE enables traversability estimation to adaptively
leverage specialized approaches for different terrains, which enhances
generalization across diverse and unseen environments. Second, our approach
significantly improves efficiency with negligible cost of solution quality by
introducing a training-free lazy gating mechanism, which is designed to
minimize the number of activated experts during inference. Third, our approach
uses a two-stage training strategy that enables the training for the gating
networks within the hybrid MoE method that contains nondifferentiable modules.
Extensive experiments show that NAVMOE delivers a better efficiency and
performance balance than any individual expert or full ensemble across
different domains, improving cross- domain generalization and reducing average
computational cost by 81.2% via lazy gating, with less than a 2% loss in path
quality.

</details>


### [255] [Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model](https://arxiv.org/abs/2509.12754)
*Saki Hashimoto,Shoichi Hasegawa,Tomochika Ishikawa,Akira Taniguchi,Yoshinobu Hagiwara,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 机器人通过提问来学习物品归属，并利用大语言模型进行辅助，提高了学习效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 需要解决机器人在家庭和办公室环境中理解物品归属的问题，因为仅凭视觉特征无法可靠推断所有权。

Method: 提出主动归属学习（ActOwL）框架，利用概率生成模型选择能最大化信息增益的问题，并结合大语言模型（LLM）的常识知识预分类物品。

Result: 在模拟和真实环境中，ActOwL相比基线方法，用更少的问题实现了更高的物品归属聚类准确性。

Conclusion: 结合主动推理和LLM常识推理能有效提升机器人获取物品归属知识的能力，使其能更实际、更适当地执行任务。

Abstract: Robots operating in domestic and office environments must understand object
ownership to correctly execute instructions such as ``Bring me my cup.''
However, ownership cannot be reliably inferred from visual features alone. To
address this gap, we propose Active Ownership Learning (ActOwL), a framework
that enables robots to actively generate and ask ownership-related questions to
users. ActOwL employs a probabilistic generative model to select questions that
maximize information gain, thereby acquiring ownership knowledge efficiently to
improve learning efficiency. Additionally, by leveraging commonsense knowledge
from Large Language Models (LLM), objects are pre-classified as either shared
or owned, and only owned objects are targeted for questioning. Through
experiments in a simulated home environment and a real-world laboratory
setting, ActOwL achieved significantly higher ownership clustering accuracy
with fewer questions than baseline methods. These findings demonstrate the
effectiveness of combining active inference with LLM-guided commonsense
reasoning, advancing the capability of robots to acquire ownership knowledge
for practical and socially appropriate task execution.

</details>


### [256] [Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing](https://arxiv.org/abs/2509.12776)
*Renjie Wang,Shangke Lyu,Xin Lang,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 该研究提出了一种结合轨迹优化 (TO) 和强化学习 (RL) 的安全着陆框架，用于在崎岖地形上实现自适应着陆，并通过奖励放松策略鼓励探索，以提高在挑战性地形上的柔顺着陆能力。


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人跳跃研究主要关注平坦着陆，不适用于实际场景，因此需要一种能在崎岖地形上实现自适应着陆的安全着陆框架。

Method: 结合轨迹优化 (TO) 和强化学习 (RL)，其中 RL 学习在崎岖地形环境中跟踪 TO 生成的参考运动，并采用奖励放松策略鼓励着陆恢复期间的探索。

Result: 实验验证了该方法在各种场景下能够实现精确跟踪和安全着陆。

Conclusion: 所提出的安全着陆框架能够通过结合 TO 和 RL，以及采用奖励放松策略，实现在崎岖地形上的自适应和柔顺着陆。

Abstract: Jumping constitutes an essential component of quadruped robots' locomotion
capabilities, which includes dynamic take-off and adaptive landing. Existing
quadrupedal jumping studies mainly focused on the stance and flight phase by
assuming a flat landing ground, which is impractical in many real world cases.
This work proposes a safe landing framework that achieves adaptive landing on
rough terrains by combining Trajectory Optimization (TO) and Reinforcement
Learning (RL) together. The RL agent learns to track the reference motion
generated by TO in the environments with rough terrains. To enable the learning
of compliant landing skills on challenging terrains, a reward relaxation
strategy is synthesized to encourage exploration during landing recovery
period. Extensive experiments validate the accurate tracking and safe landing
skills benefiting from our proposed method in various scenarios.

</details>


### [257] [Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks](https://arxiv.org/abs/2509.12813)
*Bowen Ye,Junyue Huang,Yang Liu,Xiaozhen Qiao,Xiang Yin*

Main category: cs.RO

TL;DR: 我们提出了一个名为 S-MSP 的可微分框架，可以直接将多视图相机观测和 STL 规范映射到可行轨迹，解决了机器人领域中 STL 任务和运动规划的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的 STL 方法在非结构化环境中效果不佳，因为它们依赖于预定义的地图或移动性表示。本研究旨在解决这一局限性。

Method: S-MSP 是一个可微分框架，它利用结构感知专家混合模型（MoE）将多视图相机观测和 STL 规范直接映射到可行轨迹。它通过结合轨迹重建和 STL 鲁棒性的复合损失进行训练，并通过一个基于规则的安全过滤器在推理时提高物理可执行性。

Result: 在具有时间约束任务的工厂物流场景的仿真评估中，S-MSP 在 STL 满意度和轨迹可行性方面优于单一专家基线。

Conclusion: S-MSP 框架能够有效地解决 STL 任务和运动规划问题，并且通过推理时的安全过滤器可以实际应用。

Abstract: We investigate the task and motion planning problem for Signal Temporal Logic
(STL) specifications in robotics. Existing STL methods rely on pre-defined maps
or mobility representations, which are ineffective in unstructured real-world
environments. We propose the \emph{Structured-MoE STL Planner}
(\textbf{S-MSP}), a differentiable framework that maps synchronized multi-view
camera observations and an STL specification directly to a feasible trajectory.
S-MSP integrates STL constraints within a unified pipeline, trained with a
composite loss that combines trajectory reconstruction and STL robustness. A
\emph{structure-aware} Mixture-of-Experts (MoE) model enables horizon-aware
specialization by projecting sub-tasks into temporally anchored embeddings. We
evaluate S-MSP using a high-fidelity simulation of factory-logistics scenarios
with temporally constrained tasks. Experiments show that S-MSP outperforms
single-expert baselines in STL satisfaction and trajectory feasibility. A
rule-based \emph{safety filter} at inference improves physical executability
without compromising logical correctness, showcasing the practicality of the
approach.

</details>


### [258] [Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration](https://arxiv.org/abs/2509.12846)
*Junlin Song,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 提出一种基于离散时间状态表示的视觉-惯性传感器时空校准方法，解决了现有基于B样条等连续时间状态表示方法计算成本高的问题，并弥补了离散时间状态表示在时间校准方面的不足。


<details>
  <summary>Details</summary>
Motivation: 在机器人导航和增强现实等应用中，视觉-惯性里程计（VIO）的状态估计至关重要，而精确的时空校准是实现最优估计的关键。现有方法计算成本高。

Method: 提出一种利用离散时间状态表示的新型高效校准方法，并解决了其在时间校准方面的弱点。

Result: 该方法效率高，解决了现有方法的计算成本问题。

Conclusion: 该方法为视觉-惯性平台提供了高效的时空校准方案，具有重要的研究和工业应用价值。

Abstract: Visual-inertial fusion is crucial for a large amount of intelligent and
autonomous applications, such as robot navigation and augmented reality. To
bootstrap and achieve optimal state estimation, the spatial-temporal
displacements between IMU and cameras must be calibrated in advance. Most
existing calibration methods adopt continuous-time state representation, more
specifically the B-spline. Despite these methods achieve precise
spatial-temporal calibration, they suffer from high computational cost caused
by continuous-time state representation. To this end, we propose a novel and
extremely efficient calibration method that unleashes the power of
discrete-time state representation. Moreover, the weakness of discrete-time
state representation in temporal calibration is tackled in this paper. With the
increasing production of drones, cellphones and other visual-inertial
platforms, if one million devices need calibration around the world, saving one
minute for the calibration of each device means saving 2083 work days in total.
To benefit both the research and industry communities, our code will be
open-source.

</details>


### [259] [A Novel Skill Modeling Approach: Integrating Vergnaud's Scheme with Cognitive Architectures](https://arxiv.org/abs/2509.12851)
*Antoine Lénat,Olivier Cheminat,Damien Chablat,Camilo Charron*

Main category: cs.RO

TL;DR: 工业5.0背景下，理解和模拟人类操作员技能对人机交互至关重要，尤其是在焊接等复杂领域。现有理论（如皮亚杰的图式概念）存在局限性，未能充分考虑认知系统约束。结合认知架构模型和图式理论，并以焊接为例，可以更全面地表示和理解操作员技能及其在人机协作中的转移。


<details>
  <summary>Details</summary>
Motivation: 随着工业5.0的兴起，人机交互日益重要，理解和适应操作员技能对于优化人机协作和提升生产效率至关重要。

Method: 结合皮亚杰的图式概念和认知架构模型，以焊接为例，分析操作员技能的描述、适应及在人机协作中的转移，考虑认知系统约束（如时序、认知资源限制、任务并行化、自动手势激活等）。

Result: 提出一种更全面的表示和理解操作员技能的方法，能够考虑认知系统约束，并适用于焊接等复杂场景，为优化人机交互和技能转移提供理论基础。

Conclusion: 操作员技能的理解和模拟是人机交互的关键，特别是在工业5.0时代。结合现有理论与认知架构模型，并以焊接等实例进行分析，可以更有效地解决实际问题。

Abstract: Human-machine interaction is increasingly important in industry, and this
trend will only intensify with the rise of Industry 5.0. Human operators have
skills that need to be adapted when using machines to achieve the best results.
It is crucial to highlight the operator's skills and understand how they use
and adapt them [18]. A rigorous description of these skills is necessary to
compare performance with and without robot assistance. Predicate logic, used by
Vergnaud within Piaget's scheme concept, offers a promising approach. However,
this theory doesn't account for cognitive system constraints, such as the
timing of actions, the limitation of cognitive resources, the parallelization
of tasks, or the activation of automatic gestures contrary to optimal
knowledge. Integrating these constraints is essential for representing agent
skills understanding skill transfer between biological and mechanical
structures. Cognitive architectures models [2] address these needs by
describing cognitive structure and can be combined with the scheme for mutual
benefit. Welding provides a relevant case study, as it highlights the
challenges faced by operators, even highly skilled ones. Welding's complexity
stems from the need for constant skill adaptation to variable parameters like
part position and process. This adaptation is crucial, as weld quality, a key
factor, is only assessed afterward via destructive testing. Thus, the welder is
confronted with a complex perception-decision-action cycle, where the
evaluation of the impact of his actions is delayed and where errors are
definitive. This dynamic underscores the importance of understanding and
modeling the skills of operators.

</details>


### [260] [Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion](https://arxiv.org/abs/2509.12858)
*Yidan Lu,Rurui Yang,Qiran Kou,Mengting Chen,Tao Fan,Peter Cui,Yinzhao Dong,Peng Lu*

Main category: cs.RO

TL;DR: 我们提出了一种新的强化学习范式，使纯本体感觉策略具有前瞻性，在不增加感知部署成本的情况下，实现了感知的预见性。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界部署中的反应式本体感觉控制与复杂、脆弱的感知驱动系统之间的两难问题。

Method: 设计了一个对比学习框架，将模拟环境中的特权信息蒸馏到策略的潜在状态中，从而增强了自适应步态时钟，使其能够根据对地形的推断理解主动调整节奏。

Result: 在全尺寸人形机器人上实现了零样本模拟到现实的转移，在具有挑战性的地形（包括 30 厘米高的台阶和 26.5 度的斜坡）上展现了高度鲁棒的运动能力。

Conclusion: 所提出的方法有效解决了刚性时钟步态和不稳定的无时钟策略之间的经典权衡问题，实现了鲁棒和前瞻性的人形机器人运动。

Abstract: Reinforcement learning has produced remarkable advances in humanoid
locomotion, yet a fundamental dilemma persists for real-world deployment:
policies must choose between the robustness of reactive proprioceptive control
or the proactivity of complex, fragile perception-driven systems. This paper
resolves this dilemma by introducing a paradigm that imbues a purely
proprioceptive policy with proactive capabilities, achieving the foresight of
perception without its deployment-time costs. Our core contribution is a
contrastive learning framework that compels the actor's latent state to encode
privileged environmental information from simulation. Crucially, this
``distilled awareness" empowers an adaptive gait clock, allowing the policy to
proactively adjust its rhythm based on an inferred understanding of the
terrain. This synergy resolves the classic trade-off between rigid, clocked
gaits and unstable clock-free policies. We validate our approach with zero-shot
sim-to-real transfer to a full-sized humanoid, demonstrating highly robust
locomotion over challenging terrains, including 30 cm high steps and 26.5{\deg}
slopes, proving the effectiveness of our method. Website:
https://lu-yidan.github.io/cra-loco.

</details>


### [261] [Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation](https://arxiv.org/abs/2509.13109)
*Fabian Flürenbrock,Yanick Büchel,Johannes Köhler,Marianne Schmid Daners,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: 本研究提出一种基于学习的控制框架，用于调节颅内压（ICP）波形，以研究脑脊液动力学和神经系统疾病的病理过程。


<details>
  <summary>Details</summary>
Motivation: 颅内压（ICP）波形调节对于研究脑脊液动力学和神经系统疾病的病理过程至关重要。

Method: 提出一个两层控制框架：第一层使用带扰动观测器的模型预测控制器（MPC）来实现安全约束下的零偏跟踪；第二层使用贝叶斯优化（BO）算法在线学习产生期望ICP调节的电机位置参考轨迹，以解决ICP对电机位置未知的非线性依赖问题。

Result: MPC将电机位置参考跟踪误差平均值和最大值分别降低了83%和73%。BO算法在少于20次迭代内学习到了能够产生期望平均值和幅度的ICP波形的电机位置参考轨迹。

Conclusion: 该学习控制框架能够有效且安全地实现ICP波形的目标调节，并在体外实验中得到了验证。

Abstract: This paper introduces a learning-based control framework for a soft robotic
actuator system designed to modulate intracranial pressure (ICP) waveforms,
which is essential for studying cerebrospinal fluid dynamics and pathological
processes underlying neurological disorders. A two-layer framework is proposed
to safely achieve a desired ICP waveform modulation. First, a model predictive
controller (MPC) with a disturbance observer is used for offset-free tracking
of the system's motor position reference trajectory under safety constraints.
Second, to address the unknown nonlinear dependence of ICP on the motor
position, we employ a Bayesian optimization (BO) algorithm used for online
learning of a motor position reference trajectory that yields the desired ICP
modulation. The framework is experimentally validated using a test bench with a
brain phantom that replicates realistic ICP dynamics in vitro. Compared to a
previously employed proportional-integral-derivative controller, the MPC
reduces mean and maximum motor position reference tracking errors by 83 % and
73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor
position reference trajectory that yields an ICP waveform with the desired mean
and amplitude.

</details>


### [262] [GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration](https://arxiv.org/abs/2509.12863)
*Haozhan Ni,Jingsong Liang,Chenyu He,Yuhong Cao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: GRATE是一个基于深度强化学习的方法，利用图Transformer增强机器人对未知环境的探索能力，并通过卡尔曼滤波器确保路径的运动学可行性，在模拟和真实环境中均表现出更高的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的机器人自主探索方法在处理图结构数据时推理能力有限，并且在优化策略时倾向于最小化行驶距离而非时间效率。

Method: 提出GRATE方法，结合图Transformer来捕捉信息图的局部结构和全局依赖关系，并使用卡尔曼滤波器平滑输出的航点以确保路径的运动学可行性。

Result: 实验结果表明，GRATE在探索效率（距离和时间）方面优于最先进的基线方法，并在模拟和真实环境中都得到了验证。

Conclusion: GRATE通过增强图结构数据的推理能力和考虑机器人的运动动力学，提高了机器人在未知环境中的探索效率。

Abstract: Autonomous robot exploration (ARE) is the process of a robot autonomously
navigating and mapping an unknown environment. Recent Reinforcement Learning
(RL)-based approaches typically formulate ARE as a sequential decision-making
problem defined on a collision-free informative graph. However, these methods
often demonstrate limited reasoning ability over graph-structured data.
Moreover, due to the insufficient consideration of robot motion, the resulting
RL policies are generally optimized to minimize travel distance, while
neglecting time efficiency. To overcome these limitations, we propose GRATE, a
Deep Reinforcement Learning (DRL)-based approach that leverages a Graph
Transformer to effectively capture both local structure patterns and global
contextual dependencies of the informative graph, thereby enhancing the model's
reasoning capability across the entire environment. In addition, we deploy a
Kalman filter to smooth the waypoint outputs, ensuring that the resulting path
is kinodynamically feasible for the robot to follow. Experimental results
demonstrate that our method exhibits better exploration efficiency (up to 21.5%
in distance and 21.3% in time to complete exploration) than state-of-the-art
conventional and learning-based baselines in various simulation benchmarks. We
also validate our planner in real-world scenarios.

</details>


### [263] [TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving](https://arxiv.org/abs/2509.13164)
*Jiawei Wang,Haowei Sun,Xintao Yan,Shuo Feng,Jun Gao,Henry X. Liu*

Main category: cs.RO

TL;DR: TeraSim-World是一个自动化的流水线，用于为自动驾驶系统生成逼真的、地理多样化的安全关键数据，解决了现有数据来源的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了安全可扩展地部署自动驾驶，需要广泛且多样化的数据，特别是安全关键事件。然而，现有的数据主要来自存在显著模拟到现实差距的模拟器，或者来自成本高昂且不安全的实际道路测试。

Method: TeraSim-World从任意地点开始，检索真实世界的地图和交通需求，并利用自然驾驶数据集模拟行为。通过引入各种对抗性条件来创建极端情况。利用同一地点的街景图像，通过Cosmos-Drive模型实现照片般逼真且地理相关的传感器渲染。

Result: TeraSim-World能够提供逼真的、地理多样化的安全关键数据，弥合了代理和传感器的模拟差距，为端到端自动驾驶系统的训练和评估提供了一个可扩展且关键的数据合成框架。

Conclusion: TeraSim-World提供了一个可扩展且关键的数据合成框架，用于训练和评估端到端自动驾驶系统。

Abstract: Safe and scalable deployment of end-to-end (E2E) autonomous driving requires
extensive and diverse data, particularly safety-critical events. Existing data
are mostly generated from simulators with a significant sim-to-real gap or
collected from on-road testing that is costly and unsafe. This paper presents
TeraSim-World, an automated pipeline that synthesizes realistic and
geographically diverse safety-critical data for E2E autonomous driving at
anywhere in the world. Starting from an arbitrary location, TeraSim-World
retrieves real-world maps and traffic demand from geospatial data sources.
Then, it simulates agent behaviors from naturalistic driving datasets, and
orchestrates diverse adversities to create corner cases. Informed by street
views of the same location, it achieves photorealistic, geographically grounded
sensor rendering via the frontier video generation model Cosmos-Drive. By
bridging agent and sensor simulations, TeraSim-World provides a scalable and
critical~data synthesis framework for training and evaluation of E2E autonomous
driving systems.

</details>


### [264] [Towards Context-Aware Human-like Pointing Gestures with RL Motion Imitation](https://arxiv.org/abs/2509.12880)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 使用强化学习训练机器人生成类似人类的指向动作，以提高精确度和自然度。


<details>
  <summary>Details</summary>
Motivation: 虽然指向是人机交互的关键，但以往的研究主要集中在识别而非生成上。

Method: 收集包含不同风格、惯用手和空间目标的指向手势运动捕捉数据集，并使用强化学习和运动模仿来训练生成类似人类指向动作的策略。

Result: 在模拟环境中，该方法能够生成注重上下文感知、平衡任务表现和动态自然的指向行为。

Conclusion: 所提出的方法可以生成更自然、更精确的机器人指向动作，提高了人机交互的效率和体验。

Abstract: Pointing is a key mode of interaction with robots, yet most prior work has
focused on recognition rather than generation. We present a motion capture
dataset of human pointing gestures covering diverse styles, handedness, and
spatial targets. Using reinforcement learning with motion imitation, we train
policies that reproduce human-like pointing while maximizing precision. Results
show our approach enables context-aware pointing behaviors in simulation,
balancing task performance with natural dynamics.

</details>


### [265] [Responsibility and Engagement -- Evaluating Interactions in Social Robot Navigation](https://arxiv.org/abs/2509.12890)
*Malte Probst,Raphael Wenzel,Monica Dasi*

Main category: cs.RO

TL;DR: 该论文提出并扩展了社会机器人导航（SRN）中的“责任”和“参与”两个新指标，用于量化和评估机器人解决冲突的贡献和行为质量。


<details>
  <summary>Details</summary>
Motivation: 在社会机器人导航（SRN）领域，需要有意义的指标来评估人机交互中的轨迹，特别是解决多智能体冲突时的贡献度。

Method: 提出“责任”指标的扩展，包括时间归一化来模拟冲突累积阶段，并引入新的“参与”指标来衡量行为如何加剧冲突。

Result: 通过在模拟的二元、群体和人群交互场景中进行综合测试，证明了这些指标能够有效传达关于合作解决冲突的含义，并可用于评估行为质量和预见性。

Conclusion: 所提出的“责任”和“参与”指标为SRN中的冲突解决评估提供了有价值的工具，具有广泛的应用前景，但同时也存在设计选择和局限性需要考虑。

Abstract: In Social Robot Navigation (SRN), the availability of meaningful metrics is
crucial for evaluating trajectories from human-robot interactions. In the SRN
context, such interactions often relate to resolving conflicts between two or
more agents. Correspondingly, the shares to which agents contribute to the
resolution of such conflicts are important. This paper builds on recent work,
which proposed a Responsibility metric capturing such shares. We extend this
framework in two directions: First, we model the conflict buildup phase by
introducing a time normalization. Second, we propose the related Engagement
metric, which captures how the agents' actions intensify a conflict. In a
comprehensive series of simulated scenarios with dyadic, group and crowd
interactions, we show that the metrics carry meaningful information about the
cooperative resolution of conflicts in interactions. They can be used to assess
behavior quality and foresightedness. We extensively discuss applicability,
design choices and limitations of the proposed metrics.

</details>


### [266] [Spotting the Unfriendly Robot -- Towards better Metrics for Interactions](https://arxiv.org/abs/2509.12912)
*Raphael Wenzel,Malte Probst*

Main category: cs.RO

TL;DR: 目前用于社会机器人导航(SRN)的评估指标无法量化机器人与人类交互时的合作程度。为此，本文提出了冲突强度和责任两个新指标，以评估交互质量、冲突减少程度以及机器人承担的责任。


<details>
  <summary>Details</summary>
Motivation: 当前用于社会机器人导航(SRN)算法的常用评估指标，缺乏量化机器人在与人类交互时行为合作程度的能力。具体来说，在简单的 frontal approach 场景中，没有一个指标能够明确区分是双方都合作了，还是其中一方坚持在碰撞路线上，迫使另一方回避。

Method: 提出一个新的冲突强度指标和责任指标，用于评估机器人与人类交互的质量，量化给定算法在减少冲突方面的贡献，以及是哪个代理承担了解决冲突的责任。

Result: 新提出的冲突强度指标和责任指标能够评估机器人与人类交互的质量，量化算法在减少冲突方面的贡献以及责任归属。

Conclusion: 这项工作旨在为SRN提供一个全面且标准化的评估方法，以提高机器人在以人为中心的环境中的安全性、效率和社会接受度。

Abstract: Establishing standardized metrics for Social Robot Navigation (SRN)
algorithms for assessing the quality and social compliance of robot behavior
around humans is essential for SRN research. Currently, commonly used
evaluation metrics lack the ability to quantify how cooperative an agent
behaves in interaction with humans. Concretely, in a simple frontal approach
scenario, no metric specifically captures if both agents cooperate or if one
agent stays on collision course and the other agent is forced to evade. To
address this limitation, we propose two new metrics, a conflict intensity
metric and the responsibility metric. Together, these metrics are capable of
evaluating the quality of human-robot interactions by showing how much a given
algorithm has contributed to reducing a conflict and which agent actually took
responsibility of the resolution. This work aims to contribute to the
development of a comprehensive and standardized evaluation methodology for SRN,
ultimately enhancing the safety, efficiency, and social acceptance of robots in
human-centric environments.

</details>


### [267] [Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint](https://arxiv.org/abs/2509.12928)
*Peiwen Yang,Mingquan Jiang,Xinyue Shen,Heping Zhang*

Main category: cs.RO

TL;DR: 提出了一种激光视觉传感器（LVS）的时空校准新方法，以解决机器人焊接应用中相机延迟和手眼外参变化的问题。


<details>
  <summary>Details</summary>
Motivation: 工业机器人中的激光视觉传感器（LVS）在焊接应用中用于实时获取工件几何数据，但相机通信延迟会导致图像与机器人运动不同步，且手眼外参可能随时间变化。

Method: 提出了一种考虑相机时间偏移的LVS测量模型，并采用一种利用直线约束的免示教时空校准方法。该方法让机器人配备LVS，使用S形轨迹重复扫描直线焊缝。所有测量到的焊接位置被约束在一条直线上（用Plucker坐标表示）。基于直线约束建立了非线性优化模型，并使用Levenberg-Marquardt算法（LMA）优化时间偏移、手眼外参和直线参数。

Result: 通过在弯曲焊缝扫描实验中对所提方法的 ज्यात可行性和准确性进行了定量验证。

Conclusion: 所提出的免示教时空校准方法能够有效解决LVS在机器人焊接应用中因时间偏移和手眼外参变化带来的精度问题。

Abstract: Laser vision sensors (LVS) are critical perception modules for industrial
robots, facilitating real-time acquisition of workpiece geometric data in
welding applications. However, the camera communication delay will lead to a
temporal desynchronization between captured images and the robot motions.
Additionally, hand-eye extrinsic parameters may vary during prolonged
measurement. To address these issues, we introduce a measurement model of LVS
considering the effect of the camera's time-offset and propose a teaching-free
spatiotemporal calibration method utilizing line constraints. This method
involves a robot equipped with an LVS repeatedly scanning straight-line fillet
welds using S-shaped trajectories. Regardless of the robot's orientation
changes, all measured welding positions are constrained to a straight-line,
represented by Plucker coordinates. Moreover, a nonlinear optimization model
based on straight-line constraints is established. Subsequently, the
Levenberg-Marquardt algorithm (LMA) is employed to optimize parameters,
including time-offset, hand-eye extrinsic parameters, and straight-line
parameters. The feasibility and accuracy of the proposed approach are
quantitatively validated through experiments on curved weld scanning. We
open-sourced the code, dataset, and simulation report at
https://anonymous.4open.science/r/LVS_ST_CALIB-015F/README.md.

</details>


### [268] [Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators](https://arxiv.org/abs/2509.12969)
*Jae-Hyun Lee,Jonghoo Park,Kyu-Jin Cho*

Main category: cs.RO

TL;DR: 该研究提出了一种基于串联弹性驱动器（SEA）的肌腱本体感觉的拟人化欠驱动手，实现了对“手-物”交互的全面情境感知，无需视觉或触觉反馈。


<details>
  <summary>Details</summary>
Motivation: 为了在欠驱动系统中实现实用的抓握功能，需要将紧凑的传感与正确的解译相结合，以适应欠驱动的特性。

Method: 开发了一种紧凑、高精度、高可靠性的SEA，并将其集成到无传感器指体中。通过将本体感觉与基于势能的建模相结合，来估计抓握相关的变量，如接触时机、关节角度、相对物体刚度以及表明外部干扰的手指构型变化。

Result: 实验证明，所提出的方法能够实现抓握姿态重构、安全处理可变形物体，以及在仅依赖本体感觉的情况下识别不同几何形状和刚度的物体，从而实现盲抓。

Conclusion: 肌腱本体感觉是一种紧凑且鲁棒的传感方式，可以实现无需视觉或触觉反馈的实用操作。

Abstract: Anthropomorphic underactuated hands are widely employed for their versatility
and structural simplicity. In such systems, compact sensing integration and
proper interpretation aligned with underactuation are crucial for realizing
practical grasp functionalities. This study proposes an anthropomorphic
underactuated hand that achieves comprehensive situational awareness of
hand-object interaction, utilizing tendon-based proprioception provided by
series elastic actuators (SEAs). We developed a compact SEA with high accuracy
and reliability that can be seamlessly integrated into sensorless fingers. By
coupling proprioceptive sensing with potential energy-based modeling, the
system estimates key grasp-related variables, including contact timing, joint
angles, relative object stiffness, and finger configuration changes indicating
external disturbances. These estimated variables enable grasp posture
reconstruction, safe handling of deformable objects, and blind grasping with
proprioceptive-only recognition of objects with varying geometry and stiffness.
Finger-level experiments and hand-level demonstrations confirmed the
effectiveness of the proposed approach. The results demonstrate that
tendon-based proprioception serves as a compact and robust sensing modality for
practical manipulation without reliance on vision or tactile feedback.

</details>


### [269] [Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins](https://arxiv.org/abs/2509.12982)
*Erblin Isaku,Hassan Sartaj,Shaukat Ali,Beatriz Sanguino,Tongtong Wang,Guoyuan Li,Houxiang Zhang,Thomas Peyrucain*

Main category: cs.RO

TL;DR: 该研究提出了一种基于数字孪生的自适应机器人异常检测方法（ODiSAR），利用Transformer模型预测机器人状态，并通过重建误差和蒙特卡洛丢弃法量化不确定性，有效检测并解释异常行为。


<details>
  <summary>Details</summary>
Motivation: 复杂的、不确定的环境中的自适应机器人（SARs）必须主动检测和解决异常行为，包括分布外（OOD）情况。

Method: 提出一种基于数字孪生的OOD检测方法（ODiSAR），使用基于Transformer的数字孪生来预测SARs状态，并采用重建误差和蒙特卡洛丢弃法进行不确定性量化。

Result: ODiSAR在两个工业机器人场景（办公室导航和海上导航）的评估中，显示出高检测性能（AUROC高达98%，TNR@TPR95高达96%，F1分数高达95%），并能提供可解释的洞察以支持自适应。

Conclusion: ODiSAR通过结合重建误差和预测方差，能够有效检测OOD行为，即使在以前未见过的情况下也能检测。此外，该数字孪生还包含一个可解释性层，将潜在的OOD与特定的SARs状态联系起来，为自适应提供见解。

Abstract: Self-adaptive robots (SARs) in complex, uncertain environments must
proactively detect and address abnormal behaviors, including
out-of-distribution (OOD) cases. To this end, digital twins offer a valuable
solution for OOD detection. Thus, we present a digital twin-based approach for
OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to
forecast SAR states and employs reconstruction error and Monte Carlo dropout
for uncertainty quantification. By combining reconstruction error with
predictive variance, the digital twin effectively detects OOD behaviors, even
in previously unseen conditions. The digital twin also includes an
explainability layer that links potential OOD to specific SAR states, offering
insights for self-adaptation. We evaluated ODiSAR by creating digital twins of
two industrial robots: one navigating an office environment, and another
performing maritime ship navigation. In both cases, ODiSAR forecasts SAR
behaviors (i.e., robot trajectories and vessel motion) and proactively detects
OOD events. Our results showed that ODiSAR achieved high detection performance
-- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing
interpretable insights to support self-adaptation.

</details>


### [270] [DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception](https://arxiv.org/abs/2509.13024)
*Haohan Min,Zhoujian Li,Yu Yang,Jinyu Chen,Shenghai Yuan*

Main category: cs.RO

TL;DR: 本文提出了一种名为DVDP（直接视觉对接策略）的端到端视觉对接方法，仅需一个双目RGB-D摄像头即可直接输出机器人的对接路径，克服了传统视觉对接方法对初始位置的严格要求。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉对接方法对机器人初始位置要求较高，限制了其应用。

Method: 提出了一种名为DVDP（直接视觉对接策略）的端到端视觉对接方法，使用双目RGB-D摄像头直接输出机器人的对接路径。

Result: 在收集的大规模数据集上进行评估，并将DVDP与领先的感知主干网络进行基准测试，结果表明DVDP性能更优。在SCOUT Mini上的真实部署也证实了DVDP的有效性，生成的对接轨迹平滑、可行且满足物理约束。

Conclusion: DVDP是一种创新的端到端视觉对接方法，它克服了传统方法的局限性，并在模拟和真实环境中都取得了优越的性能。

Abstract: Automatic docking has long been a significant challenge in the field of
mobile robotics. Compared to other automatic docking methods, visual docking
methods offer higher precision and lower deployment costs, making them an
efficient and promising choice for this task. However, visual docking methods
impose strict requirements on the robot's initial position at the start of the
docking process. To overcome the limitations of current vision-based methods,
we propose an innovative end-to-end visual docking method named DVDP(direct
visual docking policy). This approach requires only a binocular RGB-D camera
installed on the mobile robot to directly output the robot's docking path,
achieving end-to-end automatic docking. Furthermore, we have collected a
large-scale dataset of mobile robot visual automatic docking dataset through a
combination of virtual and real environments using the Unity 3D platform and
actual mobile robot setups. We developed a series of evaluation metrics to
quantify the performance of the end-to-end visual docking method. Extensive
experiments, including benchmarks against leading perception backbones adapted
into our framework, demonstrate that our method achieves superior performance.
Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy,
with our model generating smooth, feasible docking trajectories that meet
physical constraints and reach the target pose.

</details>


### [271] [Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol](https://arxiv.org/abs/2509.13069)
*James C. Ward,Arthur Richards,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 本研究提出了一种用于动态环境的多机器人巡逻新方法，该方法能够进行完全分布式的在线环境动态监测和调整，并在高度动态的场景中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在安全、环境监测和灾难恢复等领域，使用机器人团队进行持续监测越来越受关注。在完全分布式的在线模式下执行此类监测，在鲁棒性、适应性和可扩展性方面具有显著优势，并能在现实世界中有效适应不断变化的环境。

Method: 提出了一种在完全分布式的在线模式下进行监测和调整环境动态的多机器人巡逻新方法。

Result: 所提出的方法在高度动态的场景中显著优于现实基线。

Conclusion: 所提出的方法在动态环境中表现出色，并探讨了在某些情况下，显式考虑环境动态可能是不必要的或不切实际的。

Abstract: Persistent monitoring using robot teams is of interest in fields such as
security, environmental monitoring, and disaster recovery. Performing such
monitoring in a fully on-line decentralised fashion has significant potential
advantages for robustness, adaptability, and scalability of monitoring
solutions, including, in principle, the capacity to effectively adapt in
real-time to a changing environment. We examine this through the lens of
multi-robot patrol, in which teams of patrol robots must persistently minimise
time between visits to points of interest, within environments where
traversability of routes is highly dynamic. These dynamics must be observed by
patrol agents and accounted for in a fully decentralised on-line manner. In
this work, we present a new method of monitoring and adjusting for environment
dynamics in a decentralised multi-robot patrol team. We demonstrate that our
method significantly outperforms realistic baselines in highly dynamic
scenarios, and also investigate dynamic scenarios in which explicitly
accounting for environment dynamics may be unnecessary or impractical.

</details>


### [272] [Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five](https://arxiv.org/abs/2509.13074)
*Simon Fritsch,Liam Achenbach,Riccardo Bianco,Nicola Irmiger,Gawain Marti,Samuel Visca,Chenyu Yang,Davide Liconti,Barnabas Gavin Cangan,Robert Jomar Malate,Ronan J. Hinchet,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SABD手是一个16自由度的仿生机械手，通过合并指关节减少了驱动器数量，扩展了抓取范围，并能实现超越人类能力的抓握姿态。


<details>
  <summary>Details</summary>
Motivation: 为了扩展抓取范围、实现超越人类能力的抓握姿态并减少驱动器数量，本研究设计了一种新型机械手。

Method: 通过将第四、五指的内收/外展（Add/Abd）关节合并为一个具有大运动范围的单一关节，增加了手指的运动空间。

Result: 实验结果表明，该设计将手指的运动空间增加了400%，并能抓取最大侧面距离为200毫米的物体。强化学习研究表明，该设计能够实现更有效的抓握策略，以处理更大的物体并提高抓握稳定性。在遥操作试验中，该机械手在YCB对象上的抓握成功率为86%，包括具有挑战性的非仿生配置。

Conclusion: SABD手的合并内收/外展关节设计提高了抓握的稳定性、灵活性和灵巧性，同时没有增加复杂性，适用于多种应用场景。

Abstract: This paper presents the SABD hand, a 16-degree-of-freedom (DoF) robotic hand
that departs from purely anthropomorphic designs to achieve an expanded grasp
envelope, enable manipulation poses beyond human capability, and reduce the
required number of actuators. This is achieved by combining the
adduction/abduction (Add/Abd) joint of digits four and five into a single joint
with a large range of motion. The combined joint increases the workspace of the
digits by 400\% and reduces the required DoFs while retaining dexterity.
Experimental results demonstrate that the combined Add/Abd joint enables the
hand to grasp objects with a side distance of up to 200 mm. Reinforcement
learning-based investigations show that the design enables grasping policies
that are effective not only for handling larger objects but also for achieving
enhanced grasp stability. In teleoperated trials, the hand successfully
performed 86\% of attempted grasps on suitable YCB objects, including
challenging non-anthropomorphic configurations. These findings validate the
design's ability to enhance grasp stability, flexibility, and dexterous
manipulation without added complexity, making it well-suited for a wide range
of applications.

</details>


### [273] [A Design Co-Pilot for Task-Tailored Manipulators](https://arxiv.org/abs/2509.13077)
*Jonathan Külz,Sehoon Ha,Matthias Althoff*

Main category: cs.RO

TL;DR: 自动化设计和优化机器人形态以适应特定环境，缩短设计周期，并能适应不同硬件限制，最终在现实世界中得到成功应用。


<details>
  <summary>Details</summary>
Motivation: 通用机器人设计在各种应用中表现不佳，定制化开发成本高昂。当前的方法依赖于耗时的优化过程。

Method: 提出一种自动设计和优化机器人形态的方法，通过可微分框架学习逆运动学，并进行基于梯度的微调，加速设计过程。

Result: 所提出的方法能够生成在杂乱环境中导航、在指定工作空间内表现良好且能适应不同硬件约束的机器人。

Conclusion: 该方法通过生成式设计加速了专用机器人的设计，能够实现即时适应和有效的人机协作，并在现实世界中得到验证。

Abstract: Although robotic manipulators are used in an ever-growing range of
applications, robot manufacturers typically follow a ``one-fits-all''
philosophy, employing identical manipulators in various settings. This often
leads to suboptimal performance, as general-purpose designs fail to exploit
particularities of tasks. The development of custom, task-tailored robots is
hindered by long, cost-intensive development cycles and the high cost of
customized hardware. Recently, various computational design methods have been
devised to overcome the bottleneck of human engineering. In addition, a surge
of modular robots allows quick and economical adaptation to changing industrial
settings. This work proposes an approach to automatically designing and
optimizing robot morphologies tailored to a specific environment. To this end,
we learn the inverse kinematics for a wide range of different manipulators. A
fully differentiable framework realizes gradient-based fine-tuning of designed
robots and inverse kinematics solutions. Our generative approach accelerates
the generation of specialized designs from hours with optimization-based
methods to seconds, serving as a design co-pilot that enables instant
adaptation and effective human-AI collaboration. Numerical experiments show
that our approach finds robots that can navigate cluttered environments,
manipulators that perform well across a specified workspace, and can be adapted
to different hardware constraints. Finally, we demonstrate the real-world
applicability of our method by setting up a modular robot designed in
simulation that successfully moves through an obstacle course.

</details>


### [274] [Empowering Multi-Robot Cooperation via Sequential World Models](https://arxiv.org/abs/2509.13095)
*Zijie Zhao,Honglei Guo,Shengqian Chen,Kaixuan Xu,Bo Jiang,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.RO

TL;DR: SeqWM是一个新颖的框架，通过顺序通信和代理级世界模型来解决多机器人协同中的复杂联合动力学问题，提高了样本效率和协同性能，并在模拟和物理环境中都取得了成功。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，基于模型强化学习（MBRL）虽然显示出巨大潜力，但在多机器人协同方面，由于联合动力学的复杂性，仍然面临挑战。

Method: 提出了一种名为顺序世界模型（SeqWM）的新颖框架，该框架将顺序范式集成到基于模型的多智能体强化学习中。SeqWM采用独立的、顺序结构化的代理级世界模型来分解复杂的联合动力学。通过顺序通信进行潜在的轨迹生成和决策制定，每个代理根据其前驱的预测来生成未来的轨迹和规划其动作。

Result: 在具有挑战性的模拟环境（Bi-DexHands和Multi-Quad）中，SeqWM在整体性能和样本效率方面均优于现有的无模型和基于模型的基线方法，并展现出预测适应和角色划分等高级协同行为。此外，SeqWM已成功部署到物理四足机器人上，证明了其在真实多机器人系统中的有效性。

Conclusion: SeqWM通过分解复杂联合动力学和实现显式意图共享，有效解决了多机器人协同中的挑战，并在模拟和物理环境中都取得了优于现有方法的性能。

Abstract: Model-based reinforcement learning (MBRL) has shown significant potential in
robotics due to its high sample efficiency and planning capability. However,
extending MBRL to multi-robot cooperation remains challenging due to the
complexity of joint dynamics. To address this, we propose the Sequential World
Model (SeqWM), a novel framework that integrates the sequential paradigm into
model-based multi-agent reinforcement learning. SeqWM employs independent,
sequentially structured agent-wise world models to decompose complex joint
dynamics. Latent rollouts and decision-making are performed through sequential
communication, where each agent generates its future trajectory and plans its
actions based on the predictions of its predecessors. This design enables
explicit intention sharing, enhancing cooperative performance, and reduces
communication overhead to linear complexity. Results in challenging simulated
environments (Bi-DexHands and Multi-Quad) show that SeqWM outperforms existing
state-of-the-art model-free and model-based baselines in both overall
performance and sample efficiency, while exhibiting advanced cooperative
behaviors such as predictive adaptation and role division. Furthermore, SeqWM
has been success fully deployed on physical quadruped robots, demonstrating its
effectiveness in real-world multi-robot systems. Demos and code are available
at: https://github.com/zhaozijie2022/seqwm-marl

</details>


### [275] [Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation](https://arxiv.org/abs/2509.13126)
*Miquel Oller,An Dang,Nima Fazeli*

Main category: cs.RO

TL;DR: 该论文提出了一种计算高效的非完整流体弹塑性模型，用于模拟机器人触觉传感器中由顺应性引起的复杂非线性动力学，实现了对路径依赖的接触力和动态表面积变化的精确建模。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器研究忽视了其固有的顺应性，而顺应性是实现丰富力交互的关键。本文旨在解决由顺应性元件引入的复杂非线性动力学建模的挑战。

Method: 提出了一种计算高效的非完整流体弹塑性模型，通过扩展物体状态空间（显式包含顺应性传感器产生的分布式力）来捕获路径依赖的接触力和动态表面积变化。该模型是可微分的，支持基于梯度的轨迹优化。

Result: 该模型能够准确模拟路径依赖的接触力分布和动态表面积变化，并且支持梯度优化的轨迹优化。在模拟和真实世界的实验中均证明了其有效性。

Conclusion: 对触觉传感器动力学中的路径依赖性进行建模对于实现先进的机器人感知和交互至关重要。

Abstract: Tactile sensors have long been valued for their perceptual capabilities,
offering rich insights into the otherwise hidden interface between the robot
and grasped objects. Yet their inherent compliance -- a key driver of
force-rich interactions -- remains underexplored. The central challenge is to
capture the complex, nonlinear dynamics introduced by these passive-compliant
elements. Here, we present a computationally efficient non-holonomic
hydroelastic model that accurately models path-dependent contact force
distributions and dynamic surface area variations. Our insight is to extend the
object's state space, explicitly incorporating the distributed forces generated
by the compliant sensor. Our differentiable formulation not only accounts for
path-dependent behavior but also enables gradient-based trajectory
optimization, seamlessly integrating with high-resolution tactile feedback. We
demonstrate the effectiveness of our approach across a range of simulated and
real-world experiments and highlight the importance of modeling the path
dependence of sensor dynamics.

</details>


### [276] [An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios](https://arxiv.org/abs/2509.13132)
*Zhihao Zhang,Chengyang Peng,Minghao Zhu,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: UWDT是一个新的框架，它结合了多通道鸟瞰图占用栅格和基于Transformer的序列建模，用于复杂环形交叉路口场景中的战术驾驶。它使用不确定性加权来解决低风险和高风险决策之间的不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 为了在密集、动态的环境中实现自动驾驶，需要能够利用空间结构和长时序依赖关系，并能应对不确定性的决策系统。

Method: UWDT采用冻结的教师Transformer来估计每个token的预测熵，并将其用作学生模型损失函数中的权重，以解决低风险和高风险状态之间的不平衡问题。

Result: 在不同交通密度下，UWDT在环形交叉路口模拟器中，在奖励、碰撞率和行为稳定性方面持续优于其他基线。

Conclusion: 不确定性感知、时空Transformer可以为复杂交通环境中的自动驾驶提供更安全、更有效的决策。

Abstract: Autonomous driving in dense, dynamic environments requires decision-making
systems that can exploit both spatial structure and long-horizon temporal
dependencies while remaining robust to uncertainty. This work presents a novel
framework that integrates multi-channel bird's-eye-view occupancy grids with
transformer-based sequence modeling for tactical driving in complex roundabout
scenarios. To address the imbalance between frequent low-risk states and rare
safety-critical decisions, we propose the Uncertainty-Weighted Decision
Transformer (UWDT). UWDT employs a frozen teacher transformer to estimate
per-token predictive entropy, which is then used as a weight in the student
model's loss function. This mechanism amplifies learning from uncertain,
high-impact states while maintaining stability across common low-risk
transitions. Experiments in a roundabout simulator, across varying traffic
densities, show that UWDT consistently outperforms other baselines in terms of
reward, collision rate, and behavioral stability. The results demonstrate that
uncertainty-aware, spatial-temporal transformers can deliver safer and more
efficient decision-making for autonomous driving in complex traffic
environments.

</details>


### [277] [ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation](https://arxiv.org/abs/2509.13177)
*Salvatore Esposito,Matías Mattamala,Daniel Rebain,Francis Xiatian Zhang,Kevin Dhaliwal,Mohsen Khadem,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 该研究提出了ROOM（Realistic Optical Observation in Medicine）模拟框架，用于生成逼真的支气管镜检查训练数据，以解决目前缺乏真实训练和测试环境的问题。


<details>
  <summary>Details</summary>
Motivation: 目前， the development of continuum robots for bronchoscopy is limited by the lack of realistic training and test environments. Real data is difficult to collect due to ethical constraints and patient safety concerns, and developing autonomy algorithms requires realistic imaging and physical feedback.

Method: ROOM利用患者的CT扫描生成多模态传感器数据，包括带有真实噪声和光照反射的RGB图像、深度图、表面法线、光流和点云。

Result: 通过在多视图姿态估计和单目深度估计这两个典型医学机器人任务中验证ROOM生成的数据，证明了ROOM能够生成具有挑战性的数据，并表明使用ROOM生成的数据可以对现有的深度估计模型进行微调，以应对这些挑战。

Conclusion: ROOM能够生成大量跨越不同患者解剖结构和临床环境中难以捕捉的手术场景的数据，从而促进医学机器人领域的发展。

Abstract: Continuum robots are advancing bronchoscopy procedures by accessing complex
lung airways and enabling targeted interventions. However, their development is
limited by the lack of realistic training and test environments: Real data is
difficult to collect due to ethical constraints and patient safety concerns,
and developing autonomy algorithms requires realistic imaging and physical
feedback. We present ROOM (Realistic Optical Observation in Medicine), a
comprehensive simulation framework designed for generating photorealistic
bronchoscopy training data. By leveraging patient CT scans, our pipeline
renders multi-modal sensor data including RGB images with realistic noise and
light specularities, metric depth maps, surface normals, optical flow and point
clouds at medically relevant scales. We validate the data generated by ROOM in
two canonical tasks for medical robotics -- multi-view pose estimation and
monocular depth estimation, demonstrating diverse challenges that
state-of-the-art methods must overcome to transfer to these medical settings.
Furthermore, we show that the data produced by ROOM can be used to fine-tune
existing depth estimation models to overcome these challenges, also enabling
other downstream applications such as navigation. We expect that ROOM will
enable large-scale data generation across diverse patient anatomies and
procedural scenarios that are challenging to capture in clinical settings. Code
and data: https://github.com/iamsalvatore/room.

</details>


### [278] [StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening](https://arxiv.org/abs/2509.13200)
*Moonyoung Lee,Dong Ki Kim,Jai Krishna Bandi,Max Smith,Aileen Liao,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: StageACT是一个模仿学习框架，通过引入任务阶段信息来提高人形机器人开门的成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开门是人形机器人必须掌握的一项基本技能，但由于门闩状态等不确定因素，使得该任务充满挑战，标准模仿学习方法容易出现模式崩溃。

Method: 提出StageACT框架，将任务阶段信息作为输入，增强低层策略，以应对部分可观察性问题。

Result: 在真实办公环境中，StageACT使人形机器人开此前未见过门的成功率达到55%，是现有基线方法的两倍以上。该方法还能通过阶段提示实现意图行为引导和恢复行为。

Conclusion: 阶段条件化是一种简单有效的方法，可以显著提升人形机器人在长序列操作任务中的表现。

Abstract: Humanoid robots promise to operate in everyday human environments without
requiring modifications to the surroundings. Among the many skills needed,
opening doors is essential, as doors are the most common gateways in built
spaces and often limit where a robot can go. Door opening, however, poses
unique challenges as it is a long-horizon task under partial observability,
such as reasoning about the door's unobservable latch state that dictates
whether the robot should rotate the handle or push the door. This ambiguity
makes standard behavior cloning prone to mode collapse, yielding blended or
out-of-sequence actions. We introduce StageACT, a stage-conditioned imitation
learning framework that augments low-level policies with task-stage inputs.
This effective addition increases robustness to partial observability, leading
to higher success rates and shorter completion times. On a humanoid operating
in a real-world office environment, StageACT achieves a 55% success rate on
previously unseen doors, more than doubling the best baseline. Moreover, our
method supports intentional behavior guidance through stage prompting, enabling
recovery behaviors. These results highlight stage conditioning as a lightweight
yet powerful mechanism for long-horizon humanoid loco-manipulation.

</details>


### [279] [Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum](https://arxiv.org/abs/2509.13239)
*Tianxu An,Flavio De Vincenti,Yuntao Ma,Marco Hutter,Stelian Coros*

Main category: cs.RO

TL;DR: 该研究提出了一种分层强化学习（RL）流程，用于训练单腿机器人执行端到端的拾取-放置（P&P）任务，并扩展到双机器人协作场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决长时序P&P任务的RL训练效率和双机器人协作问题，提出了一种新的动态奖励课程，引导智能体学习任务。

Method: 采用分层RL流程，并引入动态奖励课程，使单个策略能够通过逐步引导智能体完成以负载为中心的子目标来学习长时序P&P操作。在双机器人场景下，策略使每个机器人能够关注其观测空间的特定部分，并通过自主注意力转移促进有效协调。

Result: 与现有的长时序RL任务方法相比，该方法在训练效率上提高了55%，在仿真实验中执行时间减少了18.6%。在双机器人场景下，验证了其有效的协调能力。

Conclusion: 该研究首次提出了一个完整的、端到端的、基于RL的P&P流程，用于双腿机器人协作完成拾取-放置任务，并通过真实世界实验进行了验证。

Abstract: We present a hierarchical RL pipeline for training one-armed legged robots to
perform pick-and-place (P&P) tasks end-to-end -- from approaching the payload
to releasing it at a target area -- in both single-robot and cooperative
dual-robot settings. We introduce a novel dynamic reward curriculum that
enables a single policy to efficiently learn long-horizon P&P operations by
progressively guiding the agents through payload-centered sub-objectives.
Compared to state-of-the-art approaches for long-horizon RL tasks, our method
improves training efficiency by 55% and reduces execution time by 18.6% in
simulation experiments. In the dual-robot case, we show that our policy enables
each robot to attend to different components of its observation space at
distinct task stages, promoting effective coordination via autonomous attention
shifts. We validate our method through real-world experiments using ANYmal D
platforms in both single- and dual-robot scenarios. To our knowledge, this is
the first RL pipeline that tackles the full scope of collaborative P&P with two
legged manipulators.

</details>


### [280] [Design and Control of a Perching Drone Inspired by the Prey-Capturing Mechanism of Venus Flytrap](https://arxiv.org/abs/2509.13249)
*Ye Li,Daming Liu,Yanhe Zhu,Junming Zhang,Yongsheng Luo,Ziqi Wang,Chenyu Liu,Jie Zhao*

Main category: cs.RO

TL;DR: 本论文提出了一种受捕蝇草启发的仿生倾斜无人机，可在100毫秒内实现快速倾斜，并通过基于级联扩展高增益观测器（EHGO）的控制方法来增强稳定性和抵抗外部干扰的能力。


<details>
  <summary>Details</summary>
Motivation: 为了延长无人机的任务续航时间，研究了利用着陆机制来节省能量。

Method: 提出了一种受捕蝇草启发的<seg_13>夹式无人机，并开发了一种基于级联扩展高增益观测器（EHGO）的控制方法。

Result: 实验结果表明，该仿生着陆结构具有良好的适应性，并且级联EHGO在抵抗风力和着陆干扰方面表现优越。

Conclusion: 所提出的仿生着陆方法和控制策略能够有效延长无人机的续航时间和提高其稳定性。

Abstract: The endurance and energy efficiency of drones remain critical challenges in
their design and operation. To extend mission duration, numerous studies
explored perching mechanisms that enable drones to conserve energy by
temporarily suspending flight. This paper presents a new perching drone that
utilizes an active flexible perching mechanism inspired by the rapid predation
mechanism of the Venus flytrap, achieving perching in less than 100 ms. The
proposed system is designed for high-speed adaptability to the perching
targets. The overall drone design is outlined, followed by the development and
validation of the biomimetic perching structure. To enhance the system
stability, a cascade extended high-gain observer (EHGO) based control method is
developed, which can estimate and compensate for the external disturbance in
real time. The experimental results demonstrate the adaptability of the
perching structure and the superiority of the cascaded EHGO in resisting wind
and perching disturbances.

</details>


### [281] [HARMONIC: A Content-Centric Cognitive Robotic Architecture](https://arxiv.org/abs/2509.13279)
*Sanjay Oruganti,Sergei Nirenburg,Marjorie McShane,Jesse English,Michael K. Roberts,Christian Arndt,Carlos Gonzalez,Mingyo Seo,Luis Sentis*

Main category: cs.RO

TL;DR: HARMONIC是一个认知机器人架构，旨在提高人机协作中的安全性、质量、可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决机器人与人类协作中的数据稀缺、可解释性和安全性问题，并提升透明度和信任度。

Method: 提出HARMONIC认知机器人架构，支持语义感知解释、类人决策和意图化语言交流，并开发了两个基于HARMONIC的机器人系统，在仿真和物理平台上进行了演示。

Result: 通过两个基于HARMONIC的机器人系统在仿真和物理平台上的演示，证明了该架构在提高机器人与人类协作中的安全性、质量、可解释性和信任度方面的有效性。

Conclusion: HARMONIC架构能够有效提升人机协作中的机器人性能，特别是在安全性、质量、可解释性和信任度方面。

Abstract: This paper introduces HARMONIC, a cognitive-robotic architecture designed for
robots in human-robotic teams. HARMONIC supports semantic perception
interpretation, human-like decision-making, and intentional language
communication. It addresses the issues of safety and quality of results; aims
to solve problems of data scarcity, explainability, and safety; and promotes
transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are
demonstrated, each implemented in both a high-fidelity simulation environment
and on physical robotic platforms.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [282] [Skeletal editing by tip-induced chemistry](https://arxiv.org/abs/2509.12433)
*Shantanu Mishra,Valentina Malave,Rasmus Svensson,Henrik Grönbeck,Florian Albrecht,Diego Peña,Leo Gross*

Main category: cond-mat.mes-hall

TL;DR: 通过扫描探针显微镜和密度泛函理论计算，实现了在单分子尺度上对含氧七元环进行骨架编辑，生成了苝骨架分子，拓展了尖端诱导化学的应用。


<details>
  <summary>Details</summary>
Motivation: 将分子骨架编辑的范围从溶液相合成扩展到单分子尺度，以实现对分子结构的精确控制和新分子的合成。

Method: 使用原子力显微镜和扫描隧道显微镜，通过尖端诱导的方式，对负载在NaCl薄膜上的含氧七元环进行氧原子脱除和环收缩反应，生成苝骨架分子。利用密度泛函理论计算辅助解析反应机理。

Result: 成功在单分子尺度上实现了含氧七元环的骨架编辑，生成了苝骨架分子，并通过高分辨率显微成像技术表征了产物的分子结构和轨道密度。

Conclusion: 该研究将尖端诱导化学应用于单分子合成，实现了在单分子尺度上对分子结构的精确编辑，为药物发现和绿色化学提供了新的工具和途径。

Abstract: Skeletal editing of cyclic molecules has garnered considerable attention in
the context of drug discovery and green chemistry, with notable examples in
solution-phase synthesis. Here, we extend the scope of skeletal editing to the
single-molecule scale. We demonstrate tip-induced oxygen deletion and ring
contraction of an oxygen-containing seven-membered ring on bilayer NaCl films
to generate molecules containing the perylene skeleton. The products were
identified and characterized by atomic force and scanning tunneling
microscopies, which provided access to bond-resolved molecular structures and
orbital densities. Insights into the reaction mechanisms were obtained by
density functional theory calculations. Our work expands the toolbox of
tip-induced chemistry for single-molecule synthesis.

</details>


### [283] [Topological Phononic Crystal on the Scale of Quasi-Ballistic Phonon Transport](https://arxiv.org/abs/2509.12528)
*Keita Funayama,Yuki Akura,Hiroya Tanaka,Jun Hirotani*

Main category: cond-mat.mes-hall

TL;DR: 利用拓扑声子晶体实现了准弹道声子输运的热管理。


<details>
  <summary>Details</summary>
Motivation: 在基于准弹道声子输运的半导体器件热管理方面，设计精确热特性的挑战依然存在。

Method: 使用基于1D Su-Schrieffer-Heeger模型的拓扑声子晶体，通过微热反射技术实验研究了准弹道声子输运尺度的热行为。

Result: 实验观察到准弹道声子输运现象，发现热导率随拓扑系统结构参数的变化而变化，且实验结果与基于拓扑界面态的理论预测吻合良好。

Conclusion: 拓扑学是微纳系统中准弹道声子输运热管理的有效方法，为实现波动和扩散现象（如准弹道声子）的统一控制提供了途径。

Abstract: Phonon engineering technology has opened up the functional thermal management
of semiconductor-based classical and quantum electronics at the micro- and
nanoscales. However, challenges have remained in designing accurate thermal
characteristics based on quasi-ballistic phonon transport. The quasi-ballistic
thermal transport arises from the combination of wave-like and diffusive phonon
behaviors unlike pure diffusion. The topological nature has been known to be
compatible with both wave and diffusive phenomena. Therefore, topological
phononic crystals have great potential for the development of controllable and
designable thermal transport based on quasi-ballistic phonons. In this study,
we experimentally investigated the thermal behavior at the scale of
quasi-ballistic phonon transport using a 1D Su-Schrieffer-Heeger model-based
topological phononic crystal. Quasi-ballistic phonon transport was observed
through change in thermal conductivity depending on the structural parameters
of topological systems using micro-thermoreflectance. Furthermore, using
topological interface states, the experimentally observed thermal behaviors
were found to agree well with the theoretically expected those. Accordingly,
the topological nature is an effective approach for thermal management in
micro- and nanoscale systems with quasi-ballistic phonon transport. Our results
pave the way for a unified control scheme for wave and diffusion phenomena,
such as quasi-ballistic phonons.

</details>


### [284] [Reentrant localization in fractionally charged electron wave packets](https://arxiv.org/abs/2509.12532)
*Y. Yin*

Main category: cond-mat.mes-hall

TL;DR: 分数量子电荷电子波包在量子导体中的局域化转变是单向的，而中性电子-空穴对的转变是双向的，具体取决于电压脉冲的长尾行为。


<details>
  <summary>Details</summary>
Motivation: 研究分数量子电荷电子波包在量子导体中经历的局域化转变，特别是与中性电子-空穴对的转变行为的对比。

Method: 通过施加任意磁通量的单电压脉冲，研究分数量子电荷电子波包的局域化转变，并分析电压脉冲长尾行为对中性电子-空穴对转变方向的影响。

Result: 个体电子或空穴的转变是单向的，即从非局域化到局域化；中性电子-空穴对的转变是双向的，其方向取决于电压脉冲的尾部衰减特性（快于或慢于洛伦兹衰减）。长尾脉冲导致从局域化到非局域化的转变，而短尾脉冲则导致从非局域化到局域化的转变，并可能出现重入局域化现象。

Conclusion: 电压脉冲的尾部行为是控制中性电子-空穴对局域化转变方向的关键因素，这与个体电子或空穴的单向转变行为形成对比。洛伦兹衰减脉冲的情况下，中性电子-空穴对的局域化状态无法被激发。

Abstract: We investigate the localization transition in fractionally charged electron
wave packets, which is injected into a quantum conductor by a single voltage
pulse with arbitrary flux quantum. We show that the transition is
unidirectional for individual electrons or holes. They always undergo a
delocalization-to-localization transition as the flux increases. In contrast,
the transition of the neutral electron-hole pairs is bidirectional. As the flux
increases, the transition can be a localization-to-delocalization transition or
vice versa, which is controlled via the long-time tail of the voltage pulse.
The localization-to-delocalization transition occurs in the case of
short-tailed pulses, which decay faster than Lorentzian. In this case, the
directions of the transitions for the neutral eh pairs and individual electrons
or holes are opposite. Certain localized neutral electron-hole pairs can first
evolve into delocalized ones, then split into individual electrons and holes
with localized wave functions, which gives a reentrant localization. The
delocalization-to-localization transition occurs in the case of long-tailed
pulses, which decay slower than Lorentzian. The reentrant localization vanishes
in this case, as the directions of the two transitions are the same. It is also
absent in the case of Lorentzian pulses, where the localized neutral
electron-hole pairs cannot be excited at all.

</details>


### [285] [Symmetry and Topology of Successive Quantum Feedback Control](https://arxiv.org/abs/2509.12637)
*Junxuan Wen,Zongping Gong,Takahiro Sagawa*

Main category: cond-mat.mes-hall

TL;DR: 我们对一类通用的量子反馈控制建立了对称性分类。对于具有正Kraus算符的非自适应的纯粹测量序列的连续反馈控制，我们证明了对称性分类会崩溃为十类AZ$^	ext{†}$类，这规定了与反馈控制相关的CPTP映射的允许拓扑。我们证明了一个具有高斯测量误差的चक्रवात麦克斯韦妖精表现出量化的绕组数。此外，对于一般的（非纯粹）测量，我们显式地构造了一个不属于十类分类的协议。这些结果拓宽并阐明了在工程化量子控制的拓扑方面，使其能够抵抗无序和不完善性。


<details>
  <summary>Details</summary>
Motivation: 对于一类通用的量子反馈控制，需要建立对称性分类，以理解和工程化其拓扑特性，并抵抗无序和不完善性。

Method: 对具有正Kraus算符的非自适应纯粹测量序列的连续反馈控制，进行了对称性分类，并证明其崩溃为十类AZ$^	ext{†}$类。分析了具有高斯测量误差的चक्रवात麦克斯韦妖精，并证明了其量化绕组数。构造了一个不属于十类分类的一般（非纯粹）测量协议。

Result: 证明了连续反馈控制的对称性分类崩溃为十类AZ$^	ext{†}$类。证明了具有高斯测量误差的चक्रवात麦克斯韦妖精表现出量化的绕组数。构造了一个不属于十类分类的一般测量协议。

Conclusion: 研究结果拓宽并阐明了在工程化量子控制的拓扑方面，使其能够抵抗无序和不完善性的原理。

Abstract: We establish a symmetry classification for a general class of quantum
feedback control. For successive feedback control with a non-adaptive sequence
of bare measurements (i.e., with positive Kraus operators), we prove that the
symmetry classification collapses to the ten-fold AZ$^\dagger$ classes,
specifying the allowed topology of CPTP maps associated with feedback control.
We demonstrate that a chiral Maxwell's demon with Gaussian measurement errors
exhibits quantized winding numbers. Moreover, for general (non-bare)
measurements, we explicitly construct a protocol that falls outside the
ten-fold classification. These results broaden and clarify the principles in
engineering topological aspects of quantum control robust against disorder and
imperfections.

</details>


### [286] [Anomalous inverse Faraday effect for graphene quantum dots in optical vortices](https://arxiv.org/abs/2509.12654)
*Zi-Yang Xu,Wei E. I. Sha,Hang Xie*

Main category: cond-mat.mes-hall

TL;DR: 二维材料中的手征光子相互作用可实现前所未有的量子现象控制。本文研究了在 А-002 偏振光涡旋照明下石墨烯量子点（GQD）中的反常逆法拉第效应（IFE），其中转移的轨道角动量（OAM）产生光诱导磁矩。


<details>
  <summary>Details</summary>
Motivation: 探索手征光子与二维材料的相互作用，特别是研究光涡旋照明下石墨烯量子点中的反常逆法拉第效应。

Method: 利用新开发的时间相关量子微扰框架 [Phys. Rev. B 110, 085425 (2024)]。

Result: 观察到反常现象：在轴外位置出现反向磁矩，表现为与涡旋螺旋波前反向旋转的电流。OAM 转移效率远低于其自旋对应物。

Conclusion: 该研究首次实现了量子工程二维系统中光 OAM 到磁化的转换新范式。

Abstract: Chiral photon interactions with two-dimensional (2D) materials enable
unprecedented control of quantum phenomena. In this paper, we report anomalous
inverse Faraday effects (IFE) in graphene quantum dots (GQDs) under linearly
polarized optical vortex illumination, where transferred orbital angular
momentum (OAM) generates light-induced magnetic moments. Employing our recently
developed time-dependent quantum perturbation framework [Phys. Rev. B 110,
085425 (2024)], we demonstrate a counterintuitive observation: some reversed
magnetic moments at off-axis positions occur-manifested as counter-rotating
currents to the vortex helical wavefront. Phase-difference analysis and
eigenmode decomposition resolve this anomaly, revealing that the OAM transfer
efficiency is orders of magnitude weaker than its spin counterpart. This work
establishes a new paradigm for optical OAM-to-magnetization conversion in
quantum-engineered 2D systems.

</details>


### [287] [Algebraic solution and thermodynamic properties of graphene in the presence of minimal length](https://arxiv.org/abs/2509.12793)
*J. Gbètoho,F. A. Dossa,G. Y. H. Avossevou*

Main category: cond-mat.mes-hall

TL;DR: Graphene in a magnetic field with a minimal length exhibits hidden su(1,1) symmetry, allowing for algebraic spectrum construction. This leads to control over bound states and verification of the Dulong-Petit law for thermodynamic properties, with heat capacity independent of the deformation parameter.


<details>
  <summary>Details</summary>
Motivation: To investigate the properties of graphene under a magnetic field in the presence of a minimal length, particularly its hidden symmetries and their implications for its spectrum and thermodynamic behavior.

Method: Constructing the spectrum algebraically using the hidden su(1,1) symmetry. Using the partition function based on the Epstein zeta function to determine thermodynamic properties.

Result: A hidden su(1,1) symmetry was found in graphene under a magnetic field with a minimal length. The algebraic method successfully constructed the spectrum. The Dulong-Petit law was verified, and the heat capacity was found to be independent of the deformation parameter.

Conclusion: The presence of a minimal length in graphene under a magnetic field leads to a hidden su(1,1) symmetry, which is crucial for algebraic spectrum construction and understanding its thermodynamic properties. The Dulong-Petit law is satisfied, and the heat capacity shows independence from the deformation parameter, suggesting a robust behavior of these systems.

Abstract: Graphene is a zero-gap semiconductor, where the electrons propagating inside
are described by the ultra-relativistic Dirac equation normally reserved for
very high energy massless particles. In this work, we show that graphene under
a magnetic field in the presence of a minimal length has a hidden $su(1,1)$
symmetry. This symmetry allows us to construct the spectrum algebraically. In
fact, a generalized uncertainty relation, leading to a non-zero minimum
uncertainty on the position, would be closer to physical reality and allow us
to control or create bound states in graphene. Using the partition function
based on the Epstein zeta function, the thermodynamic properties are well
determined. We find that the Dulong-Petit law is verified and the heat capacity
is independent of the deformation parameter.

</details>


### [288] [Sources of nonlinearity in the response of a driven nano-electromechanical resonator](https://arxiv.org/abs/2509.12830)
*Sofia Sevitz,Kushagra Aggarwal,Jorge Tabanera-Bravo,Juliette Monsel,Florian Vigneau,Federico Fedele,Joe Dunlop,Juan M. R. Parrondo,Gerard J. Milburn,Janet Anders,Natalia Ares,Federico Cerisola*

Main category: cond-mat.mes-hall

TL;DR: 利用悬挂的碳纳米管研究电子传输和非线性机械运动的相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究电子传输和非线性机械运动的相互作用，特别是利用包含静电定义的量子点的外部驱动悬挂碳纳米管。

Method: 观察和模拟了由机电耦合和谐振器固有非线性引起的拱形共振现象。

Result: 在强驱动下，电子传输中出现了拱形共振，模型与实验测量结果吻合良好。

Conclusion: 该研究为利用介观机电谐振器探索非线性现象铺平了道路。

Abstract: Nanoelectromechanical resonators provide an ideal platform for investigating
the interplay between electron transport and nonlinear mechanical motion.
Externally driven suspended carbon nanotubes, containing an electrostatically
defined quantum dot are especially promising. These devices possess two main
sources of nonlinearity: the electromechanical coupling and the intrinsic
contributions of the resonator that induce a Duffing-like nonlinear behavior.
In this work, we observe the interplay between the two sources across different
driving regimes. The main nonlinear feature we observe is the emergence of
arch-like resonances in the electronic transport when the resonator is strongly
driven. We show that our model is in good agreement with our experimental
electron transport measurements on a suspended carbon nanotube. This
characterization paves the way for the exploration of nonlinear phenomena using
mesoscopic electromechanical resonators.

</details>


### [289] [Engineering strong correlations in a perfectly aligned dual moiré system](https://arxiv.org/abs/2509.13159)
*Amine Ben Mhenni,Elif Çetiner,Kenji Watanabe,Takashi Taniguchi,Jonathan J. Finley,Nathan P. Wilson*

Main category: cond-mat.mes-hall

TL;DR: 文章提出了一个具有完美平移和旋转对齐的双莫尔体系，利用扭曲的六方氮化硼（hBN）双层结构来生成静电莫尔势并分离MoSe2和WSe2单层。


<details>
  <summary>Details</summary>
Motivation: 探索强相互作用玻色子在晶格中产生的奇异集体现象，但缺乏稳健且可调的固态平台。

Method: 利用扭曲的六方氮化硼（hBN）双层结构实现双莫尔体系的完美对齐，并实现静电可编程以调整相互作用。

Result: 观察到由层内相互作用驱动的强关联电子相，并发现了被莫特绝缘态捕获的层间Rydberg三体激子。实现了吸引层间相互作用，形成了偶极子激子相。

Conclusion: 该平台为探索和操控奇异及拓扑玻色子量子多体相提供了一个多功能平台。

Abstract: Exotic collective phenomena emerge when bosons strongly interact within a
lattice. However, creating a robust and tunable solid-state platform to explore
such phenomena has been elusive. Dual moir\'e systems$-$compromising two
Coulomb-coupled moir\'e lattices$-$offer a promising system for investigating
strongly correlated dipolar excitons (composite bosons) with electrical
control. Thus far, their implementation has been hindered by the relative
misalignment and incommensurability of the two moir\'e patterns. Here we report
a dual moir\'e system with perfect translational and rotational alignment,
achieved by utilizing twisted hexagonal boron nitride (hBN) bilayer to both
generate an electrostatic moir\'e potential and separate MoSe$_{2}$ and
WSe$_{2}$ monolayers. We observe strongly correlated electron phases driven by
intralayer interactions and identify interlayer Rydberg trions, which become
trapped in the presence of the Mott insulating state. Importantly, our platform
is electrostatically programmable, allowing the realization of different
lattice symmetries with either repulsive or attractive interlayer interactions.
In particular, we implement the latter scenario by optically injecting charges,
which form a dipolar excitonic phase. Our results establish a versatile
platform for the exploration and manipulation of exotic and topological bosonic
quantum many-body phases.

</details>


### [290] [Distinguishing Majorana bound states from accidental zero-energy modes with a microwave cavity](https://arxiv.org/abs/2509.13194)
*Sarath Prem,Olesia Dmytruk,Mircea Trif*

Main category: cond-mat.mes-hall

TL;DR: 本文提出并验证了一种利用微波吸收可见性来区分马约拉纳束缚态（MBSs）和平凡零能安德烈夫束缚态（ABSs）或准马约拉纳束缚态（QMBSs）的新方法，通过分析它们在与微波腔耦合时的非局域性来识别MBSs。


<details>
  <summary>Details</summary>
Motivation: 区分混合纳米线中的马约拉纳束缚态（MBSs）和平凡零能安德烈夫束缚态（ABSs）或准马约拉纳束缚态（QMBSs）是实验上的一个挑战，需要新的探测方法。

Method: 提出并研究了基于微波吸收可见性的方法，该方法通过测量电荷奇偶性相关的腔-纳米线磁化率来提取。研究了具有超导段和量子点区域的Rashba自旋-轨道纳米线，并分析了MBSs、ABSs和QMBSs在不同耦合条件下的可见性。同时考虑了高斯无序和“穷人版”马约拉纳体系。

Result: 研究表明，真正的MBSs只有在两个MBSs同时耦合到腔时才表现出有限的可见性，而ABSs和QMBSs即使在腔只与纳米线的一部分局部耦合时也会表现出可见性极值。这一区别在高斯无序存在时依然保持，并且在“穷人版”马约拉纳体系中也得到证实。

Conclusion: 基于腔的微波吸收可见性是一种鲁棒且通用的MBSs探测方法，能够清晰地区分MBSs和零能平凡态，为混合超导体系的研究提供了新途径。

Abstract: Transport measurements of hybrid nanowires often rely on the observation of a
zero-bias conductance peak as a hallmark of Majorana bound states (MBSs).
However, such signatures can also be produced by trivial zero-energy Andreev
bound states (ABSs) or by quasi-Majorana bound states (QMBSs), complicating
their unambiguous identification. Here we propose microwave absorption
visibility, extracted from parity-dependent cavity-nanowire susceptibility
measurements, as a complementary probe of MBSs nonlocality. We study a Rashba
spin-orbit nanowire consisting of a proximitized superconducting segment and an
uncovered quantum-dot region, capacitively coupled to a single-mode microwave
cavity. We show that true MBSs yield finite visibility only when both MBSs are
simultaneously coupled to the cavity, reflecting their intrinsic nonlocality.
In contrast, ABSs and QMBSs exhibit visibility extrema even when the cavity
couples only locally to part of the nanowire. We further demonstrate that this
distinction persists in the presence of Gaussian disorder, which may otherwise
generate trivial subgap states. Motivated by recent experiments, we also
analyze ``poor man's" Majoranas in double-quantum-dot setups, where analytical
results confirm the same nonlocal visibility criterion. Finally, we discuss a
cavity-driven scheme for initializing the electronic system in a given parity
state. Our results establish cavity-based visibility as a robust and versatile
probe of MBSs, providing a clear route to distinguish them from trivial
zero-energy states in hybrid superconducting platforms.

</details>


### [291] [Band geometric transverse current driven by inhomogeneous AC electric field](https://arxiv.org/abs/2509.13242)
*M. Maneesh Kumar,Sanjay Sarkar,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: 我们提出了一种用于电子波包动力学的半经典理论，可以处理不均匀的交流电场。该理论揭示了交流电场梯度如何通过一种新的带几何量——高阶连接（HOC）张量——产生一种在直流电场下会消失的几何电流。这种效应即使在非磁性系统中也能产生类似霍尔效应的响应，并在双层石墨烯的计算中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 探索不均匀交流电场对电子波包动力学的影响，并识别由该效应产生的新的几何电流及其背后的带几何量。

Method: 开发一种半经典理论，推导出交流电流的显式表达式，并将其应用于伯纳尔堆叠的双层石墨烯。

Result: 推导了高阶连接（HOC）张量的显式表达式，并展示了不均匀交流电场如何产生一种新的几何电流，该电流在直流电场极限下消失。在双层石墨烯的例子中，观察到HOC引起的响应产生可测量的霍尔电流。

Conclusion: 不均匀的交流电场是一种探测超越贝里曲率和量子度量的高阶带几何量的有力工具。

Abstract: We develop a semiclassical theory for electron wavepacket dynamics in the
presence of an inhomogeneous AC electric field. While static electric-field
gradients are known to generate charge transport governed by the quantum
metric, we show that AC field gradients induce an additional geometric current
that vanishes in the DC limit. This response originates from a novel
band-geometric quantity, the higher-order connection (HOC) tensor, constructed
from cubic products of interband Berry connections. We derive explicit
expressions for the AC current and identify the symmetry conditions under which
it arises. Remarkably, inhomogeneous AC fields can generate an anomalous
Hall-like response even in nonmagnetic systems. Applying the theory to
Bernal-stacked bilayer graphene, we demonstrate that the HOC-induced response
produces a measurable Hall current peaking at band edges. These results
establish inhomogeneous AC fields as a powerful probe of higher-order band
geometric quantities beyond Berry curvature and the quantum metric.

</details>


### [292] [Odd-parity longitudinal magnetoconductivity in time-reversal symmetry broken materials](https://arxiv.org/abs/2509.13277)
*Sunit Das,Akash Adhikary,Divya Sahani,Aveek Bid,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: 磁性材料中存在一种奇偶校验的磁导率，是时间反转对称性破缺的标志。


<details>
  <summary>Details</summary>
Motivation: 由于量子材料中的对称性和电子结构对磁输运测量很敏感，因此需要研究新的磁输运现象。

Method: 通过半经典输运理论推导了磁导率的显式表达式，并分析了其在晶体对称性下的行为。此外，还研究了在大磁场下的量子振荡以及在谷极化能隙石墨烯中的具体计算。

Result: 发现了奇偶校验的磁导率，并将其与贝里曲率和轨道磁矩联系起来。证明了纵向奇偶校验的磁导率遵循与反常霍尔效应相同的点群约束，而横向奇偶校验的磁导率遵循不同的规则。在量子振荡区域发现了奇偶和偶校验的磁导率。在谷极化能隙石墨烯中，奇偶校验的磁导率在能带边缘附近达到峰值，在能带间隙中消失，并遵循磁序参数的温度依赖性。

Conclusion: 奇偶校验的磁导率是内在时间反转对称性破缺的稳健输运信号，可以解释最近在磁化石墨烯中观察到的奇偶校验磁阻。

Abstract: Magnetotransport measurements are a sensitive probe of symmetry and
electronic structure in quantum materials. While conventional metals exhibit
longitudinal magnetoconductivity that is even in a magnetic field ($B$) for
small $B$, we show that magnetic materials which intrinsically break
time-reversal symmetry (TRS) show an {\it odd-parity magnetoconductivity}
(OMC), with a leading linear-$B$ response. Using semiclassical transport
theory, we derive explicit expressions for the longitudinal and transverse
conductivities and identify their origin in Berry curvature and orbital
magnetic moment. Crystalline symmetry analysis shows that longitudinal OMC
follows the same point-group constraints as the anomalous Hall effect, while
transverse OMC obeys distinct rules, providing an independent probe of TRS
breaking. In the large $B$ quantum oscillation regime, we uncover both odd- and
even-$B$ contributions, demonstrating OMC beyond the semiclassical picture.
Explicit calculations in valley-polarized gapped graphene show that OMC peaks
near the band edges, vanish in the band gap and follow the temperature
dependence of the magnetic order parameter. Our results explain the odd-parity
magnetoresistance recently observed in magnetized graphene and establish OMC as
a robust transport signature of intrinsic TRS breaking in metals.

</details>


### [293] [QDFlow: A Python package for physics simulations of quantum dot devices](https://arxiv.org/abs/2509.13298)
*Donovan L. Buterakos,Sandesh S. Kalantre,Joshua Ziegler,Jacob M Taylor,Justyna P. Zwolak*

Main category: cond-mat.mes-hall

TL;DR: QDFlow是一个开源量子点阵列物理模拟器，可以生成用于机器学习的合成数据。


<details>
  <summary>Details</summary>
Motivation: 机器学习在量子点（QD）设备校准和操作方面取得了进展，但需要大量高质量的标记数据集，而实验获取这些数据集具有挑战性。

Method: QDFlow结合了自洽托马斯-费米求解器、动态电容模型和灵活的噪声模块，以生成接近实验的电荷稳定性图和基于射线的图。它具有广泛的可调参数和可自定义的噪声模型。

Result: QDFlow生成真实的合成数据及其地面实况标签，可用于机器学习的开发、基准测试和量子设备研究。

Conclusion: QDFlow通过提供一个能够生成多样化数据集的物理模拟器，解决了机器学习在量子点设备研究中对标记数据的依赖性问题。

Abstract: Recent advances in machine learning (ML) have accelerated progress in
calibrating and operating quantum dot (QD) devices. However, most ML approaches
rely on access to large, high-quality labeled datasets for training,
benchmarking, and validation, with labels capturing key features in the data.
Obtaining such datasets experimentally is challenging due to limited data
availability and the labor-intensive nature of labeling. QDFlow is an
open-source physics simulator for multi-QD arrays that generates realistic
synthetic data with ground-truth labels. QDFlow combines a self-consistent
Thomas-Fermi solver, a dynamic capacitance model, and flexible noise modules to
produce charge stability diagrams and ray-based data closely resembling
experiments. With extensive tunable parameters and customizable noise models,
QDFlow supports the creation of large, diverse datasets for ML development,
benchmarking, and quantum device research.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [294] [Efficient lattice field theory simulation using adaptive normalizing flow on a resistive memory-based neural differential equation solver](https://arxiv.org/abs/2509.12812)
*Meng Xu,Jichang Yang,Ning Lin,Qundao Xu,Siqi Tang,Han Wang,Xiaojuan Qi,Zhongrui Wang,Ming Xu*

Main category: cs.NE

TL;DR: 本研究提出了一种软硬件协同设计的计算框架，通过结合自适应归一化流（ANF）和基于阻变内存的神经微分方程求解器，为高维格点场理论（LFT）模拟提供了一种高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的LFT模拟方法在计算成本、并行化能力和硬件能效方面存在挑战，限制了其在高维系统中的应用。

Method: 该框架在软件层面采用ANF实现高效并行采样，并利用低秩自适应（LoRA）技术进行模型微调；在硬件层面，利用基于阻变内存的内存计算（in-memory computing）来提高并行度和能效。

Result: 在标量phi4理论和石墨烯线有效场论的验证中，该方法实现了显著的计算效率提升：与混合蒙特卡洛（HMC）相比，积分自相关时间缩短了约8.2倍和13.9倍；与最先进的GPU相比，速度分别提高了16.1倍和17.0倍，能效分别提高了73.7倍和138.0倍。

Conclusion: 所提出的软硬件协同设计能够显著降低LFT模拟的计算成本和能耗，为解决高维系统模拟的挑战提供了一条有效途径。

Abstract: Lattice field theory (LFT) simulations underpin advances in classical
statistical mechanics and quantum field theory, providing a unified
computational framework across particle, nuclear, and condensed matter physics.
However, the application of these methods to high-dimensional systems remains
severely constrained by several challenges, including the prohibitive
computational cost and limited parallelizability of conventional sampling
algorithms such as hybrid Monte Carlo (HMC), the substantial training expense
associated with traditional normalizing flow models, and the inherent energy
inefficiency of digital hardware architectures. Here, we introduce a
software-hardware co-design that integrates an adaptive normalizing flow (ANF)
model with a resistive memory-based neural differential equation solver,
enabling efficient generation of LFT configurations. Software-wise, ANF enables
efficient parallel generation of statistically independent configurations,
thereby reducing computational costs, while low-rank adaptation (LoRA) allows
cost-effective fine-tuning across diverse simulation parameters. Hardware-wise,
in-memory computing with resistive memory substantially enhances both
parallelism and energy efficiency. We validate our approach on the scalar phi4
theory and the effective field theory of graphene wires, using a hybrid
analog-digital neural differential equation solver equipped with a 180 nm
resistive memory in-memory computing macro. Our co-design enables low-cost
computation, achieving approximately 8.2-fold and 13.9-fold reductions in
integrated autocorrelation time over HMC, while requiring fine-tuning of less
than 8% of the weights via LoRA. Compared to state-of-the-art GPUs, our
co-design achieves up to approximately 16.1- and 17.0-fold speedups for the two
tasks, as well as 73.7- and 138.0-fold improvements in energy efficiency.

</details>


### [295] [A Neuromorphic Model of Learning Meaningful Sequences with Long-Term Memory](https://arxiv.org/abs/2509.12850)
*Laxmi R. Iyer,Ali A. Minai*

Main category: cs.NE

TL;DR: 该研究使用基于HTM模型的脉冲神经网络，嵌入SWOW-EN数据集，模拟长期记忆，以研究有意义的句子学习速度与随机词语序列学习速度的差异，并得出有意义句子学习速度更快且系统对噪声的容忍度更高的结论。


<details>
  <summary>Details</summary>
Motivation: 研究人类如何快速理解有意义的句子，并探讨其中的学习机制。

Method: 将SWOW-EN（一个词语联想规范数据集）嵌入基于HTM模型的脉冲神经网络中，以模拟长期记忆。

Result: 与随机词语序列相比，有意义的句子（例如短诗）学习速度明显更快。此外，使用SWOW-EN初始化权重的系统对噪声的容忍度更高。

Conclusion: 有意义的句子学习速度比随机词语序列更快，并且系统对噪声的容忍度更高。

Abstract: Learning meaningful sentences is different from learning a random set of
words. When humans understand the meaning, the learning occurs relatively
quickly. What mechanisms enable this to happen? In this paper, we examine the
learning of novel sequences in familiar situations. We embed the Small World of
Words (SWOW-EN), a Word Association Norms (WAN) dataset, in a spiking neural
network based on the Hierarchical Temporal Memory (HTM) model to simulate
long-term memory. Results show that in the presence of SWOW-EN, there is a
clear difference in speed between the learning of meaningful sentences and
random noise. For example, short poems are learned much faster than sequences
of random words. In addition, the system initialized with SWOW-EN weights shows
greater tolerance to noise.

</details>


### [296] [Large Language Model-assisted Meta-optimizer for Automated Design of Constrained Evolutionary Algorithm](https://arxiv.org/abs/2509.13251)
*Xu Yang,Rui Wang,Kaiwen Li,Wenhua Li,Weixiong Huang*

Main category: cs.NE

TL;DR: AwesomeDE利用大型语言模型（LLM）作为元优化器的策略，为约束进化算法生成更新规则，并在$RTO^2H$框架下标准化LLM的提示设计，实验结果表明该方法在计算效率和解的准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在约束进化优化方面，利用大型语言模型（LLM）进行元黑盒优化仍有提升空间。本文提出AwesomeDE，旨在解决这一问题。

Method: AwesomeDE利用LLM作为元优化器的策略来生成约束进化算法的更新规则，并引入$RTO^2H$框架来标准化LLM的提示设计。通过在各种约束优化问题上训练元优化器，并系统地分析提示设计和迭代优化等关键组成部分的影响。

Result: 实验结果表明，AwesomeDE在计算效率和解的准确性方面优于现有方法，并且在不同的问题域上表现出良好的泛化能力。

Conclusion: 本文提出了一种可扩展、数据驱动的方法，用于自动化约束算法设计，并指出了未来工作的局限性和方向。

Abstract: Meta-black-box optimization has been significantly advanced through the use
of large language models (LLMs), yet in fancy on constrained evolutionary
optimization. In this work, AwesomeDE is proposed that leverages LLMs as the
strategy of meta-optimizer to generate update rules for constrained
evolutionary algorithm without human intervention. On the meanwhile, $RTO^2H$
framework is introduced for standardize prompt design of LLMs. The
meta-optimizer is trained on a diverse set of constrained optimization
problems. Key components, including prompt design and iterative refinement, are
systematically analyzed to determine their impact on design quality.
Experimental results demonstrate that the proposed approach outperforms
existing methods in terms of computational efficiency and solution accuracy.
Furthermore, AwesomeDE is shown to generalize well across distinct problem
domains, suggesting its potential for broad applicability. This research
contributes to the field by providing a scalable and data-driven methodology
for automated constrained algorithm design, while also highlighting limitations
and directions for future work.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [297] [Reduced Order Modeling of Energetic Materials Using Physics-Aware Recurrent Convolutional Neural Networks in a Latent Space (LatentPARC)](https://arxiv.org/abs/2509.12401)
*Zoë J. Gray,Joseph B. Choi,Youngsoo Choi,H. Keo Springer,H. S. Udaykumar,Stephen S. Baek*

Main category: cond-mat.mtrl-sci

TL;DR: 通过将物理感知深度学习（PADL）的挑战分解为学习几何特征和在较低维特征空间中建模动力学，可以简化和加速计算模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决物理感知深度学习（PADL）在计算模型中学习复杂时空动力学（例如能量材料（EM）的场演化）时面临的挑战，并提高其效率。

Method: 将PADL分解为两个任务：学习演化场中的复杂几何特征，以及在较低维特征空间中对这些特征上的动力学进行建模。在此基础上，作者提出了物理感知循环卷积（PARC）的加速和计算成本降低方法，通过将原始动力学投影到较低维不变流形（“潜在空间”）上实现。

Result: 与PARC相比，在训练和推理时间上显著减少，同时在推理时保持了可比的结果。

Conclusion: 这项工作通过在较低维潜在空间中学习演化场，为实现能量材料（EM）热力学的大规模快速预测以及在完整应用规模上表征能量材料（EM）的结构-性能-应用联系奠定了基础。

Abstract: Physics-aware deep learning (PADL) has gained popularity for use in complex
spatiotemporal dynamics (field evolution) simulations, such as those that arise
frequently in computational modeling of energetic materials (EM). Here, we show
that the challenge PADL methods face while learning complex field evolution
problems can be simplified and accelerated by decoupling it into two tasks:
learning complex geometric features in evolving fields and modeling dynamics
over these features in a lower dimensional feature space. To accomplish this,
we build upon our previous work on physics-aware recurrent convolutions (PARC).
PARC embeds knowledge of underlying physics into its neural network
architecture for more robust and accurate prediction of evolving physical
fields. PARC was shown to effectively learn complex nonlinear features such as
the formation of hotspots and coupled shock fronts in various initiation
scenarios of EMs, as a function of microstructures, serving effectively as a
microstructure-aware burn model. In this work, we further accelerate PARC and
reduce its computational cost by projecting the original dynamics onto a
lower-dimensional invariant manifold, or 'latent space.' The projected latent
representation encodes the complex geometry of evolving fields (e.g.
temperature and pressure) in a set of data-driven features. The reduced
dimension of this latent space allows us to learn the dynamics during the
initiation of EM with a lighter and more efficient model. We observe a
significant decrease in training and inference time while maintaining results
comparable to PARC at inference. This work takes steps towards enabling rapid
prediction of EM thermomechanics at larger scales and characterization of EM
structure-property-performance linkages at a full application scale.

</details>


### [298] [Spectral Analysis of Light Interstitial Segregation Energies in Ni: The Role of Local Cr Coordination for Boron and Carbon](https://arxiv.org/abs/2509.12447)
*Tyler D. Doležal,Rodrigo Freitas,Ju Li*

Main category: cond-mat.mtrl-sci

TL;DR: 在化学成分复杂的合金中，间隙原子的偏聚行为受到界面化学和结构异质性的影响。本文提出了一种谱偏聚框架，用于分析镍基合金中轻间隙原子（如硼和碳）的偏聚能谱，并将其与局部铬（Cr）配位数相关联。结果表明，硼的偏聚能谱宽泛且不稳定，具有显著的位置灵活性，而碳的偏聚能谱则狭窄且稳定。在自由表面，富Cr配位会破坏间隙原子的稳定性（偏聚能为正），这与Cr在晶界（GB）的稳定作用形成鲜明对比。这种相互作用导致间隙原子从无配位内部表面向晶界迁移，形成了自然的偏聚梯度。研究结果强调了传统单值偏聚描述符的局限性，并展示了分布方法如何揭示化学成分复杂合金中，间隙原子与界面相互作用的机制。


<details>
  <summary>Details</summary>
Motivation: 理解化学成分复杂的合金中，间隙原子的偏聚行为需要考虑界面化学和结构异质性，因此需要超越单一描述符的方法来捕捉偏聚行为的空间和成分全谱。

Method: 提出一种谱偏聚框架，将镍基合金中轻间隙原子的偏聚能分布映射为局部Cr配位数的函数。

Result: 硼表现出宽泛、崎岖的能量谱，具有显著的位置灵活性；碳则被限制在狭窄的谱内，位移很小。在自由表面，富Cr配位会破坏间隙原子（例如，偏聚能为正），这与Cr在晶界的稳定作用形成鲜明对比。这种反转建立了自然的偏聚梯度，将间隙原子从无配位的内表面推向晶界。

Conclusion: 该研究结果强调了单值偏聚描述符的局限性，并证明了分布方法如何揭示化学成分复杂合金中，间隙原子-界面相互作用的机制。

Abstract: Understanding interstitial segregation in chemically complex alloys requires
accounting for chemical and structural heterogeneity of interfaces, motivating
approaches that move beyond scalar descriptors to capture the full spatial and
compositional spectra of segregation behavior. Here, we introduce a spectral
segregation framework that maps distributions of segregation energies for light
interstitials in Ni as a function of local Cr coordination. Boron exhibits a
broad, rugged energy spectrum with significant positional flexibility whereas
carbon remains confined to a narrow spectrum with minimal displacement. At the
free surface, Cr-rich coordination destabilizes both interstitials (e.g.,
positive segregation energies), in sharp contrast to the stabilizing role of Cr
at the GB. This inversion establishes a natural segregation gradient that
drives interstitials away from undercoordinated internal surfaces and toward
GBs. These results underscore the limitations of single-valued segregation
descriptors and demonstrate how a distributional approach reveals the
mechanistic origins of interstitial--interface interactions in chemically
heterogeneous alloys.

</details>


### [299] [Multi-Dimensional Photon-Correlations Reveal Triexciton Features in Single Perovskite Quantum Dots](https://arxiv.org/abs/2509.12461)
*Alex Hinkle,Chieh Tsao,Adam Duell,Hendrik Utzat*

Main category: cond-mat.mtrl-sci

TL;DR: PQDs可用于纠缠光子对生成，但多体激子行为尚不清楚。研究人员使用光子相关光谱法研究了单个CsPbBr3 PQDs，发现了二激子结合能和电荷态，并确定了三激子光谱特征及其发射顺序。


<details>
  <summary>Details</summary>
Motivation: PQDs在多激子 the energetics and dynamics 方面仍然知之甚少，而这对于纠缠光子对的生成至关重要。

Method: 使用单光子雪崩二极管（SPAD）阵列探测器，在低温下对单个CsPbBr3 PQDs进行时间和频率分辨的光子相关光谱分析。

Result: 确定了二激子结合能并分配了它们的电荷态，这些电荷态经历了快速（μs）的开关动力学。识别出比激子蓝移7.4±1.9 meV的光谱特征，并将其确定为束缚三激子，同时确定了其串联发射的顺序。

Conclusion: 低温、多维光子相关光谱法能够有效解决复杂的多体动力学问题，这对于理解PQDs的发光机理具有重要意义。

Abstract: Lead-halide perovskite quantum dots (PQDs) are established quantum emitters
with potential for entangled photon-pair generation via multiexciton cascades.
However, the energetics and dynamics of many-body excitations remain poorly
understood. Here, we perform time- and frequency-resolved photon-correlation
spectroscopy of single CsPbBr\textsubscript{3} PQDs at low temperatures using a
single-photon avalanche diode (SPAD) array detector. We report biexciton
binding energies and assign their charged states, which undergo fast ($\mu$s)
switching dynamics. Most notably, we identify a spectral feature blue-shifted
from the exciton by $7.4 \pm 1.9$ meV as the bound triexciton and establish the
order of its cascade emission. These results highlight the power of
low-temperature, multidimensional photon-correlation spectroscopy for resolving
complex many-body dynamics.

</details>


### [300] [Coupled Infrared Imaging and Multiphysics Modeling to Predict Three-Dimensional Thermal Characteristics during Selective Laser Melting](https://arxiv.org/abs/2509.12545)
*Vijay Kumar,Kaitlyn M. Mullin,Hyunggon Park,Matthew Gerigk,Andrew Bresk,Tresa M. Pollock,Yangying Zhu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过结合高速红外成像和多物理场模拟，精确测量和预测了增材制造过程中的熔池温度分布、凝固条件和微观结构。


<details>
  <summary>Details</summary>
Motivation: 精确测量增材制造（AM）过程中的瞬态高温条件以了解微观结构演变和力学性能，这是一个关键的挑战。

Method: 提出了一种结合高速红外成像和三维多物理场瞬态模拟的方法，以重建熔池的动态亚表面温度分布，并估算凝固条件。

Result: 该方法能够估算三维凝固条件（包括凝固速度和冷却速率），并预测由激光加工参数驱动的微观结构尺寸和方向的变化，且已通过实验验证。

Conclusion: 结合实验和计算的方法对于在商业增材制造中实现原位预测和优化微观结构至关重要。

Abstract: Laser heating during additive manufacturing (AM) induces extreme and
transient thermal conditions which critically influence the microstructure
evolution and mechanical properties of the resulting component. However,
accurately resolving these conditions with sufficient spatiotemporal accuracy
remains a central challenge. We demonstrate a unique approach that couples
high-speed infrared imaging, during selective laser melting of MAR-M247, with a
transient three-dimensional (3D) multiphysics simulation to reconstruct the
dynamic sub-surface temperature distribution of the melt pool. This integrated
framework enables the estimation of experimentally-validated, 3D solidification
conditions-including solidification velocities and cooling rates-at the
solid-liquid interface while also significantly lowering computational cost. By
quantifying solidification conditions, we predict variations in microstructure
size and orientation driven by laser processing parameters and validate them
with ex situ scanning electron microscopy and electron backscatter diffraction
maps. Our findings substantiate that an integrated experimental-computational
approach is crucial to realize in situ prediction and optimization of
microstructures in commercial AM.

</details>


### [301] [High-pressure electronic states in semiconductors studied by infrared spectroscopy: metallization and band gap tuning in Mg$_2$Si, InAs and InSb](https://arxiv.org/abs/2509.12559)
*Hidekazu Okamura,Haruna Okazaki,Katsunori Marugaku,Subin Lee,Tomoki Yoneda,Haruhiko Udono,Yoshihisa Mori,Mitsuhiko Maesato,Hiroshi Kitagawa,Yuka Ikemoto,Taro Moriwaki*

Main category: cond-mat.mtrl-sci

TL;DR: Mg2Si在~10 GPa下发生金属性转变，InAs和InSb的带隙随压力线性增大，并在结构转变后呈现金属性。


<details>
  <summary>Details</summary>
Motivation: 介绍高压金刚石压腔红外光谱学在材料研究中的应用，并展示Mg2Si、InAs和InSb的高压红外光谱实验结果。

Method: 使用金刚石压腔进行高压红外光谱测量，并分析了Mg2Si、InAs和InSb的光谱数据。

Result: Mg2Si在约10 GPa时金属性转变；InAs和InSb的带隙随压力线性增大（dEg/dP分别为84.6和112 meV/GPa），并在7 GPa和3 GPa的结构转变压力之后呈现金属性。

Conclusion: 高压红外光谱是研究材料高压行为的有效手段。Mg2Si、InAs和InSb在高压下表现出金属性转变和带隙变化，其带隙随晶格参数的变化规律为研究III-V族半导体提供了新的视角。

Abstract: In this article, a brief introduction is first given on infrared studies of
materials at high pressures using a diamond anvil cell. Then, our recent
results of high-pressure infrared studies are described for Mg$_2$Si, InAs, and
InSb. For Mg$_2$Si, pressure-induced metallization at pressures near 10 GPa
were clearly demonstrated for both carrier-doped and undoped Mg$_2$Si by large
increases of reflectivity. For InAs and InSb, their band gap ($E_g$) increased
rapidly and almost linearly with pressure with linear coefficients of
$dE_g/dP$=84.6 and 112 meV/GPa, respectively. Obtained values of $E_g$ versus
lattice parameter at high pressures are compared with those for other IIl-V
semiconductors at ambient pressure, giving unique insight into effects of
physical and chemical pressures on $E_g$. Above the structural transition
pressures of 7 and 3 GPa for InAs and InSb, respectively, they exhibit highly
metallic characteristics accompanied by high reflectivity.

</details>


### [302] [Over One Order of Magnitude Enhancement in Hole Mobility of 2D III-V Semiconductors through Valence Band Edge Shift](https://arxiv.org/abs/2509.12588)
*Jianshi Sun,Shouhang Li,Cheng Shao,Zhen Tong,Meng An,Yue Hu,Xiongfei Zhu,Thomas Frauenheim,Xiangjun Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 二维GaAs的量子无谐波效应显著降低了空穴迁移率，但可以通过价带边缘移动策略（VBES）和1%的双轴压缩应变来大幅提高。


<details>
  <summary>Details</summary>
Motivation: 解决二维半导体（特别是二维GaAs）中由量子无谐波效应引起的低空穴迁移率问题，以维持摩尔定律在超大规模电子学中的应用。

Method: 采用基于机器学习势的随机自洽谐波近似方法，研究量子无谐波效应对二维GaAs空穴传输的影响。提出价带边缘移动（VBES）策略，并通过施加1%的双轴压缩应变来验证其效果。

Result: 量子无谐波效应将室温下二维GaAs的空穴迁移率降低了约44%，这是由于面外声学极化引起的增强的电子-声子散射。价带边缘移动（VBES）策略结合1%的双轴压缩应变，可以将室温下的空穴迁移率提高约1600%，这是因为原始平带空穴口袋中的带间电子-声子散射通道被完全过滤。

Conclusion: 量子无谐波效应对二维GaAs的空穴迁移率有负面影响，但提出的VBES策略，特别是结合1%的双轴压缩应变，能够显著提高空穴迁移率，并且该策略可以推广到其他二维III-V族半导体。

Abstract: Two-dimensional (2D) semiconductors show great potential to sustain Moore's
law in the era of ultra-scaled electronics. However, their scalable
applications are severely constrained by low hole mobility. In this work, we
take 2D-GaAs as a prototype of III-V semiconductors to investigate the effects
of quantum anharmonicity (QA) on hole transport, employing the stochastic
self-consistent harmonic approximation assisted by the machine learning
potential. It is found that the room-temperature hole mobility of 2D-GaAs is
reduced by $\sim$44% as the QA effects are incorporated, which is attributed to
the enhanced electron-phonon scattering from the out-of-plane acoustic
polarization. The valence band edge shift (VBES) strategy is proposed to
increase the hole mobility by $\sim$1600% at room temperature, which can be
realized by 1% biaxial compressive strain. The electron-phonon scattering rate
is dramatically decreased due to the full filtering of the original interband
electron-phonon scattering channels that existed in the flat hole pocket. The
VBES strategy can be further extended to other 2D III-V semiconductors to
promote their hole mobilities.

</details>


### [303] [Atomic-scale phase-field modeling with universal machine learning potentials](https://arxiv.org/abs/2509.12648)
*Kairi Masuda,Yu Kumagai*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过引入机器学习势能，将原子尺度相场模型推广到多体系统，提高了精度和适用性，并成功应用于块体铜和晶界，验证了其在复杂材料和缺陷结构建模中的通用性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的原子尺度相场模型仅限于经典的成对相互作用势，限制了其在特定材料上的应用和定量精度。本研究旨在通过引入通用机器学习势能，将原子尺度相场方法扩展到多体系统，以提高其准确性和适用性。

Method: 本研究将通用机器学习势能集成到原子尺度相场模型中，将自由能泛函推广到多体系统。该方法通过原子尺度分解自由能，实现对局部热力学状态的精确描述。

Result: 在NVT和NPT系综下，将该方法应用于块体铜，预测的压力和平衡晶格常数与分子动力学模拟结果高度吻合。将该方法应用于Σ5(310)[001]铜晶界，成功实现了原子尺度分辨率下局部自由能分布的可视化，并揭示了晶界核心处显著的自由能集中现象。

Conclusion: 本研究建立了一个通用且准确的原子尺度热力学建模框架，将相场方法显著扩展到包括复杂材料和缺陷结构在内的更广泛应用领域。

Abstract: Atomic-scale phase-field modeling formulates the probability densities of
atomic vibrations as Gaussian distributions and derives a free energy
functional using variational Gaussian theory and interatomic potentials. This
framework permits per-Gaussian decomposition of the free energy, providing a
description of local thermodynamic states with atomic resolution. However,
existing formulations are limited to classical pairwise interatomic potentials,
restricting their applicability to specific materials and compromising
quantitative accuracy. In this work, we extend the atomic-scale phase-field
methodology by incorporating universal machine learning interatomic potentials,
thereby generalizing the free energy functional to many-body systems. This
extension enhances both the accuracy and transferability of the approach. We
demonstrate the method by applying it to bulk copper under NVT and NPT
ensembles, where the predicted pressures and equilibrium lattice constants show
excellent agreement with molecular dynamics simulations, validating the
theoretical framework. Furthermore, we apply the method to {\Sigma}5(310)[001]
grain boundaries in copper, enabling the visualization of local free energy
distributions with atomic-scale resolution. The results reveal a pronounced
free energy concentration at the grain boundary core, capturing the
thermodynamic signature of the interface. This study establishes a versatile
and accurate framework for atomic-scale thermodynamic modeling, significantly
broadening the scope of phase-field approaches to include complex materials and
defect structures.

</details>


### [304] [Beyond conventional half-metals: gapless states and spin gapless semiconducting behavior in X$_2$MnGa (X = Ti, Ir) Heusler compounds](https://arxiv.org/abs/2509.12803)
*N. Bouteldja,N. Hacini,I. Ouadha,H. Rached*

Main category: cond-mat.mtrl-sci

TL;DR: Ti$_2$MnGa和Ir$_2$MnGa在不同结构下表现出不同的电子特性，具有潜在的自旋电子学应用前景。


<details>
  <summary>Details</summary>
Motivation: 寻找具有优异电子特性的赫斯勒合金以用于自旋电子学材料。

Method: 使用包含Hubbard校正（DFT+U，U=4 eV）的密度泛函理论研究了X$_2$MnGa（X = Ti, Ir）合金。

Result: Ti$_2$MnGa从金属L2$_1$-型相转变为XA-型的自旋隙态半导体（SGS）。Ir$_2$MnGa在L2$_1$-型中表现出无隙半金属特性，在XA-型中变为半金属。磁性由Mn-3d和X-d/Ga-p态之间的sp杂化决定，Hubbard U校正对于准确描述Mn-3d电子至关重要。

Conclusion: 研究的赫斯勒合金结合了结构稳定性和可调的电子、磁性，为下一代自旋电子器件中的偏振传输提供了有前景的平台。

Abstract: The search for high-performance spintronic materials motivates the
exploration of Heusler alloys with unconventional electronic properties. Using
density functional theory with Hubbard correction (DFT+$U$, $U = 4$~eV), we
investigate X$_2$MnGa (X = Ti, Ir) alloys, which stabilize in the ferromagnetic
L2$_1$-type structure with strong thermodynamic stability. Electronic structure
calculations reveal contrasting behaviors: Ti$_2$MnGa transitions from a
metallic L2$_1$-type phase to a spin gapless semiconductor (SGS) in the
XA-type, while Ir$_2$MnGa exhibits gapless half-metallicity behavior in the
L2$_1$-type but becomes half-metallic in the XA-type. The magnetic properties
are governed by spd hybridization between Mn-3$d$ and X-$d$/Ga-$p$ states,
which stabilizes ferromagnetism and tailors electronic states near the Fermi
level. The Hubbard $U$ correction proves essential for accurately describing
the correlated Mn-3$d$ electrons. These alloys combine structural stability
with tunable electronic and magnetic properties, offering a promising platform
for spin-polarized transport in next-generation spintronic devices.

</details>


### [305] [Recent Advancements in the Development of Two-dimensional Transition Metal Dichalcogenides (TMDs) and their potential application](https://arxiv.org/abs/2509.12940)
*Mitesh B. Solanki,Margi Jani*

Main category: cond-mat.mtrl-sci

TL;DR: 本文总结了二维过渡金属硫族化物（2D TMDs）的最新进展，特别是在纳米电子学、光子学、传感、储能和光电子学等领域的应用，并讨论了可扩展生产和新材料开发方面的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 本文旨在全面概述二维过渡金属硫族化物（2D TMDs）的最新进展，重点关注其在纳米电子学、光子学、传感、储能和光电子学等领域的应用潜力，并探讨实现这些应用所面临的挑战及研究方向。

Method: 本文通过文献综述的方式，总结了近年来在原子级二维过渡金属硫族化物（2D TMDs）领域取得的进展，包括材料生长策略、新材料开发以及在电子、光电子、能源和传感等领域的应用探索。

Result: 研究表明，二维过渡金属硫族化物（2D TMDs）在电子、光电子、能源和传感领域展现出巨大潜力，尽管在可扩展生产和无缺陷材料制备方面仍存在挑战，但创新的生长策略和新材料的开发为实际应用开辟了道路。

Conclusion: 二维过渡金属硫族化物（2D TMDs）是下一代电子和光电子器件的有希望的候选材料，其在能源和传感领域的应用也日益受到关注。持续的研究和开发将推动这些材料及其集成到实际设备和系统中的进步。

Abstract: This article explores the recent advancements in atomically thin
two-dimensional transition metal dichalcogenides (2D TMDs) and their potential
applications in various fields, including nanoelectronics, photonics, sensing,
energy storage, and optoelectronics. Specifically, the focus is on TMDs such as
MoS2, WS2, MoSe2, and WSe2, promising for next-generation electronics and
optoelectronics devices based on ultra-thin atomic layers. One of the main
challenges in utilising TMDs for practical applications is the scalable
production of defect-free materials on desired substrates. However, innovative
growth strategies have been developed to address this issue and meet the
growing demand for high-quality and controllable TMD materials. These
strategies are compatible with conventional and unconventional substrates,
opening up new possibilities for practical implementation. Furthermore, the
article highlights the development of novel 2D TMDs with unique functionalities
and remarkable chemistry. These advancements contribute to expanding the range
of applications and capabilities of TMD materials, pushing the boundaries of
what can be achieved with these ultra-thin layers. In addition to electronics,
the article delves into the significant efforts dedicated to exploring the
potential of 2D TMDs in energy and sensor applications. These materials have
shown promising characteristics for energy storage and have been extensively
studied for their sensing capabilities, showcasing their versatility and
potential impact in these fields. This article provides a comprehensive
overview of the recent progress in 2D TMDs, emphasising their applications in
electronics, optoelectronics, energy, and sensing. The continuous research and
development in this area is promising for advancing these materials and their
integration into practical devices and systems.

</details>


### [306] [Structural and Electrocatalytic Properties of La-Co-Ni Oxide Thin Films](https://arxiv.org/abs/2509.12946)
*Patrick Marx,Shivam Shukla,Alejandro Esteban Perez Mendoza,Florian Lourens,Corina Andronescu,Alfred Ludwig*

Main category: cond-mat.mtrl-sci

TL;DR: La-Co-Ni氧化物薄膜库在不同组成范围内进行了结构和功能性质的分析，发现钴含量富集区域的尖晶石相和钙钛矿相组合显示出最高的析氧反应催化活性，其中La11Co20Ni9O60的性能最优。


<details>
  <summary>Details</summary>
Motivation: 研究La-Co-Ni氧化物在宽广的成分范围内，探索其结构相变与析氧反应(OER)催化活性的关系，以期发现高性能的OER催化剂。

Method: 采用组合反应共溅射技术制备La-Co-Ni氧化物薄膜材料库，并通过X射线衍射、表面微观结构分析和能量色散X射线光谱分析等手段，研究了不同组成下的相结构、微观形貌和元素分布。随后，对所有材料进行了析氧反应性能测试。

Result: 在La-Co-Ni氧化物薄膜中，随着Co含量的变化，形成了三种不同的相组成区域：La富集区（La2O3、钙钛矿、La(OH)3混合相）、Co富集区（钙钛矿和尖晶石相）以及单一钙钛矿相区。表面析晶现象在两相区尤为明显，且随Ni含量的增加而增多，这些析晶主要包含Co和Ni，可能为表面生长的尖晶石相。析氧反应测试表明，钙钛矿/尖晶石两相区域表现出最高的催化活性，且活性随Ni含量的升高而增加。其中，La11Co20Ni9O60的组成在1.8 V vs. RHE下达到了最高的2.24 mA/cm2 OER电流密度。

Conclusion: La-Co-Ni氧化物薄膜库的研究表明，钙钛矿相与尖晶石相的混合物，特别是在Ni含量较高时，对析氧反应表现出优异的催化活性。La11Co20Ni9O60是其中性能最佳的材料，证明了通过组合溅射技术精确调控氧化物组成是开发高性能OER催化剂的有效途径。

Abstract: La-Co-Ni oxides were fabricated in the form of thin-film materials libraries
by combinatorial reactive co-sputtering and analyzed for structural and
functional properties over large compositional ranges: normalized to the metals
of the film they span about 0 - 70 at.-% for Co, 18 - 81 at.-% for La and 11 -
25 at.-% for Ni. Composition-dependent phase analysis shows formation of three
areas with different phase constitutions in dependance of Co-content: In the
La-rich region with low Co content, a mixture of the phases La2O3, perovskite,
and La(OH)3 is observed. In the Co-rich region, perovskite and spinel phases
form. Between the three-phase region and the Co-rich two-phase region, a
single-phase perovskite region emerges. Surface microstructure analysis shows
formation of additional crystallites on the surface in the two-phase area,
which become more numerous with increasing Ni-content. Energy-dispersive X-ray
analysis indicates that these crystallites mainly contain Co and Ni, so they
could be spinels growing on the surface. The analysis of the oxygen evolution
reaction (OER) electrocatalytic activity over all compositions and phase
constitutions reveals that the perovskite/spinel two-phase region shows the
highest catalytic activity, which increases with higher Ni-content. The highest
OER current density was measured as 2.24 mA/cm2 at 1.8 V vs. RHE for the
composition La11Co20Ni9O60.

</details>


### [307] [Origin of Reverse Size Effect in Ferroelectric Hafnia Thin Films](https://arxiv.org/abs/2509.12952)
*Tianyuan Zhu,Shi Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 铁电性在超薄HfO2薄膜中的持续存在是一个挑战，因为人们发现其面外晶格间距随厚度减小而增大。本研究通过揭示晶格膨胀与面外极化减弱之间的反直觉耦合关系来解决这一难题。


<details>
  <summary>Details</summary>
Motivation: 解释超薄HfO2薄膜中铁电性的持续存在，特别是面外晶格间距随厚度减小而增大的反常现象。

Method: 利用第一性原理计算和分析模型，识别出导致晶格膨胀的两种机制：残余去极化场引起的负纵向压电响应和在减薄时变得显著的正表面应力。

Result: 计算和模型能够定量地重现实验观察到的晶格膨胀。此外，(111)取向的HfO2薄膜即使在开路条件下也能支持面外极化，这与稳定非极性基态的(001)薄膜形成对比。

Conclusion: 识别出一种名为“取向诱导超铁电性”的新兴机制，它使得无需电极屏蔽即可通过取向工程实现极化持续存在。该原理也可应用于钙钛矿铁电体，通过选择合适的薄膜取向来消除临界厚度限制。

Abstract: The persistence of ferroelectricity in ultrathin HfO$_2$ films challenges
conventional theories, particularly given the paradoxical observation that the
out-of-plane lattice spacing increases with decreasing thickness. We resolve
this puzzle by revealing that this anomalous lattice expansion is
counterintuitively coupled to suppressed out-of-plane polarization.
First-principles calculations combined with analytical modeling identify two
mechanisms behind this expansion: a negative longitudinal piezoelectric
response to the residual depolarization field and a positive surface stress
that becomes significant at reduced thickness. Their interplay quantitatively
reproduces the experimentally observed lattice expansion. Furthermore,
(111)-oriented HfO$_2$ films can support out-of-plane polarization even under
open-circuit conditions, in contrast to (001) films that stabilize a nonpolar
ground state. This behavior points to the emergence of orientation-induced
hyperferroelectricity, an unrecognized mechanism that enables polarization
persistence through orientation engineering without electrode screening. The
principle also extends to perovskite ferroelectrics, offering a strategy to
eliminate critical thickness limits by selecting appropriate film orientations.

</details>


### [308] [Structural effects of boron doping in diamond crystals for gamma-ray light-source applications: Insights from molecular dynamics simulations](https://arxiv.org/abs/2509.13045)
*Matthew D. Dickers,Felipe Fantuzzi,Nigel J. Mason,Andrei V. Korol,Andrey V. Solov'yov*

Main category: cond-mat.mtrl-sci

TL;DR: 硼掺杂金刚石(BDD)因其优异的机械强度、电子可调性和抗辐射损伤能力，在基于伽马射线晶体的光源中具有应用前景。本文通过分子动力学模拟研究了硼浓度对BDD晶体结构畸变的影响，发现晶格常数和平面间距随硼浓度的增加呈线性关系，但偏离Vegard定律。该方法考虑了微波等离子体化学气相沉积(MPCVD)的生长条件，并通过统计分析验证了其可靠性，为BDD晶体的建模和未来伽马射线光源的设计提供了支持。


<details>
  <summary>Details</summary>
Motivation: 硼掺杂金刚石(BDD)作为一种有前途的材料，在伽马射线晶体光源中具有潜在应用。然而，掺杂引起的结构畸变对其沟道效率至关重要，需要对其进行深入理解和量化。

Method: 采用原子尺度的分子动力学模拟，研究了不同尺寸的周期性C1-xB x体系。通过模拟评估了在室温(300 K)和0%至5%硼浓度范围内，硼浓度对晶格常数以及(110)和(100)晶面间距的影响。该方法结合了MPCVD晶体生长的条件，并通过全面的统计分析来验证其准确性。

Result: 研究观察到晶格常数和晶面间距与掺杂浓度之间存在线性关系，但存在偏离Vegard定律的现象。与先前研究相比，观察到的偏差更大，这可能归因于该研究所采用的晶体质量更高。所提出的方法论在反映MPCVD生长条件下进行了优化，并通过对生成的晶体结构的统计分析进行了验证。

Conclusion: 本研究通过分子动力学模拟，精确地量化了硼掺杂对金刚石晶体结构的影响，揭示了掺杂浓度与晶格常数和平面间距之间的线性关系，并指出了其偏离Vegard定律的现象。所提出的方法论能够可靠地进行掺杂金刚石晶体的原子尺度建模，为设计和制造用于下一代伽马射线光源的周期性弯曲结构提供了理论支持。

Abstract: Boron-doped diamond crystals (BDD, C$_{1-x}$B$_{x}$) exhibit exceptional
mechanical strength, electronic tunability, and resistance to radiation damage.
This makes them promising materials for use in gamma-ray crystal-based light
sources. To better understand and quantify the structural distortions
introduced by doping, which are critical for maintaining channelling
efficiency, we perform atomistic-level molecular dynamics simulations on
periodic C$_{1-x}$B$_{x}$ systems of various sizes. These simulations allow the
influence of boron concentration on the lattice constant and the (110) and
(100) inter-planar distances to be evaluated over the concentration range from
pure diamond (0%) to 5% boron at room temperature (300 K). Linear relationships
between both lattice constant and inter-planar distance with increasing dopant
concentration are observed, with a deviation from Vegard's Law. This deviation
is larger than that reported by other theoretical and computational studies;
however, this may be attributed to an enhanced crystal quality over these
studies, a vital aspect when considering gamma-ray crystal light source design.
The methodology presented here incorporates several refinements to closely
reflect the conditions of microwave plasma chemical vapour deposition (MPCVD)
crystal growth. Validation of the methodology is provided through a
comprehensive statistical analysis of the structure of our generated crystals.
These results enable reliable atomistic modelling of doped diamond crystals and
support their use in the design and fabrication of periodically bent structures
for next-generation gamma-ray light source technologies.

</details>


### [309] [Explaining Principles of Tip-Enhanced Raman Images with Ab Initio Modeling](https://arxiv.org/abs/2509.13075)
*Krystof Brezina,Yair Litman,Mariana Rossi*

Main category: cond-mat.mtrl-sci

TL;DR: TERS模拟应考虑周期性衬底，而非孤立体系，以准确反映实验结果。


<details>
  <summary>Details</summary>
Motivation: 以往TERS理论模拟常忽略衬底影响，导致与实验数据存在偏差。本文旨在通过考虑衬底周期性的模拟方法，修正和解释TERS实验现象。

Method: 开发了一种新的有限场第一性原理模拟方法，能够处理周期性延展体系，并用于计算TERS光谱。通过对比孤立分子/团簇模型和考虑衬底周期性模型的模拟结果，分析衬底对TERS图像的影响。

Result: 对于"四氰基乙烯/Ag(100)"和"缺陷MoS2单层"体系，考虑衬底周期性的模拟结果与孤立模型结果存在显著差异。对于"Mg(II)-卟啉/Ag(100)"体系，考虑衬底周期性的模拟结果与实验数据吻合，成功解释了TERS强度图样的空间变化。

Conclusion: TERS模拟必须考虑周期性衬底的影响，才能准确解释实验结果。表面相互作用对非平面振动模式的影响比平面振动模式更大，这为理解和解释复杂体系的TERS图像提供了重要依据。

Abstract: Tip-enhanced Raman spectroscopy (TERS) is a powerful method for imaging
vibrational motion and chemically characterizing surface-bound systems.
Theoretical simulations of TERS images often consider systems in isolation,
ignoring any substrate support, such as metallic surfaces. Here, we show that
this omission leads to deviations from experimentally measured data through
simulations with a new finite-field formulation of first-principles simulation
of TERS spectra that can address extended, periodic systems. We show that TERS
images of tetracyanoethylene on Ag(100) and defective MoS$_2$ monolayers
calculated using isolated molecules or cluster models are qualitatively
different from those calculated when accounting for the periodicity of the
substrate. For Mg(II)-porphine on Ag(100), a system for which a direct
experimental comparison is possible, these simulations prove to be crucial for
explaining the spatial variation of TERS intensity patterns and allow us to
uncover fundamental principles of TERS spectroscopy. We explain how and why
surface interactions affect images of out-of-plane vibrational modes much more
than those of in-plane modes, providing an important tool for the future
interpretation of these images in more complex systems.

</details>


### [310] [Relaxation and Its Effects on Electronic Structure in Twisted Systems: An Analytical Perspective](https://arxiv.org/abs/2509.13114)
*Junxi Yu,Bingbing Wang,Cheng-Cheng Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 我们开发了一个统一的分析框架，用于研究扭曲材料中的晶格弛豫及其对电子结构的影响，克服了传统计算密集型和不透明方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的研究扭曲材料中晶格弛豫的方法（如密度泛函理论）计算成本高且机理不透明，需要更有效和透明的方法。

Method: 该研究从连续弹性理论出发，推导了面内外弛豫场的闭合解，并引入了分析相位因子展开理论将弛豫映射到电子哈密顿量中。

Result: 该框架能够准确捕捉扭曲MoTe$_{2}$中由弛豫介导的单粒子和多体拓扑相变，并定量重现了魔角石墨烯中平带的演化。

Conclusion: 该研究将扭曲材料的弛豫研究从黑箱数值拟合转变为分析范式，提供了基本见解、出色的效率和广泛的适用性。

Abstract: Lattice relaxation profoundly reshapes electronic structures in twisted
materials. Prevailing treatments, however, typically rely on large-scale
density functional theory (DFT), which is computationally costly and
mechanistically opaque. Here, we develop a unified analytical framework to
overcome these limitations. From continuum elastic theory, we derive
closed-form solutions for both in-plane and out-of-plane relaxation fields. We
further introduce an analytical phase factor expansion theory that maps
relaxation into the electronic Hamiltonian. By applying this framework, the
relaxation-mediated single-particle and many-body topological phase transitions
in twisted MoTe$_{2}$ is accurately captured, and the evolution of flat bands
in magic-angle graphene is quantitatively reproduced. Our work transforms the
research of moir\'e relaxation from black-box numerical fitting to an
analytical paradigm, offering fundamental insights, exceptional efficiency, and
general applicability to a wide range of twisted materials.

</details>


### [311] [Understanding oxide surface stability: Theoretical insights from silver chromate](https://arxiv.org/abs/2509.13155)
*Augusto Facundes,Thiago T. Dorini,Theodora W. von Zuben,Miguel A. San-Miguel*

Main category: cond-mat.mtrl-sci

TL;DR: 银铬矿（Ag2CrO4）的光催化性能对其表面晶向敏感。本研究使用DFT和原子热力学方法，研究了Ag2CrO4在不同化学势下的表面稳定性，发现表面铬氧团簇的配位度是决定表面稳定性的关键。Wulff构造预测了在不同外部条件下晶体形态的演变，并确定了平衡晶体形状下暴露面的原子结构。


<details>
  <summary>Details</summary>
Motivation: 为了理解和提升银铬矿（Ag2CrO4）在光催化领域的应用，需要对其在实际条件下不同表面晶向的结构稳定性进行深入研究。

Method: 结合密度泛函理论（DFT）和第一性原理原子热力学，系统研究了Ag2CrO4多种表面取向和终端的稳定性。评估了表面吉布斯自由能与氧气和银化学势的关系，并利用Wulff构造预测了晶体形态的演变。

Result: 研究结果表明，表面铬氧团簇的配位度是决定表面稳定性的关键因素。通过Wulff构造预测了晶体在不同外部条件下的形态演变，并确定了平衡晶体形状下暴露面的原子结构。

Conclusion: 本研究为理解银铬矿（Ag2CrO4）及其相关银基氧化物中与表面相关的光催化活性提供了基础性框架。

Abstract: Silver chromate ($\mathrm{Ag_{2}CrO_{4}}$) has attracted considerable
attention in recent years due to its promising photocatalytic performance,
which strongly depends on the crystallographic orientation of its exposed
surfaces. A detailed understanding of the structural stability of these
surfaces under realistic conditions is therefore essential for advancing its
applications. In this work, we combine density functional theory (DFT) with
first-principles atomistic thermodynamics to systematically investigate the
stability of multiple surface orientations and terminations of
$\mathrm{Ag_{2}CrO_{4}}$. The surface Gibbs free energy was evaluated as a
function of oxygen and silver chemical potentials, enabling the construction of
stability trends under non-vacuum environments. Our results reveal that the
degree of coordination of surface chromium-oxygen clusters plays a decisive
role in determining surface stability. Furthermore, Wulff constructions predict
morphology evolution as a function of external conditions, allowing us to
identify the atomic structures of the exposed facets in the equilibrium crystal
shape. These insights provide a fundamental framework for understanding
surface-dependent photocatalytic activity in $\mathrm{Ag_{2}CrO_{4}}$ and
related silver-based oxides.

</details>


### [312] [Strain-tuned magnetoelectric properties of monolayer NiX$_2$ (X = I, Br): a first-principles analysis](https://arxiv.org/abs/2509.13182)
*Ali Ghojavand,Cem Sevik,Milorad V. Milošević*

Main category: cond-mat.mtrl-sci

TL;DR: 通过引入应变，可以精确调控NiX_2（X = I, Br）单层材料的磁电耦合和自旋驱动的极化。


<details>
  <summary>Details</summary>
Motivation:  NiX_2（X = I, Br）单层材料在无应变时，会自发形成破坏反演对称性的非共线自旋态，从而在材料平面内产生铁电极化。本研究旨在探索通过应变调控该材料的磁电耦合和自旋极化。

Method: 采用从头算（ab initio）方法，研究双轴和单轴应变对NiX_2（X = I, Br）单层材料的磁电响应的调控作用，重点分析应变通过直接修改磁电张量分量和调整自旋纹理的特征传播矢量这两个机制来调控磁电响应。

Result: 研究表明，双轴和单轴应变可以通过上述两个机制广泛地调控NiX_2（X = I, Br）单层材料的磁电响应。其中，第三近邻自旋对的贡献在应变下可以增加，甚至超过第一近邻效应驱动的极化，从而实现对自旋诱导电极化的精确控制。

Conclusion: 本研究揭示了应变在调控低维压磁电材料中的关键作用，并为设计多功能二维应变电子器件提供了新的可能性。

Abstract: Using \textit{ab initio} methodology, we reveal a strain-mediated approach to
precisely tune the magnetoelectric coupling and spin-driven emergent
polarization of NiX$_2$ (X = I, Br) monolayers. In the absence of strain, these
systems spontaneously stabilize non-collinear spin states that break the
inversion symmetry, inducing a ferroelectric polarization in the plane of the
material. We show that biaxial and uniaxial strains broadly modulate the
magnetoelectric response in these materials through two distinct mechanisms:
(i) direct modification of the magnetoelectric tensor components, and (ii)
tuning of the characteristic propagation vectors of a spin texture. This dual
mechanism enables precise control over the magnitude of the spin-induced
electric polarization of these materials. With respect to the achievable
magnitude of the electric polarization, we demonstrate the critical role of
third-nearest-neighbor spin-pair contributions, which can increase under strain
to levels that compete with or even exceed the polarization driven by
first-nearest-neighbor effects. These findings offer important insights into
low-dimensional piezo-magnetoelectricity and expand the possibilities for
designing multifunctional two-dimensional straintronic devices.

</details>


### [313] [High-throughput screening of spin Hall conductivity in 2D materials](https://arxiv.org/abs/2509.13204)
*Fu Li,Xiaoxiong Liu,Vikrant Chaudhary,Ruiwen Xie,Chen Shen,Hao Wang,Hongbin Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 找到六种具有高自旋霍尔电导率（SHC）的二维材料，其SHC超过500（ħ/e）（S/cm），并发现了57种具有量子化SHC的拓扑绝缘体。


<details>
  <summary>Details</summary>
Motivation: 寻找具有大自旋霍尔效应（SHE）的二维材料，用于下一代自旋电子器件。

Method: 使用高通量计算方法，对4486种非磁性化合物的自旋霍尔电导率（SHC）进行了计算。

Result: 识别出六种SHC超过500（ħ/e）（S/cm）的材料，以及57种具有量子化SHC的拓扑绝缘体。发现SOC引起的狄拉克带交叉处能隙打开是高SHC的原因，并且镜面对称性可以增强SHC。

Conclusion: 这项工作通过高通量计算加速了新型二维材料的发现，为自旋电子学应用提供了潜在的实验验证途径。

Abstract: Two-dimensional (2D) materials with large spin Hall effect (SHE) have
attracted significant attention due to their potential applications in
next-generation spintronic devices. In this work, we perform high-throughput
(HTP) calculations to obtain the spin Hall conductivity (SHC) of 4486
non-magnetic compounds in the \texttt{2Dmatpedia} database and identify six
materials with SHC exceeding $500\,(\hbar/e)\,(\mathrm{S/cm})$, surpassing
those of previously known materials. Detailed analysis reveals that the
significant SHC can be attributed to spin-orbit coupling (SOC)-induced gap
openings at Dirac-like band crossings. Additionally, the presence of mirror
symmetry further enhances the SHC. Beyond the high-SHC materials, 57
topological insulators with quantized SHCs have also been identified. Our work
enables rapid screening and paves the way for experimental validation,
potentially accelerating the discovery of novel 2D materials optimized for
spintronics applications.

</details>


### [314] [Effective conduction-band model for zincblende III-V semiconductors in the presence of strain: tuning the properties of bulk crystals and nanostructures](https://arxiv.org/abs/2509.13246)
*Samuel D. Escribano,Alfredo Levy Yeyati,Elsa Prada*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究推导了一个包含应变效应的锌 بلende III-V 半导体导带的有效哈密顿量，该模型能够准确模拟多种纳米结构，为 III-V 半导体器件设计提供了实用工具。


<details>
  <summary>Details</summary>
Motivation: 为了在要求苛刻的介观尺度纳米结构模拟中，对 III-V 族化合物（量子应用的关键材料）的应变效应进行简单而精确的近似，但目前相关方法尚不完善。

Method: 从具有 Bir-Pikus 修正的八带 k·p 模型出发，通过折叠程序得到包含应变效应的导带参数（有效质量、化学势、自旋-轨道耦合和 g 因子）的解析表达式。

Result: 所提出的模型在小到中等应变下能够重现完整的亚带计算结果，并适用于器件尺度的计算。通过对块体变形和代表性纳米结构（如核-壳纳米线和平面异质结构）进行基准测试和应用，验证了模型的有效性。

Conclusion: 该模型为在 III-V 半导体器件设计中纳入应变效应提供了一个实用且通用的工具，能够对器件性质进行可靠预测，对自旋电子学、应变电子学、光电子学和拓扑量子技术具有直接意义。

Abstract: Strain provides a powerful knob to tailor the electronic properties of
semiconductors. Simple yet accurate approximations that capture strain effects
in demanding simulations of mesoscopic nanostructures are therefore highly
desirable. However, for III-V compounds, key materials for quantum
applications, such approaches remain comparatively underdeveloped. In this
work, we derive a compact, effective Hamiltonian that describes the conduction
band of zincblende III-V semiconductors incorporating strain effects. Starting
from the eight-band k$\cdot$p model with Bir-Pikus corrections, we perform a
folding-down procedure to obtain analytical expressions for conduction-band
strain-renormalized parameters, including the effective mass, chemical
potential, spin-orbit coupling, and $g$-factor. The model reproduces full
multiband results under small to moderate strain, while retaining a form
suitable for device-scale calculations. We benchmark the model for bulk
deformations and apply it to representative nanostructures, such as core.shell
nanowires and planar heterostructures. Our results provide a practical and
versatile tool for incorporating strain into the design of III-V semiconductor
devices, enabling reliable predictions of their properties with direct
implications for spintronic, straintronic, optoelectronic, and topological
quantum technologies.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [315] [Low-Altitude UAV Tracking via Sensing-Assisted Predictive Beamforming](https://arxiv.org/abs/2509.12698)
*Yifan Jiang,Qingqing Wu,Hongxun Hui,Wen Chen,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 本篇论文研究了在感知辅助预测波束成形技术下，如何最大化无人机（UAV）跟踪的断信容量。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注频谱效率，而忽略了感知辅助预测波束成形技术对通信可靠性的影响，本研究旨在填补这一空白。

Method: 提出了一种利用扩展卡尔曼滤波（EKF）的蜂窝连接无人机跟踪方案，通过联合优化预测的无人机轨迹、感知持续时间比和目标信噪比（SNR），以最大化每个时间槽的断信容量。利用二阶泰勒展开，推导了预测和测量阶段的断信概率（OP）的闭式近似，并提出了结合二分搜索和连续凸近似（SCA）以及交替优化（AO）的算法来解决非凸优化问题。

Result: 仿真结果表明，所提出的OP近似准确，算法有效，并且在断信容量方面显著优于基准方法。同时，结果还显示，在最大化断信容量时，存在减小路径损耗和享受宽波束覆盖之间的权衡。

Conclusion: 本研究成功解决了感知辅助预测波束成形下的无人机跟踪断信容量最大化问题，并提出了有效的优化算法和近似方法，为未来的无人机应用提供了重要的理论和实践指导。

Abstract: Sensing-assisted predictive beamforming, as one of the enabling technologies
for emerging integrated sensing and communication (ISAC) paradigm, shows
significant promise for enhancing various future unmanned aerial vehicle (UAV)
applications. However, current works predominately emphasized on spectral
efficiency enhancement, while the impact of such beamforming techniques on the
communication reliability was largely unexplored and challenging to
characterize. To fill this research gap and tackle this issue, this paper
investigates outage capacity maximization for UAV tracking under the
sensing-assisted predictive beamforming scheme. Specifically, a
cellular-connected UAV tracking scheme is proposed leveraging extended Kalman
filtering (EKF), where the predicted UAV trajectory, sensing duration ratio,
and target constant received signal-to-noise ratio (SNR) are jointly optimized
to maximize the outage capacity at each time slot. To address the implicit
nature of the objective function, closed-form approximations of the outage
probabilities (OPs) at both prediction and measurement stages of each time slot
are proposed based on second-order Taylor expansions, providing an efficient
and full characterization of outage capacity. Subsequently, an efficient
algorithm is proposed based on a combination of bisection search and successive
convex approximation (SCA) to address the non-convex optimization problem with
guaranteed convergence. To further reduce computational complexity, a second
efficient algorithm is developed based on alternating optimization (AO).
Simulation results validate the accuracy of the derived OP approximations, the
effectiveness of the proposed algorithms, and the significant outage capacity
enhancement over various benchmarks, while also indicating a trade-off between
decreasing path loss and enjoying wide beam coverage for outage capacity
maximization.

</details>


### [316] [FAS-ARIS: Turning Multipath Challenges Into Localization Opportunities](https://arxiv.org/abs/2509.12348)
*Hua Chen,Tao Gong,Tuo Wu,Maged Elkashlan,Baiyang Liu,Chan-Byoung Chae,Kin-Fai Tong,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 该研究提出了一种新颖的流体天线系统（FAS）-有源可重构智能表面（ARIS）框架，用于在多径环境下实现精确的三维（3D）定位。该系统通过放大信号（ARIS）和空间分集（FAS）来利用多径效应，无需到达时（ToA）或频率分集等辅助信息。


<details>
  <summary>Details</summary>
Motivation: 传统单输入单输出（SISO）系统在三维（3D）定位方面存在局限性，容易受到多径传播的不利影响。

Method: 提出了一种结合ARIS信号放大和FAS空间分集的新型框架。通过定制的信号解耦策略分离视距（LoS）和非视距（NLoS）信道，并采用多阶段估计算法：MUSIC算法估计AoA，最大似然估计恢复级联信道参数，最后通过最小二乘估计进行三维定位。

Result: 推导了信道和位置估计的Cramér-Rao界限，并通过仿真验证了所提出的FAS-ARIS框架在多径环境下的定位精度接近最优，且鲁棒性强。

Conclusion: 所提出的FAS-ARIS框架能够有效地将传统定位中的挑战转化为优势，在恶劣的多径环境中实现接近最优的定位精度和鲁棒性。

Abstract: Traditional single-input single-output (SISO) systems face fundamental
limitations in achieving accurate three-dimensional (3D) localization due to
limited spatial degrees of freedom (DoF) and the adverse impact of multipath
propagation. This paper proposes a novel fluid antenna system (FAS)-active
reconfigurable intelligent surface (ARIS) framework that transforms multipath
effects from a hindrance into a resource for enhanced localization. By
synergistically combining the signal amplification capabilities of ARIS with
the spatial diversity enabled by FAS, the proposed system achieves robust 3D
user equipment (UE) positioning -- without relying on auxiliary information
such as time-of-arrival (ToA) or frequency diversity. The system exploits both
line-of-sight (LoS) and non-line-of-sight (NLoS) components through a tailored
signal decoupling strategy. We design novel UE pilot sequences and ARIS phase
configurations to effectively separate LoS and NLoS channels, enabling
independent parameter estimation. A multi-stage estimation algorithm is then
applied: the multiple signal classification (MUSIC) algorithm estimates
angle-of-arrival (AoA) from the direct path, while maximum likelihood
estimation with interior-point refinement recovers cascaded channel parameters
from the reflected path. Finally, geometric triangulation using least-squares
estimation determines the UE's 3D position based on the extracted AoA
information. Comprehensive performance analysis, including the derivation of
Cram\'{e}r-Rao bounds for both channel and position estimation, establishes
theoretical benchmarks. Simulation results confirm that the proposed FAS-ARIS
framework achieves near-optimal localization accuracy while maintaining
robustness in rich multipath environments -- effectively turning conventional
localization challenges into advantages.

</details>


### [317] [Partial Secrecy Analysis in Wireless Systems: Diversity-Enhanced PLS over Generalized Fading Channels](https://arxiv.org/abs/2509.12359)
*Henry Carvajal Mora,Nathaly Orozco,Fernando Almeida García,José Vega-Sánchez,Felipe Grijalva,Edgar Benitez Olivo*

Main category: eess.SP

TL;DR: 该论文在广义多簇波动双射线（MFTR）衰落模型下，针对计算资源受限的未来移动网络中的部分保密性问题进行了分析，并推导了广义保密中断概率（GSOP）、平均分数 الاختصار（AFE）和平均信息泄露率（AILR）的精确解析表达式和闭式近似表达式，证明了在部分保密下，增加接收端B处的最大比合并（MRC）分支数量可以提升保密性能，且该方法复杂度恒定。


<details>
  <summary>Details</summary>
Motivation: 在未来移动网络中，为计算资源有限的设备提供信息安全是一个挑战。物理层安全（PLS）通过利用无线信道随机性提供了一种可行的解决方案，特别是在无法实现完全保密的情况下，部分保密机制提供了一种更现实的替代方案。

Method: 研究了在广义多簇波动双射线（MFTR）衰落模型下，包含发射端（A）、合法接收端（B）和窃听端（E）的系统，其中B和E采用天线阵列和最大比合并（MRC），并考虑了不独立且不恒定方差（i.n.i.d.）的衰落。推导了广义保密中断概率（GSOP）、平均分数 الاختصار（AFE）和平均信息泄露率（AILR）的精确解析表达式和闭式近似表达式。

Result: 推导了GSOP、AFE和AILR的精确解析表达式和闭式近似表达式，并与蒙特卡洛仿真结果进行了验证。结果表明，该方法具有恒定的复杂度，不随分集阶数变化。MFTR模型的灵活性使得能够全面评估各种衰落条件下的性能，并且表明增加B处的MRC分支数量可以提升保密性能，具体提升程度取决于A-E链路的特性。

Conclusion: 在MFTR衰落模型下，针对部分保密场景，推导了关键保密指标的精确表达式和近似表达式。仿真结果表明，增加接收端B处的MRC分支数量能够提升保密性能，且性能提升效果与A-E链路的特性相关。所提出的方法复杂度恒定，并且MFTR模型具有良好的灵活性。

Abstract: Securing information in future mobile networks is challenging, especially for
devices with limited computational resources. Physical layer security (PLS)
offers a viable solution by leveraging wireless channel randomness. When full
secrecy is unattainable, the partial secrecy regime provides a realistic
alternative. This work analyzes partial secrecy performance under the
generalized multicluster fluctuating two-ray (MFTR) fading model, which
subsumes many classical fading cases. We study a system with a transmitter (A),
legitimate receiver (B), and eavesdropper (E), both B and E using antenna
arrays with maximal ratio combining (MRC), under i.n.i.d. fading. Exact and
closed-form approximations are derived for key secrecy metrics: generalized
secrecy outage probability (GSOP), average fractional equivocation (AFE), and
average information leakage rate (AILR). The results, validated by Monte Carlo
simulations, retain constant complexity regardless of diversity order. The MFTR
model's flexibility enables comprehensive assessment across fading conditions,
showing that more MRC branches at B enhance secrecy performance depending on
the A-E link characteristics.

</details>


### [318] [Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device](https://arxiv.org/abs/2509.12510)
*Wei Shao,Ruoyu Zhang,Zequan Liang,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 该研究提出了一种新颖的、完全无监督的 PPG 信号质量评估 (SQA) 框架，结合了自监督学习 (SSL) 和拓扑数据分析 (TDA)，能够处理各种设备和运动伪影。


<details>
  <summary>Details</summary>
Motivation: 现有的 PPG 信号质量评估方法要么依赖于脆弱的启发式方法，要么依赖于需要大量数据的监督模型，而我们提出的方法是完全无监督的，并且对各种干扰具有鲁棒性。

Method: 第一阶段，使用 276 小时的数据训练一个对比学习的 1-D ResNet-18 模型，以生成对光学发射器和运动不敏感的嵌入。第二阶段，使用持久同源性 (PH) 将这些嵌入转换为拓扑特征，并使用 HDBSCAN 对其进行聚类，密度最高的簇被认为是高质量信号。

Result: 在 10,000 个样本窗口的测试中，该方法达到了 0.72 的轮廓系数，0.34 的 Davies-Bouldin 指数和 6173 的 Calinski-Harabasz 指数，表明了其在信号质量评估方面的有效性。

Conclusion: 我们提出了一个混合自监督学习-拓扑数据分析 (SSL-TDA) 框架，为 PPG 信号提供了一个易于集成、可扩展且跨设备的质量门控解决方案。

Abstract: Wearable photoplethysmography (PPG) is embedded in billions of devices, yet
its optical waveform is easily corrupted by motion, perfusion loss, and ambient
light, jeopardizing downstream cardiometric analytics. Existing signal-quality
assessment (SQA) methods rely either on brittle heuristics or on data-hungry
supervised models. We introduce the first fully unsupervised SQA pipeline for
wrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,
unlabeled data from heterogeneous sources (varying in device and sampling
frequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,
the learned representation is stable across differences in LED wavelength,
drive intensity, and device optics, as well as wrist motion). Stage 2 converts
each 512-D encoder embedding into a 4-D topological signature via persistent
homology (PH) and clusters these signatures with HDBSCAN. To produce a binary
signal-quality index (SQI), the acceptable PPG signals are represented by the
densest cluster while the remaining clusters are assumed to mainly contain
poor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,
Davies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,
respectively, on a stratified sample of 10,000 windows. In this study, we
propose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)
framework that offers a drop-in, scalable, cross-device quality gate for PPG
signals.

</details>


### [319] [Rapid Adaptation of SpO2 Estimation to Wearable Devices via Transfer Learning on Low-Sampling-Rate PPG](https://arxiv.org/abs/2509.12515)
*Zequan Liang,Ruoyu Zhang,Wei Shao,krishna Karthik,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 提出一种基于迁移学习的框架，用于在低功耗可穿戴设备上快速适配血氧饱和度（SpO2）估算，使用低采样率（25Hz）双通道光电容积脉搏波（PPG）。


<details>
  <summary>Details</summary>
Motivation: 传统SpO2估算方法需要复杂的临床校准，不适用于低功耗可穿戴设备。

Method: 首先在公开临床数据集上预训练双向长短期记忆（BiLSTM）模型，然后使用从自研可穿戴设备“We-Be band”和FDA批准的参考脉搏血氧仪收集的数据进行微调。

Result: 在公开数据集上达到2.967%的平均绝对误差（MAE），在私有数据集上达到2.624%的MAE，显著优于传统校准和非迁移学习基线。使用25Hz PPG可减少40%的功耗。在瞬时SpO2预测中达到3.284%的MAE。

Conclusion: 所提出的方法能够快速适配准确、低功耗的SpO2监测，用于可穿戴设备，无需临床校准。

Abstract: Blood oxygen saturation (SpO2) is a vital marker for healthcare monitoring.
Traditional SpO2 estimation methods often rely on complex clinical calibration,
making them unsuitable for low-power, wearable applications. In this paper, we
propose a transfer learning-based framework for the rapid adaptation of SpO2
estimation to energy-efficient wearable devices using low-sampling-rate (25Hz)
dual-channel photoplethysmography (PPG). We first pretrain a bidirectional Long
Short-Term Memory (BiLSTM) model with self-attention on a public clinical
dataset, then fine-tune it using data collected from our wearable We-Be band
and an FDA-approved reference pulse oximeter. Experimental results show that
our approach achieves a mean absolute error (MAE) of 2.967% on the public
dataset and 2.624% on the private dataset, significantly outperforming
traditional calibration and non-transferred machine learning baselines.
Moreover, using 25Hz PPG reduces power consumption by 40% compared to 100Hz,
excluding baseline draw. Our method also attains an MAE of 3.284% in
instantaneous SpO2 prediction, effectively capturing rapid fluctuations. These
results demonstrate the rapid adaptation of accurate, low-power SpO2 monitoring
on wearable devices without the need for clinical calibration.

</details>


### [320] [Generalizable Blood Pressure Estimation from Multi-Wavelength PPG Using Curriculum-Adversarial Learning](https://arxiv.org/abs/2509.12518)
*Zequan Liang,Ruoyu Zhang,Wei Shao,Mahdi Pirayesh Shirazi Nejad,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 本研究提出了一种基于课程-对抗学习的通用血压估计算法，通过融合多通道光电容积脉搏波（PPG）信号，在严格的受试者级别划分下，实现了对收缩压（SBP）和舒张压（DBP）的准确估计。


<details>
  <summary>Details</summary>
Motivation: 准确且可泛化的血压（BP）估计对于心血管疾病的早期检测和管理至关重要。

Method: 本研究提出了一种基于课程-对抗学习的通用血压估计算法。该方法结合了课程学习（从高血压分类过渡到血压回归）和领域对抗训练（混淆受试者身份以鼓励学习受试者不变的特征），并对公共多波长光电容积脉搏波（PPG）数据集执行了受试者级别的数据划分。

Result: 在四波长PPG数据集上，在严格的受试者级别划分下，本研究提出的方法实现了强大的性能，收缩压（SBP）的平均绝对误差（MAE）为14.2mmHg，舒张压（DBP）为6.4mmHg。实验表明，多通道融合始终优于单通道模型。消融研究验证了课程学习和对抗学习组件的有效性。

Conclusion: 研究结果强调了利用多波长PPG中的互补信息以及课程-对抗策略进行准确、鲁棒的血压估计的潜力。

Abstract: Accurate and generalizable blood pressure (BP) estimation is vital for the
early detection and management of cardiovascular diseases. In this study, we
enforce subject-level data splitting on a public multi-wavelength
photoplethysmography (PPG) dataset and propose a generalizable BP estimation
framework based on curriculum-adversarial learning. Our approach combines
curriculum learning, which transitions from hypertension classification to BP
regression, with domain-adversarial training that confuses subject identity to
encourage the learning of subject-invariant features. Experiments show that
multi-channel fusion consistently outperforms single-channel models. On the
four-wavelength PPG dataset, our method achieves strong performance under
strict subject-level splitting, with mean absolute errors (MAE) of 14.2mmHg for
systolic blood pressure (SBP) and 6.4mmHg for diastolic blood pressure (DBP).
Additionally, ablation studies validate the effectiveness of both the
curriculum and adversarial components. These results highlight the potential of
leveraging complementary information in multi-wavelength PPG and
curriculum-adversarial strategies for accurate and robust BP estimation.

</details>


### [321] [Kalman Filtering of Stationary Graph Signals](https://arxiv.org/abs/2509.12605)
*Yang Chen,Yeonju Lee,Yao Shi,Qiyu Sun*

Main category: eess.SP

TL;DR: 本文提出了一种新的平稳图信号定义，并研究了其在动态系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究平稳图信号的生成、保持和过滤方法，特别是在具有多项式状态和观测矩阵的动态系统背景下。

Method: 提出了一种新的平稳图信号定义，并研究了通过多项式图信道传输白噪声来生成和保持平稳图信号的方法。此外，研究了在动态系统中应用卡尔曼滤波来处理平稳图信号，并将其与静态逆滤波和零信号策略进行比较。

Result: 证明了平稳图信号可以通过多项式图信道生成和保持。研究表明，卡尔曼滤波能够保持图信号的平稳性，并有效地结合系统动力学和噪声结构，提供比静态逆滤波和零信号策略更准确和自适应的信号估计。

Conclusion: 卡尔曼滤波是一种在图信号处理中强大且通用的方法，能够精确地估计动态系统中的平稳图信号。

Abstract: In this paper, we propose a novel definition of stationary graph signals,
formulated with respect to a symmetric graph shift, such as the graph
Laplacian. We show that stationary graph signals can be generated by
transmitting white noise through polynomial graph channels, and that their
stationarity is preserved under polynomial channel transmission.
  In this paper, we also investigate Kalman filtering to dynamical systems
characterized by polynomial state and observation matrices. We demonstrate that
Kalman filtering maintains the stationarity of graph signals, while effectively
incorporating both system dynamics and noise structure. In comparison to the
static inverse filtering method and naive zero-signal strategy, the Kalman
filtering procedure yields more accurate and adaptive signal estimates,
highlighting its robustness and versatility in graph signal processing.

</details>


### [322] [Data Fusion for BS-UE Cooperative MIMO-OFDM ISAC](https://arxiv.org/abs/2509.12646)
*Yixin Ding,Haoyu Jiang,Xiaoli Xu,Yanan Liang,Yong Zeng*

Main category: eess.SP

TL;DR: 该论文提出了一种新的基站（BS）和用户设备（UE）协同感知操作模式，以提高无线网络的感知能力。


<details>
  <summary>Details</summary>
Motivation: 为了进一步增强无线网络的感知能力，并利用现有的通信基础设施来执行感知任务。

Method: 提出了一种基站（BS）和用户设备（UE）协同感知的新操作模式。UE在解码通信数据后，进一步处理接收到的信号以提取目标感知信息。提出了一种有效的数据融合算法，该算法利用BS、UE和目标之间的几何关系以及BS单站和BS-UE双站感知中预期的感知质量来融合来自BS和UE的感知结果。

Result: 所提出的数据融合方法可以有效提高多目标的位置和速度估计精度。

Conclusion: 所提出的协同感知数据融合方法为扩展感知模式提供了新的途径，并能有效提升多目标定位和测速的精度。

Abstract: Integrated sensing and communication (ISAC) is a promising technique for
expanding the functionalities of wireless networks with enhanced spectral
efficiency. The 3rd Generation Partnership Project (3GPP) has defined six basic
sensing operation modes in wireless networks. To further enhance the sensing
capability of wireless networks, this paper proposes a new sensing operation
mode, i.e., the base station (BS) and user equipment (UE) cooperative sensing.
Specifically, after decoding the communication data, the UE further processes
the received signal to extract the target sensing information. We propose an
efficient algorithm for fusing the sensing results obtained by the BS and UE,
by exploiting the geometric relationship among BS, UE and targets as well as
the expected sensing quality in the BS monostatic and BS-UE bistatic sensing.
The results show that the proposed data fusion method for cooperative sensing
can effectively improve the position and velocity estimation accuracy of
multiple targets, and provide a new approach on the expansion of the sensing
pattern.

</details>


### [323] [Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI](https://arxiv.org/abs/2509.12658)
*Po-Heng Chou,Jiun-Jia Wu,Wan-Jen Huang,Ronald Y. Chang*

Main category: eess.SP

TL;DR: 提出一种基于LSTM的预编码框架，用于RIS辅助的毫米波MIMO系统，无需显式信道状态信息（CSI），利用上行导频序列隐式学习信道特征，并考虑了RIS元件的相位依赖幅度模型和多标签训练策略。


<details>
  <summary>Details</summary>
Motivation: 提高RIS辅助毫米波MIMO系统的能效和性能，减少导频开销和推理复杂度。

Method: 提出一种基于LSTM的预编码框架，利用上行导频序列隐式学习信道特征，并结合相位依赖幅度模型和多标签训练策略。

Result: 在计算时间和能耗方面，提出的设计实现了穷举搜索（ES）的90%以上的频谱效率，而计算时间仅为其2.2%，能耗降低了近两个数量级。

Conclusion: 该方法在分布不匹配下表现出韧性，并且可以扩展到更大的RIS阵列，是一种实用且节能的6G无线网络解决方案。

Abstract: In this paper, we propose a sustainable long short-term memory (LSTM)-based
precoding framework for reconfigurable intelligent surface (RIS)-assisted
millimeter-wave (mmWave) MIMO systems. Instead of explicit channel state
information (CSI) estimation, the framework exploits uplink pilot sequences to
implicitly learn channel characteristics, reducing both pilot overhead and
inference complexity. Practical hardware constraints are addressed by
incorporating the phase-dependent amplitude model of RIS elements, while a
multi-label training strategy improves robustness when multiple near-optimal
codewords yield comparable performance. Simulations show that the proposed
design achieves over 90% of the spectral efficiency of exhaustive search (ES)
with only 2.2% of its computation time, cutting energy consumption by nearly
two orders of magnitude. The method also demonstrates resilience under
distribution mismatch and scalability to larger RIS arrays, making it a
practical and energy-efficient solution for sustainable 6G wireless networks.

</details>


### [324] [NEFT: A Unified Transformer Framework for Efficient Near-Field CSI Feedback in XL-MIMO Systems](https://arxiv.org/abs/2509.12748)
*Haiyang Li,Tianqi Mao,Pengyu Wang,Ruiqi Liu,Shunyu Li,Zhaocheng Wang*

Main category: eess.SP

TL;DR: NEFT是一种用于XL-MIMO近场CSI反馈的Transformer模型，能在保持高精度的同时，通过轻量化设计降低计算开销，并支持多样化的硬件部署。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在近场CSI反馈中存在结构复杂、计算开销大等问题，难以满足实际移动设备的需求。

Method: 提出NEFT（Near-Field Efficient Feedback Transformer）系列模型，采用分层Vision Transformer骨干，并推出NEFT-Compact（多级知识蒸馏）、NEFT-Hybrid（无注意力编码）和NEFT-Edge（边缘约束）等轻量化变体。

Result: NEFT在NMSE方面比现有方法有15-21dB的提升；NEFT-Compact和NEFT-Edge将FLOPs降低25-36%，精度损失可忽略；NEFT-Hybrid将编码器复杂度降低高达64%。

Conclusion: NEFT系列模型为XL-MIMO系统提供了实用且可扩展的近场CSI反馈解决方案。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems,
operating in the near-field region due to their massive antenna arrays, are a
key enabler of next-generation wireless communications but face significant
challenges in channel state information (CSI) feedback. Deep learning has
emerged as a powerful tool by learning compact CSI representations for
feedback. However, existing methods struggle to capture the intricate structure
of near-field CSI while incurring prohibitive computational overhead on
practical mobile devices. To overcome these limitations, we propose the
Near-Field Efficient Feedback Transformer (NEFT) family for accurate and
efficient near-field CSI feedback across diverse hardware platforms. Built on a
hierarchical Vision Transformer backbone, NEFT is extended with lightweight
variants to meet various deployment constraints: NEFT-Compact applies
multi-level knowledge distillation (KD) to reduce complexity while maintaining
accuracy, and NEFT-Hybrid and NEFT-Edge address encoder- and edge-constrained
scenarios via attention-free encoding and KD. Extensive simulations show that
NEFT achieves a 15--21 dB improvement in normalized mean-squared error (NMSE)
over state-of-the-art methods, while NEFT-Compact and NEFT-Edge reduce total
FLOPs by 25--36% with negligible accuracy loss. Moreover, NEFT-Hybrid lowers
encoder-side complexity by up to 64%, enabling deployment in highly asymmetric
device scenarios. These results establish NEFT as a practical and scalable
solution for near-field CSI feedback in XL-MIMO systems.

</details>


### [325] [EMC Limit Level Guidelines for In-System Interference with GPS Receivers](https://arxiv.org/abs/2509.12770)
*Giorgi Tsintsadze,Haran Manoharan,Aaron Harmon,Daniel Commerou,Connor Buneta,Brian Booth,Daryl Beetner*

Main category: eess.SP

TL;DR: 本文提出了针对靠近GPS接收器的电子设备EMC（电磁兼容性）限制水平指南。


<details>
  <summary>Details</summary>
Motivation: 电子系统和组件的电磁干扰会干扰GPS信号，影响GPS接收器的性能。

Method: 提出了一种理论模型，用于预测由射频干扰引起的载波噪声比（C/N0）的下降，并通过实际噪声源进行了验证。利用该模型开发了评估电子设备对附近GPS接收器影响的指南。

Result: 该模型能够根据噪声的频率、带宽和幅度预测对C/N0的影响，并据此制定了EMC限制水平指南。

Conclusion: 所提出的指南为评估电子设备对GPS接收器的干扰提供了一种比传统方法更精细的评估方式。

Abstract: Because GPS signals are weak, electronic systems and components that are
placed near GPS receivers can easily cause disruptive electromagnetic
interference through their unintended radiated emissions. In this paper, EMC
limit level guidelines are presented for electronics that are intended to be
placed near to GPS receivers, as often happens in automotive and other
applications. One of the challenges of defining limit-levels for systems
intended to be integrated with GPS receivers is that the impact of noise at the
input of the receiver may vary substantially depending on the form of the noise
due to the correlator function implemented by GPS receiver. The quality of the
correlated signal is typically represented using the carrier-to-noise ratio ($C
/ N_0$). A theoretical model predicting the degredation of the carrier-to-noise
ratio with radio frequency interference is presented in this paper and is
validated with realistic noise sources. The model is then used to develop
guidelines to assess the impact of unintended emissions from electronic devices
on nearby GPS receivers based on the frequency, bandwidth, and magnitude of the
noise. These guidelines provide a more nuanced method of evaluating emissions
than simple limit lines that are used by many emissions standards.

</details>


### [326] [A Statistical Benchmark for Diffusion Posterior Sampling Algorithms](https://arxiv.org/abs/2509.12821)
*Martin Zach,Youssef Haouchat,Michael Unser*

Main category: eess.SP

TL;DR: 本文提出了一个用于扩散后验采样（DPS）算法的统计基准，该基准用于贝叶斯线性逆问题。


<details>
  <summary>Details</summary>
Motivation: 为了评估和改进用于贝叶斯线性逆问题的扩散后验采样（DPS）算法，需要一个标准的评估框架。

Method: 提出一个合成稀疏L'evy-过程先验的信号的统计基准，其后验分布允许高效的Gibbs采样。通过使用Gibbs采样来解决反向扩散中的去噪问题，该框架还可以分离由似然得分近似引起误差。在基准中，我们使用最小均方误差最优性差距和后验覆盖率测试，并在去噪、去卷积、插补和部分傅里叶测量重构等逆问题上对流行的DPS算法进行了数值实验。

Result: 通过使用Gibbs采样作为黄金标准，并隔离似然得分近似误差，对多种DPS算法在不同逆问题上的性能进行了评估。

Conclusion: 本文提出了一个用于DPS算法的统计基准，并提供了代码实现，以促进对这些算法的进一步研究和改进。

Abstract: We propose a statistical benchmark for diffusion posterior sampling (DPS)
algorithms for Bayesian linear inverse problems. The benchmark synthesizes
signals from sparse L\'evy-process priors whose posteriors admit efficient
Gibbs methods. These Gibbs methods can be used to obtain gold-standard
posterior samples that can be compared to the samples obtained by the DPS
algorithms. By using the Gibbs methods for the resolution of the denoising
problems in the reverse diffusion, the framework also isolates the error that
arises from the approximations to the likelihood score. We instantiate the
benchmark with the minimum-mean-squared-error optimality gap and posterior
coverage tests and provide numerical experiments for popular DPS algorithms on
the inverse problems of denoising, deconvolution, imputation, and
reconstruction from partial Fourier measurements. We release the benchmark code
at https://github.com/zacmar/dps-benchmark. The repository exposes simple
plug-in interfaces, reference scripts, and config-driven runs so that new
algorithms can be added and evaluated with minimal effort. We invite
researchers to contribute and report results.

</details>


### [327] [Bayesian Signal Separation via Plug-and-Play Diffusion-Within-Gibbs Sampling](https://arxiv.org/abs/2509.12857)
*Yi Zhang,Rui Guo,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出一种结合Gibbs采样和即插即用（PnP）扩散先验的后验采样算法，用于从噪声叠加中估计多个独立源信号。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的方法在信号分离时，通常需要重新训练以组合不同的源先验。而本文提出的算法允许独立学习和灵活组合源先验，无需重新训练。

Method: 提出一种后验采样算法，结合了Gibbs采样方法和即插即用（PnP）扩散先验。

Result: 在从包含合成运动伪影的混合信号中提取心跳信号的任务上，实验证明了该方法优于现有方法。

Conclusion: 在假设扩散模型训练完美的情况下，该方法可产生源信号后验分布的样本，并在心跳提取任务中表现出优越性能。

Abstract: We propose a posterior sampling algorithm for the problem of estimating
multiple independent source signals from their noisy superposition. The
proposed algorithm is a combination of Gibbs sampling method and plug-and-play
(PnP) diffusion priors. Unlike most existing diffusion-model-based approaches
for signal separation, our method allows source priors to be learned separately
and flexibly combined without retraining. Moreover, under the assumption of
perfect diffusion model training, the proposed method provably produces samples
from the posterior distribution. Experiments on the task of heartbeat
extraction from mixtures with synthetic motion artifacts demonstrate the
superior performance of our method over existing approaches.

</details>


### [328] [Towards personalized, precise and survey-free environment recognition: AI-enhanced sensor fusion without pre-deployment](https://arxiv.org/abs/2509.12870)
*Ruichen Wang,Zhikang Ni,Pengzhou Wang,Xiya Cao,Zhi Li,Bao Zhang*

Main category: eess.SP

TL;DR: 该研究提出了一种无需踩点、能在设备上运行的传感器融合框架，通过融合行人航迹推算、WiFi/蜂窝网络、GNSS和交互时间标签，构建个性化、轻量级多源指纹库。利用AI增强的动态时间规整（AIDTW）模块进行匹配，并通过基于云的在线强化学习（RLHF）循环持续优化策略，将网络切换延迟（TTS）降低了32-65%。


<details>
  <summary>Details</summary>
Motivation: 传统指纹识别需要昂贵的踩点，且缺乏用户级别的自适应能力，因此需要一种无需踩点、能进行用户级别自适应的环境识别方法。

Method: 提出了一种无需踩点、能在设备上运行的传感器融合框架，融合了行人航迹推算、WiFi/蜂窝网络、GNSS和交互时间标签，构建个性化、轻量级多源指纹库。利用AI增强的动态时间规整（AIDTW）模块进行匹配。通过云边协同的在线强化学习（RLHF）循环，利用近端策略优化（PPO）算法聚合去标识化摘要和用户反馈，以优化策略，并将更新周期性地分发到设备上。

Result: 在室内/室外场景下，与传统方法相比，该系统将日常环境中的网络切换延迟（TTS）降低了32-65%，且无需进行特定站点的预部署。

Conclusion: 该研究提出了一种无需踩点、用户自适应的环境识别框架，通过传感器融合、AIDTW匹配和RLHF优化，显著降低了网络切换延迟，为实现无缝室内定位和优化连接提供了有效解决方案。

Abstract: Accurate and personalized environment recognition is essential for seamless
indoor positioning and optimized connectivity, yet traditional fingerprinting
requires costly site surveys and lacks user-level adaptation. We present a
survey-free, on-device sensor-fusion framework that builds a personalized,
lightweight multi-source fingerprint (FP) database from pedestrian dead
reckoning (PDR), WiFi/cellular, GNSS, and interaction time tags. Matching is
performed by an AI-enhanced dynamic time warping module (AIDTW) that aligns
noisy, asynchronous sequences. To turn perception into continually improving
actions, a cloud-edge online Reinforcement Learning from Human Feedback (RLHF)
loop aggregates desensitized summaries and human feedback in the cloud to
optimize a policy via proximal policy optimization (PPO), and periodically
distills updates to devices. Across indoor/outdoor scenarios, our system
reduces network-transition latency (measured by time-to-switch, TTS) by 32-65%
in daily environments compared with conventional baselines, without
site-specific pre-deployment.

</details>


### [329] [Next-Generation Backscatter Networks for Integrated Communications and RF Sensing](https://arxiv.org/abs/2509.12954)
*Traian E. Abrudan,Kartik Patel,John Kimionis,Tara Esmaeilbeig,Eleftherios Kampianakis,Sahan Damith Liyanaarachchi,Michael Eggleston*

Main category: eess.SP

TL;DR: 本论文提出了一个结合通信和射频定位感知功能的下一代回波散射网络模型，并通过理论和实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 下一代回波散射网络需要集成射频定位感知功能，以支持大规模、能源效率高的机器类型通信网络。

Method: 推导了宽带OFDM回波散射系统的端到端系统模型，包括信道、接收器损伤、射频标签操作和不同步网络节点。提出了一种实用的非同步测距方法，并推导了Cramér-Rao下界（CRLB）来分析性能极限。

Result: 通过实际硬件实验验证了理论模型的准确性，并展示了通信、射频感知和测距方面的系统性能，同时与理论极限进行了基准测试。

Conclusion: 该分析框架和实验验证为未来大规模部署的、能源效率高的分布式、非同步回波散射系统奠定了基础理解。

Abstract: This paper provides a comprehensive analysis and theoretical foundation for
next-generation backscatter networks that move beyond communication and
integrate RF location sensing capabilities. An end-to-end system model for
wideband OFDM backscatter systems is derived, including detailed
characterization of propagation channels, receiver chain impairments, RF tag
operation, and unsynchronized network nodes. The theoretical system model is
validated through experimental evaluation using actual hardware, demonstrating
the detailed model's accuracy. A practical bistatic ranging method that can
operate with unsynchronized nodes is presented, along with the Cram\'er-Rao
Lower Bound (CRLB) derived to show the achievable performance limits. Our
experimental results demonstrate the system performance for communication, RF
sensing, and ranging, while also benchmarking against the derived theoretical
limits. This analytical framework and experimental validation establish
fundamental understanding of distributed, unsynchronized backscatter systems
for future machine-type communication networks that are deployed in massive
scale, while remaining energy-efficient.

</details>


### [330] [Difference-Based Recovery for Modulo Sampling: Tightened Bounds and Robustness Guarantees](https://arxiv.org/abs/2509.12971)
*Wenyi Yan,Zeyuan Li,Lu Gan,Honqing Liu,Guoquan Li*

Main category: eess.SP

TL;DR: 与传统ADC不同，本文提出的基于差分的恢复方法克服了信号超出输入范围的限制，并且在减少过采样因子和考虑采样抖动方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 现有模数转换器(ADC)在信号超出其输入范围时会出现削波现象。为了克服这一限制，本文旨在研究一种新的方法，该方法可以处理超出输入范围的信号，并能有效恢复原始信号，同时解决计算量大、过采样界限宽松以及采样抖动等问题。

Method: 本文重新审视了基于差分的恢复方法，建立了新的理论和实践保证。在无噪声情况下，证明了任意高差分阶数可将过采样因子从$2\pi e$减小到$\\pi$，显著收紧了经典界限。对于固定阶数N，推导了保证稳定恢复的噪声感知采样条件。对于二阶差分恢复(N=2)，进一步将分析扩展到非均匀采样，证明了在有界抖动下的鲁棒性。基于FPGA的硬件原型验证了该方法的高性能和可行性。

Result: 在无噪声情况下，将过采样因子从$2\pi e$减小到$\\pi$。对于固定阶数N，提出了噪声感知采样条件。对于二阶差分恢复，证明了在有界抖动下的鲁棒性。FPGA原型验证了高达$\\rho = 108$的幅度扩展，证明了高性能和简单鲁棒的恢复流程。

Conclusion: 本文提出的基于差分的恢复方法在理论和实践上都取得了显著进展，能够实现高性能的无限采样，并且硬件实现简单、鲁棒。

Abstract: Conventional analog-to-digital converters (ADCs) clip when signals exceed
their input range. Modulo (unlimited) sampling overcomes this limitation by
folding the signal before digitization, but existing recovery methods are
either computationally intensive or constrained by loose oversampling bounds
that demand high sampling rates. In addition, none account for sampling jitter,
which is unavoidable in practice. This paper revisits difference-based recovery
and establishes new theoretical and practical guarantees. In the noiseless
setting, we prove that arbitrarily high difference order reduces the sufficient
oversampling factor from $2\pi e$ to $\pi$, substantially tightening classical
bounds. For fixed order $N$, we derive a noise-aware sampling condition that
guarantees stable recovery. For second-order difference-based recovery ($N=2$),
we further extend the analysis to non-uniform sampling, proving robustness
under bounded jitter. An FPGA-based hardware prototype demonstrates reliable
reconstruction with amplitude expansion up to $\rho = 108$, confirming the
feasibility of high-performance unlimited sensing with a simple and robust
recovery pipeline.

</details>


### [331] [RF-Powered Batteryless Plant Movement Sensor for Precision Agriculture](https://arxiv.org/abs/2509.13004)
*Jona Cappelle,Jarne Van Mulders,Sarah Goossens,Thomas Reher,Liesbet Van der Perre,Lieven De Strycker,Bram Van de Poel,Gilles Callebaut*

Main category: eess.SP

TL;DR: 本文设计并实现了一种仅由射频能量供电、无需电池的轻量化植物运动传感器，用于精准农业中的植物监测。


<details>
  <summary>Details</summary>
Motivation: 为了满足精准农业对非侵入式、节能、可持续的植物监测解决方案的需求，本文旨在设计一种无需电池的植物运动传感器，以减少环境影响、重量和维护需求。

Method: 通过集成惯性测量单元（IMU）来监测叶片运动，该运动与植物对环境胁迫的生理反应相关。所提出的传感器能够根据能量可用性和传感器数据，最小化电路复杂度并实现灵活、自适应的读数调度。

Result: 文中详细阐述了能量需求、射频能量传输的考虑因素、集成限制，并提出了包括多天线供电和传感器网络同步在内的未来发展方向。

Conclusion: 本文提出了一种创新的、无电池的植物运动传感器，能够通过射频能量供电，为精准农业提供了一种可持续且维护量低的解决方案，并为未来的进一步发展指明了方向。

Abstract: Precision agriculture demands non-invasive, energy-efficient, and sustainable
plant monitoring solutions. In this work, we present the design and
implementation of a lightweight, batteryless plant movement sensor powered
solely by RF energy. This sensor targets Controlled Environment Agriculture
(CEA) and utilizes inertial measurements units (IMUs) to monitor leaf motion,
which correlates with plant physiological responses to environmental stress. By
eliminating the battery, we reduce the ecological footprint, weight, and
maintenance requirements, transitioning from lifetime-based to operation-based
energy storage. Our design minimizes circuit complexity while enabling
flexible, adaptive readout scheduling based on energy availability and sensor
data. We detail the energy requirements, RF power transfer considerations,
integration constraints, and outline future directions, including multi-antenna
power delivery and networked sensor synchronization.

</details>


### [332] [Deep Tensor Learning for Reliable Channel Charting from Incomplete and Noisy Measurements](https://arxiv.org/abs/2509.13030)
*Ge Chen,Panqi Chen,Lei Cheng*

Main category: eess.SP

TL;DR: 现有信道图谱方法在处理真实世界中噪声大且不完整的无线信道数据时性能会下降，本文提出一种深度张量学习方法来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的无线信道数据通常不完整且噪声大，现有信道图谱方法在这种情况下性能会下降，需要新的方法来处理这些挑战。

Method: 提出一种深度张量学习方法，该方法利用无线信道的内在张量结构，从噪声大且不完整的测量数据中提取信息丰富且低维的特征（即信道图谱）。

Result: 实验结果表明，所提出的方法在具有挑战性的场景中具有可靠性和有效性。

Conclusion: 所提出的深度张量学习方法能够有效处理真实世界中噪声大且不完整的无线信道数据，生成可靠且有效的信道图谱。

Abstract: Channel charting has emerged as a powerful tool for user equipment
localization and wireless environment sensing. Its efficacy lies in mapping
high-dimensional channel data into low-dimensional features that preserve the
relative similarities of the original data. However, existing channel charting
methods are largely developed using simulated or indoor measurements, often
assuming clean and complete channel data across all frequency bands. In
contrast, real-world channels collected from base stations are typically
incomplete due to frequency hopping and are significantly noisy, particularly
at cell edges. These challenging conditions greatly degrade the performance of
current methods. To address this, we propose a deep tensor learning method that
leverages the inherent tensor structure of wireless channels to effectively
extract informative while low-dimensional features (i.e., channel charts) from
noisy and incomplete measurements. Experimental results demonstrate the
reliability and effectiveness of the proposed approach in these challenging
scenarios.

</details>


### [333] [Scatterer Localization Using Multi-Bounce Paths](https://arxiv.org/abs/2509.13071)
*Yuan Liu,Linlong Wu,Xuesong Cai,M. R. Bhavani Shankar*

Main category: eess.SP

TL;DR: 本论文提出了一种基于图论和SAGE算法的室内无线传感方法，以解决近场效应带来的多径传播挑战。


<details>
  <summary>Details</summary>
Motivation: 室内传感受多径效应、球面波前和空间非平稳性（SNS）的近场效应的影响，具有挑战性。本研究旨在解决这些问题。

Method: 利用图论（GT）对近场的<seg_13> 径传播进行建模，将室内反射/散射体视为传播图中的顶点，将多径路径视为连接顶点的边。同时，近场中的耦合多径参数（范围和角度）由顶点的坐标表示。然后，将空间交替广义期望最大化（SAGE）算法改编为所提出的基于图论的字典辅助的多径SAGE（GM-SAGE），并将搜索参数（范围和出发/到达角（AoD/AoA））转换为图中的散射体坐标。

Result: 通过在复杂的室内办公室中进行测量校准的光线追踪（RT）来验证所提出的GM-SAGE算法。结果表明，所提出的GM-SAGE能够处理多径信道。

Conclusion: 所提出的GM-SAGE算法能够有效处理室内传感中的多径效应。

Abstract: Indoor sensing is challenging because of the multi-bounce effect, spherical
wavefront, and spatial nonstationarity (SNS) of the near-field effect. This
paper addresses radio-based environment sensing considering these issues.
Specifically, graph theory (GT) is used to model the multi-bounce propagation
of the near field. In this manner, indoor reflectors/scatterers are modeled as
vertices in a propagation graph, the multi-bounce paths are modeled by the
edges linking the vertices. Besides, the coupled multipath parameters in the
near field, i.e., range and angles, are denoted directly by the coordinates of
vertices. Then, the space-alternating generalized expectation-maximization
(SAGE) algorithm is adapted to the proposed Graph theory-based dictionary-aided
Multi-bounce SAGE (GM-SAGE), where the searching parameters including range and
angle of departure/arrival (AoD/AoA) are transformed to the coordinates of
scatterers in the graph. The proposed algorithm is validated through
measurement-calibrated ray tracing (RT) in a complex indoor office. The results
demonstrate that the proposed GM-SAGE can deal with multi-bounce channels.

</details>


### [334] [Transmitter Subspace-Aware Target Detection in Two-Channel Passive Radars with Inter-Receiver Collaboration](https://arxiv.org/abs/2509.13287)
*Nandan Sriranga,Haodong Yang,Pramod K. Varshney*

Main category: eess.SP

TL;DR: 分布式双通道无源雷达在单延迟多普勒单元中进行目标检测。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决使用分布式双通道无源雷达在单延迟多普勒单元中进行目标检测的问题，并假设存在一个未知的发射源。

Method: 接收器将参考和测量信号转换到发射源子空间，进行互相关测量。为了节省带宽，接收器会协同交换和组合互相关输出，并将部分结果发送到融合中心。通过优化融合中心的测量值来设计协同权重，以提高检测性能。

Result: 通过上述方法，可以实现对目标进行有效检测。

Conclusion: 分布式双通道无源雷达系统能够有效地进行目标检测，并且可以通过优化协同权重进一步提高性能。

Abstract: We address target detection in a single Delay-Doppler cell using spatially
distributed two-channel passive radars. An unknown illuminator of opportunity
(IO) is assumed to emit a waveform lying in a known low-dimensional subspace
(e.g., OFDM). Each receiver transforms its reference and surveillance signals
onto the IO subspace after noise-whitening, to obtain cross-correlation (CC)
measurements. To save bandwidth, receivers collaboratively exchange and
linearly combine the CC output, and only a subset transmits them to a fusion
center (FC) over a multiple-access channel (MAC). Collaboration weights are
designed using the moments of the FC measurement to enhance detection
performance.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [335] [An Analysis of Resource Allocation and User Association Strategies in Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2509.12657)
*Siri Vennela Geddam,Sruthi Ilapuram,Kamesh Namuduri,K L V Sai Prakash Sakuru*

Main category: cs.ET

TL;DR: 该论文分析了下文提到的资源管理框架，并评估了交替优化、阻尼迭代水填充和遗传算法等关键方法在资源分配中的应用。


<details>
  <summary>Details</summary>
Motivation: 为智慧交通、医疗保健、智慧城市和灾难响应等应用提供无缝数据连接，通过协调低地球轨道（LEO）卫星、装有无人机（UAV）的基站和陆地基础设施。

Method: 对资源管理框架进行详细分析，对文献进行回顾，并评估交替优化（AO）、阻尼迭代水填充（DIWF）和遗传算法（GA）等关键资源分配方法。

Result: MATLAB 仿真结果通过 10,000 次试验对这些算法进行了基准测试，证明了稳健、公平且低延迟的资源分配。此外，还分析了紧急情况和网络过载期间用户与陆地和空中基站关联的策略。

Conclusion: 对 SAGIN 中的资源分配策略进行比较评估，并深入分析紧急情况下的用户关联策略。本研究为设计弹性高效的下一代网络提供了指导。

Abstract: Space-Air-Ground-Integrated Networks (SAGIN) enable seamless data
connectivity for applications such as smart transport, healthcare, smart
cities, and disaster response through the coordinated use of low-earth orbit
(LEO) satellites, base stations mounted with uncrewed aerial vehicles (UAV),
and terrestrial infrastructure. This paper provides a detailed analysis of
resource management frameworks, reviews the literature, and evaluates key
methods such as alternating optimization (AO), damped iterative water filling
(DIWF), and genetic algorithms (GA) for resource allocation. MATLAB simulation
results benchmark these algorithms across 10,000 trials, demonstrating robust,
fair, and low-latency resource allocation. In addition, this paper also
analyzes strategies for user association with terrestrial and aerial base
stations during emergencies and network overloads. The main contributions
include a comparative assessment of resource allocation strategies in SAGIN and
an in-depth analysis of user association policies for emergency scenarios. The
study provides guidance for designing resilient and efficient next-generation
networks. Potential future research directions include investigating satellite
handover and multi-domain orchestration for SAGIN deployments.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [336] [Entanglement Suppression in Quantum Field Theories: Holography, Chaos, and Mixed-State Dynamics](https://arxiv.org/abs/2509.12260)
*Davood Momeni*

Main category: quant-ph

TL;DR: entanglement entropy growth in CFTs can be suppressed by local operator quenches, with implications for black hole physics in AdS.


<details>
  <summary>Details</summary>
Motivation: The paper proposes to explore the phenomenon of 'entanglement suppression' in conformal field theories (CFTs) and its holographic dual in anti-de Sitter (AdS) space. This phenomenon, where entanglement entropy growth is suppressed due to the interaction of a local operator quench with a mixed-state excitation, opens up new research avenues.

Method: The proposed research involves five interconnected directions: 1. Generalizing entanglement suppression to higher dimensions. 2. Investigating the role of quantum chaos, using out-of-time-order correlators (OTOCs). 3. Examining the absence of suppression in integrable models. 4. Extending the study to entanglement negativity to probe mixed states. 5. Developing a geometric interpretation using scattering cross sections in AdS.

Result: The research is expected to provide new insights into the interplay between holography, non-equilibrium dynamics, and quantum information by exploring entanglement suppression in various contexts.

Conclusion: The proposed research directions are expected to yield significant advancements in understanding entanglement suppression and its broader implications in theoretical physics.

Abstract: Recent work has revealed that entanglement entropy growth in conformal field
theories (CFTs) can be suppressed when a local operator quench interacts with a
mixed-state excitation, providing a dual interpretation in terms of black hole
scattering in AdS. This phenomenon, termed \emph{entanglement suppression},
opens several promising directions for exploration. In this proposal, I outline
five distinct yet interconnected research trajectories: generalization to
higher dimensions, the role of quantum chaos via out-of-time-order correlators
(OTOCs), the absence of suppression in integrable models, the extension to
entanglement negativity as a probe of mixedness, and a geometric interpretation
based on scattering cross sections in AdS. Each direction offers new insights
into the interplay between holography, non-equilibrium dynamics, and quantum
information.

</details>


### [337] [The Emergence of Objective Classicality: A Computational First-Principles Study of Observer-Induced Decoherence in Unitary Quantum Mechanics](https://arxiv.org/abs/2509.12280)
*Eyad I. B Hamid*

Main category: quant-ph

TL;DR: 量子测量问题可以通过模拟一个完全统一的宇宙来解决，该宇宙包括量子系统、退相干环境和物理观察者，而无需崩溃公理。


<details>
  <summary>Details</summary>
Motivation: 量子测量问题，即波函数统一演化与波函数崩溃假说之间的未解决冲突，仍然是量子基础中最深刻的概念挑战。虽然环境诱导的退相herence提供了崩溃出现的引人注мок机制，但它并没有解决观察者自身量子态的基本问题。

Method: 通过引入一个新的计算框架来模拟一个完全统一的宇宙，该宇宙包括量子系统（Q）、退相干环境（E）和模型物理观察者（O），并严格禁止崩溃公理。

Result: 结果表明，客观的经典性可以从统一的动力学中出现，挑战了测量公理的必要性，并为解决量子测量问题提供了计算途径。

Conclusion: 这项工作通过引入一个新的计算框架来模拟一个完全统一的宇宙，该宇宙包括量子系统、退相干环境和模型物理观察者，而无需崩溃公理，从而证明客观经典性可以从统一动力学中出现，从而挑战了测量公理的必要性，并为解决量子测量问题提供了计算途径。

Abstract: The quantum measurement problem, the unresolved conflict between the unitary
evolution of the wave function and the postulate of wave function collapse,
remains the most profound conceptual challenge in quantum foundations. While
environment-induced decoherence provides a compelling practical mechanism for
the appearance of collapse, it does not resolve the fundamental issue of the
observer's own quantum state. This work moves beyond philosophical discourse by
introducing a novel computational framework to simulate a fully unitary
universe comprising a quantum system (Q), a decohering environment (E), and a
model physical observer (O). We strictly forbid the collapse axiom. Our
simulations investigate whether a definite, classical measurement outcome can
emerge objectively within O's state. The results demonstrate that objective
classicality can emerge from unitary dynamics, challenging the necessity of the
measurement postulate and providing a computational pathway toward resolving
the quantum measurement problem.

</details>


### [338] [Privacy in continuous-variable distributed quantum sensing](https://arxiv.org/abs/2509.12338)
*A. de Oliveira Junior,Anton L. Andersen,Benjamin Lundgren Larsen,Sean William Moore,Damian Markham,Masahiro Takeoka,Jonatan Bohr Brask,Ulrik L. Andersen*

Main category: quant-ph

TL;DR: Yes, a distributed quantum sensing network can estimate a global parameter while keeping local values private. This paper introduces a protocol for continuous-variable distributed quantum sensing using entangled Gaussian states. It achieves Heisenberg scaling for average phase estimation, making individual phases inaccessible. Complete privacy is possible in the large-squeezing limit, but trade-offs exist with estimation accuracy and privacy under displacements and losses. The protocol is benchmarked against other CV states.


<details>
  <summary>Details</summary>
Motivation: Determine if a distributed quantum sensor network can estimate a global parameter while preserving the privacy of locally encoded values.

Method: Introduce and analyze a protocol for distributed quantum sensing in the continuous-variable regime using a multipartite network with shared entangled Gaussian states. Investigate the impact of displacements and optical losses, and compare with other CV resource states.

Result: The average phase can be estimated with high precision, achieving Heisenberg scaling with the total photon number. Individual phases remain inaccessible. Complete privacy is achieved in the large-squeezing limit. Trade-offs between accuracy and privacy are observed under non-ideal conditions.

Conclusion: The proposed protocol enables precise global parameter estimation in a distributed quantum sensing network while protecting local information, with achievable privacy depending on squeezing levels and resilience to noise.

Abstract: Can a distributed network of quantum sensors estimate a global parameter
while protecting every locally encoded value? We answer this question
affirmatively by introducing and analysing a protocol for distributed quantum
sensing in the continuous-variable regime. We consider a multipartite network
in which each node encodes a local phase into a shared entangled Gaussian
state. We show that the average phase can be estimated with high precision,
exhibiting Heisenberg scaling in the total photon number, while individual
phases are inaccessible. Although complete privacy - where all other
combinations of phases remain entirely hidden - is unattainable for finite
squeezing in multi-party settings, it emerges in the large-squeezing limit. We
further investigate the impact of displacements and optical losses, revealing
trade-offs between estimation accuracy and privacy. Finally, we benchmark the
protocol against other continuous-variable resource states.

</details>


### [339] [Exact Coset Sampling for Quantum Lattice Algorithms](https://arxiv.org/abs/2509.12341)
*Yifan Zhang*

Main category: quant-ph

TL;DR: 我们为近期窗口化QFT格子算法的第9步提供了一个改进的、完全正确且假设较少的替代方案，解决了该步骤中存在的周期性/支持不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 近期窗口化QFT格子算法的第9步（使用复高斯窗口）存在周期性/支持不匹配的问题，需要改进。

Method: 提出了一种配对偏移差分构造，可以相干地抵消所有未知的偏移量，生成$\\mathbb{Z}_{P}$上的精确均匀CRT-coset状态，然后使用QFT强制执行预期的模线性关系。

Result: 改进后的第9步是可逆的，使用了poly(log M_2)门，并且保持了算法的渐近性。

Conclusion: 我们提出的方法成功解决了原始算法第9步存在的问题，提供了一个更优化的解决方案。

Abstract: We give a simple, fully correct, and assumption-light replacement for the
contested "domain-extension" in Step 9 of a recent windowed-QFT lattice
algorithm with complex-Gaussian windows~\citep{chen2024quantum}. The published
Step~9 suffers from a periodicity/support mismatch. We present a pair-shift
difference construction that coherently cancels all unknown offsets, produces
an exact uniform CRT-coset state over $\mathbb{Z}_{P}$, and then uses the QFT
to enforce the intended modular linear relation. The unitary is reversible,
uses $\mathrm{poly}(\log M_2)$ gates, and preserves the algorithm's
asymptotics. Project Page: https://github.com/yifanzhang-pro/quantum-lattice.

</details>


### [340] [Entanglement and optimization within autoregressive neural quantum states](https://arxiv.org/abs/2509.12365)
*Andrew Jreissaty,Hang Zhang,Jairo C. Quijano,Juan Carrasquilla,Roeland Wiersema*

Main category: quant-ph

TL;DR: 使用大尺度模拟揭示了自回归神经量子态（NQS）的平均纠缠特性，并提出了一种新的归一化函数来增强纠缠。


<details>
  <summary>Details</summary>
Motivation: 探索自回归NQS（如RNN和Transformer）的纠缠结构，因为这方面的研究比限制玻尔兹曼机（RBM）的平均纠缠特性要少。

Method: 对最多256个自旋的链进行随机自回归波函数系综的大尺度模拟，分析平均纠缠尺度、纠缠谱和相关函数，并比较了标准softmax归一化和平方模归一化。

Result: 发现了平均纠缠尺度、纠缠谱和相关函数中出现相变的迹象。标准softmax归一化会抑制纠缠和涨落，而平方模归一化可以恢复它们。

Conclusion: 标准softmax归一化会抑制自回归NQS的纠缠。平方模归一化可以恢复纠缠。研究结果可用于改进变分蒙特卡洛方法寻找强关联哈密顿量的基态的初始化策略。

Abstract: Neural quantum states (NQS) are powerful variational ans\"atze capable of
representing highly entangled quantum many-body wavefunctions. While the
average entanglement properties of ensembles of restricted Boltzmann machines
are well understood, the entanglement structure of autoregressive NQS such as
recurrent neural networks and transformers remains largely unexplored. We
perform large-scale simulations of ensembles of random autoregressive
wavefunctions for chains of up to $256$ spins and uncover signatures of
transitions in their average entanglement scaling, entanglement spectra, and
correlation functions. We show that the standard softmax normalization of the
wavefunction suppresses entanglement and fluctuations, and introduce a square
modulus normalization function that restores them. Finally, we connect the
insights gained from our entanglement and activation function analysis to
initialization strategies for finding the ground states of strongly correlated
Hamiltonians via variational Monte Carlo.

</details>


### [341] [Efficient Entanglement Purification Circuit Design for Dual-Species Atom Arrays](https://arxiv.org/abs/2509.12370)
*Bikun Li,Daniel Dilley,Alvin Gonzales,Thomas A. Hahn,Rotem Arnon,Hannes Bernien,Zain Saleem,Liang Jiang*

Main category: quant-ph

TL;DR: 我们提出了一种用于任意稳定器码的双向纠缠提纯协议（EPP），并通过分析和模拟证明了其性能的提升，特别是针对双原子体系设计了高效的电路实现方案，为实现容错量子技术奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 高保真纠缠态对于构建鲁棒的量子网络和计算至关重要，而纠缠提纯协议（EPP）是实现这一目标的关键技术，尤其是在存在噪声的量子系统中。

Method: 在基础递归协议的电路基础上，将双向EPP推广到任意稳定器码，并通过分析推导和包含电路级噪声的噪声电路模拟来验证其性能。针对双原子里德堡原子阵列，提出了一种利用物种特异性激光控制和物种间里德堡相互作用的高效EPP电路设计，并引入了一种低开销的操作集（双原子便捷操作集）以简化EPP电路的编译。

Result: 通过分析和噪声电路模拟，证明了所提出的EPP具有增强的提纯性能，能够提高保真度，并为可蒸馏输入态提供有限的蒸馏率。针对双原子里德堡原子阵列的电路设计实现了高效的EPP实现，无需额外的原子或复杂的原子重排。

Conclusion: 我们提出的框架为双原子平台上的近端实现提供了实际指导，推动了中性原子系统中可扩展的纠缠分发，并为容错量子技术铺平了道路。

Abstract: Entanglement purification protocols (EPPs) are essential for generating
high-fidelity entangled states in noisy quantum systems, enabling robust
quantum networking and computation. Building on the circuit of the foundational
recurrence protocol, we generalize two-way EPPs to arbitrary stabilizer codes.
Through analytical derivations and noisy circuit simulations incorporating
circuit-level noise, we demonstrate enhanced purification performance, with
fidelity improvements and finite distillation rates for distillable input
states. We propose efficient circuit designs for EPPs tailored to dual-species
Rydberg atom arrays, leveraging species-specific laser control and interspecies
Rydberg interactions. Introducing a low-overhead operation set, the
dual-species atom convenient operation set, we facilitate straightforward
compilation of EPP circuits without the need for ancillary atoms or complex
atom rearrangements. Our framework provides practical guidance for near-term
implementations on dual-species platforms, advancing towards scalable
entanglement distribution in neutral atom systems and paving the way for
fault-tolerant quantum technologies.

</details>


### [342] [Efficient Privacy-Preserving Training of Quantum Neural Networks by Using Mixed States to Represent Input Data Ensembles](https://arxiv.org/abs/2509.12465)
*Gaoyuan Wang,Jonathan Warrell,Mark Gerstein*

Main category: quant-ph

TL;DR: 本研究提出了一种利用混合量子态进行量子神经网络（QNN）训练的隐私保护方案，解决了量子联邦学习中的通信开销大、任务修改需重新训练等问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决在医疗等领域，特别是基因组学研究中，数据共享带来的隐私问题，以及现有量子联邦学习方案的局限性，如通信开销大和任务修改不灵活。

Method: 提出一种利用混合量子态编码数据集合的隐私保护QNN训练方案，允许在不暴露原始数据的情况下安全共享统计信息，并支持多方协作训练，实现单轮通信、高训练速度和任务通用性。

Result: 在三个不同数据集上验证了该方案的有效性，特别是在基因组学研究方面，并展示了其跨领域的适用性。理论分析证明了该方案的效用和隐私保护能力，能够防止个体数据恢复并抵抗成员推断攻击。

Conclusion: 本研究提出的隐私保护QNN训练方案能够安全有效地在多方之间进行协作训练，克服了现有量子联邦学习方法的缺点，并在多个数据集上得到了验证，具有广泛的应用前景。

Abstract: Quantum neural networks (QNNs) are gaining increasing interest due to their
potential to detect complex patterns in data by leveraging uniquely quantum
phenomena. This makes them particularly promising for biomedical applications.
In these applications and in other contexts, increasing statistical power often
requires aggregating data from multiple participants. However, sharing data,
especially sensitive information like personal genomic sequences, raises
significant privacy concerns. Quantum federated learning offers a way to
collaboratively train QNN models without exposing private data. However, it
faces major limitations, including high communication overhead and the need to
retrain models when the task is modified. To overcome these challenges, we
propose a privacy-preserving QNN training scheme that utilizes mixed quantum
states to encode ensembles of data. This approach allows for the secure sharing
of statistical information while safeguarding individual data points. QNNs can
be trained directly on these mixed states, eliminating the need to access raw
data. Building on this foundation, we introduce protocols supporting
multi-party collaborative QNN training applicable across diverse domains. Our
approach enables secure QNN training with only a single round of communication
per participant, provides high training speed and offers task generality, i.e.,
new analyses can be conducted without reacquiring information from
participants. We present the theoretical foundation of our scheme's utility and
privacy protections, which prevent the recovery of individual data points and
resist membership inference attacks as measured by differential privacy. We
then validate its effectiveness on three different datasets with a focus on
genomic studies with an indication of how it can used in other domains without
adaptation.

</details>


### [343] [Enlarging the GKP stabilizer group for enhanced noise protection](https://arxiv.org/abs/2509.12502)
*Jonathan Pelletier,Baptiste Royer*

Main category: quant-ph

TL;DR: 通过修改GKP码的稳定器群并提出优化的编译器，提高了GKP量子比特在面临噪声时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了在量子信息处理中保护量子信息免受退相干的影响，提出了使用包含GKP码的振荡器希尔伯特空间进行编码的方法。

Method: 研究了修改GKP码的稳定器群，并提出了一种能够寻找给定逻辑克利福德电路最优实现的算法，该算法可以减少计算过程中由于损耗错误造成的状态影响。

Result: 通过对GKP码的稳定器群进行修改，并提出优化的编译器，该编译器能够增加方形GKP量子比特在运行克利福德电路时的寿命。

Conclusion: 修改GKP码的稳定器群并采用优化的编译器，能够提高量子信息在面对噪声时的鲁棒性，为实现最优的量子信息处理提供了新的思路。

Abstract: Encoding a qubit in a larger Hilbert space of an oscillator is an efficient
way to protect its quantum information against decoherence. Promising examples
of such bosonic encodings are the Gottesman-Kitaev-Preskill (GKP) codes. In
this work, we investigate how redefining the stabilizer group of the GKP codes
to include all operations with trivial action on the code space can contribute
to the search for an optimal implementation of a logical circuit when it is
affected by noise. We find the generators of the Gaussian stabilizer group,
allowing us to search for different physical implementations of a Clifford
operation. We then propose an algorithm that finds the optimal implementation
of a given logical Clifford circuit on GKP codes, such that the state is less
affected by loss errors during the computation. Finally, we demonstrate
numerically, with logical randomized benchmarking, that such a compiler can
increase the lifetime of square-GKP qubits while running Clifford circuits,
compared to a random walk compiler.

</details>


### [344] [Leveraging Machine Learning Force Fields (MLFFs) to Simulate Large Atomistic Systems for Fidelity Improvement of Superconducting Qubits and Sensors](https://arxiv.org/abs/2509.12509)
*Søren Smidstrup,Shela Aboud,Ricardo Borges,Anders Blom,Pankaj Aggarwal,Robert Freeman,Jamil Kawa*

Main category: quant-ph

TL;DR: 量子化学模拟方法在量子计算和传感材料工程中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统密度泛函理论（DFT）在模拟超导、表面态和热力学性质方面存在局限性，无法满足量子计算应用的需求。

Method: 利用QuantumATK工具，结合基于LCAO基组的DFT、非平衡格林函数（NEGF）以及机器学习力场，模拟超导体-绝缘体界面特性、拓扑绝缘体表面态及大尺度系统的热力学性质。此外，通过在原子尺度紧束缚模型单粒子能级中加入电子-电子相互作用，构建描述双量子点体系的超导量子比特和量子传感器模型。

Result: QuantumATK能够计算超导体-绝缘体界面和拓扑绝缘体表面态的特性，并利用机器学习力场模拟大尺度系统的热力学性质和生成非晶几何结构。同时，成功构建了考虑电子-电子相互作用的双量子点模型，用于描述超导量子比特和量子传感器。

Conclusion: 所提出的结合DFT、NEGF、机器学习力场和多体物理的方法，能够克服传统DFT的局限性，为量子计算和传感材料的设计与开发提供更全面的模拟手段。

Abstract: Materials engineering using atomistic modeling is an essential tool for the
development of qubits and quantum sensors. Traditional density-functional
theory (DFT) does however not adequately capture the complete physics involved,
including key aspects and dynamics of superconductivity, surface states, etc.
There are also significant challenges regarding the system sizes that can be
simulated, not least for thermal properties which are key in quantum-computing
applications. The QuantumATK tool combines DFT, based on LCAO basis sets, with
non-equilibrium Green's functions, to compute the characteristics of interfaces
between superconductors and insulators, as well as the surface states of
topological insulators. Additionally, the software leverages machine-learned
force-fields to simulate thermal properties and to generate realistic amorphous
geometries in large-scale systems. Finally, the description of superconducting
qubits and sensors as two-level systems modeled with a double-well potential
requires many-body physics, and this paper demonstrates how electron-electron
interaction can be added to the single-particle energy levels from an atomistic
tight-binding model to describe a realistic double-quantum dot system.

</details>


### [345] [Real-time vacuum-state quantum random number generator on a chip](https://arxiv.org/abs/2509.13105)
*Guan-Ru Qiao,Bing Bai,Zi-Xuan Weng,Han-Shen Chen,Wei Zheng,Zhi-Yuan Zheng,You-Qi Nie,Jun Zhang,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 制造了一个基于真空涨落的量子随机数生成器芯片，尺寸为16.6毫米x7.8毫米，通过混合光子集成和系统级封装技术实现，输出速率为5.2 Mbps。


<details>
  <summary>Details</summary>
Motivation: 微型化量子随机数生成器对于通信和密码学应用至关重要。

Method: 利用真空涨落作为量子熵源，通过混合光子集成（二氧化硅波导）产生原始量子随机数。将光子和电子元件封装在陶瓷封装中，并使用微控制器单元处理数据，通过SPI输出。

Result: 制造了一个16.6毫米x7.8毫米的量子随机数生成器芯片，在-40°C至85°C的工业温度范围内，实现了5.2 Mbps的恒定实时输出速率。

Conclusion: 所提出的量子随机数生成器芯片尺寸小，性能稳定，适用于实际应用。

Abstract: Quantum random number generators (QRNGs) produce true random numbers, which
are guaranteed by the fundamental principles of quantum physics.
Miniaturization of QRNGs is crucial for a wide range of communication and
cryptography applications. Here, we first report a fully functional QRNG chip
based on vacuum-state fluctuations, with dimensions of 16.6 mm x 7.8 mm. The
quantum entropy source, which is achieved via hybrid photonic integration with
a SiO2 waveguide, generates raw quantum random numbers. The hybrid photonic and
electrical components are assembled into a compact ceramic package using
system-in-package technology. A microcontroller unit acquires the raw data and
outputs the processed quantum random numbers via a serial peripheral interface.
According to the characterization results, the QRNG chip achieves a constant
real-time output rate of 5.2 Mbps across the industrial temperature range of
-40{\deg}C to 85{\deg}C, making it suitable for practical applications.

</details>


### [346] [Pulsed Generation of Continuous-Variable Cluster States in a Phononic Quantum Network](https://arxiv.org/abs/2509.12529)
*A. Govindarajan,M. Mazzei,H. Wang,L. Tian*

Main category: quant-ph

TL;DR: 通过使用声子波导、机械谐振器和光学腔组成的声学量子网络，提出了一种生成连续变量（CV）簇态的脉冲协议，该协议具有模块化设计，可扩展性强，并且可以通过局部测量纠缠远程机械模式。


<details>
  <summary>Details</summary>
Motivation: 连续变量（CV）簇态由于其最大连通性和抗退相干性，在量子信息处理中具有重要应用价值。

Method: 提出了一种利用声子波导、机械谐振器和光学腔组成的声学量子网络的脉冲协议来生成CV簇态。该协议采用模块化设计，其中机械模式对作为构建模块，仅在机械模式和腔模式之间进行局部的、可调的相互作用。该方案可扩展，需要$N$个机械谐振器只需要$4N$个驱动音。

Result: 通过评估CV模式的零化因子来表征生成的簇态。研究了耗散的影响，表明强压缩和大的声子占有数在有限的机械和光学损耗下会降低生成的簇态质量。作为直接应用，演示了可以通过局部测量实现远程机械模式的纠缠。

Conclusion: 所提出的脉冲协议能够有效地生成CV簇态，并且具有良好的可扩展性。该方案为在声学量子网络中实现量子信息处理提供了新的途径。

Abstract: Cluster states are multipartite entangled states that are maximally connected
and resilient to decoherence, making them valuable resources for quantum
information processing. Continuous-variable (CV) cluster states have been
extensively investigated for such applications. Here we present a pulsed
protocol for generating CV cluster states in a phononic quantum network
composed of phonon waveguides, mechanical resonators, and optical cavities. A
key feature of this architecture is the modular design, where pairs of
mechanical modes act as building blocks with only local, tunable interactions
between mechanical and cavity modes. The scheme is scalable, requiring just
$4N$ driving tones for $N$ mechanical resonators. We characterize the resulting
cluster states by evaluating the nullifiers of the CV modes. We also study the
effects of dissipation, showing that strong squeezing with large phonon
occupations can degrade the generated cluster states under finite mechanical
and optical losses. As a direct application, we demonstrate that distant
mechanical modes can be entangled via local measurements.

</details>


### [347] [Toward Heisenberg Scaling in Non-Hermitian Metrology at the Quantum Regime](https://arxiv.org/abs/2509.12579)
*Xinglei Yu,Xinzhi Zhao,Liangsheng Li,Xiao-Min Hu,Xiangmei Duan,Haidong Yuan,Chengjie Zhang*

Main category: quant-ph

TL;DR: 我们提出了一个通用的量子费舍尔信息量表达式，并证明了非厄米系统可以达到海森堡极限，通过实验验证了理论分析。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米量子计量学在量子精密测量领域的应用潜力，特别是实现海森堡极限。

Method: 推导适用于一般非厄米哈密顿量的量子费舍尔信息量表达式，并构造了由具有和不具有特定对称性的两个非厄米哈密顿量控制的非酉演化。

Result: 证明了非厄米系统可以实现 $1/t$ 的海森堡极限，并通过实验验证了理论分析，达到了量子克拉美-拉奥下界。

Conclusion: 非厄米量子计量学在实现高精度测量方面具有巨大潜力，并且可以通过设计合适的非厄米系统来达到海森堡极限。

Abstract: Non-Hermitian quantum metrology, an emerging field at the intersection of
quantum estimation and non-Hermitian physics, holds promise for revolutionizing
precision measurement. Here, we present a comprehensive investigation of
non-Hermitian quantum parameter estimation in the quantum regime, with a
special focus on achieving Heisenberg scaling. We introduce a concise
expression for the quantum Fisher information (QFI) that applies to general
non-Hermitian Hamiltonians, enabling the analysis of estimation precision in
these systems. Our findings unveil the remarkable potential of non-Hermitian
systems to attain the Heisenberg scaling of $1/t$, where $t$ represents time.
Moreover, we derive optimal measurement conditions based on the proposed QFI
expression, demonstrating the attainment of the quantum Cram\'{e}r-Rao bound.
By constructing non-unitary evolutions governed by two non-Hermitian
Hamiltonians, one with parity-time symmetry and the other without specific
symmetries, we experimentally validate our theoretical analysis. The
experimental results affirm the realization of Heisenberg scaling in estimation
precision, marking a substantial milestone in non-Hermitian quantum metrology.

</details>


### [348] [Erasing, Converting, and Communicating: The Power of Resource-Nongenerating Operations](https://arxiv.org/abs/2509.12604)
*Xian Shi*

Main category: quant-ph

TL;DR: 该研究探讨了静态和动态量子资源理论中的非生成操作（RNOs），并提出了量化量子通道的公理化方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于深入理解资源非生成操作（RNOs）在静态和动态量子资源理论中的作用，并为量子信息处理任务提供新的见解。

Method: 研究方法包括：1. 导出状态在RNOs下的状态转换的充分条件。2. 构建一个动态资源理论，其中RNOs被视为自由操作。3. 提出一个量化量子通道的公理化方法。4. 分析动态资源的擦除过程。5. 应用所提出的理论来界定通用凸资源理论中状态的渐近成本，并获得辅助动态相干性的通信任务的容量界限。

Result: 研究结果包括：1. 提出了状态在RNOs下的转换的充分条件。2. 建立了包含RNOs的动态资源理论。3. 提出了量化量子通道的公理化方法。4. 分析了动态资源的擦除。5. 确定了状态的渐近成本界限和通信任务的容量界限。

Conclusion: 本研究阐明了RNOs在量子信息处理任务中的关键作用，并为理解和量化量子资源提供了新的理论框架。

Abstract: We investigate resource nongenerating operations (RNOs) in both static and
dynamical quantum resource theories. For the static scenarios, we derive a
sufficient condition for state transformations under RNOs. Then we construct a
dynamical resource theory where RNOs constitute the set of free operations, and
we propose an axiomatic approach to quantify quantum channels. We further
analyze the erasure of the dynamical resources. As applications, we establish
bounds on the asymptotic cost of states under RNOs in a generic convex resource
theory and obtain capacity bounds for communication tasks assisted by dynamical
coherence. Our results clarify the key roles of RNOs in quantum information
processing tasks.

</details>


### [349] [Stabilizer Perturbation Theory: A Systematic Construction via Schrieffer-Wolff Transformation](https://arxiv.org/abs/2509.12621)
*Xuzhe Ying,Kangle Li,Hoi Chun Po*

Main category: quant-ph

TL;DR: 通过使用二进制编码的泡利代数，为量子比特系统开发了系统稳定器微扰理论，并在各种模型上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 为了在量子比特系统上分析更一般的量子多体问题，需要一种新的微扰理论。

Method: 使用局部Schrieffer-Wolff变换，通过二进制编码泡利代数有效地执行稳定器微扰理论。

Result: 该方法已成功应用于一维横向场伊辛链、二维$\mathbb{Z}_2$ تورic code（方形和kagome晶格）的基准测试和分析，以探测任意子激发子的限制趋势。

Conclusion: 所开发的系统稳定器微扰理论为研究量子比特系统上的量子多体问题提供了一种有效的方法，并已在几个模型上得到验证。

Abstract: Perturbation theories provide valuable insights on quantum many-body systems.
Systems of interacting particles, like electrons, are often treated
perturbatively around exactly solvable Gaussian points. Systems of interacting
qubits have gained increasing prominence as another class of models for quantum
systems thanks to the recent advances in experimentally realizing mesoscopic
quantum devices. Stabilizer states, innately defined on systems of qudits, have
correspondingly emerged as another class of classically simulatable starting
point for the study of quantum error-correcting codes and topological phases of
matter in such devices. As a step towards analyzing more general quantum
many-body problems on these platforms, we develop a systematic stabilizer
perturbation theory in qubit systems. Our approach relies on the local
Schrieffer-Wolff transformation, which we show can be efficiently performed
through the binary encoding the Pauli algebra. As demonstrations, we first
benchmark the stabilizer perturbation theory on the transverse field Ising
chain in one dimension. The method is then further applied to $\mathbb{Z}_2$
toric code on square lattice and kagome lattice to probe the tendency toward
confinement for anyonic excitations.

</details>


### [350] [Derivation of the Landau-Zener formula via functional equations](https://arxiv.org/abs/2504.02576)
*Chen Sun*

Main category: quant-ph

TL;DR: 提出了一种不依赖特殊函数、拉普拉斯变换或复 contour 积分的 Landau-Zener 公式推导方法，利用函数方程和可积性证明了跃迁概率满足一个函数方程，并由此推导出指数形式。


<details>
  <summary>Details</summary>
Motivation: 现有的 Landau-Zener 公式推导方法通常需要复杂的数学工具，如特殊函数、拉普拉斯变换或复 contour 积分。本文旨在提供一种更简洁、更易于理解的推导方法。

Method: 利用函数方程和可积性来推导 Landau-Zener 跃迁概率。首先证明该概率满足一个函数方程，然后通过求解该方程得到其指数形式。最后通过最低阶微扰计算确定指数内的系数。

Result: 成功推导出了 Landau-Zener 跃迁概率的指数形式，并且该推导不涉及复杂的数学工具。研究结果揭示了 Landau-Zener 跃迁概率指数形式的来源，并表明该公式可以看作是可积性的结果。

Conclusion:  Landau-Zener 公式可以通过函数方程和可积性来推导，这提供了一种新的理解该公式的方式，并揭示了其指数形式的数学起源。尽管两能级 Landau-Zener 哈密顿量本身不满足可积性条件，但其跃迁概率却可以看作是可积性的结果。

Abstract: The Landau-Zener formula describes the diabatic transition probability of a
two-level system under linear driving. Its rigorous derivation typically relies
on sophisticated mathematical tools, such as special functions, Laplace
transforms, or contour integrals. In this work, we present a derivation of the
Landau-Zener transition probability using a fundamentally different approach
via functional equations. By leveraging integrability, we prove that this
transition probability satisfies a functional equation, whose solutions
establish the exponential form of the formula. The coefficient in the exponent
is then determined through a lowest-order perturbation calculation. This
derivation is rigorous and does not involve any sophisticated mathematics. Our
work provides insights into the origin of the exponential form of the
Landau-Zener transition probability, and shows that the Landau-Zener formula
can be viewed as a consequence of integrability, though the two-level
Landau-Zener Hamiltonian itself does not satisfy the integrability conditions.

</details>


### [351] [Cavity-Modified Nonequilibrium Fermi's Golden Rule Rate Coefficients from Cavity-Free Inputs](https://arxiv.org/abs/2509.12634)
*Pouya Khazaei,Eitan Geva*

Main category: quant-ph

TL;DR: NE-FGR rates are modified by microcavities even with weak coupling, allowing for estimations without explicit cavity simulations. An approximate limit, cavity-modified Instantaneous Marcus Theory, is also introduced.


<details>
  <summary>Details</summary>
Motivation: To show that NE-FGR rates can be significantly modified by placing a molecular system inside an electromagnetic microcavity, even with weak coupling, and to develop a framework for estimating these modified rates.

Method: Developed a theoretical framework to estimate cavity-modified NE-FGR rates using the same inputs as cavity-free calculations. Introduced an approximate limit: cavity-modified Instantaneous Marcus Theory.

Result: Demonstrated the utility of the framework with applications to photo-induced charge transfer in a carotenoid-porphyrin-C60 molecular triad and the Garg-Onuchic-Ambegaokar model.

Conclusion: NE-FGR rates are significantly modified by microcavities even with weak coupling, and these modified rates can be estimated without explicit cavity simulations. A new approximate theory, cavity-modified Instantaneous Marcus Theory, is also presented.

Abstract: The Nonequilibrium Fermi's Golden Rule (NE-FGR) provides a convenient
theoretical framework for calculating the charge transfer rate between a
photoexcited bright donor electronic state and a dark acceptor electronic
state, when the nuclear degrees of freedom start out in a nonequilibrium
initial state. In this paper, we show that NE-FGR rates can be significantly
modified by placing the molecular system inside an electromagnetic microcavity,
even when the coupling with the cavity modes is weak. In this case,
cavity-modified NE-FGR rates can also be estimated from the same inputs needed
for calculating the cavity-free NE-FGR rates, thereby bypassing the need for an
explicit simulation of the molecular system inside the cavity. We also
introduce an approximate limit of the cavity-modified NE-FGR, which we denote
cavity-modified Instantaneous Marcus Theory, since it is based on the same
assumptions underlying Marcus theory. The utility of the proposed framework for
calculating cavity-modified NE-FGR rates is demonstrated by applications to
photo-induced charge transfer in the carotenoid-porphyrin-C$_{60}$ molecular
triad dissolved in liquid tetrahydrofuran and the Garg-Onuchic-Ambegaokar model
for charge transfer in the condensed phase.

</details>


### [352] [EmuPlat: A Framework-Agnostic Platform for Quantum Hardware Emulation with Validated Transpiler-to-Pulse Pipeline](https://arxiv.org/abs/2509.12639)
*Jun Ye,Jun Yong Khoo*

Main category: quant-ph

TL;DR: EmuPlat是一个框架无关的量子硬件仿真平台，解决了高层量子编程框架与硬件特定脉冲控制系统之间的互操作性问题。它提供了一个统一的基础设施，能够无缝集成CUDA-Q、Qiskit和Qibolab等多种量子计算生态系统。


<details>
  <summary>Details</summary>
Motivation: 解决高层量子编程框架与硬件特定脉冲控制系统之间的互操作性问题，提供统一的基础设施以集成多种量子计算生态系统。

Method: EmuPlat实现了一个完整的编译器流水线，包括递归门分解、虚拟Z优化、连接感知路由和确定性脉冲编译。其模块化架构基于整洁架构原则和适配器模式，支持集成多种量子动力学模拟引擎。

Result: 在超导Transmon架构上进行了基准测试：贝尔态制备保真度达到99.958%，4比特量子傅里叶变换实现可扩展的电路执行。

Conclusion: EmuPlat是一个现生产就绪的平台，通过了端到端测试，是加速混合量子经典算法开发和软硬件协同设计的关键基础设施。

Abstract: We present EmuPlat, a framework-agnostic quantum hardware emulation platform
that addresses the interoperability gap between high-level quantum programming
frameworks and hardware-specific pulse control systems. Unlike existing
solutions that operate within isolated software stacks, EmuPlat provides a
unified infrastructure enabling seamless integration across diverse quantum
computing ecosystems, including CUDA-Q, Qiskit, and Qibolab. The platform
implements a complete transpiler-compiler pipeline that systematically
transforms abstract quantum circuits through four validated stages: (1)
recursive gate decomposition to a minimal native set
$\mathcal{G}_{\text{native}} = \{I, Z, RZ(\theta), \text{GPI2}(\phi), CZ, M\}$,
(2) virtual Z optimization implementing phase tracking without physical pulses,
(3) connectivity-aware routing with automated SWAP insertion, and (4)
deterministic pulse compilation respecting hardware timing constraints. Our
modular architecture, based on clean architecture principles with a novel
adapter pattern, supports extensible integration of multiple quantum dynamics
simulation engines while maintaining consistent interfaces. We demonstrate
EmuPlat's capabilities through comprehensive benchmarks on superconducting
transmon architectures: Bell state preparation achieves 99.958\% fidelity with
hardware-calibrated noise models, while 4-qubit Quantum Fourier Transform
implementations successfully demonstrate scalable circuit execution. The
platform's production-ready implementation, validated through end-to-end
testing with TransformationValidator, establishes EmuPlat as essential
infrastructure for accelerating hybrid quantum-classical algorithm development
and hardware-software co-design.

</details>


### [353] [Non-Markovian amplitude damping in a central spin model with random couplings](https://arxiv.org/abs/2509.12670)
*Mehboob Rashid,Rayees A Mala,Saima Bashir,Muzaffar Qadir Lone*

Main category: quant-ph

TL;DR: 随机系统-环境耦合影响开放量子系统的非马尔可夫行为，并可能导致量子Fisher信息流无法检测到记忆效应。


<details>
  <summary>Details</summary>
Motivation: 研究随机系统-环境耦合在开放量子系统中非马尔可夫行为中的作用。

Method: 使用时间无关主方程框架和中心自旋模型，并采用量子Fisher信息流和Breuer-Laine-Piilo（BLP）度量来分析。

Result: 随机系统-环境耦合可以塑造非马尔可夫行为，量子Fisher信息流在某些情况下可能无法检测到记忆效应，而BLP度量仍然可以检测到信息回流。外部调制可以产生更丰富的行为，包括不规则和频率依赖的非马尔可夫性复苏。

Conclusion: 理解记忆效应的物理起源，强调单一证据方法的局限性，并提出随机性和调制可用于工程化鲁棒的、抗噪声的量子技术。

Abstract: Non-Markovian dynamics is central to quantum information processing, as
memory effects strongly influence coherence preservation, metrology, and
communication. In this work, we investigate the role of stochastic system--bath
couplings in shaping non-Markovian behavior of open quantum systems, using the
central spin model within a time-convolutionless master equation framework. We
show that the character of the reduced dynamics depends jointly on the
intrinsic memory of the environment and on the structure of the
system--environment interaction. In certain regimes, the dynamics simplify to
pure dephasing, while in general both amplitude damping and dephasing
contribute to the evolution. By employing two complementary measures: the
Quantum Fisher Information (QFI) flow and the Breuer--Laine--Piilo (BLP)
measure, we demonstrate that QFI flow may fail to witness memory effects in
weak-coupling and near-resonant regimes, whereas the BLP measure still detects
information backflow. Furthermore, external modulation of the interaction
kernel produces qualitatively richer behavior, including irregular and
frequency-dependent revivals of non-Markovianity. These results clarify the
physical origin of memory effects, highlight the limitations of single-witness
approaches, and suggest that stochasticity and modulation can be harnessed to
engineer robust, noise-resilient quantum technologies.

</details>


### [354] [Sample-optimal single-copy quantum state tomography via shallow depth measurements](https://arxiv.org/abs/2509.12703)
*Gyungmin Cho,Dohun Kim*

Main category: quant-ph

TL;DR: 该研究提出了一种用于量子态层析（QST）的新方法，使用深度为 O(log n) 的电路，在 n 量子比特系统上实现了近乎最优的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 在量子信息领域，量子态层析（QST）是一个基本问题。虽然多副本测量在理论上能达到最优样本复杂度，但在实际的近期量子设备上难以实现。因此，使用单副本测量和浅层电路进行QST在实践中更为可行。然而，先前提出的针对单量子比特测量的近乎最优的QST算法，其样本复杂度未能达到单副本测量的已知下界。

Method: 本研究采用深度为 O(log n) 的电路，在 n 量子比特系统上，针对秩为 r、d 维的量子态 $ho$，实现了样本复杂度为 O( (dr^2 ln d) / ε^2 ) 的 QST，误差为 ε（以迹距离衡量）。这与已知的下界 Ω( (dr^2) / ε^2 ) 相比，在 ln d 因子上接近最优。对于 r = d 的通用情况，研究进一步消除了 ln d 因子，得到了最优样本复杂度 O( d^3 / ε^2 )。

Result: 研究在两个方面取得了进展：1. 对于秩为 r、d 维的量子态，实现了接近最优的样本复杂度 O( (dr^2 ln d) / ε^2 )。2. 对于通用情况 r = d，实现了最优样本复杂度 O( d^3 / ε^2 )。

Conclusion: 本研究通过使用深度为 O(log n) 的电路，在量子态层析方面取得了显著进展，特别是在样本复杂度方面，为实际量子设备上的QST提供了更有效的解决方案。

Abstract: Quantum state tomography (QST) is one of the fundamental problems in quantum
information. Among various metrics, sample complexity is widely used to
evaluate QST algorithms. While multi-copy measurements are known to achieve
optimal sample complexity, they are challenging to implement on near-term
quantum devices. In practice, single-copy measurements with shallow-depth
circuits are more feasible. Although a near-optimal QST algorithm under
single-qubit measurements has recently been proposed, its sample complexity
does not match the known lower bound for single-copy measurements. Here, we
make two contributions by employing circuits with depth $\mathcal{O}(\log n)$
on an $n$-qubit system. First, QST for rank-$r$ $d$-dimensional state $\rho$
can be achieved with sample complexity $\mathcal{O}\!\left(\tfrac{dr^2 \ln
d}{\epsilon^2}\right)$ to error $\epsilon$ in trace distance, which is
near-optimal up to a $\ln d$ factor compared to the known lower bound
$\Omega\left(\frac{dr^2}{\epsilon^2}\right)$. Second, for the general case of
$r = d$, we can remove the $\ln d$ factor, yielding an optimal sample
complexity of $\mathcal{O}\!\left(\frac{d^3}{\epsilon^2}\right)$.

</details>


### [355] [Ancilla-train quantum algorithm for simulating non-Markovian open quantum systems](https://arxiv.org/abs/2509.12717)
*Hans Michael Christensen,Johannes Agerskov,Frederik Nathan*

Main category: quant-ph

TL;DR: 我们提出了一种模拟与高斯环境耦合的开放量子系统的量子算法，该算法适用于任何配置和耦合强度。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种能够精确模拟开放量子系统与高斯环境相互作用的量子算法，尤其适用于强耦合、非马尔可夫、多重环境或时变哈密顿量等复杂情况。

Method: 该算法基于一个关键的洞见：任何高斯环境都可以表示为一系列辅助量子比特，这些量子比特通过与系统进行时间局域耦合来依次与系统相互作用。这种耦合作用由环境关联函数的卷积平方根给出。

Result: 该算法能够以任意精度重现复杂开放量子系统的真实动力学，并且对于广泛的问题，其资源成本仅比Trotter化时间演化略有增加，成本与目标精度的倒数成多项式关系。

Conclusion: 我们的研究结果为量子计算机在模拟非平衡和开放量子系统方面开辟了新的应用途径。

Abstract: We present a quantum algorithm for simulating open quantum systems coupled to
Gaussian environments valid for any configuration and coupling strength. The
algorithm is for instance applicable to problems with strongly coupled, or
non-Markovian, environments; problems with multiple environments out of mutual
equilibrium; and problems with time-dependent Hamiltonians. We show that the
algorithm can reproduce the true dynamics of such problems at arbitrary
accuracy and, for a broad range of problems, only adds a minor resource cost
relative to Trotterized time evolution; the cost is polynomial in the inverse
target accuracy. The algorithm is based on the insight that any Gaussian
environment can be represented as a train of ancillary qubits that sequentially
interact with the system through a time-local coupling, given by the
convolution square root of the bath correlation function; this is a secondary
result of our work. Our results open up new applications of quantum computers
for efficient simulation of non-equilibrium and open quantum systems.

</details>


### [356] [Low-complexity CV-QKD system with optical pilot-tone local oscillator synchronization](https://arxiv.org/abs/2509.12735)
*Samael Sarmiento,Jeison Tabares,Sebastian Etcheverry*

Main category: quant-ph

TL;DR: 本研究使用基于高斯调制的相干态的连续可变量子密钥分发（CV-QKD）系统，通过仿真分析了用于本地振荡器同步的光学导频音生成技术。


<details>
  <summary>Details</summary>
Motivation: 为了提高连续可变量子密钥分发（CV-QKD）系统在本地振荡器同步方面的鲁棒性并降低实现复杂性，需要对光学导频音生成技术进行研究。

Method: 通过仿真比较了两种导频音生成方式（电子式和光学式）的系统性能，并分析了导频音功率、激光线宽、数模转换器分辨率和链路距离等关键参数的影响。

Result: 仿真结果揭示了不同导频音生成策略对系统性能的影响。

Conclusion: 研究为CV-QKD系统提供了关于如何选择导频音生成策略以提高鲁棒性和降低实现复杂性的见解。

Abstract: This study presents a comprehensive simulation-based analysis of optical
pilot tone generation for local oscillator synchronization in
continuous-variable quantum key distribution (CV-QKD) systems using
Gaussian-modulated (GM) coherent states. We compare system performance when the
pilot tone is generated either electrically or optically, examining the effects
of key parameters such as pilot tone power, laser linewidth, digital-to-analog
converter resolution, and link distance. The results provide insights into
pilot tone generation strategies that enhance robustness while reducing the
implementation complexity of GM CV-QKD systems

</details>


### [357] [RandomMeas.jl: A Julia Package for Randomized Measurements in Quantum Devices](https://arxiv.org/abs/2509.12749)
*Andreas Elben,Benoît Vermersch*

Main category: quant-ph

TL;DR: RandomMeas.jl是一个用Julia编写的开源软件包，用于实现和分析量子计算中的随机测量协议。


<details>
  <summary>Details</summary>
Motivation: 随机测量提供了一种强大的框架，用于通过简单的实验程序结合经典后处理（最著名的是通过经典影集形式主义）来提取量子态和过程的属性，例如期望值、纠缠和保真度。

Method: RandomMeas.jl涵盖了完整的随机测量工作流程，从在量子计算机上使用的测量设置的生成，到张量网络的（可选）经典模拟，再到基于经典影集的物理属性的估计器。

Result: 该包包括先进的功能，如鲁棒和浅影集技术、批估计器和内置统计不确定性估计。

Conclusion: 其统一的、可组合的设计能够将随机测量协议扩展到理论和实验环境中的应用和进一步开发。

Abstract: We introduce RandomMeas.jl, a modular and high-performance open-source
software package written in Julia for implementing and analyzing randomized
measurement protocols in quantum computing. Randomized measurements provide a
powerful framework for extracting properties of quantum states and processes
such as expectation values, entanglement, and fidelities using simple
experimental procedures combined with classical post-processing, most
prominently via the classical shadow formalism. RandomMeas.jl covers the full
randomized measurement workflow, from the generation of measurement settings
for use on a quantum computer, the optional classical simulation of randomized
measurements with tensor networks, to a suite of estimators for physical
properties based on classical shadows. The package includes advanced features
such as robust and shallow shadow techniques, batch estimators, and built-in
statistical uncertainty estimation. Its unified, composable design enables the
scalable application and further development of randomized measurements
protocols across theoretical and experimental contexts.

</details>


### [358] [Spontaneous formation of subsystem and bath under accordion-type driving](https://arxiv.org/abs/2509.12761)
*Suyang Lin,Ming Gong,Congjun Wu*

Main category: quant-ph

TL;DR: Floquet系统在没有固定空间周期性的情况下，其哈密顿量可以被有效地构造，从而为研究量子动力学开辟了新的途径。研究发现，单粒子希尔伯特空间会自发形成一个两能级子系统和一个作为“浴”的其余部分，并且该动力学过程表现出稳定的时间演化。


<details>
  <summary>Details</summary>
Motivation: 探索具有时间依赖性空间周期性的Floquet系统中的新物理现象，特别是关于热化和新动力学结构。

Method: 通过对两能级子系统进行微扰分析和数值求解来研究系统的动力学过程。

Result: 发现了单粒子希尔伯特空间会自发形成一个两能级子系统和一个作为“浴”的其余部分，并且动力学过程表现出稳定的时间演化。

Conclusion: 该研究丰富了对不具有确定空间周期性的Floquet热化的理解，并为探索量子疤痕态等许多体物理现象提供了新的思路。

Abstract: Floquet modulations often yield effective Hamiltonians not easily accessible
in traditional time-dependent systems, which brings opportunities for exploring
novel physics of quantum dynamics. We investigate a Floquet system exhibiting
translational symmetry at any fixed time but the spatial periodicity is
time-dependent. Such a system is a natural platform for studying thermalization
and novel dynamical structures. We find that the single-particle Hilbert space
spontaneously develops a structure of a two-level subsystem and the rest part
forms a bath. The dynamic process is analyzed perturbatively within the
two-level subsystem as well as numerical solutions, exhibiting stable
time-evolutions. These results enrich our understanding of Floquet
thermalization without definite spatial periodicity, which brings hints for
exploring many-body physics such as scar states.

</details>


### [359] [Designing Shadow Tomography Protocols by Natural Language Processing](https://arxiv.org/abs/2509.12782)
*Yadong Wu,Pengfei Zhang,Ce Wang,Juan Yao,Yi-Zhuang You*

Main category: quant-ph

TL;DR: 通过利用类自然语言处理技术，我们开发了一种由人工智能驱动的协议，用于设计高效的量子电路，该协议使用 iSWAP 门作为关键元素，并通过强化学习进行训练，以在量子计算任务中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 设计用于特定计算任务的高效量子电路是一个重大挑战。

Method: 采用受自然语言处理启发的协议，首先选择一个包含 iSWAP 门的紧凑门集，然后使用强化学习训练循环神经网络来生成量子电路。

Result: 所提出的方法在新颖的量子计算任务上实现了高效的电路设计，并表现出良好的泛化能力。

Conclusion: 人工智能驱动的协议，特别是使用 iSWAP 门和强化学习，为设计高效量子电路提供了一个有前景的途径，并且在量子计算中有广泛的应用潜力。

Abstract: Quantum circuits form a foundational framework in quantum science, enabling
the description, analysis, and implementation of quantum computations. However,
designing efficient circuits, typically constructed from single- and two-qubit
gates, remains a major challenge for specific computational tasks. In this
work, we introduce a novel artificial intelligence-driven protocol for quantum
circuit design, benchmarked using shadow tomography for efficient quantum state
readout. Inspired by techniques from natural language processing (NLP), our
approach first selects a compact gate dictionary by optimizing the entangling
power of two-qubit gates. We identify the iSWAP gate as a key element that
significantly enhances sample efficiency, resulting in a minimal gate set of
{I, SWAP, iSWAP}. Building on this, we implement a recurrent neural network
trained via reinforcement learning to generate high-performing quantum
circuits. The trained model demonstrates strong generalization ability,
discovering efficient circuit architectures with low sample complexity beyond
the training set. Our NLP-inspired framework offers broad potential for quantum
computation, including extracting properties of logical qubits in quantum error
correction.

</details>


### [360] [Generalised two-dimensional nonlinear oscillator with a position-dependent effective mass and the thermodynamic properties](https://arxiv.org/abs/2509.12796)
*S. E. Bokpe,F. A. Dossa,G. Y. H. Avossevou*

Main category: quant-ph

TL;DR: 研究二维非相对论量子力学中的变质量非线性振荡器，利用Nikiforov-Uvarov方法获得能量谱和波函数解析解，并推导出热力学量。结果表明，与一维情况不同，二维系统的比热强烈依赖于非线性参数k，并且在高温度下，当k<0时，比热不依赖于温度，符合Dulong-Petit定律。该研究强调了有效质量非线性对宏观热力学量的影响，并提出调整k参数可用于提升量子器件性能。


<details>
  <summary>Details</summary>
Motivation: 研究在非相对论量子力学框架下，具有位置相关有效质量的二维非线性振荡器的性质，特别是其能量谱、波函数以及相关的热力学行为。

Method: 利用Nikiforov-Uvarov方法求解薛定谔方程，获得能量谱和波函数的解析表达式。基于正则配分函数推导内能、比热、自由能和熵等关键热力学量。

Result: 获得能量谱和波函数的精确解析表达式。发现二维系统的比热强烈依赖于非线性参数k，且当k<0时，高温度下的比热不依赖于温度，符合Dulong-Petit定律。这些行为仅在k<0时出现。

Conclusion: 有效质量的非线性对宏观热力学量有显著影响。通过调整非线性参数k可以作为一种有效策略，用于提升量子器件（包括热机和光电器件）的性能。

Abstract: We investigate a two-dimensional nonlinear oscillator with a
position-dependent effective mass in the framework of nonrelativistic quantum
mechanics. Using the Nikiforov-Uvarov method, we obtain exact analytical
expressions for the energy spectrum and wave functions. Based on the canonical
partition function, we derive key thermodynamic quantities, including internal
energy, specific heat, free energy, and entropy. Our results show that, unlike
the one-dimensional case, where the specific heat is unaffected by the
nonlinearity parameter $k$, the two-dimensional system exhibits a strong
$k-$dependence. At high temperatures, the specific heat becomes
temperature-independent for fixed values of $k$, in line with the Dulong-Petit
law. However, these behaviors occur only for negative values of $k$. These
findings highlight the impact of effective mass nonlinearity on macroscopic
thermodynamic quantities and suggest that tuning the parameter $k$ could serve
as an effective strategy for enhancing the performance of quantum devices,
including thermal machines and optoelectronic components.

</details>


### [361] [Mitigating the phase-mismatch effect in non-resonant four-wave mixing enabled by optimal control](https://arxiv.org/abs/2509.12827)
*Ning Jia,Hamid R. Hamedi,Jing Qian*

Main category: quant-ph

TL;DR: 通过优化耦合场失谐来解决非线性光学过程中的相位失配问题，从而提高光场传播和转换效率。


<details>
  <summary>Details</summary>
Motivation: 非线性光学过程中的相位失配严重限制了光场的传播和转换效率。

Method: 利用固定、线性调制的耦合场诱导暗本征模式，并通过全局优化单耦合场失谐来最小化自发辐射损耗。

Result: 该方法在保持高效的探针到信号转换的同时，表现出对大相位失配变化的强大鲁棒性，优于现有的四波混频方案。

Conclusion: 该方法为提高非线性频率转换效率提供了一条有前景的途径，并放宽了对实验相位匹配的严格要求。

Abstract: Phase-mismatch in nonlinear optical processes can severely limit the
propagation and conversion efficiency of light fields. Here, we present an
efficient optimal-control strategy to mitigate the detrimental effects of
phase-mismatch in an electromagnetically induced transparency medium via
non-resonant four-wave mixing (FWM). By applying a set of fixed, linearly
modulated coupling fields that induce a dark eigenmode, we globally optimize a
single coupling detuning to minimize the spontaneous emission loss, the primary
factor limiting conversion efficiency. Our approach outperforms existing FWM
schemes by providing strong robustness against large phase-mismatch variations
while maintaining efficient probe-to-signal conversion. These results offer a
promising route toward more efficient nonlinear frequency conversion,
alleviating the stringent requirement for phase matching in experiments.

</details>


### [362] [The Quantum Control Hierarchy: When Physics-Informed Design Meets Machine Learning](https://arxiv.org/abs/2509.12832)
*Atta ur Rahman,M. Y. Abd-Rabbou,Cong-feng Qiao*

Main category: quant-ph

TL;DR: 没有单一的量子控制策略能完全主导所有场景，未来的高保真度量子控制将依赖于结合物理信息设计和自适应机器学习。


<details>
  <summary>Details</summary>
Motivation: 评估和比较各种量子控制策略（包括开放循环和自适应方法）在处理实际量子系统中的复杂性（如噪声、不完善性和多体效应）方面的有效性。

Method: 对开放循环协议和基于强化学习（RL）的自适应方法进行了基准测试，并在模拟环境中评估了它们的性能，该环境考虑了非马尔可夫彩色噪声、不完善性和马尔可夫林德布拉德方程。

Result: 确定性协议在纠缠生成/保持方面非常有效，在某些情况下甚至优于 RL。混合量子纠错和动力学解耦（QEC-DD）协议在纠缠保持方面表现最佳。对于需要发现非平凡控制序列的动态任务（如 DD、Floquet 工程、快速纠缠生成或相干传输），RL 代理表现优异。控制脉冲包络的形状会显著影响控制景观和协议的难度。

Conclusion: 没有一种万能的量子控制策略。未来的高保真度量子控制需要结合物理学启发的、鲁棒的混合方法（如 QEC-DD）和自适应机器学习（如 RL）的专业化优化能力。

Abstract: We address a wide spectrum of quantum control strategies, including various
open-loop protocols and advanced adaptive methods. These methodologies apply to
few-qubit scenarios and naturally scale to larger N-qubit systems. We benchmark
them across fundamental quantum tasks: entanglement preservation/generation,
and directed quantum transport in a disordered quantum walk. All simulations
are performed in a challenging environment featuring non-Markov colored noise,
imperfections, and the Markov Lindblad equation. With a complex task-dependent
performance hierarchy, our deterministic protocols proved highly effective for
entanglement generation/preservation, and in specific pulse configurations,
they even outperformed the RL-optimization. In contrast, more advanced methods
demonstrate a marked specialization. For entanglement preservation, a
physics-informed hybrid Quantum Error Correction and Dynamical Decoupling
(QEC-DD) protocol provides the most stable and effective solution,
outperforming all other approaches. Conversely, for dynamic tasks requiring the
discovery of non-trivial control sequences, such as DD, Floquet engineering,
and rapid entanglement generation or coherent transport, the model-free
Reinforcement Learning (RL) agents consistently find superior solutions. We
further demonstrate that the control pulse envelope is a non-trivial factor
that actively shapes the control landscape, which determines the difficulty for
all protocols and highlights the adaptability of the RL agent. We conclude that
no single strategy is universally dominant. A clear picture emerges: the future
of high-fidelity quantum control lies in a synthesis of physics-informed
design, as exemplified by robust hybrid methods, and the specialized,
high-performance optimization power of adaptive machine learning.

</details>


### [363] [Dynamics of Quantum Analogs of Classical Impact Oscillators](https://arxiv.org/abs/2509.12835)
*Arnab Acharya,Titir Mukherjee,Deepshikha Singh,Soumitro Banerjee*

Main category: quant-ph

TL;DR: 量子系统可以展现出类似于经典非线性系统的丰富动力学特征，包括准周期性、奇异非混沌动力学甚至混沌，尤其是在耗散存在的情况下。


<details>
  <summary>Details</summary>
Motivation: 探索经典冲击振荡器的量子类似物如何展现复杂的非线性行为，以及量子系统是否可能出现经典系统中存在的混沌和分叉等动力学。

Method: 通过对未受迫、受迫和耗散的量子振荡器进行模拟，并利用熵时间序列、傅里叶光谱、OTOCs、李雅普诺夫分析和0-1测试等方法进行分析。

Result: 研究发现，在耗散存在的情况下，量子振荡器可以表现出准周期性、奇异非混沌动力学甚至混沌现象，这些现象与经典非线性系统中的动力学类似。

Conclusion: 量子系统，即使其基本方程是线性的，也可以通过耗散等机制展现出丰富的非线性动力学行为，这在量子力学和混沌理论之间架起了一座桥梁。

Abstract: This paper investigates the dynamics of quantum analogs of classical impact
oscillators to explore how complex nonlinear behaviors manifest in quantum
systems. While classical impact oscillators exhibit chaos and bifurcations,
quantum systems, governed by linear equations, appear to forbid such dynamics.
Through simulations of unforced, forced, and dissipative quantum oscillators,
we uncover quasiperiodicity, strange nonchaotic dynamics, and even chaos in the
presence of dissipation. Using entropy time series, Fourier spectra, OTOCs,
Lyapunov analysis, and the 0-1 test, we demonstrate that quantum systems can
exhibit rich dynamical signatures analogous to classical nonlinear systems,
bridging quantum mechanics and chaos theory.

</details>


### [364] [Uniqueness of purifications is equivalent to Haag duality](https://arxiv.org/abs/2509.12911)
*Lauritz van Luijk,Alexander Stottmeister,Henrik Wilming*

Main category: quant-ph

TL;DR: 量子态的纯化在局部酉变换下具有唯一性，这在量子信息理论中至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究量子态纯化的唯一性及其与Haag对偶的关系。

Method: 通过分析量子系统A和B的算子代数（M_A和M_B）来研究纯化的唯一性。

Result: 证明了纯化唯一性等价于Haag对偶（M_A = M_B'），并指出在无限自由度系统中纯化唯一性可能失败。

Conclusion: 在具有无限自由度的系统中，即使算子代数满足特定条件，纯化唯一性也可能不成立。

Abstract: The uniqueness of purifications of quantum states on a system $A$ up to local
unitary transformations on a purifying system $B$ is central to quantum
information theory. We show that, if the two systems are modelled by commuting
von Neumann algebras $M_A$ and $M_B$ on a Hilbert space $\mathcal H$, then
uniqueness of purifications is equivalent to Haag duality $M_A = M_B'$. In
particular, the uniqueness of purifications can fail in systems with infinitely
many degrees of freedom -- even when $M_A$ and $M_B$ are commuting factors that
jointly generate $B(\mathcal H)$ and hence allow for local tomography of all
density matrices on $\mathcal H$.

</details>


### [365] [Data-Efficient Quantum Noise Modeling via Machine Learning](https://arxiv.org/abs/2509.12933)
*Yanjun Ji,Marco Roth,David A. Kreplin,Ilia Polian,Frank K. Wilhelm*

Main category: quant-ph

TL;DR: 通过从现有电路的测量数据中学习硬件特定的错误参数，开发了一种数据高效、基于机器学习的框架，用于构建准确、参数化的超导量子处理器噪声模型，从而提高了模型保真度。


<details>
  <summary>Details</summary>
Motivation: 需要预测性噪声模型来指导鲁棒的、噪声感知的编译和错误缓解，以最大化近期量子处理器的计算效用。

Method: 提出了一种数据高效的、基于机器学习的框架，该框架直接从现有应用程序和基准电路的测量数据中学习硬件特定的错误参数，以构建准确的、参数化的噪声模型。

Result: 与从设备属性派生的标准噪声模型相比，通过Hellinger距离量化的模型保真度提高了65%。在一个模型仅在小规模电路上训练的情况下，也能准确预测大规模验证电路的行为。

Conclusion: 这项工作提出了一种实用的噪声表征范式，为开发更有效的噪声感知编译和错误缓解策略提供了关键工具。

Abstract: Maximizing the computational utility of near-term quantum processors requires
predictive noise models that inform robust, noise-aware compilation and error
mitigation. Conventional models often fail to capture the complex error
dynamics of real hardware or require prohibitive characterization overhead. We
introduce a data-efficient, machine learning-based framework to construct
accurate, parameterized noise models for superconducting quantum processors.
Our approach circumvents costly characterization protocols by learning
hardware-specific error parameters directly from the measurement data of
existing application and benchmark circuits. The generality and robustness of
the framework are demonstrated through comprehensive benchmarking across
multiple quantum devices and algorithms. Crucially, we show that a model
trained exclusively on small-scale circuits accurately predicts the behavior of
larger validation circuits. Our data-efficient approach achieves up to a 65%
improvement in model fidelity quantified by the Hellinger distance between
predicted and experimental circuit output distributions, compared to standard
noise models derived from device properties. This work establishes a practical
paradigm for noise characterization, providing a crucial tool for developing
more effective noise-aware compilation and error-mitigation strategies.

</details>


### [366] [First Practical Experiences Integrating Quantum Computers with HPC Resources: A Case Study With a 20-qubit Superconducting Quantum Computer](https://arxiv.org/abs/2509.12949)
*Eric Mansfield,Stefan Seegerer,Panu Vesanen,Jorge Echavarria,Burak Mete,Muhammad Nufail Farooqi,Laura Schulz*

Main category: quant-ph

TL;DR: 量子计算机已成功集成到高性能计算(HPC)环境中，为科学研究带来了新的计算能力，并为未来的集成提供了指导方针。


<details>
  <summary>Details</summary>
Motivation: 将量子计算机整合到高性能计算(HPC)环境中，以增强科学研究的计算能力。

Method: 将一个基于超导的20量子比特量子计算机整合到Leibniz超级计算中心(LRZ)的HPC基础设施中，并记录了实际操作中遇到的挑战和经验。

Result: 量子计算机需要比经典系统更严格的设施要求，但通过严格的场地勘测是可行的。量子计算机是动态系统，需要自动且可控的定期重新校准。冗余的电力和冷却基础设施是必不可少的。需要为量子专家和新用户提供实践指导。未来的HPC中心集成应该遵循这些结论。

Conclusion: 本研究为未来在HPC环境中集成量子计算机提供了路线图，强调了对设施、操作、基础设施和用户培训的关注。

Abstract: Incorporating Quantum Computers into High Performance Computing (HPC)
environments (commonly referred to as HPC+QC integration) marks a pivotal step
in advancing computational capabilities for scientific research. Here we report
the integration of a superconducting 20-qubit quantum computer into the HPC
infrastructure at Leibniz Supercomputing Centre (LRZ), one of the first
practical implementations of its kind. This yielded four key lessons: (1)
quantum computers have stricter facility requirements than classical systems,
yet their deployment in HPC environments is feasible when preceded by a
rigorous site survey to ensure compliance; (2) quantum computers are inherently
dynamic systems that require regular recalibration that is automatic and
controllable by the HPC scheduler; (3) redundant power and cooling
infrastructure is essential; and (4) effective hands-on onboarding should be
provided for both quantum experts and new users. The identified conclusions
provide a roadmap to guide future HPC center integrations.

</details>


### [367] [Towards Universal Quantum Tamper Detection](https://arxiv.org/abs/2509.12986)
*Anne Broadbent,Upendra Kapshikar,Denis Rochette*

Main category: quant-ph

TL;DR: 本论文首次对任意量子映射进行了防篡改检测的普遍性处理，展示了量子编码在处理古典设置中无法克服的限制（如常数函数篡改）方面的优越性，并提出了量子防篡改检测的普遍存在性猜想。


<details>
  <summary>Details</summary>
Motivation: 研究如何在数据被解码前，受到能够物理操作码字的不诚实对手的操纵时保护数据。此前的研究主要集中在经典对抗或仅限于酉酉篡改的量子对抗。

Method: 通过使用 Haar 随机编码方案来实现指数级小的可靠性误差，并分析了篡改家族的大小、Kraus 秩和纠缠保真度等约束条件。此外，还探讨了经典和量子篡改检测之间的根本性区别，并提出了量子编码可以克服经典放松篡改检测的障碍。

Result: 在任意量子映射下，Haar 随机编码方案实现了指数级小的可靠性误差。与经典情况不同，量子编码可以处理常数函数篡改，并可能提供放松篡改检测和非延展性安全，其规模可达 $2^{2^{\alpha n}}$（其中 $\alpha < \frac{1}{2}$）。

Conclusion: 本研究为量子防篡改检测提供了第一个证据，证明其比经典防篡改检测更强大，并提出了量子防篡改检测的普遍存在性猜想。

Abstract: Tamper-resilient cryptography studies how to protect data against adversaries
who can physically manipulate codewords before they are decoded. The notion of
tamper detection codes formalizes this goal, requiring that any unauthorized
modification be detected with high probability. Classical results, starting
from Jafargholi and Wichs (TCC 2015), established the existence of such codes
against very large families of tampering functions, subject to structural
restrictions ruling out identity and constant maps. Recent works of Boddu and
Kapshikar (Quantum, 7) and Bergamaschi (Eurocrypt 2024) have extended these
ideas to quantum adversaries, but only consider unitary tampering families.
  In this work, we give the first general treatment of tamper detection against
arbitrary quantum maps. We show that Haar-random encoding schemes achieve
exponentially small soundness error against any adversarial family whose size,
Kraus rank, and entanglement fidelity obey natural constraints, which are
direct quantum analogues of restrictions in the classical setting. Our results
unify and extend previous works. Beyond this, we demonstrate a fundamental
separation between classical and quantum tamper detection. Classically, relaxed
tamper detection which allows either rejection or recovery of the original
message cannot protect even against the family of constant functions. This
family is of size $2^n$. In contrast, we show that quantum encodings can handle
this obstruction, and we conjecture and provide evidence that they may in fact
provide relaxed tamper detection and non-malleable security against any family
of quantum maps of size up to $2^{2^{\alpha n}}$ for any constant $\alpha
<\frac{1}{2}$, leading to a conjecture on the existence of universal quantum
tamper detection. Our results provide the first evidence that quantum tamper
detection is strictly more powerful than its classical counterpart.

</details>


### [368] [Mitigating the sign problem by quantum computing](https://arxiv.org/abs/2509.13017)
*Kwai-Kong Ng,Min-Fong Yang*

Main category: quant-ph

TL;DR: qc-SSE方法并未严格解决量子蒙特卡洛模拟中的符号问题，但可以作为一种缓解策略，通过引入能量位移来抑制负权重。


<details>
  <summary>Details</summary>
Motivation: 评估qc-SSE方法是否能解决量子蒙特卡洛模拟中的符号问题，并分析其有效性。

Method: 使用反铁磁各向异性XY链作为测试用例，分析平均符号对系统大小、温度、各向异性和位移参数的依赖性，并引入算符收缩法提高效率。

Result: 中等位移可以最佳地平衡符号缓解和统计精度，而大的位移会放大误差，符号问题得到缓解但未解决。

Conclusion: qc-SSE方法并非严格解决符号问题的方案，但作为一种缓解策略，通过引入能量位移可以抑制负权重，尤其在中等位移下效果最佳。

Abstract: The notorious sign problem severely limits the applicability of quantum Monte
Carlo (QMC) simulations, as statistical errors grow exponentially with system
size and inverse temperature. A recent proposal of a quantum-computing
stochastic series expansion (qc-SSE) method suggested that the problem could be
avoided by introducing constant energy shifts into the Hamiltonian. Here we
critically examine this framework and show that it does not strictly resolve
the sign problem for Hamiltonians with non-commuting terms. Instead, it
provides a practical mitigation strategy that suppresses the occurrence of
negative weights. Using the antiferromagnetic anisotropic XY chain as a test
case, we analyze the dependence of the average sign on system size,
temperature, anisotropy, and shift parameters. An operator contraction method
is introduced to improve efficiency. Our results demonstrate that moderate
shifts optimally balance sign mitigation and statistical accuracy, while large
shifts amplify errors, leaving the sign problem unresolved but alleviated.

</details>


### [369] [Slice-Wise Initial State Optimization to Improve Cost and Accuracy of the VQE on Lattice Models](https://arxiv.org/abs/2509.13034)
*Cedric Gaberle,Manpreet Singh Jattana*

Main category: quant-ph

TL;DR: 提出了一种结合自适应和受物理启发的ansatz设计的VQE优化方法，通过增量构建ansatz并进行子空间优化，在海森堡和哈伯德模型上实现了更高的保真度或更少的函数评估。


<details>
  <summary>Details</summary>
Motivation: 为了改进变分量子本征求解器（VQE）的性能，提出了一种新的ansatz设计和优化方法。

Method: 该方法通过增量方式构建ansatz，从其算子子集中逐步添加，实现了子空间优化，并结合了自适应和受物理启发的策略。

Result: 在具有多达20个量子比特的二维海森堡和哈伯德模型上的基准测试表明，与固定的VQE相比，该方法提高了保真度，减少了函数评估次数，或两者兼而有之。

Conclusion: 所提出的方法简单、成本效益高，并且非常适合当前的噪声中等规模量子（NISQ）设备，因为它在保持ansatz的表达能力和硬件效率的同时，避免了自适应方法中与算子选择相关的开销。

Abstract: We propose an optimization method for the Variational Quantum Eigensolver
(VQE) that combines adaptive and physics-inspired ansatz design. Instead of
optimizing multiple layers simultaneously, the ansatz is built incrementally
from its operator subsets, enabling subspace optimization that provides better
initialization for subsequent steps. This quasi-dynamical approach preserves
expressivity and hardware efficiency while avoiding the overhead of operator
selection associated with adaptive methods. Benchmarks on one- and
two-dimensional Heisenberg and Hubbard models with up to 20 qubits show
improved fidelities, reduced function evaluations, or both, compared to
fixed-layer VQE. The method is simple, cost-effective, and particularly
well-suited for current noisy intermediate-scale quantum (NISQ) devices.

</details>


### [370] [Resource-efficient entanglement detection in high-dimensional states via two-qubit witnesses](https://arxiv.org/abs/2509.13061)
*Josef Kadlec,Artur Barasiński,Karel Lemr*

Main category: quant-ph

TL;DR: 该方法将高维两-qudit态的希尔伯特空间映射到两量子比特空间，利用成熟的两量子比特纠缠判据来检测纠缠，适用于各类量子态，测量次数不随维度增加，且具备良好的实验可行性。


<details>
  <summary>Details</summary>
Motivation: 需要一种高效的方法来检测高维两-qudit态中的纠缠，并能识别大部分纯纠缠态。

Method: 将高维两-qudit态的希尔伯特空间映射到两量子比特空间，并应用两量子比特纠缠判据。

Result: 该方法能成功识别大部分纯纠缠态，测量次数不随维度增加，对不完全置换对称态和带噪声的随机纯态具有良好的敏感性，并证明了其在实验上的可行性。

Conclusion: 所提出的方法能够高效地检测高维两-qudit态中的纠缠，适用于广泛的量子态，并且易于进行实验验证。

Abstract: This paper presents an efficient method for detecting entanglement in
high-dimensional two-qudit states by mapping the Hilbert space onto the space
of two qubits. This transformation enables the use of well-established
two-qubit entanglement witnesses. The proposed approach is not restricted to
any specific class of states, successfully identifies a vast majority of pure
entangled states, and requires a number of measurements that does not increase
with the dimensionality of the qudits. The method demonstrates solid
sensitivity when applied to two notable classes of states,
incomplete-permutation-symmetric states and random pure states mixed with white
noise, and is shown to be feasible with current experimental techniques.

</details>


### [371] [Certifying bipartite entangled states with few local measurements: from separable stabilizers to applications](https://arxiv.org/abs/2509.13082)
*Jennifer Ahiable,Andreas Winter*

Main category: quant-ph

TL;DR: 任何给定的二分状态都可以被认证为两个可分离投影仪的唯一联合1-本征态，并且这些投影仪可以通过简单的局部可观测值来测量。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是提供一种简单系统的方法来认证二分状态，并将其应用于量子信道的纠缠保真度。

Method: 通过将二分结果递归地推广到多方系统，并使用可分离投影仪来界定状态的保真度。

Result: 任何n方纯状态都是2^(n-1)个可分离投影仪的唯一联合1-本征态，并且状态失效率的上界可以用可分离稳定器投影仪的失效率来表示。

Conclusion: 该研究提出了一种认证二分状态和界定量子信道纠缠保真度的新方法，并将该方法推广到多方系统。

Abstract: We show a simple and systematic way to certify any given bipartite state as
the unique joint $1$-eigenstate of two separable projectors, each of which can
be measured with simple local observables. This is practically useful, as the
detection probabilities of the two stabilizer projectors relate directly to the
fidelity of certification. The same result gives a simple and effective lower
bound on the entanglement fidelity of a quantum channel in terms of two
ensemble fidelities.
  We then generalise the bipartite result recursively to multipartite systems,
showing that every $n$-party pure state is the unique joint $1$-eigenstate of
$2^{n-1}$ separable projectors, and an upper bound of the infidelity of the
state in terms of the infidelities of the separable stabilizer projectors.

</details>


### [372] [Steady-state entanglement of spin qubits mediated by non-reciprocal and chiral magnons](https://arxiv.org/abs/2509.13094)
*Martijn Dols,Mikhail Cherkasskii,Victor A. S. V. Bittencourt,Carlos Gonzalez-Ballestero,Durga B. R. Dasari,Silvia Viola Kusminskiy*

Main category: quant-ph

TL;DR: 提出了一种混合量子系统，其中支持非互易或手征磁声子的磁体介导自旋量子比特的耗散和单向耦合，从而实现最大纠缠贝尔态，并对该方案进行了数值测试，确定了技术要求，为利用磁子学实现固态自旋纠缠提供了可行途径。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索一种新的量子系统，该系统能够实现固态自旋之间的最大纠缠，并为量子信息处理提供新的工具。

Method: 提出了一种混合量子系统，其中磁体介导自旋量子比特的耗散和单向耦合。通过驱动量子比特，系统的稳态变为最大纠缠贝尔态。对该协议进行了数值测试，考虑了量子比特的衰减和退相干。

Result: 在包含氮-空位（NV）中心和钇铁石榴石（YIG）薄膜磁表面模式的混合系统中，数值测试表明，NV中心的退相干时间是实现微米以上距离NV中心纠缠的瓶颈。

Conclusion: 该研究提出了一个利用磁子量子网络实现固态自旋在微米尺度上纠缠的可行方案，并确定了实现该目标的关键技术要求，为磁子学在量子信息处理中的应用提供了新的思路和工具。

Abstract: We propose a hybrid quantum system in which a magnet supporting
non-reciprocal magnons, chiral magnons, or both mediates the dissipative and
unidirectional coupling of spin qubits. By driving the qubits, the steady state
of this qubit-qubit coupling scheme becomes the maximally entangled Bell state.
We devise a protocol where the system converges to this entangled state and
benchmark it including qubit decay and dephasing. The protocol is numerically
tested on a hybrid system consisting of nitrogen-vacancy (NV) centers coupled
to magnon surface modes of an yttrium iron garnet (YIG) film. We show that the
dephasing time of the NV centers forms the bottleneck for achieving the
entanglement of NV centers separated by a distance exceeding microns. Our
findings identify the key technological requirements and demonstrate a viable
route toward steady-state entanglement of solid-state spins over distances of
several microns using magnonic quantum networks, expanding the toolbox of
magnonics for quantum information purposes.

</details>


### [373] [Cyclic Variational Quantum Eigensolver: Escaping Barren Plateaus through Staircase Descent](https://arxiv.org/abs/2509.13096)
*Hao Zhang,Ayush Asthana*

Main category: quant-ph

TL;DR: CVQE是一种用于NISQ设备的量子模拟框架，通过迭代添加具有高采样概率的 Slater 决定式来扩大参考叠加，并复用固定的纠缠器，以实现精确的基态模拟。


<details>
  <summary>Details</summary>
Motivation: 开发一种在噪声中型量子（NISQ）设备上进行精确基态量子模拟的硬件高效框架。

Method: CVQE通过结合测量驱动的反馈循环来改进传统的VQE。它迭代地将具有显着采样概率的 Slater 决定式添加到参考叠加中，并重复使用固定的纠缠器（例如，单层UCCSD）。这种自适应参考增长系统地在最有希望的方向上扩大了变分空间。

Result: CVQE展示了独特的阶梯状下降模式，能量的连续下降表明有效地避开了 barren plateaus。与固定的UCCSD相比，CVQE的化学精度在不同相关性范围内始终保持，并且性能优越数个数量级。与已选的相互作用相比，CVQE实现了有利的精度-成本权衡。

Conclusion: CVQE是一种可扩展、可解释且资源高效的近期量子模拟范式。

Abstract: We introduce the Cyclic Variational Quantum Eigensolver (CVQE), a
hardware-efficient framework for accurate ground-state quantum simulation on
noisy intermediate-scale quantum (NISQ) devices. CVQE departs from conventional
VQE by incorporating a measurement-driven feedback cycle: Slater determinants
with significant sampling probability are iteratively added to the reference
superposition, while a fixed entangler (e.g., single-layer UCCSD) is reused
throughout. This adaptive reference growth systematically enlarges the
variational space in most promising directions, avoiding manual ansatz or
operator-pool design, costly searches, and preserving compile-once circuits.
The strategy parallels multi-reference methods in quantum chemistry, while
remaining fully automated on quantum hardware. Remarkably, CVQE exhibits a
distinctive staircase-like descent pattern, where successive energy drops
sharply signal efficient escape from barren plateaus. Benchmarks show that CVQE
consistently maintains chemical precision across correlation regimes,
outperforms fixed UCCSD by several orders of magnitude, and achieves favorable
accuracy-cost trade-offs compared to the Selected Configuration Interaction.
These results position CVQE as a scalable, interpretable, and
resource-efficient paradigm for near-term quantum simulation.

</details>


### [374] [Ultrafast non-adiabatic molecular energy conversion into photons induced by quantized electromagnetic fields](https://arxiv.org/abs/2509.13233)
*Arley Flórez López,Johan F. Triana,José Luis Sanz-Vicario*

Main category: quant-ph

TL;DR: 利用基于 Holstein-quantum-Rabi 汉密尔顿量的分子模型，研究了在量化腔内受限电磁场中双原子分子的超快光动力学，发现在非绝热耦合存在的情况下，会产生两种新的光诱导交叉。


<details>
  <summary>Details</summary>
Motivation: 开发新的光子产生方法在纳米光子学中仍然是一个挑战。

Method: 提出一个基于 Holstein-quantum-Rabi 汉密尔顿量的分子模型，该模型考虑了真实的偶极矩和电子激发态之间的非绝热耦合，用于研究量化腔内受限电磁场中双原子分子的超快光动力学。

Result: 发现了两种新的光诱导交叉，并研究了非绝热耦合对极化激子能量谱的影响，证明了分子非绝热耦合和反旋转耦合在通过激发缀饰态将振动子能量转化为光子方面起着关键作用。

Conclusion: 分子非绝热耦合和腔-分子相互作用中的反旋转耦合对于通过激发缀饰态将振动子能量转化为光子至关重要，并且 Huang-Rhys 因子也对此过程有显著影响。

Abstract: Molecular polaritons within the mid-infrared regime have emerged as a source
for modifying and manipulating molecular and photonic properties. However, the
development of new methodologies for photon generation is still a challenge in
nanophotonics. We propose a molecular model based on the Holstein-quantum-Rabi
Hamiltonian, which also incorporates realistic dipole moments and non-adiabatic
couplings among electronic excited states, to study the ultrafast photodynamics
of diatomic molecules in confined electromagnetic fields within quantized
cavities. In addition to vibronic transitions due to intrinsic non-adiabatic
couplings, two types of light-induced crossings emerge: one type is located at
molecular nuclear geometries where the rotating wave approximation is
fulfilled, and another type appears at different geometries where
counter-rotating transitions may occur. We make a comprehensive study of
polariton photodynamics within a time window of a few tens of femtoseconds,
where dissipative mechanisms do not influence the polariton photodynamics. We
stress the dramatic change of the polariton energy spectrum as a function of
the Huang-Rhys factor when non-adiabatic couplings are included in the model.
We conclude that both the molecular non-adiabatic couplings and, more
specifically, the counter-rotating couplings in the cavity-molecule interaction
play a crucial role in converting vibronic energy into photons through excited
dressed states. We also show that the sign of the Huang-Rhys factor has a
significant impact on this photon conversion. Our work paves the way for the
development of many-photon generation powered by strong light-matter
interaction, along with potential applications using alkaline earth monohydride
molecules.

</details>


### [375] [Demonstration of a Logical Architecture Uniting Motion and In-Place Entanglement: Shor's Algorithm, Constant-Depth CNOT Ladder, and Many-Hypercube Code](https://arxiv.org/abs/2509.13247)
*Rich Rines,Benjamin Hall,Mariesa H. Teo,Joshua Viszlai,Daniel C. Cole,David Mason,Cameron Barker,Matt J. Bedalov,Matt Blakely,Tobias Bothwell,Caitlin Carnahan,Frederic T. Chong,Samuel Y. Eubanks,Brian Fields,Matthew Gillette,Palash Goiporia,Pranav Gokhale,Garrett T. Hickman,Marin Iliev,Eric B. Jones,Ryan A. Jones,Kevin W. Kuper,Stephanie Lee,Martin T. Lichtman,Kevin Loeffler,Nate Mackintosh,Farhad Majdeteimouri,Peter T. Mitchell,Thomas W. Noel,Ely Novakoski,Victory Omole,David Owusu-Antwi,Alexander G. Radnaev,Anthony Reiter,Mark Saffman,Bharath Thotakura,Teague Tomesh,Ilya Vinogradov*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量子比特架构，通过将量子比特运动和原地纠缠相结合，减少了量子计算中的开销和错误。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有量子比特架构中，频繁的量子比特运动带来的高昂时间成本和错误累积问题，提出了一种新的架构。

Method: 该架构通过在最近邻的量子比特间进行原地纠缠门操作，同时保持了全连接性，并最小化了量子比特的运动开销。研究人员在Infleqtion的114个中性原子量子比特的Sqale QPU上进行了实验验证。

Result: 1. 实现了Shor算法的逻辑量子比特版本，并在多种设置下（包括损耗纠正和泄漏检测）表现出优于物理量子比特的性能。 2. 提出了一种CNOT ladder技术，其深度与逻辑量子比特数量N和编码距离d无关，并在8和12个逻辑量子比特的实验中实现了约4倍的错误减少。 3. 实验实现了[[16, 4, 4]]多超立方体量子纠错码的初始化。

Conclusion: 所提出的结合量子比特运动和原地纠缠的架构，为减少大规模量子应用相对于基于纠缠区域的架构的开销提供了一条可行的路径。

Abstract: Logical qubits are considered an essential component for achieving
utility-scale quantum computation. Multiple recent demonstrations of logical
qubits on neutral atoms have relied on coherent qubit motion into entangling
zones. However, this architecture requires motion prior to every entangling
gate, incurring significant cost in wall clock runtime and motion-related error
accumulation. We propose and experimentally realize an alternative architecture
which unites qubit motion and in-place entanglement via nearest-neighbor gates.
Our approach maintains all-to-all connectivity, while minimizing qubit motion
overheads. We demonstrate three key results on Infleqtion's Sqale QPU, which
hosts an array of 114 neutral atom qubits. First, we perform a logical qubit
realization of a pre-compiled variant of Shor's Algorithm. We find better
logical-than-physical performance over a range of settings including with loss
correction and leakage detection. Second, we introduce a technique for
performing CNOT ladders with depth independent of both the number of logical
qubits N and the code distance d. In proof-of-principle experiments with 8 and
12 logical qubits, we find ~4x reduction in error via the logical encodings.
Third, we experimentally realize initialization of the [[16, 4, 4]]
many-hypercube QEC code. All three results benefit from optimized compilation
via Superstaq, as well as our underlying architecture uniting motion and
in-place entanglement. This architecture offers a path to reducing the overhead
of utility-scale quantum applications relative to architectures based on
entangling zones.

</details>


### [376] [A Robust Modular Quantum Processor](https://arxiv.org/abs/2509.13269)
*Ramesh Bhandari*

Main category: quant-ph

TL;DR: 通过引入冗余设计来提高量子计算架构的鲁棒性，特别是针对具有潜在单点故障的中心路由器。


<details>
  <summary>Details</summary>
Motivation: 为了规避关键元件（例如由宇宙射线事件引起的故障）对量子操作的破坏，探索了量子计算架构中关键元件冗余的概念。

Method: 提出了一种双星配置，其中第二个星配置作为第一个星配置的备份，以实现路由器的冗余。还检查了在正常运行条件下的双星配置的有用性。

Result: 双星配置可以实现路由器的冗余，可以容忍一个路由器的故障。在正常条件下，这种配置还可以同时实现两量子比特对交互和多量子比特门。

Conclusion: 双星配置是一种有前景的量子计算架构设计，可以提高鲁棒性和门保真度。

Abstract: We explore the concept of redundancy of critical elements in a quantum
computing architecture to circumvent disruption of quantum operations due to a
failure of such an element, for example, from a catastrophic cosmic ray event.
We illustrate this concept with reference to a recently proposed
superconducting modular quantum architecture with a star-like configuration,
which has a router at the center that enables superconducting qubit
interactions across various modules. Regarding this router as a vital element,
we propose a double-star configuration, where a loss of one router is backed by
the second one. We also examine the usefulness of this double-star
configuration under normal conditions, namely, when the quantum hardware has
been rendered safe against cosmic rays due to other mitigating actions like
shielding or movement to an underground facility. Simultaneous two qubit-pair
interactions like two simultaneous CZ gates and multiqubit gates like CCZS are
then easily facilitated.

</details>


### [377] [Coherence and Dimensionality Witnesses for Fractional OAM Modes](https://arxiv.org/abs/2509.13275)
*A. L. S. Santos Junior,I. Prego,M. Gil de Oliveira,A. C. Barbosa,B. P. da Silva,D. J. Brod,E. F. Galvão,A. Z. Khoury*

Main category: quant-ph

TL;DR: We use properties of light beams to demonstrate a new method for analyzing fractional orbital angular momentum (OAM) states, which could be useful for quantum information.


<details>
  <summary>Details</summary>
Motivation: This paper aims to characterize sets of fractional orbital angular momentum (OAM) modes using properties that are independent of the specific basis used to describe them. The goal is to enable the use of these fractional OAM states in advanced quantum information applications.

Method: The study utilizes basis-independent coherence and dimension witnesses to experimentally verify the coherence and dimensionality of a triple of fractional OAM modes. A new, efficient experimental technique is also introduced, which requires only one intensity image per interference pair to extract two-mode overlaps.

Result: The experiment successfully certified the coherence of the fractional OAM states and confirmed that they span a space of dimension 3. The proposed method for extracting two-mode overlaps was implemented and shown to be practical and fast.

Conclusion: The findings provide a foundational understanding and experimental validation for using fractional OAM states, paving the way for their application in high-dimensional quantum information protocols.

Abstract: We characterize sets of fractional orbital angular momentum (OAM) modes of a
light beam using unitary-invariant properties encoded by two-mode overlaps.
Using basis-independent coherence and dimension witnesses, we experimentally
certify, on a triple of fractional modes, both the presence of coherence and
that the states necessarily span a space of dimension 3. We propose and
implement a practical, fast experimental method to extract two-mode overlaps
requiring only a single intensity image per interference pair. These results
lay the groundwork for using fractional OAM states in high-dimensional quantum
information protocols.

</details>


### [378] [Generalized Quantum Stein's Lemma and Reversibility of Quantum Resource Theories for Classical-Quantum Channels](https://arxiv.org/abs/2509.13280)
*Bjarne Bergh,Nilanjana Datta,Anirudh Khaitan*

Main category: quant-ph

TL;DR: 我们证明了经典-量子(c-q)信道复合假设检验问题的最优渐近不对称错误指数由Umegaki信道散度的正则化给出，该散度在S_n上最小化。


<details>
  <summary>Details</summary>
Motivation: 将Hayashi和Yamasaki的广义量子Stein引理(GQSL)推广到经典-量子(c-q)信道，并分析其在平行策略下的复合假设检验问题。

Method: 通过正则化Umegaki信道散度，并最小化$\(mathcal{S}_n\)$中的散度来分析c-q信道的复合假设检验问题。

Result: 证明了最优渐近不对称错误指数由Umegaki信道散度的正则化给出，该散度在$\(mathcal{S}_n\)$上最小化，并证明了经典-量子信道资源理论的可逆性。

Conclusion: 这项工作将GQSL推广到c-q信道，证明了其在资源理论中的可逆性，并提出了与现有工作类似但证明技术不同的结果。

Abstract: We extend the recent proof of the Generalized Quantum Stein's Lemma by
Hayashi and Yamasaki [arXiv:2408.02722] to classical-quantum (c-q) channels. We
analyze the composite hypothesis testing problem of testing a c-q channel
$\mathcal{E}^{\otimes n}$ against a sequence of sets of c-q channels
$(\mathcal{S}_n)_n$ (satisfying certain natural assumptions), under parallel
strategies. We prove that the optimal asymptotic asymmetric error exponent is
given by the regularization of Umegaki channel divergence, minimized over
$\mathcal{S}_n$. This allows us to prove the reversibility of resource theories
of classical-quantum channels in a natural framework, where the distance
between channels (and hence also the notion of approximate interconvertibility
of channels) is measured in diamond norm, and the set of free operations is the
set of all asymptotically resource non-generating superchannels. The results we
obtain are similar to the ones in the concurrent and independent work by
Hayashi and Yamasaki [arXiv:2509.07271]. However the proof of the direct part
of the GQSL uses different arguments and techniques to deal with the challenges
that arise from dealing with c-q channels.

</details>
