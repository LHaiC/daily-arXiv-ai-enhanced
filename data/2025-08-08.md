<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 101]
- [cs.CL](#cs.CL) [Total: 41]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.DS](#cs.DS) [Total: 8]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.LG](#cs.LG) [Total: 97]
- [quant-ph](#quant-ph) [Total: 53]
- [cs.RO](#cs.RO) [Total: 29]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.MA](#cs.MA) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [cs.ET](#cs.ET) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 18]
- [eess.SY](#eess.SY) [Total: 10]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [eess.SP](#eess.SP) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration](https://arxiv.org/abs/2508.04797)
*Mohab Kishawy,Ali Abdellatif Hussein,Jun Chen*

Main category: cs.CV

TL;DR: 提出了一种名为RetinexDual的新型UHD图像恢复框架，它结合了两个子网络（SAMBA和FIA），分别处理图像的反射分量和颜色/照明失真，并在多种任务中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如下采样或频域转换）在UHD图像恢复中存在信息丢失和无法处理空间局部退化的问题。本研究旨在克服这些限制，提出一种更通用的UHD IR框架。

Method: 提出了一种名为RetinexDual的新型基于Retinex理论的框架，该框架包含两个子网络：Scale-Attentive maMBA (SAMBA) 和 Frequency Illumination Adaptor (FIA)。SAMBA通过粗粒到细粒的机制纠正反射分量，FIA在频域中操作并利用其全局上下文来精确校正颜色和照明失真。

Result: RetinexDual在四个UHD IR任务（去雨、去模糊、去雾和低光图像增强）上取得了定性和定量的优越性能。

Conclusion: RetinexDual在四个UHD IR任务（去雨、去模糊、去雾和低光图像增强）上进行了评估，并取得了定性和定量上的优于现有方法。消融研究证明了RetinexDual中不同分支设计的必要性及其各组成部分的有效性。

Abstract: Advancements in image sensing have elevated the importance of
Ultra-High-Definition Image Restoration (UHD IR). Traditional methods, such as
extreme downsampling or transformation from the spatial to the frequency
domain, encounter significant drawbacks: downsampling induces irreversible
information loss in UHD images, while our frequency analysis reveals that pure
frequency-domain approaches are ineffective for spatially confined image
artifacts, primarily due to the loss of degradation locality. To overcome these
limitations, we present RetinexDual, a novel Retinex theory-based framework
designed for generalized UHD IR tasks. RetinexDual leverages two complementary
sub-networks: the Scale-Attentive maMBA (SAMBA) and the Frequency Illumination
Adaptor (FIA). SAMBA, responsible for correcting the reflectance component,
utilizes a coarse-to-fine mechanism to overcome the causal modeling of mamba,
which effectively reduces artifacts and restores intricate details. On the
other hand, FIA ensures precise correction of color and illumination
distortions by operating in the frequency domain and leveraging the global
context provided by it. Evaluating RetinexDual on four UHD IR tasks, namely
deraining, deblurring, dehazing, and Low-Light Image Enhancement (LLIE), shows
that it outperforms recent methods qualitatively and quantitatively. Ablation
studies demonstrate the importance of employing distinct designs for each
branch in RetinexDual, as well as the effectiveness of its various components.

</details>


### [2] [ACM Multimedia Grand Challenge on ENT Endoscopy Analysis](https://arxiv.org/abs/2508.04801)
*Trong-Thuan Nguyen,Viet-Tham Huynh,Thao Thi Phuong Dao,Ha Nguyen Thi,Tien To Vu Thuy,Uyen Hanh Tran,Tam V. Nguyen,Thanh Dinh Le,Minh-Triet Tran*

Main category: cs.CV

TL;DR: ENTRep is a new dataset and challenge for analyzing ENT endoscopic images, offering classification and retrieval capabilities in English and Vietnamese to aid clinicians.


<details>
  <summary>Details</summary>
Motivation: Automated analysis of endoscopic imagery in ENT care is underdeveloped due to device/operator variability, subtle findings, and fine-grained distinctions. Clinicians need reliable retrieval of similar cases, visually and textually, which existing benchmarks lack.

Method: The study introduces ENTRep, a dataset for ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis. It includes expert-annotated images with labels for anatomical region and normal/abnormal status, accompanied by dual-language descriptions. Three benchmark tasks are defined, a submission protocol is standardized, and performance is evaluated on public and private test splits.

Result: The paper reports results from top-performing teams and provides an insight discussion on the benchmark tasks, evaluating performance using server-side scoring.

Conclusion: The ENTRep dataset and benchmark tasks address the need for automated analysis of endoscopic imagery in ENT care, enabling fine-grained classification and bilingual retrieval.

Abstract: Automated analysis of endoscopic imagery is a critical yet underdeveloped
component of ENT (ear, nose, and throat) care, hindered by variability in
devices and operators, subtle and localized findings, and fine-grained
distinctions such as laterality and vocal-fold state. In addition to
classification, clinicians require reliable retrieval of similar cases, both
visually and through concise textual descriptions. These capabilities are
rarely supported by existing public benchmarks. To this end, we introduce
ENTRep, the ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis,
which integrates fine-grained anatomical classification with image-to-image and
text-to-image retrieval under bilingual (Vietnamese and English) clinical
supervision. Specifically, the dataset comprises expert-annotated images,
labeled for anatomical region and normal or abnormal status, and accompanied by
dual-language narrative descriptions. In addition, we define three benchmark
tasks, standardize the submission protocol, and evaluate performance on public
and private test splits using server-side scoring. Moreover, we report results
from the top-performing teams and provide an insight discussion.

</details>


### [3] [CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework](https://arxiv.org/abs/2508.04816)
*Sriram Mandalika,Lalitha V*

Main category: cs.CV

TL;DR: CoMAD是一个轻量级框架，通过非对称掩码和共识门控融合了MAE、MoCo v3和iBOT三个预训练ViT的知识，实现了紧凑型自监督学习模型的性能提升，在ImageNet-1K、ADE20K和MS-COCO上均达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有自监督学习方法（如对比学习和掩码图像建模）在独立预训练、忽略互补信息以及模型庞大不适合资源受限部署的挑战，提出了一种名为CoMAD的轻量级、无参数框架，旨在将多个先进的自监督Vision Transformer的知识融合到一个紧凑的学生网络中。

Method: CoMAD框架采用非对称掩码策略，让学生网络仅接收25%的可见图像块，同时让三个不同的预训练ViT-Base教师（MAE、MoCo v3、iBOT）接收不同程度的掩码。通过线性适配器和层归一化将教师嵌入对齐到学生空间，并利用结合了余弦亲和度和教师间一致性的联合共识门控机制来融合特征。学生网络通过对可见令牌和重构特征图施加双层KL散度进行训练，以同时捕捉局部和全局结构。

Result: CoMAD框架成功地将三个先进的自监督Vision Transformer（MAE, MoCo v3, iBOT）的知识融合到一个紧凑的学生网络中。在ImageNet-1K数据集上，CoMAD的学生网络（ViT-Tiny）取得了75.4%的Top-1准确率，比之前的最先进技术提高了0.4%。在ADE20K数据集上，该模型在密集预测任务中达到了47.3%的mIoU；在MS-COCO数据集上，达到了44.5%的框平均精度和40.5%的掩码平均精度。

Conclusion: CoMAD在ImageNet-1K上实现了75.4%的Top-1准确率，优于现有技术，并在ADE20K和MS-COCO等密集预测任务上取得了领先的性能，成为紧凑型自监督学习蒸馏领域的最新标杆。

Abstract: Numerous self-supervised learning paradigms, such as contrastive learning and
masked image modeling, learn powerful representations from unlabeled data but
are typically pretrained in isolation, overlooking complementary insights and
yielding large models that are impractical for resource-constrained deployment.
To overcome these challenges, we introduce Consensus-oriented Masked
Distillation (CoMAD), a lightweight, parameter-free framework that unifies
knowledge from multiple current state-of-the-art self-supervised Vision
Transformers into a compact student network. CoMAD distills from three
pretrained ViT-Base teachers, MAE, MoCo v3, and iBOT, each offering distinct
semantic and contextual priors. Rather than naively averaging teacher outputs,
we apply asymmetric masking: the student sees only 25 percent of patches while
each teacher receives a progressively lighter, unique mask, forcing the student
to interpolate missing features under richer contexts. Teacher embeddings are
aligned to the student's space via a linear adapter and layer normalization,
then fused through our joint consensus gating, which weights each token by
combining cosine affinity with inter-teacher agreement. The student is trained
with dual-level KL divergence on visible tokens and reconstructed feature maps,
capturing both local and global structure. On ImageNet-1K, CoMAD's ViT-Tiny
achieves 75.4 percent Top-1, an increment of 0.4 percent over the previous
state-of-the-art. In dense-prediction transfers, it attains 47.3 percent mIoU
on ADE20K, and 44.5 percent box average precision and 40.5 percent mask average
precision on MS-COCO, establishing a new state-of-the-art in compact SSL
distillation.

</details>


### [4] [Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models](https://arxiv.org/abs/2508.04818)
*Mehrdad Moradi,Marco Grasso,Bianca Maria Colosimo,Kamran Paynabar*

Main category: cs.CV

TL;DR: RADAR是一种无需重建的实时异常检测方法，它直接生成异常图，解决了现有方法的局限性，并在MVTec-AD和3D打印材料数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的异常检测方法（通常基于重建）存在计算成本高、在复杂模式下可能无法准确重建以及难以选择合适的中间噪声水平等问题，这限制了它们在实际应用中的使用。

Method: RADAR（Reconstruction-free Anomaly Detection with Attention-based diffusion models in Real-time）是一种新的扩散模型，它直接从模型生成异常图，而不是重建输入图像，从而解决了现有重建方法的三个主要挑战（计算成本高、重建复杂或细微模式的能力有限、选择中间噪声水平具有挑战性）。

Result: RADAR在MVTec-AD数据集和3D打印材料数据集上的表现优于最先进的方法，在准确率、精确率、召回率和F1分数等关键指标上均表现出色。

Conclusion: RADAR的表现优于最先进的基于扩散和统计机器学习的模型，在MVTec-AD数据集和3D打印材料数据集上的F1分数分别提高了7%和13%。

Abstract: Generative models have demonstrated significant success in anomaly detection
and segmentation over the past decade. Recently, diffusion models have emerged
as a powerful alternative, outperforming previous approaches such as GANs and
VAEs. In typical diffusion-based anomaly detection, a model is trained on
normal data, and during inference, anomalous images are perturbed to a
predefined intermediate step in the forward diffusion process. The
corresponding normal image is then reconstructed through iterative reverse
sampling.
  However, reconstruction-based approaches present three major challenges: (1)
the reconstruction process is computationally expensive due to multiple
sampling steps, making real-time applications impractical; (2) for complex or
subtle patterns, the reconstructed image may correspond to a different normal
pattern rather than the original input; and (3) Choosing an appropriate
intermediate noise level is challenging because it is application-dependent and
often assumes prior knowledge of anomalies, an assumption that does not hold in
unsupervised settings.
  We introduce Reconstruction-free Anomaly Detection with Attention-based
diffusion models in Real-time (RADAR), which overcomes the limitations of
reconstruction-based anomaly detection. Unlike current SOTA methods that
reconstruct the input image, RADAR directly produces anomaly maps from the
diffusion model, improving both detection accuracy and computational
efficiency. We evaluate RADAR on real-world 3D-printed material and the
MVTec-AD dataset. Our approach surpasses state-of-the-art diffusion-based and
statistical machine learning models across all key metrics, including accuracy,
precision, recall, and F1 score. Specifically, RADAR improves F1 score by 7% on
MVTec-AD and 13% on the 3D-printed material dataset compared to the next best
model.
  Code available at: https://github.com/mehrdadmoradi124/RADAR

</details>


### [5] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
*Chirag Seth,Divya Naiken,Keyan Lin*

Main category: cs.CV

TL;DR: 本研究提出了一种经济高效的眼动追踪算法，使用事件相机和CNN_LSTM模型，准确率达81%，旨在提升VR/AR用户体验。


<details>
  <summary>Details</summary>
Motivation: 精确的眼动追踪在消费电子（尤其VR/AR产品开发）中有广泛应用，但现有方法依赖昂贵的高速相机。本研究旨在开发一种经济高效且可解释的算法来解决此挑战，以提高设备舒适度和用户体验。

Method: 利用事件相机输入，通过CNN_LSTM深度学习模型进行眼动追踪，定位眼中心（x, y），并预测人类注意力。

Result: CNN_LSTM模型在眼动追踪任务中达到了约81%的准确率。

Conclusion: 为提高设备舒适度和整体用户体验，研究提出了一种基于事件相机和深度学习（特别是CNN_LSTM模型）的眼动追踪算法，旨在预测人类注意力。该模型达到了约81%的准确率，并提出未来工作将利用LRP技术进一步提高模型的可解释性和预测性能。

Abstract: This research project addresses the challenge of accurately tracking eye
movements during specific events by leveraging previous research. Given the
rapid movements of human eyes, which can reach speeds of 300{\deg}/s, precise
eye tracking typically requires expensive and high-speed cameras. Our primary
objective is to locate the eye center position (x, y) using inputs from an
event camera. Eye movement analysis has extensive applications in consumer
electronics, especially in VR and AR product development. Therefore, our
ultimate goal is to develop an interpretable and cost-effective algorithm using
deep learning methods to predict human attention, thereby improving device
comfort and enhancing overall user experience. To achieve this goal, we
explored various approaches, with the CNN\_LSTM model proving most effective,
achieving approximately 81\% accuracy. Additionally, we propose future work
focusing on Layer-wise Relevance Propagation (LRP) to further enhance the
model's interpretability and predictive performance.

</details>


### [6] [LuKAN: A Kolmogorov-Arnold Network Framework for 3D Human Motion Prediction](https://arxiv.org/abs/2508.04847)
*Md Zahidul Hasan,A. Ben Hamza,Nizar Bouguila*

Main category: cs.CV

TL;DR: LuKAN是一种基于 Kolmogorov-Arnold Networks (KAN) 和 Lucas 多项式激活函数的三维人体运动预测模型。它通过离散小波变换、空间投影层和时间依赖性学习器来有效编码时间信息、捕捉关节依赖关系并进行函数逼近，从而实现高精度和高计算效率的运动预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测准确性和计算效率之间取得平衡时面临局限性。

Method: LuKAN模型首先应用离散小波变换来编码输入运动序列中的时间信息，然后使用空间投影层来捕捉关节间的依赖关系，以确保人体结构的一致性。LuKAN的核心是时间依赖性学习器，它采用由 Lucas 多项式参数化的 KAN 层进行有效的函数逼近。最后，逆离散小波变换在时域中重建运动序列，从而生成时间上连贯的预测。

Result: LuKAN模型在三个基准数据集上进行了广泛的实验，结果表明与强大的基线相比，LuKAN在定量和定性评估方面均表现出竞争力。

Conclusion: LuKAN模型在三个基准数据集上的广泛实验证明，与强大的基线相比，它在定量和定性评估中都具有竞争力。此外，其紧凑的架构和 Lucas 多项式的线性递归确保了计算效率。

Abstract: The goal of 3D human motion prediction is to forecast future 3D poses of the
human body based on historical motion data. Existing methods often face
limitations in achieving a balance between prediction accuracy and
computational efficiency. In this paper, we present LuKAN, an effective model
based on Kolmogorov-Arnold Networks (KANs) with Lucas polynomial activations.
Our model first applies the discrete wavelet transform to encode temporal
information in the input motion sequence. Then, a spatial projection layer is
used to capture inter-joint dependencies, ensuring structural consistency of
the human body. At the core of LuKAN is the Temporal Dependency Learner, which
employs a KAN layer parameterized by Lucas polynomials for efficient function
approximation. These polynomials provide computational efficiency and an
enhanced capability to handle oscillatory behaviors. Finally, the inverse
discrete wavelet transform reconstructs motion sequences in the time domain,
generating temporally coherent predictions. Extensive experiments on three
benchmark datasets demonstrate the competitive performance of our model
compared to strong baselines, as evidenced by both quantitative and qualitative
evaluations. Moreover, its compact architecture coupled with the linear
recurrence of Lucas polynomials, ensures computational efficiency.

</details>


### [7] [VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence](https://arxiv.org/abs/2508.04852)
*Chenhui Qiang,Zhaoyang Wei,Xumeng Han Zipeng Wang,Siyao Li,Xiangyuan Lan,Jianbin Jiao,Zhenjun Han*

Main category: cs.CV

TL;DR: VER-Bench 是一个评估 MLLMs 细粒度视觉理解和推理能力的新框架，包含 374 个问题，侧重于占图像面积很小的细微视觉线索，并揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前的基准测试主要分为两类：基础感知基准测试（侧重于局部细节但缺乏深度推理）和主流推理基准测试（侧重于突出的图像元素但可能无法评估需要复杂分析的细微线索）。然而，深刻的视觉理解和复杂的推理更多地依赖于解释细微、不显眼的局部细节，而不是感知显著的、宏观的物体。这些细节虽然占据的图像区域很小，但通常包含更丰富、更关键的信息，以支持鲁棒的分析。为了弥补这一差距，我们引入了 VER-Bench。

Method: VER-Bench 是一个新颖的框架，用于评估 MLLMs 的能力：1) 识别细粒度视觉线索（平均仅占图像区域的 0.25%）；2) 将这些线索与世界知识相结合进行复杂推理。VER-Bench 包含 374 个精心设计的问题，涵盖地理空间、时间、情境、意图、系统状态和符号推理。

Result: VER-Bench 包含 374 个精心设计的问题，每个问题都附有结构化证据：视觉线索和从中推导出的与问题相关的推理。VER-Bench 揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性。

Conclusion: VER-Bench 揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性，突出了增强模型在细粒度视觉证据提取、整合和推理方面的能力，以实现真正的视觉理解和类似人类的分析的必要性。

Abstract: With the rapid development of MLLMs, evaluating their visual capabilities has
become increasingly crucial. Current benchmarks primarily fall into two main
types: basic perception benchmarks, which focus on local details but lack deep
reasoning (e.g., "what is in the image?"), and mainstream reasoning benchmarks,
which concentrate on prominent image elements but may fail to assess subtle
clues requiring intricate analysis. However, profound visual understanding and
complex reasoning depend more on interpreting subtle, inconspicuous local
details than on perceiving salient, macro-level objects. These details, though
occupying minimal image area, often contain richer, more critical information
for robust analysis. To bridge this gap, we introduce the VER-Bench, a novel
framework to evaluate MLLMs' ability to: 1) identify fine-grained visual clues,
often occupying on average just 0.25% of the image area; 2) integrate these
clues with world knowledge for complex reasoning. Comprising 374 carefully
designed questions across Geospatial, Temporal, Situational, Intent, System
State, and Symbolic reasoning, each question in VER-Bench is accompanied by
structured evidence: visual clues and question-related reasoning derived from
them. VER-Bench reveals current models' limitations in extracting subtle visual
evidence and constructing evidence-based arguments, highlighting the need to
enhance models's capabilities in fine-grained visual evidence extraction,
integration, and reasoning for genuine visual understanding and human-like
analysis. Dataset and additional materials are available
https://github.com/verbta/ACMMM-25-Materials.

</details>


### [8] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: HOW-Seg是首个用于开放世界点云语义分割的人机交互框架。它通过直接在查询数据上构建原型并利用稀疏的人工标注来解决现有方法的局限性。该方法通过原型去模糊化和CRF优化，能够处理新类别的分割，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的开放世界点云语义分割方法要么依赖资源密集型的离线增量学习，要么需要密集的标注数据，这限制了它们的实用性。为了解决这些问题，需要一种更轻量级、更灵活的方法。

Method: HOW-Seg框架，首先在查询数据上直接构建类别原型，然后利用稀疏的人工标注进行引导，实现基于原型的分割。该框架还引入了分层原型去模糊化机制来优化原型，并使用条件随机场（CRF）进行后处理，通过迭代的人工反馈动态改进预测。

Result: HOW-Seg在稀疏标注（例如，单次点击标注一个新类别）的情况下，性能与最先进的GFS-Seg方法（5-shot设置）相当或更优。在使用更先进的骨干网络（例如，Stratified Transformer）和更密集的标注（例如，每个子场景10次点击）时，HOW-Seg在S3DIS上达到了85.27%的mIoU，在ScanNetv2上达到了66.37%的mIoU，显著优于其他方法。

Conclusion: HOW-Seg通过使用稀疏的人工标注，在S3DIS和ScanNetv2数据集上实现了先进的性能，证明了其在开放世界点云语义分割方面的有效性和实用性。

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


### [9] [Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications](https://arxiv.org/abs/2508.04868)
*Noreen Anwar,Guillaume-Alexandre Bilodeau,Wassim Bouachir*

Main category: cs.CV

TL;DR: DAMM是一个新颖的Transformer-based object detector框架，通过多模态查询（外观、位置、随机）和双流交叉注意力机制，解决了现有模型的遮挡、定位精度和计算效率问题，并在多个基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Transformer-based object detectors 在遮挡、细粒度定位和固定查询及密集注意力引起的计算效率低下方面存在不足。

Method: DAMM框架引入了查询适应和结构化交叉注意力机制，包含三种查询：来自视觉-语言模型的基于外观的查询、使用多边形嵌入的位置查询以及用于一般场景覆盖的随机学习查询。此外，双流交叉注意力模块分别优化语义和空间特征。

Result: DAMM在四个具有挑战性的基准测试中取得了最先进的性能，在平均精度（AP）和召回率方面均表现出色。

Conclusion: DAMM在四个具有挑战性的基准测试中取得了最先进的性能，在平均精度（AP）和召回率方面均表现出色，证明了多模态查询适应和双流注意力的有效性。

Abstract: Transformer-based object detectors often struggle with occlusions,
fine-grained localization, and computational inefficiency caused by fixed
queries and dense attention. We propose DAMM, Dual-stream Attention with
Multi-Modal queries, a novel framework introducing both query adaptation and
structured cross-attention for improved accuracy and efficiency. DAMM
capitalizes on three types of queries: appearance-based queries from
vision-language models, positional queries using polygonal embeddings, and
random learned queries for general scene coverage. Furthermore, a dual-stream
cross-attention module separately refines semantic and spatial features,
boosting localization precision in cluttered scenes. We evaluated DAMM on four
challenging benchmarks, and it achieved state-of-the-art performance in average
precision (AP) and recall, demonstrating the effectiveness of multi-modal query
adaptation and dual-stream attention. Source code is at:
\href{https://github.com/DET-LIP/DAMM}{GitHub}.

</details>


### [10] [Revealing Temporal Label Noise in Multimodal Hateful Video Classification](https://arxiv.org/abs/2508.04900)
*Shuonan Yang,Tailin Chen,Rahul Singh,Jiangbei Yue,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 该研究通过细粒度方法分析了视频级标签噪声对多模态仇恨视频检测的影响。通过使用时间戳修剪仇恨视频，研究发现噪声会影响模型性能，并强调了时间感知模型和数据集的重要性。


<details>
  <summary>Details</summary>
Motivation: 在线多媒体内容的快速传播加剧了仇恨言论的传播，带来了严峻的社会和监管挑战。尽管最近的工作在多模态仇恨视频检测方面取得了进展，但大多数方法依赖于粗粒度的、视频级别的注释，而忽略了仇恨内容的 Temporal 粒度。这会引入大量的标签噪声，因为被标记为仇恨的视频通常包含长的不含仇恨的片段。

Method: 本研究采用一种细粒度的方法，通过使用带注释的时间戳来修剪来自HateMM和MultiHateClip英语数据集的仇恨视频，以分离明确的仇恨片段。然后，对这些修剪后的片段进行探索性分析，以检查仇恨和非仇恨内容的分布和特征。

Result: 这项分析突显了由粗粒度的、视频级别的注释所引入的语义重叠和混淆程度。受控实验证明，时间戳噪声会从根本上改变模型的决策边界并削弱分类置信度，这凸显了仇恨言论表达中固有的上下文依赖性和时间连续性。

Conclusion: 时间戳噪声会从根本上改变模型的决策边界并削弱分类置信度，这凸显了仇恨言论表达中固有的上下文依赖性和时间连续性。我们的研究结果提供了对多模态仇恨视频的时间动态的新见解，并强调了对时间感知模型和基准的需求，以提高鲁棒性和可解释性。

Abstract: The rapid proliferation of online multimedia content has intensified the
spread of hate speech, presenting critical societal and regulatory challenges.
While recent work has advanced multimodal hateful video detection, most
approaches rely on coarse, video-level annotations that overlook the temporal
granularity of hateful content. This introduces substantial label noise, as
videos annotated as hateful often contain long non-hateful segments. In this
paper, we investigate the impact of such label ambiguity through a fine-grained
approach. Specifically, we trim hateful videos from the HateMM and
MultiHateClip English datasets using annotated timestamps to isolate explicitly
hateful segments. We then conduct an exploratory analysis of these trimmed
segments to examine the distribution and characteristics of both hateful and
non-hateful content. This analysis highlights the degree of semantic overlap
and the confusion introduced by coarse, video-level annotations. Finally,
controlled experiments demonstrated that time-stamp noise fundamentally alters
model decision boundaries and weakens classification confidence, highlighting
the inherent context dependency and temporal continuity of hate speech
expression. Our findings provide new insights into the temporal dynamics of
multimodal hateful videos and highlight the need for temporally aware models
and benchmarks for improved robustness and interpretability. Code and data are
available at
https://github.com/Multimodal-Intelligence-Lab-MIL/HatefulVideoLabelNoise.

</details>


### [11] [Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations](https://arxiv.org/abs/2508.04924)
*Zahidul Islam,Sujoy Paul,Mrigank Rochan*

Main category: cs.CV

TL;DR: 本研究提出Highlight-TTA框架，通过在测试时自适应模型来解决视频精彩片段检测的泛化能力问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频精彩片段检测方法泛化能力不足，无法适应所有测试视频的独特特征和变化，导致性能下降。

Method: Highlight-TTA是一个在测试时进行自适应的框架，通过一个辅助任务——跨模态幻觉——与主要的精彩片段检测任务联合优化，并采用元辅助训练方案进行有效自适应和任务增强。

Result: 在三个基准数据集上进行的广泛实验表明，将Highlight-TTA集成到三个最先进的精彩片段检测模型中，可以提升它们的性能，并取得更优越的结果。

Conclusion: Highlight-TTA框架通过在测试时动态调整模型以适应每个测试视频的特定特征，提高了视频精彩片段检测的泛化能力和性能。

Abstract: Existing video highlight detection methods, although advanced, struggle to
generalize well to all test videos. These methods typically employ a generic
highlight detection model for each test video, which is suboptimal as it fails
to account for the unique characteristics and variations of individual test
videos. Such fixed models do not adapt to the diverse content, styles, or audio
and visual qualities present in new, unseen test videos, leading to reduced
highlight detection performance. In this paper, we propose Highlight-TTA, a
test-time adaptation framework for video highlight detection that addresses
this limitation by dynamically adapting the model during testing to better
align with the specific characteristics of each test video, thereby improving
generalization and highlight detection performance. Highlight-TTA is jointly
optimized with an auxiliary task, cross-modality hallucinations, alongside the
primary highlight detection task. We utilize a meta-auxiliary training scheme
to enable effective adaptation through the auxiliary task while enhancing the
primary task. During testing, we adapt the trained model using the auxiliary
task on the test video to further enhance its highlight detection performance.
Extensive experiments with three state-of-the-art highlight detection models
and three benchmark datasets show that the introduction of Highlight-TTA to
these models improves their performance, yielding superior results.

</details>


### [12] [Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens](https://arxiv.org/abs/2508.04928)
*Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong*

Main category: cs.CV

TL;DR: A new method uses "Calibration Tokens" to adapt pre-trained depth estimation models to work with fisheye cameras by aligning image features, without needing new training data or retraining the models.


<details>
  <summary>Details</summary>
Motivation: Foundational monocular depth estimators (FMDEs) trained on perspective images are susceptible to errors when applied to fisheye images due to covariate shift caused by changes in camera calibration parameters. The goal is to enable the use of these pre-trained FMDEs for fisheye cameras without the need for retraining or finetuning.

Method: The method introduces "Calibration Tokens" as a light-weight adaptation mechanism to modulate latent embeddings for alignment. It is self-supervised, requiring only publicly available large-scale perspective image datasets. The training process involves recalibrating perspective images to fisheye images and enforcing consistency between their depth estimates.

Result: The approach consistently improves depth estimation accuracy compared to state-of-the-art methods on both indoor and outdoor datasets, using a single set of calibration tokens for both scenarios. The method leverages the expressive latent space of FMDEs and avoids artifacts associated with image space recalibration or projection.

Conclusion: The proposed method effectively extends foundational monocular depth estimators (FMDEs) to fisheye images by aligning latent embeddings of fisheye images to those of perspective images using calibration tokens. This approach allows the reuse of FMDEs without retraining or finetuning, outperforming state-of-the-art methods on both indoor and outdoor datasets.

Abstract: We propose a method to extend foundational monocular depth estimators
(FMDEs), trained on perspective images, to fisheye images. Despite being
trained on tens of millions of images, FMDEs are susceptible to the covariate
shift introduced by changes in camera calibration (intrinsic, distortion)
parameters, leading to erroneous depth estimates. Our method aligns the
distribution of latent embeddings encoding fisheye images to those of
perspective images, enabling the reuse of FMDEs for fisheye cameras without
retraining or finetuning. To this end, we introduce a set of Calibration Tokens
as a light-weight adaptation mechanism that modulates the latent embeddings for
alignment. By exploiting the already expressive latent space of FMDEs, we posit
that modulating their embeddings avoids the negative impact of artifacts and
loss introduced in conventional recalibration or map projection to a canonical
reference frame in the image space. Our method is self-supervised and does not
require fisheye images but leverages publicly available large-scale perspective
image datasets. This is done by recalibrating perspective images to fisheye
images, and enforcing consistency between their estimates during training. We
evaluate our approach with several FMDEs, on both indoors and outdoors, where
we consistently improve over state-of-the-art methods using a single set of
tokens for both. Code available at:
https://github.com/JungHeeKim29/calibration-token.

</details>


### [13] [Toward Errorless Training ImageNet-1k](https://arxiv.org/abs/2508.04941)
*Bo Deng,Levi Heath*

Main category: cs.CV

TL;DR: 本文介绍了一种前馈人工神经网络，在ImageNet 2012数据集上训练，达到了98.3%的准确率，但由于双标签问题，未能达到100%的准确率。


<details>
  <summary>Details</summary>
Motivation: 作者旨在训练一个前馈人工神经网络，以达到很高的准确率。

Method: 使用[5]中的新方法和在ImageNet 2012竞赛数据集上训练的前馈人工神经网络。

Result: 模型达到了98.3%的准确率，99.69%的Top-1率，并且在10个批处理分区的1000个样本中平均正确分类了285.9个标签。表现最佳的模型拥有322,430,160个参数，并使用了4位小数的精度。

Conclusion: 目前尚不清楚模型未能达到100%准确率的原因，但我们推测这可能是由于数据集中存在带有不同标签的重复图像的双标签问题。

Abstract: In this paper, we describe a feedforward artificial neural network trained on
the ImageNet 2012 contest dataset [7] with the new method of [5] to an accuracy
rate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are
perfectly classified over the 10 batch partitions of the dataset. The best
performing model uses 322,430,160 parameters, with 4 decimal places precision.
We conjecture that the reason our model does not achieve a 100% accuracy rate
is due to a double-labeling problem, by which there are duplicate images in the
dataset with different labels.

</details>


### [14] [Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models](https://arxiv.org/abs/2508.04942)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: 提出 ProMIM 框架，通过结合掩码图像建模（MIM）和提示学习，提升视觉-语言模型的泛化能力，解决过拟合问题，实现高效适应新任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）虽然在零样本学习方面表现出色，但适应新任务需要高昂的训练成本；而提示学习技术（如 CoOp、CoCoOp）虽然高效，但容易过拟合已知类别，限制了对未见类别的泛化能力。本研究旨在提出一种能够提高模型泛化能力并减少过拟合的解决方案。

Method: ProMIM 框架采用一种有效的掩码策略，仅掩码可见图像块，并利用这些表示来指导生成实例条件提示，从而增强条件提示学习。

Result: ProMIM 框架在零样本和少样本分类任务的广泛实验中，证明了其在即插即用时能持续提升现有方法的泛化性能，为实际视觉-语言应用提供了轻量级解决方案。

Conclusion: ProMIM 框架通过整合掩码图像建模（MIM）到现有的视觉-语言模型（VLMs）和提示学习方法（如 CoOp、CoCoOp）中，提高了模型的泛化能力，有效解决了现有方法在适应新任务时易过拟合已知类别的问题，同时保持了较低的计算成本。

Abstract: Vision-language models (VLMs) like CLIP excel in zero-shot learning but often
require resource-intensive training to adapt to new tasks. Prompt learning
techniques, such as CoOp and CoCoOp, offer efficient adaptation but tend to
overfit to known classes, limiting generalization to unseen categories. We
introduce ProMIM, a plug-and-play framework that enhances conditional prompt
learning by integrating masked image modeling (MIM) into existing VLM
pipelines. ProMIM leverages a simple yet effective masking strategy to generate
robust, instance-conditioned prompts, seamlessly augmenting methods like CoOp
and CoCoOp without altering their core architectures. By masking only visible
image patches and using these representations to guide prompt generation,
ProMIM improves feature robustness and mitigates overfitting, all while
introducing negligible additional computational cost. Extensive experiments
across zero-shot and few-shot classification tasks demonstrate that ProMIM
consistently boosts generalization performance when plugged into existing
approaches, providing a practical, lightweight solution for real-world
vision-language applications.

</details>


### [15] [TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring](https://arxiv.org/abs/2508.04943)
*Zhu Xu,Ting Lei,Zhimin Li,Guan Wang,Qingchao Chen,Yuxin Peng,Yang liu*

Main category: cs.CV

TL;DR: TRKT是一种用于弱监督动态场景图生成的新方法，通过挖掘关系感知和运动感知的知识，并利用双流融合模块增强物体检测，从而提高了检测精度和置信度，并在Action Genome数据集上取得了优异结果。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督动态场景图生成（WS-DSGG）方法依赖于外部物体检测器来生成伪标签，但这些检测器在动态、关系感知的场景下表现不佳，导致定位不准确和低置信度。为了解决这个问题，提出TRKT方法来增强关系感知动态场景下的检测能力。

Method: TRKT方法包含两个关键组件：(1) 关系感知知识挖掘，包括使用物体和关系类别解码器生成类别特定的注意力图，并利用相邻帧的光流信息进行帧间注意力增强，以生成关系感知和运动感知的知识。(2) 双流融合模块，将类别特定的注意力图融入外部检测结果，以优化物体定位和提高物体提议的置信度。

Result: TRKT方法通过关系感知知识挖掘和双流融合模块，成功解决了外部物体检测器在WS-DSGG中的挑战，并在Action Genome数据集上实现了最先进的性能。

Conclusion: TRKT方法在Action Genome数据集上取得了最先进的性能。

Abstract: Dynamic Scene Graph Generation (DSGG) aims to create a scene graph for each
video frame by detecting objects and predicting their relationships. Weakly
Supervised DSGG (WS-DSGG) reduces annotation workload by using an unlocalized
scene graph from a single frame per video for training. Existing WS-DSGG
methods depend on an off-the-shelf external object detector to generate pseudo
labels for subsequent DSGG training. However, detectors trained on static,
object-centric images struggle in dynamic, relation-aware scenarios required
for DSGG, leading to inaccurate localization and low-confidence proposals. To
address the challenges posed by external object detectors in WS-DSGG, we
propose a Temporal-enhanced Relation-aware Knowledge Transferring (TRKT)
method, which leverages knowledge to enhance detection in relation-aware
dynamic scenarios. TRKT is built on two key components:(1)Relation-aware
knowledge mining: we first employ object and relation class decoders that
generate category-specific attention maps to highlight both object regions and
interactive areas. Then we propose an Inter-frame Attention Augmentation
strategy that exploits optical flow for neighboring frames to enhance the
attention maps, making them motion-aware and robust to motion blur. This step
yields relation- and motion-aware knowledge mining for WS-DSGG. (2) we
introduce a Dual-stream Fusion Module that integrates category-specific
attention maps into external detections to refine object localization and boost
confidence scores for object proposals. Extensive experiments demonstrate that
TRKT achieves state-of-the-art performance on Action Genome dataset. Our code
is avaliable at https://github.com/XZPKU/TRKT.git.

</details>


### [16] [AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics](https://arxiv.org/abs/2508.04955)
*Stella Su,Marc Harary,Scott J. Rodig,William Lotter*

Main category: cs.CV

TL;DR: AdvDINO是一种用于解决医学成像中域偏移问题的自监督学习框架，能学习到更鲁棒的特征并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 在医学成像领域，由于批次效应等因素导致的域偏移会模糊真实的生物信号，而标准自监督学习方法对此类问题的鲁棒性尚不明确。

Method: 提出了一种名为AdvDINO的领域对抗性自监督学习框架，通过在DINOv2架构中集成梯度反转层，促进领域不变特征的学习。

Result: AdvDINO在六通道多重免疫荧光（mIF）全切片图像上表现优于非对抗性基线方法，能够识别具有不同蛋白质组特征和预后意义的表型簇，并提高了生存预测的准确性。

Conclusion: AdvDINO通过集成梯度反转层到DINOv2架构中，成功缓解了医学成像（特别是多重免疫荧光）中的批次效应，学习到了更鲁棒且具有生物学意义的表征。该方法在超过546万个图像块上验证了其有效性，能够识别具有不同蛋白质组特征和预后意义的表型簇，并提高了生存预测的准确性。

Abstract: Self-supervised learning (SSL) has emerged as a powerful approach for
learning visual representations without manual annotations. However, the
robustness of standard SSL methods to domain shift -- systematic differences
across data sources -- remains uncertain, posing an especially critical
challenge in biomedical imaging where batch effects can obscure true biological
signals. We present AdvDINO, a domain-adversarial self-supervised learning
framework that integrates a gradient reversal layer into the DINOv2
architecture to promote domain-invariant feature learning. Applied to a
real-world cohort of six-channel multiplex immunofluorescence (mIF) whole slide
images from non-small cell lung cancer patients, AdvDINO mitigates
slide-specific biases to learn more robust and biologically meaningful
representations than non-adversarial baselines. Across $>5.46$ million mIF
image tiles, the model uncovers phenotype clusters with distinct proteomic
profiles and prognostic significance, and improves survival prediction in
attention-based multiple instance learning. While demonstrated on mIF data,
AdvDINO is broadly applicable to other imaging domains -- including radiology,
remote sensing, and autonomous driving -- where domain shift and limited
annotated data hinder model generalization and interpretability.

</details>


### [17] [F2PASeg: Feature Fusion for Pituitary Anatomy Segmentation in Endoscopic Surgery](https://arxiv.org/abs/2508.05465)
*Lumin Chen,Zhiying Wu,Tianye Lei,Xuexue Bai,Ming Feng,Yuxi Wang,Gaofeng Meng,Zhen Lei,Hongbin Liu*

Main category: cs.CV

TL;DR: 该研究提出了 F2PASeg，一个用于吡啶手术解剖结构分割的新数据集（PAS）和一种新方法，解决了数据稀缺和术中变化的问题，提高了分割的准确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 为了解决吡啶手术中解剖结构分割的挑战，特别是由于数据稀缺和术中变化（如遮挡、相机移动和手术出血）导致的特征表示不一致问题。

Method: 提出了一种名为 F2PASeg 的新方法，通过结合高分辨率图像特征和深度语义嵌入来改进解剖结构分割，以应对术中变化。

Result: 实验结果表明，F2PASeg 能够实时分割关键解剖结构，增强了手术规划的可靠性。

Conclusion: F2PASeg 能够实时分割关键解剖结构，为术中吡啶手术规划提供可靠解决方案。

Abstract: Pituitary tumors often cause deformation or encapsulation of adjacent vital
structures. Anatomical structure segmentation can provide surgeons with early
warnings of regions that pose surgical risks, thereby enhancing the safety of
pituitary surgery. However, pixel-level annotated video stream datasets for
pituitary surgeries are extremely rare. To address this challenge, we introduce
a new dataset for Pituitary Anatomy Segmentation (PAS). PAS comprises 7,845
time-coherent images extracted from 120 videos. To mitigate class imbalance, we
apply data augmentation techniques that simulate the presence of surgical
instruments in the training data. One major challenge in pituitary anatomy
segmentation is the inconsistency in feature representation due to occlusions,
camera motion, and surgical bleeding. By incorporating a Feature Fusion module,
F2PASeg is proposed to refine anatomical structure segmentation by leveraging
both high-resolution image features and deep semantic embeddings, enhancing
robustness against intraoperative variations. Experimental results demonstrate
that F2PASeg consistently segments critical anatomical structures in real time,
providing a reliable solution for intraoperative pituitary surgery planning.
Code: https://github.com/paulili08/F2PASeg.

</details>


### [18] [UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS](https://arxiv.org/abs/2508.04968)
*Zhihao Guo,Peng Wang,Zidong Chen,Xiangyu Kong,Yan Lyu,Guanyu Gao,Liangxiu Han*

Main category: cs.CV

TL;DR: 透過學習到的不確定性來對 3D 高斯進行自適應加權，以提高稀疏視圖下的渲染質量並防止過擬合。


<details>
  <summary>Details</summary>
Motivation: 解決現有 3DGS 方法在稀疏視圖場景中容易過擬合的問題，通過讓 Gaussian 加權適應性學習來提高渲染質量。

Method: 通過學習不確定性來實現 Gaussian 的自適應加權，該不確定性指導 Gaussian 不透明度的可微分更新，並通過軟性可微分 dropout 正則化來實現渲染。

Result: 與現有的稀疏視圖方法（例如 DropGaussian）相比，所提出的方法在 MipNeRF 360 數據集上實現了 3.27% 的 PSNR 增強，並且在大多數數據集上需要更少的 Gaussian。

Conclusion: 所提出的方法在稀疏視圖 3D 合成方面優於現有方法，在大多數數據集上實現了更高的重建質量和更少的 Gaussian 數量。

Abstract: 3D Gaussian Splatting (3DGS) has become a competitive approach for novel view
synthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian
projection and blending. However, Gaussians are treated equally weighted for
rendering in most 3DGS methods, making them prone to overfitting, which is
particularly the case in sparse-view scenarios. To address this, we investigate
how adaptive weighting of Gaussians affects rendering quality, which is
characterised by learned uncertainties proposed. This learned uncertainty
serves two key purposes: first, it guides the differentiable update of Gaussian
opacity while preserving the 3DGS pipeline integrity; second, the uncertainty
undergoes soft differentiable dropout regularisation, which strategically
transforms the original uncertainty into continuous drop probabilities that
govern the final Gaussian projection and blending process for rendering.
Extensive experimental results over widely adopted datasets demonstrate that
our method outperforms rivals in sparse-view 3D synthesis, achieving higher
quality reconstruction with fewer Gaussians in most datasets compared to
existing sparse-view approaches, e.g., compared to DropGaussian, our method
achieves 3.27\% PSNR improvements on the MipNeRF 360 dataset.

</details>


### [19] [CSRAP: Enhanced Canvas Attention Scheduling for Real-Time Mission Critical Perception](https://arxiv.org/abs/2508.04976)
*Md Iftekharul Islam Sakib,Yigong Hu,Tarek Abdelzaher*

Main category: cs.CV

TL;DR: 该研究提出了一种改进的基于画布的注意力调度方法，通过允许可变尺寸和帧率的画布框架，在边缘设备上实现了更高效、更高精度的实时目标检测。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限的边缘平台上，在严格的延迟约束下执行高分辨率目标检测的核心挑战。

Method: 提出了一种扩展的基于画布的注意力调度机制，允许可变尺寸和可变帧率的画布框架，以在资源受限的边缘平台上实现低延迟、高分辨率的目标检测。

Result: 通过在NVIDIA Jetson Orin Nano上运行YOLOv11，并在Waymo开放数据集上进行评估，结果表明所提出的方法能够实现比现有技术更高的mAP和召回率。

Conclusion: 所提出的可变尺寸和可变帧率画布框架能够改善在边缘平台上的实时物体检测的质量/成本权衡，实现了更高的mAP和召回率。

Abstract: Real-time perception on edge platforms faces a core challenge: executing
high-resolution object detection under stringent latency constraints on limited
computing resources. Canvas-based attention scheduling was proposed in earlier
work as a mechanism to reduce the resource demands of perception subsystems. It
consolidates areas of interest in an input data frame onto a smaller area,
called a canvas frame, that can be processed at the requisite frame rate. This
paper extends prior canvas-based attention scheduling literature by (i)
allowing for variable-size canvas frames and (ii) employing selectable canvas
frame rates that may depart from the original data frame rate. We evaluate our
solution by running YOLOv11, as the perception module, on an NVIDIA Jetson Orin
Nano to inspect video frames from the Waymo Open Dataset. Our results show that
the additional degrees of freedom improve the attainable quality/cost
trade-offs, thereby allowing for a consistently higher mean average precision
(mAP) and recall with respect to the state of the art.

</details>


### [20] [Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression](https://arxiv.org/abs/2508.04979)
*Zheng Chen,Mingde Zhou,Jinpei Guo,Jiale Yuan,Yifei Ji,Yulun Zhang*

Main category: cs.CV

TL;DR: SODEC是一种单步扩散图像压缩模型，通过使用VAE生成信息丰富的潜在表示和引入保真度引导模块，解决了现有扩散模型延迟高和保真度差的问题，并在极低比特率下实现了优越的性能和更快的解码速度。


<details>
  <summary>Details</summary>
Motivation: 解决基于扩散的图像压缩模型存在的两个关键问题：1.由于多步采样导致的过高解码延迟；2.过度依赖生成先验导致的保真度差。

Method: 提出了一种名为SODEC的新型单步扩散图像压缩模型。该模型利用预训练的基于VAE的模型生成信息丰富的潜在表示，并用单步解码取代了迭代去噪过程。为了提高保真度，引入了保真度引导模块。此外，还设计了一种速率退火训练策略。

Result: SODEC显著优于现有方法，在速率-失真-感知性能上表现更佳，并且解码速度比以前的基于扩散的压缩模型提高了20倍以上。

Conclusion: SODEC在极低比特率下实现了优于现有方法的速率-失真-感知性能，解码速度比以前的基于扩散的压缩模型提高了20倍以上。

Abstract: Diffusion-based image compression has demonstrated impressive perceptual
performance. However, it suffers from two critical drawbacks: (1) excessive
decoding latency due to multi-step sampling, and (2) poor fidelity resulting
from over-reliance on generative priors. To address these issues, we propose
SODEC, a novel single-step diffusion image compression model. We argue that in
image compression, a sufficiently informative latent renders multi-step
refinement unnecessary. Based on this insight, we leverage a pre-trained
VAE-based model to produce latents with rich information, and replace the
iterative denoising process with a single-step decoding. Meanwhile, to improve
fidelity, we introduce the fidelity guidance module, encouraging output that is
faithful to the original image. Furthermore, we design the rate annealing
training strategy to enable effective training under extremely low bitrates.
Extensive experiments show that SODEC significantly outperforms existing
methods, achieving superior rate-distortion-perception performance. Moreover,
compared to previous diffusion-based compression models, SODEC improves
decoding speed by more than 20$\times$. Code is released at:
https://github.com/zhengchen1999/SODEC.

</details>


### [21] [Propagating Sparse Depth via Depth Foundation Model for Out-of-Distribution Depth Completion](https://arxiv.org/abs/2508.04984)
*Shenglun Chen,Xinzhu Ma,Hong Zhang,Haojie Li,Zhihui Wang*

Main category: cs.CV

TL;DR: 提出了一种利用深度基础模型的新型深度补全框架，在不依赖大规模训练的情况下，通过双空间传播和可学习校正模块提高了在分布外场景下的鲁棒性，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法依赖于精心准备但有限的数据，导致在分布外（OOD）场景下性能显著下降。近期基础模型在大规模训练中表现出卓越的单目深度估计鲁棒性，利用这些模型增强深度补全模型的鲁棒性是一个有前途的解决方案。

Method: 提出了一种新颖的深度补全框架，该框架利用深度基础模型来实现卓越的鲁棒性，而无需大规模训练。具体来说，利用深度基础模型从RGB图像中提取环境线索（包括结构和语义上下文），以指导稀疏深度信息向缺失区域传播。设计了一种不含任何可学习参数的双空间传播方法，在三维和二维空间中有效地传播稀疏深度，以保持几何结构和局部一致性。引入了一个可学习的校正模块，以逐步调整深度预测以逼近真实深度。

Result: 在NYUv2和KITTI数据集上进行训练，并在16个其他数据集上进行了广泛评估，框架在分布外场景下表现出色，并且优于现有的最先进的深度补全方法。

Conclusion: 该框架在分布外（OOD）场景下表现出色，并且优于现有的最先进的深度补全方法。

Abstract: Depth completion is a pivotal challenge in computer vision, aiming at
reconstructing the dense depth map from a sparse one, typically with a paired
RGB image. Existing learning based models rely on carefully prepared but
limited data, leading to significant performance degradation in
out-of-distribution (OOD) scenarios. Recent foundation models have demonstrated
exceptional robustness in monocular depth estimation through large-scale
training, and using such models to enhance the robustness of depth completion
models is a promising solution. In this work, we propose a novel depth
completion framework that leverages depth foundation models to attain
remarkable robustness without large-scale training. Specifically, we leverage a
depth foundation model to extract environmental cues, including structural and
semantic context, from RGB images to guide the propagation of sparse depth
information into missing regions. We further design a dual-space propagation
approach, without any learnable parameters, to effectively propagates sparse
depth in both 3D and 2D spaces to maintain geometric structure and local
consistency. To refine the intricate structure, we introduce a learnable
correction module to progressively adjust the depth prediction towards the real
depth. We train our model on the NYUv2 and KITTI datasets as in-distribution
datasets and extensively evaluate the framework on 16 other datasets. Our
framework performs remarkably well in the OOD scenarios and outperforms
existing state-of-the-art depth completion methods. Our models are released in
https://github.com/shenglunch/PSD.

</details>


### [22] [Unified modality separation: A vision-language framework for unsupervised domain adaptation](https://arxiv.org/abs/2508.04987)
*Xinyao Li,Jingjing Li,Zhekai Du,Lei Zhu,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的框架，用于解决预训练视觉语言模型（VLM）在无监督域适应（UDA）中的模态鸿沟问题。该框架通过分离和分别处理模态特异性和模态不变的组件，并采用自适应集成策略，显著提高了模型在目标域上的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域适应（UDA）方法在处理预训练视觉语言模型（VLM）时，由于模态鸿沟的存在，往往只能迁移模态不变的知识，导致在目标域上的性能不佳。本研究旨在解决这一局限性。

Method: 提出了一种统一的模态分离框架，该框架可以将视觉语言模型（VLM）的特征解耦为模态特异性和模态不变性组件，并分别处理。在测试时，通过自动确定的模态自适应集成权重来最大化不同组件的协同作用。设计了一个模态差异度量指标来区分实例级别的模态特征，并将模态不变样本用于跨模态对齐，将不确定样本用于增强模型能力。该方法结合了提示调优技术，实现了计算效率的9倍提升。

Result: 所提出的方法在多个骨干网络、基线模型、数据集和域适应设置上进行了广泛的实验，取得了高达9%的性能提升，并且计算效率提高了9倍。实验结果证明了该设计的有效性。

Conclusion: 本研究提出的统一模态分离框架在解决领域鸿沟和模态鸿沟方面取得了显著成效，通过解耦模态特异性和模态不变性组件，并在测试时自适应地组合它们，显著提升了模型在目标域上的性能。

Abstract: Unsupervised domain adaptation (UDA) enables models trained on a labeled
source domain to handle new unlabeled domains. Recently, pre-trained
vision-language models (VLMs) have demonstrated promising zero-shot performance
by leveraging semantic information to facilitate target tasks. By aligning
vision and text embeddings, VLMs have shown notable success in bridging domain
gaps. However, inherent differences naturally exist between modalities, which
is known as modality gap. Our findings reveal that direct UDA with the presence
of modality gap only transfers modality-invariant knowledge, leading to
suboptimal target performance. To address this limitation, we propose a unified
modality separation framework that accommodates both modality-specific and
modality-invariant components. During training, different modality components
are disentangled from VLM features then handled separately in a unified manner.
At test time, modality-adaptive ensemble weights are automatically determined
to maximize the synergy of different components. To evaluate instance-level
modality characteristics, we design a modality discrepancy metric to categorize
samples into modality-invariant, modality-specific, and uncertain ones. The
modality-invariant samples are exploited to facilitate cross-modal alignment,
while uncertain ones are annotated to enhance model capabilities. Building upon
prompt tuning techniques, our methods achieve up to 9% performance gain with 9
times of computational efficiencies. Extensive experiments and analysis across
various backbones, baselines, datasets and adaptation settings demonstrate the
efficacy of our design.

</details>


### [23] [Modeling Rapid Contextual Learning in the Visual Cortex with Fast-Weight Deep Autoencoder Networks](https://arxiv.org/abs/2508.04988)
*Yue Li,Weifan Wang,Tai Sing Lee*

Main category: cs.CV

TL;DR: 本研究使用ViT自动编码器和LoRA技术，模拟了视觉皮层如何通过熟悉度训练快速学习全局上下文。研究发现，这种训练能增强早期层的全局敏感性，LoRA能放大此效果，为大脑学习机制提供了计算模型。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在从功能角度研究熟悉度训练如何诱导深度神经网络早期层对全局上下文的敏感性，以期为理解大脑中快速学习全局上下文提供计算模型。

Method: 本研究采用基于Vision Transformer (ViT) 的自动编码器，从功能角度研究熟悉度训练如何诱导深度神经网络早期层对全局上下文的敏感性。研究人员探索了在每个Transformer层中使用低秩自适应 (LoRA) 来实现快速权重，并提出快速权重编码瞬时或短期记忆痕迹。

Result: 1. 所提出的基于ViT的自动编码器的自注意力机制执行了与熟悉度效应的神经回路模型相似的流形变换。 2. 熟悉度训练将早期层的潜在表征与包含全局上下文信息的顶层对齐。 3. 熟悉度训练拓宽了记忆图像上下文中的自注意力范围。 4. LoRA实现的快速权重显著放大了这些效果。

Conclusion: 本研究表明，熟悉度训练能够使分层网络中的早期层获得全局敏感性，并且混合的快慢权重架构可以为研究大脑中快速全局上下文学习提供一个可行的计算模型。

Abstract: Recent neurophysiological studies have revealed that the early visual cortex
can rapidly learn global image context, as evidenced by a sparsification of
population responses and a reduction in mean activity when exposed to familiar
versus novel image contexts. This phenomenon has been attributed primarily to
local recurrent interactions, rather than changes in feedforward or feedback
pathways, supported by both empirical findings and circuit-level modeling.
Recurrent neural circuits capable of simulating these effects have been shown
to reshape the geometry of neural manifolds, enhancing robustness and
invariance to irrelevant variations. In this study, we employ a Vision
Transformer (ViT)-based autoencoder to investigate, from a functional
perspective, how familiarity training can induce sensitivity to global context
in the early layers of a deep neural network. We hypothesize that rapid
learning operates via fast weights, which encode transient or short-term memory
traces, and we explore the use of Low-Rank Adaptation (LoRA) to implement such
fast weights within each Transformer layer. Our results show that (1) The
proposed ViT-based autoencoder's self-attention circuit performs a manifold
transform similar to a neural circuit model of the familiarity effect. (2)
Familiarity training aligns latent representations in early layers with those
in the top layer that contains global context information. (3) Familiarity
training broadens the self-attention scope within the remembered image context.
(4) These effects are significantly amplified by LoRA-based fast weights.
Together, these findings suggest that familiarity training introduces global
sensitivity to earlier layers in a hierarchical network, and that a hybrid
fast-and-slow weight architecture may provide a viable computational model for
studying rapid global context learning in the brain.

</details>


### [24] [Attribute Guidance With Inherent Pseudo-label For Occluded Person Re-identification](https://arxiv.org/abs/2508.04998)
*Rui Zhi,Zhen Yang,Haiyang Zhang*

Main category: cs.CV

TL;DR: AG-ReID通过生成属性伪标签和采用双重指导机制，利用预训练模型提取细粒度属性，解决了遮挡Re-ID中的细粒度信息缺失问题，并在多个数据集上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言模型在处理遮挡场景时，侧重于整体图像语义而忽略细粒度属性信息，这在处理部分遮挡的行人或区分细微外观差异的个体时尤为明显。为了克服这一局限性，我们提出了AG-ReID框架。

Method: AG-ReID框架采用两阶段过程：首先生成捕获细微视觉特征的属性伪标签，然后引入结合整体和细粒度属性信息的双重指导机制，以增强图像特征提取。

Result: AG-ReID在多个广泛使用的Re-ID数据集上取得了最先进的结果，在处理遮挡和细微属性差异方面显示出显著的改进，同时在标准Re-ID场景中保持了具有竞争力的性能。

Conclusion: AG-ReID

Abstract: Person re-identification (Re-ID) aims to match person images across different
camera views, with occluded Re-ID addressing scenarios where pedestrians are
partially visible. While pre-trained vision-language models have shown
effectiveness in Re-ID tasks, they face significant challenges in occluded
scenarios by focusing on holistic image semantics while neglecting fine-grained
attribute information. This limitation becomes particularly evident when
dealing with partially occluded pedestrians or when distinguishing between
individuals with subtle appearance differences. To address this limitation, we
propose Attribute-Guide ReID (AG-ReID), a novel framework that leverages
pre-trained models' inherent capabilities to extract fine-grained semantic
attributes without additional data or annotations. Our framework operates
through a two-stage process: first generating attribute pseudo-labels that
capture subtle visual characteristics, then introducing a dual-guidance
mechanism that combines holistic and fine-grained attribute information to
enhance image feature extraction. Extensive experiments demonstrate that
AG-ReID achieves state-of-the-art results on multiple widely-used Re-ID
datasets, showing significant improvements in handling occlusions and subtle
attribute differences while maintaining competitive performance on standard
Re-ID scenarios.

</details>


### [25] [CRAM: Large-scale Video Continual Learning with Bootstrapped Compression](https://arxiv.org/abs/2508.05001)
*Shivani Mall,Joao F. Henriques*

Main category: cs.CV

TL;DR: 本研究提出 CRAM 方法，通过存储压缩视频编码并刷新它们来解决视频持续学习中的内存和灾难性遗忘问题，并在大规模视频数据集上取得了更好的性能和更低的内存占用。


<details>
  <summary>Details</summary>
Motivation: 持续学习（CL）旨在使神经网络能够从连续输入流中学习，而不是依赖于需要随机访问完整数据集的 IID 采样。这使得部署的系统在处理自然分布变化时，能够满足更小的存储需求并实现自给自足，类似于生物学习。然而，在视频 CL 领域，高内存需求是一个主要挑战，尤其是在处理长视频和连续视频流时，这与通常的内存缓冲区大小限制相悖。

Method: 本研究提出了一种名为 Continually Refreshed Amodal Memory (CRAM) 的视频持续学习方法。该方法的核心在于使用压缩后的视频编码（embeddings）代替原始输入存储在内存缓冲区中，以解决视频数据内存占用大的问题。为了应对在线训练视频压缩器时出现的灾难性遗忘，CRAM 提出了一种刷新视频编码的机制，该机制涉及使用旧版本网络进行解压，再用新版本网络进行重压缩。

Result: 研究将现有的视频 CL 基准扩展到大规模设置，包括 EpicKitchens-100 和 Kinetics-700 数据集，并将数千个相对较长的视频存储在 2 GB 以下的空间中。实验结果表明，所提出的 CRAM 方法在视频 CL 任务上显著优于现有技术，同时内存占用大大减少。

Conclusion: CRAM 方法在视频持续学习任务中，通过使用压缩表示（视频编码）和刷新编码的机制，显著降低了内存占用，同时在 EpicKitchens-100 和 Kinetics-700 等大规模数据集上取得了优于现有方法的性能。

Abstract: Continual learning (CL) promises to allow neural networks to learn from
continuous streams of inputs, instead of IID (independent and identically
distributed) sampling, which requires random access to a full dataset. This
would allow for much smaller storage requirements and self-sufficiency of
deployed systems that cope with natural distribution shifts, similarly to
biological learning. We focus on video CL employing a rehearsal-based approach,
which reinforces past samples from a memory buffer. We posit that part of the
reason why practical video CL is challenging is the high memory requirements of
video, further exacerbated by long-videos and continual streams, which are at
odds with the common rehearsal-buffer size constraints. To address this, we
propose to use compressed vision, i.e. store video codes (embeddings) instead
of raw inputs, and train a video classifier by IID sampling from this rolling
buffer. Training a video compressor online (so not depending on any pre-trained
networks) means that it is also subject to catastrophic forgetting. We propose
a scheme to deal with this forgetting by refreshing video codes, which requires
careful decompression with a previous version of the network and recompression
with a new one. We name our method Continually Refreshed Amodal Memory (CRAM).
We expand current video CL benchmarks to large-scale settings, namely
EpicKitchens-100 and Kinetics-700, storing thousands of relatively long videos
in under 2 GB, and demonstrate empirically that our video CL method outperforms
prior art with a significantly reduced memory footprint.

</details>


### [26] [Multimodal Causal-Driven Representation Learning for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2508.05008)
*Xusheng Liang,Lihua Zhou,Nianxin Li,Miao Xu,Ziyang Song,Dong Yi,Jinlin Wu,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: MCDRL框架通过结合因果推断和VLM，利用CLIP识别混淆因素并训练因果干预网络，有效解决了医学图像分割中的领域泛化问题，提高了分割准确性和模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在医学影像应用中面临挑战，主要是因为医学数据的高变异性和复杂性，特别是由于设备差异、操作伪影和成像模式等混淆因素造成的显著领域转移，导致模型在未见过的领域泛化能力差。

Method: 提出了一种名为多模态因果驱动表示学习（MCDRL）的新框架，该框架结合了因果推断和视觉-语言模型（VLM），以解决医学图像分割中的领域泛化问题。具体分为两步：1. 利用CLIP的跨模态能力和文本提示来识别候选病灶区域，并构建包含领域特定变化的混淆因素词典。2. 训练一个因果干预网络，利用该词典来识别并消除这些领域特定变化的影响，同时保留对分割至关重要的人体解剖结构信息。

Result: 实验结果表明，MCDRL框架的分割准确性优于现有方法，并且具有强大的泛化能力。

Conclusion: MCDRL框架在医学图像分割任务中展现出优越的性能和鲁棒的泛化能力，能够有效克服领域转移问题。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot capabilities in various computer vision tasks. However, their
application to medical imaging remains challenging due to the high variability
and complexity of medical data. Specifically, medical images often exhibit
significant domain shifts caused by various confounders, including equipment
differences, procedure artifacts, and imaging modes, which can lead to poor
generalization when models are applied to unseen domains. To address this
limitation, we propose Multimodal Causal-Driven Representation Learning
(MCDRL), a novel framework that integrates causal inference with the VLM to
tackle domain generalization in medical image segmentation. MCDRL is
implemented in two steps: first, it leverages CLIP's cross-modal capabilities
to identify candidate lesion regions and construct a confounder dictionary
through text prompts, specifically designed to represent domain-specific
variations; second, it trains a causal intervention network that utilizes this
dictionary to identify and eliminate the influence of these domain-specific
variations while preserving the anatomical structural information critical for
segmentation tasks. Extensive experiments demonstrate that MCDRL consistently
outperforms competing methods, yielding superior segmentation accuracy and
exhibiting robust generalizability.

</details>


### [27] [AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content](https://arxiv.org/abs/2508.05016)
*Shushi Wang,Chunyi Li,Zicheng Zhang,Han Zhou,Wei Dong,Jun Chen,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: 该研究构建了AU-IQA数据集，用于评估AI增强的用户生成内容（AI-UGC）的图像质量。研究发现，现有质量评估方法在AI-UGC上的表现不佳，需要开发新的评估模型。


<details>
  <summary>Details</summary>
Motivation: AI图像增强技术虽然广泛应用于改善用户生成内容（UGC）的视觉质量，但缺乏专门的质量评估模型限制了其发展和用户体验。现有评估方法在单独评估UGC和AIGC（人工智能生成内容）时表现良好，但在评估混合了两者特征的AI-UGC时的有效性尚未得到充分研究。

Method: 构建了一个名为AU-IQA的基准数据集，包含4,800张AI-UGC图像，涵盖了超分辨率、弱光增强和去噪三种增强类型。在此数据集上评估了一系列现有的质量评估模型（包括传统IQA方法和大型多模态模型），并对它们评估AI-UGC感知质量的表现进行了全面分析。

Result: 评估结果表明，现有模型在评估AI-UGC的感知质量方面存在局限性，为后续开发更有效的评估方法提供了分析基础。

Conclusion: 现有AI图像增强技术的质量评估方法在AI-UGC（人工智能增强的用户生成内容）上的表现仍有待提升，需要专门针对AI-UGC开发新的评估模型。

Abstract: AI-based image enhancement techniques have been widely adopted in various
visual applications, significantly improving the perceptual quality of
user-generated content (UGC). However, the lack of specialized quality
assessment models has become a significant limiting factor in this field,
limiting user experience and hindering the advancement of enhancement methods.
While perceptual quality assessment methods have shown strong performance on
UGC and AIGC individually, their effectiveness on AI-enhanced UGC (AI-UGC)
which blends features from both, remains largely unexplored. To address this
gap, we construct AU-IQA, a benchmark dataset comprising 4,800 AI-UGC images
produced by three representative enhancement types which include
super-resolution, low-light enhancement, and denoising. On this dataset, we
further evaluate a range of existing quality assessment models, including
traditional IQA methods and large multimodal models. Finally, we provide a
comprehensive analysis of how well current approaches perform in assessing the
perceptual quality of AI-UGC. The access link to the AU-IQA is
https://github.com/WNNGGU/AU-IQA-Dataset.

</details>


### [28] [Skin-SOAP: A Weakly Supervised Framework for Generating Structured SOAP Notes](https://arxiv.org/abs/2508.05019)
*Sadia Kamal,Tim Oates,Joy Wan*

Main category: cs.CV

TL;DR: skin-SOAP是一个新框架，可以根据有限的输入（图像和文本）生成SOAP笔记，其性能可与GPT-4o等模型相媲美，同时减少了对注释数据的需求。


<details>
  <summary>Details</summary>
Motivation: 手动生成SOAP笔记耗时费力，并导致临床医生倦怠。该研究旨在通过自动化笔记生成来解决这一问题。

Method: skin-SOAP是一个弱监督多模态框架，旨在于从病灶图像和稀疏的临床文本等有限输入生成SOAP笔记。

Result: skin-SOAP在关键临床相关性指标上达到了与GPT-4o、Claude和DeepSeek Janus Pro相当的性能。研究中还引入了MedConceptEval和Clinical Coherence Score (CCS)两个新指标来评估临床相关性。

Conclusion: 该研究提出了skin-SOAP，一个弱监督多模态框架，能够根据有限的输入（包括病灶图像和稀疏的临床文本）生成临床结构化SOAP笔记。该方法减少了对手动注释的依赖，实现了可扩展的、有临床依据的文档记录，同时减轻了临床医生的负担，并减少了对大规模注释数据的需求。

Abstract: Skin carcinoma is the most prevalent form of cancer globally, accounting for
over $8 billion in annual healthcare expenditures. Early diagnosis, accurate
and timely treatment are critical to improving patient survival rates. In
clinical settings, physicians document patient visits using detailed SOAP
(Subjective, Objective, Assessment, and Plan) notes. However, manually
generating these notes is labor-intensive and contributes to clinician burnout.
In this work, we propose skin-SOAP, a weakly supervised multimodal framework to
generate clinically structured SOAP notes from limited inputs, including lesion
images and sparse clinical text. Our approach reduces reliance on manual
annotations, enabling scalable, clinically grounded documentation while
alleviating clinician burden and reducing the need for large annotated data.
Our method achieves performance comparable to GPT-4o, Claude, and DeepSeek
Janus Pro across key clinical relevance metrics. To evaluate this clinical
relevance, we introduce two novel metrics MedConceptEval and Clinical Coherence
Score (CCS) which assess semantic alignment with expert medical concepts and
input features, respectively.

</details>


### [29] [A Novel Image Similarity Metric for Scene Composition Structure](https://arxiv.org/abs/2508.05037)
*Md Redwanul Haque,Manzur Murshed,Manoranjan Paul,Tsz-Kwan Lee*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SCSSIM 的新指标，用于评估生成 AI 模型的图像质量，重点关注场景组成结构 (SCS) 的保留情况。SCSSIM 是一种无需训练的分析方法，通过图像分层划分的统计量来工作，能够准确评估图像的结构完整性，优于传统和基于神经网络的指标。


<details>
  <summary>Details</summary>
Motivation: 随着生成 AI 模型的发展，需要超越人类感知的图像质量评估方法。模型的一个关键问题是保留图像的场景组成结构 (SCS)，即对象之间的几何关系、它们的位置、大小、方向等。传统的图像相似度指标在评估 SCS 方面存在不足，而基于神经网络的指标则有训练开销和泛化问题。

Method: 提出了一种名为 SCSSIM (Scene Composition Structure Similarity Index Measure) 的新颖的、无需训练的、基于分析的指标。该指标利用图像立方体分层划分的统计量来量化场景组成结构 (SCS) 的保留情况，能够稳健地捕获非对象结构关系。

Result: 实验表明，SCSSIM 对非成分失真具有高度不变性，能准确反映 SCS 的变化。相反，对于成分失真，它显示出强烈的单调递减，精确地指示 SCS 何时已被改变。与现有指标相比，SCSSIM 在结构评估方面表现出优越的性能。

Conclusion: SCSSIM 是一种新颖的、无需训练的、基于分析的指标，它通过利用图像立方体分层划分的统计量来量化 SCS 的保留情况，从而稳健地捕获非对象结构关系。与现有指标相比，SCSSIM 在结构评估方面表现出优越的性能，是开发和评估生成模型、确保场景组成的完整性的宝贵工具。

Abstract: The rapid advancement of generative AI models necessitates novel methods for
evaluating image quality that extend beyond human perception. A critical
concern for these models is the preservation of an image's underlying Scene
Composition Structure (SCS), which defines the geometric relationships among
objects and the background, their relative positions, sizes, orientations, etc.
Maintaining SCS integrity is paramount for ensuring faithful and structurally
accurate GenAI outputs. Traditional image similarity metrics often fall short
in assessing SCS. Pixel-level approaches are overly sensitive to minor visual
noise, while perception-based metrics prioritize human aesthetic appeal,
neither adequately capturing structural fidelity. Furthermore, recent
neural-network-based metrics introduce training overheads and potential
generalization issues. We introduce the SCS Similarity Index Measure (SCSSIM),
a novel, analytical, and training-free metric that quantifies SCS preservation
by exploiting statistical measures derived from the Cuboidal hierarchical
partitioning of images, robustly capturing non-object-based structural
relationships. Our experiments demonstrate SCSSIM's high invariance to
non-compositional distortions, accurately reflecting unchanged SCS. Conversely,
it shows a strong monotonic decrease for compositional distortions, precisely
indicating when SCS has been altered. Compared to existing metrics, SCSSIM
exhibits superior properties for structural evaluation, making it an invaluable
tool for developing and evaluating generative models, ensuring the integrity of
scene composition.

</details>


### [30] [HAMoBE: Hierarchical and Adaptive Mixture of Biometric Experts for Video-based Person ReID](https://arxiv.org/abs/2508.05038)
*Yiyang Su,Yunping Shi,Feng Liu,Xiaoming Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HAMoBE的新型视频重识别框架，该框架通过结合外观、体型和步态等多方面信息，并使用一种自适应的专家系统来整合这些信息，从而提高了识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频重识别方法常常忽略了从查询-图库对中的视频识别和选择最具辨别力的特征以进行有效匹配的必要性。

Method: 提出了一种新颖的层级自适应混合生物识别专家（HAMoBE）框架，该框架利用预训练大模型（如CLIP）的多层特征，通过独立建模外观、静态体型和动态步态这三个关键生物识别特征来模拟人类感知机制，并进行自适应融合。具体来说，HAMoBE包含两个层级：第一层级从冻结的大模型提供的多层表示中提取低层特征；第二层级包含专注于长期、短期和时间特征的专门专家。为了确保鲁棒匹配，引入了一种新的双输入决策门控网络，根据每个专家与输入场景的相关性动态调整其贡献。

Result: 在MEVID等基准数据集上的大量评估表明，该方法在性能上取得了显著的改进（例如，Rank-1准确率提高了13.0%）。

Conclusion: 该研究提出的HAMoBE框架通过利用多层特征、独立建模生物识别特征（外观、静态体型、动态步态）并自适应地融合它们，并引入双输入决策门控网络来动态调整专家贡献，在视频重识别任务上取得了显著的性能提升（例如，Rank-1准确率提高了13.0%），证明了其有效性。

Abstract: Recently, research interest in person re-identification (ReID) has
increasingly focused on video-based scenarios, which are essential for robust
surveillance and security in varied and dynamic environments. However, existing
video-based ReID methods often overlook the necessity of identifying and
selecting the most discriminative features from both videos in a query-gallery
pair for effective matching. To address this issue, we propose a novel
Hierarchical and Adaptive Mixture of Biometric Experts (HAMoBE) framework,
which leverages multi-layer features from a pre-trained large model (e.g.,
CLIP) and is designed to mimic human perceptual mechanisms by independently
modeling key biometric features--appearance, static body shape, and dynamic
gait--and adaptively integrating them. Specifically, HAMoBE includes two
levels: the first level extracts low-level features from multi-layer
representations provided by the frozen large model, while the second level
consists of specialized experts focusing on long-term, short-term, and temporal
features. To ensure robust matching, we introduce a new dual-input decision
gating network that dynamically adjusts the contributions of each expert based
on their relevance to the input scenarios. Extensive evaluations on benchmarks
like MEVID demonstrate that our approach yields significant performance
improvements (e.g., +13.0% Rank-1 accuracy).

</details>


### [31] [Finding Needles in Images: Can Multimodal LLMs Locate Fine Details?](https://arxiv.org/abs/2508.05053)
*Parth Thakkar,Ankush Agarwal,Prasad Kasu,Pulkit Bansal,Chaitanya Devaguptapu*

Main category: cs.CV

TL;DR: 介绍了一个名为 NiM 的新基准和 Spot-IT 方法，用于评估和增强多模态大语言模型在文档细粒度细节查找和推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在文档理解任务中表现出色，但在定位和推理文档中的细粒度细节方面能力尚待开发，这类似于在图像中寻找针（NiM）。

Method: 通过智能图像块选择和高斯注意力来增强多模态大语言模型的能力，模仿人类在搜索文档时缩放和聚焦的方式。

Result: 实验证明了 Spot-IT 在处理细粒度文档理解任务方面的有效性，并揭示了当前多模态大语言模型在这些任务上的能力和局限性。

Conclusion: Spot-IT 在需要从复杂布局中精确提取细节的场景中，相比基线方法取得了显著的改进。

Abstract: While Multi-modal Large Language Models (MLLMs) have shown impressive
capabilities in document understanding tasks, their ability to locate and
reason about fine-grained details within complex documents remains
understudied. Consider searching a restaurant menu for a specific nutritional
detail or identifying a disclaimer in a lengthy newspaper article tasks that
demand careful attention to small but significant details within a broader
narrative, akin to Finding Needles in Images (NiM). To address this gap, we
introduce NiM, a carefully curated benchmark spanning diverse real-world
documents including newspapers, menus, and lecture images, specifically
designed to evaluate MLLMs' capability in these intricate tasks. Building on
this, we further propose Spot-IT, a simple yet effective approach that enhances
MLLMs capability through intelligent patch selection and Gaussian attention,
motivated from how humans zoom and focus when searching documents. Our
extensive experiments reveal both the capabilities and limitations of current
MLLMs in handling fine-grained document understanding tasks, while
demonstrating the effectiveness of our approach. Spot-IT achieves significant
improvements over baseline methods, particularly in scenarios requiring precise
detail extraction from complex layouts.

</details>


### [32] [DualMat: PBR Material Estimation via Coherent Dual-Path Diffusion](https://arxiv.org/abs/2508.05060)
*Yifeng Huang,Zhang Chen,Yi Xu,Minh Hoai,Zhong Li*

Main category: cs.CV

TL;DR: DualMat 是一个双路径扩散框架，用于从单张图像估计 PBR 材料，在反照率估计和金属度-粗糙度预测方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于从复杂光照条件下的单张图像估计基于物理的渲染 (PBR) 材料的新颖方法。

Method: DualMat 是一个新颖的双路径扩散框架，用于从复杂光照条件下的单张图像估计基于物理的渲染 (PBR) 材料。该方法在两个不同的潜在空间中运行：一个利用通过 RGB 潜在空间预训练的视觉知识的反照率优化路径，以及一个在为精确金属度-粗糙度估计设计的紧凑潜在空间中运行的材料专业化路径。为了确保反照率优化和材料专业化路径之间的一致性预测，我们在训练期间引入了特征蒸馏。我们采用校正流通过减少推理步骤来提高效率，同时保持质量。我们的框架通过基于块的估计和跨视图注意力扩展到高分辨率和多视图输入，从而能够无缝集成到图像到 3D 管道中。

Result: DualMat 在 Objaverse 和真实世界数据上均取得了最先进的性能。

Conclusion: DualMat 在 Objaverse 和真实世界数据上均取得了最先进的性能，在反照率估计方面提高了 28%，在金属度-粗糙度预测误差方面降低了 39%，显著优于现有方法。

Abstract: We present DualMat, a novel dual-path diffusion framework for estimating
Physically Based Rendering (PBR) materials from single images under complex
lighting conditions. Our approach operates in two distinct latent spaces: an
albedo-optimized path leveraging pretrained visual knowledge through RGB latent
space, and a material-specialized path operating in a compact latent space
designed for precise metallic and roughness estimation. To ensure coherent
predictions between the albedo-optimized and material-specialized paths, we
introduce feature distillation during training. We employ rectified flow to
enhance efficiency by reducing inference steps while maintaining quality. Our
framework extends to high-resolution and multi-view inputs through patch-based
estimation and cross-view attention, enabling seamless integration into
image-to-3D pipelines. DualMat achieves state-of-the-art performance on both
Objaverse and real-world data, significantly outperforming existing methods
with up to 28% improvement in albedo estimation and 39% reduction in
metallic-roughness prediction errors.

</details>


### [33] [Decoupling Continual Semantic Segmentation](https://arxiv.org/abs/2508.05065)
*Yifu Guo,Yuquan Lu,Wentao Zhang,Zishan Xu,Dexia Chen,Siyu Zhang,Yizhe Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: DecoupleCSS是一个两阶段框架，通过将类别检测和分割解耦来解决持续语义分割中的灾难性遗忘问题，并在保留旧知识的同时学习新类别，从而提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CSS方法通常采用单一阶段的编码器-解码器架构，其中分割掩码和类别标签紧密耦合，导致新旧类别学习之间的干扰以及次优的保留-可塑性平衡。为了解决这个问题，需要一种能够更好地区分不同类别信息同时又能够有效分割的方法。

Method: 提出了一种新颖的两阶段框架DecoupleCSS，其中第一阶段利用预训练的文本和图像编码器（通过LoRA适配）来编码特定类别的知识并生成位置感知提示，第二阶段利用分割任何模型（SAM）生成精确的分割掩码，从而将分割知识在旧类别和新类别之间共享。

Result: DecoupleCSS提高了CSS中保留和适应性之间的平衡，并在各种具有挑战性的任务中实现了最先进的性能。

Conclusion: DecoupleCSS通过解耦类别感知检测和类别不可知分割，实现了更有效的持续学习，在保持旧知识的同时学习新类别，并在各种具有挑战性的任务中实现了最先进的性能。

Abstract: Continual Semantic Segmentation (CSS) requires learning new classes without
forgetting previously acquired knowledge, addressing the fundamental challenge
of catastrophic forgetting in dense prediction tasks. However, existing CSS
methods typically employ single-stage encoder-decoder architectures where
segmentation masks and class labels are tightly coupled, leading to
interference between old and new class learning and suboptimal
retention-plasticity balance. We introduce DecoupleCSS, a novel two-stage
framework for CSS. By decoupling class-aware detection from class-agnostic
segmentation, DecoupleCSS enables more effective continual learning, preserving
past knowledge while learning new classes. The first stage leverages
pre-trained text and image encoders, adapted using LoRA, to encode
class-specific information and generate location-aware prompts. In the second
stage, the Segment Anything Model (SAM) is employed to produce precise
segmentation masks, ensuring that segmentation knowledge is shared across both
new and previous classes. This approach improves the balance between retention
and adaptability in CSS, achieving state-of-the-art performance across a
variety of challenging tasks. Our code is publicly available at:
https://github.com/euyis1019/Decoupling-Continual-Semantic-Segmentation.

</details>


### [34] [Automatic Image Colorization with Convolutional Neural Networks and Generative Adversarial Networks](https://arxiv.org/abs/2508.05068)
*Ruiyu Li,Changyuan Qiu,Hangrui Cao,Qihan Ren,Yuqing Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种基于分类和对抗学习的自动图像上色方法。


<details>
  <summary>Details</summary>
Motivation: 图像上色因其在色彩修复和动画自动上色等领域的广泛应用而成为计算机视觉领域的研究热点。然而，由于图像维度丢失导致的高度不适定性，使得该任务充满挑战。场景语义和表面纹理可以提供重要的颜色线索（例如，天空通常是蓝色的，草地通常是绿色的），并且有大量的训练数据可供利用。

Method: 本文提出了一种基于分类和对抗学习的自动图像上色方法。

Result: 本文将探索自动图像上色，并基于先前的工作进行修改和比较。

Conclusion: 本文提出了一种基于分类和对抗学习的自动图像上色方法，以解决传统回归方法忽略颜色预测多模态性质的问题。

Abstract: Image colorization, the task of adding colors to grayscale images, has been
the focus of significant research efforts in computer vision in recent years
for its various application areas such as color restoration and automatic
animation colorization [15, 1]. The colorization problem is challenging as it
is highly ill-posed with two out of three image dimensions lost, resulting in
large degrees of freedom. However, semantics of the scene as well as the
surface texture could provide important cues for colors: the sky is typically
blue, the clouds are typically white and the grass is typically green, and
there are huge amounts of training data available for learning such priors
since any colored image could serve as a training data point [20].
  Colorization is initially formulated as a regression task[5], which ignores
the multi-modal nature of color prediction. In this project, we explore
automatic image colorization via classification and adversarial learning. We
will build our models on prior works, apply modifications for our specific
scenario and make comparisons.

</details>


### [35] [FLUX-Makeup: High-Fidelity, Identity-Consistent, and Robust Makeup Transfer via Diffusion Transformer](https://arxiv.org/abs/2508.05069)
*Jian Zhu,Shanyuan Liu,Liuzhuozheng Li,Yue Gong,He Wang,Bo Cheng,Yuhang Ma,Liebucha Wu,Xiaoyu Wu,Dawei Leng,Yuhui Yin,Yang Xu*

Main category: cs.CV

TL;DR: FLUX-Makeup 是一种新的妆容迁移框架，它利用源图像作为条件输入，并引入 RefLoRAInjector 来提取妆容特征，从而无需辅助组件即可实现高质量、身份一致的妆容迁移。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方法在保持妆容迁移质量和面部身份一致性方面对辅助组件的依赖而引入的额外错误，FLUX-Makeup 旨在消除对任何辅助面部控制组件的需求，直接利用源-参考图像对来实现卓越的迁移性能。

Method: FLUX-Makeup 框架构建在 FLUX-Kontext 之上，并将源图像作为其原生条件输入。引入了 RefLoRAInjector，一种轻量级的妆容特征注入器，将参考通道与主干分离，从而能够高效全面地提取与妆容相关的信息。同时，设计了一个强大且可扩展的数据生成流程，在训练过程中提供更准确的监督。

Result: FLUX-Makeup 实现了高保真度、身份一致性和鲁棒性的妆容迁移。

Conclusion: FLUX-Makeup 框架在各种场景下实现了最先进的性能，并表现出强大的鲁棒性。

Abstract: Makeup transfer aims to apply the makeup style from a reference face to a
target face and has been increasingly adopted in practical applications.
Existing GAN-based approaches typically rely on carefully designed loss
functions to balance transfer quality and facial identity consistency, while
diffusion-based methods often depend on additional face-control modules or
algorithms to preserve identity. However, these auxiliary components tend to
introduce extra errors, leading to suboptimal transfer results. To overcome
these limitations, we propose FLUX-Makeup, a high-fidelity,
identity-consistent, and robust makeup transfer framework that eliminates the
need for any auxiliary face-control components. Instead, our method directly
leverages source-reference image pairs to achieve superior transfer
performance. Specifically, we build our framework upon FLUX-Kontext, using the
source image as its native conditional input. Furthermore, we introduce
RefLoRAInjector, a lightweight makeup feature injector that decouples the
reference pathway from the backbone, enabling efficient and comprehensive
extraction of makeup-related information. In parallel, we design a robust and
scalable data generation pipeline to provide more accurate supervision during
training. The paired makeup datasets produced by this pipeline significantly
surpass the quality of all existing datasets. Extensive experiments demonstrate
that FLUX-Makeup achieves state-of-the-art performance, exhibiting strong
robustness across diverse scenarios.

</details>


### [36] [AdaFusion: Prompt-Guided Inference with Adaptive Fusion of Pathology Foundation Models](https://arxiv.org/abs/2508.05084)
*Yuxiang Xiao,Yang Hu,Bin Li,Tianyang Zhang,Zexi Li,Huazhu Fu,Jens Rittscher,Kaixiang Yang*

Main category: cs.CV

TL;DR: AdaFusion 是一个新颖的框架，可以通过自适应地融合来自多个 PFM 的知识来提高性能和可解释性，解决了 PFM 中存在的潜在偏差问题。


<details>
  <summary>Details</summary>
Motivation: PFM 在下游应用中的通用性和透明度受到其多样化但又不透明的预训练环境（由数据相关和结构/训练因素决定）所引入的潜在偏差的阻碍。

Method: AdaFusion 是一个新颖的、由提示引导的推理框架，它动态地整合来自多个 PFM 的互补知识。该方法压缩并对齐来自不同模型的 tile 级特征，并采用轻量级注意力机制，根据组织表型上下文自适应地融合它们。

Result: AdaFusion 在三个真实基准（涵盖治疗反应预测、肿瘤分级和空间基因表达推理）上进行评估，在分类和回归任务上始终优于各个 PFM，同时还能提供对每个模型生物语义专业化的可解释见解。

Conclusion: AdaFusion 能够弥合异构 PFM 的差距，从而提高性能和可解释性。

Abstract: Pathology foundation models (PFMs) have demonstrated strong representational
capabilities through self-supervised pre-training on large-scale, unannotated
histopathology image datasets. However, their diverse yet opaque pretraining
contexts, shaped by both data-related and structural/training factors,
introduce latent biases that hinder generalisability and transparency in
downstream applications. In this paper, we propose AdaFusion, a novel
prompt-guided inference framework that, to our knowledge, is among the very
first to dynamically integrate complementary knowledge from multiple PFMs. Our
method compresses and aligns tile-level features from diverse models and
employs a lightweight attention mechanism to adaptively fuse them based on
tissue phenotype context. We evaluate AdaFusion on three real-world benchmarks
spanning treatment response prediction, tumour grading, and spatial gene
expression inference. Our approach consistently surpasses individual PFMs
across both classification and regression tasks, while offering interpretable
insights into each model's biosemantic specialisation. These results highlight
AdaFusion's ability to bridge heterogeneous PFMs, achieving both enhanced
performance and interpretability of model-specific inductive biases.

</details>


### [37] [PoseGen: In-Context LoRA Finetuning for Pose-Controllable Long Human Video Generation](https://arxiv.org/abs/2508.05091)
*Jingxuan He,Busheng Su,Finn Wong*

Main category: cs.CV

TL;DR: PoseGen是一个新框架，可以根据单个参考图像和姿态序列生成任意长的视频，解决了身份漂移和短片段限制问题。


<details>
  <summary>Details</summary>
Motivation: 生成具有精确主体身份和运动控制的、时间连贯的长视频是当前扩散模型的重大挑战，它们经常出现身份漂移且仅限于短片段。

Method: PoseGen提出了一种新颖的框架，通过在token级别注入主体外观的上下文LoRA微调策略来实现身份保持，同时在通道级别进行姿态信息条件化以实现细粒度运动控制。为了克服持续时间限制，PoseGen采用交错的片段生成方法，利用共享的KV缓存机制和专门的过渡过程无缝拼接视频片段，确保背景一致性和时间平滑性。

Result: PoseGen能够生成任意长度的视频，只需单个参考图像和驱动姿态序列，在身份保真度、姿态准确性和视频连贯性方面表现出色。

Conclusion: PoseGen在身份保真度、姿态准确性和生成无限时长的连贯、无伪影视频方面显著优于最先进的方法。

Abstract: Generating long, temporally coherent videos with precise control over subject
identity and motion is a formidable challenge for current diffusion models,
which often suffer from identity drift and are limited to short clips. We
introduce PoseGen, a novel framework that generates arbitrarily long videos of
a specific subject from a single reference image and a driving pose sequence.
Our core innovation is an in-context LoRA finetuning strategy that injects
subject appearance at the token level for identity preservation, while
simultaneously conditioning on pose information at the channel level for
fine-grained motion control. To overcome duration limits, PoseGen pioneers an
interleaved segment generation method that seamlessly stitches video clips
together, using a shared KV cache mechanism and a specialized transition
process to ensure background consistency and temporal smoothness. Trained on a
remarkably small 33-hour video dataset, extensive experiments show that PoseGen
significantly outperforms state-of-the-art methods in identity fidelity, pose
accuracy, and its unique ability to produce coherent, artifact-free videos of
unlimited duration.

</details>


### [38] [Sculpting Margin Penalty: Intra-Task Adapter Merging and Classifier Calibration for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.05094)
*Liang Bai,Hong Song,Jinfu Li,Yucong Lin,Jingfan Fan,Tianyu Fu,Danni Ai,Deqiang Xiao,Jian Yang*

Main category: cs.CV

TL;DR: SMP通过整合边际惩罚来解决FSCIL中的数据隐私和高获取成本问题，通过MIAM和MPCC机制在基础类可分性和新类泛化之间取得更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有FSCIL方法在平衡基础类可分性和新类泛化方面存在的不足，以及在增量任务中数据访问受限导致类决策边界模糊的问题，我们提出了SMP。

Method: SMP (Sculpting Margin Penalty) 是一种新颖的FSCIL方法，它在参数高效微调范式中策略性地整合了不同阶段的边际惩罚。具体来说，我们引入了用于基础任务学习的边际感知类内适配器合并（MIAM）机制。MIAM训练两个具有不同分类损失的低秩适配器集：一个带有边际惩罚以增强基础类可分性，另一个没有边际约束以促进对未来新类的泛化。然后，这些适配器被自适应地合并以提高前向兼容性。对于增量任务，我们提出了一种基于边际惩罚的分类器校准（MPCC）策略，通过在所有可见类的嵌入上进行边际惩罚微调来优化决策边界。

Result: SMP在CIFAR100、ImageNet-R和CUB200上的大量实验表明，SMP在FSCIL方面取得了最先进的性能，同时在基础类和新类之间保持了更好的平衡。

Conclusion: SMP在FSCIL方面取得了最先进的性能，同时在基础类和新类之间保持了更好的平衡。

Abstract: Real-world applications often face data privacy constraints and high
acquisition costs, making the assumption of sufficient training data in
incremental tasks unrealistic and leading to significant performance
degradation in class-incremental learning. Forward-compatible learning, which
prospectively prepares for future tasks during base task training, has emerged
as a promising solution for Few-Shot Class-Incremental Learning (FSCIL).
However, existing methods still struggle to balance base-class discriminability
and new-class generalization. Moreover, limited access to original data during
incremental tasks often results in ambiguous inter-class decision boundaries.
To address these challenges, we propose SMP (Sculpting Margin Penalty), a novel
FSCIL method that strategically integrates margin penalties at different stages
within the parameter-efficient fine-tuning paradigm. Specifically, we introduce
the Margin-aware Intra-task Adapter Merging (MIAM) mechanism for base task
learning. MIAM trains two sets of low-rank adapters with distinct
classification losses: one with a margin penalty to enhance base-class
discriminability, and the other without margin constraints to promote
generalization to future new classes. These adapters are then adaptively merged
to improve forward compatibility. For incremental tasks, we propose a Margin
Penalty-based Classifier Calibration (MPCC) strategy to refine decision
boundaries by fine-tuning classifiers on all seen classes' embeddings with a
margin penalty. Extensive experiments on CIFAR100, ImageNet-R, and CUB200
demonstrate that SMP achieves state-of-the-art performance in FSCIL while
maintaining a better balance between base and new classes.

</details>


### [39] [AHDMIL: Asymmetric Hierarchical Distillation Multi-Instance Learning for Fast and Accurate Whole-Slide Image Classification](https://arxiv.org/abs/2508.05114)
*Jiuyang Dong,Jiahan Li,Junjun Jiang,Kui Jiang,Yongbing Zhang*

Main category: cs.CV

TL;DR: AHDMIL是一种用于病理图像分类的多实例学习框架，通过非对称分层蒸馏和创新的CKA分类器，显著提高了分类准确性和推理速度，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决全切片成像（WSI）病理图像分类中，由于需要处理数千个图像块导致的高推理成本问题，提出AHDMIL框架以实现快速准确的分类。

Method: AHDMIL框架包含动态多实例网络（DMIN）和双分支轻量级实例预筛选网络（DB-LIPN）。首先，通过自蒸馏（SD）训练DMIN，并生成实例注意力分数以识别不相关图像块。接着，利用这些分数引导非对称蒸馏（AD），使DB-LIPN学习预测低分辨率图像块的相关性。最后，将DB-LIPN预测的相关图像块用于DMIN的微调和推理，并引入了首个基于Chebyshev多项式的Kolmogorov-Arnold（CKA）分类器。

Result: AHDMIL在Camelyon16数据集上实现了5.3%的相对准确率提升和1.2倍的推理加速。在所有测试的数据集上，AHDMIL在AUC、准确率、f1分数和Brier分数上均有稳定提升，平均推理速度提升了1.2到2.1倍，表现优于现有最先进方法。

Conclusion: AHDMIL在病理图像分类任务中，通过结合高分辨率WSIs的DMIN和低分辨率的DB-LIPN，利用自蒸馏和非对称蒸馏两步训练过程，有效消除了不相关图像块，实现了快速准确的分类。此外，提出的基于Chebyshev多项式的CKA分类器进一步提升了性能。实验证明，AHDMIL在准确率和推理速度上均优于现有方法，并在多个数据集上实现了显著的性能提升和加速。

Abstract: Although multi-instance learning (MIL) has succeeded in pathological image
classification, it faces the challenge of high inference costs due to the need
to process thousands of patches from each gigapixel whole slide image (WSI). To
address this, we propose AHDMIL, an Asymmetric Hierarchical Distillation
Multi-Instance Learning framework that enables fast and accurate classification
by eliminating irrelevant patches through a two-step training process. AHDMIL
comprises two key components: the Dynamic Multi-Instance Network (DMIN), which
operates on high-resolution WSIs, and the Dual-Branch Lightweight Instance
Pre-screening Network (DB-LIPN), which analyzes corresponding low-resolution
counterparts. In the first step, self-distillation (SD), DMIN is trained for
WSI classification while generating per-instance attention scores to identify
irrelevant patches. These scores guide the second step, asymmetric distillation
(AD), where DB-LIPN learns to predict the relevance of each low-resolution
patch. The relevant patches predicted by DB-LIPN have spatial correspondence
with patches in high-resolution WSIs, which are used for fine-tuning and
efficient inference of DMIN. In addition, we design the first
Chebyshev-polynomial-based Kolmogorov-Arnold (CKA) classifier in computational
pathology, which improves classification performance through learnable
activation layers. Extensive experiments on four public datasets demonstrate
that AHDMIL consistently outperforms previous state-of-the-art methods in both
classification performance and inference speed. For example, on the Camelyon16
dataset, it achieves a relative improvement of 5.3% in accuracy and accelerates
inference by 1.2.times. Across all datasets, area under the curve (AUC),
accuracy, f1 score, and brier score show consistent gains, with average
inference speedups ranging from 1.2 to 2.1 times. The code is available.

</details>


### [40] [Latent Expression Generation for Referring Image Segmentation and Grounding](https://arxiv.org/abs/2508.05123)
*Seonghoon Yu,Joonbeom Hong,Joonseok Lee,Jeany Son*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的视觉基础框架，通过利用单个文本输入生成的多个潜在表达式，并结合补充视觉细节来解决现有方法依赖单一文本输入的问题。该框架通过主体分配器和视觉概念注入器模块来捕获独特且针对目标的视觉线索，并通过正边距对比学习策略进行优化。实验证明，该方法在RIS、REC和GRES任务上均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 大多数现有方法依赖于单一的文本输入，仅捕获视觉域中丰富信息的一小部分，这可能导致相似对象的错误识别。为了解决这个问题，提出了一种新颖的视觉基础框架。

Method: 提出了一种新颖的视觉基础框架，通过结合来自原始描述的补充视觉细节，利用单个文本输入生成的多个潜在表达式。具体来说，引入了主体分配器和视觉概念注入器模块，将共享主体和不同属性的概念嵌入到潜在表示中，从而捕获独特且针对目标的视觉线索。还提出了一种正边距对比学习策略，以在保留细微差异的同时，将所有潜在表达式与原始文本对齐。

Result: 实验结果表明，该方法不仅在多个基准上超越了最先进的RIS和REC方法，而且在GRES基准上也取得了出色的性能。

Conclusion: 该方法在多个基准上超越了最先进的RIS和REC方法，并在GRES基准上取得了优异的性能。

Abstract: Visual grounding tasks, such as referring image segmentation (RIS) and
referring expression comprehension (REC), aim to localize a target object based
on a given textual description. The target object in an image can be described
in multiple ways, reflecting diverse attributes such as color, position, and
more. However, most existing methods rely on a single textual input, which
captures only a fraction of the rich information available in the visual
domain. This mismatch between rich visual details and sparse textual cues can
lead to the misidentification of similar objects. To address this, we propose a
novel visual grounding framework that leverages multiple latent expressions
generated from a single textual input by incorporating complementary visual
details absent from the original description. Specifically, we introduce
subject distributor and visual concept injector modules to embed both
shared-subject and distinct-attributes concepts into the latent
representations, thereby capturing unique and target-specific visual cues. We
also propose a positive-margin contrastive learning strategy to align all
latent expressions with the original text while preserving subtle variations.
Experimental results show that our method not only outperforms state-of-the-art
RIS and REC approaches on multiple benchmarks but also achieves outstanding
performance on the generalized referring expression segmentation (GRES)
benchmark.

</details>


### [41] [FedGIN: Federated Learning with Dynamic Global Intensity Non-linear Augmentation for Organ Segmentation using Multi-modal Images](https://arxiv.org/abs/2508.05137)
*Sachin Dudda Nagaraju,Ashkan Moradi,Bendik Skarre Abrahamsen,Mattijs Elschot*

Main category: cs.CV

TL;DR: FedGIN是一个联邦学习框架，通过GIN模块增强实现多模态医学图像分割，在保护隐私的同时，提升了跨模态分割的准确性和泛化能力，尤其在数据有限的情况下效果显著。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分割在AI辅助诊断、手术规划和治疗监测中起着关键作用。开发一个能够有效泛化到多种成像模态（如CT和MRI）的统一分割模型，对于简化临床工作流程和减少特定于模态的训练需求具有重要意义。然而，数据稀缺、跨模态域转移以及隐私限制是真实世界部署的主要挑战。FedGIN旨在通过联邦学习提供一种解决方案，在保护患者数据隐私的前提下，实现多模态器官分割。

Method: FedGIN是一个联邦学习（FL）框架，集成了轻量级的全局非线性（GIN）增强模块。GIN模块旨在解决医学图像分割中的域转移问题，通过在本地训练期间协调特定模态的强度分布来增强模型的泛化能力。该框架在不共享原始患者数据的情况下，允许多个参与方（客户端）协同训练一个统一的分割模型。模型评估在两种数据集设置下进行：一种是有限数据集场景（仅初始使用MRI数据，然后加入CT数据评估性能提升），另一种是完整数据集场景（所有客户端完全利用MRI和CT数据进行训练）。

Result: 在有限数据集场景下，FedGIN相较于未使用GIN的联邦学习方法，在MRI测试用例上的3D Dice分数提高了12%到18%，并持续优于本地基线模型。在完整数据集场景下，FedGIN表现出接近中心化训练的性能，相比仅使用MRI数据的基线模型，Dice分数提高了30%，相比仅使用CT数据的基线模型，Dice分数提高了10%。这表明FedGIN在隐私约束下具有强大的跨模态泛化能力。

Conclusion: FedGIN框架在联邦学习的背景下，通过集成GIN数据增强模块，成功实现了跨模态的医学图像分割。该方法在数据稀疏和完整的数据集场景下均表现出色，尤其在数据稀疏场景下，相对于不带GIN模块的联邦学习方法，在MRI测试用例上实现了12%到18%的3D Dice分数提升。在完整数据集场景下，FedGIN接近中心化训练的性能，显著优于仅使用单一模态（MRI或CT）的基线模型，证明了其在隐私限制下强大的跨模态泛化能力。

Abstract: Medical image segmentation plays a crucial role in AI-assisted diagnostics,
surgical planning, and treatment monitoring. Accurate and robust segmentation
models are essential for enabling reliable, data-driven clinical decision
making across diverse imaging modalities. Given the inherent variability in
image characteristics across modalities, developing a unified model capable of
generalizing effectively to multiple modalities would be highly beneficial.
This model could streamline clinical workflows and reduce the need for
modality-specific training. However, real-world deployment faces major
challenges, including data scarcity, domain shift between modalities (e.g., CT
vs. MRI), and privacy restrictions that prevent data sharing. To address these
issues, we propose FedGIN, a Federated Learning (FL) framework that enables
multimodal organ segmentation without sharing raw patient data. Our method
integrates a lightweight Global Intensity Non-linear (GIN) augmentation module
that harmonizes modality-specific intensity distributions during local
training. We evaluated FedGIN using two types of datasets: an imputed dataset
and a complete dataset. In the limited dataset scenario, the model was
initially trained using only MRI data, and CT data was added to assess its
performance improvements. In the complete dataset scenario, both MRI and CT
data were fully utilized for training on all clients. In the limited-data
scenario, FedGIN achieved a 12 to 18% improvement in 3D Dice scores on MRI test
cases compared to FL without GIN and consistently outperformed local baselines.
In the complete dataset scenario, FedGIN demonstrated near-centralized
performance, with a 30% Dice score improvement over the MRI-only baseline and a
10% improvement over the CT-only baseline, highlighting its strong
cross-modality generalization under privacy constraints.

</details>


### [42] [Deep Learning-based Animal Behavior Analysis: Insights from Mouse Chronic Pain Models](https://arxiv.org/abs/2508.05138)
*Yu-Hsi Chen,Wei-Hsin Chen,Chien-Yao Wang,Hong-Yuan Mark Liao,James C. Liao,Chien-Chang Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种新的小鼠疼痛行为自动分析框架，无需人工标注即可准确识别和分类疼痛行为，准确率远超人类专家和现有方法，并能辅助药物研发。


<details>
  <summary>Details</summary>
Motivation: 现有评估慢性疼痛行为的方法依赖人工标注，且对哪些行为最能代表慢性疼痛的理解模糊，难以准确捕捉慢性疼痛中微妙且持续的行为变化。

Method: 提出了一种无需人工标注即可自动提取小鼠疼痛行为特征的框架，利用通用动作空间投影仪提取动作特征，保留视频中的丰富行为信息。

Result: 在15类疼痛分类任务中达到48.41%的准确率，优于人类专家（21.33%）和B-SOiD（30.52%）。在简化为三类（神经性疼痛、炎症性疼痛、无疼痛）的分类任务中，准确率达到73.1%，显著高于人类专家（48%）和B-SOiD（58.43%）。此外，研究还通过零样本测试揭示了药物（加巴喷丁）对不同类型疼痛的疗效差异，且结果与已有文献一致。

Conclusion: 本研究提出的方法在小鼠疼痛行为分类任务中表现出色，尤其是在简化分类至三类时，准确率显著高于人类专家和现有方法B-SOiD。此外，该方法还能揭示不同类型疼痛的药物疗效差异，并与现有文献结果一致，显示出其在临床应用和药物研发方面的潜力。

Abstract: Assessing chronic pain behavior in mice is critical for preclinical studies.
However, existing methods mostly rely on manual labeling of behavioral
features, and humans lack a clear understanding of which behaviors best
represent chronic pain. For this reason, existing methods struggle to
accurately capture the insidious and persistent behavioral changes in chronic
pain. This study proposes a framework to automatically discover features
related to chronic pain without relying on human-defined action labels. Our
method uses universal action space projector to automatically extract mouse
action features, and avoids the potential bias of human labeling by retaining
the rich behavioral information in the original video. In this paper, we also
collected a mouse pain behavior dataset that captures the disease progression
of both neuropathic and inflammatory pain across multiple time points. Our
method achieves 48.41\% accuracy in a 15-class pain classification task,
significantly outperforming human experts (21.33\%) and the widely used method
B-SOiD (30.52\%). Furthermore, when the classification is simplified to only
three categories, i.e., neuropathic pain, inflammatory pain, and no pain, then
our method achieves an accuracy of 73.1\%, which is notably higher than that of
human experts (48\%) and B-SOiD (58.43\%). Finally, our method revealed
differences in drug efficacy for different types of pain on zero-shot
Gabapentin drug testing, and the results were consistent with past drug
efficacy literature. This study demonstrates the potential clinical application
of our method, which can provide new insights into pain research and related
drug development.

</details>


### [43] [Rotation Equivariant Arbitrary-scale Image Super-Resolution](https://arxiv.org/abs/2508.05160)
*Qi Xie,Jiahong Fu,Zongben Xu,Deyu Meng*

Main category: cs.CV

TL;DR: ASISR任务中，为了解决低分辨率图像中的几何模式变形问题，提出了一种新的ASISR方法，通过在INR和编码器模块中嵌入旋转等变性，实现了端到端的旋转等变性，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: ASISR任务中，低分辨率图像中的几何模式（如重复纹理、边缘或形状）常常会发生扭曲和变形，导致恢复的高分辨率图像出现伪影。为了忠实地保持几何模式的原始方向和结构完整性，有必要在ASISR网络中嵌入旋转等变性。

Method: 重新设计了INR和编码器模块，并融入了内在的旋转等变性能力，实现了端到端的旋转等变ASISR方法。

Result: 提出的方法在模拟和真实数据集上的实验证明了其优越性，并且可以即插即用地集成到现有的ASISR方法中以进一步提升性能。

Conclusion: 通过将旋转等变性嵌入到ASISR网络中，首次实现了从输入到输出的端到端旋转等变性，从而提高了几何模式的保真度。

Abstract: The arbitrary-scale image super-resolution (ASISR), a recent popular topic in
computer vision, aims to achieve arbitrary-scale high-resolution recoveries
from a low-resolution input image. This task is realized by representing the
image as a continuous implicit function through two fundamental modules, a
deep-network-based encoder and an implicit neural representation (INR) module.
Despite achieving notable progress, a crucial challenge of such a highly
ill-posed setting is that many common geometric patterns, such as repetitive
textures, edges, or shapes, are seriously warped and deformed in the
low-resolution images, naturally leading to unexpected artifacts appearing in
their high-resolution recoveries. Embedding rotation equivariance into the
ASISR network is thus necessary, as it has been widely demonstrated that this
enhancement enables the recovery to faithfully maintain the original
orientations and structural integrity of geometric patterns underlying the
input image. Motivated by this, we make efforts to construct a rotation
equivariant ASISR method in this study. Specifically, we elaborately redesign
the basic architectures of INR and encoder modules, incorporating intrinsic
rotation equivariance capabilities beyond those of conventional ASISR networks.
Through such amelioration, the ASISR network can, for the first time, be
implemented with end-to-end rotational equivariance maintained from input to
output. We also provide a solid theoretical analysis to evaluate its intrinsic
equivariance error, demonstrating its inherent nature of embedding such an
equivariance structure. The superiority of the proposed method is substantiated
by experiments conducted on both simulated and real datasets. We also validate
that the proposed framework can be readily integrated into current ASISR
methods in a plug \& play manner to further enhance their performance.

</details>


### [44] [X-MoGen: Unified Motion Generation across Humans and Animals](https://arxiv.org/abs/2508.05162)
*Xuan Wang,Kai Ruan,Liyang Qian,Zhizhi Guo,Chang Su,Gaoang Wang*

Main category: cs.CV

TL;DR: X-MoGen is a new framework for generating human and animal motions from text descriptions. It uses a novel two-stage architecture and a large dataset (UniMo4D) to achieve better results than previous methods, even for species not seen during training.


<details>
  <summary>Details</summary>
Motivation: Existing text-driven motion generation methods model human and animal motion separately. A joint cross-species approach offers advantages like unified representation and improved generalization, but morphological differences pose a challenge. X-MoGen addresses this by proposing the first unified framework for cross-species text-driven motion generation.

Method: X-MoGen utilizes a two-stage architecture: a conditional graph variational autoencoder for canonical T-pose priors and an autoencoder for encoding motion into a shared latent space regularized by morphological loss. The second stage involves masked motion modeling for text-conditioned motion generation, with a morphological consistency module ensuring skeletal plausibility across species during training.

Result: The proposed framework, X-MoGen, has been evaluated on the UniMo4D dataset, which contains 115 species and 119k motion sequences. Experiments show that X-MoGen surpasses existing state-of-the-art methods for both seen and unseen species.

Conclusion: X-MoGen outperforms state-of-the-art methods on both seen and unseen species, demonstrating the effectiveness of the unified framework.

Abstract: Text-driven motion generation has attracted increasing attention due to its
broad applications in virtual reality, animation, and robotics. While existing
methods typically model human and animal motion separately, a joint
cross-species approach offers key advantages, such as a unified representation
and improved generalization. However, morphological differences across species
remain a key challenge, often compromising motion plausibility. To address
this, we propose \textbf{X-MoGen}, the first unified framework for
cross-species text-driven motion generation covering both humans and animals.
X-MoGen adopts a two-stage architecture. First, a conditional graph variational
autoencoder learns canonical T-pose priors, while an autoencoder encodes motion
into a shared latent space regularized by morphological loss. In the second
stage, we perform masked motion modeling to generate motion embeddings
conditioned on textual descriptions. During training, a morphological
consistency module is employed to promote skeletal plausibility across species.
To support unified modeling, we construct \textbf{UniMo4D}, a large-scale
dataset of 115 species and 119k motion sequences, which integrates human and
animal motions under a shared skeletal topology for joint training. Extensive
experiments on UniMo4D demonstrate that X-MoGen outperforms state-of-the-art
methods on both seen and unseen species.

</details>


### [45] [PhysPatch: A Physically Realizable and Transferable Adversarial Patch Attack for Multimodal Large Language Models-based Autonomous Driving Systems](https://arxiv.org/abs/2508.05167)
*Qi Guo,Xiaojun Jia,Shanmin Pang,Simeng Qin,Lin Wang,Ju Jia,Yang Liu,Qing Guo*

Main category: cs.CV

TL;DR: 本研究提出了 PhysPatch，一种可物理实现的、可迁移的对抗性补丁框架，专门用于对抗自动驾驶系统中的多模态大语言模型（MLLM）。该方法通过优化补丁的位置、形状和内容，并结合语义初始化、SVD 对齐和势场细化等技术，显著提高了攻击效果和现实世界的可行性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于补丁的攻击方法主要针对目标检测模型，在迁移到具有复杂架构和推理能力的大语言模型（MLLM）为基础的系统时表现不佳。然而，大语言模型（MLLM）容易受到对抗性攻击，特别是对抗性补丁攻击，这在真实世界的自动驾驶场景中构成了严重威胁。

Method: PhysPatch 框架通过联合优化对抗性补丁的位置、形状和内容来增强攻击效果和现实世界适用性。具体而言，它引入了基于语义的掩码初始化策略以实现真实放置，利用基于 SVD 的局部对齐损失和基于补丁的裁剪调整来提高可迁移性，并采用基于势场的方法进行掩码细化。

Result: 实验表明，PhysPatch 在引导基于大语言模型（MLLM）的自动驾驶（AD）系统实现目标对齐的感知和规划输出方面，显著优于先前的方法。此外，PhysPatch 能够将对抗性补丁持续放置在自动驾驶场景中物理上可行的区域，保证了其在现实世界中的应用性和可部署性。

Conclusion: PhysPatch 框架在针对基于大语言模型的多模态大语言模型（MLLM）的自动驾驶（AD）系统中，能够显著优于现有方法，实现对目标感知和规划输出的有效引导，并且在真实世界场景中具有良好的可行性和部署能力。

Abstract: Multimodal Large Language Models (MLLMs) are becoming integral to autonomous
driving (AD) systems due to their strong vision-language reasoning
capabilities. However, MLLMs are vulnerable to adversarial attacks,
particularly adversarial patch attacks, which can pose serious threats in
real-world scenarios. Existing patch-based attack methods are primarily
designed for object detection models and perform poorly when transferred to
MLLM-based systems due to the latter's complex architectures and reasoning
abilities. To address these limitations, we propose PhysPatch, a physically
realizable and transferable adversarial patch framework tailored for MLLM-based
AD systems. PhysPatch jointly optimizes patch location, shape, and content to
enhance attack effectiveness and real-world applicability. It introduces a
semantic-based mask initialization strategy for realistic placement, an
SVD-based local alignment loss with patch-guided crop-resize to improve
transferability, and a potential field-based mask refinement method. Extensive
experiments across open-source, commercial, and reasoning-capable MLLMs
demonstrate that PhysPatch significantly outperforms prior methods in steering
MLLM-based AD systems toward target-aligned perception and planning outputs.
Moreover, PhysPatch consistently places adversarial patches in physically
feasible regions of AD scenes, ensuring strong real-world applicability and
deployability.

</details>


### [46] [Multi-tracklet Tracking for Generic Targets with Adaptive Detection Clustering](https://arxiv.org/abs/2508.05172)
*Zewei Wu,Longhao Wang,Cui Wang,César Teixeira,Wei Ke,Zhang Xiong*

Main category: cs.CV

TL;DR: MTT框架通过短时片段的聚类和多线索关联，解决了在多目标跟踪中遇到的遮挡和低置信度检测等问题。


<details>
  <summary>Details</summary>
Motivation: 在一些真实场景中，由于低置信度检测、弱运动和外观约束以及长期遮挡，未见过的类别常常给现有的方法带来挑战。

Method: MTT框架首先根据检测结果的短期时空相关性自适应地将它们聚类成鲁棒的短片，然后利用位置和外观随时间变化的线索来估计最佳的短片分割，以减轻长期关联中的错误传播。

Result: 在标准的MOT基准测试中，MTT框架相比于其他方法具有竞争力。

Conclusion: 现有的的跟踪方法在处理低置信度检测、弱运动和外观约束以及长期遮挡等问题时面临挑战，而MTT通过集成灵活的短时片段生成到多短片关联框架中，能够自适应地聚类检测结果，并利用位置和外观等多种线索来估计最佳短片分割，从而减轻长期关联中的错误传播，在标准的MOT基准测试中展现出竞争力。

Abstract: Tracking specific targets, such as pedestrians and vehicles, has been the
focus of recent vision-based multitarget tracking studies. However, in some
real-world scenarios, unseen categories often challenge existing methods due to
low-confidence detections, weak motion and appearance constraints, and
long-term occlusions. To address these issues, this article proposes a
tracklet-enhanced tracker called Multi-Tracklet Tracking (MTT) that integrates
flexible tracklet generation into a multi-tracklet association framework. This
framework first adaptively clusters the detection results according to their
short-term spatio-temporal correlation into robust tracklets and then estimates
the best tracklet partitions using multiple clues, such as location and
appearance over time to mitigate error propagation in long-term association.
Finally, extensive experiments on the benchmark for generic multiple object
tracking demonstrate the competitiveness of the proposed framework.

</details>


### [47] [SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation](https://arxiv.org/abs/2508.05182)
*Zhiqing Xiao,Haobo Wang,Xu Lu,Wentao Ye,Gang Chen,Junbo Zhao*

Main category: cs.CV

TL;DR: SPA++ 是一种新的域自适应框架，通过图对齐和邻域传播来提高可辨别性，并在各种场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 以往的域自适应（DA）研究主要关注捕获跨域可迁移性，而忽略了丰富的域内结构，这会影响可辨别性。SPA++ 旨在解决这种权衡问题。

Method: SPA++ 通过将域自适应问题转化为图基元，并结合粗粒度图对齐机制和新颖的谱正则化器来在特征空间中对齐域图。此外，还开发了一种细粒度的邻域感知传播机制来增强目标域的可辨别性。SPA++ 还通过结合数据增强和一致性正则化来适应复杂场景。

Result: 实验结果表明，SPA++ 在基准数据集上持续优于现有的最先进方法。

Conclusion: SPA++ 在各种具有挑战性的适应场景中持续优于现有的最先进方法，并在鲁棒性和适应性方面取得了优异的性能。

Abstract: Domain Adaptation (DA) aims to transfer knowledge from a labeled source
domain to an unlabeled or sparsely labeled target domain under domain shifts.
Most prior works focus on capturing the inter-domain transferability but
largely overlook rich intra-domain structures, which empirically results in
even worse discriminability. To tackle this tradeoff, we propose a generalized
graph SPectral Alignment framework, SPA++. Its core is briefly condensed as
follows: (1)-by casting the DA problem to graph primitives, it composes a
coarse graph alignment mechanism with a novel spectral regularizer toward
aligning the domain graphs in eigenspaces; (2)-we further develop a
fine-grained neighbor-aware propagation mechanism for enhanced discriminability
in the target domain; (3)-by incorporating data augmentation and consistency
regularization, SPA++ can adapt to complex scenarios including most DA settings
and even challenging distribution scenarios. Furthermore, we also provide
theoretical analysis to support our method, including the generalization bound
of graph-based DA and the role of spectral alignment and smoothing consistency.
Extensive experiments on benchmark datasets demonstrate that SPA++ consistently
outperforms existing cutting-edge methods, achieving superior robustness and
adaptability across various challenging adaptation scenarios.

</details>


### [48] [SPEX: A Vision-Language Model for Land Cover Extraction on Spectral Remote Sensing Images](https://arxiv.org/abs/2508.05202)
*Dongchen Si,Di Wang,Erzhong Gao,Xiaolei Qin,Liu Zhao,Jing Zhang,Minqiang Xu,Jianbo Zhan,Jianshe Wang,Lin Liu,Bo Du,Liangpei Zhang*

Main category: cs.CV

TL;DR: SPEX是一个新模型，它利用光谱信息进行土地覆盖提取，效果优于现有方法，并且能解释其预测。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉语言模型在多光谱遥感场景下，光谱信息利用不足导致性能不佳的问题，构建了一个名为SPIE的数据集，将土地覆盖物的光谱先验知识编码为语言模型可识别的文本属性。

Method: 提出了一种名为SPEX的多模态语言模型，并通过多尺度特征聚合、令牌上下文冷凝和多光谱视觉预训练等组件和训练策略，实现了精确灵活的像素级解释。

Result: SPEX在五个公共多光谱数据集上进行了广泛的实验，在提取植被、建筑物和水体等典型土地覆盖类别方面，始终优于现有的最新方法，并且能够生成文本解释以增强可解释性。

Conclusion: SPEX是首个用于光谱遥感图像土地覆盖提取的多模态视觉语言模型。实验表明，SPEX在提取植被、建筑物和水体等典型土地覆盖类别方面，始终优于现有的最新方法。此外，SPEX能够为其预测生成文本解释，从而提高可解释性和用户友好性。

Abstract: Spectral information has long been recognized as a critical cue in remote
sensing observations. Although numerous vision-language models have been
developed for pixel-level interpretation, spectral information remains
underutilized, resulting in suboptimal performance, particularly in
multispectral scenarios. To address this limitation, we construct a
vision-language instruction-following dataset named SPIE, which encodes
spectral priors of land-cover objects into textual attributes recognizable by
large language models (LLMs), based on classical spectral index computations.
Leveraging this dataset, we propose SPEX, a multimodal LLM designed for
instruction-driven land cover extraction. To this end, we introduce several
carefully designed components and training strategies, including multiscale
feature aggregation, token context condensation, and multispectral visual
pre-training, to achieve precise and flexible pixel-level interpretation. To
the best of our knowledge, SPEX is the first multimodal vision-language model
dedicated to land cover extraction in spectral remote sensing imagery.
Extensive experiments on five public multispectral datasets demonstrate that
SPEX consistently outperforms existing state-of-the-art methods in extracting
typical land cover categories such as vegetation, buildings, and water bodies.
Moreover, SPEX is capable of generating textual explanations for its
predictions, thereby enhancing interpretability and user-friendliness. Code
will be released at: https://github.com/MiliLab/SPEX.

</details>


### [49] [EndoMatcher: Generalizable Endoscopic Image Matcher via Multi-Domain Pre-training for Robot-Assisted Surgery](https://arxiv.org/abs/2508.05205)
*Bingyu Yang,Qingyao Tian,Yimeng Geng,Huai Liao,Xinyan Huang,Jiebo Luo,Hongbin Liu*

Main category: cs.CV

TL;DR: EndoMatcher通过大规模多领域预训练解决了内窥镜图像匹配的挑战，在不进行微调的情况下，在多个基准测试中显著优于最先进的方法，并在各种手术场景中实现了零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 为了解决内窥镜图像中通用密集特征匹配的挑战，这些挑战源于视觉条件困难（如弱纹理、大视角变化）和标注数据稀缺，旨在为机器人辅助任务（包括3D重建、导航和手术场景理解）提供可推广的解决方案。

Method: EndoMatcher采用两分支Vision Transformer提取多尺度特征，并通过双交互模块增强以进行鲁棒的对应学习。它还构建了一个包含约120万个真实和合成图像对的“Endo-Mix6”数据集，并采用渐进式多目标训练策略以促进平衡学习和提高跨域表示质量。

Result: EndoMatcher在Hamlyn和Bladder数据集上将内点匹配数比最先进方法分别提高了140.69%和201.43%，在Gastro-Matching数据集上将匹配方向预测准确率（MDPA）提高了9.40%，在具有挑战性的内窥镜条件下实现了密集、准确的匹配。

Conclusion: EndoMatcher在Hamlyn和Bladder数据集上将内点匹配数比最先进方法分别提高了140.69%和201.43%，在Gastro-Matching数据集上将匹配方向预测准确率（MDPA）提高了9.40%，在具有挑战性的内窥镜条件下实现了密集、准确的匹配。

Abstract: Generalizable dense feature matching in endoscopic images is crucial for
robot-assisted tasks, including 3D reconstruction, navigation, and surgical
scene understanding. Yet, it remains a challenge due to difficult visual
conditions (e.g., weak textures, large viewpoint variations) and a scarcity of
annotated data. To address these challenges, we propose EndoMatcher, a
generalizable endoscopic image matcher via large-scale, multi-domain data
pre-training. To address difficult visual conditions, EndoMatcher employs a
two-branch Vision Transformer to extract multi-scale features, enhanced by dual
interaction blocks for robust correspondence learning. To overcome data
scarcity and improve domain diversity, we construct Endo-Mix6, the first
multi-domain dataset for endoscopic matching. Endo-Mix6 consists of
approximately 1.2M real and synthetic image pairs across six domains, with
correspondence labels generated using Structure-from-Motion and simulated
transformations. The diversity and scale of Endo-Mix6 introduce new challenges
in training stability due to significant variations in dataset sizes,
distribution shifts, and error imbalance. To address them, a progressive
multi-objective training strategy is employed to promote balanced learning and
improve representation quality across domains. This enables EndoMatcher to
generalize across unseen organs and imaging conditions in a zero-shot fashion.
Extensive zero-shot matching experiments demonstrate that EndoMatcher increases
the number of inlier matches by 140.69% and 201.43% on the Hamlyn and Bladder
datasets over state-of-the-art methods, respectively, and improves the Matching
Direction Prediction Accuracy (MDPA) by 9.40% on the Gastro-Matching dataset,
achieving dense and accurate matching under challenging endoscopic conditions.
The code is publicly available at https://github.com/Beryl2000/EndoMatcher.

</details>


### [50] [VFlowOpt: A Token Pruning Framework for LMMs with Visual Information Flow-Guided Optimization](https://arxiv.org/abs/2508.05211)
*Sihan Yang,Runsen Xu,Chenhang Cui,Tai Wang,Dahua Lin,Jiangmiao Pang*

Main category: cs.CV

TL;DR: VFlowOpt prunes 90% of visual tokens in LMMs with minimal performance loss, reducing memory usage by 89% and increasing inference speed by 3.8x, through an importance map, progressive pruning with recycling, and a visual information flow-guided optimization.


<details>
  <summary>Details</summary>
Motivation: Large Multimodal Models (LMMs) excel in visual-language tasks but suffer from significant computational costs due to token redundancy. Previous research on pruning visual tokens often results in substantial performance degradation due to simplistic pruning frameworks and strategies.

Method: VFlowOpt is a token pruning framework that introduces an importance map derivation process and a progressive pruning module with a recycling mechanism. The hyperparameters of its pruning strategy are optimized by a visual information flow-guided method. Specifically, it computes an importance map for image tokens based on their attention-derived context relevance and patch-level information entropy. Then, it decides which tokens to retain or prune and aggregates the pruned ones as recycled tokens to avoid potential information loss. Finally, it applies a visual information flow-guided method that regards the last token in the LMM as the most representative signal of text-visual interactions. This method minimizes the discrepancy between token representations in LMMs with and without pruning, thereby enabling superior pruning strategies tailored to different LMMs.

Result: VFlowOpt can prune 90% of visual tokens while maintaining comparable performance, leading to an 89% reduction in KV-Cache memory and 3.8 times faster inference.

Conclusion: VFlowOpt can prune 90% of visual tokens while maintaining comparable performance, leading to an 89% reduction in KV-Cache memory and 3.8 times faster inference.

Abstract: Large Multimodal Models (LMMs) excel in visual-language tasks by leveraging
numerous visual tokens for fine-grained visual information, but this token
redundancy results in significant computational costs. Previous research aimed
at reducing visual tokens during inference typically leverages importance maps
derived from attention scores among vision-only tokens or vision-language
tokens to prune tokens across one or multiple pruning stages. Despite this
progress, pruning frameworks and strategies remain simplistic and
insufficiently explored, often resulting in substantial performance
degradation. In this paper, we propose VFlowOpt, a token pruning framework that
introduces an importance map derivation process and a progressive pruning
module with a recycling mechanism. The hyperparameters of its pruning strategy
are further optimized by a visual information flow-guided method. Specifically,
we compute an importance map for image tokens based on their attention-derived
context relevance and patch-level information entropy. We then decide which
tokens to retain or prune and aggregate the pruned ones as recycled tokens to
avoid potential information loss. Finally, we apply a visual information
flow-guided method that regards the last token in the LMM as the most
representative signal of text-visual interactions. This method minimizes the
discrepancy between token representations in LMMs with and without pruning,
thereby enabling superior pruning strategies tailored to different LMMs.
Experiments demonstrate that VFlowOpt can prune 90% of visual tokens while
maintaining comparable performance, leading to an 89% reduction in KV-Cache
memory and 3.8 times faster inference.

</details>


### [51] [Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2508.05213)
*Jianming Liu,Wenlong Qiu,Haitao Wei*

Main category: cs.CV

TL;DR: 提出了一种创新的源无关跨域少样本分割方法，利用文本和视觉信息通过TSAA、VVEA和TVEA模块进行目标域自适应，在多个数据集上取得了优于现有方法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有跨域少样本分割（CD-FSS）方法主要在源域上开发分割模型以实现跨域泛化。然而，出于对数据隐私的担忧以及最小化数据传输和训练成本的需要，源无关CD-FSS方法变得至关重要。

Method: 提出了一种源无关的跨域少样本分割方法，该方法利用文本和视觉信息进行目标域任务自适应。具体包括：1.将任务特定注意力适配器（TSAA）附加到预训练骨干网络的特征金字塔上，以自适应目标任务的多级特征。2.通过视觉-视觉嵌入对齐（VVEA）和文本-视觉嵌入对齐（TVEA）模块训练TSAA的参数，其中VVEA利用全局-局部视觉特征对齐图像特征，TVEA利用预对齐的多模态特征（如CLIP）的文本先验指导跨模态自适应。3.通过密集比较操作和跳过连接融合，生成精炼的预测掩码。

Result: 在1-shot和5-shot设置下，所提出的方法在四个跨域数据集上平均分割准确率分别提高了2.18%和4.11%，显著优于最先进的CD-FSS方法。

Conclusion: 该方法通过引入任务特定注意力适配器（TSAA）、视觉-视觉嵌入对齐（VVEA）和文本-视觉嵌入对齐（TVEA）模块，成功实现了在无需源域数据的情况下进行跨域少样本分割，并在四个跨域数据集上取得了显著的性能提升。

Abstract: Few-Shot Segmentation(FSS) aims to efficient segmentation of new objects with
few labeled samples. However, its performance significantly degrades when
domain discrepancies exist between training and deployment. Cross-Domain
Few-Shot Segmentation(CD-FSS) is proposed to mitigate such performance
degradation. Current CD-FSS methods primarily sought to develop segmentation
models on a source domain capable of cross-domain generalization. However,
driven by escalating concerns over data privacy and the imperative to minimize
data transfer and training expenses, the development of source-free CD-FSS
approaches has become essential. In this work, we propose a source-free CD-FSS
method that leverages both textual and visual information to facilitate target
domain task adaptation without requiring source domain data. Specifically, we
first append Task-Specific Attention Adapters (TSAA) to the feature pyramid of
a pretrained backbone, which adapt multi-level features extracted from the
shared pre-trained backbone to the target task. Then, the parameters of the
TSAA are trained through a Visual-Visual Embedding Alignment (VVEA) module and
a Text-Visual Embedding Alignment (TVEA) module. The VVEA module utilizes
global-local visual features to align image features across different views,
while the TVEA module leverages textual priors from pre-aligned multi-modal
features (e.g., from CLIP) to guide cross-modal adaptation. By combining the
outputs of these modules through dense comparison operations and subsequent
fusion via skip connections, our method produces refined prediction masks.
Under both 1-shot and 5-shot settings, the proposed approach achieves average
segmentation accuracy improvements of 2.18\% and 4.11\%, respectively, across
four cross-domain datasets, significantly outperforming state-of-the-art CD-FSS
methods. Code are available at https://github.com/ljm198134/TVGTANet.

</details>


### [52] [ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking](https://arxiv.org/abs/2508.05221)
*Xiao Wang,Liye Jin,Xufeng Lou,Shiao Wang,Lan Chen,Bo Jiang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为ReasoningTrack的新型视觉语言跟踪框架，利用预训练大模型Qwen2.5-VL，结合SFT和GRPO优化推理与语言生成，并通过新数据集TNLLT验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言跟踪方法在处理目标变化时存在局限性，要么直接融合固定的语言与视觉特征，要么仅使用注意力机制进行修改，性能提升有限。一些利用文本生成适应目标变化的研究未能提供模型推理过程的洞察，且未充分利用大模型的优势。

Method: 提出了一种新颖的基于推理的视觉语言跟踪框架ReasoningTrack，该框架基于预训练的视觉语言模型Qwen2.5-VL。框架同时采用了监督微调（SFT）和强化学习GRPO进行推理和语言生成优化。将更新后的语言描述与视觉特征一起输入统一的跟踪骨干网络，并通过跟踪头预测目标对象的具体位置。此外，还构建了一个大规模的长期视觉语言跟踪基准数据集TNLLT，包含200个视频序列，并重新训练和评估了20个基线视觉跟踪器。

Result: 所提出的方法在多个视觉语言跟踪基准数据集上的实验结果充分验证了其有效性。

Conclusion: 通过引入基于推理的自然语言生成策略，在多个视觉语言跟踪基准数据集上进行了广泛的实验，充分验证了所提出方法的有效性。

Abstract: Vision-language tracking has received increasing attention in recent years,
as textual information can effectively address the inflexibility and inaccuracy
associated with specifying the target object to be tracked. Existing works
either directly fuse the fixed language with vision features or simply modify
using attention, however, their performance is still limited. Recently, some
researchers have explored using text generation to adapt to the variations in
the target during tracking, however, these works fail to provide insights into
the model's reasoning process and do not fully leverage the advantages of large
models, which further limits their overall performance. To address the
aforementioned issues, this paper proposes a novel reasoning-based
vision-language tracking framework, named ReasoningTrack, based on a
pre-trained vision-language model Qwen2.5-VL. Both SFT (Supervised Fine-Tuning)
and reinforcement learning GRPO are used for the optimization of reasoning and
language generation. We embed the updated language descriptions and feed them
into a unified tracking backbone network together with vision features. Then,
we adopt a tracking head to predict the specific location of the target object.
In addition, we propose a large-scale long-term vision-language tracking
benchmark dataset, termed TNLLT, which contains 200 video sequences. 20
baseline visual trackers are re-trained and evaluated on this dataset, which
builds a solid foundation for the vision-language visual tracking task.
Extensive experiments on multiple vision-language tracking benchmark datasets
fully validated the effectiveness of our proposed reasoning-based natural
language generation strategy. The source code of this paper will be released on
https://github.com/Event-AHU/Open_VLTrack

</details>


### [53] [Segmenting the Complex and Irregular in Two-Phase Flows: A Real-World Empirical Study with SAM2](https://arxiv.org/abs/2508.05227)
*Semanur Küçük,Cosimo Della Santina,Angeliki Laskari*

Main category: cs.CV

TL;DR: A Segment Anything Model (SAM v2.1) fine-tuned with minimal data can accurately segment complex, non-spherical gas bubbles, overcoming limitations of previous methods.


<details>
  <summary>Details</summary>
Motivation: Segmenting deformed, coalesced, or broken gas bubbles in multiphase flows is crucial for industrial applications like metallurgical processing and maritime drag reduction, but traditional and existing learning-based methods struggle with non-spherical shapes found in systems like air lubrication.

Method: Transfer learning using a fine-tuned Segment Anything Model (SAM) v2.1, casting the task as a transfer learning problem.

Result: Demonstrated accurate segmentation of highly non-convex, irregular bubble structures with as few as 100 annotated images.

Conclusion: Fine-tuned SAM v2.1 can accurately segment highly non-convex, irregular gas bubble structures using minimal annotated images, outperforming traditional and other learning-based methods that assume near-spherical shapes.

Abstract: Segmenting gas bubbles in multiphase flows is a critical yet unsolved
challenge in numerous industrial settings, from metallurgical processing to
maritime drag reduction. Traditional approaches-and most recent learning-based
methods-assume near-spherical shapes, limiting their effectiveness in regimes
where bubbles undergo deformation, coalescence, or breakup. This complexity is
particularly evident in air lubrication systems, where coalesced bubbles form
amorphous and topologically diverse patches. In this work, we revisit the
problem through the lens of modern vision foundation models. We cast the task
as a transfer learning problem and demonstrate, for the first time, that a
fine-tuned Segment Anything Model SAM v2.1 can accurately segment highly
non-convex, irregular bubble structures using as few as 100 annotated images.

</details>


### [54] [ArbiViewGen: Controllable Arbitrary Viewpoint Camera Data Generation for Autonomous Driving via Stable Diffusion Models](https://arxiv.org/abs/2508.05236)
*Yatong Lan,Jingfeng Chen,Yiru Wang,Lei He*

Main category: cs.CV

TL;DR: Arbiviewgen uses diffusion models, view stitching, and self-supervised learning to generate arbitrary viewpoint images for autonomous driving, even without ground-truth data for new views.


<details>
  <summary>Details</summary>
Motivation: Arbitrary viewpoint image generation is important for autonomous driving but is difficult due to the lack of ground-truth data for extrapolated views, hindering the training of high-fidelity generative models.

Method: The paper proposes Arbiviewgen, a diffusion-based framework for generating controllable camera images from arbitrary viewpoints. It addresses the lack of ground-truth data using Feature-Aware Adaptive View Stitching (FAVS) for geometric correspondence and alignment, and Cross-View Consistency Self-Supervised Learning (CVC-SSL) for training a diffusion model to reconstruct original views from stitched images, enforcing consistency without extrapolated data.

Result: The framework enables controllable arbitrary view camera image generation using only multi-camera images and their poses, eliminating the need for extra sensors or depth maps.

Conclusion: Arbiviewgen is the first method capable of controllable arbitrary view camera image generation in multiple vehicle configurations, requiring only multi-camera images and their associated poses for training.

Abstract: Arbitrary viewpoint image generation holds significant potential for
autonomous driving, yet remains a challenging task due to the lack of
ground-truth data for extrapolated views, which hampers the training of
high-fidelity generative models. In this work, we propose Arbiviewgen, a novel
diffusion-based framework for the generation of controllable camera images from
arbitrary points of view. To address the absence of ground-truth data in unseen
views, we introduce two key components: Feature-Aware Adaptive View Stitching
(FAVS) and Cross-View Consistency Self-Supervised Learning (CVC-SSL). FAVS
employs a hierarchical matching strategy that first establishes coarse
geometric correspondences using camera poses, then performs fine-grained
alignment through improved feature matching algorithms, and identifies
high-confidence matching regions via clustering analysis. Building upon this,
CVC-SSL adopts a self-supervised training paradigm where the model reconstructs
the original camera views from the synthesized stitched images using a
diffusion model, enforcing cross-view consistency without requiring supervision
from extrapolated data. Our framework requires only multi-camera images and
their associated poses for training, eliminating the need for additional
sensors or depth maps. To our knowledge, Arbiviewgen is the first method
capable of controllable arbitrary view camera image generation in multiple
vehicle configurations.

</details>


### [55] [Navigating the Trade-off: A Synthesis of Defensive Strategies for Zero-Shot Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2508.05237)
*Zane Xu,Jason Sun*

Main category: cs.CV

TL;DR: 本文分析了视觉-语言模型（VLM）的零样本对抗鲁棒性，重点关注对抗性微调（AFT）和无需训练/测试时防御。研究了从TeCoA、LAAT、TIMA到AOM、TTC、CLIPure等方法的演变，并指出了混合防御和对抗性预训练的未来方向。


<details>
  <summary>Details</summary>
Motivation: 合成关于视觉-语言模型（VLM）如CLIP的零样本对抗鲁棒性的八篇开创性论文，并分析了增强鲁棒性和保持零样本泛化能力之间的固有权衡这一核心挑战。

Method: 分析了两种主要的防御范式：对抗性微调（AFT）和无需训练/测试时防御。内容涵盖了从保持对齐的方法（TeCoA）到嵌入空间再工程（LAAT, TIMA），再到输入启发式（AOM, TTC）和潜在空间纯化（CLIPure）的演变。

Result: 梳理了对抗性鲁棒性和零样本泛化之间的权衡，并概述了现有防御方法的演变。

Conclusion: 未来研究方向包括混合防御策略和对抗性预训练。

Abstract: This report synthesizes eight seminal papers on the zero-shot adversarial
robustness of vision-language models (VLMs) like CLIP. A central challenge in
this domain is the inherent trade-off between enhancing adversarial robustness
and preserving the model's zero-shot generalization capabilities. We analyze
two primary defense paradigms: Adversarial Fine-Tuning (AFT), which modifies
model parameters, and Training-Free/Test-Time Defenses, which preserve them. We
trace the evolution from alignment-preserving methods (TeCoA) to embedding
space re-engineering (LAAT, TIMA), and from input heuristics (AOM, TTC) to
latent-space purification (CLIPure). Finally, we identify key challenges and
future directions including hybrid defense strategies and adversarial
pre-training.

</details>


### [56] [RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding](https://arxiv.org/abs/2508.05244)
*Tianchen Fang,Guiru Liu*

Main category: cs.CV

TL;DR: RegionMed-CLIP是一个创新的框架，通过整合局部病理信息和全局语义，并利用大规模标注数据，显著提升了医学图像理解能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学图像理解中存在的两个主要挑战：高质量标注的医学数据有限，以及过度依赖容易忽略细微病理区域的全局图像特征，该研究提出了RegionMed-CLIP。

Method: RegionMed-CLIP是一个区域感知的多模态对比学习框架，它结合了局部病理信号和整体语义表示。其核心是一个创新的感兴趣区域（ROI）处理器，该处理器通过渐进式训练策略将细粒度的区域特征与全局上下文自适应地集成起来，以增强多模态对齐。此外，研究人员构建了一个名为MedRegion-500k的全面医学图像-文本语料库，其中包含广泛的区域注释和多级临床描述，以实现大规模的区域级表示学习。

Result: 实验结果表明，RegionMed-CLIP在图像-文本检索、零样本分类和视觉问答任务上，始终显著优于最先进的视觉语言模型，凸显了区域感知对比预训练的关键作用，并为推动多模态医学图像理解奠定了坚实的基础。

Conclusion: RegionMed-CLIP

Abstract: Medical image understanding plays a crucial role in enabling automated
diagnosis and data-driven clinical decision support. However, its progress is
impeded by two primary challenges: the limited availability of high-quality
annotated medical data and an overreliance on global image features, which
often miss subtle but clinically significant pathological regions. To address
these issues, we introduce RegionMed-CLIP, a region-aware multimodal
contrastive learning framework that explicitly incorporates localized
pathological signals along with holistic semantic representations. The core of
our method is an innovative region-of-interest (ROI) processor that adaptively
integrates fine-grained regional features with the global context, supported by
a progressive training strategy that enhances hierarchical multimodal
alignment. To enable large-scale region-level representation learning, we
construct MedRegion-500k, a comprehensive medical image-text corpus that
features extensive regional annotations and multilevel clinical descriptions.
Extensive experiments on image-text retrieval, zero-shot classification, and
visual question answering tasks demonstrate that RegionMed-CLIP consistently
exceeds state-of-the-art vision language models by a wide margin. Our results
highlight the critical importance of region-aware contrastive pre-training and
position RegionMed-CLIP as a robust foundation for advancing multimodal medical
image understanding.

</details>


### [57] [A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis](https://arxiv.org/abs/2508.05246)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 该研究对性别分类方法进行了全面的概述，重点是基于面部和虹膜的方法，为研究人员提供了见解和未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 性别分类在监控、公司分析和人机交互等各种应用中都很有吸引力，因为性别信息可以揭示个人的身份。该研究旨在为研究人员提供对现有性别分类方法的知识和分析。

Method: 该研究回顾了性别分类的多种方法，重点关注基于面部特征和虹膜的方法，并讨论了不同性别分类步骤的各种方法。

Result: 该研究审查了几种性别分类方法，并讨论了用于性别分类不同步骤的各种方法。

Conclusion: 该研究提供了对现有性别分类方法的知识和分析，为研究人员提供了该领域的指导，并指出了该领域的差距和挑战，最后提供了改进的建议和未来方向。

Abstract: Gender classification is attractive in a range of applications, including
surveillance and monitoring, corporate profiling, and human-computer
interaction. Individuals' identities may be gleaned from information about
their gender, which is a kind of soft biometric.Over the years, several methods
for determining a person's gender have been devised. Some of the most
well-known ones are based on physical characteristics like face, fingerprint,
palmprint, DNA, ears, gait, and iris. On the other hand, facial features
account for the vast majority of gender classification methods. Also, the iris
is a significant biometric trait because the iris, according to research,
remains basically constant during an individual's life. Besides that, the iris
is externally visible and is non-invasive to the user, which is important for
practical applications. Furthermore, there are already high-quality methods for
segmenting and encoding iris images, and the current methods facilitate
selecting and extracting attribute vectors from iris textures. This study
discusses several approaches to determining gender. The previous works of
literature are briefly reviewed. Additionally, there are a variety of
methodologies for different steps of gender classification. This study provides
researchers with knowledge and analysis of the existing gender classification
approaches. Also, it will assist researchers who are interested in this
specific area, as well as highlight the gaps and challenges in the field, and
finally provide suggestions and future paths for improvement.

</details>


### [58] [CF3: Compact and Fast 3D Feature Fields](https://arxiv.org/abs/2508.05254)
*Hyunjoon Lee,Joonkyu Min,Jaesik Park*

Main category: cs.CV

TL;DR: CF3是一种新的3D高斯特征场构建方法，通过自顶向下流程和自适应稀疏化，显著减少了计算成本和高斯数量，同时保持了细节。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法依赖于自底向上的优化，将2D特征视为真实值，导致计算成本增加。

Method: 提出了一种自顶向下的流程，首先通过加权融合多视角2D特征与预训练高斯，然后训练了每个高斯的自编码器，最后通过自适应稀疏化优化属性并裁剪冗余高斯。

Result: CF3实现了一个具有竞争力的3D特征场，高斯数量比Feature-3DGS少95%，同时保留了几何细节。

Conclusion: CF3通过自编码器和自适应稀疏化方法，实现了高效且保留几何细节的3D高斯特征场，相较于Feature-3DGS，高斯数量减少高达95%。

Abstract: 3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D
foundation models. However, most approaches rely on a bottom-up optimization
process that treats raw 2D features as ground truth, incurring increased
computational costs. We propose a top-down pipeline for constructing compact
and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast
weighted fusion of multi-view 2D features with pre-trained Gaussians. This
approach enables training a per-Gaussian autoencoder directly on the lifted
features, instead of training autoencoders in the 2D domain. As a result, the
autoencoder better aligns with the feature distribution. More importantly, we
introduce an adaptive sparsification method that optimizes the Gaussian
attributes of the feature field while pruning and merging the redundant
Gaussians, constructing an efficient representation with preserved geometric
details. Our approach achieves a competitive 3D feature field using as little
as 5% of the Gaussians compared to Feature-3DGS.

</details>


### [59] [Robust Tracking with Particle Filtering for Fluorescent Cardiac Imaging](https://arxiv.org/abs/2508.05262)
*Suresh Guttikonda,Maximilian Neidhart,Johanna Sprenger,Johannes Petersen,Christian Detter,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 一种新的粒子滤波跟踪器，用于心脏手术中的荧光成像，提高了跟踪精度和速度。


<details>
  <summary>Details</summary>
Motivation: 传统的跟踪方法受心脏运动和血管结构富集引起的光照变化影响，难以准确跟踪。为解决此问题，提出一种新的跟踪方法。

Method: 提出了一种基于循环一致性检查的粒子滤波跟踪器，通过跟踪局部特征点来估计局部量化指标，如心脏灌注。

Result: 该方法能够同时跟踪117个目标，速度为25.4帧/秒，实现了每秒25.4帧的实时估计。跟踪误差为(5.00 +/- 0.22 px)，优于其他深度学习跟踪器(22.3 +/- 1.1 px)和传统跟踪器(58.1 +/- 27.1 px)。

Conclusion: 提出的基于循环一致性检查的粒子滤波跟踪器能够鲁棒地跟踪目标样点，实现对冠状动脉搭桥手术后心脏灌注的实时估计。

Abstract: Intraoperative fluorescent cardiac imaging enables quality control following
coronary bypass grafting surgery. We can estimate local quantitative
indicators, such as cardiac perfusion, by tracking local feature points.
However, heart motion and significant fluctuations in image characteristics
caused by vessel structural enrichment limit traditional tracking methods. We
propose a particle filtering tracker based on cyclicconsistency checks to
robustly track particles sampled to follow target landmarks. Our method tracks
117 targets simultaneously at 25.4 fps, allowing real-time estimates during
interventions. It achieves a tracking error of (5.00 +/- 0.22 px) and
outperforms other deep learning trackers (22.3 +/- 1.1 px) and conventional
trackers (58.1 +/- 27.1 px).

</details>


### [60] [MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs](https://arxiv.org/abs/2508.05502)
*Yufei Gao,Jiaying Fei,Nuo Chen,Ruirui Chen,Guohang Yan,Yunshi Lan,Botian Shi*

Main category: cs.CV

TL;DR: MELLA 数据集通过双源策略（网络原生 alt-text 和 MLLM 生成的标题）提升了 MLLM 在低资源语言上的表现，同时增强了语言能力和文化接地性，实现了“厚描述”。


<details>
  <summary>Details</summary>
Motivation: 目前的多语言 MLLM 方法在低资源语言上效果不佳，现有方法往往局限于文本模式或依赖机器翻译，忽略了多模态信息和文化接地性的重要性。为了有效服务低资源语言用户，需要解决这些问题。

Method: 提出了一种双源策略，利用网络原生 alt-text 来获取文化信息，并利用 MLLM 生成的标题来提升语言能力，以实现语言能力和文化接地性这两个双重目标。具体实现方式是引入了一个名为 MELLA 的多模态、多语言数据集。

Result: 在 MELLA 数据集上进行微调后，MLLM 在八种低资源语言上的性能得到了普遍提升，能够生成更丰富的“厚描述”，证明了该方法在增强文化知识和语言能力方面的有效性。

Conclusion:  MELLA 数据集在八种语言的 MLLM 主干上进行了微调后，性能普遍提高，模型能够生成“厚描述”。通过实验验证了性能提升同时来源于文化知识增强和语言能力增强。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable performance in
high-resource languages. However, their effectiveness diminishes significantly
in the contexts of low-resource languages. Current multilingual enhancement
methods are often limited to text modality or rely solely on machine
translation. While such approaches help models acquire basic linguistic
capabilities and produce "thin descriptions", they neglect the importance of
multimodal informativeness and cultural groundedness, both of which are crucial
for serving low-resource language users effectively. To bridge this gap, in
this study, we identify two significant objectives for a truly effective MLLM
in low-resource language settings, namely 1) linguistic capability and 2)
cultural groundedness, placing special emphasis on cultural awareness. To
achieve these dual objectives, we propose a dual-source strategy that guides
the collection of data tailored to each goal, sourcing native web alt-text for
culture and MLLM-generated captions for linguistics. As a concrete
implementation, we introduce MELLA, a multimodal, multilingual dataset.
Experiment results show that after fine-tuning on MELLA, there is a general
performance improvement for the eight languages on various MLLM backbones, with
models producing "thick descriptions". We verify that the performance gains are
from both cultural knowledge enhancement and linguistic capability enhancement.
Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.

</details>


### [61] [SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible Image Fusion](https://arxiv.org/abs/2508.05264)
*Xiaoyang Zhang,Zhen Hua,Yakun Ju,Wei Zhou,Jun Liu,Alex C. Kot*

Main category: cs.CV

TL;DR: SGDFuse是一种以SAM为指导的条件化扩散模型，用于红外与可见光图像融合。它通过利用SAM生成的语义掩码来指导融合过程，以解决现有方法在保留关键目标和避免伪影方面的问题。实验证明SGDFuse在提高图像质量和下游任务性能方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的红外与可见光图像融合（IVIF）方法往往由于缺乏对场景的深度语义理解而无法保留关键目标，并且融合过程本身可能引入伪影和细节丢失，从而严重影响图像质量和任务性能。本研究旨在解决这些问题。

Method: SGDFuse采用一种条件化扩散模型，并以分割一切模型（SAM）为指导，通过生成高质量的语义掩码作为先验，引导融合过程的优化。该框架分两个阶段进行：首先进行初步的多模态特征融合，然后利用SAM生成的语义掩码和初步融合的图像作为条件，驱动扩散模型的由粗到精去噪生成。

Result: SGDFuse在主观和客观评估以及适应下游任务方面均取得了最先进的性能，为图像融合中的核心挑战提供了有效的解决方案。

Conclusion: SGDFuse

Abstract: Infrared and visible image fusion (IVIF) aims to combine the thermal
radiation information from infrared images with the rich texture details from
visible images to enhance perceptual capabilities for downstream visual tasks.
However, existing methods often fail to preserve key targets due to a lack of
deep semantic understanding of the scene, while the fusion process itself can
also introduce artifacts and detail loss, severely compromising both image
quality and task performance. To address these issues, this paper proposes
SGDFuse, a conditional diffusion model guided by the Segment Anything Model
(SAM), to achieve high-fidelity and semantically-aware image fusion. The core
of our method is to utilize high-quality semantic masks generated by SAM as
explicit priors to guide the optimization of the fusion process via a
conditional diffusion model. Specifically, the framework operates in a
two-stage process: it first performs a preliminary fusion of multi-modal
features, and then utilizes the semantic masks from SAM jointly with the
preliminary fused image as a condition to drive the diffusion model's
coarse-to-fine denoising generation. This ensures the fusion process not only
has explicit semantic directionality but also guarantees the high fidelity of
the final result. Extensive experiments demonstrate that SGDFuse achieves
state-of-the-art performance in both subjective and objective evaluations, as
well as in its adaptability to downstream tasks, providing a powerful solution
to the core challenges in image fusion. The code of SGDFuse is available at
https://github.com/boshizhang123/SGDFuse.

</details>


### [62] [B4DL: A Benchmark for 4D LiDAR LLM in Spatio-Temporal Understanding](https://arxiv.org/abs/2508.05269)
*Changho Choi,Youngwoo Shin,Gyojin Han,Dong-Jae Lee,Junmo Kim*

Main category: cs.CV

TL;DR: B4DL是一个处理4D LiDAR数据的新基准和模型，用于训练MLLM在动态户外环境中进行时空推理。


<details>
  <summary>Details</summary>
Motivation: 为了解决4D LiDAR在MLLM领域中缺乏高质量、特定模态的注释以及MLLM架构无法处理其高维组合的问题。

Method: 提出了一种可扩展的数据生成流程和一个能够直接处理原始4D LiDAR数据并结合语言理解的MLLM模型。

Result: B4DL是一个专门用于训练和评估MLLM在4D LiDAR理解方面的新基准，并提供了该领域的一个MLLM模型。

Conclusion: B4DL提供了一个统一的解决方案，用于动态户外环境中的时空推理。

Abstract: Understanding dynamic outdoor environments requires capturing complex object
interactions and their evolution over time. LiDAR-based 4D point clouds provide
precise spatial geometry and rich temporal cues, making them ideal for
representing real-world scenes. However, despite their potential, 4D LiDAR
remains underexplored in the context of Multimodal Large Language Models
(MLLMs) due to the absence of high-quality, modality-specific annotations and
the lack of MLLM architectures capable of processing its high-dimensional
composition. To address these challenges, we introduce B4DL, a new benchmark
specifically designed for training and evaluating MLLMs on 4D LiDAR
understanding. In addition, we propose a scalable data generation pipeline and
an MLLM model that, for the first time, directly processes raw 4D LiDAR by
bridging it with language understanding. Combined with our dataset and
benchmark, our model offers a unified solution for spatio-temporal reasoning in
dynamic outdoor environments. We provide rendered 4D LiDAR videos, generated
dataset, and inference outputs on diverse scenarios at:
https://mmb4dl.github.io/mmb4dl/

</details>


### [63] [Wavelet-Guided Dual-Frequency Encoding for Remote Sensing Change Detection](https://arxiv.org/abs/2508.05271)
*Xiaoyang Zhang,Guodong Fan,Guang-Yong Chen,Zhen Hua,Jinjiang Li,Min Gan,C. L. Philip Chen*

Main category: cs.CV

TL;DR: The proposed Wavelet-Guided Dual-Frequency Encoding (WGDF) method utilizes wavelet transform to model frequency-domain features, enhancing the detection of subtle changes and edge details in remote sensing imagery compared to traditional spatial-domain methods.


<details>
  <summary>Details</summary>
Motivation: Most existing methods rely on spatial-domain modeling, where the limited diversity of feature representations hinders the detection of subtle change regions. Wavelet domain frequency-domain feature modeling can amplify fine-grained differences in frequency components, enhancing the perception of edge changes.

Method:  WGDF first applies Discrete Wavelet Transform (DWT) to decompose the input images into high-frequency and low-frequency components. The high-frequency branch uses a Dual-Frequency Feature Enhancement (DFFE) module to strengthen edge detail representation and a Frequency-Domain Interactive Difference (FDID) module to enhance the modeling of fine-grained changes. The low-frequency branch uses Transformers to capture global semantic relationships and a Progressive Contextual Difference Module (PCDM) to progressively refine change regions. Finally, the high- and low-frequency features are fused.

Result: Extensive experiments on multiple remote sensing datasets demonstrate that WGDF significantly alleviates edge ambiguity and achieves superior detection accuracy and robustness compared to state-of-the-art methods.

Conclusion:  WGDF significantly alleviates edge ambiguity and achieves superior detection accuracy and robustness compared to state-of-the-art methods.

Abstract: Change detection in remote sensing imagery plays a vital role in various
engineering applications, such as natural disaster monitoring, urban expansion
tracking, and infrastructure management. Despite the remarkable progress of
deep learning in recent years, most existing methods still rely on
spatial-domain modeling, where the limited diversity of feature representations
hinders the detection of subtle change regions. We observe that
frequency-domain feature modeling particularly in the wavelet domain an amplify
fine-grained differences in frequency components, enhancing the perception of
edge changes that are challenging to capture in the spatial domain. Thus, we
propose a method called Wavelet-Guided Dual-Frequency Encoding (WGDF).
Specifically, we first apply Discrete Wavelet Transform (DWT) to decompose the
input images into high-frequency and low-frequency components, which are used
to model local details and global structures, respectively. In the
high-frequency branch, we design a Dual-Frequency Feature Enhancement (DFFE)
module to strengthen edge detail representation and introduce a
Frequency-Domain Interactive Difference (FDID) module to enhance the modeling
of fine-grained changes. In the low-frequency branch, we exploit Transformers
to capture global semantic relationships and employ a Progressive Contextual
Difference Module (PCDM) to progressively refine change regions, enabling
precise structural semantic characterization. Finally, the high- and
low-frequency features are synergistically fused to unify local sensitivity
with global discriminability. Extensive experiments on multiple remote sensing
datasets demonstrate that WGDF significantly alleviates edge ambiguity and
achieves superior detection accuracy and robustness compared to
state-of-the-art methods. The code will be available at
https://github.com/boshizhang123/WGDF.

</details>


### [64] [VS-LLM: Visual-Semantic Depression Assessment based on LLM for Drawing Projection Test](https://arxiv.org/abs/2508.05299)
*Meiqi Wu,Yaxuan Kang,Xuchen Li,Shiyu Hu,Xiaotang Chen,Yunfeng Kang,Weiqiang Wang,Kaiqi Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为VS-LLM的自动化方法，利用大语言模型分析“摘苹果”素描，以更高效、更准确地评估心理健康状况（特别是抑郁症），实验证明其效果优于传统的人工评估。


<details>
  <summary>Details</summary>
Motivation: 为了解决艺术治疗中“一个人从树上摘苹果”（PPAT）测试的解释过程耗时且依赖于心理学家经验的问题，提出了一种自动化的识别方法，以支持大规模的PPAT测试分析。

Method: 提出了一种名为视觉-语义大语言模型（VS-LLM）的自动化识别方法，用于分析“一个人从树上摘苹果”（PPAT）素描的整体特征（如颜色使用和空间利用），以评估个体的心理状态（如抑郁症）。

Result: 提出的VS-LLM方法在抑郁症评估方面比传统心理学家评估方法提高了17.6%的准确率。

Conclusion: 该研究提出了一种基于视觉-语义大语言模型（VS-LLM）的心理评估方法，通过分析“一个人从树上摘苹果”（PPAT）的素描来辅助心理学家评估个体的心理状态，特别是在抑郁症评估方面。实验结果表明，该方法比传统心理学家评估方法提高了17.6%的评估准确率。

Abstract: The Drawing Projection Test (DPT) is an essential tool in art therapy,
allowing psychologists to assess participants' mental states through their
sketches. Specifically, through sketches with the theme of "a person picking an
apple from a tree (PPAT)", it can be revealed whether the participants are in
mental states such as depression. Compared with scales, the DPT can enrich
psychologists' understanding of an individual's mental state. However, the
interpretation of the PPAT is laborious and depends on the experience of the
psychologists. To address this issue, we propose an effective identification
method to support psychologists in conducting a large-scale automatic DPT.
Unlike traditional sketch recognition, DPT more focus on the overall evaluation
of the sketches, such as color usage and space utilization. Moreover, PPAT
imposes a time limit and prohibits verbal reminders, resulting in low drawing
accuracy and a lack of detailed depiction. To address these challenges, we
propose the following efforts: (1) Providing an experimental environment for
automated analysis of PPAT sketches for depression assessment; (2) Offering a
Visual-Semantic depression assessment based on LLM (VS-LLM) method; (3)
Experimental results demonstrate that our method improves by 17.6% compared to
the psychologist assessment method. We anticipate that this work will
contribute to the research in mental state assessment based on PPAT sketches'
elements recognition. Our datasets and codes are available at
https://github.com/wmeiqi/VS-LLM.

</details>


### [65] [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](https://arxiv.org/abs/2508.05606)
*Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li*

Main category: cs.CV

TL;DR: Uni-CoT 是一个统一的框架，通过两级推理（宏观和微观）和结构化训练，解决了视觉-语言推理中的挑战，并在各项基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链（CoT）方法在扩展到视觉-语言推理任务时面临挑战，因为它们难以解释视觉状态的转换，并且可能由于碎片化的架构而导致视觉轨迹不连贯。

Method: Uni-CoT 是一个统一的思维链（CoT）框架，通过利用能够进行图像理解和生成的模型，在统一模型内实现连贯和基于视觉的多模态推理。它采用了新颖的两级推理范式：宏观层面 CoT 用于高级任务规划，微观层面 CoT 用于子任务执行，以降低计算开销。此外，它还采用了结构化训练范式，结合了宏观层面 CoT 的交错图像-文本监督和微观层面 CoT 的多任务目标。

Result: Uni-CoT 实现了最先进的性能和强大的泛化能力，并且所有实验均可在每个 80GB VRAM 的 8 个 A100 GPU 上高效完成。

Conclusion: Uni-CoT 在 WISE、RISE 和 KRIS 等推理驱动的图像生成和编辑基准测试中取得了最先进的性能和强大的泛化能力，证明了其作为多模态推理的有效解决方案。

Abstract: Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large
Language Models (LLMs) by decomposing complex tasks into simpler, sequential
subtasks. However, extending CoT to vision-language reasoning tasks remains
challenging, as it often requires interpreting transitions of visual states to
support reasoning. Existing methods often struggle with this due to limited
capacity of modeling visual state transitions or incoherent visual trajectories
caused by fragmented architectures.
  To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought
framework that enables coherent and grounded multimodal reasoning within a
single unified model. The key idea is to leverage a model capable of both image
understanding and generation to reason over visual content and model evolving
visual states. However, empowering a unified model to achieve that is
non-trivial, given the high computational cost and the burden of training. To
address this, Uni-CoT introduces a novel two-level reasoning paradigm: A
Macro-Level CoT for high-level task planning and A Micro-Level CoT for subtask
execution. This design significantly reduces the computational overhead.
Furthermore, we introduce a structured training paradigm that combines
interleaved image-text supervision for macro-level CoT with multi-task
objectives for micro-level CoT. Together, these innovations allow Uni-CoT to
perform scalable and coherent multi-modal reasoning. Furthermore, thanks to our
design, all experiments can be efficiently completed using only 8 A100 GPUs
with 80GB VRAM each. Experimental results on reasoning-driven image generation
benchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT
demonstrates SOTA performance and strong generalization, establishing Uni-CoT
as a promising solution for multi-modal reasoning. Project Page and Code:
https://sais-fuxi.github.io/projects/uni-cot/

</details>


### [66] [CoCAViT: Compact Vision Transformer with Robust Global Coordination](https://arxiv.org/abs/2508.05307)
*Xuyang Wang,Lingjuan Miao,Zhiqiang Zhou*

Main category: cs.CV

TL;DR: CoCAViT通过CoCA机制解决了高效视觉模型在OOD数据上泛化能力不足的问题，并在多个任务上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有高效视觉模型在分布外（OOD）数据上存在显著的性能下降问题，表明其泛化能力不足。

Method: 提出了一种名为Coordinator-patch Cross Attention (CoCA) 的机制，该机制引入了动态的、域感知的全局令牌，以增强局部-全局特征建模，并以最小的计算开销自适应地捕获跨域的鲁棒模式。

Result: CoCAViT-28M在224*224分辨率下，在ImageNet-1K上达到了84.0%的top-1准确率，并在多个OOD基准测试上相比现有模型有显著提升，同时在COCO对象检测上达到52.2 mAP，在ADE20K语义分割上达到51.3 mIOU，且保持低延迟。

Conclusion: CoCAViT是一种新颖的视觉骨干网络，通过CoCA机制增强了小模型的泛化能力和鲁棒性，在ImageNet-1K、COCO和ADE20K等多个基准测试中表现出色，同时保持低延迟。

Abstract: In recent years, large-scale visual backbones have demonstrated remarkable
capabilities in learning general-purpose features from images via extensive
pre-training. Concurrently, many efficient architectures have emerged that have
performance comparable to that of larger models on in-domain benchmarks.
However, we observe that for smaller models, the performance drop on
out-of-distribution (OOD) data is disproportionately larger, indicating a
deficiency in the generalization performance of existing efficient models. To
address this, we identify key architectural bottlenecks and inappropriate
design choices that contribute to this issue, retaining robustness for smaller
models. To restore the global field of pure window attention, we further
introduce a Coordinator-patch Cross Attention (CoCA) mechanism, featuring
dynamic, domain-aware global tokens that enhance local-global feature modeling
and adaptively capture robust patterns across domains with minimal
computational overhead. Integrating these advancements, we present CoCAViT, a
novel visual backbone designed for robust real-time visual representation.
Extensive experiments empirically validate our design. At a resolution of
224*224, CoCAViT-28M achieves 84.0% top-1 accuracy on ImageNet-1K, with
significant gains on multiple OOD benchmarks, compared to competing models. It
also attains 52.2 mAP on COCO object detection and 51.3 mIOU on ADE20K semantic
segmentation, while maintaining low latency.

</details>


### [67] [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](https://arxiv.org/abs/2508.05615)
*Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen*

Main category: cs.CV

TL;DR: This paper introduces GUI-RC and GUI-RCPO, novel test-time methods that improve GUI grounding accuracy by leveraging consistency among model predictions, reducing reliance on costly annotations and enhancing agent performance.


<details>
  <summary>Details</summary>
Motivation: Existing GUI grounding methods are constrained by the cost and availability of pixel-level annotations. The proposed methods leverage implicit confidence signals from spatial overlap patterns in multiple predictions to guide more accurate localization.

Method: GUI-RC (Region Consistency) constructs spatial voting grids from multiple sampled predictions to identify consensus regions, improving accuracy without training. GUI-RCPO transforms these consistency patterns into rewards for test-time reinforcement learning, enabling iterative refinement of outputs on unlabeled data during inference.

Result: GUI-RC improves accuracy by 2-3% across various architectures on ScreenSpot benchmarks. GUI-RCPO further improves performance, boosting Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% with GUI-RC and to 85.14% with GUI-RCPO on ScreenSpot-v2.

Conclusion: GUI-RC and GUI-RCPO demonstrate the untapped potential of test-time scaling and reinforcement learning for GUI grounding, offering a promising path toward more robust and data-efficient GUI agents.

Abstract: Graphical User Interface (GUI) grounding, the task of mapping natural
language instructions to precise screen coordinates, is fundamental to
autonomous GUI agents. While existing methods achieve strong performance
through extensive supervised training or reinforcement learning with labeled
rewards, they remain constrained by the cost and availability of pixel-level
annotations. We observe that when models generate multiple predictions for the
same GUI element, the spatial overlap patterns reveal implicit confidence
signals that can guide more accurate localization. Leveraging this insight, we
propose GUI-RC (Region Consistency), a test-time scaling method that constructs
spatial voting grids from multiple sampled predictions to identify consensus
regions where models show highest agreement. Without any training, GUI-RC
improves accuracy by 2-3% across various architectures on ScreenSpot
benchmarks. We further introduce GUI-RCPO (Region Consistency Policy
Optimization), which transforms these consistency patterns into rewards for
test-time reinforcement learning. By computing how well each prediction aligns
with the collective consensus, GUI-RCPO enables models to iteratively refine
their outputs on unlabeled data during inference. Extensive experiments
demonstrate the generality of our approach: GUI-RC boosts
Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO
further improves it to 85.14% through self-supervised optimization. Our
approach reveals the untapped potential of test-time scaling and test-time
reinforcement learning for GUI grounding, offering a promising path toward more
robust and data-efficient GUI agents.

</details>


### [68] [mKG-RAG: Multimodal Knowledge Graph-Enhanced RAG for Visual Question Answering](https://arxiv.org/abs/2508.05318)
*Xu Yuan,Liangbo Ning,Wenqi Fan,Qing Li*

Main category: cs.CV

TL;DR: 提出 mKG-RAG 框架，利用多模态知识图谱增强 RAG 在视觉问答任务中的表现，通过改进的检索策略提高了答案的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有 RAG 方法在处理非结构化文档时引入不相关或误导性内容，从而降低答案准确性和可靠性的挑战，本研究提出将多模态知识图谱集成到 RAG 框架中，通过引入结构化多模态知识来增强生成。

Method: 提出了一种新颖的多模态知识增强生成框架（mKG-RAG），利用 MLLM 驱动的关键词提取和视觉-文本匹配从多模态文档中提取语义一致且模态对齐的实体/关系，构建高质量的多模态知识图谱作为结构化知识表示。此外，还引入了一种配备有问询感知多模态检索器的双阶段检索策略，以提高检索效率和精度。

Result: 实验结果表明，该方法显著优于现有方法，为知识库视觉问答设定了新的最先进水平。

Conclusion: 该方法在知识密集型视觉问答任务上显著优于现有方法，达到了新的最先进水平。

Abstract: Recently, Retrieval-Augmented Generation (RAG) has been proposed to expand
internal knowledge of Multimodal Large Language Models (MLLMs) by incorporating
external knowledge databases into the generation process, which is widely used
for knowledge-based Visual Question Answering (VQA) tasks. Despite impressive
advancements, vanilla RAG-based VQA methods that rely on unstructured documents
and overlook the structural relationships among knowledge elements frequently
introduce irrelevant or misleading content, reducing answer accuracy and
reliability. To overcome these challenges, a promising solution is to integrate
multimodal knowledge graphs (KGs) into RAG-based VQA frameworks to enhance the
generation by introducing structured multimodal knowledge. Therefore, in this
paper, we propose a novel multimodal knowledge-augmented generation framework
(mKG-RAG) based on multimodal KGs for knowledge-intensive VQA tasks.
Specifically, our approach leverages MLLM-powered keyword extraction and
vision-text matching to distill semantically consistent and modality-aligned
entities/relationships from multimodal documents, constructing high-quality
multimodal KGs as structured knowledge representations. In addition, a
dual-stage retrieval strategy equipped with a question-aware multimodal
retriever is introduced to improve retrieval efficiency while refining
precision. Comprehensive experiments demonstrate that our approach
significantly outperforms existing methods, setting a new state-of-the-art for
knowledge-based VQA.

</details>


### [69] [Textual Inversion for Efficient Adaptation of Open-Vocabulary Object Detectors Without Forgetting](https://arxiv.org/abs/2508.05323)
*Frank Ruis,Gertjan Burghouts,Hugo Kuijf*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent progress in large pre-trained vision language models (VLMs) has
reached state-of-the-art performance on several object detection benchmarks and
boasts strong zero-shot capabilities, but for optimal performance on specific
targets some form of finetuning is still necessary. While the initial VLM
weights allow for great few-shot transfer learning, this usually involves the
loss of the original natural language querying and zero-shot capabilities.
Inspired by the success of Textual Inversion (TI) in personalizing
text-to-image diffusion models, we propose a similar formulation for
open-vocabulary object detection. TI allows extending the VLM vocabulary by
learning new or improving existing tokens to accurately detect novel or
fine-grained objects from as little as three examples. The learned tokens are
completely compatible with the original VLM weights while keeping them frozen,
retaining the original model's benchmark performance, and leveraging its
existing capabilities such as zero-shot domain transfer (e.g., detecting a
sketch of an object after training only on real photos). The storage and
gradient calculations are limited to the token embedding dimension, requiring
significantly less compute than full-model fine-tuning. We evaluated whether
the method matches or outperforms the baseline methods that suffer from
forgetting in a wide variety of quantitative and qualitative experiments.

</details>


### [70] [3DGabSplat: 3D Gabor Splatting for Frequency-adaptive Radiance Field Rendering](https://arxiv.org/abs/2508.05343)
*Junyu Zhou,Yuyang Huang,Wenrui Dai,Junni Zou,Ziyang Zheng,Nuowen Kan,Chenglin Li,Hongkai Xiong*

Main category: cs.CV

TL;DR: 3DGabSplat通过使用3D Gabor基元取代3DGS中的高斯基元，提高了高频细节的表示能力、训练效率和内存效率，并在新视角合成方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）方法虽然实现了实时渲染和高保真新视角合成，但其低通性质的高斯函数在表示高频细节方面存在局限性。这导致了冗余的基元、训练和渲染效率的下降以及过大的内存开销。

Method: 提出了一种名为3D Gabor Splatting (3DGabSplat) 的新方法，该方法使用新颖的3D Gabor基元来表示辐射场。该基元具有多方向3D频率响应，能够捕捉高频细节。通过结合不同频率的3D Gabor核，形成一个滤波器组，提高了表示的灵活性和效率。此外，开发了一个高效的CUDA光栅化器，将3D Gabor基元的多方向3D频率分量投影到2D图像平面，并提出了一个频率自适应机制来联合优化基元。

Result: 3DGabSplat在渲染质量上超越了3DGS及其变体，在真实世界和合成场景中均达到了最先进的水平。与3DGS相比，3DGabSplat实现了高达1.35 dB的PSNR增益，同时减少了基元数量和内存占用。

Conclusion: 3DGabSplat通过利用新颖的3D Gabor基元、多方向3D频率响应以及高效的CUDA光栅化器和频率自适应机制，克服了3D高斯泼溅（3DGS）在表示高频细节、训练效率和内存开销方面的限制。实验证明，3DGabSplat在渲染质量和效率方面优于现有的3DGS方法及其变体，实现了最先进的性能，并显著减少了基元数量和内存消耗。

Abstract: Recent prominence in 3D Gaussian Splatting (3DGS) has enabled real-time
rendering while maintaining high-fidelity novel view synthesis. However, 3DGS
resorts to the Gaussian function that is low-pass by nature and is restricted
in representing high-frequency details in 3D scenes. Moreover, it causes
redundant primitives with degraded training and rendering efficiency and
excessive memory overhead. To overcome these limitations, we propose 3D Gabor
Splatting (3DGabSplat) that leverages a novel 3D Gabor-based primitive with
multiple directional 3D frequency responses for radiance field representation
supervised by multi-view images. The proposed 3D Gabor-based primitive forms a
filter bank incorporating multiple 3D Gabor kernels at different frequencies to
enhance flexibility and efficiency in capturing fine 3D details. Furthermore,
to achieve novel view rendering, an efficient CUDA-based rasterizer is
developed to project the multiple directional 3D frequency components
characterized by 3D Gabor-based primitives onto the 2D image plane, and a
frequency-adaptive mechanism is presented for adaptive joint optimization of
primitives. 3DGabSplat is scalable to be a plug-and-play kernel for seamless
integration into existing 3DGS paradigms to enhance both efficiency and quality
of novel view synthesis. Extensive experiments demonstrate that 3DGabSplat
outperforms 3DGS and its variants using alternative primitives, and achieves
state-of-the-art rendering quality across both real-world and synthetic scenes.
Remarkably, we achieve up to 1.35 dB PSNR gain over 3DGS with simultaneously
reduced number of primitives and memory consumption.

</details>


### [71] [PriorRG: Prior-Guided Contrastive Pre-training and Coarse-to-Fine Decoding for Chest X-ray Report Generation](https://arxiv.org/abs/2508.05353)
*Kang Liu,Zhuoqi Ma,Zikang Fang,Yunan Li,Kun Xie,Qiguang Miao*

Main category: cs.CV

TL;DR: 本文提出了PriorRG框架，通过整合患者临床背景和历史影像等先验知识，利用两阶段训练（对比预训练和粗到细解码）来生成更准确、更流畅的胸部X光报告，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多仅从单张图像生成报告，忽略了患者特定的先验知识（如临床背景和最近的先验影像），而这些知识对于放射科医生进行诊断推理至关重要。本文旨在弥合这一差距，使模型能够捕捉诊断意图和疾病进展。

Method: 提出了一种名为PriorRG的新颖框架，采用两阶段训练流程。第一阶段引入了先验引导对比预训练方案，利用临床背景信息指导时空特征提取，使模型能更好地与放射学报告中的时空语义对齐。第二阶段提出了一种先验感知粗到细解码方法，用于报告生成，该方法逐步将患者特定的先验知识与视觉编码器的隐藏状态相结合。

Result: PriorRG框架在MIMIC-CXR和MIMIC-ABN数据集上进行了广泛实验，结果表明其在BLEU-4、F1分数和BLEU-1分数上均取得了显著提升，优于现有最先进方法。

Conclusion: PriorRG框架在MIMIC-CXR和MIMIC-ABN数据集上展现出优于现有最先进方法的性能，在MIMIC-CXR上BLEU-4和F1分数分别提高了3.6%和3.8%，在MIMIC-ABN上BLEU-1分数提高了5.9%，有效提升了生成报告的临床准确性和流畅性。

Abstract: Chest X-ray report generation aims to reduce radiologists' workload by
automatically producing high-quality preliminary reports. A critical yet
underexplored aspect of this task is the effective use of patient-specific
prior knowledge -- including clinical context (e.g., symptoms, medical history)
and the most recent prior image -- which radiologists routinely rely on for
diagnostic reasoning. Most existing methods generate reports from single
images, neglecting this essential prior information and thus failing to capture
diagnostic intent or disease progression. To bridge this gap, we propose
PriorRG, a novel chest X-ray report generation framework that emulates
real-world clinical workflows via a two-stage training pipeline. In Stage 1, we
introduce a prior-guided contrastive pre-training scheme that leverages
clinical context to guide spatiotemporal feature extraction, allowing the model
to align more closely with the intrinsic spatiotemporal semantics in radiology
reports. In Stage 2, we present a prior-aware coarse-to-fine decoding for
report generation that progressively integrates patient-specific prior
knowledge with the vision encoder's hidden states. This decoding allows the
model to align with diagnostic focus and track disease progression, thereby
enhancing the clinical accuracy and fluency of the generated reports. Extensive
experiments on MIMIC-CXR and MIMIC-ABN datasets demonstrate that PriorRG
outperforms state-of-the-art methods, achieving a 3.6% BLEU-4 and 3.8% F1 score
improvement on MIMIC-CXR, and a 5.9% BLEU-1 gain on MIMIC-ABN. Code and
checkpoints will be released upon acceptance.

</details>


### [72] [Cross-View Localization via Redundant Sliced Observations and A-Contrario Validation](https://arxiv.org/abs/2508.05369)
*Yongjun Zhang,Mingtao Xiong,Yi Wan,Gui-Song Xia*

Main category: cs.CV

TL;DR: Slice-Loc 是一种新的 CVL 方法，它将图像分割成块以生成冗余观测，从而提高定位精度和可靠性评估能力。它通过几何刚性过滤和 NFA 量化来处理错误，并将平均定位误差降低了 60% 以上。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的跨视图定位（CVL）方法仅输出单一观测（相机位姿），缺乏测量学原理所需的冗余观测，难以通过观测数据的相互验证来评估定位可靠性。

Method: Slice-Loc 是一种两阶段方法，包含一个适用于 CVL 的 a-contrario 可靠性验证。它将查询图像分割成子图像，为每个子图像估计 3-DoF 位姿，生成冗余和独立的观测。然后，提出了一种几何刚性公式来过滤错误的 3-DoF 位姿，并将内点合并以生成最终的相机位姿。此外，还提出了一种通过估计假警报数（NFA）来量化定位有意义程度的模型，该模型基于切片图像位置的分布。

Result: Slice-Loc 将超过 10 米的误差比例降低到 3% 以下。在 DReSS 数据集上的跨城市测试中，Slice-Loc 将平均定位误差从 4.47 米降低到 1.86 米，平均方向误差从 3.42 度降低到 1.24 度，优于最先进的方法。

Conclusion: Slice-Loc 通过生成冗余观测来解决现有跨视图定位（CVL）方法缺乏对定位可靠性进行评估的问题。它通过将查询图像分割成子图像并估计每个子图像的 3-DoF 位姿，然后使用几何刚性公式过滤错误位姿，最后合并内点来估计最终的相机位姿。该方法通过量化本地化过程中的有意义程度（通过估计错误警报数 NFA）来提高定位精度和故障检测能力。与最先进的方法相比，Slice-Loc 将平均定位误差从 4.47 米降低到 1.86 米，平均方向误差从 3.42 度降低到 1.24 度，并将超过 10 米的误差比例降低到 3% 以下。

Abstract: Cross-view localization (CVL) matches ground-level images with aerial
references to determine the geo-position of a camera, enabling smart vehicles
to self-localize offline in GNSS-denied environments. However, most CVL methods
output only a single observation, the camera pose, and lack the redundant
observations required by surveying principles, making it challenging to assess
localization reliability through the mutual validation of observational data.
To tackle this, we introduce Slice-Loc, a two-stage method featuring an
a-contrario reliability validation for CVL. Instead of using the query image as
a single input, Slice-Loc divides it into sub-images and estimates the 3-DoF
pose for each slice, creating redundant and independent observations. Then, a
geometric rigidity formula is proposed to filter out the erroneous 3-DoF poses,
and the inliers are merged to generate the final camera pose. Furthermore, we
propose a model that quantifies the meaningfulness of localization by
estimating the number of false alarms (NFA), according to the distribution of
the locations of the sliced images. By eliminating gross errors, Slice-Loc
boosts localization accuracy and effectively detects failures. After filtering
out mislocalizations, Slice-Loc reduces the proportion of errors exceeding 10 m
to under 3\%. In cross-city tests on the DReSS dataset, Slice-Loc cuts the mean
localization error from 4.47 m to 1.86 m and the mean orientation error from
$\mathbf{3.42^{\circ}}$ to $\mathbf{1.24^{\circ}}$, outperforming
state-of-the-art methods. Code and dataset will be available at:
https://github.com/bnothing/Slice-Loc.

</details>


### [73] [CT-GRAPH: Hierarchical Graph Attention Network for Anatomy-Guided CT Report Generation](https://arxiv.org/abs/2508.05375)
*Hamza Kalisch,Fabian Hörst,Jens Kleesiek,Ken Herrmann,Constantin Seibold*

Main category: cs.CV

TL;DR: CT-GRAPH 是一种新的图注意力网络，通过结合医学影像的解剖结构信息和大型语言模型，提高了医学影像报告生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 目前的医学影像报告生成方法主要依赖全局图像特征，未能捕捉到准确报告所需的精细器官关系，而放射科医生面临着繁重的工作量，因此需要自动化报告生成来辅助他们。

Method: CT-GRAPH 是一种分层图注意力网络，它通过构建解剖区域图并将细粒度的器官特征与更粗略的解剖系统和全局患者背景联系起来，显式地模拟放射学知识。该方法利用预训练的 3D 医学特征编码器，并通过解剖掩码获取全局和器官级别的特征，这些特征在图中进一步细化，然后整合到大型语言模型中以生成详细的医学报告。

Result: 在大型胸部 CT 数据集 CT-RATE 上进行的评估显示，CT-GRAPH 在 F1 分数上相较于现有最先进的方法有绝对的 7.9% 的提升。

Conclusion: CT-GRAPH 通过显式地将解剖区域构建成图并整合语言模型，在胸部 CT 报告生成任务上取得了显著的改进，F1 分数相较于现有最先进的方法提高了 7.9%。

Abstract: As medical imaging is central to diagnostic processes, automating the
generation of radiology reports has become increasingly relevant to assist
radiologists with their heavy workloads. Most current methods rely solely on
global image features, failing to capture fine-grained organ relationships
crucial for accurate reporting. To this end, we propose CT-GRAPH, a
hierarchical graph attention network that explicitly models radiological
knowledge by structuring anatomical regions into a graph, linking fine-grained
organ features to coarser anatomical systems and a global patient context. Our
method leverages pretrained 3D medical feature encoders to obtain global and
organ-level features by utilizing anatomical masks. These features are further
refined within the graph and then integrated into a large language model to
generate detailed medical reports. We evaluate our approach for the task of
report generation on the large-scale chest CT dataset CT-RATE. We provide an
in-depth analysis of pretrained feature encoders for CT report generation and
show that our method achieves a substantial improvement of absolute 7.9\% in F1
score over current state-of-the-art methods. The code is publicly available at
https://github.com/hakal104/CT-GRAPH.

</details>


### [74] [Deformable Attention Graph Representation Learning for Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2508.05382)
*Mingxi Fu,Xitong Ling,Yuxuan Chen,Jiawen Li,fanglei fu,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: A new GNN with deformable attention that uses dynamic graphs and spatial offsets improves pathology image analysis by better capturing spatial relationships in tissue structures, achieving top results on multiple datasets.


<details>
  <summary>Details</summary>
Motivation: Mainstream Multiple Instance Learning (MIL) approaches struggle to capture spatial dependencies among tissue structures in Whole Slide Images (WSIs). Existing Graph Neural Networks (GNNs) often overlook the physical spatial positions of tissue patches and employ conventional attention mechanisms that lack specificity.

Method: A novel GNN framework with deformable attention is proposed. It constructs a dynamic weighted directed graph based on patch features, where each node aggregates contextual information from its neighbors via attention-weighted edges. Learnable spatial offsets informed by patch coordinates are incorporated to adaptively attend to morphologically relevant regions.

Result: The framework achieves state-of-the-art performance on four benchmark datasets: TCGA-COAD, BRACS, gastric intestinal metaplasia grading, and intestinal ROI classification.

Conclusion: The proposed GNN framework with deformable attention achieves state-of-the-art performance on four benchmark datasets, demonstrating its effectiveness in capturing complex spatial structures in WSIs and ROIs.

Abstract: Accurate classification of Whole Slide Images (WSIs) and Regions of Interest
(ROIs) is a fundamental challenge in computational pathology. While mainstream
approaches often adopt Multiple Instance Learning (MIL), they struggle to
capture the spatial dependencies among tissue structures. Graph Neural Networks
(GNNs) have emerged as a solution to model inter-instance relationships, yet
most rely on static graph topologies and overlook the physical spatial
positions of tissue patches. Moreover, conventional attention mechanisms lack
specificity, limiting their ability to focus on structurally relevant regions.
In this work, we propose a novel GNN framework with deformable attention for
pathology image analysis. We construct a dynamic weighted directed graph based
on patch features, where each node aggregates contextual information from its
neighbors via attention-weighted edges. Specifically, we incorporate learnable
spatial offsets informed by the real coordinates of each patch, enabling the
model to adaptively attend to morphologically relevant regions across the
slide. This design significantly enhances the contextual field while preserving
spatial specificity. Our framework achieves state-of-the-art performance on
four benchmark datasets (TCGA-COAD, BRACS, gastric intestinal metaplasia
grading, and intestinal ROI classification), demonstrating the power of
deformable attention in capturing complex spatial structures in WSIs and ROIs.

</details>


### [75] [UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation](https://arxiv.org/abs/2508.05399)
*Wonjun Kang,Byeongkeun Ahn,Minjae Lee,Kevin Galim,Seunghyuk Oh,Hyung Il Koo,Nam Ik Cho*

Main category: cs.CV

TL;DR: UNCAGE 是一种无需训练的方法，可提高掩蔽生成 Transformer 在文本到图像生成中的组合保真度。


<details>
  <summary>Details</summary>
Motivation: 掩蔽生成 Transformer 在组合文本到图像生成方面存在与扩散模型类似的挑战，即难以准确绑定属性和实现适当的文本-图像对齐。尽管扩散模型已被广泛研究，但掩蔽生成 Transformer 在此背景下尚未得到探索。

Method: UNCAGE 通过利用注意图来优先揭开清晰表示单个对象的 token，从而提高组合保真度。

Result: UNCAGE 在多个基准和度量上的一致性地提高了定量和定性评估的性能，并且推理开销可忽略不计。

Conclusion: UNCAGE 是一种新颖的、无需训练的方法，通过利用注意图来优先揭开清晰表示单个对象的 token，从而提高组合保真度。 UNCAGE 在多个基准和度量上的一致性地提高了定量和定性评估的性能，并且推理开销可忽略不计。

Abstract: Text-to-image (T2I) generation has been actively studied using Diffusion
Models and Autoregressive Models. Recently, Masked Generative Transformers have
gained attention as an alternative to Autoregressive Models to overcome the
inherent limitations of causal attention and autoregressive decoding through
bidirectional attention and parallel decoding, enabling efficient and
high-quality image generation. However, compositional T2I generation remains
challenging, as even state-of-the-art Diffusion Models often fail to accurately
bind attributes and achieve proper text-image alignment. While Diffusion Models
have been extensively studied for this issue, Masked Generative Transformers
exhibit similar limitations but have not been explored in this context. To
address this, we propose Unmasking with Contrastive Attention Guidance
(UNCAGE), a novel training-free method that improves compositional fidelity by
leveraging attention maps to prioritize the unmasking of tokens that clearly
represent individual objects. UNCAGE consistently improves performance in both
quantitative and qualitative evaluations across multiple benchmarks and
metrics, with negligible inference overhead. Our code is available at
https://github.com/furiosa-ai/uncage.

</details>


### [76] [From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization](https://arxiv.org/abs/2508.05409)
*Farah Wahida,M. A. P. Chamikara,Yashothara Shanmugarasa,Mohan Baruwal Chhetri,Thilina Ranbaduge,Ibrahim Khalil*

Main category: cs.CV

TL;DR: TrueBiometric is a novel approach that accurately detects and corrects poisoned images in biometric systems using multiple large vision language models and targeted corrective noise, offering a practical and effective solution against backdoor attacks.


<details>
  <summary>Details</summary>
Motivation: Biometric systems, such as face recognition systems powered by deep neural networks (DNNs), rely on large and highly sensitive datasets. Backdoor attacks can subvert these systems by manipulating the training process. By inserting a small trigger, such as a sticker, make-up, or patterned mask, into a few training images, an adversary can later present the same trigger during authentication to be falsely recognized as another individual, thereby gaining unauthorized access. Existing defense mechanisms against backdoor attacks still face challenges in precisely identifying and mitigating poisoned images without compromising data utility, which undermines the overall reliability of the system.

Method: TrueBiometric

Result: TrueBiometric detects and corrects poisoned images with 100% accuracy without compromising accuracy on clean images. Compared to existing state-of-the-art approaches, TrueBiometric offers a more practical, accurate, and effective solution for mitigating backdoor attacks in face recognition systems.

Conclusion: TrueBiometric

Abstract: Biometric systems, such as face recognition systems powered by deep neural
networks (DNNs), rely on large and highly sensitive datasets. Backdoor attacks
can subvert these systems by manipulating the training process. By inserting a
small trigger, such as a sticker, make-up, or patterned mask, into a few
training images, an adversary can later present the same trigger during
authentication to be falsely recognized as another individual, thereby gaining
unauthorized access. Existing defense mechanisms against backdoor attacks still
face challenges in precisely identifying and mitigating poisoned images without
compromising data utility, which undermines the overall reliability of the
system. We propose a novel and generalizable approach, TrueBiometric:
Trustworthy Biometrics, which accurately detects poisoned images using a
majority voting mechanism leveraging multiple state-of-the-art large vision
language models. Once identified, poisoned samples are corrected using targeted
and calibrated corrective noise. Our extensive empirical results demonstrate
that TrueBiometric detects and corrects poisoned images with 100\% accuracy
without compromising accuracy on clean images. Compared to existing
state-of-the-art approaches, TrueBiometric offers a more practical, accurate,
and effective solution for mitigating backdoor attacks in face recognition
systems.

</details>


### [77] [Physical Adversarial Camouflage through Gradient Calibration and Regularization](https://arxiv.org/abs/2508.05414)
*Jiawei Liang,Siyuan Liang,Jianjie Huang,Chenxi Si,Ming Zhang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出了一种新的对抗性迷彩框架，通过梯度校准和梯度解相关来解决物理对抗性迷彩中的不一致采样和梯度冲突问题，从而提高对深度物体检测器的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 物理对抗性迷彩对自动驾驶等安全关键领域构成了重大安全风险，因为它们会改变物体纹理以欺骗检测器。现有技术在多变的环境中存在挑战：1）跨距离不一致的采样点密度阻碍了确保局部连续性的梯度优化；2）从多个角度更新纹理梯度会导致冲突，降低优化稳定性和攻击效果。

Method: 提出了一种基于梯度优化的新型对抗性迷彩框架。首先，引入梯度校准策略，通过将梯度从稀疏采样点传播到未采样点，确保跨距离的一致梯度更新。其次，开发了梯度解相关方法，根据损失值对梯度进行优先级排序和正交化，通过消除冗余或冲突的更新来增强多角度优化中的稳定性和有效性。

Result: 在各种检测模型、角度和距离上进行的广泛实验结果表明，该方法显著优于现有技术。

Conclusion: 该方法显著超越了最先进的技术，在跨距离和跨角度的平均攻击成功率（ASR）方面分别提高了13.46%和11.03%。实际场景中的经验评估强调了对更鲁棒的系统设计的需求。

Abstract: The advancement of deep object detectors has greatly affected safety-critical
fields like autonomous driving. However, physical adversarial camouflage poses
a significant security risk by altering object textures to deceive detectors.
Existing techniques struggle with variable physical environments, facing two
main challenges: 1) inconsistent sampling point densities across distances
hinder the gradient optimization from ensuring local continuity, and 2)
updating texture gradients from multiple angles causes conflicts, reducing
optimization stability and attack effectiveness. To address these issues, we
propose a novel adversarial camouflage framework based on gradient
optimization. First, we introduce a gradient calibration strategy, which
ensures consistent gradient updates across distances by propagating gradients
from sparsely to unsampled texture points. Additionally, we develop a gradient
decorrelation method, which prioritizes and orthogonalizes gradients based on
loss values, enhancing stability and effectiveness in multi-angle optimization
by eliminating redundant or conflicting updates. Extensive experimental results
on various detection models, angles and distances show that our method
significantly exceeds the state of the art, with an average increase in attack
success rate (ASR) of 13.46% across distances and 11.03% across angles.
Furthermore, empirical evaluation in real-world scenarios highlights the need
for more robust system design.

</details>


### [78] [Smoothing Slot Attention Iterations and Recurrences](https://arxiv.org/abs/2508.05417)
*Rongzhen Zhao,Wenyan Yang,Juho Kannala,Joni Pajarinen*

Main category: cs.CV

TL;DR: SmoothSA通过预热查询和区分帧变换，优化了对象中心学习中Slot Attention的冷启动和跨帧传递问题，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Slot Attention (SA)的对象中心学习方法在处理视频时，其冷启动查询缺乏样本特异性线索，影响了在视频首帧的精确聚合；同时，非首帧的查询已经具备样本特异性，需要与首帧不同的变换方式。为了解决这些问题，需要一种能够平滑SA迭代和跨帧传递的方法。

Method: SmoothSA通过两个关键技术优化了Slot Attention (SA)的冷启动和跨帧传递问题：1. 预热查询：在图像或视频的第一帧，通过一个微小的自蒸馏模块为冷启动查询注入丰富的输入特征信息，以平滑SA迭代过程。2. 区分变换：在视频的非首帧，区分于首帧的聚合方式，使用单次迭代来平滑SA的跨帧传递。

Result: 通过在物体发现、识别和下游基准测试中的综合实验，证明了SmoothSA的有效性。进一步的分析直观地阐明了该方法如何平滑SA的迭代和跨帧传递。

Conclusion: 所提出的SmoothSA方法通过预热冷启动查询和区分不同帧的变换来优化基于Transformer的对象中心学习方法，并在多个基准测试中验证了其有效性。

Abstract: Slot Attention (SA) and its variants lie at the heart of mainstream
Object-Centric Learning (OCL). Objects in an image can be aggregated into
respective slot vectors, by \textit{iteratively} refining cold-start query
vectors, typically three times, via SA on image features. For video, such
aggregation is \textit{recurrently} shared across frames, with queries
cold-started on the first frame while transitioned from the previous frame's
slots on non-first frames. However, the cold-start queries lack sample-specific
cues thus hinder precise aggregation on the image or video's first frame; Also,
non-first frames' queries are already sample-specific thus require transforms
different from the first frame's aggregation. We address these issues for the
first time with our \textit{SmoothSA}: (1) To smooth SA iterations on the image
or video's first frame, we \textit{preheat} the cold-start queries with rich
information of input features, via a tiny module self-distilled inside OCL; (2)
To smooth SA recurrences across all video frames, we \textit{differentiate} the
homogeneous transforms on the first and non-first frames, by using full and
single iterations respectively. Comprehensive experiments on object discovery,
recognition and downstream benchmarks validate our method's effectiveness.
Further analyses intuitively illuminate how our method smooths SA iterations
and recurrences. Our code is available in the supplement.

</details>


### [79] [Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions](https://arxiv.org/abs/2508.05430)
*Hubert Baniecki,Maximilian Muschalik,Fabian Fumagalli,Barbara Hammer,Eyke Hüllermeier,Przemyslaw Biecek*

Main category: cs.CV

TL;DR: FIxLIP 是一种新的解释方法，用于视觉-语言模型，它使用博弈论来捕捉跨模态交互，并在准确性和模型比较方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（LIP）解释方法（如显著图）只能捕捉一阶归因，忽略了模型内在的复杂跨模态交互。FIxLIP 旨在提供一种更全面的解释方法，以捕捉这些交互。

Method: FIxLIP 是一种基于博弈论的方法，利用加权 Banzhaf 交互指数来量化视觉-语言模型中跨模态交互的贡献。它扩展了现有的解释评估指标，如指向游戏和插入/删除曲线之间的区域，以适应二阶交互解释。

Result: FIxLIP 在 MS COCO 和 ImageNet-1k 数据集上的实验证明，其解释质量优于一阶归因方法。此外，FIxLIP 还可用于比较 CLIP 和 SigLIP-2、ViT-B/32 和 ViT-L/16 等不同模型。

Conclusion: FIxLIP 作为一种统一的方法，通过分析加权 Banzhaf 交互指数来分解视觉-语言编码器的相似性，并且在计算效率和灵活性方面优于 Shapley 交互量化框架。FIxLIP 还可以通过指向游戏和插入/删除曲线之间的区域等指标进行评估。在 MS COCO 和 ImageNet-1k 基准测试上的实验表明，FIxLIP 等二阶方法优于一阶归因方法，并且能够区分不同的模型。

Abstract: Language-image pre-training (LIP) enables the development of vision-language
models capable of zero-shot classification, localization, multimodal retrieval,
and semantic understanding. Various explanation methods have been proposed to
visualize the importance of input image-text pairs on the model's similarity
outputs. However, popular saliency maps are limited by capturing only
first-order attributions, overlooking the complex cross-modal interactions
intrinsic to such encoders. We introduce faithful interaction explanations of
LIP models (FIxLIP) as a unified approach to decomposing the similarity in
vision-language encoders. FIxLIP is rooted in game theory, where we analyze how
using the weighted Banzhaf interaction index offers greater flexibility and
improves computational efficiency over the Shapley interaction quantification
framework. From a practical perspective, we propose how to naturally extend
explanation evaluation metrics, like the pointing game and area between the
insertion/deletion curves, to second-order interaction explanations.
Experiments on MS COCO and ImageNet-1k benchmarks validate that second-order
methods like FIxLIP outperform first-order attribution methods. Beyond
delivering high-quality explanations, we demonstrate the utility of FIxLIP in
comparing different models like CLIP vs. SigLIP-2 and ViT-B/32 vs. ViT-L/16.

</details>


### [80] [How and Why: Taming Flow Matching for Unsupervised Anomaly Detection and Localization](https://arxiv.org/abs/2508.05461)
*Liangwei Li,Lin Liu,Juanxiu Liu,Jing Zhang,Ruqian Hao,Xiaohui Du*

Main category: cs.CV

TL;DR: Unsupervised anomaly detection using Flow Matching (FM) with a new time-reversed approach (rFM) and Worst Transport (WT) interpolation (WT-Flow) overcomes prior limitations and achieves state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Address model expressivity limitations of conventional flow-based methods in unsupervised anomaly detection and localization.

Method: Propose time-reversed Flow Matching (rFM) as a vector field regression, utilizing Worst Transport (WT) displacement interpolation to reconstruct a non-probabilistic evolution path (WT-Flow).

Result: WT-Flow enhances dynamical control over sample trajectories, constructing ''degenerate potential wells'' for anomaly-free samples while allowing anomalous samples to escape, offering a theoretically grounded separation mechanism for anomalous samples. Achieved state-of-the-art performance on the MVTec dataset.

Conclusion: We present the first successful application of Flow Matching (FM) for unsupervised anomaly detection, achieving state-of-the-art performance.

Abstract: We propose a new paradigm for unsupervised anomaly detection and localization
using Flow Matching (FM), which fundamentally addresses the model expressivity
limitations of conventional flow-based methods. To this end, we formalize the
concept of time-reversed Flow Matching (rFM) as a vector field regression along
a predefined probability path to transform unknown data distributions into
standard Gaussian. We bring two core observations that reshape our
understanding of FM. First, we rigorously prove that FM with linear
interpolation probability paths is inherently non-invertible. Second, our
analysis reveals that employing reversed Gaussian probability paths in
high-dimensional spaces can lead to trivial vector fields. This issue arises
due to the manifold-related constraints. Building on the second observation, we
propose Worst Transport (WT) displacement interpolation to reconstruct a
non-probabilistic evolution path. The proposed WT-Flow enhances dynamical
control over sample trajectories, constructing ''degenerate potential wells''
for anomaly-free samples while allowing anomalous samples to escape. This novel
unsupervised paradigm offers a theoretically grounded separation mechanism for
anomalous samples. Notably, FM provides a computationally tractable framework
that scales to complex data. We present the first successful application of FM
for the unsupervised anomaly detection task, achieving state-of-the-art
performance at a single scale on the MVTec dataset. The reproducible code for
training will be released upon camera-ready submission.

</details>


### [81] [Keep It Real: Challenges in Attacking Compression-Based Adversarial Purification](https://arxiv.org/abs/2508.05489)
*Samuel Räber,Till Aczel,Andreas Plesner,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 研究发现，能生成逼真图像的压缩模型更能抵抗对抗性攻击，因为逼真图像与自然图像相似，提供了内在鲁棒性，而非梯度掩蔽。


<details>
  <summary>Details</summary>
Motivation: 评估损失性压缩在防御对抗性扰动方面的有效性，并找出其中的关键挑战。

Method: 本研究构建了针对各种压缩模型的强白盒和自适应攻击，并通过严格评估不同攻击场景来验证压缩模型（特别是能够生成逼真、高保真度重建图像的模型）的鲁棒性，并分析了低保真度模型被攻破的原因。

Result: 高保真度重建能够显著提高攻击难度，而低保真度重建则容易被攻破。逼真重建的鲁棒性并非源于梯度掩蔽，而是源于其与自然图像的分布一致性。

Conclusion: 本研究表明，能够生成逼真、高保真度重建图像的压缩模型，在抵御攻击方面表现出更强的鲁棒性，而低保真度压缩模型则容易被攻破。这种鲁棒性并非源于梯度掩蔽，而是由于逼真的重建图像在分布上与自然图像保持一致，从而提供了内在的鲁棒性。

Abstract: Previous work has suggested that preprocessing images through lossy
compression can defend against adversarial perturbations, but comprehensive
attack evaluations have been lacking. In this paper, we construct strong
white-box and adaptive attacks against various compression models and identify
a critical challenge for attackers: high realism in reconstructed images
significantly increases attack difficulty. Through rigorous evaluation across
multiple attack scenarios, we demonstrate that compression models capable of
producing realistic, high-fidelity reconstructions are substantially more
resistant to our attacks. In contrast, low-realism compression models can be
broken. Our analysis reveals that this is not due to gradient masking. Rather,
realistic reconstructions maintaining distributional alignment with natural
images seem to offer inherent robustness. This work highlights a significant
obstacle for future adversarial attacks and suggests that developing more
effective techniques to overcome realism represents an essential challenge for
comprehensive security evaluation.

</details>


### [82] [SMOL-MapSeg: Show Me One Label](https://arxiv.org/abs/2508.05501)
*Yunshuang Yuan,Frank Thiemann,Thorsten Dahms,Monika Sester*

Main category: cs.CV

TL;DR: A new method called SMOL-MapSeg uses 'On-Need Declarative' prompting to help deep learning models understand and segment historical maps, which often have inconsistent visual patterns. It performs better than existing methods like UNet.


<details>
  <summary>Details</summary>
Motivation: Existing foundation models struggle with historical maps because these maps lack consistency in patterns and styles, unlike modern or domain-specific images. OND prompting addresses this by introducing explicit prompts to guide the model on concept-pattern correspondences.

Method: Proposed On-Need Declarative (OND) knowledge-based prompting by replacing the prompt encoder of the foundation model SAM with OND prompting and fine-tuning it on historical maps. The resulting model is SMOL-MapSeg.

Result: SMOL-MapSeg accurately segments classes defined by OND knowledge, adapts to unseen classes via few-shot fine-tuning, and outperforms a UNet-based baseline in average segmentation performance.

Conclusion: SMOL-MapSeg can accurately segment classes defined by OND knowledge and adapt to unseen classes through few-shot fine-tuning, outperforming a UNet-based baseline.

Abstract: Historical maps are valuable for studying changes to the Earth's surface.
With the rise of deep learning, models like UNet have been used to extract
information from these maps through semantic segmentation. Recently,
pre-trained foundation models have shown strong performance across domains such
as autonomous driving, medical imaging, and industrial inspection. However,
they struggle with historical maps. These models are trained on modern or
domain-specific images, where patterns can be tied to predefined concepts
through common sense or expert knowledge. Historical maps lack such consistency
-- similar concepts can appear in vastly different shapes and styles. To
address this, we propose On-Need Declarative (OND) knowledge-based prompting,
which introduces explicit prompts to guide the model on what patterns
correspond to which concepts. This allows users to specify the target concept
and pattern during inference (on-need inference). We implement this by
replacing the prompt encoder of the foundation model SAM with our OND prompting
mechanism and fine-tune it on historical maps. The resulting model is called
SMOL-MapSeg (Show Me One Label). Experiments show that SMOL-MapSeg can
accurately segment classes defined by OND knowledge. It can also adapt to
unseen classes through few-shot fine-tuning. Additionally, it outperforms a
UNet-based baseline in average segmentation performance.

</details>


### [83] [AutoIAD: Manager-Driven Multi-Agent Collaboration for Automated Industrial Anomaly Detection](https://arxiv.org/abs/2508.05503)
*Dongwei Ji,Bingzhang Hu,Yi Zhou*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Industrial anomaly detection (IAD) is critical for manufacturing quality
control, but conventionally requires significant manual effort for various
application scenarios. This paper introduces AutoIAD, a multi-agent
collaboration framework, specifically designed for end-to-end automated
development of industrial visual anomaly detection. AutoIAD leverages a
Manager-Driven central agent to orchestrate specialized sub-agents (including
Data Preparation, Data Loader, Model Designer, Trainer) and integrates a
domain-specific knowledge base, which intelligently handles the entire pipeline
using raw industrial image data to develop a trained anomaly detection model.
We construct a comprehensive benchmark using MVTec AD datasets to evaluate
AutoIAD across various LLM backends. Extensive experiments demonstrate that
AutoIAD significantly outperforms existing general-purpose agentic
collaboration frameworks and traditional AutoML frameworks in task completion
rate and model performance (AUROC), while effectively mitigating issues like
hallucination through iterative refinement. Ablation studies further confirm
the crucial roles of the Manager central agent and the domain knowledge base
module in producing robust and high-quality IAD solutions.

</details>


### [84] [Symmetry Understanding of 3D Shapes via Chirality Disentanglement](https://arxiv.org/abs/2508.05505)
*Weikang Wang,Tobias Weißberg,Nafie El Amrani,Florian Bernard*

Main category: cs.CV

TL;DR: 该论文提出了一种从2D基础模型中提取手性信息并将其应用于形状分析的方法，解决了现有形状描述子无法区分左右对称部分的问题，并在多个下游任务中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 尽管手性信息在计算机视觉的多种数据模式中无处不在，但在形状分析领域（如点云和网格）的研究尚不充分。现有的形状顶点描述子虽然对刚体变换具有鲁棒性，但往往无法区分左右对称部分。鉴于手性信息在形状分析问题中的普遍性以及当前形状描述子中缺乏手性感知特征，开发手性特征提取器具有必要性和紧迫性。

Method: 基于现有的Diff3F框架，提出了一种无监督的手性特征提取流程，用于从2D基础模型中提取手性信息并装饰到形状顶点上。

Result: 通过在多个数据集上进行定量和定性实验，评估了提取的手性特征。下游任务的结果证明了其有效性和实用性。

Conclusion: 该研究提出的无监督手性特征提取方法在左-右分离、形状匹配和部件分割等下游任务中表现出有效性和实用性。

Abstract: Chirality information (i.e. information that allows distinguishing left from
right) is ubiquitous for various data modes in computer vision, including
images, videos, point clouds, and meshes. While chirality has been extensively
studied in the image domain, its exploration in shape analysis (such as point
clouds and meshes) remains underdeveloped. Although many shape vertex
descriptors have shown appealing properties (e.g. robustness to rigid-body
transformations), they are often not able to disambiguate between left and
right symmetric parts. Considering the ubiquity of chirality information in
different shape analysis problems and the lack of chirality-aware features
within current shape descriptors, developing a chirality feature extractor
becomes necessary and urgent. Based on the recent Diff3F framework, we propose
an unsupervised chirality feature extraction pipeline to decorate shape
vertices with chirality-aware information, extracted from 2D foundation models.
We evaluated the extracted chirality features through quantitative and
qualitative experiments across diverse datasets. Results from downstream tasks
including left-right disentanglement, shape matching, and part segmentation
demonstrate their effectiveness and practical utility. Project page:
https://wei-kang-wang.github.io/chirality/

</details>


### [85] [MagicHOI: Leveraging 3D Priors for Accurate Hand-object Reconstruction from Short Monocular Video Clips](https://arxiv.org/abs/2508.05506)
*Shibo Wang,Haonan He,Maria Parelli,Christoph Gebhardt,Zicong Fan,Jie Song*

Main category: cs.CV

TL;DR: MagicHOI reconstructs hands and objects from videos using diffusion models for supervision, improving accuracy even with limited views and outperforming prior methods.


<details>
  <summary>Details</summary>
Motivation: Existing RGB-based hand-object reconstruction methods either rely on object templates or assume full object visibility, which often breaks in real-world settings with limited viewpoints, leading to implausible reconstructions. MagicHOI aims to overcome this limitation for reconstructing hands and objects from short monocular interaction videos, even under limited viewpoint variation.

Method: MagicHOI integrates a novel view synthesis diffusion model into a hand-object reconstruction framework, leveraging large-scale novel view synthesis diffusion models for object supervision to regularize unseen object regions. It also incorporates visible contact constraints to align hands to objects.

Result: MagicHOI significantly outperforms existing state-of-the-art hand-object reconstruction methods and demonstrates that novel view synthesis diffusion priors effectively regularize unseen object regions, enhancing 3D hand-object reconstruction.

Conclusion: MagicHOI’s novel view synthesis diffusion prior effectively regularizes unseen object regions, enhancing 3D hand-object reconstruction and significantly outperforming existing state-of-the-art methods.

Abstract: Most RGB-based hand-object reconstruction methods rely on object templates,
while template-free methods typically assume full object visibility. This
assumption often breaks in real-world settings, where fixed camera viewpoints
and static grips leave parts of the object unobserved, resulting in implausible
reconstructions. To overcome this, we present MagicHOI, a method for
reconstructing hands and objects from short monocular interaction videos, even
under limited viewpoint variation. Our key insight is that, despite the
scarcity of paired 3D hand-object data, large-scale novel view synthesis
diffusion models offer rich object supervision. This supervision serves as a
prior to regularize unseen object regions during hand interactions. Leveraging
this insight, we integrate a novel view synthesis model into our hand-object
reconstruction framework. We further align hand to object by incorporating
visible contact constraints. Our results demonstrate that MagicHOI
significantly outperforms existing state-of-the-art hand-object reconstruction
methods. We also show that novel view synthesis diffusion priors effectively
regularize unseen object regions, enhancing 3D hand-object reconstruction.

</details>


### [86] [Revealing Latent Information: A Physics-inspired Self-supervised Pre-training Framework for Noisy and Sparse Events](https://arxiv.org/abs/2508.05507)
*Lin Zhu,Ruonan Liu,Xiao Wang,Lizhi Wang,Hua Huang*

Main category: cs.CV

TL;DR: 事件相机数据的自监督预训练框架，通过差分引导掩码建模、主干固定特征迁移和关注对比学习，有效提取了事件数据的边缘和纹理信息，并在多项下游任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据具有高时间分辨率和宽动态范围，但在具有挑战性的场景下，数据稀疏且嘈杂，主要反映亮度变化，这使得特征提取变得复杂。为了解决这个问题，需要一个框架来充分揭示事件数据中潜在的边缘信息和纹理线索。

Method: 提出了一种自监督预训练框架，包含三个阶段：1. 差分引导掩码建模：通过重建时间强度差分图来提取增强信息。2. 主干固定特征迁移：在不更新主干的情况下对比事件和图像特征。3. 关注对比学习：通过关注高价值区域来更新整个模型，提升语义区分度。

Result: 该框架能够有效提取事件数据中的边缘信息和纹理线索，并在物体识别、语义分割和光流估计等任务上取得显著成果，性能优于现有最先进方法。

Conclusion: 事件相机数据预训练框架在物体识别、语义分割和光流估计等下游任务中表现稳健，性能优于现有最先进方法。

Abstract: Event camera, a novel neuromorphic vision sensor, records data with high
temporal resolution and wide dynamic range, offering new possibilities for
accurate visual representation in challenging scenarios. However, event data is
inherently sparse and noisy, mainly reflecting brightness changes, which
complicates effective feature extraction. To address this, we propose a
self-supervised pre-training framework to fully reveal latent information in
event data, including edge information and texture cues. Our framework consists
of three stages: Difference-guided Masked Modeling, inspired by the event
physical sampling process, reconstructs temporal intensity difference maps to
extract enhanced information from raw event data. Backbone-fixed Feature
Transition contrasts event and image features without updating the backbone to
preserve representations learned from masked modeling and stabilizing their
effect on contrastive learning. Focus-aimed Contrastive Learning updates the
entire model to improve semantic discrimination by focusing on high-value
regions. Extensive experiments show our framework is robust and consistently
outperforms state-of-the-art methods on various downstream tasks, including
object recognition, semantic segmentation, and optical flow estimation. The
code and dataset are available at https://github.com/BIT-Vision/EventPretrain.

</details>


### [87] [Head Anchor Enhanced Detection and Association for Crowded Pedestrian Tracking](https://arxiv.org/abs/2508.05514)
*Zewei Wu,César Teixeira,Wei Ke,Zhang Xiong*

Main category: cs.CV

TL;DR: 该研究提出了一种改进的行人跟踪方法，通过结合更丰富的特征（包括头部关键点）和改进的运动模型（迭代卡尔曼滤波）来解决遮挡问题，以提高在拥挤场景下的跟踪稳定性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的视觉行人跟踪应用面临严峻的遮挡挑战。当多个行人相互作用或重叠时，目标特征的丢失会严重损害跟踪器维持稳定轨迹的能力。传统的跟踪方法通常依赖于从{Re-ID}模型提取的全身体边界框特征和线性恒定速度运动假设，在严重遮挡的情况下往往表现不佳。

Method: 该方法提出了一种增强的跟踪框架，该框架利用了更丰富的特征表示和更鲁棒的运动模型。具体来说，所提出的方法结合了来自物体检测器回归和分类分支的检测特征，将空间和位置信息直接嵌入特征表示。为了进一步缓解遮挡挑战，引入了头部关键点检测模型，因为头部与全身相比不易被遮挡。在运动建模方面，提出了一种迭代卡尔曼滤波方法，旨在与现代检测器假设保持一致，并整合了三维先验以更好地在复杂场景中完成运动轨迹。

Result: 通过结合外观和运动建模的这些进展，所提出的方法为在遮挡普遍存在的拥挤环境中进行多目标跟踪提供了更鲁棒的解决方案。

Conclusion: 该方法通过结合检测特征、头部关键点模型和迭代卡尔曼滤波，为解决遮挡问题提供了更鲁棒的多目标跟踪解决方案。

Abstract: Visual pedestrian tracking represents a promising research field, with
extensive applications in intelligent surveillance, behavior analysis, and
human-computer interaction. However, real-world applications face significant
occlusion challenges. When multiple pedestrians interact or overlap, the loss
of target features severely compromises the tracker's ability to maintain
stable trajectories. Traditional tracking methods, which typically rely on
full-body bounding box features extracted from {Re-ID} models and linear
constant-velocity motion assumptions, often struggle in severe occlusion
scenarios. To address these limitations, this work proposes an enhanced
tracking framework that leverages richer feature representations and a more
robust motion model. Specifically, the proposed method incorporates detection
features from both the regression and classification branches of an object
detector, embedding spatial and positional information directly into the
feature representations. To further mitigate occlusion challenges, a head
keypoint detection model is introduced, as the head is less prone to occlusion
compared to the full body. In terms of motion modeling, we propose an iterative
Kalman filtering approach designed to align with modern detector assumptions,
integrating 3D priors to better complete motion trajectories in complex scenes.
By combining these advancements in appearance and motion modeling, the proposed
method offers a more robust solution for multi-object tracking in crowded
environments where occlusions are prevalent.

</details>


### [88] [FS-IQA: Certified Feature Smoothing for Robust Image Quality Assessment](https://arxiv.org/abs/2508.05516)
*Ekaterina Shumitskaya,Dmitriy Vatolin,Anastasia Antsiferova*

Main category: cs.CV

TL;DR: 提出了一种新颖的、基于特征空间随机平滑的图像质量评估模型认证防御方法，在不损害图像视觉质量和不改变模型结构的前提下，提供了鲁棒性保证，并且计算效率高，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了在不损害图像视觉质量的情况下为图像质量评估模型提供鲁棒性保证。

Method: 基于特征空间中的随机平滑噪声注入，通过分析主干网络的雅可比矩阵的*大奇异值来连接特征空间噪声水平和输入空间扰动。

Result: 在两个基准数据集上，针对六种广泛使用的图像质量评估模型进行了验证，与五种最先进的认证防御方法进行了比较，结果显示与主观质量分数的*相关性*高了30.9%。

Conclusion: 该方法在不改变模型结构的情况下，为全参考和无参考的图像质量评估模型提供了鲁棒性保证，并且计算效率高，在主观质量评分方面取得了显著提升。

Abstract: We propose a novel certified defense method for Image Quality Assessment
(IQA) models based on randomized smoothing with noise applied in the feature
space rather than the input space. Unlike prior approaches that inject Gaussian
noise directly into input images, often degrading visual quality, our method
preserves image fidelity while providing robustness guarantees. To formally
connect noise levels in the feature space with corresponding input-space
perturbations, we analyze the maximum singular value of the backbone network's
Jacobian. Our approach supports both full-reference (FR) and no-reference (NR)
IQA models without requiring any architectural modifications, suitable for
various scenarios. It is also computationally efficient, requiring a single
backbone forward pass per image. Compared to previous methods, it reduces
inference time by 99.5% without certification and by 20.6% when certification
is applied. We validate our method with extensive experiments on two benchmark
datasets, involving six widely-used FR and NR IQA models and comparisons
against five state-of-the-art certified defenses. Our results demonstrate
consistent improvements in correlation with subjective quality scores by up to
30.9%.

</details>


### [89] [Leveraging AI to Accelerate Clinical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods](https://arxiv.org/abs/2508.05519)
*Matthew Purri,Amit Patel,Erik Deurrell*

Main category: cs.CV

TL;DR: Octozi, an AI platform using LLMs and heuristics, significantly improves clinical trial data cleaning by increasing throughput (6.03x), reducing errors (6.44x), and minimizing false positive queries (15.48x), showing broad applicability and potential to accelerate drug development.


<details>
  <summary>Details</summary>
Motivation: Clinical trial data cleaning represents a critical bottleneck in drug development, with manual review processes struggling to manage exponentially increasing data volumes and complexity.

Method: This paper presents Octozi, an artificial intelligence-assisted platform that combines large language models with domain-specific heuristics to transform clinical data review. In a controlled experimental study with experienced clinical reviewers (n=10), we demonstrate that AI assistance increased data cleaning throughput by 6.03-fold while simultaneously decreasing cleaning errors from 54.67% to 8.48% (a 6.44-fold improvement). Crucially, the system reduced false positive queries by 15.48-fold, minimizing unnecessary site burden. These improvements were consistent across reviewers regardless of experience level, suggesting broad applicability.

Result: AI assistance increased data cleaning throughput by 6.03-fold while simultaneously decreasing cleaning errors from 54.67% to 8.48% (a 6.44-fold improvement). The system reduced false positive queries by 15.48-fold, minimizing unnecessary site burden. These improvements were consistent across reviewers regardless of experience level, suggesting broad applicability.

Conclusion: AI-assisted approaches can address fundamental inefficiencies in clinical trial operations, potentially accelerating drug development timelines and reducing costs while maintaining regulatory compliance. This work establishes a framework for integrating AI into safety-critical clinical workflows and demonstrates the transformative potential of human-AI collaboration in pharmaceutical clinical trials.

Abstract: Clinical trial data cleaning represents a critical bottleneck in drug
development, with manual review processes struggling to manage exponentially
increasing data volumes and complexity. This paper presents Octozi, an
artificial intelligence-assisted platform that combines large language models
with domain-specific heuristics to transform clinical data review. In a
controlled experimental study with experienced clinical reviewers (n=10), we
demonstrate that AI assistance increased data cleaning throughput by 6.03-fold
while simultaneously decreasing cleaning errors from 54.67% to 8.48% (a
6.44-fold improvement). Crucially, the system reduced false positive queries by
15.48-fold, minimizing unnecessary site burden. These improvements were
consistent across reviewers regardless of experience level, suggesting broad
applicability. Our findings indicate that AI-assisted approaches can address
fundamental inefficiencies in clinical trial operations, potentially
accelerating drug development timelines and reducing costs while maintaining
regulatory compliance. This work establishes a framework for integrating AI
into safety-critical clinical workflows and demonstrates the transformative
potential of human-AI collaboration in pharmaceutical clinical trials.

</details>


### [90] [Optimal Brain Connection: Towards Efficient Structural Pruning](https://arxiv.org/abs/2508.05521)
*Shaowu Chen,Wei Ma,Binhua Huang,Qingyuan Wang,Guoxin Wang,Weize Sun,Lei Huang,Deepu John*

Main category: cs.CV

TL;DR: 一种新的结构化剪枝方法，考虑了参数间的相互联系，并通过雅可比准则和等价剪枝机制提升了剪枝效果和微调后的性能。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法通常忽略参数间的相互联系，导致剪枝效果不佳。本研究旨在解决这一局限性，提出一种能有效考虑参数间相互联系的剪枝框架。

Method: 本研究提出了一种名为“最优脑连接”的结构化剪枝框架。该框架包含两个主要部分：1. 雅可比准则（Jacobian Criterion）：一种新的评估结构化参数显著性的指标，能够同时考虑参数内部的相互作用以及层间依赖关系。2. 等价剪枝（Equivalent Pruning）机制：利用自动编码器在微调过程中保留所有原始连接（包括剪枝掉的连接）的贡献。

Result: 实验结果表明，雅可比准则在保持模型性能方面优于多种流行指标。同时，等价剪枝机制能有效减轻微调后出现的性能下降问题。

Conclusion: 该研究提出的最优脑连接（Optimal Brain Connection）框架通过雅可比准则（Jacobian Criterion）和等价剪枝（Equivalent Pruning）机制，在结构化剪枝方面取得了显著成效，有效解决了现有方法忽略参数间相互联系的问题，并在模型性能保持方面优于现有方法。

Abstract: Structural pruning has been widely studied for its effectiveness in
compressing neural networks. However, existing methods often neglect the
interconnections among parameters. To address this limitation, this paper
proposes a structural pruning framework termed Optimal Brain Connection. First,
we introduce the Jacobian Criterion, a first-order metric for evaluating the
saliency of structural parameters. Unlike existing first-order methods that
assess parameters in isolation, our criterion explicitly captures both
intra-component interactions and inter-layer dependencies. Second, we propose
the Equivalent Pruning mechanism, which utilizes autoencoders to retain the
contributions of all original connection--including pruned ones--during
fine-tuning. Experimental results demonstrate that the Jacobian Criterion
outperforms several popular metrics in preserving model performance, while the
Equivalent Pruning mechanism effectively mitigates performance degradation
after fine-tuning. Code: https://github.com/ShaowuChen/Optimal_Brain_Connection

</details>


### [91] [When Deepfake Detection Meets Graph Neural Network:a Unified and Lightweight Learning Framework](https://arxiv.org/abs/2508.05526)
*Haoyu Liu,Chaoyu Gong,Mengke He,Jiate Li,Kai Han,Siqiang Luo*

Main category: cs.CV

TL;DR: SSTGNN 是一种轻量级的时空图神经网络，可以有效检测 AI 生成的视频，其性能优于现有方法，参数量却大大减少。


<details>
  <summary>Details</summary>
Motivation: 生成视频模型的扩散使得检测 AI 生成和操纵的视频成为一项紧迫的挑战。现有的检测方法由于依赖于孤立的空间、时间或光谱信息，并且通常需要大型模型才能表现良好，因此在各种操纵类型上泛化能力不足。

Method: SSTGNN 是一个轻量级的时空图神经网络框架，它将视频表示为结构化图，实现了对空间不一致性、时间伪影和光谱失真的联合推理。它包含可学习的光谱滤波器和基于图的架构中的时间差分建模，从而更有效地捕获细微的操纵痕迹。

Result: SSTGNN 在域内和跨域设置中均取得了卓越的性能，并对未见过的操纵表现出强大的鲁棒性，同时参数量大大减少。

Conclusion: SSTGNN 在各种基准数据集的域内和跨域设置中均取得了卓越的性能，并且对未见过的操纵表现出强大的鲁棒性。此外，SSTGNN 的参数量比最先进的模型少 42.4 倍，使其轻量级且可扩展，适用于实际部署。

Abstract: The proliferation of generative video models has made detecting AI-generated
and manipulated videos an urgent challenge. Existing detection approaches often
fail to generalize across diverse manipulation types due to their reliance on
isolated spatial, temporal, or spectral information, and typically require
large models to perform well. This paper introduces SSTGNN, a lightweight
Spatial-Spectral-Temporal Graph Neural Network framework that represents videos
as structured graphs, enabling joint reasoning over spatial inconsistencies,
temporal artifacts, and spectral distortions. SSTGNN incorporates learnable
spectral filters and temporal differential modeling into a graph-based
architecture, capturing subtle manipulation traces more effectively. Extensive
experiments on diverse benchmark datasets demonstrate that SSTGNN not only
achieves superior performance in both in-domain and cross-domain settings, but
also offers strong robustness against unseen manipulations. Remarkably, SSTGNN
accomplishes these results with up to 42.4$\times$ fewer parameters than
state-of-the-art models, making it highly lightweight and scalable for
real-world deployment.

</details>


### [92] [AI vs. Human Moderators: A Comparative Evaluation of Multimodal LLMs in Content Moderation for Brand Safety](https://arxiv.org/abs/2508.05527)
*Adi Levi,Or Levi,Sardhendu Mishra,Jonathan Morra*

Main category: cs.CV

TL;DR: 本研究首次评估了MLLMs在品牌安全分类中的应用，并提出了一个包含多维度风险类别的新型多模态、多语言数据集。研究结果表明，MLLMs在准确性和成本效益方面可与专业人工审核员相媲美，但仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 随着在线视频内容的爆炸式增长，视频审核的需求已超出人工能力，带来了运营和心理健康挑战。MLLMs在视频理解任务中表现出优势，但其在需要细致理解视觉和文本线索的多模态内容审核中的应用仍有待探索。

Method: 通过引入新颖的多模态、多语言数据集，并对Gemini、GPT和Llama等MLLMs进行详细的比较分析，评估它们在多模态品牌安全方面的能力，并与专业人工审核员在准确性和成本效益方面进行比较。

Result: MLLMs在品牌安全分类方面是有效的，其准确性和成本效益与专业人工审核员相当。

Conclusion: MLLMs在品牌安全分类方面展现出有效性，但仍存在局限性，其准确性和成本效益与专业人工审核员相当。

Abstract: As the volume of video content online grows exponentially, the demand for
moderation of unsafe videos has surpassed human capabilities, posing both
operational and mental health challenges. While recent studies demonstrated the
merits of Multimodal Large Language Models (MLLMs) in various video
understanding tasks, their application to multimodal content moderation, a
domain that requires nuanced understanding of both visual and textual cues,
remains relatively underexplored. In this work, we benchmark the capabilities
of MLLMs in brand safety classification, a critical subset of content
moderation for safe-guarding advertising integrity. To this end, we introduce a
novel, multimodal and multilingual dataset, meticulously labeled by
professional reviewers in a multitude of risk categories. Through a detailed
comparative analysis, we demonstrate the effectiveness of MLLMs such as Gemini,
GPT, and Llama in multimodal brand safety, and evaluate their accuracy and cost
efficiency compared to professional human reviewers. Furthermore, we present an
in-depth discussion shedding light on limitations of MLLMs and failure cases.
We are releasing our dataset alongside this paper to facilitate future research
on effective and responsible brand safety and content moderation.

</details>


### [93] [Looking into the Unknown: Exploring Action Discovery for Segmentation of Known and Unknown Actions](https://arxiv.org/abs/2508.05529)
*Federico Spurio,Emad Bahrami,Olga Zatsarynna,Yazan Abu Farha,Gianpiero Francesca,Juergen Gall*

Main category: cs.CV

TL;DR: 提出了一种名为 Action Discovery 的新方法，用于解决部分标注数据集中的动作分割问题。该方法通过模仿已知动作的粒度来处理未知动作，并根据嵌入相似性来识别未知动作的语义类别，在多个数据集上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在部分标注的数据集中，存在定义和标注模糊动作以及不完整标注的挑战。例如，在神经科学领域，明确的行为（如行走、饮食）与不易察觉或罕见的动作并存，后者常常被忽略。此外，在一些数据集中，由于标注模糊或缺失，数据本身就是部分标注的。

Method: 提出了一种两步法来解决部分标注数据集中的未知动作分割问题。首先，通过梯度引导分割模块（GGSM）来模仿标注动作的粒度，从而识别已知和未知动作的时间间隔。其次，通过未知动作段分配（UASA）模块，基于学习到的嵌入相似性来识别未知动作中语义上有意义的类别。

Result: 所提出的方法（Action Discovery）在三个具有挑战性的数据集上，相比现有基线方法，能够更好地处理部分标注数据，在时间粒度和语义粒度上都进行了改进。

Conclusion: 所提出的方法在 Breakfast, 50Salads, 和 Desktop Assembly 这三个具有挑战性的数据集上进行了系统性探索，并且取得了比现有基线方法明显更好的性能。

Abstract: We introduce Action Discovery, a novel setup within Temporal Action
Segmentation that addresses the challenge of defining and annotating ambiguous
actions and incomplete annotations in partially labeled datasets. In this
setup, only a subset of actions - referred to as known actions - is annotated
in the training data, while other unknown actions remain unlabeled. This
scenario is particularly relevant in domains like neuroscience, where
well-defined behaviors (e.g., walking, eating) coexist with subtle or
infrequent actions that are often overlooked, as well as in applications where
datasets are inherently partially annotated due to ambiguous or missing labels.
To address this problem, we propose a two-step approach that leverages the
known annotations to guide both the temporal and semantic granularity of
unknown action segments. First, we introduce the Granularity-Guided
Segmentation Module (GGSM), which identifies temporal intervals for both known
and unknown actions by mimicking the granularity of annotated actions. Second,
we propose the Unknown Action Segment Assignment (UASA), which identifies
semantically meaningful classes within the unknown actions, based on learned
embedding similarities. We systematically explore the proposed setting of
Action Discovery on three challenging datasets - Breakfast, 50Salads, and
Desktop Assembly - demonstrating that our method considerably improves upon
existing baselines.

</details>


### [94] [Follow-Your-Instruction: A Comprehensive MLLM Agent for World Data Synthesis](https://arxiv.org/abs/2508.05580)
*Kunyu Feng,Yue Ma,Xinhua Zhang,Boshi Liu,Yikuang Yuluo,Yinhan Zhang,Runtao Liu,Hongyu Liu,Zhiyuan Qin,Shanhui Mo,Qifeng Chen,Zeyu Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为"Follow-Your-Instruction"的框架，利用多模态大语言模型自动生成高质量的2D、3D和4D数据，解决了手动数据收集的成本和可扩展性问题，并在实验中证明了其能有效提升下游模型的性能。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容（AIGC）需求的增长，对高质量、多样化和可扩展数据的需求日益增加。然而，收集大规模真实世界数据成本高昂且耗时，阻碍了下游应用的发展。现有方法大多依赖手动场景构建，限制了可扩展性和准确性。因此，需要一种自动化的方法来解决这些挑战。

Method: 该研究提出了一个名为"Follow-Your-Instruction"的框架，该框架利用多模态大语言模型（MLLM）来自动合成高质量的2D、3D和4D数据。具体步骤包括：1. 使用MLLM-Collector通过多模态输入收集资产及其描述。2. 随后，利用MLLM-Generator构建3D布局。3. 接着，利用MLLM-Optimizer通过多视角场景进行语义精炼。4. 最后，使用MLLM-Planner生成时间连贯的未来帧。

Result: 实验结果表明，使用Follow-Your-Instruction框架合成的数据能够显著提升现有基线模型在2D、3D和4D生成任务上的性能。

Conclusion: 该研究提出的Follow-Your-Instruction框架能够自动合成高质量的2D、3D和4D数据，并且能够显著提升现有基线模型的性能，证明了其作为生成式智能的可扩展和有效的数据引擎的潜力。

Abstract: With the growing demands of AI-generated content (AIGC), the need for
high-quality, diverse, and scalable data has become increasingly crucial.
However, collecting large-scale real-world data remains costly and
time-consuming, hindering the development of downstream applications. While
some works attempt to collect task-specific data via a rendering process, most
approaches still rely on manual scene construction, limiting their scalability
and accuracy. To address these challenges, we propose Follow-Your-Instruction,
a Multimodal Large Language Model (MLLM)-driven framework for automatically
synthesizing high-quality 2D, 3D, and 4D data. Our
\textbf{Follow-Your-Instruction} first collects assets and their associated
descriptions through multimodal inputs using the MLLM-Collector. Then it
constructs 3D layouts, and leverages Vision-Language Models (VLMs) for semantic
refinement through multi-view scenes with the MLLM-Generator and
MLLM-Optimizer, respectively. Finally, it uses MLLM-Planner to generate
temporally coherent future frames. We evaluate the quality of the generated
data through comprehensive experiments on the 2D, 3D, and 4D generative tasks.
The results show that our synthetic data significantly boosts the performance
of existing baseline models, demonstrating Follow-Your-Instruction's potential
as a scalable and effective data engine for generative intelligence.

</details>


### [95] [DART: Dual Adaptive Refinement Transfer for Open-Vocabulary Multi-Label Recognition](https://arxiv.org/abs/2508.05585)
*Haijing Liu,Tao Pu,Hefeng Wu,Keze Wang,Liang Lin*

Main category: cs.CV

TL;DR: DART框架通过集成LLM挖掘的知识和自适应模块，改进了开放词汇多标签识别中的类内定位和类间迁移，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有视觉语言预训练（VLP）模型在开放词汇多标签识别（OV-MLR）方面存在的局限性，例如在弱监督下进行细粒度定位的困难以及未能显式利用结构化关系知识（尤其是在处理未见类别时），我们提出了DART框架。

Method: DART框架通过两个协同的自适应模块来增强冻结的视觉语言预训练（VLP）骨干网络。对于类内细化，自适应细化模块（ARM）自适应地细化图像块特征，并结合新颖的弱监督图像块选择（WPS）损失，仅使用图像级标签即可实现区分性定位。对于类间迁移，自适应迁移模块（ATM）利用使用从大型语言模型（LLM）挖掘的结构化知识构建的类别关系图（CRG），并采用图注意力网络将关系信息自适应地从类别表示转移出去。

Result: DART框架成功地增强了冻结的VLP骨干网络，通过自适应模块实现了类内和类间的细化与迁移，并在OV-MLR任务中取得了显著的性能提升，达到了新的最先进水平。

Conclusion: DART框架在具有挑战性的基准测试中取得了新的最先进性能，验证了其有效性。

Abstract: Open-Vocabulary Multi-Label Recognition (OV-MLR) aims to identify multiple
seen and unseen object categories within an image, requiring both precise
intra-class localization to pinpoint objects and effective inter-class
reasoning to model complex category dependencies. While Vision-Language
Pre-training (VLP) models offer a strong open-vocabulary foundation, they often
struggle with fine-grained localization under weak supervision and typically
fail to explicitly leverage structured relational knowledge beyond basic
semantics, limiting performance especially for unseen classes. To overcome
these limitations, we propose the Dual Adaptive Refinement Transfer (DART)
framework. DART enhances a frozen VLP backbone via two synergistic adaptive
modules. For intra-class refinement, an Adaptive Refinement Module (ARM)
refines patch features adaptively, coupled with a novel Weakly Supervised Patch
Selecting (WPS) loss that enables discriminative localization using only
image-level labels. Concurrently, for inter-class transfer, an Adaptive
Transfer Module (ATM) leverages a Class Relationship Graph (CRG), constructed
using structured knowledge mined from a Large Language Model (LLM), and employs
graph attention network to adaptively transfer relational information between
class representations. DART is the first framework, to our knowledge, to
explicitly integrate external LLM-derived relational knowledge for adaptive
inter-class transfer while simultaneously performing adaptive intra-class
refinement under weak supervision for OV-MLR. Extensive experiments on
challenging benchmarks demonstrate that our DART achieves new state-of-the-art
performance, validating its effectiveness.

</details>


### [96] [WeTok: Powerful Discrete Tokenization for High-Fidelity Visual Reconstruction](https://arxiv.org/abs/2508.05599)
*Shaobin Zhuang,Yiwei Guo,Canmiao Fu,Zhipeng Huang,Zeyue Tian,Ying Zhang,Chen Li,Yali Wang*

Main category: cs.CV

TL;DR: WeTok is a new visual tokenizer that improves compression and reconstruction using novel quantization and decoding methods, achieving better results than existing methods on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing visual tokenizers face an unsatisfactory trade-off between compression ratios and reconstruction fidelity. WeTok aims to fill this gap with a powerful and concise solution.

Method: Introduced WeTok tokenizer with two core innovations: (1) Group-wise lookup-free Quantization (GQ) for efficient memory and computation with scalable codebooks, and (2) Generative Decoding (GD) with a prior of extra noise variable for probabilistic modeling of visual data, enabling reconstruction of visual details at high compression ratios.

Result: WeTok achieves superior performance on mainstream benchmarks, including a record-low zero-shot rFID of 0.12 on ImageNet 50k validation set (compared to FLUX-VAE's 0.18 and SD-VAE 3.5's 0.19). The highest compression model achieves a zero-shot rFID of 3.49 with a compression ratio of 768, outperforming Cosmos (384) at 4.57.

Conclusion: WeTok tokenizer outperforms previous leading tokenizers through group-wise lookup-free quantization and generative decoding, achieving state-of-the-art performance in compression and reconstruction.

Abstract: Visual tokenizer is a critical component for vision generation. However, the
existing tokenizers often face unsatisfactory trade-off between compression
ratios and reconstruction fidelity. To fill this gap, we introduce a powerful
and concise WeTok tokenizer, which surpasses the previous leading tokenizers
via two core innovations. (1) Group-wise lookup-free Quantization (GQ). We
partition the latent features into groups, and perform lookup-free quantization
for each group. As a result, GQ can efficiently overcome memory and computation
limitations of prior tokenizers, while achieving a reconstruction breakthrough
with more scalable codebooks. (2) Generative Decoding (GD). Different from
prior tokenizers, we introduce a generative decoder with a prior of extra noise
variable. In this case, GD can probabilistically model the distribution of
visual data conditioned on discrete tokens, allowing WeTok to reconstruct
visual details, especially at high compression ratios. Extensive experiments on
mainstream benchmarks show superior performance of our WeTok. On the ImageNet
50k validation set, WeTok achieves a record-low zero-shot rFID (WeTok: 0.12 vs.
FLUX-VAE: 0.18 vs. SD-VAE 3.5: 0.19). Furthermore, our highest compression
model achieves a zero-shot rFID of 3.49 with a compression ratio of 768,
outperforming Cosmos (384) 4.57 which has only 50% compression rate of ours.
Code and models are available: https://github.com/zhuangshaobin/WeTok.

</details>


### [97] [LLaVA-RE: Binary Image-Text Relevancy Evaluation with Multimodal Large Language Model](https://arxiv.org/abs/2508.05602)
*Tao Sun,Oliver Liu,JinJin Li,Lan Ma*

Main category: cs.CV

TL;DR: 本研究提出了LLaVA-RE，一个利用多模态大语言模型（MLLM）进行图像-文本相关性二元评估的新框架，解决了现有评估方法的挑战，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 评估图像-文本相关性对于衡量响应质量和对候选响应进行排名至关重要，特别是二元相关性评估（“相关”或“不相关”）是一个基本但具有挑战性的问题，因为文本格式多样且相关性定义因场景而异。MLLM因其处理复杂文本格式和整合额外任务信息的能力，成为构建此类评估器的理想选择。

Method: 该研究提出了LLaVA-RE框架，该框架基于LLaVA架构，采用了详细的任务指令和多模态上下文样本，并构建了一个涵盖多种任务的新型二元相关性数据集。

Result: 实验结果证明了LLaVA-RE框架的有效性。

Conclusion: LLaVA-RE是一个首次使用MLLM进行二元图像-文本相关性评估的框架，实验结果验证了其有效性。

Abstract: Multimodal generative AI usually involves generating image or text responses
given inputs in another modality. The evaluation of image-text relevancy is
essential for measuring response quality or ranking candidate responses. In
particular, binary relevancy evaluation, i.e., ``Relevant'' vs. ``Not
Relevant'', is a fundamental problem. However, this is a challenging task
considering that texts have diverse formats and the definition of relevancy
varies in different scenarios. We find that Multimodal Large Language Models
(MLLMs) are an ideal choice to build such evaluators, as they can flexibly
handle complex text formats and take in additional task information. In this
paper, we present LLaVA-RE, a first attempt for binary image-text relevancy
evaluation with MLLM. It follows the LLaVA architecture and adopts detailed
task instructions and multimodal in-context samples. In addition, we propose a
novel binary relevancy data set that covers various tasks. Experimental results
validate the effectiveness of our framework.

</details>


### [98] [Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity](https://arxiv.org/abs/2508.05609)
*Yuhan Zhang,Long Zhuo,Ziyang Chu,Tong Wu,Zhibing Li,Liang Pan,Dahua Lin,Ziwei Liu*

Main category: cs.CV

TL;DR: Hi3DEval是一个用于评估3D生成内容的框架，它通过结合对象级和部件级评估以及改进的纹理评估来解决现有方法的局限性。Hi3DBench数据集和3D感知自动评分系统支持该框架。实验结果表明，Hi3DEval在3D特性建模和与人类偏好的一致性方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D内容生成质量评估方法主要依赖基于图像的指标，并且仅在对象级别上操作，这限制了它们捕捉空间连贯性、材料真实性和高保真局部细节的能力。

Method: Hi3DEval框架结合了对象级和部件级评估，并扩展了纹理评估，包括材料真实性。Hi3DBench数据集是通过多主体标注流程构建的。评分系统利用了基于视频的表示（用于对象级和材料-主体评估）和预训练的3D特征（用于部件级感知）。

Result: Hi3DEval在3D特性建模方面优于现有的基于图像的指标，并且与人类偏好的一致性更高，为手动评估提供了一个可扩展的替代方案。

Conclusion: Hi3DEval是一个分层评估框架，可以对3D生成内容进行整体和细粒度的质量评估，并且在评估纹理真实性时，超越了单纯的视觉吸引力，还包括了对反照率、饱和度和金属度等属性的真实性评估。Hi3DBench数据集和基于混合3D表示的3D感知自动评分系统支持了该框架。实验证明，Hi3DEval在3D特性建模方面优于现有的基于图像的指标，并且与人类偏好的一致性更高。

Abstract: Despite rapid advances in 3D content generation, quality assessment for the
generated 3D assets remains challenging. Existing methods mainly rely on
image-based metrics and operate solely at the object level, limiting their
ability to capture spatial coherence, material authenticity, and high-fidelity
local details. 1) To address these challenges, we introduce Hi3DEval, a
hierarchical evaluation framework tailored for 3D generative content. It
combines both object-level and part-level evaluation, enabling holistic
assessments across multiple dimensions as well as fine-grained quality
analysis. Additionally, we extend texture evaluation beyond aesthetic
appearance by explicitly assessing material realism, focusing on attributes
such as albedo, saturation, and metallicness. 2) To support this framework, we
construct Hi3DBench, a large-scale dataset comprising diverse 3D assets and
high-quality annotations, accompanied by a reliable multi-agent annotation
pipeline. We further propose a 3D-aware automated scoring system based on
hybrid 3D representations. Specifically, we leverage video-based
representations for object-level and material-subject evaluations to enhance
modeling of spatio-temporal consistency and employ pretrained 3D features for
part-level perception. Extensive experiments demonstrate that our approach
outperforms existing image-based metrics in modeling 3D characteristics and
achieves superior alignment with human preference, providing a scalable
alternative to manual evaluations. The project page is available at
https://zyh482.github.io/Hi3DEval/.

</details>


### [99] [MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes](https://arxiv.org/abs/2508.05630)
*Henghui Ding,Kaining Ying,Chang Liu,Shuting He,Xudong Jiang,Yu-Gang Jiang,Philip H. S. Torr,Song Bai*

Main category: cs.CV

TL;DR: MOSEv2是一个比MOSEv1更具挑战性的视频对象分割数据集，旨在模拟真实世界场景的复杂性。现有VOS技术在该数据集上的表现显著下降，表明其在应对真实世界挑战方面仍需改进。


<details>
  <summary>Details</summary>
Motivation: 为了推动VOS技术在更真实的场景下应用，克服现有数据集（如DAVIS, YouTube-VOS）主要包含显著、主导、分离对象的局限性，需要一个更具挑战性的数据集来模拟真实世界的复杂性。

Method: MOSEv2数据集的构建和评估。数据集包含5024个视频，超过701,976个高质量掩码，覆盖200个类别。评估了20种VOS方法和9种视频对象跟踪方法在5种不同设置下的性能，并与MOSEv1数据集进行了对比。

Result: 在MOSEv2数据集上，20种VOS方法和9种视频对象跟踪方法均表现出性能显著下降，例如SAM2模型在MOSEv1上的准确率为76.4%，在MOSEv2上降至50.9%。这证明了MOSEv2对现有VOS技术的有效性，并指出了当前技术在应对真实世界复杂性方面的不足。

Conclusion: 现有的视频对象分割（VOS）方法在标准的基准测试中表现优异，但在面对真实世界复杂场景时仍显不足。MOSEv2数据集的引入，通过包含更复杂的场景、物体消失重现、遮挡、小物体、恶劣天气、低光照、伪装目标等挑战，显著提升了VOS研究的难度。即使是先进模型（如SAM2）在该数据集上的性能也有大幅下降，表明当前VOS技术在处理真实世界复杂性方面仍有很大提升空间。

Abstract: Video object segmentation (VOS) aims to segment specified target objects
throughout a video. Although state-of-the-art methods have achieved impressive
performance (e.g., 90+% J&F) on existing benchmarks such as DAVIS and
YouTube-VOS, these datasets primarily contain salient, dominant, and isolated
objects, limiting their generalization to real-world scenarios. To advance VOS
toward more realistic environments, coMplex video Object SEgmentation (MOSEv1)
was introduced to facilitate VOS research in complex scenes. Building on the
strengths and limitations of MOSEv1, we present MOSEv2, a significantly more
challenging dataset designed to further advance VOS methods under real-world
conditions. MOSEv2 consists of 5,024 videos and over 701,976 high-quality masks
for 10,074 objects across 200 categories. Compared to its predecessor, MOSEv2
introduces significantly greater scene complexity, including more frequent
object disappearance and reappearance, severe occlusions and crowding, smaller
objects, as well as a range of new challenges such as adverse weather (e.g.,
rain, snow, fog), low-light scenes (e.g., nighttime, underwater), multi-shot
sequences, camouflaged objects, non-physical targets (e.g., shadows,
reflections), scenarios requiring external knowledge, etc. We benchmark 20
representative VOS methods under 5 different settings and observe consistent
performance drops. For example, SAM2 drops from 76.4% on MOSEv1 to only 50.9%
on MOSEv2. We further evaluate 9 video object tracking methods and find similar
declines, demonstrating that MOSEv2 presents challenges across tasks. These
results highlight that despite high accuracy on existing datasets, current VOS
methods still struggle under real-world complexities. MOSEv2 is publicly
available at https://MOSE.video.

</details>


### [100] [GAP: Gaussianize Any Point Clouds with Text Guidance](https://arxiv.org/abs/2508.05631)
*Weiqi Zhang,Junsheng Zhou,Haotian Geng,Wenyuan Zhang,Yu-Shen Liu*

Main category: cs.CV

TL;DR: GAP 是一种创新的方法，通过利用文本指导，将无色的 3D 点云转换为高质量的 3D 高斯表示。它使用多视图优化、深度感知扩散模型、表面锚定和修复策略来确保视觉一致性和几何精度，成功解决了从无色点云生成高斯表示的难题。


<details>
  <summary>Details</summary>
Motivation: 点云是一种广泛使用且易于获取的 3D 表示形式，而 3D 高斯泼溅（3DGS）在快速和高质量渲染方面表现出色。因此，弥合点云和高斯之间的差距变得越来越重要。尽管已有研究探索了将彩色点转换为高斯的方法，但直接从无色的 3D 点云生成高斯表示仍然是一个未解决的挑战。

Method: GAP 方法设计了一个多视图优化框架，利用深度感知图像扩散模型来合成跨不同视点的统一外观。为了确保几何精度，引入了一个表面锚定机制，在优化过程中将高斯约束在 3D 形状的表面上。此外，GAP 还结合了基于扩散的修复策略，用于填充难以观察的区域。

Result: GAP 在点云到高斯转换任务上进行了评估，涵盖了从合成点云到具有挑战性的真实世界扫描，乃至大规模场景等不同复杂度的场景，并在所有评估中取得了成功。

Conclusion: GAP 方法成功地将无色 3D 点云转换为高质量的 3D 高斯表示，并利用文本进行指导。该方法通过多视图优化框架、深度感知图像扩散模型、表面锚定机制以及基于扩散的修复策略，实现了视图间的一致外观和几何准确性，解决了直接从无色点云生成高斯表示的挑战。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated its advantages in achieving
fast and high-quality rendering. As point clouds serve as a widely-used and
easily accessible form of 3D representation, bridging the gap between point
clouds and Gaussians becomes increasingly important. Recent studies have
explored how to convert the colored points into Gaussians, but directly
generating Gaussians from colorless 3D point clouds remains an unsolved
challenge. In this paper, we propose GAP, a novel approach that gaussianizes
raw point clouds into high-fidelity 3D Gaussians with text guidance. Our key
idea is to design a multi-view optimization framework that leverages a
depth-aware image diffusion model to synthesize consistent appearances across
different viewpoints. To ensure geometric accuracy, we introduce a
surface-anchoring mechanism that effectively constrains Gaussians to lie on the
surfaces of 3D shapes during optimization. Furthermore, GAP incorporates a
diffuse-based inpainting strategy that specifically targets at completing
hard-to-observe regions. We evaluate GAP on the Point-to-Gaussian generation
task across varying complexity levels, from synthetic point clouds to
challenging real-world scans, and even large-scale scenes. Project Page:
https://weiqi-zhang.github.io/GAP.

</details>


### [101] [FaceAnonyMixer: Cancelable Faces via Identity Consistent Latent Space Mixing](https://arxiv.org/abs/2508.05636)
*Mohammed Talha Alam,Fahad Shamshad,Fakhri Karray,Karthik Nandakumar*

Main category: cs.CV

TL;DR: FaceAnonyMixer通过混合真实人脸和合成代码来生成可注销人脸，满足生物识别模板保护要求，并提高了识别准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在提高人脸识别（FR）技术的同时，解决日益增长的隐私担忧，需要一种能够在保护身份的同时保持识别效用的方法。现有的面部匿名化方法通常侧重于模糊身份，但未能满足可撤销性、不可链接性和不可逆性等生物识别模板保护的要求。

Method: FaceAnonyMixer是一个可注销人脸生成框架，它利用预训练生成模型的潜在空间来合成保护隐私的人脸图像。其核心思想是将真实人脸图像的潜在代码与源自可注销密钥的合成代码进行不可逆混合。然后，通过精心设计的多目标损失函数对混合后的潜在代码进行优化，以满足所有可注销生物识别要求。

Result: 实验结果表明，FaceAnonyMixer能够生成高质量的可注销人脸，并能直接用于现有的FR系统进行匹配，无需修改。在基准数据集上的广泛实验表明，FaceAnonyMixer在提供更强隐私保护的同时，实现了优越的识别准确性，在商业API上比最近的可注销生物识别方法提高了11%以上。

Conclusion: FaceAnonyMixer能够生成高质量的可注销人脸，并能直接用于现有的FR系统进行匹配，无需修改。该方法在提供更强隐私保护的同时，实现了优越的识别准确性，在商业API上比最近的可注销生物识别方法提高了11%以上。

Abstract: Advancements in face recognition (FR) technologies have amplified privacy
concerns, necessitating methods that protect identity while maintaining
recognition utility. Existing face anonymization methods typically focus on
obscuring identity but fail to meet the requirements of biometric template
protection, including revocability, unlinkability, and irreversibility. We
propose FaceAnonyMixer, a cancelable face generation framework that leverages
the latent space of a pre-trained generative model to synthesize
privacy-preserving face images. The core idea of FaceAnonyMixer is to
irreversibly mix the latent code of a real face image with a synthetic code
derived from a revocable key. The mixed latent code is further refined through
a carefully designed multi-objective loss to satisfy all cancelable biometric
requirements. FaceAnonyMixer is capable of generating high-quality cancelable
faces that can be directly matched using existing FR systems without requiring
any modifications. Extensive experiments on benchmark datasets demonstrate that
FaceAnonyMixer delivers superior recognition accuracy while providing
significantly stronger privacy protection, achieving over an 11% gain on
commercial API compared to recent cancelable biometric methods. Code is
available at: https://github.com/talha-alam/faceanonymixer.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [102] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 该研究提出了一种新的对话后处理方法，通过结合语音基础模型和 LLAMA 模型，为转录的对话添加说话人特征元数据标签，无需进行模型微调，即可在扬声器画像任务上取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 为了在对话转录流水线中，通过添加说话人特征（如年龄、性别和情绪）的元数据标签来丰富转录的对话内容，作为一种补充性的后处理步骤。

Method: 该方法结合了冻结的语音基础模型（如 Whisper 或 WavLM）和一个冻结的 LLAMA 语言模型，通过使用轻量级、高效的连接器来桥接音频和语言表示，从而推断说话人属性，无需对任一模型进行特定任务的微调。此外，研究还表明，冻结的 LLAMA 模型可以直接比较 x-vectors。

Result: 使用轻量级、高效的连接器，在扬声器画像任务上取得了有竞争力的性能。在某些场景下，冻结的 LLAMA 模型可以直接比较 x-vectors，实现了 8.8% 的错误率。

Conclusion: 该方法在扬声器画像任务上取得了有竞争力的性能，同时保持了模块化和速度。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [103] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: Tokenization algorithms often disadvantage lower-resource languages. We propose Parity-aware BPE, which prioritizes equitable token counts across languages by improving compression for the worst-compressed languages, with minimal impact on overall performance.


<details>
  <summary>Details</summary>
Motivation: Standard algorithms for learning tokenizers rely on frequency-based objectives, which favor languages dominant in the training data and consequently leave lower-resource languages with tokenizations that are disproportionately longer, morphologically implausible, or even riddled with <UNK> placeholders. This phenomenon ultimately amplifies computational and financial inequalities between users from different language backgrounds.

Method: We introduce Parity-aware Byte Pair Encoding (BPE), a variant of the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes the compression gain of the currently worst-compressed language, trading a small amount of global compression for cross-lingual parity.

Result: Parity-aware BPE leads to more equitable token counts across languages, with negligible impact on global compression rate and no substantial effect on language-model performance in downstream tasks.

Conclusion: Parity-aware BPE can lead to more equitable token counts across languages with negligible impact on global compression rate and no substantial effect on language-model performance in downstream tasks.

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [104] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: A joint model improved ASR and pitch accent detection, showing the value of prosody in speech models.


<details>
  <summary>Details</summary>
Motivation: To boost the performance of Automatic Speech Recognition (ASR) systems using semi-supervised speech representations by incorporating pitch accent detection.

Method: A joint ASR and pitch accent detection model was introduced, combining semi-supervised speech representations with a pitch accent detection module.

Result: The pitch accent detection component achieved a significant improvement in F1-score (41% gap closure). The ASR performance saw a 28.3% reduction in Word Error Rate (WER) on LibriSpeech under limited resource fine-tuning.

Conclusion: The study highlights the importance of incorporating prosodic cues like pitch accent into pretrained speech models to improve ASR performance, especially in resource-limited scenarios.

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [105] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 大型语言模型在个性一致性方面存在严重问题，即使是较大的模型和常用的稳定化措施也无法解决，这可能使基于个性的对齐策略在安全关键应用中失效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全部署时需要一致的行为模式，但其类似个性的特征却知之甚少。本研究旨在全面评估不同规模的开源语言模型在模拟人类个性时的稳定性。

Method: 本研究提出了PERSIST（PERsonality Stability in Synthetic Text）框架，该框架使用传统的（BFI-44, SD3）和新颖的、针对LLM改编的个性测量工具，系统地测试了25个以上不同规模（1B-671B参数）的开源模型，评估了超过500,000个响应。研究中操控了问题的顺序、释义、角色设定和推理模式等因素。

Result: 研究发现，即使是参数量大于400B的模型，其响应变异性（SD > 0.4）也相当大。仅仅是提示顺序的微小变动就可能导致个性测量发生高达20%的变化。旨在稳定行为的措施（如思维链推理、详细的角色设定、对话历史）反而可能增加变异性。针对LLM改编的测量工具与以人类为中心的版本一样不稳定，这表明问题根源在于模型架构而非翻译限制。

Conclusion: 本研究表明，当前的大型语言模型（LLMs）缺乏真正的行为一致性基础。即使是规模较大的模型，其响应也表现出显著的变异性，并且像思维链（chain-of-thought）推理、详细的指令和对话历史等旨在稳定行为的干预措施，反而可能增加变异性。这表明，在需要可预测行为的安全关键应用中，基于个性的对齐策略可能根本上不足。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [106] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: RCR-Router 是一种新的上下文路由框架，可提高多主体 LLM 的效率和适应性，方法是动态选择相关的记忆子集并优化其上下文，从而减少令牌消耗并保持答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有的协调方案通常依赖于静态或全上下文路由策略，这会导致过多的令牌消耗、冗余的内存暴露以及跨交互回合的有限适应性。

Method: 提出了一种名为 RCR-Router 的模块化、角色感知上下文路由框架，该框架根据代理的角色和任务阶段动态选择相关的记忆子集，并遵循严格的令牌预算。使用轻量级评分策略来指导记忆选择，并通过将代理输ায়迭代地集成到共享记忆库中来实现渐进式上下文优化。此外，还提出了一个答案质量评分（AQS）指标来评估 LLM 生成的解释。

Result: 在 HotPotQA、MuSiQue 和 2WikiMultihop 三个多跳问答基准上的实验表明，RCR-Router 可将令牌使用量减少高达 30%，同时提高或保持答案质量。

Conclusion: RCR-Router 通过结构化的记忆路由和面向输出的评估，提高了可扩展的多主体 LLM 系统的性能，在降低令牌消耗的同时保持或提高了答案质量。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [107] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 该研究发现大型语言模型会因使用套话而系统性地惩罚回应，即使内容质量相当，并提出了一个评估此类偏见的基准。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）对语言“ Shibboleths ”的反应，这些 Shibboleths 是可能无意中揭示性别、社会阶层或地域背景等人口统计学属性的微妙语言标记。

Method: 通过仔细构建包含100个经验证的问答对的访谈模拟，生成控制的语言变体，以分离特定现象，同时保持语义等价性，从而精确测量自动化评估系统中的人口统计学偏见。

Result: 研究表明，大型语言模型系统性地惩罚某些语言模式，特别是套话，即使在内容质量相当的情况下。套话回应的平均评分低了 25.6%，并证明了该基准在识别模型特定偏见方面的有效性。

Conclusion: 该研究提出了一个检测和衡量人工智能系统中语言歧视的框架，并具有广泛的公平性应用前景。

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [108] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 传统的活动识别评估方法因未能充分考虑动词的语义歧义和图像解释的多样性而存在不足。本研究提出了一种基于聚类的评估框架，该框架通过构建动词义类来解决这些问题，能更准确地反映人类的判断。


<details>
  <summary>Details</summary>
Motivation: 标准的精确匹配评估方法未能充分捕捉视觉活动识别中动词语义和图像解释的固有歧义，导致对模型性能的评估不完整。

Method: 提出了一种视觉语言聚类框架，用于构建动词义类，从而实现更鲁棒的评估。

Result: 在 imSitu 数据集上的分析表明，每个图像平均映射到 2.8 个义类，每个类代表图像的一个不同视角。该框架的评估结果表明，基于聚类的评估方法比标准评估方法更能与人类判断保持一致。

Conclusion: 研究表明，基于聚类的评估方法比标准的基于精确匹配的评估方法更能与人类判断保持一致，从而对模型性能进行更细致的评估。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [109] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 一种新的多阶段大语言模型框架，用于从文本中提取社会健康决定因素（SDoH），以帮助预防自杀。该框架提高了提取的准确性和模型的可解释性，并比现有模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 理解导致自杀事件的社会健康决定因素（SDoH）对于早期干预和预防至关重要。然而，数据驱动的方法面临长尾因子分布、分析自杀事件前的关键压力源以及模型可解释性有限等挑战。

Method: 提出一个多阶段大语言模型框架，用于从非结构化文本中提取社会健康决定因素（SDoH）因子。将该方法与BioBERT、GPT-3.5-turbo和DeepSeek-R1等模型进行比较，并评估了模型解释如何帮助用户更快、更准确地标注SDoH因子。分析包括自动化比较和试点用户研究。

Result: 所提出的框架在提取SDoH因子的总体任务和检索相关上下文的细粒度任务上均表现出性能提升。此外，研究表明，微调一个更小、面向特定任务的模型可以实现相当或更好的性能，同时降低推理成本。多阶段设计不仅增强了提取能力，还提供了中间解释，提高了模型的可解释性。

Conclusion: 本研究提出的方法提高了从非结构化文本中提取与自杀相关的社会健康决定因素（SDoH）的准确性和透明度。这些进步有潜力支持早期识别高风险个体，并为制定更有效的预防策略提供信息。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [110] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 通过结构熵最小化分割对话并两步提取情感四元组，提高了DiaASQ任务的性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨整个对话学习词语关系时，会引入不必要的噪声，因为对话常包含多个语义上独立的子对话，缺乏明确的依赖关系。为了解决这个问题，本文旨在通过分割对话来优化提取过程。

Method: 提出了一种新颖的对话分割方法，利用结构熵最小化算法将对话划分为独立的子对话，并采用两步框架进行四元组提取：首先在话语层面提取情感元素，然后在子对话层面匹配四元组。

Result: 实验证明，该方法在DiaASQ任务上取得了最先进的性能，并且计算成本更低。

Conclusion: 本文提出的基于结构熵最小化的方法，在对话方面情感四元组提取任务上取得了最先进的性能，同时显著降低了计算成本。

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [111] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 通过微调LLMs（特别是LLaMA 3.2），可以有效地进行AMR解析，达到与现有先进方法相当的性能水平。


<details>
  <summary>Details</summary>
Motivation: 探索和评估微调解码器模型（LLMs）在AMR（ অর্থ প্রতিনিধিত্ব ）解析任务上的潜力，并与现有先进解析器进行比较。

Method: 对Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled这四种不同的解码器模型进行微调，并在LDC2020T02 Gold AMR3.0测试集上进行了评估。

Result: 直接微调LLMs在AMR解析任务上取得了与复杂先进解析器相当的性能。LLaMA 3.2取得了0.804的SMATCH F1得分，与APT + Silver（IBM）相当，并接近Graphene Smatch（MBSE）的0.854。LLaMA 3.2在语义性能上表现最好，Phi 3.5在结构有效性上表现最好。

Conclusion: 直接微调解码器模型（如LLaMA 3.2）可以达到与先进的AMR解析器相当的性能，LLaMA 3.2在语义性能上表现突出，Phi 3.5在结构有效性方面表现优异。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [112] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: PEFT 和 MTL 的新范式：Align-LoRA 通过对齐表示而不是使用多个适配器，在 LLM 的多任务适应方面取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 在多任务学习 (MTL) 的背景下，探索参数高效微调 (PEFT) 的有效方法，挑战了现有的多适配器/多头方法，并提出了一种新的假设，即有效的 MTL 泛化依赖于学习共享的表示，而不是隔离特定任务的特征。

Method: 提出了一种简化的多头架构，并证明了具有足够增加的秩的单适配器 LoRA 的有效性。引入显式损失来对齐共享适配器空间中的任务表示。

Result: 简化的多头架构和具有更高秩的单适配器 LoRA 的性能优于复杂的多适配器和多头系统。Align-LoRA 显著优于所有基线。

Conclusion: Align-LoRA 通过引入显式损失来对齐共享适配器空间中的任务表示，显著优于所有基线，为将 LLM 适应多个任务提供了一种更简单但更有效的方法。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [113] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 开发了一个名为'MultiCheck'的框架，用于细粒度的多模态事实核查，通过结合文本和图像信息来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 针对以文本和图像支持的、对事实核查系统构成重大挑战的多模态错误信息，提出了一种新的方法。

Method: 提出了一种名为'MultiCheck'的统一框架，该框架结合了专门的文本和图像编码器，并通过一个融合模块来捕获跨模态关系。使用对比学习目标来鼓励声明-证据对在共享的潜在空间中的语义对齐。

Result: 在Factify 2数据集上，MultiCheck取得了0.84的加权F1分数，显著优于基线方法，证明了显式多模态推理的有效性。

Conclusion: MultiCheck框架通过显式多模态推理有效地提高了细粒度多模态事实核查的准确性，在Factify 2数据集上达到了0.84的加权F1分数，超越了基线方法。

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [114] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: BEE-RAG通过熵工程解决了长上下文对RAG性能的影响，提高了适应性。


<details>
  <summary>Details</summary>
Motivation: 从熵工程的角度，识别出检索上下文过长导致的熵无约束增长和注意力稀释是影响RAG性能的关键因素。

Method: 提出了一种基于熵工程的平衡熵RAG（BEE-RAG）框架，该框架利用平衡上下文熵来重塑注意力动态，并将注意力敏感性与上下文长度分离。此外，还引入了一种用于多重要性估计的零样本推理策略和一种参数高效的自适应微调机制。

Result: 实验证明BEE-RAG在多种RAG任务上是有效的。

Conclusion: BEE-RAG框架通过熵不变性原则提高了RAG系统对不同上下文长度的适应性，通过平衡上下文熵重塑注意力动态，确保了稳定的熵水平。

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [115] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在处理序列输入时存在“注意力盆地”现象，即更关注序列的开头和结尾。本文提出了AttnRank方法，通过重新排序输入内容以匹配模型的注意力偏好，从而提升LLMs在多项任务上的性能，且无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 研究了大型语言模型（LLMs）性能对输入信息上下文位置敏感性的原因，发现了“注意力盆地”现象——模型倾向于关注序列的开头和结尾，而忽略中间部分。研究表明，将更高的注意力分配给关键信息是提升模型性能的关键。

Method: 提出了一种名为Attention-Driven Reranking (AttnRank) 的两阶段框架：1. 使用小的校准集估计模型内在的位置注意力偏好；2. 重新排序检索文档或少样本示例，使最显著的内容与高注意力位置对齐。

Result: 通过实验证明，AttnRank在多跳问答和少样本语境学习任务上，针对10种不同架构和规模的大型语言模型，实现了显著的性能提升。

Conclusion: AttnRank是一种模型无关、无需训练、即插即用的方法，只需极低的计算开销，即可在多跳问答和少样本语境学习任务上，针对不同架构和规模的10种大型语言模型实现显著的性能提升，且无需修改模型参数或训练过程。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [116] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 一项新的基准测试PrinciplismQA发现，大型语言模型在医疗伦理方面的表现存在差距，尤其是在应用“仁慈”原则时，闭源模型表现领先，而医学微调可以提高模型能力。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在医疗保健领域的应用需要对其伦理推理进行严格评估，而现有基准测试常常忽略了这一点。

Method: 通过引入一个包含3,648个问题的全面的基准测试PrinciplismQA，系统地评估大型语言模型在核心医学伦理方面的一致性。该基准测试以原则主义为基础，包含高质量的数据集，其中包括从权威教科书中精心挑选的多项选择题，以及从权威医学伦理案例研究文献中提取的开放式问题，并经过医学专家的验证。

Result: 实验表明，模型在伦理知识与实际应用之间存在显著差距，特别是在将伦理原则动态应用于现实场景方面。大多数大型语言模型在涉及“仁慈”原则的困境中挣扎，常常过度强调其他原则。由强大通用能力驱动的前沿闭源模型目前在该基准测试中处于领先地位。值得注意的是，医学领域微调可以增强模型的整体伦理能力，但进一步的进展需要更好地与医学伦理知识保持一致。

Conclusion: PrinciplismQA提供了一个可扩展的框架，用于诊断医疗人工智能在伦理方面的具体弱点，为实现更均衡、更负责任的医疗AI铺平了道路。

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [117] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: ATLANTIS团队致力于解决问答系统中幻觉文本跨度检测问题，通过少样本提示、令牌级分类和微调LLM等方法，在多语言评估中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自然语言生成（NLG）方面取得了显著进展，但仍然容易出现幻觉，生成不正确或误导性的内容。

Method: 本研究探索了有外部上下文和无外部上下文的方法，利用了少样本提示与大型语言模型（LLM）、令牌级分类或在合成数据上微调的LLM。

Result: 我们的方法在西班牙语中取得了最高排名，在英语和德语中也取得了有竞争力的成绩。

Conclusion: 该研究强调了整合相关性以减轻幻觉的重要性，并展示了微调模型和提示工程的潜力。

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [118] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 提出 MulCoT-RD 模型，在资源受限环境下，通过“教师-助教-学生”蒸馏和多任务学习，实现了高效的多模态情感推理生成和分类，仅用 3B 参数即取得优异性能、泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要利用大型语言模型的知识和推理能力进行情感分类，忽略了在资源受限环境下进行自主多模态情感推理生成的需求。

Method: 提出了一种名为 MulCoT-RD 的模型，采用“教师-助教-学生”的蒸馏范式，并结合多任务学习机制，以解决资源受限环境下的多模态情感推理和分类问题。

Result: MulCoT-RD 模型在四个数据集上进行了广泛的实验，证明了其在 JMSRC 任务上的有效性。

Conclusion: MulCoT-RD 模型在 JMSRC 任务上取得了强大的性能，仅用 3B 参数即可实现，同时展现出良好的泛化能力和增强的可解释性。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [119] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 通过识别LLM中的功能网络和关键神经元进行剪枝，以提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法忽略了神经元之间的交互和协作，破坏了LLM的宏观功能架构，导致剪枝性能下降。受人脑功能网络的启发，提出通过识别和保留LLM中的功能网络来解决此挑战。

Method: 将LLM视为数字大脑，通过识别功能网络和关键神经元来进行剪枝。

Result: 提出的方法能够成功识别和定位LLM中的功能网络和关键神经元，实现高效的模型剪枝。

Conclusion: 该研究提出了一种新的结构化剪枝方法，通过识别和保留大型语言模型（LLM）中的功能网络及其关键神经元来实现模型压缩，实验结果证明了该方法在识别功能网络和关键神经元方面的有效性，能够实现高效的模型剪枝。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [120] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost是一个新的代码LLM训练框架，它使用代码片段而非人工指令进行训练，并通过多种技术（如最大团选择、双向预测、错误感知预测、异构增强和异构奖励）来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLM的训练依赖于人工标注的指令，成本高昂且难以扩展，而代码片段资源丰富，存在供需不平衡问题。

Method: CodeBoost框架通过最大团选择、双向预测、错误感知预测、异构增强和异构奖励（包括格式正确性和执行反馈）等组件，从代码片段中学习。

Result: 在多个代码LLM和基准测试上的广泛实验证明，CodeBoost能够持续提升模型性能。

Conclusion: CodeBoost通过纯粹利用代码片段进行训练，无需人工标注的指令，可以有效提升代码大语言模型（LLMs）的性能，并且具有良好的可扩展性。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [121] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 本研究通过ASCoT方法解决了LLM推理中的“后期脆弱性”问题，通过自适应性验证和校正显著提高了推理准确性。


<details>
  <summary>Details</summary>
Motivation: 挑战了“级联失效”假设，发现了“后期脆弱性”现象，即LLM推理链中的后期错误比早期错误更具破坏性。

Method: 提出自适应性思维链（ASCoT）方法，包含自适应性验证管理器（AVM）和多视角自校正引擎（MSCE）。AVM利用位置影响评分函数I(k)识别和优先处理高风险后期步骤，MSCE则针对性地对这些关键步骤进行双通路校正。

Result: ASCoT在GSM8K和MATH等基准测试上取得了优于标准CoT等强基线的准确性。

Conclusion: 本研究通过系统性错误注入实验，挑战了CoT推理中“级联失效”的普遍假设，发现了“后期脆弱性”现象，即后期错误比早期错误更容易导致最终答案出错。为解决此问题，我们提出了自适应性思维链（ASCoT）方法，该方法包含自适应性验证管理器（AVM）和多视角自校正引擎（MSCE）。AVM利用位置影响评分函数I(k)识别和优先处理高风险后期步骤，MSCE则针对性地对这些关键步骤进行双通路校正。在GSM8K和MATH等基准测试上的大量实验表明，ASCoT的准确性显著优于包括标准CoT在内的强基线。研究强调了诊断LLM推理中特定失效模式的重要性，并倡导从统一验证策略转向关注脆弱性的自适应校正机制。

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


### [122] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
*Sukannya Purkayastha,Nils Dycke,Anne Lauscher,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本研究提出了一种利用大型语言模型（LLM）生成合成数据并训练对话代理的方法，以提高元审稿的效率。实验结果表明，该方法生成的对话代理比现有的助手更有效。


<details>
  <summary>Details</summary>
Motivation: 以往对元审稿的研究将其视为一个基于审稿报告的摘要问题。然而，元审稿本质上是一个决策过程，需要权衡审稿人的论点并将其置于更广泛的背景中。对话代理已被证明可以有效地辅助此类决策任务。因此，本研究旨在探讨实现能够有效辅助元审稿的对话代理所面临的实际挑战。

Method: 首先，利用大型语言模型（LLM）和自我完善策略生成合成数据，以提高对话与专家领域的关联性。其次，利用这些数据训练专门用于元审稿的对话代理，并将其与现成的基于 LLM 的代理进行比较。最后，在实际的元审稿场景中应用这些代理，以验证其有效性。

Result: 实验表明，所提出的方法生成的合成数据质量更高，可用于训练元审稿助手。此外，专门为元审稿训练的对话代理的表现优于现成的基于 LLM 的助手，并在实际应用中证明了其在提高元审稿效率方面的有效性。

Conclusion: 通过生成合成数据并训练专门的对话代理，可以提高元审稿的效率。

Abstract: Meta-reviewing is a pivotal stage in the peer-review process, serving as the
final step in determining whether a paper is recommended for acceptance. Prior
research on meta-reviewing has treated this as a summarization problem over
review reports. However, complementary to this perspective, meta-reviewing is a
decision-making process that requires weighing reviewer arguments and placing
them within a broader context. Prior research has demonstrated that
decision-makers can be effectively assisted in such scenarios via dialogue
agents. In line with this framing, we explore the practical challenges for
realizing dialog agents that can effectively assist meta-reviewers. Concretely,
we first address the issue of data scarcity for training dialogue agents by
generating synthetic data using Large Language Models (LLMs) based on a
self-refinement strategy to improve the relevance of these dialogues to expert
domains. Our experiments demonstrate that this method produces higher-quality
synthetic data and can serve as a valuable resource towards training
meta-reviewing assistants. Subsequently, we utilize this data to train dialogue
agents tailored for meta-reviewing and find that these agents outperform
\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our
agents in real-world meta-reviewing scenarios and confirm their effectiveness
in enhancing the efficiency of meta-reviewing.\footnote{Code and Data:
https://github.com/UKPLab/arxiv2025-meta-review-as-dialog

</details>


### [123] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
*Nikita Dragunov,Temurbek Rahmatullaev,Elizaveta Goncharova,Andrey Kuznetsov,Anton Razzhigaev*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.

</details>


### [124] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: CGRS是一种新的方法，通过在模型自信时抑制反思来减少LRLM的过度思考，从而降低成本而不影响性能。


<details>
  <summary>Details</summary>
Motivation: 现有的长链思维推理模型（LRLMs）中的反思行为（如“等等”和“或者”）虽然能提高性能，但也可能导致过度思考问题，增加token使用量、推理成本和降低实用性。

Method: CGRS通过动态抑制模型生成反思触发词来解决过度思考问题，当模型对其当前响应表现出高置信度时，可以防止冗余的反思循环。

Result: 在AIME24、AMC23、MATH500和GPQA-D等四个推理基准上的实验表明，CGRS能将token使用量平均减少18.5%至41.9%，同时保持准确性。与现有基线方法相比，CGRS在长度缩减和性能之间取得了最佳平衡。

Conclusion: CGRS能够有效减少LRLM的过度思考问题，在不损害准确性的前提下显著降低token使用量和推理成本。

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [125] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
*Fenya Wasserroth,Eleftherios Avramidis,Vera Czehmann,Tanja Kojic,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 本研究调查了在 Hololens 2 设备上手语虚拟化身添加调整功能的影响。发现尽管用户喜欢可调节的设置，但可用性、可理解性和用户体验均未得到显著改善。主要问题包括缺乏口型和面部表情、模糊的手形以及交互界面的问题。用户发现系统在美学上比在功能上更令人愉悦，并且在与可调节虚拟化身交互时感到压力更大。研究强调，仅个性化是不够的，手语虚拟化身必须默认是可理解的。建议改进动画、交互界面和使用参与式设计。


<details>
  <summary>Details</summary>
Motivation: 本论文提出了对在现有的微软 Hololens 2 设备上的手语（SL）虚拟化身添加调整功能的调查。

Method: 通过对专家德国手语（DGS）用户在特定用例中与可调节和不可调节虚拟化身的交互进行详细分析，本研究确定了影响此类系统可理解性、用户体验（UX）和可接受性的关键因素。

Result: 尽管用户偏爱可调节设置，但用户体验或可理解性没有观察到显著改善，仍处于较低水平，存在手语缺失（口型和面部表情）和实施问题（手形模糊、缺乏反馈和菜单定位）。享乐质量的评分高于实用质量，表明用户发现该系统在情感或美学上更令人愉悦，而非功能上更有用。可调节虚拟化身的压力水平更高，反映了较低的性能、较大的努力和更多的挫败感。此外，人们还担心 Hololens 调整姿势是否直观且易于熟悉。

Conclusion: 个性化本身不足以提高手语虚拟化身的可用性，手语虚拟化身必须默认具有可理解性。关键建议包括增强口型和面部动画、改进交互界面以及应用参与式设计。

Abstract: This paper presents an investigation into the impact of adding adjustment
features to an existing sign language (SL) avatar on a Microsoft Hololens 2
device. Through a detailed analysis of interactions of expert German Sign
Language (DGS) users with both adjustable and non-adjustable avatars in a
specific use case, this study identifies the key factors influencing the
comprehensibility, the user experience (UX), and the acceptability of such a
system. Despite user preference for adjustable settings, no significant
improvements in UX or comprehensibility were observed, which remained at low
levels, amid missing SL elements (mouthings and facial expressions) and
implementation issues (indistinct hand shapes, lack of feedback and menu
positioning). Hedonic quality was rated higher than pragmatic quality,
indicating that users found the system more emotionally or aesthetically
pleasing than functionally useful. Stress levels were higher for the adjustable
avatar, reflecting lower performance, greater effort and more frustration.
Additionally, concerns were raised about whether the Hololens adjustment
gestures are intuitive and easy to familiarise oneself with. While
acceptability of the concept of adjustability was generally positive, it was
strongly dependent on usability and animation quality. This study highlights
that personalisation alone is insufficient, and that SL avatars must be
comprehensible by default. Key recommendations include enhancing mouthing and
facial animation, improving interaction interfaces, and applying participatory
design.

</details>


### [126] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
*Samy Ateia,Udo Kruschwitz*

Main category: cs.CL

TL;DR: 本研究探索了LLM在生物医学专业搜索中的自我反馈机制，并评估了Gemini-Flash 2.0、o3-mini、o4-mini和DeepSeek-R1等模型在查询扩展和答案生成方面的表现。研究发现自我反馈策略在不同模型和任务上的表现各异，为未来研究LLM自我纠错能力和与人类专家反馈的比较提供了见解。


<details>
  <summary>Details</summary>
Motivation: 将Agentic RAG和‘deep research’系统应用于生物医学研究等领域特定专业搜索存在挑战，因为自动化系统可能会减少用户参与，并与专家信息需求不符。专业搜索任务通常需要高度的用户专业知识和透明度。

Method: 本研究采用了一种自我反馈机制，其中LLM会生成、评估然后优化其输出，以进行查询扩展和多种答案类型（是/否、事实、列表、理想）。研究人员调查了这种迭代的自我纠正是否能提高性能，以及推理模型是否更能生成有用的反馈。

Result: 初步结果表明，在不同模型和任务上，自我反馈策略的表现各不相同。

Conclusion: 初步结果表明，在不同模型和任务上，自我反馈策略的表现各不相同。这项工作为理解LLM的自我纠错能力提供了见解，并为未来比较LLM生成的反馈与人类专家直接输入在这些搜索系统中的有效性提供了信息。

Abstract: Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim
to enable autonomous search processes where Large Language Models (LLMs)
iteratively refine outputs. However, applying these systems to domain-specific
professional search, such as biomedical research, presents challenges, as
automated systems may reduce user involvement and misalign with expert
information needs. Professional search tasks often demand high levels of user
expertise and transparency. The BioASQ CLEF 2025 challenge, using
expert-formulated questions, can serve as a platform to study these issues. We
explored the performance of current reasoning and nonreasoning LLMs like
Gemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our
methodology was a self-feedback mechanism where LLMs generated, evaluated, and
then refined their outputs for query expansion and for multiple answer types
(yes/no, factoid, list, ideal). We investigated whether this iterative
self-correction improves performance and if reasoning models are more capable
of generating useful feedback. Preliminary results indicate varied performance
for the self-feedback strategy across models and tasks. This work offers
insights into LLM self-correction and informs future work on comparing the
effectiveness of LLM-generated feedback with direct human expert input in these
search systems.

</details>


### [127] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
*Eleftherios Avramidis,Vera Czehmann,Fabian Deckert,Lorenz Hufe,Aljoscha Lipski,Yuni Amaloa Quintero Villalobos,Tae Kwon Rhee,Mengqian Shi,Lennart Stölting,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文发布了一个包含12种手语的大型视频平行语料库，其中包含8种拉丁美洲手语的语料，并提供了数据收集方法和统计信息。


<details>
  <summary>Details</summary>
Motivation: 为了填补手语资源的空白，特别是拉丁美洲手语的平行语料库，并扩大已有的德国手语语料库规模。

Method: 通过收集和处理来自新闻、政府和教育频道等在线资源的视频，经过数据收集、内容创作者告知与授权、爬取和裁剪等多个阶段创建了该语料库。

Result: 创建了一个包含1300多小时、4381个视频文件、130万条字幕和1400万个词元的平行语料库，其中包含8种拉丁美洲手语的首个平行语料库，德国手语语料库规模是之前的十倍。

Conclusion: 本文介绍了12种手语的平行语料库，为这些语言的自然语言处理研究提供了资源。

Abstract: We present a collection of parallel corpora of 12 sign languages in video
format, together with subtitles in the dominant spoken languages of the
corresponding countries. The entire collection includes more than 1,300 hours
in 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.
Most notably, it includes the first consistent parallel corpora for 8 Latin
American sign languages, whereas the size of the German Sign Language corpora
is ten times the size of the previously available corpora. The collection was
created by collecting and processing videos of multiple sign languages from
various online sources, mainly broadcast material of news shows, governmental
bodies and educational channels. The preparation involved several stages,
including data collection, informing the content creators and seeking usage
approvals, scraping, and cropping. The paper provides statistics on the
collection and an overview of the methods used to collect the data.

</details>


### [128] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
*Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng chan*

Main category: cs.CL

TL;DR: MyCulture是一个评估大型语言模型（LLMs）在马来西亚文化方面的新基准，采用开放式选择题以减少偏见。评估显示LLMs在文化理解方面存在差异，需要更具文化适应性的模型。


<details>
  <summary>Details</summary>
Motivation: 由于训练数据主要包含英语和中文等高资源语言，大型语言模型（LLMs）常常表现出文化偏见，这在低资源语言环境中准确表示和评估不同文化背景方面带来了挑战。因此，需要一个能够全面评估LLMs在马来西亚文化方面的基准。

Method: 提出了一种名为MyCulture的新型基准，用于评估LLMs在马来西亚文化方面的能力。该基准采用新颖的开放式选择题形式（无预定义选项），以减少猜测和格式偏差。此外，还通过比较结构化与自由形式输出的性能以及多语言提示的变化来分析结构偏差和语言偏差。

Result: 评估结果显示，不同地区和国际的LLMs在文化理解方面存在显著差异，这表明需要开发和评估更具文化适应性和语言包容性的LLMs。

Conclusion: LLMs在理解和代表马来西亚文化方面存在显著差异，凸显了在开发和评估LLMs时需要建立符合文化和语言包容性的基准。

Abstract: Large Language Models (LLMs) often exhibit cultural biases due to training
data dominated by high-resource languages like English and Chinese. This poses
challenges for accurately representing and evaluating diverse cultural
contexts, particularly in low-resource language settings. To address this, we
introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on
Malaysian culture across six pillars: arts, attire, customs, entertainment,
food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,
MyCulture employs a novel open-ended multiple-choice question format without
predefined options, thereby reducing guessing and mitigating format bias. We
provide a theoretical justification for the effectiveness of this open-ended
structure in improving both fairness and discriminative power. Furthermore, we
analyze structural bias by comparing model performance on structured versus
free-form outputs, and assess language bias through multilingual prompt
variations. Our evaluation across a range of regional and international LLMs
reveals significant disparities in cultural comprehension, highlighting the
urgent need for culturally grounded and linguistically inclusive benchmarks in
the development and assessment of LLMs.

</details>


### [129] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
*Ming Zhang,Yujiong Shen,Jingyi Deng,Yuhui Wang,Yue Zhang,Junzhe Wang,Shichun Liu,Shihan Dou,Huayu Sha,Qiyuan Peng,Changhao Jiang,Jingqi Tong,Yilong Wu,Zhihao Zhang,Mingqi Wu,Zhiheng Xi,Mingxu Chai,Tao Liang,Zhihui Fei,Zhen Wang,Mingyang Wan,Guojun Ma,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: LLMEval-3是一个动态评估框架，使用大规模、动态生成的研究生级别问题集来克服静态基准的数据污染和排行榜过拟合问题。它通过先进的防作弊和LLM-as-a-judge技术，提供了更可靠的模型能力评估，并揭示了传统基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在静态基准上的评估方法容易受到数据污染和排行榜过拟合的影响，这些关键问题模糊了模型真实能力的展现。为了解决这一问题，我们引入了LLMEval-3框架，用于LLM的动态评估。

Method: LLMEval-3框架通过动态采样220k研究生级别的问题库来构建测试集，采用自动化流程确保完整性，包括抗数据污染的数据整理、新颖的防作弊架构以及与人类专家高达90%一致率的校准LLM-as-a-judge过程，并辅以相对排名系统进行公平比较。

Result: 为期20个月的纵向研究，涵盖了近50个主流模型，揭示了知识记忆能力的性能上限，并暴露了静态基准无法检测到的数据污染漏洞。该框架在排名稳定性和一致性方面表现出卓越的鲁棒性，为动态评估范式提供了强有力的实证支持。

Conclusion: LLMEval-3提供了一种超越传统基准测试的、可信的LLM能力评估方法，有助于推动更值得信赖的评估标准的制定。

Abstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is
vulnerable to data contamination and leaderboard overfitting, critical issues
that obscure true model capabilities. To address this, we introduce LLMEval-3,
a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary
bank of 220k graduate-level questions, from which it dynamically samples unseen
test sets for each evaluation run. Its automated pipeline ensures integrity via
contamination-resistant data curation, a novel anti-cheating architecture, and
a calibrated LLM-as-a-judge process achieving 90% agreement with human experts,
complemented by a relative ranking system for fair comparison. An 20-month
longitudinal study of nearly 50 leading models reveals a performance ceiling on
knowledge memorization and exposes data contamination vulnerabilities
undetectable by static benchmarks. The framework demonstrates exceptional
robustness in ranking stability and consistency, providing strong empirical
validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and
credible methodology for assessing the true capabilities of LLMs beyond
leaderboard scores, promoting the development of more trustworthy evaluation
standards.

</details>


### [130] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
*Chenzhuo Zhao,Xinda Wang,Yue Huang,Junting Lu,Ziqian Liu*

Main category: cs.CL

TL;DR: TASE 是一个评估 LLMs 在 token 级别理解和结构化推理能力的全面基准，涵盖多语言和多种任务。评估结果显示，尽管 LLMs 在语义任务上表现优异，但在细粒度任务上仍有待提高，人类表现优于 LLMs。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在高级语义任务上表现出色，但在需要精确性和控制力的细粒度 token 级别理解和结构化推理方面存在挣扎。

Method: 提出 TASE 基准，涵盖 10 项任务，分为 token 意识和结构理解两大类，并支持中、英、韩三种语言。TASE 包含 35,927 个实例的评估集，并提供了一个可扩展的合成数据生成管线用于训练。对超过 30 个主流 LLMs 进行了评估，并使用 GRPO 训练方法定制了 Qwen2.5-14B 模型。

Result: 在 TASE 基准的评估中，人类表现显著优于所有接受测试的 LLMs，显示出 LLMs 在 token 级别推理方面存在持续的弱点。TASE 揭示了这些局限性，并为未来在低级别语言理解和跨语言泛化方面的改进提供了新的诊断工具。

Conclusion: 大型语言模型（LLMs）在处理细粒度的 token 级别理解和结构化推理方面存在持续的不足，人类在该领域的表现明显优于当前 LLMs。

Abstract: While large language models (LLMs) have demonstrated remarkable performance
on high-level semantic tasks, they often struggle with fine-grained,
token-level understanding and structural reasoning--capabilities that are
essential for applications requiring precision and control. We introduce TASE,
a comprehensive benchmark designed to evaluate LLMs' ability to perceive and
reason about token-level information across languages. TASE covers 10 tasks
under two core categories: token awareness and structural understanding,
spanning Chinese, English, and Korean, with a 35,927-instance evaluation set
and a scalable synthetic data generation pipeline for training. Tasks include
character counting, token alignment, syntactic structure parsing, and length
constraint satisfaction. We evaluate over 30 leading commercial and open-source
LLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a
custom Qwen2.5-14B model using the GRPO training method. Results show that
human performance significantly outpaces current LLMs, revealing persistent
weaknesses in token-level reasoning. TASE sheds light on these limitations and
provides a new diagnostic lens for future improvements in low-level language
understanding and cross-lingual generalization. Our code and dataset are
publicly available at https://github.com/cyzcz/Tase .

</details>


### [131] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
*Li-Chun Lu,Miri Liu,Pin-Chun Lu,Yufei Tian,Shao-Hua Sun,Nanyun Peng*

Main category: cs.CL

TL;DR: 现有的创造力评估指标在不同创意领域表现不一且存在局限性，需要更可靠的评估框架。


<details>
  <summary>Details</summary>
Motivation: 在创意领域，准确评估创造力至关重要，但现有的评估指标存在局限性，需要进行系统性的比较和分析，以了解它们在不同创意任务中的表现和适用性。

Method: 本研究系统地检查、分析和比较了具有代表性的创造力指标，包括创造力指数、困惑度、句法模板和LLM-as-a-Judge，涵盖了创意写作、非常规问题解决和研究构思等不同的创意领域。

Result: 研究结果表明，这些创造力指标之间的一致性有限，它们衡量了创造力的不同方面。具体来说，创造力指数主要关注词汇多样性，困惑度对模型的置信度敏感，句法模板难以评估概念创造力，而LLM-as-a-Judge则存在不稳定性和偏见。

Conclusion: 现有的创造力评估指标（如创造力指数、困惑度、句法模板和LLM-as-a-Judge）在不同的创意领域（如创意写作、非常规问题解决和研究构思）中表现出有限的一致性，并且各自捕捉了创造力的不同维度。这些指标存在关键局限性，例如创造力指数侧重于词汇多样性、困惑度对模型置信度的敏感性以及句法模板无法捕捉概念创造力。此外，LLM-as-a-Judge表现出不稳定的偏见。

Abstract: We systematically examine, analyze, and compare representative creativity
measures--creativity index, perplexity, syntactic templates, and
LLM-as-a-Judge--across diverse creative domains, including creative writing,
unconventional problem-solving, and research ideation. Our analyses reveal that
these metrics exhibit limited consistency, capturing different dimensions of
creativity. We highlight key limitations, including the creativity index's
focus on lexical diversity, perplexity's sensitivity to model confidence, and
syntactic templates' inability to capture conceptual creativity. Additionally,
LLM-as-a-Judge shows instability and bias. Our findings underscore the need for
more robust, generalizable evaluation frameworks that better align with human
judgments of creativity.

</details>


### [132] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: LAG是一种新的范式，通过将问题分解为子问题并进行依赖感知推理来增强LLM的知识，从而提高其在知识密集型任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在处理需要专业知识的知识密集型任务时，由于依赖于直接语义检索且缺乏结构化逻辑组织，常常在复杂推理场景中挣扎，并产生幻觉。

Method: LAG首先将复杂问题分解为由逻辑依赖关系排序的原子子问题。然后，它按顺序解决这些子问题，并利用先前的答案来指导后续子问题的上下文检索，确保了逻辑链条的逐步基础。为了防止错误传播，LAG包含了一个逻辑终止机制，该机制在遇到无法回答的子问题时会停止推理，并减少在过度推理上浪费的计算量。最后，它综合所有子问题解决方案来生成经过验证的响应。

Result: 实验结果表明，LAG在四个基准数据集上显著提高了推理鲁棒性，减少了幻觉，并将LLM的问题解决方式与人类认知对齐。

Conclusion: LAG通过将复杂问题分解为原子子问题并进行依赖感知推理，显著增强了LLM在知识密集型任务中的推理鲁棒性，减少了幻觉，并将LLM的问题解决方式与人类认知对齐，为现有的RAG系统提供了一个原则性的替代方案。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


### [133] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
*Harsh Nishant Lalai,Raj Sanjay Shah,Jiaxin Pei,Sashank Varma,Yi-Chia Wang,Ali Emami*

Main category: cs.CL

TL;DR: LLMs在20问游戏中表现出地理偏见，在推断来自“全球北方”和“全球西方”的实体时比来自“全球南方”和“全球东方”的实体更成功。此偏见不因游戏语言而异，并且不能完全用Wikipedia流量或预训练语料库频率来解释。研究人员发布了Geo20Q+数据集和代码，以促进对LLMs中隐藏偏见的进一步研究。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在消除显式偏差方面进行了大量调整，但它们常常表现出源于其预训练数据的微妙的隐式偏差。本研究的动机是开发一种新的方法来研究这些隐藏的偏见，特别关注模型在主动提问时而不是被动回答时如何表现。

Method: 本研究提出了一种研究LLM行为的新方法，即在模型主动提问时进行研究，而不是直接探测。研究使用了20个问题游戏，这是一个多轮推理任务，并引入了一个名为Geo20Q+的新数据集，其中包含来自不同地区的知名人物和具有文化意义的物体。评估在两种游戏配置（标准的20个问题和无限轮）和七种语言（英语、印地语、普通话、日语、法语、西班牙语和土耳其语）中进行。

Result: 研究结果显示存在地理差异：LLMs在推断“全球北方”实体方面比推断“全球南方”实体更成功，在推断“全球西方”实体方面也比推断“全球东方”实体更成功。Wikipedia的页面浏览量和预训练语料库的频率与性能有轻微关联，但未能完全解释这些差异。重要的是，游戏语言对性能差距的影响很小。

Conclusion: LLMs在20问游戏中表现出地理偏见，在推断来自“全球北方”和“全球西方”的实体时比推断来自“全球南方”和“全球东方”的实体更成功。语言对这些性能差距的影响很小。这些发现强调了在LLMs中揭示隐藏的微妙偏见的创造性、自由形式评估框架的价值。

Abstract: Large Language Models (LLMs) have been extensively tuned to mitigate explicit
biases, yet they often exhibit subtle implicit biases rooted in their
pre-training data. Rather than directly probing LLMs with human-crafted
questions that may trigger guardrails, we propose studying how models behave
when they proactively ask questions themselves. The 20 Questions game, a
multi-turn deduction task, serves as an ideal testbed for this purpose. We
systematically evaluate geographic performance disparities in entity deduction
using a new dataset, Geo20Q+, consisting of both notable people and culturally
significant objects (e.g., foods, landmarks, animals) from diverse regions. We
test popular LLMs across two gameplay configurations (canonical 20-question and
unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,
French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs
are substantially more successful at deducing entities from the Global North
than the Global South, and the Global West than the Global East. While
Wikipedia pageviews and pre-training corpus frequency correlate mildly with
performance, they fail to fully explain these disparities. Notably, the
language in which the game is played has minimal impact on performance gaps.
These findings demonstrate the value of creative, free-form evaluation
frameworks for uncovering subtle biases in LLMs that remain hidden in standard
prompting setups. By analyzing how models initiate and pursue reasoning goals
over multiple turns, we find geographic and cultural disparities embedded in
their reasoning processes. We release the dataset (Geo20Q+) and code at
https://sites.google.com/view/llmbias20q/home.

</details>


### [134] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
*Santosh T. Y. S. S,Youssef Tarek Elkhayat,Oana Ichim,Pranav Shetty,Dongsheng Wang,Zhiqiang Ma,Armineh Nourbakhsh,Xiaomo Liu*

Main category: cs.CL

TL;DR: CoCoLex是一种新的解码策略，通过结合模型输出和基于上下文复制来提高法律文本生成的准确性，特别擅长处理长文本。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（Retrieval-Augmented Generation）虽然可以为LLM提供外部知识，但不能保证有效整合上下文。上下文感知解码策略虽然可以放大相关上下文的影响，但通常不明确强制执行对上下文的忠实性，这在法律领域尤为重要，因为LLM容易产生不忠实、无根据或幻觉的输出。

Method: 提出了一种名为CoCoLex（Confidence-guided Copy-based Decoding for Legal Text Generation）的解码策略，该策略动态地将模型产生的词汇分布与基于从上下文中复制的分布进行插值，并基于模型的置信度鼓励直接复制，以确保更高的忠实度。

Result: 在五个法律基准测试上进行的实验结果表明，CoCoLex在法律文本生成方面，尤其是在长文本生成任务上，优于现有的上下文感知解码方法。

Conclusion: CoCoLex通过动态地将模型产生的词汇分布与从上下文中复制的分布进行插值，并基于模型的置信度鼓励直接复制，从而提高了法律文本生成的忠实度，在长文本生成任务上表现优于现有的上下文感知解码方法。

Abstract: Due to their ability to process long and complex contexts, LLMs can offer key
benefits to the Legal domain, but their adoption has been hindered by their
tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While
Retrieval-Augmented Generation offers a promising solution by grounding
generations in external knowledge, it offers no guarantee that the provided
context will be effectively integrated. To address this, context-aware decoding
strategies have been proposed to amplify the influence of relevant context, but
they usually do not explicitly enforce faithfulness to the context. In this
work, we introduce Confidence-guided Copy-based Decoding for Legal Text
Generation (CoCoLex)-a decoding strategy that dynamically interpolates the
model produced vocabulary distribution with a distribution derived based on
copying from the context. CoCoLex encourages direct copying based on the
model's confidence, ensuring greater fidelity to the source. Experimental
results on five legal benchmarks demonstrate that CoCoLex outperforms existing
context-aware decoding methods, particularly in long-form generation tasks.

</details>


### [135] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
*Guang Yang,Xinyang Liu*

Main category: cs.CL

TL;DR: 该研究提出了一种新的方法来提高大型语言模型在多项选择题问答中的可靠性，特别是在高风险领域。该方法通过分析模型输出的频率来量化不确定性，并提供可证明的准确性保证，即使在无法访问模型内部细节（黑盒）的情况下也有效。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在多项选择题问答（MCQA）中存在的不可靠性问题，如幻觉和过度自信，这些问题限制了它们在高风险领域的应用。

Method: 提出了一种在黑盒设置下的基于频率的不确定性量化方法，并利用共形预测（CP）来确保可证明的覆盖率保证。该方法通过对每个输入的模型输出分布进行多次独立采样，并将最频繁的样本作为参考来计算预测熵（PE）。

Result: 在六个LLM和四个数据集（MedMCQA、MedQA、MMLU、MMLU-Pro）上的实验评估表明，基于频率的PE在区分正确和错误预测方面优于基于logit的PE（以AUROC衡量）。此外，该方法在用户指定的风险水平下能有效控制经验性错误覆盖率。

Conclusion: 该研究提出了一种基于频率的、在黑盒设置下的不确定性量化方法，并利用共形预测（CP）来确保可证明的覆盖率保证。实验结果表明，基于频率的预测熵（PE）在区分正确和错误预测方面优于基于logit的PE，并且能够有效控制经验性错误覆盖率，证明了在黑盒场景下，采样频率可以作为基于logit概率的可行替代方案。该框架为MCQA中的可靠不确定性量化提供了分布无关、模型无关的解决方案，并具有保证覆盖率的优点，提高了LLM在实际应用中的可信度。

Abstract: Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.

</details>


### [136] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
*Franziska Weeber,Tanise Ceron,Sebastian Padó*

Main category: cs.CL

TL;DR: 本研究发现，多语言大语言模型（MLLMs）在西方语言中，政治观点会跨语言转移，而非各自独立。模型在接受左倾或右倾的政治观点对齐后，这种转移在所有测试语言中几乎同步发生。这说明要让模型在不同语言中表现出符合特定社会文化和政治立场的观点，存在相当大的挑战。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探究公共意见调查所显示的跨文化政治观点差异，是否也会在多语言大语言模型（MLLMs）中体现为跨语言的差异，而目前尚无明确证据。

Method: 本研究通过提示多语言大语言模型（MLLMs）对来自投票建议应用的政治声明（例如，‘我同意/不同意’）的（不）同意情况，来分析和评估MLLMs的政治观点。研究对象包括不同规模的模型，并跨越五种西方语言。为了深入了解模型中语言的交互作用，研究人员在仅使用英语对齐数据通过直接偏好优化（DPO）进行左倾或右倾对齐之前和之后，都对模型进行了评估。

Result: 研究结果显示，未经政治观点对齐处理的MLLMs在所反映的政治观点方面，仅表现出极少数显著的跨语言差异。而在使用直接偏好优化和仅使用英语对齐数据进行左倾或右倾对齐后，政治观点的转变在所有五种语言中几乎是统一地发生。

Conclusion: 本研究得出结论，在西方语言环境中，多语言大语言模型（MLLMs）的政治观点会在不同语言之间转移，这表明在实现MLLMs明确的社会语言、文化和政治对齐方面存在挑战。

Abstract: Public opinion surveys show cross-cultural differences in political opinions
between socio-cultural contexts. However, there is no clear evidence whether
these differences translate to cross-lingual differences in multilingual large
language models (MLLMs). We analyze whether opinions transfer between languages
or whether there are separate opinions for each language in MLLMs of various
sizes across five Western languages. We evaluate MLLMs' opinions by prompting
them to report their (dis)agreement with political statements from voting
advice applications. To better understand the interaction between languages in
the models, we evaluate them both before and after aligning them with more left
or right views using direct preference optimization and English alignment data
only. Our findings reveal that unaligned models show only very few significant
cross-lingual differences in the political opinions they reflect. The political
alignment shifts opinions almost uniformly across all five languages. We
conclude that in Western language contexts, political opinions transfer between
languages, demonstrating the challenges in achieving explicit socio-linguistic,
cultural, and political alignment of MLLMs.

</details>


### [137] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
*Shaoxiong Zhan,Yanlin Lai,Ziyu Lu,Dahua Lin,Ziqing Yang,Fei Tang*

Main category: cs.CL

TL;DR: MathSmith是一个新的框架，通过从头合成高难度数学问题来增强大型语言模型（LLM）的推理能力。它使用PlanetMath数据、九种难度策略和强化学习来生成多样化、有挑战性的问题，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在数学推理方面虽有进展，但受限于高质量、高难度训练数据的稀缺性。现有的合成方法主要依赖于对人类编写的模板进行转换，这限制了数据的多样性和可扩展性。因此，需要一种新的框架来合成更具挑战性的数学问题，以增强大型语言模型的推理能力。

Method: MathSmith框架通过从PlanetMath中随机采样概念-解释对来从头开始构建新的数学问题，而不是修改现有问题，以确保数据的独立性和避免污染。为了提高难度，框架设计了九种预定义的策略作为推理过程中的软约束，并采用强化学习来联合优化结构有效性、推理复杂性和答案一致性。通过追踪自回归提示下的推理轨迹长度来反映认知复杂性，以生成更符合长链思维（long-chain-of-thought）的挑战性问题。此外，还包含一个以弱点为中心的变体生成模块，以实现针对特定概念的定向改进。

Result: 实验结果表明，在GSM8K、MATH-500（易中等难度）和AIME2024、AIME2025、OlympiadBench（高难度）五个基准测试中，MathSmith在短链和长链思维提示下均持续优于现有基线方法。这证明了该框架在生成高难度、多样化且能有效提升模型推理能力的数据方面的有效性。

Conclusion: MathSmith框架在数学问题合成方面表现出强大的可扩展性、泛化性和迁移性，证明了高难度合成数据在提升大型语言模型推理能力方面的潜力。

Abstract: Large language models have achieved substantial progress in mathematical
reasoning, yet their advancement is limited by the scarcity of high-quality,
high-difficulty training data. Existing synthesis methods largely rely on
transforming human-written templates, limiting both diversity and scalability.
We propose MathSmith, a novel framework for synthesizing challenging
mathematical problems to enhance LLM reasoning. Rather than modifying existing
problems, MathSmith constructs new ones from scratch by randomly sampling
concept-explanation pairs from PlanetMath, ensuring data independence and
avoiding contamination. To increase difficulty, we design nine predefined
strategies as soft constraints during rationales. We further adopts
reinforcement learning to jointly optimize structural validity, reasoning
complexity, and answer consistency. The length of the reasoning trace generated
under autoregressive prompting is used to reflect cognitive complexity,
encouraging the creation of more demanding problems aligned with
long-chain-of-thought reasoning. Experiments across five benchmarks,
categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,
OlympiadBench), show that MathSmith consistently outperforms existing baselines
under both short and long CoT settings. Additionally, a weakness-focused
variant generation module enables targeted improvement on specific concepts.
Overall, MathSmith exhibits strong scalability, generalization, and
transferability, highlighting the promise of high-difficulty synthetic data in
advancing LLM reasoning capabilities.

</details>


### [138] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
*Haitao Hong,Yuchen Yan,Xingyu Wu,Guiyang Hou,Wenqi Zhang,Weiming Lu,Yongliang Shen,Jun Xiao*

Main category: cs.CL

TL;DR: 提出Cooper框架，通过联合优化策略和奖励模型，解决奖励范式中的鲁棒性和奖励攻击问题，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的奖励范式鲁棒性不足，而基于模型的奖励范式容易受到奖励攻击。为了解决这些问题，需要一种新的方法来改进LLM的推理能力。

Method: Cooper框架通过以下方式协同优化策略模型和奖励模型：1. 动态构建和选择正负样本对来持续训练奖励模型，以增强鲁棒性并减轻奖励攻击。2. 引入混合标注策略来高效准确地生成奖励模型的训练数据。3. 提出参考式奖励建模范式，将参考答案作为奖励模型的输入。基于此，训练了VerifyRM奖励模型，并在VerifyBench上取得了优于同等规模模型的准确率。

Result: Cooper框架不仅减轻了奖励攻击，还将端到端的强化学习性能提升了0.54%（在Qwen2.5-1.5B-Instruct的平均准确率上）。VerifyRM奖励模型在VerifyBench上的准确率也高于同等规模的其他模型。

Conclusion: Cooper框架通过联合优化策略模型和奖励模型，有效解决了现有奖励范式鲁棒性不足和易受奖励攻击的问题。通过动态构建和选择正负样本对，并引入混合标注策略和参考式奖励建模，Cooper提高了奖励模型的准确性和鲁棒性，并最终提升了端到端强化学习的性能，如在Qwen2.5-1.5B-Instruct上实现了0.54%的准确率提升。

Abstract: Large language models (LLMs) have demonstrated remarkable performance in
reasoning tasks, where reinforcement learning (RL) serves as a key algorithm
for enhancing their reasoning capabilities. Currently, there are two mainstream
reward paradigms: model-based rewards and rule-based rewards. However, both
approaches suffer from limitations: rule-based rewards lack robustness, while
model-based rewards are vulnerable to reward hacking. To address these issues,
we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework
that jointly optimizes both the policy model and the reward model. Cooper
leverages the high precision of rule-based rewards when identifying correct
responses, and dynamically constructs and selects positive-negative sample
pairs for continued training the reward model. This design enhances robustness
and mitigates the risk of reward hacking. To further support Cooper, we
introduce a hybrid annotation strategy that efficiently and accurately
generates training data for the reward model. We also propose a reference-based
reward modeling paradigm, where the reward model takes a reference answer as
input. Based on this design, we train a reward model named VerifyRM, which
achieves higher accuracy on VerifyBench compared to other models of the same
size. We conduct reinforcement learning using both VerifyRM and Cooper. Our
experiments show that Cooper not only alleviates reward hacking but also
improves end-to-end RL performance, for instance, achieving a 0.54% gain in
average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that
dynamically updating reward model is an effective way to combat reward hacking,
providing a reference for better integrating reward models into RL.

</details>


### [139] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
*Zixuan Wang,Dingming Li,Hongxing Li,Shuo Chen,Yuchen Yan,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CL

TL;DR: OmniEAR是一个评估语言模型在具身任务中推理能力的框架，发现现有模型在处理物理交互、工具使用和多智能体协调方面存在严重不足，尤其是在需要自主学习和处理复杂约束时。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分评估语言模型在具身任务中的推理能力，尤其是在动态能力获取和自主协调方面。本研究旨在填补这一空白，探索语言模型在物理交互、工具使用和多智能体协调方面的潜力。

Method: 提出OmniEAR框架，通过文本环境表示模拟物理属性和空间关系，覆盖1,500个家居和工业领域场景，评估语言模型在具身任务中的推理能力，特别关注工具使用和多智能体协调。

Result: 在具身任务中，语言模型在需要从约束中推理时表现出显著的性能下降，从明确指令的85-96%成功率下降到工具推理的56-85%和隐式协作的63-85%，复合任务失败率超过50%。虽然微调能显著提高单智能体任务性能，但对多智能体协作的提升效果甚微，表明存在根本性的架构限制。

Conclusion: 大型语言模型在具身推理方面面临严峻的挑战，这与它们当前的能力不同。OmniEAR 提供了一个评估具身推理的基准，突显了现有模型在处理动态能力获取、自主协调和约束推理方面的局限性。

Abstract: Large language models excel at abstract reasoning but their capacity for
embodied agent reasoning remains largely unexplored. We present OmniEAR, a
comprehensive framework for evaluating how language models reason about
physical interactions, tool usage, and multi-agent coordination in embodied
tasks. Unlike existing benchmarks that provide predefined tool sets or explicit
collaboration directives, OmniEAR requires agents to dynamically acquire
capabilities and autonomously determine coordination strategies based on task
demands. Through text-based environment representation, we model continuous
physical properties and complex spatial relationships across 1,500 scenarios
spanning household and industrial domains. Our systematic evaluation reveals
severe performance degradation when models must reason from constraints: while
achieving 85-96% success with explicit instructions, performance drops to
56-85% for tool reasoning and 63-85% for implicit collaboration, with compound
tasks showing over 50% failure rates. Surprisingly, complete environmental
information degrades coordination performance, indicating models cannot filter
task-relevant constraints. Fine-tuning improves single-agent tasks dramatically
(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing
fundamental architectural limitations. These findings demonstrate that embodied
reasoning poses fundamentally different challenges than current models can
address, establishing OmniEAR as a rigorous benchmark for evaluating and
advancing embodied AI systems. Our code and data are included in the
supplementary materials and will be open-sourced upon acceptance.

</details>


### [140] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
*Xilun Chen,Ilia Kulikov,Vincent-Pierre Berges,Barlas Oğuz,Rulin Shao,Gargi Ghosh,Jason Weston,Wen-tau Yih*

Main category: cs.CL

TL;DR: R-LLMs hallucinate more in long-form content. We propose a new reward function for online RL that balances factuality, detail, and relevance, reducing hallucinations by 23.1% and increasing detail by 23% without harming helpfulness.


<details>
  <summary>Details</summary>
Motivation: Reasoning Large Language Models (R-LLMs) struggle with factuality, generating more hallucinations than non-reasoning counterparts on long-form factuality benchmarks. Extending online RL to this setting is challenging due to the lack of reliable verification methods and the reward hacking issue observed when using automatic factuality evaluation frameworks like FActScore.

Method: Extending online Reinforcement Learning (RL) to the long-form factuality setting by proposing a novel reward function that simultaneously considers factual precision, response detail level, and answer relevance.

Result: Our factual reasoning model achieves an average reduction of 23.1 percentage points in hallucination rate, a 23% increase in answer detail level, and no degradation in overall response helpfulness, when evaluated on six long-form factuality benchmarks.

Conclusion: We propose a novel reward function that simultaneously considers factual precision, response detail level, and answer relevance, and applies online RL to learn high quality factual reasoning. Evaluated on six long-form factuality benchmarks, our factual reasoning model achieves an average reduction of 23.1 percentage points in hallucination rate, a 23% increase in answer detail level, and no degradation in overall response helpfulness.

Abstract: Reasoning Large Language Models (R-LLMs) have significantly advanced complex
reasoning tasks but often struggle with factuality, generating substantially
more hallucinations than their non-reasoning counterparts on long-form
factuality benchmarks. However, extending online Reinforcement Learning (RL), a
key component in recent R-LLM advancements, to the long-form factuality setting
poses several unique challenges due to the lack of reliable verification
methods. Previous work has utilized automatic factuality evaluation frameworks
such as FActScore to curate preference data in the offline RL setting, yet we
find that directly leveraging such methods as the reward in online RL leads to
reward hacking in multiple ways, such as producing less detailed or relevant
responses. We propose a novel reward function that simultaneously considers the
factual precision, response detail level, and answer relevance, and applies
online RL to learn high quality factual reasoning. Evaluated on six long-form
factuality benchmarks, our factual reasoning model achieves an average
reduction of 23.1 percentage points in hallucination rate, a 23% increase in
answer detail level, and no degradation in the overall response helpfulness.

</details>


### [141] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
*Brandon Jaipersaud,David Krueger,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 使用线性探针研究大型语言模型（LLM）的说服动态，发现它们比基于提示的方法更快、更有效，并能识别说服的各个方面，这表明它们也可用于研究欺骗和操纵等行为。


<details>
  <summary>Details</summary>
Motivation: 在理解大型语言模型（LLM）如何说服人类的方面，现有的研究是有限的。本研究旨在利用线性探针来分析模型表征，以解决这一知识缺口。

Method: 使用来自认知科学的见解，在多轮对话中应用线性探针来研究说服动态，对说服成功、说服对象个性和说服策略的不同方面进行训练。

Result: 探针能够捕捉说服的不同方面，并能识别对话中的特定点（例如，说服发生的时间点）以及跨数据集的说服成功。

Conclusion: 探针可以识别说服动态的各个方面，并且可以作为研究复杂行为（如欺骗和操纵）的一种可行方法，特别是在涉及多轮对话和大范围数据集分析的情况下，因为它们比基于提示的方法更快且计算效率更高。

Abstract: Large Language Models (LLMs) have started to demonstrate the ability to
persuade humans, yet our understanding of how this dynamic transpires is
limited. Recent work has used linear probes, lightweight tools for analyzing
model representations, to study various LLM skills such as the ability to model
user sentiment and political perspective. Motivated by this, we apply probes to
study persuasion dynamics in natural, multi-turn conversations. We leverage
insights from cognitive science to train probes on distinct aspects of
persuasion: persuasion success, persuadee personality, and persuasion strategy.
Despite their simplicity, we show that they capture various aspects of
persuasion at both the sample and dataset levels. For instance, probes can
identify the point in a conversation where the persuadee was persuaded or where
persuasive success generally occurs across the entire dataset. We also show
that in addition to being faster than expensive prompting-based approaches,
probes can do just as well and even outperform prompting in some settings, such
as when uncovering persuasion strategy. This suggests probes as a plausible
avenue for studying other complex behaviours such as deception and
manipulation, especially in multi-turn settings and large-scale dataset
analysis where prompting-based methods would be computationally inefficient.

</details>


### [142] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
*Mehrdad Zakershahrak,Samira Ghodratnama*

Main category: cs.CL

TL;DR: H-NET++ 是一种新的分层动态分块模型，可以高效地处理词法丰富的语言，无需分词器，并在波斯语上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 字节级语言模型虽然可以消除不稳定的分词器，但在词法丰富的语言（MRLs）中面临计算挑战，因为单词会跨越许多字节。

Method: H-NET++ 采用分层动态分块模型，通过端到端训练学习语言学驱动的分段。关键创新包括：一个轻量级 Transformer 上下文混合器（190 万参数）用于跨块注意力，一个用于文档级一致性的两级潜在超先验，专门处理波斯语 ZWNJ 等的特殊字符，以及基于课程的、分阶段序列长度的训练。

Result: 在波斯语语料库上，H-NET++ 取得了最先进的成果：与基于 BPE 的 GPT-2-fa 相比，BPB 降低了 0.159（压缩率提高了 12%），ParsGLUE 提高了 5.4 个百分点，对 ZWNJ 损坏的鲁棒性提高了 53%，在金标准形态边界上的 F1 达到了 73.8%。

Conclusion: H-NET++ 是一种有效的、无需分词器的解决方案，能够处理词法丰富的语言，同时保持计算效率。

Abstract: Byte-level language models eliminate fragile tokenizers but face
computational challenges in morphologically-rich languages (MRLs), where words
span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that
learns linguistically-informed segmentation through end-to-end training. Key
innovations include: (1) a lightweight Transformer context-mixer (1.9M
parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for
document-level consistency, (3) specialized handling of orthographic artifacts
(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence
lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art
results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better
compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ
corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks
align with Persian morphology without explicit supervision, demonstrating that
hierarchical dynamic chunking provides an effective tokenizer-free solution for
MRLs while maintaining computational efficiency.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [143] [Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications](https://arxiv.org/abs/2508.04889)
*Theia Henderson,David R. Karger,David D. Clark*

Main category: cs.SI

TL;DR: Graffiti 是一个能轻松创建和互联个性化社交应用的系统，用户可以在不同设计间无缝切换而不丢失社交关系或数据。


<details>
  <summary>Details</summary>
Motivation: 现有社交应用（如 Twitter、Wikipedia）设计僵化且缺乏互操作性，构建新应用既具技术挑战性又会导致社区孤立。

Method: Graffiti 系统通过“完全实体化”概念实现了设计冲突（包括审核规则冲突）的互操作性，通过“频道”概念防止了意外的互操作，并通过一个最小化的客户端 API 支持去中心化实现。

Result: Graffiti 系统可以轻松构建多样化的个性化社交应用程序，并实现它们之间的互操作性。该系统通过一个 Vue.js 插件实现了类似 Twitter、Messenger 和 Wikipedia 的应用，并展示了其互操作性和生态系统的潜力。

Conclusion: Graffiti 系统能够轻松构建多样化的个性化社交应用程序，并实现它们之间的互操作性，解决了现有社交应用设计僵化和社区孤立的问题。

Abstract: Most social applications, from Twitter to Wikipedia, have rigid
one-size-fits-all designs, but building new social applications is both
technically challenging and results in applications that are siloed away from
existing communities. We present Graffiti, a system that can be used to build a
wide variety of personalized social applications with relative ease that also
interoperate with each other. People can freely move between a plurality of
designs -- each with its own aesthetic, feature set, and moderation -- all
without losing their friends or data.
  Our concept of total reification makes it possible for seemingly
contradictory designs, including conflicting moderation rules, to interoperate.
Conversely, our concept of channels prevents interoperation from occurring by
accident, avoiding context collapse.
  Graffiti applications interact through a minimal client-side API, which we
show admits at least two decentralized implementations. Above the API, we built
a Vue.js plugin, which we use to develop applications similar to Twitter,
Messenger, and Wikipedia using only client-side code. Our case studies explore
how these and other novel applications interoperate, as well as the broader
ecosystem that Graffiti enables.

</details>


### [144] [Community-Aware Social Community Recommendation](https://arxiv.org/abs/2508.05107)
*Runhao Jiang,Renchi Yang,Wenqing Lin*

Main category: cs.SI

TL;DR: CASO是一种新颖有效的模型，专门用于社交社区推荐，通过利用社交网络中的社区相关结构和用户偏好来解决现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的社交推荐模型主要用于推荐博客、图片、产品等常规项目，但由于忽略了社区的独特特征，因此在社区推荐方面效果不佳。社区由个体组成，这些个体具有高度的动态性，并在社交网络中展现出丰富的结构模式。本研究旨在弥补这一差距，专门为社交社区推荐提出CASO模型。

Method: CASO利用三个精心设计的用户嵌入编码器：一个利用社区相关全局结构，一个利用社交邻近性聚合利用社区相关局部结构，最后一个利用协同过滤和用户社区隶属关系来捕获用户偏好。CASO还通过互斥性消除了特征冗余，并通过社区检测损失进行模型优化，以生成社区感知嵌入。

Result: CASO模型在社区推荐任务上表现出了优越的性能，并且优于九个强大的基线。

Conclusion: CASO在六个真实世界社交网络上的广泛实验表明，在社区推荐性能方面，它始终优于最先进的技术，并优于九个强大的基线。

Abstract: Social recommendation, which seeks to leverage social ties among users to
alleviate the sparsity issue of user-item interactions, has emerged as a
popular technique for elevating personalized services in recommender systems.
Despite being effective, existing social recommendation models are mainly
devised for recommending regular items such as blogs, images, and products, and
largely fail for community recommendations due to overlooking the unique
characteristics of communities. Distinctly, communities are constituted by
individuals, who present high dynamicity and relate to rich structural patterns
in social networks. To our knowledge, limited research has been devoted to
comprehensively exploiting this information for recommending communities.
  To bridge this gap, this paper presents CASO, a novel and effective model
specially designed for social community recommendation. Under the hood, CASO
harnesses three carefully-crafted encoders for user embedding, wherein two of
them extract community-related global and local structures from the social
network via social modularity maximization and social closeness aggregation,
while the third one captures user preferences using collaborative filtering
with observed user-community affiliations. To further eliminate feature
redundancy therein, we introduce a mutual exclusion between social and
collaborative signals. Finally, CASO includes a community detection loss in the
model optimization, thereby producing community-aware embeddings for
communities. Our extensive experiments evaluating CASO against nine strong
baselines on six real-world social networks demonstrate its consistent and
remarkable superiority over the state of the art in terms of community
recommendation performance.

</details>


### [145] [Modeling roles and trade-offs in multiplex networks](https://arxiv.org/abs/2508.05488)
*Nikolaos Nakis,Sune Lehmann,Nicholas A. Christakis,Morten Mørup*

Main category: cs.SI

TL;DR: MLT模型可以分析多层社交网络，揭示社会、健康和经济关系中的不同模式。社会关系更注重相互依存性，而健康和经济关系则更多受个体因素影响。


<details>
  <summary>Details</summary>
Motivation: 理解多层社交网络的结构有助于我们识别社会交换如何受到个体自身属性和行为（独立性）、他人地位或资源（依赖性）以及实体之间相互影响（相互依存性）的驱动。然而，表征多层网络中的结构具有挑战性，因为不同的层可以反映不同但互补的角色，并且相互依存性会出现在多个尺度上。

Method: 本研究引入了多层潜在权衡模型（MLT），这是一个用于提取多层社交网络中角色的框架。MLT模型将角色定义为一种权衡，要求每个节点在其层之间分配其源角色和目标角色，同时在其分层的、多尺度的结构中分配其社区成员身份。

Result: MLT模型通过对176个真实多层网络（包括社会、健康和经济层面）进行应用，揭示了核心社会交换原则，并识别出不同尺度上的社区结构。链接预测分析显示，在社交层面考虑相互依存性可以带来最大的性能提升，而在健康和经济层面，这种影响则较小。这表明社会关系在结构上是嵌入的，而健康和经济关系则主要受个体地位和行为参与的影响。

Conclusion: 本研究提出的多层潜在权衡模型（MLT）能够有效提取多层社交网络中的角色，并揭示了独立性、依赖性和相互依存性。通过对洪都拉斯乡村的176个真实多层网络进行分析，MLT模型不仅揭示了核心的社会交换原则，还识别出不同尺度上的社区结构。链接预测分析表明，在社交层面考虑相互依存性可以带来最大的性能提升，而在健康和经济层面，个体属性和行为参与对网络结构的影响更为显著，这说明社会关系具有结构嵌入性，而健康和经济关系则更多地受个体因素影响。

Abstract: A multiplex social network captures multiple types of social relations among
the same set of people, with each layer representing a distinct type of
relationship. Understanding the structure of such systems allows us to identify
how social exchanges may be driven by a person's own attributes and actions
(independence), the status or resources of others (dependence), and mutual
influence between entities (interdependence). Characterizing structure in
multiplex networks is challenging, as the distinct layers can reflect different
yet complementary roles, with interdependence emerging across multiple scales.
Here, we introduce the Multiplex Latent Trade-off Model (MLT), a framework for
extracting roles in multiplex social networks that accounts for independence,
dependence, and interdependence. MLT defines roles as trade-offs, requiring
each node to distribute its source and target roles across layers while
simultaneously distributing community memberships within hierarchical,
multi-scale structures. Applying the MLT approach to 176 real-world multiplex
networks, composed of social, health, and economic layers, from villages in
western Honduras, we see core social exchange principles emerging, while also
revealing local, layer-specific, and multi-scale communities. Link prediction
analyses reveal that modeling interdependence yields the greatest performance
gains in the social layer, with subtler effects in health and economic layers.
This suggests that social ties are structurally embedded, whereas health and
economic ties are primarily shaped by individual status and behavioral
engagement. Our findings offer new insights into the structure of human social
systems.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [146] [Optimality Principles and Neural Ordinary Differential Equations-based Process Modeling for Distributed Control](https://arxiv.org/abs/2508.04799)
*Michael R. Wartmann,B. Erik Ydstie*

Main category: cs.NE

TL;DR: 提出一个流程建模框架，将数据驱动方法与经典过程模型和控制集成，并通过示例展示了其在库存控制系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 旨在解决将数据驱动方法与经典过程模型和控制自然集成的问题。

Method: 提出一个流程建模框架，通过连接矩阵和网络图表示流程网络单元之间的互连，并推导出系统自然目标函数作为稳态系统的非平衡熵产，以驱动过程动态。

Result: 在简单的库存控制系统实例中，展示了如何将基本流程拓扑与神经网络常微分（ODE）模型集成，其中神经网络 ODE 模型使用伴随方法和自适应 ODE 求解器从合成时间序列数据中学习。

Conclusion: 该框架通过一致的拓扑属性和广泛量的守恒来实现数据驱动算法的集成，并将基本守恒性质与稀疏深度神经网络中的学习动态关系相结合。

Abstract: Most recent advances in machine learning and analytics for process control
pose the question of how to naturally integrate new data-driven methods with
classical process models and control. We propose a process modeling framework
enabling integration of data-driven algorithms through consistent topological
properties and conservation of extensive quantities. Interconnections among
process network units are represented through connectivity matrices and network
graphs. We derive the system's natural objective function equivalent to the
non-equilibrium entropy production in a steady state system as a driving force
for the process dynamics. We illustrate how distributed control and
optimization can be implemented into process network structures and how control
laws and algorithms alter the system's natural equilibrium towards engineered
objectives. The basic requirement is that the flow conditions can be expressed
in terms of conic sector (passivity) conditions. Our formalism allows
integration of fundamental conservation properties from topology with learned
dynamic relations from data through sparse deep neural networks.
  We demonstrate in a practical example of a simple inventory control system
how to integrate the basic topology of a process with a neural network ordinary
differential equation model. The system specific constitutive equations are
left undescribed and learned by the neural ordinary differential equation
algorithm using the adjoint method in combination with an adaptive ODE solver
from synthetic time-series data. The resulting neural network forms a state
space model for use in e.g. a model predictive control algorithm.

</details>


### [147] [Modelling the emergence of open-ended technological evolution](https://arxiv.org/abs/2508.04828)
*James Winters,Mathieu Charbonneau*

Main category: cs.NE

TL;DR: 开放式技术进步的罕见性在于技术系统与搜索空间的共同进化，需要随机性和选择性过程的平衡。


<details>
  <summary>Details</summary>
Motivation: 人类在集体和累积地以开放方式改进技术方面是独一无二的，这使得社会能够不断扩展资源并提高集体信息存储、传输和处理能力。本文旨在理解这种开放式增长的条件。

Method: 提出一个宏观模型，将技术系统（社会的技能、技术和人工制品的集合）和搜索空间（社会的需求、问题和目标的集合）视为受文化进化动力学驱动的实体。通过操纵这些动力学的随机性或选择性过程的程度来模拟。

Result: 研究表明，开放式增长极为罕见，并且仅在技术系统和搜索空间共同进化时才可能发生。随机因素需要足够强大以持续扰动动力学，使其处于远离平衡的状态，而选择性因素则有助于维持有效性并确保资源的持续生产。只有当这种共同进化动力学维持有效技术系统、支持搜索空间的持续扩展并增加资源供应时，才能观察到开放式技术进化。

Conclusion: 开放式技术进步是罕见的、历史性的偶然事件，只有在技术系统和搜索空间共同进化时才可能实现。

Abstract: Humans stand alone in terms of their potential to collectively and
cumulatively improve technologies in an open-ended manner. This open-endedness
provides societies with the ability to continually expand their resources and
to increase their capacity to store, transmit and process information at a
collective-level. Here, we propose that the production of resources arises from
the interaction between technological systems (a society's repertoire of
interdependent skills, techniques and artifacts) and search spaces (the
aggregate collection of needs, problems and goals within a society). Starting
from this premise we develop a macro-level model wherein both technological
systems and search spaces are subject to cultural evolutionary dynamics. By
manipulating the extent to which these dynamics are characterised by stochastic
or selection-like processes, we demonstrate that open-ended growth is extremely
rare, historically contingent and only possible when technological systems and
search spaces co-evolve. Here, stochastic factors must be strong enough to
continually perturb the dynamics into a far-from-equilibrium state, whereas
selection-like factors help maintain effectiveness and ensure the sustained
production of resources. Only when this co-evolutionary dynamic maintains
effective technological systems, supports the ongoing expansion of the search
space and leads to an increased provision of resources do we observe open-ended
technological evolution.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [148] [Understanding and Mitigating Errors of LLM-Generated RTL Code](https://arxiv.org/abs/2508.05266)
*Jiazheng Zhang,Cheng Liu,Huawei Li*

Main category: cs.AR

TL;DR: 该研究通过分析LLM在RTL代码生成中的错误原因（主要为缺乏领域知识和描述模糊，而非LLM推理能力不足），提出了一系列纠正技术（如引入RAG、设计规则、外部工具和迭代调试），显著提升了代码生成的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前基于LLM的RTL代码生成成功率不高的问题，并深入理解导致错误的关键因素，从而提出有效的改进方法。

Method: 1. 进行了全面的错误分析和手动分类，发现LLM的不足主要源于缺乏RTL编程知识、对电路概念理解不足、设计描述模糊或多模态输入误解，而非LLM本身的推理能力限制。 2. 提出了针对性的错误纠正技术：a. 构建领域特定的知识库并使用RAG提供RTL知识。 b. 引入设计描述规则和规则检查机制来处理模糊性错误。 c. 集成外部工具将多模态输入转换为LLM兼容的元格式。 d. 对剩余错误采用迭代调试循环（模拟-错误定位-纠正）。

Result: 所提出的增强框架在VerilogEval基准测试上实现了91.0%的准确率，相较于基线代码生成方法，准确率提升了32.7%，证明了所提方法的有效性。

Conclusion: 通过整合特定领域的知识库、检索增强生成（RAG）、设计描述规则、规则检查机制、外部工具集成以及迭代调试循环等技术，并将其融入基于LLM的RTL代码生成框架，显著提高了性能。实验结果表明，该增强框架在VerilogEval基准测试上达到了91.0%的准确率，比基线方法提高了32.7%，有效证明了所提方法的可行性。

Abstract: Despite the promising potential of large language model (LLM) based
register-transfer-level (RTL) code generation, the overall success rate remains
unsatisfactory. Errors arise from various factors, with limited understanding
of specific failure causes hindering improvement. To address this, we conduct a
comprehensive error analysis and manual categorization. Our findings reveal
that most errors stem not from LLM reasoning limitations, but from insufficient
RTL programming knowledge, poor understanding of circuit concepts, ambiguous
design descriptions, or misinterpretation of complex multimodal inputs.
Leveraging in-context learning, we propose targeted error correction
techniques. Specifically, we construct a domain-specific knowledge base and
employ retrieval-augmented generation (RAG) to supply necessary RTL knowledge.
To mitigate ambiguity errors, we introduce design description rules and
implement a rule-checking mechanism. For multimodal misinterpretation, we
integrate external tools to convert inputs into LLM-compatible meta-formats.
For remaining errors, we adopt an iterative debugging loop (simulation-error
localization-correction). Integrating these techniques into an LLM-based
framework significantly improves performance. We incorporate these error
correction techniques into a foundational LLM-based RTL code generation
framework, resulting in significantly improved performance. Experimental
results show that our enhanced framework achieves 91.0\% accuracy on the
VerilogEval benchmark, surpassing the baseline code generation approach by
32.7\%, demonstrating the effectiveness of our methods.

</details>


### [149] [relOBI: A Reliable Low-latency Interconnect for Tightly-Coupled On-chip Communication](https://arxiv.org/abs/2508.05354)
*Michael Rogenmoser,Angelo Garofalo,Luca Benini*

Main category: cs.AR

TL;DR: relOBI enhances SoC interconnects with TMR and ECC for full reliability against radiation, outperforming existing methods in area efficiency.


<details>
  <summary>Details</summary>
Motivation: On-chip communication in radiation-heavy environments is critical, as soft errors in interconnects can cause SoC failure. Existing methods have high area overhead.

Method: Extension of Open Bus Interface (OBI) with triple modular redundancy (TMR) for handshake signals and error correction codes (ECC) for other signals.

Result: A fully reliable crossbar showed a reduction in fault vulnerability from 34.85% to 0% with a 2.6x area increase and 1.4x timing impact. The area overhead is 1.8x lower than fine-grained triplication.

Conclusion: The proposed relOBI, combining TMR and ECC, achieves complete reliability against injected faults in SoCs with lower area overhead compared to existing fine-grained triplication methods.

Abstract: On-chip communication is a critical element of modern systems-on-chip (SoCs),
allowing processor cores to interact with memory and peripherals. Interconnects
require special care in radiation-heavy environments, as any soft error within
the SoC interconnect is likely to cause a functional failure of the whole SoC.
This work proposes relOBI, an extension to Open Bus Interface (OBI) combining
triple modular redundancy (TMR) for critical handshake signals with error
correction codes (ECC) protection on other signals for complete reliability.
Implementing and testing a fully reliable crossbar shows improved reliability
to injected faults from a vulnerability of 34.85 % to 0 % compared to a
reference design, with an area increase of 2.6x and 1.4x timing impact. The
area overhead is 1.8x lower than that reported in the literature for
fine-grained triplication and voting.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [150] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 该研究利用大型语言模型（LLM）和多主体系统，结合轴承振动数据分析和维护手册处理，开发了一个预测性维护系统。该系统能检测异常、分类故障、评估严重性，并提供详细的维护建议，以提高工业机械的维护效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 工业机械的维护需要及时干预，以防止灾难性故障并优化运营效率。传统的异常检测方法在提供可操作的维护建议方面存在局限性。因此，有必要开发一种能够超越传统异常检测并提供明确维护建议的智能系统。

Method: 本研究提出了一种集成的大型语言模型（LLM）驱动的预测性维护智能系统。该系统将轴承振动频率分析（BPFO、BPFI、BSF、FTF）与多主体生成相结合，用于智能维护规划。具体而言，该系统将轴承振动数据序列化为自然语言，以实现少样本异常检测。同时，利用向量嵌入和语义搜索处理维护手册，并通过网络搜索获取最新的维护实践，以提供更准确、更深入的维护建议。最后，利用Gemini模型生成结构化的维护建议，包括即时操作、检查清单、纠正措施、零件需求和时间表。

Result: 实验验证表明，该系统在轴承振动数据集上实现了有效的异常检测，并提供了与上下文相关的维护指导。该系统能够准确地对故障类型（内圈、外圈、滚珠/滚子、保持架故障）进行分类并评估严重性级别。

Conclusion: 该研究成功弥合了状态监测与可操作维护计划之间的差距，为工业从业者提供了智能决策支持。该工作推进了大型语言模型在工业维护中的应用，为跨机械部件和工业领域的预测性维护提供了一个可扩展的框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [151] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 在EL和DL-Lite逻辑中，最小模型推理比预期更难。EL中的纯最小模型概念可满足性是不可判定的，而DL-Lite_horn则具有ExpSpace-hardness。


<details>
  <summary>Details</summary>
Motivation: 虽然最小模型推理是知识表示的核心，但其在描述逻辑（DLs）中的理解仍然有限。特别是纯粹最小模型，即所有谓词的扩展都必须最小化的情况，研究尚少。本文旨在填补这一空白，并探索在不同DLs中最小模型推理的复杂性。

Method: 研究者们分析了描述逻辑（DLs）中的最小模型推理问题，重点关注了EL和DL-Lite系列逻辑。通过引入和分析不同的最小化概念（如谓词最小化和纯粹最小模型），并施加如TBox非循环性等约束条件，来研究相关问题的可判定性和复杂度。

Result: 在EL逻辑中，纯粹最小模型下的概念可满足性被证明是不可判定的。即使对TBox施加了非循环性条件，复杂度也低于双指数时间。对于DL-Lite系列，DL-Lite_horn被发现具有ExpSpace-hardness。

Conclusion: 本文研究了描述逻辑（DLs）中最小模型推理问题，特别是在EL和DL-Lite系列逻辑中。研究发现，在EL中概念可满足性在纯最小模型下是不可判定的，即使是对TBox施加了非循环条件，其最坏情况复杂度也低于双指数时间。在DL-Lite系列中，虽然DL-Lite_core已知是可判定的，但DL-Lite_horn已经具有ExpSpace-hardness。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [152] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种用于地理空间任务的方法，它通过明确指导API调用来提高代理的成功率并减少令牌使用量。


<details>
  <summary>Details</summary>
Motivation: 与以往侧重于推理分解而隐式选择API的先前工作不同，GeoFlow旨在明确指导地理空间API的调用。

Method: GeoFlow是一种自动生成用于地理空间任务的代理工作流的方法，通过提供详细的工具调用目标来指导地理空间API调用。

Result: GeoFlow将代理的成功率提高了6.8%，并将各种主流LLM家族的令牌使用量减少了高达四倍。

Conclusion: GeoFlow通过为每个代理提供详细的工具调用目标来指导地理空间API调用，从而提高了代理的成功率并减少了令牌使用量。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [153] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 本研究提出了一个基于棋盘游戏竞赛的评估框架，用于衡量大型语言模型（LLMs）的性能和心理健康，并发现LLMs在对抗性环境中表现出韧性但技能不稳定。


<details>
  <summary>Details</summary>
Motivation: 为了弥补当前基于问答（Q&A）的主流基准方法在数据依赖性方面的局限性，本研究旨在通过棋盘游戏竞赛来评估大型语言模型（LLMs）的综合性能。

Method: 本研究提出了一个对抗性基准框架，通过棋盘游戏比赛来评估大型语言模型（LLMs）的综合性能。该框架在一个名为“Qi Town”的专用评估平台上实现，该平台支持5种流行的棋盘游戏，并包含20个由LLM驱动的玩家。该平台使用Elo评级系统和新颖的性能环图（PLG）来量化评估LLM的技术能力，并通过游戏过程中的积极情绪得分（PSS）来评估其心理健康状况。评估采用循环赛的形式进行，以便对玩家进行系统性比较。

Result: 实验结果表明，尽管存在技术差异，大多数LLM在面对输赢时都表现出乐观的态度，并且比人类更能适应高压对抗环境。此外，PLG中循环的输赢关系揭示了LLM在游戏中的技能不稳定，这表明其表现的波动性，需要进一步的研究来解释。

Conclusion: 大多数语言模型在面对输赢时都表现出乐观的态度，并且比人类更能适应高压对抗环境。然而，PLG中循环的输赢关系揭示了语言模型在游戏中的技能不稳定，需要进一步的解释和探索。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [154] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 本研究提出并验证了一种在客户端浏览器中运行小语言模型（SLM）的方法，用于实现无需互联网连接、保护用户隐私且高效的自动地理信息系统（AWebGIS），其准确性超越了传统在线和离线方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前基于云的 LLM 在自动 WebGIS（AWebGIS）中存在的互联网依赖、用户隐私和可扩展性问题，本研究旨在探索更优的解决方案。

Method: 研究人员比较了三种方法：1. 全自动在线方法（使用云端 LLM）；2. 半自动离线方法（使用经典机器学习分类器）；3. 全自动离线方法（使用在客户端浏览器中运行的微调小语言模型 T5-small）。

Result: 基于小语言模型（SLM）的第三种方法在准确性方面表现最佳，具体指标包括：精确匹配准确率 0.93，Levenshtein 相似度 0.99，以及 ROUGE-1 和 ROUGE-L 分数均为 0.98。此外，这种客户端计算策略通过将处理转移到用户设备，减少了后端服务器的负载，并消除了对服务器端推理的需求。

Conclusion: 该研究的结果强调了在客户端浏览器中执行模型的可行性，为自动 WebGIS 解决方案提供了新的方向。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [155] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 强化学习微调提升LLM在理想场景下的推理能力，但在噪声、不完整上下文等非理想场景下表现不佳，暴露了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常在理想条件下评估大型语言模型的推理能力，忽略了在现实世界中常见的非理想场景，这可能导致对模型能力的评估过于乐观。

Method: 提出了一种受脑科学启发的、在不完美输入下进行人类推理的新研究方向，并形式化定义和评估了三种具有实际意义的非理想场景：摘要推理、细粒度噪声抑制和上下文过滤。使用代表性的策略梯度算法对三种大型语言模型（LLM）和一种先进的大型视觉语言模型（LVLM）进行了强化学习微调，并在八个公开数据集上进行了测试。

Result: 强化学习微调在理想场景下能提升模型推理能力，但在摘要推理、细粒度噪声抑制和上下文过滤等非理想场景下，模型性能显著下降，暴露了现有模型在高级推理能力方面的局限性。提出的特定场景补救方法未能完全解决这些问题。

Conclusion: 现有强化学习微调方法在处理非理想输入场景时存在局限性，可能导致模型推理能力下降，需要开发更鲁棒的微调策略。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [156] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一个能自主优化其问题解决策略的AI代理，克服了现有AI在医疗研究中作为工具使用者而非战略规划者的局限。通过EHRFlowBench基准的实验证明，HealthFlow表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前的AI代理在医疗研究中效能受限于静态、预定义的策略，导致AI只能成为更好的工具使用者，却无法学会成为更好的战略规划者，这在医疗等复杂领域是关键的局限。

Method: HealthFlow通过新颖的元级别进化机制实现自主进化，能够从程序化成功和失败中提炼出持久的战略知识库，自主优化其高级问题解决策略。EHRFlowBench是一个包含复杂、真实的健康数据分析任务的新基准，用于可复现的评估。

Result: HealthFlow的自主进化方法显著优于最先进的代理框架。

Conclusion: HealthFlow的自主进化方法标志着从构建更好的工具使用者到设计更智能、自主进化的任务管理者的重要转变，为更自主、更有效的科学发现AI铺平了道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [157] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: CogniWeb智能体通过模拟人类的“直觉”和“深思熟虑”两种认知模式，在Web导航任务中取得了高成功率和高效率。


<details>
  <summary>Details</summary>
Motivation: 评估通用人工智能（AGI）在复杂、高熵、动态且具有组合爆炸行动空间的Web导航领域面临巨大挑战。现有方法在整合离线模仿学习和在线探索方面存在不足。

Method: 受人类双重处理理论启发，将智能体认知过程分解为快速的系统1和慢速的系统2。CogniWeb作为一个模块化代理架构，能够根据任务复杂度自适应地在这两种处理模式之间切换，以平衡直觉反应和深思熟虑的规划能力。

Result: 在WebArena评估中，CogniWeb实现了43.96%的成功率，并且在显著降低了75%的token使用量的情况下，保持了具有竞争力的性能，证明了其效率和效果。

Conclusion: CogniWeb框架通过整合离线模仿学习和在线探索，并借鉴双重处理理论，成功实现了在Web导航任务上的高效能与低成本。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [158] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: A new game-theory approach called Docking Game with LoopPlay algorithm improves molecular docking accuracy by 10% by treating protein-ligand interaction as a two-player game and enabling mutual adaptation between ligand and protein docking modules.


<details>
  <summary>Details</summary>
Motivation: Current multi-task learning models for molecular docking show inferior performance in ligand docking compared to protein docking due to distinct structural complexities of ligands and proteins.

Method: Developed a game-theoretic framework modeling protein-ligand interaction as a two-player game (Docking Game) and a Loop Self-Play (LoopPlay) algorithm that alternately trains ligand and protein docking modules through a two-level loop for mutual adaptation and refinement.

Result: The LoopPlay algorithm demonstrated approximately a 10% improvement in predicting accurate binding modes compared to previous state-of-the-art methods on public benchmark datasets.

Conclusion: Proposed a novel game-theoretic framework (Docking Game) with Loop Self-Play (LoopPlay) algorithm to address the performance disparity in multi-task learning models for molecular docking, achieving a 10% improvement in predicting accurate binding modes.

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [159] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 生成式AI正重塑高等教育。本研究评估了一个苏格拉底AI导师，发现它能增强学生的批判性思维。研究还提出了“精心编排的多智能体系统”概念，并探讨了其对高等教育的系统性影响，旨在促进人与AI的协作学习。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能在高等教育中日益普及，本研究旨在探讨其在促进学生研究问题发展方面的潜力，特别是通过一种模拟苏格拉底对话方式的AI导师，以期挑战关于生成式AI可能导致技能退化的观点，并为教育机构适应这一变革提供概念框架和实证依据。

Method: 本研究通过一项对照实验，评估了一个苏格拉底AI导师，该导师是一个大型语言模型，旨在通过基于建构主义理论的结构化对话来引导学生研究问题的开发。该实验在德国对65名职前教师学生进行，并将使用苏格拉底导师的互动与使用无指导AI聊天机器人的互动进行了比较。

Result: 使用苏格拉底AI导师的学生在批判性、独立性和反思性思维方面获得了显著更多的支持，这表明对话式AI能够激发元认知参与，并对近期关于生成式AI使用导致技能退化的说法提出了挑战。研究结果为一种更广泛的教学转变提供了概念验证，即使用由专业AI代理组成的多智能体系统（MAS），并提出了一种“精心编排的MAS”概念，即由教育工作者策划的、模块化的、教学上相符的代理星座，通过差异化的角色和协调的互动来支持多样化的学习轨迹。

Conclusion: 本研究提出了一个经过调整的“提供与使用”模型，学生可以从中选择和使用来自专门人工智能代理的教学资源。此外，研究还探讨了对高等教育机构和学生产生的系统性影响，包括资金需求、教师角色的变化、课程设置、能力要求和评估实践。最后，通过比较成本效益分析，突显了这类混合学习生态系统的可扩展性，其中融合了人与人工智能的共事关系以及与教学的相互适应性。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [160] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: LLMs show promise for spatial data integration, especially when provided with relevant features and refined using a review-and-refine method, offering a flexible alternative to traditional approaches despite initial reasoning limitations.


<details>
  <summary>Details</summary>
Motivation: Traditional rule-based and machine learning methods for integrating large, heterogeneous, and noisy urban spatial datasets have limitations, including inability to cover edge cases and the need for large labeled datasets. This study investigates LLMs as a potential solution.

Method: The study explores LLMs for spatial data integration, analyzing their spatial reasoning abilities and adapting a review-and-refine method to correct errors. It considers how LLMs reason about environmental spatial relationships and tests their performance when provided with relevant features.

Result: LLMs show spatial reasoning capabilities but struggle to connect macro-scale environments with computational geometry tasks, often producing incoherent responses. However, when provided with relevant features, LLMs achieve high-performing results. A review-and-refine method is effective in correcting errors while preserving accurate responses.

Conclusion: LLMs are a promising and flexible alternative to traditional rule-based heuristics for spatial data integration, advancing adaptive spatial data integration capabilities.

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [161] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: MedMKEB是首个医学多模式知识编辑基准，用于评估和改进MLLMs的知识更新能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模式医学大型语言模型（MLLMs）在更新知识方面存在效率问题，以及现有基准在医学多模式知识编辑方面的不足，本文提出了MedMKEB。

Method: 提出了MedMKEB基准，该基准建立在高质量的医学视觉问答数据集之上，并通过反事实修正、语义泛化、知识迁移和对抗鲁棒性等编辑任务进行增强，同时结合了人类专家验证。

Result: 现有的基于知识的编辑方法在医学领域存在局限性，需要专门的编辑策略。MedMKEB通过广泛的单次编辑和顺序编辑实验证明了其有效性。

Conclusion: MedMKEB是一个全面的基准，用于评估和促进多模式医学知识编辑算法的发展，以应对现有方法在医学领域知识编辑方面的局限性。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [162] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个轻量级的模拟电路门尺寸调整框架，基于微调的Qwen3-8B模型，通过EOA和混合优化算法，在不同工艺节点上实现了高效、通用的门尺寸调整，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI方法在模拟电路门尺寸调整中的通用性、速度和稳定性方面的挑战，克服现有方法对大模型尺寸和跨工艺节点可移植性的依赖。

Method: EasySize框架，一个轻量级的门尺寸调整框架，基于微调的Qwen3-8B模型，利用性能指标的可达到性(EOA)来动态构建特定任务的损失函数，并通过全局差分进化(DE)和局部粒子群优化(PSO)进行高效的启发式搜索。

Result: EasySize在180nm、45nm和22nm工艺节点上的5个运算放大器(Op-Amp)电路网表中表现强劲，无需额外针对性训练，并且在86.67%的任务上超越了基于强化学习的AutoCkt框架，同时节省了96.67%以上的仿真资源。

Conclusion: EasySize框架可以通过减少对人类专业知识和计算资源 in gate sizing的依赖，从而加速和简化模拟电路设计过程。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [163] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 该论文提出了一种新的异构图神经网络模型，用于处理流程挖掘中缺失事件属性的问题，并在各种数据集上显示出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 事件日志的质量对于流程挖掘中的任何形式的分析都至关重要，但现实世界的事件日志可能包含缺失的信息。

Method: 提出了一种异构图神经网络模型，给定包含某些不完整事件的轨迹，将返回这些事件缺失的全部属性。

Result: 该方法与利用自动编码器的最先进方法进行了比较，在两个合成日志和四个真实事件日志上，针对不同类型的缺失值进行了评估。

Conclusion: 该方法在重新构建所有不同事件属性方面表现出非常好的性能。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [164] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon 通过结合文本和图像检索，并引入智能路由，解决了现有 RAG 方法在处理复杂视觉问答任务时的局限性，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在处理需要多步推理或最新事实知识的复杂查询时，由于仅检索文本或图像，存在局限性。因此需要一个能够整合多模态信息并支持复杂推理的系统。

Method: 提出 QA-Dragon 系统，包含领域路由器以识别查询主题领域，以及搜索路由器动态选择检索策略。系统整合文本和图像搜索代理，支持多模态、多轮和多步推理。

Result: QA-Dragon 在 Meta CRAG-MM 挑战赛上显著提升了基础模型的推理性能，在单源任务上提高了 5.06%，多源任务上提高了 6.35%，多轮任务上提高了 5.03%，在答案准确率和知识重叠度方面均优于基线模型。

Conclusion: QA-Dragon 通过引入领域路由器和搜索路由器，实现了对文本和图像的联合检索，支持多模态、多轮和多步推理，有效提升了知识密集型视觉问答的性能，在 Meta CRAG-MM 挑战赛上取得了显著成果。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [165] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: A new framework using RDF graphs and LLMs helps large maintenance organizations communicate better by understanding natural language queries for targeted messages, making communication faster and more efficient.


<details>
  <summary>Details</summary>
Motivation: Traditional communication approaches in large-scale maintenance organizations face challenges like information overload and longer response times in identifying subject matter experts and managing complex relationships. Our solution addresses these issues.

Method: The framework combines RDF graph databases with LLMs and utilizes a planning-orchestration architecture for transparent reasoning and natural language query processing.

Result: The solution enables communication owners to formulate intuitive queries combining various concepts, delivering explainable results that maintain trust and improve communication efficiency.

Conclusion: We propose a novel framework combining RDF graph databases with LLMs for precise audience targeting and transparent reasoning in large-scale maintenance organizations, enabling intuitive queries and improving communication efficiency.

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [166] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种将决策树和 LLM 相结合的混合多智能体架构，用于神经符号推理，在多个推理基准测试中均取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决先前将符号和神经模块松散耦合的问题，我们提出了一种更紧密的集成方法。

Method: 提出了一种将基于决策树的符号推理与大型语言模型（LLM）的生成能力相结合的混合架构，并将其置于一个协调的多智能体框架中。该设计将决策树和随机森林作为可调用预言机嵌入统一的推理系统中，其中树基模块负责可解释的规则推理和因果逻辑，而 LLM 智能体则处理溯因推理、泛化和交互式规划。一个中央协调器负责维护信念状态一致性并通过智能体和外部工具进行通信。

Result: 在 ProofWriter 上，通过逻辑推理树验证，将蕴含一致性提高了 7.2%；在 GSM8k 上，通过符号增强，在多步数学问题上提高了 5.3% 的准确率；在 ARC 上，通过集成符号预言机，将抽象准确率提高了 6.0%。在临床决策支持和科学发现中的应用表明，该系统能够以符号方式编码领域规则，同时利用 LLM 进行上下文推理和假设生成。

Conclusion: 该混合架构为通用神经符号推理提供了一个强大、可解释且可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [167] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 人工智能中的“智能体”一词定义模糊，影响研究和政策。本文提出一个框架，根据交互、学习、自主性、目标和时间连贯性等维度对智能体进行多维定义，以提高清晰度和可重复性，并为术语标准化提供建议。


<details>
  <summary>Details</summary>
Motivation: 人工智能领域的'智能体'一词具有多种解释，尤其是在大型语言模型系统取得进展的背景下，这种模糊性加剧了研究交流、系统评估和可重复性以及政策制定方面的挑战。

Method: 本文通过历史分析和当代用法模式，提出了一个框架，为系统被视为智能体设定了清晰的最低要求，并根据环境交互、学习与适应、自主性、目标复杂性以及时间连贯性等维度对系统进行了特征描述。

Result: 提出了一个多维度框架，用于定义和描述人工智能系统，以解决'智能体'一词的歧义，从而提高研究清晰度和可重复性，并支持更有效的政策制定。

Conclusion: 该论文认为'智能体'一词需要重新定义，并提出了一个框架来为被认为是智能体的系统设定清晰的最低要求，同时根据环境交互、学习与适应、自主性、目标复杂性以及时间连贯性等多个维度对系统进行特征描述。该方法旨在提供精确的系统描述词汇，同时保留该术语历史上多方面的含义。最后，论文提出了术语标准化和框架采纳等具体建议，以提高研究的清晰度和可重复性，并支持更有效的政策制定。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [168] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: NomicLaw模拟了LLM在法律环境中的协作和冲突，展示了它们的社会推理和说服能力。


<details>
  <summary>Details</summary>
Motivation: LLM在开放式、多主体环境中（尤其是在涉及法律和道德困境的审议中）的行为仍有待经验性理解。

Method: 提出NomicLaw，一个结构化的多主体模拟，LLM在其中参与协作立法，通过提出规则、进行辩护和对同行提案进行投票来应对复杂的法律小插曲。通过投票模式量化信任和互惠，并通过评估代理人如何使用战略语言来辩护提案和影响结果来定性评估。

Result: 实验表明，代理人会自发形成联盟、背叛信任并调整其言辞以塑造集体决策，突显了十个开源LLM的潜在社会推理和说服能力。

Conclusion: LLMs展示出潜在的社会推理和说服能力，并为设计未来能够在法律环境中自主谈判、协调和起草立法的AI系统提供了见解。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [169] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM通过引入一个能够提供细粒度、子问题级别反馈的基于模型的验证器，解决了现有视觉-语言模型在处理复杂、多问题推理任务时遇到的困难，实现了部分正确性评分，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在处理复杂的、多问题的推理任务时，往往难以取得令人满意的结果，因为在这些任务中，部分正确性对于有效学习至关重要。传统的奖励机制提供单一的、二元的整体性评分，这种粗粒度的评分方式不足以指导模型解决包含多个子部分、错综复杂的问题。

Method: StructVRM是一种结合了结构化和可验证奖励模型的多模态推理方法，其核心是一个基于模型的验证器，能够提供细粒度的、子问题级别的反馈，评估语义和数学等价性，而非依赖于严格的字符串匹配。

Result: 在六个公共多模态基准测试和新创建的高难度STEM-Bench数据集上，名为Seed-StructVRM的训练模型取得了最先进的性能。

Conclusion: 结构化、可验证的奖励训练是提升多模态模型在复杂、现实推理领域能力的一种极其有效的方法。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [170] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 该研究提出了一种用于智能交通系统（特别是铁路）的实时数据驱动预测性维护解决方案。该方法利用预处理、机器学习和可解释性模块，在MetroPT数据集上实现了超过98%的F测量值和99%的准确率，有效提高了维护决策的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 为智能交通系统（特别是铁路）开发实时数据驱动的预测性维护解决方案，以提高服务可用性、可靠性、成本效益和安全性。

Method: 通过由样本预处理、带有机器学习模型的增量分类和结果解释组成的在线处理流程，实现了实时数据驱动的预测性维护解决方案。该流程的特点是能够动态构建统计和频率相关特征，并提供自然语言和视觉解释。

Result: 在MetroPT数据集上实现了超过98%的F测量值和99%的准确率，即使在存在类别不平衡和噪声的情况下，该流程也能保持高性能，并且其解释能有效反映决策过程。

Conclusion: 该方法论证了其在铁路预测性维护中的方法健全性和实际适用性，通过识别故障的早期迹象，使决策者能够快速了解根本问题并采取相应行动。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [171] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个基准框架，用于评估视觉语言模型在物理推理方面的能力，发现现有模型在这方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在复杂动态环境中对细节的关注和精确的动作规划方面存在不足，导致性能不佳。现实世界的任务通常需要复杂的交互、高级的空间推理、长期规划和持续的策略改进，这通常需要理解目标场景的物理规则。然而，在真实场景中评估这些能力通常成本高昂。

Method: 提出了一种名为DeepPHY的新型基准框架，该框架通过一系列具有挑战性的模拟环境系统地评估视觉语言模型对基本物理原理的理解和推理能力。DeepPHY集成了多个不同难度级别的物理推理环境，并包含了细粒度的评估指标。

Result: 评估结果表明，即使是最先进的视觉语言模型也难以将描述性的物理知识转化为精确的预测性控制。

Conclusion: 即使是最先进的视觉语言模型也难以将描述性的物理知识转化为精确的预测性控制。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [172] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: LLM正改变有机合成，通过学习、预测和自动化实验，并结合其他技术加速研发，但仍需解决数据偏见、可解释性和安全问题，社区正在努力实现其普及和可控的创新。


<details>
  <summary>Details</summary>
Motivation: LLM正开始重塑化学家规划和运行有机合成反应的方式。

Method: LLM通过学习数百万个已报道的转化过程，可以提出合成路线、预测反应结果，并指导执行实验的机器人。

Result: LLM已成为实用的实验室伙伴，并有潜力实现由人工智能和自动化驱动的快速、可靠和包容性的分子创新。

Conclusion: LLM与图神经网络、量子计算和实时光谱相结合，可以缩短研发周期，支持更绿色、数据驱动的化学。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [173] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: AI alignment needs to be geographically sensitive, as what's acceptable varies by region. Current methods are often one-size-fits-all, which is problematic with AI's growing influence. This paper reviews research, suggests future work, and proposes methods to assess this sensitivity, especially as AI becomes more autonomous.


<details>
  <summary>Details</summary>
Motivation: The geographic variability of AI alignment is underexplored. AI systems need to align with societal norms and goals, which differ across regions. Current alignment measures can produce outcomes that diverge from statistical realities and may not be globally acceptable, necessitating context-aware approaches.

Method: This paper reviews key geographic research problems, suggests topics for future work, and outlines methods for assessing alignment sensitivity.

Result: AI alignment measures must account for geographic variations in cultural norms, political realities, and legislation. Models need to be sensitive to user location and context to provide globally acceptable outputs and accurately represent geographic reality.

Conclusion: AI alignment needs to consider geographic variability due to cultural norms, political realities, and legislation, as one-size-fits-all approaches are insufficient, especially with the advent of agentic AI. Future work should focus on spatio-temporally aware alignment and methods for assessing alignment sensitivity.

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [174] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 本研究量化了现有AI基准测试与欧盟AI法案监管要求之间的差距，发现现有测试严重忽视了失控、网络攻击等关键风险的评估，为AI监管和评估工具的未来发展提供了重要指导。


<details>
  <summary>Details</summary>
Motivation: 随着通用人工智能（GPAI）模型的快速发展以及欧盟AI法案等新兴法规的出台，建立健全的评估框架变得至关重要。现有评估工具未能充分衡量新监管环境所关注的系统性风险，因此需要量化“基准-监管”差距。

Method: 研究引入了一个名为Bench-2-CoP的新颖系统框架，利用经过验证的LLM-as-judge（大语言模型作为裁判）分析方法，将广泛使用的基准测试中的194,955个问题映射到欧盟AI法案的“模型能力”和“模型倾向”分类标准。

Result: 研究发现，评估生态系统过度关注“幻觉”和“歧视性偏见”等少数行为倾向，而忽视了关键的功能性能力。特别是，与失控场景相关的能力，如逃避人类监督、自我复制和自主AI发展，在现有基准测试中完全缺失。失控和网络攻击等系统性风险的评估覆盖率极低（分别为0.4%和0.8%），表明存在巨大的评估鸿沟。

Conclusion: 该研究首次对基准测试与欧盟AI法案监管要求之间的差距进行了全面、量化的分析，为政策制定者完善实践守则和开发者构建下一代评估工具提供了关键见解，旨在促进更安全、更合规的AI发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [175] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 利用LLM技术生成了用于对话情感识别（ERC）的新数据集，克服了现有数据集的不足，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有ERC数据集稀缺且存在偏差，而LLM在ERC数据生成方面的应用有限，且训练成本高。

Method: 使用小型、资源高效、通用的LLM来合成ERC数据集，并生成了六个新的数据集，其中两个是为了增强现有的ERC基准。

Result: 在ERC分类任务中，使用生成的数据集训练的模型表现出良好的鲁棒性，并在现有ERC基准上取得了显著的性能提升，同时还分析了标签不平衡对ERC的影响。

Conclusion: 所生成的数据集在增强现有ERC基准方面表现出优越的性能，提高了模型的鲁棒性和准确性。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [176] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign通过智能数据筛选和SFT+DPO，用更少的数据高效提升了LLM的推理能力，尤其在数学方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理能力提升方法（如训练后调整）在数据和计算成本上非常昂贵。尽管已有方法试图通过选择性数据整理来提高样本效率，但它们通常依赖于启发式或特定任务的策略，这限制了其可扩展性。

Method: InfiAlign框架整合了监督微调（SFT）和直接偏好优化（DPO），其核心是一个数据选择流程，利用多维度质量指标从开源推理数据集中自动筛选出高质量的对齐数据，从而实现可扩展和样本高效的LLM推理能力增强。

Result: 在Qwen2.5-Math-7B-Base模型上，InfiAlign的SFT模型在仅使用了约12%的训练数据的情况下，达到了与DeepSeek-R1-Distill-Qwen-7B相当的性能，并展示了在多样化推理任务上的强大泛化能力。DPO的应用进一步提升了模型性能，特别是在数学推理任务上，在AIME 24/25基准测试中的平均提升为3.89%。

Conclusion: InfiAlign通过结合监督微调（SFT）和直接偏好优化（DPO），并采用多维度质量指标自动筛选高质量的对齐数据，实现了可扩展且样本高效的LLM增强推理能力。该方法在Qwen2.5-Math-7B-Base模型上展现了显著的性能提升，同时大幅降低了数据需求，并在数学推理任务上取得了尤为显著的改进，平均提高了3.89%。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [177] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL是一个图检索增强的交互式学习框架，通过LLM引导的探索和路径过滤来合成数据，并采用两阶段训练来优化图检索策略，以解决现有RAG方法在处理结构化知识图谱时的局限性，并在知识图谱问答任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要处理非结构化数据，在处理知识图谱等结构化知识方面能力有限，且当前图检索方法在捕获整体图结构和控制精度方面存在挑战。

Method: GRAIL框架整合了LLM引导的随机探索与路径过滤，构建了数据合成流程，为每个任务自动生成精细化的推理轨迹。随后，采用两阶段训练过程来学习一个策略，动态决定每个推理步骤的最优动作。

Result: GRAIL在三个知识图谱问答数据集上取得了显著的性能提升，平均准确率提高21.01%，F1分数提高22.43%。

Conclusion: GRAIL通过解耦精度-简洁性平衡、引入精细化的过程监督奖励以及采用交互式检索范式，显著提高了在知识图谱问答任务上的准确性和F1分数，平均准确率提升21.01%，F1分数提升22.43%。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [178] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出一个通用的、模块化的代理评估框架，可进行逐步推理评估，并在基准测试中优于LLM-as-a-Judge。


<details>
  <summary>Details</summary>
Motivation: 当前评估基础模型作为代理的方法（如LLM-as-a-Judge）仅关注最终输出，忽略了代理决策过程中的逐步推理；而现有的Agent-as-a-Judge系统通常针对狭窄的、特定领域的设置。

Method: 提出一个可泛化的、模块化的框架，该框架通过分解任务到子任务，并使用可用信息（如代理的输出和推理）验证每个步骤来模仿类似人类的评估。

Result: 在Magentic-One Actor Agent的GAIA和BigCodeBench基准测试中，Judge Agent在任务成功预测方面与人类评估的一致性更高，分别比GPT-4o的LLM-as-a-Judge基线提高了4.76%和10.52%的对齐准确率。

Conclusion: 该框架通过分解任务、验证每个步骤并聚合模块输出来对代理任务完成情况进行评估，在基准测试中显示出比LLM-as-a-Judge更高的与人类评估的一致性。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [179] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI是一个AI工具，使用NLP和大型语言模型（RoBERTa，LLAMA）自动评估研究生申请者推荐信中的领导力技能，RoBERTa模型达到了91.6%的F1分数，有助于简化招生和更全面地评估申请人。


<details>
  <summary>Details</summary>
Motivation: 为了解决招生委员会在审查耗时且劳动密集型的推荐信（LORs）以评估申请人能力方面的挑战，并支持学生职业成长方面的反馈，本研究旨在开发一种AI工具来自动化和标准化领导力技能的评估。

Method: 本研究采用自然语言处理（NLP）技术，并利用RoBERTa和LLAMA等大型语言模型来开发LORI：LOR Insights工具，以自动评估在线硕士项目申请者推荐信（LORs）中的领导力技能，如团队合作、沟通和创新。

Result: 研究结果表明，其最新的RoBERTa模型在测试数据上取得了91.6%的加权F1分数，92.4%的精确率和91.6%的召回率，显示出高度的一致性。

Conclusion: LORI: LOR Insights是一个新颖的AI驱动的检测工具，用于评估在线硕士项目申请者的推荐信（LORs）中的领导力技能。通过使用自然语言处理和基于RoBERTa和LLAMA的大型语言模型，该工具旨在识别团队合作、沟通和创新等领导力属性。该研究强调了在STEM领域日益增长的领导力技能的重要性，并将LORI整合到研究生招生过程中，以更准确地评估申请人的领导力能力，从而简化流程并实现更全面的能力评估。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [180] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate是一个多视图智能体辩论框架，用于检测有害内容，它通过整合多种分析视角和迭代辩论来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 识别社交媒体中隐藏的有害意图（如讽刺、仇恨言论或错误信息）具有挑战性，因为存在跨模态矛盾、快速的文化变化和微妙的语用线索。

Method: 提出了一种名为MV-Debate的多视图智能体辩论框架，该框架采用动态反射门控机制，并集成了四个互补的智能体：表面分析器、深度推理器、模态对比器和社会情境主义者。通过迭代辩论和基于“反射增益”标准的反射，智能体能够优化响应，以实现准确性和效率。

Result: 实验结果表明，MV-Debate在三个基准数据集上显著优于强单模型和现有的多智能体辩论基线。

Conclusion: MV-Debate框架在统一的多模态有害内容检测方面表现出色，显著优于现有的单模型和多智能体辩论基线，展示了多智能体辩论在可靠的社交意图检测方面的潜力。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [181] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 主动推理（AIF）通过引入内在驱动力来解决AI的“grounded-agency gap”，使智能体能够自主学习和制定目标，从而克服对人工奖励工程的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在从经验中学习时面临可扩展性挑战，因为它们依赖于昂贵的人工奖励工程，而“经验时代”的愿景仍然依赖于奖励函数的广泛人工工程，这突显了AI系统在自主制定、适应和追求目标方面的不足，即“the grounded-agency gap”。

Method: 提出主动推理（AIF）可以弥合“ the grounded-agency gap”，通过用最小化自由能的内在驱动力取代外部奖励信号，使智能体能够通过统一的贝叶斯目标自然地平衡探索和利用。

Result: 主动推理（AIF）可以弥合“the grounded-agency gap”，通过用最小化自由能的内在驱动力取代外部奖励信号，使智能体能够通过统一的贝叶斯目标自然地平衡探索和利用。

Conclusion: 通过将大型语言模型作为生成世界模型与主动推理原则性决策框架相结合，可以创建能够从经验中有效学习并保持与人类价值观一致的智能体，从而为实现可自主开发并遵循计算和物理约束的AI系统提供了一条引人注目的路径。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [182] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 本研究提出LearnerAgent框架，利用LLM模拟教学环境，分析不同学习者（深度、表面、懒惰、通用）的行为。发现深度学习者能持续进步，表面学习者知识浅薄，通用学习者自我效能高但认知有限。LLM默认表现为“勤奋但脆弱的表面学习者”。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习方法捕获人类学习行为的研究，虽然取得了一定进展，但现有方法在捕捉学习动态、追踪时序进度或提供可解释性方面存在不足。因此，本研究旨在通过一个新颖的框架来解决这些挑战，以更真实地模拟和理解人类学习过程及其与LLM行为的关联。

Method: 本研究引入了一个名为LearnerAgent的新型多智能体框架，该框架基于大型语言模型（LLM）来模拟真实教学环境。研究人员为LLM创建了具有心理学依据的学习者档案（深度、表面、懒惰）以及一个无个人特征的通用学习者，以检查基础LLM的默认行为。通过为期一年的模拟，包括每周的知识获取、每月的策略选择、定期的测试和同伴互动，研究追踪了每个学习者动态学习进度的变化。

Result: 1. 纵向分析显示，只有“深度学习者”实现了持续的认知增长，而研究设计的“陷阱问题”有效诊断了“表面学习者”的浅层知识。2. 不同学习者的行为和认知模式与其心理学特征高度一致。3. “通用学习者”的自我概念得分真实演变，并表现出与认知局限不符的高自我效能感。4. 基础LLM的默认模型是一个“勤奋但脆弱的表面学习者”。

Conclusion: LearnerAgent框架能够模拟真实世界的教学环境，并能有效分析LLM的行为。研究发现，LLM的默认表现为“勤奋但脆弱的表面学习者”，具备良好学生行为但缺乏真正、可泛化的理解。此外，不同学习者（深度、表面、懒惰和通用学习者）的行为和认知模式与其心理学特征高度吻合，且学习者自我概念得分能真实演变，通用学习者甚至表现出与认知局限不符的高自我效能感。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [183] [Online EFX Allocations with Predictions](https://arxiv.org/abs/2508.04779)
*Themistoklis Melissourgos,Nicos Protopapas*

Main category: cs.GT

TL;DR: 研究人员研究了在线公平分配问题，重点是 EFX（无嫉妒）属性。他们发现近似 EFX 分配在一般情况下是不可行的，即使在有约束的情况下也是如此。为了解决这个问题，他们提出了一种结合机器学习预测和真实值的算法。他们证明了仅依赖预测或忽略预测的算法是不可能的，并展示了实现近似 EFX 所需的预测准确性的下限。最后，他们提出了一个针对有两个代理和相同估值的系统的算法，该算法可以近似 EFX，并且其性能随着预测准确性的提高而提高。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决在线公平分配问题，并寻求满足 EFX（无嫉妒）属性的分配。由于近似 EFX 分配在一般情况下不可行，因此研究人员探索了结合预测（例如，来自机器学习模型）来增强算法的方法。

Method: 本研究探讨了在线公平分配问题，其中物品依次到达并分配给代理。研究了 EFX（无嫉妒）属性，并证明了即使在具有约束的设置中，近似 EFX 也不可行。为了解决这个问题，研究人员提出了一种结合预测（例如，来自机器学习模型）和真实值的算法。重点是加性估值，并使用总变化距离来衡量预测误差。

Result: 研究结果表明，即使在对估值函数有限制的情况下，也无法实现近似的 EFX 分配。然而，研究人员提出了一种结合预测和真实值的算法，可以近似 EFX，并且其保证随着预测准确性的提高而提高。

Conclusion: 即使在对估值函数有限制的情况下，也无法实现近似的 EFX 分配。本研究的重点是加性估值，并证明了仅忽略或仅依赖预测的算法的不可能性。此外，我们还展示了任何算法在近似 EFX 分配方面所需的预测准确性方面的下限。这些负面结果即使在个体估值相同的情况下也存在，这与离线设置不同，在离线设置中，无需预测即可获得精确的 EFX 分配。最后，我们提出了一种针对两个具有相同估值的代理的算法，该算法有效地利用了预测和真实值，并近似 EFX，其保证随着预测准确性的提高而提高。

Abstract: We study an online fair division problem where a fixed number of goods arrive
sequentially and must be allocated to a given set of agents. Once a good
arrives, its true value for each agent is revealed, and it has to be
immediately and irrevocably allocated to some agent. The ultimate goal is to
ensure envy-freeness up to any good (EFX) after all goods have been allocated.
Unfortunately, as we show, approximate EFX allocations are unattainable in
general, even under restrictive assumptions on the valuation functions.
  To address this, we follow a recent and fruitful trend of augmenting
algorithms with predictions. Specifically, we assume access to a prediction
vector estimating the agents' true valuations -- e.g., generated by a machine
learning model trained on past data. Predictions may be unreliable, and we
measure their error using the total variation distance from the true
valuations, that is, the percentage of predicted value-mass that disagrees with
the true values.
  Focusing on the natural class of additive valuations, we prove impossibility
results even on approximate EFX allocations for algorithms that either ignore
predictions or rely solely on them. We then turn to algorithms that use both
the predictions and the true values and show strong lower bounds on the
prediction accuracy that is required by any algorithm to compute an approximate
EFX. These negative results persist even under identical valuations, contrary
to the offline setting where exact EFX allocations always exist without the
necessity of predictions. We then present an algorithm for two agents with
identical valuations that uses effectively the predictions and the true values.
The algorithm approximates EFX, with its guarantees improving as the accuracy
of the predictions increases.

</details>


### [184] [Toward Energy and Location-Aware Resource Allocation in Next Generation Networks](https://arxiv.org/abs/2508.05109)
*Mandar Datar,Mattia Merluzzi*

Main category: cs.GT

TL;DR: 无线网络正在从纯粹的无线电资源提供者转变为包含分布式计算（边缘和云）的复杂系统。优化目标也正从关注性能转向关注价值。本文提出了一种基于渔业市场的解决方案，用于在能源约束下分配通信和计算资源，旨在平衡效用、用户体验和公平性，并成功证明了市场均衡，同时通过数值结果展示了服务的多维度权衡。


<details>
  <summary>Details</summary>
Motivation: 在能源和碳足迹等全局约束下，平衡通信和计算资源，以最大化服务提供商的效用、用户的体验质量和公平性。

Method: 将通信和计算资源分配建模为渔业市场，并提出了一种低复杂度的解决方案。

Result: 市场均衡得到了数学证明，数值结果显示了不同地点、通信和计算密集型服务之间效用与能源之间的多维度权衡。

Conclusion: 通过将通信和计算资源分配建模为渔业市场，提出了一种低复杂度的解决方案，该方案能够在满足能源约束的同时实现高效用并促进服务提供商之间的公平性。

Abstract: Wireless networks are evolving from radio resource providers to complex
systems that also involve computing, with the latter being distributed across
edge and cloud facilities. Also, their optimization is shifting more and more
from a performance to a value-oriented paradigm. The two aspects shall be
balanced continuously, to maximize the utilities of Services Providers (SPs),
users quality of experience and fairness, while meeting global constraints in
terms of energy consumption and carbon footprint among others, with all these
heterogeneous resources contributing. In this paper, we tackle the problem of
communication and compute resource allocation under energy constraints, with
multiple SPs competing to get their preferred resource bundle by spending a a
fictitious currency budget. By modeling the network as a Fisher market, we
propose a low complexity solution able to achieve high utilities and guarantee
energy constraints, while also promoting fairness among SPs, as compared to a
social optimal solution. The market equilibrium is proved mathematically, and
numerical results show the multi-dimensional trade-off between utility and
energy at different locations, with communication and computation-intensive
services.

</details>


### [185] [A New Three-Players Auction Bridge with Dynamic Opponents and Team Members](https://arxiv.org/abs/2508.05582)
*Sourish Sarkar,Aritrabha Majumdar,Moutushi Chatterjee*

Main category: cs.GT

TL;DR: 一种新的三玩家桥牌游戏，旨在提高灵活性和策略深度，并通过新颖的计分系统促进公平竞争。


<details>
  <summary>Details</summary>
Motivation: 为了结束固定搭档，使游戏更具动感和灵活性。

Method: 提出了一种新的三玩家桥牌游戏版本，旨在消除固定搭档，使游戏更具动感和灵活性。通过动态重定义团队构成，游戏设计增加了不可预测性，并迫使玩家不断更新策略。引入了一种新颖的计分系统，通过奖励机制来减少传统基于规则的游戏的偏见，从而有利于公平性，并强制执行战术决策和风险评估。该版本遵循常规桥牌规则，测试玩家在没有固定伙伴的情况下进行协作，需要实时的流畅调整和适应性竞标行为。战略问题包括在三玩家结构中进行积极和消极的竞标、适应性游戏风格以及寻求损失的策略。文章讨论了竞标的概率问题、主叫和无主叫的声明效果以及夺取纸牌的算法方法。

Result: 模拟结果说明了不同策略的效率。该游戏的架构非常适合比赛，并可能对扩大比赛纸牌游戏的参与人数产生影响。

Conclusion: 该桥牌版本通过动态重定义团队构成，增加了不可预测性，并鼓励玩家进行实时策略更新。它引入了一种新颖的计分系统，通过奖励机制来减少传统基于规则的游戏的偏见，从而有利于公平性，并强制执行战术决策和风险评估。该版本遵循常规桥牌规则，测试玩家在没有固定伙伴的情况下进行协作，需要实时的流畅调整和适应性竞标行为。

Abstract: This article presents a new three-player version of the bridge playing card
game for the purpose of ending fixed partnerships so that the play can be more
dynamic and flexible. By dynamically redefining team makeup in real time, this
game design increases unpredictability and forces players to repeatedly update
strategy. A novel scoring system is introduced to reduce biases present in
conventional rule-based games by favoring fairness via reward systems that
enforce tactical decision making and risk assessment. Being subject to regular
bridge rules, this version tests players to collaborate without fixed
friendships, requiring fluid adjustment and adaptive bidding behavior in real
time. Strategic issues involve aggressive and defensive bidding, adaptable
playing styles, and loss-seeking strategies specific to the three-player
structure. The article discusses probabilistic issues of bidding, trump and
no-trump declarative effects, and algorithmic methods to trick-taking.
Simulation outcomes illustrate the efficiency of diverse strategies. The game's
architecture is ideal for competitions and possibly influential in broadening
entry pools for tournament card games.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [186] [Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space](https://arxiv.org/abs/2508.04726)
*Thejas Radhika Sajith*

Main category: cs.DS

TL;DR: 本文改进了子集和问题的算法，提出了时间和空间复杂度更优的确定性和随机化算法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决子集和问题，并回答了是否能实现O(n+t)时间复杂度的随机化算法以及是否能构造出时间复杂度与Bellman算法相当的确定性多项式空间算法这两个问题。

Method: 使用多点求值技术来加速一个瓶颈步骤。

Result: 成功构造了一个确定性算法，运行时间为O(nt)，空间复杂度为O(n log^2 t)；以及一个随机化算法，运行时间为O(n+t)，空间复杂度为O(n^2 + n log^2 t)。

Conclusion: 本文通过多点求值方法改进了现有算法，解决了子集和问题。提出了一个确定性算法，运行时间为O(nt)，空间复杂度为O(n log^2 t)；以及一个随机化算法，运行时间为O(n+t)，空间复杂度为O(n^2 + n log^2 t)。

Abstract: Given a multiset $A = \{a_1, \dots, a_n\}$ of positive integers and a target
integer $t$, the Subset Sum problem asks if there is a subset of $A$ that sums
to $t$. Bellman's [1957] classical dynamic programming algorithm runs in
$O(nt)$ time and $O(t)$ space. Since then, there have been multiple
improvements in both time and space complexity.
  Notably, Bringmann [SODA 2017] uses a two-step color-coding technique to
obtain a randomized algorithm that runs in $\tilde{O}(n+t)$ time and
$\tilde{O}(t)$ space. On the other hand, there are polynomial space algorithms
-- for example, Jin, Vyas and Williams [SODA 2021] build upon the algorithm
given by Bringmann, using a clever algebraic trick first seen in Kane's
Logspace algorithm, to obtain an $\tilde{O}(nt)$ time and $\tilde{O}(\log(nt))$
space algorithm. A natural question, asked by Jin et al. is if there is an
$\tilde{O}(n+t)$ time algorithm running in poly$(n, \log t)$ space. Another
natural question is whether it is possible to construct a deterministic
polynomial space algorithm with time complexity comparable to that of
Bellman's.
  In this paper, we answer both questions affirmatively. We build on the
framework given by Jin et al., using a multipoint evaluation-based approach to
speed up a bottleneck step in their algorithm. We construct a deterministic
algorithm that runs in $\tilde{O}(nt)$ time and $\tilde{O}(n \log^2 t)$ space
and a randomized algorithm that runs in $\tilde{O}(n+t)$ time and
$\tilde{O}(n^2 + n \log^2 t)$ space.

</details>


### [187] [A Refutation of Elmasry's $\tilde{O}(m \sqrt{n})$-Time Algorithm for Single-Source Shortest Paths](https://arxiv.org/abs/2508.04872)
*Sunny Atalig,Marek Chrobak*

Main category: cs.DS

TL;DR: The claimed $\tilde{O}(m\sqrt{n})$ running time for Elmasry's shortest path algorithm is incorrect; a counterexample shows its running time is $\Omega(mn)$.


<details>
  <summary>Details</summary>
Motivation: To examine and verify the claims made in Amr Elmasry's paper "Breaking the Bellman-Ford Shortest-Path Bound" regarding the running time complexity of his proposed algorithm for the single-source shortest path problem.

Method: The analysis involves providing a weighted graph as a counterexample to demonstrate the incorrectness of Elmasry's claimed running time complexity.

Result: The analysis shows that Elmasry's algorithm has a running time complexity of $\Omega(mn)$ on a specific weighted graph, contradicting his claim of $\tilde{O}(m\sqrt{n})$.

Conclusion: Elmasry's analysis of his shortest path algorithm is incorrect, and its running time complexity is actually $\Omega(mn)$ on certain weighted graphs, not $\tilde{O}(m\sqrt{n})$.

Abstract: In this note we examine the recent paper "Breaking the Bellman-Ford
Shortest-Path Bound" by Amr Elmasry, where he presents an algorithm for the
single-source shortest path problem and claims that its running time complexity
is $\tilde{O}(m\sqrt{n})$, where $n$ is the number of vertices and $m$ is the
number of edges. We show that his analysis is incorrect, by providing an
example of a weighted graph on which the running time of his algorithm is
$\Omega(mn)$.

</details>


### [188] [Text Indexing and Pattern Matching with Ephemeral Edits](https://arxiv.org/abs/2508.05124)
*Solon P. Pissis*

Main category: cs.DS

TL;DR: 该研究提出了一种新的文本索引方法，支持临时子串编辑操作，并给出了高效的预处理和查询算法。


<details>
  <summary>Details</summary>
Motivation: 为了支持对文本进行临时子串插入、删除或替换等编辑操作的模式匹配查询。

Method: 该方法对长度为 n 的文本 T 进行了预处理，预处理时间为 O(n)。对于任意长度为 m 的模式 P，可以在 O(m log log m) 时间和 O(m) 空间内进行在线预处理。该方法还支持任意的临时编辑操作序列，并在每次操作后 O(log log n + Occ) 的时间内报告模式 P 在当前文本 T^i 中的所有出现次数，其中 Occ 是出现次数。

Result: 提出了一种新的文本索引方法，并给出了相应的预处理和查询时间复杂度。

Conclusion: 该研究提出了一种新的文本索引方法，称为“带临时子串编辑的文本索引”，并设计了一种数据结构来支持这种类型的编辑操作。

Abstract: A sequence $e_0,e_1,\ldots$ of edit operations in a string $T$ is called
ephemeral if operation $e_i$ constructing string $T^i$, for all $i=2k$ with
$k\in\mathbb{N}$, is reverted by operation $e_{i+1}$ that reconstructs $T$.
Such a sequence arises when processing a stream of independent edits or testing
hypothetical edits.
  We introduce text indexing with ephemeral substring edits, a new version of
text indexing. Our goal is to design a data structure over a given text that
supports subsequent pattern matching queries with ephemeral substring
insertions, deletions, or substitutions in the text; we require insertions and
substitutions to be of constant length. In particular, we preprocess a text
$T=T[0\mathinner{.\,.} n)$ over an integer alphabet $\Sigma=[0,\sigma)$ with
$\sigma=n^{\mathcal{O}(1)}$ in $\mathcal{O}(n)$ time. Then, we can preprocess
any arbitrary pattern $P=P[0\mathinner{.\,.} m)$ given online in
$\mathcal{O}(m\log\log m)$ time and $\mathcal{O}(m)$ space and allow any
ephemeral sequence of edit operations in $T$. Before reverting the $i$th
operation, we report all Occ occurrences of $P$ in $T^i$ in
$\mathcal{O}(\log\log n + \text{Occ})$ time.
  We also introduce pattern matching with ephemeral edits. In particular, we
preprocess two strings $T$ and $P$, each of length at most $n$, over an integer
alphabet $\Sigma=[0,\sigma)$ with $\sigma=n^{\mathcal{O}(1)}$ in
$\mathcal{O}(n)$ time. Then, we allow any ephemeral sequence of edit operations
in $T$. Before reverting the $i$th operation, we report all Occ occurrences of
$P$ in $T^i$ in the optimal $\mathcal{O}(\text{Occ})$ time. Along our way to
this result, we also give an optimal solution for pattern matching with
ephemeral block deletions.

</details>


### [189] [Space-Efficient Hierholzer: Eulerian Cycles in O(m) Time and O(n) Space](https://arxiv.org/abs/2508.05251)
*Ziad Ismaili Alaoui,Detlef Plump,Sebastian Wild*

Main category: cs.DS

TL;DR: 一种改进的 Hierholzer 算法，内存占用更少，运行时间仍为线性。


<details>
  <summary>Details</summary>
Motivation: 与标准的 Hierholzer 算法实现相比，该算法大大改进了工作空间，后者使用 O(m lg n)比特的空间。

Method: 一种 Hierholzer 算法的简单变体，该算法在具有 n 个顶点和 m 个边的（多）图中查找欧拉回路，使用 O(n lg m)比特的工作内存。

Result: 该算法运行时间为线性时间，但避免了 O(m)大小的顶点栈或存储每条边的信息。对于具有大边重数 的稠密图或多重图来说，空间节省尤其重要。

Conclusion: 该算法是第一个达到此空间复杂度并运行在线性时间内的算法，并且易于实现。

Abstract: We describe a simple variant of Hierholzer's algorithm that finds an Eulerian
cycle in a (multi)graph with $n$ vertices and $m$ edges using $\mathrm{O}(n \lg
m)$ bits of working memory. This substantially improves the working space
compared to standard implementations of Hierholzer's algorithm, which use
$\mathrm{O}(m \lg n)$ bits of space. Our algorithm runs in linear time, like
the classical versions, but avoids an $\mathrm{O}(m)$-size stack of vertices or
storing information for each edge. To our knowledge, this is the first
linear-time algorithm to achieve this space bound, and the method is very easy
to implement. The correctness argument, by contrast, is surprisingly subtle; we
give a detailed formal proof. The space savings are particularly relevant for
dense graphs or multigraphs with large edge multiplicities.

</details>


### [190] [Parameterized Algorithms for Spanning Tree Isomorphism by Redundant Set Size](https://arxiv.org/abs/2508.05351)
*Fangjian Shen,Yicheng Zheng,Wushao Wen,Hankz Hankui Zhuo*

Main category: cs.DS

TL;DR: 本文提出了针对图的生成树同构问题的固定参数可处理性算法。


<details>
  <summary>Details</summary>
Motivation: 解决无向和有向图的生成树同构问题

Method: 固定参数可处理性算法

Result: 对于无向版本，算法时间复杂度为O(n^2 log n * 2^(k log k))。对于有向版本，算法时间复杂度为O(n^2 * 2^(4k-3))。

Conclusion: 本文提出了针对无向和有向图的生成树同构问题的固定参数可处理性算法，参数为冗余集的大小k。消除了冗余集中的边可以将图转换为生成树。对于无向版本，该算法的时间复杂度为O(n^2 log n * 2^(k log k))。对于有向版本，我们提出了一种更有效的算法，时间复杂度为O(n^2 * 2^(4k-3))，其中n是顶点的数量。

Abstract: In this paper, we present fixed-parameter tractability algorithms for both
the undirected and directed versions of the Spanning Tree Isomorphism Problem,
parameterized by the size $k$ of a redundant set. A redundant set is a
collection of edges whose removal transforms the graph into a spanning tree.
For the undirected version, our algorithm achieves a time complexity of $O(n^2
\log n \cdot 2^{k \log k})$. For the directed version, we propose a more
efficient algorithm with a time complexity of $O(n^2 \cdot 2^{4k-3})$, where
$n$ is the number of vertices.

</details>


### [191] [Online Sparsification of Bipartite-Like Clusters in Graphs](https://arxiv.org/abs/2508.05437)
*Joyentanuj Das,Suranjan De,He Sun*

Main category: cs.DS

TL;DR: 本研究提出了用于识别二分图样簇的在线稀疏化算法，并在保证聚类有效性的前提下显著加速了现有聚类算法的运行时间。


<details>
  <summary>Details</summary>
Motivation: 为了在分析真实世界数据集时考虑顶点集合之间的相互连接，本研究关注二分图样簇的识别，这是对现有仅关注低电导率顶点集的研究的补充。

Method: 本文提出了能够有效识别二分图样簇的在线稀疏化算法，并将其应用于无向图和有向图中。

Result: 实验结果表明，本研究提出的算法能够有效加速现有聚类算法的运行时间，同时保持其聚类效果。

Conclusion: 本研究提出的算法在保证聚类有效性的前提下，显著加速了现有聚类算法的运行时间。

Abstract: Graph clustering is an important algorithmic technique for analysing massive
graphs, and has been widely applied in many research fields of data science.
While the objective of most graph clustering algorithms is to find a vertex set
of low conductance, a sequence of recent studies highlights the importance of
the inter-connection between vertex sets when analysing real-world datasets.
Following this line of research, in this work we study bipartite-like clusters
and present efficient and online sparsification algorithms that find such
clusters in both undirected graphs and directed ones. We conduct experimental
studies on both synthetic and real-world datasets, and show that our algorithms
significantly speedup the running time of existing clustering algorithms while
preserving their effectiveness.

</details>


### [192] [Parameterized complexity of isometric path partition: treewidth and diameter](https://arxiv.org/abs/2508.05448)
*Dibyayan Chakraborty,Oscar Defrain,Florent Foucaud,Mathieu Mari,Prafullkumar Tale*

Main category: cs.DS

TL;DR: 等距路径划分问题在以树宽为参数时是 W[1]-hard 的，但作者设计了 n^O(tw) 和 diam^O(tw^2) * n^O(1) 时间复杂度的动态规划算法，并排除了更快的算法（除非随机化 ETH 失败）。


<details>
  <summary>Details</summary>
Motivation: 该研究的主要动机是探索等距路径划分问题（Isometric Path Partition）在参数化复杂性理论中的地位，特别是当以图的树宽（tw）作为参数时。许多涉及图距离的度量问题难以用固定大小的 MSO 公式表达，因此不适用于 Courcelle 定理提供的基于树宽的 FPT 算法。这项工作旨在填补这一研究空白，并为解决此类问题提供新的见解和算法。

Method: 作者首先证明了等距路径划分问题在以树宽（tw）为参数时的 W[1]-hard 复杂性，甚至扩展到了路径宽。为了弥补这一硬度结果，作者设计了一个定制的动态规划算法，其运行时间为 n^O(tw)，并且还提供了一个运行时间为 diam^O(tw^2) * n^O(1) 的算法，其中 diam 是图的直径。此外，作者还证明了除非随机化 ETH 失败，否则等距路径划分问题不存在运行时间为 diam^o(tw^2 / (log^3(tw)))) * n^O(1) 的算法。

Result: 该研究证明了等距路径划分问题在以树宽（tw）为参数时是 W[1]-hard 的。同时，提出了一种时间复杂度为 n^O(tw) 的动态规划算法，以及一种时间复杂度为 diam^O(tw^2) * n^O(1) 的算法。此外，还排除了在 Randomized-ETH 失败之前，存在运行时间为 diam^o(tw^2 / (log^3(tw)))) * n^O(1) 的算法的可能性。

Conclusion: 该论文证明了当以图的树宽（tw）为参数时，等距路径划分问题（Isometric Path Partition）是 W[1]-hard 的，甚至对于路径宽也成立。这证实了许多基于度量的问题（特别是涉及图距离的问题）难以通过以树宽为参数进行有效求解。

Abstract: We investigate the parameterized complexity of the Isometric Path Partition
problem when parameterized by the treewidth ($\mathrm{tw}$) of the input graph,
arguably one of the most widely studied parameters. Courcelle's theorem shows
that graph problems that are expressible as MSO formulas of constant size admit
FPT algorithms parameterized by the treewidth of the input graph. This
encompasses many natural graph problems. However, many metric-based graph
problems, where the solution is defined using some metric-based property of the
graph (often the distance) are not expressible as MSO formulas of constant
size. These types of problems, Isometric Path Partition being one of them,
require individual attention and often draw the boundary for the success story
of parameterization by treewidth.
  In this paper, we prove that Isometric Path Partition is $W[1]$-hard when
parameterized by treewidth (in fact, even pathwidth), answering the question by
Dumas et al. [SIDMA, 2024], Fernau et al. [CIAC, 2023], and confirming the
aforementioned tendency. We complement this hardness result by designing a
tailored dynamic programming algorithm running in $n^{O(\mathrm{tw})}$ time.
This dynamic programming approach also results in an algorithm running in time
$\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$, where $\textrm{diam}$ is the
diameter of the graph. Note that the dependency on treewidth is unusually high,
as most problems admit algorithms running in time $2^{O(\mathrm{tw})}\cdot
n^{O(1)}$ or $2^{O(\mathrm{tw} \log (\mathrm{tw}))}\cdot n^{O(1)}$. However, we
rule out the possibility of a significantly faster algorithm by proving that
Isometric Path Partition does not admit an algorithm running in time
$\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$, unless
the Randomized-ETH fails.

</details>


### [193] [An Improved Approximation Algorithm for the Capacitated Arc Routing Problem](https://arxiv.org/abs/2508.05471)
*Jingyang Zhao,Mingyu Xiao*

Main category: cs.DS

TL;DR: 本文改进了容量弧路径问题（CARP）的近似比，是对此类问题近似比的首次改进。


<details>
  <summary>Details</summary>
Motivation: 为了改进容量弧路径问题（CARP）在客户需求量为单位量时的已知最佳近似比，该问题由Golden和Wong在1981年提出，并且是著名容量车辆路径问题（CVRP）的推广。

Method: 提出了一种（5/2-Θ(1/√k)）近似算法。

Result: 将容量弧路径问题（CARP）在客户需求量为单位量时的近似比从Jansen在1993年提出的（5/2-1.5/k）提高到了（5/2-Θ(1/√k)）。

Conclusion: 本文提出了一个（5/2-Θ(1/√k)）近似算法，改进了Jansen在1993年提出的针对具有单位需求量的容量车辆路径问题的近似比（5/2-1.5/k），这是对此类问题近似比的首次改进。

Abstract: The Capacitated Arc Routing Problem (CARP), introduced by Golden and Wong in
1981, is an important arc routing problem in Operations Research, which
generalizes the famous Capacitated Vehicle Routing Problem (CVRP). When every
customer has a unit demand, the best known approximation ratio for CARP, given
by Jansen in 1993, remains $\frac{5}{2}-\frac{1.5}{k}$, where $k$ denotes the
vehicle capacity. Based on recent progress in approximating CVRP, we improve
this result by proposing a
$(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$-approximation algorithm, which to
the best of our knowledge constitutes the first improvement over Jansen's
bound.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [194] [Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off](https://arxiv.org/abs/2508.04825)
*Seungyong Lee,Jeong-gi Kwak*

Main category: cs.GR

TL;DR: Voost是一个统一的框架，通过联合学习虚拟试穿和试穿，并结合注意力温度缩放和自校正采样，解决了服装-身体对应关系中的挑战，并在实验中取得了优于现有技术的成果。


<details>
  <summary>Details</summary>
Motivation: 虚拟试穿在准确模拟服装-身体对应关系方面仍然面临挑战，尤其是在姿势和外观变化的情况下。

Method: 提出了一种名为Voost的统一且可扩展的框架，该框架使用单一的扩散Transformer来联合学习虚拟试穿和试穿。通过联合建模这两个任务，Voost允许每个服装-人物对同时监督两个方向，并支持对生成方向和服装类别的灵活条件控制，从而在没有特定任务网络、辅助损失或额外标签的情况下增强服装-身体关系推理。

Result: Voost在试穿和试穿基准测试中均取得了最先进的成果，在对齐精度、视觉保真度和泛化能力方面持续优于强大的基线。

Conclusion: Voost通过联合学习虚拟试穿和试穿，并引入了注意力温度缩放和自校正采样等推理时技术，在对齐精度、视觉保真度和泛化能力方面取得了最先进的成果。

Abstract: Virtual try-on aims to synthesize a realistic image of a person wearing a
target garment, but accurately modeling garment-body correspondence remains a
persistent challenge, especially under pose and appearance variation. In this
paper, we propose Voost - a unified and scalable framework that jointly learns
virtual try-on and try-off with a single diffusion transformer. By modeling
both tasks jointly, Voost enables each garment-person pair to supervise both
directions and supports flexible conditioning over generation direction and
garment category, enhancing garment-body relational reasoning without
task-specific networks, auxiliary losses, or additional labels. In addition, we
introduce two inference-time techniques: attention temperature scaling for
robustness to resolution or mask variation, and self-corrective sampling that
leverages bidirectional consistency between tasks. Extensive experiments
demonstrate that Voost achieves state-of-the-art results on both try-on and
try-off benchmarks, consistently outperforming strong baselines in alignment
accuracy, visual fidelity, and generalization.

</details>


### [195] [Perceive-Sample-Compress: Towards Real-Time 3D Gaussian Splatting](https://arxiv.org/abs/2508.04965)
*Zijian Wang,Beizhen Zhao,Hao Wang*

Main category: cs.GR

TL;DR: A new framework for 3D Gaussian Splatting improves efficiency and quality by intelligently refining Gaussian parameters, using hierarchical sampling, and applying advanced compression techniques, outperforming traditional methods in large-scale scenes.


<details>
  <summary>Details</summary>
Motivation: Traditional 3D Gaussian Splatting representations struggle with large-scale scene management and efficient storage, especially in complex environments or with limited resources.

Method: The paper introduces a perceive-sample-compress framework for 3D Gaussian Splatting. It includes a scene perception compensation algorithm to refine Gaussian parameters, prioritizing visual importance. A pyramid sampling representation manages Gaussian primitives hierarchically. A Generalized Gaussian Mixed model compression algorithm is used for efficient storage.

Result: The method demonstrates significant improvements in memory efficiency and visual quality, while maintaining real-time rendering speed.

Conclusion: The proposed method significantly improves memory efficiency and high visual quality while maintaining real-time rendering speed.

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
capabilities in real-time and photorealistic novel view synthesis. However,
traditional 3DGS representations often struggle with large-scale scene
management and efficient storage, particularly when dealing with complex
environments or limited computational resources. To address these limitations,
we introduce a novel perceive-sample-compress framework for 3D Gaussian
Splatting. Specifically, we propose a scene perception compensation algorithm
that intelligently refines Gaussian parameters at each level. This algorithm
intelligently prioritizes visual importance for higher fidelity rendering in
critical areas, while optimizing resource usage and improving overall visible
quality. Furthermore, we propose a pyramid sampling representation to manage
Gaussian primitives across hierarchical levels. Finally, to facilitate
efficient storage of proposed hierarchical pyramid representations, we develop
a Generalized Gaussian Mixed model compression algorithm to achieve significant
compression ratios without sacrificing visual fidelity. The extensive
experiments demonstrate that our method significantly improves memory
efficiency and high visual quality while maintaining real-time rendering speed.

</details>


### [196] [Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Reconstruction](https://arxiv.org/abs/2508.04966)
*Yifan Zhou,Beizhen Zhao,Pengcheng Wu,Hao Wang*

Main category: cs.GR

TL;DR: 为解决动态3DGS中的平滑和特征碰撞问题，提出了一种结合哈希编码和拉普拉斯模块的频谱感知编码架构，并辅以增强的高斯动力学属性和KDTree控制的自适应分裂策略，以提高动态场景重建的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法在处理动态场景时面临挑战，要么因为低秩分解导致过度平滑，要么因为高维网格采样引起特征碰撞，这是由于在不同频率下保持运动细节和变形一致性之间存在固有的频谱冲突。

Method: 提出了一种新颖的动态3DGS框架，采用混合显式-隐式函数，包含三个关键创新：1. 频谱感知拉普拉斯编码架构（结合哈希编码和基于拉普拉斯的模块，实现灵活的频率运动控制）；2. 增强的高斯动力学属性（补偿几何变形引起的光度失真）；3. 自适应高斯分裂策略（以KDTree为基础的图元控制，高效查询和优化动态区域）。

Result: 通过广泛的实验，证明了该方法在重建复杂动态场景方面取得了最先进的性能，实现了更好的重建保真度。

Conclusion: 该方法在重建复杂动态场景方面表现出色，达到了更高的重建保真度。

Abstract: While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its
extension to dynamic scenes introduces significant challenges. Existing dynamic
3DGS methods suffer from either over-smoothing due to low-rank decomposition or
feature collision from high-dimensional grid sampling. This is because of the
inherent spectral conflicts between preserving motion details and maintaining
deformation consistency at different frequency. To address these challenges, we
propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions.
Our approach contains three key innovations: a spectral-aware Laplacian
encoding architecture which merges Hash encoding and Laplacian-based module for
flexible frequency motion control, an enhanced Gaussian dynamics attribute that
compensates for photometric distortions caused by geometric deformation, and an
adaptive Gaussian split strategy guided by KDTree-based primitive control to
efficiently query and optimize dynamic areas. Through extensive experiments,
our method demonstrates state-of-the-art performance in reconstructing complex
dynamic scenes, achieving better reconstruction fidelity.

</details>


### [197] [A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding](https://arxiv.org/abs/2508.05064)
*Mahmoud Chick Zaouali,Todd Charter,Yehor Karpichev,Brandon Haworth,Homayoun Najjjaran*

Main category: cs.GR

TL;DR: 该文全面概述了语言引导的高斯溅射技术，讨论了其理论、集成、应用、局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 为了填补当前缺乏对语言引导的高斯溅射技术这一新兴交叉领域进行全面概述的空白。

Method: 对当前结合语言指导和3D高斯溅射的研究工作进行了结构化的回顾。

Result: 文章详细介绍了理论基础、集成策略和现实世界的用例，并强调了计算瓶颈、通用性和语义标注的3D高斯数据稀缺性等关键限制。

Conclusion: 该文对语言引导的高斯溅射技术进行了全面的概述，讨论了其理论基础、集成策略和实际应用。

Abstract: Gaussian Splatting has rapidly emerged as a transformative technique for
real-time 3D scene representation, offering a highly efficient and expressive
alternative to Neural Radiance Fields (NeRF). Its ability to render complex
scenes with high fidelity has enabled progress across domains such as scene
reconstruction, robotics, and interactive content creation. More recently, the
integration of Large Language Models (LLMs) and language embeddings into
Gaussian Splatting pipelines has opened new possibilities for text-conditioned
generation, editing, and semantic scene understanding. Despite these advances,
a comprehensive overview of this emerging intersection has been lacking. This
survey presents a structured review of current research efforts that combine
language guidance with 3D Gaussian Splatting, detailing theoretical
foundations, integration strategies, and real-world use cases. We highlight key
limitations such as computational bottlenecks, generalizability, and the
scarcity of semantically annotated 3D Gaussian data and outline open challenges
and future directions for advancing language-guided 3D scene understanding
using Gaussian Splatting.

</details>


### [198] [RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer](https://arxiv.org/abs/2508.05115)
*Fangyu Du,Taiqing Li,Ziwei Zhang,Qian Qiao,Tan Yu,Dingcheng Zhen,Xu Jia,Yang Yang,Shunshun Yin,Siyuan Liu*

Main category: cs.GR

TL;DR: RAP是一个统一的框架，可以在实时约束下生成高质量的Talking Head，通过混合注意力机制和静态-动态训练-推理范式实现精确的音频控制和高视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法计算复杂度高，不适用于实时部署。实时推理需要在低延迟和低内存约束下运行，通常需要使用高度压缩的潜在表示，但这会影响时空细节的保留和音视频同步。

Method: RAP框架采用了混合注意力机制来精确控制音频，并引入了静态-动态训练-推理范式来避免显式的运动监督。

Result: RAP在保持高视觉保真度的同时，实现了精确的音频驱动控制，并减轻了长期的 temporal drift。

Conclusion: RAP通过混合注意力机制和静态-动态训练-推理范式，在实时约束下实现了高质量的Talking Head生成，并达到了最先进的性能。

Abstract: Audio-driven portrait animation aims to synthesize realistic and natural
talking head videos from an input audio signal and a single reference image.
While existing methods achieve high-quality results by leveraging
high-dimensional intermediate representations and explicitly modeling motion
dynamics, their computational complexity renders them unsuitable for real-time
deployment. Real-time inference imposes stringent latency and memory
constraints, often necessitating the use of highly compressed latent
representations. However, operating in such compact spaces hinders the
preservation of fine-grained spatiotemporal details, thereby complicating
audio-visual synchronization RAP (Real-time Audio-driven Portrait animation), a
unified framework for generating high-quality talking portraits under real-time
constraints. Specifically, RAP introduces a hybrid attention mechanism for
fine-grained audio control, and a static-dynamic training-inference paradigm
that avoids explicit motion supervision. Through these techniques, RAP achieves
precise audio-driven control, mitigates long-term temporal drift, and maintains
high visual fidelity. Extensive experiments demonstrate that RAP achieves
state-of-the-art performance while operating under real-time constraints.

</details>


### [199] [Refining Gaussian Splatting: A Volumetric Densification Approach](https://arxiv.org/abs/2508.05187)
*Mohamed Abdul Gafoor,Marius Preda,Titus Zaharia*

Main category: cs.GR

TL;DR: 本文提出了一种新的密度控制方法，利用惯性体来指导高斯函数的细化过程，并研究了SfM和DIM对点云初始化的影响，在MIP-NeRF 360数据集上取得了优于3DGS的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有3DGS的稠化策略的不足，本文提出了一种新的密度控制方法。

Method: 本文提出了一种新的密度控制方法，该方法利用与每个高斯函数相关的惯性体来指导细化过程。此外，我们还研究了传统的运动恢复结构（SfM）和深度图像匹配（DIM）方法对点云初始化的影响。

Result: 我们的方法在MIP-NeRF 360数据集上的广泛实验评估表明，我们的方法在重建质量上超越了3DGS，并在各种场景中表现出令人鼓舞的性能。

Conclusion: 该方法在MIP-NeRF 360数据集上的广泛实验评估表明，我们的方法在重建质量上超越了3DGS，并在各种场景中表现出令人鼓舞的性能。

Abstract: Achieving high-quality novel view synthesis in 3D Gaussian Splatting (3DGS)
often depends on effective point primitive management. The underlying Adaptive
Density Control (ADC) process addresses this issue by automating densification
and pruning. Yet, the vanilla 3DGS densification strategy shows key
shortcomings. To address this issue, in this paper we introduce a novel density
control method, which exploits the volumes of inertia associated to each
Gaussian function to guide the refinement process. Furthermore, we study the
effect of both traditional Structure from Motion (SfM) and Deep Image Matching
(DIM) methods for point cloud initialization. Extensive experimental
evaluations on the Mip-NeRF 360 dataset demonstrate that our approach surpasses
3DGS in reconstruction quality, delivering encouraging performance across
diverse scenes.

</details>


### [200] [GASP: A Gradient-Aware Shortest Path Algorithm for Boundary-Confined Visualization of 2-Manifold Reeb Graphs](https://arxiv.org/abs/2508.05524)
*Sefat Rahman,Tushar M. Athawale,Paul Rosen*

Main category: cs.GR

TL;DR: GASP算法通过考虑关键可视化属性，改进了Reeb图的表示，使其更准确地反映数据。


<details>
  <summary>Details</summary>
Motivation: 现有的Reeb图绘制算法忽略或违反了Reeb图可视化的三个重要属性：边界约束、紧凑性和与函数梯度对齐，这影响了其表示的准确性。

Method: 提出了一种名为GASP的算法，用于生成Reeb图可视化，该算法考虑了边界约束、紧凑性和与函数梯度对齐的属性。

Result: GASP算法生成的Reeb图可视化在定性和定量上都优于几何重心算法，如通过与TTK实现进行对比评估所示。

Conclusion: GASP算法生成的Reeb图可视化比现有的几何重心算法更能代表底层数据，因为它考虑了Reeb图在边界约束、紧凑性和与函数梯度对齐方面的可视化属性。

Abstract: Reeb graphs are an important tool for abstracting and representing the
topological structure of a function defined on a manifold. We have identified
three properties for faithfully representing Reeb graphs in a visualization.
Namely, they should be constrained to the boundary, compact, and aligned with
the function gradient. Existing algorithms for drawing Reeb graphs are agnostic
to or violate these properties. In this paper, we introduce an algorithm to
generate Reeb graph visualizations, called \textit{GASP}, that is cognizant of
these properties, thereby producing visualizations that are more representative
of the underlying data. To demonstrate the improvements, the resulting Reeb
graphs are evaluated both qualitatively and quantitatively against the
geometric barycenter algorithm, using its implementation available in the
Topology ToolKit (TTK), a widely adopted tool for calculating and visualizing
Reeb graphs.

</details>


### [201] [Point cloud segmentation for 3D Clothed Human Layering](https://arxiv.org/abs/2508.05531)
*Davide Garavaso,Federico Masi,Pietro Musoni,Umberto Castellani*

Main category: cs.GR

TL;DR: 为了解决3D服装建模和模拟中，尤其是在生成逼真褶皱方面，由于人体形态多变带来的挑战，本研究提出了一种名为“clothed human layering”的新型3D点云分割方法。该方法允许点同时关联到多个衣物层，能够估计出隐藏的衣物区域。通过构建包含逼真3D扫描和衣物层真实信息的合成数据集，并测试不同的神经网络设置，实验结果表明该方法在服装分割领域具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有的3D形状分割方法主要针对场景理解，较少应用于建模领域。在服装建模中，分割是语义重建（如人体和服装层）的关键预备步骤。然而，目前的分割方法产生不相交的集合，而服装层之间存在重叠，这与服装建模的需求不符。

Method: 提出了一种新的3D点云分割范式（clothed human layering），允许点同时属于多个层，以估计身体部位和被遮挡的衣物区域。使用新创建的合成数据集，该数据集模拟了逼真的3D扫描和衣物层的地面真实信息，并评估了不同的神经网络设置来处理3D衣物分层，包括粗粒度和细粒度的逐层服装识别。

Result: 实验证明，在服装领域引入适当的分割策略能够带来益处，并在合成和真实世界的扫描数据集上都验证了方法的有效性。

Conclusion: 该研究提出了一种新的3D点云分割范式，称为“clothed human layering”，其中每个3D点可以同时关联到不同的层，从而实现对身体部位和被遮挡衣物的估计。通过构建包含逼真3D扫描和地面真实衣物层信息的新合成数据集，并评估了不同的神经网络设置，实验证明了该方法在服装领域分割的有效性，并在合成和真实扫描数据集上都取得了良好的效果。

Abstract: 3D Cloth modeling and simulation is essential for avatars creation in several
fields, such as fashion, entertainment, and animation. Achieving high-quality
results is challenging due to the large variability of clothed body especially
in the generation of realistic wrinkles. 3D scan acquisitions provide more
accuracy in the representation of real-world objects but lack semantic
information that can be inferred with a reliable semantic reconstruction
pipeline. To this aim, shape segmentation plays a crucial role in identifying
the semantic shape parts. However, current 3D shape segmentation methods are
designed for scene understanding and interpretation and only few work is
devoted to modeling. In the context of clothed body modeling the segmentation
is a preliminary step for fully semantic shape parts reconstruction namely the
underlying body and the involved garments. These parts represent several layers
with strong overlap in contrast with standard segmentation methods that provide
disjoint sets. In this work we propose a new 3D point cloud segmentation
paradigm where each 3D point can be simultaneously associated to different
layers. In this fashion we can estimate the underlying body parts and the
unseen clothed regions, i.e., the part of a cloth occluded by the clothed-layer
above. We name this segmentation paradigm clothed human layering. We create a
new synthetic dataset that simulates very realistic 3D scans with the ground
truth of the involved clothing layers. We propose and evaluate different neural
network settings to deal with 3D clothing layering. We considered both coarse
and fine grained per-layer garment identification. Our experiments demonstrates
the benefit in introducing proper strategies for the segmentation on the
garment domain on both the synthetic and real-world scan datasets.

</details>


### [202] [Physically Controllable Relighting of Photographs](https://arxiv.org/abs/2508.05626)
*Chris Careaga,Yağız Aksoy*

Main category: cs.GR

TL;DR: 一种自监督的图像重新照明方法，结合了物理渲染和神经渲染，实现了对真实世界图像中光照的精确控制和照片级真实感渲染。


<details>
  <summary>Details</summary>
Motivation: 为了实现可控的、基于物理的、照片级真实的图像重新照明。

Method: 提出了一种自监督方法，通过推断场景的有色网格表示（使用单眼估计的几何和内在成分），用户可以定义所需的照明配置，然后使用路径追踪引擎渲染场景，最后通过前馈神经渲染器预测照片级的重新照明结果。通过可微分渲染过程，在原始图像集合上进行自监督训练。

Result: 实现了在真实世界图像上进行可控的、基于物理的重新照明，将3D图形工具（如Blender）中的显式物理灯光控制能力带到了真实世界重新照明的领域。 能够对图像进行重新照明。

Conclusion: 该方法能够将传统渲染的物理准确性与神经渲染带来的照片级真实感相结合，实现了可控的、基于物理的图像重新照明。

Abstract: We present a self-supervised approach to in-the-wild image relighting that
enables fully controllable, physically based illumination editing. We achieve
this by combining the physical accuracy of traditional rendering with the
photorealistic appearance made possible by neural rendering. Our pipeline works
by inferring a colored mesh representation of a given scene using monocular
estimates of geometry and intrinsic components. This representation allows
users to define their desired illumination configuration in 3D. The scene under
the new lighting can then be rendered using a path-tracing engine. We send this
approximate rendering of the scene through a feed-forward neural renderer to
predict the final photorealistic relighting result. We develop a differentiable
rendering process to reconstruct in-the-wild scene illumination, enabling
self-supervised training of our neural renderer on raw image collections. Our
method represents a significant step in bringing the explicit physical control
over lights available in typical 3D computer graphics tools, such as Blender,
to in-the-wild relighting.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [203] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
*Shruti Saxena,Arijit Khan,Joydeep Chandra*

Main category: cs.LG

TL;DR: NAEx是一个可解释的网络对齐框架，可以识别关键子图和特征，并且可以处理新的数据。


<details>
  <summary>Details</summary>
Motivation: 尽管网络对齐（NA）模型取得了进展，但其可解释性仍然有限，导致难以理解对齐决策，并在建立信任方面带来挑战，特别是在高风险领域。

Method: NAEx通过（1）联合参数化图结构和特征空间（通过可学习的边和特征掩码），以及（2）引入一个优化目标（确保解释既忠实于原始预测，又能实现网络之间结构和基于特征的相似性的有意义的比较）来解决保留跨网络联合依赖性这一关键挑战。

Result: NAEx是一个归纳框架，能够为先前未见过的数据高效生成网络对齐解释。我们引入了针对网络对齐可解释性量身定制的评估指标，并通过将其与四种代表性的网络对齐模型集成，在基准数据集上证明了NAEx的有效性和效率。

Conclusion: NAEx是一个即插即用、模型无关的框架，通过识别影响预测的关键子图和特征来解释网络对齐模型。该框架通过联合参数化图结构和特征空间以及引入确保解释的忠实性和有意义的跨网络相似性比较的优化目标，解决了保留跨网络联合依赖性这一关键挑战。NAEx是一个归纳框架，能够为先前未见过的数据高效生成网络对齐解释。我们引入了针对网络对齐可解释性量身定制的评估指标，并通过将其与四种代表性的网络对齐模型集成，在基准数据集上证明了NAEx的有效性和效率。

Abstract: Network alignment (NA) identifies corresponding nodes across multiple
networks, with applications in domains like social networks, co-authorship, and
biology. Despite advances in alignment models, their interpretability remains
limited, making it difficult to understand alignment decisions and posing
challenges in building trust, particularly in high-stakes domains. To address
this, we introduce NAEx, a plug-and-play, model-agnostic framework that
explains alignment models by identifying key subgraphs and features influencing
predictions. NAEx addresses the key challenge of preserving the joint
cross-network dependencies on alignment decisions by: (1) jointly
parameterizing graph structures and feature spaces through learnable edge and
feature masks, and (2) introducing an optimization objective that ensures
explanations are both faithful to the original predictions and enable
meaningful comparisons of structural and feature-based similarities between
networks. NAEx is an inductive framework that efficiently generates NA
explanations for previously unseen data. We introduce evaluation metrics
tailored to alignment explainability and demonstrate NAEx's effectiveness and
efficiency on benchmark datasets by integrating it with four representative NA
models.

</details>


### [204] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
*Haoyu Zhang,Shihao Zhang,Ian Colbert,Rayan Saab*

Main category: cs.LG

TL;DR: 该研究为流行的 GPTQ 量化算法及其相关算法（如 Qronos）提供了首个理论误差界限，解释了其有效性并指导了参数选择。


<details>
  <summary>Details</summary>
Motivation: 尽管 OPTQ（也称为 GPTQ）在减小大型语言模型（LLM）的内存和计算成本方面非常有效，但它缺乏严格的量化误差理论保证。此论文旨在为 OPTQ 及其相关算法提供理论分析和误差界限。

Method: 通过分析 OPTQ 的迭代过程来推导量化误差，并为 OPTQ 的确定性和随机变体以及 Qronos 算法（包括其确定性和随机变体）提供非渐近 2-范数和无穷范数误差界限。

Result: 推导了 OPTQ 的确定性和随机变体以及 Qronos 的定量误差界限。分析结果为特征排序和正则化参数选择提供了理论依据，并对 Qronos 的优势进行了理论解释。

Conclusion: 该研究首次为 OPTQ 的确定性和随机变体以及相关的最先进 PTQ 算法 Qronos 提供了定量误差界限。分析解释了 OPTQ 的迭代过程如何引起量化误差，并推导了依赖于校准数据和正则化参数的非渐近 2-范数误差界限，为特征排序和正则化参数选择等实际设计选择提供了理论依据。此外，还为随机变体建立了更强的无穷范数误差界限，以控制量化字母表的大小，并为 Qronos 提供了新的理论界限。

Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the
memory and compute costs of modern deep neural networks, including large
language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as
GPTQ-has emerged as a leading method due to its computational efficiency and
strong empirical performance. Despite its widespread adoption, however, OPTQ
lacks rigorous quantitative theoretical guarantees. This paper presents the
first quantitative error bounds for both deterministic and stochastic variants
of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ
algorithm. We analyze how OPTQ's iterative procedure induces quantization error
and derive non-asymptotic 2-norm error bounds that depend explicitly on the
calibration data and a regularization parameter that OPTQ uses. Our analysis
provides theoretical justification for several practical design choices,
including the widely used heuristic of ordering features by decreasing norm, as
well as guidance for selecting the regularization parameter. For the stochastic
variant, we establish stronger infinity-norm error bounds, which enable control
over the required quantization alphabet and are particularly useful for
downstream layers and nonlinearities. Finally, we extend our analysis to
Qronos, providing new theoretical bounds, for both its deterministic and
stochastic variants, that help explain its empirical advantages.

</details>


### [205] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LumiGen是一个集成了LVLM的T2I框架，通过IPPA和IVFR模块，在文本渲染、姿态生成等方面实现了更可控、更高质量的图像生成。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到图像（T2I）生成模型在处理复杂指令、实现精细内容控制和保持深层语义一致性方面仍面临挑战，具体表现在文本渲染、姿态生成或构图连贯性等方面。LVLM在跨模态理解和指令遵循方面展现出强大能力，可用于提升T2I模型性能。

Method: 提出了一种名为LumiGen的新型框架，该框架增强了文本到图像（T2I）模型，并通过闭环、LVLM驱动的反馈机制实现精细控制。LumiGen包含一个智能提示解析与增强（IPPA）模块和一个迭代视觉反馈与细化（IVFR）模块，后者充当“视觉评论家”以迭代地校正和优化生成的图像。

Result: 在具有挑战性的LongBench-T2I基准测试中，LumiGen取得了3.08的优越平均分，超越了最先进的基线模型，在文本渲染和姿态表达等维度上显示出显著改进。

Conclusion: LumiGen通过集成LVLM的闭环反馈机制，在处理复杂指令、实现细粒度内容控制和保持深层语义一致性方面显著优于现有T2I模型，尤其在文本渲染和姿态表达等关键维度上表现突出。

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [206] [Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms](https://arxiv.org/abs/2508.05141)
*Yahong Yang,Juncai He*

Main category: cs.LG

TL;DR: 深度神经网络在逼近PDE弱解方面具有超收敛性，其精度优于传统数值方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为科学计算中基于神经网络的PDE方法提供统一的理论基础，并填补了相关误差估计理论的空白。

Method: 该分析表明，具有通用激活函数的深度网络可以比传统数值方法在逼近程度上更准确地逼近偏微分方程（PDE）的弱解。

Result: 所提出的收敛速度超过了有限元和谱方法等经典数值逼近技术的收敛速度，展现了我们称为“超收敛”的现象。

Conclusion: 本研究为常用的激活函数深度全连接神经网络在Sobolev空间$W^{n,\infty}$中提供了全面的逼近结果，并衡量了在$W^{m,p}$范数（$m<n$, $1\le p \le \infty$）下的误差。

Abstract: This paper establishes a comprehensive approximation result for deep
fully-connected neural networks with commonly-used and general activation
functions in Sobolev spaces $W^{n,\infty}$, with errors measured in the
$W^{m,p}$-norm for $m < n$ and $1\le p \le \infty$. The derived rates surpass
those of classical numerical approximation techniques, such as finite element
and spectral methods, exhibiting a phenomenon we refer to as
\emph{super-convergence}. Our analysis shows that deep networks with general
activations can approximate weak solutions of partial differential equations
(PDEs) with superior accuracy compared to traditional numerical methods at the
approximation level. Furthermore, this work closes a significant gap in the
error-estimation theory for neural-network-based approaches to PDEs, offering a
unified theoretical foundation for their use in scientific computing.

</details>


### [207] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: MissMecha is a new Python toolkit that helps researchers simulate and analyze missing data in tables containing both numbers and categories, under different missingness assumptions (MCAR, MAR, MNAR). It's useful for research, benchmarking, and education.


<details>
  <summary>Details</summary>
Motivation: Incomplete data is a common problem in real-world datasets, often with complex and unobservable missing mechanisms. Simulating missingness is crucial for understanding its impact on learning and analysis. However, existing tools are limited in their ability to handle different mechanisms and often focus only on numerical data, failing to account for the heterogeneous nature of real-world tabular data.

Method: The paper presents MissMecha, a Python toolkit that simulates missing data. The toolkit supports MCAR, MAR, and MNAR assumptions and handles both numerical and categorical features. It includes features for visualization, MCAR testing, and imputation evaluation.

Result: MissMecha provides a unified platform for simulating, visualizing, and evaluating missing data in mixed-type tabular datasets. It supports MCAR, MAR, and MNAR assumptions, includes visual diagnostics and MCAR testing, and offers type-aware imputation evaluation metrics. This toolkit is designed to aid data quality research, benchmarking, and educational purposes.

Conclusion: MissMecha is a unified open-source Python toolkit designed to simulate, visualize, and evaluate missing data under various missingness mechanisms (MCAR, MAR, MNAR). It supports mixed-type tabular datasets (numerical and categorical features), addressing the limitations of existing fragmented and mechanism-limited tools. The toolkit includes visual diagnostics, MCAR testing utilities, and type-aware imputation evaluation metrics, making it a valuable resource for data quality research, benchmarking, and education.

Abstract: Incomplete data is a persistent challenge in real-world datasets, often
governed by complex and unobservable missing mechanisms. Simulating missingness
has become a standard approach for understanding its impact on learning and
analysis. However, existing tools are fragmented, mechanism-limited, and
typically focus only on numerical variables, overlooking the heterogeneous
nature of real-world tabular data. We present MissMecha, an open-source Python
toolkit for simulating, visualizing, and evaluating missing data under MCAR,
MAR, and MNAR assumptions. MissMecha supports both numerical and categorical
features, enabling mechanism-aware studies across mixed-type tabular datasets.
It includes visual diagnostics, MCAR testing utilities, and type-aware
imputation evaluation metrics. Designed to support data quality research,
benchmarking, and education,MissMecha offers a unified platform for researchers
and practitioners working with incomplete data.

</details>


### [208] [Echo State Networks for Bitcoin Time Series Prediction](https://arxiv.org/abs/2508.05416)
*Mansi Sharma,Enrico Sartor,Marc Cavazza,Helmut Prendinger*

Main category: cs.LG

TL;DR: ESNs在预测高波动加密货币方面优于传统方法，即使在混沌时期也是如此。


<details>
  <summary>Details</summary>
Motivation: 预测股票和加密货币价格充满挑战，ESNs已被证明能有效模拟短期股票市场动态，本研究旨在探索ESNs在加密货币预测中的应用，特别是在极端波动和混沌时期。

Method: 使用回声状态网络（ESNs）进行加密货币预测，并通过 Lyapunov 指数进行混沌分析。

Result: ESNs在加密货币预测中表现优于现有的机器学习方法，并且在混沌时期表现稳健，与Lyapunov指数分析结果一致。

Conclusion: ESNs在加密货币预测方面表现稳健，尤其在混沌时期优于Boosting和朴素方法。

Abstract: Forecasting stock and cryptocurrency prices is challenging due to high
volatility and non-stationarity, influenced by factors like economic changes
and market sentiment. Previous research shows that Echo State Networks (ESNs)
can effectively model short-term stock market movements, capturing nonlinear
patterns in dynamic data. To the best of our knowledge, this work is among the
first to explore ESNs for cryptocurrency forecasting, especially during extreme
volatility. We also conduct chaos analysis through the Lyapunov exponent in
chaotic periods and show that our approach outperforms existing machine
learning methods by a significant margin. Our findings are consistent with the
Lyapunov exponent analysis, showing that ESNs are robust during chaotic periods
and excel under high chaos compared to Boosting and Na\"ive methods.

</details>


### [209] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
*Nan Li,Wanting Yang,Marie Siew,Zehui Xiong,Binbin Chen,Shiwen Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Diffusion models (DMs) have emerged as powerful tools for high-quality
content generation, yet their intensive computational requirements for
inference pose challenges for resource-constrained edge devices. Cloud-based
solutions aid in computation but often fall short in addressing privacy risks,
personalization efficiency, and communication costs in multi-user edge-AIGC
scenarios. To bridge this gap, we first analyze existing edge-AIGC applications
in personalized content synthesis, revealing their limitations in efficiency
and scalability. We then propose a novel cluster-aware hierarchical federated
aggregation framework. Based on parameter-efficient local fine-tuning via
Low-Rank Adaptation (LoRA), the framework first clusters clients based on the
similarity of their uploaded task requirements, followed by an intra-cluster
aggregation for enhanced personalization at the server-side. Subsequently, an
inter-cluster knowledge interaction paradigm is implemented to enable
hybrid-style content generation across diverse clusters.Building upon federated
learning (FL) collaboration, our framework simultaneously trains personalized
models for individual users at the devices and a shared global model enhanced
with multiple LoRA adapters on the server,enabling efficient edge inference;
meanwhile, all prompts for clustering and inference are encoded prior to
transmission, thereby further mitigating the risk of plaintext leakage. Our
evaluations demonstrate that the framework achieves accelerated convergence
while maintaining practical viability for scalable multi-user personalized AIGC
services under edge constraints.

</details>


### [210] [Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search](https://arxiv.org/abs/2508.05433)
*Qinglong Hu,Xialiang Tong,Mingxuan Yuan,Fei Liu,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: MLES是一种新颖的程序化策略发现方法，利用多模态大语言模型和进化搜索，实现了高leetcode和可解释性，性能与PPO相当。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度强化学习在可解释性和高性能方面存在的挑战，尤其是在安全关键任务中，因为其固有的不可解释性会削弱信任并阻碍实际部署。

Method: MLES利用多模态大语言模型作为策略生成器，并结合进化机制进行自动策略优化。它在策略生成过程中整合了视觉反馈驱动的行为分析，以识别失败模式并促进有针对性的改进，从而提高了策略发现的效率，并生成了适应性强、与人类对齐的策略。

Result: 实验结果表明，MLES在两个控制任务上实现了与PPO相当的策略发现能力和效率，同时提供了透明的控制逻辑和可追溯的设计过程。

Conclusion: MLES在两个控制任务上实现了与PPO相当的策略发现能力和效率，同时提供了透明的控制逻辑和可追溯的设计过程。该范式克服了预定义特定领域语言的限制，促进了知识转移和复用，并且可以扩展到各种控制任务。MLES有望成为下一代可解释控制策略发现的领先方法。

Abstract: Interpretability and high performance are essential goals in designing
control policies, particularly for safety-critical tasks. Deep reinforcement
learning has greatly enhanced performance, yet its inherent lack of
interpretability often undermines trust and hinders real-world deployment. This
work addresses these dual challenges by introducing a novel approach for
programmatic policy discovery, called Multimodal Large Language Model-assisted
Evolutionary Search (MLES). MLES utilizes multimodal large language models as
policy generators, combining them with evolutionary mechanisms for automatic
policy optimization. It integrates visual feedback-driven behavior analysis
within the policy generation process to identify failure patterns and
facilitate targeted improvements, enhancing the efficiency of policy discovery
and producing adaptable, human-aligned policies. Experimental results show that
MLES achieves policy discovery capabilities and efficiency comparable to
Proximal Policy Optimization (PPO) across two control tasks, while offering
transparent control logic and traceable design processes. This paradigm
overcomes the limitations of predefined domain-specific languages, facilitates
knowledge transfer and reuse, and is scalable across various control tasks.
MLES shows promise as a leading approach for the next generation of
interpretable control policy discovery.

</details>


### [211] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 由于现有电力系统恢复策略存在不公平问题，本研究提出了EPOPR框架，该框架结合了不确定性预测和公平强化学习，能够有效缩短停电时间并减少社区间的不平等。


<details>
  <summary>Details</summary>
Motivation: 当前的电力系统恢复决策主要基于各区域的电力恢复请求量，但数据分析显示，由于弱势社区提交的请求量较少，导致恢复决策存在不公平现象，使这些社区更容易面临长时间停电。为了解决这一问题，需要提出一种既能保证恢复效率又能兼顾社区公平性的电力系统恢复策略。

Method: 设计了一个名为EPOPR的预测-优化框架，包含两个关键组件：1) 采用公平性一致性分位数回归（Equity-Conformalized Quantile Regression）进行不确定性感知的修复时长预测；2) 采用时空注意力强化学习（Spatial-Temporal Attentional RL）以适应不同区域的变化不确定性水平，从而做出公平的决策。

Result: 实验结果表明，EPOPR策略有效地将平均停电时间缩短了3.60%，并将社区间的不平等程度降低了14.19%。

Conclusion: 提出的EPOPR策略通过了实验验证，与现有基线方法相比，平均停电时间减少了3.60%，社区间不平等现象减少了14.19%，证明了其在提高电力系统恢复效率和公平性方面的有效性。

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [212] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
*Pengtao Dang,Tingbo Guo,Sha Cao,Chi Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种用于科学领域少样本学习的多模态大型模型框架（M3F）和数据集（M3FD），该框架能处理多样化数据并优于传统方法，同时易于使用，降低了应用门槛。


<details>
  <summary>Details</summary>
Motivation: 少样本学习（FSL）在科学领域至关重要，因为这些领域的数据收集成本高昂、耗时或受伦理限制。然而，现有的FSL模型在处理多样化的科学数据时存在局限性。因此，需要一种能够有效处理不同数据模态并提高泛化能力的新方法。

Method: 提出了一种名为M3F（Multi-Modal Model for Few-shot learning framework）的新型大型多模态模型框架，该框架支持多种科学数据类型。研究人员构建了一个包含10,000多个样本的多模态少样本数据集（M3FD），涵盖2D RGB图像、2D/3D医学扫描、表格和时间序列数据。通过在M3FD上对M3F进行微调，并与用户友好的数据工具相结合，以解决数据稀疏的科学领域中的少样本学习问题。

Result: 通过在M3FD数据集上进行微调，M3F框架在少样本学习任务上取得了比传统元学习模型更好的性能。该研究还发布了M3FD数据集和M3F框架的源代码，并提供了一个用户友好的工具，以降低在数据稀疏的科学领域应用大型多模态模型的门槛，促进研究的可重复性和普及。

Conclusion: 该研究提出了一种新颖的大型多模态模型（LMMM）框架M3F，用于少样本学习（FSL），并构建了一个包含多样化科学数据（2D/3D图像、表格、时间序列）的多模态少样本数据集（M3FD）。通过在M3FD上微调，M3F在少样本学习任务上表现优于传统的元学习模型，证明了LMMM在科学领域的FSL应用的可行性，并提供了易于使用的工具以促进研究的民主化和可重复性。

Abstract: Few-shot learning (FSL) is a machine learning paradigm that aims to
generalize models from a small number of labeled examples, typically fewer than
10 per class. FSL is particularly crucial in biomedical, environmental,
materials, and mechanical sciences, where samples are limited and data
collection is often prohibitively costly, time-consuming, or ethically
constrained. In this study, we present an innovative approach to FSL by
demonstrating that a Large Multi-Modal Model (LMMM), trained on a set of
independent tasks spanning diverse domains, task types, and input modalities,
can substantially improve the generalization of FSL models, outperforming
models based on conventional meta-learning on tasks of the same type. To
support this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,
over 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,
tabular and time-course datasets, from which we manually curated FSL tasks such
as classification. We further introduced M3F (Multi-Modal Model for Few-shot
learning framework), a novel Large Multi-Modal Model framework tailored for
data-constrained scientific applications. M3F supports a wide range of
scientific data types through a modular pipeline. By fine-tuning the model on
M3FD, M3F improves model performance, making LMMM feasible for real-world FSL
deployment. The source code is located at https://github.com/ptdang1001/M3F. To
democratize access to complex FSL data and promote reproducibility for public
usage, M3FD is paired with a flexible and user-friendly tool that enables
efficient querying, task-specific sampling, and preprocessing. Together, our
dataset and framework offer a unified, scalable solution that significantly
lowers the barrier to applying LMMMs in data-scarce scientific domains.

</details>


### [213] [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](https://arxiv.org/abs/2508.05616)
*Zhikai Zhao,Chuanbo Hua,Federico Berto,Kanghoon Lee,Zihan Ma,Jiachen Li,Jinkyoo Park*

Main category: cs.LG

TL;DR: TrajEvo 是一个利用 LLM 自动设计轨迹预测启发式方法的框架，在准确性、可解释性和泛化性方面均表现出色，尤其是在 OOD 场景中。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法准确性和泛化性不足，深度学习方法计算成本高、可解释性有限且在 OOD 场景中泛化性差，因此需要新的方法来解决这些问题。

Method: TrajEvo 框架利用大型语言模型（LLM）通过进化算法从过去的轨迹数据中生成和优化预测启发式方法，并采用跨代精英采样和统计反馈循环来鼓励多样性和分析改进。

Result: TrajEvo 在多个真实数据集上超越了现有的启发式方法，并在泛化到未见过的 OOD 真实数据集方面显著优于启发式和深度学习方法。

Conclusion: TrajEvo 标志着在自动化设计快速、可解释和可推广的轨迹预测启发式方法方面迈出了重要一步。

Abstract: Trajectory prediction is a critical task in modeling human behavior,
especially in safety-critical domains such as social robotics and autonomous
vehicle navigation. Traditional heuristics based on handcrafted rules often
lack accuracy and generalizability. Although deep learning approaches offer
improved performance, they typically suffer from high computational cost,
limited explainability, and, importantly, poor generalization to
out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a
framework that leverages Large Language Models (LLMs) to automatically design
trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to
generate and refine prediction heuristics from past trajectory data. We propose
two key innovations: Cross-Generation Elite Sampling to encourage population
diversity, and a Statistics Feedback Loop that enables the LLM to analyze and
improve alternative predictions. Our evaluations demonstrate that TrajEvo
outperforms existing heuristic methods across multiple real-world datasets, and
notably surpasses both heuristic and deep learning methods in generalizing to
an unseen OOD real-world dataset. TrajEvo marks a promising step toward the
automated design of fast, explainable, and generalizable trajectory prediction
heuristics. We release our source code to facilitate future research at
https://github.com/ai4co/trajevo.

</details>


### [214] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
*Lin Jiang,Yu Yang,Guang Wang*

Main category: cs.LG

TL;DR: HCRide 是一个基于 Habic 多智能体强化学习算法的人本网约车系统，通过平衡乘客公平性和司机偏好来提升效率，并在实际数据中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在设计一个以人为本的网约车系统，在不牺牲整体系统效率的情况下，同时考虑乘客公平性和司机偏好。现有系统往往只关注效率，可能导致乘客和司机的糟糕体验。

Method: 设计了一个名为 Habic（Harmonization-oriented Actor-Bi-Critic）的新型多智能体强化学习算法，该算法包含多智能体竞争机制、动态 Actor 网络和 Bi-Critic 网络。

Result: 在深圳和纽约市的两个真实世界网约车数据集上进行了广泛评估，结果显示 HCRide 在效率方面提高了 2.02%，公平性方面提高了 5.39%，司机偏好方面提高了 10.21%。

Conclusion: 研究表明，HCRide 在效率、公平性和司机偏好方面均优于现有基线。

Abstract: Order dispatch systems play a vital role in ride-hailing services, which
directly influence operator revenue, driver profit, and passenger experience.
Most existing work focuses on improving system efficiency in terms of operator
revenue, which may cause a bad experience for both passengers and drivers.
Hence, in this work, we aim to design a human-centered ride-hailing system by
considering both passenger fairness and driver preference without compromising
the overall system efficiency. However, it is nontrivial to achieve this target
due to the potential conflicts between passenger fairness and driver preference
since optimizing one may sacrifice the other. To address this challenge, we
design HCRide, a Human-Centered Ride-hailing system based on a novel
multi-agent reinforcement learning algorithm called Harmonization-oriented
Actor-Bi-Critic (Habic), which includes three major components (i.e., a
multi-agent competition mechanism, a dynamic Actor network, and a Bi-Critic
network) to optimize system efficiency and passenger fairness with driver
preference consideration. We extensively evaluate our HCRide using two
real-world ride-hailing datasets from Shenzhen and New York City. Experimental
results show our HCRide effectively improves system efficiency by 2.02%,
fairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art
baselines.

</details>


### [215] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: LLM在分子属性预测中表现不佳，AttriLens-Mol通过奖励机制改进了LLM的推理过程，提高了性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在分子属性预测任务中虽然有潜力，但依赖人工设计的提示和思维链模板，且先进模型的推理过程可能冗长且缺乏相关性。本研究旨在改进LLM在分子属性预测任务中的表现，使其推理过程更有效、更具相关性。

Method: AttriLens-Mol是一种属性引导的强化学习框架，用于LLM的分子属性预测。它通过格式奖励、计数奖励和理性奖励来引导模型的推理过程，其中理性奖励利用高级LLM和RDKit来验证生成属性的相关性。

Result: 在分子属性预测任务中，AttriLens-Mol框架在7B规模的R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1模型上，使用4000个样本进行训练，显著提升了性能。其表现可与监督微调模型（如Mol-Instructions, ChemDFM）和高级模型（如GPT-3.5, GPT-4o, DeepSeek-V3, DeepSeek-R1）相媲美或更优。此外，提取的属性用于决策树模型时，性能优于直接提示LLM生成的属性，证明了AttriLens-Mol能有效提取相关且有预测性的分子属性。

Conclusion: AttriLens-Mol框架通过引入格式奖励、计数奖励和理性奖励，有效地引导了LLM进行分子属性预测，隐式地激发了模型在推理过程中对相关分子属性的内在知识，相比于提示工程和现有的高级模型，取得了更优越或相当的性能，并且能够提取出更具解释性和预测性的属性，用于下游任务。

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [216] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.LG

TL;DR: PA-RNet是一个用于多模态时间序列预测的框架，通过其扰动感知投影模块和跨模态注意力机制，有效处理文本数据中的噪声，并提高了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态时间序列预测方法常常忽略文本数据中固有的扰动，例如不相关、噪声或模糊的内容，这些内容会显著降低模型性能，特别是在噪声强度变化或结构不一致的情况下。

Method: 提出了一种称为PA-RNet（Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting）的鲁棒多模态预测框架。该框架包含一个扰动感知投影模块和一个跨模态注意力机制，用于有效分离文本嵌入中的噪声，同时保持有意义的语义表征，从而提高模型的泛化能力。理论上，证明了PA-RNet相对于文本输入的Lipschitz连续性，并证明了所提出的扰动模块可以减少预期的预测误差，为在有噪声条件下的稳定性提供了强有力的保证。此外，还引入了一个文本扰动流程，可以无缝集成到现有的多模态时间序列预测任务中，从而能够系统地评估模型在不同程度文本噪声存在下的鲁棒性。

Result: PA-RNet有效分离了文本嵌入中的噪声，同时保持了有意义的语义表征，提高了模型的泛化能力。实验证明，PA-RNet在不同领域和时间设置下，持续优于最先进的基线。

Conclusion: PA-RNet在不同领域和时间设置的广泛实验中，持续优于最先进的基线。

Abstract: In real-world applications, multimodal time series data often suffer from
interference, especially in the textual modality. Existing methods for
multimodal time series forecasting often neglect the inherent perturbations
within textual data, where irrelevant, noisy, or ambiguous content can
significantly degrade model performance, particularly when the noise exhibits
varying intensity or stems from structural inconsistencies. To address this
challenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for
Multimodal Time Series Forecasting), a robust multimodal forecasting framework.
PA-RNet features a perturbation-aware projection module and a cross-modal
attention mechanism to effectively separate noise from the textual embeddings
while maintaining semantically meaningful representations, thereby enhancing
the model's generalization ability. Theoretically, we establish the Lipschitz
continuity of PA-RNet with respect to textual inputs and prove that the
proposed perturbation module can reduce expected prediction error, offering
strong guarantees of stability under noisy conditions. Furthermore, we
introduce a textual perturbation pipeline that can be seamlessly incorporated
into existing multimodal time series forecasting tasks, allowing for systematic
evaluation of the model's robustness in the presence of varying levels of
textual noise. Extensive experiments across diverse domains and temporal
settings demonstrate that PA-RNet consistently outperforms state-of-the-art
baselines.

</details>


### [217] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
*Mehmet Emre Akbulut,Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Manuel Roveri*

Main category: cs.LG

TL;DR: InfoQ是一种新颖的混合精度量化（MPQ）框架，它通过测量量化对网络信息流的影响来评估层敏感性，从而实现训练无关的比特宽度搜索。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的混合精度量化（MPQ）方法依赖于计算成本高昂的搜索算法或局部敏感性启发式代理（如Hessian），但这些方法未能捕捉量化误差的级联全局效应。

Method: InfoQ通过一个前向传播来量化每一层在不同比特宽度下的量化，并测量由此产生的后续层中互信息的这种变化。。

Result: InfoQ的无重新训练搜索阶段提供了优越的搜索时间/准确性权衡，同时在ImageNet上的MobileNetV2和ResNet18在高压缩率下（分别为14倍和10.66倍）实现了高达1%的准确率提升。

Conclusion: InfoQ通过量化每一层并测量后续层中互信息的这种变化，来量化每一层量化对网络信息流的影响。

Abstract: Mixed-precision quantization (MPQ) is crucial for deploying deep neural
networks on resource-constrained devices, but finding the optimal bit-width for
each layer represents a complex combinatorial optimization problem. Current
state-of-the-art methods rely on computationally expensive search algorithms or
local sensitivity heuristic proxies like the Hessian, which fail to capture the
cascading global effects of quantization error. In this work, we argue that the
quantization sensitivity of a layer should not be measured by its local
properties, but by its impact on the information flow throughout the entire
network. We introduce InfoQ, a novel framework for MPQ that is training-free in
the bit-width search phase. InfoQ assesses layer sensitivity by quantizing each
layer at different bit-widths and measuring, through a single forward pass, the
resulting change in mutual information in the subsequent layers. This
quantifies how much each layer quantization impacts the network information
flow. The resulting scores are used to formulate bit-width allocation as an
integer linear programming problem, which is solved efficiently to minimize
total sensitivity under a given budget (e.g., model size or BitOps). Our
retraining-free search phase provides a superior search-time/accuracy trade-off
(using two orders of magnitude less data compared to state-of-the-art methods
such as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2
and ResNet18 on ImageNet at high compression rates (14X and 10.66X).

</details>


### [218] [MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling](https://arxiv.org/abs/2508.05492)
*Jifan Gao,Mahmudur Rahman,John Caskey,Madeline Oguss,Ann O'Rourke,Randy Brown,Anne Stey,Anoop Mayampurath,Matthew M. Churpek,Guanhua Chen,Majid Afshar*

Main category: cs.LG

TL;DR: MoMA利用多个LLM智能体处理多模态EHR数据，将非文本数据转换为文本摘要，然后整合这些摘要和临床笔记，最终用于临床预测，在真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了有效整合多模态EHR数据以用于临床预测建模，尽管多模态EHR数据提供了比单模态数据更丰富、互补的见解，但整合过程面临数据需求大等挑战。

Method: 提出了一种名为MoMA（Mixture-of-Multimodal-Agents）的新型架构，该架构利用多个大型语言模型（LLM）智能体来处理多模态EHR数据。该架构包含专门处理非文本模态（如医学影像和实验室结果）的“专家智能体”，将这些数据转换为文本摘要；一个“聚合智能体”，用于整合这些摘要和临床笔记，生成统一的多模态摘要；以及一个“预测智能体”，利用该摘要进行临床预测。

Result: 在三种预测任务上使用具有不同模态组合和预测设置的真实世界数据集评估了MoMA，结果显示MoMA优于当前最先进的方法。

Conclusion: MoMA在结合多种模态的EHR数据进行临床预测任务时，表现优于现有的最先进方法，显示了其在不同任务中的准确性和灵活性。

Abstract: Multimodal electronic health record (EHR) data provide richer, complementary
insights into patient health compared to single-modality data. However,
effectively integrating diverse data modalities for clinical prediction
modeling remains challenging due to the substantial data requirements. We
introduce a novel architecture, Mixture-of-Multimodal-Agents (MoMA), designed
to leverage multiple large language model (LLM) agents for clinical prediction
tasks using multimodal EHR data. MoMA employs specialized LLM agents
("specialist agents") to convert non-textual modalities, such as medical images
and laboratory results, into structured textual summaries. These summaries,
together with clinical notes, are combined by another LLM ("aggregator agent")
to generate a unified multimodal summary, which is then used by a third LLM
("predictor agent") to produce clinical predictions. Evaluating MoMA on three
prediction tasks using real-world datasets with different modality combinations
and prediction settings, MoMA outperforms current state-of-the-art methods,
highlighting its enhanced accuracy and flexibility across various tasks.

</details>


### [219] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
*Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: LLMs在动态胰岛素剂量调整方面，通过精心设计的零样本提示，表现出与RL相当的性能，但在CoT推理时存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: RL-based DTRs在临床应用中存在工程投入大、需要注入临床知识和保证患者安全等挑战。LLMs因其嵌入临床知识和启发式的能力，提供了一种有前景的替代方法。

Method: 本研究在1型糖尿病的计算机模拟中，使用开源LLM作为动态胰岛素剂量调整剂，并将其零样本推理性能与经过训练的基于小型神经网络的RL代理（SRAs）进行了比较。

Result: 在稳定的患者群体中，精心设计的零样本提示使较小的LLMs（如Qwen2.5-7B）能够达到与经过充分训练的SRAs相当或更优的临床性能。然而，LLMs在采用链式思考（CoT）推理时，会表现出过于激进的胰岛素剂量调整，以及算术幻觉、时间误解和临床逻辑不一致等关键故障模式。在提示中加入对潜在临床状态（如进餐）的显式推理，对性能的提升很小。

Conclusion: LLMs在临床工作流程中的集成应谨慎进行，需要有针对性的提示工程、仔细的验证以及结合语言推理和结构化生理建模的混合方法，以实现安全、稳健和临床有效的决策支持系统。

Abstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold
promise for automating complex clinical decision-making, yet their practical
deployment remains hindered by the intensive engineering required to inject
clinical knowledge and ensure patient safety. Recent advancements in large
language models (LLMs) suggest a complementary approach, where implicit prior
knowledge and clinical heuristics are naturally embedded through linguistic
prompts without requiring environment-specific training. In this study, we
rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in
silico Type 1 diabetes simulator, comparing their zero-shot inference
performance against small neural network-based RL agents (SRAs) explicitly
trained for the task. Our results indicate that carefully designed zero-shot
prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or
superior clinical performance relative to extensively trained SRAs,
particularly in stable patient cohorts. However, LLMs exhibit notable
limitations, such as overly aggressive insulin dosing when prompted with
chain-of-thought (CoT) reasoning, highlighting critical failure modes including
arithmetic hallucination, temporal misinterpretation, and inconsistent clinical
logic. Incorporating explicit reasoning about latent clinical states (e.g.,
meals) yielded minimal performance gains, underscoring the current model's
limitations in capturing complex, hidden physiological dynamics solely through
textual inference. Our findings advocate for cautious yet optimistic
integration of LLMs into clinical workflows, emphasising the necessity of
targeted prompt engineering, careful validation, and potentially hybrid
approaches that combine linguistic reasoning with structured physiological
modelling to achieve safe, robust, and clinically effective decision-support
systems.

</details>


### [220] [HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation](https://arxiv.org/abs/2508.05135)
*Thinh Nguyen,Trung Phan,Binh T. Nguyen,Khoa D Doan,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 本论文提出了HFedDG场景和HFedATM方法，用于解决分层联邦学习中的域转移问题，通过滤波器对齐和正则化聚合来提升模型性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习（FL）和分层联邦学习（HFL）在面对大量客户端时面临可扩展性挑战，并且HFL在域偏移（数据分布不一致）问题上表现不佳。现有的联邦域泛化（FedDG）方法尚未很好地集成到HFL框架中。

Method: 提出了一种名为HFedATM的分层聚合方法，该方法首先通过滤波器最优传输对齐（Filter-wise Optimal Transport Alignment）来对齐不同站点模型的卷积滤波器，然后使用收缩感知正则化平均（Shrinkage-aware Regularized Mean Aggregation）来合并对齐后的模型。

Result: 实验证明，HFedATM在多个数据集上显著提升了现有FedDG基线方法的性能，并保持了计算和通信效率。理论分析表明，HFedATM比标准分层平均法具有更严格的泛化误差界限，从而实现了更快的收敛和更稳定的训练行为。

Conclusion: HFedDG是一个新的研究场景，旨在解决分层联邦学习中的域转移问题。HFedATM通过对齐模型滤波器和正则化平均聚合来提高模型性能和泛化能力。

Abstract: Federated Learning (FL) is a decentralized approach where multiple clients
collaboratively train a shared global model without sharing their raw data.
Despite its effectiveness, conventional FL faces scalability challenges due to
excessive computational and communication demands placed on a single central
server as the number of participating devices grows. Hierarchical Federated
Learning (HFL) addresses these issues by distributing model aggregation tasks
across intermediate nodes (stations), thereby enhancing system scalability and
robustness against single points of failure. However, HFL still suffers from a
critical yet often overlooked limitation: domain shift, where data
distributions vary significantly across different clients and stations,
reducing model performance on unseen target domains. While Federated Domain
Generalization (FedDG) methods have emerged to improve robustness to domain
shifts, their integration into HFL frameworks remains largely unexplored. In
this paper, we formally introduce Hierarchical Federated Domain Generalization
(HFedDG), a novel scenario designed to investigate domain shift within
hierarchical architectures. Specifically, we propose HFedATM, a hierarchical
aggregation method that first aligns the convolutional filters of models from
different stations through Filter-wise Optimal Transport Alignment and
subsequently merges aligned models using a Shrinkage-aware Regularized Mean
Aggregation. Our extensive experimental evaluations demonstrate that HFedATM
significantly boosts the performance of existing FedDG baselines across
multiple datasets and maintains computational and communication efficiency.
Moreover, theoretical analyses indicate that HFedATM achieves tighter
generalization error bounds compared to standard hierarchical averaging,
resulting in faster convergence and stable training behavior.

</details>


### [221] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu*

Main category: cs.LG

TL;DR: 该研究提出了F3CRec框架，以解决联邦学习和持续学习在推荐系统中的兼容性问题，并能在处理用户偏好演变的同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦推荐（FedRec）方法在处理非平稳数据流时遇到困难，导致推荐质量下降。而持续学习推荐（CLRec）方法虽然能处理用户偏好演变，但通常需要中心化数据访问，这与联邦学习（FL）的限制不兼容。为了解决这个问题，引入了联邦持续推荐（FCRec）任务，它需要在保护隐私的同时从流式数据中学习。

Method: 提出了一种名为F3CRec的框架，包含两个关键组件：客户端的自适应重放记忆（Adaptive Replay Memory），根据用户特定偏移量选择性地保留用户过去偏好；服务器端的项目时间平均（Item-wise Temporal Mean），在保留先验信息的同时整合新知识。

Result: 通过大量实验证明，F3CRec在联邦环境下保持推荐质量方面优于现有方法。

Conclusion: F3CRec框架在联邦环境下保持了推荐质量，并在各种实验中表现优于现有方法。

Abstract: The increasing emphasis on privacy in recommendation systems has led to the
adoption of Federated Learning (FL) as a privacy-preserving solution, enabling
collaborative training without sharing user data. While Federated
Recommendation (FedRec) effectively protects privacy, existing methods struggle
with non-stationary data streams, failing to maintain consistent recommendation
quality over time. On the other hand, Continual Learning Recommendation (CLRec)
methods address evolving user preferences but typically assume centralized data
access, making them incompatible with FL constraints. To bridge this gap, we
introduce Federated Continual Recommendation (FCRec), a novel task that
integrates FedRec and CLRec, requiring models to learn from streaming data
while preserving privacy. As a solution, we propose F3CRec, a framework
designed to balance knowledge retention and adaptation under the strict
constraints of FCRec. F3CRec introduces two key components: Adaptive Replay
Memory on the client side, which selectively retains past preferences based on
user-specific shifts, and Item-wise Temporal Mean on the server side, which
integrates new knowledge while preserving prior information. Extensive
experiments demonstrate that F3CRec outperforms existing approaches in
maintaining recommendation quality over time in a federated environment.

</details>


### [222] [X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment](https://arxiv.org/abs/2508.05568)
*Qinghua Yao,Xiangrui Xu,Zhize Li*

Main category: cs.LG

TL;DR: X-VFL 通过 XCom 和 DS-Align 模块解决了 VFL 的数据缺失和本地推理问题，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有垂直联邦学习（VFL）在数据样本不完全对齐（存在缺失特征）和不支持本地独立推理方面的两大挑战。

Method: 提出了一种名为 X-VFL 的新垂直联邦学习框架，包含两个关键模块：Cross Completion (XCom) 用于补全缺失特征，Decision Subspace Alignment (DS-Align) 用于对齐决策子空间中的特征，从而支持本地独立推理。

Result: X-VFL 在图像 CIFAR-10 数据集上准确率提升 15%，在医疗 MIMIC-III 数据集上准确率提升 43%。所提出的算法具有理论收敛性保证，SGD 类算法收敛率为 $O(1/\sqrt{T})$，PAGE 类算法收敛率为 $O(1/T)$。

Conclusion: X-VFL 框架通过 XCom 和 DS-Align 模块有效解决了 VFL 中数据不完全对齐和本地独立推理的挑战，并在真实世界数据集上取得了显著的性能提升，验证了其有效性和优越性。

Abstract: Vertical Federated Learning (VFL) enables collaborative learning by
integrating disjoint feature subsets from multiple clients/parties. However,
VFL typically faces two key challenges: i) the requirement for perfectly
aligned data samples across all clients (missing features are not allowed); ii)
the requirement for joint collaborative inference/prediction involving all
clients (it does not support locally independent inference on a single client).
To address these challenges, we propose X-VFL, a new VFL framework designed to
deal with the non-aligned data samples with (partially) missing features and to
support locally independent inference of new data samples for each client. In
particular, we design two novel modules in X-VFL: Cross Completion (XCom) and
Decision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing
features for non-aligned data samples by leveraging information from other
clients. DS-Align aligns local features with completed and global features
across all clients within the decision subspace, thus enabling locally
independent inference at each client. Moreover, we provide convergence theorems
for different algorithms used in training X-VFL, showing an $O(1/\sqrt{T})$
convergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type
algorithms, where $T$ denotes the number of training update steps. Extensive
experiments on real-world datasets demonstrate that X-VFL significantly
outperforms existing methods, e.g., achieving a 15% improvement in accuracy on
the image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III
dataset. These results validate the practical effectiveness and superiority of
X-VFL, particularly in scenarios involving partially missing features and
locally independent inference.

</details>


### [223] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [224] [RCUKF: Data-Driven Modeling Meets Bayesian Estimation](https://arxiv.org/abs/2508.04985)
*Kumar Anurag,Kasra Azizi,Francesco Sorrentino,Wenbin Wan*

Main category: cs.LG

TL;DR: A new RCUKF framework combines reservoir computing and unscented Kalman filtering to accurately model complex systems, outperforming traditional methods in high-dimensional and chaotic scenarios.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of complex systems is challenging, and existing methods often struggle with high-dimensional or chaotic systems. The paper aims to address this by developing a robust modeling framework.

Method: The paper proposes a novel framework called Reservoir Computing with Unscented Kalman Filtering (RCUKF), which combines data-driven modeling via Reservoir Computing (RC) with Bayesian estimation through the Unscented Kalman Filter (UKF). The RC model learns system dynamics from data, and the UKF uses this model for prediction and real-time sensor data for correction.

Result: RCUKF demonstrated effectiveness on benchmark problems and a real-time vehicle trajectory estimation task, showing its capability in handling complex dynamics and real-world applications.

Conclusion: RCUKF can effectively learn nonlinear system dynamics and provide accurate state estimates, even in high-dimensional or chaotic systems where traditional models fail.

Abstract: Accurate modeling is crucial in many engineering and scientific applications,
yet obtaining a reliable process model for complex systems is often
challenging. To address this challenge, we propose a novel framework, reservoir
computing with unscented Kalman filtering (RCUKF), which integrates data-driven
modeling via reservoir computing (RC) with Bayesian estimation through the
unscented Kalman filter (UKF). The RC component learns the nonlinear system
dynamics directly from data, serving as a surrogate process model in the UKF
prediction step to generate state estimates in high-dimensional or chaotic
regimes where nominal mathematical models may fail. Meanwhile, the UKF
measurement update integrates real-time sensor data to correct potential drift
in the data-driven model. We demonstrate RCUKF effectiveness on well-known
benchmark problems and a real-time vehicle trajectory estimation task in a
high-fidelity simulation environment.

</details>


### [225] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
*Robert Frenken,Sidra Ghayour Bhatti,Hanqin Zhang,Qadeer Ahmed*

Main category: cs.LG

TL;DR: 本研究提出了一种创新的多阶段入侵检测框架，结合了VGAE和KD-GAT技术，有效提高了汽车CAN流量的网络安全性，并在多个基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 控制器局域网（CAN）协议缺乏内置安全性，容易受到网络攻击，因此需要一种有效的入侵检测方法。

Method: 该框架首先使用VGAE进行结构异常检测和类别不平衡处理，然后使用KD-GAT进行攻击分类，并通过可选的得分级融合来提高鲁棒性。

Result: 该框架在六个公共CAN入侵检测数据集上进行了实验，平均F1分数比现有方法提高了16.2%，尤其在高度不平衡的数据集上表现出色，F1分数提升高达55%。

Conclusion: 该研究提出了一种结合变分图自编码器（VGAE）和知识蒸馏图注意力网络（KD-GAT）的多阶段入侵检测框架，用于汽车CAN流量的网络安全。

Abstract: The Controller Area Network (CAN) protocol is a standard for in-vehicle
communication but remains susceptible to cyber-attacks due to its lack of
built-in security. This paper presents a multi-stage intrusion detection
framework leveraging unsupervised anomaly detection and supervised graph
learning tailored for automotive CAN traffic. Our architecture combines a
Variational Graph Autoencoder (VGAE) for structural anomaly detection with a
Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack
classification. CAN bus activity is encoded as graph sequences to model
temporal and relational dependencies. The pipeline applies VGAE-based selective
undersampling to address class imbalance, followed by GAT classification with
optional score-level fusion. The compact student GAT achieves 96% parameter
reduction compared to the teacher model while maintaining strong predictive
performance. Experiments on six public CAN intrusion datasets--Car-Hacking,
Car-Survival, and can-train-and-test--demonstrate competitive accuracy and
efficiency, with average improvements of 16.2% in F1-score over existing
methods, particularly excelling on highly imbalanced datasets with up to 55%
F1-score improvements.

</details>


### [226] [Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction](https://arxiv.org/abs/2508.05210)
*Saddam Hussain Khan*

Main category: cs.LG

TL;DR: 使用LSTM、Transformer编码器、TS-Mixer块和注意力机制的混合深度学习模型可提高钻井速度预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以捕捉钻井数据的复杂时间、动态和高维特性，导致预测不佳且实时效用有限。

Method: 提出了一种新颖的混合深度学习架构，该架构整合了长短期记忆（LSTM）网络、Transformer编码器、时间序列混合（TS-Mixer）块和注意力机制，以协同模拟时间依赖性、静态特征交互、全局上下文和动态特征重要性。

Result: 在真实钻井数据集上评估，该模型优于基准模型（独立的LSTM、TS-Mixer和简单的混合模型），R方得分为0.9988，平均绝对百分比误差为1.447%。

Conclusion: 该混合深度学习模型能够可靠地进行实时ROP预测，为智能、经济高效的钻井优化系统铺平了道路，并具有重大的运营影响。

Abstract: The Rate of Penetration (ROP) is crucial for optimizing drilling operations;
however, accurately predicting it is hindered by the complex, dynamic, and
high-dimensional nature of drilling data. Traditional empirical, physics-based,
and basic machine learning models often fail to capture intricate temporal and
contextual relationships, resulting in suboptimal predictions and limited
real-time utility. To address this gap, we propose a novel hybrid deep learning
architecture integrating Long Short-Term Memory (LSTM) networks, Transformer
encoders, Time-Series Mixer (TS-Mixer) blocks, and attention mechanisms to
synergistically model temporal dependencies, static feature interactions,
global context, and dynamic feature importance. Evaluated on a real-world
drilling dataset, our model outperformed benchmarks (standalone LSTM, TS-Mixer,
and simpler hybrids) with an R-squared score of 0.9988 and a Mean Absolute
Percentage Error of 1.447%, as measured by standard regression metrics
(R-squared, MAE, RMSE, MAPE). Model interpretability was ensured using SHAP and
LIME, while actual vs. predicted curves and bias checks confirmed accuracy and
fairness across scenarios. This advanced hybrid approach enables reliable
real-time ROP prediction, paving the way for intelligent, cost-effective
drilling optimization systems with significant operational impact.

</details>


### [227] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
*Aleksander Boruch-Gruszecki,Yangtian Zi,Zixuan Wu,Tejas Oberoi,Carolyn Jane Anderson,Joydeep Biswas,Arjun Guha*

Main category: cs.LG

TL;DR: Agnostics 是一个语言不可知的大型语言模型后训练框架，它通过统一的验证器和可验证的奖励来简化低资源语言的训练。该方法在 Lua、Julia、R、OCaml 和 Fortran 等语言上显著提升了模型性能，并设定了新的行业标准，同时使未来的多语言模型训练更加便捷。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）虽然在 Python 和 JavaScript 等高资源语言方面表现出色，但在科学和工程领域至关重要的低资源语言方面却存在不足。造成这一问题的原因不仅在于预训练数据的稀缺，还在于后训练过程的瓶颈：每增加一门新语言似乎都需要一套全新的数据集、测试工具和强化学习（RL）基础设施。

Method: Agnostics 采用一种语言不可知的方法进行后训练。该方法的核心在于仅根据代码的外部可观察行为来评估其质量，从而允许使用单一的验证器来测试任何语言编写的解决方案。具体步骤包括：1. 使用大型语言模型将现有的单元测试数据集转换为 I/O 格式。2. 提供简短的配置文件，指导验证器如何编译和运行目标语言的代码。3. 在一个稳健的代码执行环境中，利用可验证的奖励（RLVR）进行强化学习。

Result: Agnostics 方法在五种低资源语言（Lua、Julia、R、OCaml 和 Fortran）上的应用取得了显著成果：1. 将 Qwen-3 4B 模型的性能提升至可与 16B-70B 参数的其他开源模型相媲美的水平。2. 能够轻松扩展以支持更大和更多样化的模型家族，包括 Qwen-3 8B、DeepSeek Coder 6.7B Instruct 和 Phi 4 Mini。3. 对于参数量小于等于 16B 的模型，在 MultiPL-E 和新引入的多语言基准测试 LiveCodeBench 上取得了新的最优 pass@1 结果。

Conclusion: Agnostics 旨在通过其语言不可知性来简化和改进针对低资源编程语言的大型语言模型的训练过程。该方法通过外部可观察行为评估代码，并使用统一的验证器来处理不同语言。通过将此方法应用于 Lua、Julia、R、OCaml 和 Fortran 等五种语言，Agnostics 显著提高了 Qwen-3 4B 模型的性能，使其能够与更大、更成熟的模型相媲美。此外，Agnostics 还能有效地扩展到不同的模型家族，并为参数量小于等于 16B 的模型设定了 MultiPL-E 和新的 LiveCodeBench 基准测试的最优 pass@1 结果。研究团队将公开 Agnostics 的训练数据集、代码和配置文件，旨在使任何编程语言的 RL 后训练过程变得像编辑 YAML 文件一样简单。

Abstract: Large language models (LLMs) already excel at writing code in high-resource
languages such as Python and JavaScript, yet stumble on low-resource languages
that remain essential to science and engineering. Besides the obvious shortage
of pre-training data, post-training itself is a bottleneck: every new language
seems to require new datasets, test harnesses, and reinforcement-learning (RL)
infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that
eliminates this per-language engineering. The key idea is to judge code solely
by its externally observable behavior, so a single verifier can test solutions
written in any language. Concretely, we (i) use an LLM to rewrite existing
unit-test datasets into an I/O format, (ii) supply a short configuration that
tells the verifier how to compile and run a target language, and (iii) apply
reinforcement learning with verifiable rewards (RLVR) in a robust code
execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and
Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other
16B-70B open-weight models; (2) scales cleanly to larger and diverse model
families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for
${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on
MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X,
Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use
configurations, making RL post-training in any programming language as simple
as editing a short YAML file.

</details>


### [228] [Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain](https://arxiv.org/abs/2508.04882)
*Saman Pordanesh,Pejman Shahsavari,Hossein Ghadjari*

Main category: cs.LG

TL;DR: HNO是一种新的神经算子架构，它使用希尔伯特变换来提取瞬时幅度和相位信息，以更有效地为因果、对相位敏感和非平稳系统建模算子。


<details>
  <summary>Details</summary>
Motivation: 为了解决FNO的局限性，例如傅立叶变换的周期性假设，并利用信号处理的归纳偏倚。

Method: HNO通过希尔伯特变换将输入信号映射到其解析表示，然后在希尔伯特变换后的表示上应用谱卷积。

Result: HNO能够通过显化瞬时幅度和相位信息来更有效地为因果、对相位敏感和非平稳系统建模算子。

Conclusion: HNO架构能够更有效地为因果、对相位敏感和非平稳系统建模算子。

Abstract: Neural operators have emerged as a powerful, data-driven paradigm for
learning solution operators of partial differential equations (PDEs).
State-of-the-art architectures, such as the Fourier Neural Operator (FNO), have
achieved remarkable success by performing convolutions in the frequency domain,
making them highly effective for a wide range of problems. However, this method
has some limitations, including the periodicity assumption of the Fourier
transform. In addition, there are other methods of analysing a signal, beyond
phase and amplitude perspective, and provide us with other useful information
to learn an effective network. We introduce the \textbf{Hilbert Neural Operator
(HNO)}, a new neural operator architecture to address some advantages by
incorporating a strong inductive bias from signal processing. HNO operates by
first mapping the input signal to its analytic representation via the Hilbert
transform, thereby making instantaneous amplitude and phase information
explicit features for the learning process. The core learnable operation -- a
spectral convolution -- is then applied to this Hilbert-transformed
representation. We hypothesize that this architecture enables HNO to model
operators more effectively for causal, phase-sensitive, and non-stationary
systems. We formalize the HNO architecture and provide the theoretical
motivation for its design, rooted in analytic signal theory.

</details>


### [229] [Gaussian mixture layers for neural networks](https://arxiv.org/abs/2508.04883)
*Sinho Chewi,Philippe Rigollet,Yuling Yan*

Main category: cs.LG

TL;DR: This paper introduces Gaussian mixture (GM) layers, which implement dynamics over probability measures using Wasserstein gradient flows. These layers show comparable performance to traditional layers on classification tasks but exhibit distinct behaviors, even in large networks.


<details>
  <summary>Details</summary>
Motivation: The paper investigates the applicability of mean-field theory for two-layer neural networks, which considers infinitely wide networks, to networks of moderate width by exploring the opposite direction: implementing dynamics directly over probability measures.

Method: This work explores implementing dynamics directly over probability measures using Gaussian mixture models and Wasserstein gradient flows to derive training dynamics. A new type of layer, the Gaussian mixture (GM) layer, is introduced.

Result: Experiments on simple classification tasks show that GM layers achieve test performance comparable to two-layer fully connected networks. Numerical analysis demonstrates that GM layers exhibit markedly different behavior compared to classical fully connected layers.

Conclusion: Gaussian mixture (GM) layers can be integrated into neural network architectures and achieve test performance comparable to two-layer fully connected networks on simple classification tasks. GM layers exhibit markedly different behavior compared to classical fully connected layers, even in the mean-field regime.

Abstract: The mean-field theory for two-layer neural networks considers infinitely wide
networks that are linearly parameterized by a probability measure over the
parameter space. This nonparametric perspective has significantly advanced both
the theoretical and conceptual understanding of neural networks, with
substantial efforts made to validate its applicability to networks of moderate
width. In this work, we explore the opposite direction, investigating whether
dynamics can be directly implemented over probability measures. Specifically,
we employ Gaussian mixture models as a flexible and expressive parametric
family of distributions together with the theory of Wasserstein gradient flows
to derive training dynamics for such measures. Our approach introduces a new
type of layer -- the Gaussian mixture (GM) layer -- that can be integrated into
neural network architectures. As a proof of concept, we validate our proposal
through experiments on simple classification tasks, where a GM layer achieves
test performance comparable to that of a two-layer fully connected network.
Furthermore, we examine the behavior of these dynamics and demonstrate
numerically that GM layers exhibit markedly different behavior compared to
classical fully connected layers, even when the latter are large enough to be
considered in the mean-field regime.

</details>


### [230] [Uncertainty Quantification for Surface Ozone Emulators using Deep Learning](https://arxiv.org/abs/2508.04885)
*Kelsey Doerksen,Yuliya Marchetti,Steven Lu,Kevin Bowman,James Montgomery,Kazuyuki Miyazaki,Yarin Gal,Freddie Kalaitzis*

Main category: cs.LG

TL;DR: 深度学习模型用于预测臭氧偏差，并提供不确定性量化，以支持公共卫生政策。


<details>
  <summary>Details</summary>
Motivation: 传统的基于物理的模型在模拟地表臭氧及其趋势方面存在局限性，难以满足与人类健康影响相关的尺度需求。深度学习模型虽然有潜力，但缺乏可解释性，难以支持公共政策决策。

Method: 本研究采用不确定性感知的U-Net架构，并结合贝叶斯和分位数回归方法来预测MOMO-Chem模型的地表臭氧残差（偏差）。

Result: 研究展示了所提出技术在北美和欧洲区域估计MOMO-Chem模型地表臭氧偏差的能力，并对两种不确定性量化方法进行了比较，确定了MOMO-Chem偏差校优选和次优的地面站点，同时评估了土地利用信息对地表臭氧残差建模的影响。

Conclusion: 该研究使用不确定性感知的U-Net架构，结合贝叶斯和分位数回归方法，对MOMO-Chem模型的地表臭氧残差（偏差）进行了区域估计，展示了其在北美和欧洲的应用能力，并评估了土地利用信息的影响，为地面站点优化和偏差校正提供了依据。

Abstract: Air pollution is a global hazard, and as of 2023, 94\% of the world's
population is exposed to unsafe pollution levels. Surface Ozone (O3), an
important pollutant, and the drivers of its trends are difficult to model, and
traditional physics-based models fall short in their practical use for scales
relevant to human-health impacts. Deep Learning-based emulators have shown
promise in capturing complex climate patterns, but overall lack the
interpretability necessary to support critical decision making for policy
changes and public health measures. We implement an uncertainty-aware U-Net
architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data
assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian
and quantile regression methods. We demonstrate the capability of our
techniques in regional estimation of bias in North America and Europe for June
2019. We highlight the uncertainty quantification (UQ) scores between our two
UQ methodologies and discern which ground stations are optimal and sub-optimal
candidates for MOMO-Chem bias correction, and evaluate the impact of land-use
information in surface ozone residual modeling.

</details>


### [231] [Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates](https://arxiv.org/abs/2508.04886)
*Kelsey Doerksen,Yuliya Marchetti,Kevin Bowman,Steven Lu,James Montgomery,Yarin Gal,Freddie Kalaitzis,Kazuyuki Miyazaki*

Main category: cs.LG

TL;DR: 这项研究使用卷积神经网络来改进地表臭氧的模型估算，以应对空气污染问题，并讨论了其对环境政策的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 空气污染是全球最大的环境风险因素，尤其是在地表臭氧方面，其对人类健康的影响尚不清楚，限制了基于物理的模型在相关尺度上的应用。

Method: 我们采用基于 2D 卷积神经网络的架构来估计地表臭氧的 MOMO-Chem 模型残差（模型偏差）。

Result: 我们的研究证明了该技术在北美和欧洲的潜力，相比传统的机器学习方法，它能更好地捕捉物理模型的残差。我们还评估了整合高分辨率卫星图像的土地利用信息对改进模型估算的影响。

Conclusion: 该研究使用 2D 卷积神经网络来估计地表臭氧的 MOMO-Chem 模型残差，以解决空气污染对人类健康的影响，并展示了其在北美和欧洲的潜力，优于传统机器学习方法。

Abstract: Air pollution is the world's largest environmental risk factor for human
disease and premature death, resulting in more than 6 million permature deaths
in 2019. Currently, there is still a challenge to model one of the most
important air pollutants, surface ozone, particularly at scales relevant for
human health impacts, with the drivers of global ozone trends at these scales
largely unknown, limiting the practical use of physics-based models. We employ
a 2D Convolutional Neural Network based architecture that estimate surface
ozone MOMO-Chem model residuals, referred to as model bias. We demonstrate the
potential of this technique in North America and Europe, highlighting its
ability better to capture physical model residuals compared to a traditional
machine learning method. We assess the impact of incorporating land use
information from high-resolution satellite imagery to improve model estimates.
Importantly, we discuss how our results can improve our scientific
understanding of the factors impacting ozone bias at urban scales that can be
used to improve environmental policy.

</details>


### [232] [Retrieval-Augmented Water Level Forecasting for Everglades](https://arxiv.org/abs/2508.04888)
*Rahuul Rangaraj,Jimeng Shi,Rajendra Paudel,Giri Narasimhan,Yanzhao Wu*

Main category: cs.LG

TL;DR: 通过检索历史相似水文数据来增强预测模型，提高了水位预测的准确性，特别是在大沼泽地（Everglades）的应用中。


<details>
  <summary>Details</summary>
Motivation: 准确的水位预测对于管理如大沼泽地（Everglades）这样的生态系统至关重要，而现有的深度学习模型在跨不同数据集和领域泛化方面存在困难。为了解决这个问题，研究旨在将检索增强预测（RAF）方法引入水文学领域。

Method: 提出了一种名为检索增强预测（RAF）的框架，该框架通过维护一个外部历史观测数据库，识别并结合历史数据中相关的模式，以增强模型的上下文感知和预测准确性，而无需对模型进行特定任务的重新训练或微调。此外，研究还探索并比较了基于相似性和基于互信息的两种RAF方法。

Result: 在对大沼泽地（Everglades）的真实世界数据进行全面评估后，RAF框架在水位预测准确性方面取得了显著的改进。

Conclusion: 本研究将检索增强预测（RAF）框架应用于水文学领域，通过检索历史相似的水文数据来丰富模型输入，从而提高水位预测的准确性，并证明了RAF在环境水文学中的潜力。

Abstract: Accurate water level forecasting is crucial for managing ecosystems such as
the Everglades, a subtropical wetland vital for flood mitigation, drought
management, water resource planning, and biodiversity conservation. While
recent advances in deep learning, particularly time series foundation models,
have demonstrated success in general-domain forecasting, their application in
hydrology remains underexplored. Furthermore, they often struggle to generalize
across diverse unseen datasets and domains, due to the lack of effective
mechanisms for adaptation. To address this gap, we introduce
Retrieval-Augmented Forecasting (RAF) into the hydrology domain, proposing a
framework that retrieves historically analogous multivariate hydrological
episodes to enrich the model input before forecasting. By maintaining an
external archive of past observations, RAF identifies and incorporates relevant
patterns from historical data, thereby enhancing contextual awareness and
predictive accuracy without requiring the model for task-specific retraining or
fine-tuning. Furthermore, we explore and compare both similarity-based and
mutual information-based RAF methods. We conduct a comprehensive evaluation on
real-world data from the Everglades, demonstrating that the RAF framework
yields substantial improvements in water level forecasting accuracy. This study
highlights the potential of RAF approaches in environmental hydrology and paves
the way for broader adoption of adaptive AI methods by domain experts in
ecosystem management. The code and data are available at
https://github.com/rahuul2992000/WaterRAF.

</details>


### [233] [Honest and Reliable Evaluation and Expert Equivalence Testing of Automated Neonatal Seizure Detection](https://arxiv.org/abs/2508.04899)
*Jovana Kljajic,John M. O'Toole,Robert Hogan,Tamara Skoric*

Main category: cs.LG

TL;DR: 由于当前儿科癫痫检测AI模型评估指标的不一致和有偏见，本研究提出了一套最佳实践，包括使用平衡指标、敏感性、特异性、PPV、NPV和多评分者图灵测试（使用Fleiss kappa）来更可靠地评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了在临床上推广机器学习模型，可靠地评估儿科癫痫检测模型至关重要。然而，当前的实践常常依赖于不一致且有偏见的指标，这阻碍了模型的可比性和可解释性。专家声称的AI性能常常缺乏严格的验证，这引发了对其可靠性的担忧。因此，有必要系统地评估常用的性能指标，并提出针对儿科癫痫检测特定挑战的最佳实践。

Method: 本研究系统地评估了常用的性能指标、共识策略以及人类专家水平的等效性测试，同时考虑了类别不平衡、评分者间一致性和评分者数量的可变性。评估了包括马修斯和皮尔逊相关系数在内的指标，并与AUC进行了比较，还研究了不同共识类型对评分者数量和一致性水平的敏感性。此外，还评估了多评分者图灵测试（使用Fleiss kappa）和人类专家水平等效性测试。

Result: 研究结果显示，在类别不平衡的情况下，马修斯和皮尔逊相关系数的表现优于AUC。共识类型指标对评分者数量和评分者之间的一致性水平敏感。在人类专家水平等效性测试中，使用Fleiss kappa的多评分者图灵测试最能准确地捕捉专家水平的AI性能。研究建议报告至少一种平衡指标、敏感性、特异性、PPV和NPV、使用Fleiss kappa的多评分者图灵测试结果，以及在预留验证集上的所有上述指标。

Conclusion: 该研究提出的框架为评估儿科癫痫检测AI方法提供了重要先决条件，能够实现对其进行全面和诚实的评估。

Abstract: Reliable evaluation of machine learning models for neonatal seizure detection
is critical for clinical adoption. Current practices often rely on inconsistent
and biased metrics, hindering model comparability and interpretability.
Expert-level claims about AI performance are frequently made without rigorous
validation, raising concerns about their reliability. This study aims to
systematically evaluate common performance metrics and propose best practices
tailored to the specific challenges of neonatal seizure detection. Using real
and synthetic seizure annotations, we assessed standard performance metrics,
consensus strategies, and human-expert level equivalence tests under varying
class imbalance, inter-rater agreement, and number of raters. Matthews and
Pearson's correlation coefficients outperformed the area under the curve in
reflecting performance under class imbalance. Consensus types are sensitive to
the number of raters and agreement level among them. Among human-expert level
equivalence tests, the multi-rater Turing test using Fleiss k best captured
expert-level AI performance. We recommend reporting: (1) at least one balanced
metric, (2) Sensitivity, specificity, PPV and NPV, (3) Multi-rater Turing test
results using Fleiss k, and (4) All the above on held-out validation set. This
proposed framework provides an important prerequisite to clinical validation by
enabling a thorough and honest appraisal of AI methods for neonatal seizure
detection.

</details>


### [234] [Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning](https://arxiv.org/abs/2508.04901)
*Prabhav Singh,Jessica Sorrell*

Main category: cs.LG

TL;DR: 迁移学习的可靠性，特别是自适应数据选择策略，对模型结果的一致性至关重要。本研究提出了一个量化这种权衡的框架，并发现高度自适应的策略会牺牲可复现性，但可以通过源域预训练来缓解。


<details>
  <summary>Details</summary>
Motivation: 理解迁移学习中适应的可靠性，特别是当使用动态化优先化训练样本的自适应数据选择策略时。

Method: 提出一个数学框架，量化适应性与结果一致性之间的基本权衡，并引入选择敏感性（Δ_Q）作为衡量自适应选择策略对训练数据扰动的响应程度的指标。

Result: 理论和实证分析表明，可复现性失败概率随选择敏感性呈二次方增加，随样本量呈指数级减少。梯度选择和课程学习等高度自适应策略在任务性能上表现更优，但可复现性失败率较高（低于7%），而适应性较低的方法则保持了较低的失败率。源域预训练可将失败率降低高达30%，同时保持性能增益。 tldr: 迁移学习的可靠性，特别是自适应数据选择策略，对模型结果的一致性至关重要。本研究提出了一个量化这种权衡的框架，并发现高度自适应的策略会牺牲可复现性，但可以通过源域预训练来缓解。 结论：该研究为实践者提供了应对性能-可复现性权衡的原则性指导，并强调了在现代迁移学习系统中进行可复现性感知设计的重要性。研究结果表明，源域预训练是降低失败率（最高可达30%）同时保持性能提升的有效机制。

Conclusion: 该研究为实践者提供了应对性能-可复现性权衡的原则性指导，并强调了在现代迁移学习系统中进行可复现性感知设计的重要性。研究结果表明，源域预训练是降低失败率（最高可达30%）同时保持性能提升的有效机制。

Abstract: The widespread adoption of transfer learning has revolutionized machine
learning by enabling efficient adaptation of pre-trained models to new domains.
However, the reliability of these adaptations remains poorly understood,
particularly when using adaptive data selection strategies that dynamically
prioritize training examples. We present a comprehensive theoretical and
empirical analysis of replicability in transfer learning, introducing a
mathematical framework that quantifies the fundamental trade-off between
adaptation effectiveness and result consistency. Our key contribution is the
formalization of selection sensitivity ($\Delta_Q$), a measure that captures
how adaptive selection strategies respond to perturbations in training data. We
prove that replicability failure probability: the likelihood that two
independent training runs produce models differing in performance by more than
a threshold, increases quadratically with selection sensitivity while
decreasing exponentially with sample size. Through extensive experiments on the
MultiNLI corpus using six adaptive selection strategies - ranging from uniform
sampling to gradient-based selection - we demonstrate that this theoretical
relationship holds precisely in practice. Our results reveal that highly
adaptive strategies like gradient-based and curriculum learning achieve
superior task performance but suffer from high replicability failure rates,
while less adaptive approaches maintain failure rates below 7%. Crucially, we
show that source domain pretraining provides a powerful mitigation mechanism,
reducing failure rates by up to 30% while preserving performance gains. These
findings establish principled guidelines for practitioners to navigate the
performance-replicability trade-off and highlight the need for
replicability-aware design in modern transfer learning systems.

</details>


### [235] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: The study explores transformer-based models for hate speech detection using the MetaHate dataset, with fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). Challenges with sarcasm, coded language, and label noise were also identified.


<details>
  <summary>Details</summary>
Motivation: Hate speech is a widespread and harmful form of online discourse that has increasingly been linked to real-world hate crimes. Addressing this issue requires the development of robust automated methods to detect hate speech in diverse social media environments.

Method: This study represents the comprehensive exploration of transformer-based models for hate speech detection using the MetaHate dataset--a meta-collection of 36 datasets with 1.2 million social media samples. We evaluate multiple state-of-the-art transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA.

Result: Fine-tuned ELECTRA achieved the highest performance (F1 score: 0.8980).

Conclusion: Fine-tuned ELECTRA achieved the highest performance (F1 score: 0.8980), and the study also analyzes classification errors, revealing challenges with sarcasm, coded language, and label noise.

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [236] [ALScope: A Unified Toolkit for Deep Active Learning](https://arxiv.org/abs/2508.04937)
*Chenkai Wu,Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Gang Liu,Wray Buntine,Lan Du*

Main category: cs.LG

TL;DR: 本文提出了ALScope，一个用于评估深度主动学习（DAL）算法的统一平台，包含10个CV/NLP数据集和21个算法。实验发现，DAL算法在不同场景下的表现差异很大，在处理不平衡和开放集问题时仍有改进空间，且部分算法的效率不高。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界应用日益复杂，分布偏移（如开放集识别）和数据不平衡等挑战受到越来越多的关注，推动了多种DAL算法的发展。然而，缺乏一个统一的评估平台阻碍了在多样化条件下进行公平和系统性评估。因此，本文旨在构建一个名为ALScope的平台，以解决这一问题，促进对DAL算法在不同场景下表现的深入理解和公平比较。

Method: 本文提出了一个名为ALScope的深度主动学习（DAL）评估平台，该平台集成了10个来自计算机视觉（CV）和自然语言处理（NLP）的数据集，以及21个代表性的DAL算法。ALScope支持用户灵活配置实验参数，包括算法选择、数据集选择以及特定任务的因素，如分布外（OOD）样本比例和类别不平衡比例。通过在该平台上进行广泛的实验，研究者考察了不同设置下DAL算法的性能表现。

Result: 1. DAL算法在不同领域和任务设置下的性能表现存在显著差异。 2. 在不平衡和开放集等非标准场景下，DAL算法的表现有待提升，需要进一步研究。 3. 一些算法虽然性能优异，但选择时间成本较高。

Conclusion: 所提出的ALScope平台为深度主动学习（DAL）在计算机视觉（CV）和自然语言处理（NLP）领域的分类任务提供了一个统一、灵活且可扩展的评估框架。实验结果表明，DAL算法在不同领域和任务设置下的表现存在显著差异，尤其在处理分布偏移（如开放集识别）和数据不平衡等非标准场景时，现有算法仍有较大提升空间。此外，一些表现优异的算法需要更长的选择时间，这提示了未来研究需要在性能和效率之间进行权衡。

Abstract: Deep Active Learning (DAL) reduces annotation costs by selecting the most
informative unlabeled samples during training. As real-world applications
become more complex, challenges stemming from distribution shifts (e.g.,
open-set recognition) and data imbalance have gained increasing attention,
prompting the development of numerous DAL algorithms. However, the lack of a
unified platform has hindered fair and systematic evaluation under diverse
conditions. Therefore, we present a new DAL platform ALScope for classification
tasks, integrating 10 datasets from computer vision (CV) and natural language
processing (NLP), and 21 representative DAL algorithms, including both
classical baselines and recent approaches designed to handle challenges such as
distribution shifts and data imbalance. This platform supports flexible
configuration of key experimental factors, ranging from algorithm and dataset
choices to task-specific factors like out-of-distribution (OOD) sample ratio,
and class imbalance ratio, enabling comprehensive and realistic evaluation. We
conduct extensive experiments on this platform under various settings. Our
findings show that: (1) DAL algorithms' performance varies significantly across
domains and task settings; (2) in non-standard scenarios such as imbalanced and
open-set settings, DAL algorithms show room for improvement and require further
investigation; and (3) some algorithms achieve good performance, but require
significantly longer selection time.

</details>


### [237] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: 介绍了一种名为REINA的新损失函数，用于提高SimulST系统的翻译质量和速度的平衡，并在多个语种上实现了最先进的流式传输结果。


<details>
  <summary>Details</summary>
Motivation: SimulST系统需要平衡翻译质量和延迟，这带来了重大挑战。

Method: 提出了一种名为REINA（Regularized Entropy INformation Adaptation）的损失函数，该函数基于信息论原理，用于训练自适应策略。使用REINA，在法语、西班牙语和德语之间以及与英语之间训练SimulST模型。

Result: REINA有助于推动延迟/质量权衡的帕累托前沿。使用REINA训练的SimulST模型在仅使用开源或合成数据的情况下，在可比大小的模型上实现了最先进的流式传输结果。提出的流式传输效率指标在量化上表明，与先前的方法相比，REINA将延迟/质量权衡提高了21%。

Conclusion: SimulST系统在平衡翻译质量和延迟方面面临重大挑战。REINA是一种新的损失函数，可以训练一个自适应策略，该策略基于“只有在获得更多信息时才等待更多输入”的策略。

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [238] [Self-Error Adjustment: Theory and Practice of Balancing Individual Performance and Diversity in Ensemble Learning](https://arxiv.org/abs/2508.04948)
*Rui Zou*

Main category: cs.LG

TL;DR: SEA是一种新的集成学习框架，通过分解误差并引入可调参数来精确控制准确性-多样性权衡，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的集成学习方法（如Bagging、Boosting和负相关学习NCL）在平衡个体学习器准确性与多样性方面存在不足，缺乏精确控制准确性-多样性权衡的能力或理论界限松散、调整范围有限。

Method: 提出了一种名为自误差调整（SEA）的新框架，通过将集成误差分解为个体学习器性能项和学习器之间交互的项，并引入一个可调参数到损失函数中，以精确控制每个组成部分的贡献，从而实现对集成性能的更精细调节。

Result: SEA框架提供了比NCL及其变体更广泛的有效调整范围和更一致的多样性变化，并建立了可调集成方法的更紧密理论界限。

Conclusion: SEA框架在回归和分类任务上均优于基线方法，并且在细化调整策略方面表现出更灵活的调整能力和更优越的性能。

Abstract: Ensemble learning boosts performance by aggregating predictions from multiple
base learners. A core challenge is balancing individual learner accuracy with
diversity. Traditional methods like Bagging and Boosting promote diversity
through randomness but lack precise control over the accuracy-diversity
trade-off. Negative Correlation Learning (NCL) introduces a penalty to manage
this trade-off but suffers from loose theoretical bounds and limited adjustment
range. To overcome these limitations, we propose a novel framework called
Self-Error Adjustment (SEA), which decomposes ensemble errors into two distinct
components: individual performance terms, representing the self-error of each
base learner, and diversity terms, reflecting interactions among learners. This
decomposition allows us to introduce an adjustable parameter into the loss
function, offering precise control over the contribution of each component,
thus enabling finer regulation of ensemble performance. Compared to NCL and its
variants, SEA provides a broader range of effective adjustments and more
consistent changes in diversity. Furthermore, we establish tighter theoretical
bounds for adjustable ensemble methods and validate them through empirical
experiments. Experimental results on several public regression and
classification datasets demonstrate that SEA consistently outperforms baseline
methods across all tasks. Ablation studies confirm that SEA offers more
flexible adjustment capabilities and superior performance in fine-tuning
strategies.

</details>


### [239] [Compressed Decentralized Momentum Stochastic Gradient Methods for Nonconvex Optimization](https://arxiv.org/abs/2508.04950)
*Wei Liu,Anweshit Panda,Ujwal Pandey,Christopher Brissette,Yikang Shen,George M. Slota,Naigang Wang,Jie Chen,Yangyang Xu*

Main category: cs.LG

TL;DR: 本文提出两种压缩型去中心化算法，分别用于梯度有限和数据异质性场景，解决了在去中心化算法中结合动量和压缩通信的挑战，实现了最优收敛速度、线性加速和拓扑无关的参数，并在实际应用中表现优越。


<details>
  <summary>Details</summary>
Motivation: 在去中心化算法中，将动量技术和压缩通信技术相结合，同时控制共识误差、压缩误差和动量梯度偏差，以理论上证明其有效性并兼顾两者的优势，这是一项具有挑战性的工作。

Method: 本文设计了两种压缩型去中心化算法来解决非凸随机优化问题。一种是针对梯度有限场景的压缩型去中心化自适应方法，另一种是针对数据异质性且梯度无界场景的压缩型去中心化 heavy-ball 方法，该方法采用梯度跟踪技术来解决数据异质性问题。

Result: 所提出的两种方法在训练深度神经网络（DNN）和 Transformer 时，相比现有最先进的方法，都表现出了优越的经验性能。

Conclusion: 本文提出的压缩型去中心化自适应方法和压缩型去中心化 heavy-ball 方法均实现了最优收敛速度，并且在一定用户指定的误差容限范围内，能够实现线性加速并采用与拓扑无关的算法参数。

Abstract: In this paper, we design two compressed decentralized algorithms for solving
nonconvex stochastic optimization under two different scenarios. Both
algorithms adopt a momentum technique to achieve fast convergence and a
message-compression technique to save communication costs. Though momentum
acceleration and compressed communication have been used in literature, it is
highly nontrivial to theoretically prove the effectiveness of their composition
in a decentralized algorithm that can maintain the benefits of both sides,
because of the need to simultaneously control the consensus error, the
compression error, and the bias from the momentum gradient.
  For the scenario where gradients are bounded, our proposal is a compressed
decentralized adaptive method. To the best of our knowledge, this is the first
decentralized adaptive stochastic gradient method with compressed
communication. For the scenario of data heterogeneity without bounded
gradients, our proposal is a compressed decentralized heavy-ball method, which
applies a gradient tracking technique to address the challenge of data
heterogeneity. Notably, both methods achieve an optimal convergence rate, and
they can achieve linear speed up and adopt topology-independent algorithmic
parameters within a certain regime of the user-specified error tolerance.
Superior empirical performance is observed over state-of-the-art methods on
training deep neural networks (DNNs) and Transformers.

</details>


### [240] [MENDR: Manifold Explainable Neural Data Representations](https://arxiv.org/abs/2508.04956)
*Matthew Chen,Micky Nnamdi,Justin Shao,Andrew Hornback,Hongyun Huang,Ben Tamo,Yishan Zhong,Benoit Marteau,Wenqi Shi,May Dongmei Wang*

Main category: cs.LG

TL;DR: MENDR是一种创新的EEG基础模型，它通过黎曼流形Transformer和可解释的嵌入（可视化为几何椭球）解决了现有模型的透明度和可解释性问题。该模型在大量EEG数据上进行预训练，并在多项临床任务中取得了优于参数效率的成果。


<details>
  <summary>Details</summary>
Motivation: 当前的EEG基础模型在预训练动态方面缺乏透明度，并且对其嵌入中EEG信息的保留程度了解有限。为了成功进行临床整合，EEG基础模型必须确保预训练、下游微调和学习表征的可解释性。现有方法主要在时间域操作，忽视了数字信号处理领域的进展，例如小波变换等确定性和可追溯特征的提取。

Method: 提出了一种名为MENDR（流形可解释神经数据表示）的基于滤波器组的EEG基础模型，该模型建立在新颖的黎曼流形Transformer架构之上。MENDR学习EEG信号的对称正定矩阵嵌入，并在包含超过4000小时EEG数据的大型语料库上进行预训练，该语料库通过离散小波包变换分解为多分辨率系数。MENDR通过将对称正定嵌入可视化为几何椭球来显著增强可解释性，并支持从学习的嵌入中准确重建EEG信号。

Result: MENDR在多个临床EEG任务上的评估表明，其性能接近最先进水平，但参数量却大大减少，并且能够从学习的嵌入中准确重建EEG信号。

Conclusion: MENDR通过其基于流形的可解释神经数据表示，在临床EEG任务中实现了接近最先进的性能，同时参数量大大减少，展示了其在高效、可解释和临床适用EEG分析方面的潜力。

Abstract: Foundation models for electroencephalography (EEG) signals have recently
demonstrated success in learning generalized representations of EEGs,
outperforming specialized models in various downstream tasks. However, many of
these models lack transparency in their pretraining dynamics and offer limited
insight into how well EEG information is preserved within their embeddings. For
successful clinical integration, EEG foundation models must ensure transparency
in pretraining, downstream fine-tuning, and the interpretability of learned
representations. Current approaches primarily operate in the temporal domain,
overlooking advancements in digital signal processing that enable the
extraction of deterministic and traceable features, such as wavelet-based
representations. We propose MENDR (Manifold Explainable Neural Data
Representations), a filter bank-based EEG foundation model built on a novel
Riemannian Manifold Transformer architecture to resolve these issues. MENDR
learns symmetric positive definite matrix embeddings of EEG signals and is
pretrained on a large corpus comprising over 4,000 hours of EEG data,
decomposed via discrete wavelet packet transforms into multi-resolution
coefficients. MENDR significantly enhances interpretability by visualizing
symmetric positive definite embeddings as geometric ellipsoids and supports
accurate reconstruction of EEG signals from learned embeddings. Evaluations
across multiple clinical EEG tasks demonstrate that MENDR achieves near
state-of-the-art performance with substantially fewer parameters, underscoring
its potential for efficient, interpretable, and clinically applicable EEG
analysis.

</details>


### [241] [Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning](https://arxiv.org/abs/2508.05077)
*Luai Abuelsamen,Temitope Lukman Adebanjo*

Main category: cs.LG

TL;DR: 本研究运用统计学习理论，证明了多模态模仿学习在泛化和优化方面优于单一模态学习。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨多模态模仿学习的理论基础，并解释像PerAct和CLIPort这样的多模态架构为何能取得优越的性能。

Method: 本研究运用统计学习理论的视角，分析了多模态感知（RGB-D、本体感觉、语言）如何影响模仿策略的样本复杂度和优化格局。

Result: 研究表明，正确整合的多模态策略可以实现比单一模态策略更紧致的泛化界和更有利的优化格局。

Conclusion: 多模态策略通过更紧凑的泛化界和更有利的优化前景，可以比单一模态对应物实现优越的性能。

Abstract: This paper examines the theoretical foundations of multimodal imitation
learning through the lens of statistical learning theory. We analyze how
multimodal perception (RGB-D, proprioception, language) affects sample
complexity and optimization landscapes in imitation policies. Building on
recent advances in multimodal learning theory, we show that properly integrated
multimodal policies can achieve tighter generalization bounds and more
favorable optimization landscapes than their unimodal counterparts. We provide
a comprehensive review of theoretical frameworks that explain why multimodal
architectures like PerAct and CLIPort achieve superior performance, connecting
these empirical results to fundamental concepts in Rademacher complexity, PAC
learning, and information theory.

</details>


### [242] [ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning](https://arxiv.org/abs/2508.05310)
*Jelle Luijkx,Zlatan Ajanović,Laura Ferranti,Jens Kober*

Main category: cs.LG

TL;DR: ASkDAgger框架通过利用新手计划中的反馈，减少了交互式模仿学习中的人类教学工作量，提高了效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了减少交互式模仿学习所需的人类教学工作量，该研究提出了一个框架，用于利用新手计划中的信息，包括新手能力和不确定性水平，以优化教师的查询。

Method: ASkDAgger框架（Active Skill-level Data Aggregation）通过S感知门控（SAG）、预见性交互经验回放（FIER）和优先交互经验回放（PIER）来利用教师对新手计划的反馈。

Result: ASkDAgger框架通过利用新手计划中的教师反馈，实现了查询频率与失败发生率的平衡，减少了所需演示注释的数量，提高了泛化能力，并加快了对变化领域的适应。

Conclusion: ASkDAgger框架通过利用新手计划中的教师反馈，在（1）S感知门控（SAG）调整门控阈值以跟踪灵敏度、特异性或最小成功率、（2）预见性交互经验回放（FIER）将有效和重新标记的新手动作计划重新定义为演示、（3）优先交互经验回放（PIER）根据不确定性、新手成功和演示年龄优先回放，实现了查询频率与失败发生率的平衡，减少了所需演示注释的数量，提高了泛化能力，并加快了对变化领域的适应。ASkDAgger在模拟和真实环境的语言条件操纵任务中得到了验证。

Abstract: Human teaching effort is a significant bottleneck for the broader
applicability of interactive imitation learning. To reduce the number of
required queries, existing methods employ active learning to query the human
teacher only in uncertain, risky, or novel situations. However, during these
queries, the novice's planned actions are not utilized despite containing
valuable information, such as the novice's capabilities, as well as
corresponding uncertainty levels. To this end, we allow the novice to say: "I
plan to do this, but I am uncertain." We introduce the Active Skill-level Data
Aggregation (ASkDAgger) framework, which leverages teacher feedback on the
novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating
threshold to track sensitivity, specificity, or a minimum success rate; (2)
Foresight Interactive Experience Replay (FIER), which recasts valid and
relabeled novice action plans into demonstrations; and (3) Prioritized
Interactive Experience Replay (PIER), which prioritizes replay based on
uncertainty, novice success, and demonstration age. Together, these components
balance query frequency with failure incidence, reduce the number of required
demonstration annotations, improve generalization, and speed up adaptation to
changing domains. We validate the effectiveness of ASkDAgger through
language-conditioned manipulation tasks in both simulation and real-world
environments. Code, data, and videos are available at
https://askdagger.github.io.

</details>


### [243] [Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.04999)
*Menghua Jiang,Yuxia Lin,Baoliang Chen,Haifeng Hu,Yuncheng Jiang,Sijie Mai*

Main category: cs.LG

TL;DR: MMCI是一种多模态情感分析模型，通过因果干预解决统计捷径问题，在分布外测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多模态情感分析时，常常受到模态内和模态间的虚假关联的影响，导致模型依赖统计捷径而非真正的因果关系，从而削弱了泛化能力。

Method: 首先将多模态输入建模为多关系图以捕获模态内和模态间依赖关系，然后应用注意力机制分别估计和分离因果特征和捷径特征，最后通过应用后门调整来分层捷径特征并将其与因果特征动态组合，以鼓励MMCI在分布变化下产生稳定的预测。

Result: 在多个标准MSA数据集和分布外（OOD）测试集上的广泛实验表明，MMCI模型有效抑制了偏差，提高了性能。

Conclusion: MMCI模型通过利用因果理论中的后门调整来解决由统计捷径引起的混淆效应，从而有效抑制偏差并提高多模态情感分析的性能。

Abstract: Multimodal sentiment analysis (MSA) aims to understand human emotions by
integrating information from multiple modalities, such as text, audio, and
visual data. However, existing methods often suffer from spurious correlations
both within and across modalities, leading models to rely on statistical
shortcuts rather than true causal relationships, thereby undermining
generalization. To mitigate this issue, we propose a Multi-relational
Multimodal Causal Intervention (MMCI) model, which leverages the backdoor
adjustment from causal theory to address the confounding effects of such
shortcuts. Specifically, we first model the multimodal inputs as a
multi-relational graph to explicitly capture intra- and inter-modal
dependencies. Then, we apply an attention mechanism to separately estimate and
disentangle the causal features and shortcut features corresponding to these
intra- and inter-modal relations. Finally, by applying the backdoor adjustment,
we stratify the shortcut features and dynamically combine them with the causal
features to encourage MMCI to produce stable predictions under distribution
shifts. Extensive experiments on several standard MSA datasets and
out-of-distribution (OOD) test sets demonstrate that our method effectively
suppresses biases and improves performance.

</details>


### [244] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero是一个全自主的LLM训练框架，它不依赖人类提供的任务和标签，而是通过Challenger和Solver模型的协同进化来生成训练数据，从而提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM训练方法依赖大量人工标注数据，这限制了AI能力超越人类智能的进步。本研究旨在克服这一瓶颈，探索完全自主的训练方法。

Method: R-Zero框架通过初始化一个Challenger和一个Solver模型，使它们通过交互进行协同进化。Challenger提出具有挑战性的任务，Solver则负责解决这些任务，并通过这种方式实现无需人类先验知识的自我改进。

Result: R-Zero框架在不同的LLM骨干上都取得了显著的推理能力提升，例如，将Qwen3-4B-Base在数学推理和通用领域推理基准上的表现分别提高了+6.49和+7.54。

Conclusion: R-Zero框架通过自主生成和优化训练数据，实现了LLM能力的显著提升，为迈向超越人类智能的AI系统提供了新的途径。

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [245] [SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models](https://arxiv.org/abs/2508.05015)
*Dai Do,Manh Nguyen,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: SPaRFT是一种自定步调学习框架，通过优化数据选择和时机，能够用更少的样本（高达100倍）实现高效学习，并提升大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前精调大型语言模型（LLMs）需要大量数据和计算资源，使得其不适用于较小模型，且现有课程学习或数据选择方法在可扩展性和泛化性方面存在局限性的问题。

Method: SPaRFT框架结合了基于聚类的数 据约简（将训练数据按语义和难度分区，提取紧凑且多样化的子集以减少冗余）和多臂老虎机（将数据簇视为臂，根据模型当前表现优化训练样本分配）两种技术。

Result: SPaRFT在多个推理基准测试中取得了与最先进基线相当或更好的准确率，同时使用的样本数量减少高达100倍。消融研究和分析也强调了数据聚类和自适应选择的重要性。

Conclusion: SPaRFT可以通过优化训练数据的选择和时机，从而实现高效学习，并在多种推理基准测试中取得与最先进基线相当或更好的准确率，同时使用的样本数量减少高达100倍。该方法强调了数据聚类和自适应选择在解锁大型语言模型推理能力方面的作用，并且所需资源极少。

Abstract: Large language models (LLMs) have shown strong reasoning capabilities when
fine-tuned with reinforcement learning (RL). However, such methods require
extensive data and compute, making them impractical for smaller models. Current
approaches to curriculum learning or data selection are largely
heuristic-driven or demand extensive computational resources, limiting their
scalability and generalizability. We propose \textbf{SPaRFT}, a self-paced
learning framework that enables efficient learning based on the capability of
the model being trained through optimizing which data to use and when. First,
we apply \emph{cluster-based data reduction} to partition training data by
semantics and difficulty, extracting a compact yet diverse subset that reduces
redundancy. Then, a \emph{multi-armed bandit} treats data clusters as arms,
optimized to allocate training samples based on model current performance.
Experiments across multiple reasoning benchmarks show that SPaRFT achieves
comparable or better accuracy than state-of-the-art baselines while using up to
\(100\times\) fewer samples. Ablation studies and analyses further highlight
the importance of both data clustering and adaptive selection. Our results
demonstrate that carefully curated, performance-driven training curricula can
unlock strong reasoning abilities in LLMs with minimal resources.

</details>


### [246] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
*Zhehan Qu,Tianyi Hu,Christian Fronk,Maria Gorlatova*

Main category: cs.LG

TL;DR: 本研究探讨了AR引导CPR中的情境感知（SA）问题，发现眼动追踪指标（如扫视幅度和速度）与SA水平相关。提出的FixGraphPool模型利用眼动数据预测SA，准确率达83.0%，为设计更安全的AR系统提供了依据。


<details>
  <summary>Details</summary>
Motivation: 增强现实（AR）系统在提高任务绩效的同时，也可能因过度关注虚拟内容而导致认知隧道效应，从而损害安全关键场景中的情境感知（SA）。本研究旨在探讨AR引导的心肺复苏（CPR）中的SA问题，因为施救者需要在有效的按压和对不可预见危险（例如患者呕吐）的警惕之间取得平衡。

Method: 研究人员开发了一款基于Magic Leap 2的AR应用程序，该程序可叠加实时心肺复苏（CPR）反馈（按压深度和速率）。通过模拟的意外事件（例如出血）进行用户研究，并收集SA指标（通过观察和在冻结探测事件中进行问卷调查）。提出了一个图神经网络模型FixGraphPool，将注视事件（固定和扫视）构建成时空图，以预测SA。

Result: 眼动追踪分析显示，更高的SA水平与更大的扫视幅度、扫视速度以及更少地注视虚拟内容相关。FixGraphPool模型在预测SA方面达到了83.0%的准确率（F1=81.0%），优于基于特征的机器学习和最先进的时间序列模型。

Conclusion: 该研究证明了眼动追踪技术在增强现实（AR）系统中的情境感知（SA）建模方面的潜力，并强调了其在设计确保用户安全和情境感知的AR系统中的实用性。

Abstract: Augmented Reality (AR) systems, while enhancing task performance through
real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on
virtual content that compromises situational awareness (SA) in safety-critical
scenarios. This paper investigates SA in AR-guided cardiopulmonary
resuscitation (CPR), where responders must balance effective compressions with
vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR
app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth
and rate) and conducted a user study with simulated unexpected incidents (e.g.,
bleeding) to evaluate SA, in which SA metrics were collected via observation
and questionnaires administered during freeze-probe events. Eye tracking
analysis revealed that higher SA levels were associated with greater saccadic
amplitude and velocity, and with reduced proportion and frequency of fixations
on virtual content. To predict SA, we propose FixGraphPool, a graph neural
network that structures gaze events (fixations, saccades) into spatiotemporal
graphs, effectively capturing dynamic attentional patterns. Our model achieved
83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and
state-of-the-art time-series models by leveraging domain knowledge and
spatial-temporal information encoded in ET data. These findings demonstrate the
potential of eye tracking for SA modeling in AR and highlight its utility in
designing AR systems that ensure user safety and situational awareness.

</details>


### [247] [Learning from Oblivion: Predicting Knowledge Overflowed Weights via Retrodiction of Forgetting](https://arxiv.org/abs/2508.05059)
*Jinhyeok Jang,Jaehong Kim,Jung Uk Kim*

Main category: cs.LG

TL;DR: 通过在逐渐缩小的下游任务数据上进行顺序微调，诱导结构化遗忘，然后逆转该过程，可以恢复知识并生成比在原始数据集上训练的更好的预训练权重。


<details>
  <summary>Details</summary>
Motivation: 预训练权重是现代深度学习的基础，尤其在数据稀疏的情况下，能够实现有效的知识迁移和提升下游任务性能。然而，如何获得能够封装超越现有数据集的更多知识的、更好的预训练权重仍然是一个基本问题。

Method: 研究利用结构化遗忘及其逆转来合成知识增强的权重。具体来说，通过在逐渐缩小的下游任务数据上进行顺序微调，诱导一种结构化遗忘过程，然后对其进行建模和逆转，以恢复如同在更大数据集上训练的知识。研究构建了一个由这种可控遗忘决定的权重转换数据集，并采用元学习来有效建模权重预测。提出的“知识溢出权重预测器”（KNOWN）作为一个超模型，学习权重的普遍演变规律，并预测具有更好泛化能力的增强权重。

Result: 通过在多样化的数据集和架构上进行的大量实验证明，KNOW预测在下游任务性能上持续优于朴素微调和简单的权重预测。

Conclusion: 该研究提出了一种名为“知识溢出权重”（KNOW）预测的新策略，通过利用结构化遗忘及其逆转来合成知识增强的权重，旨在获取超越给定数据集的、包含更多知识的预训练权重。实验证明，该方法在多样化的数据集和架构上均优于朴素微调和简单的权重预测，提升了下游任务的性能。该工作为重新解释遗忘动态以突破深度学习中知识迁移的极限提供了一个新视角。

Abstract: Pre-trained weights have become a cornerstone of modern deep learning,
enabling efficient knowledge transfer and improving downstream task
performance, especially in data-scarce scenarios. However, a fundamental
question remains: how can we obtain better pre-trained weights that encapsulate
more knowledge beyond the given dataset? In this work, we introduce
\textbf{KNowledge Overflowed Weights (KNOW)} prediction, a novel strategy that
leverages structured forgetting and its inversion to synthesize
knowledge-enriched weights. Our key insight is that sequential fine-tuning on
progressively downsized datasets induces a structured forgetting process, which
can be modeled and reversed to recover knowledge as if trained on a larger
dataset. We construct a dataset of weight transitions governed by this
controlled forgetting and employ meta-learning to model weight prediction
effectively. Specifically, our \textbf{KNowledge Overflowed Weights Nowcaster
(KNOWN)} acts as a hyper-model that learns the general evolution of weights and
predicts enhanced weights with improved generalization. Extensive experiments
across diverse datasets and architectures demonstrate that KNOW prediction
consistently outperforms Na\"ive fine-tuning and simple weight prediction,
leading to superior downstream performance. Our work provides a new perspective
on reinterpreting forgetting dynamics to push the limits of knowledge transfer
in deep learning.

</details>


### [248] [TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows](https://arxiv.org/abs/2508.05070)
*Moshe Eliasof,Eldad Haber,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: TANGO是一个创新的图表示学习框架，利用动力学系统和能量景观来优化节点特征演化，提高了模型的稳定性和信号传播效率，并在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: TANGO框架旨在解决图表示学习中的信号传播和模型稳定性问题，通过引入能量景观和切向演化机制，以更灵活的方式学习节点特征的演化。

Method: TANGO是一个受动力学系统启发的图表示学习框架，通过学习到的能量景观及其相关的下降动力学来控制节点特征的演化。该方法的核心是可学习的节点嵌入上的Lyapunov函数，其梯度定义了一个保证收敛和稳定性的能量递减方向。为了在保持能量基础动力学优势的同时增强灵活性，我们引入了一个通过消息传递学习的新型切向分量，该分量在演化特征的同时保持能量值。这种分解为能量梯度下降和切向演化的正交流，产生了灵活的图动力学形式，并能在图学习中常见的平坦或病态能量区域中实现有效的信号传播。

Result: TANGO能够缓解过拟合问题，并兼容不同的图神经网络骨干网络。

Conclusion: TANGO在各种节点和图分类及回归基准测试中取得了强大的性能，证明了联合学习的能量函数和切向流对于图神经网络的有效性。

Abstract: We introduce TANGO -- a dynamical systems inspired framework for graph
representation learning that governs node feature evolution through a learned
energy landscape and its associated descent dynamics. At the core of our
approach is a learnable Lyapunov function over node embeddings, whose gradient
defines an energy-reducing direction that guarantees convergence and stability.
To enhance flexibility while preserving the benefits of energy-based dynamics,
we incorporate a novel tangential component, learned via message passing, that
evolves features while maintaining the energy value. This decomposition into
orthogonal flows of energy gradient descent and tangential evolution yields a
flexible form of graph dynamics, and enables effective signal propagation even
in flat or ill-conditioned energy regions, that often appear in graph learning.
Our method mitigates oversquashing and is compatible with different graph
neural network backbones. Empirically, TANGO achieves strong performance across
a diverse set of node and graph classification and regression benchmarks,
demonstrating the effectiveness of jointly learned energy functions and
tangential flows for graph neural networks.

</details>


### [249] [ULU: A Unified Activation Function](https://arxiv.org/abs/2508.05073)
*Simin Huo*

Main category: cs.LG

TL;DR: ULU 是一种新的激活函数，在图像任务中表现优于 ReLU 和 Mish。


<details>
  <summary>Details</summary>
Motivation: 为了改进现有激活函数（如 ReLU）的性能，并提出一种新的方法来量化模型的归纳偏置。

Method: 提出了一种名为 ULU 的新型非单调分段激活函数，其定义为：f(x;α) = 0.5x(tanh(αx) + 1)，其中 α > 0。ULU 根据输入值的正负采用不同的处理方式。其变体 AULU 的参数是可学习的，允许其分别适应正负输入。

Result: ULU 和 AULU 在图像分类和目标检测任务中表现出色，优于 ReLU 和 Mish。LIB 指标被提出用于量化归纳偏置。

Conclusion: ULU 及其变体 AULU 在图像分类和目标检测任务中显著优于 ReLU 和 Mish。此外，还引入了 LIB 指标来量化模型的归纳偏置。

Abstract: We propose \textbf{ULU}, a novel non-monotonic, piecewise activation function
defined as $\{f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0 \}$, where
$f(x;\alpha)=0.5x(tanh(\alpha x)+1),\alpha >0$. ULU treats positive and
negative inputs differently. Extensive experiments demonstrate ULU
significantly outperforms ReLU and Mish across image classification and object
detection tasks. Its variant Adaptive ULU (\textbf{AULU}) is expressed as
$\{f(x;\beta_1^2),x<0; f(x;\beta_2^2),x>=0 \}$, where $\beta_1$ and $\beta_2$
are learnable parameters, enabling it to adapt its response separately for
positive and negative inputs. Additionally, we introduce the LIB (Like
Inductive Bias) metric from AULU to quantitatively measure the inductive bias
of the model.

</details>


### [250] [Integrated Influence: Data Attribution with Baseline](https://arxiv.org/abs/2508.05089)
*Linxiao Yang,Xinyu Gu,Liang Sun*

Main category: cs.LG

TL;DR: 集成影响是一种新颖的数据归因方法，它通过结合基线方法来解决现有方法（如基于LOO的方法）的局限性。它通过一个理论框架来支持，并被证明比现有方法更可靠。


<details>
  <summary>Details</summary>
Motivation: 现有的基于留一法（LOO）的数据归因方法存在局限性，例如仅扰动单个训练样本，忽略了训练集的集体影响，并且缺乏基线导致解释的灵活性不足，无法提供反事实解释。

Method: 集成影响通过定义基线数据集，并遵循数据退化过程将当前数据集过渡到基线，然后累积每个样本在此过程中的影响。

Result: 实验结果表明，集成影响在数据归因任务和错误标签示例识别任务中都比现有方法生成更可靠的数据归因。

Conclusion: 集成影响通过结合基线方法，为数据归因提供了更可靠的归因，并在数据归因和错误标签示例识别任务中都优于现有方法。

Abstract: As an effective approach to quantify how training samples influence test
sample, data attribution is crucial for understanding data and model and
further enhance the transparency of machine learning models. We find that
prevailing data attribution methods based on leave-one-out (LOO) strategy
suffer from the local-based explanation, as these LOO-based methods only
perturb a single training sample, and overlook the collective influence in the
training set. On the other hand, the lack of baseline in many data attribution
methods reduces the flexibility of the explanation, e.g., failing to provide
counterfactual explanations. In this paper, we propose Integrated Influence, a
novel data attribution method that incorporates a baseline approach. Our method
defines a baseline dataset, follows a data degeneration process to transition
the current dataset to the baseline, and accumulates the influence of each
sample throughout this process. We provide a solid theoretical framework for
our method, and further demonstrate that popular methods, such as influence
functions, can be viewed as special cases of our approach. Experimental results
show that Integrated Influence generates more reliable data attributions
compared to existing methods in both data attribution task and mislablled
example identification task.

</details>


### [251] [Cold Start Active Preference Learning in Socio-Economic Domains](https://arxiv.org/abs/2508.05090)
*Mojtaba Fayaz-Bakhsh,Danial Ataee,MohammadAmin Fazli*

Main category: cs.LG

TL;DR: 通过自监督预训练和主动学习相结合，提出了一种新的冷启动主动偏好学习框架，解决了初始数据稀疏的问题，并在金融、职业和社经地位等领域取得了比传统方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 为解决主动偏好学习在冷启动时性能下降的问题，特别是在计算社会系统和经济分析等标记数据稀疏、昂贵且易受专家噪声影响的领域。

Method: 本文提出了一种新颖的冷启动主动偏好学习框架。该方法首先利用主成分分析（PCA）通过自监督预训练阶段从数据固有结构中导出初始伪标签，从而在没有任何初始 oracle 交互的情况下创建冷启动模型。随后，通过主动学习循环对模型进行优化，该循环会策略性地从模拟的噪声 oracle 查询标签。

Result: 实验结果表明，与从零开始的标准主动学习策略相比，本文提出的冷启动方法在准确性和标记对数量方面均表现更优。

Conclusion: 该框架为数据受限环境下的偏好学习提供了实用有效的解决方案，提高了样本效率和适用性。

Abstract: Active preference learning is a powerful paradigm for efficiently modeling
preferences, yet it suffers from the cold-start problem: a significant drop in
performance when no initial labeled data is available. This challenge is
particularly acute in computational social systems and economic analysis, where
labeled data is often scarce, expensive, and subject to expert noise. To
address this gap, we propose a novel framework for cold-start active preference
learning. Our method initiates the learning process through a self-supervised
pre-training phase, utilizing Principal Component Analysis (PCA) to derive
initial pseudo-labels from the data's inherent structure, thereby creating a
cold-start model without any initial oracle interaction. Subsequently, the
model is refined through an active learning loop that strategically queries a
simulated noisy oracle for labels. We conduct extensive experiments on diverse
datasets from different domains, including financial credibility, career
success rate, and socio-economic status. The results demonstrate that our
cold-start approach outperforms standard active learning strategies that begin
from a blank slate, achieving higher accuracy with substantially fewer labeled
pairs. Our framework offers a practical and effective solution to mitigate the
cold-start problem, enhancing the sample efficiency and applicability of
preference learning in data-constrained environments. We release our code at
https://github.com/Dan-A2/cold-start-preference-learning

</details>


### [252] [Learning from Similarity-Confidence and Confidence-Difference](https://arxiv.org/abs/2508.05108)
*Tomoya Tate,Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 本文提出了一种名为SconfConfDiff分类的新型框架，用于处理标记数据有限的情况。该框架利用两种不同的弱标签（相似性置信度和置信度差异），并通过推导优化的风险估计器和引入风险校正方法来提高准确性和鲁棒性。实验证明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在实际机器学习应用中，为数据分配准确的标签常常具有挑战性，并且标记实例的数量通常有限。在这些情况下，弱监督学习（WSL）提供了一种实用有效的解决方案，因为它允许使用不完整或不精确的监督进行训练。然而，大多数现有的WSL方法都专注于利用单一类型的弱监督。因此，当标记数据有限时，利用来自多个关系视角的互补弱监督信号显得尤为重要。

Method: 本文提出了一种利用多关系视角下的互补弱监督信号的新型弱监督学习框架，名为SconfConfDiff分类。该方法整合了分配给未标记数据对的两种不同形式的弱标签：相似性置信度和置信度差异。为了实现这一方法，我们推导了两种无偏风险估计器：一种基于现有估计器的凸组合，另一种通过模拟两个弱标签之间的交互来设计。我们证明了这两种估计器在估计误差界方面都达到了最优收敛率。此外，我们还引入了一种风险校正方法来缓解负经验风险导致的过拟合，并对该方法在不准确的类先验概率和标签噪声下的鲁棒性进行了理论分析。

Result: 实验结果表明，该方法在各种设置下持续优于现有基线。

Conclusion: 该方法在多种设置下持续优于现有基线。

Abstract: In practical machine learning applications, it is often challenging to assign
accurate labels to data, and increasing the number of labeled instances is
often limited. In such cases, Weakly Supervised Learning (WSL), which enables
training with incomplete or imprecise supervision, provides a practical and
effective solution. However, most existing WSL methods focus on leveraging a
single type of weak supervision. In this paper, we propose a novel WSL
framework that leverages complementary weak supervision signals from multiple
relational perspectives, which can be especially valuable when labeled data is
limited. Specifically, we introduce SconfConfDiff Classification, a method that
integrates two distinct forms of weaklabels: similarity-confidence and
confidence-difference, which are assigned to unlabeled data pairs. To implement
this method, we derive two types of unbiased risk estimators for
classification: one based on a convex combination of existing estimators, and
another newly designed by modeling the interaction between two weak labels. We
prove that both estimators achieve optimal convergence rates with respect to
estimation error bounds. Furthermore, we introduce a risk correction approach
to mitigate overfitting caused by negative empirical risk, and provide
theoretical analysis on the robustness of the proposed method against
inaccurate class prior probability and label noise. Experimental results
demonstrate that the proposed method consistently outperforms existing
baselines across a variety of settings.

</details>


### [253] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: LLM在函数调用方面存在推理策略不足的问题。我们提出了一个强化学习框架，通过基于熵的探索来优化策略，以解决探索不足、缺乏结构化推理和参数提取验证不足的问题。该方法通过两阶段数据准备流程（迭代LLM评估和抽象语法树验证）提高了样本质量。实验结果在伯克利函数调用排行榜上达到了86.02%的准确率，优于标准GRPO，特别是在代码预训练模型上效果更佳。


<details>
  <summary>Details</summary>
Motivation: 函数调用能力对于将大型语言模型部署到实际应用至关重要，但目前的训练方法未能培养出强大的推理策略。监督微调产生的模型依赖于肤浅的模式匹配，而标准的强化学习方法在结构化函数调用的复杂动作空间方面存在困难。

Method: 提出了一种新颖的强化学习框架，通过战略性的基于熵的探索来增强组相对策略优化，该框架专门针对函数调用任务进行了定制。该方法解决了函数调用中的三个关键挑战：策略学习期间的探索不足、思维链生成中结构化推理的缺乏以及参数提取的验证不足。

Result: 在伯克利函数调用排行榜上取得了86.02%的总体准确率，在复杂多函数场景中比标准GRPO提高了6%。

Conclusion: 通过迭代LLM评估和抽象语法树验证的两阶段数据准备流程确保了高质量的训练样本。该框架在伯克利函数调用排行榜上的广泛实验证明，其在开源模型中实现了最先进的性能，整体准确率为86.02%，在复杂的多函数场景中比标准的GRPO高出6%。特别是，该方法在代码预训练模型上显示出特别强的改进，这表明结构化语言生成能力为函数调用任务中的强化学习提供了有利的起点。

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [254] [PSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning](https://arxiv.org/abs/2508.05144)
*Beicheng Xu,Wei Liu,Keyao Ding,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: PSEO是一个用于事后堆叠集成优化的框架，通过优化基础模型选择和多层堆叠策略来提高AutoML性能。


<details>
  <summary>Details</summary>
Motivation: 现有AutoML系统在集成阶段通常采用固定的策略，未能适应特定的任务特性，尽管它们在搜索最优单一模型方面进行了大量的搜索。

Method: PSEO框架通过以下方式进行事后堆叠集成优化：1. 通过二元二次规划进行基础模型选择，平衡多样性和性能。2. 引入两个机制，充分发挥多层堆叠的潜力。3. 构建超参数空间，并在其中搜索最优的事后集成策略。

Result: PSEO在80个公共数据集上的平均测试排名为2.96，优于16种对比方法。

Conclusion: PSEO在80个公共数据集上的实证结果表明，在包括近期AutoML系统中的事后设计和最先进的集成学习方法在内的16种方法中，PSEO实现了最佳的平均测试排名（2.96）。

Abstract: The Combined Algorithm Selection and Hyperparameter Optimization (CASH)
problem is fundamental in Automated Machine Learning (AutoML). Inspired by the
success of ensemble learning, recent AutoML systems construct post-hoc
ensembles for final predictions rather than relying on the best single model.
However, while most CASH methods conduct extensive searches for the optimal
single model, they typically employ fixed strategies during the ensemble phase
that fail to adapt to specific task characteristics. To tackle this issue, we
propose PSEO, a framework for post-hoc stacking ensemble optimization. First,
we conduct base model selection through binary quadratic programming, with a
trade-off between diversity and performance. Furthermore, we introduce two
mechanisms to fully realize the potential of multi-layer stacking. Finally,
PSEO builds a hyperparameter space and searches for the optimal post-hoc
ensemble strategy within it. Empirical results on 80 public datasets show that
\sys achieves the best average test rank (2.96) among 16 methods, including
post-hoc designs in recent AutoML systems and state-of-the-art ensemble
learning methods.

</details>


### [255] [Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation](https://arxiv.org/abs/2508.05154)
*Rishabh Gaur,Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 该研究开发了一种名为“Domain-driven-RL-metrics”的新评估方法，用于评估基于强化学习的代理模型（ABM）和理性代理模型（RABM）。通过将此方法应用于模拟大流行病的案例研究，证明了其在评估不同干预措施（如口罩使用和疫苗接种）方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 评估基于强化学习的代理模型（ABM）和理性代理模型（RABM）的性能具有挑战性，因为这些模型复杂且具有随机性，而且缺乏用于比较强化学习算法的标准化度量标准。

Method: 该研究开发了基于域的度量标准，并将其应用于理性主义建模的疾病建模案例研究，以模拟大流行病中的掩蔽行为、疫苗接种和封锁。

Result: 研究结果表明，基于域的奖励与传统的和最先进的度量标准结合使用，可以针对不同的模拟场景（例如口罩的可用性差异）有效地评估强化学习驱动的代理模型。

Conclusion: 该研究表明，在流行病学建模案例研究中，使用基于域的奖励以及传统和最先进的度量标准，可以对政策优化进行评估。

Abstract: For the development and optimization of agent-based models (ABMs) and
rational agent-based models (RABMs), optimization algorithms such as
reinforcement learning are extensively used. However, assessing the performance
of RL-based ABMs and RABMS models is challenging due to the complexity and
stochasticity of the modeled systems, and the lack of well-standardized metrics
for comparing RL algorithms. In this study, we are developing domain-driven
metrics for RL, while building on state-of-the-art metrics. We demonstrate our
``Domain-driven-RL-metrics'' using policy optimization on a rational ABM
disease modeling case study to model masking behavior, vaccination, and
lockdown in a pandemic. Our results show the use of domain-driven rewards in
conjunction with traditional and state-of-the-art metrics for a few different
simulation scenarios such as the differential availability of masks.

</details>


### [256] [pFedDSH: Enabling Knowledge Transfer in Personalized Federated Learning through Data-free Sub-Hypernetwork](https://arxiv.org/abs/2508.05157)
*Thinh Nguyen,Le Huy Khiem,Van-Tuan Tran,Khoa D Doan,Nitesh V Chawla,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 本文提出了一种名为pFedDSH的个性化联邦学习框架，用于解决新用户不断加入的动态场景。该框架通过使用中央超网络、特定批次的掩码和无数据重放策略，在保持已有用户性能的同时，有效适应新用户，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数个性化联邦学习（pFL）方法都假设客户端参与是静态的，这与现实世界中新客户端可能不断加入联邦系统的场景（动态客户端加入）不符。本文旨在解决这种动态环境下的挑战，包括在不重新训练的情况下保持已有客户端的性能，以及实现客户端批次之间的高效知识迁移。

Method: 提出了一种名为pFedDSH（Personalized Federated Data-Free Sub-Hypernetwork）的新框架。该框架的核心是一个中央超网络，通过嵌入向量为每个客户端生成个性化模型。为了在客户端不断加入时保持已有客户端的性能，pFedDSH采用了特定批次的掩码（batch-specific masks）来激活部分神经元以保留知识。此外，引入了一种基于DeepInversion的无数据重放策略（data-free replay strategy）来促进反向知识迁移，从而在不牺牲隐私的前提下提升已有客户端的性能。

Result: pFedDSH成功地解决了动态客户端加入的联邦学习场景中的挑战，实现了现有客户端的性能稳定性、新客户端的适应性以及神经资源的有效利用，并在实验中超越了现有SOTA方法。

Conclusion: pFedDSH框架在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上进行了广泛的实验，证明了其在动态客户端加入场景下，相比于现有的pFL和联邦持续学习基线方法，能够实现更优越的性能。该方法在保持已有客户端性能稳定性的同时，还能适应新加入的客户端，并有效利用神经资源。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients without sharing raw data, offering a significant privacy
benefit. However, most existing Personalized Federated Learning (pFL) methods
assume a static client participation, which does not reflect real-world
scenarios where new clients may continuously join the federated system (i.e.,
dynamic client onboarding). In this paper, we explore a practical scenario in
which a new batch of clients is introduced incrementally while the learning
task remains unchanged. This dynamic environment poses various challenges,
including preserving performance for existing clients without retraining and
enabling efficient knowledge transfer between client batches. To address these
issues, we propose Personalized Federated Data-Free Sub-Hypernetwork (pFedDSH),
a novel framework based on a central hypernetwork that generates personalized
models for each client via embedding vectors. To maintain knowledge stability
for existing clients, pFedDSH incorporates batch-specific masks, which activate
subsets of neurons to preserve knowledge. Furthermore, we introduce a data-free
replay strategy motivated by DeepInversion to facilitate backward transfer,
enhancing existing clients' performance without compromising privacy. Extensive
experiments conducted on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate
that pFedDSH outperforms the state-of-the-art pFL and Federated Continual
Learning baselines in our investigation scenario. Our approach achieves robust
performance stability for existing clients, as well as adaptation for new
clients and efficient utilization of neural resources.

</details>


### [257] [S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection](https://arxiv.org/abs/2508.05164)
*Jiaqi Wang,Zhengyu Ma,Xiongri Shen,Chenlin Zhou,Leilei Zhao,Han Zhang,Yi Zhong,Siqi Cai,Zhenxi Song,Zhiguo Zhang*

Main category: cs.LG

TL;DR: S$^2$M-Former 是一种用于听觉注意力检测 (AAD) 的新型脉冲对称混合框架，通过其创新的对称架构和轻量级设计，在降低功耗和提高参数效率的同时，实现了与最先进水平相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的基于脑电图 (EEG) 的听觉注意力检测 (AAD) 技术在能量效率方面存在限制，并且缺乏能够充分利用互补 EEG 特征的协同框架。

Method: 提出了一种名为 S$^2$M-Former 的新型脉冲对称混合框架。该框架的特点是：1) 采用受生物启发的脉冲驱动对称架构，包含并行的空间和频率分支，并采用镜像模块化设计，利用了生物学上合理化的 Token-通道混合器来增强跨分支的互补学习；2) 引入轻量级的一维 Token 序列取代传统的二维操作，将参数量减少了 14.7 倍。该框架还通过受脑启发的脉冲架构进一步降低了功耗，与最近的 ANN 方法相比，功耗降低了 5.8 倍。

Result: S$^2$M-Former 在参数效率和性能方面均超过了现有的 SNN 基线。其能量消耗比最近的 ANN 方法低 5.8 倍，参数量减少了 14.7 倍，同时在 AAD 任务上达到了与 SOTA 相当的解码精度。

Conclusion: S$^2$M-Former 在 KUL、DTU 和 AV-GC-AAD 三个 AAD 基准测试以及试验内、跨试验和跨主试的设置下，实现了与当前最先进 (SOTA) 的解码精度相当的性能，为 AAD 任务提供了一种有前景的低功耗、高性能解决方案。

Abstract: Auditory attention detection (AAD) aims to decode listeners' focus in complex
auditory environments from electroencephalography (EEG) recordings, which is
crucial for developing neuro-steered hearing devices. Despite recent
advancements, EEG-based AAD remains hindered by the absence of synergistic
frameworks that can fully leverage complementary EEG features under
energy-efficiency constraints. We propose S$^2$M-Former, a novel spiking
symmetric mixing framework to address this limitation through two key
innovations: i) Presenting a spike-driven symmetric architecture composed of
parallel spatial and frequency branches with mirrored modular design,
leveraging biologically plausible token-channel mixers to enhance complementary
learning across branches; ii) Introducing lightweight 1D token sequences to
replace conventional 3D operations, reducing parameters by 14.7$\times$. The
brain-inspired spiking architecture further reduces power consumption,
achieving a 5.8$\times$ energy reduction compared to recent ANN methods, while
also surpassing existing SNN baselines in terms of parameter efficiency and
performance. Comprehensive experiments on three AAD benchmarks (KUL, DTU and
AV-GC-AAD) across three settings (within-trial, cross-trial and cross-subject)
demonstrate that S$^2$M-Former achieves comparable state-of-the-art (SOTA)
decoding accuracy, making it a promising low-power, high-performance solution
for AAD tasks.

</details>


### [258] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: HIA 是一种创新的、无需微调的方法，可以在不牺牲对齐质量的情况下，通过启发式引导和两阶段过滤来优化 LLM 推理过程，从而有效降低成本并提高效率。


<details>
  <summary>Details</summary>
Motivation: 在真实世界中使用 LLM 需要将其与用户偏好对齐，但这通常需要昂贵的微调或推理，需要在对齐质量和计算成本之间进行权衡。现有的推理时间方法通常会忽略这种平衡，只关注优化策略的性能。

Method: HIA（启发式引导的推理时间对齐）是一种无需微调、兼容黑盒的方法，它使用轻量级提示优化器、启发式奖励模型和两阶段过滤来减少推理调用，同时保持对齐质量。

Result: HIA 在真实世界提示数据集 HelpSteer 和 ComPRed 的多目标、目标条件任务中，优于 N 采样、束搜索和贪婪搜索基线，并且在低推理预算下（仅一到两次响应查询）也有效。

Conclusion: HIA 在相同的推理预算下，在真实世界提示数据集 HelpSteer 和 ComPRed 的多目标、目标条件任务中，优于 N 采样、束搜索和贪婪搜索基线，并且在低推理预算下（仅一到两次响应查询）也有效，为可扩展的个性化 LLM 部署提供了实用的解决方案。

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [259] [Near Optimal Inference for the Best-Performing Algorithm](https://arxiv.org/abs/2508.05173)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 提出一种新的子集选择框架，用于在机器学习算法竞赛中识别最佳算法。该框架在理论和实践上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从具有竞争关系的机器学习算法集合中，根据其在基准数据集上的表现，识别出在未来未见数据集上最有可能排名最高的算法。

Method: 将问题形式化为多项式分布的子集选择问题，并引入新颖的框架，提供渐近和有限样本保证，并给出匹配的下界。

Result: 提出了新的子集选择框架，其渐近和有限样本保证均显著优于现有方法，并给出了匹配的下界证明了其优越性。

Conclusion: 所提出的框架在理论和实践上都优于现有方法，为在未来数据集上选择最佳算法提供了新的解决方案。

Abstract: Consider a collection of competing machine learning algorithms. Given their
performance on a benchmark of datasets, we would like to identify the best
performing algorithm. Specifically, which algorithm is most likely to rank
highest on a future, unseen dataset. A natural approach is to select the
algorithm that demonstrates the best performance on the benchmark. However, in
many cases the performance differences are marginal and additional candidates
may also be considered. This problem is formulated as subset selection for
multinomial distributions. Formally, given a sample from a countable alphabet,
our goal is to identify a minimal subset of symbols that includes the most
frequent symbol in the population with high confidence. In this work, we
introduce a novel framework for the subset selection problem. We provide both
asymptotic and finite-sample schemes that significantly improve upon currently
known methods. In addition, we provide matching lower bounds, demonstrating the
favorable performance of our proposed schemes.

</details>


### [260] [Human Activity Recognition from Smartphone Sensor Data for Clinical Trials](https://arxiv.org/abs/2508.05175)
*Stefania Russo,Rafał Klimas,Marta Płonka,Hugo Le Gall,Sven Holm,Dimitar Stanev,Florian Lipsmeier,Mattia Zanon,Lito Kriara*

Main category: cs.LG

TL;DR: 本研究开发了一种基于ResNet的人类活动识别（HAR）模型，用于检测步态与非步态活动以及日常活动。该模型在检测步态与非步态活动方面表现良好，并且在日常活动检测方面优于现有最先进的模型，同时对智能手机的佩戴位置具有高鲁棒性，显示出实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了检测步态与非步态活动以及日常活动，例如行走、跑步、爬楼梯、站立、坐着、躺着、坐到站转移。

Method: 本研究开发了一种基于ResNet的人类活动识别（HAR）模型，具有最小的开销，用于检测步态与非步态活动以及日常活动（行走、跑步、爬楼梯、站立、坐着、躺着、坐到站转移）。

Result: HAR模型在GaitLab和Roche数据集中检测步态与非步态活动的准确率分别为98.4%和99.6%，与比较性的最先进的ResNet模型（分别为99.3%和99.4%）相当。在日常活动方面，所提出的模型不仅准确率高于最先进的模型（分别为96.2%对91.9%；内部Roche数据集），而且在9个智能手机佩戴位置（手提包、购物袋、斜挎包、背包、连帽衫口袋、外套/夹克口袋、手、颈部、皮带）上保持了高性能，其表现比最先进的模型高出2.8%-9.0%。

Conclusion: 该研究提出的HAR模型能够准确检测日常活动，并且对各种智能手机佩戴位置具有高鲁棒性，证明了其在实际应用中的可行性。

Abstract: We developed a ResNet-based human activity recognition (HAR) model with
minimal overhead to detect gait versus non-gait activities and everyday
activities (walking, running, stairs, standing, sitting, lying, sit-to-stand
transitions). The model was trained and evaluated using smartphone sensor data
from adult healthy controls (HC) and people with multiple sclerosis (PwMS) with
Expanded Disability Status Scale (EDSS) scores between 0.0-6.5. Datasets
included the GaitLab study (ISRCTN15993728), an internal Roche dataset, and
publicly available data sources (training only). Data from 34 HC and 68 PwMS
(mean [SD] EDSS: 4.7 [1.5]) were included in the evaluation. The HAR model
showed 98.4% and 99.6% accuracy in detecting gait versus non-gait activities in
the GaitLab and Roche datasets, respectively, similar to a comparative
state-of-the-art ResNet model (99.3% and 99.4%). For everyday activities, the
proposed model not only demonstrated higher accuracy than the state-of-the-art
model (96.2% vs 91.9%; internal Roche dataset) but also maintained high
performance across 9 smartphone wear locations (handbag, shopping bag,
crossbody bag, backpack, hoodie pocket, coat/jacket pocket, hand, neck, belt),
outperforming the state-of-the-art model by 2.8% - 9.0%. In conclusion, the
proposed HAR model accurately detects everyday activities and shows high
robustness to various smartphone wear locations, demonstrating its practical
applicability.

</details>


### [261] [Physics-Informed Time-Integrated DeepONet: Temporal Tangent Space Operator Learning for High-Accuracy Inference](https://arxiv.org/abs/2508.05190)
*Luis Mandl,Dibyajyoti Nayak,Tim Ricken,Somdatta Goswami*

Main category: cs.LG

TL;DR: PITI-DeepONet是一种新的深度学习模型，通过学习时间导数算子来更准确、更稳定地模拟长期时间依赖性偏微分方程，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的全滚动和自回归方法在模拟时间依赖性偏微分方程的长期演化时存在准确性和泛化性不足的问题，如因果依赖性捕捉不足、训练时间范围外泛化差、误差累积等。

Method: 提出了一种名为PITI-DeepONet的双输出架构，通过完全物理信息或混合物理和数据驱动的目标进行训练，学习时间导数算子，并利用经典时间步进方案进行时间演化。该框架还利用推理过程中的残差监控来估计预测质量。

Result: PITI-DeepONet在基准测试问题上表现出更优的长期预测精度。与全滚动方法相比，一维热方程的平均相对L2误差降低了84%，一维Burgers方程降低了87%，二维Allen-Cahn方程降低了42%。与自回归方法相比，一维热方程的平均相对L2误差降低了79%，一维Burgers方程降低了98%，二维Allen-Cahn方程降低了89%。

Conclusion: PITI-DeepONet通过学习时间导数算子并利用经典时间步进方案来解决时间依赖性偏微分方程的长期预测问题，在准确性和稳定性方面优于传统的全滚动和自回归方法。

Abstract: Accurately modeling and inferring solutions to time-dependent partial
differential equations (PDEs) over extended horizons remains a core challenge
in scientific machine learning. Traditional full rollout (FR) methods, which
predict entire trajectories in one pass, often fail to capture the causal
dependencies and generalize poorly outside the training time horizon.
Autoregressive (AR) approaches, evolving the system step by step, suffer from
error accumulation, limiting long-term accuracy. These shortcomings limit the
long-term accuracy and reliability of both strategies. To address these issues,
we introduce the Physics-Informed Time-Integrated Deep Operator Network
(PITI-DeepONet), a dual-output architecture trained via fully physics-informed
or hybrid physics- and data-driven objectives to ensure stable, accurate
long-term evolution well beyond the training horizon. Instead of forecasting
future states, the network learns the time-derivative operator from the current
state, integrating it using classical time-stepping schemes to advance the
solution in time. Additionally, the framework can leverage residual monitoring
during inference to estimate prediction quality and detect when the system
transitions outside the training domain. Applied to benchmark problems,
PITI-DeepONet shows improved accuracy over extended inference time horizons
when compared to traditional methods. Mean relative $\mathcal{L}_2$ errors
reduced by 84% (vs. FR) and 79% (vs. AR) for the one-dimensional heat equation;
by 87% (vs. FR) and 98% (vs. AR) for the one-dimensional Burgers equation; and
by 42% (vs. FR) and 89% (vs. AR) for the two-dimensional Allen-Cahn equation.
By moving beyond classic FR and AR schemes, PITI-DeepONet paves the way for
more reliable, long-term integration of complex, time-dependent PDEs.

</details>


### [262] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 金融领域LLM的幻觉是一个关键问题，需要对表格数据进行准确的提取和计算。本研究提出了一个评估金融LLM内部幻觉的框架，该框架基于上下文感知的掩码跨度预测，并使用从S&P 500年报创建的数据集进行评估。


<details>
  <summary>Details</summary>
Motivation: 为了应对在金融领域部署大型语言模型（LLM）时，幻觉造成的关键挑战，特别是准确提取和精确计算表格数据对于可靠的金融分析至关重要，因为即使是微小的数值错误也可能影响决策和合规性。现有的幻觉基准测试很少能捕捉到金融应用通常依赖的依赖于上下文、数值和专有的表格数据。

Method: 开发了一个严谨且可扩展的框架，将金融LLM的内部幻觉评估概念化为在真实金融文档上进行上下文感知掩码跨度预测任务。其主要贡献包括：1）一个使用掩码策略的新颖的、自动化的数据集创建范例；2）一个从S&P 500年报中得出的新的幻觉评估数据集；3）对最先进的LLM在金融表格数据上的内部幻觉模式进行全面评估。

Result: 对最先进的大型语言模型在金融表格数据上的内部幻觉模式进行了全面评估。

Conclusion: 这项研究为金融领域的大型语言模型（LLM）的内部幻觉评估提供了一种严格且可扩展的框架，该框架将幻觉视为在真实金融文档上进行上下文感知掩码跨度预测任务。

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [263] [Bidding-Aware Retrieval for Multi-Stage Consistency in Online Advertising](https://arxiv.org/abs/2508.05206)
*Bin Liu,Yunfei Liu,Ziru Xu,Zhaoyu Zhou,Zhi Kou,Yeqiu Yang,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“竞价感知检索”（BAR）的新框架，通过整合广告出价信息来解决在线广告系统中多阶段不一致的问题，并在阿里巴巴的广告平台上实现了显著的收入和展示量提升。


<details>
  <summary>Details</summary>
Motivation: 在线广告系统中，检索阶段和排名阶段之间由于无法访问大量广告语料库的精确实时出价而存在不一致性，这导致平台收入和广告商成果出现次优。

Method: 提出了一种名为“竞价感知检索”（BAR）的基于模型的检索框架，该框架通过在检索评分函数中整合广告出价信号来解决多阶段不一致性问题。其核心创新包括“竞价感知建模”（通过单调约束学习和多任务蒸馏整合竞价信号）和“异步近线推理”（实现市场响应能力的嵌入实时更新），以及“任务注意力细化”模块（选择性地增强特征交互，以区分用户兴趣和商业价值信号）。

Result: 线下实验和在阿里巴巴展示广告平台上的全面部署验证了BAR的有效性，平台收入提高了4.32%，正面广告的展示量提升了22.2%。

Conclusion: BAR通过将广告出价纳入检索评分函数，解决了多阶段不一致性问题，并在阿里巴巴展示广告平台上的广泛部署验证了其有效性，实现了4.32%的平台收入增长和22.2%的正面广告展示量提升。

Abstract: Online advertising systems typically use a cascaded architecture to manage
massive requests and candidate volumes, where the ranking stages allocate
traffic based on eCPM (predicted CTR $\times$ Bid). With the increasing
popularity of auto-bidding strategies, the inconsistency between the
computationally sensitive retrieval stage and the ranking stages becomes more
pronounced, as the former cannot access precise, real-time bids for the vast ad
corpus. This discrepancy leads to sub-optimal platform revenue and advertiser
outcomes. To tackle this problem, we propose Bidding-Aware Retrieval (BAR), a
model-based retrieval framework that addresses multi-stage inconsistency by
incorporating ad bid value into the retrieval scoring function. The core
innovation is Bidding-Aware Modeling, incorporating bid signals through
monotonicity-constrained learning and multi-task distillation to ensure
economically coherent representations, while Asynchronous Near-Line Inference
enables real-time updates to the embedding for market responsiveness.
Furthermore, the Task-Attentive Refinement module selectively enhances feature
interactions to disentangle user interest and commercial value signals.
Extensive offline experiments and full-scale deployment across Alibaba's
display advertising platform validated BAR's efficacy: 4.32% platform revenue
increase with 22.2% impression lift for positively-operated advertisements.

</details>


### [264] [DFW: A Novel Weighting Scheme for Covariate Balancing and Treatment Effect Estimation](https://arxiv.org/abs/2508.05215)
*Ahmad Saeed Khan,Erik Schaffernicht,Johannes Andreas Stork*

Main category: cs.LG

TL;DR: DFW 是一种新的倾向性得分加权方法，通过去混淆因子来稳定权重，提高选择偏差估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决观察性数据因选择偏差导致的处理效应估计不准确问题，以及现有倾向性得分加权方法（如 IPW）在处理高方差倾向性得分时的局限性。

Method: 提出了一种名为 Deconfounding Factor Weighting (DFW) 的新型倾向性得分加权方法，该方法利用去混淆因子来构建稳定有效的样本权重，优先考虑混淆程度较低的样本，同时减轻混淆程度高的样本的影响。

Result: DFW 在协变量平衡和处理效应估计方面优于 IPW 和 CBPS 等现有方法，尤其是在处理高混淆样本时。

Conclusion: DFW 通过利用去混淆因子构建稳定有效的样本权重，解决了选择偏差问题，能够更好地近似 RCT，确保权重有界、方差较低并改善协变量平衡。实验证明 DFW 在协变量平衡和处理效应估计方面优于 IPW 和 CBPS 等现有方法。

Abstract: Estimating causal effects from observational data is challenging due to
selection bias, which leads to imbalanced covariate distributions across
treatment groups. Propensity score-based weighting methods are widely used to
address this issue by reweighting samples to simulate a randomized controlled
trial (RCT). However, the effectiveness of these methods heavily depends on the
observed data and the accuracy of the propensity score estimator. For example,
inverse propensity weighting (IPW) assigns weights based on the inverse of the
propensity score, which can lead to instable weights when propensity scores
have high variance-either due to data or model misspecification-ultimately
degrading the ability of handling selection bias and treatment effect
estimation. To overcome these limitations, we propose Deconfounding Factor
Weighting (DFW), a novel propensity score-based approach that leverages the
deconfounding factor-to construct stable and effective sample weights. DFW
prioritizes less confounded samples while mitigating the influence of highly
confounded ones, producing a pseudopopulation that better approximates a RCT.
Our approach ensures bounded weights, lower variance, and improved covariate
balance.While DFW is formulated for binary treatments, it naturally extends to
multi-treatment settings, as the deconfounding factor is computed based on the
estimated probability of the treatment actually received by each sample.
Through extensive experiments on real-world benchmark and synthetic datasets,
we demonstrate that DFW outperforms existing methods, including IPW and CBPS,
in both covariate balancing and treatment effect estimation.

</details>


### [265] [ML-based Short Physical Performance Battery future score prediction based on questionnaire data](https://arxiv.org/abs/2508.05222)
*Marcin Kolakowski,Seif Ben Bader*

Main category: cs.LG

TL;DR: Predicting older adults


<details>
  <summary>Details</summary>
Motivation: Effective slowing down of older adults

Method: The paper analyzed the possibility of predicting the SPPB score at a four-year horizon using questionnaire data. Several ML algorithms were tested, including Random Forest, XGBoost, Linear Regression, dense and TabNet neural networks. Feature selection was performed using Shapley values to identify important features (10-20) for retraining the XGBoost model.

Result: The best results were achieved for the XGBoost algorithm, yielding a mean absolute error of 0.79 points. After reducing the feature set to 10-20 features using Shapley values, the XGBoost regressor achieved a mean absolute error of 0.82.

Conclusion: The study demonstrates the feasibility of predicting SPPB scores using questionnaire data with ML algorithms, with XGBoost showing the best performance. Feature selection through Shapley values slightly impacted accuracy but reduced model complexity.

Abstract: Effective slowing down of older adults\' physical capacity deterioration
requires intervention as soon as the first symptoms surface. In this paper, we
analyze the possibility of predicting the Short Physical Performance Battery
(SPPB) score at a four-year horizon based on questionnaire data. The ML
algorithms tested included Random Forest, XGBoost, Linear Regression, dense and
TabNet neural networks. The best results were achieved for the XGBoost (mean
absolute error of 0.79 points). Based on the Shapley values analysis, we
selected smaller subsets of features (from 10 to 20) and retrained the XGBoost
regressor, achieving a mean absolute error of 0.82.

</details>


### [266] [Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning](https://arxiv.org/abs/2508.05224)
*Mirko Konstantin,Anirban Mukhopadhyay*

Main category: cs.LG

TL;DR: 本文提出了一种名为LIGHTYEAR的去中心化联邦学习框架，通过“一致性得分”和正则化，使客户端能够选择性地聚合个性化的、可信赖的更新，从而提高了在异构和对抗环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的中心化联邦学习（FL）架构存在单点故障、个性化能力有限、对分布变化的鲁棒性差以及易受故障客户端影响等缺点。此外，中心化FL中的更新选择依赖于低级参数差异，在客户端数据不独立同分布时可能不可靠，并且客户端的控制权有限。

Method: 本文提出了一个去中心化的、点对点（P2P）的联邦学习（FL）框架，称为LIGHTYEAR。该框架利用P2P拓扑的灵活性，使每个客户端能够识别和聚合来自可信赖的、有益的更新的个性化集合。其核心是一种在本地验证集上计算的“一致性得分”，用于量化传入更新在函数空间中相对于客户端参考模型的语义对齐程度。每个客户端使用此分数来选择定制的更新子集，并进行聚合，同时使用一个正则化项来进一步稳定训练。

Result: 在两个数据集上的实证评估表明，该方法在客户端层面表现优于中心化基线和现有的P2P方法，尤其是在对抗性和异构条件下。

Conclusion: 本文提出的LIGHTYEAR框架在客户端级别性能上持续优于中心化基线和现有的P2P方法，尤其是在对抗性和异构条件下。

Abstract: Federated learning (FL) enables collaborative model training across
distributed clients while preserving data privacy by keeping data local.
Traditional FL approaches rely on a centralized, star-shaped topology, where a
central server aggregates model updates from clients. However, this
architecture introduces several limitations, including a single point of
failure, limited personalization, and poor robustness to distribution shifts or
vulnerability to malfunctioning clients. Moreover, update selection in
centralized FL often relies on low-level parameter differences, which can be
unreliable when client data is not independent and identically distributed, and
offer clients little control. In this work, we propose a decentralized,
peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P
topology to enable each client to identify and aggregate a personalized set of
trustworthy and beneficial updates.This framework is the Local Inference Guided
Aggregation for Heterogeneous Training Environments to Yield Enhancement
Through Agreement and Regularization (LIGHTYEAR). Central to our method is an
agreement score, computed on a local validation set, which quantifies the
semantic alignment of incoming updates in the function space with respect to
the clients reference model. Each client uses this score to select a tailored
subset of updates and performs aggregation with a regularization term that
further stabilizes the training. Our empirical evaluation across two datasets
shows that the proposed approach consistently outperforms both centralized
baselines and existing P2P methods in terms of client-level performance,
particularly under adversarial and heterogeneous conditions.

</details>


### [267] [Cross-LoRA: A Data-Free LoRA Transfer Framework across Heterogeneous LLMs](https://arxiv.org/abs/2508.05232)
*Feifan Xia,Mingyang Liao,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.LG

TL;DR: Cross-LoRA transfers LoRA modules between different LLMs without extra data or training by aligning subspaces using SVD and projecting weights, achieving performance gains and comparable results to direct training.


<details>
  <summary>Details</summary>
Motivation: Traditional parameter-efficient fine-tuning (PEFT) methods like LoRA are limited in their applicability across heterogeneous pretrained LLMs due to their tight coupling with the base model architecture. This necessitates a method to transfer LoRA modules between diverse models without requiring additional training data.

Method: Cross-LoRA is a data-free framework comprising two components: LoRA-Align, which uses rank-truncated SVD and Frobenius-optimal linear transformation for subspace alignment between source and target base models, and LoRA-Shift, which projects source LoRA weight updates into the target model parameter space using the aligned subspaces.

Result: Experiments show Cross-LoRA achieves relative gains of up to 5.26% over base models on ARCs, OBOA, and HellaSwag benchmarks. It also maintains performance comparable to directly trained LoRA adapters on other commonsense reasoning benchmarks. The framework is data-free, training-free, and can be completed on a commodity GPU in 20 minutes.

Conclusion: Cross-LoRA is a data-free framework that enables the transfer of LoRA modules between diverse base models without additional training. It consists of LoRA-Align for subspace alignment and LoRA-Shift for projecting weight updates, achieving significant performance gains and maintaining comparable results to directly trained LoRA adapters.

Abstract: Traditional parameter-efficient fine-tuning (PEFT) methods such as LoRA are
tightly coupled with the base model architecture, which constrains their
applicability across heterogeneous pretrained large language models (LLMs). To
address this limitation, we introduce Cross-LoRA, a data-free framework for
transferring LoRA modules between diverse base models without requiring
additional training data. Cross-LoRA consists of two key components: (a)
LoRA-Align, which performs subspace alignment between source and target base
models through rank-truncated singular value decomposition (SVD) and
Frobenius-optimal linear transformation, ensuring compatibility under dimension
mismatch; and (b) LoRA-Shift, which applies the aligned subspaces to project
source LoRA weight updates into the target model parameter space. Both
components are data-free, training-free, and enable lightweight adaptation on a
commodity GPU in 20 minutes. Experiments on ARCs, OBOA and HellaSwag show that
Cross-LoRA achieves relative gains of up to 5.26% over base models. Across
other commonsense reasoning benchmarks, Cross-LoRA maintains performance
comparable to that of directly trained LoRA adapters.

</details>


### [268] [MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs](https://arxiv.org/abs/2508.05257)
*Xiaodong Chen,Mingming Ha,Zhenzhong Lan,Jing Zhang,Jianguo Li*

Main category: cs.LG

TL;DR: 提出MoBE方法，通过共享基矩阵压缩MoE模型，显著降低参数量和内存需求，同时保持了模型准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型（如DeepSeek-V3-0324和Kimi-K2-Instruct）存在巨大的内存需求，而现有的压缩方法会导致显著的准确率下降（7-14%）。

Method: 提出了一种新颖的混合基专家（MoBE）方法，通过秩分解和共享基矩阵来压缩MoE模型。具体来说，将专家中的up/gate矩阵分解为W=AB，其中A是专家独有的，B则通过共享基矩阵的线性组合进行重参数化，并通过最小化重构误差来学习因子。

Result: MoBE方法在Qwen3-235B-A22B-2507、DeepSeek-V3-0324 (671B) 和 Kimi-K2-Instruct (1T)等模型上，实现了24%-30%的参数量缩减，同时准确率仅下降1%-2%。

Conclusion: MoBE方法在显著降低MoE模型参数量的同时，将准确率下降控制在1%-2%（相对下降），优于现有压缩方法。

Abstract: The Mixture-of-Experts (MoE) architecture has become a predominant paradigm
for scaling large language models (LLMs). Despite offering strong performance
and computational efficiency, large MoE-based LLMs like DeepSeek-V3-0324 and
Kimi-K2-Instruct present serious challenges due to substantial memory
requirements in deployment. While recent works have explored MoE compression to
address this issue, existing methods often suffer from considerable accuracy
drops (e.g., 7-14% relatively) even at modest compression rates. This paper
introduces a novel Mixture-of-Basis-Experts (MoBE) method that achieves model
compression while incurring minimal accuracy drops. Specifically, each up/gate
matrix in an expert is decomposed via a rank decomposition as W = AB, where
matrix A is unique to each expert. The relatively larger matrix B is further
re-parameterized as a linear combination of basis matrices {Bi} shared across
all experts within a given MoE layer. The factorization is learned by
minimizing the reconstruction error relative to the original weight matrices.
Experiments demonstrate that MoBE achieves notably lower accuracy drops
compared to prior works. For instance, MoBE can reduce the parameter counts of
Qwen3-235B-A22B-2507, DeepSeek-V3-0324 (671B) and Kimi-K2-Instruct (1T) by
24%-30% with only 1%-2% accuracy drop (about 2% drops when measured
relatively).

</details>


### [269] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: Fairy±i是一种用于复杂值LLM的2位量化框架，它通过提升全精度模型的精度上限，并将权重映射到单位的四次方根$\{\pm1, \pm i\}$，实现了无乘法的推理，并在精度和效率上均超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 打破现有量化感知训练（QAT）研究主要关注最小化全精度模型量化误差，并将全精度精度视为精度上限的局限，探索超越此上限的量化方法。

Method: 提出了一种名为Fairy±i的新范式，通过提升全精度模型的精度上限，并将其高效量化为2位。该方法利用复数域的表示优势来提高全精度精度，并将权重映射到单位的四次方根$\{\pm1, \pm i\}$，形成完美的对称性和信息论最优的2位表示。每个量化权重只有实部或虚部为零，实现了仅通过加法和元素交换即可进行无乘法推理。

Result: Fairy±i在PPL和下游任务上均优于现有2位量化方法的精度上限，同时保持了严格的存储和计算效率。

Conclusion: Fairy±i为复杂的LLM开创了首个2位量化框架，在PPL和下游任务上均优于现有2位量化方法的精度上限，同时保持了严格的存储和计算效率。这项工作为在极低位约束下构建高精度、实用的LLM开辟了新方向。

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [270] [Marine Chlorophyll Prediction and Driver Analysis based on LSTM-RF Hybrid Models](https://arxiv.org/abs/2508.05260)
*Zhouyao Qian,Yang Chen,Baodian Li,Shuyi Zhang,Zhen Tian,Gongsen Wang,Tianyue Gu,Xinyu Zhou,Huilin Chen,Xinyi Li,Hao Zhu,Shuyao Zhang,Zongheng Li,Siyuan Wang*

Main category: cs.LG

TL;DR: A new LSTM-RF model accurately predicts marine chlorophyll concentration, outperforming older models by leveraging multi-source ocean data and improved techniques.


<details>
  <summary>Details</summary>
Motivation: The accurate prediction of marine chlorophyll concentration is crucial for monitoring ecosystem health, understanding the carbon cycle, and enabling timely red tide warnings and ecological responses. This is motivated by the limitations of single models in capturing both temporal dynamics and complex nonlinear features.

Method: The paper proposes a hybrid LSTM-RF model that combines the strengths of Long Short-Term Memory (LSTM) for time-series modeling and Random Forest (RF) for nonlinear feature portrayal. The model is trained using multi-source ocean data, including temperature, salinity, and dissolved oxygen. Standardized treatment and a sliding window approach are employed to enhance prediction accuracy.

Result: The LSTM-RF model achieved an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test set. These results are significantly better than those obtained using LSTM alone (R^2 = 0.0208) and RF alone (R^2 = 0.4934).

Conclusion: The proposed LSTM-RF hybrid model significantly improves the prediction accuracy of marine chlorophyll concentration compared to standalone LSTM and RF models. The model

Abstract: Marine chlorophyll concentration is an important indicator of ecosystem
health and carbon cycle strength, and its accurate prediction is crucial for
red tide warning and ecological response. In this paper, we propose a LSTM-RF
hybrid model that combines the advantages of LSTM and RF, which solves the
deficiencies of a single model in time-series modelling and nonlinear feature
portrayal. Trained with multi-source ocean data(temperature, salinity,
dissolved oxygen, etc.), the experimental results show that the LSTM-RF model
has an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test
set, which is significantly better than using LSTM (R^2 = 0.0208) and RF (R^2
=0.4934) alone , respectively. The standardised treatment and sliding window
approach improved the prediction accuracy of the model and provided an
innovative solution for high-frequency prediction of marine ecological
variables.

</details>


### [271] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: LLMs can generate accurate medical programs (phenotypes) with less data using an iterative learning method, showing promise for clinical decision support.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of Large Language Models (LLMs) for generating interpretable computable phenotypes (CPs), which could enable scalable clinical decision support to improve care for patients with hypertension.

Method: The paper investigates LLMs' potential for generating interpretable computable phenotypes (CPs) for six clinical phenotypes of varying complexity. It proposes and tests a "synthesize, execute, debug, instruct" strategy that uses LLMs to generate and iteratively refine CPs using data-driven feedback. Both zero-shot performance and the iterative strategy are evaluated.

Result: LLMs, particularly when using the "synthesize, execute, debug, instruct" strategy, can generate interpretable and reasonably accurate CPs. These CPs approach the performance of state-of-the-art ML methods but require significantly fewer training examples.

Conclusion: LLMs can generate interpretable and reasonably accurate programs that approach the performance of state-of-the-art ML methods while requiring significantly fewer training examples, especially when coupled with iterative learning.

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>


### [272] [FlowState: Sampling Rate Invariant Time Series Forecasting](https://arxiv.org/abs/2508.05287)
*Lars Graf,Thomas Ortner,Stanisław Woźniak,Angeliki Pantazi*

Main category: cs.LG

TL;DR: FlowState是一种新颖的时间序列基础模型（TSFM），它使用SSM编码器和函数基解码器来处理任意时间分辨率和动态调整预测范围，在GIFT-ZS和Chronos-ZS基准测试中表现优于现有模型，并且模型更小、数据需求更少、效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的时间序列基础模型（TSFM）在泛化能力、适应不同采样率以及计算效率方面存在不足，而FlowState旨在解决这些问题。

Method: FlowState采用基于状态空间模型（SSM）的编码器和基于函数基的解码器，实现了连续时间建模和动态时间尺度调整，使其能够泛化到所有时间分辨率并动态调整预测范围。

Result: FlowState是最小的模型，但在GIFT-ZS和Chronos-ZS基准测试中均超越了所有其他模型，达到了最先进水平。

Conclusion: FlowState是首个能够处理任意时间分辨率的TSFM，在GIFT-ZS和Chronos-ZS基准测试中表现优于所有其他模型，并证明了其组件的有效性以及在线适应不同输入采样率的独特能力。

Abstract: Foundation models (FMs) have transformed natural language processing, but
their success has not yet translated to time series forecasting. Existing time
series foundation models (TSFMs), often based on transformer variants, struggle
with generalization across varying context and target lengths, lack
adaptability to different sampling rates, and are computationally inefficient.
We introduce FlowState, a novel TSFM architecture that addresses these
challenges through two key innovations: a state space model (SSM) based encoder
and a functional basis decoder. This design enables continuous-time modeling
and dynamic time-scale adjustment, allowing FlowState to inherently generalize
across all possible temporal resolutions, and dynamically adjust the
forecasting horizons. In contrast to other state-of-the-art TSFMs, which
require training data across all possible sampling rates to memorize patterns
at each scale, FlowState inherently adapts its internal dynamics to the input
scale, enabling smaller models, reduced data requirements, and improved
efficiency. We further propose an efficient pretraining strategy that improves
robustness and accelerates training. Despite being the smallest model,
FlowState outperforms all other models and is state-of-the-art for the GIFT-ZS
and the Chronos-ZS benchmarks. Ablation studies confirm the effectiveness of
its components, and we demonstrate its unique ability to adapt online to
varying input sampling rates.

</details>


### [273] [RLHF Fine-Tuning of LLMs for Alignment with Implicit User Feedback in Conversational Recommenders](https://arxiv.org/abs/2508.05289)
*Zhongheng Yang,Aijia Sun,Yushang Zhao,Yinuo Yang,Dannier Li,Chengrui Zhou*

Main category: cs.LG

TL;DR: LLM-based recommender systems struggle with implicit user feedback. This paper uses RLHF to optimize LLMs based on implicit signals like engagement, improving recommendation accuracy, coherence, and user satisfaction compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional supervised fine-tuning for LLM-based CRS fails to capture implicit feedback signals like dwell time, sentiment, or engagement patterns. This limits the ability to provide satisfying and context-relevant recommendations. Therefore, there is a need for a method that can effectively utilize these implicit signals.

Method: The study proposes a fine-tuning solution using reinforcement learning from human feedback (RLHF) to maximize implied user feedback (IUF). A reward model R_φ is trained on engagement information and used to optimize the foundational LLM M_θ via proximal policy optimization (PPO). The architecture models conversational state transitions, where actions (item suggestions) are conditioned on conversation history.

Result: The RLHF-fine-tuned models outperform baseline models in terms of top-k recommendation accuracy, coherence, and user satisfaction, as evidenced by evaluations on synthetic and real-world datasets (REDIAL, OpenDialKG).

Conclusion: This paper demonstrates that aligning implicit signals can lead to scalable and user-adaptive conversational recommender systems (CRS).

Abstract: Conversational recommender systems (CRS) based on Large Language Models
(LLMs) need to constantly be aligned to the user preferences to provide
satisfying and context-relevant item recommendations. The traditional
supervised fine-tuning cannot capture the implicit feedback signal, e.g., dwell
time, sentiment polarity, or engagement patterns. In this paper, we share a
fine-tuning solution using human feedback reinforcement learning (RLHF) to
maximize implied user feedback (IUF) in a multi-turn recommendation context. We
specify a reward model $R_{\phi}$ learnt on weakly-labelled engagement
information and maximize user-centric utility by optimizing the foundational
LLM M_{\theta} through a proximal policy optimization (PPO) approach. The
architecture models conversational state transitions $s_t \to a_t \to s_{t
+1}$, where the action $a_t$ is associated with LLM-generated item suggestions
only on condition of conversation history in the past. The evaluation across
synthetic and real-world datasets (e.g.REDIAL, OpenDialKG) demonstrates that
our RLHF-fine-tuned models can perform better in terms of top-$k$
recommendation accuracy, coherence, and user satisfaction compared to
(arrow-zero-cmwrquca-teja-falset ensuite 2Round group-deca States penalty give
up This paper shows that implicit signal alignment can be efficient in
achieving scalable and user-adaptive design of CRS.

</details>


### [274] [Optimal Growth Schedules for Batch Size and Learning Rate in SGD that Reduce SFO Complexity](https://arxiv.org/abs/2508.05297)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: Deep learning models are getting bigger, but training them takes a lot of time and resources. This paper figures out how to adjust the batch size and learning rate during training to make it faster and better, using mathematical analysis and experiments.


<details>
  <summary>Details</summary>
Motivation: To address the computational bottlenecks introduced by the unprecedented growth of deep learning models, specifically focusing on the impact of batch-size and learning-rate scheduling on training efficiency and generalization.

Method: The paper analyzes the problem on the basis of stochastic first-order oracle (SFO) complexity, defined as the expected number of gradient evaluations needed to reach an $\epsilon$-approximate stationary point of the empirical loss. Optimal growth schedules for batch size and learning rate were theoretically derived.

Result: Optimal growth schedules for batch size and learning rate were theoretically derived, reducing SFO complexity and validated through extensive experiments. The results offer both theoretical insights and practical guidelines for scalable and efficient large-batch training.

Conclusion: The paper provides theoretical insights and practical guidelines for scalable and efficient large-batch training in deep learning by deriving optimal growth schedules for batch size and learning rate.

Abstract: The unprecedented growth of deep learning models has enabled remarkable
advances but introduced substantial computational bottlenecks. A key factor
contributing to training efficiency is batch-size and learning-rate scheduling
in stochastic gradient methods. However, naive scheduling of these
hyperparameters can degrade optimization efficiency and compromise
generalization. Motivated by recent theoretical insights, we investigated how
the batch size and learning rate should be increased during training to balance
efficiency and convergence. We analyzed this problem on the basis of stochastic
first-order oracle (SFO) complexity, defined as the expected number of gradient
evaluations needed to reach an $\epsilon$-approximate stationary point of the
empirical loss. We theoretically derived optimal growth schedules for the batch
size and learning rate that reduce SFO complexity and validated them through
extensive experiments. Our results offer both theoretical insights and
practical guidelines for scalable and efficient large-batch training in deep
learning.

</details>


### [275] [Adaptive Batch Size and Learning Rate Scheduler for Stochastic Gradient Descent Based on Minimization of Stochastic First-order Oracle Complexity](https://arxiv.org/abs/2508.05302)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: This paper presents an adaptive SGD scheduling strategy that dynamically adjusts batch size and learning rate using insights about critical batch size and observed gradient decay, outperforming existing methods in convergence speed.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to address the sensitivity of mini-batch SGD convergence to batch size and learning rate settings and to accelerate SGD by leveraging theoretical insights about a critical batch size.

Method: This paper introduces an adaptive scheduling strategy that adjusts batch size and learning rate based on the observed decay in the full gradient norm during training. This approach leverages theoretical findings on the critical batch size that minimizes SFO complexity for mini-batch SGD.

Result: Experiments demonstrated that the adaptive joint scheduler based on this strategy achieved improved convergence speed compared to existing schedulers.

Conclusion: In conclusion, this paper proposes an adaptive scheduling strategy for SGD that leverages theoretical findings on critical batch size and adjusts batch size and learning rate based on observed full gradient norm decay, leading to improved convergence speed compared to existing schedulers.

Abstract: The convergence behavior of mini-batch stochastic gradient descent (SGD) is
highly sensitive to the batch size and learning rate settings. Recent
theoretical studies have identified the existence of a critical batch size that
minimizes stochastic first-order oracle (SFO) complexity, defined as the
expected number of gradient evaluations required to reach a stationary point of
the empirical loss function in a deep neural network. An adaptive scheduling
strategy is introduced to accelerate SGD that leverages theoretical findings on
the critical batch size. The batch size and learning rate are adjusted on the
basis of the observed decay in the full gradient norm during training.
Experiments using an adaptive joint scheduler based on this strategy
demonstrated improved convergence speed compared with that of existing
schedulers.

</details>


### [276] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
*Yue Duan,Taicai Chen,Lei Qi,Yinghuan Shi*

Main category: cs.LG

TL;DR: USP is a framework that improves semi-supervised continual learning by using FSR, DCP, and CUD to boost learning plasticity, unlabeled learning, and memory stability, showing significant performance gains.


<details>
  <summary>Details</summary>
Motivation: Leverage both labeled and unlabeled data in a sequential learning setup to reduce annotation costs while managing continual data arrival, addressing challenges in unlabeled learning (UL), memory stability (MS), and learning plasticity (LP).

Method: USP framework, including Feature Space Reservation (FSR) for LP, Divide-and-Conquer Pseudo-labeling (DCP) for UL, and Class-mean-anchored Unlabeled Distillation (CUD) for MS.

Result: USP enhances LP, UL, and MS synergistically, outperforming prior SSCL methods.

Conclusion: USP outperforms prior SSCL methods, with gains up to 5.94% in the last accuracy, validating its effectiveness.

Abstract: Semi-supervised continual learning (SSCL) seeks to leverage both labeled and
unlabeled data in a sequential learning setup, aiming to reduce annotation
costs while managing continual data arrival. SSCL introduces complex
challenges, including ensuring effective unlabeled learning (UL), while
balancing memory stability (MS) and learning plasticity (LP). Previous SSCL
efforts have typically focused on isolated aspects of the three, while this
work presents USP, a divide-and-conquer framework designed to synergistically
enhance these three aspects: (1) Feature Space Reservation (FSR) strategy for
LP, which constructs reserved feature locations for future classes by shaping
old classes into an equiangular tight frame; (2) Divide-and-Conquer
Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels
across both high- and low-confidence unlabeled data; and (3)
Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's
outputs to anchor unlabeled data to stable class means for distillation to
prevent forgetting. Comprehensive evaluations show USP outperforms prior SSCL
methods, with gains up to 5.94% in the last accuracy, validating its
effectiveness. The code is available at https://github.com/NJUyued/USP4SSCL.

</details>


### [277] [Optimal Corpus Aware Training for Neural Machine Translation](https://arxiv.org/abs/2508.05364)
*Yi-Hsiu Liao,Cheng Shen,Brenda,Yang*

Main category: cs.LG

TL;DR: OCAT通过微调预训练的CAT模型，仅调整少量语料库相关参数，实现了轻量化、抗过拟合，并有效提升了翻译准确率，优于常规训练和部分现有微调技术。


<details>
  <summary>Details</summary>
Motivation: 现有的CAT方法在训练前需要预定义高质量数据，该过程容易出错且效率低下。因此，需要一种更优化的方法来利用语料库元数据。

Method: OCAT通过冻结大部分模型参数，仅微调与语料库相关的参数来优化CAT预训练模型。

Result: OCAT在WMT23英译中和英译德翻译任务上，分别取得了+3.6和+1.8的chrF提升，并且在性能上与其他最先进的微调技术相当或略有超越，同时对超参数的敏感度更低。

Conclusion: OCAT通过冻结大部分模型参数并仅调整少量与语料库相关的参数来微调预训练的CAT模型，实现了轻量化、抗过拟合和提升模型准确率。在WMT23英译中和英译德翻译任务上，OCAT相比常规训练分别取得了+3.6和+1.8的chrF提升，并且在性能上与其他最先进的微调技术相当或略有超越，同时对超参数的敏感度更低。

Abstract: Corpus Aware Training (CAT) leverages valuable corpus metadata during
training by injecting corpus information into each training example, and has
been found effective in the literature, commonly known as the "tagging"
approach. Models trained with CAT inherently learn the quality, domain and
nuance between corpora directly from data, and can easily switch to different
inference behavior. To achieve the best evaluation, CAT models pre-define a
group of high quality data before training starts which can be error-prone and
inefficient. In this work, we propose Optimal Corpus Aware Training (OCAT),
which fine-tunes a CAT pre-trained model by freezing most of the model
parameters and only tuning small set of corpus-related parameters. We show that
OCAT is lightweight, resilient to overfitting, and effective in boosting model
accuracy. We use WMT23 English to Chinese and English to German translation
tasks as our test ground and show +3.6 and +1.8 chrF improvement, respectively,
over vanilla training. Furthermore, our approach is on-par or slightly better
than other state-of-the-art fine-tuning techniques while being less sensitive
to hyperparameter settings.

</details>


### [278] [Latent Preference Bandits](https://arxiv.org/abs/2508.05367)
*Newton Mwai,Emil Carlsson,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 我们放宽了潜在匪徒的假设，仅要求对每个潜在状态下的动作偏好排序进行建模，并提出了一种后采样算法，该算法在处理个性化决策任务时，探索成本更低，并且在实际应用中表现更具竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在匪徒方法在处理需要个性化决策的任务时，探索成本过高，且假设潜在状态下的奖励分布已知且准确，这在实际中难以满足。

Method: 提出了一种适用于潜在匪徒的后采样算法。

Result: 所提出的算法在经验上具有竞争力，并且在某些情况下优于现有的潜在匪徒方法。

Conclusion: 该方法在奖励分布被正确指定时，其经验性能与具有完全奖励分布知识的潜在匪徒相当，而在奖励尺度在同一潜在状态的实例之间存在差异时，其性能优于后者。

Abstract: Bandit algorithms are guaranteed to solve diverse sequential decision-making
problems, provided that a sufficient exploration budget is available. However,
learning from scratch is often too costly for personalization tasks where a
single individual faces only a small number of decision points. Latent bandits
offer substantially reduced exploration times for such problems, given that the
joint distribution of a latent state and the rewards of actions is known and
accurate. In practice, finding such a model is non-trivial, and there may not
exist a small number of latent states that explain the responses of all
individuals. For example, patients with similar latent conditions may have the
same preference in treatments but rate their symptoms on different scales. With
this in mind, we propose relaxing the assumptions of latent bandits to require
only a model of the \emph{preference ordering} of actions in each latent state.
This allows problem instances with the same latent state to vary in their
reward distributions, as long as their preference orderings are equal. We give
a posterior-sampling algorithm for this problem and demonstrate that its
empirical performance is competitive with latent bandits that have full
knowledge of the reward distribution when this is well-specified, and
outperforms them when reward scales differ between instances with the same
latent state.

</details>


### [279] [Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms](https://arxiv.org/abs/2508.05387)
*Jie Xiao,Shaoduo Gan,Changyuan Fan,Qingnan Ren,Alfred Long,Yuchen Zhang,Rymon Yu,Eric Yang,Lynn Ai*

Main category: cs.LG

TL;DR: Echo system allows RL for LLMs to use decentralised, heterogeneous resources, matching datacentre performance by decoupling inference and training phases.


<details>
  <summary>Details</summary>
Motivation: Modern RL-based post-training for LLMs co-locate trajectory sampling and policy optimisation on the same GPU cluster, violating the SPMD assumption underlying distributed training systems.

Method: Echo decouples trajectory sampling and policy optimisation across heterogeneous 'inference' and 'training' swarms using two lightweight synchronization protocols: a sequential pull mode and an asynchronous push-pull mode.

Result: Echo matches a fully co-located baseline in convergence speed and final reward while off-loading trajectory generation to commodity edge hardware when training on Qwen3-4B, Qwen2.5-7B and Qwen3-32B.

Conclusion: Echo system can achieve datacentre-grade performance using decentralised, heterogeneous resources for large-scale RL for LLMs.

Abstract: Modern RL-based post-training for large language models (LLMs) co-locate
trajectory sampling and policy optimisation on the same GPU cluster, forcing
the system to switch between inference and training workloads. This serial
context switching violates the single-program-multiple-data (SPMD) assumption
underlying today's distributed training systems. We present Echo, the RL system
that cleanly decouples these two phases across heterogeneous "inference" and
"training" swarms while preserving statistical efficiency. Echo introduces two
lightweight synchronization protocols: a sequential pull mode that refreshes
sampler weights on every API call for minimal bias, and an asynchronous
push-pull mode that streams version-tagged rollouts through a replay buffer to
maximise hardware utilisation. Training three representative RL workloads with
Qwen3-4B, Qwen2.5-7B and Qwen3-32B on a geographically distributed cluster,
Echo matches a fully co-located Verl baseline in convergence speed and final
reward while off-loading trajectory generation to commodity edge hardware.
These promising results demonstrate that large-scale RL for LLMs could achieve
datacentre-grade performance using decentralised, heterogeneous resources.

</details>


### [280] [NT-ML: Backdoor Defense via Non-target Label Training and Mutual Learning](https://arxiv.org/abs/2508.05404)
*Wenjie Huo,Katinka Wolter*

Main category: cs.LG

TL;DR: A new defense mechanism called NT-ML can fix models damaged by backdoor attacks by retraining and mutual learning.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks (DNNs) are vulnerable to backdoor attacks, where a designed trigger is injected into the dataset, causing erroneous predictions when activated.

Method: NT-ML involves retraining the model with standard training outputs to reduce the harm of poisoned data, creating a teacher model with high accuracy on clean data and a student model with higher confidence in correct predictions on poisoned data. Then, a purified student model is obtained through mutual learning between the teacher and student models.

Result: NT-ML successfully restores the poisoned model under advanced backdoor attacks.

Conclusion: NT-ML can effectively defend against 6 backdoor attacks with a small number of clean samples, and outperforms 5 state-of-the-art backdoor defenses.

Abstract: Recent studies have shown that deep neural networks (DNNs) are vulnerable to
backdoor attacks, where a designed trigger is injected into the dataset,
causing erroneous predictions when activated. In this paper, we propose a novel
defense mechanism, Non-target label Training and Mutual Learning (NT-ML), which
can successfully restore the poisoned model under advanced backdoor attacks. NT
aims to reduce the harm of poisoned data by retraining the model with the
outputs of the standard training. At this stage, a teacher model with high
accuracy on clean data and a student model with higher confidence in correct
prediction on poisoned data are obtained. Then, the teacher and student can
learn the strengths from each other through ML to obtain a purified student
model. Extensive experiments show that NT-ML can effectively defend against 6
backdoor attacks with a small number of clean samples, and outperforms 5
state-of-the-art backdoor defenses.

</details>


### [281] [Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam](https://arxiv.org/abs/2508.05408)
*Asma Atamna,Tom Maus,Fabian Kievelitz,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 通过修正一种基于累积路径的自适应方案，以解决 Adam 优化器中的不一致性，并对 SGD 和 Adam 的在线学习率自适应策略进行了基准测试，以评估其在实际应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的学习率是一个关键超参数，其理想值取决于问题并且可能在训练期间发生变化。研究自适应学习率机制的实用性，该机制动态地调整步长以响应损失景观。

Method: 重新审视了一种基于累积路径的自适应方案，并提出了一种修正变体，以更好地反映 Adam 的更新动态，然后对 SGD 和 Adam（有/无累积自适应）进行了基准测试，并与一种最近的替代方法进行了比较。

Result: 发现原始方法对 Adam 的自适应机制由于优化器内部的预处理而存在概念上的不一致性，并提出了一个修正变体。

Conclusion: 研究结果旨在阐明在线学习率自适应策略在何时以及为何能提供实际益处。

Abstract: The learning rate is a crucial hyperparameter in deep learning, with its
ideal value depending on the problem and potentially changing during training.
In this paper, we investigate the practical utility of adaptive learning rate
mechanisms that adjust step sizes dynamically in response to the loss
landscape. We revisit a cumulative path-based adaptation scheme proposed in
2017, which adjusts the learning rate based on the discrepancy between the
observed path length, computed as a time-discounted sum of normalized gradient
steps, and the expected length of a random walk. While the original approach
offers a compelling intuition, we show that its adaptation mechanism for Adam
is conceptually inconsistent due to the optimizer's internal preconditioning.
We propose a corrected variant that better reflects Adam's update dynamics. To
assess the practical value of online learning rate adaptation, we benchmark SGD
and Adam, with and without cumulative adaptation, and compare them to a recent
alternative method. Our results aim to clarify when and why such adaptive
strategies offer practical benefits.

</details>


### [282] [MolSnap: Snap-Fast Molecular Generation with Latent Variational Mean Flow](https://arxiv.org/abs/2508.05411)
*Md Atik Ahamed,Qiang Ye,Qiang Cheng*

Main category: cs.LG

TL;DR: 本文提出了一种因果感知框架（CAT+VMF），用于解决分子生成任务中的挑战，实现了高质量、多样化且高效的生成。


<details>
  <summary>Details</summary>
Motivation: 现有分子生成方法在同时保证高质量、多样化生成和快速推理方面存在挑战，因此需要一种能够解决这些问题的框架。

Method: 本文提出了一种新颖的因果感知框架，包含两个关键创新：1. 因果感知Transformer（CAT）：该模型能够联合编码分子图标记和文本指令，并在生成过程中强制执行因果依赖关系。2. 变分平均流（VMF）：该框架将潜在空间建模为高斯混合模型，超越了单峰先验的限制，增强了模型的表达能力，并实现了高效的单步推理。

Result: 实验结果表明，本文提出的模型在四个标准的分子数据集上显著优于现有最先进的方法，在新鲜度（高达74.5%）、多样性（高达70.3%）方面表现更优，并实现了100%的有效性。此外，VMF在条件生成时仅需一次函数评估（NFE），在无条件生成时最多需要五次函数评估，在计算效率上远超基于扩散的方法。

Conclusion: 本文提出的因果感知框架通过因果感知Transformer（CAT）和变分平均流（VMF）模型，在分子图和文本指令的联合编码以及潜在空间的建模方面取得了创新，有效解决了现有方法在分子生成任务中面临的高质量、多样化生成和快速推理的挑战。

Abstract: Molecular generation conditioned on textual descriptions is a fundamental
task in computational chemistry and drug discovery. Existing methods often
struggle to simultaneously ensure high-quality, diverse generation and fast
inference. In this work, we propose a novel causality-aware framework that
addresses these challenges through two key innovations. First, we introduce a
Causality-Aware Transformer (CAT) that jointly encodes molecular graph tokens
and text instructions while enforcing causal dependencies during generation.
Second, we develop a Variational Mean Flow (VMF) framework that generalizes
existing flow-based methods by modeling the latent space as a mixture of
Gaussians, enhancing expressiveness beyond unimodal priors. VMF enables
efficient one-step inference while maintaining strong generation quality and
diversity. Extensive experiments on four standard molecular benchmarks
demonstrate that our model outperforms state-of-the-art baselines, achieving
higher novelty (up to 74.5\%), diversity (up to 70.3\%), and 100\% validity
across all datasets. Moreover, VMF requires only one number of function
evaluation (NFE) during conditional generation and up to five NFEs for
unconditional generation, offering substantial computational efficiency over
diffusion-based methods.

</details>


### [283] [Negative Binomial Variational Autoencoders for Overdispersed Latent Modeling](https://arxiv.org/abs/2508.05423)
*Yixuan Zhang,Wenxin Zhang,Hua Jiang,Quyu Kong,Feng Zhou*

Main category: cs.LG

TL;DR: NegBio-VAE使用负二项分布改进了VAE，能更准确地模拟神经元放电，提高了重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统的变分自编码器（VAE）无法有效模拟生物神经元发放脉冲的离散、不规则和高度可变性。现有的泊松-VAE虽然引入了泊松分布，但其均值与方差相等的限制无法反映神经活动的真实随机性质。

Method: NegBio-VAE框架，使用负二项分布建模放电计数，并开发了两种ELBO优化方案和两种可微分重参数化策略。

Result: NegBio-VAE在重建保真度方面取得了显著的改进，证明了显式建模脉冲状激活中的过度离散性的重要性。

Conclusion: NegBio-VAE通过使用负二项分布来建模神经元放电计数，并引入一个额外的离散度参数，从而克服了泊松分布的均值-方差相等限制，能够更准确地捕捉神经活动的随机性。该模型在重建保真度方面取得了显著的提升，证明了显式建模放电状激活中的过度离散性的重要性。

Abstract: Biological neurons communicate through spike trains, discrete, irregular
bursts of activity that exhibit variability far beyond the modeling capacity of
conventional variational autoencoders (VAEs). Recent work, such as the
Poisson-VAE, makes a biologically inspired move by modeling spike counts using
the Poisson distribution. However, they impose a rigid constraint: equal mean
and variance, which fails to reflect the true stochastic nature of neural
activity. In this work, we challenge this constraint and introduce NegBio-VAE,
a principled extension of the VAE framework that models spike counts using the
negative binomial distribution. This shift grants explicit control over
dispersion, unlocking a broader and more accurate family of neural
representations. We further develop two ELBO optimization schemes and two
differentiable reparameterization strategies tailored to the negative binomial
setting. By introducing one additional dispersion parameter, NegBio-VAE
generalizes the Poisson latent model to a negative binomial formulation.
Empirical results demonstrate this minor yet impactful change leads to
significant gains in reconstruction fidelity, highlighting the importance of
explicitly modeling overdispersion in spike-like activations.

</details>


### [284] [Federated Multi-Objective Learning with Controlled Pareto Frontiers](https://arxiv.org/abs/2508.05424)
*Jiansheng Rao,Jiayi Li,Zhizhi Gong,Soummya Kar,Haoxuan Li*

Main category: cs.LG

TL;DR: CR-FMOL是一种新的联邦学习框架，通过偏锥约束解决了少数客户端被忽视的问题，提高了客户端公平性，并在长期训练中能达到与FedAvg相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法（如FMOL）在优化时偏向大多数客户端，而牺牲了少数客户端的利益。FMOL虽然引入了多目标优化（MOO），但仅实现了任务级帕累托平稳点，未能保证客户端公平性。

Method: CR-FMOL框架在本地进行联邦多梯度下降平均（FMGDA）/联邦随机多梯度下降平均（FSMGDA）步骤后，每个客户端将其聚合的任务损失向量作为隐式偏好进行传输。服务器接着解决一个以均匀向量为中心的、受锥约束的Pareto-MTL子问题，生成一个在每个客户端的锥内满足帕累托平稳条件的下降方向。

Result: 实验结果表明，CR-FMOL在非IID基准测试中能够提升客户端公平性。虽然在早期训练阶段性能略低于FedAvg，但在经过足够多的训练轮数后，CR-FMOL的准确性有望与FedAvg相媲美。

Conclusion: CR-FMOL是第一个强制执行客户端级帕累托最优的联邦MOO框架，通过新颖的偏锥约束实现。CR-FMOL在非IID基准测试中提高了客户端公平性，并且其早期性能略逊于FedAvg，但在足够的训练轮数下有望达到可比的准确性。

Abstract: Federated learning (FL) is a widely adopted paradigm for privacy-preserving
model training, but FedAvg optimise for the majority while under-serving
minority clients. Existing methods such as federated multi-objective learning
(FMOL) attempts to import multi-objective optimisation (MOO) into FL. However,
it merely delivers task-wise Pareto-stationary points, leaving client fairness
to chance. In this paper, we introduce Conically-Regularised FMOL (CR-FMOL),
the first federated MOO framework that enforces client-wise Pareto optimality
through a novel preference-cone constraint. After local federated
multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient
descent averaging (FSMGDA) steps, each client transmits its aggregated
task-loss vector as an implicit preference; the server then solves a
cone-constrained Pareto-MTL sub-problem centred at the uniform vector,
producing a descent direction that is Pareto-stationary for every client within
its cone. Experiments on non-IID benchmarks show that CR-FMOL enhances client
fairness, and although the early-stage performance is slightly inferior to
FedAvg, it is expected to achieve comparable accuracy given sufficient training
rounds.

</details>


### [285] [Group Causal Policy Optimization for Post-Training Large Language Models](https://arxiv.org/abs/2508.05428)
*Ziyin Gu,Jingyao Wang,Ran Zuo,Chuxiong Sun,Zeen Song,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: A new method called GCPO improves upon GRPO by considering semantic interactions between candidate responses using causal insights, leading to better performance on reasoning tasks.


<details>
  <summary>Details</summary>
Motivation: GRPO treats candidate responses as independent, overlooking semantic interactions such as complementarity and contradiction. This paper introduces a Structural Causal Model (SCM) to reveal hidden dependencies among candidate responses and proposes GCPO to address these limitations.

Method: GCPO integrates causal structure into optimization through two key components: a causally informed reward adjustment and a novel KL regularization term that aligns the policy with a causally projected reference distribution.

Result: Experimental evaluations show that GCPO outperforms existing methods across multiple reasoning benchmarks.

Conclusion: GCPO consistently surpasses existing methods, including GRPO across multiple reasoning benchmarks.

Abstract: Recent advances in large language models (LLMs) have broadened their
applicability across diverse tasks, yet specialized domains still require
targeted post training. Among existing methods, Group Relative Policy
Optimization (GRPO) stands out for its efficiency, leveraging groupwise
relative rewards while avoiding costly value function learning. However, GRPO
treats candidate responses as independent, overlooking semantic interactions
such as complementarity and contradiction. To address this challenge, we first
introduce a Structural Causal Model (SCM) that reveals hidden dependencies
among candidate responses induced by conditioning on a final integrated output
forming a collider structure. Then, our causal analysis leads to two insights:
(1) projecting responses onto a causally informed subspace improves prediction
quality, and (2) this projection yields a better baseline than query only
conditioning. Building on these insights, we propose Group Causal Policy
Optimization (GCPO), which integrates causal structure into optimization
through two key components: a causally informed reward adjustment and a novel
KL regularization term that aligns the policy with a causally projected
reference distribution. Comprehensive experimental evaluations demonstrate that
GCPO consistently surpasses existing methods, including GRPO across multiple
reasoning benchmarks.

</details>


### [286] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
*Vincent Jeanselme,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 忽略竞争风险会扭曲生存预测并加剧不平等。我们的研究量化了这种误差，并强调了在开发生存模型时必须考虑竞争风险的重要性，以提高准确性和促进公平性。


<details>
  <summary>Details</summary>
Motivation: 准确的事件发生时间预测对于医疗指南、招聘决策和资源分配等决策至关重要。然而，许多患者会经历阻碍观察到感兴趣结果的事件（竞争风险）。这些竞争风险通常被视为审查，但这种做法常常被忽视，因为它可能导致系统性地高估风险并加剧不平等。

Method: 我们首先形式化将竞争风险视为审查的问题，并量化生存估计中由此产生的错误。我们开发了一个框架来估计这种误差，并证明了它对预测性能和算法公平性的影响。此外，我们研究了不同人口群体之间的不同风险状况如何导致特定群体的错误。

Result: 我们证明了将竞争风险视为审查会引入对生存估计的重大偏差。我们量化了由此产生的误差，并表明它会影响预测性能和算法公平性。我们在心血管管理中的一项实证分析表明，忽略竞争风险会对那些最有可能发生这些事件的个体产生不成比例的影响，从而可能加剧不平等。

Conclusion: 忽略竞争风险会导致生存估计出现偏差，并可能加剧现有的不平等。我们必须考虑竞争风险，以提高准确性、减少风险评估中的差异并更好地为下游决策提供信息。

Abstract: Accurate time-to-event prediction is integral to decision-making, informing
medical guidelines, hiring decisions, and resource allocation. Survival
analysis, the quantitative framework used to model time-to-event data, accounts
for patients who do not experience the event of interest during the study
period, known as censored patients. However, many patients experience events
that prevent the observation of the outcome of interest. These competing risks
are often treated as censoring, a practice frequently overlooked due to a
limited understanding of its consequences. Our work theoretically demonstrates
why treating competing risks as censoring introduces substantial bias in
survival estimates, leading to systematic overestimation of risk and,
critically, amplifying disparities. First, we formalize the problem of
misclassifying competing risks as censoring and quantify the resulting error in
survival estimates. Specifically, we develop a framework to estimate this error
and demonstrate the associated implications for predictive performance and
algorithmic fairness. Furthermore, we examine how differing risk profiles
across demographic groups lead to group-specific errors, potentially
exacerbating existing disparities. Our findings, supported by an empirical
analysis of cardiovascular management, demonstrate that ignoring competing
risks disproportionately impacts the individuals most at risk of these events,
potentially accentuating inequity. By quantifying the error and highlighting
the fairness implications of the common practice of considering competing risks
as censoring, our work provides a critical insight into the development of
survival models: practitioners must account for competing risks to improve
accuracy, reduce disparities in risk assessment, and better inform downstream
decisions.

</details>


### [287] [Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees](https://arxiv.org/abs/2508.05441)
*Zuyuan Zhang,Arnob Ghosh,Tian Lan*

Main category: cs.LG

TL;DR: 本文提出 CVaR-MCTS 和 W-MCTS 来解决 MCTS 中的尾部风险问题，通过嵌入 CVaR 和使用 Wasserstein 模糊集来提供更强的风险控制和安全保证，并在模拟实验中表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统的蒙特卡洛树搜索 (MCTS) 仅考虑预期回报，无法应对高风险、不利结果的潜在范围。现有的安全感知 MCTS 方法在处理极端或高风险结果（尾部风险）方面缺乏严格的保证，可能导致严重后果。

Method: 本文提出了两种新的解决方案：CVaR-MCTS，它将条件在险价值 (CVaR) 嵌入 MCTS，并提供显式的尾部风险控制；以及 Wasserstein-MCTS (W-MCTS)，它通过引入一阶 Wasserstein 模糊集来解决尾部风险估计偏差。

Result: CVaR-MCTS 和 W-MCTS 提供了显式的尾部风险控制，并具有 PAC 尾部安全保证。评估结果表明，所提出的方法在各种模拟环境中优于现有基线，有效实现了稳健的尾部风险保证、改进的奖励和稳定性。

Conclusion: CVaR-MCTS and W-MCTS 提供了显式尾部风险控制和 PAC 尾部安全保证，并在各种模拟环境中优于现有基线，实现了稳健的尾部风险保证、改进的奖励和稳定性。

Abstract: Making decisions with respect to just the expected returns in Monte Carlo
Tree Search (MCTS) cannot account for the potential range of high-risk, adverse
outcomes associated with a decision. To this end, safety-aware MCTS often
consider some constrained variants -- by introducing some form of mean risk
measures or hard cost thresholds. These approaches fail to provide rigorous
tail-safety guarantees with respect to extreme or high-risk outcomes (denoted
as tail-risk), potentially resulting in serious consequence in high-stake
scenarios. This paper addresses the problem by developing two novel solutions.
We first propose CVaR-MCTS, which embeds a coherent tail risk measure,
Conditional Value-at-Risk (CVaR), into MCTS. Our CVaR-MCTS with parameter
$\alpha$ achieves explicit tail-risk control over the expected loss in the
"worst $(1-\alpha)\%$ scenarios." Second, we further address the estimation
bias of tail-risk due to limited samples. We propose Wasserstein-MCTS (or
W-MCTS) by introducing a first-order Wasserstein ambiguity set
$\mathcal{P}_{\varepsilon_{s}}(s,a)$ with radius $\varepsilon_{s}$ to
characterize the uncertainty in tail-risk estimates. We prove PAC tail-safety
guarantees for both CVaR-MCTS and W-MCTS and establish their regret.
Evaluations on diverse simulated environments demonstrate that our proposed
methods outperform existing baselines, effectively achieving robust tail-risk
guarantees with improved rewards and stability.

</details>


### [288] [EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting](https://arxiv.org/abs/2508.05454)
*Wei Li,Zixin Wang,Qizheng Sun,Qixiang Gao,Fenglei Yang*

Main category: cs.LG

TL;DR: EnergyPatchTST improves energy forecasting by addressing multi-scale dynamics and data irregularity using a Transformer-based approach with enhanced feature extraction, uncertainty estimation, and pre-training, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The limitations of existing deep learning methods in capturing multi-scale time dynamics and handling the irregularity of real-world energy data.

Method: EnergyPatchTST, an extension of the Patch Time Series Transformer, incorporating a multi-scale feature extraction mechanism, a probability prediction framework with Monte Carlo elimination, integration of future known variables, and pre-training/fine-tuning strategies.

Result: The prediction error is reduced by 7-12% compared to other commonly used methods, and reliable uncertainty estimation is provided.

Conclusion: EnergyPatchTST is superior to other commonly used methods, reducing prediction error by 7-12% and providing reliable uncertainty estimation, offering a significant reference for time series prediction in the energy field.

Abstract: Accurate and reliable energy time series prediction is of great significance
for power generation planning and allocation. At present, deep learning time
series prediction has become the mainstream method. However, the multi-scale
time dynamics and the irregularity of real data lead to the limitations of the
existing methods. Therefore, we propose EnergyPatchTST, which is an extension
of the Patch Time Series Transformer specially designed for energy forecasting.
The main innovations of our method are as follows: (1) multi-scale feature
extraction mechanism to capture patterns with different time resolutions; (2)
probability prediction framework to estimate uncertainty through Monte Carlo
elimination; (3) integration path of future known variables (such as
temperature and wind conditions); And (4) Pre-training and Fine-tuning examples
to enhance the performance of limited energy data sets. A series of experiments
on common energy data sets show that EnergyPatchTST is superior to other
commonly used methods, the prediction error is reduced by 7-12%, and reliable
uncertainty estimation is provided, which provides an important reference for
time series prediction in the energy field.

</details>


### [289] [Task complexity shapes internal representations and robustness in neural networks](https://arxiv.org/abs/2508.05463)
*Robert Jankowski,Filippo Radicchi,M. Ángeles Serrano,Marián Boguñá,Santo Fortunato*

Main category: cs.LG

TL;DR: 研究人员开发了一种衡量神经网络任务复杂度的新方法。他们使用多种探针技术分析了MLP，发现任务的难度会影响其内部表示的拓扑结构和鲁棒性。研究结果表明，符号二分图拓扑对于学习表示至关重要，并为模型压缩和可解释性提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 旨在解决神经网络（尤其是MLP）的黑箱性质，特别是它们的内部表示如何受到输入数据复杂性和所解决问题的影响。

Method: 使用数据无关的探针（剪枝、二值化、噪声注入、符号翻转、二分网络随机化）来量化任务难度如何影响多层感知机（MLP）中表示的拓扑结构和鲁棒性。将MLP从网络科学的角度表示为有符号加权二分图。

Result: 研究发现，在MNIST和Fashion-MNIST数据集上，二值化权重对难任务模型会显著降低准确率，而对易任务模型则影响较小。修剪二值化难任务模型中的低幅度边会引发性能的急剧转变。适度的噪声注入可以提高准确率，类似于随机共振效应。仅保留符号结构（而非权重幅度）足以维持高准确率。

Conclusion: 该研究提出了一种衡量任务复杂度的新方法，即全精度和二值化/随机化神经网络之间的性能差距。研究结果强调了带符号二分图拓扑在学习表示中的关键作用，并为模型压缩和可解释性提供了实用的策略。

Abstract: Neural networks excel across a wide range of tasks, yet remain black boxes.
In particular, how their internal representations are shaped by the complexity
of the input data and the problems they solve remains obscure. In this work, we
introduce a suite of five data-agnostic probes-pruning, binarization, noise
injection, sign flipping, and bipartite network randomization-to quantify how
task difficulty influences the topology and robustness of representations in
multilayer perceptrons (MLPs). MLPs are represented as signed, weighted
bipartite graphs from a network science perspective. We contrast easy and hard
classification tasks on the MNIST and Fashion-MNIST datasets. We show that
binarizing weights in hard-task models collapses accuracy to chance, whereas
easy-task models remain robust. We also find that pruning low-magnitude edges
in binarized hard-task models reveals a sharp phase-transition in performance.
Moreover, moderate noise injection can enhance accuracy, resembling a
stochastic-resonance effect linked to optimal sign flips of small-magnitude
weights. Finally, preserving only the sign structure-instead of precise weight
magnitudes-through bipartite network randomizations suffices to maintain high
accuracy. These phenomena define a model- and modality-agnostic measure of task
complexity: the performance gap between full-precision and binarized or
shuffled neural network performance. Our findings highlight the crucial role of
signed bipartite topology in learned representations and suggest practical
strategies for model compression and interpretability that align with task
complexity.

</details>


### [290] [Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](https://arxiv.org/abs/2508.05469)
*Zachary Robertson,Sanmi Koyejo*

Main category: cs.LG

TL;DR: 我们开发了一种无需地面真实即可评估AI系统的方法，该方法利用了游戏抵抗性和输出质量之间的联系。我们的方法比现有实践在面对对抗性操纵时具有更好的鲁棒性，并且在特定条件下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 开发用于评估AI系统的机制，在没有地面真实性的情况下，利用游戏抵抗性和输出质量之间的联系。

Method: 利用游戏抵抗性和输出质量之间的联系，开发了无需地面真实性即可评估AI系统的机制。证明了f-互信息度量是在自然条件下，监督者作为代理人的唯一抗游戏度量。Shannon互信息面临指数级样本复杂性，而有界度量（如全变分距离）则易于处理。

Result: 在十个领域（从翻译到同行评审）的实验中，所有信息论机制在区分忠实代理和战略代理方面均实现了完美的区分（d > 0.5）。相比之下，LLM评估者在偏好虚假内容而非准确摘要方面表现出系统性的评估反转。我们的机制在面对对抗性操纵时，比现有实践表现出10-100倍的鲁棒性。我们还发现，性能随压缩比呈倒U型曲线，在10:1时达到峰值，此时代理响应表现出最佳的信息多样性（3个有效维度），这提供了关于何时预期我们的方法最有效的偏倚-方差视角。

Conclusion: 开发了评估AI系统的机制，无需地面真实性，利用了游戏抵抗性和输出质量之间的联系。证明了f-互信息度量是在自然条件下，监督者作为代理人的唯一抗游戏度量。与Shannon互信息相比，有界度量（如全变分距离）是易于处理的。实验结果表明，信息论机制在区分忠实代理和战略代理方面表现完美，并且在面对对抗性操纵时比现有方法具有更好的鲁棒性（提高10-100倍）。研究还发现，性能随压缩比呈倒U型曲线，在10:1时达到峰值，此时代理响应表现出最佳的信息多样性（3个有效维度），这为我们的方法提供了偏倚-方差视角。

Abstract: We develop mechanisms for evaluating AI systems without ground truth by
exploiting a connection between gaming resistance and output quality. The data
processing inequality ensures post-hoc attempts to game a metric degrades both
information content and task performance. We prove that f-mutual information
measures are the unique gaming resistant mechanisms under natural conditions,
with the overseer acting as an agent. While Shannon mutual information faces
exponential sample complexity, bounded measures like total variation distance
remain tractable. Empirically, across ten domains from translation to peer
review, all information-theoretic mechanisms achieve perfect discrimination (d
> 0.5) between faithful and strategic agents. In contrast, LLM judges exhibit
systematic evaluation inversion, preferring fabricated content over accurate
summaries. Our mechanisms show 10-100x better robustness to adversarial
manipulation than current practices. We also find performance follows an
inverted-U curve with compression ratio, peaking at 10:1 where agent responses
exhibit optimal information diversity (3 effective dimensions), giving a
bias-variance perspective on when our approach is expected to be most
effective.

</details>


### [291] [Prediction of Survival Outcomes under Clinical Presence Shift: A Joint Neural Network Architecture](https://arxiv.org/abs/2508.05472)
*Vincent Jeanselme,Glen Martin,Matthew Sperrin,Niels Peek,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: This paper introduces a multi-task recurrent neural network to model 'clinical presence' in electronic health records, improving the performance and transportability of clinical prediction models by accounting for how patient-healthcare interactions evolve over time and across different settings.


<details>
  <summary>Details</summary>
Motivation: Clinical presence, the observation process of patient-healthcare system interactions captured in electronic health records, is often overlooked in clinical prediction models, impacting performance and transportability. This work formalizes the concept of clinical presence shift and theoretically justifies joint modeling to improve transportability.

Method: A multi-task recurrent neural network is proposed to jointly model the inter-observation time and missingness processes in parallel to the survival outcome of interest.

Result: The strategy was demonstrated on a real-world mortality prediction task in the MIMIC-III dataset, showing improved performance and transportability compared to models that do not incorporate the observation process.

Conclusion: The proposed strategy improves performance and transportability compared to state-of-the-art prediction models by leveraging clinical presence, emphasizing its importance for creating more transportable clinical prediction models.

Abstract: Electronic health records arise from the complex interaction between patients
and the healthcare system. This observation process of interactions, referred
to as clinical presence, often impacts observed outcomes. When using electronic
health records to develop clinical prediction models, it is standard practice
to overlook clinical presence, impacting performance and limiting the
transportability of models when this interaction evolves. We propose a
multi-task recurrent neural network that jointly models the inter-observation
time and the missingness processes characterising this interaction in parallel
to the survival outcome of interest. Our work formalises the concept of
clinical presence shift when the prediction model is deployed in new settings
(e.g. different hospitals, regions or countries), and we theoretically justify
why the proposed joint modelling can improve transportability under changes in
clinical presence. We demonstrate, in a real-world mortality prediction task in
the MIMIC-III dataset, how the proposed strategy improves performance and
transportability compared to state-of-the-art prediction models that do not
incorporate the observation process. These results emphasise the importance of
leveraging clinical presence to improve performance and create more
transportable clinical prediction models.

</details>


### [292] [Parameter-free entropy-regularized multi-view clustering with hierarchical feature selection](https://arxiv.org/abs/2508.05504)
*Kristina P. Sinaga,Sara Colantonio,Miin-Shen Yang*

Main category: cs.LG

TL;DR: 本研究提出AMVFCM-U和AAMVFCM-U算法，实现了参数无关的多视图聚类框架，通过信噪比特征加权和双层熵自动平衡视图/特征贡献，AAMVFCM-U还包含层次降维。实验证明其在效率、降维和模式发现上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多视图聚类在处理高维异构数据、消除无关信息以及手动调参和缺乏跨视图整合机制的挑战。

Method: 提出AMVFCM-U和AAMVFCM-U两种算法，采用基于信噪比的正则化项（δ_j^h = (x̄_j^h)/((σ_j^h)^2)）进行特征加权，并结合双层熵项来自动平衡视图和特征贡献，实现了参数无关的框架。AAMVFCM-U进一步引入了通过自适应阈值（θ^(h^(t)) = (d_h^(t))/n）在特征和视图层面进行分层降维。

Result: 在五个不同基准测试中，与15种现有方法相比，AMVFCM-U和AAMVFCM-U表现更优。AAMVFCM-U实现了高达97%的计算效率提升，将维度降低至原始大小的0.45%，并能自动识别关键视图组合以优化模式发现。

Conclusion: 该研究提出的AMVFCM-U和AAMVFCM-U算法在多视图聚类任务中表现出优越性，能够处理高维异构数据，并有效整合不同视图信息。

Abstract: Multi-view clustering faces critical challenges in automatically discovering
patterns across heterogeneous data while managing high-dimensional features and
eliminating irrelevant information. Traditional approaches suffer from manual
parameter tuning and lack principled cross-view integration mechanisms. This
work introduces two complementary algorithms: AMVFCM-U and AAMVFCM-U, providing
a unified parameter-free framework. Our approach replaces fuzzification
parameters with entropy regularization terms that enforce adaptive cross-view
consensus. The core innovation employs signal-to-noise ratio based
regularization ($\delta_j^h = \frac{\bar{x}_j^h}{(\sigma_j^h)^2}$) for
principled feature weighting with convergence guarantees, coupled with
dual-level entropy terms that automatically balance view and feature
contributions. AAMVFCM-U extends this with hierarchical dimensionality
reduction operating at feature and view levels through adaptive thresholding
($\theta^{h^{(t)}} = \frac{d_h^{(t)}}{n}$). Evaluation across five diverse
benchmarks demonstrates superiority over 15 state-of-the-art methods. AAMVFCM-U
achieves up to 97% computational efficiency gains, reduces dimensionality to
0.45% of original size, and automatically identifies critical view combinations
for optimal pattern discovery.

</details>


### [293] [Tractable Sharpness-Aware Learning of Probabilistic Circuits](https://arxiv.org/abs/2508.05537)
*Hrithik Suresh,Sahil Sidheekh,Vishnu Shreeram M. P,Sriraam Natarajan,Narayanan C. Krishnan*

Main category: cs.LG

TL;DR: 通过最小化Hessian迹来训练概率电路，以解决过拟合问题，并提高泛化性能。


<details>
  <summary>Details</summary>
Motivation: 深度和表达性强的概率电路（PCs）在数据有限时容易出现过拟合。过拟合的原因是收敛到泛化能力差的sharp optima。因此，需要一种方法来解决PCs的过拟合问题。

Method: 提出了一种基于Hessian的正则化方法，该方法通过最小化对数似然的Hessian迹来训练概率电路（PCs）。Hessian迹被用作sharpness的代理，并且对于PCs可以有效地计算。这种方法可以与基于梯度的方法集成，并且可以为EM算法提供简单的闭式参数更新。

Result: 实验结果表明，所提出的方法能够一致地将PCs引导至更平坦的最小值，并提高泛化性能。

Conclusion: 该研究提出了一种基于Hessian的正则化方法，用于训练概率电路（PCs），以解决过拟合问题。通过最小化Hessian迹（一种PC的计算效率高的sharpness代理），可以诱导一种基于梯度范数的正则化，从而实现简单的参数更新，并能与基于梯度的学习方法无缝集成。实验结果表明，该方法能够有效地将PCs引导至更平坦的最小值，并提高泛化性能。

Abstract: Probabilistic Circuits (PCs) are a class of generative models that allow
exact and tractable inference for a wide range of queries. While recent
developments have enabled the learning of deep and expressive PCs, this
increased capacity can often lead to overfitting, especially when data is
limited. We analyze PC overfitting from a log-likelihood-landscape perspective
and show that it is often caused by convergence to sharp optima that generalize
poorly. Inspired by sharpness aware minimization in neural networks, we propose
a Hessian-based regularizer for training PCs. As a key contribution, we show
that the trace of the Hessian of the log-likelihood-a sharpness proxy that is
typically intractable in deep neural networks-can be computed efficiently for
PCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer
that yields simple closed-form parameter updates for EM, and integrates
seamlessly with gradient based learning methods. Experiments on synthetic and
real-world datasets demonstrate that our method consistently guides PCs toward
flatter minima, improves generalization performance.

</details>


### [294] [Adapting Vision-Language Models Without Labels: A Comprehensive Survey](https://arxiv.org/abs/2508.05547)
*Hao Dong,Lijun Sheng,Jian Liang,Ran He,Eleni Chatzi,Olga Fink*

Main category: cs.LG

TL;DR: 该论文对无监督视觉语言模型（VLM）适应进行了全面的调查，提出了一个分类框架，并讨论了各种方法和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLM）在各种任务中展现出强大的泛化能力，但它们在直接应用于特定下游场景时性能往往不理想，需要针对特定任务进行适应。为了在保持数据效率的同时提高其效用，研究重点转向不依赖标签数据的无监督适应方法。然而，目前缺乏一个统一的、面向任务的关于无监督VLM适应的调查。

Method: 该论文提出了一种基于无标签视觉数据可用性和性质的分类法，将现有方法分为四类：无数据迁移（无数据）、无监督域迁移（丰富数据）、情景测试时适应（批处理数据）和在线测试时适应（流式数据）。在此框架下，分析了与每个范例相关联的核心方法和适应策略。

Result: 该论文对无监督VLM适应领域进行了全面的概述，提出了一个分类框架，分析了各种方法，并审查了相关的基准和未来研究方向。

Conclusion: 该论文提出了一个统一的、面向任务的调查，用于无监督视觉语言模型（VLM）适应，并提出了一个基于无标签视觉数据可用性和性质的分类法，将现有方法分为四类：无数据迁移、无监督域迁移、情景测试时适应和在线测试时适应。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable generalization
capabilities across a wide range of tasks. However, their performance often
remains suboptimal when directly applied to specific downstream scenarios
without task-specific adaptation. To enhance their utility while preserving
data efficiency, recent research has increasingly focused on unsupervised
adaptation methods that do not rely on labeled data. Despite the growing
interest in this area, there remains a lack of a unified, task-oriented survey
dedicated to unsupervised VLM adaptation. To bridge this gap, we present a
comprehensive and structured overview of the field. We propose a taxonomy based
on the availability and nature of unlabeled visual data, categorizing existing
approaches into four key paradigms: Data-Free Transfer (no data), Unsupervised
Domain Transfer (abundant data), Episodic Test-Time Adaptation (batch data),
and Online Test-Time Adaptation (streaming data). Within this framework, we
analyze core methodologies and adaptation strategies associated with each
paradigm, aiming to establish a systematic understanding of the field.
Additionally, we review representative benchmarks across diverse applications
and highlight open challenges and promising directions for future research. An
actively maintained repository of relevant literature is available at
https://github.com/tim-learn/Awesome-LabelFree-VLMs.

</details>


### [295] [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](https://arxiv.org/abs/2508.05587)
*Claudia d'Amato,Ivan Diliso,Nicola Fanizzi,Zafar Saeed*

Main category: cs.LG

TL;DR: 为PyKEEN知识图谱嵌入框架添加了先进的负采样功能，以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱嵌入库通常只支持基本的负采样策略，缺乏高级解决方案，而负采样策略的选择对模型性能有重要影响。

Method: 通过集成一套先进的负采样器（包括静态和动态破坏策略）来扩展PyKEEN框架，以生成有意义的负样本，同时保持与现有PyKEEN工作流和管道的兼容性。

Result: 提出了一个PyKEEN框架的扩展，其中包含一套先进的负采样器，并通过实证研究证明了其对不同嵌入方法在链接预测任务上的性能影响，为设计更有效的策略提供了有用的见解。

Conclusion: 该扩展增强了PyKEEN框架，并允许更轻松、更全面地开发或定制嵌入方法。

Abstract: Embedding methods have become popular due to their scalability on link
prediction and/or triple classification tasks on Knowledge Graphs. Embedding
models are trained relying on both positive and negative samples of triples.
However, in the absence of negative assertions, these must be usually
artificially generated using various negative sampling strategies, ranging from
random corruption to more sophisticated techniques which have an impact on the
overall performance. Most of the popular libraries for knowledge graph
embedding, support only basic such strategies and lack advanced solutions. To
address this gap, we deliver an extension for the popular KGE framework PyKEEN
that integrates a suite of several advanced negative samplers (including both
static and dynamic corruption strategies), within a consistent modular
architecture, to generate meaningful negative samples, while remaining
compatible with existing PyKEEN -based workflows and pipelines. The developed
extension not only enhancesPyKEEN itself but also allows for easier and
comprehensive development of embedding methods and/or for their customization.
As a proof of concept, we present a comprehensive empirical study of the
developed extensions and their impact on the performance (link prediction
tasks) of different embedding methods, which also provides useful insights for
the design of more effective strategies

</details>


### [296] [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](https://arxiv.org/abs/2508.05591)
*Natalia Emelianova,Carlos Kamienski,Ronaldo C. Prati*

Main category: cs.LG

TL;DR: 物联网面临严峻的安全挑战，本研究提出使用KANs进行入侵检测，结果显示KANs性能优越且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 物联网的指数级增长导致安全问题日益严重，物联网网络已成为网络攻击的主要目标，因此需要更有效的入侵检测方法。

Method: 研究了Kolmogorov-Arnold Networks (KANs)在物联网入侵检测中的应用，并将其与传统机器学习模型（如MLP、随机森林和XGBoost）进行了比较。

Result: KANs在物联网入侵检测中展现出竞争力，准确率可与现有先进模型相媲美，并且具有更好的可解释性。

Conclusion: KANs在物联网入侵检测方面表现出优于传统MLP模型的性能，并能与随机森林和XGBoost等先进模型相媲美，同时提供更优越的可解释性。

Abstract: The exponential growth of the Internet of Things (IoT) has led to the
emergence of substantial security concerns, with IoT networks becoming the
primary target for cyberattacks. This study examines the potential of
Kolmogorov-Arnold Networks (KANs) as an alternative to conventional machine
learning models for intrusion detection in IoT networks. The study demonstrates
that KANs, which employ learnable activation functions, outperform traditional
MLPs and achieve competitive accuracy compared to state-of-the-art models such
as Random Forest and XGBoost, while offering superior interpretability for
intrusion detection in IoT networks.

</details>


### [297] [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](https://arxiv.org/abs/2508.05600)
*Thorsten Peinemann,Paula Arnold,Sebastian Berndt,Thomas Eisenbarth,Esfandiar Mohammadi*

Main category: cs.LG

TL;DR: 攻击者仅用一个投毒样本就能成功为机器学习模型植入后门，且对模型正常性能影响很小。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决机器学习模型安全中的一个关键问题：在不可信数据源上训练的模型易受后门注入攻击。尽管已有研究探讨了后门攻击的成功率和对良性学习任务的影响，但对于成功发起后门攻击所需的投毒数据量仍然是一个悬而未决的问题。本研究试图阐明，是否仅用一个投毒样本就可以成功发起后门攻击。

Method: 本研究提出了“一次投毒假设”，即攻击者可以使用一个投毒样本和有限的背景知识来注入后门，同时保持零后门错误并最小化对良性学习任务性能的影响。研究人员通过理论证明（尤其是在线性回归和线性分类方面）以及在现实基准数据集上的实验来验证这一假设。他们还分析了在不同条件下（例如，投毒样本利用了良性数据分布未使用的方向）对良性学习任务性能的影响。

Result: 本研究证明了“一次投毒假设”，即一个投毒样本和有限的背景知识足以成功注入后门，且对良性学习任务的影响极小。研究结果表明，当投毒样本利用良性数据分布未使用的方向时，模型的效果等同于未包含该投毒样本的训练模型。在其他情况下，对良性学习任务的影响也是有限的。实验结果也证实了这些理论发现。

Conclusion: 该研究证明了“一次投毒假设”，即攻击者仅用一个投毒样本和有限的背景知识即可在不显著影响良性学习任务性能的情况下，实现零后门错误地注入后门。研究为线性回归和线性分类提供了理论证明，并表明当投毒样本利用了良性数据分布未使用的方向时，模型等同于排除了投毒样本的训练模型。在其他情况下，该研究也证明了对良性学习任务的影响仍然是有限的。此外，研究还通过在实际基准数据集上的实验验证了这些理论结果。

Abstract: Backdoor injection attacks are a threat to machine learning models that are
trained on large data collected from untrusted sources; these attacks enable
attackers to inject malicious behavior into the model that can be triggered by
specially crafted inputs. Prior work has established bounds on the success of
backdoor attacks and their impact on the benign learning task, however, an open
question is what amount of poison data is needed for a successful backdoor
attack. Typical attacks either use few samples, but need much information about
the data points or need to poison many data points.
  In this paper, we formulate the one-poison hypothesis: An adversary with one
poison sample and limited background knowledge can inject a backdoor with zero
backdooring-error and without significantly impacting the benign learning task
performance. Moreover, we prove the one-poison hypothesis for linear regression
and linear classification. For adversaries that utilize a direction that is
unused by the benign data distribution for the poison sample, we show that the
resulting model is functionally equivalent to a model where the poison was
excluded from training. We build on prior work on statistical backdoor learning
to show that in all other cases, the impact on the benign learning task is
still limited. We also validate our theoretical results experimentally with
realistic benchmark data sets.

</details>


### [298] [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://arxiv.org/abs/2508.05612)
*Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai*

Main category: cs.LG

TL;DR: Shuffle-R1通过成对轨迹采样和基于优势的轨迹混洗，解决了RL微调中的优势折叠和Rollout Silencing问题，提高了MLLM的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前RL管线因优势折叠（大部分优势集中在零附近）和Rollout Silencing（贡献非零梯度的rollout比例随时间减少）而存在训练效率低下的问题，导致次优梯度更新并阻碍长期学习效率。

Method: 提出了一种名为Shuffle-R1的框架，包含（1）成对轨迹采样，选择具有大优势的高对比度轨迹以提高梯度信号质量；（2）基于优势的轨迹混洗，通过信息丰富的批次重排来增加有价值的rollout的暴露。

Result: 在多个推理基准上的实验表明，Shuffle-R1框架在开销极小的情况下，始终优于强大的RL基线。

Conclusion: Shuffle-R1框架通过动态重构轨迹采样和批次组成，提高了RL微调效率，并在多个推理基准上取得了优于现有RL基线的结果，同时开销极小。研究强调了以数据为中心的适应性对于提高MLLM中RL训练效率的重要性。

Abstract: Reinforcement learning (RL) has emerged as an effective post-training
paradigm for enhancing the reasoning capabilities of multimodal large language
model (MLLM). However, current RL pipelines often suffer from training
inefficiencies caused by two underexplored issues: Advantage Collapsing, where
most advantages in a batch concentrate near zero, and Rollout Silencing, where
the proportion of rollouts contributing non-zero gradients diminishes over
time. These issues lead to suboptimal gradient updates and hinder long-term
learning efficiency. To address these issues, we propose Shuffle-R1, a simple
yet principled framework that improves RL fine-tuning efficiency by dynamically
restructuring trajectory sampling and batch composition. It introduces (1)
Pairwise Trajectory Sampling, which selects high-contrast trajectories with
large advantages to improve gradient signal quality, and (2) Advantage-based
Trajectory Shuffle, which increases exposure of valuable rollouts through
informed batch reshuffling. Experiments across multiple reasoning benchmarks
show that our framework consistently outperforms strong RL baselines with
minimal overhead. These results highlight the importance of data-centric
adaptations for more efficient RL training in MLLM.

</details>


### [299] [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](https://arxiv.org/abs/2508.05629)
*Yongliang Wu,Yizhou Zhou,Zhou Ziheng,Yingzhe Peng,Xinyu Ye,Xinting Hu,Wenbo Zhu,Lu Qi,Ming-Hsuan Yang,Xu Yang*

Main category: cs.LG

TL;DR: 通过动态调整（DFT）改进了大型语言模型的监督微调（SFT），提高了泛化能力，并在多个基准测试中表现优于标准SFT。


<details>
  <summary>Details</summary>
Motivation: 解决监督微调（SFT）相比强化学习（RL）在泛化能力上的局限性。

Method: 通过数学分析揭示标准SFT梯度中存在的限制泛化能力的潜在奖励结构，并提出动态微调（DFT）方法，通过动态缩放目标函数来稳定每个token的梯度更新。

Result: 动态微调（DFT）在多个具有挑战性的基准测试和基础模型上显著优于标准SFT，展示了更强的泛化能力。此外，该方法在离线强化学习设置中也取得了有竞争力的结果。

Conclusion: 该研究提出了动态调整（DFT）作为监督微调（SFT）的改进方法，通过动态缩放目标函数来稳定梯度更新，从而提高泛化能力。DFT在多个基准测试和模型上显著优于标准SFT，并在离线强化学习设置中取得了有竞争力的结果，提供了一种更简单有效的替代方案。

Abstract: We present a simple yet theoretically motivated improvement to Supervised
Fine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited
generalization compared to reinforcement learning (RL). Through mathematical
analysis, we reveal that standard SFT gradients implicitly encode a problematic
reward structure that may severely restrict the generalization capabilities of
model. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing
gradient updates for each token by dynamically rescaling the objective function
with the probability of this token. Remarkably, this single-line code change
significantly outperforms standard SFT across multiple challenging benchmarks
and base models, demonstrating greatly improved generalization. Additionally,
our approach shows competitive results in offline RL settings, offering an
effective yet simpler alternative. This work bridges theoretical insight and
practical solutions, substantially advancing SFT performance. The code will be
available at https://github.com/yongliang-wu/DFT.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [300] [Causal Interventions Beyond Time: A CP-do(C)-Calculus for Indefinite Quantum Order](https://arxiv.org/abs/2508.04737)
*Jordi Vallverdu*

Main category: quant-ph

TL;DR: 将do-calculus扩展到量子系统，并发现不确定的因果顺序会导致Rule 2失败。


<details>
  <summary>Details</summary>
Motivation: 澄清为什么在量子信息科学中必须修改手术干预、忠实性和反事实依赖性的经典概念。

Method: 将Pearl的三条do-calculus规则的语言改写为完全正（CP）迹保持映射，并将其扩展到具有纠缠的量子系统。

Result: 证明了当底层过程允许不确定的因果顺序时，Rule 2会失败，并在一个三量子比特的“量子开关”电路上展示了这种失败。

Conclusion: CP-do(C)-calculus为因果建模提供了通用语法，涵盖经典、确定顺序量子和不确定顺序量子系统。

Abstract: We reformulate Pearl's three rules of do-calculus in the language of
completely positive (CP) trace-preserving maps, thereby extending them to
quantum systems with entanglement. We prove that Rule~2 fails whenever the
underlying process admits indefinite causal order, and we demonstrate this
failure in a three-qubit ``quantum switch'' circuit. Our analysis clarifies why
the classical notions of surgical intervention, faithfulness, and
counterfactual dependence must be revised in quantum information science. The
CP-do($C$)-calculus introduced here provides a common syntax for causal
modelling across classical, definite-order quantum, and indefinite-order
quantum regimes.

</details>


### [301] [Comment on "Energy-speed relationship of quantum particles challenges Bohmian mechanics"](https://arxiv.org/abs/2508.04756)
*Aurélien Drezet,Dustin Lazarovici,Bernard Michael Nabet*

Main category: quant-ph

TL;DR: Sharaglazova等人的研究声称实验结果挑战了玻姆力学，但该分析表明实验结果与玻姆力学预测一致，挑战无效。


<details>
  <summary>Details</summary>
Motivation: 指出Sharaglazova等人的研究中关于玻姆粒子动力学有效性的论点是错误的，并澄清实验结果与玻姆力学完全一致。

Method: 通过对光学微腔实验中观察到的人口转移进行分析，并仅依赖于单粒子玻姆引导方程来解释。

Result: 实验结果与玻姆力学预测一致，操作上定义的测量速度与玻姆力学中的粒子速度无关。

Conclusion: 实验结果与玻姆力学的预测一致，作者的挑战无效。

Abstract: In their recent paper [Nature 643, 67 (2025)], Sharaglazova et al. report an
optical microcavity experiment yielding an "energy-speed relationship" for
quantum particles in evanescent states, which they infer from the observed
population transfer between two coupled waveguides. The authors argue that
their findings challenge the validity of Bohmian particle dynamics because,
according to the Bohmian guiding equation, the velocities in the classically
forbidden region would be zero. In this note, we explain why this claim is
false and the experimental findings are in perfect agreement with Bohmian
mechanics. We also clarify why the operationally defined speeds reported in the
paper are unrelated to particle velocities in the sense described by Bohmian
mechanics. In contrast to other recent replies, our analysis relies solely on
the standard Bohmian guidance equation for single particles.

</details>


### [302] [Power and Limitations of Linear Programming Decoder for Quantum LDPC Codes](https://arxiv.org/abs/2508.04769)
*Shouzhen Gu,Mehdi Soleimanifar*

Main category: quant-ph

TL;DR: 该研究发现，量子LDPC码的LP解码在处理某些错误模式时存在局限性。通过引入有序统计解码（OSD）作为后处理步骤，可以显著提高LP解码器的性能，使其在中等规模编码上优于信念传播算法。


<details>
  <summary>Details</summary>
Motivation: 解码量子纠错码是实现容错量子计算的关键挑战。在经典情况下，线性规划（LP）解码器提供可证明的性能保证，并且可以利用快速的实际优化算法。尽管已经提出了用于量子码的LP解码器，但它们的性能和局限性仍然相对未被充分探索。

Method: 本研究揭示了LP解码在量子低密度奇偶校验（LDPC）码中的一个关键限制：某些恒定权重错误模式会导致模糊的分数解，无法通过独立舍入解决。为了解决这个问题，我们结合了被称为有序统计解码（OSD）的后处理技术，这在实践中显著提高了LP解码的性能。

Result: 结果表明，当与OSD结合时，LP解码可以 outperforming（优于）具有相同后处理的信念传播，尤其是在多达数百个量子比特的中等规模编码上。

Conclusion: LP解码，当与OSD结合时，对于多达数百个量子比特的中等规模编码，其性能优于具有相同后处理的信念传播，这表明基于LP的解码器，配备有效的后处理，为解码近期量子LDPC编码提供了一种有前途的方法。

Abstract: Decoding quantum error-correcting codes is a key challenge in enabling
fault-tolerant quantum computation. In the classical setting, linear
programming (LP) decoders offer provable performance guarantees and can
leverage fast practical optimization algorithms. Although LP decoders have been
proposed for quantum codes, their performance and limitations remain relatively
underexplored. In this work, we uncover a key limitation of LP decoding for
quantum low-density parity-check (LDPC) codes: certain constant-weight error
patterns lead to ambiguous fractional solutions that cannot be resolved through
independent rounding. To address this issue, we incorporate a post-processing
technique known as ordered statistics decoding (OSD), which significantly
enhances LP decoding performance in practice. Our results show that LP
decoding, when augmented with OSD, can outperform belief propagation with the
same post-processing for intermediate code sizes of up to hundreds of qubits.
These findings suggest that LP-based decoders, equipped with effective
post-processing, offer a promising approach for decoding near-term quantum LDPC
codes.

</details>


### [303] [QFOR: A Fidelity-aware Orchestrator for Quantum Computing Environments using Deep Reinforcement Learning](https://arxiv.org/abs/2508.04974)
*Hoa T. Nguyen,Muhammad Usman,Rajkumar Buyya*

Main category: quant-ph

TL;DR: QFOR是一个利用深度强化学习的量子任务编排框架，通过自适应调度提高了异构量子云的保真度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有量子云服务中的硬件异构性和噪声问题，导致任务分配和调度优化复杂化，传统启发式方法难以适应动态变化或平衡保真度和时间，因此需要一种能够适应动态条件并有效平衡执行保真度和时间的调度方法。

Method: 提出了一种名为QFOR的量子保真度感知任务编排框架，该框架使用深度强化学习（具体为近端策略优化算法）将量子任务编排建模为马尔可夫决策过程，并利用IBM量子处理器校准数据进行感知噪声的性能估计，以学习自适应调度策略。

Result: QFOR框架表现出自适应性，在提供可配置的保真度和时间平衡能力的同时，相比于启发式基线方法，在相对保真度性能上实现了29.5%-84%的显著提升，且执行时间相当，有助于实现量子计算资源的成本效益。

Conclusion: QFOR框架通过深度强化学习实现异构量子节点上量子任务的自适应调度，在保证执行时间的同时，显著提高了量子任务的执行保真度（29.5%-84%），实现了量子计算资源的高效利用。

Abstract: Quantum cloud computing enables remote access to quantum processors, yet the
heterogeneity and noise of available quantum hardware create significant
challenges for efficient resource orchestration. These issues complicate the
optimization of quantum task allocation and scheduling, as existing heuristic
methods fall short in adapting to dynamic conditions or effectively balancing
execution fidelity and time. Here, we propose QFOR, a Quantum Fidelity-aware
Orchestration of tasks across heterogeneous quantum nodes in cloud-based
environments using Deep Reinforcement learning. We model the quantum task
orchestration as a Markov Decision Process and employ the Proximal Policy
Optimization algorithm to learn adaptive scheduling policies, using IBM quantum
processor calibration data for noise-aware performance estimation. Our
configurable framework balances overall quantum task execution fidelity and
time, enabling adaptation to different operational priorities. Extensive
evaluation demonstrates that QFOR is adaptive and achieves significant
performance with 29.5-84% improvements in relative fidelity performance over
heuristic baselines. Furthermore, it maintains comparable quantum execution
times, contributing to cost-efficient use of quantum computation resources.

</details>


### [304] [Ergotopy transport in a one dimensional spin chain](https://arxiv.org/abs/2508.04770)
*Dara Murphy,Anthony Kiely,Irene D'Amico,Steve Campbell*

Main category: quant-ph

TL;DR: 该研究探讨了能量如何在具有可调耦合的量子电池链中传输，发现量子相干性在能量传输方面优于反转状态，并且 PST 耦合在能量传输和稳定性方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 研究能量传输，特别是可提取功（能量）在自旋链中的传输，以及能量初始状态对能量传输能力的影响。

Method: 通过对量子电池进行建模，研究了可提取功（以能量度量）在具有可调交换耦合的自旋链中的传输。

Result: 对于非 PST 耦合，量子相干性比反转状态能更有效地传输能量。对于 PST 耦合，相干能量赋予更具鲁棒性。

Conclusion: 对于非 PST 耦合，当能量初始赋予量子相干性时，存在明显优势，且能量传输更有效率。对于 PST 耦合，研究了其对无序的鲁棒性，并再次证明了相干能量赋予的优势。PST 耦合在切换相互作用时的能量成本波动更小，表明其更稳定。

Abstract: We examine the transport of useful energy, i.e. extractable work as
quantified by the ergotropy, along a spin chain with tuneable exchange
couplings between the sites. We focus on, and interpolate between, the two
physically relevant limits of uniform interaction strengths and engineered
couplings which achieve perfect state transfer (PST). By modelling the
individual constituents as quantum batteries, we consider how the manner in
which the extractable work appears in the initial state of the first site
impacts the chain's ability to transport ergotropy to the final site. For
non-PST couplings, we establish that there is a clear quantum advantage when
the ergotropy is initially endowed in quantum coherences and demonstrate that
this ergotropy is more efficiently transferred. For extractable work encoded in
a population inverted state, we show that this considerably limits the length
of chain over which any ergotropy can be faithfully transported. For PST
couplings, we consider the robustness to disorder and again demonstrate a
quantum advantage for coherently endowed ergotropy. Finally, we examine the
work probability distribution associated with quenching on the interactions
which provides insight into the work cost in switching on the couplings. We
show that PST couplings lead to smaller fluctuations in this work cost,
indicating that they are more stable.

</details>


### [305] [Universal quantum phase classification on quantum computers from machine learning](https://arxiv.org/abs/2508.04774)
*Weicheng Ye,Shuwei Liu,Shiyu Zhou,Yijian Zou*

Main category: quant-ph

TL;DR: 提出了一种结合量子 தேர்ந்தெடுக்க线描法和时间序列机器学习的新框架，用于高效、实用地对量子物态相进行分类。


<details>
  <summary>Details</summary>
Motivation: 量子物态相的分类是凝聚态物理中的一个基本挑战，需要更高效实用的方法。

Method: 结合了量子 தேர்ந்தெடுக்க线描法和现代时间序列机器学习模型，通过对代表性量子态应用Haar随机演化来生成训练数据，并利用时间序列模型处理数据以进行分类。

Result: 在包括Ising模型和ANNNI模型在内的量子自旋链上进行了测试，结果与已知的相边界非常吻合，验证了该方法的通用性和多样性。

Conclusion: 该方法可以有效地对量子相进行分类，实现了不依赖于局域序参量的通用量子相分类。

Abstract: The classification of quantum phases of matter remains a fundamental
challenge in condensed matter physics. We present a novel framework that
combines shadow tomography with modern time-series machine learning models to
enable efficient and practical quantum phase classification. Our approach
leverages the definition of quantum phases based on connectivity through
finite-depth local unitary circuits, generating abundant training data by
applying Haar random evolution to representative quantum states for a given
phase. In this way, the training data can be efficiently obtained from a
quantum simulator. Additionally, we demonstrate that advanced time-series
models can be used to process the training data and achieve universal quantum
phase classification that does not rely on local order parameters. To validate
the universality and versatility of our method, we test the model against
one-dimensional quantum spin chains such as the Ising model and the axial
next-nearest-neighbor Ising (ANNNI) model, showing excellent agreement with
known phase boundaries.

</details>


### [306] [Absolutely maximally entangled pure states of multipartite quantum systems](https://arxiv.org/abs/2508.04777)
*Grzegorz Rajchel-Mieldzioć,Rafał Bistroń,Albert Rico,Arul Lakshminarayan,Karol Życzkowski*

Main category: quant-ph

TL;DR: 本文对绝对极大纠缠（AME）纯态的生成技术进行了更新调查，并分析了其相关性质。


<details>
  <summary>Details</summary>
Motivation: AME纯态因其在量子信息处理中的应用而受到关注，包括多用户隐写术、量子错误纠正和秘密共享。

Method: 本文提出了一种对AME投影仪得到的归约状态的纠缠度进行分析的方法，并对GHZ状态的对称叠加得到的AAME状态进行了研究。

Result: 本文对AME纯态的生成技术进行了更新的调查，并分析了部分追踪AAME投影仪产生的缩减状态的纠缠度。

Conclusion: 该论文提供了绝对极大纠缠（AME）纯态的更新调查，包括超越图和稳定器状态的标准构造的技术。

Abstract: Absolutely maximally entangled (AME) pure states of a system composed of $N$
parties are distinguished by the property that for any splitting at least one
partial trace is maximally mixed. Due to maximal possible correlations between
any two selected subsystems these states have numerous applications in various
fields of quantum information processing including multi-user teleportation,
quantum error correction and secret sharing. We present an updated survey of
various techniques to generate such strongly entangled states, including those
going beyond the standard construction of graph and stabilizer states. Our
contribution includes, in particular, analysis of the degree of entanglement of
reduced states obtained by partial trace of AME projectors, states obtained by
a symmetric superposition of GHZ states, an orthogonal frequency square
representation of the "golden" AME state and an updated summary of the number
of local unitary equivalence classes.

</details>


### [307] [Excising dead components in the surface code using minimally invasive alterations: A performance study](https://arxiv.org/abs/2508.04786)
*Ryan V. Mishmash,Vadym Kliuchnikov,Juan Bello-Rivas,Adam Paetznick,David Aasen,Christina Knapp,Yue Wu,Bela Bauer,Marcus P. da Silva,Parsa Bonderson*

Main category: quant-ph

TL;DR: 该研究提出了一种名为 MIA 的方案，用于在存在有缺陷组件的情况下，在量子计算机的表面代码中进行误差纠正。该方案能有效剔除有缺陷组件，同时最大限度地利用可用组件并保持一致的操作计划。此外，还开发了自动计算检查基的技术。这些方法在电路级噪声下进行了广泛的模拟，并展示了最先进的性能，可用于基于测量和基于 CNOT 的电路。


<details>
  <summary>Details</summary>
Motivation: 在易出错的量子计算机中，需要一种量子误差纠正协议来处理有缺陷的物理组件，同时最大程度地利用可用组件并保持一致的全局操作计划。

Method: 通过对存在缺陷组件的成对测量表面代码协议进行广泛的数值模拟，并在电路级别噪声下进行测试。

Result: 所提出的 MIA 方案能够有效地从表面代码中剔除有缺陷的组件，同时满足使用相同的原生操作集、最大化利用功能组件和使用一致的全局操作计划这三个标准。此外，还描述了在没有手动电路注释的情况下从电路自动构建高性能检查基的技术。

Conclusion: 所提出的最小干预改动（MIA）方案以及自动检查基计算方法可以轻松地与基于测量的电路和基于 CNOT 的电路一起使用，并且所呈现的结果展示了最先进的性能。

Abstract: The physical implementation of a large-scale error-corrected quantum
processor will necessarily need to mitigate the presence of defective (thereby
"dead") physical components in its operation, for example, identified during
bring-up of the device or detected in the middle of a computation. In the
context of solid-state qubits, the quantum error correcting protocol operating
in the presence of dead components should ideally (i) use the same native
operation set as that without dead components, (ii) maximize salvaging of
functional components, and (iii) use a consistent global operating schedule
which optimizes logical qubit performance and is compatible with the control
requirements of the system. The scheme proposed by Grans-Samuelsson et al.
[Quantum 8, 1429 (2024)] satisfies all three of these criteria: it effectively
excises (cuts out) dead components from the surface code using minimally
invasive alterations (MIA). We conduct extensive numerical simulations of this
proposal for the pairwise-measurement-based surface code protocol in the
presence of dead components under circuit-level noise. To that end, we also
describe techniques to automatically construct performant check (detector)
bases directly from circuits without manual circuit annotation, which may be of
independent interest. Both the MIA scheme and this automated check basis
computation can be readily used with measurement-based as well as CNOT-based
circuits, and the results presented here demonstrate state-of-the-art
performance.

</details>


### [308] [Automorphism gadgets in homological product codes](https://arxiv.org/abs/2508.04794)
*Noah Berthusen,Michael J. Gullans,Yifan Hong,Maryam Mudassar,Shi Jie Samuel Tan*

Main category: quant-ph

TL;DR: 研究提出了一个理论框架，用于理解和实现同调积码的逻辑操作，这些操作源于输入码的置换对称性。该框架允许仅通过量子比特置换或结合子系统电路来实现逻辑操作，并可能提供固有的容错能力，为在实践中实现容错量子计算提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 探究具有逻辑操作的结构化同调积码，特别是那些源于输入码置换对称性的操作，以期在非拓扑码平台中实现实用的容错量子计算。

Method: 提出了一种理论框架来表征由输入码的自同构产生的逻辑操作，并展示了如何通过物理量子比特置换和子系统电路的组合来实现这些操作。研究还探讨了特定对称性下仅通过量子比特置换实现逻辑操作的可能性，并分析了“自同构小工具”的容错特性。

Result: 开发了一个理论框架，用于表征由输入码的置换对称性产生的逻辑操作，并展示了这些操作的实现方式（量子比特置换和子系统电路）。证明了“自同构小工具”具有潜在的容错特性（如有效距离保持）。对现有经典线性码的文献进行了调研，并将它们纳入该框架。为同调积码的容错性研究提供了新的途径。

Conclusion: 该研究为同调积码的逻辑操作提供了一个理论框架，特别是那些源于输入码的置换对称性的操作。这些操作可以通过物理量子比特置换和子系统电路的组合来实现，在某些情况下甚至可以仅通过量子比特置换来实现。研究还表明，这些“自同构小工具”具有固有的容错特性，例如在假设物理置换免费的情况下可以保持有效距离。

Abstract: The homological product is a general-purpose recipe that forges new quantum
codes from arbitrary classical or quantum input codes, often providing enhanced
error-correcting properties. When the input codes are classical linear codes,
it is also known as the hypergraph product. We investigate structured
homological product codes that admit logical operations arising from
permutation symmetries in their input codes. We present a broad theoretical
framework that characterizes the logical operations resulting from these
underlying automorphisms. In general, these logical operations can be performed
by a combination of physical qubit permutations and a subsystem circuit. In
special cases related to symmetries of the input Tanner graphs, logical
operations can be performed solely through qubit permutations. We further
demonstrate that these "automorphism gadgets" can possess inherent
fault-tolerant properties such as effective distance preservation, assuming
physical permutations are free. Finally, we survey the literature of classical
linear codes with rich automorphism structures and show how various classical
code families fit into our framework. Complementary to other fault-tolerant
gadgets for homological product codes, our results further advance the search
for practical fault tolerance beyond topological codes in platforms capable of
long-range connectivity.

</details>


### [309] [Dissipative Dynamics and Symmetry Breaking in Bosonic Sachdev-Ye-Kitaev Lindbladian](https://arxiv.org/abs/2508.04802)
*Yifei Liu,Anish Kulkarni,Shinsei Ryu*

Main category: quant-ph

TL;DR: A bosonic SYK model coupled to a Lindbladian environment shows a rich phase structure with symmetry breaking and phase transitions due to dissipation, potentially leading to novel steady states and metastable phases.


<details>
  <summary>Details</summary>
Motivation: Investigating a bosonic variant of the Sachdev-Ye-Kitaev (SYK) model coupled to a Lindbladian environment, focusing on the interplay between quantum many-body dynamics and dissipation.

Method: Using the Schwinger-Keldysh path integral formalism in the large-N limit

Result: The dissipation can partially tame the instability of the inverted potential, leading to novel steady-state phases.

Conclusion: We identify regimes with multiple competing saddle points and discuss potential implications for the landscape of metastable states.

Abstract: We investigate a bosonic variant of the Sachdev-Ye-Kitaev (SYK) model coupled
to a Lindbladian environment, focusing on the interplay between quantum
many-body dynamics and dissipation. Using the Schwinger-Keldysh path integral
formalism in the large-N limit, we uncover a rich phase structure, including
symmetry breaking and phase transitions. Our results suggest that the
dissipation can partially tame the instability of the inverted potential,
leading to novel steady-state phases. We also identify regimes with multiple
competing saddle points and discuss potential implications for the landscape of
metastable states.

</details>


### [310] [Minimum-Weight Parity Factor Decoder for Quantum Error Correction](https://arxiv.org/abs/2508.04969)
*Yue Wu,Binghong Li,Kathleen Chang,Shruti Puri,Lin Zhong*

Main category: quant-ph

TL;DR: HyperBlossom统一了量子纠错解码，通过将MLE解码转化为MWPF问题并泛化花算法，提高了解码精度和效率，其软件Hyperion在多项基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展的容错量子计算，需要快速准确的量子纠错（QEC）解码。然而，最大似然错误（MLE）解码虽然接近最优，但在通用的量子低密度奇偶校验（qLDPC）码上难以处理，通常依赖于近似和启发式方法。

Method: 提出了一种名为HyperBlossom的统一框架，将最大似然错误（MLE）解码转化为最小权重奇偶校验因子（MWPF）问题。该框架通过类似原始对偶线性规划模型将花算法推广到超图，并提供了可认证的邻近界限。

Result: Hyperion软件实现了HyperBlossom框架，在距离为11的表面码上，其逻辑错误率比MWPM解码器低4.8倍；在双变量自行车码上，其逻辑错误率比BPOSD解码器低1.6倍。该框架在表面码和颜色码上实现了近乎线性的平均运行时扩展，在代码容量噪声下可达距离99，在电路级噪声下可达距离31。

Conclusion: HyperBlossom框架成功将MLE解码统一为MWPF问题，并泛化了花算法到超图，弥合了启发式和认证解码器之间的差距。其软件实现Hyperion在表面码和双变量自行车码上均表现出优于现有解码器的性能，并在大距离下实现了近乎线性的运行时扩展。

Abstract: Fast and accurate quantum error correction (QEC) decoding is crucial for
scalable fault-tolerant quantum computation. Most-Likely-Error (MLE) decoding,
while being near-optimal, is intractable on general quantum Low-Density
Parity-Check (qLDPC) codes and typically relies on approximation and
heuristics. We propose HyperBlossom, a unified framework that formulates MLE
decoding as a Minimum-Weight Parity Factor (MWPF) problem and generalizes the
blossom algorithm to hypergraphs via a similar primal-dual linear programming
model with certifiable proximity bounds. HyperBlossom unifies all the existing
graph-based decoders like (Hypergraph) Union-Find decoders and Minimum-Weight
Perfect Matching (MWPM) decoder, thus bridging the gap between heuristic and
certifying decoders.
  We implement HyperBlossom in software, namely Hyperion. Hyperion achieves a
4.8x lower logical error rate compared to the MWPM decoder on the distance-11
surface code and 1.6x lower logical error rate compared to a fine-tuned BPOSD
decoder on the $[[90, 8, 10]]$ bivariate bicycle code under code-capacity
noise. It also achieves an almost-linear average runtime scaling on both the
surface code and the color code, with numerical results up to sufficiently
large code distances of 99 and 31 for code-capacity noise and circuit-level
noise, respectively.

</details>


### [311] [Non-Hermitian Quantum Metrology Enhancement and Skin Effect Suppression in PT-Symmetric Bardeen-Cooper-Schrieffer Chains](https://arxiv.org/abs/2508.04815)
*Harshank Matkar*

Main category: quant-ph

TL;DR: 本研究提出了非厄米量子计量学的理论框架，发现在非厄米皮肤效应相中灵敏度指数级降低，而在 PT 对称破缺点附近灵敏度呈二次增强，达到海森堡极限。研究结果为提高量子计量精度提供了理论指导和实验方案。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为非厄米系统中的量子计量学提供一个理论框架，并展示 PT 对称 Bardeen-Cooper-Schrieffer 链中的显著失败和特殊机制。

Method: 通过双正交量子费雪信息分析，识别出两种不同的模式：在非厄米皮肤效应（NHSE）相中灵敏度呈指数级抑制（$F_Q \propto N^3 e^{-2\kappa N}$），其中本征态呈指数级局域化；在 PT 破缺的厄能点附近，灵敏度呈二次增强（$F_Q \propto N^2/\delta$），达到海森堡极限。通过多参数分析，确定了化学势、皮尔茨相位和增益/损耗强度同时估计的最佳方案，量子费雪信息矩阵的标度为 $N^2$，超过标准量子极限的因子超过 $10^2$。

Result: 对于实际参数（$t/2\pi=10$ MHz, $\Delta/2\pi=1$ MHz, $N=50$），化学势估计的增强因子 $\eta_\mu \approx 20\sqrt{N}=141$，相位估计的增强因子 $\eta_\phi \approx t^2 \sqrt{3N/2}=100\sqrt{N}$，均超过经典传感。这些结果通过精确的有限尺寸计算得到验证，并为超导电路实现提供了具体的方案。

Conclusion: 非厄米系统中的量子计量学存在核心二分法：NHSE 指数级抑制灵敏度，而 PT 对称性则能够实现海森堡极限增强，这两种情况都源于不同的谱和局域化拓扑。

Abstract: We outline a theoretical framework for quantum metrology in non-Hermitian
systems, demonstrating both significant failure and exceptional regimes in
PT-symmetric Bardeen-Cooper-Schrieffer chains. Through biorthogonal quantum
Fisher information analysis, we identify two distinct regimes: exponential
sensitivity suppression in the non-Hermitian skin effect phase ($F_Q \propto
N^3 e^{-2\kappa N}$) where eigenstates localize exponentially, and quadratic
enhancement near PT-breaking exceptional points [1-4] ($F_Q \propto
N^2/\delta$) achieving Heisenberg scaling. Our multiparameter analysis
establishes optimal simultaneous estimation of chemical potential, Peierls
phase, and gain/loss strength with quantum Fisher information matrix scaling as
$N^2$, surpassing the standard quantum limit by factors exceeding $10^2$. For
realistic parameters ($t/2\pi=10$ MHz, $\Delta/2\pi=1$ MHz, $N=50$), we predict
enhancement factors $\eta_\mu \approx 20\sqrt{N}=141$ for chemical potential
estimation and $\eta_\phi \approx t^2 \sqrt{3N/2}=100\sqrt{N}$ over classical
sensing. These results are validated through exact finite-size calculations and
provide concrete protocols for superconducting circuit implementations.We
reveal a core dichotomy in non-Hermitian quantum metrology: NHSE suppresses
sensitivity exponentially, while $\mathcal{PT}$-symmetry enables
Heisenberg-limited enhancement -- each arising from distinct spectral and
localization topologies.

</details>


### [312] [Hybrid oscillator-qudit quantum processors: stabilizer states and symplectic operations](https://arxiv.org/abs/2508.04819)
*Sayan Chakraborty,Victor V. Albert*

Main category: quant-ph

TL;DR: 本研究将GKP量子格形式主义扩展到混合量子系统，实现了更强的纠错能力，并构建了通用的混合纠错码。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将GKP量子格形式主义推广到离散和连续变量系统的组合，以期在量子信息处理中实现更强大的纠错能力和资源。

Method: 我们构建了离散和连续变量系统的稳定器状态和纠错码的混合量子格形式主义，将qudit的离散相空间嵌入到由谐振荡器的连续变量参数化的混合相空间中。我们通过应用条件位移到GKP状态和Pauli特征态，或将稳定器状态的物理qudit编码到GKP码中来获得简单的混合状态。我们通过将稳定器码与非交换环相关联并利用Morita等价性获得逻辑算符来构建通用混合纠错码。

Result: 我们成功构建了混合量子格形式主义，能够同时测量任意大的非对易位置和动量位移。我们还展示了如何获得混合状态，并成功构建了通用的混合纠错码，为未来的量子纠错研究提供了新的途径。

Conclusion: 我们提出的框架通过将离散相空间嵌入混合相空间，并完全由谐振荡器的连续变量参数化，从而概括了GKP量子格形式主义。该框架允许同时测量任意大的非对易位置和动量位移范围，并提供了使用条件位移或将物理qudit编码到GKP码中的方法。通过将稳定器码与非交换环联系起来，并利用Morita等价性获得逻辑算符，我们构建了通用的混合纠错码，并提供了使用交换矩阵、整数辛矩阵和二进制码的示例。

Abstract: We construct stabilizer states and error-correcting codes on combinations of
discrete- and continuous-variable systems, generalizing the
Gottesman-Kitaev-Preskill (GKP) quantum lattice formalism. Our framework
absorbs the discrete phase space of a qudit into a hybrid phase space
parameterizable entirely by the continuous variables of a harmonic oscillator.
The unit cell of a hybrid quantum lattice grows with the qudit dimension,
yielding a way to simultaneously measure an arbitrarily large range of
non-commuting position and momentum displacements. Simple hybrid states can be
obtained by applying a conditional displacement to a Gottesman-Kitaev-Preskill
(GKP) state and a Pauli eigenstate, or by encoding some of the physical qudits
of a stabilizer state into a GKP code. The states' oscillator-qudit
entanglement cannot be generated using symplectic (i.e., Gaussian-Clifford)
operations, distinguishing them as a resource from tensor products of
oscillator and qudit stabilizer states. We construct general hybrid
error-correcting codes by relating stabilizer codes to non-commutative tori and
obtaining logical operators via Morita equivalence. We provide examples using
commutation matrices, integer symplectic matrices, and binary codes.

</details>


### [313] [Q-DPTS: Quantum Differentially Private Time Series Forecasting via Variational Quantum Circuits](https://arxiv.org/abs/2508.05036)
*Chi-Sheng Chen,Samuel Yen-Chi Chen*

Main category: quant-ph

TL;DR: Q-DPTS是一种混合量子经典框架，通过结合VQC、每样本梯度裁剪和高斯噪声注入来实现量子差分隐私时间序列预测。在ETT数据集上的结果表明，在相同的隐私预算下，它比经典的和量子的基线具有更低的预测误差，实现了更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 在金融和能源系统等数据敏感性至关重要的领域，时间序列预测至关重要。虽然差分隐私（DP）为保护个人数据贡献提供了理论保证，但其集成（尤其是在DP-SGD中）常常会因注入的噪声而损害模型性能。

Method: 提出了一种名为Q-DPTS的混合量子经典框架，用于量子差分隐私时间序列预测。Q-DPTS结合了变分量子电路（VQC）、每样本梯度裁剪和高斯噪声注入，以确保严格的$(\epsilon, \delta)$-差分隐私。

Result: 在ETT（电力变压器温度）数据集上评估了Q-DPTS，这是一个标准的长期时间序列预测基准。与包括LSTM、QASA、QRWKV和QLSTM在内的经典和量子基线相比，我们的方法在相同的隐私预算下始终实现了更低的预测误差，表明了有利的隐私-效用权衡。

Conclusion: 这项工作是对增强量子差分隐私预测的首次探索之一，为隐私关键场景中的安全准确的时间序列建模提供了有前景的方向。

Abstract: Time series forecasting is vital in domains where data sensitivity is
paramount, such as finance and energy systems. While Differential Privacy (DP)
provides theoretical guarantees to protect individual data contributions, its
integration especially via DP-SGD often impairs model performance due to
injected noise. In this paper, we propose Q-DPTS, a hybrid quantum-classical
framework for Quantum Differentially Private Time Series Forecasting. Q-DPTS
combines Variational Quantum Circuits (VQCs) with per-sample gradient clipping
and Gaussian noise injection, ensuring rigorous $(\epsilon,
\delta)$-differential privacy. The expressiveness of quantum models enables
improved robustness against the utility loss induced by DP mechanisms. We
evaluate Q-DPTS on the ETT (Electricity Transformer Temperature) dataset, a
standard benchmark for long-term time series forecasting. Our approach is
compared against both classical and quantum baselines, including LSTM, QASA,
QRWKV, and QLSTM. Results demonstrate that Q-DPTS consistently achieves lower
prediction error under the same privacy budget, indicating a favorable
privacy-utility trade-off. This work presents one of the first explorations
into quantum-enhanced differentially private forecasting, offering promising
directions for secure and accurate time series modeling in privacy-critical
scenarios.

</details>


### [314] [Quantum Graph States: Bridging Classical Theory and Quantum Innovation, Workshop Summary](https://arxiv.org/abs/2508.04823)
*Eric Chitambar,Kenneth Goodenough,Otfried Gühne,Rose McCarty,Simon Perdrix,Vito Scarola,Shuo Sun,Quntao Zhang*

Main category: quant-ph

TL;DR: 图论和量子信息科学交叉领域的研讨会，重点关注量子图态及其应用。挑战包括可扩展的纠缠生成和理论理解。建议加强跨学科合作以解决开放性问题。


<details>
  <summary>Details</summary>
Motivation: 本次研讨会的目的是探索经典图论和量子信息科学的交叉点，特别关注量子图态及其在计算、网络和传感中的应用。

Method: 本次研讨会汇集了经典图论和量子信息科学的专家，重点关注量子图态及其在计算、网络和传感中的应用。讨论的关键领域包括秩宽度、顶点 दिसते和超图等图论结构在测量基量子计算、容错架构和分布式量子传感中的作用。

Result: 研讨会重点介绍了图论结构（如秩宽度、顶点 दिसते和超图）在测量基量子计算、容错架构和分布式量子传感中的基础作用，并确定了可扩展纠缠生成、鲁棒基准测试和对广义图态的更深入的理论理解等关键挑战。

Conclusion: 本次研讨会总结了图论和量子信息科学交叉领域的进展，强调了可扩展的纠缠生成、鲁棒的基准测试方法以及对广义图态的深入理论理解等关键挑战。会议最后提出了有针对性的研究建议，强调跨学科合作以解决纠缠结构、模拟复杂性和量子平台实验实现等开放性问题。

Abstract: This workshop brought together experts in classical graph theory and quantum
information science to explore the intersection of these fields, with a focus
on quantum graph states and their applications in computing, networking, and
sensing. The sessions highlighted the foundational role of graph-theoretic
structure, such as rank-width, vertex-minors, and hypergraphs, in enabling
measurement-based quantum computation, fault-tolerant architectures, and
distributed quantum sensing. Key challenges identified include the need for
scalable entanglement generation, robust benchmarking methods, and deeper
theoretical understanding of generalized graph states. The workshop concluded
with targeted research recommendations, emphasizing interdisciplinary
collaboration to address open problems in entanglement structure, simulation
complexity, and experimental realization across diverse quantum platforms.

</details>


### [315] [Joint parameter estimation and multidimensional reconciliation for CV-QKD](https://arxiv.org/abs/2508.05558)
*Jisheng Dai,Xue-Qin Jiang,Peng Huang,Tao Wang,Guihua Zeng*

Main category: quant-ph

TL;DR: 本研究提出了一种新颖的联合消息传递方案，在贝叶斯框架内统一了量子密钥分发中的信道参数估计和信息协调，通过期望最大化（EM）算法和混合多维旋转方案提高了效率并减少了开销。


<details>
  <summary>Details</summary>
Motivation: 为了有效的信息协调，需要准确的量子信道参数估计，但传统的最大似然（ML）估计器会丢弃大量数据，导致符号效率低下，并且估计和协调阶段的分离会引入误差传播。

Method: 提出了一种新颖的联合消息传递方案，在贝叶斯框架内统一了信道参数估计和信息协调。通过利用期望最大化（EM）算法，该方法在解码过程中同时估计未知参数，无需单独的最大似然估计。此外，还引入了一种混合多维旋转方案，消除了对范数反馈的要求。

Result: 通过期望最大化（EM）算法在解码过程中同时估计未知参数，无需单独的最大似然估计。引入混合多维旋转方案，消除了对范数反馈的要求，显著降低了经典信道开销。

Conclusion: 该研究首次将多维协调和信道参数估计统一在量子密钥分发中，为高效率协调和最小化导引头提供了实际解决方案。

Abstract: Accurate quantum channel parameter estimation is essential for effective
information reconciliation in continuous-variable quantum key distribution
(CV-QKD). However, conventional maximum likelihood (ML) estimators rely on a
large amount of discarded data (or pilot symbols), leading to a significant
loss in symbol efficiency. Moreover, the separation between the estimation and
reconciliation phases can introduce error propagation. In this paper, we
propose a novel joint message-passing scheme that unifies channel parameter
estimation and information reconciliation within a Bayesian framework. By
leveraging the expectation-maximization (EM) algorithm, the proposed method
simultaneously estimates unknown parameters during decoding, eliminating the
need for separate ML estimation. Furthermore, we introduce a hybrid
multidimensional rotation scheme that removes the requirement for norm
feedback, significantly reducing classical channel overhead. To the best of our
knowledge, this is the first work to unify multidimensional reconciliation and
channel parameter estimation in CV-QKD, providing a practical solution for
high-efficiency reconciliation with minimal pilots.

</details>


### [316] [Exact Solutions of the Schrödinger-Dunkl Equation for a Free Particle in a Finite and Infinite Cylindrical Well](https://arxiv.org/abs/2508.04840)
*R. D. Mota,D. Ojeda-Guillén,M. Salazar-Ramírez*

Main category: quant-ph

TL;DR: 该研究使用Dunkl导数和反射算子分析了圆柱形势阱中自由粒子的薛定谔方程，得到了能量谱和波函数的精确解析解，并讨论了Dunkl参数对解奇偶性的影响。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于探索Dunkl导数和反射算子对自由粒子在圆柱形势阱中薛定谔方程解的影响，以及它们如何改变哈密顿量的结构和解的奇偶性。

Method: 该研究采用Dunkl算子和反射算子来研究自由粒子在圆柱形势阱中的薛定谔方程，并通过引入圆柱坐标系得到径向和轴向波函数的精确解析表达式，然后根据反射算子的特征值对能量谱和解进行分类。

Result: 该研究得到了在圆柱形势阱中自由粒子的薛定谔方程的精确解析解，并分析了Dunkl参数对波函数奇偶性的影响。

Conclusion: 该研究通过分析能量谱和波函数来详细阐述在圆柱形势阱中自由粒子的薛定谔方程，并考虑了Dunkl导数和反射算子对解的奇偶性的影响，最后讨论了Dunkl参数对波函数奇偶性的约束。

Abstract: In this paper, we study the Schr\"odinger equation with Dunkl derivative for
a free particle confined in a cylindrical potential well. We consider both the
finite and infinite height cases. The Dunkl formalism introduces reflection
operators that modify the structure of the Hamiltonian and affect the parity of
the solutions. By working in cylindrical coordinates, we obtain exact
analytical expressions for the radial and axial wavefunctions in terms of
Bessel functions. The energy spectrum and the solutions are classified
according to the eigenvalues of the reflection operators in the three
coordinates. We analyze in detail the conditions under which the wavefunctions
acquire definite parity and discuss the resulting constraints on the Dunkl
parameters.

</details>


### [317] [Noisy Quantum Simulation Using Tracking, Uncomputation and Sampling](https://arxiv.org/abs/2508.04880)
*Siddharth Dangwal,Tina Oberoi,Ajay Sailopal,Dhirpal Shah,Frederic T. Chong*

Main category: quant-ph

TL;DR: TUSQ 是一种新的量子模拟器，通过减少电路执行次数和重用计算，显著提高了含噪声量子电路模拟的速度和效率。


<details>
  <summary>Details</summary>
Motivation: 由于对量子硬件的访问受限，需要开发能够准确且可扩展地模拟含噪声量子硬件的模拟器。

Method: TUSQ 通过 ECM 减少了表示噪声所需的唯一电路执行次数，并通过 TEM 跨电路重用计算。TEM 将电路表示为树，通过深度优先搜索和反向计算进行采样和修剪，以减少模拟时间。

Result: TUSQ 在 186 个基准测试中，相对于 Qiskit 和 CUDA-Q 分别实现了平均 52.5 倍和 12.53 倍的加速，对于超过 15 个量子比特的更大基准测试，平均加速分别达到 55.42 倍和 23.03 倍。

Conclusion: TUSQ 通过误差表征模块 (ECM) 和基于树的执行模块 (TEM) 实现了对含噪声量子硬件的准确且可扩展的模拟，平均提速显著。

Abstract: Quantum computers have grown in size and qubit quality in recent years,
enabling the execution of complex quantum circuits. However, for most
researchers, access to compute time on quantum hardware is limited. This
necessitates the need to build simulators that mimic the execution of quantum
circuits on noisy quantum hardware accurately and scalably.
  In this work, we propose TUSQ - Tracking, Uncomputation, and Sampling for
Noisy Quantum Simulation. To represent the stochastic noisy channels
accurately, we average the output of multiple quantum circuits with fixed noisy
gates sampled from the channels. However, this leads to a substantial increase
in circuit overhead, which slows down the simulation. To eliminate this
overhead, TUSQ uses two modules: the Error Characterization Module (ECM), and
the Tree-based Execution Module (TEM).
  The ECM tracks the number of unique circuit executions needed to accurately
represent the noise. That is, if initially we needed $n_{1}$ circuit
executions, ECM reduces that number to $n_{2}$ by eliminating redundancies so
that $n_{2} < n_{1}$. This is followed by the TEM, which reuses computation
across these $n_{2}$ circuits. This computational reuse is facilitated by
representing all $n_{2}$ circuits as a tree. We sample the significant leaf
nodes of this tree and prune the remaining ones. We traverse this tree using
depth-first search. We use uncomputation to perform rollback-recovery at
several stages which reduces simulation time. We evaluate TUSQ for a total of
186 benchmarks and report an average speedup of $52.5\times$ and $12.53\times$
over Qiskit and CUDA-Q, which goes up to $7878.03\times$ and $439.38\times$
respectively. For larger benchmarks (more than than 15 qubits), the average
speedup is $55.42\times$ and $23.03\times$ over Qiskit and CUDA-Q respectively

</details>


### [318] [Fault-Tolerant Universal Quantum Computing in the Presence of Anisotropic Noise](https://arxiv.org/abs/2508.04892)
*Yang-Yang Xie,Zhao-Ming Wang,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 提出了一种利用系统-浴纠缠资源基来规避退相干的通用量子计算门集，无需量子纠错。


<details>
  <summary>Details</summary>
Motivation: 受到近期噪声操纵技术的进展启发，旨在寻找一种在退相干存在的情况下进行量子计算的方法，且无需量子纠错的额外开销。

Method: 通过一种“敷层变换”（dressing transformation）来实现，该变换能够生成一个系统-浴纠缠的资源基。当系统初始化到这个基时，计算的演化如同没有退相干一样。

Result: 证明了一类广泛的各向异性量子比特-浴耦合可以通过敷层变换来实现解耦，从而提供了一种灵活的替代方案。

Conclusion: 提出了一种在不进行量子纠错的情况下，在退相干存在的情况下运行的通用量子计算门集。该方法利用了部分可调的系统-浴耦合。

Abstract: We propose a universal gate set for quantum computing that operates in the
presence of decoherence without requiring the overhead of quantum error
correction. Inspired by recent advances in noise manipulation technologies, we
demonstrate that a broad class of anisotropic qubit-bath couplings can be
decoupled via a dressing transformation, which generates a system-bath
entangled resource basis. When initialized in this basis, the computation
evolves as if decoherence is absent. Our proposal offers a flexible alternative
to systems requiring quantum error correction by utilizing partially tunable
system-bath couplings.

</details>


### [319] [Taming coherent noise with teleportation](https://arxiv.org/abs/2508.04947)
*Kathleen Chang,Qile Su,Shruti Puri*

Main category: quant-ph

TL;DR: 通过量子比特的传送可以有效地将相干错误转化为 Pauli 错误，从而为量子纠错提供可分析和可模拟的解决方案，并可能消除对随机编译的需求。


<details>
  <summary>Details</summary>
Motivation: 相干错误在量子计算和量子纠错中带来了新的挑战，例如可能导致整体失败率增加，并且目前没有针对相干错误的拓扑码阈值分析。此外，在经典计算机上有效模拟量子纠错在相干错误下的性能也存在困难。

Method: 通过分析量子比特的重复传送来处理相干错误，并证明其等效于 Pauli 错误模型。

Result: 研究结果表明，通过传送实现的 CSS 码在特定相干噪声下等效于 Pauli 错误模型，从而可以在经典计算机上进行有效模拟并具有可分析证明的阈值。这可能消除对传送量子计算方案中随机编译的需要。

Conclusion: 该研究表明，量子比特的重复传送可以使相干错误退相干，平均保真度最坏情况下与传送次数成线性关系，这与 Pauli 错误类似。此外，该研究发现，传送的 CSS 码的物理模型 Z 相干错误模型等效于 Pauli 错误模型。

Abstract: Compared to the more widely studied Pauli errors, coherent errors present
several new challenges in quantum computing and quantum error correction (QEC).
For example, coherent errors may interfere constructively over a long circuit
and significantly increase the overall failure rate compared to Pauli noise.
Additionally, there is so far no analytical proof for a topological code
threshold under coherent errors. Moreover, it is hard to even numerically
estimate the performance of QEC under coherent errors as their effect in a
Clifford circuit cannot be efficiently classically simulated. In this work, we
demonstrate that teleportation effectively tailors coherent errors into Pauli
errors, for which analytical and numerical results are abundant. We first show
that repeated teleportation of a single qubit decoheres errors, and the average
infidelity grows at worst linearly with the number of teleportations, similar
to Pauli errors. We then analyze a physically motivated pure $Z$-coherent error
model for teleported CSS codes in which over-rotation errors accompany every
gate, and find that such an error model is equivalent to a Pauli error model.
Our result implies that the performance of a CSS code implemented via
teleportation-based error correction or measurement-based error correction with
such coherent noise can be efficiently simulated on a classical computer and
has an analytically provable threshold. The intrinsic noise-tailoring property
of teleportation may ultimately remove the need for randomized compiling in
teleportation-based quantum computing schemes.

</details>


### [320] [A Design for an Early Quantum Network](https://arxiv.org/abs/2508.04967)
*Yuan Li,Chen Zhang,Hao Zhang,Tao Huang,Yunjie Liu*

Main category: quant-ph

TL;DR: Proposed a design for early-stage quantum networks compatible with current repeater tech, aiming to support diverse applications despite resource limits. Used simulations to test its feasibility and analyze performance metrics like fidelity and completion time, also exploring controller decision-making beyond basic path selection.


<details>
  <summary>Details</summary>
Motivation: To design early-stage quantum networks compatible with existing quantum repeater technologies that maximize the ability to accommodate diverse quantum application needs, even under conditions of limited quantum resources and suboptimal network performance.

Method: Discrete-event modeling of quantum networks, simulations considering various noise types and imperfect parameters, analysis of impact on fidelity and request completion time, investigation of additional controller decisions (cutoff time, resource allocation).

Result: Simulations analyzed the impact of noise and imperfect parameters on the fidelity of generated entangled states and request completion time. Investigated additional controller decisions beyond path selection.

Conclusion: The proposed design is compatible with existing quantum repeater technologies and aims to maximize network accommodation of diverse quantum application needs, even with limited resources and suboptimal performance. Simulations based on discrete-event modeling, considering noise and imperfect parameters, were used to assess feasibility and analyze the impact on fidelity and request completion time. Additional controller decisions beyond path selection, such as cutoff time and resource allocation, were also investigated.

Abstract: With the rapid advancement of quantum information technology, quantum
networks have become essential for supporting diverse applications, which often
have stringent demands for key metrics such as fidelity and request completion
time. In this work, we propose a design for early-stage quantum networks that
is compatible with the three existing quantum repeater technologies. The design
aims to maximize the ability of the network to accommodate the diverse needs of
quantum applications, even under conditions of limited quantum resources and
suboptimal network performance. We have also described the required identifiers
in the quantum network and the specific process for implementing quantum
requests. To assess the feasibility of our design, we conduct simulations based
on discrete-event modeling of quantum networks. The simulations consider
various types of noise and imperfect parameters that might exist in early-stage
networks. We analyze the impact of these parameters on the fidelity of the
generated entangled states and the request completion time. Furthermore, we
investigated additional decisions that the central controller can make beyond
path selection, such as the choice of cutoff time and the allocation of network
resources to requests.

</details>


### [321] [Corner functions from entanglement indices of harmonic lattices](https://arxiv.org/abs/2508.04992)
*Masafumi Shimojo,Satoshi Ishihara,Hironobu Kataoka,Atsuko Matsukawa*

Main category: quant-ph

TL;DR: This paper analyzes entanglement in harmonic oscillator lattices, comparing different boundary conditions and dimensions. It finds LNs are consistent across conditions but MIs have discrepancies, and also studies 3D lattice properties.


<details>
  <summary>Details</summary>
Motivation: This study aims to investigate and compare entanglement properties, specifically logarithmic negativities (LNs) and mutual informations (MIs), in a system of harmonic oscillators arranged on a 2D lattice. The research seeks to verify existing results and understand the impact of different boundary conditions (periodic vs. fixed) and lattice dimensions on these entanglement measures, particularly focusing on corner functions and edge terms.

Method: The paper calculates logarithmic negativities (LNs) and mutual informations (MIs) for a 2D lattice of harmonic oscillators. It verifies previous results for corner functions under periodic boundary conditions (PBCs) and then calculates and compares these entanglement indices under fixed end boundary conditions (FBCs), specifically examining the effect of these fixed ends. Additionally, Renyi entropies for 3D lattice sites and corner functions with solid and dihedral angles are investigated.

Result: The study found that logarithmic negativities (LNs) calculated under fixed end boundary conditions (FBCs) are nearly equal to previously reported values under periodic boundary conditions (PBCs). However, mutual informations (MIs) for a 3π/4 corner function under FBCs showed inconsistency with those computed from LNs. The research also examined Renyi entropies for 3D lattice sites and found specific values for corner functions and edge terms related to dihedral angles.

Conclusion: The study compares entanglement indices (LNs and MIs) between adjacent subsets in a 2D lattice of harmonic oscillators under periodic and fixed boundary conditions. While LNs show consistency, MIs for a 3π/4 corner function under fixed boundary conditions are not fully consistent with LN values. The study also examines Renyi entropies for 3D lattice sites and corner/edge terms with solid and dihedral angles.

Abstract: We study the entanglement indices such as logarithmic negativities (LNs) and
mutual informations (MIs) between two adjacent subsets in a isolated universal
set $U$ of harmonic oscillators arranged on a two dimensional lattice within a
sufficiently large square. First, we verify the values of the corner functions
of angle $\pi/2, \pi/4, 3\pi/4$ presented in the previous study which adopts
periodic boundary conditions (PBCs) for the $U$. The values of each corner
function obtained from LNs are nearly equal to those in the previous ones,
while those of $3\pi/4$ from MIs are not sufficiently consistent with those
computed from LNs. Next, for the case where the universal system $U$ satisfies
the fixed end boundary conditions(FBCs), we calculate LNs, MIs at several
locations in $U$, compare them, especially corner functions with the values
obtained in the PBCs case, and examine the effect of the fixed ends. In
addition, we examine Renyi entropies for sets of three dimensional lattice
sites, the corner functions and the edge terms with solid angles and dihedral
angles $\pi/2,\pi/4$, respectively.

</details>


### [322] [Optimal Qubit Purification and Unitary Schur Sampling via Random SWAP Tests](https://arxiv.org/abs/2508.05046)
*Shrigyan Brahmachari,Austin Hulse,Henry D. Pfister,Iman Marvian*

Main category: quant-ph

TL;DR: 基于随机 SWAP 测试的量子比特纯化协议，可实现与舒尔变换相同的最优保真度，并提供一种无损提取置换不变信息的方法。


<details>
  <summary>Details</summary>
Motivation: 量子比特纯化旨在通过合并多个嘈杂的未知纯量子态副本，获得更接近纯态的一个或多个副本。

Method: 该协议基于随机 SWAP 测试，通过识别和分离单重态对来合并多个嘈杂的量子比特副本，最终获得更接近纯态的副本。

Result: 随机 SWAP 测试协议实现的保真度与最优的舒尔变换相同。对于 $n$ 个量子比特的系统，在执行约 $T \approx n \ln n$ 次随机 SWAP 测试后，检测到任何新的单重态的概率会随 $T$ 指数级下降，并且每个剩余量子比特的保真度会收敛到由舒尔变换给出的最优值。

Conclusion: 该协议实现了弱舒尔采样和酉舒尔采样，其误差为 $\epsilon$ ，仅需 $2n \ln(n \epsilon^{-1})$ 次 SWAP 测试。它提供了一种无损的方法来提取对量子比特排列不变的任何信息，使其成为量子态层析和计量等任务的有力子程序。

Abstract: The goal of qubit purification is to combine multiple noisy copies of an
unknown pure quantum state to obtain one or more copies that are closer to the
pure state. We show that a simple protocol based solely on random SWAP tests
achieves the same fidelity as the Schur transform, which is optimal. This
protocol relies only on elementary two-qubit SWAP tests, which project a pair
of qubits onto the singlet or triplet subspaces, to identify and isolate
singlet pairs, and then proceeds with the remaining qubits. For a system of $n$
qubits, we show that after approximately $T \approx n \ln n$ random SWAP tests,
a sharp transition occurs: the probability of detecting any new singlet
decreases exponentially with $T$. Similarly, the fidelity of each remaining
qubit approaches the optimal value given by the Schur transform, up to an error
that is exponentially small in $T$. More broadly, this protocol achieves what
is known as weak Schur sampling and unitary Schur sampling with error
$\epsilon$, after only $2n \ln(n \epsilon^{-1})$ SWAP tests. That is, it
provides a lossless method for extracting any information invariant under
permutations of qubits, making it a powerful subroutine for tasks such as
quantum state tomography and metrology.

</details>


### [323] [Factorizability of multi-party quantum sequence discrimination under local operations and classical communication](https://arxiv.org/abs/2508.05050)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: This paper studies multi-party quantum sequence discrimination using LOCC. It finds conditions where discrimination can be done step-by-step and simplified to guessing the most likely state, which is useful for quantum data hiding.


<details>
  <summary>Details</summary>
Motivation: To provide conditions under which the optimal LOCC discrimination of a multi-party quantum sequence ensemble can be factorized into individual ensemble discriminations.

Method: The paper considers multi-party quantum sequence discrimination under LOCC and analyzes conditions for factorizability of optimal discrimination.

Result: The paper illustrates factorizability with examples and establishes a condition for realizing optimal LOCC discrimination through guessing the most probable state. The results can be applied to quantum data hiding.

Conclusion: We provide conditions for factorizability of optimal LOCC discrimination for multi-party quantum sequence ensembles and establish a condition for realizing optimal discrimination by guessing the most probable state.

Abstract: We consider multi-party quantum sequence discrimination under local
operations and classical communication(LOCC), and provide conditions under
which the optimal LOCC discrimination of a multi-party quantum sequence
ensemble can be factorized into that of each individual ensemble. In other
words, the optimal LOCC discrimination of a multi-party quantum sequence
ensemble can be achieved just by performing optimal LOCC discrimination
independently at each step of the quantum sequence. We also illustrate through
examples of multi-party quantum states that such factorizability of optimal
LOCC discrimination is possible. We further establish a necessary and
sufficient condition under which the optimal LOCC discrimination of a
multi-party quantum state ensemble can be realized just by guessing the state
with the largest probability. Our results can provide a useful application to
investigate the fundamental limits of quantum data hiding.

</details>


### [324] [Quantum State Preparation for Medical Data: Comprehensive Methods, Implementation Challenges, and Clinical Prospects](https://arxiv.org/abs/2508.05063)
*Nikhil Kumar Rajput,Riya Bansal*

Main category: quant-ph

TL;DR: 该调查全面审查了将医学信息编码到量子系统中的当前方法，并讨论了张量网络分解、变分量子算法、量子机器学习技术和专门的误差缓解策略。量子在医学中的优势依赖于利用固有的数据结构，如成像中的空间相关性、生理信号中的时间模式和分层生物组织。虽然目前的硬件限制了在小规模问题上的实现，但新兴方法在近期使用方面显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 量子计算在医疗应用方面具有变革潜力，但从复杂的医疗数据中有效制备量子态仍然是一个基本挑战。

Method: 对将医学信息编码到量子系统中的当前方法进行了全面审查，分析了理论原理、算法进展和实际限制。讨论了张量网络分解、变分量子算法、量子机器学习技术和专门的误差缓解策略。

Result: 量子在医学中的优势依赖于利用固有的数据结构，如成像中的空间相关性、生理信号中的时间模式和分层生物组织。

Conclusion: 虽然目前的硬件限制了在小规模问题上的实现，但新兴方法在近期使用方面显示出潜力。该研究为评估何时量子态制备在医学中优于经典方法提供了结构化框架，并附带了实现指南和性能基准。

Abstract: Quantum computing holds transformative potential for medical applications,
yet efficiently preparing quantum states from complex medical data remains a
fundamental challenge. This survey provides a comprehensive examination of
current approaches for encoding medical information into quantum systems,
analyzing theoretical principles, algorithmic advancements, and practical
limitations. It discusses tensor network decomposition, variational quantum
algorithms, quantum machine learning techniques, and specialized error
mitigation strategies for medical computing. The findings indicate that quantum
advantages in medicine rely on leveraging inherent data structures such as
spatial correlations in imaging, temporal patterns in physiological signals,
and hierarchical biological organization. While current hardware restricts
implementations to small-scale problems, emerging methods show potential for
near-term use. The study provides a structured framework for assessing when
quantum state preparation outperforms classical approaches in medicine, along
with implementation guidelines and performance benchmarks.

</details>


### [325] [One-sided composite cavity on an optical nanocapillary fiber](https://arxiv.org/abs/2508.05072)
*Srinu Gadde,Jelba John,Ramachandrarao Yalla*

Main category: quant-ph

TL;DR: 该论文报告了一种用于光学纳米毛细管光纤（NCF）的单侧腔，使用复合腔（NCF和不对称缺陷模式光栅）实现高达80%的耦合效率，并实现了19354的品质因数、240的精细度和1.3%的单程损耗，为构建单光子源提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 我们设计该腔是为了在欠耦合、临界耦合和过耦合状态下，将高达80%的耦合效率最大化地导入到单侧NCF引导模式中。

Method: 我们使用复合腔在光学纳米毛细管光纤（NCF）上数值报告了一个单侧腔，该复合腔由光学NCF和不对称缺陷模式光栅组成。

Result: 在最大耦合效率情况下，我们发现该腔的最佳品质因数、精细度和单程损耗分别为19354、240和1.3%。

Conclusion: 该光纤平台为量子技术中基于光纤的确定性单光子源的设计开辟了新途径。

Abstract: We numerically report a one-sided cavity on an optical nanocapillary fiber
(NCF) using a composite cavity. The composite cavity is formed by combining an
optical NCF and an asymmetric defect mode grating. We design the cavity to
realize the maximum channeling efficiency of up to 80% into one-sided
NCF-guided modes while operating from under- to critical- and overcoupling
regimes. For the maximum channeling efficiency case, we found the best quality
factor, finesse, and one-pass loss of the cavity are 19354, 240, and 1.3%,
respectively. The present platform may open a novel route for designing
fiber-based deterministic single-photon sources in quantum technologies.

</details>


### [326] [Explicit Instances of Quantum Tanner Codes](https://arxiv.org/abs/2508.05095)
*Rebecca Katharina Radebold,Stephen D. Bartlett,Andrew C. Doherty*

Main category: quant-ph

TL;DR: 构造了量子 Tanner 码，性能良好，接近表面码。


<details>
  <summary>Details</summary>
Motivation: 构造一类渐近好的量子低密度奇偶校验 (qLDPC) 码，并评估其性能和开销。

Method: 使用二面体群和经典码对的随机化来构造量子 Tanner 码。

Result: 构造了量子 Tanner 码的实例，这些码具有高编码率、相对距离和伪阈值，并使用 BP+OSD 解码器展示了良好的性能。

Conclusion: 量子 Tanner 码在现象学和电路级噪声设置下表现出与表面码相当的性能，并对空间时间开销进行了分析。

Abstract: We construct several explicit instances of quantum Tanner codes, a class of
asymptotically good quantum low-density parity check (qLDPC) codes. The codes
are constructed using dihedral groups and random pairs of classical codes and
exhibit high encoding rates, relative distances, and pseudo-thresholds. Using
the BP+OSD decoder, we demonstrate good performance in the phenomenological and
circuit-level noise settings, comparable to the surface code with similar
distances. Finally, we conduct an analysis of the space-time overhead incurred
by these codes.

</details>


### [327] [Quantum Path Signatures](https://arxiv.org/abs/2508.05103)
*Samuel Crew,Cristopher Salvi,William F. Turner,Thomas Cass,Antoine Jacquier*

Main category: quant-ph

TL;DR: Physics-inspired quantum approach to path signatures using matrix models and quantum circuits.


<details>
  <summary>Details</summary>
Motivation: To elucidate the physical aspects of path signatures by connecting them to concepts in quantum field theory and quantum computation.

Method: We formulated randomized path developments within matrix models in quantum field theory, derived loop equations for a new family of randomized path developments, and studied a random ensemble of Pauli strings in the Gaussian matrix model to formulate a quantum algorithm for computing the quantum signature kernel.

Result: We derived loop equations for randomized path developments and defined a quantum path signature feature map and kernel, with a quantum algorithm proposed for the Gaussian matrix model.

Conclusion: We introduced a quantum path signature feature map and kernel through quantum circuit construction, using insights from matrix models in quantum field theory and interpreting unitary randomized path developments as time evolution operators on a Hilbert space of qubits.

Abstract: We elucidate physical aspects of path signatures by formulating randomised
path developments within the framework of matrix models in quantum field
theory. Using tools from physics, we introduce a new family of randomised path
developments and derive corresponding loop equations. We then interpret unitary
randomised path developments as time evolution operators on a Hilbert space of
qubits. This leads to a definition of a quantum path signature feature map and
associated quantum signature kernel through a quantum circuit construction. In
the case of the Gaussian matrix model, we study a random ensemble of Pauli
strings and formulate a quantum algorithm to compute such kernel.

</details>


### [328] [Current comparator for both AC and DC ratio measurements with 10-8-level accuracy](https://arxiv.org/abs/2508.05140)
*Hidekazu Muramatsu,Yuta Kainuma,Hiromitsu Kato,Norihiko Sakamoto,Tatsuji Yamada,Chiharu Urano,Hiroshi Abe,Shinobu Onoda,Takeshi Ohshima,Yuji Hatano,Mutsuko Hatano,Nobu-Hisa Kaneko,Yasutaka Amagai,Takayuki Iwasaki*

Main category: quant-ph

TL;DR: 本研究提出了一种创新的室温、无制冷交流/直流电流比较仪，利用金刚石NV中心磁力计实现了高精度测量，有望统一电流标准。


<details>
  <summary>Details</summary>
Motivation: 传统的交流和直流电流比较仪依赖不同的技术，导致溯源系统复杂化。为了满足新兴电力技术的需求，需要弥合这一技术鸿沟，发展统一的电流标准。

Method: 本研究提出了一种集成金刚石基氮-空位（NV）中心磁力计的紧凑型室温交流/直流电流比较仪。

Result: 该设备实现了10⁻⁸的交流和直流信号精度，系统带宽高达300 Hz，无需制冷。其精度超越了典型的交流比较仪（提高了十倍），并达到了最先进的直流比较仪的性能。

Conclusion: 本研究提出的室温、无制冷的交流/直流电流比较仪，采用基于金刚石的氮-空位（NV）中心磁力计，实现了10⁻⁸的精度，带宽达300 Hz。该设备在准确性和通用性上超越了传统的交流比较仪，并达到了最先进的直流比较仪的性能水平，为实现统一的电流标准和量子电气测量奠定了基础。

Abstract: Accurate measurements of alternating current (AC) and direct current(DC)
ratios are fundamental to electric power metrology. However, conventional
current comparators for AC and DC typically rely on distinct
technologies-electromagnetic induction for AC and superconducting quantum
interference devices for DC. This technological divide leads to a fragmented
and complex traceability system. Bridging this gap is critical for developing
unified current standards that meet the demands of emerging power technologies.
In this work, we present a compact, room-temperature AC/DC current comparator
that integrates a diamond-based magnetometer using nitrogen-vacancy centers.
The device achieves an accuracy of 10-8 for both AC and DC signals and supports
a system bandwidth up to 300 Hz, without the need for cryogenics. It surpasses
the performance of typical AC comparators, offering ten-fold higher accuracy,
and matches that of state-of-the-art DC comparators. This unified,
cryogenics-free solution not only enhances precision and versatility but also
expands the applicability of the system to DC resistance bridges in quantum
electrical standards.

</details>


### [329] [Hybrid quantum tensor networks for aeroelastic applications](https://arxiv.org/abs/2508.05169)
*M. Lautaro Hickmann,Pedro Alves,David Quero,Friedhelm Schwenker,Hans-Martin Rieser*

Main category: quant-ph

TL;DR: 研究人员将混合量子张量网络与量子机器学习相结合，以解决航空弹性问题中的时间序列分类和回归任务。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子张量网络在航空弹性问题中的应用，利用量子机器学习（QML）的潜力来解决复杂的时间序列分类和回归任务。

Method: 该方法结合了张量网络和变分量子电路，将时间序列编码到张量网络中，然后使用可训练的张量网络进行降维，并将结果张量转换为量子电路进行分类或回归任务。

Result: 混合量子张量网络在二元分类任务中实现了高精度，并在离散变量回归方面表现出有前景的性能。

Conclusion: 这项工作为使用混合量子张量网络解决复杂的空气弹性问题的发展做出了重大贡献，并提出了一个端到端可训练的混合算法。

Abstract: We investigate the application of hybrid quantum tensor networks to
aeroelastic problems, harnessing the power of Quantum Machine Learning (QML).
By combining tensor networks with variational quantum circuits, we demonstrate
the potential of QML to tackle complex time series classification and
regression tasks. Our results showcase the ability of hybrid quantum tensor
networks to achieve high accuracy in binary classification. Furthermore, we
observe promising performance in regressing discrete variables. While
hyperparameter selection remains a challenge, requiring careful optimisation to
unlock the full potential of these models, this work contributes significantly
to the development of QML for solving intricate problems in aeroelasticity. We
present an end-to-end trainable hybrid algorithm. We first encode time series
into tensor networks to then utilise trainable tensor networks for
dimensionality reduction, and convert the resulting tensor to a quantum circuit
in the encoding step. Then, a tensor network inspired trainable variational
quantum circuit is applied to solve either a classification or a multivariate
or univariate regression task in the aeroelasticity domain.

</details>


### [330] [Exploring Satellite Quantum Key Distribution under Atmospheric Constraints](https://arxiv.org/abs/2508.05235)
*Aditya Ajith,S. Saravana Veni*

Main category: quant-ph

TL;DR: 该研究通过数值模拟，为地面到卫星的量子密钥分发链路在不同距离下的可行性提供了量化评估，并考虑了大气湍流和吸收损耗等因素。


<details>
  <summary>Details</summary>
Motivation: 卫星量子密钥分发为安全的全球通信提供了一条途径，其安全级别无与伦比。然而，地面到卫星的量子密钥分发链路会受到大气湍流退化。

Method: 该论文提出了一个使用角谱传播、Hufnagel-Valley湍流模型和Von Karman相位屏的数值框架，并考虑了由O2、CO2和H2O等大气成分的吸收引起的静态损耗。该模拟逐步通过大气传播高斯光束，并使用基于标准Cn2剖面的相位屏来模拟光束的抖动和闪烁等相位失真。此外，还模拟了具有诱饵态的BB84协议以增强安全性。

Result: 模拟结果量化了在各种距离下的预期链路预算和安全密钥速率。

Conclusion: 该模拟为不同距离的自由空间光量子密钥分发链路的生存能力提供了量化。

Abstract: Satellite Quantum Key Distribution creates a pathway for secure global
communication with a level of security that is peerless. However,
ground-to-satellite Quantum Key Distribution links are degraded due to the
atmospheric turbulence. This paper gives a numerical framework using angular
spectrum propagation, Hufnagel-Valley model of turbulence and Von Karman phase
screens and takes into account the static losses introduced due to the
absorption of the beam by the different elements and compounds in the
atmosphere like O2, CO2 and H2O. This simulation propagates a Gaussian beam
step by step through the atmosphere, where we incorporate the phase distortions
using phase screens based on standard Cn2 profiles which take into account
losses such as scintillation and beam wander. We simulate the BB84 protocol
with decoy states for added security. The results of the simulation quantify
the expected link budget and Secure key rates over a range of distances to
measure the viability of Free Space Optical Quantum Key Distribution links at
different distances.

</details>


### [331] [Bipartite entanglement in a nuclear spin register mediated by a quasi-free electron spin](https://arxiv.org/abs/2508.05255)
*Marco Klotz,Andreas Tangemann,David Opferkuch,Alexander Kubanek*

Main category: quant-ph

TL;DR: 通过高应变金刚石中的SiV中心，实现了对耦合到准自由电子自旋的$^{13}	extrm{C}$核自旋寄存器的控制和纠缠。利用连续解耦技术进行控制，并通过核自旋条件相位门实现纠缠，为固态量子网络提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 量子网络依赖于与健壮的、局域的量子寄存器纠缠的光子来进行计算和纠错。

Method: 利用连续解耦（通过整形、低功率微波和直接射频驱动）来检测和控制核自旋寄存器。实现了核自旋条件相位门，以介导二分纠缠。

Result: 展示了在金刚石中全连接三比特$^{13}	extrm{C}$核自旋寄存器的控制和纠缠。该寄存器耦合到硅-空位（SiV）中心的准自由电子自旋1/2。高应变使SiV的电子自旋与自旋轨道相互作用解耦，从而降低了在液氦温度下对声子的敏感性。因此，电子自旋寿命长达数百毫秒，能够感知低至几赫兹的核-核耦合。

Conclusion: 此方法提供了一种替代动态解耦核自旋纠缠的方法，不受电子自旋1/2性质的限制，为光学可及的固态量子寄存器开辟了新途径。

Abstract: Quantum networks will rely on photons entangled to robust, local quantum
registers for computation and error correction. We demonstrate control of and
entanglement in a fully connected three-qubit $^{13}\mathrm{C}$ nuclear spin
register in diamond. The register is coupled to a quasi-free electron spin-1/2
of a silicon-vacancy center (SiV). High strain decouples the SiVs electron spin
from spin-orbit interaction reducing the susceptibility to phonons at liquid
helium temperature. As a result, the electron spin lifetime of hundreds of
milli seconds enables sensing of nuclear-nuclear couplings down to few hertz.
To detect and control the register we leverage continuous decoupling using
shaped, low-power microwave and direct radio frequency driving. Furthermore, we
implement a nuclear spin conditional phase-gate on the electron spin to mediate
bipartite entanglement. This approach presents an alternative to dynamically
decoupled nuclear spin entanglement, not limited by the electron spin's 1/2
nature, opening up new avenues to an optically-accessible, solid-state quantum
register.

</details>


### [332] [Towards integrated sensors for optimized OCT with undetected photons](https://arxiv.org/abs/2508.05320)
*Franz Roeder,René Pollmann,Viktor Quiring,Christof Eigner,Benjamin Brecht,Christine Silberhorn*

Main category: quant-ph

TL;DR: This paper explores integrated OCT systems for detecting photons without prior knowledge. It compares two schemes, finding that induced coherence works better for miniaturized systems and achieves a resolution of 28 μm.


<details>
  <summary>Details</summary>
Motivation: To develop practical sensors for optical coherence tomography (OCT) with undetected photons that require miniaturization via integration, large spectral bandwidth, and high brightness.

Method: The paper investigates the performance benchmarks of the SU(1,1) scheme and an induced coherence scheme for OCT measurements with undetected photons using nonlinear Ti:LiNbO3 waveguides. Pump gain optimization and OCT measurements were performed in both schemes.

Result: The induced coherence scheme demonstrated better suitability for integrated systems in OCT measurements with undetected photons. An axial resolution as low as 28 μm was achieved in both schemes.

Conclusion: The induced coherence scheme is better suited for OCT measurements with undetected photons in integrated systems compared to the SU(1,1) scheme.

Abstract: The development of practical sensors for optical coherence tomography (OCT)
with undetected photons requires miniaturization via integration. To be
practical, these sensors must exhibit a large spectral bandwidth and a high
brightness, which are linked to a high axial resolution and a sufficient signal
to noise ratio, respectively. Here, we combine these requirements in a scheme
for OCT-measurements with undetected photons based on nonlinear Ti:LiNbO$_3$
waveguides. We investigate the performance benchmarks of the commonly used
SU(1,1) scheme in comparison to an induced coherence scheme and find that the
latter is actually better suited when implementing measurements with undetected
photons in integrated systems. In both schemes, we perform pump gain
optimization and OCT measurements with undetected photons with an axial
resolution as low as 28 $\mathrm{\mu}$m.

</details>


### [333] [Quantum Circuit Benchmarking on IBM Brisbane: Performance Insights from Superconducting Qubit Models](https://arxiv.org/abs/2508.05331)
*J. Thirunirai Selvam,S. Saravana Veni*

Main category: quant-ph

TL;DR: 本研究利用IBM Brisbane量子处理器，通过模拟和控制超导量子比特，研究了量子通信中的纠缠态演化和量子门操作，并考虑了实际噪声因素，最终证明了超导量子比特在量子通信领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究量子通信的安全性与可靠性，重点关注超导量子比特在模拟和控制量子系统中的应用，以及纠缠态作为关键资源的作用。

Method: 使用IBM Brisbane量子处理器进行量子比特模拟和控制，实现基本量子门操作，分析纠缠态演化，并考虑了退相干和噪声等实际条件。

Result: 成功模拟了基本量子门和纠缠态演化，并探讨了其在量子通信网络中的应用前景。同时，研究还扩展到模拟了Jaynes Cummings和纵向Ising模型。

Conclusion: 本研究证明了超导量子比特系统在量子通信中的潜力，为基础研究和实际应用奠定了基础。

Abstract: This paper investigates quantum communication using superconducting qubits,
emphasizing the simulation and control of quantum systems via IBM Brisbane
quantum processor. We focus on implementing fundamental quantum gates and
analyzing the evolution of entangled states, which are essential for secure and
reliable information transfer. The study highlights the role of entanglement as
a critical resource in quantum communication, enabling secure connectivity
across quantum networks. Simulations incorporate realistic conditions,
including decoherence and noise, to assess the practical viability of entangled
state operations. Additionally, we explore the extension of these systems to
simulate key quantum models such as the Jaynes Cummings and longitudinal Ising
models, offering insight into complex interactions in superconducting
architectures. The findings advance quantum information science by
demonstrating the potential of superconducting qubit systems for both
foundational research and real world applications in quantum communication.

</details>


### [334] [Material-Driven Optimization of Transmon Qubits for Scalable and Efficient Quantum Architectures](https://arxiv.org/abs/2508.05339)
*Jonnalagadda Gayatri,S. Saravana Veni*

Main category: quant-ph

TL;DR: 这项工作通过结合电路设计和材料模拟来优化超导量子比特，解决了量子比特优化问题，其方法包括使用 Qiskit Metal 和 Ansys HFSS 进行设计和仿真，以及在 COMSOL Multiphysics 中进行材料影响分析。研究结果表明，材料选择对量子比特的性能有重要影响，并提出了一种可行的超导量子比特系统设计框架。


<details>
  <summary>Details</summary>
Motivation: 为了构建实用的量子计算机，设计可扩展且高效的超导量子比特至关重要，其中相干时间、量子比特间的连接以及环境噪声的减少是影响量子比特成功率的关键因素。基于 Transmon 架构的超导量子比特因其可光刻制造且对电荷噪声不敏感，已成为有希望的可扩展平台。

Method: 研究结合了设计迭代、材料分析和仿真，使用 Qiskit Metal 创建了 4 和 8 量子比特的 Transmon 布局，并进行了单独分析。研究了非谐性，提取了本征频率，计算了多个设计通道的参与比，并使用 Ansys HFSS 确定了前五个能量本征态。然后，在 COMSOL Multiphysics 中创建了单个量子比特设计的二维横截面，以评估不同材料对性能的影响，包括本征损耗和电磁特性。

Result: 通过对不同材料的研究，发现量子比特的相干性和器件的整体质量受到所选材料的显著影响。

Conclusion: 该综合框架通过材料模拟和电路设计相结合，为制造可靠的超导量子比特系统提供了一种可行的途径，并支持实现可扩展、容错的量子计算。

Abstract: One of the most crucial steps in creating practical quantum computers is
designing scalable and efficient superconducting qubits. Coherence times,
connections between individual qubits, and reduction of environmental noise are
critical factors in the success of these qubits. Because they can be
lithographically fabricated and are less sensitive to charge noise,
superconducting qubits, especially those based on the Transmon architecture,
have emerged as top contenders for scalable platforms. In this work, we use a
combination of design iteration, material analysis, and simulation to tackle
the superconducting qubit optimization challenge. We created transmon-based
layouts for 4 qubits and 8 qubits using Qiskit Metal and conducted an
individual analysis for each qubit. We investigated anharmonicity and extracted
eigenfrequencies, computing participation ratios across several design passes,
and identifying the top five energy eigenstates using Ansys HFSS. We then
created a 2D cross section of a single qubit design in COMSOL Multiphysics to
evaluate how different materials affect performance. This enables us to assign
various superconducting materials and substrates and investigate their effects
on energy loss and electromagnetic properties. Qubit coherence and overall
device quality are significantly influenced by the materials chosen. This
integrated framework of material based simulation and circuit design offers a
workable way to create reliable superconducting qubit systems and supports
continued attempts to create scalable, fault-tolerant quantum computing.

</details>


### [335] [Reinforcement Learning Generation of 4-Qubits Entangled States](https://arxiv.org/abs/2204.12351)
*Sara Giordano,Miguel A. Martin-Delgado*

Main category: quant-ph

TL;DR: 该研究使用Q学习强化学习算法和状态连接图（SLG）工具，成功构建了四量子比特纠缠态的代表性状态，并发现了最优量子线路，为实验实现和理论研究提供了有价值的资源。


<details>
  <summary>Details</summary>
Motivation: 为了构建卓越的纠缠态，特别是生成四量子比特纠缠态的49个真实SLOC（Strictly Local Complementary）类别中的代表性状态。

Method: 本研究提出了一种人工智能算法，利用基于Q学习的强化学习来构建包含4个量子比特的纠缠态，并引入了状态连接图（SLG）作为一种图形化工具来表示算法构建目标状态所使用的Q矩阵。

Result: 该算法能够生成四量子比特纠缠态的代表性状态，覆盖了九种纠缠家族中的至少一种真实SLOC类别。此外，算法发现的量子线路在所选量子门集合上是最优的。

Conclusion: 该算法生成的量子线路对于实现这些重要的量子纠缠态类具有实用价值，并有助于揭示宇宙的内在属性。

Abstract: We have devised an artificial intelligence algorithm with machine
reinforcement learning (Q-learning) to construct remarkable entangled states
with 4 qubits. This way, the algorithm is able to generate representative
states for some of the 49 true SLOCC classes of the four-qubit entanglement
states. In particular, it is possible to reach at least one true SLOCC class
for each of the nine entanglement families. The quantum circuits synthesized by
the algorithm may be useful for the experimental realization of these important
classes of entangled states and to draw conclusions about the intrinsic
properties of our universe. We introduce a graphical tool called the state-link
graph (SLG) to represent the construction of the Quality matrix (Q-matrix) used
by the algorithm to build a given objective state belonging to the
corresponding entanglement class. This allows us to discover the necessary
connections between specific entanglement features and the role of certain
quantum gates that the algorithm needs to include in the quantum gate set of
actions. The quantum circuits found are optimal by construction with respect to
the quantum gate-set chosen. These SLGs make the algorithm simple, intuitive
and a useful resource for the automated construction of entangled states with a
low number of qubits.

</details>


### [336] [Geometric quantum encoding of a turbulent field](https://arxiv.org/abs/2508.05346)
*Zhaoyuan Meng,Yue Yang*

Main category: quant-ph

TL;DR: 本文提出了一种高效的超球编码方法，用于对湍流场进行量子编码，该方法利用霍普夫纤维丛将量子可观测量映射到涡管上，在减少量子比特需求方面取得了显著进展，并为大规模量子模拟奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 多尺度系统的混沌结构对它们的量子编码提出了严峻的挑战。

Method: 本文提出了一种三阶段超球编码方法来处理湍流场，该方法包括：1.守恒扰动；2.特定于测量的卷积；3.可观测量的最终解卷积。其中，后两个阶段利用霍普夫纤维丛将量子可观测量映射到涡管上，而涡管是流体湍流的基本构成块。

Result: 使用 27 个量子比特，我们生成了一个即时湍流场，其雷诺数为 Re = 13900，该场成功复现了能量谱的 Kolmogorov 五分之三律、缠结的涡结构和强烈的间歇性。

Conclusion: 该方法只需要 O(log2Re) 量子比特，这对于湍流场编码来说是渐进最优的。这相对于经典方法实现了指数级内存缩减，并为大规模多尺度系统量子模拟的状态制备提供了可能。

Abstract: The chaotic structure of multiscale systems presents a formidable challenge
to their quantum encoding. We propose a three-stage hyperspherical encoding
method for turbulent fields. This method comprises a symmetry-preserving
perturbation of the ground state, a measurement-specific convolution, and a
final deconvolution of observables. The latter two stages employ the Hopf
fibration to map quantum observables onto vortex tubes, the building blocks of
fluid turbulence. Using 27 qubits, we generate an instantaneous turbulent field
at a Reynolds number of $\mathit{Re} = 13900$ that reproduces the energy
spectrum with Kolmogorov's five-thirds scaling, tangled vortex structures, and
strong intermittency. The method only requires $\mathcal{O}(\log_2\mathit{Re})$
qubits, which is asymptotically optimal for turbulent-field encoding. This
yields an exponential memory reduction over classical methods, and enables
state preparation for large-scale quantum simulation of multiscale systems.

</details>


### [337] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
*Sara Giordano,Kornikar Sen,Miguel A. Martin-Delgado*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A reinforcement learning (RL) framework is introduced for the efficient
synthesis of quantum circuits that generate specified target quantum states
from a fixed initial state, addressing a central challenge in both the NISQ era
and future fault-tolerant quantum computing. The approach utilizes tabular
Q-learning, based on action sequences, within a discretized quantum state
space, to effectively manage the exponential growth of the space dimension. The
framework introduces a hybrid reward mechanism, combining a static,
domain-informed reward that guides the agent toward the target state with
customizable dynamic penalties that discourage inefficient circuit structures
such as gate congestion and redundant state revisits. By leveraging sparse
matrix representations and state-space discretization, the method enables
scalable navigation of high-dimensional environments while minimizing
computational overhead. Benchmarking on graph-state preparation tasks for up to
seven qubits, we demonstrate that the algorithm consistently discovers
minimal-depth circuits with optimized gate counts. Moreover, extending the
framework to a universal gate set for arbitrary quantum states, it still
produces minimal depth circuits, highlighting the algorithm's robustness and
adaptability. The results confirm that this RL-driven approach efficiently
explores the complex quantum state space and synthesizes near-optimal quantum
circuits, providing a resource-efficient foundation for quantum circuit
optimization.

</details>


### [338] [Secure and practical Quantum Digital Signatures](https://arxiv.org/abs/2508.05355)
*Federico Grasselli,Gaetano Russo,Massimiliano Proietti*

Main category: quant-ph

TL;DR: 本研究改进了三种量子数字签名协议，提高了其安全性与效率。


<details>
  <summary>Details</summary>
Motivation: 为了保护数字签名免受量子攻击，并提高现有量子数字签名协议的效率。

Method: 对三种现有的基于预共享安全密钥和通用哈希族的量子数字签名（QDS）协议进行了分析、改进和数值优化。

Result: 成功改进了三种现有的QDS协议，证明了其IT安全性，并确定了最有效的协议，该协议在预共享比特消耗和签名长度方面具有更高的效率。

Conclusion: 所提出的方法对三种现有的基于预共享安全密钥和通用哈希族的量子数字签名（QDS）协议进行了改进，以解决潜在的安全漏洞，并证明了其信息论（IT）安全性。通过对协议参数进行数值优化，以减少预共享比特消耗和签名长度，从而确定了最高效的协议。

Abstract: Digital signatures represent a crucial cryptographic asset that must be
protected against quantum adversaries. Quantum Digital Signatures (QDS) can
offer solutions that are information-theoretically (IT) secure and thus immune
to quantum attacks. In this work, we analyze three existing practical QDS
protocols based on preshared secure keys (e.g., established with quantum key
distribution) and universal hashing families. For each protocol, we make
amendments to close potential loopholes and prove their IT security while
accounting for the failure of IT-secure authenticated communication. We then
numerically optimize the protocol parameters to improve efficiency in terms of
preshared bit consumption and signature length, allowing us to identify the
most efficient protocol.

</details>


### [339] [Resource-Efficient Synthesis of Sparse Quantum States](https://arxiv.org/abs/2508.05386)
*Renaud Vilmart,Sunheang Ty,Chetra Mang*

Main category: quant-ph

TL;DR: 该研究提出了一种用于合成稀疏量子态的算法，该算法通过优化电路深度、辅助数量和特别是昂贵的非Clifford门数量，在量子资源利用方面具有高效性。算法的关键在于广义W状态的合成和利用经典可逆电路及改进的高斯-约旦消元法来处理状态映射。


<details>
  <summary>Details</summary>
Motivation: 在容错量子计算的背景下，非Clifford门比Clifford门昂贵得多。因此，需要一种能够有效合成稀疏量子态的算法，并特别关注量子资源，例如最小化非Clifford门的使用。

Method: 该算法包含两个关键部分：1. 广义W状态的合成，采用基于树的电路构建方法，并分析了树结构与电路复杂度的关系。2. 实现置换的经典可逆电路，用于将W状态的基态映射到稀疏量子态的基态。该问题被归约到二元矩阵的对角化，利用了与经典可逆门相对应的基本矩阵运算，并通过高斯-约旦消元法的新版本解决，该方法最小化了包括电路深度在内的电路复杂度，并采用并行消元步骤。

Result: 提供了一种合成稀疏量子态的算法，其电路深度、辅助数量和非Clifford数量均与稀疏性呈线性关系。其中非Clifford数量的复杂性被认为是最佳的。

Conclusion: 该算法生成的电路具有稀疏性，其电路深度、辅助数量和非Clifford数量均与稀疏性呈线性关系。我们推测非Clifford数量的复杂性是最佳的，并对此提出一个较弱的证明。

Abstract: Preparing a quantum circuit that implements a given sparse state is an
important building block that is necessary for many different quantum
algorithms. In the context of fault-tolerant quantum computing, the so-called
non-Clifford gates are much more expensive to perform than the Clifford ones.
We hence provide an algorithm for synthesizing sparse quantum states with a
special care for quantum resources. The circuit depth, ancilla count, and
crucially non-Clifford count of the circuit produced by the algorithm are all
linear in the sparsity. We conjecture that the non-Clifford count complexity is
tight, and show a weakened version of this claim. The first key component of
the algorithm is the synthesis of a generalized W-state. We provide a
tree-based circuit construction approach, and the relationship between the
tree's structure and the circuit's complexity. The second key component is a
classical reversible circuit implementing a permutation that maps the basis
states of the W-state to those of the sparse quantum state. We reduce this
problem to the diagonalization of a binary matrix, using a specific set of
elementary matrix operations corresponding to the classical reversible gates.
We then solve this problem using a new version of Gauss-Jordan elimination,
that minimizes the circuit complexities including circuit depth using parallel
elimination steps.

</details>


### [340] [Quantum State Preparation Of Multiconfigurational States For Quantum Chemistry](https://arxiv.org/abs/2508.05390)
*Gabriel Greene-Diniz,Georgia Prokopiou,David Zsolt Manrique,David Muñoz Ramo*

Main category: quant-ph

TL;DR: 本研究实现了两种量子电路制备多构型状态的方法，并进行了比较。结果表明，利用状态向量稀疏性的方法比外部控制的吉文斯旋转方法更优越，能获得更简化的电路。


<details>
  <summary>Details</summary>
Motivation: 量子计算机在制备量子化学状态方面具有潜力，而高效的化学状态制备技术是当前的研究热点。

Method: 文章实现并研究了用于量子化学应用的多构型状态的两种量子电路制备方法：一种是自动寻找用于吉文斯旋转以制备多构型状态的外部控制的方法，另一种是利用化学状态向量稀疏性的方法。

Result: 研究表明，利用状态向量稀疏性的方法可以获得高度简化的电路，优于外部控制的吉文斯旋转方法。此外，还演示了这些技术在强关联分子的基态、激发态的Q-SCEOM算法的矩阵元以及量子计算矩和量子相位估计的量子子空间方法的关联初始状态等方面的优势。

Conclusion: 与基于量子计算期望值和量子相位估计的量子子空间方法相比，利用化学状态向量稀疏性的方法在制备多构型状态方面优于外部控制的吉文斯旋转。

Abstract: The ability to prepare states for quantum chemistry is a promising feature of
quantum computers, and efficient techniques for chemical state preparation is
an active area of research. In this paper, we implement and investigate two
methods of quantum circuit preparation for multiconfigurational states for
quantum chemical applications. It has previously been shown that controlled
Givens rotations are universal for quantum chemistry. To prepare a selected
linear combination of Slater determinants (represented as occupation number
configurations) using Givens rotations, the gates that rotate between the
reference and excited determinants need to be controlled on qubits outside the
excitation (external controls), in general. We implement a method to
automatically find the external controls required for utilizing Givens
rotations to prepare multiconfigurational states on a quantum circuit. We
compare this approach to an alternative technique that exploits the sparsity of
the chemical state vector and find that the latter can outperform the method of
externally controlled Givens rotations; highly reduced circuits can be obtained
by taking advantage of the sparse nature (where the number of basis states is
significantly less than 2$^{n_q}$ for $n_q$ qubits) of chemical wavefunctions.
We demonstrate the benefits of these techniques in a range of applications,
including the ground states of a strongly correlated molecule, matrix elements
of the Q-SCEOM algorithm for excited states, as well as correlated initial
states for a quantum subspace method based on quantum computed moments and
quantum phase estimation.

</details>


### [341] [LLM-based Multi-Agent Copilot for Quantum Sensor](https://arxiv.org/abs/2508.05421)
*Rong Sha,Binglin Wang,Jun Yang,Xiaoxiao Ma,Chengkun Wu,Liang Yan,Chao Zhou,Jixun Liu,Guochao Wang,Shuhua Yan,Lingxiao Zhu*

Main category: quant-ph

TL;DR: QCopilot是一个基于LLM的多代理框架，通过自动化和智能优化，将量子传感器的实验速度提高了100倍，并能自主诊断问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在量子传感器开发中面临跨学科知识壁垒和复杂优化过程的限制。

Method: QCopilot是一个基于LLM的多代理框架，集成了外部知识访问、主动学习和不确定性量化。它利用商业LLM、少样本提示工程和向量知识库，并包含专门的代理来适应性地选择优化方法、自动化建模分析和独立执行问题诊断。

Result: 在原子冷却实验中，QCopilot在几小时内实现了无需人工干预、生成10${}^{m{8}}$亚微开尔文（$m{
u}$K）原子的目标，速度比手动实验快约100倍。它还能自主识别多参数实验中的异常参数。

Conclusion: QCopilot通过集成外部知识访问、主动学习和不确定性量化，成功地解决了量子传感器开发中的跨学科知识壁垒和复杂优化问题。通过在原子冷却实验中的应用，实现了无需人工干预、数小时内生成10${}^{m{8}}$亚微开尔文（$m{
u}$K）原子的目标，并将实验速度提高了约100倍。该框架通过持续积累先验知识和动态建模，能够自主识别多参数实验中的异常参数，为大规模量子传感器部署降低了门槛，并可扩展到其他量子信息系统。

Abstract: Large language models (LLM) exhibit broad utility but face limitations in
quantum sensor development, stemming from interdisciplinary knowledge barriers
and involving complex optimization processes. Here we present QCopilot, an
LLM-based multi-agent framework integrating external knowledge access, active
learning, and uncertainty quantification for quantum sensor design and
diagnosis. Comprising commercial LLMs with few-shot prompt engineering and
vector knowledge base, QCopilot employs specialized agents to adaptively select
optimization methods, automate modeling analysis, and independently perform
problem diagnosis. Applying QCopilot to atom cooling experiments, we generated
10${}^{\rm{8}}$ sub-$\rm{\mu}$K atoms without any human intervention within a
few hours, representing $\sim$100$\times$ speedup over manual experimentation.
Notably, by continuously accumulating prior knowledge and enabling dynamic
modeling, QCopilot can autonomously identify anomalous parameters in
multi-parameter experimental settings. Our work reduces barriers to large-scale
quantum sensor deployment and readily extends to other quantum information
systems.

</details>


### [342] [Block entanglement bounds distribution of regionally localized entanglement](https://arxiv.org/abs/2508.05431)
*Jithin G. Krishnan,Aditi Sen De,Amit Kumar Pal*

Main category: quant-ph

TL;DR: 量子网络可以通过“区域局部纠缠”来衡量纠缠，这与“中心枢纽”和“可定位块纠缠”有关，并为某些量子态提供了边界，即使在有噪声的情况下也能保持。


<details>
  <summary>Details</summary>
Motivation: 在量子网络中，需要消除节点连接以减轻退相干效应，并表征由此产生的较小网络的纠缠内容。

Method: 通过定义“区域局部纠缠”和“中心枢纽”，并将总区域局部纠缠与“可定位块纠缠”联系起来，来表征量子网络的纠缠内容。

Result: 证明了总区域局部纠缠与中心枢纽及其余系统的可定位块纠缠之间存在上限和下限关系，适用于某些纯量子态。数值模拟证实，即使在有噪声的情况下，对于对称纯态，这些边界也是有效的。不同磁化扇区的状态与对称态相比，具有不同的边界，显示出其独特的纠缠特性。

Conclusion: 这项工作提出了“区域局部纠缠”的概念，它量化了多量子比特系统中两比特区域的平均纠缠。该指标与“中心枢纽”及其余系统的“可定位块纠缠”相关联，为纯量子态（包括对称态和特定磁化扇区中的态）提供了上限和下限。

Abstract: In quantum networks, eliminating connections between nodes is crucial to
mitigate the effects of decoherence, often achieved by performing measurements
on nodes that are idle, or vulnerable to noise. To characterize the
entanglement content of the resulting smaller network, we introduce the notion
of ``regionally localized entanglement", defined as the average entanglement
concentrated over a two-qubit region in a multi-qubit system. Hence, the total
regionally localized entanglement can be obtained by considering all two-qubit
regions sharing a common qubit, referred to as the ``hub". We prove that the
total regionally localized entanglement corresponding to a specific hub is
bounded above and below via the localizable block entanglement shared between
the hub and the rest of the multi-qubit system for a number of paradigmatic
pure quantum states, including permutation-symmetric states and arbitrary
superposition of states from a specific magnetization sector. Numerical
simulations confirm that the bounds for permutation-symmetric pure states
remain valid even for Haar-uniformly generated pure states, and when each of
the qubits is sent through local phase-flip channels of Markovian and
non-Markovian types, except when the system-size is small. On the other hand,
arbitrary states from a particular magnetization sector yield bounds on total
regionally localized entanglement that are distinct from the
permutation-symmetric states, highlighting the structurally unique entanglement
properties of the former.

</details>


### [343] [Efficient certification of high-dimensional entanglement](https://arxiv.org/abs/2508.05484)
*Yiwen Wu,Zihao Li,Huangjun Zhu*

Main category: quant-ph

TL;DR: This paper presents an efficient framework to certify high-dimensional entanglement in quantum states using limited operations, showing it's feasible and becomes easier with larger local dimensions. It also offers an optimal strategy for two-qubit states.


<details>
  <summary>Details</summary>
Motivation: Efficient certification of high-dimensional entanglement (HDE) is crucial for many applications in quantum information processing.

Method: A simple and general framework for certifying HDE in general bipartite pure states under restricted operations (LOCC) is proposed. An optimal entanglement certification strategy for general two-qubit pure states based on separable operations is constructed.

Result: High-dimensional entanglement (HDE) in general bipartite pure states can be certified efficiently. The sample cost for certifying a given degree of HDE decreases monotonically with the local dimensions. An optimal entanglement certification strategy for a general two-qubit pure state is constructed.

Conclusion: HDE can be certified efficiently in general bipartite pure states under restricted operations like LOCC. The sample cost decreases monotonically with local dimensions. An optimal entanglement certification strategy for two-qubit pure states is constructed.

Abstract: High-dimensional entanglement (HDE) is a valuable resource in quantum
information processing, and efficient certification of HDE is crucial to many
applications. In this work, we propose a simple and general framework for
certifying HDE in general bipartite pure states under restricted operations,
such as local operations and classical communication (LOCC). On this basis we
show that HDE in general bipartite pure states can be certified efficiently.
Moreover, the sample cost for certifying a given degree of HDE even decreases
monotonically with the local dimensions. In addition, for a general two-qubit
pure state, we construct an optimal entanglement certification strategy based
on separable operations, which can be realized by LOCC when the target state
has sufficiently high entanglement. The core concept of our framework is
versatile and can be extended to certify a wide range of critical resources
under restricted operations.

</details>


### [344] [Efficient Mediated Multiparty Semi-Quantum Secret Sharing Protocol Based on Single-Qubit Reordering](https://arxiv.org/abs/2508.05487)
*Mustapha Anis Younes,Sofia Zebboudj,Abdelhakim Gharbi*

Main category: quant-ph

TL;DR: 本研究提出了一个简化的多方半量子秘密共享协议，降低了经典用户的操作要求，并首次使用单个量子位作为量子资源，提高了效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决了现有典型多方半量子秘密共享（MSQSS）协议需要庄家具备完全量子能力，以及经典用户需要执行三个操作的实际限制。

Method: 提出了一种新的 the mediated MSQSS protocol，该协议使得经典用户Alice能够与M个经典的Bobs共享秘密，并由一个不可信的第三方（TP）协助。该协议只需要参与者执行两个操作：(a) 在Z基进行测量；(b) 重排序量子比特。

Result: Alice与M个经典的Bobs共享秘密，TP作为辅助方。相比现有方案，该协议使用单个量子位而非纠缠态，量子比特效率更高。

Conclusion: 该协议是第一个采用单个量子位而非纠缠态作为量子资源的多方半量子秘密共享协议，更具实用性和易实现性，并且具有更高的量子比特效率。安全分析表明该协议可防御已知攻击。

Abstract: Typical multiparty semi-quantum secret sharing (MSQSS) protocols require the
dealer to possess full quantum capabilities, while the classical users usually
need to perform three operations. To address this practical limitation, this
paper introduces a new mediated MSQSS protocol that enables Alice, a classical
user, to share a secret with $M$ classical Bobs, with the assistance of an
untrusted third party (TP) who may attempt any possible attack to steal Alice's
secret. Furthermore, the classical participants require only two capabilities
instead of three, namely: (a) performing measurements in the $Z$ basis; and (b)
reordering qubits. The proposed scheme offers significant advantages over
existing mediated QSS protocols: (1) it is the first mediated SQSS protocol to
adopt single qubits, instead of entangled states, as the quantum resource,
which makes it more practical and easier to implement; (2) It achieves higher
qubit efficiency. Security analysis also demonstrates that the protocol is
secure against well-known attacks.

</details>


### [345] [$Λ$-Type Giant Atom Mediated Controllable Single-Photon Transport in a One-Dimensional Chiral Waveguide](https://arxiv.org/abs/2508.05510)
*Yimei Wang,Jing Li,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 本研究利用实空间散射方法，分析了驱动$\\%0$型巨原子与一维波导的手征耦合的单光子散射谱。结果发现，驱动场可诱导双谷透射谱，手征耦合可控制光子透射与反射，且巨原子尺寸影响非马尔可夫状态下的散射谱振荡行为。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索驱动的 $\Lambda$ 型巨原子系统与一维波导的手征耦合的单光子散射谱。

Method: 采用实空间散射方法，获得了在马尔可夫和非马尔可夫两种状态下均有效的散射振幅解析解。

Result: 成功获得了散射振幅的解析解，并发现外部驱动场在透射谱中产生双谷现象，该现象与驱动场强度相关。手征耦合实现了光子透射与反射的切换，并在特定相位实现了完美透射。在非马尔可夫状态下，巨原子尺寸影响了散射谱的振荡行为，并可用于控制解耦点和完美反射点的数量。

Conclusion: 该研究表明，外部驱动场能将透射谱的谷分裂成双谷，且谷间距随驱动场强度的增强而增大。该系统的手征耦合允许在完全透射和完美反射入射光子之间进行受控切换。在马尔可夫极限下，无论驱动场参数如何，在特定的相位值下都能实现鲁棒的完美透射。此外，在非马尔可夫极限下，随着巨原子尺寸的增大，散射谱的振荡行为更加明显，并且可以通过调整巨原子尺寸来控制解耦点和完美反射点的数量。

Abstract: We investigate the single-photon scattering spectrum of a driven
$\Lambda$-type giant atom system chirally coupled to a one-dimensional (1D)
waveguide. By employing a real-space scattering approach, we obtain analytical
solutions for the scattering amplitudes that remain valid in both Markovian and
non-Markovian regimes. We observe that an external driving field induces a
splitting of the transmission spectrum's dip into double dips, with the
distance between the two dips increasing as the strength of the driving field
increases. The chiral nature of the coupling allows for controlled switching
between complete transmission and perfect reflection of incident photons. In
the Markovian limit, we predict robust perfect transmission at specific phase
values, independent of the driving field parameters.Moreover, in the
non-Markovian regime, as the size of the giant atom increases, the oscillatory
behavior of the scattering spectrum becomes more pronounced. Adjusting the
giant atom size enables control over the number of decoupling points as well as
the number of complete reflection points.

</details>


### [346] [Logical accreditation: a framework for efficient certification of fault-tolerant computations](https://arxiv.org/abs/2508.05523)
*James Mills,Adithya Sireesh,Dominik Leichtle,Joschka Roffe,Elham Kashefi*

Main category: quant-ph

TL;DR: 为容错量子计算中的逻辑量子比特提出了一种名为逻辑认证的新框架，并通过一种新的随机编译技术解决了关键的技术难题，实现了可扩展且设备无关的计算认证。


<details>
  <summary>Details</summary>
Motivation: 随着容错量子计算机的发展，对其进行可扩展、设备无关的认证变得至关重要，以确保逻辑量子比特计算的准确性。

Method: 提出了一种名为逻辑认证（logical accreditation）的新框架，并通过一种新颖的随机编译方案将任意逻辑电路噪声转换为随机保利噪声（stochastic Pauli noise），该方案解决了针对标准T门以外的非横向逻辑门进行旋转（twirling）的难题。

Result: 通过数值模拟，证明了逻辑认证能够有效地认证量子优势实验，并确定了逻辑计算超越物理计算的临界点。此外，它还能用于评估逻辑电路的错误率，为基于量子纠错码的性能分析提供了一种超越标准噪声模型的鲁棒方法，并将熵基准测试方法扩展到容错计算领域，同时给出了逻辑输出态的上限保真度。

Conclusion: 逻辑认证作为一种高效的认证框架，能够为容错量子计算中的逻辑量子比特执行提供可扩展的认证方法，并能有效评估逻辑电路的错误率，为容错计算与计算认证之间架起了桥梁。

Abstract: As fault-tolerant quantum computers scale, certifying the accuracy of
computations performed with encoded logical qubits will soon become classically
intractable. This creates a critical need for scalable, device-independent
certification methods. In this work, we introduce logical accreditation, a
framework for efficiently certifying quantum computations performed on logical
qubits. Our protocol is robust against general noise models, far beyond those
typically considered in performance analyses of quantum error-correcting codes.
Through numerical simulations, we demonstrate that logical accreditation can
scalably certify quantum advantage experiments and indicate the crossover point
where encoded computations begin to outperform physical computations. Logical
accreditation can also find application in evaluating whether logical circuit
error rates are sufficiently low that error mitigation can be efficiently
performed, extending the entropy benchmarking method to the regime of
fault-tolerant computation, and upper-bounding the infidelity of the logical
output state. Underpinning the framework is a novel randomised compiling scheme
that converts arbitrary logical circuit noise into stochastic Pauli noise. This
scheme includes a method for twirling non-transversal logical gates beyond the
standard T-gate, resolving an open problem posed by Piveteau et al. [Piveteau
et al. PRL 127, 200505 (2001)]. By bridging fault-tolerant computation and
computational certification, logical accreditation offers a practical tool to
assess the quality of computations performed on quantum hardware using encoded
logical qubits.

</details>


### [347] [Model-based framework for automated quantification of error sources in quantum state tomography](https://arxiv.org/abs/2508.05538)
*Junpei Oba,Hsin-Pin Lo,Yasuhiro Yamada,Takayuki Matsui,Takuya Ikuta,Yuya Yonezu,Toshimori Honjo,Seiji Kajita,Hiroki Takesue*

Main category: quant-ph

TL;DR: An automated method combining simulation and optimization quantifies errors in quantum state generation by modeling and fitting experimental data, improving state quality and applicable to various quantum platforms.


<details>
  <summary>Details</summary>
Motivation: To address the difficulty in identifying individual error sources in Quantum State Tomography (QST) where multiple errors converge in a single density matrix, hindering the improvement of quantum state quality for applications like quantum communication, sensing, and computing.

Method: Combining simulation and parameter optimization to reproduce the experimental density matrix, focusing on modeling error sources for time-bin entangled photon pairs and optimizing parameters to minimize trace distance to experimental data.

Result: Reduced the trace distance from 0.177 to 0.024, indicating that the modeled error sources explain 86% of the errors. This reduction in predicted error sources improved the state quality, consistent with predictions and validating the proposed method.

Conclusion: The proposed automated method, by combining simulation and parameter optimization, successfully quantifies error sources in quantum state generation by reproducing the experimental density matrix. This method reduced the trace distance from 0.177 to 0.024, explaining 86% of the errors and validating the approach. The modular structure allows for application to other quantum platforms.

Abstract: High-quality quantum state generation is essential for advanced quantum
information processing, including quantum communication, quantum sensing, and
quantum computing. In practice, various error sources degrade the quality of
quantum states, and quantum state tomography (QST) is a standard diagnostic
tool. However, in QST, multiple error sources gather in a single density
matrix, making it difficult to identify individual error sources. To address
this problem, we propose an automated method for quantifying error sources by
combining simulation and parameter optimization to reproduce the experimental
density matrix. We focus on the experimental generation of time-bin entangled
photon pairs, for which we model the relevant error sources and simulate the
density matrix with adjustable model parameters, thereby optimizing the
parameters and minimizing the trace distance to the experimental data.
Optimization of the parameters reduced the trace distance from 0.177 to 0.024,
indicating that our modeled error sources explain 86% of the errors. Reducing
the predicted error sources improves the state quality, consistent with our
predictions and thus validating the proposed method. In addition, the modular
structure of this framework makes it applicable to other quantum platforms,
such as superconducting qubits, atoms, and solid-state spins.

</details>


### [348] [On the Design of Expressive and Trainable Pulse-based Quantum Machine Learning Models](https://arxiv.org/abs/2508.05559)
*Han-Xiao Tao,Xin Wang,Re-Bing Wu*

Main category: quant-ph

TL;DR: 脉冲基QML模型在动态对称下可训练，但可能牺牲表达能力。本研究提出了一个必要条件来平衡表达能力和可训练性，为设计实际的脉冲基QML模型提供了框架。


<details>
  <summary>Details</summary>
Motivation: 为了在实际应用中有效利用硬件效率高的脉冲基QML模型，必须使其既有表达能力又可训练。

Method: 通过数值模拟，提出了一个关于系统初始状态、测量可观测量和动力学对称李代人的必要条件。

Result: 找到了脉冲基QML模型在动态对称下可训练且不存在无望平坦区，但可能牺牲表达能力。本研究提出了一个必要条件来确保模型的表达能力和可训练性。

Conclusion: 本研究提出了脉冲基QML模型的设计框架，以平衡表达能力和可训练性。

Abstract: Pulse-based Quantum Machine Learning (QML) has emerged as a novel paradigm in
quantum artificial intelligence due to its exceptional hardware efficiency. For
practical applications, pulse-based models must be both expressive and
trainable. Previous studies suggest that pulse-based models under dynamic
symmetry can be effectively trained, thanks to a favorable loss landscape that
has no barren plateaus. However, the resulting uncontrollability may compromise
expressivity when the model is inadequately designed. This paper investigates
the requirements for pulse-based QML models to be expressive while preserving
trainability. We present a necessary condition pertaining to the system's
initial state, the measurement observable, and the underlying dynamical
symmetry Lie algebra, supported by numerical simulations. Our findings
establish a framework for designing practical pulse-based QML models that
balance expressivity and trainability.

</details>


### [349] [Quench dynamics of entanglement entropy under projective charge measurements: the free fermion case](https://arxiv.org/abs/2508.05588)
*Riccardo Travaglino,Colin Rylands,Pasquale Calabrese*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the effect of projective measurements on the quench dynamics of
the bipartite entanglement entropy in one dimensional free fermionic systems.
In our protocol, we consider projective measurements of a $U(1)$ conserved
charge, the particle number, on some large subsystem, and study the
entanglement entropies between the same subsystem and its complement. We
compare the dynamics emanating from two classes of initial states, one which is
an eigenstate of the charge and another which is not. Moreover, we consider the
effects of a single measurement as well as multiple which are periodically
performed. Using the quasiparticle picture, we obtain analytic expressions for
the behaviour of the entanglement which admit a transparent physical
interpretation. In general, we find that measurements introduce two distinct
types of corrections to the entanglement, which can be interpreted separately
as classical and quantum contributions. The classical contribution is
independent of the measurement outcome and scales logarithmically with variance
of the charge distribution. In contrast, the quantum contribution depends on
the specific measurement outcome and can be significant for individual
realizations; however, it becomes negligible when averaged over all possible
outcomes. Our expressions reduce to previously known results for symmetry
resolved entanglement and full counting statistics in some relevant limits, and
are confirmed by an exact calculation performed on the N\'eel initial state.

</details>


### [350] [Secure Quantum Key Distribution via Entangled Quantum Walkers](https://arxiv.org/abs/2508.05593)
*Chia-Tso Lai*

Main category: quant-ph

TL;DR: 提出了一种基于两个纠缠量子行走者的新型QKD协议，利用量子行走末端的关联来建立安全密钥。


<details>
  <summary>Details</summary>
Motivation: 受量子密钥分发（QKD）和量子随机行走（QRW）的启发，提出一种新的QKD协议。

Method: 提出了一种基于两个纠缠量子行走者的新型量子密钥分发（QKD）协议，该协议利用了量子行走中的干涉和叠加等现象。

Result: 该协议利用了两个纠缠量子行走者在行走末端的独特关联来建立共享密钥，并且其安全性通过分析行走者测量位置的联合概率分布及其相关币状态得到增强。

Conclusion: 该协议利用了两个纠缠量子行走者在行走末端的独特关联来建立共享密钥，并且其安全性通过分析行走者测量位置的联合概率分布及其相关币状态得到增强。

Abstract: Quantum Key Distribution (QKD) is an emerging cryptographic method designed
for secure key sharing. Its security is theoretically guaranteed by fundamental
principles of quantum mechanics, making it a leading candidate for future
communication protocols. Quantum Random Walks (QRWs), on the other hand, are
quantum processes that exhibit intriguing phenomena such as interference and
superposition, enabling the generation of decentralized and asymmetric
probability distributions. Inspired by both fields of study, we propose a novel
QKD protocol based on two entangled quantum walkers. Our protocol exploits the
unique correlations between the walkers at extremal positions of the walk to
establish secret keys shared exclusively by the two parties. The security of
the protocol is augmented by analyzing the joint probability distributions of
the walkers' measured positions and their associated coin states.

</details>


### [351] [Ultra-Large-Scale Compilation and Manipulation of Quantum Circuits with Pandora](https://arxiv.org/abs/2508.05608)
*Ioana Moflic,Alexandru Paler*

Main category: quant-ph

TL;DR: Pandora是一个高效的量子电路编译和分析工具，能够处理大规模电路，并在性能上优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 为了弥合当前量子软件在编译和操作量子电路的能力与实际应用（如量子化学或Shor算法）所需规模之间的巨大差距。

Method: Pandora是一个基于电路重写的、开源的、多线程的高性能计算工具。

Result: Pandora能够处理数十亿个门控电路，并以很高的速率在资源估算流水线中对电路分区进行流式传输。与TKET和Qiskit相比，Pandora在操作超过10000个门控的电路方面具有性能优势。在等价性检查任务中，Pandora在超过32个量子比特的特定电路上优于MQT.QCEC。

Conclusion: Pandora在处理大规模量子电路方面表现出优越的性能和多功能性，为量子软件开辟了新的道路。

Abstract: There is an enormous gap between what quantum circuit sizes can be compiled
and manipulated with the current generation of quantum software and the sizes
required by practical applications such as quantum chemistry or Shor's
algorithm. We present Pandora, an efficient, open-source, multithreaded,
high-performance-computing-enabled tool based on circuit rewrites. Pandora can
be used for quantum circuit equivalence checking, full compilations of large
circuits, and scalable, streaming quantum resource estimation frameworks.
Pandora can easily handle billions of gates and can stream circuit partitions
in resource estimation pipelines at very high rates. We utilized Pandora for
full compilations of Fermi-Hubbard 100x100 and 1024-bit Shor's algorithm
circuits. Compared to TKET and Qiskit, we determine a performance advantage for
manipulating circuits of more than 10000 gates. For equivalence checking tasks,
Pandora outperforms MQT.QCEC on specific circuits that have more than 32
qubits. The performance and versatility of Pandora open novel paths in quantum
software.

</details>


### [352] [Partial projected ensembles and spatiotemporal structure of information scrambling](https://arxiv.org/abs/2508.05632)
*Saptarshi Mandal,Pieter W. Claeys,Sthitadhi Roy*

Main category: quant-ph

TL;DR: 该研究提出了部分投影系综（PPE）框架，用以分析量子多体系统中的信息传播。PPE 通过追踪测量结果的统计涨落和比特串概率，能够揭示 scrambling 的时空结构，并区分不同的动力学机制，为实验研究提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 为了更深入地理解非平衡量子多体系统中热化和信息 scrambling 之间的关系，以及如何通过局部子系统逼近热密度矩阵并追踪信息传播。

Method: 提出了一种名为“部分投影系综”（PPE）的新框架，用于研究信息 scrambling 的时空结构如何体现在投影系综中。PPE 通过对互补子系统的测量结果进行条件化，并在追踪信息传播的同时，将非此子系统的部分迹化，来构成一个混合态系综。

Result: PPE 的统计涨落忠实地追踪了信息传播的因果光锥，揭示了 scrambling 动力学是如何编码在系综结构中的。PPE 的比特串概率（PoPs）展现出独特的动力学机制，并对丢弃区域的大小呈现指数敏感性。

Conclusion: 所提出的部分投影系综（PPE）框架能够有效地研究量子多体系统中信息 the spatiotemporal structure of scrambling 动力学。PPE 的统计涨落和比特串概率（PoPs）都能作为探测 the spatiotemporal structure of scrambling 的实验可及探针。该方法在 the kicked Ising chain 和 the $\ell$-bit model 中都得到了验证，能够区分 the ergodic 和 MBL 两种动力学机制。

Abstract: Thermalisation and information scrambling in out-of-equilibrium quantum
many-body systems are deeply intertwined: local subsystems dynamically approach
thermal density matrices while their entropies track information spreading.
Projected ensembles--ensembles of pure states conditioned on measurement
outcomes of complementary subsystems--provide higher-order probes of
thermalisation, converging at late times to universal maximum-entropy
ensembles. In this work, we introduce the partial projected ensemble (PPE) as a
framework to study how the spatiotemporal structure of scrambling is imprinted
on projected ensembles. The PPE consists of an ensemble of mixed states induced
on a subsystem by measurements on a spatially separated part of its complement,
tracing out the remainder, naturally capturing scenarios involving discarded
outcomes or noise-induced losses. We show that statistical fluctuations of the
PPE faithfully track the causal lightcone of information spreading, revealing
how scrambling dynamics are encoded in ensemble structure. In addition, we
demonstrate that the probabilities of bit-string probabilities (PoPs)
associated with the PPE exhibit distinct dynamical regimes and provide an
experimentally accessible probe of scrambling. Both PPE fluctuations and PoPs
display exponential sensitivity to the size of the discarded region, reflecting
exponential degradation of quantum correlations under erasure. We substantiate
these findings using the non-integrable kicked Ising chain, combining numerics
in the ergodic regime with exact results at its self-dual point. We extend our
analysis to a many-body localised (MBL) regime numerically, along with analytic
results for the $\ell$-bit model. The linear and logarithmic lightcones
characteristic of ergodic and MBL regimes emerge naturally from PPE dynamics,
establishing it as a powerful tool for probing scrambling and deep
thermalisation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [353] [On the causality between affective impact and coordinated human-robot reactions](https://arxiv.org/abs/2508.04834)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 机器人对共享事件的反应会影响人类的看法。研究发现，200毫秒的延迟对小型非人型机器人影响最大，而100毫秒的延迟则最能让观察者感觉自己对机器人产生了影响。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人在社交环境中的功能，本研究调查了一个机器人是否通过与人类分享对事件的反应来改变人类对机器人情感影响的看法。

Method: 该研究通过两个不同的测试设置进行。第一个测试隔离了机器人情感表达的反应因素，第二个测试研究了将特定时间延迟应用于机器人对与人类的物理遭遇做出反应的效果。第一个测试有两组（n=84）观察者，第二测试有110名参与者。

Result: 结果表明，当机器人对与人类观察者共享的事件做出反应时，与随机做出反应相比，机器人的感知情感影响发生了统计学上的显著变化（p<0.05）。此外，对于共享的物理互动，机器人接近人类的反应时间最适合该场景。

Conclusion: 机器人对共享事件的反应会改变人类对其情感影响的看法。对于小型非人型机器人，大约200毫秒的延迟时间可能对人类观察者产生最大的影响。对于旨在使人类观察者感觉他们对机器人产生最大影响的目标，大约100毫秒的反应时间最为有效。

Abstract: In an effort to improve how robots function in social contexts, this paper
investigates if a robot that actively shares a reaction to an event with a
human alters how the human perceives the robot's affective impact. To verify
this, we created two different test setups. One to highlight and isolate the
reaction element of affective robot expressions, and one to investigate the
effects of applying specific timing delays to a robot reacting to a physical
encounter with a human. The first test was conducted with two different groups
(n=84) of human observers, a test group and a control group both interacting
with the robot. The second test was performed with 110 participants using
increasingly longer reaction delays for the robot with every ten participants.
The results show a statistically significant change (p$<$.05) in perceived
affective impact for the robots when they react to an event shared with a human
observer rather than reacting at random. The result also shows for shared
physical interaction, the near-human reaction times from the robot are most
appropriate for the scenario. The paper concludes that a delay time around
200ms may render the biggest impact on human observers for small-sized
non-humanoid robots. It further concludes that a slightly shorter reaction time
around 100ms is most effective when the goal is to make the human observers
feel they made the biggest impact on the robot.

</details>


### [354] [INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM](https://arxiv.org/abs/2508.04931)
*Jin Wang,Weijie Wang,Boyuan Deng,Heng Zhang,Rui Dai,Nikos Tsagarakis*

Main category: cs.RO

TL;DR: INTENTION框架利用视觉-语言模型和交互记忆，使机器人具备学习到的交互直觉，能在真实场景中进行自主操纵。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人操纵控制和规划依赖于精确的物理模型和预定义的动作序列，在结构化环境中有效，但在真实场景中由于模型不准确和难以泛化到新任务而失败。而人类能够直观地与周围环境互动，展示出卓越的适应性，并通过隐性物理理解做出有效的决策。

Method: 通过整合视觉-语言模型（VLM）的场景推理和驱动交互的记忆，并引入记忆图（Memory Graph）来记录任务交互的场景，以及设计直观感知器（Intuitive Perceptor）来提取视觉场景中的物理关系和可供性。

Result: 该框架使机器人能够在没有重复指令的情况下，从新场景中推断出合适的交互行为。

Conclusion: 机器人可以通过整合视觉-语言模型（VLM）的场景推理和驱动交互的记忆，在各种场景中实现学习到的交互直觉和自主操纵。

Abstract: Traditional control and planning for robotic manipulation heavily rely on
precise physical models and predefined action sequences. While effective in
structured environments, such approaches often fail in real-world scenarios due
to modeling inaccuracies and struggle to generalize to novel tasks. In
contrast, humans intuitively interact with their surroundings, demonstrating
remarkable adaptability, making efficient decisions through implicit physical
understanding. In this work, we propose INTENTION, a novel framework enabling
robots with learned interactive intuition and autonomous manipulation in
diverse scenarios, by integrating Vision-Language Models (VLMs) based scene
reasoning with interaction-driven memory. We introduce Memory Graph to record
scenes from previous task interactions which embodies human-like understanding
and decision-making about different tasks in real world. Meanwhile, we design
an Intuitive Perceptor that extracts physical relations and affordances from
visual scenes. Together, these components empower robots to infer appropriate
interaction behaviors in new scenes without relying on repetitive instructions.
Videos: https://robo-intention.github.io

</details>


### [355] [Optimal Planning for Multi-Robot Simultaneous Area and Line Coverage Using Hierarchical Cyclic Merging Regulation](https://arxiv.org/abs/2508.04981)
*Tianyuan Zheng,Jingang Yi,Kaiyan Yu*

Main category: cs.RO

TL;DR: 提出HCMR算法解决多机器人双重覆盖问题，通过分层循环合并调控和Morse理论分析，显著提升了路径规划效率并保证了无冲突操作。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人同时覆盖线性特征（如地表裂缝）和区域（如停车场）的双重覆盖问题，同时要满足效率、无碰撞和不同机器人角色（服务-线性覆盖，探索-区域覆盖）的成本差异。

Method: 提出了一种名为“分层循环合并调控”（HCMR）的算法，并从Morse理论角度分析了图遍历中的流形附件过程，以减少最优规划解决方案的复杂性。HCMR算法通过循环合并搜索来调控遍历行为，通过边序列反向传播将调控转化为图边遍历序列，并结合平衡划分来选择最优序列，从而为每个机器人生成路径。

Result: HCMR算法能显著提高规划路径长度（至少10.0%），减少任务时间（平均至少16.9%），并确保冲突。

Conclusion: HCMR算法在固定扫描方向下具有最优性，并且在多机器人路径规划中，相较于其他现有方法，能显著提高路径长度（至少10.0%），减少任务时间（平均至少16.9%），并确保无冲突操作。

Abstract: The double coverage problem focuses on determining efficient, collision-free
routes for multiple robots to simultaneously cover linear features (e.g.,
surface cracks or road routes) and survey areas (e.g., parking lots or local
regions) in known environments. In these problems, each robot carries two
functional roles: service (linear feature footprint coverage) and exploration
(complete area coverage). Service has a smaller operational footprint but
incurs higher costs (e.g., time) compared to exploration. We present optimal
planning algorithms for the double coverage problems using hierarchical cyclic
merging regulation (HCMR). To reduce the complexity for optimal planning
solutions, we analyze the manifold attachment process during graph traversal
from a Morse theory perspective. We show that solutions satisfying minimum path
length and collision-free constraints must belong to a Morse-bounded
collection. To identify this collection, we introduce the HCMR algorithm. In
HCMR, cyclic merging search regulates traversal behavior, while edge sequence
back propagation converts these regulations into graph edge traversal
sequences. Incorporating balanced partitioning, the optimal sequence is
selected to generate routes for each robot. We prove the optimality of the HCMR
algorithm under a fixed sweep direction. The multi-robot simulation results
demonstrate that the HCMR algorithm significantly improves planned path length
by at least 10.0%, reduces task time by at least 16.9% in average, and ensures
conflict-free operation compared to other state-of-the-art planning methods.

</details>


### [356] [Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots](https://arxiv.org/abs/2508.04994)
*Wenjie Hu,Ye Zhou,Hann Woei Ho*

Main category: cs.RO

TL;DR: HDDPG 算法通过引入高层和低层策略来改进 DDPG 在迷宫导航中的表现。它通过生成子目标、使用离策略修正、改进探索和奖励函数来提高稳定性和学习效率。实验证明，HDDPG 在成功率和平均奖励方面显著优于标准 DDPG。


<details>
  <summary>Details</summary>
Motivation: 标准 DDPG 算法在迷宫导航中的性能受到稀疏奖励、探索效率低下和长期规划困难的限制，这通常会导致较低的成功率和平均奖励，有时甚至无法实现有效的导航。

Method: 提出了一种高效的层次化 DDPG (HDDPG) 算法，该算法包含一个高层策略和一个低层策略。高层策略使用先进的 DDPG 框架从长远和更高的时间尺度生成中间子目标。低层策略也由改进的 DDPG 算法驱动，通过观察当前状态并遵循高层策略分配的子目标来生成基本动作。该方法通过使用离策略修正来增强稳定性，并通过重新标记历史经验来优化子目标分配。此外，还利用自适应参数空间噪声来改进探索，并采用重塑的内在-外在奖励函数来提高学习效率。额为地，采用了梯度裁剪和 Xavier 初始化等优化措施来提高鲁棒性。

Result: HDDPG 在三个不同的自主迷宫导航任务的最终目标方面，显著克服了标准 DDPG 及其变体的局限性，成功率至少提高了 56.59%，平均奖励至少提高了 519.03。

Conclusion: HDDPG 显著克服了标准 DDPG 及其变体的局限性，在自主迷宫导航任务中，与基线算法相比，成功率至少提高了 56.59%，平均奖励至少提高了 519.03。

Abstract: Maze navigation is a fundamental challenge in robotics, requiring agents to
traverse complex environments efficiently. While the Deep Deterministic Policy
Gradient (DDPG) algorithm excels in control tasks, its performance in maze
navigation suffers from sparse rewards, inefficient exploration, and
long-horizon planning difficulties, often leading to low success rates and
average rewards, sometimes even failing to achieve effective navigation. To
address these limitations, this paper proposes an efficient Hierarchical DDPG
(HDDPG) algorithm, which includes high-level and low-level policies. The
high-level policy employs an advanced DDPG framework to generate intermediate
subgoals from a long-term perspective and on a higher temporal scale. The
low-level policy, also powered by the improved DDPG algorithm, generates
primitive actions by observing current states and following the subgoal
assigned by the high-level policy. The proposed method enhances stability with
off-policy correction, refining subgoal assignments by relabeling historical
experiences. Additionally, adaptive parameter space noise is utilized to
improve exploration, and a reshaped intrinsic-extrinsic reward function is
employed to boost learning efficiency. Further optimizations, including
gradient clipping and Xavier initialization, are employed to improve
robustness. The proposed algorithm is rigorously evaluated through numerical
simulation experiments executed using the Robot Operating System (ROS) and
Gazebo. Regarding the three distinct final targets in autonomous maze
navigation tasks, HDDPG significantly overcomes the limitations of standard
DDPG and its variants, improving the success rate by at least 56.59% and
boosting the average reward by a minimum of 519.03 compared to baseline
algorithms.

</details>


### [357] [MAG-Nav: Language-Driven Object Navigation Leveraging Memory-Reserved Active Grounding](https://arxiv.org/abs/2508.05021)
*Weifan Zhang,Tingguang Li,Yuzhen Liu*

Main category: cs.RO

TL;DR: 提出了一种结合了视角调整和历史记忆回溯的视觉导航框架，使用户能够通过自然语言指令在未知环境中进行导航。该方法在Habitat-Matterport 3D数据集上表现优于现有方法，并在实际的四足机器人上得到了验证。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中仅依靠自然语言描述进行视觉导航是智能机器人的关键能力。

Method: 提出了一种基于现成的视觉语言模型（VLMs）的导航框架，并辅以两种受人类启发的机制：基于视角的积极接地，动态调整机器人的视角以改进视觉检查；以及历史记忆回溯，使系统能够随着时间的推移保留和重新评估不确定的观测。

Result: 在Habitat-Matterport 3D (HM3D)数据集上，该方法在语言驱动的目标导航任务上超越了现有的最先进方法。通过在现实世界的四足机器人上的部署，也证明了其鲁棒性和有效性。

Conclusion: 该框架在Habitat-Matterport 3D (HM3D)上的实验结果表明，在语言驱动的目标导航方面，我们的方法优于最先进的方法。此外，通过在四足机器人上进行实际部署，我们证明了其可行性，实现了稳健有效的导航性能。

Abstract: Visual navigation in unknown environments based solely on natural language
descriptions is a key capability for intelligent robots. In this work, we
propose a navigation framework built upon off-the-shelf Visual Language Models
(VLMs), enhanced with two human-inspired mechanisms: perspective-based active
grounding, which dynamically adjusts the robot's viewpoint for improved visual
inspection, and historical memory backtracking, which enables the system to
retain and re-evaluate uncertain observations over time. Unlike existing
approaches that passively rely on incidental visual inputs, our method actively
optimizes perception and leverages memory to resolve ambiguity, significantly
improving vision-language grounding in complex, unseen environments. Our
framework operates in a zero-shot manner, achieving strong generalization to
diverse and open-ended language descriptions without requiring labeled data or
model fine-tuning. Experimental results on Habitat-Matterport 3D (HM3D) show
that our method outperforms state-of-the-art approaches in language-driven
object navigation. We further demonstrate its practicality through real-world
deployment on a quadruped robot, achieving robust and effective navigation
performance.

</details>


### [358] [Benchmarking Shortcutting Techniques for Multi-Robot-Arm Motion Planning](https://arxiv.org/abs/2508.05027)
*Philip Huang,Yorai Shaoul,Jiaoyang Li*

Main category: cs.RO

TL;DR: 该研究比较和改进了用于多臂机器人运动规划的缩短技术。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法难以生成高质量的多臂运动计划，且缩短技术的性能和影响通常描述不清。

Method: 对现有的缩短技术进行了定量比较，并提出了两种组合这些技术以实现最佳性能-运行时间权衡的策略。

Result: 对现有的缩短技术进行了全面的定量比较，并提出了一种结合这些技术以优化性能-运行时间权衡的新方法。

Conclusion: 该研究全面比较了多臂机器人运动规划中现有缩短技术，并提出了一种结合这些技术以优化性能-运行时间权衡的新方法。

Abstract: Generating high-quality motion plans for multiple robot arms is challenging
due to the high dimensionality of the system and the potential for inter-arm
collisions. Traditional motion planning methods often produce motions that are
suboptimal in terms of smoothness and execution time for multi-arm systems.
Post-processing via shortcutting is a common approach to improve motion quality
for efficient and smooth execution. However, in multi-arm scenarios, optimizing
one arm's motion must not introduce collisions with other arms. Although
existing multi-arm planning works often use some form of shortcutting
techniques, their exact methodology and impact on performance are often vaguely
described. In this work, we present a comprehensive study quantitatively
comparing existing shortcutting methods for multi-arm trajectories across
diverse simulated scenarios. We carefully analyze the pros and cons of each
shortcutting method and propose two simple strategies for combining these
methods to achieve the best performance-runtime tradeoff. Video, code, and
dataset are available at https://philip-huang.github.io/mr-shortcut/.

</details>


### [359] [A Vision-Based Collision Sensing Method for Stable Circular Object Grasping with A Soft Gripper System](https://arxiv.org/abs/2508.05040)
*Boyang Zhang,Jiahui Zuo,Zeyu Duan,Fumin Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的碰撞检测系统，用于稳定机器人抓取圆形物体，该系统能瞬时反应并精确识别碰撞。


<details>
  <summary>Details</summary>
Motivation: 解决机器人抓取圆形物体时因外部碰撞导致的不稳定风险。

Method: 提出了一种基于视觉的传感模块，利用“掌上眼”摄像头监控手指和被抓物体的运动，并开发了一种富含碰撞的抓取策略。

Result: 实验证实了该碰撞检测机制能够瞬时反应，并且能够精确检测外部碰撞的方向和尺度，确保了抓取过程的稳定性和安全性。

Conclusion: 该系统能够实时检测碰撞并做出反应，成功解决了机器人抓取圆形物体时因外部碰撞导致的不稳定问题。

Abstract: External collisions to robot actuators typically pose risks to grasping
circular objects. This work presents a vision-based sensing module capable of
detecting collisions to maintain stable grasping with a soft gripper system.
The system employs an eye-in-palm camera with a broad field of view to
simultaneously monitor the motion of fingers and the grasped object.
Furthermore, we have developed a collision-rich grasping strategy to ensure the
stability and security of the entire dynamic grasping process. A physical soft
gripper was manufactured and affixed to a collaborative robotic arm to evaluate
the performance of the collision detection mechanism. An experiment regarding
testing the response time of the mechanism confirmed the system has the
capability to react to the collision instantaneously. A dodging test was
conducted to demonstrate the gripper can detect the direction and scale of
external collisions precisely.

</details>


### [360] [Examining the legibility of humanoid robot arm movements in a pointing task](https://arxiv.org/abs/2508.05104)
*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Ana Farić,Kristína Malinovská,Michal Vavrecka,Igor Farkaš*

Main category: cs.RO

TL;DR: 该研究通过实验发现，人类可以通过机器人手臂的指向和注视线索来预测其意图，并且多模态信息和眼动信息在预测中起着重要作用。


<details>
  <summary>Details</summary>
Motivation: 为了提高人机交互的安全性，需要机器人能够清晰地表达其意图，使人类能够理解、预测并感到安全。

Method: 设计了一个使用NICO人形机器人进行指向任务的实验，改变了机器人的注视、指向和注视与指向的配合（一致或不一致）等线索，并记录了手臂轨迹在60%或80%时参与者对最终目标的预测。

Result: 实验结果支持了多模态优势和眼动优先假说，表明人类可以通过机器人的肢体线索（如注视和指向）来预测其意图。

Conclusion: 该研究得到了多模态优势和眼动优先假说的支持。

Abstract: Human--robot interaction requires robots whose actions are legible, allowing
humans to interpret, predict, and feel safe around them. This study
investigates the legibility of humanoid robot arm movements in a pointing task,
aiming to understand how humans predict robot intentions from truncated
movements and bodily cues. We designed an experiment using the NICO humanoid
robot, where participants observed its arm movements towards targets on a
touchscreen. Robot cues varied across conditions: gaze, pointing, and pointing
with congruent or incongruent gaze. Arm trajectories were stopped at 60\% or
80\% of their full length, and participants predicted the final target. We
tested the multimodal superiority and ocular primacy hypotheses, both of which
were supported by the experiment.

</details>


### [361] [From Canada to Japan: How 10,000 km Affect User Perception in Robot Teleoperation](https://arxiv.org/abs/2508.05143)
*Siméon Capy,Thomas M. Kwok,Kevin Joseph,Yuichiro Kawasumi,Koichi Nagashima,Tomoya Sasaki,Yue Hu,Eiichi Yoshida*

Main category: cs.RO

TL;DR: 研究评估了长距离机器人遥操作对用户感知的影响，发现在本地和远程机器人控制之间没有显著差异，表明机器人是传统本地控制的可行替代方案，特别是在老年人护理领域。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨距离对用户在机器人遥操作（RTo）中的感知影响，并探索远程操作机器人在老年人护理中的应用潜力。

Method: 设计了一个包含多个问卷的特定协议，并使用机器人操作系统（ROS）和Unity构建了专门的软件架构，以评估非专业用户对长距离机器人遥操作的感知，并考察了他们的感知在交互前后以及与本地操作机器人相比的变化。

Result: 研究结果显示，在本地和远程机器人条件下，用户的感知没有统计学上的显著差异。

Conclusion: 研究结果表明，在远程和本地控制条件下，机器人感知没有显著差异，表明机器人可能是传统本地控制的可行替代方案。

Abstract: Robot teleoperation (RTo) has emerged as a viable alternative to local
control, particularly when human intervention is still necessary. This research
aims to study the distance effect on user perception in RTo, exploring the
potential of teleoperated robots for older adult care. We propose an evaluation
of non-expert users' perception of long-distance RTo, examining how their
perception changes before and after interaction, as well as comparing it to
that of locally operated robots. We have designed a specific protocol
consisting of multiple questionnaires, along with a dedicated software
architecture using the Robotics Operating System (ROS) and Unity. The results
revealed no statistically significant differences between the local and remote
robot conditions, suggesting that robots may be a viable alternative to
traditional local control.

</details>


### [362] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
*Albert Yu,Chengshu Li,Luca Macesanu,Arnav Balaji,Ruchira Ray,Raymond Mooney,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: MICoBot是一个人机协作系统，通过混合主动对话和多层决策来优化任务分配和执行，显著提升了协作效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 为了实现能够适应各种人类合作伙伴的长期人机协作，机器人系统需要一个紧密耦合的通信循环，允许双方在任务协调中提出、接受或拒绝请求，MICoBot 旨在处理这种混合主动的对话场景，以最小化人类的精力。

Method: MICoBot 系统采用混合主动对话范例，通过三个层面的决策来实现协作：(1) 元规划器利用人类对话制定高层协作策略；(2) 规划器根据机器人的能力（通过模拟预训练的亲和力模型衡量）和人类的估计可用性来最优地分配剩余任务步骤；(3) 行动执行器负责执行低层动作或与人类的对话。

Result: MICoBot 能够有效地与多样化的人类用户进行协作，在任务成功率和用户体验方面取得了显著的改善。

Conclusion: MICoBot 在与人类参与者进行模拟和真实世界的广泛评估中，证明了其与各种人类用户有效协作的能力，与纯粹的 LLM 基线和其他代理分配模型相比，在任务成功率和用户体验方面均有显著提高。

Abstract: Effective robotic systems for long-horizon human-robot collaboration must
adapt to a wide range of human partners, whose physical behavior, willingness
to assist, and understanding of the robot's capabilities may change over time.
This demands a tightly coupled communication loop that grants both agents the
flexibility to propose, accept, or decline requests as they coordinate toward
completing the task effectively. We apply a Mixed-Initiative dialog paradigm to
Collaborative human-roBot teaming and propose MICoBot, a system that handles
the common scenario where both agents, using natural language, take initiative
in formulating, accepting, or rejecting proposals on who can best complete
different steps of a task. To handle diverse, task-directed dialog, and find
successful collaborative strategies that minimize human effort, MICoBot makes
decisions at three levels: (1) a meta-planner considers human dialog to
formulate and code a high-level collaboration strategy, (2) a planner optimally
allocates the remaining steps to either agent based on the robot's capabilities
(measured by a simulation-pretrained affordance model) and the human's
estimated availability to help, and (3) an action executor decides the
low-level actions to perform or words to say to the human. Our extensive
evaluations in simulation and real-world -- on a physical robot with 18 unique
human participants over 27 hours -- demonstrate the ability of our method to
effectively collaborate with diverse human users, yielding significantly
improved task success and user experience than a pure LLM baseline and other
agent allocation models. See additional videos and materials at
https://robin-lab.cs.utexas.edu/MicoBot/.

</details>


### [363] [Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories](https://arxiv.org/abs/2508.05148)
*Francisco Munguia-Galeano,Zhengxue Zhou,Satheeshkumar Veeramani,Hatem Fakhruldeen,Louis Longley,Rob Clowes,Andrew I. Cooper*

Main category: cs.RO

TL;DR: Chemist Eye是一个利用视觉-语言模型来监控无人驾驶实验室安全、识别人员和火灾风险的系统，能指导机器人避开危险并实时通知人员。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人和自动化在无人驾驶实验室（SDLs）中引入的安全复杂性，特别是火灾风险和人员安全问题。

Method: Chemist Eye是一个集成了RGB、深度和红外摄像头的分布式安全监控系统，利用视觉-语言模型（VLM）进行决策，以识别事故、不合规的PPE和火灾风险。

Result: Chemist Eye在包含三台移动机器人的SDL的真实世界数据测试中，识别安全隐患的准确率达到97%，决策表现达到95%。

Conclusion: Chemist Eye系统能够识别安全隐患并驱动自主移动，并能向实验室人员发送即时通知。

Abstract: The integration of robotics and automation into self-driving laboratories
(SDLs) can introduce additional safety complexities, in addition to those that
already apply to conventional research laboratories. Personal protective
equipment (PPE) is an essential requirement for ensuring the safety and
well-being of workers in laboratories, self-driving or otherwise. Fires are
another important risk factor in chemical laboratories. In SDLs, fires that
occur close to mobile robots, which use flammable lithium batteries, could have
increased severity. Here, we present Chemist Eye, a distributed safety
monitoring system designed to enhance situational awareness in SDLs. The system
integrates multiple stations equipped with RGB, depth, and infrared cameras,
designed to monitor incidents in SDLs. Chemist Eye is also designed to spot
workers who have suffered a potential accident or medical emergency, PPE
compliance and fire hazards. To do this, Chemist Eye uses decision-making
driven by a vision-language model (VLM). Chemist Eye is designed for seamless
integration, enabling real-time communication with robots. Based on the VLM
recommendations, the system attempts to drive mobile robots away from potential
fire locations, exits, or individuals not wearing PPE, and issues audible
warnings where necessary. It also integrates with third-party messaging
platforms to provide instant notifications to lab personnel. We tested Chemist
Eye with real-world data from an SDL equipped with three mobile robots and
found that the spotting of possible safety hazards and decision-making
performances reached 97 % and 95 %, respectively.

</details>


### [364] [FCBV-Net: Category-Level Robotic Garment Smoothing via Feature-Conditioned Bimanual Value Prediction](https://arxiv.org/abs/2508.05153)
*Mohammed Daba,Jing Qiu*

Main category: cs.RO

TL;DR: FCBV-Net通过在3D点云上操作，并利用预训练的几何特征来预测双臂动作价值，提高了机器人服装操作（如平滑）的类别级别泛化能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人服装操作方法（如双臂平滑）在高维度、复杂动力学和类别内变化方面存在挑战，难以实现类别级别泛化。现有方法要么过拟合特定实例，要么在感知泛化后无法预测协同双臂动作的价值。

Method: 提出特征条件双臂价值网络（FCBV-Net），该网络在3D点云上操作，通过条件化预训练的、固定的密集几何特征来预测双臂动作价值，以增强对服装平滑任务的类别级别策略泛化能力。可训练的下游组件利用这些静态特征学习特定任务的策略。

Result: 在CLOTH3D数据集的GarmentLab模拟实验中，FCBV-Net在未见过服装上的效率下降仅为11.5%（Steps80），相比之下2D图像基线为96.2%；最终覆盖率达到89%，优于使用相同每点几何特征但固定原语的3D对应基线（83%）。

Conclusion: FCBV-Net通过将几何理解与双臂动作价值学习分离，实现了更好的类别级别泛化能力。

Abstract: Category-level generalization for robotic garment manipulation, such as
bimanual smoothing, remains a significant hurdle due to high dimensionality,
complex dynamics, and intra-category variations. Current approaches often
struggle, either overfitting with concurrently learned visual features for a
specific instance or, despite category-level perceptual generalization, failing
to predict the value of synergistic bimanual actions. We propose the
Feature-Conditioned Bimanual Value Network (FCBV-Net), operating on 3D point
clouds to specifically enhance category-level policy generalization for garment
smoothing. FCBV-Net conditions bimanual action value prediction on pre-trained,
frozen dense geometric features, ensuring robustness to intra-category garment
variations. Trainable downstream components then learn a task-specific policy
using these static features. In simulated GarmentLab experiments with the
CLOTH3D dataset, FCBV-Net demonstrated superior category-level generalization.
It exhibited only an 11.5% efficiency drop (Steps80) on unseen garments
compared to 96.2% for a 2D image-based baseline, and achieved 89% final
coverage, outperforming an 83% coverage from a 3D correspondence-based baseline
that uses identical per-point geometric features but a fixed primitive. These
results highlight that the decoupling of geometric understanding from bimanual
action value learning enables better category-level generalization.

</details>


### [365] [A General Control Method for Human-Robot Integration](https://arxiv.org/abs/2412.14762)
*Maddalena Feder,Giorgio Grioli,Manuel G. Catalano,Antonio Bicchi*

Main category: cs.RO

TL;DR: 提出了一种新颖的广义控制方法，用于控制多自由度设备，以协助行动能力受限的人士进行日常活动。该方法将用户的补偿性运动映射到机器人指令，以实现目标，同时最大限度地减少用户的能量消耗和不适感。该框架已通过模拟和真实世界试验得到验证，可应用于各种机器人辅助设备。


<details>
  <summary>Details</summary>
Motivation: 为残疾人士的日常生活活动提供助力，解决在低维空间中映射用户运动到复杂的机器人辅助设备（如假肢、超数假肢、远程机器人化身）的控制接口的适应性策略的挑战。

Method: 提出了一种控制通用多自由度辅助系统的框架，该系统可以将用户补偿性运动转化为机器人指令，以实现目标，同时消除或减少用户补偿。

Result: 通过包括模拟场景和涉及机器人部件（假肢和机器人）虚拟孪生以及物理人形化身的真实世界试验，对该控制策略进行了验证和应用。

Conclusion: 该框架可扩展至任意自由度的假肢，直至全身假肢（在此被视为一种完整的外骨骼假肢），使人类能够以外化身的形式实现目标，并通过自我补偿的方式来减少用户的损耗和不适感。

Abstract: This paper introduces a new generalized control method designed for
multi-degrees-of-freedom devices to help people with limited motion
capabilities in their daily activities. The challenge lies in finding the most
adapted strategy for the control interface to effectively map user's motions in
a low-dimensional space to complex robotic assistive devices, such as
prostheses, supernumerary limbs, up to remote robotic avatars. The goal is a
system which integrates the human and the robotic parts into a unique system,
moving so as to reach the targets decided by the human while autonomously
reducing the user's effort and discomfort. We present a framework to control
general multi DoFs assistive systems, which translates user-performed
compensatory motions into the necessary robot commands for reaching targets
while canceling or reducing compensation. The framework extends to prostheses
of any number of DoF up to full robotic avatars, regarded here as a sort of
whole-body prosthesis of the person who sees the robot as an artificial
extension of their own body without a physical link but with a sensory-motor
integration. We have validated and applied this control strategy through tests
encompassing simulated scenarios and real-world trials involving a virtual twin
of the robotic parts (prosthesis and robot) and a physical humanoid avatar.

</details>


### [366] [Learning to See and Act: Task-Aware View Planning for Robotic Manipulation](https://arxiv.org/abs/2508.05186)
*Yongjie Bai,Zhouxia Wang,Yang Liu,Weixing Chen,Ziliang Chen,Mingtong Dai,Yongsen Zheng,Lingbo Liu,Guanbin Li,Liang Lin*

Main category: cs.RO

TL;DR: TAVP通过主动视角规划和任务特定的表征学习（MoE编码器），解决了机器人操作VLA模型的局限性，提高了3D感知、任务泛化能力和动作预测精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人操作VLA模型依赖静态视角和共享视觉编码器的问题，这些问题限制了3D感知并引起任务干扰，从而阻碍了鲁棒性和泛化能力。

Method: TAVP框架整合了主动视角规划与任务特定表征学习。它采用高效的探索策略，并通过新颖的伪环境进行加速，以主动获取信息性视角。此外，引入了混合专家（MoE）视觉编码器，以解耦不同任务的特征，从而提高表征保真度和任务泛化能力。

Result: TAVP在RLBench任务上实现了优于现有固定视角方法的性能。

Conclusion: TAVP通过学习以任务为导向的方式观察世界，生成更完整、更具辨别力的视觉表征，在广泛的操作挑战中显著提高了动作预测能力。实验表明，TAVP的性能优于最先进的固定视角方法。

Abstract: Recent vision-language-action (VLA) models for multi-task robotic
manipulation commonly rely on static viewpoints and shared visual encoders,
which limit 3D perception and cause task interference, hindering robustness and
generalization. In this work, we propose Task-Aware View Planning (TAVP), a
framework designed to overcome these challenges by integrating active view
planning with task-specific representation learning. TAVP employs an efficient
exploration policy, accelerated by a novel pseudo-environment, to actively
acquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)
visual encoder to disentangle features across different tasks, boosting both
representation fidelity and task generalization. By learning to see the world
in a task-aware way, TAVP generates more complete and discriminative visual
representations, demonstrating significantly enhanced action prediction across
a wide array of manipulation challenges. Extensive experiments on RLBench tasks
show that our proposed TAVP model achieves superior performance over
state-of-the-art fixed-view approaches. Visual results and code are provided
at: https://hcplab-sysu.github.io/TAVP.

</details>


### [367] [Dancing with a Robot: An Experimental Study of Child-Robot Interaction in a Performative Art Setting](https://arxiv.org/abs/2508.05208)
*Victor Ngo,Rachel,Ramchurn,Roma Patel,Alan Chamberlain,Ayse Kucukyilmaz*

Main category: cs.RO

TL;DR: This paper evaluates children's interactions with a robot performer named NED. It found that while children are curious and capable of interacting with robots, there are challenges in engagement, robot expressivity, and meeting expectations. The study emphasizes the need to improve HRI design for better audience experiences, particularly for children.


<details>
  <summary>Details</summary>
Motivation: To evaluate children's in-the-wild experiences with the autonomous robot arm performer NED (Never-Ending Dancer) within the Thingamabobas installation.

Method: Observational analysis of 18 children

Result: Three key challenges were identified: 1) Initiating and maintaining engagement, 2) Lack of robot expressivity and reciprocity, and 3) Unmet expectations.

Conclusion: Children are naturally curious and adept at interacting with robotic art performers, but HRI systems need optimization considering audience capabilities, perceptions, and expectations within the performing arts context to foster engaging experiences, especially for young audiences.

Abstract: This paper presents an evaluation of 18 children's in-the-wild experiences
with the autonomous robot arm performer NED (Never-Ending Dancer) within the
Thingamabobas installation, showcased across the UK. We detail NED's design,
including costume, behaviour, and human interactions, all integral to the
installation. Our observational analysis revealed three key challenges in
child-robot interactions: 1) Initiating and maintaining engagement, 2) Lack of
robot expressivity and reciprocity, and 3) Unmet expectations. Our findings
show that children are naturally curious, and adept at interacting with a
robotic art performer. However, our observations emphasise the critical need to
optimise human-robot interaction (HRI) systems through careful consideration of
audience's capabilities, perceptions, and expectations, within the performative
arts context, to enable engaging and meaningful experiences, especially for
young audiences.

</details>


### [368] [Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction](https://arxiv.org/abs/2508.05294)
*Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本调查论文重点介绍了基础模型（如 LLMs、VLMs 和 VLAs/BLMs）在机器人自主性和人机交互领域的最新进展，特别是那些旨在实现 agentic 应用和架构的模型。它探讨了这些模型如何使机器人能够理解自然语言指令、使用 API、规划任务以及协助操作，并包括社区项目和工业框架以反映该领域的快速发展。该论文还提出了一个分类模型集成方法，并对文献中 AI 代理的作用进行了比较分析。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型（包括 LLMs、VLMs 和 VLAs/BLMs）在机器人自主性和人机交互方面取得进展，探索这些模型在 agentic 应用和架构中的作用，以增强机器人的推理、规划和操作能力。

Method: 通过纳入同行评审的研究、社区驱动的项目、ROS 包和工业框架，对基础模型在机器人领域的应用进行分类和比较分析，重点关注 agentic 架构。

Result: 对现有文献进行了分类和比较分析，强调了 AI 代理在不同机器人解决方案中的作用，并突出了该领域的新兴趋势和社区驱动的贡献。

Conclusion: 该论文总结了基础模型在机器人自主性和人机交互方面的进展，特别是关注了致力于 agentic 应用和架构的模型，如 GPT 风格的接口和更复杂的 AI 代理系统，这些系统能够处理自然语言指令、调用 API、规划任务序列以及协助操作和诊断。

Abstract: Foundation models, including large language models (LLMs) and vision-language
models (VLMs), have recently enabled novel approaches to robot autonomy and
human-robot interfaces. In parallel, vision-language-action models (VLAs) or
large behavior models (BLMs) are increasing the dexterity and capabilities of
robotic systems. This survey paper focuses on those words advancing towards
agentic applications and architectures. This includes initial efforts exploring
GPT-style interfaces to tooling, as well as more complex system where AI agents
are coordinators, planners, perception actors, or generalist interfaces. Such
agentic architectures allow robots to reason over natural language
instructions, invoke APIs, plan task sequences, or assist in operations and
diagnostics. In addition to peer-reviewed research, due to the fast-evolving
nature of the field, we highlight and include community-driven projects, ROS
packages, and industrial frameworks that show emerging trends. We propose a
taxonomy for classifying model integration approaches and present a comparative
analysis of the role that agents play in different solutions in today's
literature.

</details>


### [369] [GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming](https://arxiv.org/abs/2508.05298)
*Jian Gong,Youwei Huang,Bo Yuan,Ming Zhu,Juncheng Zhan,Jinke Wang,Hang Shu,Mingyue Xiong,Yanjun Ye,Yufan Zu,Yang Zhou,Yihan Ding,Xuannian Chen,Xingyu Lu,Runjie Ban,Bingchao Huang,Fusen Liu*

Main category: cs.RO

TL;DR: GhostShell利用LLMs实现具身系统的流式和并发行为编程，通过增量式函数调用驱动实时行动，并在机器人原型上实现了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在克服传统方法中依赖预设动作序列或行为树的局限性，实现具身系统的实时、动态行为编程。

Method: GhostShell通过流式XML函数令牌解析器、动态函数接口映射器和多通道调度器，利用大型语言模型（LLMs）实现具身系统的流式和并发行为编程，通过增量式调用函数来驱动具身系统即时行动。

Result: 在34个真实交互任务和多种LLMs上对COCO机器人原型进行了评估，结果显示GhostShell在行为正确性、响应速度、鲁棒性和泛化能力方面均表现出色。

Conclusion: GhostShell在长期多模态任务中被证明是有效的，展示了强大的鲁棒性和泛化能力，在与Claude-4 Sonnet的结合下，达到了0.85的最佳行为正确性指标，并且响应时间比LLM原生函数调用API快66倍。

Abstract: We present GhostShell, a novel approach that leverages Large Language Models
(LLMs) to enable streaming and concurrent behavioral programming for embodied
systems. In contrast to conventional methods that rely on pre-scheduled action
sequences or behavior trees, GhostShell drives embodied systems to act
on-the-fly by issuing function calls incrementally as tokens are streamed from
the LLM. GhostShell features a streaming XML function token parser, a dynamic
function interface mapper, and a multi-channel scheduler that orchestrates
intra-channel synchronous and inter-channel asynchronous function calls,
thereby coordinating serial-parallel embodied actions across multiple robotic
components as directed by the LLM. We evaluate GhostShell on our robot
prototype COCO through comprehensive grounded experiments across 34 real-world
interaction tasks and multiple LLMs. The results demonstrate that our approach
achieves state-of-the-art Behavioral Correctness Metric of 0.85 with Claude-4
Sonnet and up to 66X faster response times compared to LLM native function
calling APIs. GhostShell also proves effective in long-horizon multimodal
tasks, demonstrating strong robustness and generalization.

</details>


### [370] [A Multi-view Landmark Representation Approach with Application to GNSS-Visual-Inertial Odometry](https://arxiv.org/abs/2508.05368)
*Tong Hua,Jiale Han,Wei Ouyang*

Main category: cs.RO

TL;DR: 提出了一种高效的多视图仅姿态估计方法，并成功应用于GNSS-视觉-惯性里程计（GVIO），提高了精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高视觉辅助传感器融合技术（如不变扩展卡尔曼滤波器IEKF）在联合优化相机姿态和路标时的效率和适用性，本研究提出了一个多视图仅姿态估计方法。

Method: 提出了一种多视图仅姿态估计方法，并推导了视觉测量模型，将路标表示与多个摄像机姿态和观测直接关联。将该方法应用于结合GNSS、视觉和惯性测量单元（IMU）的里程计（GVIO），并采用了新颖的特征管理策略。

Result: 仿真测试和真实世界实验均表明，该方法在效率和准确性方面优于现有方法。

Conclusion: 本论文提出了一种多视图仅姿态估计方法，并将其应用于GNSS-视觉-惯性里程计（GVIO）。该方法通过推导视觉测量模型，直接将路标表示与多个摄像机姿态和观测关联起来。这种仅姿态的测量被证明是路标和姿态之间紧密耦合的，并保持一个独立于估计姿态的完美零空间。最后，本方法结合新颖的特征管理策略应用于基于滤波的GVIO。

Abstract: Invariant Extended Kalman Filter (IEKF) has been a significant technique in
vision-aided sensor fusion. However, it usually suffers from high computational
burden when jointly optimizing camera poses and the landmarks. To improve its
efficiency and applicability for multi-sensor fusion, we present a multi-view
pose-only estimation approach with its application to GNSS-Visual-Inertial
Odometry (GVIO) in this paper. Our main contribution is deriving a visual
measurement model which directly associates landmark representation with
multiple camera poses and observations. Such a pose-only measurement is proven
to be tightly-coupled between landmarks and poses, and maintain a perfect null
space that is independent of estimated poses. Finally, we apply the proposed
approach to a filter based GVIO with a novel feature management strategy. Both
simulation tests and real-world experiments are conducted to demonstrate the
superiority of the proposed method in terms of efficiency and accuracy.

</details>


### [371] [Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control](https://arxiv.org/abs/2508.05342)
*Shunlei Li,Longsen Gao,Jin Wang,Chang Che,Xi Xiao,Jiuwen Cao,Yingbai Hu,Hamid Reza Karimi*

Main category: cs.RO

TL;DR: GF-VLA框架通过信息论场景图和语言-动作Transformer，使双臂机器人能够从RGB和深度人类演示中进行任务级推理和执行，解决了低级轨迹模仿的泛化性问题，并在块体组装任务中取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 从人类视频中学习机器人灵巧技能的教学仍然具有挑战性，因为这种方法依赖于低级轨迹模仿，而这种模仿在跨对象类型、空间布局和机械手配置的泛化性方面存在不足。

Method: GF-VLA框架首先提取基于香农信息论的线索来识别任务相关性最高的手和物体，然后将这些线索编码成时间有序的场景图，捕捉手-物体和物体-物体交互。这些图与语言条件下的Transformer融合，生成分层行为树和可解释的笛卡尔运动指令。此外，还引入了跨手选择策略，用于在双臂设置中推断最优夹持器分配。

Result: 信息论场景表示实现了超过95%的图准确率和93%的子任务分割准确率，支持LLM规划器生成可靠且人类可读的任务策略。当由双臂机器人执行时，这些策略在堆叠、字母构建和几何重构场景中产生了94%的抓取成功率、89%的放置准确率和90%的总体任务成功率，证明了其在各种空间和语义变化下的强大泛化性和鲁棒性。

Conclusion: GF-VLA框架在双臂抓取和放置任务中展现出强大的泛化性和鲁棒性，实现了94%的抓取成功率、89%的放置准确率和90%的总体任务成功率，并能生成人类可读的任务策略。

Abstract: Teaching robots dexterous skills from human videos remains challenging due to
the reliance on low-level trajectory imitation, which fails to generalize
across object types, spatial layouts, and manipulator configurations. We
propose Graph-Fused Vision-Language-Action (GF-VLA), a framework that enables
dual-arm robotic systems to perform task-level reasoning and execution directly
from RGB and Depth human demonstrations. GF-VLA first extracts
Shannon-information-based cues to identify hands and objects with the highest
task relevance, then encodes these cues into temporally ordered scene graphs
that capture both hand-object and object-object interactions. These graphs are
fused with a language-conditioned transformer that generates hierarchical
behavior trees and interpretable Cartesian motion commands. To improve
execution efficiency in bimanual settings, we further introduce a cross-hand
selection policy that infers optimal gripper assignment without explicit
geometric reasoning. We evaluate GF-VLA on four structured dual-arm block
assembly tasks involving symbolic shape construction and spatial
generalization. Experimental results show that the information-theoretic scene
representation achieves over 95 percent graph accuracy and 93 percent subtask
segmentation, supporting the LLM planner in generating reliable and
human-readable task policies. When executed by the dual-arm robot, these
policies yield 94 percent grasp success, 89 percent placement accuracy, and 90
percent overall task success across stacking, letter-building, and geometric
reconfiguration scenarios, demonstrating strong generalization and robustness
across diverse spatial and semantic variations.

</details>


### [372] [Affecta-Context: The Context-Guided Behavior Adaptation Framework](https://arxiv.org/abs/2508.05359)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: Affecta-context是一个通用框架，可帮助机器人适应环境和用户偏好，并通过在不同场景中学习行为优先级来优化其行为。


<details>
  <summary>Details</summary>
Motivation: 提出Affecta-context框架是为了促进社交机器人的行为适应性，该框架利用物理上下文信息来指导人机交互中的行为。

Method: 该框架包含两部分：一部分用于表示遇到的上下文，另一部分通过人机交互学习行为的优先级。在遇到物理上下文时，框架会根据其物理属性对其进行聚类。在每个上下文中，该框架会学习对行为进行优先级排序，以优化机器人的行为属性，使其符合当前环境和用户偏好。

Result: 通过在两个不同的物理环境中与6名不同的真人测试参与者进行72次交互的训练，实现了机器人的自主行为优先级学习。研究表明，该框架能够泛化输入并将其行为与以前未访问过的物理上下文进行匹配。

Conclusion: 该研究展示了Affecta-context框架的能力，通过让机器人自主学习离散行为的优先级。

Abstract: This paper presents Affecta-context, a general framework to facilitate
behavior adaptation for social robots. The framework uses information about the
physical context to guide its behaviors in human-robot interactions. It
consists of two parts: one that represents encountered contexts and one that
learns to prioritize between behaviors through human-robot interactions. As
physical contexts are encountered the framework clusters them by their measured
physical properties. In each context, the framework learns to prioritize
between behaviors to optimize the physical attributes of the robot's behavior
in line with its current environment and the preferences of the users it
interacts with. This paper illlustrates the abilities of the Affecta-context
framework by enabling a robot to autonomously learn the prioritization of
discrete behaviors. This was achieved by training across 72 interactions in two
different physical contexts with 6 different human test participants. The paper
demonstrates the trained Affecta-context framework by verifying the robot's
ability to generalize over the input and to match its behaviors to a previously
unvisited physical context.

</details>


### [373] [Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling](https://arxiv.org/abs/2508.05634)
*Jianpeng Yao,Xiaopan Zhang,Yu Xia,Zejin Wang,Amit K. Roy-Chowdhury,Jiachen Li*

Main category: cs.RO

TL;DR: 通过考虑行人不确定性，增强了机器人导航的鲁棒性，减少了碰撞和侵入，并在分布内和分布外场景中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在人群中导航时，当面临分布外场景时，性能会下降。通过考虑行人的不确定性，可以提高导航策略的鲁棒性。

Method: 该方法通过自适应一致推理生成的预测不确定性估计来增强代理观察，并使用这些估计通过约束强化学习来指导代理的行为。

Result: 在分布内设置中，成功率达到96.93%，比之前的最先进基线高出8.80%，碰撞次数减少3.72倍，侵入真实人类未来轨迹次数减少2.43倍。在三种分布外场景中，该方法在处理速度变化、策略变化和个体到群体动态转换的分布变化方面表现出更强的鲁棒性。

Conclusion: 通过考虑行人的不确定性，可以学习到安全且对分布变化具有鲁棒性的导航策略。该方法通过自适应一致推理生成的预测不确定性估计来增强代理观察，并使用这些估计通过约束强化学习来指导代理的行为。实验表明，该方法在模拟和真实机器人部署中都表现出色。

Abstract: Mobile robots navigating in crowds trained using reinforcement learning are
known to suffer performance degradation when faced with out-of-distribution
scenarios. We propose that by properly accounting for the uncertainties of
pedestrians, a robot can learn safe navigation policies that are robust to
distribution shifts. Our method augments agent observations with prediction
uncertainty estimates generated by adaptive conformal inference, and it uses
these estimates to guide the agent's behavior through constrained reinforcement
learning. The system helps regulate the agent's actions and enables it to adapt
to distribution shifts. In the in-distribution setting, our approach achieves a
96.93% success rate, which is over 8.80% higher than the previous
state-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times
fewer intrusions into ground-truth human future trajectories. In three
out-of-distribution scenarios, our method shows much stronger robustness when
facing distribution shifts in velocity variations, policy changes, and
transitions from individual to group dynamics. We deploy our method on a real
robot, and experiments show that the robot makes safe and robust decisions when
interacting with both sparse and dense crowds. Our code and videos are
available on https://gen-safe-nav.github.io/.

</details>


### [374] [Robots can defuse high-intensity conflict situations](https://arxiv.org/abs/2508.05373)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 机器人可以通过多种情感表达方式（包括运动、语音等）来缓解与人类的冲突，但机器人的社会意识和对情境的反应能力可能比特定的情感表达方式更为关键。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索机器人如何在高强度冲突中缓解人类的敌对情绪，重点研究五种不同的情感表达方式在该过程中的作用。

Method: 本研究使用了定制的情感机器人，在模拟冲突场景中进行了105名参与者的测试，并评估了五种不同情感表达方式在缓和冲突方面的有效性。

Result: 所有五种情感表达方式都能成功地缓和冲突并传达冲突的确认，参与者对机器人受冲突影响程度的感受相似。其中，运动（movement）表达方式与其它方式存在显著差异（p < 0.05）。

Conclusion: 本研究表明，所有测试的表达方式都能成功地缓和冲突并传达冲突的确认。然而，在处理高强度人机对抗时，机器人社会意识和适当反应的能力可能比特定的情感表达方式更重要。

Abstract: This paper investigates the specific scenario of high-intensity
confrontations between humans and robots, to understand how robots can defuse
the conflict. It focuses on the effectiveness of using five different affective
expression modalities as main drivers for defusing the conflict. The aim is to
discover any strengths or weaknesses in using each modality to mitigate the
hostility that people feel towards a poorly performing robot. The defusing of
the situation is accomplished by making the robot better at acknowledging the
conflict and by letting it express remorse. To facilitate the tests, we used a
custom affective robot in a simulated conflict situation with 105 test
participants. The results show that all tested expression modalities can
successfully be used to defuse the situation and convey an acknowledgment of
the confrontation. The ratings were remarkably similar, but the movement
modality was different (ANON p$<$.05) than the other modalities. The test
participants also had similar affective interpretations on how impacted the
robot was of the confrontation across all expression modalities. This indicates
that defusing a high-intensity interaction may not demand special attention to
the expression abilities of the robot, but rather require attention to the
abilities of being socially aware of the situation and reacting in accordance
with it.

</details>


### [375] [Real-Time Iteration Scheme for Diffusion Policy](https://arxiv.org/abs/2508.05396)
*Yufei Duan,Hang Yin,Danica Kragic*

Main category: cs.RO

TL;DR: 提出了一种基于 RTI 方案的加速推理方法，无需蒸馏或重新设计策略，即可将推理时间减少多达 90%，并且性能相当。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散策略推理时间长以及需要执行动作块然后进行下一步预测以维持一致动作的问题，这些问题限制了它们在延迟关键任务或短周期时间的简单任务中的应用。

Method: 提出了一种受实时迭代（RTI）方案启发的方案，该方案借鉴了最优控制，通过利用先前时间步的解作为后续迭代的初始猜测来加速优化，并提出了一种基于缩放的方法来有效处理机器人操作中的离散动作。

Result: 通过大量的仿真实验获得的定量结果表明，推理时间大大减少，并且与使用全步去噪的扩散策略相比，整体性能相当。

Conclusion: 该方法显著减少了推理时间，且在与使用全步去噪的扩散策略相比，整体性能相当。

Abstract: Diffusion Policies have demonstrated impressive performance in robotic
manipulation tasks. However, their long inference time, resulting from an
extensive iterative denoising process, and the need to execute an action chunk
before the next prediction to maintain consistent actions limit their
applicability to latency-critical tasks or simple tasks with a short cycle
time. While recent methods explored distillation or alternative policy
structures to accelerate inference, these often demand additional training,
which can be resource-intensive for large robotic models. In this paper, we
introduce a novel approach inspired by the Real-Time Iteration (RTI) Scheme, a
method from optimal control that accelerates optimization by leveraging
solutions from previous time steps as initial guesses for subsequent
iterations. We explore the application of this scheme in diffusion inference
and propose a scaling-based method to effectively handle discrete actions, such
as grasping, in robotic manipulation. The proposed scheme significantly reduces
runtime computational costs without the need for distillation or policy
redesign. This enables a seamless integration into many pre-trained
diffusion-based models, in particular, to resource-demanding large models. We
also provide theoretical conditions for the contractivity which could be useful
for estimating the initial denoising step. Quantitative results from extensive
simulation experiments show a substantial reduction in inference time, with
comparable overall performance compared with Diffusion Policy using full-step
denoising. Our project page with additional resources is available at:
https://rti-dp.github.io/.

</details>


### [376] [DistillDrive: End-to-End Multi-Mode Autonomous Driving Distillation by Isomorphic Hetero-Source Planning Model](https://arxiv.org/abs/2508.05402)
*Rui Yu,Xianghang Zhang,Runkai Zhao,Huaicheng Yan,Meng Wang*

Main category: cs.RO

TL;DR: DistillDrive是一个端到端的自动驾驶模型，通过知识蒸馏和多样化实例模仿来学习多模态运动特征，提高了决策鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶模型过度关注自身车辆状态，缺乏面向规划的理解，限制了决策过程的鲁棒性。

Method: DistillDrive是一种端到端的知识蒸馏模型，它利用基于结构化场景表示的规划模型作为教师模型，并将规划实例作为多目标学习目标。此外，还结合了强化学习来优化状态到决策的映射，并利用生成模型来构建面向规划的实例。

Result: 在nuScenes和NAVSIM数据集上验证，与基线模型相比，碰撞率降低了50%，闭环性能提高了3个百分点。

Conclusion: DistillDrive通过利用多样化的实例模仿来增强多模态运动特征学习，实现了50%的碰撞率降低和3个百分点的闭环性能提升，优于基线模型。

Abstract: End-to-end autonomous driving has been recently seen rapid development,
exerting a profound influence on both industry and academia. However, the
existing work places excessive focus on ego-vehicle status as their sole
learning objectives and lacks of planning-oriented understanding, which limits
the robustness of the overall decision-making prcocess. In this work, we
introduce DistillDrive, an end-to-end knowledge distillation-based autonomous
driving model that leverages diversified instance imitation to enhance
multi-mode motion feature learning. Specifically, we employ a planning model
based on structured scene representations as the teacher model, leveraging its
diversified planning instances as multi-objective learning targets for the
end-to-end model. Moreover, we incorporate reinforcement learning to enhance
the optimization of state-to-decision mappings, while utilizing generative
modeling to construct planning-oriented instances, fostering intricate
interactions within the latent space. We validate our model on the nuScenes and
NAVSIM datasets, achieving a 50\% reduction in collision rate and a 3-point
improvement in closed-loop performance compared to the baseline model. Code and
model are publicly available at https://github.com/YuruiAI/DistillDrive

</details>


### [377] [Computational Design and Fabrication of Modular Robots with Untethered Control](https://arxiv.org/abs/2508.05410)
*Manas Bhargava,Takefumi Hiraki,Malina Strugaru,Michal Piovarci,Chiara Daraio,Daisuke Iwai,Bernd Bickel*

Main category: cs.RO

TL;DR: 提出了一种新的机器人设计和控制框架，利用3D打印骨骼和液晶弹性体肌肉实现分布式驱动和形态变化，并通过计算工具优化设计和控制，以实现比现有软体机器人更强的适应性和运动能力。


<details>
  <summary>Details</summary>
Motivation: 模仿自然生物的分布驱动和肌肉骨骼系统以适应不同地形或执行不同任务，解决了现有软体机器人系统优化单一功能、缺乏按需改变形态或功能的能力或通常受限于笨重的控制系统等挑战。

Method: 提出了一种结合3D打印骨骼和液晶弹性体（LCE）肌肉作为轻质致动器的新型构建模块，实现了肌肉骨骼机器人的模块化组装。开发了响应红外辐射收缩的LCE杆，实现了对分布式骨骼网络的局部、无线控制，从而实现机器人的全局变形。为利用广泛的设计空间，开发了两个计算工具：一个用于优化机器人骨骼图，实现多种目标变形；另一个用于协同优化骨骼设计和控制步态，以实现目标运动。

Result: 通过构建多个机器人进行了验证，这些机器人展示了复杂变形、不同的控制方案以及对环境的适应性。

Conclusion: 该系统集成了模块化材料构建、无线分布式控制和计算设计方面的进步，引入了新一代机器人，使其能力更接近生物体的能力。

Abstract: Natural organisms use distributed actuation via their musculoskeletal systems
to adapt their gait for traversing diverse terrains or to morph their bodies to
perform varied tasks. A longstanding challenge in the field of robotics is to
mimic this extensive adaptability and range of motion. This has led humans to
develop various soft robotic systems that emulate natural organisms. However,
such systems are generally optimized for a single functionality, lack the
ability to change form or function on demand, or are often tethered to bulky
control systems. To address these challenges, we present our framework for
designing and controlling robots that mimic nature's blueprint by utilizing
distributed actuation. We propose a novel building block that combines
3D-printed bones with liquid crystal elastomer (LCE) muscles as lightweight
actuators and enables the modular assembly of musculoskeletal robots. We
developed LCE rods that contract in response to infrared radiation, thereby
achieving local and untethered control over the distributed network of bones,
which in turn results in global deformation of the robot. Furthermore, to
capitalize on the extensive design space, we develop two computational tools:
one to optimize the robot's skeletal graph, enabling multiple target
deformations, and another to co-optimize the skeletal designs and control gaits
to achieve target locomotion. We validate our system by building several robots
that show complex shape morphing, varying control schemes, and adaptability to
their environment. Our system integrates advances in modular material building,
untethered and distributed control, and computational design to introduce a new
generation of robots that brings us closer to the capabilities of living
organisms.

</details>


### [378] [Do Robots Really Need Anthropomorphic Hands?](https://arxiv.org/abs/2508.05415)
*Alexander Fabisch,Wadhah Zai El Amri,Chandandeep Singh,Nicolás Navarro-Guerrero*

Main category: cs.RO

TL;DR: 人手不一定是机器人手的理想目标。腕部灵活性和手指外展/内收比手指数量、执行器或自由度更重要。三指手是一个不错的选择，而非拟人化设计或六指手可以提供更高的灵巧性。


<details>
  <summary>Details</summary>
Motivation: 探讨了机器人手是否需要拟人化，以及人手是否是机器人技术追求的理想目标。

Method: 通过概述人手、比较市面上可买到的机器人手和假肢手，以及对机器手及其技能进行系统性回顾来回答。

Result: 研究发现，腕部灵活性和手指外展/内收对机器人的操作能力至关重要。然而，增加手指数量、执行器或自由度并非总是必要的，三指手是一个不错的选择。非拟人化设计（如两个相对的手指对）或具有六个手指的人手可以提供更高的灵巧性，这表明人手并非最优。

Conclusion: 并非所有任务都需要复杂的五指手，腕部灵活性和手指外展/内收对于操作能力很重要。增加手指、执行器或自由度的数量通常不是必需的。三指手在简洁性和灵巧性之间取得了良好的折衷。非拟人化的双手设计（例如，具有两个相对的手指对）或具有六个手指的人类手可以进一步提高灵巧性，这表明人手可能不是最优化的。

Abstract: Human manipulation skills represent a pinnacle of their voluntary motor
functions, requiring the coordination of many degrees of freedom and processing
of high-dimensional sensor input to achieve such a high level of dexterity.
Thus, we set out to answer whether the human hand, with its associated
biomechanical properties, sensors, and control mechanisms, is an ideal that we
should strive for in robotics-do we really need anthropomorphic robotic hands?
  This survey can help practitioners to make the trade-off between hand
complexity and potential manipulation skills. We provide an overview of the
human hand, a comparison of commercially available robotic and prosthetic
hands, and a systematic review of hand mechanisms and skills that they are
capable of. This leads to follow-up questions. What is the minimum requirement
for mechanisms and sensors to implement most skills that a robot needs? What is
missing to reach human-level dexterity? Can we improve upon human dexterity?
  Although complex five-fingered hands are often used as the ultimate goal for
robotic manipulators, they are not necessary for all tasks. We found that wrist
flexibility and finger abduction/adduction are important for manipulation
capabilities. On the contrary, increasing the number of fingers, actuators, or
degrees of freedom is often not necessary. Three fingers are a good compromise
between simplicity and dexterity. Non-anthropomorphic hand designs with two
opposing pairs of fingers or human hands with six fingers can further increase
dexterity, suggesting that the human hand may not be the optimum.

</details>


### [379] [CleanUpBench: Embodied Sweeping and Grasping Benchmark](https://arxiv.org/abs/2508.05543)
*Wenbo Li,Guanting Chen,Tao Zhao,Jiyao Wang,Tianxin Hu,Yuwen Liao,Weixiang Guo,Shenghai Yuan*

Main category: cs.RO

TL;DR: CleanUpBench是一个用于评估移动清洁机器人的新基准，它弥合了研究与现实世界应用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统评估具有清扫和抓取双重能力的移动清洁机器人在结构化、多目标清洁任务中的基准，这表明学术研究与实际应用之间存在关键差距。

Method: CleanUpBench在NVIDIA Isaac Sim上模拟了一个配备清扫装置和六自由度机械臂的移动服务机器人，使其能够与异构对象进行交互。该基准包括手动设计的环境和一个程序生成布局，以评估泛化能力，以及涵盖任务完成、空间效率、运动质量和控制性能的全面评估套件。

Result: CleanUpBench是一个可重现且可扩展的基准，用于在真实的室内清洁场景中评估具身智能体。它包括用于评估泛化能力的基准测试和基线代理。

Conclusion: CleanUpBench弥合了低级技能评估和全场景测试之间的差距，为日常环境中的具身智能提供了可扩展的测试平台。

Abstract: Embodied AI benchmarks have advanced navigation, manipulation, and reasoning,
but most target complex humanoid agents or large-scale simulations that are far
from real-world deployment. In contrast, mobile cleaning robots with dual mode
capabilities, such as sweeping and grasping, are rapidly emerging as realistic
and commercially viable platforms. However, no benchmark currently exists that
systematically evaluates these agents in structured, multi-target cleaning
tasks, revealing a critical gap between academic research and real-world
applications. We introduce CleanUpBench, a reproducible and extensible
benchmark for evaluating embodied agents in realistic indoor cleaning
scenarios. Built on NVIDIA Isaac Sim, CleanUpBench simulates a mobile service
robot equipped with a sweeping mechanism and a six-degree-of-freedom robotic
arm, enabling interaction with heterogeneous objects. The benchmark includes
manually designed environments and one procedurally generated layout to assess
generalization, along with a comprehensive evaluation suite covering task
completion, spatial efficiency, motion quality, and control performance. To
support comparative studies, we provide baseline agents based on heuristic
strategies and map-based planning. CleanUpBench bridges the gap between
low-level skill evaluation and full-scene testing, offering a scalable testbed
for grounded, embodied intelligence in everyday settings.

</details>


### [380] [Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator](https://arxiv.org/abs/2508.05584)
*Van Cuong Pham,Minh Hai Tran,Phuc Anh Nguyen,Ngoc Son Vu,Nga Nguyen Thi*

Main category: cs.RO

TL;DR: AFSMC通过模糊逻辑和滑模控制的结合，提高了机器人操纵器的轨迹跟踪性能、稳定性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高气缸机器人操纵器在数控和3D打印等应用中的轨迹跟踪性能。

Method: 提出了一种鲁棒自适应模糊滑模控制（AFSMC）方法，该方法将模糊逻辑与滑模控制（SMC）相结合，模糊逻辑用于逼近系统的不确定动力学，SMC则确保了强大的性能。

Result: 仿真结果表明，与传统方法相比，AFSMC显著提高了轨迹跟踪精度、稳定性和抗干扰能力。

Conclusion: 该研究强调了AFSMC在控制机器人操纵器方面的有效性，提高了工业机器人应用的精度。

Abstract: This research proposes a robust adaptive fuzzy sliding mode control (AFSMC)
approach to enhance the trajectory tracking performance of cylindrical robotic
manipulators, extensively utilized in applications such as CNC and 3D printing.
The proposed approach integrates fuzzy logic with sliding mode control (SMC) to
bolster adaptability and robustness, with fuzzy logic approximating the
uncertain dynamics of the system, while SMC ensures strong performance.
Simulation results in MATLAB/Simulink demonstrate that AFSMC significantly
improves trajectory tracking accuracy, stability, and disturbance rejection
compared to traditional methods. This research underscores the effectiveness of
AFSMC in controlling robotic manipulators, contributing to enhanced precision
in industrial robotic applications.

</details>


### [381] [Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation](https://arxiv.org/abs/2508.05635)
*Yue Liao,Pengfei Zhou,Siyuan Huang,Donglin Yang,Shengcong Chen,Yuxin Jiang,Yue Hu,Jingbin Cai,Si Liu,Jianlan Luo,Liliang Chen,Shuicheng Yan,Maoqing Yao,Guanghui Ren*

Main category: cs.RO

TL;DR: Genie Envisioner (GE) is a unified platform for robotic manipulation that uses a video-generative framework to learn, evaluate, and simulate policies. It includes a diffusion model (GE-Base), a policy inference module (GE-Act), and a neural simulator (GE-Sim), along with a benchmark suite (EWMBench). GE aims to provide scalable and practical embodied intelligence for instruction-driven tasks.


<details>
  <summary>Details</summary>
Motivation: To create a unified world foundation platform for robotic manipulation that integrates policy learning, evaluation, and simulation within a single video-generative framework, enabling precise and generalizable policy inference across diverse embodiments with minimal supervision.

Method: GE integrates policy learning, evaluation, and simulation using GE-Base (a large-scale, instruction-conditioned video diffusion model), GE-Act (a flow-matching decoder for mapping latent representations to action trajectories), and GE-Sim (an action-conditioned neural simulator). It is supported by EWMBench, a standardized benchmark suite.

Result: GE captures spatial, temporal, and semantic dynamics of robotic interactions in a structured latent space, enabling precise and generalizable policy inference with minimal supervision. EWMBench provides standardized measurement of visual fidelity, physical consistency, and instruction-action alignment.

Conclusion: Genie Envisioner (GE) is a scalable and practical foundation for instruction-driven, general-purpose embodied intelligence, integrating policy learning, evaluation, and simulation within a single video-generative framework.

Abstract: We introduce Genie Envisioner (GE), a unified world foundation platform for
robotic manipulation that integrates policy learning, evaluation, and
simulation within a single video-generative framework. At its core, GE-Base is
a large-scale, instruction-conditioned video diffusion model that captures the
spatial, temporal, and semantic dynamics of real-world robotic interactions in
a structured latent space. Built upon this foundation, GE-Act maps latent
representations to executable action trajectories through a lightweight,
flow-matching decoder, enabling precise and generalizable policy inference
across diverse embodiments with minimal supervision. To support scalable
evaluation and training, GE-Sim serves as an action-conditioned neural
simulator, producing high-fidelity rollouts for closed-loop policy development.
The platform is further equipped with EWMBench, a standardized benchmark suite
measuring visual fidelity, physical consistency, and instruction-action
alignment. Together, these components establish Genie Envisioner as a scalable
and practical foundation for instruction-driven, general-purpose embodied
intelligence. All code, models, and benchmarks will be released publicly.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [382] [OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks](https://arxiv.org/abs/2508.04833)
*Nicolas Nicolaou,Onyeka Obi,Aayush Rajasekaran,Alejandro Bergasov,Aleksandr Bezobchuk,Kishori M. Konwar,Michael Meier,Santiago Paiva,Har Preet Singh,Swarnabha Sinha*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Gossip algorithms are pivotal in the dissemination of information within
decentralized systems. Consequently, numerous gossip libraries have been
developed and widely utilized especially in blockchain protocols for the
propagation of blocks and transactions. A well-established library is libp2p,
which provides two gossip algorithms: floodsup and gossibsup. These algorithms
enable the delivery of published messages to a set of peers. In this work we
aim to enhance the performance and reliability of libp2p by introducing
OPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random
Linear Network Coding (RLNC) to expedite the dissemination of information in a
peer-to-peer (P2P) network while ensuring reliable delivery, even in the
presence of malicious actors capable of corrupting the transmitted data.
Preliminary research from the Ethereum Foundation has demonstrated the use of
RLNC in the significant improvement in the block propagation time [14]. Here we
present extensive evaluation results both in simulation and real-world
environments that demonstrate the performance gains of OPTIMUMP2P over the
Gossipsub protocol.

</details>


### [383] [Linear Search for Capturing an Oblivious Mobile Target in the Sender/Receiver Model](https://arxiv.org/abs/2508.04870)
*Khaled Jawhar,Evangelos Kranakis*

Main category: cs.DC

TL;DR: 双机器人通过不同通信方式（无线/面对面）协作搜索移动目标，研究新的搜索算法及其效率。


<details>
  <summary>Details</summary>
Motivation: 理解不对称通信（一个机器人可以无线发送和接收信息，另一个只能面对面通信）如何影响双机器人系统捕获移动目标的效率（竞争比）。

Method: 提出并分析了适用于S/R（Sender/Receiver）通信模型的线性搜索算法，该算法考虑了机器人对搜索环境（如起始距离、移动速度、移动方向等）的不同认知。

Result: 设计了新的线性搜索算法，并分析了在不同认知场景下捕获目标的竞争比。研究结果有助于理解通信能力差异对搜索策略的影响。

Conclusion: 该研究通过设计新的线性搜索算法，分析了具有不同通信能力的两自主机器人捕获盲目移动目标的时间竞争比，并探讨了不对称通信对线性搜索竞争比的影响。

Abstract: We consider linear search for capturing an oblivious moving target by two
autonomous robots with different communicating abilities. Both robots can
communicate Face-to-Face (F2F) when co-located but in addition one robot is a
Sender (can also send messages wirelessly) and the other also a Receiver (can
also receive messages wirelessly). This is known as Sender/Receiver (S/R, for
short) communication model. The robots can move with max speed $1$. The moving
target starts at distance $d$ from the origin and can move either with speed
$v<1$ away from the origin in the ``away'' model or with speed $v \geq 0$
toward the origin in the ``toward'' model. We assume that the direction of
motion of the target (i.e., whether it is the away or toward model) is known to
the robots in advance. To capture the target the two robots must be co-located
with it.
  We design new linear search algorithms and analyze the competitive ratio of
the time required to capture the target. The approach takes into account
various scenarios related to what the robots know about the search environment
(e.g., starting distance or speed of the mobile, away or toward model, or a
combination thereof). Our study contributes to understanding how asymmetric
communication affects the competitive ratio of linear search.

</details>


### [384] [Managing, Analyzing and Sharing Research Data with Gen3 Data Commons](https://arxiv.org/abs/2508.04944)
*Craig Barnes,Kyle Burton,Michael S. Fitzsimons,Hara Prasad Juvvala,Brienna Larrick,Christopher Meyer,Pauline Ribeyre,Ao Liu,Clint Malson,Noah Metoki-Shlubsky,Andrii Prokhorenkov,Jawad Qureshi,Radhika Reddy,L. Philip Schumm,Mingfei Shao,Trevar Simmons,Alexander VanTol,Peter Vassilatos,Aarti Venkat,Robert L. Grossman*

Main category: cs.DC

TL;DR: Gen3是一个开源的数据平台，可以轻松构建和管理数据共享中心，具有数据探索、数据提交和API访问功能，并支持与其他平台互操作。


<details>
  <summary>Details</summary>
Motivation: Gen3旨在为研究社区提供一个云基础的数据平台，以有效管理、分析和共享PB级的数据集和数百万个FAIR数据对象。

Method: Gen3通过定义数据模型来自动生成数据门户（用于搜索和探索数据）和数据提交门户，以及用于以编程方式访问数据的FAIR API。它构建在一系列基于标准的软件服务之上，以支持现有和未来的组件，并实现与其他数据平台的互操作。

Result: Gen3已成功用于构建十多个数据共享中心，总共包含超过28 PB的数据和6400万个FAIR数据对象。

Conclusion: Gen3是一个开源的数据平台，用于构建数据共享中心。它通过自动生成数据门户和FAIR API，简化了数据管理、分析和共享的流程，并支持与其他数据平台的互操作性。

Abstract: Gen3 is an open-source data platform for building data commons. A data
commons is a cloud-based data platform for managing, analyzing, and sharing
data with a research community. Gen3 has been used to build over a dozen data
commons that in aggregate contain over 28 PB of data and 64 million FAIR data
objects. To set up a Gen3 data commons, you first define a data model. Gen3
then autogenerates 1) a data portal for searching and exploring data in the
commons; 2) a data portal for submitting data to the commons; and 3) FAIR APIs
for accessing the data programmatically. Gen3 is built over a small number of
standards-based software services, which are designed to support current and
future Gen3 components so that Gen3 can interoperate with other data platforms
and data ecosystems.

</details>


### [385] [Tesserae: Scalable Placement Policies for Deep Learning Workloads](https://arxiv.org/abs/2508.04953)
*Song Bian,Saurabh Agarwal,Md. Tareq Mahmood,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: Tesserae 是一种 GPU 集群调度程序，可将作业放置策略设计为图匹配问题，从而提高资源利用率和性能。


<details>
  <summary>Details</summary>
Motivation: 提高深度学习 (DL) 集群调度程序的资源利用率，解决现有放置策略的性能低下或可扩展性差的问题。

Method: 设计新颖的作业放置策略，通过图匹配来最小化作业迁移开销和作业打包。

Result: Tesserae 相比现有调度程序，平均 JCT 提高了 1.62 倍，Makespan 提高了 1.15 倍。

Conclusion: Tesserae 通过将作业放置约束设计为图匹配问题，实现了可扩展且有效的 GPU 群集调度，与现有调度程序相比，平均 JCT 提高了 1.62 倍，Makespan 提高了 1.15 倍。

Abstract: Training deep learning (DL) models has become a dominant workload in
data-centers and improving resource utilization is a key goal of DL cluster
schedulers. In order to do this, schedulers typically incorporate placement
policies that govern where jobs are placed on the cluster. Existing placement
policies are either designed as ad-hoc heuristics or incorporated as
constraints within a complex optimization problem and thus either suffer from
suboptimal performance or poor scalability. Our key insight is that many
placement constraints can be formulated as graph matching problems and based on
that we design novel placement policies for minimizing job migration overheads
and job packing. We integrate these policies into Tesserae and describe how our
design leads to a scalable and effective GPU cluster scheduler. Our
experimental results show that Tesserae improves average JCT by up to 1.62x and
the Makespan by up to 1.15x compared with the existing schedulers.

</details>


### [386] [Task-Based Programming for Adaptive Mesh Refinement in Compressible Flow Simulations](https://arxiv.org/abs/2508.05020)
*Anjiang Wei,Hang Song,Mert Hidayetoglu,Elliott Slaughter,Sanjiva K. Lele,Alex Aiken*

Main category: cs.DC

TL;DR: Regent中的AMR求解器通过任务融合和自动GPU内核生成，显著提高了可压缩流体模拟的效率。


<details>
  <summary>Details</summary>
Motivation: 高阶求解器在科学应用中对于模拟可压缩流动至关重要，而AMR技术通过在感兴趣区域集中分辨率来降低计算成本，因此，在Regent中开发AMR求解器以提高计算效率和解决相关实现挑战是本研究的主要动机。

Method: 本研究在Regent（一种用于Legion编程模型的高级编程语言）中开发了一个基于AMR的数值求解器，并解决了AMR实现中的几个关键挑战，包括动态数据结构（用于块细化/粗化）、网格有效性强制以及通过任务融合降低任务启动开销。

Result: 实验结果表明，任务融合实现了18倍的加速，而通过简单的注解实现的自动GPU内核生成为目标内核带来了9.7倍的加速。通过求解Euler方程的可压缩流动问题的模拟，验证了所提出方法的可行性。

Conclusion: 该研究通过在Regent中实现基于AMR的数值求解器，并着重解决了AMR相关的挑战，如动态数据结构、网格有效性强制以及通过任务融合降低任务启动开销，为可压缩流动的高阶求解提供了新的解决方案。

Abstract: High-order solvers for compressible flows are vital in scientific
applications. Adaptive mesh refinement (AMR) is a key technique for reducing
computational cost by concentrating resolution in regions of interest. In this
work, we develop an AMR-based numerical solver using Regent, a high-level
programming language for the Legion programming model. We address several
challenges associated with implementing AMR in Regent. These include dynamic
data structures for patch refinement/coarsening, mesh validity enforcement, and
reducing task launch overhead via task fusion. Experimental results show that
task fusion achieves 18x speedup, while automated GPU kernel generation via
simple annotations yields 9.7x speedup for the targeted kernel. We demonstrate
our approach through simulations of two canonical compressible flow problems
governed by the Euler equations.

</details>


### [387] [Theseus: A Distributed and Scalable GPU-Accelerated Query Processing Platform Optimized for Efficient Data Movement](https://arxiv.org/abs/2508.05029)
*Felipe Aramburú,William Malpica,Kaouther Abrougui,Amin Aramoon,Romulo Auccapuclla,Claude Brisson,Matthijs Brobbel,Colby Farrell,Pradeep Garigipati,Joost Hoozemans,Supun Kamburugamuve,Akhil Nair,Alexander Ocsa,Johan Peltenburg,Rubén Quesada López,Deepak Sihag,Ahmet Uyar,Dhruv Vats,Michael Wendt,Jignesh M. Patel,Rodrigo Aramburú*

Main category: cs.DC

TL;DR: Theseus 是一个生产级、企业级、分布式、加速器原生的查询引擎，旨在优化 GPU 等加速器环境下的数据移动、内存利用率和计算。


<details>
  <summary>Details</summary>
Motivation: 为了降低在线分析处理（OLAP）查询的成本并提高吞吐量，系统可以利用 GPU 等加速器。然而，这带来了数据移动、内存利用率和计算协调方面的挑战。

Method: Theseus 采用专门的异步控制机制来平衡数据移动、内存利用率和计算，以优化基于加速器（如 GPU）的系统。它还使用固定大小的锁页主机内存分配来提高吞吐量并减少内存碎片。

Result: 在 TPC-H 基准测试中，Theseus 在 1k 到 30k 的比例因子下，其性能比 Databricks Photon 高出 4 倍，同时成本相当。

Conclusion: Theseus 可以在 2 个 DGX A100 640GB 节点上处理 100TB 数据，并且在 TPC-H 基准测试中，其性能比 Databricks Photon 高出 4 倍，同时成本相当。

Abstract: Online analytical processing of queries on datasets in the many-terabyte
range is only possible with costly distributed computing systems. To decrease
the cost and increase the throughput, systems can leverage accelerators such as
GPUs, which are now ubiquitous in the compute infrastructure. This introduces
many challenges, the majority of which are related to when, where, and how to
best move data around the system. We present Theseus -- a production-ready
enterprise-scale distributed accelerator-native query engine designed to
balance data movement, memory utilization, and computation in an
accelerator-based system context. Specialized asynchronous control mechanisms
are tightly coupled to the hardware resources for the purpose of network
communication, data pre-loading, data spilling across memories and storage, and
GPU compute tasks. The memory subsystem contains a mechanism for fixed-size
page-locked host memory allocations to increase throughput and reduce memory
fragmentation. For the TPC-H benchmarks at scale factors ranging from 1k to 30k
on cloud infrastructure, Theseus outperforms Databricks Photon by up to
$4\times$ at cost parity. Theseus is capable of processing all queries of the
TPC-H and TPC-DS benchmarks at scale factor 100k (100 TB scale) with as few as
2 DGX A100 640GB nodes.

</details>


### [388] [Simulating LLM training workloads for heterogeneous compute and network infrastructure](https://arxiv.org/abs/2508.05370)
*Sumit Kumar,Arjun Temura,Naman Sharma,Ramanjeet Singh,Meet Dadhania,Praveen Tammana,Satananda Burla,Abed Mohammad Kamaluddin,Rinku Shah*

Main category: cs.DC

TL;DR: Existing LLM training simulators assume uniform hardware, but real-world clusters have varied devices. This paper introduces a new simulator that accounts for this heterogeneity to provide more accurate training time predictions and guide system design.


<details>
  <summary>Details</summary>
Motivation: Current LLM training simulators assume homogeneous compute and network infrastructure, which does not reflect practical scenarios involving device heterogeneity in cloud environments, varying device generations, and intra-chip interconnect heterogeneity. This gap hinders innovation in areas like model optimization and performance tuning.

Method: The paper proposes a new design for a heterogeneity-aware distributed LLM simulator. Key components include abstractions for custom configurations of device groups and device-to-parallelism mapping, and non-uniform workload partitioning. The simulator aims to predict training time in heterogeneous environments.

Result: Initial simulation results demonstrate the impact of heterogeneity on model computation and communication time, highlighting the need for heterogeneity-aware simulation.

Conclusion: The paper proposes a heterogeneity-aware distributed LLM simulator to address the limitations of current simulators that assume homogeneous infrastructure. The new simulator can predict training time for heterogeneous environments by allowing custom configurations for device groups and device-to-parallelism mapping. Initial results show the impact of heterogeneity on computation and communication time.

Abstract: The growing demand for large-scale GPU clusters in distributed model training
presents a significant barrier to innovation, particularly in model
optimization, performance tuning, and system-level enhancements. To address
this challenge, LLM training simulators are employed to estimate training time
and guide design decisions. However, the state-of-the-art LLM training
simulators assume homogeneous compute and network infrastructure. In practice,
device heterogeneity is inevitable due to resource sharing in cloud
environments, frequent shifts in device generations, and inherent intra-chip
interconnect heterogeneity. To address the gap between state-of-the-art and
practical requirements, we propose the design of a heterogeneity-aware
distributed LLM simulator capable of predicting training time while enabling
abstractions to specify custom configurations for device groups and
device-to-parallelism mapping. We present the design requirements and
challenges in building a heterogeneity-aware distributed ML training simulator,
and design components such as non-uniform workload partitioning. Our initial
simulation results demonstrate the impact of heterogeneity on the model
computation and communication time.

</details>


### [389] [Adaptive Parallel Downloader for Large Genomic Datasets](https://arxiv.org/abs/2508.05511)
*Rasman Mubtasim Swargo,Engin Arslan,Md Arifuzzaman*

Main category: cs.DC

TL;DR: FastBioDL is a new downloader for large biological datasets that uses an adaptive controller to maximize download speed and minimize resource overhead, achieving up to 4x speedup over existing tools.


<details>
  <summary>Details</summary>
Motivation: Existing download tools often employ static concurrency settings, leading to inefficient bandwidth utilization and prolonged download times due to their inability to adapt to dynamic network conditions.

Method: FastBioDL frames the download process as an online optimization problem, utilizing a utility function and gradient descent to adjust the number of concurrent socket streams in real-time dynamically.

Result: FastBioDL achieves up to 4x speedup over state-of-the-art tools. Moreover, in high-speed network experiments, its adaptive design was up to 2.1x faster than existing tools.

Conclusion: FastBioDL is a robust and efficient solution for large-scale genomic data acquisition, democratizing high-performance data retrieval for researchers without requiring specialized commercial software or protocols.

Abstract: Modern next-generation sequencing (NGS) projects routinely generate terabytes
of data, which researchers commonly download from public repositories such as
SRA or ENA. Existing download tools often employ static concurrency settings,
leading to inefficient bandwidth utilization and prolonged download times due
to their inability to adapt to dynamic network conditions. We introduce
FastBioDL, a parallel file downloader designed for large biological datasets,
featuring an adaptive concurrency controller. FastBioDL frames the download
process as an online optimization problem, utilizing a utility function and
gradient descent to adjust the number of concurrent socket streams in real-time
dynamically. This approach maximizes download throughput while minimizing
resource overhead. Comprehensive evaluations on public genomic datasets
demonstrate that FastBioDL achieves up to $4x$ speedup over state-of-the-art
tools. Moreover, in high-speed network experiments, its adaptive design was up
to $2.1x$ faster than existing tools. By intelligently optimizing standard HTTP
or FTP downloads on the client side, FastBioDL provides a robust and efficient
solution for large-scale genomic data acquisition, democratizing
high-performance data retrieval for researchers without requiring specialized
commercial software or protocols.

</details>


### [390] [Modular Architecture for High-Performance and Low Overhead Data Transfers](https://arxiv.org/abs/2508.05546)
*Rasman Mubtasim Swargo,Engin Arslan,Md Arifuzzaman*

Main category: cs.DC

TL;DR: AutoMDT使用深度强化学习优化数据传输，比现有方法快8倍，减少68%的完成时间。


<details>
  <summary>Details</summary>
Motivation: 传统文件传输工具因固定配置或单一的优化方法，常导致资源利用不足和不稳定，无法满足高性能应用快速可靠传输海量数据集的需求。

Method: 提出了一种名为AutoMDT的新型模块化数据传输架构，该架构利用基于深度强化学习的代理来同时优化读、网络和写操作的并发级别。该方案包含一个轻量级的网络-系统模拟器，能够在约45分钟内完成Proximal Policy Optimization (PPO)代理的离线训练。

Result: 在生产级测试平台上进行评估，AutoMDT实现了高达8倍的收敛速度，并使传输完成时间减少了68%，相比于最先进的解决方案。

Conclusion: AutoMDT通过深度强化学习智能优化数据传输的并发级别，并在生产级测试中实现了高达8倍的收敛速度和68%的传输完成时间缩减，显著优于现有技术。

Abstract: High-performance applications necessitate rapid and dependable transfer of
massive datasets across geographically dispersed locations. Traditional file
transfer tools often suffer from resource underutilization and instability
because of fixed configurations or monolithic optimization methods. We propose
AutoMDT, a novel modular data transfer architecture that employs a deep
reinforcement learning based agent to simultaneously optimize concurrency
levels for read, network, and write operations. Our solution incorporates a
lightweight network-system simulator, enabling offline training of a Proximal
Policy Optimization (PPO) agent in approximately 45 minutes on average, thereby
overcoming the impracticality of lengthy online training in production
networks. AutoMDT's modular design decouples I/O and network tasks, allowing
the agent to capture complex buffer dynamics precisely and to adapt quickly to
changing system and network conditions. Evaluations on production-grade
testbeds show that AutoMDT achieves up to 8x faster convergence and a 68%
reduction in transfer completion times compared with state-of-the-art
solutions.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [391] [BTPG-max: Achieving Local Maximal Bidirectional Pairs for Bidirectional Temporal Plan Graphs](https://arxiv.org/abs/2508.04849)
*Yifan Su,Rishi Veerapaneni,Jiaoyang Li*

Main category: cs.MA

TL;DR: BTPG-max算法通过寻找更多双向对来改进MAPF解决方案的鲁棒性，尤其是在存在延迟的情况下。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体路径寻找（MAPF）中由于延迟导致代理偏离而产生的碰撞问题，需要一种能够处理时间和空间依赖性的方法。

Method: 提出了一种名为BPTG-max的算法，该算法旨在寻找更多的双向对，并证明了该算法在局部最优性方面进行了设计。

Result: BTPG-max算法被设计出来，可以在局部最优的情况下构建BTPG，并且在实践中找到了更多的双向边，提供了更好的任意时间行为和对延迟的鲁棒性。

Conclusion: BTPG-max算法在实践中可以找到更多的双向边，具有更优的任意时间行为，并提高了对延迟的鲁棒性。

Abstract: Multi-Agent Path Finding (MAPF) requires computing collision-free paths for
multiple agents in shared environment. Most MAPF planners assume that each
agent reaches a specific location at a specific timestep, but this is
infeasible to directly follow on real systems where delays often occur. To
address collisions caused by agents deviating due to delays, the Temporal Plan
Graph (TPG) was proposed, which converts a MAPF time dependent solution into a
time independent set of inter-agent dependencies. Recently, a Bidirectional TPG
(BTPG) was proposed which relaxed some dependencies into ``bidirectional pairs"
and improved efficiency of agents executing their MAPF solution with delays.
Our work improves upon this prior work by designing an algorithm, BPTG-max,
that finds more bidirectional pairs. Our main theoretical contribution is in
designing the BTPG-max algorithm is locally optimal, i.e. which constructs a
BTPG where no additional bidirectional pairs can be added. We also show how in
practice BTPG-max leads to BTPGs with significantly more bidirectional edges,
superior anytime behavior, and improves robustness to delays.

</details>


### [392] [Congestion Mitigation Path Planning for Large-Scale Multi-Agent Navigation in Dense Environments](https://arxiv.org/abs/2508.05253)
*Takuro Kato,Keisuke Okumura,Yoko Sasaki,Naoya Yokomachi*

Main category: cs.MA

TL;DR: 本文提出了一种名为CMPP的新路径规划方法，通过惩罚拥挤路径来减少交通拥堵，提高了多代理系统的导航效率。


<details>
  <summary>Details</summary>
Motivation: 在高密度环境中，大量自主代理同时以分布式方式移动，需要优化全局流以缓解局部拥堵，从而维持整体导航效率。

Method: 本文提出了拥堵缓解路径规划（CMPP）问题，将拥堵直接纳入成本函数，定义为代理路径上入边使用情况。CMPP为稀疏图的每个顶点分配基于流的乘性惩罚。为解决该问题，开发了两种求解器：一种是用于小规模实例的精确混合整数非线性规划求解器，另一种是可扩展的两层搜索算法A-CMTS，用于快速找到大规模实例的次优解并迭代优化。实验表明，CMPP能显著减少局部拥堵并提高系统吞吐量。

Result: 实验表明，CMPP显著减少了局部拥堵，提高了系统吞吐量，并在离散和连续空间场景中都表现出了优越性。将CMPP与最先进的避碰规划器结合，能够提升多代理系统的性能。

Conclusion: CMPP通过在成本函数中嵌入拥堵信息，为解决高密度环境中多自主代理的路径规划问题提供了一种新颖的方法。该方法通过对图的顶点施加基于流的乘性惩罚来捕捉拥堵的本质，并能在实际应用中有效减少局部拥堵，提高系统吞吐量。

Abstract: In high-density environments where numerous autonomous agents move
simultaneously in a distributed manner, streamlining global flows to mitigate
local congestion is crucial to maintain overall navigation efficiency. This
paper introduces a novel path-planning problem, congestion mitigation path
planning (CMPP), which embeds congestion directly into the cost function,
defined by the usage of incoming edges along agents' paths. CMPP assigns a
flow-based multiplicative penalty to each vertex of a sparse graph, which grows
steeply where frequently-traversed paths intersect, capturing the intuition
that congestion intensifies where many agents enter the same area from
different directions. Minimizing the total cost yields a set of coarse-level,
time-independent routes that autonomous agents can follow while applying their
own local collision avoidance. We formulate the problem and develop two
solvers: (i) an exact mixed-integer nonlinear programming solver for small
instances, and (ii) a scalable two-layer search algorithm, A-CMTS, which
quickly finds suboptimal solutions for large-scale instances and iteratively
refines them toward the optimum. Empirical studies show that augmenting
state-of-the-art collision-avoidance planners with CMPP significantly reduces
local congestion and enhances system throughput in both discrete- and
continuous-space scenarios. These results indicate that CMPP improves the
performance of multi-agent systems in real-world applications such as logistics
and autonomous-vehicle operations.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [393] [Quantum-impurity sensing of altermagnetic order](https://arxiv.org/abs/2508.04788)
*V. A. S. V. Bittencourt,H. Hosseinabadi,J. Sinova,L. Šmejkal,J. Marino*

Main category: cond-mat.mes-hall

TL;DR: 利用氮-空位（NV）中心量子弛豫测量技术可以探测反磁性绝缘体的各向异性自旋动力学。


<details>
  <summary>Details</summary>
Motivation: 量子传感技术被用于探测凝聚态物质系统。

Method: 利用氮-空位（NV）中心量子弛豫测量技术。

Result: 量子弛豫测量技术可以揭示反磁性绝缘体的各向异性自旋动力学及其特征性的自旋极化能带。通过测量附近量子杂质的距离和方位角依赖的弛豫率，可以获得反磁性磁性所特有的动量空间各向异性信息。这种方向敏感性可以区分反磁性体和常规反铁磁体。

Conclusion: NV-sensing 实验可以用于研究自旋输运和对称性破缺，NV 轴向对于研究各向异性现象很重要。

Abstract: Quantum sensing with individual spin defects has emerged as a versatile
platform to probe microscopic properties of condensed matter systems. Here we
demonstrate that quantum relaxometry with nitrogen-vacancy (NV) centers in
diamond can reveal the anisotropic spin dynamics of altermagnetic insulators
together with their characteristic spin polarised bands. We show that the
distance and orientation dependent relaxation rate of a nearby quantum impurity
encodes signatures of momentum space anisotropy in the spin diffusion response,
a hallmark of altermagnetic order. This directional sensitivity is
unprecedented in the landscape of quantum materials sensing, and it enables the
distinction of altermagnets from conventional antiferromagnets via local,
noninvasive measurements. Our results could spark new NV-sensing experiments on
spin transport and symmetry breaking in altermagnets, and highlight the role of
NV orientation to probe anisotropic phenomena in condensed matter systems.

</details>


### [394] [Observation of σ-πcoupling and mode selection in optically trapped artificial polariton molecules](https://arxiv.org/abs/2508.04909)
*Krzysztof Sawicki,Valtýr Kári Daníelsson,Dmitriy Dovzhenko,Pavlos G. Lagoudakis,Simone De Liberato,Helgi Sigurðsson*

Main category: cond-mat.mes-hall

TL;DR: 通过光学约束和相互作用，研究了极化激子凝聚体中的耦合机制，并展示了其在模拟分子键合方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索受限的非平衡和非线性物质态之间的耦合机制。

Method: 通过利用光学重构激光激发模式，创建环形光束来约束极化激子，并利用光学陷阱的耗散性实现与相邻凝聚体的相互作用。

Result: 研究揭示了基于激发参数的丰富模式结构，并展示了极化激子凝聚体在模拟分子键合机制方面的潜力。

Conclusion: 该研究结果支持了极化激子凝聚体在探索和模拟σ和π分子键合机制方面的潜力。

Abstract: Microcavity exciton-polariton condensates under additional transverse
confinement constitute a flexible optical platform to study the coupling
mechanism between confined nonequilibrium and nonlinear states of matter.
Driven far from equilibrium, polariton condensates can display spontaneous
synchronization and instabilities depending on excitation and material
parameters, showcasing emergent and intricate interference patterns based on
mode competition over mutual gain landscapes. Here, we explore this coupling
mechanism between polariton condensates populating the first excited ${\it
p}$-state manifold of coupled optically trapped condensates and show a rich
structure of patterns based on excitation parameters. The optical
reconfigurability of the laser excitation patterns enables the creation of an
annular-shaped beam to confine polaritons in a tailored trapping potential,
whilst the dissipative nature of the optical traps enables effective
interaction with neighboring condensates. Our results underpin the potential
role of polariton condensates in exploring and simulating $\sigma$ and $\pi$
molecular bonding mechanisms between artificial two-dimensional diatomic
orbitals and beyond.

</details>


### [395] [Micromagnetic Design of Bias-Free Reconfigurable Microwave Properties in Hexagonal Shaped Multilayer Nanomagnets](https://arxiv.org/abs/2508.04910)
*Krishna Begari*

Main category: cond-mat.mes-hall

TL;DR: 通过微磁模拟，开发了一种新颖的六边形纳米磁体结构，可在不同磁状态下实现GHz频段的可调谐微波频率响应，并观察到显著的频率偏移。


<details>
  <summary>Details</summary>
Motivation: 为了探索和开发用于当前和未来微波技术的新型磁性微型化纳米结构，以利用其在GHz频率范围内的磁化动力学特性。

Method: 本研究采用微磁模拟方法，通过简单的场初始化和纳秒宽磁脉冲场，研究了新颖六边形纳米磁体结构（包括单层和多层）的静态和动态磁特性，并调谐了其在不同磁剩余状态下的磁化动力学参数。

Result: 研究发现在单层和多层纳米磁体中，两个不同的磁剩余状态在亚吉赫和吉赫区域之间存在显著的频率偏移，证明了该结构的可重构微波特性。

Conclusion: 所提出的新颖六边形纳米磁体结构在亚吉赫和吉赫区域表现出可调谐的微波频率响应，并且在两个不同的磁剩余状态之间具有显著的频率偏移。

Abstract: Magnetic miniaturized nanostructures hold great promise for current and
future microwave technologies due to their magnetization dynamics in the GHz
frequency range. This work presents a method for investigating reconfigurable
microwave properties using a novel hexagonal nanomagnet structure.
Micromagnetic simulations are employed to investigate the magnetic static and
dynamic properties of the nanomagnets. A simple field initialization method is
used to examine two distinct magnetic remanent states in each sample. A
nanosecond-width magnetic pulse field can be applied to tune the unique
magnetization dynamics parameters corresponding to the different remanent
states. Find that for both single-layer and multilayer nanomagnets, there is a
notable frequency shift in the sub-GHz and GHz regions between the two distinct
magnetic remanent states.

</details>


### [396] [Engineering Topological Materials](https://arxiv.org/abs/2508.04927)
*Amit Goft,Eric Akkermans*

Main category: cond-mat.mes-hall

TL;DR: 嵌入缺陷或空间纹理可实现拓扑材料设计和可控的拓扑相变。


<details>
  <summary>Details</summary>
Motivation: 十折分类法虽为组织拓扑物态提供了框架，但缺乏在不同类之间进行系统过渡或工程化材料以实现所需拓扑特性的方法。

Method: 通过嵌入缺陷或空间纹理来改变对称性或空间维度，从而实现拓扑相变的控制。

Result: 通过嵌入缺陷或空间纹理，可以实现拓扑相变的按需诱导，并通过具体实例证明了局部缺陷能够生成具有不同对称性和拓扑不变量的相。

Conclusion: 文章提出了通过嵌入缺陷或空间纹理来设计拓扑材料的一般方法，实现了在十折分类表中的受控导航，并可按需诱导拓扑相变。

Abstract: The tenfold classification provides a powerful framework for organizing
topological phases of matter based on symmetry and spatial dimension. However,
it does not offer a systematic method for transitioning between classes or
engineering materials to realize desired topological properties. In this work,
we introduce a general method for designing topological materials by embedding
defects or spatial textures, which alter symmetry or dimension. This enables
controlled navigation across the tenfold table, allowing one to induce
topological phase transitions on demand. We illustrate this approach through
several nontrivial examples, demonstrating how local defects can generate
phases with different symmetries and topological invariants.

</details>


### [397] [Chern junctions in Moiré-Patterned Graphene/PbI2](https://arxiv.org/abs/2508.04935)
*Sun Yan,M. Monteverde,V. Derkach,K. Watanabe,T. Taniguchi,F. Chiodi,H. Bouchiat,A. D. Chepelianskii*

Main category: cond-mat.mes-hall

TL;DR: 通过将PbI2引入莫尔材料家族，研究了其异质结构莫尔超晶格的磁输运性质。发现了无耗散输运、分数电导平台和相干电子干涉等现象，并认为PbI2层诱导的自旋-轨道耦合影响了结果。该材料平台有望用于实现新颖的莫尔现象和工程化相干边缘输运。


<details>
  <summary>Details</summary>
Motivation: 拓展莫尔材料库以解锁新的量子物相和涌现电子行为。

Method: 研究了六方氮化硼/石墨烯/PbI2 异质结构莫尔超晶格的磁输运性质。

Result: 在强场量子霍尔区域，观察到电荷中性点处鲁棒的无耗散输运（v_h = 0），以及2/3 e^2/h处的分数电导平台（归因于具有不同陈数的畴之间的陈结）。莫尔哈夫施塔特能谱表现出非传统的风味序列（可能受PbI2层引起的近邻诱导自旋-轨道耦合影响），并且在陈数为-2的线上观察到相干电子干涉。

Conclusion: PbI2基异质结构为实现自旋轨道耦合增强的莫尔现象和工程化二维量子材料中的相干边缘输运提供了一个多功能平台。

Abstract: Expanding the moir\'e material library continues to unlock novel quantum
phases and emergent electronic behaviors. In this work, we introduce PbI2 into
the moir\'e family and investigate the magnetotransport properties of moir\'e
superlattice in a hexagonal boron nitride/graphene/PbI2 heterostructures. In
high-field quantum Hall regime, we observe a robust dissipationless transport
at charge neutrality point, indicative of incompressible states stabilized at
the filling factor vh = 0. Additionally, a fractional conductance plateau at
2/3 e2/h emerges, which we attribute to a Chern junction between domains with
distinct Chern numbers originating from moir\'e-modulated and conventional
integer quantum Hall states. The moir\'e Hofstadter spectrum displays an
unconventional flavor sequence, likely influenced by proximity-induced
spin-orbit coupling from the PbI2 layer. We also see coherent electronic
interference along lines with Chern number vm = -2. These findings position
PbI2-based heterostructures as a versatile platform for realizing
spin-orbit-enhanced moir\'e phenomena and engineering coherent edge transport
in two-dimensional quantum materials.

</details>


### [398] [Theory of magnon hydrodynamics in collinear antiferromagnets](https://arxiv.org/abs/2508.05057)
*Vivianne Olguín-Arias,Alireza Qaiumzadeh,Roberto E. Troncoso*

Main category: cond-mat.mes-hall

TL;DR: “This paper explores magnon transport in antiferromagnets, modeling magnons as a viscous fluid to understand hydrodynamic effects. It proposes a theoretical framework for viscous magnon hydrodynamics, identifying transport signatures like nonlocal resistance and spin/thermal conductance. The study highlights how magnon scattering influences spin current propagation and derives key parameters for magnon conductivity.”


<details>
  <summary>Details</summary>
Motivation: “We investigate the transport of spin angular momentum and linear momentum carried by magnons in electrically insulating collinear antiferromagnets (AFs). Focusing on both transverse and longitudinal geometries.”

Method: “We model magnons as a viscous fluid and explore the hydrodynamic transport regime that emerges when the magnon-magnon scattering length is shorter than the momentum-relaxation length, such that momentum-conserving processes dominate over momentum-relaxing ones. We develop a theoretical framework to investigate viscous effects in the magnon hydrodynamic regime, which give rise to measurable transport signatures such as nonlocal resistance and spin and thermal conductance. Accounting for both momentum and spin relaxations, we derive hydrodynamic equations governing magnon momentum and spin transport.”

Result: “Notably, interspecies scattering between antiferromagnetic magnons with opposite spin angular momentum induces drag-like effects that strongly modify spin current propagation. We derive expressions for magnon conductivity and introduce an accessibility parameter quantifying intra-band momentum transfer.”

Conclusion: “The results establish antiferromagnetic insulators as a promising platform for observing magnon-fluid dynamics and exploring collective spin transport phenomena.”

Abstract: We investigate the transport of spin angular momentum and linear momentum
carried by magnons in electrically insulating collinear antiferromagnets (AFs).
Focusing on both transverse and longitudinal geometries, we model magnons as a
viscous fluid and explore the hydrodynamic transport regime that emerges when
the magnon-magnon scattering length is shorter than the momentum-relaxation
length, such that momentum-conserving processes dominate over momentum-relaxing
ones. We develop a theoretical framework to investigate viscous effects in the
magnon hydrodynamic regime, which give rise to measurable transport signatures
such as nonlocal resistance and spin and thermal conductance. Accounting for
both momentum and spin relaxations, we derive hydrodynamic equations governing
magnon momentum and spin transport. Notably, interspecies scattering between
antiferromagnetic magnons with opposite spin angular momentum induces drag-like
effects that strongly modify spin current propagation. We derive expressions
for magnon conductivity and introduce an accessibility parameter quantifying
intra-band momentum transfer. Our results establish antiferromagnetic
insulators as a promising platform for observing magnon-fluid dynamics and
exploring collective spin transport phenomena.

</details>


### [399] [Multiple quantum spin Hall states and topological current divider in Twisted Bilayer WSe$_2$](https://arxiv.org/abs/2508.05092)
*Hao He,Zhao Gong,Shuai Li,Jian-Jun Liu,Hui-Ying Mu,Xing-Tao An*

Main category: cond-mat.mes-hall

TL;DR: 扭曲的WSe$_{2}$双层存在新的量子自旋霍尔态（双重和四重），边缘态新颖且更鲁棒，可用于构建拓扑电流分流器，支持无耗散自旋电子学发展。


<details>
  <summary>Details</summary>
Motivation: 为了全面理论表征扭曲过渡金属二硫化钨双层中存在的拓扑量子自旋霍尔态的边缘态。

Method: 通过理论计算研究了扭曲的WSe$_{2}$双层的拓扑输运性质，识别了新的量子自旋霍尔态及其边缘态的特性。

Result: 发现了除单重量子自旋霍尔态之外，还存在双重和四重量子自旋霍尔态。这些边缘态的载流子不局限于边缘，而是位于莫尔超晶格边界的高电势点，可以连续地进行层间跃迁并向前传播。这些状态具有鲁棒性，并且可以通过门电压进行调控，最终提出了一个五端器件作为拓扑电流分流器。

Conclusion: 该研究发现了扭曲的WSe$_{2}$双层中出现的新的量子自旋霍尔态（双重和四重），其边缘态具有新颖的传输特性，并且比传统的单重量子自旋霍尔态更具鲁棒性。通过门电压调控可以实现单重和双重量子自旋霍尔态之间的转换，并提出了基于此特性的拓扑电流分流器器件。

Abstract: It has been demonstrated that topological quantum spin Hall (QSH) state exist
in twisted bilayers of transition metal dichalcogenides. However, a
comprehensive theoretical characterization of the topological edge states
remains a topic of interest and an unresolved issue. Here, the topological
transport properties of the twisted WSe$_2$ bilayers are investigated. Beyond
the conventional single QSH, we identify emergent double and quartuple quantum
spin Hall states, hosting two and four pairs of counter-propagating helical
edge channels respectively. Furthermore, the charge carriers in these edge
states are not localized at edge but rather the high potential point of the
moire superlattice boundary, undergoing interlayer transitions and propagating
forward continuously. We term these edge states as moire edge states. These
edge states can survive in non-magnetic disorder, with the robustness of double
QSH states surpassing that of single QSH states. At a twisting angle of
2.45$^\circ$, the transition between the single and double QSH states can be
achieved by adjusting the gate on the surface. Based on this, we propose a
five-terminal device to as a topological current devider. Our findings provide
support for the development of dissipationless spintronics.

</details>


### [400] [Unraveling Size Dependent Bi- and Tri-exciton Characteristics in CdSe/CdS Core/Shell Quantum Dots via Ensemble Time Gated Heralded Spectroscopy](https://arxiv.org/abs/2508.05203)
*Einav Scharf,Rotem Liran,Adar Levi,Omer Alon,Nadav Chefetz,Dan Oron,Uri Banin*

Main category: cond-mat.mes-hall

TL;DR: 一种新的光谱学方法，用于研究量子点中的多激子。


<details>
  <summary>Details</summary>
Motivation: 多激子（MXs）在量子点（QDs）中表现出量子限制下的多体相互作用。MXs在QD激光、发光二极管和光催化等多种光电应用中也很重要。然而，MXs之间导致快速非辐射衰减的强相互作用给它们的表征带来了挑战。

Method: 利用光谱分辨的时间门控预言光谱学来研究量子点（QD）系综中的多激子（MXs）。

Result: 提取了一系列CdSe/CdS QD系综的激子结合能，并研究了三激子（MXs）的能量和寿命。

Conclusion: 该方法可以应用于表征其他量子点系统中MXs的能量和寿命，从而能够快速表征和理解MXs的性质。这种洞察与从激子到电致发光器件再到量子光源等光电应用相关。

Abstract: Multiexcitons (MXs) in quantum dots (QDs) manifest many body interactions
under quantum confinement. Beyond this fundamental interest, MXs are of
importance in numerous optoelectronic applications including QD lasing, light
emitting diodes and photocatalysis. Yet, the strong interactions between MXs
leading to rapid non-radiative decay introduce challenges for their
characterization. While so far, the measurement techniques rely either on
indirect methods or on single particle studies, herein we introduce a new
method to study MXs in QD ensembles utilizing spectrally resolved time-gated
heralded spectroscopy. With this approach we extract the biexciton binding
energies in a series of CdSe/CdS QD ensembles of several core/shell sizes,
manifesting a transition between attractive and repulsive exciton-exciton
interactions. Additionally, for triexcitons, which involve occupation of two
excitons in the 1s energy levels, as well as one exciton in the 1p energy
levels, we address the open issues of isolating the spectra of the two
triexciton pathways from one another and from high-order MXs, and extract the
MX lifetimes. The measurements on ensembles provide high photon counts and low
noise levels, and alongside the time-gated heralded approach thus enable the
observation of MX characteristics that are difficult to resolve in single
particle studies. The approach can be further implemented in the
characterization of the energies and lifetimes of MXs in other QD systems to
enable rapid characterization and understanding of the MX properties. Such
insight bears relevance to optoelectronic applications ranging from lasing to
electroluminescent devices to quantum light sources.

</details>


### [401] [Stacking-induced type-II quantum spin Hall insulators with high spin Chern number in unconventional magnetism](https://arxiv.org/abs/2508.05365)
*Chao-Yang Tan,Panjun Feng,Ze-Feng Gao,Fengjie Ma,Peng-Jie Guo,Zhong-Yi Lu*

Main category: cond-mat.mes-hall

TL;DR: 堆叠两个II型量子自旋霍尔绝缘体形成高自旋陈数量子自旋霍尔绝缘体，具有拓扑边缘态和高量子化自旋霍尔电导。


<details>
  <summary>Details</summary>
Motivation: 探索堆叠两个II型量子自旋霍尔绝缘体是否会产生平凡绝缘体。

Method: 基于晶格模型的计算和第一性原理电子结构计算。

Result: 堆叠两个II型量子自旋霍尔绝缘体不会产生平凡绝缘体，而是形成一个高自旋陈数量子自旋霍尔绝缘体。该相在边界处共存着一对具有相反手性和极化的拓扑边缘态。双层系统的量子自旋霍尔电导量是单层系统的两倍。当存在U(1)对称性时，高自旋陈数相保持稳定；当U(1)对称性被破坏时，它在广泛的参数范围内仍然存在。提出双层Nb2SeTeO是具有高自旋陈数的高量子自旋霍尔绝缘体。将该策略扩展到多层堆叠可以自然地得到具有更大自旋陈数的量子自旋霍尔绝缘体。

Conclusion: 本工作不仅加深了I型和II型量子自旋霍尔绝缘体之间的区别，还提供了一条实现高量子化自旋霍尔电导的途径。

Abstract: Generally, stacking two monolayer type-I quantum spin Hall insulators gives
rise to a trivial insulator. However, whether or not stacking two type-II
quantum spin Hall insulators results in a trivial insulator has not yet been
explored. In this letter, based on the calculations of lattice model, we
demonstrate that stacking two type-II quantum spin Hall insulators does not
yield a trivial insulator, but instead forms a quantum spin Hall insulator with
high spin Chern number. In this phase, there are two pairs of topological edge
states with opposite chirality and polarization coexisting in the boundary. Our
calculations further reveal that the quantized spin Hall conductance of the
bilayer is twice that of the monolayer. When U(1) symmetry is present, the high
spin Chern number phase remains stable; when U(1) symmetry is broken, it
persists over a broad parameter range. Furthermore, based on the
first-principles electronic structure calculations, we propose that bilayer
Nb$_2$SeTeO is a type-II quantum spin Hall insulator with high spin Chern
number. Finally, extending this strategy to multilayer stacks naturally leads
to quantum spin Hall insulator with larger spin Chern number. Our work not only
deepens the distinction between type-I and type-II quantum spin Hall
insulators, but also offers a route toward realizing highly quantized spin Hall
conductance.

</details>


### [402] [Universal relations between thermoelectrics and noise in mesoscopic transport across a tunnel junction](https://arxiv.org/abs/2508.05413)
*Andrei I. Pavlov,Mikhail N. Kiselev*

Main category: cond-mat.mes-hall

TL;DR: 开发了一个统一理论，连接了量子输运中的电荷、热量和噪声性质，发现了普适关系，并应用于量子点系统，用于识别额外能量尺度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在揭示系统热电和噪声性质之间普适的输运关系，并为理解量子点等复杂系统的输运现象提供新的视角。

Method: 本研究提出了一种统一的理论框架，用于分析输运实验中电流和噪声的弱探测微分可观测量。

Result: 研究发现了一组普适的输运关系，连接了系统的热电和噪声性质，并将此理论应用于多种量子点系统，展示了这些关系在不同模型中的普适性，并指出这些关系可以指示系统中是否存在额外的能量尺度。

Conclusion: 本研究揭示了在输运实验中，电流和噪声的弱探测微分可观测量的一个统一理论，发现了热电和噪声性质之间的一组普适输运关系，而维德曼-陈宁定律只是电荷和热流之间普适性的一例。该理论应用于各种量子点系统，包括多通道Kondo、量子霍尔和Sachdev-Ye-Kitaev量子点，并证明每个微观理论都具有连接电导、热电和噪声的普适关系集。这些关系的存在指示了系统中是否存在其他的能量尺度。

Abstract: We develop a unified theory of weakly probed differential observables for
currents and noise in transport experiments. Our findings uncover a set of
universal transport relations between thermoelectric and noise properties of a
system probed through a tunnel contact, with the Wiedemann-Franz law being just
one example of such universality between charge and heat currents. We apply
this theory to various quantum dot systems, including multichannel Kondo,
quantum Hall and Sachdev-Ye-Kitaev quantum dots, and demonstrate that each of
the microscopic theories is characterized by a set of universal relations
connecting conductance and thermoelectrics with noise. Violations of these
relations indicate additional energy scales emerging in a system.

</details>


### [403] [Negative differential conductance in triangular molecular assemblies](https://arxiv.org/abs/2508.05575)
*Chao Li,Vladislav Pokorný,Prokop Hapala,Martin Žonda,Ping Zhou,Silvio Decurtins,Shi-Xia Liu,Fengqi Song,Rémy Pawlak,Ernst Meyer*

Main category: cond-mat.mes-hall

TL;DR: 在超导铅衬底上用TBTAP分子构建的分子器件展现出负微分电导（NDC）特性，这是由于分子间的库仑阻塞和电容耦合。改变分子簇结构可以调控其电子性质，为分子电子学提供新平台。


<details>
  <summary>Details</summary>
Motivation: 探索在分子尺度上实现负微分电导（NDC）现象，并研究分子间相互作用和衬底效应如何影响电子性质，以期为分子器件和纳电子学提供新的实现路径。

Method: 通过在超导Pb(111)衬底上自组装四溴四嗪（TBTAP）分子的三角三聚体，并利用低温扫描隧道谱（STS）观测NDC现象。通过二维差分电导映射可视化库仑阻塞和分子间电容耦合效应，并采用三杂质安德森模型和主方程方法进行理论建模。

Result: 成功在TBTAP分子三聚体上观测到负微分电导（NDC）行为，该行为源于库仑阻塞和分子间电容耦合。通过改变分子簇结构（如六聚体）可以调控电子性质。理论模型成功复现了实验结果，并证明NDC效应与超导性无关，而是由电子相关性主导。

Conclusion: 该研究展示了一种基于分子自组装的负微分电导（NDC）器件，证明了通过调控分子簇的拓扑结构可以实现对电子性质的灵活控制，为构建多功能分子器件和可编程、可扩展的纳电子学提供了平台。

Abstract: We report the creation and characterization of a molecular-scale negative
differential conductance (NDC) device by assembling a triangular trimer of
4,5,9,10-tetrabromo-1,3,6,8-tetraazapyrene (TBTAP) molecules on a
superconducting Pb(111) substrate. Using low-temperature scanning tunneling
spectroscopy, we observe robust NDC behavior manifesting as a decrease in
current with increasing voltage between 0.7-0.9 V arising from the interplay of
Coulomb blockade and strong inter-molecular capacitive coupling within the
molecular cluster. Gate-controlled charging and discharging processes are
directly visualized via two-dimensional differential conductance mapping, which
reveals the emergence of Coulomb rings and spatial regions of NDC. Theoretical
modeling using a three-impurity Anderson model and master equation approach
quantitatively reproduces the experimental observations and demonstrates that
the NDC emerges purely from electron correlations, independent of the
underlying superconductivity. By tuning the geometry to a hexamer structure, we
further show that cluster topology provides versatile control over electronic
properties at the molecular scale. These results establish a functional
platform for implementing multifunctional molecular devices and highlight a
strategy toward programmable and scalable nanoelectronics.

</details>


### [404] [Nonreciprocal inertial spin-wave dynamics in twisted magnetic nanostrips](https://arxiv.org/abs/2508.05576)
*Massimiliano d'Aquino,Riccardo Hertel*

Main category: cond-mat.mes-hall

TL;DR: 研究了软磁纳米带的惯性自旋波动力学，发现了几何形状（曲率、扭转、拓扑）和磁惯性可以产生太赫兹振荡和非互易性，并提出了相应的理论模型和解析表达式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索软磁纳米带中的惯性自旋波动力学，特别是几何形状（曲率和扭转）如何影响磁振荡，并利用这些效应开发太赫兹宏观磁学和非互易性自旋电子学器件。

Method: 开发了三维扭曲软磁纳米带中惯性自旋波动力学的理论框架，并推导了描述色散关系和光谱线宽的解析表达式，涵盖了章动（THz）和进动（GHz）两种模式。

Result: 理论框架揭示了曲率和扭转耦合磁惯性可产生太赫兹磁振荡，并导致自旋波谱的显著非互易性。通过分析几何（贝里）相位，得到了色散关系和线宽的解析表达式。不同的拓扑结构（如莫比乌斯和螺旋）对波数量化有不同的影响。

Conclusion: 这项研究提出了扭曲软磁纳米带中的惯性自旋波动力学理论框架，利用曲率和扭转耦合磁惯性产生太赫兹（THz）磁振荡。研究结果表明，几何手性和惯性效应引起有效对称性破缺，导致自旋波谱表现出显著的非互易性。通过分析，该行为由曲率引起的几何（贝里）相位控制，该相位可以通过简明表达式解析地捕捉到。研究还阐述了拓扑变化（如莫比乌斯和螺旋几何）对波数量化的影响，并强调了拓扑在自旋波传输中的作用。这些发现为扭曲磁性条带在曲线太赫兹宏观磁学和非互易性自旋电子学应用中的潜力提供了依据。

Abstract: We develop a theoretical framework for inertial spin-wave dynamics in
three-dimensional twisted soft-magnetic nanostrips, where curvature and torsion
couple with magnetic inertia to generate terahertz (THz) magnetic oscillations.
The resulting spin-wave spectra exhibit pronounced nonreciprocity due to
effective symmetry breaking arising from geometric chirality and inertial
effects. We show that this behavior is governed by a curvature-induced
geometric (Berry) phase, which we analytically capture through compact
expressions for dispersion relations and spectral linewidths in both nutational
(THz) and precessional (GHz) regimes. Topological variations, including
M\"obius and helical geometries, impose distinct wavenumber quantization rules,
elucidating the role of topology in spin-wave transport. These results position
twisted magnetic strips as a viable platform for curvilinear THz magnonics and
nonreciprocal spintronic applications.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [405] [Injection Locking and Coupling Dynamics in Superconducting Nanowire based Cryogenic Oscillators](https://arxiv.org/abs/2508.04878)
*Md Mazharul Islam,Md Shafayat Hossain,Kathleen E Hamilton,Ahmedullah Aziz*

Main category: cs.ET

TL;DR: 研究了超导纳米线低温振荡器的同步和耦合机制，结果可用于构建新型低温计算器件。


<details>
  <summary>Details</summary>
Motivation: 低温振荡器在超导电子学和量子计算中至关重要，可提供稳定、低噪声和低功耗的信号。本研究旨在深入理解超导纳米线（ScNW）低温振荡器的注入锁定和互耦合动力学，为优化其性能和开发新型低温计算架构提供指导。

Method: 对基于ScNW的独立振荡器进行了设计空间研究，并考察了两种关键机制：1. 外部AC信号注入锁定；2. 两个ScNW振荡器在不同耦合强度下的互耦合动力学。研究了分流电阻、纳米线电感和耦合强度等参数对锁定范围的影响，并分析了注入信号幅度对锁定振荡幅度的影响。此外，还利用容性和阻性耦合元件分析了耦合ScNW振荡器之间的互同步，并研究了耦合强度对相位差的控制。

Result: 研究确定了影响锁定范围的关键设计参数，如分流电阻、纳米线电感和耦合强度。发现注入信号幅度会影响锁定振荡的幅度。通过调整耦合强度，可以精确控制耦合ScNW振荡器之间的相位差，为可编程相位编码信息处理提供了可能。

Conclusion: 本研究提出了超导纳米线（ScNW）低温振荡器的注入锁定和互耦合动力学模型，并进行了全面的数值研究。通过调整分流电阻、纳米线电感和耦合强度等关键参数，可以实现频率同步和信号协调，并精确控制振荡器之间的相位差，为构建基于ScNW的振荡神经网络、同步低温逻辑块和片上低温谐振器阵列等应用提供了理论基础。

Abstract: Oscillators designed to function at cryogenic temperatures play a critical
role in superconducting electronics and quantum computing by providing stable,
low noise signals with minimal energy loss.Here we present a comprehensive
numerical study of injection locking and mutual coupling dynamics in
superconducting nanowire based cryogenic oscillators.Using the design space of
standalone ScNW based oscillator, we investigate two critical mechanisms that
govern frequency synchronization and signal coordination in cryogenic computing
architectures.First, an injection locking induced by an external AC signal with
a frequency near the oscillators natural frequency, and second, the mutual
coupling dynamics between two ScNW oscillators under varying coupling
strengths.We identify key design parameters such as shunt resistance, nanowire
inductance, and coupling strength that govern the locking range.Additionally,
we examine how the amplitude of the injected signal affects the amplitude of
the locked oscillation, offering valuable insights for power aware oscillator
synchronization.Furthermore, we analyze mutual synchronization between coupled
ScNW oscillators using capacitive and resistive coupling elements.Our results
reveal that the phase difference between oscillators can be precisely
controlled by tuning the coupling strength, enabling programmable phase encoded
information processing.These findings could enable building ScNW based
oscillatory neural networks, synchronized cryogenic logic blocks, and on chip
cryogenic resonator arrays.

</details>


### [406] [Wave Computing based on Dynamical Networks: Applications in Optimization Problems](https://arxiv.org/abs/2508.05014)
*Yunwen Liu,Jiang Xiao*

Main category: cs.ET

TL;DR: 开发了一种基于波传播的计算框架，可实现多维度并行，并已通过SPICE模拟验证了其在解决NP难问题方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了探索一种能够内在并行化并能在空间、时间、频率等多个维度上扩展，从而有效解决NP难问题的计算范式。

Method: 开发了一个计算框架，该框架利用了节点和边缘具有波操纵能力（如频率混合或时间延迟）的互连网络中的波传播。

Result: 通过SPICE模拟验证了所提出的架构，证明了其在解决数量分割问题、0/1背包问题和旅行商问题等NP难问题方面的潜力。

Conclusion: 该计算框架通过利用互连网络中的波传播，并在节点和边缘具有频率混合或时间延迟等波操纵能力，为解决NP难问题提供了一种新的方法。

Abstract: We develop a computing framework that leverages wave propagation within an
interconnected network, where nodes and edges possess wave manipulation
capabilities, such as frequency mixing or time delay. This computing paradigm
can not only achieve intrinsic parallelism like existing works by the
exploration of an exponential number of possibilities simultaneously with very
small number of hardware units, but also extend this unique characteristic to a
multidimensional space including spatial, temporal and frequency domains,
making it particularly effective for addressing NP-hard problems. The proposed
architecture has been validated through SPICE simulations, demonstrating its
potential capability in solving several NP-hard problems, such as the Number
Partitioning Problem, the 0/1 Knapsack Problem, and the Traveling Salesman
Problem.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [407] [peaks: a Python package for analysis of angle-resolved photoemission and related spectroscopies](https://arxiv.org/abs/2508.04803)
*Phil D. C. King,Brendan Edwards,Shu Mo,Tommaso Antonelli,Edgar Abarca Morales,Lewis Hart,Liam Trzaska*

Main category: cond-mat.mtrl-sci

TL;DR: peaks是一个用于ARPES数据分析的Python包，可以加速和简化对大量复杂光谱数据的处理和可视化。


<details>
  <summary>Details</summary>
Motivation: ARPES是研究电子带状结构的重要实验方法，但面临数据量大、结构复杂等挑战，需要高级的数据分析工具。

Method: 使用Python语言，提供GUI支持，便于交互式笔记本环境中的数据可视化和分析。

Result: peaks包能够快速可视化和分析多维ARPES数据集，支持复杂的数据层级结构，并优化了数据加载和处理的效率。facilitates the fast visualisation and analysis of multi-dimensional datasets, allows for the complex data hierarchy typical to ARPES experiments, and supports lazy data loading and parallel processing, reflecting the ever-increasing data volumes used in ARPES.

Conclusion: peaks是一个用于高级ARPES数据分析的Python包，它促进了多维数据集的快速可视化和分析，支持ARPES实验的数据层级结构，并能处理不断增长的数据量。

Abstract: The electronic band structure, describing the motion and interactions of
electrons in materials, dictates the electrical, optical, and thermodynamic
properties of solids. Angle-resolved photoemission spectroscopy (ARPES)
provides a direct experimental probe of such electronic band structures, and so
is widely employed in the study of functional, quantum, and 2D materials.
\texttt{peaks} (\textbf{P}ython \textbf{E}lectron spectroscopy
\textbf{A}nalysis by \textbf{K}ing group @ \textbf{S}t Andrews) provides a
Python package for advanced data analysis of ARPES and related spectroscopic
data. It facilitates the fast visualisation and analysis of multi-dimensional
datasets, allows for the complex data hierarchy typical to ARPES experiments,
and supports lazy data loading and parallel processing, reflecting the
ever-increasing data volumes used in ARPES. It is designed to be run in an
interactive notebook environment, with extensive inline and pop-out GUI support
for data visualisation.

</details>


### [408] [Engineering Phonons in Compositionally Complex Carbide Ceramics](https://arxiv.org/abs/2508.04812)
*Linu Malakkal,Jarin C French,Lanh Trinh,Kaustubh K Bawane,Shuxiang Zhou,Zilong Hua,Lingfeng He,Yongfeng Lu,Bai Cui*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过从头算和实验技术，探索了成分复合碳化物（CCCs）的声子性质。结果显示，虽然CCCs具有阳离子无序，但其热导率可以通过元素选择进行调控，甚至在某些情况下高于预期，这为开发用于极端环境的新型材料提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了开发具有优异抗辐照性和高温耐受性的先进陶瓷材料，用于核应用，成分复合碳化物（CCCs）作为在极端环境下具有潜力的候选材料出现。在这些极端条件下，热稳定性、弹性、热导率和热力学行为等关键材料性质主要受声子影响。CCCs中显著的阳离子无序会导致固有的质量和力常数变化，从而引起显著的声子散射，进而影响这些关键性质。

Method: 本研究采用从头算（ab initio）计算方法，预测了具有岩盐结构的CCCs的声子带结构，并系统地研究了质量和力常数变化对声子谱函数的影响，范围涵盖了从二元到五元金属成分的碳化物。此外，研究还利用空间域热反射技术（spatial-domain thermoreflectance）测量了部分CCCs的热导率。

Result: 研究预测了CCCs的声子带结构，并系统地探索了质量和力常数方差对声子谱函数的影响。研究发现，可以通过选择和浓度来调整CCCs的声子带结构、声子带隙和声子散射。实验测量结果显示，某些五元CCCs的热导率高于某些三元和二元合金，这与预期“更复杂的阳离子无序导致更强的声子散射和更低的热导率”相反。

Conclusion: 研究结果表明，可以通过选择和调整组成元素的种类与含量来优化成分复合碳化物（CCCs）的声子带结构、声子带隙及声子散射，从而调控其声子相关性质。实验测量结果显示，某些五元碳化物的热导率高于某些三元和二元合金，这与通常认为的“更复杂的阳离子无序会导致更强的声子散射和更低的热导率”的预期相反。这一发现为发现具有更高热导率的CCCs材料提供了新的可能性，为它们在极端环境下的应用开辟了新机遇。

Abstract: In the pursuit of advanced ceramic materials with exceptional
irradiation-resistance and high-temperature tolerance for nuclear applications,
compositionally complex carbides (CCCs) have emerged as a highly promising
class of candidate materials for extreme environments. In such conditions,
critical material properties such as thermal stability, elasticity, thermal
conductivity and thermodynamics behavior are predominantly influenced by
phonons. In CCCs, pronounced cation disorder can lead to significant phonon
scattering due to inherent mass and force constant variations, impacting these
critical properties. In this study, we used ab initio calculations to predict
the phonon band structures and systematically explore the influence of mass and
force constant variance on the phonon spectral function of CCCs with a rock
salt structure, ranging from binary to five-metal component carbides. Our
findings reveal that the selection and concentration of constituent elements
can be strategically utilized to tune the phonon band structure, phonon bandgap
and phonon scattering in CCCs, thereby enabling control over phonon-related
properties. Additionally, we measured the thermal conductivity of some of these
CCCs using the spatial-domain thermoreflectance technique. Interestingly, the
measured thermal conductivity of some of these CCCs indicates that
five-component ceramics exhibit higher thermal conductivity than certain
ternary and binary alloys. This observation contrasts with the expectation that
greater cation disorder would result in more scattering and lower thermal
conductivity. This intriguing result opens up the possibility of discovering
CCCs with better thermal conductivity, presenting new opportunities for their
application in extreme environments.

</details>


### [409] [Inverse Lieb Materials: Altermagnetism and More](https://arxiv.org/abs/2508.04839)
*Po-Hao Chang,Igor I. Mazin,Kirill D. Belashchenko*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过理论计算和实验比对，深入研究了逆型列开格（ILL）材料中的磁相，发现了d$^2-3$和d$^5$构型的交替磁性倾向，并确定了一种有潜力的交替磁性材料Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$。


<details>
  <summary>Details</summary>
Motivation: 逆型列开格（ILL）因其几何结构能够容纳复杂的磁有序，并具有磁性质的高度可调性，因此在交替磁性领域受到越来越多的关注。

Method: 研究结合了使用 Heisenberg 模型构建相图以阐明交替磁性背后的基本机制，以及使用密度泛函理论（DFT）计算来系统地研究一系列现有的逆型列开格（ILL）化合物的磁基态。

Result: 研究发现了与实验观察结果一致的计算结果，并确定了d$^2-3$和d$^5$电子构型倾向于表现出交替磁性的趋势。此外，还发现Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$是一种有潜力的交替磁性材料，并计算了其磁激发谱，发现其手性分裂与晶体学上不等价的J$_{2}$交换耦合之间的各向异性直接相关。

Conclusion: 该研究为识别逆型列开格（ILL）材料中的交替磁性材料提供了指导方针，并确定了Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$作为一种有潜力的交替磁性材料，其特点是具有高度各向异性的J$_{2}$交换耦合和较高的 Néel 温度。

Abstract: The Lieb lattice, originally proposed for cuprate superconductors, has gained
new attention in the emerging field of altermagnetism as a minimal analytical
model for the latter. While initially the so-called inverse Lieb lattice (ILL)
was deemed only a theoretical model, recently several real materials with this
crystallographic motif have been found. The unique geometry of ILL can
accommodate complex magnetic orderings arising from competing exchange
interactions and geometric frustration, offering great tunability for magnetic
properties. In this work, we provide comprehensive insights into magnetic
phases in ILL materials and establish guidelines for efficient identification
of altermagnetic materials within this family. We begin by constructing phase
diagrams using a simple Heisenberg model to elucidate the fundamental
mechanisms underlying altermagnetism and other complex magnetic phases observed
experimentally. To bridge theory with experiment, we systematically investigate
a series of existing ILL compounds using density functional theory (DFT)
calculations to determine their magnetic ground states. Our computational
results are in good agreement with experimental observations. Importantly, we
identify a trend linking magnetic ordering to the $d$-shell filling of
transition metal ions, with $d^{2-3}$ and $d^{5}$ configurations showing
propensity for altermagnetic behavior. Additionally, we identify a promising
metallic compound Sr$_{2}$CrO$_{2}$Cr$_{2}$OAs$_{2}$ as an altermagnet that is
highly anisotropic in its $J_2$ exchange couplings with large N\'eel
temperature ($\sim 600$ K). Using exchange coupling parameters extracted from
DFT calculations, we compute the magnon spectra for altermagnetic systems. As
expected, chiral splittings in the magnon dispersion are directly correlated
with anisotropy between crystallographically inequivalent $J_{2}$ exchange
interactions.

</details>


### [410] [Data Driven Insights into Composition Property Relationships in FCC High Entropy Alloys](https://arxiv.org/abs/2508.04841)
*Nicolas Flores,Daniel Salas Mula,Wenle Xu,Sahu Bibhu,Daniel Lewis,Alexandra Eve Salinas,Samantha Mitra,Raj Mahat,Surya R. Kalidindi,Justin Wilkerson,James Paramore,Ankit Srivastiva,George Pharr,Douglas Allaire,Ibrahim Karaman,Brady Butler,Vahid Attari,Raymundo Arroyave*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用编码器-解码器模型和贝叶斯优化，成功预测了高熵合金的机械性能，尤其在屈服强度和 UTS/YS 比方面表现优异，并揭示了关键元素的组成-性能关系。


<details>
  <summary>Details</summary>
Motivation: 为了克服高熵合金（HEAs）数据稀疏和设计空间广阔的挑战，本研究旨在开发能够从有限且异构的数据集中学习的先进方法，以进行预测性性能建模，并揭示其潜在模式。

Method: 本研究提出并评估了几种基于编码器-解码器的化学性质模型，并采用贝叶斯多目标超参数优化进行微调，以实现合金成分到六种机械性能的映射。此外，还进行了敏感性分析，以确定关键元素对机械行为的贡献。

Result: 所提出的模型在所有性能指标上均达到有竞争力的或优于传统回归器的性能，尤其在屈服强度和 UTS/YS 比方面表现突出，证明了其在捕捉复杂成分-性能关系方面的有效性。研究还通过敏感性分析，强调了关键元素对机械行为的贡献，并揭示了影响 NiCoFeCrVMnCuAl 系统数据中观察到的脆性和断裂响应的成分因素。

Conclusion: 该研究通过编码器-解码器模型和贝叶斯超参数优化，在表征高熵合金的组成-性能关系方面取得了有竞争力的甚至更优越的性能，特别是在屈服强度和 UTS/YS 比方面。

Abstract: Structural High Entropy Alloys (HEAs) are crucial in advancing technology
across various sectors, including aerospace, automotive, and defense
industries. However, the scarcity of integrated chemistry, process, structure,
and property data presents significant challenges for predictive property
modeling. Given the vast design space of these alloys, uncovering the
underlying patterns is essential yet difficult, requiring advanced methods
capable of learning from limited and heterogeneous datasets. This work presents
several sensitivity analyses, highlighting key elemental contributions to
mechanical behavior, including insights into the compositional factors
associated with brittle and fractured responses observed during nanoindentation
testing in the BIRDSHOT center NiCoFeCrVMnCuAl system dataset. Several encoder
decoder based chemistry property models, carefully tuned through Bayesian multi
objective hyperparameter optimization, are evaluated for mapping alloy
composition to six mechanical properties. The models achieve competitive or
superior performance to conventional regressors across all properties,
particularly for yield strength and the UTS/YS ratio, demonstrating their
effectiveness in capturing complex composition property relationships.

</details>


### [411] [Optimization of Ab-Initio Based Tight-Binding Models](https://arxiv.org/abs/2508.04861)
*Henrik Dick,Thomas Dahm*

Main category: cond-mat.mtrl-sci

TL;DR: 提出一种基于机器学习的优化方法，用于构建更精确、更简洁的紧束缚模型，以处理复杂的电子结构计算。


<details>
  <summary>Details</summary>
Motivation: 在界面、晶界或接触几何等复杂情况下，需要更简化的电子结构模型，而传统的紧束缚模型（如最大局域瓦讷函数）精度有限。

Method: 通过机器学习技术优化模型参数，以尽可能高的精度和尽可能少的模型参数来重现第一性原理能带结构数据。

Result: 所提出的方法能够生成比最大局域瓦讷函数具有更小范围和更少轨道的紧束缚模型，同时保持相当或更高的精度，并且更适用于自动化构建紧束缚模型，特别是在大规模材料计算中。

Conclusion: 该程序比最大局域瓦讷函数需要更少的轨道范围和更少的轨道，但精度相当或更高。

Abstract: The electronic structure of solids can routinely be calculated by standard
methods like density functional theory. However, in complicated situations like
interfaces, grain boundaries or contact geometries one needs to resort to more
simplified models of the electronic structure. Tight-binding models are using a
reduced set of orbitals and aim to approximate the electronic structure by
short range hopping processes. For example, maximally localized Wannier
functions are often used for that purpose. However, their accuracy is limited
by the need to disentangle the electronic bands. Here, we develop and
investigate a different procedure to obtain tight-binding models inspired by
machine-learning techniques. The model parameters are optimized in such a way
as to reproduce ab-initio band structure data as accurately as possible using
an as small as possible number of model parameters. The procedure is shown to
result in models with smaller ranges and fewer orbitals than maximally
localized Wannier functions but same or even better accuracy. We argue that
such a procedure is more useful for automated construction of tight-binding
models particularly for large-scale materials calculations.

</details>


### [412] [Pressure-induced decomposition of Bi14WO24](https://arxiv.org/abs/2508.05617)
*E. Karaca,D. Santamaria-Perez,A. Otero-de-la-Roza,R. Oliva,K. S. Rao,S. N. Achary,C. Popescu,D. Errandonea*

Main category: cond-mat.mtrl-sci

TL;DR: Bi14WO24 在 2.85 GPa 压力下会分解成 Bi2O3 和 WO3。


<details>
  <summary>Details</summary>
Motivation: 研究高压条件下 Bi14WO24 的行为，Bi14WO24 是 Bi2O3-WO3 二元系统中高氧化物离子导体。

Method: 使用同步加速器粉末 X 射线衍射在加压条件下研究了 Bi14WO24 的四方多晶型物，并确定了晶胞参数与压力的关系，进而推导出其线性和体积可压缩性。

Result: Bi14WO24 的体积模量为 49.8(2.6) GPa，线压缩系数 
k{appa}a 和 
k{appa}c 分别为 6.94(2) x 10^-3 GPa^-1 和 3.73(1) x 10^-3 GPa^-1。

Conclusion: Bi14WO24 在 2.85 GPa 左右发生不可逆的化学分解，生成 Bi2O3 和 WO3。该分解归因于系统密度的增加以适应压力引起的应力。

Abstract: We present a study of the high-pressure behaviour Bi14WO24, a high oxide ion
conductor member of the Bi2O3-WO3 binary system. The tetragonal polymorph of
Bi14WO24 was studied under high-pressure conditions using synchrotron powder
X-ray diffraction. It was found that in contrast to isostructural Bi14CrO24 and
Bi14MoO24 which experience a phase transition around 5 GPa, in our study
Bi14WO24 undergoes an irreversible chemical decomposition into Bi2O3 and WO3 at
2.85(5) GPa. The pressure dependence of the unit-cell parameters of Bi14WO24
was also determined, and hence the linear compressibility along different axes
and room-temperature pressure-volume equation of state were derived. Bulk
modulus of tetragonal Bi14WO24 was found to be 49.8(2.6) GPa, and the linear
compressibility of the two crystallographic axes, \k{appa}a and \k{appa}c were
6.94(2) 10-3 GPa-1 and = 3.73(1) 10-3 GPa-1, respectively. The pressure induced
decomposition can be attributed to the favourable increasing density of the
system to accommodate the pressure induced stress.

</details>


### [413] [SERS Raman detection of the CO$_2$ Moisture Swing](https://arxiv.org/abs/2508.04893)
*Javier Mendez-Lozoya,Estrella Solis Mata,J. Jesus Velazquez Salazar,Alondra Hernandez Cedillo,Miguel Jose Yacaman,Jennifer L. Wade*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The development of scalable, energy-efficient carbon dioxide capture
technologies is critical for achieving net-zero emissions. Moisture swing
sorbents offer a promising alternative to traditional thermal regeneration
methods by enabling reversible CO$_2$ binding through humidity-driven ion
hydrolysis. In this study, we investigate the anion speciation dynamics in two
classes of MS materials, an anion-exchange resin with bicarbonate anion and
activated carbon impregnated with potassium bicarbonate salt using both
sorption measurements and in situ surface-enhanced Raman spectroscopy. Ni
coated Ag nanowires were employed as SERS substrates to enhance signal
intensity and enable the real-time detection of carbonate , bicarbonate , and
hydroxide species under controlled humidity conditions in both air and nitrogen
atmospheres. The results reveal humidity-dependent interconversion between
anionic species, with significant spectral shifts confirming the reversible
hydrolysis reactions that drive the MS mechanism. Under humid conditions, we
observed the depletion of bicarbonate signals and a concurrent increase in
carbonate species, consistent with moisture-induced desorption of CO$_2$. These
findings not only validate the mechanistic models of humidity-driven anion
exchange in moisture swing sorbents but also demonstrate the practical
potential of SERS as an operando diagnostic tool for monitoring CO$_2$ capture
media. The ability to resolve and quantify the reversible transformation of
carbonate, bicarbonate, and hydroxide ions under realistic environmental
conditions provides valuable insight for the rational design, performance
optimization, and quality control of next-generation sorbent materials for
direct air capture applications.

</details>


### [414] [Intrinsic Layer-Dependent Surface Energy and Exfoliation Energy of van der Waals Materials](https://arxiv.org/abs/2508.04898)
*Lin-Lin Wang,Jiaqiang Yan,Yong Han,Claire C. Wang,Jian-Xiang Qiu,Su-Yang Xu,Adam Kaminski,Michael C. Tringides,Paul C. Canfield*

Main category: cond-mat.mtrl-sci

TL;DR: Exfoliation effectiveness of vdW materials depends on how surface energy changes with atomic layers within a single vdW layer.


<details>
  <summary>Details</summary>
Motivation: Stacking and twisting 2D van der Waals (vdW) layers are crucial for tuning electron correlation, but exfoliation effectiveness varies.

Method: Density functional theory calculations were used to determine the intrinsic layer-dependent surface and exfoliation energies of various van der Waals materials.

Result: A single vdW layer consistently shows the lowest surface energy compared to thicker layers, with the reduction magnitude varying based on the material's atomic structure.

Conclusion: The study explains the varying effectiveness of exfoliating different van der Waals materials down to a single layer, based on the atomic layer-dependence of surface energy reduction.

Abstract: Stacking and twisting 2D van der Waals (vdW) layers have become versatile
platforms to tune electron correlation. These platforms rely on exfoliating vdW
materials down to a single and few vdW layers. We calculate the intrinsic
layer-dependent surface and exfoliation energies of typical vdW materials such
as, graphite, h-BN, black P, MX$_2$ (M=Mo and W, X=S, Se and Te), MX (M=Ga and
In, X=S, Se and Te), Bi$_2$Te$_3$ and MnBi$_2$Te$_4$ using density functional
theory. For exchange-correlation functionals with explicit vdW interaction, a
single vdW layer always has the smallest surface energy, giving a surface
energy reduction when compared to thicker vdW layers. However, the magnitude of
this surface energy reduction quickly decreases with increasing number of
atomic layers inside the single vdW layer for different vdW materials. Such
atomic-layer-dependence in surface energy reduction helps explain the different
effectiveness of exfoliation for different vdW materials down to a single vdW
layer.

</details>


### [415] [Magnetic Anisotropy in Two-dimensional van der Waals Magnetic Materials and Their Heterostructures: Importance, Mechanisms, and Opportunities](https://arxiv.org/abs/2508.04952)
*Yusheng Hou,Ruqian Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 该综述全面概述了磁各向异性在二维磁性材料中的作用，重点介绍了其在克服热涨落方面的作用以及通过各种工程技术进行调整的可能性，旨在推动室温应用。


<details>
  <summary>Details</summary>
Motivation: 二维范德瓦尔斯单分子层和异质结构中的二维磁性因其在下一代自旋电子学和量子技术中有潜力而备受关注。

Method: 对稳定二维磁性中的磁各向异性至关重要，以克服梅森-瓦格纳定理的限制。本文献综述了磁各向异性在实现内在二维磁性以及塑造二维范德瓦尔斯材料的电子、磁和拓扑特性方面的重要性，重点介绍了其理论和实验概述。

Result: 文献综述了磁各向异性的基本机制，强调了强配体自旋-轨道耦合和未淬灭的轨道磁矩的贡献。文献还考察了合金化、掺杂、静电门控、应变和压力等材料工程方法，这些方法已被用来有效地调整这些材料中的磁各向异性。

Conclusion: 该综述旨在通过提供磁各向异性在二维磁性中的作用的广泛视角，激发在基于二维范德瓦尔斯磁性材料及其异质结构实现稳健的室温应用方面的持续努力和新想法。

Abstract: Two-dimensional (2D) magnetism in atomically thin van der Waals (vdW)
monolayers and heterostructures has attracted significant attention due to its
promising potential for next-generation spintronic and quantum technologies. A
key factor in stabilizing long-range magnetic order in these systems is
magnetic anisotropy, which plays a crucial role in overcoming the limitations
imposed by the Mermin-Wagner theorem. This review provides a comprehensive
theoretical and experimental overview of the importance of magnetic anisotropy
in enabling intrinsic 2D magnetism and shaping the electronic, magnetic, and
topological properties of 2D vdW materials. We begin by summarizing the
fundamental mechanisms that determine magnetic anisotropy, emphasizing the
contributions from strong ligand spin-orbit coupling of ligand atoms and
unquenched orbital magnetic moments. We then examine a range of material
engineering approaches, including alloying, doping, electrostatic gating,
strain, and pressure, that have been employed to effectively tune magnetic
anisotropy in these materials. Finally, we discuss open challenges and
promising future directions in this rapidly advancing field. By presenting a
broad perspective on the role of magnetic anisotropy in 2D magnetism, this
review aims to stimulate ongoing efforts and new ideas toward the realization
of robust, room-temperature applications based on 2D vdW magnetic materials and
their heterostructures.

</details>


### [416] [Alpha-, Beta-, and Gamma-TODD-G: Novel 2D Planar Carbon Allotropes](https://arxiv.org/abs/2508.05013)
*Kleuton A. L. Lima,Jose A. S. Laranjeira,Alysson M. A. Silva,Bill. D. Aparicio-Huacarpuma,Fabrício M. Vasconcelos,Julio R. Sambrano,Douglas S. Galvão,Luiz A. Ribeiro Junior*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过第一性原理计算，发现了三种新型二维碳材料（alpha-、beta-和gamma-TODD-G），它们具有良好的稳定性、金属性质、可调的力学各向异性以及独特的光学特性，有望应用于电子和光电子领域。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索和理解三种新型二维碳同素异形体（alpha-、beta-和gamma-TODD-G）的结构、稳定性、电子、力学和光学性质，为新型碳基材料的开发提供理论依据。

Method: 本研究采用了第一性原理计算方法，包括结构优化、声子谱分析和从头算分子动力学模拟，并结合了力学和光学性质分析。

Result: 研究发现alpha-、beta-和gamma-TODD-G具有良好的热稳定性和动力学稳定性，均为金属性，并具有独特的狄拉克特征和倾斜的狄拉克锥，预示着各向异性的电荷传输。力学性质方面，alpha-TODD-G表现出强各向异性，beta-TODD-G表现出中等各向异性，gamma-TODD-G则表现出近乎各向同性的力学响应。光学性质上，gamma-TODD-G在红外区域有强吸收，而alpha-和beta-TODD-G主要在可见光和紫外区域吸收。

Conclusion: 三种新型二维碳同素异形体（alpha-、beta-和gamma-TODD-G）均表现出良好的热稳定性和动力学稳定性，并具有金属性质。它们展现出可调的各向异性以及独特的光学特性，这为未来的电子和光电子器件设计提供了新的可能性。

Abstract: We present a comprehensive first-principles investigation of three novel
two-dimensional carbon allotropes: alpha-, beta-, and gamma-TODD-Graphene
(TODD-G), composed of 3-8-12-16, 3-8-12-16, and 3-4-8-12 interconnected carbon
rings with sp/sp2 hybridization, respectively. Structural optimization, phonon
spectra, and ab initio molecular dynamics simulations confirm their thermal and
dynamical stability. All phases exhibit metallic electronic behavior, with
distinct Dirac-like features and tilted Dirac cones that suggest anisotropic
charge transport. Mechanical analysis reveals tunable anisotropy: alpha-TODD-G
is strongly anisotropic, beta-TODD-G shows moderate anisotropy, and
gamma-TODD-G displays an almost isotropic mechanical response. Optical spectra
further differentiate the phases, with gamma-TODD-G showing strong absorption
in the infrared region, while alpha- and beta-TODD-G mainly absorb in the
visible and ultraviolet ranges.

</details>


### [417] [Rotational-Mode-Enhanced Piezoelectricity in a Ferroelectric Double Helix](https://arxiv.org/abs/2508.05017)
*Yihao Hu,Shi Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 使用第一性原理计算，首次发现了一种在应变PbTiO3中存在的手性、非共线的铁电双螺旋结构。该结构由相互缠绕的Pb和Ti亚晶格构成，并由扭曲的氧八面体框架稳定。这种“自莫尔”晶体同时具有巨大的压电响应（e33≈16 C/m^2）和在价带边缘出现的多谷电子拓扑。


<details>
  <summary>Details</summary>
Motivation: 揭示了应变下悬空膜中“偶极螺旋”结构的存在，并探索了其微观性质、能量景观和电子效应。

Method: 使用对PbTiO3在双轴拉伸应变下的第一性原理计算。

Result: 发现了一种新颖的极性有序形式：一种手性、非共线的铁电双螺旋。Pb和Ti阳离子亚晶格形成了两个独特的、相互缠绕的螺旋。该结构具有两种耦合的功能：一种是驱动巨大压电响应（e33≈16 C/m^2）的旋转赝零能量模式；二是螺旋的长期势能从根本上重构了电子能带结构，在价带边缘产生了新的多谷电子拓扑。

Conclusion: 这项工作建立了一种强大的、纯粹物理的方法来设计复杂的手性阶序，并提供了一个统一的平台，其中结构拓扑、巨大的机电耦合和多谷电子学内在联系在一起。

Abstract: Recent theoretical work has predicted the existence of a ``dipole spiral"
structure in strained freestanding membranes, promising a route to giant
electromechanical
responses[\href{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.133.046802}{PRL
\textbf{133}, 046802 (2024)}]. However, its microscopic nature, energetic
landscape, and electronic consequences remain largely unexplored. Here, using
first-principles calculations on PbTiO$_3$ under biaxial tensile strain, we
unveil a novel form of polar order: a chiral, non-collinear ferroelectric
double helix. We find that the Pb- and Ti-cation sublattices form two distinct,
intertwined helices, reminiscent of DNA. This intricate topology is stabilized
by a collective helical twisting of the oxygen octahedral framework, which
mediates an emergent electric Dzyaloshinskii-Moriya interaction.This unique
structure, conceptualized as a ``self-Moir\'e" crystal, manifests two coupled
functionalities. First, it possesses a rotational pseudo-zero-energy mode that
underpins a giant piezoelectric response ($e_{33}\approx$16 C/m$^2$). Second,
the spiral's long-period potential fundamentally reconstructs the electronic
band structure, leading to an emergent multi-valley electronic topology at the
valence band edge. Our work establishes a powerful, purely physical route to
designing complex chiral order and provides a unified platform where structural
topology, giant electromechanical coupling, and multi-valley electronics are
intrinsically linked.

</details>


### [418] [Many-body perturbation theory vs. density functional theory: A systematic benchmark for band gaps of solids](https://arxiv.org/abs/2508.05247)
*Max Großmann,Marc Thieme,Malte Grunert,Erich Runge*

Main category: cond-mat.mtrl-sci

TL;DR: 在固体带隙计算中，QS$G\hat{W}$的精度最高，甚至优于实验测量。


<details>
  <summary>Details</summary>
Motivation: DFT在固体带隙计算中表现不佳，需要测试GW的计算精度。

Method: 本文基准测试了许多体微扰理论与密度泛函理论（DFT）在固体带隙上的表现。系统地比较了四种GW变体：使用Godby-Needs等离子体极点模型（PPA）的$G_{0}W_{0}$（$G_{0}W_{0}$-PPA）、全频准粒子$G_{0}W_{0}$（QP$G_{0}W_{0}$）、全频准粒子自洽$GW$（QS$GW$）以及在W中加入顶点校正的QS$GW$（QS$G\hat{W}$），并与目前表现最好和最流行的密度泛函mBJ和HSE06进行了比较。

Result: $G_{0}W_{0}$-PPA计算的精度提升有限，但成本更高。使用全频积分代替PPA可以极大提高预测精度，接近QS$G\hat{W}$的精度。QS$GW$消除了起始点偏差，但系统地高估了实验间隙约15%。在W中加入顶点校正的QS$G\hat{W}$消除了高估现象。

Conclusion: QS$G\hat{W}$的计算结果是准确的，甚至可以可靠地标记有问题的实验测量结果。

Abstract: We benchmark many-body perturbation theory against density functional theory
(DFT) for the band gaps of solids. We systematically compare four $GW$ variants
$-$ $G_{0}W_{0}$ using the Godby-Needs plasmon-pole approximation
($G_{0}W_{0}$-PPA), full-frequency quasiparticle $G_{0}W_{0}$ (QP$G_{0}W_{0}$),
full-frequency quasiparticle self-consistent $GW$ (QS$GW$), and QS$GW$
augmented with vertex corrections in $W$ (QS$G\hat{W}$) $-$ against the
currently best performing and popular density functionals mBJ and HSE06. Our
results show that $G_{0}W_{0}$-PPA calculations offer only a marginal accuracy
gain over the best DFT methods, however at a higher cost. Replacing the PPA
with a full-frequency integration of the dielectric screening improves the
predictions dramatically, almost matching the accuracy of the QS$G\hat{W}$. The
QS$GW$ removes starting-point bias, but systematically overestimates
experimental gaps by about $15\%$. Adding vertex corrections to the screened
Coulomb interaction, i.e., performing a QS$G\hat{W}$ calculation, eliminates
the overestimation, producing band gaps that are so accurate that they even
reliably flag questionable experimental measurements.

</details>


### [419] [Enhanced spin-to-charge conversion in La$_{0.67}$Sr$_{0.33}$MnO$_3$/NdNiO$_3$ bilayers at the nickelate metal-insulator phase transition](https://arxiv.org/abs/2508.05300)
*Biswajit Sahoo,Sarmistha Das,Akilan K,Alexandre Pofelski,Sebastien Petit-Watelot,Juan-Carlos Rojas-Sánchez,Yimei Zhu,Alex Frano,Eric E Fullerton*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究探索了LSMO/NNO氧化物双层薄膜中的自旋到电荷转换，发现在NNO经历相变时，逆自旋霍尔效应信号增强，为开发节能自旋电子器件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探索相变材料（如NNO）与低阻尼铁磁材料（如LSMO）耦合产生的多功能材料系统，利用电荷、自旋和轨道自由度的相互作用。

Method: 利用自旋抽运铁磁共振技术，研究了外延型LSMO/NNO双层薄膜（NNO厚度分别为4、8和16 nm）中自旋到电荷的转换。通过跟踪NNO层在顺磁金属到反铁磁绝缘体转变过程中信号的变化来研究自旋电荷转换。

Result: 在NNO层中观察到，随着材料经历由顺磁金属到反铁磁绝缘体的相变，逆自旋霍尔效应信号在相变开始时出现显著增强，并将其归因于NNO在第一类相变过程中的电子和磁性无序。

Conclusion: 该研究通过自旋抽运铁磁共振技术，在氧化物双层薄膜中实现了自旋到电荷的转换，并通过分析NNO层在顺磁金属到反铁磁绝缘体相变过程中的信号变化，发现了在相变开始时逆自旋霍尔效应信号的显著增强，这为开发多功能、节能的自旋电子器件提供了新途径。

Abstract: Phase transition materials such as NdNiO3 (NNO) when coupled with low damping
ferromagnets such as La$_{0.67}$Sr$_{0.33}$MnO$_3$ (LSMO) can lead to new
multi-functional material systems harnessing the interplay of charge, spin and
orbital degrees of freedom. In this study, we probe the evolution of the
spin-to-charge conversion in epitaxial all-oxide LSMO (12 nm)/NNO (4, 8, and 16
nm) bilayers. Using spin pumping ferromagnetic resonance we track the
spin-charge conversion in the NNO layer through the paramagnetic metal to
antiferromagnetic insulator transition and observe a pronounced enhancement of
the inverse spin Hall effect signal at the onset of this transition. We
attribute this enhancement to the electronic and magnetic disorder in NNO at
the first-order phase transition, thereby providing insights into the mechanism
of spin transport through the phase transition. The tunability of spin charge
conversion in this low damping bilayer system offers a pathway for developing
multifunctional, energy-efficient spintronic devices.

</details>


### [420] [Stranski-Krastanov Growth of Disordered ScNx Thin Films on MgO(100): Influence of Defect Densities on Electronic Structure and Transport Properties](https://arxiv.org/abs/2508.05330)
*Susmita Chowdhury,Rachana Gupta,Najnin Bano,Yogesh Kumar,Shashi Prakash,Dinesh Kumar Shukla,Vasant G. Sathe,Mukul Gupta*

Main category: cond-mat.mtrl-sci

TL;DR: 在 MgO(100) 上外延生长 ScNx 薄膜，研究了衬底温度对薄膜生长、结构和性质的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在不同衬底温度下，氮化钪 (ScNx) 薄膜的生长动力学、结构演变及其对光学和电学性质的影响。

Method: 通过反应溅射在 MgO(100) 上外延生长 ScNx 薄膜，并进行原位 RHEED 和拉曼光谱分析。

Result: 在 25°C 时，外延生长仅限于 5 nm；在 250°C 和 500°C 时，外延生长可达 25 nm；在 700°C 时，出现氮缺陷的六方 Sc-N 相。

Conclusion: 氧原子间隙和氮空位是导致 ScNx 系统无序、弱局域化效应以及拉曼弛豫的随机一阶横向和纵向光学声子模式的原因。

Abstract: We report a nascent real time Stranski-Krastanov growth of reactively
sputtered ScNx thin films on MgO(100). The epitaxial growth was limited to 5 nm
at a substrate temperature (Ts) of 25 C while the self-sustaining epitaxial
nature along the [100] azimuth was retained up to 25 nm in Ts = 250 and 500 C
samples due to enhanced adatom mobility. At Ts = 700 C, the film showed half
order in-situ RHEED pattern, with forbidden (hkl) planes indicating N deficient
hcp Sc-N phase. Presence of defect densities i.e., N vacancies and O
interstitials leads to a disorder in ScNx system with weak localization effect
and appearance of Raman relaxed first order transverse and longitudinal optical
phonon modes and further leads to metal like Seebeck coefficient. Higher grain
boundaries at Ts = 25 C and higher N out-diffusion at Ts = 700 C paves way for
incorporation of higher oxygen interstitial in these samples.

</details>


### [421] [Hole-doping reduces the coercive field in ferroelectric hafnia](https://arxiv.org/abs/2508.05345)
*Pravan Omprakash,Gwan Yeong Jung,Guodong Ren,Rohan Mishra*

Main category: cond-mat.mtrl-sci

TL;DR: Hole doping reduces the coercive field in ferroelectric hafnia by altering polarization switching pathways, making it more suitable for next-generation memory and logic applications.


<details>
  <summary>Details</summary>
Motivation: The high coercive field required for polarization switching in hafnia is a critical challenge for efficient device operations.

Method: First-principles calculations and phenomenological modeling.

Result: Hole doping can reduce the coercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with 0.2 holes per formula unit (f.u.). The energy barrier for switching through the Pbcm phase is reduced from 180 meV/f.u. in undoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.

Conclusion: Hole doping makes hafnia a proper ferroelectric with a lower coercive field by making the switching pathway through the Pbcm phase competitive.

Abstract: Ferroelectric hafnia holds promise for next-generation memory and logic
applications because of its CMOS compatibility. However, the high coercive
field required for polarization switching in hafnia remains a critical
challenge for efficient device operations. Using first-principles calculations
and phenomenological modeling, we predict that hole doping can reduce the
coercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with
0.2 holes per formula unit (f.u.). In the absence of doping, the reversal of
polarization of the Pca21 phase is preferred through the non-polar, tetragonal
P42/nmc phase. This switching pathway involves the coupling of three hard
distortion modes that render undoped hafnia as an improper ferroelectric. The
overall energy barrier through this pathway remains unchanged (80 meV/f.u.)
upon hole doping. However, the introduction of holes hardens the polar
distortion mode that connects the polar Pca21 phase to the non-polar,
orthorhombic Pbcm phase, and reduces the energy barrier from 180 meV/f.u. in
undoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.. Overall, hole doping makes the
latter switching pathway through the Pbcm phase competitive, and renders hafnia
as a proper ferroelectric with a lower coercive field.

</details>


### [422] [Single-shot optical precessional magnetization switching of Pt/Co/Pt ferromagnetic trilayers](https://arxiv.org/abs/2508.05460)
*Rui Xu,Chen Xiao,Xiangyu Zheng,Renyou Xu,Xiaobai Ning,Tianyi Zhu,Dinghao Ma,Kangning Xu,Fei Xu,Youguang Zhang,Boyu Zhang,Jiaqi Wei*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过飞秒激光和磁场实现了Pt/Co/Pt三层结构中的超快磁化开关，并引入Cu层加速各向异性场重构，通过微磁模拟发现热激子各向异性扭矩是关键因素，为开发光磁存储器提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 为了克服Gd基材料在存储应用中磁矩较弱的缺点，探索在Pt/Co/Pt铁磁三层结构中实现超快磁化开关。

Method: 通过引入Cu层加速各向异性场重构时间，并利用微磁模拟研究了热激子各向异性扭矩对磁化开关的影响。

Result: 成功在Pt/Co/Pt铁磁三层结构中，通过单个飞秒激光脉冲和面内磁场实现了特定激光功率窗口内的磁化开关，并观察到由于Cu层引入而产生的靶心状磁畴翻转模式。

Conclusion: 本研究表明，单发光学旋进磁化反转在更广泛的材料中是可行的，为开发光磁存储器开辟了道路。

Abstract: Ultra-fast magnetization switching triggered by a single femtosecond laser
pulse has gained significant attention over the last decade for its potential
in low-power consumption, high-speed memory applications. However, this
phenomenon has been primarily observed in Gd-based ferrimagnetic materials,
which are unsuitable for storage due to their weak perpendicular magnetic
anisotropy (PMA). In this work, we demonstrated that applying a single laser
pulse and an in-plane magnetic field can facilitate magnetic switching in a
Pt/Co/Pt ferromagnetic trilayers stack within a specific laser power window. To
further understand this phenomenon, we introduce a Cu layer to accelerates the
re-establishment time of the anisotropy field of Pt/Co/Pt trilayers, which
leads to bullseye-patterned magnetic switching. We have mapped state diagrams
for these phenomena, and through micromagnetic simulations, we have determined
that these switchings are influenced by thermal anisotropy torque, which can be
modulated through PMA. These findings indicate that single-shot optical
precessional magnetization reversal is feasible in a broader range of
materials, opening avenues for the development of optical-magnetic memory
devices.

</details>


### [423] [Ta2Pd3Te8: A potential candidate of 1D van der Waals stacked thermoelectric materials](https://arxiv.org/abs/2508.05549)
*Shi Chen,Aijun Hong,Junming Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过计算方法预测了一维范德华力堆叠的 Ta2Pd3Te8 晶体具有优良的热电性能，并提出了提高其性能的途径，为相关领域的研究和实验提供了参考。


<details>
  <summary>Details</summary>
Motivation: 发现新的热电材料是热电领域的永恒目标。尽管 3D 和 2D 堆叠材料得到了广泛研究，但一维堆叠材料因其数量稀少而受到关注较少。

Method: 通过结合第一性原理计算、声子和电子玻尔兹曼输运方程以及分子动力学方法，预测一维范德华力堆叠的 Ta2Pd3Te8 晶体是一种有前途的热电候选材料。

Result: 研究发现 Ta2Pd3Te8 晶体具有机械、动力学和热稳定性，并且其热电性质表现出强各向异性、高功率因子 (PF) 和低晶格热导率。预测的 ZT 值在 900 K 下，n 型 Ta2Pd3Te8 沿 a、b 和 c 轴分别为 0.48、0.39 和 0.22。通过增大带隙来减弱双极效应，ZT 值可以提高到 1.11。

Conclusion: 这项工作不仅促进了对一维范德华力堆叠热电材料的更多理论研究，还为实验上改进热电材料提供了有价值的信息。

Abstract: Discovering new thermoelectric (TE) materials is an eternal goal in the TE
field. Excellent TE materials have ranged from 3D stacked to 2D stacked bulk.
However, the 1D stacked receives little attention due to the scarcity in
quantity. In this work, it is predicted that 1D van der Waals (vdW) stacked
Ta2Pd3Te8 crystal is a compelling candidate for TE applications by combining
first-principles calculations with phonon and electron Boltzmann transport
equations and molecular dynamics methods. We find that Ta2Pd3Te8 crystal has
mechanical, dynamical, and thermal stabilities, and its TE properties are
featured by strong anisotropy, high power factor (PF) and low lattice thermal
conductivity. The results indicate the ZT values of n-type Ta2Pd3Te8 at 900 K
along a, b and c axes reach 0.48, 0.39 and 0.22, respectively. We propose that
enlarging the bandgap can weaken the bipolar effect and thus significantly
increases ZT to 1.11. The findings in the work not only stimulate more
theoretical works on 1D vdW stacked TE materials, but also provide valuable
information for experimentally improving TE materials.

</details>


### [424] [Unveiling the Lithium-Ion Transport Mechanism in Li2ZrCl6 Solid-State Electrolyte via Deep Learning-Accelerated Molecular Dynamics Simulations](https://arxiv.org/abs/2508.05598)
*Hanzeng Guo,Volodymyr Koverga,Selva Chandrasekaran Selvaraj,Anh T. Ngo*

Main category: cond-mat.mtrl-sci

TL;DR: LZCs是成本效益高的固态电解质。通过深度学习加速分子动力学模拟，研究了Li2ZrCl6（α-和β-LZO）的离子传输。发现非晶态α-LZO具有最高的离子电导率，这是由于其疏松的锆原子排列和较低的层间跳跃势垒。β-LZO的离子电导率较低，主要受层内扩散控制。


<details>
  <summary>Details</summary>
Motivation: 锂锆氯化物（LZCs）作为一类有潜力的固态电解质，其独特的晶体结构对锂离子迁移至关重要，为了理解控制离子传输的潜在机制，需要进行深入研究。

Method: 通过深度学习加速的分子动力学模拟，重点关注锆的配位环境，研究了Li2ZrCl6（包括α-和β-LZO）的锂离子传输机制。

Result: 非晶态α-LZO相的离子电导率最高，而β-LZO相的离子电导率显著较低。α-LZO相的锂离子动力学表现出显著的集体扩散和层间传输，而β-LZO相的锂离子迁移则主要由各向同性的平移运动和层内扩散决定。 LZCs的局部结构组织证实，锆的特定排列会产生不同的离子通道能量势垒，从而影响动态行为。在α-LZO相中，层间跳跃势垒低于层内跳跃势垒，而在β-LZO相中，则相反，导致离子迁移速率较慢。

Conclusion: 非晶态α-LZO相表现出最高的离子电导率，而β-LZO相的电导率则显著较低，这与实验结果高度一致。研究结果表明，α-LZO相的锂离子传输主要由各向异性的层间传输驱动，而β-LZO相的锂离子迁移则受各向同性的平移运动和层内扩散控制。两种物相的锂迁移均通过位点跳跃机制进行，而位点停留时间的变化是影响整体离子电导率的关键因素。特别是，α-LZO相的层间跳跃势垒低于层内跳跃势垒，有利于更快的离子传输，其中非晶态α-LZO相的低势垒和高电导率是由于其疏松的锆原子排列。

Abstract: Lithium zirconium chlorides (LZCs) present a promising class of
cost-effective solid electrolyte for next-generation all-solid-state batteries.
The unique crystal structure of LZCs plays a crucial role in facilitating
lithium-ion mobility, which is central to their electrochemical performance. To
understand the underlying mechanism governing ion transport, we employed deep
learning-accelerated molecular dynamics simulation on Li2ZrCl6 (trigonal
{\alpha}- and monoclinic \b{eta}-LZC), focusing specifically on the zirconium
coordination environment. Our results reveal that disordered {\alpha}-LZC
exhibits the highest ionic conductivity, while \b{eta}-LZC demonstrates
significantly lower conductivity, closely aligning with experimental findings.
Detailed analysis shows substantial differences in lithium-ion dynamics:
{\alpha}-LZC phases display pronounced collective diffusion driven anisotropic
interlayer transport, whereas lithium mobility in \b{eta}-LZC is largely
determined by isotropic translations and individual diffusion dominated by
intralayer migration. Across all phases, lithium migration proceeds via
site-to-site hopping mechanism, where variations in site residence times
critically impact the overall ionic conductivity. Local structure organizations
analysis confirms that particular zirconium arrangements in LZC phases create
varied ion channel energy barriers, influencing dynamic behaviors: In
{\alpha}-LZC phases, the interlayer hopping barrier is lower than the
intralayer barrier, facilitating faster ion transport. Disordered {\alpha}-LZC,
with its loose zirconium arrangement, presents the lowest energy barrier,
enhancing conductivity. Conversely, \b{eta}-LZC features a higher overall
barrier, with intralayer hopping favored over interlayer, resulting in slower
ion migration.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [425] [Probabilistic Alternating Simulations for Policy Synthesis in Uncertain Stochastic Dynamical Systems](https://arxiv.org/abs/2508.05062)
*Thom Badings,Alessandro Abate*

Main category: eess.SY

TL;DR: 为同时存在随机和非确定性扰动的系统扩展了概率模拟关系，用于策略合成。


<details>
  <summary>Details</summary>
Motivation: 现有的基于有限状态抽象（如马尔可夫决策过程）的形式化策略合成方法，在处理同时存在随机和非确定性（集合值）扰动的系统时，依赖的概率模拟关系不足以保证正确性。

Method: 提出了一种受交替模拟启发的概率模拟关系，能够对随机不确定性进行概率推理，并对非确定性扰动进行鲁棒（对抗性）推理。

Result: 成功将概率模拟关系扩展到同时受随机和非确定性扰动的系统，并验证了其在4D状态Dubins车辆策略合成中的有效性。

Conclusion: 本文将概率模拟关系扩展到同时受随机和非确定性扰动的系统，并实验证明了该关系在4D状态Dubins车辆的策略合成中的适用性。

Abstract: A classical approach to formal policy synthesis in stochastic dynamical
systems is to construct a finite-state abstraction, often represented as a
Markov decision process (MDP). The correctness of these approaches hinges on a
behavioural relation between the dynamical system and its abstraction, such as
a probabilistic simulation relation. However, probabilistic simulation
relations do not suffice when the system dynamics are, next to being
stochastic, also subject to nondeterministic (i.e., set-valued) disturbances.
In this work, we extend probabilistic simulation relations to systems with both
stochastic and nondeterministic disturbances. Our relation, which is inspired
by a notion of alternating simulation, generalises existing relations used for
verification and policy synthesis used in several works. Intuitively, our
relation allows reasoning probabilistically over stochastic uncertainty, while
reasoning robustly (i.e., adversarially) over nondeterministic disturbances. We
experimentally demonstrate the applicability of our relations for policy
synthesis in a 4D-state Dubins vehicle.

</details>


### [426] [Linear Program-Based Stability Conditions for Nonlinear Autonomous Systems](https://arxiv.org/abs/2508.04871)
*Sadredin Hokmi,Mohammad Khajenejad*

Main category: eess.SY

TL;DR: 通过使用LP条件替代SDP技术，该研究提出了一种更有效的方法来评估非线性系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了降低计算成本，包括高维系统的时间和内存使用量。

Method: 该方法利用间接Lyapunov方法和通过雅可比矩阵线性化系统动力学，用计算效率高的线性规划（LP）条件替代了传统半定规划（SDP）技术。

Result: 所提出的稳定性标准通过矩阵变换和利用系统的结构特性来开发，提高了可扩展性。与现有的基于SDP的标准相比，所提出的方法在计算效率方面得到了证明，特别是在处理高维系统时。

Conclusion: 该研究提出了一种评估连续时间和离散时间非线性自治系统平衡点渐近稳定性}的新方法。

Abstract: This paper introduces a novel approach to evaluating the asymptotic stability
of equilibrium points in both continuous-time (CT) and discrete-time (DT)
nonlinear autonomous systems. By utilizing indirect Lyapunov methods and
linearizing system dynamics through Jacobian matrices, the methodology replaces
traditional semi-definite programming (SDP) techniques with computationally
efficient linear programming (LP) conditions. This substitution substantially
lowers the computational burden, including time and memory usage, particularly
for high-dimensional systems. The stability criteria are developed using matrix
transformations and leveraging the structural characteristics of the system,
improving scalability. Several examples demonstrated the computational
efficiency of the proposed approach compared to the existing SDP-based
criteria, particularly for high-dimensional systems.

</details>


### [427] [Sequence Aware SAC Control for Engine Fuel Consumption Optimization in Electrified Powertrain](https://arxiv.org/abs/2508.04874)
*Wafeeq Jaleel,Md Ragib Rownak,Athar Hanif,Sidra Ghayour Bhatti,Qadeer Ahmed*

Main category: eess.SY

TL;DR: A new RL framework using SAC with GRUs and DTs optimizes HEV engine control, significantly reducing fuel consumption and showing strong generalization on diverse driving conditions.


<details>
  <summary>Details</summary>
Motivation: To improve energy management in heavy-duty HEVs for reduced fuel consumption and sustained battery charge during long operations, addressing the critical need for adaptive and efficient control.

Method: A reinforcement learning (RL) framework using the Soft Actor-Critic (SAC) algorithm is proposed. The framework incorporates Gated Recurrent Units (GRUs) and Decision Transformers (DTs) into actor and critic networks to optimize engine control in series HEVs.

Result: The SAC agent with a DT-based actor and GRU-based critic achieved 1.8% of DP fuel savings on HFET, outperforming GRU-based (3.16%) and FFN-based (3.43%) agents. Sequence-aware agents showed better generalization and robustness on unseen drive cycles (US06, HHDDT) compared to FFN-based agents.

Conclusion: The proposed RL framework enhances engine control in series HEVs, with the DT-based actor and GRU-based critic achieving near-optimal fuel savings compared to DP and outperforming FFN-based agents on unseen drive cycles.

Abstract: As hybrid electric vehicles (HEVs) gain traction in heavy-duty trucks,
adaptive and efficient energy management is critical for reducing fuel
consumption while maintaining battery charge for long operation times. We
present a new reinforcement learning (RL) framework based on the Soft
Actor-Critic (SAC) algorithm to optimize engine control in series HEVs. We
reformulate the control task as a sequential decision-making problem and
enhance SAC by incorporating Gated Recurrent Units (GRUs) and Decision
Transformers (DTs) into both actor and critic networks to capture temporal
dependencies and improve planning over time. To evaluate robustness and
generalization, we train the models under diverse initial battery states, drive
cycle durations, power demands, and input sequence lengths. Experiments show
that the SAC agent with a DT-based actor and GRU-based critic was within 1.8%
of Dynamic Programming (DP) in fuel savings on the Highway Fuel Economy Test
(HFET) cycle, while the SAC agent with GRUs in both actor and critic networks,
and FFN actor-critic agent were within 3.16% and 3.43%, respectively. On unseen
drive cycles (US06 and Heavy Heavy-Duty Diesel Truck (HHDDT) cruise segment),
generalized sequence-aware agents consistently outperformed feedforward network
(FFN)-based agents, highlighting their adaptability and robustness in
real-world settings.

</details>


### [428] [Uncovering the Influence Flow Model of Transistor Amplifiers, Its Reconstruction and Application](https://arxiv.org/abs/2508.04977)
*Mohammed Tuhin Rana,Mishfad Shaikh Veedu,Murti V. Salapaka*

Main category: eess.SY

TL;DR: 本研究提出了一种将多级晶体管放大器建模为线性动态影响模型（LDIM）的方法，并利用电压时间序列数据重建放大器级之间的相互作用网络，可用于故障诊断和电路分析。


<details>
  <summary>Details</summary>
Motivation: 为了有效模拟相互作用并进行故障诊断，需要一种能够表征放大器级相互作用的模型。

Method: 本研究采用电路分析技术，将多级晶体管放大器建模为线性动态影响模型（LDIM），其中放大器级之间的相互作用被建模为线性动态方程。利用图模型技术和维纳滤波，仅通过在电路特定点采样的电压时间序列测量数据来重建网络结构。

Result: 通过Cadence仿真和实际硬件实验，证明了LDIM模型和网络重建方法在多级放大器中的有效性，能够高效地识别故障和关键电路参数。

Conclusion: 该研究表明，仅从采样点处的电压时间序列测量数据即可推断出网络结构，为设计、分析和调试放大器电路提供了高效的工具。此外，还提出了一种利用网络重建技术进行故障诊断的方法。

Abstract: Multistage transistor amplifiers can be effectively modeled as network of
dynamic systems where individual amplifier stages interact through couplings
that are dynamic in nature. Using circuit analysis techniques, we show that a
large class of transistor amplifiers can be modeled as Linear Dynamic Influence
Model (LDIM), where the interactions between different amplifier stages are
modeled as linear dynamic equations. LDIM modeling of transistor circuits leads
to application of data-driven network reconstruction techniques to characterize
stage interactions and identify faults and critical circuit parameters
efficiently. Employing graphical modeling techniques and Wiener filtering, we
demonstrate that the network structure can be reconstructed solely from voltage
time-series measurements sampled at specified points in the circuit. The
efficacy of these network reconstruction methods in multistage amplifiers is
demonstrated through extensive simulations involving multiple amplifier
circuits in Cadence, as well as experimental results on physical hardware. The
ability to infer network structure directly from measurement data offers
designers and users efficient tools to design, analyze, and debug amplifier
circuits. To demonstrate the utility of network reconstruction in multistage
amplifier circuits, a fault diagnosis method leveraging these techniques is
presented.

</details>


### [429] [Preparing for the worst: Long-term and short-term weather extremes in resource adequacy assessment](https://arxiv.org/abs/2508.05163)
*Aleksander Grochowicz,Hannah C. Bloomfield,Marta Victoria*

Main category: eess.SY

TL;DR: 本研究提出一种基于影子价格的方法，用于识别和分析极端天气事件对净零电力系统造成的压力（系统定义事件），并评估其对电力系统运行和规划的影响，强调了具备财务可行性的弹性备用容量的必要性，并区分了短期和长期弹性挑战，为未来的能源模型评估提供了方法。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源在净零电力系统中的集成，供应链安全问题日益突出。极端天气会影响电力需求和供应，给电力系统带来压力，这种压力可能在欧洲大陆范围内扩散。因此，有必要研究这些系统压力事件，以应对未来的能源挑战。

Method: 本研究采用基于影子价格的方法来识别和分析“系统定义事件”对电力系统的影响。通过对不同类型的系统定义事件进行分类，以识别电力系统运行和规划所面临的挑战。该方法及其在开放模型PyPSA-Eur中的实现可以应用于其他系统。

Result: 研究识别了“系统定义事件”，即电力系统压力增加的时期，并分析了这些事件对电力系统的影响。研究结果强调了拥有足够的弹性备用容量的必要性，并指出这些容量的财务可行性因天气多变而受到威胁。此外，研究区分了短期和长期弹性挑战，并提供了相应的评估方法。

Conclusion: 该研究强调了在净零电力系统中整合可再生能源时，供应链安全至关重要。通过识别和分析“系统定义事件”的影响，该研究揭示了对电力系统运行和规划的挑战。研究结果表明，需要有足够的弹性备用（电力）容量，但其财务可行性因天气多变而受到威胁。此外，该研究区分了短期和长期弹性挑战，并提出了不同的指标和压力测试，以将其纳入未来的能源模型评估中。

Abstract: Security of supply is a common and important concern when integrating
renewables in net-zero power systems. Extreme weather affects both demand and
supply leading to power system stress; in Europe this stress spreads
continentally beyond the meteorological root cause. We use an approach based on
shadow prices to identify periods of elevated stress called system-defining
events and analyse their impact on the power system. By classifying different
types of system-defining events, we identify challenges to power system
operation and planning. Crucially, we find the need for sufficient resilience
back-up (power) capacities whose financial viability is precarious due to
weather variability. Furthermore, we disentangle short- and long-term
resilience challenges with distinct metrics and stress tests to incorporate
both into future energy modelling assessments. Our methodology and
implementation in the open model PyPSA-Eur can be re-applied to other systems
and help researchers and policymakers in building more resilient and adequate
energy systems.

</details>


### [430] [Overview of Controllability Definitions in Supervisory Control Theory](https://arxiv.org/abs/2508.05177)
*Jeroen J. A. Keiren,Michel A. Reniers*

Main category: eess.SY

TL;DR: 本文梳理了监督控制理论中关于可控性的多种定义，并在不同设定下探究了它们之间的等价性和蕴含关系，特别是关注了有监督工厂与工厂之间的可控性。


<details>
  <summary>Details</summary>
Motivation:  the literature often proposes different definitions for the same concept, making it difficult to understand how these definitions are related. This is definitely so for the fundamental notion of controllability of a supervisor w.r.t. a plant.

Method: 通过列举文献中已有的可控性定义，并在确定性和非确定性自动机的设定下研究它们之间的关系。

Result: 在一般环境中，Flordal和Malik的可控性概念与Kushi和Takai的不可控事件可容性是等价的，并且这两个概念也蕴含了传统的（语言）可控性。在有监督的工厂与工厂之间可控性的情境下，除上述两个概念外，Zhou等人的状态可控性也蕴含了语言可控性。

Conclusion: 本文研究了在确定性和非确定性自动机环境中，监督者可控性的不同定义及其相互关系，并重点关注了在有监督的工厂与工厂之间的可控性。

Abstract: In the field of supervisory control theory, the literature often proposes
different definitions for the same concept, making it difficult to understand
how these definitions are related. This is definitely so for the fundamental
notion of controllability of a supervisor w.r.t. a plant. This paper lists
definitions of controllability found in the literature and studies their
relationships in settings of both deterministic and nondeterministic automata.
In the general context, where both the supervisor and the plant are allowed to
be nondeterministic, the notions of controllability as described by Flordal and
Malik, and uncontrollable event admissibility by Kushi and Takai are
equivalent. These are also the only notions that imply the traditional notion
of (language) controllability. From a practical perspective, one is often more
interested in controllability of a supervised plant w.r.t. a plant. In this
context, in addition to the previous two controllability notions, state
controllability by Zhou et al. implies language controllability.

</details>


### [431] [Passive nonlinear FIR filters for data-driven control](https://arxiv.org/abs/2508.05279)
*Zixing Wang,Fulvio Forni*

Main category: eess.SY

TL;DR: 提出了一种新的无源非线性有限脉冲响应算子，用于高效的控制器综合，特别适用于机电系统。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效的控制器综合，需要引入新的非线性算子。

Method: 通过在提升空间中作用有限脉冲响应滤波器来构造此类无源非线性有限脉冲响应算子，并基于虚拟参考反馈整理论的最小二乘拟合来考虑闭环性能，通过频域采样建立的有效线性约束来保证无源性。

Result: 提出了一类新的无源非线性有限脉冲响应算子，并证明了其在控制物理系统（如机电系统）方面的有效性。

Conclusion: 该类非线性算子特别适用于机电系统等物理系统的控制。

Abstract: We propose a new class of passive nonlinear finite impulse response
operators. This class is constructed by the action of finite impulse response
filters in a lifted space. This allows for efficient control synthesis through
constrained optimization. Closed-loop performance is taken into account through
least-squares fitting, based on the theory of virtual reference feedback
tuning. Passivity is established through efficient linear constraints, based on
sampling in the frequency domain. Because of passivity, this class of operators
is particularly suited for the control of physical systems, such as
electromechanical systems.

</details>


### [432] [A 20-Year Retrospective on Power and Thermal Modeling and Management](https://arxiv.org/abs/2508.05495)
*David Atienza,Kai Zhu,Darong Huang,Luis Costero*

Main category: eess.SY

TL;DR: This survey examines over 20 years of research on managing power and thermal issues in processors, covering various modeling techniques and management strategies, and highlighting future challenges and research opportunities.


<details>
  <summary>Details</summary>
Motivation: Increasing power densities and complex thermal behaviors, driven by processor performance advances, threaten energy efficiency and system reliability.

Method: This survey compares analytical, regression-based, and neural network-based techniques for power estimation, reviews thermal modeling methods (finite element, finite difference, data-driven), and categorizes dynamic runtime management strategies.

Result: The survey covers over two decades of research on power and thermal modeling and management in modern processors, comparing different modeling techniques and categorizing management strategies.

Conclusion: The survey concludes with a discussion of emerging challenges and promising research directions in power and thermal modeling and management for modern processors.

Abstract: As processor performance advances, increasing power densities and complex
thermal behaviors threaten both energy efficiency and system reliability. This
survey covers more than two decades of research on power and thermal modeling
and management in modern processors. We start by comparing analytical,
regression-based, and neural network-based techniques for power estimation,
then review thermal modeling methods, including finite element, finite
difference, and data-driven approaches. Next, we categorize dynamic runtime
management strategies that balance performance, power consumption, and
reliability. Finally, we conclude with a discussion of emerging challenges and
promising research directions.

</details>


### [433] [Research on integrated intelligent energy management system based on big data analysis and machine learning](https://arxiv.org/abs/2508.05583)
*Jinzhou Xu,Yadan Zhang,Paola Tapia*

Main category: eess.SY

TL;DR: 该文章讨论了在综合智能能源项目的文档管理和控制中实施大数据分析的优点和挑战，并提出了一种利用机器学习优化项目文档管理效率的框架和方法。结果表明，该方法可以显著提高项目文档管理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 将大数据应用于综合智能能源项目的文件管理，对于提高项目管理和控制的效率具有重要意义。

Method: 提出了一种利用机器学习优化综合能源项目文档管理效率的方法，并利用三种不同的机器学习方法，通过项目文档管理过程中产生的各种类型的数据和信息，对整个过程项目文档控制的效率进行了优化。拟合结果表明，当有足够的数据作为训练集时，所获得模型的准确性可以达到95%以上。

Result: 当有足够的数据作为训练集时，所获得模型的准确性可以达到95%以上。

Conclusion: 通过使用大数据分析和机器学习来分析综合能源项目文档管理的效率，可以跟踪综合能源项目的整个过程文件，并优化业务流程，从而加强项目建设控制，提高项目建设效率。

Abstract: The application of big data is one of the significant features of integrated
smart energy. Applying it to the file management of integrated smart energy
projects is of great significance for improving the efficiency of project
management and control. This article first discussed the benefits and
challenges of implementing big data analysis in document management and control
of integrated smart energy projects. In addition, an implementation framework
for big data analysis in integrated smart energy project document management
was developed, and a method for optimizing the efficiency of integrated smart
energy project document management through machine learning was proposed. Using
various types of data and information generated during the project document
management process, the efficiency of the entire process project document
control through three different machine learning methods was optimized. The
result of fitting a penalty linear regression model shows that when there is
enough data as a training set, the accuracy of the model achieved can reach
over 95\%. By using big data analysis and machine learning to analyze the
efficiency of comprehensive smart energy project document management, it is
possible to track the entire process of comprehensive smart energy project
documents and optimize business processes, thereby strengthening project
construction control and improving project construction efficiency.

</details>


### [434] [Error Bounds for Radial Network Topology Learning from Quantized Measurements](https://arxiv.org/abs/2508.05620)
*Samuel Talkington,Aditya Rangarajan,Pedro A. de Alcântara,Line Roald,Daniel K. Molzahn,Daniel R. Fuhrmann*

Main category: eess.SY

TL;DR: 该研究提出了一种新的径向网络拓扑学习方法，该方法考虑了传感器量化误差，并推导了相应的误差界限。结果表明，该方法的误差与量化误差成正比，并随网络规模的增加而亚线性增长。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于解决传统电力系统估计算法中存在的局限性，即它们通常只考虑加性噪声模型，而忽略了传感器精度（量化）引起的数据误差。通过引入一个非线性测量模型，该研究旨在更准确地模拟和分析实际网络中的误差。

Method: 该研究通过对量化误差进行建模，并分析其对径向网络拓扑学习误差的影响来推导误差界限。研究表明，学习到的径向网络拓扑的误差与量化 bin 宽度成正比，并且在节点数量的对数级样本下，误差随节点数量的增加而亚线性增长。

Result: 研究结果表明，学习到的径向网络拓扑的误差与量化 bin 宽度成正比。此外，当每个节点的样本数量相对于节点数量是对数增长时，误差随节点数量的增加而亚线性增长。

Conclusion: 该研究为径向网络拓扑学习问题提供了一个概率误差界限，该问题同时估计连接性和线路参数。与典型的仅考虑加性噪声的模型不同，该模型考虑了由传感器精度（量化）引起的数据误差，从而引入了一个非线性测量模型。

Abstract: We probabilistically bound the error of a solution to a radial network
topology learning problem where both connectivity and line parameters are
estimated. In our model, data errors are introduced by the precision of the
sensors, i.e., quantization. This produces a nonlinear measurement model that
embeds the operation of the sensor communication network into the learning
problem, expanding beyond the additive noise models typically seen in power
system estimation algorithms. We show that the error of a learned radial
network topology is proportional to the quantization bin width and grows
sublinearly in the number of nodes, provided that the number of samples per
node is logarithmic in the number of nodes.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [435] [Impact of Au Ion Implantation on 2D $Cr_2Ge_2Te_6$ for Spintronics](https://arxiv.org/abs/2508.04715)
*Gurupada Ghorai,Kalyan Ghosh,Pratap K. Sahoo*

Main category: physics.app-ph

TL;DR: 通过Au离子注入调控Cr2Ge2Te6的磁性，以用于自旋电子学。


<details>
  <summary>Details</summary>
Motivation: 二维磁性材料在半导体、磁性和自旋电子学领域展现出巨大潜力，尤其是在调控自旋电子学应用的磁性方面。本研究旨在探索低能Au离子注入对2D层状Cr2Ge2Te6薄片磁性的影响。

Method: 本研究采用苏格兰胶带法制备了Si/SiO2衬底上的2D层状Cr2Ge2Te6薄片，并使用30KeV的Au离子注入，研究了五种不同的离子剂量（5x10^13、1x10^14、5x10^14、1x10^15和2.5x10^15 ions/cm^2）对样品形貌、成分、结构和振动特性的影响。

Result: Au离子注入显著改变了Cr2Ge2Te6薄片的形貌和磁行为，提高了居里温度，并将相互作用从超交换转变为双交换。Au离子插层导致交换能量隙减小和磁矩改变，证明了离子注入调控2D材料磁性的潜力。

Conclusion: 研究表明，通过低能Au离子注入可以有效地调控2D材料Cr2Ge2Te6的磁性，这为其在高级自旋电子学应用中的潜力提供了支持。

Abstract: Advancements in 2D magnetic materials highlight their potential in
semiconductors, magnetism, and spintronics, particularly in tuning magnetic
properties for spintronic applications. This study investigates the impact of
low-energy (30 KeV) Au ion implantation on 2D layered exfoliated $Cr_2Ge_2Te_6$
flakes prepared on Si/SiO$_2$ substrates using the Scotch tape method. Five
different ion doses (5$\times10^{13}$, 1$\times10^{14}$, 5$\times10^{14}$,
1$\times10^{15}$, and 2.5$\times10^{15}$ ions/cm$^2$) were used to modify the
morphology, composition, structural, and vibrational properties of the samples.
The implantation introduces significant changes in morphology and magnetic
behavior, leading to an increase in Curie temperature and an attribution from
superexchange to double exchange interactions. The reduced exchange energy gaps
and modified magnetic moments attribute to Au ions intercalation in
$Cr_2Ge_2Te_6$ underscore the potential of ions implantation to tune the
magnetic properties of 2D materials for advanced spintronic applications.

</details>


### [436] [Parametric Analysis of First High-Gain Vertical Fe-doped Ultrafast Ga2O3 Photoconductive Semiconductor Switch](https://arxiv.org/abs/2508.04911)
*N. Karpourazar,S. K. Mazumder,V. Jangir,K. M. Dowling,J. Leach,L. Voss*

Main category: physics.app-ph

TL;DR: LLNL资助的一项研究，通过SILVACO仿真分析了Fe掺杂Ga2O3光电导开关的性能，结果显示该开关在高电场和光激发下能实现高增益，并可能通过低成本激光器驱动。


<details>
  <summary>Details</summary>
Motivation: 为了研究Fe掺杂Ga2O3超宽带隙光电导开关（FG-PCSS）在嵌入电极下的参数化性能。

Method: 利用SILVACO仿真软件，并结合实验获得的寿命、吸收系数和迁移率数据，对Fe掺杂Ga2O3超宽带隙光电导开关（FG-PCSS）的参数化性能进行了分析。

Result: 分析结果展示了FG-PCSS在高电场和高光激发能量下的性能，特别关注了电流增益、量子效率、导通电阻以及光束位置的影响，并指出高增益操作是可能实现的。

Conclusion: 研究表明，Ga2O3开关在特定条件下有望实现高增益，从而可用低成本激光器驱动。

Abstract: We investigate, as part of a Lawrence-Livermore-National-Laboratory (LLNL)
sponsored-research work initiated in February of 2021, the parametric
performance analysis of ultra-wide bandgap (UWBG) Fe-doped Ga2O3
photoconductive semiconductor switch (FG-PCSS) with embedded electrode. The
detailed SILVACO based simulation of the FG-PCSS uses experimentally obtained
lifetime, absorption coefficient, and mobility data. The key analysis results,
demonstrated first to the sponsor LLNL in 2022, focus on the performance of the
FG-PCSS under relatively high electric field and optical-excitation energy with
specific regard to current gain, quantum efficiency, on-state resistance, and
impact of beam position. The parametric analysis indicates that a high-gain
operation yielding a low-cost laser beam for the FG-PCSS is possible.

</details>


### [437] [Double Negative Metamaterials in Water Waves](https://arxiv.org/abs/2508.05458)
*Zixun Ge,Junke Liao,Linkang Han,Qilin Duan,Xiaofan Wang,Mengwei Dai,Shan Zhu,Huanyang Chen*

Main category: physics.app-ph

TL;DR: 通过嵌套齿轮和分裂管构建的双负超材料（DNM）可用于水波的负折射，实现可控的水波传播，并为海岸工程提供新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 水波既带来机遇也带来危害，需要精确控制以有效利用其能量并减轻其破坏性影响。利用负折射的独特传播特性，可以实现多种控制策略。

Method: 提出了一种由嵌套齿轮和分裂管组成的双负超材料（DNM）用于水波的负折射。采用相干势近似（CPA）预测了有效的负水深和负重力，并通过带结构和表面波激发下的隔离、波浪弯曲和全角度成像模拟进行了验证。最后通过简化的实验验证了水波弯曲。

Result: 预测的DNM参数与带结构吻合良好，并通过隔离、波浪弯曲和全角度成像模拟进行了验证。简化的水波弯曲实验与分析预测和模拟结果吻合良好。研究实现了结构参数与传播特性之间的定量映射，能够实现可调的带隙和可控的负折射。

Conclusion: 提出的双负超材料（DNM）通过嵌套齿轮和分裂管实现，可用于水波的负折射，为控制水波能量和减轻破坏性效应提供了新的策略。该结构能够实现可调的负折射，解决了先前结构中不明确的结构-传播关系和严格的布局要求。通过相干势近似（CPA）预测了有效的负水深和负重力，并通过带结构和表面波激发下的波浪弯曲、全角度成像等模拟进行了验证。简化的水波弯曲实验也与预测和模拟结果吻合良好。该DNM为海岸工程提供了变革性的工具，可用于平静港口、增强波浪能收集器和引导河流弯曲以遏制侵蚀。

Abstract: Water waves present both opportunities and hazards, which demand precise
control to effectively exploit their energy and mitigate their destructive
effects. Leveraging the unique propagation characteristic of negative
refraction enables versatile strategies for achieving such control. Here, we
propose a Veselago-Pendry double negative metamaterial (DNM) for water waves
constructed by nested gears and split tubes. This uniform array structure
realizes effective negative water depth and gravity distributions, enabling
tunable negative refraction that resolves the unclear structure-propagation
relationships and stringent layout requirements of prior negative refraction
structures. By employing coherent potential approximation (CPA), negative
effective water depth ue and gravity ge are predicted. The predicted DNM
parameters align well with band structures, and are validated by simulations of
isolation, wave bending and all-angle imaging with surface waves excitation. A
simplified experiment demonstrating water wave bending was successfully
performed, matching the analytical predictions and simulation results well.
Through quantitative mapping between structural parameters and propagation
properties that enables tunable bandgaps and controllable negative refraction,
DNMs furnish a transformative toolkit for coastal engineering, and are able to
calm harbors, boost wave-energy harvesters, and steer river-bend currents to
curb erosion.

</details>


### [438] [Thin-Film Solar Photovoltaics: Trends and Future Directions](https://arxiv.org/abs/2508.05589)
*Donald Intal,Abasifreke U. Ebong*

Main category: physics.app-ph

TL;DR: 本文回顾了薄膜光伏技术，包括现有技术（如CdTe和CIGS）和新兴技术（如钙钛矿）。虽然薄膜技术在成本和应用方面具有优势，但仍面临稳定性和毒性等挑战。


<details>
  <summary>Details</summary>
Motivation: 薄膜光伏技术在太阳能应用中解决了可扩展性、成本效益和环境可持续性等关键挑战。

Method: 本文对薄膜光伏技术进行了批判性回顾，重点介绍了非晶硅（a-Si）、碲化镉（CdTe）和铜铟镓硒（CIGS），并讨论了钙钛矿、铜锌锡硫（CZTS）、量子点（QDs）、有机光伏（OPV）和染料敏化太阳能电池（DSSC）等新兴技术。

Result: CdTe和CIGS的实验室效率分别达到23.1%和23.6%，而钙钛矿的实验室效率达到26.7%。薄膜光伏技术通过减少材料使用和制造成本，以及提供柔性和轻质结构等优势，实现了多样化的应用。

Conclusion: CdTe和CIGS是目前商业上可行的薄膜光伏技术，而钙钛矿则在实验室效率方面取得了显著进展。克服长期稳定性、毒性担忧和材料稀缺性等挑战，对于薄膜光伏技术在全球可再生能源转型中发挥重要作用至关重要。

Abstract: Thin-film photovoltaic (PV) technologies address crucial challenges in solar
energy applications, including scalability, cost-effectiveness, and
environmental sustainability. This paper reviews critically, thin-film
technologies such as amorphous silicon (a-Si), cadmium telluride (CdTe), and
copper indium gallium selenide (CIGS). It also discusses emerging technologies,
including perovskites, copper zinc tin sulfide (CZTS), quantum dots (QDs),
organic photovoltaics (OPV), and dye-sensitized solar cells (DSSC). Among
these, CdTe and CIGS currently dominate commercial viability, achieving
laboratory-scale efficiencies of 23.1% and 23.6%, respectively. Perovskites
have notably advanced, reaching a laboratory efficiency of 26.7%. Thin-film PV
technologies significantly reduce material use and manufacturing costs,
offering distinct advantages such as flexibility and lightweight structures,
thereby enabling diverse applications from building-integrated systems to
portable electronic devices. Despite these benefits, broader adoption remains
limited by challenges including long-term stability, toxicity concerns, and
material scarcity. Addressing these challenges through advancements in tandem
architectures, improved encapsulation strategies, and sustainable material
sourcing is essential for thin-film PV technologies to substantially contribute
to the global renewable energy transition.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [439] [Real-Time Doppler and Ionospheric Dispersion Correction Techniques for Arbitrary Waveforms Utilizing GPU Compute](https://arxiv.org/abs/2508.04951)
*Daniel J. Vickers,A. H. Mack,Idahosa A. Osaretin*

Main category: eess.SP

TL;DR: 雷达信号处理中，离子层和多普勒频散校正的实时实现通常需要专用硬件。本研究提出并分析了两种通用的、基于GPU的软件算法（FFT和sinc插值）来解决这个问题。这些算法精度高、实时性好、不依赖特定波形，易于集成到软件定义无线电设备中，提高了灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的雷达数字信号处理需要雷达专用的硬件来实现实时校正，这带来了系统设计上的限制，如波形灵活性差和系统复杂性增加。随着通用计算系统性能的提升，使用非雷达专用的高性能计算进行实时数字信号处理变得可行。本研究旨在分析通用的多普勒和离子层校正算法，并探讨其在GPU硬件上的高效软件实现。

Method: 1. 离子层频散校正：提出一种基于FFT的算法。 2. 多普勒频散校正：提出一种通过sinc插值进行数值插值的方法。 3. 性能分析：评估算法在执行时间、误差校正精度以及在GPU硬件上的实现效率。 4. 推荐：为雷达信号处理提供应用建议。

Result: 所提出的基于FFT的离子层频散校正算法和基于sinc插值的多普勒频散校正算法，在精度上能够达到与特定波形解析方法相当的水平。在实际测试中，这些算法能够在单个NVIDIA H100 GPU上实现实时处理。算法具有波形无关性，可直接应用于采样点，提高了系统的灵活性，并易于集成到软件定义无线电系统中。

Conclusion: 本研究提出了两种用于雷达数字信号处理的通用频散校正算法：一种基于FFT的离子层频散校正方法和一种基于sinc插值的数值插值方法，用于多普勒频散校正。这两种算法的准确性可以与特定波形的解析方法相媲美，并且可以在单个NVIDIA H100 GPU上实时执行。这些方法不依赖于特定波形，直接应用于采样点，提高了系统的灵活性，并易于集成到现有的软件定义无线电系统中。

Abstract: General requirements for radar digital signal processing are ionospheric
distortion and Doppler dispersion correction, which has historically required
radar-specific hardware to implement in real time. Although analog solutions
are computationally efficient, they often come with system design drawbacks
which limit waveform flexibility and can result in an overall increase of
system complexity. With improvements in modern general compute systems,
real-time digital signal processing is becoming more realizable using
non-radar-specific high-performance compute. In this paper, we present an
analysis of general Doppler and ionospheric correction algorithms for arbitrary
waveforms for radar digital signal processing. We also include considerations
for efficient implementation of these algorithms in software, specifically
using GPU hardware. This analysis includes metrics of performance such as
execution time and error correction accuracy. We also provide recommendations
for application in radar signal processing. We identify two algorithms for
dispersion correction: an FFT-based method for ionospheric dispersion and a
numerical interpolation method via sinc interpolation for Doppler dispersion.
Both of these algorithms are able to compensate for dispersion equivalent in
accuracy to waveform-specific analytical methods and were able to be performed
in real-time on a single NVIDIA H100 GPU. These methods are waveform agnostic
and applied directly to the samples, improving system flexibility and making
them easy to incorporate into existing software-defined radio systems.

</details>


### [440] [Anti-Jamming Sensing with Distributed Reconfigurable Intelligent Metasurface Antennas](https://arxiv.org/abs/2508.04964)
*Zhaowei Wang,Yunsong Huang,Weicheng Liu,Hui-Ming Wang*

Main category: eess.SP

TL;DR: 提出使用分布式可重构智能超表面天线（RIMSA）通过深度强化学习和神经网络进行无线传感，以克服射频环境挑战并抵抗干扰攻击。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统射频传感方法在不可预测和不利的射频环境中易受衰落和噪声影响的问题，并应对潜在的恶意干扰攻击。

Method: 提出了一种深度强化学习（DRL）算法来计算最优波束形成模式，并使用一个神经网络将接收信号转换为传感结果。

Result: 仿真结果表明，与集中式实现相比，所提出的分布式RIMSA系统在不利环境影响下实现了更有效的传感性能，并且在受到干扰攻击时仍能确保高精度的传感性能。

Conclusion: 该分布式RIMSA系统在干扰和不利的传播环境中实现了更有效的传感性能，并能抵御干扰攻击。

Abstract: The utilization of radio frequency (RF) signals for wireless sensing has
garnered increasing attention. However, the radio environment is unpredictable
and often unfavorable, the sensing accuracy of traditional RF sensing methods
is often affected by adverse propagation channels from the transmitter to the
receiver, such as fading and noise. In this paper, we propose employing
distributed Reconfigurable Intelligent Metasurface Antennas (RIMSA) to detect
the presence and location of objects where multiple RIMSA receivers (RIMSA Rxs)
are deployed on different places. By programming their beamforming patterns,
RIMSA Rxs can enhance the quality of received signals. The RF sensing problem
is modeled as a joint optimization problem of beamforming pattern and mapping
of received signals to sensing outcomes. To address this challenge, we
introduce a deep reinforcement learning (DRL) algorithm aimed at calculating
the optimal beamforming patterns and a neural network aimed at converting
received signals into sensing outcomes. In addition, the malicious attacker may
potentially launch jamming attack to disrupt sensing process. To enable
effective sensing in interferenceprone environment, we devise a combined loss
function that takes into account the Signal to Interference plus Noise Ratio
(SINR) of the received signals. The simulation results show that the proposed
distributed RIMSA system can achieve more efficient sensing performance and
better overcome environmental influences than centralized implementation.
Furthermore, the introduced method ensures high-accuracy sensing performance
even under jamming attack.

</details>


### [441] [Localized Kernel Methods for Signal Processing](https://arxiv.org/abs/2508.04978)
*Sippanon Kitimoon*

Main category: eess.SP

TL;DR: 本文提出两种基于局部核的信号处理方法，用于在噪声条件下恢复指数模型参数和分离线性啁啾分量，均无需子空间分解或稀疏正则化，并在实验中验证了其鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在噪声条件下实现参数恢复，本文研究了信号处理方法。

Method: 本文提出了两种基于局部核的信号处理方法：一种是用于多维指数模型中频率和幅度的估计，采用局部三角多项式核来检测多变量频率，并与MUSIC和ESPRIT等经典算法进行比较，在低信噪比下表现更优；另一种是用于分离时间局部信号段中的线性啁啾分量，通过构建局部核的信号分离算子（SSO）变体，利用基于FFT的滤波获得瞬时频率估计，然后进行聚类和分段线性回归，该方法无需预知分量数量，即可在低至-30dB的信噪比下恢复相交和不连续的啁啾信号。

Result: 本文提出的两种方法在低信噪比和恢复相交、不连续的啁啾信号方面表现出鲁棒性和有效性。

Conclusion: 该论文提出了一种基于局部核的信号处理方法，该方法在噪声条件下能够实现参数恢复，并且不需要子空间分解或稀疏性正则化。

Abstract: This dissertation presents two signal processing methods using specially
designed localized kernels for parameter recovery under noisy condition. The
first method addresses the estimation of frequencies and amplitudes in
multidimensional exponential models. It utilizes localized trigonometric
polynomial kernels to detect the multivariate frequencies, followed by a more
detailed parameter estimation. We compare our method with MUSIC and ESPRIT,
which are classical subspace-based algorithms widely used for estimating the
parameters of exponential signals. In the univariate case, the method
outperforms MUSIC and ESPRIT under low signal-to-noise ratios. For the
multivariate case, we develop a coordinate-wise projection and registration
approach that achieves high recovery accuracy using significantly fewer samples
than other methods.
  The second method focuses on separating linear chirp components from
time-localized signal segments. A variant of the Signal Separation Operator
(SSO) is constructed using a localized kernel. Instantaneous frequency
estimates are obtained via FFT-based filtering, then clustered and fitted with
piecewise linear regression. The method operates without prior knowledge of the
number of components and is shown to recover intersecting and discontinuous
chirps at SNR levels as low as -30 dB.
  Both methods share an idea based on localized kernels and efficient FFT-based
implementation, and neither requires subspace decomposition or sparsity
regularization. Experimental results confirm the robustness and tractability of
the proposed approaches across a range of simulated data conditions. Potential
extensions include application to nonlinear chirps, adaptive kernel design, and
signal classification using extracted features.

</details>


### [442] [Power-Constrained and Quantized MIMO-RSMA Systems with Imperfect CSIT: Joint Precoding, Antenna Selection, and Power Control](https://arxiv.org/abs/2508.05080)
*Jiwon Sung,Seokjun Park,Jinseok Choi*

Main category: eess.SP

TL;DR: This paper presents a joint algorithm for precoding, antenna selection, and power control in downlink multi-user MIMO RSMA systems to maximize spectral efficiency under a total power budget. The method handles imperfect channel information and uses approximation techniques for tractability. It decomposes the problem into subproblems solved efficiently. Simulation results confirm the algorithm's effectiveness and suggest medium-resolution DACs might be more power-efficient than low-resolution ones when fully utilizing the BS power budget.


<details>
  <summary>Details</summary>
Motivation: To utilize the full potential of the available power at a base station (BS).

Method: The paper proposes a joint algorithm for precoding, antenna selection, and transmit power control to maximize sum spectral efficiency (SE) in downlink multi-user MIMO RSMA systems with arbitrary-resolution DACs. The problem is reformulated using conditional average rate for imperfect CSIT and approximation techniques. It's then decomposed into precoding direction and power control subproblems, solved via a superior Lagrangian stationary point and gradient descent, respectively. A complexity-reduction approach is also suggested for massive MIMO.

Result: The proposed joint algorithm maximizes sum spectral efficiency (SE) in downlink multi-user MIMO RSMA systems with arbitrary-resolution DACs, even with imperfect CSIT. Simulation results validate the algorithm and show potential power efficiency benefits of medium-resolution DACs.

Conclusion: The proposed algorithm is validated by simulation results, which also show that medium-resolution DACs (8-11 bits) can be more power-efficient than low-resolution DACs when the BS power budget is fully utilized.

Abstract: To utilize the full potential of the available power at a base station (BS),
we propose a joint precoding, antenna selection, and transmit power control
algorithm for a total power budget at the BS. We formulate a sum spectral
efficiency (SE) maximization problem for downlink multi-user multiple-input
multiple-output (MIMO) rate-splitting multiple access (RSMA) systems with
arbitrary-resolution digital-to-analog converters (DACs). We reformulate the
problem by defining the ergodic sum SE using the conditional average rate
approach to handle imperfect channel state information at the transmitter
(CSIT), and by using approximation techniques to make the problem more
tractable. Then, we decompose the problem into precoding direction and power
control subproblems. We solve the precoding direction subproblem by identifying
a superior Lagrangian stationary point, and the power control subproblem using
gradient descent. We also propose a complexity-reduction approach that is more
suitable for massive MIMO systems. Simulation results not only validate the
proposed algorithm but also reveal that when utilizing the full potential of
the power budget at the BS, medium-resolution DACs with 8-11 bits may actually
be more power-efficient than low-resolution DACs.

</details>


### [443] [Digital Twin Channel-Aided CSI Prediction: A Environment-based Subspace Extraction Approach for Achieving Low Overhead and Robustness](https://arxiv.org/abs/2508.05142)
*Yichen Cai,Jianhua Zhang,Li Yu,Zhen Zhang,Yuxiang Zhang,Lianzheng Shi,Yuelong Qiu*

Main category: eess.SP

TL;DR: 提出一种新的CSI预测方法（EB-P2WCP），利用数字孪生环境信息（EB）和本地CSI，有效降低6G通信开销，并提高预测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了满足第六代（6G）移动通信系统在复杂场景下对鲁棒性和高速通信的需求，基于感知和人工智能（AI）的数字孪生信道（DTC）技术被提出，以降低系统开销。

Method: 提出了一种基于环境特定的信道子空间基（EB）辅助的部分到整体信道状态信息（CSI）预测方法（EB-P2WCP），并设计了EB-P2WNet网络来实现。该方法利用EB表征电磁环境的静态特性，并与本地CSI融合，以预测当前和未来时间实例的全空间频率域信道。

Result: 仿真结果表明，EB的引入在低信噪比和导频比条件下带来了显著优势，导频开销降低了高达50%。此外，该方法对多用户干扰具有鲁棒性，可容忍3米定位误差而NMSE仅增加0.5 dB，并能在1.3毫秒内预测下一个信道相干时间内的CSI。

Conclusion: 所提出的EB-P2WCP方法通过融合数字孪生地图提取的环境信息（EB）和本地CSI，能够有效预测全空间频率域信道，并在低信噪比和导频比条件下显著降低系统开销（高达50%）。该方法还能抵抗多用户干扰和定位误差，并能快速预测未来信道状态。

Abstract: To meet the robust and high-speed communication requirements of the
sixth-generation (6G) mobile communication system in complex scenarios,
sensing- and artificial intelligence (AI)-based digital twin channel (DTC)
techniques become a promising approach to reduce system overhead. In this
paper, we propose an environment-specific channel subspace basis (EB)-aided
partial-to-whole channel state information (CSI) prediction method (EB-P2WCP)
for realizing DTC-enabled low-overhead channel prediction. Specifically, EB is
utilized to characterize the static properties of the electromagnetic
environment, which is extracted from the digital twin map, serving as
environmental information prior to the prediction task. Then, we fuse EB with
real-time estimated local CSI to predict the entire spatial-frequency domain
channel for both the present and future time instances. Hence, an EB-based
partial-to-whole CSI prediction network (EB-P2WNet) is designed to achieve a
robust channel prediction scheme in various complex scenarios. Simulation
results indicate that incorporating EB provides significant benefits under low
signal-to-noise ratio and pilot ratio conditions, achieving a reduction of up
to 50% in pilot overhead. Additionally, the proposed method maintains
robustness against multi-user interference, tolerating 3-meter localization
errors with only a 0.5 dB NMSE increase, and predicts CSI for the next channel
coherent time within 1.3 milliseconds.

</details>


### [444] [Optimization of Liquid Lens-based Imaging Receiver for MIMO VLC Systems](https://arxiv.org/abs/2508.05204)
*Kapila W. S. Palitharathna,Christodoulos Skouroumounis,Ioannis Krikidis*

Main category: eess.SP

TL;DR: 该研究提出了一种基于液态透镜的MIMO可见光通信接收器，通过动态调整透镜以降低信道相关性，显著提高了在动态环境下的BER性能，BER从4x10^-2降低到5x10^-4（在10°方向方差下）。


<details>
  <summary>Details</summary>
Motivation: 为了提高多输入多输出（MIMO）可见光通信（VLC）系统的性能，特别是在用户移动和接收器方向随机变化等动态条件下，提出了一种基于液态透镜的成像接收器，旨在通过降低MIMO信道增益的空间相关性来增强比特误差率（BER）性能。

Method: 开发了一个精确的数学框架来模拟信道增益，并提出了一种优化问题来最小化BER。针对复杂的信道模型，引入了两种透镜调整方案：CLS方案和VULO方案。

Result: 数值结果表明，该液态透镜系统在各种随机接收器方向条件下均能显著改善BER。具体而言，在10°的随机接收器方向方差下，采用该液态透镜可将BER从4x10^-2提高到5x10^-4，相比于传统的基于静态透镜的接收器有了显著提升。

Conclusion: 该研究提出了基于液态透镜的MIMO可见光通信（VLC）系统，通过动态调整液态透镜的焦距和方向角来降低空间相关性，从而提高比特误差率（BER）性能。与静态透镜不同，液态透镜在动态条件下具有自适应性，例如用户移动和接收器方向随机变化。研究开发了一个精确的数学框架来模拟信道增益，并提出了一种优化问题来最小化BER。针对复杂的信道模型，引入了两种透镜调整方案：CLS方案和VULO方案。数值结果表明，与传统的基于静态透镜的接收器相比，该液态透镜系统在各种随机接收器方向条件下均能显著改善BER。具体而言，在10°的随机接收器方向方差下，采用该液态透镜可将BER从4x10^-2提高到5x10^-4。

Abstract: In this paper, a liquid lens-based imaging receiver is proposed for
multiple-input multiple-output (MIMO) visible light communication (VLC)
systems. By dynamically adjusting the focal length and orientation angles of
the liquid lens, the spatial correlation between MIMO channel gains is reduced,
leading to enhanced bit-error rate (BER) performance. Unlike static lenses,
liquid lenses offer adaptability in dynamic conditions, including user mobility
and random receiver orientation. An accurate mathematical framework is
developed to model the channel gains of the proposed system, and an
optimization problem is formulated to minimize its BER. Due to the complexity
of the resulting channel model, two lens adjustment schemes, namely, ($i$) the
CLS scheme, and ($ii$) the VULO scheme are introduced. Numerical results
demonstrate that the proposed liquid lens-based system offers substantial BER
improvements over conventional static lens-based receivers across a wide range
of random receiver orientation conditions. Specifically, at a random receiver
orientation variance of $10^{\circ}$, the BER is improved from $4\times
10^{-2}$ to $5\times 10^{-4}$ by employing the proposed liquid lens.

</details>


### [445] [Deep Learning Based Dynamic Environment Reconstruction for Vehicular ISAC Scenarios](https://arxiv.org/abs/2508.05226)
*Junzhe Song,Ruisi He,Mi Yang,Zhengyu Zhang,Bingcheng Liu,Jiahui Han,Haoxiang Zhang,Bo Ai*

Main category: eess.SP

TL;DR: A new deep learning framework uses ISAC channels to reconstruct dynamic vehicle environments, improving accuracy and efficiency for intelligent transport systems.


<details>
  <summary>Details</summary>
Motivation: Existing ISAC based reconstruction methods lack the ability to accurately and temporally consistently track dynamic scenes, limiting their real-world applicability in intelligent transportation systems.

Method: A deep learning based framework using a multistage network (scene decoder, cluster center decoder, point cloud decoder) is developed. A joint channel environment dataset based on multi modal measurements from real world urban street scenarios is established for training.

Result: The proposed method achieves high-quality dynamic environment reconstruction with a Chamfer Distance of 0.29 and F Score@1% of 0.87. Complexity analysis demonstrates its efficiency and practical applicability in real-time scenarios.

Conclusion: The proposed deep learning framework effectively reconstructs dynamic vehicular environments using ISAC channels, achieving high-quality results with practical efficiency for intelligent transportation systems.

Abstract: Integrated Sensing and Communication (ISAC) technology plays a critical role
in future intelligent transportation systems, by enabling vehicles to perceive
and reconstruct the surrounding environment through reuse of wireless signals,
thereby reducing or even eliminating the need for additional sensors such as
LiDAR or radar. However, existing ISAC based reconstruction methods often lack
the ability to track dynamic scenes with sufficient accuracy and temporal
consistency, limiting the real world applicability. To address this limitation,
we propose a deep learning based framework for vehicular environment
reconstruction by using ISAC channels. We first establish a joint channel
environment dataset based on multi modal measurements from real world urban
street scenarios. Then, a multistage deep learning network is developed to
reconstruct the environment. Specifically, a scene decoder identifies the
environmental context such as buildings, trees and so on; a cluster center
decoder predicts coarse spatial layouts by localizing dominant scattering
centers; a point cloud decoder recovers fine grained geometry and structure of
surrounding environments. Experimental results demonstrate that the proposed
method achieves high-quality dynamic environment reconstruction with a Chamfer
Distance of 0.29 and F Score@1% of 0.87. In addition, complexity analysis
demonstrates the efficiency and practical applicability of the method in real
time scenarios. This work provides a pathway toward low cost environment
reconstruction based on ISAC for future intelligent transportation.

</details>


### [446] [Unifying Common Signal Analyses with Instantaneous Time-Frequency Atoms](https://arxiv.org/abs/2508.05380)
*Steven Sandoval,Phillip L. De Leon*

Main category: eess.SP

TL;DR: 本研究提出了一种使用瞬时时频原子来计算多种信号分析（包括时间域、频域、分数傅里叶变换、同步压缩短时傅里叶变换和同步压缩短时分数傅里叶变换）的瞬时频谱（IS）的方法，并通过二次啁啾将它们统一在一个二维连续统中，并给出了闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 在先前的工作中，我们提出了一个通用的瞬时时频分析框架，但没有提供计算特定瞬时频谱（IS）的任何具体细节。本研究旨在解决这一问题。

Method: 使用瞬时时频原子获得与时间域分析、频域分析、分数傅里叶变换、同步压缩短时傅里叶变换和同步压缩短时分数傅里叶变换相关的瞬时频谱（IS）。

Result: 使用两个参数的二次啁啾，将IS组织成一个二维连续统，其中平面上的点对应于与其中一个信号分析相关的分解。最后，使用几个示例信号，我们以闭式计算了各种分析的IS。

Conclusion: 通过将这些分析视为对AM-FM分量的分解，并认识到每个分析在分析过程中都使用一种专门的（或极限的）二次啁啾形式作为模板，我们开发了相应的瞬时频谱（IS）的闭式表达式，并使用两个参数的二次啁啾将这些IS组织成一个二维连续统，其中平面上的点对应于与其中一个信号分析相关的分解。

Abstract: In previous work, we presented a general framework for instantaneous
time-frequency analysis but did not provide any specific details of how to
compute a particular instantaneous spectrum (IS). In this work, we use
instantaneous time-frequency atoms to obtain an IS associated with common
signal analyses: time domain analysis, frequency domain analysis, fractional
Fourier transform, synchrosqueezed short-time Fourier transform, and
synchrosqueezed short-time fractional Fourier transform. By doing so, we
demonstrate how the general framework can be used to unify these analyses and
we develop closed-form expressions for the corresponding ISs. This is
accomplished by viewing these analyses as decompositions into AM--FM components
and recognizing that each uses a specialized (or limiting) form of a quadratic
chirplet as a template during analysis. With a two-parameter quadratic
chirplet, we can organize these ISs into a 2D continuum with points in the
plane corresponding to a decomposition related to one of the signal analyses.
Finally, using several example signals, we compute in closed-form the ISs for
the various analyses.

</details>


### [447] [Sub- μ W Battery-Less and Oscillator-Less Wi-Fi Backscattering Transmitter Reusing RF Signal for Harvesting, Communications, and Motion Detection](https://arxiv.org/abs/2508.05479)
*Marco Privitera,Andrea Ballo,Karim Ali Ahmed,Alfio Dario Grasso,Massimo Alioto*

Main category: eess.SP

TL;DR: 本文介绍了一种超低功耗 (sub-uW) 的 802.11b 反散射发射器，它能通过能量收集、反散射通信和位置/运动传感来复用入射波。通过消除本地振荡器和使用双音入射波，该设备打破了 WiFi 发射器的功耗限制，并实现了低至 -19 dBm 的灵敏度。此外，它还能通过利用收集的电压作为 RSS 的代理来实现位置传感。


<details>
  <summary>Details</summary>
Motivation: 为了实现 RF 能量收集、反散射通信和位置/运动传感的同一入射波复用，并实现设备的小型化、普遍性、无限制的设备寿命以及低制造成本和维护成本。

Method: 通过消除本地振荡器，利用双音入射波的二阶互调提取频率，打破了 WiFi 发射器的 uW 功耗墙。利用收集的电压作为接收信号强度 (RSS) 的代理，实现了位置/运动传感。

Result: 实现了 sub-uW 功耗的 802.11b 反散射发射器，并将 uW 功耗墙打破。同时实现了累积能量收集/传输/传感的灵敏度低至 Pmin -19 dBm，并能够实现芯片相对于室内邻里标签共享的音调发生器的位置传感。

Conclusion: 本文提出了一种 sub-uW 功耗的 802.11b 反散射发射器，实现了 RF 能量收集、反散射通信和位置/运动传感的同一入射波复用。

Abstract: In this paper, a sub-uW power 802.11b backscattering transmitter is presented
to enable reuse of the same incident wave for three purposes: RF harvesting,
backscattering communications and position/motion sensing. The removal of the
battery and any off-chip motion sensor (e.g., MEMS) enables unprecedented level
of miniaturization and ubiquity, unrestricted device lifespan, low fabrication
and maintenance cost. The uW power wall for WiFi transmitters is broken for the
first time via local oscillator elimination, as achieved by extracting its
frequency through second-order intermodulation of a twotone incident wave. The
two-tone scheme also enables a cumulative harvesting/transmission/sensing
sensitivity down to Pmin -19 dBm. Position/motion sensing is enabled by using
the harvested voltage as a proxy for the Received Signal Strength (RSS),
allowing to sense the chip location with respect to the tone generator(s)
shared across tags in indoor neighborhoods.

</details>


### [448] [0.6-V, uW-Power 4-Stage OTA with Minimal Components and 100X Load Range](https://arxiv.org/abs/2508.05499)
*M. Privitera,A. D. Grasso,A. Ballo,M. Alioto*

Main category: eess.SP

TL;DR: 本文提出了一种用于超低功耗应用的四级OTA，它使用最少的元件，易于补偿，功率效率高，并且在宽负载范围内保持稳定。


<details>
  <summary>Details</summary>
Motivation: 为了超低功耗应用设计一种运算跨导放大器（OTA）。

Method: 提出了一种包含频率补偿的四级运算跨导放大器（OTA），该放大器所需的晶体管和无源元件数量最少，克服了传统四级OTA的补偿难题，并恢复了其简单性，使其可以与三级OTA相媲美。

Result: 与之前的四级OTA和低于1V的多级OTA相比，所提出的电路在ষধ(大信号)和FOMS(小信号)方面分别取得了超过3.7倍和11.3倍的功率效率提升，并且在宽负载条件下（负载电容的最大/最小比率超过100倍）保持稳定。

Conclusion: 所提出的OTA在宽负载范围内保持稳定，负载电容的最大/最小比率超过100倍。

Abstract: A four-stage operational transconductance amplifier (OTA) for ultra-low-power
applications is introduced in this paper. The proposed circuit inclusive of
frequency compensation requires minimal transistor count and passives,
overcoming the traditionally difficult compensation of 4-stage OTAs and
bringing it back to the simplicity of 3-stage OTAs. At the same time, the
proposed circuit achieves high power efficiency, as evidenced by the >3.7X
(>11.3X) improvement in the large-signal (small-signal) power efficiency figure
of merit FOML (FOMS), compared to prior 4-stage OTAs (sub-1 V multi-stage
OTAs). Thanks to the lower sensitivity of the phase margin to the load
capacitance, the proposed OTA remains stable under a wide range of loads
(double-sided as in any 3-4-stage OTA), achieving a max/min ratio of the load
capacitance of >100X.

</details>
