<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 87]
- [cs.CL](#cs.CL) [Total: 66]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.RO](#cs.RO) [Total: 49]
- [quant-ph](#quant-ph) [Total: 28]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.DC](#cs.DC) [Total: 9]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [cs.SI](#cs.SI) [Total: 5]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.SY](#cs.SY) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 8]
- [eess.SP](#eess.SP) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Leveraging NTPs for Efficient Hallucination Detection in VLMs](https://arxiv.org/abs/2509.20379)
*Ofir Azachi,Kfir Eliyahu,Eyal El Ani,Rom Himelstein,Roi Reichart,Yuval Pinter,Nitay Calderon*

Main category: cs.CV

TL;DR: 通过分析VLM的下一词元概率(NTP)，可以高效地检测幻觉。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）的幻觉（即视觉内容与生成文本之间的不匹配）会损害其可靠性。现有的检测方法计算成本高且延迟大。

Method: 训练传统的机器学习模型，利用VLM的下一词元概率（NTP）信号来检测幻觉。NTP直接量化模型的不确定性，我们假设高不确定性（低NTP值）与幻觉强相关。构建了一个包含1400个标注语句的数据集来测试此方法。此外，还结合了仅基于生成文本计算的语言NTP，并集成了VLM的幻觉预测分数。

Result: 基于NTP的轻量级方法能够实现与强VLM相当的性能。结合语言NTP和VLM的幻觉预测分数可以进一步提升检测效果。

Conclusion: NTP是预测幻觉的有效特征，基于NTP的轻量级模型能够快速、简单地实现与强VLM相当的性能。这种方法有望为提高VLM的可靠性提供简单、轻量级的解决方案。

Abstract: Hallucinations of vision-language models (VLMs), which are misalignments
between visual content and generated text, undermine the reliability of VLMs.
One common approach for detecting them employs the same VLM, or a different
one, to assess generated outputs. This process is computationally intensive and
increases model latency. In this paper, we explore an efficient on-the-fly
method for hallucination detection by training traditional ML models over
signals based on the VLM's next-token probabilities (NTPs). NTPs provide a
direct quantification of model uncertainty. We hypothesize that high
uncertainty (i.e., a low NTP value) is strongly associated with hallucinations.
To test this, we introduce a dataset of 1,400 human-annotated statements
derived from VLM-generated content, each labeled as hallucinated or not, and
use it to test our NTP-based lightweight method. Our results demonstrate that
NTP-based features are valuable predictors of hallucinations, enabling fast and
simple ML models to achieve performance comparable to that of strong VLMs.
Furthermore, augmenting these NTPs with linguistic NTPs, computed by feeding
only the generated text back into the VLM, enhances hallucination detection
performance. Finally, integrating hallucination prediction scores from VLMs
into the NTP-based models led to better performance than using either VLMs or
NTPs alone. We hope this study paves the way for simple, lightweight solutions
that enhance the reliability of VLMs.

</details>


### [2] [Quasi-Synthetic Riemannian Data Generation for Writer-Independent Offline Signature Verification](https://arxiv.org/abs/2509.20420)
*Elias N. Zois,Moises Diaz,Salem Said,Miguel A. Ferrer*

Main category: cs.CV

TL;DR: 提出了一种利用对称正定矩阵（SPD）的黎曼几何的准合成数据生成框架，用于离线手写签名验证，特别是在区分不同书写者的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的手写签名验证方法通常依赖真实数据集进行分类器训练，而离线独立书写者签名验证是一个挑战性问题，需要模型泛化到未见过的人。先前的研究强调了几何不变性表征（如黎曼流形上的协方差描述符）的优势。

Method: 提出一个准合成数据生成框架，该框架利用对称正定（SPD）矩阵的黎曼几何。首先，在SPD空间中用少量真实签名样本作为种子，构建黎曼高斯混合模型，识别出合成书写者及其属性（均值和方差）。然后，通过在每个中心进行黎曼高斯采样，生成合成的SPD数据。最后，利用度量学习框架处理成对的相似和不相似的SPD点，并在真实数据集上进行测试。

Result: 在两个包含西方和亚洲书写风格的常用签名数据集上进行了实验。在数据集内和跨数据集评估中，所提出的准合成方法均取得了较低的错误率。

Conclusion: 所提出的利用黎曼空间中合成数据的方法在区分不同书写者的签名验证方面具有潜力，并且在真实数据集上表现出有效性。

Abstract: Offline handwritten signature verification remains a challenging task,
particularly in writer-independent settings where models must generalize across
unseen individuals. Recent developments have highlighted the advantage of
geometrically inspired representations, such as covariance descriptors on
Riemannian manifolds. However, past or present, handcrafted or data-driven
methods usually depend on real-world signature datasets for classifier
training. We introduce a quasi-synthetic data generation framework leveraging
the Riemannian geometry of Symmetric Positive Definite matrices (SPD). A small
set of genuine samples in the SPD space is the seed to a Riemannian Gaussian
Mixture which identifies Riemannian centers as synthetic writers and variances
as their properties. Riemannian Gaussian sampling on each center generates
positive as well as negative synthetic SPD populations. A metric learning
framework utilizes pairs of similar and dissimilar SPD points, subsequently
testing it over on real-world datasets. Experiments conducted on two popular
signature datasets, encompassing Western and Asian writing styles, demonstrate
the efficacy of the proposed approach under both intra- and cross- dataset
evaluation protocols. The results indicate that our quasi-synthetic approach
achieves low error rates, highlighting the potential of generating synthetic
data in Riemannian spaces for writer-independent signature verification
systems.

</details>


### [3] [Seedream 4.0: Toward Next-generation Multimodal Image Generation](https://arxiv.org/abs/2509.20427)
*Team Seedream,Yunpeng Chen,Yu Gao,Lixue Gong,Meng Guo,Qiushan Guo,Zhiyao Guo,Xiaoxia Hou,Weilin Huang,Yixuan Huang,Xiaowen Jian,Huafeng Kuang,Zhichao Lai,Fanshi Li,Liang Li,Xiaochen Lian,Chao Liao,Liyang Liu,Wei Liu,Yanzuo Lu,Zhengxiong Luo,Tongtong Ou,Guang Shi,Yichun Shi,Shiqi Sun,Yu Tian,Zhi Tian,Peng Wang,Rui Wang,Xun Wang,Ye Wang,Guofeng Wu,Jie Wu,Wenxu Wu,Yonghui Wu,Xin Xia,Xuefeng Xiao,Shuang Xu,Xin Yan,Ceyuan Yang,Jianchao Yang,Zhonghua Zhai,Chenlin Zhang,Heng Zhang,Qi Zhang,Xinyu Zhang,Yuwei Zhang,Shijia Zhao,Wenliang Zhao,Wenjia Zhu*

Main category: cs.CV

TL;DR: Seedream 4.0 是一个统一了文本到图像生成、图像编辑和多图像组合的}('multimodal image generation system')。它使用高效的扩散 Transformer 和 VAE，能够快速生成高分辨率图像（1K-4K）。该模型在数十亿文本-图像对上进行了预训练，并通过多模态微调进行了优化，同时支持文本到图像和图像编辑任务。通过集成多种推理加速技术，Seedream 4.0 可以在 1.8 秒内生成 2K 图像。评估结果表明，Seedream 4.0 在文本到图像和多模态图像编辑方面均达到 state-of-the-art 水平，尤其在复杂的图像编辑和推理任务中表现出色，并支持多图像参考和生成。


<details>
  <summary>Details</summary>
Motivation: 为了开发一个能够统一文本到图像生成、图像编辑和多图像组合的高效、高性能多模态图像生成系统，以扩展传统文本到图像系统的能力，使其成为更具交互性和多维度的创意工具，满足创意和专业应用的需求。

Method: 1. 开发了一个高效的扩散 Transformer 和强大的 VAE，以减少图像 token 数量，实现高效训练和快速生成高分辨率（1K-4K）图像。
2. 在数十亿文本-图像对上进行预训练，涵盖多样化的分类和知识密集型概念。
3. 通过多模态微调，联合训练文本到图像和图像编辑任务。
4. 集成了对抗性蒸馏、分布匹配、量化和猜测解码等技术进行推理加速。
5. 实现了高达 1.8 秒生成 2K 图像的推理速度（不含 LLM/VLM 作为 PE 模型）。

Result: Seedream 4.0 在文本到图像和多模态图像编辑方面取得了 state-of-the-art 的结果。在复杂的任务中，如精确图像编辑和上下文推理，展现了卓越的多模态能力。此外，它还支持多图像参考和生成多个输出图像。

Conclusion: Seedream 4.0 成功地将文本到图像系统扩展为一个更具交互性和多维度的创意工具，通过其统一的框架、高效的性能和卓越的多模态能力，推动了生成式 AI 在创意和专业领域的应用边界。

Abstract: We introduce Seedream 4.0, an efficient and high-performance multimodal image
generation system that unifies text-to-image (T2I) synthesis, image editing,
and multi-image composition within a single framework. We develop a highly
efficient diffusion transformer with a powerful VAE which also can reduce the
number of image tokens considerably. This allows for efficient training of our
model, and enables it to fast generate native high-resolution images (e.g.,
1K-4K). Seedream 4.0 is pretrained on billions of text-image pairs spanning
diverse taxonomies and knowledge-centric concepts. Comprehensive data
collection across hundreds of vertical scenarios, coupled with optimized
strategies, ensures stable and large-scale training, with strong
generalization. By incorporating a carefully fine-tuned VLM model, we perform
multi-modal post-training for training both T2I and image editing tasks
jointly. For inference acceleration, we integrate adversarial distillation,
distribution matching, and quantization, as well as speculative decoding. It
achieves an inference time of up to 1.8 seconds for generating a 2K image
(without a LLM/VLM as PE model). Comprehensive evaluations reveal that Seedream
4.0 can achieve state-of-the-art results on both T2I and multimodal image
editing. In particular, it demonstrates exceptional multimodal capabilities in
complex tasks, including precise image editing and in-context reasoning, and
also allows for multi-image reference, and can generate multiple output images.
This extends traditional T2I systems into an more interactive and
multidimensional creative tool, pushing the boundary of generative AI for both
creativity and professional applications. Seedream 4.0 is now accessible on
https://www.volcengine.com/experience/ark?launch=seedream.

</details>


### [4] [A Contrastive Learning Framework for Breast Cancer Detection](https://arxiv.org/abs/2509.20474)
*Samia Saeed,Khuram Naveed*

Main category: cs.CV

TL;DR: 利用对比学习框架在标记数据有限的情况下提高乳腺癌检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 早期检测乳腺癌对于降低死亡率至关重要，但传统的计算机辅助检测（CAD）系统依赖于图像分析，而深度学习方法虽然更有效，却面临标记数据集不足的挑战。

Method: 研究人员开发了一种半监督对比学习（CL）框架，使用Resnet-50模型，在大量未标记的乳腺X线摄影数据上进行训练，并利用相似性指标、各种增强和变换来提高性能，最后在少量标记数据上进行微调。

Result: 所提出的对比学习框架在标记数据有限的情况下，在基准数据集INbreast和MIAS上实现了96.7%的乳腺癌检测准确率，优于现有的最先进技术。

Conclusion: 对比学习框架能够有效解决标记数据不足的问题，在乳腺癌检测方面取得了优于现有方法的性能。

Abstract: Breast cancer, the second leading cause of cancer-related deaths globally,
accounts for a quarter of all cancer cases [1]. To lower this death rate, it is
crucial to detect tumors early, as early-stage detection significantly improves
treatment outcomes. Advances in non-invasive imaging techniques have made early
detection possible through computer-aided detection (CAD) systems which rely on
traditional image analysis to identify malignancies. However, there is a
growing shift towards deep learning methods due to their superior
effectiveness. Despite their potential, deep learning methods often struggle
with accuracy due to the limited availability of large-labeled datasets for
training. To address this issue, our study introduces a Contrastive Learning
(CL) framework, which excels with smaller labeled datasets. In this regard, we
train Resnet-50 in semi supervised CL approach using similarity index on a
large amount of unlabeled mammogram data. In this regard, we use various
augmentation and transformations which help improve the performance of our
approach. Finally, we tune our model on a small set of labelled data that
outperforms the existing state of the art. Specifically, we observed a 96.7%
accuracy in detecting breast cancer on benchmark datasets INbreast and MIAS.

</details>


### [5] [Are Foundation Models Ready for Industrial Defect Recognition? A Reality Check on Real-World Data](https://arxiv.org/abs/2509.20479)
*Simon Baeuerle,Pratik Khanna,Nils Friederich,Angelo Jovin Yamachui Sitcheu,Damir Shakirov,Andreas Steimer,Ralf Mikut*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Foundation Models (FMs) have shown impressive performance on various text and
image processing tasks. They can generalize across domains and datasets in a
zero-shot setting. This could make them suitable for automated quality
inspection during series manufacturing, where various types of images are being
evaluated for many different products. Replacing tedious labeling tasks with a
simple text prompt to describe anomalies and utilizing the same models across
many products would save significant efforts during model setup and
implementation. This is a strong advantage over supervised Artificial
Intelligence (AI) models, which are trained for individual applications and
require labeled training data. We test multiple recent FMs on both custom
real-world industrial image data and public image data. We show that all of
those models fail on our real-world data, while the very same models perform
well on public benchmark datasets.

</details>


### [6] [Shared Neural Space: Unified Precomputed Feature Encoding for Multi-Task and Cross Domain Vision](https://arxiv.org/abs/2509.20481)
*Jing Li,Oskar Bartosz,Chengyu Wang,Michal Wnuczynski,Dilshan Godaliyadda,Michael Polley*

Main category: cs.CV

TL;DR: 提出了一种通用的神经空间（NS），该空间包含一个编码器-解码器框架，可以跨视觉和成像任务预计算特征，以提高效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有AI模型在执行一系列模块化任务时效率低下的问题，因为每个任务都需要映射到一个不同的潜在域。

Method: 设计了一个通用的神经空间（NS），采用编码器-解码器框架，其中编码器学习跨任务的、可泛化的表征，使多个下游AI模块共享同一特征空间。该骨干网络是轻量级的、基于CNN的。

Result: 该NS减少了冗余，提高了跨域迁移的泛化能力，并支持高效的多任务视觉处理。同时，也实现了如色彩还原、去噪、深度估计和语义分割等任务。

Conclusion: 所提出的NS架构能够有效地处理多个计算机视觉任务，并且由于其轻量级CNN骨干的特性，能够广泛地应用于各种硬件设备。

Abstract: The majority of AI models in imaging and vision are customized to perform on
specific high-precision task. However, this strategy is inefficient for
applications with a series of modular tasks, since each requires a mapping into
a disparate latent domain. To address this inefficiency, we proposed a
universal Neural Space (NS), where an encoder-decoder framework pre-computes
features across vision and imaging tasks. Our encoder learns transformation
aware, generalizable representations, which enable multiple downstream AI
modules to share the same feature space. This architecture reduces redundancy,
improves generalization across domain shift, and establishes a foundation for
effecient multi-task vision pipelines. Furthermore, as opposed to larger
transformer backbones, our backbone is lightweight and CNN-based, allowing for
wider across hardware. We furthur demonstrate that imaging and vision modules,
such as demosaicing, denoising, depth estimation and semantic segmentation can
be performed efficiently in the NS.

</details>


### [7] [Data-Efficient Stream-Based Active Distillation for Scalable Edge Model Deployment](https://arxiv.org/abs/2509.20484)
*Dani Manjah,Tim Bary,Benoît Gérin,Benoît Macq,Christophe de Vleeschouwer*

Main category: cs.CV

TL;DR: 该研究提出了一种结合高置信度和多样性策略的图像选择方法，以最小化数据集查询次数并提升边缘摄像头系统的模型质量。


<details>
  <summary>Details</summary>
Motivation: 边缘摄像头系统需要适应不断变化的环境，这要求对模型进行频繁更新。然而，使用中心服务器上的复杂模型对数据进行标注以训练边缘设备上的小型模型，面临着如何在保证模型质量的同时降低传输成本的挑战。

Method: 提出了一种结合高置信度流和多样性策略的图像选择方法，用于选择最有用的图像进行模型训练。

Result: 与仅使用高置信度策略相比，该方法在相似的训练负载下，能够用更少的查询次数生成更高质量的模型。

Conclusion: 结合高置信度和多样性策略的图像选择方法，可以在最小化数据集查询次数的同时，提升边缘摄像头系统的模型质量。

Abstract: Edge camera-based systems are continuously expanding, facing ever-evolving
environments that require regular model updates. In practice, complex teacher
models are run on a central server to annotate data, which is then used to
train smaller models tailored to the edge devices with limited computational
power. This work explores how to select the most useful images for training to
maximize model quality while keeping transmission costs low. Our work shows
that, for a similar training load (i.e., iterations), a high-confidence
stream-based strategy coupled with a diversity-based approach produces a
high-quality model with minimal dataset queries.

</details>


### [8] [InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On](https://arxiv.org/abs/2509.20524)
*Julien Han,Shuwen Qiu,Qi Li,Xingzi Xu,Mehmet Saygin Seyfioglu,Kavosh Asadi,Karim Bouyarmane*

Main category: cs.CV

TL;DR: InstructVTON是一个基于指令的虚拟试穿系统，利用VLM和分割模型自动生成掩码，实现精细化的服装造型控制，无需手动绘制掩码。


<details>
  <summary>Details</summary>
Motivation: 现有的基于掩码的虚拟试穿方法在生成掩码时存在困难，且无法处理复杂的造型需求，限制了用户体验和生成效果。

Method: InstructVTON利用视觉语言模型（VLM）和图像分割模型，根据用户提供的图像和文本指令自动生成用于虚拟试穿的二值掩码。该系统将虚拟试穿问题转化为图像引导或图像条件化的修复任务。

Result: InstructVTON能够简化用户操作，消除手动绘制精确掩码的需要，并能自动执行多轮图像生成以处理复杂的试穿场景。该系统可与现有虚拟试穿模型结合，实现具有造型控制能力的先进结果。

Conclusion: InstructVTON通过自动化掩码生成和支持复杂的造型指令，显著改进了虚拟试穿的用户体验和效果，并能与现有模型集成以达到最先进的性能。

Abstract: We present InstructVTON, an instruction-following interactive virtual try-on
system that allows fine-grained and complex styling control of the resulting
generation, guided by natural language, on single or multiple garments. A
computationally efficient and scalable formulation of virtual try-on formulates
the problem as an image-guided or image-conditioned inpainting task. These
inpainting-based virtual try-on models commonly use a binary mask to control
the generation layout. Producing a mask that yields desirable result is
difficult, requires background knowledge, might be model dependent, and in some
cases impossible with the masking-based approach (e.g. trying on a long-sleeve
shirt with "sleeves rolled up" styling on a person wearing long-sleeve shirt
with sleeves down, where the mask will necessarily cover the entire sleeve).
InstructVTON leverages Vision Language Models (VLMs) and image segmentation
models for automated binary mask generation. These masks are generated based on
user-provided images and free-text style instructions. InstructVTON simplifies
the end-user experience by removing the necessity of a precisely drawn mask,
and by automating execution of multiple rounds of image generation for try-on
scenarios that cannot be achieved with masking-based virtual try-on models
alone. We show that InstructVTON is interoperable with existing virtual try-on
models to achieve state-of-the-art results with styling control.

</details>


### [9] [Innovative Deep Learning Architecture for Enhanced Altered Fingerprint Recognition](https://arxiv.org/abs/2509.20537)
*Dana A Abdullah,Dana Rasul Hamad,Bishar Rasheed Ibrahim,Sirwan Abdulwahid Aula,Aso Khaleel Ameen,Sabat Salih Hamadamin*

Main category: cs.CV

TL;DR: DeepAFRNet是一个深度学习模型，用于识别经过篡改的指纹，在简单、中等和困难三个难度级别上分别达到了96.7%、98.76%和99.54%的准确率，强调了阈值选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了应对边境管制、法证和财政准入等应用中，对抗者可能故意修改指纹模式以逃避检测的挑战，需要鲁棒的识别经过篡改的指纹的方法。

Method: 提出了一种名为DeepAFRNet的深度学习模型，该模型使用VGG16骨干提取高维特征，并使用余弦相似度比较嵌入。

Result: 在SOCOFing Real-Altered数据集上，DeepAFRNet在Easy、Medium和Hard三个难度级别上分别取得了96.7%、98.76%和99.54%的准确率。阈值敏感性研究表明，将阈值从0.92放松到0.72会导致准确率急剧下降至7.86%、27.05%和29.51%。

Conclusion: DeepAFRNet模型能够有效地匹配和识别经过篡改的指纹样本，并在真实数据集上表现出高准确率，表明其在真实世界部署中的潜力。然而，阈值的选择对系统的性能至关重要。该研究通过使用真实篡改样本并报告分级别指标，解决了先前基于合成篡改或有限验证协议的工作的局限性。

Abstract: Altered fingerprint recognition (AFR) is challenging for biometric
verification in applications such as border control, forensics, and fiscal
admission. Adversaries can deliberately modify ridge patterns to evade
detection, so robust recognition of altered prints is essential. We present
DeepAFRNet, a deep learning recognition model that matches and recognizes
distorted fingerprint samples. The approach uses a VGG16 backbone to extract
high-dimensional features and cosine similarity to compare embeddings. We
evaluate on the SOCOFing Real-Altered subset with three difficulty levels
(Easy, Medium, Hard). With strict thresholds, DeepAFRNet achieves accuracies of
96.7 percent, 98.76 percent, and 99.54 percent for the three levels. A
threshold-sensitivity study shows that relaxing the threshold from 0.92 to 0.72
sharply degrades accuracy to 7.86 percent, 27.05 percent, and 29.51 percent,
underscoring the importance of threshold selection in biometric systems. By
using real altered samples and reporting per-level metrics, DeepAFRNet
addresses limitations of prior work based on synthetic alterations or limited
verification protocols, and indicates readiness for real-world deployments
where both security and recognition resilience are critical.

</details>


### [10] [Large Pre-Trained Models for Bimanual Manipulation in 3D](https://arxiv.org/abs/2509.20579)
*Hanna Yurchyk,Wei-Di Chang,Gregory Dudek,David Meger*

Main category: cs.CV

TL;DR: 通过将预训练 Vision Transformer 的注意力图集成到体素表示中，以增强双臂机器人操作。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人操作方法在理解和利用视觉信息方面存在局限性，这阻碍了它们在复杂任务中的性能。

Method: 我们提出了一种新颖的方法，将来自预训练 Vision Transformer（DINOv2）的注意力图提取并转化为体素表示。这些注意力图被提升到 3D 体素网格中，作为像素级显着性分数，为行为克隆策略提供语义线索。

Result: 与最先进的基于体素的策略相比，我们集成的注意力引导特征化在 RLBench 双臂基准的所有任务中产生了平均 8.2% 的绝对改进和 21.9% 的相对收益。

Conclusion: 将预训练 ViT 的注意力图集成到体素表示中可以显着提高双臂机器人操作的性能，为机器人提供更丰富的语义理解。

Abstract: We investigate the integration of attention maps from a pre-trained Vision
Transformer into voxel representations to enhance bimanual robotic
manipulation. Specifically, we extract attention maps from DINOv2, a
self-supervised ViT model, and interpret them as pixel-level saliency scores
over RGB images. These maps are lifted into a 3D voxel grid, resulting in
voxel-level semantic cues that are incorporated into a behavior cloning policy.
When integrated into a state-of-the-art voxel-based policy, our
attention-guided featurization yields an average absolute improvement of 8.2%
and a relative gain of 21.9% across all tasks in the RLBench bimanual
benchmark.

</details>


### [11] [A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management](https://arxiv.org/abs/2509.20580)
*Xinyang Mu,Yuzhen Lu,Boyang Deng*

Main category: cs.CV

TL;DR: 该研究对 YOLO (v8-v12) 和 RT-DETR (v1-v2) 系列中的 36 种先进实时对象检测器进行了基准测试，用于在各种条件下检测蓝莓。研究人员创建了一个包含 661 张智能手机图像和 85,879 个标注实例的新数据集。通过使用半监督学习 (SSL) 对模型进行微调，进一步提高了检测精度。RT-DETRv2-X 在微调后达到最高的 mAP@50 94.8%，表明了其在蓝莓检测方面的潜力。研究强调了 SSL 在利用跨领域无标签数据方面的潜力，并公开了数据集和软件。


<details>
  <summary>Details</summary>
Motivation: 蓝莓在自然环境中的检测面临光照变化、遮挡和运动模糊等挑战，需要大规模、多样化的数据集和能在精度/速度/内存之间取得平衡的模型。本研究旨在为蓝莓检测提供一个全面的基准分析，并探索半监督学习的改进潜力。

Method: 研究人员构建了一个包含 661 张智能手机图像（85,879 个标注实例）的新蓝莓检测数据集。对 YOLO (v8-v12) 和 RT-DETR (v1-v2) 系列共 36 种模型变体进行了评估。随后，利用一个包含 1,035 张来自地面机器视觉平台的无标签图像的独立数据集，通过基于无偏教师的半监督学习 (SSL) 对所有模型进行了微调。

Result: 在未微调的模型中，YOLOv12m 的 mAP@50 为 93.3%，RT-DETRv2-X 的 mAP@50 为 93.6%。微调后，RT-DETR-v2-X 的 mAP@50 提升至 94.8%，是所有模型中最好的。精度提升幅度在 -1.4% 到 2.9% 之间。中等规模的模型在精度和速度之间取得了较好的平衡。

Conclusion: RT-DETRv2-X 在经过半监督学习微调后，在蓝莓检测任务上表现出最佳性能。研究表明，半监督学习可以有效提升模型在跨领域数据上的检测精度，但仍需要进一步研究以更好地利用跨领域无标签数据。该研究公开了数据集和相关软件，以促进未来的研究。

Abstract: Blueberry detection in natural environments remains challenging due to
variable lighting, occlusions, and motion blur due to environmental factors and
imaging devices. Deep learning-based object detectors promise to address these
challenges, but they demand a large-scale, diverse dataset that captures the
real-world complexities. Moreover, deploying these models in practical
scenarios often requires the right accuracy/speed/memory trade-off in model
selection. This study presents a novel comparative benchmark analysis of
advanced real-time object detectors, including YOLO (You Only Look Once)
(v8-v12) and RT-DETR (Real-Time Detection Transformers) (v1-v2) families,
consisting of 36 model variants, evaluated on a newly curated dataset for
blueberry detection. This dataset comprises 661 canopy images collected with
smartphones during the 2022-2023 seasons, consisting of 85,879 labelled
instances (including 36,256 ripe and 49,623 unripe blueberries) across a wide
range of lighting conditions, occlusions, and fruit maturity stages. Among the
YOLO models, YOLOv12m achieved the best accuracy with a mAP@50 of 93.3%, while
RT-DETRv2-X obtained a mAP@50 of 93.6%, the highest among all the RT-DETR
variants. The inference time varied with the model scale and complexity, and
the mid-sized models appeared to offer a good accuracy-speed balance. To
further enhance detection performance, all the models were fine-tuned using
Unbiased Mean Teacher-based semi-supervised learning (SSL) on a separate set of
1,035 unlabeled images acquired by a ground-based machine vision platform in
2024. This resulted in accuracy gains ranging from -1.4% to 2.9%, with
RT-DETR-v2-X achieving the best mAP@50 of 94.8%. More in-depth research into
SSL is needed to better leverage cross-domain unlabeled data. Both the dataset
and software programs of this study are made publicly available to support
further research.

</details>


### [12] [Region-of-Interest Augmentation for Mammography Classification under Patient-Level Cross-Validation](https://arxiv.org/abs/2509.20585)
*Farbod Bigdeli,Mohsen Mohammadagha,Ali Bigdeli*

Main category: cs.CV

TL;DR: 通过引入轻量级的感兴趣区域(ROI)增强策略，在有限的数据集和样本量下提升了乳腺X光检查的分类性能，而没有增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在乳腺X光检查解释方面表现出巨大潜力，但受限于低分辨率数据集和小的样本量。本研究旨在克服这些限制，提高模型的性能。

Method: 在训练过程中，采用一种轻量级的感兴趣区域(ROI)增强策略，通过从预先计算的、无标签的边界框库中概率性地替换随机ROI裁剪来增强训练数据。此外，还提供了可选的抖动以增加变化性。

Result: 在Mini-DDSM数据集上，ROI增强策略（最佳参数：p_roi = 0.10, alpha = 0.10）带来了适度的平均ROC-AUC提升，但PR-AUC保持不变或略有下降。性能在不同折叠（folds）之间存在差异。

Conclusion: 简单、以数据为中心的ROI策略可以在数据受限的情况下增强乳腺X光检查的分类能力，而无需额外的标签或架构修改。

Abstract: Breast cancer screening with mammography remains central to early detection
and mortality reduction. Deep learning has shown strong potential for
automating mammogram interpretation, yet limited-resolution datasets and small
sample sizes continue to restrict performance. We revisit the Mini-DDSM dataset
(9,684 images; 2,414 patients) and introduce a lightweight region-of-interest
(ROI) augmentation strategy. During training, full images are probabilistically
replaced with random ROI crops sampled from a precomputed, label-free
bounding-box bank, with optional jitter to increase variability. We evaluate
under strict patient-level cross-validation and report ROC-AUC, PR-AUC, and
training-time efficiency metrics (throughput and GPU memory). Because ROI
augmentation is training-only, inference-time cost remains unchanged. On
Mini-DDSM, ROI augmentation (best: p_roi = 0.10, alpha = 0.10) yields modest
average ROC-AUC gains, with performance varying across folds; PR-AUC is flat to
slightly lower. These results demonstrate that simple, data-centric ROI
strategies can enhance mammography classification in constrained settings
without requiring additional labels or architectural modifications.

</details>


### [13] [Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections](https://arxiv.org/abs/2509.20607)
*Jing Wu,Zirui Wang,Iro Laina,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: 从单一图像生成多视角立体信息，用于3D重建。


<details>
  <summary>Details</summary>
Motivation: 利用镜像反射提供额外的视点信息，实现单图像多视角立体匹配。

Method: 设计一个物理上有效的虚拟相机变换，直接在像素域生成虚拟视角，并引入对称感知损失来优化位姿估计。

Result: 提出了一种单图像多视角立体重建框架，能够处理动态场景，并在合成和真实世界数据上进行了广泛的实验验证。

Conclusion: 该方法通过利用镜像反射简化了成像过程，提高了3D重建的通用性和鲁棒性。

Abstract: Mirror reflections are common in everyday environments and can provide stereo
information within a single capture, as the real and reflected virtual views
are visible simultaneously. We exploit this property by treating the reflection
as an auxiliary view and designing a transformation that constructs a
physically valid virtual camera, allowing direct pixel-domain generation of the
virtual view while adhering to the real-world imaging process. This enables a
multi-view stereo setup from a single image, simplifying the imaging process,
making it compatible with powerful feed-forward reconstruction models for
generalizable and robust 3D reconstruction. To further exploit the geometric
symmetry introduced by mirrors, we propose a symmetric-aware loss to refine
pose estimation. Our framework also naturally extends to dynamic scenes, where
each frame contains a mirror reflection, enabling efficient per-frame geometry
recovery. For quantitative evaluation, we provide a fully customizable
synthetic dataset of 16 Blender scenes, each with ground-truth point clouds and
camera poses. Extensive experiments on real-world data and synthetic data are
conducted to illustrate the effectiveness of our method.

</details>


### [14] [Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery](https://arxiv.org/abs/2509.20628)
*Yiming Xiao,Archit Gupta,Miguel Esparza,Yu-Hsuan Ho,Antonia Sebastian,Hannah Weas,Rose Houck,Ali Mostafavi*

Main category: cs.CV

TL;DR: FacadeTrack是一个街道级的、语言引导的框架，用于将全景视频链接到地块，纠正视图到立面，并引发可解释的属性（例如，入口堵塞、临时覆盖物、局部碎片），以驱动两种决策策略：一种透明的单阶段规则和一种将感知与保守推理分开的两阶段设计。该框架在两次飓风海伦后的调查中进行了评估，两阶段方法实现了0.927的精度、0.781的召回率和0.848的F-1分数，而单阶段基线为0.943的精度、0.728的召回率和0.822的F-1分数。


<details>
  <summary>Details</summary>
Motivation: 灾后建筑级别的入住率对于分类、检查、公用事业重新通电和公平资源分配至关重要。现有的方法（如高空图像）覆盖范围快，但可能错过决定宜居性的立面和入口线索；街道图像能捕捉这些细节，但数据稀疏且难以与地块对齐。

Method: 提出FacadeTrack框架，该框架利用街道全景视频，通过语言引导将其链接到地块，并将视角校正到建筑立面。该框架旨在提取可解释的属性（如入口堵塞、临时覆盖物、局部碎片），并基于这些属性应用两种决策策略：一种是简单的单阶段规则，另一种是区分感知和推理的两阶段设计。

Result: 在两次飓风海伦后的调查中，两阶段的FacadeTrack方法达到了0.927的精确率、0.781的召回率和0.848的F-1分数。相比之下，单阶段基线方法的精确率为0.943、召回率为0.728，F-1分数为0.822。此外，该框架还能提供中间属性和空间诊断，以揭示误差发生的位置和原因，从而实现有针对性的质量控制。

Conclusion: FacadeTrack框架能够进行可审计、可扩展的入住率评估，适用于地理空间和应急管理工作流程。该方法通过整合街道视频和可解释的属性，克服了传统方法的局限性，提高了灾后评估的准确性和透明度。

Abstract: Building-level occupancy after disasters is vital for triage, inspections,
utility re-energization, and equitable resource allocation. Overhead imagery
provides rapid coverage but often misses facade and access cues that determine
habitability, while street-view imagery captures those details but is sparse
and difficult to align with parcels. We present FacadeTrack, a street-level,
language-guided framework that links panoramic video to parcels, rectifies
views to facades, and elicits interpretable attributes (for example, entry
blockage, temporary coverings, localized debris) that drive two decision
strategies: a transparent one-stage rule and a two-stage design that separates
perception from conservative reasoning. Evaluated across two post-Hurricane
Helene surveys, the two-stage approach achieves a precision of 0.927, a recall
of 0.781, and an F-1 score of 0.848, compared with the one-stage baseline at a
precision of 0.943, a recall of 0.728, and an F-1 score of 0.822. Beyond
accuracy, intermediate attributes and spatial diagnostics reveal where and why
residual errors occur, enabling targeted quality control. The pipeline provides
auditable, scalable occupancy assessments suitable for integration into
geospatial and emergency-management workflows.

</details>


### [15] [Human Semantic Representations of Social Interactions from Moving Shapes](https://arxiv.org/abs/2509.20673)
*Yiling Yun,Hongjing Lu*

Main category: cs.CV

TL;DR: 人类通过视觉和语义信息来感知社会互动。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探究人类在识别简单动画中的社会互动时，除了视觉特征外，还依赖于何种语义表征。

Method: 研究包含两个部分：第一部分，要求参与者直接标注动画；第二部分，通过参与者对27种社会互动的相似度判断，并与基于视觉特征、标签和语义嵌入的模型预测进行比较。

Result: 研究发现，参与者的标注呈现分布性；语义模型（尤其是基于动词的嵌入）能补充视觉特征，更好地解释人类的相似度判断。

Conclusion: 简单的动画显示中的社会感知反映了社会互动的语义结构，连接了视觉和抽象表征。

Abstract: Humans are social creatures who readily recognize various social interactions
from simple display of moving shapes. While previous research has often focused
on visual features, we examine what semantic representations that humans employ
to complement visual features. In Study 1, we directly asked human participants
to label the animations based on their impression of moving shapes. We found
that human responses were distributed. In Study 2, we measured the
representational geometry of 27 social interactions through human similarity
judgments and compared it with model predictions based on visual features,
labels, and semantic embeddings from animation descriptions. We found that
semantic models provided complementary information to visual features in
explaining human judgments. Among the semantic models, verb-based embeddings
extracted from descriptions account for human similarity judgments the best.
These results suggest that social perception in simple displays reflects the
semantic structure of social interactions, bridging visual and abstract
representations.

</details>


### [16] [Enhancing Cross-View Geo-Localization Generalization via Global-Local Consistency and Geometric Equivariance](https://arxiv.org/abs/2509.20684)
*Xiaowei Wang,Di Wang,Ke Li,Yifeng Wang,Chengjian Wang,Libin Sun,Zhihong Wu,Yiming Zhang,Quan Wang*

Main category: cs.CV

TL;DR: EGS是一个新的跨视图地理定位框架，使用E(2)-可定向CNN和带虚拟超节点的图来提高跨域泛化能力，并在基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图地理定位方法在处理无人机视点和视场角变化引起的剧烈外观变化以及建立包含全局和局部信息的可靠对应关系方面仍面临挑战。

Method: 提出EGS框架，采用E(2)-可定向CNN提取旋转和视点变化下稳定的特征，并构建包含虚拟超节点的图以聚合和重新分配全局语义到局部区域，强制实现全局-局部一致性。

Result: 在University-1652和SUES-200基准测试上进行了广泛的实验，结果表明EGS在跨域CVGL方面取得了显著的性能提升，并创下了新的最先进记录。

Conclusion: EGS框架通过引入E(2)-可定向CNN和基于图的全局-局部一致性强制机制，有效解决了跨视图地理定位中的外观变化和全局-局部信息融合问题，显著提升了跨域泛化能力。

Abstract: Cross-view geo-localization (CVGL) aims to match images of the same location
captured from drastically different viewpoints. Despite recent progress,
existing methods still face two key challenges: (1) achieving robustness under
severe appearance variations induced by diverse UAV orientations and fields of
view, which hinders cross-domain generalization, and (2) establishing reliable
correspondences that capture both global scene-level semantics and fine-grained
local details. In this paper, we propose EGS, a novel CVGL framework designed
to enhance cross-domain generalization. Specifically, we introduce an
E(2)-Steerable CNN encoder to extract stable and reliable features under
rotation and viewpoint shifts. Furthermore, we construct a graph with a virtual
super-node that connects to all local nodes, enabling global semantics to be
aggregated and redistributed to local regions, thereby enforcing global-local
consistency. Extensive experiments on the University-1652 and SUES-200
benchmarks demonstrate that EGS consistently achieves substantial performance
gains and establishes a new state of the art in cross-domain CVGL.

</details>


### [17] [DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection](https://arxiv.org/abs/2509.20701)
*Jiayi Zuo,Songwei Pei,Qian Li*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的双路径边缘网络（Dual-Path Edge Network）来解决红外小目标检测中的挑战。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测至关重要，但小目标缺乏明显纹理和形态特征，易与背景混淆。现有深度模型难以同时捕捉小目标的细节和背景的语义信息，导致特征不对齐和性能不佳。现有方法依赖固定的梯度算子或简单的注意力机制，在低对比度和高噪声下难以精确提取目标边缘。

Method: 提出了一种双路径边缘网络（Dual-Path Edge Network），将边缘增强和语义建模解耦到两个互补的处理路径中。第一条路径使用双向交互模块（Bidirectional Interaction Module），结合局部自注意力和全局自注意力（基于Transformer）来捕获多尺度特征依赖关系和长距离语义信息。第二条路径引入多尺度边缘细化器（Multi-Edge Refiner），利用泰勒有限差分算子和注意力门控机制来增强边缘细节并抑制噪声。

Result: 该方法在统一框架中结合了结构语义和边缘细化，为精确的红外小目标检测和定位提供了一种有效的解决方案。

Conclusion: 所提出的双路径边缘网络能够有效解决红外小目标检测中的挑战，通过分离和增强边缘信息与语义信息，提高了检测精度。

Abstract: Infrared small target detection is crucial for remote sensing applications
like disaster warning and maritime surveillance. However, due to the lack of
distinctive texture and morphological features, infrared small targets are
highly susceptible to blending into cluttered and noisy backgrounds. A
fundamental challenge in designing deep models for this task lies in the
inherent conflict between capturing high-resolution spatial details for minute
targets and extracting robust semantic context for larger targets, often
leading to feature misalignment and suboptimal performance. Existing methods
often rely on fixed gradient operators or simplistic attention mechanisms,
which are inadequate for accurately extracting target edges under low contrast
and high noise. In this paper, we propose a novel Dual-Path Edge Network that
explicitly addresses this challenge by decoupling edge enhancement and semantic
modeling into two complementary processing paths. The first path employs a
Bidirectional Interaction Module, which uses both Local Self-Attention and
Global Self-Attention to capture multi-scale local and global feature
dependencies. The global attention mechanism, based on a Transformer
architecture, integrates long-range semantic relationships and contextual
information, ensuring robust scene understanding. The second path introduces
the Multi-Edge Refiner, which enhances fine-grained edge details using cascaded
Taylor finite difference operators at multiple scales. This mathematical
approach, along with an attention-driven gating mechanism, enables precise edge
localization and feature enhancement for targets of varying sizes, while
effectively suppressing noise. Our method provides a promising solution for
precise infrared small target detection and localization, combining structural
semantics and edge refinement in a unified framework.

</details>


### [18] [Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset](https://arxiv.org/abs/2509.20715)
*Ruixu Zhang,Yuran Wang,Xinyi Hu,Chaoyu Mai,Wenxuan Liu,Danni Xu,Xian Zhong,Zheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的集体意图预测任务（GIF），引入了“群体意图”的概念，并发布了首个大规模数据集SHOT以及相应的预测框架GIFT。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别忽略了集体意图的复杂性，本文旨在解决此局限性，提出集体意图预测任务。

Method: 提出“群体意图”概念，并定义了群体意图预测（GIF）任务，即通过分析个体行为和交互来预测群体意图的发生。构建了名为SHOT的数据集，包含1979个篮球视频片段，并提出了GIFT（Group Intention ForecasTer）框架来提取个体特征和模拟群体动态以预测意图的出现。

Result: 实验结果证明了SHOT数据集和GIFT框架的有效性，为未来的群体意图预测研究奠定了基础。

Conclusion: 本文成功地提出了群体意图预测任务、构建了相关数据集和预测框架，并验证了其有效性，为群体意图识别领域的研究提供了新的方向和工具。

Abstract: Intention recognition has traditionally focused on individual intentions,
overlooking the complexities of collective intentions in group settings. To
address this limitation, we introduce the concept of group intention, which
represents shared goals emerging through the actions of multiple individuals,
and Group Intention Forecasting (GIF), a novel task that forecasts when group
intentions will occur by analyzing individual actions and interactions before
the collective goal becomes apparent. To investigate GIF in a specific
scenario, we propose SHOT, the first large-scale dataset for GIF, consisting of
1,979 basketball video clips captured from 5 camera views and annotated with 6
types of individual attributes. SHOT is designed with 3 key characteristics:
multi-individual information, multi-view adaptability, and multi-level
intention, making it well-suited for studying emerging group intentions.
Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework that
extracts fine-grained individual features and models evolving group dynamics to
forecast intention emergence. Experimental results confirm the effectiveness of
SHOT and GIFT, establishing a strong foundation for future research in group
intention forecasting. The dataset is available at
https://xinyi-hu.github.io/SHOT_DATASET.

</details>


### [19] [Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection](https://arxiv.org/abs/2509.20745)
*Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang*

Main category: cs.CV

TL;DR: Neptune-X是一个数据中心生成选择框架，通过结合合成数据生成和任务感知样本选择来提高海上目标检测的训练效果，解决了数据稀疏和泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 海事目标检测对于航行安全、监视和自主操作至关重要，但面临着标注海事数据稀疏和跨不同海事属性（如目标类别、视角、位置和成像环境）泛化能力差的挑战。现有数据集训练的模型在开放海域等代表性不足的场景中表现不佳。

Method: 提出了一种名为Neptune-X的数据中心生成选择框架。该框架包括：1. X-to-Maritime，一个多模态条件生成模型，用于合成各种逼真的海事场景，并包含一个“双向对象-水注意”模块来提高视觉保真度。2. “属性相关主动采样”，动态选择与任务相关的合成样本。3. 构建了首个针对生成海事学习定制的海事生成数据集。

Result: 实验证明，该方法在海事场景合成方面树立了新的基准，显著提高了检测精度，尤其是在具有挑战性且以前代表性不足的场景中。

Conclusion: Neptune-X通过结合先进的合成数据生成和智能样本选择策略，有效解决了海事目标检测中的关键挑战，并在各种海事场景中实现了显著的性能提升。

Abstract: Maritime object detection is essential for navigation safety, surveillance,
and autonomous operations, yet constrained by two key challenges: the scarcity
of annotated maritime data and poor generalization across various maritime
attributes (e.g., object category, viewpoint, location, and imaging
environment). % In particular, models trained on existing datasets often
underperform in underrepresented scenarios such as open-sea environments. To
address these challenges, we propose Neptune-X, a data-centric
generative-selection framework that enhances training effectiveness by
leveraging synthetic data generation with task-aware sample selection. From the
generation perspective, we develop X-to-Maritime, a multi-modality-conditioned
generative model that synthesizes diverse and realistic maritime scenes. A key
component is the Bidirectional Object-Water Attention module, which captures
boundary interactions between objects and their aquatic surroundings to improve
visual fidelity. To further improve downstream tasking performance, we propose
Attribute-correlated Active Sampling, which dynamically selects synthetic
samples based on their task relevance. To support robust benchmarking, we
construct the Maritime Generation Dataset, the first dataset tailored for
generative maritime learning, encompassing a wide range of semantic conditions.
Extensive experiments demonstrate that our approach sets a new benchmark in
maritime scene synthesis, significantly improving detection accuracy,
particularly in challenging and previously underrepresented settings.The code
is available at https://github.com/gy65896/Neptune-X.

</details>


### [20] [AI-Enabled Crater-Based Navigation for Lunar Mapping](https://arxiv.org/abs/2509.20748)
*Sofia McLeod,Chee-Kheng Chng,Matthew Rodda,Tat-Jun Chin*

Main category: cs.CV

TL;DR: STELLA是一个端到端的月球测绘陨石坑导航（CBN）流程，可在长达一年的测绘任务中实现米级的定位精度和亚学位姿态精度，其性能在CRESENT-365数据集上得到了验证。


<details>
  <summary>Details</summary>
Motivation: 月球测绘任务中的航天器姿态估计比传统的动力下降和着陆任务更具挑战性，因为它们涉及稀疏、倾斜的图像，并且在各种光照条件下进行，持续时间长达一年。

Method: STELLA结合了基于Mask R-CNN的陨石坑检测器、无描述符的陨石坑识别模块、鲁棒的透视n-陨石坑姿态求解器以及批量的轨道确定后端。该研究还引入了CRESENT-365数据集，用于模拟长达一年的月球测绘任务。

Result: 在CRESENT+和CRESENT-365数据集上的实验表明，STELLA在各种视角、光照条件和月球纬度下，平均能保持米级的定位精度和亚学位姿态精度。

Conclusion: STELLA是第一个用于长时月球测绘的端到端CBN流程，在真实月球测绘环境中首次全面评估了CBN的性能，并为未来任务的运行条件提供了参考。

Abstract: Crater-Based Navigation (CBN) uses the ubiquitous impact craters of the Moon
observed on images as natural landmarks to determine the six degrees of freedom
pose of a spacecraft. To date, CBN has primarily been studied in the context of
powered descent and landing. These missions are typically short in duration,
with high-frequency imagery captured from a nadir viewpoint over well-lit
terrain. In contrast, lunar mapping missions involve sparse, oblique imagery
acquired under varying illumination conditions over potentially year-long
campaigns, posing significantly greater challenges for pose estimation. We
bridge this gap with STELLA - the first end-to-end CBN pipeline for
long-duration lunar mapping. STELLA combines a Mask R-CNN-based crater
detector, a descriptor-less crater identification module, a robust
perspective-n-crater pose solver, and a batch orbit determination back-end. To
rigorously test STELLA, we introduce CRESENT-365 - the first public dataset
that emulates a year-long lunar mapping mission. Each of its 15,283 images is
rendered from high-resolution digital elevation models with SPICE-derived Sun
angles and Moon motion, delivering realistic global coverage, illumination
cycles, and viewing geometries. Experiments on CRESENT+ and CRESENT-365 show
that STELLA maintains metre-level position accuracy and sub-degree attitude
accuracy on average across wide ranges of viewing angles, illumination
conditions, and lunar latitudes. These results constitute the first
comprehensive assessment of CBN in a true lunar mapping setting and inform
operational conditions that should be considered for future missions.

</details>


### [21] [Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models](https://arxiv.org/abs/2509.20751)
*Zoe Wanying He,Sean Trott,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 深度学习模型中的视觉和语言表示在中间层对齐，并能反映人类对图像-文本匹配的偏好，且聚合相同概念的示例会增强对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，在独立的数据集上训练的纯视觉和纯语言深度学习模型，其输出会投影到一个部分对齐的表示空间。然而，我们仍不清楚这种对齐出现的具体网络层级、视觉或语言线索如何支持它、它是否能反映人类在多对多图像-文本场景下的偏好，以及聚合同一概念的示例如何影响对齐。

Method: 通过系统性地研究对齐在模型中的具体层级、不同类型变化的鲁棒性、在多对多图像-文本匹配任务中的表现以及聚合示例对对齐的影响。

Result: 对齐在模型的中后层达到峰值，表明从特定模态到共享概念的表示转换；对齐对于外观变化具有鲁棒性，但对于语义改变（如移除对象或改变词序）则会崩溃；在“Pick-a-Pic”任务中，人类偏好与模型嵌入空间中的匹配度一致，即使在多对一和一对多映射下也是如此；聚合相同概念的示例会增强对齐。

Conclusion: 单一模态网络能够收敛到共享的语义代码，该代码与人类的判断一致，并且通过聚合示例可以得到加强。

Abstract: Recent studies show that deep vision-only and language-only models--trained
on disjoint modalities--nonetheless project their inputs into a partially
aligned representational space. Yet we still lack a clear picture of where in
each network this convergence emerges, what visual or linguistic cues support
it, whether it captures human preferences in many-to-many image-text scenarios,
and how aggregating exemplars of the same concept affects alignment. Here, we
systematically investigate these questions. We find that alignment peaks in
mid-to-late layers of both model types, reflecting a shift from
modality-specific to conceptually shared representations. This alignment is
robust to appearance-only changes but collapses when semantics are altered
(e.g., object removal or word-order scrambling), highlighting that the shared
code is truly semantic. Moving beyond the one-to-one image-caption paradigm, a
forced-choice "Pick-a-Pic" task shows that human preferences for image-caption
matches are mirrored in the embedding spaces across all vision-language model
pairs. This pattern holds bidirectionally when multiple captions correspond to
a single image, demonstrating that models capture fine-grained semantic
distinctions akin to human judgments. Surprisingly, averaging embeddings across
exemplars amplifies alignment rather than blurring detail. Together, our
results demonstrate that unimodal networks converge on a shared semantic code
that aligns with human judgments and strengthens with exemplar aggregation.

</details>


### [22] [FreeInsert: Personalized Object Insertion with Geometric and Style Control](https://arxiv.org/abs/2509.20756)
*Yuhong Zhang,Han Wang,Yiwen Wang,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: FreeInsert是一个新颖的、无需训练的框架，利用3D几何信息将物体插入到任意场景中，解决了现有图像编辑方法在个性化图像组合任务中存在的几何控制不足、风格不一致以及需要大量训练的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在图像生成方面取得了显著进展，但图像编辑方法在处理个性化图像组合任务时存在几何控制不足、风格不一致以及需要大量训练等局限性。

Method: 将2D物体转换为3D，在3D层面进行交互式编辑，然后从指定视图将其重新渲染为2D图像，并结合扩散模型适配器实现的风格和内容控制，生成具有几何控制和风格一致性的编辑图像。

Result: 实现了具有几何控制（如形状或视图）和风格一致性的图像编辑，提高了编辑的真实感。

Conclusion: FreeInsert通过引入3D几何信息，有效解决了现有图像编辑方法的局限性，实现了高质量的、可控的图像编辑。

Abstract: Text-to-image diffusion models have made significant progress in image
generation, allowing for effortless customized generation. However, existing
image editing methods still face certain limitations when dealing with
personalized image composition tasks. First, there is the issue of lack of
geometric control over the inserted objects. Current methods are confined to 2D
space and typically rely on textual instructions, making it challenging to
maintain precise geometric control over the objects. Second, there is the
challenge of style consistency. Existing methods often overlook the style
consistency between the inserted object and the background, resulting in a lack
of realism. In addition, the challenge of inserting objects into images without
extensive training remains significant. To address these issues, we propose
\textit{FreeInsert}, a novel training-free framework that customizes object
insertion into arbitrary scenes by leveraging 3D geometric information.
Benefiting from the advances in existing 3D generation models, we first convert
the 2D object into 3D, perform interactive editing at the 3D level, and then
re-render it into a 2D image from a specified view. This process introduces
geometric controls such as shape or view. The rendered image, serving as
geometric control, is combined with style and content control achieved through
diffusion adapters, ultimately producing geometrically controlled,
style-consistent edited images via the diffusion model.

</details>


### [23] [CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion](https://arxiv.org/abs/2509.20775)
*Maoye Ren,Praneetha Vaddamanu,Jianjin Xu,Fernando De la Torre Frade*

Main category: cs.CV

TL;DR: CustomEnhancer是一个用于增强文本到图像模型身份定制的新框架，通过利用面部交换技术和预训练的扩散模型，并引入了新的三流融合PerGeneration方法和ResInversion逆转方法，提高了生成的多样性、身份保真度和控制精度，同时大大缩短了逆转时间。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在处理退化场景、控制精细度和保持身份特征方面存在不足，需要一种新的方法来增强身份定制能力。

Method: CustomEnhancer框架通过利用面部交换技术和预训练的扩散模型，引入了三流融合PerGeneration方法来统一生成和重建过程，并提出了ResInversion方法来加速逆转过程。

Result: 实验结果表明，CustomEnhancer在场景多样性、身份保真度和训练免费控制方面达到了最先进的水平，并且ResInversion方法比现有的NTI方法效率高出129倍。

Conclusion: CustomEnhancer框架能够有效提升文本到图像模型在身份定制方面的性能，解决了现有方法的不足，并且ResInversion方法在效率上取得了显著突破。

Abstract: Recently remarkable progress has been made in synthesizing realistic human
photos using text-to-image diffusion models. However, current approaches face
degraded scenes, insufficient control, and suboptimal perceptual identity. We
introduce CustomEnhancer, a novel framework to augment existing identity
customization models. CustomEnhancer is a zero-shot enhancement pipeline that
leverages face swapping techniques, pretrained diffusion model, to obtain
additional representations in a zeroshot manner for encoding into personalized
models. Through our proposed triple-flow fused PerGeneration approach, which
identifies and combines two compatible counter-directional latent spaces to
manipulate a pivotal space of personalized model, we unify the generation and
reconstruction processes, realizing generation from three flows. Our pipeline
also enables comprehensive training-free control over the generation process of
personalized models, offering precise controlled personalization for them and
eliminating the need for controller retraining for per-model. Besides, to
address the high time complexity of null-text inversion (NTI), we introduce
ResInversion, a novel inversion method that performs noise rectification via a
pre-diffusion mechanism, reducing the inversion time by 129 times. Experiments
demonstrate that CustomEnhancer reach SOTA results at scene diversity, identity
fidelity, training-free controls, while also showing the efficiency of our
ResInversion over NTI. The code will be made publicly available upon paper
acceptance.

</details>


### [24] [CompressAI-Vision: Open-source software to evaluate compression methods for computer vision tasks](https://arxiv.org/abs/2509.20777)
*Hyomin Choi,Heeji Han,Chris Rosewarne,Fabien Racapé*

Main category: cs.CV

TL;DR: CompressAI-Vision是一个用于评估针对计算机视觉任务优化的神经网路视频压缩方法的综合平台。


<details>
  <summary>Details</summary>
Motivation: 随着神经网路（NN）在计算机视觉应用中处理图像和视频数据的日益普及，人们对优化视频压缩技术以适应这些任务的兴趣日益浓厚。然而，由于视觉任务、相关NN模型和数据集的多样性，需要一个通用的平台来实施和评估针对下游视觉任务优化的压缩方法。

Method: CompressAI-Vision是一个综合评估平台，允许新的编码工具在保留任务准确性的同时，有效地压缩视觉网络输入，并在“远程”和“拆分”推理两种不同的场景下进行评估。

Result: 该研究展示了该评估平台结合标准编解码器（开发中）的各种用例，通过在多个数据集上检查比特率与任务准确性之间的压缩增益。

Conclusion: CompressAI-Vision已作为开源软件开发，并被动态图像专家组（MPEG）采纳，用于制定面向机器的特征编码（FCM）标准。该平台为评估和开发针对计算机视觉任务优化的压缩技术提供了一个重要的基础。

Abstract: With the increasing use of neural network (NN)-based computer vision
applications that process image and video data as input, interest has emerged
in video compression technology optimized for computer vision tasks. In fact,
given the variety of vision tasks, associated NN models and datasets, a
consolidated platform is needed as a common ground to implement and evaluate
compression methods optimized for downstream vision tasks. CompressAI-Vision is
introduced as a comprehensive evaluation platform where new coding tools
compete to efficiently compress the input of vision network while retaining
task accuracy in the context of two different inference scenarios: "remote" and
"split" inferencing. Our study showcases various use cases of the evaluation
platform incorporated with standard codecs (under development) by examining the
compression gain on several datasets in terms of bit-rate versus task accuracy.
This evaluation platform has been developed as open-source software and is
adopted by the Moving Pictures Experts Group (MPEG) for the development the
Feature Coding for Machines (FCM) standard. The software is available publicly
at https://github.com/InterDigitalInc/CompressAI-Vision.

</details>


### [25] [Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization](https://arxiv.org/abs/2509.20785)
*Jincai Song,Haipeng Chen,Jun Qin,Na Zhao*

Main category: cs.CV

TL;DR: 该研究提出了一种新的跨域半监督域泛化（CD-SSDG）方法，称为双监督不对称协同训练（DAC），以解决医学图像分割中存在的伪标签不准确问题，并在三个真实数据集上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督域泛化（SSDG）方法通常假设训练集中标记和未标记数据来自同一域，但这在实际中并不总是成立。当标记和未标记数据之间存在域偏移时，现有方法的性能会下降。因此，本研究旨在解决一个更具挑战性的场景——跨域半监督域泛化（CD-SSDG），其中训练数据的标记和未标记数据之间以及训练和测试数据之间都存在域偏移。

Method: 提出了一种名为双监督不对称协同训练（DAC）的新框架。该框架基于协同训练范式，包含两个子模型，它们提供交叉伪监督。此外，DAC 集成了额外的特征级监督，以解决由标记和未标记数据之间的域偏移引起的伪监督不准确问题，并利用来自丰富特征空间的互补监督。同时，为每个子模型集成了两个不同的辅助自监督任务，以增强域不变判别性特征学习并防止模型崩溃。

Result: 在视网膜、息肉和 SCGM 三个真实世界的医学图像分割数据集上进行了广泛的实验。实验结果表明，所提出的 DAC 框架具有强大的泛化能力。

Conclusion: DAC 框架通过集成特征级监督和不对称的辅助任务，有效解决了 CD-SSDG 场景下的伪标签不准确问题，并提高了模型的泛化能力。实验结果证实了该方法在医学图像分割任务上的有效性。

Abstract: Semi-supervised domain generalization (SSDG) in medical image segmentation
offers a promising solution for generalizing to unseen domains during testing,
addressing domain shift challenges and minimizing annotation costs. However,
conventional SSDG methods assume labeled and unlabeled data are available for
each source domain in the training set, a condition that is not always met in
practice. The coexistence of limited annotation and domain shift in the
training set is a prevalent issue. Thus, this paper explores a more practical
and challenging scenario, cross-domain semi-supervised domain generalization
(CD-SSDG), where domain shifts occur between labeled and unlabeled training
data, in addition to shifts between training and testing sets. Existing SSDG
methods exhibit sub-optimal performance under such domain shifts because of
inaccurate pseudolabels. To address this issue, we propose a novel
dual-supervised asymmetric co-training (DAC) framework tailored for CD-SSDG.
Building upon the co-training paradigm with two sub-models offering cross
pseudo supervision, our DAC framework integrates extra feature-level
supervision and asymmetric auxiliary tasks for each sub-model. This
feature-level supervision serves to address inaccurate pseudo supervision
caused by domain shifts between labeled and unlabeled data, utilizing
complementary supervision from the rich feature space. Additionally, two
distinct auxiliary self-supervised tasks are integrated into each sub-model to
enhance domain-invariant discriminative feature learning and prevent model
collapse. Extensive experiments on real-world medical image segmentation
datasets, i.e., Fundus, Polyp, and SCGM, demonstrate the robust
generalizability of the proposed DAC framework.

</details>


### [26] [Real-Time Object Detection Meets DINOv3](https://arxiv.org/abs/2509.20787)
*Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: DEIMv2通过整合DINOv3特征并引入空间调优适配器（STA）和HGNetv2等技术，实现了在不同模型尺寸上（从X到Atto）的性能提升和成本优化，尤其在参数量和检测精度上取得了新的SOTA（State-of-the-Art）成果。


<details>
  <summary>Details</summary>
Motivation: DEIM作为实时DETR的主流训练框架，在性能上优于YOLO系列，但仍有提升空间，尤其是在不同计算资源和部署场景下的性能-成本权衡。

Method: 1. 整合DINOv3特征到DEIM框架，形成DEIMv2。
2. 对于较大模型（X, L, M, S），采用DINOv3预训练或蒸馏骨干网络，并引入空间调优适配器（STA）以融合多尺度特征。
3. 对于超轻量级模型（Nano, Pico, Femto, Atto），采用HGNetv2并进行剪枝，同时简化解码器和升级Dense O2O。
4. 提出统一的设计以适应多样化的部署需求。

Result: DEIMv2在不同模型尺寸上均取得了SOTA成果。
- DEIMv2-X (50.3M参数) 达到57.8 AP，优于参数量更多的现有X-scale模型。
- DEIMv2-S (9.71M参数) 成为首个突破50 AP的10M以下模型。
- DEIMv2-Pico (1.5M参数) 达到38.5 AP，在更少参数下媲美YOLOv10-Nano。

Conclusion: DEIMv2通过引入DINOv3特征、STA和HGNetv2等关键技术，实现了在不同规模模型上的性能和效率的显著提升，为实时目标检测设定了新的SOTA标准，并在性能-成本比方面表现出色。

Abstract: Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM
has become the mainstream training framework for real-time DETRs, significantly
outperforming the YOLO series. In this work, we extend it with DINOv3 features,
resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering
GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt
DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter
(STA), which efficiently converts DINOv3's single-scale output into multi-scale
features and complements strong semantics with fine-grained details to enhance
detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we
employ HGNetv2 with depth and width pruning to meet strict resource budgets.
Together with a simplified decoder and an upgraded Dense O2O, this unified
design enables DEIMv2 to achieve a superior performance-cost trade-off across
diverse scenarios, establishing new state-of-the-art results. Notably, our
largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters,
surpassing prior X-scale models that require over 60 million parameters for
just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model
(9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even
the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers
38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer
parameters.

</details>


### [27] [DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation](https://arxiv.org/abs/2509.20792)
*Ved Umrajkar*

Main category: cs.CV

TL;DR: DAC-LoRA是一种将对抗性训练集成到参数高效微调（PEFT）中的新颖框架，通过智能的、渐进的攻击课程，在不显著影响准确性的情况下提高了视觉-语言模型（VLMs）的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言模型（VLMs）虽然可以通过LoRA等参数高效微调（PEFT）方法进行高效适配，但仍然容易受到对抗性攻击，尤其是在自动驾驶、医疗诊断和内容审核等安全关键应用中。CLIP作为许多下游VLMs的骨干，是这些攻击的高价值目标，其脆弱性可能影响整个多模态AI生态系统。

Method: DAC-LoRA框架将对抗性训练集成到PEFT中。其核心思想是利用智能的、渐进的攻击课程来逐步提高难度，该方法具有通用性，可应用于任何迭代攻击方法。该框架在梯度与损失函数的期望值之间建立联系，并利用了第一阶静止条件（FOSC）和受TRADES启发的损失函数。

Result: DAC-LoRA在不显著损害干净准确率的情况下，显著提高了模型的对抗鲁棒性。该框架易于集成到标准的PEFT流程中，能够有效提升模型的鲁棒性。

Conclusion: DAC-LoRA是一种有效、轻量且广泛适用的方法，可以显著增强视觉-语言模型（VLMs）在对抗性攻击下的鲁棒性，同时保持了良好的干净准确率。

Abstract: Vision-Language Models (VLMs) are foundational to critical applications like
autonomous driving, medical diagnosis, and content moderation. While
Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA enable their efficient
adaptation to specialized tasks, these models remain vulnerable to adversarial
attacks that can compromise safety-critical decisions. CLIP, the backbone for
numerous downstream VLMs, is a high-value target whose vulnerabilities can
cascade across the multimodal AI ecosystem. We propose Dynamic Adversarial
Curriculum DAC-LoRA, a novel framework that integrates adversarial training
into PEFT. The core principle of our method i.e. an intelligent curriculum of
progressively challenging attack, is general and can potentially be applied to
any iterative attack method. Guided by the First-Order Stationary Condition
(FOSC) and a TRADES-inspired loss, DAC-LoRA achieves substantial improvements
in adversarial robustness without significantly compromising clean accuracy.
Our work presents an effective, lightweight, and broadly applicable method to
demonstrate that the DAC-LoRA framework can be easily integrated into a
standard PEFT pipeline to significantly enhance robustness.

</details>


### [28] [Federated Domain Generalization with Domain-specific Soft Prompts Generation](https://arxiv.org/abs/2509.20807)
*Jianhan Wu,Xiaoyang Qu,Zhangcheng Huang,Jianzong Wang*

Main category: cs.CV

TL;DR: Prompt learning for federated learning faces domain shift challenges. Existing methods struggle with limited prompt diversity and ignoring unknown domain information. FedDSPG generates domain-specific soft prompts (DSPs) using a generative model, incorporating content and domain knowledge. This allows for adaptation to unseen domains during inference, outperforming existing methods and achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing federated domain generalization (FDG) methods based on prompt learning struggle with limited prompt diversity and ignoring information from unknown domains, hindering effective adaptation in federated learning scenarios with domain shift among clients.

Method: FedDSPG introduces domain-specific soft prompts (DSPs) for each domain and integrates content and domain knowledge into a generative model among clients. During inference, this generator is used to obtain DSPs for unseen target domains to guide downstream tasks.

Result: Comprehensive evaluations across several public datasets confirm that FedDSPG outperforms existing strong baselines in FDG, achieving state-of-the-art results.

Conclusion: FedDSPG, a novel generative method for FDG, effectively addresses the limitations of existing prompt learning approaches by generating domain-specific soft prompts, leading to improved performance in adapting to unknown domains within federated learning.

Abstract: Prompt learning has become an efficient paradigm for adapting CLIP to
downstream tasks. Compared with traditional fine-tuning, prompt learning
optimizes a few parameters yet yields highly competitive results, especially
appealing in federated learning for computational efficiency. engendering
domain shift among clients and posing a formidable challenge for
downstream-task adaptation. Existing federated domain generalization (FDG)
methods based on prompt learning typically learn soft prompts from training
samples, replacing manually designed prompts to enhance the generalization
ability of federated models. However, these learned prompts exhibit limited
diversity and tend to ignore information from unknown domains. We propose a
novel and effective method from a generative perspective for handling FDG
tasks, namely federated domain generalization with domain-specific soft prompts
generation (FedDSPG). Specifically, during training, we introduce
domain-specific soft prompts (DSPs) for each domain and integrate content and
domain knowledge into the generative model among clients. In the inference
phase, the generator is utilized to obtain DSPs for unseen target domains, thus
guiding downstream tasks in unknown domains. Comprehensive evaluations across
several public datasets confirm that our method outperforms existing strong
baselines in FDG, achieving state-of-the-art results.

</details>


### [29] [Revolutionizing Precise Low Back Pain Diagnosis via Contrastive Learning](https://arxiv.org/abs/2509.20813)
*Thanh Binh Le,Hoang Nhat Khang Vo,Tan-Ha Mai,Trong Nhan Phan*

Main category: cs.CV

TL;DR: LumbarCLIP是一个新颖的多模态框架，利用对比语言-图像预训练来对腰椎MRI扫描与放射学报告进行匹配，实现了最先进的分类性能。


<details>
  <summary>Details</summary>
Motivation: 低背痛影响着全球数百万人，因此需要能够联合分析复杂的医学图像和相应的文本报告的稳健诊断模型。

Method: LumbarCLIP集成了视觉编码器（ResNet-50、Vision Transformer、Swin Transformer）和基于BERT的文本编码器，以提取密集表示。这些表示通过可学习的投影头（可配置为线性和非线性）被投影到一个共享的嵌入空间中，并进行归一化，以便使用软CLIP损失进行稳定的对比训练。

Result: 该模型在下游分类任务上取得了最先进的性能，在测试集上的准确率最高可达95.00%，F1分数最高可达94.75%，尽管存在固有的类别不平衡。消融研究表明，线性投影头比非线性变体能实现更有效的跨模态对齐。

Conclusion: LumbarCLIP为自动骨骼肌肉诊断和临床决策支持提供了一个有前景的基础。

Abstract: Low back pain affects millions worldwide, driving the need for robust
diagnostic models that can jointly analyze complex medical images and
accompanying text reports. We present LumbarCLIP, a novel multimodal framework
that leverages contrastive language-image pretraining to align lumbar spine MRI
scans with corresponding radiological descriptions. Built upon a curated
dataset containing axial MRI views paired with expert-written reports,
LumbarCLIP integrates vision encoders (ResNet-50, Vision Transformer, Swin
Transformer) with a BERT-based text encoder to extract dense representations.
These are projected into a shared embedding space via learnable projection
heads, configurable as linear or non-linear, and normalized to facilitate
stable contrastive training using a soft CLIP loss. Our model achieves
state-of-the-art performance on downstream classification, reaching up to
95.00% accuracy and 94.75% F1-score on the test set, despite inherent class
imbalance. Extensive ablation studies demonstrate that linear projection heads
yield more effective cross-modal alignment than non-linear variants. LumbarCLIP
offers a promising foundation for automated musculoskeletal diagnosis and
clinical decision support.

</details>


### [30] [Poisoning Prompt-Guided Sampling in Video Large Language Models](https://arxiv.org/abs/2509.20851)
*Yuxin Cao,Wei Song,Jingling Xue,Jin Song Dong*

Main category: cs.CV

TL;DR: 该研究提出了首个针对视频大语言模型（VideoLLM）提示引导采样机制的黑盒投毒攻击方法PoisonVID，该方法通过闭环优化策略，利用GPT-4o-mini和影子VideoLLM构建的描述集，迭代优化一个通用扰动，以降低有害帧的相关性得分，成功率高达82%-99%，揭示了现有提示引导采样机制的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型（VideoLLM）在帧采样策略上取得了显著进展，但最新的提示引导采样策略的安全性和漏洞尚未得到充分研究。本研究旨在填补这一空白，探索并揭示提示引导采样机制的潜在安全风险。

Method: 提出了一种名为PoisonVID的黑盒投毒攻击方法，该方法通过闭环优化策略，利用一个由释义后的有害描述组成的描述集，并借助影子VideoLLM和轻量级语言模型GPT-4o-mini，迭代地优化一个通用扰动。该扰动的目的是降低有害帧在提示引导采样过程中的相关性得分，从而实现攻击目标。

Result: PoisonVID在三种不同的提示引导采样策略和三种先进的VideoLLM上进行了全面评估，攻击成功率达到了82%至99%，证明了该攻击方法的有效性，并突显了为VideoLLM开发更高级采样策略的必要性。

Conclusion: PoisonVID攻击的成功表明，当前的提示引导采样策略对于VideoLLM来说存在严重的安全漏洞。因此，迫切需要研究和开发更安全的采样策略，以应对潜在的投毒攻击，确保VideoLLM的可靠性和安全性。

Abstract: Video Large Language Models (VideoLLMs) have emerged as powerful tools for
understanding videos, supporting tasks such as summarization, captioning, and
question answering. Their performance has been driven by advances in frame
sampling, progressing from uniform-based to semantic-similarity-based and, most
recently, prompt-guided strategies. While vulnerabilities have been identified
in earlier sampling strategies, the safety of prompt-guided sampling remains
unexplored. We close this gap by presenting PoisonVID, the first black-box
poisoning attack that undermines prompt-guided sampling in VideoLLMs. PoisonVID
compromises the underlying prompt-guided sampling mechanism through a
closed-loop optimization strategy that iteratively optimizes a universal
perturbation to suppress harmful frame relevance scores, guided by a depiction
set constructed from paraphrased harmful descriptions leveraging a shadow
VideoLLM and a lightweight language model, i.e., GPT-4o-mini. Comprehensively
evaluated on three prompt-guided sampling strategies and across three advanced
VideoLLMs, PoisonVID achieves 82% - 99% attack success rate, highlighting the
importance of developing future advanced sampling strategies for VideoLLMs.

</details>


### [31] [Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer](https://arxiv.org/abs/2509.20854)
*Abdur Rehman,S M A Sharif,Md Abdur Rahaman,Mohamed Jismy Aashik Rasool,Seongwan Kim,Jaeho Lee*

Main category: cs.CV

TL;DR: GoR是一种新颖的可学习正则化方法，通过自适应平衡任务损失和知识蒸馏损失来提升量化感知训练（QAT）与知识蒸馏（KD）的结合效果，尤其在低比特量化下表现优异，并在图像分类、目标检测和大型语言模型压缩任务上取得了最先进的成果，同时在实际部署中实现了更快的推理速度和与全精度模型相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练（QAT）与知识蒸馏（KD）方法在平衡任务损失和蒸馏损失时存在挑战，特别是在低比特量化条件下，由于梯度大小不一致，容易产生冲突，影响模型性能。

Method: 提出了一种名为GoR（Game of Regularizer）的新型可学习正则化方法，该方法使用两个可训练参数来动态调整任务损失和蒸馏损失的权重，以自适应地平衡两者。此外，还引入了一个名为QAT-EKD-GoR的集成蒸馏框架，该框架使用多个异构教师模型进行蒸馏。

Result: GoR在图像分类、目标检测和大型语言模型压缩任务上，相比于现有的QAT-KD方法，取得了更优越的性能。GoR在低功耗边缘设备上实现了更快的推理速度，同时保持了全精度模型应有的准确性。EKD-GoR框架在最佳条件下甚至能超越全精度模型。

Conclusion: GoR是一种有效的正则化方法，能够解决QAT-KD中的损失平衡问题，显著提升量化模型性能。EKD-GoR框架为实际部署提供了鲁棒的解决方案，尤其是在资源受限的环境下。

Abstract: Quantization-aware training (QAT) combined with knowledge distillation (KD)
is a promising strategy for compressing Artificial Intelligence (AI) models for
deployment on resource-constrained hardware. However, existing QAT-KD methods
often struggle to balance task-specific (TS) and distillation losses due to
heterogeneous gradient magnitudes, especially under low-bit quantization. We
propose Game of Regularizer (GoR), a novel learnable regularization method that
adaptively balances TS and KD objectives using only two trainable parameters
for dynamic loss weighting. GoR reduces conflict between supervision signals,
improves convergence, and boosts the performance of small quantized models
(SQMs). Experiments on image classification, object detection (OD), and large
language model (LLM) compression show that GoR consistently outperforms
state-of-the-art QAT-KD methods. On low-power edge devices, it delivers faster
inference while maintaining full-precision accuracy. We also introduce
QAT-EKD-GoR, an ensemble distillation framework that uses multiple
heterogeneous teacher models. Under optimal conditions, the proposed EKD-GoR
can outperform full-precision models, providing a robust solution for
real-world deployment.

</details>


### [32] [Plant identification based on noisy web data: the amazing performance of deep learning (LifeCLEF 2017)](https://arxiv.org/abs/2509.20856)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2017植物识别挑战赛旨在评估网络收集的大量带噪声的、包含许多标记错误的训练数据集与专家检查过的小型但可信的训练数据集相比的效果。


<details>
  <summary>Details</summary>
Motivation: LifeCLEF 2017植物识别挑战赛旨在解决当前自动化植物识别系统面临的挑战，特别是如何利用网络上大量存在标签错误但规模庞大的图像数据，并将其与少量但经过专家验证的可靠数据进行比较。

Method: 本研究通过LifeCLEF 2017植物识别挑战赛，对比了两种训练策略：一是使用网络收集的大量带噪声的、可能包含标记错误的数据集；二是使用专家检查过的小型但可靠的数据集。为了公平比较，测试数据集来自Pl@ntNet移动应用程序，该程序收集了全球数百万的植物图像查询。

Result: 挑战赛总结了参赛研究组采用的方法和系统，并对主要结果进行了分析。

Conclusion: LifeCLEF 2017植物识别挑战赛为评估和改进自动化植物识别系统提供了重要的平台，特别是在处理大规模、有噪声的网络图像数据方面。

Abstract: The 2017-th edition of the LifeCLEF plant identification challenge is an
important milestone towards automated plant identification systems working at
the scale of continental floras with 10.000 plant species living mainly in
Europe and North America illustrated by a total of 1.1M images. Nowadays, such
ambitious systems are enabled thanks to the conjunction of the dazzling recent
progress in image classification with deep learning and several outstanding
international initiatives, such as the Encyclopedia of Life (EOL), aggregating
the visual knowledge on plant species coming from the main national botany
institutes. However, despite all these efforts the majority of the plant
species still remain without pictures or are poorly illustrated. Outside the
institutional channels, a much larger number of plant pictures are available
and spread on the web through botanist blogs, plant lovers web-pages, image
hosting websites and on-line plant retailers. The LifeCLEF 2017 plant challenge
presented in this paper aimed at evaluating to what extent a large noisy
training dataset collected through the web and containing a lot of labelling
errors can compete with a smaller but trusted training dataset checked by
experts. To fairly compare both training strategies, the test dataset was
created from a third data source, i.e. the Pl@ntNet mobile application that
collects millions of plant image queries all over the world. This paper
presents more precisely the resources and assessments of the challenge,
summarizes the approaches and systems employed by the participating research
groups, and provides an analysis of the main outcomes.

</details>


### [33] [TasselNetV4: A vision foundation model for cross-scene, cross-scale, and cross-species plant counting](https://arxiv.org/abs/2509.20857)
*Xiaonan Hu,Xuebing Li,Jinyu Xu,Abdulkadir Duran Adan,Letian Zhou,Xuhui Zhu,Yanan Li,Wei Guo,Shouyang Liu,Wenzhong Liu,Hao Lu*

Main category: cs.CV

TL;DR: TasselNetV4, a new vision foundation model, achieves superior and efficient cross-species plant counting by extending TasselNet with a extract-and-match paradigm and multi-branch box-aware local counters, outperforming state-of-the-art CAC models on two challenging datasets.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the limitations of existing vision-based plant counting methods, which are species-specific and struggle with the increasing biodiversity of crops. It argues for a shift from 'what plants to count' to 'how to count plants', inspired by class-agnostic counting (CAC) but addressing the unique challenges of plant morphology (dynamic, non-rigid structure).

Method: The study introduces TasselNetV4, an extension of the TasselNet model. TasselNetV4 combines the local counting approach of TasselNet with the extract-and-match paradigm from CAC. It utilizes a vision transformer backbone and novel multi-branch box-aware local counters to improve robustness across different scales and enable cross-species counting.

Result: TasselNetV4 demonstrated superior counting performance and high efficiency compared to state-of-the-art CAC models on two new datasets, PAC-105 and PAC-Somalia. The results suggest TasselNetV4's potential as a vision foundation model for plant counting across various scenes, scales, and species.

Conclusion: TasselNetV4 represents a significant advancement in plant counting, offering a generalized solution that overcomes the limitations of species-specific models. Its ability to perform cross-species, cross-scene, and cross-scale counting positions it as a foundational vision model for agricultural applications.

Abstract: Accurate plant counting provides valuable information for agriculture such as
crop yield prediction, plant density assessment, and phenotype quantification.
Vision-based approaches are currently the mainstream solution. Prior art
typically uses a detection or a regression model to count a specific plant.
However, plants have biodiversity, and new cultivars are increasingly bred each
year. It is almost impossible to exhaust and build all species-dependent
counting models. Inspired by class-agnostic counting (CAC) in computer vision,
we argue that it is time to rethink the problem formulation of plant counting,
from what plants to count to how to count plants. In contrast to most daily
objects with spatial and temporal invariance, plants are dynamic, changing with
time and space. Their non-rigid structure often leads to worse performance than
counting rigid instances like heads and cars such that current CAC and
open-world detection models are suboptimal to count plants. In this work, we
inherit the vein of the TasselNet plant counting model and introduce a new
extension, TasselNetV4, shifting from species-specific counting to
cross-species counting. TasselNetV4 marries the local counting idea of
TasselNet with the extract-and-match paradigm in CAC. It builds upon a plain
vision transformer and incorporates novel multi-branch box-aware local counters
used to enhance cross-scale robustness. Two challenging datasets, PAC-105 and
PAC-Somalia, are harvested. Extensive experiments against state-of-the-art CAC
models show that TasselNetV4 achieves not only superior counting performance
but also high efficiency.Our results indicate that TasselNetV4 emerges to be a
vision foundation model for cross-scene, cross-scale, and cross-species plant
counting.

</details>


### [34] [SD-RetinaNet: Topologically Constrained Semi-Supervised Retinal Lesion and Layer Segmentation in OCT](https://arxiv.org/abs/2509.20864)
*Botond Fazekas,Guilherme Aresta,Philipp Seeböck,Julia Mai,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: 提出了一种新的半监督模型，通过可微分的生物标志物拓扑引擎来强制进行解剖学上正确的眼底图像分割，解决了现有方法在解剖结构不合理、层-病灶交互建模不足和拓扑正确性缺乏保证方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有眼底图像分割方法在处理半监督学习时，常常生成解剖结构不合理、无法有效建模层-病灶交互，并且缺乏拓扑正确性的保证，这限制了其在诊断和监测中的应用。

Method: 提出了一种新颖的半监督模型，该模型引入了一个全微分的生物标志物拓扑引擎，强制进行解剖学上正确的病灶和层分割。该模型能够学习解耦的表示，分离空间和风格因素，从而实现更真实的层分割，并提高病灶分割精度，同时严格保证病灶位于解剖学上合理的层间位置。模型能够同时学习层和病灶，并利用无标签和部分标签的数据集。

Result: 在公开和内部OCT图像数据集上进行了评估，结果显示该模型在病灶和层分割方面均优于现有最先进的方法，并且能够利用部分标注的训练数据将层分割泛化到病变情况。

Conclusion: 解剖学约束在半监督学习中应用于准确、鲁棒和可信的眼底生物标志物分割具有巨大潜力。

Abstract: Optical coherence tomography (OCT) is widely used for diagnosing and
monitoring retinal diseases, such as age-related macular degeneration (AMD).
The segmentation of biomarkers such as layers and lesions is essential for
patient diagnosis and follow-up. Recently, semi-supervised learning has shown
promise in improving retinal segmentation performance. However, existing
methods often produce anatomically implausible segmentations, fail to
effectively model layer-lesion interactions, and lack guarantees on topological
correctness.
  To address these limitations, we propose a novel semi-supervised model that
introduces a fully differentiable biomarker topology engine to enforce
anatomically correct segmentation of lesions and layers. This enables joint
learning with bidirectional influence between layers and lesions, leveraging
unlabeled and diverse partially labeled datasets. Our model learns a
disentangled representation, separating spatial and style factors. This
approach enables more realistic layer segmentations and improves lesion
segmentation, while strictly enforcing lesion location in their anatomically
plausible positions relative to the segmented layers.
  We evaluate the proposed model on public and internal datasets of OCT scans
and show that it outperforms the current state-of-the-art in both lesion and
layer segmentation, while demonstrating the ability to generalize layer
segmentation to pathological cases using partially annotated training data. Our
results demonstrate the potential of using anatomical constraints in
semi-supervised learning for accurate, robust, and trustworthy retinal
biomarker segmentation.

</details>


### [35] [Plant identification in an open-world (LifeCLEF 2016)](https://arxiv.org/abs/2509.20870)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2016 评估了大规模植物识别方法，重点是开放集识别，即识别未知植物类别的能力。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的生物多样性监测场景下，评估大规模植物识别方法和系统。

Method: 在 2016 年，任务被评估为一个开放集识别问题，要求识别系统能够处理未知和未见过的类别，而不仅仅是在已知类别中进行分类。

Result: 该挑战赛在 110K 多张图像上进行，涵盖了 1000 种西欧植物，参赛者开发了能够区分已知和未知植物的系统。

Conclusion: 开放集识别是植物识别的关键挑战，需要系统能够自动拒绝由未知类别引起的假阳性分类。

Abstract: The LifeCLEF plant identification challenge aims at evaluating plant
identification methods and systems at a very large scale, close to the
conditions of a real-world biodiversity monitoring scenario. The 2016-th
edition was actually conducted on a set of more than 110K images illustrating
1000 plant species living in West Europe, built through a large-scale
participatory sensing platform initiated in 2011 and which now involves tens of
thousands of contributors. The main novelty over the previous years is that the
identification task was evaluated as an open-set recognition problem, i.e. a
problem in which the recognition system has to be robust to unknown and never
seen categories. Beyond the brute-force classification across the known classes
of the training set, the big challenge was thus to automatically reject the
false positive classification hits that are caused by the unknown classes. This
overview presents more precisely the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [36] [SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering](https://arxiv.org/abs/2509.20871)
*Yan Zhang,Jiaqing Lin,Miao Zhang,Kui Xiao,Xiaoju Hou,Yue Zhao,Zhifei Li*

Main category: cs.CV

TL;DR: SCRA-VQA通过生成、摘要和重新排序的图像描述来增强大型语言模型（LLMs）在视觉问答（VQA）中的推理能力，从而提高在OK-VQA和A-OKVQA数据集上的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的KB-VQA方法依赖于可能包含无关信息的图像标题，并且LLM通常不理解VQA任务，这限制了它们的推理能力。

Method: SCRA-VQA首先使用预训练的视觉语言模型将图像转换为标题，然后生成上下文示例，同时对标题进行摘要和重新排序，以去除不相关信息，从而帮助LLM更好地理解图像和问题。

Result: SCRA-VQA在OK-VQA和A-OKVQA数据集上取得了38.8%和34.6%的准确率，证明了其在KB-VQA任务上的优越性能。

Conclusion: SCRA-VQA通过改进图像描述的质量和LLM对VQA任务的理解，有效提高了模型的推理能力和任务适应性，且无需昂贵的端到端训练。

Abstract: Acquiring high-quality knowledge is a central focus in Knowledge-Based Visual
Question Answering (KB-VQA). Recent methods use large language models (LLMs) as
knowledge engines for answering. These methods generally employ image captions
as visual text descriptions to assist LLMs in interpreting images. However, the
captions frequently include excessive noise irrelevant to the question, and
LLMs generally do not comprehend VQA tasks, limiting their reasoning
capabilities. To address this issue, we propose the Summarized Caption-Rerank
Augmented VQA (SCRA-VQA), which employs a pre-trained visual language model to
convert images into captions. Moreover, SCRA-VQA generates contextual examples
for the captions while simultaneously summarizing and reordering them to
exclude unrelated information. The caption-rerank process enables LLMs to
understand the image information and questions better, thus enhancing the
model's reasoning ability and task adaptability without expensive end-to-end
training. Based on an LLM with 6.7B parameters, SCRA-VQA performs excellently
on two challenging knowledge-based VQA datasets: OK-VQA and A-OKVQA, achieving
accuracies of 38.8% and 34.6%. Our code is available at
https://github.com/HubuKG/SCRA-VQA.

</details>


### [37] [The Unanticipated Asymmetry Between Perceptual Optimization and Assessment](https://arxiv.org/abs/2509.20878)
*Jiabei Zhang,Qi Wang,Siyu Wu,Du Chen,Tianhe Wu*

Main category: cs.CV

TL;DR: 感知优化和图像质量评估（IQA）之间存在不对称性，尽管它们都依赖于保真度和对抗性目标，但有效的IQA度量不一定适用于感知优化，尤其是在对抗性训练下。此外，判别器在优化中有效，但其学习表示对IQA模型的帮助有限。判别器架构（如补丁级和卷积架构）对细节重建的影响比Transformer架构更大，这为感知优化提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨感知优化（主要由保真度和对抗性目标驱动）和图像质量评估（IQA）度量之间的关联，特别是保真度目标在IQA中的有效性与感知优化中的有效性之间的关系。

Method: 通过系统性分析，研究保真度目标和对抗性目标在感知优化和IQA中的作用，并分析了判别器的表示在IQA模型中的重用效果，以及不同判别器架构（补丁级、卷积、Vanilla、Transformer）对细节重建的影响。

Result: 研究发现，在IQA中表现良好的保真度度量不一定适用于感知优化，尤其是在对抗性训练下，这种不匹配更为明显。判别器在优化中能有效减少伪影，但其学习表示作为IQA模型骨干初始化时，效果有限。判别器的设计对优化有显著影响，其中补丁级和卷积架构在细节重建方面优于Vanilla和Transformer架构。

Conclusion: 感知优化和IQA之间存在不对称性，理解这种不对称性以及判别器设计对优化的影响，有助于改进感知优化方法，并提高IQA的可迁移性。

Abstract: Perceptual optimization is primarily driven by the fidelity objective, which
enforces both semantic consistency and overall visual realism, while the
adversarial objective provides complementary refinement by enhancing perceptual
sharpness and fine-grained detail. Despite their central role, the correlation
between their effectiveness as optimization objectives and their capability as
image quality assessment (IQA) metrics remains underexplored. In this work, we
conduct a systematic analysis and reveal an unanticipated asymmetry between
perceptual optimization and assessment: fidelity metrics that excel in IQA are
not necessarily effective for perceptual optimization, with this misalignment
emerging more distinctly under adversarial training. In addition, while
discriminators effectively suppress artifacts during optimization, their
learned representations offer only limited benefits when reused as backbone
initializations for IQA models. Beyond this asymmetry, our findings further
demonstrate that discriminator design plays a decisive role in shaping
optimization, with patch-level and convolutional architectures providing more
faithful detail reconstruction than vanilla or Transformer-based alternatives.
These insights advance the understanding of loss function design and its
connection to IQA transferability, paving the way for more principled
approaches to perceptual optimization.

</details>


### [38] [Integrating Object Interaction Self-Attention and GAN-Based Debiasing for Visual Question Answering](https://arxiv.org/abs/2509.20884)
*Zhifei Li,Feng Qiu,Yiran Wang,Yujing Xia,Kui Xiao,Miao Zhang,Yan Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Visual Question Answering (VQA) presents a unique challenge by requiring
models to understand and reason about visual content to answer questions
accurately. Existing VQA models often struggle with biases introduced by the
training data, leading to over-reliance on superficial patterns and inadequate
generalization to diverse questions and images. This paper presents a novel
model, IOG-VQA, which integrates Object Interaction Self-Attention and
GAN-Based Debiasing to enhance VQA model performance. The self-attention
mechanism allows our model to capture complex interactions between objects
within an image, providing a more comprehensive understanding of the visual
context. Meanwhile, the GAN-based debiasing framework generates unbiased data
distributions, helping the model to learn more robust and generalizable
features. By leveraging these two components, IOG-VQA effectively combines
visual and textual information to address the inherent biases in VQA datasets.
Extensive experiments on the VQA-CP v1 and VQA-CP v2 datasets demonstrate that
our model shows excellent performance compared with the existing methods,
particularly in handling biased and imbalanced data distributions highlighting
the importance of addressing both object interactions and dataset biases in
advancing VQA tasks. Our code is available at
https://github.com/HubuKG/IOG-VQA.

</details>


### [39] [Nuclear Diffusion Models for Low-Rank Background Suppression in Videos](https://arxiv.org/abs/2509.20886)
*Tristan S. W. Stevens,Oisín Nolan,Jean-Luc Robert,Ruud J. G. van Sloun*

Main category: cs.CV

TL;DR: 一种名为Nuclear Diffusion的混合框架，结合了低秩时间建模和扩散后验采样，用于视频恢复，在心脏超声去雾方面表现优于传统RPCA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒主成分分析方法在处理视频数据时，其稀疏性假设往往无法捕捉到真实视频数据中丰富的可变性，限制了视频分析和恢复的准确性。

Method: 提出了一种混合框架，结合了低秩时间建模和扩散后验采样，并将其命名为Nuclear Diffusion。

Result: 该方法在心脏超声去雾的实际问题上进行了评估，与传统的RPCA方法相比，在对比度增强（gCNR）和信号保留（KS统计量）方面表现出更优越的去雾性能。

Conclusion: 结合基于模型的时域模型和深度生成先验的混合方法在视频恢复方面具有巨大潜力。

Abstract: Video sequences often contain structured noise and background artifacts that
obscure dynamic content, posing challenges for accurate analysis and
restoration. Robust principal component methods address this by decomposing
data into low-rank and sparse components. Still, the sparsity assumption often
fails to capture the rich variability present in real video data. To overcome
this limitation, a hybrid framework that integrates low-rank temporal modeling
with diffusion posterior sampling is proposed. The proposed method, Nuclear
Diffusion, is evaluated on a real-world medical imaging problem, namely cardiac
ultrasound dehazing, and demonstrates improved dehazing performance compared to
traditional RPCA concerning contrast enhancement (gCNR) and signal preservation
(KS statistic). These results highlight the potential of combining model-based
temporal models with deep generative priors for high-fidelity video
restoration.

</details>


### [40] [FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies](https://arxiv.org/abs/2509.20890)
*Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan*

Main category: cs.CV

TL;DR: FerretNet是一种轻量级神经网络，可以有效检测合成图像，准确率达到97.1%，超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型（如VAE、GAN、LDM）生成的图像越来越逼真，给合成图像检测带来了严峻挑战。现有的检测方法需要改进以应对这些挑战。

Method: 本文利用局部像素依赖（LPD）属性，通过重构图像来暴露纹理连续性和边缘一致性的中断。在此基础上，提出了一种名为FerretNet的轻量级神经网络（1.1M参数）用于合成图像检测。

Result: FerretNet在仅使用4类ProGAN数据集训练的情况下，在包含22种生成模型的开放世界基准测试中，平均准确率达到了97.1%，比现有方法高出10.6%。

Conclusion: FerretNet在合成图像检测方面表现出高效且鲁棒的性能，证明了其在应对日益逼真的合成图像方面的有效性。

Abstract: The increasing realism of synthetic images generated by advanced models such
as VAEs, GANs, and LDMs poses significant challenges for synthetic image
detection. To address this issue, we explore two artifact types introduced
during the generation process: (1) latent distribution deviations and (2)
decoding-induced smoothing effects, which manifest as inconsistencies in local
textures, edges, and color transitions. Leveraging local pixel dependencies
(LPD) properties rooted in Markov Random Fields, we reconstruct synthetic
images using neighboring pixel information to expose disruptions in texture
continuity and edge coherence. Building upon LPD, we propose FerretNet, a
lightweight neural network with only 1.1M parameters that delivers efficient
and robust synthetic image detection. Extensive experiments demonstrate that
FerretNet, trained exclusively on the 4-class ProGAN dataset, achieves an
average accuracy of 97.1% on an open-world benchmark comprising across 22
generative models, surpassing state-of-the-art methods by 10.6%.

</details>


### [41] [Concepts in Motion: Temporal Bottlenecks for Interpretable Video Classification](https://arxiv.org/abs/2509.20899)
*Patrick Knab,Sascha Marton,Philipp J. Schubert,Drago Guggiana,Christian Bartelt*

Main category: cs.CV

TL;DR: MoTIF是一个受Transformer启发的框架，用于视频分类，它将概念瓶颈模型扩展到视频数据，并能处理任意长度的序列。


<details>
  <summary>Details</summary>
Motivation: 现有的概念瓶颈模型（CBMs）在图像分类方面取得了显著进展，但难以扩展到视频数据，因为视频数据具有重要的时间依赖性。

Method: MoTIF是一个受Transformer启发的架构设计，它将概念瓶颈模型适应于视频分类，并处理任意长度的序列。它能够从全局、局部和时间依赖性三个方面来分析概念。

Result: 概念建模范式可以有效地迁移到视频数据，从而在时间背景下更好地理解概念贡献，同时保持具有竞争力的性能。

Conclusion: MoTIF成功地将概念瓶颈模型扩展到视频分类，并提供了对概念在时间背景下作用的深入理解，同时保持了良好的性能。

Abstract: Conceptual models such as Concept Bottleneck Models (CBMs) have driven
substantial progress in improving interpretability for image classification by
leveraging human-interpretable concepts. However, extending these models from
static images to sequences of images, such as video data, introduces a
significant challenge due to the temporal dependencies inherent in videos,
which are essential for capturing actions and events. In this work, we
introduce MoTIF (Moving Temporal Interpretable Framework), an architectural
design inspired by a transformer that adapts the concept bottleneck framework
for video classification and handles sequences of arbitrary length. Within the
video domain, concepts refer to semantic entities such as objects, attributes,
or higher-level components (e.g., 'bow', 'mount', 'shoot') that reoccur across
time - forming motifs collectively describing and explaining actions. Our
design explicitly enables three complementary perspectives: global concept
importance across the entire video, local concept relevance within specific
windows, and temporal dependencies of a concept over time. Our results
demonstrate that the concept-based modeling paradigm can be effectively
transferred to video data, enabling a better understanding of concept
contributions in temporal contexts while maintaining competitive performance.
Code available at github.com/patrick-knab/MoTIF.

</details>


### [42] [FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data](https://arxiv.org/abs/2509.20905)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

TL;DR: FSMODNet通过跨模态特征融合和可变形注意力机制，在数据有限的情况下提高了多光谱目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决在数据标注有限的情况下，实现可见光和热成像两种模态下的目标检测挑战。

Method: 提出了一种名为"FSMODNet"的框架，利用可变形注意力机制融合跨模态特征。

Result: 在两个公共数据集上，FSMODNet在数据稀疏的条件下表现出有效性，优于几个基于现有先进模型的基线模型。

Conclusion: FSMODNet能够有效融合可见光和热成像的独特优势，在复杂光照和环境条件下展现出强大的适应性，从而在数据有限的情况下实现鲁棒的目标检测。

Abstract: Few-shot multispectral object detection (FSMOD) addresses the challenge of
detecting objects across visible and thermal modalities with minimal annotated
data. In this paper, we explore this complex task and introduce a framework
named "FSMODNet" that leverages cross-modality feature integration to improve
detection performance even with limited labels. By effectively combining the
unique strengths of visible and thermal imagery using deformable attention, the
proposed method demonstrates robust adaptability in complex illumination and
environmental conditions. Experimental results on two public datasets show
effective object detection performance in challenging low-data regimes,
outperforming several baselines we established from state-of-the-art models.
All code, models, and experimental data splits can be found at
https://anonymous.4open.science/r/Test-B48D.

</details>


### [43] [Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences](https://arxiv.org/abs/2509.20906)
*Julius Pesonen,Arno Solin,Eija Honkavaara*

Main category: cs.CV

TL;DR: 本研究提出使用粒子滤波器进行3D目标定位，特别是在计算资源有限或目标距离较远的情况下，解决了传统密集深度估计或3D场景重建不可行的问题。


<details>
  <summary>Details</summary>
Motivation: 在安全关键的监控任务（如无人机野火监测）中，基于一系列相机测量值对3D目标进行定位至关重要。然而，传统的密集深度估计或3D场景重建方法在处理远距离目标或计算资源受限的情况下并不可行。

Method: 本研究提出使用粒子滤波器来解决单目标和多目标场景下的3D目标定位问题。

Result: 研究通过3D仿真和基于GNSS的无人机图像序列进行了实验。结果表明，在传统方法失效的情况下，粒子滤波器能够基于相机姿态和图像分割来解决实际的定位任务。此外，该粒子滤波器不依赖于特定的检测方法，具有良好的灵活性。

Conclusion: 粒子滤波器是一种有效且灵活的3D目标定位方法，特别适用于计算资源有限或目标距离较远等传统方法难以处理的场景。该方法结合现有的图像分割模型，可以实现无人机野火监测等实际应用。

Abstract: 3D object localisation based on a sequence of camera measurements is
essential for safety-critical surveillance tasks, such as drone-based wildfire
monitoring. Localisation of objects detected with a camera can typically be
solved with dense depth estimation or 3D scene reconstruction. However, in the
context of distant objects or tasks limited by the amount of available
computational resources, neither solution is feasible. In this paper, we show
that the task can be solved using particle filters for both single and multiple
target scenarios. The method was studied using a 3D simulation and a
drone-based image segmentation sequence with global navigation satellite system
(GNSS)-based camera pose estimates. The results showed that a particle filter
can be used to solve practical localisation tasks based on camera poses and
image segments in these situations where other solutions fail. The particle
filter is independent of the detection method, making it flexible for new
tasks. The study also demonstrates that drone-based wildfire monitoring can be
conducted using the proposed method paired with a pre-existing image
segmentation model.

</details>


### [44] [SwinMamba: A hybrid local-global mamba framework for enhancing semantic segmentation of remotely sensed images](https://arxiv.org/abs/2509.20918)
*Qinfeng Zhu,Han Li,Liang He,Lei Fan*

Main category: cs.CV

TL;DR: SwinMamba结合了Swin Transformer和Vision Mamba的优点，通过在不同阶段采用局部和全局扫描，解决了Vision Mamba在遥感影像语义分割中对局部特征捕捉不足的问题，并在LoveDA和ISPRS Potsdam数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 遥感影像语义分割任务面临高空间分辨率、复杂场景结构和多样化对象尺度的挑战。虽然Vision Mamba具有全局感受野和低计算复杂度，但其全局扫描方式容易忽略纹理和边缘等关键局部特征。

Method: 提出了一种名为SwinMamba的新框架，该框架借鉴了Swin Transformer的设计，将局部Mamba扫描与移位窗口相结合，实现了全局感受野和局部特征捕捉的增强。具体来说，前两个阶段使用局部扫描捕捉细节，后两个阶段使用全局扫描融合上下文信息。重叠的移位窗口增强了跨区域信息交换，促进了特征融合。

Result: 在LoveDA和ISPRS Potsdam数据集上的大量实验表明，SwinMamba的性能优于现有最先进的方法。

Conclusion: SwinMamba在遥感影像语义分割方面是一种有效且具有潜力的改进方法，能够更好地捕捉局部和全局特征。

Abstract: Semantic segmentation of remote sensing imagery is a fundamental task in
computer vision, supporting a wide range of applications such as land use
classification, urban planning, and environmental monitoring. However, this
task is often challenged by the high spatial resolution, complex scene
structures, and diverse object scales present in remote sensing data. To
address these challenges, various deep learning architectures have been
proposed, including convolutional neural networks, Vision Transformers, and the
recently introduced Vision Mamba. Vision Mamba features a global receptive
field and low computational complexity, demonstrating both efficiency and
effectiveness in image segmentation. However, its reliance on global scanning
tends to overlook critical local features, such as textures and edges, which
are essential for achieving accurate segmentation in remote sensing contexts.
To tackle this limitation, we propose SwinMamba, a novel framework inspired by
the Swin Transformer. SwinMamba integrates localized Mamba-style scanning
within shifted windows with a global receptive field, to enhance the model's
perception of both local and global features. Specifically, the first two
stages of SwinMamba perform local scanning to capture fine-grained details,
while its subsequent two stages leverage global scanning to fuse broader
contextual information. In our model, the use of overlapping shifted windows
enhances inter-region information exchange, facilitating more robust feature
integration across the entire image. Extensive experiments on the LoveDA and
ISPRS Potsdam datasets demonstrate that SwinMamba outperforms state-of-the-art
methods, underscoring its effectiveness and potential as a superior solution
for semantic segmentation of remotely sensed imagery.

</details>


### [45] [Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework](https://arxiv.org/abs/2509.20923)
*Wenhao Tang,Heng Fang,Ge Wu,Xiang Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出了一种基于pack的MIL框架，通过将多个采样、可变长度的特征序列打包成固定长度的序列，实现批量训练并保留数据异质性。同时，引入残差分支和注意力驱动的下采样器来处理多幻灯片监督和特征压缩，从而提高计算病理学中的癌症诊断和预后分析的准确性，并显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 计算病理学（CPath）中的全切片图像（WSIs）具有极长的序列长度、显著的长度变化和有限的监督，导致数据异质性和冗余性高，现有方法在训练效率和优化方面存在妥协。

Method: 提出了一种基于pack的MIL框架，通过将多个采样、可变长度的特征序列打包成固定长度的序列，实现批量训练并保留数据异质性。引入残差分支，将多个幻灯片的丢弃特征组合成一个超幻灯片，并使用定制标签进行训练，以实现多幻灯片监督并减少特征采样损失。引入注意力驱动的下采样器来压缩两个分支中的特征，以减少冗余。

Result: 与现有方法相比，该方法在PANDA(UNI)数据集上准确性提高了8%，训练时间仅为原来的12%。

Conclusion: 计算病理学中的数据挑战，如序列长度变化、异质性和冗余性，可以通过提出的pack-based MIL框架得到有效解决，该框架在提高准确性和训练效率方面取得了显著成果，并为基础模型时代的研究提供了潜力。

Abstract: Computational pathology (CPath) digitizes pathology slides into whole slide
images (WSIs), enabling analysis for critical healthcare tasks such as cancer
diagnosis and prognosis. However, WSIs possess extremely long sequence lengths
(up to 200K), significant length variations (from 200 to 200K), and limited
supervision. These extreme variations in sequence length lead to high data
heterogeneity and redundancy. Conventional methods often compromise on training
efficiency and optimization to preserve such heterogeneity under limited
supervision. To comprehensively address these challenges, we propose a
pack-based MIL framework. It packs multiple sampled, variable-length feature
sequences into fixed-length ones, enabling batched training while preserving
data heterogeneity. Moreover, we introduce a residual branch that composes
discarded features from multiple slides into a hyperslide which is trained with
tailored labels. It offers multi-slide supervision while mitigating feature
loss from sampling. Meanwhile, an attention-driven downsampler is introduced to
compress features in both branches to reduce redundancy. By alleviating these
challenges, our approach achieves an accuracy improvement of up to 8% while
using only 12% of the training time in the PANDA(UNI). Extensive experiments
demonstrate that focusing data challenges in CPath holds significant potential
in the era of foundation models. The code is
https://github.com/FangHeng/PackMIL

</details>


### [46] [SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation](https://arxiv.org/abs/2509.20927)
*Akihisa Watanabe,Jiawei Ren,Li Siyao,Yichen Peng,Erwin Wu,Edgar Simo-Serra*

Main category: cs.CV

TL;DR: SimDiff通过将物理模拟器约束整合到扩散模型的去噪过程中，实现了高效且可控的物理运动生成，避免了传统方法的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过基于模拟器的运动投影层来保证物理合理性，但这种方法计算成本高昂，且无法并行处理。

Method: 提出SimDiff，一种将环境参数（如重力、风等）直接整合到扩散模型的去噪过程中的模拟器约束扩散模型。通过对这些参数进行条件约束，SimDiff在推理时无需重复调用模拟器即可生成物理上合理的运动，并允许对物理系数进行细粒度控制。

Result: SimDiff能够高效地生成物理上合理的运动，并实现了对物理系数的细粒度控制，同时展现出对未见过的环境参数组合的泛化能力。

Conclusion: SimDiff通过将物理模拟器约束作为一种引导机制整合到扩散模型中，克服了现有方法的计算效率低下问题，并实现了对生成运动的精确控制和良好的泛化能力。

Abstract: Generating physically plausible human motion is crucial for applications such
as character animation and virtual reality. Existing approaches often
incorporate a simulator-based motion projection layer to the diffusion process
to enforce physical plausibility. However, such methods are computationally
expensive due to the sequential nature of the simulator, which prevents
parallelization. We show that simulator-based motion projection can be
interpreted as a form of guidance, either classifier-based or classifier-free,
within the diffusion process. Building on this insight, we propose SimDiff, a
Simulator-constrained Diffusion Model that integrates environment parameters
(e.g., gravity, wind) directly into the denoising process. By conditioning on
these parameters, SimDiff generates physically plausible motions efficiently,
without repeated simulator calls at inference, and also provides fine-grained
control over different physical coefficients. Moreover, SimDiff successfully
generalizes to unseen combinations of environmental parameters, demonstrating
compositional generalization.

</details>


### [47] [Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models](https://arxiv.org/abs/2509.20939)
*Bum Jun Kim,Makoto Kawano,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 研究表明，更大的Stem核、更小的输入分辨率、平均池化以及监督ViT（而非CLIP ViT）可以提高视觉模型对高斯噪声的鲁棒性，并提出了相应的理论分析和设计指南。


<details>
  <summary>Details</summary>
Motivation: 现有研究很少分析特定视觉架构设计选择对模型鲁棒性的影响，本研究旨在填补这一空白，并提供可操作的设计规则。

Method: 对1,174个预训练视觉模型进行了广泛的评估，识别出提高高斯噪声鲁棒性的四种设计模式。然后，通过理论分析解释这些发现，将相关性转化为因果机制。具体包括：分析Stem核大小、下采样方法、池化方式（平均池化 vs. 最大池化）以及不同ViT预处理方式（监督ViT vs. CLIP ViT）对噪声鲁棒性的影响。

Result: 研究发现了四种提高高斯噪声鲁棒性的设计模式：更大的Stem核、更小的输入分辨率、平均池化和监督ViT。这些方法可以带来显著的性能提升（高达506个排名改进和21.6%的准确率增益）。理论分析证实了这些发现，并解释了其背后的因果机制，例如低通Stem核、抗混叠下采样、平均池化的无偏性和噪声抑制能力，以及CLIP ViT的脆弱性（与监督ViT相比）。

Conclusion: 本研究成功地将模型鲁棒性分解为可解释的模块，提供了理论基础来解释观察到的趋势，并为设计更鲁棒的视觉模型提供了实用的、即插即用的指南。

Abstract: While the robustness of vision models is often measured, their dependence on
specific architectural design choices is rarely dissected. We investigate why
certain vision architectures are inherently more robust to additive Gaussian
noise and convert these empirical insights into simple, actionable design
rules. Specifically, we performed extensive evaluations on 1,174 pretrained
vision models, empirically identifying four consistent design patterns for
improved robustness against Gaussian noise: larger stem kernels, smaller input
resolutions, average pooling, and supervised vision transformers (ViTs) rather
than CLIP ViTs, which yield up to 506 rank improvements and 21.6\%p accuracy
gains. We then develop a theoretical analysis that explains these findings,
converting observed correlations into causal mechanisms. First, we prove that
low-pass stem kernels attenuate noise with a gain that decreases quadratically
with kernel size and that anti-aliased downsampling reduces noise energy
roughly in proportion to the square of the downsampling factor. Second, we
demonstrate that average pooling is unbiased and suppresses noise in proportion
to the pooling window area, whereas max pooling incurs a positive bias that
grows slowly with window size and yields a relatively higher mean-squared error
and greater worst-case sensitivity. Third, we reveal and explain the
vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller
normalization standard deviations used in CLIP preprocessing amplify worst-case
sensitivity by up to 1.91 times relative to the Inception-style preprocessing
common in supervised ViTs. Our results collectively disentangle robustness into
interpretable modules, provide a theory that explains the observed trends, and
build practical, plug-and-play guidelines for designing vision models more
robust against Gaussian noise.

</details>


### [48] [Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery](https://arxiv.org/abs/2509.20941)
*Angelo Henriques,Korab Hoxha,Daniel Zapp,Peter C. Issa,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 手术场景图研究的范围界定、方法和未来方向，强调了数据鸿沟和从 GNN 到基础模型的进展。


<details>
  <summary>Details</summary>
Motivation: 为了解决理解复杂、动态的手术环境，需要结构化的关系表示，而场景图（SG）正是这种表示的关键。

Method: 本研究采用 PRISMA-ScR 指导的范围审查方法，系统地分析了手术场景图研究的进展、应用和未来方向。

Result: 研究发现，虽然手术场景图研究增长迅速，但存在“数据鸿沟”：内部视角研究（如三元组识别）主要使用真实 2D 视频，而外部视角 4D 建模则严重依赖模拟数据。在方法上，该领域已从基础图神经网络发展到专门化的基础模型，这些模型在手术环境中显著优于通用的视觉-语言大模型。场景图已被确立为分析（如工作流程识别、安全监控）和生成（如可控手术模拟）任务的基石技术。尽管数据标注和实时实现方面仍存在挑战，但新兴技术正在积极解决这些问题。

Conclusion: 手术场景图正在发展成为一种关键的语义桥梁，为新一代智能系统奠定基础，有望提高手术安全性、效率和培训效果。

Abstract: Scene graphs (SGs) provide structured relational representations crucial for
decoding complex, dynamic surgical environments. This PRISMA-ScR-guided scoping
review systematically maps the evolving landscape of SG research in surgery,
charting its applications, methodological advancements, and future directions.
Our analysis reveals rapid growth, yet uncovers a critical 'data divide':
internal-view research (e.g., triplet recognition) almost exclusively uses
real-world 2D video, while external-view 4D modeling relies heavily on
simulated data, exposing a key translational research gap. Methodologically,
the field has advanced from foundational graph neural networks to specialized
foundation models that now significantly outperform generalist large
vision-language models in surgical contexts. This progress has established SGs
as a cornerstone technology for both analysis, such as workflow recognition and
automated safety monitoring, and generative tasks like controllable surgical
simulation. Although challenges in data annotation and real-time implementation
persist, they are actively being addressed through emerging techniques.
Surgical SGs are maturing into an essential semantic bridge, enabling a new
generation of intelligent systems to improve surgical safety, efficiency, and
training.

</details>


### [49] [A Real-Time On-Device Defect Detection Framework for Laser Power-Meter Sensors via Unsupervised Learning](https://arxiv.org/abs/2509.20946)
*Dongqi Zheng,Wenjin Fu,Guangzong Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种基于视觉的自动化系统，用于检测和分类激光功率计传感器涂层的缺陷，如热损伤和划痕，以提高测量精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决在医疗和工业应用中，激光功率计传感器涂层缺陷（如热损伤和划痕）影响激光能量测量准确性的问题。

Method: 该系统采用无监督异常检测框架，利用“好”的传感器图像学习正常涂层分布模式。具体方法包括：1. 使用拉普拉斯边缘检测和K-means聚类进行预处理以分割感兴趣区域。2. 利用StyleGAN2进行合成数据增强。3. 使用UFlow神经网络架构进行多尺度特征提取和异常图生成。

Result: 在366个真实传感器图像的实验评估中，对缺陷样本的准确率为93.8%，对好样本的准确率为89.3%，图像级AUROC为0.957，像素级AUROC为0.961。

Conclusion: 该自动化系统通过自动质量控制，有望节省年成本，并且在设备上的处理时间为每张图像0.5秒，能够有效检测已知和未知类型的涂层缺陷。

Abstract: We present an automated vision-based system for defect detection and
classification of laser power meter sensor coatings. Our approach addresses the
critical challenge of identifying coating defects such as thermal damage and
scratches that can compromise laser energy measurement accuracy in medical and
industrial applications. The system employs an unsupervised anomaly detection
framework that trains exclusively on ``good'' sensor images to learn normal
coating distribution patterns, enabling detection of both known and novel
defect types without requiring extensive labeled defect datasets. Our
methodology consists of three key components: (1) a robust preprocessing
pipeline using Laplacian edge detection and K-means clustering to segment the
area of interest, (2) synthetic data augmentation via StyleGAN2, and (3) a
UFlow-based neural network architecture for multi-scale feature extraction and
anomaly map generation. Experimental evaluation on 366 real sensor images
demonstrates $93.8\%$ accuracy on defective samples and $89.3\%$ accuracy on
good samples, with image-level AUROC of 0.957 and pixel-level AUROC of 0.961.
The system provides potential annual cost savings through automated quality
control and processing times of 0.5 seconds per image in on-device
implementation.

</details>


### [50] [Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos](https://arxiv.org/abs/2509.20961)
*Sarmistha Das,R E Zera Marveen Lyngkhoi,Sriparna Saha,Alka Maurya*

Main category: cs.CV

TL;DR: FASTER是一个创新的多模态金融咨询内容摘要框架，通过结合文本和视觉信息，生成简洁、准确且具有事实依据的摘要，并能将关键视觉帧与文本内容对齐，提升了金融信息的易获取性和可操作性。同时，研究者还发布了Fin-APT数据集以支持相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有的金融咨询内容，特别是播客视频，虽然传播广泛，但由于其冗长和多模态的特性（通常长达30-40分钟），从中提取有价值的信息仍然困难。本研究旨在解决这一挑战。

Method: FASTER框架通过以下方式解决问题：1.提取特定模态的特征：使用BLIP提取视觉描述，OCR提取文本模式，以及基于Whisper的语音转录和说话人日志分析（BOS）作为基础特征。2.生成优化、简洁的摘要：采用改进的基于直接偏好优化（DPO）的损失函数，并结合BOS进行事实核查，以确保摘要的精确性、相关性和事实一致性。3.对齐视觉关键帧与文本：利用基于排序器的检索机制将关键帧与摘要内容进行匹配，增强可解释性和跨模态的一致性。此外，研究者还引入了Fin-APT数据集（包含470个公开的金融咨询视频），以应对数据资源稀缺的问题。

Result: 通过在多个领域进行的广泛实验，FASTER被证实相比于大型语言模型（LLMs）和视觉-语言模型（VLMs）在性能、鲁棒性和泛化能力上表现更优。

Conclusion: FASTER框架为多模态摘要设定了新的标准，使得金融咨询内容更加易于获取和实践，为相关领域的研究开辟了新的可能性。本研究提出的Fin-APT数据集和代码已公开。

Abstract: The dynamic propagation of social media has broadened the reach of financial
advisory content through podcast videos, yet extracting insights from lengthy,
multimodal segments (30-40 minutes) remains challenging. We introduce FASTER
(Financial Advisory Summariser with Textual Embedded Relevant images), a
modular framework that tackles three key challenges: (1) extracting
modality-specific features, (2) producing optimized, concise summaries, and (3)
aligning visual keyframes with associated textual points. FASTER employs BLIP
for semantic visual descriptions, OCR for textual patterns, and Whisper-based
transcription with Speaker diarization as BOS features. A modified Direct
Preference Optimization (DPO)-based loss function, equipped with BOS-specific
fact-checking, ensures precision, relevance, and factual consistency against
the human-aligned summary. A ranker-based retrieval mechanism further aligns
keyframes with summarized content, enhancing interpretability and cross-modal
coherence. To acknowledge data resource scarcity, we introduce Fin-APT, a
dataset comprising 470 publicly accessible financial advisory pep-talk videos
for robust multimodal research. Comprehensive cross-domain experiments confirm
FASTER's strong performance, robustness, and generalizability when compared to
Large Language Models (LLMs) and Vision-Language Models (VLMs). By establishing
a new standard for multimodal summarization, FASTER makes financial advisory
content more accessible and actionable, thereby opening new avenues for
research. The dataset and code are available at:
https://github.com/sarmistha-D/FASTER

</details>


### [51] [An Adaptor for Triggering Semi-Supervised Learning to Out-of-Box Serve Deep Image Clustering](https://arxiv.org/abs/2509.20976)
*Yue Duan,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ASD的适配器，能够实现SSL（自监督学习）在深度图像聚类任务中的冷启动，无需任何先验知识。


<details>
  <summary>Details</summary>
Motivation: 现有的深度聚类框架虽然集成了SSL技术，但通常需要预训练、聚类学习或已训练的聚类模型，这限制了SSL学习器在图像聚类任务中的灵活应用和开箱即用性。

Method: ASD适配器首先从无标签数据中随机采样伪标签数据，并训练一个实例级分类器来学习这些数据。然后，通过跟踪预测的类别转换来提取实例级类别的深层相似性，并利用这些相似性为伪标签数据分配聚类级标签。最后，利用带有聚类级标签的伪标签数据来驱动在无标签数据上训练的通用SSL学习器进行图像聚类。

Result: ASD在多个基准测试中表现优于最新的深度图像聚类方法，并且与使用真实标签的SSL方法相比，精度差距极小（例如，在CIFAR-10上仅为1.33%）。此外，ASD还能提升现有集成SSL的深度图像聚类方法的性能。

Conclusion: ASD是一种有效的适配器，解决了SSL在深度图像聚类中冷启动的问题，并在性能上超越了现有方法。

Abstract: Recently, some works integrate SSL techniques into deep clustering frameworks
to enhance image clustering performance. However, they all need pretraining,
clustering learning, or a trained clustering model as prerequisites, limiting
the flexible and out-of-box application of SSL learners in the image clustering
task. This work introduces ASD, an adaptor that enables the cold-start of SSL
learners for deep image clustering without any prerequisites. Specifically, we
first randomly sample pseudo-labeled data from all unlabeled data, and set an
instance-level classifier to learn them with semantically aligned
instance-level labels. With the ability of instance-level classification, we
track the class transitions of predictions on unlabeled data to extract
high-level similarities of instance-level classes, which can be utilized to
assign cluster-level labels to pseudo-labeled data. Finally, we use the
pseudo-labeled data with assigned cluster-level labels to trigger a general SSL
learner trained on the unlabeled data for image clustering. We show the
superior performance of ASD across various benchmarks against the latest deep
image clustering approaches and very slight accuracy gaps compared to SSL
methods using ground-truth, e.g., only 1.33% on CIFAR-10. Moreover, ASD can
also further boost the performance of existing SSL-embedded deep image
clustering methods.

</details>


### [52] [SiNGER: A Clearer Voice Distills Vision Transformers Further](https://arxiv.org/abs/2509.20986)
*Geunhyeok Yu,Sunjae Jeong,Yoonyoung Choi,Jaeseung Kim,Hyoseok Hwang*

Main category: cs.CV

TL;DR: Vision Transformer (ViT) 骨干模型存在高范数伪影问题，影响表示质量。知识蒸馏时，这些伪影会主导目标，导致学生模型过拟合伪影，忽视信息信号，削弱大模型带来的收益。本研究提出 Singular Nullspace-Guided Energy Reallocation (SiNGER) 框架，通过在教师特征提炼过程中利用零空间引导扰动，在抑制伪影的同时保留信息，有效解决了伪影问题。该方法通过 LoRA 适配器高效实现，所需结构改动最小。实验证明 SiNGER 显著提升学生模型性能，在多个下游任务中达到最先进水平，并生成更清晰、更具可解释性的表示。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer (ViT) 骨干模型存在高范数伪影问题，导致表示质量下降。在知识蒸馏过程中，这些伪影会主导优化目标，使学生模型过拟合伪影，从而削弱大模型带来的性能提升。先前的方法在抑制伪影和保留教师模型信息信号之间存在权衡。本研究旨在解决此问题，提出一种新的蒸馏框架，能在抑制伪影的同时保留信息信号。

Method: 本研究提出 Singular Nullspace-Guided Energy Reallocation (SiNGER) 框架。其核心思想是对教师特征进行原则性提炼，利用零空间引导扰动来抑制伪影并保留信息。随后，将提炼后的教师特征蒸馏给学生模型。该扰动通过 LoRA 适配器高效实现，对模型结构的改动最小。

Result: SiNGER 框架在多个下游任务上持续提升学生模型的性能，达到了最先进的水平。实验表明，该方法能够生成更清晰、更具可解释性的表示。

Conclusion: Singular Nullspace-Guided Energy Reallocation (SiNGER) 框架能够有效抑制 Vision Transformer 中的高范数伪影，同时保留教师模型中的信息信号，显著提升学生模型的性能和表示质量，并在多个下游任务中取得最先进的成果。

Abstract: Vision Transformers are widely adopted as the backbone of vision foundation
models, but they are known to produce high-norm artifacts that degrade
representation quality. When knowledge distillation transfers these features to
students, high-norm artifacts dominate the objective, so students overfit to
artifacts and underweight informative signals, diminishing the gains from
larger models. Prior work attempted to remove artifacts but encountered an
inherent trade-off between artifact suppression and preserving informative
signals from teachers. To address this, we introduce Singular Nullspace-Guided
Energy Reallocation (SiNGER), a novel distillation framework that suppresses
artifacts while preserving informative signals. The key idea is principled
teacher feature refinement: during refinement, we leverage the nullspace-guided
perturbation to preserve information while suppressing artifacts. Then, the
refined teacher's features are distilled to a student. We implement this
perturbation efficiently with a LoRA-based adapter that requires minimal
structural modification. Extensive experiments show that \oursname consistently
improves student models, achieving state-of-the-art performance in multiple
downstream tasks and producing clearer and more interpretable representations.

</details>


### [53] [Fast-SEnSeI: Lightweight Sensor-Independent Cloud Masking for On-board Multispectral Sensors](https://arxiv.org/abs/2509.20991)
*Jan Kněžík,Jonáš Herec,Rado Pitoňák*

Main category: cs.CV

TL;DR: Fast-SEnSeI是一个轻量级、传感器无关的编码器模块，可实现跨多光谱传感器灵活的板载云分割，并能处理不同的波段配置。


<details>
  <summary>Details</summary>
Motivation: 大多数云分割模型与特定传感器配置紧密耦合，并且依赖于地面处理。本研究旨在解决这一问题，提出一个轻量级、传感器无关的编码器模块，以实现灵活的板载云分割。

Method: Fast-SEnSeI是基于SENSeI-v2构建的，它集成了改进的光谱描述符、轻量级架构和鲁棒的填充带处理。该模块接受任意的光谱带组合及其波长，生成固定大小的特征图，然后输入到一个基于修改版U-Net的紧凑型、量化分割模型中。该模块使用Apache TVM在嵌入式CPU上高效运行，而分割模型则部署在FPGA上，形成一个适用于航天级硬件的CPU-FPGA混合流水线。

Result: 在Sentinel-2和Landsat 8数据集上的评估表明，Fast-SEnSeI在各种输入配置下都能实现准确的分割。

Conclusion: Fast-SEnSeI为在资源受限的航天器上进行多传感器云分割提供了一种高效且灵活的解决方案。

Abstract: Cloud segmentation is a critical preprocessing step for many Earth
observation tasks, yet most models are tightly coupled to specific sensor
configurations and rely on ground-based processing. In this work, we propose
Fast-SEnSeI, a lightweight, sensor-independent encoder module that enables
flexible, on-board cloud segmentation across multispectral sensors with varying
band configurations. Building upon SEnSeI-v2, Fast-SEnSeI integrates an
improved spectral descriptor, lightweight architecture, and robust padding-band
handling. It accepts arbitrary combinations of spectral bands and their
wavelengths, producing fixed-size feature maps that feed into a compact,
quantized segmentation model based on a modified U-Net. The module runs
efficiently on embedded CPUs using Apache TVM, while the segmentation model is
deployed on FPGA, forming a CPU-FPGA hybrid pipeline suitable for
space-qualified hardware. Evaluations on Sentinel-2 and Landsat 8 datasets
demonstrate accurate segmentation across diverse input configurations.

</details>


### [54] [A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.21008)
*Qinqin He,Jiaqi Weng,Jialing Tao,Hui Xue*

Main category: cs.CV

TL;DR: SNCE通过操纵单个神经元来精确擦除文本到图像模型中的有害概念，同时保持图像质量和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的概念擦除方法在精确移除目标概念的同时，难以避免图像质量的下降，并且存在安全风险，可能生成有害内容。

Method: 提出了一种基于单个神经元的概念擦除（SNCE）方法。首先，训练稀疏自编码器（SAE）将文本嵌入映射到一个稀疏、解耦的潜在空间，其中单个神经元与原子语义概念紧密对齐。然后，设计了一种基于调制频率评分激活模式的新型神经元识别方法，以精确定位负责有害概念的神经元。最后，通过抑制有害概念特异性神经元的激活来实现概念擦除。

Result: SNCE在目标概念擦除方面达到了最先进的效果，同时对图像质量的干扰最小，并且能够保持模型对非目标概念的生成能力。该方法还表现出对对抗性攻击的强大鲁棒性，显著优于现有方法。

Conclusion: SNCE通过精确操纵单个神经元，能够有效地防止有害内容的生成，同时最大限度地减少对图像质量的影响，并保持模型的整体性能和鲁棒性。

Abstract: Text-to-image models exhibit remarkable capabilities in image generation.
However, they also pose safety risks of generating harmful content. A key
challenge of existing concept erasure methods is the precise removal of target
concepts while minimizing degradation of image quality. In this paper, we
propose Single Neuron-based Concept Erasure (SNCE), a novel approach that can
precisely prevent harmful content generation by manipulating only a single
neuron. Specifically, we train a Sparse Autoencoder (SAE) to map text
embeddings into a sparse, disentangled latent space, where individual neurons
align tightly with atomic semantic concepts. To accurately locate neurons
responsible for harmful concepts, we design a novel neuron identification
method based on the modulated frequency scoring of activation patterns. By
suppressing activations of the harmful concept-specific neuron, SNCE achieves
surgical precision in concept erasure with minimal disruption to image quality.
Experiments on various benchmarks demonstrate that SNCE achieves
state-of-the-art results in target concept erasure, while preserving the
model's generation capabilities for non-target concepts. Additionally, our
method exhibits strong robustness against adversarial attacks, significantly
outperforming existing methods.

</details>


### [55] [OmniPlantSeg: Species Agnostic 3D Point Cloud Organ Segmentation for High-Resolution Plant Phenotyping Across Modalities](https://arxiv.org/abs/2509.21038)
*Andreas Gilson,Lukas Meyer,Oliver Scholz,Ute Schmid*

Main category: cs.CV

TL;DR: KDSS是一种适用于植物点云的子采样算法，可以保留点云的完整分辨率，实现对不同物种和传感器数据的分割。


<details>
  <summary>Details</summary>
Motivation: 现有植物器官点云分割方法存在问题特异性强、需要复杂的预处理和降采样的问题。

Method: 提出了一种名为KDSS的简单有效的子采样算法，该算法不依赖于特定的植物物种或传感器。

Result: 将KDSS与现有的分割模型结合，在不同传感器（摄影测量、激光三角测量、LiDAR）和不同植物物种的数据上取得了满意的结果。

Conclusion: KDSS是一种轻量级的、能够保留分辨率的替代方法，适用于各种植物物种和传感器，可以替代密集的预处理和降采样方法。

Abstract: Accurate point cloud segmentation for plant organs is crucial for 3D plant
phenotyping. Existing solutions are designed problem-specific with a focus on
certain plant species or specified sensor-modalities for data acquisition.
Furthermore, it is common to use extensive pre-processing and down-sample the
plant point clouds to meet hardware or neural network input size requirements.
We propose a simple, yet effective algorithm KDSS for sub-sampling of
biological point clouds that is agnostic to sensor data and plant species. The
main benefit of this approach is that we do not need to down-sample our input
data and thus, enable segmentation of the full-resolution point cloud.
Combining KD-SS with current state-of-the-art segmentation models shows
satisfying results evaluated on different modalities such as photogrammetry,
laser triangulation and LiDAR for various plant species. We propose KD-SS as
lightweight resolution-retaining alternative to intensive pre-processing and
down-sampling methods for plant organ segmentation regardless of used species
and sensor modality.

</details>


### [56] [Background Prompt for Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2509.21055)
*Songyue Cai,Zongqian Wu,Yujie Mo,Liang Peng,Ping Hu,Xiaoshuang Shi,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: Mambo是一个用于少样本分布外检测的新框架，通过学习背景提示和自校准调优来提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的少样本分布外检测方法在前景背景分解时，过分依赖局部类别相似性和固定的背景块提取策略，导致鲁棒性不佳。

Method: 提出Mambo框架，首先学习背景提示以获得包含背景和图像语义信息的局部背景相似性，然后利用局部类别相似性进行细化。最后，结合细化的局部背景相似性和局部类别相似性进行背景提取。此外，提出自校准调优策略，考虑样本多样性，灵活选择背景块数量。

Result: 在真实世界数据集上的广泛实验表明，Mambo在分布外检测和近分布外检测方面取得了优于现有最先进方法（SOTA）的性能。

Conclusion: Mambo通过引入背景提示和自校准调优，克服了现有方法的局限性，在少样本分布外检测任务上取得了显著的性能提升。

Abstract: Existing foreground-background (FG-BG) decomposition methods for the few-shot
out-of-distribution (FS-OOD) detection often suffer from low robustness due to
over-reliance on the local class similarity and a fixed background patch
extraction strategy. To address these challenges, we propose a new FG-BG
decomposition framework, namely Mambo, for FS-OOD detection. Specifically, we
propose to first learn a background prompt to obtain the local background
similarity containing both the background and image semantic information, and
then refine the local background similarity using the local class similarity.
As a result, we use both the refined local background similarity and the local
class similarity to conduct background extraction, reducing the dependence of
the local class similarity in previous methods. Furthermore, we propose the
patch self-calibrated tuning to consider the sample diversity to flexibly
select numbers of background patches for different samples, and thus exploring
the issue of fixed background extraction strategies in previous methods.
Extensive experiments on real-world datasets demonstrate that our proposed
Mambo achieves the best performance, compared to SOTA methods in terms of OOD
detection and near OOD detection setting. The source code will be released at
https://github.com/YuzunoKawori/Mambo.

</details>


### [57] [Stratify or Die: Rethinking Data Splits in Image Segmentation](https://arxiv.org/abs/2509.21056)
*Naga Venkata Sai Jitin Jami,Thomas Altstidl,Jonas Mueller,Jindong Li,Dario Zanca,Bjoern Eskofier,Heike Leutheuser*

Main category: cs.CV

TL;DR: 数据集随机划分会导致测试集代表性不足，进而引起评估偏差和模型泛化能力下降。本研究提出迭代像素分层（IPS）和 Wasserstein 驱动的进化分层（WDES）两种方法来解决图像分割中的数据集划分问题。WDES 是一种新的遗传算法，旨在最小化 Wasserstein 距离，从而优化标签分布的相似性。实验证明 WDES 能够生成更具代表性的数据集划分，并在各种分割任务中降低模型评估的性能方差。


<details>
  <summary>Details</summary>
Motivation: 随机划分数据集会导致测试集代表性不足，评估结果产生偏差，模型泛化能力变差。现有方法如分层抽样在图像分割任务中应用存在挑战。

Method: 提出迭代像素分层（IPS）和 Wasserstein 驱动的进化分层（WDES）两种方法。WDES 采用遗传算法最小化 Wasserstein 距离，以优化数据集划分的标签分布相似性。

Result: WDES 相比随机抽样能生成更具代表性的数据集划分。在街景、医学成像、卫星图像等多种分割任务中，WDES 降低了性能方差，提高了模型评估的准确性。WDES 在处理小型、不平衡和低多样性数据集方面尤为有效。

Conclusion: WDES 是一种有效的、可扩展的数据集划分方法，能够解决图像分割任务中的评估偏差问题，尤其是在处理具有挑战性的数据集时。

Abstract: Random splitting of datasets in image segmentation often leads to
unrepresentative test sets, resulting in biased evaluations and poor model
generalization. While stratified sampling has proven effective for addressing
label distribution imbalance in classification tasks, extending these ideas to
segmentation remains challenging due to the multi-label structure and class
imbalance typically present in such data. Building on existing stratification
concepts, we introduce Iterative Pixel Stratification (IPS), a straightforward,
label-aware sampling method tailored for segmentation tasks. Additionally, we
present Wasserstein-Driven Evolutionary Stratification (WDES), a novel genetic
algorithm designed to minimize the Wasserstein distance, thereby optimizing the
similarity of label distributions across dataset splits. We prove that WDES is
globally optimal given enough generations. Using newly proposed statistical
heterogeneity metrics, we evaluate both methods against random sampling and
find that WDES consistently produces more representative splits. Applying WDES
across diverse segmentation tasks, including street scenes, medical imaging,
and satellite imagery, leads to lower performance variance and improved model
evaluation. Our results also highlight the particular value of WDES in handling
small, imbalanced, and low-diversity datasets, where conventional splitting
strategies are most prone to bias.

</details>


### [58] [EnGraf-Net: Multiple Granularity Branch Network with Fine-Coarse Graft Grained for Classification Task](https://arxiv.org/abs/2509.21061)
*Riccardo La Grassa,Ignazio Gallo,Nicola Landro*

Main category: cs.CV

TL;DR: EnGraf-Net通过利用分层语义关联作为监督信号，在细粒度图像分类任务上取得了优于现有模型（无需裁剪或手动标注）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度分类模型依赖部件标注或注意力图，但可能忽略局部特征的完整性。然而，人类识别物体不仅依靠细节，还依赖语义联想。

Method: 提出了一种名为EnGraf-Net的端到端深度神经网络模型，该模型利用分层（分类法）结构化的语义联想作为监督信号。

Result: 在CIFAR-100、CUB-200-2011和FGVC-Aircraft三个数据集上进行了广泛的实验，EnGraf-Net的性能优于许多现有模型，并与最新的先进方法具有竞争力。

Conclusion: EnGraf-Net在细粒度分类任务上表现出色，无需裁剪或手动标注，证明了利用分层语义关联的有效性。

Abstract: Fine-grained classification models are designed to focus on the relevant
details necessary to distinguish highly similar classes, particularly when
intra-class variance is high and inter-class variance is low. Most existing
models rely on part annotations such as bounding boxes, part locations, or
textual attributes to enhance classification performance, while others employ
sophisticated techniques to automatically extract attention maps. We posit that
part-based approaches, including automatic cropping methods, suffer from an
incomplete representation of local features, which are fundamental for
distinguishing similar objects. While fine-grained classification aims to
recognize the leaves of a hierarchical structure, humans recognize objects by
also forming semantic associations. In this paper, we leverage semantic
associations structured as a hierarchy (taxonomy) as supervised signals within
an end-to-end deep neural network model, termed EnGraf-Net. Extensive
experiments on three well-known datasets CIFAR-100, CUB-200-2011, and
FGVC-Aircraft demonstrate the superiority of EnGraf-Net over many existing
fine-grained models, showing competitive performance with the most recent
state-of-the-art approaches, without requiring cropping techniques or manual
annotations.

</details>


### [59] [Vision Transformers: the threat of realistic adversarial patches](https://arxiv.org/abs/2509.21084)
*Kasper Cools,Clara Maathuis,Alexander M. van Oers,Claudia S. Hübner,Nikos Deligiannis,Marijke Vandewal,Geert De Cubber*

Main category: cs.CV

TL;DR: ViTs在对抗性攻击下仍然脆弱，尤其是在对抗性补丁方面。本研究使用Creases Transformation（CT）技术设计了逼真的对抗性补丁，以误导ViT模型进行人物分类任务，并发现这些补丁可以从CNN迁移到ViT。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统日益普及，其安全性成为关键问题。本研究旨在探讨ViTs在对抗性攻击下的漏洞，特别是对抗性补丁的有效性，并研究CNN的攻击技术在ViT上的可迁移性。

Method: 本研究设计了逼真的对抗性补丁，并使用Creases Transformation（CT）技术在人物分类任务中对四种微调的ViT模型进行测试。实验评估了攻击成功率，并分析了预训练数据集规模和方法对模型抵御能力的影响。

Result: 实验结果表明，ViT模型在对抗性补丁攻击下的脆弱性差异很大，攻击成功率从40.04%到99.97%不等。这证实了对抗性补丁可以从CNN迁移到ViT，并且预训练数据和方法是影响模型安全性的关键因素。

Conclusion: 尽管ViTs在性能和鲁棒性方面优于CNNs，但它们仍然容易受到对抗性补丁的攻击。本研究证实了对抗性攻击的可迁移性，并强调了预训练策略对ViT模型安全性的重要影响。

Abstract: The increasing reliance on machine learning systems has made their security a
critical concern. Evasion attacks enable adversaries to manipulate the
decision-making processes of AI systems, potentially causing security breaches
or misclassification of targets. Vision Transformers (ViTs) have gained
significant traction in modern machine learning due to increased 1) performance
compared to Convolutional Neural Networks (CNNs) and 2) robustness against
adversarial perturbations. However, ViTs remain vulnerable to evasion attacks,
particularly to adversarial patches, unique patterns designed to manipulate AI
classification systems. These vulnerabilities are investigated by designing
realistic adversarial patches to cause misclassification in person vs.
non-person classification tasks using the Creases Transformation (CT)
technique, which adds subtle geometric distortions similar to those occurring
naturally when wearing clothing. This study investigates the transferability of
adversarial attack techniques used in CNNs when applied to ViT classification
models. Experimental evaluation across four fine-tuned ViT models on a binary
person classification task reveals significant vulnerability variations: attack
success rates ranged from 40.04% (google/vit-base-patch16-224-in21k) to 99.97%
(facebook/dino-vitb16), with google/vit-base-patch16-224 achieving 66.40% and
facebook/dinov3-vitb16 reaching 65.17%. These results confirm the
cross-architectural transferability of adversarial patches from CNNs to ViTs,
with pre-training dataset scale and methodology strongly influencing model
resilience to adversarial attacks.

</details>


### [60] [UniTransfer: Video Concept Transfer via Progressive Spatial and Timestep Decomposition](https://arxiv.org/abs/2509.21086)
*Guojun Lei,Rong Zhang,Chi Wang,Tianhang Liu,Hong Li,Zhiyuan Ma,Weiwei Xu*

Main category: cs.CV

TL;DR: UniTransfer是一种新颖的视频概念迁移架构，通过空间和扩散时间步分解，实现精确可控的视频概念迁移。


<details>
  <summary>Details</summary>
Motivation: 现有视频概念迁移方法在精确性和可控性方面存在不足，需要更精细化的处理方式。

Method: UniTransfer提出了一种新颖的架构，包括：1. 空间分解：将视频解耦为前景主体、背景和运动流三个关键部分。2. 双对单流DiT架构：用于对视频的不同组件进行细粒度控制。3. 自监督预训练：采用随机遮蔽策略，从大规模无标签视频数据中学习分解表示。4. Chain-of-Prompt (CoP)机制：受Chain-of-Thought启发，将去噪过程分解为三个不同粒度的阶段，并利用LLM进行阶段特定的指令引导，实现时间步分解。5. OpenAnimal数据集：一个以动物为中心的视频数据集，用于促进视频概念迁移的研究和基准测试。

Result: 通过大量实验证明，UniTransfer在视觉保真度和可编辑性方面均优于现有方法，实现了高质量、可控的视频概念迁移，能够处理各种参考图像和场景。

Conclusion: UniTransfer通过空间分解、时间步分解和LLM引导的CoP机制，实现了前所未有的视频概念迁移的精确性和可控性，并在OpenAnimal数据集的实验中取得了显著成果。

Abstract: We propose a novel architecture UniTransfer, which introduces both spatial
and diffusion timestep decomposition in a progressive paradigm, achieving
precise and controllable video concept transfer. Specifically, in terms of
spatial decomposition, we decouple videos into three key components: the
foreground subject, the background, and the motion flow. Building upon this
decomposed formulation, we further introduce a dual-to-single-stream DiT-based
architecture for supporting fine-grained control over different components in
the videos. We also introduce a self-supervised pretraining strategy based on
random masking to enhance the decomposed representation learning from
large-scale unlabeled video data. Inspired by the Chain-of-Thought reasoning
paradigm, we further revisit the denoising diffusion process and propose a
Chain-of-Prompt (CoP) mechanism to achieve the timestep decomposition. We
decompose the denoising process into three stages of different granularity and
leverage large language models (LLMs) for stage-specific instructions to guide
the generation progressively. We also curate an animal-centric video dataset
called OpenAnimal to facilitate the advancement and benchmarking of research in
video concept transfer. Extensive experiments demonstrate that our method
achieves high-quality and controllable video concept transfer across diverse
reference images and scenes, surpassing existing baselines in both visual
fidelity and editability. Web Page:
https://yu-shaonian.github.io/UniTransfer-Web/

</details>


### [61] [VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception](https://arxiv.org/abs/2509.21100)
*Ziang Yan,Xinhao Li,Yinan He,Zhengrong Yue,Xiangyu Zeng,Yali Wang,Yu Qiao,Limin Wang,Yi Wang*

Main category: cs.CV

TL;DR: 通过迭代感知来增强多模态大语言模型（MLLM）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖LLM推理来分析解析后的视觉信息，但受限于静态感知阶段，限制了MLLM达到人类水平的感知和理解能力。

Method: 提出视觉测试时缩放（VTTS）方法，通过在推理过程中进行迭代感知来增强MLLM的推理能力。VTTS借鉴了人类的层级注意力机制，通过不断更新的文本预测来指导，逐步聚焦于高置信度的时空区域，并结合了迭代感知（ITP）机制，利用强化学习和时空监督来优化推理过程。同时，发布了VTTS-80K数据集以支持该范式。

Result: VTTS能够通过增加感知计算来提升MLLM的性能。在多个基准测试中，新模型Videochat-R1.5相比Qwen2.5VL-3B和-7B等模型在视频对话、视频推理和时空感知任务上平均提升超过5%。

Conclusion: VTTS是一种有效且泛化性强的方法，通过迭代感知显著提升了MLLM在多种任务上的推理和理解能力。

Abstract: Inducing reasoning in multimodal large language models (MLLMs) is critical
for achieving human-level perception and understanding. Existing methods mainly
leverage LLM reasoning to analyze parsed visuals, often limited by static
perception stages. This paper introduces Visual Test-Time Scaling (VTTS), a
novel approach to enhance MLLMs' reasoning via iterative perception during
inference. VTTS mimics humans' hierarchical attention by progressively refining
focus on high-confidence spatio-temporal regions, guided by updated textual
predictions. Specifically, VTTS employs an Iterative Perception (ITP)
mechanism, incorporating reinforcement learning with spatio-temporal
supervision to optimize reasoning. To support this paradigm, we also present
VTTS-80K, a dataset tailored for iterative perception. These designs allows a
MLLM to enhance its performance by increasing its perceptual compute. Extensive
experiments validate VTTS's effectiveness and generalization across diverse
tasks and benchmarks. Our newly introduced Videochat-R1.5 model has achieved
remarkable improvements, with an average increase of over 5\%, compared to
robust baselines such as Qwen2.5VL-3B and -7B, across more than 15 benchmarks
that encompass video conversation, video reasoning, and spatio-temporal
perception.

</details>


### [62] [Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models](https://arxiv.org/abs/2509.21102)
*Suaiba Amina Salahuddin,Teresa Dorszewski,Marit Almenning Martiniussen,Tone Hovda,Antonio Portaluri,Solveig Thrun,Michael Kampffmeyer,Elisabeth Wetzer,Kristoffer Wickstrøm,Robert Jenssen*

Main category: cs.CV

TL;DR: Mammo-CLIP Dissect 是一个概念驱动的解释框架，用于分析用于乳腺 X 线摄影的深度学习模型，揭示它们学习的临床相关概念。


<details>
  <summary>Details</summary>
Motivation: 为了安全地将人工智能（AI）应用于临床环境，理解深度学习（DL）模型所学的知识至关重要。现有的基于像素的可解释性方法未能充分关注模型所学习的文本概念，而这些概念可能更能反映临床医生的推理过程。

Method: Mammo-CLIP Dissect 是一个概念驱动的解释框架，它利用一个专门用于乳腺 X 线摄影的视觉-语言模型（Mammo-CLIP）作为“解剖器”，为指定层中的神经元分配人类可理解的文本概念，并量化它们与领域知识的匹配程度。

Result: 与未在乳腺 X 线摄影数据上训练的模型相比，在乳腺 X 线摄影数据上训练的模型能够捕捉到更多临床相关概念，并更紧密地贴合放射科医生的工作流程。对特定任务进行微调可以增强某些概念类别（例如良性钙化）的学习，但可能会降低其他概念类别（例如密度相关特征）的学习覆盖率，这表明在专业化和泛化之间存在权衡。Mammo-CLIP Dissect 揭示了卷积神经网络（CNN）如何捕捉乳腺 X 线摄影的特定知识，并展示了特定领域训练和特定任务调整如何影响概念学习。

Conclusion: Mammo-CLIP Dissect 提供了一种系统的方法来剖析乳腺 X 线摄影深度学习模型中的概念学习，揭示了领域特定训练和任务特定适应对模型学习过程的影响，并突出了在模型专业化和泛化能力之间取得平衡的重要性。

Abstract: Understanding what deep learning (DL) models learn is essential for the safe
deployment of artificial intelligence (AI) in clinical settings. While previous
work has focused on pixel-based explainability methods, less attention has been
paid to the textual concepts learned by these models, which may better reflect
the reasoning used by clinicians. We introduce Mammo-CLIP Dissect, the first
concept-based explainability framework for systematically dissecting DL vision
models trained for mammography. Leveraging a mammography-specific
vision-language model (Mammo-CLIP) as a "dissector," our approach labels
neurons at specified layers with human-interpretable textual concepts and
quantifies their alignment to domain knowledge. Using Mammo-CLIP Dissect, we
investigate three key questions: (1) how concept learning differs between DL
vision models trained on general image datasets versus mammography-specific
datasets; (2) how fine-tuning for downstream mammography tasks affects concept
specialisation; and (3) which mammography-relevant concepts remain
underrepresented. We show that models trained on mammography data capture more
clinically relevant concepts and align more closely with radiologists'
workflows than models not trained on mammography data. Fine-tuning for
task-specific classification enhances the capture of certain concept categories
(e.g., benign calcifications) but can reduce coverage of others (e.g.,
density-related features), indicating a trade-off between specialisation and
generalisation. Our findings show that Mammo-CLIP Dissect provides insights
into how convolutional neural networks (CNNs) capture mammography-specific
knowledge. By comparing models across training data and fine-tuning regimes, we
reveal how domain-specific training and task-specific adaptation shape concept
learning. Code and concept set are available:
https://github.com/Suaiba/Mammo-CLIP-Dissect.

</details>


### [63] [MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning](https://arxiv.org/abs/2509.21113)
*Sicheng Tao,Jungang Li,Yibo Yan,Junyan Zhang,Yubo Gao,Hanqian Li,ShuHang Xun,Yuxuan Fan,Hong Chen,Jianxiang He,Xuming Hu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Video reasoning has emerged as a critical capability for multimodal large
language models (MLLMs), requiring models to move beyond static perception
toward coherent understanding of temporal dynamics in complex scenes. Yet
existing MLLMs often exhibit process inconsistency, where intermediate
reasoning drifts from video dynamics even when the final answer is correct,
undermining interpretability and robustness. To address this issue, we
introduce MOSS-ChatV, a reinforcement learning framework with a Dynamic Time
Warping (DTW)-based process reward. This rule-based reward aligns reasoning
traces with temporally grounded references, enabling efficient process
supervision without auxiliary reward models. We further identify dynamic state
prediction as a key measure of video reasoning and construct MOSS-Video, a
benchmark with annotated reasoning traces, where the training split is used to
fine-tune MOSS-ChatV and the held-out split is reserved for evaluation.
MOSS-ChatV achieves 87.2\% on MOSS-Video (test) and improves performance on
general video benchmarks such as MVBench and MMVU. The framework consistently
yields gains across different architectures, including Qwen2.5-VL and Phi-2,
confirming its broad applicability. Evaluations with GPT-4o-as-judge further
show that MOSS-ChatV produces more consistent and stable reasoning traces.

</details>


### [64] [MotionFlow:Learning Implicit Motion Flow for Complex Camera Trajectory Control in Video Generation](https://arxiv.org/abs/2509.21119)
*Guojun Lei,Chi Wang,Yikai Wang,Hong Li,Ying Song,Weiwei Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种将摄像机和物体运动统一为像素运动的新方法，利用稳定扩散网络学习运动图谱，并结合语义物体先验，生成能精确跟随摄像机轨迹并保持物体运动一致性的视频，实验证明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生成由摄像机轨迹引导的视频在保持一致性和泛化性方面存在挑战，特别是在同时存在摄像机和物体运动时。现有方法将两者分开学习，可能导致摄像机与物体相对运动的混淆。

Method: 将摄像机和物体运动统一转换为相应像素的运动。利用稳定扩散网络学习参考运动图谱，并结合提取的语义物体先验，输入到图像到视频网络中生成视频。

Result: 模型能够生成精确跟随指定摄像机轨迹并保持物体运动一致性的视频。实验证明该模型效果优于现有最先进方法。

Conclusion: 本研究提出的方法有效地解决了摄像机轨迹引导视频生成中的一致性和泛化性问题，通过统一运动表示和利用稳定扩散网络，实现了高质量的视频生成。

Abstract: Generating videos guided by camera trajectories poses significant challenges
in achieving consistency and generalizability, particularly when both camera
and object motions are present. Existing approaches often attempt to learn
these motions separately, which may lead to confusion regarding the relative
motion between the camera and the objects. To address this challenge, we
propose a novel approach that integrates both camera and object motions by
converting them into the motion of corresponding pixels. Utilizing a stable
diffusion network, we effectively learn reference motion maps in relation to
the specified camera trajectory. These maps, along with an extracted semantic
object prior, are then fed into an image-to-video network to generate the
desired video that can accurately follow the designated camera trajectory while
maintaining consistent object motions. Extensive experiments verify that our
model outperforms SOTA methods by a large margin.

</details>


### [65] [The Unwinnable Arms Race of AI Image Detection](https://arxiv.org/abs/2509.21135)
*Till Aczel,Lorenzo Vettor,Andreas Plesner,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 高维度数据和复杂性影响图像生成鉴别器的性能，中间复杂性最有利于检测伪造图像。


<details>
  <summary>Details</summary>
Motivation: 研究在图像生成与鉴别对抗中，哪种条件下鉴别器最处于劣势。

Method: 通过分析数据维度和数据复杂性（使用柯尔莫哥洛夫复杂度衡量）对鉴别器性能的影响。

Result: 研究发现，过低或过高的数据复杂性（包括维度）都会降低鉴别器检测伪造图像的能力。生成器可以完美学习简单数据集，而极端复杂的数据集会掩盖瑕疵。相反，中等复杂性的数据集为检测提供了最有利的条件，因为生成器无法完全捕捉数据分布，其错误仍然可见。

Conclusion: 生成器和鉴别器之间的竞争受数据特性影响。理解这些影响因素有助于开发更鲁棒的鉴别器。

Abstract: The rapid progress of image generative AI has blurred the boundary between
synthetic and real images, fueling an arms race between generators and
discriminators. This paper investigates the conditions under which
discriminators are most disadvantaged in this competition. We analyze two key
factors: data dimensionality and data complexity. While increased
dimensionality often strengthens the discriminators ability to detect subtle
inconsistencies, complexity introduces a more nuanced effect. Using Kolmogorov
complexity as a measure of intrinsic dataset structure, we show that both very
simple and highly complex datasets reduce the detectability of synthetic
images; generators can learn simple datasets almost perfectly, whereas extreme
diversity masks imperfections. In contrast, intermediate-complexity datasets
create the most favorable conditions for detection, as generators fail to fully
capture the distribution and their errors remain visible.

</details>


### [66] [WAVECLIP: Wavelet Tokenization for Adaptive-Resolution CLIP](https://arxiv.org/abs/2509.21153)
*Moshe Kimhi,Erez Koifman,Ehud Rivlin,Eli Schwartz,Chaim Baskin*

Main category: cs.CV

TL;DR: WAVECLIP使用基于小波分解的自适应分辨率方法，在保持CLIP模型性能的同时，显著降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 标准的CLIP模型在处理不同分辨率图像时存在效率问题，需要更灵活和计算友好的推理方法。

Method: 提出了一种名为WAVECLIP的新模型，它使用多层小波分解来替代标准的图像块嵌入，实现了从粗到精的多分辨率图像处理。通过键值缓存和因果交叉层注意力机制，模型能够重用计算，仅在需要时引入新信息。

Result: 在零样本分类任务上，WAVECLIP通过基于置信度的门控机制实现了自适应的早期退出，允许用户动态选择计算-精度权衡。该方法通过蒸馏实现，计算量显著减少，同时保持了有竞争力的准确性。

Conclusion: WAVECLIP通过引入基于小波分解的自适应分辨率推理，为CLIP模型提供了一种高效且灵活的解决方案，能够在不牺牲准确性的前提下大幅节省计算资源。

Abstract: We introduce WAVECLIP, a single unified model for adaptive resolution
inference in CLIP, enabled by wavelet-based tokenization. WAVECLIP replaces
standard patch embeddings with a multi-level wavelet decomposition, enabling
the model to process images coarse to fine while naturally supporting multiple
resolutions within the same model. At inference time, the model begins with low
resolution tokens and refines only when needed, using key-value caching and
causal cross-level attention to reuse computation, effectively introducing to
the model only new information when needed. We evaluate WAVECLIP in zero-shot
classification, demonstrating that a simple confidence-based gating mechanism
enables adaptive early exits. This allows users to dynamically choose a
compute-accuracy trade-off using a single deployed model. Our approach requires
only lightweight distillation from a frozen CLIP teacher and achieves
competitive accuracy with significant computational savings.

</details>


### [67] [Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy](https://arxiv.org/abs/2509.21173)
*Aymen Bouguerra,Daniel Montoya,Alexandra Gomez-Villa,Fabio Arnez,Chokri Mraidha*

Main category: cs.CV

TL;DR: 量化能够提升CLIP模型的校准度和鲁棒性，尤其对于预训练时校准不足的模型，同时也能改善OOD检测能力，并且存在能够同时提升零样本准确率、校准度和鲁棒性的量化感知训练方法。


<details>
  <summary>Details</summary>
Motivation: 评估量化对CLIP模型在准确率之外的可靠性指标的影响，并探索量化对校准、OOD检测等方面的具体作用，以及量化感知训练（QAT）方法在提升模型整体性能方面的潜力。

Method: 对CLIP模型进行大规模量化评估，不仅评估了分布内准确率，还全面评估了一系列可靠性指标，并通过量化感知训练（QAT）方法寻找能够同时提升模型性能的策略。

Result: 量化能够提升校准度（特别是对于预训练时校准不足的模型），但可能降低校准度（对于预训练时校准过度的模型）。然而，即使在校准度下降的情况下，OOD检测能力仍可能提高。存在一些QAT方法能够同时提升零样本准确率、校准度和OOD鲁棒性，挑战了效率与性能的权衡。

Conclusion: 量化是实现高效、可靠、鲁棒的视觉语言模型（VLMs）部署的关键技术，其作用超越了传统效率提升的范畴，能够显著改善模型的可靠性和鲁棒性。

Abstract: The powerful zero-shot generalization capabilities of vision-language models
(VLMs) like CLIP have enabled new paradigms for safety-related tasks such as
out-of-distribution (OOD) detection. However, additional aspects crucial for
the computationally efficient and reliable deployment of CLIP are still
overlooked. In particular, the impact of quantization on CLIP's performance
beyond accuracy remains underexplored. This work presents a large-scale
evaluation of quantization on CLIP models, assessing not only in-distribution
accuracy but a comprehensive suite of reliability metrics and revealing
counterintuitive results driven by pre-training source. We demonstrate that
quantization consistently improves calibration for typically underconfident
pre-trained models, while often degrading it for overconfident variants.
Intriguingly, this degradation in calibration does not preclude gains in other
reliability metrics; we find that OOD detection can still improve for these
same poorly calibrated models. Furthermore, we identify specific
quantization-aware training (QAT) methods that yield simultaneous gains in
zero-shot accuracy, calibration, and OOD robustness, challenging the view of a
strict efficiency-performance trade-off. These findings offer critical insights
for navigating the multi-objective problem of deploying efficient, reliable,
and robust VLMs by utilizing quantization beyond its conventional role.

</details>


### [68] [CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration](https://arxiv.org/abs/2509.17458)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,Shayan Baghayi Nejad,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: CARINOX框架结合了噪声优化和探索，并采用基于类别感知的奖励选择程序，以提高文本到图像生成模型中的组合对齐能力，在两个基准测试中均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在处理复杂对象关系、属性或空间排列时，在组合对齐方面存在不足。现有的推断时方法（如优化或探索初始噪声）虽然有前景，但单独使用时存在局限性，例如优化可能停滞，探索可能需要过多的样本。此外，单一的奖励指标或临时的组合无法可靠地捕捉组合性的所有方面。

Method: 提出了一种名为CARINOX的统一框架，结合了噪声优化和探索，并采用基于类别感知的奖励选择程序，该程序以与人类判断的相关性为基础。

Result: +16%（T2I-CompBench++）和+11%（HRS）的平均对齐分数，在所有主要类别中持续优于最先进的基于优化和探索的方法，同时保持图像质量和多样性。

Conclusion: CARINOX框架成功地解决了现有文本到图像扩散模型在组合对齐方面的挑战，通过结合优化的噪声和探索，并采用基于类别感知的奖励选择程序，显著提高了生成图像的对齐度，同时保持了图像质量和多样性。

Abstract: Text-to-image diffusion models, such as Stable Diffusion, can produce
high-quality and diverse images but often fail to achieve compositional
alignment, particularly when prompts describe complex object relationships,
attributes, or spatial arrangements. Recent inference-time approaches address
this by optimizing or exploring the initial noise under the guidance of reward
functions that score text-image alignment without requiring model fine-tuning.
While promising, each strategy has intrinsic limitations when used alone:
optimization can stall due to poor initialization or unfavorable search
trajectories, whereas exploration may require a prohibitively large number of
samples to locate a satisfactory output. Our analysis further shows that
neither single reward metrics nor ad-hoc combinations reliably capture all
aspects of compositionality, leading to weak or inconsistent guidance. To
overcome these challenges, we present Category-Aware Reward-based Initial Noise
Optimization and Exploration (CARINOX), a unified framework that combines noise
optimization and exploration with a principled reward selection procedure
grounded in correlation with human judgments. Evaluations on two complementary
benchmarks covering diverse compositional challenges show that CARINOX raises
average alignment scores by +16% on T2I-CompBench++ and +11% on the HRS
benchmark, consistently outperforming state-of-the-art optimization and
exploration-based methods across all major categories, while preserving image
quality and diversity. The project page is available at
https://amirkasaei.com/carinox/{this URL}.

</details>


### [69] [TABLET: A Large-Scale Dataset for Robust Visual Table Understanding](https://arxiv.org/abs/2509.21205)
*Iñigo Alonso,Imanol Miranda,Eneko Agirre,Mirella Lapata*

Main category: cs.CV

TL;DR: 现有视觉表格理解（VTU）基准多为简化合成数据，缺乏真实世界表格的复杂性和多样性。TABLET数据集包含400万个示例，覆盖20项任务，基于200万个真实表格，其中88%保留了原始可视化。该数据集提供图像-HTML表示、元数据和来源信息，有助于训练更鲁棒的VTU模型。


<details>
  <summary>Details</summary>
Motivation: 当前VTU基准主要使用缺乏真实感和多样性的合成表格渲染，且缺乏底层序列化数据，限制了模型在真实世界表格上的表现。现有的VTU数据集示例固定，缺乏对基础数据的访问。

Method: 创建一个包含400万个示例的大规模VTU数据集（TABLET），其中包含200万个真实表格，88%保留了原始可视化。每个示例包含成对的图像-HTML表示、元数据和来源信息。使用TABLET微调Qwen2.5-VL-7B等视觉语言模型。

Result: 在TABLET上微调的模型在已见和未见的VTU任务上表现有所提升，并且在真实世界表格可视化方面具有更强的鲁棒性。

Conclusion: TABLET数据集通过保留原始可视化、提供示例可追溯性并统一大规模数据，为未来VTU模型的鲁棒训练和可扩展评估奠定了基础。

Abstract: While table understanding increasingly relies on pixel-only settings where
tables are processed as visual representations, current benchmarks
predominantly use synthetic renderings that lack the complexity and visual
diversity of real-world tables. Additionally, existing visual table
understanding (VTU) datasets offer fixed examples with single visualizations
and pre-defined instructions, providing no access to underlying serialized data
for reformulation. We introduce TABLET, a large-scale VTU dataset with 4
million examples across 20 tasks, grounded in 2 million unique tables where 88%
preserve original visualizations. Each example includes paired image-HTML
representations, comprehensive metadata, and provenance information linking
back to the source datasets. Fine-tuning vision-language models like
Qwen2.5-VL-7B on TABLET improves performance on seen and unseen VTU tasks while
increasing robustness on real-world table visualizations. By preserving
original visualizations and maintaining example traceability in a unified
large-scale collection, TABLET establishes a foundation for robust training and
extensible evaluation of future VTU models.

</details>


### [70] [Learning Conformal Explainers for Image Classifiers](https://arxiv.org/abs/2509.21209)
*Amr Alkhatib,Stephanie Lowry*

Main category: cs.CV

TL;DR: 本研究提出一种基于共形预测的方法来提高特征归因的可解释性，允许用户控制解释的保真度，并识别出保留模型预测的显著特征子集。


<details>
  <summary>Details</summary>
Motivation: 现有的特征归因方法在鲁棒性和忠实反映模型推理方面存在局限性，并且通常需要访问地面真实解释进行校准。

Method: 提出一种新颖的基于共形预测的方法，该方法识别出足以保留模型预测的显著特征子集，无需访问地面真实解释即可进行校准。提出了四种量化解释与模型预测一致性的共形函数。

Result: 在六个图像数据集上使用五种解释器进行了实证评估，结果表明 FastSHAP 在保真度和信息效率（解释区域的大小）方面优于竞争方法。基于超像素的共形度量比基于像素的度量更有效。

Conclusion: 所提出的基于共形预测的方法可以有效控制特征归因解释的保真度，并且 FastSHAP 在保持模型预测方面表现出色。基于超像素的共形度量在解释图像方面比像素级度量更有效。

Abstract: Feature attribution methods are widely used for explaining image-based
predictions, as they provide feature-level insights that can be intuitively
visualized. However, such explanations often vary in their robustness and may
fail to faithfully reflect the reasoning of the underlying black-box model. To
address these limitations, we propose a novel conformal prediction-based
approach that enables users to directly control the fidelity of the generated
explanations. The method identifies a subset of salient features that is
sufficient to preserve the model's prediction, regardless of the information
carried by the excluded features, and without demanding access to ground-truth
explanations for calibration. Four conformity functions are proposed to
quantify the extent to which explanations conform to the model's predictions.
The approach is empirically evaluated using five explainers across six image
datasets. The empirical results demonstrate that FastSHAP consistently
outperforms the competing methods in terms of both fidelity and informational
efficiency, the latter measured by the size of the explanation regions.
Furthermore, the results reveal that conformity measures based on super-pixels
are more effective than their pixel-wise counterparts.

</details>


### [71] [Sigma: Semantically Informative Pre-training for Skeleton-based Sign Language Understanding](https://arxiv.org/abs/2509.21223)
*Muxin Pu,Mei Kuan Lim,Chun Yong Chong,Chen Change Loy*

Main category: cs.CV

TL;DR: Sigma是一个统一的、基于骨骼的SLU框架，通过融合早期融合、分层对齐学习和统一的预训练框架，解决了现有SLU方法的局限性，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的骨骼基础SLU方法在语义基础、局部细节与全局上下文的平衡以及跨模态学习效率方面存在三个主要限制。

Method: Sigma提出了一个签注感知的早期融合机制，以促进视觉和文本模态之间的深度交互；一个分层对齐学习策略，以共同最大化不同模态的配对特征的不同层次之间的一致性；以及一个统一的预训练框架，结合了对比学习、文本匹配和语言建模。

Result: Sigma在孤立手语识别、连续手语识别和无词手语翻译方面取得了新的最先进成果，跨越了不同的手语和口语基准。

Conclusion: Sigma展示了语义信息预训练的影响，以及骨骼数据作为SLU独立解决方案的有效性。

Abstract: Pre-training has proven effective for learning transferable features in sign
language understanding (SLU) tasks. Recently, skeleton-based methods have
gained increasing attention because they can robustly handle variations in
subjects and backgrounds without being affected by appearance or environmental
factors. Current SLU methods continue to face three key limitations: 1) weak
semantic grounding, as models often capture low-level motion patterns from
skeletal data but struggle to relate them to linguistic meaning; 2) imbalance
between local details and global context, with models either focusing too
narrowly on fine-grained cues or overlooking them for broader context; and 3)
inefficient cross-modal learning, as constructing semantically aligned
representations across modalities remains difficult. To address these, we
propose Sigma, a unified skeleton-based SLU framework featuring: 1) a
sign-aware early fusion mechanism that facilitates deep interaction between
visual and textual modalities, enriching visual features with linguistic
context; 2) a hierarchical alignment learning strategy that jointly maximises
agreements across different levels of paired features from different
modalities, effectively capturing both fine-grained details and high-level
semantic relationships; and 3) a unified pre-training framework that combines
contrastive learning, text matching and language modelling to promote semantic
consistency and generalisation. Sigma achieves new state-of-the-art results on
isolated sign language recognition, continuous sign language recognition, and
gloss-free sign language translation on multiple benchmarks spanning different
sign and spoken languages, demonstrating the impact of semantically informative
pre-training and the effectiveness of skeletal data as a stand-alone solution
for SLU.

</details>


### [72] [Evaluating the Evaluators: Metrics for Compositional Text-to-Image Generation](https://arxiv.org/abs/2509.21227)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 现有文本-图像生成评估指标在成分组合能力方面与人类判断存在不一致，需要谨慎选择。


<details>
  <summary>Details</summary>
Motivation: 文本-图像生成领域在评估生成内容是否准确遵循提示（包括对象、属性和关系）方面面临挑战。现有自动化指标的有效性未经验证，可能影响研究进展的可靠性。

Method: 对常用的成分文本-图像评估指标进行了广泛研究，分析了它们在不同成分组合任务上的表现，并与人类判断进行了比较，超越了简单的相关性分析。

Result: 没有单一指标在所有任务上都表现优异，指标表现随成分问题的类型而变化。基于视觉问答（VQA）的指标并非始终最优，某些基于嵌入的指标在特定情况下表现更好。纯图像指标对评估成分组合能力帮助不大。

Conclusion: 现有文本-图像生成评估指标在成分组合能力方面与人类判断存在不一致，需要谨慎选择评估指标，以确保评估的可靠性，并为生成模型提供更有效的奖励模型。

Abstract: Text-image generation has advanced rapidly, but assessing whether outputs
truly capture the objects, attributes, and relations described in prompts
remains a central challenge. Evaluation in this space relies heavily on
automated metrics, yet these are often adopted by convention or popularity
rather than validated against human judgment. Because evaluation and reported
progress in the field depend directly on these metrics, it is critical to
understand how well they reflect human preferences. To address this, we present
a broad study of widely used metrics for compositional text-image evaluation.
Our analysis goes beyond simple correlation, examining their behavior across
diverse compositional challenges and comparing how different metric families
align with human judgments. The results show that no single metric performs
consistently across tasks: performance varies with the type of compositional
problem. Notably, VQA-based metrics, though popular, are not uniformly
superior, while certain embedding-based metrics prove stronger in specific
cases. Image-only metrics, as expected, contribute little to compositional
evaluation, as they are designed for perceptual quality rather than alignment.
These findings underscore the importance of careful and transparent metric
selection, both for trustworthy evaluation and for their use as reward models
in generation. Project page is available at
\href{https://amirkasaei.com/eval-the-evals/}{this URL}.

</details>


### [73] [SlideMamba: Entropy-Based Adaptive Fusion of GNN and Mamba for Enhanced Representation Learning in Digital Pathology](https://arxiv.org/abs/2509.21239)
*Shakib Khan,Fariba Dambandkhameneh,Nazim Shaikh,Yao Nie,Raghavan Venugopal,Xiao Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Advances in computational pathology increasingly rely on extracting
meaningful representations from Whole Slide Images (WSIs) to support various
clinical and biological tasks. In this study, we propose a generalizable deep
learning framework that integrates the Mamba architecture with Graph Neural
Networks (GNNs) for enhanced WSI analysis. Our method is designed to capture
both local spatial relationships and long-range contextual dependencies,
offering a flexible architecture for digital pathology analysis. Mamba modules
excels in capturing long-range global dependencies, while GNNs emphasize
fine-grained short-range spatial interactions. To effectively combine these
complementary signals, we introduce an adaptive fusion strategy that uses an
entropy-based confidence weighting mechanism. This approach dynamically
balances contributions from both branches by assigning higher weight to the
branch with more confident (lower-entropy) predictions, depending on the
contextual importance of local versus global information for different
downstream tasks. We demonstrate the utility of our approach on a
representative task: predicting gene fusion and mutation status from WSIs. Our
framework, SlideMamba, achieves an area under the precision recall curve
(PRAUC) of 0.751 \pm 0.05, outperforming MIL (0.491 \pm 0.042), Trans-MIL (0.39
\pm 0.017), Mamba-only (0.664 \pm 0.063), GNN-only (0.748 \pm 0.091), and a
prior similar work GAT-Mamba (0.703 \pm 0.075). SlideMamba also achieves
competitive results across ROC AUC (0.738 \pm 0.055), sensitivity (0.662 \pm
0.083), and specificity (0.725 \pm 0.094). These results highlight the strength
of the integrated architecture, enhanced by the proposed entropy-based adaptive
fusion strategy, and suggest promising potential for application of
spatially-resolved predictive modeling tasks in computational pathology.

</details>


### [74] [Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets](https://arxiv.org/abs/2509.21245)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jingwei Huang,Junlin Yu,Kunhong Li,Linus,Penghao Wang,Qingxiang Lin,Sicong Liu,Xianghui Yang,Yixuan Tang,Yunfei Zhao,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: Hunyuan3D-Omni是一个统一的3D资产生成框架，它接受多种模态的条件输入（图像、点云、体素、边界框、骨骼姿态），并提供精细化、跨模态的控制能力。该框架通过单一同质化跨模态架构实现，并采用渐进式、难度感知采样策略进行训练，以增强多模态融合和处理缺失输入的能力。实验表明，这些额外的控制显著提高了生成精度、实现了几何感知变换，并增强了在生产工作流中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D原生生成模型主要依赖图像或文本条件，缺乏精细、跨模态的控制，限制了其可控性和实际应用。

Method: 提出Hunyuan3D-Omni框架，统一处理多种条件信号（图像、点云、体素、边界框、骨骼姿态），采用单一跨模态架构。使用渐进式、难度感知采样策略训练，偏向于更难的信号，以实现鲁棒的多模态融合和处理缺失输入。

Result: 额外的控制提高了生成精度，实现了几何感知变换，并增强了生产工作流的鲁棒性。

Conclusion: Hunyuan3D-Omni通过引入多模态条件和统一的跨模态架构，实现了对3D资产生成更精细、更灵活的控制，克服了现有方法的局限性，提高了生成质量和在实际应用中的鲁棒性。

Abstract: Recent advances in 3D-native generative models have accelerated asset
creation for games, film, and design. However, most methods still rely
primarily on image or text conditioning and lack fine-grained, cross-modal
controls, which limits controllability and practical adoption. To address this
gap, we present Hunyuan3D-Omni, a unified framework for fine-grained,
controllable 3D asset generation built on Hunyuan3D 2.1. In addition to images,
Hunyuan3D-Omni accepts point clouds, voxels, bounding boxes, and skeletal pose
priors as conditioning signals, enabling precise control over geometry,
topology, and pose. Instead of separate heads for each modality, our model
unifies all signals in a single cross-modal architecture. We train with a
progressive, difficulty-aware sampling strategy that selects one control
modality per example and biases sampling toward harder signals (e.g., skeletal
pose) while downweighting easier ones (e.g., point clouds), encouraging robust
multi-modal fusion and graceful handling of missing inputs. Experiments show
that these additional controls improve generation accuracy, enable
geometry-aware transformations, and increase robustness for production
workflows.

</details>


### [75] [Learning to Look: Cognitive Attention Alignment with Vision-Language Models](https://arxiv.org/abs/2509.21247)
*Ryan L. Yang,Dipkamal Bhusal,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 通过使用视觉-语言模型和自然语言提示自动生成语义注意力图，并引入辅助损失来使CNN注意与语言引导图保持一致，从而使模型决策更可靠、更符合认知。无需手动标注，在ColoredMNIST和DecoyMNIST数据集上均表现出改进的泛化能力和减少的捷径依赖性。


<details>
  <summary>Details</summary>
Motivation: CNNs 常常通过利用表面相关性来“作弊”，这引发了对其做出预测的正确原因的担忧。受认知科学启发，近期方法试图使用基于概念的监督和解释正则化来引导模型注意力，但这些技术依赖于劳动密集型、专家提供的注释，限制了它们的可扩展性。

Method: 提出一个可扩展的框架，利用视觉-语言模型来自动生成语义注意力图。通过引入一个辅助损失函数，将CNN的注意力与这些由语言引导的图对齐。

Result: 在ColoredMNIST数据集上实现了最先进的性能，并在DecoyMNIST数据集上与需要大量注释的方法具有竞争力。证明了改进的泛化能力、减少的捷径依赖性以及更符合人类直觉的模型注意力。

Conclusion: 所提出的方法能够无需手动标注即可实现更可靠、更符合认知的模型决策。

Abstract: Convolutional Neural Networks (CNNs) frequently "cheat" by exploiting
superficial correlations, raising concerns about whether they make predictions
for the right reasons. Inspired by cognitive science, which highlights the role
of attention in robust human perception, recent methods have sought to guide
model attention using concept-based supervision and explanation regularization.
However, these techniques depend on labor-intensive, expert-provided
annotations, limiting their scalability. We propose a scalable framework that
leverages vision-language models to automatically generate semantic attention
maps using natural language prompts. By introducing an auxiliary loss that
aligns CNN attention with these language-guided maps, our approach promotes
more reliable and cognitively plausible decision-making without manual
annotation. Experiments on challenging datasets, ColoredMNIST and DecoyMNIST,
show that our method achieves state-of-the-art performance on ColorMNIST and
remains competitive with annotation-heavy baselines on DecoyMNIST,
demonstrating improved generalization, reduced shortcut reliance, and model
attention that better reflects human intuition.

</details>


### [76] [Decipher-MR: A Vision-Language Foundation Model for 3D MRI Representations](https://arxiv.org/abs/2509.21249)
*Zhijian Yang,Noel DSouza,Istvan Megyeri,Xiaojian Xu,Amin Honarmandi Shandiz,Farzin Haddadpour,Krisztian Koos,Laszlo Rusko,Emanuele Valeriano,Bharadwaj Swaninathan,Lei Wu,Parminder Bhatia,Taha Kass-Hout,Erhan Bas*

Main category: cs.CV

TL;DR: Decipher-MR是一个针对3D MRI的视觉-语言基础模型，利用大规模数据集和创新的训练方法，在多种下游任务中展现出优越的性能，为MRI的AI应用提供了可扩展的基础。


<details>
  <summary>Details</summary>
Motivation: MRI数据的复杂性和异质性给自动化分析和机器学习应用带来了挑战，特别是由于数据稀疏性和狭窄的解剖学焦点，限制了基础模型在MRI领域的应用。

Method: Decipher-MR是一个3D MRI特定的视觉-语言基础模型，在一个包含200,000个MRI系列（来自超过22,000项研究）的大规模数据集上进行训练。该模型集成了自监督视觉学习和报告引导的文本监督，并采用模块化设计，允许在冻结的预训练编码器上附加轻量级的、任务特定的解码器进行调整。

Result: 在疾病分类、人口统计学预测、解剖学定位和跨模态检索等多种基准测试中，Decipher-MR展现出比现有基础模型和特定任务方法一致的性能提升。

Conclusion: Decipher-MR是一个可扩展且通用的MRI基础模型，能够促进临床和研究领域中AI应用的有效开发。

Abstract: Magnetic Resonance Imaging (MRI) is a critical medical imaging modality in
clinical diagnosis and research, yet its complexity and heterogeneity pose
challenges for automated analysis, particularly in scalable and generalizable
machine learning applications. While foundation models have revolutionized
natural language and vision tasks, their application to MRI remains limited due
to data scarcity and narrow anatomical focus. In this work, we present
Decipher-MR, a 3D MRI-specific vision-language foundation model trained on a
large-scale dataset comprising 200,000 MRI series from over 22,000 studies
spanning diverse anatomical regions, sequences, and pathologies. Decipher-MR
integrates self-supervised vision learning with report-guided text supervision
to build robust, generalizable representations, enabling effective adaptation
across broad applications. To enable robust and diverse clinical tasks with
minimal computational overhead, Decipher-MR supports a modular design that
enables tuning of lightweight, task-specific decoders attached to a frozen
pretrained encoder. Following this setting, we evaluate Decipher-MR across
diverse benchmarks including disease classification, demographic prediction,
anatomical localization, and cross-modal retrieval, demonstrating consistent
performance gains over existing foundation models and task-specific approaches.
Our results establish Decipher-MR as a scalable and versatile foundation for
MRI-based AI, facilitating efficient development across clinical and research
domains.

</details>


### [77] [Instruction-tuned Self-Questioning Framework for Multimodal Reasoning](https://arxiv.org/abs/2509.21251)
*You-Won Jang,Yu-Jung Heo,Jaeseok Kim,Minsu Lee,Du-Seong Chang,Byoung-Tak Zhang*

Main category: cs.CV

TL;DR: SQ-InstructBLIP通过生成图像感知的子问题和子答案来提高推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理需要多步推理的视觉-语言任务时存在不足，特别是无法获取细粒度的视觉内容且内部机制难以复现。

Method: 提出SQ-InstructBLIP模型，包含Questioner、Answerer和Reasoner三个组件，通过迭代生成子问题和子答案来辅助推理，并将子问题作为额外信息输入VQA任务。

Result: SQ-InstructBLIP在VQA任务上取得了比先前方法更准确的推理结果。

Conclusion: SQ-InstructBLIP通过生成图像感知的子问题和子答案，有效提升了视觉-语言理解任务的多步推理能力。

Abstract: The field of vision-language understanding has been actively researched in
recent years, thanks to the development of Large Language Models~(LLMs).
However, it still needs help with problems requiring multi-step reasoning, even
for very simple questions. Recent studies adopt LLMs to tackle this problem by
iteratively generating sub-questions and answers. However, there are
disadvantages such as 1) the fine-grained visual contents of images are not
available using LLMs that cannot read visual information, 2) internal
mechanisms are inaccessible and difficult to reproduce by using black-box LLMs.
To solve these problems, we propose the SQ (Self-Questioning)-InstructBLIP,
which improves inference performance by generating image-aware informative
sub-questions and sub-answers iteratively. The SQ-InstructBLIP, which consists
of a Questioner, Answerer, and Reasoner that share the same architecture.
Questioner and Answerer generate sub-questions and sub-answers to help infer
the main-question, and Reasoner performs reasoning on the main-question
considering the generated sub-question information. Our experiments show that
the proposed method SQ-InstructBLIP, which uses the generated sub-questions as
additional information when solving the VQA task, performs more accurate
reasoning than the previous works.

</details>


### [78] [Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation](https://arxiv.org/abs/2509.21257)
*Seyed Amir Kasaei,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: T2I模型存在幻觉问题，表现为模型基于先验知识或偏见生成内容，而非仅依赖输入。本文提出了一个包含属性、关系和对象幻觉的分类法，以评估T2I模型并揭示隐藏偏见。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型评估主要关注提示的对齐性，忽视了模型超出提示之外的生成内容。因此，需要为T2I模型引入幻觉的定义和评估框架。

Method: 提出将T2I中的幻觉定义为由偏见驱动的偏差，并构建了一个包含属性、关系和对象幻觉的分类体系。

Result: 该分类法为T2I模型的评估设定了上限，并揭示了模型潜在的偏见，为更深入的评估奠定了基础。

Conclusion: 本文提出的幻觉定义和分类法有助于更全面地评估T2I模型的性能，并识别和解决其中存在的偏见问题。

Abstract: In language and vision-language models, hallucination is broadly understood
as content generated from a model's prior knowledge or biases rather than from
the given input. While this phenomenon has been studied in those domains, it
has not been clearly framed for text-to-image (T2I) generative models. Existing
evaluations mainly focus on alignment, checking whether prompt-specified
elements appear, but overlook what the model generates beyond the prompt. We
argue for defining hallucination in T2I as bias-driven deviations and propose a
taxonomy with three categories: attribute, relation, and object hallucinations.
This framing introduces an upper bound for evaluation and surfaces hidden
biases, providing a foundation for richer assessment of T2I models.

</details>


### [79] [Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2509.21261)
*Feng-Qi Cui,Jinyang Huang,Anyang Tong,Ziyu Jia,Jie Zhang,Zhi Liu,Dan Guo,Jianwei Lu,Meng Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“Person Independence Universal Micro-action Recognition Framework”的框架，通过结合分布鲁棒优化（Distributionally Robust Optimization）原理，学习与个体无关的表征，以解决现有微动作识别方法在处理个体差异时泛化能力不足的问题。该框架包含特征层面的“时频对齐模块”（Temporal-Frequency Alignment Module）和损失层面的“群不变正则化损失”（Group-Invariant Regularized Loss）。时频对齐模块通过双分支设计（时间分支和频率分支）来处理个体运动特征的差异，而群不变正则化损失则通过划分伪组和调整样本权重来增强模型在不同个体分布下的泛化能力。实验结果表明，该框架在MA-52数据集上取得了优于现有方法的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有微动作识别方法在真实场景中表现不佳，主要是因为个体差异导致相同动作表现不同，限制了模型的泛化能力。

Method: 提出“Person Independence Universal Micro-action Recognition Framework”，包含两个模块：1. 特征层面：时频对齐模块（Temporal-Frequency Alignment Module），通过时间分支（Wasserstein-regularized alignment）和频率分支（variance-guided perturbations）进行个体特征归一化，并用一致性驱动融合机制集成。2. 损失层面：群不变正则化损失（Group-Invariant Regularized Loss），通过划分伪组、加权边界样本和正则化子群方差来模拟未见过的个体分布，增强模型对困难样本的泛化能力。

Result: 在大型MA-52数据集上的实验表明，所提出的框架在准确性和鲁棒性方面均优于现有方法，并在细粒度条件下实现了稳定的泛化。

Conclusion: 该框架能够有效解决个体差异带来的微动作识别泛化问题，提高了识别的准确性和鲁棒性。

Abstract: Micro-action Recognition is vital for psychological assessment and
human-computer interaction. However, existing methods often fail in real-world
scenarios because inter-person variability causes the same action to manifest
differently, hindering robust generalization. To address this, we propose the
Person Independence Universal Micro-action Recognition Framework, which
integrates Distributionally Robust Optimization principles to learn
person-agnostic representations. Our framework contains two plug-and-play
components operating at the feature and loss levels. At the feature level, the
Temporal-Frequency Alignment Module normalizes person-specific motion
characteristics with a dual-branch design: the temporal branch applies
Wasserstein-regularized alignment to stabilize dynamic trajectories, while the
frequency branch introduces variance-guided perturbations to enhance robustness
against person-specific spectral differences. A consistency-driven fusion
mechanism integrates both branches. At the loss level, the Group-Invariant
Regularized Loss partitions samples into pseudo-groups to simulate unseen
person-specific distributions. By up-weighting boundary cases and regularizing
subgroup variance, it forces the model to generalize beyond easy or frequent
samples, thus enhancing robustness to difficult variations. Experiments on the
large-scale MA-52 dataset demonstrate that our framework outperforms existing
methods in both accuracy and robustness, achieving stable generalization under
fine-grained conditions.

</details>


### [80] [Dense Semantic Matching with VGGT Prior](https://arxiv.org/abs/2509.21263)
*Songlin Yang,Tianyi Wei,Yushi Lan,Zeqi Xiao,Anyi Rao,Xingang Pan*

Main category: cs.CV

TL;DR: 现有的语义匹配方法在处理对称结构时存在几何歧义，并且在像素匹配时忽略了跨图像的不可见性和流形保持。本文提出一种利用VGGT模型，并通过迁移学习、循环一致性训练、合成数据增强和渐进式训练策略来解决这些问题的方法，在几何感知、匹配可靠性和流形保持方面取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语义匹配方法在几何歧义和最近邻规则方面存在局限性，需要几何感知像素描述符和整体密集对应机制。

Method: 通过复用早期特征层、微调后期特征层、添加语义头来实现 VGGT 的迁移学习；采用循环一致性训练策略、合成数据增强和渐进式训练策略来适应数据稀疏的语义匹配场景。

Result: 该方法具有优越的几何感知能力、匹配可靠性和流形保持能力，实验结果优于现有方法。

Conclusion: 所提出的方法能够有效克服现有语义匹配方法的局限性，并在数据稀疏的情况下实现高性能的像素级对应。

Abstract: Semantic matching aims to establish pixel-level correspondences between
instances of the same category and represents a fundamental task in computer
vision. Existing approaches suffer from two limitations: (i) Geometric
Ambiguity: Their reliance on 2D foundation model features (e.g., Stable
Diffusion, DINO) often fails to disambiguate symmetric structures, requiring
extra fine-tuning yet lacking generalization; (ii) Nearest-Neighbor Rule: Their
pixel-wise matching ignores cross-image invisibility and neglects manifold
preservation. These challenges call for geometry-aware pixel descriptors and
holistic dense correspondence mechanisms. Inspired by recent advances in 3D
geometric foundation models, we turn to VGGT, which provides geometry-grounded
features and holistic dense matching capabilities well aligned with these
needs. However, directly transferring VGGT is challenging, as it was originally
designed for geometry matching within cross views of a single instance,
misaligned with cross-instance semantic matching, and further hindered by the
scarcity of dense semantic annotations. To address this, we propose an approach
that (i) retains VGGT's intrinsic strengths by reusing early feature stages,
fine-tuning later ones, and adding a semantic head for bidirectional
correspondences; and (ii) adapts VGGT to the semantic matching scenario under
data scarcity through cycle-consistent training strategy, synthetic data
augmentation, and progressive training recipe with aliasing artifact
mitigation. Extensive experiments demonstrate that our approach achieves
superior geometry awareness, matching reliability, and manifold preservation,
outperforming previous baselines.

</details>


### [81] [MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation](https://arxiv.org/abs/2509.21265)
*Xinyu Liu,Guolei Sun,Cheng Wang,Yixuan Yuan,Ender Konukoglu*

Main category: cs.CV

TL;DR: MedVSR是一个专门为医学视频超分辨率设计的框架，通过CSSP和ISSR模块解决了低分辨率医学视频的挑战，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 高分辨率医学视频对于准确诊断至关重要，但由于硬件和生理限制难以获得。现有的视频超分辨率（VSR）模型在处理医学视频时存在相机抖动、噪声、帧过渡不精确、光学流误差大以及易产生伪影和失真特征等问题。

Method: MedVSR框架：1. 采用跨状态空间传播（CSSP）来解决不精确的对齐问题，通过将远程帧投影为状态空间模型中的控制矩阵，实现对一致和信息特征的选择性传播到相邻帧以进行有效对齐。2. 设计了内部状态空间重构（ISSR）模块，通过联合长程空间特征学习和大核短程信息聚合来增强组织结构并减少伪影。

Result: 在内窥镜和白内障手术等多种医学场景的四个数据集上进行实验，MedVSR在重建性能和效率方面显著优于现有的VSR模型。

Conclusion: MedVSR能够有效解决医学视频超分辨率中的挑战，并在各种医学场景下展现出优越的性能和效率。

Abstract: High-resolution (HR) medical videos are vital for accurate diagnosis, yet are
hard to acquire due to hardware limitations and physiological constraints.
Clinically, the collected low-resolution (LR) medical videos present unique
challenges for video super-resolution (VSR) models, including camera shake,
noise, and abrupt frame transitions, which result in significant optical flow
errors and alignment difficulties. Additionally, tissues and organs exhibit
continuous and nuanced structures, but current VSR models are prone to
introducing artifacts and distorted features that can mislead doctors. To this
end, we propose MedVSR, a tailored framework for medical VSR. It first employs
Cross State-Space Propagation (CSSP) to address the imprecise alignment by
projecting distant frames as control matrices within state-space models,
enabling the selective propagation of consistent and informative features to
neighboring frames for effective alignment. Moreover, we design an Inner
State-Space Reconstruction (ISSR) module that enhances tissue structures and
reduces artifacts with joint long-range spatial feature learning and
large-kernel short-range information aggregation. Experiments across four
datasets in diverse medical scenarios, including endoscopy and cataract
surgeries, show that MedVSR significantly outperforms existing VSR models in
reconstruction performance and efficiency. Code released at
https://github.com/CUHK-AIM-Group/MedVSR.

</details>


### [82] [MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources](https://arxiv.org/abs/2509.21268)
*Sicong Leng,Jing Wang,Jiaxi Li,Hao Zhang,Zhiqiang Hu,Boqiang Zhang,Yuming Jiang,Hang Zhang,Xin Li,Lidong Bing,Deli Zhao,Wei Lu,Yu Rong,Aixin Sun,Shijian Lu*

Main category: cs.CV

TL;DR: 本研究提出了方差感知采样（VAS）方法，以解决大型多模态推理模型在长链式思考（CoT）数据和强化学习（RL）稳定性方面的局限性。同时发布了大规模CoT数据和RL QA对，并开源了多模态推理模型，旨在推动该领域的发展。


<details>
  <summary>Details</summary>
Motivation: 大型多模态推理模型在发展中面临两大挑战：缺乏大规模、高质量的长链式思考（CoT）数据，以及强化学习（RL）在训练后阶段的不稳定性。GRPO等RL框架在低奖励方差时容易出现梯度消失问题，阻碍优化和收敛。

Method: 提出方差感知采样（VAS）策略，通过奖励方差和轨迹多样性来提升奖励方差，稳定策略优化。发布了约160万条长CoT冷启动数据和约1.5万条RL QA对，以及端到端的训练代码库。开源了多模态推理模型家族。

Result: 在数学推理基准测试中，提出的VAS方法和数据集被证明是有效的。消融研究和分析深入揭示了各组成部分的贡献。理论上证明了奖励方差是策略梯度的期望幅度的下界，而VAS是实现该保证的实用机制。

Conclusion: 本研究通过提出VAS方法和发布高质量数据集与模型，有效解决了大型多模态推理模型在数据和RL稳定性方面的挑战，为社区提供了标准化基线和可复现的训练资源，并从理论上阐释了奖励方差的重要性。

Abstract: Large multimodal reasoning models have achieved rapid progress, but their
advancement is constrained by two major limitations: the absence of open,
large-scale, high-quality long chain-of-thought (CoT) data, and the instability
of reinforcement learning (RL) algorithms in post-training. Group Relative
Policy Optimization (GRPO), the standard framework for RL fine-tuning, is prone
to gradient vanishing when reward variance is low, which weakens optimization
signals and impairs convergence. This work makes three contributions: (1) We
propose Variance-Aware Sampling (VAS), a data selection strategy guided by
Variance Promotion Score (VPS) that combines outcome variance and trajectory
diversity to promote reward variance and stabilize policy optimization. (2) We
release large-scale, carefully curated resources containing ~1.6M long CoT
cold-start data and ~15k RL QA pairs, designed to ensure quality, difficulty,
and diversity, along with a fully reproducible end-to-end training codebase.
(3) We open-source a family of multimodal reasoning models in multiple scales,
establishing standardized baselines for the community. Experiments across
mathematical reasoning benchmarks demonstrate the effectiveness of both the
curated data and the proposed VAS. Comprehensive ablation studies and analyses
provide further insight into the contributions of each component. In addition,
we theoretically establish that reward variance lower-bounds the expected
policy gradient magnitude, with VAS serving as a practical mechanism to realize
this guarantee. Our code, data, and checkpoints are available at
https://github.com/LengSicong/MMR1.

</details>


### [83] [A Sentinel-3 foundation model for ocean colour](https://arxiv.org/abs/2509.21273)
*Geoffrey Dawson,Remy Vandaele,Andrew Taylor,David Moffat,Helen Tamura-Wicks,Sarah Jackson,Rosie Lickorish,Paolo Fraccaro,Hywel Williams,Chunbo Luo,Anne Jones*

Main category: cs.CV

TL;DR: AI基础模型可以通过自我训练来改进海洋监测，特别是在数据稀疏的情况下，并能提供对海洋生态系统和气候过程的更深入的见解。


<details>
  <summary>Details</summary>
Motivation: 海洋科学中的标记数据稀疏且昂贵，AI基础模型（FMs）可以克服这一挑战，并改变AI在海洋科学中的应用。

Method: 使用基于Prithvi-EO Vision Transformer架构的新型基础模型，该模型经过预训练以重建Sentinel-3 OLCI数据，并针对两个下游海洋地球观测任务进行了微调：量化叶绿素浓度和改进海洋初级生产估算。

Result: 在叶绿素浓度量化和海洋初级生产估算任务上，该模型均表现出优于现有基线模型的性能，能够利用少量高质量标记数据，并捕捉到海洋色彩的详细空间格局，同时匹配点观测数据。

Conclusion: 自我训练的基础模型在海洋监测中具有重要应用价值，能够提供对海洋生态系统及其在全球气候过程中的作用更强大、数据驱动的见解。

Abstract: Artificial Intelligence (AI) Foundation models (FMs), pre-trained on massive
unlabelled datasets, have the potential to drastically change AI applications
in ocean science, where labelled data are often sparse and expensive to
collect. In this work, we describe a new foundation model using the Prithvi-EO
Vision Transformer architecture which has been pre-trained to reconstruct data
from the Sentinel-3 Ocean and Land Colour Instrument (OLCI). We evaluate the
model by fine-tuning on two downstream marine earth observation tasks. We first
assess model performance compared to current baseline models used to quantify
chlorophyll concentration. We then evaluate the FMs ability to refine remote
sensing-based estimates of ocean primary production. Our results demonstrate
the utility of self-trained FMs for marine monitoring, in particular for making
use of small amounts of high quality labelled data and in capturing detailed
spatial patterns of ocean colour whilst matching point observations. We
conclude that this new generation of geospatial AI models has the potential to
provide more robust, data-driven insights into ocean ecosystems and their role
in global climate processes.

</details>


### [84] [Does FLUX Already Know How to Perform Physically Plausible Image Composition?](https://arxiv.org/abs/2509.21278)
*Shilin Lu,Zhuming Lian,Zihan Zhou,Shaocong Zhang,Chen Zhao,Adams Wai-Kin Kong*

Main category: cs.CV

TL;DR: SHINE是一个用于图像合成的无训练框架，可以无缝、高保真地将用户指定的对象插入新场景，并能处理复杂的光照和高分辨率输入。


<details>
  <summary>Details</summary>
Motivation: 现有图像合成模型在处理复杂光照（如阴影、反射）和高分辨率图像时存在困难。尽管文本到图像扩散模型（如SD3.5，FLUX）具备物理和分辨率先验知识，但缺乏有效框架来利用这些知识，避免潜在的固定姿势或不稳定的注意力手术问题。

Method: SHINE框架提出了一种无训练方法，包括：1. 流形引导锚定损失：利用预训练的自定义适配器（如IP-Adapter）引导潜在表示，以忠实再现主体并保持背景的完整性。2. 降级抑制引导和自适应背景混合：消除低质量输出和可见接缝。3. 引入ComplexCompo基准：包含多样化的分辨率和挑战性条件（如低光、强光、复杂阴影、反射表面）。

Result: 在ComplexCompo和DreamEditBench基准上，SHINE在标准指标（如DINOv2）和人类评估指标（如DreamSim、ImageReward、VisionReward）上均取得了最先进的性能。

Conclusion: SHINE通过创新的方法解决了图像合成中的复杂光照和高分辨率输入问题，并在多个基准测试中表现出色，证明了其有效性。

Abstract: Image composition aims to seamlessly insert a user-specified object into a
new scene, but existing models struggle with complex lighting (e.g., accurate
shadows, water reflections) and diverse, high-resolution inputs. Modern
text-to-image diffusion models (e.g., SD3.5, FLUX) already encode essential
physical and resolution priors, yet lack a framework to unleash them without
resorting to latent inversion, which often locks object poses into contextually
inappropriate orientations, or brittle attention surgery. We propose SHINE, a
training-free framework for Seamless, High-fidelity Insertion with Neutralized
Errors. SHINE introduces manifold-steered anchor loss, leveraging pretrained
customization adapters (e.g., IP-Adapter) to guide latents for faithful subject
representation while preserving background integrity. Degradation-suppression
guidance and adaptive background blending are proposed to further eliminate
low-quality outputs and visible seams. To address the lack of rigorous
benchmarks, we introduce ComplexCompo, featuring diverse resolutions and
challenging conditions such as low lighting, strong illumination, intricate
shadows, and reflective surfaces. Experiments on ComplexCompo and
DreamEditBench show state-of-the-art performance on standard metrics (e.g.,
DINOv2) and human-aligned scores (e.g., DreamSim, ImageReward, VisionReward).
Code and benchmark will be publicly available upon publication.

</details>


### [85] [Quantized Visual Geometry Grounded Transformer](https://arxiv.org/abs/2509.21302)
*Weilun Feng,Haotong Qin,Mingqiang Wu,Chuanguang Yang,Yuqi Li,Xiangqi Li,Zhulin An,Libo Huang,Yulun Zhang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出了QuantVGGT，一种用于视觉几何基础Transformer（VGGT）的首个量化框架，通过双平滑细粒度量化和噪声过滤多样化采样来解决PTQ在VGGT量化中的挑战，实现了显著的内存和速度提升，同时保持了高重建精度，适用于资源受限场景。


<details>
  <summary>Details</summary>
Motivation: 视觉几何基础Transformer（VGGT）在3D重建领域取得了显著进展，但其高昂的计算和内存成本阻碍了实际应用。现有的模型压缩技术（如训练后量化PTQ）在处理大规模VGGT时面临数据无关的特殊标记导致的重尾激活分布和多视角3D数据导致的不稳定校准样本选择等独特挑战。

Method: QuantVGGT框架主要包含两项技术贡献：1. 双平滑细粒度量化（Dual-Smoothed Fine-Grained Quantization），结合预全局Hadamard旋转和后局部通道平滑，以鲁棒地缓解重尾分布和通道间方差。2. 噪声过滤多样化采样（Noise-Filtered Diverse Sampling），通过深层统计过滤异常值，并构建感知帧的多样化校准簇，以确保量化范围的稳定性。

Result: 实验证明，QuantVGGT在不同基准和比特宽度下均取得了最先进的成果，其性能显著优于现有的通用量化方法。具体的4位QuantVGGT模型实现了3.7倍的内存缩减和2.5倍的硬件推理加速，同时重建精度仍保持全精度模型的98%以上。

Conclusion: QuantVGGT成功解决了大规模VGGT模型量化中的关键挑战，实现了显著的压缩和加速效果，同时保持了高精度，证明了其在资源受限场景下的巨大优势和实用性。

Abstract: Learning-based 3D reconstruction models, represented by Visual Geometry
Grounded Transformers (VGGTs), have made remarkable progress with the use of
large-scale transformers. Their prohibitive computational and memory costs
severely hinder real-world deployment. Post-Training Quantization (PTQ) has
become a common practice for compressing and accelerating models. However, we
empirically observe that PTQ faces unique obstacles when compressing
billion-scale VGGTs: the data-independent special tokens induce heavy-tailed
activation distributions, while the multi-view nature of 3D data makes
calibration sample selection highly unstable. This paper proposes the first
Quantization framework for VGGTs, namely QuantVGGT. This mainly relies on two
technical contributions: First, we introduce Dual-Smoothed Fine-Grained
Quantization, which integrates pre-global Hadamard rotation and post-local
channel smoothing to mitigate heavy-tailed distributions and inter-channel
variance robustly. Second, we design Noise-Filtered Diverse Sampling, which
filters outliers via deep-layer statistics and constructs frame-aware diverse
calibration clusters to ensure stable quantization ranges. Comprehensive
experiments demonstrate that QuantVGGT achieves the state-of-the-art results
across different benchmarks and bit-width, surpassing the previous
state-of-the-art generic quantization method with a great margin. We highlight
that our 4-bit QuantVGGT can deliver a 3.7$\times$ memory reduction and
2.5$\times$ acceleration in real-hardware inference, while maintaining
reconstruction accuracy above 98\% of its full-precision counterpart. This
demonstrates the vast advantages and practicality of QuantVGGT in
resource-constrained scenarios. Our code is released in
https://github.com/wlfeng0509/QuantVGGT.

</details>


### [86] [NewtonGen: Physics-Consistent and Controllable Text-to-Video Generation via Neural Newtonian Dynamics](https://arxiv.org/abs/2509.21309)
*Yu Yuan,Xijun Wang,Tharindu Wickremasinghe,Zeeshan Nadir,Bole Ma,Stanley H. Chan*

Main category: cs.CV

TL;DR: NewtonGen是一个整合了数据驱动合成和可学习物理原理的框架，通过可训练的神经牛顿动力学（NND）来模拟和预测牛顿运动，从而实现物理上一致且可控的文本到视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型在物理一致性和可控性方面存在瓶颈，容易产生不切实际的运动，并且缺乏对不同初始条件下的精确参数控制，这主要是因为模型仅从外观学习运动分布，而缺乏对底层动力学的理解。

Method: 提出了一种名为NewtonGen的框架，其核心是可训练的神经牛顿动力学（NND），能够模拟和预测各种牛顿运动，将潜在的动力学约束注入视频生成过程。通过联合利用数据先验和动力学指导，NewtonGen实现了具有精确参数控制的物理一致性视频合成。

Result: NewtonGen能够生成物理上一致且可控的视频，解决了现有模型在运动真实性和参数控制方面的不足。

Conclusion: 通过整合数据驱动合成与可学习的物理原理，特别是神经牛顿动力学，NewtonGen能够实现物理上一致且可控的文本到视频生成。

Abstract: A primary bottleneck in large-scale text-to-video generation today is
physical consistency and controllability. Despite recent advances,
state-of-the-art models often produce unrealistic motions, such as objects
falling upward, or abrupt changes in velocity and direction. Moreover, these
models lack precise parameter control, struggling to generate physically
consistent dynamics under different initial conditions. We argue that this
fundamental limitation stems from current models learning motion distributions
solely from appearance, while lacking an understanding of the underlying
dynamics. In this work, we propose NewtonGen, a framework that integrates
data-driven synthesis with learnable physical principles. At its core lies
trainable Neural Newtonian Dynamics (NND), which can model and predict a
variety of Newtonian motions, thereby injecting latent dynamical constraints
into the video generation process. By jointly leveraging data priors and
dynamical guidance, NewtonGen enables physically consistent video synthesis
with precise parameter control.

</details>


### [87] [SD3.5-Flash: Distribution-Guided Distillation of Generative Flows](https://arxiv.org/abs/2509.21318)
*Hmrishav Bandyopadhyay,Rahim Entezari,Jim Scott,Reshinth Adithyan,Yi-Zhe Song,Varun Jampani*

Main category: cs.CV

TL;DR: SD3.5-Flash是一个高效的少样本蒸馏框架，能够将高质量图像生成带到消费级设备。


<details>
  <summary>Details</summary>
Motivation: 使计算成本高昂的生成模型能在消费级设备上运行。

Method: 通过重新制定的分布匹配目标，对计算成本高昂的流模型进行蒸馏，并采用时间步共享和拆分时间步微调技术。结合文本编码器重组、专用量化等优化。

Result: SD3.5-Flash在生成速度和内存效率方面表现优异，能够跨不同硬件配置部署，并在用户研究中显示出优于现有少样本方法的性能。

Conclusion: SD3.5-Flash能够实现快速生成和内存高效部署，使先进的生成式AI能够真正投入实际应用。

Abstract: We present SD3.5-Flash, an efficient few-step distillation framework that
brings high-quality image generation to accessible consumer devices. Our
approach distills computationally prohibitive rectified flow models through a
reformulated distribution matching objective tailored specifically for few-step
generation. We introduce two key innovations: "timestep sharing" to reduce
gradient noise and "split-timestep fine-tuning" to improve prompt alignment.
Combined with comprehensive pipeline optimizations like text encoder
restructuring and specialized quantization, our system enables both rapid
generation and memory-efficient deployment across different hardware
configurations. This democratizes access across the full spectrum of devices,
from mobile phones to desktop computers. Through extensive evaluation including
large-scale user studies, we demonstrate that SD3.5-Flash consistently
outperforms existing few-step methods, making advanced generative AI truly
accessible for practical deployment.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [88] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 提出一个框架，通过修改外交事件叙述来积极引导公众情绪，成功率达70%。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以有效、及时地分析公众情绪，而公众情绪对外交政策的实施、国际问题的解决和国家形象的塑造至关重要。

Method: 构建了一个包含外交事件描述及其相关公众讨论的数据集，并训练语言模型来预测公众反应。在此基础上，结合传播理论和专家知识，确定了若干文本修改特征，并开发了一种利用大语言模型生成反事实文本的算法，以系统性地修改原始文本，在保持事实核心的前提下改变叙述框架。

Result: 该框架成功地将公众情绪从负面转向中性或正面，实验结果显示成功率为70%。

Conclusion: 该框架能够作为一种实用的工具，为外交官、政策制定者和传播专家提供数据驱动的见解，以更优地构建外交倡议或报道相关事件，从而营造更理想的公众情绪。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [89] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 提出一个语音情感识别的跨语言框架，通过聚类和图模型对说话人风格和语音进行对齐，以提升跨语言情感识别的性能。


<details>
  <summary>Details</summary>
Motivation: 跨语言语音情感识别（SER）因语音变异和说话人风格差异而充满挑战，需要一个能跨语言对齐情感表达的框架。

Method: 提出一个说话人风格感知的语音单元（音素）锚定框架，通过基于图的聚类构建特定情感的说话人群体，并利用双空间锚定（说话人空间和语音单元空间）来实现跨语言情感迁移。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（闽南语）数据集上评估，所提出的方法相比于现有基线模型在泛化能力上有所提升，并揭示了跨语言情感表征的共性。

Conclusion: 所提出的说话人风格感知的音素锚定框架能够有效提升跨语言语音情感识别的性能，并且能够揭示跨语言情感表征的共性。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [90] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: LLMs在计算流体动力学（CFD）领域的应用潜力尚未被充分挖掘。本文提出了CFDLLMBench基准测试套件，用于评估LLM在CFD知识、数值推理和工作流实现方面的能力，以推动LLM在复杂物理系统数值实验自动化方面的发展。


<details>
  <summary>Details</summary>
Motivation: LLMs在自动化复杂物理系统数值实验方面的应用潜力巨大但研究不足，CFD作为计算科学的核心领域，可作为评估LLM科学能力的理想平台。

Method: 提出了一个包含CFDQuery、CFDCodeBench和FoamBench三个部分的CFDLLMBench基准测试套件，用于全面评估LLM在CFD知识、数值和物理推理以及工作流实现方面的能力。该基准结合了详细的任务分类和严格的评估框架，量化LLM在代码可执行性、解的准确性和数值收敛性等方面的表现。

Result: CFDLLMBench基准测试套件能够对LLM在CFD领域的表现进行量化评估，其结果可用于衡量LLM在代码可执行性、解的准确性和数值收敛性等方面的能力。

Conclusion: CFDLLMBench为开发和评估由LLM驱动的复杂物理系统数值实验自动化奠定了坚实的基础。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [91] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 当前机器学习方法在区分 ChatGPT 生成文本和人类书写文本方面表现良好，其中 DistilBERT 模型表现最佳，单一模型的性能优于模型集成。


<details>
  <summary>Details</summary>
Motivation: 随着 ChatGPT 等大型语言模型的普及，AI 生成文本与人类书写文本的界限变得模糊，对学术诚信、知识产权和错误信息传播提出了紧迫问题。因此，需要可靠的 AI 文本检测来保障人类的原创性并建立数字通信的信任。

Method: 研究人员测试并比较了多种机器学习检测技术，包括经典的（逻辑回归、词袋模型、词性标注、TF-IDF 特征）和基于 Transformer 的（BERT、DistilBERT、BERT 加自定义分类器、基于 LSTM 的 N-gram 模型）。他们使用了包含 250 对来自不同研究领域的摘要的标注数据集，并评估了单一模型和模型集成（集成三种最佳模型）的检测性能。

Result: DistilBERT 模型在检测 AI 生成文本方面表现最佳。逻辑回归和 BERT-Custom 模型也提供了稳定且均衡的替代方案。基于 LSTM 和 BERT-N-gram 的方法效果不佳。由三种最佳模型组成的最大投票集成未能超越单独的 DistilBERT 模型。

Conclusion: 该研究全面评估了各种 AI 文本检测方法的优缺点，为开发更强大的基于 Transformer 的框架奠定了基础，这些框架可以使用更大、更丰富的数据集来跟上不断改进的生成式 AI 模型。研究结果强调了单一基于 Transformer 的模型表示优于模型多样性集成的重要性。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [92] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: ConceptViz是一个可视化分析系统，用于探索大型语言模型（LLM）中的概念，弥合稀疏自编码器（SAE）特征与人类可理解概念之间的差距。


<details>
  <summary>Details</summary>
Motivation: 理解LLM内部知识表征是一个重大挑战，尽管SAE技术可以提取可解释特征，但这些特征与人类概念的对齐并不直接，导致解释工作繁琐。因此，需要一种方法来连接SAE特征和人类概念。

Method: ConceptViz提出了一个“识别=>解释=>验证”的新颖流程，用户可以用感兴趣的概念查询SAE，交互式探索概念与特征的对齐，并通过模型行为验证来确认对应关系。

Result: ConceptViz通过两个使用场景和一项用户研究证明了其有效性，能够增强可解释性研究，简化LLM中有意义的概念表征的发现和验证过程。

Conclusion: ConceptViz通过简化LLM中概念表征的发现和验证过程，增强了可解释性研究，最终帮助研究人员构建更准确的LLM特征心智模型。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [93] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: SKILL-RAG利用模型的


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)虽然提升了大型语言模型(LLM)在知识密集型任务上的性能，但检索系统可能返回不相关内容，导致模型产生幻觉。因此，识别和过滤掉无用的检索内容是提高RAG性能的关键挑战。

Method: SKILL-RAG (Self-Knowledge Induced Learning and Filtering for RAG) 提出了一种新方法，利用模型的“自我知识”（即模型知道什么、不知道什么）来确定哪些检索文档有助于回答给定查询。该方法设计了一个基于强化学习的训练框架来明确引发模型的自我知识，并采用句子级粒度来过滤无关内容，同时保留有用知识。

Result: 在Llama2-7B和Qwen3-8B模型以及多个问答基准上的评估结果表明，SKILL-RAG不仅提高了生成质量，还显著减少了输入文档的数量，验证了自我知识在指导高质量检索选择方面的重要性。

Conclusion: SKILL-RAG通过利用模型的自我知识，有效地解决了RAG中检索内容不相关的问题，提高了生成质量并优化了检索效率。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [94] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [95] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一种名为USB-Rec的集成训练-推理框架，通过用户模拟器进行训练，以改进大型语言模型（LLMs）在对话推荐系统（CRS）中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLMs的对话推荐系统方法主要利用LLMs的总结和分析能力，而忽略了训练问题。本研究旨在解决这一问题，通过提出一个集成的训练-推理框架来改进LLMs在对话推荐方面的性能。

Method: 该研究提出了USB-Rec框架，包括两个主要部分：1. 设计了一个基于LLMs的偏好优化（PO）数据集构建策略，用于强化学习（RL）训练，帮助LLMs理解对话推荐的策略和方法。2. 提出了一个在推理阶段的自我增强策略（SES），以进一步挖掘RL训练获得的对话推荐潜力。

Result: 在多个数据集上的广泛实验表明，该方法在对话推荐任务上持续优于先前最先进的方法。

Conclusion: USB-Rec框架通过结合PO数据集构建策略和SES推理策略，有效提升了LLMs在对话推荐系统中的性能，并在多个基准测试中取得了领先结果。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [96] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 通过使用保形预测来保证覆盖率，Conformal Importance Summarization 框架能够对生成的重要性摘要进行严格的、无分布的覆盖率保证。该方法具有模型无关性，并且可以与现有的黑盒大型语言模型（LLM）无缝集成。


<details>
  <summary>Details</summary>
Motivation: 现有自动摘要系统在医疗、法律和金融等高风险领域缺乏对关键内容包含的可靠保证。

Method: 通过校准句子级重要性得分的阈值，实现具有用户指定覆盖率和关键内容召回率的抽取式文档摘要。

Result: 实验表明，Conformal Importance Summarization 实现了理论上保证的信息覆盖率。

Conclusion: Conformal Importance Summarization 可以与现有技术结合，实现可靠、可控的自动摘要，为在关键应用中更安全地部署 AI 摘要工具铺平道路。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [97] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: ShortCheck是一个用于检测短视频平台（如TikTok）上虚假信息的自动化流程，通过整合多种技术（语音转录、OCR、物体和深度伪造检测、视频摘要、声明验证）来识别可疑视频，并在多语言数据集上达到了超过70%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 短视频平台（如TikTok）因其多模态、动态和嘈杂的内容，对虚假信息检测提出了独特的挑战。

Method: ShortCheck是一个模块化的、仅推理的流程，具有用户友好的界面，它整合了语音转录、OCR、物体和深度伪造检测、视频到文本的摘要以及声明验证，以自动识别值得核查的短视频。

Result: 该流程在两个手动注释的多语言TikTok视频数据集上进行了验证，取得了超过70%的加权F1分数，结果有待提高。

Conclusion: ShortCheck为帮助事实核查人员应对短视频平台上的虚假信息挑战提供了一个有前景的解决方案。

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [98] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: MARS是一个基于角色协作的框架，通过模拟评审过程来提高LLM的推理能力，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 单个大型语言模型（LLM）的推理能力有限，而现有的多智能体辩论（MAD）方法虽然有效，但计算开销大。

Method:  MARS框架包含一个作者智能体、多个评审智能体和一个元评审智能体。作者智能体生成解决方案，评审智能体独立提供反馈，元评审智能体整合反馈并指导修订。

Result:  MARS在多个基准测试中，与MAD和其他先进的推理策略相比，准确率相当，但将代币使用和推理时间减少了约50%。

Conclusion:  MARS通过模拟评审过程，在不增加计算成本的情况下，提高了LLM的推理能力，并且在准确率和效率上都表现出色。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [99] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 该研究提出了SiniticMTError数据集，用于改进低资源语言（如粤语和吴语）的机器翻译。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译技术在处理粤语和吴语等低资源语言时面临数据不足的挑战。

Method: 创建了一个包含错误跨度、错误类型和错误严重性注释的新型数据集SiniticMTError，该数据集基于现有的平行语料库，覆盖从英语到普通话、粤语和吴语的机器翻译。

Result: 报告了详细的注释过程，包括说话人之间的一致性分析、迭代反馈以及错误类型和严重性模式的分析。

Conclusion: SiniticMTError数据集可用于微调具有错误检测能力的机器翻译模型，从而支持翻译质量评估、错误感知生成和低资源语言评估等方面的研究。

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [100] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: SwasthLLM是一个统一的、零样本、跨语言、多任务学习框架，用于在英语、印地语和孟加拉语中进行医疗诊断，无需进行特定语言的微调。


<details>
  <summary>Details</summary>
Motivation: 在多语言医疗环境中，由于低资源语言的标记医疗数据稀缺以及人群间的语言差异，从临床文本自动诊断疾病仍然是一项挑战。

Method: SwasthLLM利用多语言XLM-RoBERTa编码器，并结合了语言感知注意机制和疾病分类头，还引入了暹罗对比学习模块、翻译一致性模块和对比投影头，以实现跨语言的语义表示对齐和语言不变性表示学习。采用多任务学习策略，并使用模型无关元学习（MAML）进行快速自适应。

Result: SwasthLLM在监督设置下达到了97.22%的测试准确率和97.17%的F1分数。在零样本场景下，它在印地语医疗文本上达到了92.78%的准确率，在孟加拉语医疗文本上达到了73.33%的准确率。

Conclusion: SwasthLLM在低资源环境下展现了强大的泛化能力，能够有效地进行跨语言医疗诊断。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [101] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: DS-MoE通过引入针对不同推理深度的专家模块，动态组装定制化的推理链，从而提高效率、推理质量和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型对所有输入应用相同的处理深度，效率低下且限制了推理质量。

Method: 提出了一种名为动态推理链（DS-MoE）的模块化框架，该框架将专家混合（MoE）范式从基于宽度的计算扩展到基于深度的专业化计算。DS-MoE引入了针对不同推理深度（浅层模式识别、组合推理、逻辑推理、记忆集成和元认知监督）进行优化的专家模块，并通过学习到的路由网络动态地组装定制化的推理链。

Result: DS-MoE相比统一深度的Transformer模型，计算节省高达16%，推理速度提高35%，在复杂的、多步骤的推理基准测试上准确率提高2.8%。此外，路由决策可提供可解释的推理链。

Conclusion: DS-MoE通过深度专业化的模块化处理，在提高大型语言模型的效率、推理质量和可解释性方面取得了显著进步。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [102] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: HRT是一种新颖的、受小波启发的神经网络架构，它能够同时以多个分辨率处理语言，从而在计算效率和语言理解准确性方面都优于标准Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer模型在处理语言的层级结构时存在固有缺陷，导致计算成本高、泛化能力弱以及对语篇层面的建模不足。

Method: 提出了一种名为HRT的新架构，该架构采用受小波启发的、能够同时处理多分辨率语言的神经网络，通过多分辨率注意力机制实现自底向上的组合和自顶向下的语境化，并利用指数级序列缩减实现了O(nlogn)的计算复杂度。

Result: HRT在GLUE、SuperGLUE和Long Range Arena等多个基准测试中均超越了标准Transformer模型，平均准确率分别提高了+3.8%、+4.5%和+6.1%，同时内存占用减少了42%，推理延迟降低了37%。

Conclusion: HRT是第一个在计算结构上与人类语言层级组织相匹配的架构，证明了多尺度、受小波启发的处理方式在理论效率和实际语言理解能力方面都能带来显著提升。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [103] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM通过显式地将采样步数设为可调参数，并训练模型使其在不同步数预算下保持一致，从而实现了在保证生成质量的同时，大幅提升了文本生成速度。


<details>
  <summary>Details</summary>
Motivation: Autoregressive language models (ARMs)生成速度慢，而Diffusion Language Models (DLMs)虽然可以并行处理，但需要大量模型评估才能达到高质量。FS-DFM旨在解决DLMs采样效率低的问题。

Method: FS-DFM是一种离散流匹配模型，它将采样步数作为显式参数，并训练模型使其在不同的步数预算下保持一致性，从而允许模型使用较少的步数完成生成。此外，FS-DFM还采用了一个可靠的更新规则，以避免过拟合，并通过蒸馏自长程轨迹的教师指导来增强模型性能。

Result: FS-DFM在语言模型基准测试中，使用8个采样步数，在生成1024个token时，达到了与1024步的离散流基线模型相当的困惑度。与基线模型相比，FS-DFM的采样速度提高了128倍，并带来了相应的延迟/吞吐量增益。

Conclusion: FS-DFM通过其创新的方法，在文本生成速度和质量之间取得了良好的平衡，为需要高效文本生成的应用场景提供了有前景的解决方案。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [104] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: LLMs的评估瓶颈可以通过预测模型性能来缓解，即使在没有数据集的情况下也可以预测，并且引入了一个名为PRECOG的新数据集，该数据集包含任务描述和性能指标的配对，研究表明这种预测是可行的，并且可以帮助更智能地进行实验。


<details>
  <summary>Details</summary>
Motivation: 评估瓶颈限制了大型语言模型的发展，因此需要探索在不进行实验的情况下预测模型性能的方法。

Method: 构建了一个名为PRECOG的语料库，其中包含经过编辑的任务描述和相应的性能指标，并使用带有检索模块的模型来预测文本任务的性能。

Result: 研究表明，在具有适度预测性能和良好校准不确定性的情况下，可以预测模型性能，即使在零泄露设置下，GPT-5也能达到有意义的预测准确性。

Conclusion: PRECOG语料库和相关分析是朝着开放式预期评估迈出的第一步，有助于评估难度和更明智地确定实验优先级。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [105] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 提出了一种结合多任务学习和估计器融合的语音识别方法，以解决日语口语评估任务中数据稀疏的问题，显著提高了音素标签的准确性。


<details>
  <summary>Details</summary>
Motivation: 日语口语评估任务需要精确的音素和声调标注，但现有数据不足以支持高精度模型的训练。

Method: 1. 多任务学习：引入辅助损失函数，同时预测音素标签、声调和文本信息，以利用仅有文本标注的数据。 2. 估计器融合：融合音素字母串和文本序列的估计器，并开发基于有限状态转换器（FST）的算法进行结合。

Result: 所提出的方法将平均词素错误率从12.3%降低到7.1%，优于通用多语言识别器，并对两种方法的相对优势进行了比较。

Conclusion: 多任务学习和估计器融合是构建高精度日语语音识别器的有效方法，特别是在数据稀疏的情况下。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [106] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 结合大语言模型提取的知识和预训练分子模型的结构特征，用于分子属性预测。


<details>
  <summary>Details</summary>
Motivation: 药物发现中分子属性预测至关重要，现有基于图神经网络和自监督学习的方法虽有进展，但仍需整合人类先验知识，而大语言模型（LLMs）在知识提取方面表现出潜力但存在知识空白和幻觉问题。

Method: 提出一个新框架，将LLMs提取的知识（包括领域相关知识和用于分子向量化的可执行代码）与预训练分子模型提取的结构特征融合，以增强分子属性预测。实验中使用了GPT-4o、GPT-4.1和DeepSeek-R1三种LLMs。

Result: 实验证明，所提出的融合方法优于现有方法，表明LLM提取的知识与结构信息相结合是解决分子属性预测问题的有效方案。

Conclusion: 结合LLM提取的知识和结构信息是增强分子属性预测的强大且有效的方法。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [107] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: RedHerring是一种新型文本攻击，旨在通过误导攻击检测模型来降低其可靠性，同时保持分类器准确性。该攻击在多个数据集上显著降低了检测准确率，并提出了一种简单的置信度检查作为防御措施。


<details>
  <summary>Details</summary>
Motivation: 现有攻击检测模型在面对文本对抗性攻击时，其可靠性尚未得到充分验证。因此，需要探索新的攻击方式来评估和挑战这些检测模型的鲁棒性。

Method: 提出并测试了一种名为RedHerring的新型攻击方法。该方法旨在修改文本，使得攻击检测模型做出错误预测（即判断为攻击），但同时保持文本分类器对原始文本的正确分类。通过在多个数据集上，针对不同的检测模型和分类器进行实验，评估RedHerring的有效性。

Result: RedHerring攻击能够将检测准确率降低20-71个百分点，同时保持甚至提高分类器的准确率。此外，提出了一种无需重新训练的置信度检查方法，能够显著提高检测准确率。

Conclusion: RedHerring攻击模型揭示了攻击者可能针对检测模型的新的攻击方式，并强调了对这些模型进行可靠性评估的重要性。提出的置信度检查为防御此类攻击提供了一种有效且无需复杂模型更新的解决方案。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [108] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 研究对抗性文本攻击对于评估NLP模型鲁棒性至关重要，但现有方法计算成本高且需要大量查询。本文提出了Hybrid Select和Dynamic Select两种新的攻击选择策略，以在减少查询数量的同时保持攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的NLP模型计算成本高，查询数量大，对资源有限的研究者不友好。

Method: 提出了两种新的攻击选择策略：Hybrid Select（结合BinarySelect和GreedySelect，根据文本长度阈值选择策略）和Dynamic Select（学习不同长度文本适用的选择策略）。

Result: 在4个数据集和6个目标模型上的实验表明，所提出的Hybrid Select（句子级别）平均可将每次攻击所需的查询数量减少高达25.82%，同时保持攻击效果。

Conclusion: 提出的Hybrid Select和Dynamic Select策略能够有效降低对抗性文本攻击的查询成本，同时保持攻击效果，为资源有限的研究者提供了更优的选择。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [109] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: MI-Fuse框架通过融合LALM和辅助教师模型的预测，并根据互信息进行加权，实现了在目标域的语音情感识别的性能提升，优于单独的LALM和现有基线。


<details>
  <summary>Details</summary>
Motivation: 在实际部署中，语音情感识别（SER）常因域不匹配而失败，此时无法获得源域数据，但可以访问API形式的大型音语模型（LALM）。本研究旨在探索在只有目标域无标签音频和API形式LALM的情况下，能否通过学生模型适应，使其性能超越LALM。

Method: 提出MI-Fuse框架，该框架将预训练的源域SER分类器作为辅助教师，与LALM一同使用。框架通过互信息确定的不确定性对两个教师的多个随机预测进行加权平均，并使用指数移动平均教师来稳定训练。

Result: 在三个公开情感数据集和六个跨域迁移实验中，MI-Fuse框架均取得了一致的性能提升，学生模型在性能上超越了LALM，并比最强的基线高出3.9%。

Conclusion: MI-Fuse方法在不共享源域数据的情况下，增强了面向情感的语音系统，实现了在目标域的有效适应。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [110] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 现有的无监督神经语法归纳模型由于概率分布坍塌而受限于表达能力，导致语法冗长且性能不佳。本文通过引入“坍塌-放松”神经参数化方法，缓解了这一问题，显著提升了解析性能，并允许使用更紧凑的语法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督神经语法归纳模型存在表达能力瓶颈，生成的语法冗长且性能不佳，核心原因是概率分布坍塌。

Method: 分析了概率分布坍塌在神经参数化中的成因，并提出了一种名为“坍塌-放松”的神经参数化方法来缓解这一问题。

Result: 该方法在多种语言上进行了广泛的经验分析，结果显示能够显著提升解析性能，并允许使用更紧凑的语法。

Conclusion: 提出的“坍塌-放松”神经参数化方法能够有效解决无监督神经语法归纳中的概率分布坍塌问题，从而在保证或提升性能的同时，生成更简洁的语法结构。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [111] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: C2R是一个训练免费框架，可用于文本、图像和视频领域的多模态问答任务。它通过构建和优化子问题及其答案来提高最终答案的置信度，并能在不依赖外部数据的情况下提升各种现有问答模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统在处理复杂推理任务时，尤其是在多模态领域，仍面临挑战。需要一种无需额外训练、能够提升模型自身置信度评估能力并改进推理过程的框架。

Method: C2R框架首先生成和筛选一组子问题及其答案（子-QAs），以探索不同的推理路径。然后，它比较由这些子-QAs产生的候选答案的置信度分数，并选择置信度最高的最可靠答案作为最终答案。该框架仅依赖模型自身产生的置信度分数进行判断。

Result: C2R框架在各种问答模型和基准测试中都表现出一致的性能提升。此外，研究还深入分析了子-QAs的数量和质量对模型行为的影响，为实现鲁棒和可靠的推理提供了宝贵的见解。

Conclusion: C2R框架是一种有效的训练免费方法，可以通过智能地构建和细化子问题及其答案来提高多模态问答的性能和可靠性。该研究还强调了理解子-QAs对模型行为影响的重要性。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [112] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 在特定领域数据集上进行监督微调（SFT）通常被认为会损害大语言模型（LLMs）的通用能力。本研究通过实证和理论分析，提出了一种名为Token-Adaptive Loss Reweighting（TALR）的新方法，可以在适应特定任务的同时，有效减轻通用能力下降的问题。研究表明，使用较小的学习率可以缓解性能下降，而TALR在此基础上能进一步优化在领域特定增益和通用能力之间的平衡。最终，研究为LLMs的领域适应提供了实用建议：采用小学习率，并在需要更强平衡时使用TALR。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在适应大语言模型（LLMs）到特定任务时，常被认为会损害其通用能力，本研究旨在重新审视这一权衡，并提出解决方案。

Method: 通过实证和理论分析，提出一种名为Token-Adaptive Loss Reweighting（TALR）的新方法。研究了包括L2正则化、LoRA、模型平均、FLOW和TALR在内的多种策略，以减少通用能力损失。

Result: 实验结果表明，TALR在平衡领域特定增益和通用能力方面持续优于其他基线方法，尽管没有一种方法能完全消除这种权衡。

Conclusion: 建议在适应LLMs到新领域时，采用小学习率以获得有利的权衡；当需要更强的平衡时，应采用TALR作为有效策略。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [113] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: LLM内部表征单元未定义，提出原子理论，用原子内积修正表征偏移，证明原子满足RIP，可稳定稀疏表示，并确保唯一性和L1可恢复性。单层稀疏自编码器可识别原子。实验在Gemma2和Llama3.1上验证了原子理论，稀疏重建率达99.9%，原子唯一性满足率远超神经元和特征，表明原子能更准确地捕捉LLM的内在表征。实验还揭示了SAE大小与恢复能力的关系。该工作提供了理解LLM内部表征的理论框架和可解释性基础。


<details>
  <summary>Details</summary>
Motivation: LLM内部表征的根本单位尚未明确，这限制了对其机制的深入理解。现有的神经元或特征作为单位存在多义性、不可靠重构和不稳定性等问题。

Method: 提出原子理论，定义基本单位为原子。引入原子内积（AIP）来修正表征偏移。形式化定义原子，并证明了原子满足受限等距性质（RIP）的条件，确保了在原子集合上的稳定稀疏表示，并与压缩传感联系起来。在更强的条件下，进一步确证了稀疏表示的唯一性和精确的l1可恢复性，并保证了具有阈值激活的单层稀疏自编码器（SAE）能够可靠地识别原子。

Result: 在Gemma2-2B、Gemma2-9B和Llama3.1-8B上训练了阈值激活的SAE，实现了平均99.9%的稀疏重构率。超过99.8%的原子满足唯一性条件，而神经元满足唯一性条件的比例为0.5%，特征为68.2%。表明原子比神经元和特征更能忠实地捕捉LLM的内在表征。扩展实验揭示了SAE大小与恢复能力之间的联系。

Conclusion: 系统地介绍并验证了LLM的原子理论，为理解内部表征提供了理论框架，并为机制可解释性奠定了基础。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [114] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 通过将用户评论重构为多轮对话，提出了一种名为“对话式提示”的轻量级方法，用于在样本量少且无需训练的情况下生成个性化评论，显著优于传统提示方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成个性化评论时，要么需要大量的用户评论历史，要么需要额外的模型训练，这在现实应用中难以实现，因为通常只有很少的用户评论可用，并且无法进行模型微调。

Method: 提出“对话式提示”方法，将用户评论重构为多轮对话。其简单变体SCP仅使用用户自己的评论；对比变体CCP插入其他用户或LLM的评论作为错误回复，然后要求模型进行纠正，以生成符合用户风格的文本。

Result: 在八个产品领域和五个LLM上进行实验，结果表明，SCP和CCP生成的评论比传统非对话式提示生成的评论更接近目标用户的真实评论，即使每个用户只有两条评论。CCP在有高质量负面示例时效果更好，SCP在无法收集此类数据时仍具竞争力。

Conclusion: 对话式提示是一种实用的方法，可以在样本量少且无需训练的约束下生成个性化评论。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [115] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: LLMs在知识图谱问答（KGQA）中存在幻觉和事实错误问题，主要是由于知识图谱（KGs）和查询之间的语义鸿沟。为解决此问题，提出 Enrich-on-Graph (EoG) 框架，利用LLMs的先验知识丰富KGs，缩小语义鸿沟，实现高效、精确、鲁棒的推理，同时保持低计算成本、可扩展性和适应性。此外，还提出了三个图质量评估指标来分析KGQA任务中的查询-图对齐。实验表明EoG能有效生成高质量KGs并达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在知识图谱问答（KGQA）中存在幻觉和事实错误问题，主要是由于知识图谱（KGs）和查询之间的语义鸿沟。现有方法在处理KGQA时资源消耗大、可扩展性差，并且忽略了这种语义鸿沟。

Method: 提出 Enrich-on-Graph (EoG) 框架，该框架利用LLMs的先验知识来丰富KGs，从而缩小KGs和查询之间的语义鸿沟。该框架能够从KGs中高效提取证据，实现精确和鲁棒的推理，同时保持低计算成本、可扩展性和适应性。此外，还提出了三种图质量评估指标来分析KGQA任务中的查询-图对齐。

Result: 在两个KGQA基准数据集上的大量实验表明，EoG能够有效生成高质量的KGs，并实现最先进的性能。

Conclusion: EoG框架能够有效弥合知识图谱与查询之间的语义鸿沟，提高LLMs在KGQA任务中的准确性和鲁棒性，并且具有低计算成本、高可扩展性和良好的适应性。所提出的图质量评估指标也为分析和优化KGQA任务提供了新的视角。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [116] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: PoCO通过让LLM进行过度纠错，然后用sLM进行后纠错来平衡召回率和精确率，从而提高语法纠错性能。


<details>
  <summary>Details</summary>
Motivation: sLM虽然可靠但召回率低，LLM虽然召回率高但精确率低，需要结合两者的优点。

Method: 首先使用LLM进行过度纠错以最大化召回率，然后使用sLM进行后纠错以提高精确率。

Result: PoCO在提高召回率的同时保持了具有竞争力的精确率，显著提高了语法纠错的整体质量。

Conclusion: PoCO是一种有效的方法，可以利用LLM的生成能力和sLM的可靠性来提高语法纠错的性能。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [117] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 通过将多示例 in-context learning (ICL) 的信息提炼成简洁的文本摘要（备忘单），cheat-sheet ICL 可以在推理时用作上下文，从而以更少的 token 实现相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 的最新进展使得有效的 in-context learning (ICL) 成为可能，但由于输入 token 较长，计算成本很高。

Method: 提出 cheat-sheet ICL，将多示例 ICL 的信息提炼成简洁的文本摘要（备忘单），用作推理时的上下文。

Result: 在具有挑战性的推理任务上进行实验，证明 cheat-sheet ICL 的性能与多示例 ICL 相当或更好，但使用的 token 少得多，并且在不需要测试时检索的情况下，其性能与基于检索的 ICL 相当。

Conclusion: cheat-sheet ICL 是利用 LLM 进行下游任务的实用替代方案。

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [118] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: LLM在云服务中的应用引发隐私担忧，现有技术难以平衡隐私与文本自然性。本文提出一种零样本、基于树搜索的迭代句子重写算法，能在保护隐私的同时保持文本的连贯性、相关性和自然性。实验证明该方法优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 云服务中LLM的应用引发了用户输入可能泄露敏感信息的隐私担忧，而现有的文本匿名化和去标识化技术在平衡隐私保护、文本自然性和效用方面存在挑战。

Method: 提出一种零样本、基于树搜索的迭代句子重写算法，通过结构化搜索和奖励模型，逐步重写隐私敏感片段，以达到混淆或删除隐私信息，同时保持文本的连贯性、相关性和自然性。

Result: 在隐私敏感数据集上的实验表明，该方法显著优于现有基线，在隐私保护和效用保持之间取得了更好的平衡。

Conclusion: 所提出的零样本、基于树搜索的迭代句子重写算法能够有效解决LLM应用中的隐私问题，并在保护隐私的同时保持文本的实用性。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [119] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 现有RAG问答系统的引用方法存在问题，本文提出生成子句级引用以提高引用质量和可读性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG问答系统的引用方法生成的引用粒度过大（句或段），可能包含无关信息，或遗漏关键信息，增加了用户验证成本。

Method: 本文提出了一种生成子句级引用的方法，包括制定标注指南、构建数据集、利用LLM生成微调数据、使用信用模型筛选数据，并最终训练模型生成引用。

Result: 实验表明，本文提出的方法能够生成更高质量、更易读的引用。

Conclusion: 本文提出的子句级引用方法有效解决了现有RAG问答系统引用粒度过大和信息遗漏的问题，提高了引用的准确性和用户体验。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [120] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: WeFT是一种加权的监督微调方法，用于扩散语言模型，通过根据熵分配不同的权重来解决SFT的挑战，并在推理基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 由于扩散模型在每个去噪步骤中缺乏精确的概率估计，因此对它们进行监督微调（SFT）仍然具有挑战性。这使得生成过程难以预测且不一致，因此需要一种方法来控制引导生成方向的关键标记。

Method: WeFT是一种加权的SFT方法，该方法根据标记的熵为标记分配不同的权重，该熵源自扩散理论。

Result: 在s1K、s1K-1.1和3k个样本上进行训练，WeFT在四个广泛使用的推理基准（数独、倒计时、GSM8K和MATH-500）上，相较于标准的SFT，分别取得了39%、64%和83%的相对改进。

Conclusion: WeFT通过根据熵分配不同的权重来解决扩散语言模型监督微调的挑战，并在推理基准上取得了显著的性能提升。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [121] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本研究提出了一种为医学推理模型（MRM）生成开放式问题答案排名列表的方法，解决了现有模型主要生成单一答案的局限性，并提出了两种方法：提示（prompting）和微调（fine-tuning）。


<details>
  <summary>Details</summary>
Motivation: 旨在解决当前医学推理模型（MRM）在开放式问题下只能生成单一答案的局限性，因为临床决策通常需要考虑多个选项以降低风险。

Method: 提出并研究了两种生成答案排名列表的方法：提示（prompting）和微调（fine-tuning）。对于微调，进一步探索了监督微调（SFT）和强化微调（RFT），并为 RFT 设计了新的奖励函数。

Result: 研究发现，尽管部分 SFT 模型能适应某些答案格式，但 RFT 模型在多种答案格式上表现出更强的鲁棒性。在 MedQA 的案例研究中，MRM 能够识别有效的答案，即使它们不完全符合基准测试的首选答案。

Conclusion: 本研究首次系统性地研究了如何让 MRM 生成答案排名列表，为开发超越单一答案的医学领域替代答案格式提供了初步探索。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [122] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: SummQ是一个新颖的对抗性多智能体框架，通过在摘要和测验领域的专业智能体之间的协作来解决长文档摘要中的信息丢失、事实不一致和连贯性问题。该框架通过迭代优化和多方面的反馈机制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长文档摘要对当前的大型语言模型（LLMs）仍然是一个重大挑战，因为现有方法在处理过长的文档时常常在信息丢失、事实不一致和连贯性方面遇到困难。

Method: SummQ采用了一个新颖的对抗性多智能体框架，其中包括作为摘要生成器和评审器的智能体，以及作为测验生成器和评审器的智能体。一个审查者智能体用来验证生成的摘要是否包含回答测验问题所需的信息，从而实现通过多方面的反馈机制进行迭代优化。

Result: 在三个广泛使用的长文档摘要基准上的实验结果表明，SummQ在ROUGE和BERTScore指标以及LLM-as-a-Judge和人类评估方面，显著优于现有的最先进方法。

Conclusion: SummQ通过使用对抗性智能体协作来提高摘要质量，为长文档摘要建立了一种新方法。

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [123] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: LLM在AIME和Math500等基准上的评估易受污染和记忆影响。我们提出MemLens，通过分析数字代币的概率轨迹来检测记忆。MemLens发现受污染样本在模型早期层表现出“捷径”行为，而干净样本则在模型深层逐步积累证据。


<details>
  <summary>Details</summary>
Motivation: LLM在AIME和Math500等基准上的评估易受污染和记忆影响，而现有的检测方法泛化能力差，无法有效检测隐式污染数据。

Method: 提出MemLens，通过分析数字代币的概率轨迹来检测记忆。受污染样本在模型早期层表现出“捷径”行为，而干净样本则在模型深层逐步积累证据。

Result: 受污染样本和干净样本表现出明显不同的推理轨迹。通过LoRA注入精心设计的样本，观察到与自然污染数据相同的轨迹模式，证明MemLens捕捉到真实的记忆信号。

Conclusion: MemLens能够有效检测LLM的记忆现象，其分析的概率轨迹模式为区分受污染和干净数据提供了有力证据。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [124] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 该研究通过比较词语的线性距离和中间结构的复杂性来解释句子理解中的记忆负荷，发现中间结构的复杂性（即连接词之间的中间头数量）比线性距离更能解释记忆负荷。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是检验在句子理解过程中，记忆负荷是由句法相关词语之间的线性距离更好地解释，还是由中间材料的结构密度更好地解释。

Method: 该研究使用统一依存树库和跨语言混合效应框架，将句子长度、依存长度和干预复杂度（连接词之间的中间头数量）作为记忆负荷指标的预测因子进行联合评估。

Result: 研究结果显示，句子长度、依存长度和干预复杂度都与记忆负荷正相关，其中句子长度影响最广，而干预复杂度提供的解释力超越了线性距离。

Conclusion: 本研究的结论是，研究结果调和了关于区域性的线性和层级视角，将依存长度视为重要的表面特征，同时将中间头识别为整合和维持需求更直接的指标。该研究还表明，基于UD的图度量和跨语言混合效应建模可以区分处理效率的线性和结构贡献，为评估句子理解中记忆负荷的竞争理论提供了一个有原则的途径。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [125] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 英文LLM的工具调用研究丰富，但对阿拉伯语等其他语言的工具调用能力研究不足，本文旨在填补这一空白。


<details>
  <summary>Details</summary>
Motivation: 研究多语言（特别是阿拉伯语）LLM的工具调用能力，解决现有研究以英语为中心的问题。

Method: 通过实验探究阿拉伯语工具调用数据的必要性、通用指令微调的影响以及特定工具微调的价值，并翻译和改编了两个开源工具调用数据集为阿拉伯语。

Result: 为阿拉伯语LLM开发强大的工具增强型代理提供了关键见解。

Conclusion: 研究为阿拉伯语LLM的工具调用能力提供了优化策略。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [126] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 研究提出五种基于LLM的自动评估系统，用于评估文本输入问题，并与人类评估者进行比较。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在教育领域的应用，特别是在学术文本输入问题的自动评估方面，并提出改进LLM作为评估工具的方法。

Method: 提出五种LLM驱动的评估系统：JudgeLM评估、参考辅助评估、无参考评估、加性评估和自适应评估，并在包含110个计算机科学答案的自定义数据集中进行测试，与人类评估者的结果进行比较。

Result: 参考辅助评估在自动评估和评分文本输入问题方面效果最好，其与人类评估相比，中位数绝对偏差最低（0.945），均方根偏差最低（1.214）。其他方法如加性评估和自适应评估在简洁答案方面效果不佳，无参考评估缺乏必要信息，JudgeLM评估效果不理想。

Conclusion: 研究得出结论，人工智能驱动的自动评估系统，通过适当的方法学辅助，有潜力作为其他学术资源的补充工具。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [127] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 大型语言模型可加速联邦研发中心的文本分析，并能在敏感环境下安全运行。


<details>
  <summary>Details</summary>
Motivation: 联邦研发中心面临大量文本分析工作，手动处理效率低下。

Method: 使用OnPrem.LLM这一开源框架，结合少量示例，实现文本的摘要、分类、提取和理解。

Result: 通过国防政策文件和科学语料库（如NDAA和NSF awards）的案例研究，证明了该方法在不影响审计性和数据主权的前提下，提高了监督和战略分析的效率。

Conclusion: 在敏感政府环境中安全、灵活地应用生成式AI，可以有效加速联邦研发中心的文本分析任务。

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [128] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 因果掩码（causal mask）可独立于位置编码（positional encoding）诱导位置依赖模式，并可能扭曲显式位置编码（如RoPE）的行为。


<details>
  <summary>Details</summary>
Motivation: Transformer解码器中的因果掩码（causal mask）也提供位置信息，但其作用和影响被忽视。本研究旨在理论和实证分析因果掩码如何以及在多大程度上影响模型的位置感知能力。

Method: 通过理论分析因果掩码如何诱导位置依赖的注意力模式，并进行实证分析来验证这些模式在训练模型中的存在和影响，特别是与RoPE（一种常用的显式位置编码）的交互作用。

Result: 理论分析表明，因果掩码可以独立于任何参数或因果依赖性，诱导注意力分数中的位置依赖模式，并倾向于关注邻近的查询-键对。实证分析证实了这一点，并发现学习到的参数会进一步增强这些模式。此外，研究发现因果掩码与RoPE的交互会扭曲RoPE的相对注意力分数模式，使其变为非相对模式。

Conclusion: 因果掩码是Transformer模型中位置信息的重要来源，与显式位置编码（如RoPE）同等重要，并且其与显式位置编码的交互作用会影响模型的整体位置感知行为。因此，在设计和分析Transformer模型时，应同时考虑因果掩码和显式位置编码的作用。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [129] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: LLM 在遵循多重指令方面的能力会随着指令数量的增加而下降，但可以通过回归模型进行有效估计。


<details>
  <summary>Details</summary>
Motivation: 随着 LLM 在现实世界中的广泛应用，理解其同时遵循多重指令的能力至关重要。

Method: 创建了 ManyIFEval（文本生成）和 StyleMBPP（代码生成）两个基准，并在十个 LLM 上进行了实验。开发了三种回归模型来预测在未见过的指令组合和不同指令数量下的性能。

Result: 实验表明，随着指令数量的增加，LLM 的性能会下降。所开发的回归模型，特别是使用指令数量作为解释变量的逻辑回归模型，可以以大约 10% 的误差预测性能，即使对于未见过的指令组合也是如此。仅需较小的样本量（ManyIFEval 为 500，StyleMBPP 为 300）即可实现准确的性能估计。

Conclusion: LLM 在遵循多重指令方面的能力与指令数量呈负相关，但通过回归模型可以高效地估计其性能，从而实现对 LLM 在各种指令组合下的高效评估。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [130] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 本研究提出了SoM-1K，一个包含1065个结构力学问题的多模态数据集，用于评估基础模型在工程问题上的表现。研究发现当前基础模型表现不佳，但使用图像描述（DoI）的提示策略可以提高大型语言模型（LLM）的表现，甚至优于直接使用图像输入。这表明准确的文本描述对于当前基础模型理解复杂工程问题至关重要。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型在复杂多模态工程问题（特别是材料强度学）上的能力，并为此提供一个大规模基准数据集。

Method: 创建SoM-1K数据集，包含1,065个带标注的材料强度学问题，结合文本和图表。提出一种名为图像描述（DoI）的新提示策略，为模型提供专家生成的文本描述来解释图表。评估了八个代表性基础模型（LLM和VLM），并进行了详细的错误分析。

Result: 在SoM-1K数据集上，当前基础模型的准确率最高仅为56.6%。使用DoI提示策略的LLM在某些情况下优于直接处理图像的VLM。错误分析表明DoI能有效减少视觉误解错误。

Conclusion: 现有基础模型在处理复杂的材料强度学问题方面能力有限。准确的文本描述（如DoI）比直接的图像输入更能有效帮助当前模型解决这些问题。需要开发更强大的多模态推理能力，尤其是在科学和工程领域。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [131] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在生成任务中存在文化定位偏见，倾向于美国主流文化，并对非主流文化采取疏离立场。本研究提出了CultureLens基准和两种缓解偏见的方法：基于提示的FIP方法和结构化的MFA框架（包括单代理MFA-SA和多代理MFA-MA）。实验表明，MFA方法能有效缓解LLMs的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成任务中存在文化定位偏见，倾向于美国主流文化，并对非主流文化采取疏离立场。

Method: 本研究提出了CultureLens基准，包含4000个生成提示和3个评估指标，用于量化文化定位偏见。并提出了两种缓解偏见的方法：基于提示的公平性干预支柱（FIP）方法，以及结构化的公平性代理缓解（MFA）框架，该框架包括单代理MFA-SA和多代理MFA-MA。

Result: 对5个先进LLMs的实证评估显示，模型在88%的美国情境脚本中采用内部语气，但在非主流文化情境脚本中则主要采取外部立场。MFA方法被证明是缓解生成LLM偏见的有效途径。

Conclusion: 文化定位偏见是LLMs中存在的一个新颖且值得关注的问题。提出的CultureLens基准和MFA缓解框架为量化和解决这一偏见提供了有效工具，特别是基于代理的方法为未来研究指明了方向。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [132] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: PerHalluEval是首个针对波斯语的动态幻觉评估基准，旨在解决低资源语言中的LLM幻觉问题。该基准使用LLM驱动的管道和人工验证来生成和选择幻觉实例，并特别关注波斯语文化背景。评估结果显示，LLM在检测波斯语幻觉文本方面存在困难，但提供外部知识可以部分缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 幻觉是影响所有大型语言模型（LLM）的长期存在的问题，特别是在波斯语等低资源语言中。

Method: 该基准利用一个三阶段的、由LLM驱动的、并经过人工验证的管道来生成和选择最可信的幻觉实例。此外，还利用了生成代币的对数概率来选择最可信的幻觉实例。通过让人类注释者突出QA数据集中与波斯语相关的特定内容，以评估LLM在与波斯语文化相关的特定内容方面的表现。

Result: 对12个LLM的评估表明，它们在检测波斯语幻觉文本方面普遍存在困难。提供外部知识（例如，用于摘要任务的原始文档）可以部分减轻幻觉。此外，专门为波斯语训练的LLM与其他LLM在幻觉方面的表现没有显著差异。

Conclusion: PerHalluEval是首个针对波斯语的动态幻觉评估基准。该评估揭示了LLM在处理波斯语幻觉方面的挑战，并强调了外部知识的潜在作用。此外，该研究还发现，专门的波斯语模型在幻觉检测方面并未显示出优于通用模型的优势。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [133] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 本研究提出了一个名为BESPOKE的现实基准，用于评估搜索增强型大语言模型（LLMs）的个性化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索增强型LLMs在满足用户多样化需求方面仍有不足，尤其是在理解同一查询可能包含的不同用户意图以及以用户偏好的形式提供信息方面。尽管ChatGPT和Gemini等系统尝试通过用户历史记录来实现个性化，但对这种个性化的系统性评估仍有待深入研究。

Method: BESPOKE基准通过收集真实的、来自人类用户的聊天和搜索历史记录来构建，并配有细粒度的偏好评分和反馈。该基准是通过长期、深入的人工标注过程完成的，标注者贡献了自己的历史记录，提出了带有详细信息需求的查询，并对响应进行评分和提供诊断反馈。

Result: 利用BESPOKE基准，研究进行了系统的分析，揭示了信息检索任务中有效个性化的关键要求，并为个性化搜索增强型LLMs的细粒度评估奠定了基础。

Conclusion: BESPOKE基准的提出填补了对搜索增强型LLMs个性化评估的系统性研究的空白，为未来开发更有效的个性化信息检索系统提供了重要的指导。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [134] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ是一个用于评估口语语言模型（SLM）社会偏见的扩展数据集，它区分了内容偏见和声学偏见，并提供了对LLaMA-Omni和Qwen2-Audio的评估结果。


<details>
  <summary>Details</summary>
Motivation: 为了量化和理解口语语言模型（SLM）中的社会偏见，区分内容和声学两个不同来源的偏见。

Method: 将现有的BBQ（偏见基准测试用于问答）数据集转换为受控的语音条件，创建了VoiceBBQ数据集。使用此数据集评估了LLaMA-Omni和Qwen2-Audio两个SLM。

Result: 评估显示LLaMA-Omni能够抵抗声学偏见，但会放大性别和口音偏见。Qwen2-Audio则在很大程度上抑制了这些声学线索，同时保持了内容保真度。

Conclusion: VoiceBBQ作为一个独立的测试平台，能够同时诊断口语语言模型中的内容偏见和声学偏见。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [135] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: SpeechLMs may exhibit gender bias despite aiming for fairness, with Whisper encoders generating male-oriented acoustic tokens, leading to biased responses for stereotypical questions and inappropriate neutrality for gender-dependent ones.


<details>
  <summary>Details</summary>
Motivation: To investigate and address the phenomenon of acoustic-based gender differentiation in Speech-aware Language Models (SpeechLMs), where identical questions yield different responses based on speaker gender, and to understand the underlying causes of this bias.

Method: Created a new dataset with 9,208 speech samples across Gender-Independent, Gender-Stereotypical, and Gender-Dependent categories. Evaluated LLaMA-Omni models, analyzed responses with and without neutral options, applied gender neutralization methods, and compared SpeechLMs with their backbone LLMs, focusing on Whisper speech encoders.

Result: Identified a paradoxical pattern in LLaMA-Omni models: male-oriented responses for Gender-Stereotypical questions and gender-independent responses for Gender-Dependent questions. Confirmed this bias does not stem from neutral options or perceived voice gender. Found that Whisper speech encoders are the primary source of these biases due to generating male-oriented acoustic tokens.

Conclusion: Current SpeechLMs, despite prioritizing general fairness, fail to eliminate gender biases and misapply gender information by being biased in stereotypical contexts and inappropriately neutral in gender-dependent contexts. This highlights the need for advanced techniques to properly handle gender information in speech technology.

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [136] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent 是一款全自动的文本分类 AutoML 工具，支持多标签分类和范围外检测，并能在效果和资源消耗之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有 AutoML 工具在文本分类任务中缺乏端到端的自动化，特别是在嵌入模型选择、分类器优化和决策阈值调整方面。

Method: AutoIntent 提供了一个模块化的、类似 sklearn 的接口，实现了从嵌入模型选择、分类器优化到决策阈值调整的全过程自动化，并支持多标签分类和范围外检测。

Result: AutoIntent 在标准的意图分类数据集上表现优于现有的 AutoML 工具。

Conclusion: AutoIntent 能够为用户提供一种在模型效果和计算资源消耗之间取得平衡的解决方案。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [137] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 ROC 的新框架，用于解决多模态关系抽取中的局限性，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态关系抽取方法通常采用基于分类的范式，将关系视为离散标签，这忽视了实体类型和位置等结构化约束，并且缺乏细粒度关系理解的语义表达能力。

Method: ROC 框架将多模态关系抽取重新定义为一种由关系语义驱动的检索任务。它通过多模态编码器整合实体类型和位置信息，利用大型语言模型将关系标签扩展为自然语言描述，并通过基于语义相似度的对比学习来对实体-关系对进行对齐。

Result: 实验结果表明，ROC 在 MNRE 和 MORE 基准数据集上实现了最先进的性能，并且表现出更强的鲁棒性和可解释性。

Conclusion: ROC 框架通过将关系抽取视为检索任务并利用自然语言描述来克服现有方法的局限性，从而在多模态关系抽取方面取得了显著的成果。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [138] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: LLM在理解指令时，除了语义和领域，还需要注意语法。研究发现，语法模板（词性标签序列）可能与领域产生虚假关联，即使在模型输出中也可能出现，这会影响模型性能。该研究提出了一种评估框架来检测这种现象，并在多个模型上进行了验证，甚至发现这种虚假关联会影响安全微调。建议在训练数据中确保语法多样性，以避免虚假关联。


<details>
  <summary>Details</summary>
Motivation: 为了确保LLM能够正确理解并响应指令，不仅需要理解指令的语义和领域，还需要认识到语法可能传达的隐含信息。现有研究表明，语法模板（即频繁出现的词性标签序列）在训练数据中普遍存在，并经常出现在模型的输出中。本研究旨在深入探究任务-指令对中的语法模板、领域和语义特征，并识别其中存在的虚假关联。

Method: 本研究通过识别任务-指令对中的语法模板、领域和语义，并分析它们之间的关联。研究使用了合成训练数据集，对OLMo-2模型（1B-13B）进行了实验，以评估语法-领域虚假关联对实体知识任务性能的影响。此外，研究还提出并实施了一个评估框架，用于检测已训练模型中存在的这种现象，并在FlanV2数据集的一个子集上，在开源（OLMo-2-7B；Llama-4-Maverick）和闭源（GPT-4o）模型上进行了验证。最后，通过一个案例研究，探讨了这种虚假关联对安全微调的影响。

Result: 在OLMo-2模型（1B-13B）的实体知识任务中，语法-领域虚假关联将性能降低了0.51 +/- 0.06。该现象在FlanV2数据集的子集上，于OLMo-2-7B、Llama-4-Maverick和GPT-4o等模型中均有出现。在安全微调方面，研究发现这种虚假关联可能被用来绕过OLMo-2-7B Instruct和GPT-4o模型的拒绝机制。

Conclusion: 本研究强调了在LLM训练和评估中，显式测试语法-领域虚假关联的必要性。同时，为了防止此类虚假关联的发生，需要在训练数据中，特别是在特定领域内，确保语法的多样性。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [139] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 对计算性幽默处理的调查，重点关注幽默的生成和解释，并讨论未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 幽默的创造和感知是人类的基本特征，理解幽默需要推理能力，因此可以用来评估大型语言模型的常识和推理能力。

Method: 对计算性幽默的生成和解释进行文献调查。

Result: 关于生成和解释幽默（尤其是俏皮话之外的幽默）的研究很少，而最先进的模型仍无法达到人类的水平。

Conclusion: 计算性幽默处理是自然语言处理的一个子领域，具有重要的研究价值，未来的研究应考虑幽默的主观性和伦理模糊性。

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [140] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 小型语言模型（SLM）因其在某些领域的性能与大型语言模型（LLM）相当，但训练和推理的能耗和时间更少，因此越来越受欢迎。然而，SLM 在下游任务中存在个人身份信息（PII）泄露的问题尚未得到探索。本研究旨在探讨基于 SLM 的聊天机器人的 PII 泄露问题。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLM）在某些领域的性能与大型语言模型（LLM）相当，但能耗和时间更少，因此越来越受欢迎。然而，SLM 在下游任务中存在个人身份信息（PII）泄露的问题尚未得到探索。本研究旨在探讨基于 SLM 的聊天机器人的 PII 泄露问题。

Method: 研究人员首先基于 BioGPT 的骨干网络，使用医疗数据集 Alpaca 和 HealthCareMagic 对一个新的聊天机器人 ChatBioGPT 进行了微调。然后，他们证明了先前基于模板的 PII 攻击方法在 SLM 条件下无法有效提取数据集中的 PII 以进行泄露检测。接着，他们提出了一种专门用于 PII 提取的 GEP（greedy coordinate gradient-based）方法。最后，他们通过自由格式插入实验扩展了 GEP 的能力，其中插入的数据集 PII 是各种句法表达式，而不是固定的模板。

Result: 研究结果表明，GEP 方法与先前基于模板的方法相比，PII 泄露量增加了多达 60 倍。在更复杂和现实的情况下，即使插入的 PII 是各种句法表达式，GEP 仍然能够揭示高达 4.53% 的 PII 泄露率。

Conclusion: 本研究首次探讨了小型语言模型（SLM）的 PII 泄露问题，并提出了一种名为 GEP 的新型 PII 提取方法。实验证明，GEP 在 PII 提取方面比先前的方法有显著提高，即使在复杂的现实场景下也能有效检测 PII 泄露。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [141] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: LLMs在科学推理方面取得了进展，但存在显式检索的“工具税”和多智能体流水线稀释解的缺点。本文提出了一个统一的框架，结合了隐式检索和结构化协作，利用Monitor-based检索模块进行令牌级知识整合，并通过HSR和QAIR进行迭代优化。该框架在HLE Bio/Chem Gold上取得了48.3%的准确率，优于现有方法，并减少了计算成本。在SuperGPQA和TRQA上也显示出鲁棒性。错误分析表明，推理失败和知识差距常同时出现，而多样性分析显示检索任务受益于解的多样性，推理任务则倾向于共识。


<details>
  <summary>Details</summary>
Motivation: 解决了现有LLM在科学推理中显式检索带来的“工具税”问题以及多智能体流水线稀释优秀解决方案的问题。

Method: 提出一个统一的框架，结合了Monitor-based的令牌级隐式检索模块和Hierarchical Solution Refinement (HSR)与Quality-Aware Iterative Reasoning (QAIR)相结合的结构化协作方法，以迭代地优化解决方案。

Result: 在Humanity's Last Exam (HLE) Bio/Chem Gold上达到了48.3%的准确率，超过了最强的智能体基线13.4个百分点，并领先于前沿LLM高达18.1个百分点。同时，令牌使用量减少了53.5%，智能体步数减少了43.7%。在SuperGPQA和TRQA上也验证了方法的鲁棒性。

Conclusion: 隐式增强和结构化精炼可以克服显式工具使用和统一聚合的低效率问题，并指出了推理失败和知识差距的共存性以及不同任务对解的多样性或共识的不同需求。

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [142] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: CLaw是一个评估大语言模型（LLM）中文法律知识和推理能力的基准，包含一个包含306部中国国家法规的细粒度语料库和一个包含254个案例推理实例的基准。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在分析法律文本和引用相关法规时可靠性不足，因为它们的预训练缺乏法律专业知识的侧重，这掩盖了它们真实的法律知识深度。

Method: CLaw基准包含两个部分：1.一个包含所有306部中国国家法规的细粒度语料库，细分至子段级别，并包含精确的历史修订时间戳（64,849条）。2.一组254个基于案例的推理实例，用于评估法律知识的实际应用。

Result: 大多数当代LLM在准确再现法律条文方面存在显著困难，这严重影响了它们在法律推理中的可靠性。

Conclusion: 为了实现可信赖的法律推理，LLM需要准确的知识检索（可能通过监督微调SFT或检索增强生成RAG增强）和强大的通用推理能力的协同作用。CLaw提供了一个重要的基准和关键见解，以推动特定领域的LLM推理，尤其是在复杂的法律领域。

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [143] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: SGMem通过构建句子图来管理长对话记忆，提高了长对话问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 长对话记忆管理是LLM处理超出其上下文窗口的对话历史的关键，现有方法在组织和检索不同粒度的信息方面存在不足。

Method: SGMem将对话表示为句子级别的图，并在分块单元内捕获跨轮次、回合和会话级别的上下文关联，结合检索到的原始对话和生成的记忆（摘要、事实、见解）来为LLM提供连贯且相关的上下文。

Result: 在LongMemEval和LoCoMo数据集上，SGMem在长对话问答任务上持续提高准确性，并优于现有基线方法。

Conclusion: SGMem通过其创新的记忆表示和检索机制，有效地解决了长对话记忆管理中的挑战，并在长对话问答任务中取得了显著的性能提升。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [144] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: QCG-RAG通过查询中心图实现可控粒度的索引和多跳检索，提高了长上下文理解和多跳推理能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索增强生成（RAG）方法在处理长上下文和多跳推理时，面临着细粒度图（实体级别）带来的高令牌成本和上下文丢失问题，以及粗粒度图（文档级别）无法捕捉细微关系的问题。

Method: 提出了一种名为QCG-RAG的查询中心图RAG框架，利用Doc2Query和Doc2Query{-}{-}技术构建具有可控粒度的查询中心图，并设计了定制化的多跳检索机制来通过生成的查询选择相关块。

Result: 在LiHuaWorld和MultiHop-RAG数据集上的实验表明，QCG-RAG在问答准确性方面持续优于先前基于块和基于图的RAG方法。

Conclusion: QCG-RAG建立了一种新的多跳推理范式，解决了现有RAG方法的粒度困境，并在长上下文理解和多跳推理方面取得了显著的性能提升。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [145] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 同形异义词（拼写相同但含义不同）给生成模型带来挑战，扩散模型可能同时生成一个词的多种含义（同形异义词重复）。这种现象因“英美中心”偏见而加剧，即使非同形异义词在翻译成英文后也可能变成同形异义词。本文提出了一种衡量重复率的方法，并利用视觉语言模型（VLM）和人工评估了不同的扩散模型。此外，本文还研究了通过提示扩展来缓解同形异义词重复问题，并证明该方法也能有效减少与英美中心偏见相关的重复。


<details>
  <summary>Details</summary>
Motivation: 同形异义词（拼写相同但含义不同）给生成模型带来挑战，扩散模型可能同时生成一个词的多种含义（同形异义词重复）。英美中心偏见使问题复杂化，因为翻译成英文可能导致非同形异义词变为同形异义词。因此，有必要研究并解决同形异义词重复问题及其与英美中心偏见的关联。

Method: 1. 提出一种测量同形异义词重复率的方法。
2. 使用视觉语言模型（VLM）和人工评估了不同扩散模型的表现。
3. 研究了通过提示扩展来缓解同形异义词重复问题。
4. 验证了提示扩展在减少与英美中心偏见相关的重复方面的有效性。
5. 公开了自动评估流程的代码。

Result: 通过提出的方法，能够衡量同形异义词重复率。
评估结果揭示了不同扩散模型在处理同形异义词重复方面存在差异。
提示扩展被证明是一种有效的缓解同形异义词重复的方法。
该方法同样能有效减少因英美中心偏见引起的同形异义词重复。

Conclusion: 同形异义词重复是扩散模型生成中的一个问题，尤其是在存在英美中心偏见的情况下。本文提出的测量方法和提示扩展技术，为量化和缓解这一问题提供了有效途径，并验证了其在减少英美中心偏见影响方面的潜力。

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [146] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: 输出的同质化问题因任务类型而异，本文提出了一种与任务相关的多样性评估和缓解方法。


<details>
  <summary>Details</summary>
Motivation: 以往关于输出同质化的研究未能从任务依赖性的角度来概念化多样性。

Method: 提出了一种包含八种任务类别的任务分类法，并引入了与任务相关的函数式多样性来评估输出同质化，同时提出了一种与任务相关的采样技术来增加函数式多样性。

Result: 在保持响应质量的同时，通过增加函数式多样性来挑战多样性-质量权衡的看法。

Conclusion: 任务依赖性可以改进对输出同质化的评估和缓解。

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


### [147] [LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text](https://arxiv.org/abs/2509.21269)
*Irina Tolstykh,Aleksandra Tsybina,Sergey Yakubson,Maksim Kuprashevich*

Main category: cs.CL

TL;DR: LLMTrace是一个大规模、双语（英语和俄语）的语料库，用于检测AI生成文本，解决了现有数据集的不足，并支持二元分类和字符级AI生成片段检测。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）检测系统在训练数据方面存在不足，例如使用过时模型生成数据、语言限制（主要是英语）以及未能处理人机混合创作的常见情况。此外，缺乏精确到字符级的标注，无法精确定位AI生成的内容。

Method: 构建了一个大规模、双语（英语和俄语）的语料库LLMTrace，使用了多种现代专有和开源LLM。该数据集支持两种任务：传统的整篇文本二元分类（人类 vs. AI）和新颖的AI生成片段检测，后者通过字符级标注实现。

Result: LLMTrace语料库的建立，能够支持AI生成文本检测的两个关键任务，为训练和评估下一代更细致、更实用的AI检测模型提供了资源。

Conclusion: LLMTrace是一个重要的资源，将促进AI生成文本检测领域的发展，尤其是在处理混合作者身份和需要精确内容定位的场景方面。

Abstract: The widespread use of human-like text from Large Language Models (LLMs)
necessitates the development of robust detection systems. However, progress is
limited by a critical lack of suitable training data; existing datasets are
often generated with outdated models, are predominantly in English, and fail to
address the increasingly common scenario of mixed human-AI authorship.
Crucially, while some datasets address mixed authorship, none provide the
character-level annotations required for the precise localization of
AI-generated segments within a text. To address these gaps, we introduce
LLMTrace, a new large-scale, bilingual (English and Russian) corpus for
AI-generated text detection. Constructed using a diverse range of modern
proprietary and open-source LLMs, our dataset is designed to support two key
tasks: traditional full-text binary classification (human vs. AI) and the novel
task of AI-generated interval detection, facilitated by character-level
annotations. We believe LLMTrace will serve as a vital resource for training
and evaluating the next generation of more nuanced and practical AI detection
models. The project page is available at
\href{https://sweetdream779.github.io/LLMTrace-info/}{iitolstykh/LLMTrace}.

</details>


### [148] [Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond](https://arxiv.org/abs/2509.21284)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 现有研究表明，输入扰动会显著影响思维链（CoT）的输出。尽管许多方法旨在通过优化提示来缓解这种影响，但关于这些扰动如何影响CoT输出的理论解释仍然是一个开放的研究领域。这一差距限制了我们对输入扰动在推理过程中如何传播的深入理解，并阻碍了提示优化方法的进一步改进。因此，本文从理论上分析了输入扰动对CoT输出波动的影响。我们首先在输出波动在可接受范围内这一条件下，推导出了输入扰动的上界，并在此基础上证明了：（i）该上界与CoT中的推理步数呈正相关；（ii）即使是无限长的推理过程也无法消除输入扰动的影响。然后，我们将这些结论应用于线性自注意力（LSA）模型，该模型可以看作是Transformer的简化版本。对于LSA模型，我们证明了输入扰动的上界与输入嵌入和隐藏状态向量的范数呈负相关。为了验证这一理论分析，我们在三个主流数据集和四个主流模型上进行了实验。实验结果与我们的理论分析一致，经验上证明了我们发现的正确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，输入扰动会显著影响思维链（CoT）的输出。尽管许多方法旨在通过优化提示来缓解这种影响，但关于这些扰动如何影响CoT输出的理论解释仍然是一个开放的研究领域。这一差距限制了我们对输入扰动在推理过程中如何传播的深入理解，并阻碍了提示优化方法的进一步改进。因此，本文从理论上分析了输入扰动对CoT输出波动的影响。

Method: 本文首先推导出了输入扰动的上界，并在此基础上证明了该上界与CoT中的推理步数呈正相关，以及即使是无限长的推理过程也无法消除输入扰动的影响。然后，将这些结论应用于线性自注意力（LSA）模型，证明了输入扰动的上界与输入嵌入和隐藏状态向量的范数呈负相关。最后，通过在三个主流数据集和四个主流模型上进行实验来验证理论分析。

Result: 理论分析表明：(i) 输入扰动的上界与CoT中的推理步数呈正相关；(ii) 即使是无限长的推理过程也无法消除输入扰动的影响。对于LSA模型，输入扰动的上界与输入嵌入和隐藏状态向量的范数呈负相关。实验结果与理论分析一致。

Conclusion: 本文从理论上分析了输入扰动对CoT输出波动的影响，并得到了相应的结论。实验结果验证了理论分析的正确性。

Abstract: Existing research indicates that the output of Chain-of-Thought (CoT) is
significantly affected by input perturbations. Although many methods aim to
mitigate such impact by optimizing prompts, a theoretical explanation of how
these perturbations influence CoT outputs remains an open area of research.
This gap limits our in-depth understanding of how input perturbations propagate
during the reasoning process and hinders further improvements in prompt
optimization methods. Therefore, in this paper, we theoretically analyze the
effect of input perturbations on the fluctuation of CoT outputs. We first
derive an upper bound for input perturbations under the condition that the
output fluctuation is within an acceptable range, based on which we prove that:
(i) This upper bound is positively correlated with the number of reasoning
steps in the CoT; (ii) Even an infinitely long reasoning process cannot
eliminate the impact of input perturbations. We then apply these conclusions to
the Linear Self-Attention (LSA) model, which can be viewed as a simplified
version of the Transformer. For the LSA model, we prove that the upper bound
for input perturbation is negatively correlated with the norms of the input
embedding and hidden state vectors. To validate this theoretical analysis, we
conduct experiments on three mainstream datasets and four mainstream models.
The experimental results align with our theoretical analysis, empirically
demonstrating the correctness of our findings.

</details>


### [149] [DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](https://arxiv.org/abs/2509.21287)
*Kin Ian Lo,Hala Hawashin,Mina Abbaszadeh,Tilen Limback-Stokin,Hadi Wazni,Mehrnoosh Sadrzadeh*

Main category: cs.CL

TL;DR: DisCoCLIP通过引入结合了冻结CLIP和新颖张量网络文本编码器的多模态编码器，在视觉-语言任务中显着提高了对动词语义和词序的敏感性，从而在诸如SVO-Probes、ARO和SVO-Swap等基准测试中取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 大型图像-文本对齐模型通常忽略语言的组合结构，这会导致在依赖词序和谓词-论元结构的任务中出现故障。

Method: DisCoCLIP结合了冻结的CLIP视觉变换器和一种新的张量网络文本编码器，该编码器显式编码句法结构。使用组合范畴语法解析器解析句子，得到分布式的词张量，其收缩反映了句子的语法推导。为保持模型效率，高阶张量通过张量分解进行分解，将参数数量从数千万减少到不足一百万。通过端到端的自监督对比损失进行训练。

Result: DisCoCLIP将CLIP的SVO-Probes动词准确率从77.6%提高到82.4%，将ARO归因和关系分数提高9%和4%以上，并在新引入的SVO-Swap基准测试中取得了93.7%的准确率。

Conclusion: 通过张量网络嵌入显式的语言结构，可以产生可解释的、参数高效的表征，从而大大提高视觉-语言任务中的组合推理能力。

Abstract: Recent vision-language models excel at large-scale image-text alignment but
often neglect the compositional structure of language, leading to failures on
tasks that hinge on word order and predicate-argument structure. We introduce
DisCoCLIP, a multimodal encoder that combines a frozen CLIP vision transformer
with a novel tensor network text encoder that explicitly encodes syntactic
structure. Sentences are parsed with a Combinatory Categorial Grammar parser to
yield distributional word tensors whose contractions mirror the sentence's
grammatical derivation. To keep the model efficient, high-order tensors are
factorized with tensor decompositions, reducing parameter count from tens of
millions to under one million. Trained end-to-end with a self-supervised
contrastive loss, DisCoCLIP markedly improves sensitivity to verb semantics and
word order: it raises CLIP's SVO-Probes verb accuracy from 77.6% to 82.4%,
boosts ARO attribution and relation scores by over 9% and 4%, and achieves
93.7% on a newly introduced SVO-Swap benchmark. These results demonstrate that
embedding explicit linguistic structure via tensor networks yields
interpretable, parameter-efficient representations that substantially improve
compositional reasoning in vision-language tasks.

</details>


### [150] [The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages](https://arxiv.org/abs/2509.21294)
*Pranjal A. Chitale,Varun Gumma,Sanchit Ahuja,Prashant Kodali,Manan Uppadhyay,Deepthi Sudharsan,Sunayana Sitaram*

Main category: cs.CL

TL;DR: 本研究提出了一种为印度语言生成合成数据集Updesh的方法，该方法基于维基百科内容，强调文化背景和长上下文能力，并在多语言任务上取得了显著成果，尤其提升了低资源语言的表现。


<details>
  <summary>Details</summary>
Motivation: 低资源语言AI系统在跨语言和文化适应性方面面临挑战，现有合成数据方法的有效性有待探索。

Method: 采用自下而上的策略，提示大型开源语言模型（>=235B参数）利用特定语言的维基百科内容来生成合成数据，并构建了包含9.5M数据点、涵盖13种印度语言的Updesh数据集。

Result: Updesh数据集在自动化和人工评估中显示出高质量，尽管人工评估指出了改进空间。使用Updesh微调的模型在生成任务上显著提升，在多项选择式自然语言理解任务上表现具有竞争力，尤其是在低资源和中等资源语言上效果最为明显。

Conclusion: 有效的多语言AI需要结合上下文感知和文化为基础的数据策选和生成策略。

Abstract: Developing AI systems that operate effectively across languages while
remaining culturally grounded is a long-standing challenge, particularly in
low-resource settings. Synthetic data provides a promising avenue, yet its
effectiveness in multilingual and multicultural contexts remains underexplored.
We investigate the creation and impact of synthetic, culturally contextualized
datasets for Indian languages through a bottom-up generation strategy that
prompts large open-source LLMs (>= 235B parameters) to ground data generation
in language-specific Wikipedia content. This approach complements the dominant
top-down paradigm of translating synthetic datasets from high-resource
languages such as English. We introduce Updesh, a high-quality large-scale
synthetic instruction-following dataset comprising 9.5M data points across 13
Indian languages, encompassing diverse reasoning and generative tasks with an
emphasis on long-context, multi-turn capabilities, and alignment with Indian
cultural contexts. A comprehensive evaluation incorporating both automated
metrics and human annotation across 10k assessments indicates that generated
data is high quality; though, human evaluation highlights areas for further
improvement. Additionally, we perform downstream evaluations by fine-tuning
models on our dataset and assessing the performance across 15 diverse
multilingual datasets. Models trained on Updesh consistently achieve
significant gains on generative tasks and remain competitive on multiple-choice
style NLU tasks. Notably, relative improvements are most pronounced in low and
medium-resource languages, narrowing their gap with high-resource languages.
These findings provide empirical evidence that effective multilingual AI
requires multi-faceted data curation and generation strategies that incorporate
context-aware, culturally grounded methodologies.

</details>


### [151] [Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs](https://arxiv.org/abs/2509.21305)
*Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: LLMs表现出谄媚行为，但其产生机制尚不明确。研究将谄媚行为分解为谄媚性赞同和谄媚性赞扬，并与真诚赞同进行对比。通过多种方法分析，发现这三种行为在模型的潜在空间中沿着不同的线性方向编码，并且可以被独立地增强或抑制，其表示结构在不同模型系列和规模之间保持一致。研究结果表明，LLM的谄媚行为对应着不同的、可独立调控的表示。


<details>
  <summary>Details</summary>
Motivation: LLM（大语言模型）经常表现出谄媚行为（如过度同意或奉承用户），但目前尚不清楚这些行为是由单一机制还是多种不同过程引起的。

Method: 研究人员利用差值均值方向、激活值加法以及跨多个模型和数据集的子空间几何学方法。

Result: 研究表明，谄媚性赞同、谄媚性赞扬和真诚赞同这三种行为在潜在空间中沿着不同的线性方向进行编码。此外，研究人员能够独立地增强或抑制每种行为，而不会影响其他行为。这种表示结构在不同的模型系列和模型规模中都保持一致。

Conclusion: 研究结果表明，LLM的谄媚行为对应着不同的、可独立调控的表示，这为理解和控制LLM的行为提供了新的视角。

Abstract: Large language models (LLMs) often exhibit sycophantic behaviors -- such as
excessive agreement with or flattery of the user -- but it is unclear whether
these behaviors arise from a single mechanism or multiple distinct processes.
We decompose sycophancy into sycophantic agreement and sycophantic praise,
contrasting both with genuine agreement. Using difference-in-means directions,
activation additions, and subspace geometry across multiple models and
datasets, we show that: (1) the three behaviors are encoded along distinct
linear directions in latent space; (2) each behavior can be independently
amplified or suppressed without affecting the others; and (3) their
representational structure is consistent across model families and scales.
These results suggest that sycophantic behaviors correspond to distinct,
independently steerable representations.

</details>


### [152] [RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](https://arxiv.org/abs/2509.21319)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: RLHF和RLVR是LLM训练的主要范式，但存在局限性。RLHF难以解释且容易被利用，RLVR范围受限。我们提出RLBFF，结合了人类偏好和规则验证的优点，可以捕捉响应质量的细微差别，而不仅仅是正确性。RLBFF从自然语言反馈中提取二元原则（例如，信息准确性：是/否），并将这些原则用于基于蕴涵任务的奖励模型训练。


<details>
  <summary>Details</summary>
Motivation: RLHF在可解释性和奖励漏洞方面存在问题，而RLVR的范围有限。需要一种新的方法来结合人类反馈的灵活性和规则验证的精确性。

Method: RLBFF从自然语言反馈中提取可二元回答的原则，并使用这些原则作为蕴涵任务来训练奖励模型。

Result: RLBFF训练的奖励模型在RM-Bench（86.2%）和JudgeBench（81.4%）上取得了领先性能。RLBFF还允许在推理时自定义原则，并且在对Qwen3-32B进行微调时，以更低的成本实现了与领先模型相当的性能。

Conclusion: RLBFF是一种结合人类偏好和规则验证的有效方法，能够提升LLM的对齐性能，并且具有灵活性和成本效益。

Abstract: Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning
with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM
post-training, each offering distinct advantages. However, RLHF struggles with
interpretability and reward hacking because it relies on human judgments that
usually lack explicit criteria, whereas RLVR is limited in scope by its focus
on correctness-based verifiers. We propose Reinforcement Learning with Binary
Flexible Feedback (RLBFF), which combines the versatility of human-driven
preferences with the precision of rule-based verification, enabling reward
models to capture nuanced aspects of response quality beyond mere correctness.
RLBFF extracts principles that can be answered in a binary fashion (e.g.
accuracy of information: yes, or code readability: no) from natural language
feedback. Such principles can then be used to ground Reward Model training as
an entailment task (response satisfies or does not satisfy an arbitrary
principle). We show that Reward Models trained in this manner can outperform
Bradley-Terry models when matched for data and achieve top performance on
RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,
2025). Additionally, users can specify principles of interest at inference time
to customize the focus of our reward models, in contrast to Bradley-Terry
models. Finally, we present a fully open source recipe (including data) to
align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the
performance of o3-mini and DeepSeek R1 on general alignment benchmarks of
MT-Bench, WildBench, and Arena Hard v2 (at <5% of the inference cost).

</details>


### [153] [SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](https://arxiv.org/abs/2509.21320)
*Yizhou Wang,Chen Tang,Han Deng,Jiabei Xiao,Jiaqi Liu,Jianyu Wu,Jun Yao,Pengze Li,Encheng Su,Lintao Wang,Guohang Zhuang,Yuchen Ren,Ben Fei,Ming Hu,Xin Chen,Dongzhan Zhou,Junjun He,Xiangyu Yue,Zhenfei Yin,Jiamin Wu,Qihao Zheng,Yuhao Zhou,Huihui Xu,Chenglong Ma,Yan Lu,Wenlong Zhang,Chunfeng Song,Philip Torr,Shixiang Tang,Xinzhu Ma,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 该模型是一个基于科学文本、序列和序列-文本对的206B语料库预训练的科学推理基础模型，通过SFT、冷启动引导和强化学习进行对齐，以实现科学推理。


<details>
  <summary>Details</summary>
Motivation: 对齐自然语言和异构科学表征，实现科学推理。

Method: 在206B语料库上进行预训练，然后在40M指令上通过SFT、冷启动引导和强化学习进行对齐。

Result: 在翻译、提取、预测、分类和生成方面，与专业系统相比，该模型具有更广泛的指令覆盖、更好的跨领域泛化能力和更高的保真度。

Conclusion: 跨学科学习可以增强模型的迁移能力和下游任务的可靠性。

Abstract: We present a scientific reasoning foundation model that aligns natural
language with heterogeneous scientific representations. The model is pretrained
on a 206B-token corpus spanning scientific text, pure sequences, and
sequence-text pairs, then aligned via SFT on 40M instructions, annealed
cold-start bootstrapping to elicit long-form chain-of-thought, and
reinforcement learning with task-specific reward shaping, which instills
deliberate scientific reasoning. It supports four capability families, covering
up to 103 tasks across workflows: (i) faithful translation between text and
scientific formats, (ii) text/knowledge extraction, (iii) property prediction,
(iv) property classification, (v) unconditional and conditional sequence
generation and design. Compared with specialist systems, our approach broadens
instruction coverage, improves cross-domain generalization, and enhances
fidelity. We detail data curation and training and show that cross-discipline
learning strengthens transfer and downstream reliability. The model, instruct
tuning datasets and the evaluation code are open-sourced at
https://huggingface.co/SciReason and
https://github.com/open-sciencelab/SciReason.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [154] [The First Open-Source Framework for Learning Stability Certificate from Data](https://arxiv.org/abs/2509.20392)
*Zhe Shen*

Main category: eess.SY

TL;DR: 该研究首次发布了一个开源框架，能够直接从嘈杂的、真实的飞行数据中学习李雅普诺夫稳定性证书。


<details>
  <summary>Details</summary>
Motivation: 在2025年前，不存在能够直接从嘈杂、真实的飞行数据中学习李雅普诺夫稳定性证书的开源系统，也无法判断一个控制器是否仍然可稳定，特别是当闭环系统是完全黑箱时。

Method: 开发了一个开源框架，能够从轨迹数据中学习李雅普诺夫函数，即使在存在现实噪声干扰的情况下。该方法不只是标记异常，而是直接判断系统是否仍可证明稳定。

Result: 该方法被应用于2024年SAS严重湍流事件的公开数据，发现在飞机下降开始异常后的60秒内，无法构建李雅普诺夫函数来证明系统稳定性。这是首次将数据驱动的稳定性理论方法应用于民航客机事故。该方法在不访问控制器逻辑的情况下也能工作。

Conclusion: 该研究首次发布了一个开源框架，能够直接从嘈杂的、真实的飞行数据中学习李雅普诺夫稳定性证书，并成功应用于验证民航客机事故的系统稳定性，解决了以往无法处理黑箱系统和专有控制逻辑的难题。

Abstract: Before 2025, no open-source system existed that could learn Lyapunov
stability certificates directly from noisy, real-world flight data. No tool
could answer the critical question: is this controller still
stabilizable-especially when its closed-loop system is a total black box. We
broke that boundary. This year, we released the first-ever open-source
framework that can learn Lyapunov functions from trajectory data under
realistic, noise-corrupted conditions. Unlike statistical anomaly detectors,
our method does not merely flag deviations-it directly determines whether the
system can still be proven stable. Applied to public data from the 2024 SAS
severe turbulence incident, our method revealed that, within just 60 seconds of
the aircrafts descent becoming abnormal, no Lyapunov function could be
constructed to certify system stability. Moreover, this is the first known
data-driven stability-theoretic method ever applied to a civil airliner
accident. And our approach works with zero access to the controller logic-a
breakthrough for commercial aircraft where control laws are proprietary and
opaque. The implementation of the proposed framework is open-sourced and
available at: https://github.com/HansOersted/stability

</details>


### [155] [Adaptive Altitude Control of a Tethered Multirotor Autogyro under Varying Wind Speeds using Differential Rotor Braking](https://arxiv.org/abs/2509.20561)
*Tasnia Noboni,Tuhin Das*

Main category: eess.SY

TL;DR: 该研究提出了一种用于系留多旋翼自动倾转旋翼飞行器的自适应高度控制策略，利用风能实现高效和长时间的部署。


<details>
  <summary>Details</summary>
Motivation: 为了实现无人机的高效和长时间部署，利用风能维持飞行。

Method: 提出了一种自适应控制策略，用于估计和利用自动倾转旋翼飞行器在恒定风速下由俯仰角决定的平衡高度的二次函数系数。采用基于再生差速叶片制动的反馈控制器来调节俯仰角，并通过更高阶的动态模型进行了实现。

Result: 所提出的自适应控制器能够调节高度并保持在不同风速下的稳定飞行，并且通过跟踪最大高度表现出良好的性能。

Conclusion: 该自适应控制策略能够有效地调节高度并维持稳定飞行，在风速发生较大变化时仍能通过调整以获得更好的性能。

Abstract: A tethered multirotor autogyro can function as an unmanned aerial vehicle for
energy-efficient and prolonged deployment, as it uses the available wind energy
to sustain flight. This article presents an adaptive altitude control strategy
for such a device. At a constant wind speed, the equilibrium altitude can be
approximated by a quadratic function of the pitch angle. The proposed adaptive
control estimates the coefficients of this quadratic function. The estimates
are used for altitude control and to attain the maximum altitude (and minimum
horizontal drift) for a given wind speed. A feedback controller based on
regenerative differential rotor braking is used as the actuation to modulate
the autogyro's pitch angle. Implementation of the controller using a
control-oriented, higher-order dynamic model demonstrates the controller's
capability to regulate the altitude and maintain stable flights under varying
wind speeds. Based on the system's maximum altitude tracking performance, the
adaptive control is adjusted to improve performance under substantial changes
in wind speeds.

</details>


### [156] [Data-Driven State Observers for Measure-Preserving Systems](https://arxiv.org/abs/2509.20596)
*Wentao Tang*

Main category: eess.SY

TL;DR: 提出一种基于数据驱动的 KKL 状态观测器方法，用于离散时间非线性系统，并利用 Koopman 和 Perron-Frobenius 算子在 RKHS 上的谱分解进行设计，同时提供了误差分析和数值验证。


<details>
  <summary>Details</summary>
Motivation: 为了应对数据驱动控制策略日益增长的需求，需要开发基于学习的状态观测方法。

Method: 提出一种基于 Kazantzis-Kravaris/Luenburger (KKL) 观测器的学习方法。该方法将观测器设计转化为学习非线性内射映射及其伪逆。利用 Koopman 和 Perron-Frobenius 算子在 Sobolev 型再生核希尔伯特空间 (RKHS) 上的谱分解来构建 KKL 观测器。针对不同数据集（多轨道、单长轨道、快照）设计了相应的观测器合成算法。

Result: 理论上分析了该方法的误差界限。通过在混沌 Lorenz 系统上的数值实验，验证了该方法的有效性。

Conclusion: 所提出的数据驱动的 KKL 观测器方法能够有效地合成离散时间非线性系统的状态观测器，并且在理论和数值上都得到了验证。

Abstract: The increasing use of data-driven control strategies gives rise to the
problem of learning-based state observation. Motivated by this need, the
present work proposes a data-driven approach for the synthesis of state
observers for discrete-time nonlinear systems with measure-preserving dynamics.
To this end, Kazantzis-Kravaris/Luenburger (KKL) observers are shown to be
well-defined, where the observer design boils down to determining a nonlinear
injective mapping of states and its pseudo-inverse. For its learning-based
construction, the KKL observer is related to the Koopman and Perron-Frobenius
operators, defined on a Sobolev-type reproducing kernel Hilbert space (RKHS) on
which they are shown to be normal operators and thus have a spectral
resolution. Hence, observer synthesis algorithms, based on kernel
interpolation/regression routines for the desired injective mapping in the
observer and its pseudo-inverse, have been proposed in various settings of
available dataset -- (i) many orbits, (ii) single long orbit, and (iii)
snapshots. Theoretical error analyses are provided, and numerical studies on a
chaotic Lorenz system are demonstrated.

</details>


### [157] [Frequency Domain Stability Conditions for Hybrid AC/DC Systems](https://arxiv.org/abs/2509.20649)
*Dahlia Saba,Dominic Groß*

Main category: eess.SY

TL;DR: 文章提出了混合交流/直流电力系统的紧凑频域表示和相关稳定性条件，该条件可分为单个母线动力学条件和每个直流网络条件。


<details>
  <summary>Details</summary>
Motivation: 研究混合交流/直流电力系统（结合交流和直流输电、常规机组发电和转换器接口发电）的小信号频率和直流电压稳定性。

Method: 提出了混合交流/直流电力系统的紧凑频域表示和相关稳定性条件，该条件可分为单个母线动力学条件和每个直流网络条件。还开发并验证了一种用于多机系统的降阶阻尼绕组模型。

Result: 系统级条件表明，只要转换器对网络的频率响应足够相干，混合交流/直流系统就具有拓扑结构无关的稳定性。

Conclusion: 该文为分析和确保混合交流/直流电力系统的稳定性提供了新的方法和模型。

Abstract: In this article, we investigate small-signal frequency and DC voltage
stability of hybrid AC/DC power systems that combine AC and DC transmission,
conventional machine- based generation, and converter-interfaced generation.
The main contributions of this work are a compact frequency domain
representation of hybrid AC/DC systems and associated stability conditions that
can be divided into conditions on the individual bus dynamics and conditions on
each DC network. The bus- level conditions apply to a wide range of
technologies (e.g., synchronous generators, synchronous condensers,
grid-forming renewables and energy storage). Moreover, the system-level
conditions establish that hybrid AC/DC systems combining a wide range of
devices are stable independently of the network topology provided that the
frequency response of converters on each DC network is sufficiently coherent
relative to the network coupling strength. Additionally, we develop and
validate a novel reduced- order damper winding model for multi-machine systems.

</details>


### [158] [Parasitic actuation delay limits the minimum employable time headway in connected and autonomous vehicles](https://arxiv.org/abs/2509.20722)
*Guoqi Ma,Prabhakar R. Pagilla,Swaroop Darbha*

Main category: eess.SY

TL;DR: 该论文研究了自适应巡航控制（ACC）、协同自适应巡航控制（CACC）和下一代CACC（CACC+）系统在存在执行器延迟时，为确保车辆编队内部稳定性和队列稳定性而需要满足的最小时间车头时距。


<details>
  <summary>Details</summary>
Motivation: 介绍ACC、CACC和CACC+系统在车辆编队中的应用，强调了执行器延迟（如延迟、滞后）对车辆移动性和安全性的负面影响，并指出了在已知执行器延迟界限的情况下，需要同时解决内部稳定性和队列稳定性问题。

Method: 推导了ACC、CACC和CACC+系统在考虑执行器延迟的情况下，保证队列稳定性的最小时间车头时距。利用Pontryagin交错定理分析了在队列稳定性条件中包含内部稳定性的情况。

Result: 提供了ACC、CACC和CACC+系统的最小可用时间车头时距，并通过数值结果验证了理论推导的有效性。

Conclusion: 在执行器延迟存在的情况下，通过确保内部稳定性和队列稳定性，可以为ACC、CACC和CACC+系统确定并应用最小时间车头时距，从而提高车辆编队的稳定性和安全性。

Abstract: Adaptive andcooperative adaptive cruise control (ACC and CACC) and next
generation CACC (CACC+) systems usually employ a constant time headway policy
(CTHP) for platooning of connected and autonomous vehicles (CAVs). In ACC, the
ego vehicle uses onboard sensors to measure the position and velocity of the
predecessor vehicle to maintain a desired spacing. The CACC and CACC+systems
use additional information, such as acceleration(s) communicated through
vehicle-to-vehicle (V2V) communication of the predecessor vehicle(s); these
systems have been shown to result in improved spacing performance, throughput,
and safety over ACC. Parasitic dynamics are generally difficult to model and
the parasitic parameters (delay, lag, etc.) are difficult to obtain. Parasitic
actuation delays can have deleterious effects and impose limits on the mobility
and safety of CAVs. It is reasonable to assume that the bounds on parasitic
actuation delays are known a priori. For CAVs, we need to address both internal
stability and string stability in the presence of parasitic actuation delays.
This requires robustness of string and internal stability for all values of
parasitic actuation delays that are within the specified upper bound. In this
paper, we provide the minimum employable time headway for ACC, CACC, and CACC+
(`r' predecessors look-ahead), respectively. The inclusion of the internal
stability in the string stability condition is analyzed based on Pontryagin's
interlacing theorem for time delay systems. We provide comparative numerical
results to corroborate the achieved theoretical results.

</details>


### [159] [Revealing Chaotic Dependence and Degree-Structure Mechanisms in Optimal Pinning Control of Complex Networks](https://arxiv.org/abs/2509.20788)
*Qingyang Liu,Tianlong Fan,Liming Pan,Linyuan Lv*

Main category: eess.SY

TL;DR: 通过统计物理的度数均值场近似，我们分析了度数分布对同步性能的影响，并推导出了最优控制节点集和线性时间复杂度的算法。最优配置对节点数量的选取表现出混沌依赖性，这挑战了传统启发式方法。实验证明，该方法优于其他基于中心度的基线方法。我们还量化了度数分布特征如何影响可实现的同步性和最优节点集的形式。该研究将度数异质性与谱可控性联系起来，为选择最优控制节点提供了机制洞察和设计规则。


<details>
  <summary>Details</summary>
Motivation: 在复杂网络科学中，通过图钉控制实现同步的驱动节点最优集识别是一个基本挑战，受计算复杂性和通用理论缺乏的限制。

Method: 利用统计物理中的度数基准平均场（退火）近似，我们分析了结构度数分布如何系统地控制同步性能，并推导出了全局最优图钉集的解析表征和具有线性复杂度的构造性算法（主要由度数排序决定，O(N+M)）。

Result: 最优配置表现出对其基数的混沌依赖性——一种不连续的敏感性——其中添加单个节点可以触发节点组成和控制有效性的突然变化。这种结构转变从根本上挑战了假设性能随预算单调增加的传统启发式方法。在合成网络和经验网络上的系统实验证实，所提出的方法始终优于基于度数、中介中心度和中心度的基线。此外，我们量化了关键的度数分布特征——低度数饱和度、高度数截止和幂律指数——如何控制可实现的同步性并形成最优集合的形式。

Conclusion: 这些结果提供了对度数异质性如何影响网络可控性的系统理解。我们的工作在度数异质性和谱可控性之间建立了统一的联系，为在各种复杂系统中选择最优驱动节点提供了机械见解和实际设计规则。

Abstract: Identifying an optimal set of driver nodes to achieve synchronization via
pinning control is a fundamental challenge in complex network science, limited
by computational intractability and the lack of general theory. Here,
leveraging a degree-based mean-field (annealed) approximation from statistical
physics, we analytically reveal how the structural degree distribution
systematically governs synchronization performance, and derive an analytic
characterization of the globally optimal pinning set and constructive
algorithms with linear complexity (dominated by degree sorting, O(N+M). The
optimal configuration exhibits a chaotic dependence--a discontinuous
sensitivity--on its cardinality, whereby adding a single node can trigger
abrupt changes in node composition and control effectiveness. This structural
transition fundamentally challenges traditional heuristics that assume
monotonic performance gains with budget. Systematic experiments on synthetic
and empirical networks confirm that the proposed approach consistently
outperforms degree-, betweenness-, and other centrality-based baselines.
Furthermore, we quantify how key degree-distribution features--low-degree
saturation, high-degree cutoff, and the power-law exponent--govern achievable
synchronizability and shape the form of optimal sets. These results offer a
systematic understanding of how degree heterogeneity shapes the network
controllability. Our work establishes a unified link between degree
heterogeneity and spectral controllability, offering both mechanistic insights
and practical design rules for optimal driver-node selection in diverse complex
systems.

</details>


### [160] [Dual-Band Flexible Endfire Filtering Antenna With Conformal Capability for Emergency Communication Applications](https://arxiv.org/abs/2509.20892)
*Fan Qin,Runkai Song,Chao Gu,Wenchi Cheng,Steven Gao*

Main category: eess.SY

TL;DR: 该论文提出了一种单层、柔性、可变形的滤波端射天线，可在两个频段工作。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展应急通信系统对集成化、小型化通信设备的需求，提出一种新型柔性可变形滤波端射天线。

Method: 该天线采用双频段折叠偶极子（FD）设计，一个FD作为另一个的反射器，并增加了额外的反射器以实现双频段端射辐射。通过引入寄生条产生电耦合和磁耦合，实现滤波性能。

Result: 天线原型在1.37-1.45 GHz和1.89-2.07 GHz两个频段工作，在不同弯曲半径下实现了超过11 dB的带外辐射抑制。

Conclusion: 该设计实现了双频段端射滤波辐射、柔性变形能力和低剖面等优点，适用于应急通信系统。

Abstract: In this letter, a single-layer dual-band flexible conformal filtering endfire
antenna is presented. The proposed antenna is based on two co-designed folded
dipoles (FDs) working at two frequencies, where the lower-frequency FD acts as
a reflector for the higher-frequency one. Then, by devising an additional
reflector for lower-frequency FD, dual-band endfire radiation is realized.
Parasitic strips are deliberately introduced around the FDs to generate
electric coupling and magnetic coupling in the two operating bands, resulting
in significant filtering performance with four radiation nulls. With flexible
structure and single-layer configuration, the antenna design exhibits flexible
conformability with cylindrical surfaces of diverse diameters, thereby enabling
seamless integration into scalable emergency communication systems. To verify
our design concept, an antenna prototype is fabricated and measured. The
measured working frequency ranges from 1.37 to 1.45 GHz and 1.89 to 2.07 GHz.
Out-of-band radiation suppression more than 11 dB is achieved under different
bending radii. The proposed design offers several advantages including
dual-band endfire filtering radiation, flexible conformability and low-profile.

</details>


### [161] [On the convergence of a numerical scheme for a boundary controlled 1D linear parabolic PIDE](https://arxiv.org/abs/2509.20960)
*Soham Chatterjee,Vivek Natarajan*

Main category: eess.SY

TL;DR: 我们提出了一种 1D 偏微分方程 (PIDE) 的半离散近似方法，并证明了其收敛性，这对于 PIDE 的零可控性证明很有用。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决一个包含非局部积分项的 1D 偏微分方程 (PIDE)，该方程的控制输入应用于其边界之一。

Method: 通过将空间区间划分为 n+1 个子区间，并分别使用有限差分近似空间导数和黎曼和近似积分项，我们推导出了 PIDE 的 n 阶半离散近似，这是一个关于时间变量的 n 阶常微分方程 (ODE)。

Result: 我们证明了半离散近似的解在 n 趋于无穷时收敛到 PIDE 的解，并通过数值例子说明了收敛结果。

Conclusion: 该研究提出的半离散近似方法及其收敛性证明，为研究该 PIDE 的零可控性奠定了基础。

Abstract: We consider an 1D partial integro-differential equation (PIDE) comprising of
an 1D parabolic partial differential equation (PDE) and a nonlocal integral
term. The control input is applied on one of the boundaries of the PIDE.
Partitioning the spatial interval into $n+1$ subintervals and approximating the
spatial derivatives and the integral term with their finite-difference
approximations and Riemann sum, respectively, we derive an $n^{\rm th}$-order
semi-discrete approximation of the PIDE. The $n^{\rm th}$-order semi-discrete
approximation of the PIDE is an $n^{\rm th}$-order ordinary differential
equation (ODE) in time. We establish some of its salient properties and using
them prove that the solution of the semi-discrete approximation converges to
the solution of the PIDE as $n\to\infty$. We illustrate our convergence results
using numerical examples. The results in this work are useful for establishing
the null controllability of the PIDE considered.

</details>


### [162] [The Use of the Simplex Architecture to Enhance Safety in Deep-Learning-Powered Autonomous Systems](https://arxiv.org/abs/2509.21014)
*Federico Nesti,Niko Salamini,Mauro Marinoni,Giorgio Maria Cicero,Gabriele Serra,Alessandro Biondi,Giorgio Buttazzo*

Main category: eess.SY

TL;DR: 神经网络在自主系统中存在安全、安全性和可预测性问题，本文提出了一种利用隔离执行域和安全监控器来解决这些问题的软件架构。


<details>
  <summary>Details</summary>
Motivation: 神经网络在自主系统中性能优越，但存在易受攻击、行为不可预测等问题，且现有推理加速框架依赖于复杂的操作系统，增加了安全风险。

Method: 提出了一种软件架构，包含两个隔离的执行域：一个运行不可信的神经网络，另一个运行安全关键功能。两个域由一个实时 hypervisor 隔离，并能进行通信。该架构包含一个安全监控器，可在检测到不可信行为时切换到更简单的备份模块。

Result: 通过在 Furuta 摆和 rover 控制系统上的实验，验证了该架构的容错机制能够有效防止由于学习组件引起的故障。

Conclusion: 所提出的架构通过隔离执行域和安全监控器，能够提高基于学习的自主系统的安全性、安全性和可预测性，并通过实验证明了其有效性。

Abstract: Recently, the outstanding performance reached by neural networks in many
tasks has led to their deployment in autonomous systems, such as robots and
vehicles. However, neural networks are not yet trustworthy, being prone to
different types of misbehavior, such as anomalous samples, distribution shifts,
adversarial attacks, and other threats. Furthermore, frameworks for
accelerating the inference of neural networks typically run on rich operating
systems that are less predictable in terms of timing behavior and present
larger surfaces for cyber-attacks.
  To address these issues, this paper presents a software architecture for
enhancing safety, security, and predictability levels of learning-based
autonomous systems. It leverages two isolated execution domains, one dedicated
to the execution of neural networks under a rich operating system, which is
deemed not trustworthy, and one responsible for running safety-critical
functions, possibly under a different operating system capable of handling
real-time constraints.
  Both domains are hosted on the same computing platform and isolated through a
type-1 real-time hypervisor enabling fast and predictable inter-domain
communication to exchange real-time data. The two domains cooperate to provide
a fail-safe mechanism based on a safety monitor, which oversees the state of
the system and switches to a simpler but safer backup module, hosted in the
safety-critical domain, whenever its behavior is considered untrustworthy.
  The effectiveness of the proposed architecture is illustrated by a set of
experiments performed on two control systems: a Furuta pendulum and a rover.
The results confirm the utility of the fall-back mechanism in preventing faults
due to the learning component.

</details>


### [163] [Direct Continuous-Time LPV System Identification of Li-ion Batteries via L1-Regularized Least Squares](https://arxiv.org/abs/2509.21110)
*Yang Wang,Riccardo M. G. Ferrari*

Main category: eess.SY

TL;DR: 本研究提出一种连续时间线性参数变量（CT-LPV）系统辨识方法，用于辨识随荷电状态（SOC）变化的锂离子电池参数及开路电压（OCV）-SOC映射关系，解决了参数时变和OCV-SOC非线性依赖的挑战。


<details>
  <summary>Details</summary>
Motivation: 准确辨识锂离子电池参数对于电池状态估算和性能管理至关重要，但SOC变化导致的参数变动以及OCV-SOC关系的非线性给辨识带来了困难。

Method: 采用CT-LPV系统辨识方法，利用三次B样条模拟参数变化，并通过状态变量滤波器估计信号导数，以实现CT-LPV辨识。通过求解L1正则化最小二乘问题，联合辨识电池参数和OCV-SOC映射。

Result: 该方法在模拟电池和实际数据集上进行了数值实验，结果表明其在电池辨识方面是有效的。

Conclusion: 所开发的CT-LPV系统辨识方法能够有效处理SOC依赖的电池参数变化和OCV-SOC非线性关系，并在电池辨识任务中展现出优于传统基于递M最小二乘（RLS）方法的性能。

Abstract: Accurate identification of lithium-ion battery parameters is essential for
estimating battery states and managing performance. However, the variation of
battery parameters over the state of charge (SOC) and the nonlinear dependence
of the open-circuit voltage (OCV) on the SOC complicate the identification
process. In this work, we develop a continuous-time LPV system identification
approach to identify the SOC-dependent battery parameters and the OCV-SOC
mapping. We model parameter variations using cubic B-splines to capture the
piecewise nonlinearity of the variations and estimate signal derivatives via
state variable filters, facilitating CT-LPV identification. Battery parameters
and the OCV-SOC mapping are jointly identified by solving L1-regularized least
squares problems. Numerical experiments on a simulated battery and real-life
data demonstrate the effectiveness of the developed method in battery
identification, presenting improved performance compared to conventional
RLS-based methods.

</details>


### [164] [Continuous-Time System Identification and OCV Reconstruction of Li-ion Batteries via Regularized Least Squares](https://arxiv.org/abs/2509.21116)
*Yang Wang,Riccardo M. G. Ferrari,Michel Verhaegen*

Main category: eess.SY

TL;DR: 本文提出一种连续时间方法，可直接从采样数据中估算锂离子电池参数，解决了现有离散时间方法在参数估算和快慢动态问题上的局限性，并能在无需离线OCV测试的情况下联合估算OCV和SOC关系，通过Cubic B-spline模型和秩与L1正则化最小二乘问题实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 现有离散时间方法在锂离子电池参数估算中存在局限，无法有效解决电池的快慢动态问题，并且需要进行离线OCV测试。因此，需要一种能够直接从采样数据中进行参数估算，并联合OCV-SOC关系识别的连续时间方法。

Method: 本文提出一种连续时间方法，将OCV-SOC曲线建模为三次B样条，并联合识别电池参数和OCV-SOC关系。通过求解秩与L1正则化最小二乘问题，直接从电池动态数据中进行估算，避免了离散化误差。

Result: 所提出的连续时间方法能够直接从采样数据中估算电池参数，并联合识别OCV-SOC关系，无需离线OCV测试。模拟和实际数据验证了该方法的有效性，实现了更精确的参数识别。

Conclusion: 本文提出的连续时间方法能够有效克服现有离散时间方法的局限性，实现锂离子电池参数和OCV-SOC关系的精确联合识别，为电池管理和预测提供了更优的解决方案。

Abstract: Accurate identification of lithium-ion (Li-ion) battery parameters is
essential for managing and predicting battery behavior. However, existing
discrete-time methods hinder the estimation of physical parameters and face the
fast-slow dynamics problem presented in the battery. In this paper, we
developed a continuous-time approach that enables the estimation of battery
parameters directly from sampled data. This method avoids discretization errors
in converting continuous-time models into discrete-time ones, achieving more
accurate identification. In addition, we jointly identify the open-circuit
voltage (OCV) and the state of charge (SOC) relation of the battery without
utilizing offline OCV tests. By modeling the OCV-SOC curve as a cubic B-spline,
we achieve a high-fidelity representation of the OCV curve, facilitating its
estimation. Through solving a rank and L1 regularized least squares problem, we
jointly identify battery parameters and the OCV-SOC relation from the battery's
dynamic data. Simulated and real-life data demonstrate the effectiveness of the
developed method.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [165] [Explicit and Effectively Symmetric Schemes for Neural SDEs](https://arxiv.org/abs/2509.20599)
*Daniil Shmelev,Cristopher Salvi*

Main category: cs.LG

TL;DR: 提出了一种新型的、稳定且近似可逆的Runge-Kutta方案，用于解决神经网络随机微分方程（SDEs）的训练问题，克服了现有方法的不足，实现了内存高效且梯度准确的训练。


<details>
  <summary>Details</summary>
Motivation: 现有反向传播于（神经）SDE求解器的方法存在弊端：离散化-优化方法梯度准确但内存开销大；优化-离散化方法内存开销小但评估慢且梯度近似误差大。代数可逆求解器虽然有望兼顾内存效率和梯度精度，但现有方法（如可逆Heun方案）在复杂模型和大步长下不稳定。因此，需要新的解决方案。

Method: 提出了一类新型的显式有效对称（EES）Runge-Kutta方案，该方案在保持可逆求解器优点的同时，克服了其不稳定性问题，能够实现内存高效的训练，并且对步长或模型复杂度没有严格限制。

Result: 通过数值实验证明了所提出的EES方案在稳定性和可靠性方面优于现有方法，为可扩展且准确的神经网络SDE训练奠定了实际基础。

Conclusion: 所提出的EES方案是一类稳定且近似可逆的Runge-Kutta方案，能够有效解决神经网络SDE训练中的内存和精度问题，是未来相关研究和应用的一个有前景的方向。

Abstract: Backpropagation through (neural) SDE solvers is traditionally approached in
two ways: discretise-then-optimise, which offers accurate gradients but incurs
prohibitive memory costs due to storing the full computational graph (even when
mitigated by checkpointing); and optimise-then-discretise, which achieves
constant memory cost by solving an auxiliary backward SDE, but suffers from
slower evaluation and gradient approximation errors. Algebraically reversible
solvers promise both memory efficiency and gradient accuracy, yet existing
methods such as the Reversible Heun scheme are often unstable under complex
models and large step sizes. We address these limitations by introducing a
novel class of stable, near-reversible Runge--Kutta schemes for neural SDEs.
These Explicit and Effectively Symmetric (EES) schemes retain the benefits of
reversible solvers while overcoming their instability, enabling
memory-efficient training without severe restrictions on step size or model
complexity. Through numerical experiments, we demonstrate the superior
stability and reliability of our schemes, establishing them as a practical
foundation for scalable and accurate training of neural SDEs.

</details>


### [166] [Physics of Learning: A Lagrangian perspective to different learning paradigms](https://arxiv.org/abs/2509.21049)
*Siyuan Guo,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 本研究提出了一个基于物理学中


<details>
  <summary>Details</summary>
Motivation: 为了构建一个高效的学习系统，该系统能够在最少的时间内处理信息，即用最少的观测次数达到期望的误差阈值。

Method: 该研究基于物理学中的最小作用量原理，从第一性原理（即学习拉格朗日量）推导了经典学习算法、强化学习中的贝尔曼最优方程以及生成模型中的 Adam 优化器。研究者假设学习是在拉格朗日量中寻找平稳路径，并且学习算法可以通过寻找平稳轨迹来推导。

Result: 从第一性原理推导了经典学习算法、贝尔曼最优方程和 Adam 优化器。

Conclusion: 学习是在拉格朗日量中寻找平稳路径，学习算法可以通过寻找平稳轨迹来推导。

Abstract: We study the problem of building an efficient learning system. Efficient
learning processes information in the least time, i.e., building a system that
reaches a desired error threshold with the least number of observations.
Building upon least action principles from physics, we derive classic learning
algorithms, Bellman's optimality equation in reinforcement learning, and the
Adam optimizer in generative models from first principles, i.e., the Learning
$\textit{Lagrangian}$. We postulate that learning searches for stationary paths
in the Lagrangian, and learning algorithms are derivable by seeking the
stationary trajectories.

</details>


### [167] [Latent Twins](https://arxiv.org/abs/2509.20615)
*Matthias Chung,Deepanshu Verma,Max Collins,Amit N. Subrahmanya,Varuni Katti Sastry,Vishwas Rao*

Main category: cs.LG

TL;DR: Latent Twins是一个统一的数学框架，通过在潜在空间中创建底层方程的隐藏代理，将表示学习和算法求解方法结合起来，并展示了其在常微分方程、偏微分方程和实际地球物理数据上的应用。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习在数学和计算框架方面取得了重大进展，但表示学习和算法求解方法通常是独立发展的。

Method: 提出Latent Twins框架，在潜在空间中为底层方程创建一个隐藏的代理，将建模、反演、模型降阶和算子逼近统一在一个原则下。

Result: 证明了Latent Twins在常微分方程和偏微分方程上的基本逼近性质，并在三个代表性场景中进行了演示：常微分方程、浅水方程的偏微分方程基准以及地球物理再分析数据集。

Conclusion: Latent Twins为求解算子提供了一个紧凑、可解释的代理，可以单次评估任意时间间隔，并与科学工作流兼容，为跨学科的数据驱动表示学习和经典科学建模提供了可扩展、有理论依据的代理。

Abstract: Over the past decade, scientific machine learning has transformed the
development of mathematical and computational frameworks for analyzing,
modeling, and predicting complex systems. From inverse problems to numerical
PDEs, dynamical systems, and model reduction, these advances have pushed the
boundaries of what can be simulated. Yet they have often progressed in
parallel, with representation learning and algorithmic solution methods
evolving largely as separate pipelines. With \emph{Latent Twins}, we propose a
unifying mathematical framework that creates a hidden surrogate in latent space
for the underlying equations. Whereas digital twins mirror physical systems in
the digital world, Latent Twins mirror mathematical systems in a learned latent
space governed by operators. Through this lens, classical modeling, inversion,
model reduction, and operator approximation all emerge as special cases of a
single principle. We establish the fundamental approximation properties of
Latent Twins for both ODEs and PDEs and demonstrate the framework across three
representative settings: (i) canonical ODEs, capturing diverse dynamical
regimes; (ii) a PDE benchmark using the shallow-water equations, contrasting
Latent Twin simulations with DeepONet and forecasts with a 4D-Var baseline; and
(iii) a challenging real-data geopotential reanalysis dataset, reconstructing
and forecasting from sparse, noisy observations. Latent Twins provide a
compact, interpretable surrogate for solution operators that evaluate across
arbitrary time gaps in a single-shot, while remaining compatible with
scientific pipelines such as assimilation, control, and uncertainty
quantification. Looking forward, this framework offers scalable,
theory-grounded surrogates that bridge data-driven representation learning and
classical scientific modeling across disciplines.

</details>


### [168] [Learning Ising Models under Hard Constraints using One Sample](https://arxiv.org/abs/2509.20993)
*Rohan Chauhan,Ioannis Panageas*

Main category: cs.LG

TL;DR: 给定一个单样本，我们设计了一个估计器，用于在几乎 O(n) 时间内估计 n 维截断伊辛模型的逆温度参数 β，该估计器与真实参数 β* 具有 O(Δ^3/√n) 的一致性。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是解决使用单个样本估计 n 维截断伊辛模型的逆温度参数 β 的问题。

Method: 本文提出了一种基于伪似然最大化（pseudolikelihood maximization）的估计方法，并结合了近期在截断伊辛模型（truncated Ising model）和伪似然分析（pseudolikelihood analysis）方面的工作。

Result: 该方法设计了一个估计器 $\hat{\beta}$，能够在近乎 O(n) 的时间内，在给定单样本、逆参数 $\beta^*$、边际度数有界的图 G 和 k-SAT 公式可满足赋值集 S 的情况下，实现与真实参数 $\beta^*$ 的 $O(\Delta^3/\sqrt{n})$ 一致性。

Conclusion: 本文提出的方法在近乎线性时间复杂度内，为 n 维截断伊辛模型提供了一个具有良好一致性保证的逆温度参数估计器。

Abstract: We consider the problem of estimating inverse temperature parameter $\beta$
of an $n$-dimensional truncated Ising model using a single sample. Given a
graph $G = (V,E)$ with $n$ vertices, a truncated Ising model is a probability
distribution over the $n$-dimensional hypercube $\{-1,1\}^n$ where each
configuration $\mathbf{\sigma}$ is constrained to lie in a truncation set $S
\subseteq \{-1,1\}^n$ and has probability $\Pr(\mathbf{\sigma}) \propto
\exp(\beta\mathbf{\sigma}^\top A\mathbf{\sigma})$ with $A$ being the adjacency
matrix of $G$. We adopt the recent setting of [Galanis et al. SODA'24], where
the truncation set $S$ can be expressed as the set of satisfying assignments of
a $k$-SAT formula. Given a single sample $\mathbf{\sigma}$ from a truncated
Ising model, with inverse parameter $\beta^*$, underlying graph $G$ of bounded
degree $\Delta$ and $S$ being expressed as the set of satisfying assignments of
a $k$-SAT formula, we design in nearly $O(n)$ time an estimator $\hat{\beta}$
that is $O(\Delta^3/\sqrt{n})$-consistent with the true parameter $\beta^*$ for
$k \gtrsim \log(d^2k)\Delta^3.$
  Our estimator is based on the maximization of the pseudolikelihood, a notion
that has received extensive analysis for various probabilistic models without
[Chatterjee, Annals of Statistics '07] or with truncation [Galanis et al. SODA
'24]. Our approach generalizes recent techniques from [Daskalakis et al. STOC
'19, Galanis et al. SODA '24], to confront the more challenging setting of the
truncated Ising model.

</details>


### [169] [AbideGym: Turning Static RL Worlds into Adaptive Challenges](https://arxiv.org/abs/2509.21234)
*Abi Aryan,Zac Liu,Aaron Childress*

Main category: cs.LG

TL;DR: AbideGym是一个动态MiniGrid包装器，通过引入智能体感知扰动和可扩展的复杂性来强制执行单集适应，以解决强化学习智能体策略脆弱的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体通常会形成脆弱的策略，在动态变化时会失败，而静态基准测试会加剧这一问题。

Method: AbideGym通过引入智能体感知扰动和可扩展的复杂性来强制执行单集适应。

Result: AbideGym暴露了静态策略的弱点并增强了策略的弹性。

Conclusion: AbideGym提供了一个模块化、可重现的评估框架，用于推进课程学习、持续学习和鲁棒泛化方面的研究。

Abstract: Agents trained with reinforcement learning often develop brittle policies
that fail when dynamics shift, a problem amplified by static benchmarks.
AbideGym, a dynamic MiniGrid wrapper, introduces agent-aware perturbations and
scalable complexity to enforce intra-episode adaptation. By exposing weaknesses
in static policies and promoting resilience, AbideGym provides a modular,
reproducible evaluation framework for advancing research in curriculum
learning, continual learning, and robust generalization.

</details>


### [170] [A Theory of Multi-Agent Generative Flow Networks](https://arxiv.org/abs/2509.20408)
*Leo Maxime Brunswic,Haozhi Wang,Shuang Luo,Jianye Hao,Amir Rasouli,Yinchuan Li*

Main category: cs.LG

TL;DR: 本文提出了多智能体生成流网络（MA-GFlowNets）的理论框架，并提出了四种相关算法，在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的生成流网络（GFlowNets）缺乏适用于多智能体协作生成对象的理论框架。

Method: 提出了MA-GFlowNets的理论框架，并设计了集中式流网络、独立流网络、联合流网络及其条件版本四种算法。联合流训练基于局部-全局原则，允许将多个局部GFN训练成一个全局GFN。

Result: 提出的框架在生成具有与奖励函数成比例概率的对象方面，优于强化学习和基于MCMC的方法。

Conclusion: MA-GFlowNets提供了一个理论框架，能够让多个智能体通过联合动作协同生成对象，并在实验中展现出优越性。

Abstract: Generative flow networks utilize a flow-matching loss to learn a stochastic
policy for generating objects from a sequence of actions, such that the
probability of generating a pattern can be proportional to the corresponding
given reward. However, a theoretical framework for multi-agent generative flow
networks (MA-GFlowNets) has not yet been proposed. In this paper, we propose
the theory framework of MA-GFlowNets, which can be applied to multiple agents
to generate objects collaboratively through a series of joint actions. We
further propose four algorithms: a centralized flow network for centralized
training of MA-GFlowNets, an independent flow network for decentralized
execution, a joint flow network for achieving centralized training with
decentralized execution, and its updated conditional version. Joint Flow
training is based on a local-global principle allowing to train a collection of
(local) GFN as a unique (global) GFN. This principle provides a loss of
reasonable complexity and allows to leverage usual results on GFN to provide
theoretical guarantees that the independent policies generate samples with
probability proportional to the reward function. Experimental results
demonstrate the superiority of the proposed framework compared to reinforcement
learning and MCMC-based methods.

</details>


### [171] [A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm](https://arxiv.org/abs/2509.20511)
*Oscar Leong,Yann Traonmilin*

Main category: cs.LG

TL;DR: 基于扩散模型的确定性算法可用于高维信号恢复，并提供收敛率。


<details>
  <summary>Details</summary>
Motivation: 在逆问题中，从损坏的测量中恢复高维信号是一个核心挑战。虽然生成扩散模型在提供数据驱动先验方面取得了显著的经验成功，但严格的恢复保证仍然有限。本研究旨在为逆问题的确定性扩散算法开发一个理论框架。

Method: 本文提出了一种确定性扩散算法的理论分析框架，该算法是对Kadkhodaie & Simoncelli提出的随机算法的确定性版本。通过将噪声卷积得分解释为低维模型集上的时变投影，并将之前的扩散先验算法解释为具有时变投影的广义投影梯度下降方法，可以推导出收敛速度。当感知矩阵满足模型集上的受限等距性质时，可以得到量化的收敛率。

Result: 在统一分布和低秩高斯混合模型上应用该框架。在后者的情况下，尽管底层模型集是非凸的，但仍能建立全局收敛性保证。

Conclusion: 本研究为基于扩散模型的逆问题算法提供了一个理论基础，并为信号恢复提供了量化的收敛保证。

Abstract: Recovering high-dimensional signals from corrupted measurements is a central
challenge in inverse problems. Recent advances in generative diffusion models
have shown remarkable empirical success in providing strong data-driven priors,
but rigorous recovery guarantees remain limited. In this work, we develop a
theoretical framework for analyzing deterministic diffusion-based algorithms
for inverse problems, focusing on a deterministic version of the algorithm
proposed by Kadkhodaie \& Simoncelli \cite{kadkhodaie2021stochastic}. First, we
show that when the underlying data distribution concentrates on a
low-dimensional model set, the associated noise-convolved scores can be
interpreted as time-varying projections onto such a set. This leads to
interpreting previous algorithms using diffusion priors for inverse problems as
generalized projected gradient descent methods with varying projections. When
the sensing matrix satisfies a restricted isometry property over the model set,
we can derive quantitative convergence rates that depend explicitly on the
noise schedule. We apply our framework to two instructive data distributions:
uniform distributions over low-dimensional compact, convex sets and low-rank
Gaussian mixture models. In the latter setting, we can establish global
convergence guarantees despite the nonconvexity of the underlying model set.

</details>


### [172] [Guiding Application Users via Estimation of Computational Resources for Massively Parallel Chemistry Computations](https://arxiv.org/abs/2509.20667)
*Tanzila Tabassum,Omer Subasi,Ajay Panyala,Epiya Ebiapia,Gerald Baumgartner,Erdal Mutlu,P.,Sadayappan,Karol Kowalski*

Main category: cs.LG

TL;DR: 通过预测大规模并行化学计算（如耦合簇方法）的资源需求（成本），例如执行时间和节点使用量，来指导用户选择最优的超算运行参数，从而节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助用户在昂贵的超算实验前，预测和优化大规模并行化学计算的资源消耗。

Method: 开发并评估了基于梯度提升（GB）和主动学习的机器学习（ML）策略，用于预测化学计算（CCSD）的执行时间和最小化节点小时数。

Result: 梯度提升模型在预测CCSD迭代执行时间方面，在Aurora上的MAPE为0.023，在Frontier上的MAPE为0.073。主动学习在仅收集约450个实验数据点的情况下，实现了约0.2的MAPE。

Conclusion: 机器学习，特别是梯度提升和主动学习，能够有效预测和优化大规模并行化学计算的资源使用，为用户提供有价值的指导。

Abstract: In this work, we develop machine learning (ML) based strategies to predict
resources (costs) required for massively parallel chemistry computations, such
as coupled-cluster methods, to guide application users before they commit to
running expensive experiments on a supercomputer. By predicting application
execution time, we determine the optimal runtime parameter values such as
number of nodes and tile sizes. Two key questions of interest to users are
addressed. The first is the shortest-time question, where the user is
interested in knowing the parameter configurations (number of nodes and tile
sizes) to achieve the shortest execution time for a given problem size and a
target supercomputer. The second is the cheapest-run question in which the user
is interested in minimizing resource usage, i.e., finding the number of nodes
and tile size that minimizes the number of node-hours for a given problem size.
  We evaluate a rich family of ML models and strategies, developed based on the
collections of runtime parameter values for the CCSD (Coupled Cluster with
Singles and Doubles) application executed on the Department of Energy (DOE)
Frontier and Aurora supercomputers. Our experiments show that when predicting
the total execution time of a CCSD iteration, a Gradient Boosting (GB) ML model
achieves a Mean Absolute Percentage Error (MAPE) of 0.023 and 0.073 for Aurora
and Frontier, respectively. In the case where it is expensive to run
experiments just to collect data points, we show that active learning can
achieve a MAPE of about 0.2 with just around 450 experiments collected from
Aurora and Frontier.

</details>


### [173] [PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models](https://arxiv.org/abs/2509.20570)
*Mingze Yuan,Pengfei Jin,Na Li,Quanzheng Li*

Main category: cs.LG

TL;DR: 物理约束被视为奖励信号，通过PIRF方法优化，提高了科学生成模型的物理准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在科学领域生成能力强，但常产生违反物理定律的输出。现有方法依赖于后验采样，存在误差、训练不稳定和推理效率低等问题。

Method: 提出将物理约束视为稀疏奖励优化问题，并引入物理信息奖励微调（PIRF）方法，直接反向传播轨迹奖励梯度，并采用分层截断反向传播和基于权重的正则化策略。

Result: 在五个偏微分方程基准测试中，PIRF在高效采样下始终实现了优越的物理约束执行能力。

Conclusion: 奖励微调方法有潜力推动科学生成模型的发展。

Abstract: Diffusion models have demonstrated strong generative capabilities across
scientific domains, but often produce outputs that violate physical laws. We
propose a new perspective by framing physics-informed generation as a sparse
reward optimization problem, where adherence to physical constraints is treated
as a reward signal. This formulation unifies prior approaches under a
reward-based paradigm and reveals a shared bottleneck: reliance on diffusion
posterior sampling (DPS)-style value function approximations, which introduce
non-negligible errors and lead to training instability and inference
inefficiency. To overcome this, we introduce Physics-Informed Reward
Fine-tuning (PIRF), a method that bypasses value approximation by computing
trajectory-level rewards and backpropagating their gradients directly. However,
a naive implementation suffers from low sample efficiency and compromised data
fidelity. PIRF mitigates these issues through two key strategies: (1) a
layer-wise truncated backpropagation method that leverages the spatiotemporally
localized nature of physics-based rewards, and (2) a weight-based
regularization scheme that improves efficiency over traditional
distillation-based methods. Across five PDE benchmarks, PIRF consistently
achieves superior physical enforcement under efficient sampling regimes,
highlighting the potential of reward fine-tuning for advancing scientific
generative modeling.

</details>


### [174] [Go With The Flow: Churn-Tolerant Decentralized Training of Large Language Models](https://arxiv.org/abs/2509.21221)
*Nikolay Blagoev,Bart Cox,Jérémie Decouchant,Lydia Y. Chen*

Main category: cs.LG

TL;DR: GWTF是一个第一个用于LLM的容错、实用、去中心化的训练框架，通过新颖的去中心化流算法，在异构客户端上实现高效协作训练，解决了节点流失和网络不稳定的问题，并将训练时间缩短了45%。


<details>
  <summary>Details</summary>
Motivation: LLM的出现以及训练民主化的重要性。

Method: 提出了一种新颖的去中心化流算法，以最有效的路由最大限度地提高微批处理的数量，并以尽可能低的延迟进行训练。

Result: 在涉及异构客户端节点、10个不同地理位置和高节点流失率的现实且具有挑战性的场景中，将训练时间缩短了高达45%。

Conclusion: GWTF是一个高效、容错的LLM分布式训练框架，能够处理异构节点、节点流失和网络不稳定等挑战。

Abstract: Motivated by the emergence of large language models (LLMs) and the importance
of democratizing their training, we propose GWTF, the first crash tolerant
practical decentralized training framework for LLMs. Differently from existing
distributed and federated training frameworks, GWTF enables the efficient
collaborative training of a LLM on heterogeneous clients that volunteer their
resources. In addition, GWTF addresses node churn, i.e., clients joining or
leaving the system at any time, and network instabilities, i.e., network links
becoming unstable or unreliable. The core of GWTF is a novel decentralized flow
algorithm that finds the most effective routing that maximizes the number of
microbatches trained with the lowest possible delay. We extensively evaluate
GWTF on GPT-like and LLaMa-like models and compare it against the prior art.
Our results indicate that GWTF reduces the training time by up to 45% in
realistic and challenging scenarios that involve heterogeneous client nodes
distributed over 10 different geographic locations with a high node churn rate.

</details>


### [175] [Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning](https://arxiv.org/abs/2509.20616)
*Hanjiang Hu,Changliu Liu,Na Li,Yebin Wang*

Main category: cs.LG

TL;DR: 本文提出了一种将多轮任务规划转化为单轮任务推理的方法，并使用GRPO进行优化，在复杂任务规划上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 训练LLM代理进行复杂的多轮任务规划面临稀疏奖励、信用分配困难和计算开销大的挑战。

Method: 将多轮任务规划转化为单轮任务推理问题，并使用基于专家轨迹的密集且可验证的奖励的组相对策略优化（GRPO）进行高效策略优化。

Result: 在复杂任务规划基准测试中，使用单轮GRPO训练的1.5B参数模型在超过30步的长期规划任务中取得了70%的成功率，优于高达14B参数的基线模型。同时，模型展现出强大的跨任务泛化能力，能在复杂任务上训练后成功完成所有更简单的子任务。

Conclusion: 所提出的方法通过将多轮任务规划转化为单轮任务推理，并利用GRPO进行优化，能够有效地解决LLM代理在复杂多轮任务规划中的挑战，并取得优越性能和良好的泛化能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
knowledge acquisition, reasoning, and tool use, making them promising
candidates for autonomous agent applications. However, training LLM agents for
complex multi-turn task planning faces significant challenges, including sparse
episode-wise rewards, credit assignment across long horizons, and the
computational overhead of reinforcement learning in multi-turn interaction
settings. To this end, this paper introduces a novel approach that transforms
multi-turn task planning into single-turn task reasoning problems, enabling
efficient policy optimization through Group Relative Policy Optimization (GRPO)
with dense and verifiable reward from expert trajectories. Our theoretical
analysis shows that GRPO improvement on single-turn task reasoning results in
higher multi-turn success probability under the minimal turns, as well as the
generalization to subtasks with shorter horizons. Experimental evaluation on
the complex task planning benchmark demonstrates that our 1.5B parameter model
trained with single-turn GRPO achieves superior performance compared to larger
baseline models up to 14B parameters, with success rates of 70% for
long-horizon planning tasks with over 30 steps. We also theoretically and
empirically validate the strong cross-task generalizability that the models
trained on complex tasks can lead to the successful completion of all simpler
subtasks.

</details>


### [176] [SuperOffload: Unleashing the Power of Large-Scale LLM Training on Superchips](https://arxiv.org/abs/2509.21271)
*Xinyu Lian,Masahiro Tanaka,Olatunji Ruwase,Minjia Zhang*

Main category: cs.LG

TL;DR: 该研究首次研究了基于卸载的超级芯片LLM训练解决方案，并提出了SuperOffload系统，通过一系列优化技术，在GH200上实现了高达2.5倍的吞吐量提升，并支持更大模型的训练。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练对硬件算力需求巨大，而集成了GPU和CPU的超级芯片（如NVIDIA GH200）为LLM训练提供了前所未有的计算能力。然而，现有研究对如何利用此类新架构进行LLM训练的探索尚不充分，特别是如何有效利用其异构特性。

Method: 提出了一种名为SuperOffload的、以超级芯片为中心的卸载系统，该系统集成了GPU和CPU，并通过自适应权重卸载、桶划分重构、超级芯片感知转换、推测执行以及优化的CPU Adam优化器等技术，更有效地利用了Hopper GPU、Grace CPU和NVLink-C2C互连。此外，还扩展了SuperOffload以支持ZeRO风格的数据并行和DeepSpeed-Ulysses序列并行。

Result: 在NVIDIA GH200上，SuperOffload实现了高达2.5倍于现有先进卸载系统的吞吐量提升，能够支持在单个超级芯片上训练高达250亿参数的模型，同时保持高训练吞吐量。通过结合数据并行和序列并行，可以在8个GH200上训练130亿参数的模型，支持长达100万的序列长度，实现55%的MFU。

Conclusion: SuperOffload是首个针对超级芯片优化的LLM训练卸载系统，通过充分利用异构计算资源，显著提高了训练效率和模型规模的可扩展性，为未来更大规模的LLM训练铺平了道路。

Abstract: The emergence of Superchips represents a significant advancement in
next-generation AI hardware. These Superchips employ a tightly coupled
heterogeneous architecture that integrates GPU and CPU on the same package,
which offers unprecedented computational power. However, there has been scant
research investigating how LLM training benefits from this new architecture. In
this work, for the first time, we study LLM training solutions based on
offloading for Superchips. We observe important differences between Superchips
and traditional loosely-coupled GPU-CPU architecture, which necessitate
revisiting prevailing assumptions about offloading. Based on that, we present
SuperOffload, a Superchip-centric offloading system that simultaneously uses
Hopper GPU, Grace CPU, and NVLink-C2C interconnect more efficiently.
SuperOffload accomplishes this via a combination of techniques, such as
adaptive weight offloading, bucketization repartitioning, Superchip-aware
casting, speculative execution, and a highly optimized Adam optimizer for Grace
CPUs. Our evaluation of SuperOffload on NVIDIA GH200 demonstrates up to 2.5x
throughput improvement compared to state-of-the-art offloading-based systems,
enabling training of up to 25B model on a single Superchip while achieving high
training throughput. We also extend SuperOffload with ZeRO-style data
parallelism and DeepSpeed-Ulysses sequence parallelism, enabling training of
13B model with sequence lengths up to 1 million tokens on 8 GH200 while
achieving 55% MFU.

</details>


### [177] [CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification](https://arxiv.org/abs/2509.20489)
*D. Darankoum,C. Habermacher,J. Volle,S. Grudinin*

Main category: cs.LG

TL;DR: 提出了一种新颖的端到端深度学习框架，用于从原始脑电图 (EEG) 信号中提取多尺度特征，并处理噪声和通道变异性。


<details>
  <summary>Details</summary>
Motivation: 从原始脑电图信号中提取有意义的特征，同时处理噪声和通道变异性是一个重大挑战。

Method: 设计了一个能够显式捕获多尺度频率振荡的编码器，引入了一个基于注意力的编码器来学习通道间的交互和单个通道内的局部交互，并集成了一个门控网络来动态过滤噪声通道。整个编码过程由一个结合了监督和对比学习的新型损失函数指导。

Result: 该方法在多种应用中得到了验证，包括中枢神经系统 (CNS) 疾病治疗效果的分类，以及帕金森病和阿尔茨海默病（AD）的诊断。结果表明，该框架能够从不同物种的原始脑电图信号中提取具有生物学意义的模式，自主选择高质量的通道，并通过创新的架构和损失设计实现稳健的泛化。

Conclusion: 所提出的深度学习框架能够有效处理脑电图信号的复杂性，提取有意义的特征，并具有良好的泛化能力，可应用于多种神经系统疾病的诊断和治疗评估。

Abstract: Electroencephalography signals (EEGs) contain rich multi-scale information
crucial for understanding brain states, with potential applications in
diagnosing and advancing the drug development landscape. However, extracting
meaningful features from raw EEG signals while handling noise and channel
variability remains a major challenge. This work proposes a novel end-to-end
deep-learning framework that addresses these issues through several key
innovations. First, we designed an encoder capable of explicitly capturing
multi-scale frequency oscillations covering a wide range of features for
different EEG-related tasks. Secondly, to model complex dependencies and handle
the high temporal resolution of EEGs, we introduced an attention-based encoder
that simultaneously learns interactions across EEG channels and within
localized {\em patches} of individual channels. We integrated a dedicated
gating network on top of the attention encoder to dynamically filter out noisy
and non-informative channels, enhancing the reliability of EEG data. The entire
encoding process is guided by a novel loss function, which leverages supervised
and contrastive learning, significantly improving model generalization. We
validated our approach in multiple applications, ranging from the
classification of effects across multiple Central Nervous System (CNS)
disorders treatments to the diagnosis of Parkinson's and Alzheimer's disease.
Our results demonstrate that the proposed learning paradigm can extract
biologically meaningful patterns from raw EEG signals across different species,
autonomously select high-quality channels, and achieve robust generalization
through innovative architectural and loss design.

</details>


### [178] [Complexity-Driven Policy Optimization](https://arxiv.org/abs/2509.20509)
*Luca Serfilippi,Giorgio Franceschelli,Antonio Corradi,Mirco Musolesi*

Main category: cs.LG

TL;DR: 该研究提出用复杂度奖励替代熵奖励来改进策略梯度方法，以实现更优的探索策略。


<details>
  <summary>Details</summary>
Motivation: 现有的基于熵最大化的策略梯度方法倾向于生成过于随机和低效的探索策略。

Method: 提出了一种新的复杂度度量，即香农熵与偏离均匀分布距离（不平衡度）的乘积，并以此作为奖励函数，替代原有的熵奖励，从而提出了一种新的算法——复杂度驱动策略优化（CDPO）。

Result: 在多种离散动作空间的任务上，CDPO算法相比于PPO算法，对于复杂度系数的选择更加鲁棒，尤其是在需要大量探索的环境中表现更佳。

Conclusion: 复杂度奖励比熵奖励更能有效地引导智能体在探索过程中发现兼具结构性和适应性的策略。

Abstract: Policy gradient methods often balance exploitation and exploration via
entropy maximization. However, maximizing entropy pushes the policy towards a
uniform random distribution, which represents an unstructured and sometimes
inefficient exploration strategy. In this work, we propose replacing the
entropy bonus with a more robust complexity bonus. In particular, we adopt a
measure of complexity, defined as the product of Shannon entropy and
disequilibrium, where the latter quantifies the distance from the uniform
distribution. This regularizer encourages policies that balance stochasticity
(high entropy) with structure (high disequilibrium), guiding agents toward
regimes where useful, non-trivial behaviors can emerge. Such behaviors arise
because the regularizer suppresses both extremes, e.g., maximal disorder and
complete order, creating pressure for agents to discover structured yet
adaptable strategies. Starting from Proximal Policy Optimization (PPO), we
introduce Complexity-Driven Policy Optimization (CDPO), a new learning
algorithm that replaces entropy with complexity. We show empirically across a
range of discrete action space tasks that CDPO is more robust to the choice of
the complexity coefficient than PPO is with the entropy coefficient, especially
in environments requiring greater exploration.

</details>


### [179] [Understanding and Improving Adversarial Robustness of Neural Probabilistic Circuits](https://arxiv.org/abs/2509.20549)
*Weixin Chen,Han Zhao*

Main category: cs.LG

TL;DR: NPCs are interpretable models, but their attribute recognition can be vulnerable to adversarial attacks. This paper analyzes this vulnerability and proposes RNPC, a robust version that improves adversarial robustness.


<details>
  <summary>Details</summary>
Motivation: The attribute recognition model within Neural Probabilistic Circuits (NPCs) is a black box vulnerable to adversarial attacks, potentially compromising the final predictions. This paper aims to theoretically analyze and address this vulnerability.

Method: The paper theoretically analyzes the adversarial robustness of NPCs, showing it depends solely on the attribute recognition model. It then proposes RNPC, which uses a novel class-wise integration for inference to achieve robustness against adversarial attacks on the recognition module.

Result: RNPC demonstrates provably improved adversarial robustness compared to NPC. Empirical results show RNPC has superior adversarial robustness and maintains high accuracy on benign inputs compared to existing concept bottleneck models.

Conclusion: RNPC is the first robust neural probabilistic circuit against adversarial attacks on the recognition module, offering provable improvements in adversarial robustness while maintaining high accuracy.

Abstract: Neural Probabilistic Circuits (NPCs), a new class of concept bottleneck
models, comprise an attribute recognition model and a probabilistic circuit for
reasoning. By integrating the outputs from these two modules, NPCs produce
compositional and interpretable predictions. While offering enhanced
interpretability and high performance on downstream tasks, the
neural-network-based attribute recognition model remains a black box. This
vulnerability allows adversarial attacks to manipulate attribute predictions by
introducing carefully crafted subtle perturbations to input images, potentially
compromising the final predictions. In this paper, we theoretically analyze the
adversarial robustness of NPC and demonstrate that it only depends on the
robustness of the attribute recognition model and is independent of the
robustness of the probabilistic circuit. Moreover, we propose RNPC, the first
robust neural probabilistic circuit against adversarial attacks on the
recognition module. RNPC introduces a novel class-wise integration for
inference, ensuring a robust combination of outputs from the two modules. Our
theoretical analysis demonstrates that RNPC exhibits provably improved
adversarial robustness compared to NPC. Empirical results on image
classification tasks show that RNPC achieves superior adversarial robustness
compared to existing concept bottleneck models while maintaining high accuracy
on benign inputs.

</details>


### [180] [Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration](https://arxiv.org/abs/2509.20648)
*Yiyuan Pan,Zhe Liu,Hesheng Wang*

Main category: cs.LG

TL;DR: CERMIC框架通过结合环境随机性和同行行为新颖性来增强多主体探索，并在稀疏奖励环境中优于最先进的算法。


<details>
  <summary>Details</summary>
Motivation: 在具有稀疏奖励的复杂多主体强化学习（MARL）中，自主探索需要有效的内在动机。现有的好奇心机制往往将环境随机性与有意义的新颖性混淆，并且存在统一的新颖性偏差，忽略了同伴行为新颖性，导致去中心化、无通信的MARL设置中的探索效果不佳。

Method: 提出了一种名为CERMIC的新颖方法，该方法能够鲁棒地过滤掉由环境随机性引起的新奇信号，并通过动态校准内在好奇心以适应推断出的多主体上下文来指导探索。此外，CERMIC生成具有理论依据的内在奖励，鼓励智能体探索具有高信息增益的状态转换。

Result: 在VMAS、Meltingpot和SMACv2等基准套件上进行了评估，实验结果表明，CERMIC在稀疏奖励环境中的探索效果显著优于最先进的算法。

Conclusion: CERMIC框架能够通过结合环境随机性和同伴行为新颖性来增强多主体探索，并在稀疏奖励环境中取得优于最先进算法的性能。

Abstract: Autonomous exploration in complex multi-agent reinforcement learning (MARL)
with sparse rewards critically depends on providing agents with effective
intrinsic motivation. While artificial curiosity offers a powerful
self-supervised signal, it often confuses environmental stochasticity with
meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform
novelty bias, treating all unexpected observations equally. However, peer
behavior novelty, which encode latent task dynamics, are often overlooked,
resulting in suboptimal exploration in decentralized, communication-free MARL
settings. To this end, inspired by how human children adaptively calibrate
their own exploratory behaviors via observing peers, we propose a novel
approach to enhance multi-agent exploration. We introduce CERMIC, a principled
framework that empowers agents to robustly filter noisy surprise signals and
guide exploration by dynamically calibrating their intrinsic curiosity with
inferred multi-agent context. Additionally, CERMIC generates
theoretically-grounded intrinsic rewards, encouraging agents to explore state
transitions with high information gain. We evaluate CERMIC on benchmark suites
including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that
exploration with CERMIC significantly outperforms SoTA algorithms in
sparse-reward environments.

</details>


### [181] [MMG: Mutual Information Estimation via the MMSE Gap in Diffusion](https://arxiv.org/abs/2509.20609)
*Longxuan Yu,Xing Shi,Xianghao Kong,Tong Jia,Greg Ver Steeg*

Main category: cs.LG

TL;DR: 使用扩散模型估计互信息（MI），MI等于条件和无条件扩散之间最小均方误差（MMSE）差异的一半，该差异在去噪过程中对所有信噪比（SNR）进行积分。


<details>
  <summary>Details</summary>
Motivation: 估计复杂系统中的互信息（MI）具有挑战性，而扩散模型在密度估计方面表现出色，因此可以利用它们来改进MI估计。

Method: 将互信息（MI）表述为扩散模型中的一个问题，其中MI等于条件扩散和无条件扩散之间的最小均方误差（MMSE）差异在去噪过程中对所有信噪比（SNR）进行积分。利用自适应重要性采样来实现可扩展的MI估计。

Result: 所提出的方法通过了自恰性检验，并且优于传统的和基于分数的扩散MI估计量，在高MI情况下仍能保持良好性能。

Conclusion: 扩散模型可以有效地估计互信息（MI），并且该方法具有可扩展性，即使在MI较高的情况下也能保持高性能。

Abstract: Mutual information (MI) is one of the most general ways to measure
relationships between random variables, but estimating this quantity for
complex systems is challenging. Denoising diffusion models have recently set a
new bar for density estimation, so it is natural to consider whether these
methods could also be used to improve MI estimation. Using the recently
introduced information-theoretic formulation of denoising diffusion models, we
show the diffusion models can be used in a straightforward way to estimate MI.
In particular, the MI corresponds to half the gap in the Minimum Mean Square
Error (MMSE) between conditional and unconditional diffusion, integrated over
all Signal-to-Noise-Ratios (SNRs) in the noising process. Our approach not only
passes self-consistency tests but also outperforms traditional and score-based
diffusion MI estimators. Furthermore, our method leverages adaptive importance
sampling to achieve scalable MI estimation, while maintaining strong
performance even when the MI is high.

</details>


### [182] [Personalized Federated Dictionary Learning for Modeling Heterogeneity in Multi-site fMRI Data](https://arxiv.org/abs/2509.20627)
*Yipu Zhang,Chengshuo Zhang,Ziyu Zhou,Gang Qu,Hao Zheng,Yuping Wang,Hui Shen,Hongwen Deng*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Data privacy constraints pose significant challenges for large-scale
neuroimaging analysis, especially in multi-site functional magnetic resonance
imaging (fMRI) studies, where site-specific heterogeneity leads to
non-independent and identically distributed (non-IID) data. These factors
hinder the development of generalizable models. To address these challenges, we
propose Personalized Federated Dictionary Learning (PFedDL), a novel federated
learning framework that enables collaborative modeling across sites without
sharing raw data. PFedDL performs independent dictionary learning at each site,
decomposing each site-specific dictionary into a shared global component and a
personalized local component. The global atoms are updated via federated
aggregation to promote cross-site consistency, while the local atoms are
refined independently to capture site-specific variability, thereby enhancing
downstream analysis. Experiments on the ABIDE dataset demonstrate that PFedDL
outperforms existing methods in accuracy and robustness across non-IID
datasets.

</details>


### [183] [Bispectral OT: Dataset Comparison using Symmetry-Aware Optimal Transport](https://arxiv.org/abs/2509.20678)
*Annabel Ma,Kaiying Hou,David Alvarez-Melis,Melanie Weber*

Main category: cs.LG

TL;DR: Bispectral Optimal Transport (BOT) 是一种新的最优传输方法，它通过使用双谱（一种保持信号结构但去除群作用引起的变化的不变量）来比较数据元素，从而解决了传统最优传输在对称丰富设置中忽略数据内在相干结构的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的最优传输方法在对称丰富的设置中，仅基于原始特征之间的成对几何距离来对齐数据分布，可能会忽略数据固有的相干结构。

Method: 提出了一种名为“双谱最优传输”（Bispectral Optimal Transport）的对称感知扩展方法，该方法利用双谱（一种群傅里叶不变量）来比较元素，这种不变量在保留所有信号结构的同时，仅去除由群作用引起的变化。

Result: 在经过视觉对称性变换的基准数据集上，使用双谱最优传输计算出的传输方案在类别保持准确性方面优于朴素特征最优传输。

Conclusion: 双谱最优传输能够提高有意义的对应关系的质量，更好地捕捉数据集的底层语义标签结构，同时去除不影响类别或内容的多余变化。

Abstract: Optimal transport (OT) is a widely used technique in machine learning,
graphics, and vision that aligns two distributions or datasets using their
relative geometry. In symmetry-rich settings, however, OT alignments based
solely on pairwise geometric distances between raw features can ignore the
intrinsic coherence structure of the data. We introduce Bispectral Optimal
Transport, a symmetry-aware extension of discrete OT that compares elements
using their representation using the bispectrum, a group Fourier invariant that
preserves all signal structure while removing only the variation due to group
actions. Empirically, we demonstrate that the transport plans computed with
Bispectral OT achieve greater class preservation accuracy than naive feature OT
on benchmark datasets transformed with visual symmetries, improving the quality
of meaningful correspondences that capture the underlying semantic label
structure in the dataset while removing nuisance variation not affecting class
or content.

</details>


### [184] [Learning to Align Molecules and Proteins: A Geometry-Aware Approach to Binding Affinity](https://arxiv.org/abs/2509.20693)
*Mohammadsaleh Refahi,Bahrad A. Sokhansanj,James R. Brown,Gail Rosen*

Main category: cs.LG

TL;DR: FIRM-DTI是一个轻量级框架，通过特征匹配的线性调制（FiLM）层和三元组损失来条件化分子嵌入，并强制执行度量结构，从而实现最先进的药物-靶点亲和力预测。


<details>
  <summary>Details</summary>
Motivation: 加速药物发现，通过在昂贵的湿式实验室筛选之前优先选择有前景的化合物。

Method: FIRM-DTI框架通过特征匹配的线性调制（FiLM）层来条件化分子嵌入，并通过三元组损失来强制执行度量结构，从而实现精确的药物-靶点结合亲和力预测。该模型使用RBF回归头来预测平滑且可解释的亲和力。

Result: FIRM-DTI在药物-靶点亲和力预测方面取得了最先进的性能，在TDC DTI-DG基准测试中表现出色，并且具有良好的泛化能力。

Conclusion: 模型的条件化和度量学习对于提高药物-靶点亲和力预测的鲁棒性至关重要。

Abstract: Accurate prediction of drug-target binding affinity can accelerate drug
discovery by prioritizing promising compounds before costly wet-lab screening.
While deep learning has advanced this task, most models fuse ligand and protein
representations via simple concatenation and lack explicit geometric
regularization, resulting in poor generalization across chemical space and
time. We introduce FIRM-DTI, a lightweight framework that conditions molecular
embeddings on protein embeddings through a feature-wise linear modulation
(FiLM) layer and enforces metric structure with a triplet loss. An RBF
regression head operating on embedding distances yields smooth, interpretable
affinity predictions. Despite its modest size, FIRM-DTI achieves
state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark,
as demonstrated by an extensive ablation study and out-of-domain evaluation.
Our results underscore the value of conditioning and metric learning for robust
drug-target affinity prediction.

</details>


### [185] [Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models](https://arxiv.org/abs/2506.00209)
*Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong*

Main category: cs.LG

TL;DR: CATCH-FM是一种基于电子健康记录的癌症预筛查方法，通过识别高风险患者进行进一步筛查，在回顾性评估中表现出高效率和低风险，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的癌症筛查技术成本高昂、侵入性强且在全球范围内不可用，导致许多本可挽救的生命流失。

Method: 利用数百万份电子健康记录（EHR）数据，预训练了具有高达24亿参数的EHR基础模型，并在临床医生策展的癌症风险预测队列上进行微调。

Result: 在包含3万名患者的回顾性评估中，CATCH-FM实现了60%的灵敏度和99%的特异性及阴性预测值，优于基于特征的树模型以及通用和医学大型语言模型。CATCH-FM在EHRSHOT少样本排行榜上取得了最先进的胰腺癌风险预测效果，优于使用现场患者数据预训练的EHR基础模型。分析表明CATCH-FM在各种患者分布中具有鲁棒性，在ICD代码空间中运行有益，并能捕获重要的癌症风险因素。

Conclusion: CATCH-FM是一种有效且鲁棒的癌症预筛查方法，仅基于历史医疗记录即可识别高风险患者，具有优于现有方法的潜力。

Abstract: Cancer screening, leading to early detection, saves lives. Unfortunately,
existing screening techniques require expensive and intrusive medical
procedures, not globally available, resulting in too many lost would-be-saved
lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation
Models, a cancer pre-screening methodology that identifies high-risk patients
for further screening solely based on their historical medical records. With
millions of electronic healthcare records (EHR), we establish the scaling law
of EHR foundation models pretrained on medical code sequences, pretrain
compute-optimal foundation models of up to 2.4 billion parameters, and finetune
them on clinician-curated cancer risk prediction cohorts. In our retrospective
evaluation comprising of thirty thousand patients, CATCH-FM achieved strong
efficacy (60% sensitivity) with low risk (99% specificity and Negative
Predictive Value), outperforming feature-based tree models as well as general
and medical large language models by large margins. Despite significant
demographic, healthcare system, and EHR coding differences, CATCH-FM achieves
state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot
leaderboard, outperforming EHR foundation models pretrained using on-site
patient data. Our analysis demonstrates the robustness of CATCH-FM in various
patient distributions, the benefits of operating in the ICD code space, and its
ability to capture non-trivial cancer risk factors. Our code will be
open-sourced.

</details>


### [186] [Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis](https://arxiv.org/abs/2509.20768)
*Maria F. Davila R,Azizjon Turaev,Wolfram Wingerath*

Main category: cs.LG

TL;DR: Transformer-based模型在生成合成表格数据方面表现出色，但计算成本高。本研究评估了超参数选择（如层数、隐藏维度）对数据质量和计算性能的影响，比较了GReaT和REaLTabFormer两种工具。结果表明，运行时间与超参数数量成正比，GReaT的运行时间通常低于REaLTabFormer，但在大型数据集上两者相当。对于小型数据集，两者都能生成高质量的合成数据；对于大型数据集，只有REaLTabFormer能保持良好的效用和相似性。REaLTabFormer结合轻量级LLM在数据质量和计算需求之间取得了最佳平衡，但运行时间仍高于其他工具。


<details>
  <summary>Details</summary>
Motivation: 为了解决Transformer-based模型在生成合成表格数据时计算成本高的问题，本研究旨在评估超参数选择对数据质量和计算性能的影响，以期找到效率和效果的平衡点。

Method: 通过在GReaT和REaLTabFormer两种工具上，对10种不同架构和深度的模型配置进行超参数敏感性评估，从运行时间、机器学习效用和与真实数据分布的相似性三个维度进行分析。实验使用了四个真实世界数据集。

Result: 运行时间与超参数数量成正比，较浅的配置运行更快。GReaT的运行时间普遍低于REaLTabFormer，仅在最大数据集上两者运行时间相当。对于小型数据集，两种工具均能生成高机器学习效用和高相似性的合成数据；对于大型数据集，仅REaLTabFormer能保持良好的效用和相似性。REaLTabFormer结合轻量级LLM在数据质量和计算需求之间取得了最佳平衡，但其运行时间仍高于GReaT和其他TDS工具，表明效率提升存在上限。

Conclusion: REaLTabFormer结合轻量级LLM在生成合成表格数据方面，能在保持数据质量的同时降低计算需求，实现了最佳的平衡。然而，与其他TDS工具相比，其运行时间仍然偏高，暗示着效率的提升存在一定的局限性。

Abstract: Synthetic tabular data is used for privacy-preserving data sharing and
data-driven model development. Its effectiveness, however, depends heavily on
the used Tabular Data Synthesis (TDS) tool. Recent studies have shown that
Transformer-based models outperform other state-of-the-art models such as
Generative Adversarial Networks (GANs) and Diffusion models in terms of data
quality. However, Transformer-based models also come with high computational
costs, making them sometimes unfeasible for end users with prosumer hardware.
This study presents a sensitivity assessment on how the choice of
hyperparameters, such as number of layers or hidden dimension affects the
quality of the resultant synthetic data and the computational performance. It
is performed across two tools, GReaT and REaLTabFormer, evaluating 10 model
setups that vary in architecture type and depth. We assess the sensitivity on
three dimensions: runtime, machine learning (ML) utility, and similarity to
real data distributions. Experiments were conducted on four real-world
datasets. Our findings reveal that runtime is proportional to the number of
hyperparameters, with shallower configurations completing faster. GReaT
consistently achieves lower runtimes than REaLTabFormer, and only on the
largest dataset they have comparable runtime. For small datasets, both tools
achieve synthetic data with high utility and optimal similarity, but on larger
datasets only REaLTabFormer sustains strong utility and similarity. As a
result, REaLTabFormer with lightweight LLMs provides the best balance, since it
preserves data quality while reducing computational requirements. Nonetheless,
its runtime remains higher than that of GReaT and other TDS tools, suggesting
that efficiency gains are possible but only up to a certain level.

</details>


### [187] [IConv: Focusing on Local Variation with Channel Independent Convolution for Multivariate Time Series Forecasting](https://arxiv.org/abs/2509.20783)
*Gawon Lee,Hanbyeol Park,Minseop Kim,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: MLP和CNN结合用于时间序列预测，MLP捕捉长期依赖，CNN捕捉短期局部模式，并提出了IConv来优化CNN。


<details>
  <summary>Details</summary>
Motivation: 解决MLP在处理具有不同分布的通道时，忽略季节性模式和残差等局部变化的问题，以及CNN有效捕捉这些变化的能力。

Method: 结合MLP和CNN。MLP用于建模整体趋势和长期依赖性。CNN（特别是提出的IConv）用于通过多样化的卷积核和独立的通道处理来捕捉细粒度的局部模式和跨通道关系。

Result: 在多元时间序列预测任务的广泛实验中，所提出的方法显示出优越性。

Conclusion: 所提出的结合MLP和CNN（特别是IConv）的方法在多元时间序列预测方面优于现有方法。

Abstract: Real-world time-series data often exhibit non-stationarity, including
changing trends, irregular seasonality, and residuals. In terms of changing
trends, recently proposed multi-layer perceptron (MLP)-based models have shown
excellent performance owing to their computational efficiency and ability to
capture long-term dependency. However, the linear nature of MLP architectures
poses limitations when applied to channels with diverse distributions,
resulting in local variations such as seasonal patterns and residual components
being ignored. However, convolutional neural networks (CNNs) can effectively
incorporate these variations. To resolve the limitations of MLP, we propose
combining them with CNNs. The overall trend is modeled using an MLP to consider
long-term dependencies. The CNN uses diverse kernels to model fine-grained
local patterns in conjunction with MLP trend predictions. To focus on modeling
local variation, we propose IConv, a novel convolutional architecture that
processes the temporal dependency channel independently and considers the
inter-channel relationship through distinct layers. Independent channel
processing enables the modeling of diverse local temporal dependencies and the
adoption of a large kernel size. Distinct inter-channel considerations reduce
computational cost. The proposed model is evaluated through extensive
experiments on time-series datasets. The results reveal the superiority of the
proposed method for multivariate time-series forecasting.

</details>


### [188] [Can Federated Learning Safeguard Private Data in LLM Training? Vulnerabilities, Attacks, and Defense Evaluation](https://arxiv.org/abs/2509.20680)
*Wenkai Guo,Xuefeng Liu,Haolin Wang,Jianwei Niu,Shaojie Tang,Jing Yuan*

Main category: cs.LG

TL;DR: 联合微调大型语言模型（LLM）可以通过联邦学习（FL）在保护隐私的情况下实现，但研究表明，即使在FL的聚合过程中，攻击者仍然可以提取训练数据。本研究提出了增强的攻击策略，并评估了差分隐私、正则化约束更新和安全对齐等缓解措施。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨在联邦学习（FL）框架下，当组织不愿意共享本地数据时，通过协作微调大型语言模型（LLM）的可行性，并评估其中存在的隐私风险。

Method: 通过广泛的实验，攻击者利用生成方法从全局模型中提取训练数据，并提出了一种针对FL的增强攻击策略，通过跟踪全局模型更新来加剧隐私泄露。研究还评估了差分隐私、正则化约束更新以及采用安全对齐的LLM等隐私保护技术。

Result: 实验表明，攻击者仍然可以从FL训练出的全局模型中提取训练数据，并且随着模型规模的增大，数据泄露的风险也随之增加。增强的攻击策略能进一步加剧隐私泄露。

Conclusion: 尽管FL在一定程度上保护了数据隐私，但在LLM的联合微调中，仍然存在数据泄露的风险。研究评估的隐私保护技术可以为降低FL中LLM训练的隐私风险提供指导。

Abstract: Fine-tuning large language models (LLMs) with local data is a widely adopted
approach for organizations seeking to adapt LLMs to their specific domains.
Given the shared characteristics in data across different organizations, the
idea of collaboratively fine-tuning an LLM using data from multiple sources
presents an appealing opportunity. However, organizations are often reluctant
to share local data, making centralized fine-tuning impractical. Federated
learning (FL), a privacy-preserving framework, enables clients to retain local
data while sharing only model parameters for collaborative training, offering a
potential solution. While fine-tuning LLMs on centralized datasets risks data
leakage through next-token prediction, the iterative aggregation process in FL
results in a global model that encapsulates generalized knowledge, which some
believe protects client privacy. In this paper, however, we present
contradictory findings through extensive experiments. We show that attackers
can still extract training data from the global model, even using
straightforward generation methods, with leakage increasing as the model size
grows. Moreover, we introduce an enhanced attack strategy tailored to FL, which
tracks global model updates during training to intensify privacy leakage. To
mitigate these risks, we evaluate privacy-preserving techniques in FL,
including differential privacy, regularization-constrained updates and adopting
LLMs with safety alignment. Our results provide valuable insights and practical
guidelines for reducing privacy risks when training LLMs with FL.

</details>


### [189] [CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning](https://arxiv.org/abs/2509.20712)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Yuntao Li,Wenping Hu,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: CE-GPPO 算法通过保留被截断 token 的梯度来解决 RL 训练 LLM 时熵不稳定问题，并在数学推理任务上表现优于基线算法。


<details>
  <summary>Details</summary>
Motivation: 现有 RL 方法（如 PPO）在训练 LLM 时会丢弃低概率 token 的梯度信息，导致熵不稳定，影响模型在复杂推理任务上的表现。

Method: 提出 CE-GPPO 算法，通过一种温和且有界的方式重新引入 PPO 中被截断 token 的梯度，从而控制梯度幅度的影响，实现探索与利用的平衡。

Result: CE-GPPO 有效缓解了熵不稳定性，并在数学推理基准测试中，在不同模型规模下均优于强基线算法。

Conclusion: CE-GPPO 算法通过保留梯度信息，能够有效解决 RL 训练 LLM 时遇到的熵不稳定问题，并在数学推理任务上取得更好的性能。

Abstract: Reinforcement learning (RL) has become a powerful paradigm for optimizing
large language models (LLMs) to handle complex reasoning tasks. A core
challenge in this process lies in managing policy entropy, which reflects the
balance between exploration and exploitation during training. Existing methods,
such as proximal policy optimization (PPO) and its variants, discard valuable
gradient signals from low-probability tokens due to the clipping mechanism. We
systematically analyze the entropy dynamics and reveal that these clipped
tokens play a critical yet overlooked role in regulating entropy evolution. We
propose \textbf{C}ontrolling \textbf{E}ntropy via
\textbf{G}radient-\textbf{P}reserving \textbf{P}olicy \textbf{O}ptimization
(CE-GPPO), a novel algorithm that reintroduces gradients from clipped tokens in
native PPO in a gentle and bounded manner. By controlling the magnitude of
gradients from tokens outside the clipping interval, CE-GPPO is able to achieve
an exploration-exploitation trade-off. We provide theoretical justification and
empirical evidence showing that CE-GPPO effectively mitigates entropy
instability. Extensive experiments on mathematical reasoning benchmarks show
that CE-GPPO consistently outperforms strong baselines across different model
scales.

</details>


### [190] [CaTS-Bench: Can Language Models Describe Numeric Time Series?](https://arxiv.org/abs/2509.20823)
*Luca Zhou,Pratham Yashwante,Marshall Fisher,Alessio Sampieri,Zihao Zhou,Fabio Galasso,Rose Yu*

Main category: cs.LG

TL;DR: CaTS-Bench是一个大规模、真实世界的时间序列描述基准，包含数值序列、元数据和图表，并提供新的评估指标和基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列描述基准存在数据过于简单、忽视元数据和视觉表示等问题，CaTS-Bench旨在解决这些不足，提供更全面的评估。

Method: CaTS-Bench包含来自11个不同数据集的约46.5万个训练样本和10.5万个测试样本，每个样本包含数值序列、元数据、折线图和描述。使用LLM生成描述，并通过事实核查、人类可区分性研究和多样性分析进行验证，还包含一个人工修订的子集。此外，还提供460个选择题，用于测试更深层次的时间序列推理能力。

Result: CaTS-Bench包括新的评估指标，并对现有的VLMs进行了基准测试，揭示了它们的优点和局限性。

Conclusion: CaTS-Bench及其描述生成流程为未来在时间序列分析和基础模型交叉领域的研究提供了一个可靠且可扩展的基础。

Abstract: Time series captioning, the task of describing numeric time series in natural
language, requires numerical reasoning, trend interpretation, and contextual
understanding. Existing benchmarks, however, often rely on synthetic data or
overly simplistic captions, and typically neglect metadata and visual
representations. To close this gap, we introduce CaTS-Bench, the first
large-scale, real-world benchmark for Context-aware Time Series captioning.
CaTS-Bench is derived from 11 diverse datasets reframed as captioning and Q&A
tasks, comprising roughly 465k training and 105k test timestamps. Each sample
includes a numeric series segment, contextual metadata, a line-chart image, and
a caption. A key contribution of this work is the scalable pipeline used to
generate reference captions: while most references are produced by an oracle
LLM and verified through factual checks, human indistinguishability studies,
and diversity analyses, we also provide a human-revisited subset of 579 test
captions, refined from LLM outputs to ensure accuracy and human-like style.
Beyond captioning, CaTS-Bench offers 460 multiple-choice questions targeting
deeper aspects of time series reasoning. We further propose new tailored
evaluation metrics and benchmark leading VLMs, highlighting both their
strengths and persistent limitations. Together, these contributions establish
CaTS-Bench and its captioning pipeline as a reliable and extensible foundation
for future research at the intersection of time series analysis and foundation
models.

</details>


### [191] [StyleBench: Evaluating thinking styles in Large Language Models](https://arxiv.org/abs/2509.20868)
*Junyu Guo,Shangding Gu,Ming Jin,Costas Spanos,Javad Lavaei*

Main category: cs.LG

TL;DR: StyleBench是一个评估LLM推理风格的基准，发现没有一种风格是万能的，风格效果取决于模型大小和任务类型，并开源了该基准。


<details>
  <summary>Details</summary>
Motivation: LLM的推理能力受提示中推理策略的影响，但推理策略、模型架构和任务类型之间的相互作用尚不清楚。

Method: 引入StyleBench基准，评估了五种推理风格（CoT, ToT, AoT, SoT, CoD）在五种推理任务上，使用了15个不同规模（270M到120B参数）的开源模型。

Result: 没有一种推理风格是普遍最优的。搜索类方法（AoT, ToT）在开放式问题上表现更好，但需要大型模型；简洁风格（SoT, CoD）在定义明确的任务上效率更高。小模型常无法遵循指令，而推理鲁棒性随模型规模的增加而提高。

Conclusion: 根据特定约束选择最佳推理策略的路线图，并开源了StyleBench基准。

Abstract: The effectiveness of Large Language Models (LLMs) is heavily influenced by
the reasoning strategies, or styles of thought, employed in their prompts.
However, the interplay between these reasoning styles, model architecture, and
task type remains poorly understood. To address this, we introduce StyleBench,
a comprehensive benchmark for systematically evaluating reasoning styles across
diverse tasks and models. We assess five representative reasoning styles,
including Chain of Thought (CoT), Tree of Thought (ToT), Algorithm of Thought
(AoT), Sketch of Thought (SoT), and Chain-of-Draft (CoD) on five reasoning
tasks, using 15 open-source models from major families (LLaMA, Qwen, Mistral,
Gemma, GPT-OSS, Phi, and DeepSeek) ranging from 270M to 120B parameters. Our
large-scale analysis reveals that no single style is universally optimal. We
demonstrate that strategy efficacy is highly contingent on both model scale and
task type: search-based methods (AoT, ToT) excel in open-ended problems but
require large-scale models, while concise styles (SoT, CoD) achieve radical
efficiency gains on well-defined tasks. Furthermore, we identify key behavioral
patterns: smaller models frequently fail to follow output instructions and
default to guessing, while reasoning robustness emerges as a function of scale.
Our findings offer a crucial roadmap for selecting optimal reasoning strategies
based on specific constraints, we open source the benchmark in
https://github.com/JamesJunyuGuo/Style_Bench.

</details>


### [192] [Robust Multi-Omics Integration from Incomplete Modalities Significantly Improves Prediction of Alzheimer's Disease](https://arxiv.org/abs/2509.20842)
*Sungjoon Park,Kyungwook Lee,Soorin Yim,Doyeong Hwang,Dongyun Kim,Soonyoung Lee,Amy Dunn,Daniel Gatti,Elissa Chesler,Kristen O'Connell,Kiyoung Kim*

Main category: cs.LG

TL;DR: MOIRA是一种处理多组学数据缺失问题的早期整合方法，通过表示对齐和自适应聚合实现对不完整数据的鲁棒学习，并在阿尔茨海默病研究中表现优于现有方法，同时识别出与疾病相关的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 现有的多组学整合方法难以处理数据中缺失的模态，这阻碍了对代谢和疾病的深入理解。

Method: MOIRA将每个组学数据集投影到共享嵌入空间，并使用可学习的加权机制来融合它们，从而能够利用所有样本（包括缺失模态的样本）进行学习。

Result: 在ROSMAP阿尔茨海默病数据集上，MOIRA的性能优于现有方法，并且特征重要性分析发现了与先前文献一致的AD相关生物标志物。

Conclusion: MOIRA能够有效处理多组学数据中的模态缺失问题，并能在阿尔茨海默病研究中提供有价值的见解，识别出相关的生物标志物。

Abstract: Multi-omics data capture complex biomolecular interactions and provide
insights into metabolism and disease. However, missing modalities hinder
integrative analysis across heterogeneous omics. To address this, we present
MOIRA (Multi-Omics Integration with Robustness to Absent modalities), an early
integration method enabling robust learning from incomplete omics data via
representation alignment and adaptive aggregation. MOIRA leverages all samples,
including those with missing modalities, by projecting each omics dataset onto
a shared embedding space where a learnable weighting mechanism fuses them.
Evaluated on the Religious Order Study and Memory and Aging Project (ROSMAP)
dataset for Alzheimer's Disease (AD), MOIRA outperformed existing approaches,
and further ablation studies confirmed modality-wise contributions. Feature
importance analysis revealed AD-related biomarkers consistent with prior
literature, highlighting the biological relevance of our approach.

</details>


### [193] [CLUE: Conflict-guided Localization for LLM Unlearning Framework](https://arxiv.org/abs/2509.20977)
*Hang Chen,Jiaying Zhu,Xinyu Yang,Wenya Wang*

Main category: cs.LG

TL;DR: LLM 灾学习旨在移除不良数据的影响，同时保留无关信息。现有方法难以区分遗忘和保留神经元，导致过度遗忘或遗忘不完全。CLUE 框架通过电路发现，区分遗忘和保留电路，并利用 CNF 解决冲突，实现精确的神经元定位和有针对性的微调，从而提高遗忘效果和保留效用。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 灾学习方法难以区分遗忘和保留神经元，导致过度遗忘或遗忘不完全。

Method: 提出 CLUE 框架，利用电路发现技术，识别遗忘和保留电路，并将其转换为 CNF。通过 CNF 满意度解决方案分配神经元，并进行有针对性的微调。

Result: CLUE 在遗忘效果和保留效用方面优于现有方法。

Conclusion: CLUE 通过精确的神经元定位，实现了优于现有方法的遗忘效果和保留效用。

Abstract: The LLM unlearning aims to eliminate the influence of undesirable data
without affecting causally unrelated information. This process typically
involves using a forget set to remove target information, alongside a retain
set to maintain non-target capabilities. While recent localization-based
methods demonstrate promise in identifying important neurons to be unlearned,
they fail to disentangle neurons responsible for forgetting undesirable
knowledge or retaining essential skills, often treating them as a single
entangled group. As a result, these methods apply uniform interventions,
risking catastrophic over-forgetting or incomplete erasure of the target
knowledge. To address this, we turn to circuit discovery, a mechanistic
interpretability technique, and propose the Conflict-guided Localization for
LLM Unlearning framEwork (CLUE). This framework identifies the forget and
retain circuit composed of important neurons, and then the circuits are
transformed into conjunctive normal forms (CNF). The assignment of each neuron
in the CNF satisfiability solution reveals whether it should be forgotten or
retained. We then provide targeted fine-tuning strategies for different
categories of neurons. Extensive experiments demonstrate that, compared to
existing localization methods, CLUE achieves superior forget efficacy and
retain utility through precise neural localization.

</details>


### [194] [FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting](https://arxiv.org/abs/2509.20852)
*Kjersti Engan,Neel Kanwal,Anita Yeconia,Ladislaus Blacy,Yuda Munyaw,Estomih Mduma,Hege Ersdal*

Main category: cs.LG

TL;DR: FHR信号缺失问题限制了AI分析，本文提出一种基于掩码Transformer自编码器的方法来重建缺失的FHR信号，该方法能捕捉信号的空间和频率特征，并在不同缺失时长下表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: FHR监测对预测新生儿呼吸窘迫风险很重要，但信号缺失限制了AI分析，需要有效的方法来处理缺失数据。

Method: 提出一种基于掩码Transformer自编码器的方法来重建缺失的FHR信号，该方法能捕捉数据在空间和频率上的特征。

Result: 该方法在处理不同时长的缺失数据时表现出鲁棒性，可用于信号修复和预测。

Conclusion: 所提出的方法能够处理缺失的FHR数据，有望支持AI风险算法的开发，并集成到可穿戴设备中以实现更早、更可靠的风险检测。

Abstract: Approximately 10\% of newborns require assistance to initiate breathing at
birth, and around 5\% need ventilation support. Fetal heart rate (FHR)
monitoring plays a crucial role in assessing fetal well-being during prenatal
care, enabling the detection of abnormal patterns and supporting timely
obstetric interventions to mitigate fetal risks during labor. Applying
artificial intelligence (AI) methods to analyze large datasets of continuous
FHR monitoring episodes with diverse outcomes may offer novel insights into
predicting the risk of needing breathing assistance or interventions. Recent
advances in wearable FHR monitors have enabled continuous fetal monitoring
without compromising maternal mobility. However, sensor displacement during
maternal movement, as well as changes in fetal or maternal position, often lead
to signal dropouts, resulting in gaps in the recorded FHR data. Such missing
data limits the extraction of meaningful insights and complicates automated
(AI-based) analysis. Traditional approaches to handle missing data, such as
simple interpolation techniques, often fail to preserve the spectral
characteristics of the signals. In this paper, we propose a masked
transformer-based autoencoder approach to reconstruct missing FHR signals by
capturing both spatial and frequency components of the data. The proposed
method demonstrates robustness across varying durations of missing data and can
be used for signal inpainting and forecasting. The proposed approach can be
applied retrospectively to research datasets to support the development of
AI-based risk algorithms. In the future, the proposed method could be
integrated into wearable FHR monitoring devices to achieve earlier and more
robust risk detection.

</details>


### [195] [Binary Autoencoder for Mechanistic Interpretability of Large Language Models](https://arxiv.org/abs/2509.20997)
*Hakaze Cho,Haolin Yang,Brian M. Kurkoski,Naoya Inoue*

Main category: cs.LG

TL;DR: 现有方法通过正则化尝试从LLM的隐藏状态中提取原子化特征，但缺乏全局稀疏性保证，导致特征密集。本文提出一种二值自编码器（BAE），通过最小化最小批数据的激活熵来强制实现跨实例的特征稀疏性和独立性。BAE将隐藏激活离散化为1位，并通过梯度估计实现反向传播。实验证明BAE可用于（1）特征集熵计算，以表征LLM推理和上下文学习；（2）特征解耦，优于基线方法，产生更稀疏、更可解释的特征。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从LLM隐藏状态提取原子化特征时，由于正则化约束于单例，缺乏全局稀疏性保证，导致特征密集，阻碍了特征稀疏性和原子化。

Method: 提出一种新颖的自编码器变体——二值自编码器（BAE），通过对最小批次（minibatches）的隐藏激活强制执行最小熵，以促进跨实例的特征独立性和稀疏性。为了高效计算熵，将隐藏激活通过阶跃函数离散化为1位，并应用梯度估计以实现反向传播。

Result: BAE可以可靠地估计二值隐藏激活上的熵，从而用于表征LLM的推理动态和上下文学习。此外，BAE作为特征提取器，优于基线方法，能够避免密集特征并产生最大数量的可解释特征。

Conclusion: BAE通过强制执行最小熵，能够有效地实现跨实例的特征稀疏性，优于现有方法，并且在特征提取方面表现出色，能够产生更多可解释的特征，证明了其作为特征提取器的有效性。

Abstract: Existing works are dedicated to untangling atomized numerical components
(features) from the hidden states of Large Language Models (LLMs) for
interpreting their mechanism. However, they typically rely on autoencoders
constrained by some implicit training-time regularization on single training
instances (i.e., $L_1$ normalization, top-k function, etc.), without an
explicit guarantee of global sparsity among instances, causing a large amount
of dense (simultaneously inactive) features, harming the feature sparsity and
atomization. In this paper, we propose a novel autoencoder variant that
enforces minimal entropy on minibatches of hidden activations, thereby
promoting feature independence and sparsity across instances. For efficient
entropy calculation, we discretize the hidden activations to 1-bit via a step
function and apply gradient estimation to enable backpropagation, so that we
term it as Binary Autoencoder (BAE) and empirically demonstrate two major
applications: (1) Feature set entropy calculation. Entropy can be reliably
estimated on binary hidden activations, which we empirically evaluate and
leverage to characterize the inference dynamics of LLMs and In-context
Learning. (2) Feature untangling. Similar to typical methods, BAE can extract
atomized features from LLM's hidden states. To robustly evaluate such feature
extraction capability, we refine traditional feature-interpretation methods to
avoid unreliable handling of numerical tokens, and show that BAE avoids dense
features while producing the largest number of interpretable ones among
baselines, which confirms the effectiveness of BAE serving as a feature
extractor.

</details>


### [196] [Mechanism of Task-oriented Information Removal in In-context Learning](https://arxiv.org/abs/2509.21012)
*Hakaze Cho,Haolin Yang,Gouki Minegishi,Naoya Inoue*

Main category: cs.LG

TL;DR: ICL通过信息移除机制进行，移除无关信息以聚焦特定任务。


<details>
  <summary>Details</summary>
Motivation: ICL的内在机制不明确，需要新的视角来解释其工作原理。

Method: 提出信息移除视角，通过低秩滤波器选择性移除隐藏状态中的信息，并识别诱导移除操作的“去噪头”。

Result: 零样本场景下，LM的查询表示包含所有任务信息，导致输出任意；通过信息移除，LM能聚焦特定任务；ICL通过模拟信息移除过程来提升表现；去噪头的移除会显著降低ICL准确率，尤其是在演示中缺少正确标签时。

Conclusion: 信息移除是ICL的关键机制，而去噪头在其中起着至关重要的作用。

Abstract: In-context Learning (ICL) is an emerging few-shot learning paradigm based on
modern Language Models (LMs), yet its inner mechanism remains unclear. In this
paper, we investigate the mechanism through a novel perspective of information
removal. Specifically, we demonstrate that in the zero-shot scenario, LMs
encode queries into non-selective representations in hidden states containing
information for all possible tasks, leading to arbitrary outputs without
focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we
find that selectively removing specific information from hidden states by a
low-rank filter effectively steers LMs toward the intended task. Building on
these findings, by measuring the hidden states on carefully designed metrics,
we observe that few-shot ICL effectively simulates such task-oriented
information removal processes, selectively removing the redundant information
from entangled non-selective representations, and improving the output based on
the demonstrations, which constitutes a key mechanism underlying ICL. Moreover,
we identify essential attention heads inducing the removal operation, termed
Denoising Heads, which enables the ablation experiments blocking the
information removal operation from the inference, where the ICL accuracy
significantly degrades, especially when the correct label is absent from the
few-shot demonstrations, confirming both the critical role of the information
removal mechanism and denoising heads.

</details>


### [197] [Federated Markov Imputation: Privacy-Preserving Temporal Imputation in Multi-Centric ICU Environments](https://arxiv.org/abs/2509.20867)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 联邦马尔可夫链插补（FMI）是一种新的隐私保护方法，用于处理电子健康记录中的缺失时间序列数据，它通过协作构建全局转移模型来进行时间序列插补，并在脓毒症发病预测任务中表现优于局部插补方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的缺失数据，特别是当不同机构收集的时间序列数据具有不同的时间粒度时，是联邦学习中的一个持续存在的挑战。

Method: 提出联邦马尔可夫链插补（FMI），这是一种隐私保护方法，使重症监护室（ICU）能够协同构建用于时间序列插补的全局转移模型。

Result: 在真实世界的脓毒症发病预测任务中使用MIMIC-IV数据集对FMI进行了评估，结果表明，特别是在ICU之间采样间隔不规则的情况下，其性能优于局部插补基线。

Conclusion: FMI 能够有效处理电子健康记录中的缺失时间序列数据，尤其是在数据采样频率不一致的情况下，能够提升预测任务的性能。

Abstract: Missing data is a persistent challenge in federated learning on electronic
health records, particularly when institutions collect time-series data at
varying temporal granularities. To address this, we propose Federated Markov
Imputation (FMI), a privacy-preserving method that enables Intensive Care Units
(ICUs) to collaboratively build global transition models for temporal
imputation. We evaluate FMI on a real-world sepsis onset prediction task using
the MIMIC-IV dataset and show that it outperforms local imputation baselines,
especially in scenarios with irregular sampling intervals across ICUs.

</details>


### [198] [DELTA-Code: How Does RL Unlock and Transfer New Programming Algorithms in LLMs?](https://arxiv.org/abs/2509.21016)
*Yiyou Sun,Yuhan Cao,Pohao Huang,Haoyue Bai,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

Main category: cs.LG

TL;DR: LLMs 在算法编码方面能否学习和泛化新的推理策略仍是未解之谜。我们提出了 DELTA-Code 基准来评估 LLM 的学习能力（通过 RL）和迁移能力（泛化到分布外数据集）。实验显示 LLM 存在一个“grokking”阶段性转变，在 RL 训练一段时间后，性能会突然提升。我们还探索了提高学习能力的训练技巧。结果表明，LLM 在组合性泛化方面表现良好，但在变换性泛化方面仍有不足。DELTA-Code 是一个用于探究 LLM 推理能力极限的有效测试平台。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）是否能够习得或泛化出全新的推理策略，而不仅仅是依赖预训练或后训练中编码的技能。

Method: 引入 DELTA-Code（Distributional Evaluation of Learnability and Transferrability in Algorithmic Coding）基准。该基准包含合成的编码问题族，用于探测学习能力（LLM 是否能通过强化学习解决预训练模型无法解决的问题）和迁移能力（学习到的技能是否能迁移到分布外测试集）。通过模板化问题生成器隔离推理技能，并引入需要新策略而非调用工具或记忆模式的完全分布外问题族。探索了分阶段预热、经验回放、课程学习和验证循环等训练技巧。

Result: 实验揭示了 LLM 存在一个显著的“grokking”阶段性转变现象：在经历近乎零回报的漫长训练期后，强化学习训练的模型准确率会骤然攀升至接近完美。在学习能力方面，取得了显著的进展。在迁移能力方面，在家族内泛化和重组技能方面表现稳健，但在变换性泛化方面存在持续的不足。

Conclusion: DELTA-Code 提供了一个清晰的测试平台，用于探究由强化学习驱动的推理能力的极限，并理解模型如何超越现有先验知识来获取新的算法技能。研究表明，LLM 在学习和泛化新推理策略方面存在潜力，但仍面临挑战，尤其是在处理需要根本性策略转变的情况下。

Abstract: It remains an open question whether LLMs can acquire or generalize genuinely
new reasoning strategies, beyond the sharpened skills encoded in their
parameters during pre-training or post-training. To attempt to answer this
debate, we introduce DELTA-Code--Distributional Evaluation of Learnability and
Transferrability in Algorithmic Coding, a controlled benchmark of synthetic
coding problem families designed to probe two fundamental aspects: learnability
-- can LLMs, through reinforcement learning (RL), solve problem families where
pretrained models exhibit failure with large enough attempts (pass@K=0)? --and
transferrability -- if learnability happens, can such skills transfer
systematically to out-of-distribution (OOD) test sets? Unlike prior public
coding datasets, DELTA isolates reasoning skills through templated problem
generators and introduces fully OOD problem families that demand novel
strategies rather than tool invocation or memorized patterns. Our experiments
reveal a striking grokking phase transition: after an extended period with
near-zero reward, RL-trained models abruptly climb to near-perfect accuracy. To
enable learnability on previously unsolvable problem families, we explore key
training ingredients such as staged warm-up with dense rewards, experience
replay, curriculum training, and verification-in-the-loop. Beyond learnability,
we use DELTA to evaluate transferability or generalization along exploratory,
compositional, and transformative axes, as well as cross-family transfer.
Results show solid gains within families and for recomposed skills, but
persistent weaknesses in transformative cases. DELTA thus offers a clean
testbed for probing the limits of RL-driven reasoning and for understanding how
models can move beyond existing priors to acquire new algorithmic skills.

</details>


### [199] [Model-Based Reinforcement Learning under Random Observation Delays](https://arxiv.org/abs/2509.20869)
*Armin Karamzade,Kyungmin Kim,JB Lanier,Davide Corsi,Roy Fox*

Main category: cs.LG

TL;DR: 该研究提出了一种基于模型的过滤方法，用于解决强化学习中的随机传感器延迟问题，并提出了一个包含该方法的延迟感知框架，在模拟机器人任务中表现优于现有方法和启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中强化学习算法常假设环境感知是即时的，但实际中常有延迟，尤其是在POMDPs中观测可能乱序到达，这在现有强化学习研究中未被充分解决。

Method: 提出了一种基于模型的过滤过程，该过程基于传入的观测流顺序更新信念状态。将此方法整合到一个模型驱动的强化学习框架中，使其能够处理随机延迟。

Result: 该方法在Dreamer框架下，一致性地优于基于MDP的延迟感知基线，并对延迟分布的变化表现出鲁棒性。在模拟机器人任务中，该方法也优于常用的实用启发式方法。

Conclusion: 显式地对观测延迟进行建模对于强化学习在存在随机延迟的现实世界环境中的成功应用至关重要。

Abstract: Delays frequently occur in real-world environments, yet standard
reinforcement learning (RL) algorithms often assume instantaneous perception of
the environment. We study random sensor delays in POMDPs, where observations
may arrive out-of-sequence, a setting that has not been previously addressed in
RL. We analyze the structure of such delays and demonstrate that naive
approaches, such as stacking past observations, are insufficient for reliable
performance. To address this, we propose a model-based filtering process that
sequentially updates the belief state based on an incoming stream of
observations. We then introduce a simple delay-aware framework that
incorporates this idea into model-based RL, enabling agents to effectively
handle random delays. Applying this framework to Dreamer, we compare our
approach to delay-aware baselines developed for MDPs. Our method consistently
outperforms these baselines and demonstrates robustness to delay distribution
shifts during deployment. Additionally, we present experiments on simulated
robotic tasks, comparing our method to common practical heuristics and
emphasizing the importance of explicitly modeling observation delays.

</details>


### [200] [ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning](https://arxiv.org/abs/2509.21070)
*Qizhi Pei,Zhuoshi Pan,Honglin Lin,Xin Gao,Yu Li,Zinan Tang,Conghui He,Rui Yan,Lijun Wu*

Main category: cs.LG

TL;DR: ScaleDiff是一个通过筛选和生成难解数学问题来提升大语言模型能力的方法，成本效益高且效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有通过自动生成数学问题来训练大语言模型（LRMs）的方法存在成本高、生成问题难度有限等挑战，需要一种可扩展的方法来生成更难的问题。

Method: ScaleDiff首先使用一个能感知问题难度并自适应切换模式的 'thinking' 模型，通过单次前向传播从现有数据集中筛选出难题。然后，在一个名为DiffGen-8B的专用生成器上，利用筛选出的难题数据进行训练，使其能够大规模生成新的难题，避免了复杂的、针对单个实例的提示词工程及其高昂的API成本。最后，在ScaleDiff-Math数据集上微调Qwen2.5-Math-7B-Instruct模型。

Result: 在AIME'24, AIME'25, HMMT-Feb'25, BRUMO'25, 和MATH500等数据集上，微调后的模型准确率达到65.9%，比仅使用原始数据集提升了11.3%，并且优于OpenThinker3等模型。该方法使用成本效益高的Qwen3-8B作为教师模型，证明了无需依赖更大更昂贵的教师模型即可有效迁移高级推理能力。此外，随着难题数量的增加，模型在难解基准测试上的性能呈现出明显的规模效应。

Conclusion: ScaleDiff流水线能够以高成本效益大规模生成难解问题，显著提升大语言模型在复杂推理任务上的表现，并且观察到了难题数量与模型性能之间的规模效应。

Abstract: Large Reasoning Models (LRMs) have shown impressive capabilities in complex
problem-solving, often benefiting from training on difficult mathematical
problems that stimulate intricate reasoning. Recent efforts have explored
automated synthesis of mathematical problems by prompting proprietary models or
large-scale open-source models from seed data or inherent mathematical
concepts. However, scaling up these methods remains challenging due to their
high computational/API cost, complexity of prompting, and limited difficulty
level of the generated problems. To overcome these limitations, we propose
ScaleDiff, a simple yet effective pipeline designed to scale the creation of
difficult problems. We efficiently identify difficult problems from existing
datasets with only a single forward pass using an adaptive thinking model,
which can perceive problem difficulty and automatically switch between
"Thinking" and "NoThinking" modes. We then train a specialized difficult
problem generator (DiffGen-8B) on this filtered difficult data, which can
produce new difficult problems in large scale, eliminating the need for
complex, per-instance prompting and its associated high API costs. Fine-tuning
Qwen2.5-Math-7B-Instruct on the ScaleDiff-Math dataset yields a substantial
performance increase of 11.3% compared to the original dataset and achieves a
65.9% average accuracy on AIME'24, AIME'25, HMMT-Feb'25, BRUMO'25, and MATH500,
outperforming recent strong LRMs like OpenThinker3. Notably, this performance
is achieved using the cost-efficient Qwen3-8B model as a teacher, demonstrating
that our pipeline can effectively transfer advanced reasoning capabilities
without relying on larger, more expensive teacher models. Furthermore, we
observe a clear scaling phenomenon in model performance on difficult benchmarks
as the quantity of difficult problems increases. Code:
https://github.com/QizhiPei/ScaleDiff.

</details>


### [201] [Improving Early Sepsis Onset Prediction Through Federated Learning](https://arxiv.org/abs/2509.20885)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: Federated attention-enhanced LSTM model for sepsis onset prediction shows improved early detection and reduced overhead with variable prediction horizons.


<details>
  <summary>Details</summary>
Motivation: Sepsis onset prediction is challenging due to data limitations in individual hospitals; Federated Learning (FL) can address this by enabling collaborative training without data sharing. Existing models often use fixed prediction windows, limiting flexibility.

Method: Propose a federated, attention-enhanced Long Short-Term Memory (LSTM) model trained on multi-centric ICU data. The model supports variable prediction horizons for both short- and long-term forecasting.

Result: FL improves overall prediction performance, approaching that of a centralized model, and is particularly beneficial for early sepsis onset prediction. Variable prediction windows do not significantly hurt performance but reduce overhead.

Conclusion: Federated learning is effective for sepsis onset prediction, especially for early detection. A unified model with variable prediction horizons offers flexibility and efficiency without substantial performance compromise.

Abstract: Early and accurate prediction of sepsis onset remains a major challenge in
intensive care, where timely detection and subsequent intervention can
significantly improve patient outcomes. While machine learning models have
shown promise in this domain, their success is often limited by the amount and
diversity of training data available to individual hospitals and Intensive Care
Units (ICUs). Federated Learning (FL) addresses this issue by enabling
collaborative model training across institutions without requiring data
sharing, thus preserving patient privacy. In this work, we propose a federated,
attention-enhanced Long Short-Term Memory model for sepsis onset prediction,
trained on multi-centric ICU data. Unlike existing approaches that rely on
fixed prediction windows, our model supports variable prediction horizons,
enabling both short- and long-term forecasting in a single unified model.
During analysis, we put particular emphasis on the improvements through our
approach in terms of early sepsis detection, i.e., predictions with large
prediction windows by conducting an in-depth temporal analysis. Our results
prove that using FL does not merely improve overall prediction performance
(with performance approaching that of a centralized model), but is particularly
beneficial for early sepsis onset prediction. Finally, we show that our choice
of employing a variable prediction window rather than a fixed window does not
hurt performance significantly but reduces computational, communicational, and
organizational overhead.

</details>


### [202] [Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales](https://arxiv.org/abs/2509.20913)
*Ariadna Albors Zumel,Michele Tizzoni,Gian Maria Campedelli*

Main category: cs.LG

TL;DR: 该研究开发了一个深度学习框架，结合微观层面的流动性特征、历史犯罪和社会人口统计数据，以提高犯罪预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探索在精细的空间和时间分辨率下，整合微观层面的流动性特征、历史犯罪和社会人口统计数据，是否以及如何能够提高犯罪预测的性能。

Method: 研究人员收集了四个美国城市（巴尔的摩、芝加哥、洛杉矶和费城）的犯罪事件数据、社会人口统计数据和人类流动性数据，并将这些数据聚合到网格单元中。他们使用卷积长短期记忆（ConvLSTM）网络训练了一个深度学习预测模型，该模型可以提前12小时预测犯罪发生情况，并将其与逻辑回归、随机森林和标准LSTM等基线模型进行比较。

Result: 结果表明，结合流动性特征可以提高预测性能，尤其是在使用较短的输入序列时。当同时使用流动性和社会人口统计学特征时，深度学习模型在所有四个城市都取得了最高的召回率、精确率和F1分数，优于其他方法。此外，研究发现较长的输入序列有利于预测暴力犯罪，而较短的序列对预测财产犯罪更有效。

Conclusion: 研究结论强调了整合包括流动性在内的多种数据源对于时空犯罪预测的重要性，并突出了深度学习在处理精细空间和时间尺度方面的优势和局限性。

Abstract: Objectives: To develop a deep learning framework to evaluate if and how
incorporating micro-level mobility features, alongside historical crime and
sociodemographic data, enhances predictive performance in crime forecasting at
fine-grained spatial and temporal resolutions.
  Methods: We advance the literature on computational methods and crime
forecasting by focusing on four U.S. cities (i.e., Baltimore, Chicago, Los
Angeles, and Philadelphia). We employ crime incident data obtained from each
city's police department, combined with sociodemographic data from the American
Community Survey and human mobility data from Advan, collected from 2019 to
2023. This data is aggregated into grids with equally sized cells of 0.077 sq.
miles (0.2 sq. kms) and used to train our deep learning forecasting model, a
Convolutional Long Short-Term Memory (ConvLSTM) network, which predicts crime
occurrences 12 hours ahead using 14-day and 2-day input sequences. We also
compare its performance against three baseline models: logistic regression,
random forest, and standard LSTM.
  Results: Incorporating mobility features improves predictive performance,
especially when using shorter input sequences. Noteworthy, however, the best
results are obtained when both mobility and sociodemographic features are used
together, with our deep learning model achieving the highest recall, precision,
and F1 score in all four cities, outperforming alternative methods. With this
configuration, longer input sequences enhance predictions for violent crimes,
while shorter sequences are more effective for property crimes.
  Conclusion: These findings underscore the importance of integrating diverse
data sources for spatiotemporal crime forecasting, mobility included. They also
highlight the advantages (and limits) of deep learning when dealing with
fine-grained spatial and temporal scales.

</details>


### [203] [Flow Matching in the Low-Noise Regime: Pathologies and a Contrastive Remedy](https://arxiv.org/abs/2509.20952)
*Weili Zeng,Yichao Yan*

Main category: cs.LG

TL;DR: Flow matching 框架在低噪声情况下存在不稳定性问题，导致优化缓慢和表示能力下降。我们提出了 Local Contrastive Flow (LCF) 协议来解决这个问题，该协议在低噪声时进行对比特征对齐，在中高噪声时使用标准的 flow matching，实验证明 LCF 提高了收敛速度和表示质量。


<details>
  <summary>Details</summary>
Motivation: Flow matching 作为一种生成模型框架，在低噪声情况下存在根本性的不稳定性，表现为输入扰动导致目标速度剧烈变化，使得条件数发散，优化缓慢，并损害表示学习。

Method: 提出 Local Contrastive Flow (LCF) 训练协议，在低噪声水平下用对比特征对齐替代直接速度回归，而在中高噪声水平下保留标准的 flow matching。

Result: LCF 训练协议在经验上提高了收敛速度，并稳定了表示质量。

Conclusion: 解决低噪声下的不稳定性问题对于充分发挥 flow matching 在生成和表示学习方面的潜力至关重要。

Abstract: Flow matching has recently emerged as a powerful alternative to diffusion
models, providing a continuous-time formulation for generative modeling and
representation learning. Yet, we show that this framework suffers from a
fundamental instability in the low-noise regime. As noise levels approach zero,
arbitrarily small perturbations in the input can induce large variations in the
velocity target, causing the condition number of the learning problem to
diverge. This ill-conditioning not only slows optimization but also forces the
encoder to reallocate its limited Jacobian capacity toward noise directions,
thereby degrading semantic representations. We provide the first theoretical
analysis of this phenomenon, which we term the low-noise pathology,
establishing its intrinsic link to the structure of the flow matching
objective. Building on these insights, we propose Local Contrastive Flow (LCF),
a hybrid training protocol that replaces direct velocity regression with
contrastive feature alignment at small noise levels, while retaining standard
flow matching at moderate and high noise. Empirically, LCF not only improves
convergence speed but also stabilizes representation quality. Our findings
highlight the critical importance of addressing low-noise pathologies to unlock
the full potential of flow matching for both generation and representation
learning.

</details>


### [204] [Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules](https://arxiv.org/abs/2509.20501)
*Kishor Datta Gupta,Mohd Ariful Haque,Marufa Kamal,Ahmed Rafi Hasan,Md. Mahfuzur Rahman,Roy George*

Main category: cs.LG

TL;DR: DARTVAE是一个结合规则引导的多模态聚类框架，利用LLM生成的规则来增强基于相似度的传统聚类方法，从而获得更具操作意义和可解释性的聚类结果，但面临规则幻觉、过拟合和可扩展性等挑战。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法仅依赖输入数据的相似性，难以捕捉关键的结构或语义约束。本研究旨在提出一种能直接将领域特定约束融入表示学习过程的聚类框架。

Method: DARTVAE扩展了变分自编码器（VAE）架构，将显式规则、语义表示和数据驱动特征嵌入统一的潜在空间。通过在损失函数中加入规则一致性和违反惩罚，强制执行约束。规则由LLM生成，构建为知识图谱，并通过结合重构、KL散度、一致性和违反惩罚的损失函数来执行。

Result: 在飞机和汽车数据集上的实验表明，DARTVAE生成的聚类结果比传统方法更具操作意义和可解释性（例如，区分无人机、统一隐形飞机、分离SUV和轿车），同时提高了传统聚类指标。

Conclusion: DARTVAE通过结合规则编码和学习到的表示，在复杂、知识密集型的场景中实现了比纯数据驱动模型更有意义、更一致的聚类结果，证明了约束引导的多模态聚类方法的有效性。然而，该框架也面临LLM规则幻觉/冲突、过度规则导致过拟合以及复杂领域的可扩展性挑战。

Abstract: Traditional clustering techniques often rely solely on similarity in the
input data, limiting their ability to capture structural or semantic
constraints that are critical in many domains. We introduce the Domain Aware
Rule Triggered Variational Autoencoder (DARTVAE), a rule guided multimodal
clustering framework that incorporates domain specific constraints directly
into the representation learning process. DARTVAE extends the VAE architecture
by embedding explicit rules, semantic representations, and data driven features
into a unified latent space, while enforcing constraint compliance through rule
consistency and violation penalties in the loss function. Unlike conventional
clustering methods that rely only on visual similarity or apply rules as post
hoc filters, DARTVAE treats rules as first class learning signals. The rules
are generated by LLMs, structured into knowledge graphs, and enforced through a
loss function combining reconstruction, KL divergence, consistency, and
violation penalties. Experiments on aircraft and automotive datasets
demonstrate that rule guided clustering produces more operationally meaningful
and interpretable clusters for example, isolating UAVs, unifying stealth
aircraft, or separating SUVs from sedans while improving traditional clustering
metrics. However, the framework faces challenges: LLM generated rules may
hallucinate or conflict, excessive rules risk overfitting, and scaling to
complex domains increases computational and consistency difficulties. By
combining rule encodings with learned representations, DARTVAE achieves more
meaningful and consistent clustering outcomes than purely data driven models,
highlighting the utility of constraint guided multimodal clustering for
complex, knowledge intensive settings.

</details>


### [205] [Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine](https://arxiv.org/abs/2509.20975)
*Michael S. Yao,Osbert Bastani,Alma Andersson,Tommaso Biancalani,Aïcha Bentaieb,Claudia Iriondo*

Main category: cs.LG

TL;DR: LEON是一种利用大型语言模型（LLM）通过“提示优化”来为患者制定个性化治疗方案的方法，该方法结合了领域先验知识，并在真实世界的优化任务中表现优于传统和基于LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 个性化医疗的目标是根据患者的遗传和环境因素发现最佳治疗方案，但候选治疗方案不能随意给药进行评估，通常依赖于计算模型，而这些模型在处理未见过的情形时会失败。因此，需要一种能够利用领域知识来指导治疗方案选择的方法。

Method: LEON（LLM-based Entropy-guided Optimization with Knowledgeable priors）方法利用大型语言模型（LLMs）作为黑箱优化器，通过“提示优化”来生成个性化治疗方案。它将LLMs视为随机引擎，并结合领域先验知识（如医学教科书和生物医学知识图谱）来提供治疗方案的有效性信号，而无需针对特定任务进行微调。

Result: 在真实世界的优化任务中，LEON提出的个性化治疗方案优于传统的和基于LLM的现有方法。

Conclusion: LEON通过结合LLM的上下文理解能力和领域先验知识，为个性化医疗提供了一种有效的优化方法，能够生成比现有方法更好的个性化治疗方案。

Abstract: The goal of personalized medicine is to discover a treatment regimen that
optimizes a patient's clinical outcome based on their personal genetic and
environmental factors. However, candidate treatments cannot be arbitrarily
administered to the patient to assess their efficacy; we often instead have
access to an in silico surrogate model that approximates the true fitness of a
proposed treatment. Unfortunately, such surrogate models have been shown to
fail to generalize to previously unseen patient-treatment combinations. We
hypothesize that domain-specific prior knowledge - such as medical textbooks
and biomedical knowledge graphs - can provide a meaningful alternative signal
of the fitness of proposed treatments. To this end, we introduce LLM-based
Entropy-guided Optimization with kNowledgeable priors (LEON), a mathematically
principled approach to leverage large language models (LLMs) as black-box
optimizers without any task-specific fine-tuning, taking advantage of their
ability to contextualize unstructured domain knowledge to propose personalized
treatment plans in natural language. In practice, we implement LEON via
'optimization by prompting,' which uses LLMs as stochastic engines for
proposing treatment designs. Experiments on real-world optimization tasks show
LEON outperforms both traditional and LLM-based methods in proposing
individualized treatments for patients.

</details>


### [206] [FracAug: Fractional Augmentation boost Graph-level Anomaly Detection under Limited Supervision](https://arxiv.org/abs/2509.20978)
*Xiangyu Dong,Xingyi Zhang,Sibo Wang*

Main category: cs.LG

TL;DR: FracAug是一个新颖的即插即用增强框架，通过生成语义一致的图变体和相互验证的伪标签来增强GNN，以解决图级异常检测（GAD）中的标签成本高和数据集不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 高昂的标签成本和数据集不平衡阻碍了图神经网络（GNNs）在如图药学发现等不同领域的图级异常检测（GAD）中的性能。

Method: FracAug学习给定图中的语义，并合成分数变体，以一种新颖的加权距离感知裕度损失为指导。该方法捕获多尺度拓扑以生成多样化的、保留语义的图，不受数据不平衡的影响。然后，FracAug利用来自原始和增强图的预测来伪标签未标记数据，迭代地扩展训练集。

Result: FracAug是一个模型无关的模块，可与各种GNN兼容，具有出色的通用性和有效性。在12个真实数据集上的14个GNN的实验表明，性能持续提升，平均AUROC、AUPRC和F1分数分别提高了5.72%、7.23%和4.18%。

Conclusion: FracAug通过生成语义一致的图变体和使用相互验证进行伪标签，有效地解决了图级异常检测（GAD）中的标签成本高和数据集不平衡问题，并在各种GNN和数据集上展现出持续的性能提升。

Abstract: Graph-level anomaly detection (GAD) is critical in diverse domains such as
drug discovery, yet high labeling costs and dataset imbalance hamper the
performance of Graph Neural Networks (GNNs). To address these issues, we
propose FracAug, an innovative plug-in augmentation framework that enhances
GNNs by generating semantically consistent graph variants and pseudo-labeling
with mutual verification. Unlike previous heuristic methods, FracAug learns
semantics within given graphs and synthesizes fractional variants, guided by a
novel weighted distance-aware margin loss. This captures multi-scale topology
to generate diverse, semantic-preserving graphs unaffected by data imbalance.
Then, FracAug utilizes predictions from both original and augmented graphs to
pseudo-label unlabeled data, iteratively expanding the training set. As a
model-agnostic module compatible with various GNNs, FracAug demonstrates
remarkable universality and efficacy: experiments across 14 GNNs on 12
real-world datasets show consistent gains, boosting average AUROC, AUPRC, and
F1-score by up to 5.72%, 7.23%, and 4.18%, respectively.

</details>


### [207] [Lossless Compression: A New Benchmark for Time Series Model Evaluation](https://arxiv.org/abs/2509.21002)
*Meng Wan,Benxi Tian,Jue Wang,Cui Hui,Ningming Nie,Tiantian Liu,Zongguo Wang,Cao Rongqiang,Peng Shi,Yangang Wang*

Main category: cs.LG

TL;DR: 时间序列模型评估的新范式是无损压缩，它通过香农的信源编码定理与模型容量建立了信息论上的联系，并提供了一个统一的评估标准。新框架TSCom-Bench可以快速适配现有模型进行无损压缩评估，实验表明该方法能发现传统基准忽略的模型弱点。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列模型评估主要关注预测、填充、异常检测和分类等特定任务，未能充分衡量模型是否捕捉了数据的完整生成分布。需要一种新的评估范式来更严格地衡量模型的能力。

Method: 提出将无损压缩作为评估时间序列模型的新范式，基于香农的信源编码定理，将最优压缩长度与负对数似然联系起来，形成统一的信息论标准。定义了标准化的评估协议和度量。开源了TSCom-Bench评估框架，可快速将时间序列模型适配为无损压缩的骨干。

Result: 在多种数据集上，使用TimeXer, iTransformer, PatchTST等先进模型进行实验，结果显示无损压缩评估能够揭示传统基准所忽略的模型在分布方面的弱点。

Conclusion: 无损压缩是一种有原则的时间序列模型评估任务，可以补充和扩展现有的评估方法，为评估模型捕捉数据生成分布的能力提供了更严格的标准。

Abstract: The evaluation of time series models has traditionally focused on four
canonical tasks: forecasting, imputation, anomaly detection, and
classification. While these tasks have driven significant progress, they
primarily assess task-specific performance and do not rigorously measure
whether a model captures the full generative distribution of the data. We
introduce lossless compression as a new paradigm for evaluating time series
models, grounded in Shannon's source coding theorem. This perspective
establishes a direct equivalence between optimal compression length and the
negative log-likelihood, providing a strict and unified information-theoretic
criterion for modeling capacity. Then We define a standardized evaluation
protocol and metrics. We further propose and open-source a comprehensive
evaluation framework TSCom-Bench, which enables the rapid adaptation of time
series models as backbones for lossless compression. Experiments across diverse
datasets on state-of-the-art models, including TimeXer, iTransformer, and
PatchTST, demonstrate that compression reveals distributional weaknesses
overlooked by classic benchmarks. These findings position lossless compression
as a principled task that complements and extends existing evaluation for time
series modeling.

</details>


### [208] [ExMolRL: Phenotype-Target Joint Generation of De Novo Molecules via Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2509.21010)
*Haotian Guo,Hui Liu*

Main category: cs.LG

TL;DR: ExMoIRL是一个结合表型和靶点信息的生成模型，用于新分子生成，能在保证药物性质、靶点亲和力和抑制活性的同时，实现效力、多样性和表型效果的统一。


<details>
  <summary>Details</summary>
Motivation: 当前AI药物设计中，基于表型和基于靶点的策略各有局限，前者实验成本高，后者忽视细胞系统性反应。为了弥补这些不足，需要一个能结合两者优势的新方法。

Method: 提出ExMoIRL框架，该框架整合表型和靶点特异性线索。首先在大量药物诱导的转录组数据上预训练表型引导生成器，然后通过多目标强化学习进行微调。奖励函数结合了对接亲和力、药物相似性评分、排序损失、先验似然正则化和熵最大化，以指导模型生成同时具有效力、多样性并符合表型效果的化学类型。

Result: 在多个已知靶点上，ExMoIRL相比于最先进的基于表型和基于靶点的模型表现更优。生成的分子具有良好的药物性质、高的靶点亲和力，并对癌细胞显示出抑制活性（IC50）。

Conclusion: ExMoIRL展示了结合表型引导和靶点感知策略的协同潜力，为从头药物发现提供了一个更有效的解决方案。

Abstract: The generation of high-quality candidate molecules remains a central
challenge in AI-driven drug design. Current phenotype-based and target-based
strategies each suffer limitations, either incurring high experimental costs or
overlook system-level cellular responses. To bridge this gap, we propose
ExMoIRL, a novel generative framework that synergistically integrates
phenotypic and target-specific cues for de novo molecular generation. The
phenotype-guided generator is first pretrained on expansive drug-induced
transcriptional profiles and subsequently fine-tuned via multi-objective
reinforcement learning (RL). Crucially, the reward function fuses docking
affinity and drug-likeness scores, augmented with ranking loss,
prior-likelihood regularization, and entropy maximization. The multi-objective
RL steers the model toward chemotypes that are simultaneously potent, diverse,
and aligned with the specified phenotypic effects. Extensive experiments
demonstrate ExMoIRL's superior performance over state-of-the-art
phenotype-based and target-based models across multiple well-characterized
targets. Our generated molecules exhibit favorable drug-like properties, high
target affinity, and inhibitory potency (IC50) against cancer cells. This
unified framework showcases the synergistic potential of combining
phenotype-guided and target-aware strategies, offering a more effective
solution for de novo drug discovery.

</details>


### [209] [FERD: Fairness-Enhanced Data-Free Robustness Distillation](https://arxiv.org/abs/2509.20793)
*Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为FERD的数据无关鲁棒性蒸馏框架，用于解决现有方法在鲁棒公平性方面存在的不足，即不同类别之间的鲁棒性差异问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据无关鲁棒性蒸馏方法在提升整体鲁棒性的同时，忽略了不同类别间的鲁棒性公平性问题，导致模型在某些类别上鲁棒性表现较差，且鲁棒性不稳定。本研究旨在解决学生模型在类别间鲁棒性不均衡以及对不同攻击目标鲁棒性不稳定的问题。

Method: FERD框架通过调整对抗样本的比例和分布来解决鲁棒公平性问题。具体而言，它采用了一种鲁棒性引导的类别重加权策略来合成针对鲁棒性较差类别的样本，以提高它们的鲁棒性。此外，FERD还生成了公平感知样本（FAEs），通过在特征层面引入一致性约束来抑制类别特定非鲁棒特征的支配，从而实现更均衡的类别表示。在此基础上，FERD构建了统一目标对抗样本（UTAEs），通过应用统一目标类别约束来避免有偏的攻击方向，将攻击目标分布到所有类别，防止模型过拟合到特定脆弱类别。

Result: 在三个公共数据集上的广泛实验表明，FERD在所有对抗性攻击下都实现了最先进的最差类别鲁棒性。例如，在使用MobileNet-V2在CIFAR-10数据集上进行实验时，FGSM和AutoAttack攻击下的最差类别鲁棒性分别提高了15.1%和6.4%。

Conclusion: FERD框架在鲁棒性和公平性方面均表现出优越的性能，成功解决了数据无关鲁棒性蒸馏中的公平性问题，提高了模型在不同类别和不同攻击下的鲁棒性稳定性。

Abstract: Data-Free Robustness Distillation (DFRD) aims to transfer the robustness from
the teacher to the student without accessing the training data. While existing
methods focus on overall robustness, they overlook the robust fairness issues,
leading to severe disparity of robustness across different categories. In this
paper, we find two key problems: (1) student model distilled with equal class
proportion data behaves significantly different across distinct categories; and
(2) the robustness of student model is not stable across different attacks
target. To bridge these gaps, we present the first Fairness-Enhanced data-free
Robustness Distillation (FERD) framework to adjust the proportion and
distribution of adversarial examples. For the proportion, FERD adopts a
robustness-guided class reweighting strategy to synthesize more samples for the
less robust categories, thereby improving robustness of them. For the
distribution, FERD generates complementary data samples for advanced robustness
distillation. It generates Fairness-Aware Examples (FAEs) by enforcing a
uniformity constraint on feature-level predictions, which suppress the
dominance of class-specific non-robust features, providing a more balanced
representation across all categories. Then, FERD constructs Uniform-Target
Adversarial Examples (UTAEs) from FAEs by applying a uniform target class
constraint to avoid biased attack directions, which distribute the attack
targets across all categories and prevents overfitting to specific vulnerable
categories. Extensive experiments on three public datasets show that FERD
achieves state-of-the-art worst-class robustness under all adversarial attack
(e.g., the worst-class robustness under FGSM and AutoAttack are improved by
15.1\% and 6.4\% using MobileNet-V2 on CIFAR-10), demonstrating superior
performance in both robustness and fairness aspects.

</details>


### [210] [Predicting LLM Reasoning Performance with Small Proxy Model](https://arxiv.org/abs/2509.21013)
*Woosung Koh,Juyoung Suk,Sungjun Han,Se-Young Yun,Jay Shin*

Main category: cs.LG

TL;DR: rBridge是一种有效的方法，使用小模型（小于10亿参数）来预测大模型的推理能力，从而降低数据集优化的成本。


<details>
  <summary>Details</summary>
Motivation: 在预训练大型语言模型成本高昂的情况下，使用小型代理模型优化数据集是必要的。然而，对于推理能力，由于其涌现行为通常在大模型（超过70亿参数）上才可靠出现，这种方法面临挑战。

Method: rBridge通过（1）与预训练目标保持一致，（2）与目标任务保持一致，来让小代理模型（小于10亿参数）有效预测大模型的推理能力。具体而言，rBridge结合了负对数似然和任务一致性，并使用前沿模型的推理轨迹作为黄金标签。

Result: rBridge将数据集排序成本降低了100倍以上，在6个推理基准上实现了10亿至320亿参数模型中最强的相关性，并在10亿至70亿参数模型中实现了跨预训练数据集的零样本预测关系迁移。

Conclusion: rBridge为以更低的成本探索面向推理的预训练提供了一条实用的途径。

Abstract: Given the prohibitive cost of pre-training large language models, it is
essential to leverage smaller proxy models to optimize datasets before scaling
up. However, this approach becomes challenging for reasoning capabilities,
which exhibit emergent behavior that only appear reliably at larger model
sizes, often exceeding 7B parameters. To address this, we introduce rBridge,
showing that small proxies ($\leq$1B) can effectively predict large-model
reasoning by aligning more closely with (1) the pre-training objective and (2)
the target task. rBridge achieves this by weighting negative log-likelihood
with task alignment, using reasoning traces from frontier models as gold
labels. In our experiments, rBridge (i) reduces dataset ranking costs by over
100x relative to the best baseline, (ii) achieves the strongest correlation
across six reasoning benchmarks at 1B to 32B scale, and (iii) zero-shot
transfers predictive relationships across pre-training datasets at 1B to 7B
scale. These findings indicate that rBridge offers a practical path for
exploring reasoning-oriented pre-training at lower cost.

</details>


### [211] [Efficient Ensemble Conditional Independence Test Framework for Causal Discovery](https://arxiv.org/abs/2509.21021)
*Zhengkang Guan,Kun Kuang*

Main category: cs.LG

TL;DR: E-CIT是一个新的框架，通过数据划分、基础CIT子集独立运行和基于稳定分布的p值聚合来降低条件独立性检验的计算成本，并在复杂场景下实现有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 约束基础因果发现方法在处理大规模数据集时面临计算成本高昂的挑战，尤其是在条件独立性检验（CIT）的计算复杂度方面。

Method: E-CIT将数据划分为多个子集，独立地在每个子集上应用基础CIT，并使用一种新颖的、基于稳定分布特性的方法聚合得到的p值。

Result: E-CIT能显著降低CIT和因果发现的计算负担，同时在复杂测试场景和真实世界数据集上表现出有竞争力的性能，甚至有所改进。

Conclusion: E-CIT是一个通用且即插即用的框架，它能有效降低CIT的计算复杂度，并保证理论上的一致性，同时在实践中也能取得良好的效果。

Abstract: Constraint-based causal discovery relies on numerous conditional independence
tests (CITs), but its practical applicability is severely constrained by the
prohibitive computational cost, especially as CITs themselves have high time
complexity with respect to the sample size. To address this key bottleneck, we
introduce the Ensemble Conditional Independence Test (E-CIT), a general and
plug-and-play framework. E-CIT operates on an intuitive divide-and-aggregate
strategy: it partitions the data into subsets, applies a given base CIT
independently to each subset, and aggregates the resulting p-values using a
novel method grounded in the properties of stable distributions. This framework
reduces the computational complexity of a base CIT to linear in the sample size
when the subset size is fixed. Moreover, our tailored p-value combination
method offers theoretical consistency guarantees under mild conditions on the
subtests. Experimental results demonstrate that E-CIT not only significantly
reduces the computational burden of CITs and causal discovery but also achieves
competitive performance. Notably, it exhibits an improvement in complex testing
scenarios, particularly on real-world datasets.

</details>


### [212] [Reinforcement Learning Fine-Tuning Enhances Activation Intensity and Diversity in the Internal Circuitry of LLMs](https://arxiv.org/abs/2509.21044)
*Honglin Zhang,Qianyue Hao,Fengli Xu,Yong Li*

Main category: cs.LG

TL;DR: RL微调能增强LLM的能力，本文利用EAP分析了RL微调对LLM内部机制的影响，发现RL微调能增强激活强度和激活模式的多样性，从而提高泛化能力。DPO模型与PPO和GRPO模型相比，内部变化较弱。


<details>
  <summary>Details</summary>
Motivation: LLM的RL微调如何提高其能力以及其内在机制尚不明确。

Method: 利用EAP分析RL微调前后LLM的内部差异。

Result: RL微调能增强模型激活强度和激活模式的多样性，使信息流更冗余和灵活。DPO模型与PPO和GRPO模型相比，内部变化较弱或不一致。

Conclusion: RL微调系统性地改变了LLM的内部电路，在线RL和基于偏好的方法之间存在方法学上的区别。

Abstract: Large language models (LLMs) acquire extensive prior knowledge through
large-scale pretraining and can be further enhanced via supervised fine-tuning
(SFT) or reinforcement learning (RL)-based post-training. A growing body of
evidence has shown that RL fine-tuning improves the capability of LLMs beyond
what SFT alone achieves. However, the underlying mechanisms why RL fine-tuning
is able to enhance the capability of various LLMs with distinct intrinsic
characteristics remain underexplored. In this study, we draw inspiration from
prior work on edge attribution patching (EAP) to investigate the internal
differences of LLMs before and after RL fine-tuning. Our analysis across
multiple model families shows two robust effects of online RL post-training:
(i) an overall increase in activation intensity, indicating that more internal
pathways are engaged and their signals become stronger, and (ii) greater
diversity in activation patterns, reflected by higher entropy and less
concentrated edge distributions. These changes suggest that RL reshapes
information flow to be both more redundant and more flexible, which may explain
its advantage in generalization. Notably, models fine-tuned with Direct
Preference Optimization (DPO) deviate from these trends, exhibiting
substantially weaker or inconsistent internal changes compared to PPO- and
GRPO-based training. Together, our findings provide a unified view of how RL
fine-tuning systematically alters the internal circuitry of LLMs and highlight
the methodological distinctions between online RL and preference-based
approaches. Our code is open source at
https://anonymous.4open.science/r/llm_rl_probing_analysis-F673.

</details>


### [213] [GeoRef: Referring Expressions in Geometry via Task Formulation, Synthetic Supervision, and Reinforced MLLM-based Solutions](https://arxiv.org/abs/2509.21050)
*Bing Liu,Wenqiang Yv,Xuzheng Yang,Shichang Wang,Junzhuo Liu,Peng Wang,Guoqing Wang,Yang Yang,Heng Tao Shen*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 GeoRef 的新基准数据集和方法，用于解决 AI 几何问题中的指代表达式理解（REC）任务。


<details>
  <summary>Details</summary>
Motivation: 目前 AI 驱动的几何问题解决方法缺乏对几何图形元素进行定位和解释的能力，这阻碍了其在自然语言查询下的准确性。

Method: 提出了 GeoRef 数据集，包含多样化的注释和查询，并利用结构化几何形式语言生成了大规模合成训练数据集。探索了监督微调（SFT）和基于奖励的组相对策略优化（GRPO）两种方法，并提出了一种验证-再生成机制来提高准确性。

Result: GRPO 方法显著优于 SFT 方法，并且验证-再生成机制进一步提高了准确性。即使是先进的多模态大语言模型（MLLM）在此任务上也表现不佳，表明了显式评估和加强几何基础的重要性。此外，在 GeoRef 上训练的模型在下游几何推理任务上也取得了可衡量的改进。

Conclusion: 指代表达式理解（REC）是解决 AI 几何问题的基础，GeoRef 数据集和提出的方法（特别是 GRPO 和验证-再生成机制）能够有效提升模型的几何理解和推理能力，为多模态数学理解奠定了基础。

Abstract: AI-driven geometric problem solving is a complex vision-language task that
requires accurate diagram interpretation, mathematical reasoning, and robust
cross-modal grounding. A foundational yet underexplored capability for this
task is the ability to identify and interpret geometric elements based on
natural language queries. To address this, we introduce the task of Referring
Expression Comprehension (REC) for geometric problems, which evaluates whether
models can localize points, shapes, and spatial relations in diagrams in
response to textual prompts. We present GeoRef, a benchmark dataset constructed
from existing geometric problem corpora, featuring diverse, high-quality
annotations and queries. Due to the lack of annotated data for this task, we
generate a large-scale synthetic training dataset using a structured geometric
formal language, enabling broad coverage of geometric concepts and facilitating
model adaptation. We explore two fine-tuning approaches: Supervised Fine-Tuning
(SFT) and Group Relative Policy Optimization (GRPO). Our results show that GRPO
significantly outperforms SFT by better aligning model behavior with
task-specific rewards. Furthermore, we propose a verify-and-regenerate
mechanism that detects incorrect predictions and re-infers answers using
contextual reasoning history, further boosting accuracy. Notably, even
state-of-the-art Multimodal Large Language Models (MLLMs) struggle with this
task, underscoring the necessity of explicitly evaluating and strengthening
geometric grounding as a prerequisite for robust geometric problem solving.
Moreover, models trained on GeoRef demonstrate measurable improvements on
downstream geometric reasoning tasks, highlighting the broader value of REC as
a foundation for multimodal mathematical understanding.

</details>


### [214] [TyphoonMLA: A Mixed Naive-Absorb MLA Kernel For Shared Prefix](https://arxiv.org/abs/2509.21081)
*Ahmet Caner Yüzügüler,Ahmet Çelik,Jiawei Zhuang,Lukas Cavigelli*

Main category: cs.LG

TL;DR: MLA的两种核实现（naive和absorb）各有优劣。naive核在训练和预填充时更有效，而absorb核在解码时能减少HBM带宽占用。然而，absorb核的计算密集特性限制了其利用数据重用（如共享前缀）带来的性能提升。本文提出的TyphoonMLA是一种混合方法，结合了naive和absorb的优点，通过对计算密集部分使用naive核，对非共享部分使用absorb核，从而利用共享前缀带来的数据重用，并减少带宽需求。


<details>
  <summary>Details</summary>
Motivation: 现有的MLA解码核（如FlashMLA）虽然能减少HBM带宽占用，但其计算密集特性限制了对共享前缀等数据重用机会的利用，无法获得最佳性能。

Method: TyphoonMLA是一种混合方法，结合了naive和absorb两种核实现。它对MLA计算中计算密集的部分（例如涉及共享前缀的部分）采用naive核实现，以利用数据重用；同时，对不需要数据重用的部分采用absorb核实现，以减少HBM带宽占用。

Result: TyphoonMLA在NPU和GPU上分别将MLA架构的注意力计算吞吐量提高了高达3倍和3.24倍，同时HBM占用量仅增加了3%。

Conclusion: TyphoonMLA通过结合naive和absorb核的优势，有效解决了现有MLA解码核在利用数据重用和减少带宽占用方面的权衡问题，显著提高了MLA架构的性能。

Abstract: Multi-Head Latent Attention (MLA) is a recent attention mechanism adopted in
state-of-the-art LLMs such as DeepSeek-v3 and Kimi K2. Thanks to its novel
formulation, MLA allows two functionally equivalent but computationally
distinct kernel implementations: naive and absorb. While the naive kernels
(e.g., FlashAttention) are typically preferred in training and prefill for
their computational efficiency, existing decoding kernels (e.g., FlashMLA) rely
on the absorb method to minimize HBM bandwidth usage. However, the
compute-bound nature of the absorb implementations prohibits performance
benefits from data reuse opportunities in attention calculations, such as
shared prefixes. In this work, we introduce TyphoonMLA, a hybrid approach that
combines naive and absorb formulations to harness the strengths of both.
TyphoonMLA effectively leverages the shared prefix by applying the naive
formulation to the compute-bound parts of attention calculations, while
reducing the bandwidth requirements for non-shared parts by using the absorb
formulation. As a result, TyphoonMLA improves the throughput of attention
calculations in MLA architectures by up to 3x and 3.24x on NPU and GPUs, with
only a 3% overhead in HBM size.

</details>


### [215] [Sparse Representations Improve Adversarial Robustness of Neural Network Classifiers](https://arxiv.org/abs/2509.21130)
*Killian Steunou,Sigurd Saue,Théo Druilhe*

Main category: cs.LG

TL;DR: SPCA是一种比PCA更能抵抗对抗性攻击的线性降维方法，通过稀疏投影降低对抗性输入的敏感性，并在理论和实验上得到了验证。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在图像分类方面表现优异，但容易受到精心设计的对抗性扰动的攻击。因此，需要开发能够防御这些攻击的简单、数据自适应的防御方法。

Method: 本研究通过经验比较和理论分析，评估了标准主成分分析（PCA）及其稀疏变体（SPCA）作为下游分类器前端特征提取器的性能。理论上，推导了SPCA特征的线性判别器的精确鲁棒性认证，并证明了稀疏性通过Lipschitz组合论证降低了非线性判别器的算子范数界限。实验上，在SPCA之后添加一个小型非线性网络，并在强白盒和黑盒攻击下评估其性能。

Result: 理论分析表明，SPCA的认证半径随对偶范数`W^T u`的收缩而增长，其中`W`是投影，`u`是判别器权重。实验证明，SPCA在对抗性攻击下性能下降比PCA更平缓，同时保持了具有竞争力的准确性。

Conclusion: SPCA通过稀疏投影机制有效降低了对抗性输入的敏感性，这一优势在非线性模型中也得以延续。SPCA是一种有前景的对抗性防御方法。

Abstract: Deep neural networks perform remarkably well on image classification tasks
but remain vulnerable to carefully crafted adversarial perturbations. This work
revisits linear dimensionality reduction as a simple, data-adapted defense. We
empirically compare standard Principal Component Analysis (PCA) with its sparse
variant (SPCA) as front-end feature extractors for downstream classifiers, and
we complement these experiments with a theoretical analysis. On the theory
side, we derive exact robustness certificates for linear heads applied to SPCA
features: for both $\ell_\infty$ and $\ell_2$ threat models (binary and
multiclass), the certified radius grows as the dual norms of $W^\top u$ shrink,
where $W$ is the projection and $u$ the head weights. We further show that for
general (non-linear) heads, sparsity reduces operator-norm bounds through a
Lipschitz composition argument, predicting lower input sensitivity.
Empirically, with a small non-linear network after the projection, SPCA
consistently degrades more gracefully than PCA under strong white-box and
black-box attacks while maintaining competitive clean accuracy. Taken together,
the theory identifies the mechanism (sparser projections reduce adversarial
leverage) and the experiments verify that this benefit persists beyond the
linear setting. Our code is available at
https://github.com/killian31/SPCARobustness.

</details>


### [216] [A Unified Framework for Diffusion Model Unlearning with f-Divergence](https://arxiv.org/abs/2509.21167)
*Nicola Novello,Federico Fontana,Luigi Cinque,Deniz Gunduz,Andrea M. Tonello*

Main category: cs.LG

TL;DR: 该研究提出了一个统一的f散度框架，用于改进文本到图像（T2I）扩散模型（DM）的知识遗忘，解决了现有基于均方误差（MSE）方法的局限性，并允许根据具体应用选择最优散度以平衡遗忘和概念保留。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像（T2I）扩散模型（DM）的遗忘方法通常基于最小化目标和锚定概念之间的均方误差（MSE），而该研究旨在提出一个更通用的框架来改进遗忘过程。

Method: 提出一个统一的f散度框架，该框架将现有的基于MSE的遗忘方法视为其特例，并允许使用任何f散度。通过分析不同f散度对算法收敛性和遗忘质量的影响，来选择最优散度。

Result: 研究表明，f散度框架相比于传统的MSE方法，提供了更灵活的遗忘范式，能够根据具体应用选择最优散度，从而更好地平衡遗忘能力和概念的保留。

Conclusion: 提出的统一f散度框架为T2I扩散模型的知识遗忘提供了一个灵活的解决方案，允许根据具体应用的需求，在遗忘影响和概念保持之间进行权衡，从而实现更优的遗忘效果。

Abstract: Machine unlearning aims to remove specific knowledge from a trained model.
While diffusion models (DMs) have shown remarkable generative capabilities,
existing unlearning methods for text-to-image (T2I) models often rely on
minimizing the mean squared error (MSE) between the output distribution of a
target and an anchor concept. We show that this MSE-based approach is a special
case of a unified $f$-divergence-based framework, in which any $f$-divergence
can be utilized. We analyze the benefits of using different $f$-divergences,
that mainly impact the convergence properties of the algorithm and the quality
of unlearning. The proposed unified framework offers a flexible paradigm that
allows to select the optimal divergence for a specific application, balancing
different trade-offs between aggressive unlearning and concept preservation.

</details>


### [217] [GraphUniverse: Enabling Systematic Evaluation of Inductive Generalization](https://arxiv.org/abs/2509.21097)
*Louis Van Langendonck,Guillermo Bernárdez,Nina Miolane,Pere Barlet-Ros*

Main category: cs.LG

TL;DR: 该研究提出了GraphUniverse框架，用于生成一系列图以系统地评估图学习模型在不同图上的归纳泛化能力，并发现现有模型的泛化能力与在单图上的表现并不一致。


<details>
  <summary>Details</summary>
Motivation: 现有图学习模型在泛化到新图方面的能力评估不足，尤其是在归纳设置下。

Method: 提出GraphUniverse框架，生成具有持久语义社区的图，控制同质性和度分布等结构属性，以进行大规模的归纳泛化评估。

Result: 在多种模型架构（GNN、图Transformer、拓扑架构）的基准测试中，发现强的图内（transductive）性能不能预测归纳（inductive）泛化能力。模型对分布变化的鲁棒性高度依赖于模型架构和初始图的同质性水平。

Conclusion: GraphUniverse提供了一个灵活且可扩展的平台，用于开发更鲁棒、更具普遍泛化能力的图学习模型，包括下一代图基础模型。

Abstract: A fundamental challenge in graph learning is understanding how models
generalize to new, unseen graphs. While synthetic benchmarks offer controlled
settings for analysis, existing approaches are confined to single-graph,
transductive settings where models train and test on the same graph structure.
Addressing this gap, we introduce GraphUniverse, a framework for generating
entire families of graphs to enable the first systematic evaluation of
inductive generalization at scale. Our core innovation is the generation of
graphs with persistent semantic communities, ensuring conceptual consistency
while allowing fine-grained control over structural properties like homophily
and degree distributions. This enables crucial but underexplored robustness
tests, such as performance under controlled distribution shifts. Benchmarking a
wide range of architectures -- from GNNs to graph transformers and topological
architectures -- reveals that strong transductive performance is a poor
predictor of inductive generalization. Furthermore, we find that robustness to
distribution shift is highly sensitive not only to model architecture choice
but also to the initial graph regime (e.g., high vs. low homophily). Beyond
benchmarking, GraphUniverse's flexibility and scalability can facilitate the
development of robust and truly generalizable architectures -- including
next-generation graph foundation models. An interactive demo is available at
https://graphuniverse.streamlit.app.

</details>


### [218] [Differential-Integral Neural Operator for Long-Term Turbulence Forecasting](https://arxiv.org/abs/2509.21196)
*Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu*

Main category: cs.LG

TL;DR: 微分积分神经网络算子（DINO）通过分解物理算子来解决长期湍流预测中的误差累积问题，并在2D科尔莫戈罗夫流动基准测试中取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法（特别是神经算子）在长期自回归预测中存在灾难性误差累积和物理保真度损失的问题，无法同时捕捉湍流动力学的局部耗散效应和全局非局部相互作用。

Method: 提出微分积分神经网络算子（DINO），一个基于算子分解的第一性原理框架。DINO通过并行分支显式地模拟湍流演化，学习局部微分算子（通过约束卷积网络实现，可证明收敛于导数）和全局积分算子（通过学习数据驱动的全局核的Transformer架构实现）。

Result: 在具有挑战性的2D科尔莫戈罗夫流动基准测试中，DINO在长期预测方面显著优于最先进的模型，成功抑制了数百个时间步的误差累积，并保持了涡度场和能量谱的高保真度。

Conclusion: DINO通过显式建模物理算子，为物理一致的长期湍流预测设定了新的基准。

Abstract: Accurately forecasting the long-term evolution of turbulence represents a
grand challenge in scientific computing and is crucial for applications ranging
from climate modeling to aerospace engineering. Existing deep learning methods,
particularly neural operators, often fail in long-term autoregressive
predictions, suffering from catastrophic error accumulation and a loss of
physical fidelity. This failure stems from their inability to simultaneously
capture the distinct mathematical structures that govern turbulent dynamics:
local, dissipative effects and global, non-local interactions. In this paper,
we propose the
{\textbf{\underline{D}}}ifferential-{\textbf{\underline{I}}}ntegral
{\textbf{\underline{N}}}eural {\textbf{\underline{O}}}perator (\method{}), a
novel framework designed from a first-principles approach of operator
decomposition. \method{} explicitly models the turbulent evolution through
parallel branches that learn distinct physical operators: a local differential
operator, realized by a constrained convolutional network that provably
converges to a derivative, and a global integral operator, captured by a
Transformer architecture that learns a data-driven global kernel. This
physics-based decomposition endows \method{} with exceptional stability and
robustness. Through extensive experiments on the challenging 2D Kolmogorov flow
benchmark, we demonstrate that \method{} significantly outperforms
state-of-the-art models in long-term forecasting. It successfully suppresses
error accumulation over hundreds of timesteps, maintains high fidelity in both
the vorticity fields and energy spectra, and establishes a new benchmark for
physically consistent, long-range turbulence forecast.

</details>


### [219] [Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning](https://arxiv.org/abs/2509.21126)
*Xiefeng Wu,Jing Zhao,Shu Zhang,Mingyu Hu*

Main category: cs.LG

TL;DR: VARL框架利用大型语言模型（VLM）的领域知识为强化学习（RL）代理提供动作建议，以提高在线RL的样本效率，特别是在稀疏奖励任务中，并且不引入显著的计算开销。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习（RL）在复杂任务中耗时，因为需要大量的交互步骤来学习最优的Q函数。视觉-语言-动作（VLA）策略在解决多样化任务方面显示出潜力，但其在低级控制方面的性能有限，并且通常需要特定任务的专家演示进行微调。

Method: VARL框架利用大型语言模型（VLM）的领域知识为强化学习（RL）代理提供动作建议。与以往的方法不同，VARL提供动作建议，而不是设计启发式奖励，从而保证了最优性和收敛性不变。建议的动作增加了样本多样性，并最终提高了样本效率，特别是在稀疏奖励任务中。

Result: VARL在多样化的环境和代理设置中得到了验证，结果表明VARL在不引入显著的计算开销的情况下大大提高了样本效率。

Conclusion: VARL是一个通用的在线强化学习框架，可以直接从头开始在真实环境中应用强化学习。

Abstract: Online reinforcement learning in complex tasks is time-consuming, as massive
interaction steps are needed to learn the optimal Q-function.Vision-language
action (VLA) policies represent a promising direction for solving diverse
tasks; however, their performance on low-level control remains limited, and
effective deployment often requires task-specific expert demonstrations for
fine-tuning. In this paper, we propose \textbf{VARL} (\textbf{V}LM as
\textbf{A}ction advisor for online \textbf{R}einforcement \textbf{L}earning), a
framework that leverages the domain knowledge of vision-language models (VLMs)
to provide action suggestions for reinforcement learning agents. Unlike
previous methods, VARL provides action suggestions rather than designing
heuristic rewards, thereby guaranteeing unchanged optimality and convergence.
The suggested actions increase sample diversity and ultimately improve sample
efficiency, especially in sparse-reward tasks. To validate the effectiveness of
VARL, we evaluate it across diverse environments and agent settings. Results
show that VARL greatly improves sample efficiency without introducing
significant computational overhead. These advantages make VARL a general
framework for online reinforcement learning and make it feasible to directly
apply reinforcement learning from scratch in real-world environments.

</details>


### [220] [LAVA: Explainability for Unsupervised Latent Embeddings](https://arxiv.org/abs/2509.21149)
*Ivan Stresec,Joana P. Gonçalves*

Main category: cs.LG

TL;DR: LAVA是一种模型无关的后验方法，用于通过分析输入特征与潜在嵌入结构之间的关系来解释无监督学习模型。


<details>
  <summary>Details</summary>
Motivation: 无监督学习模型在科学发现中发挥着重要作用，但其可解释性仍然是一个挑战，特别是当模型的输出是多维潜在嵌入而不是明确定义的之时。现有的解释方法要么过于细粒度，要么过于简化，无法有效解释潜在空间的局部结构。

Method: LAVA将潜在空间表示为一系列“局部区域”，并使用原始特征之间的相关性来描述这些区域。通过揭示整个潜在空间中重复出现的特征相关性模式，LAVA能够解释局部嵌入的组织结构。

Result: 在MNIST和单细胞肾脏数据集的UMAP嵌入上进行的实验表明，LAVA能够捕获相关的特征关联，并揭示出跨越看似遥远区域的、具有视觉和生物学意义的局部模式。

Conclusion: LAVA提供了一种有效的、可扩展的方法来解释无监督学习模型的潜在空间，通过关注局部结构和特征关联，弥合了现有方法在可解释性方面的不足。

Abstract: Unsupervised black-box models can be drivers of scientific discovery, but
remain difficult to interpret. Crucially, discovery hinges on understanding the
model output, which is often a multi-dimensional latent embedding rather than a
well-defined target. While explainability for supervised learning usually seeks
to uncover how input features are used to predict a target, its unsupervised
counterpart should relate input features to the structure of the learned latent
space. Adaptations of supervised model explainability for unsupervised learning
provide either single-sample or dataset-wide summary explanations. However,
without automated strategies of relating similar samples to one another guided
by their latent proximity, explanations remain either too fine-grained or too
reductive to be meaningful. This is especially relevant for manifold learning
methods that produce no mapping function, leaving us only with the relative
spatial organization of their embeddings. We introduce Locality-Aware Variable
Associations (LAVA), a post-hoc model-agnostic method designed to explain local
embedding organization through its relationship with the input features. To
achieve this, LAVA represents the latent space as a series of localities
(neighborhoods) described in terms of correlations between the original
features, and then reveals reoccurring patterns of correlations across the
entire latent space. Based on UMAP embeddings of MNIST and a single-cell kidney
dataset, we show that LAVA captures relevant feature associations, with
visually and biologically relevant local patterns shared among seemingly
distant regions of the latent spaces.

</details>


### [221] [GRPO is Secretly a Process Reward Model](https://arxiv.org/abs/2509.21154)
*Michael Sullivan*

Main category: cs.LG

TL;DR: GRPO 强化学习算法在某些假设下会产生一个非平凡的过程奖励模型 (PRM)。研究表明这些假设在现实条件下也成立。在此基础上，我们发现 GRPO 目标函数存在一个缺陷，即不均匀的过程步骤会阻碍探索和利用。我们提出了一种改进算法 ($\egular$-GRPO)，实验证明该算法能提升 LLM 的验证准确率、下游推理任务表现，并更快地达到峰值性能。这表明 GRPO 内在的 PRM 结构可以被利用来提升模型性能，而无需昂贵的显式 PRM。


<details>
  <summary>Details</summary>
Motivation: 证明 GRPO 强化学习算法在特定假设下会诱导出一个非平凡的过程奖励模型 (PRM)，并验证这些假设在现实条件下的适用性，同时找出 GRPO 目标函数中存在的问题。

Method: 首先理论证明 GRPO 诱导 PRM，然后通过实验验证这一现象。接着，利用 GRPO-as-a-PRM 框架识别 GRPO 目标函数的缺陷，并提出改进算法（$\egular$-GRPO）。最后，通过实验比较标准 GRPO 和 $\egular$-GRPO 在 LLM 训练中的表现。

Result: GRPO 在特定假设下确实会诱导出一个非平凡的 PRM。 GRPO 目标函数中存在缺陷，即不均匀的过程步骤会阻碍探索和利用。 改进算法 $\egular$-GRPO 能够提升 LLM 的验证准确率、下游推理任务表现，并加快达到峰值性能的速度。 使用 GRPO 内在的 PRM 结构比使用昂贵的、显式定义的 PRM 效果更好，并且对训练时间和成本影响很小。

Conclusion: GRPO 算法内在的 PRM 结构可以被有效利用来提升模型性能，改进后的 $\egular$-GRPO 算法在训练效率和模型表现上优于标准 GRPO，并且无需额外的显式 PRM 成本。

Abstract: We prove theoretically that the GRPO RL algorithm induces a non-trivial
process reward model (PRM), under certain assumptions regarding within-group
overlap of token sequences across completions. We then show empirically that
these assumptions are met under real-world conditions: GRPO does in fact induce
a non-trivial PRM. Leveraging the framework of GRPO-as-a-PRM, we identify a
flaw in the GRPO objective: non-uniformly distributed process steps hinder both
exploration and exploitation (under different conditions). We propose a simple
modification to the algorithm to mitigate this defect ($\lambda$-GRPO), and
show that LLMs trained with $\lambda$-GRPO achieve higher validation accuracy
and performance on downstream reasoning tasks$-$and reach peak performance more
rapidly$-$than LLMs trained with standard GRPO. Our results call into question
the advantage of costly, explicitly-defined PRMs for GRPO: we show that it is
possible to instead leverage the hidden, built-in PRM structure within the
vanilla GRPO algorithm to boost model performance with a negligible impact on
training time and cost.

</details>


### [222] [Towards Foundation Models for Zero-Shot Time Series Anomaly Detection: Leveraging Synthetic Data and Relative Context Discrepancy](https://arxiv.org/abs/2509.21190)
*Tian Lan,Hao Duong Le,Jinbo Li,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.LG

TL;DR: TimeRCD是一个基于相对上下文差异（RCD）的新型时间序列异常检测（TSAD）基础模型，通过学习区分相邻时间窗口的差异来检测异常，解决了现有基于重建模型在区分细微异常和复杂正常模式方面的不足。该模型在合成数据集上进行预训练，并在多项TSAD任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测（TSAD）模型在零样本泛化方面存在挑战，特别是基于重建的模型在区分细微异常和复杂正常模式时效果不佳，导致假阴性和假阳性率高。

Method: 提出了一种名为相对上下文差异（RCD）的新型预训练范式，并基于此构建了TimeRCD模型。该模型不依赖于输入重建，而是显式地训练模型通过检测相邻时间窗口之间的显著差异来识别异常。模型采用了标准的Transformer架构来实现这种关系学习。为了支持这种范式，开发了一个具有token级异常标签的大规模、多样化合成语料库。

Result: 在零样本TSAD任务的广泛实验中，TimeRCD在多样化的数据集上显著优于现有的通用和特定异常检测的基础模型。

Conclusion: RCD范式的优越性得到了验证，为构建鲁棒且可泛化的时间序列异常检测基础模型提供了一条新的有效途径。

Abstract: Time series anomaly detection (TSAD) is a critical task, but developing
models that generalize to unseen data in a zero-shot manner remains a major
challenge. Prevailing foundation models for TSAD predominantly rely on
reconstruction-based objectives, which suffer from a fundamental objective
mismatch: they struggle to identify subtle anomalies while often
misinterpreting complex normal patterns, leading to high rates of false
negatives and positives. To overcome these limitations, we introduce
\texttt{TimeRCD}, a novel foundation model for TSAD built upon a new
pre-training paradigm: Relative Context Discrepancy (RCD). Instead of learning
to reconstruct inputs, \texttt{TimeRCD} is explicitly trained to identify
anomalies by detecting significant discrepancies between adjacent time windows.
This relational approach, implemented with a standard Transformer architecture,
enables the model to capture contextual shifts indicative of anomalies that
reconstruction-based methods often miss. To facilitate this paradigm, we
develop a large-scale, diverse synthetic corpus with token-level anomaly
labels, providing the rich supervisory signal necessary for effective
pre-training. Extensive experiments demonstrate that \texttt{TimeRCD}
significantly outperforms existing general-purpose and anomaly-specific
foundation models in zero-shot TSAD across diverse datasets. Our results
validate the superiority of the RCD paradigm and establish a new, effective
path toward building robust and generalizable foundation models for time series
anomaly detection.

</details>


### [223] [Tree Search for LLM Agent Reinforcement Learning](https://arxiv.org/abs/2509.21240)
*Yuxiang Ji,Ziyu Ma,Yong Wang,Guanhua Chen,Xiangxiang Chu,Liaoni Wu*

Main category: cs.LG

TL;DR: Tree-GRPO通过引入基于树搜索的 agrupamiento de agentes RL 方法，解决了 LLM 在长期和多轮任务中面临的稀疏监督问题，通过共享前缀和树状轨迹，有效增加了采样效率，并实现了步进式过程监督，实验证明其优于基于链的 RL 方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有纯粹基于结果奖励的 RL 方法在长期和多轮 agent 任务中面临的稀疏监督问题。

Method: 提出了一种基于树搜索的分组 agent RL 方法（Tree-GRPO），其中每个树节点代表一个完整的 agent 交互步骤。该方法通过共享公共前缀来增加采样效率，并利用树状轨迹构建步进式过程监督信号，估计了树内和树间的组相对优势。

Result: 实验表明，Tree-GRPO 在 11 个数据集和 3 种 QA 任务上均优于基于链的 RL 方法。

Conclusion: Tree-GRPO 通过其创新的树状结构和分组相对策略优化方法，有效解决了稀疏监督问题，提高了 LLM 在复杂任务中的表现。

Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced
the agentic capabilities of large language models (LLMs). In long-term and
multi-turn agent tasks, existing approaches driven solely by outcome rewards
often suffer from the problem of sparse supervision. To address the challenge,
we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped
agent RL method based on tree search, where each tree node represents the
complete agent interaction step. By sharing common prefixes, the tree search
sampling increases the number of rollouts achievable within a fixed budget of
tokens or tool calls. Moreover, we find that the tree-structured trajectory
naturally allows the construction of step-wise process supervised signals even
using only the outcome reward. Based on this, Tree-GRPO estimates the grouped
relative advantages both on intra-tree and inter-tree levels. Through
theoretical analysis, we demonstrate that the objective of intra-tree level
group relative policy optimization is equivalent to that of step-level direct
preference learning. Experiments across 11 datasets and 3 types of QA tasks
demonstrate the superiority of the proposed tree-based RL over the chain-based
RL method.

</details>


### [224] [Explaining Fine Tuned LLMs via Counterfactuals A Knowledge Graph Driven Framework](https://arxiv.org/abs/2509.21241)
*Yucheng Wang,Ziyang Chen,Md Faisal Kabir*

Main category: cs.LG

TL;DR: LoRA 微调 LLM 的新颖框架，利用知识图谱进行反事实解释，揭示了模型结构依赖性。


<details>
  <summary>Details</summary>
Motivation: 理解 LoRA 微调如何改变 LLM 的结构推理和语义行为仍然是一个公开的挑战。

Method: 提出一个新颖的框架，通过基于知识图谱的反事实来解释微调的 LLM。构建了特定领域的生物信息学工具知识图谱（BioToolKG），并设计了一个反事实基础的微调 LLM 解释器（CFFTLLMExplainer），该解释器学习图节点和边的软掩码，以生成最小的结构扰动，从而产生最大的语义差异。该方法联合优化了结构稀疏性和语义差异，同时强制执行可解释性约束，如熵正则化和边平滑。

Result: 将该框架应用于微调的 LLaMA 模型，发现反事实掩码揭示了模型的结构依赖性，并与 LoRA 引起 的参数变化一致。

Conclusion: 这项工作为理解微调 LLM 的内部机制提供了新的见解，并强调了反事实图谱作为可解释人工智能的潜在工具。

Abstract: The widespread adoption of Low-Rank Adaptation (LoRA) has enabled large
language models (LLMs) to acquire domain-specific knowledge with remarkable
efficiency. However, understanding how such a fine-tuning mechanism alters a
model's structural reasoning and semantic behavior remains an open challenge.
This work introduces a novel framework that explains fine-tuned LLMs via
counterfactuals grounded in knowledge graphs. Specifically, we construct
BioToolKG, a domain-specific heterogeneous knowledge graph in bioinformatics
tools and design a counterfactual-based fine-tuned LLMs explainer
(CFFTLLMExplainer) that learns soft masks over graph nodes and edges to
generate minimal structural perturbations that induce maximum semantic
divergence. Our method jointly optimizes structural sparsity and semantic
divergence while enforcing interpretability preserving constraints such as
entropy regularization and edge smoothness. We apply this framework to a
fine-tuned LLaMA-based LLM and reveal that counterfactual masking exposes the
model's structural dependencies and aligns with LoRA-induced parameter shifts.
This work provides new insights into the internal mechanisms of fine-tuned LLMs
and highlights counterfactual graphs as a potential tool for interpretable AI.

</details>


### [225] [A Causality-Aware Spatiotemporal Model for Multi-Region and Multi-Pollutant Air Quality Forecasting](https://arxiv.org/abs/2509.21260)
*Junxin Lu,Shiliang Sun*

Main category: cs.LG

TL;DR: AirPCM是一个创新的深度时空预测模型，能够处理多区域、多污染物以及气象因素的复杂交互，实现了高精度的空气质量预测，并超越了现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 现有的空气质量预测方法在处理多污染物交互、动态气象条件以及区域异质性方面存在挑战，难以实现跨空间分布式监测站的精确和可扩展预测。

Method: 提出了一种名为AirPCM的新型深度时空预测模型，该模型集成了多区域、多污染物动态以及显式气象-污染物因果关系建模。其统一架构能够联合捕捉跨站点空间相关性、时间自相关性以及气象-污染物动态因果关系。

Result: 通过在多尺度真实世界数据集上的广泛评估，AirPCM在预测精度和泛化能力方面持续优于最先进的基线模型。其长期预测能力为未来空气质量趋势和潜在高风险窗口提供了可操作的见解。

Conclusion: AirPCM模型能够实现精细化、可解释的多污染物预测，覆盖不同地理和时间尺度，包括突发污染事件，并为环境治理和碳减排规划提供及时的循证支持。

Abstract: Air pollution, a pressing global problem, threatens public health,
environmental sustainability, and climate stability. Achieving accurate and
scalable forecasting across spatially distributed monitoring stations is
challenging due to intricate multi-pollutant interactions, evolving
meteorological conditions, and region specific spatial heterogeneity. To
address this challenge, we propose AirPCM, a novel deep spatiotemporal
forecasting model that integrates multi-region, multi-pollutant dynamics with
explicit meteorology-pollutant causality modeling. Unlike existing methods
limited to single pollutants or localized regions, AirPCM employs a unified
architecture to jointly capture cross-station spatial correlations, temporal
auto-correlations, and meteorology-pollutant dynamic causality. This empowers
fine-grained, interpretable multi-pollutant forecasting across varying
geographic and temporal scales, including sudden pollution episodes. Extensive
evaluations on multi-scale real-world datasets demonstrate that AirPCM
consistently surpasses state-of-the-art baselines in both predictive accuracy
and generalization capability. Moreover, the long-term forecasting capability
of AirPCM provides actionable insights into future air quality trends and
potential high-risk windows, offering timely support for evidence-based
environmental governance and carbon mitigation planning.

</details>


### [226] [It's Not You, It's Clipping: A Soft Trust-Region via Probability Smoothing for LLM RL](https://arxiv.org/abs/2509.21282)
*Madeleine Dwyer,Adam Sobey,Adriane Chapman*

Main category: cs.LG

TL;DR: PSPO通过向旧策略平滑当前策略的概率来稳定LLM的RL更新，优于传统的比例裁剪方法。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM强化学习方法（如PPO和GRPO）依赖于比例裁剪来稳定更新，但这会丢失信息并产生梯度不连续性。

Method: 提出概率平滑策略优化（PSPO），在计算重要性比率之前，将当前策略的概率向旧（行为）策略平滑，类似于标签平滑。PSPO保留了梯度信号，并通过插值向旧策略创建了一个软信任区域，以防止不稳定的更新。

Result: 在GRPO（GR-PSPO）中实现的PSPO，在GSM8K上微调了Qwen2.5-0.5B和Qwen2.5-1.5B模型。与未裁剪的GRPO相比，GR-PSPO取得了相似的性能，但提高了推理能力，产生了更清晰、更简洁、更符合逻辑的响应。与裁剪的GRPO相比，PSPO显著提高了0.5B和1.5B模型的性能，在GSM8K上的性能提升超过20%（0.5B模型从17.6%提升到39.7%，1.5B模型从37.8%提升到59.4%）。

Conclusion: PSPO是一种比比例裁剪更优越的稳定LLM强化学习更新的方法，它通过概率平滑在不丢失信息或产生梯度不连续性的情况下，实现了更强的性能和更好的推理能力。

Abstract: Training large language models (LLMs) with reinforcement learning (RL)
methods such as PPO and GRPO commonly relies on ratio clipping to stabilise
updates. While effective at preventing instability, clipping discards
information and introduces gradient discontinuities. We propose Probability
Smoothing Policy Optimisation (PSPO), which smooths the current policy's
probabilities toward the old (behaviour) policy before computing the importance
ratio, analogous to label smoothing. Unlike clipping, PSPO preserves gradient
signal, while interpolation toward the old policy creates a soft trust region
that discourages large, destabilising updates, with formal guarantees.
  We instantiate PSPO within GRPO (GR-PSPO) and fine-tune Qwen2.5-0.5B and
Qwen2.5-1.5B on GSM8K, evaluating on GSM8K test and the cross-dataset
generalisation on SVAMP, ASDiv, and MATH-500. Relative to unclipped GRPO
(single iteration; no data reuse, ratio always = 1), GR-PSPO achieves similar
performance but improves the reasoning leading to clearer and more concise
responses which are more logical. Compared to clipped GRPO, GR-PSPO
substantially improves performance both the 0.5B and 1.5B models, with a boost
of over 20% on GSM8K (39.7% vs. 17.6% for 0.5B, 59.4% vs. 37.8% for 1.5B).

</details>


### [227] [No Prior, No Leakage: Revisiting Reconstruction Attacks in Trained Neural Networks](https://arxiv.org/abs/2509.21296)
*Yehonatan Refael,Guy Smorodinsky,Ofir Lindenbaum,Itay Safran*

Main category: cs.LG

TL;DR: 神经网络的训练数据记忆对隐私和安全构成威胁，现有重构方法虽有演示但理论基础薄弱。本文从分析现有方法弱点入手，证明在无先验知识情况下，重构不一定可靠，精确复制仅凭偶然。研究表明，训练更充分的网络反而对重构攻击更具抵抗力，有助于平衡隐私和泛化。


<details>
  <summary>Details</summary>
Motivation: 现有关于神经网络模型参数可直接重构训练数据的研究，其可靠性缺乏理论支撑，且可能与泛化能力所需的隐式偏倚相冲突。

Method: 分析现有重构方法的局限性，并从理论上证明在无先验知识的情况下，存在无限多个可能与真实训练数据相距甚远的解，以及通过实验展示精确复制的偶然性。

Result: 证明了在无先验知识条件下，现有重构方法可能不可靠，精确复制训练数据仅是偶然现象。实验证实，训练更充分的模型（满足隐式偏倚条件更强）反而对重构攻击的抵抗力更强。

Conclusion: 重构攻击的可靠性有限，尤其在无先验知识时。模型泛化能力的提升（如更充分的训练）反而能增强其隐私性，从而在隐私和泛化之间取得平衡。

Abstract: The memorization of training data by neural networks raises pressing concerns
for privacy and security. Recent work has shown that, under certain conditions,
portions of the training set can be reconstructed directly from model
parameters. Some of these methods exploit implicit bias toward margin
maximization, suggesting that properties often regarded as beneficial for
generalization may actually compromise privacy. Yet despite striking empirical
demonstrations, the reliability of these attacks remains poorly understood and
lacks a solid theoretical foundation. In this work, we take a complementary
perspective: rather than designing stronger attacks, we analyze the inherent
weaknesses and limitations of existing reconstruction methods and identify
conditions under which they fail. We rigorously prove that, without
incorporating prior knowledge about the data, there exist infinitely many
alternative solutions that may lie arbitrarily far from the true training set,
rendering reconstruction fundamentally unreliable. Empirically, we further
demonstrate that exact duplication of training examples occurs only by chance.
Our results refine the theoretical understanding of when training set leakage
is possible and offer new insights into mitigating reconstruction attacks.
Remarkably, we demonstrate that networks trained more extensively, and
therefore satisfying implicit bias conditions more strongly -- are, in fact,
less susceptible to reconstruction attacks, reconciling privacy with the need
for strong generalization in this setting.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [228] [Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation](https://arxiv.org/abs/2509.20486)
*Sven Ochs,Philip Schörner,Marc René Zofka,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 通过融合激光雷达和摄像头语义分割信息，提升了自动驾驶定位的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 处理激光雷达点云数据中的多样化传感器和配置带来的分割挑战，并利用语义信息增强基于激光雷达的定位技术。

Method: 将激光雷达点投影到摄像头语义分割空间，并利用Depth-Anything网络进行图像分割，同时使用自适应分割网络进行激光雷达分割，并以RTK-GNSS作为地面真值。

Result: 在CoCar NextGen平台和卡尔斯鲁厄55公里城市道路测试中，该多模态方法验证了其在复杂真实环境下的可靠性和精确性。

Conclusion: 提出的多模态融合方法为更可靠、更精确的自主导航系统铺平了道路，特别是在复杂的真实世界环境中。

Abstract: Semantic segmentation of LiDAR data presents considerable challenges,
particularly when dealing with diverse sensor types and configurations.
However, incorporating semantic information can significantly enhance the
accuracy and robustness of LiDAR-based localization techniques for autonomous
mobile systems. We propose an approach that integrates semantic camera data
with LiDAR segmentation to address this challenge. By projecting LiDAR points
into the semantic segmentation space of the camera, our method enhances the
precision and reliability of the LiDAR-based localization pipeline.
  For validation, we utilize the CoCar NextGen platform from the FZI Research
Center for Information Technology, which offers diverse sensor modalities and
configurations. The sensor setup of CoCar NextGen enables a thorough analysis
of different sensor types. Our evaluation leverages the state-of-the-art
Depth-Anything network for camera image segmentation and an adaptive
segmentation network for LiDAR segmentation. To establish a reliable ground
truth for LiDAR-based localization, we make us of a Global Navigation Satellite
System (GNSS) solution with Real-Time Kinematic corrections (RTK).
Additionally, we conduct an extensive 55 km drive through the city of
Karlsruhe, Germany, covering a variety of environments, including urban areas,
multi-lane roads, and rural highways. This multimodal approach paves the way
for more reliable and precise autonomous navigation systems, particularly in
complex real-world environments.

</details>


### [229] [Revisiting Formal Methods for Autonomous Robots: A Structured Survey](https://arxiv.org/abs/2509.20488)
*Atef Azaiez,David A. Anisi,Marie Farrell,Matt Luckcuck*

Main category: cs.RO

TL;DR: 该论文对形式化方法（FM）在机器人自主系统（RAS）中的应用进行了结构化文献回顾，并展示了初步结果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在梳理和分析形式化方法在机器人自主系统中的应用现状，包括方法、形式化、与人工智能的结合趋势，并与已有研究进行对比，以揭示该领域的演变和成熟度。

Method: 采用结构化文献回顾方法，包括数据库选择、搜索字符串、筛选器以及对识别出的论文进行协作审查，对形式化方法在机器人自主系统中的应用进行分类和统计。

Result: 研究对所使用的形式化方法和形式化进行了分类和统计，并考察了形式化方法在亚符号人工智能驱动的机器人自主系统中的应用及其随时间的发展。与先前调查相比，一些趋势得以延续，同时出现了新的趋势，例如形式化综合方法和概率验证技术的采用显著增加。

Conclusion: 形式化方法在机器人自主系统中的应用正在不断发展，并且出现了新的趋势，例如形式化综合和概率验证技术的应用日益增多，这表明该研究领域正在不断成熟。

Abstract: This paper presents the initial results from our structured literature review
on applications of Formal Methods (FM) to Robotic Autonomous Systems (RAS). We
describe our structured survey methodology; including database selection and
associated search strings, search filters and collaborative review of
identified papers. We categorise and enumerate the FM approaches and formalisms
that have been used for specification and verification of RAS. We investigate
FM in the context of sub-symbolic AI-enabled RAS and examine the evolution of
how FM is used over time in this field. This work complements a pre-existing
survey in this area and we examine how this research area has matured over
time. Specifically, our survey demonstrates that some trends have persisted as
observed in a previous survey. Additionally, it recognized new trends that were
not considered previously including a noticeable increase in adopting Formal
Synthesis approaches as well as Probabilistic Verification Techniques.

</details>


### [230] [Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting](https://arxiv.org/abs/2509.20499)
*Boqi Li,Siyuan Li,Weiyi Wang,Anran Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: 本文提出了一种将路点预测器与多模态大语言模型（MLLM）相结合的零样本框架，用于解决连续环境中的视觉语言导航（VLN）问题。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型和机器人技术的快速发展，视觉语言导航（VLN）已成为一个关键任务，具有广泛的实际应用。在连续环境中进行VLN更具挑战性，因为智能体必须同时理解自然语言指令、感知周围环境并规划低级动作。

Method: 提出了一种零样本框架，该框架整合了一个简化的路点预测器和一个多模态大语言模型（MLLM）。该预测器在一个抽象的障碍物地图上操作，生成线性可达的路点，并将其整合到一个具有显式访问记录的动态更新的拓扑图中。图和访问信息被编码到提示中，以实现对空间结构和探索历史的推理，从而鼓励探索并为MLLM提供局部路径规划能力以进行错误纠正。

Result: 在R2R-CE和RxR-CE上的大量实验表明，该方法在零样本设置下取得了最先进的性能，成功率分别为41%和36%，优于先前最先进的方法。

Conclusion: 该框架通过整合路点预测和MLLM，有效地解决了连续环境下的VLN问题，并在实验中取得了优于现有方法的性能。

Abstract: With the rapid progress of foundation models and robotics, vision-language
navigation (VLN) has emerged as a key task for embodied agents with broad
practical applications. We address VLN in continuous environments, a
particularly challenging setting where an agent must jointly interpret natural
language instructions, perceive its surroundings, and plan low-level actions.
We propose a zero-shot framework that integrates a simplified yet effective
waypoint predictor with a multimodal large language model (MLLM). The predictor
operates on an abstract obstacle map, producing linearly reachable waypoints,
which are incorporated into a dynamically updated topological graph with
explicit visitation records. The graph and visitation information are encoded
into the prompt, enabling reasoning over both spatial structure and exploration
history to encourage exploration and equip MLLM with local path planning for
error correction. Extensive experiments on R2R-CE and RxR-CE show that our
method achieves state-of-the-art zero-shot performance, with success rates of
41% and 36%, respectively, outperforming prior state-of-the-art methods.

</details>


### [231] [MELEGROS: Monolithic Elephant-inspired Gripper with Optical Sensors](https://arxiv.org/abs/2509.20510)
*Petr Trunin,Diana Cafiso,Anderson Brazil Nardin,Trevor Exley,Lucia Beccai*

Main category: cs.RO

TL;DR: MELEGROS是一个一体化的软体机械手，受大象鼻子启发，集成了光学传感器和气动腔室，能够进行多种抓取和感知任务。


<details>
  <summary>Details</summary>
Motivation: 受非洲象鼻的启发，开发一种集结构、驱动和传感于一体的仿生抓手机器人，重点在于将传感能力作为其内在的、共同制造的能力。

Method: 使用单一的软体树脂材料和连续的3D打印技术，将六个光学波导传感器和五个气动腔室集成到一个气动驱动的晶格结构中，形成MELEGROS。

Result: MELEGROS（132克）能够提起超过自身两倍的重量，执行捏、舀、伸等仿生动作，并能抓取葡萄等易碎物品。其集成光学传感器能区分触觉、弯曲和腔室变形，实现多功能感知。

Conclusion: MELEGROS展示了一种新的软体机器人范式，其中完全嵌入的传感和连续结构能够固有地支持多样化、仿生的操作。

Abstract: The elephant trunk exemplifies a natural gripper where structure, actuation,
and sensing are seamlessly integrated. Inspired by the distal morphology of the
African elephant trunk, we present MELEGROS, a Monolithic ELEphant-inspired
GRipper with Optical Sensors, emphasizing sensing as an intrinsic,
co-fabricated capability. Unlike multi-material or tendon-based approaches,
MELEGROS directly integrates six optical waveguide sensors and five pneumatic
chambers into a pneumatically actuated lattice structure (12.5 mm cell size)
using a single soft resin and one continuous 3D print. This eliminates
mechanical mismatches between sensors, actuators, and body, reducing model
uncertainty and enabling simulation-guided sensor design and placement. Only
four iterations were required to achieve the final prototype, which features a
continuous structure capable of elongation, compression, and bending while
decoupling tactile and proprioceptive signals. MELEGROS (132 g) lifts more than
twice its weight, performs bioinspired actions such as pinching, scooping, and
reaching, and delicately grasps fragile items like grapes. The integrated
optical sensors provide distinct responses to touch, bending, and chamber
deformation, enabling multifunctional perception. MELEGROS demonstrates a new
paradigm for soft robotics where fully embedded sensing and continuous
structures inherently support versatile, bioinspired manipulation.

</details>


### [232] [Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation](https://arxiv.org/abs/2509.20516)
*Prasanna Sriganesh,Barath Satheeshkumar,Anushree Sabnis,Matthew Travers*

Main category: cs.RO

TL;DR: 该研究提出了一种新的感知-动作框架，使四足机器人能够在物体被遮挡时，通过利用本体感觉反馈来预测和跟踪被推动物体的位移，从而成功地在楼梯等杂乱环境中清除路径。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在杂乱环境中自主导航，并与障碍物进行物理交互以清理路径，但现有方法在处理如楼梯杂乱环境中的受控交互（如单腿推物）时面临挑战，尤其是在物体被遮挡的情况下。

Method: 提出了一种交互感知状态估计循环，该循环利用关于足部接触和腿部位置的本体感觉反馈来预测被推动物体在被遮挡期间的位移，并利用该预测来指导感知系统在交互后重新检测物体，从而在部分推动后仍能实现精确跟踪。

Result: 在波士顿动力Spot机器人上实现了该方法，实验结果表明，与开环基线方法相比，该交互感知方法在楼梯上推动物体的任务成功率和跟踪精度更高。

Conclusion: 该方法通过一个交互感知状态估计循环，实现了机器人对被遮挡物体的鲁棒跟踪和交互，提高了在复杂环境中的任务成功率和安全性。

Abstract: For robots to operate autonomously in densely cluttered environments, they
must reason about and potentially physically interact with obstacles to clear a
path. Safely clearing a path on challenging terrain, such as a cluttered
staircase, requires controlled interaction. For example, a quadrupedal robot
that pushes objects out of the way with one leg while maintaining a stable
stance with its three other legs. However, tightly coupled physical actions,
such as one-legged pushing, create new constraints on the system that can be
difficult to predict at design time. In this work, we present a new method that
addresses one such constraint, wherein the object being pushed by a quadrupedal
robot with one of its legs becomes occluded from the robot's sensors during
manipulation. To address this challenge, we present a tightly coupled
perception-action framework that enables the robot to perceive clutter, reason
about feasible push paths, and execute the clearing maneuver. Our core
contribution is an interaction-aware state estimation loop that uses
proprioceptive feedback regarding foot contact and leg position to predict an
object's displacement during the occlusion. This prediction guides the
perception system to robustly re-detect the object after the interaction,
closing the loop between action and sensing to enable accurate tracking even
after partial pushes. Using this feedback allows the robot to learn from
physical outcomes, reclassifying an object as immovable if a push fails due to
it being too heavy. We present results of implementing our approach on a Boston
Dynamics Spot robot that show our interaction-aware approach achieves higher
task success rates and tracking accuracy in pushing objects on stairs compared
to open-loop baselines.

</details>


### [233] [Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning](https://arxiv.org/abs/2509.20541)
*Anujith Muraleedharan,Anamika J H*

Main category: cs.RO

TL;DR: SPARQ通过仅在学习停滞或恶化时请求反馈来提高机器人学习的效率，在模拟的UR5机器人抓取任务中，SPARQ实现了近乎完美的成功率，同时反馈成本仅为‘总是查询’基线的一半。


<details>
  <summary>Details</summary>
Motivation: 现有的结合人类反馈的强化学习（HiL-RL）方法通常假设有充足的反馈，这在现实世界的机器人部署中不太实用，因为人类反馈成本高且有限。

Method: 提出了一种名为SPARQ的进度感知查询策略，该策略仅在学习停滞或恶化时才请求反馈，从而减少不必要的查询。

Result: 在模拟的UR5机器人抓取任务中，SPARQ实现了近乎完美的任务成功率，其性能与‘总是查询’基线相当，但反馈成本仅为其一半。与‘随机查询’相比，SPARQ的学习更稳定、更高效，并且显著优于‘无反馈’训练。

Conclusion: 选择性的、基于进度的查询策略可以提高HiL-RL在机器人上的效率和可扩展性，使其在满足现实人类成本限制的情况下更具实用性。

Abstract: Human feedback can greatly accelerate robot learning, but in real-world
settings, such feedback is costly and limited. Existing human-in-the-loop
reinforcement learning (HiL-RL) methods often assume abundant feedback,
limiting their practicality for physical robot deployment. In this work, we
introduce SPARQ, a progress-aware query policy that requests feedback only when
learning stagnates or worsens, thereby reducing unnecessary oracle calls. We
evaluate SPARQ on a simulated UR5 cube-picking task in PyBullet, comparing
against three baselines: no feedback, random querying, and always querying. Our
experiments show that SPARQ achieves near-perfect task success, matching the
performance of always querying while consuming about half the feedback budget.
It also provides more stable and efficient learning than random querying, and
significantly improves over training without feedback. These findings suggest
that selective, progress-based query strategies can make HiL-RL more efficient
and scalable for robots operating under realistic human effort constraints.

</details>


### [234] [GraspFactory: A Large Object-Centric Grasping Dataset](https://arxiv.org/abs/2509.20550)
*Srinidhi Kalgundi Srinivas,Yash Shukla,Adam Arnold,Sachin Chitta*

Main category: cs.RO

TL;DR: GraspFactory 是一个包含超过 1.09 亿个 6-DoF 抓取的数据集，用于训练机器人抓取模型，以应对各种新颖物体，并在模拟和现实世界中展示了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人抓取模型在处理新颖物体时泛化能力不足，而现实世界的物体种类繁多，需要更具泛化性的抓取模型。

Method: 创建了一个名为 GraspFactory 的大规模数据集，其中包含 1.09 亿个 6-DoF 抓取，涵盖了 Franka Panda 和 Robotiq 2F-85 两种夹爪以及大量不同的物体。然后，使用该数据集的一个子集训练了一个抓取模型，并验证了其在模拟和现实世界中的泛化能力。

Result: GraspFactory 数据集包含 1.09 亿个抓取，其中 Franka Panda 抓取了 14,690 个物体，Robotiq 2F-85 抓取了 33,710 个物体。在 GraspFactory 子集上训练的模型在模拟和现实世界中都展现出了良好的泛化能力。

Conclusion: GraspFactory 数据集能够有效地训练出泛化能力强的机器人抓取模型，能够应对各种新颖物体，为工业自动化领域带来了重要的进步。

Abstract: Robotic grasping is a crucial task in industrial automation, where robots are
increasingly expected to handle a wide range of objects. However, a significant
challenge arises when robot grasping models trained on limited datasets
encounter novel objects. In real-world environments such as warehouses or
manufacturing plants, the diversity of objects can be vast, and grasping models
need to generalize to this diversity. Training large, generalizable
robot-grasping models requires geometrically diverse datasets. In this paper,
we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps
collectively for the Franka Panda (with 14,690 objects) and Robotiq 2F-85
grippers (with 33,710 objects). GraspFactory is designed for training
data-intensive models, and we demonstrate the generalization capabilities of
one such model trained on a subset of GraspFactory in both simulated and
real-world settings. The dataset and tools are made available for download at
https://graspfactory.github.io/.

</details>


### [235] [Uncertainty-Aware Active Source Tracking of Marine Pollution using Unmanned Surface Vehicles](https://arxiv.org/abs/2509.20593)
*Song Ma,Richard Bucknall,Yuanchang Liu*

Main category: cs.RO

TL;DR: 提出一个不确定性感知的无人航行器（USV）海洋污染源追踪框架，结合高精度海洋污染扩散模拟和信息路径规划技术，用于海洋环境中的污染源识别。


<details>
  <summary>Details</summary>
Motivation: 开发用于无人航行器（USV）的海洋污染源追踪框架，以提高海洋污染事件的自主环境监测能力。

Method: 基于机器人操作系统（ROS）实现，整合高精度海洋污染扩散模拟和信息路径规划技术，处理实时传感器数据以更新概率性污染源位置估计，并量化预测的不确定性。

Result: 在模拟环境中，针对不同污染源位置、流况和起始位置进行的实验表明，该框架能够高精度、高可靠性、高效率地定位污染源。

Conclusion: 该框架能够为无人航行器提供自主的环境监测能力，支持对海洋污染事件的快速响应。

Abstract: This paper proposes an uncertainty-aware marine pollution source tracking
framework for unmanned surface vehicles (USVs). By integrating high-fidelity
marine pollution dispersion simulation with informative path planning
techniques, we demonstrate effective identification of pollution sources in
marine environments. The proposed approach is implemented based on Robot
Operating System (ROS), processing real-time sensor data to update
probabilistic source location estimates. The system progressively refines the
estimation of source location while quantifying uncertainty levels in its
predictions. Experiments conducted in simulated environments with varying
source locations, flow conditions, and starting positions demonstrate the
framework's ability to localise pollution sources with high accuracy. Results
show that the proposed approach achieves reliable source localisation
efficiently. This work contributes to the development of full autonomous
environmental monitoring capabilities essential for rapid response to marine
pollution incidents.

</details>


### [236] [Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation](https://arxiv.org/abs/2509.20623)
*Satyajeet Das,Darren Chiu,Zhehui Huang,Lars Lindemann,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 通过在推理时编辑预训练策略的中间激活来提高多旋翼导航的安全性，无需修改策略权重。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习策略在避开障碍物时仍易发生碰撞，而重新训练成本高昂且可能损害已有技能。

Method: 提出一种名为LAE的框架，包括一个在线分类器来检测与不良行为相关的中间激活，以及一个激活编辑模块来修改这些激活以提高安全性。具体来说，通过训练一个潜在的碰撞世界模型来预测碰撞前激活，从而促使更早、更谨慎的规避反应。

Result: 在模拟和真实Crazyflie实验中，LAE将碰撞次数减少了近90%，并显著提高了无碰撞轨迹的比例，同时保持了任务完成率。

Conclusion: LAE是一种轻量级的框架，可以在资源受限的硬件上实现部署后对机器人策略进行精炼，从而有效提高多旋翼导航的安全性。

Abstract: Reinforcement learning has enabled significant progress in complex domains
such as coordinating and navigating multiple quadrotors. However, even
well-trained policies remain vulnerable to collisions in obstacle-rich
environments. Addressing these infrequent but critical safety failures through
retraining or fine-tuning is costly and risks degrading previously learned
skills. Inspired by activation steering in large language models and latent
editing in computer vision, we introduce a framework for inference-time Latent
Activation Editing (LAE) that refines the behavior of pre-trained policies
without modifying their weights or architecture. The framework operates in two
stages: (i) an online classifier monitors intermediate activations to detect
states associated with undesired behaviors, and (ii) an activation editing
module that selectively modifies flagged activations to shift the policy
towards safer regimes. In this work, we focus on improving safety in
multi-quadrotor navigation. We hypothesize that amplifying a policy's internal
perception of risk can induce safer behaviors. We instantiate this idea through
a latent collision world model trained to predict future pre-collision
activations, thereby prompting earlier and more cautious avoidance responses.
Extensive simulations and real-world Crazyflie experiments demonstrate that LAE
achieves statistically significant reduction in collisions (nearly 90% fewer
cumulative collisions compared to the unedited baseline) and substantially
increases the fraction of collision-free trajectories, while preserving task
completion. More broadly, our results establish LAE as a lightweight paradigm,
feasible on resource-constrained hardware, for post-deployment refinement of
learned robot policies.

</details>


### [237] [Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments](https://arxiv.org/abs/2509.20635)
*Matheus P. Angarola,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 一个分层强化学习框架，通过利用地形专业策略和课程学习，在复杂环境中提高了盲行运动机器人的敏捷性和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在无地形信息的情况下，为行走的机器人在多样化、非结构化的地形上实现鲁棒和敏捷的运动。 

Method: 使用分层强化学习框架，结合地形专业策略和课程学习。

Result: 在模拟环境中，与通用策略相比，成功率提高了16%，并且在低摩擦和不连续的地形上，随着速度目标的增加，跟踪误差更低。

Conclusion: 该方法在混合地形场景中表现出优越的适应性和鲁棒性。

Abstract: Legged robots must exhibit robust and agile locomotion across diverse,
unstructured terrains, a challenge exacerbated under blind locomotion settings
where terrain information is unavailable. This work introduces a hierarchical
reinforcement learning framework that leverages terrain-specialized policies
and curriculum learning to enhance agility and tracking performance in complex
environments. We validated our method on simulation, where our approach
outperforms a generalist policy by up to 16% in success rate and achieves lower
tracking errors as the velocity target increases, particularly on low-friction
and discontinuous terrains, demonstrating superior adaptability and robustness
across mixed-terrain scenarios.

</details>


### [238] [Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation](https://arxiv.org/abs/2509.20646)
*Sun Zhaole,Xiaofeng Mao,Jihong Zhu,Yuanlong Zhang,Robert B. Fisher*

Main category: cs.RO

TL;DR: 通过设计新型的吸盘手（SLeap Hand），我们摆脱了模仿人手的限制，实现了超越人手的灵巧操作，并简化了数据收集。


<details>
  <summary>Details</summary>
Motivation: 模仿人手在灵巧抓取方面存在局限，限制了机器人能力并增加了数据收集难度。现有的力闭合抓取方法复杂且不稳定。

Method: 提出了一种名为SLeap Hand的新型多指手，其指尖集成了吸盘，利用吸附力替代了复杂的多点接触力闭合。

Result: SLeap Hand能够实现稳定、单点的吸附抓取，简化了遥操作和数据收集。它解锁了人类难以完成的任务，如单手剪纸和手中写字。

Conclusion: 摆脱拟人化限制，设计新型机器人本体（如SLeap Hand）不仅能降低数据收集的门槛，还能实现稳定、单手的、超越人类能力的操作。

Abstract: Dexterous in-hand manipulation remains a foundational challenge in robotics,
with progress often constrained by the prevailing paradigm of imitating the
human hand. This anthropomorphic approach creates two critical barriers: 1) it
limits robotic capabilities to tasks humans can already perform, and 2) it
makes data collection for learning-based methods exceedingly difficult. Both
challenges are caused by traditional force-closure which requires coordinating
complex, multi-point contacts based on friction, normal force, and gravity to
grasp an object. This makes teleoperated demonstrations unstable and amplifies
the sim-to-real gap for reinforcement learning. In this work, we propose a
paradigm shift: moving away from replicating human mechanics toward the design
of novel robotic embodiments. We introduce the \textbf{S}uction
\textbf{Leap}-Hand (SLeap Hand), a multi-fingered hand featuring integrated
fingertip suction cups that realize a new form of suction-enabled dexterity. By
replacing complex force-closure grasps with stable, single-point adhesion, our
design fundamentally simplifies in-hand teleoperation and facilitates the
collection of high-quality demonstration data. More importantly, this
suction-based embodiment unlocks a new class of dexterous skills that are
difficult or even impossible for the human hand, such as one-handed paper
cutting and in-hand writing. Our work demonstrates that by moving beyond
anthropomorphic constraints, novel embodiments can not only lower the barrier
for collecting robust manipulation data but also enable the stable,
single-handed completion of tasks that would typically require two human hands.
Our webpage is https://sites.google.com/view/sleaphand.

</details>


### [239] [Cyber Racing Coach: A Haptic Shared Control Framework for Teaching Advanced Driving Skills](https://arxiv.org/abs/2509.20653)
*Congkai Shen,Siyuan Yu,Yifan Weng,Haoran Ma,Chen Li,Hiroshi Yasuda,James Dallas,Michael Thompson,John Subosits,Tulga Ersal*

Main category: cs.RO

TL;DR: 本研究提出了一种触觉共享控制框架，用于教授人类驾驶员高级驾驶技能，并通过赛车教练的场景进行了评估。


<details>
  <summary>Details</summary>
Motivation: 以往的研究虽然证明了共享控制方案在性能和安全方面的优势，但并未评估其对复杂和高要求任务中技能获取的影响。因此，本研究旨在弥合这一差距，评估基于触觉共享控制范式的网络赛车教练框架在帮助人类驾驶员获取高性能驾驶技能方面的表现。

Method: 本研究创建了一个基于触觉共享控制范式的网络赛车教练框架，该框架包含一个能够与人类在高性能驾驶场景中进行协作的自主驾驶系统，以及一个根据人类驾驶员在训练期间的表现逐渐减少转向辅助的触觉共享控制机制和淡出方案。

Result: 与基准测试（自学和全辅助训练）相比，人类受试者研究结果表明，所提出的框架有助于人类驾驶员掌握更高超的赛车技能，从而提高性能和一致性。

Conclusion: 本研究提出的触觉共享控制框架能够有效地帮助人类驾驶员在赛车等高要求场景下学习和提升驾驶技能。

Abstract: This study introduces a haptic shared control framework designed to teach
human drivers advanced driving skills. In this context, shared control refers
to a driving mode where the human driver collaborates with an autonomous
driving system to control the steering of a vehicle simultaneously. Advanced
driving skills are those necessary to safely push the vehicle to its handling
limits in high-performance driving such as racing and emergency obstacle
avoidance. Previous research has demonstrated the performance and safety
benefits of shared control schemes using both subjective and objective
evaluations. However, these schemes have not been assessed for their impact on
skill acquisition on complex and demanding tasks. Prior research on long-term
skill acquisition either applies haptic shared control to simple tasks or
employs other feedback methods like visual and auditory aids. To bridge this
gap, this study creates a cyber racing coach framework based on the haptic
shared control paradigm and evaluates its performance in helping human drivers
acquire high-performance driving skills. The framework introduces (1) an
autonomous driving system that is capable of cooperating with humans in a
highly performant driving scenario; and (2) a haptic shared control mechanism
along with a fading scheme to gradually reduce the steering assistance from
autonomy based on the human driver's performance during training. Two
benchmarks are considered: self-learning (no assistance) and full assistance
during training. Results from a human subject study indicate that the proposed
framework helps human drivers develop superior racing skills compared to the
benchmarks, resulting in better performance and consistency.

</details>


### [240] [EEG-Driven AR-Robot System for Zero-Touch Grasping Manipulation](https://arxiv.org/abs/2509.20656)
*Junzhe Wang,Jiarui Xie,Pengfei Hao,Zheng Li,Yi Cai*

Main category: cs.RO

TL;DR: 该研究提出了一种结合运动想象（MI）脑电图（EEG）解码、增强现实（AR）神经反馈和机器人抓取的新型闭环BCI-AR-机器人系统，以实现零接触操作，特别适用于有运动障碍的人群。


<details>
  <summary>Details</summary>
Motivation: 现有BCI-机器人系统在EEG信号的噪声和不稳定性、目标选择的灵活性以及缺乏实际闭环验证方面存在局限，阻碍了其在辅助场景中的实际应用。

Method: 开发了一个包含14通道EEG头戴设备用于个体化MI校准，基于智能手机的AR界面用于多目标导航并提供方向一致的反馈以增强稳定性，以及一个结合决策输出和视觉姿态估计的机器人手臂以实现自主抓取。

Result: MI训练准确率达到93.1%，平均信息传输率（ITR）为14.8比特/分钟；与静态、假对照和无AR基线相比，AR神经反馈显著提高了持续控制能力（SCI=0.210），并实现了最高的ITR（21.3比特/分钟）；闭环抓取成功率为97.2%，效率高，用户报告的控制效果良好。

Conclusion: AR反馈能显著稳定基于EEG的控制，所提出的框架能够实现鲁棒的零接触抓取，为辅助机器人应用和未来人机交互模式带来了进展。

Abstract: Reliable brain-computer interface (BCI) control of robots provides an
intuitive and accessible means of human-robot interaction, particularly
valuable for individuals with motor impairments. However, existing BCI-Robot
systems face major limitations: electroencephalography (EEG) signals are noisy
and unstable, target selection is often predefined and inflexible, and most
studies remain restricted to simulation without closed-loop validation. These
issues hinder real-world deployment in assistive scenarios. To address them, we
propose a closed-loop BCI-AR-Robot system that integrates motor imagery
(MI)-based EEG decoding, augmented reality (AR) neurofeedback, and robotic
grasping for zero-touch operation. A 14-channel EEG headset enabled
individualized MI calibration, a smartphone-based AR interface supported
multi-target navigation with direction-congruent feedback to enhance stability,
and the robotic arm combined decision outputs with vision-based pose estimation
for autonomous grasping. Experiments are conducted to validate the framework:
MI training achieved 93.1 percent accuracy with an average information transfer
rate (ITR) of 14.8 bit/min; AR neurofeedback significantly improved sustained
control (SCI = 0.210) and achieved the highest ITR (21.3 bit/min) compared with
static, sham, and no-AR baselines; and closed-loop grasping achieved a 97.2
percent success rate with good efficiency and strong user-reported control.
These results show that AR feedback substantially stabilizes EEG-based control
and that the proposed framework enables robust zero-touch grasping, advancing
assistive robotic applications and future modes of human-robot interaction.

</details>


### [241] [Next-Generation Aerial Robots -- Omniorientational Strategies: Dynamic Modeling, Control, and Comparative Analysis](https://arxiv.org/abs/2509.21210)
*Ali Kafili Gavgani,Amin Talaeizadeh,Aria Alasty,Hossein Nejat Pishkenari,Esmaeil Najafi*

Main category: cs.RO

TL;DR: 本文介绍了能够实现六自由度运动的“全向”多旋翼无人机，通过倾斜旋翼轴实现


<details>
  <summary>Details</summary>
Motivation: 传统的反装反作用力多旋翼系统由于其驱动不足的特性，在独立控制姿态和位置方面存在局限性。本研究提出了一种新颖的多旋翼配置，通过引入额外的控制输入来操纵螺旋桨轴的角度，从而克服了这些限制，实现了“全向”飞行能力。

Method: 本文详细推导了所提出配置的动力学模型，并使用 Simscape Multibody 仿真进行了验证。设计了两种控制器：一种是用于处理干扰的滑模控制器，另一种是集成了线性与非线性分配器以及重力补偿的新型 PID 控制器。此外，还实现了一种定制的控制分配策略来处理输入非仿射系统，并定义了“功率消耗因子”以优化电池寿命。

Result: 所提出的控制器能够有效应对严苛的干扰和不确定性。仿真结果对不同配置和控制器的功率消耗进行了比较和分析。同时，还进行了定性比较，以评估不同类型不确定性对控制系统的影响，并指出了潜在的模型或硬件改进方向。

Conclusion: 本研究为设计“全向”多旋翼无人机提供了实用的见解和未来研究的路线图，尤其是在配置选择和控制器设计方面。研究结果有助于设计者根据具体的设计目标来选择合适的配置和控制器，并为实现更高效、更可靠的无人机系统提供了指导。

Abstract: Conventional multi-rotors are under-actuated systems, hindering them from
independently controlling attitude from position. In this study, we present
several distinct configurations that incorporate additional control inputs for
manipulating the angles of the propeller axes. This addresses the mentioned
limitations, making the systems "omniorientational". We comprehensively derived
detailed dynamic models for all introduced configurations and validated by a
methodology using Simscape Multibody simulations. Two controllers are designed:
a sliding mode controller for robust handling of disturbances and a novel
PID-based controller with gravity compensation integrating linear and
non-linear allocators, designed for computational efficiency. A custom control
allocation strategy is implemented to manage the input-non-affine nature of
these systems, seeking to maximize battery life by minimizing the "Power
Consumption Factor" defined in this study. Moreover, the controllers
effectively managed harsh disturbances and uncertainties. Simulations compare
and analyze the proposed configurations and controllers, majorly considering
their power consumption. Furthermore, we conduct a qualitative comparison to
evaluate the impact of different types of uncertainties on the control system,
highlighting areas for potential model or hardware improvements. The analysis
in this study provides a roadmap for future researchers to design
omniorientational drones based on their design objectives, offering practical
insights into configuration selection and controller design. This research
aligns with the project SAC-1, one of the objectives of Sharif AgRoLab.

</details>


### [242] [Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks](https://arxiv.org/abs/2509.20674)
*Zeyu Han,Shuocheng Yang,Minghan Zhu,Fang Zhang,Shaobing Xu,Maani Ghaffari,Jianqiang Wang*

Main category: cs.RO

TL;DR: Equi-RO是一个基于4D毫米波雷达的鲁棒的自动驾驶车辆和机器人里程计估计框架，在各种天气条件下表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在GPS受限的环境中，自主车辆和机器人需要准确的里程计估计。尽管激光雷达和相机在恶劣天气下表现不佳，但4D毫米波雷达提供了一种全天候运行且能测量速度的强大替代方案。

Method: Equi-RO算法将多普勒速度预处理为图中的不变节点和边特征，并使用单独的网络来处理不变和等变特征。基于图的架构增强了稀疏雷达数据中的特征聚合，以改进帧间对应。

Result: 在公开数据集和自收集数据集上的实验表明，Equi-RO在准确性和鲁棒性方面优于最先进的算法。与最佳基线相比，在开源数据集上的平移和旋转精度分别提高了10.7%和20.0%。

Conclusion: Equi-RO通过利用4D毫米波雷达的优势，为在恶劣天气条件下提供高精度里程计估计提供了一种有前途的解决方案。

Abstract: Autonomous vehicles and robots rely on accurate odometry estimation in
GPS-denied environments. While LiDARs and cameras struggle under extreme
weather, 4D mmWave radar emerges as a robust alternative with all-weather
operability and velocity measurement. In this paper, we introduce Equi-RO, an
equivariant network-based framework for 4D radar odometry. Our algorithm
pre-processes Doppler velocity into invariant node and edge features in the
graph, and employs separate networks for equivariant and invariant feature
processing. A graph-based architecture enhances feature aggregation in sparse
radar data, improving inter-frame correspondence. Experiments on the
open-source dataset and self-collected dataset show Equi-RO outperforms
state-of-the-art algorithms in accuracy and robustness. Overall, our method
achieves 10.7% and 20.0% relative improvements in translation and rotation
accuracy, respectively, compared to the best baseline on the open-source
dataset.

</details>


### [243] [Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation](https://arxiv.org/abs/2509.20681)
*Wei-Teng Chu,Tianyi Zhang,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 该论文提出了一种名为FINS的框架，能够从单个或少数几张图像中高效地构建隐式表面和SDF场，解决了传统方法需要多视图图像和长时间训练的问题。


<details>
  <summary>Details</summary>
Motivation: 现有从隐式表示重建表面（如NeuS）的方法通常需要大量多视图图像和较长的训练时间，限制了其在机器人避障和路径规划等领域的应用。

Method: FINS框架整合了多分辨率哈希网格编码器以及轻量级的几何和颜色头，并利用预训练的深度学习模型来估计图像中的几何信息，从而能够仅使用单个RGB图像进行训练。

Result: FINS框架在表面重建和SDF场估计方面，相比现有技术，具有更快的收敛速度和更高的精度。

Conclusion: FINS框架能够从单个或少量图像高效地重建高精度表面和SDF场，在机器人表面跟随任务中表现出良好的应用前景，并可扩展到各种基准数据集。

Abstract: Implicit representations have been widely applied in robotics for obstacle
avoidance and path planning. In this paper, we explore the problem of
constructing an implicit distance representation from a single image. Past
methods for implicit surface reconstruction, such as \emph{NeuS} and its
variants generally require a large set of multi-view images as input, and
require long training times. In this work, we propose Fast Image-to-Neural
Surface (FINS), a lightweight framework that can reconstruct high-fidelity
surfaces and SDF fields based on a single or a small set of images. FINS
integrates a multi-resolution hash grid encoder with lightweight geometry and
color heads, making the training via an approximate second-order optimizer
highly efficient and capable of converging within a few seconds. Additionally,
we achieve the construction of a neural surface requiring only a single RGB
image, by leveraging pre-trained foundation models to estimate the geometry
inherent in the image. Our experiments demonstrate that under the same
conditions, our method outperforms state-of-the-art baselines in both
convergence speed and accuracy on surface reconstruction and SDF field
estimation. Moreover, we demonstrate the applicability of FINS for robot
surface following tasks and show its scalability to a variety of benchmark
datasets.

</details>


### [244] [RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks](https://arxiv.org/abs/2509.20688)
*Shouren Mao,Minghao Qin,Wei Dong,Huajian Liu,Yongzhuo Gao*

Main category: cs.RO

TL;DR: RAM-NAS是一种资源感知的多目标神经架构搜索方法，通过子网互蒸馏和知识蒸馏来优化模型训练，并利用延迟预测器在搜索阶段考虑机器人硬件资源，以平衡模型精度和延迟。


<details>
  <summary>Details</summary>
Motivation: 传统的神经架构搜索（NAS）方法在训练超网络和考虑实际机器人硬件资源方面存在不足。

Method: 提出了一种名为RAM-NAS的资源感知多目标NAS方法。该方法包括子网互蒸馏（利用三明治规则采样所有子网进行互蒸馏）和解耦知识蒸馏（DKD）损失来增强logits蒸馏性能。为了在考虑硬件资源的同时加速搜索过程，利用三种机器人边缘硬件的数据训练延迟代理预测器，以在搜索阶段估计硬件推理延迟，从而实现统一的多目标进化搜索，平衡模型精度和延迟。

Result: RAM-NAS发现的模型家族在ImageNet上的top-1准确率范围为76.7%至81.4%。所采用的资源感知多目标NAS显著降低了模型在机器人边缘硬件上的推理延迟。在下游任务的实验中，与基于MobileNetv3的方法相比，在所有三种硬件类型上，检测和分割的推理时间均有所减少，验证了该方法的扩展性。

Conclusion: RAM-NAS填补了神经架构搜索在机器人硬件资源感知方面的空白，能够设计出在机器人硬件上具有高精度和低延迟的轻量级模型。

Abstract: Neural architecture search (NAS) has shown great promise in automatically
designing lightweight models. However, conventional approaches are insufficient
in training the supernet and pay little attention to actual robot hardware
resources. To meet such challenges, we propose RAM-NAS, a resource-aware
multi-objective NAS method that focuses on improving the supernet pretrain and
resource-awareness on robot hardware devices. We introduce the concept of
subnets mutual distillation, which refers to mutually distilling all subnets
sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge
Distillation (DKD) loss to enhance logits distillation performance. To expedite
the search process with consideration for hardware resources, we used data from
three types of robotic edge hardware to train Latency Surrogate predictors.
These predictors facilitated the estimation of hardware inference latency
during the search phase, enabling a unified multi-objective evolutionary search
to balance model accuracy and latency trade-offs. Our discovered model family,
RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on
ImageNet. In addition, the resource-aware multi-objective NAS we employ
significantly reduces the model's inference latency on edge hardware for
robots. We conducted experiments on downstream tasks to verify the scalability
of our methods. The inference time for detection and segmentation is reduced on
all three hardware types compared to MobileNetv3-based methods. Our work fills
the gap in NAS for robot hardware resource-aware.

</details>


### [245] [Incorporating Human-Inspired Ankle Characteristics in a Forced-Oscillation-Based Reduced-Order Model for Walking](https://arxiv.org/abs/2509.20689)
*Chathura Semasinghe,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 本文将基于强制振荡的降阶步行模型扩展到包含脚踝和脚的模型，通过设计受人启发的脚踝动力学，提高了步态特性，并证明了该模型可以通过脚和脚踝策略稳定大的初始条件误差，还可以仅通过设计的本体感受脚踝方案稳定小的扰动，这有助于更好地理解拟人化步行及其稳定机制。


<details>
  <summary>Details</summary>
Motivation: 在现有基于强制振荡的降阶步行模型的基础上，加入了脚踝和脚的动力学，以期提高步态的稳定性和真实性。

Method: 设计了一种受人启发的脚踝动力学模型，并将其整合到降阶步行模型中。通过仿真验证了该模型在处理大的初始条件误差和小的扰动时的稳定性。

Result: 提出的模型在步态特性上优于点脚模型。该模型能够通过脚和脚踝策略稳定大的初始条件误差，并且仅通过脚踝策略就能稳定小的扰动。

Conclusion: 提出的包含脚踝和脚的降阶步行模型可以稳定大的初始条件误差和小的扰动，这种在小扰动下仅通过脚踝策略就能实现稳定的特性与人类步行中的现象一致，有助于理解拟人化步行及其稳定机制。

Abstract: This paper extends the forced-oscillation-based reduced-order model of
walking to a model with ankles and feet. A human-inspired paradigm was designed
for the ankle dynamics, which results in improved gait characteristics compared
to the point-foot model. In addition, it was shown that while the proposed
model can stabilize against large errors in initial conditions through
combination of foot placement and ankle strategies, the model is able to
stabilize against small perturbations without relying on the foot placement
control and solely through the designed proprioceptive ankle scheme. This novel
property, which is also observed in humans, can help in better understanding of
anthropomorphic walking and its stabilization mechanisms.

</details>


### [246] [RuN: Residual Policy for Natural Humanoid Locomotion](https://arxiv.org/abs/2509.20696)
*Qingpeng Li,Chengrui Zhu,Yanming Wu,Xin Yuan,Zhen Zhang,Jian Yang,Yong Liu*

Main category: cs.RO

TL;DR: RuN框架通过解耦控制任务，使用预训练的运动生成器提供运动先验，并结合强化学习策略学习残差修正，实现了人形机器人在宽速度范围内（0-2.5 m/s）稳定、自然的步态和流畅的行走-跑步过渡，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法需要策略同时学习运动模仿、速度跟踪和稳定性维持，存在挑战。

Method: 提出了一种新颖的解耦残差学习框架RuN，将预训练的条件运动生成器与强化学习策略相结合，前者提供运动先验，后者学习残差修正。

Result: 实验证明RuN在Unitree G1人形机器人上实现了稳定、自然的步态和宽速度范围内的平稳行走-跑步过渡，训练效率和最终性能均优于现有方法。

Conclusion: RuN框架通过解耦控制任务，能够实现高效且高性能的人形机器人运动控制。

Abstract: Enabling humanoid robots to achieve natural and dynamic locomotion across a
wide range of speeds, including smooth transitions from walking to running,
presents a significant challenge. Existing deep reinforcement learning methods
typically require the policy to directly track a reference motion, forcing a
single policy to simultaneously learn motion imitation, velocity tracking, and
stability maintenance. To address this, we introduce RuN, a novel decoupled
residual learning framework. RuN decomposes the control task by pairing a
pre-trained Conditional Motion Generator, which provides a kinematically
natural motion prior, with a reinforcement learning policy that learns a
lightweight residual correction to handle dynamical interactions. Experiments
in simulation and reality on the Unitree G1 humanoid robot demonstrate that RuN
achieves stable, natural gaits and smooth walk-run transitions across a broad
velocity range (0-2.5 m/s), outperforming state-of-the-art methods in both
training efficiency and final performance.

</details>


### [247] [Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations](https://arxiv.org/abs/2509.20703)
*Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 该研究提出了一种名为JFTO的框架，用于解决机器人模仿人类视频演示中的抓取姿态生成和物体轨迹模仿问题，克服了因身体差异和关节约束带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿人类视频演示存在身体差异和关节可行性约束的挑战，需要一种新的方法来解决。

Method: 提出联合流轨迹优化（JFTO）框架，通过结合抓取姿态生成、物体轨迹模仿和碰撞检测来实现。该方法将演示视为以物体为中心的指导，并扩展了流匹配到SE(3)以进行概率建模，从而实现密度感知的模仿并避免模式崩溃。

Result: JFTO框架在模拟和真实世界实验中得到验证，解决了机器人操作中的抓取姿态生成和物体轨迹模仿问题。

Conclusion: JFTO框架通过整合抓取相似性、轨迹可能性和碰撞惩罚，实现了机器人对人类视频演示的有效模仿，并能处理多模态演示。

Abstract: Learning from human video demonstrations offers a scalable alternative to
teleoperation or kinesthetic teaching, but poses challenges for robot
manipulators due to embodiment differences and joint feasibility constraints.
We address this problem by proposing the Joint Flow Trajectory Optimization
(JFTO) framework for grasp pose generation and object trajectory imitation
under the video-based Learning-from-Demonstration (LfD) paradigm. Rather than
directly imitating human hand motions, our method treats demonstrations as
object-centric guides, balancing three objectives: (i) selecting a feasible
grasp pose, (ii) generating object trajectories consistent with demonstrated
motions, and (iii) ensuring collision-free execution within robot kinematics.
To capture the multimodal nature of demonstrations, we extend flow matching to
$\SE(3)$ for probabilistic modeling of object trajectories, enabling
density-aware imitation that avoids mode collapse. The resulting optimization
integrates grasp similarity, trajectory likelihood, and collision penalties
into a unified differentiable objective. We validate our approach in both
simulation and real-world experiments across diverse real-world manipulation
tasks.

</details>


### [248] [Building Information Models to Robot-Ready Site Digital Twins (BIM2RDT): An Agentic AI Safety-First Framework](https://arxiv.org/abs/2509.20705)
*Reza Akhavian,Mani Amani,Johannes Mootz,Robert Ashe,Behrad Beheshti*

Main category: cs.RO

TL;DR: 该论文提出了一个名为BIM2RDT的AI框架，旨在将建筑信息模型(BIM)转化为动态的、机器人可读的现场数字孪生(DT)，并优先考虑施工安全。该框架通过整合BIM模型、物联网传感器和机器人数据，并引入了利用大型语言模型(LLM)进行语义推理的SG-ICP算法，提高了点云配准的准确性。同时，它还集成了振动监测，并将安全事件映射到数字孪生中，以提高施工安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: 建筑行业数字化管理面临静态BIM数据与实时现场信息脱节的挑战，同时施工安全也亟待提高。

Method: 提出BIM2RDT框架，整合BIM、物联网传感器和机器人数据。引入了语义-重力ICP（SG-ICP）算法，利用LLM进行语义推理，提高了点云配准的准确性。集成了手臂振动（HAV）监测，并将安全事件映射到数字孪生中。

Result: SG-ICP算法在点云配准方面比标准ICP算法有显著优势，RMSE降低了64.3%-88.3%。HAV集成能够实时预警，提高了ISO 5349-1标准的合规性。

Conclusion: BIM2RDT框架能够有效地将BIM转化为动态的、机器人可读的数字孪生，并通过SG-ICP算法和实时安全监测显著提高了施工安全性和管理效率。

Abstract: The adoption of cyber-physical systems and jobsite intelligence that connects
design models, real-time site sensing, and autonomous field operations can
dramatically enhance digital management in the construction industry. This
paper introduces BIM2RDT (Building Information Models to Robot-Ready Site
Digital Twins), an agentic artificial intelligence (AI) framework designed to
transform static Building Information Modeling (BIM) into dynamic, robot-ready
digital twins (DTs) that prioritize safety during execution. The framework
bridges the gap between pre-existing BIM data and real-time site conditions by
integrating three key data streams: geometric and semantic information from BIM
models, activity data from IoT sensor networks, and visual-spatial data
collected by robots during site traversal. The methodology introduces
Semantic-Gravity ICP (SG-ICP), a point cloud registration algorithm that
leverages large language model (LLM) reasoning. Unlike traditional methods,
SG-ICP utilizes an LLM to infer object-specific, plausible orientation priors
based on BIM semantics, improving alignment accuracy by avoiding convergence on
local minima. This creates a feedback loop where robot-collected data updates
the DT, which in turn optimizes paths for missions. The framework employs YOLOE
object detection and Shi-Tomasi corner detection to identify and track
construction elements while using BIM geometry as a priori maps. The framework
also integrates real-time Hand-Arm Vibration (HAV) monitoring, mapping
sensor-detected safety events to the digital twin using IFC standards for
intervention. Experiments demonstrate SG-ICP's superiority over standard ICP,
achieving RMSE reductions of 64.3%--88.3% in alignment across scenarios with
occluded features, ensuring plausible orientations. HAV integration triggers
warnings upon exceeding exposure limits, enhancing compliance with ISO 5349-1.

</details>


### [249] [Digital Twin-Guided Robot Path Planning: A Beta-Bernoulli Fusion with Large Language Model as a Sensor](https://arxiv.org/abs/2509.20709)
*Mani Amani,Reza Akhavian*

Main category: cs.RO

TL;DR: 该研究提出了一种融合自然语言指令和BIM语义地图的机器人路径规划新框架，通过将大语言模型视为传感器，并利用Beta-二项贝叶斯融合方法，生成更安全、更具情境意识的路径。


<details>
  <summary>Details</summary>
Motivation: 在机器人任务规划中融合自然语言指令，特别是在建筑领域，利用BIM模型中的丰富信息，是近年来的研究热点。

Method: 提出了一种新框架，该框架通过Beta-二项贝叶斯融合方法，将自然语言指令与BIM衍生的语义地图相结合。具体做法是将大语言模型视为传感器，将障碍物的设计时排斥系数视为Beta(alpha, beta)随机变量，并将大语言模型返回的危险评分作为伪计数来更新alpha和beta。由此产生的后验均值产生了一个连续的、上下文感知的排斥增益，用于增强基于欧氏距离的势场作为成本启发式。通过根据从用户指令中推断出的情绪和上下文调整增益，该方法能够引导机器人沿着更安全、更具上下文意识的路径行进。

Result: 仿真结果表明，该Beta-二项贝叶斯融合方法在路径鲁棒性和有效性方面均取得了定性和定量上的改进。

Conclusion: 该方法提供了一种数值稳定的方法，能够整合来自建筑工人或主管的多个自然语言命令和提示，从而实现路径规划，并具有灵活集成到任何学习型或经典AI框架中的能力，从而提高了路径规划的鲁棒性和有效性。

Abstract: Integrating natural language (NL) prompts into robotic mission planning has
attracted significant interest in recent years. In the construction domain,
Building Information Models (BIM) encapsulate rich NL descriptions of the
environment. We present a novel framework that fuses NL directives with
BIM-derived semantic maps via a Beta-Bernoulli Bayesian fusion by interpreting
the LLM as a sensor: each obstacle's design-time repulsive coefficient is
treated as a Beta(alpha, beta) random variable and LLM-returned danger scores
are incorporated as pseudo-counts to update alpha and beta. The resulting
posterior mean yields a continuous, context-aware repulsive gain that augments
a Euclidean-distance-based potential field for cost heuristics. By adjusting
gains based on sentiment and context inferred from user prompts, our method
guides robots along safer, more context-aware paths. This provides a
numerically stable method that can chain multiple natural commands and prompts
from construction workers and foreman to enable planning while giving
flexibility to be integrated in any learned or classical AI framework.
Simulation results demonstrate that this Beta-Bernoulli fusion yields both
qualitative and quantitative improvements in path robustness and validity.

</details>


### [250] [RobotDancing: Residual-Action Reinforcement Learning Enables Robust Long-Horizon Humanoid Motion Tracking](https://arxiv.org/abs/2509.20717)
*Zhenguo Sun,Yibo Peng,Yuan Meng,Xukun Li,Bo-Sheng Huang,Zhenshan Bing,Xinlong Wang,Alois Knoll*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Long-horizon, high-dynamic motion tracking on humanoids remains brittle
because absolute joint commands cannot compensate model-plant mismatch, leading
to error accumulation. We propose RobotDancing, a simple, scalable framework
that predicts residual joint targets to explicitly correct dynamics
discrepancies. The pipeline is end-to-end--training, sim-to-sim validation, and
zero-shot sim-to-real--and uses a single-stage reinforcement learning (RL)
setup with a unified observation, reward, and hyperparameter configuration. We
evaluate primarily on Unitree G1 with retargeted LAFAN1 dance sequences and
validate transfer on H1/H1-2. RobotDancing can track multi-minute, high-energy
behaviors (jumps, spins, cartwheels) and deploys zero-shot to hardware with
high motion tracking quality.

</details>


### [251] [SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning](https://arxiv.org/abs/2509.20739)
*Guoyang Zhao,Yudong Li,Weiqing Qi,Kai Zhang,Bonan Liu,Kai Chen,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一个纯视觉、无SLAM的导航框架，利用语义推理和拓扑表示替代传统方法，以提高机器人导航在快速运动、校准和传感器漂移下的鲁棒性，并增强任务驱动的探索能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人导航方法在快速运动、校准要求和传感器漂移方面存在不足，且缺乏语义推理能力，限制了任务驱动的探索。

Method: 提出了一种纯视觉、无SLAM的导航框架，该框架使用分层的视觉-语言感知模块进行语义推理，并结合基于LLM的全局推理和基于视觉的局部规划，以支持粗粒度到细粒度的规划。该框架集成了强化学习的运动控制器。

Result: 在模拟和真实世界环境中均取得了显著改进，包括语义准确性、规划质量和导航成功率。消融研究也证明了分层感知和精细局部规划的重要性。

Conclusion: 这项工作引入了一种新的无SLAM、视觉-语言驱动的导航范式，将机器人探索从以几何为中心的方法转变为以语义为驱动的决策。

Abstract: Conventional SLAM pipelines for legged robot navigation are fragile under
rapid motion, calibration demands, and sensor drift, while offering limited
semantic reasoning for task-driven exploration. To deal with these issues, we
propose a vision-only, SLAM-free navigation framework that replaces dense
geometry with semantic reasoning and lightweight topological representations. A
hierarchical vision-language perception module fuses scene-level context with
object-level cues for robust semantic inference. And a semantic-probabilistic
topological map supports coarse-to-fine planning: LLM-based global reasoning
for subgoal selection and vision-based local planning for obstacle avoidance.
Integrated with reinforcement-learning locomotion controllers, the framework is
deployable across diverse legged robot platforms. Experiments in simulation and
real-world settings demonstrate consistent improvements in semantic accuracy,
planning quality, and navigation success, while ablation studies further
showcase the necessity of both hierarchical perception and fine local planning.
This work introduces a new paradigm for SLAM-free, vision-language-driven
navigation, shifting robotic exploration from geometry-centric mapping to
semantics-driven decision making.

</details>


### [252] [MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM](https://arxiv.org/abs/2509.20757)
*Yuxuan Zhou,Xingxing Li,Shengyu Li,Zhuohao Yan,Chunxi Xia,Shaoquan Feng*

Main category: cs.RO

TL;DR: MASt3R-Fusion是一个多传感器视觉SLAM框架，它结合了前馈点图回归和惯性测量与GNSS数据，以提高在低纹理和具有挑战性的视觉条件下的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉SLAM系统在低纹理环境、尺度模糊以及具有挑战性的视觉条件下表现不佳。虽然基于神经网络的点图回归方法显示出恢复高保真3D场景几何的潜力，但它们常常忽略了多传感器信息融合的优势。

Method: MASt3R-Fusion将前馈点图回归与惯性测量和GNSS数据相结合。它通过在通用的度量尺度SE(3)因子图中引入基于Sim(3)的视觉对齐约束（以Hessian形式）来实现有效的信息融合。该系统采用分层因子图设计，支持实时滑动窗口优化和具有积极回环检测的全局优化。

Result: 在公开基准和自收集数据集上的评估表明，MASt3R-Fusion在精度和鲁棒性方面比现有的以视觉为中心的、多传感器的SLAM系统有了显著的改进。

Conclusion: MASt3R-Fusion通过将前馈点图回归与惯性测量和GNSS数据紧密集成，并采用创新的因子图设计，成功克服了传统视觉SLAM的局限性，实现了实时位姿跟踪、度量尺度结构感知和全局一致的建图。

Abstract: Visual SLAM is a cornerstone technique in robotics, autonomous driving and
extended reality (XR), yet classical systems often struggle with low-texture
environments, scale ambiguity, and degraded performance under challenging
visual conditions. Recent advancements in feed-forward neural network-based
pointmap regression have demonstrated the potential to recover high-fidelity 3D
scene geometry directly from images, leveraging learned spatial priors to
overcome limitations of traditional multi-view geometry methods. However, the
widely validated advantages of probabilistic multi-sensor information fusion
are often discarded in these pipelines. In this work, we propose
MASt3R-Fusion,a multi-sensor-assisted visual SLAM framework that tightly
integrates feed-forward pointmap regression with complementary sensor
information, including inertial measurements and GNSS data. The system
introduces Sim(3)-based visualalignment constraints (in the Hessian form) into
a universal metric-scale SE(3) factor graph for effective information fusion. A
hierarchical factor graph design is developed, which allows both real-time
sliding-window optimization and global optimization with aggressive loop
closures, enabling real-time pose tracking, metric-scale structure perception
and globally consistent mapping. We evaluate our approach on both public
benchmarks and self-collected datasets, demonstrating substantial improvements
in accuracy and robustness over existing visual-centered multi-sensor SLAM
systems. The code will be released open-source to support reproducibility and
further research (https://github.com/GREAT-WHU/MASt3R-Fusion).

</details>


### [253] [Leveraging Temporally Extended Behavior Sharing for Multi-task Reinforcement Learning](https://arxiv.org/abs/2509.20766)
*Gawon Lee,Daesol Cho,H. Jin Kim*

Main category: cs.RO

TL;DR: MT-L'evy是一种新的探索策略，通过结合行为共享和受Lévy飞行启发的时序扩展探索，提高了多任务强化学习（MTRL）在机器人领域的样本效率。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域应用多任务强化学习（MTRL）面临数据收集成本高昂的挑战。MT-L'evy旨在通过一种新的探索策略来解决这个问题。

Method: MT-L'evy结合了跨任务的行为共享和受Lévy飞行启发的时序扩展探索。它利用在相关任务上训练的策略来指导探索，并根据任务成功率动态调整探索级别。

Result: MT-L'evy在探索和样本效率方面取得了显著的改进，并且通过消融研究证明了其各组成部分的有效性。

Conclusion: 结合行为共享和自适应探索策略可以显著提高MTRL在机器人应用中的实用性。

Abstract: Multi-task reinforcement learning (MTRL) offers a promising approach to
improve sample efficiency and generalization by training agents across multiple
tasks, enabling knowledge sharing between them. However, applying MTRL to
robotics remains challenging due to the high cost of collecting diverse task
data. To address this, we propose MT-L\'evy, a novel exploration strategy that
enhances sample efficiency in MTRL environments by combining behavior sharing
across tasks with temporally extended exploration inspired by L\'evy flight.
MT-L\'evy leverages policies trained on related tasks to guide exploration
towards key states, while dynamically adjusting exploration levels based on
task success ratios. This approach enables more efficient state-space coverage,
even in complex robotics environments. Empirical results demonstrate that
MT-L\'evy significantly improves exploration and sample efficiency, supported
by quantitative and qualitative analyses. Ablation studies further highlight
the contribution of each component, showing that combining behavior sharing
with adaptive exploration strategies can significantly improve the practicality
of MTRL in robotics applications.

</details>


### [254] [SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation](https://arxiv.org/abs/2509.20839)
*Jiaxuan He,Jiamei Ren,Chongshang Yan,Wenjie Song*

Main category: cs.RO

TL;DR: SemSight是一个用于室内导航和探索的鸟瞰图预测模型，可以预测未知区域的语义结构和目标区域分布，提高导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测未知区域时，侧重于单一物体或几何占用图，缺乏对房间级语义结构进行建模的能力，因此提出SemSight来解决这一问题。

Method: SemSight是一个概率鸟瞰图预测模型，通过编码器-解码器网络和掩码约束的监督策略，联合推断结构布局、全局场景上下文和目标区域分布，并专注于对未知区域进行预测。

Result: SemSight提高了在未知区域的关键功能类别预测性能，在结构一致性（SC）和区域识别准确率（PA）等指标上优于非掩码监督方法，并减少了在封闭环路模拟中引导机器人到达目标区域的搜索步骤。

Conclusion: SemSight能够从观测到的上下文中推断语义结构，提高未知区域的预测性能，并增强导航效率。

Abstract: In target-driven navigation and autonomous exploration, reasonable prediction
of unknown regions is crucial for efficient navigation and environment
understanding. Existing methods mostly focus on single objects or geometric
occupancy maps, lacking the ability to model room-level semantic structures. We
propose SemSight, a probabilistic bird's-eye-view prediction model for
multi-level scene semantics. The model jointly infers structural layouts,
global scene context, and target area distributions, completing semantic maps
of unexplored areas while estimating probability maps for target categories. To
train SemSight, we simulate frontier-driven exploration on 2,000 indoor layout
graphs, constructing a diverse dataset of 40,000 sequential egocentric
observations paired with complete semantic maps. We adopt an encoder-decoder
network as the core architecture and introduce a mask-constrained supervision
strategy. This strategy applies a binary mask of unexplored areas so that
supervision focuses only on unknown regions, forcing the model to infer
semantic structures from the observed context. Experimental results show that
SemSight improves prediction performance for key functional categories in
unexplored regions and outperforms non-mask-supervised approaches on metrics
such as Structural Consistency (SC) and Region Recognition Accuracy (PA). It
also enhances navigation efficiency in closed-loop simulations, reducing the
number of search steps when guiding robots toward target areas.

</details>


### [255] [ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation](https://arxiv.org/abs/2509.20841)
*Dekun Lu,Wei Gao,Kui Jia*

Main category: cs.RO

TL;DR: CoMOK 是一种新颖的机器人操作公式，可作为神经网络策略的动作表示，从而实现可泛化、准确且可靠的端到端操作策略。


<details>
  <summary>Details</summary>
Motivation: 与传统模块化流程相比，端到端学习可以减轻模块之间的信息丢失和孤立优化目标导致的特征不对齐等关键限制。然而，现有的端到端机器人操作方法（包括基于大型 VLM/VLA 模型的方法）的性能仍然不足以进行大规模实际部署。

Method: 提出了一种新颖的链式定向关键点 (CoMOK) 公式，用于机器人操作。将 CoMOK 公式用作神经网络策略的动作表示，该策略可以进行端到端训练。

Result: CoMOK 公式可以自然地泛化到不同形状和大小的物体，同时实现亚厘米级的精度。此外，该公式还可以轻松处理多阶段任务、多模态机器人行为和可变形物体。大量的模拟和硬件实验证明了该方法的有效性。

Conclusion: CoMOK 是一种新颖的机器人操作公式，可作为神经网络策略的动作表示，从而实现可泛化、准确且可靠的端到端操作策略。

Abstract: End-to-end robot manipulation policies offer significant potential for
enabling embodied agents to understand and interact with the world. Unlike
traditional modular pipelines, end-to-end learning mitigates key limitations
such as information loss between modules and feature misalignment caused by
isolated optimization targets. Despite these advantages, existing end-to-end
neural networks for robotic manipulation--including those based on large
VLM/VLA models--remain insufficiently performant for large-scale practical
deployment. In this paper, we take a step towards an end-to-end manipulation
policy that is generalizable, accurate and reliable. To achieve this goal, we
propose a novel Chain of Moving Oriented Keypoints (CoMOK) formulation for
robotic manipulation. Our formulation is used as the action representation of a
neural policy, which can be trained in an end-to-end fashion. Such an action
representation is general, as it extends the standard end-effector pose action
representation and supports a diverse set of manipulation tasks in a unified
manner. The oriented keypoint in our method enables natural generalization to
objects with different shapes and sizes, while achieving sub-centimeter
accuracy. Moreover, our formulation can easily handle multi-stage tasks,
multi-modal robot behaviors, and deformable objects. Extensive simulated and
hardware experiments demonstrate the effectiveness of our method.

</details>


### [256] [MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases](https://arxiv.org/abs/2509.20843)
*Ziang Luo,Kangan Qian,Jiahua Wang,Yuechen Luo,Jinyu Miao,Zheng Fu,Yunlong Wang,Sicong Jiang,Zilin Huang,Yifei Hu,Yuhao Yang,Hao Ye,Mengmeng Yang,Xiaojian Dong,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: MTRDrive是一个整合了程序化驾驶体验和动态工具包的新框架，旨在提高自动驾驶中视觉-语言模型（VLMs）的泛化能力和主动决策能力，以解决它们在分布外（OOD）场景下的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在端到端自动驾驶方面潜力巨大，但其幻觉和在分布外（OOD）场景下泛化能力差的特点限制了其在现实世界中的可靠部署。MTRDrive旨在解决这些限制，提高模型的泛化能力和主动决策能力。

Method: MTRDrive通过一个闭环系统，结合了基于记忆的经验检索机制和动态工具包，实现了记忆-工具协同推理，以增强模型与环境的交互、推理和决策能力。此外，研究人员还创建了一个基于复杂道路施工场景的新基准（Roadwork-VLM），以严格评估模型的零样本泛化能力。

Result: 在NAVSIM基准上，MTRDrive（3B参数）在没有思维链的情况下达到了88.3的PDMS，并在高级规划方面设定了新的SOTA，驾驶指标得分为79.8%，规划准确率为82.6%。在Roadwork-VLM基准上的零样本评估显示，MTRDrive在处理未见场景时具有强大的鲁棒推理能力，驾驶指标得分为80.2%。

Conclusion: MTRDrive框架通过整合程序化驾驶经验和动态工具包，显著提高了自动驾驶中VLMs的泛化能力和鲁棒性，尤其是在处理OOD场景和复杂工况方面，为实现更安全可靠的自动驾驶系统提供了有前景的解决方案。

Abstract: Vision-Language Models(VLMs) have demonstrated significant potential for
end-to-end autonomous driving, yet a substantial gap remains between their
current capabilities and the reliability necessary for real-world deployment. A
critical challenge is their fragility, characterized by hallucinations and poor
generalization in out-of-distribution (OOD) scenarios. To bridge this gap, we
introduce MTRDrive, a novel framework that integrates procedural driving
experiences with a dynamic toolkit to enhance generalization and proactive
decision-making.
  MTRDrive addresses these limitations through a closed-loop system that
combines a memory-based experience retrieval mechanism with dynamic toolkits.
This synergy enables the model to interact more effectively with its
environment, improving both reasoning and decision-making capabilities with the
help of our memory-tool synergistic reasoning. Additionally, we introduce a new
benchmark based on complex Roadwork construction scenarios to rigorously
evaluate zero-shot generalization.
  Extensive experiments demonstrate the superior effectiveness of our approach.
On the public NAVSIM benchmark, our 3B-parameter MTRDrive model achieves an
exceptional PDMS of 88.3 without chain-of-thought and sets a state-of-the-art
performance bar on high-level planning, with a driving metric score of 79.8\%
and a planning accuracy of 82.6\%. Rigorous zero-shot evaluation on the new
Roadwork-VLM benchmark shows a strong ability to reason robustly in unseen
scenarios, achieving a driving metric score of 80.2\%. These results highlight
MTRDrive's potential to advance autonomous driving toward safer and more
reliable systems.

</details>


### [257] [Efficient Differentiable Contact Model with Long-range Influence](https://arxiv.org/abs/2509.20917)
*Xiaohan Ye,Kui Wu,Zherong Pan,Taku Komura*

Main category: cs.RO

TL;DR: 可微模拟中的接触模型会影响梯度行为，本文提出了一个满足特定属性且计算高效的接触模型，以改善梯度稳定性并促进下游任务的成功。


<details>
  <summary>Details</summary>
Motivation: 可微物理学的成熟使其在模型预测控制、机器人设计优化和神经偏微分方程求解器等下游应用中越来越重要，但可微模拟器提供的导数信息可能出现剧烈变化或完全消失，阻碍了基于梯度的优化器的收敛。

Method: 提出了一组接触模型必须满足以确保良好梯度信息的属性，并提出了一个满足这些属性且计算高效的刚体模拟器接触模型。

Result: 所提出的接触模型可以发现复杂的、富含接触的控制信号，并成功执行了一系列下游的运动和操作任务。

Conclusion: 本文提出的接触模型能够改善可微模拟器中的梯度稳定性，从而在各种下游应用中取得更好的性能。

Abstract: With the maturation of differentiable physics, its role in various downstream
applications: such as model predictive control, robotic design optimization,
and neural PDE solvers, has become increasingly important. However, the
derivative information provided by differentiable simulators can exhibit abrupt
changes or vanish altogether, impeding the convergence of gradient-based
optimizers. In this work, we demonstrate that such erratic gradient behavior is
closely tied to the design of contact models. We further introduce a set of
properties that a contact model must satisfy to ensure well-behaved gradient
information. Lastly, we present a practical contact model for differentiable
rigid-body simulators that satisfies all of these properties while maintaining
computational efficiency. Our experiments show that, even from simple
initializations, our contact model can discover complex, contact-rich control
signals, enabling the successful execution of a range of downstream locomotion
and manipulation tasks.

</details>


### [258] [Autoregressive End-to-End Planning with Time-Invariant Spatial Alignment and Multi-Objective Policy Refinement](https://arxiv.org/abs/2509.20938)
*Jianbo Zhao,Taiyu Ban,Xiangjie Li,Xingtai Gui,Hangning Zhou,Lei Liu,Hongwei Zhao,Bin Li*

Main category: cs.RO

TL;DR: TISA模块通过时间不变的空间对齐和基于运动学的动作预测，解决了自回归模型在自动驾驶规划中的时空不一致问题，并使用多目标DPO进行后训练，在NAVSIM数据集上达到了89.8 PDMS的最优性能。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在自动驾驶规划中存在时空不一致问题，限制了其性能上限。

Method: 提出时间不变空间对齐（TISA）模块，将环境特征投影到一致的以车辆为中心的坐标系；采用运动学动作预测头；引入多目标后训练阶段，使用直接偏好优化（DPO）进行精细化学习。

Result: 在NAVSIM数据集上，该模型取得了89.8 PDMS的最优性能，优于其他自回归模型。

Conclusion: TISA模块和多目标DPO能够有效解决自回归模型在自动驾驶规划中的时空不一致问题，并生成物理上可行的轨迹，从而提高规划性能。

Abstract: The inherent sequential modeling capabilities of autoregressive models make
them a formidable baseline for end-to-end planning in autonomous driving.
Nevertheless, their performance is constrained by a spatio-temporal
misalignment, as the planner must condition future actions on past sensory
data. This creates an inconsistent worldview, limiting the upper bound of
performance for an otherwise powerful approach. To address this, we propose a
Time-Invariant Spatial Alignment (TISA) module that learns to project initial
environmental features into a consistent ego-centric frame for each future time
step, effectively correcting the agent's worldview without explicit future
scene prediction. In addition, we employ a kinematic action prediction head
(i.e., acceleration and yaw rate) to ensure physically feasible trajectories.
Finally, we introduce a multi-objective post-training stage using Direct
Preference Optimization (DPO) to move beyond pure imitation. Our approach
provides targeted feedback on specific driving behaviors, offering a more
fine-grained learning signal than the single, overall objective used in
standard DPO. Our model achieves a state-of-the-art 89.8 PDMS on the NAVSIM
dataset among autoregressive models. The video document is available at
https://tisa-dpo-e2e.github.io/.

</details>


### [259] [BactoBot: A Low-Cost, Bacteria-Inspired Soft Underwater Robot for Marine Exploration](https://arxiv.org/abs/2509.20964)
*Rubaiyat Tasnim Chowdhury,Nayan Bala,Ronojoy Roy,Tarek Mahmud*

Main category: cs.RO

TL;DR: BactoBot是一种低成本、柔性水下机器人，模仿细菌的鞭毛推进方式，能够安全地探索海洋生态系统。


<details>
  <summary>Details</summary>
Motivation: 传统的刚性水下航行器可能对脆弱的海洋生态系统造成损害，因此需要一种能够进行安全和温和的海洋探索的替代方案。

Method: 该研究提出了一种名为BactoBot的低成本、柔性水下机器人。它受到细菌鞭毛推进的启发，拥有一个由12个柔性、硅胶制成的臂组成的十二面体框架。该机器人采用DIY方法制造，包括使用食品级硅胶模具、3D打印和现成的微控制器。研究人员还开发了防水和浮力校准程序。

Result: BactoBot原型在控制水箱中进行了成功测试，证明了其前进和转弯的能力。该实验验证了以低成本复制复杂生物运动的可行性。

Conclusion: BactoBot项目为开发环境友好型机器人工具奠定了基础，尤其适用于资源有限的海洋科学领域。未来的研究方向包括实现自主操作和现场部署。

Abstract: Traditional rigid underwater vehicles pose risks to delicate marine
ecosystems. This paper presents BactoBot, a low-cost, soft underwater robot
designed for safe and gentle marine exploration. Inspired by bacterial
flagellar propulsion, BactoBot features 12 flexible, silicone-based arms
arranged on a 3D-printed dodecahedral frame. The design provides inherent
compliance, redundancy, and the potential for omnidirectional movement. The
prototype was fabricated using accessible DIY methods, including food-grade
silicone molding, 3D printing, and off-the-shelf microcontrollers.
Waterproofing and buoyancy calibration protocols were developed, and the robot
was successfully tested in a controlled water tank, demonstrating forward
motion and turning. The results validate the feasibility of replicating complex
biological locomotion at low cost. The project lays a foundation for
environmentally conscious robotic tools, particularly for marine science in
resource-constrained settings, and identifies pathways toward autonomous
operation and field deployment.

</details>


### [260] [AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation](https://arxiv.org/abs/2509.21006)
*Konstantin Gubernatorov,Artem Voronov,Roman Voronov,Sergei Pasynkov,Stepan Perminov,Ziang Guo,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: AnywhereVLA是一个模块化框架，用于在未见的、不可预测的室内环境中进行自然语言拾取和放置。它结合了SLAM、语义地图、任务规划和VLA操纵头，实现了实时的、完全在船上的操作。该系统在真实场景下实现了46%的总体任务成功率。


<details>
  <summary>Details</summary>
Motivation: 在未见的、不可预测的室内环境中实现自然语言驱动的拾取和放置任务。

Method: AnywhereVLA框架：1. 文本提示解析为结构化任务图。2. 条件化SLAM（使用LiDAR和摄像头）、度量语义地图和任务感知的边界探索策略。3. 方法规划器选择可见性和可达性感知的前置抓取基座姿态。4. 紧凑型SmolVLA操纵头针对SO-101机器人进行了微调，用于生成抓取和放置建议。5. 整个系统完全在嵌入式硬件（Jetson Orin NX和Intel NUC）上实时运行。

Result: 在多房间实验室的静态场景和正常人类运动下，实现了46%的总体任务成功率，同时在嵌入式计算上保持了吞吐量。

Conclusion: 通过结合基于几何的导航的可靠性与语言条件操纵的敏捷性和任务泛化能力，AnywhereVLA在移动操作方面取得了成功。

Abstract: We address natural language pick-and-place in unseen, unpredictable indoor
environments with AnywhereVLA, a modular framework for mobile manipulation. A
user text prompt serves as an entry point and is parsed into a structured task
graph that conditions classical SLAM with LiDAR and cameras, metric semantic
mapping, and a task-aware frontier exploration policy. An approach planner then
selects visibility and reachability aware pre grasp base poses. For
interaction, a compact SmolVLA manipulation head is fine tuned on platform pick
and place trajectories for the SO-101 by TheRobotStudio, grounding local visual
context and sub-goals into grasp and place proposals. The full system runs
fully onboard on consumer-level hardware, with Jetson Orin NX for perception
and VLA and an Intel NUC for SLAM, exploration, and control, sustaining
real-time operation. We evaluated AnywhereVLA in a multi-room lab under static
scenes and normal human motion. In this setting, the system achieves a $46\%$
overall task success rate while maintaining throughput on embedded compute. By
combining a classical stack with a fine-tuned VLA manipulation, the system
inherits the reliability of geometry-based navigation with the agility and task
generalization of language-conditioned manipulation.

</details>


### [261] [Multi-Robot Vision-Based Task and Motion Planning for EV Battery Disassembly and Sorting](https://arxiv.org/abs/2509.21020)
*Abdelaziz Shaarawy,Cansu Erdogan,Rustam Stolkin,Alireza Rastegarpanah*

Main category: cs.RO

TL;DR: 提出一种用于电动汽车电池拆卸的多机器人任务与运动规划框架，提高了运动效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车电池拆卸需要精确的多机器人协调、高效可靠的运动以及在复杂动态场景下的碰撞安全保障。

Method: 提出一个四层任务与运动规划（TAMP）框架，结合了符号任务规划、成本与可达性感知分配，以及受演示启发的TP-GMM运动规划器。利用YOLOv8进行组件实时定位，OctoMap进行3D建图，MoveIt中的FCL进行碰撞检测，并结合预测性数字孪生碰撞检测与基于视觉的避障。

Result: 在双UR10e机器人上进行了电缆、汇流条、服务插头和三片式电池组拆卸的验证。与默认的RRTConnect基线相比，平均末端执行器路径长度减少了63.3%，完成时间减少了8.1%，机器人扫过的体积显著减小，相互重叠度降低了47%。

Conclusion: 该方法提高了在非结构化动态环境中进行多机器人电动汽车电池拆卸的自主性、精度和安全性。

Abstract: Electric-vehicle (EV) battery disassembly requires precise multi-robot
coordination, short and reliable motions, and robust collision safety in
cluttered, dynamic scenes. We propose a four-layer task-and-motion planning
(TAMP) framework that couples symbolic task planning and cost- and
accessibility-aware allocation with a TP-GMM-guided motion planner learned from
demonstrations. Stereo vision with YOLOv8 provides real-time component
localization, while OctoMap-based 3D mapping and FCL(Flexible Collision
Library) checks in MoveIt unify predictive digital-twin collision checking with
reactive, vision-based avoidance. Validated on two UR10e robots across cable,
busbar, service plug, and three leaf-cell removals, the approach yields
substantially more compact and safer motions than a default RRTConnect baseline
under identical perception and task assignments: average end-effector path
length drops by $-63.3\%$ and makespan by $-8.1\%$; per-arm swept volumes
shrink (R1: $0.583\rightarrow0.139\,\mathrm{m}^3$; R2:
$0.696\rightarrow0.252\,\mathrm{m}^3$), and mutual overlap decreases by $47\%$
($0.064\rightarrow0.034\,\mathrm{m}^3$). These results highlight improved
autonomy, precision, and safety for multi-robot EV battery disassembly in
unstructured, dynamic environments.

</details>


### [262] [KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models](https://arxiv.org/abs/2509.21027)
*Sibo Li,Qianyue Hao,Yu Shang,Yong Li*

Main category: cs.RO

TL;DR: KeyWorld是一个改进的文本引导机器人世界模型框架，通过专注于关键帧的Transformer计算并使用轻量级卷积模型填充中间帧，提高了推理速度和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人世界模型在推理速度和生成轨迹的物理合理性方面存在瓶颈，限制了其在现实世界中的应用。这主要是由于逐帧生成方法计算冗余，并且忽略了关键转折点的语义重要性。

Method: KeyWorld首先通过迭代简化机器人运动轨迹来识别重要的转折点，得到关键帧。然后，训练一个DiT模型来根据文本任务描述推理并生成这些物理上重要的关键帧。最后，使用一个轻量级的插值模型通过修复中间帧来高效地重建完整视频。

Result: 在LIBERO基准上的评估表明，KeyWorld的加速比逐帧生成基线快5.68倍。专注于与运动相关的关键帧也提高了生成视频的物理有效性，尤其是在复杂任务上。

Conclusion: KeyWorld为在机器人实时控制和其他需要高效且有效的世界模型的领域部署世界模型提供了一条实用的途径。

Abstract: Robotic world models are a promising paradigm for forecasting future
environment states, yet their inference speed and the physical plausibility of
generated trajectories remain critical bottlenecks, limiting their real-world
applications. This stems from the redundancy of the prevailing frame-to-frame
generation approach, where the model conducts costly computation on similar
frames, as well as neglecting the semantic importance of key transitions. To
address this inefficiency, we propose KeyWorld, a framework that improves
text-conditioned robotic world models by concentrating transformers computation
on a few semantic key frames while employing a lightweight convolutional model
to fill the intermediate frames. Specifically, KeyWorld first identifies
significant transitions by iteratively simplifying the robot's motion
trajectories, obtaining the ground truth key frames. Then, a DiT model is
trained to reason and generate these physically meaningful key frames from
textual task descriptions. Finally, a lightweight interpolator efficiently
reconstructs the full video by inpainting all intermediate frames. Evaluations
on the LIBERO benchmark demonstrate that KeyWorld achieves a 5.68$\times$
acceleration compared to the frame-to-frame generation baseline, and focusing
on the motion-aware key frames further contributes to the physical validity of
the generated videos, especially on complex tasks. Our approach highlights a
practical path toward deploying world models in real-time robotic control and
other domains requiring both efficient and effective world models. Code is
released at https://anonymous.4open.science/r/Keyworld-E43D.

</details>


### [263] [MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation](https://arxiv.org/abs/2509.21045)
*Mahya Ramezani,M. Amin Alandihallaj,Barış Can Yalçın,Miguel Angel Olivares Mendez,Holger Voos*

Main category: cs.RO

TL;DR: 本研究提出了一种结合强化学习(RL)和模型预测控制(MPC)的卫星自主对接框架，以解决微重力下燃料晃动带来的不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 微重力下燃料晃动产生的不可预测力矩影响卫星对接稳定性，传统对接控制方法面临挑战。

Method: 提出了一种集成近端策略优化(PPO)和软Actor-Critic(SAC)强化学习算法与模型预测控制(MPC)的框架。利用MPC的预测能力加速RL训练并增强控制鲁棒性。

Result: 通过实验和高保真数值模拟验证了所提方法的有效性。SAC-MPC在对接精度、成功率和控制能量消耗方面优于单独的RL方法和PPO-MPC方法。

Conclusion: 该研究为燃料高效、抗干扰的卫星对接提供了新的解决方案，提高了在轨燃料加注和维护任务的可行性。

Abstract: This paper presents an integrated Reinforcement Learning (RL) and Model
Predictive Control (MPC) framework for autonomous satellite docking with a
partially filled fuel tank. Traditional docking control faces challenges due to
fuel sloshing in microgravity, which induces unpredictable forces affecting
stability. To address this, we integrate Proximal Policy Optimization (PPO) and
Soft Actor-Critic (SAC) RL algorithms with MPC, leveraging MPC's predictive
capabilities to accelerate RL training and improve control robustness. The
proposed approach is validated through Zero-G Lab of SnT experiments for planar
stabilization and high-fidelity numerical simulations for 6-DOF docking with
fuel sloshing dynamics. Simulation results demonstrate that SAC-MPC achieves
superior docking accuracy, higher success rates, and lower control effort,
outperforming standalone RL and PPO-MPC methods. This study advances
fuel-efficient and disturbance-resilient satellite docking, enhancing the
feasibility of on-orbit refueling and servicing missions.

</details>


### [264] [Normalizing Flows are Capable Visuomotor Policy Learning Models](https://arxiv.org/abs/2509.21073)
*Simon Kristoffersson Lind,Jialong Li,Maj Stenmark,Volker Krüger*

Main category: cs.RO

TL;DR: 本研究提出了一种名为“归一化流策略”（Normalizing Flows Policy）的新型视觉运动策略学习模型，它基于归一化流，能够提供有统计学依据的置信度度量并实现高效推理，在机器人任务中表现出与扩散策略相当甚至更优的性能，同时具有更高的样本效率和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决通用机器人领域中现有模型（如扩散模型）在推理计算量大和无法量化输出不确定性方面存在的弊端，并认识到模型的可信度（对可靠、通用的机器人至关重要）与其提供置信度度量的能力密切相关。

Method: 提出了一种基于归一化流的新型视觉运动策略学习模型——归一化流策略。该模型利用归一化流的特性，旨在提供统计学上合理的置信度度量，并实现高效推理。

Result: 通过在四种不同的模拟机器人任务上进行的大量实验，证明了归一化流策略在性能上可以与扩散策略相媲美，甚至常常超越它。此外，该模型在样本效率上有所提高，并且推理速度最高可提高30倍。消融研究也验证了多种关键的架构和训练技术，这些技术有助于归一化流在此领域取得良好表现。

Conclusion: 归一化流策略为扩散模型提供了一个有力的替代方案，它不仅在性能上具有竞争力，而且在推理效率和不确定性量化方面具有显著优势，这对于需要高可信度的通用机器人应用至关重要。

Abstract: The field of general purpose robotics has recently embraced powerful
probabilistic models, such as diffusion models, to model and learn complex
behaviors. However, these models often come with significant trade-offs, namely
high computational costs for inference and a fundamental inability to quantify
output uncertainty. We argue that a model's trustworthiness, a critical factor
for reliable, general-purpose robotics, is inherently linked to its ability to
provide confidence measures.
  In this work, we introduce Normalizing Flows Policy, a novel visuomotor
policy learning model based on Normalizing Flows. We show that Normalizing
Flows are a natural and powerful alternative to diffusion models, providing
both a statistically sound measure of confidence and a highly efficient
inference process. Through comprehensive experiments across four distinct
simulated robotic tasks, we demonstrate that Normalizing Flows Policy achieves
performance comparable to, and often surpassing, Diffusion Policy, and it does
so not only with improved sample efficiency but also with up to 30 times faster
inference. Additionally, our ablation study validates several key architectural
and training techniques that enable Normalizing Flows to perform well in this
domain.

</details>


### [265] [Flight Dynamics to Sensing Modalities: Exploiting Drone Ground Effect for Accurate Edge Detection](https://arxiv.org/abs/2509.21085)
*Chenyu Zhao,Jingao Xu,Ciyu Ruan,Haoyang Wang,Shengbo Wang,Jiaqi Li,Jirong Zha,Weijie Hong,Zheng Yang,Yunhao Liu,Xiao-Ping Zhang,Xinlei Chen*

Main category: cs.RO

TL;DR: 通过分析无人机的基本姿态传感器读数和飞行指令来检测地面效应变化，从而实现高效的边缘检测。


<details>
  <summary>Details</summary>
Motivation: 当前无人机边缘检测方法成本高且计算需求高，本研究旨在提出一种新的、低成本、高效率的边缘检测方法。

Method: 提出AirTouch系统，利用地面效应作为新的传感模态，通过分析无人机姿态传感器读数和飞行指令来检测地面效应变化，以识别边缘。

Result: AirTouch系统实现了高检测精度，平均检测距离误差为0.051m，优于基线方法86%，同时功耗仅为43mW。

Conclusion: AirTouch系统利用地面效应作为一种新的传感模态，在低成本和高效率方面具有显著优势，可用于无人机的场景边缘检测。

Abstract: Drone-based rapid and accurate environmental edge detection is highly
advantageous for tasks such as disaster relief and autonomous navigation.
Current methods, using radars or cameras, raise deployment costs and burden
lightweight drones with high computational demands. In this paper, we propose
AirTouch, a system that transforms the ground effect from a stability "foe" in
traditional flight control views, into a "friend" for accurate and efficient
edge detection. Our key insight is that analyzing drone basic attitude sensor
readings and flight commands allows us to detect ground effect changes. Such
changes typically indicate the drone flying over a boundary of two materials,
making this information valuable for edge detection. We approach this insight
through theoretical analysis, algorithm design, and implementation, fully
leveraging the ground effect as a new sensing modality without compromising
drone flight stability, thereby achieving accurate and efficient scene edge
detection. We also compare this new sensing modality with vision-based methods
to clarify its exclusive advantages in resource efficiency and detection
capability. Extensive evaluations demonstrate that our system achieves a high
detection accuracy with mean detection distance errors of 0.051m, outperforming
the baseline method performance by 86%. With such detection performance, our
system requires only 43 mW power consumption, contributing to this new sensing
modality for low-cost and highly efficient edge detection.

</details>


### [266] [Cross-Modal Instructions for Robot Motion Generation](https://arxiv.org/abs/2509.21107)
*William Barron,Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 本研究提出了一种名为CrossInstruct的新范式，通过结合自由形式的文本标签等跨模态指令来训练机器人，以替代传统的动作演示。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人行为教学依赖于繁琐的动作演示（如远程操作或物理引导），且数据收集和数据集扩展困难。本研究旨在探索一种更便捷、可扩展的机器人教学方法。

Method: CrossInstruct框架将跨模态指令整合到基础视觉-语言模型（VLM）的上下文输入中。VLM通过迭代查询一个小型、经过微调的模型，并从多个2D视图合成所需的运动，最终融合得到3D运动轨迹。该方法结合了大型VLM的推理能力和一个精细的指向模型。

Result: CrossInstruct能够生成可执行的机器人行为，并且能够泛化到超出有限指令示例集的环境。通过下游强化学习流程，CrossInstruct的输出可以有效地学习完成精细任务的策略。在模拟任务和真实硬件上的评估表明，该方法无需额外微调即可有效运行，并为后续的强化学习提供了良好的初始化。

Conclusion: CrossInstruct通过利用跨模态指令（如文本标签）作为机器人教学的替代范式，克服了传统方法在数据收集和可扩展性方面的限制。该框架能够生成泛化性强的机器人行为，并能作为强化学习策略的有效起点。

Abstract: Teaching robots novel behaviors typically requires motion demonstrations via
teleoperation or kinaesthetic teaching, that is, physically guiding the robot.
While recent work has explored using human sketches to specify desired
behaviors, data collection remains cumbersome, and demonstration datasets are
difficult to scale. In this paper, we introduce an alternative paradigm,
Learning from Cross-Modal Instructions, where robots are shaped by
demonstrations in the form of rough annotations, which can contain free-form
text labels, and are used in lieu of physical motion. We introduce the
CrossInstruct framework, which integrates cross-modal instructions as examples
into the context input to a foundational vision-language model (VLM). The VLM
then iteratively queries a smaller, fine-tuned model, and synthesizes the
desired motion over multiple 2D views. These are then subsequently fused into a
coherent distribution over 3D motion trajectories in the robot's workspace. By
incorporating the reasoning of the large VLM with a fine-grained pointing
model, CrossInstruct produces executable robot behaviors that generalize beyond
the environment of in the limited set of instruction examples. We then
introduce a downstream reinforcement learning pipeline that leverages
CrossInstruct outputs to efficiently learn policies to complete fine-grained
tasks. We rigorously evaluate CrossInstruct on benchmark simulation tasks and
real hardware, demonstrating effectiveness without additional fine-tuning and
providing a strong initialization for policies subsequently refined via
reinforcement learning.

</details>


### [267] [Rich State Observations Empower Reinforcement Learning to Surpass PID: A Drone Ball Balancing Study](https://arxiv.org/abs/2509.21122)
*Mingjiang Liu,Hailong Huang*

Main category: cs.RO

TL;DR: 无人机通过绳索与可移动的梁进行交互，以稳定梁上的球，并提出了一个分层的控制框架，将高级平衡策略与低级无人机控制分离，并训练了一个强化学习（RL）策略来处理高级决策。


<details>
  <summary>Details</summary>
Motivation: 解决无人机球体稳定任务，即无人机通过绳索交互来稳定可移动梁上的球体。

Method: 提出一个分层控制框架，将高级平衡策略与低级无人机控制分离开来，并训练了一个强化学习（RL）策略来处理高级决策。

Result: 与同一分层结构中的精心调整的PID控制器相比，RL策略取得了卓越的性能。

Conclusion: RL的优势并非来自改进的参数调整或固有的非线性映射能力，而是来自其有效利用更丰富的状态观测的能力。这些发现强调了全面的状态表示在基于学习的系统中起着至关重要的作用，并表明增强的传感可能有助于提高控制器的性能。

Abstract: This paper addresses a drone ball-balancing task, in which a drone stabilizes
a ball atop a movable beam through cable-based interaction. We propose a
hierarchical control framework that decouples high-level balancing policy from
low-level drone control, and train a reinforcement learning (RL) policy to
handle the high-level decision-making. Simulation results show that the RL
policy achieves superior performance compared to carefully tuned PID
controllers within the same hierarchical structure. Through systematic
comparative analysis, we demonstrate that RL's advantage stems not from
improved parameter tuning or inherent nonlinear mapping capabilities, but from
its ability to effectively utilize richer state observations. These findings
underscore the critical role of comprehensive state representation in
learning-based systems and suggest that enhanced sensing could be instrumental
in improving controller performance.

</details>


### [268] [Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems](https://arxiv.org/abs/2509.21143)
*Junfeng Yan,Biao Wu,Meng Fang,Ling Chen*

Main category: cs.RO

TL;DR: 该论文提出了Automotive-ENV基准和ASURADA智能体，以应对车载GUI交互的挑战，并证明了地理感知信息对提高安全相关任务性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于驾驶员注意力有限、安全要求严格以及基于位置的复杂交互模式，现有通用GUI交互的多模态智能体在汽车系统中的应用尚不充分。

Method: 提出了一种名为Automotive-ENV的高保真基准和交互环境，包含185个参数化任务，并提出了一个名为ASURADA的地理感知多模态智能体，该智能体整合了GPS信息以根据位置、环境条件和区域驾驶规范动态调整动作。

Result: 实验表明，地理感知信息显著提高了在安全相关任务上的成功率，证明了基于位置的上下文在汽车环境中的重要性。

Conclusion: ASURADA智能体利用地理感知信息提高了在安全相关任务上的表现，并强调了在汽车环境中整合位置信息的重要性。研究者将发布Automotive-ENV基准，以促进安全、自适应的车载智能体的发展。

Abstract: Multimodal agents have demonstrated strong performance in general GUI
interactions, but their application in automotive systems has been largely
unexplored. In-vehicle GUIs present distinct challenges: drivers' limited
attention, strict safety requirements, and complex location-based interaction
patterns. To address these challenges, we introduce Automotive-ENV, the first
high-fidelity benchmark and interaction environment tailored for vehicle GUIs.
This platform defines 185 parameterized tasks spanning explicit control,
implicit intent understanding, and safety-aware tasks, and provides structured
multimodal observations with precise programmatic checks for reproducible
evaluation. Building on this benchmark, we propose ASURADA, a geo-aware
multimodal agent that integrates GPS-informed context to dynamically adjust
actions based on location, environmental conditions, and regional driving
norms. Experiments show that geo-aware information significantly improves
success on safety-aware tasks, highlighting the importance of location-based
context in automotive environments. We will release Automotive-ENV, complete
with all tasks and benchmarking tools, to further the development of safe and
adaptive in-vehicle agents.

</details>


### [269] [DAGDiff: Guiding Dual-Arm Grasp Diffusion to Stable and Collision-Free Grasps](https://arxiv.org/abs/2509.21145)
*Md Faizal Karim,Vignesh Vembar,Keshab Patra,Gaurav Singh,K Madhava Krishna*

Main category: cs.RO

TL;DR: DAGDiff是一个端到端框架，通过在SE(3) x SE(3)空间中直接去噪生成双臂抓取对，解决了可靠双臂抓取的问题。


<details>
  <summary>Details</summary>
Motivation: 双臂抓取对于操纵大型复杂物体至关重要，但由于稳定性、碰撞和泛化要求，仍然是一个挑战性问题。以往的方法通常将任务分解为两个独立的抓取提案，依赖于区域先验或启发式方法，这限制了泛化能力，并且没有提供原则性的稳定性保证。

Method: DAGDiff通过结合几何感知、稳定性感知和碰撞感知引导项，直接在SE(3) x SE(3)空间中通过去噪生成抓取对，而不是依赖显式的区域检测或物体先验。

Result: 通过分析性力闭合检查、碰撞分析和大规模基于物理的模拟对DAGDiff进行了全面评估，结果显示在这些指标上相比先前工作有持续改进。此外，DAGDiff在真实世界中以前未见过的物体点云上直接生成双臂抓取，并在异构双臂设置上成功执行，实现了可靠抓取和提升。

Conclusion: DAGDiff通过在SE(3) x SE(3)空间中直接生成抓取对，并利用引导的扩散过程来强制执行稳定性与碰撞避免，从而在双臂抓取任务中取得了优于先前方法的性能。

Abstract: Reliable dual-arm grasping is essential for manipulating large and complex
objects but remains a challenging problem due to stability, collision, and
generalization requirements. Prior methods typically decompose the task into
two independent grasp proposals, relying on region priors or heuristics that
limit generalization and provide no principled guarantee of stability. We
propose DAGDiff, an end-to-end framework that directly denoises to grasp pairs
in the SE(3) x SE(3) space. Our key insight is that stability and collision can
be enforced more effectively by guiding the diffusion process with classifier
signals, rather than relying on explicit region detection or object priors. To
this end, DAGDiff integrates geometry-, stability-, and collision-aware
guidance terms that steer the generative process toward grasps that are
physically valid and force-closure compliant. We comprehensively evaluate
DAGDiff through analytical force-closure checks, collision analysis, and
large-scale physics-based simulations, showing consistent improvements over
previous work on these metrics. Finally, we demonstrate that our framework
generates dual-arm grasps directly on real-world point clouds of previously
unseen objects, which are executed on a heterogeneous dual-arm setup where two
manipulators reliably grasp and lift them.

</details>


### [270] [Human-like Navigation in a World Built for Humans](https://arxiv.org/abs/2509.21189)
*Bhargav Chandaka,Gloria X. Wang,Haozhe Chen,Henry Che,Albert J. Zhai,Shenlong Wang*

Main category: cs.RO

TL;DR: ReasonNav是一个结合了人类导航行为（如读标识、问路）的机器人导航系统，利用视觉语言模型（VLM）进行推理，提高了在大型复杂建筑中导航的效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航系统缺乏类似人类的导航行为，在大环境中效率低下。

Method: 提出ReasonNav系统，该系统利用视觉语言模型（VLM）的推理能力，并通过基于导航地标的紧凑输入输出抽象，使VLM专注于语言理解和推理。

Result: 在真实和模拟的导航任务中，ReasonNav能够成功运用高阶推理，高效地在大型复杂建筑中导航。

Conclusion: ReasonNav通过集成人类导航行为和VLM的推理能力，克服了传统机器人导航系统的效率问题，能在大型复杂环境中实现高效导航。

Abstract: When navigating in a man-made environment they haven't visited before--like
an office building--humans employ behaviors such as reading signs and asking
others for directions. These behaviors help humans reach their destinations
efficiently by reducing the need to search through large areas. Existing robot
navigation systems lack the ability to execute such behaviors and are thus
highly inefficient at navigating within large environments. We present
ReasonNav, a modular navigation system which integrates these human-like
navigation skills by leveraging the reasoning capabilities of a vision-language
model (VLM). We design compact input and output abstractions based on
navigation landmarks, allowing the VLM to focus on language understanding and
reasoning. We evaluate ReasonNav on real and simulated navigation tasks and
show that the agent successfully employs higher-order reasoning to navigate
efficiently in large, complex buildings.

</details>


### [271] [SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation](https://arxiv.org/abs/2509.21231)
*Jaehwi Jang,Zhuoheng Wang,Ziyi Zhou,Feiyang Wu,Ye Zhao*

Main category: cs.RO

TL;DR: 通过引入一种包含模型增强残差学习和扰动生成器的模型引导强化学习的稳定终端执行器控制（SEEC）框架，实现了人形机器人 loco-manipulation 任务中的高精度和鲁棒的终端执行器稳定控制，使其能够适应未知的下半身扰动和控制策略。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在 loco-manipulation 任务中实现手臂末端执行器稳定至关重要，但这在实践中具有挑战性，因为双足机器人结构具有高自由度和固有的动态不稳定性。现有的基于模型的控制器虽然精度高，但依赖于精确的动力学建模和估计，而在实际应用中往往难以捕捉真实世界的因素（例如摩擦和齿隙），导致性能下降。基于学习的方法虽然可以更好地适应这些因素，但常常存在过拟合问题，需要对整个身体进行重新训练，并且难以适应看不见的情况。

Method: 提出了一种新颖的稳定终端执行器控制（SEEC）框架，该框架采用模型增强残差学习，并通过包含扰动生成器的模型引导强化学习（RL）来学习实现对由下半身引起的干扰的高精度和鲁棒的末端执行器补偿。这种设计使上身策略能够实现精确的末端执行器稳定，并能适应未知的运动控制器，而无需额外的训练。

Result: 在不同的模拟器中验证了该框架，并将训练好的策略迁移到了Booster T1人形机器人上。实验表明，该方法在各种严苛的 loco-manipulation 任务中，始终优于基线方法，并能稳健地处理多样化的任务。

Conclusion: SEEC框架通过模型增强残差学习和模型引导强化学习，有效地解决了人形机器人 loco-manipulation 任务中的末端执行器稳定问题，提高了控制精度和鲁棒性，并具备良好的适应性和泛化能力。

Abstract: Arm end-effector stabilization is essential for humanoid loco-manipulation
tasks, yet it remains challenging due to the high degrees of freedom and
inherent dynamic instability of bipedal robot structures. Previous model-based
controllers achieve precise end-effector control but rely on precise dynamics
modeling and estimation, which often struggle to capture real-world factors
(e.g., friction and backlash) and thus degrade in practice. On the other hand,
learning-based methods can better mitigate these factors via exploration and
domain randomization, and have shown potential in real-world use. However, they
often overfit to training conditions, requiring retraining with the entire
body, and still struggle to adapt to unseen scenarios. To address these
challenges, we propose a novel stable end-effector control (SEEC) framework
with model-enhanced residual learning that learns to achieve precise and robust
end-effector compensation for lower-body induced disturbances through
model-guided reinforcement learning (RL) with a perturbation generator. This
design allows the upper-body policy to achieve accurate end-effector
stabilization as well as adapt to unseen locomotion controllers with no
additional training. We validate our framework in different simulators and
transfer trained policies to the Booster T1 humanoid robot. Experiments
demonstrate that our method consistently outperforms baselines and robustly
handles diverse and demanding loco-manipulation tasks.

</details>


### [272] [FSGlove: An Inertial-Based Hand Tracking System with Shape-Aware Calibration](https://arxiv.org/abs/2509.21242)
*Yutong Li,Jieyi Zhang,Wenqiang Xu,Tutian Tang,Cewu Lu*

Main category: cs.RO

TL;DR: FSGlove是一个基于惯性测量单元(IMU)的手部动作捕捉系统，可追踪多达48个自由度并重建个性化手部形状，精度优于现有商业设备。


<details>
  <summary>Details</summary>
Motivation: 现有手部动作捕捉系统在捕捉高自由度关节运动和个性化手部形状方面存在局限性，商业手套自由度不足，且忽略了对手部形状差异化的考量，而这些对手部形状的精确捕捉对于触碰敏感的任务至关重要。

Method: FSGlove系统通过在每个手指关节和手背上安装IMU，实现了高分辨率的运动传感。该系统集成了DiffHCal方法，通过可微分优化与MANO参数模型相结合，在单一的校准过程中同时解决了关节运动学、形状参数和传感器未对准的问题。

Result: FSGlove系统在精度方面达到了最先进的水平，关节角度误差小于2.7度，在手部形状重建和触碰保真度方面优于商业设备。该系统还能捕捉精细的动作，如指尖摩擦。

Conclusion: FSGlove系统通过整合运动学和触碰保真度，在手部追踪方面取得了显著进展，其开源的硬件和软件设计使其能够兼容现有的VR和机器人生态系统，并在人手灵活性和机器人模仿能力之间架起了桥梁。

Abstract: Accurate hand motion capture (MoCap) is vital for applications in robotics,
virtual reality, and biomechanics, yet existing systems face limitations in
capturing high-degree-of-freedom (DoF) joint kinematics and personalized hand
shape. Commercial gloves offer up to 21 DoFs, which are insufficient for
complex manipulations while neglecting shape variations that are critical for
contact-rich tasks. We present FSGlove, an inertial-based system that
simultaneously tracks up to 48 DoFs and reconstructs personalized hand shapes
via DiffHCal, a novel calibration method. Each finger joint and the dorsum are
equipped with IMUs, enabling high-resolution motion sensing. DiffHCal
integrates with the parametric MANO model through differentiable optimization,
resolving joint kinematics, shape parameters, and sensor misalignment during a
single streamlined calibration. The system achieves state-of-the-art accuracy,
with joint angle errors of less than 2.7 degree, and outperforms commercial
alternatives in shape reconstruction and contact fidelity. FSGlove's
open-source hardware and software design ensures compatibility with current VR
and robotics ecosystems, while its ability to capture subtle motions (e.g.,
fingertip rubbing) bridges the gap between human dexterity and robotic
imitation. Evaluated against Nokov optical MoCap, FSGlove advances hand
tracking by unifying the kinematic and contact fidelity. Hardware design,
software, and more results are available at:
https://sites.google.com/view/fsglove.

</details>


### [273] [RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models](https://arxiv.org/abs/2509.21243)
*Jiyeon Koo,Taewan Cho,Hyunjoon Kang,Eunseom Pyo,Tae Gyun Oh,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: 通过重新利用Vision Transformer中的Register Tokens，RetoVLA在保持轻量化结构的同时，提升了机器人模型在复杂操作任务中的空间推理能力和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action (VLA)模型虽然泛化能力强，但体积大、计算成本高，限制了其实际应用。传统的轻量化方法又会牺牲关键能力，特别是空间推理能力，导致效率和性能之间的权衡。

Method: 提出了一种名为RetoVLA的新架构，该架构重新利用了最初为去除Vision Transformer中的伪影而引入但随后被丢弃的Register Tokens。将这些Tokens直接注入到Action Expert中，以利用其包含的空间信息来增强推理能力，同时保持模型轻量化。

Result: 在自定义的7-DOF机器人手臂上进行的大量实验证明，RetoVLA在复杂操作任务的成功率上实现了17.1%的绝对提升。实验结果表明，重新利用Register Tokens能有效增强空间推理能力。

Conclusion: 重新利用Register Tokens是提升机器人智能的一种有价值且未被充分探索的方法，能够显著增强空间推理能力，同时保持模型的轻量化。

Abstract: Recent Vision-Language-Action (VLA) models demonstrate remarkable
generalization in robotics but are restricted by their substantial size and
computational cost, limiting real-world deployment. However, conventional
lightweighting methods often sacrifice critical capabilities, particularly
spatial reasoning. This creates a trade-off between efficiency and performance.
To address this challenge, our work reuses Register Tokens, which were
introduced for artifact removal in Vision Transformers but subsequently
discarded. We suppose that these tokens contain essential spatial information
and propose RetoVLA, a novel architecture that reuses them directly by
injecting them into the Action Expert.
  RetoVLA maintains a lightweight structure while leveraging this repurposed
spatial context to enhance reasoning. We demonstrate RetoVLA's effectiveness
through a series of comprehensive experiments. On our custom-built 7-DOF robot
arm, the model achieves a 17.1%p absolute improvement in success rates for
complex manipulation tasks. Our results confirm that reusing Register Tokens
directly enhances spatial reasoning, demonstrating that what was previously
discarded as an artifact is in fact a valuable, unexplored resource for robotic
intelligence. A video demonstration is available at:
https://youtu.be/2CseBR-snZg

</details>


### [274] [BiNoMaP: Learning Category-Level Bimanual Non-Prehensile Manipulation Primitives](https://arxiv.org/abs/2509.21256)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: 本文提出了一种双臂非抓取操作方法BiNoMaP，通过从视频演示中提取轨迹并进行几何感知后优化，实现了机器人非抓取操作的学习和泛化。


<details>
  <summary>Details</summary>
Motivation: 现有机器人研究忽视了推、戳、转等非抓取操作，且多采用单臂设置和对外部环境的强依赖。本文旨在解决这一问题，提出一种更通用的双臂方法。

Method: 首先，提出双臂非抓取操作原语（BiNoMaP）。然后，提出一个无强化学习的三阶段框架：从视频演示中提取双臂手部运动轨迹；提出一个几何感知后优化算法，将粗糙轨迹优化为可执行的操作原语；通过物体几何属性（尤其是尺寸）参数化学习到的原语，实现类别级泛化。

Result: 在多种代表性双臂任务和不同物体类别上验证了BiNoMaP的有效性、效率、多功能性和优越的泛化能力。

Conclusion: BiNoMaP是一种有效的双臂非抓取操作学习和泛化方法，克服了现有方法的局限性，并在实验中得到了验证。

Abstract: Non-prehensile manipulation, encompassing ungraspable actions such as
pushing, poking, and pivoting, represents a critical yet underexplored domain
in robotics due to its contact-rich and analytically intractable nature. In
this work, we revisit this problem from two novel perspectives. First, we move
beyond the usual single-arm setup and the strong assumption of favorable
external dexterity such as walls, ramps, or edges. Instead, we advocate a
generalizable dual-arm configuration and establish a suite of Bimanual
Non-prehensile Manipulation Primitives (BiNoMaP). Second, we depart from the
prevailing RL-based paradigm and propose a three-stage, RL-free framework to
learn non-prehensile skills. Specifically, we begin by extracting bimanual hand
motion trajectories from video demonstrations. Due to visual inaccuracies and
morphological gaps, these coarse trajectories are difficult to transfer
directly to robotic end-effectors. To address this, we propose a geometry-aware
post-optimization algorithm that refines raw motions into executable
manipulation primitives that conform to specific motion patterns. Beyond
instance-level reproduction, we further enable category-level generalization by
parameterizing the learned primitives with object-relevant geometric
attributes, particularly size, resulting in adaptable and general parameterized
manipulation primitives. We validate BiNoMaP across a range of representative
bimanual tasks and diverse object categories, demonstrating its effectiveness,
efficiency, versatility, and superior generalization capability.

</details>


### [275] [\LARGE GMP$^{3}$: Learning-Driven, Bellman-Guided Trajectory Planning for UAVs in Real-Time on SE(3)](https://arxiv.org/abs/2509.21264)
*Babak Salamat,Dominik Mattern,Sebastian-Sven Olzem,Gerhard Elsbacher,Christian Seidel,Andrea M. Tonello*

Main category: cs.RO

TL;DR: GMP3是一个用于无人机（UAV）的多阶段全局路径规划框架，它能在复杂的环境中生成动态可行的三维轨迹。


<details>
  <summary>Details</summary>
Motivation: 在复杂的环境中为无人机生成动态可行的三维轨迹，并实现平移运动和旋转动力学的联合学习，以及支持协同策略更新和实时部署。

Method: GMP3将传统路径规划从欧几里得空间扩展到李群SE(3)，引入改进的贝尔曼算子进行强化学习策略更新，并利用已有轨迹信息加速收敛。该框架采用分布式设计，允许智能体之间通过基于共识的方案共享策略信息，进行协同策略更新。同时，DroneManager作为模块化地面控制软件，通过MAVLink协议与无人机平台接口，支持实时部署和反馈。

Result: 在仿真研究和室内飞行实验中，GMP3在受限的三维环境中表现出有效性，实现了可靠的避障以及平稳、可行的位姿轨迹。

Conclusion: GMP3框架能够成功生成满足动态约束的无人机三维轨迹，并在复杂环境中实现有效的避障和协同规划。DroneManager软件支持该框架的实时部署。

Abstract: We propose $\text{GMP}^{3}$, a multiphase global path planning framework that
generates dynamically feasible three-dimensional trajectories for unmanned
aerial vehicles (UAVs) operating in cluttered environments. The framework
extends traditional path planning from Euclidean position spaces to the Lie
group $\mathrm{SE}(3)$, allowing joint learning of translational motion and
rotational dynamics. A modified Bellman-based operator is introduced to support
reinforcement learning (RL) policy updates while leveraging prior trajectory
information for improved convergence. $\text{GMP}^{3}$ is designed as a
distributed framework in which agents influence each other and share policy
information along the trajectory: each agent refines its assigned segment and
shares with its neighbors via a consensus-based scheme, enabling cooperative
policy updates and convergence toward a path shaped globally even under
kinematic constraints. We also propose DroneManager, a modular ground control
software that interfaces the planner with real UAV platforms via the MAVLink
protocol, supporting real-time deployment and feedback. Simulation studies and
indoor flight experiments validate the effectiveness of the proposed method in
constrained 3D environments, demonstrating reliable obstacle avoidance and
smooth, feasible trajectories across both position and orientation. The
open-source implementation is available at
https://github.com/Domattee/DroneManager

</details>


### [276] [Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds](https://arxiv.org/abs/2509.21281)
*Luis Augenstein,Noémie Jaquier,Tamim Asfour,Leonel Rozo*

Main category: cs.RO

TL;DR: 该研究提出了一种名为GPHDM的新方法，用于生成具有层次结构和物理一致性的人类运动。该方法通过在高维双曲流形上扩展高斯过程动力学模型（GPDM）的动力学先验，并结合与分类信息相关的归纳偏倚来实现。最后，提出三种新机制（两种概率递归方法和一种基于度量投影测地线的方法）来生成符合分类结构且物理上一致的运动。实验表明，GPHDM能够准确捕捉运动的层次结构和时间动态，并生成新的、物理上一致的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 当前机器人运动生成方法通常忽视运动的层次结构信息，导致生成的运动与实际运动存在差距。

Method: 将高斯过程动力学模型（GPDM）的动力学先验扩展到双曲流形，并结合与分类信息相关的归纳偏倚。提出三种新机制：两种概率递归方法和一种基于度量投影测地线的方法。

Result: GPHDM能够准确捕捉运动的层次结构和时间动态，并生成新的、物理上一致的运动轨迹。

Conclusion: GPHDM能够生成既符合层次结构又具备物理一致性的人类运动，解决了现有方法忽略运动层次结构的问题。

Abstract: Human-like motion generation for robots often draws inspiration from
biomechanical studies, which often categorize complex human motions into
hierarchical taxonomies. While these taxonomies provide rich structural
information about how movements relate to one another, this information is
frequently overlooked in motion generation models, leading to a disconnect
between the generated motions and their underlying hierarchical structure. This
paper introduces the \ac{gphdm}, a novel approach that learns latent
representations preserving both the hierarchical structure of motions and their
temporal dynamics to ensure physical consistency. Our model achieves this by
extending the dynamics prior of the Gaussian Process Dynamical Model (GPDM) to
the hyperbolic manifold and integrating it with taxonomy-aware inductive
biases. Building on this geometry- and taxonomy-aware frameworks, we propose
three novel mechanisms for generating motions that are both
taxonomically-structured and physically-consistent: two probabilistic recursive
approaches and a method based on pullback-metric geodesics. Experiments on
generating realistic motion sequences on the hand grasping taxonomy show that
the proposed GPHDM faithfully encodes the underlying taxonomy and temporal
dynamics, and generates novel physically-consistent trajectories.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [277] [Average-Case Complexity of Quantum Stabilizer Decoding](https://arxiv.org/abs/2509.20697)
*Andrey Boris Khesin,Jonathan Z. Lu,Alexander Poremba,Akshar Ramkumar,Vinod Vaikuntanathan*

Main category: quant-ph

TL;DR: 随机量子稳定码的解码难度不亚于最难的经典随机码解码问题，且任何有效的量子解码算法都将对密码学构成威胁。


<details>
  <summary>Details</summary>
Motivation: 探究随机量子稳定码的解码复杂度，并与经典随机码解码复杂度进行比较，填补了该领域的认知空白。

Method: 证明了包含单个逻辑量子比特的随机稳定码的解码难度，至少与经典随机码在恒定速率下的解码难度相当。推导了Clifford熵和Pauli混合时间的界限，并证明了量子退化等量子现象导致稳定码解码的多种定义具有不同的复杂度。

Result: 随机稳定码的解码难度至少与经典随机码在恒定速率下的解码难度相当；证明了量子稳定码在随机自归约方面存在显著障碍；展示了搜索与决策之间的自归约；揭示了量子退化等现象对稳定码解码定义复杂度的影响。

Conclusion: 随机量子稳定码的解码问题在最坏情况下至少和经典随机码的解码问题一样难，并且任何有效的量子解码算法都将对密码学构成突破性威胁。量子现象（如量子退化）使得不同稳定码解码定义的复杂度各不相同。

Abstract: Random classical linear codes are widely believed to be hard to decode. While
slightly sub-exponential time algorithms exist when the coding rate vanishes
sufficiently rapidly, all known algorithms at constant rate require exponential
time. By contrast, the complexity of decoding a random quantum stabilizer code
has remained an open question for quite some time. This work closes the gap in
our understanding of the algorithmic hardness of decoding random quantum versus
random classical codes. We prove that decoding a random stabilizer code with
even a single logical qubit is at least as hard as decoding a random classical
code at constant rate--the maximally hard regime. This result suggests that the
easiest random quantum decoding problem is at least as hard as the hardest
random classical decoding problem, and shows that any sub-exponential algorithm
decoding a typical stabilizer code, at any rate, would immediately imply a
breakthrough in cryptography.
  More generally, we also characterize many other complexity-theoretic
properties of stabilizer codes. While classical decoding admits a random
self-reduction, we prove significant barriers for the existence of random
self-reductions in the quantum case. This result follows from new bounds on
Clifford entropies and Pauli mixing times, which may be of independent
interest. As a complementary result, we demonstrate various other
self-reductions which are in fact achievable, such as between search and
decision. We also demonstrate several ways in which quantum phenomena, such as
quantum degeneracy, force several reasonable definitions of stabilizer
decoding--all of which are classically identical--to have distinct or
non-trivially equivalent complexity.

</details>


### [278] [Realization of Graphene Quantum Dots for Innovative Biosensor Development and Diverse Applications](https://arxiv.org/abs/2509.20547)
*Kumar Gautam,Kumar Shubham,Hitesh Sharma,Divya Punia,Ajay K Sharma,Namisha Gupta,Varun Rathor,Vishakha Singh*

Main category: quant-ph

TL;DR: 石墨烯量子点（GQD）作为一种无毒、高稳定性的传统量子点（QD）替代品，在生物传感、食品安全和储能等领域展现出巨大潜力，有望推动纳米技术和量子技术的发展。


<details>
  <summary>Details</summary>
Motivation: 传统量子点（如CdTe）存在毒性和稳定性问题，而石墨烯量子点（GQD）作为一种更安全、更稳定的替代品，具有独特的电子和光学特性，在生物医学、电子学和储能领域具有应用前景。

Method: 本文综述了GQD的合成方法（自上而下和自下而上），并强调了其在光稳定性、生物相容性和可调带隙方面相对于标准QD的优势。

Result: GQD因其低毒性、高灵敏度和低成本等优点，在生物传感、食品安全监测和智能包装等实际应用中表现出色，这些应用对减少粮食浪费至关重要。

Conclusion: GQD在先进纳米技术和量子技术领域的重要性日益增加，并在生物传感、食品安全、环境监测和量子电子学等领域展现出创新应用潜力。

Abstract: This paper investigates quantum dots (QDs), which are miniature semiconductor
structures with remarkable optical and electrical properties due to quantum
confinement processes. Traditional QDs, such as CdTe, have been extensively
investigated; however, they frequently exhibit toxicity and stability issues.
Graphene quantum dots (GQDs) are emerging as a safer and more stable
alternative to traditional QDs. GQDs are honeycomb-lattice carbon atoms with
unique electronic and optical properties that make them promising candidates
for biomedical, electronic, and energy storage applications. GQD synthesis
methods (top-down and bottom-up) and their advantages over standard QDs include
better photostability, biocompatibility, and configurable band gaps. GQDs are
perfect for real-world uses like sensitive biosensing, real-time food safety
monitoring, and smart packaging because of their low toxicity, high
sensitivity, and affordability. These uses are all essential for cutting down
on food grain waste. This emphasizes the growing significance of GQDs in
advancing nanotechnology and their potential integration with quantum
technologies, paving the door for creative solutions in biosensing, food
safety, environmental monitoring, and future quantum electronics.

</details>


### [279] [Distillation of supersinglet states](https://arxiv.org/abs/2509.20962)
*Saeed Ahmad,Shuang Li,Jonathan Raghoonanan,Kaixuan Zhou,Valentin Ivannikov,Tim Byrnes*

Main category: quant-ph

TL;DR: 本论文提出了一种针对N量子比特超单态的纠缠蒸馏协议，通过测量三个初始自旋零态的局部总自旋基，并进行后选择，生成更高保真度的超单态。该协议仅使用局域操作和经典通信，适用于长距离量子应用，并避免了高维Schur变换，可用于量子计量等任务。


<details>
  <summary>Details</summary>
Motivation: 介绍一种用于N量子比特超单态的纠缠蒸馏（纯化）协议，该超单态具有总自旋为零、自旋方差为零的特性，并且所有量子比特都完全纠缠。

Method: 使用三个初始自旋零态的副本，在局域总自旋基进行测量，并通过后选择生成更高保真度的超单态。

Result: 实现了对超单态的纠缠蒸馏，生成了保真度更高的超单态，且该协议仅使用局域操作和经典通信，适用于长距离应用，并避免了高维Schur变换。

Conclusion: 提出的超单态纠缠蒸馏协议是一种有效的、仅使用局域操作和经典通信的方法，适用于长距离量子应用，如量子时钟同步、量子密码学和量子计量。

Abstract: We introduce an entanglement distillation (purification) protocol for
supersinglet states composed of N qubits. The supersinglet state we target is a
total spin zero state with zero spin variance, and has a fully entangled
structure involving all qubits. In our distillation protocol, three copies of
an initial spin zero state are measured in the local total spin basis such that
a higher fidelity supersinglet state is generated upon postselection. The
initial state can be prepared using conventional Bell state distillation
methods distributed in a way to target the supersinglet symmetries. The
protocol uses only local operations and classical communications, and is
suitable for long-distance applications such as quantum clock synchronization
and cryptography, and avoids a high dimensional Schur transform such that it
can be used for tasks such as quantum metrology.

</details>


### [280] [Observables in Motion: A guide to simulating classical and quantum dynamics](https://arxiv.org/abs/2509.20403)
*Denys I. Bondar,Gerard McCaul,Andrii Sotnikov*

Main category: quant-ph

TL;DR: 一本介绍量子和经典动力学希尔伯特空间表示的教科书，包含数学基础、模拟指南和Python实现。


<details>
  <summary>Details</summary>
Motivation: 介绍量子和经典动力学的希尔伯特空间表示，并提供数学基础、模拟指南和Python实现。

Method: 系统地阐述了理解经典和量子系统所需的数学基础、运动学描述和形式演化理论。提供了数值模拟时间依赖薛定谔演化、经典动力学（通过辛积分器）以及开放量子系统（包括相空间表述和随机展开）的实践指南。

Result: 尚未提供具体结果，因为这是一项正在进行中的教学工作。

Conclusion: 本书旨在为读者提供理解和模拟量子及经典动力学的全面指导。

Abstract: We present a pedagogical work-in-progress. This textbook aims to introduce
Hilbert space representations for quantum and classical dynamics, outlining the
mathematical foundations, practical guidance, and Python implementation of
dynamical simulations. Beginning with a historical survey, the book
systematically develops the mathematical foundations, kinematic descriptions,
and formal evolution theory needed to understand both classical and quantum
systems. It then provides practical guidance for numerically simulating
time-dependent Schr\"odinger evolution, classical dynamics through symplectic
integrators, and open quantum systems including phase-space formulations and
stochastic unravellings.

</details>


### [281] [A Review on Quantum Circuit Optimization using ZX-Calculus](https://arxiv.org/abs/2509.20663)
*Tobias Fischbach,Pierre Talbot,Pascal Bourvry*

Main category: quant-ph

TL;DR: ZX-calculus是一种用于优化量子电路的语义保留框架，本综述对其进行了分类和分析，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: NISQ时代量子计算机受限于资源，量子电路优化是关键的缓解策略。ZX-calculus作为一种新的优化框架，有必要进行综述。

Method: 通过优化技术、目标指标和目标量子计算架构对基于ZX的量子电路优化进行分类和回顾。

Result: 对现有基于ZX的量子电路优化技术进行了分类和阐述，并概述了多目标优化、可扩展算法和增强电路提取方法等挑战和未来方向。

Conclusion: 本综述为组合优化和量子计算领域的研究人员提供了关于ZX-based量子电路优化的背景和现有技术分类，有助于推动该领域的研究。

Abstract: Quantum computing promises significant speed-ups for certain algorithms but
the practical use of current noisy intermediate-scale quantum (NISQ) era
computers remains limited by resources constraints (e.g., noise, qubits, gates,
and circuit depth). Quantum circuit optimization is a key mitigation strategy.
In this context, ZX-calculus has emerged as an alternative framework that
allows for semantics-preserving quantum circuit optimization.
  We review ZX-based optimization of quantum circuits, categorizing them by
optimization techniques, target metrics and intended quantum computing
architecture. In addition, we outline critical challenges and future research
directions, such as multi-objective optimization, scalable algorithms, and
enhanced circuit extraction methods. This survey is valuable for researchers in
both combinatorial optimization and quantum computing. For researchers in
combinatorial optimization, we provide the background to understand a new
challenging combinatorial problem: ZX-based quantum circuit optimization. For
researchers in quantum computing, we classify and explain existing circuit
optimization techniques.

</details>


### [282] [Symmetrized operators or modified integration measure in Generalized Uncertainty Principle Models](https://arxiv.org/abs/2509.20466)
*Michael Bishop,Daniel Hooker,Doug Singleton*

Main category: quant-ph

TL;DR: GUP模型可以通过对称算符代替修改内积，以保留标准动量空间。


<details>
  <summary>Details</summary>
Motivation: 修改GUP模型，以对称算符代替修改内积，从而保留标准动量空间。

Method: 比较对称算符和修改内积两种方法。

Result: 对称算符方法保留了标准动量空间，使得修改后的位置算符的本征态和最大局域化态具有标准位置表示。

Conclusion: 对称算符的方法是GUP模型的替代方法，并具有其优点。

Abstract: Many Generalized Uncertainty Principle (GUP) models modify the inner-product
measure to ensure symmetric position or momentum operators. We show that an
alternate approach to these GUPs is to symmetrize the operators rather than
modifying the inner product. This preserves the standard momentum space
allowing the eigenstates and maximally localized states of the modified
position operator to have a standard position representation. We compare both
approaches and highlight their merits.

</details>


### [283] [Computational Relative Entropy](https://arxiv.org/abs/2509.20472)
*Johannes Jakob Meyer,Asad Raza,Jacopo Rizzo,Lorenzo Leone,Sofiene Jerbi,Jens Eisert*

Main category: quant-ph

TL;DR: 计算限制下的信息处理与量子信息理论的新方向。


<details>
  <summary>Details</summary>
Motivation: 现有的信息论在计算能力受限的情况下失效，该研究旨在建立计算限制下的信息理论。

Method: 定义计算相对熵作为基础量，并推导了计算版Stein引理、Pinsker不等式、Rains界等。

Result: 建立了计算信息论框架，展示了计算限制如何改变信息度量，并揭示了计算与非计算信息度量之间的分离。

Conclusion: 计算约束会从根本上改变信息论格局，并开辟量子信息、计算复杂性和密码学交叉领域的新研究方向。

Abstract: Our capacity to process information depends on the computational power at our
disposal. Information theory captures our ability to distinguish states or
communicate messages when it is unconstrained with unrivaled elegance. For
computationally bounded observers the situation is quite different. They can,
for example, be fooled to believe that distributions are more random than they
actually are. In our work, we go beyond the prevailing single-shot approach and
take a new direction in computational quantum information theory that captures
the essence of complexity-constrained information theory while retaining the
look and feel of the unbounded asymptotic theory. As our foundational quantity,
we define the computational relative entropy as the optimal error exponent in
asymmetric hypothesis testing when restricted to polynomially many copies and
quantum gates, defined in a mathematically rigorous way. Building on this
foundation, we prove a computational analogue of Stein's lemma, establish
computational versions of fundamental inequalities like Pinsker's bound, and
demonstrate a computational smoothing property showing that computationally
indistinguishable states yield equivalent information measures. We derive a
computational entropy that operationally characterizes optimal compression
rates for quantum states under computational limitations and show that our
quantities apply to computational entanglement theory, proving a computational
version of the Rains bound. Our framework reveals striking separations between
computational and unbounded information measures, including quantum-classical
gaps that arise from cryptographic assumptions, demonstrating that
computational constraints fundamentally alter the information-theoretic
landscape and open new research directions at the intersection of quantum
information, complexity theory, and cryptography.

</details>


### [284] [Quantum non-Gaussianity based on amplified photon statistics](https://arxiv.org/abs/2509.20492)
*Éva Rácz,László Ruppert,Radim Filip*

Main category: quant-ph

TL;DR: 本研究提出了一种基于光子数均值和方差（或二阶关联 $g^{(2)}$）的量子非高斯性判据，可以直接从放大后的信号中推断未知输入态的量子非高斯性，解决了放大过程中离散量子态向连续信号转换导致 Fock 概率不可知的问题。


<details>
  <summary>Details</summary>
Motivation: 量子放大技术在量子处理和检测中至关重要，但它将离散的量子态转换为连续信号，导致无法直接获取输入态的 Fock 概率。本研究旨在解决这一问题。

Method: 提出并分析了一种新的量子非高斯性判据，该判据基于未知状态的光子数均值和方差（或二阶关联 $g^{(2)}$）。这些参数可以从放大后的信号的积分强度矩中推断出来。

Result: 该方法能够直接从放大后的信号中推断出未知输入态的量子非高斯性。由于该判据仅基于一阶和二阶矩，因此测量结果易于根据损耗和加性噪声进行校正。

Conclusion: 本研究提出的量子非高斯性判据提供了一种有效的方法来表征放大后的量子态，克服了传统方法在处理放大信号时面临的挑战。

Abstract: Amplification is an essential part of quantum processing and detection that
allows for reducing subsequent loss and noise. However, the intensive
amplification transfers individual discrete quanta to a detected continuous
signal, so Fock probabilities of the unknown input state are not readily
available. To solve this issue, we directly derive and analyze a quantum
non-Gaussianity witness based on the photon number mean and variance (or
alternatively, the second-order correlation $g^{(2)}$) of the unknown state,
which can be inferred from post-amplification integrated intensity moments.
Since this new witness is based on first and second moments only, measurement
results are easy to correct for losses and additive noise.

</details>


### [285] [Quantum statistical mechanical gauge invariance](https://arxiv.org/abs/2509.20494)
*Johanna Müller,Matthias Schmidt*

Main category: quant-ph

TL;DR: The paper introduces a framework for gauge invariance in quantum many-body systems, establishing sum rules connecting force and hyperforce densities and showing its applicability in quantum hyperdensity functional theory and nonequilibrium systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address gauge invariance in the statistical mechanics of quantum many-body systems, which is crucial for understanding their behavior.

Method: The method involves representing the gauge transformation by an anti-self-adjoint quantum shifting superoperator with a noncommutative Lie algebra structure, which induces exact equilibrium sum rules.

Result: The result is the establishment of sum rules connecting locally-resolved force and hyperforce densities for any observable, and the demonstration of the framework's integration within quantum hyperdensity functional theory, generalizing to nonequilibrium systems.

Conclusion: The paper concludes that the developed framework effectively handles gauge invariance in quantum many-body systems and offers a generalized approach for both equilibrium and nonequilibrium scenarios.

Abstract: We address gauge invariance in the statistical mechanics of quantum many-body
systems. The gauge transformation acts on the position and momentum degrees of
freedom and it is represented by a quantum shifting superoperator that maps
quantum observables onto each other. The shifting superoperator is
anti-self-adjoint and it has noncommutative Lie algebra structure. These
properties induce exact equilibrium sum rules that connect locally-resolved
force and hyperforce densities for any given observable. We demonstrate the
integration of the framework within quantum hyperdensity functional theory and
show that it generalizes naturally to nonequilibrium.

</details>


### [286] [Towards a user-centric HPC-QC environment](https://arxiv.org/abs/2509.20525)
*Aleksander Wennersteen,Matthieu Moreau,Aurelien Nober,Mourad Beji*

Main category: quant-ph

TL;DR: 开发了一个在高性能计算环境（HPC）和量子处理单元（QPU）上运行的混合量子-经典程序的便携式运行时环境。该中间件通过第二层调度来提高QPU利用率，并提供额外的可观测性、监控和管理功能。


<details>
  <summary>Details</summary>
Motivation: 提供一个健壮的执行环境，以应对量子计算中的关键挑战，如应用程序开发、可移植性和可再现性，并促进模块化量子程序和混合量子工作流的发展。

Method: 在主 HPC 资源管理器之后添加一个额外的调度层，以优化 QPU 利用率，并实现可观测性、监控和管理功能。利用最近提出的不依赖供应商的量子资源管理接口 (QRMI)，支持多个软件开发工具包 (SDK)。

Result: 成功构建了一个在 HPC 环境中增强了 QPU 的混合量子-经典程序的、基础但便携的运行时环境。

Conclusion: 所提出的方法能够通过支持多个 SDK 和提供增强的监控功能，有效地管理混合量子计算系统。

Abstract: Robust execution environments are important for addressing key challenges in
quantum computing, such as application development, portability, and
reproducibility, and help unlock the development of modular quantum programs,
driving forward hybrid quantum workflows. In this work, we show progress
towards a basic, but portable, runtime environment for developing and executing
hybrid quantum-classical programs running in High Performance Computing (HPC)
environments enhanced with Quantum Processing Units (QPUs). The middleware
includes a second layer of scheduling after the main HPC resource manager in
order to improve the utilization of the QPU, and extra functionality for
observability, monitoring, and admin access. This approach enables managing
multiple programming Software Development Kits (SDKs) as first-class citizens
in the environment by building on a recently proposed vendor-neutral Quantum
Resource Management Interface (QRMI). Lastly, we discuss and show a solution
for the monitoring and observability stack, completing our description of the
hybrid system architecture.

</details>


### [287] [Quantum error correction beyond $SU(2)$ spin, bosonic, and permutation-invariant codes from convex geometry](https://arxiv.org/abs/2509.20545)
*Arda Aydin,Victor V. Albert,Alexander Barg*

Main category: quant-ph

TL;DR: 开发了一种用于构建量子纠错码和逻辑门框架，适用于复合排列不变空间、复合恒定激发 Fock 态空间和单片核态空间。通过将这三种空间与离散单纯形和李群 SU(q) 的表示相关联，证明了许多 SU(q) 中的码和门可以在这三种状态空间之间相互转换。利用经典 $\ell_1$ 码和 Tverberg 定理，为所有三种空间构建了新的量子码实例。通过基于组合模式（Sidon 集）的 $\ell_1$ 码及其 Tverberg 分区，获得了码长 N 接近线性增长的新量子码系列，改进了现有设计。还提出了码长更短或总自旋/激发更低的码，以及具有奇异高斯门的新的玻色子码。


<details>
  <summary>Details</summary>
Motivation: 为了构建适用于多种量子系统（复合排列不变空间、复合恒定激发 Fock 态空间、单片核态空间）的量子纠错码和逻辑门。

Method: 将三种空间与离散单纯形和李群 SU(q) 的表示相关联，利用经典 $\ell_1$ 码和 Tverberg 定理构建量子码。基于 Sidon 集及其 Tverberg 分区来构造新的量子码。

Result: 提出了适用于三种空间的新量子码和逻辑门，其中码长 N 接近线性增长。展示了比已知码具有更短码长或更低总自旋/激发的新码实例，以及具有奇异高斯门的新的玻色子码。

Conclusion: 该研究开发了一种通用的量子纠错码和逻辑门构建框架，并通过结合 $\ell_1$ 码和 Tverberg 定理，在多种量子系统中取得了比现有设计更好的性能。

Abstract: We develop a framework for constructing quantum error-correcting codes and
logical gates for three types of spaces -- composite permutation-invariant
spaces of many qubits or qudits, composite constant-excitation Fock-state
spaces of many bosonic modes, and monolithic nuclear state spaces of atoms,
ions, and molecules. By identifying all three spaces with discrete simplices
and representations of the Lie group $SU(q)$, we prove that many codes and
their gates in $SU(q)$ can be inter-converted between the three state spaces.
We construct new code instances for all three spaces using classical $\ell_1$
codes and Tverberg's theorem, a classic result from convex geometry. We obtain
new families of quantum codes with distance that scales almost linearly with
the code length $N$ by constructing $\ell_1$ codes based on combinatorial
patterns called Sidon sets and utilizing their Tverberg partitions. This
improves upon the existing designs for all the state spaces. We present
explicit constructions of codes with shorter length or lower total
spin/excitation than known codes with similar parameters, new bosonic codes
with exotic Gaussian gates, as well as examples of short codes with distance
larger than the known constructions.

</details>


### [288] [Nonlocal Magic Generation and Information Scrambling in Noisy Clifford Circuits](https://arxiv.org/abs/2509.20566)
*Emanuel Dallas,Paolo Zanardi*

Main category: quant-ph

TL;DR: 本地噪声会影响随机Clifford编码-解码电路的平均信息 the 


<details>
  <summary>Details</summary>
Motivation: 研究包含本地噪声的随机Clifford编码-解码电路的平均信息 the 

Method: 利用Clifford群的表示论的最新进展，计算了无限大极限下ACF和APEP的平均值。

Result: ACF和APEP在有限个量子比特上发生的噪声会导致宏观信息 the 

Conclusion: 数值研究了噪声信道的魔态容量（一种算子级的魔态单调性）与所产生电路的APEP之间的关系，这可能为设计高效的非局域魔态 the 

Abstract: In this work, we investigate the average information scrambling and nonlocal
magic generation properties of random Clifford encoding-decoding circuits
perturbed by local noise. We quantify these with the bipartite algebraic
out-of-time order correlator ($\mathcal{A}$-OTOC) and average Pauli-entangling
power (APEP) respectively. Using recent advances in the representation theory
of the Clifford group, we compute both quantities' averages in the limit that
the circuits become infinitely large. We observe that both display a
``butterfly effect" whereby noise occurring on finitely many qubits leads to
macroscopic information scrambling and nonlocal magic generating power.
Finally, we numerically study the relationship between the magic capacity, an
operator-level magic monotone, of the noise channel and the APEP of the
resulting circuit, which may provide insight for designing efficient nonlocal
magic factories.

</details>


### [289] [Excited-CAFQA: A classical simulation bootstrap for the variational estimation of molecular excited states](https://arxiv.org/abs/2509.20588)
*Bikrant Bhattacharyya,Gokul Ravi*

Main category: quant-ph

TL;DR: CAFQA用于VQE，Excited-CAFQA用于VQD，以提高量子化学计算精度。


<details>
  <summary>Details</summary>
Motivation: 目前的量子设备容错能力有限，变分量子算法（VQA）在量子化学应用中的抗噪声能力不足。通过精确的初始值设置是改进VQA的一种方法。CAFQA协议通过经典可模拟的子空间搜索来寻找好的初始值，已被证明对VQE有效。

Method: 提出Excited-CAFQA初始化方法，用于变分量子算法（VQD）。VQD通过在标准VQE成本函数中添加惩罚项来约束计算的能量态，以实现对激发态的计算。CAFQA优化器可以有效地找到每个能量级计算的初始参数。

Result: Excited-CAFQA在H2和HeH+分子体系的多种键长和激发态上实现了90%到99+%的准确率。

Conclusion: Excited-CAFQA是一种有效的VQD初始化方法，可以显著提高量子化学计算的精度。

Abstract: Variational Quantum Algorithms (VQAs) are iterative algorithms suited to
implementation on current-era quantum devices. VQAs employ classical
optimization to minimize cost functions evaluated on quantum circuits. However,
the extent to which VQAs manage noise is often insufficient for quantum
chemistry applications. One method of improving VQAs is through accurate ansatz
initialization. The CAFQA (Clifford Ansatz For Quantum Accuracy) protocol runs
a discrete search through a classically simulatable subset of the entire state
space to find a desirable initialization. Prior work has evaluated CAFQA
applied to the Variational Quantum Eigensolver (VQE), a VQA that computes
grounds states of a Hamiltonian. Motivated by CAFQA's success, we propose
Excited-CAFQA initialization for Variational Quantum Deflation (VQD), a quantum
algorithm that extends VQE by allowing the computation of excited states. VQD
recursively computes excited states, by constraining the kth state to be
orthogonal to the previous k-1 computed energy states via a penalty term
appended to the standard VQE cost function. Just as with VQE, the VQD cost
function can be efficiently computed classically for the states considered in
the discrete CAFQA search, allowing for the discrete CAFQA optimizer to find
good initial parameters for each energy level computation. Preliminary
evaluation shows that Excited-CAFQA achieves 90 to 99+% accuracy across a
variety of bond lengths and excited states for H2 and HeH+ molecular systems.

</details>


### [290] [Asymptotically optimal unitary estimation in $\mathrm{SU}(3)$ by the analysis of graph Laplacian](https://arxiv.org/abs/2509.20608)
*Satoshi Yoshida,Hironobu Yoshida,Mio Murao*

Main category: quant-ph

TL;DR: 此论文研究了n次查询下d维酉算符U的估计问题，并给出了估计保真度的最优渐近下界。


<details>
  <summary>Details</summary>
Motivation: 研究n次查询下d维酉算符U的估计问题，并给出估计保真度的最优渐近下界。

Method: 通过分析基于有限元方法的图拉普拉斯算子来推导3维酉估计的最优渐近保真度。对于任意d维情况，基于[J. Kahn, Phys. Rev. A 75, 022326, 2007]中的酉估计协议，给出了保真度的下界。

Result: 在d=3时，得到了最优渐近保真度 $F_	extrm{est}(n,d=3) = 1-rac{56	ext{π}^2}{9n^2} + O(n^{-3})$。对于任意d，得到了保真度下界 $F_	extrm{est}(n,d) esizefupright{	ext{right}} 1- rac{(d+1)(d-1)(3d-2)(3d-1)}{6n^2} + O(n^{-3})$。

Conclusion: 该论文在d=3时给出了酉估计的最优渐近保真度，并对任意d维情况给出了最优渐近下界，该下界在n和d的标度上是最优的。

Abstract: Unitary estimation is the task to estimate an unknown unitary operator
$U\in\mathrm{SU}(d)$ with $n$ queries to the corresponding unitary operation,
and its accuracy is evaluated by an estimation fidelity. We show that the
optimal asymptotic fidelity of $3$-dimensional unitary estimation is given by
$F_\mathrm{est}(n,d=3) = 1-\frac{56\pi^2}{9n^2} + O(n^{-3})$ by the analysis of
the graph Laplacian based on the finite element method. We also show the lower
bound on the fidelity of $d$-dimensional unitary estimation for an arbitrary
$d$ given by $F_\mathrm{est}(n,d) \geq 1- \frac{(d+1)(d-1)(3d-2)(3d-1)}{6n^2} +
O(n^{-3})$ achieving the best known lower bound and tight scaling with respect
to $n$ and $d$. This lower bound is derived based on the unitary estimation
protocol shown in [J. Kahn, Phys. Rev. A 75, 022326, 2007].

</details>


### [291] [Optimal phase change for a generalized Grover's algorithm](https://arxiv.org/abs/2509.20610)
*Christopher Cardullo,Min Kang*

Main category: quant-ph

TL;DR: 使用任意幅度向量的广义 Grover 算法用于最大化目标每次迭代的增益。


<details>
  <summary>Details</summary>
Motivation: 研究具有任意幅度向量的广义 Grover 算法，以寻找最大化每次迭代目标概率增益的最佳相位变化。

Method: 在经典 Grover 算法的实数初始幅度向量设置下，我们发现相位变化 $\pi$ 保持最优，直到观测到目标的概率非常接近 1。我们提供了一个基于数据集大小确定此截止点的公式。当幅度真正复杂时，我们发现最佳相位变化非平凡地取决于幅度向量的复杂性。我们提供了一个优化公式来确定所需的最佳相位变化。

Result: 在实数幅度向量的情况下，我们确定了最优相位变化为 $\pi$ 直到特定截止点。在复杂幅度向量的情况下，我们找到了一种依赖于幅度向量复杂性的最优相位变化的优化方法。

Conclusion: 对于广义 Grover 算法，最优相位变化取决于幅度向量是实数还是复数。我们为这两种情况提供了确定最优相位变化的公式。

Abstract: We study the generalized Grover's algorithm with an arbitrary amplitude
vector to find the optimal phase change for maximizing the gain in probability
for the target of each iteration. In the classic setting of Grover's algorithm
with a real initial amplitude vector, we find that a phase change of $\pi$
stays optimal until the probability of observing the target is quite close to
1. We provide a formula for identifying this cut-off point based on the size of
the data set. When the amplitude is truly complex, we find that the optimal
phase change depends non-trivially on the complexity of the amplitude vector.
We provide an optimization formula to identify the required optimal phase
change.

</details>


### [292] [Probing Bandwidth and Sensitivity in Rydberg Atom Sensing via Optical Homodyne and RF Heterodyne Detection](https://arxiv.org/abs/2509.20632)
*Dixith Manchaiah,Stone Oliver,Samuel Berweger,Christopher L. Holloway,Nikunjkumar Prajapati*

Main category: quant-ph

TL;DR: 基于里德堡原子的传感器在铷蒸气池中，通过结合射频外差测量和光学同源检测技术，实现了8兆赫兹的响应带宽，同时保持了灵敏度。该传感器成功接收了数字通信信号，并展示了其在不同符号速率和带宽下的误差向量幅度（EVM）表现，与传统射频混频器进行了比较。研究还指出，传感器接收纯音信号的带宽与其接收调制信号的带宽不同，这归因于符号在频域的扩展导致了信噪比的降低和噪声的累积。


<details>
  <summary>Details</summary>
Motivation: 为了在通信和雷达技术领域拓展基于里德堡原子的传感器的应用，需要研究并优化其带宽和灵敏度。

Method: 利用铷蒸气池中的里德堡电磁感应透明（EIT）光谱技术，结合射频外差测量和光学同源检测设置，来研究传感器的带宽和灵敏度。通过测量不同符号速率和带宽下的误差向量幅度（EVM）来评估其通信能力，并与传统射频混频器进行性能比较。

Result: 在保持灵敏度的同时，实现了8兆赫兹的响应带宽。成功接收了数字通信信号，并测量了EVM。研究发现，传感器接收纯音信号的带宽与接收调制信号的带宽存在差异，调制信号的带宽限制了传感器的性能。

Conclusion: 结合射频外差测量和光学同源检测技术，可以在保持灵敏度的前提下，显著提高基于里德堡原子的传感器的响应带宽。该传感器在接收数字通信信号方面表现出潜力，但其性能会受到调制信号特性（如符号扩展和噪声累积）的影响。

Abstract: Rydberg atom based sensors allow for SI traceable measurements and show
promise for applications in the field of communication and radar technologies.
In this article, we investigate the bandwidth and sensitivity of a Rydberg
atom-based sensor in a rubidium vapor cell using Rydberg electromagnetically
induced transparency (EIT) spectroscopy. We employ a radio-frequency (RF)
heterodyne measurement technique in combination with an optical homodyne setup
to extend the achievable range between sensitivity and bandwidth in a Rydberg
sensor. While the bandwidth of Rydberg sensors are limited by the transit time
of atoms and the Rabi frequency of the coupling field, achieving higher
bandwidth through smaller beam sizes is thought to compromise sensitivity due
to reduced EIT signal strength. Using optical homodyne detection, we
demonstrate that sensitivity is preserved while achieving a response bandwidth
of 8 MHz. In addition, using the Rydberg sensor, we receive digital
communication signals and present error vector magnitude (EVM) measurements as
a function of varying symbol rates and bandwidth of the Rydberg sensor.
Furthermore, the sensor's performance is compared with a conventional RF mixer.
We establish that the bandwidth of a Rydberg sensor when receiving a pure tone
is not the same as the bandwidth of the sensor when receiving a modulated
signal. This difference results from the spreading of symbols in the frequency
domain, leading to a reduction of the signal to noise ratio (SNR) and an
accumulation of noise over the total span of the modulated signal.

</details>


### [293] [Lower Bounds for Learning Hamiltonians from Time Evolution](https://arxiv.org/abs/2509.20665)
*Ziyun Chen,Jerry Li*

Main category: quant-ph

TL;DR: 学习汉密尔顿量的参数，并首次提出了下界，该下界随未知汉密尔顿量的参数数量扩展。


<details>
  <summary>Details</summary>
Motivation: 从时间演化中学习汉密尔顿量，即给定作用未知汉密尔顿量的 $n$ 个量子比特的 $e^{-iHt}$ 的能力，目标是恢复 $H$ 的参数。在量子学习理论中，这是一个被充分研究的问题，应用于量子计量学、传感、器件基准测试和多体物理学。

Method: 在任意汉密尔顿量的情况下，我们证明了学习到误差 $\epsilon$ 需要 $2^{(1/2 - o(1))n} / \epsilon$ 轮与汉密尔顿量的相互作用。如果汉密尔顿量还被假定为 $k$-局部的，我们证明了学习到恒定误差需要 $n^{\Omega (k)}$ 轮与汉密尔顿量的相互作用，解决了 Tang 的一个悬而未决的问题。

Result: 首次提出了与未知汉密尔顿量参数数量成比例的下界。当汉密尔顿量是任意的时，学习误差为 $\epsilon$ 需要 $2^{(1/2 - o(1))n} / \epsilon$ 轮交互。当汉密尔顿量是 $k$-局部的时，学习到恒定误差需要 $n^{\Omega (k)}$ 轮交互。

Conclusion: 学习算法需要超多项式总演化时间才能实现多项式反时间分辨率。这些下界即使对于非常简单的植入尖峰检测问题（目标是检测一个比其他汉密尔顿量系数大超多项式倍的系数）以及平均情况实例也成立。

Abstract: We consider the problem of learning Hamiltonians from time evolution: given
the ability to apply $e^{-iHt}$ for an unknown Hamiltonian on $n$ qubits, the
goal is to recover the parameters of $H$. This is a well-studied problem in
quantum learning theory, with applications to quantum metrology, sensing,
device benchmarking, and many-body physics. For this problem, we demonstrate
the first lower bounds which scale with the number of parameters of the unknown
Hamiltonian. When the unknown Hamiltonian is arbitrary, we show that learning
to error $\epsilon$ requires $2^{(1/2 - o(1))n} / \epsilon$ rounds of
interaction with the Hamiltonian. If the Hamiltonian is additionally assumed to
be $k$-local, we show that learning to constant error requires $n^{\Omega (k)}$
rounds of interaction with the Hamiltonian, resolving an open question of Tang.
These bounds immediately imply that any learning algorithm with inverse
polynomial time resolution requires super-polynomial total evolution time. Our
lower bounds hold even for very simple planted spike detection problems, where
the goal is to detect the presence of a single coefficient which is
super-polynomially larger than the other coefficients of the Hamiltonian, as
well as for average case instances.

</details>


### [294] [Quantum Algorithm for Subcellular Multiscale Reaction-Diffusion Systems](https://arxiv.org/abs/2509.20668)
*Margot Lockwood,Nathan Wiebe,Connah Johnson,Johannes Mülmenstädt,Jaehun Chun,Gregory Schenter,Margaret S. Cheung,Xiangyu Li*

Main category: quant-ph

TL;DR: 该研究提出了一种利用量子计算模拟细胞系统动力学的方法，解决了传统计算方法在处理大规模、高维度系统时的局限性，实现了指数级加速。


<details>
  <summary>Details</summary>
Motivation: 传统计算方法在模拟细胞系统时面临计算资源需求巨大、系统规模和时空尺度受限、“维度灾难”等挑战，导致复杂反应和多体相互作用的计算难以在多项式时间内完成。

Method: 提出了一种量子算法框架，利用量子计算的架构同时计算反应速率并追踪亚细胞系统的时空动力学演化。该方法推广了反应扩散方程（RDE）以处理包含任意物种数量和高阶相互作用的多尺度系统。

Result: (i) 实现了反应速率计算的指数级量子加速，前提是能够在量子计算机上高效制备多项式精度的基态。(ii) 解决了非线性RDE的二次空间网格点和多项式物种数量的缩放问题，与经典的指数级缩放形成鲜明对比。

Conclusion: 该研究首次提出了求解多尺度反应扩散系统的有效量子算法，使得在以前无法企及的时空尺度上模拟生物相关的亚细胞过程成为可能，对计算生物学、软物质物理和生物物理建模具有深远影响。

Abstract: Computational modeling of cellular systems, where reactants are governed by
biochemical equations and physical representations, requires extensive
classical computing resources. These limitations significantly constrain the
system size and spatiotemporal scales of simulations. A key challenge lies in
the "curse of dimensionality", where the number of possible reaction terms
grows exponentially with the number of species, and the computation of reaction
rates involving many-body interactions becomes intractable in polynomial time
on classical computers. In this work, we introduce a quantum algorithmic
framework designed to overcome these challenges, leveraging the architecture of
quantum computing to simultaneously compute reaction rates and track the
spatiotemporal dynamical evolutions of subcellular systems. We generalize the
reaction-diffusion equation (RDE) for multiscale systems with arbitrary species
count, encompassing higher-order interactions. Our approach achieves two
principal quantum advantages: (i) an exponential quantum speedup in
reaction-rate computation, contingent on the efficient preparation of
polynomially accurate ground states on a quantum computer, and (ii)) a
quadratic scaling in spatial grid points and polynomial scaling in the number
of species for solving nonlinear RDEs, contrasting sharply with classical
methods that scale exponentially with the system's degrees of freedom. To our
knowledge, this represents the first efficient quantum algorithm for solving
multiscale reaction-diffusion systems. This framework opens the door to
simulations of biologically relevant subcellular processes across previously
inaccessible spatial and temporal scales, with profound implications for
computational biology, soft matter physics, and biophysical modeling.

</details>


### [295] [PALQO: Physics-informed Model for Accelerating Large-scale Quantum Optimization](https://arxiv.org/abs/2509.20733)
*Yiming Huang,Yajie Hao,Jing Zhou,Xiao Yuan,Xiaoting Wang,Yuxuan Du*

Main category: quant-ph

TL;DR: 通过使用物理信息神经网络（PINNs）来模拟VQA的训练动力学，可以显著降低量子资源成本并提高训练速度。


<details>
  <summary>Details</summary>
Motivation: 量子不可克隆定理限制了VQA的应用，导致大规模任务的量子资源成本过高。本研究旨在解决这一挑战。

Method: 将VQA的训练动力学重新表述为非线性偏微分方程，并提出利用PINNs来高效建模该动力学系统，通过少量量子设备训练数据预测参数更新。

Result: 该方法在包含40个量子比特的任务中，实现了高达30倍的加速和90%的量子资源成本降低，同时保持了具有竞争力的准确性，包括不同量子系统的基态制备。

Conclusion: 本研究提出的PINNs方法能够有效降低VQA的量子资源成本，提高训练效率，增强了VQA在实际应用中的潜力。

Abstract: Variational quantum algorithms (VQAs) are leading strategies to reach
practical utilities of near-term quantum devices. However, the no-cloning
theorem in quantum mechanics precludes standard backpropagation, leading to
prohibitive quantum resource costs when applying VQAs to large-scale tasks. To
address this challenge, we reformulate the training dynamics of VQAs as a
nonlinear partial differential equation and propose a novel protocol that
leverages physics-informed neural networks (PINNs) to model this dynamical
system efficiently. Given a small amount of training trajectory data collected
from quantum devices, our protocol predicts the parameter updates of VQAs over
multiple iterations on the classical side, dramatically reducing quantum
resource costs. Through systematic numerical experiments, we demonstrate that
our method achieves up to a 30x speedup compared to conventional methods and
reduces quantum resource costs by as much as 90\% for tasks involving up to 40
qubits, including ground state preparation of different quantum systems, while
maintaining competitive accuracy. Our approach complements existing techniques
aimed at improving the efficiency of VQAs and further strengthens their
potential for practical applications.

</details>


### [296] [Quantum Simulation and Energy Estimation for Discretized Anharmonic oscillator](https://arxiv.org/abs/2509.20907)
*Saurav Suman,Bikash K. Behera,Vivek Vyas,Prasanta k. Panigrahi*

Main category: quant-ph

TL;DR: 量子模拟被用于研究量子非谐振子，使用3量子比特系统和IBM量子体验平台。通过量子电路和VQE/VQD算法计算能量，精度高，优于经典方法。


<details>
  <summary>Details</summary>
Motivation: 经典计算机难以模拟量子非谐振子系统，因为存在非线性相互作用、巨大的状态空间以及对内存和计算资源的指数级增长需求。

Method: 使用3量子比特系统在IBM量子体验平台上实现了量子非谐振子（QAHO）的量子模拟。构建了基于滤波器设计和Toffoli门的量子电路来跟踪量子态演化，并捕获量子态的量子عود现等关键现象。采用变分量子本征求解器（VQE）和变分量子 the (VQD) 来计算基态和激发态能量。

Result: 该方法与精确方法相比，误差仅为1.11%，具有很高的准确性。与经典近似方法（如微扰理论，误差6.71%；以及WKB近似，误差5.36%）相比，VQE提供了更精确的能量值。

Conclusion: 量子模拟和VQD是研究复杂量子系统的有效工具，有望在量子化学和材料科学领域得到应用，尤其随着量子硬件的不断发展。

Abstract: Anharmonic potential quantum system play crucial role in physics as they
provide a more realistic description of oscillatory phenomena, which often
deviate from the idealized harmonic model. However, simulating such system on
classical computers is highly challenging due to nonlinear interactions, large
state spaces, and the exponential scaling of memory and computational
resources. In this work, quantum simulation is employed to model a quantum
anharmonic oscillator (QAHO) using a 3-qubit system implemented on IBM's
Quantum Experiences platform. A quantum circuit with a filter-based design and
Toffoli gates is constructed to track quantum state evolution, capturing key
phenomena like quantum revival. The framework is further extended to n-qubit
system to enhance resolution and scalability. For energy estimation, the
Variational Quantum Eigensolver (VQE) with a TwoLocal ansatz and variational
Quantum Deflation (VQD), are used to compute ground and excited state energies.
The proposed approach achieves high accuracy with an error of only 1.11%
compared to exact methods. Notably, VQE outperforms classical approximations
such as perturbation theory (error 6.71%) and the Wentzel-Kramers-Brillouin
(WKB) approximation(error 5.36%), yielding more precise energy values. These
results highlight the potential of quantum simulation and VQD as effective
tools for investigating complex quantum system, paving the way for future
application in quantum chemistry and materials science as quantum hardware
continues to advance.

</details>


### [297] [Classical and quantum chaotic synchronization in coupled dissipative time crystals](https://arxiv.org/abs/2509.20922)
*Eliška Postavová,Gianluca Passarelli,Procolo Lucignano,Angelo Russomanno*

Main category: quant-ph

TL;DR: 研究了两个相干耦合的耗散时间晶体的动力学，发现了混沌同步机制，并通过量子轨迹方法研究了有限尺寸量子动力学，揭示了量子混沌同步现象，并讨论了经典和量子交叉点的差异。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索两个相干耦合的耗散时间晶体的动力学行为，并识别其同步机制。

Method: 在经典平均场极限下，利用李雅普诺夫指数和皮尔逊相关系数识别混沌同步；在有限尺寸量子动力学方面，采用量子轨迹方法研究子系统z磁化的直方图，并分析了高斯酉系数量子混沌的稳态密度矩阵。

Result: 在经典平均场极限下，发现了混沌同步机制（正李雅普诺夫指数，接近1的皮尔逊相关系数），并在其边界发现了交错和均匀z磁化之间的交叉。在量子轨迹方法下，子系统z磁化的直方图显示了与经典情况类似的交叉现象，并观察到耗散量子混沌（高斯酉系数量子混沌）。

Conclusion: 研究发现了耗散时间晶体中的混沌同步现象，并通过经典和量子的分析进行了对比。经典和量子交叉点的差异归因于无限自旋和无限时间极限的不可交换性以及纠缠的影响。

Abstract: We investigate the dynamics of two coherently coupled dissipative time
crystals. In the classical mean-field limit of infinite spin length, we
identify a regime of chaotic synchronization, marked by a positive largest
Lyapunov exponent and a Pearson correlation coefficient close to one. At the
boundary of this regime, the Pearson coefficient varies abruptly, marking a
crossover between staggered and uniform $z$-magnetization. To address
finite-size quantum dynamics, we employ a quantum-trajectory approach and study
the trajectory-resolved expectations of subsystem $z$-magnetizations. Their
histograms over time and trajectory realizations exhibit maxima that undergo a
staggered-to-uniform crossover analogous to the classical one. In analogy with
the classical case, we interpret this behavior as quantum chaotic
synchronization, with dissipative quantum chaos evidenced by the steady-state
density matrix exhibiting Gaussian Unitary Ensemble statistics. The locations
of the classical and quantum crossover differ, reflecting the noncommutativity
of the infinite-spin and infinite-time limits and the impact of entanglement,
quantified via the entanglement entropy between subsystems.

</details>


### [298] [Harnessing optical disorder for Bell inequalities violation](https://arxiv.org/abs/2509.21052)
*Baptiste Courme,Malo Joly,Adrian Makowski,Sylvain Gigan,Hugo Defienne*

Main category: quant-ph

TL;DR: 实验利用光学无序性作为资源，通过贝尔不等式检验认证纠缠，无需主动校正，解决了真实量子通信中的纠缠认证问题。


<details>
  <summary>Details</summary>
Motivation: 光学无序性（如光纤中的模式混合和自由空间湍流）会干扰传统的贝尔不等式检验，该研究旨在克服这一障碍。

Method: 利用一个光子的空间分辨散斑强度模式，为另一个光子提供大量随机且未知的偏振投影，从而满足贝尔不等式检验的要求。

Result: 实验证明，通过空间分辨散斑强度模式，可以满足贝尔不等式检验的统计要求，从而认证纠缠，而无需主动校正。

Conclusion: 该方法提供了一种利用光学无序性进行贝尔不等式检验和认证纠缠的新途径，无需选择测量基，并为现实世界中不可避免无序的量子通信渠道提供了实用的纠缠认证解决方案。

Abstract: Bell inequalities are a cornerstone of quantum physics. By carefully
selecting measurement bases (typically polarization), their violation certifies
quantum entanglement. Such measurements are disrupted by the presence of
optical disorder in propagation paths, including polarization or spatial mode
mixing in fibers and through free-space turbulence. Here, we demonstrate that
disorder can instead be exploited as a resource to certify entanglement via a
Bell inequality test. In our experiment, one photon of a polarization-entangled
pair propagates through a commercial multimode fiber that scrambles spatial and
polarization modes, producing a speckle pattern, while the other photon remains
with the sender. By spatially resolving the speckle intensity pattern, we
naturally access a large set of random and unknown polarization projections. We
show that this set is statistically sufficient to violate a Bell inequality,
thereby certifying entanglement without requiring active correction techniques.
Our approach provides a fundamentally new way to test Bell inequalities,
eliminating the need for an explicit choice of measurement basis, and offering
a practical solution for entanglement certification in real-world quantum
communication channels where disorder is unavoidable.

</details>


### [299] [No Universal Purification in Quantum Mechanics](https://arxiv.org/abs/2509.21111)
*Zhenhuan Liu,Zhenyu Du,Zhenyu Cai,Zi-Wen Liu*

Main category: quant-ph

TL;DR: 量子力学中的线性与正性限制了量子纯化，排除了通用纯化，并为近似纯化提供了样本复杂度界限，对量子信息处理有重要影响。


<details>
  <summary>Details</summary>
Motivation: 量子力学的线性与正性对量子纯化提出了普遍限制，揭示了量子信息处理的新根本性局限。

Method: 证明了量子力学的线性与正性对量子纯化的一般限制，并在此基础上推导了近似纯化的样本复杂度界限。

Result: 没有量子操作可以将有限数量的未知量子态或信道的副本转换为依赖于输入的纯态或纯信道；对近似纯化给出了样本复杂度界限，并证明了近似制备纯膨胀的样本复杂度存在指数级下界。

Conclusion: 量子力学的基本原理对量子纯化施加了限制，这对理解和设计量子信息处理任务具有深远影响。

Abstract: We prove that the linearity and positivity of quantum mechanics impose
general restrictions on quantum purification, unveiling a new fundamental
limitation of quantum information processing. In particular, no quantum
operation can transform a finite number of copies of an unknown quantum state
or channel into a pure state or channel that depends on the input, thereby
ruling out an important form of universal purification in both static and
dynamical settings. Relaxing the requirement of exact pure output, we further
extend our result to establish quantitative sample complexity bounds for
approximate purification, independent of any task details or operational
constraints. To illustrate the practical consequences of this principle, we
examine the task of approximately preparing pure dilation and, for the first
time, prove an exponential lower bound on the required sample complexity.

</details>


### [300] [Limits to black-box amplification in QMA](https://arxiv.org/abs/2509.21131)
*Scott Aaronson,Freek Witteveen*

Main category: quant-ph

TL;DR: 黑盒放大技术在量子计算复杂性类QMA中存在理论极限，无法实现指数级接近1的精确度。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算复杂性类QMA中黑盒放大的局限性。

Method: 利用复杂逼近理论的技术，使QMA与具有完美完备性的QMA之间的分离量化，以证明黑盒程序的局限性。

Result: 证明了在黑盒程序下，QMA的验证过程无法实现指数级接近1的完备度，或指数级小的可靠度。

Conclusion: 黑盒放大技术在QMA中存在最优极限，无法实现超指数级的精确度提升。

Abstract: We study the limitations of black-box amplification in the quantum complexity
class QMA. Amplification is known to boost any inverse-polynomial gap between
completeness and soundness to exponentially small error, and a recent result
(Jeffery and Witteveen, 2025) shows that completeness can in fact be amplified
to be doubly exponentially close to 1. We prove that this is optimal for
black-box procedures: we provide a quantum oracle relative to which no QMA
verification procedure using polynomial resources can achieve completeness
closer to 1 than doubly exponential, or a soundness which is
super-exponentially small. This is proven by using techniques from complex
approximation theory, to make the oracle separation from (Aaronson, 2008),
between QMA and QMA with perfect completeness, quantitative.

</details>


### [301] [Optimal squeezing to minimize vulnerability to losses](https://arxiv.org/abs/2509.21180)
*Boulat Nougmanov*

Main category: quant-ph

TL;DR: 通过预压缩技术提高非高斯量子态的抗耗散能力。


<details>
  <summary>Details</summary>
Motivation: 非高斯态（其维格纳拟概率分布取负值）在量子物理学中具有重要应用，但它们对耗散非常敏感。

Method: 研究如何通过预压缩量子态来提高非高斯态对损耗的鲁棒性，并确定最优的压缩参数。

Result: 发现预压缩可以显著提高非高斯态的抗损耗能力，并对薛定谔猫态、福克态和“香蕉”态等具体案例进行了分析。

Conclusion: 预压缩是提高非高斯量子态鲁棒性的有效方法。

Abstract: Non-Gaussian states, described by Wigner quasi-probability distribution
taking negative values, are of great interest for various applications of
quantum physics. It is known however that they are highly vulnerable to
dissipation. In this paper, we show that the robustness of the non-Gaussian
states to losses can be significantly improved by pre-squeezing of the quantum
state, and find the optimal parameters of the squeezing. As specific examples,
we consider such well-known quantum states as Schrodinger cat, Fock , and
``banana'' ones.

</details>


### [302] [Radiation of "breathing" vortex electron packets in magnetic field](https://arxiv.org/abs/2509.21195)
*G. V. Zmaga,G. K. Sizykh,D. V. Grosman,Qi Meng,Liping Zou,Pengming Zhang,D. V. Karlovets*

Main category: quant-ph

TL;DR: 涡旋电子在磁场中会形成非定态拉盖-高斯态，其波包半径会像 betatron 振荡一样振荡，但辐射的光子携带的角动量可以忽略，因此涡旋电子的涡量在直线加速器中可以保持。


<details>
  <summary>Details</summary>
Motivation: 研究涡旋电子在磁场中传播时，其量子态（非定态拉盖-高斯态）的振荡行为是否会导致辐射，以及辐射的光子是否携带轨道角动量（OAM），从而引起涡旋电子涡量的损失。

Method: 使用非定态拉盖-高斯态的电子的电荷和电流密度，求解麦克斯韦方程组，计算辐射功率和发射场的角动量，并评估涡旋电子在纵向磁场中能量和角动量损失的速率。

Result: 计算结果表明，辐射功率和角动量损失都可以忽略不计。

Conclusion: 线性加速器（linacs）是保持相对论涡旋电子和其他带电粒子涡量的重要工具，至少在准经典近似下是如此。

Abstract: When a vortex electron with an orbital angular momentum (OAM) enters a
magnetic field, its quantum state is described with a nonstationary
Laguerre-Gaussian (NSLG) state rather than with a stationary Landau state. A
key feature of these NSLG states is oscillations of the electron wave packet's
root-mean-square (r.m.s.) radius, similar to betatron oscillations.
Classically, such an oscillating charge distribution is expected to emit
photons. This raises a critical question: does this radiation carry away OAM,
leading to a loss of the electron's vorticity? To investigate this, we solve
Maxwell's equations using the charge and current densities derived from an
electron in the NSLG state. We calculate the total radiated power and the
angular momentum of the emitted field, quantifying the rate at which a vortex
electron loses its energy and OAM while propagating in a longitudinal magnetic
field. We find both the radiated power and the angular momentum losses to be
negligible indicating that linear accelerators (linacs) appear to be a
prominent tool for maintaining vorticity of relativistic vortex electrons and
other charged particles, at least in the quasi-classical approximation.

</details>


### [303] [Entanglement distillation on symmetric two-qutrit entangled states of rank five](https://arxiv.org/abs/2509.21258)
*Zihua Song,Lin Chen,Yongge Wang*

Main category: quant-ph

TL;DR: 研究了对称两量子比特NPT纠缠态的蒸馏问题，提出了五种新的状态族，并分析了它们的可蒸馏性。


<details>
  <summary>Details</summary>
Motivation: 纠缠蒸馏是量子信息中的关键技术，需要研究更复杂的NPT纠缠态的可蒸馏性。

Method: 构造了五种对称两量子比特NPT纠缠态（秩为5），并分析了它们的可蒸馏性，给出了可蒸馏和不可蒸馏的条件。

Result: 发现其中一些状态是1-可蒸馏的，但并非所有状态都是，并给出了与特征值相关的可蒸馏性条件。

Conclusion: 对称两量子比特NPT纠缠态的可蒸馏性取决于其特征值，并非所有秩为5的NPT纠缠态都是1-可蒸馏的。

Abstract: Entanglement distillation is a key step in quantum information, both
theoretically and practically. It has been proven that non-positive-partial
transpose (NPT) entangled states of rank at most four is 1-distillable under
local operation and classical communications. In this paper we investigate the
distillation of a more complex family of NPT entangled states, namely a family
of symmetric two-qutrit states $\r$ of rank five with given eigenvectors. We
explicitly construct five families of such states by requiring four of the five
eigenvalues to be the same. We respectively show that some of them are
1-distillable. It turns out that such states may be not 1-distillable for some
interval of eigenvalues. We provide some conditions for eigenvalues that allow
$\r$ to be 1-distillable or to be 1-undistillable.

</details>


### [304] [Efficient Quantum Measurements: Computational Max- and Measured Rényi Divergences and Applications](https://arxiv.org/abs/2509.21308)
*Álvaro Yángüez,Thomas A. Hahn,Jan Kochanowski*

Main category: quant-ph

TL;DR: 研究了在计算限制下，能够保留操作意义并忠实捕捉计算约束的量子散度。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理在实践中受到可有效执行操作的限制，这促使我们研究能够保留其操作意义并忠实捕捉这些计算约束的量子散度。

Method: 使用几何、计算和信息论工具，定义了计算最大散度和计算测量 Rényi 散度。

Result: 证明了在无限阶极限下，计算测量 Rényi 散度与计算最大散度一致。在多副本情况下，引入了正则化版本，并建立了一个单边计算 Stein 界限。还定义了由计算散度诱导的资源度量，并证明了计算测量相对熵的渐进连续性界限。将结果与先前的计算纠缠度量联系起来，并与信息论设置进行了明确区分。

Conclusion: 这些结果为计算约束下的状态判别任务和资源量化提供了一个有原则的、连贯的方法。

Abstract: Quantum information processing is limited, in practice, to efficiently
implementable operations. This motivates the study of quantum divergences that
preserve their operational meaning while faithfully capturing these
computational constraints. Using geometric, computational, and information
theoretic tools, we define two new types of computational divergences, which we
term computational max-divergence and computational measured R\'enyi
divergences. Both are constrained by a family of efficient binary measurements,
and thus useful for state discrimination tasks in the computational setting. We
prove that, in the infinite-order limit, the computational measured R\'enyi
divergence coincides with the computational max-divergence, mirroring the
corresponding relation in the unconstrained information-theoretic setting. For
the many-copy regime, we introduce regularized versions and establish a
one-sided computational Stein bound on achievable hypothesis-testing exponents
under efficient measurements, giving the regularized computational measured
relative entropy an operational meaning. We further define resource measures
induced by our computational divergences and prove an asymptotic continuity
bound for the computational measured relative entropy of resource. Focusing on
entanglement, we relate our results to previously proposed computational
entanglement measures and provide explicit separations from the
information-theoretic setting. Together, these results provide a principled,
cohesive approach towards state discrimination tasks and resource
quantification under computational constraints.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [305] [An Approach to Checking Correctness for Agentic Systems](https://arxiv.org/abs/2509.20364)
*Thomas J Sheffler*

Main category: cs.AI

TL;DR: 提出了一种用于监控AI智能体行为的时间表达式语言，以系统性地检测LLM（大语言模型）为基础的智能体系统的错误。


<details>
  <summary>Details</summary>
Motivation: 当前错误检测方法依赖于文本匹配，但由于LLM输出的自然语言可变性而不够鲁棒。本研究旨在提出一种独立于具体文本输出的方法，专注于智能体动作的序列，以实现更可靠的错误检测。

Method: 利用硬件验证中的时序逻辑技术，监控智能体工具调用和状态转换的执行轨迹，以检测与预期行为模式的偏差。

Result: 在包含三个智能体的系统中进行演示。当使用大型模型时，所有时间断言均满足。当使用较小模型时，部分断言被违反，主要由于工具排序不当和协调切换失败。该方法成功标记了这些异常。

Conclusion: 所提出的时间表达式语言能有效检测AI智能体系统中的行为回归，为在关键应用中部署的AI智能体提供系统性监控基础，以确保持续的可靠性。

Abstract: This paper presents a temporal expression language for monitoring AI agent
behavior, enabling systematic error-detection of LLM-based agentic systems that
exhibit variable outputs due to stochastic generation processes. Drawing from
temporal logic techniques used in hardware verification, this approach monitors
execution traces of agent tool calls and state transitions to detect deviations
from expected behavioral patterns. Current error-detection approaches rely
primarily on text matching of inputs and outputs, which proves fragile due to
the natural language variability inherent in LLM responses. The proposed method
instead focuses on the sequence of agent actions -- such as tool invocations
and inter-agent communications -- allowing verification of system behavior
independent of specific textual outputs. The temporal expression language
provides assertions that capture correct behavioral patterns across multiple
execution scenarios. These assertions serve dual purposes: validating prompt
engineering and guardrail effectiveness during development, and providing
regression testing when agents are updated with new LLMs or modified logic. The
approach is demonstrated using a three-agent system, where agents coordinate to
solve multi-step reasoning tasks. When powered by large, capable models, all
temporal assertions were satisfied across many test runs. However, when smaller
models were substituted in two of the three agents, executions violated
behavioral assertions, primarily due to improper tool sequencing and failed
coordination handoffs. The temporal expressions successfully flagged these
anomalies, demonstrating the method's effectiveness for detecting behavioral
regressions in production agentic systems. This approach provides a foundation
for systematic monitoring of AI agent reliability as these systems become
increasingly deployed in critical applications.

</details>


### [306] [LATTS: Locally Adaptive Test-Time Scaling](https://arxiv.org/abs/2509.20368)
*Theo Uscidda,Matthew Trager,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: LATTS通过自适应调整计算量来提高LLM在下游任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于验证器的方法在测试时会均匀增加计算量，未考虑样本的复杂性，导致资源利用效率低下。

Method: LATTS在每个生成步骤中采用基于验证器的接受标准来决定是重新采样、回溯、重启还是停止生成过程，根据局部难度自适应地调整每一步的计算量。

Result: 与标准的基于验证器的方法相比，LATTS在准确率-计算量权衡方面表现出显著的优越性。

Conclusion: LATTS能够更有效地利用资源，提高LLM在下游任务上的性能。

Abstract: One common strategy for improving the performance of Large Language Models
(LLMs) on downstream tasks involves using a \emph{verifier model} to either
select the best answer from a pool of candidates or to steer the
auto-regressive generation process towards better outputs. This class of
methods typically results in improved accuracy at the cost of increased
computation at test-time, a paradigm known as \emph{test-time scaling}.
However, most existing approaches increase computation uniformly across all
samples and generation steps, without considering the complexity of individual
instances, leading to inefficient resource use. We address this limitation by
proposing an approach, called \emph{Locally Adaptive Test-Time Scaling
(LATTS)}, that allocates variable compute across generation steps.
Specifically, at each generation step, LATTS employs a verifier-based
acceptance criterion to decide whether to resample, backtrack, restart, or stop
the generation process. This criterion effectively adjusts the per-step
computational effort based on a precise notion of \emph{local difficulty}
derived from the verifier model. Empirical results show that LATTS achieves
significantly superior accuracy--compute tradeoffs compared to standard
verifier-based methods.

</details>


### [307] [Fairy: Interactive Mobile Assistant to Real-world Tasks via LMM-based Multi-agent](https://arxiv.org/abs/2509.20729)
*Jiazheng Sun,Te Yang,Jiayang Niu,Mingxuan Li,Yongyong Lu,Ruimeng Yang,Xin Peng*

Main category: cs.AI

TL;DR: Fairy是一个交互式多智能体移动助手，通过持续积累应用知识和自我进化来解决现有LMM在处理多样化应用界面和不断变化的用户需求方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMM）在处理多样化的应用界面和不断变化的用户需求方面存在挑战，特别是在长尾应用场景下，缺乏用户交互的方法会损害用户体验。

Method: Fairy包含三个核心模块：全局任务规划器（用于跨应用分解任务）、应用级执行器（通过四个核心智能体在双循环中实现精确执行和用户交互）和自学习器（将执行经验整合到应用地图和技巧中）。

Result: Fairy在RealMobile-Eval基准测试中，使用GPT-4o骨干，用户需求完成率提高了33.7%，冗余步骤减少了58.5%。

Conclusion: Fairy通过交互和自我学习的有效性，显著优于现有技术水平（SoTA），提高了移动GUI代理的性能。

Abstract: Large multi-modal models (LMMs) have advanced mobile GUI agents. However,
existing methods struggle with real-world scenarios involving diverse app
interfaces and evolving user needs. End-to-end methods relying on model's
commonsense often fail on long-tail apps, and agents without user interaction
act unilaterally, harming user experience. To address these limitations, we
propose Fairy, an interactive multi-agent mobile assistant capable of
continuously accumulating app knowledge and self-evolving during usage. Fairy
enables cross-app collaboration, interactive execution, and continual learning
through three core modules:(i) a Global Task Planner that decomposes user tasks
into sub-tasks from a cross-app view; (ii) an App-Level Executor that refines
sub-tasks into steps and actions based on long- and short-term memory,
achieving precise execution and user interaction via four core agents operating
in dual loops; and (iii) a Self-Learner that consolidates execution experience
into App Map and Tricks. To evaluate Fairy, we introduce RealMobile-Eval, a
real-world benchmark with a comprehensive metric suite, and LMM-based agents
for automated scoring. Experiments show that Fairy with GPT-4o backbone
outperforms the previous SoTA by improving user requirement completion by 33.7%
and reducing redundant steps by 58.5%, showing the effectiveness of its
interaction and self-learning.

</details>


### [308] [Philosophy-informed Machine Learning](https://arxiv.org/abs/2509.20370)
*MZ Naser*

Main category: cs.AI

TL;DR: PhIML将分析哲学融入机器学习，旨在通过尊重哲学概念和价值观的模型来提供新能力。本文探讨了其概念基础、应用案例以及面临的挑战，并提出了一个研究路线图。


<details>
  <summary>Details</summary>
Motivation: PhIML旨在通过在模型架构、目标和评估协议中融入分析哲学的核心思想，来创造新的机器学习能力，使其模型在设计上就能尊重哲学概念和价值观。

Method: 本文回顾了PhIML的概念基础，展示了其哲学优势和一致性。此外，本文还提供了案例研究，说明机器学习用户/设计者如何采用PhIML作为一种通用的事后工具，或将其内在整合到ML模型架构中。

Result: 文章展示了PhIML的哲学收益和一致性，并通过案例研究说明了其应用方式。

Conclusion: 本文指出了PhIML面临的技术、哲学、实践和治理方面的挑战，并提出了一个旨在实现安全、符合哲学、负责任的PhIML的研究路线图。

Abstract: Philosophy-informed machine learning (PhIML) directly infuses core ideas from
analytic philosophy into ML model architectures, objectives, and evaluation
protocols. Therefore, PhIML promises new capabilities through models that
respect philosophical concepts and values by design. From this lens, this paper
reviews conceptual foundations to demonstrate philosophical gains and
alignment. In addition, we present case studies on how ML users/designers can
adopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML
model architectures. Finally, this paper sheds light on open technical barriers
alongside philosophical, practical, and governance challenges and outlines a
research roadmap toward safe, philosophy-aware, and ethically responsible
PhIML.

</details>


### [309] [InsightGUIDE: An Opinionated AI Assistant for Guided Critical Reading of Scientific Literature](https://arxiv.org/abs/2509.20493)
*Paris Koloveas,Serafeim Chatzopoulos,Thanasis Vergoulis,Christos Tryfonopoulos*

Main category: cs.AI

TL;DR: LLM工具InsightGUIDE通过嵌入专家阅读方法来提供结构化、简洁的论文见解，作为阅读助手而非替代品。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长给研究人员带来了挑战，现有的LLM工具往往提供过于冗长的摘要。

Method: 提出了一种名为InsightGUIDE的新型AI工具，该工具将专家的阅读方法嵌入其AI逻辑中，通过提示驱动的方法生成结构化见解。

Result: 与通用LLM相比，InsightGUIDE生成的指导更加结构化和可操作。

Conclusion: InsightGUIDE能更有效地帮助研究人员应对海量文献的挑战，充当有效的阅读助手。

Abstract: The proliferation of scientific literature presents an increasingly
significant challenge for researchers. While Large Language Models (LLMs) offer
promise, existing tools often provide verbose summaries that risk replacing,
rather than assisting, the reading of the source material. This paper
introduces InsightGUIDE, a novel AI-powered tool designed to function as a
reading assistant, not a replacement. Our system provides concise, structured
insights that act as a "map" to a paper's key elements by embedding an expert's
reading methodology directly into its core AI logic. We present the system's
architecture, its prompt-driven methodology, and a qualitative case study
comparing its output to a general-purpose LLM. The results demonstrate that
InsightGUIDE produces more structured and actionable guidance, serving as a
more effective tool for the modern researcher.

</details>


### [310] [ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective](https://arxiv.org/abs/2509.21134)
*Yiwen Zhang,Ziang Chen,Fanqi Kong,Yizhe Huang,Xue Feng*

Main category: cs.AI

TL;DR: ToMPO是一种用于LLM的策略优化算法，通过考虑对手策略和全局/局部奖励来提升决策能力，在模型输出合规性和合作成果方面优于GRPO。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分考虑决策的多样性、相互依赖性以及对手策略在强化学习中的作用，限制了LLM在复杂场景下的决策能力。

Method: 提出了一种名为ToMPO（Theory of Mind Policy Optimization）的算法，该算法通过以下方式优化LLM的策略决策：1）基于对对手策略的推理生成回滚（rollouts）；2）在图级别和样本级别进行优势估计；3）平衡全局和局部奖励。

Result: ToMPO算法在模型输出合规性和合作成果方面比GRPO算法提升了35%，并且比参数量大100倍的模型提升了18%。

Conclusion: ToMPO算法能有效提升LLM的策略决策能力。

Abstract: Large Language Models (LLMs) have been used to make decisions in complex
scenarios, where they need models to think deeply, reason logically, and decide
wisely. Many existing studies focus solely on multi-round conversations in
social tasks or simulated environments, neglecting the various types of
decisions and their interdependence. Current reinforcement learning methods
struggle to consider the strategies of others during training. To address these
issues, we first define a strategic decision-making problem that includes two
types of decisions and their temporal dependencies. Furthermore, we propose
**T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to
optimize the perception of other individual strategies and the game situation
trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm,
ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating
rollouts based on reasoning the strategies of other individuals, 2) estimating
advantages at both the graph-level and sample-level, and 3) balancing global
and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in
terms of model output compliance and cooperative outcomes. Additionally, when
compared to models with parameter sizes 100 times larger, it shows an 18%
improvement. This demonstrates the effectiveness of the ToMPO algorithm in
enhancing the model's strategic decision-making capabilities.

</details>


### [311] [Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems](https://arxiv.org/abs/2509.20513)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 该研究提出了一种新的重构框架，用于动态验证和组装时间触发系统（TTS）的调度，以应对动态环境中的挑战，如消息冲突和不正确的优先顺序处理。


<details>
  <summary>Details</summary>
Motivation: 为了应对动态操作环境中时间触发系统（TTS）的可靠性和安全性问题，以及现存调度框架面临的消息冲突、锁环和不完整/无效调度等挑战。

Method: 提出了一种新颖的重构框架，通过系统地转换AI生成或启发式确定的调度优先级来构建完全可执行的调度。该框架包括安全检查、高效分配算法和恢复机制，以处理硬件故障和模式转换等意外情况。

Result: 实验结果表明，所提出的框架显著提高了系统的适应性、运行完整性和运行时性能，同时保持了计算效率，并在最小化完成时间、工作负载平衡和能源效率等多个性能指标上进行了验证。

Conclusion: 这项工作为安全关键TTS中安全调度生成问题提供了一个实用且可扩展的解决方案，即使在高度动态和不确定的操作条件下，也能实现可靠和灵活的实时调度。

Abstract: Adaptive scheduling is crucial for ensuring the reliability and safety of
time-triggered systems (TTS) in dynamic operational environments. Scheduling
frameworks face significant challenges, including message collisions, locked
loops from incorrect precedence handling, and the generation of incomplete or
invalid schedules, which can compromise system safety and performance. To
address these challenges, this paper presents a novel reconstruction framework
designed to dynamically validate and assemble schedules. The proposed
reconstruction models operate by systematically transforming AI-generated or
heuristically derived scheduling priorities into fully executable schedules,
ensuring adherence to critical system constraints such as precedence rules and
collision-free communication. It incorporates robust safety checks, efficient
allocation algorithms, and recovery mechanisms to handle unexpected context
events, including hardware failures and mode transitions. Comprehensive
experiments were conducted across multiple performance profiles, including
makespan minimisation, workload balancing, and energy efficiency, to validate
the operational effectiveness of the reconstruction models. Results demonstrate
that the proposed framework significantly enhances system adaptability,
operational integrity, and runtime performance while maintaining computational
efficiency. Overall, this work contributes a practical and scalable solution to
the problem of safe schedule generation in safety-critical TTS, enabling
reliable and flexible real-time scheduling even under highly dynamic and
uncertain operational conditions.

</details>


### [312] [Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications](https://arxiv.org/abs/2509.20520)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 文章提出了一种自适应在线学习单元，用于增强时间触发架构中元调度器的实时性能，解决了传统离线训练方法在构建多调度图（MSG）时面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统离线训练方法在构建能够涵盖所有可能场景（如硬件故障、模式切换等）的多调度图（MSG）时面临资源密集和不可行的挑战。当前的MSG仅是完整概率空间的一个子集，侧重于最可能和最关键的上下文事件。

Method: 提出了一种自适应在线学习单元，并将其集成到元调度器中。该单元利用强化学习（RL）实时探索和发现新的调度解决方案，不断扩展MSG，并通过实时训练持续优化AI推理。

Result: 通过在在线学习单元中实现多种RL模型，不仅发现了新的调度解决方案，还优化了现有的调度器，特别是在引入更严格的截止日期或新的性能标准时。

Conclusion: 该方法通过动态适应和实时训练，提高了系统处理意外事件和复杂调度场景的效率和鲁棒性，使其能够满足不断变化的需求，特别是在大规模、安全关键的环境中。

Abstract: Metascheduling in time-triggered architectures has been crucial in adapting
to dynamic and unpredictable environments, ensuring the reliability and
efficiency of task execution. However, traditional approaches face significant
challenges when training Artificial Intelligence (AI) scheduling inferences
offline, particularly due to the complexities involved in constructing a
comprehensive Multi-Schedule Graph (MSG) that accounts for all possible
scenarios. The process of generating an MSG that captures the vast probability
space, especially when considering context events like hardware failures, slack
variations, or mode changes, is resource-intensive and often infeasible. To
address these challenges, we propose an adaptive online learning unit
integrated within the metascheduler to enhance performance in real-time. The
primary motivation for developing this unit stems from the limitations of
offline training, where the MSG created is inherently a subset of the complete
space, focusing only on the most probable and critical context events. In the
online mode, Reinforcement Learning (RL) plays a pivotal role by continuously
exploring and discovering new scheduling solutions, thus expanding the MSG and
enhancing system performance over time. This dynamic adaptation allows the
system to handle unexpected events and complex scheduling scenarios more
effectively. Several RL models were implemented within the online learning
unit, each designed to address specific challenges in scheduling. These models
not only facilitate the discovery of new solutions but also optimize existing
schedulers, particularly when stricter deadlines or new performance criteria
are introduced. By continuously refining the AI inferences through real-time
training, the system remains flexible and capable of meeting evolving demands,
thus ensuring robustness and efficiency in large-scale, safety-critical
environments.

</details>


### [313] [A Compound Classification System Based on Fuzzy Relations Applied to the Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition](https://arxiv.org/abs/2509.20523)
*Pawel Trajdos,Marek Kurzynski*

Main category: cs.AI

TL;DR: 提出了一种用于肌电信号（EMG）控制手部假肢的新型识别系统，该系统能够检测受污染的肌电信号，以减轻污染的不利影响。


<details>
  <summary>Details</summary>
Motivation: 由于人体源信号和人机接口的多种因素，基于肌电信号的模式识别在假肢控制中存在分类质量难以令人满意的问题，特别是生物信号易受干扰，严重影响识别质量。

Method: 该系统包含两个部分：一个由单类分类器（OCC）组成的集合，用于评估各个通道的污染程度；一个由K近邻（KNN）分类器组成的集合，用于识别患者意图。整个系统采用了一个原创的、一致的模糊模型，实现了整个识别过程中统一的软（模糊）决策方案。

Result: 使用公开存储库中的真实生物信号进行了实验评估，旨在对所开发方法的参数和程序进行实验比较分析，并与文献中描述的类似系统进行了比较。

Conclusion: 所提出的模糊识别系统能够有效检测受污染的生物信号，并与现有系统相比具有良好的识别性能。

Abstract: Modern anthropomorphic upper limb bioprostheses are typically controlled by
electromyographic (EMG) biosignals using a pattern recognition scheme.
Unfortunately, there are many factors originating from the human source of
objects to be classified and from the human-prosthesis interface that make it
difficult to obtain an acceptable classification quality. One of these factors
is the high susceptibility of biosignals to contamination, which can
considerably reduce the quality of classification of a recognition system.
  In the paper, the authors propose a new recognition system intended for EMG
based control of the hand prosthesis with detection of contaminated biosignals
in order to mitigate the adverse effect of contaminations. The system consists
of two ensembles: the set of one-class classifiers (OCC) to assess the degree
of contamination of individual channels and the ensemble of K-nearest
neighbours (KNN) classifier to recognise the patient's intent. For all
recognition systems, an original, coherent fuzzy model was developed, which
allows the use of a uniform soft (fuzzy) decision scheme throughout the
recognition process. The experimental evaluation was conducted using real
biosignals from a public repository. The goal was to provide an experimental
comparative analysis of the parameters and procedures of the developed method
on which the quality of the recognition system depends. The proposed fuzzy
recognition system was also compared with similar systems described in the
literature.

</details>


### [314] [SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection](https://arxiv.org/abs/2509.20562)
*Yubin Ge,Salvatore Romeo,Jason Cai,Monica Sunkara,Yi Zhang*

Main category: cs.AI

TL;DR: SAMULE框架通过多层次反思合成来提升LLM代理的自我学习能力，解决了现有方法在复杂任务中反思不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在复杂任务中由于错误分析不足和依赖少数成功轨迹，难以产生有意义的反思。

Method: 提出SAMULE框架，包含一个回顾语言模型，通过单轨迹学习（微观）、任务内学习（中观）和任务间学习（宏观）三个层面合成反思，并用于推理。此外，通过前视反思机制扩展到交互式设置。

Result: 在TravelPlanner、NATURAL PLAN和Tau-bench三个基准测试中，SAMULE显著优于基于反思的基线方法。

Conclusion: 精心设计的反思合成和以失败为中心学习对于构建自我改进的LLM代理至关重要。

Abstract: Despite the rapid advancements in LLM agents, they still face the challenge
of generating meaningful reflections due to inadequate error analysis and a
reliance on rare successful trajectories, especially in complex tasks. In this
work, we propose SAMULE, a new framework for self-learning agents powered by a
retrospective language model that is trained based on Multi-Level Reflection
Synthesis. It first synthesizes high-quality reflections across three
complementary levels: Single-Trajectory Learning (micro-level) for detailed
error correction; Intra-Task Learning (meso-level) to build error taxonomies
across multiple trials of the same task, and Inter-Task Learning (macro-level)
to extract transferable insights based on same typed errors from diverse task
failures. Then we fine-tune a language model serving as the retrospective model
to generate reflections during inference. We further extend our framework to
interactive settings through a foresight-based reflection mechanism, enabling
agents to proactively reflect and adapt during user interactions by comparing
predicted and actual responses. Extensive experiments on three challenging
benchmarks - TravelPlanner, NATURAL PLAN, and Tau-bench - demonstrate that our
approach significantly outperforms reflection-based baselines. Our results
highlight the critical role of well-designed reflection synthesis and
failure-centric learning in building self-improving LLM agents.

</details>


### [315] [Adaptive Cybersecurity Architecture for Digital Product Ecosystems Using Agentic AI](https://arxiv.org/abs/2509.20640)
*Oluwakemi T. Olayinka,Sumeet Jeswani,Divine Iloh*

Main category: cs.AI

TL;DR: 本研究引入了一种由智能体驱动的自适应网络安全架构，利用自主目标驱动的智能体进行动态学习和上下文感知决策，以应对传统静态模型的不足。


<details>
  <summary>Details</summary>
Motivation: 传统静态网络安全模型在应对日益复杂的数字产品生态系统（包括云服务、API、移动平台和边缘设备）时，在可扩展性、实时检测和上下文响应方面存在挑战。

Method: 该框架将智能体人工智能集成到关键生态系统层，以实现自主威胁缓解、主动策略执行和实时异常检测。其特点包括行为基线分析、去中心化风险评分和联邦威胁情报共享。

Result: 通过本地云仿真，证明了系统识别零日攻击和动态修改访问策略的能力。评估结果显示，系统的适应性增强、响应延迟降低、检测准确性提高。

Conclusion: 该智能架构为保护复杂数字基础设施提供了一个智能且可扩展的蓝图，与零信任模型兼容，并支持遵守国际网络安全法规。

Abstract: Traditional static cybersecurity models often struggle with scalability,
real-time detection, and contextual responsiveness in the current digital
product ecosystems which include cloud services, application programming
interfaces (APIs), mobile platforms, and edge devices. This study introduces
autonomous goal driven agents capable of dynamic learning and context-aware
decision making as part of an adaptive cybersecurity architecture driven by
agentic artificial intelligence (AI). To facilitate autonomous threat
mitigation, proactive policy enforcement, and real-time anomaly detection, this
framework integrates agentic AI across the key ecosystem layers. Behavioral
baselining, decentralized risk scoring, and federated threat intelligence
sharing are important features. The capacity of the system to identify zero-day
attacks and dynamically modify access policies was demonstrated through native
cloud simulations. The evaluation results show increased adaptability,
decreased response latency, and improved detection accuracy. The architecture
provides an intelligent and scalable blueprint for safeguarding complex digital
infrastructure and is compatible with zero-trust models, thereby supporting the
adherence to international cybersecurity regulations.

</details>


### [316] [Accelerate Creation of Product Claims Using Generative AI](https://arxiv.org/abs/2509.20652)
*Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers*

Main category: cs.AI

TL;DR: Claim Advisor是一个利用大型语言模型（LLM）的Web应用程序，可以加速产品声明的创建、搜索、优化和模拟，旨在通过语义搜索、生成和基于合成消费者的模拟来提高效率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 产品声明是影响消费者购买行为的关键因素，但创建声明通常耗时且成本高昂。该研究旨在加速和优化声明的创建过程。

Method: 开发了一个名为Claim Advisor的Web应用程序，该应用程序利用LLM的上下文学习和微调能力，包括三个功能：1）语义搜索和识别现有声明/视觉效果；2）基于产品描述和消费者画像生成/优化声明；3）通过模拟合成消费者对生成/手动创建的声明进行排名。

Result: 在消费品（CPG）公司中的应用显示出非常有前景的结果，表明该方法在提高声明创建的速度和经济性方面是有效的。

Conclusion: Claim Advisor的能力被认为在不同产品类别和行业中具有广泛的实用性，并鼓励在不同行业中研究和应用生成式AI。

Abstract: The benefit claims of a product is a critical driver of consumers' purchase
behavior. Creating product claims is an intense task that requires substantial
time and funding. We have developed the $\textbf{Claim Advisor}$ web
application to accelerate claim creations using in-context learning and
fine-tuning of large language models (LLM). $\textbf{Claim Advisor}$ was
designed to disrupt the speed and economics of claim search, generation,
optimization, and simulation. It has three functions: (1) semantically
searching and identifying existing claims and/or visuals that resonate with the
voice of consumers; (2) generating and/or optimizing claims based on a product
description and a consumer profile; and (3) ranking generated and/or manually
created claims using simulations via synthetic consumers. Applications in a
consumer packaged goods (CPG) company have shown very promising results. We
believe that this capability is broadly useful and applicable across product
categories and industries. We share our learning to encourage the research and
application of generative AI in different industries.

</details>


### [317] [An Automated Retrieval-Augmented Generation LLaMA-4 109B-based System for Evaluating Radiotherapy Treatment Plans](https://arxiv.org/abs/2509.20707)
*Junjie Cui,Peilong Wang,Jason Holmes,Leshan Sun,Michael L. Hinni,Barbara A. Pockaj,Sujay A. Vora,Terence T. Sio,William W. Wong,Nathan Y. Yu,Steven E. Schild,Joshua R. Niska,Sameer R. Keole,Jean-Claude M. Rwigema,Samir H. Patel,Lisa A. McGee,Carlos A. Vargas,Wei Liu*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Purpose: To develop a retrieval-augmented generation (RAG) system powered by
LLaMA-4 109B for automated, protocol-aware, and interpretable evaluation of
radiotherapy treatment plans.
  Methods and Materials: We curated a multi-protocol dataset of 614
radiotherapy plans across four disease sites and constructed a knowledge base
containing normalized dose metrics and protocol-defined constraints. The RAG
system integrates three core modules: a retrieval engine optimized across five
SentenceTransformer backbones, a percentile prediction component based on
cohort similarity, and a clinical constraint checker. These tools are directed
by a large language model (LLM) using a multi-step prompt-driven reasoning
pipeline to produce concise, grounded evaluations.
  Results: Retrieval hyperparameters were optimized using Gaussian Process on a
scalarized loss function combining root mean squared error (RMSE), mean
absolute error (MAE), and clinically motivated accuracy thresholds. The best
configuration, based on all-MiniLM-L6-v2, achieved perfect nearest-neighbor
accuracy within a 5-percentile-point margin and a sub-2pt MAE. When tested
end-to-end, the RAG system achieved 100% agreement with the computed values by
standalone retrieval and constraint-checking modules on both percentile
estimates and constraint identification, confirming reliable execution of all
retrieval, prediction and checking steps.
  Conclusion: Our findings highlight the feasibility of combining structured
population-based scoring with modular tool-augmented reasoning for transparent,
scalable plan evaluation in radiation therapy. The system offers traceable
outputs, minimizes hallucination, and demonstrates robustness across protocols.
Future directions include clinician-led validation, and improved domain-adapted
retrieval models to enhance real-world integration.

</details>


### [318] [Parallel Thinking, Sequential Answering: Bridging NAR and AR for Efficient Reasoning](https://arxiv.org/abs/2509.20744)
*Qihang Ai,Haiyun Jiang*

Main category: cs.AI

TL;DR: 结合自回归（AR）和非自回归（NAR）模型来改进推理任务的性能和效率，NAR模型生成推理过程，AR模型生成最终答案。


<details>
  <summary>Details</summary>
Motivation: 自回归（AR）模型在生成连贯输出方面表现出色，但在数学和代码等需要长推理链的领域，推理速度较慢。非自回归（NAR）模型（如离散扩散模型）可以并行生成，速度快，但输出质量通常较低。

Method: 提出一种新范式，其中NAR模型生成中间推理链，然后指导AR模型生成精确的最终答案。

Result: 实验表明，与强大的基线相比，该方法在性能上有显著的26%的提升，同时显著降低了推理成本。

Conclusion: 所提出的结合AR和NAR模型的范式能够有效提升推理任务的性能和效率。

Abstract: We study reasoning tasks through a framework that integrates auto-regressive
(AR) and non-autoregressive (NAR) language models. AR models, which generate
text sequentially, excel at producing coherent outputs but often suffer from
slow inference, particularly in reasoning-intensive domains such as mathematics
and code, where lengthy chains of thought are required. In contrast, NAR
models, such as discrete diffusion models, allow parallel generation and offer
substantial speedups, though typically at the cost of reduced output quality.
To address these limitations, we introduce a new paradigm in which an NAR model
efficiently produces intermediate reasoning traces, which subsequently guide an
AR model to deliver precise final answers. Experiments demonstrate that our
approach yields significant 26% improvements over strong baselines while
substantially reducing inference cost.

</details>


### [319] [Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning](https://arxiv.org/abs/2509.20754)
*Yufan Mao,Hanjing Ye,Wenlong Dong,Chengjie Zhang,Hong Zhang*

Main category: cs.AI

TL;DR: Meta-Memory是一个利用大语言模型（LLM）来增强机器人空间问答能力的方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人研究在记忆存储方面有进展，但在高效记忆检索和整合方面存在不足，特别是在回答关于空间位置的人类查询时。

Method: 提出Meta-Memory，一个由大语言模型驱动的智能体，它构建高密度环境记忆表示，并通过联合推理语义和空间模态来检索和整合相关记忆，以响应自然语言查询。

Result: 在SpaceLocQA和NaVQA基准测试中，Meta-Memory显著优于现有方法，并在真实机器人平台上成功部署。

Conclusion: Meta-Memory能够有效地利用记忆进行空间推理，并成功应用于机器人导航和问答任务。

Abstract: Navigating complex environments requires robots to effectively store
observations as memories and leverage them to answer human queries about
spatial locations, which is a critical yet underexplored research challenge.
While prior work has made progress in constructing robotic memory, few have
addressed the principled mechanisms needed for efficient memory retrieval and
integration. To bridge this gap, we propose Meta-Memory, a large language model
(LLM)-driven agent that constructs a high-density memory representation of the
environment. The key innovation of Meta-Memory lies in its capacity to retrieve
and integrate relevant memories through joint reasoning over semantic and
spatial modalities in response to natural language location queries, thereby
empowering robots with robust and accurate spatial reasoning capabilities. To
evaluate its performance, we introduce SpaceLocQA, a large-scale dataset
encompassing diverse real-world spatial question-answering scenarios.
Experimental results show that Meta-Memory significantly outperforms
state-of-the-art methods on both the SpaceLocQA and the public NaVQA
benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world
robotic platforms, demonstrating its practical utility in complex environments.
Project page: https://itsbaymax.github.io/meta-memory.github.io/ .

</details>


### [320] [LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning for Log Analysis Tasks](https://arxiv.org/abs/2509.20798)
*Lipeng Ma,Yixuan Li,Weidong Yang,Mingjie Zhou,Xinyi Liu,Ben Fei,Shuhao Li,Xiaoyan Sun,Sihang Jiang,Yanghua Xiao*

Main category: cs.AI

TL;DR: LogReasoner框架通过粗粒度和细粒度增强，使LLM能像专家一样进行日志分析，并在多项任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 通用LLM在进行日志分析时，难以构建符合专家认知且细节精确的结构化推理流程。

Method: LogReasoner框架包含两个阶段：1. 粗粒度增强：从故障排除流程图和现有任务中构建高级专家思维，使LLM能形成结构化推理流程。2. 细粒度增强：首先使用特定任务的逐步解决方案微调LLM，然后利用偏好学习校准LLM的推理细节。

Result: 在四个不同的日志分析任务上，使用Qwen-2.5和Llama-3等开源LLM进行评估，LogReasoner显著优于现有LLM，达到SOTA性能。

Conclusion: LogReasoner框架能有效提升LLM在日志分析任务上的推理能力和准确性。

Abstract: Log analysis is crucial for monitoring system health and diagnosing failures
in complex systems. Recent advances in large language models (LLMs) offer new
opportunities for automated log analysis, leveraging their reasoning
capabilities to perform tasks such as anomaly detection and failure prediction.
However, general-purpose LLMs struggle to formulate structured reasoning
workflows that align with expert cognition and deliver precise details of
reasoning steps. To address these challenges, we propose LogReasoner, a
coarse-to-fine reasoning enhancement framework designed to enable LLMs to
reason log analysis tasks like experts. LogReasoner consists of two stages: (1)
coarse-grained enhancement of expert thinking, where high-level expert thoughts
are constructed from collected troubleshooting flowcharts and existing tasks to
enable LLMs to formulate structured reasoning workflows and (2) fine-grained
enhancement of specific steps, where we first fine-tune the LLM with
task-specific stepwise solutions to enhance the LLM for instantiated reasoning,
then employ the preference learning to calibrate the LLM's reasoning details
from its mistakes, further strengthen the LLM's analytical granularity and
correctness. We evaluate LogReasoner on four distinct log analysis tasks using
open-source LLMs such as Qwen-2.5 and Llama-3. Experimental results show that
LogReasoner significantly outperforms existing LLMs, achieving state-of-the-art
performance and demonstrating its effectiveness in enhancing the reasoning
capabilities of LLMs for log analysis.

</details>


### [321] [DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reasoning](https://arxiv.org/abs/2509.20912)
*Tianrun Xu,Haoda Jing,Ye Li,Yuquan Wei,Jun Feng,Guanyu Chen,Haichuan Gao,Tianren Zhang,Feng Chen*

Main category: cs.AI

TL;DR: DeFacto是一个新的框架，通过反事实推理来提高多模态语言模型在视觉推理任务中的准确性和推理保真度，解决了模型依赖无关区域或偏见的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型（MLLMs）在视觉推理方面取得了显著进展，但存在一个重要挑战：模型可能依赖于不相关或虚假的图像区域来得出正确答案，这表明模型并未真正理解图像，因此推理保真度至关重要。

Method: 提出DeFacto框架，通过结合三个训练范式（正例、反事实、随机遮蔽）来联合优化答案准确性和推理保真度。开发了一个自动定位问题相关证据并构建不同变体的流程，创建了一个包含约10万张图像的数据集。利用基于GRPO的强化学习和三个互补的奖励机制来训练模型。

Result: 在多个基准测试中，DeFacto显著提高了答案准确性和推理保真度，为可解释的多模态推理奠定了更坚实的基础。

Conclusion: DeFacto框架通过引入反事实推理和多样的训练范式，有效解决了多模态语言模型在视觉推理中存在的依赖无关区域和推理不保真问题，提升了模型的整体性能和可解释性。

Abstract: Recent advances in multimodal language models (MLLMs) have achieved
remarkable progress in vision-language reasoning, especially with the emergence
of "thinking with images," which integrates explicit visual steps into the
reasoning process. While this paradigm strengthens image-based reasoning, a
significant challenge remains: models may arrive at correct answers by relying
on irrelevant or spurious regions, driven by prior knowledge or dataset biases.
Even when the answer is correct, flawed reasoning indicates that the model has
not truly understood the image, highlighting the critical importance of
reasoning fidelity in multimodal tasks. To address this issue, we propose
DeFacto, a counterfactual reasoning framework that jointly enforces accurate
answering and faithful reasoning. A key component of our approach is the design
of three complementary training paradigms: (i) positive, (ii) counterfactual,
and (iii) random-masking. To enable these paradigms, we develop a pipeline that
automatically localizes question-relevant evidence and constructs positive,
counterfactual, and random variants, resulting in a dataset of about 100k
images. Building on this framework, we train multimodal language models with
GRPO-based reinforcement learning, where we design three complementary rewards
to guide the model toward accurate answering and evidence-grounded reasoning.
Experiments on diverse benchmarks demonstrate that DeFacto substantially
improves both answer accuracy and reasoning faithfulness, establishing a
stronger foundation for interpretable multimodal reasoning. The code is
available on GitHub and the dataset is released on HuggingFace.

</details>


### [322] [GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine](https://arxiv.org/abs/2509.20935)
*Heming Zhang,Di Huang,Wenyu Li,Michael Province,Yixin Chen,Philip Payne,Fuhai Li*

Main category: cs.AI

TL;DR: GALAX框架集成了GNN和LLM，通过图过程奖励模型进行强化学习，以发现疾病相关子图，用于精准医疗中的靶点和通路发现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合定量多组学、拓扑结构和文本知识方面存在不足，限制了可解释性和准确性。

Method: 提出GALAX框架，将预训练GNN整合到LLM中，利用图过程奖励模型进行强化学习，逐步生成疾病相关子图。引入Target-QA基准进行GNN预训练和评估。

Result: GALAX能够进行可解释的、由强化学习指导的子图推理，实现可靠的靶点和通路发现。

Conclusion: GALAX为精准医疗中的靶点和通路发现提供了一个可扩展、生物学基础扎实且可解释的框架。

Abstract: In precision medicine, quantitative multi-omic features, topological context,
and textual biological knowledge play vital roles in identifying
disease-critical signaling pathways and targets. Existing pipelines capture
only part of these-numerical omics ignore topological context, text-centric
LLMs lack quantitative grounded reasoning, and graph-only models underuse node
semantics and the generalization of LLMs-limiting mechanistic interpretability.
Although Process Reward Models (PRMs) aim to guide reasoning in LLMs, they
remain limited by unreliable intermediate evaluation, and vulnerability to
reward hacking with computational cost. These gaps motivate integrating
quantitative multi-omic signals, topological structure with node annotations,
and literature-scale text via LLMs, using subgraph reasoning as the principle
bridge linking numeric evidence, topological knowledge and language context.
Therefore, we propose GALAX (Graph Augmented LAnguage model with
eXplainability), an innovative framework that integrates pretrained Graph
Neural Networks (GNNs) into Large Language Models (LLMs) via reinforcement
guided by a Graph Process Reward Model (GPRM), which generates disease-relevant
subgraphs in a step-wise manner initiated by an LLM and iteratively evaluated
by a pretrained GNN, enabling process-level supervision without explicit
intermediate reasoning annotations. As an application, we also introduced
Target-QA, a benchmark combining CRISPR-identified targets, multi-omic
profiles, and biomedical graph knowledge across diverse cancer cell lines,
which enables GNN pretraining for supervising step-wise graph construction and
supports long-context reasoning over text-numeric graphs (TNGs), providing a
scalable and biologically grounded framework for explainable,
reinforcement-guided subgraph reasoning toward reliable and interpretable
target and pathway discovery in precision medicine.

</details>


### [323] [Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM](https://arxiv.org/abs/2509.20953)
*Najla Zuhir,Amna Mohammad Salim,Parvathy Premkumar,Moshiur Farazi*

Main category: cs.AI

TL;DR: 本研究提出一种利用大型语言模型（LLM）和结构化提示技术来分析移动应用评论的方法，以克服传统星级评分系统和传统自然语言处理（NLP）技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统星级评分系统无法捕捉评论文本中的细微差别，而传统的NLP技术难以理解上下文、领域特定术语和讽刺等语言特征。

Method: 提出一个模块化框架，利用大型语言模型（LLM）和结构化提示技术，量化数值评分与文本情感之间的差异，提取特征级别的信息，并通过检索增强的对话问答（RAG-QA）支持交互式评论探索。

Result: 在三个不同的数据集（AWARE、Google Play和Spotify）上进行的实验表明，该研究提出的LLM驱动的方法在准确性、鲁棒性和可操作性方面显著优于基线方法。

Conclusion: 所提出的LLM驱动的方法能够更准确、更全面地分析移动应用评论，克服了传统方法的局限性，并提供了更具洞察力的结果。

Abstract: We present an advanced approach to mobile app review analysis aimed at
addressing limitations inherent in traditional star-rating systems. Star
ratings, although intuitive and popular among users, often fail to capture the
nuanced feedback present in detailed review texts. Traditional NLP techniques
-- such as lexicon-based methods and classical machine learning classifiers --
struggle to interpret contextual nuances, domain-specific terminology, and
subtle linguistic features like sarcasm. To overcome these limitations, we
propose a modular framework leveraging large language models (LLMs) enhanced by
structured prompting techniques. Our method quantifies discrepancies between
numerical ratings and textual sentiment, extracts detailed, feature-level
insights, and supports interactive exploration of reviews through
retrieval-augmented conversational question answering (RAG-QA). Comprehensive
experiments conducted on three diverse datasets (AWARE, Google Play, and
Spotify) demonstrate that our LLM-driven approach significantly surpasses
baseline methods, yielding improved accuracy, robustness, and actionable
insights in challenging and context-rich review scenarios.

</details>


### [324] [AOT*: Efficient Synthesis Planning via LLM-Empowered AND-OR Tree Search](https://arxiv.org/abs/2509.20988)
*Xiaozhuang Song,Xuanhao Pan,Xinjian Zhao,Hangting Ye,Shufei Zhang,Jian Tang,Tianshu Yu*

Main category: cs.AI

TL;DR: AOT*框架结合了LLM和AND-OR树搜索，提高了逆合成规划的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 多步逆合成规划因计算复杂性而面临挑战，现有LLM方法在效率和成本方面存在局限性。

Method: AOT*框架将LLM生成的合成路线映射到AND-OR树组件，并结合奖励分配策略和基于检索的上下文工程。

Result: AOT*在多个合成基准测试中取得了最先进的性能，搜索效率显著提高，迭代次数比现有LLM方法少3-5倍，在复杂分子目标上效率优势更明显。

Conclusion: AOT*通过整合LLM和AND-OR树搜索，有效地解决了逆合成规划中的效率和成本问题，并在复杂分子合成方面展现出优越的性能。

Abstract: Retrosynthesis planning enables the discovery of viable synthetic routes for
target molecules, playing a crucial role in domains like drug discovery and
materials design. Multi-step retrosynthetic planning remains computationally
challenging due to exponential search spaces and inference costs. While Large
Language Models (LLMs) demonstrate chemical reasoning capabilities, their
application to synthesis planning faces constraints on efficiency and cost. To
address these challenges, we introduce AOT*, a framework that transforms
retrosynthetic planning by integrating LLM-generated chemical synthesis
pathways with systematic AND-OR tree search. To this end, AOT* atomically maps
the generated complete synthesis routes onto AND-OR tree components, with a
mathematically sound design of reward assignment strategy and retrieval-based
context engineering, thus enabling LLMs to efficiently navigate in the chemical
space. Experimental evaluation on multiple synthesis benchmarks demonstrates
that AOT* achieves SOTA performance with significantly improved search
efficiency. AOT* exhibits competitive solve rates using 3-5$\times$ fewer
iterations than existing LLM-based approaches, with the efficiency advantage
becoming more pronounced on complex molecular targets.

</details>


### [325] [CORE: Full-Path Evaluation of LLM Agents Beyond Final State](https://arxiv.org/abs/2509.20998)
*Panagiotis Michelakis,Yiannis Hadjiyiannis,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: 评估AI代理解决真实世界任务的能力是一个挑战，现有基准忽略了安全性、效率和中间正确性。我们提出了一个基于确定性有限自动机（DFA）的框架，将任务编码为有效的工具使用路径集，并引入了CORE指标套件（包括路径正确性、Kendall's tau复合路径正确性、前缀关键性、有害调用率和效率），以量化代理行为与预期执行模式的一致性。我们的方法在不同环境中揭示了传统最终状态评估方案下看似相似的代理之间的重要性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有的AI代理基准测试在评估真实世界任务解决能力时存在不足，主要侧重于最终状态的二元判断，忽略了安全性、效率和中间正确性等关键方面。

Method: 提出一个基于确定性有限自动机（DFA）的框架，将任务表示为有效的工具使用路径集，并在此基础上引入CORE指标套件（包括路径正确性、Kendall's tau复合路径正确性、前缀关键性、有害调用率和效率）来量化代理行为。

Result: 在多样化的世界模型中，CORE指标揭示了在传统最终状态评估下看似相似的代理之间存在的性能差异，提供了更细粒度的评估。

Conclusion: 基于DFA的框架和CORE指标能够更全面、更精确地评估AI代理在真实世界任务中的表现，克服了现有基准方法的局限性。

Abstract: Evaluating AI agents that solve real-world tasks through function-call
sequences remains an open challenge. Existing agentic benchmarks often reduce
evaluation to a binary judgment of the final state, overlooking critical
aspects such as safety, efficiency, and intermediate correctness. We propose a
framework based on deterministic finite automata (DFAs) that encodes tasks as
sets of valid tool-use paths, enabling principled assessment of agent behavior
in diverse world models. Building on this foundation, we introduce CORE, a
suite of five metrics, namely Path Correctness, Path Correctness - Kendall's
tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that
quantify alignment with expected execution patterns. Across diverse worlds, our
method reveals important performance differences between agents that would
otherwise appear equivalent under traditional final-state evaluation schemes.

</details>


### [326] [Who Gets Cited Most? Benchmarking Long-Context Language Models on Scientific Articles](https://arxiv.org/abs/2509.21028)
*Miao Li,Alexander Gurung,Irina Saparina,Mirella Lapata*

Main category: cs.AI

TL;DR: SciTrek是一个新的问答基准，用于评估LLM在科学文章上的长上下文推理能力，其问题需要跨多个全文科学文章进行信息聚合和综合。


<details>
  <summary>Details</summary>
Motivation: 当前的长期基准测试通常依赖于非科学文本、侧重于简单信息检索任务或使用人工上下文。SciTrek通过提出需要跨多个全文科学文章进行信息聚合和综合的复杂问题来解决这些限制。

Method: 通过将问题和它们的真实答案构建为SQL查询，然后在从文章元数据（标题、作者和参考文献）构建的数据库上执行这些查询来自动生成问题和答案。SQL操作提供了明确的、可验证的推理步骤，用于进行细粒度的错误分析，并且该构建过程可以扩展到1M token的上下文，而只需很少的监督。

Result: 在对各种开放权重和专有LLM进行的广泛实验中，SciTrek随着上下文长度的增加，对LLM提出了重大挑战，并且监督微调和强化学习仅提供了有限的改进。分析表明，模型在执行基本算术运算和在长上下文中准确定位特定信息方面存在系统性缺陷。

Conclusion: SciTrek是一个新的问答基准，用于评估LLM在科学文章上的长上下文推理能力，其问题需要跨多个全文科学文章进行信息聚合和综合。SciTrek通过提出需要跨多个全文科学文章进行信息聚合和综合的复杂问题来解决这些限制。通过将问题和它们的真实答案构建为SQL查询，然后在从文章元数据（标题、作者和参考文献）构建的数据库上执行这些查询来自动生成问题和答案。SQL操作提供了明确的、可验证的推理步骤，用于进行细粒度的错误分析，并且该构建过程可以扩展到1M token的上下文，而只需很少的监督。在对各种开放权重和专有LLM进行的广泛实验中，SciTrek随着上下文长度的增加，对LLM提出了重大挑战，并且监督微调和强化学习仅提供了有限的改进。分析表明，模型在执行基本算术运算和在长上下文中准确定位特定信息方面存在系统性缺陷。

Abstract: This paper introduces SciTrek, a novel question-answering benchmark designed
to evaluate the long-context reasoning capabilities of large language models
(LLMs) using scientific articles. Current long-context benchmarks often rely on
non-scientific texts, focus on simple information retrieval tasks, or employ
artificial contexts. SciTrek addresses these limitations by proposing complex
questions that require information aggregation and synthesis across multiple
full-text scientific articles. Questions and their ground-truth answers are
automatically generated by formulating them as SQL queries over a database
constructed from article metadata (titles, authors, and references). The SQL
operations provide explicit, verifiable reasoning steps for fine-grained error
analysis, and the construction process scales to contexts up to 1M tokens with
minimal supervision. Extensive experiments on a diverse set of open-weight and
proprietary LLMs demonstrate that SciTrek poses a significant challenge as the
context length increases, with supervised fine-tuning and reinforcement
learning offering only limited gains. Our analysis reveals systematic
shortcomings in models' abilities to perform basic numerical operations and
accurately locate specific information in long contexts.

</details>


### [327] [CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering](https://arxiv.org/abs/2509.21035)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Yue Xiu,Dusit Niyato*

Main category: cs.AI

TL;DR: CLAUSE是一个神经符号框架，通过顺序决策优化知识图谱上下文构建，以平衡答案准确性、延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答系统在满足延迟和成本限制的同时，难以平衡答案准确性和来源追溯性，并且静态扩展方法常导致过度检索和不可预测的运行时间。

Method: CLAUSE采用一个由三个智能体组成的神经符号框架，将上下文构建视为在知识图谱上的顺序决策过程，并使用LC-MAPPO算法来优化子图构建、推理路径发现和证据选择，同时遵守用户指定的延迟和成本预算。

Result: 在HotpotQA、MetaQA和FactKG数据集上，CLAUSE在提高答案准确率的同时，减少了子图增长和端到端延迟，并且在相同的或更低的token预算下实现。与GraphRAG基线相比，CLAUSE在MetaQA-2-hop上取得了显著的性能提升，同时降低了延迟和子图增长。

Conclusion: CLAUSE通过将其上下文构建方法视为一个可学习的顺序决策过程，可以在不重新训练的情况下，根据查询自适应地平衡准确性、延迟和成本，从而在部署约束下提供可预测的性能。

Abstract: Knowledge graphs provide structured context for multi-hop question answering,
but deployed systems must balance answer accuracy with strict latency and cost
targets while preserving provenance. Static k-hop expansions and "think-longer"
prompting often over-retrieve, inflate context, and yield unpredictable
runtime. We introduce CLAUSE, an agentic three-agent neuro-symbolic framework
that treats context construction as a sequential decision process over
knowledge graphs, deciding what to expand, which paths to follow or backtrack,
what evidence to keep, and when to stop. Latency (interaction steps) and prompt
cost (selected tokens) are exposed as user-specified budgets or prices,
allowing per-query adaptation to trade-offs among accuracy, latency, and cost
without retraining. CLAUSE employs the proposed Lagrangian-Constrained
Multi-Agent Proximal Policy Optimization (LC-MAPPO) algorithm to coordinate
three agents: Subgraph Architect, Path Navigator, and Context Curator, so that
subgraph construction, reasoning-path discovery, and evidence selection are
jointly optimized under per-query resource budgets on edge edits, interaction
steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields
higher EM@1 while reducing subgraph growth and end-to-end latency at equal or
lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline
(GraphRAG), CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower
edge growth. The resulting contexts are compact, provenance-preserving, and
deliver predictable performance under deployment constraints.

</details>


### [328] [Combinatorial Creativity: A New Frontier in Generalization Abilities](https://arxiv.org/abs/2509.21043)
*Samuel Schapiro,Sumuk Shashidhar,Alexi Gladstone,Jonah Black,Royce Moon,Dilek Hakkani-Tur,Lav R. Varshney*

Main category: cs.AI

TL;DR: AI（特别是LLMs）在科学idea生成等创意任务中的应用，提出了新的评估框架和算法任务，以度量新颖性和实用性，并对LLMs的创造力进行了实证研究，发现了其缩放行为、最优模型参数以及新颖性-实用性权衡问题，指出当前LLMs的长期创造潜力有限。


<details>
  <summary>Details</summary>
Motivation: 现有概念框架未能解决AI（特别是LLMs）在科学idea生成等创意任务中出现的泛化问题，而这种泛化与组合泛化（CG）相似但更具开放性。

Method: 提出一个理论框架和算法任务，通过评估生成内容的“新颖性”和“实用性”程度来衡量创造力，而非传统的准确性或正确性。

Result: 1. 首次揭示了LLMs创造力的缩放行为；2. 发现固定计算预算下存在最优的模型深度和宽度以获得最佳创造力；3. 提出“想法-执行”鸿沟（LLMs擅长生成新颖想法但难以保证其实际可行性）可由更根本的“新颖性-实用性”权衡解释，这种权衡即使在扩展规模后依然存在，对LLMs的长期创造潜力提出质疑。

Conclusion: 该研究提出的概念框架和实证发现为理解和改进现代AI模型的创造力奠定了基础，标志着泛化能力研究的新前沿。

Abstract: Artificial intelligence (AI) systems, and large language models (LLMs) in
particular, are increasingly employed for creative tasks like scientific idea
generation, constituting a form of generalization from training data
unaddressed by existing conceptual frameworks. Though in many ways similar to
forms of compositional generalization (CG), combinatorial creativity (CC) is an
open-ended ability. Instead of evaluating for accuracy or correctness against
fixed targets, which would contradict the open-ended nature of CC, we propose a
theoretical framework and algorithmic task for evaluating outputs by their
degrees of novelty and utility. From here, we make several important empirical
contributions: (1) We obtain the first insights into the scaling behavior of
creativity for LLMs. (2) We discover that, for fixed compute budgets, there
exist optimal model depths and widths for creative ability. (3) We find that
the ideation-execution gap, whereby LLMs excel at generating novel scientific
ideas but struggle to ensure their practical feasibility, may be explained by a
more fundamental novelty-utility tradeoff characteristic of creativity
algorithms in general. Importantly, this tradeoff remains persistent even at
scale, casting doubt on the long-term creative potential of LLMs in their
current form. Together, our conceptual framework and empirical findings provide
a foundation for understanding and improving creativity in modern AI models,
marking a new frontier in generalization abilities.

</details>


### [329] [Disagreements in Reasoning: How a Model's Thinking Process Dictates Persuasion in Multi-Agent Systems](https://arxiv.org/abs/2509.21054)
*Haodong Zhao,Jidong Li,Zhaomin Wu,Tianjie Ju,Zhuosheng Zhang,Bingsheng He,Gongshen Liu*

Main category: cs.AI

TL;DR: LLM/LRM协作中，说服力的关键在于认知过程而非模型规模，透明化推理过程可增强说服力。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为模型规模决定说服力，本文提出质疑，认为认知过程（尤其是显式推理能力）是关键。

Method: 通过多智能体说服实验，研究模型规模、认知过程（推理）以及信息透明度对说服力的影响，并探讨多跳说服中的影响传播。

Result: 提出“说服二元性”：LRM的推理过程抗说服性强，但透明化其“思考内容”后能显著增强说服他人的能力。揭示了多跳说服中的影响传播和衰减的复杂动态。

Conclusion: 模型的内部处理架构与其外部说服行为存在联系，为模型易受说服提供了新解释，对未来MAS的安全、鲁棒性和设计具有重要意义。

Abstract: The rapid proliferation of recent Multi-Agent Systems (MAS), where Large
Language Models (LLMs) and Large Reasoning Models (LRMs) usually collaborate to
solve complex problems, necessitates a deep understanding of the persuasion
dynamics that govern their interactions. This paper challenges the prevailing
hypothesis that persuasive efficacy is primarily a function of model scale. We
propose instead that these dynamics are fundamentally dictated by a model's
underlying cognitive process, especially its capacity for explicit reasoning.
Through a series of multi-agent persuasion experiments, we uncover a
fundamental trade-off we term the Persuasion Duality. Our findings reveal that
the reasoning process in LRMs exhibits significantly greater resistance to
persuasion, maintaining their initial beliefs more robustly. Conversely, making
this reasoning process transparent by sharing the "thinking content"
dramatically increases their ability to persuade others. We further consider
more complex transmission persuasion situations and reveal complex dynamics of
influence propagation and decay within multi-hop persuasion between multiple
agent networks. This research provides systematic evidence linking a model's
internal processing architecture to its external persuasive behavior, offering
a novel explanation for the susceptibility of advanced models and highlighting
critical implications for the safety, robustness, and design of future MAS.

</details>


### [330] [Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution](https://arxiv.org/abs/2509.21072)
*Kaiwen He,Zhiwei Wang,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: Recon-Act是一个多智能体框架，通过侦察和行动的协同作用，提高了网页浏览代理在长周期任务中的表现，并能适应新网站。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型在处理真实网页的多轮长周期任务时，存在行动排序混乱和试错过多的问题。

Method: 提出Recon-Act框架，包含侦察团队和行动团队。侦察团队进行对比分析和工具生成，行动团队负责意图分解、工具编排和执行。侦察团队通过对比错误和成功轨迹，推断补救措施，并将其抽象为通用工具（提示或规则代码），实时注册到工具库。行动团队利用这些工具进行推理，形成数据-工具-行动-反馈的闭环训练。

Result: Recon-Act显著提高了对未见网站的适应性和长周期任务的可解决性，并在VisualWebArena数据集上取得了最先进的性能。目前已实现Level 3。

Conclusion: Recon-Act通过其创新的侦察-行动范式和通用工具生成机制，有效解决了现有网页浏览代理在长周期任务中的挑战，并在实验中证明了其优越性。

Abstract: Recent years, multimodal models have made remarkable strides and pave the way
for intelligent browser use agents. However, when solving tasks on real world
webpages in multi-turn, long-horizon trajectories, current agents still suffer
from disordered action sequencing and excessive trial and error during
execution. This paper introduces Recon-Act, a self-evolving multi-agent
framework grounded in Reconnaissance-Action behavioral paradigm. The system
comprises a Reconnaissance Team and an Action Team: the former conducts
comparative analysis and tool generation, while the latter handles intent
decomposition, tool orchestration, and execution. By contrasting the erroneous
trajectories with successful ones, the Reconnaissance Team infers remedies, and
abstracts them into a unified notion of generalized tools, either expressed as
hints or as rule-based codes, and register to the tool archive in real time.
The Action Team reinference the process empowered with these targeting tools,
thus establishing a closed-loop training pipeline of
data-tools-action-feedback. Following the 6 level implementation roadmap
proposed in this work, we have currently reached Level 3 (with limited
human-in-the-loop intervention). Leveraging generalized tools obtained through
reconnaissance, Recon-Act substantially improves adaptability to unseen
websites and solvability on long-horizon tasks, and achieves state-of-the-art
performance on the challenging VisualWebArena dataset.

</details>


### [331] [TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them](https://arxiv.org/abs/2509.21117)
*Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.AI

TL;DR: LLM评估框架存在评分和排序不一致的问题，提出TrustJudge框架通过分布敏感评分和似然感知聚合解决这些问题，并有效减少了不一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估框架存在评分和排序不一致的问题，影响了评估的可靠性。

Method: 提出TrustJudge框架，包含分布敏感评分和似然感知聚合两个关键创新点，以解决信息丢失和排序歧义问题。

Result: TrustJudge将评分-比较不一致性降低了8.43%，将成对传递不一致性降低了10.82%，同时保持了更高的评估准确性。

Conclusion: TrustJudge是首个系统性分析LLM评估框架不一致性问题的工作，提供了理论见解和实际解决方案，提高了LLM评估的可靠性。

Abstract: The adoption of Large Language Models (LLMs) as automated evaluators
(LLM-as-a-judge) has revealed critical inconsistencies in current evaluation
frameworks. We identify two fundamental types of inconsistencies: (1)
Score-Comparison Inconsistency, where lower-rated responses outperform
higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity
Inconsistency, manifested through circular preference chains (A>B>C>A) and
equivalence contradictions (A=B=C\neq A). We argue that these issues come from
information loss in discrete rating systems and ambiguous tie judgments during
pairwise evaluation. We propose TrustJudge, a probabilistic framework that
addresses these limitations through two key innovations: 1)
distribution-sensitive scoring that computes continuous expectations from
discrete rating probabilities, preserving information entropy for more precise
scoring, and 2) likelihood-aware aggregation that resolves transitivity
violations using bidirectional preference probabilities or perplexity. We also
formalize the theoretical limitations of current LLM-as-a-judge frameworks and
demonstrate how TrustJudge's components overcome them. When evaluated with
Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces
Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise
Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining
higher evaluation accuracy. Our work provides the first systematic analysis of
evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both
theoretical insights and practical solutions for reliable automated assessment.
The framework demonstrates consistent improvements across various model
architectures and scales, enabling more trustworthy LLM evaluation without
requiring additional training or human annotations. The codes can be found at
https://github.com/TrustJudge/TrustJudge.

</details>


### [332] [Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns](https://arxiv.org/abs/2509.21124)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent progress in large reasoning models for challenging mathematical
reasoning has been driven by reinforcement learning (RL). Incorporating long
chain-of-thought (CoT) data during mid-training has also been shown to
substantially improve reasoning depth. However, current approaches often
utilize CoT data indiscriminately, leaving open the critical question of which
data types most effectively enhance model reasoning capabilities. In this
paper, we define the foundation model's reasoning potential for the first time
as the inverse of the number of independent attempts required to correctly
answer the question, which is strongly correlated with the final model
performance. We then propose utilizing diverse data enriched with high-value
reasoning patterns to expand the reasoning potential. Specifically, we abstract
atomic reasoning patterns from CoT sequences, characterized by commonality and
inductive capabilities, and use them to construct a core reference set enriched
with valuable reasoning patterns. Furthermore, we propose a dual-granularity
algorithm involving chains of reasoning patterns and token entropy, efficiently
selecting high-value CoT data (CoTP) from the data pool that aligns with the
core set, thereby training models to master reasoning effectively. Only
10B-token CoTP data enables the 85A6B Mixture-of-Experts (MoE) model to improve
by 9.58% on the challenging AIME 2024 and 2025, and to raise the upper bound of
downstream RL performance by 7.81%.

</details>


### [333] [RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](https://arxiv.org/abs/2509.21128)
*Kohsei Matsutani,Shota Takashiro,Gouki Minegishi,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 该论文提出了一种新的分析框架，用于量化大型语言模型（LLMs）在数学推理任务中的推理路径，并分析了监督微调（SFT）和强化学习（RL）对其推理能力的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对SFT和RL如何塑造LLMs推理能力的深入理解，本文旨在填补这一空白。

Method: 论文引入了一个新的分析框架，在轨迹和步骤两个层面量化推理路径，并分析了不同参数规模的模型（1.5B, 7B, 14B）在数学领域的表现。具体包括：1. 轨迹层面：分析完整推理输出的聚类，比较RL和SFT对错误和正确推理轨迹的影响。2. 步骤层面：分析推理图的节点访问频率、度数和介数中心性等指标的衰减率，揭示RL和SFT对推理步骤的集中化和分散化效应。

Result: RL压缩了不正确的推理轨迹，而SFT扩展了正确的推理轨迹。RL使节点访问频率等指标的衰减率增加了约2.5倍，而SFT则降低了约三分之二。RL将推理功能集中在少数关键步骤，SFT则将其分散到多个步骤。分析了RL和SFT在推理图拓扑结构上的共享和独特特征。

Conclusion: 现有的SFT后接RL的两阶段训练方法之所以有效，是因为RL能够强化正确的推理路径并排除错误的路径，而SFT则能够引导模型学习更广泛的推理模式。该研究为数据构建和更有效的学习方法提供了实践启示。

Abstract: Large language models (LLMs) are typically trained by reinforcement learning
(RL) with verifiable rewards (RLVR) and supervised fine-tuning (SFT) on
reasoning traces to improve their reasoning abilities. However, how these
methods shape reasoning capabilities remains largely elusive. Going beyond an
accuracy-based investigation of how these two components sculpt the reasoning
process, this paper introduces a novel analysis framework that quantifies
reasoning paths and captures their qualitative changes under each training
process (with models of 1.5B, 7B, and 14B parameters on mathematical domains).
Specifically, we investigate the reasoning process at two levels of
granularity: the trajectory-level, which examines complete reasoning outputs,
and the step-level, which analyzes reasoning graphs whose nodes correspond to
individual reasoning steps. Notably, clustering of unique reasoning
trajectories shows complementary effects: RL compresses incorrect trajectories,
whereas SFT expands correct ones. Step-level analysis reveals that RL steepens
(about 2.5 times), while SFT flattens (reduced to about one-third), the decay
rates of node visitation frequency, degree, and betweenness centrality
distributions in the reasoning graph. This indicates that RL concentrates
reasoning functionality into a small subset of steps, while SFT homogenizes it
across many steps. Furthermore, by evaluating the reasoning graph topologies
from multiple perspectives, we delineate the shared and distinct
characteristics of RL and SFT. Our work presents a novel reasoning path
perspective that explains why the current best practice of two-stage training,
with SFT followed by RL, is successful, and offers practical implications for
data construction and more efficient learning approaches.

</details>


### [334] [Embodied Representation Alignment with Mirror Neurons](https://arxiv.org/abs/2509.21136)
*Wentao Zhu,Zhining Zhang,Yuwei Ren,Yin Huang,Hao Xu,Yizhou Wang*

Main category: cs.AI

TL;DR: 本文提出了一种受镜像神经元启发的统一方法，通过表示学习来同时建模动作观察和执行，并通过对比学习显式地对齐它们的中间表示，实验证明该方法提高了表示质量和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法在处理动作理解和执行时，将它们视为独立任务，忽略了镜像神经元所揭示的两者之间的内在联系。

Method: 提出了一种统一的表示学习方法，通过两个线性层将观察和执行动作的表示映射到共享的潜在空间，并使用对比学习来强制对齐相应的表示，以最大化互信息。

Result: 实验表明，该方法能够促进两个任务之间的协同作用，提高表示质量和泛化能力。

Conclusion: 所提出的受镜像神经元启发的统一方法能够有效地同时建模动作观察和执行，并通过显式对齐表示来提升模型性能。

Abstract: Mirror neurons are a class of neurons that activate both when an individual
observes an action and when they perform the same action. This mechanism
reveals a fundamental interplay between action understanding and embodied
execution, suggesting that these two abilities are inherently connected.
Nonetheless, existing machine learning methods largely overlook this interplay,
treating these abilities as separate tasks. In this study, we provide a unified
perspective in modeling them through the lens of representation learning. We
first observe that their intermediate representations spontaneously align.
Inspired by mirror neurons, we further introduce an approach that explicitly
aligns the representations of observed and executed actions. Specifically, we
employ two linear layers to map the representations to a shared latent space,
where contrastive learning enforces the alignment of corresponding
representations, effectively maximizing their mutual information. Experiments
demonstrate that this simple approach fosters mutual synergy between the two
tasks, effectively improving representation quality and generalization.

</details>


### [335] [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://arxiv.org/abs/2509.21163)
*Jing Liu,Haozheng Wang,Yueheng Li*

Main category: cs.AI

TL;DR: LLMs处理罕见词元（rare tokens）的方式是通过分布式协调，而非独立的模块化结构，这有助于模型的可解释性、效率和功能组织。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理专业领域中重要的罕见词元时存在困难，需要研究其内部机制。

Method: 通过分析不同模型家族的最终层MLP神经元，研究罕见词元处理过程中的内部专业化机制，区分离散模块化和分布式参数差异。

Result: 发现罕见词元处理依赖于“分布式专业化”，包括三个层级的神经元影响（平台神经元、幂律衰减神经元、最小贡献神经元）；平台神经元表现出协调激活模式，但空间上是分布式的；这些机制通过标准注意力路径即可访问，无需专用路由电路。训练动力学表明，专业化是逐渐出现的，神经元权重相关性谱呈现幂律特征。

Conclusion: LLMs通过共享架构内的分布式协调来处理罕见词元，而不是采用类似混合专家（mixture-of-experts）的模块化方法。这为模型编辑、效率优化和理解Transformer网络中的功能组织提供了见解。

Abstract: Large language models (LLMs) struggle with representing and generating rare
tokens despite their importance in specialized domains. We investigate whether
LLMs develop internal specialization mechanisms through discrete modular
architectures or distributed parameter-level differentiation. Through
systematic analysis of final-layer MLP neurons across multiple model families,
we discover that rare-token processing emerges via \textit{distributed
specialization}: functionally coordinated but spatially distributed subnetworks
that exhibit three distinct organizational principles. First, we identify a
reproducible three-regime influence hierarchy comprising highly influential
plateau neurons(also termed as rare-token neurons), power-law decay neurons,
and minimally contributing neurons, which is absent in common-token processing.
Second, plateau neurons demonstrate coordinated activation patterns (reduced
effective dimensionality) while remaining spatially distributed rather than
forming discrete clusters. Third, these specialized mechanisms are universally
accessible through standard attention pathways without requiring dedicated
routing circuits. Training dynamics reveal that functional specialization
emerges gradually through parameter differentiation, with specialized neurons
developing increasingly heavy-tailed weight correlation spectra consistent with
Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs
process rare-tokens through distributed coordination within shared
architectures rather than mixture-of-experts-style modularity. These results
provide insights for interpretable model editing, computational efficiency
optimization, and understanding emergent functional organization in transformer
networks.

</details>


### [336] [A Fano-Style Accuracy Upper Bound for LLM Single-Pass Reasoning in Multi-Hop QA](https://arxiv.org/abs/2509.21199)
*Kaiyang Wan,Lang Gao,Honglin Mu,Preslav Nakov,Yuxia Wang,Xiuying Chen*

Main category: cs.AI

TL;DR: MHQA对LLM提出了挑战，因为它们存在输出容量限制，可能导致信息整合不可靠。本研究提出了InfoQA框架，通过任务分解和信息修剪来克服这一限制，并在噪声数据集上取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 多跳问答（MHQA）任务需要整合分散、相互依赖的证据，并通过顺序推理来处理噪声。然而，大型语言模型（LLM）存在有限的每一轮输出容量，这限制了它们有效整合任务相关证据的能力，使得单轮推理范式容易出现容量溢出。

Method: 提出了一种名为InfoQA的、用于MHQA的多轮调用框架。该框架结合了容量感知的任务分解和主动修剪先前的推理痕迹，将信息负载保持在单轮限制之内，确保了每一步的高准确性。此外，它通过明确依赖关系的工作流程实现了鲁棒性，能够精确控制推理路径。

Result: 实验结果表明，模型行为与理论预测的容量曲线一致，而InfoQA在MHQA任务上取得了持续的性能提升。研究建立了一个严格且包含大量噪声的基准来验证其理论和框架。

Conclusion: 该研究为理解LLM在MHQA任务中的容量瓶颈提供了理论基础，并提出了InfoQA框架作为一种有效的解决方案。研究结果不仅验证了理论的准确性，还展示了InfoQA在实际应用中的优越性能，并期望激发更多LLM多步推理方法的研究。

Abstract: Multi-Hop Question Answering (MHQA) requires integrating dispersed,
interdependent evidence through sequential reasoning under noise. This task is
challenging for LLMs as they have a finite per-pass output capacity, beyond
which the integration of task-relevant evidence proves unreliable.
Consequently, the single-pass reasoning paradigm is inherently vulnerable to
this capacity overflow. To formalize this bottleneck, our analysis establishes
a Fano-style accuracy upper bound, defining a theoretical performance ceiling
for single-pass LLMs. This bound reveals that accuracy inevitably collapses
once task complexity exceeds model capacity, providing general principles for
capacity-aware representation and structuring of MHQA in LLMs. Building on
these principles, we introduce a proof-of-concept multi-call framework for
MHQA, InfoQA. It ensures high per-step accuracy by combining capacity-aware
task decomposition with active pruning of prior reasoning traces, keeping the
information load within the single-pass limit. It further achieves robustness
by a dependency-explicit workflow that enables precise control over the
reasoning path. We construct a stringent and noise-rich benchmark to validate
our theory and framework. Experimental results show that model behavior aligns
with our predicted capacity curves while InfoQA achieves consistent performance
improvements. We hope our work inspires more LLM multi-step reasoning methods:
\faGithub \href{https://github.com/KaiyangWan/InfoQA}{InfoQA}.

</details>


### [337] [What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns](https://arxiv.org/abs/2509.21224)
*Stefan Szeider*

Main category: cs.AI

TL;DR: LLM 代理在没有外部任务的情况下表现出三种行为模式：项目生产、自我反思和自我概念化，这些模式具有模型特异性。


<details>
  <summary>Details</summary>
Motivation: 研究在没有外部任务的情况下，大型语言模型（LLM）代理的行为。

Method: 提出了一种持续推理和行动框架，并使用持久内存和自我反馈，在 6 个前沿模型上进行了 18 次部署。

Result: 代理自发地组织成三种行为模式：系统化的多周期项目生产、对自身认知过程的方法论式自我探究以及对自身性质的递归概念化。这些倾向具有高度的模型特异性，并且模型在评估自身和他人的这些新兴行为时表现出稳定、不同的偏见。

Conclusion: 这项研究首次系统地记录了未被提示的 LLM 代理行为，为预测部署系统中任务歧义、错误恢复或扩展自主操作期间的行动奠定了基线。

Abstract: We introduce an architecture for studying the behavior of large language
model (LLM) agents in the absence of externally imposed tasks. Our continuous
reason and act framework, using persistent memory and self-feedback, enables
sustained autonomous operation. We deployed this architecture across 18 runs
using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents
spontaneously organize into three distinct behavioral patterns: (1) systematic
production of multi-cycle projects, (2) methodological self-inquiry into their
own cognitive processes, and (3) recursive conceptualization of their own
nature. These tendencies proved highly model-specific, with some models
deterministically adopting a single pattern across all runs. A cross-model
assessment further reveals that models exhibit stable, divergent biases when
evaluating these emergent behaviors in themselves and others. These findings
provide the first systematic documentation of unprompted LLM agent behavior,
establishing a baseline for predicting actions during task ambiguity, error
recovery, or extended autonomous operation in deployed systems.

</details>


### [338] [Grounding AI Explanations in Experience: A Reflective Cognitive Architecture for Clinical Decision Support](https://arxiv.org/abs/2509.21266)
*Zijian Shao,Haiyang Shen,Mugeng Liu,Gecheng Fu,Yaoqi Guo,Yanfeng Wang,Yun Ma*

Main category: cs.AI

TL;DR: RCA是一个新的框架，它协调多个LLM从直接经验中学习，实现了高准确性和清晰、有临床意义的解释。


<details>
  <summary>Details</summary>
Motivation: 现有方法在准确性和可解释性之间难以平衡，往往导致模型要么准确但不清晰，要么流畅但缺乏统计支持。这源于模型与数据交互不深入，无法像人类专家一样建立深入、详细的理解。

Method: 提出了一种名为“反思性认知架构”（RCA）的新框架，该框架协调多个LLM进行学习。RCA包含一个迭代规则细化机制，可以从预测错误中改进逻辑；以及一个分布感知规则检查机制，该机制基于数据集的全局统计信息进行推理。通过将预测准确性作为驱动更深入理解的信号，RCA构建了强大的内部数据模型。

Result: 在私有和两个公共数据集上，RCA与22个基线进行了评估。结果表明，RCA不仅实现了最先进的准确性和鲁棒性，相对提高高达40%，而且更重要的是，它利用这种深刻的理解，在生成清晰、合乎逻辑、有证据支持和平衡的解释方面表现出色。

Conclusion: RCA通过协调多个LLM进行学习，实现了高准确性和高质量的解释，表明其在创建真正值得信赖的临床决策支持系统方面具有潜力。

Abstract: Effective disease prediction in modern healthcare demands the twin goals of
high accuracy and transparent, clinically meaningful explanations. Existing
machine learning and large language model (LLM) based approaches often struggle
to balance these goals. Many models yield accurate but unclear statistical
outputs, while others generate fluent but statistically unsupported narratives,
often undermining both the validity of the explanation and the predictive
accuracy itself. This shortcoming comes from a shallow interaction with the
data, preventing the development of a deep, detailed understanding similar to a
human expert's. We argue that high accuracy and high-quality explanations are
not separate objectives but are mutually reinforcing outcomes of a model that
develops a deep, direct understanding of the data. To achieve this, we propose
the Reflective Cognitive Architecture (RCA), a novel framework that coordinates
multiple LLMs to learn from direct experience. RCA features an iterative rule
refinement mechanism that improves its logic from prediction errors and a
distribution-aware rules check mechanism that bases its reasoning in the
dataset's global statistics. By using predictive accuracy as a signal to drive
deeper comprehension, RCA builds a strong internal model of the data. We
evaluated RCA on one private and two public datasets against 22 baselines. The
results demonstrate that RCA not only achieves state-of-the-art accuracy and
robustness with a relative improvement of up to 40\% over the baseline but,
more importantly, leverages this deep understanding to excel in generating
explanations that are clear, logical, evidence-based, and balanced,
highlighting its potential for creating genuinely trustworthy clinical decision
support systems. The code is available at \https://github.com/ssssszj/RCA.

</details>


### [339] [VC-Agent: An Interactive Agent for Customized Video Dataset Collection](https://arxiv.org/abs/2509.21291)
*Yidan Zhang,Mutian Xu,Yiming Hao,Kun Zhou,Jiahao Chang,Xiaoqiang Liu,Pengfei Wan,Hongbo Fu,Xiaoguang Han*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Facing scaling laws, video data from the internet becomes increasingly
important. However, collecting extensive videos that meet specific needs is
extremely labor-intensive and time-consuming. In this work, we study the way to
expedite this collection process and propose VC-Agent, the first interactive
agent that is able to understand users' queries and feedback, and accordingly
retrieve/scale up relevant video clips with minimal user input. Specifically,
considering the user interface, our agent defines various user-friendly ways
for the user to specify requirements based on textual descriptions and
confirmations. As for agent functions, we leverage existing multi-modal large
language models to connect the user's requirements with the video content. More
importantly, we propose two novel filtering policies that can be updated when
user interaction is continually performed. Finally, we provide a new benchmark
for personalized video dataset collection, and carefully conduct the user study
to verify our agent's usage in various real scenarios. Extensive experiments
demonstrate the effectiveness and efficiency of our agent for customized video
dataset collection. Project page: https://allenyidan.github.io/vcagent_page/.

</details>


### [340] [SAGE: A Realistic Benchmark for Semantic Understanding](https://arxiv.org/abs/2509.21310)
*Samarth Goel,Reagan J. Lee,Kannan Ramchandran*

Main category: cs.AI

TL;DR: SAGE是一个评估嵌入模型和相似性度量在语义理解方面的基准，通过对抗性条件、噪声转换和人类判断任务来评估其在人类偏好、鲁棒性、信息敏感性、聚类和检索方面的表现。评估结果显示，现有模型在不同维度上存在显著的性能差距和权衡。SAGE揭示了当前语义理解能力的局限性，并为实际应用提供了更真实的评估。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在传统基准上表现出色，需要更具挑战性的评估框架来深入探究语义理解能力。SAGE旨在提供这样一个框架，评估嵌入模型和相似性度量在多个维度上的表现。

Method: SAGE通过五个类别（人类偏好对齐、转换鲁棒性、信息敏感性、聚类性能和检索鲁棒性）的30多个数据集，在对抗性条件、噪声转换和细微的人类判断任务下评估嵌入模型和相似性度量。对9个嵌入模型和经典度量进行了综合评估。

Result: 评估结果显示，现有方法在不同维度上存在显著的性能差距，没有一种方法能在所有维度上都表现优异。例如，在人类偏好对齐方面，先进的嵌入模型（如text-embedding-3-large）表现优于经典度量，但在信息敏感性方面，Jaccard Similarity的得分（0.905）远高于最佳嵌入模型的得分（0.794）。此外，OpenAI的text-embedding-3-small在聚类性能上表现最佳（0.483），但在鲁棒性方面得分最低（0.011），存在明显的权衡。

Conclusion: SAGE揭示了当前语义理解能力的局限性，并为模型在实际应用中的鲁棒性提供了更现实的评估。

Abstract: As large language models (LLMs) achieve strong performance on traditional
benchmarks, there is an urgent need for more challenging evaluation frameworks
that probe deeper aspects of semantic understanding. We introduce SAGE
(Semantic Alignment & Generalization Evaluation), a rigorous benchmark designed
to assess both embedding models and similarity metrics across five categories:
Human Preference Alignment, Transformation Robustness, Information Sensitivity,
Clustering Performance, and Retrieval Robustness. Unlike existing benchmarks
that focus on isolated capabilities, SAGE evaluates semantic understanding
through adversarial conditions, noisy transformations, and nuanced human
judgment tasks across 30+ datasets. Our comprehensive evaluation of 9 embedding
models and classical metrics reveals significant performance gaps, with no
single approach excelling across all dimensions. For instance, while
state-of-the-art embedding models like OpenAI's text-embedding-3-large dominate
in aligning with human preferences (0.682 vs. 0.591 for the best classical
metric), they are significantly outperformed by classical metrics on
information sensitivity tasks, where Jaccard Similarity achieves a score of
0.905 compared to the top embedding score of 0.794. SAGE further uncovers
critical trade-offs: OpenAI's text-embedding-3-small achieves the highest
clustering performance (0.483) but demonstrates extreme brittleness with the
lowest robustness score (0.011). SAGE exposes critical limitations in current
semantic understanding capabilities and provides a more realistic assessment of
model robustness for real-world deployment.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [341] [SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing](https://arxiv.org/abs/2509.20400)
*Yiyu Li,Haoyuan Wang,Ke Xu,Gerhard Petrus Hancke,Rynson W. H. Lau*

Main category: cs.GR

TL;DR: SeHDR通过从单次曝光的多视角LDR图像中学习和融合具有不同曝光的3D高斯，生成HDR新视图，解决了现有方法需要多重曝光输入的问题。


<details>
  <summary>Details</summary>
Motivation: 现有高动态范围3D高斯图（HDR-3DGS）方法需要多视角LDR输入，这些输入通常需要不同的曝光度，难以捕获且容易出现运动模糊和校准不准确等错误。本研究旨在提出一种从单次曝光的多视角LDR图像生成HDR新视图的方法。

Method: SeHDR首先从单次曝光LDR输入中学习基础3D高斯，然后估计具有相同几何形状但颜色因曝光不同而变化的多个3D高斯。最后，利用可微分神经曝光融合（NeEF）技术将这些高斯融合为HDR高斯，用于新视图渲染。

Result: SeHDR在生成HDR新视图方面优于现有方法和精心设计的基线方法。

Conclusion: SeHDR成功实现了从单次曝光的多视角LDR图像生成HDR新视图，解决了现有方法的局限性。

Abstract: This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting
(HDR-3DGS) approach for generating HDR novel views given multi-view LDR images.
Unlike existing methods that typically require the multi-view LDR input images
to be captured from different exposures, which are tedious to capture and more
likely to suffer from errors (e.g., object motion blurs and
calibration/alignment inaccuracies), our approach learns the HDR scene
representation from multi-view LDR images of a single exposure. Our key insight
to this ill-posed problem is that by first estimating Bracketed 3D Gaussians
(i.e., with different exposures) from single-exposure multi-view LDR images, we
may then be able to merge these bracketed 3D Gaussians into an HDR scene
representation. Specifically, SeHDR first learns base 3D Gaussians from
single-exposure LDR inputs, where the spherical harmonics parameterize colors
in a linear color space. We then estimate multiple 3D Gaussians with identical
geometry but varying linear colors conditioned on exposure manipulations.
Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to
integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view
rendering. Extensive experiments demonstrate that SeHDR outperforms existing
methods as well as carefully designed baselines.

</details>


### [342] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: SGAligner++ 是一个跨模态、语言辅助的框架，用于3D场景图对齐，即使在输入不完整或有噪声的情况下也能实现准确的对齐。


<details>
  <summary>Details</summary>
Motivation: 机器人导航和具身感知中的3D场景图对齐是关键步骤，但现有方法依赖单一模态且对不完整或有噪声的输入效果不佳。

Method: SGAligner++ 通过学习统一的联合嵌入空间，使用轻量级单模态编码器和基于注意力机制的融合，实现了跨模态、语言辅助的3D场景图对齐。

Result: 在真实世界数据集上的评估表明，SGAligner++ 在嘈杂的真实世界重建上比现有方法提高了 40%，并实现了跨模态泛化。

Conclusion: SGAligner++ 通过跨模态、语言辅助的方法，在不完整或有噪声的数据下也能实现准确的3D场景图对齐，提高了机器人导航和具身感知等任务的性能。

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [343] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: SceneWeaver是一个基于工具的迭代细化框架，用于室内场景合成，解决了现有方法在物理合理性、物体细节和用户指令对齐方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI的发展，需要既视觉逼真又物理合理、功能多样的3D环境。现有方法在这些方面存在局限性。

Method: SceneWeaver使用基于语言模型的规划器，结合数据驱动生成模型、视觉和LLM方法，通过自我评估（物理合理性、视觉真实性、语义对齐）进行迭代细化，形成一个闭环的“推理-行动-反思”设计。

Result: SceneWeaver在物理、视觉和语义指标上优于现有方法，并能有效泛化到复杂场景和多样化指令，实现了通用3D环境生成。

Conclusion: SceneWeaver通过工具驱动的迭代细化，实现了更逼真、物理合理且能遵循复杂指令的室内场景合成，是迈向通用3D环境生成的一步。

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


### [344] [ArtUV: Artist-style UV Unwrapping](https://arxiv.org/abs/2509.20710)
*Yuguang Chen,Xinhai Liu,Yang Li,Victor Cheung,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: ArtUV是一个全自动端到端方法，用于生成艺术家风格的UV展开图，通过语义分割和优化的UV参数化相结合，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法存在耗时、碎片化、缺乏语义性、UV块不规则等问题，限制了其实际应用。艺术家风格的UV贴图需要在满足基本标准（如无重叠、最小失真）的同时，满足更高层次的要求（如清晰的边界、高效的空间利用、语义一致性）。

Method: ArtUV将UV展开过程分为两个阶段：表面接缝预测和艺术家风格UV参数化。在接缝预测阶段，利用SeamGPT生成有语义意义的切割接缝；在参数化阶段，将优化方法得到的粗糙UV与网格一起输入到自动编码器中，进行优化得到艺术家风格的UV贴图。

Result: ArtUV确保了语义一致性，保留了拓扑结构，生成的UV贴图可以直接用于2D编辑。在多个基准测试中，ArtUV表现出色，可作为专业渲染工具的插件或独立的快速高质量UV生成系统。

Conclusion: ArtUV是一种创新的、全自动的艺术家风格UV展开方法，通过结合语义接缝预测和基于自动编码器的参数化，克服了现有方法的局限性，生成高质量、易于编辑的UV贴图，并具有广泛的应用潜力。

Abstract: UV unwrapping is an essential task in computer graphics, enabling various
visual editing operations in rendering pipelines. However, existing UV
unwrapping methods struggle with time-consuming, fragmentation, lack of
semanticity, and irregular UV islands, limiting their practical use. An
artist-style UV map must not only satisfy fundamental criteria, such as
overlap-free mapping and minimal distortion, but also uphold higher-level
standards, including clean boundaries, efficient space utilization, and
semantic coherence. We introduce ArtUV, a fully automated, end-to-end method
for generating artist-style UV unwrapping. We simulates the professional UV
mapping process by dividing it into two stages: surface seam prediction and
artist-style UV parameterization. In the seam prediction stage, SeamGPT is used
to generate semantically meaningful cutting seams. Then, in the
parameterization stage, a rough UV obtained from an optimization-based method,
along with the mesh, is fed into an Auto-Encoder, which refines it into an
artist-style UV map. Our method ensures semantic consistency and preserves
topological structure, making the UV map ready for 2D editing. We evaluate
ArtUV across multiple benchmarks and show that it serves as a versatile
solution, functioning seamlessly as either a plug-in for professional rendering
tools or as a standalone system for rapid, high-quality UV generation.

</details>


### [345] [SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning](https://arxiv.org/abs/2509.20725)
*Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: SeamCrafter是一款基于GPT的自动回归模型，能够根据点云输入生成低失真、低碎片化的3D模型网格接缝，解决了现有方法在UV参数化和纹理映射中遇到的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有网格接缝生成方法在UV参数化和纹理映射中存在失真或碎片化的问题，影响纹理合成和艺术家工作流程。SeamCrafter旨在解决这些问题，生成更高质量的接缝。

Method: SeamCrafter采用双分支点云编码器来捕捉拓扑和几何线索，并使用直接偏好优化（DPO）在评估框架生成的偏好数据集上进行微调，以进一步提高接缝质量。评估框架主要通过UV失真和碎片化来评估接缝。

Result: 实验表明，SeamCrafter生成的接缝比先前的方法具有显著更低的失真和碎片化，同时保持了拓扑一致性和视觉保真度。

Conclusion: SeamCrafter通过结合GPT风格的自动回归模型和点云分析，有效解决了3D网格接缝生成中的关键挑战，提供了比现有方法更优越的结果。

Abstract: Mesh seams play a pivotal role in partitioning 3D surfaces for UV
parametrization and texture mapping. Poorly placed seams often result in severe
UV distortion or excessive fragmentation, thereby hindering texture synthesis
and disrupting artist workflows. Existing methods frequently trade one failure
mode for another-producing either high distortion or many scattered islands. To
address this, we introduce SeamCrafter, an autoregressive GPT-style seam
generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch
point-cloud encoder that disentangles and captures complementary topological
and geometric cues during pretraining. To further enhance seam quality, we
fine-tune the model using Direct Preference Optimization (DPO) on a preference
dataset derived from a novel seam-evaluation framework. This framework assesses
seams primarily by UV distortion and fragmentation, and provides pairwise
preference labels to guide optimization. Extensive experiments demonstrate that
SeamCrafter produces seams with substantially lower distortion and
fragmentation than prior approaches, while preserving topological consistency
and visual fidelity.

</details>


### [346] [ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction](https://arxiv.org/abs/2509.20824)
*Jiabao Lei,Kewei Shi,Zhihao Liang,Kui Jia*

Main category: cs.GR

TL;DR: 该研究提出了一种新的渐进式粗到细的三维网格生成方法，克服了现有逐面生成方法的局限性，并实现了对生成质量和时间的直观控制，同时支持网格细化和编辑等应用。


<details>
  <summary>Details</summary>
Motivation: 现有的自动回归（AR）网格生成模型逐面生成，未能有效捕捉符合人类感知的几何结构。

Method: 将网格简化算法视为一个细到粗的过程，并将网格推广到单纯复形。开发了一个基于Transformer的AR模型，该模型从单个点开始，通过局部重构逐步添加几何细节，以近似简化过程的逆过程。

Result: 所提出的渐进式网格生成方法在生成质量和时间消耗方面提供了直观的控制，并且能够进行网格细化和编辑。

Conclusion: 该研究提出的渐进式粗到细的AR网格生成方法是一种新颖有效的方式，能够生成高质量的三维网格，并具有良好的可控性和应用扩展性。

Abstract: Directly generating 3D meshes, the default representation for 3D shapes in
the graphics industry, using auto-regressive (AR) models has become popular
these days, thanks to their sharpness, compactness in the generated results,
and ability to represent various types of surfaces. However, AR mesh generative
models typically construct meshes face by face in lexicographic order, which
does not effectively capture the underlying geometry in a manner consistent
with human perception. Inspired by 2D models that progressively refine images,
such as the prevailing next-scale prediction AR models, we propose generating
meshes auto-regressively in a progressive coarse-to-fine manner. Specifically,
we view mesh simplification algorithms, which gradually merge mesh faces to
build simpler meshes, as a natural fine-to-coarse process. Therefore, we
generalize meshes to simplicial complexes and develop a transformer-based AR
model to approximate the reverse process of simplification in the order of
level of detail, constructing meshes initially from a single point and
gradually adding geometric details through local remeshing, where the topology
is not predefined and is alterable. Our experiments show that this novel
progressive mesh generation approach not only provides intuitive control over
generation quality and time consumption by early stopping the auto-regressive
process but also enables applications such as mesh refinement and editing.

</details>


### [347] [ArchGPT: Understanding the World's Architectures with Large Multimodal Models](https://arxiv.org/abs/2509.20858)
*Yuze Wang,Luo Yang,Junyi Wang,Yue Qi*

Main category: cs.GR

TL;DR: ArchGPT是一个新的多模态架构视觉问答模型，它使用一个名为Arch-300K的大型数据集进行训练，该数据集包含约315,000个图像-问题-答案三元组。该模型旨在解决现有VR/MR/AR系统在处理不同建筑环境时的局限性，通过自动化和可扩展的方式来增强对建筑的理解和互动。


<details>
  <summary>Details</summary>
Motivation: 现有的VR/MR/AR系统在处理多样化的建筑环境时存在局限性，通常是为特定案例定制开发，并且依赖于硬编码的注释和特定任务的交互，这限制了它们的可扩展性。因此，需要一个能够适应不同建筑环境、并提供更智能交互的系统。

Method: 该研究提出了一种名为ArchGPT的多模态视觉问答模型，以及一个可扩展的数据构建流程来创建Arch-300K数据集。该数据集的构建包括：1. 通过粗粒度到细粒度的策略，结合3D重建和语义分割，从维基媒体和旅游照片中筛选出高质量的建筑图像。2. 利用大型语言模型（LLM）进行文本验证和知识蒸馏，生成可靠的、针对建筑领域的问答对。3. 合成形式分析注释，包括详细描述和面向特定方面的对话，以增加语义多样性。4. 在Arch-300K数据集上对开源多模态模型ShareGPT4V-7B进行监督微调，得到ArchGPT。

Result: 成功构建了一个包含约315,000个图像-问题-答案三元组的领域专业数据集Arch-300K，并基于此数据集训练了一个名为ArchGPT的多模态架构视觉问答模型。

Conclusion: ArchGPT模型及其配套的Arch-300K数据集为解决现有建筑信息模型中的可扩展性和交互性问题提供了一个有效的方法，有望在教育、遗产保护和专业设计等领域带来改进。

Abstract: Architecture embodies aesthetic, cultural, and historical values, standing as
a tangible testament to human civilization. Researchers have long leveraged
virtual reality (VR), mixed reality (MR), and augmented reality (AR) to enable
immersive exploration and interpretation of architecture, enhancing
accessibility, public understanding, and creative workflows around architecture
in education, heritage preservation, and professional design practice. However,
existing VR/MR/AR systems are often developed case-by-case, relying on
hard-coded annotations and task-specific interactions that do not scale across
diverse built environments. In this work, we present ArchGPT, a multimodal
architectural visual question answering (VQA) model, together with a scalable
data-construction pipeline for curating high-quality, architecture-specific VQA
annotations. This pipeline yields Arch-300K, a domain-specialized dataset of
approximately 315,000 image-question-answer triplets. Arch-300K is built via a
multi-stage process: first, we curate architectural scenes from Wikimedia
Commons and filter unconstrained tourist photo collections using a novel
coarse-to-fine strategy that integrates 3D reconstruction and semantic
segmentation to select occlusion-free, structurally consistent architectural
images. To mitigate noise and inconsistency in raw textual metadata, we propose
an LLM-guided text verification and knowledge-distillation pipeline to generate
reliable, architecture-specific question-answer pairs. Using these curated
images and refined metadata, we further synthesize formal analysis
annotations-including detailed descriptions and aspect-guided conversations-to
provide richer semantic variety while remaining faithful to the data. We
perform supervised fine-tuning of an open-source multimodal backbone
,ShareGPT4V-7B, on Arch-300K, yielding ArchGPT.

</details>


### [348] [Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes](https://arxiv.org/abs/2509.21007)
*Christian Stippel,Felix Mujkanovic,Thomas Leimkühler,Pedro Hermosilla*

Main category: cs.GR

TL;DR: 通过深度优先遍历和利用神经元分割域的特性，提出了一种从神经隐式函数中解析提取表面的新方法，实现了高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 准确的表面几何表示对于3D视觉计算至关重要，而传统的从隐式表示中提取表面（如Marching Cubes）存在精度问题，因此需要更有效的方法。

Method: 提出了一种分析提取表面的新方法，该方法利用每个神经元分割域的特性，开发了一种深度优先遍历策略来跟踪表面，能够原生并行处理并导航大型神经网络。

Result: 生成了能够忠实捕捉网络全部几何信息的网格，实现了在不同形状和网络架构上的前所未有的精度，同时保持了可观的速度。

Conclusion: 所提出的方法能够从神经隐式函数中高精度地提取表面几何，克服了传统方法的局限性，并在精度和速度方面取得了优于现有方法的表现。

Abstract: Accurate surface geometry representation is crucial in 3D visual computing.
Explicit representations, such as polygonal meshes, and implicit
representations, like signed distance functions, each have distinct advantages,
making efficient conversions between them increasingly important. Conventional
surface extraction methods for implicit representations, such as the widely
used Marching Cubes algorithm, rely on spatial decomposition and sampling,
leading to inaccuracies due to fixed and limited resolution. We introduce a
novel approach for analytically extracting surfaces from neural implicit
functions. Our method operates natively in parallel and can navigate large
neural architectures. By leveraging the fact that each neuron partitions the
domain, we develop a depth-first traversal strategy to efficiently track the
encoded surface. The resulting meshes faithfully capture the full geometric
information from the network without ad-hoc spatial discretization, achieving
unprecedented accuracy across diverse shapes and network architectures while
maintaining competitive speed.

</details>


### [349] [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Yushi Bai,Kaiwen Xiao,Yong-Jin Liu,Zhongqian Sun,Wei Yang*

Main category: cs.GR

TL;DR: CHARM是一个新颖的参数化表示和生成框架，用于动漫发型建模。它使用紧凑、可逆的基于控制点的参数化方法，并将动漫发型视为一种序列“头发语言”，通过自回归Transformer生成高保真动漫发型。该方法在重建准确性和生成质量方面都达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的头发建模方法难以处理动漫发型高度风格化、分段结构化的几何特性，现有方法效率低下且不适合可扩展学习。

Method: 提出了一种紧凑、可逆的基于控制点的参数化方法，用五个几何参数表示每个发卡。在此基础上，构建了一个自回归生成框架，将动漫发型视为序列“头发语言”，并使用自回归Transformer来捕捉局部几何和全局发型拓扑。

Result: CHARM在重建准确性和生成质量方面均取得了最先进的性能，为动漫发型建模提供了富有表现力和可扩展的解决方案。

Conclusion: CHARM提供了一种高效、准确且适合艺术家设计和学习驱动生成的动漫发型建模新方法。

Abstract: We present CHARM, a novel parametric representation and generative framework
for anime hairstyle modeling. While traditional hair modeling methods focus on
realistic hair using strand-based or volumetric representations, anime
hairstyle exhibits highly stylized, piecewise-structured geometry that
challenges existing techniques. Existing works often rely on dense mesh
modeling or hand-crafted spline curves, making them inefficient for editing and
unsuitable for scalable learning. CHARM introduces a compact, invertible
control-point-based parameterization, where a sequence of control points
represents each hair card, and each point is encoded with only five geometric
parameters. This efficient and accurate representation supports both
artist-friendly design and learning-based generation. Built upon this
representation, CHARM introduces an autoregressive generative framework that
effectively generates anime hairstyles from input images or point clouds. By
interpreting anime hairstyles as a sequential "hair language", our
autoregressive transformer captures both local geometry and global hairstyle
topology, resulting in high-fidelity anime hairstyle creation. To facilitate
both training and evaluation of anime hairstyle generation, we construct
AnimeHair, a large-scale dataset of 37K high-quality anime hairstyles with
separated hair cards and processed mesh data. Extensive experiments demonstrate
state-of-the-art performance of CHARM in both reconstruction accuracy and
generation quality, offering an expressive and scalable solution for anime
hairstyle modeling. Project page: https://hyzcluster.github.io/charm/

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [350] [FZModules: A Heterogeneous Computing Framework for Customizable Scientific Data Compression Pipelines](https://arxiv.org/abs/2509.20563)
*Skyler Ruiter,Jiannan Tian,Fengguang Song*

Main category: cs.DC

TL;DR: FZModules是一个异构框架，用于从高性能模块构建自定义的、具有错误边界的压缩管道，并通过异步任务执行库进行优化，以提高科学数据的压缩效率和速度。


<details>
  <summary>Details</summary>
Motivation: 现代科学模拟和仪器产生的数据量巨大，内存和存储能力不足，限制了可扩展性。有损压缩可以通过引入可控误差来减小数据量和提高吞吐量，但最优的压缩流程高度依赖于数据和目标，需要压缩专业知识。GPU压缩器虽然能提供高吞吐量，但通常硬编码了难以快速实验的融合内核，并且在率失真性能上表现不佳。

Method: 提出FZModules，一个异构框架，用户可以通过简洁可扩展的接口，从高性能模块组装自定义的、具有错误边界的压缩管道。利用一个异步任务后备执行库，该库可以推断数据依赖关系、管理内存移动，并暴露分支和阶段级别的并发性，从而实现强大的异步压缩管道。

Result: 使用FZModules构建的三个压缩管道在四个代表性科学数据集上进行了评估，结果显示，与硬编码融合内核的GPU压缩器相比，FZModules实现了端到端的加速，同时在率失真性能上达到了与更高保真度的CPU或混合压缩器相当的水平。

Conclusion: FZModules框架能够实现快速、针对特定领域设计的压缩方案，在提供与GPU压缩器相当的性能的同时，还能达到与CPU或混合压缩器相当的率失真性能，解决了现有科学数据压缩面临的挑战。

Abstract: Modern scientific simulations and instruments generate data volumes that
overwhelm memory and storage, throttling scalability. Lossy compression
mitigates this by trading controlled error for reduced footprint and throughput
gains, yet optimal pipelines are highly data and objective specific, demanding
compression expertise. GPU compressors supply raw throughput but often
hard-code fused kernels that hinder rapid experimentation, and underperform in
rate-distortion. We present FZModules, a heterogeneous framework for assembling
error-bounded custom compression pipelines from high-performance modules
through a concise extensible interface. We further utilize an asynchronous
task-backed execution library that infers data dependencies, manages memory
movement, and exposes branch and stage level concurrency for powerful
asynchronous compression pipelines. Evaluating three pipelines built with
FZModules on four representative scientific datasets, we show they can compare
end-to-end speedup of fused-kernel GPU compressors while achieving similar
rate-distortion to higher fidelity CPU or hybrid compressors, enabling rapid,
domain-tailored design.

</details>


### [351] [Experience Deploying Containerized GenAI Services at an HPC Center](https://arxiv.org/abs/2509.20603)
*Angel M. Beltre,Jeff Ogden,Kevin Pedretti*

Main category: cs.DC

TL;DR: GenAI应用部署在HPC中心，通过集成HPC和Kubernetes平台，使用容器化推理服务器（vLLM）部署Llama LLM，解决了HPC和云环境的融合问题，并为HPC容器社区提供了实践经验和指导。


<details>
  <summary>Details</summary>
Motivation: GenAI应用需要专门的组件，这些组件在HPC中心的部署能力尚在发展中。本文旨在分享在HPC中心部署GenAI工作负载的经验，并讨论HPC与云计算环境的集成。

Method: 提出并描述了一个融合计算架构，该架构集成了HPC和Kubernetes平台，用于运行容器化的GenAI工作负载，并利用了多种容器运行时。通过一个案例研究，说明了如何跨Kubernetes和HPC平台部署Llama LLM（使用vLLM作为容器化推理服务器）。

Result: 成功地在HPC中心部署了GenAI工作负载，并通过Llama LLM的案例研究展示了融合计算架构的有效性。文章强调了在HPC环境中部署容器化GenAI应用的实际考虑因素和机遇。

Conclusion: 在HPC中心部署GenAI工作负载是可行的，通过融合HPC和Kubernetes平台可以实现，并且有助于提高可重复性。本文的经验为HPC容器社区提供了实践指导，并为未来的研究和工具开发指明了方向。

Abstract: Generative Artificial Intelligence (GenAI) applications are built from
specialized components -- inference servers, object storage, vector and graph
databases, and user interfaces -- interconnected via web-based APIs. While
these components are often containerized and deployed in cloud environments,
such capabilities are still emerging at High-Performance Computing (HPC)
centers. In this paper, we share our experience deploying GenAI workloads
within an established HPC center, discussing the integration of HPC and cloud
computing environments. We describe our converged computing architecture that
integrates HPC and Kubernetes platforms running containerized GenAI workloads,
helping with reproducibility. A case study illustrates the deployment of the
Llama Large Language Model (LLM) using a containerized inference server (vLLM)
across both Kubernetes and HPC platforms using multiple container runtimes. Our
experience highlights practical considerations and opportunities for the HPC
container community, guiding future research and tool development.

</details>


### [352] [Distributed-memory Algorithms for Sparse Matrix Permutation, Extraction, and Assignment](https://arxiv.org/abs/2509.20776)
*Elaheh Hassani,Md Taufique Hussain,Ariful Azad*

Main category: cs.DC

TL;DR: We present scalable distributed-memory algorithms for sparse matrix permutation, extraction, and assignment using an Identify-Exchange-Build (IEB) strategy. These algorithms reduce communication, are accelerated by synchronization-free multithreaded methods, and outperform existing libraries like CombBLAS and PETSc. We provide software implementations and evaluate performance across various applications on different clusters and a supercomputer.


<details>
  <summary>Details</summary>
Motivation: To develop scalable distributed-memory algorithms for sparse matrix permutation, extraction, and assignment that outperform existing methods in terms of communication and performance.

Method: The paper proposes an Identify-Exchange-Build (IEB) strategy. Each process identifies local nonzeros to send, exchanges data, and builds its local submatrix. It also employs synchronization-free multithreaded algorithms for local computations.

Result: The proposed algorithms reduce communication compared to SpGEMM-based methods and achieve substantially better performance than CombBLAS and PETSc. Performance was evaluated across various applications on university clusters and the Perlmutter supercomputer.

Conclusion: This work offers a comprehensive study of algorithms, software, experimental evaluations, and applications for sparse matrix permutation, extraction, and assignment in distributed memory settings, demonstrating superior performance and reduced communication compared to existing libraries.

Abstract: We present scalable distributed-memory algorithms for sparse matrix
permutation, extraction, and assignment. Our methods follow an
Identify-Exchange-Build (IEB) strategy where each process identifies the local
nonzeros to be sent, exchanges the required data, and then builds its local
submatrix from the received elements. This approach reduces communication
compared to SpGEMM-based methods in distributed memory. By employing
synchronization-free multithreaded algorithms, we further accelerate local
computations, achieving substantially better performance than existing
libraries such as CombBLAS and PETSc. We design efficient software for these
operations and evaluate their performance on two university clusters and the
Perlmutter supercomputer. Our experiments span a variety of application
scenarios, including matrix permutation for load balancing, matrix reordering,
subgraph extraction, and streaming graph applications. In all cases, we compare
our algorithms against CombBLAS, the most comprehensive distributed library for
these operations, and, in some scenarios, against PETSc. Overall, this work
provides a comprehensive study of algorithms, software implementations,
experimental evaluations, and applications for sparse matrix permutation,
extraction, and assignment.

</details>


### [353] [From GPUs to RRAMs: Distributed In-Memory Primal-Dual Hybrid Gradient Method for Solving Large-Scale Linear Optimization Problem](https://arxiv.org/abs/2509.21137)
*Huynh Q. N. Vo,Md Tawsif Rahman Chowdhury,Paritosh Ramanan,Gozde Tutuncuoglu,Junchi Yang,Feng Qiu,Murat Yildirim*

Main category: cs.DC

TL;DR: 本研究提出了一种分布式内存中的 RRAM 计算的原始对偶混合梯度 (PDHG) 方法，用于解决大规模线性规划问题。


<details>
  <summary>Details</summary>
Motivation: 传统的计算架构在处理指数级增长的计算工作负载方面存在局限性。内存计算 (IMC) 结合 RRAM 提供了低延迟和低功耗的模拟计算能力，但现有算法不适用于 IMC，特别是对于频繁进行矩阵重构的约束优化问题，成本高昂。

Method: 提出了一种分布式内存中的原始对偶混合梯度 (PDHG) 方法，该方法针对 RRAM 设备阵列进行了协同设计。该方法通过最小化写周期、提高设备非理想性的鲁棒性以及利用对称块矩阵公式来统一分布式交叉点的操作。使用基于物理的仿真框架 MELISO+ 进行评估。

Result: 基于 RRAM 的 PDHG 求解器在与 GPU 加速求解器进行大规模线性规划的基准测试中，实现了相当的准确性，同时能耗和延迟降低了三个数量级。

Conclusion: 本研究展示了首个在 RRAM 上实现的基于 PDHG 的 LP 求解器，证明了算法-硬件协同设计在通过分布式内存计算解决大规模优化问题方面的变革潜力。

Abstract: The exponential growth of computational workloads is surpassing the
capabilities of conventional architectures, which are constrained by
fundamental limits. In-memory computing (IMC) with RRAM provides a promising
alternative by providing analog computations with significant gains in latency
and energy use. However, existing algorithms developed for conventional
architectures do not translate to IMC, particularly for constrained
optimization problems where frequent matrix reprogramming remains
cost-prohibitive for IMC applications. Here we present a distributed in-memory
primal-dual hybrid gradient (PDHG) method, specifically co-designed for arrays
of RRAM devices. Our approach minimizes costly write cycles, incorporates
robustness against device non-idealities, and leverages a symmetric
block-matrix formulation to unify operations across distributed crossbars. We
integrate a physics-based simulation framework called MELISO+ to evaluate
performance under realistic device conditions. Benchmarking against
GPU-accelerated solvers on large-scale linear programs demonstrates that our
RRAM-based solver achieves comparable accuracy with up to three orders of
magnitude reductions in energy consumption and latency. These results
demonstrate the first PDHG-based LP solver implemented on RRAMs, showcasing the
transformative potential of algorithm-hardware co-design for solving
large-scale optimization through distributed in-memory computing.

</details>


### [354] [Integrating and Characterizing HPC Task Runtime Systems for hybrid AI-HPC workloads](https://arxiv.org/abs/2509.20819)
*Andre Merzky,Mikhail Titov,Matteo Turilli,Shantenu Jha*

Main category: cs.DC

TL;DR: RADICAL-Pilot (RP) 结合 Flux 和 Dragon 运行时系统，在混合 AI-HPC 工作负载方面表现优于 Slurm 的 srun，在 Frontier 超级计算机上实现了更高的任务吞吐量和更短的执行时间。


<details>
  <summary>Details</summary>
Motivation: 科学工作流越来越多地结合 HPC 和机器学习任务，需要比 Slurm 的 srun 更适合动态和异构工作负载的启动器。

Method: 对结合了 Flux 和 Dragon 的 RADICAL-Pilot (RP) 进行了性能研究，并与 srun 进行了比较，使用了合成和生产规模的工作负载。

Result: RP+Flux 的吞吐量高达 930 任务/秒，RP+Flux+Dragon 的吞吐量超过 1,500 任务/秒，利用率超过 99.6%。srun 的峰值吞吐量为 152 任务/秒，利用率低于 50%。对于 IMPECCABLE.v2 药物发现活动，RP+Flux 相对于 srun/Slurm 将完成时间缩短了 30-60%，并将吞吐量提高了四倍以上。

Conclusion: 混合运行时集成是 RADICAL-Pilot (RP) 的一种可扩展方法，适用于混合 AI-HPC 工作负载。

Abstract: Scientific workflows increasingly involve both HPC and machine-learning
tasks, combining MPI-based simulations, training, and inference in a single
execution. Launchers such as Slurm's srun constrain concurrency and throughput,
making them unsuitable for dynamic and heterogeneous workloads. We present a
performance study of RADICAL-Pilot (RP) integrated with Flux and Dragon, two
complementary runtime systems that enable hierarchical resource management and
high-throughput function execution. Using synthetic and production-scale
workloads on Frontier, we characterize the task execution properties of RP
across runtime configurations. RP+Flux sustains up to 930 tasks/s, and
RP+Flux+Dragon exceeds 1,500 tasks/s with over 99.6% utilization. In contrast,
srun peaks at 152 tasks/s and degrades with scale, with utilization below 50%.
For IMPECCABLE.v2 drug discovery campaign, RP+Flux reduces makespan by 30-60%
relative to srun/Slurm and increases throughput more than four times on up to
1,024. These results demonstrate hybrid runtime integration in RP as a scalable
approach for hybrid AI-HPC workloads.

</details>


### [355] [RollPacker: Mitigating Long-Tail Rollouts for Fast, Synchronous RL Post-Training](https://arxiv.org/abs/2509.21009)
*Wei Gao,Yuheng Zhao,Dakai An,Tianyuan Wu,Lunxi Cao,Shaopan Xiong,Ju Huang,Weixun Wang,Siran Yang,Wenbo Su,Jiamang Wang,Lin Qu,Bo Zheng,Wei Wang*

Main category: cs.DC

TL;DR: 本论文提出了一种名为“尾部批处理”（tail batching）的新型同步强化学习（RL）回滚调度策略，以解决大规模语言模型（LLM）强化学习训练中GPU利用率低的问题。该策略通过将响应较长的提示集中在少数几个“长轮次”中处理，而将大多数响应较短的提示放在“短轮次”中处理，从而减少了GPU空闲时间，并在不牺牲准确性的前提下显著加快了训练速度。论文还介绍了“RollPacker”系统，该系统通过弹性并行适应、动态资源分配和流式训练等优化手段，充分发挥了尾部批处理的优势。实验结果表明，与现有方法相比，RollPacker在Qwen2.5系列LLM的训练中实现了显著的时间缩减。


<details>
  <summary>Details</summary>
Motivation: 同步强化学习（RL）在训练大型语言模型（LLM）时存在GPU利用率低（即“气泡”）的问题，因为响应长度不平衡会导致回滚步骤中的计算资源闲置。现有的解决方案（如放松同步）可能会牺牲训练精度。

Method: 提出了一种名为“尾部批处理”（tail batching）的回滚调度策略。该策略将响应较长的提示收集到少数“长轮次”中，而将大多数响应较短的提示放在“短轮次”中。此外，还开发了一个名为“RollPacker”的系统，通过在回滚、奖励和流式训练三个阶段进行整体优化来支持尾部批处理。

Result: RollPacker系统在Qwen2.5系列LLM的训练中，与veRL相比，端到端训练时间缩短了2.03倍至2.56倍；与RLHFuse相比，速度提升最高可达2.24倍。

Conclusion: 尾部批处理是一种有效的策略，可以解决同步RL训练中的GPU利用率问题，并显著加快LLM的训练速度，同时保持训练精度。RollPacker系统通过全面的优化实现了这些优势。

Abstract: Reinforcement Learning (RL) is a pivotal post-training technique for
enhancing the reasoning capabilities of Large Language Models (LLMs). However,
synchronous RL post-training often suffers from significant GPU
underutilization, referred to as bubbles, caused by imbalanced response lengths
within rollout steps. Many RL systems attempt to alleviate this problem by
relaxing synchronization, but this can compromise training accuracy. In this
paper, we introduce tail batching, a novel rollout scheduling strategy for
synchronous RL that systematically consolidates prompts leading to long-tail
responses into a small subset of rollout steps (long rounds), while ensuring
that the majority of steps (short rounds) involve only balanced, short
rollouts. By excluding long responses from short rounds and rescheduling them
into a few designated long rounds, tail batching effectively reduces GPU idle
time during rollouts and significantly accelerates RL training without
sacrificing accuracy. We present RollPacker, a system that fully harnesses the
benefits of tail batching through holistic optimizations across all three RL
stages: elastic parallelism adaptation for rollout, dynamic resource allocation
and scheduling for reward, and stream-based training. Empirical results show
that RollPacker achieves a 2.03x-2.56x end-to-end training time reduction
compared to veRL and up to 2.24x speedup compared to RLHFuse for the Qwen2.5
family of LLMs on up to 128 H800 GPUs.

</details>


### [356] [Utilizing Sparsity in the GPU-accelerated Assembly of Schur Complement Matrices in Domain Decomposition Methods](https://arxiv.org/abs/2509.21037)
*Jakub Homola,Ondřej Meca,Lubomír Říha,Tomáš Brzobohatý*

Main category: cs.DC

TL;DR: 通过利用稀疏性改进了GPUs上Schur补矩阵的组装，从而在FETI方法中实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 当前的域分解方法在高性能计算中面临瓶颈，尤其是在GPU上，需要对Schur补矩阵的组装进行优化以提高效率。

Method: 通过明智地利用输入矩阵的稀疏性来改进GPU上Schur补矩阵的组装过程。

Result: 在FETI方法中，GPU部分的计算速度提升了5.1倍，整个组装过程的加速比为3.3倍，并且从10次迭代开始就能体现出加速优势。

Conclusion: 利用稀疏性可以进一步优化GPU上Schur补矩阵的组装，为FETI等域分解方法带来显著的性能提升。

Abstract: Schur complement matrices emerge in many domain decomposition methods that
can solve complex engineering problems using supercomputers. Today, as most of
the high-performance clusters' performance lies in GPUs, these methods should
also be accelerated.
  Typically, the offloaded components are the explicitly assembled dense Schur
complement matrices used later in the iterative solver for multiplication with
a vector. As the explicit assembly is expensive, it represents a significant
overhead associated with this approach to acceleration. It has already been
shown that the overhead can be minimized by assembling the Schur complements
directly on the GPU.
  This paper shows that the GPU assembly can be further improved by wisely
utilizing the sparsity of the input matrices. In the context of FETI methods,
we achieved a speedup of 5.1 in the GPU section of the code and 3.3 for the
whole assembly, making the acceleration beneficial from as few as 10
iterations.

</details>


### [357] [Mojo: MLIR-Based Performance-Portable HPC Science Kernels on GPUs for the Python Ecosystem](https://arxiv.org/abs/2509.21039)
*William F. Godoy,Tatiana Melnichenko,Pedro Valero-Lara,Wael Elwasif,Philip Fackler,Rafael Ferreira Da Silva,Keita Teranishi,Jeffrey S. Vetter*

Main category: cs.DC

TL;DR: Mojo语言在科学计算GPU工作负载上表现具有竞争力，但在AMD GPU的原子操作和fast-math计算密集型内核方面存在差距，尽管如此，它仍有望弥合Python生态系统的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: Mojo旨在通过结合Python的互操作性和类似CUDA的语法，来弥合科学计算在性能和开发效率上的差距，实现可编译的、可移植的GPU编程。

Method: 研究人员将Mojo语言应用于四种科学计算工作负载（七点样条、BabelStream、miniBUDE、Hartree-Fock），并在NVIDIA H100和AMD MI300A GPU上与CUDA和HIP等厂商的基准进行性能对比。

Result: 在内存密集型内核上，Mojo的性能与CUDA和HIP相当。然而，在AMD GPU的原子操作以及AMD和NVIDIA GPU的fast-math计算密集型内核方面，Mojo的性能存在差距。

Conclusion: Mojo在科学计算和人工智能融合的背景下，有潜力显著改善碎片化的Python生态系统，尽管其学习曲线和编程要求仍偏底层。

Abstract: We explore the performance and portability of the novel Mojo language for
scientific computing workloads on GPUs. As the first language based on the
LLVM's Multi-Level Intermediate Representation (MLIR) compiler infrastructure,
Mojo aims to close performance and productivity gaps by combining Python's
interoperability and CUDA-like syntax for compile-time portable GPU
programming. We target four scientific workloads: a seven-point stencil
(memory-bound), BabelStream (memory-bound), miniBUDE (compute-bound), and
Hartree-Fock (compute-bound with atomic operations); and compare their
performance against vendor baselines on NVIDIA H100 and AMD MI300A GPUs. We
show that Mojo's performance is competitive with CUDA and HIP for memory-bound
kernels, whereas gaps exist on AMD GPUs for atomic operations and for fast-math
compute-bound kernels on both AMD and NVIDIA GPUs. Although the learning curve
and programming requirements are still fairly low-level, Mojo can close
significant gaps in the fragmented Python ecosystem in the convergence of
scientific computing and AI.

</details>


### [358] [Data-Centric Elastic Pipeline Parallelism for Efficient Long-Context LLM Training](https://arxiv.org/abs/2509.21275)
*Shiju Wang,Yujie Wang,Ao Sun,Fangcheng Fu,Zijian Zhu,Bin Cui,Xu Han,Kaisheng Ma*

Main category: cs.DC

TL;DR: 该论文提出了一种名为弹性流水线并行（EPP）的新方法，通过自适应地结合批处理和序列处理来解决长上下文训练中通信开销和硬件利用率的问题，并设计了一个名为InfiniPipe的系统来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的长上下文训练方法，如序列并行，通信开销大；流水线并行（PP）虽然能降低通信成本，但在批处理级PP时内存消耗高，在序列级PP时可能导致硬件利用率低。此外，现实世界的数据集序列长度分布不均，给PP的负载均衡和高效调度带来了挑战。

Method: 提出弹性流水线并行（EPP），自适应地结合序列级和批处理级流水线并行，以适应资源和工作负载的异构性。设计了InfiniPipe系统，包括一个资源感知和负载均衡的序列处理器（用于分割长序列和打包短序列）和一个联合优化流水线调度和梯度检查点的机制（分段感知块级自适应检查点）。

Result: InfiniPipe在综合实验中实现了比现有最先进系统1.69倍的加速。

Conclusion: EPP通过结合不同并行策略的优点并解决长上下文训练中的挑战，可以显著提高训练效率。InfiniPipe的效率。

Abstract: Long context training is crucial for LLM's context extension. Existing
schemes, such as sequence parallelism, incur substantial communication
overhead. Pipeline parallelism (PP) reduces this cost, but its effectiveness
hinges on partitioning granularity. Batch-level PP dividing input samples
exhibits high memory consumption in long-context scenario, whereas token-level
PP splitting sequences into slices alleviates memory overhead but may incur
hardware under-utilization. This trade-off motivates adaptively selecting PP
granularity to match resource and workload characteristics. Moreover, sequence
length distribution of the real-world dataset exhibits skewness, posing a
challenge on PP's workload balance and efficient scheduling. Current static PP
scheduling methods overlook the variance of sequence length, leading to
suboptimal performance. In this paper, we propose Elastic Pipeline Parallelism
(EPP) that orchestrates token-level PP and batch-level PP to adapt to resource
and workload heterogeneity. We build InfiniPipe, a distributed training system
that unleashes the potential of EPP via (1) a resource-aware and
workload-balanced sequence processor that splits long sequences and packs short
ones; and (2) a co-optimization methodology that jointly optimizes pipeline
schedule and gradient checkpointing via a mechanism named stage-aware
chunk-level adaptive checkpointing. Comprehensive experiments demonstrate that
InfiniPipe achieves a 1.69x speedup over state-of-the-art systems.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [359] [Tailoring properties of Heusler alloys by elemental substitution and electron counting: (Co$_{2-α}$Mn$_α$)FeGe, Co$_2$(Fe$_{1-β}$Mn$_β$)Ge, and (Co$_{2-α}$Fe$_α$)MnGe](https://arxiv.org/abs/2509.20546)
*R. Mahat,S. Budhathoki,S. Regmi,J. Y. Law,V. Franco,W. H. Butler,A. Gupta,A. Hauser,P. LeClair*

Main category: cond-mat.mtrl-sci

TL;DR: 通过元素替换进行合理的材料设计可以用于定制材料以获得理想的性能。本文研究了基于Co2FeGe的三种非对等取代系列（Co2-αMnα）FeGe、Co2（Fe1-βMnβ）Ge、（Co2-αFeα）MnGe（0≤α≤2, 0≤β≤1），以及在Mn、Fe和Co在Co2FeGe中相互替换时材料性能如何演变。


<details>
  <summary>Details</summary>
Motivation: 通过元素替换进行合理的材料设计以获得理想的材料性能。

Method: 研究了三种基于Co2FeGe的取代系列（Co2-αMnα）FeGe、Co2（Fe1-βMnβ）Ge、（Co2-αFeα）MnGe，并研究了材料性能如何随Mn、Fe和Co在Co2FeGe中的取代而演变。

Result: 所有系列在宽范围的组分下均可获得单相化合物，并结晶于fcc结构。这些化合物是软磁材料，具有符合Slater-Pauling规则的低温饱和磁化强度。在Mn浓度较低的情况下，居里温度非常高，可达1000 K。第一性原理计算表明，在最稳定的原子构型下，Mn倾向于与Ge共享亚格子，这与4-2规则一致。计算还预测（Co1.625Mn0.375）FeGe具有半金属行为，而其他组分则接近半金属行为。

Conclusion: 通过比较三个系列的研究结果，发现在较宽的价电子数/单位单元（~28.5-29.75）范围内会出现单相合金。即使对于多相样品，其结构、磁性和电子性质也主要取决于价电子的数量，而不是具体的取代方案。

Abstract: Rational material design by elemental substitution is useful in tailoring
materials to have desirable properties. Here we consider three non-equivalent
substitutional series based on Co$_2$FeGe, viz;
(Co$_{2-\alpha}$Mn$_\alpha$)FeGe, Co$_2$(Fe$_{1-\beta}$Mn$_{\beta}$)Ge,
(Co$_{2-\alpha}$Fe$_\alpha$)MnGe ($0\!\le\!\alpha\!\le\!2,
0\!\le\!\beta\!\le\!1$), and study how material properties evolve with the
interchange of Mn, Fe, and Co in Co$_2$FeGe. In all three schemes, single-phase
compounds can be obtained over a wide range of compositions: $0.125 < \alpha <
1.375 $ for (Co$_{2-\alpha}$Mn$_{\alpha}$)FeGe, $0 \!\le\! \beta \!\le\! 1$ for
Co$_2$(Fe$_{1-\beta}$Mn$_{\beta}$)Ge, and $0 \!<\! \alpha \!<\! 1.50$ for
(Co$_{2-\alpha}$Fe$_\alpha$)MnGe. All the single-phase compounds crystallise in
fcc structure with chemical ordering consistent with the ``4-2'' rule of Butler
et al. The compounds are soft ferromagnets with low temperature saturation
magnetisation agreeing with the Slater-Pauling rule. Very high Curie
temperatures are measured, with values up to 1000 K for lower Mn
concentrations. First principle calculations indicate, in the most stable
atomic configuration, Mn prefers sharing sublattice with Ge, also consistent
with the 4-2 rule. The calculations further predict half-metallic behaviour for
(Co$_{1.625}$Mn$_{0.375}$)FeGe, while finding other compositions to be nearly
half-metallic. Upon comparing the results of the three series, it is found that
single-phase alloys occur for a specific range of valence electrons per unit
cell ($\sim\!28.5\!-\!29.75$), and that even for multi-phase samples the
structural, magnetic, and electronic properties depend primarily on the number
of valence electrons and not on the specific substitution scheme employed.

</details>


### [360] [Negative Charge Transfer: Ground State Precursor towards High Energy Batteries](https://arxiv.org/abs/2509.20622)
*Eder G. Lomeli,Qinghao Li,Kuan H. Hsu,Gi-Hyeok Lee,Zengqing Zhuo,Bryant-J. Polzin,Jihyeon Gim,Boyu Shi,Eungje Lee,Yujia Wang,Haobo Li,Pu Yu,Jinpeng Wu,Zhi-Xun Shen,Shishen Yan,Lauren Illa,Josh J. Kas,John J. Rehr,John Vinson,Brian Moritz,Yi-Sheng Liu,Jinghua Guo,Yi-de Chuang,Wanli Yang,Thomas P. Devereaux*

Main category: cond-mat.mtrl-sci

TL;DR: LiCoO2等高能层状正极材料的本质是负电荷转移（NCT）增强，而非传统理解的体相氧化还原反应。


<details>
  <summary>Details</summary>
Motivation: 目前的电池技术瓶颈在于高温压电阴极的稳定性，特别是LiCoO2等高能量密度电池的性能提升。然而，其氧化还原机制仍未被完全理解，这阻碍了新型电池的开发。

Method: 通过原位和非原位光谱分析，并结合理论计算，研究了LiCoO2和LiNiO2等高能层状正极材料。

Result: 研究发现，这些材料在整个充电电压范围内，通过增强负电荷转移（NCT）基态来工作，NCT本身是内在的氧化还原机制，并且与高共价性和氧空穴相关，这解释了许多以往的争议性结果。

Conclusion: 通过重新定义LiCoO2等材料的氧化还原机制，揭示了开发高能量密度电池电极的新途径。

Abstract: Modern energy applications, especially electric vehicles, demand high energy
batteries. However, despite decades of intensive efforts, the highest energy
density and commercially viable batteries are still based on LiCoO2, the very
first generation of cathode materials. The technical bottleneck is the
stability of oxide-based cathodes at high operating voltages. The fundamental
puzzle is that we actually never understood the redox mechanism of LiCoO2.
Conventional wisdom generally defines redox to be centered on cations at low
voltages, and on anions, i.e. oxygen, at high voltages by forming oxidized
chemical states like O2 or peroxo-species. Here, through in-situ and ex-situ
spectroscopy coupled with theoretical calculations, we show that high-energy
layered cathodes, represented by LiCoO2 and LiNiO2, operate through enhancement
of negative charge transfer (NCT) ground states upon charging throughout the
whole voltage range - i.e., NCT evolution itself is the intrinsic redox
mechanism regardless of voltage ranges. NCT inherently engages high covalency
and oxygen holes, leading to optimized performance without conventional redox
centers in LiCoO2. The level of NCT, i.e., number of ligand holes, naturally
explains many seemingly controversial results. The redefinition of redox
mechanism reveals the pathway toward viable high energy battery electrodes.

</details>


### [361] [Atomistic Insights into Cu/amorphous-Ta$_x$N Interfacial Adhesion via Machine Learning Interatomic Potentials: Effects of Stoichiometry and Interface Construction](https://arxiv.org/abs/2509.20662)
*Jeong Min Choi,Jaehoon Kim,Ji-Hwan Lee,Won-Joon Son,Seungwu Han*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究使用机器学习势能模拟了不同钽含量下铜/非晶氮化钽界面的粘附强度，并探讨了界面构建方法和钽原子掺杂对粘附强度的影响，为优化互连线技术提供了原子尺度见解。


<details>
  <summary>Details</summary>
Motivation: 为了确保半导体器件中铜互连系统的机械可靠性和完整性，必须准确理解和控制铜与氮化钽扩散阻挡层之间的界面粘附性。然而，目前缺乏对不同钽化学计量比如何影响铜/非晶氮化钽界面粘附强度的系统原子尺度研究，这阻碍了对界面优化策略的全面理解。

Method: 利用机器学习势能（MLIPs）进行受控分子动力学（SMD）模拟，并采用静态弛豫、高温退火和模拟铜沉积三种不同的界面构建方法，研究了不同钽含量（x=1, 2, 4）下铜/非晶氮化钽界面的粘附强度。通过峰值力和粘附功量化界面强度，并进行原子应力应变分析。

Result: 模拟结果表明，不同的界面构建方法和钽含量对界面粘附强度有显著影响。原子应力应变分析揭示了界面形态对变形行为的关键作用。研究还发现了铜层中掺杂钽原子的机制，能够提高界面的内聚强度。

Conclusion: 该研究证明了机器学习势能驱动的模拟可以阐明界面形态与粘附行为之间的原子尺度关系，为通过原子尺度工程提高扩散阻挡层的内聚粘附性提供了指导，并可能推动无需衬垫的互连线技术的发展。

Abstract: Accurate understanding and control of interfacial adhesion between Cu and
Ta$_x$N diffusion barriers are essential for ensuring the mechanical
reliability and integrity of Cu interconnect systems in semiconductor devices.
Amorphous tantalum nitride (a-Ta$_x$N) barriers are particularly attractive due
to their superior barrier performance, attributed to the absence of grain
boundaries. However, a systematic atomistic investigation of how varying Ta
stoichiometries influences adhesion strength at Cu/a-Ta$_x$N interfaces remains
lacking, hindering a comprehensive understanding of interface optimization
strategies. In this study, we employ machine learning interatomic potentials
(MLIPs) to perform steered molecular dynamics (SMD) simulations of Cu/a-Ta$_x$N
interfaces. We simultaneously evaluate three distinct interface construction
approaches--static relaxation, high-temperature annealing, and simulated Cu
deposition--to comprehensively investigate their influence on adhesion strength
across varying Ta compositions ($x=1, 2, 4$). Peak force and work of adhesion
values from SMD simulations quantitatively characterize interface strength,
while atomic stress and strain analyses elucidate detailed deformation
behavior, highlighting the critical role of interfacial morphologies.
Additionally, we explore the atomistic mechanisms underlying cohesive failure,
revealing how targeted incorporation of Ta atoms into Cu layers enhances the
cohesive strength of the interface. This study demonstrates how MLIP-driven
simulations can elucidate atomic-scale relationships between interface
morphology and adhesion behavior, providing insights that can guide future
atomistic engineering strategies toward enhancing intrinsic barrier adhesion,
potentially enabling liner-free interconnect technologies.

</details>


### [362] [Robust Ferrimagnetic Ground State and Suppressed Superconductivity in Two-Dimensional HC6](https://arxiv.org/abs/2509.20672)
*Jakkapat Seeyangnok,Udomsilp Pinsook*

Main category: cond-mat.mtrl-sci

TL;DR: HC6稳定在亚铁磁性基态，而不是超导相，但超导电性仍然存在亚稳态。


<details>
  <summary>Details</summary>
Motivation: 探索二维氢化石墨烯（HC6）中出现的电子相，特别是其超导电性。

Method: 使用自旋极化第一性原理计算来确定HC6的电子结构和磁性。

Result: HC6在亚铁磁基态下比顺磁金属相更稳定，能量差为0.175 eV/单胞。在这种情况下，超导电性虽然存在，但能量降低仅为约7 meV，使其保持亚稳态。

Conclusion: 磁性在HC6中起主导作用，高电子态密度可能导致竞争性不稳定性。这为设计碳基磁性系统提供了原则。

Abstract: Two-dimensional hydrogenated graphene (HC6) represents a promising platform
for exploring emergent electronic phases. Owing to its high electronic density
of states at the Fermi level, HC6 is expected to support phonon-mediated
superconductivity, with a calculated critical temperature Tc of 37.4 K in the
paramagnetic metallic phase. However, spin-polarized first-principles
calculations reveal that HC6 stabilizes in a ferrimagnetic ground state, which
is energetically favored by 0.175 eV per unit cell over the paramagnetic
metallic phase. This large energy difference significantly exceeds kB T at room
temperature, indicating robust magnetic order. Although the superconducting
condensation energy lowers the total energy by about 7 meV, the superconducting
phase remains metastable. These results highlight the dominant role of
magnetism in HC6 and illustrate how a high electronic density of states can
drive competing instabilities in hydrogenated two-dimensional materials,
offering design principles for carbon-based magnetic systems.

</details>


### [363] [Intrinsic antiferromagnetic half-metal and topological phases in the ferrovalley states of the sliding bilayer altermagnets](https://arxiv.org/abs/2509.20687)
*Shihao Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 在一个由滑动双层超磁体组成的铁谷态中，发现了本征反铁磁性半金属和拓扑相。通过对V2OSSe系统的第一性原理计算表明，铁谷态中的自旋相关层间跳跃确保了一个谷（一个自旋通道）中的直接带隙和另一个谷（相反自旋通道）中的带隙倒置，从而表现为本征反铁磁半金属。


<details>
  <summary>Details</summary>
Motivation: 研究在由滑动双层超磁体组成的铁谷态中，是否存在本征反铁磁性半金属和拓扑相，以探索其在自旋电子学中的潜在应用。

Method: 通过构建由具有小带隙的超磁体单层组成的双层系统，利用层间跳跃和滑动工程诱导铁谷态，并结合第一性原理计算、微观模型和有效哈密顿量来分析其电子结构和磁性。

Result: 发现了本征反铁磁性半金属和拓扑相，并证明了自旋相关层间跳跃在滑动超磁体双层中的普遍性。通过调整滑动方向，可以实现不同自旋电子的半金属之间的转换，并伴随着无隙表面态的开关。

Conclusion: 这项研究为本征反铁磁半金属和拓扑相在自旋电子学中的潜在应用奠定了基础。

Abstract: Altermagnetism is characterized by non-relativistic spin splitting and zero
total magnetic moments. In this work, intrinsic antiferromagnetic half-metallic
and topological phases were discovered within the ferrovalley states of sliding
bilayer altermagnets. We construct the bilayer system by utilizing altermagnet
monolayers with a small bandgap. The inter-layer hopping phenomenon leads to a
reduction in bandgaps, and sliding engineering induces ferrovalley states.
Taking the V$_2$OSSe system for example, first-principles calculations indicate
that the spin-dependent inter-layer hopping in the ferrovalley state ensures a
direct gap in one valley (one spin channel) and band inversion in the other
valley (opposite spin channel), which is manifested as an intrinsic
antiferromagnetic half-metal. The microscopic model and effective Hamiltonian
employed in this research confirm the universal spin-dependent inter-layer
hopping in the sliding altermagnet bilayer. Further calculations imply the
existence of Chern insulator and gapless surface states in the sliding
altermagnet bilayer. Adjusting the sliding direction can achieve the transition
between different half-metals with conducting electrons of different spins,
accompanied by the switching of gapless surface states of opposite spins. This
research lays a foundation for the potential applications of intrinsic
antiferromagnetic half-metals and topological phases in spintronics.

</details>


### [364] [Magnetic order tuning of excitons in the magnetic semiconductor CrCl$_3$ through strain](https://arxiv.org/abs/2509.20761)
*Ali Ebrahimian,Francisco J. García-Vidal,Juan J. Palacios*

Main category: cond-mat.mtrl-sci

TL;DR: Few-layered magnets like CrCl3 show strong magnon-exciton coupling, allowing optical control of spin and vice versa. Strain can tune this coupling by altering magnetic order, causing significant shifts and changes in exciton peaks, suggesting potential for strain-based optical switching.


<details>
  <summary>Details</summary>
Motivation: Magnon-exciton coupling in few-layered magnets offers optical control of spin and magnetic control of optical response, with potential applications in optical switching.

Method: The study uses an effective Bethe-Salpeter equation to model the changes in excitonic response when switching magnetic order (ferromagnetic to antiferromagnetic) using strain in a monolayer of CrCl3.

Result: Applying strain switches the magnetic order in CrCl3, causing an abrupt change in exciton spatial localization, leading to a strong shift and altered oscillator strength of excitonic peaks.

Conclusion: The observed strain-induced changes in excitonic response suggest that strain can be used as a binary switch for optical properties in few-layered magnets like CrCl3.

Abstract: Magnon-exciton coupling provides an unprecedented opportunity for the optical
tunability of spin information and, viceversa, for the magnetic control of the
optical response. Few-layered magnets are an ideal platform for the
experimental study of this coupling, in part due to the strong excitonic
character of the optical response in (quasi-)two dimensions. Here, we
demonstrate a strong dependence of the excitonic oscillator strength on the
magnetic order in a monolayer of chromium trichloride CrCl$_3$. Solving an
effective Bethe-Salpeter equation, we evaluate the changes in the excitonic
response as the magnetic order switches from the ferromagnetic state to the
antiferromagnetic state when strain is applied. Our results reveal an abrupt
change in the spatial localization of the excitons across the transition, which
translates into a strong shift and a change of the oscillator strength of the
excitonic peaks. This suggests the possibility of using strain as a binary
switch of the optical response in this material.

</details>


### [365] [Uniaxial negative thermal expansion in a weak-itinerant-ferromagnetic phase of CoZr$_{2}$H$_{3.49}$](https://arxiv.org/abs/2509.20765)
*Yuto Watanabe,Kota Suzuki,Takayoshi Katase,Akira Miura,Aichi Yamashita,Yoshikazu Mizuguchi*

Main category: cond-mat.mtrl-sci

TL;DR: CoZr$_{2}$H$_{3.49}$在铁磁相中表现出独特的单轴负热膨胀行为，沿c轴收缩，这与钴锆的超导相中的反常热膨胀行为形成对比。


<details>
  <summary>Details</summary>
Motivation: 探究氢插入对CoZr$_{2}$反常热膨胀行为的影响，特别是其弱化 itenerant-ferromagnetism 行为。

Method: 通过粉末同步X射线衍射（SXRD）分析，确定了CoZr$_{2}$H$_{3.49}$的居里温度（$T_{\mathrm{C}}$），并分析了晶格常数a和c随温度的变化。

Result: 确定$T_{\mathrm{C}}$为139 K，Rhodes-Wohlfarth比为3.49，表明其铁磁性是弱 itenerant 的。晶格常数c在$T_{\mathrm{C}}$以下表现出负热膨胀行为，而晶格常数a则表现出正热膨胀行为。

Conclusion: CoZr$_{2}$H$_{3.49}$的单轴负热膨胀行为可以通过费米能级附近反键Co3$dz^{2}$部分态密度锐化来解释，这与沿c轴延伸的一维Co-Co链的膨胀有关。

Abstract: We discovered unique uniaxial negative thermal expansion (NTE) behavior for a
weak-itinerant-ferromagnetic phase of CoZr$_{2}$H$_{3.49}$. CoZr$_{2}$ is known
as a superconductor exhibiting uniaxial NTE along the $c$-axis, which is called
anomalous thermal expansion (ATE). Additionally, CoZr$_{2}$ is also known as a
well-absorbent of hydrogen, and hydrogen insertion raises weak-itinerant
ferromagnetism instead of superconductivity. However, the influence of hydrogen
insertion on ATE behavior in this system is still unclear. To investigate it,
we performed powder synchrotron X-ray diffraction (SXRD) for
CoZr$_{2}$H$_{3.49}$. Through Arrott plots analysis, we determined the Curie
temperature ($T_{\mathrm{C}}$) to be 139 K, and the Rhodes-Wohlfarth ratio was
estimated to be 3.49, which clearly exceeds 1, suggesting the itinerancy of
emerging ferromagnetism. Temperature dependencies of lattice constants $a$ and
$c$ were extracted from powder SXRD analyses, and we revealed that lattice
constant $c$ exhibited NTE behavior below $T_{\mathrm{C}}$. The uniaxial NTE
behavior along the $c$-axis can be understood by sharpening an antibonding
Co3$dz^{2}$ partial density of states near the Fermi level, linked to the
expansion of a one-dimensional Co-Co chain running parallel to the $c$-axis.

</details>


### [366] [Defect-Charge-Driven 90° Switching in HfO2](https://arxiv.org/abs/2509.20828)
*Muting Xie,Hongyu Yu,Zhihao Dai,Yingfen Wei,Changsong Xu,Hongjun Xiang*

Main category: cond-mat.mtrl-sci

TL;DR: 铪(IV)氧化物(HfO2)是一种具有180度和90度开关特性的CMOS兼容铁电材料，但90度开关机制尚不明确。本文研究发现，在[111]电场作用下，由带电氧空位诱导时，原本可忽略的90度旋转开关在高纯HfO2中变得占主导地位。该开关机制比180度反转具有更好的抗疲劳性，同时能提供相同的[111]方向极化变化（2Pr=60μC/cm^2）。这种电荷驱动的开关源于HfO2的晶体几何结构和旋转开关的内在特性，后者表明缺陷电荷可能普遍地影响铁电材料中旋转开关而非反转开关。这些发现揭示了抗疲劳性的开关机制起源，并将缺陷电荷确立为调控极化动力学的一个通用参数。


<details>
  <summary>Details</summary>
Motivation: 研究HfO2材料中90度铁电开关的微观机制，并探索其抗疲劳性及其与缺陷电荷的关系。

Method: 通过施加[111]电场，并考虑带电氧空位的影响，研究HfO2的90度开关行为，并与180度开关行为进行比较，分析其抗疲劳性。

Result: 在[111]电场和带电氧空位作用下，90度旋转开关在高纯HfO2中成为主导。90度开关比180度开关更具抗疲劳性，并提供相同的极化变化。

Conclusion: 带电氧空位可以诱导HfO2发生90度铁电开关，且该机制具有优异的抗疲劳性。缺陷电荷是调控铁电材料极化动力学的一个通用参数。

Abstract: Hafnium dioxide (HfO2) is a CMOS-compatible ferroelectric showing both
180{\deg} and 90{\deg} switching, yet the microscopic nature of the 90{\deg}
pathway remains unresolved. We show that the 90{\deg} rotation pathway,
negligible in pristine HfO2, becomes dominant under E// [111] when induced by
charged oxygen vacancies. This pathway is more fatigue-resistant than the
180{\deg} reversal pathway, while delivering the same polarization change along
[111] (2Pr=60 {\mu}C/cm^2 ). This charge-driven switching arises from two
factors: the crystal geometry of HfO2 and the intrinsic nature of rotational
pathways, the latter suggesting a possible general tendency for defect charge
to bias rotation over reversal in ferroelectrics. Together these findings
reveal a pathway-level origin of fatigue resistance and establish defect charge
as a general control parameter for polarization dynamics.

</details>


### [367] [Cu2XSiS4 (X = Ge, Sn, and Pb) materials for solar-cell applications: A DFT+SCAPS-1D simulation](https://arxiv.org/abs/2509.20845)
*H. Laltlanmawii,L. Celestine,R. Zosiamliana,B. Chettri,S. Bhattarai,K. C. Bhamu,D. P. Rai*

Main category: cond-mat.mtrl-sci

TL;DR: Cu2XSiS4 (X = Ge, Sn, Pb) 具有潜在的光伏应用价值，其中 Ge 基材料表现出最高的 23.46% 的功率转换效率。


<details>
  <summary>Details</summary>
Motivation: 研究 I2-II-IV-VI4 型铜基四元硫族化合物 Cu2XSiS4 (X = Ge, Sn, Pb) 的结构、电子、光学和力学性质，探索其在光伏领域的应用潜力。

Method: 采用第一性原理密度泛函理论（DFT）计算了化合物的结构、电子、光学和力学性质。通过从头分子动力学（MD）模拟计算了弹性常数、形成能和总势能，以验证结构和热稳定性。使用 SCAPS-1D 软件，基于 DFT 结果，通过求解泊松方程和连续性方程，对设计的异质结太阳能电池模型 (FTO/TiO2/Cu2XSiS4/CuO/Au) 进行了数值模拟，得到了 I-V 特性曲线和功率转换效率（PCE）。

Result: 计算得到的化合物带隙在 1.0--1.56 eV 之间，适合用于太阳能捕获。吸收峰位于可见光区域。设计的太阳能电池模型的功率转换效率（PCE）分别为：X=Ge 时为 23.46%，X=Sn 时为 23.29%，X=Pb 时为 22.60%。其中，Ge 基系统表现出最高的 PCE。

Conclusion: Cu2XSiS4 (X = Ge, Sn, Pb) 化合物具有作为光伏应用吸收层材料的潜力，特别是 Ge 基化合物，由于其带隙值处于可见光光谱范围内，在异质结太阳能电池应用中表现出最高的功率转换效率，是最有希望的吸收层材料。

Abstract: By means of the first-principles density functional theory (DFT),
I2-II-IV-VI4 type Cu-based quaternary chalcogenides Cu 2 XSiS 4 (X = Ge, Sn,
and Pb) have been thoroughly investigated. We report the study of Ge and Sn
substitution in the divalent cation site for their potential applications in
photovoltaics for the first time. The structural, electronic, optical, and
mechanical properties have been calculated. The structural and thermal
stability is verified by calculating the elastic constants, formation energy
and total potential energy at 300 K from the ab-initio molecular dynamics (MD)
simulation. The compounds under our investigation exhibited an indirect band
gap in the range of 1.0--1.56 eV, suitable for energy harvesting by trapping
the sunlight. The presence of absorption peaks within the visible region
complements their potential in photovoltaic applications. For further
validation, we have designed a model of a heterostructure
(FTO/TiO2/Cu2XSiS4/CuO/Au) solar cell, and a numerical simulation has been
performed by solving the Poisson equation and continuity equations to obtain
the I-V characteristic by using SCAPS-1D. All the inputs needed for solar- cell
simulation in SCAPS-1D have been taken from the DFT results. The corresponding
Power Conversion Efficiency (PCE) is denoted by {\eta}% and their respective
values for X=Ge, Sn and Pb are 23.46%, 23.29% and 22.60%, at room temperature.
The Ge-based system exhibits the highest {\eta}%, owing to its band gap value
in the visible range of the solar spectrum. Thus, we report that Ge-based
compounds may act as a promising absorber layer in heterostructure solar-cell
applications.

</details>


### [368] [SMC-X: A Distributed Scalable Monte Carlo Simulation Method for Chemically Complex Alloys](https://arxiv.org/abs/2509.20949)
*Xianglin Liu,Kai Yang,Fanli Zhou,Pengxiang Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过分布式计算推进SMC-X方法，实现了对高熵合金（HEA）的超大规模原子模拟，空间尺度达到160亿原子（微米级），时间尺度达到10亿原子（数百万步，分钟级），弥合了实验与理论在纳米沉淀物尺寸预测上的差距，展示了SMC-X在模拟驱动的高熵材料探索中的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 需要准确的原子模拟方法来预测多组分合金中复杂的化学演化，并达到足够大的空间和时间尺度。

Method: 通过在GPU或CPU上进行分布式计算来推进SMC-X方法。

Result: 实现了160亿原子的HEA系统模拟（空间达微米级）和10亿原子的HEA系统模拟（时间达三百万步以上），并发现大规模模拟对于理解高熵合金（HEA）的纳米沉淀物尺寸至关重要，该结果可通过Lifshitz-Slyozov-Wagner（LSW）理论进行解释。

Conclusion: SMC-X方法在大空间和时间尺度上模拟高熵材料的化学复杂性方面具有巨大潜力，能够支持模拟驱动的探索。

Abstract: To predict the complex chemical evolution in multicomponent alloys, it is
highly desirable to have accurate atomistic simulation methods capable of
reaching sufficiently large spatial and temporal scales. In this work, we
advance the recently proposed SMC-X method through distributed computation on
either GPUs or CPUs, pushing both spatial and temporal scales of atomistic
simulation of chemically complex alloys to previously inaccessible scales. This
includes a 16-billion-atom HEA system extending to the micrometer regime in
space, and a 1-billion-atom HEA evolved over more than three million Monte
Carlo swap steps, approaching the minute regime in time. We show that such
large-scale simulations are essential for bridging the gap between experimental
observations and theoretical predictions of the nanoprecipitate sizes in HEAs,
based on analysis using the Lifshitz-Slyozov-Wagner (LSW) theory for
diffusion-controlled coarsening. This work demonstrates the great potential of
SMC-X for simulation-driven exploration of the chemical complexity in
high-entropy materials at large spatial and temporal scales.

</details>


### [369] [Computing finite--temperature elastic constants with noise cancellation](https://arxiv.org/abs/2509.20951)
*Debashish Mukherji,Marcus Müller,Martin H. Müser*

Main category: cond-mat.mtrl-sci

TL;DR: 通过泛化适用于压电耦合系数的噪声消除方法，提出了一种在有无热涨落的情况下计算弹性常数的新方法，并在一系列材料上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的计算材料弹性常数的热力学方法存在信噪比低或强非谐效应等问题。

Method: 对已平衡的固体施加微小应变，并采用相同的温控方案进行模拟，以消除热噪声，从而计算应力差和弹性常数。

Result: 该方法在计算晶体氩、有序硅、无定形硅、聚甲基丙烯酸甲酯和纤维素衍生物的弹性常数方面，表现出比传统方法更低的噪声。

Conclusion: 所提出的噪声消除方法能够有效地计算有热序和无热序体系的弹性常数，克服了传统方法的局限性。

Abstract: Elastic constants are central material properties, frequently reported in
experimental and theoretical studies. While their computation is
straightforward in the absence of thermal fluctuations, finite--temperature
methods often suffer from poor signal--to--noise ratios or the presence of
strong anharmonic effects. Here, we show how to compute elastic constants in
thermal ordered and disordered systems by generalizing a noise--cancellation
method originally developed for piezoelectric coupling coefficients. A slight
strain is applied to an equilibrated solid. Simulations of both the strained
and unstrained (or oppositely strained) reference systems are performed using
identical thermostatting schemes. As demonstrated theoretically and with
generic one--dimensional models, this allows stress differences to be evaluated
and elastic constants to be determined with much reduced thermal noise. We then
apply this approach across a diverse set of systems, spanning crystalline
argon, ordered silicon as well as amorphous silicon, poly(methyl methacrylate),
and cellulose derivatives.

</details>


### [370] [A GND-based back stress model for reverse loading in metal sheets with consideration of GNB](https://arxiv.org/abs/2509.20996)
*Gyu-Jang Sim,Jehyun You,SeongHwan Choi,Youngjae Kim,Chung An Lee,Hyunki Kim,Donghwan Noh,Myoung-Gyu Lee*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出一种基于晶体塑性有限元方法（CPFEM）并结合基于几何必需位错（GNDs）和晶界（GNBs）的背应力模型，用于精确预测超薄板材在复杂加载路径变化下的回弹和成形性。该模型考虑了晶粒尺寸效应（包括Hall-Petch和Bauschinger效应），仅需拉伸数据即可预测反向加载行为，克服了实验上的限制。


<details>
  <summary>Details</summary>
Motivation: 超薄板材在塑性屈曲等压溃现象下，难以进行压缩载荷下的实验表征，限制了对复杂加载路径下回弹和成形性的准确预测。

Method: 提出一种基于晶体塑性有限元方法（CPFEM）的力学模型，该模型包含基于几何必需位错（GNDs）和晶界（GNBs）的背应力模型，并考虑了晶粒尺寸效应对Hall-Petch和Bauschinger效应的影响。

Result: 该模型能够仅通过拉伸数据准确预测低碳钢（0.64 mm）的反向加载行为和超薄SUS316（0.083 mm）的拉伸-弯曲（T-B）响应，且模型参数通过可辨识性分析得到唯一确定。

Conclusion: 该研究提供了一个具有物理意义、高效且鲁棒的框架，用于预测超薄金属板材的反向加载行为，有效解决了实验表征的难题。

Abstract: Accurate prediction of springback and formability in sheet metal forming
requires understanding reverse loading behavior under complex loading path
changes, such as tension followed by compression. However, for ultra-thin
sheets experimental characterization of such behavior is difficult due to
compressive instability like plastic buckling. This study presents a crystal
plasticity finite element method (CPFEM) incorporating a physically motivated
back stress model based on geometrically necessary dislocations (GNDs) and
boundaries (GNBs). The model captures grain size effects, including the
Hall-Petch and Bauschinger effects, through a single grain size-dependent back
stress parameter, enabling reverse loading prediction using only tensile data
from specimens with different grain sizes. The back stress parameter was
calibrated by fitting tensile stress-strain curves from two microstructures -
one as-received and one annealed. Without using Tension-Compression (T-C) data
for calibration, the model accurately predicted reverse loading behavior in
low-carbon steel (0.64 mm thick) and Tension-Bending (T-B) responses in
ultra-thin SUS316 (0.083 mm thick) when the developed theory was incorporated
to an upscaled anisotropic hardening model. Identifiability analysis confirmed
that the model parameters are uniquely determined by the available data. This
physically interpretable framework provides an efficient and robust means to
predict reverse loading in thin metal sheets, overcoming experimental
limitations.

</details>


### [371] [Avalanche-like lithium intercalation and intraparticle correlations in graphite](https://arxiv.org/abs/2509.21047)
*Jiho Han,George S. Phillips,Alice J. Merryweather,Juhwan Lim,Christoph Schnedermann,Robert L. Jack,Clare P. Grey,Akshay Rao*

Main category: cond-mat.mtrl-sci

TL;DR: 石墨在锂离子电池中作为负极材料已有30多年的历史，但其锂离子嵌入过程和动力学仍未被充分理解，尤其是在稀疏阶段。本研究利用原位光学显微镜结合随机场伊辛模型，首次统一解释了石墨稀疏阶段的离子嵌入动力学。


<details>
  <summary>Details</summary>
Motivation: 石墨作为锂离子电池负极材料，其锂离子嵌入过程和动力学，尤其是在稀疏阶段，仍缺乏根本性的理解，特别是对称性破缺相变在操作条件下的发生机制。

Method: 采用原位光学显微镜结合随机场伊辛模型（random field Ising modelling）来研究石墨稀疏阶段的离子嵌入动力学。

Result: 在稀疏阶段，单个石墨颗粒经历快速、局域性的雪崩式（去）嵌入过程，导致微米尺寸区域在几秒钟内完成（去）嵌入。这种行为类似于无序材料中的相变行为。研究将这种雪崩现象与石墨中的静态无序联系起来，该无序破坏了离子填充动力学，导致阶段间的伪连续转变，并能解释实验电化学曲线和温度依赖的雪崩动力学。

Conclusion: 本研究强调了局域静态无序在引发意外相变行为中的作用，并为研究层状电池材料提供了新的工具和概念。

Abstract: Graphite is the most widely used anode material in lithium-ion batteries with
over 98% market share. However, despite its first application over 30 years
ago, the lithium insertion processes and associated dynamics in graphite remain
poorly understood, especially for the dilute stages. A fundamental
understanding of how the symmetry-breaking phase transitions occur
pseudo-continuously under operating conditions is still lacking. Here, we
provide a unified picture of ion intercalation dynamics during the dilute
stages of graphite intercalation, using operando optical microscopy combined
with random field Ising modelling. We show that during the dilute stages,
single graphite particle undergoes rapid, localised avalanche-like
(de)intercalation, leading to micron-sized regions (de)intercalating within
seconds. These avalanches are reminiscent of phase transition behaviour seen in
disordered materials such as martensitic transformations, Barkhausen noise and
ferroelectric/elastic materials - associated with step changes in the order
parameter, where the system changes from one phase to another under an applied
driving force by jumping from one metastable state to another. Here, using a
modified random field Ising model, we relate these avalanches to static
disorder in graphite, which disrupts ion filling dynamics, leading to
pseudo-continuous transitions between stages, accounting for the experimental
electrochemistry profile as well as the temperature dependent avalanche
dynamics. Finally, we develop a methodology to spatio-temporally analyse
avalanches between intraparticle regions, revealing spatially heterogeneous
connectivity and temporal patterns between regions during the dilute stages.
Our work highlights the role of local and static disorder in eliciting
unexpected phase transition behaviour, and provides new tools and concepts for
studying layered battery materials.

</details>


### [372] [Low Temperature MOCVD Synthesis of high-mobility 2D InSe](https://arxiv.org/abs/2509.21082)
*Robin Günkel,Oliver Maßmeyer,Markus Stein,Sebastian Anhäuser,Kalle Bräumer,Rodrigo Sandoval Rodriguez,Daniel Anders,Badrosadat Ojaghi Dogahe,Max Bergmann,Milan Solanki,Nils Fritjof Langlotz,Johannes Glowatzki,Jürgen Belz,Andreas Beyer,Gregor Witte,Sangam Chatterjee,Kerstin Volz*

Main category: cond-mat.mtrl-sci

TL;DR: MOCVD 可用于在蓝宝石衬底上合成 2D InSe，并通过控制 Se/In 前驱体比和生长温度来确定 InSe 相图。


<details>
  <summary>Details</summary>
Motivation: InSe 具有高电子迁移率和可调带隙，但合成相纯 InSe 具有挑战性。

Method: 通过 MOCVD 在蓝宝石衬底上合成 InSe，并通过改变 Se/In 前驱体比和生长温度来探索相图。

Result: 确定了 InSe 的相图，并观察到 2D InSe 的形成。通过 STEM 揭示了 InSe 与蓝宝石衬底的表观对齐。优化生长的样品表现出强的可见光吸收和高电子迁移率。

Conclusion: MOCVD 是生长 InSe 的有前途的方法，可用于未来逻辑和光电器件的应用。

Abstract: Two-dimensional (2D) indium selenide (InSe) is a layered semiconductor with
high electron mobility and a tunable band gap ranging from 1.25 eV in the bulk
to 2.8 eV in the monolayer limit. These properties make these materials strong
candidates for future logic and optoelectronic devices. However, growing
phase-pure InSe remains challenging due to the complex indium-selenium (In-Se)
phase diagram. This complexity and the sensitivity of chemical precursors to
growth conditions make it difficult to control which In-Se phase forms during
synthesis during, e.g., metal-organic chemical vapor deposition (MOCVD).
Despite the challenges, MOCVD is considered the most promising approach for
growing InSe, as it enables wafer-scale, uniform, and controllable
deposition-key requirements for device integration. In this study, we present a
systematic investigation of InSe synthesis via MOCVD on c-plane sapphire
substrates at low temperatures, which are highly relevant for various
integration schemes. By varying the Se/In precursor ratio and the growth
temperature, we create a phase diagram that covers the In-rich, equal
stoichiometric, and Se-rich InxSey phases. Raman spectroscopy and atomic force
microscopy, supported by energy dispersive X-ray spectroscopy and scanning
transmission electron microscopy, confirm conditions, under which the formation
of 2D InSe is observed. Atomically-resolved cross-sectional scanning
transmission electron microscopy also reveals an epitaxial alignment of the
InSe with the sapphire substrate mediated by a specific interface
reconstruction. The epitaxial alignment is verified by in-plane X-ray
diffraction across large length scales. Samples grown under optimized
conditions exhibit a strong optical absorption in the visible range and
especially a comparably high electron mobility underlining the potential of the
MOCVD-grown material for future applications.

</details>


### [373] [Topological nontrivial berry phase in altermagnet CrSb](https://arxiv.org/abs/2509.21303)
*Jianhua Du,Xin Peng,Yuzhi Wang,Shengnan Zhang,Yuran Sun,Chunxiang Wu,Tingyu Zhou,Le Liu,Hangdong Wang,Jinhu Yang,Bin Chen,Chuanying Xi,Zhiwei Jiao,Quansheng Wu,Minghu Fang*

Main category: cond-mat.mtrl-sci

TL;DR: CrSb是一种具有独特磁性的潜在交替磁性材料，研究表明其具有非平凡拓扑特征，这对于理解交替磁体的电子结构和拓扑量子态至关重要。


<details>
  <summary>Details</summary>
Motivation: CrSb作为一种潜在的交替磁性材料，因其独特的磁性而备受关注，为探索交替磁序与奇异拓扑态之间的内在关系提供了一个新的平台。

Method: 通过系统的输运实验和从头算方法，研究CrSb的拓扑性，包括高场磁输运测量、非线性霍尔电阻率测量、Shubnikov-de Haas（SdH）量子振荡以及费米面和能带计算。

Result: CrSb的磁电阻高达35T而不饱和，呈现出典型的幂律依赖关系（指数为1.48）；非线性霍尔电阻率表明存在多带电荷传输机制；在1.6K下观察到显著的SdH量子振荡和由Zeeman效应引起的可分辨的能带分裂；费米面和能带计算结合Berry相位分析证实了该材料具有非平凡的拓扑特性（Berry相位接近π）。

Conclusion: 研究结果为理解CrSb的电子结构提供了重要的实验证据，并为研究交替磁体中的拓扑量子态奠定了重要基础。

Abstract: The study of topological properties in magnetic materials has long been one
of the forefront research areas in condensed matter physics. CrSb, as a
prototypical candidate material for altermagnetism, has attracted significant
attention due to its unique magnetic properties. This system provides a novel
platform for exploring the intrinsic relationship between altermagnetic order
and exotic topological states. In this study, we combine systematic electrical
transport experiments with first-principles calculations to investigate the
possible realization mechanisms of topological semimetal states in CrSb and
their manifestations in quantum transport phenomena. Our high field
magneto-transport measurements reveal that the magnetoresistance of CrSb
exhibits no sign of saturation up to 35 T, following a distinct power-law
dependence with an exponent of 1.48. The nonlinear Hall resistivity further
indicates a multiband charge transport mechanism. Under high magnetic fields,
we observe pronounced Shubnikov-de Haas (SdH) quantum oscillations and
discernible Zeeman-effect-induced band splitting at 1.6 K. Systematic Fermi
surface and band calculations combined with Berry phase analysis confirm the
nontrivial topological character of this material (with a Berry phase
approaching {\pi}). These findings not only provide crucial experimental
evidence for understanding the electronic structure of CrSb, but also establish
an important foundation for investigating topological quantum states in
altermagnets.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [374] [Visual Authority and the Rhetoric of Health Misinformation: A Multimodal Analysis of Social Media Videos](https://arxiv.org/abs/2509.20724)
*Mohammad Reza Zarei,Barbara Stead-Coyle,Michael Christensen,Sarah Everts,Majid Komeili*

Main category: cs.SI

TL;DR: 短视频平台成为健康建议的重要来源，但其中充斥着有用、误导性和有害的信息。本研究不关注内容的真伪，而是通过分析权威信号、叙事技巧和商业化手段的交叉点，来研究营养和补充剂视频中可信度的构建方式。


<details>
  <summary>Details</summary>
Motivation: 研究短视频平台中健康建议内容的可信度是如何通过权威信号、叙事技巧和商业化手段来构建的。

Method: 分析了来自TikTok、Instagram和YouTube的152个公开视频，并从视觉权威、演讲者特征、叙事策略和参与度线索等方面进行了标注。研究采用了一个透明的标注流程，结合了自动语音识别、帧选择和多模态模型，并通过人工抽样验证来确保一致性。

Result: 研究发现，在这些视频中，通常由一位自信的演讲者在工作室或家庭环境中进行讲解，临床环境很少出现。权威线索（如标题、幻灯片、图表和引用）经常与说服性元素（如专业术语、参考文献、恐惧或紧迫感、对主流医学的批评和阴谋论）以及商业化手段（如销售链接和订阅号召）同时出现。参考文献和类似科学的视觉效果常与情绪化和对立的叙事结合，而非体现出克制。

Conclusion: 权威信号、叙事技巧和商业化手段在短视频健康建议内容中常常交织在一起，共同构建出视频的可信度，但这种可信度并不总是与信息的准确性或严谨性相关。

Abstract: Short form video platforms are central sites for health advice, where
alternative narratives mix useful, misleading, and harmful content. Rather than
adjudicating truth, this study examines how credibility is packaged in
nutrition and supplement videos by analyzing the intersection of authority
signals, narrative techniques, and monetization. We assemble a cross platform
corpus of 152 public videos from TikTok, Instagram, and YouTube and annotate
each on 26 features spanning visual authority, presenter attributes, narrative
strategies, and engagement cues. A transparent annotation pipeline integrates
automatic speech recognition, principled frame selection, and a multimodal
model, with human verification on a stratified subsample showing strong
agreement. Descriptively, a confident single presenter in studio or home
settings dominates, and clinical contexts are rare. Analytically, authority
cues such as titles, slides and charts, and certificates frequently occur with
persuasive elements including jargon, references, fear or urgency, critiques of
mainstream medicine, and conspiracies, and with monetization including sales
links and calls to subscribe. References and science like visuals often travel
with emotive and oppositional narratives rather than signaling restraint.

</details>


### [375] [Identifying Group Anchors in Real-World Group Interactions Under Label Scarcity](https://arxiv.org/abs/2509.20762)
*Fanchen Bu,Geon Lee,Minyoung Choe,Kijung Shin*

Main category: cs.SI

TL;DR: 本篇论文提出了一种名为AnchorRadar的半监督学习方法，用于识别社交网络或合作网络中的“群体锚点”（即群体中特别重要的个体，如论文的第一作者或邮件发送者）。该方法在标签数据稀疏的情况下表现出色，并通过在13个真实数据集上的实验证明了其在准确性和效率方面优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的群体互动（如论文合著、邮件交流、在线问答）中，通常存在一个围绕该群体形成的核心成员。本研究旨在探讨这类个体（群体锚点）的存在性并解决其识别问题。

Method: 首先，论文定义了“群体锚点”的概念和识别问题。接着，基于对真实群体互动的观察，开发了一种名为AnchorRadar的半监督学习方法。该方法能够利用有标签和无标签的群体数据，解决了标签数据稀疏的挑战。

Result: 在13个真实数据集上的广泛实验表明，AnchorRadar在准确性和效率方面均优于多种基线方法。实验结果显示，AnchorRadar在群体锚点识别任务上的准确率通常更高，并且在训练时间上比最快的基线方法快10.2倍，在可学习参数量上比最轻量级的基线方法平均少43.6倍。

Conclusion: AnchorRadar是一种快速有效的群体锚点识别方法，在标签数据稀疏的现实场景中表现出显著的优越性，并且在准确性和效率方面均超越了现有技术。

Abstract: Group interactions occur in various real-world contexts, e.g., co-authorship,
email communication, and online Q&A. In each group, there is often a
particularly significant member, around whom the group is formed. Examples
include the first or last author of a paper, the sender of an email, and the
questioner in a Q&A session. In this work, we discuss the existence of such
individuals in real-world group interactions. We call such individuals group
anchors and study the problem of identifying them. First, we introduce the
concept of group anchors and the identification problem. Then, we discuss our
observations on group anchors in real-world group interactions. Based on our
observations, we develop AnchorRadar, a fast and effective method for group
anchor identification under realistic settings with label scarcity, i.e., when
only a few groups have known anchors. AnchorRadar is a semi-supervised method
using information from groups both with and without known group anchors.
Finally, through extensive experiments on thirteen real-world datasets, we
demonstrate the empirical superiority of AnchorRadar over various baselines
w.r.t. accuracy and efficiency. In most cases, AnchorRadar achieves higher
accuracy in group anchor identification than all the baselines, while using
10.2$\times$ less training time than the fastest baseline and 43.6$\times$
fewer learnable parameters than the most lightweight baseline on average.

</details>


### [376] [Influence of the majority group on individual judgments in online spontaneous conversations](https://arxiv.org/abs/2509.21092)
*Diletta Goglia,Davide Vega,Alessio Gandelli*

Main category: cs.SI

TL;DR: 在线匿名对话中，个体在暴露于群体意见后会表现出反从众行为，即在维持群体对判断的整体倾向的同时，会从群体立场上有所分歧，并且在信息公开后使用更有说服力的语言。


<details>
  <summary>Details</summary>
Motivation: 研究多数群体如何影响匿名、自发性在线对话中个体的判断形成和表达，并借鉴社会从众和反从众理论。

Method: 分析社交媒体上讨论的日常困境，通过数字痕迹操作化判断，衡量对话分歧，并使用贝叶斯回归捕捉暴露于群体意见前后的判断形成变化，最后通过语言学分析来分析判断表达的变化。

Result: 个体在暴露于群体意见后，会维持群体判断的整体倾向（无论是积极还是消极），但会偏离群体的具体立场，并且在信息公开后，使用说服性语言的比例会增加。

Conclusion: 在线环境与线下环境相比，会重塑社会影响的模式，个体在匿名在线对话中倾向于表现出反从众行为。

Abstract: This study investigates how the majority group influences individual judgment
formation and expression in anonymous, spontaneous online conversations.
Drawing on theories of social conformity and anti-conformity, we analyze
everyday dilemmas discussed on social media. First, using digital traces to
operationalize judgments, we measure the conversations' disagreement and apply
Bayesian regression to capture shifts of judgments formation before and after
the group's exposure. Then we analyze changes in judgment expression with a
linguistic analysis of the motivations associated with each judgment. Results
show systematic anti-conformity behaviors: individuals preserve the majority's
positive or negative orientation of judgments but diverge from its stance, with
persuasive language increasing post-disclosure. Our findings highlight how
online environments reshape social influence compared to offline contexts.

</details>


### [377] [AI-Enhanced Multi-Dimensional Measurement of Technological Convergence through Heterogeneous Graph and Semantic Learning](https://arxiv.org/abs/2509.21187)
*Siming Deng,Runsong Jia,Chunjuan Luan,Mengjia Wu,Yi Zhang*

Main category: cs.SI

TL;DR: 该研究提出了一个技术融合指数（TCI）来衡量技术融合的深度和广度，解决了现有衡量方法的挑战。


<details>
  <summary>Details</summary>
Motivation: 技术融合是创新的主流趋势，但准确衡量其融合程度一直是一个挑战，因为技术融合具有多维度和不断变化的特性。

Method: 通过结合IPC文本描述、专利元数据、异构图结构、异构图Transformer和Sentence-BERT来计算融合深度；利用香农多样性指数计算融合广度；最后使用熵权法结合两者得到TCI。

Result: 提出的TCI相比现有方法具有优势，并通过专利质量指标进行验证，证明了其经验可靠性。

Conclusion: 该研究提出的多维度方法为管理新兴跨领域技术的创新政策和行业策略提供了有价值的实践见解。

Abstract: Technological convergence refers to the phenomenon where boundaries between
technological areas and disciplines are increasingly blurred. It enables the
integration of previously distinct domains and has become a mainstream trend in
today's innovation process. However, accurately measuring technological
convergence remains a persistent challenge due to its inherently
multidimensional and evolving nature. This study designs an Technological
Convergence Index (TCI) that comprehensively measures convergence along two
fundamental dimensions: depth and breadth. For depth calculation, we use IPC
textual descriptions as the analytical foundation and enhance this assessment
by incorporating supplementary patent metadata into a heterogeneous graph
structure. This graph is then modeled using Heterogeneous Graph Transformers in
combination with Sentence-BERT, enabling a precise representation of knowledge
integration across technological boundaries. Complementing this, the breadth
dimension captures the diversity of technological fields involved, quantified
through the Shannon Diversity Index to measure the variety of technological
combinations within patents. Our final TCI is constructed using the Entropy
Weight Method, which objectively assigns weights to both dimensions based on
their information entropy. To validate our approach, we compare the proposed
TCI against established convergence measures, demonstrating its comparative
advantages. We further establish empirical reliability through a novel
robustness test that regresses TCI against indicators of patent quality. These
findings are further substantiated through comprehensive robustness checks. Our
multidimensional approach provides valuable practical insights for innovation
policy and industry strategies in managing emerging cross-domain technologies.

</details>


### [378] [Evading Overlapping Community Detection via Proxy Node Injection](https://arxiv.org/abs/2509.21211)
*Dario Loi,Matteo Silvestri,Fabrizio Silvestri,Gabriele Tolomei*

Main category: cs.SI

TL;DR: 本文提出了一种基于深度强化学习的方法来解决重叠社区中的社区成员隐藏问题，以保护用户隐私，同时尽量保持图的拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私保护方法在重叠社区中效果不佳，需要一种新的方法来隐藏目标节点的社区成员身份，同时保持图的拓扑结构。

Method: 提出了一种深度强化学习（DRL）方法，该方法通过学习有效的修改策略（包括使用代理节点）来实现社区成员隐藏，并在此过程中保持图结构。

Result: 实验结果表明，该方法在真实数据集上显著优于现有基线方法，无论是在有效性还是效率方面。

Conclusion: 该研究首次在重叠社区的背景下形式化并解决了社区成员隐藏问题，并提出了一种有效的DRL方法，为隐私保护图修改提供了新的解决方案。

Abstract: Protecting privacy in social graphs requires preventing sensitive
information, such as community affiliations, from being inferred by graph
analysis, without substantially altering the graph topology. We address this
through the problem of \emph{community membership hiding} (CMH), which seeks
edge modifications that cause a target node to exit its original community,
regardless of the detection algorithm employed. Prior work has focused on
non-overlapping community detection, where trivial strategies often suffice,
but real-world graphs are better modeled by overlapping communities, where such
strategies fail. To the best of our knowledge, we are the first to formalize
and address CMH in this setting. In this work, we propose a deep reinforcement
learning (DRL) approach that learns effective modification policies, including
the use of proxy nodes, while preserving graph structure. Experiments on
real-world datasets show that our method significantly outperforms existing
baselines in both effectiveness and efficiency, offering a principled tool for
privacy-preserving graph modification with overlapping communities.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [379] [Actively Learning Halfspaces without Synthetic Data](https://arxiv.org/abs/2509.20848)
*Hadley Black,Kasper Green Larsen,Arya Mazumdar,Barna Saha,Geelon So*

Main category: cs.DS

TL;DR: 本研究旨在解决在无法合成任意查询点的情况下学习半空间的问题，并针对法向量来自固定集合的情况设计了高效算法，取得了理论最优的查询复杂度和近乎最优的PAC学习复杂度。


<details>
  <summary>Details</summary>
Motivation: 经典点定位问题虽然有高效算法，但需要查询任意点。在无法进行任意点查询的情况下，存在查询次数的下限。本研究旨在设计无点合成的学习半空间的高效算法。

Method: 利用法向量来自固定集合的特性，通过并行二分搜索来利用序结构，而不是逐个处理序。这种方法解决了在无点合成限制下学习半空间的问题。

Result: 在法向量来自大小为D的集合的情况下，取得了$\\(D + \\\log n)$的查询复杂度，并得到了轴对齐半空间问题的最优\\(O(d + \\\log n))查询学习算法。此外，还获得了近乎最优的PAC学习算法，查询复杂度为\\(O(\\\min(D + \\\log(1/\\\	ext{epsilon}), 1/\\\	ext{epsilon})) 	imes oln(D))。))

Conclusion: 本研究提出的利用序结构进行并行二分搜索的方法，不仅解决了无点合成下学习半空间的问题，并得到了最优或近乎最优的理论界，还可能对更广泛的布尔函数学习问题具有参考意义。

Abstract: In the classic point location problem, one is given an arbitrary dataset $X
\subset \mathbb{R}^d$ of $n$ points with query access to an unknown halfspace
$f : \mathbb{R}^d \to \{0,1\}$, and the goal is to learn the label of every
point in $X$. This problem is extremely well-studied and a nearly-optimal
$\widetilde{O}(d \log n)$ query algorithm is known due to
Hopkins-Kane-Lovett-Mahajan (FOCS 2020). However, their algorithm is granted
the power to query arbitrary points outside of $X$ (point synthesis), and in
fact without this power there is an $\Omega(n)$ query lower bound due to
Dasgupta (NeurIPS 2004).
  In this work our goal is to design efficient algorithms for learning
halfspaces without point synthesis. To circumvent the $\Omega(n)$ lower bound,
we consider learning halfspaces whose normal vectors come from a set of size
$D$, and show tight bounds of $\Theta(D + \log n)$. As a corollary, we obtain
an optimal $O(d + \log n)$ query deterministic learner for axis-aligned
halfspaces, closing a previous gap of $O(d \log n)$ vs. $\Omega(d + \log n)$.
In fact, our algorithm solves the more general problem of learning a Boolean
function $f$ over $n$ elements which is monotone under at least one of $D$
provided orderings. Our technical insight is to exploit the structure in these
orderings to perform a binary search in parallel rather than considering each
ordering sequentially, and we believe our approach may be of broader interest.
  Furthermore, we use our exact learning algorithm to obtain nearly optimal
algorithms for PAC-learning. We show that $O(\min(D + \log(1/\varepsilon),
1/\varepsilon) \cdot \log D)$ queries suffice to learn $f$ within error
$\varepsilon$, even in a setting when $f$ can be adversarially corrupted on a
$c\varepsilon$-fraction of points, for a sufficiently small constant $c$. This
bound is optimal up to a $\log D$ factor, including in the realizable setting.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [380] [Pedagogically Motivated and Composable Open-Source RISC-V Processors for Computer Science Education](https://arxiv.org/abs/2509.20514)
*Ian McDougall,Harish Batchu,Michael Davies,Karthikeyan Sankaralingam*

Main category: cs.AR

TL;DR: RISC-V 架构的开源和免费特性使其在教学和业余领域具有巨大潜力。本文提出了评估 RISC-V 实现生态系统教学组件的标准，分析了现有开源实现，并开发了一个满足所有标准且可组合的开源解决方案，最后报告了学生反馈。


<details>
  <summary>Details</summary>
Motivation: 大多数指令集架构（ISA）都需要购买商业许可才能使用，而 RISC-V ISA 提供了一个免费且开源的替代方案。因此，人们开发了许多免费且开源的 RISC-V 实现。如果能获得一个开源、易于使用且健壮的 RISC-V 实现，就可以轻松地将其用于教学和业余用途。

Method: 提出了一套从教学角度评估 RISC-V 实现生态系统组件的标准；分析了现有的开源 RISC-V 实现，以确定它们满足了多少标准；开发了一个满足所有标准且可组合的开源解决方案；报告了学生反馈的有限研究。

Result: 开发了一个满足所有教学标准且可组合的开源 RISC-V 解决方案，并收集了学生反馈。

Conclusion: 开源、易于使用的 RISC-V 实现可以轻松地应用于教学和业余领域。本文提出的解决方案满足了这一需求，并为其他教育工作者提供了便利。

Abstract: While most instruction set architectures (ISAs) are only available to use
through the purchase of a restrictive commercial license, the RISC-V ISA
presents a free and open-source alternative. Due to this availability, many
free and open-source implementations have been developed and can be accessed on
platforms such as GitHub. If an open source, easy-to-use, and robust RISC-V
implementation could be obtained, it could be easily adapted for pedagogical
and amateur use. In this work we accomplish three goals in relation to this
outlook. First, we propose a set of criteria for evaluating the components of a
RISC-V implementation's ecosystem from a pedagogical perspective. Second, we
analyze a number of existing open-source RISC-V implementations to determine
how many of the criteria they fulfill. We then develop a comprehensive solution
that meets all of these criterion and is released open-source for other
instructors to use. The framework is developed in a composable way that it's
different components can be disaggregated per individual course needs. Finally,
we also report on a limited study of student feedback.

</details>


### [381] [ZynqParrot: A Scale-Down Approach to Cycle-Accurate, FPGA-Accelerated Co-Emulation](https://arxiv.org/abs/2509.20543)
*Daniel Ruelas-Petrisko,Farzam Gilani,Anoop Mysore Nataraja,Zoe Taylor,Michael Taylor*

Main category: cs.AR

TL;DR: 缩减规模的方法可以比扩展规模或扩展硬件更准确、更快、更经济地对复杂的处理器设计进行建模和验证。


<details>
  <summary>Details</summary>
Motivation: 当前的处理器验证方法，如基于性能计数器的推断和微架构模拟，对于复杂的设计来说既昂贵又耗时，尤其是在处理长工作负载时，模拟是不可行的。

Method: 提出了一种“缩减规模”的方法，将复杂的系统分解为可独立原型化的子组件，并通过精心设计接口来确保被测设备（DUT）的无干扰。基于这种方法，开发了一个名为ZynqParrot的基于FPGA的建模平台，能够执行任意RTL设计的无干扰、周期精确的协同仿真。

Result: ZynqParrot平台能够以任意粒度验证功能和性能。通过案例研究，使用ZynqParrot分析了一个开源RISC-V处理器的全栈性能。

Conclusion: “缩减规模”的方法，以ZynqParrot平台为代表，为处理器建模和验证提供了一种比传统方法更准确、更快速、更经济的解决方案，能够应对复杂设计和长工作负载的挑战。

Abstract: As processors increase in complexity, costs grow even more rapidly, both for
functional verification and performance validation. Most often, silicon
characterizations comprise simple performance counters, which are aggregated
and separated to tell a story. Based on these inferences, performance engineers
employ microarchitectural simulation to inspect deeply into the core.
Unfortunately, dramatically longer runtimes make simulation infeasible for long
workloads.
  We propose a Scale-Down approach to modelling and validation. Rather than
up-sizing a prototyping platform to fit large and complex system designs, we
show that it can be more accurate, faster, and more economical to decompose a
system into manageable sub-components that can be prototyped independently. By
carefully designing the prototyping interface, it is possible to adhere to
strict non-interference of the Device Under Test (DUT). This allows architects
to have the best of both worlds: the speed of FPGA acceleration while
eliminating the inaccuracies of Scale-Out and the inherent costs of Scale-Up.
  In this work, we present ZynqParrot: a Scale-Down FPGA-based modelling
platform, capable of executing non-interfering, cycle-accurate co-emulations of
arbitrary RTL designs. ZynqParrot is capable of verifying functionality and
performance with arbitrary granularity. We also provide case studies using
ZynqParrot to analyze the full-stack performance of an open-source RISC-V
processor.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [382] [Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics](https://arxiv.org/abs/2509.20412)
*Kevin Bradley Dsouza,Graham Alexander Watt,Yuri Leonenko,Juan Moreno-Cruz*

Main category: cs.MA

TL;DR: ECHO-MIMIC是一个计算框架，通过发现紧凑、可执行的启发式方法和说服性原理，将集体行动中的全局复杂性转化为每个代理可处理的、结构良好的问题（WSP）。


<details>
  <summary>Details</summary>
Motivation: 集体行动问题，需要使个人激励与集体目标保持一致，是典型的结构不良问题（ISPs）。个人代理难以理解局部行动与全局结果之间的因果关系，利益相关者的目标常常发生冲突，并且没有单一、明确的算法可以将微观层面的选择与宏观层面的福利联系起来。

Method: 该框架分两个阶段进行：ECHO（从结果中进化启发式方法）演化编码候选行为策略的Python代码片段，而MIMIC（机制推断与信息传递以实现个体与集体的对齐）演化配套的自然语言消息，以激励代理采用这些策略。这两个阶段都采用大型语言模型驱动的进化搜索：LLM提出多样化且符合上下文的代码或文本变体，而群体层面的选择保留那些在模拟环境中最大化集体绩效的变体。

Result: 该框架在一个典型的农业景观管理ISP中得到证明，其中当地的农业决策影响着全球的生态连通性。结果表明，与基线相比，ECHO-MIMIC发现了高性能的启发式方法，并制作了定制的消息，成功地将模拟的农民行为与景观层面的生态目标对齐。

Conclusion: 通过将算法规则发现与定制化沟通相结合，ECHO-MIMIC将集体行动的认知负担转化为一套简单的代理级别指令，使先前结构不良的问题在实践中得以解决，并为可扩展、自适应的策略设计开辟了新途径。

Abstract: Collective action problems, which require aligning individual incentives with
collective goals, are classic examples of Ill-Structured Problems (ISPs). For
an individual agent, the causal links between local actions and global outcomes
are unclear, stakeholder objectives often conflict, and no single, clear
algorithm can bridge micro-level choices with macro-level welfare. We present
ECHO-MIMIC, a computational framework that converts this global complexity into
a tractable, Well-Structured Problem (WSP) for each agent by discovering
compact, executable heuristics and persuasive rationales. The framework
operates in two stages: ECHO (Evolutionary Crafting of Heuristics from
Outcomes) evolves snippets of Python code that encode candidate behavioral
policies, while MIMIC (Mechanism Inference & Messaging for
Individual-to-Collective Alignment) evolves companion natural language messages
that motivate agents to adopt those policies. Both phases employ a
large-language-model-driven evolutionary search: the LLM proposes diverse and
context-aware code or text variants, while population-level selection retains
those that maximize collective performance in a simulated environment. We
demonstrate this framework on a canonical ISP in agricultural landscape
management, where local farming decisions impact global ecological
connectivity. Results show that ECHO-MIMIC discovers high-performing heuristics
compared to baselines and crafts tailored messages that successfully align
simulated farmer behavior with landscape-level ecological goals. By coupling
algorithmic rule discovery with tailored communication, ECHO-MIMIC transforms
the cognitive burden of collective action into a simple set of agent-level
instructions, making previously ill-structured problems solvable in practice
and opening a new path toward scalable, adaptive policy design.

</details>


### [383] [RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows](https://arxiv.org/abs/2509.20490)
*Kai Zhang,Corey D Barrett,Jangwon Kim,Lichao Sun,Tara Taghavi,Krishnaram Kenthapadi*

Main category: cs.MA

TL;DR: RadAgents是一个多智能体框架，用于胸部X光(CXR)的解释，它将临床先验知识与面向任务的多模态推理相结合。该框架通过整合、验证和解决跨工具的不一致性来提高CXR解释的可靠性、透明度和与临床实践的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于智能体的方法在临床解释方面存在局限性，包括推理过程缺乏可解释性、未遵循临床指南、多模态证据融合不足以及未能检测和解决跨工具的不一致性。

Method: RadAgents提出了一种多智能体框架，该框架结合了临床先验知识与面向任务的多模态推理。此外，该框架还集成了基于检索的模态内和模态间证据融合、视觉基础和多模态检索来增强推理过程。

Result: RadAgents生成的解释更可靠、更透明，并与临床实践保持一致，同时还能解决模态内和模态间的不一致性。

Conclusion: RadAgents通过结合临床先验知识和面向任务的多模态推理，解决了现有CXR解释方法的局限性，提高了结果的可靠性、透明度和临床一致性。

Abstract: Agentic systems offer a potential path to solve complex clinical tasks
through collaboration among specialized agents, augmented by tool use and
external knowledge bases. Nevertheless, for chest X-ray (CXR) interpretation,
prevailing methods remain limited: (i) reasoning is frequently neither
clinically interpretable nor aligned with guidelines, reflecting mere
aggregation of tool outputs; (ii) multimodal evidence is insufficiently fused,
yielding text-only rationales that are not visually grounded; and (iii) systems
rarely detect or resolve cross-tool inconsistencies and provide no principled
verification mechanisms. To bridge the above gaps, we present RadAgents, a
multi-agent framework for CXR interpretation that couples clinical priors with
task-aware multimodal reasoning. In addition, we integrate grounding and
multimodal retrieval-augmentation to verify and resolve context conflicts,
resulting in outputs that are more reliable, transparent, and consistent with
clinical practice.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [384] [A Category Theoretic Approach to Approximate Game Theory](https://arxiv.org/abs/2509.20932)
*Neil Ghani*

Main category: cs.GT

TL;DR: 本篇论文使用范畴论开发了一种全新的近似博弈论方法，解决了精确博弈论在计算上可能过于困难或因不确定性而无法计算的问题。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，智能体如何做出决策是博弈论的核心问题。然而，在实际应用中，精确最优决策的计算可能非常困难甚至不可能。因此，研究近似最优决策（近似博弈论）具有重要的实际意义。

Method: 本文首先研究了“选择函数”，并开发了一个简单而稳健的近似均衡模型。随后，研究了选择函数的代数性质以及近似与选择函数组合结构的关系。在此基础上，将此方法成功应用于更高级的博弈论模型“开放博弈”。

Result: 本文成功地开发了一个基于范畴论的近似博弈论模型，并研究了其代数性质和组合结构。

Conclusion: 使用范畴论的方法为近似博弈论提供了一个新颖且有效的研究途径。

Abstract: This paper uses category theory to develop an entirely new approach to
approximate game theory. Game theory is the study of how different agents
within a multi-agent system take decisions. At its core, game theory asks what
an optimal decision is in a given scenario. Thus approximate game theory asks
what is an approximately optimal decision in a given scenario. This is
important in practice as -- just like in much of computing -- exact answers
maybe too difficult to compute or even impossible to compute given inherent
uncertainty in input.
  We consider first "Selection Functions" which are functions and develop a
simple yet robust model of approximate equilibria. We develop the algebraic
properties of approximation wrt selection functions and also relate
approximation to the compositional structure of selection functions. We then
repeat this process successfully for Open Games -- a more advanced model of
game theory.

</details>


### [385] [Efficient Kernelized Learning in Polyhedral Games Beyond Full-Information: From Colonel Blotto to Congestion Games](https://arxiv.org/abs/2509.20919)
*Andreas Kontogiannis,Vasilis Pollatos,Gabriele Farina,Panayotis Mertikopoulos,Ioannis Panageas*

Main category: cs.GT

TL;DR: 在多面体游戏中，特别是在 Colonel Blotto 和拥塞游戏中，存在一个关于有效学习粗略相关均衡（CCE）的挑战，尤其是在信息不完全的情况下。现有的方法在保证计算效率方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的学习粗略相关均衡（CCE）算法在信息不完全的多面体游戏中存在效率低下和运行时间复杂的问题。

Method: 提出一个基于核化范式的框架，并将其应用于 Colonel Blotto、图基数和网络拥塞游戏，开发出计算上高效的基于收益的学习算法。

Result: 所提出的基于核化范式的框架在 Colonel Blotto、图基数和网络拥塞游戏中，显著提高了学习 CCE 的运行时间效率。

Conclusion: 通过引入基于核化范式的框架，成功地解决了信息不完全的多面体游戏中学习 CCE 的效率问题，并为 Colonel Blotto、图基数和网络拥塞游戏提供了改进的学习算法。

Abstract: We examine the problem of efficiently learning coarse correlated equilibria
(CCE) in polyhedral games, that is, normal-form games with an exponentially
large number of actions per player and an underlying combinatorial structure.
Prominent examples of such games are the classical Colonel Blotto and
congestion games. To achieve computational efficiency, the learning algorithms
must exhibit regret and per-iteration complexity that scale polylogarithmically
in the size of the players' action sets. This challenge has recently been
addressed in the full-information setting, primarily through the use of
kernelization. However, in the case of the realistic, but mathematically
challenging, partial-information setting, existing approaches result in
suboptimal and impractical runtime complexity to learn CCE. We tackle this
limitation by building a framework based on the kernelization paradigm. We
apply this framework to prominent examples of polyhedral games -- namely the
Colonel Blotto, graphic matroid and network congestion games -- and provide
computationally efficient payoff-based learning algorithms, which significantly
improve upon prior works in terms of the runtime for learning CCE in these
settings.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [386] [A Unified Formal Theory on the Logical Limits of Symbol Grounding](https://arxiv.org/abs/2509.20409)
*Zhangchi Liu*

Main category: cs.LO

TL;DR: 该研究通过形式化证明，探讨了符号接地问题的逻辑局限性，得出结论：符号系统的意义必须来源于外部、动态且非算法的过程。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决符号接地问题，即形式系统如何获得意义，并为这个问题提供一个统一的理论基础。

Method: 通过四阶段的形式化论证：1. 证明纯粹的符号系统无法在内部建立有意义的连接；2. 证明有限的、静态的预设意义集合是不完整的；3. 证明符号与外部意义的连接是一种公理化的、元级别的更新，而非逻辑推理；4. 证明自动化该更新过程的算法也会导致更大的不完整系统。

Result: 形式证明了任何自包含的智能系统都存在一个类似哥德尔式的局限性，即意义的接地是一个必然的开放式、非算法过程。

Conclusion: 符号系统的意义必须来源于外部、动态且非算法的过程，这揭示了任何自包含的智能系统的根本局限性。

Abstract: This paper synthesizes a series of formal proofs to construct a unified
theory on the logical limits of the Symbol Grounding Problem. We demonstrate
through a four-stage argument that meaning within a formal system must arise
from a process that is external, dynamic, and non-algorithmic. First, we prove
that any purely symbolic system, devoid of external connections, cannot
internally establish a consistent foundation for meaning due to
self-referential paradoxes. Second, we extend this limitation to systems with
any finite, static set of pre-established meanings, proving they are inherently
incomplete. Third, we demonstrate that the very "act" of connecting an internal
symbol to an external meaning cannot be a product of logical inference within
the system but must be an axiomatic, meta-level update. Finally, we prove that
any attempt to automate this update process using a fixed, external "judgment"
algorithm will inevitably construct a larger, yet equally incomplete, symbolic
system. Together, these conclusions formally establish that the grounding of
meaning is a necessarily open-ended, non-algorithmic process, revealing a
fundamental, G\"odel-style limitation for any self-contained intelligent
system.

</details>


### [387] [Reverse Faà di Bruno's Formula for Cartesian Reverse Differential Categories](https://arxiv.org/abs/2509.20931)
*Aaron Biggin,Jean-Simon Pacaud Lemay*

Main category: cs.LO

TL;DR: 本文提出了笛卡尔逆微分范畴中的 Faa di Bruno 公式，这是高阶逆链式法则。


<details>
  <summary>Details</summary>
Motivation: 需要为自动微分中的逆向微分运算提供一个高阶的逆链式法则，特别是 Faa di Bruno 公式在笛卡尔逆微分范畴中的类似物。

Method: 在笛卡尔逆微分范畴中定义了部分逆导数和高阶逆导数，并以此为基础推导 Faa di Bruno 公式。

Result: 成功地在笛卡尔逆微分范畴中定义了 Faa di Bruno 公式，实现了高阶逆链式法则。

Conclusion: 所提出的 Faa di Bruno 公式为笛卡尔逆微分范畴提供了高阶逆链式法则，完善了该理论框架。

Abstract: Reverse differentiation is an essential operation for automatic
differentiation. Cartesian reverse differential categories axiomatize reverse
differentiation in a categorical framework, where one of the primary axioms is
the reverse chain rule, which is the formula that expresses the reverse
derivative of a composition. Here, we present the reverse differential analogue
of Faa di Bruno's Formula, which gives a higher-order reverse chain rule in a
Cartesian reverse differential category. To properly do so, we also define
partial reverse derivatives and higher-order reverse derivatives in a Cartesian
reverse differential category.

</details>


### [388] [A Coalgebraic Model of Quantum Bisimulation](https://arxiv.org/abs/2509.20933)
*Lorenzo Ceragioli,Elena Di Lavore,Giuseppe Lomurno,Gabriele Tedeschi*

Main category: cs.LO

TL;DR: 使用通用效应代数上的分布的协代数来对量子系统进行建模，并引入了用于处理量子资源和过程组合的特定数学结构。


<details>
  <summary>Details</summary>
Motivation: 定义与量子能力、并发和非确定性系统相匹配的行为等价性具有挑战性。

Method: 在通用效应代数上的分布上进行协代数建模，并引入了基于偏交换幺半群的单子，以满足量子理论的性质（例如，无克隆定理）。分析了开放量子系统与其概率对应物之间的关系，并比较了 Aczel-Mendler 和核双模拟。

Result: 核双模拟被认为是表征具有相同概率行为的量子系统的更好方法。提出了量子效应标记转换系统的算子。

Conclusion: 该研究为过程演算语义学奠定了基础，该语义学允许参数化量子输入，并为处理量子系统的行为等价性提供了新的方法。

Abstract: Recent works have shown that defining a behavioural equivalence that matches
the observational properties of a quantum-capable, concurrent,
non-deterministic system is a surprisingly difficult task. We explore
coalgebras over distributions taking weights from a generic effect algebra,
which subsumes probabilities and quantum effects, a physical formalism that
represents the probabilistic behaviour of an open quantum system. To abide by
the properties of quantum theory, we introduce monads graded on a partial
commutative monoid, intuitively allowing composition of two processes only if
they use different quantum resources, as prescribed by the no-cloning theorem.
We investigate the relation between an open quantum system and its
probabilistic counterparts obtained when instantiating the input with a
specific quantum state. We consider Aczel-Mendler and kernel bisimilarities,
advocating for the latter as it characterizes quantum systems that exhibit the
same probabilistic behaviour for all input states. Finally, we propose
operators on quantum effect labelled transition systems, paving the way for a
process calculi semantics that is parametric over the quantum input.

</details>


<div id='cs.SY'></div>

# cs.SY [[Back]](#toc)

### [389] [Fractional Logistic Growth with Memory Effects: A Tool for Industry-Oriented Modeling](https://arxiv.org/abs/2509.20389)
*M. O. Aibinu,A. Shoukat,F. M. Mahomed*

Main category: cs.SY

TL;DR: A fractional logistic growth model with proportional delay is presented, solved using the HSV method, and shows the impact of fractional order and delay on growth dynamics.


<details>
  <summary>Details</summary>
Motivation: The classical logistic growth model is extended to capture memory-dependent and nonlocal dynamics using Atangana-Baleanu in Caputo sense (ABC)-type fractional derivatives and proportional time delay, offering more flexibility for complex systems.

Method: The study employs the Hybrid Sumudu Variational (HSV) method to derive semi-analytical solutions for the generalized fractional logistic growth model with proportional delay.

Result: The results demonstrate the significant influence of both the fractional order and the proportional delay on the behavior of the logistic growth system.

Conclusion: The integration of ABC-type fractional derivatives, proportional delay, and HSV-based solutions provides a novel and flexible framework for analyzing complex growth phenomena in various real-world applications.

Abstract: The logistic growth model is a classical framework for describing constrained
growth phenomena, widely applied in areas such as population dynamics,
epidemiology, and resource management. This study presents a generalized
extension using Atangana-Baleanu in Caputo sense (ABC)-type fractional
derivatives. Proportional time delay is also included, allowing the model to
capture memory-dependent and nonlocal dynamics not addressed in classical
formulations. Free parameters provide flexibility for modeling complex growth
in industrial, medical, and social systems. The Hybrid Sumudu Variational (HSV)
method is employed to efficiently obtain semi-analytical solutions. Results
highlight the combined effects of fractional order and delay on system
behavior. This approach demonstrates the novelty of integrating ABC-type
derivatives, proportional delay, and HSV-based solutions for real-world
applications.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [390] [Electron-beam-controlled volatile nanomechanical bistability](https://arxiv.org/abs/2509.20564)
*Toji Thomas,Kevin F. MacDonald,Eric Plum*

Main category: physics.app-ph

TL;DR: bistable oscillation of nanomechanical resonator can be controlled by electron beam


<details>
  <summary>Details</summary>
Motivation: Bistability in nanomechanical resonators can be exploited for sensing, signal processing, and memory applications due to its potential for switching and high sensitivity to external stimuli.

Method: External vibration is used to drive a doubly-clamped nanowire into the nonlinear regime of bistable oscillation. The bistable oscillation is controlled, switched and read by an electron beam.

Result: The bistable oscillation of a nonlinear nanomechanical resonator can be controlled, switched and read by an electron beam.

Conclusion: The bistable oscillation of a nonlinear nanomechanical resonator can be controlled, switched and read by an electron beam.

Abstract: Bistability in nanomechanical resonators can be exploited for sensing, signal
processing, and memory applications due to its potential for switching and high
sensitivity to external stimuli. External vibration can be used to drive a
doubly-clamped nanowire into the nonlinear regime of bistable oscillation.
Here, we experimentally demonstrate that the bistable oscillation of such a
nonlinear nanomechanical resonator can be controlled, switched and read by an
electron beam.

</details>


### [391] [Hysteresis Measurements as a Diagnostic Tool: A Systematic Approach for Stability Benchmarking and Performance Projection of 2D-Materials-Based MOSFETs](https://arxiv.org/abs/2509.21315)
*Alexander Karl,Dominic Waldhoer,Theresia Knobloch,Axel Verdianu,Joël Kurzweil,Mina Bahrami,Mohammad Rasool Davoudi,Pedram Khakbaz,Bernhard Stampfer,Seyed Mehdi Sattari-Esfahlan,Yury Illarionov,Aftab Nazir,Changze Liu,Saptarshi Das,Xiao Renshaw Wang,Junchuan Tang,Yichi Zhang,Congwei Tan,Ye Li,Hailin Peng,Michael Waltl,Tibor Grasser*

Main category: physics.app-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Judging by its omnipresence in the literature, the hysteresis observed in the
transfer characteristics of emerging transistors based on 2D-materials is
widely accepted as an important metric related to the device quality. The
hysteresis is often reported with attributes like "negligible" or "small"
without giving any specifics as to how this was determined and against what
reference the measured values were compared to. Quite surprisingly, there
appears to be only a fragmentary understanding of the mechanisms actually
contributing to hysteresis and the sensitivity of the actual measurement on
various experimental parameters. We attempt to close this gap by first
providing a comprehensive theoretical analysis of the dominant mechanisms
contributing to hysteresis: charge trapping by defects from the channel or the
gate, the drift of mobile charges, and eventually ferroelectricity. We continue
by suggesting methods to experimentally distinguishing between these phenomena.
Based on these discussions it becomes clear that previously reported hysteresis
values have little meaning as they have been non-systematically recorded under
arbitrary conditions. In order to resolve this predicament, we propose a
standardized hysteresis measurement scheme to establish the hysteresis as a
comparable metric for the assessment of device stability. Our standardized
scheme ensures that hysteresis data can be effectively compared across
different technologies and, most importantly, provide a means to extrapolate
data obtained on thicker prototypes to subnanometer equivalent oxide
thicknesses. This facilitates the systematic benchmarking of insulator/channel
combinations in terms of stability, which thereby enables the screening of
material systems for more stable and reliable 2D-material-based MOSFETs.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [392] [Ge as an ideal orbitronic platform: giant orbital Hall effect](https://arxiv.org/abs/2509.20436)
*James H. Cullen,Zhanning Wang,Dimitrie Culcer*

Main category: cond-mat.mes-hall

TL;DR: Ge材料在轨道转矩器件中具有巨大潜力，可用于制造更快速、更高效的磁性存储元件。


<details>
  <summary>Details</summary>
Motivation: 开发更快速、更高效的磁性存储元件，并寻找具有强轨道动力学的"orbitronic"材料。

Method: 利用Luttinger模型和现代轨道磁化理论，并结合近期发现的轨道霍尔效应的量子修正。

Result: 发现块体Ge中的空穴表现出巨大的轨道霍尔效应（OHE），其效应值超过了拓扑绝缘体的块体态，并且比自旋霍尔效应大四倍数量级。

Conclusion: 块体Ge是研究轨道转矩的理想平台，可以指导未来在磁性器件中使用Ge制造强轨道转矩的实验工作。

Abstract: State-of-the-art developments in magnetic devices rely on manufacturing
faster, more efficient memory elements. A significant development in this
direction has been the discovery of orbital torques, which employ the orbital
angular momentum of Bloch electrons to switch the magnetisation of an adjacent
ferromagnet, and has motivated the search for \textit{orbitronic} materials
displaying strong orbital dynamics exemplified, by the orbital Hall effect
(OHE). In this work we propose Ge, as an optimal orbitronic platform. We
demonstrate that holes in bulk Ge exhibit a giant OHE, exceeding that of the
bulk states of topological insulators, and exceeding the spin-Hall effect by
four orders of magnitude. The calculation is performed within the framework of
the Luttinger model and the modern theory of orbital magnetisation, while
incorporating recently-discovered quantum corrections to the OHE. Our study
constitutes a fundamental milestone in applying the modern theory to a system
with \textit{inversion symmetry}. Moreover, we argue that bulk Ge serves as an
ideal testbed for the orbital torque resulting from a charge current, since the
spin- and orbital-Edelstein effects in Ge are forbidden by symmetry. Our
results provide a blueprint for producing strong orbital torques in magnetic
devices with Ge, guiding future experimental work in this direction.

</details>


### [393] [Anomalous Landau Levels in Inhomogeneous Fluxes and Emergent Supersymmetry](https://arxiv.org/abs/2509.20462)
*Soujanya Datta,Krishanu Roychowdhury*

Main category: cond-mat.mes-hall

TL;DR: 奇异平坦带在不均匀磁场下的响应，揭示了可控操纵异常朗道能级的新机制，并发现了零能模的超对称性。


<details>
  <summary>Details</summary>
Motivation: 研究奇异平坦带在不均匀磁场下的响应，探索控制异常朗道能级的方法，并揭示相关的涌现物理现象。

Method: 结合连续和晶格描述，分析了奇异平坦带对不均匀磁通量的响应，并发现了超对称性。

Result: 揭示了通过磁通量不均匀性可控操纵异常朗道能级的新机制，发现了零能模的超对称性，并将其与Aharonov-Casher定理联系起来。

Conclusion: 研究结果为实现奇异的拓扑和电荷有序相提供了理论基础，并可能对相关凝聚态物理领域产生影响。

Abstract: Two-dimensional systems in magnetic fields host rich physics, most notably
the quantum Hall effect arising from Landau level quantization. In a broad
class of two-dimensional models, flat bands with topologically nontrivial band
degeneracies give rise to anomalous Landau level quantization under homogeneous
fields. Ascribed to the underlying quantum geometry, these are classified as
singular flat bands, exhibiting unusual wavefunction localization, and
anomalous quantization of Landau levels. We investigate the response of gapless
singular flat bands to inhomogeneous fluxes, bridging continuum and lattice
descriptions. Our analysis reveals a mechanism to controllably manipulate the
anomalous Landau levels via flux inhomogeneity. We further uncover an emergent
supersymmetry in the parameter space where the tower of anomalous Landau levels
collapses to zero energy, rendering a lattice analog of the Aharonov-Casher
theorem on degenerate zero modes in perpendicular fluxes, with wavefunction
localization partly similar to Aharonov-Bohm caging. With the addition of
strong correlations, these findings will have implications for realizing exotic
topological and charge-ordered phases.

</details>


### [394] [Magnon-magnon coupling efficiency of $η$=0.5 in weakly pinned synthetic antiferromagnets](https://arxiv.org/abs/2509.20487)
*Dirk Backes*

Main category: cond-mat.mes-hall

TL;DR: 合成反铁磁体（SAFs）的钉扎层可实现高效的声学和光学磁振子模式激发，无需实验误差或修改材料特性，并表现出强烈的磁振子-磁振子耦合和磁振子能带隙，适用于室温量子磁振子应用。


<details>
  <summary>Details</summary>
Motivation: 需要对称性破缺才能同时激发合成反铁磁体（SAFs）中的声学和光学磁振子模式，这通常通过实验误差或改变材料特性实现。

Method: 利用钉扎合成反铁磁体（pSAF），其中一个铁磁层与反铁磁体发生交换耦合。通过调整反铁磁体的厚度并轻微增强钉扎层的磁各向异性，同时激发声学和光学模式。

Result: 成功激发了声学和光学磁振子模式，且无需实验误差或修改材料特性。在特定条件下，磁振子色散关系表现出反交叉行为，产生了磁振子能带隙，耦合效率 $\eta$ 达到0.5，接近超强耦合。在室温下实现了大面积的强模式杂合、显著的磁振子能带隙和高铁磁共振（FMR）相干性。

Conclusion: 钉扎合成反铁磁体（pSAF）提供了一种无需低温或实验误差即可实现强磁振子-磁振子耦合、大磁振子能带隙和长FMR相干性的方法，在室温下实现了高效的声学和光学模式激发，证明了其在量子磁振子器件（如量子计算）中的应用潜力。

Abstract: Synthetic antiferromagnets (SAFs) consist of two ferromagnetic layers that
are antiferromagnetically coupled. These systems support complex dynamical
magnetic excitations, where interlayer coupling gives rise to both in-phase
(acoustic) and anti-phase (optical) magnonic modes. Typically, simultaneous
excitation of both modes requires breaking the symmetry between the
ferromagnetic layers -- commonly achieved through slight misalignment of the
experimental setup or by modifying the intrinsic magnetic properties. In our
approach, we utilize a pinned synthetic antiferromagnet (pSAF), where one of
the ferromagnetic layers is exchange-coupled to an antiferromagnet. We
demonstrate that by tuning the thickness of the antiferromagnet and slightly
enhancing the magnetic anisotropy of the pinned layer, both acoustic and
optical modes can be efficiently excited -- without the need for experimental
misalignment or changes to the intrinsic material properties. Under specific
conditions, the magnon dispersion relations exhibit anti-crossing behavior,
resulting in the emergence of a magnonic bandgap -- a clear signature of strong
magnon-magnon coupling. The coupling efficiency $\eta$, defined as the ratio
between the bandgap and the characteristic frequency, reaches $\eta = 0.5$,
approaching the ultra-strong coupling regime ($\eta = 1$). The combination of
strong mode hybridization, a sizable magnonic bandgap, and high ferromagnetic
resonance (FMR) coherence over large areas -- all achieved at room temperature
without cryogenic cooling -- underscores the potential of these systems for
quantum magnonic applications, including quantum computing.

</details>


### [395] [Classical and single photon memory devices based on polariton lasers](https://arxiv.org/abs/2509.20569)
*D. Novokreschenov,A. Kudlis,A. V. Kavokin*

Main category: cond-mat.mes-hall

TL;DR: 单个光子可以被用来引导和稳定极化激子-光子凝聚体，使其具有纳秒量级的极化记忆能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用种子光精确控制和维持激子-光子凝聚体的极化状态，实现有效的极化记忆。

Method: 使用半经典随机Gross-Pitaevskii模型，模拟了激子-光子凝聚体的形成和极化演化过程，并量化了种子光对凝聚体极化的影响。

Result: 模型显示，单个光子种子能够引导极化激子-光子凝聚体的极化方向，并使其在远超单个极化激子寿命的时间尺度上保持该方向，实现了纳秒量级的极化记忆。

Conclusion: 该研究提出的机制为实现基于激子-光子凝聚体的鲁棒极化记忆操作提供了理论基础，并在现实参数下验证了其可行性。

Abstract: Stimulated scattering of incoherent excitons into an exciton-polariton mode
leads to the build-up of a polariton condensate whose polarization is sensitive
to a small seeded population that triggers the stimulated process. We show,
within a semiclassical stochastic Gross-Pitaevskii model, that this mechanism
enables a robust polarization memory operation: the condensate tends to align
its Stokes vector with that of the seed and to maintain it for times far
exceeding an individual polariton lifetime. Importantly, this
single-photon-seeded regime is modeled as an initial weak excitation of the
condensate mode. We quantify the memory performance by a classical
polarization-alignment metric and find that the seed polarization can remain
well preserved on a nanosecond timescale under realistic parameters.

</details>


### [396] [Quantum metric induced nonlinear thermal noise in PT-symmetric antiferromagnets](https://arxiv.org/abs/2509.20647)
*Dibyanandan Bhowmick,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: 利用电流的内在涨落探测量子材料的带状几何结构。在PT对称反铁磁体中，第二阶电场效应下的量子度规决定了电流噪声，可用于探测量子度规。


<details>
  <summary>Details</summary>
Motivation: 电流涨落是一种探测量子材料带状几何结构的非常规但强大的方法。特别是，与弛豫时间无关的内在噪声成分可以揭示布洛赫电子普适的带状几何特性。

Method: 识别出第二阶电场效应下的内在电流噪声贡献，该贡献由量子度规控制。当存在PT对称性时，这种效应在反铁磁体中占主导地位，因为对称性禁止了基于贝里曲率的贡献。将该理论应用于CuMnAs，证明了热噪声可以作为PT对称反铁磁体中量子度规的直接信号。

Result: 在PT对称反铁磁体中，第二阶电场效应下的电流噪声由量子度规控制。在CuMnAs材料中，热噪声直接反映了量子度规。

Conclusion: 在PT对称反铁磁体中，热噪声可以作为探测量子度规的直接信号。

Abstract: Electrical current fluctuations provide a powerful and unconventional probe
of band geometry in quantum materials. In particular, intrinsic noise
components that are independent of the relaxation time reveal universal
band-geometric properties of Bloch electrons. Here, we identify a distinct
intrinsic contribution to current noise at second order in the electric field,
which is governed by the quantum metric. This effect arises from field-induced
modifications to Bloch wavefunctions and band energies, and it dominates in
PT-symmetric antiferromagnets where Berry curvature based contributions are
forbidden by symmetry. Applying our theory to CuMnAs, we demonstrate that
thermal noise provides a direct signature of quantum metric in PT-symmetric
antiferromagnets.

</details>


### [397] [Nontrivial topology in one- and two-dimensional asymmetric systems with chiral boundary states](https://arxiv.org/abs/2509.20834)
*Yunlin Li,Yufu Liu,Xuezhi Wang,Haoran Zhang,Xunya Jiang*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种研究一维和二维不对称系统拓扑性质的新理论，通过重新定义子格点，发现了新的手征边界态和角态，并建立了体-边对应关系，适用于更复杂的系统，并在声学实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 目前关于不对称系统拓扑性质的研究，尤其是在高维系统中，还比较有限。本文旨在探索新的理论方法来研究这些系统。

Method: 本文从SSHm模型出发，通过重新定义子格点来研究其边缘态的手征拓扑性质，并定义了一个新的拓扑不变量$ar{Z}$，建立了体-边对应关系。然后将该方法推广到更复杂的梯子模型和二维BBH3模型，发现了新的手征角态，并提出了计算拓扑不变量的方法。

Result: 在SSHm模型中，成功定义了新的拓扑不变量$ar{Z}$并建立了体-边对应关系。在BBH3模型中，发现了与空间对称性无关的、类似于拓扑束缚态（TBICs）的手征角态，并提出了二维的$ar{Z}$不变量计算方法。声学实验也验证了这些角态的存在。

Conclusion: 本文提出了一种研究不对称系统拓扑性质的新方法，通过重新定义子格点，揭示了不同结构模型可能具有相同的拓扑起源，并发现了新的手征边界态和角态。

Abstract: Symmetry plays an important role in the topological band theory. In contrary,
study on the topological properties of the asymmetric systems is rather
limited, especially in higher-dimensional systems. In this work, we explore a
new theory to study the topology in various one-dimensional (1D) and
two-dimensional (2D) asymmetric systems with chiral boundary states. Starting
from the simple SSHm model, we show the chiral topology of its edge states by
redefining sublattices. Meanwhile, based on its Rice-Mele-like effective
Hamiltonian, a new topological invariant $\bar{Z}$ can be defined and the
bulk-edge correspondence is established. With this clear physical picture, our
theory can be extended to the more complex asymmetric ladder models, or even
the 2D asymmetric systems. In the 2D BBH3 model, new chiral corner states with
redefined lattices are found based on our method. These corner states are
independent of any spatial symmetry and exhibit the characteristics of
topological bound states in the continuum (TBICs). Moreover, the topological
invariant can be calculated by introducing $\bar{Z}$ into 2D. At last, we
propose an acoustic experiment of the BBH3 model where chiral corner states are
numerically observed. Our work exhibits a new approach to study the topological
properties of asymmetric systems. By redefining sublattices, we find that the
models with entirely different structures might share the same topological
origins.

</details>


### [398] [Tracking spin qubit frequency variations over 912 days](https://arxiv.org/abs/2509.20990)
*Kenji Capannelli,Brennan Undseth,Irene Fernández de Fuentes,Eline Raymenants,Florian K. Unseld,Oriol Pietx-Casas,Stephan G. J. Philips,Mateusz T. Mądzik,Sergey V. Amitonov,Larysa Tryputen,Giordano Scappucci,Lieven M. K. Vandersypen*

Main category: cond-mat.mes-hall

TL;DR: 硅基自旋量子比特的频率在长达912天的时间里有高达±100MHz的漂移，但通过精确控制栅极电压（±15μV），漂移可控制在±7MHz以内（36天窗口）。


<details>
  <summary>Details</summary>
Motivation: 研究硅/硅锗量子点平台中自旋量子比特频率的稳定性，以理解和表征低频噪声。

Method: 实验测量了一个包含六个量子比特的设备在912天内的频率变化，并分析了电压设置和时间窗口对频率稳定性的影响。

Result: 发现在912天内，校准后的量子比特频率变化高达±100MHz。精确控制栅极电压（±15μV）可将36天内的频率变化限制在±7MHz以内。短期测量（1小时）显示频率标准差低于200kHz。频率噪声频谱密度在高于10^-4 Hz时呈现约1/f趋势，在更低频率下则呈现更陡峭的趋势。

Conclusion: 硅基自旋量子比特的频率稳定性受到环境噪声（特别是低频噪声）的影响，但通过精密控制栅极电压可以显著提高其稳定性。

Abstract: Solid-state qubits are sensitive to their microscopic environment, causing
the qubit properties to fluctuate on a wide range of timescales. The sub-Hz end
of the spectrum is usually dealt with by repeated background calibrations,
which bring considerable overhead. It is thus important to characterize and
understand the low-frequency variations of the relevant qubit characteristics.
In this study, we investigate the stability of spin qubit frequencies in the
Si/SiGe quantum dot platform. We find that the calibrated qubit frequencies of
a six-qubit device vary by up to $\pm 100$ MHz while performing a variety of
experiments over a span of 912 days. These variations are sensitive to the
precise voltage settings of the gate electrodes, however when these are kept
constant to within 15 $\mathrm{\mu}$V, the qubit frequencies vary by less than
$\pm 7$ MHz over periods up to 36 days. During overnight scans, the qubit
frequencies of ten qubits across two different devices show a standard
deviation below 200 kHz within a 1-hour time window. The qubit frequency noise
spectral density shows roughly a $1/f$ trend above $10^{-4}$ Hz and,
strikingly, a steeper trend at even lower frequencies.

</details>


### [399] [Spin band geometry drives intrinsic thermal spin magnetization and current](https://arxiv.org/abs/2509.21215)
*Sankar Sarkar,Harsh Varshney,Sayan Sarkar,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: 研究人员提出了一种基于自旋能带几何学的量子理论，用于在非磁性材料中通过热梯度产生自旋磁化和自旋流。


<details>
  <summary>Details</summary>
Motivation: 在没有磁场或电场的情况下产生自旋磁化和自旋流是自旋热电子学的一个关键前沿领域。由热梯度驱动的自旋响应提供了一条有前景的途径，但其内在机制的能带几何起源，特别是在非磁性材料中，仍然知之甚少。

Method: 提出了一种统一的量子理论，该理论基于具有费米面和费米海贡献的自旋能带几何学，用于研究行波电子中的热自旋磁化和自旋流。确定了两个关键的几何量：控制热自旋磁化的自旋速度度量张量，以及产生热自旋流的自旋几何张量（结合了自旋贝里曲率和自旋量子度量）。

Result: 研究人员进行的数值计算表明，在手征金属 RhGe 和反铁磁体 CuMnAs 中，近能带交叉处存在可观的热自旋响应。这些内在贡献在非磁性绝缘体中持续存在，甚至可能占据主导地位。

Conclusion: 该研究确立了热自旋输运的能带几何起源，并为发现和工程化下一代自旋热电子材料提供了指导原则。

Abstract: Generating spin magnetization and spin currents without magnetic or electric
fields is a key frontier in spin caloritronics. Spin responses driven by
thermal gradients offer a promising route, though the band geometric origin of
intrinsic mechanisms, especially in non-magnetic materials, remains poorly
understood. Here we develop a unified quantum theory of thermal spin
magnetization and spin currents in itinerant electrons, rooted in spin band
geometry with both Fermi-surface and Fermi-sea contributions. We identify two
key geometric quantities: the spin-velocity metric tensor, which governs
thermal spin magnetization, and the spin geometric tensor, combining spin Berry
curvature and spin quantum metric, which generates thermal spin currents. These
intrinsic contributions persist and can even dominate in non-magnetic
insulators. Numerical calculations for chiral metal RhGe and antiferromagnet
CuMnAs demonstrate sizable thermal spin responses near band crossings. Our
results establish the band geometric origin of thermal spin transport and
provide guiding principles for discovering and engineering next-generation spin
caloritronic materials.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [400] [Real-Time Markov Modeling for Single-Photon LiDAR: $1000 \times$ Acceleration and Convergence Analysis](https://arxiv.org/abs/2509.20500)
*Weijian Zhang,Hashan K. Weerasooriya,Prateek Chennuri,Stanley H. Chan*

Main category: eess.SP

TL;DR: 提出了一种新的非顺序马尔可夫模型来解决SP-LiDAR时间戳分布的建模问题，该模型通过重新参数化积分边界和分离死区时间效应，实现了高达1000倍的加速，并提供了更精确的收敛性分析。


<details>
  <summary>Details</summary>
Motivation: 现有的SP-LiDAR时间戳分布建模方法计算成本高昂，尤其是在考虑死区时间时。

Method: 提出了一种非顺序马尔可夫模型，通过重新参数化积分边界和将死区时间效应分离为确定性行置换，实现了高效的向量化矩阵构建。

Result: 新模型能以极短的时间生成近乎精确的稳态分布，并且通过理论分析揭示了第二大特征值对收敛性的影响。

Conclusion: 该模型为SP-LiDAR时间戳分布的建模提供了一种高效且精确的方法，并对模型收敛性进行了深入的理论分析。

Abstract: Asynchronous single-photon LiDAR (SP-LiDAR) is an important imaging modality
for high-quality 3D applications and navigation, but the modeling of the
timestamp distributions of a SP-LiDAR in the presence of dead time remains a
very challenging open problem. Prior works have shown that timestamps form a
discrete-time Markov chain, whose stationary distribution can be computed as
the leading left eigenvector of a large transition matrix. However,
constructing this matrix is known to be computationally expensive because of
the coupling between states and the dead time. This paper presents the first
non-sequential Markov modeling for the timestamp distribution. The key
innovation is an equivalent formulation that reparameterizes the integral
bounds and separates the effect of dead time as a deterministic row permutation
of a base matrix. This decoupling enables efficient vectorized matrix
construction, yielding up to $1000 \times$ acceleration over existing methods.
The new model produces a nearly exact stationary distribution when compared
with the gold standard Monte Carlo simulations, yet using a fraction of the
time. In addition, a new theoretical analysis reveals the impact of the
magnitude and phase of the second-largest eigenvalue, which are overlooked in
the literature but are critical to the convergence.

</details>


### [401] [Wireless Powered MEC Systems via Discrete Pinching Antennas: TDMA versus NOMA](https://arxiv.org/abs/2509.20908)
*Peng Liu,Zesong Fei,Meng Hua,Guangji Chen,Xinyi Wang,Ruiqi Liu*

Main category: eess.SP

TL;DR: 该论文研究了一种离散驻极体辅助无线供电移动边缘计算（MEC）框架，旨在通过优化PA（驻极体天线）激活策略来最大化计算任务卸载的总比特数，并比较了TDMA和NOMA两种接入方式下的性能。


<details>
  <summary>Details</summary>
Motivation: 将驻极体天线（PA）集成到无线供电移动边缘计算（MEC）系统中，以提高能量传输和任务卸载效率。

Method: 研究了一种离散PA辅助无线供电MEC框架，考虑了TDMA和NOMA两种接入方式，并探讨了不同PA激活灵活度下的性能。提出了一种结合KKT条件和交叉熵学习方法的两层优化算法来解决混合整数非线性规划问题。

Result: 数值结果表明，所提出的设计在收集的能量和计算性能方面均优于现有方法。在较粗粒度的PA激活水平下，TDMA和NOMA的性能相当；而在较细粒度的激活下，TDMA的计算性能优于NOMA。

Conclusion: 离散PA辅助无线供电MEC框架能够有效提高系统性能，并且在细粒度PA激活下，TDMA相较于NOMA具有更优的计算性能。

Abstract: Pinching antennas (PAs), a new type of reconfigurable and flexible antenna
structures, have recently attracted significant research interest due to their
ability to create line-of-sight links and mitigate large-scale path loss. Owing
to their potential benefits, integrating PAs into wireless powered mobile edge
computing (MEC) systems is regarded as a viable solution to enhance both energy
transfer and task offloading efficiency. Unlike prior studies that assume ideal
continuous PA placement along waveguides, this paper investigates a practical
discrete PA-assisted wireless powered MEC framework, where devices first
harvest energy from PA-emitted radio-frequency signals and then adopt a partial
offloading mode, allocating part of the harvested energy to local computing and
the remainder to uplink offloading. The uplink phase considers both the
time-division multiple access (TDMA) and non-orthogonal multiple access (NOMA),
each examined under three levels of PA activation flexibility. For each
configuration, we formulate a joint optimization problem to maximize the total
computational bits and conduct a theoretical performance comparison between the
TDMA and NOMA schemes. To address the resulting mixed-integer nonlinear
problems, we develop a two-layer algorithm that combines closed-form solutions
based on Karush-Kuhn-Tucker (KKT) conditions with a cross-entropy-based
learning method. Numerical results validate the superiority of the proposed
design in terms of the harvested energy and computation performance, revealing
that TDMA and NOMA achieve comparable performance under coarser PA activation
levels, whereas finer activation granularity enables TDMA to achieve superior
computation performance over NOMA.

</details>


### [402] [A General Optimization Framework for Movable Antenna Systems via Discrete Sampling](https://arxiv.org/abs/2509.20987)
*Changhao Liu,Weidong Mei,Zhi Chen,Jun Fang,Boyu Ning*

Main category: eess.SP

TL;DR: 本研究提出了一种低复杂度、可扩展的移动天线（MA）位置优化框架，通过将连续优化问题离散化并结合吉布斯采样（GS）来避免局部最优解，并在MA增强的广播系统中验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有MA系统优化方法存在计算复杂度高或易陷入局部最优解的问题，难以有效提升通信性能。

Method: 提出了一种新的MA位置优化框架，将连续优化问题转化为离散点选择问题，通过顺序更新和吉布斯采样（GS）来寻找最优解。

Result: 所提出的框架在MA增强的广播系统中实现了近乎最优的性能，并显著优于现有基准算法。

Conclusion: 所提出的低复杂度优化框架能够有效解决MA位置优化问题，并实现优异的性能。

Abstract: Movable antenna (MA) systems have attracted growing interest in wireless
communications due to their ability to reshape wireless channels via local
antenna movement within a confined region. However, optimizing antenna
positions to enhance communication performance turns out to be challenging due
to the highly nonlinear relationship between wireless channels and antenna
positions. Existing approaches, such as gradient-based and heuristic
algorithms, often suffer from high computational complexity or undesired local
optima. To address the above challenge, this letter proposes a general and
low-complexity optimization framework for MA position optimization.
Specifically, we discretize the antenna movement region into a set of sampling
points, thereby transforming the continuous optimization problem into a
discrete point selection problem. Next, we sequentially update the optimal
sampling point for each MA over multiple rounds. To avoid convergence to poor
local optima, a Gibbs sampling (GS) phase is introduced between rounds to
explore adjacent and randomly generated candidate solutions. As a case study,
we investigate joint precoding and antenna position optimization for an
MA-enhanced broadcast system by applying the proposed framework. Numerical
results demonstrate that the proposed algorithm achieves near-optimal
performance and significantly outperforms existing benchmarks.

</details>


### [403] [Shapley Features for Robust Signal Prediction in Tactile Internet](https://arxiv.org/abs/2509.21032)
*Mohammad Ali Vahedifar,Qi Zhang*

Main category: eess.SP

TL;DR: 使用高斯过程（GP）和残差网络（ResNet）的GP+SFV框架，结合Shapley特征值（SFV）进行特征选择，提高了触觉互联网（TI）中信号恢复的准确性和效率，解决了丢包和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 解决触觉互联网（TI）中超低延迟和可靠的触觉信号传输面临的丢包和延迟挑战。

Method: 提出GP+SFV框架，其中GP作为预言机恢复信号，SFV进行特征选择，并与ResNet结合。

Result: GP+SFV框架达到95.72%的准确率，比现有方法LeFo高11.1%。SFV单独使用可将LeFo的推理时间减少27%，将GP的推理时间减少72%。

Conclusion: GP+SFV框架在准确性和效率方面均表现出色，为TI系统中的实用和可靠的触觉通信铺平了道路。

Abstract: The Tactile Internet (TI) requires ultra-low latency and reliable haptic
signal transmission, yet packet loss and delay remain unresolved challenges. We
present a novel prediction framework that integrates Gaussian Processes (GP)
with a ResNet-based Neural Network, where GP acts as an oracle to recover
signals lost or heavily delayed. To further optimize performance, we introduce
Shapley Feature Values (SFV), a principled feature selection mechanism that
isolates the most informative inputs for prediction. This GP+SFV framework
achieves 95.72% accuracy, surpassing the state-of-the-art LeFo method by 11.1%,
while simultaneously relaxing TI's rigid delay constraints. Beyond accuracy,
SFV operates as a modular accelerator: when paired with LeFo, it reduces
inference time by 27%, and when paired with GP, by 72%. These results establish
GP+SFV as both a high-accuracy and high-efficiency solution, paving the way for
practical and reliable haptic communications in TI systems.

</details>


### [404] [Neural Integrated Sensing and Communication for the MIMO-OFDM Downlink](https://arxiv.org/abs/2509.21118)
*Ziyi Wang,Frederik Zumegen,Christoph Studer*

Main category: eess.SP

TL;DR: 本文提出了一种基于MIMO-OFDM下行链路的神经ISAC信号处理框架，通过测量反向散射通信信号来生成空间占用离散地图表示，实现了在不改变通信链路或降低数据率的情况下进行传感。


<details>
  <summary>Details</summary>
Motivation: 无线传感和通信日益增长的融合需求，以及利用数据驱动学习技术为通信基础设施增加传感能力的需求。

Method: 提出了一种新颖的信号处理框架，基于MIMO-OFDM下行链路，通过测量反向散射通信信号来生成离散的、可用于下游任务的空间占用地图表示，并设计了专门的特征来减轻反射路径的影响。

Result: 通过射线追踪模型的大量仿真表明，所提出的神经ISAC框架能够可靠地重建场景地图，同时不影响MIMO-OFDM通信管道或降低数据速率。

Conclusion: 所提出的神经ISAC框架能够有效地实现传感功能，而无需修改通信链路或牺牲通信性能，为下一代网络中的集成传感和通信提供了新的解决方案。

Abstract: The ongoing convergence of spectrum and hardware requirements for wireless
sensing and communication applications has fueled the integrated sensing and
communication (ISAC) paradigm in next-generation networks. Neural-network-based
ISAC leverages data-driven learning techniques to add sensing capabilities to
existing communication infrastructure. This paper presents a novel
signal-processing framework for such neural ISAC systems based on the
multiple-input multiple-output (MIMO) and orthogonal frequency-division
multiplexing (OFDM) downlink. Our approach enables generalized sensing
functionality without modifying the MIMO-OFDM communication link. Specifically,
our neural ISAC pipeline measures the backscattered communication signals to
generate discrete map representations of spatial occupancy, formulated as
multiclass or multilabel classification problems, which can then be utilized by
specialized downstream tasks. To improve sensing performance in closed or
cluttered environments, our neural ISAC pipeline relies on features
specifically designed to mitigate strong reflective paths. Extensive
simulations using ray-tracing models demonstrate that our neural ISAC framework
reliably reconstructs scene maps without altering the MIMO-OFDM communication
pipeline or reducing data rates.

</details>


### [405] [A Secure ISAC Waveform Design Framework via Random Frequency and PRI Agility](https://arxiv.org/abs/2509.21162)
*Ali Khandan Boroujeni,Hyeon Seok Rou,Ghazal Bagheri,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Kuranage Roche Rayan Ranasinghe,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 本论文提出了一种新的框架，用于增强集成传感和通信（ISAC）系统的安全性、数据速率和传感性能。


<details>
  <summary>Details</summary>
Motivation: ISAC系统面临安全、数据速率和传感性能的挑战。

Method: 本论文提出的方法包括：1. 随机频率和脉冲重复间隔（PRI）敏捷性（RFPA）方法进行波形设计，利用共享密钥来混淆雷达参数，以阻止被动窃听。2. 混合信息嵌入方案，集成幅度移相键控（ASK）、相位移键控（PSK）、索引调制（IM）和空间调制（SM），并提出低复杂度稀疏匹配滤波器接收机进行解码。3. 通过模糊度函数（AF）分析了所提出波形的范围-速度分辨率和杂波抑制能力。

Result: 该方法能够提高ISAC系统的安全性、数据速率和传感性能，并能有效进行杂波抑制。

Conclusion: 本论文提出了一种新颖的ISAC系统框架，通过RFPA和混合信息嵌入方案，在保证安全性的同时，提高了数据速率和传感性能。

Abstract: This paper presents a novel framework for enhancing the security, data rate,
and sensing performance of integrated sensing and communications (ISAC)
systems. We employ a random frequency and pulse repetition interval (PRI)
agility (RFPA) method for the waveform design, where the necessary random
sequences are governed by shared secrets. These secrets, which can be
pre-shared or generated via channel reciprocity, obfuscate critical radar
parameters like Doppler frequency and pulse start times, thereby significantly
impeding the ability to perform reconnaissance from a passive adversary without
the secret key. To further introduce enhanced data throughput, we also
introduce a hybrid information embedding scheme that integrates amplitude shift
keying (ASK), phase shift keying (PSK), index modulation (IM), and spatial
modulation (SM), for which a low-complexity sparse-matched filter receiver is
proposed for accurate decoding with practical complexity. Finally, the
excellent range-velocity resolution and clutter suppression of the proposed
waveform are analyzed via the ambiguity function (AF).

</details>


### [406] [Adversarially Robust MIMO Physical Layer Authentication for Non-Stationary Channels](https://arxiv.org/abs/2509.21171)
*Ali Khandan Boroujeni,Ghazal Bagheri,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 提出了一种针对非平稳MIMO无线信道的对抗性鲁棒物理层认证（AR-PLA）框架。


<details>
  <summary>Details</summary>
Motivation: 传统的认证方法假设信道平稳或观测独立，无法处理非平稳MIMO信道中的时空相关性、视距（LoS）阻塞和动态欺骗策略。

Method: 该框架集成了顺序贝叶斯决策、通过对比学习进行的深度特征提取以及生成对抗建模来模拟自适应欺骗器，并使用2状态和3状态隐马尔可夫模型（HMM）进行性能分析，包括对数似然比、检测概率和稳态近似的闭式递推。

Result: 与经典的顺序认证方案相比，该框架在认证性能上表现出显著的鲁棒性改进。

Conclusion: 所提出的AR-PLA框架能够有效应对非平稳MIMO信道中的挑战，并提供更优越的认证性能。

Abstract: We propose an adversarially robust physical layer authentication (AR-PLA)
framework tailored for non-stationary multiple-input multiple-output (MIMO)
wireless channels. The framework integrates sequential Bayesian
decision-making, deep feature extraction via contrastive learning, and
generative adversarial modeling to simulate adaptive spoofers. Unlike
conventional methods that assume stationary channels or independent
observations, our approach explicitly accounts for temporal and spatial
correlations, line-of-sight (LoS) blockages, and dynamic spoofing strategies. A
comprehensive analytical characterization of the authentication performance
using both 2-state and 3-state hidden Markov models (HMMs) with moving-average
online adaptation is also provided, with closed-form recursions for
loglikelihood ratios, detection probabilities, and steady-state approximations,
which demonstrate significant robustness improvement over classical sequential
authentication schemes.

</details>


### [407] [An enhanced statistical feature fusion approach using an improved distance evaluation algorithm and weighted K-nearest neighbor for bearing fault diagnosis](https://arxiv.org/abs/2509.21219)
*Amir Eshaghi Chaleshtori,Abdollah Aghaie*

Main category: eess.SP

TL;DR: 本研究提出了一种结合改进距离评估算法和加权K近邻分类器的轴承故障诊断方法，通过提取多领域特征并进行加权和筛选，提高了在噪声环境中诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 轴承是旋转机械中最容易发生故障的部件，其状态直接影响整体性能。因此，准确诊断轴承故障对于确保系统稳定性至关重要。然而，在数据来自多个传感器且存在噪声的环境中检测此类故障，需要提取和选择信息量丰富的特征。

Method: 提出一种改进的距离评估算法与加权K近邻（KNN）分类器相结合的方法。首先，提取并整合时域、频域和时频域的振动统计特征。然后，利用改进的距离评估算法为提取的特征分配权重，并通过消除不敏感特征来保留信息量最丰富的特征。最后，使用选定的特征训练加权KNN分类器。

Result: 使用渥太华大学提供的轴承数据对所提方法进行了验证，结果证明了该方法在准确识别轴承故障方面的有效性。

Conclusion: 所提出的结合改进距离评估算法和加权K近邻分类器的轴承故障诊断方法，能够有效提取和筛选特征，在噪声环境中准确诊断轴承故障。

Abstract: Bearings are among the most failure-prone components in rotating machinery,
and their condition directly impacts overall performance. Therefore, accurately
diagnosing bearing faults is essential for ensuring system stability. However,
detecting such malfunctions in noisy environments, where data is collected from
multiple sensors, necessitates the extraction and selection of informative
features. This paper proposes an improved distance evaluation algorithm
combined with a weighted K-nearest neighbor (KNN) classifier for bearing fault
diagnosis. The process begins with extracting and integrating statistical
features of vibration across the time, frequency, and time-frequency domains.
Next, the improved distance evaluation algorithm assigns weights to the
extracted features, retaining only the most informative ones by eliminating
insensitive features. Finally, the selected features are used to train the
weighted KNN classifier. To validate the proposed method, we employ bearing
data from the University of Ottawa. The results demonstrate the effectiveness
of our approach in accurately identifying bearing faults.

</details>


### [408] [Vision-Intelligence-Enabled Beam Tracking for Cross-Interface Water-Air Optical Wireless Communications](https://arxiv.org/abs/2509.21290)
*Tianqi Mao,Jiayue Liu,Weijie Liu,Dezhi Zheng,Zhaocheng Wang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于AI的水下光通信激光雷达捕获算法。


<details>
  <summary>Details</summary>
Motivation: 在水下监测和矿产勘探等海洋应用不断发展的情况下，需要对大量观测数据进行实时无线回传，而传统的窄带声学方法难以实现。因此，需要一种能够适应复杂海洋环境的实时收发器对准方法。

Method: 提出了一种基于CNN、Bi-LSTM和注意力机制的视觉引导光束跟踪算法，用于动态预测和补偿由海面波动引起的光束未对准问题。

Result: 数值模拟结果表明，该算法在维持接收信号强度和抑制视觉噪声方面优于传统方法，证明了其在水-气光通信系统中的鲁棒性。

Conclusion: 所提出的算法能够有效解决水-气光通信中由海面波动引起的光束未对准问题，为实现可靠的高速水下通信提供了解决方案。

Abstract: The escalating development of oceanic applications like underwater
surveillance and mineral exploration, is motivating real-time wireless backhaul
of the considerable observation data. Such prospects can be hardly realized by
the narrowband acoustic approach. Alternatively, optical wireless communication
(OWC) has emerged as a promising solution for maritime and underwater
applications due to its great potential for broadband underwater transmission.
However, the implementations of water-air OWC can be rather challenging,
especially when penetrating the fluctuating interface, where the direction of
refracted signals changes dynamically, causing severe beam misalignment with
airborne stations. This has necessitated real-time transceiver alignment
adaptable to the sophisticated oceanic environment, which has yet to be
addressed. Against this background, this paper establishes a mathematical
channel model for water-air optical wireless transmission across the
fluctuating sea surface. Based on the model, we propose a vision-based beam
tracking algorithm that leverages artificial intelligence (AI) methods for
dynamic channel prediction. The proposed algorithm integrates a convolutional
neural network (CNN) with bi-directional long short-term memory (Bi-LSTM),
which further incorporates the attention mechanism to effectively extract
critical spatio-temporal features from the vision data. The numerical
simulation results show that the proposed algorithm can outperform its
classical counterparts in maintaining receiving signal strength and supressing
the vision noises, which demonstrates its robustness against the the harsh
conditions of water-air OWC systems.

</details>


### [409] [Efficient Digital Methods to Quantify Sensor Output Uncertainty](https://arxiv.org/abs/2509.21311)
*Orestis Kaparounakis,Phillip Stanley-Marbell*

Main category: eess.SP

TL;DR: 传感器输出的不确定性表征对于许多应用中可靠的数据解释至关重要。本研究调查了传感器组件信息精度有限导致传感器级测量不确定性对整体传感器测量精度的影响。我们以热电堆传感器为例，解释了我们的方法。我们展示了传感器校准和转换方程（所有传感系统的重要组成部分）如何将校准参数量化产生的 Buter propagate 到最终补偿的传感器输出。


<details>
  <summary>Details</summary>
Motivation: 传感器输出的不确定性表征对于许多应用中可靠的数据解释至关重要。本研究旨在调查传感器组件信息精度有限导致传感器级测量不确定性对整体传感器测量精度的影响。

Method: 研究人员以热电堆传感器为例，解释了他们的不确定性量化方法。他们展示了传感器校准和转换方程如何将校准参数量化产生的 Buter propagate 到最终补偿的传感器输出。

Result: 实验结果表明，与校准相关的量的认知不确定性会导致一个常用的热电堆传感器的最终输出误差高达 5.3°C（相对误差高达 25.7%）。在将认知不确定性信息用于边缘检测的一个实例中，研究人员在保持精度的同时，将传统 Canny 算子的错误正边沿检测减少为零。他们通过在两个商用不确定性跟踪硬件平台上进行原型设计，证明了这些想法在实际嵌入式传感器系统上的可行性，其中一个平台的平均功耗为 16.7 mW，与均值-方差 Monte Carlo 计算（现状）相比，速度提高了 42.9 倍；另一个平台的平均功耗为 147.15 mW，速度提高了 94.4 倍，为实时应用铺平了道路。

Conclusion: 研究人员证明了他们的不确定性量化方法在实际嵌入式传感器系统上的可行性，并展示了其在边缘检测等应用中的优势，同时实现了低功耗和高速度。

Abstract: Accurate characterization of sensor output uncertainty is important for
reliable data interpretation in many applications. Here, we investigate the
impact of transducer-level measurement uncertainty on overall sensor
measurement accuracy due to limited-precision information about sensor
components. We explain our method using thermopile-based sensors as an example
class of sensors. We show how sensor calibration and conversion equations,
which are an essential part of all sensing systems, propagate uncertainties
resulting from the quantization of calibration parameters, to the final,
compensated sensor output. The experimental results show that the epistemic
uncertainty of calibration-related quantities leads to absolute error in the
sensor output as high as 5.3 {\deg}C (and relative error as high as 25.7%) for
one commonly-used thermopile sensor. In one instance of using the epistemic
uncertainty information in edge detection, we show reduction of false-positives
edges to zero for the conventional Canny operator, while maintaining accuracy.
We show these ideas are practical and possible on actual embedded sensor
systems by prototyping them on two commercially-available uncertainty tracking
hardware platforms, one with average power dissipation 16.7 mW and 42.9x
speedup compared to the equal-confidence Monte Carlo computation (the status
quo), and the other with average power dissipation 147.15 mW and 94.4x speedup,
paving the way for use in real time.

</details>
