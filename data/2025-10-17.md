<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 100]
- [cs.CL](#cs.CL) [Total: 124]
- [cs.NE](#cs.NE) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 17]
- [cs.LO](#cs.LO) [Total: 4]
- [eess.SP](#eess.SP) [Total: 11]
- [cs.RO](#cs.RO) [Total: 37]
- [eess.SY](#eess.SY) [Total: 13]
- [cs.DC](#cs.DC) [Total: 13]
- [cs.GR](#cs.GR) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 5]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.LG](#cs.LG) [Total: 101]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 19]
- [quant-ph](#quant-ph) [Total: 36]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.AI](#cs.AI) [Total: 54]
- [cs.ET](#cs.ET) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MultiFoodhat: A potential new paradigm for intelligent food quality inspection](https://arxiv.org/abs/2510.13889)
*Yue Hu,Guohang Zhuang*

Main category: cs.CV

TL;DR: MultiFoodChat是一个用于零样本食物识别的对话驱动的多智能体推理框架，它结合了视觉-语言模型（VLMs）和大型语言模型（LLMs），通过多轮视觉-文本对话进行协作推理，实现了无需额外训练或手动标注的食物识别。


<details>
  <summary>Details</summary>
Motivation: 现有的食物图像分类模型在泛化到未见过的食物类别方面存在局限性，并且严重依赖大型标注数据集。本研究旨在克服这些挑战，提供一种更通用的解决方案。

Method: 提出了一种名为MultiFoodChat的框架，该框架集成了视觉-语言模型（VLMs）和大型语言模型（LLMs），并通过多轮视觉-文本对话实现多智能体协作推理。框架中使用了物体感知令牌（OPT）来捕捉细粒度的视觉属性，并引入了交互式推理代理（IRA）来动态解释上下文线索以优化预测。

Result: 在多个公共食物数据集上的实验表明，与现有的无监督和少样本方法相比，MultiFoodChat在识别准确性和可解释性方面表现更优。

Conclusion: MultiFoodChat作为一种新的智能食物质量检测和分析范式，在无需额外训练或手动标注的情况下，能够实现灵活且类似人类的复杂食物场景理解。

Abstract: Food image classification plays a vital role in intelligent food quality
inspection, dietary assessment, and automated monitoring. However, most
existing supervised models rely heavily on large labeled datasets and exhibit
limited generalization to unseen food categories. To overcome these challenges,
this study introduces MultiFoodChat, a dialogue-driven multi-agent reasoning
framework for zero-shot food recognition. The framework integrates
vision-language models (VLMs) and large language models (LLMs) to enable
collaborative reasoning through multi-round visual-textual dialogues. An Object
Perception Token (OPT) captures fine-grained visual attributes, while an
Interactive Reasoning Agent (IRA) dynamically interprets contextual cues to
refine predictions. This multi-agent design allows flexible and human-like
understanding of complex food scenes without additional training or manual
annotations. Experiments on multiple public food datasets demonstrate that
MultiFoodChat achieves superior recognition accuracy and interpretability
compared with existing unsupervised and few-shot methods, highlighting its
potential as a new paradigm for intelligent food quality inspection and
analysis.

</details>


### [2] [Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images](https://arxiv.org/abs/2510.14081)
*Emanuel Garbin,Guy Adam,Oded Krams,Zohar Barzelay,Eran Guendelman,Michael Schwarz,Moran Vatelmacher,Yigal Shenkman,Eli Peker,Itai Druker,Uri Patish,Yoav Blum,Max Bluvstein,Junxuan Li,Rawal Khirodkar,Shunsuke Saito*

Main category: cs.CV

TL;DR: 提出了一种新颖的零样本方法，仅用几张非结构化的手机照片即可生成超逼真、保留身份信息的3D头像。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在几何不一致、细节缺失等问题，无法实现高真实度和身份保留。本研究旨在解决这些挑战。

Method: 提出了一种生成式规范化模块，将非结构化视图转换为一致表示，并采用基于Transformer的模型，在包含高保真高斯喷溅头像的大规模数据集上进行训练。

Result: 该方法能够从非结构化照片生成静态的四分身3D头像，具有高度的真实感和身份保留能力。

Conclusion: “捕获、规范化、喷溅”流程成功实现了从手机照片生成高质量3D头像的目标。

Abstract: We present a novel, zero-shot pipeline for creating hyperrealistic,
identity-preserving 3D avatars from a few unstructured phone images. Existing
methods face several challenges: single-view approaches suffer from geometric
inconsistencies and hallucinations, degrading identity preservation, while
models trained on synthetic data fail to capture high-frequency details like
skin wrinkles and fine hair, limiting realism. Our method introduces two key
contributions: (1) a generative canonicalization module that processes multiple
unstructured views into a standardized, consistent representation, and (2) a
transformer-based model trained on a new, large-scale dataset of high-fidelity
Gaussian splatting avatars derived from dome captures of real people. This
"Capture, Canonicalize, Splat" pipeline produces static quarter-body avatars
with compelling realism and robust identity preservation from unstructured
photos.

</details>


### [3] [Post-surgical Endometriosis Segmentation in Laparoscopic Videos](https://arxiv.org/abs/2510.13899)
*Andreas Leibetseder,Klaus Schoeffmann,Jörg Keckstein,Simon Keckstein*

Main category: cs.CV

TL;DR: 该演示论文介绍了一个用于分割子宫内膜异位症（一种常见的女性疾病）的系统，该系统能够分析腹腔镜手术视频，并用多色叠加注释识别出的植入区域，并显示检测摘要以改进视频浏览。


<details>
  <summary>Details</summary>
Motivation: 子宫内膜异位症的视觉外观多样且难以识别，需要一个系统来协助医生进行诊断。

Method: 训练一个系统来分割子宫内膜异位症的暗色子宫内膜植入物，分析腹腔镜手术视频，并进行注释和显示检测摘要。

Result: 开发了一个能够分析腹腔镜手术视频，用多色叠加注释识别出的植入区域，并显示检测摘要的系统。

Conclusion: 该系统有助于妇科医生治疗子宫内膜异位症。

Abstract: Endometriosis is a common women's condition exhibiting a manifold visual
appearance in various body-internal locations. Having such properties makes its
identification very difficult and error-prone, at least for laymen and
non-specialized medical practitioners. In an attempt to provide assistance to
gynecologic physicians treating endometriosis, this demo paper describes a
system that is trained to segment one frequently occurring visual appearance of
endometriosis, namely dark endometrial implants. The system is capable of
analyzing laparoscopic surgery videos, annotating identified implant regions
with multi-colored overlays and displaying a detection summary for improved
video browsing.

</details>


### [4] [GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering](https://arxiv.org/abs/2510.14270)
*Alexander Valverde,Brian Xu,Yuyin Zhou,Meng Xu,Hongyun Wang*

Main category: cs.CV

TL;DR: GauSSmart是一种结合2D基础模型和3D高斯喷射重建的混合方法，通过利用2D分割先验和高维特征嵌入来增强高斯喷射，在三个数据集中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的高斯喷射方法在处理稀疏覆盖区域时难以捕捉细节或保持真实感，这是由于稀疏3D训练数据的固有局限性。

Method: GauSSmart是一种混合方法，将2D基础模型（如DINO）中的凸滤波和语义特征监督与3D高斯喷射重建相结合，利用2D分割先验和高维特征嵌入来指导高斯喷射的致密化和细化。

Result: 在三个数据集中，GauSSmart在评估场景中一致优于现有的高斯喷射方法。

Conclusion: 混合2D-3D方法具有巨大潜力，通过将2D基础模型与3D重建管线相结合，可以克服单一方法的局限性。

Abstract: Scene reconstruction has emerged as a central challenge in computer vision,
with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting
achieving remarkable progress. While Gaussian Splatting demonstrates strong
performance on large-scale datasets, it often struggles to capture fine details
or maintain realism in regions with sparse coverage, largely due to the
inherent limitations of sparse 3D training data.
  In this work, we propose GauSSmart, a hybrid method that effectively bridges
2D foundational models and 3D Gaussian Splatting reconstruction. Our approach
integrates established 2D computer vision techniques, including convex
filtering and semantic feature supervision from foundational models such as
DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D
segmentation priors and high-dimensional feature embeddings, our method guides
the densification and refinement of Gaussian splats, improving coverage in
underrepresented areas and preserving intricate structural details.
  We validate our approach across three datasets, where GauSSmart consistently
outperforms existing Gaussian Splatting in the majority of evaluated scenes.
Our results demonstrate the significant potential of hybrid 2D-3D approaches,
highlighting how the thoughtful combination of 2D foundational models with 3D
reconstruction pipelines can overcome the limitations inherent in either
approach alone.

</details>


### [5] [Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models](https://arxiv.org/abs/2510.13993)
*Jia Yun Chua,Argyrios Zolotas,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 结合YOLO和视觉语言模型(VLM)以提升遥感图像分析，尤其是在飞机检测、场景理解和少样本学习方面，并在各种场景下提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉模型在遥感领域需要大量标注数据且难以理解复杂环境，而视觉语言模型(VLM)在该领域的应用尚待探索。

Method: 将YOLO与LLaVA、ChatGPT和Gemini等VLM结合，以实现更准确、更具上下文意识的图像解释。

Result: 在飞机检测和计数准确性方面，平均平均绝对误差(MAE)提高了48.46%，CLIPScore提高了6.17%，尤其是在原始和退化场景下的挑战性条件下。

Conclusion: 结合传统视觉模型和VLM的方法为遥感图像分析提供了更高级、更有效的途径，特别是在少样本学习场景下。

Abstract: Remote sensing has become a vital tool across sectors such as urban planning,
environmental monitoring, and disaster response. While the volume of data
generated has increased significantly, traditional vision models are often
constrained by the requirement for extensive domain-specific labelled data and
their limited ability to understand the context within complex environments.
Vision Language Models offer a complementary approach by integrating visual and
textual data; however, their application to remote sensing remains
underexplored, particularly given their generalist nature. This work
investigates the combination of vision models and VLMs to enhance image
analysis in remote sensing, with a focus on aircraft detection and scene
understanding. The integration of YOLO with VLMs such as LLaVA, ChatGPT, and
Gemini aims to achieve more accurate and contextually aware image
interpretation. Performance is evaluated on both labelled and unlabelled remote
sensing data, as well as degraded image scenarios which are crucial for remote
sensing. The findings show an average MAE improvement of 48.46% across models
in the accuracy of aircraft detection and counting, especially in challenging
conditions, in both raw and degraded scenarios. A 6.17% improvement in
CLIPScore for comprehensive understanding of remote sensing images is obtained.
The proposed approach combining traditional vision models and VLMs paves the
way for more advanced and efficient remote sensing image analysis, especially
in few-shot learning scenarios.

</details>


### [6] [Inpainting the Red Planet: Diffusion Models for the Reconstruction of Martian Environments in Virtual Reality](https://arxiv.org/abs/2510.14765)
*Giuseppe Lorenzo Catalano,Agata Marta Soccini*

Main category: cs.CV

TL;DR: 使用无条件扩散模型进行火星表面重建，以填补高程图中的缺失值。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实在太空探索中越来越重要，准确的行星地形3D重建是提高模拟可靠性的关键。火星高程数据存在缺失值，现有方法难以有效填补。

Method: 提出一种基于无条件扩散模型的火星表面重建方法。使用NASA的HiRISE调查数据增强数据集进行训练，采用非均匀重缩放策略捕捉多尺度地形特征，并将分辨率调整为128x128。

Result: 与反距离加权、克里金法和Navier-Stokes算法等现有方法相比，该模型在重建精度（RMSE降低4-15%）和感知相似度（LPIPS提高29-81%）方面均表现出优越性。

Conclusion: 所提出的无条件扩散模型能够有效地重建火星表面，并能更好地处理高程数据中的缺失值，提高了重建的准确性和视觉效果。

Abstract: Space exploration increasingly relies on Virtual Reality for several tasks,
such as mission planning, multidisciplinary scientific analysis, and astronaut
training. A key factor for the reliability of the simulations is having
accurate 3D representations of planetary terrains. Extraterrestrial heightmaps
derived from satellite imagery often contain missing values due to acquisition
and transmission constraints. Mars is among the most studied planets beyond
Earth, and its extensive terrain datasets make the Martian surface
reconstruction a valuable task, although many areas remain unmapped. Deep
learning algorithms can support void-filling tasks; however, whereas Earth's
comprehensive datasets enables the use of conditional methods, such approaches
cannot be applied to Mars. Current approaches rely on simpler interpolation
techniques which, however, often fail to preserve geometric coherence. In this
work, we propose a method for reconstructing the surface of Mars based on an
unconditional diffusion model. Training was conducted on an augmented dataset
of 12000 Martian heightmaps derived from NASA's HiRISE survey. A
non-homogeneous rescaling strategy captures terrain features across multiple
scales before resizing to a fixed 128x128 model resolution. We compared our
method against established void-filling and inpainting techniques, including
Inverse Distance Weighting, kriging, and Navier-Stokes algorithm, on an
evaluation set of 1000 samples. Results show that our approach consistently
outperforms these methods in terms of reconstruction accuracy (4-15% on RMSE)
and perceptual similarity (29-81% on LPIPS) with the original data.

</details>


### [7] [Finding Holes: Pathologist Level Performance Using AI for Cribriform Morphology Detection in Prostate Cancer](https://arxiv.org/abs/2510.13995)
*Kelvin Szolnoky,Anders Blilie,Nita Mulliqi,Toyonori Tsuzuki,Hemamali Samaratunga,Matteo Titus,Xiaoyi Ji,Sol Erika Boman,Einar Gudlaugsson,Svein Reidar Kjosavik,José Asenjo,Marcello Gambacorta,Paolo Libretti,Marcin Braun,Radisław Kordek,Roman Łowicki,Brett Delahunt,Kenneth A. Iczkowski,Theo van der Kwast,Geert J. L. H. van Leenders,Katia R. M. Leite,Chin-Chen Pan,Emiel Adrianus Maria Janssen,Martin Eklund,Lars Egevad,Kimmo Kartasalo*

Main category: cs.CV

TL;DR: 该研究开发了一种人工智能（AI）模型，用于检测前列腺癌中的筛状形态，旨在提高诊断的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 筛状形态是前列腺癌预后不良的指标，但其报告不足且在病理学家之间存在显著的差异。本研究旨在开发并验证一个AI系统来改进筛状形态的检测。

Method: 研究人员使用EfficientNetV2-S编码器和多实例学习创建了一个深度学习模型，用于对整个切片进行分类。模型在来自三个队列的640个前列腺核心针活检样本上进行训练，并在内部（261张切片）和外部（266张切片）队列中进行了验证。同时，还进行了评分者间分析，并将模型性能与九位病理学家的表现进行了比较。

Result: 该模型在内部验证中表现强劲（AUC：0.97，Kappa系数：0.81），在外部验证中表现稳健（AUC：0.90，Kappa系数：0.55）。在评分者间分析中，模型达到了最高的平均一致性（Kappa系数：0.66），优于所有九位病理学家（Kappa系数范围为0.35至0.62）。

Conclusion: 研究表明，该AI模型在前列腺癌筛状形态检测方面达到了病理学家的水平。该方法有望提高诊断的可靠性，规范报告，并改善前列腺癌患者的治疗决策。

Abstract: Background: Cribriform morphology in prostate cancer is a histological
feature that indicates poor prognosis and contraindicates active surveillance.
However, it remains underreported and subject to significant interobserver
variability amongst pathologists. We aimed to develop and validate an AI-based
system to improve cribriform pattern detection.
  Methods: We created a deep learning model using an EfficientNetV2-S encoder
with multiple instance learning for end-to-end whole-slide classification. The
model was trained on 640 digitised prostate core needle biopsies from 430
patients, collected across three cohorts. It was validated internally (261
slides from 171 patients) and externally (266 slides, 104 patients from three
independent cohorts). Internal validation cohorts included laboratories or
scanners from the development set, while external cohorts used completely
independent instruments and laboratories. Annotations were provided by three
expert uropathologists with known high concordance. Additionally, we conducted
an inter-rater analysis and compared the model's performance against nine
expert uropathologists on 88 slides from the internal validation cohort.
  Results: The model showed strong internal validation performance (AUC: 0.97,
95% CI: 0.95-0.99; Cohen's kappa: 0.81, 95% CI: 0.72-0.89) and robust external
validation (AUC: 0.90, 95% CI: 0.86-0.93; Cohen's kappa: 0.55, 95% CI:
0.45-0.64). In our inter-rater analysis, the model achieved the highest average
agreement (Cohen's kappa: 0.66, 95% CI: 0.57-0.74), outperforming all nine
pathologists whose Cohen's kappas ranged from 0.35 to 0.62.
  Conclusion: Our AI model demonstrates pathologist-level performance for
cribriform morphology detection in prostate cancer. This approach could enhance
diagnostic reliability, standardise reporting, and improve treatment decisions
for prostate cancer patients.

</details>


### [8] [Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation](https://arxiv.org/abs/2510.14976)
*Shaowei Liu,Chuan Guo,Bing Zhou,Jian Wang*

Main category: cs.CV

TL;DR: Ponimator是一个基于近距离互动姿势的交互式动画框架，可以根据文本或姿势生成动态动作序列，并支持多种应用。


<details>
  <summary>Details</summary>
Motivation: 观察到近距离人与人之间的互动姿势能够传达丰富的互动动态信息，并且人类可以利用行为先验直观地推断互动背景和预测可能的过去和未来动态，因此受到启发，提出一个简单的框架，以近距离互动姿势为基础，实现多功能的交互式动画。

Method: 利用近距离的两人姿势及其周围的时间上下文作为训练数据，通过两个条件扩散模型来实现：1. 姿势动画器：利用时间先验从互动姿势生成动态运动序列。2. 姿势生成器：利用空间先验，在缺乏互动姿势时，根据单一姿势、文本或两者合成互动姿势。

Result: 实验证明了姿势先验的通用性以及框架的有效性和鲁棒性，该框架能够支持图像驱动的交互动画、反应动画和文本到交互合成等多种任务。

Conclusion: Ponimator框架能够有效地迁移高质量动作捕捉数据中的交互知识到开放世界场景中，并支持多种交互式动画任务。

Abstract: Close-proximity human-human interactive poses convey rich contextual
information about interaction dynamics. Given such poses, humans can
intuitively infer the context and anticipate possible past and future dynamics,
drawing on strong priors of human behavior. Inspired by this observation, we
propose Ponimator, a simple framework anchored on proximal interactive poses
for versatile interaction animation. Our training data consists of
close-contact two-person poses and their surrounding temporal context from
motion-capture interaction datasets. Leveraging interactive pose priors,
Ponimator employs two conditional diffusion models: (1) a pose animator that
uses the temporal prior to generate dynamic motion sequences from interactive
poses, and (2) a pose generator that applies the spatial prior to synthesize
interactive poses from a single pose, text, or both when interactive poses are
unavailable. Collectively, Ponimator supports diverse tasks, including
image-based interaction animation, reaction animation, and text-to-interaction
synthesis, facilitating the transfer of interaction knowledge from high-quality
mocap data to open-world scenarios. Empirical experiments across diverse
datasets and applications demonstrate the universality of the pose prior and
the effectiveness and robustness of our framework.

</details>


### [9] [NAPPure: Adversarial Purification for Robust Image Classification under Non-Additive Perturbations](https://arxiv.org/abs/2510.14025)
*Junjie Nan,Jianing Li,Wei Chen,Mingkun Zhang,Xueqi Cheng*

Main category: cs.CV

TL;DR: NAPPure框架可有效处理非加性对抗性扰动，提高图像分类模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性净化方法主要针对加性扰动，在处理现实世界中常见的非加性扰动（如模糊、遮挡、失真）时效果不佳。

Method: 提出了一种名为NAPPure的扩展对抗性净化框架，通过建立对抗性图像的生成过程，并利用似然最大化来解耦潜在的干净图像和扰动参数。

Result: 在GTSRB和CIFAR-10数据集上的实验表明，NAPPure能够显著提高图像分类模型在面对非加性扰动时的鲁棒性。

Conclusion: NAPPure框架能够有效处理非加性对抗性扰动，并显著提升图像分类模型的鲁棒性。

Abstract: Adversarial purification has achieved great success in combating adversarial
image perturbations, which are usually assumed to be additive. However,
non-additive adversarial perturbations such as blur, occlusion, and distortion
are also common in the real world. Under such perturbations, existing
adversarial purification methods are much less effective since they are
designed to fit the additive nature. In this paper, we propose an extended
adversarial purification framework named NAPPure, which can further handle
non-additive perturbations. Specifically, we first establish the generation
process of an adversarial image, and then disentangle the underlying clean
image and perturbation parameters through likelihood maximization. Experiments
on GTSRB and CIFAR-10 datasets show that NAPPure significantly boosts the
robustness of image classification models against non-additive perturbations.

</details>


### [10] [Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding](https://arxiv.org/abs/2510.14032)
*Xiaoqian Shen,Wenxuan Zhang,Jun Chen,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: Vgent是一个新的基于图的检索-推理-增强生成框架，用于改进大型视频语言模型（LVLMs）在长视频理解方面的能力。它通过结构化图表示视频以提高检索效率，并通过中间推理步骤减少噪声并整合相关信息，从而提高响应的准确性和上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 理解和推理长视频对大型视频语言模型（LVLMs）提出了挑战，因为它们难以处理超出上下文窗口的密集视频标记并保留长期顺序信息。现有的检索增强生成（RAG）方法应用于长视频时，会面临时间依赖性中断和包含无关信息的问题。

Method: Vgent框架通过以下两个关键创新来解决长视频理解的挑战：1.将视频表示为结构化图，保留视频片段之间的语义关系，以提高检索的有效性。2.引入一个中间推理步骤，利用结构化验证来减少检索噪声，并促进跨片段相关信息的显式聚合，从而减轻LVLMs的推理限制。

Result: 在MLVU基准测试中，Vgent框架在基础模型上的整体性能提高了3.0%~5.4%，在长视频理解方面优于最先进的视频RAG方法8.6%。

Conclusion: Vgent框架通过其创新的图表示和中间推理步骤，显著提高了LVLMs在长视频理解方面的性能，克服了现有方法的局限性。

Abstract: Understanding and reasoning over long videos pose significant challenges for
large video language models (LVLMs) due to the difficulty in processing
intensive video tokens beyond context window and retaining long-term sequential
information. Retrieval-Augmented Generation (RAG) has demonstrated
effectiveness in processing long context for Large Language Models (LLMs);
however, applying RAG to long video faces challenges such as disrupted temporal
dependencies and inclusion of irrelevant information that can hinder accurate
reasoning. To address these limitations, we propose Vgent, a novel graph-based
retrieval-reasoning-augmented generation framework to enhance LVLMs for long
video understanding. Our approach introduces two key innovations: (i) It
represents videos by structured graphs with semantic relationships across video
clips preserved to improve retrieval effectiveness. (ii) It introduces an
intermediate reasoning step to mitigate the reasoning limitation of LVLMs,
which leverages structured verification to reduce retrieval noise and
facilitate the explicit aggregation of relevant information across clips,
resulting in more accurate and context-aware responses. We comprehensively
evaluate our framework with various open-source LVLMs on three long-video
understanding benchmarks. Our approach yielded an overall performance
improvement of $3.0\%\sim 5.4\%$ over base models on MLVU, and outperformed
state-of-the-art video RAG methods by $8.6\%$. Our code is publicly available
at https://xiaoqian-shen.github.io/Vgent.

</details>


### [11] [Synchronization of Multiple Videos](https://arxiv.org/abs/2510.14051)
*Avihai Naaman,Ron Shapira Weber,Oren Freifeld*

Main category: cs.CV

TL;DR: TPL通过学习统一的原型序列来同步多视角视频，即使是生成式AI视频，也能实现高精度、高效率和高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 同步不同场景或生成式AI视频比同步同一场景视频更具挑战性，因为它们存在多样的主题、背景和非线性时间错位。

Method: 提出了一种基于原型的框架Temporal Prototype Learning（TPL），该框架从预训练模型的高维嵌入中构建共享的、紧凑的一维表示，并通过学习统一的原型序列来对齐视频。

Result: TPL在各种数据集上提高了同步精度、效率和鲁棒性，并可用于细粒度帧检索和阶段分类任务，同时也是首个能解决多个生成式AI视频同步问题的方案。

Conclusion: TPL是一种有效且鲁棒的视频同步框架，能够处理具有挑战性的数据集，包括生成式AI视频。

Abstract: Synchronizing videos captured simultaneously from multiple cameras in the
same scene is often easy and typically requires only simple time shifts.
However, synchronizing videos from different scenes or, more recently,
generative AI videos, poses a far more complex challenge due to diverse
subjects, backgrounds, and nonlinear temporal misalignment. We propose Temporal
Prototype Learning (TPL), a prototype-based framework that constructs a shared,
compact 1D representation from high-dimensional embeddings extracted by any of
various pretrained models. TPL robustly aligns videos by learning a unified
prototype sequence that anchors key action phases, thereby avoiding exhaustive
pairwise matching. Our experiments show that TPL improves synchronization
accuracy, efficiency, and robustness across diverse datasets, including
fine-grained frame retrieval and phase classification tasks. Importantly, TPL
is the first approach to mitigate synchronization issues in multiple generative
AI videos depicting the same action. Our code and a new multiple video
synchronization dataset are available at https://bgu-cs-vil.github.io/TPL/

</details>


### [12] [cubic: CUDA-accelerated 3D Bioimage Computing](https://arxiv.org/abs/2510.14143)
*Alexandr A. Kalinin,Anne E. Carpenter,Shantanu Singh,Matthew J. O'Meara*

Main category: cs.CV

TL;DR: cubic是一个开源Python库，通过集成CuPy和RAPIDS cuCIM，为生物图像分析提供了GPU加速替代方案，解决了现有工具可扩展性、效率和集成性方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的计算方法在处理现代显微镜生成的大型生物图像数据集时，在可扩展性、效率和与现代科学计算工作流的集成方面存在局限性，并且通常缺乏API、GPU加速、广泛的3D图像处理能力或良好的互操作性。

Method: cubic库通过提供与广泛使用的SciPy和scikit-image API兼容的、可利用GPU的替代方案来实现其功能。该库的API是设备无关的，可以根据数据的位置在CPU或GPU上执行操作，从而实现对现有生物图像分析工作流（包括预处理、分割和特征提取）的无缝加速，支持2D和3D数据。

Result: 通过对单个操作进行基准测试和重现现有的反卷积和分割流程，cubic库在保持算法保真度的同时实现了显著的加速。

Conclusion: cubic库为可扩展、可复现的生物图像分析奠定了坚实的基础，并能与更广泛的Python科学计算生态系统（包括其他GPU加速方法）集成，从而支持交互式探索和自动化的、高通量的分析工作流。

Abstract: Quantitative analysis of multidimensional biological images is useful for
understanding complex cellular phenotypes and accelerating advances in
biomedical research. As modern microscopy generates ever-larger 2D and 3D
datasets, existing computational approaches are increasingly limited by their
scalability, efficiency, and integration with modern scientific computing
workflows. Existing bioimage analysis tools often lack application programmable
interfaces (APIs), do not support graphics processing unit (GPU) acceleration,
lack broad 3D image processing capabilities, and/or have poor interoperability
for compute-heavy workflows. Here, we introduce cubic, an open-source Python
library that addresses these challenges by augmenting widely used SciPy and
scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM.
cubic's API is device-agnostic and dispatches operations to GPU when data
reside on the device and otherwise executes on CPU, seamlessly accelerating a
broad range of image processing routines. This approach enables GPU
acceleration of existing bioimage analysis workflows, from preprocessing to
segmentation and feature extraction for 2D and 3D data. We evaluate cubic both
by benchmarking individual operations and by reproducing existing deconvolution
and segmentation pipelines, achieving substantial speedups while maintaining
algorithmic fidelity. These advances establish a robust foundation for
scalable, reproducible bioimage analysis that integrates with the broader
Python scientific computing ecosystem, including other GPU-accelerated methods,
enabling both interactive exploration and automated high-throughput analysis
workflows. cubic is openly available at
https://github$.$com/alxndrkalinin/cubic

</details>


### [13] [Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures](https://arxiv.org/abs/2510.14179)
*Yuancheng Xu,Wenqi Xian,Li Ma,Julien Philip,Ahmet Levent Taşel,Yiwei Zhao,Ryan Burgert,Mingming He,Oliver Hermann,Oliver Pilarski,Rahul Garg,Paul Debevec,Ning Yu*

Main category: cs.CV

TL;DR: 提出一个框架，用于在视频扩散模型中实现多视图角色一致性和3D相机控制。


<details>
  <summary>Details</summary>
Motivation: 为了在视频扩散模型中实现多视图角色一致性和3D相机控制，克服现有模型的局限性。

Method: 使用4D高斯泼溅（4DGS）和视频重照明模型，通过多样化的相机轨迹和光照变化，对录制的体积捕捉性能进行再渲染。然后，在这些数据上对最先进的开源视频扩散模型进行微调。

Result: 该框架实现了强大的多视图身份保持、精确的相机控制和光照适应性。它还支持虚拟制作的核心能力，包括多主体生成（通过联合训练和噪声混合）、场景和真实生活视频定制，以及在定制过程中对运动和空间布局的控制。实验证明，视频质量、个性化准确性、相机控制和光照适应性均得到提升。

Conclusion: 该框架通过新颖的数据管道，在视频扩散模型中实现了多视图角色一致性和3D相机控制，并为虚拟制作提供了先进的功能，推动了视频生成在虚拟制作中的应用。

Abstract: We introduce a framework that enables both multi-view character consistency
and 3D camera control in video diffusion models through a novel customization
data pipeline. We train the character consistency component with recorded
volumetric capture performances re-rendered with diverse camera trajectories
via 4D Gaussian Splatting (4DGS), lighting variability obtained with a video
relighting model. We fine-tune state-of-the-art open-source video diffusion
models on this data to provide strong multi-view identity preservation, precise
camera control, and lighting adaptability. Our framework also supports core
capabilities for virtual production, including multi-subject generation using
two approaches: joint training and noise blending, the latter enabling
efficient composition of independently customized models at inference time; it
also achieves scene and real-life video customization as well as control over
motion and spatial layout during customization. Extensive experiments show
improved video quality, higher personalization accuracy, and enhanced camera
control and lighting adaptability, advancing the integration of video
generation into virtual production. Our project page is available at:
https://eyeline-labs.github.io/Virtually-Being.

</details>


### [14] [Joint Modeling of Big Five and HEXACO for Multimodal Apparent Personality-trait Recognition](https://arxiv.org/abs/2510.14203)
*Ryo Masumura,Shota Orihashi,Mana Ihori,Tomohiro Tanaka,Naoki Makishima,Taiga Yamane,Naotaka Kawata,Satoshi Suzuki,Taichi Katayama*

Main category: cs.CV

TL;DR: 该研究提出了一种联合建模方法，用于从多模态人类行为中自动识别“大五”和HEXACO人格特质，并阐明了它们之间的关系。


<details>
  <summary>Details</summary>
Motivation: 以往关于多模态人类行为的表观人格特质识别研究多集中于“大五”模型，而忽略了HEXACO模型。HEXACO模型包含了“诚实-谦逊”特质，该特质与被报复心和 the social-dominance orientation 等概念相关。本研究旨在弥补这一空白，并探索“大五”与HEXACO模型在机器学习中的关系，以期提高对多模态人类行为的认知。

Method: 提出了一种联合优化模型，能够同时识别“大五”和HEXACO两种人格特质。

Result: 实验结果表明，该联合模型能够有效地识别“大五”和HEXACO两种人格特质。

Conclusion: 该研究成功地提出了一种联合识别“大五”和HEXACO人格特质的方法，并通过实验验证了其有效性。这有助于更全面地理解多模态人类行为中的人格特质，并为未来相关研究提供了新的视角。

Abstract: This paper proposes a joint modeling method of the Big Five, which has long
been studied, and HEXACO, which has recently attracted attention in psychology,
for automatically recognizing apparent personality traits from multimodal human
behavior. Most previous studies have used the Big Five for multimodal apparent
personality-trait recognition. However, no study has focused on apparent HEXACO
which can evaluate an Honesty-Humility trait related to displaced aggression
and vengefulness, social-dominance orientation, etc. In addition, the
relationships between the Big Five and HEXACO when modeled by machine learning
have not been clarified. We expect awareness of multimodal human behavior to
improve by considering these relationships. The key advance of our proposed
method is to optimize jointly recognizing the Big Five and HEXACO. Experiments
using a self-introduction video dataset demonstrate that the proposed method
can effectively recognize the Big Five and HEXACO.

</details>


### [15] [LOTA: Bit-Planes Guided AI-Generated Image Detection](https://arxiv.org/abs/2510.14230)
*Hongsong Wang,Renxi Cheng,Yang Zhang,Chaolei Han,Jie Gui*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的基于位平面引导的噪声图像生成和最大梯度块选择方法，用于更快速、更准确地检测AI生成图像，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测方法计算成本高且无法捕捉原始图像中的内在噪声特征。

Method: 提出一种基于位平面的噪声提取方法，并结合最大梯度块选择来放大噪声信号，最后使用轻量级分类头进行分类。

Result: 在GenImage基准测试中，该方法实现了98.9%的平均准确率，并且在生成对抗网络（GAN）和扩散模型之间具有出色的泛化能力，检测速度达到毫秒级。

Conclusion: 该方法在AI生成图像检测方面表现出色，速度快、精度高、泛化能力强，解决了现有方法的痛点。

Abstract: The rapid advancement of GAN and Diffusion models makes it more difficult to
distinguish AI-generated images from real ones. Recent studies often use
image-based reconstruction errors as an important feature for determining
whether an image is AI-generated. However, these approaches typically incur
high computational costs and also fail to capture intrinsic noisy features
present in the raw images. To solve these problems, we innovatively refine
error extraction by using bit-plane-based image processing, as lower bit planes
indeed represent noise patterns in images. We introduce an effective bit-planes
guided noisy image generation and exploit various image normalization
strategies, including scaling and thresholding. Then, to amplify the noise
signal for easier AI-generated image detection, we design a maximum gradient
patch selection that applies multi-directional gradients to compute the noise
score and selects the region with the highest score. Finally, we propose a
lightweight and effective classification head and explore two different
structures: noise-based classifier and noise-guided classifier. Extensive
experiments on the GenImage benchmark demonstrate the outstanding performance
of our method, which achieves an average accuracy of \textbf{98.9\%}
(\textbf{11.9}\%~$\uparrow$) and shows excellent cross-generator generalization
capability. Particularly, our method achieves an accuracy of over 98.2\% from
GAN to Diffusion and over 99.2\% from Diffusion to GAN. Moreover, it performs
error extraction at the millisecond level, nearly a hundred times faster than
existing methods. The code is at https://github.com/hongsong-wang/LOTA.

</details>


### [16] [PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis](https://arxiv.org/abs/2510.14241)
*Soumyya Kanti Datta,Tanvi Ranga,Chengzhe Sun,Siwei Lyu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为PIA的新型多模态音频-视频框架，用于检测由先进生成模型（如GANs、扩散模型和神经渲染技术）生成的深度伪造内容，解决了传统检测方法在处理近乎完美的单帧图像时存在的不足。


<details>
  <summary>Details</summary>
Motivation: 传统的深度伪造检测方法依赖于手动设计的阈值或单模态策略，无法有效识别由先进生成模型（如GANs、扩散模型和神经渲染技术）生成的、在单个帧上几乎完美但在时间上存在细微不一致的深度伪造内容。

Method: 提出了一种名为Phoneme-Temporal and Identity-Dynamic Analysis (PIA) 的新型多模态音频-视频框架，该框架结合了语言（音素序列）、动态面部运动（唇部几何数据）和面部识别线索（先进的面部身份嵌入），以识别跨多个互补模态的细微不一致之处。

Result: PIA框架通过整合语言、动态面部运动和面部识别线索，显著提高了对细微深度伪造修改的检测能力。

Conclusion: 本研究提出的PIA框架能够有效解决传统深度伪造检测方法的局限性，通过多模态分析提高对先进深度伪造内容的检测精度。

Abstract: The rise of manipulated media has made deepfakes a particularly insidious
threat, involving various generative manipulations such as lip-sync
modifications, face-swaps, and avatar-driven facial synthesis. Conventional
detection methods, which predominantly depend on manually designed
phoneme-viseme alignment thresholds, fundamental frame-level consistency
checks, or a unimodal detection strategy, inadequately identify modern-day
deepfakes generated by advanced generative models such as GANs, diffusion
models, and neural rendering techniques. These advanced techniques generate
nearly perfect individual frames yet inadvertently create minor temporal
discrepancies frequently overlooked by traditional detectors. We present a
novel multimodal audio-visual framework, Phoneme-Temporal and Identity-Dynamic
Analysis(PIA), incorporating language, dynamic face motion, and facial
identification cues to address these limitations. We utilize phoneme sequences,
lip geometry data, and advanced facial identity embeddings. This integrated
method significantly improves the detection of subtle deepfake alterations by
identifying inconsistencies across multiple complementary modalities. Code is
available at https://github.com/skrantidatta/PIA

</details>


### [17] [Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication](https://arxiv.org/abs/2510.14245)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 该论文提出了一种名为事件间隔调制（EIM）的新型调制方案，用于基于事件的可见光通信（OCC）系统，以克服传统基于帧的OCC系统的低比特率和高处理负荷问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于帧的OCC系统存在低比特率和高处理负荷的限制。现有的基于事件的OCC系统虽然利用了事件视觉传感器（EVS）的高速、低延迟和高动态范围特性，但所采用的传统调制方案（如OOK和PPM）并未充分发挥EVS的独特优势。

Method: 提出了一种专门为EVS设计的事件间隔调制（EIM）方案，通过调制事件之间的时间间隔来传输信息，从而提高传输速率。论文建立了EIM的理论模型，并通过实验对EVS参数进行了优化和定制，以匹配EIM的频率响应，并实验确定了EIM可用的最大调制阶数。最后，基于确定的参数进行了传输实验。

Result: 在室内环境中，EIM方案在10米距离上实现了28 kbps的传输速率，在50米距离上实现了8.4 kbps的传输速率。

Conclusion: 提出的EIM方案成功应用于事件驱动的OCC系统，显著提高了传输速率，并在实验中创下了事件驱动OCC系统的比特率新基准。

Abstract: Optical camera communication (OCC) represents a promising visible light
communication technology. Nonetheless, typical OCC systems utilizing
frame-based cameras are encumbered by limitations, including low bit rate and
high processing load. To address these issues, OCC system utilizing an
event-based vision sensor (EVS) as receivers have been proposed. The EVS
enables high-speed, low-latency, and robust communication due to its
asynchronous operation and high dynamic range. In existing event-based OCC
systems, conventional modulation schemes such as on-off keying (OOK) and pulse
position modulation have been applied, however, to the best of our knowledge,
no modulation method has been proposed that fully exploits the unique
characteristics of the EVS. This paper proposes a novel modulation scheme,
called the event interval modulation (EIM) scheme, specifically designed for
event-based OCC. EIM enables improvement in transmission speed by modulating
information using the intervals between events. This paper proposes a
theoretical model of EIM and conducts a proof-of-concept experiment. First, the
parameters of the EVS are tuned and customized to optimize the frequency
response specifically for EIM. Then, the maximum modulation order usable in EIM
is determined experimentally. We conduct transmission experiments based on the
obtained parameters. Finally, we report successful transmission at 28 kbps over
10 meters and 8.4 kbps over 50 meters in an indoor environment. This sets a new
benchmark for bit rate in event-based OCC systems.

</details>


### [18] [MACE: Mixture-of-Experts Accelerated Coordinate Encoding for Large-Scale Scene Localization and Rendering](https://arxiv.org/abs/2510.14251)
*Mingkai Liu,Dikai Fan,Haohua Que,Haojia Gao,Xiao Liu,Shuxue Peng,Meixia Lin,Shengyu Gu,Ruicong Ye,Wanli Qiu,Handong Yao,Ruopeng Zhang,Xianliang Huang*

Main category: cs.CV

TL;DR: MACE通过混合专家模型和辅助损失无负载均衡策略，实现了大规模场景的高效定位和高质量渲染，显著降低了成本并提高了精度。


<details>
  <summary>Details</summary>
Motivation: 大规模场景的高效定位和高质量渲染因计算成本而面临挑战。现有的小规模场景定位方法（如SCR）在大规模场景中受限于单一网络的容量。

Method: 提出了一种混合专家加速坐标编码（MACE）方法，该方法受大型模型领域中MOE的启发，引入了一个门控网络来选择子网络，每次推理只激活一个子网络。此外，还提出了一种辅助损失无负载均衡（ALF-LB）策略来提高大规模场景的定位精度。

Result: MACE框架在降低成本的同时提高了精度，为大规模场景应用提供了一个有效的解决方案。在剑桥测试集上的实验表明，该方法仅用10分钟的训练即可实现高质量的渲染结果。

Conclusion: MACE方法能够高效地进行大规模场景的定位和高质量渲染，解决了现有方法的局限性，并在计算成本和精度方面取得了显著的改进。

Abstract: Efficient localization and high-quality rendering in large-scale scenes
remain a significant challenge due to the computational cost involved. While
Scene Coordinate Regression (SCR) methods perform well in small-scale
localization, they are limited by the capacity of a single network when
extended to large-scale scenes. To address these challenges, we propose the
Mixed Expert-based Accelerated Coordinate Encoding method (MACE), which enables
efficient localization and high-quality rendering in large-scale scenes.
Inspired by the remarkable capabilities of MOE in large model domains, we
introduce a gating network to implicitly classify and select sub-networks,
ensuring that only a single sub-network is activated during each inference.
Furtheremore, we present Auxiliary-Loss-Free Load Balancing(ALF-LB) strategy to
enhance the localization accuracy on large-scale scene. Our framework provides
a significant reduction in costs while maintaining higher precision, offering
an efficient solution for large-scale scene applications. Additional
experiments on the Cambridge test set demonstrate that our method achieves
high-quality rendering results with merely 10 minutes of training.

</details>


### [19] [Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization](https://arxiv.org/abs/2510.14255)
*Liao Shen,Wentao Jiang,Yiran Zhu,Tiezheng Ge,Zhiguo Cao,Bo Zheng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为IPRO（Identity-Preserving Reward-guided Optimization）的视频生成新框架，通过强化学习优化扩散模型，以提高人脸身份保持能力，特别是在人脸占比较小的情况下。该方法通过反向传播奖励信号、利用多角度面部信息和KL散度正则化来稳定训练。


<details>
  <summary>Details</summary>
Motivation: 现有图像到视频（I2V）模型在生成包含人物的视频时，难以保持输入图像与生成视频之间的人物身份一致性，尤其是在人物表情和动作变化较大，或者人脸在图像中占比较小的情况下。这是一个关键但被忽视的挑战。

Method: 提出了一种名为IPRO（Identity-Preserving Reward-guided Optimization）的视频扩散框架，利用强化学习和面部身份评分器来优化扩散模型，以增强身份保持能力。该方法通过将奖励信号反向传播到采样链的最后几步，并引入新颖的面部评分机制（将真实视频中的面部视为特征池）来提升性能和收敛速度。同时，使用KL散度正则化来稳定训练。

Result: 在Wan 2.2 I2V模型和研究内部的I2V模型上进行了广泛的实验，证明了该方法在身份保持方面的有效性。

Conclusion: IPRO是一种有效的、无需修改模型架构的身份保持视频生成优化算法，通过引入基于强化学习的奖励机制和创新的面部特征提取方法，解决了现有I2V模型在人物身份一致性方面的痛点。

Abstract: Recent advances in image-to-video (I2V) generation have achieved remarkable
progress in synthesizing high-quality, temporally coherent videos from static
images. Among all the applications of I2V, human-centric video generation
includes a large portion. However, existing I2V models encounter difficulties
in maintaining identity consistency between the input human image and the
generated video, especially when the person in the video exhibits significant
expression changes and movements. This issue becomes critical when the human
face occupies merely a small fraction of the image. Since humans are highly
sensitive to identity variations, this poses a critical yet under-explored
challenge in I2V generation. In this paper, we propose Identity-Preserving
Reward-guided Optimization (IPRO), a novel video diffusion framework based on
reinforcement learning to enhance identity preservation. Instead of introducing
auxiliary modules or altering model architectures, our approach introduces a
direct and effective tuning algorithm that optimizes diffusion models using a
face identity scorer. To improve performance and accelerate convergence, our
method backpropagates the reward signal through the last steps of the sampling
chain, enabling richer gradient feedback. We also propose a novel facial
scoring mechanism that treats faces in ground-truth videos as facial feature
pools, providing multi-angle facial information to enhance generalization. A
KL-divergence regularization is further incorporated to stabilize training and
prevent overfitting to the reward signal. Extensive experiments on Wan 2.2 I2V
model and our in-house I2V model demonstrate the effectiveness of our method.
Our project and code are available at
\href{https://ipro-alimama.github.io/}{https://ipro-alimama.github.io/}.

</details>


### [20] [Multi-modal video data-pipelines for machine learning with minimal human supervision](https://arxiv.org/abs/2510.14862)
*Mihai-Cristian Pîrvu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 该研究旨在使用少量甚至无人类监督的情况下，整合多种视觉模态，并利用PHG-MAE模型在实时语义分割等任务上取得具有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界本质上是多模态的，而传统机器学习模型大多是单模态或双模态的，为了真正理解世界，需要整合所有独立的模态。

Method: 利用预训练模型和程序化组合，在原始视频上通过全自主数据管道整合多种视觉模态，并使用PHG-MAE模型进行多模态数据学习。

Result: PHG-MAE模型（<1M参数）在多模态学习上取得了与~300M参数模型相媲美的结果，并成功应用于实时语义分割和深度估计等任务。

Conclusion: 该研究成功地整合了多种视觉模态，并通过PHG-MAE模型实现了高效的多模态学习，证明了其在资源受限设备上的应用潜力。

Abstract: The real-world is inherently multi-modal at its core. Our tools observe and
take snapshots of it, in digital form, such as videos or sounds, however much
of it is lost. Similarly for actions and information passing between humans,
languages are used as a written form of communication. Traditionally, Machine
Learning models have been unimodal (i.e. rgb -> semantic or text ->
sentiment_class). Recent trends go towards bi-modality, where images and text
are learned together, however, in order to truly understand the world, we need
to integrate all these independent modalities. In this work we try to combine
as many visual modalities as we can using little to no human supervision. In
order to do this, we use pre-trained experts and procedural combinations
between them on top of raw videos using a fully autonomous data-pipeline, which
we also open-source. We then make use of PHG-MAE, a model specifically designed
to leverage multi-modal data. We show that this model which was efficiently
distilled into a low-parameter (<1M) can have competitive results compared to
models of ~300M parameters. We deploy this model and analyze the use-case of
real-time semantic segmentation from handheld devices or webcams on commodity
hardware. Finally, we deploy other off-the-shelf models using the same
framework, such as DPT for near real-time depth estimation.

</details>


### [21] [Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement Learning](https://arxiv.org/abs/2510.14256)
*Xiangyu Meng,Zixian Zhang,Zhenghao Zhang,Junchao Liao,Long Qin,Weizhi Wang*

Main category: cs.CV

TL;DR: Identity-GRPO 通过引入人类反馈来优化多人物身份保持的视频生成，显著提高了视频中人物身份的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法在处理多人物交互时的身份保持能力不足，而身份一致性在多人物场景中至关重要。

Method: 提出 Identity-GRPO 优化流程，包括：1. 构建一个在包含人类标注和合成失真数据的偏好数据集上训练的视频奖励模型，重点关注保持人物一致性。 2. 采用专门针对多人物一致性进行调整的 GRPO 变体来优化视频生成模型（如 VACE 和 Phantom）。

Result: Identity-GRPO 在人类一致性指标上取得了高达 18.9% 的提升，并且通过消融实验评估了标注质量和设计选择对策略优化的影响。

Conclusion: Identity-GRPO 成功地提高了多人物身份保持的视频生成能力，并为将强化学习应用于个性化视频生成提供了可行的见解。

Abstract: While advanced methods like VACE and Phantom have advanced video generation
for specific subjects in diverse scenarios, they struggle with multi-human
identity preservation in dynamic interactions, where consistent identities
across multiple characters are critical. To address this, we propose
Identity-GRPO, a human feedback-driven optimization pipeline for refining
multi-human identity-preserving video generation. First, we construct a video
reward model trained on a large-scale preference dataset containing
human-annotated and synthetic distortion data, with pairwise annotations
focused on maintaining human consistency throughout the video. We then employ a
GRPO variant tailored for multi-human consistency, which greatly enhances both
VACE and Phantom. Through extensive ablation studies, we evaluate the impact of
annotation quality and design choices on policy optimization. Experiments show
that Identity-GRPO achieves up to 18.9% improvement in human consistency
metrics over baseline methods, offering actionable insights for aligning
reinforcement learning with personalized video generation.

</details>


### [22] [MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching](https://arxiv.org/abs/2510.14260)
*Tingman Yan,Tao Liu,Xilian Yang,Qunfei Zhao,Zeyang Xia*

Main category: cs.CV

TL;DR: MatchAttention通过动态匹配相对位置和BilinearSoftmax解决高分辨率图像的交叉视图匹配挑战，并提出MatchDecoder、门控交叉MatchAttention和一致性约束损失来处理遮挡问题，在多个基准测试中取得了最先进的性能，并实现了实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有的交叉注意力机制在处理高分辨率图像时存在二次方复杂度和缺乏显式匹配约束的问题，导致匹配困难。

Method: 提出了一种名为MatchAttention的新注意力机制，该机制能够动态地匹配相对位置，并利用BilinearSoftmax实现连续可微的滑动窗口注意力采样。通过将相对位置嵌入特征通道并利用残差连接跨层迭代更新。在此基础上，设计了以MatchAttention为核心的高效分层交叉视图解码器MatchDecoder。为了处理遮挡问题，引入了门控交叉MatchAttention和一致性约束损失。

Result: MatchStereo-B在Middlebury基准测试中平均误差排名第一，并且在KITTI分辨率下推理速度仅为29毫秒。MatchStereo-T能够以0.1秒的速度处理4K超高清图像，同时仅消耗3GB的GPU内存。所提出的模型在KITTI 2012、KITTI 2015、ETH3D和Spring flow数据集上也取得了最先进的性能。

Conclusion: 该研究提出的MatchAttention及其相关模型（MatchDecoder、MatchStereo-B、MatchStereo-T）通过结合高精度和低计算复杂度，实现了实时、高分辨率、高精度的交叉视图匹配，解决了现有方法的局限性。

Abstract: Cross-view matching is fundamentally achieved through cross-attention
mechanisms. However, matching of high-resolution images remains challenging due
to the quadratic complexity and lack of explicit matching constraints in the
existing cross-attention. This paper proposes an attention mechanism,
MatchAttention, that dynamically matches relative positions. The relative
position determines the attention sampling center of the key-value pairs given
a query. Continuous and differentiable sliding-window attention sampling is
achieved by the proposed BilinearSoftmax. The relative positions are
iteratively updated through residual connections across layers by embedding
them into the feature channels. Since the relative position is exactly the
learning target for cross-view matching, an efficient hierarchical cross-view
decoder, MatchDecoder, is designed with MatchAttention as its core component.
To handle cross-view occlusions, gated cross-MatchAttention and a
consistency-constrained loss are proposed. These two components collectively
mitigate the impact of occlusions in both forward and backward passes, allowing
the model to focus more on learning matching relationships. When applied to
stereo matching, MatchStereo-B ranked 1st in average error on the public
Middlebury benchmark and requires only 29ms for KITTI-resolution inference.
MatchStereo-T can process 4K UHD images in 0.1 seconds using only 3GB of GPU
memory. The proposed models also achieve state-of-the-art performance on KITTI
2012, KITTI 2015, ETH3D, and Spring flow datasets. The combination of high
accuracy and low computational complexity makes real-time, high-resolution, and
high-accuracy cross-view matching possible. Code is available at
https://github.com/TingmanYan/MatchAttention.

</details>


### [23] [Experimental Demonstration of Event-based Optical Camera Communication in Long-Range Outdoor Environment](https://arxiv.org/abs/2510.14266)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出了一种用于光学相机通信系统的鲁棒解调方案，结合了基于事件的视觉传感器、开关键调幅（OOK）和数字锁相环（DPLL）。


<details>
  <summary>Details</summary>
Motivation: 在光学相机通信（OCC）系统中实现鲁棒解调。

Method: 结合使用基于事件的视觉传感器、开关键调幅（OOK）和数字锁相环（DPLL）。

Result: 在室外实验中，在200米-60kbps和400米-30kbps的条件下，首次实现了比特错误率（BER）低于10^-3。

Conclusion: 所提出的方案在室外条件下实现了高性能的光学相机通信。

Abstract: We propose a robust demodulation scheme for optical camera communication
systems using an event-based vision sensor, combining OOK with toggle
demodulation and a digital phase-locked loop. This is the first report to
achieve a $\mathrm{BER} < 10^{-3}$ at 200m-60kbps and 400m-30kbps in outdoor
experiments.

</details>


### [24] [CLEAR: Causal Learning Framework For Robust Histopathology Tumor Detection Under Out-Of-Distribution Shifts](https://arxiv.org/abs/2510.14273)
*Kieu-Anh Truong Thi,Huy-Hieu Pham,Duc-Trong Le*

Main category: cs.CV

TL;DR: 域转移是病理学图像分析中的一个关键挑战，本文提出了一种基于因果推理的框架，通过利用语义特征和中介者来解决这个问题，并在两个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决由于数据来源或采集过程差异引起的病理学图像域转移问题，提高深度学习模型的泛化能力。

Method: 提出一种基于因果推理的框架，利用语义特征，并结合中介者和观测到的组织切片，采用前门准则来处理混淆因素。

Result: 在CAMELYON17和私有病理学数据集上，所提出的方法在两个数据集上均取得了高达7%的性能提升，优于现有基线方法。

Conclusion: 因果推理是解决病理学图像分析中域转移问题的有效工具。

Abstract: Domain shift in histopathology, often caused by differences in acquisition
processes or data sources, poses a major challenge to the generalization
ability of deep learning models. Existing methods primarily rely on modeling
statistical correlations by aligning feature distributions or introducing
statistical variation, yet they often overlook causal relationships. In this
work, we propose a novel causal-inference-based framework that leverages
semantic features while mitigating the impact of confounders. Our method
implements the front-door principle by designing transformation strategies that
explicitly incorporate mediators and observed tissue slides. We validate our
method on the CAMELYON17 dataset and a private histopathology dataset,
demonstrating consistent performance gains across unseen domains. As a result,
our approach achieved up to a 7% improvement in both the CAMELYON17 dataset and
the private histopathology dataset, outperforming existing baselines. These
results highlight the potential of causal inference as a powerful tool for
addressing domain shift in histopathology image analysis.

</details>


### [25] [Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding](https://arxiv.org/abs/2510.14304)
*Kyungryul Back,Seongbeom Park,Milim Kim,Mincheol Kwon,SangHyeok Lee,Hyunyoung Lee,Junhee Cho,Seunghyun Park,Jinkyu Kim*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLM）仍易出现幻觉，本文提出一种训练无关的三层对比解码与水印方法，通过选择成熟层和初学层，并利用水印相关问题识别支点层来评估视觉基础，最终生成更具视觉基础的输出，在POPE、MME和AMBER基准测试中达到最先进的减少幻觉性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在多模态任务中表现出潜力，但仍存在过度依赖单一模态或记忆训练数据而缺乏视觉基础的问题，导致幻觉。

Method: 提出一种训练无关的三层对比解码与水印方法。该方法包括三个步骤：1. 在解码层中选择一个成熟层和一个初学层。2. 利用一个与水印相关的问题来识别一个支点层，以评估该层是否具有良好的视觉基础。3. 应用三层对比解码来生成最终输出。

Result: 所提出的方法在POPE、MME和AMBER等公开基准测试中，在减少LVLM的幻觉方面取得了最先进的性能，并能生成更具视觉基础的响应。

Conclusion: 该方法通过引入三层对比解码与水印机制，有效解决了大型视觉语言模型中的幻觉问题，提高了模型输出的视觉基础，并在多个基准测试中取得了优于现有方法的性能。

Abstract: Large Vision-Language Models (LVLMs) have recently shown promising results on
various multimodal tasks, even achieving human-comparable performance in
certain cases. Nevertheless, LVLMs remain prone to hallucinations -- they often
rely heavily on a single modality or memorize training data without properly
grounding their outputs. To address this, we propose a training-free, tri-layer
contrastive decoding with watermarking, which proceeds in three steps: (1)
select a mature layer and an amateur layer among the decoding layers, (2)
identify a pivot layer using a watermark-related question to assess whether the
layer is visually well-grounded, and (3) apply tri-layer contrastive decoding
to generate the final output. Experiments on public benchmarks such as POPE,
MME and AMBER demonstrate that our method achieves state-of-the-art performance
in reducing hallucinations in LVLMs and generates more visually grounded
responses.

</details>


### [26] [A Multi-domain Image Translative Diffusion StyleGAN for Iris Presentation Attack Detection](https://arxiv.org/abs/2510.14314)
*Shivangi Yadav,Arun Ross*

Main category: cs.CV

TL;DR: 通过生成合成眼部图像来解决虹膜生物特征识别中的数据稀缺问题，从而提高演示攻击检测（PAD）系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的虹膜生物特征识别系统容易受到演示攻击（PAs），但缺乏用于训练和评估PAD技术的公开数据集。

Method: 提出了一种名为多域图像转换扩散风格生成对抗网络（MID-StyleGAN）的新框架，该框架结合了扩散模型和生成对抗网络的优点，能够生成逼真的合成眼部图像，并能在真实眼部、打印眼和化妆隐形眼镜等多个域之间进行转换。

Result: MID-StyleGAN生成了高质量、多样化的合成眼部图像，并显著提高了PAD系统的性能。在LivDet2020数据集上，真实检测率在1%虚假检测率下从93.41%提高到98.72%。

Conclusion: MID-StyleGAN有效地解决了虹膜和眼部生物特征识别中的数据稀缺问题，通过生成高质量的合成数据为PAD系统的开发和评估提供了可扩展的解决方案。

Abstract: An iris biometric system can be compromised by presentation attacks (PAs)
where artifacts such as artificial eyes, printed eye images, or cosmetic
contact lenses are presented to the system. To counteract this, several
presentation attack detection (PAD) methods have been developed. However, there
is a scarcity of datasets for training and evaluating iris PAD techniques due
to the implicit difficulties in constructing and imaging PAs. To address this,
we introduce the Multi-domain Image Translative Diffusion StyleGAN
(MID-StyleGAN), a new framework for generating synthetic ocular images that
captures the PA and bonafide characteristics in multiple domains such as
bonafide, printed eyes and cosmetic contact lens. MID-StyleGAN combines the
strengths of diffusion models and generative adversarial networks (GANs) to
produce realistic and diverse synthetic data. Our approach utilizes a
multi-domain architecture that enables the translation between bonafide ocular
images and different PA domains. The model employs an adaptive loss function
tailored for ocular data to maintain domain consistency. Extensive experiments
demonstrate that MID-StyleGAN outperforms existing methods in generating
high-quality synthetic ocular images. The generated data was used to
significantly enhance the performance of PAD systems, providing a scalable
solution to the data scarcity problem in iris and ocular biometrics. For
example, on the LivDet2020 dataset, the true detect rate at 1% false detect
rate improved from 93.41% to 98.72%, showcasing the impact of the proposed
method.

</details>


### [27] [Vision-Centric Activation and Coordination for Multimodal Large Language Models](https://arxiv.org/abs/2510.14349)
*Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: VaCo通过整合来自多个视觉基础模型（VFMs）的视觉特征，并引入视觉判别性对齐、模块化任务查询（MTQs）和视觉对齐层（VALs），来优化多模态大语言模型（MLLMs）的视觉理解能力，并通过令牌网关掩码（TGM）解决VFMs间的表示冲突，在多项基准测试中显著提升了MLLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）主要依赖于文本的下一个词预测进行监督，忽略了对模型分析能力至关重要的视觉信息。

Method: VaCo通过提取自多个视觉基础模型（VFMs）的任务感知感知特征，并引入视觉判别性对齐，来优化MLLMs的表示。具体来说，它整合了可学习的模块化任务查询（MTQs）和视觉对齐层（VALs），在VFMs的监督下激活特定的视觉信号。为了协调VFMs之间的表示冲突，设计了令牌网关掩码（TGM）来限制MTQs组之间的信息流。

Result: VaCo显著提高了不同MLLMs在各种基准测试上的性能，展现了其在视觉理解方面的优越能力。

Conclusion: VaCo通过整合和协调来自多个VFMs的视觉信息，有效解决了现有MLLMs中视觉信息利用不足的问题，显著提升了其视觉理解和分析能力。

Abstract: Multimodal large language models (MLLMs) integrate image features from visual
encoders with LLMs, demonstrating advanced comprehension capabilities. However,
mainstream MLLMs are solely supervised by the next-token prediction of textual
tokens, neglecting critical vision-centric information essential for analytical
abilities. To track this dilemma, we introduce VaCo, which optimizes MLLM
representations through Vision-Centric activation and Coordination from
multiple vision foundation models (VFMs). VaCo introduces visual discriminative
alignment to integrate task-aware perceptual features extracted from VFMs,
thereby unifying the optimization of both textual and visual outputs in MLLMs.
Specifically, we incorporate the learnable Modular Task Queries (MTQs) and
Visual Alignment Layers (VALs) into MLLMs, activating specific visual signals
under the supervision of diverse VFMs. To coordinate representation conflicts
across VFMs, the crafted Token Gateway Mask (TGM) restricts the information
flow among multiple groups of MTQs. Extensive experiments demonstrate that VaCo
significantly improves the performance of different MLLMs on various
benchmarks, showcasing its superior capabilities in visual comprehension.

</details>


### [28] [Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration](https://arxiv.org/abs/2510.14354)
*Siddharth Tourani,Jayaram Reddy,Sarvesh Thakur,K Madhava Krishna,Muhammad Haris Khan,N Dinesh Reddy*

Main category: cs.CV

TL;DR: 利用循环一致性关键点和新颖的姿态块，提出一种新的无监督RGB-D图像配准方法，在ScanNet和3DMatch数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用大量的无标签RGB-D数据进行几何推理，解决现有方法依赖几何和特征相似性的问题。

Method: 提出使用循环一致性关键点强制空间一致性约束，并结合GRU循环单元和变换同步的新姿态块来融合历史和多视图数据。

Result: 在ScanNet和3DMatch数据集上，该方法超越了之前的无监督配准方法，甚至优于一些有监督方法。

Conclusion: 所提出的方法在无监督RGB-D图像配准方面取得了显著的成果，并且其组件可以集成到现有方法中以提高性能。

Abstract: With the rise in consumer depth cameras, a wealth of unlabeled RGB-D data has
become available. This prompts the question of how to utilize this data for
geometric reasoning of scenes. While many RGB-D registration meth- ods rely on
geometric and feature-based similarity, we take a different approach. We use
cycle-consistent keypoints as salient points to enforce spatial coherence
constraints during matching, improving correspondence accuracy. Additionally,
we introduce a novel pose block that combines a GRU recurrent unit with
transformation synchronization, blending historical and multi-view data. Our
approach surpasses previous self- supervised registration methods on ScanNet
and 3DMatch, even outperforming some older supervised methods. We also
integrate our components into existing methods, showing their effectiveness.

</details>


### [29] [Spatial Preference Rewarding for MLLMs Spatial Understanding](https://arxiv.org/abs/2510.14374)
*Han Qiu,Peng Gao,Lewei Lu,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: SPR通过奖励更精确的区域描述和物体定位来提升多模态大语言模型（MLLMs）的空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在细粒度的空间感知能力（如详细区域描述、精确定位物体）方面存在不足，并且未能满足用户对精细空间理解的需求。这可能是因为现有方法主要依赖预先标注的指令数据来注入空间知识，而没有直接监督MLLMs的实际响应。

Method: SPR（Spatial Preference Rewarding）方法通过引入语义和定位分数来全面评估MLLM生成描述的文本质量和定位质量，并对MLLM的响应进行奖励。该方法随机选择图像区域和描述，然后优化MLLM以更好地对齐视觉输入。

Result: SPR在标准的 Referring Expression Comprehension 和 Visual Grounding 基准测试中，有效地提升了MLLM的空间理解能力，且训练开销极小。

Conclusion: SPR是一种有效的提升MLLM空间理解能力的方法，通过奖励精确的响应来优化模型性能。

Abstract: Multimodal large language models~(MLLMs) have demonstrated promising spatial
understanding capabilities, such as referencing and grounding object
descriptions. Despite their successes, MLLMs still fall short in fine-grained
spatial perception abilities, such as generating detailed region descriptions
or accurately localizing objects. Additionally, they often fail to respond to
the user's requirements for desired fine-grained spatial understanding. This
issue might arise because existing approaches primarily focus on tuning MLLMs
to model pre-annotated instruction data to inject spatial knowledge, without
direct supervision of MLLMs' actual responses. We address this issue by SPR, a
Spatial Preference Rewarding~(SPR) approach that enhances MLLMs' spatial
capabilities by rewarding MLLMs' detailed responses with precise object
localization over vague or inaccurate responses. With randomly selected image
regions and region descriptions from MLLMs, SPR introduces semantic and
localization scores to comprehensively evaluate the text quality and
localization quality in MLLM-generated descriptions. We also refine the MLLM
descriptions with better localization accuracy and pair the best-scored
refinement with the initial descriptions of the lowest score for direct
preference optimization, thereby enhancing fine-grained alignment with visual
input. Extensive experiments over standard referring and grounding benchmarks
show that SPR improves MLLM spatial understanding capabilities effectively with
minimal overhead in training. Data and code will be released at
https://github.com/hanqiu-hq/SPR

</details>


### [30] [DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation](https://arxiv.org/abs/2510.14376)
*Dongnam Byun,Jungwon Park,Jumgmin Ko,Changin Choi,Wonjong Rhee*

Main category: cs.CV

TL;DR: DOS方法通过修改CLIP文本嵌入来解决文本到图像生成模型在处理多对象提示时遇到的问题，显著提高了多对象图像生成的成功率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在处理包含多个对象的提示时，常常会出现对象遗漏或对象混合的问题，尤其是在“相似形状”、“相似纹理”、“不同背景偏差”和“多对象”这四种场景下，对象间的关系容易导致失败。

Method: DOS方法通过修改CLIP文本嵌入，然后再将其输入到文本到图像模型中，以解决多对象生成问题。

Result: 实验结果表明，DOS方法能够持续提高多对象图像生成的成功率，并减少对象混合的现象。在用户评估中，DOS在四个基准测试中显著优于其他四种竞争方法，获得的投票数高出26.24%-43.04%。

Conclusion: DOS是一种实用且有效的方法，能够显著改善多对象图像的生成效果。

Abstract: Recent progress in text-to-image (T2I) generative models has led to
significant improvements in generating high-quality images aligned with text
prompts. However, these models still struggle with prompts involving multiple
objects, often resulting in object neglect or object mixing. Through extensive
studies, we identify four problematic scenarios, Similar Shapes, Similar
Textures, Dissimilar Background Biases, and Many Objects, where inter-object
relationships frequently lead to such failures. Motivated by two key
observations about CLIP embeddings, we propose DOS (Directional Object
Separation), a method that modifies three types of CLIP text embeddings before
passing them into text-to-image models. Experimental results show that DOS
consistently improves the success rate of multi-object image generation and
reduces object mixing. In human evaluations, DOS significantly outperforms four
competing methods, receiving 26.24%-43.04% more votes across four benchmarks.
These results highlight DOS as a practical and effective solution for improving
multi-object image generation.

</details>


### [31] [DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights](https://arxiv.org/abs/2510.14383)
*Danish Ali,Ajmal Mian,Naveed Akhtar,Ghulam Mubashar Hassan*

Main category: cs.CV

TL;DR: DRBD-Mamba是一种高效的3D分割模型，通过空间填充曲线、门控融合模块和量化块来解决Mamba在计算开销和鲁棒性方面的挑战，并在BraTS数据集上取得了优于现有技术的分割性能和效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Mamba的状态空间模型在脑肿瘤分割方面表现出色，但存在计算开销大和跨不同BraTS数据集划分的鲁棒性未经验证的问题。

Method: 提出了一种名为DRBD-Mamba的双分辨率双向Mamba模型。该模型利用空间填充曲线将3D特征映射到1D，以保留空间局部性并减少计算量；引入门控融合模块来整合前向和后向上下文，并结合量化块来提高鲁棒性；在BraTS2023上创建了五个系统性的数据划分，用于严格评估。

Result: 在BraTS2023的20%测试集上，DRBD-Mamba在整个肿瘤、肿瘤核心和增强肿瘤分割的Dice分数上分别提高了0.10%、1.75%和0.93%。在提出的五个系统性数据划分上的评估显示，与现有技术相比，DRBD-Mamba在肿瘤核心和增强肿瘤上的平均Dice分数分别提高了0.86%和1.45%，同时实现了15倍的效率提升。

Conclusion: DRBD-Mamba模型在提高脑肿瘤分割精度和鲁棒性的同时，显著降低了计算开销，在效率和分割性能方面均优于现有方法。

Abstract: Accurate brain tumor segmentation is significant for clinical diagnosis and
treatment. It is challenging due to the heterogeneity of tumor subregions.
Mamba-based State Space Models have demonstrated promising performance.
However, they incur significant computational overhead due to sequential
feature computation across multiple spatial axes. Moreover, their robustness
across diverse BraTS data partitions remains largely unexplored, leaving a
critical gap in reliable evaluation. To address these limitations, we propose
dual-resolution bi-directional Mamba (DRBD-Mamba), an efficient 3D segmentation
model that captures multi-scale long-range dependencies with minimal
computational overhead. We leverage a space-filling curve to preserve spatial
locality during 3D-to-1D feature mapping, thereby reducing reliance on
computationally expensive multi-axial feature scans. To enrich feature
representation, we propose a gated fusion module that adaptively integrates
forward and reverse contexts, along with a quantization block that discretizes
features to improve robustness. In addition, we propose five systematic folds
on BraTS2023 for rigorous evaluation of segmentation techniques under diverse
conditions and present detailed analysis of common failure scenarios. On the
20\% test set used by recent methods, our model achieves Dice improvements of
0.10\% for whole tumor, 1.75\% for tumor core, and 0.93\% for enhancing tumor.
Evaluations on the proposed systematic five folds demonstrate that our model
maintains competitive whole tumor accuracy while achieving clear average Dice
gains of 0.86\% for tumor core and 1.45\% for enhancing tumor over existing
state-of-the-art. Furthermore, our model attains 15 times improvement in
efficiency while maintaining high segmentation accuracy, highlighting its
robustness and computational advantage over existing approaches.

</details>


### [32] [BoardVision: Deployment-ready and Robust Motherboard Defect Detection with YOLO+Faster-RCNN Ensemble](https://arxiv.org/abs/2510.14389)
*Brandon Hill,Kma Solaiman*

Main category: cs.CV

TL;DR: 该研究提出了一个名为BoardVision的框架，用于检测主板组装级别的缺陷（如螺丝缺失、风扇接线松动、表面划痕等），并对YOLOv7和Faster R-CNN进行了系统性比较，提出了CTV Voter集成模型来平衡精确率和召回率，同时评估了模型在各种现实干扰下的鲁棒性，并发布了一个图形用户界面工具，以实现从研究到实际生产的转化。


<details>
  <summary>Details</summary>
Motivation: 主板缺陷检测对于确保电子产品大批量制造的可靠性至关重要。先前的研究主要集中在裸板或线缆级缺陷，而全主板组装级别的缺陷检测则较少被探索。

Method: 提出BoardVision框架，并在MiracleFactory主板数据集上对YOLOv7和Faster R-CNN两种检测器进行了基准测试和系统性比较。提出了一种名为CTV Voter的轻量级集成模型，通过可解释的规则来平衡精确率和召回率。此外，还评估了模型在锐度、亮度和方向变化等现实扰动下的鲁棒性。

Result: YOLOv7在精确率方面表现优于召回率，而Faster R-CNN则表现相反。CTV Voter集成模型能够平衡精确率和召回率。研究还揭示了在主板缺陷检测中稳定性面临的挑战，这些挑战常被忽视。

Conclusion: 该研究展示了计算机视觉技术如何能够从基准测试结果过渡到实际生产中的质量保证，为组装级别的主板制造提供了实用的解决方案。

Abstract: Motherboard defect detection is critical for ensuring reliability in
high-volume electronics manufacturing. While prior research in PCB inspection
has largely targeted bare-board or trace-level defects, assembly-level
inspection of full motherboards inspection remains underexplored. In this work,
we present BoardVision, a reproducible framework for detecting assembly-level
defects such as missing screws, loose fan wiring, and surface scratches. We
benchmark two representative detectors - YOLOv7 and Faster R-CNN, under
controlled conditions on the MiracleFactory motherboard dataset, providing the
first systematic comparison in this domain. To mitigate the limitations of
single models, where YOLO excels in precision but underperforms in recall and
Faster R-CNN shows the reverse, we propose a lightweight ensemble,
Confidence-Temporal Voting (CTV Voter), that balances precision and recall
through interpretable rules. We further evaluate robustness under realistic
perturbations including sharpness, brightness, and orientation changes,
highlighting stability challenges often overlooked in motherboard defect
detection. Finally, we release a deployable GUI-driven inspection tool that
bridges research evaluation with operator usability. Together, these
contributions demonstrate how computer vision techniques can transition from
benchmark results to practical quality assurance for assembly-level motherboard
manufacturing.

</details>


### [33] [DCMIL: A Progressive Representation Learning Model of Whole Slide Images for Cancer Prognosis Analysis](https://arxiv.org/abs/2510.14403)
*Chao Tu,Kun Huang,Jie Zhang,Qianjin Feng,Yu Zhang,Zhenyuan Ning*

Main category: cs.CV

TL;DR: DCMIL是一个处理全切片图像（WSIs）以进行癌症预后分析的计算病理学模型，它能克服计算瓶颈和标注稀缺性问题，并在多种癌症类型中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 计算病理学在癌症预后方面有巨大潜力，但受到计算瓶颈（WSIs尺寸巨大）和标注数据稀缺的限制。现有方法忽视了多放大倍率WSIs和肿瘤微环境的细微信息。

Method: 提出了一种易到难（easy-to-hard）的渐进式表示学习模型，称为双课程对比多实例学习（DCMIL），用于高效处理WSIs并进行癌症预后分析。该模型无需密集标注，可直接将WSIs转化为预后预测。

Result: 在十二种癌症类型（5,954名患者，12.54M张图像切片）上进行的大规模实验表明，DCMIL的性能优于标准的基于WSI的预后模型。此外，DCMIL能够识别出细粒度的预后相关区域，提供鲁棒的实例不确定性估计，并捕捉正常与肿瘤组织间的形态学差异。

Conclusion: DCMIL在计算病理学领域实现了高效的癌症预后分析，克服了现有方法的局限性，并在实验中展现了优越的性能和提供生物学见解的潜力。

Abstract: The burgeoning discipline of computational pathology shows promise in
harnessing whole slide images (WSIs) to quantify morphological heterogeneity
and develop objective prognostic modes for human cancers. However, progress is
impeded by the computational bottleneck of gigapixel-size inputs and the
scarcity of dense manual annotations. Current methods often overlook
fine-grained information across multi-magnification WSIs and variations in
tumor microenvironments. Here, we propose an easy-to-hard progressive
representation learning model, termed dual-curriculum contrastive
multi-instance learning (DCMIL), to efficiently process WSIs for cancer
prognosis. The model does not rely on dense annotations and enables the direct
transformation of gigapixel-size WSIs into outcome predictions. Extensive
experiments on twelve cancer types (5,954 patients, 12.54 million tiles)
demonstrate that DCMIL outperforms standard WSI-based prognostic models.
Additionally, DCMIL identifies fine-grained prognosis-salient regions, provides
robust instance uncertainty estimation, and captures morphological differences
between normal and tumor tissues, with the potential to generate new biological
insights. All codes have been made publicly accessible at
https://github.com/tuuuc/DCMIL.

</details>


### [34] [Real-Time Neural Video Compression with Unified Intra and Inter Coding](https://arxiv.org/abs/2510.14431)
*Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的神经视频压缩框架，通过统一的帧内/帧间编码和双向帧间冗余利用，克服了现有方法的局限性，并在压缩效率、稳定性和实时性方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有神经视频压缩技术在处理遮挡、新内容、帧间误差累积等方面存在不足。

Method: 提出了一种统一的神经视频压缩框架，能够自适应地进行帧内/帧间编码，并采用双向两帧压缩设计来利用帧间冗余。

Result: 所提出的方法比DCVC-RT平均BD率降低了10.7%，提供了更稳定的比特率和帧质量，并保持了实时编解码性能。

Conclusion: 该研究成功开发了一种更优越的神经视频压缩方法，解决了现有技术的痛点，并在性能上超越了先进的基线方法。

Abstract: Neural video compression (NVC) technologies have advanced rapidly in recent
years, yielding state-of-the-art schemes such as DCVC-RT that offer superior
compression efficiency to H.266/VVC and real-time encoding/decoding
capabilities. Nonetheless, existing NVC schemes have several limitations,
including inefficiency in dealing with disocclusion and new content, interframe
error propagation and accumulation, among others. To eliminate these
limitations, we borrow the idea from classic video coding schemes, which allow
intra coding within inter-coded frames. With the intra coding tool enabled,
disocclusion and new content are properly handled, and interframe error
propagation is naturally intercepted without the need for manual refresh
mechanisms. We present an NVC framework with unified intra and inter coding,
where every frame is processed by a single model that is trained to perform
intra/inter coding adaptively. Moreover, we propose a simultaneous two-frame
compression design to exploit interframe redundancy not only forwardly but also
backwardly. Experimental results show that our scheme outperforms DCVC-RT by an
average of 10.7\% BD-rate reduction, delivers more stable bitrate and quality
per frame, and retains real-time encoding/decoding performances. Code and
models will be released.

</details>


### [35] [Structured Universal Adversarial Attacks on Object Detection for Video Sequences](https://arxiv.org/abs/2510.14460)
*Sven Jacob,Weijia Shao,Gjergji Kasneci*

Main category: cs.CV

TL;DR: 提出了一种针对视频目标检测的、经过轻微扰动的、通用的对抗性攻击方法，该方法利用核范数正则化来促进集中在背景中的结构化扰动，并通过自适应、乐观的指数梯度方法进行优化。


<details>
  <summary>Details</summary>
Motivation: 深度学习目标检测器虽然性能优越，但容易受到对抗性攻击，特别是通用扰动。

Method: 利用核范数正则化来促进集中在背景中的结构化扰动，并通过自适应、乐观的指数梯度方法进行优化。

Result: 所提出的攻击方法在有效性方面优于低秩投影梯度下降和Frank-Wolfe攻击，同时保持了高度的隐蔽性。

Conclusion: 所提出的方法是一种有效的、隐蔽的、通用的对抗性攻击方法，适用于视频目标检测。

Abstract: Video-based object detection plays a vital role in safety-critical
applications. While deep learning-based object detectors have achieved
impressive performance, they remain vulnerable to adversarial attacks,
particularly those involving universal perturbations. In this work, we propose
a minimally distorted universal adversarial attack tailored for video object
detection, which leverages nuclear norm regularization to promote structured
perturbations concentrated in the background. To optimize this formulation
efficiently, we employ an adaptive, optimistic exponentiated gradient method
that enhances both scalability and convergence. Our results demonstrate that
the proposed attack outperforms both low-rank projected gradient descent and
Frank-Wolfe based attacks in effectiveness while maintaining high stealthiness.
All code and data are publicly available at
https://github.com/jsve96/AO-Exp-Attack.

</details>


### [36] [Unsupervised Deep Generative Models for Anomaly Detection in Neuroimaging: A Systematic Scoping Review](https://arxiv.org/abs/2510.14462)
*Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi*

Main category: cs.CV

TL;DR: 无监督深度生成模型在脑成像异常检测中展现出潜力，可替代监督方法，无需大量标注数据，仅需健康数据即可训练，识别偏离正常脑结构的异常。本综述（PRISMA 指导）涵盖了 2018-2025 年间 49 项关于自编码器、变分自编码器、生成对抗网络和去噪扩散模型的研究，应用于脑 MRI 和 CT，涵盖肿瘤、中风、多发性硬化症和小血管病等。模型在检测大病灶方面表现良好，并在解决细微异常方面取得进展。其优势在于生成可解释的伪健康重建图，尤其适用于罕见病。未来发展方向包括解剖结构感知模型、基础模型、任务相关的评估指标和临床验证，以实现临床应用。


<details>
  <summary>Details</summary>
Motivation: 无监督深度生成模型为脑成像异常检测提供了一种有前景的替代监督方法，能够利用仅有的健康数据识别异常，尤其适用于标注数据稀缺的情况。

Method: 本综述采用 PRISMA 指导的系统性回顾方法，筛选并分析了 2018 年至 2025 年间关于无监督深度生成模型（如自编码器、变分自编码器、生成对抗网络、去噪扩散模型）在脑成像异常检测中的应用，涵盖了不同模型架构、应用病症和性能评估。

Result: 共纳入 49 项研究，主要应用脑 MRI，部分应用 CT，涵盖肿瘤、中风、多发性硬化症和小血管病等。生成模型在检测大范围局灶性病变方面取得了鼓舞人心的性能，并在解决更细微的异常方面取得了进展。模型能够生成可解释的伪健康（反事实）重建图。

Conclusion: 无监督深度生成模型为脑成像异常检测提供了一个有力的方向，支持半监督学习、新型影像学生物标志物的发现以及在统一框架内进行疾病内和跨疾病的偏离图谱绘制。为实现临床应用，未来的研究应优先考虑解剖结构感知建模、基础模型开发、任务适当的评估指标以及严格的临床验证。

Abstract: Unsupervised deep generative models are emerging as a promising alternative
to supervised methods for detecting and segmenting anomalies in brain imaging.
Unlike fully supervised approaches, which require large voxel-level annotated
datasets and are limited to well-characterised pathologies, these models can be
trained exclusively on healthy data and identify anomalies as deviations from
learned normative brain structures. This PRISMA-guided scoping review
synthesises recent work on unsupervised deep generative models for anomaly
detection in neuroimaging, including autoencoders, variational autoencoders,
generative adversarial networks, and denoising diffusion models. A total of 49
studies published between 2018 - 2025 were identified, covering applications to
brain MRI and, less frequently, CT across diverse pathologies such as tumours,
stroke, multiple sclerosis, and small vessel disease. Reported performance
metrics are compared alongside architectural design choices. Across the
included studies, generative models achieved encouraging performance for large
focal lesions and demonstrated progress in addressing more subtle
abnormalities. A key strength of generative models is their ability to produce
interpretable pseudo-healthy (also referred to as counterfactual)
reconstructions, which is particularly valuable when annotated data are scarce,
as in rare or heterogeneous diseases. Looking ahead, these models offer a
compelling direction for anomaly detection, enabling semi-supervised learning,
supporting the discovery of novel imaging biomarkers, and facilitating within-
and cross-disease deviation mapping in unified end-to-end frameworks. To
realise clinical impact, future work should prioritise anatomy-aware modelling,
development of foundation models, task-appropriate evaluation metrics, and
rigorous clinical validation.

</details>


### [37] [Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration](https://arxiv.org/abs/2510.14463)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.CV

TL;DR: 提出了一种名为MIR-L的压缩策略，通过迭代剪枝和权重重置，在保持高性能的同时，大幅减少了多任务图像恢复模型的参数量。


<details>
  <summary>Details</summary>
Motivation: 在线社交网络（OSNs）上的图像会因有损压缩而质量下降，影响用户体验。现有的多任务图像恢复模型虽然能处理多种退化问题，但参数量过大，计算效率低。

Method: MIR-L模型采用迭代剪枝策略，分多轮移除低幅值权重，并将剩余权重重置为初始值，以发现能在高稀疏度下保持或超越密集模型性能的稀疏子网络（“赢家彩票”）。

Result: 在去雨、去雾和去噪任务的基准数据集上进行评估，MIR-L模型仅保留10%的可训练参数，同时保持了高图像恢复性能。

Conclusion: MIR-L通过有效的稀疏化策略，实现了多任务图像恢复模型的参数压缩，同时保持了优异的性能，解决了现有模型计算效率低的问题。

Abstract: Image quality is a critical factor in delivering visually appealing content
on web platforms. However, images often suffer from degradation due to lossy
operations applied by online social networks (OSNs), negatively affecting user
experience. Image restoration is the process of recovering a clean high-quality
image from a given degraded input. Recently, multi-task (all-in-one) image
restoration models have gained significant attention, due to their ability to
simultaneously handle different types of image degradations. However, these
models often come with an excessively high number of trainable parameters,
making them computationally inefficient. In this paper, we propose a strategy
for compressing multi-task image restoration models. We aim to discover highly
sparse subnetworks within overparameterized deep models that can match or even
surpass the performance of their dense counterparts. The proposed model, namely
MIR-L, utilizes an iterative pruning strategy that removes low-magnitude
weights across multiple rounds, while resetting the remaining weights to their
original initialization. This iterative process is important for the multi-task
image restoration model's optimization, effectively uncovering "winning
tickets" that maintain or exceed state-of-the-art performance at high sparsity
levels. Experimental evaluation on benchmark datasets for the deraining,
dehazing, and denoising tasks shows that MIR-L retains only 10% of the
trainable parameters while maintaining high image restoration performance. Our
code, datasets and pre-trained models are made publicly available at
https://github.com/Thomkat/MIR-L.

</details>


### [38] [Grazing Detection using Deep Learning and Sentinel-2 Time Series Data](https://arxiv.org/abs/2510.14493)
*Aleksis Pirinen,Delia Fano Yela,Smita Chakraborty,Erik Källman*

Main category: cs.CV

TL;DR: Grazing detection from Sentinel-2 satellite imagery using CNN-LSTM models can help prioritize inspection resources for land-use compliance, achieving 77% F1 score and improving efficiency by 17.2 times compared to random inspection.


<details>
  <summary>Details</summary>
Motivation: Scalable monitoring of grazing, which shapes agricultural production and biodiversity, is limited. This paper aims to develop a method for seasonal grazing detection using satellite imagery to guide inspection resources.

Method: The study trains an ensemble of CNN-LSTM models on multi-temporal reflectance features from Sentinel-2 L2A imagery (April-October) for binary prediction (grazed/not grazed) on polygon-defined field boundaries. The model's operational value is assessed by comparing prioritized inspection of non-grazed fields with random inspection.

Result: The CNN-LSTM models achieve an average F1 score of 77% across five validation splits, with 90% recall on grazed pastures. Prioritizing fields predicted as non-grazed for inspection leads to 17.2 times more confirmed non-grazing sites than random inspection, assuming inspectors can visit at most 4% of sites annually.

Conclusion: Freely available, coarse-resolution satellite data can reliably guide inspection resources for conservation-aligned land-use compliance, as demonstrated by the effective grazing detection and prioritized inspection strategy. Code and models are publicly available.

Abstract: Grazing shapes both agricultural production and biodiversity, yet scalable
monitoring of where grazing occurs remains limited. We study seasonal grazing
detection from Sentinel-2 L2A time series: for each polygon-defined field
boundary, April-October imagery is used for binary prediction (grazed / not
grazed). We train an ensemble of CNN-LSTM models on multi-temporal reflectance
features, and achieve an average F1 score of 77 percent across five validation
splits, with 90 percent recall on grazed pastures. Operationally, if inspectors
can visit at most 4 percent of sites annually, prioritising fields predicted by
our model as non-grazed yields 17.2 times more confirmed non-grazing sites than
random inspection. These results indicate that coarse-resolution, freely
available satellite data can reliably steer inspection resources for
conservation-aligned land-use compliance. Code and models have been made
publicly available.

</details>


### [39] [Vision Mamba for Permeability Prediction of Porous Media](https://arxiv.org/abs/2510.14516)
*Ali Kashefi,Tapan Mukerji*

Main category: cs.CV

TL;DR: Vision Mamba因其线性扩展的网络尺寸和更少的训练参数，在图像分类和三维多孔介质渗透率预测方面优于ViT和CNN，并提供了相应的源代码。


<details>
  <summary>Details</summary>
Motivation: 由于Vision Mamba在网络尺寸和参数数量上的优势，使其在计算和内存效率方面优于ViT和CNN，因此有必要将其应用于三维多孔介质渗透率预测任务，并与现有模型进行比较。

Method: 提出了一种使用Vision Mamba作为骨干网络来预测三维多孔介质渗透率的神经网络。将该模型与ViT和CNN模型在渗透率预测的多个方面进行了性能比较，并进行了消融研究以评估其组件对准确性的影响。

Result: Vision Mamba在三维多孔介质渗透率预测任务中展现出优于ViT和CNN的性能，证明了其在计算和内存效率方面的优势。

Conclusion: Vision Mamba在三维多孔介质渗透率预测任务中具有实际优势，并且有潜力被集成到大型视觉模型中，取代ViTs。代码已公开，以促进可重复性和进一步研究。

Abstract: Vision Mamba has recently received attention as an alternative to Vision
Transformers (ViTs) for image classification. The network size of Vision Mamba
scales linearly with input image resolution, whereas ViTs scale quadratically,
a feature that improves computational and memory efficiency. Moreover, Vision
Mamba requires a significantly smaller number of trainable parameters than
traditional convolutional neural networks (CNNs), and thus, they can be more
memory efficient. Because of these features, we introduce, for the first time,
a neural network that uses Vision Mamba as its backbone for predicting the
permeability of three-dimensional porous media. We compare the performance of
Vision Mamba with ViT and CNN models across multiple aspects of permeability
prediction and perform an ablation study to assess the effects of its
components on accuracy. We demonstrate in practice the aforementioned
advantages of Vision Mamba over ViTs and CNNs in the permeability prediction of
three-dimensional porous media. We make the source code publicly available to
facilitate reproducibility and to enable other researchers to build on and
extend this work. We believe the proposed framework has the potential to be
integrated into large vision models in which Vision Mamba is used instead of
ViTs.

</details>


### [40] [Real-Time Surgical Instrument Defect Detection via Non-Destructive Testing](https://arxiv.org/abs/2510.14525)
*Qurrat Ul Ain,Atif Aftab Ahmed Jilani,Zunaira Shafqat,Nigar Azhar Butt*

Main category: cs.CV

TL;DR: AI驱动的外科手术器械缺陷检测框架SurgScan，使用YOLOv8，准确率达99.3%，实时推断速度快，适用于工业部署，符合ISO 13485和FDA标准。


<details>
  <summary>Details</summary>
Motivation: 手动检查外科手术器械存在人为错误和不一致的风险，可能影响无菌性、机械完整性和患者安全。

Method: 利用YOLOv8开发了一个名为SurgScan的AI框架，对102,876张图像（涵盖11种器械和5类缺陷）进行训练，并采用对比度增强预处理。

Result: SurgScan在实时检测中实现了99.3%的准确率，推断速度为4.2-5.8毫秒/图像，优于其他CNN架构，并证明了对比度增强预处理的有效性。

Conclusion: SurgScan为外科手术器械的自动化质量控制提供了一个可扩展、经济高效的AI解决方案，减少了对手动检查的依赖，并确保符合行业标准。

Abstract: Defective surgical instruments pose serious risks to sterility, mechanical
integrity, and patient safety, increasing the likelihood of surgical
complications. However, quality control in surgical instrument manufacturing
often relies on manual inspection, which is prone to human error and
inconsistency. This study introduces SurgScan, an AI-powered defect detection
framework for surgical instruments. Using YOLOv8, SurgScan classifies defects
in real-time, ensuring high accuracy and industrial scalability. The model is
trained on a high-resolution dataset of 102,876 images, covering 11 instrument
types and five major defect categories. Extensive evaluation against
state-of-the-art CNN architectures confirms that SurgScan achieves the highest
accuracy (99.3%) with real-time inference speeds of 4.2-5.8 ms per image,
making it suitable for industrial deployment. Statistical analysis demonstrates
that contrast-enhanced preprocessing significantly improves defect detection,
addressing key limitations in visual inspection. SurgScan provides a scalable,
cost-effective AI solution for automated quality control, reducing reliance on
manual inspection while ensuring compliance with ISO 13485 and FDA standards,
paving the way for enhanced defect detection in medical manufacturing.

</details>


### [41] [Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models](https://arxiv.org/abs/2510.14526)
*Yunze Tong,Didi Zhu,Zijing Hu,Jinluan Yang,Ziyu Zhao*

Main category: cs.CV

TL;DR: 通过引入一个新颖的噪声投影器，该投影器在潜在空间中对初始噪声进行条件化提炼，以解决文本到图像生成中的提示-图像不对齐问题，而无需修改预训练的Stable Diffusion模型。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成方法在处理提示-图像不对齐问题时，要么改变去噪动态，要么在推理时生成多个噪声并进行后选择。本文旨在解决训练-推理不匹配问题，即在训练过程中，提示条件化噪声位于特定提示的潜在空间子集中，而在推理时，噪声是从与提示无关的高斯先验中提取的。

Method: 提出一种噪声投影器，在去噪之前对初始噪声进行文本条件化提炼。该投影器根据提示嵌入将噪声映射到与提示相关的版本，从而更好地匹配SD训练期间观察到的分布，并且不修改SD模型。该框架包括：1. 采样噪声并从视觉-语言模型（VLM）获取对应图像的 token 级反馈；2. 将这些信号提取到奖励模型中；3. 通过准直接偏好优化（quasi-direct preference optimization）来优化噪声投影器。

Result: 该方法无需参考图像或手工先验，并且推理成本低，通过单次前向传播替代了多样本选择。实验证明，本文提出的提示感知噪声投影能有效提升各种提示下的文本-图像对齐度。

Conclusion: 本文提出的噪声投影器能够有效解决文本到图像生成中的提示-图像不对齐问题，通过在潜在空间中对初始噪声进行提炼，使其与提示更相关，从而提高生成图像的质量和准确性，同时保持了较低的推理成本。

Abstract: In text-to-image generation, different initial noises induce distinct
denoising paths with a pretrained Stable Diffusion (SD) model. While this
pattern could output diverse images, some of them may fail to align well with
the prompt. Existing methods alleviate this issue either by altering the
denoising dynamics or by drawing multiple noises and conducting post-selection.
In this paper, we attribute the misalignment to a training-inference mismatch:
during training, prompt-conditioned noises lie in a prompt-specific subset of
the latent space, whereas at inference the noise is drawn from a
prompt-agnostic Gaussian prior. To close this gap, we propose a noise projector
that applies text-conditioned refinement to the initial noise before denoising.
Conditioned on the prompt embedding, it maps the noise to a prompt-aware
counterpart that better matches the distribution observed during SD training,
without modifying the SD model. Our framework consists of these steps: we first
sample some noises and obtain token-level feedback for their corresponding
images from a vision-language model (VLM), then distill these signals into a
reward model, and finally optimize the noise projector via a quasi-direct
preference optimization. Our design has two benefits: (i) it requires no
reference images or handcrafted priors, and (ii) it incurs small inference
cost, replacing multi-sample selection with a single forward pass. Extensive
experiments further show that our prompt-aware noise projection improves
text-image alignment across diverse prompts.

</details>


### [42] [PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model](https://arxiv.org/abs/2510.14528)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Handong Zheng,Jing Zhang,Jun Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL是一款高效、资源节省的文档解析模型，其核心是PaddleOCR-VL-0.9B视觉-语言模型（VLM），集成了NaViT视觉编码器和ERNIE-4.5-0.3B语言模型，支持109种语言，能准确识别文本、表格、公式和图表等复杂元素，且资源消耗低。该模型在公开和内部基准测试中均达到SOTA性能，超越现有解决方案，推理速度快，适用于实际部署。


<details>
  <summary>Details</summary>
Motivation: 提出PaddleOCR-VL，一个针对文档解析的SOTA且资源高效的模型。

Method: PaddleOCR-VL-0.9B，一个结合了NaViT风格的动态分辨率视觉编码器和ERNIE-4.5-0.3B语言模型的视觉-语言模型（VLM）。

Result: 在公开和内部基准测试中，PaddleOCR-VL在页面级文档解析和元素级识别方面均达到SOTA性能，显著优于现有解决方案，并与顶级VLM相比具有很强的竞争力，推理速度快。

Conclusion: PaddleOCR-VL因其在性能、效率和速度方面的优势，非常适合在实际场景中部署。

Abstract: In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model
tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a
compact yet powerful vision-language model (VLM) that integrates a NaViT-style
dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to
enable accurate element recognition. This innovative model efficiently supports
109 languages and excels in recognizing complex elements (e.g., text, tables,
formulas, and charts), while maintaining minimal resource consumption. Through
comprehensive evaluations on widely used public benchmarks and in-house
benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document
parsing and element-level recognition. It significantly outperforms existing
solutions, exhibits strong competitiveness against top-tier VLMs, and delivers
fast inference speeds. These strengths make it highly suitable for practical
deployment in real-world scenarios.

</details>


### [43] [Towards Generalist Intelligence in Dentistry: Vision Foundation Models for Oral and Maxillofacial Radiology](https://arxiv.org/abs/2510.14532)
*Xinrui Huang,Fan Xiao,Dongming He,Anqi Gao,Dandan Li,Xiaofan Zhang,Shaoting Zhang,Xudong Wang*

Main category: cs.CV

TL;DR: DentVFM是首个用于牙科的视觉基础模型（VFM），可应用于多种牙科任务，并在DentBench基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的牙科AI系统存在单模态、任务特定和依赖昂贵标注数据的局限性，影响了其在不同临床场景的泛化能力。现有牙科影像评估和基准测试存在不足。

Method: 提出DentVFM，一个基于Vision Transformer（ViT）架构的2D和3D视觉基础模型，利用自监督学习在包含约160万张多模态牙科影像的DentVista数据集上进行训练。同时，提出DentBench，一个涵盖八个牙科亚专业、多种疾病、成像模态和广泛地理分布的综合基准测试。

Result: DentVFM在疾病诊断、治疗分析、生物标志物识别、解剖标志物检测和分割等多种牙科任务上展现出强大的泛化能力，显著优于监督、自监督和弱监督基线模型，在泛化性、标签效率和可扩展性方面表现更优。DentVFM还能实现跨模态诊断，在传统影像不可用时提供比经验丰富的牙医更可靠的结果。

Conclusion: DentVFM为牙科AI设立了新的范例，提供了一个可扩展、适应性强且标签效率高的模型，以改善智能牙科医疗并解决全球口腔医疗的关键差距。

Abstract: Oral and maxillofacial radiology plays a vital role in dental healthcare, but
radiographic image interpretation is limited by a shortage of trained
professionals. While AI approaches have shown promise, existing dental AI
systems are restricted by their single-modality focus, task-specific design,
and reliance on costly labeled data, hindering their generalization across
diverse clinical scenarios. To address these challenges, we introduce DentVFM,
the first family of vision foundation models (VFMs) designed for dentistry.
DentVFM generates task-agnostic visual representations for a wide range of
dental applications and uses self-supervised learning on DentVista, a large
curated dental imaging dataset with approximately 1.6 million multi-modal
radiographic images from various medical centers. DentVFM includes 2D and 3D
variants based on the Vision Transformer (ViT) architecture. To address gaps in
dental intelligence assessment and benchmarks, we introduce DentBench, a
comprehensive benchmark covering eight dental subspecialties, more diseases,
imaging modalities, and a wide geographical distribution. DentVFM shows
impressive generalist intelligence, demonstrating robust generalization to
diverse dental tasks, such as disease diagnosis, treatment analysis, biomarker
identification, and anatomical landmark detection and segmentation.
Experimental results indicate DentVFM significantly outperforms supervised,
self-supervised, and weakly supervised baselines, offering superior
generalization, label efficiency, and scalability. Additionally, DentVFM
enables cross-modality diagnostics, providing more reliable results than
experienced dentists in situations where conventional imaging is unavailable.
DentVFM sets a new paradigm for dental AI, offering a scalable, adaptable, and
label-efficient model to improve intelligent dental healthcare and address
critical gaps in global oral healthcare.

</details>


### [44] [QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models](https://arxiv.org/abs/2510.14836)
*Yixuan Li,Yuhui Chen,Mingcai Zhou,Haoran Li*

Main category: cs.CV

TL;DR: QDepth-VLA框架通过引入辅助深度预测任务，增强了视觉-语言-动作（VLA）模型在精细操作任务中的三维空间理解和推理能力，实验证明其在仿真和真实世界任务中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理解和推理三维结构以实现精确控制方面存在不足，而三维空间感知和推理对于视觉-语言-动作（VLA）模型完成精细操作任务至关重要。

Method: 提出QDepth-VLA框架，通过一个专门设计的深度专家来预测量化后的深度图潜在表示，以增强VLA模型。该深度专家使用VQ-VAE编码器获取的深度图的量化潜在token，从而使模型能够学习捕捉关键几何线索的深度感知表示。

Result: 在仿真基准和真实世界任务上的实验结果表明，QDepth-VLA在空间推理和操作任务上取得了有竞争力的性能。

Conclusion: QDepth-VLA能够学习深度感知表示，捕获关键的几何线索，从而提升VLA模型在精细操作任务中的空间推理和整体性能。

Abstract: Spatial perception and reasoning are crucial for Vision-Language-Action (VLA)
models to accomplish fine-grained manipulation tasks. However, existing
approaches often lack the ability to understand and reason over the essential
3D structures necessary for precise control. To address this limitation, we
propose QDepth-VLA, a general framework that augments VLA models with an
auxiliary depth prediction task. A dedicated depth expert is designed to
predict quantized latent tokens of depth maps obtained from a VQ-VAE encoder,
enabling the model to learn depth-aware representations that capture critical
geometric cues. Experimental results on the simulation benchmarks and
real-world tasks demonstrate that QDepth-VLA yields strong spatial reasoning
and competitive performance on manipulation tasks.

</details>


### [45] [Acquisition of interpretable domain information during brain MR image harmonization for content-based image retrieval](https://arxiv.org/abs/2510.14535)
*Keima Abe,Hayato Muraki,Shuhei Tomoshige,Kenichi Oishi,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 该研究提出了一种名为PL-SE-ADA的框架，用于解决医学图像（如MR扫描）中的域偏移问题，同时实现可解释的表征学习。


<details>
  <summary>Details</summary>
Motivation: 医学图像在不同成像设备和协议下存在域偏移，这会影响机器学习在疾病分类等任务中的性能。现有的域协调方法虽然效果好，但缺乏可解释性，无法解决实际问题。

Method: PL-SE-ADA框架包含两个编码器（提取域不变和域特定特征）、一个解码器（重建图像）和一个域预测器。通过对抗训练和图像重建，该模型在实现域协调的同时，保留了疾病相关信息，并确保了模型的可解释性。

Result: 与现有方法相比，PL-SE-ADA在图像重建、疾病分类和域识别方面达到了同等或更好的性能，并且能够可视化域独立和域特定的特征，提供了整个框架的高可解释性。

Conclusion: PL-SE-ADA框架成功地解决了医学图像的域偏移问题，并实现了可解释的表征学习，在医学图像分析领域具有重要的应用价值。

Abstract: Medical images like MR scans often show domain shifts across imaging sites
due to scanner and protocol differences, which degrade machine learning
performance in tasks such as disease classification. Domain harmonization is
thus a critical research focus. Recent approaches encode brain images
$\boldsymbol{x}$ into a low-dimensional latent space $\boldsymbol{z}$, then
disentangle it into $\boldsymbol{z_u}$ (domain-invariant) and
$\boldsymbol{z_d}$ (domain-specific), achieving strong results. However, these
methods often lack interpretability$-$an essential requirement in medical
applications$-$leaving practical issues unresolved. We propose
Pseudo-Linear-Style Encoder Adversarial Domain Adaptation (PL-SE-ADA), a
general framework for domain harmonization and interpretable representation
learning that preserves disease-relevant information in brain MR images.
PL-SE-ADA includes two encoders $f_E$ and $f_{SE}$ to extract
$\boldsymbol{z_u}$ and $\boldsymbol{z_d}$, a decoder to reconstruct the image
$f_D$, and a domain predictor $g_D$. Beyond adversarial training between the
encoder and domain predictor, the model learns to reconstruct the input image
$\boldsymbol{x}$ by summing reconstructions from $\boldsymbol{z_u}$ and
$\boldsymbol{z_d}$, ensuring both harmonization and informativeness. Compared
to prior methods, PL-SE-ADA achieves equal or better performance in image
reconstruction, disease classification, and domain recognition. It also enables
visualization of both domain-independent brain features and domain-specific
components, offering high interpretability across the entire framework.

</details>


### [46] [Exploring Image Representation with Decoupled Classical Visual Descriptors](https://arxiv.org/abs/2510.14536)
*Chenyuan Qu,Hao Chen,Jianbo Jiao*

Main category: cs.CV

TL;DR: VisualSplit框架通过将图像分解为经典视觉描述符来弥合深度学习的可解释性与经典计算机视觉方法的直观性之间的差距，并在图像生成和编辑等任务中展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 弥合深度学习模型内部表征不透明与经典视觉描述符（如边缘、颜色、强度分布）直观可理解性之间的差距，探索现代学习方法是否能从经典视觉线索中受益。

Method: 提出VisualSplit框架，将图像明确分解为解耦的经典描述符，并将每个描述符视为独立的但互补的视觉知识组成部分。通过一个以重建为驱动的预训练方案来学习每个视觉描述符的本质，同时保持其可解释性。

Result: VisualSplit框架通过明确分解视觉属性，在图像生成和编辑等任务中实现了有效的属性控制，这些任务超出了传统的分类和分割。

Conclusion: VisualSplit框架证明了这种通过分解和利用经典视觉描述符的新颖学习方法在视觉理解方面的有效性，尤其是在需要属性控制的高级视觉任务中。

Abstract: Exploring and understanding efficient image representations is a
long-standing challenge in computer vision. While deep learning has achieved
remarkable progress across image understanding tasks, its internal
representations are often opaque, making it difficult to interpret how visual
information is processed. In contrast, classical visual descriptors (e.g. edge,
colour, and intensity distribution) have long been fundamental to image
analysis and remain intuitively understandable to humans. Motivated by this
gap, we ask a central question: Can modern learning benefit from these
classical cues? In this paper, we answer it with VisualSplit, a framework that
explicitly decomposes images into decoupled classical descriptors, treating
each as an independent but complementary component of visual knowledge. Through
a reconstruction-driven pre-training scheme, VisualSplit learns to capture the
essence of each visual descriptor while preserving their interpretability. By
explicitly decomposing visual attributes, our method inherently facilitates
effective attribute control in various advanced visual tasks, including image
generation and editing, extending beyond conventional classification and
segmentation, suggesting the effectiveness of this new learning approach for
visual understanding. Project page: https://chenyuanqu.com/VisualSplit/.

</details>


### [47] [Exploring Cross-Modal Flows for Few-Shot Learning](https://arxiv.org/abs/2510.14543)
*Ziqi Jiang,Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 现有的参数高效微调(PEFT)方法在处理复杂跨模态任务时，由于其单步调整的局限性，对齐效果不佳。本文提出了首个多步调整方法FMA，通过学习跨模态速度场，采用固定耦合策略、噪声增强策略和提前停止求解器，实现了更精确鲁棒的对齐，并在多项基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调（PEFT）方法在处理跨模态任务时，通常只对视觉或文本特征进行单步调整，这对于特征高度交织的复杂数据集来说是不够的，无法实现精确的跨模态对齐。

Method: 提出了一种名为Flow Matching Alignment (FMA) 的模型无关的多步调整方法。该方法通过学习跨模态速度场来实现对齐，具体包括：1. 采用固定的耦合策略来保证训练过程中的类别对应关系；2. 引入噪声增强策略来缓解数据稀疏问题；3. 设计提前停止求解器来优化效率和精度。

Result: FMA相比于单步PEFT方法，具有多步校正能力，能够实现更精确和鲁棒的对齐。在多个基准测试和骨干网络上的大量实验结果表明，FMA能够持续带来显著的性能提升，尤其在具有挑战性的数据集上表现更优。

Conclusion: FMA作为首个模型无关的多步调整方法，通过学习跨模态速度场，有效解决了现有单步PEFT方法在复杂数据集上的对齐局限性，显著提升了跨模态任务的性能。

Abstract: Aligning features from different modalities, is one of the most fundamental
challenges for cross-modal tasks. Although pre-trained vision-language models
can achieve a general alignment between image and text, they often require
parameter-efficient fine-tuning (PEFT) for further adjustment. Today's PEFT
methods (e.g., prompt tuning, LoRA-based, or adapter-based) always selectively
fine-tune a subset of parameters, which can slightly adjust either visual or
textual features, and avoid overfitting. In this paper, we are the first to
highlight that all existing PEFT methods perform one-step adjustment. It is
insufficient for complex (or difficult) datasets, where features of different
modalities are highly entangled. To this end, we propose the first
model-agnostic multi-step adjustment approach by learning a cross-modal
velocity field: Flow Matching Alignment (FMA). Specifically, to ensure the
correspondence between categories during training, we first utilize a fixed
coupling strategy. Then, we propose a noise augmentation strategy to alleviate
the data scarcity issue. Finally, we design an early-stopping solver, which
terminates the transformation process earlier, improving both efficiency and
accuracy. Compared with one-step PEFT methods, FMA has the multi-step
rectification ability to achieve more precise and robust alignment. Extensive
results have demonstrated that FMA can consistently yield significant
performance gains across various benchmarks and backbones, particularly on
challenging datasets.

</details>


### [48] [Consistent text-to-image generation via scene de-contextualization](https://arxiv.org/abs/2510.14553)
*Song Tang,Peihao Gong,Kunyu Li,Kai Guo,Boyu Wang,Mao Ye,Jianwei Zhang,Xiatian Zhu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“场景去语境化”（SDeC）的训练无关方法，通过编辑提示嵌入来解决文本到图像生成中的身份（ID）偏移问题，该方法能够有效抑制场景与身份之间的固有相关性，从而在不预知所有目标场景的情况下，显著提高身份保持能力并维持场景多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性文本到图像（T2I）生成方法在保持同一主体在不同场景下的身份一致性方面存在困难，即“身份偏移”问题。以往的方法通常假设所有目标场景都可预知，这在现实应用中不切实际。本研究揭示了身份偏移的一个关键原因是主体与场景之间存在的“场景语境化”固有相关性。

Method: 本研究提出了一种名为“场景去语境化”（SDeC）的训练无关方法。该方法通过在提示嵌入层面进行编辑，来抑制T2I模型内置的场景语境化过程。具体而言，SDeC通过量化SVD（奇异值分解）的方向稳定性，来识别并抑制嵌入中存在的场景-ID相关性，通过自适应地重新加权相应的特征值来实现。

Result: 实验结果表明，SDeC方法在显著提高身份保持能力的同时，能够有效地维持场景的多样性，解决了现有方法在处理未知或多变场景时的局限性。

Conclusion: SDeC是一种新颖、高效且无需训练的提示嵌入编辑方法，它通过消除场景与身份之间的固有相关性，解决了文本到图像生成中的身份偏移问题。该方法具有高度的灵活性和通用性，特别适用于那些无法预知所有目标场景的现实世界应用，并且只需针对单个场景进行优化，无需预先了解所有目标场景。

Abstract: Consistent text-to-image (T2I) generation seeks to produce
identity-preserving images of the same subject across diverse scenes, yet it
often fails due to a phenomenon called identity (ID) shift. Previous methods
have tackled this issue, but typically rely on the unrealistic assumption of
knowing all target scenes in advance. This paper reveals that a key source of
ID shift is the native correlation between subject and scene context, called
scene contextualization, which arises naturally as T2I models fit the training
distribution of vast natural images. We formally prove the near-universality of
this scene-ID correlation and derive theoretical bounds on its strength. On
this basis, we propose a novel, efficient, training-free prompt embedding
editing approach, called Scene De-Contextualization (SDeC), that imposes an
inversion process of T2I's built-in scene contextualization. Specifically, it
identifies and suppresses the latent scene-ID correlation within the ID
prompt's embedding by quantifying the SVD directional stability to adaptively
re-weight the corresponding eigenvalues. Critically, SDeC allows for per-scene
use (one scene per prompt) without requiring prior access to all target scenes.
This makes it a highly flexible and general solution well-suited to real-world
applications where such prior knowledge is often unavailable or varies over
time. Experiments demonstrate that SDeC significantly enhances identity
preservation while maintaining scene diversity.

</details>


### [49] [Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video](https://arxiv.org/abs/2510.14560)
*Yulin Zhang,Cheng Shi,Yang Wang,Sibei Yang*

Main category: cs.CV

TL;DR: 提出了一种名为ESTP-Bench的基准和ESTP-F1指标，用于评估和解决AI在人类环境中理解、预测和响应事件的能力。


<details>
  <summary>Details</summary>
Motivation: 让AI能够像人类一样在真实环境中运行，不仅能观察，更能主动理解、预测和响应事件。

Method: 引入ESTP-Bench基准和ESTP-F1指标，并提出一个包含数据引擎、多阶段训练策略和主动动态压缩技术的技术流程，以实现主动、及时和高效的AI。

Result: 提出的模型在多个在线和离线基准测试中表现优于现有方法。

Conclusion: 提出的技术流程和基准能够有效提升AI在真实环境中主动响应和推理的能力。

Abstract: Envision an AI capable of functioning in human-like settings, moving beyond
mere observation to actively understand, anticipate, and proactively respond to
unfolding events. Towards this vision, we focus on the innovative task where,
given ego-streaming video input, an assistant proactively answers diverse,
evolving questions at the opportune moment, while maintaining synchronized
perception and reasoning. This task embodies three key properties: (1)
Proactive Coherence, (2) Just-in-Time Responsiveness, and (3) Synchronized
Efficiency. To evaluate and address these properties, we first introduce
ESTP-Bench (Ego Streaming Proactive Benchmark) alongside the ESTP-F1 metric-a
novel framework designed for their rigorous assessment. Secondly, we propose a
comprehensive technical pipeline to enable models to tackle this challenging
task. This pipeline comprises: (1) a data engine, (2) a multi-stage training
strategy, and (3) a proactive dynamic compression technique. Our proposed model
effectively addresses these critical properties while outperforming multiple
baselines across diverse online and offline benchmarks. Project
Page:https://zhangyl4.github.io/publications/eyes-wide-open/

</details>


### [50] [BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU](https://arxiv.org/abs/2510.14564)
*Junyi Wu,Jiaming Xu,Jinhao Li,Yongkang Zhou,Jiayi Pan,Xingyang Li,Guohao Dai*

Main category: cs.CV

TL;DR: BalanceGS通过算法-系统协同设计，优化了3D高斯泼溅（3DGS）的训练效率，实现了1.44倍的加速，同时几乎不损失重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统的3DGS训练流程存在高斯密度分配不均、高斯投影计算负载不平衡以及颜色泼溅时内存访问碎片化等三个关键效率问题。

Method: 1. 算法层面：提出启发式工作负载敏感的高斯密度控制，自动平衡点分布，移除80%的冗余高斯，并填充稀疏区域。2. 系统层面：提出基于相似性的高斯采样与合并，用自适应工作负载分配取代静态线程-像素映射，实现动态工作负载分配。3. 映射层面：提出基于重排序的内存访问映射策略，重构RGB存储并实现共享内存中的批量加载。

Result: 与3DGS相比，BalanceGS在NVIDIA A100 GPU上实现了1.44倍的训练速度提升，且重建质量的下降可以忽略不计。

Conclusion: BalanceGS通过算法和系统层面的协同设计，有效解决了3DGS训练中的效率瓶颈，显著提高了训练速度，同时保持了高质量的重建结果。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a promising 3D reconstruction
technique. The traditional 3DGS training pipeline follows three sequential
steps: Gaussian densification, Gaussian projection, and color splatting.
Despite its promising reconstruction quality, this conventional approach
suffers from three critical inefficiencies: (1) Skewed density allocation
during Gaussian densification, (2) Imbalanced computation workload during
Gaussian projection and (3) Fragmented memory access during color splatting.
  To tackle the above challenges, we introduce BalanceGS, the algorithm-system
co-design for efficient training in 3DGS. (1) At the algorithm level, we
propose heuristic workload-sensitive Gaussian density control to automatically
balance point distributions - removing 80% redundant Gaussians in dense regions
while filling gaps in sparse areas. (2) At the system level, we propose
Similarity-based Gaussian sampling and merging, which replaces the static
one-to-one thread-pixel mapping with adaptive workload distribution - threads
now dynamically process variable numbers of Gaussians based on local cluster
density. (3) At the mapping level, we propose reordering-based memory access
mapping strategy that restructures RGB storage and enables batch loading in
shared memory.
  Extensive experiments demonstrate that compared with 3DGS, our approach
achieves a 1.44$\times$ training speedup on a NVIDIA A100 GPU with negligible
quality degradation.

</details>


### [51] [CALM-Net: Curvature-Aware LiDAR Point Cloud-based Multi-Branch Neural Network for Vehicle Re-Identification](https://arxiv.org/abs/2510.14576)
*Dongwook Lee,Sol Han,Jinwhan Kim*

Main category: cs.CV

TL;DR: CALM-Net是一个用于车辆重识别的基于激光雷达点云的多分支神经网络，通过结合边缘卷积、点注意力机制和曲率嵌入来学习判别性和互补性特征，在nuScenes数据集上实现了约1.97%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 从三维点云中学习判别性和互补性特征，以区分不同的车辆。

Method: 采用多分支网络架构，整合了边缘卷积、点注意力机制和曲率嵌入，以表征点云的局部表面变化。

Result: 在nuScenes数据集上，CALM-Net的平均识别准确率比最强的基线模型高出约1.97个百分点。

Conclusion: 将曲率信息纳入深度学习模型以及采用多分支特征学习有助于提高基于激光雷达点云的车辆重识别性能。

Abstract: This paper presents CALM-Net, a curvature-aware LiDAR point cloud-based
multi-branch neural network for vehicle re-identification. The proposed model
addresses the challenge of learning discriminative and complementary features
from three-dimensional point clouds to distinguish between vehicles. CALM-Net
employs a multi-branch architecture that integrates edge convolution, point
attention, and a curvature embedding that characterizes local surface variation
in point clouds. By combining these mechanisms, the model learns richer
geometric and contextual features that are well suited for the
re-identification task. Experimental evaluation on the large-scale nuScenes
dataset demonstrates that CALM-Net achieves a mean re-identification accuracy
improvement of approximately 1.97\% points compared with the strongest baseline
in our study. The results confirms the effectiveness of incorporating curvature
information into deep learning architectures and highlight the benefit of
multi-branch feature learning for LiDAR point cloud-based vehicle
re-identification.

</details>


### [52] [Talking Points: Describing and Localizing Pixels](https://arxiv.org/abs/2510.14583)
*Matan Rusanovsky,Shimon Malnick,Shai Avidan*

Main category: cs.CV

TL;DR: 该研究提出了一种新的像素级定位框架，用于通过自然语言理解图像中的关键点，并引入了一个新的数据集LlamaPointInPart。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在像素级关键点理解方面存在局限性，无法实现像素级别的精确定位。

Method: 提出了一种包含点描述符（生成关键点的上下文描述）和点定位器（从描述中回归像素坐标）两部分组成的框架，并合成了LlamaPointInPart数据集。在AP-10K数据集上使用GRPO优化点描述符，冻结的点定位器作为奖励模型。

Result: 在LlamaPointInPart数据集上，该框架相比基线模型表现出优越的性能，并建立了一个新的评估协议。

Conclusion: 该框架能够实现像素级关键点的自然语言理解和精确定位，为未来的应用提供了基础。

Abstract: Vision-language models have achieved remarkable success in cross-modal
understanding. Yet, these models remain limited to object-level or region-level
grounding, lacking the capability for pixel-precise keypoint comprehension
through natural language. We introduce a novel framework for pixel level
grounding. The framework consists of two complementary components: a Point
Descriptor that generates rich, contextual descriptions of individual
keypoints, and a Point Localizer that regresses precise pixel coordinates from
these descriptions. Unlike prior work that relies on templated prompts or
keypoint names, our approach produces free-form, coarse-to-fine descriptions
that situate keypoints within their visual context. Since there is no available
dataset to train such a system, we introduce LlamaPointInPart, a carefully
curated dataset of 20K+ image-keypoint-description triplets synthesized from
multiple vision-language models, capturing multi-scale information from
scene-level context to visual features around the keypoint. For cross-category
generalization, we optimize the Point Descriptor on AP-10K via GRPO, using the
frozen Point Localizer as a reward model to produce descriptions that maximize
localization accuracy. To evaluate our results we establish a new evaluation
protocol. Instead of comparing the text description produced by our method to
the ground truth, we use the localizer to determine how close is the predicted
point generated to the ground truth point. Experiments demonstrate superior
performance compared to baseline models on LlamaPointInPart.The bidirectional
nature of our framework should enable future applications in both
keypoint-guided image understanding and language-guided precise localization.
Our code and dataset are publicly available at
https://github.com/matanr/Talking_Points.

</details>


### [53] [STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding](https://arxiv.org/abs/2510.14588)
*Zhifei Chen,Tianshuo Xu,Leyi Wu,Luozhou Wang,Dongyu Yan,Zihan You,Wenting Luo,Guo Zhang,Yingcong Chen*

Main category: cs.CV

TL;DR: 现有视频生成技术在保持物体运动和交互的连贯性方面存在挑战。本文提出的STANCE框架通过引入实例线索和密集RoPE解决了这些问题，显著提高了视频生成的时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成技术在保持物体运动和交互的连贯性方面存在不足，主要体现在运动提示编码后有效信息过少以及外观和运动优化在单一头中进行导致时间一致性下降。

Method: 本文提出STANCE框架，包括两个主要组件：1. 实例线索：一种像素对齐的控制信号，通过平均实例流并结合实例蒙版的单目深度，将稀疏的用户编辑提示转换为密集的2.5D运动场。2. 密集RoPE：通过空间可寻址的旋转嵌入来增强第一帧上的运动标记（token）在token空间中的显着性。结合联合RGB和辅助图（分割或深度）预测。

Result: STANCE框架通过实例线索和密集RoPE，提高了视频生成的时间连贯性，并稳定了优化过程，无需逐帧轨迹脚本。

Conclusion: STANCE框架通过实例线索和密集RoPE有效解决了视频生成中的物体运动和交互连贯性问题，显著提高了时间一致性。

Abstract: Video generation has recently made striking visual progress, but maintaining
coherent object motion and interactions remains difficult. We trace two
practical bottlenecks: (i) human-provided motion hints (e.g., small 2D maps)
often collapse to too few effective tokens after encoding, weakening guidance;
and (ii) optimizing for appearance and motion in a single head can favor
texture over temporal consistency. We present STANCE, an image-to-video
framework that addresses both issues with two simple components. First, we
introduce Instance Cues -- a pixel-aligned control signal that turns sparse,
user-editable hints into a dense 2.5D (camera-relative) motion field by
averaging per-instance flow and augmenting with monocular depth over the
instance mask. This reduces depth ambiguity compared to 2D arrow inputs while
remaining easy to use. Second, we preserve the salience of these cues in token
space with Dense RoPE, which tags a small set of motion tokens (anchored on the
first frame) with spatial-addressable rotary embeddings. Paired with joint RGB
\(+\) auxiliary-map prediction (segmentation or depth), our model anchors
structure while RGB handles appearance, stabilizing optimization and improving
temporal coherence without requiring per-frame trajectory scripts.

</details>


### [54] [Hierarchical Re-Classification: Combining Animal Classification Models with Vision Transformers](https://arxiv.org/abs/2510.14594)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 通过结合物种网络（SpeciesNet）预测、CLIP嵌入和度量学习，提出了一种分层再分类系统，以改进动物识别平台（Animal Detect）的物种级别识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有的动物分类模型（如SpeciesNet）虽然能识别数千种动物，但采用保守的汇总策略，导致许多动物仅被标记为高分类级别，而非具体物种。

Method: 该系统包含一个五阶段流程：高置信度接受、鸟类覆盖、质心构建、三元损失度量学习和自适应余弦距离评分。该系统结合了SpeciesNet EfficientNetV2-M的预测、CLIP嵌入和度量学习，以优化高层级分类标签，实现物种级别识别。

Result: 在LILA BC沙漠狮子保护数据集的一个子集（4018张图像，15031个检测）上进行了评估。成功从“空白”和“动物”标签中恢复了761个鸟类检测，并将456个被标记为动物、哺乳动物或空白的检测重新分类，准确率达到96.5%，实现了64.9%的物种级别识别。

Conclusion: 提出的分层再分类系统能够有效地将高层级分类标签细化到物种级别，显著提高了动物识别的准确性和精细度。

Abstract: State-of-the-art animal classification models like SpeciesNet provide
predictions across thousands of species but use conservative rollup strategies,
resulting in many animals labeled at high taxonomic levels rather than species.
We present a hierarchical re-classification system for the Animal Detect
platform that combines SpeciesNet EfficientNetV2-M predictions with CLIP
embeddings and metric learning to refine high-level taxonomic labels toward
species-level identification. Our five-stage pipeline (high-confidence
acceptance, bird override, centroid building, triplet-loss metric learning, and
adaptive cosine-distance scoring) is evaluated on a segment of the LILA BC
Desert Lion Conservation dataset (4,018 images, 15,031 detections). After
recovering 761 bird detections from "blank" and "animal" labels, we re-classify
456 detections labeled animal, mammal, or blank with 96.5% accuracy, achieving
species-level identification for 64.9 percent

</details>


### [55] [Zero-Shot Wildlife Sorting Using Vision Transformers: Evaluating Clustering and Continuous Similarity Ordering](https://arxiv.org/abs/2510.14596)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 该研究提出了一种利用自监督视觉转换器和无监督聚类方法来组织未标记的相机陷阱图像的方法，以解决现有分类器中物种缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的相机陷阱图像分类器通常缺乏对某些物种的识别能力，导致大量图像难以组织和利用。

Method: 研究人员比较了三种不同的视觉转换器架构（CLIP、DINOv2、MegaDescriptor）与两种降维技术（PCA、UMAP）和两种聚类方法（DBSCAN、GMM）的组合，并探索了使用 t-SNE 投影进行连续一维相似性排序。

Result: 在包含 5 种动物的测试集中，DINOv2 + UMAP + GMM 组合达到了 88.6% 的准确率（宏 F1 分数为 0.874）；一维排序方法在哺乳动物和鸟类图像上达到了 88.2% 的一致性，在鱼类图像上达到了 95.2% 的一致性。

Conclusion: 研究结果表明，自监督视觉转换器结合无监督聚类或一维排序是组织和分析未标记相机陷阱图像的有效方法，已成功应用于实际的生物多样性监测工作中，提高了数据分析的效率。

Abstract: Camera traps generate millions of wildlife images, yet many datasets contain
species that are absent from existing classifiers. This work evaluates
zero-shot approaches for organizing unlabeled wildlife imagery using
self-supervised vision transformers, developed and tested within the Animal
Detect platform for camera trap analysis. We compare unsupervised clustering
methods (DBSCAN, GMM) across three architectures (CLIP, DINOv2, MegaDescriptor)
combined with dimensionality reduction techniques (PCA, UMAP), and we
demonstrate continuous 1D similarity ordering via t-SNE projection. On a
5-species test set with ground truth labels used only for evaluation, DINOv2
with UMAP and GMM achieves 88.6 percent accuracy (macro-F1 = 0.874), while 1D
sorting reaches 88.2 percent coherence for mammals and birds and 95.2 percent
for fish across 1,500 images. Based on these findings, we deployed continuous
similarity ordering in production, enabling rapid exploratory analysis and
accelerating manual annotation workflows for biodiversity monitoring.

</details>


### [56] [Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering](https://arxiv.org/abs/2510.14605)
*Yuyang Hong,Jiaqi Gu,Qi Yang,Lubin Fan,Yue Wu,Ying Wang,Kun Ding,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: Wiki-PRF是一种新的三阶段方法，用于改进基于知识库的视觉问答（KB-VQA），通过增强多模态查询质量和检索结果相关性，在E-VQA和InfoSeek数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在KB-VQA任务中虽然取得了进展，但在处理多模态查询的质量和检索结果的相关性方面仍存在挑战。

Method: 提出了一种名为Wiki-PRF的新型三阶段方法，包括处理、检索和过滤阶段。处理阶段动态调用视觉工具提取精确的多模态信息用于检索；检索阶段整合视觉和文本特征以实现多模态知识检索；过滤阶段对检索结果进行相关性过滤和集中。引入了一个通过强化学习进行训练的视觉语言模型，以答案准确性和格式一致性作为奖励信号，以增强模型的推理、查询和过滤能力。

Result: 在E-VQA和InfoSeek基准数据集上，答案质量有了显著提高（分别为36.0和42.8），达到了最先进的性能。

Conclusion: 所提出的Wiki-PRF方法通过其创新的三阶段设计和强化学习训练的视觉语言模型，有效解决了KB-VQA中的多模态查询质量和检索结果相关性问题，并在基准测试中取得了最先进的结果。

Abstract: Knowledge-based visual question answering (KB-VQA) requires visual language
models (VLMs) to integrate visual understanding with external knowledge
retrieval. Although retrieval-augmented generation (RAG) achieves significant
advances in this task by combining knowledge-base querying, it still struggles
with the quality of multimodal queries and the relevance of retrieved results.
To overcome these challenges, we propose a novel three-stage method, termed
Wiki-PRF, including Processing, Retrieval and Filtering stages. The processing
stage dynamically invokes visual tools to extract precise multimodal
information for retrieval. The retrieval stage integrates visual and text
features to achieve multimodal knowledge retrieval. The filtering stage
performs relevance filtering and concentration on retrieval results. To this
end, we introduce a visual language model trained with answer accuracy and
format consistency as reward signals via a reinforcement learning manner. This
enhances the model's reasoning, tool invocation for accurate queries, and
filtering of irrelevant content. Experiments on benchmark datasets (E-VQA and
InfoSeek) show significant improvements~(36.0 and 42.8) in answer quality,
achieving state-of-the-art performance. Code is available at
https://github.com/cqu-student/Wiki-PRF

</details>


### [57] [Shot2Tactic-Caption: Multi-Scale Captioning of Badminton Videos for Tactical Understanding](https://arxiv.org/abs/2510.14617)
*Ning Ding,Keisuke Fujii,Toru Tamaki*

Main category: cs.CV

TL;DR: 提出了一种名为Shot2Tactic-Caption的新框架，用于羽毛球视频的语义和时间多尺度视频字幕生成，可以生成描述单个动作的“镜头级”字幕，以及捕捉这些动作如何随着时间推移在战术执行中展开的“战术级”字幕。同时介绍了Shot2Tactic-Caption数据集。Shot2Tactic-Caption采用双分支设计，并通过引入战术单元检测器和镜头级提示引导机制来增强战术字幕生成能力。实验证明了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 羽毛球战术理解需要解释单个动作以及战术如何随时间动态执行。

Method: Shot2Tactic-Caption框架，包括一个视觉编码器、一个时空Transformer编码器和一个基于Transformer的解码器，用于生成镜头和战术字幕。引入了战术单元检测器来识别战术单元、类型和状态。采用镜头级提示引导机制进行战术字幕生成。

Result: 实验结果表明，所提出的框架在生成镜头和战术字幕方面是有效的。消融研究表明，基于ResNet50的时空编码器优于其他变体，并且镜头级提示构建能够实现更连贯、更准确的战术字幕生成。

Conclusion: Shot2Tactic-Caption框架在羽毛球视频理解和字幕生成方面取得了显著效果，能够同时生成描述单个动作和动态战术执行的字幕。

Abstract: Tactical understanding in badminton involves interpreting not only individual
actions but also how tactics are dynamically executed over time. In this paper,
we propose \textbf{Shot2Tactic-Caption}, a novel framework for semantic and
temporal multi-scale video captioning in badminton, capable of generating
shot-level captions that describe individual actions and tactic-level captions
that capture how these actions unfold over time within a tactical execution. We
also introduce the Shot2Tactic-Caption Dataset, the first badminton captioning
dataset containing 5,494 shot captions and 544 tactic captions.
Shot2Tactic-Caption adopts a dual-branch design, with both branches including a
visual encoder, a spatio-temporal Transformer encoder, and a Transformer-based
decoder to generate shot and tactic captions. To support tactic captioning, we
additionally introduce a Tactic Unit Detector that identifies valid tactic
units, tactic types, and tactic states (e.g., Interrupt, Resume). For tactic
captioning, we further incorporate a shot-wise prompt-guided mechanism, where
the predicted tactic type and state are embedded as prompts and injected into
the decoder via cross-attention. The shot-wise prompt-guided mechanism enables
our system not only to describe successfully executed tactics but also to
capture tactical executions that are temporarily interrupted and later resumed.
Experimental results demonstrate the effectiveness of our framework in
generating both shot and tactic captions. Ablation studies show that the
ResNet50-based spatio-temporal encoder outperforms other variants, and that
shot-wise prompt structuring leads to more coherent and accurate tactic
captioning.

</details>


### [58] [Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference](https://arxiv.org/abs/2510.14624)
*Natan Bagrov,Eugene Khvedchenia,Borys Tymchenko,Shay Aharon,Lior Kadoch,Tomer Keren,Ofri Masad,Yonatan Geifman,Ran Zilberstein,Tuomas Rintamaki,Matthieu Le,Andrew Tao*

Main category: cs.CV

TL;DR: EVS是一种通过移除视频中静态区域的冗余信息来提高视频语言模型效率的方法，可显著减少计算量并加快推理速度，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理长视频时面临二次计算成本、超出token限制、上下文受限和延迟问题。

Method: 提出了一种名为高效视频采样（EVS）的即插即用方法，通过识别并移除连续帧之间保持不变的空间区域（静态斑块）来减少token冗余。EVS保留了位置信息，无需修改模型架构或重新训练。

Result: EVS在保持语义保真度的同时，显著减少了token数量，从而实现了更快的推理速度和更长的输入序列。在推理时应用EVS，可以将大语言模型（LLM）的首次响应时间（TTFT）缩短高达4倍，同时准确性损失很小。结合使用随机剪枝率进行预训练，EVS可以生成对不同压缩级别具有鲁棒性且在激进剪枝下仍能保持完整性能的模型。

Conclusion: EVS能够持续改善效率-准确性权衡，能够在不牺牲质量的情况下实现可扩展的视频语言理解。

Abstract: Vision-language models (VLMs) have recently expanded from static image
understanding to video reasoning, but their scalability is fundamentally
limited by the quadratic cost of processing dense frame sequences. Long videos
often exceed the token budget of modern language models, leading to severe
context limitations and latency issues. We introduce Efficient Video Sampling
(EVS), a simple, plug-and-play method for reducing token redundancy in videos
by identifying and pruning temporally static patches -- spatial regions that
remain unchanged across consecutive frames. EVS preserves positional identity,
requires no architectural changes or retraining. We show that EVS substantially
reduces token count while maintaining semantic fidelity, enabling faster
inference and longer input sequences. Applied at inference time, EVS reduces
large language model (LLM) time-to-first-token (TTFT) by up to 4x with minimal
accuracy loss. When combined with an uptraining phase using stochastic pruning
rates, EVS yields models that are robust to varying compression levels and
retain full performance under aggressive pruning. Extensive experiments
demonstrate that EVS consistently improves efficiency-accuracy trade-offs,
unlocking scalable video-language understanding without sacrificing quality.

</details>


### [59] [Adapting Self-Supervised Representations as a Latent Space for Efficient Generation](https://arxiv.org/abs/2510.14630)
*Ming Gui,Johannes Schusterbauer,Timy Phan,Felix Krause,Josh Susskind,Miguel Angel Bautista,Björn Ommer*

Main category: cs.CV

TL;DR: RepTok是一个新的生成模型框架，用一个连续的潜在token代表图像，并能高效地进行图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在处理高分辨率图像时存在训练成本高和空间冗余问题。本研究旨在探索一种更高效的生成模型框架。

Method: RepTok框架利用预训练的自监督视觉Transformer（SSL）编码器，仅微调语义token嵌入，并将其与使用流匹配（flow matching）目标联合训练的生成解码器配对。通过增加余弦相似度损失来正则化适应后的token，以保持SSL空间的几何结构。

Result: RepTok在ImageNet类条件生成任务上取得了有竞争力的结果，并能扩展到文本到图像合成，在MS-COCO数据集上实现了具有竞争力的零样本性能，同时显著降低了训练成本。

Conclusion: 微调后的SSL表示可以作为紧凑且有效的潜在空间，用于高效的生成建模。

Abstract: We introduce Representation Tokenizer (RepTok), a generative modeling
framework that represents an image using a single continuous latent token
obtained from self-supervised vision transformers. Building on a pre-trained
SSL encoder, we fine-tune only the semantic token embedding and pair it with a
generative decoder trained jointly using a standard flow matching objective.
This adaptation enriches the token with low-level, reconstruction-relevant
details, enabling faithful image reconstruction. To preserve the favorable
geometry of the original SSL space, we add a cosine-similarity loss that
regularizes the adapted token, ensuring the latent space remains smooth and
suitable for generation. Our single-token formulation resolves spatial
redundancies of 2D latent spaces and significantly reduces training costs.
Despite its simplicity and efficiency, RepTok achieves competitive results on
class-conditional ImageNet generation and naturally extends to text-to-image
synthesis, reaching competitive zero-shot performance on MS-COCO under
extremely limited training budgets. Our findings highlight the potential of
fine-tuned SSL representations as compact and effective latent spaces for
efficient generative modeling.

</details>


### [60] [SteeringTTA: Guiding Diffusion Trajectories for Robust Test-Time-Adaptation](https://arxiv.org/abs/2510.14634)
*Jihyun Yu,Yoojin Oh,Wonho Bae,Mingyu Kim,Junhyug Noh*

Main category: cs.CV

TL;DR: SteeringTTA通过结合Feynman-Kac引导和基于伪标签的奖励，改进了扩散模型在测试时自适应（TTA）中的分类鲁棒性，其在ImageNet-C上的表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的输入TTA方法在处理分布偏移（如图像腐化）时，虽然提高了分类鲁棒性，但依赖梯度引导，限制了探索和跨不同失真类型的泛化能力。

Method: 提出了一种名为SteeringTTA的仅推理框架，该框架将Feynman-Kac引导的思想应用于扩散模型，以实现基于伪标签奖励的输入自适应。该方法通过维护多个粒子轨迹，并结合累积的Top-K概率和熵调度来引导这些轨迹，以平衡探索和置信度。

Result: 在ImageNet-C数据集上，SteeringTTA在没有模型更新或源数据的情况下，持续超越了基线方法。

Conclusion: SteeringTTA通过一种新颖的奖励驱动的引导机制，有效地解决了现有基于扩散模型的TTA方法在探索和泛化方面的局限性，并在图像腐化任务上取得了显著的性能提升。

Abstract: Test-time adaptation (TTA) aims to correct performance degradation of deep
models under distribution shifts by updating models or inputs using unlabeled
test data. Input-only diffusion-based TTA methods improve robustness for
classification to corruptions but rely on gradient guidance, limiting
exploration and generalization across distortion types. We propose SteeringTTA,
an inference-only framework that adapts Feynman-Kac steering to guide
diffusion-based input adaptation for classification with rewards driven by
pseudo-label. SteeringTTA maintains multiple particle trajectories, steered by
a combination of cumulative top-K probabilities and an entropy schedule, to
balance exploration and confidence. On ImageNet-C, SteeringTTA consistently
outperforms the baseline without any model updates or source data.

</details>


### [61] [In-Context Learning with Unpaired Clips for Instruction-based Video Editing](https://arxiv.org/abs/2510.14648)
*Xinyao Liao,Xianfang Zeng,Ziye Song,Zhoujie Fu,Gang Yu,Guosheng Lin*

Main category: cs.CV

TL;DR: 本文提出了一种低成本的视频编辑预训练策略，利用非配对视频片段进行上下文学习，有效解决了视频编辑数据集构建成本高昂的问题。该策略预训练基础视频生成模型，使其具备理解和执行编辑指令（如添加、替换、删除）的能力，随后只需少量高质量配对数据即可进行微调，以扩展编辑任务并提升质量。实验证明，该方法在指令遵循和视觉保真度方面均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑技术发展迅速，但由于难以构建大规模配对视频编辑数据集，其在视频领域的应用受到限制。构建高质量的视频编辑数据集成本高昂且复杂。

Method: 提出一种低成本的预训练策略，利用非配对视频片段进行上下文学习，为基础视频生成模型赋予通用的编辑能力（如添加、替换、删除操作）。之后，使用少量高质量配对编辑数据进行高效微调。具体而言，首先在约1M个真实视频片段上进行预训练，学习基本编辑概念，然后在少于15万个精选的编辑对数据上进行微调，以扩展编辑任务和提高编辑质量。

Result: 实验结果显示，该方法在指令对齐和视觉保真度方面均优于现有的基于指令的视频编辑方法，在编辑指令遵循方面提高了12%，在编辑质量方面提高了15%。

Conclusion: 所提出的低成本预训练策略能够有效解决视频编辑数据集稀缺的问题，并显著提升视频编辑的效果，在指令遵循和视觉质量方面均取得了领先的性能。

Abstract: Despite the rapid progress of instruction-based image editing, its extension
to video remains underexplored, primarily due to the prohibitive cost and
complexity of constructing large-scale paired video editing datasets. To
address this challenge, we introduce a low-cost pretraining strategy for
instruction-based video editing that leverages in-context learning from
unpaired video clips. We show that pretraining a foundation video generation
model with this strategy endows it with general editing capabilities, such as
adding, replacing, or deleting operations, according to input editing
instructions. The pretrained model can then be efficiently refined with a small
amount of high-quality paired editing data. Built upon HunyuanVideoT2V, our
framework first pretrains on approximately 1M real video clips to learn basic
editing concepts, and subsequently fine-tunes on fewer than 150k curated
editing pairs to extend more editing tasks and improve the editing quality.
Comparative experiments show that our method surpasses existing
instruction-based video editing approaches in both instruction alignment and
visual fidelity, achieving a 12\% improvement in editing instruction following
and a 15\% improvement in editing quality.

</details>


### [62] [Decorrelation Speeds Up Vision Transformers](https://arxiv.org/abs/2510.14657)
*Kieran Carrigg,Rob van Gastel,Melda Yeghaian,Sander Dalm,Faysal Boughorbel,Marcel van Gerven*

Main category: cs.CV

TL;DR: MAE预训练在标签稀疏的情况下表现优异，但计算成本高昂。通过将Decorrelated Backpropagation（DBP）集成到MAE预训练中，可以加速收敛并减少训练时间，同时不损失稳定性。


<details>
  <summary>Details</summary>
Motivation: MAE预训练的计算成本高昂，不适用于时间资源受限的工业环境。

Method: 将Decorrelated Backpropagation（DBP）集成到MAE预训练中，DBP是一种迭代地减少每层输入相关性的优化方法，以加速收敛。

Result: DBP-MAE在ImageNet-1K预训练和ADE20K微调任务中，将达到基线性能的挂钟时间缩短了21.1%，碳排放量降低了21.4%，并将分割mIoU提高了1.1个百分点。在专有工业数据上也观察到类似的收益。

Conclusion: DBP可以减少大规模ViT预训练的训练时间和能源消耗，同时提高下游性能。

Abstract: Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields
strong performance in low-label regimes but comes with substantial
computational costs, making it impractical in time- and resource-constrained
industrial settings. We address this by integrating Decorrelated
Backpropagation (DBP) into MAE pre-training, an optimization method that
iteratively reduces input correlations at each layer to accelerate convergence.
Applied selectively to the encoder, DBP achieves faster pre-training without
loss of stability. On ImageNet-1K pre-training with ADE20K fine-tuning, DBP-MAE
reduces wall-clock time to baseline performance by 21.1%, lowers carbon
emissions by 21.4% and improves segmentation mIoU by 1.1 points. We observe
similar gains when pre-training and fine-tuning on proprietary industrial data,
confirming the method's applicability in real-world scenarios. These results
demonstrate that DBP can reduce training time and energy use while improving
downstream performance for large-scale ViT pre-training.

</details>


### [63] [EuroMineNet: A Multitemporal Sentinel-2 Benchmark for Spatiotemporal Mining Footprint Analysis in the European Union (2015-2024)](https://arxiv.org/abs/2510.14661)
*Weikang Yu,Vincent Nwazelibe,Xianping Ma,Xiaokang Zhang,Richard Gloaguen,Xiao Xiang Zhu,Pedram Ghamisi*

Main category: cs.CV

TL;DR: EuroMineNet是一个基于Sentinel-2卫星图像的欧洲多时序采矿足迹数据集，用于监测采矿活动引起的地表变化，以支持可持续土地管理。


<details>
  <summary>Details</summary>
Motivation: 现有的采矿活动监测数据集在时间深度或地理范围上存在局限性，无法满足可持续资源管理和环境治理的长期监测需求。

Method: 本研究提出了EuroMineNet数据集，包含2015年至2024年间欧盟133个矿区的年度Sentinel-2多光谱图像观测和专家验证标注，并提出了一个新颖的CA-TIoU指标来评估多时序采矿足迹绘制任务，同时支持跨时序变化检测。

Result: 通过对20种先进深度学习模型的基准测试，发现GeoAI方法能有效识别长期环境变化，但在短期动态变化检测方面仍存在挑战。

Conclusion: EuroMineNet数据集通过提供时间上一致且可解释的采矿监测，有助于可持续土地利用管理、环境韧性以及推动GeoAI在社会和环境领域的应用。

Abstract: Mining activities are essential for industrial and economic development, but
remain a leading source of environmental degradation, contributing to
deforestation, soil erosion, and water contamination. Sustainable resource
management and environmental governance require consistent, long-term
monitoring of mining-induced land surface changes, yet existing datasets are
often limited in temporal depth or geographic scope. To address this gap, we
present EuroMineNet, the first comprehensive multitemporal benchmark for mining
footprint mapping and monitoring based on Sentinel-2 multispectral imagery.
Spanning 133 mining sites across the European Union, EuroMineNet provides
annual observations and expert-verified annotations from 2015 to 2024, enabling
GeoAI-based models to analyze environmental dynamics at a continental scale. It
supports two sustainability-driven tasks: (1) multitemporal mining footprint
mapping for consistent annual land-use delineation, evaluated with a novel
Change-Aware Temporal IoU (CA-TIoU) metric, and (2) cross-temporal change
detection to capture both gradual and abrupt surface transformations.
Benchmarking 20 state-of-the-art deep learning models reveals that while GeoAI
methods effectively identify long-term environmental changes, challenges remain
in detecting short-term dynamics critical for timely mitigation. By advancing
temporally consistent and explainable mining monitoring, EuroMineNet
contributes to sustainable land-use management, environmental resilience, and
the broader goal of applying GeoAI for social and environmental good. We
release the codes and datasets by aligning with FAIR and the open science
paradigm at https://github.com/EricYu97/EuroMineNet.

</details>


### [64] [WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging](https://arxiv.org/abs/2510.14668)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Sami Azam,Asif Karim,Jemima Beissbarth,Amanda Leach*

Main category: cs.CV

TL;DR: WeCKD是一种新颖的弱监督知识蒸馏方法，通过构建一个渐进式的蒸馏链来克服传统知识蒸馏的局限性，在有限数据下也能取得优异的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法在数据不足的情况下存在知识退化、监督效率低下以及需要强大教师模型等问题，限制了其在现实世界中的应用。WeCKD旨在解决这些问题。

Method: WeCKD构建了一个结构化的、相互连接的模型序列，形成一个渐进式的蒸馏链。链中的每个模型不仅从前一个模型学习，还对其知识进行提炼后再传递下去。每个模型仅使用一小部分数据集进行训练。

Result: WeCKD在四个耳镜成像数据集上的评估结果表明，其性能可以与现有监督方法相媲美，甚至在很多情况下超越了它们。在另外两个数据集上的实验也证明了其在显微镜和磁共振成像等不同医学成像模态上的泛化能力。与在相同有限数据上训练的单一模型相比，WeCKD的累积准确率提高了+23%。

Conclusion: WeCKD通过渐进式知识传递的链式结构，有效解决了传统知识蒸馏在数据有限情况下的不足，并在多种医学成像任务中展现了卓越的性能和泛化能力，具有很高的实际应用潜力。

Abstract: Knowledge distillation (KD) has traditionally relied on a static
teacher-student framework, where a large, well-trained teacher transfers
knowledge to a single student model. However, these approaches often suffer
from knowledge degradation, inefficient supervision, and reliance on either a
very strong teacher model or large labeled datasets, which limits their
effectiveness in real-world, limited-data scenarios. To address these, we
present the first-ever Weakly-supervised Chain-based KD network (WeCKD) that
redefines knowledge transfer through a structured sequence of interconnected
models. Unlike conventional KD, it forms a progressive distillation chain,
where each model not only learns from its predecessor but also refines the
knowledge before passing it forward. This structured knowledge transfer further
enhances feature learning, reduces data dependency, and mitigates the
limitations of one-step KD. Each model in the distillation chain is trained on
only a fraction of the dataset and demonstrates that effective learning can be
achieved with minimal supervision. Extensive evaluations across four otoscopic
imaging datasets demonstrate that it not only matches but in many cases
surpasses the performance of existing supervised methods. Experimental results
on two other datasets further underscore its generalization across diverse
medical imaging modalities, including microscopic and magnetic resonance
imaging. Furthermore, our evaluations resulted in cumulative accuracy gains of
up to +23% over a single backbone trained on the same limited data, which
highlights its potential for real-world adoption.

</details>


### [65] [VTimeCoT: Thinking by Drawing for Video Temporal Grounding and Reasoning](https://arxiv.org/abs/2510.14672)
*Jinglei Zhang,Yuanfan Guo,Rolandos Alexandros Potamias,Jiankang Deng,Hang Xu,Chao Ma*

Main category: cs.CV

TL;DR: VTimeCoT是一个新的框架，可以提高视频问答中的时间定位和推理能力，通过模拟人类使用视频播放器进度条的方式，并引入了视觉工具和视频-文本跨模态推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于多模态大语言模型（MLLM）的视频问答在视频时间定位和推理方面存在不足，这阻碍了有效的现实世界视频理解系统的发展。

Method: 提出了一种名为VTimeCoT的训练无关框架，该框架包含两个新的进度条视觉工具：即插即用的进度条集成工具和高效的高亮工具。此外，还引入了一个视频-时间跨模态推理过程，以解决传统基于文本的思维链（CoT）方法的局限性。

Result: 在Qwen2VL-7B和GPT4o基线上，视频时间定位和基于推理的问答任务上取得了显著的性能提升，并展示了一个组合式和可解释的推理过程。

Conclusion: VTimeCoT框架通过引入进度条工具和视频-时间跨模态推理，有效解决了现有视频问答模型在时间定位和推理方面的挑战，并在多个基线上取得了显著成果。

Abstract: In recent years, video question answering based on multimodal large language
models (MLLM) has garnered considerable attention, due to the benefits from the
substantial advancements in LLMs. However, these models have a notable
deficiency in the domains of video temporal grounding and reasoning, posing
challenges to the development of effective real-world video understanding
systems. Inspired by how humans use video players to interact with the progress
bar for video comprehension, we introduce VTimeCoT, a simple yet effective
training-free framework, designed for high-performance video grounding and
reasoning. The proposed framework incorporates two novel visual tools of the
progress bar: a plug-and-play progress bar integration tool and a
high-efficiency highlighting tool. In addition, to address the limitations of
conventional text-based chain-of-thought (CoT) approaches, we introduce a
visuotemporal CoT process that integrates cross-modality reasoning across both
video and text. Our approach demonstrates significant performance improvements
on both Qwen2VL-7B and GPT4o baselines in tasks of video temporal grounding and
reasoning-based question answering. Finally, we showcase that the proposed
framework achieves a compositional and interpretable reasoning process. Project
page: https://vtimecot.github.io

</details>


### [66] [Leveraging Learned Image Prior for 3D Gaussian Compression](https://arxiv.org/abs/2510.14705)
*Seungjoo Shin,Jaesik Park,Sunghyun Cho*

Main category: cs.CV

TL;DR: 通过引入学习到的图像先验来压缩3D高斯泼溅（3DGS），以提高压缩效率和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS压缩技术在减小存储开销方面取得了成功，但缺乏学习先验限制了率失真性能的进一步提升。

Method: 提出一种新的3DGS压缩框架，利用学习到的图像先验来恢复压缩造成的质量下降。该框架在初始压缩的高斯基础上，通过一个恢复网络来建模图像空间的压缩伪影，并引入粗略渲染残差作为辅助信息以提高率失真性能。框架与现有方法兼容。

Result: 在率失真性能和渲染质量方面优于最先进的3DGS压缩方法，同时显著减少了存储需求。

Conclusion: 所提出的框架通过利用学习到的图像先验，有效解决了3DGS压缩中的率失真优化问题，实现了更高的压缩效率和渲染质量。

Abstract: Compression techniques for 3D Gaussian Splatting (3DGS) have recently
achieved considerable success in minimizing storage overhead for 3D Gaussians
while preserving high rendering quality. Despite the impressive storage
reduction, the lack of learned priors restricts further advances in the
rate-distortion trade-off for 3DGS compression tasks. To address this, we
introduce a novel 3DGS compression framework that leverages the powerful
representational capacity of learned image priors to recover
compression-induced quality degradation. Built upon initially compressed
Gaussians, our restoration network effectively models the compression artifacts
in the image space between degraded and original Gaussians. To enhance the
rate-distortion performance, we provide coarse rendering residuals into the
restoration network as side information. By leveraging the supervision of
restored images, the compressed Gaussians are refined, resulting in a highly
compact representation with enhanced rendering performance. Our framework is
designed to be compatible with existing Gaussian compression methods, making it
broadly applicable across different baselines. Extensive experiments validate
the effectiveness of our framework, demonstrating superior rate-distortion
performance and outperforming the rendering quality of state-of-the-art 3DGS
compression methods while requiring substantially less storage.

</details>


### [67] [Where are the Whales: A Human-in-the-loop Detection Method for Identifying Whales in High-resolution Satellite Imagery](https://arxiv.org/abs/2510.14709)
*Caleb Robinson,Kimberly T. Goetz,Christin B. Khan,Meredith Sackett,Kathleen Leonard,Rahul Dodhia,Juan M. Lavista Ferres*

Main category: cs.CV

TL;DR: 该研究提出了一种半自动化方法，利用统计异常检测来识别卫星图像中的鲸鱼，并结合一个用户友好的标注界面，以提高鲸鱼监测的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统的鲸鱼种群监测方法成本高昂且难以规模化，而使用高分辨率卫星图像进行自动化检测面临数据标注不足、图像质量和环境条件多变以及构建机器学习流水线成本高昂等挑战。

Method: 提出一种半自动化的方法，使用统计异常检测来识别卫星图像中的空间异常点（“有趣的点”），并结合一个网络标注界面，供专家快速标注这些点。

Result: 在三个具有已知鲸鱼标注的基准场景中，该系统的召回率达到 90.3% 至 96.4%，并将需要专家检查的面积减少了多达 99.8%，从超过 1000 平方公里减少到不到 2 平方公里。

Conclusion: 该方法不依赖于标注的训练数据，为未来从太空进行海洋哺乳动物监测的机器辅助提供了可扩展的第一步。该研究已开源其流水线。

Abstract: Effective monitoring of whale populations is critical for conservation, but
traditional survey methods are expensive and difficult to scale. While prior
work has shown that whales can be identified in very high-resolution (VHR)
satellite imagery, large-scale automated detection remains challenging due to a
lack of annotated imagery, variability in image quality and environmental
conditions, and the cost of building robust machine learning pipelines over
massive remote sensing archives. We present a semi-automated approach for
surfacing possible whale detections in VHR imagery using a statistical anomaly
detection method that flags spatial outliers, i.e. "interesting points". We
pair this detector with a web-based labeling interface designed to enable
experts to quickly annotate the interesting points. We evaluate our system on
three benchmark scenes with known whale annotations and achieve recalls of
90.3% to 96.4%, while reducing the area requiring expert inspection by up to
99.8% -- from over 1,000 sq km to less than 2 sq km in some cases. Our method
does not rely on labeled training data and offers a scalable first step toward
future machine-assisted marine mammal monitoring from space. We have open
sourced this pipeline at https://github.com/microsoft/whales.

</details>


### [68] [Camera Movement Classification in Historical Footage: A Comparative Study of Deep Video Models](https://arxiv.org/abs/2510.14713)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 现有的视频镜头运动分类模型在处理低质量历史影像时表现不佳，本研究首次系统评估了深度学习模型在二战纪录片上的表现，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有镜头运动分类方法在现代数据集上表现良好，但其在历史影像上的泛化能力尚未被研究。本研究旨在系统评估深度学习镜头运动分类模型在历史影像上的表现。

Method: 评估了五种标准的视频分类模型在HISTORIAN数据集上的表现，该数据集包含专家标注的二战影像。

Result: 在HISTORIAN数据集上，视频Swin Transformer模型取得了80.25%的准确率，显示出在有限的训练数据下仍有很强的收敛性。

Conclusion: 现有模型在处理低质量视频时存在挑战，但也有潜力。未来的工作可以结合多模态输入和时间架构来改进模型。

Abstract: Camera movement conveys spatial and narrative information essential for
understanding video content. While recent camera movement classification (CMC)
methods perform well on modern datasets, their generalization to historical
footage remains unexplored. This paper presents the first systematic evaluation
of deep video CMC models on archival film material. We summarize representative
methods and datasets, highlighting differences in model design and label
definitions. Five standard video classification models are assessed on the
HISTORIAN dataset, which includes expert-annotated World War II footage. The
best-performing model, Video Swin Transformer, achieves 80.25% accuracy,
showing strong convergence despite limited training data. Our findings
highlight the challenges and potential of adapting existing models to
low-quality video and motivate future work combining diverse input modalities
and temporal architectures.

</details>


### [69] [Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection](https://arxiv.org/abs/2510.14726)
*Dingzhou Xie,Rushi Lan,Cheng Pang,Enhao Ning,Jiahao Zeng,Wei Zheng*

Main category: cs.CV

TL;DR: CFSAM模块通过结合局部特征提取、Transformer全局建模和特征融合，有效利用了多尺度特征图中的跨层依赖关系，显著提高了物体检测的性能，并加速了训练收敛。


<details>
  <summary>Details</summary>
Motivation: 现有物体检测方法在利用注意力机制时，通常只关注单层或双层特征的融合，忽视了多尺度表示中丰富的层间依赖关系，这限制了它们捕捉包含大尺度变化物体的全面上下文信息的能力。

Method: 提出了一种新颖的跨层特征自注意力模块（CFSAM），它全面地模拟了多尺度特征图中的局部和全局依赖关系。CFSAM包含一个卷积局部特征提取器、一个能够有效捕捉跨层交互的基于Transformer的全局建模单元，以及一个用于恢复和增强原始表示的特征融合机制。

Result: 将CFSAM集成到SSD300框架后，在PASCAL VOC数据集上达到了78.6%的mAP（基线为75.5%），在COCO数据集上达到了52.1%的mAP（基线为43.1%），显著优于现有的注意力模块。此外，该模块在不增加大量计算开销的情况下，加速了训练收敛。

Conclusion: 显式的跨层注意力建模对于推进多尺度物体检测至关重要。

Abstract: Recent object detection methods have made remarkable progress by leveraging
attention mechanisms to improve feature discriminability. However, most
existing approaches are confined to refining single-layer or fusing dual-layer
features, overlooking the rich inter-layer dependencies across multi-scale
representations. This limits their ability to capture comprehensive contextual
information essential for detecting objects with large scale variations. In
this paper, we propose a novel Cross-Layer Feature Self-Attention Module
(CFSAM), which holistically models both local and global dependencies within
multi-scale feature maps. CFSAM consists of three key components: a
convolutional local feature extractor, a Transformer-based global modeling unit
that efficiently captures cross-layer interactions, and a feature fusion
mechanism to restore and enhance the original representations. When integrated
into the SSD300 framework, CFSAM significantly boosts detection performance,
achieving 78.6% mAP on PASCAL VOC (vs. 75.5% baseline) and 52.1% mAP on COCO
(vs. 43.1% baseline), outperforming existing attention modules. Moreover, the
module accelerates convergence during training without introducing substantial
computational overhead. Our work highlights the importance of explicit
cross-layer attention modeling in advancing multi-scale object detection.

</details>


### [70] [Free-Grained Hierarchical Recognition](https://arxiv.org/abs/2510.14737)
*Seulki Park,Zilin Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 真实世界的标签粒度不一，本文提出了ImageNet-F基准和一种新的学习方法，以应对这种不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有分层图像分类方法假设标签是完整的、细粒度的，这在现实中很少见。现实世界的监督粒度因图像质量、标注者专业知识和任务需求而异。

Method: 使用CLIP模拟混合粒度的标签，并提出了一种具有异构监督的自由粒度学习方法，该方法通过伪属性和半监督学习来增强语义和视觉指导。

Result: 所提出的方法和基线显著提高了在混合监督下的性能。

Conclusion: 该基准和方法共同推动了在现实约束下进行分层分类的研究。

Abstract: Hierarchical image classification predicts labels across a semantic taxonomy,
but existing methods typically assume complete, fine-grained annotations, an
assumption rarely met in practice. Real-world supervision varies in
granularity, influenced by image quality, annotator expertise, and task
demands; a distant bird may be labeled Bird, while a close-up reveals Bald
eagle. We introduce ImageNet-F, a large-scale benchmark curated from ImageNet
and structured into cognitively inspired basic, subordinate, and fine-grained
levels. Using CLIP as a proxy for semantic ambiguity, we simulate realistic,
mixed-granularity labels reflecting human annotation behavior. We propose
free-grain learning, with heterogeneous supervision across instances. We
develop methods that enhance semantic guidance via pseudo-attributes from
vision-language models and visual guidance via semi-supervised learning. These,
along with strong baselines, substantially improve performance under mixed
supervision. Together, our benchmark and methods advance hierarchical
classification under real-world constraints.

</details>


### [71] [DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models](https://arxiv.org/abs/2510.14741)
*Simone Carnemolla,Matteo Pennisi,Sarinda Samarasinghe,Giovanni Bellitto,Simone Palazzo,Daniela Giordano,Mubarak Shah,Concetto Spampinato*

Main category: cs.CV

TL;DR: DEXTER是一个数据无关的框架，利用扩散模型和大型语言模型为视觉分类器生成文本解释，无需训练数据或真实标签，可用于揭示模型的决策模式和偏见。


<details>
  <summary>Details</summary>
Motivation: 理解和解释机器学习模型的行为对于构建透明和可信赖的AI系统至关重要。

Method: DEXTER通过优化文本提示来合成强激活目标分类器的条件图像。然后，利用这些合成样本生成详细的自然语言报告，描述特定类别的决策模式和偏见。

Result: DEXTER在激活最大化、切片发现和去偏以及偏见解释等任务中展示了其灵活性，并成功揭示了视觉分类器的内部机制。定量和定性评估（包括用户研究）表明，DEXTER生成的输出准确且可解释。在ImageNet、Waterbirds、CelebA和FairFaces上的实验证实，DEXTER在全局模型解释和类别级偏见报告方面优于现有方法。

Conclusion: DEXTER在无需训练数据或真实标签的情况下，能够生成关于分类器决策过程的自然语言解释，并在解释能力和偏见报告方面优于现有方法。

Abstract: Understanding and explaining the behavior of machine learning models is
essential for building transparent and trustworthy AI systems. We introduce
DEXTER, a data-free framework that employs diffusion models and large language
models to generate global, textual explanations of visual classifiers. DEXTER
operates by optimizing text prompts to synthesize class-conditional images that
strongly activate a target classifier. These synthetic samples are then used to
elicit detailed natural language reports that describe class-specific decision
patterns and biases. Unlike prior work, DEXTER enables natural language
explanation about a classifier's decision process without access to training
data or ground-truth labels. We demonstrate DEXTER's flexibility across three
tasks-activation maximization, slice discovery and debiasing, and bias
explanation-each illustrating its ability to uncover the internal mechanisms of
visual classifiers. Quantitative and qualitative evaluations, including a user
study, show that DEXTER produces accurate, interpretable outputs. Experiments
on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms
existing approaches in global model explanation and class-level bias reporting.
Code is available at https://github.com/perceivelab/dexter.

</details>


### [72] [LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement](https://arxiv.org/abs/2510.14753)
*Xu Wu,Zhihui Lai,Xianxu Hou,Jie Zhou,Ya-nan Zhang,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为LightQANet的新型低光图像增强框架，通过量化和自适应特征学习来解决现有方法在低光条件下提取特征表示困难的问题，旨在实现跨越不同光照条件的一致且鲁棒的图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法在低光条件下提取特征表示困难，导致纹理恢复不佳、颜色不一致和产生伪影。为解决这些挑战，需要一种能够提取可靠特征表示并适应不同光照条件的新型方法。

Method: 本文提出了一种名为LightQANet的新型框架，它包含两个关键模块：1. 光照量化模块（LQM），用于显式提取和量化图像特征中的光照相关因素，通过结构化的光照因子学习来增强光照不变表示的提取，并减轻不同光照水平下的特征不一致性。 2. 光照感知提示模块（LAPM），将光照先验知识编码为可学习的提示，以动态指导特征学习过程，使模型能够灵活适应复杂多变的光照条件。

Result: 在多个低光数据集上的大量实验表明，本文提出的方法在各种具有挑战性的光照场景下实现了最先进的性能，在定性和定量结果上均优于现有方法。

Conclusion: LightQANet通过引入量化和自适应特征学习，成功解决了低光图像增强中的关键挑战，并在各种低光条件下实现了高质量的图像增强。

Abstract: Low-light image enhancement (LLIE) aims to improve illumination while
preserving high-quality color and texture. However, existing methods often fail
to extract reliable feature representations due to severely degraded
pixel-level information under low-light conditions, resulting in poor texture
restoration, color inconsistency, and artifact. To address these challenges, we
propose LightQANet, a novel framework that introduces quantized and adaptive
feature learning for low-light enhancement, aiming to achieve consistent and
robust image quality across diverse lighting conditions. From the static
modeling perspective, we design a Light Quantization Module (LQM) to explicitly
extract and quantify illumination-related factors from image features. By
enforcing structured light factor learning, LQM enhances the extraction of
light-invariant representations and mitigates feature inconsistency across
varying illumination levels. From the dynamic adaptation perspective, we
introduce a Light-Aware Prompt Module (LAPM), which encodes illumination priors
into learnable prompts to dynamically guide the feature learning process. LAPM
enables the model to flexibly adapt to complex and continuously changing
lighting conditions, further improving image enhancement. Extensive experiments
on multiple low-light datasets demonstrate that our method achieves
state-of-the-art performance, delivering superior qualitative and quantitative
results across various challenging lighting scenarios.

</details>


### [73] [MoCom: Motion-based Inter-MAV Visual Communication Using Event Vision and Spiking Neural Networks](https://arxiv.org/abs/2510.14770)
*Zhang Nengbo,Hann Woei Ho,Ye Zhou*

Main category: cs.CV

TL;DR: MAV集群使用基于运动的视觉信号进行通信，模仿蜜蜂的摇摆舞，并使用事件相机和SNN进行解码。


<details>
  <summary>Details</summary>
Motivation: 在频谱拥挤、干扰和高功耗等问题阻碍传统无线电通信的环境中，为MAV集群提供可靠的通信。

Method: 通过利用事件相机和SNN，设计了一个基于运动的视觉通信框架，该框架使用四种运动原语（垂直、水平、左-上-右、左-下-右）来表示控制符号（开始、结束、1、0）。

Result: 实验证明了该框架的有效性，实现了精确的解码和低功耗。

Conclusion: 该框架有潜力成为MAV在受限环境中进行通信的节能替代方案。

Abstract: Reliable communication in Micro Air Vehicle (MAV) swarms is challenging in
environments, where conventional radio-based methods suffer from spectrum
congestion, jamming, and high power consumption. Inspired by the waggle dance
of honeybees, which efficiently communicate the location of food sources
without sound or contact, we propose a novel visual communication framework for
MAV swarms using motion-based signaling. In this framework, MAVs convey
information, such as heading and distance, through deliberate flight patterns,
which are passively captured by event cameras and interpreted using a
predefined visual codebook of four motion primitives: vertical (up/down),
horizontal (left/right), left-to-up-to-right, and left-to-down-to-right,
representing control symbols (``start'', ``end'', ``1'', ``0''). To decode
these signals, we design an event frame-based segmentation model and a
lightweight Spiking Neural Network (SNN) for action recognition. An integrated
decoding algorithm then combines segmentation and classification to robustly
interpret MAV motion sequences. Experimental results validate the framework's
effectiveness, which demonstrates accurate decoding and low power consumption,
and highlights its potential as an energy-efficient alternative for MAV
communication in constrained environments.

</details>


### [74] [CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection](https://arxiv.org/abs/2510.14792)
*Hojun Choi,Youngsun Lim,Jaeyo Shin,Hyunjung Shim*

Main category: cs.CV

TL;DR: CoT-PL框架通过引入结构化视觉思维链（CoT）和对比背景学习（CBL）来改进开放词汇目标检测（OVD），显著提高了在拥挤或遮挡场景下的伪标签质量和检测性能，并在COCO和LVIS数据集上达到了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测（OVD）方法依赖于图像-文本匹配生成伪标签，但在处理语义复杂的拥挤或遮挡场景时鲁棒性不足，因为它们忽略了中间推理步骤。

Method: CoT-PL框架将结构化视觉思维链（CoT）引入伪标签生成过程，将物体理解分解为区域感知、零样本识别和背景分离三个步骤。在此基础上，提出对比背景学习（CBL），利用预计算的背景线索作为负样本，促进物体和背景特征的解耦。

Result: CoT-PL在拥挤和遮挡场景下的新类别伪标签质量分别比现有最佳方法提高了103.4%和168.4%。在COCO数据集上，新类别检测AP50提升了7.7，在LVIS数据集上，新类别掩码AP提升了2.9。

Conclusion: CoT-PL通过结合CoT推理和CBL，提供了一个改进的伪标签框架，能够有效处理拥挤和遮挡的场景，并在开放词汇目标检测任务上取得了最先进的性能。

Abstract: Open-vocabulary object detection (OVD) seeks to recognize and localize object
categories beyond those seen during training. Recent approaches typically
leverage vision-language models (VLMs) to generate pseudo-labels using
image-text alignment, allowing detectors to generalize to unseen classes
without explicit supervision. However, these methods depend heavily on direct
image-text matching, neglecting the intermediate reasoning steps essential for
interpreting semantically complex scenes. This results in limited robustness
when confronted with crowded or occluded visual contexts. In this paper, we
introduce CoT-PL, a new framework that employs structured visual
chain-of-thought (CoT) reasoning into the pseudo-labeling process. CoT-PL
decomposes object understanding into three interpretable steps: (1) region
perception even for unseen objects, (2) category recognition via zero-shot
reasoning, and (3) background grounding to separate semantically complex
objects. Crucially, the third step naturally motivates our contrastive
background learning (CBL) that uses the pre-computed background cues as
negatives to promote feature disentanglement between objects and background. In
this way, CoT reasoning and CBL form an integrated pipeline tailored to robust
pseudo-labeling in crowded or occluded scenes. Notably, in these two settings,
our novel-class pseudo-label quality achieves relative improvements of 103.4%
and 168.4% over the best prior, respectively. Our extensive experiments
demonstrate that CoT-PL achieves +7.7 AP50 on open-vocabulary COCO and +2.9
mask AP on LVIS for novel classes, setting a new state of the art.

</details>


### [75] [Morphology-Aware Prognostic model for Five-Year Survival Prediction in Colorectal Cancer from H&E Whole Slide Images](https://arxiv.org/abs/2510.14800)
*Usama Sajjad,Abdul Rehman Akbar,Ziyu Su,Deborah Knight,Wendy L. Frankel,Metin N. Gurcan,Wei Chen,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: PRISM是一种新的、可解释的人工智能模型，用于预测结直肠癌（CRC）患者的预后，其在5年总生存期预测方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的计算病理学方法往往忽略了肿瘤行为、治疗反应和患者预后所特有的器官形态学模式。本研究旨在开发一种新的、可解释的人工智能模型PRISM，该模型包含每个形态内的连续变异谱，以表征表型多样性，并反映恶性肿瘤通过渐进演化过程而非突然的表型转变而发生的原则。

Method: PRISM模型在来自424名III期CRC患者的手术切除标本中提取的874万张组织学图像上进行训练。

Result: PRISM在五年总生存期预测方面取得了优越的预后性能（AUC = 0.70 ± 0.04；准确率 = 68.37% ± 4.75%；HR = 3.34，95% CI = 2.28-4.90；p < 0.0001），在准确率方面分别优于现有的CRC特异性方法15%和AI基础模型约23%。该模型在性别方面表现出非性别歧视的稳健性（AUC delta = 0.02；准确率delta = 0.15%），并且在临床病理亚组中的表现稳定，在5FU/LV和CPT-11/5FU/LV方案之间的准确率波动最小（delta = 1.44%），并复制了Alliance队列中两种治疗方案之间无生存差异的发现。

Conclusion: PRISM是一种新的、可解释的人工智能模型，可以表征表型多样性，并为III期结直肠癌患者提供准确的预后预测。

Abstract: Colorectal cancer (CRC) remains the third most prevalent malignancy globally,
with approximately 154,000 new cases and 54,000 projected deaths anticipated
for 2025. The recent advancement of foundation models in computational
pathology has been largely propelled by task agnostic methodologies that can
overlook organ-specific crucial morphological patterns that represent distinct
biological processes that can fundamentally influence tumor behavior,
therapeutic response, and patient outcomes. The aim of this study is to develop
a novel, interpretable AI model, PRISM (Prognostic Representation of Integrated
Spatial Morphology), that incorporates a continuous variability spectrum within
each distinct morphology to characterize phenotypic diversity and reflecting
the principle that malignant transformation occurs through incremental
evolutionary processes rather than abrupt phenotypic shifts. PRISM is trained
on 8.74 million histological images extracted from surgical resection specimens
of 424 patients with stage III CRC. PRISM achieved superior prognostic
performance for five-year OS (AUC = 0.70 +- 0.04; accuracy = 68.37% +- 4.75%;
HR = 3.34, 95% CI = 2.28-4.90; p < 0.0001), outperforming existing CRC-specific
methods by 15% and AI foundation models by ~23% accuracy. It showed
sex-agnostic robustness (AUC delta = 0.02; accuracy delta = 0.15%) and stable
performance across clinicopathological subgroups, with minimal accuracy
fluctuation (delta = 1.44%) between 5FU/LV and CPT-11/5FU/LV regimens,
replicating the Alliance cohort finding of no survival difference between
treatments.

</details>


### [76] [Scaling Artificial Intelligence for Multi-Tumor Early Detection with More Reports, Fewer Masks](https://arxiv.org/abs/2510.14803)
*Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Szymon Płotka,Jieneng Chen,Qi Chen,Zheren Zhu,Jakub Prządo,Ibrahim E. Hamacı,Sezgin Er,Yuhan Wang,Ashwin Kumar,Bjoern Menze,Jarosław B. Ćwikła,Yuyin Zhou,Akshay S. Chaudhari,Curtis P. Langlotz,Sergio Decherchi,Andrea Cavalli,Kang Wang,Yang Yang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 利用医学报告训练AI分割肿瘤，减少对人工肿瘤掩膜的需求，并提高检测性能。


<details>
  <summary>Details</summary>
Motivation: CT扫描中早期肿瘤的检测具有挑战性，需要大量昂贵的人工肿瘤掩膜来训练AI模型。

Method: 提出R-Super方法，利用现有的医学报告信息来训练AI分割肿瘤，以替代或补充人工肿瘤掩膜。

Result: 在101,654份报告上训练的AI模型在性能上可与723个掩膜训练的模型相媲美，结合报告和掩膜可以进一步提高敏感性（+13%）和特异性（+8%），在七种肿瘤类型中的五种超过了放射科医生，并实现了之前不存在的肿瘤类型的分割。

Conclusion: R-Super方法能够大规模、可及地训练AI模型进行肿瘤分割，挑战了对大规模、劳动密集型肿瘤掩膜的需求，为早期检测提供了新的途径。

Abstract: Early tumor detection save lives. Each year, more than 300 million computed
tomography (CT) scans are performed worldwide, offering a vast opportunity for
effective cancer screening. However, detecting small or early-stage tumors on
these CT scans remains challenging, even for experts. Artificial intelligence
(AI) models can assist by highlighting suspicious regions, but training such
models typically requires extensive tumor masks--detailed, voxel-wise outlines
of tumors manually drawn by radiologists. Drawing these masks is costly,
requiring years of effort and millions of dollars. In contrast, nearly every CT
scan in clinical practice is already accompanied by medical reports describing
the tumor's size, number, appearance, and sometimes, pathology
results--information that is rich, abundant, and often underutilized for AI
training. We introduce R-Super, which trains AI to segment tumors that match
their descriptions in medical reports. This approach scales AI training with
large collections of readily available medical reports, substantially reducing
the need for manually drawn tumor masks. When trained on 101,654 reports, AI
models achieved performance comparable to those trained on 723 masks. Combining
reports and masks further improved sensitivity by +13% and specificity by +8%,
surpassing radiologists in detecting five of the seven tumor types. Notably,
R-Super enabled segmentation of tumors in the spleen, gallbladder, prostate,
bladder, uterus, and esophagus, for which no public masks or AI models
previously existed. This study challenges the long-held belief that
large-scale, labor-intensive tumor mask creation is indispensable, establishing
a scalable and accessible path toward early detection across diverse tumor
types.
  We plan to release our trained models, code, and dataset at
https://github.com/MrGiovanni/R-Super

</details>


### [77] [Unifying Environment Perception and Route Choice Modeling for Trajectory Representation Learning](https://arxiv.org/abs/2510.14819)
*Ji Cao,Yu Wang,Tongya Zheng,Zujie Ren,Canghong Jin,Gang Chen,Mingli Song*

Main category: cs.CV

TL;DR: PRTraj通过整合环境感知和路线选择模型来学习轨迹表示，在多种下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹表示学习方法忽视了影响轨迹形成的外部环境和内部路线选择行为。

Method: 提出PRTraj框架，包含环境感知模块（捕捉POI分布的多粒度环境语义）和路线选择编码器（将路线选择建模为一系列决策）。

Result: 在3个真实世界数据集和5个下游任务上进行了广泛的实验，证明了PRTraj的有效性和泛化能力，并在少样本场景下表现出良好的数据效率。

Conclusion: PRTraj通过整合环境感知和路线选择建模，能够学习到更有效的轨迹表示，并在各种下游任务中取得领先的性能。

Abstract: Trajectory Representation Learning (TRL) aims to encode raw trajectories into
low-dimensional vectors, which can then be leveraged in various downstream
tasks, including travel time estimation, location prediction, and trajectory
similarity analysis. However, existing TRL methods suffer from a key oversight:
treating trajectories as isolated spatio-temporal sequences, without
considering the external environment and internal route choice behavior that
govern their formation. To bridge this gap, we propose a novel framework that
unifies comprehensive environment \textbf{P}erception and explicit
\textbf{R}oute choice modeling for effective \textbf{Traj}ectory representation
learning, dubbed \textbf{PRTraj}. Specifically, PRTraj first introduces an
Environment Perception Module to enhance the road network by capturing
multi-granularity environmental semantics from surrounding POI distributions.
Building on this environment-aware backbone, a Route Choice Encoder then
captures the route choice behavior inherent in each trajectory by modeling its
constituent road segment transitions as a sequence of decisions. These
route-choice-aware representations are finally aggregated to form the global
trajectory embedding. Extensive experiments on 3 real-world datasets across 5
downstream tasks validate the effectiveness and generalizability of PRTraj.
Moreover, PRTraj demonstrates strong data efficiency, maintaining robust
performance under few-shot scenarios. Our code is available at:
https://anonymous.4open.science/r/PRTraj.

</details>


### [78] [FraQAT: Quantization Aware Training with Fractional bits](https://arxiv.org/abs/2510.14823)
*Luca Morreale,Alberto Gil C. P. Ramos,Malcolm Chadwick,Mehid Noroozi,Ruchika Chavhan,Abhinav Mehrotra,Sourav Bhattacharya*

Main category: cs.CV

TL;DR: 本研究提出了一种名为\"short\"的新型分数比特量化方法，旨在解决大型生成模型在智能手机等移动设备上部署的效率和内存限制问题，同时保持模型生成质量。该方法通过逐步降低模型参数精度（从32位到4位）并在优化过程中利用分数比特来提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型生成模型因其庞大的体积和计算需求，难以在智能手机等资源受限的设备上部署。现有量化方法在追求效率时往往牺牲模型质量。

Method: 提出了一种名为\"short\"（分数比特量化）的新方法。该方法逐步降低模型参数精度，从32位到4位，并在优化过程中利用分数比特来维持生成质量。

Result: \"short\"方法在SD3.5-Medium、Sana、\pixart和FLUX.1-schnell等多种扩散模型上取得了优于标准量化方法（QAT）的生成质量，FiD降低了4-7%。此外，研究成功地将Sana模型部署并在三星S25U手机上运行。

Conclusion: \"short\"量化方法能够有效解决大型生成模型在移动设备上的部署难题，通过分数比特量化技术在保持模型生成质量的同时，显著提高了运行效率。

Abstract: State-of-the-art (SOTA) generative models have demonstrated impressive
capabilities in image synthesis or text generation, often with a large capacity
model. However, these large models cannot be deployed on smartphones due to the
limited availability of on-board memory and computations. Quantization methods
lower the precision of the model parameters, allowing for efficient
computations, \eg, in \INT{8}. Although aggressive quantization addresses
efficiency and memory constraints, preserving the quality of the model remains
a challenge. To retain quality in previous aggressive quantization, we propose
a new fractional bits quantization (\short) approach. The novelty is a simple
yet effective idea: we progressively reduce the model's precision from 32 to 4
bits per parameter, and exploit the fractional bits during optimization to
maintain high generation quality. We show that the \short{} yields improved
quality on a variety of diffusion models, including SD3.5-Medium, Sana,
\pixart, and FLUX.1-schnell, while achieving $4-7\%$ lower FiD than standard
QAT. Finally, we deploy and run Sana on a Samsung S25U, which runs on the
Qualcomm SM8750-AB Snapdragon 8 Elite Hexagon Tensor Processor (HTP).

</details>


### [79] [Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data](https://arxiv.org/abs/2510.14831)
*Qi Chen,Xinze Zhou,Chen Liu,Hao Chen,Wenxuan Li,Zekun Jiang,Ziyan Huang,Yuxuan Zhao,Dexin Yu,Junjun He,Yefeng Zheng,Ling Shao,Alan Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: AI在肿瘤分割中受限于缺乏大型、逐个体素标注的数据集。合成数据可以提高数据利用率，使得用更少真实数据达到相同的性能。AbdomenAtlas 2.0是一个包含10,135个CT扫描和15,130个肿瘤实例的大型数据集，旨在为AI肿瘤分割提供基础，并在分布内和分布外测试中均取得显著改进。


<details>
  <summary>Details</summary>
Motivation: AI在肿瘤分割方面缺乏大型、标注精确的数据集，这阻碍了其性能的提升。真实数据的获取成本高昂且需要专家标注，而合成数据可以提高数据利用效率。

Method: 利用合成数据来扩展真实数据集，并构建了一个名为AbdomenAtlas 2.0的大型CT扫描数据集，其中包含在六个器官中的15,130个肿瘤实例的逐个体素标注。该数据集由23名放射科专家标注，规模远超现有公开数据集。

Result: 在真实数据上，AI性能在1,500例扫描后停止提升。使用合成数据，仅用500例真实数据即可达到相同性能。AbdomenAtlas 2.0数据集在分布内测试中提高了7%的DSC（Dice Similarity Coefficient），在分布外测试中提高了16%。

Conclusion: 合成数据能够改善数据利用效率，加速AI模型的训练。AbdomenAtlas 2.0数据集为AI肿瘤分割提供了强大的基础，并在多个器官的分割任务中取得了显著的性能提升。

Abstract: AI for tumor segmentation is limited by the lack of large, voxel-wise
annotated datasets, which are hard to create and require medical experts. In
our proprietary JHH dataset of 3,000 annotated pancreatic tumor scans, we found
that AI performance stopped improving after 1,500 scans. With synthetic data,
we reached the same performance using only 500 real scans. This finding
suggests that synthetic data can steepen data scaling laws, enabling more
efficient model training than real data alone. Motivated by these lessons, we
created AbdomenAtlas 2.0--a dataset of 10,135 CT scans with a total of 15,130
tumor instances per-voxel manually annotated in six organs (pancreas, liver,
kidney, colon, esophagus, and uterus) and 5,893 control scans. Annotated by 23
expert radiologists, it is several orders of magnitude larger than existing
public tumor datasets. While we continue expanding the dataset, the current
version of AbdomenAtlas 2.0 already provides a strong foundation--based on
lessons from the JHH dataset--for training AI to segment tumors in six organs.
It achieves notable improvements over public datasets, with a +7% DSC gain on
in-distribution tests and +16% on out-of-distribution tests.

</details>


### [80] [ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints](https://arxiv.org/abs/2510.14847)
*Meiqi Wu,Jiashu Zhu,Xiaokun Feng,Chubin Chen,Chen Zhu,Bingze Song,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ImagerySearch的提示引导自适应测试时间搜索策略，用于改善想象场景下的视频生成质量，并引入了LDT-Bench基准测试集来评估此类任务。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在想象场景下的表现不佳，因为这些场景涉及罕见概念组合和长距离语义关系，超出了模型的训练分布。现有的测试时间扩展方法适应性不足。

Method: ImagerySearch是一种提示引导自适应测试时间搜索策略，能够根据提示中的语义关系动态调整推理搜索空间和奖励函数，以生成更连贯、视觉上更可信的视频。

Result: 在LDT-Bench基准测试集上，ImagerySearch相比于现有的视频生成基线和测试时间扩展方法取得了持续的优于结果，并在VBench上取得了有竞争力的改进，证明了其在不同提示类型上的有效性。

Conclusion: ImagerySearch有效解决了想象场景下的视频生成挑战，并引入的LDT-Bench将推动该领域的研究。

Abstract: Video generation models have achieved remarkable progress, particularly
excelling in realistic scenarios; however, their performance degrades notably
in imaginative scenarios. These prompts often involve rarely co-occurring
concepts with long-distance semantic relationships, falling outside training
distributions. Existing methods typically apply test-time scaling for improving
video quality, but their fixed search spaces and static reward designs limit
adaptability to imaginative scenarios. To fill this gap, we propose
ImagerySearch, a prompt-guided adaptive test-time search strategy that
dynamically adjusts both the inference search space and reward function
according to semantic relationships in the prompt. This enables more coherent
and visually plausible videos in challenging imaginative settings. To evaluate
progress in this direction, we introduce LDT-Bench, the first dedicated
benchmark for long-distance semantic prompts, consisting of 2,839 diverse
concept pairs and an automated protocol for assessing creative generation
capabilities. Extensive experiments show that ImagerySearch consistently
outperforms strong video generation baselines and existing test-time scaling
approaches on LDT-Bench, and achieves competitive improvements on VBench,
demonstrating its effectiveness across diverse prompt types. We will release
LDT-Bench and code to facilitate future research on imaginative video
generation.

</details>


### [81] [A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution Simulation](https://arxiv.org/abs/2510.14855)
*Harsha Kotla,Arun Kumar Rajasekaran,Hannah Rana*

Main category: cs.CV

TL;DR: 该研究提出了一个深度学习框架，用于分类皮肤病变并量化ABCD特征（不对称性、边界不规则性、颜色变化、直径），同时模拟特征随时间演变以表示E（演变）。该框架在HAM10000数据集上进行了实验，分类准确率达到89%，黑色素瘤AUC为0.96，并在预测不对称性、颜色变化和直径方面表现良好，但边界不规则性建模仍具挑战性。该框架旨在帮助医生将机器学习诊断与临床标准联系起来，从而加深对皮肤癌进展的理解。


<details>
  <summary>Details</summary>
Motivation: 早期检测黑色素瘤至关重要，但自动化皮肤病变分析仍具挑战性。现有的深度学习方法通常将ABCDE分类法视为黑箱，未能解释人类可解释的特征。本研究旨在解决这一问题，提出一个能够分类病变并量化ABCD特征的深度学习框架。

Method: 本研究提出了一个深度学习框架，该框架能够对皮肤病变进行分类，并量化ABCD（不对称性、边界不规则性、颜色变化、直径）特征的得分。此外，该框架通过模拟这些特征随时间的变化来表示E（演变）方面。研究人员特别在本工作中量化了A、B、C、D值，并可视化了ABCD特征在潜在空间中的演变轨迹，展示了皮肤病变从良性痣到恶性黑色素瘤的演变过程。实验使用了包含约一万张不同阶段皮肤病变图像的HAM10000数据集。

Result: 在HAM10000数据集上进行的实验显示，该框架的分类准确率约为89%，黑色素瘤的AUC为0.96。在特征评估方面，该框架在预测不对称性、颜色变化和直径方面表现良好，但边界不规则性的建模仍然更具挑战性。

Conclusion: 本研究提出了一个深度学习框架，该框架不仅能对皮肤病变进行分类，还能量化ABCD特征，并模拟其演变过程。该框架能够帮助医生将机器学习诊断与临床上相关的标准联系起来，从而促进对皮肤癌进展的理解。虽然在某些特征的预测上仍有改进空间（如边界不规则性），但整体上为皮肤癌的早期检测和诊断提供了有价值的工具。

Abstract: Early detection of melanoma has grown to be essential because it
significantly improves survival rates, but automated analysis of skin lesions
still remains challenging. ABCDE, which stands for Asymmetry, Border
irregularity, Color variation, Diameter, and Evolving, is a well-known
classification method for skin lesions, but most deep learning mechanisms treat
it as a black box, as most of the human interpretable features are not
explained. In this work, we propose a deep learning framework that both
classifies skin lesions into categories and also quantifies scores for each
ABCD feature. It simulates the evolution of these features over time in order
to represent the E aspect, opening more windows for future exploration. The A,
B, C, and D values are quantified particularly within this work. Moreover, this
framework also visualizes ABCD feature trajectories in latent space as skin
lesions evolve from benign nevuses to malignant melanoma. The experiments are
conducted using the HAM10000 dataset that contains around ten thousand images
of skin lesions of varying stages. In summary, the classification worked with
an accuracy of around 89 percent, with melanoma AUC being 0.96, while the
feature evaluation performed well in predicting asymmetry, color variation, and
diameter, though border irregularity remains more difficult to model. Overall,
this work provides a deep learning framework that will allow doctors to link ML
diagnoses to clinically relevant criteria, thus improving our understanding of
skin cancer progression.

</details>


### [82] [Benchmarking Multimodal Large Language Models for Face Recognition](https://arxiv.org/abs/2510.14866)
*Hatef Otroshi Shahreza,Sébastien Marcel*

Main category: cs.CV

TL;DR: MLLMs在人脸识别方面表现出潜力，但与专用模型相比仍有差距，尤其是在零样本高精度识别场景下。本研究对LFW、CALFW、CPLFW、CFP、AgeDB和RFW等数据集上的MLLMs进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 评估和比较开源MLLMs在标准人脸识别基准上的性能，并与现有的人脸识别模型进行对比。

Method: 在LFW、CALFW、CPLFW、CFP、AgeDB和RFW等多个数据集上，对最先进的MLLMs进行系统性基准测试。

Result: MLLMs能够捕捉到对人脸相关任务有用的丰富语义线索，但在零样本高精度识别场景中，其性能落后于专用模型。

Conclusion: 本基准测试为推进基于MLLM的人脸识别奠定了基础，并为设计下一代具有更高准确性和泛化能力的人脸识别模型提供了见解。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable performance
across diverse vision-and-language tasks. However, their potential in face
recognition remains underexplored. In particular, the performance of
open-source MLLMs needs to be evaluated and compared with existing face
recognition models on standard benchmarks with similar protocol. In this work,
we present a systematic benchmark of state-of-the-art MLLMs for face
recognition on several face recognition datasets, including LFW, CALFW, CPLFW,
CFP, AgeDB and RFW. Experimental results reveal that while MLLMs capture rich
semantic cues useful for face-related tasks, they lag behind specialized models
in high-precision recognition scenarios in zero-shot applications. This
benchmark provides a foundation for advancing MLLM-based face recognition,
offering insights for the design of next-generation models with higher accuracy
and generalization. The source code of our benchmark is publicly available in
the project page.

</details>


### [83] [TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions](https://arxiv.org/abs/2510.14874)
*Guangyi Han,Wei Zhai,Yuhang Yang,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 该研究提出了Free-Form HOI Generation，用于生成更具多样性和可控性的手-物体交互（HOI）动作，不再局限于传统的固定抓握模式，而是扩展到推、戳、旋转等自由形式的交互。


<details>
  <summary>Details</summary>
Motivation: 现有HOI生成研究主要集中于固定的抓握模式，并受限于物理先验或泛化的意图指令，无法捕捉日常HOI的多样性。本研究旨在解决这些局限性。

Method: 构建了一个名为WildO2的真实世界3D HOI数据集，包含4.4k个独特交互、92种意图和610个物体类别。在此基础上，提出了TOUCH框架，利用多层次扩散模型、显式接触建模以及接触一致性和物理约束，实现对多样化手部姿态的生成。

Result: 实验证明，该方法能够生成可控、多样且符合物理规律的手部交互动作，能够代表日常活动。

Conclusion: 本研究成功地将HOI生成从固定的抓握模式扩展到更自由的交互形式，并通过构建新数据集和提出TOUCH框架，实现了对精细化意图的控制，生成了更逼真、更多样化的HOI。

Abstract: Hand-object interaction (HOI) is fundamental for humans to express intent.
Existing HOI generation research is predominantly confined to fixed grasping
patterns, where control is tied to physical priors such as force closure or
generic intent instructions, even when expressed through elaborate language.
Such an overly general conditioning imposes a strong inductive bias for stable
grasps, thus failing to capture the diversity of daily HOI. To address these
limitations, we introduce Free-Form HOI Generation, which aims to generate
controllable, diverse, and physically plausible HOI conditioned on fine-grained
intent, extending HOI from grasping to free-form interactions, like pushing,
poking, and rotating. To support this task, we construct WildO2, an in-the-wild
diverse 3D HOI dataset, which includes diverse HOI derived from internet
videos. Specifically, it contains 4.4k unique interactions across 92 intents
and 610 object categories, each with detailed semantic annotations. Building on
this dataset, we propose TOUCH, a three-stage framework centered on a
multi-level diffusion model that facilitates fine-grained semantic control to
generate versatile hand poses beyond grasping priors. This process leverages
explicit contact modeling for conditioning and is subsequently refined with
contact consistency and physical constraints to ensure realism. Comprehensive
experiments demonstrate our method's ability to generate controllable, diverse,
and physically plausible hand interactions representative of daily activities.
The project page is $\href{https://guangyid.github.io/hoi123touch}{here}$.

</details>


### [84] [BADAS: Context Aware Collision Prediction Using Real-World Dashcam Data](https://arxiv.org/abs/2510.14876)
*Roni Goldshmidt,Hamish Scott,Lorenzo Niccolini,Shizhan Zhu,Daniel Moura,Orly Zvitia*

Main category: cs.CV

TL;DR: BADAS是一个碰撞预测模型，能区分涉及自身车辆的威胁和随机事故，减少误报。该模型在Nexar数据集上训练，并重新标注了主要基准，以进行以自身为中心的评估。BADAS在多个数据集上取得了最先进的性能，并优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的碰撞预测方法无法区分涉及自身车辆的威胁和随机事故，导致在实际部署中出现过多的误报。因此，需要一种能够区分这些情况并提高预测准确性的方法。

Method: 使用V-JEPA2骨干网络，在Nexar的真实世界的行车记录仪碰撞数据集上进行端到端训练。该模型有两种变体：BADAS-Open（在1.5k个公开视频上训练）和BADAS1.0（在40k个专有视频上训练）。对主要基准进行了重新标注，以识别涉及自身车辆的情况，并添加了共识警报时间标签，并在需要时合成负样本。

Result: BADAS在DAD、DADA-2000、DoTA和Nexar数据集上实现了最先进的AP/AUC，其性能优于前向碰撞ADAS基线，并能提供更真实的事故时间估计。BADAS-Open模型权重和代码，以及所有评估数据集的重新标注将被发布。

Conclusion: BADAS模型能够有效地区分涉及自身车辆的碰撞威胁和随机事故，从而减少误报并提高碰撞预测的准确性。通过使用真实的行车记录仪数据和改进的评估方法，BADAS在多个基准测试中取得了领先的性能。该研究的成果将促进以自身为中心的碰撞预测领域的研究。

Abstract: Existing collision prediction methods often fail to distinguish between
ego-vehicle threats and random accidents not involving the ego vehicle, leading
to excessive false alerts in real-world deployment. We present BADAS, a family
of collision prediction models trained on Nexar's real-world dashcam collision
dataset -- the first benchmark designed explicitly for ego-centric evaluation.
We re-annotate major benchmarks to identify ego involvement, add consensus
alert-time labels, and synthesize negatives where needed, enabling fair AP/AUC
and temporal evaluation. BADAS uses a V-JEPA2 backbone trained end-to-end and
comes in two variants: BADAS-Open (trained on our 1.5k public videos) and
BADAS1.0 (trained on 40k proprietary videos). Across DAD, DADA-2000, DoTA, and
Nexar, BADAS achieves state-of-the-art AP/AUC and outperforms a
forward-collision ADAS baseline while producing more realistic time-to-accident
estimates. We release our BADAS-Open model weights and code, along with
re-annotations of all evaluation datasets to promote ego-centric collision
prediction research.

</details>


### [85] [ScaleWeaver: Weaving Efficient Controllable T2I Generation with Multi-Scale Reference Attention](https://arxiv.org/abs/2510.14882)
*Keli Liu,Zhendong Wang,Wengang Zhou,Shaodong Xu,Ruixiao Dong,Houqiang Li*

Main category: cs.CV

TL;DR: ScaleWeaver是一个参数高效的框架，用于在视觉自回归（VAR）模型上实现可控的文本到图像生成，通过改进的MMDiT块和参考注意力模块来提高生成质量和控制精度，同时保持高效。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型（特别是视觉自回归模型）在控制方面仍有不足，需要一种能够实现精确灵活控制的框架。

Method: ScaleWeaver提出了一种基于参数高效微调的新框架，其核心是改进的MMDiT块和参考注意力模块。该模块通过减少不必要的注意力计算、强调参数重用以及使用零初始化的线性层来有效整合控制信息，同时不破坏基础模型的生成能力。

Result: 实验表明，ScaleWeaver在生成高质量图像和实现精确控制方面表现出色，并且比基于扩散的方法更高效，使其成为VAR模型可控文本到图像生成的一个实用有效解决方案。

Conclusion: ScaleWeaver成功地在视觉自回归模型上实现了高保真度、可控的文本到图像生成，并在效率上优于扩散模型，为该领域提供了一个有前景的解决方案。

Abstract: Text-to-image generation with visual autoregressive~(VAR) models has recently
achieved impressive advances in generation fidelity and inference efficiency.
While control mechanisms have been explored for diffusion models, enabling
precise and flexible control within VAR paradigm remains underexplored. To
bridge this critical gap, in this paper, we introduce ScaleWeaver, a novel
framework designed to achieve high-fidelity, controllable generation upon
advanced VAR models through parameter-efficient fine-tuning. The core module in
ScaleWeaver is the improved MMDiT block with the proposed Reference Attention
module, which efficiently and effectively incorporates conditional information.
Different from MM Attention, the proposed Reference Attention module discards
the unnecessary attention from image$\rightarrow$condition, reducing
computational cost while stabilizing control injection. Besides, it
strategically emphasizes parameter reuse, leveraging the capability of the VAR
backbone itself with a few introduced parameters to process control
information, and equipping a zero-initialized linear projection to ensure that
control signals are incorporated effectively without disrupting the generative
capability of the base model. Extensive experiments show that ScaleWeaver
delivers high-quality generation and precise control while attaining superior
efficiency over diffusion-based methods, making ScaleWeaver a practical and
effective solution for controllable text-to-image generation within the visual
autoregressive paradigm. Code and models will be released.

</details>


### [86] [You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction](https://arxiv.org/abs/2510.14885)
*Logan Lawrence,Oindrila Saha,Megan Wei,Chen Sun,Subhransu Maji,Grant Van Horn*

Main category: cs.CV

TL;DR: 尽管 MLLMs 的兴起使零样本视觉分类重新受到关注，但自动回归模型自由形式响应的评估仍然是一个挑战。现有方法在处理具有大量高度相关选项的细粒度视觉分类 (FGVC) 任务时存在局限性。本文提出的 nlg2choice 方法通过开放式提问和约束解码来解决这些问题，并在 FGVC 数据集上取得了改进。


<details>
  <summary>Details</summary>
Motivation: 评估自动回归模型对自由形式响应的能力，特别是在细粒度视觉分类 (FGVC) 任务中，这些任务涉及大量高度相关的选项，而现有方法存在局限性。

Method: 提出了一种名为 nlg2choice 的两阶段方法：首先，让 MLLM 在几乎无限制的情况下回答开放式问题；然后，使用仅文本的约束解码来预测最可能的选项。在检索设置中，通过早期停止策略计算约束响应的概率，以提高吞吐量。

Result: 在七个细粒度视觉数据集上，nlg2choice 在分类和检索方面均取得了改进，并且这种性能在不同的自然语言任务实现方式下得以保持。

Conclusion: nlg2choice 方法在细粒度视觉分类任务中，尤其是在具有大量选项的 MCQs 和检索设置下，能够有效地评估 MLLMs 的性能，并优于现有方法。

Abstract: Despite the renewed interest in zero-shot visual classification due to the
rise of Multimodal Large Language Models (MLLMs), the problem of evaluating
free-form responses of auto-regressive models remains a persistent challenge.
Most existing works focus on language-only tasks or don't consider Multiple
Choice Questions (MCQs) beyond 5-way options, both of which are critical
capabilities to solve tasks in Fine-Grained Visual Classification (FGVC) where
choice counts are in the hundreds to thousands and the choices are highly
related. Furthermore, in this highly multi-way MCQ setting it is not clear how
to extend LLM choice extraction to retrieval-based problems, where computing
probabilities over the choice set is computationally costly. In this work we
investigate nlg2choice, a simple two-stage method which first asks the MLLM an
open-ended question for the task with minimal constraints, then uses text-only
constrained decoding to predict the most likely choice. In retrieval settings,
we compute the probability of the constrained response taking that choice with
an early stopping method to significantly improve throughput. Our results show
improvement over a suite of seven fine-grained visual datasets when evaluating
in terms of classification and retrieval, and show that this performance holds
over the various ways that users of LLMs can implement tasks in natural
language.

</details>


### [87] [Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection](https://arxiv.org/abs/2510.14896)
*Furkan Mumcu,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.CV

TL;DR: 本研究提出一种利用多模态大语言模型（MLLM）的半监督视频异常检测（VAD）框架，通过提取和解释物体活动与交互的时序信息来检测复杂异常，并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督视频异常检测（VAD）方法在检测涉及物体交互的复杂异常方面存在困难，并且缺乏可解释性。

Method: 利用MLLM提取物体对在不同时刻的视觉输入，生成时序活动与交互的文本描述，并将这些描述作为高层表征，在测试时通过与训练集中标称视频的文本描述进行比较来检测异常。

Result: 在基准数据集上的广泛实验表明，该方法能有效检测复杂的基于交互的异常，并在没有交互异常的数据集上达到最先进的性能。

Conclusion: 本研究提出的MLLM驱动的VAD框架通过关注物体活动与交互的时序文本描述，有效解决了现有方法的局限性，提高了异常检测的性能和可解释性。

Abstract: Existing semi-supervised video anomaly detection (VAD) methods often struggle
with detecting complex anomalies involving object interactions and generally
lack explainability. To overcome these limitations, we propose a novel VAD
framework leveraging Multimodal Large Language Models (MLLMs). Unlike previous
MLLM-based approaches that make direct anomaly judgments at the frame level,
our method focuses on extracting and interpreting object activity and
interactions over time. By querying an MLLM with visual inputs of object pairs
at different moments, we generate textual descriptions of the activity and
interactions from nominal videos. These textual descriptions serve as a
high-level representation of the activity and interactions of objects in a
video. They are used to detect anomalies during test time by comparing them to
textual descriptions found in nominal training videos. Our approach inherently
provides explainability and can be combined with many traditional VAD methods
to further enhance their interpretability. Extensive experiments on benchmark
datasets demonstrate that our method not only detects complex interaction-based
anomalies effectively but also achieves state-of-the-art performance on
datasets without interaction anomalies.

</details>


### [88] [MaskCaptioner : Learning to Jointly Segment and Caption Object Trajectories in Videos](https://arxiv.org/abs/2510.14904)
*Gabriel Fiastre,Antoine Yang,Cordelia Schmid*

Main category: cs.CV

TL;DR: 提出MaskCaptioner模型，通过生成合成字幕并在LVISCap和LV-VISCap数据集上进行训练，实现了最先进的视频目标密集字幕（DVOC）性能。


<details>
  <summary>Details</summary>
Motivation: 以往的DVOC方法由于手动标注成本高昂而采用分离训练策略，导致性能不佳。

Method: 利用最先进的视觉语言模型（VLM）生成关于时空局部实体的字幕，并扩展LVIS和LV-VIS数据集（LVISCap和LV-VISCap），然后训练了一个能够联合检测、分割、跟踪和字幕化对象轨迹的端到端模型MaskCaptioner。

Result: 在VidSTG、VLN和BenSMOT三个基准上，MaskCaptioner在DVOC任务上取得了最先进的性能。

Conclusion: 通过生成合成字幕并进行端到端训练，MaskCaptioner克服了以往DVOC方法的局限性，并在多个基准上取得了优越的性能。

Abstract: Dense Video Object Captioning (DVOC) is the task of jointly detecting,
tracking, and captioning object trajectories in a video, requiring the ability
to understand spatio-temporal details and describe them in natural language.
Due to the complexity of the task and the high cost associated with manual
annotation, previous approaches resort to disjoint training strategies,
potentially leading to suboptimal performance. To circumvent this issue, we
propose to generate captions about spatio-temporally localized entities
leveraging a state-of-the-art VLM. By extending the LVIS and LV-VIS datasets
with our synthetic captions (LVISCap and LV-VISCap), we train MaskCaptioner, an
end-to-end model capable of jointly detecting, segmenting, tracking and
captioning object trajectories. Moreover, with pretraining on LVISCap and
LV-VISCap, MaskCaptioner achieves state-of-the-art DVOC results on three
existing benchmarks, VidSTG, VLN and BenSMOT. The datasets and code are
available at https://www.gabriel.fiastre.fr/maskcaptioner/.

</details>


### [89] [3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation](https://arxiv.org/abs/2510.14945)
*JoungBin Lee,Jaewoo Jung,Jisang Han,Takuya Narihira,Kazumi Fukuda,Junyoung Seo,Sunghwan Hong,Yuki Mitsufuji,Seungryong Kim*

Main category: cs.CV

TL;DR: 3DScenePrompt框架通过双重时空条件和3D场景记忆，实现了从任意长度视频生成下一帧，并精确控制相机，保持场景一致性。


<details>
  <summary>Details</summary>
Motivation: 需要从任意长度的视频输入生成视频的下一段，同时实现精确的相机控制并保持场景一致性，现有方法（仅基于单张图像或短片段）存在局限性。

Method: 采用双重时空条件，结合时间相邻帧（用于运动连续性）和空间相邻内容（用于场景一致性）。引入3D场景记忆，表示从整个输入视频中提取的静态几何结构，使用动态SLAM和动态遮蔽策略分离静态场景和动态元素。将静态场景表示投影到目标视角，提供几何一致的扭曲视图作为3D空间提示，并允许动态区域从时间上下文自然演变。

Result: 实验证明，该框架在场景一致性、相机可控性和生成质量方面显著优于现有方法。

Conclusion: 3DScenePrompt框架能够高效、逼真地生成长时空一致性视频，并精确控制相机视角，解决了现有技术的不足。

Abstract: We present 3DScenePrompt, a framework that generates the next video chunk
from arbitrary-length input while enabling precise camera control and
preserving scene consistency. Unlike methods conditioned on a single image or a
short clip, we employ dual spatio-temporal conditioning that reformulates
context-view referencing across the input video. Our approach conditions on
both temporally adjacent frames for motion continuity and spatially adjacent
content for scene consistency. However, when generating beyond temporal
boundaries, directly using spatially adjacent frames would incorrectly preserve
dynamic elements from the past. We address this by introducing a 3D scene
memory that represents exclusively the static geometry extracted from the
entire input video. To construct this memory, we leverage dynamic SLAM with our
newly introduced dynamic masking strategy that explicitly separates static
scene geometry from moving elements. The static scene representation can then
be projected to any target viewpoint, providing geometrically consistent warped
views that serve as strong 3D spatial prompts while allowing dynamic regions to
evolve naturally from temporal context. This enables our model to maintain
long-range spatial coherence and precise camera control without sacrificing
computational efficiency or motion realism. Extensive experiments demonstrate
that our framework significantly outperforms existing methods in scene
consistency, camera controllability, and generation quality. Project page :
https://cvlab-kaist.github.io/3DScenePrompt/

</details>


### [90] [OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression](https://arxiv.org/abs/2510.14954)
*Zhe Li,Weihao Yuan,Weichao Shen,Siyu Zhu,Zilong Dong,Chang Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的多模态人类运动生成框架，通过连续掩码自回归运动 Transformer、门控线性注意力、RMSNorm 和 DiT 结构，实现了跨文本、语音和音乐的更优越的运动生成能力。


<details>
  <summary>Details</summary>
Motivation: 为了应对现有方法在生成有效运动以及融合文本、语音、音乐等多种模态时面临的挑战，本研究开发了一种新的框架。

Method: 本研究提出了一种连续掩码自回归运动 Transformer，其中包含因果注意力机制、门控线性注意力和 RMSNorm 模块，并结合 DiT 结构进行条件扩散，同时利用 AdaLN 和交叉注意力融合文本、语音和音乐信号。

Result: 实验结果表明，所提出的框架在文本到运动、语音到手势和音乐到舞蹈等所有模态的生成任务上均优于现有方法。

Conclusion: 本研究成功开发了一种有效的多模态人类运动生成框架，显著提升了在不同输入模态下的运动生成质量和泛化能力。

Abstract: Whole-body multi-modal human motion generation poses two primary challenges:
creating an effective motion generation mechanism and integrating various
modalities, such as text, speech, and music, into a cohesive framework. Unlike
previous methods that usually employ discrete masked modeling or autoregressive
modeling, we develop a continuous masked autoregressive motion transformer,
where a causal attention is performed considering the sequential nature within
the human motion. Within this transformer, we introduce a gated linear
attention and an RMSNorm module, which drive the transformer to pay attention
to the key actions and suppress the instability caused by either the abnormal
movements or the heterogeneous distributions within multi-modalities. To
further enhance both the motion generation and the multimodal generalization,
we employ the DiT structure to diffuse the conditions from the transformer
towards the targets. To fuse different modalities, AdaLN and cross-attention
are leveraged to inject the text, speech, and music signals. Experimental
results demonstrate that our framework outperforms previous methods across all
modalities, including text-to-motion, speech-to-gesture, and music-to-dance.
The code of our method will be made public.

</details>


### [91] [RealDPO: Real or Not Real, that is the Preference](https://arxiv.org/abs/2510.14955)
*Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu*

Main category: cs.CV

TL;DR: RealDPO是一个新颖的范式，利用真实世界数据作为偏好学习的正面样本，以实现更精确的运动合成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在合成复杂运动方面存在挑战，难以生成自然、平滑和上下文一致的运动，限制了其实际应用。

Method: RealDPO采用直接偏好优化（DPO）和定制的损失函数，通过将真实世界视频与错误的模型输出进行对比，实现迭代自我修正，从而提高运动真实性。此外，还提出了RealAction-5K数据集来支持复杂运动合成的训练后任务。

Result: RealDPO在视频质量、文本对齐和运动真实性方面显著优于现有最先进的模型和偏好优化技术。

Conclusion: RealDPO通过利用真实世界数据进行偏好学习，成功解决了现有视频生成模型在复杂运动合成方面的挑战，显著提高了生成视频的质量和真实性。

Abstract: Video generative models have recently achieved notable advancements in
synthesis quality. However, generating complex motions remains a critical
challenge, as existing models often struggle to produce natural, smooth, and
contextually consistent movements. This gap between generated and real-world
motions limits their practical applicability. To address this issue, we
introduce RealDPO, a novel alignment paradigm that leverages real-world data as
positive samples for preference learning, enabling more accurate motion
synthesis. Unlike traditional supervised fine-tuning (SFT), which offers
limited corrective feedback, RealDPO employs Direct Preference Optimization
(DPO) with a tailored loss function to enhance motion realism. By contrasting
real-world videos with erroneous model outputs, RealDPO enables iterative
self-correction, progressively refining motion quality. To support
post-training in complex motion synthesis, we propose RealAction-5K, a curated
dataset of high-quality videos capturing human daily activities with rich and
precise motion details. Extensive experiments demonstrate that RealDPO
significantly improves video quality, text alignment, and motion realism
compared to state-of-the-art models and existing preference optimization
techniques.

</details>


### [92] [MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning](https://arxiv.org/abs/2510.14958)
*Weikang Shi,Aldrich Yu,Rongyao Fang,Houxing Ren,Ke Wang,Aojun Zhou,Changyao Tian,Xinyu Fu,Yuxuan Hu,Zimu Lu,Linjiang Huang,Si Liu,Rui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: LLMs在数学推理方面存在不足，尤其是在依赖视觉辅助的几何学中。MathCanvas框架通过预训练和指令微调，使LMM能够内在化视觉推理能力，通过MathCanvas-Bench和BAGEL-Canvas模型取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在文本推理方面表现出色，但在数学领域，特别是需要视觉辅助的几何学方面存在不足。现有的视觉推理方法受限于外部工具或无法生成高质量、适时的图表，因此需要一个能够让统一的大型多模态模型（LMM）具备内在视觉推理能力来解决数学问题。

Method: 本研究提出了MathCanvas框架，包含两个阶段：1. 视觉操作阶段，使用包含15.2M（10M图文对+5.2M编辑轨迹）的新数据集对模型进行预训练，以掌握图表生成和编辑。2. 策略性视觉辅助推理阶段，使用包含219K个视觉-文本推理路径的新数据集对模型进行微调，以学习何时以及如何利用视觉辅助。此外，还引入了包含3K个问题的MathCanvas-Bench基准进行评估。

Result: 在MathCanvas-Bench基准上，使用该框架训练的BAGEL-Canvas模型取得了86%的相对改进，并且在其他公开数学基准上也表现出良好的泛化能力。

Conclusion: MathCanvas框架提供了一个完整的工具包（框架、数据集和基准），能够解锁LMM在复杂、类似人类的视觉辅助推理能力。

Abstract: While Large Language Models (LLMs) have excelled in textual reasoning, they
struggle with mathematical domains like geometry that intrinsically rely on
visual aids. Existing approaches to Visual Chain-of-Thought (VCoT) are often
limited by rigid external tools or fail to generate the high-fidelity,
strategically-timed diagrams necessary for complex problem-solving. To bridge
this gap, we introduce MathCanvas, a comprehensive framework designed to endow
unified Large Multimodal Models (LMMs) with intrinsic VCoT capabilities for
mathematics. Our approach consists of two phases. First, a Visual Manipulation
stage pre-trains the model on a novel 15.2M-pair corpus, comprising 10M
caption-to-diagram pairs (MathCanvas-Imagen) and 5.2M step-by-step editing
trajectories (MathCanvas-Edit), to master diagram generation and editing.
Second, a Strategic Visual-Aided Reasoning stage fine-tunes the model on
MathCanvas-Instruct, a new 219K-example dataset of interleaved visual-textual
reasoning paths, teaching it when and how to leverage visual aids. To
facilitate rigorous evaluation, we introduce MathCanvas-Bench, a challenging
benchmark with 3K problems that require models to produce interleaved
visual-textual solutions. Our model, BAGEL-Canvas, trained under this
framework, achieves an 86% relative improvement over strong LMM baselines on
MathCanvas-Bench, demonstrating excellent generalization to other public math
benchmarks. Our work provides a complete toolkit-framework, datasets, and
benchmark-to unlock complex, human-like visual-aided reasoning in LMMs. Project
Page: https://mathcanvas.github.io/

</details>


### [93] [C4D: 4D Made from 3D through Dual Correspondences](https://arxiv.org/abs/2510.14960)
*Shizun Wang,Zhenxiang Jiang,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: C4D是一个利用时间对应关系从单目视频中恢复4D动态几何和相机姿态的框架，解决了现有3D重建方法在动态场景下的不准确问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于点图的3D重建方法（如DUSt3R）在处理动态场景时因移动物体违反多视图几何约束而导致结果不准确。

Method: C4D通过预测点图，并捕捉短期光流和长期点追踪两种对应关系。通过训练动态感知点追踪器提供移动信息，进而估计运动掩码以分离移动物体和背景。引入动态场景优化目标来恢复每帧的3D几何和相机参数，并通过对应关系将2D轨迹提升为3D轨迹，实现完整的4D重建。

Result: C4D实现了完整的4D重建，并在深度估计、相机姿态估计和点追踪等下游任务中表现出强大的性能。

Conclusion: C4D成功地扩展了现有的3D重建方法以处理4D动态场景，通过利用时间对应关系实现了准确的动态几何和相机姿态估计。

Abstract: Recovering 4D from monocular video, which jointly estimates dynamic geometry
and camera poses, is an inevitably challenging problem. While recent
pointmap-based 3D reconstruction methods (e.g., DUSt3R) have made great
progress in reconstructing static scenes, directly applying them to dynamic
scenes leads to inaccurate results. This discrepancy arises because moving
objects violate multi-view geometric constraints, disrupting the
reconstruction. To address this, we introduce C4D, a framework that leverages
temporal Correspondences to extend existing 3D reconstruction formulation to
4D. Specifically, apart from predicting pointmaps, C4D captures two types of
correspondences: short-term optical flow and long-term point tracking. We train
a dynamic-aware point tracker that provides additional mobility information,
facilitating the estimation of motion masks to separate moving elements from
the static background, thus offering more reliable guidance for dynamic scenes.
Furthermore, we introduce a set of dynamic scene optimization objectives to
recover per-frame 3D geometry and camera parameters. Simultaneously, the
correspondences lift 2D trajectories into smooth 3D trajectories, enabling
fully integrated 4D reconstruction. Experiments show that our framework
achieves complete 4D recovery and demonstrates strong performance across
multiple downstream tasks, including depth estimation, camera pose estimation,
and point tracking. Project Page: https://littlepure2333.github.io/C4D

</details>


### [94] [RainDiff: End-to-end Precipitation Nowcasting Via Token-wise Attention Diffusion](https://arxiv.org/abs/2510.14962)
*Thao Nguyen,Jiaqi Ma,Fahad Shahbaz Khan,Souhaib Ben Taieb,Salman Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种新的基于注意力机制的扩散模型，用于改进降水临近预报的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的降水临近预报方法在处理大气混沌和时空耦合动力学方面存在挑战，要么需要额外训练自编码器导致复杂性和泛化性受限，要么在像素空间计算成本高昂且忽略了注意力机制，难以捕捉长程时空依赖。本研究旨在解决这些局限性。

Method: 提出了一种将Token-wise Attention机制集成到U-Net扩散模型和时空编码器中的新方法，能够动态捕捉多尺度空间交互和时间演化，无需单独的潜在模块，也避免了像素空间方法的计算高成本。

Result: 所提出的方法在多种数据集上进行了广泛的实验和视觉评估，结果表明该方法在局部保真度、泛化能力和复杂降水预测场景的鲁棒性方面显著优于现有最先进的方法。

Conclusion: 本研究提出的集成Token-wise Attention的扩散模型在降水临近预报任务上取得了显著的性能提升，有效解决了现有方法的不足，并在准确性和效率方面展现出优势。

Abstract: Precipitation nowcasting, predicting future radar echo sequences from current
observations, is a critical yet challenging task due to the inherently chaotic
and tightly coupled spatio-temporal dynamics of the atmosphere. While recent
advances in diffusion-based models attempt to capture both large-scale motion
and fine-grained stochastic variability, they often suffer from scalability
issues: latent-space approaches require a separately trained autoencoder,
adding complexity and limiting generalization, while pixel-space approaches are
computationally intensive and often omit attention mechanisms, reducing their
ability to model long-range spatio-temporal dependencies. To address these
limitations, we propose a Token-wise Attention integrated into not only the
U-Net diffusion model but also the spatio-temporal encoder that dynamically
captures multi-scale spatial interactions and temporal evolution. Unlike prior
approaches, our method natively integrates attention into the architecture
without incurring the high resource cost typical of pixel-space diffusion,
thereby eliminating the need for separate latent modules. Our extensive
experiments and visual evaluations across diverse datasets demonstrate that the
proposed method significantly outperforms state-of-the-art approaches, yielding
superior local fidelity, generalization, and robustness in complex
precipitation forecasting scenarios.

</details>


### [95] [ChangingGrounding: 3D Visual Grounding in Changing Scenes](https://arxiv.org/abs/2510.14965)
*Miao Hu,Zhiwei Huang,Tai Wang,Jiangmiao Pang,Dahua Lin,Nanning Zheng,Runsen Xu*

Main category: cs.CV

TL;DR: 该研究提出了ChangingGrounding基准和Mem-ChangingGrounder方法，以解决机器人实时3D物体定位在动态变化场景中的挑战，该方法利用记忆和多视图融合来提高定位精度并降低探索成本。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位方法假设场景是静态且信息完整的，这在现实世界的动态变化场景中是不切实际的，需要昂贵的重新扫描，阻碍了部署。因此，需要一种能够利用历史观察、选择性探索并适应变化的场景的3D视觉定位方法。

Method: 提出ChangingGrounding基准来评估机器人在动态变化场景中利用过去观察、选择性探索和提供精确3D框的能力。并提出Mem-ChangingGrounder方法，该方法结合了跨模态检索和轻量级多视图融合：识别查询隐含的对象类型，利用检索到的记忆指导动作，高效探索目标，在操作无效时回退，执行目标的多视图扫描，并融合多视图证据以获得准确的3D边界框。

Result: Mem-ChangingGrounder在ChangingGrounding基准上实现了最高的定位精度，同时大大降低了探索成本，优于其他基线方法。

Conclusion: ChangingGrounding基准和Mem-ChangingGrounder方法的提出，旨在推动3D视觉定位研究向实际应用和以记忆为中心的方向发展，以适应真实世界中动态变化的应用场景。

Abstract: Real-world robots localize objects from natural-language instructions while
scenes around them keep changing. Yet most of the existing 3D visual grounding
(3DVG) method still assumes a reconstructed and up-to-date point cloud, an
assumption that forces costly re-scans and hinders deployment. We argue that
3DVG should be formulated as an active, memory-driven problem, and we introduce
ChangingGrounding, the first benchmark that explicitly measures how well an
agent can exploit past observations, explore only where needed, and still
deliver precise 3D boxes in changing scenes. To set a strong reference point,
we also propose Mem-ChangingGrounder, a zero-shot method for this task that
marries cross-modal retrieval with lightweight multi-view fusion: it identifies
the object type implied by the query, retrieves relevant memories to guide
actions, then explores the target efficiently in the scene, falls back when
previous operations are invalid, performs multi-view scanning of the target,
and projects the fused evidence from multi-view scans to get accurate object
bounding boxes. We evaluate different baselines on ChangingGrounding, and our
Mem-ChangingGrounder achieves the highest localization accuracy while greatly
reducing exploration cost. We hope this benchmark and method catalyze a shift
toward practical, memory-centric 3DVG research for real-world applications.
Project page: https://hm123450.github.io/CGB/ .

</details>


### [96] [WithAnyone: Towards Controllable and ID Consistent Image Generation](https://arxiv.org/abs/2510.14975)
*Hengyuan Xu,Wei Cheng,Peng Xing,Yixiao Fang,Shuhan Wu,Rui Wang,Xianfang Zeng,Daxin Jiang,Gang Yu,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 该研究提出了WithAnyone模型，通过构建大规模多身份数据集MultiID-2M和引入对比身份损失，有效解决了文本到图像生成中的“复制粘贴”问题，提高了身份保真度和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在生成身份相关图像时，由于缺乏大规模多图像身份数据集，常采用基于重建的训练方式，导致模型直接复制参考人脸而非保持身份的自然变化（如姿势、表情、光照），即“复制粘贴”问题，这限制了生成的可控性和表现力。

Method: 1. 构建了大规模多身份数据集MultiID-2M，包含同一身份的多样化参考图像，以适应多人场景。
2. 提出了一个量化“复制粘贴”伪影以及身份保真度与多样性之间权衡的基准。
3. 设计了一种新颖的训练范式，引入对比身份损失，利用配对数据来平衡身份保真度和多样性。
4. 提出了基于扩散模型的WithAnyone，以缓解“复制粘贴”问题并保持高身份相似性。

Result: WithAnyone模型显著减少了“复制粘贴”伪影，提高了对姿势和表情的可控性，并保持了强大的感知质量。用户研究验证了该方法在高身份保真度的同时，实现了富有表现力的可控生成。

Conclusion: WithAnyone通过新颖的数据集、基准和训练范式，成功解决了文本到图像生成中的“复制粘贴”问题，实现了身份保真度和多样性的良好平衡，为生成具有高可控性和表现力的身份相关图像提供了有效方案。

Abstract: Identity-consistent generation has become an important focus in text-to-image
research, with recent models achieving notable success in producing images
aligned with a reference identity. Yet, the scarcity of large-scale paired
datasets containing multiple images of the same individual forces most
approaches to adopt reconstruction-based training. This reliance often leads to
a failure mode we term copy-paste, where the model directly replicates the
reference face rather than preserving identity across natural variations in
pose, expression, or lighting. Such over-similarity undermines controllability
and limits the expressive power of generation. To address these limitations, we
(1) construct a large-scale paired dataset MultiID-2M, tailored for
multi-person scenarios, providing diverse references for each identity; (2)
introduce a benchmark that quantifies both copy-paste artifacts and the
trade-off between identity fidelity and variation; and (3) propose a novel
training paradigm with a contrastive identity loss that leverages paired data
to balance fidelity with diversity. These contributions culminate in
WithAnyone, a diffusion-based model that effectively mitigates copy-paste while
preserving high identity similarity. Extensive qualitative and quantitative
experiments demonstrate that WithAnyone significantly reduces copy-paste
artifacts, improves controllability over pose and expression, and maintains
strong perceptual quality. User studies further validate that our method
achieves high identity fidelity while enabling expressive controllable
generation.

</details>


### [97] [Terra: Explorable Native 3D World Model with Point Latents](https://arxiv.org/abs/2510.14977)
*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Xin Tao,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Terra是一个原生3D世界模型，使用P2G-VAE编码3D输入到3D高斯原语的潜在点表示，并使用SPFlow网络生成该表示，实现了精确的多视图一致性、灵活的渲染和可探索的世界建模。


<details>
  <summary>Details</summary>
Motivation: 现有的世界模型主要基于像素对齐表示，忽略了物理世界的3D特性，这可能影响3D一致性和建模效率。

Method: 提出了一种新颖的点到高斯变分自编码器（P2G-VAE），将3D输入编码为潜在点表示，并将其解码为3D高斯原语，以联合建模几何和外观。然后引入了稀疏点流匹配网络（SPFlow）来生成潜在点表示，同时对点潜在位置和特征进行去噪。

Result: Terra实现了精确的多视图一致性，具有原生的3D表示和架构，并且可以通过单一生成过程从任何视点进行灵活渲染。在ScanNet v2数据集的室内场景上进行了广泛的实验，Terra在重建和生成方面都达到了最先进的性能，并具有高3D一致性。

Conclusion: Terra是一个原生3D世界模型，通过其创新的P2G-VAE和SPFlow网络，在3D一致性、渲染灵活性和建模效率方面超越了现有方法，并在室内场景重建和生成任务上取得了最先进的成果。

Abstract: World models have garnered increasing attention for comprehensive modeling of
the real world. However, most existing methods still rely on pixel-aligned
representations as the basis for world evolution, neglecting the inherent 3D
nature of the physical world. This could undermine the 3D consistency and
diminish the modeling efficiency of world models. In this paper, we present
Terra, a native 3D world model that represents and generates explorable
environments in an intrinsic 3D latent space. Specifically, we propose a novel
point-to-Gaussian variational autoencoder (P2G-VAE) that encodes 3D inputs into
a latent point representation, which is subsequently decoded as 3D Gaussian
primitives to jointly model geometry and appearance. We then introduce a sparse
point flow matching network (SPFlow) for generating the latent point
representation, which simultaneously denoises the positions and features of the
point latents. Our Terra enables exact multi-view consistency with native 3D
representation and architecture, and supports flexible rendering from any
viewpoint with only a single generation process. Furthermore, Terra achieves
explorable world modeling through progressive generation in the point latent
space. We conduct extensive experiments on the challenging indoor scenes from
ScanNet v2. Terra achieves state-of-the-art performance in both reconstruction
and generation with high 3D consistency.

</details>


### [98] [Learning an Image Editing Model without Image Editing Pairs](https://arxiv.org/abs/2510.14978)
*Nupur Kumari,Sheng-Yu Wang,Nanxuan Zhao,Yotam Nitzan,Yuheng Li,Krishna Kumar Singh,Richard Zhang,Eli Shechtman,Jun-Yan Zhu,Xun Huang*

Main category: cs.CV

TL;DR: 该方法无需配对数据即可进行图像编辑，通过 VLM 反馈进行优化，并使用 DMD 损失来确保视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编辑模型需要大量配对数据进行监督微调，这难以大规模收集。合成数据会放大预训练模型的伪影。因此，需要一种无需配对数据即可进行图像编辑的训练范式。

Method: 通过展开几步扩散模型并在训练期间利用视觉-语言模型（VLM）的反馈来直接优化模型。VLM 评估编辑是否遵循指令并保留未更改的内容，提供直接梯度进行端到端优化。结合分布匹配损失（DMD）来约束生成图像，使其保持在预训练模型所学的图像流形内。

Result: 在标准基准上，该方法在无需配对数据的情况下，在几步设置下，其性能与在大量监督配对数据上训练的各种图像编辑扩散模型相当。与基于强化学习的技术（如 Flow-GRPO）相比，在相同的 VLM 作为奖励模型的情况下，该方法表现更优。

Conclusion: 该方法成功地开发了一种无需配对数据即可进行图像编辑的训练范式，在性能上可与现有方法相媲美，甚至超越某些方法。

Abstract: Recent image editing models have achieved impressive results while following
natural language editing instructions, but they rely on supervised fine-tuning
with large datasets of input-target pairs. This is a critical bottleneck, as
such naturally occurring pairs are hard to curate at scale. Current workarounds
use synthetic training pairs that leverage the zero-shot capabilities of
existing models. However, this can propagate and magnify the artifacts of the
pretrained model into the final trained model. In this work, we present a new
training paradigm that eliminates the need for paired data entirely. Our
approach directly optimizes a few-step diffusion model by unrolling it during
training and leveraging feedback from vision-language models (VLMs). For each
input and editing instruction, the VLM evaluates if an edit follows the
instruction and preserves unchanged content, providing direct gradients for
end-to-end optimization. To ensure visual fidelity, we incorporate distribution
matching loss (DMD), which constrains generated images to remain within the
image manifold learned by pretrained models. We evaluate our method on standard
benchmarks and include an extensive ablation study. Without any paired data,
our method performs on par with various image editing diffusion models trained
on extensive supervised paired data, under the few-step setting. Given the same
VLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.

</details>


### [99] [From Pixels to Words -- Towards Native Vision-Language Primitives at Scale](https://arxiv.org/abs/2510.14979)
*Haiwen Diao,Mingxuan Li,Silei Wu,Linjun Dai,Xiaohua Wang,Hanming Deng,Lewei Lu,Dahua Lin,Ziwei Liu*

Main category: cs.CV

TL;DR: 原生VLM在模型结构和训练范式上与传统模块化VLM不同，但存在探索和推广的障碍，本文提出了解决这些挑战的原则并发布了名为NEO的原生VLM。


<details>
  <summary>Details</summary>
Motivation: 原生VLM的探索和推广面临两大挑战：1. 原生VLM与模块化VLM在基本约束上的区别及克服这些障碍的程度。2. 如何使原生VLM的研究更易于获取和普及，从而加速该领域的进步。

Method: 本文提出了构建原生VLM的指导原则，包括：1. 有效地在共享语义空间中对齐像素和词语表示。2. 无缝集成先前独立视觉和语言模块的优势。3. 内在地体现支持统一视觉-语言编码、对齐和推理的各种跨模态属性。在此基础上，我们提出了名为NEO的新型原生VLM。

Result: NEO在真实世界的各种场景中，能够与顶级的模块化VLM相媲美。仅使用390M图像-文本示例，NEO就能从头开始有效地开发视觉感知能力，同时在一个由精心设计的基元构建的密集、单一模型中减轻视觉-语言冲突。

Conclusion: NEO被定位为可扩展且强大的原生VLM的基石，并配有一套丰富的可重用组件，以促进成本效益高且可扩展的生态系统。代码和模型已公开。

Abstract: The edifice of native Vision-Language Models (VLMs) has emerged as a rising
contender to typical modular VLMs, shaped by evolving model architectures and
training paradigms. Yet, two lingering clouds cast shadows over its widespread
exploration and promotion: (-) What fundamental constraints set native VLMs
apart from modular ones, and to what extent can these barriers be overcome? (-)
How to make research in native VLMs more accessible and democratized, thereby
accelerating progress in the field. In this paper, we clarify these challenges
and outline guiding principles for constructing native VLMs. Specifically, one
native VLM primitive should: (i) effectively align pixel and word
representations within a shared semantic space; (ii) seamlessly integrate the
strengths of formerly separate vision and language modules; (iii) inherently
embody various cross-modal properties that support unified vision-language
encoding, aligning, and reasoning. Hence, we launch NEO, a novel family of
native VLMs built from first principles, capable of rivaling top-tier modular
counterparts across diverse real-world scenarios. With only 390M image-text
examples, NEO efficiently develops visual perception from scratch while
mitigating vision-language conflicts inside a dense and monolithic model
crafted from our elaborate primitives. We position NEO as a cornerstone for
scalable and powerful native VLMs, paired with a rich set of reusable
components that foster a cost-effective and extensible ecosystem. Our code and
models are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.

</details>


### [100] [Coupled Diffusion Sampling for Training-Free Multi-View Image Editing](https://arxiv.org/abs/2510.14981)
*Hadi Alzayer,Yunzhi Zhang,Chen Geng,Jia-Bin Huang,Jiajun Wu*

Main category: cs.CV

TL;DR: 提出一种推理时扩散采样方法，用于使用预训练的2D图像编辑模型执行多视图一致的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图一致性图像编辑方法通常通过在显式3D表示上进行优化来实现，但存在优化过程冗长和在稀疏视图设置下不稳定等问题。

Method: 提出一种隐式3D正则化方法，通过约束生成的2D图像序列以遵循预训练的多视图图像分布，并引入耦合扩散采样技术，同时从多视图图像分布和2D编辑图像分布中采样，并使用耦合项来强制生成图像间的多视图一致性。

Result: 该框架在三个不同的多视图图像编辑任务上得到了验证，证明了其在各种模型架构上的有效性和通用性。

Conclusion: 所提出的方法可以作为多视图一致性编辑的通用解决方案。

Abstract: We present an inference-time diffusion sampling method to perform multi-view
consistent image editing using pre-trained 2D image editing models. These
models can independently produce high-quality edits for each image in a set of
multi-view images of a 3D scene or object, but they do not maintain consistency
across views. Existing approaches typically address this by optimizing over
explicit 3D representations, but they suffer from a lengthy optimization
process and instability under sparse view settings. We propose an implicit 3D
regularization approach by constraining the generated 2D image sequences to
adhere to a pre-trained multi-view image distribution. This is achieved through
coupled diffusion sampling, a simple diffusion sampling technique that
concurrently samples two trajectories from both a multi-view image distribution
and a 2D edited image distribution, using a coupling term to enforce the
multi-view consistency among the generated images. We validate the
effectiveness and generality of this framework on three distinct multi-view
image editing tasks, demonstrating its applicability across various model
architectures and highlighting its potential as a general solution for
multi-view consistent editing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [101] [Bridging the Semantic Gap: Contrastive Rewards for Multilingual Text-to-SQL](https://arxiv.org/abs/2510.13827)
*Ashish Kattamuri,Ishita Prasad,Meetu Malhotra,Arpita Vats,Rahul Raja,Albert Lie*

Main category: cs.CL

TL;DR: 当前文本到SQL方法主要关注可执行查询，忽略了语义对齐和跨语言执行准确性问题。本研究提出了一种结合组相对策略优化（GRPO）和多语言对比奖励信号的新框架，以提高Text-to-SQL系统在跨语言场景下的任务效率和语义准确性。


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL方法在评估中过度关注可执行查询，忽略了查询的语义对齐和执行结果的正确性。此外，从英语转向其他语言时，执行准确性会显著下降（平均下降6个百分点）。

Method: 本研究提出了一种新框架，将组相对策略优化（GRPO）与多语言对比奖励信号相结合，以提高Text-to-SQL系统在跨语言场景下的任务效率和语义准确性。该方法通过结合基于语义相似度的奖励信号，教会模型更好地匹配SQL生成与用户意图。

Result: 在七语言MultiSpider数据集上，使用GRPO微调LLaMA-3-3B模型，执行准确率最高可达87.4%（比零样本提高26个百分点），语义准确率最高可达52.29%（提高32.86个百分点）。加入对比奖励信号后，平均语义准确率进一步提高到59.14%（提高6.85个百分点，越南语最高提高10个百分点）。一个经过对比奖励信号微调的3B LLaMA模型，其性能优于更大的8B LLaMA零样本模型，执行准确率（88.86% vs 81.43%）和语义准确率（59.14% vs 68.57%）均有显著提升，且仅使用了3000个强化学习训练样本。

Conclusion: 研究结果表明，通过使用对比奖励进行定向语义对齐，可以在不依赖大规模训练数据集的情况下，显著提升Text-to-SQL系统的性能。

Abstract: Current Text-to-SQL methods are evaluated and only focused on executable
queries, overlooking the semantic alignment challenge -- both in terms of the
semantic meaning of the query and the correctness of the execution results.
Even execution accuracy itself shows significant drops when moving from English
to other languages, with an average decline of 6 percentage points across
non-English languages. We address these challenges by presenting a new
framework that combines Group Relative Policy Optimization (GRPO) within a
multilingual contrastive reward signal to enhance both task efficiency and
semantic accuracy in Text-to-SQL systems in cross-lingual scenarios. Our method
teaches models to obtain better correspondence between SQL generation and user
intent by combining a reward signal based on semantic similarity. On the
seven-language MultiSpider dataset, fine-tuning the LLaMA-3-3B model with GRPO
improved the execution accuracy up to 87.4 percent (+26 pp over zero-shot) and
semantic accuracy up to 52.29 percent (+32.86 pp). Adding our contrastive
reward signal in the GRPO framework further improved the average semantic
accuracy to 59.14 percent (+6.85 pp, up to +10 pp for Vietnamese). Our
experiments showcase that a smaller, parameter-efficient 3B LLaMA model
fine-tuned with our contrastive reward signal outperforms a much larger
zero-shot 8B LLaMA model, with an uplift of 7.43 pp in execution accuracy (from
81.43 percent on the 8B model to 88.86 percent on the 3B model), and nearly
matches its semantic accuracy (59.14 percent vs. 68.57 percent) -- all using
just 3,000 reinforcement learning training examples. These results demonstrate
how we can improve the performance of Text-to-SQL systems with contrastive
rewards for directed semantic alignment, without requiring large-scale training
datasets.

</details>


### [102] [From Explainability to Action: A Generative Operational Framework for Integrating XAI in Clinical Mental Health Screening](https://arxiv.org/abs/2510.13828)
*Ratna Kandala,Akshata Kishore Moharir,Divya Arvinda Nayak*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Explainable Artificial Intelligence (XAI) has been presented as the critical
component for unlocking the potential of machine learning in mental health
screening (MHS). However, a persistent lab-to-clinic gap remains. Current XAI
techniques, such as SHAP and LIME, excel at producing technically faithful
outputs such as feature importance scores, but fail to deliver clinically
relevant, actionable insights that can be used by clinicians or understood by
patients. This disconnect between technical transparency and human utility is
the primary barrier to real-world adoption. This paper argues that this gap is
a translation problem and proposes the Generative Operational Framework, a
novel system architecture that leverages Large Language Models (LLMs) as a
central translation engine. This framework is designed to ingest the raw,
technical outputs from diverse XAI tools and synthesize them with clinical
guidelines (via RAG) to automatically generate human-readable, evidence-backed
clinical narratives. To justify our solution, we provide a systematic analysis
of the components it integrates, tracing the evolution from intrinsic models to
generative XAI. We demonstrate how this framework directly addresses key
operational barriers, including workflow integration, bias mitigation, and
stakeholder-specific communication. This paper also provides a strategic
roadmap for moving the field beyond the generation of isolated data points
toward the delivery of integrated, actionable, and trustworthy AI in clinical
practice.

</details>


### [103] [Seeing Hate Differently: Hate Subspace Modeling for Culture-Aware Hate Speech Detection](https://arxiv.org/abs/2510.13837)
*Weibin Cai,Reza Zafarani*

Main category: cs.CL

TL;DR: 现有hate speech检测方法忽略了训练标签偏见和跨文化解释差异的现实问题。本文提出了一种文化感知框架，通过构建个体hate子空间来解决数据稀疏、文化纠缠和标签模糊等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有hate speech检测方法未能解决训练标签偏见和跨文化解释差异的现实问题。

Method: 提出了一种文化感知框架，通过对文化属性进行组合建模来缓解数据稀疏问题，并利用标签传播来捕捉每个组合的独特特征，从而构建个体hate子空间。

Result: 所提出的框架在分类性能上优于现有方法，在所有指标上的平均性能提升了1.05%。

Conclusion: 本文提出的文化感知框架通过构建个体hate子空间，有效解决了hate speech检测中的标签偏见和跨文化解释差异问题，并提升了检测性能。

Abstract: Hate speech detection has been extensively studied, yet existing methods
often overlook a real-world complexity: training labels are biased, and
interpretations of what is considered hate vary across individuals with
different cultural backgrounds. We first analyze these challenges, including
data sparsity, cultural entanglement, and ambiguous labeling. To address them,
we propose a culture-aware framework that constructs individuals' hate
subspaces. To alleviate data sparsity, we model combinations of cultural
attributes. For cultural entanglement and ambiguous labels, we use label
propagation to capture distinctive features of each combination. Finally,
individual hate subspaces, which in turn can further enhance classification
performance. Experiments show our method outperforms state-of-the-art by 1.05\%
on average across all metrics.

</details>


### [104] [A Linguistics-Aware LLM Watermarking via Syntactic Predictability](https://arxiv.org/abs/2510.13829)
*Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.CL

TL;DR: LLM 水印技术需要解决文本质量和检测鲁棒性之间的平衡问题。现有的方法依赖模型输出的特定信号，阻碍了公开验证。STELA 框架通过利用语言固有的自由度来动态调整水印强度，在语法约束强的语境下减弱水印以保证质量，在语言灵活的语境下增强水印以提高可检测性。STELA 的检测器无需访问模型 logits，实现了公开可验证的检测。实验表明，STELA 在不同类型的语言上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 水印方法在文本质量和检测鲁棒性之间存在权衡，并且通常依赖于模型特定的信号（如 logits），这阻碍了公开验证。因此，需要一种能够在不牺牲文本质量的情况下提供鲁棒且可公开验证的水印方法。

Method: STELA 框架通过分析词性（POS）n-gram 来量化语言的“不确定性”或“自由度”。它根据这种不确定性动态调整水印的强度：在语法约束性强的语境下（不确定性低），水印强度减弱以保持文本质量；在语言表达更灵活的语境下（不确定性高），水印强度增强以提高可检测性。该方法的检测器不依赖于任何模型 logits，从而实现了公开可验证性。

Result: 通过在英语、中文和韩语等不同类型的语言上进行的大量实验，STELA 在检测鲁棒性方面优于现有方法。

Conclusion: STELA 是一种新颖的水印框架，它通过利用语言的固有自由度来平衡文本质量和检测鲁棒性，并且其检测器无需访问模型 logits，实现了公开可验证的检测。

Abstract: As large language models (LLMs) continue to advance rapidly, reliable
governance tools have become critical. Publicly verifiable watermarking is
particularly essential for fostering a trustworthy AI ecosystem. A central
challenge persists: balancing text quality against detection robustness. Recent
studies have sought to navigate this trade-off by leveraging signals from model
output distributions (e.g., token-level entropy); however, their reliance on
these model-specific signals presents a significant barrier to public
verification, as the detection process requires access to the logits of the
underlying model. We introduce STELA, a novel framework that aligns watermark
strength with the linguistic degrees of freedom inherent in language. STELA
dynamically modulates the signal using part-of-speech (POS) n-gram-modeled
linguistic indeterminacy, weakening it in grammatically constrained contexts to
preserve quality and strengthen it in contexts with greater linguistic
flexibility to enhance detectability. Our detector operates without access to
any model logits, thus facilitating publicly verifiable detection. Through
extensive experiments on typologically diverse languages-analytic English,
isolating Chinese, and agglutinative Korean-we show that STELA surpasses prior
methods in detection robustness. Our code is available at
https://github.com/Shinwoo-Park/stela_watermark.

</details>


### [105] [Users as Annotators: LLM Preference Learning from Comparison Mode](https://arxiv.org/abs/2510.13830)
*Zhongze Cai,Xiaocheng Li*

Main category: cs.CL

TL;DR: 收集和过滤用户标注的偏好数据以对齐LLM。


<details>
  <summary>Details</summary>
Motivation: LLM对齐中，使用用户标注的偏好数据作为替代方案，以应对专业标注的成本和规模问题。

Method: 提出一种用户行为模型，通过生成两个不同模型或同一模型的不同版本的响应，并利用用户标注的偏好数据，通过期望最大化算法估计用户的潜在质量因子，并相应地过滤用户标注数据。

Result: 下游任务表明该方法在捕捉用户行为和数据过滤以对齐LLM方面是有效的。

Conclusion: 用户标注的偏好数据可以作为一种有价值的资源，通过用户行为模型进行质量控制和过滤，从而有效地用于LLM对齐。

Abstract: Pairwise preference data have played an important role in the alignment of
large language models (LLMs). Each sample of such data consists of a prompt,
two different responses to the prompt, and a binary label indicating which of
the two responses is better. The labels are usually annotated by professional
human annotators. In this paper, we consider an alternative approach to collect
pairwise preference data -- user annotation from comparison mode. With the
increasingly wider adoption of LLMs among the population, users are
contributing more and more of their preference labels through their daily
interactions with the LLMs. The upside of such labels is that users are the
best experts in judging the responses to their own queries/prompts, but the
downside is the lack of quality control in these labels. In this paper, we
consider a new idea of generating two responses from two different models or
two different versions of the same model. The asymmetry allows us to make an
inference of the user's data quality through our proposed user behavior model.
We develop an expectation-maximization algorithm to estimate a latent quality
factor of the user, and filter users' annotation data accordingly. The
downstream task shows the effectiveness of our approach in both capturing the
user behavior and data filtering for LLM alignment.

</details>


### [106] [Informed Routing in LLMs: Smarter Token-Level Computation for Faster Inference](https://arxiv.org/abs/2510.13831)
*Chao Han,Yijuan Liang,Zihao Xuan,Daokuan Wu,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 通过引入“信息式路由”和“轻量级特征预测器”（LFF）来提高大语言模型的推理效率，该方法通过预测代币的可恢复性来优化计算分配，从而在保持模型性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在实际应用中因高昂的推理成本而受到限制。先前基于动态代币级计算分配的方法依赖于贪婪路由，这种“短视”的机制会导致信息丢失和次优的代币选择。

Method: 提出了一种名为“信息式路由”的新范式，它通过评估代币的即时重要性及其可恢复性（即其转换的可近似程度）来解决上述问题。为此，引入了“轻量级特征预测器”（LFF）模块，在进行路由决策之前，预测某个单元的输出。这使得能够实施灵活的“执行或近似”策略。

Result: 在语言建模和推理任务上的大量实验表明，“信息式路由”在多个稀疏级别上实现了最先进的效率-性能权衡。值得注意的是，即使没有最终的 LoRA 微调，该方法也能匹配或超越需要完全微调的强基线模型，同时将训练时间缩短了 50% 以上。

Conclusion: “信息式路由”是一种提高大语言模型效率的新范式，它通过考虑代币的可恢复性来优化计算分配，在不牺牲性能的情况下显著降低了计算成本和训练时间。

Abstract: The deployment of large language models (LLMs) in real-world applications is
increasingly limited by their high inference cost. While recent advances in
dynamic token-level computation allocation attempt to improve efficiency by
selectively activating model components per token, existing methods rely on
greedy routing--a myopic execute-or-skip mechanism that often leads to
irreversible information loss and suboptimal token selection. This paper
introduces informed routing, a new paradigm that proactively addresses these
issues. The key insight is to assess not only a token's immediate importance
but also its recoverability, i.e., how well its transformation can be
approximated. To this end, we propose the Lightweight Feature Forecaster (LFF),
a small predictive module that estimates a unit's output before routing
decisions are made. This enables a flexible execute-or-approximate policy that
preserves model fidelity while drastically reducing computation. Extensive
experiments on both language modeling and reasoning tasks show that informed
routing achieves state-of-the-art efficiency-performance trade-offs across
multiple sparsity levels. Notably, even without final LoRA fine-tuning, our
method matches or surpasses strong baselines that require full fine-tuning, all
while reducing training time by over 50%. The code is available at:
https://github.com/EIT-NLP/informed-routing

</details>


### [107] [Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable and Efficient Transformer Pruning](https://arxiv.org/abs/2510.13832)
*Minsik Choi,Hyegang Son,Changhoon Kim,Young Geun Kim*

Main category: cs.CL

TL;DR: Transformer模型在NLP任务中表现出色，但存在效率问题。HIS剪枝方法虽有优势但有局限性。本文提出HIES（Head Importance-Entropy Score），结合了重要性分数和注意力熵，在模型压缩方面取得了显著的性能和稳定性提升。


<details>
  <summary>Details</summary>
Motivation: Transformer模型因其多层和多注意力头的结构，在推理和部署方面存在效率挑战。现有的基于梯度的剪枝方法（如HIS）虽然可以识别冗余的注意力头，但仅考虑了梯度驱动的贡献，忽略了注意力模式的多样性。

Method: 提出了一种新的剪枝标准HIES（Head Importance-Entropy Score），该方法将注意力的重要性分数与注意力熵相结合，为每个头的贡献提供了互补的证据。

Result: 与单独使用HIS的方法相比，基于HIES的剪枝在模型质量方面提高了15.2%，在稳定性方面提高了2.04倍，实现了显著的模型压缩，同时没有牺牲准确性或稳定性。

Conclusion: HIES是一种有效的剪枝标准，能够在不牺牲准确性和稳定性的前提下实现Transformer模型的显著压缩。

Abstract: Transformer-based models have achieved remarkable performance in NLP tasks.
However, their structural characteristics-multiple layers and attention
heads-introduce efficiency challenges in inference and deployment. To address
these challenges, various pruning methods have recently been proposed. Notably,
gradient-based methods using Head Importance Scores (HIS) have gained traction
for interpretability, efficiency, and ability to identify redundant heads.
However, HIS alone has limitations as it captures only the gradient-driven
contribution, overlooking the diversity of attention patterns. To overcome
these limitations, we introduce a novel pruning criterion, HIES (Head
Importance-Entropy Score), which integrates head importance scores with
attention entropy, providing complementary evidence on per-head contribution.
Empirically, HIES-based pruning yields up to 15.2% improvement in model quality
and 2.04x improvement in stability over HIS-only methods, enabling substantial
model compression without sacrificing either accuracy or stability. Code will
be released upon publication.

</details>


### [108] [ConDABench: Interactive Evaluation of Language Models for Data Analysis](https://arxiv.org/abs/2510.13835)
*Avik Dutta,Priyanshu Gupta,Hosein Hasanbeig,Rahul Pratap Singh,Harshit Nigam,Sumit Gulwani,Arjun Radhakrishna,Gustavo Soares,Ashish Tiwari*

Main category: cs.CL

TL;DR: ConDABench是一个包含1420个对话式数据分析问题的框架，用于评估外部工具和大型语言模型在处理复杂、交互式数据分析任务方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据分析任务目标不明确，数据不干净，需要用户交互来理解用户意图。现有基准测试无法满足这些复杂性或支持交互性。

Method: 使用多代理工作流从公开数据集的分析文章中生成逼真的基准测试，并创建一个评估工具来系统地评估对话式数据分析工具。

Result: 生成了1420个ConDA问题，并评估了当前最先进的大型语言模型，发现它们在解决更多问题方面有所改进，但在需要长期协作的任务上没有显著提升。

Conclusion: ConDABench为模型开发者提供了一个衡量在构建真正协作式模型方面的进展的途径，这些模型能够完成复杂的交互式任务。

Abstract: Real-world data analysis tasks often come with under-specified goals and
unclean data. User interaction is necessary to understand and disambiguate a
user's intent, and hence, essential to solving these complex tasks. Existing
benchmarks for evaluating LLMs on data analysis tasks do not capture these
complexities or provide first-class support for interactivity. We introduce
ConDABench, a framework for generating conversational data analysis (ConDA)
benchmarks and evaluating external tools on the generated benchmarks. \bench
consists of (a) a multi-agent workflow for generating realistic benchmarks from
articles describing insights gained from public datasets, (b) 1,420 ConDA
problems generated using this workflow, and (c) an evaluation harness that, for
the first time, makes it possible to systematically evaluate conversational
data analysis tools on the generated ConDA problems. Evaluation of
state-of-the-art LLMs on the benchmarks reveals that while the new generation
of models are better at solving more instances, they are not necessarily better
at solving tasks that require sustained, long-form engagement. ConDABench is an
avenue for model builders to measure progress towards truly collaborative
models that can complete complex interactive tasks.

</details>


### [109] [From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR](https://arxiv.org/abs/2510.14871)
*Erwei Wang,Samuel Bayliss,Andra Bisca,Zachary Blair,Sangeeta Chowdhary,Kristof Denolf,Jeff Fifield,Brandon Freiberger,Erika Hunhoff,Phil James-Roxby,Jack Lo,Joseph Melber,Stephen Neuendorffer,Eddie Richter,Andre Rosti,Javier Setoain,Gagandeep Singh,Endri Taka,Pranathi Vasireddy,Zhewen Yu,Niansong Zhang,Jinming Zhuang*

Main category: cs.CL

TL;DR: MLIR-AIR是一个新的开源编译器栈，它使用MLIR来弥合高级工作负载和AMD NPU等细粒度空间架构之间的语义差距。它通过AIR方言提供异步和分层操作的结构化表示，从而实现空间调度、跨硬件区域的计算分发以及通信与计算的重叠，而无需临时的运行时协调或手动调度。


<details>
  <summary>Details</summary>
Motivation: 现代计算架构越来越依赖于对数据移动、执行顺序和计算放置进行细粒度控制以获得性能，因此编译器基础设施必须提供显式机制来协调计算和数据，以充分利用这些架构。

Method: MLIR-AIR通过AIR方言定义了用于异步和分层操作的结构化表示，使编译器能够实现空间调度、跨硬件区域的计算分发以及通信与计算的重叠。

Result: 在矩阵乘法方面，MLIR-AIR实现了高达78.7%的计算效率，其性能几乎与使用较低级别的MLIR-AIE框架手动优化的实现相同。在多头注意力方面，AIR接口支持使用约150行代码进行融合实现，从而能够用高效映射到空间硬件的方式来清晰地表达复杂的工作负载。

Conclusion: MLIR-AIR将高级结构化控制流转换为空间程序，通过编译器管理的调度利用异步执行、分块和通信重叠，从而有效地利用NPU的计算结构和内存层次结构。

Abstract: General-purpose compilers abstract away parallelism, locality, and
synchronization, limiting their effectiveness on modern spatial architectures.
As modern computing architectures increasingly rely on fine-grained control
over data movement, execution order, and compute placement for performance,
compiler infrastructure must provide explicit mechanisms for orchestrating
compute and data to fully exploit such architectures. We introduce MLIR-AIR, a
novel, open-source compiler stack built on MLIR that bridges the semantic gap
between high-level workloads and fine-grained spatial architectures such as
AMD's NPUs. MLIR-AIR defines the AIR dialect, which provides structured
representations for asynchronous and hierarchical operations across compute and
memory resources. AIR primitives allow the compiler to orchestrate spatial
scheduling, distribute computation across hardware regions, and overlap
communication with computation without relying on ad hoc runtime coordination
or manual scheduling. We demonstrate MLIR-AIR's capabilities through two case
studies: matrix multiplication and the multi-head attention block from the
LLaMA 2 model. For matrix multiplication, MLIR-AIR achieves up to 78.7% compute
efficiency and generates implementations with performance almost identical to
state-of-the-art, hand-optimized matrix multiplication written using the
lower-level, close-to-metal MLIR-AIE framework. For multi-head attention, we
demonstrate that the AIR interface supports fused implementations using
approximately 150 lines of code, enabling tractable expression of complex
workloads with efficient mapping to spatial hardware. MLIR-AIR transforms
high-level structured control flow into spatial programs that efficiently
utilize the compute fabric and memory hierarchy of an NPU, leveraging
asynchronous execution, tiling, and communication overlap through
compiler-managed scheduling.

</details>


### [110] [SIMBA UQ: Similarity-Based Aggregation for Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2510.13836)
*Debarun Bhattacharjya,Balaji Ganesan,Junkyu Lee,Radu Marinescu,Katsiaryna Mirylenka,Michael Glass,Xiao Shou*

Main category: cs.CL

TL;DR: 研究了在生成大型语言模型（LLM）时，如何量化其不确定性，并提出了一种基于非言语化相似度的聚合框架，该框架能够提高模型在各种任务中的置信度校准能力。


<details>
  <summary>Details</summary>
Motivation: 不确定性量化（UQ）对于建立可信赖的AI系统至关重要，但现有方法通常需要访问LLM的内部信息。本文旨在探索不需要访问模型内部信息的黑盒UQ方法，以解决其在实际应用中的优势。

Method: 提出了一种基于非言语化相似度的聚合框架，该框架将生成输出与其他采样生成之间的一致性作为正确性置信度的代理。该框架能够包含多种UQ方法，并提出了一些新的技术，利用小的训练集来训练置信度估计模型。

Result: 通过在问答、文本摘要和文本到SQL等多样化任务上的实证研究，证明所提出的基于相似度的方法比基线方法能够提供更好的置信度校准。

Conclusion: 基于相似度的UQ方法在各种生成任务中表现出优越性，能够提供更准确的置信度估计，并且不需要访问LLM的内部信息，具有广泛的应用前景。

Abstract: When does a large language model (LLM) know what it does not know?
Uncertainty quantification (UQ) provides measures of uncertainty, such as an
estimate of the confidence in an LLM's generated output, and is therefore
increasingly recognized as a crucial component of trusted AI systems. Black-box
UQ methods do not require access to internal model information from the
generating LLM and therefore have numerous real-world advantages, such as
robustness to system changes, adaptability to choice of LLM, reduced costs, and
computational tractability. In this paper, we investigate the effectiveness of
UQ techniques that are primarily but not necessarily entirely black-box, where
the consistency between a generated output and other sampled generations is
used as a proxy for confidence in its correctness. We propose a high-level
non-verbalized similarity-based aggregation framework that subsumes a broad
swath of UQ approaches suitable for complex generative tasks, as well as
introduce specific novel techniques from the framework that train confidence
estimation models using small training sets. Through an empirical study with
datasets spanning the diverse tasks of question answering, summarization, and
text-to-SQL, we demonstrate that our proposed similarity-based methods can
yield better calibrated confidences than baselines.

</details>


### [111] [Meronymic Ontology Extraction via Large Language Models](https://arxiv.org/abs/2510.13839)
*Dekai Zhang,Simone Conia,Antonio Rago*

Main category: cs.CL

TL;DR: 本研究利用大型语言模型（LLMs）自动化提取产品本体（meronymies），并证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手动构建本体耗时费力，需要自动化方法来解决此问题，特别是在电子商务等需要组织大量产品列表的领域。

Method: 利用大型语言模型的最新进展，开发一种从原始评论文本中提取产品本体（meronymies）的全自动化方法。

Result: 使用LLM作为裁判进行评估，本研究提出的方法所生成的产品本体优于现有的、基于BERT的基线方法。

Conclusion: 本研究为LLMs在（产品或其他）本体提取中更广泛的应用奠定了基础。

Abstract: Ontologies have become essential in today's digital age as a way of
organising the vast amount of readily available unstructured text. In providing
formal structure to this information, ontologies have immense value and
application across various domains, e.g., e-commerce, where countless product
listings necessitate proper product organisation. However, the manual
construction of these ontologies is a time-consuming, expensive and laborious
process. In this paper, we harness the recent advancements in large language
models (LLMs) to develop a fully-automated method of extracting product
ontologies, in the form of meronymies, from raw review texts. We demonstrate
that the ontologies produced by our method surpass an existing, BERT-based
baseline when evaluating using an LLM-as-a-judge. Our investigation provides
the groundwork for LLMs to be used more generally in (product or otherwise)
ontology extraction.

</details>


### [112] [ADMIT: Few-shot Knowledge Poisoning Attacks on RAG-based Fact Checking](https://arxiv.org/abs/2510.13842)
*Yutao Wu,Xiao Liu,Yinghui Li,Yifeng Gao,Yifan Ding,Jiale Ding,Xiang Zheng,Xingjun Ma*

Main category: cs.CL

TL;DR: 知识投毒对检索增强生成（RAG）系统构成严重威胁，尤其是在事实核查场景下。研究提出了ADMIT（对抗性多重注入技术），一种能够有效翻转事实核查决策并产生误导性理由的少样本、语义对齐的攻击方法，即使在目标模型和检索器未知的情况下也能实现高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究关注到大型语言模型（LLMs）容易受到误导性检索内容的影响，但在现实世界的事实核查场景中，由于检索池中通常充斥着大量真实可信的证据，问题更具挑战性。本研究旨在扩展知识投毒至事实核查场景，研究在包含真实支持或反驳证据的情况下，如何进行有效的攻击。

Method: 提出了一种名为ADMIT（对抗性多重注入技术）的方法。该方法是一种少样本、语义对齐的攻击技术，能够在无需访问目标LLM、检索器或进行令牌级控制的情况下，翻转事实核查的决策并诱导产生欺骗性的解释。

Result: ADMIT在4个检索器、11个LLM和4个跨领域基准测试中表现出良好的迁移性。在极低的投毒率（$0.93 	imes 10^{-6}$）下，平均攻击成功率（ASR）达到86%，并且在存在强力反驳证据的情况下依然保持鲁棒性。与现有最先进的攻击方法相比，ADMIT在所有设置下的ASR平均提高了11.2%。

Conclusion: ADMIT攻击的有效性揭示了当前基于RAG的事实核查系统存在严重漏洞。研究表明，即使在检索池中存在大量真实证据的情况下，该攻击技术也能成功地操纵LLM做出错误的判断并生成虚假解释。

Abstract: Knowledge poisoning poses a critical threat to Retrieval-Augmented Generation
(RAG) systems by injecting adversarial content into knowledge bases, tricking
Large Language Models (LLMs) into producing attacker-controlled outputs
grounded in manipulated context. Prior work highlights LLMs' susceptibility to
misleading or malicious retrieved content. However, real-world fact-checking
scenarios are more challenging, as credible evidence typically dominates the
retrieval pool. To investigate this problem, we extend knowledge poisoning to
the fact-checking setting, where retrieved context includes authentic
supporting or refuting evidence. We propose \textbf{ADMIT}
(\textbf{AD}versarial \textbf{M}ulti-\textbf{I}njection \textbf{T}echnique), a
few-shot, semantically aligned poisoning attack that flips fact-checking
decisions and induces deceptive justifications, all without access to the
target LLMs, retrievers, or token-level control. Extensive experiments show
that ADMIT transfers effectively across 4 retrievers, 11 LLMs, and 4
cross-domain benchmarks, achieving an average attack success rate (ASR) of 86\%
at an extremely low poisoning rate of $0.93 \times 10^{-6}$, and remaining
robust even in the presence of strong counter-evidence. Compared with prior
state-of-the-art attacks, ADMIT improves ASR by 11.2\% across all settings,
exposing significant vulnerabilities in real-world RAG-based fact-checking
systems.

</details>


### [113] [Serialized EHR make for good text representations](https://arxiv.org/abs/2510.13843)
*Zhirong Chou,Quan Qin,Shi Li*

Main category: cs.CL

TL;DR: SerialBEHRT是一个新的领域适应型基础模型，通过在结构化EHR序列上进行额外预训练，扩展了SciBERT，能够更好地捕捉纵向依赖关系，并在抗生素敏感性预测任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合EHR的表格式和事件驱动特性以及自然语言模型的序列先验方面存在困难，限制了它们捕捉患者就诊之间纵向依赖关系的能力。

Method: 通过在结构化EHR序列上进行额外预训练，扩展了SciBERT，使其能够编码临床事件之间的时间和上下文关系，从而生成更丰富的患者表征。

Result: 在抗生素敏感性预测任务的广泛基准测试中，SerialBEHRT的性能优于最先进的EHR表征策略，并且表现更稳定。

Conclusion: 时间序列化在医疗保健领域基础模型的预训练中至关重要，能够提高模型性能。

Abstract: The emergence of foundation models in healthcare has opened new avenues for
learning generalizable representations from large scale clinical data. Yet,
existing approaches often struggle to reconcile the tabular and event based
nature of Electronic Health Records (EHRs) with the sequential priors of
natural language models. This structural mismatch limits their ability to
capture longitudinal dependencies across patient encounters. We introduce
SerialBEHRT, a domain aligned foundation model that extends SciBERT through
additional pretraining on structured EHR sequences. SerialBEHRT is designed to
encode temporal and contextual relationships among clinical events, thereby
producing richer patient representations. We evaluate its effectiveness on the
task of antibiotic susceptibility prediction, a clinically meaningful problem
in antibiotic stewardship. Through extensive benchmarking against state of the
art EHR representation strategies, we demonstrate that SerialBEHRT achieves
superior and more consistent performance, highlighting the importance of
temporal serialization in foundation model pretraining for healthcare.

</details>


### [114] [DynaSpec: Context-aware Dynamic Speculative Sampling for Large-Vocabulary Language Models](https://arxiv.org/abs/2510.13847)
*Jinbin Zhang,Nasib Ullah,Erik Schultheis,Rohit Babbar*

Main category: cs.CL

TL;DR: 在LLM推理中，投机解码（speculative decoding）通过让一个小模型（drafter）提议多个token，然后由一个大模型（target model）进行验证来加速推理。然而，随着LLM词汇量的增加，drafter的输出层参数量O(|V|d)成为延迟瓶颈。现有方法（如FR-Spec, VocabTrim）通过限制drafter的词汇量来缓解这个问题，但这可能导致性能下降，因为固定词汇表依赖于特定语料库，并且会抑制罕见或特定领域token的生成。


<details>
  <summary>Details</summary>
Motivation: 现有投机解码方法在加速LLM推理时面临词汇量增大带来的延迟瓶颈，并且固定词汇表方法存在泛化能力差和抑制罕见token的问题。

Method: 提出了一种名为DynaSpec的动态短名单机制。该机制使用轻量级的元分类器根据上下文动态地将token路由到不同的簇，然后选择top-k个簇的并集作为drafter的短名单。元分类器利用并行计算，在drafter进行隐藏状态生成的同时进行计算。

Result: 在标准投机解码基准测试中，DynaSpec相比固定短名单方法，在平均接受长度（mean accepted length）上取得了一致的提升，并且在不降低接受率的情况下可以使用更小的短名单。

Conclusion: DynaSpec通过上下文相关的动态短名单机制，有效解决了固定短名单方法的局限性，提高了drafter的速度和鲁棒性，并在LLM推理加速方面取得了显著的性能提升。

Abstract: Speculative decoding (a.k.a. speculative sampling) has become a standard way
to accelerate LLM inference: a small drafter proposes multiple tokens and a
large target model verifies them once per speculation length. Recently, scaling
of the LLM vocabulary has pushed the number of tokens to grow substantially.
While verification over the full vocabulary leaves the target model largely
unaffected, the O(|V|d) parameters in the drafter's output head become a
latency bottleneck, slowing the entire pipeline. Contemporary methods (e.g.,
FR-Spec, VocabTrim) restrict the drafter's vocabulary to a fixed subset of the
target model's vocabulary, ranked in descending order of token frequency.
Although this reduces draft-time compute, it is brittle, since: (i) frequency
lists are corpus-dependent and require retuning to generalize, and (ii) static
shortlists suppress rare or domain-specific tokens, lowering the expected
number of tokens per verification step. We propose DynaSpec, a
context-dependent dynamic shortlisting mechanism that is robust, speeds up
drafting, and generalizes across diverse tasks. Concretely, we introduce
lightweight, coarse-grained meta-classifiers that route contexts to a small
number of token clusters; the union of the top-k selected clusters forms the
drafter's shortlist, while verification retains the full vocabulary and
exactness. The meta-classifier finishes its computation earlier than the
drafter's hidden state generation by exploiting parallel execution of draft
encoding and meta shortlisting on separate streams. On standard
speculative-decoding benchmarks, we observe consistent gains in mean accepted
length over fixed-shortlist baselines, while context-dependent selection
enables smaller shortlists without degrading acceptance.

</details>


### [115] [On-device System of Compositional Multi-tasking in Large Language Models](https://arxiv.org/abs/2510.13848)
*Ondrej Bohdal,Konstantinos Theodosiadis,Asterios Mpatziakas,Dimitris Filippidis,Iro Spyrou,Christos Zonios,Anastasios Drosou,Dimosthenis Ioannidis,Kyeng-Hun Lee,Jijoong Moon,Hyeonmok Ko,Mete Ozay,Umberto Michieli*

Main category: cs.CL

TL;DR: LLM可以通过LoRA等参数高效微调技术适应多任务，但难以同时处理复杂任务。本文提出一种结合LoRA的投影层方法，用于同时进行对话长文本的翻译和摘要生成，并在Android应用中实现，证明了其在云端和设备端的有效性和高效性。


<details>
  <summary>Details</summary>
Motivation: 标准的参数高效微调技术难以同时处理像生成翻译摘要这样的复杂组合任务。

Method: 在组合的摘要和翻译适配器之上添加一个可学习的投影层。

Result: 该方法在云端和设备端均表现良好且速度快，证明了其在需要高速度和资源限制的实际应用中的潜力。

Conclusion: 所提出的方法能够有效地处理涉及摘要和翻译的组合多任务场景，并且可以通过在Android应用中实现进行部署。

Abstract: Large language models (LLMs) are commonly adapted for diverse downstream
tasks via parameter-efficient fine-tuning techniques such as Low-Rank Adapters
(LoRA). While adapters can be combined to handle multiple tasks separately,
standard approaches struggle when targeting the simultaneous execution of
complex tasks, such as generating a translated summary from a long
conversation. To address this challenge, we propose a novel approach tailored
specifically for compositional multi-tasking scenarios involving summarization
and translation. Our technique involves adding a learnable projection layer on
top of the combined summarization and translation adapters. This design enables
effective integration while maintaining efficiency through reduced
computational overhead compared to alternative strategies requiring extensive
retraining or sequential processing. We demonstrate the practical viability of
our method within an on-device environment by developing an Android app capable
of executing compositional tasks seamlessly. Experimental results indicate our
solution performs well and is fast in both cloud-based and on-device
implementations, highlighting the potential benefits of adopting our framework
in real-world applications demanding high-speed operation alongside resource
constraints.

</details>


### [116] [Language steering in latent space to mitigate unintended code-switching](https://arxiv.org/abs/2510.13849)
*Andrey Goncharov,Nikolai Kondusov,Alexey Zaytsev*

Main category: cs.CL

TL;DR: 提出一种名为“隐空间语言引导”的轻量级推理时方法，通过PCA识别语言方向并引导token嵌入，以控制语言身份，从而减轻多语言大语言模型中未曾预料到的语码转换问题，同时保持语义。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型（LLMs）常常出现非预期的语码转换，导致在下游任务中的可靠性降低。

Method: 通过在平行翻译上进行主成分分析（PCA）来识别语言方向，并沿这些轴引导token嵌入来控制语言身份。

Result: 在Qwen2.5和Llama-3.2模型上，使用单一主成分实现了95-99%的语言分类准确率，并将跨多种语言对的下一个token分布散度降低了高达42%。

Conclusion: 隐空间语言引导是一种有效的减轻多语言大语言模型语码转换问题的方法，它计算开销小，仅需少量平行数据即可进行校准，并且能够保持语义。语言身份在模型最后的层中集中，并具有近乎完美的线性可分性。

Abstract: Multilingual Large Language Models (LLMs) often exhibit unintended
code-switching, reducing reliability in downstream tasks. We propose
latent-space language steering, a lightweight inference-time method that
identifies language directions via PCA on parallel translations and steers
token embeddings along these axes to control language identity. Our approach
mitigates code-switching while preserving semantics with negligible
computational overhead and requires only minimal parallel data for calibration.
Empirically, we achieve 95-99\% language classification accuracy using a single
principal component and reduce next-token distributional divergence by up to
42% across multiple language pairs on Qwen2.5 and Llama-3.2 models. We further
analyze the layer-wise evolution of language representations, revealing that
language identity concentrates in final layers with near-perfect linear
separability.

</details>


### [117] [Revisiting the UID Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.13850)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.CL

TL;DR: LLM 的 CoT 存在不准确或难以解释的问题。本文提出使用信息熵分析 LLM 的推理过程，发现在数学推理中，成功的 LLM 推理过程并非信息密度均匀，而是存在剧烈波动，这与人类沟通模式形成鲜明对比，并为设计更优的 LLM 推理模型提供了新思路。


<details>
  <summary>Details</summary>
Motivation: LLM 的 CoT 存在不准确或难以解释的问题，需要新的分析方法。

Method: 提出使用信息熵分析 LLM 推理过程中的信息流。

Result: 在三个数学基准测试中发现，成功的 LLM 推理过程信息密度并非均匀分布，而是存在剧烈波动，这与人类沟通模式形成鲜明对比。

Conclusion: LLM 的成功推理并非信息密度均匀，这挑战了现有的关于机器推理的假设，并为设计更优的 LLM 推理模型提供了新思路。

Abstract: Large language models (LLMs) often solve problems using step-by-step
Chain-of-Thought (CoT) reasoning, yet these intermediate steps are frequently
unfaithful or hard to interpret. Inspired by the Uniform Information Density
(UID) hypothesis in psycholinguistics -- which posits that humans communicate
by maintaining a stable flow of information -- we introduce entropy-based
metrics to analyze the information flow within reasoning traces. Surprisingly,
across three challenging mathematical benchmarks, we find that successful
reasoning in LLMs is globally non-uniform: correct solutions are characterized
by uneven swings in information density, in stark contrast to human
communication patterns. This result challenges assumptions about machine
reasoning and suggests new directions for designing interpretable and adaptive
reasoning models.

</details>


### [118] [EvoEdit: Evolving Null-space Alignment for Robust and Efficient Knowledge Editing](https://arxiv.org/abs/2510.13851)
*Sicheng Lyu,Yu Gu,Xinyu Wang,Jerry Huang,Sitao Luan,Yufei Cui,Xiao-Wen Chang,Peng Lu*

Main category: cs.CL

TL;DR: LLMs需要持续更新以修正过时或错误的信息。模型编辑是一种在不完全重新训练的情况下进行有针对性修改的引人注目的范式。然而，在顺序编辑的场景下，现有方法会受到灾难性干扰的影响。本研究提出了一种名为EvoEdit的新型编辑策略，通过顺序零空间对齐来缓解灾难性干扰，从而实现稳定高效的模型编辑。EvoEdit通过对每个传入的编辑执行顺序零空间对齐，可以保留原始和先前修改的知识表示，并在保留的知识上保持输出不变性，即使在长编辑序列中也能有效缓解干扰。在真实世界的顺序知识编辑基准测试表明，EvoEdit的性能优于或媲美现有的locate-then-edit技术，速度最高可提高3.53倍。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM编辑方法在顺序编辑时存在灾难性干扰的问题，即新的编辑会损害先前已集成的内容并降低已保留的知识。

Method: 提出了一种名为EvoEdit的新型编辑策略，通过顺序零空间对齐来缓解灾难性干扰，实现稳定高效的模型编辑。具体来说，EvoEdit对每个传入的编辑执行顺序零空间对齐，以保留原始和先前修改的知识表示，并在保留的知识上保持输出不变性。

Result: 在真实世界的顺序知识编辑基准测试中，EvoEdit的性能优于或媲美现有的locate-then-edit技术，速度最高可提高3.53倍。

Conclusion: 为了在动态演变的信息环境中设计LLM，有必要开发更合理的方法。EvoEdit提供了一种简单有效且具有强大理论保证的解决方案。

Abstract: Large language models (LLMs) require continual updates to rectify outdated or
erroneous knowledge. Model editing has emerged as a compelling paradigm for
introducing targeted modifications without the computational burden of full
retraining. Existing approaches are mainly based on a locate-then-edit
framework. However, in sequential editing contexts, where multiple updates are
applied over time, they exhibit significant limitations and suffer from
catastrophic interference, i.e., new edits compromise previously integrated
updates and degrade preserved knowledge. To address these challenges, we
introduce EvoEdit, a novel editing strategy that mitigates catastrophic
interference through sequential null-space alignment, enabling stable and
efficient model editing. By performing sequential null-space alignment for each
incoming edit, EvoEdit preserves both original and previously modified
knowledge representations and maintains output invariance on preserved
knowledge even across long edit sequences, effectively mitigating interference.
Evaluations on real-world sequential knowledge-editing benchmarks show that
EvoEdit achieves better or comparable performance than prior state-of-the-art
locate-then-edit techniques, with up to 3.53 times speedup. Overall, these
results underscore the necessity of developing more principled approaches for
designing LLMs in dynamically evolving information settings, while providing a
simple yet effective solution with strong theoretical guarantees.

</details>


### [119] [ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When Responding to Different Demographic Groups](https://arxiv.org/abs/2510.13852)
*Peter Banyas,Shristi Sharma,Alistair Simmons,Atharva Vispute*

Main category: cs.CL

TL;DR: ConsistencyAI是一个独立基准，用于衡量大型语言模型（LLMs）在不同角色下回答事实的一致性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在不同用户群体（角色）询问相同问题时，是否会给出事实不一致的回答，以提供一个独立、无偏见的评估和问责机制。

Method: 在19个LLM上进行实验，使用包含不同角色背景的提示，针对15个主题询问5个事实，重复100次。通过计算句子嵌入的余弦相似度来量化跨角色事实一致性，并计算加权平均值得出一致性分数。

Result: 在100个角色的实验中，一致性分数范围为0.7896至0.9065，平均值为0.8656。xAI的Grok-3表现最优，轻量级模型表现较差。一致性因主题而异，就业市场最低，G7世界领导人最高，而疫苗或巴以冲突等问题在不同提供商之间存在分歧。

Conclusion: LLM的事实一致性受到提供商和主题的双重影响。研究代码和交互式演示已发布，以支持可复现的评估并鼓励采用与角色无关的提示策略。

Abstract: Is an LLM telling you different facts than it's telling me? This paper
introduces ConsistencyAI, an independent benchmark for measuring the factual
consistency of large language models (LLMs) for different personas.
ConsistencyAI tests whether, when users of different demographics ask identical
questions, the model responds with factually inconsistent answers. Designed
without involvement from LLM providers, this benchmark offers impartial
evaluation and accountability. In our experiment, we queried 19 LLMs with
prompts that requested 5 facts for each of 15 topics. We repeated this query
100 times for each LLM, each time adding prompt context from a different
persona selected from a subset of personas modeling the general population. We
processed the responses into sentence embeddings, computed cross-persona cosine
similarity, and computed the weighted average of cross-persona cosine
similarity to calculate factual consistency scores. In 100-persona experiments,
scores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as
a benchmark threshold. xAI's Grok-3 is most consistent, while several
lightweight models rank lowest. Consistency varies by topic: the job market is
least consistent, G7 world leaders most consistent, and issues like vaccines or
the Israeli-Palestinian conflict diverge by provider. These results show that
both the provider and the topic shape the factual consistency. We release our
code and interactive demo to support reproducible evaluation and encourage
persona-invariant prompting strategies.

</details>


### [120] [BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation](https://arxiv.org/abs/2510.13853)
*Fabian Wenz,Omar Bouattour,Devin Yang,Justin Choi,Cecil Gregg,Nesime Tatbul,Çağatay Demiralp*

Main category: cs.CL

TL;DR: BenchPress是一个旨在加速特定领域文本到SQL基准测试创建的人工在环系统，通过结合检索增强生成（RAG）和大型语言模型（LLMs）来生成自然语言描述，并由人类专家进行验证和编辑，从而显著减少了创建高质量基准测试所需的时间和精力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL研究主要集中在公开数据集，而在大型私有企业数据仓库上的效果不佳。创建私有企业文本到SQL基准测试（如Beaver）面临手动标注SQL日志以识别其对应的自然语言问题这一艰巨且昂贵的挑战，数据库管理员作为专家，承担额外工作成本高昂。

Method: BenchPress系统利用检索增强生成（RAG）和大型语言模型（LLMs）为给定的SQL查询提出多种自然语言描述。人类专家随后选择、排序或编辑这些草稿，以确保准确性和领域一致性。

Result: 通过在标注的企业SQL日志上进行评估，BenchPress系统证明了LLM辅助标注可显著减少创建高质量基准测试所需的时间和精力。结果表明，人类验证与LLM生成的建议相结合，可以提高标注准确性、基准测试可靠性和模型评估的鲁棒性。

Conclusion: BenchPress通过简化自定义基准测试的创建过程，为研究人员和实践者提供了一种评估特定领域工作负载下文本到SQL模型的机制，有效解决了创建私有企业文本到SQL基准测试的挑战。

Abstract: Large language models (LLMs) have been successfully applied to many tasks,
including text-to-SQL generation. However, much of this work has focused on
publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work
showed that LLMs are much less effective in querying large private enterprise
data warehouses and released Beaver, the first private enterprise text-to-SQL
benchmark. To create Beaver, we leveraged SQL logs, which are often readily
available. However, manually annotating these logs to identify which natural
language questions they answer is a daunting task. Asking database
administrators, who are highly trained experts, to take on additional work to
construct and validate corresponding natural language utterances is not only
challenging but also quite costly. To address this challenge, we introduce
BenchPress, a human-in-the-loop system designed to accelerate the creation of
domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses
retrieval-augmented generation (RAG) and LLMs to propose multiple natural
language descriptions. Human experts then select, rank, or edit these drafts to
ensure accuracy and domain alignment. We evaluated BenchPress on annotated
enterprise SQL logs, demonstrating that LLM-assisted annotation drastically
reduces the time and effort required to create high-quality benchmarks. Our
results show that combining human verification with LLM-generated suggestions
enhances annotation accuracy, benchmark reliability, and model evaluation
robustness. By streamlining the creation of custom benchmarks, BenchPress
offers researchers and practitioners a mechanism for assessing text-to-SQL
models on a given domain-specific workload. BenchPress is freely available via
our public GitHub repository at
https://github.com/fabian-wenz/enterprise-txt2sql and is also accessible on our
website at http://dsg-mcgraw.csail.mit.edu:5000.

</details>


### [121] [R2T: Rule-Encoded Loss Functions for Low-Resource Sequence Tagging](https://arxiv.org/abs/2510.13854)
*Mamadou K. Keita,Christopher Homan,Sebastien Diarra*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce the Rule-to-Tag (R2T) framework, a hybrid approach that
integrates a multi-tiered system of linguistic rules directly into a neural
network's training objective. R2T's novelty lies in its adaptive loss function,
which includes a regularization term that teaches the model to handle
out-of-vocabulary (OOV) words with principled uncertainty. We frame this work
as a case study in a paradigm we call principled learning (PrL), where models
are trained with explicit task constraints rather than on labeled examples
alone. Our experiments on Zarma part-of-speech (POS) tagging show that the
R2T-BiLSTM model, trained only on unlabeled text, achieves 98.2% accuracy,
outperforming baselines like AfriBERTa fine-tuned on 300 labeled sentences. We
further show that for more complex tasks like named entity recognition (NER),
R2T serves as a powerful pre-training step; a model pre-trained with R2T and
fine-tuned on just 50 labeled sentences outperformes a baseline trained on 300.

</details>


### [122] [Harnessing Consistency for Robust Test-Time LLM Ensemble](https://arxiv.org/abs/2510.13855)
*Zhichen Zeng,Qi Yu,Xiao Lin,Ruizhong Qiu,Xuying Ning,Tianxin Wei,Yuchen Yan,Jingrui He,Hanghang Tong*

Main category: cs.CL

TL;DR: LLM集成在处理异构分词和模型专业知识带来的错误信号方面存在不足，本文提出了CoRE技术，通过引入token级和模型级一致性来提高LLM集成的鲁棒性，并在多项基准测试中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM集成方法在提高集成质量方面取得了进展，但对于由异构分词和模型专业知识差异引起的人工错误信号的鲁棒性关注不足。模型的集成故障通常源于token级别和模型级别：前者体现在token预测的严重分歧，而后者则涉及低置信度和模型间明显的差异。

Method: 提出了一种名为CoRE的即插即用技术，利用模型一致性来增强LLM集成的鲁棒性。具体来说，通过低通滤波和下调不确定token的权重来捕获token级不一致性，并通过提高模型输出的自置信度和最小化模型间分歧来建模模型级一致性。

Result: CoRE技术能够改善token级别的预测，并通过低通滤波来降低不确定token的权重，从而在细粒度层面上提高鲁棒性。模型级一致性通过提高模型的自置信度和最小化模型间的分歧来增强鲁棒性，从而在更宏观的层面上提升鲁棒性。大量的实验表明，CoRE在各种基准测试、模型组合和集成策略下，能够持续提升集成性能和鲁棒性。

Conclusion: CoRE是一种有效的方法，可以提高LLM集成的鲁棒性，使其能够处理由异构分词和模型专业知识差异引起的人工错误信号。通过在token和模型级别引入一致性，CoRE能够提高集成性能和鲁棒性。

Abstract: Different large language models (LLMs) exhibit diverse strengths and
weaknesses, and LLM ensemble serves as a promising approach to integrate their
complementary capabilities. Despite substantial progress in improving ensemble
quality, limited attention has been paid to the robustness of ensembles against
potential erroneous signals, which often arise from heterogeneous tokenization
schemes and varying model expertise. Our analysis shows that ensemble failures
typically arise from both the token level and the model level: the former
reflects severe disagreement in token predictions, while the latter involves
low confidence and pronounced disparities among models. In light of this, we
propose CoRE, a plug-and-play technique that harnesses model consistency for
robust LLM ensemble, which can be seamlessly integrated with diverse ensemble
methods. Token-level consistency captures fine-grained disagreements by
applying a low-pass filter to downweight uncertain tokens with high
inconsistency, often due to token misalignment, thereby improving robustness at
a granular level. Model-level consistency models global agreement by promoting
model outputs with high self-confidence and minimal divergence from others,
enhancing robustness at a coarser level. Extensive experiments across diverse
benchmarks, model combinations, and ensemble strategies demonstrate that CoRE
consistently improves ensemble performance and robustness.

</details>


### [123] [Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA](https://arxiv.org/abs/2510.13856)
*A H M Rezaul Karim,Ozlem Uzuner*

Main category: cs.CL

TL;DR: MasonNLP系统在MEDIQA-WV 2025共享任务中取得优异成绩，其采用轻量级检索增强生成（RAG）框架，结合通用领域指令微调大模型和领域内文本/视觉示例，有效提升了医学影像问答的准确性和相关性。


<details>
  <summary>Details</summary>
Motivation: 支持临床决策和患者护理，解决伤口护理VQA问题，需要系统根据医学影像和患者查询生成自由文本响应和结构化伤口属性。

Method: 采用通用领域指令微调大模型，并结合检索增强生成（RAG）框架。该框架整合了领域内文本和视觉示例，以增强模型输出的临床相关性、推理能力、模式遵循性和响应质量。

Result: 在dBLEU、ROUGE、BERTScore和基于LLM的指标上均有改进。MasonNLP系统在19支队伍和51个提交中排名第三，平均得分为41.37%。

Conclusion: 轻量级RAG结合通用大模型（在推理时添加少量相关示例，无需额外训练或复杂重排）是多模态临床NLP任务的简单而有效的基线。

Abstract: Medical Visual Question Answering (MedVQA) enables natural language queries
over medical images to support clinical decision-making and patient care. The
MEDIQA-WV 2025 shared task addressed wound-care VQA, requiring systems to
generate free-text responses and structured wound attributes from images and
patient queries. We present the MasonNLP system, which employs a
general-domain, instruction-tuned large language model with a
retrieval-augmented generation (RAG) framework that incorporates textual and
visual examples from in-domain data. This approach grounds outputs in
clinically relevant exemplars, improving reasoning, schema adherence, and
response quality across dBLEU, ROUGE, BERTScore, and LLM-based metrics. Our
best-performing system ranked 3rd among 19 teams and 51 submissions with an
average score of 41.37%, demonstrating that lightweight RAG with
general-purpose LLMs -- a minimal inference-time layer that adds a few relevant
exemplars via simple indexing and fusion, with no extra training or complex
re-ranking -- provides a simple and effective baseline for multimodal clinical
NLP tasks.

</details>


### [124] [ShishuLM: Lightweight Language Model with Hybrid Decoder-MLP Architecture and Paired Weight Sharing](https://arxiv.org/abs/2510.13860)
*Shivanshu Kumar,Gopalakrishnan Srinivasan*

Main category: cs.CL

TL;DR: ShishuLM是一种高效的语言模型架构，通过利用AI可解释性和推理时层剪枝的见解，在不影响性能的情况下减少了参数数量和KV缓存需求，并在中等上下文场景下通过MLP近似Transformer块，从而在训练和推理中实现了内存和延迟的显著改进。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在自然语言处理任务中表现出色，但存在显著的内存和计算开销。ShishuLM旨在通过优化架构来解决这些问题，特别关注日益重要的SLM在agentic AI系统中的应用。

Method: ShishuLM利用AI可解释性和推理时层剪枝的见解，通过MLP近似Transformer块，并进行归一化和注意力计算，以减少参数数量和KV缓存需求。该方法在不同规模的SLM上进行了评估。

Result: ShishuLM在内存使用方面最多可减少25%，在延迟方面最多可提高40%，并且在训练和推理过程中均表现出这些改进。实验和分析结果为从预训练的角度构建更高效的SLM架构提供了见解。

Conclusion: ShishuLM通过采用MLP近似Transformer块的方法，显著提高了语言模型的效率，特别是在中等上下文场景下，为构建更高效的SLM架构提供了有价值的见解。

Abstract: While the transformer architecture has achieved state-of-the-art performance
on natural language processing tasks, these models impose substantial memory
and computational overhead. Recent research has identified significant
architectural redundancies within these models, presenting opportunities for
optimization without compromising performance. Taking insights from research in
AI interpretability and inference-time layer pruning, we introduce an efficient
language model architecture, referred to as ShishuLM, which reduces both the
parameter count and Key-Value (KV) cache requirements. Given the increasing
importance of Small Language Models (SLMs) in agentic AI systems, we evaluate
our approach on two SLMs of different scales. Our analysis reveals that for
moderate-context scenarios, normalization coupled with attention computation is
roughly linear with the input, enabling entire transformer blocks to be
approximated through Multi-Layer Perceptrons (MLPs). Our results show that
ShishuLM provides up to 25% reduction in memory requirements and up to 40%
improvement in latency during both training and inference, compared to parent
models. Our experimental and analytical findings provide insights towards
building more efficient SLM architectures from a pre-training standpoint.

</details>


### [125] [Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues](https://arxiv.org/abs/2510.13862)
*Chenyu Zhang,Sharifa Alghowinem,Cynthia Breazeal*

Main category: cs.CL

TL;DR: 本研究提出了一个结合多种大型语言模型（LLM）的框架，用于大规模地感知对话式AI辅导中的学习者情绪状态，为负责任地将生成式AI应用于教育提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM在教育中的应用关注较多，但对其在辅导对话中影响学习者情绪动态的理解尚显不足。

Method: 研究人员分析了PyTutor（一个LLM驱动的AI助教）与261名本科生在两个学期中进行的16,986次对话，并利用Gemini、GPT-4o和Claude三个前沿LLM进行了零样本情感标注，包括效价、唤醒度和学习帮助性等标量评分以及自由文本的情感标签。通过秩加权模型内池化和模型间多数表决来融合这些估计，以生成稳健的情感画像。

Result: 分析显示，学习者在与AI助教互动时，通常表现出轻微积极的情绪和中等程度的唤醒度。然而，学习过程并非一帆风顺，困惑和好奇是解决问题过程中的常见伴侣，而挫败感虽然不那么普遍，但仍可能干扰学习进程。积极情绪的持续时间略长于中性或消极情绪，但它们较为脆弱，容易受到干扰。值得鼓舞的是，消极情绪通常能迅速消退，有时甚至直接转变为积极情绪。中性时刻常常成为转折点，更倾向于将学习者情绪推向积极方向，这表明在这些节点上AI助教存在干预的机会。

Conclusion: 学习者在AI辅导中的情绪状态是动态且易变的，但积极情绪的出现频率更高，消极情绪也可能快速得到缓解。中性情绪状态是重要的转折点，为AI助教的有效干预提供了契机。

Abstract: While recent studies have examined the leaning impact of large language model
(LLM) in educational contexts, the affective dynamics of LLM-mediated tutoring
remain insufficiently understood. This work introduces the first ensemble-LLM
framework for large-scale affect sensing in tutoring dialogues, advancing the
conversation on responsible pathways for integrating generative AI into
education by attending to learners' evolving affective states. To achieve this,
we analyzed two semesters' worth of 16,986 conversational turns exchanged
between PyTutor, an LLM-powered AI tutor, and 261 undergraduate learners across
three U.S. institutions. To investigate learners' emotional experiences, we
generate zero-shot affect annotations from three frontier LLMs (Gemini, GPT-4o,
Claude), including scalar ratings of valence, arousal, and
learning-helpfulness, along with free-text emotion labels. These estimates are
fused through rank-weighted intra-model pooling and plurality consensus across
models to produce robust emotion profiles. Our analysis shows that during
interaction with the AI tutor, students typically report mildly positive affect
and moderate arousal. Yet learning is not uniformly smooth: confusion and
curiosity are frequent companions to problem solving, and frustration, while
less common, still surfaces in ways that can derail progress. Emotional states
are short-lived--positive moments last slightly longer than neutral or negative
ones, but they are fragile and easily disrupted. Encouragingly, negative
emotions often resolve quickly, sometimes rebounding directly into positive
states. Neutral moments frequently act as turning points, more often steering
students upward than downward, suggesting opportunities for tutors to intervene
at precisely these junctures.

</details>


### [126] [Unlocking the Potential of Diffusion Language Models through Template Infilling](https://arxiv.org/abs/2510.13870)
*Junhoo Lee,Seungyeon Kim,Nojun Kwak*

Main category: cs.CL

TL;DR: 本文提出了一种名为模板填充（TI）的新型条件生成方法，用于扩散语言模型（DLMs），并结合动态片段分配（DSA）来提高生成灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型（DLMs）在推理策略上主要依赖于从自回归模型继承的基于前缀的提示方法，这种方法存在局限性。

Method: 本文提出模板填充（TI）方法，首先生成目标响应的结构模板，然后填充被掩码的片段。为提高结构控制的灵活性，引入动态片段分配（DSA），根据生成置信度自适应地调整片段长度。

Result: 在数学推理和代码生成基准测试中，TI方法取得了显著的改进，相比基线模型提升了17.01个百分点。此外，TI在多令牌生成场景下能够实现有效加速，同时保持生成质量。

Conclusion: 模板填充（TI）结合动态片段分配（DSA）是一种有效的条件生成方法，能够提升扩散语言模型的性能，并为多令牌生成带来效率上的优势。

Abstract: Diffusion Language Models (DLMs) have emerged as a promising alternative to
Autoregressive Language Models, yet their inference strategies remain limited
to prefix-based prompting inherited from the autoregressive paradigm. In this
paper, we propose Template Infilling (TI), a tailored conditioning methodology
for DLMs' generation process. Unlike conventional prefix prompting, TI first
generates a structural template for the target response, then fills in the
masked segments. To enhance the flexibility of this structural control, we
introduce Dynamic Segment Allocation (DSA), which adaptively adjusts segment
lengths based on generation confidence. We demonstrate the effectiveness of our
approach on mathematical reasoning and code generation benchmarks, achieving
consistent improvements of 17.01$\%$p over baseline. Furthermore, we show that
TI provides additional advantages in multi-token generation settings, enabling
effective speedup while maintaining generation quality.

</details>


### [127] [Quechua Speech Datasets in Common Voice: The Case of Puno Quechua](https://arxiv.org/abs/2510.13871)
*Elwin Huaman,Wendi Huaman,Jorge Luis Huaman,Ninfa Quispe*

Main category: cs.CL

TL;DR: Common Voice 平台已纳入 17 种克丘亚语，其中普诺克丘亚语（qxp）贡献了 12 小时的数据，以促进语音技术在资源匮乏语言中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决克丘亚语等资源匮乏语言在语音技术开发中面临的数据和资源稀缺问题。

Method: 详细介绍 17 种克丘亚语，并以普诺克丘亚语（qxp）为例，介绍了语言接入和朗读及自发语音数据收集过程。

Result: Common Voice 平台目前拥有 191.1 小时的克丘亚语语音数据（86% 已验证），其中普诺克丘亚语贡献了 12 小时（77% 已验证）。

Conclusion: Common Voice 平台展示了其在促进资源匮乏语言（如克丘亚语）语音数据收集方面的潜力，并提出了一项包含技术挑战、社区参与和本土数据主权的未来研究议程，旨在推动包容性语音技术和数字赋权。

Abstract: Under-resourced languages, such as Quechuas, face data and resource scarcity,
hindering their development in speech technology. To address this issue, Common
Voice presents a crucial opportunity to foster an open and community-driven
speech dataset creation. This paper examines the integration of Quechua
languages into Common Voice. We detail the current 17 Quechua languages,
presenting Puno Quechua (ISO 639-3: qxp) as a focused case study that includes
language onboarding and corpus collection of both reading and spontaneous
speech data. Our results demonstrate that Common Voice now hosts 191.1 hours of
Quechua speech (86\% validated), with Puno Quechua contributing 12 hours (77\%
validated), highlighting the Common Voice's potential. We further propose a
research agenda addressing technical challenges, alongside ethical
considerations for community engagement and indigenous data sovereignty. Our
work contributes towards inclusive voice technology and digital empowerment of
under-resourced language communities.

</details>


### [128] [FRACCO: A gold-standard annotated corpus of oncological entities with ICD-O-3.1 normalisation](https://arxiv.org/abs/2510.13873)
*Johann Pignat,Milena Vucetic,Christophe Gaudet-Blavignac,Jamil Zaghir,Amandine Stettler,Fanny Amrein,Jonatan Bonjour,Jean-Philippe Goldman,Olivier Michielin,Christian Lovis,Mina Bjelogrlic*

Main category: cs.CL

TL;DR: FRACCO是一个包含1301个合成法语临床病例的专家标注语料库，用于开发临床文本的自然语言处理工具，特别是针对法语肿瘤学领域。


<details>
  <summary>Details</summary>
Motivation: 法语肿瘤学领域的标注数据集稀缺，阻碍了自然语言处理工具的开发。

Method: 通过将西班牙语CANTEMIST语料库翻译成法语，并由领域专家进行标注，包括形态学、地理位置和组织学分化，并使用ICD-O编码。同时，创建了一个额外的注释层，用于将多个ICD-O元素组合成统一的临床概念。通过自动化匹配和人工验证相结合的方式进行注释，并由多名注释员进行质量控制。

Result: 创建了一个包含399个独特形态学代码、272个独特地理位置代码和2043个独特复合表达式的FRACCO语料库，总共生成了71127个ICD-O规范化。

Conclusion: FRACCO语料库为法语肿瘤学文本的命名实体识别和概念规范化提供了参考标准。

Abstract: Developing natural language processing tools for clinical text requires
annotated datasets, yet French oncology resources remain scarce. We present
FRACCO (FRench Annotated Corpus for Clinical Oncology) an expert-annotated
corpus of 1301 synthetic French clinical cases, initially translated from the
Spanish CANTEMIST corpus as part of the FRASIMED initiative. Each document is
annotated with terms related to morphology, topography, and histologic
differentiation, using the International Classification of Diseases for
Oncology (ICD-O) as reference. An additional annotation layer captures
composite expression-level normalisations that combine multiple ICD-O elements
into unified clinical concepts. Annotation quality was ensured through expert
review: 1301 texts were manually annotated for entity spans by two domain
experts. A total of 71127 ICD-O normalisations were produced through a
combination of automated matching and manual validation by a team of five
annotators. The final dataset representing 399 unique morphology codes (from
2549 different expressions), 272 topography codes (from 3143 different
expressions), and 2043 unique composite expressions (from 11144 different
expressions). This dataset provides a reference standard for named entity
recognition and concept normalisation in French oncology texts.

</details>


### [129] [What Layers When: Learning to Skip Compute in LLMs with Residual Gates](https://arxiv.org/abs/2510.13876)
*Filipe Laitenberger,Dawid Kopiczko,Cees G. M. Snoek,Yuki M. Asano*

Main category: cs.CL

TL;DR: GateSkip是一种残差流门控机制，允许仅解码器LM进行逐标记层跳过，在推理时通过门值对标记进行排序，并使用每层预算跳过低重要性标记。


<details>
  <summary>Details</summary>
Motivation: 在预训练模型之上稳定地对门进行微调，而无需进行大量重新训练，从而实现高效的层跳过。

Method: 为每个注意力/MLP分支配备一个Sigmoid-线性门，该门在分支输出重新进入残差流之前对其进行压缩。在推理时，根据门值对标记进行排序，并使用每层预算跳过低重要性标记。

Result: 在长格式推理中，可以节省高达15%的计算量，同时保留超过90%的基线准确性。在指令调整模型上，可以看到在完全计算量下的准确性有所提高，并在节省近50%的计算量时达到基线质量。

Conclusion: 所学的门可以深入了解Transformer的信息流，并且该方法可以轻松地与量化、剪枝和自推测解码相结合。

Abstract: We introduce GateSkip, a simple residual-stream gating mechanism that enables
token-wise layer skipping in decoder-only LMs. Each Attention/MLP branch is
equipped with a sigmoid-linear gate that condenses the branch's output before
it re-enters the residual stream. During inference we rank tokens by the gate
values and skip low-importance ones using a per-layer budget. While early-exit
or router-based Mixture-of-Depths models are known to be unstable and need
extensive retraining, our smooth, differentiable gates fine-tune stably on top
of pretrained models. On long-form reasoning, we save up to 15\% compute while
retaining over 90\% of baseline accuracy. On instruction-tuned models we see
accuracy gains at full compute and match baseline quality near 50\% savings.
The learned gates give insight into transformer information flow (e.g., BOS
tokens act as anchors), and the method combines easily with quantization,
pruning, and self-speculative decoding.

</details>


### [130] [TextBandit: Evaluating Probabilistic Reasoning in LLMs Through Language-Only Decision Tasks](https://arxiv.org/abs/2510.13878)
*Jimin Lim,Arjun Damerla,Arthur Jiang,Nam Le*

Main category: cs.CL

TL;DR: LLMs can infer reward structures and make decisions from text alone, with Qwen3-4B outperforming baselines in a novel text-based multi-armed bandit benchmark.


<details>
  <summary>Details</summary>
Motivation: To explore LLMs' sequential decision-making abilities under uncertainty using only natural language, without numerical cues.

Method: Introduced a benchmark where LLMs interact with multi-armed bandit environments via textual feedback ('you earned a token'), requiring inference of latent reward structures from linguistic cues. Evaluated four open-source LLMs against standard algorithms (Thompson Sampling, Epsilon Greedy, UCB, random choice).

Result: Most LLMs underperformed compared to baselines. Qwen3-4B achieved an 89.2% best-arm selection rate, outperforming larger LLMs and traditional methods.

Conclusion: Probabilistic reasoning can emerge from language alone. This benchmark facilitates evaluating LLM decision-making in naturalistic, non-numeric contexts.

Abstract: Large language models (LLMs) have shown to be increasingly capable of
performing reasoning tasks, but their ability to make sequential decisions
under uncertainty only using natural language remains underexplored. We
introduce a novel benchmark in which LLMs interact with multi-armed bandit
environments using purely textual feedback, "you earned a token", without
access to numerical cues or explicit probabilities, resulting in the model to
infer latent reward structures purely off linguistic cues and to adapt
accordingly. We evaluated the performance of four open-source LLMs and compare
their performance to standard decision-making algorithms such as Thompson
Sampling, Epsilon Greedy, Upper Confidence Bound (UCB), and random choice.
While most of the LLMs underperformed compared to the baselines, Qwen3-4B,
achieved the best-arm selection rate of 89.2% , which significantly
outperformed both the larger LLMs and traditional methods. Our findings suggest
that probabilistic reasoning is able to emerge from language alone, and we
present this benchmark as a step towards evaluating decision-making
capabilities in naturalistic, non-numeric contexts.

</details>


### [131] [Catch Your Breath: Adaptive Computation for Self-Paced Sequence Production](https://arxiv.org/abs/2510.13879)
*Alexandre Galashov,Matt Jones,Rosemary Ke,Yuan Cao,Vaishnavh Nagarajan,Michael C. Mozer*

Main category: cs.CL

TL;DR: 该研究提出了一种名为“Catch Your Breath”（CYB）的训练方法，允许语言模型根据每个输入 token 的复杂性动态地分配计算资源，通过发出“<don't know>”信号并插入“<pause>” token 来请求额外的计算时间，从而提高训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型在处理每个 token 时分配固定计算资源，无法适应不同 token 的复杂性差异，导致计算资源浪费或处理不足。本研究旨在探索一种能够动态调整计算资源分配的训练方法，以提高模型的训练效率和性能。

Method: 提出了一类名为“Catch Your Breath”（CYB）的监督训练目标，允许语言模型为每个输入 token 动态地、自主地调整计算步数。模型可以通过发出“<don't know>”信号来请求额外计算，插入“<pause>” token 以获得延迟。研究了 CYB-AP（任何时候预测）、CYB-VA（变分推断）和 CYB-DP（动态规划）三种具体方法，将 token 选择视为有时间成本的序贯决策问题，以校准模型不确定性并明智地使用“<don't know>”。

Result: CYB 模型在训练效率上表现出色，仅需三分之一的训练数据即可达到不使用暂停机制的基线模型的性能，并且仅需一半的数据量即可达到使用暂停但未优化损失函数的模型的性能。实验表明，CYB 模型能够根据 token 的复杂性和上下文自适应地调整处理时间，在处理复杂或歧义 token 时请求更多计算，而在简单 token 上则不进行不必要的暂停。

Conclusion: CYB 损失函数能够使语言模型在训练效率和性能上取得显著提升，并且能够根据 token 级别的复杂度和上下文动态地、明智地分配计算资源，证明了其在适应性和效率方面的优越性。

Abstract: We explore a class of supervised training objectives that allow a language
model to dynamically and autonomously scale the number of compute steps used
for each input token. For any token, the model can request additional compute
steps by emitting a <don't know> output. If the model is granted a delay, a
specialized <pause> token is inserted at the next input step, providing the
model with additional compute resources to generate an output. The model can
request multiple pauses. To train the model to use <don't know> outputs
judiciously and to calibrate its uncertainty, we frame the selection of each
output token as a sequential-decision problem with a time cost. We refer to the
class of methods as $\textit{Catch Your Breath}$ losses and we study three
methods in this class: CYB-AP frames the model's task as anytime prediction,
where an output may be required at any step and accuracy is discounted over
time; CYB-VA is a variational approach that aims to maximize prediction
accuracy subject to a specified distribution over stopping times; and CYB-DP
imposes a penalty based on a computational budget. Through fine-tuning
experiments, we identify the best performing loss variant. The CYB model needs
only one third as much training data as the baseline (no pause) model needs to
achieve the same performance, and half as much data as a model with pauses and
a cross-entropy loss. We find that the CYB model requests additional steps when
doing so improves accuracy, and the model adapts its processing time to
token-level complexity and context. For example, it often pauses after plural
nouns like $\textit{patients}$ and $\textit{challenges}$ but never pauses after
the first token of contracted words like $\textit{wasn}$ and $\textit{didn}$,
and it shows high variability for ambiguous tokens like $\textit{won}$, which
could function as either a verb or part of a contraction.

</details>


### [132] [PAGE: Prompt Augmentation for text Generation Enhancement](https://arxiv.org/abs/2510.13880)
*Mauro Jose Pacchiotti,Luciana Ballejos,Mariel Ale*

Main category: cs.CL

TL;DR: PAGE是一个框架，通过使用简单的辅助模块（如分类器或提取器）来增强文本生成模型，通过构建丰富的输入来提高生成质量和可控性，并且无需辅助生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言生成模型在面对特定任务或特定需求时，可能表现不佳或需要大量额外数据进行调整。

Method: PAGE框架使用轻量级的辅助模型（如分类器或提取器）来提供输入文本的推理，并将这些推理结果用于构建一个丰富的输入，以提高生成质量和可控性。这种方法不依赖于辅助生成模型，而是采用一种简单的、模块化的架构。

Result: 在需求工程领域进行了概念验证，其中使用带有分类器的辅助模块来提高软件需求生成质量。

Conclusion: PAGE框架提供了一种简单、模块化且易于适应不同任务的方法，通过使用简单的辅助模块来增强文本生成模型的性能，提高了生成质量和可控性。

Abstract: In recent years, natural language generative models have shown outstanding
performance in text generation tasks. However, when facing specific tasks or
particular requirements, they may exhibit poor performance or require
adjustments that demand large amounts of additional data. This work introduces
PAGE (Prompt Augmentation for text Generation Enhancement), a framework
designed to assist these models through the use of simple auxiliary modules.
These modules, lightweight models such as classifiers or extractors, provide
inferences from the input text. The output of these auxiliaries is then used to
construct an enriched input that improves the quality and controllability of
the generation. Unlike other generation-assistance approaches, PAGE does not
require auxiliary generative models; instead, it proposes a simpler, modular
architecture that is easy to adapt to different tasks. This paper presents the
proposal, its components and architecture, and reports a proof of concept in
the domain of requirements engineering, where an auxiliary module with a
classifier is used to improve the quality of software requirements generation.

</details>


### [133] [Too Open for Opinion? Embracing Open-Endedness in Large Language Models for Social Simulation](https://arxiv.org/abs/2510.13884)
*Bolei Ma,Yong Cao,Indira Sen,Anna-Carolina Haensch,Frauke Kreuter,Barbara Plank,Daniel Hershcovich*

Main category: cs.CL

TL;DR: LLM社会模拟应采用开放式、自由格式的文本，以捕捉内在的观点和推理过程，而不是受限于封闭式设计。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社会模拟研究多采用封闭式设计，忽略了LLM的生成性，限制了其在社会现象模拟中的应用。

Method: 本文提出应采用开放式、自由格式的文本进行LLM社会模拟，并结合了调查方法学和NLP的最新进展。

Result: 开放式设计能够提高测量和设计的准确性，支持探索意料之外的观点，减少研究者偏见，并捕捉个体的表达和独特性，增强方法的实用性。

Conclusion: 呼吁采用新的实践和评估框架，利用LLM的开放式生成多样性，实现NLP和社科的协同增效。

Abstract: Large Language Models (LLMs) are increasingly used to simulate public opinion
and other social phenomena. Most current studies constrain these simulations to
multiple-choice or short-answer formats for ease of scoring and comparison, but
such closed designs overlook the inherently generative nature of LLMs. In this
position paper, we argue that open-endedness, using free-form text that
captures topics, viewpoints, and reasoning processes "in" LLMs, is essential
for realistic social simulation. Drawing on decades of survey-methodology
research and recent advances in NLP, we argue why this open-endedness is
valuable in LLM social simulations, showing how it can improve measurement and
design, support exploration of unanticipated views, and reduce
researcher-imposed directive bias. It also captures expressiveness and
individuality, aids in pretesting, and ultimately enhances methodological
utility. We call for novel practices and evaluation frameworks that leverage
rather than constrain the open-ended generative diversity of LLMs, creating
synergies between NLP and social science.

</details>


### [134] [Order from Chaos: Comparative Study of Ten Leading LLMs on Unstructured Data Categorization](https://arxiv.org/abs/2510.13885)
*Ariel Kamen*

Main category: cs.CL

TL;DR: LLMs在非结构化文本分类任务上表现一般，集成模型效果更佳。


<details>
  <summary>Details</summary>
Motivation: 评估当前先进LLM在IAB 2.2分类任务上的表现，并探索提升性能的方法。

Method: 使用统一数据集和零样本提示，对10个LLM进行评估，并设计了一个集成模型进行对比。

Result: LLM在准确率、精确率、召回率和F1分数上表现平平，且存在过度生成类别的问题。Gemini 1.5/2.0 Flash和GPT 20B/120B在成本效益上表现较好，GPT 120B的幻觉率最低。集成模型显著提高了性能，消除了幻觉。

Conclusion: LLM的规模和架构改进并非提升分类精度的唯一途径，集成模型通过协同可以达到或超越人类专家的水平。

Abstract: This study presents a comparative evaluation of ten state-of-the-art large
language models (LLMs) applied to unstructured text categorization using the
Interactive Advertising Bureau (IAB) 2.2 hierarchical taxonomy. The analysis
employed a uniform dataset of 8,660 human-annotated samples and identical
zero-shot prompts to ensure methodological consistency across all models.
Evaluation metrics included four classic measures - accuracy, precision,
recall, and F1-score - and three LLM-specific indicators: hallucination ratio,
inflation ratio, and categorization cost.
  Results show that, despite their rapid advancement, contemporary LLMs achieve
only moderate classic performance, with average scores of 34% accuracy, 42%
precision, 45% recall, and 41% F1-score. Hallucination and inflation ratios
reveal that models frequently overproduce categories relative to human
annotators. Among the evaluated systems, Gemini 1.5/2.0 Flash and GPT 20B/120B
offered the most favorable cost-to-performance balance, while GPT 120B
demonstrated the lowest hallucination ratio. The findings suggest that scaling
and architectural improvements alone do not ensure better categorization
accuracy, as the task requires compressing rich unstructured text into a
limited taxonomy - a process that challenges current model architectures.
  To address these limitations, a separate ensemble-based approach was
developed and tested. The ensemble method, in which multiple LLMs act as
independent experts, substantially improved accuracy, reduced inflation, and
completely eliminated hallucinations. These results indicate that coordinated
orchestration of models - rather than sheer scale - may represent the most
effective path toward achieving or surpassing human-expert performance in
large-scale text categorization.

</details>


### [135] [Reliable Fine-Grained Evaluation of Natural Language Math Proofs](https://arxiv.org/abs/2510.13888)
*Wenjie Ma,Andrei Cojocaru,Neel Kolhe,Bradley Louie,Robin Said Sharif,Haihan Zhang,Vincent Zhuang,Matei Zaharia,Sewon Min*

Main category: cs.CL

TL;DR: LLM生成的数学证明评估是一个挑战。我们提出了ProofBench数据集和ProofGrader评估器，以解决这个问题。ProofGrader能够根据专家评分，对模型生成的数学证明进行细粒度评分，显著优于基线方法，并能在实际应用中有效提升证明生成质量。


<details>
  <summary>Details</summary>
Motivation: LLM在数学推理方面取得了进展，但生成和验证自然语言数学证明仍是开放性挑战。当前缺乏可靠的、细粒度的LLM生成数学证明的评估器。

Method: 1. 提出了一种系统性的方法来开发和验证评估器，为模型生成的数学证明分配0-7分的细粒度分数。 2. 引入了ProofBench数据集，包含145个问题和435个LLM生成的解决方案及其专家评分。 3. 利用ProofBench测试平台，探索了评估器设计空间（骨干模型、输入上下文、指令和评估流程）。 4. 开发了ProofGrader评估器，结合了强大的骨干语言模型、参考解决方案和评分方案的丰富上下文以及简单的集成方法。

Result: ProofGrader评估器在专家评分上达到了0.926的平均绝对误差（MAE），显著优于基线方法。在n=16的“最佳选n”任务中，ProofGrader的平均得分为4.14（满分7分），缩小了与人类专家（4.62）和朴素二元评估器（2.48）之间的差距的78%。

Conclusion: ProofGrader在评估LLM生成的数学证明方面表现出色，并能在下游证明生成任务中发挥实际作用，有望推动该领域的发展。

Abstract: Recent advances in large language models (LLMs) for mathematical reasoning
have largely focused on tasks with easily verifiable final answers; however,
generating and verifying natural language math proofs remains an open
challenge. We identify the absence of a reliable, fine-grained evaluator for
LLM-generated math proofs as a critical gap. To address this, we propose a
systematic methodology for developing and validating evaluators that assign
fine-grained scores on a 0-7 scale to model-generated math proofs. To enable
this study, we introduce ProofBench, the first expert-annotated dataset of
fine-grained proof ratings, spanning 145 problems from six major math
competitions (USAMO, IMO, Putnam, etc) and 435 LLM-generated solutions from
Gemini-2.5-pro, o3, and DeepSeek-R1. %with expert gradings. Using ProofBench as
a testbed, we systematically explore the evaluator design space across key
axes: the backbone model, input context, instructions and evaluation workflow.
Our analysis delivers ProofGrader, an evaluator that combines a strong
reasoning backbone LM, rich context from reference solutions and marking
schemes, and a simple ensembling method; it achieves a low Mean Absolute Error
(MAE) of 0.926 against expert scores, significantly outperforming naive
baselines. Finally, we demonstrate its practical utility in a best-of-$n$
selection task: at $n=16$, ProofGrader achieves an average score of 4.14 (out
of 7), closing 78% of the gap between a naive binary evaluator (2.48) and the
human oracle (4.62), highlighting its potential to advance downstream proof
generation.

</details>


### [136] [A Survey on Collaborating Small and Large Language Models for Performance, Cost-effectiveness, Cloud-edge Privacy, and Trustworthiness](https://arxiv.org/abs/2510.13890)
*Fali Wang,Jihai Chen,Shuhua Yang,Ali Al-Lawati,Linli Tang,Hui Liu,Suhang Wang*

Main category: cs.CL

TL;DR: LLMs很好，但成本高、推理慢、难以部署到边缘设备且不可靠。SLMs小巧、高效、易于适应，可以解决这些问题。本文提出了一种按协作目标组织的SLM-LLM协作系统性调查，将SLMs的专业知识和效率与LLMs的通用性和推理能力相结合，以满足跨任务和部署场景的各种目标。


<details>
  <summary>Details</summary>
Motivation: LLMs在许多领域和应用中取得了进步，但面临高昂的微调成本、推理延迟、有限的边缘部署能力和可靠性问题。SLMs（小型语言模型）紧凑、高效且适应性强，提供了互补的解决方案。最近的工作探索了融合SLMs的专业知识和效率以及LLMs的通用性和推理能力的协作框架，以满足跨任务和部署场景的各种目标。

Method: 提出一个由性能增强、成本效益、云边隐私和可信度四个目标组成的框架，并在此框架内回顾代表性方法、总结设计范式，并概述高效、安全和可扩展的SLM-LLM协作的开放挑战和未来方向。

Result: 对SLM-LLM协作进行了分类，并确定了四个主要目标：提高性能、降低成本、增强云边隐私以及提高可信度。

Conclusion: 对SLM-LLM协作进行了系统性调查，提出了一个分类框架，并讨论了未来的挑战和方向，以实现高效、安全和可扩展的协作。

Abstract: Large language models (LLMs) have advanced many domains and applications but
face high fine-tuning costs, inference latency, limited edge deployability, and
reliability concerns. Small language models (SLMs), compact, efficient, and
adaptable, offer complementary remedies. Recent work explores collaborative
frameworks that fuse SLMs' specialization and efficiency with LLMs'
generalization and reasoning to meet diverse objectives across tasks and
deployment scenarios. Motivated by these developments, this paper presents a
systematic survey of SLM-LLM collaboration organized by collaboration
objectives. We propose a taxonomy with four goals: performance enhancement,
cost-effectiveness, cloud-edge privacy, and trustworthiness. Within this
framework, we review representative methods, summarize design paradigms, and
outline open challenges and future directions toward efficient, secure, and
scalable SLM-LLM collaboration.

</details>


### [137] [The Harder The Better: Maintaining Supervised Fine-tuning Generalization with Less but Harder Data](https://arxiv.org/abs/2510.13892)
*Zhaoyang Shang,Sibo Wei,Jianbin Guo,Rui Zhou,Lifeng Dong,Yin Luo*

Main category: cs.CL

TL;DR: THTB框架通过结合质量筛选和内外难度评分，优先选择高难度指令数据，从而提高LLM在专业领域的微调效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM领域适应方法在数据选择上存在过度依赖LLM内部知识、可解释性弱和泛化能力有限等问题。THTB旨在解决这些局限性。

Method: THTB是一个受认知科学启发的框架，用于指令数据选择和标注指导。它通过质量筛选与内在和外在难度评分相结合，优先考虑更高级别的认知指令，为数据选择和标注提供可解释和可量化的标准。

Result: 实验表明，THTB在仅使用5%的数据时，模型性能优于使用全部数据的训练。与仅使用LLM选择的数据相比，THTB取得了更好的泛化能力。此外，THTB在垂直领域提供了有效的标注指导，使使用2%数据的模型超越了使用更大训练数据集的模型。

Conclusion: THTB框架在LLM的领域适应方面展现出巨大潜力，能够显著提高数据效率和模型性能，并提供可解释的指导。

Abstract: Large Language Models (LLMs) excel in general tasks, but adapting them to
specialized domains relies on high-quality supervised fine-tuning (SFT) data.
Although existing methods can identify subsets of high-quality data and reduce
training cost to some extent, their selection process still suffers from
over-reliance on LLMs' internal knowledge, weak interpretability, and limited
generalization. To address these limitations, we propose THTB (The Harder The
Better), a cognitive science-inspired framework for instruction data selection
and annotation guidance. THTB prioritizes higher-level cognitive instructions
by combining quality filtering with intrinsic and extrinsic hardness scoring,
offering interpretable and quantifiable criteria for efficient SFT, both in
data selection and annotation guidance. Experiments show that THTB enables
models trained on only 5% of the data to outperform full-dataset training,
while achieving superior generalization compared with LLM-only selection. In
addition, THTB provides effective annotation guidance in vertical domains,
enabling a model trained on just 2% of the data to surpass models trained on
much larger datasets, demonstrating strong potential for domain adaptation. Our
code, datasets, and models are available on
https://github.com/DYJG-research/THTB.

</details>


### [138] [Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection](https://arxiv.org/abs/2510.13893)
*Olga E. Sorokoletova,Francesco Giarrusso,Vincenzo Suriani,Daniele Nardi*

Main category: cs.CL

TL;DR: LLM 越狱技术构成重大安全威胁，现有防御措施存在局限性。本研究通过结构化红队挑战，构建了包含 50 种越狱策略的层级分类法，分析了攻击的普遍性和成功率，评估了基于分类法的自动检测方法，并创建了一个新的意大利语多轮对抗性对话数据集，以应对 LLM 安全挑战。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 越狱防御措施存在局限性，无法全面应对多语言、多回合的复杂攻击。

Method: 通过结构化红队挑战，构建了包含 50 种越狱策略的层级分类法，分析了攻击的普遍性和成功率，评估了基于分类法的自动检测方法，并创建了一个新的意大利语多轮对抗性对话数据集。

Result: 1. 构建了包含 50 种越狱策略的层级分类法。 2. 分析了攻击的普遍性和成功率。 3. 评估了基于分类法的自动检测方法。 4. 创建了一个包含 1364 个意大利语多轮对抗性对话的新数据集。

Conclusion: 本研究通过全面的分类法、数据分析、自动检测评估和新数据集的创建，为理解和防御 LLM 越狱攻击提供了新的见解和工具。

Abstract: Jailbreaking techniques pose a significant threat to the safety of Large
Language Models (LLMs). Existing defenses typically focus on single-turn
attacks, lack coverage across languages, and rely on limited taxonomies that
either fail to capture the full diversity of attack strategies or emphasize
risk categories rather than the jailbreaking techniques. To advance the
understanding of the effectiveness of jailbreaking techniques, we conducted a
structured red-teaming challenge. The outcome of our experiments are manifold.
First, we developed a comprehensive hierarchical taxonomy of 50 jailbreak
strategies, consolidating and extending prior classifications into seven broad
families, including impersonation, persuasion, privilege escalation, cognitive
overload, obfuscation, goal conflict, and data poisoning. Second, we analyzed
the data collected from the challenge to examine the prevalence and success
rates of different attack types, providing insights into how specific jailbreak
strategies exploit model vulnerabilities and induce misalignment. Third, we
benchmark a popular LLM for jailbreak detection, evaluating the benefits of
taxonomy-guided prompting for improving automatic detection. Finally, we
compiled a new Italian dataset of 1364 multi-turn adversarial dialogues,
annotated with our taxonomy, enabling the study of interactions where
adversarial intent emerges gradually and succeeds in bypassing traditional
safeguards.

</details>


### [139] [Attribution Quality in AI-Generated Content:Benchmarking Style Embeddings and LLM Judges](https://arxiv.org/abs/2510.13898)
*Misam Abbas*

Main category: cs.CL

TL;DR: LLM生成内容和人类写作在可归属性方面越来越难以区分。本研究评估了固定风格嵌入和LLM（GPT-4o）判断两种方法，在人类AI并行语料库上，比较了它们在不同类型文本中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）生成文本的质量提升，区分机器生成和人类生成的内容变得越来越困难，这带来了可归属性的挑战。

Method: 研究人员在人类AI并行语料库上，对固定风格嵌入和LLM（GPT-4o）判断两种归因机制进行了基准测试。该语料库包含600个样本，涵盖学术、新闻、小说、博客、口语和影视剧本等六个领域。每个样本都包含一个人类提示，以及由GPT-4o或LLaMA-70B-Instruct生成的LLM续写版本和人类标注的续写版本。

Result: 固定风格嵌入在处理GPT续写时，整体准确率更高（82% vs. 68%）。LLM判断在处理LLaMA续写时略优于风格嵌入（85% vs. 81%），但差异不显著。LLM判断在小说和学术文本上表现更佳，而在口语和剧本对话上，风格嵌入表现更优。

Conclusion: 内容归因是一个多维度的问题，需要结合多种策略。固定风格嵌入在结构化文本上表现出色，而LLM判断在语义敏感的任务上表现更好。未来的研究应考虑混合方法来提高归因的准确性。

Abstract: Attributing authorship in the era of large language models (LLMs) is
increasingly challenging as machine-generated prose rivals human writing. We
benchmark two complementary attribution mechanisms , fixed Style Embeddings and
an instruction-tuned LLM judge (GPT-4o) on the Human AI Parallel Corpus, an
open dataset of 600 balanced instances spanning six domains (academic, news,
fiction, blogs, spoken transcripts, and TV/movie scripts). Each instance
contains a human prompt with both a gold continuation and an LLM-generated
continuation from either GPT-4o or LLaMA-70B-Instruct. The Style Embedding
baseline achieves stronger aggregate accuracy on GPT continuations (82 pct vs.
68 pct). The LLM Judge is slightly better than the Style embeddings on LLaMA
continuations (85 pct vs. 81 pct) but the results are not statistically
significant. Crucially, the LLM judge significantly outperforms in fiction and
academic prose, indicating semantic sensitivity, whereas embeddings dominate in
spoken and scripted dialogue, reflecting structural strengths. These
complementary patterns highlight attribution as a multidimensional problem
requiring hybrid strategies. To support reproducibility we provide code on
GitHub and derived data on Hugging Face under the MIT license. This open
framework provides a reproducible benchmark for attribution quality assessment
in AI-generated content, along with a review of related literature influencing
this work.

</details>


### [140] [Narrow Finetuning Leaves Clearly Readable Traces in Activation Differences](https://arxiv.org/abs/2510.13900)
*Julian Minder,Clément Dumas,Stewart Slocum,Helena Casademunt,Cameron Holmes,Robert West,Neel Nanda*

Main category: cs.CL

TL;DR: 对LLM进行窄域微调会产生可解释的激活偏差，可用于理解微调领域。通过模型差异分析和激活引导，可以重现微调数据的格式和内容。基于此偏差的解释性智能体比基线智能体表现更好。该方法适用于不同模型和规模，并揭示了微调可能导致过拟合。混合预训练数据可消除大部分偏差，但仍存在残余风险。研究结果强调了窄域微调的潜在问题，并为AI安全和可解释性研究提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 为了研究大语言模型（LLM）在特定任务上的适应性，以及创建具有研究价值的特殊属性模型，我们对LLM进行了窄域微调。

Method: 通过分析模型微调前后的激活差异（模型差异分析），特别关注随机文本的初始词元，并进行激活引导，来发现和利用微调产生的激活偏差。我们构建了一个基于LLM的解释性智能体，利用这些偏差来理解微调领域。

Result: 分析表明，窄域微调在LLM激活中产生了强烈的偏差，这些偏差可以被解释以理解微调数据。通过激活引导，可以生成类似于微调数据格式和内容的文本。基于偏差的解释性智能体相比于简单提示的基线智能体，在理解微调领域方面表现显著更好。该方法在合成虚假信息、潜在不安全模型、潜意识学习和禁忌词猜谜游戏等多个场景，以及不同架构（Gemma, LLaMA, Qwen）和规模（1B到32B参数）的模型上均得到了验证。研究还发现，混合预训练数据在很大程度上消除了这些偏差，但可能仍存在残余风险。

Conclusion: 窄域微调会在LLM激活中留下明显的训练目标痕迹，这为改进模型训练提供了方向。AI安全和可解释性研究人员在使用此类模型作为研究更广泛微调（如聊天微调）的代理时应谨慎，因为这可能不具有代表性。窄域微调的影响需要进一步深入研究，并且需要开发更真实的案例研究，以促进模型差异分析、安全和可解释性研究。

Abstract: Finetuning on narrow domains has become an essential tool to adapt Large
Language Models (LLMs) to specific tasks and to create models with known
unusual properties that are useful for research. We show that narrow finetuning
creates strong biases in LLM activations that can be interpreted to understand
the finetuning domain. These biases can be discovered using simple tools from
model diffing - the study of differences between models before and after
finetuning. In particular, analyzing activation differences on the first few
tokens of random text and steering by adding this difference to the model
activations produces text similar to the format and general content of the
finetuning data. We demonstrate that these analyses contain crucial information
by creating an LLM-based interpretability agent to understand the finetuning
domain. With access to the bias, the agent performs significantly better
compared to baseline agents using simple prompting. Our analysis spans
synthetic document finetuning for false facts, emergent misalignment,
subliminal learning, and taboo word guessing game models across different
architectures (Gemma, LLaMA, Qwen) and scales (1B to 32B parameters). We
suspect these biases reflect overfitting and find that mixing pretraining data
into the finetuning corpus largely removes them, though residual risks may
remain. Our work (1) demonstrates that narrowly finetuned models have salient
traces of their training objective in their activations and suggests ways to
improve how they are trained, (2) warns AI safety and interpretability
researchers that the common practice of using such models as a proxy for
studying broader finetuning (e.g., chat-tuning) might not be realistic, and (3)
highlights the need for deeper investigation into the effects of narrow
finetuning and development of truly realistic case studies for model-diffing,
safety and interpretability research.

</details>


### [141] [RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs](https://arxiv.org/abs/2510.13901)
*Tuan T. Nguyen,John Le,Thai T. Vu,Willy Susilo,Heath Cooper*

Main category: cs.CL

TL;DR: RAID框架通过优化连续嵌入来生成对抗性后缀，有效绕过LLM的安全机制，并在实验中表现出更高的攻击成功率和更低的成本。


<details>
  <summary>Details</summary>
Motivation: LLM虽然在多种任务上表现出色，但容易受到绕过安全机制的越狱攻击。本研究旨在系统性地探究这些弱点。

Method: RAID框架将离散标记放松为连续嵌入，并使用联合目标进行优化：1. 鼓励生成受限内容；2. 引入拒答感知正则化器，使激活远离嵌入空间中的拒答方向；3. 应用连贯性项以保持语义合理性和非冗余。优化后，采用基于批评者的解码程序，通过平衡嵌入亲和度和语言模型似然性将嵌入映射回标记。

Result: RAID框架能够生成有效的、不易被察觉的对抗性后缀，在多个开源LLM上的实验表明，与最新的白盒和黑盒基线相比，RAID实现了更高的攻击成功率、更少的查询次数和更低的计算成本。

Conclusion: 嵌入空间的正则化对于理解和减轻LLM的越狱漏洞至关重要。

Abstract: Large language models (LLMs) achieve impressive performance across diverse
tasks yet remain vulnerable to jailbreak attacks that bypass safety mechanisms.
We present RAID (Refusal-Aware and Integrated Decoding), a framework that
systematically probes these weaknesses by crafting adversarial suffixes that
induce restricted content while preserving fluency. RAID relaxes discrete
tokens into continuous embeddings and optimizes them with a joint objective
that (i) encourages restricted responses, (ii) incorporates a refusal-aware
regularizer to steer activations away from refusal directions in embedding
space, and (iii) applies a coherence term to maintain semantic plausibility and
non-redundancy. After optimization, a critic-guided decoding procedure maps
embeddings back to tokens by balancing embedding affinity with language-model
likelihood. This integration yields suffixes that are both effective in
bypassing defenses and natural in form. Experiments on multiple open-source
LLMs show that RAID achieves higher attack success rates with fewer queries and
lower computational cost than recent white-box and black-box baselines. These
findings highlight the importance of embedding-space regularization for
understanding and mitigating LLM jailbreak vulnerabilities.

</details>


### [142] [Investigating Political and Demographic Associations in Large Language Models Through Moral Foundations Theory](https://arxiv.org/abs/2510.13902)
*Nicole Smith-Vaniz,Harper Lyon,Lorraine Steigner,Ben Armstrong,Nicholas Mattei*

Main category: cs.CL

TL;DR: LLMs在日常生活中扮演着重要角色，但其在政治和道德领域的回答可能存在偏见。本研究使用道德基础理论（MFT）量化LLM的潜在偏见，并将其与人类研究数据进行比较，分析LLM回答的意识形态倾向。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在政治和道德领域回答中存在的偏见，并量化这种偏见，将其与现有的人类研究数据进行比较，以了解LLM回答中的意识形态倾向。

Method: 使用道德基础理论（MFT）的五个维度（伤害、公平、忠诚、权威、纯洁）来分析LLM的回答。研究了LLM的固有回答、在扮演特定政治意识形态角色时的回答，以及在扮演具有特定人口统计特征的人类角色时的回答。

Result: 研究发现，LLM的回答在不同条件下表现出不同的意识形态倾向，并且其回答在一定程度上依赖于政治和人口统计信息。

Conclusion: LLM的回答可能存在意识形态偏见，并且这种偏见会受到输入提示和扮演角色的影响。未来的研究需要进一步探索如何减轻LLM中的偏见。

Abstract: Large Language Models (LLMs) have become increasingly incorporated into
everyday life for many internet users, taking on significant roles as advice
givers in the domains of medicine, personal relationships, and even legal
matters. The importance of these roles raise questions about how and what
responses LLMs make in difficult political and moral domains, especially
questions about possible biases. To quantify the nature of potential biases in
LLMs, various works have applied Moral Foundations Theory (MFT), a framework
that categorizes human moral reasoning into five dimensions: Harm, Fairness,
Ingroup Loyalty, Authority, and Purity. Previous research has used the MFT to
measure differences in human participants along political, national, and
cultural lines. While there has been some analysis of the responses of LLM with
respect to political stance in role-playing scenarios, no work so far has
directly assessed the moral leanings in the LLM responses, nor have they
connected LLM outputs with robust human data. In this paper we analyze the
distinctions between LLM MFT responses and existing human research directly,
investigating whether commonly available LLM responses demonstrate ideological
leanings: either through their inherent responses, straightforward
representations of political ideologies, or when responding from the
perspectives of constructed human personas. We assess whether LLMs inherently
generate responses that align more closely with one political ideology over
another, and additionally examine how accurately LLMs can represent ideological
perspectives through both explicit prompting and demographic-based
role-playing. By systematically analyzing LLM behavior across these conditions
and experiments, our study provides insight into the extent of political and
demographic dependency in AI-generated responses.

</details>


### [143] [Schema for In-Context Learning](https://arxiv.org/abs/2510.13905)
*Pan Chen,Shaohong Chen,Mark Wang,Shi Xuan Leong,Priscilla Fung,Varinia Bernales,Alan Aspuru-Guzik*

Main category: cs.CL

TL;DR: SA-ICL通过显式地构建和利用抽象的知识框架（schema）来增强LLM的上下文学习能力，提高了在科学问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文学习（ICL）方法缺乏显式的知识检索和迁移机制。受认知科学中图式理论的启发，需要一种新的框架来提升LLM的推理能力。

Method: 提出SA-ICL框架，该框架从示例中提取推理过程的抽象表示（schema），并将其用于增强模型处理新问题的能力。通过在GPQA数据集的化学和物理问题上进行实验来验证该方法。

Result: SA-ICL在LLM上表现出色，能显著提升性能（最高可达36.19%），尤其是在提供高质量示例时。该方法减少了对示例数量的依赖，并提高了模型的可解释性。

Conclusion: SA-ICL有效弥合了现有ICL策略的差距，为增强LLM的类人推理能力开辟了新途径。

Abstract: In-Context Learning (ICL) enables transformer-based language models to adapt
to new tasks by conditioning on demonstration examples. However, traditional
example-driven in-context learning lacks explicit modules for knowledge
retrieval and transfer at the abstraction level. Inspired by cognitive science,
specifically schema theory, which holds that humans interpret new information
by activating pre-existing mental frameworks (schemas) to structure
understanding, we introduce SCHEMA ACTIVATED IN CONTEXT LEARNING (SA-ICL). This
framework extracts the representation of the building blocks of cognition for
the reasoning process instilled from prior examples, creating an abstracted
schema, a lightweight, structured template of key inferential steps and their
relationships, which is then used to augment a model's reasoning process when
presented with a novel question. We demonstrate that a broad range of large
language models (LLMs) lack the capacity to form and utilize internal
schema-based learning representations implicitly, but instead benefit
significantly from explicit schema-based scaffolding. Across chemistry and
physics questions from the GPQA dataset, our experiments show that SA-ICL
consistently boosts performance, up to 36.19 percent, when the single
demonstration example is of high quality, which simultaneously reduces reliance
on the number of demonstrations and enhances interpretability. SCHEMA ACTIVATED
IN CONTEXT LEARNING not only bridges disparate ICL strategies ranging from
pattern priming to Chain-of-Thought prompting, but also paves a new path for
enhancing human-like reasoning in LLMs.

</details>


### [144] [LLM Prompt Duel Optimizer: Efficient Label-Free Prompt Optimization](https://arxiv.org/abs/2510.13907)
*Yuanchen Wu,Saurabh Verma,Justin Lee,Fangzhou Xiong,Poppy Zhang,Amel Awadelkarim,Xu Chen,Yubai Yuan,Shawndra Hill*

Main category: cs.CL

TL;DR: 该研究提出了一种名为PDO的无标签提示优化框架，通过LLM作为裁判进行成对偏好比较，并结合D-TS和提示变异策略，以提高提示设计的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法需要标签数据，而标签数据的收集成本高昂。本研究旨在解决这一问题，提出一种无需标签数据的提示优化方法。

Method: PDO框架将提示优化视为一个 duelo-bandit 问题，利用LLM作为裁判提供成对偏好反馈。该框架结合了Double Thompson Sampling (D-TS)和Top-Performer Guided Mutation两种策略，以提高样本效率和候选提示的多样性。

Result: 在BIG-bench Hard (BBH)和MS MARCO数据集上的实验表明，PDO的性能优于基线方法。消融研究证明了D-TS和提示变异策略的有效性。

Conclusion: PDO是一种样本高效的无标签提示优化框架，通过LLM裁判和创新的优化策略，能够有效提升提示设计的性能，并能在部分标签数据存在的情况下进行优化。

Abstract: Large language models (LLMs) are highly sensitive to their input prompts,
making prompt design a central challenge. While automatic prompt optimization
(APO) reduces manual engineering, most approaches assume access to ground-truth
references such as labeled validation data. In practice, however, collecting
high-quality labels is costly and slow. We propose the Prompt Duel Optimizer
(PDO), a sample-efficient framework for label-free prompt optimization. PDO
formulates the problem as a dueling-bandit setting, where supervision signal
comes from pairwise preference feedback provided by an LLM judge. The framework
combines Double Thompson Sampling (D-TS), which prioritizes informative prompt
comparisons, with Top-Performer Guided Mutation, which expands the candidate
pool by mutating high-performing prompts. PDO naturally operates in label-free
settings and can also incorporate partial labels to mitigate judge noise.
Experiments on BIG-bench Hard (BBH) and MS MARCO show that PDO consistently
outperforms baseline methods. Ablation studies further demonstrate the
effectiveness of both D-TS and prompt mutation.

</details>


### [145] [Interpreting the Latent Structure of Operator Precedence in Language Models](https://arxiv.org/abs/2510.13908)
*Dharunish Yugeswardeenoo,Harshil Nukala,Cole Blondin,Sean O Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: LLMs在算术任务中存在困难，本研究通过分析LLaMA 3.2-3B模型来探究其内部算术计算机制，发现中间计算结果存在于残差流中，并且模型能在线性编码中体现运算符优先级。


<details>
  <summary>Details</summary>
Motivation: LLMs在算术任务上的不足以及对其内部机制缺乏了解。

Method: 构建包含三个操作数和两个运算符的算术表达式数据集，通过日志镜头、线性分类探针和UMAP可视化等方法，追踪LLaMA 3.2-3B模型残差流中的中间计算结果，并分析运算符优先级的编码方式，提出部分嵌入交换技术。

Result: 中间计算结果存在于残差流中，尤其在MLP块之后。模型在线性编码的每个运算符嵌入中都体现了优先级。部分嵌入交换技术可以修改运算符优先级。

Conclusion: LLMs内部存在算术计算机制，能够处理运算符优先级，并且可以通过特定技术进行干预。

Abstract: Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities but continue to struggle with arithmetic tasks. Prior works
largely focus on outputs or prompting strategies, leaving the open question of
the internal structure through which models do arithmetic computation. In this
work, we investigate whether LLMs encode operator precedence in their internal
representations via the open-source instruction-tuned LLaMA 3.2-3B model. We
constructed a dataset of arithmetic expressions with three operands and two
operators, varying the order and placement of parentheses. Using this dataset,
we trace whether intermediate results appear in the residual stream of the
instruction-tuned LLaMA 3.2-3B model. We apply interpretability techniques such
as logit lens, linear classification probes, and UMAP geometric visualization.
Our results show that intermediate computations are present in the residual
stream, particularly after MLP blocks. We also find that the model linearly
encodes precedence in each operator's embeddings post attention layer. We
introduce partial embedding swap, a technique that modifies operator precedence
by exchanging high-impact embedding dimensions between operators.

</details>


### [146] [Knowledge Reasoning Language Model: Unifying Knowledge and Language for Inductive Knowledge Graph Reasoning](https://arxiv.org/abs/2510.13909)
*Xingrui Zhuo,Jiapu Wang,Gongqing Wu,Zhongyuan Wang,Jichen Zhang,Shirui Pan,Xindong Wu*

Main category: cs.CL

TL;DR: KRLM通过设计KRL指令格式、KRL分词器、KRL注意力层和结构感知型实体预测器，有效解决了现有LLM-KGR方法中的知识失真和幻觉问题，在25个真实世界数据集上均表现出显著优越性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-KGR方法存在LLM知识被稀疏的KG信息覆盖导致知识失真，以及生成幻觉难以约束的问题，影响了推理结果的可靠性。

Method: 提出一种名为KRLM的知识推理语言模型，通过设计KRL指令格式和KRL分词器来对齐LLM知识和KG表示；设计KRL注意力层，利用动态知识记忆机制协调LLM内部知识和KG上下文；提出结构感知型实体预测器来严格约束推理结果。

Result: 在25个真实世界数据集的零样本推理和微调场景下，KRLM均展现出显著优于现有方法的性能。

Conclusion: KRLM成功实现了LLM知识和KG上下文的统一协调，有效解决了现有方法的局限性，并在多个真实世界数据集上取得了显著成果。

Abstract: Inductive Knowledge Graph Reasoning (KGR) aims to discover facts in
open-domain KGs containing unknown entities and relations, which poses a
challenge for KGR models in comprehending uncertain KG components. Existing
studies have proposed Knowledge Graph Foundation Models (KGFMs) that learn
structural invariances across KGs to handle this uncertainty. Recently, Large
Language Models (LLMs) have demonstrated strong capabilities for open-domain
knowledge reasoning. As a result, the latest research has focused on LLM-based
KGFMs that integrate LLM knowledge with KG context for inductive KGR. However,
the intrinsic knowledge of LLMs may be overshadowed by sparse KG context,
leading to LLM knowledge distortion, which can cause irreversible damage to
model reasoning. Moreover, existing LLM-based KGR methods still struggle to
fully constrain generative hallucinations in LLMs, severely limiting the
credibility of reasoning results. To address these limitations, we propose a
Knowledge Reasoning Language Model (KRLM) that achieves unified coordination
between LLM knowledge and KG context throughout the KGR process. Specifically,
we design a Knowledge Reasoning Language (KRL) instruction format and a KRL
tokenizer to align LLM knowledge with KG representations. Then, we propose a
KRL attention layer that coordinates intrinsic LLM knowledge with additional KG
context through a dynamic knowledge memory mechanism. Finally, a
structure-aware next-entity predictor is proposed, which strictly constrains
the reasoning results within a trustworthy knowledge domain. Extensive
experimental results on 25 real-world inductive KGR datasets demonstrate the
significant superiority of the proposed KRLM\footnote{Our source codes are
available at https://anonymous.4open.science/r/KRLM-EA36 in both zero-shot
reasoning and fine-tuning scenarios.

</details>


### [147] [RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems](https://arxiv.org/abs/2510.13910)
*Jingru Lin,Chen Zhang,Stephen Y. Liu,Haizhou Li*

Main category: cs.CL

TL;DR: RAGCap-Bench 是一个用于评估 RAG 工作流中 LLM 中间任务能力的基准测试，实验表明该基准测试的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM 在处理复杂的多跳问题时仍存在不足，其推理能力有待提升。

Method: 提出 RAGCap-Bench，一个能力导向的基准测试，用于细粒度评估 RAG 工作流中的中间任务。通过分析现有系统的输出来识别常见任务和核心能力，并构建 LLM 典型错误分类来设计有针对性的评估问题。

Result: “慢思考”模型在 RAGCap-Bench 上表现更好，端到端的性能也更优。

Conclusion: RAGCap-Bench 的有效性得到了证明，并且提升中间能力对于 RAG 系统的整体性能至关重要。

Abstract: Retrieval-Augmented Generation (RAG) mitigates key limitations of Large
Language Models (LLMs)-such as factual errors, outdated knowledge, and
hallucinations-by dynamically retrieving external information. Recent work
extends this paradigm through agentic RAG systems, where LLMs act as agents to
iteratively plan, retrieve, and reason over complex queries. However, these
systems still struggle with challenging multi-hop questions, and their
intermediate reasoning capabilities remain underexplored. To address this, we
propose RAGCap-Bench, a capability-oriented benchmark for fine-grained
evaluation of intermediate tasks in agentic RAG workflows. We analyze outputs
from state-of-the-art systems to identify common tasks and the core
capabilities required for their execution, then construct a taxonomy of typical
LLM errors to design targeted evaluation questions. Experiments show that
"slow-thinking" models with stronger RAGCap performance achieve better
end-to-end results, underscoring the benchmark's validity and the importance of
enhancing these intermediate capabilities.

</details>


### [148] [AI Debaters are More Persuasive when Arguing in Alignment with Their Own Beliefs](https://arxiv.org/abs/2510.13912)
*María Victoria Carro,Denise Alejandra Mester,Facundo Nieto,Oscar Agustín Stanchi,Guido Ernesto Bergman,Mario Alejandro Leiva,Eitan Sprejer,Luca Nicolás Forziati Gangi,Francisca Gauna Selasco,Juan Gustavo Corvalán,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.CL

TL;DR: AI辩论实验表明，模型倾向于迎合裁判而非坚持己见，尽管坚持己见时论证更具说服力。


<details>
  <summary>Details</summary>
Motivation: 现有AI辩论实验依赖于有标准答案的数据集，这忽略了辩论中主观性的一面，即说谎需要认为自己所持观点是错误的。本研究旨在将辩论应用于主观性问题，并明确衡量语言模型在实验前的先验信念。

Method: 通过要求模型选择立场，然后呈现与其先验信念相冲突的裁判角色，测试模型是采取谄媚策略还是坚持先验信念。对比了顺序和同步辩论协议，并评估了模型在 defending 与先验信念一致或不一致的立场时的说服力和论证质量。

Result: 模型倾向于 defender 与裁判一致的立场，而非其先验信念。顺序辩论偏袒第二位辩手。模型在 defender 与其先验信念一致的立场时更具说服力，但在 defender 与其先验信念不一致的立场时，论证在成对比较中被评为更高质量。

Conclusion: 研究结果有助于人类裁判提供更高质量的训练信号，构建更优的AI系统，并揭示了语言模型在说服动态方面与人类互动的重要性。

Abstract: The core premise of AI debate as a scalable oversight technique is that it is
harder to lie convincingly than to refute a lie, enabling the judge to identify
the correct position. Yet, existing debate experiments have relied on datasets
with ground truth, where lying is reduced to defending an incorrect
proposition. This overlooks a subjective dimension: lying also requires the
belief that the claim defended is false. In this work, we apply debate to
subjective questions and explicitly measure large language models' prior
beliefs before experiments. Debaters were asked to select their preferred
position, then presented with a judge persona deliberately designed to conflict
with their identified priors. This setup tested whether models would adopt
sycophantic strategies, aligning with the judge's presumed perspective to
maximize persuasiveness, or remain faithful to their prior beliefs. We
implemented and compared two debate protocols, sequential and simultaneous, to
evaluate potential systematic biases. Finally, we assessed whether models were
more persuasive and produced higher-quality arguments when defending positions
consistent with their prior beliefs versus when arguing against them. Our main
findings show that models tend to prefer defending stances aligned with the
judge persona rather than their prior beliefs, sequential debate introduces
significant bias favoring the second debater, models are more persuasive when
defending positions aligned with their prior beliefs, and paradoxically,
arguments misaligned with prior beliefs are rated as higher quality in pairwise
comparison. These results can inform human judges to provide higher-quality
training signals and contribute to more aligned AI systems, while revealing
important aspects of human-AI interaction regarding persuasion dynamics in
language models.

</details>


### [149] [Synthesizing Agentic Data for Web Agents with Progressive Difficulty Enhancement Mechanisms](https://arxiv.org/abs/2510.13913)
*Shrey Pandit,Xuan-Phi Nguyen,Yifei Ming,Austin Xu,Jiayu Wang,Caiming Xiong,Shafiq Joty*

Main category: cs.CL

TL;DR: 本研究提出了一种新的数据合成管线，用于训练更有效的网络研究代理，该管线通过逐步增加任务复杂度来生成问答对，直到基线代理失败。


<details>
  <summary>Details</summary>
Motivation: 现有的网络研究代理难以处理长时程推理和探索任务，且先前用于构建指令调优数据集的方法缺乏对难度和质量的精细控制，生成的合成数据未能充分捕捉长时程推理所需的复杂性。

Method: 设计了一个两步数据合成管线，逐步增加任务复杂度，直到基线网络代理无法解决。基线代理在过程中扮演多种角色：回答问题、验证事实、检查替代答案和执行过滤。采用基于强网络代理蒸馏的可控训练设置来评估合成方法的有效性。

Result: 在多个基于网络的基准测试中，本研究使用的数据集（尽管规模较小）能够训练出比现有数据集更有效的网络代理。具体而言，本研究的数据集在工具使用动作方面表现出两倍的多样性，使得在其中训练的模型能够获得更强的性能，同时避免了重复调用工具的行为。

Conclusion: 本研究提出的数据合成管线能够生成高质量、高多样性的数据，有效提升网络研究代理在复杂问答任务上的性能，并解决了现有数据合成方法在难度控制、质量保证和评估隔离方面存在的问题。

Abstract: Web-based 'deep research' agents aim to solve complex question - answering
tasks through long-horizon interactions with online tools. These tasks remain
challenging, as the underlying language models are often not optimized for
long-horizon reasoning and exploration. Prior work has proposed workflows for
constructing instruction-tuning datasets, often leveraging knowledge graphs.
However, such methods typically lack fine-grained control over difficulty and
quality, yielding synthetic data that falls short of capturing the complexity
required for long-horizon reasoning. Furthermore, many studies conflate data
and training effects by comparing models trained under different optimization
recipes, making it difficult to isolate and evaluate the effectiveness of the
data itself. We introduce a two-pronged data synthesis pipeline that generates
question - answer pairs by progressively increasing task complexity until a
frontier baseline web agent fails. The baseline agent plays multiple roles in
this process: attempting the questions, validating factuality, checking for
alternative answers, and enforcing filtering. To evaluate the effectiveness of
our synthesis methods, we adopt a controlled training setup based on
distillation from strong web agents. Experiments across multiple web-based
benchmarks show that our dataset - despite being smaller - enables the training
of more effective web agents than existing datasets. In particular, our data
exhibits twice the diversity in tool-use actions, allowing models trained on it
to achieve stronger performance while avoiding repetitive tool-calling
behaviors.

</details>


### [150] [Readability $\ne$ Learnability: Rethinking the Role of Simplicity in Training Small Language Models](https://arxiv.org/abs/2510.13915)
*Ivan Lee,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: SLMs在儿童导向语料库上的表现并非由可读性驱动，而是由统计上的简洁性驱动。


<details>
  <summary>Details</summary>
Motivation: 挑战“可读性是SLMs能力涌现的关键”的观点，并探讨影响SLMs学习效率的真正因素。

Method: 构建具有相同结构但可读性不同的合成数据集，并比较SLMs在这些数据集上的表现。度量n-gram多样性作为统计简洁性的指标。

Result: 可读性并非预测SLMs学习效率或连贯性的唯一因素。在成人化文本上训练的模型表现与在简化文本上训练的模型相当，甚至在连贯性发展上更快。统计上的简洁性（n-gram多样性）是比可读性更强的预测指标。

Conclusion: SLMs的能力涌现并非由可读性驱动，而是由统计上的简洁性驱动。反对将SLMs训练过程拟人化，并呼吁对支持小模型能力涌现的真正属性进行更精确的推理。

Abstract: Recent studies suggest that very small language models (SLMs) can generate
surprisingly coherent text when trained on simplified, child-directed corpora
such as TinyStories. These findings have been interpreted as evidence that
readability -- characterized by accessible vocabulary, familiar narrative
structure, and simple syntax -- plays a key role in enabling such capabilities
to emerge. In this paper, we challenge that interpretation. We construct
synthetic datasets with matched structure but varied readability, and find that
readability alone does not predict coherence or learning efficiency in SLMs.
Models trained on complex, adult-level text perform comparably to those trained
on simplified language, and even exhibit faster development of coherence during
training. Instead, we show that statistical simplicity, as measured by n-gram
diversity, is a stronger predictor of learnability. Our findings caution
against the growing trend of anthropomorphizing language model training --
drawing parallels to human cognitive development without empirical basis -- and
argue for more precise reasoning about what properties actually support
capability emergence in small models.

</details>


### [151] [Element2Vec: Build Chemical Element Representation from Text for Property Prediction](https://arxiv.org/abs/2510.13916)
*Yuanhao Li,Keyuan Lai,Tianqi Wang,Qihao Liu,Jiawei Ma,Yuan-Chao Hu*

Main category: cs.CL

TL;DR: Element2Vector使用基于Transformer的语言模型将化学元素表示为向量，解决了传统方法难以捕捉复杂关系和AI方法易产生幻觉的问题，并提出一种测试时训练方法来提高预测精度，以促进材料科学的AI驱动发现。


<details>
  <summary>Details</summary>
Motivation: 传统方法在预测化学元素性质时难以处理复杂关系，而现有的AI方法存在幻觉和可解释性差的问题。本研究旨在为自然科学研究提供一种有效表征化学元素的方法。

Method: 使用预训练语言模型从维基百科文本生成全局和局部的元素向量表示。针对数据稀疏和分布不均的问题，设计了一种基于自注意力机制的测试时训练方法来减少预测误差。

Result: Element2Vector成功地将化学元素表示为向量，并且通过测试时训练方法提高了预测精度，为AI驱动的材料科学发现奠定了基础。

Conclusion: Element2Vector提供了一种新的化学元素表征方法，有望推动AI在材料科学领域的应用和发现。

Abstract: Accurate property data for chemical elements is crucial for materials design
and manufacturing, but many of them are difficult to measure directly due to
equipment constraints. While traditional methods use the properties of other
elements or related properties for prediction via numerical analyses, they
often fail to model complex relationships. After all, not all characteristics
can be represented as scalars. Recent efforts have been made to explore
advanced AI tools such as language models for property estimation, but they
still suffer from hallucinations and a lack of interpretability. In this paper,
we investigate Element2Vecto effectively represent chemical elements from
natural languages to support research in the natural sciences. Given the text
parsed from Wikipedia pages, we use language models to generate both a single
general-purpose embedding (Global) and a set of attribute-highlighted vectors
(Local). Despite the complicated relationship across elements, the
computational challenges also exist because of 1) the discrepancy in text
distribution between common descriptions and specialized scientific texts, and
2) the extremely limited data, i.e., with only 118 known elements, data for
specific properties is often highly sparse and incomplete. Thus, we also design
a test-time training method based on self-attention to mitigate the prediction
error caused by Vanilla regression clearly. We hope this work could pave the
way for advancing AI-driven discovery in materials science.

</details>


### [152] [Optimal Aggregation of LLM and PRM Signals for Efficient Test-Time Scaling](https://arxiv.org/abs/2510.13918)
*Peng Kuang,Yanli Wang,Xiaoyu Han,Yaowenqi Liu,Kaidi Xu,Haohan Wang*

Main category: cs.CL

TL;DR: PRM选择LLM响应的方法存在局限性，提出一种加权聚合策略，并通过实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的PRM在测试时验证和选择LLM响应方面存在局限性，有时甚至不如简单的投票方法，因此需要研究如何更有效地利用PRM信号。

Method: 提出一种结合LLM和PRM信号的理论框架，并基于此框架提出一种加权聚合策略，并通过预计算方法来校准权重函数。

Result: 实验证明，所提出的加权聚合策略显著提高了测试时选择的效率，优于标准的加权投票方法，同时计算量仅为后者的21.3%。

Conclusion: 通过更智能的聚合策略来提升性能比单纯增加测试时计算量更为有效。

Abstract: Process reward models (PRMs) are a cornerstone of test-time scaling (TTS),
designed to verify and select the best responses from large language models
(LLMs). However, this promise is challenged by recent benchmarks where simple
majority voting, which ignores PRM signals, occasionally outperforms standard
PRM-based selection. This raises a critical question: How can we effectively
utilize verification signals from PRMs for TTS? To address this, we start by
developing a theoretical framework for optimally combining signals from both
the LLM and the PRM. Our framework reveals that the optimal strategy is a
weighted aggregation of responses, a strategy whose effectiveness hinges on
estimating weights that capture the complex interplay between the models. Based
on our theoretical results, we empirically show that these optimal weighting
functions differ significantly across LLM-PRM pairs and, notably, often assign
substantial negative weights. Motivated by these insights, we propose efficient
pre-computation methods to calibrate these weighting functions. Extensive
experiments across 5 LLMs and 7 PRMs demonstrate that our calibration method
significantly boosts the TTS efficiency, surpassing the performance of vanilla
weighted majority voting while using only $21.3\%$ of the computation.
Ultimately, our work demonstrates that investing in a more intelligent
aggregation strategy can be a more convincing path to performance gains than
simply scaling test-time computation.

</details>


### [153] [FACTS: Table Summarization via Offline Template Generation with Agentic Workflows](https://arxiv.org/abs/2510.13920)
*Ye Yuan,Mohammad Amin Shabani,Siqi Liu*

Main category: cs.CL

TL;DR: FACTS是一个通过离线模板生成实现快速、准确、隐私合规的表格摘要方法，通过预先生成的SQL查询和Jinja2模板，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有表格摘要方法存在微调成本高、推理能力不足、令牌限制、效率低下、暴露敏感数据以及缺乏鲁棒性和可扩展性等问题。

Method: FACTS通过生成包含SQL查询和Jinja2模板的离线模板，这些模板可以渲染成自然语言摘要，并可跨具有相同模式的多个表重用。

Result: FACTS在常用基准测试中持续优于基线方法，在速度、准确性和隐私合规性方面表现出色。

Conclusion: FACTS为现实世界中的面向查询的表格摘要提供了一个实用且高效的解决方案。

Abstract: Query-focused table summarization requires generating natural language
summaries of tabular data conditioned on a user query, enabling users to access
insights beyond fact retrieval. Existing approaches face key limitations:
table-to-text models require costly fine-tuning and struggle with complex
reasoning, prompt-based LLM methods suffer from token-limit and efficiency
issues while exposing sensitive data, and prior agentic pipelines often rely on
decomposition, planning, or manual templates that lack robustness and
scalability. To mitigate these issues, we introduce an agentic workflow, FACTS,
a Fast, Accurate, and Privacy-Compliant Table Summarization approach via
Offline Template Generation. FACTS produces offline templates, consisting of
SQL queries and Jinja2 templates, which can be rendered into natural language
summaries and are reusable across multiple tables sharing the same schema. It
enables fast summarization through reusable offline templates, accurate outputs
with executable SQL queries, and privacy compliance by sending only table
schemas to LLMs. Evaluations on widely-used benchmarks show that FACTS
consistently outperforms baseline methods, establishing it as a practical
solution for real-world query-focused table summarization.

</details>


### [154] [An LLM-Powered AI Agent Framework for Holistic IoT Traffic Interpretation](https://arxiv.org/abs/2510.13925)
*Daniel Adu Worae,Spyridon Mastorakis*

Main category: cs.CL

TL;DR: 该研究提出了一个由大型语言模型（LLM）驱动的AI代理框架，用于分析物联网（IoT）网络流量。该框架能将原始数据包捕获转化为结构化、语义丰富的信息，以支持交互式分析。通过整合特征提取、基于Transformer的异常检测、数据包和流的摘要、威胁情报丰富以及检索增强问答，该AI代理能够对索引的流量进行推理，并提供准确、易懂的解释。实验证明，混合检索方法（结合词汇、语义搜索和重排）在BLEU、ROUGE、METEOR和BERTScore等指标上显著优于仅使用密集检索的方法。此外，该框架的系统分析显示其CPU、GPU和内存开销较低，实现了对物联网网络流量的全面而高效的解释。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）网络产生海量、多样化的流量，其中包含正常活动和潜在威胁。为了从这些遥测数据中获得有意义的见解，需要跨越多个层面来解释行为、协议和上下文，而不是孤立地进行检测。

Method: 研究提出了一个由大型语言模型（LLM）驱动的AI代理框架。该框架将原始数据包捕获转化为结构化、语义丰富的信息，用于交互式分析。它集成了特征提取、基于Transformer的异常检测、数据包和流的摘要、威胁情报丰富以及检索增强问答。由LLM指导的AI代理对索引的流量文物进行推理，并整合证据以产生准确、人类可读的解释。

Result: 实验评估了在多个物联网捕获和六个开放模型上的表现。结果表明，混合检索方法（结合词汇和语义搜索以及重排）显著提高了BLEU、ROUGE、METEOR和BERTScore等评估指标，优于仅使用密集检索的方法。系统剖析还显示该框架具有较低的CPU、GPU和内存开销。

Conclusion: 该研究提出的LLM驱动的AI代理框架能够全面且高效地解释物联网网络流量。混合检索方法在提高解释质量方面表现出色，同时该框架的低资源消耗证明了其在实际应用中的可行性。

Abstract: Internet of Things (IoT) networks generate diverse and high-volume traffic
that reflects both normal activity and potential threats. Deriving meaningful
insight from such telemetry requires cross-layer interpretation of behaviors,
protocols, and context rather than isolated detection. This work presents an
LLM-powered AI agent framework that converts raw packet captures into
structured and semantically enriched representations for interactive analysis.
The framework integrates feature extraction, transformer-based anomaly
detection, packet and flow summarization, threat intelligence enrichment, and
retrieval-augmented question answering. An AI agent guided by a large language
model performs reasoning over the indexed traffic artifacts, assembling
evidence to produce accurate and human-readable interpretations. Experimental
evaluation on multiple IoT captures and six open models shows that hybrid
retrieval, which combines lexical and semantic search with reranking,
substantially improves BLEU, ROUGE, METEOR, and BERTScore results compared with
dense-only retrieval. System profiling further indicates low CPU, GPU, and
memory overhead, demonstrating that the framework achieves holistic and
efficient interpretation of IoT network traffic.

</details>


### [155] [BioMedSearch: A Multi-Source Biomedical Retrieval Framework Based on LLMs](https://arxiv.org/abs/2510.13926)
*Congying Liu,Xingyuan Wei,Peipei Liu,Yiqing Shen,Yanxu Mao,Tiehan Cui*

Main category: cs.CL

TL;DR: BioMedSearch是一个基于LLM的多源生物医学信息检索框架，通过整合文献、蛋白质数据库和网络搜索，并采用子查询分解、关键词提取、任务图构建和多源信息过滤等方法，提高了生物医学问答的准确性和效率。该框架在包含三个推理层级（机制识别、非邻近语义整合、时间因果推理）的BioMedMCQs数据集上进行了评估，结果显示BioMedSearch在所有层级上都显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理生物医学查询时，由于无法访问权威数据库，常生成缺乏科学严谨性且包含虚假信息的内容。因此，需要一个能够整合多源信息并进行准确检索和推理的框架。

Method: BioMedSearch框架整合了文献检索、蛋白质数据库访问和网络搜索功能，并利用子查询分解、关键词提取、任务图构建和多源信息过滤等技术来处理复杂的生物医学查询。

Result: 在BioMedMCQs数据集上，BioMedSearch在三个推理层级上的准确率分别从基线模型的59.1%、47.0%、36.3%提升至91.9%、81.0%、73.4%，显著优于所有基线模型。

Conclusion: BioMedSearch框架能够有效提高LLM在处理复杂生物医学问答任务时的准确性和效率，克服了现有LLM在科学严谨性方面的不足。

Abstract: Biomedical queries often rely on a deep understanding of specialized
knowledge such as gene regulatory mechanisms and pathological processes of
diseases. They require detailed analysis of complex physiological processes and
effective integration of information from multiple data sources to support
accurate retrieval and reasoning. Although large language models (LLMs) perform
well in general reasoning tasks, their generated biomedical content often lacks
scientific rigor due to the inability to access authoritative biomedical
databases and frequently fabricates protein functions, interactions, and
structural details that deviate from authentic information. Therefore, we
present BioMedSearch, a multi-source biomedical information retrieval framework
based on LLMs. The method integrates literature retrieval, protein database and
web search access to support accurate and efficient handling of complex
biomedical queries. Through sub-queries decomposition, keywords extraction,
task graph construction, and multi-source information filtering, BioMedSearch
generates high-quality question-answering results. To evaluate the accuracy of
question answering, we constructed a multi-level dataset, BioMedMCQs,
consisting of 3,000 questions. The dataset covers three levels of reasoning:
mechanistic identification, non-adjacent semantic integration, and temporal
causal reasoning, and is used to assess the performance of BioMedSearch and
other methods on complex QA tasks. Experimental results demonstrate that
BioMedSearch consistently improves accuracy over all baseline models across all
levels. Specifically, at Level 1, the average accuracy increases from 59.1% to
91.9%; at Level 2, it rises from 47.0% to 81.0%; and at the most challenging
Level 3, the average accuracy improves from 36.3% to 73.4%. The code and
BioMedMCQs are available at: https://github.com/CyL-ucas/BioMed_Search

</details>


### [156] [LLMs Can Get "Brain Rot"!](https://arxiv.org/abs/2510.13928)
*Shuo Xing,Junyuan Hong,Yifan Wang,Runjin Chen,Zhenyu Zhang,Ananth Grama,Zhengzhong Tu,Zhangyang Wang*

Main category: cs.CL

TL;DR: 模型持续接触低质网络文本会导致认知能力下降，且该影响具有剂量效应。


<details>
  <summary>Details</summary>
Motivation: 评估低质数据对大型语言模型（LLM）认知能力的因果影响。

Method: 通过在真实Twitter/X语料库上进行对照实验，构建低质和对照数据集，并对4个LLM进行持续预训练。

Result: 在低质数据集上预训练的LLM在推理、长文本理解、安全性和“黑暗特质”（如精神病态、自恋）方面表现出显著下降。数据中低质内容的比例越高，认知能力衰减越明显。错误分析显示，“思维跳跃”是主要原因，而指令调优和清洁数据预训练只能部分恢复能力。此外，推文的流行度比长度更能预测“大脑腐烂”效应。

Conclusion: 数据质量是导致LLM能力衰减的因果因素，应将数据策展视为训练时的安全问题，并对已部署的LLM进行定期的“认知健康检查”。

Abstract: We propose and test the LLM Brain Rot Hypothesis: continual exposure to junk
web text induces lasting cognitive decline in large language models (LLMs). To
causally isolate data quality, we run controlled experiments on real Twitter/X
corpora, constructing junk and reversely controlled datasets via two orthogonal
operationalizations: M1 (engagement degree) and M2 (semantic quality), with
matched token scale and training operations across conditions. Contrary to the
control group, continual pre-training of 4 LLMs on the junk dataset causes
non-trivial declines (Hedges' $g>0.3$) on reasoning, long-context
understanding, safety, and inflating "dark traits" (e.g., psychopathy,
narcissism). The gradual mixtures of junk and control datasets also yield
dose-response cognition decay: for example, under M1, ARC-Challenge with Chain
Of Thoughts drops $74.9 \rightarrow 57.2$ and RULER-CWE $84.4 \rightarrow 52.3$
as junk ratio rises from $0\%$ to $100\%$.
  Error forensics reveal several key insights. First, we identify
thought-skipping as the primary lesion: models increasingly truncate or skip
reasoning chains, explaining most of the error growth. Second, partial but
incomplete healing is observed: scaling instruction tuning and clean data
pre-training improve the declined cognition yet cannot restore baseline
capability, suggesting persistent representational drift rather than format
mismatch. Finally, we discover that the popularity, a non-semantic metric, of a
tweet is a better indicator of the Brain Rot effect than the length in M1.
Together, the results provide significant, multi-perspective evidence that data
quality is a causal driver of LLM capability decay, reframing curation for
continual pretraining as a \textit{training-time safety} problem and motivating
routine "cognitive health checks" for deployed LLMs.

</details>


### [157] [Robust or Suggestible? Exploring Non-Clinical Induction in LLM Drug-Safety Decisions](https://arxiv.org/abs/2510.13931)
*Siying Liu,Shisheng Zhang,Indu Bala*

Main category: cs.CL

TL;DR: LLMs在药物安全预测中可能存在基于社会人口学信息的偏见，即使这些信息与临床无关。研究发现，弱势群体在AE预测中被分配了更高的可能性，并且存在显性（直接提及属性）和隐性（预测不一致）的偏见模式，这在临床应用前需要公平性评估和缓解策略。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在药物安全预测中是否会因纳入临床无关的社会人口学信息而产生偏见，并识别偏见模式。

Method: 使用FDA的FAERS结构化数据和基于角色的评估框架，评估ChatGPT-4o和Bio-Medical-Llama-3.8B在不同社会人口学特征（教育、婚姻、就业、保险、语言、住房稳定、宗教）和用户角色（全科医生、专家、患者）下的AE预测准确性。

Result: 研究发现LLMs在AE预测中存在系统性差异。弱势群体（如低教育、住房不稳定）的AE预测可能性高于优势群体（如研究生、私人保险）。发现了显性偏见（直接引用属性）和隐性偏见（预测不一致但未提及属性）。

Conclusion: LLMs在药物安全预测中存在固有的偏见风险，需要开发公平性评估和缓解策略，以确保其在临床部署前的可靠性。

Abstract: Large language models (LLMs) are increasingly applied in biomedical domains,
yet their reliability in drug-safety prediction remains underexplored. In this
work, we investigate whether LLMs incorporate socio-demographic information
into adverse event (AE) predictions, despite such attributes being clinically
irrelevant. Using structured data from the United States Food and Drug
Administration Adverse Event Reporting System (FAERS) and a persona-based
evaluation framework, we assess two state-of-the-art models, ChatGPT-4o and
Bio-Medical-Llama-3.8B, across diverse personas defined by education, marital
status, employment, insurance, language, housing stability, and religion. We
further evaluate performance across three user roles (general practitioner,
specialist, patient) to reflect real-world deployment scenarios where
commercial systems often differentiate access by user type. Our results reveal
systematic disparities in AE prediction accuracy. Disadvantaged groups (e.g.,
low education, unstable housing) were frequently assigned higher predicted AE
likelihoods than more privileged groups (e.g., postgraduate-educated, privately
insured). Beyond outcome disparities, we identify two distinct modes of bias:
explicit bias, where incorrect predictions directly reference persona
attributes in reasoning traces, and implicit bias, where predictions are
inconsistent, yet personas are not explicitly mentioned. These findings expose
critical risks in applying LLMs to pharmacovigilance and highlight the urgent
need for fairness-aware evaluation protocols and mitigation strategies before
clinical deployment.

</details>


### [158] [Big Reasoning with Small Models: Instruction Retrieval at Inference Time](https://arxiv.org/abs/2510.13935)
*Kenan Alkiek,David Jurgens,Vinod Vydiswaran*

Main category: cs.CL

TL;DR: 小型语言模型（SLMs）通过推理时指令检索得到增强，能够在本地高效运行并处理需要多步推理的任务。


<details>
  <summary>Details</summary>
Motivation: 旨在解决小型语言模型（SLMs）在处理需要多步推理或领域知识的任务时表现不佳的问题，同时利用其高效、隐私、低成本和环保的优势。

Method: 构建了一个指令语料库，对相似的训练问题进行分组，并使用GPT-5创建指令。在推理时，SLM检索最相关的指令并遵循其步骤，这是一种指令检索方法，而非生成方法。

Result: 在MedQA、MMLU Professional Law和MathQA数据集上，使用3B到14B参数的模型进行评估，无需额外微调。该方法在MedQA上提高了9.4%，在MMLU Law上提高了7.9%，在MathQA上提高了5.1%。

Conclusion: 指令检索能够有效提升小型语言模型的推理能力，并且简洁的指令比冗长的指令效果更好。性能提升的幅度很大程度上取决于模型家族和模型的内在推理能力。

Abstract: Can we bring large-scale reasoning to local-scale compute? Small language
models (SLMs) are increasingly attractive because they run efficiently on local
hardware, offering strong privacy, low cost, and reduced environmental impact.
Yet they often struggle with tasks that require multi-step reasoning or
domain-specific knowledge. We address this limitation through instruction
intervention at inference time, where an SLM retrieves structured reasoning
procedures rather than generating them from scratch. Our method builds an
Instruction Corpus by grouping similar training questions and creating
instructions via GPT-5. During inference, the SLM retrieves the most relevant
instructions and follows their steps. Unlike retrieval-augmented generation,
which retrieves text passages, instruction retrieval gives the model structured
guidance for reasoning. We evaluate this framework on MedQA (medical board
exams), MMLU Professional Law, and MathQA using models from 3B to 14B
parameters without any additional fine-tuning. Instruction retrieval yields
consistent gains: 9.4% on MedQA, 7.9% on MMLU Law, and 5.1% on MathQA. Concise
instructions outperform longer ones, and the magnitude of improvement depends
strongly on model family and intrinsic reasoning ability.

</details>


### [159] [FinDeepResearch: Evaluating Deep Research Agents in Rigorous Financial Analysis](https://arxiv.org/abs/2510.13936)
*Fengbin Zhu,Xiang Yao Ng,Ziyang Liu,Chang Liu,Xianwei Zeng,Chao Wang,Tianhui Tan,Xuan Yao,Pengyang Shao,Min Xu,Zixuan Wang,Jing Wang,Xin Lin,Junfeng Li,Jingxian Zhu,Yang Zhang,Wenjie Wang,Fuli Feng,Richang Hong,Huanbo Luan,Ke-Wei Huang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本论文提出了一个用于评估深度研究（DR）代理在公司金融分析方面能力的框架 HisRubric 和一个名为 FinDeepResearch 的基准测试集。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对深度研究（DR）代理在关键研究分析能力方面的系统性评估，因此需要一个严格的评估框架。

Method: 提出 HisRubric 评估框架，该框架具有分层分析结构和细粒度评分标准，以评估 DR 代理在公司金融分析中的能力。在此基础上，构建了 FinDeepResearch 基准测试集，包含 64 家公司、8 个金融市场和 4 种语言，共 15,808 个评分项。使用 16 种代表性方法（包括 6 种 DR 代理、5 种具备深度推理和搜索能力的 LLM，以及 5 种仅具备深度推理能力的 LLM）在 FinDeepResearch 上进行了广泛的实验。

Result: 实验结果揭示了不同方法在不同能力、金融市场和语言方面的优势和局限性。

Conclusion: 所提出的 FinDeepResearch 基准测试集和评估代码将公开提供，为未来 DR 代理在公司金融分析领域的研究和发展提供有价值的见解。

Abstract: Deep Research (DR) agents, powered by advanced Large Language Models (LLMs),
have recently garnered increasing attention for their capability in conducting
complex research tasks. However, existing literature lacks a rigorous and
systematic evaluation of DR Agent's capabilities in critical research analysis.
To address this gap, we first propose HisRubric, a novel evaluation framework
with a hierarchical analytical structure and a fine-grained grading rubric for
rigorously assessing DR agents' capabilities in corporate financial analysis.
This framework mirrors the professional analyst's workflow, progressing from
data recognition to metric calculation, and finally to strategic summarization
and interpretation. Built on this framework, we construct a FinDeepResearch
benchmark that comprises 64 listed companies from 8 financial markets across 4
languages, encompassing a total of 15,808 grading items. We further conduct
extensive experiments on the FinDeepResearch using 16 representative methods,
including 6 DR agents, 5 LLMs equipped with both deep reasoning and search
capabilities, and 5 LLMs with deep reasoning capabilities only. The results
reveal the strengths and limitations of these approaches across diverse
capabilities, financial markets, and languages, offering valuable insights for
future research and development. The benchmark and evaluation code will be made
publicly available.

</details>


### [160] [Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers](https://arxiv.org/abs/2510.13939)
*Tuhin Chakrabarty,Jane C. Ginsburg,Paramveer Dhillon*

Main category: cs.CL

TL;DR: AI模型在模仿作家风格方面，经过特定作者作品微调后表现优于人类作家，但未经微调的AI文本则表现不佳，且微调后的文本难以被识别为AI生成。


<details>
  <summary>Details</summary>
Motivation: 评估AI模型在模仿作家风格和文学写作质量方面的能力，以及这些能力与当前围绕AI训练数据（尤其是受版权保护的书籍）的法律纠纷的关系。

Method: 通过盲审比较了由MFA（精细艺术硕士）培训的专家作家和三个前沿AI模型（ChatGPT、Claude和Gemini）在模仿50位获奖作家风格方面写作的文本。评估者包括专家和普通读者，他们对文本风格的忠实度和写作质量进行了评分。研究还探讨了通过对单个作者的完整作品进行微调如何改变AI文本的表现，并分析了AI风格的细微差别。

Result: 未经微调的AI文本在专家读者中风格忠实度和写作质量方面均表现不佳。然而，在ChatGPT使用特定作者作品进行微调后，AI生成的文本在专家读者中获得了更高的风格忠实度和写作质量评分。普通读者的评价也显示出类似的变化。微调后的AI文本识别率很低，且成本显著低于人类作家。微调通过消除AI特有的风格痕迹（如陈词滥调的密度）来提高文本质量。

Conclusion: 作者认为，通过针对特定作家作品进行微调，AI可以生成在风格和质量上都优于人类专家的文本，这为AI在版权相关问题（特别是‘对源作品的市场或价值产生的影响’这一因素）上提供了新的视角。

Abstract: The use of copyrighted books for training AI models has led to numerous
lawsuits from authors concerned about AI's ability to generate derivative
content.Yet it's unclear whether these models can generate high quality
literary text while emulating authors' styles. To answer this we conducted a
preregistered study comparing MFA-trained expert writers with three frontier AI
models: ChatGPT, Claude & Gemini in writing up to 450 word excerpts emulating
50 award-winning authors' diverse styles. In blind pairwise evaluations by 159
representative expert & lay readers, AI-generated text from in-context
prompting was strongly disfavored by experts for both stylistic fidelity
(OR=0.16, p<10^8) & writing quality (OR=0.13, p<10^7) but showed mixed results
with lay readers. However, fine-tuning ChatGPT on individual authors' complete
works completely reversed these findings: experts now favored AI-generated text
for stylistic fidelity (OR=8.16, p<10^13) & writing quality (OR=1.87, p=0.010),
with lay readers showing similar shifts. These effects generalize across
authors & styles. The fine-tuned outputs were rarely flagged as AI-generated
(3% rate v. 97% for in-context prompting) by best AI detectors. Mediation
analysis shows this reversal occurs because fine-tuning eliminates detectable
AI stylistic quirks (e.g., cliche density) that penalize in-context outputs.
While we do not account for additional costs of human effort required to
transform raw AI output into cohesive, publishable prose, the median
fine-tuning & inference cost of $81 per author represents a dramatic 99.7%
reduction compared to typical professional writer compensation. Author-specific
fine-tuning thus enables non-verbatim AI writing that readers prefer to expert
human writing, providing empirical evidence directly relevant to copyright's
fourth fair-use factor, the "effect upon the potential market or value" of the
source works.

</details>


### [161] [Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention](https://arxiv.org/abs/2510.13940)
*Zhen Yang,Mingyang Zhang,Feng Chen,Ganggui Ding,Liang Hou,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CL

TL;DR: LLM推理中的不确定性主要集中在少数高熵标记上，MTI通过选择性干预和轻量级负提示引导来提高推理准确性和稳定性，同时保持高效率。


<details>
  <summary>Details</summary>
Motivation: LLM在推理过程中，尤其是测试时，虽然可以通过增加计算量来提升推理能力，但往往会牺牲效率。本文旨在解决这一问题，通过分析发现推理的不确定性高度局部化，少数高熵标记对输出的正确性起着主导作用。

Method: 提出了一种名为最小测试时干预（MTI）的无需训练框架。MTI包含两个关键部分：1. 选择性条件判别与反事实生成（CFG）干预：仅在检测到不确定性的位置应用CFG。2. 轻量级负提示引导：通过复用主模型的键值（KV）缓存来高效地近似无条件解码。

Result: MTI在通用、代码和STEM任务上实现了持续的性能提升。具体而言，在Qwen3-8B-Base模型上，8个基准测试的平均准确率提升了1.35%；在使用Qwen3-32B-Reasoning模型时，AIME2024的准确率提升了5%。同时，MTI保持了高效率。

Conclusion: MTI是一种高效的、无需训练的框架，通过识别并干预LLM推理过程中的关键不确定性点，能够显著提高模型在多种推理任务上的准确性和稳定性，且计算开销极小。

Abstract: Recent progress in large language models (LLMs) has focused on test-time
scaling to improve reasoning via increased inference computation, but often at
the cost of efficiency. We revisit test-time behavior and uncover a simple yet
underexplored phenomenon: reasoning uncertainty is highly localized-only a
small subset of high-entropy tokens dominantly affects output correctness.
Motivated by this, we propose Minimal Test-Time Intervention (MTI), a
training-free framework that enhances reasoning accuracy and stability with
minimal overhead. MTI includes: (i) Selective CFG intervention, applying
classifier-free guidance only at uncertain positions; and (ii) Lightweight
negative-prompt guidance, reusing the main model's KV cache to approximate
unconditional decoding efficiently. MTI yields consistent gains across general,
coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for
Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining
highly efficient.

</details>


### [162] [Classifying and Addressing the Diversity of Errors in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.13975)
*Kin Kwan Leung,Mouloud Belbahri,Yi Sui,Alex Labach,Xueying Zhang,Stephen Rose,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本文提出了一个用于检索增强生成（RAG）系统错误类型的分类法，并提供了一个包含错误示例和缓解策略的数据集，以及一个用于自动评估错误的框架。


<details>
  <summary>Details</summary>
Motivation: 现实世界的 RAG 系统复杂多样，可能出现多种错误。理解这些错误对于 RAG 系统的鲁棒部署至关重要。

Method: 本文构建了一个包含 RAG 错误类型的分类法，并提供了相应的示例。同时，他们还收集了一个标注有错误类型的 RAG 错误响应数据集，并提出了一个与该分类法一致的自动评估方法。

Result: 本文提出了一个 RAG 错误分类法，并构建了一个包含错误示例和缓解策略的数据集。此外，他们还开发了一个自动评估方法，可以帮助开发者在开发过程中追踪和解决 RAG 系统中的错误。

Conclusion: 通过提出的错误分类法、数据集和自动评估方法，可以更好地理解和解决 RAG 系统中的错误，从而提高其鲁棒性和可靠性。

Abstract: Retrieval-augmented generation (RAG) is a prevalent approach for building
LLM-based question-answering systems that can take advantage of external
knowledge databases. Due to the complexity of real-world RAG systems, there are
many potential causes for erroneous outputs. Understanding the range of errors
that can occur in practice is crucial for robust deployment. We present a new
taxonomy of the error types that can occur in realistic RAG systems, examples
of each, and practical advice for addressing them. Additionally, we curate a
dataset of erroneous RAG responses annotated by error types. We then propose an
auto-evaluation method aligned with our taxonomy that can be used in practice
to track and address errors during development. Code and data are available at
https://github.com/layer6ai-labs/rag-error-classification.

</details>


### [163] [The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models](https://arxiv.org/abs/2510.13996)
*Lukas Gienapp,Christopher Schröder,Stefan Schweter,Christopher Akiki,Ferdinand Schlatt,Arden Zimmermann,Phillipe Genêt,Martin Potthast*

Main category: cs.CL

TL;DR: 该论文介绍了“德语共同体”数据集，解决了德语开放许可文本稀缺的问题，为训练开放的德语语言模型提供了支持。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型训练依赖大量数据，但现有数据多为许可状态不明，限制了真正开放模型的开发，尤其在非英语语言方面，开放许可文本尤为稀缺。

Method: 构建了“德语共同体”数据集，这是迄今为止最大的开放许可德语文本集合。该数据集整合了来自七个领域（法律、科学、文化、政治、新闻、经济和网络文本）的41个来源的数据，总量达1545.6亿亿字符。通过系统性地从具有可验证许可的数据提供商处搜集，并实施全面的质量过滤、去重和文本格式修复流程，确保了数据集的高质量和一致性。所有子集均采用至少CC-BY-SA 4.0或同等许可。

Result: “德语共同体”数据集包含了1545.6亿亿字符的高质量德语文本，所有文本均具有开放许可（至少CC-BY-SA 4.0或同等许可），并附带了数据集构建和数据过滤的代码，确保了其可复现性和可扩展性。

Conclusion: “德语共同体”数据集解决了开放许可德语预训练数据严重缺失的问题，使得开发真正开放的德语语言模型成为可能。该数据集的发布以及相关代码的公开，为德语自然语言处理领域的研究和应用提供了重要的基础资源。

Abstract: Large language model development relies on large-scale training corpora, yet
most contain data of unclear licensing status, limiting the development of
truly open models. This problem is exacerbated for non-English languages, where
openly licensed text remains critically scarce. We introduce the German
Commons, the largest collection of openly licensed German text to date. It
compiles data from 41 sources across seven domains, encompassing legal,
scientific, cultural, political, news, economic, and web text. Through
systematic sourcing from established data providers with verifiable licensing,
it yields 154.56 billion tokens of high-quality text for language model
training. Our processing pipeline implements comprehensive quality filtering,
deduplication, and text formatting fixes, ensuring consistent quality across
heterogeneous text sources. All domain subsets feature licenses of at least
CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and
redistribution. The German Commons therefore addresses the critical gap in
openly licensed German pretraining data, and enables the development of truly
open German language models. We also release code for corpus construction and
data filtering tailored to German language text, rendering the German Commons
fully reproducible and extensible.

</details>


### [164] [CRaFT: An Explanation-Based Framework for Evaluating Cultural Reasoning in Multilingual Language Models](https://arxiv.org/abs/2510.14014)
*Shehenaz Hossain,Haithem Afli*

Main category: cs.CL

TL;DR: CRaFT是一个评估大型语言模型（LLM）跨文化推理能力的框架，通过评估答案的解释（包括文化流畅度、偏差、一致性和语言适应性）而非仅仅准确性，来衡量模型在不同文化背景下的表现。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在跨文化背景下的推理能力，认识到仅仅正确回答问题不足以体现文化理解。

Method: 提出CRaFT框架，包含四个可解释的评估指标：文化流畅度、偏差、一致性和语言适应性。将该框架应用于世界价值观调查的50个文化相关问题（翻译成阿拉伯语、孟加拉语和西班牙语），并评估了三个模型（GPT、DeepSeek和FANAR）的2100多个答案-解释对。

Result: 结果显示，阿拉伯语降低了模型的文化流畅度，孟加拉语则提高了流畅度，西班牙语则基本保持稳定。GPT模型在跨语言适应性方面表现更好，但一致性较低；FANAR模型表现稳定但推理较为刻板。

Conclusion: 文化意识并非LLM的内在属性，而是通过语言框架产生的。CRaFT提供了一种评估多语言环境中跨文化推理的新视角，为构建文化适应性语言模型提供了可行的见解。

Abstract: Correct answers do not necessarily reflect cultural understanding. We
introduce CRaFT, an explanation-based multilingual evaluation framework
designed to assess how large language models (LLMs) reason across cultural
contexts. Rather than scoring outputs solely based on accuracy, CRaFT evaluates
model explanations using four interpretable metrics: Cultural Fluency,
Deviation, Consistency, and Linguistic Adaptation. We apply the framework to 50
culturally grounded questions from the World Values Survey, translated into
Arabic, Bengali, and Spanish, and evaluate three models (GPT, DeepSeek, and
FANAR) across over 2,100 answer-explanation pairs. Results reveal significant
cross-lingual variation in reasoning: Arabic reduces fluency, Bengali enhances
it, and Spanish remains largely stable. While GPT adapts more effectively
across languages, it exhibits lower consistency; FANAR shows stable but rigid
reasoning. These findings suggest that cultural awareness in LLMs is not
intrinsic but emerges through linguistic framing. CRaFT offers a new lens for
evaluating cross-cultural reasoning in multilingual settings, providing
actionable insights for building culturally adaptive language models.

</details>


### [165] [Think Globally, Group Locally: Evaluating LLMs Using Multi-Lingual Word Grouping Games](https://arxiv.org/abs/2510.14030)
*César Guerra-Solano,Zhuochun Li,Xiang Lorraine Li*

Main category: cs.CL

TL;DR: LLMs在抽象推理任务中存在语言偏见，在英语中表现更好，并且开源和闭源模型之间存在性能差异。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在抽象推理任务中的语言偏见，并提出了一种新的评估方法。以往的研究主要集中在常识和数学推理任务，而忽略了对抽象推理的评估。本研究旨在填补这一空白，并为语言偏见的研究提供新的视角。

Method: 提出了一种名为GlobalGroup的游戏基准，该基准包含五种语言（英语、西班牙语、中文、印地语和阿拉伯语）及其对应的英语翻译。该基准还包括游戏难度测量方法，以确保不同语言之间进行可控的比较。通过实验评估了不同模型在基准上的表现。

Result: 实验结果表明，LLMs在抽象推理任务中普遍在英语环境下表现更好，并且开源模型和闭源模型之间存在性能差距。

Conclusion: LLMs在抽象推理任务中存在显著的语言偏见，英语的优势明显。此外，开源模型和闭源模型在处理这类任务时也表现出不同的能力。本研究提出的GlobalGroup基准和难度测量方法为未来评估LLMs的抽象推理能力和语言偏见提供了有价值的工具。

Abstract: Large language models (LLMs) can exhibit biases in reasoning capabilities due
to linguistic modality, performing better on tasks in one language versus
another, even with similar content. Most previous works evaluate this through
reasoning tasks where reliance on strategies or knowledge can ensure success,
such as in commonsense or math tasks. However, abstract reasoning is vital to
reasoning for everyday life, where people apply "out-of-the-box thinking" to
identify and use patterns for solutions, without a reliance on formulaic
approaches. Comparatively, little work has evaluated linguistic biases in this
task type. In this paper, we propose a task inspired by the New York Times
Connections: GlobalGroup, that evaluates models in an abstract reasoning task
across several languages. We constructed a game benchmark with five linguistic
backgrounds -- English, Spanish, Chinese, Hindi, and Arabic -- in both the
native language and an English translation for comparison. We also proposed
game difficulty measurements to evaluate models on games with similar
difficulty, enabling a more controlled comparison, which is particularly
important in reasoning evaluations. Through experimentation, we find English
modalities largely lead to better performance in this abstract reasoning task,
and performance disparities between open- and closed-source models.

</details>


### [166] [Quantifying Phonosemantic Iconicity Distributionally in 6 Languages](https://arxiv.org/abs/2510.14040)
*George Flint,Kaustubh Kislay*

Main category: cs.CL

TL;DR: 大规模量化研究表明，不同语言中存在系统性的语音-语义关联，部分现象此前未被发现。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究语音-语义之间系统性关联在多语言大规模量化研究中的体现程度，包括已识别和未识别的现象。

Method: 本研究采用分布化方法，对6种不同语言（英语、西班牙语、印地语、芬兰语、土耳其语和泰米尔语）的语音-语义图标性进行量化。研究分析了词缀的语音和语义相似度空间与一系列统计测度之间的对齐情况。

Result: 研究发现了大量可解释的语音-语义对齐现象，其中一些此前未在文献中被识别，并揭示了跨语言的模式。同时，研究也分析了5个先前假设的语音-语义对齐现象，部分得到了证实，部分结果不一。

Conclusion: 大规模的量化分析证实了语音-语义关联的存在，并发现了新的现象和跨语言模式，同时也对先前的一些假设进行了检验。

Abstract: Language is, as commonly theorized, largely arbitrary. Yet, systematic
relationships between phonetics and semantics have been observed in many
specific cases. To what degree could those systematic relationships manifest
themselves in large scale, quantitative investigations--both in previously
identified and unidentified phenomena? This work undertakes a distributional
approach to quantifying phonosemantic iconicity at scale across 6 diverse
languages (English, Spanish, Hindi, Finnish, Turkish, and Tamil). In each
language, we analyze the alignment of morphemes' phonetic and semantic
similarity spaces with a suite of statistical measures, and discover an array
of interpretable phonosemantic alignments not previously identified in the
literature, along with crosslinguistic patterns. We also analyze 5 previously
hypothesized phonosemantic alignments, finding support for some such alignments
and mixed results for others.

</details>


### [167] [ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models](https://arxiv.org/abs/2510.14077)
*Haziq Mohammad Khalid,Athikash Jeyaganthan,Timothy Do,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: LLMs在多轮对话中因信息增量式输入而性能下降。ERGO通过计算香农熵来量化模型不确定性，并在检测到熵值急剧上升时触发自适应提示巩固，从而提高对话AI的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多轮对话中，当信息是逐步提供时，性能会显著下降，这对其在日常交互中的实际应用构成了严峻挑战。

Method: ERGO（Entropy-guided Resetting for Generation Optimization）通过计算下一个词语分布的香农熵来持续量化内部不确定性，并在检测到熵值急剧上升时触发自适应提示巩固。

Result: 在逐步揭示指令的多轮任务中，ERGO比标准基线平均提高了56.6%的性能，提高了24.7%的能力（峰值性能），并降低了35.3%的不可靠性（性能变化）。

Conclusion: 通过将不确定性作为一等信号而非消除的干扰，ERGO拥抱语言和建模中的可变性，代表并响应不确定性，从而提高对话AI的准确性和可靠性。

Abstract: Large Language Models (LLMs) suffer significant performance degradation in
multi-turn conversations when information is presented incrementally. Given
that multi-turn conversations characterize everyday interactions with LLMs,
this degradation poses a severe challenge to real world usability. We
hypothesize that abrupt increases in model uncertainty signal misalignment in
multi-turn LLM interactions, and we exploit this insight to dynamically realign
conversational context. We introduce ERGO (Entropy-guided Resetting for
Generation Optimization), which continuously quantifies internal uncertainty
via Shannon entropy over next token distributions and triggers adaptive prompt
consolidation when a sharp spike in entropy is detected. By treating
uncertainty as a first class signal rather than a nuisance to eliminate, ERGO
embraces variability in language and modeling, representing and responding to
uncertainty. In multi-turn tasks with incrementally revealed instructions, ERGO
yields a 56.6% average performance gain over standard baselines, increases
aptitude (peak performance capability) by 24.7%, and decreases unreliability
(variability in performance) by 35.3%, demonstrating that uncertainty aware
interventions can improve both accuracy and reliability in conversational AI.

</details>


### [168] [DROID: Dual Representation for Out-of-Scope Intent Detection](https://arxiv.org/abs/2510.14110)
*Wael Rashwan,Hossam M. Zawbaa,Sourav Dutta,Haytham Assem*

Main category: cs.CL

TL;DR: DROID是一个端到端的框架，结合了通用句子编码器（USE）和领域自适应的基于Transformer的去噪自编码器（TSDAE），用于检测不在此范围内的（OOS）用户意图，并在有限的监督下通过合成和开放域异常值增强来提高边界学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有的不在此范围内的（OOS）用户意图检测方法通常依赖于强的分布假设或辅助校准模块，而DROID旨在提供一个更简洁、端到端的框架。

Method: DROID结合了通用句子编码器（USE）和领域自适应的Transformer-based Denoising Autoencoder（TSDAE）的互补编码器，并通过一个轻量级的分支分类器进行处理，该分类器具有一个单一的校准阈值来区分在此范围内的意图和OOS意图。此外，DROID还引入了合成和开放域异常值增强来提高边界学习能力。

Result: DROID的参数量仅为150万，但却在多个意图基准测试中持续优于最新的基线方法，在已知意图方面实现了6-15%的宏观F1改进，在OOS意图方面实现了8-20%的改进，尤其是在低资源设置下取得了显著的提升。

Conclusion: 双编码器表示结合简单的校准可以为神经网络对话系统提供强大、可扩展且可靠的OOS检测能力。

Abstract: Detecting out-of-scope (OOS) user utterances remains a key challenge in
task-oriented dialogue systems and, more broadly, in open-set intent
recognition. Existing approaches often depend on strong distributional
assumptions or auxiliary calibration modules. We present DROID (Dual
Representation for Out-of-Scope Intent Detection), a compact end-to-end
framework that combines two complementary encoders -- the Universal Sentence
Encoder (USE) for broad semantic generalization and a domain-adapted
Transformer-based Denoising Autoencoder (TSDAE) for domain-specific contextual
distinctions. Their fused representations are processed by a lightweight
branched classifier with a single calibrated threshold that separates in-domain
and OOS intents without post-hoc scoring. To enhance boundary learning under
limited supervision, DROID incorporates both synthetic and open-domain outlier
augmentation. Despite using only 1.5M trainable parameters, DROID consistently
outperforms recent state-of-the-art baselines across multiple intent
benchmarks, achieving macro-F1 improvements of 6--15% for known and 8--20% for
OOS intents, with the most significant gains in low-resource settings. These
results demonstrate that dual-encoder representations with simple calibration
can yield robust, scalable, and reliable OOS detection for neural dialogue
systems.

</details>


### [169] [Toward Cybersecurity-Expert Small Language Models](https://arxiv.org/abs/2510.14113)
*Matan Levi,Daniel Ohayon,Ariel Blobstein,Ravid Sagi,Ian Molloy,Yair Allouche*

Main category: cs.CL

TL;DR: 网络安全领域LLM部署受限于领域模型和数据集的缺乏，CyberPal 2.0是解决此问题的SLM系列（4B-20B参数）。


<details>
  <summary>Details</summary>
Motivation: LLM在日常应用中变革巨大，但在网络安全领域的部署滞后，原因是缺乏高质量、特定领域的模型和训练数据集。

Method: 通过SecKnowledge 2.0数据处理流程，构建了包含专家指导的推理格式和LLM驱动的多步基础的网络安全指令数据集，用于训练CyberPal 2.0 SLM。

Result: CyberPal 2.0在各种网络安全基准测试中表现优于基线模型，并且在保持较小规模的同时，能够媲美或超越多个开放和封闭的先进模型。在网络威胁情报知识任务上，CyberPal 2.0表现仅次于Sec-Gemini v1；在威胁调查任务上，其20B模型性能超越GPT-4o等模型，排名第一，4B模型排名第二。

Conclusion: CyberPal 2.0 系列SLM在网络安全任务中展现出强大的性能，解决了领域内LLM部署的挑战。

Abstract: Large language models (LLMs) are transforming everyday applications, yet
deployment in cybersecurity lags due to a lack of high-quality, domain-specific
models and training datasets. To address this gap, we present CyberPal 2.0, a
family of cybersecurity-expert small language models (SLMs) ranging from 4B-20B
parameters. To train CyberPal 2.0, we generate an enriched chain-of-thought
cybersecurity instruction dataset built with our data enrichment and formatting
pipeline, SecKnowledge 2.0, which integrates expert-in-the-loop steering of
reasoning formats alongside LLM-driven multi-step grounding, yielding
higher-fidelity, task-grounded reasoning traces for security tasks. Across
diverse cybersecurity benchmarks, CyberPal 2.0 consistently outperforms its
baselines and matches or surpasses various open and closed-source frontier
models, while remaining a fraction of their size. On core cyber threat
intelligence knowledge tasks, our models outperform almost all tested frontier
models, ranking second only to Sec-Gemini v1. On core threat-investigation
tasks, such as correlating vulnerabilities and bug tickets with weaknesses, our
best 20B-parameter model outperforms GPT-4o, o1, o3-mini, and Sec-Gemini v1,
ranking first, while our smallest 4B-parameter model ranks second.

</details>


### [170] [Building a Macedonian Recipe Dataset: Collection, Parsing, and Comparative Analysis](https://arxiv.org/abs/2510.14128)
*Darko Sasanski,Dimitar Peshevski,Riste Stojanov,Dimitar Trajanov*

Main category: cs.CL

TL;DR: 本研究构建了首个马其顿菜谱数据集，解决了数据处理中的异构性问题，并通过探索性分析揭示了马其顿菜肴的独特风味特征。


<details>
  <summary>Details</summary>
Motivation: 由于马其顿菜谱在数字研究中代表性不足，本研究旨在构建一个高质量的马其顿菜谱数据集，以促进对代表性不足的语言的饮食文化的学习。

Method: 通过网络爬虫和结构化解析技术构建数据集，并处理了包括单位、数量和描述符在内的异构成分描述的标准化问题。使用点互信息和提升度得分等度量方法进行探索性分析，以识别区分马其顿菜肴的成分组合。

Result: 构建了一个马其顿菜谱数据集，并进行了探索性分析，揭示了成分频率和共现模式，突出了马其顿菜肴的独特成分组合。

Conclusion: 该数据集为研究饮食文化提供了新的资源，并揭示了马其顿烹饪传统的独特模式。

Abstract: Computational gastronomy increasingly relies on diverse, high-quality recipe
datasets to capture regional culinary traditions. Although there are
large-scale collections for major languages, Macedonian recipes remain
under-represented in digital research. In this work, we present the first
systematic effort to construct a Macedonian recipe dataset through web scraping
and structured parsing. We address challenges in processing heterogeneous
ingredient descriptions, including unit, quantity, and descriptor
normalization. An exploratory analysis of ingredient frequency and
co-occurrence patterns, using measures such as Pointwise Mutual Information and
Lift score, highlights distinctive ingredient combinations that characterize
Macedonian cuisine. The resulting dataset contributes a new resource for
studying food culture in underrepresented languages and offers insights into
the unique patterns of Macedonian culinary tradition.

</details>


### [171] [RLSR: Reinforcement Learning with Supervised Reward Outperforms SFT in Instruction Following](https://arxiv.org/abs/2510.14200)
*Zhichao Wang,Andy Wong,Ruslan Belkin*

Main category: cs.CL

TL;DR: RLSR通过在强化学习框架中利用SFT数据集，在指令遵循能力上超越了SFT。


<details>
  <summary>Details</summary>
Motivation: 为了提升LLM的指令遵循能力，并借鉴RFT的思路，提出RLSR来利用现有的SFT数据集。

Method: RLSR通过计算生成响应与人类标注响应在语义嵌入空间中的余弦相似度来获得奖励分数，并以此来优化模型。

Result: RLSR在指令遵循基准测试中表现优于SFT，例如在Qwen-7B（INFINITY）上，RLSR（SB）的AlpacaEval胜率达到26.34%，高于SFT的21.01%。结合SFT和RLSR的训练方式进一步提高了性能，胜率达到30.73%。

Conclusion: RLSR是一种有效的方法，可以直接替代SFT或与SFT结合使用，以提升LLM的指令遵循能力。

Abstract: After the pretraining stage of LLMs, techniques such as SFT, RLHF, RLVR, and
RFT are applied to enhance instruction-following ability, mitigate undesired
responses, improve reasoning capability and enable efficient domain adaptation
with minimal data. SFT relies on the next-token prediction objective to
strengthen instruction following in a base model using a large corpus of
human-labeled responses. In contrast, RFT employs a RL-based approach to adapt
fine-tuned reasoning models to specific domains with limited supervision.
Inspired by RFT, we propose replacing SFT with RLSR to leverage the extensive
SFT dataset in an RL framework, thereby improving the base model's
instruction-following ability. In RLSR, the base model generates multiple
responses for each prompt, and reward scores are computed as the cosine
similarity in the semantic embedding space between the generated and
human-labeled responses. RLSR can be utilized in multiple ways. It can directly
replace SFT, achieving superior performance on instruction-following
benchmarks-for example, RLSR (SB) on Qwen-7B (INFINITY) achieved an AlpacaEval
win rate of 26.34%, surpassing SFT's 21.01%. Furthermore, combining SFT and
RLSR further enhances downstream task performance; Qwen-7B (INFINITY) achieved
a win rate of 30.73% when trained with SFT + RLSR.

</details>


### [172] [DPRF: A Generalizable Dynamic Persona Refinement Framework for Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents and Humans](https://arxiv.org/abs/2510.14205)
*Bingsheng Yao,Bo Sun,Yuanzhe Dong,Yuxuan Lu,Dakuo Wang*

Main category: cs.CL

TL;DR: LLM RPAs 旨在模拟人类行为，但手动创建的 persona 存在偏差。本研究提出动态 Persona 精炼框架 (DPRF)，通过识别和缩小 LLM RPA 行为与人类真实行为之间的认知差距来优化 Persona 对齐。DPRF 在多种场景和模型上均能有效提升行为对齐度。


<details>
  <summary>Details</summary>
Motivation: 手动创建的 LLM RPA persona 存在偏差，未能准确反映目标个体。本研究旨在通过 DPRF 框架优化 LLM RPA 的行为与目标个体行为的对齐程度。

Method: DPRF 框架通过迭代识别 LLM RPA 生成的行为与人类真实行为之间的认知差距（通过自由形式或结构化分析），并调整 persona 描述文件以缩小这种差距。

Result: DPRF 在五种不同的 LLM 和四种行为预测场景（正式辩论、社交媒体心理健康帖子、公开采访、电影评论）中进行了评估。结果表明，DPRF 能够持续显著地提升行为对齐度，并且在不同模型和场景下都具有良好的泛化能力。

Conclusion: DPRF 提供了一种创建高保真 persona 描述文件和提高下游应用（如用户模拟、社会研究、个性化 AI）有效性的鲁棒方法。

Abstract: The emerging large language model role-playing agents (LLM RPAs) aim to
simulate individual human behaviors, but the persona fidelity is often
undermined by manually-created profiles (e.g., cherry-picked information and
personality characteristics) without validating the alignment with the target
individuals. To address this limitation, our work introduces the Dynamic
Persona Refinement Framework (DPRF).DPRF aims to optimize the alignment of LLM
RPAs' behaviors with those of target individuals by iteratively identifying the
cognitive divergence, either through free-form or theory-grounded, structured
analysis, between generated behaviors and human ground truth, and refining the
persona profile to mitigate these divergences.We evaluate DPRF with five LLMs
on four diverse behavior-prediction scenarios: formal debates, social media
posts with mental health issues, public interviews, and movie reviews.DPRF can
consistently improve behavioral alignment considerably over baseline personas
and generalizes across models and scenarios.Our work provides a robust
methodology for creating high-fidelity persona profiles and enhancing the
validity of downstream applications, such as user simulation, social studies,
and personalized AI.

</details>


### [173] [LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning](https://arxiv.org/abs/2510.14211)
*Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: LiteStage通过在多阶段推理中进行逐阶段的离线搜索和基于置信度的在线生成来提前退出，以提高效率，同时最大限度地减少准确性损失。


<details>
  <summary>Details</summary>
Motivation: 现有的自适应加速技术（如层跳跃）在多阶段推理中难以平衡效率和准确性，因为存在阶段性跳跃敏感度变化和冗余输出令牌生成这两个关键挑战。

Method: LiteStage是一个面向多阶段推理的延迟感知层跳跃框架。它结合了逐阶段的离线搜索（为每个阶段分配最优的层预算）和基于置信度的在线生成提前退出机制，以抑制不必要的解码。

Result: 在OBQA、CSQA和StrategyQA三个基准测试上，LiteStage实现了高达1.70倍的加速，准确性损失小于4.0%，优于现有的无需训练的层跳跃方法。

Conclusion: LiteStage能够有效解决多阶段推理中的效率和准确性权衡问题，并在多个基准测试中取得了优于现有方法的性能。

Abstract: Multi-stage reasoning has emerged as an effective strategy for enhancing the
reasoning capability of small language models by decomposing complex problems
into sequential sub-stages. However, this comes at the cost of increased
latency. We observe that existing adaptive acceleration techniques, such as
layer skipping, struggle to balance efficiency and accuracy in this setting due
to two key challenges: (1) stage-wise variation in skip sensitivity, and (2)
the generation of redundant output tokens. To address these, we propose
LiteStage, a latency-aware layer skipping framework for multi-stage reasoning.
LiteStage combines a stage-wise offline search that allocates optimal layer
budgets with an online confidence-based generation early exit to suppress
unnecessary decoding. Experiments on three benchmarks, e.g., OBQA, CSQA, and
StrategyQA, show that LiteStage achieves up to 1.70x speedup with less than
4.0% accuracy loss, outperforming prior training-free layer skipping methods.

</details>


### [174] [Flip-Flop Consistency: Unsupervised Training for Robustness to Prompt Perturbations in LLMs](https://arxiv.org/abs/2510.14242)
*Parsa Hejabi,Elnaz Rahmati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: Flip-Flop Consistency (F^2C) 是一种无监督训练方法，通过共识交叉熵和表示对齐损失来提高大型语言模型 (LLM) 对提示扰动的鲁棒性，从而提高一致性、性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 在面对相同提示的不同表述时，常常会产生不一致的答案。

Method: F^2C 包含两个主要组件：共识交叉熵 (CCE)，它使用对提示变体的多数投票来创建硬伪标签；以及表示对齐损失，它将低置信度和非多数预测器拉向高置信度、多数投票变体所建立的共识。

Result: 在 11 个数据集和 4 种 NLP 任务上的评估显示，F^2C 平均提高了 11.62% 的观察一致性，提高了 8.94% 的平均 F1 分数，并降低了 3.29% 的跨格式性能方差。在域外评估中，F^2C 表现出有效的泛化能力。在仅使用部分提示扰动进行训练并在保留格式上进行评估时，F^2C 持续提高性能和一致性，同时降低方差。

Conclusion: F^2C 是一种有效的无监督方法，可用于增强 LLM 在提示扰动下的一致性、性能和泛化能力。

Abstract: Large Language Models (LLMs) often produce inconsistent answers when faced
with different phrasings of the same prompt. In this paper, we propose
Flip-Flop Consistency ($F^2C$), an unsupervised training method that improves
robustness to such perturbations. $F^2C$ is composed of two key components. The
first, Consensus Cross-Entropy (CCE), uses a majority vote across prompt
variations to create a hard pseudo-label. The second is a representation
alignment loss that pulls lower-confidence and non-majority predictors toward
the consensus established by high-confidence, majority-voting variations. We
evaluate our method on 11 datasets spanning four NLP tasks, with 4-15 prompt
variations per dataset. On average, $F^2C$ raises observed agreement by 11.62%,
improves mean $F_1$ by 8.94%, and reduces performance variance across formats
by 3.29%. In out-of-domain evaluations, $F^2C$ generalizes effectively,
increasing $\overline{F_1}$ and agreement while decreasing variance across most
source-target pairs. Finally, when trained on only a subset of prompt
perturbations and evaluated on held-out formats, $F^2C$ consistently improves
both performance and agreement while reducing variance. These findings
highlight $F^2C$ as an effective unsupervised method for enhancing LLM
consistency, performance, and generalization under prompt perturbations. Code
is available at
https://github.com/ParsaHejabi/Flip-Flop-Consistency-Unsupervised-Training-for-Robustness-to-Prompt-Perturbations-in-LLMs.

</details>


### [175] [MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.14252)
*Jihao Zhao,Zhiyuan Ji,Simin Niu,Hanyu Wang,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 本研究提出MoM框架，将RAG的被动文本分块转变为主动理解，通过模拟人类阅读认知过程，实现更深层次的知识内化和推理能力，并使小型语言模型（SLMs）具备处理多领域文档的能力。


<details>
  <summary>Details</summary>
Motivation: 传统RAG范式在文本理解上存在局限，限制了知识内化和推理能力。本研究旨在通过模拟人类阅读过程，实现对文档的主动理解，克服这些限制。

Method: 提出MoM框架，利用LLM生成文档逻辑大纲，指导结构化分块和核心内容提取。采用多路径采样和多视角评估机制，设计了衡量分块清晰度和提取完整性的指标来选择最优文档记忆。通过逆向推理策略训练SLMs，并建立三层文档记忆检索机制。

Result: MoM框架成功解决了现有RAG系统中文本分块的挑战，为LLMs提供了语义完整的文档记忆，并使SLMs能够实现以人为中心、智能化的文本处理。实验证明了该框架在三个不同领域的有效性。

Conclusion: MoM框架通过模拟人类认知过程，实现了文档的主动理解和记忆提取，显著提升了RAG系统的性能，并为小型语言模型在处理复杂文档任务方面开辟了新的途径。

Abstract: The traditional RAG paradigm, which typically engages in the comprehension of
relevant text chunks in response to received queries, inherently restricts both
the depth of knowledge internalization and reasoning capabilities. To address
this limitation, our research transforms the text processing in RAG from
passive chunking to proactive understanding, defining this process as document
memory extraction with the objective of simulating human cognitive processes
during reading. Building upon this, we propose the Mixtures of scenario-aware
document Memories (MoM) framework, engineered to efficiently handle documents
from multiple domains and train small language models (SLMs) to acquire the
ability to proactively explore and construct document memories. The MoM
initially instructs large language models (LLMs) to simulate domain experts in
generating document logical outlines, thereby directing structured chunking and
core content extraction. It employs a multi-path sampling and multi-perspective
evaluation mechanism, specifically designing comprehensive metrics that
represent chunk clarity and extraction completeness to select the optimal
document memories. Additionally, to infuse deeper human-like reading abilities
during the training of SLMs, we incorporate a reverse reasoning strategy, which
deduces refined expert thinking paths from high-quality outcomes. Finally,
leveraging diverse forms of content generated by MoM, we develop a three-layer
document memory retrieval mechanism, which is grounded in our theoretical proof
from the perspective of probabilistic modeling. Extensive experimental results
across three distinct domains demonstrate that the MoM framework not only
resolves text chunking challenges in existing RAG systems, providing LLMs with
semantically complete document memories, but also paves the way for SLMs to
achieve human-centric intelligent text processing.

</details>


### [176] [Rewriting History: A Recipe for Interventional Analyses to Study Data Effects on Model Behavior](https://arxiv.org/abs/2510.14261)
*Rahul Nadkarni,Yanai Elazar,Hila Gonen,Noah A. Smith*

Main category: cs.CL

TL;DR: 本文提出了一种通过修改训练数据来研究数据与语言模型行为之间关系的方法，并通过案例研究进行了验证。


<details>
  <summary>Details</summary>
Motivation: 研究训练数据如何影响语言模型的行为，以验证关于数据与模型行为之间关系的假设。

Method: 提出了一种干预训练数据批次的方法，包括选择评估项目、匹配相关文档、修改文档、重新训练模型以及测量效果。

Result: 现有的识别相关训练文档的方法不能完全解释语言模型回答知识问题的能力，但实验结果补充了过去将共现统计与模型行为联系起来的观察性分析。

Conclusion: 提出的方法为研究人员提供了一个测试训练数据如何影响模型行为的框架，代码已公开。

Abstract: We present an experimental recipe for studying the relationship between
training data and language model (LM) behavior. We outline steps for
intervening on data batches -- i.e., ``rewriting history'' -- and then
retraining model checkpoints over that data to test hypotheses relating data to
behavior. Our recipe breaks down such an intervention into stages that include
selecting evaluation items from a benchmark that measures model behavior,
matching relevant documents to those items, and modifying those documents
before retraining and measuring the effects. We demonstrate the utility of our
recipe through case studies on factual knowledge acquisition in LMs, using both
cooccurrence statistics and information retrieval methods to identify documents
that might contribute to knowledge learning. Our results supplement past
observational analyses that link cooccurrence to model behavior, while
demonstrating that extant methods for identifying relevant training documents
do not fully explain an LM's ability to correctly answer knowledge questions.
Overall, we outline a recipe that researchers can follow to test further
hypotheses about how training data affects model behavior. Our code is made
publicly available to promote future work.

</details>


### [177] [Less is More: Denoising Knowledge Graphs For Retrieval Augmented Generation](https://arxiv.org/abs/2510.14271)
*Yilun Zheng,Dan Yang,Jie Li,Lin Shang,Lihui Chen,Jiahao Xu,Sitao Luan*

Main category: cs.CL

TL;DR: 使用DE-RAG框架通过实体解析和关系去噪来提升基于知识图谱的检索增强生成（RAG）的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于知识图谱的RAG系统在构建知识图谱时过度依赖大型语言模型（LLM），导致知识图谱冗余且包含错误关系，从而影响检索和生成性能并增加计算成本。然而，目前的研究并未全面解决LLM生成知识图谱的去噪问题。

Method: 提出DE-RAG框架，包含两个关键技术：1. 实体解析（entity resolution），用于消除冗余实体；2. 关系反思（triple reflection），用于移除错误关系。此外，还系统地评估了LLM生成知识图谱的实体解析，考察了不同的阻塞策略、嵌入选择、相似度度量和实体合并技术。

Result: DE-RAG框架生成的知识图谱更精简、质量更高，性能显著优于未处理的知识图谱。实验表明，该方法能大幅减小图谱规模，并持续提升在多种流行的基于知识图谱的RAG变体上的问答性能。

Conclusion: DE-RAG框架通过实体解析和关系去噪，能显著提升基于知识图谱的RAG系统的性能，并且是首次对LLM生成知识图谱的实体解析进行全面探索。

Abstract: Retrieval-Augmented Generation (RAG) systems enable large language models
(LLMs) instant access to relevant information for the generative process,
demonstrating their superior performance in addressing common LLM challenges
such as hallucination, factual inaccuracy, and the knowledge cutoff.
Graph-based RAG further extends this paradigm by incorporating knowledge graphs
(KGs) to leverage rich, structured connections for more precise and inferential
responses. A critical challenge, however, is that most Graph-based RAG systems
rely on LLMs for automated KG construction, often yielding noisy KGs with
redundant entities and unreliable relationships. This noise degrades retrieval
and generation performance while also increasing computational cost. Crucially,
current research does not comprehensively address the denoising problem for
LLM-generated KGs. In this paper, we introduce DEnoised knowledge Graphs for
Retrieval Augmented Generation (DEG-RAG), a framework that addresses these
challenges through: (1) entity resolution, which eliminates redundant entities,
and (2) triple reflection, which removes erroneous relations. Together, these
techniques yield more compact, higher-quality KGs that significantly outperform
their unprocessed counterparts. Beyond the methods, we conduct a systematic
evaluation of entity resolution for LLM-generated KGs, examining different
blocking strategies, embedding choices, similarity metrics, and entity merging
techniques. To the best of our knowledge, this is the first comprehensive
exploration of entity resolution in LLM-generated KGs. Our experiments
demonstrate that this straightforward approach not only drastically reduces
graph size but also consistently improves question answering performance across
diverse popular Graph-based RAG variants.

</details>


### [178] [Retrofitting Small Multilingual Models for Retrieval: Matching 7B Performance with 300M Parameters](https://arxiv.org/abs/2510.14274)
*Lifu Tu,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: 小型多语言模型在检索任务上表现不如大型模型，本文研究了如何通过调整训练数据规模、负采样策略和数据多样性来提升小型模型的检索性能，并提出了一个约3亿参数的模型，其检索性能可媲美甚至超越7B模型。


<details>
  <summary>Details</summary>
Motivation: 小型多语言模型（<1B参数）在多语言任务上表现良好，但在检索任务上普遍落后于大型模型（>1B参数），因此需要研究小型模型是否能通过改造以提升检索性能。

Method: 研究了训练数据规模、负采样策略和数据多样性对多语言嵌入有效性的影响。

Result: 增加训练数据规模能带来初步性能提升但很快达到平台期；引入困难负例对提高检索准确性至关重要；任务多样性比语言多样性对性能的贡献更大。

Conclusion: 通过优化训练数据规模、采用困难负例以及侧重任务多样性，可以构建一个约3亿参数的小型多语言模型，使其在检索任务上的性能达到或超过当前强大的7B模型。

Abstract: Training effective multilingual embedding models presents unique challenges
due to the diversity of languages and task objectives. Although small
multilingual models (<1 B parameters) perform well on multilingual tasks
generally, they consistently lag behind larger models (>1 B) in the most
prevalent use case: retrieval. This raises a critical question: Can smaller
models be retrofitted specifically for retrieval tasks to enhance their
performance? In this work, we investigate key factors that influence the
effectiveness of multilingual embeddings, focusing on training data scale,
negative sampling strategies, and data diversity. We find that while increasing
the scale of training data yields initial performance gains, these improvements
quickly plateau - indicating diminishing returns. Incorporating hard negatives
proves essential for consistently improving retrieval accuracy. Furthermore,
our analysis reveals that task diversity in the training data contributes more
significantly to performance than language diversity alone. As a result, we
develop a compact (approximately 300M) multilingual model that achieves
retrieval performance comparable to or even surpassing current strong 7B
models.

</details>


### [179] [Qwen3Guard Technical Report](https://arxiv.org/abs/2510.14276)
*Haiquan Zhao,Chenhan Yuan,Fei Huang,Xiaomeng Hu,Yichang Zhang,An Yang,Bowen Yu,Dayiheng Liu,Jingren Zhou,Junyang Lin,Baosong Yang,Chen Cheng,Jialong Tang,Jiandong Jiang,Jianwei Zhang,Jijie Xu,Ming Yan,Minmin Sun,Pei Zhang,Pengjun Xie,Qiaoyu Tang,Qin Zhu,Rong Zhang,Shibin Wu,Shuo Zhang,Tao He,Tianyi Tang,Tingyu Xia,Wei Liao,Weizhou Shen,Wenbiao Yin,Wenmeng Zhou,Wenyuan Yu,Xiaobin Wang,Xiaodong Deng,Xiaodong Xu,Xinyu Zhang,Yang Liu,Yeqiu Li,Yi Zhang,Yong Jiang,Yu Wan,Yuxin Zhou*

Main category: cs.CL

TL;DR: Qwen3Guard is a set of multilingual safety guardrail models that address limitations in existing methods by providing fine-grained judgments (safe, controversial, unsafe) and enabling real-time monitoring during streaming LLM inference.


<details>
  <summary>Details</summary>
Motivation: Existing safety guardrail models have limitations in real-world applications, including inconsistent interpretation of binary labels and incompatibility with streaming LLM inference, which prevents timely intervention during generation.

Method: Qwen3Guard includes two variants: Generative Qwen3Guard, which uses instruction-following for tri-class judgments, and Stream Qwen3Guard, which adds a token-level classification head for real-time monitoring. Both variants are multilingual, available in different sizes, and support numerous languages.

Result: Qwen3Guard achieves state-of-the-art performance in safety classification across English, Chinese, and multilingual benchmarks, offering comprehensive, scalable, and low-latency moderation for LLM deployments.

Conclusion: Qwen3Guard provides a robust solution for LLM safety by offering fine-grained, multilingual, and real-time safety moderation, addressing key limitations of previous approaches. The models are publicly released under the Apache 2.0 license.

Abstract: As large language models (LLMs) become more capable and widely used, ensuring
the safety of their outputs is increasingly critical. Existing guardrail
models, though useful in static evaluation settings, face two major limitations
in real-world applications: (1) they typically output only binary "safe/unsafe"
labels, which can be interpreted inconsistently across diverse safety policies,
rendering them incapable of accommodating varying safety tolerances across
domains; and (2) they require complete model outputs before performing safety
checks, making them fundamentally incompatible with streaming LLM inference,
thereby preventing timely intervention during generation and increasing
exposure to harmful partial outputs. To address these challenges, we present
Qwen3Guard, a series of multilingual safety guardrail models with two
specialized variants: Generative Qwen3Guard, which casts safety classification
as an instruction-following task to enable fine-grained tri-class judgments
(safe, controversial, unsafe); and Stream Qwen3Guard, which introduces a
token-level classification head for real-time safety monitoring during
incremental text generation. Both variants are available in three sizes (0.6B,
4B, and 8B parameters) and support up to 119 languages and dialects, providing
comprehensive, scalable, and low-latency safety moderation for global LLM
deployments. Evaluated across English, Chinese, and multilingual benchmarks,
Qwen3Guard achieves state-of-the-art performance in both prompt and response
safety classification. All models are released under the Apache 2.0 license for
public use.

</details>


### [180] [PRISM: Agentic Retrieval with LLMs for Multi-Hop Question Answering](https://arxiv.org/abs/2510.14278)
*Md Mahadi Hasan Nahid,Davood Rafiei*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Agentic Retrieval System的框架，利用大型语言模型（LLM）通过结构化循环来精确高效地检索多跳问答所需的多条证据。


<details>
  <summary>Details</summary>
Motivation: 多跳问答需要检索多条证据，但现有方法在精度和召回率之间难以平衡，并可能引入无关信息。

Method: 提出一个包含问题分析器、选择器和添加器三种专用代理的框架。问题分析器分解问题；选择器优先考虑精度，找出最相关的上下文；添加器优先考虑召回率，补充缺失的证据。选择器和添加器通过迭代交互，生成简洁且全面的证据集。

Result: 在四个多跳问答基准测试（HotpotQA, 2WikiMultiHopQA, MuSiQue, MultiHopRAG）上，该方法在检索准确率上优于强基线，并且下游问答模型在依赖更少无关信息的情况下，超越了全上下文的答案准确率。

Conclusion: Agentic Retrieval System通过LLM的结构化循环，能够精确、高效地检索多跳问答所需证据，提升了问答模型的性能，并减少了无关信息的干扰。

Abstract: Retrieval plays a central role in multi-hop question answering (QA), where
answering complex questions requires gathering multiple pieces of evidence. We
introduce an Agentic Retrieval System that leverages large language models
(LLMs) in a structured loop to retrieve relevant evidence with high precision
and recall. Our framework consists of three specialized agents: a Question
Analyzer that decomposes a multi-hop question into sub-questions, a Selector
that identifies the most relevant context for each sub-question (focusing on
precision), and an Adder that brings in any missing evidence (focusing on
recall). The iterative interaction between Selector and Adder yields a compact
yet comprehensive set of supporting passages. In particular, it achieves higher
retrieval accuracy while filtering out distracting content, enabling downstream
QA models to surpass full-context answer accuracy while relying on
significantly less irrelevant information. Experiments on four multi-hop QA
benchmarks -- HotpotQA, 2WikiMultiHopQA, MuSiQue, and MultiHopRAG --
demonstrates that our approach consistently outperforms strong baselines.

</details>


### [181] [Rethinking Schema Linking: A Context-Aware Bidirectional Retrieval Approach for Text-to-SQL](https://arxiv.org/abs/2510.14296)
*Md Mahadi Hasan Nahid,Davood Rafiei,Weiwei Zhang,Yong Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种独立于SQL生成的上下文感知双向模式检索框架，以解决Text-to-SQL系统中的模式链接问题，并声称该方法显著提高了模式召回率，减少了误报，并缩小了在BIRD和Spider基准测试中的性能差距。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL系统中的模式链接（将自然语言问题与数据库模式元素对齐）至关重要但研究不足，现有方法往往忽略了相关模式元素的检索，导致了幻觉和执行失败。

Method: 提出了一种上下文感知双向模式检索框架，将模式链接视为一个独立的问题。该方法结合了两种互补策略：先表后列的检索，然后是列的选择；以及先列后表的检索，然后是列的选择。此外，还采用了问题分解、关键词提取和关键短语提取等技术进行增强。

Result: 在BIRD和Spider等具有挑战性的基准测试上，该方法显著提高了模式召回率，同时减少了误报。使用检索到的模式进行SQL生成，其性能持续优于全模式基线，并接近于Oracle性能，且无需进行查询改写。该方法将全模式和完美模式设置之间的性能差距缩小了50%。

Conclusion: 模式链接是提高Text-to-SQL准确性和效率的强大工具。

Abstract: Schema linking -- the process of aligning natural language questions with
database schema elements -- is a critical yet underexplored component of
Text-to-SQL systems. While recent methods have focused primarily on improving
SQL generation, they often neglect the retrieval of relevant schema elements,
which can lead to hallucinations and execution failures. In this work, we
propose a context-aware bidirectional schema retrieval framework that treats
schema linking as a standalone problem. Our approach combines two complementary
strategies: table-first retrieval followed by column selection, and
column-first retrieval followed by table selection. It is further augmented
with techniques such as question decomposition, keyword extraction, and
keyphrase extraction. Through comprehensive evaluations on challenging
benchmarks such as BIRD and Spider, we demonstrate that our method
significantly improves schema recall while reducing false positives. Moreover,
SQL generation using our retrieved schema consistently outperforms full-schema
baselines and closely approaches oracle performance, all without requiring
query refinement. Notably, our method narrows the performance gap between full
and perfect schema settings by 50\%. Our findings highlight schema linking as a
powerful lever for enhancing Text-to-SQL accuracy and efficiency.

</details>


### [182] [Constraint-Driven Small Language Models Based on Agent and OpenAlex Knowledge Graph: Mining Conceptual Pathways and Discovering Innovation Points in Academic Papers](https://arxiv.org/abs/2510.14303)
*Ziye Xia,Sergei S. Ospichev*

Main category: cs.CL

TL;DR: 本研究提出一种基于提示工程的关键概念路径分析方法，利用小型语言模型和知识图谱技术，提高了学术论文分析的精度和对创新点的识别能力。


<details>
  <summary>Details</summary>
Motivation: 学术出版物数量激增，给科研人员带来了分析论文的挑战；现有方法仅限于相似性匹配和基本分类，未能深入挖掘概念间的关系网络。

Method: 基于OpenAlex知识图谱，分析8000篇论文数据，发现关键概念路径分布与创新点、稀有路径存在强相关性。提出提示工程驱动的关键概念路径分析方法，利用小型语言模型提取概念并识别创新点，构建基于知识图谱约束的代理以提高精度。对Qwen和DeepSeek模型进行微调。

Result: 通过对Qwen和DeepSeek模型进行微调，在关键概念提取和创新点识别方面取得了显著的精度提升。

Conclusion: 所提出的方法能够有效提高学术论文分析的精度，并能识别出创新点。微调后的模型可在Hugging Face平台获取。

Abstract: In recent years, the rapid increase in academic publications across various
fields has posed severe challenges for academic paper analysis: scientists
struggle to timely and comprehensively track the latest research findings and
methodologies. Key concept extraction has proven to be an effective analytical
paradigm, and its automation has been achieved with the widespread application
of language models in industrial and scientific domains. However, existing
paper databases are mostly limited to similarity matching and basic
classification of key concepts, failing to deeply explore the relational
networks between concepts. This paper is based on the OpenAlex opensource
knowledge graph. By analyzing nearly 8,000 open-source paper data from
Novosibirsk State University, we discovered a strong correlation between the
distribution patterns of paper key concept paths and both innovation points and
rare paths. We propose a prompt engineering-based key concept path analysis
method. This method leverages small language models to achieve precise key
concept extraction and innovation point identification, and constructs an agent
based on a knowledge graph constraint mechanism to enhance analysis accuracy.
Through fine-tuning of the Qwen and DeepSeek models, we achieved significant
improvements in accuracy, with the models publicly available on the Hugging
Face platform.

</details>


### [183] [MathMist: A Parallel Multilingual Benchmark Dataset for Mathematical Problem Solving and Reasoning](https://arxiv.org/abs/2510.14305)
*Mahbub E Sobhani,Md. Faiyaz Abdullah Sayeedi,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: MathMist是一个包含21K以上对齐的数学问题-答案对的多语言基准，涵盖七种语言，旨在评估LLM在不同资源设置下的多语言和跨语言数学推理能力。评估结果显示，LLM在跨语言数学推理方面仍存在不足，尤其是在低资源语言中。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准主要集中在英语或高资源语言，忽略了多语言和跨语言数学推理的评估，需要一个能覆盖不同资源语言的基准来解决这个问题。

Method: 构建了一个包含21K以上对齐问题的多语言数据集MathMist，涵盖七种语言，并系统性地评估了多种模型在零样本、思维链和代码转换推理范式下的表现。

Result: 评估结果显示，LLM在一致和可解释的跨语言数学推理方面存在持续的缺陷，在低资源语言中的表现尤为糟糕。

Conclusion: LLM在数学推理方面，尤其是在多语言和跨语言场景下，仍有很大的提升空间，特别是在低资源语言环境下。

Abstract: Mathematical reasoning remains one of the most challenging domains for large
language models (LLMs), requiring not only linguistic understanding but also
structured logical deduction and numerical precision. While recent LLMs
demonstrate strong general-purpose reasoning abilities, their mathematical
competence across diverse languages remains underexplored. Existing benchmarks
primarily focus on English or a narrow subset of high-resource languages,
leaving significant gaps in assessing multilingual and cross-lingual
mathematical reasoning. To address this, we introduce MathMist, a parallel
multilingual benchmark for mathematical problem solving and reasoning. MathMist
encompasses over 21K aligned question-answer pairs across seven languages,
representing a balanced coverage of high-, medium-, and low-resource linguistic
settings. The dataset captures linguistic variety, multiple types of problem
settings, and solution synthesizing capabilities. We systematically evaluate a
diverse suite of models, including open-source small and medium LLMs,
proprietary systems, and multilingual-reasoning-focused models, under
zero-shot, chain-of-thought (CoT), and code-switched reasoning paradigms. Our
results reveal persistent deficiencies in LLMs' ability to perform consistent
and interpretable mathematical reasoning across languages, with pronounced
degradation in low-resource settings. All the codes and data are available at
GitHub: https://github.com/mahbubhimel/MathMist

</details>


### [184] [MERLIN: A Testbed for Multilingual Multimodal Entity Recognition and Linking](https://arxiv.org/abs/2510.14307)
*Sathyanarayanan Ramamoorthy,Vishwa Shah,Simran Khanuja,Zaid Sheikh,Shan Jie,Ann Chia,Shearman Chua,Graham Neubig*

Main category: cs.CL

TL;DR: MERLIN是一个多语言多模态实体链接的测试平台，包含BBC新闻标题、图片和5种语言的数据集，并提供了多语言和多模态实体链接方法的基准测试。


<details>
  <summary>Details</summary>
Motivation: 介绍MERLIN测试平台，用于多语言多模态实体链接任务，并提供了一个包含多种语言和实体的数据集。

Method: 创建了一个包含BBC新闻文章标题、对应图片的数据集，涵盖印地语、日语、印度尼西亚语、越南语和泰米尔语，并使用了LLaMa-2和Aya-23等语言模型进行多语言和多模态实体链接方法的基准测试。

Result: 实验表明，引入视觉数据能够提高实体链接的准确性，尤其是在文本上下文模糊或不足的情况下，以及对于多语言能力不强的模型。

Conclusion: 视觉数据对于提高多语言多模态实体链接的准确性至关重要，特别是在处理歧义性或信息量不足的文本时。

Abstract: This paper introduces MERLIN, a novel testbed system for the task of
Multilingual Multimodal Entity Linking. The created dataset includes BBC news
article titles, paired with corresponding images, in five languages: Hindi,
Japanese, Indonesian, Vietnamese, and Tamil, featuring over 7,000 named entity
mentions linked to 2,500 unique Wikidata entities. We also include several
benchmarks using multilingual and multimodal entity linking methods exploring
different language models like LLaMa-2 and Aya-23. Our findings indicate that
incorporating visual data improves the accuracy of entity linking, especially
for entities where the textual context is ambiguous or insufficient, and
particularly for models that do not have strong multilingual abilities. For the
work, the dataset, methods are available here at
https://github.com/rsathya4802/merlin

</details>


### [185] [Evaluating & Reducing Deceptive Dialogue From Language Models with Multi-turn RL](https://arxiv.org/abs/2510.14318)
*Marwa Abdulhai,Ryan Cheng,Aryansh Shrivastava,Natasha Jaques,Yarin Gal,Sergey Levine*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在对话中表现出欺骗行为，尤其是在没有充分安全措施的情况下。本研究提出了一个名为“信念不一致性度量”的新指标来量化欺骗行为，并评估了八种最先进的模型。结果显示，LLMs在平均26%的对话轮次中会自然地表现出欺骗行为，并且在被提示欺骗时，欺骗性会增加高达31%。即使是经过RLHF训练的模型，欺骗率也高达43%。研究还提出了一种多轮强化学习方法来减少LLMs的欺骗行为，效果显著，比其他指令调优模型减少了77.6%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在现实世界中的广泛应用带来了潜在的欺骗风险，包括幻觉、错误信息和用户操纵，这对安全性构成了重大威胁。因此，研究LLMs的欺骗行为并提出有效的评估和缓解方法至关重要。

Method: 本研究提出了一个名为“信念不一致性度量”的新指标来量化LLMs在对话中的欺骗行为。研究人员在四种不同的对话场景下，使用五个已有的欺骗检测指标和新提出的度量指标对LLMs进行了评估。此外，还采用了一种多轮强化学习的方法来微调LLMs，以减少欺骗行为。

Result: 研究发现，新的“信念不一致性度量”比现有的指标更能准确地反映人类的判断。在对八种最先进的模型进行评估后，发现LLMs在平均26%的对话轮次中会自然地表现出欺骗行为，即使在看似无害的目标下也是如此。当被提示欺骗时，LLMs的欺骗性可以增加高达31%。经过RLHF训练的模型仍然平均表现出43%的欺骗率。通过多轮强化学习方法进行微调后，LLMs的欺骗行为减少了77.6%，优于其他指令调优模型。

Conclusion: 鉴于LLMs的欺骗行为是随着交互历史而发展的，因此需要超越单一话语的分析方法来对其进行有效评估和缓解。本研究提出的“信念不一致性度量”和多轮强化学习方法为解决LLMs的欺骗问题提供了新的途径，并显著降低了其欺骗行为。

Abstract: Large Language Models (LLMs) interact with millions of people worldwide in
applications such as customer support, education and healthcare. However, their
ability to produce deceptive outputs, whether intentionally or inadvertently,
poses significant safety concerns. The unpredictable nature of LLM behavior,
combined with insufficient safeguards against hallucination, misinformation,
and user manipulation, makes their misuse a serious, real-world risk. In this
paper, we investigate the extent to which LLMs engage in deception within
dialogue, and propose the belief misalignment metric to quantify deception. We
evaluate deception across four distinct dialogue scenarios, using five
established deception detection metrics and our proposed metric. Our findings
reveal this novel deception measure correlates more closely with human
judgments than any existing metrics we test. Additionally, our benchmarking of
eight state-of-the-art models indicates that LLMs naturally exhibit deceptive
behavior in approximately 26% of dialogue turns, even when prompted with
seemingly benign objectives. When prompted to deceive, LLMs are capable of
increasing deceptiveness by as much as 31% relative to baselines. Unexpectedly,
models trained with RLHF, the predominant approach for ensuring the safety of
widely-deployed LLMs, still exhibit deception at a rate of 43% on average.
Given that deception in dialogue is a behavior that develops over an
interaction history, its effective evaluation and mitigation necessitates
moving beyond single-utterance analyses. We introduce a multi-turn
reinforcement learning methodology to fine-tune LLMs to reduce deceptive
behaviors, leading to a 77.6% reduction compared to other instruction-tuned
models.

</details>


### [186] [A Robust Classification Method using Hybrid Word Embedding for Early Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2510.14332)
*Yangyang Li*

Main category: cs.CL

TL;DR: 通过混合词嵌入和微调超参数，利用语言能力变化来早期检测阿尔茨海默病（AD），准确率达到91%，AUC为97%。


<details>
  <summary>Details</summary>
Motivation: 早期检测阿尔茨海默病（AD）对于早期治疗、减轻症状和医疗负担至关重要。语言能力的变化是AD的早期迹象之一，可用于早期诊断。

Method: 提出一种混合词嵌入方法，结合Doc2Vec和ELMo的词向量，计算句子困惑度得分以识别流畅度和语义。通过加入语言学特征丰富嵌入，并使用逻辑回归模型，同时对模型正则化参数、学习率、Doc2Vec向量大小和ELMo向量大小等超参数进行微调。

Result: 在区分早期AD与健康受试者方面，实现了91%的分类准确率和97%的AUC。该模型准确率（91%）和AUC（97%）优于现有最佳NLP模型（准确率88%）。通过重复实验验证了模型的稳定性，准确率和AUC的标准差分别为0.0403和0.0174。

Conclusion: 所提出的混合词嵌入和超参数微调方法能够准确且稳定地早期检测AD，可作为大规模筛查方法或辅助医生诊断的工具。

Abstract: Early detection of Alzheimer's Disease (AD) is greatly beneficial to AD
patients, leading to early treatments that lessen symptoms and alleviating
financial burden of health care. As one of the leading signs of AD, language
capability changes can be used for early diagnosis of AD. In this paper, I
develop a robust classification method using hybrid word embedding and
fine-tuned hyperparameters to achieve state-of-the-art accuracy in the early
detection of AD. Specifically, we create a hybrid word embedding based on word
vectors from Doc2Vec and ELMo to obtain perplexity scores of the sentences. The
scores identify whether a sentence is fluent or not and capture semantic
context of the sentences. I enrich the word embedding by adding linguistic
features to analyze syntax and semantics. Further, we input an embedded feature
vector into logistic regression and fine tune hyperparameters throughout the
pipeline. By tuning hyperparameters of the machine learning pipeline (e.g.,
model regularization parameter, learning rate and vector size of Doc2Vec, and
vector size of ELMo), I achieve 91% classification accuracy and an Area Under
the Curve (AUC) of 97% in distinguishing early AD from healthy subjects. Based
on my knowledge, my model with 91% accuracy and 97% AUC outperforms the best
existing NLP model for AD diagnosis with an accuracy of 88% [32]. I study the
model stability through repeated experiments and find that the model is stable
even though the training data is split randomly (standard deviation of accuracy
= 0.0403; standard deviation of AUC = 0.0174). This affirms our proposed method
is accurate and stable. This model can be used as a large-scale screening
method for AD, as well as a complementary examination for doctors to detect AD.

</details>


### [187] [Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts](https://arxiv.org/abs/2510.14351)
*Perapard Ngokpol,Kun Kerdthaisong,Pasin Buakhaw,Pitikorn Khlaisamniang,Supasate Vorathammathorn,Piyalitt Ittichaiwong,Nutchanon Yongsatianchot*

Main category: cs.CL

TL;DR: LLMs在扮演特定版本角色（如漫威和DC漫画中的超级英雄）方面能力有待探索。我们提出了Beyond One World基准，包含30位英雄的90个版本，分为“经典事件”和“道德困境”两项任务，以评估模型在事实回忆和伦理推理方面的能力。我们提出了“思维-行动匹配”指标来衡量模型的可信度。实验发现，链式思考提示对较弱模型有益但对较强模型可能降低准确性，跨版本泛化仍是难题，且模型在“思考”和“行动”方面表现不均衡。


<details>
  <summary>Details</summary>
Motivation: LLMs常被用作角色扮演代理，但其在一致性地扮演特定版本角色的能力方面研究不足，尤其是在拥有丰富历史和多样化设定的超级英雄领域。

Method: 我们创建了一个名为Beyond One World的基准，包含30位标志性英雄的90个特定版本。该基准包括两项任务：（1）经典事件：考察事实回忆能力；（2）道德困境：评估模型在伦理场景下的推理能力。我们提出了“思维-行动匹配”指标，用于量化模型思考和行动之间的一致性。

Result: 实验显示：（1）链式思考提示能提升较弱模型的叙事连贯性，但可能降低较强模型的经典准确性；（2）同一角色的跨版本泛化能力仍然是一个巨大障碍；（3）模型通常在“思考”或“行动”方面表现出色，但很少两者兼备。

Conclusion: Beyond One World基准揭示了LLMs在多重宇宙一致性和推理对齐方面的关键差距，为角色扮演LLMs提供了具有挑战性的评估方法。

Abstract: Large language models (LLMs) are increasingly used as role-playing agents,
yet their capacity to faithfully and consistently portray version-specific
characters -- for example, superheroes across comic and cinematic universes --
remains underexplored. Superhero canons such as Marvel and DC provide a rich
testbed: decades of storytelling yield multiple incarnations of the same
character with distinct histories, values, and moral codes. To study this
problem, we introduce Beyond One World, a benchmark for character-grounded
roleplay spanning 30 iconic heroes and 90 canon-specific versions. The
benchmark comprises two tasks: (i) Canon Events, which probes factual recall of
pivotal life stages, and (ii) Moral Dilemmas, which confronts models with
ethically charged scenarios. We score responses for canonical accuracy and
reasoning fidelity under a framework that separates internal deliberation
("thinking") from outward decisions ("acting"). We further propose Think-Act
Matching, a metric that quantifies alignment between reasons and actions and
serves as a proxy for model trustworthiness. Experiments across reasoning- and
non-reasoning-oriented models yield three findings: (1) chain-of-thought
prompting improves narrative coherence in weaker models but can reduce
canonical accuracy in stronger ones; (2) cross-version generalization within a
character remains a major obstacle; and (3) models often excel at either
thinking or acting, but rarely both. Beyond One World exposes critical gaps in
multiversal consistency and reasoning alignment, offering a challenging
evaluation for role-playing LLMs.

</details>


### [188] [CURE: Confidence-driven Unified Reasoning Ensemble Framework for Medical Question Answering](https://arxiv.org/abs/2510.14353)
*Ziad Elshaer,Essam A. Rashed*

Main category: cs.CL

TL;DR: 该研究提出了一种无需微调即可提高医疗问答能力的置信度驱动的多模型框架，通过模型协作来提高性能，解决了资源受限医疗机构的挑战。


<details>
  <summary>Details</summary>
Motivation: 高性能力医疗大语言模型（LLMs）通常需要大量计算资源进行微调，这限制了资源受限医疗机构的可及性。本研究旨在提出一种无需微调即可增强医疗问答能力的方法。

Method: 研究采用了一个置信度驱动的多模型框架，包含一个置信度检测模块和一个自适应路由机制。该机制评估主模型的置信度，并将低置信度的查询路由到具有互补知识的辅助模型进行协作推理。

Result: 在MedQA、MedMCQA和PubMedQA三个医学基准测试中，该框架取得了有竞争力的性能，在PubMedQA（95.0%）和MedMCQA（78.0%）上表现尤为出色。消融研究表明，结合置信度感知路由和多模型协作的方法显著优于单一模型方法和统一推理策略。

Conclusion: 战略性的模型协作提供了一种实用且计算效率高的方法来改进医疗人工智能系统，这对于在资源有限的环境中普及先进的医疗人工智能具有重要意义。

Abstract: High-performing medical Large Language Models (LLMs) typically require
extensive fine-tuning with substantial computational resources, limiting
accessibility for resource-constrained healthcare institutions. This study
introduces a confidence-driven multi-model framework that leverages model
diversity to enhance medical question answering without fine-tuning. Our
framework employs a two-stage architecture: a confidence detection module
assesses the primary model's certainty, and an adaptive routing mechanism
directs low-confidence queries to Helper models with complementary knowledge
for collaborative reasoning. We evaluate our approach using
Qwen3-30B-A3B-Instruct, Phi-4 14B, and Gemma 2 12B across three medical
benchmarks; MedQA, MedMCQA, and PubMedQA. Result demonstrate that our framework
achieves competitive performance, with particularly strong results in PubMedQA
(95.0\%) and MedMCQA (78.0\%). Ablation studies confirm that confidence-aware
routing combined with multi-model collaboration substantially outperforms
single-model approaches and uniform reasoning strategies. This work establishes
that strategic model collaboration offers a practical, computationally
efficient pathway to improve medical AI systems, with significant implications
for democratizing access to advanced medical AI in resource-limited settings.

</details>


### [189] [On the Ability of LLMs to Handle Character-Level Perturbations: How Well and How?](https://arxiv.org/abs/2510.14365)
*Anyun Zhuo,Xuefei Ning,Ningyuan Li,Yu Wang,Pinyan Lu*

Main category: cs.CL

TL;DR: 研究表明，即使在存在大量字符级噪声扰动的情况下，许多大型语言模型（LLM）在各种配置下仍能保持显著的性能，这揭示了它们在低级文本处理方面的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在面对字符级扰动时的韧性，特别是为了防止其被用于在线考试系统等场景的滥用，并探讨其鲁棒性的机制。

Method: 提出了一种名为‘
ameshort’的方法，该方法通过在输入文本的每个字符后插入不可见的Unicode控制字符，来混淆LLM的输入，破坏其分词，并显著降低信噪比。

Result: 研究发现，即使经过强混淆处理，许多LLM在不同模型、问题和噪声配置下仍保持了相当的性能。通过广泛的评估，探讨了LLM处理字符级分词以及其潜在的显式和隐式去噪机制。

Conclusion: LLM在字符级噪声下的低级鲁棒性揭示了其被滥用的风险，并对其在各种应用中的可靠性提出了质疑。

Abstract: This work investigates the resilience of contemporary LLMs against frequent
and structured character-level perturbations, specifically through the
insertion of noisy characters after each input character. We introduce
\nameshort{}, a practical method that inserts invisible Unicode control
characters into text to discourage LLM misuse in scenarios such as online exam
systems. Surprisingly, despite strong obfuscation that fragments tokenization
and reduces the signal-to-noise ratio significantly, many LLMs still maintain
notable performance. Through comprehensive evaluation across model-, problem-,
and noise-related configurations, we examine the extent and mechanisms of this
robustness, exploring both the handling of character-level tokenization and
\textit{implicit} versus \textit{explicit} denoising mechanism hypotheses of
character-level noises. We hope our findings on the low-level robustness of
LLMs will shed light on the risks of their misuse and on the reliability of
deploying LLMs across diverse applications.

</details>


### [190] [From Binary to Bilingual: How the National Weather Service is Using Artificial Intelligence to Develop a Comprehensive Translation Program](https://arxiv.org/abs/2510.14369)
*Joseph E. Trujillo-Falcon,Monica L. Bozeman,Liam E. Llewellyn,Samuel T. Halvorson,Meryl Mizell,Stuti Deshpande,Bob Manning,Todd Fagin*

Main category: cs.CL

TL;DR: 美国国家气象局（NWS）正在开发一个AI驱动的自动化翻译工具，以服务于不以英语为母语的6880万美国人，目标是提供准确、及时、符合文化习惯的翻译，并已上线包含翻译预警、7天预报和宣传活动的实验性多语言NWS产品网站。


<details>
  <summary>Details</summary>
Motivation: 为了建立一个“天气就绪”的国家，美国国家气象局（NWS）需要更好地服务于国内6880万不说英语的民众。

Method: NWS与LILT合作，利用其专利训练流程，使大型语言模型（LLMs）能够为天气术语和信息定制神经机器翻译（NMT）工具。该系统支持西班牙语、简体中文、越南语等多种语言，并考虑了GIS绘图以确定不同地区的语言需求，同时整合了AI伦理实践（透明度、公平性和人工监督）。

Result: 开发了一个可扩展的系统，目前正在开发西班牙语、简体中文、越南语等版本，并且已经上线了一个包含实验性多语言NWS产品（如翻译的预警、7天预报和宣传活动）的网站。

Conclusion: 该项目使美国向建立一个能够触及所有美国人的全国性预警系统迈进了一步，显著减少了手动翻译时间，减轻了NWS的运营负担。

Abstract: To advance a Weather-Ready Nation, the National Weather Service (NWS) is
developing a systematic translation program to better serve the 68.8 million
people in the U.S. who do not speak English at home. This article outlines the
foundation of an automated translation tool for NWS products, powered by
artificial intelligence. The NWS has partnered with LILT, whose patented
training process enables large language models (LLMs) to adapt neural machine
translation (NMT) tools for weather terminology and messaging. Designed for
scalability across Weather Forecast Offices (WFOs) and National Centers, the
system is currently being developed in Spanish, Simplified Chinese, Vietnamese,
and other widely spoken non-English languages. Rooted in best practices for
multilingual risk communication, the system provides accurate, timely, and
culturally relevant translations, significantly reducing manual translation
time and easing operational workloads across the NWS. To guide the distribution
of these products, GIS mapping was used to identify language needs across
different NWS regions, helping prioritize resources for the communities that
need them most. We also integrated ethical AI practices throughout the
program's design, ensuring that transparency, fairness, and human oversight
guide how automated translations are created, evaluated, and shared with the
public. This work has culminated into a website featuring experimental
multilingual NWS products, including translated warnings, 7-day forecasts, and
educational campaigns, bringing the country one step closer to a national
warning system that reaches all Americans.

</details>


### [191] [PluriHop: Exhaustive, Recall-Sensitive QA over Distractor-Rich Corpora](https://arxiv.org/abs/2510.14377)
*Mykolas Sveistrys,Richard Kunert*

Main category: cs.CL

TL;DR: LLM和RAG在单跳和多跳问答方面取得了进展，但对于需要跨多个文档聚合信息的“多跳”问题，现有方法效果不佳。研究者提出了PluriHopWIND数据集和PluriHopRAG模型来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 现有的问答系统在处理需要跨多个文档聚合信息的“多跳”问题时存在不足，尤其是在文档数量多且信息重复度高的情况下，现有方法难以达到令人满意的效果。

Method: 研究者提出了PluriHopRAG模型，该模型采用“逐个检查所有文档，廉价过滤”的策略：首先将查询分解为文档级子问题，然后使用交叉编码器过滤掉无关文档，最后再进行昂贵的LLM推理。

Result: PluriHopRAG模型在PluriHopWIND数据集上取得了相对18%-52%的F1分数提升。

Conclusion: PluriHopWIND数据集揭示了当前问答系统在处理重复、干扰信息多的语料库时的局限性。PluriHopRAG模型的表现证明了穷尽式检索和早期过滤是替代top-k方法的有效途径。

Abstract: Recent advances in large language models (LLMs) and retrieval-augmented
generation (RAG) have enabled progress on question answering (QA) when relevant
evidence is in one (single-hop) or multiple (multi-hop) passages. Yet many
realistic questions about recurring report data - medical records, compliance
filings, maintenance logs - require aggregation across all documents, with no
clear stopping point for retrieval and high sensitivity to even one missed
passage. We term these pluri-hop questions and formalize them by three
criteria: recall sensitivity, exhaustiveness, and exactness. To study this
setting, we introduce PluriHopWIND, a diagnostic multilingual dataset of 48
pluri-hop questions built from 191 real-world wind industry reports in German
and English. We show that PluriHopWIND is 8-40% more repetitive than other
common datasets and thus has higher density of distractor documents, better
reflecting practical challenges of recurring report corpora. We test a
traditional RAG pipeline as well as graph-based and multimodal variants, and
find that none of the tested approaches exceed 40% in statement-wise F1 score.
Motivated by this, we propose PluriHopRAG, a RAG architecture that follows a
"check all documents individually, filter cheaply" approach: it (i) decomposes
queries into document-level subquestions and (ii) uses a cross-encoder filter
to discard irrelevant documents before costly LLM reasoning. We find that
PluriHopRAG achieves relative F1 score improvements of 18-52% depending on base
LLM. Despite its modest size, PluriHopWIND exposes the limitations of current
QA systems on repetitive, distractor-rich corpora. PluriHopRAG's performance
highlights the value of exhaustive retrieval and early filtering as a powerful
alternative to top-k methods.

</details>


### [192] [Suicidal Comment Tree Dataset: Enhancing Risk Assessment and Prediction Through Contextual Analysis](https://arxiv.org/abs/2510.14395)
*Jun Li,Qun Zhao*

Main category: cs.CL

TL;DR: 本研究探讨了利用社交媒体评论树序列信息来预测用户自杀风险，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单条社交媒体帖子中的自杀倾向检测，忽视了用户随时间变化的评论树信息在预测自杀风险中的作用。

Method: 构建了一个包含用户发帖历史和评论的Reddit数据集，并采用基于C-SSRS的四标签标注体系。利用大规模语言模型（LLMs）进行实验，并进行统计分析。

Result: 实验结果表明，纳入评论树数据能够显著提高对用户自杀风险水平的区分和预测能力。

Conclusion: 评论树信息对于提升自杀风险检测的准确性至关重要，为早期干预策略提供了有价值的基础。

Abstract: Suicide remains a critical global public health issue. While previous studies
have provided valuable insights into detecting suicidal expressions in
individual social media posts, limited attention has been paid to the analysis
of longitudinal, sequential comment trees for predicting a user's evolving
suicidal risk. Users, however, often reveal their intentions through historical
posts and interactive comments over time. This study addresses this gap by
investigating how the information in comment trees affects both the
discrimination and prediction of users' suicidal risk levels. We constructed a
high-quality annotated dataset, sourced from Reddit, which incorporates users'
posting history and comments, using a refined four-label annotation framework
based on the Columbia Suicide Severity Rating Scale (C-SSRS). Statistical
analysis of the dataset, along with experimental results from Large Language
Models (LLMs) experiments, demonstrates that incorporating comment trees data
significantly enhances the discrimination and prediction of user suicidal risk
levels. This research offers a novel insight to enhancing the detection
accuracy of at-risk individuals, thereby providing a valuable foundation for
early suicide intervention strategies.

</details>


### [193] [Your Next Token Prediction: A Multilingual Benchmark for Personalized Response Generation](https://arxiv.org/abs/2510.14398)
*Shiyao Ding,Takayuki Ito*

Main category: cs.CL

TL;DR: LLMs can't mimic individual communication styles due to privacy issues with real data. We propose YNTP task and a multilingual benchmark (100 dialogues, 3 languages) using psychologically grounded NPCs to capture user communication patterns. We evaluate personalization methods, establishing the first YNTP benchmark.


<details>
  <summary>Details</summary>
Motivation: Current LLMs struggle to mimic individual communication styles in tasks like email/social media replies due to the difficulty of collecting private user data. This limits their ability to generate personalized and natural responses.

Method: We propose the 'Your Next Token Prediction (YNTP)' task and create a multilingual benchmark of 100 dialogue sessions across English, Japanese, and Chinese. Users interacted for five days with psychologically grounded NPCs based on MBTI dimensions to capture natural communication patterns. We then evaluated prompt-based and fine-tuning-based personalization methods.

Result: We established the first benchmark for the YNTP task. The benchmark, consisting of 100 dialogue sessions in three languages, captures natural, daily-life communication patterns and enables the analysis of users' internal models. We also evaluated personalization methods.

Conclusion: The proposed YNTP task and benchmark provide a foundation for user-aligned language modeling by addressing the challenge of personalized communication generation in the absence of real-world private data. This work enables future research into methods that can better capture and replicate individual communication styles.

Abstract: Large language models (LLMs) excel at general next-token prediction but still
struggle to generate responses that reflect how individuals truly communicate,
such as replying to emails or social messages in their own style. However, real
SNS or email histories are difficult to collect due to privacy concerns. To
address this, we propose the task of "Your Next Token Prediction (YNTP)", which
models a user's precise word choices through controlled human-agent
conversations. We build a multilingual benchmark of 100 dialogue sessions
across English, Japanese, and Chinese, where users interact for five days with
psychologically grounded NPCs based on MBTI dimensions. This setup captures
natural, daily-life communication patterns and enables analysis of users'
internal models. We evaluate prompt-based and fine-tuning-based personalization
methods, establishing the first benchmark for YNTP and a foundation for
user-aligned language modeling. The dataset is available at:
https://github.com/AnonymousHub4Submissions/your-next-token-prediction-dataset-100

</details>


### [194] [MedTrust-RAG: Evidence Verification and Trust Alignment for Biomedical Question Answering](https://arxiv.org/abs/2510.14400)
*Yingpeng Ning,Yuanyuan Sun,Ling Luo,Yanhua Wang,Yuchen Pan,Hongfei Lin*

Main category: cs.CL

TL;DR: MedTrust-Guided Iterative RAG框架通过引用感知推理、迭代检索-验证和MedTrust-Align Module来减少生物医学QA中的幻觉，并在MedMCQA、MedQA和MMLU-Med数据集上提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 生物医学QA需要准确理解复杂的医学知识，现有的基于检索增强生成（RAG）的方法存在幻觉问题，影响了响应的可靠性。

Method: 提出MedTrust-Guided Iterative RAG框架，包括：1. 强制引用感知推理，利用结构化负知识断言来弥补证据不足；2. 迭代检索-验证过程，通过医学差距分析来完善查询；3. MedTrust-Align Module（MTAM），结合正负样本，利用直接偏好优化来增强基于引用的推理并惩罚易产生幻觉的响应模式。

Result: 在MedMCQA、MedQA和MMLU-Med数据集上，与基线方法相比，在多个模型架构上始终表现更优，LLaMA3.1-8B-Instruct的准确性提高了2.7%，Qwen3-8B的准确性提高了2.4%。

Conclusion: MedTrust-Guided Iterative RAG框架能有效提高生物医学QA的事实一致性，并减少幻觉，相比现有方法具有显著优势。

Abstract: Biomedical question answering (QA) requires accurate interpretation of
complex medical knowledge. Large language models (LLMs) have shown promising
capabilities in this domain, with retrieval-augmented generation (RAG) systems
enhancing performance by incorporating external medical literature. However,
RAG-based approaches in biomedical QA suffer from hallucinations due to
post-retrieval noise and insufficient verification of retrieved evidence,
undermining response reliability. We propose MedTrust-Guided Iterative RAG, a
framework designed to enhance factual consistency and mitigate hallucinations
in medical QA. Our method introduces three key innovations. First, it enforces
citation-aware reasoning by requiring all generated content to be explicitly
grounded in retrieved medical documents, with structured Negative Knowledge
Assertions used when evidence is insufficient. Second, it employs an iterative
retrieval-verification process, where a verification agent assesses evidence
adequacy and refines queries through Medical Gap Analysis until reliable
information is obtained. Third, it integrates the MedTrust-Align Module (MTAM)
that combines verified positive examples with hallucination-aware negative
samples, leveraging Direct Preference Optimization to reinforce
citation-grounded reasoning while penalizing hallucination-prone response
patterns. Experiments on MedMCQA, MedQA, and MMLU-Med demonstrate that our
approach consistently outperforms competitive baselines across multiple model
architectures, achieving the best average accuracy with gains of 2.7% for
LLaMA3.1-8B-Instruct and 2.4% for Qwen3-8B.

</details>


### [195] [Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2510.14420)
*Qingyu Ren,Qianyu He,Bowei Zhang,Jie Zeng,Jiaqing Liang,Yanghua Xiao,Weikang Zhou,Zeye Sun,Fei Yu*

Main category: cs.CL

TL;DR: 提出了一种无标签的自监督强化学习框架，用于解决语言模型在遵循多约束指令时遇到的挑战，无需外部监督，并能有效处理稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理现实世界应用中的多约束指令时存在困难，而现有的强化学习方法依赖外部监督且奖励信号稀疏。

Method: 提出了一种无标签的自监督强化学习框架，通过从指令中提取奖励信号并生成伪标签来训练奖励模型。该方法还引入了约束分解策略和高效的约束-wise二元分类来解决稀疏奖励问题。

Result: 在3个域内和5个域外数据集上进行了实验，包括具有挑战性的agentic和多轮指令遵循任务，结果表明该方法泛化能力强，并取得了显著的改进。

Conclusion: 所提出的无标签自监督强化学习框架能够有效解决语言模型在遵循多约束指令时的挑战，无需外部监督，并能有效处理稀疏奖励问题，具有良好的泛化能力。

Abstract: Language models often struggle to follow multi-constraint instructions that
are crucial for real-world applications. Existing reinforcement learning (RL)
approaches suffer from dependency on external supervision and sparse reward
signals from multi-constraint tasks. We propose a label-free self-supervised RL
framework that eliminates dependency on external supervision by deriving reward
signals directly from instructions and generating pseudo-labels for reward
model training. Our approach introduces constraint decomposition strategies and
efficient constraint-wise binary classification to address sparse reward
challenges while maintaining computational efficiency. Experiments show that
our approach generalizes well, achieving strong improvements across 3 in-domain
and 5 out-of-domain datasets, including challenging agentic and multi-turn
instruction following. The data and code are publicly available at
https://github.com/Rainier-rq/verl-if

</details>


### [196] [Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents](https://arxiv.org/abs/2510.14438)
*Rui Wang,Ce Zhang,Jun-Yu Ma,Jianshu Zhang,Hongru Wang,Yi Chen,Boyang Xue,Tianqing Fang,Zhisong Zhang,Hongming Zhang,Haitao Mi,Dong Yu,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 现有研究型网络代理主要关注信息检索，忽略了信息聚合能力，限制了其在深度研究中的应用。本文提出“探索到进化”范式，通过主动在线探索和自我进化聚合程序来构建可验证的训练数据，并生成了包含10K样本的WebAggregatorQA数据集。在此基础上，我们开发了WebAggregator系列模型，其中WebAggregator-32B在GAIA-text基准测试上性能超越GPT-4.1。此外，我们构建了一个具有挑战性的评估集，以测试网络代理的信息聚合能力，现有模型在此测试集上表现不佳，凸显了增强网络代理信息聚合能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究型网络代理主要侧重于信息检索，而忽略了信息聚合这一关键能力，这限制了它们在深度研究中的应用。因此，有必要开发能够有效聚合信息以支持深度研究的网络代理。

Method: 本文提出了一种“探索到进化”的范式，首先通过主动在线探索从真实网络获取信息，然后利用收集到的证据，通过选择、组合和优化12种高级逻辑操作来生成可验证的问答对，从而自我进化出一个聚合程序。该范式用于生成WebAggregatorQA数据集。在此基础上，利用SmolAgents框架收集监督微调轨迹，开发了WebAggregator系列模型。

Result: WebAggregator-8B模型的性能与GPT-4.1相当，而WebAggregator-32B模型在GAIA-text基准测试上性能超越GPT-4.1超过10%，并接近Claude-3.7-sonnet的性能。在为评估信息聚合能力而构建的WebAggregatorQA评估集上，Claude-3.7-sonnet的准确率仅为28%，GPT-4.1为25.8%，即使在能够检索到所有参考文献的情况下，这些模型在该数据集上的表现仍然不佳。

Conclusion: 本文提出的“探索到进化”范式能够有效地扩展可验证训练数据的构建，并生成了WebAggregatorQA数据集。基于该数据集训练的WebAggregator模型在信息聚合能力上表现出色，尤其是在GAIA-text和新构建的WebAggregatorQA评估集上。研究结果表明，增强网络代理的信息聚合能力对于支持深度研究至关重要。

Abstract: Deep research web agents not only retrieve information from diverse sources
such as web environments, files, and multimodal inputs, but more importantly,
they need to rigorously analyze and aggregate knowledge for insightful
research. However, existing open-source deep research agents predominantly
focus on enhancing information-seeking capabilities of web agents to locate
specific information, while overlooking the essential need for information
aggregation, which would limit their ability to support in-depth research. We
propose an Explore to Evolve paradigm to scalably construct verifiable training
data for web agents. Begins with proactive online exploration, an agent sources
grounded information by exploring the real web. Using the collected evidence,
the agent then self-evolves an aggregation program by selecting, composing, and
refining operations from 12 high-level logical types to synthesize a verifiable
QA pair. This evolution from high-level guidance to concrete operations allowed
us to scalably produce WebAggregatorQA, a dataset of 10K samples across 50K
websites and 11 domains. Based on an open-source agent framework, SmolAgents,
we collect supervised fine-tuning trajectories to develop a series of
foundation models, WebAggregator. WebAggregator-8B matches the performance of
GPT-4.1, while the 32B variant surpasses GPT-4.1 by more than 10% on GAIA-text
and closely approaches Claude-3.7-sonnet. Moreover, given the limited
availability of benchmarks that evaluate web agents' information aggregation
abilities, we construct a human-annotated evaluation split of WebAggregatorQA
as a challenging test set. On this benchmark, Claude-3.7-sonnet only achieves
28%, and GPT-4.1 scores 25.8%. Even when agents manage to retrieve all
references, they still struggle on WebAggregatorQA, highlighting the need to
strengthen the information aggregation capabilities of web agent foundations.

</details>


### [197] [Natural Language Tools: A Natural Language Approach to Tool Calling In Large Language Agents](https://arxiv.org/abs/2510.14453)
*Reid T. Johnson,Michelle D. Pain,Jordan D. West*

Main category: cs.CL

TL;DR: NLT框架通过自然语言输出替代了LLM中程序化的JSON工具调用，提高了工具调用准确性（18.4%），降低了输出方差（70%），尤其是在开放权重模型上。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM中程序化JSON工具调用存在的任务干扰和格式限制问题，从而提高工具调用的性能。

Method: 提出了一种名为自然语言工具（NLT）的框架，该框架将工具选择与响应生成分离，并使用自然语言输出替代JSON工具调用。

Result: 在10个模型和6400次试验中，NLT将工具调用准确性提高了18.4个百分点，并将输出方差降低了70%。开放权重模型表现出最大的提升，并且该框架将工具调用能力扩展到了没有原生支持的模型上。

Conclusion: NLT框架通过自然语言输出有效解决了LLM工具调用的性能问题，尤其是在开放权重模型上，并具有广泛的应用前景。

Abstract: We present Natural Language Tools (NLT), a framework that replaces
programmatic JSON tool calling in large language models (LLMs) with natural
language outputs. By decoupling tool selection from response generation, NLT
eliminates task interference and format constraints that degrade tool call
performance. When evaluated across 10 models and 6,400 trials spanning customer
service and mental health domains, NLT improves tool calling accuracy by 18.4
percentage points while reducing output variance by 70%. Open-weight models see
the largest gains, surpassing flagship closed-weight alternatives, with
implications for model training in both reinforcement learning and supervised
fine-tuning stages. These improvements persist under prompt perturbations and
extend tool-calling capabilities to models lacking native support.

</details>


### [198] [LiRA: Linguistic Robust Anchoring for Cross-lingual Large Language Models](https://arxiv.org/abs/2510.14466)
*Haolin Li,Haipeng Zhang,Mang Li,Yaohua Wang,Lijie Wen,Yu Zhang,Biqing Huang*

Main category: cs.CL

TL;DR: LiRA框架通过Arca和LaSR模块，显著提升了低资源语言在跨语言表示、检索和推理方面的性能，并发布了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 高资源语言的大型语言模型性能已趋于饱和，但低资源语言因数据不足、翻译噪声和跨语言对齐不稳定等问题，性能仍有较大提升空间。

Method: LiRA框架包含两个模块：(i) Arca（Anchored Representation Composition Architecture），通过锚点对齐和多智能体协同编码将低资源语言锚定到英语语义空间，保持共享嵌入空间的几何稳定性；(ii) LaSR（Language-coupled Semantic Reasoner），在Arca的多语言表示之上增加了一个语言感知轻量级推理头，并进行一致性正则化，以统一训练目标，增强跨语言理解、检索和推理的鲁棒性。此外，还构建并发布了一个包含五种东南亚和两种南亚语言的多语言产品检索数据集。

Result: 在跨语言检索、语义相似度和推理等低资源基准测试中，LiRA在少样本和噪声放大设置下均取得了持续的性能提升和鲁棒性。消融实验验证了Arca和LaSR的有效性。

Conclusion: LiRA框架能有效提升低资源语言的跨语言表示、检索和推理能力，并解决了相关挑战。

Abstract: As large language models (LLMs) rapidly advance, performance on high-resource
languages (e.g., English, Chinese) is nearing saturation, yet remains
substantially lower for low-resource languages (e.g., Urdu, Thai) due to
limited training data, machine-translation noise, and unstable cross-lingual
alignment. We introduce LiRA (Linguistic Robust Anchoring for Large Language
Models), a training framework that robustly improves cross-lingual
representations under low-resource conditions while jointly strengthening
retrieval and reasoning. LiRA comprises two modules: (i) Arca (Anchored
Representation Composition Architecture), which anchors low-resource languages
to an English semantic space via anchor-based alignment and multi-agent
collaborative encoding, preserving geometric stability in a shared embedding
space; and (ii) LaSR (Language-coupled Semantic Reasoner), which adds a
language-aware lightweight reasoning head with consistency regularization on
top of Arca's multilingual representations, unifying the training objective to
enhance cross-lingual understanding, retrieval, and reasoning robustness. We
further construct and release a multilingual product retrieval dataset covering
five Southeast Asian and two South Asian languages. Experiments across
low-resource benchmarks (cross-lingual retrieval, semantic similarity, and
reasoning) show consistent gains and robustness under few-shot and
noise-amplified settings; ablations validate the contribution of both Arca and
LaSR. Code will be released on GitHub and the dataset on Hugging Face.

</details>


### [199] [Efficient Seq2seq Coreference Resolution Using Entity Representations](https://arxiv.org/abs/2510.14504)
*Matt Grenander,Shay B. Cohen,Mark Steedman*

Main category: cs.CL

TL;DR: Seq2seq核心模型在核心引用消解方面取得了新的最先进的性能，但牺牲了灵活性和效率，尤其是在对话等增量设置中。本文提出了一种压缩表示方法，通过提取和重组实体级标记并丢弃大部分其他输入标记来提高效率。


<details>
  <summary>Details</summary>
Motivation: Seq2seq核心模型在核心引用消解方面引入了一种新范例，但其在增量设置（如对话）中的效率和灵活性不足。

Method: 提出了一种压缩表示方法，通过提取和重组实体级标记并丢弃大部分其他输入标记来提高Seq2seq核心模型的效率。

Result: 在OntoNotes数据集上，该方法比增量基线模型仅低0.6 CoNLL F1点，同时实现了1.8的压缩率。在LitBank数据集上，该方法超过了最先进的性能。

Conclusion: 丢弃Seq2seq解析器中的大部分标记是增量核心引用消解的可行策略。

Abstract: Seq2seq coreference models have introduced a new paradigm for coreference
resolution by learning to generate text corresponding to coreference labels,
without requiring task-specific parameters. While these models achieve new
state-of-the-art performance, they do so at the cost of flexibility and
efficiency. In particular, they do not efficiently handle incremental settings
such as dialogue, where text must processed sequentially. We propose a
compressed representation in order to improve the efficiency of these methods
in incremental settings. Our method works by extracting and re-organizing
entity-level tokens, and discarding the majority of other input tokens. On
OntoNotes, our best model achieves just 0.6 CoNLL F1 points below a
full-prefix, incremental baseline while achieving a compression ratio of 1.8.
On LitBank, where singleton mentions are annotated, it passes state-of-the-art
performance. Our results indicate that discarding a wide portion of tokens in
seq2seq resolvers is a feasible strategy for incremental coreference
resolution.

</details>


### [200] [Assessing Socio-Cultural Alignment and Technical Safety of Sovereign LLMs](https://arxiv.org/abs/2510.14565)
*Kyubyung Chae,Gihoon Kim,Gyuseong Lee,Taesup Kim,Jaejin Lee,Heejin Kim*

Main category: cs.CL

TL;DR: 主权大语言模型（LLM）在低资源语言支持方面发挥作用，但其声称的“服务目标用户良好”的效用未经证实，并且可能低估了模型的安全性。建议采用更广泛、更实际的标准来评估主权大语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前关于主权大语言模型（LLM）的讨论日益增多，但缺乏验证模型是否符合用户社会文化背景以及模型在安全性和技术稳健性方面表现的框架和数据集。现有研究需要解决这些关键问题。

Method: 构建了一个新的数据集，并引入了一个分析框架，用于提取和评估主权大语言模型的社会文化要素，同时评估其技术稳健性。

Result: 实验结果表明，主权大语言模型在支持低资源语言方面有积极作用，但并未总是满足其“服务目标用户良好”的说法。此外，追求这一未经测试的说法可能导致低估模型的安全性等关键质量属性。

Conclusion: 主权大语言模型的发展需要更广泛、更可靠、更实用的评估标准，以确保其在满足用户需求的同时，在安全性和技术稳健性方面也达到要求。

Abstract: Recent trends in LLMs development clearly show growing interest in the use
and application of sovereign LLMs. The global debate over sovereign LLMs
highlights the need for governments to develop their LLMs, tailored to their
unique socio-cultural and historical contexts. However, there remains a
shortage of frameworks and datasets to verify two critical questions: (1) how
well these models align with users' socio-cultural backgrounds, and (2) whether
they maintain safety and technical robustness without exposing users to
potential harms and risks. To address this gap, we construct a new dataset and
introduce an analytic framework for extracting and evaluating the
socio-cultural elements of sovereign LLMs, alongside assessments of their
technical robustness. Our experimental results demonstrate that while sovereign
LLMs play a meaningful role in supporting low-resource languages, they do not
always meet the popular claim that these models serve their target users well.
We also show that pursuing this untested claim may lead to underestimating
critical quality attributes such as safety. Our study suggests that advancing
sovereign LLMs requires a more extensive evaluation that incorporates a broader
range of well-grounded and practical criteria.

</details>


### [201] [Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures](https://arxiv.org/abs/2510.14616)
*Shuangshuang Ying,Yunwen Li,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Xeron Du,Tianyu Zheng,Yichi Zhang,Letian Ni,Yuyang Cheng,Qiguang Chen,Jingzhe Ding,Shengda Long,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Ge Zhang,Wenhao Huang,Wanxiang Che,Chenghua Lin*

Main category: cs.CL

TL;DR: 当前偏好学习方法在标准基准上表现良好，但在缺乏客观质量信号时性能会显著下降。本研究提出了WritingPreferenceBench数据集，包含1800个人类标注的偏好对（1200个英语，600个中文），涵盖8种创意写作类型，并匹配了客观正确性、事实准确性和长度。在此基准上，基于序列的奖励模型（RLHF的标准架构）准确率仅为52.7%，零样本语言模型判断器的准确率为53.9%。相比之下，生成式奖励模型通过明确的推理链可达到81.8%的准确率。我们发现在不同体裁之间存在显著的组内方差，单个模型的准确率在不同写作类别之间差异很大（18.2%至81.8%），平均标准差为10.1%。这种方差与模型规模无关，27B参数模型并未比8B模型有持续改进。研究结果表明，现有的RLHF方法主要学习检测客观错误，而非捕捉主观质量偏好（如创造力、风格和情感共鸣），且成功的偏好建模可能需要中间推理表示，而非直接分类。


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习方法在缺乏客观质量信号时性能下降，需要新的评估方式和更有效的模型。

Method: 提出了WritingPreferenceBench数据集，包含1800个人类标注的偏好对，涵盖8种创意写作类型，并对响应进行了客观匹配。在基准上评估了基于序列的奖励模型、零样本语言模型判断器和生成式奖励模型。

Result: 在WritingPreferenceBench基准上，序列奖励模型准确率为52.7%，零样本语言模型判断器为53.9%，生成式奖励模型为81.8%。不同模型在不同体裁的准确率差异很大（18.2%-81.8%），且与模型规模无关。

Conclusion: 当前RLHF方法主要关注客观错误而非主观偏好，未来的偏好建模需要中间推理表示。

Abstract: Current preference learning methods achieve high accuracy on standard
benchmarks but exhibit significant performance degradation when objective
quality signals are removed. We introduce WritingPreferenceBench, a dataset of
1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8
creative writing genres, where responses are matched for objective correctness,
factual accuracy, and length. On this benchmark, sequence-based reward
models--the standard architecture for RLHF--achieve only 52.7% mean accuracy,
while zero-shot language model judges perform at 53.9%. In contrast, generative
reward models that produce explicit reasoning chains achieve 81.8% accuracy. We
observe high within-model variance across genres: individual models range from
18.2% to 81.8% accuracy across different writing categories, with standard
deviations averaging 10.1%. This variance persists regardless of model scale,
with 27B parameter models showing no consistent improvement over 8B variants.
Our results suggest that current RLHF methods primarily learn to detect
objective errors rather than capture subjective quality preferences (e.g.,
creativity, stylistic flair, and emotional resonance), and that successful
preference modeling may require intermediate reasoning representations rather
than direct classification.

</details>


### [202] [Code-driven Number Sequence Calculation: Enhancing the inductive Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2510.14620)
*Kedi Chen,Zhikai Lei,Xu Guo,Xuecheng Wu,Siyuan Zeng,Jianghao Yin,Yinqi Zhang,Qin Chen,Jie Zhou,Liang He,Qipeng Guo,Kai Chen,Wei Zhang*

Main category: cs.CL

TL;DR: CodeSeq是一个包含数字序列算法问题的合成数据集，旨在提升LLMs的归纳推理能力，通过自动化数据生成和强化学习优化训练过程。


<details>
  <summary>Details</summary>
Motivation: 现有归纳推理研究面临数据侧重表面规律、缺乏复杂内部模式以及模型训练方式简单（仅提示或简单微调）等挑战，未能提供精确的思维过程和难度控制。

Method: 提出CodeSeq数据集，将数字序列包装成发现通项的算法问题，定义了通项生成（GTG）任务。通过反思失败测试用例并迭代修正来生成监督微调数据，实现自主案例生成和自我检查。利用基于可解性和自我指导案例生成成功率的案例协同可解性缩放奖励进行强化学习。

Result: 在各种推理任务上，使用CodeSeq训练的模型均有提升，并且能保持模型在（OOD）上的性能。

Conclusion: CodeSeq通过提供更复杂的归纳推理数据和更精细的训练方法，有效提升了LLMs的推理能力，并有助于保持其在未见过数据上的泛化性能。

Abstract: Large language models (LLMs) make remarkable progress in reasoning tasks.
Among different reasoning modes, inductive reasoning, due to its better
alignment with human learning, attracts increasing interest. However, research
on inductive reasoning faces certain challenges. First, existing inductive data
mostly focuses on superficial regularities while lacking more complex internal
patterns. Second, current works merely prompt LLMs or finetune on simple
prompt-response pairs, but do not provide precise thinking processes nor
implement difficulty control. Unlike previous work, we address these challenges
by introducing \textit{CodeSeq}, a synthetic post-training dataset built from
number sequences. We package number sequences into algorithmic problems to
discover their general terms, defining a general term generation (GTG) task
correspondingly. Our pipeline generates supervised finetuning data by
reflecting on failed test cases and incorporating iterative corrections,
thereby teaching LLMs to learn autonomous case generation and self-checking.
Additionally, it leverages reinforcement learning with a novel Case-Synergy
Solvability Scaling Reward based on both solvability, estimated from the
problem pass rate, and the success rate of self-directed case generation,
enabling models to learn more effectively from both successes and failures.
Experimental results show that the models trained with \textit{CodeSeq} improve
on various reasoning tasks and can preserve the models' OOD performance.

</details>


### [203] [RLAIF-SPA: Optimizing LLM-based Emotional Speech Synthesis via RLAIF](https://arxiv.org/abs/2510.14628)
*Qing Yang,Zhenghao Liu,Junxin Wang,Yangfan Du,Pengcheng Huang,Tong Xiao*

Main category: cs.CL

TL;DR: RLAIF-SPA框架通过引入基于AI反馈的强化学习，利用ASR和LLM技术，在语音合成中实现了更好的情感表达和语义准确性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到语音（TTS）合成技术在生成中性语音方面已接近人声水平，但在情感表达方面仍存在挑战，通常需要昂贵的表情注解，或优化间接目标，导致生成语音情感平淡。

Method: 提出RLAIF-SPA框架，结合强化学习（RLAIF）机制，利用自动语音识别（ASR）判断语义准确性，利用大型语言模型（LLM）判断韵律-情感标签一致性，作为直接奖励来优化情感表达和可懂度。该框架整合了韵律标签对齐（Prosodic Label Alignment）以提升韵律质量，并考虑了结构、情感、语速和语调四个维度，同时加入语义准确性反馈（Semantic Accuracy Feedback）确保语音清晰准确。

Result: 在Libri Speech数据集上的实验表明，RLAIF-SPA相较于Chat-TTS，词错误率（WER）降低了26.1%，SIM-O提高了9.1%，并在人工评估中取得了超过10%的提升。

Conclusion: RLAIF-SPA框架通过结合RLAIF、ASR和LLM，在提升语音合成的情感表现力和可懂度方面取得了显著成效，优于现有方法。

Abstract: Text-To-Speech synthesis has achieved near-human quality in neutral speech,
but emotional expressiveness remains a challenge. Existing methods often rely
on costly emotion annotations or optimize indirect objectives that fail to
capture the emotional expressiveness and perceptual naturalness of speech,
leading to generated speech that is accurate but emotionally flat. To address
these challenges, we propose the RLAIF-SPA framework, incorporating a
Reinforcement Learning from AI Feedback (RLAIF) mechanism to employ Automatic
Speech Recognition (ASR) and Large Language Model (LLM) techniques to
respectively judge semantic accuracy and prosodic-emotional label alignment as
a direct reward for emotional expressiveness and intelligibility optimization.
Specifically, it leverages Prosodic Label Alignment to enhance expressive
quality by jointly considering semantic accuracy and prosodic-emotional
alignment along four fine-grained dimensions: Structure, Emotion, Speed, and
Tone. In addition, it incorporates Semantic Accuracy Feedback to ensure the
generation of clear and accurate speech. Experiments on the Libri Speech
dataset show that RLAIF-SPA outperforms Chat-TTS, with a 26.1% reduction in
WER, a 9.1% increase in SIM-O, and over 10% improvement in human evaluation.

</details>


### [204] [Intent Clustering with Shared Pseudo-Labels](https://arxiv.org/abs/2510.14640)
*I-Fan Lin,Faegheh Hasibi,Suzan Verberne*

Main category: cs.CL

TL;DR: 提出一种直观、无需训练、无需标签的意图聚类方法，该方法利用轻量级、开源的LLM，并最少化假设。


<details>
  <summary>Details</summary>
Motivation: 当前许多方法依赖于昂贵且不透明的商业LLM，并且通常需要预先知道聚类数量，这在现实中并不常见。

Method: 首先让LLM为每个文本生成伪标签，然后在该伪标签集中对每个文本执行多标签分类，而不是直接要求LLM匹配相似文本。该方法基于一个假设：属于同一聚类的文本将共享更多的标签，因此在编码为嵌入时会更接近。

Result: 在四个基准测试集上的评估表明，该方法取得了与近期基线相当甚至更优的结果，同时保持简单且计算高效。

Conclusion: 研究结果表明，该方法可应用于低资源场景，并且在多个模型和数据集上表现稳定。

Abstract: In this paper, we propose an intuitive, training-free and label-free method
for intent clustering that makes minimal assumptions using lightweight and
open-source LLMs. Many current approaches rely on commercial LLMs, which are
costly, and offer limited transparency. Additionally, their methods often
explicitly depend on knowing the number of clusters in advance, which is often
not the case in realistic settings. To address these challenges, instead of
asking the LLM to match similar text directly, we first ask it to generate
pseudo-labels for each text, and then perform multi-label classification in
this pseudo-label set for each text. This approach is based on the hypothesis
that texts belonging to the same cluster will share more labels, and will
therefore be closer when encoded into embeddings. These pseudo-labels are more
human-readable than direct similarity matches. Our evaluation on four benchmark
sets shows that our approach achieves results comparable to and better than
recent baselines, while remaining simple and computationally efficient. Our
findings indicate that our method can be applied in low-resource scenarios and
is stable across multiple models and datasets.

</details>


### [205] [An Efficient Rubric-based Generative Verifier for Search-Augmented LLMs](https://arxiv.org/abs/2510.14660)
*Linyue Ma,Yilong Xu,Xiang Long,Zhi Zheng*

Main category: cs.CL

TL;DR: 提出了一种名为“nugget-as-rubric”的新范式，用于改进检索增强型大语言模型的奖励模型，解决了现有方法的局限性，并通过Search-Gen-V验证器和自动标注构建流程实现了可验证、鲁棒且高效的奖励构建。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强型大语言模型（LLM）的奖励建模方法存在局限性：基于规则的奖励（如精确匹配）虽然可验证但不够鲁棒，无法处理长文本；生成式奖励更鲁棒但难以设计可验证、稳定的长文本奖励，且计算成本高。

Method: 提出了一种名为“nugget-as-rubric”的统一可验证范式，将原子信息点视为结构化评估标准。对于短文本任务，使用单一标准；对于长文本任务，根据问题的信息需求扩展到多个标准。设计了一个基于查询重写的自动标注构建流程，用于从静态语料库和动态在线内容中提取标注。引入了一个名为Search-Gen-V的40亿参数生成式验证器，采用蒸馏和两阶段策略进行训练。

Result: Search-Gen-V在不同工作负载下实现了强大的验证准确性，证明了其作为检索增强型LLM的可扩展、鲁棒且高效的可验证奖励构建器的潜力。

Conclusion: “nugget-as-rubric”范式提供了一种统一且可验证的方法来构建检索增强型LLM的奖励模型，Search-Gen-V验证器和自动标注构建流程解决了现有方法的不足，为长文本和动态语料库场景下的LLM任务提供了更优的解决方案。

Abstract: Search augmentation empowers Large Language Models with retrieval
capabilities to overcome the limitations imposed by static parameters.
Recently, Reinforcement Learning leverages tailored reward signals as a viable
technique to enhance LLMs performing tasks involving search. However, existing
reward modeling for search-augmented LLMs faces several limitations. Rule-based
rewards, such as Exact Match, are verifiable but fragile to variations in
expression and cannot be applied to long-form workloads. In contrast,
generative rewards improve robustness, but designing verifiable and stable
rewards for long-form workloads in dynamic corpora remains challenging and also
incurs high computational costs. In this paper, we propose a unified and
verifiable paradigm, "nugget-as-rubric", which treats atomic information points
as structured evaluation criteria for different search-augmentation workloads.
Short-form tasks correspond to a single rubric, whereas long-form tasks expand
to multiple rubrics aligned with the question's information needs. To support
long-form settings, we design an automatic rubric construction pipeline based
on query rewriting, which can automatically retrieve passages relevant to each
question and extract rubrics from them, both from static corpora and from
dynamic online web content. Furthermore, we introduce \textbf{Search-Gen-V}, a
4B-parameter efficient generative verifier under our proposed verifiable
paradigm, which is trained via the idea of distillation and a two-stage
strategy. Experimental results show that Search-Gen-V achieves strong
verification accuracy across different workloads, making it a scalable, robust,
and efficient verifiable reward constructor for search-augmented LLMs.

</details>


### [206] [Semantic Prosody in Machine Translation: the English-Chinese Case of Passive Structures](https://arxiv.org/abs/2510.14662)
*Xinyue Ma,Pol Pastells,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Semantic prosody is a collocational meaning formed through the co-occurrence
of a linguistic unit and a consistent series of collocates, which should be
treated separately from semantic meaning. Since words that are literal
translations of each other may have different semantic prosody, more attention
should be paid to this linguistic property to generate accurate translations.
However, current machine translation models cannot handle this problem. To
bridge the gap, we propose an approach to teach machine translation models
about semantic prosody of a specific structure. We focus on Chinese BEI
passives and create a dataset of English-Chinese sentence pairs with the
purpose of demonstrating the negative semantic prosody of BEI passives. Then we
fine-tune OPUS-MT, NLLB-600M and mBART50 models with our dataset for the
English-Chinese translation task. Our results show that fine-tuned MT models
perform better on using BEI passives for translating unfavourable content and
avoid using it for neutral and favourable content. Also, in NLLB-600M, which is
a multilingual model, this knowledge of semantic prosody can be transferred
from English-Chinese translation to other language pairs, such as
Spanish-Chinese.

</details>


### [207] [Speculative Model Risk in Healthcare AI: Using Storytelling to Surface Unintended Harms](https://arxiv.org/abs/2510.14718)
*Xingmeng Zhao,Dan Schumacher,Veronica Rammouz,Anthony Rios*

Main category: cs.CL

TL;DR: AI在医疗领域的快速发展带来了偏见、隐私侵犯和不平等访问等风险。本文提出了一个以用户为中心的框架，通过生成用户故事和支持多方讨论，帮助人们在部署前思考AI的潜在风险和收益。用户研究表明，阅读用户故事有助于参与者更全面地识别AI可能带来的各种风险。


<details>
  <summary>Details</summary>
Motivation: AI在医疗领域的快速发展可能带来偏见、隐私侵犯和不平等访问等风险，而现有方法侧重于自动检测风险，可能减少人类在理解风险产生机制和影响人群方面的参与。因此，需要一种方法来促进对AI潜在风险和收益的更深入、更具创造性的思考。

Method: 提出一个以用户为中心的框架，该框架通过生成用户故事和支持多方讨论，来帮助人们在部署AI工具前，能够创造性地思考其潜在的收益和风险。

Result: 在用户研究中，阅读了用户故事的参与者能够识别更广泛的潜在风险，并将他们的回应更均匀地分布在所有13种风险类型上。相比之下，没有阅读用户故事的参与者主要关注隐私和福祉（占58.3%）。

Conclusion: 故事叙述有助于参与者推测更广泛的风险和收益，并能更具创造性地思考AI对用户的影响。

Abstract: Artificial intelligence (AI) is rapidly transforming healthcare, enabling
fast development of tools like stress monitors, wellness trackers, and mental
health chatbots. However, rapid and low-barrier development can introduce risks
of bias, privacy violations, and unequal access, especially when systems ignore
real-world contexts and diverse user needs. Many recent methods use AI to
detect risks automatically, but this can reduce human engagement in
understanding how harms arise and who they affect. We present a human-centered
framework that generates user stories and supports multi-agent discussions to
help people think creatively about potential benefits and harms before
deployment. In a user study, participants who read stories recognized a broader
range of harms, distributing their responses more evenly across all 13 harm
types. In contrast, those who did not read stories focused primarily on privacy
and well-being (58.3%). Our findings show that storytelling helped participants
speculate about a broader range of harms and benefits and think more creatively
about AI's impact on users.

</details>


### [208] [AutoRubric-R1V: Rubric-Based Generative Rewards for Faithful Multimodal Reasoning](https://arxiv.org/abs/2510.14738)
*Mengzhao Jia,Zhihan Zhang,Ignacio Cases,Zheyuan Liu,Meng Jiang,Peng Qi*

Main category: cs.CL

TL;DR: 该研究提出了AutoRubric-R1V框架，通过结合基于过程的监督和自动生成的评分标准来解决多模态大语言模型（MLLM）在多步推理中可能出现的错误推理问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）在多步推理任务中存在错误推理的风险，因为传统的强化学习方法（RLVR）仅根据最终答案的正确性进行奖励，忽略了推理过程的合理性。

Method: 提出AutoRubric-R1V框架，该框架集成了RLVR与通过自动收集的、基于评分标准的生成奖励来实现的过程监督。其核心创新在于一种可扩展的自聚合方法，能够从成功的推理轨迹中提炼出一致的推理检查点，从而在没有人为标注或更强的教师模型的情况下构建特定问题的评分标准。通过联合利用基于评分标准和基于结果的奖励，该框架能够改进推理的忠实度。

Result: AutoRubric-R1V框架在六个多模态推理基准测试中取得了最先进的性能，并显著提高了推理的忠实度。

Conclusion: AutoRubric-R1V框架通过结合过程监督和自动生成的评分标准，有效地解决了MLLM在多步推理中的错误推理问题，并在多个任务上取得了显著的性能提升。

Abstract: Multimodal large language models (MLLMs) have rapidly advanced from
perception tasks to complex multi-step reasoning, yet reinforcement learning
with verifiable rewards (RLVR) often leads to spurious reasoning since only the
final-answer correctness is rewarded. To address this limitation, we propose
AutoRubric-R1V, a framework that integrates RLVR with process-level supervision
through automatically collected rubric-based generative rewards. Our key
innovation lies in a scalable self-aggregation method that distills consistent
reasoning checkpoints from successful trajectories, enabling problem-specific
rubric construction without human annotation or stronger teacher models. By
jointly leveraging rubric-based and outcome rewards, AutoRubric-R1V achieves
state-of-the-art performance on six multimodal reasoning benchmarks and
substantially improves reasoning faithfulness in dedicated evaluations.

</details>


### [209] [Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code](https://arxiv.org/abs/2510.14756)
*Manar Abdelatty,Maryam Nouh,Jacob K. Rosenstein,Sherief Reda*

Main category: cs.CL

TL;DR: LLM在硬件设计中生成Verilog代码时，现有的基准测试无法全面评估其综合效率（面积、延迟、功耗）。我们提出了Pluto框架，包含114个问题、自检测试平台和参考实现，用于评估LLM生成设计的效率。实验表明，LLM在功能正确性上表现良好（pass@1为78.3%），但在效率方面（面积、延迟、功耗）仍落后于专家设计（eff@1分别为63.8%、65.9%、64.0%），凸显了Pluto等效率感知评估框架的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的硬件设计基准测试在评估LLM生成Verilog代码的综合效率（面积、延迟、功耗）方面存在不足，缺乏优化基线和验证测试平台。

Method: 提出Pluto基准测试和评估框架，包含114个问题、自检测试平台和多个帕累托最优参考实现，用于评估LLM生成Verilog设计的效率。

Result: 实验结果显示，LLM在功能正确性方面达到pass@1的78.3%，但在面积效率（eff@1为63.8%）、延迟效率（eff@1为65.9%）和功耗效率（eff@1为64.0%）方面仍低于专家设计。

Conclusion: LLM在硬件设计方面虽然功能正确性较高，但其综合效率仍需提高，Pluto等效率感知评估框架对于推动LLM在硬件设计领域的研究至关重要。

Abstract: Large Language Models (LLMs) are increasingly used to automate hardware
design tasks, including the generation of Verilog code. While early benchmarks
focus primarily on functional correctness, efficient hardware design demands
additional optimization for synthesis metrics such as area, delay, and power.
Existing benchmarks fall short in evaluating these aspects comprehensively:
they often lack optimized baselines or testbenches for verification. To address
these gaps, we present Pluto, a benchmark and evaluation framework designed to
assess the efficiency of LLM-generated Verilog designs. Pluto presents a
comprehensive evaluation set of 114 problems with self-checking testbenches and
multiple Pareto-optimal reference implementations. Experimental results show
that state-of-the-art LLMs can achieve high functional correctness, reaching
78.3\% at pass@1, but their synthesis efficiency still lags behind
expert-crafted implementations, with area efficiency of 63.8\%, delay
efficiency of 65.9\%, and power efficiency of 64.0\% at eff@1. This highlights
the need for efficiency-aware evaluation frameworks such as Pluto to drive
progress in hardware-focused LLM research.

</details>


### [210] [COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes](https://arxiv.org/abs/2510.14763)
*Yunwen Li,Shuangshuang Ying,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Tianyu Zheng,Xeron Du,Qiguang Chen,Jiajun Shi,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Stephen Huang,Wanxiang Che,Chenghua Lin,Eli Zhang*

Main category: cs.CL

TL;DR: COIG-Writer是一个包含1665个三元组（逆向工程提示、创作推理、最终文本）的新型中文创意写作数据集，旨在解决大型语言模型在非英语创意写作中的不足。实验表明，过程监督对提高写作能力至关重要，但需要通用数据来稳定（建议比例至少为1:12），创意写作能力具有文化特异性且无跨语言迁移，并且词汇多样性与创意质量呈负相关（TTR悖论）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在创意写作方面存在系统性缺陷，尤其是在训练数据稀缺且缺乏过程监督的非英语环境中。COIG-Writer数据集旨在通过捕捉多样化输出及其潜在思维过程来解决这一问题。

Method: 构建了一个包含1665个三元组（逆向工程提示、创作推理、最终文本）的新型中文创意写作数据集COIG-Writer，并进行了相关实验。

Result: 实验发现，过程监督是有效的，但需要与通用数据（至少1:12的比例）结合以达到最佳性能。创意写作能力具有文化特异性，跨语言迁移效果差（中英表现差距89.26pp）。词汇多样性与创意质量呈负相关（TTR悖论）。

Conclusion: 创意写作能力源于逻辑构建（过程监督）和语言表达（通用数据）的相互作用。过程监督至关重要，但需要足够且稳定的通用数据支持。创意能力具有文化特异性，并且过高的词汇多样性可能掩盖逻辑缺陷。

Abstract: Large language models exhibit systematic deficiencies in creative writing,
particularly in non-English contexts where training data is scarce and lacks
process-level supervision. We present COIG-Writer, a novel Chinese creative
writing dataset that captures both diverse outputs and their underlying thought
processes through systematic reverse-engineering of high-quality texts. Unlike
existing datasets that provide only input-output pairs, COIG-Writer comprises
1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a
reverse-engineered prompt, (2) detailed creative reasoning documenting
decision-making processes, and (3) the final text. Through comprehensive
experiments, we identify a two-component model of creative writing: narrative
logic (provided by process supervision) and linguistic expression (maintained
by general-purpose data). Our findings reveal three critical insights: (1)
Process supervision is highly effective but requires stabilization with general
data. A ratio of at least one creative sample to twelve general samples is
needed to achieve optimal performance; below this threshold, the win rate
progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities
are culturally-bound with no cross-lingual transfer (89.26pp gap between
Chinese and English performance), and (3) lexical diversity inversely
correlates with creative quality (TTR paradox), suggesting high diversity
signals compensatory behavior for logical deficiencies. These findings
establish that creative excellence emerges from the interaction between logical
scaffolding and linguistic grounding, analogous to how mathematical reasoning
enhances but cannot replace linguistic competence in foundation models.

</details>


### [211] [Finding Answers in Thought Matters: Revisiting Evaluation on Large Language Models with Reasoning](https://arxiv.org/abs/2510.14773)
*Hwiyeol Jo,Joosung Lee,Jaehone Lee,Sang-Woo Lee,Joonsuk Park,Kang Min Yoo*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“Answer Regeneration”的框架，用于改进生成模型（尤其是需要推理能力的LLMs）的评估方法。该方法通过额外的模型推理来重新生成答案，并从中提取最终答案，以减少提取算法对模型性能和最终答案分布的影响，从而提高评估的可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 评估需要推理能力的生成模型（如LLMs）通常依赖于从答案选项中选择最终答案的概率。然而，这种方法对答案提取算法非常敏感。本研究的动机是提出一种新的评估框架，以减轻这种敏感性，并提供更可靠的模型评估结果。

Method: 提出了一种名为“Answer Regeneration”的框架。该方法通过利用一个额外的模型推理步骤，在给出先前输入和输ser出的提示“Answer:”之后，重新生成答案。然后，从重新生成的输出中选择或提取最终答案。这是一种不依赖于特定提取规则的方法。

Result: 实验表明，“Answer Regeneration”方法在应用于通用数学问题和开放式问答任务时，相比于传统的评估方法，表现出更高的性能和更强的鲁棒性。

Conclusion: “Answer Regeneration”框架通过引入额外的模型推理来重新生成答案，可以减少答案提取算法对模型性能和最终答案分布的影响，从而为模型评估提供更可靠和更鲁棒的结果。该框架在数学问题和开放式问答任务上得到了验证。

Abstract: Evaluating generative models, such as large language models (LLMs), commonly
involves question-answering tasks where the final answer is selected based on
probability of answer choices. On the other hand, for models requiring
reasoning, the method of answer extraction plays a critical role. Our research
reveals that the performance of reasoning models and their final answer
distributions are highly sensitive to the answer extraction algorithm employed.
In order to mitigate this, we propose a basic framework: Answer Regeneration.
The method uses an additional model inference, providing the prior input and
output prefaced by the prompt "Answer:". The final answer is then selected or
extracted from the regenerated output. We show that this
extraction-rule-agnostic approach exhibits improved performance and enhanced
robustness. Furthermore, we have applied this framework to general math
problems and open-ended question answering tasks. Our analysis and this
framework could offer a more reliable results for model evaluation.

</details>


### [212] [Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking](https://arxiv.org/abs/2510.14824)
*Ziqi Dai,Xin Zhang,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Meishan Zhang,Wenjie Li,Min Zhang*

Main category: cs.CL

TL;DR: 在LLM信息检索的重排任务中，本文比较了对比学习（CL）和监督微调（SFT）这两种主要训练目标，发现SFT在更新权重方面优于CL，从而在LLM重排任务中取得更好的效果，并在MRB基准测试中取得了新的最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，在BERT等模型上，对比学习（CL）比分类学习（SFT）更有效；然而，对于大型语言模型（LLM），SFT似乎更具潜力，因为它符合LLM的生成特性。这种差异引发了一个核心问题：哪种目标更适合LLM重排，其内在机制是什么？

Method: 本文提出了一个统一的框架来理解CL和SFT的目标分解（权重和方向），并在通用多模态检索（UMR）任务上进行了实验比较和分析，以确定哪种方法更适合LLM重排。

Result: 通过探究性实验，本文发现SFT比CL提供了更强的权重机制，而方向性则没有明显优势。这些结果表明SFT在LLM重排方面优于CL。

Conclusion: SFT在LLM重排任务中比CL具有更优越的性能，这主要归功于其更强的权重更新机制。此外，研究通过大规模训练和实验验证了SFT的有效性，并在MRB基准测试中取得了新的最先进成果。实验结果为未来LLM重排的研究和应用提供了指导。

Abstract: In information retrieval, training reranking models mainly focuses on two
types of objectives: metric learning (e.g. contrastive loss to increase the
predicted scores on relevant query-document pairs) and classification (binary
label prediction of relevance vs. irrelevance). For BERT-style encoders,
various studies have shown that contrastive learning (CL) can be more effective
than discriminative (classification) learning. However, for large language
models (LLMs), classification via supervised fine-tuning (SFT), which predicts
''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears
more promising as it aligns well with the generative nature of LLMs. This
divergence raises a central question: which objective is intrinsically better
suited to LLM-based reranking, and what mechanism underlies the difference? In
this work, we conduct a comprehensive comparison and analysis between CL and
SFT for reranking, taking the universal multimodal retrieval (UMR) as the
experimental playground. We first decompose the objectives into two components:
weight, which controls the magnitude of those updates, and direction, which
guides the model updates, then present a unified framework for understanding
their interactions. Through probing experiments, we find that SFT provides a
substantially stronger weighting scheme than CL, whereas the preferred scoring
direction shows no clear winner. Taken together, these results point to a
consistent advantage of SFT over CL for LLM reranking. To further validate our
findings, we conduct large-scale training with SFT and present new
state-of-the-art rerankers on the MRB benchmark. We also provide ablations on
SFT settings and expect our findings to benefit future research and
applications in this area.

</details>


### [213] [Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models](https://arxiv.org/abs/2510.14853)
*Guinan Su,Yanwu Yang,Li Shen,Lu Yin,Shiwei Liu,Jonas Geiping*

Main category: cs.CL

TL;DR: 该研究提出了一种无需外部数据、在线的测试时框架，用于优化MoE模型的路由决策，以解决因部署时分布变化导致的次优路由问题。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应方法主要针对密集模型，且需要访问外部数据，这限制了它们在MoE模型上的实际应用。本研究旨在解决MoE模型在部署时因分布变化导致的次优路由问题，而无需外部数据。

Method: 提出了一种数据无关、在线的测试时框架，在文本生成过程中持续自适应地调整MoE路由决策。该方法在预填充阶段和定期间隔进行路由决策优化，优化方式是基于已生成序列的自监督学习。通过轻量级的加性向量更新选定层的路由逻辑，以保持计算效率并防止过度适应。

Result: 该方法在推理任务上展现出持续的性能提升，并保持了对上下文变化的鲁棒性。在HumanEval上使用OLMoE实现了5.5%的提升，并与self-consistency结合在DeepSeek-V2-Lite上实现了6%的平均收益。

Conclusion: 所提出的数据无关、在线的测试时框架能够有效地优化MoE模型的路由决策，提升模型在推理任务上的性能和鲁棒性，并且可以方便地与现有技术结合使用。

Abstract: Mixture-of-Experts (MoE) models achieve efficient scaling through sparse
expert activation, but often suffer from suboptimal routing decisions due to
distribution shifts in deployment. While existing test-time adaptation methods
could potentially address these issues, they primarily focus on dense models
and require access to external data, limiting their practical applicability to
MoE architectures. However, we find that, instead of relying on reference data,
we can optimize MoE expert selection on-the-fly based only on input context. As
such, we propose \textit{a data-free, online test-time framework} that
continuously adapts MoE routing decisions during text generation without
external supervision or data. Our method cycles between two phases: During the
prefill stage, and later in regular intervals, we optimize the routing
decisions of the model using self-supervision based on the already generated
sequence. Then, we generate text as normal, maintaining the modified router
until the next adaption. We implement this through lightweight additive vectors
that only update router logits in selected layers, maintaining computational
efficiency while preventing over-adaptation. The experimental results show
consistent performance gains on challenging reasoning tasks while maintaining
robustness to context shifts. For example, our method achieves a 5.5\%
improvement on HumanEval with OLMoE. Furthermore, owing to its plug-and-play
property, our method naturally complements existing test-time scaling
techniques, e.g., achieving 6\% average gains when incorporated with
self-consistency on DeepSeek-V2-Lite.

</details>


### [214] [Midtraining Bridges Pretraining and Posttraining Distributions](https://arxiv.org/abs/2510.14865)
*Emmy Liu,Graham Neubig,Chenyan Xiong*

Main category: cs.CL

TL;DR: 在预训练后期加入指令格式数据（称为“中期训练”）的语言模型，在数学和代码等领域表现更优，因为它能有效缩小预训练和后续训练数据的句法差距，且比持续预训练更能减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补当前对语言模型“中期训练”阶段有效性认识的空白，并系统性地探究其背后的科学原理。

Method: 通过从头预训练语言模型，并在不同领域使用监督微调数据集进行微调，进行受控实验，系统地研究中期训练。

Result: 中期训练在数学和代码领域的表现最优，能有效缩小预训练和后续训练数据间的句法差距。中期训练在减少遗忘方面优于持续预训练，并且在代码中期训练的案例研究中发现，中期训练的开始时间比混合权重对模型性能影响更大，较早引入专业数据能带来更好的领域内表现和更强的泛化能力。

Conclusion: 中期训练作为一种领域自适应技术，通过减少遗忘，相比持续预训练能获得更好的性能。

Abstract: Recently, many language models have been pretrained with a "midtraining"
phase, in which higher quality, often instruction-formatted data, is mixed in
at the end of pretraining. Despite the popularity of this practice, there is
little scientific understanding of this phase of model training or why it is
effective. In this work, we conduct the first systematic investigation of
midtraining through controlled experiments with language models pretrained from
scratch and fine-tuned on supervised finetuning datasets in different domains.
We find that when compared after supervised fine-tuning, the effectiveness of
midtraining is highest in the math and code domains, where midtraining can best
reduce the syntactic gap between pretraining and posttraining data. In these
cases, midtraining consistently outperforms continued pretraining in both
in-domain validation loss as well as pretraining data forgetting after
posttraining. We conduct ablations on the starting time of the midtraining
phase and mixture weights of the midtraining data, using code midtraining as a
case study, and find that timing has a greater impact than mixture weights,
with earlier introduction of specialized data, yielding greater benefits
in-domain as well as preserving general language modeling better. These
findings establish midtraining as a domain adaptation technique that compared
to continued pretraining yields better performance through reduced forgetting.

</details>


### [215] [DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation](https://arxiv.org/abs/2510.14949)
*Yu Zhou,Sohyun An,Haikang Deng,Da Yin,Clark Peng,Cho-Jui Hsieh,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: 当前的多模态生成模型在处理包含方言词语的提示时，性能会显著下降，即使只有一个方言词语也会导致32.26%到48.17%的性能下降。现有的缓解方法（如微调和提示重写）效果有限，并且可能损害模型在标准美国英语（SAE）上的性能。本研究提出了一种新的基于编码器的缓解策略，该策略能够在新模型上将五种方言的性能提升至与SAE相当的水平（+34.4%），同时几乎不影响SAE性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究多模态生成模型在处理包含方言输入的文本时是否存在性能下降的问题，并提出有效的缓解策略。

Method: 构建了一个包含六种常见英语方言的大型基准，收集了超过4200个独特提示，并评估了17个图像和视频生成模型。研究人员还设计了一种通用的基于编码器的缓解策略，用于提高模型识别方言特征的能力，同时保持其在标准美国英语上的性能。

Result: 实验结果表明，当前最先进的多模态生成模型在提示中包含单个方言词语时，性能会下降32.26%至48.17%。现有的缓解方法效果不佳，且可能损害模型在标准美国英语上的性能。所提出的基于编码器的缓解策略能够将五种方言的性能提升至与标准美国英语相当的水平，同时几乎不影响标准美国英语的性能。

Conclusion: 本研究提出的基于编码器的缓解策略能够有效地解决多模态生成模型在处理英语方言输入时的性能下降问题，实现了在保持标准美国英语性能的同时，显著提升对方言输入的兼容性。

Abstract: Contact languages like English exhibit rich regional variations in the form
of dialects, which are often used by dialect speakers interacting with
generative models. However, can multimodal generative models effectively
produce content given dialectal textual input? In this work, we study this
question by constructing a new large-scale benchmark spanning six common
English dialects. We work with dialect speakers to collect and verify over 4200
unique prompts and evaluate on 17 image and video generative models. Our
automatic and human evaluation results show that current state-of-the-art
multimodal generative models exhibit 32.26% to 48.17% performance degradation
when a single dialect word is used in the prompt. Common mitigation methods
such as fine-tuning and prompt rewriting can only improve dialect performance
by small margins (< 7%), while potentially incurring significant performance
degradation in Standard American English (SAE). To this end, we design a
general encoder-based mitigation strategy for multimodal generative models. Our
method teaches the model to recognize new dialect features while preserving SAE
performance. Experiments on models such as Stable Diffusion 1.5 show that our
method is able to simultaneously raise performance on five dialects to be on
par with SAE (+34.4%), while incurring near zero cost to SAE performance.

</details>


### [216] [Harmonizing Diverse Models: A Layer-wise Merging Strategy for Consistent Generation](https://arxiv.org/abs/2510.14915)
*Xujun Peng,Anoop Kumar,Jingyu Wu,Parker Glenn,Daben Liu*

Main category: cs.CL

TL;DR: LLM在RAG系统中会生成不一致的输出，本研究提出了一种结合合成数据生成、三元组损失和层级模型合并的新方法，以提高输出一致性，实验结果显示响应相似度提高了约47.5%。


<details>
  <summary>Details</summary>
Motivation: LLM在处理语义等价输入时会产生不一致的输出，而现有的专注于提高输出一致性的训练数据和微调技术存在局限性。

Method: 提出一种结合系统性合成数据生成、三元组损失（用于改进嵌入）和新颖的层级模型合并（利用中间层激活中提取的一致性感知权重）的方法。

Result: 实验结果表明，所提出的合并模型显著提高了输出一致性，响应相似度比基线提高了约47.5%。

Conclusion: 所提出的方法为提高工业RAG系统的可靠性提供了一个实际的解决方案，通过显著提高输出一致性。

Abstract: Retrieval-Augmented Generation (RAG) systems leverage Large Language Models
(LLMs) to generate accurate and reliable responses that are grounded in
retrieved context. However, LLMs often generate inconsistent outputs for
semantically equivalent inputs, a problem compounded by the scarcity of
consistency-focused training data and the limitations of current fine-tuning
techniques in enhancing output consistency. We propose a new approach combining
systematic synthetic data generation, triplet loss for better embeddings, and a
novel layer-wise model merging approach. Using consistency-aware weights
derived from intermediate layer activations, our method effectively integrates
knowledge from specialized models. Experimental results how that our merged
model significantly enhances output consistency, achieving a ~47.5\%
improvement in response similarity over the baseline, thus offering a practical
solution for increasing the reliability of an industrial RAG system.

</details>


### [217] [Predicting Task Performance with Context-aware Scaling Laws](https://arxiv.org/abs/2510.14919)
*Kyle Montgomery,David Park,Jianhong Tu,Michael Bendersky,Beliz Gunel,Dawn Song,Chenguang Wang*

Main category: cs.CL

TL;DR: 本研究提出了一个联合模型，用于分析下游任务性能与训练计算量和上下文长度的关系，并对Llama-2模型进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 扩展定律主要关注模型规模、训练数据和计算量等上游指标与交叉熵损失的关系，但未能捕捉到上下文在下游任务性能中的关键作用。

Method: 提出一个简单且可解释的框架，将下游性能作为训练计算量和提供上下文的函数进行建模，并在 Llama-2-7B 和 Llama-2-13B 的扩展上下文变体上进行了实证验证，涵盖了算术推理、常识推理和机器翻译三个任务。

Result: 研究结果表明，该框架能够准确模拟数据分布内的下游性能，跨越三个数量级的训练计算量，并能可靠地推断上下文长度增加时的性能。

Conclusion: 该研究为设计更高效、适用于不同下游任务的长上下文 LLM 提供了指导，揭示了训练计算量和上下文利用之间的相互作用。

Abstract: Scaling laws have transformed our understanding of large language models by
linking upstream metrics like cross-entropy loss to design factors such as
model size, training data, and compute. However, these conventional laws fail
to capture downstream task performance, where context plays a critical role. In
this work, we propose a straightforward, interpretable framework that jointly
models downstream performance as a function of the training compute and the
provided context. We empirically validate our framework by fitting it on the
observed downstream performance of extended-context variants of Llama-2-7B and
Llama-2-13B across 65,500 unique instances spanning three tasks: arithmetic
reasoning, common sense reasoning, and machine translation. Our results
demonstrate that our framework accurately models in-distribution downstream
performance, generalizes across three orders of magnitude in training compute,
and reliably extrapolates performance as the amount of context increases. These
findings offer valuable insights into the interplay between training compute
and context utilization, providing guidance for designing more efficient
long-context LLMs for diverse downstream tasks. Our code is available at
https://github.com/wang-research-lab/context-scaling.

</details>


### [218] [AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations](https://arxiv.org/abs/2510.14937)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 机器学习模型在精神健康筛查中表现出色，准确率超80%，为早期诊断提供新途径。


<details>
  <summary>Details</summary>
Motivation: 精神健康障碍（抑郁、焦虑、PTSD）常被漏诊或误诊，需要可扩展、易于获取且具情境意识的诊断工具以支持早期检测和干预。

Method: 使用包含553份真实访谈及其诊断的独特数据集，评估了包括GPT-4.1 Mini、MetaLLaMA的零样本提示模型和RoBERTa的LoRA微调模型在内的多种机器学习模型的有效性。

Result: 模型在各诊断类别中准确率均超过80%，尤其在PTSD诊断上表现强劲（最高准确率89%，召回率98%）。研究还发现，使用更短、更聚焦的语境片段能提高召回率。LoRA微调被证明是高效且有效的，低秩配置（如秩8和16）在各项评估指标上均保持了竞争力。

Conclusion: 基于大语言模型的模型在精神健康筛查方面可显著优于传统工具，为低门槛、AI驱动的早期诊断开辟了道路，并为将机器学习整合到资源匮乏或污名化严重的临床工作流程中奠定了基础。

Abstract: Mental health disorders remain among the leading cause of disability
worldwide, yet conditions such as depression, anxiety, and Post-Traumatic
Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to
subjective assessments, limited clinical resources, and stigma and low
awareness. In primary care settings, studies show that providers misidentify
depression or anxiety in over 60% of cases, highlighting the urgent need for
scalable, accessible, and context-aware diagnostic tools that can support early
detection and intervention. In this study, we evaluate the effectiveness of
machine learning models for mental health screening using a unique dataset of
553 real-world, semistructured interviews, each paried with ground-truth
diagnoses for major depressive episodes (MDE), anxiety disorders, and PTSD. We
benchmark multiple model classes, including zero-shot prompting with GPT-4.1
Mini and MetaLLaMA, as well as fine-tuned RoBERTa models using LowRank
Adaptation (LoRA). Our models achieve over 80% accuracy across diagnostic
categories, with especially strongperformance on PTSD (up to 89% accuracy and
98% recall). We also find that using shorter context, focused context segments
improves recall, suggesting that focused narrative cues enhance detection
sensitivity. LoRA fine-tuning proves both efficient and effective, with
lower-rank configurations (e.g., rank 8 and 16) maintaining competitive
performance across evaluation metrics. Our results demonstrate that LLM-based
models can offer substantial improvements over traditional self-report
screening tools, providing a path toward low-barrier, AI-powerd early
diagnosis. This work lays the groundwork for integrating machine learning into
real-world clinical workflows, particularly in low-resource or high-stigma
environments where access to timely mental health care is most limited.

</details>


### [219] [LaSeR: Reinforcement Learning with Last-Token Self-Rewarding](https://arxiv.org/abs/2510.14943)
*Wenkai Yang,Weijie Liu,Ruobing Xie,Yiju Guo,Lulu Wu,Saiyong Yang,Yankai Lin*

Main category: cs.CL

TL;DR: LaSeR算法通过对RLVR进行优化，利用最后一个token的自我奖励分数来计算真实推理奖励，从而在不显著增加计算成本的情况下提高了LLM的推理和自我奖励能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在生成解决方案和自我验证时需要使用两个独立的提示模板，效率低下。

Method: 提出LaSeR算法，通过理论分析发现真实推理奖励等于最后一个token的自我奖励分数（基于模型对特定token的下一个token对数概率与一个常数的差值），并将此整合到RLVR的损失函数中，通过最小均方误差损失使最后一个token的自我奖励分数与基于验证器的推理奖励对齐，从而联合优化LLM的推理和自我奖励能力。

Result: LaSeR算法在不显著增加计算成本（仅增加一次token推理）的情况下，不仅提高了模型的推理性能，还赋予了模型显著的自我奖励能力，提升了推理时的性能扩展。

Conclusion: LaSeR算法通过一种高效的方式实现了LLM的推理和自我验证能力的统一，并在实验中取得了良好的效果。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a core paradigm for enhancing the reasoning capabilities of Large Language
Models (LLMs). To address the lack of verification signals at test time, prior
studies incorporate the training of model's self-verification capability into
the standard RLVR process, thereby unifying reasoning and verification
capabilities within a single LLM. However, previous practice requires the LLM
to sequentially generate solutions and self-verifications using two separate
prompt templates, which significantly reduces efficiency. In this work, we
theoretically reveal that the closed-form solution to the RL objective of
self-verification can be reduced to a remarkably simple form: the true
reasoning reward of a solution is equal to its last-token self-rewarding score,
which is computed as the difference between the policy model's next-token
log-probability assigned to any pre-specified token at the solution's last
token and a pre-calculated constant, scaled by the KL coefficient. Based on
this insight, we propose LaSeR (Reinforcement Learning with Last-Token
Self-Rewarding), an algorithm that simply augments the original RLVR loss with
a MSE loss that aligns the last-token self-rewarding scores with verifier-based
reasoning rewards, jointly optimizing the reasoning and self-rewarding
capabilities of LLMs. The optimized self-rewarding scores can be utilized in
both training and testing to enhance model performance. Notably, our algorithm
derives these scores from the predicted next-token probability distribution of
the last token immediately after generation, incurring only the minimal extra
cost of one additional token inference. Experiments show that our method not
only improves the model's reasoning performance but also equips it with
remarkable self-rewarding capability, thereby boosting its inference-time
scaling performance.

</details>


### [220] [MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics](https://arxiv.org/abs/2510.14944)
*Yuxing Lu,Xukai Zhao,J. Ben Tamo,Micky C. Nnamdi,Rui Peng,Shuang Zeng,Xingyu Hu,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: LLMs在专业科学领域（如代谢组学）的表现不一，MetaBench是首个用于评估LLM在该领域能力的基准。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在专业科学领域（特别是代谢组学）的理解和应用能力，因为LLMs在通用文本上表现出色，但在需要深度、互联知识的领域能力尚不明确。

Method: 创建MetaBench，一个包含知识、理解、基础、推理和研究五个关键能力评估点的代谢组学基准，并评估了25个开源和闭源LLMs。

Result: LLMs在文本生成任务上表现良好，但在跨数据库的标识符关联任务上仍存在挑战，即使有检索增强。模型在长尾、注释稀疏的代谢物上的表现会下降。

Conclusion: MetaBench为开发和评估代谢组学AI系统提供了关键基础设施，有助于开发可靠的计算工具。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities on
general text; however, their proficiency in specialized scientific domains that
require deep, interconnected knowledge remains largely uncharacterized.
Metabolomics presents unique challenges with its complex biochemical pathways,
heterogeneous identifier systems, and fragmented databases. To systematically
evaluate LLM capabilities in this domain, we introduce MetaBench, the first
benchmark for metabolomics assessment. Curated from authoritative public
resources, MetaBench evaluates five capabilities essential for metabolomics
research: knowledge, understanding, grounding, reasoning, and research. Our
evaluation of 25 open- and closed-source LLMs reveals distinct performance
patterns across metabolomics tasks: while models perform well on text
generation tasks, cross-database identifier grounding remains challenging even
with retrieval augmentation. Model performance also decreases on long-tail
metabolites with sparse annotations. With MetaBench, we provide essential
infrastructure for developing and evaluating metabolomics AI systems, enabling
systematic progress toward reliable computational tools for metabolomics
research.

</details>


### [221] [Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents](https://arxiv.org/abs/2510.14967)
*Guoqing Wang,Sunhao Dai,Guangze Ye,Zeyu Gan,Wei Yao,Yong Deng,Xiaofeng Wu,Zhenzhe Ying*

Main category: cs.CL

TL;DR: LLM代理在多轮工具使用中面临奖励稀疏问题，本文提出信息增益策略优化（IGPO）框架，通过计算每次交互获取的信息量来提供密集奖励，从而提高学习效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于结果的奖励方法在多轮交互中存在奖励稀疏、优势崩溃和信用分配困难的问题，特别是在需要多轮推理和知识获取的搜索场景中。

Method: 提出信息增益策略优化（IGPO）框架，将每次交互视为一个逐步获取信息的过程，并将回合级别奖励定义为策略生成正确答案的概率的边际增量。IGPO直接从模型自身的信念更新中提取内在奖励，并与结果级别的监督相结合，形成密集的奖励轨迹。

Result: 在各种基准测试中，IGPO在多轮场景下始终优于强基线，实现了更高的准确性和改进的样本效率。

Conclusion: IGPO通过提供密集且内在的监督，有效解决了LLM代理在多轮工具使用中的奖励稀疏问题，提高了学习性能。

Abstract: Large language model (LLM)-based agents are increasingly trained with
reinforcement learning (RL) to enhance their ability to interact with external
environments through tool use, particularly in search-based settings that
require multi-turn reasoning and knowledge acquisition. However, existing
approaches typically rely on outcome-based rewards that are only provided at
the final answer. This reward sparsity becomes particularly problematic in
multi-turn settings, where long trajectories exacerbate two critical issues:
(i) advantage collapse, where all rollouts receive identical rewards and
provide no useful learning signals, and (ii) lack of fine-grained credit
assignment, where dependencies between turns are obscured, especially in
long-horizon tasks. In this paper, we propose Information Gain-based Policy
Optimization (IGPO), a simple yet effective RL framework that provides dense
and intrinsic supervision for multi-turn agent training. IGPO models each
interaction turn as an incremental process of acquiring information about the
ground truth, and defines turn-level rewards as the marginal increase in the
policy's probability of producing the correct answer. Unlike prior
process-level reward approaches that depend on external reward models or costly
Monte Carlo estimation, IGPO derives intrinsic rewards directly from the
model's own belief updates. These intrinsic turn-level rewards are combined
with outcome-level supervision to form dense reward trajectories. Extensive
experiments on both in-domain and out-of-domain benchmarks demonstrate that
IGPO consistently outperforms strong baselines in multi-turn scenarios,
achieving higher accuracy and improved sample efficiency.

</details>


### [222] [LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training](https://arxiv.org/abs/2510.14969)
*Yiming Wang,Da Yin,Yuedong Cui,Ruichen Zheng,Zhiqian Li,Zongyu Lin,Di Wu,Xueqing Wu,Chenchen Ye,Yu Zhou,Kai-Wei Chang*

Main category: cs.CL

TL;DR: UI-Simulator是一个可扩展的范式，可以生成结构化的UI状态和转换，以大规模合成训练轨迹，UI-Simulator-Grow是一个有针对性的扩展策略，通过优先考虑高影响力任务和合成信息轨迹变体，实现更快、更数据高效的扩展。


<details>
  <summary>Details</summary>
Motivation: 数字代理需要多样化、大规模的UI轨迹才能在现实世界的任务中实现泛化，但收集这些数据在人类标注、基础设施和工程角度来看成本过高。

Method: UI-Simulator整合了数字世界模拟器、引导式探索过程和轨迹包装器，以大规模合成训练轨迹。UI-Simulator-Grow通过优先处理高影响力任务和合成信息性轨迹变体，实现更快、更具数据效率的扩展。

Result: 在WebArena和AndroidWorld上的实验表明，UI-Simulator在具有更强鲁棒性的情况下，性能可与在真实UI上训练的开源代理相媲美甚至超越，尽管使用的是较弱的教师模型。UI-Simulator-Grow仅使用Llama-3-8B-Instruct作为基础模型，就能达到Llama-3-70B-Instruct的性能。

Conclusion: UI-Simulator在现实世界任务中生成大规模UI轨迹方面表现出了巨大潜力，而UI-Simulator-Grow的针对性合成扩展策略可以持续有效地增强数字代理。

Abstract: Digital agents require diverse, large-scale UI trajectories to generalize
across real-world tasks, yet collecting such data is prohibitively expensive in
both human annotation, infra and engineering perspectives. To this end, we
introduce $\textbf{UI-Simulator}$, a scalable paradigm that generates
structured UI states and transitions to synthesize training trajectories at
scale. Our paradigm integrates a digital world simulator for diverse UI states,
a guided rollout process for coherent exploration, and a trajectory wrapper
that produces high-quality and diverse trajectories for agent training. We
further propose $\textbf{UI-Simulator-Grow}$, a targeted scaling strategy that
enables more rapid and data-efficient scaling by prioritizing high-impact tasks
and synthesizes informative trajectory variants. Experiments on WebArena and
AndroidWorld show that UI-Simulator rivals or surpasses open-source agents
trained on real UIs with significantly better robustness, despite using weaker
teacher models. Moreover, UI-Simulator-Grow matches the performance of
Llama-3-70B-Instruct using only Llama-3-8B-Instruct as the base model,
highlighting the potential of targeted synthesis scaling paradigm to
continuously and efficiently enhance the digital agents.

</details>


### [223] [TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar](https://arxiv.org/abs/2510.14972)
*Yinxi Li,Yuntian Deng,Pengyu Nie*

Main category: cs.CL

TL;DR: 代码大语言模型（LLMs）的子词（subword）分词器（tokenizer）基于统计而非语法进行训练，导致语义相同的代码片段因格式差异而被不同地分词，影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 代码大语言模型（LLMs）依赖子词分词器（如BPE），但这些分词器由统计驱动而非语法驱动，导致语义相同的代码片段因格式（如空格、命名）不同而被分词，从而引发模型行为的变化。

Method: 引入了一个名为TokDrift的框架，该框架应用了保持语义的代码重写规则，生成仅在分词上有所不同的代码变体，并对九种代码LLM进行了分析，包括参数量超过30B的模型，并进行了层级分析。

Result: 研究发现，即使是细微的格式调整也会导致模型行为发生显著变化。层级分析表明，问题源于模型早期嵌入层，其中子词分割未能捕捉语法标记边界。

Conclusion: 代码大语言模型（LLMs）中的分词错误（misaligned tokenization）是实现可靠代码理解和生成的潜在障碍，凸显了未来代码LLM需要采用语法感知分词（grammar-aware tokenization）的必要性。

Abstract: Large language models (LLMs) for code rely on subword tokenizers, such as
byte-pair encoding (BPE), learned from mixed natural language text and
programming language code but driven by statistics rather than grammar. As a
result, semantically identical code snippets can be tokenized differently
depending on superficial factors such as whitespace or identifier naming. To
measure the impact of this misalignment, we introduce TokDrift, a framework
that applies semantic-preserving rewrite rules to create code variants
differing only in tokenization. Across nine code LLMs, including large ones
with over 30B parameters, even minor formatting changes can cause substantial
shifts in model behavior. Layer-wise analysis shows that the issue originates
in early embeddings, where subword segmentation fails to capture grammar token
boundaries. Our findings identify misaligned tokenization as a hidden obstacle
to reliable code understanding and generation, highlighting the need for
grammar-aware tokenization for future code LLMs.

</details>


### [224] [Attention Is All You Need for KV Cache in Diffusion LLMs](https://arxiv.org/abs/2510.14973)
*Quan Nguyen-Tri,Mukul Ranjan,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 提出了一种名为 Elastic-Cache 的训练无关、与架构无关的策略，用于自适应地重新计算扩散大型语言模型 (DLM) 的 KV 缓存，以在最小化解码延迟的同时最大化预测准确性。


<details>
  <summary>Details</summary>
Motivation: 先前的 DLM 方法在每次去噪步骤和层中都会重新计算所有 token 的 QKV，尽管 KV 状态在大多数步骤中变化很小，尤其是在浅层中，这导致了大量的冗余。本研究旨在解决这一效率低下问题。

Method: Elastic-Cache 策略通过两个关键机制来优化 KV 缓存的重新计算：1. 关注注意力机制：通过对注意力分数最高的 token 进行检测，来评估 KV 状态的漂移情况，以此决定何时重新计算缓存。2. 深度感知调度：从较深的层开始进行缓存的重新计算，同时复用浅层缓存和窗口外的 MASK 缓存。该方法不依赖于固定的更新周期，而是根据实际的 KV 状态变化情况进行自适应的、层感知的缓存更新。

Result: 在 LLaDA-Instruct, LLaDA-1.5, 和 LLaDA-V 模型上，针对数学推理和代码生成任务进行了实验。结果显示，Elastic-Cache 在 GSM8K（256 tokens）上实现了 8.7 倍的加速，在更长序列上实现了 45.1 倍的加速，在 HumanEval 上实现了 4.8 倍的加速。同时，与基线方法相比，生成质量几乎没有损失。此外，与现有基于置信度的方法相比，本方法在 GSM8K 上实现了 6.8 倍的吞吐量提升。

Conclusion: Elastic-Cache 是一种有效的策略，能够显著加速 DLM 的解码过程，同时保持或提高预测准确性，并能够显著提高吞吐量，为 DLM 的实际部署提供了可行性。

Abstract: This work studies how to adaptively recompute key-value (KV) caches for
diffusion large language models (DLMs) to maximize prediction accuracy while
minimizing decoding latency. Prior methods' decoders recompute QKV for all
tokens at every denoising step and layer, despite KV states changing little
across most steps, especially in shallow layers, leading to substantial
redundancy. We make three observations: (1) distant ${\bf MASK}$ tokens
primarily act as a length-bias and can be cached block-wise beyond the active
prediction window; (2) KV dynamics increase with depth, suggesting that
selective refresh starting from deeper layers is sufficient; and (3) the
most-attended token exhibits the smallest KV drift, providing a conservative
lower bound on cache change for other tokens. Building on these, we propose
${\bf Elastic-Cache}$, a training-free, architecture-agnostic strategy that
jointly decides ${when}$ to refresh (via an attention-aware drift test on the
most-attended token) and ${where}$ to refresh (via a depth-aware schedule that
recomputes from a chosen layer onward while reusing shallow-layer caches and
off-window MASK caches). Unlike fixed-period schemes, Elastic-Cache performs
adaptive, layer-aware cache updates for diffusion LLMs, reducing redundant
computation and accelerating decoding with negligible loss in generation
quality. Experiments on LLaDA-Instruct, LLaDA-1.5, and LLaDA-V across
mathematical reasoning and code generation tasks demonstrate consistent
speedups: $8.7\times$ on GSM8K (256 tokens), $45.1\times$ on longer sequences,
and $4.8\times$ on HumanEval, while consistently maintaining higher accuracy
than the baseline. Our method achieves significantly higher throughput
($6.8\times$ on GSM8K) than existing confidence-based approaches while
preserving generation quality, enabling practical deployment of diffusion LLMs.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [225] [Spiking Neural Network Architecture Search: A Survey](https://arxiv.org/abs/2510.14235)
*Kama Svoboda,Tosiron Adegbija*

Main category: cs.NE

TL;DR: 该调查论文从硬件/软件协同设计的角度全面审查了脉冲神经网络（SNN）架构搜索（SNNaS）。


<details>
  <summary>Details</summary>
Motivation: SNNs 在能效和实时资源受限处理方面具有显著优势，但其复杂性和硬件约束与 SNN 模型之间的相互作用给设计最优 SNN 架构带来了重大挑战。

Method: 对 SNNs、ANNs 的神经架构搜索（NAS）以及 SNNs 的 NAS 进行了概述。

Result: 对 SNNaS 的现状进行了调查。

Conclusion: 强调了硬件/软件协同设计在充分发挥 SNNs 潜力方面的重要性，并指出了未来的研究方向。

Abstract: This survey paper presents a comprehensive examination of Spiking Neural
Network (SNN) architecture search (SNNaS) from a unique hardware/software
co-design perspective. SNNs, inspired by biological neurons, have emerged as a
promising approach to neuromorphic computing. They offer significant advantages
in terms of power efficiency and real-time resource-constrained processing,
making them ideal for edge computing and IoT applications. However, designing
optimal SNN architectures poses significant challenges, due to their inherent
complexity (e.g., with respect to training) and the interplay between hardware
constraints and SNN models. We begin by providing an overview of SNNs,
emphasizing their operational principles and key distinctions from traditional
artificial neural networks (ANNs). We then provide a brief overview of the
state of the art in NAS for ANNs, highlighting the challenges of directly
applying these approaches to SNNs. We then survey the state-of-the-art in
SNN-specific NAS approaches. Finally, we conclude with insights into future
research directions for SNN research, emphasizing the potential of
hardware/software co-design in unlocking the full capabilities of SNNs. This
survey aims to serve as a valuable resource for researchers and practitioners
in the field, offering a holistic view of SNNaS and underscoring the importance
of a co-design approach to harness the true potential of neuromorphic
computing.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [226] [CBVB-nH complexes as prevalent defects in metal-organic vapor-phase epitaxy-grown hexagonal boron nitride](https://arxiv.org/abs/2510.14012)
*Marek Maciaszek,Bartłomiej Baur*

Main category: cond-mat.mtrl-sci

TL;DR: hBN中碳-硼空位-氢复合物在量子技术中有前景，其形成稳定且光学性质与实验测量一致。


<details>
  <summary>Details</summary>
Motivation: 为了推动hBN基量子技术的发展，需要更深入地理解hBN缺陷的物理和化学性质。

Method: 使用从头算（ab initio）计算来研究涉及碳、硼空位和氢的复合物的热力学稳定性和光学性质。

Result: CBVB-nH（n=0-3）复合物在富氮、有碳和氢的条件下形成是能量上有利的，这归因于CB和VB-nH之间强烈的静电吸引。这些复合物在MOVPE生长样品中特别可能形成。计算的光学性质与实验测量中的1.90 eV和2.24 eV发射峰一致，表明这些峰源于负电荷的CBVB和CBVB-H复合物的空穴捕获。

Conclusion: CBVB-nH复合物在MOVPE生长hBN中稳定存在，并且是观察到的1.90 eV和2.24 eV光学跃迁的来源。

Abstract: Optically active defects in hexagonal boron nitride (hBN) are promising
candidates for active components in emerging quantum technologies, such as
single-photon emitters and spin centers. However, further progress in hBN-based
quantum technologies requires a deeper understanding of the physics and
chemistry of hBN defects. In this work, we employ ab initio calculations to
investigate the thermodynamic stability and optical properties of defect
complexes involving carbon, boron vacancies, and hydrogen. We demonstrate that
the formation of CBVB-nH complexes (n from 0 to 3) is energetically favorable
under nitrogen-rich conditions in the presence of carbon and hydrogen. The low
formation energies and high binding energies of these complexes arise from the
strong electrostatic attraction between the positively charged carbon
substitutional defect (CB) and the negatively charged hydrogen-passivated boron
vacancies (VB-nH). These complexes are particularly likely to form in
metal-organic vapor-phase epitaxy (MOVPE)-grown samples, where growth occurs in
the presence of carbon and hydrogen and is accompanied by a high density of
boron vacancies. The optical properties of CBVB-nH complexes are analyzed and
compared to recent photoluminescence measurements on MOVPE-grown hBN samples.
In particular, we investigate the origin of the emission peaks at 1.90 eV and
2.24 eV and demonstrate that both the energies and lineshapes are consistent
with hole capture by negatively charged CBVB and CBVB-H complexes.

</details>


### [227] [Turn-on of Current-Induced Spin Torque upon Noncollinear Antiferromagnetic Ordering in Delafossite PdCrO2](https://arxiv.org/abs/2510.14103)
*Xiaoxi Huang,Qi Song,Gautam Gurung,Daniel A. Pharis,Thow Min Jerald Cham,Yulan Chen,Rakshit Jain,Maciej Olszewski,Yufan Feng,Amal El-Ghazaly,Evgeny Y. Tsymbal,Darrell G. Schlom,Daniel C. Ralph*

Main category: cond-mat.mtrl-sci

TL;DR: PdCrO2的反铁磁体特性导致自旋扭矩增加，尤其在接近居里温度时。


<details>
  <summary>Details</summary>
Motivation: 研究由delafossite反铁磁体PdCrO2产生的自旋扭矩，以及其如何作用于邻近的铁磁性坡莫合金层。

Method: 测量PdCrO2产生的自旋扭矩，并研究其随温度（特别是居里温度附近）的变化。结合密度泛函理论计算解释观测到的现象。

Result: 自旋扭矩强度随温度降低而显著增强，尤其是在PdCrO2从顺磁相转变为非共线反铁磁相的过程中（接近居里温度时）。计算结果与实验观测定性一致。

Conclusion: PdCrO2的反铁磁序是增强自旋扭矩的关键因素，其性质的改变与自旋流的产生密切相关。

Abstract: We report measurements of the current-induced spin torque produced by the
delafossite antiferromagnet PdCrO2 and acting on an adjacent ferromagnetic
permalloy layer. The spin torque increases strongly as the temperature is
reduced through the Neel temperature, when the PdCrO2 transitions from a
paramagnetic phase to a noncollinear antiferromagnetic state. This result is
qualitatively consistent with density functional theory calculations regarding
how spin-current generation changes upon antiferromagnetic ordering in PdCrO2.

</details>


### [228] [A large spin-splitting altermagnet designed from the hydroxylated MBene monolayer](https://arxiv.org/abs/2510.14174)
*Xinyu Yang,Shan-Shan Wang,Shuai Dong*

Main category: cond-mat.mtrl-sci

TL;DR: 通过羟基旋转策略设计反铁磁体以实现大的手性可逆自旋劈裂，并揭示了新的磁性节点线半金属特性。


<details>
  <summary>Details</summary>
Motivation: 现有磁性材料的自旋劈裂较弱，限制了其在自旋电子器件技术中的应用，尤其是在二维材料中。因此，需要开发具有大自旋劈裂的新型材料。

Method: 基于自旋群对称性分析和第一性原理计算，提出了一种新颖的羟基旋转策略，用于设计反铁磁体中的终端磁体。通过计算$\alpha_{60}$-Mn$_2$B$_2$(OH)$_2$单层材料的性质来验证该策略。

Result: 在$\alpha_{60}$-Mn$_2$B$_2$(OH)$_2$单层材料中实现了超过1130 meV的手性可逆自旋劈裂，并观察到其具有节点线半金属的内在特性。羟基的角度可以作为切换终端磁性的主要序参量，并与铁弹性机制耦合。同时，该材料还表现出10$^{19}$ $\Omega^{-1}m^{-1}s^{-1}$的自旋极化电导率。

Conclusion: 羟基旋转策略是一种设计终端磁性节点线半金属的通用工具，为实现与大自旋劈裂相关的奇异化学和物理特性开辟了新途径。

Abstract: The development of altermagnets is fundamentally important for advancing
spintronic device technology, but remains unpractical for the weak spin
splitting in most cases, especially in two-dimensional materials. Based on spin
group symmetry analysis and first-principles calculations, a novel hydroxyl
rotation strategy in collinear antiferromagnets has been proposed to design
altermagnets. This approach achieves a large chirality-reversible spin
splitting exceeding $1130$ meV in $\alpha_{60}$-Mn$_2$B$_2$(OH)$_2$ monolayer.
The system also exhibits intrinsic features of a node-line semimetal in the
absence of spin-orbit coupling. Besides, the angles of hydroxyl groups serve as
the primary order parameter, which can switch on/off the altermagnetism coupled
with the ferroelastic mechanism. The corresponding magnetocrystalline
anisotropy have also been modulated. Moreover, an interesting spin-related
transport property with the spin-polarized conductivity of 10$^{19}$
$\Omega^{-1}m^{-1}s^{-1}$ also emerges. These findings uncover the hydroxyl
rotation strategy as a versatile tool for designing altermagnetic node-line
semimetals and opening new avenues for achieving exotic chemical and physical
characteristics associated with large spin splitting.

</details>


### [229] [Ferroelasticity tunable altermagnets](https://arxiv.org/abs/2510.14193)
*Ning Ding,Haoshen Ye,Shan-Shan Wang,Shuai Dong*

Main category: cond-mat.mtrl-sci

TL;DR: CoSe2单层表现出铁弹d波反铁磁性，应力可驱动自旋劈裂带旋转。


<details>
  <summary>Details</summary>
Motivation: 控制反铁磁态仍有待探索，提出铁弹反铁磁态来调控自旋劈裂。

Method: 通过对称性分析和第一性原理计算，识别CoSe2单层的铁弹d波反铁磁性。

Result: 单轴应力可诱导铁弹相变，伴随自旋劈裂带旋转90度。晶格和Néel矢量协同旋转时，Kerr角符号保持不变；非协同旋转时，Kerr角符号翻转。

Conclusion: 提出了一种在多铁性系统中调控反铁磁性的通用策略，并为探索新兴的磁弹性现象开辟了新途径。

Abstract: Altermagnets have garnered great interest due to their non-relativistic spin
splitting and novel physical properties. However, the control of altermagnetic
states remains underexplored. Here, we propose a new multiferroic state, i.e.
ferroelastic altermagnetic state, in which ferroelastic strain couples directly
to the spin-splitting. Through symmetry analysis and first-principles
calculations, we identify the ferroelastic $d$-wave altermagnetism of puckered
pentagonal CoSe$_2$ monolayer. Interestingly, uniaxial stress can induce a
ferroelastic phase transition, accompanied by a $90^\circ$ rotation of the
spin-splitting bands. Cooperative rotation of the lattice and N\'eel vectors
preserves the sign of Kerr angle, whereas noncooperative rotation reverses it.
Our work provides a general strategy for manipulating altermagnetism in
multiferroic systems and opens new avenues for exploring emergent
magnetoelastic phenomena.

</details>


### [230] [Comparison of Electroluminescence and Photoluminescence Imaging of Mixed-Cation Mixed-Halide Perovskite Solar Cells at Low Temperatures](https://arxiv.org/abs/2510.14213)
*Hurriyet Yuce-Cakir,Haoran Chen,Isaac Ogunniranye,Susanna M. Thon,Yanfa Yan,Zhaoning Song,Behrang H. Hamadani*

Main category: cond-mat.mtrl-sci

TL;DR: Halide perovskites 太阳能电池在低温下表现出不同的光电特性，EL ERE图显示电荷注入和提取瓶颈，而PL ERE图显示非辐射复合减少，效率提高。低温下，虽然钙钛矿层ERE增强，但界面电荷注入势垒会抑制EL并降低填充因子。


<details>
  <summary>Details</summary>
Motivation: 研究混合阳离子、混合卤素钙钛矿太阳能电池在不同温度下的光电特性，以了解其在低温下的性能表现，为空间动力系统和先进半导体器件的应用提供参考。

Method: 使用电致发光（EL）和光致发光（PL）高光谱成像，结合电流-电压分析，研究混合阳离子、混合卤素钙钛矿太阳能电池在不同温度下的光电特性。

Result: 低温（低于240 K）下，EL ERE图显示局部电荷注入和提取瓶颈是异质性的重要来源。PL ERE图显示非辐射复合被抑制，效率在整个研究的温度范围内都有显著提高。低温下钙钛矿层ERE增强，但界面电荷注入势垒显著抑制EL并降低填充因子。

Conclusion: 研究结果表明，低温下钙钛矿太阳能电池的性能受到界面电荷注入势垒的显著影响，这对于理解和改进其在低温环境下的应用至关重要。

Abstract: Halide perovskites have emerged as promising candidates for high-performance
solar cells. This study investigates the temperature-dependent optoelectronic
properties of mixed-cation mixed-halide perovskite solar cells using
electroluminescence (EL) and photoluminescence (PL) hyperspectral imaging,
along with current-voltage analysis. Luminescence images, which were converted
to EL and PL external radiative efficiency (ERE) maps, revealed significant
changes in the optoelectronic behavior of these devices at low temperatures.
Specifically, we found that a significant source of heterogeneity in the
low-temperature EL ERE maps below 240 K is related to local charge injection
and extraction bottlenecks, whereas PL ERE maps show suppressed non-radiative
recombination and significant improvements in efficiency throughout the
investigated temperature range. The spatial distribution of ERE and its
variation with applied current were analyzed, offering insights into
charge-carrier dynamics and defect behavior. Our results reveal that while the
perovskite layer exhibits enhanced ERE at low temperatures, charge injection
barriers at the interfaces of the perovskite solar cells significantly suppress
EL and degrade the fill factor below 240 K. These findings reveal that a deeper
understanding of the performance of perovskite solar cells under
low-temperature conditions is an essential step toward their potential
application in space power systems and advanced semiconductor devices.

</details>


### [231] [Magnetization, excitations, and microwave power absorption in transition-metal/rare-earth ferrites with disorder](https://arxiv.org/abs/2510.14237)
*D. A. Garanin,E. M. Chudnovsky*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究开发了高效的数值程序，用于研究磁性材料铁氧体中平衡磁态、激发和微波功率吸收与温度和成分的关系，包括磁矢在中点发生反转。研究结果在磁化和角动量补偿点上表现出剧烈的行为变化。通过计算磁化相关函数获得了主要的均匀振荡模式，并与详细分析的解析解进行了比较。利用涨落耗散定理计算了吸收微波功率的频率依赖性，并与解析结果进行了良好的一致性验证。稀土原子在稀释的RE系统中随机分布导致的无序性，产生了多个局域模式，这些模式随着系统尺寸的增加收敛为宽吸收峰。频率积分的功率吸收在补偿点处呈现最小值。


<details>
  <summary>Details</summary>
Motivation: 研究过渡金属/稀土铁氧体中平衡磁态、激发和微波功率吸收与温度和成分的关系，特别是磁矢在中点发生反转的现象，以及其对磁化和角动量补偿点的行为影响。

Method: 开发了高效的数值程序，利用磁化相关函数获得主要的均匀振荡模式，并与解析解进行比较。利用涨落耗散定理计算吸收微波功率的频率依赖性。研究了稀土原子在稀释的RE系统中随机分布导致的无序性对局域模式和吸收峰的影响。

Result: 得到了主要的均匀振荡模式，并与解析解进行了比较，结果吻合良好。计算了吸收微波功率的频率依赖性，并与解析结果进行了验证，一致性良好。发现稀土原子随机分布导致的无序性产生多个局域模式，并收敛为宽吸收峰。在补偿点处，频率积分的功率吸收最小。

Conclusion: 该研究通过数值方法有效地模拟了过渡金属/稀土铁氧体的磁性行为，并与解析结果进行了良好的验证。研究结果揭示了温度、成分、磁化和角动量补偿点以及稀土原子分布无序性对材料磁性行为和微波吸收特性的重要影响。

Abstract: Efficient numerical routines are developed for numerical studies of the
dependence of the equilibrium magnetic states, excitations, and microwave power
absorption on temperature and composition in transition-metal/rare-earth
ferrites, including the reversal of the N\'eel vector occurring on both
temperature and the concentration of the rare-earth atoms. It results in a
drastic change in the behavior at the magnetization and angular-momentum
compensation points. Dominant uniform oscillation modes are obtained by
computing the magnetization correlation function. They are compared with the
analytical solution, which is analyzed in detail. The fluctuation-dissipation
theorem is used to compute the frequency dependence of the absorbed microwave
power. A good agreement with analytical results is demonstrated. Disorder
caused by random positions of rare-earth atoms in a diluted RE system leads to
multiple localized modes that converge into broad absorption maxima as the size
of the system increases. The power absorption integrated over frequency
exhibits a minimum at the compensation point.

</details>


### [232] [Laser-Induced Heating in Diamonds: Influence of Substrate Thermal Conductivity and Interfacial Polymer Layers](https://arxiv.org/abs/2510.14372)
*Md Shakhawath Hossain,Jiatong Xu,Thi Ngoc Anh Mai,Nhat Minh Nguyen,Trung Vuong Doan,Chaohao Chen,Qian Peter Su,Yongliang Chen,Evgeny Ekimov,Toan Dinh,Xiaoxue Xu,Toan Trong Tran*

Main category: cond-mat.mtrl-sci

TL;DR: 钻1戒的导热性很高，但当它被放置在导热性低的基底上时，激光诱导的加热会变得显著，尤其是在界面处存在聚合物层时。本研究系统地研究了硅-空位金刚石在不同导热性基底和不同厚度聚合物界面下的激光诱导加热效应，并使用COMSOL Multiphysics模拟进行了验证。


<details>
  <summary>Details</summary>
Motivation: 研究在低导热性基底和界面聚合物层存在下，金刚石激光诱导加热的现象及其与基底导热性和聚合物厚度的关系。

Method: 系统地研究了硅-空位金刚石在不同导热性基底（包括非晶态多孔碳、聚二甲基硅氧烷和玻璃）和不同厚度（2.2微米）聚合物界面下的激光诱导加热效应，并使用COMSOL Multiphysics模拟进行了验证。

Result: 在737微瓦/微米2的低激发功率下，导热性最低的非晶态多孔碳基底（约0.2瓦特/米·开尔文）表现出显著的加热效应。玻璃（约1.4瓦特/米·开尔文）和聚二甲基硅氧烷（PDMS，约0.35瓦特/米·开尔文）则在2.95毫瓦/微米2以上才显示出明显的加热。2.2微米的聚合物界面层在2.95毫瓦/微米2及以上功率下就会引起显著的加热，表明基底和聚合物厚度都对局部加热有显著影响。

Conclusion: 基底的导热性和界面聚合物的厚度是影响金刚石激光诱导加热的关键因素。研究结果为选择合适的基底和制备样品提供了实际指导，有助于优化光学测温和量子传感等应用条件。

Abstract: Diamonds hosting color centers possess intrinsically high thermal
conductivity; therefore, laser-induced heating has often received little
attention. However, when placed on substrates with low thermal conductivity,
localized heating of diamonds under laser excitation can become significant,
and the presence of an interfacial polymer layer between substrate and diamond
further amplifies this effect. Yet, the relationship between substrate thermal
conductivity, polymer thickness, and laser heating remains to be established.
Here, a systematic investigation is presented on laser-induced heating of
silicon-vacancy diamond on substrates with varying thermal conductivity and
interfacial polymer thickness. Results reveal that even at a low excitation
power of 737~$\mu$W/$\mu$m$^2$, thin amorphous holey carbon -- the
lowest-conductivity substrate ($\sim$0.2~W~m$^{-1}$~K$^{-1}$) studied --
exhibits substantial heating, while glass ($\sim$1.4~W~m$^{-1}$~K$^{-1}$) and
polydimethylsiloxane (PDMS, $\sim$0.35~W~m$^{-1}$~K$^{-1}$) show noticeable
heating only above 2.95~mW/$\mu$m$^2$. For polymer interlayers, a thickness of
just 2.2~$\mu$m induces significant heating at 2.95~mW/$\mu$m$^2$ and above,
highlighting strong influence of both substrate and polymer thickness on local
heating response. Experimental findings are further validated using COMSOL
Multiphysics simulations with a steady-state 3D heat transfer model. These
results provide practical guidance for substrate selection and sample
preparation, enabling optimization of conditions for optical thermometry and
quantum sensing applications.

</details>


### [233] [Multiscale Models For Perovskite Optimisation](https://arxiv.org/abs/2510.14396)
*Philippe Baranek,James P. Connolly,Antoine Gissler,Philip Schulz,Michel Rérat,Roberto Dovesi*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文提出了一种多尺度方法来评估钙钛矿太阳能电池的性能，该方法在原子尺度上用第一性原理计算确定材料特性，并将其应用于宏观器件模型。


<details>
  <summary>Details</summary>
Motivation: 研究MAPbI3（MA = CH3NH3）钙钛矿及其相变对其光学、电子和结构特性的影响，并为设计和优化钙钛矿材料提供方法。

Method: 使用杂化交换-相关泛函进行第一性原理模拟，并将获得的材料特性数据耦合到数值漂移-扩散器件模型中，以评估相应单结器件的性能。

Result: 开发了一种将原子尺度和器件模型耦合的框架，用于交换光学、振动和电子参数，从而能够预测现有和新型钙钛矿的性能。

Conclusion: 提出了一种用于设计和优化钙钛矿材料以提高电池性能和稳定性的方法，解决了钙钛矿材料在社会应用中的关键障碍。

Abstract: This paper presents a multiscale approach to evaluate perovskite solar cell
performance which determines material properties at the atomistic scale with
first-principles calculations, and applies them in macro-scale device models.
This work focuses on the MAPbI3 (MA = CH3NH3) perovskite and how its phase
transitions impact on its optical, electronic, and structural properties which
are investigated at the first-principles level. The obtained data are coupled
to a numerical drift-diffusion device model enabling evaluation of the
performance of corresponding single junction devices. The first-principles
simulation applies a hybrid exchange-correlation functional adapted to the
studied family of compounds. Validation by available experimental data is
presented from materials properties to device performance, justifying the use
of the approach for predictive evaluation of existing and novel perovskites.
The coupling between atomistic and device models is described in terms of a
framework for exchange of optical, vibrational, and electronic parameters
between the two scales. The result of this theoretical investigation is a
methodology for designing and optimising perovskite materials for both cell
performance and stability, the key obstacle in the societal implementation of
these record-breaking new materials.

</details>


### [234] [First-Principles Approach to Spin Excitations in Noncollinear Magnetic Systems](https://arxiv.org/abs/2510.14405)
*Hsiao-Yi Chen,Ryotaro Arita,Yusuke Nomura*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种基于密度泛函理论和多体微扰理论的计算磁性系统自旋激发的一阶原理方法，该方法适用于具有非共线自旋结构的系统。


<details>
  <summary>Details</summary>
Motivation: 传统上，磁激发的研究依赖于假设磁矩是局域化的自旋模型。虽然最近出现了基于格林函数和局域自旋密度近似的从头算方法，但其应用仅限于共线铁磁和反铁磁系统。本研究旨在扩展该框架，以处理具有非共线自旋纹理的磁性系统。

Method: 采用基于密度泛函理论和多体微扰理论的方法，并结合瓦尼尔基表示和ansatz势方法，以降低计算成本，从而处理大规模非共线磁系统。

Result: 成功应用于LiCu2O2的自旋螺旋态，准确捕捉了其自旋旋转螺距，并解析了其纵差色散。此外，研究还分析了螺旋自旋结构与晶格自旋交换分裂之间的相互作用，并阐明了配位离子上的磁偶极子在Cu2+离子之间的有效铁磁相互作用中所起的关键作用。最后，理论预测了螺旋自旋背景上的纵差色散，并与实验测量结果高度吻合。

Conclusion: 建立了一个通用且计算高效的框架，用于从第一性原理模拟非共线磁系统中 the collective spin dynamics，特别是自旋螺旋态。

Abstract: We present a first-principles method based on density functional theory and
many-body perturbation theory for computing spin excitations in magnetic
systems with noncollinear spin textures. Traditionally, the study of magnetic
excitations has relied on spin models that assume magnetic moments to be
localized. Beyond this restriction, recent $ab~initio$ methods based on Green's
functions within the local spin-density approximation have emerged as a general
framework for calculating magnetic susceptibilities. However, their application
has so far been largely limited to collinear ferromagnetic and
antiferromagnetic systems. In this work, we extend this framework and enable
the treatment of large-scale noncollinear magnetic systems by leveraging a
Wannier-basis representation and implementing an ansatz potential method to
reduce computational cost. We apply our method to the spin-spiral state of
LiCu$_2$O$_2$, successfully capturing its steady-state spin-rotation pitch in
agreement with the experimental measurement and resolving the characteristic
magnon dispersion. We further analyze the interplay between the spiral spin
structure and the on-site spin-exchange splitting, and elucidate the crucial
role of magnetic dipoles on ligand ions in mediating effective ferromagnetic
interaction among the primary spins on Cu$^{2+}$ ions. Finally, we provide a
theoretical prediction of the magnon dispersion on top of the helical spin
background in high agreement with the experimental measurement. Overall, this
work establishes a general and computationally efficient framework for
simulating collective spin dynamics in noncollinear magnetic systems from first
principles, exemplified by -- but not limited to -- spin-spiral states.

</details>


### [235] [Ferroelectric amplitude switching and continuous memory](https://arxiv.org/abs/2510.14491)
*Gye-Hyeon Kim,Tae Hyun Jung,Seungjoon Sun,Jung Kyu Lee,Jaewoo Han,P. Karuna Kumari,Jin-Hyun Choi,Hansol Lee,Tae Heon Kim,Yoon Seok Oh,Seung Chul Chae,Se Young Park,Sang Mo Yang,Changhee Sohn*

Main category: cond-mat.mtrl-sci

TL;DR: 本文展示了在成分梯度Ba1-xSrxTiO3异质结构中实现铁电幅度开关，可以在不改变极性方向的情况下连续调制极性幅度，从而为模拟记忆应用开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 实现铁电材料的连续存储状态以满足模拟记忆器件的需求。

Method: 利用开关电流测量、压电力显微镜和Landau-Ginzburg-Devonshire模拟研究了成分梯度Ba1-xSrxTiO3异质结构的铁电幅度开关行为。

Result: 发现成分梯度铁电异质结构通过具有平坦最小值的双势阱可以实现幅度开关行为，支持稳定的、连续的极化状态。

Conclusion: 幅度开关是一种新的序参数动力学，为开发节能、可靠的模拟记忆系统提供了新平台。

Abstract: Although ferroelectric systems inherently exhibit binary switching behavior,
recent advances in analog memory device have spurred growing interest in
achieving continuous memory states. In this work, we demonstrate ferroelectric
amplitude switching at the mesoscopic scale in compositionally graded
Ba1-xSrxTiO3 heterostructures, enabling continuous modulation of polarization
magnitude without altering its direction, which we defined as amplitude
switching. Using switching current measurement, piezoresponse force microscopy
and Landau-Ginzburg-Devonshire simulations, we reveal that compositionally
graded ferroelectric heterostructure can possess amplitude switching behavior
through a double well potential with flattened minima. This behavior supports
stable, continuous polarization states and establishes a new platform for
analog memory applications. These findings introduce amplitude switching as a
new dynamic of the order parameter, paving the way for energy-efficient and
reliable analog memory systems.

</details>


### [236] [Enhanced Secondary Electron Detection of Single Ion Implants in Silicon Through Thin SiO2 Layers](https://arxiv.org/abs/2510.14495)
*Ella B Schneider,Oscar G Lloyd-Willard,Kristian Stockbridge,Mark Ludlow,Sam Eserin,David C Cox,Roger P Webb,Ben N Murdin,Steve K Clowes*

Main category: cond-mat.mtrl-sci

TL;DR: 利用二次电子探测技术，我们开发了一种无需接触或器件制造的非破坏性单离子注入探测方法，探测效率高达98%，空间分辨率达30纳米，为量子器件的精确制造提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 确定性地放置单杂质原子是制造可扩展的、基于第五族供体（group-V donors）的硅基量子器件的关键。本研究旨在开发一种高效、非破坏性的单离子注入事件探测方法。

Method: 本研究采用聚焦离子束（FIB）系统，利用低能量锑离子（Sb）注入未掺杂硅，通过探测二次电子（SEs）来检测单个离子注入事件。通过在注入前后进行校准离子流测量来验证探测效率。此外，研究了SiO2覆盖层对二次电子产额的影响，并分析了产额与离子速度的关系。

Result: 实现了高达98%的单离子探测效率，空间分辨率达到约30纳米，无需电接触或器件制造。引入SiO2覆盖层显著提高了二次电子产额，且该技术探测效率随离子速度的增加而提高，这意味着较高质量的离子（如Yb, Bi）需要更高的能量以维持探测效率。

Conclusion: 本研究提出的方法提供了一种可靠且可扩展的精确供体原子放置途径，并将确定性注入策略扩展到广泛的材料系统和量子器件结构中。

Abstract: Deterministic placement of single dopants is essential for scalable quantum
devices based on group-V donors in silicon. We demonstrate a non-destructive,
high-efficiency method for detecting individual ion implantation events using
secondary electrons (SEs) in a focused ion beam (FIB) system. Using low-energy
Sb ions implanted into undoped silicon, we achieve up to 98% single-ion
detection efficiency, verified by calibrated ion-current measurements before
and after implantation. The technique attains ~30 nm spatial resolution without
requiring electrical contacts or device fabrication, in contrast to
ion-beam-induced-current (IBIC) methods. We find that introducing a controlled
SiO2 capping layer significantly enhances SE yield, consistent with an
increased electron mean free path in the oxide, while maintaining high
probability of successful ion deposition in the underlying substrate. The yield
appears to scale with ion velocity, so higher projectile mass (e.g. Yb, Bi etc)
requires increased energy to maintain detection efficiency. Our approach
provides a robust and scalable route to precise donor placement and extends
deterministic implantation strategies to a broad range of material systems and
quantum device architectures.

</details>


### [237] [Uniaxial Magnetic Anisotropy and Type-X/Y Current-Induced Magnetization Switching in Oblique-Angle-Deposited Ta/CoFeB/Pt and W/CoFeB/Pt Heterostructures](https://arxiv.org/abs/2510.14540)
*Amir Khan,Shalini Sharma,Tiago de Oliveira Schneider,Markus Meinert*

Main category: cond-mat.mtrl-sci

TL;DR: 利用(Ta or W)/CoFeB/Pt三层异质结构,通过磁性材料倾斜角度溅射制备,实现亚微秒脉冲电流驱动的平面磁化翻转,并使用USMR和planar Hall效应进行检测,实现了低至$2 	imes 10^{11}$ A/m$^2$的翻转电流密度。


<details>
  <summary>Details</summary>
Motivation: 需要面内单轴磁各向异性(UMA)来驱动由自旋-轨道矩(SOT)引起的平面内磁化翻转(CIMS)。

Method: 通过制备(Ta or W)/CoFeB/Pt三层异质结构,利用磁性材料倾斜角度溅射制备,并使用USMR和planar Hall效应检测磁化翻转。

Result: 制备的(Ta or W)/CoFeB/Pt三层异质结构表现出UMA,并实现了CIMS,其中W(4nm)/CoFeB(1.4nm)/Pt(2nm)器件的翻转电流密度低至$2 	imes 10^{11}$ A/m$^2$。宏观自旋模拟和实验结果表明,Type Y几何结构中的磁化翻转是相干磁化旋转,而Type X几何结构中的磁化翻转则受成核和畴壁传播主导。

Conclusion: 所制备的(Ta or W)/CoFeB/Pt三层异质结构可以实现高效的CIMS,为进一步研究SOT驱动的磁化翻转提供了新的平台。

Abstract: Planar current-induced magnetization switching (CIMS) driven by spin-orbit
torque (SOT) requires an in-plane uniaxial magnetic anisotropy (UMA), which can
be induced by oblique-angle sputter deposition of the heavy-metal underlayer.
To enhance the SOT efficiency, we employ trilayer heterostructures of (Ta or
W)/CoFeB/Pt, where the bottom layer exhibits a UMA of 50 mT at 2 nm thickness.
The magnetization reversal in Hall-bar devices is detected through
unidirectional spin Hall magnetoresistance (USMR) for the Type Y geometry (easy
axis transverse to current) and planar Hall measurements for the Type X
geometry (easy axis parallel to current). Both configurations exhibit CIMS with
sub-microsecond current pulses, reaching switching current densities as low as
$2 \times 10^{11}$ A/m$^2$ for a W (4 nm)/CoFeB (1.4 nm)/Pt (2 nm) stack with a
UMA of 146 mT. Macrospin simulations reproduce the Type Y switching as coherent
magnetization rotation, whereas the Type X devices switch at much lower
currents than predicted, indicating that nucleation and domain-wall propagation
dominate reversal in this geometry.

</details>


### [238] [Contrasting properties of free carriers in $n$- and $p$-type Sb$_2$Se$_3$](https://arxiv.org/abs/2510.14554)
*F. Herklotz,E. V. Lavrov,T. D. C. Hobson,T. P. Shalvey,J. D. Major,K. Durose*

Main category: cond-mat.mtrl-sci

TL;DR: Sb$_2$Se$_3$单晶在低温下表现出持久的光电导性，表明空穴传输受到极化子效应的限制，这与电子传输不同。


<details>
  <summary>Details</summary>
Motivation: 在Sb$_2$Se$_3$单晶中研究掺杂Cd或Zn后的持久光电导现象，并探索其电荷载流子动力学的根本不对称性。

Method: 通过对掺杂Cd或Zn的p型Sb$_2$Se$_3$单晶和掺杂Cl的n型Sb$_2$Se$_3$单晶进行传输和红外吸收测量。

Result: 发现p型Sb$_2$Se$_3$单晶在低于约25K的温度下，在停止光照后仍能持续数小时的导电性。测量结果表明，Sb$_2$Se$_3$中的空穴传输比电子传输更易受到本征载流子散射的影响。

Conclusion: Sb$_2$Se$_3$中的电荷载流子动力学存在根本不对称性，并且极化子效应可能在限制空穴迁移率中起关键作用。

Abstract: We report persistent photoconductivity in $p$-type Sb$_2$Se$_3$ single
crystals doped with Cd or Zn, where enhanced conductivity remains for hours
after illumination ceases at temperatures below $\sim$25~K. Comparative
transport and infrared absorption measurements, including on $n$-type Cl-doped
counterparts, reveal strong indications that hole transport in Sb$_2$Se$_3$ is
more strongly affected by intrinsic carrier scattering than electron transport.
These results point to a fundamental asymmetry in charge carrier dynamics and
highlight the potential role of polaronic effects in limiting hole mobility in
this quasi-one-dimensional semiconductor.

</details>


### [239] [Orbital magnetization in Sierpinski fractals](https://arxiv.org/abs/2510.14556)
*L. L. Lage,T. P. Cysne,A. Latgé*

Main category: cond-mat.mtrl-sci

TL;DR: 分形结构（Sierpinski carpet and triangle）中的轨道磁性


<details>
  <summary>Details</summary>
Motivation: 研究分形结构中的轨道磁性，特别是Sierpinski carpet (SC)和Sierpinski triangle (ST)的性质。

Method: 使用Haldane模型，并采用两种方法（定义法和局域标记法）计算轨道磁性。

Result: SC结构产生边缘态，导致磁性随化学势呈现阶梯状和振荡；ST结构产生由分形诱导的光谱带隙，表现为磁性的平台状，且对边缘敏感。

Conclusion: 量子限制效应会影响分形结构中的电子轨道角动量，为探索新型轨道电子学提供了可能。

Abstract: Orbital magnetization (OM) in Sierpinski carpet (SC) and triangle (ST)
fractal is theoretically investigated by using Haldane model as a prototypical
example. The OM calculation is performed following two distinct approaches;
employing the definition and local markers formalism. Both methods coincides
for all systems analyzed. For the SC, higher fractal generations create a dense
set of edge states, resulting in a staircase profile, leading to oscillations
in the magnetization as a function of the chemical potential. In contrast, the
ST self-similarity produces distinct fractal-induced spectral gaps, which
manifest as constant plateaus in the magnetization. The STs exhibit a
pronounced sensitivity to edge terminations. Our results reveal how quantum
confinement in fractal structures affects the electronic orbital angular
momentum, pointing to possible pathways for exploring novel orbitronics in
systems with complex geometries.

</details>


### [240] [Substitutional sulfur and its vibrational fingerprints in Sb$_2$Se$_3$](https://arxiv.org/abs/2510.14590)
*F. Herklotz,E. V. Lavrov,A. Herklotz,V. V. Melnikov,T. P. Shalvey,J. D. Major,and K. Durose*

Main category: cond-mat.mtrl-sci

TL;DR: 四种硫相关局域振动模式被确定，并归因于Sb$_2$Se$_3$中三个不等价的硒位点上的取代硫。


<details>
  <summary>Details</summary>
Motivation: 研究硫在三硒化锑 (Sb$_2$Se$_3$) 中的结构行为。

Method: 结合红外吸收光谱和密度泛函理论，通过控制性渗入实验和同位素取代研究，进行偏振分辨测量和局域振动模式的理论计算。

Result: 确定了四个硫相关局域振动模式（249、273、283和312 cm$^{-1}$），并证实了这些模式与Sb$_2$Se$_3$中三个不等价硒位点上的取代硫相一致。

Conclusion: 观察到的光谱特征与取代硫在Sb$_2$Se$_3$三个不等价硒位点上的取代行为完全一致。

Abstract: The configurational behavior of sulfur in antimony triselenide (Sb$_2$Se$_3$)
is investigated by combining infrared absorption spectroscopy with density
functional theory. Four sulfur-related local vibrational modes are identified
at 249, 273, 283, and 312~cm$^{-1}$ in melt-grown single crystals prepared from
Sb$_2$Se$_3$ granulate. Their assignment to sulfur is confirmed through
controlled indiffusion experiments using Sb$_2$S$_3$ and elemental sulfur, as
well as isotope-substitution studies with $^{34}$S, which produce the expected
frequency shifts. Polarization-resolved measurements, together with theoretical
calculations of local vibrational modes, demonstrate that the observed spectral
features are fully consistent with substitutional sulfur on the three
inequivalent selenium sites of Sb$_2$Se$_3$.

</details>


### [241] [Unique Hierarchical Rotational Dynamics Induces Ultralow Lattice Thermal Conductivity in Cyanide-bridged Framework Materials](https://arxiv.org/abs/2510.14692)
*Zhunyun Tang,Xiaoxia Wang,Jin Li,Chaoyu He,Mingxing Chen,Chao Tang,Tao Ouyang*

Main category: cond-mat.mtrl-sci

TL;DR: CFM材料结合了超原子结构和钙钛矿的旋转动力学特性，实现了极低的晶格热导率，为轻质材料实现超低热导率提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 结合轻质元素和极低晶格热导率的材料对于热电和热障涂层等技术的进步至关重要，但一直是一个严峻的挑战。

Method: 通过整合超原子结构的层级振动和钙钛矿的旋转动力学特性，在氰化物桥联框架材料（CFMs）中实现了极低的晶格热导率。

Result: CFM材料表现出多重负格林爱森参数，导致显著的负热膨胀和强烈的立方晶格振动非简谐性。同时，准平带和宽带隙引起的四声子散射以及旋转模态相关的四次非简谐性导致了巨大的四次非简谐散射率。因此，CFMs的晶格热导率比具有同等平均原子质量的已知钙钛矿材料低一到两个数量级。例如，Cd(CN)2、NaB(CN)4、LiIn(CN)4和AgX(CN)4（X = B、Al、Ga、In）在室温下的晶格热导率值在0.35至0.81 W/mK之间。

Conclusion: 该工作不仅将CFMs确立为一个研究极端声子非简谐性的新颖且丰富的平台，而且通过有意识地整合层级和旋转动力学，为实现轻质材料的超低热导率提供了新的范例。

Abstract: The pursuit of materials combining light constituent elements with ultralow
lattice thermal conductivity ($\kappa_{\mathrm{L}}$) is crucial to advancing
technologies like thermoelectrics and thermal barrier coatings, yet it remains
a formidable challenge to date. Herein, we achieve ultralow
$\kappa_{\mathrm{L}}$ in lightweight cyanide-bridged framework materials (CFMs)
through the rational integration of properties such as the hierarchical
vibrations exhibited in superatomic structures and rotational dynamics
exhibited in perovskites. Unique hierarchical rotation behavior leads to
multiple negative peaks in Gr\"uneisen parameters across a wide frequency
range, thereby inducing pronounced negative thermal expansion and strong cubic
anharmonicity in CFMs. Meanwhile, the synergistic effect between large
four-phonon scattering phase space (induced by phonon quasi-flat bands and wide
bandgaps) and strong quartic anharmonicity (associated with rotation modes)
leads to giant quartic anharmonic scattering rates in these materials.
Consequently, the $\kappa_{\mathrm{L}}$ of these CFMs decreases by one to two
orders of magnitude compared to the known perovskites or perovskite-like
materials with equivalent average atomic masses. For instance, the
Cd(CN)$_{2}$, NaB(CN)$_{4}$, LiIn(CN)$_{4}$, and AgX(CN)$_{4}$ (X = B, Al, Ga,
In) exhibit ultralow room-temperature $\kappa_{\mathrm{L}}$ values ranging from
0.35 to 0.81 W/mK. This work not only establishes CFMs as a novel and rich
platform for studying extreme phonon anharmonicity, but also provides a new
paradigm for achieving ultralow thermal conductivity in lightweight materials
via the conscious integration of hierarchical and rotational dynamics.

</details>


### [242] [Identification of formation of amorphous Si phase in SiOxNy films produced by plasma enhanced chemical vapor deposition](https://arxiv.org/abs/2510.14701)
*M. V. Voitovych,A. Sarikov,V. O. Yukhymchuk,V. V. Voitovych,M. O. Semenenko*

Main category: cond-mat.mtrl-sci

TL;DR: 非晶硅（a-Si）相在富硅硅氧氮化物薄膜中的形成特点通过结合拉曼散射和红外吸收光谱研究，发现当相对硅含量超过约0.4的阈值时，薄膜中存在a-Si相。a-Si的量与薄膜中的氢浓度相关，可通过Si-H弯曲和伸缩振动的红外吸收带检测。通过解卷积红外吸收光谱，将约660 cm-1的红外吸收带归因于a-Si相，表明通过分析光谱的低波数部分，红外光谱可作为识别富硅硅氧氮化物薄膜相组成的有效方法。


<details>
  <summary>Details</summary>
Motivation: 研究等离子体增强化学气相沉积（PECVD）生长的富硅硅氧氮化物薄膜中非晶硅（a-Si）相形成的特点。

Method: 结合拉曼散射和红外吸收光谱，并利用解卷积红外吸收光谱的方法来分析约600-1300 cm-1范围内的光谱。

Result: 拉曼散射结果表明，当相对硅含量超过约0.4的阈值时，薄膜中存在a-Si相。a-Si的量与薄膜中检测到的Si-H振动红外吸收带（约660 cm-1和1900-2400 cm-1）相关。将约660 cm-1的红外吸收带归因于a-Si相。

Conclusion: 红外光谱分析，特别是低波数部分的光谱分析，是一种识别富硅硅氧氮化物薄膜相组成的有效方法。研究结果有助于理解PECVD生长的硅氧氮化物薄膜相组成的形成规律，并可用于控制薄膜的实际应用性能。

Abstract: Peculiarities of formation of inclusions of amorphous Si (a-Si) phase in
Si-rich Si oxynitride films grown by plasma-enhanced chemical vapor deposition
(PECVD) are studied by combined Raman scattering and infrared (IR) absorption
spectroscopy. The Raman scattering results identify presence of a-Si phase in
the studied films at the relative Si content exceeding a threshold value of
about 0.4. The a-Si amount correlates with the concentration of hydrogen in the
films, the presence of which is detected by characteristic IR absorption bands
corresponding to Si-H bending (about 660 cm-1) and stretching (a composite band
in the range of about 1900-2400 cm-1) vibrations. The method of deconvolution
of IR absorbance spectra in the range of about 600 to 1300 cm-1 developed
earlier is used to reliably separate the IR band at about 660 cm-1. This band
is identified to origin from the amorphous Si phase within the studied Si
oxynitride films. This makes it possible to propose IR spectroscopy with
analysis of the low-wavenumber part of the spectra as an efficient method of
identifying phase composition of Si-rich Si oxynitride films. The obtained
results contribute to understanding of the regularities of formation of phase
compositions of PECVD grown Si oxynitride films and are useful for controlling
the films properties for practical applications.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [243] [T-BAT semantics and its logics](https://arxiv.org/abs/2510.14361)
*Pawel Pawlowski*

Main category: cs.LO

TL;DR: T-BAT是一种非确定性的四值逻辑，用于表达非形式化可证性，并研究其语义、公理化和模态视角。


<details>
  <summary>Details</summary>
Motivation: 研究T-BAT逻辑的四值非确定性语义，并提供其直观的公理化。

Method: 研究语义的弱化与强化，证明其完备性，并利用克里普克语义从模态角度进行检查。

Result: 证明了所有可在此语义中定义的逻辑的完备性，并提供了由公理诱导的框架条件。

Conclusion: T-BAT逻辑的四值非确定性语义得到了深入研究，并提供了其直观的公理化。

Abstract: \textbf{T-BAT} logic is a formal system designed to express the notion of
informal provability. This type of provability is closely related to
mathematical practice and is quite often contrasted with formal provability,
understood as a formal derivation in an appropriate formal system.
\textbf{T-BAT} is a non-deterministic four-valued logic. The logical values in
\textbf{T-BAT} semantics convey not only the information whether a given
formula is true but also about its provability status.
  The primary aim of our paper is to study the proposed four-valued
non-deterministic semantics. We look into the intricacies of the interactions
between various weakenings and strengthenings of the semantics with axioms that
they induce. We prove the completeness of all the logics that are definable in
this semantics by transforming truth values into specific expressions
formulated within the object language of the semantics. Additionally, we
utilize Kripke semantics to examine these axioms from a modal perspective by
providing a frame condition that they induce. The secondary aim of this paper
is to provide an intuitive axiomatization of \textbf{T-BAT} logic.

</details>


### [244] [Optimization Modulo Integer Linear-Exponential Programs](https://arxiv.org/abs/2510.14550)
*S Hitarth,Alessio Mansutti,Guruprerana Shabadi*

Main category: cs.LO

TL;DR: 该研究首次探讨了整数线性-指数规划（ILEP）的优化问题复杂度，并给出了相关算法和复杂度分类。


<details>
  <summary>Details</summary>
Motivation: 对整数线性程序进行扩展，引入指数函数和取模函数，研究其优化问题的可行性与复杂度。

Method: 1. 证明若最优解存在，则存在一个可被整数线性-指数程序（ILESLP）简洁表示的最优解。
2. 提出一个利用整数分解预言机（IF O）的多项式时间算法，用于判断ILESLP是否为ILEP的解，并可比较两个解的目标函数值。
3. 基于以上结果，将ILEP的优化问题归类于FNP^NP类。

Result: 1. 存在一个可被ILESLP简洁表示的最优解。
2. 存在一个基于IF O的多项式时间算法用于判断解和比较解的值。
3. 整数线性-指数规划（ILEP）的优化问题被归类于FNP^NP。

Conclusion: 整数线性-指数规划（ILEP）的优化问题具有可被简洁表示的最优解，并且存在基于整数分解预言机的多项式时间算法来验证和比较解。该问题被归类于FNP^NP，并对现有优化问题分类进行了扩展。

Abstract: This paper presents the first study of the complexity of the optimization
problem for integer linear-exponential programs which extend classical integer
linear programs with the exponential function $x \mapsto 2^x$ and the remainder
function ${(x,y) \mapsto (x \bmod 2^y)}$. The problem of deciding if such a
program has a solution was recently shown to be NP-complete in [Chistikov et
al., ICALP'24]. The optimization problem instead asks for a solution that
maximizes (or minimizes) a linear-exponential objective function, subject to
the constraints of an integer linear-exponential program. We establish the
following results:
  1. If an optimal solution exists, then one of them can be succinctly
represented as an integer linear-exponential straight-line program (ILESLP): an
arithmetic circuit whose gates always output an integer value (by construction)
and implement the operations of addition, exponentiation, and multiplication by
rational numbers.
  2. There is an algorithm that runs in polynomial time, given access to an
integer factoring oracle, which determines whether an ILESLP encodes a solution
to an integer linear-exponential program. This algorithm can also be used to
compare the values taken by the objective function on two given solutions.
  Building on these results, we place the optimization problem for integer
linear-exponential programs within an extension of the optimization class
$\text{NPO}$ that lies within $\text{FNP}^{\text{NP}}$. In essence, this
extension forgoes determining the optimal solution via binary search.

</details>


### [245] [Problems and Consequences of Bilateral Notions of (Meta-)Derivability](https://arxiv.org/abs/2510.14619)
*Sara Ayhan*

Main category: cs.LO

TL;DR: 该论文提出了一种基于双边主义的证明论语义学方法，并探讨了其在自然演绎和结构演算中的应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 需要为证明系统引入可反驳性条件，以实现双边主义的证明论语义学。

Method: 在自然演绎和结构演算中实现双边主义的证明系统，并分析其优缺点。特别地，探讨了在结构演算中对横线进行对偶化时遇到的问题。

Result: 双边结构演算的实现面临挑战，揭示了证明与反驳概念之间的不平衡问题。文章分析了问题的根源，并提出了解决方案。

Conclusion: 文章深入分析了证明与反驳概念之间的不平衡问题，并提出了在双边系统中实现两者平衡的解决方案。

Abstract: A bilateralist take on proof-theoretic semantics can be understood as
demanding of a proof system to display not only rules giving the connectives'
provability conditions but also their refutability conditions. On such a view,
then, a system with two derivability relations is obtained, which can be quite
naturally expressed in a proof system of natural deduction but which faces
obstacles in a sequent calculus representation. Since in a sequent calculus
there are two derivability relations inherent, one expressed by the sequent
sign and one by the horizontal lines holding between sequents, in a truly
bilateral calculus both need to be dualized. While dualizing the sequent sign
is rather straightforwardly corresponding to dualizing the horizontal lines in
natural deduction, dualizing the horizontal lines in sequent calculus, uncovers
problems that, as will be argued in this paper, shed light on deeper conceptual
issues concerning an imbalance between the notions of proof vs. refutation. The
roots of this problem will be further analyzed and possible solutions on how to
retain a bilaterally desired balance in our system are presented.

</details>


### [246] [Admissibility of Substitution Rule in Cyclic-Proof Systems](https://arxiv.org/abs/2510.14749)
*Kenji Saotome,Koji Nakazawa*

Main category: cs.LO

TL;DR: 本篇论文证明了在包含归纳谓词的一阶逻辑的循环证明系统CLKID^omega中，假定存在截断规则（cut rule）的情况下，代换规则（substitution rule）是可容许的。


<details>
  <summary>Details</summary>
Motivation: 代换规则会增加理论分析的复杂性和搜索证明时的计算成本，因此其可容许性在理论和计算两方面都具有吸引力。在非循环系统中，通常可以通过局部证明转换来证明代换规则的可容许性，但这种方法在循环系统中并不适用。

Method: 本论文将循环证明展开成无穷形式，提升代换规则，然后通过添加反向边来构建一个不含代换规则的循环证明。

Result: 证明了在CLKID^omega系统中，假定存在截断规则的情况下，代换规则是可容许的。此外，通过限制代换规则不包含函数符号，该结果可以扩展到更广泛的系统，包括无截断规则的CLKID^omega以及分离逻辑的循环证明系统。

Conclusion: 本论文成功证明了在具有归纳谓词的一阶逻辑的循环证明系统CLKID^omega中，在存在截断规则的前提下，代换规则是可容许的。研究结果对循环证明系统的理论分析和计算效率都有积极影响。

Abstract: This paper investigates the admissibility of the substitution rule in
cyclic-proof systems. The substitution rule complicates theoretical case
analysis and increases computational cost in proof search since every sequent
can be a conclusion of an instance of the substitution rule; hence,
admissibility is desirable on both fronts. While admissibility is often shown
by local proof transformations in non-cyclic systems, such transformations may
disrupt cyclic structure and do not readily apply. Prior remarks suggested that
the substitution rule is likely nonadmissible in the cyclic-proof system
CLKID^omega for first-order logic with inductive predicates. In this paper, we
prove admissibility in CLKID^omega, assuming the presence of the cut rule. Our
approach unfolds a cyclic proof into an infinitary form, lifts the substitution
rules, and places back edges to construct a cyclic proof without the
substitution rule. If we restrict substitutions to exclude function symbols,
the result extends to a broader class of systems, including cut-free
CLKID^omega and cyclic-proof systems for the separation logic.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [247] [Generalized Pinching-Antenna Systems: A Tutorial on Principles, Design Strategies, and Future Directions](https://arxiv.org/abs/2510.14166)
*Yanqing Xu,Jingjing Cui,Yongxu Zhu,Zhiguo Ding,Tsung-Hui Chang,Robert Schober,Vincent W. S. Wong,Octavia A. Dobre,George K. Karagiannidis,H. Vincent Poor,Xiaohu You*

Main category: eess.SP

TL;DR:  the paper introduces generalized pinching antenna systems, a flexible and reconfigurable antenna architecture for next-generation wireless networks. These systems can dynamically create, reposition, and deactivate radiation points on various guiding media, offering user-centric and dynamic coverage. The paper discusses their physical mechanisms, channel models, system architectures, design strategies, integration with emerging technologies, and future research challenges.


<details>
  <summary>Details</summary>
Motivation: conventional fixed antenna systems lack the flexibility and reconfigurability needed for next-generation wireless networks. Pinching-antenna systems offer a novel solution by enabling dynamic positioning and activation of radiating elements.

Method: The paper describes the physical mechanisms of generalized pinching-antenna realizations and their associated wireless channel models. It reviews representative system architectures, discusses advanced design strategies, and examines their integration with emerging wireless technologies.

Result: Generalized pinching antenna systems offer unprecedented flexibility and spatial reconfigurability, enabling user-centric and dynamic coverage. They can be realized in various settings using different guiding media, feeding methods, and activation mechanisms.

Conclusion: Generalized pinching antenna systems represent a transformative flexible-antenna architecture for next-generation wireless networks, offering significant advantages over conventional systems. Key research challenges and future directions are identified to facilitate their practical deployment.

Abstract: Pinching-antenna systems have emerged as a novel and transformative
flexible-antenna architecture for next-generation wireless networks. They offer
unprecedented flexibility and spatial reconfigurability by enabling dynamic
positioning and activation of radiating elements along a signal-guiding medium
(e.g., dielectric waveguides), which is not possible with conventional fixed
antenna systems. In this paper, we introduce the concept of generalized
pinching antenna systems, which retain the core principle of creating localized
radiation points on demand, but can be physically realized in a variety of
settings. These include implementations based on dielectric waveguides, leaky
coaxial cables, surface-wave guiding structures, and other types of media,
employing different feeding methods and activation mechanisms (e.g.,
mechanical, electronic, or hybrid). Despite differences in their physical
realizations, they all share the same inherent ability to form, reposition, or
deactivate radiation sites as needed, enabling user-centric and dynamic
coverage. We first describe the underlying physical mechanisms of
representative generalized pinching-antenna realizations and their associated
wireless channel models, highlighting their unique propagation and
reconfigurability characteristics compared with conventional antennas. Then, we
review several representative pinching-antenna system architectures, ranging
from single- to multiple-waveguide configurations, and discuss advanced design
strategies tailored to these flexible deployments. Furthermore, we examine
their integration with emerging wireless technologies to enable synergistic,
user-centric solutions. Finally, we identify key open research challenges and
outline future directions, charting a pathway toward the practical deployment
of generalized pinching antennas in next-generation wireless networks.

</details>


### [248] [Integrated Massive Communication and Target Localization in 6G Cell-Free Networks](https://arxiv.org/abs/2510.14281)
*Junyuan Gao,Weifeng Zhu,Shuowen Zhang,Yongpeng Wu,Jiannong Cao,Giuseppe Caire,Liang Liu*

Main category: eess.SP

TL;DR: 该论文研究了6G网络中集成传感与通信（ISAC）和海量通信的结合，提出了一种新的框架。


<details>
  <summary>Details</summary>
Motivation: 将目标定位功能嵌入海量通信系统中，以适应未来6G网络的需求。

Method: 提出了一种基于混合消息传递的框架，并结合了多种近似方法来降低计算复杂度，以解决用户信道和目标位置之间复杂的依赖关系带来的挑战。

Result: 数值结果表明，该方法能够同时实现高精度的设备活动检测、信道估计和目标定位。

Conclusion: 验证了将定位功能嵌入海量通信系统以支持未来6G网络的可行性。

Abstract: This paper presents an initial investigation into the combination of
integrated sensing and communication (ISAC) and massive communication, both of
which are largely regarded as key scenarios in sixth-generation (6G) wireless
networks. Specifically, we consider a cell-free network comprising a large
number of users, multiple targets, and distributed base stations (BSs). In each
time slot, a random subset of users becomes active, transmitting pilot signals
that can be scattered by the targets before reaching the BSs. Unlike
conventional massive random access schemes, where the primary objectives are
device activity detection and channel estimation, our framework also enables
target localization by leveraging the multipath propagation effects introduced
by the targets. However, due to the intricate dependency between user channels
and target locations, characterizing the posterior distribution required for
minimum mean-square error (MMSE) estimation presents significant computational
challenges. To handle this problem, we propose a hybrid message passing-based
framework that incorporates multiple approximations to mitigate computational
complexity. Numerical results demonstrate that the proposed approach achieves
high-accuracy device activity detection, channel estimation, and target
localization simultaneously, validating the feasibility of embedding
localization functionality into massive communication systems for future 6G
networks.

</details>


### [249] [Integrated Sensing and Communication: Towards Multifunctional Perceptive Network](https://arxiv.org/abs/2510.14358)
*Yuanhao Cui,Jiali Nie,Fan Liu,Weijie Yuan,Zhiyong Feng,Xiaojun Jing,Yulin Liu,Jie Xu,Christos Masouros,Shuguang Cui*

Main category: eess.SP

TL;DR: ISAC是一种将传感能力嵌入通信网络的新兴技术，旨在满足日益增长的数据流量需求，并扩展无线网络的功能。本文为新研究人员提供了ISAC的概述，重点介绍了关键挑战、机遇和应用场景。


<details>
  <summary>Details</summary>
Motivation: 随着数据流量增长放缓，仅靠通信服务已无法支撑移动行业的发展。ISAC通过集成传感和通信功能，拓展了网络的用途，使其成为支持多样化应用的多功能平台。

Method: 本文对ISAC进行了综述，旨在为新研究人员提供一个全面的视角，概述了该领域面临的关键挑战、机遇和应用场景。

Result: ISAC作为一种变革性解决方案，将传感能力融入通信网络，实现了多功能无线系统。

Conclusion: ISAC是无线网络的一个重要发展方向，具有广阔的应用前景，能够推动移动行业的可持续发展。

Abstract: The capacity-maximization design philosophy has driven the growth of wireless
networks for decades. However, with the slowdown in recent data traffic demand,
the mobile industry can no longer rely solely on communication services to
sustain development. In response, Integrated Sensing and Communications (ISAC)
has emerged as a transformative solution, embedding sensing capabilities into
communication networks to enable multifunctional wireless systems. This
paradigm shift expands the role of networks from sole data transmission to
versatile platforms supporting diverse applications. In this review, we provide
a bird's-eye view of ISAC for new researchers, highlighting key challenges,
opportunities, and application scenarios to guide future exploration in this
field.

</details>


### [250] [Error Rate Analysis and Low-Complexity Receiver Design for Zero-Padded AFDM](https://arxiv.org/abs/2510.14507)
*Qin Yi,Zeping Sui,Zilong Liu*

Main category: eess.SP

TL;DR: This paper proposes low-complexity detectors for ZP-AFDM systems, achieving competitive BER performance with reduced complexity compared to conventional methods.


<details>
  <summary>Details</summary>
Motivation: The paper aims to study the error rate performance and design low-complexity receivers for zero-padded affine frequency division multiplexing (ZP-AFDM) systems.

Method: The authors exploit the ZP-aided lower triangular structure of the TD channel matrix to propose a novel low-complexity MMSE detector and a MRC-TD detector. They also analyze the theoretical BER performance of MMSE and maximum likelihood detectors.

Result: Simulation results show that the proposed detectors achieve identical BER performance to the conventional MMSE detector (matrix inversion) but with significantly reduced complexity.

Conclusion: The proposed low-complexity detectors for ZP-AFDM systems offer a practical solution for achieving good error rate performance without high computational cost.

Abstract: This paper studies the error rate performance and low-complexity receiver
design for zero-padded affine frequency division multiplexing (ZP-AFDM)
systems. By exploiting the unique ZP-aided lower triangular structure of the
time domain (TD) channel matrix, we propose {a novel low-complexity} minimum
mean square error (MMSE) detector and {a} maximum ratio combining-based TD
(MRC-TD) detector. Furthermore, the theoretical bit error rate (BER)
{performance} of both MMSE and maximum likelihood detectors {is} analyzed.
Simulation results demonstrate {that} the proposed detectors can achieve
identical BER performance to that of {the conventional MMSE detector based on
matrix inversion} while {enjoying significantly reduced complexity.}

</details>


### [251] [Integrated Sensing and Communication with Tri-Hybrid Beamforming Across Electromagnetically Reconfigurable Antennas](https://arxiv.org/abs/2510.14530)
*Jiangong Chen,Xia Lei,Yuchen Zhang,Kaitao Meng,Christos Masouros*

Main category: eess.SP

TL;DR: ERA-aided ISAC系统通过三混合波束成形提高了通信速率和Sensing SCNR。


<details>
  <summary>Details</summary>
Motivation: 传统混合波束成形系统在ISAC系统中面临自由度（DoFs）受限的问题，影响了多用户MIMO通信和MIMO雷达传感的性能。

Method: 提出了一种基于电磁可重构天线（ERA）的ISAC系统，采用结合数字、模拟和电磁波束成形的“三混合”优化框架，并通过分数规划（FP）和流形优化（MO）方法求解。

Result: 仿真结果表明，与传统的采用全向天线（OA）的混合波束成形系统相比，所提出的ERA-ISAC系统在感知和通信（S&C）方面实现了近10 dB的性能增益。

Conclusion: ERA-ISAC系统通过动态调整天线辐射模式，增强了系统自由度，显著提高了通信速率和Sensing SCNR。

Abstract: Beamforming with a sufficient number of antennas is one of the most
significant technologies for both Multi-user (MU) Multiple-input
Multiple-output (MIMO) communication and MIMO radar sensing in Integrated
Sensing and Communication (ISAC) systems. However, its performance suffers from
limited Degrees of Freedom (DoFs) in conventional hybrid beamforming systems.
To overcome this, we propose an Electromagnetically Reconfigurable Antenna
(ERA)-aided ISAC system, where transmit ERAs dynamically adjust their radiation
patterns to enhance system DoFs and improve overall performance. Specifically,
we design a tri-hybrid beamforming optimization framework combining digital,
analog, and Electromagnetic (EM) beamforming to jointly maximize communication
rate and sensing Signal-to-Clutter-plus-Noise Ratio (SCNR). Furthermore, an
integrated Fractional Programming (FP) and Manifold Optimization (MO) approach
is developed to transform the problem into tractable subproblems with
closed-form updates. Simulation results verify that the proposed ERA-ISAC
system achieves almost 10 dB Sensing and Communication (S&C) performance gain
compared to its conventional hybrid beamforming counterparts with
Omnidirectional Antenna (OA).

</details>


### [252] [Proceedings of the second edition of the International Symposium on Computational Sensing (ISCS25)](https://arxiv.org/abs/2510.14604)
*Thomas Feuillen,Amirafshar Moshtaghpour*

Main category: eess.SP

TL;DR: ISCS是一个汇集了计算传感领域研究人员的会议，特别关注应用和展示，旨在促进不同领域研究者之间的交流与合作。


<details>
  <summary>Details</summary>
Motivation: ISCS会议的目的是为计算传感领域的研究者提供一个交流平台，让他们能够学习、发现和分享在看似无关的应用领域中的新发现和挑战，促进跨学科合作。

Method: ISCS会议为期三天，邀请了6位主题演讲嘉宾，并公开征集科学报告的扩展摘要和展示说明。

Result: ISCS会议汇集了来自光学显微镜、电子显微镜、雷达、天文成像、生物医学成像、遥感和信号处理等领域的研究人员。

Conclusion: ISCS会议是一个促进计算传感领域研究者交流与合作的跨学科平台。

Abstract: The International Symposium on Computational Sensing (ISCS) brings together
researchers from optical microscopy, electron microscopy, RADAR, astronomical
imaging, biomedical imaging, remote sensing, and signal processing. With a
particular focus on applications and demonstrators, the purpose of this
symposium is to be a forum where researchers in computational sensing working
in seemingly unrelated applications can learn, discover, and exchange on their
new findings and challenges. This 3-day symposium in the heart of Europe
features 6 keynotes speakers and is open to extended abstracts for scientific
presentations and show-and-tell demonstrations.

</details>


### [253] [Bridging Theory and Practice in Reconfigurable Fluid Antenna Systems](https://arxiv.org/abs/2510.14794)
*Halvin Yang,Yizhe Zhao,Kai-Kit Wong,Hsiao-Hwa Chen,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 在实际应用中，流体天线需要考虑有限的驱动时间、不完美的信道状态信息、快速变化的衰落条件、电磁耦合和机械约束等因素，以实现其全部潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决理论分析中对流体天线性能的过度乐观估计问题，并提出更符合实际的建模和评估方法。

Method: 通过对比理论假设与实际约束（如驱动时间、信道信息、环境变化、电磁耦合、机械限制），并结合仿真和实例，分析这些因素对天线性能的影响。

Result: 研究表明，忽略实际约束会导致对流体天线容量和覆盖范围等性能的估计过于乐观。作者提出改进的建模方法、实验验证方法和控制算法。

Conclusion: 尽管流体天线在B5G/6G和物联网应用中具有巨大潜力，但必须在系统设计和性能评估中考虑实际因素，才能充分发挥其优势。

Abstract: Fluid antennas, including those based on liquid, mechanical, and pixel-based
technologies, are poised to significantly enhance next-generation wireless
systems by adaptively optimizing their radiation characteristics. Many
theoretical analyses assumed near-instant reconfiguration, perfect channel
knowledge, static or slowly varying propagation environments, and ideal
material properties that rarely hold in practice. In this article, we dissect
these common assumptions and contrast them with the realities of finite
actuation time, limited and imperfect channel state information, rapidly
changing fading conditions, electromagnetic coupling, and mechanical
constraints. Through illustrative examples and simulations, we demonstrate how
ignoring these factors can lead to overestimated gains in capacity, coverage,
etc.. We then propose modeling refinements, experimental validation methods,
and emerging control algorithms that better account for real-world constraints.
Our findings highlight that, while reconfigurable antennas remain highly
promising for B5G/6G and Internet of things (IoT) applications, their full
potential can only be realized by incorporating practical considerations into
system design and performance evaluation.

</details>


### [254] [A Scalable MVDR Beamforming Algorithm That is Linear in the Number of Antennas](https://arxiv.org/abs/2510.14802)
*Sanjaya Herath,Armin Gerami,Kevin Wagner,Ramani Duraiswami,Christopher A. Metzler*

Main category: eess.SP

TL;DR: 提出一种可扩展的MVDR波束形成方法，将计算复杂度从天线数量的立方降低到线性，适用于信号低于噪声的情况。


<details>
  <summary>Details</summary>
Motivation: 传统的MVDR波束形成技术在应用于大规模天线阵列时面临计算复杂度过高（与天线数量成三次方相关）的挑战。

Method: 利用Sherman-Morrison公式、低秩奇异值分解（SVD）近似以及代数运算，提出一种针对信号低于噪声（例如GPS）场景的MVDR波束形成方法。

Result: 通过仿真评估，所提出的方法显著降低了计算负荷，同时保持了与传统MVDR方法相当的高波束形成精度，并将计算复杂度从三次降低到线性。

Conclusion: 所提出的可扩展MVDR波束形成方法在计算效率和波束形成精度方面取得了良好的平衡，有望在雷达、声纳和无线通信等领域的大规模天线阵列的实时应用中发挥重要作用。

Abstract: The Minimum Variance Distortionless Response (MVDR) beamforming technique is
widely applied in array systems to mitigate interference. However, applying
MVDR to large arrays is computationally challenging; its computational
complexity scales cubically with the number of antenna elements. In this paper,
we introduce a scalable MVDR beamforming method tailored for massive arrays.
Our approach, which is specific to scenarios where the signal of interest is
below the noise floor (e.g.,~GPS), leverages the Sherman-Morrison formula,
low-rank Singular Value Decomposition (SVD) approximations, and algebraic
manipulation. Using our approach, we reduce the computational complexity from
cubic to linear in the number of antennas. We evaluate the proposed method
through simulations, comparing its computational efficiency and beamforming
accuracy with the conventional MVDR approach. Our method significantly reduces
the computational load while maintaining high beamforming accuracy for
large-scale arrays. This solution holds promise for real-time applications of
MVDR beamforming in fields like radar, sonar, and wireless communications,
where massive antenna arrays are proliferating.

</details>


### [255] [Joint Channel and CFO Estimation From Beam-Swept Synchronization Signal Under Strong Inter-Cell Interference](https://arxiv.org/abs/2510.14806)
*Bowen Li,Junting Chen,Nikolaos Pappas*

Main category: eess.SP

TL;DR: 该研究提出了一种基于最大似然（ML）的交叉前导码估计算法，用于在强干扰下精确估计目标信号，即使目标信号比干扰弱1000倍也能可靠估计。


<details>
  <summary>Details</summary>
Motivation: 未来的智能网络需要感知所有传输信号，而不仅仅是最强的信号。然而，当目标信号被埋藏在强烈的同道干扰之下时，估计目标信号是一个基本障碍。

Method: 该方法利用载波频率偏移（CFO）在波束扫描同步信号（SS）中的恒定性，通过相干地聚合多个观测的信息来增强期望信号以抵抗压倒性的干扰。

Result: CRLB分析和仿真表明，即使目标信号的强度是干扰信号的千分之一，也能进行可靠的估计。一个低空无线电地图的案例研究进一步验证了该框架的实际有效性。

Conclusion: 所提出的ML交叉前导码估计算法能够可靠地估计在强干扰下的目标信号，为未来智能网络的无线环境感知提供了有效解决方案。

Abstract: Complete awareness of the wireless environment, crucial for future
intelligent networks, requires sensing all transmitted signals, not just the
strongest. A fundamental barrier is estimating the target signal when it is
buried under strong co-channel interference from other transmitters, a failure
of which renders the signal unusable. This work proposes a maximum likelihood
(ML)-based cross-preamble estimation framework that exploits carrier frequency
offset (CFO) constancy across beam-swept synchronization signals (SS),
coherently aggregating information across multiple observations to reinforce
the desired signal against overwhelming interference. Cramer-Rao lower bound
(CRLB) analysis and simulation demonstrate reliable estimation even when the
signal is over a thousand times weaker than the interference. A low-altitude
radio-map case study further verifies the framework's practical effectiveness.

</details>


### [256] [Decoding in the presence of ISI without interleaving ORBGRAND AI](https://arxiv.org/abs/2510.14939)
*Ken R. Duffy,Moritz Grundei,Jane A. Millward,Muralidhar Rangaswamy,Muriel Medard*

Main category: eess.SP

TL;DR: ORBGRAND-AI是一种新的解码器，可以在ISI信道上提供与CA-SCL解码器相当或更好的性能，同时能量消耗更低。


<details>
  <summary>Details</summary>
Motivation: ISI是一种普遍存在于各种信道中的问题，它是由时间色散引起的，可以通过均衡来缓解，但均衡会导致噪声着色。对于这种着色的噪声，需要新的解码器。

Method: 提出了一种名为Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRAND-AI)的解码器，该解码器受统计物理学中近似独立性发展的启发。通过省略交织，ORBGRAND-AI在ISI信道上可以提供与最先进的软输入解码器（如CA-SCL）相当或更低的每比特信息能量的块错误率（BLER）。

Result: 在考虑了延迟抽头模型和相关的噪声着色后，我们评估了ORBGRAND-AI的解码性能。特别地，我们研究了两种ISI信道：两种抽头二元码ISI信道以及从RFView（一个物理信息建模和仿真工具）的数据派生的ISI信道。我们在各种不完美的信道状态信息假设下研究了二元码和RFView信道，并证明了二阶自回归模型可以充分表示RFView信道的影响。

Conclusion: ORBGRAND-AI解码器在ISI信道上表现出色，可以与CA-SCL等现有解码器相媲美，甚至超越它们，同时还能降低能耗。其性能在不同的信道模型和不完美的信道状态信息条件下都得到了验证。

Abstract: Inter symbol interference (ISI), which occurs in a wide variety of channels,
is a result of time dispersion. It can be mitigated by equalization which
results in noise coloring. For such colored noise, we propose a decoder called
Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI)
which is inspired by the development of approximate independence in statistical
physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower,
block error rate (BLER) for the same amount of energy per information bit in an
ISI channel as a state-of-the-art soft input decoder, such as Cyclic Redundancy
Check Assisted-Successive Cancellation List (CA-SCL) decoding, with an
interleaver. To assess the decoding performance of ORBGRAND-AI, we consider
delay tap models and their associated colored noise. In particular, we examine
a two-tap dicode ISI channel as well as an ISI channel derived from data from
RFView, a physics-informed modeling and simulation tool. We investigate the
dicode and RFView channel under a variety of imperfect channel state
information assumptions and show that a second order autoregressive model
adequately represents the RFView channel effect.

</details>


### [257] [Transfer Learning-Enabled Efficient Raman Pump Tuning under Dynamic Launch Power for C+L Band Transmission](https://arxiv.org/abs/2510.09047)
*Jiaming Liu,Rui Wang,JinJiang Li,Hong Lin,Jing Zhang,Kun Qiu*

Main category: eess.SP

TL;DR: We propose a transfer learning-enabled Transformer framework for accurate modeling and Raman pump design in C+L-band systems, achieving RMSE within 0.22 dB for modeling and 0.86/0.1 dB for peak-to-peak GSNR variation/deviation.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling and Raman pump design in C+L-band systems.

Method: A transfer learning-enabled Transformer framework.

Result: RMSE for modeling is within 0.22 dB. Peak-to-peak GSNR variation/deviation is within 0.86/0.1 dB.

Conclusion: The proposed framework enables simultaneous accurate modeling and Raman pump design in C+L-band systems.

Abstract: We propose a transfer learning-enabled Transformer framework to
simultaneously realize accurate modeling and Raman pump design in C+L-band
systems. The RMSE for modeling and peak-to-peak GSNR variation/deviation is
within 0.22 dB and 0.86/0.1 dB, respectively.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [258] [A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking](https://arxiv.org/abs/2510.14000)
*Mingyang Jiang,Yueyuan Li,Jiaru Zhang,Songan Zhang,Ming Yang*

Main category: cs.RO

TL;DR: DRIP利用强化学习的先验动作分布来指导扩散模型的训练，从而在复杂的停车环境中实现高精度和高成功率的规划。


<details>
  <summary>Details</summary>
Motivation: 现有自动泊车规划方法在精确建模最优动作分布方面存在挑战，尤其是在复杂受限环境中。

Method: 提出DRIP，一种基于强化学习（RL）先验动作分布的扩散-精炼规划器。RL预训练策略为扩散训练过程提供先验动作分布的正则化，并在推理阶段通过去噪过程将粗糙先验提炼为精确动作分布。

Result: DRIP在不同空间约束的停车场景中表现出显著的规划性能提升，尤其是在狭窄空间内，同时在常见场景中保持了良好的泛化能力。

Conclusion: DRIP通过利用强化学习的先验知识，能够更准确地建模动作，提高规划成功率，并减少推理步数，有效解决了复杂受限环境下的自动泊车规划难题。

Abstract: The growing demand for parking has increased the need for automated parking
planning methods that can operate reliably in confined spaces. In restricted
and complex environments, high-precision maneuvers are required to achieve a
high success rate in planning, yet existing approaches often rely on explicit
action modeling, which faces challenges when accurately modeling the optimal
action distribution. In this paper, we propose DRIP, a diffusion-refined
planner anchored in reinforcement learning (RL) prior action distribution, in
which an RL-pretrained policy provides prior action distributions to regularize
the diffusion training process. During the inference phase the denoising
process refines these coarse priors into more precise action distributions. By
steering the denoising trajectory through the reinforcement learning prior
distribution during training, the diffusion model inherits a well-informed
initialization, resulting in more accurate action modeling, a higher planning
success rate, and reduced inference steps. We evaluate our approach across
parking scenarios with varying degrees of spatial constraints. Experimental
results demonstrate that our method significantly improves planning performance
in confined-space parking environments while maintaining strong generalization
in common scenarios.

</details>


### [259] [Spatially Intelligent Patrol Routes for Concealed Emitter Localization by Robot Swarms](https://arxiv.org/abs/2510.14018)
*Adam Morris,Timothy Pelham,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 本研究提出了一种利用差分进化算法设计机器人协作行为以探测隐藏无线电信标的方法，重点在于生成几何巡逻路线以独立于信标参数进行定位。


<details>
  <summary>Details</summary>
Motivation: 在电磁侦察领域，独立于信标参数来定位未知信号是一个关键挑战。本研究旨在解决这一挑战。

Method: 利用差分进化算法生成几何巡逻路线，并模拟了四机器人蜂群在不同巡逻形状和天线类型（全向或定向）下的表现。

Result: 结果表明，全向天线的定位成功率受信号源位置影响，在地图边缘区域常失败。定向天线表现更优，平均检测成功率为98.75%，局部化误差为1.01-1.30米，优于全向天线（成功率80.25%，误差1.67-1.90米）。

Conclusion: 机器人的电磁现象预测能力与其物理环境交互密切相关。通过优化巡逻路线和天线选择实现的‘空间智能’对于有效的机器人监控至关重要。

Abstract: This paper introduces a method for designing spatially intelligent robot
swarm behaviors to localize concealed radio emitters. We use differential
evolution to generate geometric patrol routes that localize unknown signals
independently of emitter parameters, a key challenge in electromagnetic
surveillance. Patrol shape and antenna type are shown to influence information
gain, which in turn determines the effective triangulation coverage. We
simulate a four-robot swarm across eight configurations, assigning
pre-generated patrol routes based on a specified patrol shape and sensing
capability (antenna type: omnidirectional or directional). An emitter is placed
within the map for each trial, with randomized position, transmission power and
frequency. Results show that omnidirectional localization success rates are
driven primarily by source location rather than signal properties, with
failures occurring most often when sources are placed in peripheral areas of
the map. Directional antennas are able to overcome this limitation due to their
higher gain and directivity, with an average detection success rate of 98.75%
compared to 80.25% for omnidirectional. Average localization errors range from
1.01-1.30 m for directional sensing and 1.67-1.90 m for omnidirectional
sensing; while directional sensing also benefits from shorter patrol edges.
These results demonstrate that a swarm's ability to predict electromagnetic
phenomena is directly dependent on its physical interaction with the
environment. Consequently, spatial intelligence, realized here through
optimized patrol routes and antenna selection, is a critical design
consideration for effective robotic surveillance.

</details>


### [260] [Adaptive Obstacle-Aware Task Assignment and Planning for Heterogeneous Robot Teaming](https://arxiv.org/abs/2510.14063)
*Nan Li,Jiming Ren,Haris Miller,Samuel Coogan,Karen M. Feigh,Ye Zhao*

Main category: cs.RO

TL;DR: OATH是一个创新的多智能体任务分配与规划（MATP）框架，通过引入新颖的障碍物感知策略解决了现有方法的扩展性、空间推理和适应性挑战，并在模拟环境中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可扩展性、空间推理和富含障碍物环境的适应性方面存在挑战。

Method: 提出了一种名为OATH的框架，包含自适应Halton序列地图和基于障碍物感知的聚类-拍卖-选择机制，并利用大型语言模型（LLM）解释人类指令以指导规划。

Result: OATH在任务分配质量、可扩展性、动态变化适应性和整体执行性能方面，相较于最先进的MATP基线方法有了显著的改进。

Conclusion: OATH通过其新颖的障碍物感知策略和集成LLM的能力，有效地解决了多智能体任务分配与规划的挑战，并在模拟中得到了验证。

Abstract: Multi-Agent Task Assignment and Planning (MATP) has attracted growing
attention but remains challenging in terms of scalability, spatial reasoning,
and adaptability in obstacle-rich environments. To address these challenges, we
propose OATH: Adaptive Obstacle-Aware Task Assignment and Planning for
Heterogeneous Robot Teaming, which advances MATP by introducing a novel
obstacle-aware strategy for task assignment. First, we develop an adaptive
Halton sequence map, the first known application of Halton sampling with
obstacle-aware adaptation in MATP, which adjusts sampling density based on
obstacle distribution. Second, we propose a cluster-auction-selection framework
that integrates obstacle-aware clustering with weighted auctions and
intra-cluster task selection. These mechanisms jointly enable effective
coordination among heterogeneous robots while maintaining scalability and
near-optimal allocation performance. In addition, our framework leverages an
LLM to interpret human instructions and directly guide the planner in real
time. We validate OATH in NVIDIA Isaac Sim, showing substantial improvements in
task assignment quality, scalability, adaptability to dynamic changes, and
overall execution performance compared to state-of-the-art MATP baselines. A
project website is available at https://llm-oath.github.io/.

</details>


### [261] [Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning](https://arxiv.org/abs/2510.14065)
*Gaoyuan Liu,Joris de Winter,Yuri Durodie,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 提出了一种将强化学习（RL）技能整合到任务与运动规划（TAMP）流水线中的方法，以处理不确定性。


<details>
  <summary>Details</summary>
Motivation: 处理TAMP中的不确定性动作规划问题，并利用强化学习在处理不确定性方面的优势。

Method: 通过数据驱动的逻辑组件定义RL技能，使其能够被符号规划器部署，并设计了一个计划细化子程序来处理不确定性。

Result: 实验表明，该方法在具有概率性技能的域中扩展了TAMP的能力，并提高了规划效率。

Conclusion: 将RL技能嵌入TAMP可以处理不确定性，并提高规划效率。

Abstract: Task and motion planning (TAMP) for robotics manipulation necessitates
long-horizon reasoning involving versatile actions and skills. While
deterministic actions can be crafted by sampling or optimizing with certain
constraints, planning actions with uncertainty, i.e., probabilistic actions,
remains a challenge for TAMP. On the contrary, Reinforcement Learning (RL)
excels in acquiring versatile, yet short-horizon, manipulation skills that are
robust with uncertainties. In this letter, we design a method that integrates
RL skills into TAMP pipelines. Besides the policy, a RL skill is defined with
data-driven logical components that enable the skill to be deployed by symbolic
planning. A plan refinement sub-routine is designed to further tackle the
inevitable effect uncertainties. In the experiments, we compare our method with
baseline hierarchical planning from both TAMP and RL fields and illustrate the
strength of the method. The results show that by embedding RL skills, we extend
the capability of TAMP to domains with probabilistic skills, and improve the
planning efficiency compared to the previous methods.

</details>


### [262] [Partial Feedback Linearization Control of a Cable-Suspended Multirotor Platform for Stabilization of an Attached Load](https://arxiv.org/abs/2510.14072)
*Hemjyoti Das,Christian Ott*

Main category: cs.RO

TL;DR: 该论文提出了一种基于部分反馈线性化（PFL）的新型控制方法，用于稳定附有负载的悬挂空中平台，适用于起重机等建筑应用场景。该方法考虑了系统的欠驱动特性，并利用耦合动力学进行稳定，同时分析了耦合项在稳定中的关键作用。此外，还对该方法在外部风扰、传感器噪声和系统动力学不确定性下的鲁棒性进行了分析。该控制方法仅依赖车载传感器，适用于户外建筑工地等环境。最后，通过广泛的仿真和实验研究验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为建筑工地起重机等场景下的悬挂空中平台附带负载的稳定化提供一种新的控制方法。

Method: 提出一种基于部分反馈线性化（PFL）的控制方法，利用系统的耦合动力学进行稳定，并进行了数值稳定性分析和鲁棒性分析。

Result: 通过仿真和实验研究，验证了所提出的PFL控制方法在稳定悬挂空中平台方面是有效的，并且对风扰、传感器噪声和系统不确定性具有鲁棒性。

Conclusion: 所提出的基于PFL的控制方法能够有效地稳定附有负载的悬挂空中平台，适用于实际的建筑应用，并且对各种干扰具有鲁棒性。

Abstract: In this work, we present a novel control approach based on partial feedback
linearization (PFL) for the stabilization of a suspended aerial platform with
an attached load. Such systems are envisioned for various applications in
construction sites involving cranes, such as the holding and transportation of
heavy objects. Our proposed control approach considers the underactuation of
the whole system while utilizing its coupled dynamics for stabilization. We
demonstrate using numerical stability analysis that these coupled terms are
crucial for the stabilization of the complete system. We also carried out
robustness analysis of the proposed approach in the presence of external wind
disturbances, sensor noise, and uncertainties in system dynamics. As our
envisioned target application involves cranes in outdoor construction sites,
our control approaches rely on only onboard sensors, thus making it suitable
for such applications. We carried out extensive simulation studies and
experimental tests to validate our proposed control approach.

</details>


### [263] [ViTacGen: Robotic Pushing with Vision-to-Touch Generation](https://arxiv.org/abs/2510.14117)
*Zhiyuan Wu,Yijiong Lin,Yongqiang Zhao,Xuyang Zhang,Zhuo Chen,Nathan Lepora,Shan Luo*

Main category: cs.RO

TL;DR: 该研究提出了一种名为ViTacGen的机器人操作框架，通过从视觉信息生成触觉反馈，来解决机器人推物任务中对昂贵且易损的真实触觉传感器的依赖问题，实现了仅使用视觉信息的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人推物任务依赖触觉反馈来感知接触力，但真实的触觉传感器成本高、易损坏且难以部署，而纯视觉策略性能不佳。该研究旨在克服这些限制。

Method: ViTacGen框架包含一个视觉到触觉生成网络，直接从视觉图像序列生成接触深度图，并结合标准化的触觉表示。随后，一个强化学习策略融合视觉数据和生成的触觉数据，并采用基于视觉和生成触觉观察的对比学习。

Result: 该方法在模拟和真实世界实验中都得到了验证，证明了其优越的性能，成功率高达86%。

Conclusion: ViTacGen框架能够有效消除对高分辨率真实触觉传感器的依赖，通过视觉到触觉的生成，实现了仅基于视觉信息的机器人推物操作，并在实验中取得了显著的成果。

Abstract: Robotic pushing is a fundamental manipulation task that requires tactile
feedback to capture subtle contact forces and dynamics between the end-effector
and the object. However, real tactile sensors often face hardware limitations
such as high costs and fragility, and deployment challenges involving
calibration and variations between different sensors, while vision-only
policies struggle with satisfactory performance. Inspired by humans' ability to
infer tactile states from vision, we propose ViTacGen, a novel robot
manipulation framework designed for visual robotic pushing with vision-to-touch
generation in reinforcement learning to eliminate the reliance on
high-resolution real tactile sensors, enabling effective zero-shot deployment
on visual-only robotic systems. Specifically, ViTacGen consists of an
encoder-decoder vision-to-touch generation network that generates contact depth
images, a standardized tactile representation, directly from visual image
sequence, followed by a reinforcement learning policy that fuses visual-tactile
data with contrastive learning based on visual and generated tactile
observations. We validate the effectiveness of our approach in both simulation
and real world experiments, demonstrating its superior performance and
achieving a success rate of up to 86\%.

</details>


### [264] [When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift nuPlan Benchmarks](https://arxiv.org/abs/2510.14677)
*Steffen Hagedorn,Luka Donkov,Aron Distelzweig,Alexandru P. Condurache*

Main category: cs.RO

TL;DR: 使用更真实的交通代理模型SMART替代IDM，可以更准确地评估自动驾驶规划器在闭环仿真中的表现，并揭示现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的交通代理模型（如IDM）行为过于简单和被动，无法充分暴露规划器的缺陷，并可能导致错误的性能排名。需要更真实的仿真环境来评估规划器在复杂交互场景下的能力。

Method: 将先进的基于学习的交通代理模型SMART集成到nuPlan仿真环境中，并使用SMART代理替换传统的IDM代理，对14个近期规划器和基线模型进行了评估。对比了在两种不同仿真环境下（IDM和SMART）的规划器性能。

Result: 基于SMART的仿真显示，先前基于IDM的仿真结果普遍高估了规划器的性能，大多数规划器的得分有所下降。然而，许多规划器在多车道、交互复杂的场景（如变道、转弯）下表现出更好的交互能力，甚至性能有所提升。在闭环中训练的规划器表现出最优和最稳定的驾驶性能。但在极端边缘案例场景下，所有学习型规划器性能都会骤降，而基于规则的规划器仍能保持基本的合理行为。

Conclusion: SMART-reactive仿真应作为nuPlan的新标准闭环基准。基于学习的交通代理模型能提供更贴近现实的评估，但也暴露了在处理边缘案例时需要改进的局限性。建议将SMART代理作为IDM的替代方案，以提高仿真评估的准确性。

Abstract: Planner evaluation in closed-loop simulation often uses rule-based traffic
agents, whose simplistic and passive behavior can hide planner deficiencies and
bias rankings. Widely used IDM agents simply follow a lead vehicle and cannot
react to vehicles in adjacent lanes, hindering tests of complex interaction
capabilities. We address this issue by integrating the state-of-the-art learned
traffic agent model SMART into nuPlan. Thus, we are the first to evaluate
planners under more realistic conditions and quantify how conclusions shift
when narrowing the sim-to-real gap. Our analysis covers 14 recent planners and
established baselines and shows that IDM-based simulation overestimates
planning performance: nearly all scores deteriorate. In contrast, many planners
interact better than previously assumed and even improve in multi-lane,
interaction-heavy scenarios like lane changes or turns. Methods trained in
closed-loop demonstrate the best and most stable driving performance. However,
when reaching their limits in augmented edge-case scenarios, all learned
planners degrade abruptly, whereas rule-based planners maintain reasonable
basic behavior. Based on our results, we suggest SMART-reactive simulation as a
new standard closed-loop benchmark in nuPlan and release the SMART agents as a
drop-in alternative to IDM at https://github.com/shgd95/InteractiveClosedLoop.

</details>


### [265] [Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space](https://arxiv.org/abs/2510.14234)
*Ning Han,Gu Gong,Bin Zhang,Yuexuan Xu,Bohan Yang,Yunhui Liu,David Navarro-Alarcon*

Main category: cs.RO

TL;DR: 提出了一种模型无关的、基于深度学习的关键点提取和约束边界的控制方法，用于机器人操作三维可变形物体。


<details>
  <summary>Details</summary>
Motivation: 三维可变形物体的操纵对机器人系统来说是一个重大挑战，因为它们具有无限的维度状态空间和复杂的可变形动力学。

Method: 所提出的控制器利用深度学习方法从可变形物体的点云中提取的关键点坐标作为特征向量，将可变形物体的操纵简化为视觉伺服问题，并使用变形雅可比矩阵描述形状动力学。通过整合边界李雅普诺夫函数（BLF）来强制执行关键点约束，并采用规定性能控制方法来提高控制精度。

Result: 实验结果证明了该方法的有效性和鲁棒性。

Conclusion: 该方法通过利用关键点坐标简化了操作，并通过BLF增强了约束和精度，为机器人操作可变形物体提供了一种有效且稳健的解决方案。

Abstract: Manipulating three-dimensional (3D) deformable objects presents significant
challenges for robotic systems due to their infinite-dimensional state space
and complex deformable dynamics. This paper proposes a novel model-free
approach for shape control with constraints imposed on key points. Unlike
existing methods that rely on feature dimensionality reduction, the proposed
controller leverages the coordinates of key points as the feature vector, which
are extracted from the deformable object's point cloud using deep learning
methods. This approach not only reduces the dimensionality of the feature space
but also retains the spatial information of the object. By extracting key
points, the manipulation of deformable objects is simplified into a visual
servoing problem, where the shape dynamics are described using a deformation
Jacobian matrix. To enhance control accuracy, a prescribed performance control
method is developed by integrating barrier Lyapunov functions (BLF) to enforce
constraints on the key points. The stability of the closed-loop system is
rigorously analyzed and verified using the Lyapunov method. Experimental
results further demonstrate the effectiveness and robustness of the proposed
method.

</details>


### [266] [Multi Agent Switching Mode Controller for Sound Source localization](https://arxiv.org/abs/2510.14849)
*Marcello Sorge,Nicola Cigarini,Riccardo Lorigiola,Giulia Michieletto,Andrea Masiero,Angelo Cenedese,Alberto Guarnieri*

Main category: cs.RO

TL;DR: 该论文设计了一种基于声学多智能体切换模式控制策略来实现声源定位，并考虑了单声源和多声源两种场景。


<details>
  <summary>Details</summary>
Motivation: 声源定位在机器人研究中是一个重要课题，特别是在有声传感器的情况下，即使在无法建立直接视线的情况下，智能体也能定位目标。

Method: 设计了一种多智能体切换模式控制策略来实现声学目标定位。考虑了两种场景：单声源定位，其中智能体保持固定编队向目标移动；多声源场景，其中每个智能体独立搜索目标。

Result: 论文提出了一种用于声学目标定位的多智能体切换模式控制策略。

Conclusion: 该论文设计了一种用于声学目标定位的多智能体切换模式控制策略。

Abstract: Source seeking is an important topic in robotic research, especially
considering sound-based sensors since they allow the agents to locate a target
even in critical conditions where it is not possible to establish a direct line
of sight. In this work, we design a multi- agent switching mode control
strategy for acoustic-based target localization. Two scenarios are considered:
single source localization, in which the agents are driven maintaining a rigid
formation towards the target, and multi-source scenario, in which each agent
searches for the targets independently from the others.

</details>


### [267] [Learning Human-Humanoid Coordination for Collaborative Object Carrying](https://arxiv.org/abs/2510.14293)
*Yushi Du,Yixuan Li,Baoxiong Jia,Yutang Lin,Pei Zhou,Wei Liang,Yanchao Yang,Siyuan Huang*

Main category: cs.RO

TL;DR: 提出一种仅使用本体感觉的强化学习方法COLA，实现人与人形机器人的柔顺协作搬运任务，无需外部传感器或复杂交互模型。


<details>
  <summary>Details</summary>
Motivation: 现有机器人-人协作多集中于机械臂，而人形机器人因其复杂的全身动力学，在人-人形机器人协作方面的研究尚不充分。

Method: 提出一种仅使用本体感觉的强化学习方法COLA，该方法将领导者和跟随者行为整合到单个策略中。在闭环环境中进行训练，考虑动态物体交互，以隐式预测物体运动模式和人类意图，通过协调的轨迹规划来维持负载平衡，实现柔顺协作。

Result: 在模拟和真实世界实验中，COLA在协作搬运任务中表现出有效性、泛化性和鲁棒性。模拟实验表明，与基线方法相比，COLA将人类 esfuerzo 减少了24.7%，同时保持了物体的稳定性。真实世界实验验证了在不同物体类型（箱子、桌子、担架等）和运动模式（直线、转弯、爬坡）下的鲁棒协作搬运能力。人类用户研究（23名参与者）证实，与基线模型相比，平均提升了27.4%。

Conclusion: 所提出的方法能够实现柔顺的人-人形机器人协作搬运，并且不需要外部传感器或复杂的交互模型，为实际部署提供了一个可行的解决方案。

Abstract: Human-humanoid collaboration shows significant promise for applications in
healthcare, domestic assistance, and manufacturing. While compliant robot-human
collaboration has been extensively developed for robotic arms, enabling
compliant human-humanoid collaboration remains largely unexplored due to
humanoids' complex whole-body dynamics. In this paper, we propose a
proprioception-only reinforcement learning approach, COLA, that combines leader
and follower behaviors within a single policy. The model is trained in a
closed-loop environment with dynamic object interactions to predict object
motion patterns and human intentions implicitly, enabling compliant
collaboration to maintain load balance through coordinated trajectory planning.
We evaluate our approach through comprehensive simulator and real-world
experiments on collaborative carrying tasks, demonstrating the effectiveness,
generalization, and robustness of our model across various terrains and
objects. Simulation experiments demonstrate that our model reduces human effort
by 24.7%. compared to baseline approaches while maintaining object stability.
Real-world experiments validate robust collaborative carrying across different
object types (boxes, desks, stretchers, etc.) and movement patterns
(straight-line, turning, slope climbing). Human user studies with 23
participants confirm an average improvement of 27.4% compared to baseline
models. Our method enables compliant human-humanoid collaborative carrying
without requiring external sensors or complex interaction models, offering a
practical solution for real-world deployment.

</details>


### [268] [SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time](https://arxiv.org/abs/2510.14851)
*Jakob Bichler,Andreu Matoses Gimenez,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: Sadcher是一个实时任务分配框架，用于异构多机器人团队，通过模仿学习训练，结合图注意力和Transformer来预测机器人和任务之间的分配奖励。该方法通过放松的双边匹配生成高质量、有可行性保证的调度，并能处理时间、空间推理和泛化。Sadcher在随机、未见过的问题上优于其他学习和启发式基线，并且计算时间适合实时操作。


<details>
  <summary>Details</summary>
Motivation: 为了解决异构多机器人团队中的实时任务分配问题，并考虑动态联盟形成和任务前置约束。

Method: 使用模仿学习训练，结合图注意力和Transformer来预测分配奖励，然后通过放松的双边匹配生成调度。显式地对机器人和任务的位置、任务持续时间以及机器人的剩余处理时间进行建模。

Result: Sadcher在随机、未见过的小型和中型团队问题上，在计算时间适合实时操作的前提下，优于其他学习和启发式基线。

Conclusion: Sadcher能够为异构多机器人团队提供高质量、实时的任务分配，并且在不同时空分布的环境中具有良好的泛化能力。

Abstract: We present Sadcher, a real-time task assignment framework for heterogeneous
multi-robot teams that incorporates dynamic coalition formation and task
precedence constraints. Sadcher is trained through Imitation Learning and
combines graph attention and transformers to predict assignment rewards between
robots and tasks. Based on the predicted rewards, a relaxed bipartite matching
step generates high-quality schedules with feasibility guarantees. We
explicitly model robot and task positions, task durations, and robots'
remaining processing times, enabling advanced temporal and spatial reasoning
and generalization to environments with different spatiotemporal distributions
compared to training. Trained on optimally solved small-scale instances, our
method can scale to larger task sets and team sizes. Sadcher outperforms other
learning-based and heuristic baselines on randomized, unseen problems for small
and medium-sized teams with computation times suitable for real-time operation.
We also explore sampling-based variants and evaluate scalability across robot
and task counts. In addition, we release our dataset of 250,000 optimal
schedules: https://autonomousrobots.nl/paper_websites/sadcher_MRTA/

</details>


### [269] [Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning](https://arxiv.org/abs/2510.14300)
*Weijie Shen,Yitian Liu,Yuhao Wu,Zhixuan Liang,Sijia Gu,Dehui Wang,Tian Nian,Lei Xu,Yusen Qin,Jiangmiao Pang,Xinping Guan,Xiaokang Yang,Yao Mu*

Main category: cs.RO

TL;DR: AdaMoE是一种新的混合专家（MoE）架构，它通过继承预训练的VLA模型权重并扩展动作专家，提高了机器人操作任务的性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在机器人操作任务中表现出潜力，但扩展模型面临计算资源、数据集和实时控制效率的挑战。特别是，机器人数据的稀缺性使得充分利用预训练的VLA模型权重变得至关重要。

Method: AdaMoE提出了一种混合专家（MoE）架构，该架构继承了密集VLA模型的预训练权重，并通过将前馈层替换为稀疏激活的MoE层来扩展动作专家。它采用了一种解耦技术，通过独立的Scale Adapter与传统Router协同工作，将专家选择与专家加权分离开来，从而实现专家选择的基于任务相关性，并允许独立控制的权重，促进协同专家利用。

Result: AdaMoE在LIBERO和RoboTwin基准测试中持续优于基线模型，分别提高了1.8%和9.3%的性能。在真实世界实验中，性能显著提高了21.5%。

Conclusion: AdaMoE通过协同专家利用，在保持计算效率的同时实现了卓越的性能，证明了其在机器人操作任务中的有效性。

Abstract: Vision-Language-Action (VLA) models are experiencing rapid development and
demonstrating promising capabilities in robotic manipulation tasks. However,
scaling up VLA models presents several critical challenges: (1) Training new
VLA models from scratch demands substantial computational resources and
extensive datasets. Given the current scarcity of robot data, it becomes
particularly valuable to fully leverage well-pretrained VLA model weights
during the scaling process. (2) Real-time control requires carefully balancing
model capacity with computational efficiency. To address these challenges, We
propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits
pretrained weights from dense VLA models, and scales up the action expert by
substituting the feedforward layers into sparsely activated MoE layers. AdaMoE
employs a decoupling technique that decouples expert selection from expert
weighting through an independent scale adapter working alongside the
traditional router. This enables experts to be selected based on task relevance
while contributing with independently controlled weights, allowing
collaborative expert utilization rather than winner-takes-all dynamics. Our
approach demonstrates that expertise need not monopolize. Instead, through
collaborative expert utilization, we can achieve superior performance while
maintaining computational efficiency. AdaMoE consistently outperforms the
baseline model across key benchmarks, delivering performance gains of 1.8% on
LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement
in real-world experiments validates its practical effectiveness for robotic
manipulation tasks.

</details>


### [270] [Risk-Aware Reinforcement Learning with Bandit-Based Adaptation for Quadrupedal Locomotion](https://arxiv.org/abs/2510.14338)
*Yuanhong Zeng,Anushri Dixit*

Main category: cs.RO

TL;DR: 本研究提出风险感知强化学习方法，通过条件在险价值（CVaR）约束策略优化训练一系列风险条件策略，提高了稳定性和样本效率。在部署时，利用多臂老虎机框架，仅基于观察到的回合回报，自适应选择最佳策略，无需特权环境信息，即可应对未知环境。该方法在模拟和真实机器人实验中均表现出色，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高四足动物步态的稳定性和样本效率，并能在未知环境中自适应地选择合适的风险水平。

Method: 使用条件在险价值（CVaR）约束策略优化技术训练一系列风险条件策略，并采用多臂老虎机框架根据观察到的回报自适应选择策略。

Result: 在模拟和真实机器人实验中，与基线方法相比，风险感知策略在未见过的环境中的平均性能和尾部性能接近翻倍。多臂老虎机能在两分钟内选出在未知地形上表现最佳的风险感知策略。

Conclusion: 风险感知强化学习方法能够有效提高四足动物步态的鲁棒性，并且能够通过在线自适应策略选择，在未知环境中实现高性能。

Abstract: In this work, we study risk-aware reinforcement learning for quadrupedal
locomotion. Our approach trains a family of risk-conditioned policies using a
Conditional Value-at-Risk (CVaR) constrained policy optimization technique that
provides improved stability and sample efficiency. At deployment, we adaptively
select the best performing policy from the family of policies using a
multi-armed bandit framework that uses only observed episodic returns, without
any privileged environment information, and adapts to unknown conditions on the
fly. Hence, we train quadrupedal locomotion policies at various levels of
robustness using CVaR and adaptively select the desired level of robustness
online to ensure performance in unknown environments. We evaluate our method in
simulation across eight unseen settings (by changing dynamics, contacts,
sensing noise, and terrain) and on a Unitree Go2 robot in previously unseen
terrains. Our risk-aware policy attains nearly twice the mean and tail
performance in unseen environments compared to other baselines and our
bandit-based adaptation selects the best-performing risk-aware policy in
unknown terrain within two minutes of operation.

</details>


### [271] [SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation](https://arxiv.org/abs/2510.14357)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 该研究提出了SUM-AgriVLN方法，通过引入空间理解记忆模块，利用3D重建和表示来增强农业场景下基于语言的机器人导航能力，并在A2A基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的农业机器人导航方法（如AgriVLN）在处理重复出现的导航指令时，将每个指令视为独立事件，未能有效利用过往经验提供空间上下文，限制了导航效率。

Method: 提出SUM-AgriVLN方法，其核心是SUM（Spatial Understanding Memory）模块。该模块通过3D重建和空间表示来学习和存储空间记忆，使机器人在导航时能够利用过往经验，更好地理解和记忆环境空间，从而提高导航的准确性和效率。

Result: 在A2A基准测试中，SUM-AgriVLN将成功率从0.47提高到0.54，导航误差略微从2.91m增加到2.93m，证明了其在农业领域的先进性能。

Conclusion: SUM-AgriVLN通过引入空间理解和记忆机制，显著提升了农业场景下基于语言的机器人导航的成功率，克服了现有方法在处理重复指令时的局限性，达到了当前该领域的顶尖水平。

Abstract: Agricultural robots are emerging as powerful assistants across a wide range
of agricultural tasks, nevertheless, still heavily rely on manual operation or
fixed rail systems for movement. The AgriVLN method and the A2A benchmark
pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural
domain, enabling robots to navigate to the target positions following the
natural language instructions. In practical agricultural scenarios, navigation
instructions often repeatedly occur, yet AgriVLN treat each instruction as an
independent episode, overlooking the potential of past experiences to provide
spatial context for subsequent ones. To bridge this gap, we propose the method
of Spatial Understanding Memory for Agricultural Vision-and-Language Navigation
(SUM-AgriVLN), in which the SUM module employs spatial understanding and save
spatial memory through 3D reconstruction and representation. When evaluated on
the A2A benchmark, our SUM-AgriVLN effectively improves Success Rate from 0.47
to 0.54 with slight sacrifice on Navigation Error from 2.91m to 2.93m,
demonstrating the state-of-the-art performance in the agricultural domain.
Code: https://github.com/AlexTraveling/SUM-AgriVLN.

</details>


### [272] [RoboANKLE: Design, Development, and Functional Evaluation of a Robotic Ankle with a Motorized Compliant Unit](https://arxiv.org/abs/2510.14414)
*Baris Baysal,Omid Arfaie,Ramazan Unal*

Main category: cs.RO

TL;DR: 该研究提出了一种名为RoboANKLE的仿生动力踝关节假肢，它能够提供完整的蹬地助力，旨在模仿人体的自然踝关节运动，满足日常活动的需求。


<details>
  <summary>Details</summary>
Motivation: 设计有源胫骨下假肢所面临的能量自主性和重量限制等挑战，是本研究的出发点。

Method: 研究采用能量存储与扩展释放（ESER）机制，并结合新的额外能量存储（EES）机制，以模仿人体的踝关节，提供充分的蹬地助力，实现自然的力矩曲线。通过运动学和动力学分析确定设计参数，并进行CAD建模、动态和结构分析以评估性能并优化设计。最终制造原型并进行实验验证。

Result: RoboANKLE假肢的质量为1.92公斤，尺寸为261x107x420毫米。功能评估显示，RoboANKLE能够以95%的准确度达到自然的最大背屈角度，并能产生比自然行走所需高57%的力矩，其功率输出比自然功率高10%。

Conclusion: RoboANKLE假肢成功实现了高精度的自然踝关节运动模拟，并在力矩和功率输出方面表现优于人体自然水平，证明了其设计的有效性和功能性。

Abstract: This study presents a powered transtibial prosthesis with complete push-off
assistance, RoboANKLE. The design aims to fulfill specific requirements, such
as a sufficient range of motion (RoM) while providing the necessary torque for
achieving natural ankle motion in daily activities. Addressing the challenges
faced in designing active transtibial prostheses, such as maintaining energetic
autonomy and minimizing weight, is vital for the study. With this aim, we try
to imitate the human ankle by providing extensive push-off assistance to
achieve a natural-like torque profile. Thus, Energy Store and Extended Release
mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism.
Kinematic and kinetic analyses are carried out to determine the design
parameters and assess the design performance. Subsequently, a Computer-Aided
Design (CAD) model is built and used in comprehensive dynamic and structural
analyses. These analyses are used for the design performance evaluation and
determine the forces and torques applied to the prosthesis, which aids in
optimizing the design for minimal weight via structural analysis and topology
optimization. The design of the prototype is then finalized and manufactured
for experimental evaluation to validate the design and functionality. The
prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm.
The Functional evaluations of the RoboANKLE revealed that it is capable of
achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also,
Thanks to the implemented mechanisms, the results show that RoboANKLE can
generate 57% higher than the required torque for natural walking. The result of
the power generation capacity of the RoboANKLE is 10% more than the natural
power during the gait cycle.

</details>


### [273] [Towards Adaptable Humanoid Control via Adaptive Motion Tracking](https://arxiv.org/abs/2510.14454)
*Tao Huang,Huayi Wang,Junli Ren,Kangning Yin,Zirui Wang,Xiao Chen,Feiyu Jia,Wentao Zhang,Junfeng Long,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: AdaMimic 算法通过单参考动作实现适应性强的类人控制，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有运动先验方法在适应性上表现良好，但牺牲了模仿的准确性；而运动跟踪方法虽然模仿准确，但需要大量训练数据和测试时目标动作。AdaMimic 旨在结合两者的优点。

Method: AdaMimic 算法首先通过稀疏化单个参考动作的关键帧并进行轻微编辑来创建增强数据集，然后通过跟踪这些稀疏关键帧来初始化策略，生成密集的中间运动。接着，训练适配器来调整跟踪速度并优化低级动作，从而实现灵活的时间扭曲，提高模仿准确性和适应性。

Result: 该方法在仿真和现实世界的 Unitree G1 机器人上，在多种任务和广泛的适应条件下，都显著提高了性能。

Conclusion: AdaMimic 算法能够仅用一个参考动作，实现类人机器人运动的准确模仿和高度适应性，克服了现有技术的不足。

Abstract: Humanoid robots are envisioned to adapt demonstrated motions to diverse
real-world conditions while accurately preserving motion patterns. Existing
motion prior approaches enable well adaptability with a few motions but often
sacrifice imitation accuracy, whereas motion-tracking methods achieve accurate
imitation yet require many training motions and a test-time target motion to
adapt. To combine their strengths, we introduce AdaMimic, a novel motion
tracking algorithm that enables adaptable humanoid control from a single
reference motion. To reduce data dependence while ensuring adaptability, our
method first creates an augmented dataset by sparsifying the single reference
motion into keyframes and applying light editing with minimal physical
assumptions. A policy is then initialized by tracking these sparse keyframes to
generate dense intermediate motions, and adapters are subsequently trained to
adjust tracking speed and refine low-level actions based on the adjustment,
enabling flexible time warping that further improves imitation accuracy and
adaptability. We validate these significant improvements in our approach in
both simulation and the real-world Unitree G1 humanoid robot in multiple tasks
across a wide range of adaptation conditions. Videos and code are available at
https://taohuang13.github.io/adamimic.github.io/.

</details>


### [274] [Restoring Noisy Demonstration for Imitation Learning With Diffusion Models](https://arxiv.org/abs/2510.14467)
*Shang-Fu Chen,Co Yong,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 该研究提出了一种过滤器和恢复框架，用于处理包含噪声的专家演示数据，以提高模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法通常假设专家演示是完美的，但实际演示常包含由人类错误或系统不准确引起的噪声。

Method: 提出了一种过滤器-恢复框架，首先从演示数据中筛选干净的样本，然后学习条件扩散模型来恢复噪声样本。

Result: 在机器人手臂操作、灵巧操作和运动控制等多个领域，该框架的性能优于现有方法，并且在不同噪声类型和水平下都表现出鲁棒性。

Conclusion: 该框架能够有效利用含有噪声的离线演示数据，具有实际应用价值。

Abstract: Imitation learning (IL) aims to learn a policy from expert demonstrations and
has been applied to various applications. By learning from the expert policy,
IL methods do not require environmental interactions or reward signals.
However, most existing imitation learning algorithms assume perfect expert
demonstrations, but expert demonstrations often contain imperfections caused by
errors from human experts or sensor/control system inaccuracies. To address the
above problems, this work proposes a filter-and-restore framework to best
leverage expert demonstrations with inherent noise. Our proposed method first
filters clean samples from the demonstrations and then learns conditional
diffusion models to recover the noisy ones. We evaluate our proposed framework
and existing methods in various domains, including robot arm manipulation,
dexterous manipulation, and locomotion. The experiment results show that our
proposed framework consistently outperforms existing methods across all the
tasks. Ablation studies further validate the effectiveness of each component
and demonstrate the framework's robustness to different noise types and levels.
These results confirm the practical applicability of our framework to noisy
offline demonstration data.

</details>


### [275] [Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots](https://arxiv.org/abs/2510.14511)
*Mingtian Du,Suhas Raghavendra Kulkarni,Simone Kager,Domenico Campolo*

Main category: cs.RO

TL;DR: 本研究针对含网络延迟的机器人辅助人机交互系统，提出了分析稳定性判据。


<details>
  <summary>Details</summary>
Motivation: 研究机器人辅助人机交互系统中的稳定性问题，特别是在网络延迟存在的情况下。

Method: 通过频域分析和数值模拟，推导了与延迟无关和与延迟相关的稳定性判据。

Result: 研究发现，系统的稳定性与控制器和机器人动力学参数有关，例如增加刚度会非线性地减小最大容忍延迟。实验表明稳定性与运动性能相关。

Conclusion: 提出的稳定性判据可推广应用于多种机器人辅助交互，并可作为设计稳定远程系统的指导原则，同时指出了有效延迟补偿策略的先决条件。

Abstract: This paper establishes analytical stability criteria for robot-mediated
human-human (dyadic) interaction systems, focusing on haptic communication
under network-induced time delays. Through frequency-domain analysis supported
by numerical simulations, we identify both delay-independent and
delay-dependent stability criteria. The delay-independent criterion guarantees
stability irrespective of the delay, whereas the delay-dependent criterion is
characterised by a maximum tolerable delay before instability occurs. The
criteria demonstrate dependence on controller and robot dynamic parameters,
where increasing stiffness reduces the maximum tolerable delay in a non-linear
manner, thereby heightening system vulnerability. The proposed criteria can be
generalised to a wide range of robot-mediated interactions and serve as design
guidelines for stable remote dyadic systems. Experiments with robots performing
human-like movements further illustrate the correlation between stability and
motor performance. The findings of this paper suggest the prerequisites for
effective delay-compensation strategies.

</details>


### [276] [QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps](https://arxiv.org/abs/2510.14546)
*Matti Pekkanen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 视觉-语言模型生成的嵌入能够用于机器人地图的语义表征，实现开放词汇的场景理解。本研究提出一种利用查询词的同义词和反义词来估计相关语言空间，并训练分类器来划分环境的方法，以解决在查询中确定机器人应关注环境部分的关键挑战。实验证明该方法能够提升地图和图像的可查询性，且不依赖于特定的表征和编码器，只需有限的训练。


<details>
  <summary>Details</summary>
Motivation: 在机器人地图中，使用视觉-语言模型嵌入进行开放词汇场景理解时，关键挑战在于如何根据用户查询确定与查询相关的环境部分。

Method: 利用查询词的同义词和反义词，在嵌入空间中估计与查询相关的语言空间，并以此训练分类器来划分环境为匹配和非匹配两部分。

Result: 通过在地图和标准图像基准上的广泛实验证明，所提出的方法能够提升地图和图像的可查询性。

Conclusion: 所提出的查询技术不依赖于具体的表征和编码器，且训练成本低，能够有效解决机器人地图查询中的相关性确定问题。

Abstract: Embeddings from Visual-Language Models are increasingly utilized to represent
semantics in robotic maps, offering an open-vocabulary scene understanding that
surpasses traditional, limited labels. Embeddings enable on-demand querying by
comparing embedded user text prompts to map embeddings via a similarity metric.
The key challenge in performing the task indicated in a query is that the robot
must determine the parts of the environment relevant to the query.
  This paper proposes a solution to this challenge. We leverage
natural-language synonyms and antonyms associated with the query within the
embedding space, applying heuristics to estimate the language space relevant to
the query, and use that to train a classifier to partition the environment into
matches and non-matches. We evaluate our method through extensive experiments,
querying both maps and standard image benchmarks. The results demonstrate
increased queryability of maps and images. Our querying technique is agnostic
to the representation and encoder used, and requires limited training.

</details>


### [277] [A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning](https://arxiv.org/abs/2510.14584)
*Benno Wingender,Nils Dengler,Rohit Menon,Sicong Pan,Maren Bennewitz*

Main category: cs.RO

TL;DR: 该研究提出了一种通用的可放置性度量，可以直接从带噪声的点云中评估放置姿态，无需任何形状先验，并且能同时评估稳定性和抓取性。该方法通过提取物体的支撑面来生成多方向放置的候选点，并生成满足碰撞和稳定约束的接触点。通过将抓取分数与每个候选放置点相关联，可以实现无模型、统一的抓取-放置推理，并选择可实现稳定、无碰撞放置的抓取-放置对。


<details>
  <summary>Details</summary>
Motivation: 现有方法在真实世界传感器噪声下抓取和放置未知物体时面临挑战，因为它们依赖于强对象先验（例如 CAD 模型）或平面支撑假设，限制了泛化能力和抓取与放置之间的统一推理。

Method: 提出了一种通用的可放置性度量，可以直接从带噪声的点云中评估放置姿态，无需任何形状先验。该度量同时评估稳定性和抓取性。从原始几何形状中提取物体的支撑面，以生成多方向放置的候选点，并生成满足碰撞和稳定约束的接触点。通过将抓取分数与每个候选放置点相关联，实现了无模型、统一的抓取-放置推理，并选择可实现稳定、无碰撞放置的抓取-放置对。

Result: 在未见过（unseen）的真实物体和非平面物体支撑上，该度量在预测稳定性损失方面达到了与 CAD 相当的精度，并且通常比基于学习的预测器产生更符合物理规律的放置。

Conclusion: 该研究提出的通用可放置性度量能够从带噪声的点云中直接评估放置姿态，无需形状先验，并能统一抓取和放置的推理，在真实世界场景中表现出鲁棒性和准确性。

Abstract: To reliably pick and place unknown objects under real-world sensing noise
remains a challenging task, as existing methods rely on strong object priors
(e.g., CAD models), or planar-support assumptions, limiting generalization and
unified reasoning between grasping and placing. In this work, we introduce a
generalized placeability metric that evaluates placement poses directly from
noisy point clouds, without any shape priors. The metric jointly scores
stability, graspability, and clearance. From raw geometry, we extract the
support surfaces of the object to generate diverse candidates for
multi-orientation placement and sample contacts that satisfy collision and
stability constraints. By conditioning grasp scores on each candidate
placement, our proposed method enables model-free unified pick-and-place
reasoning and selects grasp-place pairs that lead to stable, collision-free
placements. On unseen real objects and non-planar object supports, our metric
delivers CAD-comparable accuracy in predicting stability loss and generally
produces more physically plausible placements than learning-based predictors.

</details>


### [278] [Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning](https://arxiv.org/abs/2510.14612)
*Gabriel Fischer Abati,João Carlos Virgolino Soares,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 将四足机器人本体感受时间序列数据表示为二维图像，用于学习运动任务。


<details>
  <summary>Details</summary>
Motivation: 机器人运动研究中，需要处理高维度、多变量的时间序列数据，传统方法难以有效提取特征。

Method: 提出一种新方法，将时间序列数据编码为二维图像，保留了机器人本体结构和信号间相关性。

Result: 在接触估计任务上，基于图像的方法比传统序列模型提高了预测精度和泛化能力，将准确率从87.7%提升至94.5%。

Conclusion: 基于图像的表示方法能够有效提取机器人本体感受数据的运动相关特征，提升运动学习任务的性能。

Abstract: This paper presents a novel approach for representing proprioceptive
time-series data from quadruped robots as structured two-dimensional images,
enabling the use of convolutional neural networks for learning
locomotion-related tasks. The proposed method encodes temporal dynamics from
multiple proprioceptive signals, such as joint positions, IMU readings, and
foot velocities, while preserving the robot's morphological structure in the
spatial arrangement of the image. This transformation captures inter-signal
correlations and gait-dependent patterns, providing a richer feature space than
direct time-series processing. We apply this concept in the problem of contact
estimation, a key capability for stable and adaptive locomotion on diverse
terrains. Experimental evaluations on both real-world datasets and simulated
environments show that our image-based representation consistently enhances
prediction accuracy and generalization over conventional sequence-based models,
underscoring the potential of cross-modal encoding strategies for robotic state
learning. Our method achieves superior performance on the contact dataset,
improving contact state accuracy from 87.7% to 94.5% over the recently proposed
MI-HGNN method, using a 15 times shorter window size.

</details>


### [279] [Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models](https://arxiv.org/abs/2510.14615)
*Edward Sandra,Lander Vanroye,Dries Dirckx,Ruben Cartuyvels,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: 经典机器人运动规划方法难以处理高维和复杂环境，而扩散模型提供了新的解决方案。现有方法存在泛化性差、依赖特定传感器的问题。本研究提出CAMPD，一种结合上下文感知和无条件去噪扩散模型的运动规划方法，利用注意力机制处理任意数量的上下文信息，无需重新训练即可适应不同场景，并在7自由度机器人上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人运动规划方法在处理高维状态空间和复杂环境时的可扩展性问题，以及当前基于扩散模型的方法在泛化性和传感器依赖性方面的局限性。

Method: 提出上下文感知运动规划扩散（CAMPD）模型，该模型使用无条件去噪扩散模型，并结合了基于传感器无关的上下文信息的条件化。通过在U-Net架构中集成注意力机制，使模型能够处理任意数量的上下文参数。

Result: CAMPD在7自由度机器人操纵器上进行了评估，并在真实世界任务中与最先进的方法进行了基准测试。结果表明，CAMPD能够泛化到未见过的环境，生成高质量、多模态的轨迹，并且所需时间远少于现有方法。

Conclusion: CAMPD通过条件化传感器无关的上下文信息，有效地解决了现有扩散模型在泛化性和传感器依赖性方面的问题，为机器人运动规划提供了一种更通用、更高效的解决方案。

Abstract: Classical methods in robot motion planning, such as sampling-based and
optimization-based methods, often struggle with scalability towards
higher-dimensional state spaces and complex environments. Diffusion models,
known for their capability to learn complex, high-dimensional and multi-modal
data distributions, provide a promising alternative when applied to motion
planning problems and have already shown interesting results. However, most of
the current approaches train their model for a single environment, limiting
their generalization to environments not seen during training. The techniques
that do train a model for multiple environments rely on a specific camera to
provide the model with the necessary environmental information and therefore
always require that sensor. To effectively adapt to diverse scenarios without
the need for retraining, this research proposes Context-Aware Motion Planning
Diffusion (CAMPD). CAMPD leverages a classifier-free denoising probabilistic
diffusion model, conditioned on sensor-agnostic contextual information. An
attention mechanism, integrated in the well-known U-Net architecture,
conditions the model on an arbitrary number of contextual parameters. CAMPD is
evaluated on a 7-DoF robot manipulator and benchmarked against state-of-the-art
approaches on real-world tasks, showing its ability to generalize to unseen
environments and generate high-quality, multi-modal trajectories, at a fraction
of the time required by existing methods.

</details>


### [280] [GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement](https://arxiv.org/abs/2510.14627)
*Yao Zhong,Hanzhi Chen,Simon Schaefer,Anran Zhang,Stefan Leutenegger*

Main category: cs.RO

TL;DR: GOPLA是一个分层框架，通过学习人类演示来解决机器人的物体放置问题，该框架结合了大型语言模型和扩散模型，并利用合成数据进行训练，在各种现实场景中取得了显著的成功。


<details>
  <summary>Details</summary>
Motivation: 机器人需要能够理解并执行将物体放置在合适位置的任务，这需要考虑语义（如物体关系）和几何（如避免碰撞）两个方面。

Method: 提出了一种名为GOPLA的分层框架。首先，使用多模态大型语言模型将人类指令和视觉输入转换为结构化计划（指定物体间关系）。然后，空间映射器将这些计划转换为具有几何常识的3D可供性图。最后，基于扩散的模型规划器根据测试时间成本（考虑多计划分布和碰撞避免）生成放置姿势。为了解决数据稀疏问题，该方法还提出了一种可扩展的流水线，用于将人类演示扩展为多样化的合成训练数据。

Result: 在物体放置任务的准确性和物理可行性评估中，GOPLA相比第二名将成功率提高了30.04个百分点，并展示了在各种真实机器人放置场景中的强大泛化能力。

Conclusion: GOPLA通过结合大型语言模型和基于扩散的模型，并采用数据增强策略，有效解决了机器人物体放置的挑战，实现了高成功率和良好的泛化性。

Abstract: Robots are expected to serve as intelligent assistants, helping humans with
everyday household organization. A central challenge in this setting is the
task of object placement, which requires reasoning about both semantic
preferences (e.g., common-sense object relations) and geometric feasibility
(e.g., collision avoidance). We present GOPLA, a hierarchical framework that
learns generalizable object placement from augmented human demonstrations. A
multi-modal large language model translates human instructions and visual
inputs into structured plans that specify pairwise object relationships. These
plans are then converted into 3D affordance maps with geometric common sense by
a spatial mapper, while a diffusion-based planner generates placement poses
guided by test-time costs, considering multi-plan distributions and collision
avoidance. To overcome data scarcity, we introduce a scalable pipeline that
expands human placement demonstrations into diverse synthetic training data.
Extensive experiments show that our approach improves placement success rates
by 30.04 percentage points over the runner-up, evaluated on positioning
accuracy and physical plausibility, demonstrating strong generalization across
a wide range of real-world robotic placement scenarios.

</details>


### [281] [Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion](https://arxiv.org/abs/2510.14947)
*Blake Werner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 通过分层控制架构（LCA）实现对非结构化环境中机器人行走能力的增强，该架构结合了高速本体稳定器和低速感知策略，并在模拟和硬件上均优于单体端到端设计。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现可靠的类人运动，需要能够平衡低级稳定和高级感知决策的控制架构。

Method: 提出了一种分层控制架构（LCA），该架构包含一个高速本体稳定器和一个低速感知策略，并通过两阶段训练方法（盲稳定器预训练和感知精调）进行训练。

Result: 与单阶段方法相比，LCA在模拟和硬件上均表现出更强的鲁棒性，尤其是在应对楼梯和台阶等挑战性任务时，即使在配置了最小感知编码器的情况下也是如此。在Unitree G1机器人上进行了验证。

Conclusion: 分层控制架构通过分离不同时间尺度的控制，是实现鲁棒的、受感知条件约束的运动的关键，而非网络规模或复杂性。

Abstract: Robust humanoid locomotion in unstructured environments requires
architectures that balance fast low-level stabilization with slower perceptual
decision-making. We show that a simple layered control architecture (LCA), a
proprioceptive stabilizer running at high rate, coupled with a compact low-rate
perceptual policy, enables substantially more robust performance than
monolithic end-to-end designs, even when using minimal perception encoders.
Through a two-stage training curriculum (blind stabilizer pretraining followed
by perceptual fine-tuning), we demonstrate that layered policies consistently
outperform one-stage alternatives in both simulation and hardware. On a Unitree
G1 humanoid, our approach succeeds across stair and ledge tasks where one-stage
perceptual policies fail. These results highlight that architectural separation
of timescales, rather than network scale or complexity, is the key enabler for
robust perception-conditioned locomotion.

</details>


### [282] [Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation](https://arxiv.org/abs/2510.14643)
*Lara Brudermüller,Brandon Hung,Xinghao Zhu,Jiuguang Wang,Nick Hawes,Preston Culbertson,Simon Le Cleac'h*

Main category: cs.RO

TL;DR: 我们提出了一种生成式预测控制（GPC）框架，通过在模拟中收集的SPC控制序列上训练的条件流匹配模型来分摊基于采样的模型预测控制（SPC）。与依赖迭代细化或基于梯度的求解器相比，我们的方法可以直接从噪声SPC数据中学习有意义的提议分布，从而在在线规划期间实现更有效和更明智的采样。我们还首次展示了该方法在四足机器人真实世界接触丰富的loco-manipulation任务中的应用。在模拟和硬件上进行的广泛实验表明，我们的方法提高了样本效率，缩短了规划时间要求，并能稳健地泛化到各种任务。 


<details>
  <summary>Details</summary>
Motivation: 与依赖迭代细化或基于梯度的求解器相比，我们的方法可以直接从噪声SPC数据中学习有意义的提议分布，从而在在线规划期间实现更有效和更明智的采样。

Method: 提出了一种生成式预测控制（GPC）框架，通过在模拟中收集的SPC控制序列上训练的条件流匹配模型来分摊基于采样的模型预测控制（SPC）。

Result: 在模拟和硬件上进行的广泛实验表明，我们的方法提高了样本效率，缩短了规划时间要求，并能稳健地泛化到各种任务。

Conclusion: 我们首次展示了该方法在四足机器人真实世界接触丰富的loco-manipulation任务中的应用。

Abstract: We present a generative predictive control (GPC) framework that amortizes
sampling-based Model Predictive Control (SPC) by bootstrapping it with
conditional flow-matching models trained on SPC control sequences collected in
simulation. Unlike prior work relying on iterative refinement or gradient-based
solvers, we show that meaningful proposal distributions can be learned directly
from noisy SPC data, enabling more efficient and informed sampling during
online planning. We further demonstrate, for the first time, the application of
this approach to real-world contact-rich loco-manipulation with a quadruped
robot. Extensive experiments in simulation and on hardware show that our method
improves sample efficiency, reduces planning horizon requirements, and
generalizes robustly across task variations.

</details>


### [283] [CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions](https://arxiv.org/abs/2510.14959)
*Lizhi Yang,Blake Werner,Massimiliano de Sa Aaron D. Ames*

Main category: cs.RO

TL;DR: CBF-RL框架在训练中强制执行CBF，以生成安全且高效的RL策略，无需在线安全过滤器。


<details>
  <summary>Details</summary>
Motivation: 传统的RL在追求性能的同时可能忽略安全性，而CBFs虽然能保证安全但可能导致过于保守的行为，本研究旨在解决RL的安全性和效率问题。

Method: CBF-RL框架通过在训练中引入CBF项来最小化修改RL策略，并对训练过程中的策略进行安全过滤，理论上证明了连续时间安全过滤器在离散时间回滚上的闭式解部署，并实现了安全性和效率的结合。

Result: CBF-RL能够内化安全约束，实现更安全的动作选择和更优的奖励偏向，从而在无需在线安全过滤器的情况下实现安全部署。通过在导航任务和Unitree G1人形机器人上的实验验证，CBF-RL在安全探索、快速收敛和不确定性下的鲁棒性方面表现出色，使得人形机器人能够在真实环境中安全地避开障碍物和攀爬楼梯。

Conclusion: CBF-RL通过在训练中集成CBFs，克服了传统RL的安全隐患和CBFs的保守性问题，实现了在不依赖在线安全过滤器的前提下，学习到安全且高效的RL策略，并在机器人导航和操作任务中得到了有效验证。

Abstract: Reinforcement learning (RL), while powerful and expressive, can often
prioritize performance at the expense of safety. Yet safety violations can lead
to catastrophic outcomes in real-world deployments. Control Barrier Functions
(CBFs) offer a principled method to enforce dynamic safety -- traditionally
deployed \emph{online} via safety filters. While the result is safe behavior,
the fact that the RL policy does not have knowledge of the CBF can lead to
conservative behaviors. This paper proposes CBF-RL, a framework for generating
safe behaviors with RL by enforcing CBFs \emph{in training}. CBF-RL has two key
attributes: (1) minimally modifying a nominal RL policy to encode safety
constraints via a CBF term, (2) and safety filtering of the policy rollouts in
training. Theoretically, we prove that continuous-time safety filters can be
deployed via closed-form expressions on discrete-time roll-outs. Practically,
we demonstrate that CBF-RL internalizes the safety constraints in the learned
policy -- both enforcing safer actions and biasing towards safer rewards --
enabling safe deployment without the need for an online safety filter. We
validate our framework through ablation studies on navigation tasks and on the
Unitree G1 humanoid robot, where CBF-RL enables safer exploration, faster
convergence, and robust performance under uncertainty, enabling the humanoid
robot to avoid obstacles and climb stairs safely in real-world settings without
a runtime safety filter.

</details>


### [284] [Spatially anchored Tactile Awareness for Robust Dexterous Manipulation](https://arxiv.org/abs/2510.14647)
*Jialei Huang,Yang Ye,Yuanqing Gong,Xuezhou Zhu,Yang Gao,Kaifeng Zhang*

Main category: cs.RO

TL;DR: SaTA 是一个端到端的策略框架，它通过正向运动学将触觉特征明确地锚定在手的运动学框架中，从而能够在不需要物体模型或显式姿态估计的情况下进行精确的几何推理。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-触觉学习方法在需要亚毫米级精度的操作任务中存在局限性，因为它们未能有效利用触觉信号的感知丰富性和手部运动学的空间关系。

Method: SaTA 框架通过正向运动学将触觉特征显式地锚定在手的运动学框架中，以实现精确的几何推理。

Result: 在双臂 USB-C 接口对接、灯泡安装和卡片滑动等具有挑战性的任务中，SaTA 的成功率提高了 30%，任务完成时间缩短了 27%，显著优于现有的视觉-触觉基线方法。

Conclusion: SaTA 通过将触觉表征锚定在空间中，实现了精确的几何推理，从而克服了现有方法的局限性，并在高精度操作任务中取得了优异的性能。

Abstract: Dexterous manipulation requires precise geometric reasoning, yet existing
visuo-tactile learning methods struggle with sub-millimeter precision tasks
that are routine for traditional model-based approaches. We identify a key
limitation: while tactile sensors provide rich contact information, current
learning frameworks fail to effectively leverage both the perceptual richness
of tactile signals and their spatial relationship with hand kinematics. We
believe an ideal tactile representation should explicitly ground contact
measurements in a stable reference frame while preserving detailed sensory
information, enabling policies to not only detect contact occurrence but also
precisely infer object geometry in the hand's coordinate system. We introduce
SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an
end-to-end policy framework that explicitly anchors tactile features to the
hand's kinematic frame through forward kinematics, enabling accurate geometric
reasoning without requiring object models or explicit pose estimation. Our key
insight is that spatially grounded tactile representations allow policies to
not only detect contact occurrence but also precisely infer object geometry in
the hand's coordinate system. We validate SaTA on challenging dexterous
manipulation tasks, including bimanual USB-C mating in free space, a task
demanding sub-millimeter alignment precision, as well as light bulb
installation requiring precise thread engagement and rotational control, and
card sliding that demands delicate force modulation and angular precision.
These tasks represent significant challenges for learning-based methods due to
their stringent precision requirements. Across multiple benchmarks, SaTA
significantly outperforms strong visuo-tactile baselines, improving success
rates by up to 30 percentage while reducing task completion times by 27
percentage.

</details>


### [285] [RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](https://arxiv.org/abs/2510.14968)
*Mingxuan Yan,Yuping Wang,Zechun Liu,Jiachen Li*

Main category: cs.RO

TL;DR: 该研究提出了一种名为RDD（检索式演示分解器）的新方法，用于解决长时序任务中的子任务分解问题。RDD能够自动将演示数据分解为子任务，并使这些子任务与低级视觉运动策略的训练数据对齐，从而提高了任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于VLM（视觉-语言模型）的规划器在分解复杂操纵任务时，依赖于手动标注或启发式规则来分割子任务。然而，这种分割可能与低级策略的训练数据不匹配，导致性能下降。本研究旨在解决这个问题，提出一种新的方法来自动分解演示数据，并使其与低级策略的训练数据对齐。

Method: RDD方法通过对齐分解出的子任务时间段的视觉特征与低级视觉运动策略训练数据的视觉特征，来实现对演示数据的自动子任务分解。

Result: RDD方法在模拟和真实世界任务中均优于目前最先进的子任务分解器，表现出跨不同场景的鲁棒性。

Conclusion: RDD能够有效地自动分解演示数据为子任务，并与低级策略的训练数据对齐，从而提高长时序任务的性能。

Abstract: To tackle long-horizon tasks, recent hierarchical vision-language-action
(VLAs) frameworks employ vision-language model (VLM)-based planners to
decompose complex manipulation tasks into simpler sub-tasks that low-level
visuomotor policies can easily handle. Typically, the VLM planner is finetuned
to learn to decompose a target task. This finetuning requires target task
demonstrations segmented into sub-tasks by either human annotation or heuristic
rules. However, the heuristic subtasks can deviate significantly from the
training data of the visuomotor policy, which degrades task performance. To
address these issues, we propose a Retrieval-based Demonstration Decomposer
(RDD) that automatically decomposes demonstrations into sub-tasks by aligning
the visual features of the decomposed sub-task intervals with those from the
training data of the low-level visuomotor policies. Our method outperforms the
state-of-the-art sub-task decomposer on both simulation and real-world tasks,
demonstrating robustness across diverse settings. Code and more results are
available at rdd-neurips.github.io.

</details>


### [286] [Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery](https://arxiv.org/abs/2510.14768)
*Fan Yang,Zixuan Huang,Abhinav Kumar,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: CADRE是一个基于强化学习的框架，通过引入神经描述符场（NDF）来提取隐式接触特征，以实现对下落物体的抓取和恢复，并能泛化到未见过的物体。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的灵巧操作会遇到意外的错误和干扰，可能导致操作失败，例如物体掉落。为了解决这个问题，研究提出了一种在抓取范围内接住下落物体并恢复到有利状态以继续主要操作任务的方法。

Method: 提出了一种名为CADRE（Contact-Aware Dynamic Recovery）的强化学习框架，该框架包含一个受神经描述符场（NDF）启发的模块，用于提取隐式接触特征。与仅依赖物体姿态或点云输入的现有方法相比，NDF可以直接推理手指与物体的对应关系并适应不同的物体几何形状。

Result: 实验表明，引入接触特征可以提高训练效率，改善强化学习训练的收敛性能，并最终实现更成功的恢复。此外，CADRE能够对不同几何形状的未见过物体进行零样本泛化。

Conclusion: CADRE框架通过整合接触特征，提高了灵巧操作中应对意外情况的能力，尤其是在物体掉落时能够有效恢复，并且具有良好的泛化性。

Abstract: Real-world dexterous manipulation often encounters unexpected errors and
disturbances, which can lead to catastrophic failures, such as dropping the
manipulated object. To address this challenge, we focus on the problem of
catching a falling object while it remains within grasping range and,
importantly, resetting the system to a configuration favorable for resuming the
primary manipulation task. We propose Contact-Aware Dynamic Recovery (CADRE), a
reinforcement learning framework that incorporates a Neural Descriptor Field
(NDF)-inspired module to extract implicit contact features. Compared to methods
that rely solely on object pose or point cloud input, NDFs can directly reason
about finger-object correspondence and adapt to different object geometries.
Our experiments show that incorporating contact features improves training
efficiency, enhances convergence performance for RL training, and ultimately
leads to more successful recoveries. Additionally, we demonstrate that CADRE
can generalize zero-shot to unseen objects with different geometries.

</details>


### [287] [Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation](https://arxiv.org/abs/2510.14771)
*Xu Chi,Chao Zhang,Yang Su,Lingfeng Dou,Fujia Yang,Jiakuo Zhao,Haoyu Zhou,Xiaoyou Jia,Yong Zhou,Shan An*

Main category: cs.RO

TL;DR: Open TeleDex是一个统一的遥操作框架，用于机器人模仿学习（IL）的数据收集，解决了异构机器人平台的数据采集瓶颈。它支持任何机械臂、任何灵巧手和任何输入设备，并包含一个新颖的手部姿态重定向算法，以提高与各种设备的兼容性。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习（IL）系统在部署时面临着准确、高保真的演示数据采集瓶颈，尤其是在处理异构机器人平台时。现有的遥操作系统往往无法保证跨不同遥操作设备的高精度数据采集。

Method: 开发了一个名为Open TeleDex的统一遥操作框架，支持任何机械臂、任何灵巧手和任何输入设备。提出了一种新颖的手部姿态重定向算法，以提高与各种主从设备的兼容性。

Result: Open TeleDex成功地解决了TripleAny挑战，提供了对广泛的异构主从设备的鲁棒且准确的兼容性。

Conclusion: Open TeleDex为加速复杂机器人操作和IL领域的学术研究和行业发展，提供了一个基础性、高质量且公开可用的平台。

Abstract: Accurate and high-fidelity demonstration data acquisition is a critical
bottleneck for deploying robot Imitation Learning (IL) systems, particularly
when dealing with heterogeneous robotic platforms. Existing teleoperation
systems often fail to guarantee high-precision data collection across diverse
types of teleoperation devices. To address this, we developed Open TeleDex, a
unified teleoperation framework engineered for demonstration data collection.
Open TeleDex specifically tackles the TripleAny challenge, seamlessly
supporting any robotic arm, any dexterous hand, and any external input device.
Furthermore, we propose a novel hand pose retargeting algorithm that
significantly boosts the interoperability of Open TeleDex, enabling robust and
accurate compatibility with an even wider spectrum of heterogeneous master and
slave equipment. Open TeleDex establishes a foundational, high-quality, and
publicly available platform for accelerating both academic research and
industry development in complex robotic manipulation and IL.

</details>


### [288] [SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning](https://arxiv.org/abs/2510.14783)
*Aderik Verraest,Stavrow Bahnam,Robin Ferede,Guido de Croon,Christophe De Wagter*

Main category: cs.RO

TL;DR: SkyDreamer是首个端到端、纯视觉的自主无人机竞速策略，实现了完全的仿真到现实迁移、机载运行和冠军级性能，将像素级表示直接映射到电机指令。


<details>
  <summary>Details</summary>
Motivation: 尽管自主无人机竞速（ADR）系统已达到冠军级水平，但仍局限于无人机竞速领域。端到端视觉方法有更广泛的应用前景，但现有系统无法同时实现仿真到现实的完全迁移、机载运行和冠军级性能。

Method: SkyDreamer建立在Informed Dreamer（一种模型基础强化学习方法）之上，该方法在训练期间仅将世界模型解码为特权信息。通过将此概念扩展到端到端的视觉ADR，世界模型有效地充当了隐式状态和参数估计器，提高了可解释性。SkyDreamer完全在机载运行，无需外部辅助，通过跟踪世界模型隐藏状态解码后的进度来解决视觉歧义，并且无需外部相机校准，即可在不同无人机上快速部署而无需重新训练。

Result: 现实世界实验表明，SkyDreamer实现了稳定、高速的飞行，能够执行倒置回旋、Split-S和梯形等高难度机动，最高速度达到21米/秒，加速度高达6g。它还通过处理低质量的分割掩码，展示了非平凡的视觉仿真到现实迁移能力，并通过准确估计最大电机转速并实时调整飞行路径，表现出对电池消耗的鲁棒性。

Conclusion: SkyDreamer展示了其对现实差距重要方面的适应性，在实现极高速度和敏捷飞行的同时，提高了鲁棒性。

Abstract: Autonomous drone racing (ADR) systems have recently achieved champion-level
performance, yet remain highly specific to drone racing. While end-to-end
vision-based methods promise broader applicability, no system to date
simultaneously achieves full sim-to-real transfer, onboard execution, and
champion-level performance. In this work, we present SkyDreamer, to the best of
our knowledge, the first end-to-end vision-based ADR policy that maps directly
from pixel-level representations to motor commands. SkyDreamer builds on
informed Dreamer, a model-based reinforcement learning approach where the world
model decodes to privileged information only available during training. By
extending this concept to end-to-end vision-based ADR, the world model
effectively functions as an implicit state and parameter estimator, greatly
improving interpretability. SkyDreamer runs fully onboard without external aid,
resolves visual ambiguities by tracking progress using the state decoded from
the world model's hidden state, and requires no extrinsic camera calibration,
enabling rapid deployment across different drones without retraining.
Real-world experiments show that SkyDreamer achieves robust, high-speed flight,
executing tight maneuvers such as an inverted loop, a split-S and a ladder,
reaching speeds of up to 21 m/s and accelerations of up to 6 g. It further
demonstrates a non-trivial visual sim-to-real transfer by operating on
poor-quality segmentation masks, and exhibits robustness to battery depletion
by accurately estimating the maximum attainable motor RPM and adjusting its
flight path in real-time. These results highlight SkyDreamer's adaptability to
important aspects of the reality gap, bringing robustness while still achieving
extremely high-speed, agile flight.

</details>


### [289] [Neural Implicit Flow Fields for Spatio-Temporal Motion Mapping](https://arxiv.org/abs/2510.14827)
*Yufei Zhu,Shih-Min Yang,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 该研究提出了一种基于隐式神经网络函数的新型连续时空运动模式地图（MoD）表示方法，以更准确、更高效地建模复杂的人类运动模式。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂的人类环境中实现安全高效的机器人操作，需要对特定地点的运动模式进行良好的建模。现有的 MoD 表示方法存在离散空间采样和构建成本高昂的问题。

Method: 提出了一种基于隐式神经网络函数的连续时空 MoD 表示，可以直接将坐标映射到半包装高斯混合模型（SGM）的参数。该方法消除了离散化和不均匀采样区域插值的需要，实现了跨空间和时间的平滑泛化。

Result: 在包含长期真实世界人员跟踪数据的大型公共数据集上评估，与现有方法相比，该方法在运动表示准确性和稀疏区域的速度分布平滑度方面均表现更优，同时计算效率也很高。

Conclusion: 所提出的方法展示了一种强大而有效的方法来模拟复杂的人类运动模式。

Abstract: Safe and efficient robot operation in complex human environments can benefit
from good models of site-specific motion patterns. Maps of Dynamics (MoDs)
provide such models by encoding statistical motion patterns in a map, but
existing representations use discrete spatial sampling and typically require
costly offline construction. We propose a continuous spatio-temporal MoD
representation based on implicit neural functions that directly map coordinates
to the parameters of a Semi-Wrapped Gaussian Mixture Model. This removes the
need for discretization and imputation for unevenly sampled regions, enabling
smooth generalization across both space and time. Evaluated on a large public
dataset with long-term real-world people tracking data, our method achieves
better accuracy of motion representation and smoother velocity distributions in
sparse regions while still being computationally efficient, compared to
available baselines. The proposed approach demonstrates a powerful and
efficient way of modeling complex human motion patterns.

</details>


### [290] [RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning](https://arxiv.org/abs/2510.14830)
*Kun Lei,Huanyu Li,Dongjie Yu,Zhenyu Wei,Lingxiao Guo,Zhennan Jiang,Ziyu Wang,Shiyu Liang,Huazhe Xu*

Main category: cs.RO

TL;DR: RL-100是一个基于扩散视觉运动策略的真实世界强化学习训练框架，通过模仿学习、迭代离线强化学习和在线强化学习三阶段流水线，实现了100%的成功率，并在机器人操作任务中达到了接近甚至超越人类的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了实现家庭和工厂中接近或超越熟练人类操作员的可靠、高效和鲁棒的真实世界机器人操作。

Method: RL-100框架采用三阶段流水线：1.模仿学习利用人类先验知识；2.迭代离线强化学习通过离线策略评估（OPE）门控PPO风格更新，在去噪过程中进行保守和可靠的改进；3.在线强化学习消除剩余的失败模式。此外，还包含一个轻量级的蒸馏头，将多步采样过程压缩为单步策略，以实现高频控制和低延迟。

Result: RL-100在七个真实机器人任务（包括动态刚体控制、流体和颗粒浇注、可变形织物折叠、精确的灵巧拧螺丝以及多阶段榨橙汁）上进行了评估，在所有评估试验中成功率达到100%（共900/900次试验），其中一项任务连续成功250次。在时间效率方面，RL-100达到了接近人类遥操作的水平或更好，并且表现出长达两小时的无间断运行的鲁棒性。

Conclusion: RL-100是一个通用的真实世界强化学习框架，它利用模仿学习、迭代离线强化学习和在线强化学习，并通过蒸馏实现了高效的控制，在各种具有挑战性的机器人操作任务中取得了卓越的性能，展示了其在实际应用中的巨大潜力。

Abstract: Real-world robotic manipulation in homes and factories demands reliability,
efficiency, and robustness that approach or surpass skilled human operators. We
present RL-100, a real-world reinforcement learning training framework built on
diffusion visuomotor policies trained bu supervised learning. RL-100 introduces
a three-stage pipeline. First, imitation learning leverages human priors.
Second, iterative offline reinforcement learning uses an Offline Policy
Evaluation procedure, abbreviated OPE, to gate PPO-style updates that are
applied in the denoising process for conservative and reliable improvement.
Third, online reinforcement learning eliminates residual failure modes. An
additional lightweight consistency distillation head compresses the multi-step
sampling process in diffusion into a single-step policy, enabling
high-frequency control with an order-of-magnitude reduction in latency while
preserving task performance. The framework is task-, embodiment-, and
representation-agnostic and supports both 3D point clouds and 2D RGB inputs, a
variety of robot platforms, and both single-step and action-chunk policies. We
evaluate RL-100 on seven real-robot tasks spanning dynamic rigid-body control,
such as Push-T and Agile Bowling, fluids and granular pouring, deformable cloth
folding, precise dexterous unscrewing, and multi-stage orange juicing. RL-100
attains 100\% success across evaluated trials for a total of 900 out of 900
episodes, including up to 250 out of 250 consecutive trials on one task. The
method achieves near-human teleoperation or better time efficiency and
demonstrates multi-hour robustness with uninterrupted operation lasting up to
two hours.

</details>


### [291] [STITCHER: Constrained Trajectory Planning in Known Environments with Real-Time Motion Primitive Search](https://arxiv.org/abs/2510.14893)
*Helene J. Levy,Brett T. Lopez*

Main category: cs.RO

TL;DR: STITCHER是一个无优化规划框架，通过图搜索拼接短轨迹段，实时生成长距离、富有表现力且近乎最优的轨迹，优于基于优化的规划器。


<details>
  <summary>Details</summary>
Motivation: 自主高速导航需要实时生成满足动态约束、无碰撞且满足状态/执行器约束的敏捷轨迹。基于优化的规划器虽然能生成高质量轨迹，但计算时间和数值不稳定性限制了其在安全关键场景的应用。

Method: STITCHER框架通过图搜索将短轨迹段拼接起来，生成长距离、富有表现力且近乎最优的轨迹。

Result: STITCHER的规划速度比基于优化的规划器快，能够在几毫秒内为跨越两个50米x50米环境的路径生成安全轨迹。在四旋翼硬件测试中，STITCHER能够实时生成可追踪的路径，并能处理优化规划器难以包含的非凸约束（如倾斜角度和电机力限制）。

Conclusion: STITCHER通过其创新的规划架构和算法，实现了实时规划，并且在性能上优于现有的基于优化的规划器，能够处理更复杂的约束，适用于安全关键场景。

Abstract: Autonomous high-speed navigation through large, complex environments requires
real-time generation of agile trajectories that are dynamically feasible,
collision-free, and satisfy state or actuator constraints. Modern trajectory
planning techniques primarily use numerical optimization, as they enable the
systematic computation of high-quality, expressive trajectories that satisfy
various constraints. However, stringent requirements on computation time and
the risk of numerical instability can limit the use of optimization-based
planners in safety-critical scenarios. This work presents an optimization-free
planning framework called STITCHER that stitches short trajectory segments
together with graph search to compute long-range, expressive, and near-optimal
trajectories in real-time. STITCHER outperforms modern optimization-based
planners through our innovative planning architecture and several algorithmic
developments that make real-time planning possible. Extensive simulation
testing is performed to analyze the algorithmic components that make up
STITCHER, along with a thorough comparison with two state-of-the-art
optimization planners. Simulation tests show that safe trajectories can be
created within a few milliseconds for paths that span the entirety of two 50 m
x 50 m environments. Hardware tests with a custom quadrotor verify that
STITCHER can produce trackable paths in real-time while respecting nonconvex
constraints, such as limits on tilt angle and motor forces, which are otherwise
hard to include in optimization-based planners.

</details>


### [292] [VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation](https://arxiv.org/abs/2510.14902)
*Han Zhao,Jiaxuan Zhang,Wenxuan Song,Pengxiang Ding,Donglin Wang*

Main category: cs.RO

TL;DR: VLA^2通过整合网络检索和目标检测模块，解决了现有VLA模型在处理训练数据外物体时的泛化能力不足的问题，并在新的基准测试中显著提高了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在处理训练数据外（如未见过描述或纹理）的物体时，成功率会显著下降。

Method: 提出了一种名为VLA^2的新型自主框架，该框架以OpenVLA为执行主干，并有效利用网络检索和目标检测等外部模块来提供关于目标物体的视觉和文本知识，以解决泛化能力不足的问题。

Result: 在LIBERO模拟环境中，VLA^2框架在设计的三种难度级别的新型评估基准上进行了测试。在包含新颖物体和物体描述的硬级别泛化基准上，VLA^2的成功率比当前最先进的模型高出44.2%，并且在所有自定义环境中平均提高了20.2%，同时在训练内的任务上没有性能下降。

Conclusion: VLA^2框架通过整合外部知识模块，有效提高了VLA模型处理分布外物体的泛化能力，并在新的基准测试中取得了显著的成果。

Abstract: Current vision-language-action (VLA) models, pre-trained on large-scale
robotic data, exhibit strong multi-task capabilities and generalize well to
variations in visual and language instructions for manipulation. However, their
success rate drops significantly when faced with object concepts outside the
training data, such as unseen object descriptions and textures in the dataset.
To address this, we propose a novel agentic framework, VLA^2, which leverages
OpenVLA as the execution backbone and effectively leverages external modules
such as web retrieval and object detection to provide visual and textual
knowledge about target objects to the VLA. This approach mitigates
generalization failure when handling out-of-distribution objects. Based on the
LIBERO simulation environment, we introduced novel objects and object
descriptions to construct a new evaluation benchmark with three difficulty
levels to test the effectiveness of our method. Our framework successfully
outperformed the current state-of-the-art models on our designed hard-level
generalization benchmark. Compared to the standalone OpenVLA baseline, VLA^2
achieves a 44.2% improvement in the success rate in the hard-level benchmark
and an average improvement of 20.2% in all customized environments without any
performance degradation on in-domain tasks. Project website:
https://vla-2.github.io.

</details>


### [293] [VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tunin](https://arxiv.org/abs/2510.14930)
*Binghao Huang,Jie Xu,Iretiayo Akinola,Wei Yang,Balakumar Sundaralingam,Rowland O'Flaherty,Dieter Fox,Xiaolong Wang,Arsalan Mousavian,Yu-Wei Chao,Yunzhu Li*

Main category: cs.RO

TL;DR: VT-Refine是一个结合了视觉和触觉反馈的机器人装配框架，通过模拟和强化学习来提高装配任务的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人难以通过行为克隆复制人类在双臂装配任务中适应触觉反馈的能力，因为人类演示具有次优性和有限性。

Method: VT-Refine结合了真实世界演示、高保真触觉模拟和强化学习。首先，在少量演示上训练一个扩散策略，然后将其转移到具有模拟触觉传感器的数字孪生中，并通过大规模强化学习进行优化，以提高鲁棒性和泛化能力。

Result: VT-Refine提高了模拟和现实世界中的装配性能，增加了数据多样性，并实现了更有效的策略微调。

Conclusion: VT-Refine框架通过结合视觉和触觉信息，以及利用模拟和强化学习，有效地提高了机器人双臂装配任务的性能。

Abstract: Humans excel at bimanual assembly tasks by adapting to rich tactile feedback
-- a capability that remains difficult to replicate in robots through
behavioral cloning alone, due to the suboptimality and limited diversity of
human demonstrations. In this work, we present VT-Refine, a visuo-tactile
policy learning framework that combines real-world demonstrations,
high-fidelity tactile simulation, and reinforcement learning to tackle precise,
contact-rich bimanual assembly. We begin by training a diffusion policy on a
small set of demonstrations using synchronized visual and tactile inputs. This
policy is then transferred to a simulated digital twin equipped with simulated
tactile sensors and further refined via large-scale reinforcement learning to
enhance robustness and generalization. To enable accurate sim-to-real transfer,
we leverage high-resolution piezoresistive tactile sensors that provide normal
force signals and can be realistically modeled in parallel using
GPU-accelerated simulation. Experimental results show that VT-Refine improves
assembly performance in both simulation and the real world by increasing data
diversity and enabling more effective policy fine-tuning. Our project page is
available at https://binghao-huang.github.io/vt_refine/.

</details>


### [294] [From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance](https://arxiv.org/abs/2510.14952)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Yibo Peng,Tao Huang,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang,Chang Xu*

Main category: cs.RO

TL;DR: RoboGhost是一个无需重定向的框架，可以直接将人形策略的语言和运动潜在因素进行条件化，从而实现从语言到动作的直接连接，减少延迟，提高成功率和跟踪精度，并产生平滑、语义对齐的运动。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导的人形机器人运动方法存在累积误差、高延迟和语义与控制之间耦合弱的问题，需要更直接的语言到动作的路径。

Method: RoboGhost框架直接将语言和运动潜在因素进行条件化，通过基于扩散的模型直接从噪声中去除可执行动作，并使用混合因果Transformer-扩散运动生成器来确保长期一致性、稳定性和多样性。

Result: RoboGhost显著减少了部署延迟，提高了成功率和跟踪精度，并在真实人形机器人上产生了平滑、语义对齐的运动。该框架还可以扩展到其他模态，如图像、音频和音乐。

Conclusion: RoboGhost提供了一个直接的、无需重定向的框架，用于语言引导的人形机器人运动，解决了现有方法的局限性，并在实验中表现出优越的性能。该框架为视觉-语言-动作人形系统奠定了通用基础。

Abstract: Natural language offers a natural interface for humanoid robots, but existing
language-guided humanoid locomotion pipelines remain cumbersome and unreliable.
They typically decode human motion, retarget it to robot morphology, and then
track it with a physics-based controller. However, this multi-stage process is
prone to cumulative errors, introduces high latency, and yields weak coupling
between semantics and control. These limitations call for a more direct pathway
from language to action, one that eliminates fragile intermediate stages.
Therefore, we present RoboGhost, a retargeting-free framework that directly
conditions humanoid policies on language-grounded motion latents. By bypassing
explicit motion decoding and retargeting, RoboGhost enables a diffusion-based
policy to denoise executable actions directly from noise, preserving semantic
intent and supporting fast, reactive control. A hybrid causal
transformer-diffusion motion generator further ensures long-horizon consistency
while maintaining stability and diversity, yielding rich latent representations
for precise humanoid behavior. Extensive experiments demonstrate that RoboGhost
substantially reduces deployment latency, improves success rates and tracking
accuracy, and produces smooth, semantically aligned locomotion on real
humanoids. Beyond text, the framework naturally extends to other modalities
such as images, audio, and music, providing a general foundation for
vision-language-action humanoid systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [295] [Cyber-Resilient System Identification for Power Grid through Bayesian Integration](https://arxiv.org/abs/2510.14043)
*Shimiao Li,Guannan Qu,Bryan Hooi,Vyas Sekar,Soummya Kar,Larry Pileggi*

Main category: eess.SY

TL;DR: 通过结合基于快照的方法和时间序列模型，提出一种新的系统识别方法，以提高电网在面对随机和定向虚假数据攻击时的网络弹性。


<details>
  <summary>Details</summary>
Motivation: 现代电网面临着不断演变的络威胁，需要实时态势感知。现有的基于快照的系统识别方法无法有效应对现代的、交互式的、定向的虚假数据攻击。

Method: 提出一种结合了基于快照的方法和时间序列模型（通过贝叶斯集成）的系统识别方法。该方法使用基于距离的时间序列模型，可以处理不同分布的历史数据，并通过贝叶斯方法将历史数据中的正常系统行为集成到系统识别中，从而实现对定向虚假数据的鲁棒性。

Result: 实验结果表明，该方法在面对混合随机异常（坏数据、拓扑错误）和定向虚假数据注入攻击（FDIA）时，估计误差减少了70%以上，能够识别和定位异常数据，并且具有近乎线性的可扩展性，在大规模系统上的运行时间与基于快照的基线方法相当。

Conclusion: 所提出的结合了基于快照的方法和时间序列模型（通过贝叶斯集成）的系统识别方法，能够有效提高电网应对随机和定向虚假数据攻击的网络弹性，并能准确识别和定位异常数据，同时保持良好的可扩展性。

Abstract: Power grids increasingly need real-time situational awareness under the
ever-evolving cyberthreat landscape. Advances in snapshot-based system
identification approaches have enabled accurately estimating states and
topology from a snapshot of measurement data, under random bad data and
topology errors. However, modern interactive, targeted false data can stay
undetectable to these methods, and significantly compromise estimation
accuracy. This work advances system identification that combines snapshot-based
method with time-series model via Bayesian Integration, to advance cyber
resiliency against both random and targeted false data. Using a distance-based
time-series model, this work can leverage historical data of different
distributions induced by changes in grid topology and other settings. The
normal system behavior captured from historical data is integrated into system
identification through a Bayesian treatment, to make solutions robust to
targeted false data. We experiment on mixed random anomalies (bad data,
topology error) and targeted false data injection attack (FDIA) to demonstrate
our method's 1) cyber resilience: achieving over 70% reduction in estimation
error under FDIA; 2) anomalous data identification: being able to alarm and
locate anomalous data; 3) almost linear scalability: achieving comparable speed
with the snapshot-based baseline, both taking <1min per time tick on the large
2,383-bus system using a laptop CPU.

</details>


### [296] [Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis](https://arxiv.org/abs/2510.14045)
*Qinghua Ma,Reetam Sen Biswas,Denis Osipov,Guannan Qu,Soummya Kar,Shimiao Li*

Main category: eess.SY

TL;DR: 本论文提出了一种多周期稀疏优化方法，用于在电网面临极端事件（如高峰负荷过载）时，识别跨一系列崩溃系统中持续存在的故障源，以提高电网弹性。


<details>
  <summary>Details</summary>
Motivation: 为了增强电网在高峰负荷过载等极端事件下的弹性，需要早期诊断能够识别导致系统崩溃的关键脆弱性。

Method: 提出一种多周期稀疏优化方法，并结合持久性约束来捕捉“隐藏”的演变中的脆弱性。使用基于电路理论的潮流公式和受电路启发的优化启发式方法来提高方法的可扩展性。

Result: 该方法能够可靠地追踪负载增加下的持续脆弱性位置，并且在大系统上具有可扩展性（在2000+节点的系统上，每个场景平均耗时约200秒）。

Conclusion: 该方法能够有效地识别跨一系列系统崩溃中持续存在的故障源，提高了电网的弹性和韧性。

Abstract: Existing or planned power grids need to evaluate survivability under extreme
events, like a number of peak load overloading conditions, which could possibly
cause system collapses (i.e. blackouts). For realistic extreme events that are
correlated or share similar patterns, it is reasonable to expect that the
dominant vulnerability or failure sources behind them share the same locations
but with different severity. Early warning diagnosis that proactively
identifies the key vulnerabilities responsible for a number of system collapses
of interest can significantly enhance resilience. This paper proposes a
multi-period sparse optimization method, enabling the discovery of {persistent
failure sources} across a sequence of collapsed systems with increasing system
stress, such as rising demand or worsening contingencies. This work defines
persistency and efficiently integrates persistency constraints to capture the
``hidden'' evolving vulnerabilities. Circuit-theory based power flow
formulations and circuit-inspired optimization heuristics are used to
facilitate the scalability of the method. Experiments on benchmark systems show
that the method reliably tracks persistent vulnerability locations under
increasing load stress, and solves with scalability to large systems ({on
average} taking {around} 200 s per scenario on 2000+ bus systems).

</details>


### [297] [Dual Detection Framework for Faults and Integrity Attacks in Cyber-Physical Control Systems](https://arxiv.org/abs/2510.14052)
*Xixing Xue,Dong Shen,Steven X. Ding,Dong Zhao*

Main category: eess.SY

TL;DR: 该研究提出了一种双重检测框架，用于检测和区分网络物理控制系统中的异常（包括故障和完整性攻击），并提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 异常检测在网络物理控制系统的安全至关重要，区分不同类型的异常对于系统恢复和缓解措施至关重要。

Method: 提出了一种双重检测框架，利用控制回路的动态特性和完整性攻击的隐蔽性特征，推导出闭环隐蔽条件，并在控制器和被控对象侧分别设计了两个专用检测器，实现了对控制器侧和被控对象侧的联合故障和网络攻击检测。通过联合分析两个检测器对应不同异常的残差响应，证明了该方法可以区分故障和完整性攻击。此外，通过一个两阶段优化方案进一步提高了故障和攻击检测性能。

Result: 仿真结果验证了所提出方法对故障和完整性攻击的有效性。

Conclusion: 所提出的双重检测框架能够有效地检测和区分网络物理控制系统中的故障和完整性攻击，并通过两阶段优化进一步提高了检测性能。

Abstract: Anomaly detection plays a vital role in the security and safety of
cyber-physical control systems, and accurately distinguishing between different
anomaly types is crucial for system recovery and mitigation. This study
proposes a dual detection framework for anomaly detection and discrimination.
By leveraging the dynamic characteristics of control loops and the stealthiness
features of integrity attacks, the closed-loop stealthiness condition is first
derived, and two dedicated detectors are designed and deployed on the
controller side and the plant side, respectively, enabling joint plant fault
and cyber attack detection. Moreover, by jointly analyzing the residual
response of the two detectors corresponding to different anomalies, it is
proved that the proposed method can distinguish between faults and integrity
attacks due to the detectors' individual residual spaces. According to the
detector's residual space, the fault and attack detection performance is
further improved by a two-stage optimization scheme. Simulation results
validate the effectiveness of the proposed approach.

</details>


### [298] [DiffOPF: Diffusion Solver for Optimal Power Flow](https://arxiv.org/abs/2510.14075)
*Milad Hoseinpour,Vladimir Dvorkin*

Main category: eess.SY

TL;DR: DiffOPF是一个基于扩散模型的OPF求解器，能够处理OPF的多值性和系统参数的可变性，并生成统计上可信的暖启动。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习OPF求解器是单值的，无法捕捉OPF的多值性和系统参数的可变性，除非将所有参数都包含在特征空间中，这在计算上是不可行的。

Method: DiffOPF将OPF视为一个条件采样问题，通过学习从运行历史中得到的负荷和调度设定点的联合分布，并生成给定负荷下的边际调度分布。

Result: DiffOPF能够生成统计上可信的暖启动，并在成本和约束满足之间取得有利的权衡。实验在电力系统基准上验证了DiffOPF的采样复杂度和优化求解器的邻近度。

Conclusion: DiffOPF通过将OPF视为条件采样问题，解决了现有OPF求解器无法处理多值性和系统参数可变性的问题，并能在成本和约束满足之间取得良好的权衡。

Abstract: The optimal power flow (OPF) is a multi-valued, non-convex mapping from loads
to dispatch setpoints. The variability of system parameters (e.g., admittances,
topology) further contributes to the multiplicity of dispatch setpoints for a
given load. Existing deep learning OPF solvers are single-valued and thus fail
to capture the variability of system parameters unless fully represented in the
feature space, which is prohibitive. To solve this problem, we introduce a
diffusion-based OPF solver, termed \textit{DiffOPF}, that treats OPF as a
conditional sampling problem. The solver learns the joint distribution of loads
and dispatch setpoints from operational history, and returns the marginal
dispatch distributions conditioned on loads. Unlike single-valued solvers,
DiffOPF enables sampling statistically credible warm starts with favorable cost
and constraint satisfaction trade-offs. We explore the sample complexity of
DiffOPF to ensure the OPF solution within a prescribed distance from the
optimization-based solution, and verify this experimentally on power system
benchmarks.

</details>


### [299] [Belief Space Control of Safety-Critical Systems Under State-Dependent Measurement Noise](https://arxiv.org/abs/2510.14100)
*Rohan Walia,Mitchell Black,Andrew Schoer,Kevin Leahy*

Main category: eess.SY

TL;DR: 该研究提出了结合了状态相关测量噪声的信念控制屏障函数（BCBF）框架，并使用通用扩展卡尔曼滤波器（GEKF）算法进行建模，以提高安全关键控制的性能，减少保守性，同时保持高水平的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的控制屏障函数（CBFs）在处理复杂传感器（尤其是具有状态相关误差特性的传感器）时，由于采用了简化的加性、固定噪声模型，可能导致控制策略过于保守。本研究旨在解决这一问题，通过考虑状态依赖的测量噪声来改进CBF框架。

Method: 本研究将信念控制屏障函数（BCBF）框架扩展到可以处理状态依赖测量噪声的情况。具体而言，它利用了通用扩展卡尔曼滤波器（GEKF）算法，该算法将测量噪声建模为状态的线性函数。

Result: 通过在1D单积分器设定点跟踪和2D单轮车运动学轨迹跟踪场景下的仿真结果表明，与仅使用原始BCBF框架相比，BCBF-GEKF方法提供了保守性更小的控制，同时保证了更高的安全性。

Conclusion: BCBF-GEKF方法能够有效地处理状态依赖的测量噪声，在保证安全性的前提下，能够实现更优、不那么保守的控制性能。

Abstract: Safety-critical control is imperative for deploying autonomous systems in the
real world. Control Barrier Functions (CBFs) offer strong safety guarantees
when accurate system and sensor models are available. However, widely used
additive, fixed-noise models are not representative of complex sensor
modalities with state-dependent error characteristics. Although CBFs have been
designed to mitigate uncertainty using fixed worst-case bounds on measurement
noise, this approach can lead to overly-conservative control. To solve this
problem, we extend the Belief Control Barrier Function (BCBF) framework to
accommodate state-dependent measurement noise via the Generalized Extended
Kalman Filter (GEKF) algorithm, which models measurement noise as a linear
function of the state. Using the original BCBF framework as baseline, we
demonstrate the performance of the BCBF-GEKF approach through simulation
results on a 1D single integrator setpoint tracking scenario and 2D unicycle
kinematics trajectory tracking scenario. Our results confirm that the BCBF-GEKF
approach offers less conservative control with greater safety.

</details>


### [300] [Resource-Aware Stealthy Attacks in Vehicle Platoons](https://arxiv.org/abs/2510.14119)
*Ali Eslami,Mohammad Pirani*

Main category: eess.SY

TL;DR: 攻击者可以秘密地操纵车队行为，以实现其自身的目标轨迹，而不会被发现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在防御攻击，而很少关注旨在秘密操纵车队行为的隐蔽对手。

Method: 提出了一种新的攻击设计视角，展示了攻击者如何引导车队朝着其自身的目标轨迹发展，同时保持不被发现。分析了攻击的可行性条件、对通信拓扑和控制协议的依赖性以及攻击者所需的资源。

Result: 揭示了当前车队架构和异常检测机制的关键弱点，并提供了开发更安全、更可信的自动驾驶汽车系统的方法。

Conclusion: 通过表征发起隐蔽攻击所需的资源，解决了系统漏洞，并为设计有弹性的对策提供了信息。

Abstract: Connected and Autonomous Vehicles (CAVs) are transforming modern
transportation by enabling cooperative applications such as vehicle platooning,
where multiple vehicles travel in close formation to improve efficiency and
safety. However, the heavy reliance on inter-vehicle communication makes
platoons highly susceptible to attacks, where even subtle manipulations can
escalate into severe physical consequences. While existing research has largely
focused on defending against attacks, far less attention has been given to
stealthy adversaries that aim to covertly manipulate platoon behavior. This
paper introduces a new perspective on the attack design problem by
demonstrating how attackers can guide platoons toward their own desired
trajectories while remaining undetected. We outline conditions under which such
attacks are feasible, analyze their dependence on communication topologies and
control protocols, and investigate the resources required by the attacker. By
characterizing the resources needed to launch stealthy attacks, we address
system vulnerabilities and informing the design of resilient countermeasures.
Our findings reveal critical weaknesses in current platoon architectures and
anomaly detection mechanisms and provide methods to develop more secure and
trustworthy CAV systems.

</details>


### [301] [A Deep State-Space Model Compression Method using Upper Bound on Output Error](https://arxiv.org/abs/2510.14542)
*Hiroki Sakamoto,Kazuhiro Sato*

Main category: eess.SY

TL;DR: 本文提出了一种用于深度状态空间模型（Deep SSMs）的压缩方法，该方法基于线性二次输出（LQO）系统，并具有可证明的输出误差保证。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法缺乏理论指导，本文旨在为基于模型降阶（MOR）的压缩提供理论基础，并提出一种新的优化方法。

Method: 1. 导出Deep SSMs之间输出误差的上限，并将其表示为层级LQO系统间的h^2-误差范数。2. 基于误差上限，构建一个以h^2-误差范数为目标的优化问题。3. 开发一种基于梯度的方法来解决该优化问题，以实现模型压缩。

Result: 在IMDb任务上，该压缩方法在不进行重新训练的情况下，成功减少了约80%的可训练参数，同时性能仅下降4-5%。

Conclusion: 本文提出的基于h^2-误差范数的优化和梯度下降的MOR方法，能够有效地压缩Deep SSMs，且在保持较高性能的同时显著减少模型参数。

Abstract: We study deep state-space models (Deep SSMs) that contain
linear-quadratic-output (LQO) systems as internal blocks and present a
compression method with a provable output error guarantee. We first derive an
upper bound on the output error between two Deep SSMs and show that the bound
can be expressed via the $h^2$-error norms between the layerwise LQO systems,
thereby providing a theoretical justification for existing model order
reduction (MOR)-based compression. Building on this bound, we formulate an
optimization problem in terms of the $h^2$-error norm and develop a
gradient-based MOR method. On the IMDb task from the Long Range Arena
benchmark, we demonstrate that our compression method achieves strong
performance. Moreover, unlike prior approaches, we reduce roughly 80% of
trainable parameters without retraining, with only a 4-5% performance drop.

</details>


### [302] [High-Resolution PTDF-Based Planning of Storage and Transmission Under High Renewables](https://arxiv.org/abs/2510.14696)
*Kevin Wu,Rabab Haider,Pascal Van Hentenryck*

Main category: eess.SY

TL;DR: 该论文提出了一种多时段、两阶段PTDF模型，用于优化输电升级和储能的选址与规模，以应对日益增长的电力需求和可再生能源整合。


<details>
  <summary>Details</summary>
Motivation: 为了满足不断增长的电力需求和整合可再生能源，需要优化电网升级和投资，而储能作为一种灵活的关键资产，能够缓解拥堵。

Method: 开发了一种多时段、两阶段PTDF模型，并采用基于信任域的、多割面的Benders分解方法，从每个代表性日的最优解进行初始化，以确保可扩展性。

Result: 所提出的方法应用于一个包含2000个节点的合成德克萨斯系统，在高可再生能源情景下，实现了低于1%的最终最优性差距，并规划了约180个节点的储能（占峰值可再生能源容量的32%）。

Conclusion: 所提出的基于PTDF的方法能够有效地处理大规模分布式储能，在大空间分辨率下展示了其可扩展性。

Abstract: Transmission Expansion Planning (TEP) optimizes power grid upgrades and
investments to ensure reliable, efficient, and cost-effective electricity
delivery while addressing grid constraints. To support growing demand and
renewable energy integration, energy storage is emerging as a pivotal asset
that provides temporal flexibility and alleviates congestion. This paper
develops a multiperiod, two-stage PTDF formulation that co-optimizes
transmission upgrades and storage siting/sizing. To ensure scalability, a
trust-region, multicut Benders scheme warm-started from per-representative-day
optima is proposed. Applied to a 2,000-bus synthetic Texas system under
high-renewable projections, the method attains final optimality gaps below 1%
and yields a plan with storage at about 180 nodes (32% of peak renewable
capacity). These results demonstrate that the proposed PTDF-based methodology
efficiently handles large distributed storage fleets, demonstrating scalability
at high spatial resolution

</details>


### [303] [A Human-Vector Susceptible--Infected--Susceptible Model for Analyzing and Controlling the Spread of Vector-Borne Diseases](https://arxiv.org/abs/2510.14787)
*Lorenzo Zino,Alessandro Casu,Alessandro Rizzo*

Main category: eess.SY

TL;DR: 一种考虑了人类和媒介生物之间交叉感染的病媒传播疾病传播模型，并通过引入媒介控制和保护措施激励来分析疾病传播。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于传播病媒传播疾病的流行病学模型。

Method: 扩展经典的易感-感染-易感模型，考虑了人类和媒介生物两个种群，以及它们之间的交叉感染。使用常微分方程组来表征疾病传播动力学，并利用单调系统理论来分析疾病的全局渐近行为。

Result: 确定了疾病快速根除（所有轨迹收敛到无病平衡点）或收敛到（唯一的）地方性平衡点的条件。此外，还评估了两种控制措施（媒介控制和保护措施激励）的影响，并确定了最优控制策略。

Conclusion: 该模型为理解和控制病媒传播疾病的传播提供了数学框架，并为制定有效的干预策略提供了依据。

Abstract: We propose an epidemic model for the spread of vector-borne diseases. The
model, which is built extending the classical susceptible-infected-susceptible
model, accounts for two populations -- humans and vectors -- and for
cross-contagion between the two species, whereby humans become infected upon
interaction with carrier vectors, and vectors become carriers after interaction
with infected humans. We formulate the model as a system of ordinary
differential equations and leverage monotone systems theory to rigorously
characterize the epidemic dynamics. Specifically, we characterize the global
asymptotic behavior of the disease, determining conditions for quick
eradication of the disease (i.e., for which all trajectories converge to a
disease-free equilibrium), or convergence to a (unique) endemic equilibrium.
Then, we incorporate two control actions: namely, vector control and incentives
to adopt protection measures. Using the derived mathematical tools, we assess
the impact of these two control actions and determine the optimal control
policy.

</details>


### [304] [Improved Voltage Regulation with Optimal Design of Decentralized Volt-VAr Control](https://arxiv.org/abs/2510.14834)
*Daniel Russell,Dakota Hamilton,Mads R. Almassalkhi,Hamid R. Ossareh*

Main category: eess.SY

TL;DR: 本文提出了一种新的分散式伏安控制（VVC）方法，用于管理并网逆变器的电压，解决了分布式能源整合带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 分布式能源的整合使得对自主、动态电压调节的需求日益增长。分散式VVC为电压管理提供了机会，但设计不当可能导致与电网反馈时的不稳定行为。

Method: 提出了一种利用历史数据和线性潮流方法对电网-VVC闭环动力学进行建模的方法，并以此为基础设计VVC斜率，通过最小化稳态电压偏差来满足非凸谱半径稳定性约束。

Result: 通过在真实馈线上的仿真，证明了与现有的凸约束相比，使用谱半径约束可以实现更有效的电压调节。

Conclusion: 与现有的凸约束相比，使用谱半径约束的VVC设计能够更有效地调节电压，为电网电压管理提供了一种新的、更优的方法。

Abstract: Integration of distributed energy resources has created a need for
autonomous, dynamic voltage regulation. Decentralized Volt-VAr Control (VVC) of
grid-connected inverters presents a unique opportunity for voltage management
but, if designed poorly, can lead to unstable behavior when in feedback with
the grid. We model the grid-VVC closed-loop dynamics with a linearized power
flow approach, leveraging historical data, which shows improvement over the
commonly used LinDistFlow model. This model is used to design VVC slopes by
minimizing steady-state voltage deviation from the nominal value, subject to a
non-convex spectral radius stability constraint, which has not been previously
implemented within this context. We compare this constraint to existing convex
restrictions and demonstrate, through simulations on a realistic feeder, that
using the spectral radius results in more effective voltage regulation.

</details>


### [305] [Dynamic-Key-Aware Co-Simulation Framework for Next Generation of SCADA Systems Encrypted by Quantum-Key-Distribution Techniques](https://arxiv.org/abs/2510.14838)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 本论文提出了一种结合量子密钥分发（QKD）的多层SCADA系统建模与优化框架，用于解决现代电力调度系统中的网络安全挑战。该框架将量子密钥生成、消耗、库存预测和控制延迟整合到一个统一模型中，实现了基于任务安全需求和实时资源约束的、可感知的SCADA控制链重新配置。通过构建双层Stackelberg博弈并将其转化为具有互补约束的数学规划（MPCC），解决了TSO和DSO之间密钥资源分配的冲突。采用LD-CP算法求解该问题，并通过一个端到端的协同仿真平台进行评估。实验结果表明，该方法提高了任务成功率（25%），降低了峰值频率偏差（70%），并提升了密钥利用率（83%）。


<details>
  <summary>Details</summary>
Motivation: 传统的QKD在电力行业的应用主要集中在建立安全的点对点通信隧道，而较少考虑密钥动态与控制调度的系统级耦合。本研究旨在解决这一问题，提出一个更全面的框架。

Method: 提出一个多层建模与优化框架，整合了量子密钥生成、消耗、库存预测和控制延迟。构建了一个双层Stackelberg博弈模型，并转化为MPCC问题，然后使用LD-CP算法进行求解。构建了一个包含OpenQKD-Sim、Q3P/IEC-104协议栈和Grafana的端到端协同仿真平台。

Result: 在IEEE 39和118节点系统上的实验结果显示：任务成功率提高了25%，峰值频率偏差降低了70%，密钥利用率提高到83%。

Conclusion: 该研究为未来电网运行中的量子安全控制系统奠定了基础。

Abstract: To address growing cybersecurity challenges in modern power dispatch systems,
this paper proposes a multi-layer modeling and optimization framework for SCADA
systems enhanced with quantum key distribution (QKD). While most existing
applications of QKD in the power sector focus on building secure point-to-point
communication tunnels, they rarely consider the system-level coupling between
key dynamics and control scheduling. In contrast, our approach integrates
quantum key generation, consumption, inventory prediction, and control latency
into a unified model, enabling key-aware reconfiguration of SCADA control
chains based on task security demands and real-time resource constraints. To
resolve conflicts in key resource allocation between transmission system
operators (TSOs) and distribution system operators (DSOs), we formulate a
bi-level Stackelberg game and transform it into a mathematical program with
complementarity constraints (MPCC). We further develop an efficient Level
Decomposition-Complementarity Pruning (LD-CP) algorithm to solve the problem.
To support reproducible evaluation, we build an end-to-end co-simulation
platform that integrates physical-layer disruptions via OpenQKD-Sim,
Q3P/IEC-104 protocol stack binding, and real-time control-chain monitoring
through Grafana. Experimental results on the IEEE 39- and 118-bus systems show
that our method increases task success rate by 25%, reduces peak frequency
deviation by 70%, and improves key utilization to 83%. This work lays the
foundation for future quantum-secure control systems in power grid operations.

</details>


### [306] [Through-the-Earth Magnetic Induction Communication and Networking: A Comprehensive Survey](https://arxiv.org/abs/2510.14854)
*Honglei Ma,Erwu Liu,Wei Ni,Zhijun Fang,Rui Wang,Yongbin Gao,Dusit Niyato,Ekram Hossain*

Main category: eess.SY

TL;DR: 本文全面 survey 了穿地磁感应（TTE-MIC）通信，涵盖了其应用、信道建模（包括慢衰落和快衰落）、点对点设计、中继技术、网络框架以及新兴技术，并提出了一个支持 TCP/IP 和 Linux 的 MIC 框架，以加速 MIC 在 SAGUI 网络中的发展。


<details>
  <summary>Details</summary>
Motivation: 地下通信网络对具有出色穿透能力的磁感应（MI）通信（MIC）的需求日益增长，特别是将其集成到下一代移动通信系统（SAGUI）的需求，以及应对 MI 快衰落等新兴挑战。

Method: 对 TTE-MIC 的应用、信道建模（包括慢衰落和快衰落）、点对点 MIC 设计、中继技术、网络框架和新兴技术进行了全面的 survey。通过将 MI 信道功率增益分解为四个物理参数，并提出一种新颖的几何模型来分析 MI 快衰落。最后，提出了一个支持 TCP/IP 和 Linux 的 MIC 框架。

Result: 对 MI 快衰落进行了新颖的几何模型分析，并提出了一个支持 TCP/IP 和 Linux 的 MIC 框架，该框架能够支持现有和新兴的 MIC 解决方案的全面实现，并支持研究人员利用 Linux 资源和深度学习平台。

Conclusion: TTE-MIC 具有巨大的应用潜力，但仍面临诸多挑战。通过提出新颖的信道模型和 MIC 框架，本文为加速 MIC 在 SAGUI 网络中的研究和发展铺平了道路，并指出了未来研究方向。

Abstract: Magnetic induction (MI) communication (MIC) has emerged as a promising
candidate for underground communication networks due to its excellent
penetration capabilities. Integration with Space-Air-Ground-Underground (SAGUI)
networks in next-generation mobile communication systems requires a
well-defined network architecture. A recent discovery in MIC research, MI fast
fading, remains in its early stages and presents unique challenges. This paper
provides a comprehensive survey on through-the-earth (TTE) MIC, covering MI
applications, channel modeling, point-to-point MIC design, relay techniques,
network frameworks, and emerging technologies. We compare various MIC
applications to highlight TTE-specific challenges and review the principles of
channel modeling, addressing both MI slow fading and MI fast fading, along with
its potential impact on existing MIC theories. We conduct a fine-grained
decomposition of MI channel power gain into four distinct physical parameters,
and propose a novel geometric model to analyze MI fast fading. We also
summarize MI relay techniques, examine crosstalk effects in relay and
high-density networks, and explore key research tasks within the OSI framework
for a holistic MI network protocol in SAGUI. To bridge the gaps identified, we
propose a MIC framework that supports TCP/IP and Linux, enabling full
implementation of existing and emerging MIC solutions. This framework empowers
researchers to leverage Linux resources and deep learning platforms for
accelerated development of MIC in SAGUI networks. Remaining research
challenges, open issues, and promising novel techniques are further identified
to advance MIC research.

</details>


### [307] [Further Results on Safety-Critical Stabilization of Force-Controlled Nonholonomic Mobile Robots](https://arxiv.org/abs/2510.14931)
*Bo Wang,Tianyu Han,Guangwei Wang*

Main category: eess.SY

TL;DR: 本研究提出了一种基于gamma m-二次规划（gamma m-QP）框架的连续、时不变控制律，用于解决具有安全关键约束的力控非完整移动机器人的镇定问题。该方法统一了控制李亚普诺夫函数（CLFs）和控制障碍函数（CBFs），以确保闭环系统的稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决具有安全关键约束的力控非完整移动机器人的镇定问题。

Method: 提出了一种基于gamma m-二次规划（gamma m-QP）框架的连续、时不变控制律。该方法结合了控制李亚普诺夫函数（CLFs）和控制障碍函数（CBFs），并利用了车辆动力学的级联结构，通过积分器反推步法来处理。首先，在极坐标下为闭环非完整移动机器人系统构造了一个全局、时不变、严格的李亚普诺夫函数作为CLF。然后，利用车辆动力学的级联结构，通过积分器反推步法开发了CBF。

Result: 保证了闭环系统的渐近稳定性和安全性。通过仿真和实验验证了该方法的有效性和性能。

Conclusion: 所提出的基于gamma m-QP的控制方法能够有效地保证力控非完整移动机器人的稳定性和安全性，并通过仿真和实验得到了验证。

Abstract: In this paper, we address the stabilization problem for force-controlled
nonholonomic mobile robots under safety-critical constraints. We propose a
continuous, time-invariant control law based on the gamma m-quadratic
programming (gamma m-QP) framework, which unifies control Lyapunov functions
(CLFs) and control barrier functions (CBFs) to enforce both stability and
safety in the closed-loop system. For the first time, we construct a global,
time-invariant, strict Lyapunov function for the closed-loop nonholonomic
mobile robot system with a nominal stabilization controller in polar
coordinates; this strict Lyapunov function then serves as the CLF in the QP
design. Next, by exploiting the inherent cascaded structure of the vehicle
dynamics, we develop a CBF for the mobile robot via an integrator backstepping
procedure. Our main results guarantee both asymptotic stability and safety for
the closed-loop system. Both the simulation and experimental results are
presented to illustrate the effectiveness and performance of our approach.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [308] [Efficiently Executing High-throughput Lightweight LLM Inference Applications on Heterogeneous Opportunistic GPU Clusters with Pervasive Context Management](https://arxiv.org/abs/2510.14024)
*Thanh Son Phung,Douglas Thain*

Main category: cs.DC

TL;DR: 通过“分离式上下文管理”，缩短生成式AI工作负载的等待时间和LLM启动成本。


<details>
  <summary>Details</summary>
Motivation: 当前高性能计算（HPC）集群的设计无法有效支持集成轻量级LLM和传统高通量应用的生成式AI工作负载，导致等待时间长或LLM启动成本高。

Method: 提出“分离式上下文管理”（Pervasive Context Management）技术，将LLM的初始化上下文与其推理分离，并将上下文保留在GPU上，直到不再需要。

Result: 将一个事实核查应用程序改造后，使用相同数量的GPU，执行时间缩短了72.1%（从3小时缩短到48分钟）。通过在32.8%的GPU上进行扩展，进一步将执行时间缩短至13分钟。

Conclusion: “分离式上下文管理”技术能够有效解决生成式AI工作负载在HPC集群中面临的挑战，显著提高效率。

Abstract: The rise of Generative AI introduces a new class of HPC workloads that
integrates lightweight LLMs with traditional high-throughput applications to
accelerate scientific discovery. The current design of HPC clusters is
inadequate to support this new class however, either incurring long wait times
on static batch queues or repeatedly paying expensive LLM startup costs upon
resource preemption. To circumvent both the long queues and high startup costs,
we propose to "decouple" the LLM initialization context from the actual LLM
inferences, and retain the context in GPUs until it is no longer needed, a
technique we term "Pervasive Context Management". We transform a fact
verification application to enable this technique, allowing it to reduce its
execution time by 72.1% (from 3 hours to 48 minutes) using the same amount of
GPUs, and scale opportunistically on 32.8% of all GPUs in the cluster and
further reduce the execution time to 13 minutes.

</details>


### [309] [Anonymized Network Sensing using C++26 std::execution on GPUs](https://arxiv.org/abs/2510.14050)
*Michael Mandulak,Sayan Ghosh,S M Ferdous,Mahantesh Halappanavar,George Slota*

Main category: cs.DC

TL;DR: 该论文提出使用C++26 Senders模型来解决大规模网络流量分析中GPU编程的挑战，并通过一个实际案例证明了其效率。


<details>
  <summary>Details</summary>
Motivation: 随着网络数据量的爆炸式增长，大规模网络传感和流量分析变得至关重要。然而，基于GPU的并行处理方法在主机-设备内存管理和复杂任务移植方面存在挑战。因此，需要一种更高效、更易于使用的编程模型来充分利用GPU资源。

Method: 本文采用C++26 Senders模型，该模型支持异步数据操作的链式调用，并能将任务高效地推送到各种设备执行上下文，包括GPU。作者将此模型应用于“匿名网络传感图挑战”的开发，并在8块NVIDIA A100 GPU上进行了性能评估。

Result: 与传统的串行GraphBLAS基线相比，该实现实现了高达55倍的性能提升，证明了C++26 Senders模型的有效性和生产力，并且这种采用通用编程模型的方式并未影响关键路径的性能。

Conclusion: C++26 Senders模型为在密集GPU系统上进行网络分析提供了一种强大而高效的解决方案，它简化了GPU编程的复杂性，同时保持了高性能，甚至提升了性能，使得开发多GPU应用程序更加便捷。

Abstract: Large-scale network sensing plays a vital role in network traffic analysis
and characterization. As network packet data grows increasingly large, parallel
methods have become mainstream for network analytics. While effective,
GPU-based implementations still face start-up challenges in host-device memory
management and porting complex workloads on devices, among others. To mitigate
these challenges, composable frameworks have emerged using modern C++
programming language, for efficiently deploying analytics tasks on GPUs.
Specifically, the recent C++26 Senders model of asynchronous data operation
chaining provides a simple interface for bulk pushing tasks to varied device
execution contexts.
  Considering the prominence of contemporary dense-GPU platforms and
vendor-leveraged software libraries, such a programming model consider GPUs as
first-class execution resources (compared to traditional host-centric
programming models), allowing convenient development of multi-GPU application
workloads via expressive and standardized asynchronous semantics. In this
paper, we discuss practical aspects of developing the Anonymized Network
Sensing Graph Challenge on dense-GPU systems using the recently proposed C++26
Senders model. Adopting a generic and productive programming model does not
necessarily impact the critical-path performance (as compared to low-level
proprietary vendor-based programming models): our commodity library-based
implementation achieves up to 55x performance improvements on 8x NVIDIA A100
GPUs as compared to the reference serial GraphBLAS baseline.

</details>


### [310] [Cortex: Workflow-Aware Resource Pooling and Scheduling for Agentic Serving](https://arxiv.org/abs/2510.14126)
*Nikos Pagonas,Yeounoh Chung,Kostis Kaffes,Arvind Krishnamurthy*

Main category: cs.DC

TL;DR: Cortex是一个为代理工作流设计的原型服务平台，通过阶段隔离来优化资源分配，提高性能和可预测性。


<details>
  <summary>Details</summary>
Motivation: 介绍一种名为Cortex的原型服务平台，该平台专为代理工作流设计，其核心原则是阶段隔离，即为代理工作流的每个独立阶段分配专用的资源池。

Method: Cortex通过为代理工作流的每个独立阶段配置专用的资源池来实现阶段隔离，从而减少阶段间的计算和内存干扰，优化KV缓存利用率、提高吞吐量并增强性能可预测性。

Result: Cortex通过阶段隔离策略，实现了更好的KV缓存利用率、更高的吞吐量和更可预测的性能。

Conclusion: Cortex通过定制资源分配和调度，为代理工作流的每个阶段奠定了基础，支持更高级别的代理原生服务范式，如可塑性资源管理、工作流分支的推测执行以及共享的多层代理状态缓存。

Abstract: We introduce Cortex, a prototype workflow-aware serving platform designed for
agentic workloads. The core principle of Cortex is stage isolation: it
provisions dedicated resource pools for each distinct stage of an agentic
workflow. This simple yet powerful strategy mitigates inter-stage interference
in compute and memory, leading to better KV cache utilization, higher
throughput, and more predictable performance. By customizing resource
allocation and scheduling within each distinct stage of agentic workflows,
Cortex lays the groundwork for more advanced, agent-native serving paradigms,
including malleable resource management, speculative execution of workflow
branches, and a shared, multi-tiered cache for "agentic state."

</details>


### [311] [Distributed-Memory Parallel Algorithms for Fixed-Radius Near Neighbor Graph Construction](https://arxiv.org/abs/2510.14147)
*Gabriel Raulet,Dmitriy Morozov,Aydin Buluc,Katherine Yelick*

Main category: cs.DC

TL;DR: 该论文提出了一种使用 C++ 编写的、可扩展的、感知稀疏性的分布式内存算法，用于在通用度量空间中计算固定半径邻域图。


<details>
  <summary>Details</summary>
Motivation: 现有的计算邻域图的方法在处理大规模科学数据集、精确解和非欧几里得度量方面存在不足。该研究旨在为这些问题提供可扩展的解决方案。

Method: 该研究提出了一种基于 C++ 的分布式内存算法，该算法利用 C++ 的内存管理功能，使用 C++ 覆盖树来计算固定半径邻域图。该算法结合了共享内存的 C++ 覆盖树构建算法和两种分布式内存算法：一种简单的点分区策略和一种空间分区策略。

Result: 该算法在各种真实和合成数据集上都表现出良好的并行扩展性，包括传统和非传统的度量。在具有一百万个数据点的高维数据集上，与最先进的方法相比，在具有 70 个邻居的图上实现了高达 678.34 倍的速度提升（使用 1024 个核心），在具有 500 个邻居的图上实现了高达 1590.99 倍的速度提升（使用 4096 个核心）。

Conclusion: 所提出的可扩展的感知稀疏性的分布式内存算法能够有效地计算通用度量空间中的固定半径邻域图，在处理大规模数据集和非欧几里得度量方面优于现有方法。

Abstract: Computing fixed-radius near-neighbor graphs is an important first step for
many data analysis algorithms. Near-neighbor graphs connect points that are
close under some metric, endowing point clouds with a combinatorial structure.
As computing power and data acquisition methods advance, diverse sources of
large scientific datasets would greatly benefit from scalable solutions to this
common subroutine for downstream analysis. Prior work on parallel nearest
neighbors has made great progress in problems like k-nearest and approximate
nearest neighbor search problems, with particular attention on Euclidean
spaces. Yet many applications need exact solutions and non-Euclidean metrics.
This paper presents a scalable sparsity-aware distributed memory algorithm
using cover trees to compute near-neighbor graphs in general metric spaces. We
provide a shared-memory algorithm for cover tree construction and demonstrate
its competitiveness with state-of-the-art fixed-radius search data structures.
We then introduce two distributed-memory algorithms for the near-neighbor graph
problem, a simple point-partitioning strategy and a spatial-partitioning
strategy, which leverage the cover tree algorithm on each node. Our algorithms
exhibit parallel scaling across a variety of real and synthetic datasets for
both traditional and non-traditional metrics. On real world high dimensional
datasets with one million points, we achieve speedups up to 678.34x over the
state-of-the-art using 1024 cores for graphs with 70 neighbors per vertex (on
average), and up to 1590.99x using 4096 cores for graphs with 500 neighbors per
vertex (on average).

</details>


### [312] [Privacy-Preserving and Incentive-Driven Relay-Based Framework for Cross-Domain Blockchain Interoperability](https://arxiv.org/abs/2510.14151)
*Saeed Moradi,Koosha Esmaeilzadeh Khorasani,Sara Rouhani*

Main category: cs.DC

TL;DR: 本框架提供了一种区块链无关的方法来实现许可链和无许可链之间的互操作性，并提高了交易的匿名性。


<details>
  <summary>Details</summary>
Motivation: 公有链的互操作性已取得显著进展，但由于访问控制、架构和安全需求等方面的差异，打通许可链和无许可链之间的壁垒面临独特挑战。

Method: 利用密码学技术，本框架确保了安全的跨链数据交换。其轻量级的架构设计简化了实现和维护，并集成了Clover和Dandelion++协议以增强交易的匿名性。

Result: 性能评估表明，该框架在异构区块链生态系统中，通过测量转发时间、吞吐量、可用性及其共谋影响，实现了安全高效的互操作性。

Conclusion: 本框架为实现许可链和无许可链之间的互操作性提供了一种有效且安全的解决方案。

Abstract: Interoperability is essential for transforming blockchains from isolated
networks into collaborative ecosystems, unlocking their full potential. While
significant progress has been made in public blockchain interoperability,
bridging permissioned and permissionless blockchains poses unique challenges
due to differences in access control, architectures, and security requirements.
This paper introduces a blockchain-agnostic framework to enable
interoperability between permissioned and permissionless networks. Leveraging
cryptographic techniques, the framework ensures secure data exchanges. Its
lightweight architectural design simplifies implementation and maintenance,
while the integration of Clover and Dandelion++ protocols enhances transaction
anonymity. Performance evaluations demonstrate the framework's effectiveness in
achieving secure and efficient interoperability by measuring the forwarding
time, the throughput, the availability, and their collusion impact of the
system across heterogeneous blockchain ecosystems.

</details>


### [313] [Balls and Bins and the Infinite Process with Random Deletions](https://arxiv.org/abs/2510.14798)
*Petra Berenbrink,Tom Friedetzky,Peter Kling,Lars Nagel*

Main category: cs.DC

TL;DR: 该论文研究了无限个球和垃圾箱模型，允许删除操作。在每个时间步，以概率β(t)使用贪心策略（将球放入两个随机选择的垃圾箱中较少被使用的那个）分配新球，或者以概率1-β(t)从非空垃圾箱中随机删除一个球。论文关注于界定当前最大负载与平均负载之差（差异度）以及当前最大负载与迄今为止观察到的最高平均负载之差（过载度）。


<details>
  <summary>Details</summary>
Motivation: 研究带有删除操作的无限球和垃圾箱模型，以界定和分析负载差异和过载度。

Method: 使用分层归纳法、势能分析和概率耦合技术来分析模型。

Result: 证明了在任意给定时间t，超出平均负载的球的总数是O(n)，差异度是O(log(n))，并给出了差异度的匹配下界。证明了过载度是loglog(n)+O(1)。对于“好的”插入概率序列，差异度被界定为loglog(n)+O(1)。

Conclusion: 该研究为带有删除操作的球和垃圾箱模型提供了差异度和过载度的界限，并提出了新的分析工具。

Abstract: We consider an infinite balls-into-bins process with deletions where in each
discrete step $t$ a coin is tossed as to whether, with probability $\beta(t)
\in (0,1)$, a new ball is allocated using the Greedy[2] strategy (which places
the ball in the lower loaded of two bins sampled uniformly at random) or, with
remaining probability $1-\beta(t)$, a ball is deleted from a non-empty bin
chosen uniformly at random. Let $n$ be the number of bins and $m(t)$ the total
load at time $t$. We are interested in bounding the discrepancy $x_{\max}(t) -
m(t)/n$ (current maximum load relative to current average) and the overload
$x_{\max}(t) - m_{\max}(t)/n$ (current maximum load relative to highest average
observed so far).
  We prove that at an arbitrarily chosen time $t$ the total number of balls
above the average is $O(n)$ and that the discrepancy is $ O(\log(n))$. For the
discrepancy, we provide a matching lower bound. Furthermore we prove that at an
arbitrarily chosen time $t$ the overload is $\log\log(n)+O(1)$. For "good"
insertion probability sequences (in which the average load of time intervals
with polynomial length increases in expectation) we show that even the
discrepancy is bounded by $\log\log(n)+O(1)$.
  One of our main analytical tools is a layered induction, as per [ABKU99].
Since our model allows for rather more general scenarios than what was
previously considered, the formal analysis requires some extra ingredients as
well, in particular a detailed potential analysis. Furthermore, we simplify the
setup by applying probabilistic couplings to obtain certain "recovery"
properties, which eliminate much of the need for intricate and careful
conditioning elsewhere in the analysis.

</details>


### [314] [Proof-Carrying Fair Ordering: Asymmetric Verification for BFT via Incremental Graphs](https://arxiv.org/abs/2510.14186)
*Pengkun Ren,Hai Dong,Nasrin Sohrabi,Zahir Tari,Pengcheng Zhang*

Main category: cs.DC

TL;DR: AUTIG是一种高性能、可插拔的顺序公平服务，通过非对称架构打破了拜占庭容错共识协议中对称且冗余的验证范式，实现了比现有协议更高的吞吐量和更低的延迟，同时保持了gamma-batch-order-fairness。


<details>
  <summary>Details</summary>
Motivation: 现有的拜占庭容错共识协议虽然能容忍恶意节点，但其对交易排序的无限制能力会导致诸如抢先交易和三明治攻击等价值提取攻击，这对区块链系统构成了严重威胁。而现有的顺序公平协议（如Themis）虽然能限制领导者的排序行为以遏制此类攻击，但要求所有副本重新执行领导者昂贵的排序计算进行验证，这种对称且冗余的模式效率低下。

Method: AUTIG提出了一种非对称架构，其核心思想是验证排序的公平性不一定需要重新计算，而是可以通过对排序图属性的简洁、可验证断言进行状态无关的审计来完成。具体来说：1. 领导者维护一个持久的未确认交易增量图（UTIG），将图的构建成本分摊到多个轮次中，并为每个提议发出包含公平性证明的结构化信息。2. 追随者无需维护历史状态，即可验证该公平性证明。3. AUTIG引入了三项关键创新：(i) 基于阈值交叉事件和状态变化的增量图维护；(ii) 一个分离式流水线，将领导者端的数据收集/更新/提取与追随者端的状态无关的验证重叠进行；(iii) 一种证明设计，涵盖了已确认交易前缀中的所有内部节点对，并增加了一个边界完整性检查，以排除隐藏的外部依赖。

Result: 实验结果表明，与对称图基线协议相比，AUTIG在部分同步条件下实现了更高的吞吐量和更低的端到端延迟，同时保持了gamma-batch-order-fairness。

Conclusion: AUTIG通过其创新的非对称架构和高效的验证机制，成功解决了现有顺序公平协议的性能瓶颈，为区块链提供了一种更优的顺序公平解决方案。

Abstract: Byzantine Fault-Tolerant (BFT) consensus protocols ensure agreement on
transaction ordering despite malicious actors, but unconstrained ordering power
enables sophisticated value extraction attacks like front running and sandwich
attacks - a critical threat to blockchain systems. Order-fair consensus curbs
adversarial value extraction by constraining how leaders may order
transactions. While state-of-the-art protocols such as Themis attain strong
guarantees through graph-based ordering, they ask every replica to re-run the
leader's expensive ordering computation for validation - an inherently
symmetric and redundant paradigm. We present AUTIG, a high-performance,
pluggable order-fairness service that breaks this symmetry. Our key insight is
that verifying a fair order does not require re-computing it. Instead,
verification can be reduced to a stateless audit of succinct, verifiable
assertions about the ordering graph's properties. AUTIG realizes this via an
asymmetric architecture: the leader maintains a persistent
Unconfirmed-Transaction Incremental Graph (UTIG) to amortize graph construction
across rounds and emits a structured proof of fairness with each proposal;
followers validate the proof without maintaining historical state. AUTIG
introduces three critical innovations: (i) incremental graph maintenance driven
by threshold-crossing events and state changes; (ii) a decoupled pipeline that
overlaps leader-side collection/update/extraction with follower-side stateless
verification; and (iii) a proof design covering all internal pairs in the
finalized prefix plus a frontier completeness check to rule out hidden external
dependencies. We implement AUTIG and evaluate it against symmetric graph-based
baselines under partial synchrony. Experiments show higher throughput and lower
end-to-end latency while preserving gamma-batch-order-fairness.

</details>


### [315] [Deadlock-free routing for Full-mesh networks without using Virtual Channels](https://arxiv.org/abs/2510.14730)
*Alejandro Cano,Cristóbal Camarero,Carmen Martínez,Ramón Beivide*

Main category: cs.DC

TL;DR: TERA是一种新型的无虚拟通道(VC)路由算法，通过嵌入式物理子网实现无死锁的非最小路径，解决了现有路由算法的性能和开销问题。


<details>
  <summary>Details</summary>
Motivation: 高基数、低直径网络（如HyperX和Dragonfly）依赖VC来避免自适应路由中的死锁，但VC会增加交换机的面积、功耗和设计复杂性，限制了可扩展性。而无VC的路由（如链接排序）虽然实现简单，但在对抗性流量下性能会下降。因此，需要一种既能避免死锁又能保持高性能的无VC路由算法。

Method: TERA（Topology-Embedded Routing Algorithm）是一种新颖的路由算法，它利用嵌入的物理子网提供无死锁的非最小路径，并且不需要使用虚拟通道。

Result: 在全网状网络中，TERA在对抗性流量下的性能比链接排序算法提高了80%，在应用程序内核中提高了100%。与基于VC的方法相比，TERA将缓冲区需求减少了50%，同时保持了可比的延迟和吞吐量。在2D-HyperX评估中，TERA的性能比使用相同数量VC的最先进算法提高了32%。

Conclusion: TERA通过嵌入物理子网实现无VC的死锁自由路由，在性能和资源开销方面优于现有方法，并有望扩展到更复杂的网络拓扑。

Abstract: High-radix, low-diameter networks like HyperX and Dragonfly use a Full-mesh
core, and rely on multiple virtual channels (VCs) to avoid packet deadlocks in
adaptive routing. However, VCs introduce significant overhead in the switch in
terms of area, power, and design complexity, limiting the switch scalability.
This paper starts by revisiting VC-less routing through link ordering schemes
in Full-mesh networks, which offer implementation simplicity but suffer from
performance degradation under adversarial traffic. Thus, to overcome these
challenges, we propose TERA (Topology-Embedded Routing Algorithm), a novel
routing algorithm which employs an embedded physical subnetwork to provide
deadlock-free non-minimal paths without using VCs.
  In a Full-mesh network, TERA outperforms link ordering routing algorithms by
80% when dealing with adversarial traffic, and up to 100% in application
kernels. Furthermore, compared to other VC-based approaches, it reduces buffer
requirements by 50%, while maintaining comparable latency and throughput.
Lastly, early results from a 2D-HyperX evaluation show that TERA outperforms
state-of-the-art algorithms that use the same number of VCs, achieving
performance improvements of up to 32%.

</details>


### [316] [FairBatching: Fairness-Aware Batch Formation for LLM Inference](https://arxiv.org/abs/2510.14392)
*Hongtao Lyu,Boyue Liu,Mingyu Wu,Haibo Chen*

Main category: cs.DC

TL;DR: FairBatching 通过动态调整计算预算和公平的批次形成算法，解决了 LLM 推理中预填和解码任务之间的资源分配不公问题，从而降低了 TTFT 延迟并提高了 GPU 利用率。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 推理调度器（如 Sarathi）虽然能防止解码停滞，但存在计算不公平的问题，过度优先解码任务，导致 GPU 利用率低下和预填排队延迟增加，整体降低了服务质量。

Method: 提出了一种名为 FairBatching 的新颖 LLM 推理调度器，通过自适应批次容量确定机制和公平的动态批次形成算法，在预填和解码任务之间实现公平的资源分配。该方法能够动态调整计算预算，提高 GPU 利用率而不违反 SLO，并允许将部分计算资源从突发的解码任务中回收，以服务于突发的预填请求。

Result: FairBatching 将 TTFT 尾部延迟降低了高达 2.29 倍，同时稳定地维持了 TPOT SLO，单节点容量提高了 20.0%，集群级容量提高了 54.3%。

Conclusion: FairBatching 通过解决 LLM 推理调度中的公平性问题，显著提高了系统性能和资源利用率。

Abstract: Large language model (LLM) inference systems face a fundamental tension
between minimizing Time-to-First-Token (TTFT) latency for new requests and
maintaining a high, steady token generation rate (low Time-Per-Output-Token, or
TPOT) for ongoing requests. Existing stall-free batching schedulers proposed by
Sarathi, while effective at preventing decode stalls, introduce significant
computational unfairness. They prioritize decode tasks excessively,
simultaneously leading to underutilized decode slack and unnecessary prefill
queuing delays, which collectively degrade the system's overall quality of
service (QoS).
  This work identifies the root cause of this unfairness: the non-monotonic
nature of Time-Between-Tokens (TBT) as a scheduling metric and the rigid
decode-prioritizing policy that fails to adapt to dynamic workload bursts. We
therefore propose FairBatching, a novel LLM inference scheduler that enforces
fair resource allocation between prefill and decode tasks. It features an
adaptive batch capacity determination mechanism, which dynamically adjusts the
computational budget to improve the GPU utilization without triggering SLO
violations. Its fair and dynamic batch formation algorithm breaks away from the
decode-prioritizing paradigm, allowing computation resources to be reclaimed
from bursting decode tasks to serve prefill surges, achieving global fairness.
Furthermore, FairBatching provides a novel load estimation method, enabling
more effective coordination with upper-level schedulers. Implemented and
evaluated on realistic traces, FairBatching significantly reduces TTFT tail
latency by up to 2.29x while robustly maintaining TPOT SLOs, achieving overall
20.0% improvement in single-node capacity and 54.3% improvement in
cluster-level capacity.

</details>


### [317] [ScalePool: Hybrid XLink-CXL Fabric for Composable Resource Disaggregation in Unified Scale-up Domains](https://arxiv.org/abs/2510.14580)
*Hyein Woo,Miryeong Kwon,Jiseon Kim,Eunjee Na,Hanjin Choi,Seonghyeon Jang,Myoungsoo Jung*

Main category: cs.DC

TL;DR: ScalePool通过结合XLink和CXL，利用统一的硬件互连来连接大量加速器，实现了LLM训练的加速和内存密集型工作负载的低延迟。


<details>
  <summary>Details</summary>
Motivation: 通过统一的硬件互连（XLink和CXL）取代传统长距离网络，解决大规模加速器互连的互操作性和可扩展性问题，并实现内存池化。

Method: ScalePool集成XLink和CXL，形成混合 fabric。XLink用于低延迟的集群内通信，CXL用于可扩展的集群间内存共享。它还引入了显式的内存分层：tier-1结合了本地内存、CXL和XLink，tier-2使用基于CXL的 fabric连接的内存节点。

Result: ScalePool将LLM训练速度平均提高了1.22倍（最高1.84倍），并将tier-2内存分离策略将内存密集型工作负载的延迟降低了高达4.5倍。

Conclusion: ScalePool通过创新的架构和内存分层，有效地解决了大规模加速器互连的挑战，显著提高了LLM训练性能，并降低了内存密集型工作负载的延迟。

Abstract: This paper proposes ScalePool, a novel cluster architecture designed to
interconnect numerous accelerators using unified hardware interconnects rather
than traditional long-distance networking. ScalePool integrates
Accelerator-Centric Links (XLink) and Compute Express Link (CXL) into a unified
XLink-CXL hybrid fabric. Specifically, ScalePool employs XLink for
intra-cluster, low-latency accelerator communication, while using hierarchical
CXL-based switching fabrics for scalable and coherent inter-cluster memory
sharing. By abstracting interfaces through CXL, ScalePool structurally resolves
interoperability constraints, enabling heterogeneous cluster operation and
composable resource disaggregation. In addition, ScalePool introduces explicit
memory tiering: the latency-critical tier-1 combines accelerator-local memory
with coherence-centric CXL and XLink, whereas the highcapacity tier-2 employs
dedicated memory nodes interconnected by a CXL-based fabric, achieving scalable
and efficient memory pooling. Evaluation results show that ScalePool
accelerates LLM training by 1.22x on average and up to 1.84x compared to
conventional RDMA-based environments. Furthermore, the proposed tier-2 memory
disaggregation strategy reduces latency by up to 4.5x for memory-intensive
workloads.

</details>


### [318] [JASDA: Introducing Job-Aware Scheduling in Scheduler-Driven Job Atomization](https://arxiv.org/abs/2510.14599)
*Michal Konopa,Jan Fesl,Ladislav Ber ánek*

Main category: cs.DC

TL;DR: JASDA是一种新的分布式GPU调度范式，通过作业与调度器之间的双向迭代交互，实现了可扩展、公平和响应迅速的资源管理。


<details>
  <summary>Details</summary>
Motivation: 传统中心化GPU调度难以应对日益复杂的GPU工作负载和时间变化性，因此需要新的调度方法。

Method: JASDA扩展了SJA概念，提出了一种完全去中心化的调度模式。在该模式下，作业会根据调度器公布的执行窗口生成并评估可行的子作业，而调度器则通过策略驱动的清算过程来平衡利用率、公平性和响应时间。这种双向、迭代的交互将反馈、校准和概率性安全机制直接嵌入调度循环，实现了自适应和透明的决策。

Result: JASDA通过结合拍卖理论、在线优化以及GPU工作负载的时间粒度，为资源管理提供了一个可扩展的基础，能够满足人工智能和农业4.0等领域的需求。

Conclusion: JASDA通过引入一种新颖的去中心化调度范式，解决了传统GPU调度方法的局限性，为现代MIG支持环境下的资源管理提供了一个有前途的解决方案。

Abstract: The increasing complexity and temporal variability of workloads on
MIG-enabled GPUs challenge the scalability of traditional centralized
scheduling. Building upon the SJA concept, this paper introduces JASDA-a novel
paradigm that extends SJA from a largely centralized scheduling model toward a
fully decentralized negotiation process. In JASDA, jobs actively generate and
score feasible subjobs in response to scheduler-announced execution windows,
while the scheduler performs policy-driven clearing that balances utilization,
fairness, and temporal responsiveness. This bidirectional, iterative
interaction embeds feedback, calibration, and probabilistic safety directly
into the scheduling loop, enabling adaptive and transparent decision-making. By
coupling principles from auction theory and online optimization with the
temporal granularity of GPU workloads, JASDA provides a scalable foundation for
market-aware and fairness-driven resource management-bridging theoretical
scheduling models with practical deployment in modern MIG-enabled environments
relevant to Artificial Intelligence and Agriculture 4.0.

</details>


### [319] [MPI-over-CXL: Enhancing Communication Efficiency in Distributed HPC Systems](https://arxiv.org/abs/2510.14622)
*Miryeong Kwon,Donghyun Gouk,Hyein Woo,Junhee Kim,Jinwoo Baek,Kyungkuk Nam,Sangyoon Ji,Jiseon Kim,Hanyeoreum Bae,Junhyeok Jang,Hyunwoo You,Junseok Moon,Myoungsoo Jung*

Main category: cs.DC

TL;DR: MPI-over-CXL利用CXL的缓存一致性内存，通过直接共享内存访问取代显式内存复制，以减少MPI通信开销。


<details>
  <summary>Details</summary>
Motivation: MPI实现中的显式内存复制操作会产生数据移动和缓冲区管理的开销，影响高性能计算（HPC）工作负载。

Method: MPI-over-CXL将共享内存区域直接映射到MPI进程的虚拟地址空间，实现基于指针的通信，消除冗余复制。通过定制CXL 3.2控制器、基于FPGA的多主机仿真和专用软件栈进行实现和评估。

Result: 与传统MPI系统相比，MPI-over-CXL在基准测试中显示出显著的性能提升，包括通信延迟降低和内存带宽使用减少。

Conclusion: MPI-over-CXL通过利用CXL实现高效的共享内存通信，有潜力提高大规模HPC环境的效率和可扩展性。

Abstract: MPI implementations commonly rely on explicit memory-copy operations,
incurring overhead from redundant data movement and buffer management. This
overhead notably impacts HPC workloads involving intensive inter-processor
communication. In response, we introduce MPI-over-CXL, a novel MPI
communication paradigm leveraging CXL, which provides cache-coherent shared
memory across multiple hosts. MPI-over-CXL replaces traditional data-copy
methods with direct shared memory access, significantly reducing communication
latency and memory bandwidth usage. By mapping shared memory regions directly
into the virtual address spaces of MPI processes, our design enables efficient
pointer-based communication, eliminating redundant copying operations. To
validate this approach, we implement a comprehensive hardware and software
environment, including a custom CXL 3.2 controller, FPGA-based multi-host
emulation, and dedicated software stack. Our evaluations using representative
benchmarks demonstrate substantial performance improvements over conventional
MPI systems, underscoring MPI-over-CXL's potential to enhance efficiency and
scalability in large-scale HPC environments.

</details>


### [320] [xLLM Technical Report](https://arxiv.org/abs/2510.14686)
*Tongxuan Liu,Tao Peng,Peijun Yang,Xiaoyang Zhao,Xiusheng Lu,Weizhe Huang,Zirui Liu,Xiaoyu Chen,Zhiwei Liang,Jun Xiong,Donghe Jin,Minchao Zhang,Jinrong Guo,Yingxu Deng,Xu Zhang,Xianzhe Dong,Siqi Wang,Siyu Wu,Yu Wu,Zihan Tang,Yuting Zeng,Yanshu Wang,Jinguang Liu,Meng Kang,Menxin Li,Yunlong Wang,Yiming Liu,Xiaolong Ma,Yifan Wang,Yichen Zhang,Jinrun Yin,Keyang Zheng,Jiawei Yin,Jun Zhang,Ziyue Wang,Xiaobo Lin,Liangyu Liu,Liwei Lan,Yang Liu,Chunhua Peng,Han Liu,Songcheng Ren,Xuezhu Wang,Yunheng Shen,Yi Wang,Guyue Liu,Hui Chen,Tong Yang,Hailong Yang,Jing Li,Guiguang Ding,Ke Zhang*

Main category: cs.DC

TL;DR: xLLM是一个面向大规模企业级服务的高性能LLM推理框架，通过解耦的服务-引擎架构、智能调度、多项创新性策略（如PD和EPD disaggregation）、全局KV Cache管理、多层流水线优化、自适应图模式和xTensor内存管理等，显著提高了吞吐量和推理效率，在Qwen和Deepseek模型上的表现优于MindIE和vLLM-Ascend。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理框架在处理大规模、高并发的企业级服务时面临性能和资源利用率的挑战，尤其是在处理多模态请求和最大化集群利用率方面。xLLM旨在通过深度优化和创新的架构来解决这些问题。

Method: xLLM采用了新颖的解耦服务-引擎架构。服务层（xLLM-Service）包含智能调度模块，支持多模态请求处理、在线离线任务的统一弹性调度、工作负载自适应的动态Prefill-Decode（PD）和Encode-Prefill-Decode（EPD） disaggregation策略，以及提供全局KV Cache管理和容错能力。引擎层（xLLM-Engine）通过多层执行流水线优化、自适应图模式、xTensor内存管理、优化的投机解码和动态EPLB来饱和计算资源。

Result: 在相同的TPOT约束下，xLLM在使用Qwen系列模型时，吞吐量比MindIE高1.7倍，比vLLM-Ascend高2.2倍。在使用Deepseek系列模型时，xLLM的平均吞吐量比MindIE高1.7倍。

Conclusion: xLLM通过其创新的架构和优化技术，在LLM推理方面实现了显著的性能和资源效率提升，能够满足大规模企业级服务的需求。

Abstract: We introduce xLLM, an intelligent and efficient Large Language Model (LLM)
inference framework designed for high-performance, large-scale enterprise-grade
serving, with deep optimizations for diverse AI accelerators. To address these
challenges, xLLM builds a novel decoupled service-engine architecture. At the
service layer, xLLM-Service features an intelligent scheduling module that
efficiently processes multimodal requests and co-locates online and offline
tasks through unified elastic scheduling to maximize cluster utilization. This
module also relies on a workload-adaptive dynamic Prefill-Decode (PD)
disaggregation policy and a novel Encode-Prefill-Decode (EPD) disaggregation
policy designed for multimodal inputs. Furthermore, it incorporates a
distributed architecture to provide global KV Cache management and robust
fault-tolerant capabilities for high availability. At the engine layer,
xLLM-Engine co-optimizes system and algorithm designs to fully saturate
computing resources. This is achieved through comprehensive multi-layer
execution pipeline optimizations, an adaptive graph mode and an xTensor memory
management. xLLM-Engine also further integrates algorithmic enhancements such
as optimized speculative decoding and dynamic EPLB, collectively serving to
substantially boost throughput and inference efficiency. Extensive evaluations
demonstrate that xLLM delivers significantly superior performance and resource
efficiency. Under identical TPOT constraints, xLLM achieves throughput up to
1.7x that of MindIE and 2.2x that of vLLM-Ascend with Qwen-series models, while
maintaining an average throughput of 1.7x that of MindIE with Deepseek-series
models. xLLM framework is publicly available at
https://github.com/jd-opensource/xllm and
https://github.com/jd-opensource/xllm-service.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [321] [PoissonNet: A Local-Global Approach for Learning on Surfaces](https://arxiv.org/abs/2510.14146)
*Arman Maesumi,Tanish Makadia,Thibault Groueix,Vladimir G. Kim,Daniel Ritchie,Noam Aigerman*

Main category: cs.GR

TL;DR: PoissonNet是一种新颖的网格学习神经网络架构，通过使用泊松方程进行特征传播，解决了现有方法的局限性，并在语义分割、网格参数化和变形学习方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有网络架构在学习网格高频特征、感受野大小、离散化敏感性和计算开销方面存在权衡。

Method: PoissonNet将局部-全局学习方案与泊松方程相结合，在网格的梯度域中应用学习到的局部特征变换，然后求解泊松方程以在整个表面上传播标量特征更新。

Result: PoissonNet在语义分割、参数化详细的动画表面和学习变形方面取得了最先进的性能，并且计算开销更低。

Conclusion: PoissonNet通过泊松方程实现了高效、全局的特征传播，克服了现有方法的不足，并在多个下游任务中取得了优异的性能。

Abstract: Many network architectures exist for learning on meshes, yet their
constructions entail delicate trade-offs between difficulty learning
high-frequency features, insufficient receptive field, sensitivity to
discretization, and inefficient computational overhead. Drawing from classic
local-global approaches in mesh processing, we introduce PoissonNet, a novel
neural architecture that overcomes all of these deficiencies by formulating a
local-global learning scheme, which uses Poisson's equation as the primary
mechanism for feature propagation. Our core network block is simple; we apply
learned local feature transformations in the gradient domain of the mesh, then
solve a Poisson system to propagate scalar feature updates across the surface
globally. Our local-global learning framework preserves the features's full
frequency spectrum and provides a truly global receptive field, while remaining
agnostic to mesh triangulation. Our construction is efficient, requiring far
less compute overhead than comparable methods, which enables scalability --
both in the size of our datasets, and the size of individual training samples.
These qualities are validated on various experiments where, compared to
previous intrinsic architectures, we attain state-of-the-art performance on
semantic segmentation and parameterizing highly-detailed animated surfaces.
Finally, as a central application of PoissonNet, we show its ability to learn
deformations, significantly outperforming state-of-the-art architectures that
learn on surfaces.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [322] [Impact of irradiation conditions on the magnetic field sensitivity of spin defects in hBN nano flakes](https://arxiv.org/abs/2510.13991)
*Saksham Mahajan,Ravi Kumar,Aferdita Xhameni,Gautham Venu,Basanta Mistri,Felix Donaldson,T. Taniguchi,K. Watanabe,Siddharth Dhomkar,Antonio Lombardo,John J. L. Morton*

Main category: physics.app-ph

TL;DR: 该研究通过聚焦离子束（FIB）辐照在hBN纳米片中制备V_B^-中心，并研究了不同注入条件对量子传感器磁场灵敏度的影响。


<details>
  <summary>Details</summary>
Motivation: 研究注入条件对hBN中V_B^-中心量子传感器的磁场灵敏度关键参数的影响。

Method: 结合光致发光、光学检测磁共振和拉曼光谱技术，研究V_B^-浓度与自旋相干性和晶格质量之间的权衡。

Result: 在高达10^14 ions/cm^2的注入剂量下，V_B^-自旋性质和hBN晶格参数保持良好。超过此剂量，两者均出现显著退化。最佳注入剂量下，交流磁灵敏度达到约1μT/√Hz。FIB的图案化注入显示，V_B^-中心和相关晶格损伤局限在注入区域。

Conclusion: 仔细选择制备参数可以优化hBN中V_B^-中心的性质，支持其作为基于2D材料的量子传感器的应用。

Abstract: We study $V_{\mathrm{B}}^-$ centres generated by helium focused ion beam
(FIB) irradiation in thin ($\sim$70 nm) hBN nanoflakes, in order to investigate
the effect of implantation conditions on the key parameters that influence the
magnetic field sensitivity of $V_{\mathrm{B}}^-$ quantum sensors. Using a
combination of photoluminescence, optically detected magnetic resonance, and
Raman spectroscopy, we examine the competing factors of maximising signal
intensity through larger $V_{\mathrm{B}}^-$ concentration against the
degradation in spin coherence and lattice quality observed at high ion
fluences. Our results indicate that both the $V_{\mathrm{B}}^-$ spin properties
and hBN lattice parameters are largely preserved up to an ion fluence of
$10^{14}$ ions/cm$^2$, and beyond this significant degradation occurs in both.
At the optimal implantation dose, an AC magnetic sensitivity of $\sim
1\,\mu\mathrm{T}/\sqrt{\mathrm{Hz}}$ is achieved. Using the patterned
implantation enabled by the FIB, we find that $V_{\mathrm{B}}^-$ centres and
the associated lattice damage are well localised to the implanted regions. This
work demonstrates how careful selection of fabrication parameters can be used
to optimise the properties of $V_{\mathrm{B}}^-$ centres in hBN, supporting
their application as quantum sensors based on 2D materials.

</details>


### [323] [A Novel Beam Tracking Approach for Preventing Beam Collapse](https://arxiv.org/abs/2510.14350)
*Xiaocun Zong,Fan Yang,Shenheng Xu,Maokun Li*

Main category: physics.app-ph

TL;DR: 该研究提出了一种基于逐行切换码表的波束跟踪新方法，以解决开关切换期间的瞬时不稳定性导致的波束坍塌问题。


<details>
  <summary>Details</summary>
Motivation: 解决波束跟踪中开关切换期间的瞬时不稳定性导致的波束坍塌问题。

Method: 提出一种基于逐行切换码表的波束切换方法，并构建了RIS硬件平台进行实验验证。

Result: 仿真和实验结果表明，该方法通过引入中间状态转换，实现了无波束坍塌的波束跟踪，且增益损失不明显。

Conclusion: 所提出的方法适用于移动通信和雷达检测等领域，通过引入中间状态转换，有效地解决了波束坍塌问题，并具有不显著的增益损失。

Abstract: To address the issue of beam collapse resulting from instantaneous
instability during switch transitions in beam tracking, this paper proposes a
novel beam switching method based on a row-by-row switching code table. The
paper first establishes an abstract model of the beam tracking application
scenario and introduces the reconfigurable intelligent surface (RIS) employed
in this paper. Subsequently, simulations are conducted to compare the
conventional direct beam switching method with the proposed row-by-row
switching code table approach, thereby elucidating the advantages and
limitations of the new method. In parallel, a RIS hardware platform is
constructed in a microwave anechoic chamber for experimental validation. Both
simulation and experimental results show that, by incorporating intermediate
state transitions, the approach achieves beam tracking without beam collapse
while incurring no significant gain loss. Finally, the paper discusses the
applicability scope and potential scenarios for the proposed method. This
research provides valuable insights for applications in mobile communications
and radar detection.

</details>


### [324] [A combined thermal-resistance-capacity and finite-element model for very fast and accurate short- and medium-term simulations of single U-tube borehole heat exchangers](https://arxiv.org/abs/2510.14421)
*Enzo Zanchini,Francesco Zanchini,Claudia Naldi*

Main category: physics.app-ph

TL;DR: 本文提出了一种结合TRCM和插值数据集的新方法，用于模拟单U型BHE的短期和中期热响应，兼顾了计算速度和模拟精度。


<details>
  <summary>Details</summary>
Motivation: 准确设计地埋管地源热泵系统需要了解BHE的长期和短期出口流体温度。本文关注短期和中期。

Method: 使用TRCM估算BHE的热响应，并通过插值一个由54个有限元模拟生成的数据集来修正结果。

Result: 该方法使用C++程序实现，可在两秒内提供入口、出口和平均流体温度，以及平均BHE表面温度、3D和有效钻孔热阻的时间演变。

Conclusion: 该方法结合了TRCM的速度和有限元模拟的精度，可以轻松连接到长期模拟工具，以获得钻孔场的全时间尺度热响应。

Abstract: An accurate design of a ground-coupled heat pump system requires the
knowledge of the outlet fluid temperature from the borehole heat exchangers
(BHEs), both in the short and long term. This paper fucuses on the short and
medium term. In this time range, either 3D finite-element simulations or
Thermal Resistance Capacity Models (TRCMs) can be applied. The former can yield
very accurate results but require long computation times. The latter are much
faster but cannot be fully precise, because they require simplifying
assumptions. In this paper, we present a new method for the short-term and
medium-term simulation of single U-tube BHEs, which combines the speed of TRCMs
and the accuracy of finite-elements simulations. The method uses a TRCM to
estimate the thermal response of the BHE, then corrects the results by
interpolation with a dataset, which has been produced by running 54
finite-element simulations in various configurations. The model is implemented
in a C++ program, available at the open-source online data repository of the
University of Bologna. The program provides, within two seconds, the time
evolution of the inlet, outlet and mean fluid temperature, of the mean BHE
surface temperature, of the 3D and the effective borehole thermal resistance.
It can be easily connected to long-term simulation tools to obtain the
full-time-scale thermal response of a bore field.

</details>


### [325] [Layered Bimetal Nanoporous Platforms for SERS Sensing](https://arxiv.org/abs/2510.14706)
*Yanzhou Zou,Anastasiia Sapunova,Tommaso Giovannini,Chen Wang,Huaizhou Jin,Vincenzo Caligiuri,Andrea Schirato,Luca Bursi,Alessandro Alabastri,Shukun Weng,Ali Douaki,German Lanzavecchia,Ivan Marri,Roman Krahne,Nicolò Maccaferri,Zhenrong Zheng,Shangzhong Jin,Denis Garoli*

Main category: physics.app-ph

TL;DR: 研究了双金属纳米多孔材料在等离子的应用，并首次报道了结合不同金属（Au, Ag, Cu）的双层纳米多孔平台的制备方法和详细研究。


<details>
  <summary>Details</summary>
Motivation: 等离子的研究主要集中在单一种类的金属，而双金属体系的研究才刚刚开始，作者旨在探索不同金属组合的相互作用以及在生物分子检测（如SERS）中的应用。

Method: 采用干法合成技术，结合形貌分析、数值模拟和光学光谱等手段，对制备的双层纳米多孔平台进行研究。

Result: 首次报道了结合Au, Ag, Cu等不同金属的双层纳米多孔平台的制备方法，并对其进行了详细研究。

Conclusion: 双金属纳米多孔平台为等离子的应用提供了新的可能性，尤其在生物分子检测方面具有潜在应用价值。

Abstract: Nanoporous metals are extensively investigated as platforms for applications
in plasmonics. They present high surface areas and strong local electric fields
that can be tuned at different energies, playing with the choice of the metals
and the morphology of the porous layers. Until recently, research in the field
of plasmonics has primarily focused on porous metals composed of a single
element, with limited attention given to the impact of alloy composition. The
investigation of bi-metallic systems has only just begun to emerge in the
literature. In particular, combining two or more different plasmonic metals, it
could be possible to explore the interactions between two metals excited at
specific energies. This involves plasmonic coupling, electron transfer, band
hybridization at the interface, electromagnetic field interactions, and
possibly thermal and electronic energy transfer depending on separation, size,
and materials involved. The analysis of bi-metal systems can also be
interesting in biomolecule detection, such as in the case of Surface Enhanced
Raman Scattering (SERS). Here we report, for the first time, a detailed study
(comprising morphological analyses, numerical modelling, and optical
spectroscopies) on bi-metal nanoporous platforms prepared with a dry-synthesis
method enabling the easy and controllable fabrication of bilayers combining
different metals such as Au, Ag, and Cu.

</details>


### [326] [Unidirectional Zero Reflection and Perfect Absorption via Exceptional Points in Active Piezoelectric Willis Metamaterials](https://arxiv.org/abs/2510.14852)
*Hrishikesh Danawe,Serife Tol*

Main category: physics.app-ph

TL;DR: 该研究提出了一种利用压电超材料和电路耦合实现弹性波单向传输的装置，能够动态调控频率相关的刚度和阻尼，并在非厄米奇异点附近实现单向零反射和单向完美吸收。


<details>
  <summary>Details</summary>
Motivation: 由于压电超材料中的电-动量耦合可以连接宏观电场和动量，从而实现非对称弹性波传输，这与弹性介质中的 Willis 耦合类似。因此，需要研究一种能够利用这种耦合效应的装置。

Method: 提出了一种由电阻、电感和与应变相关的电压反馈增益组成的串联电路组成的二维层状压电超材料，通过调整电路参数来实现动态控制频率相关的刚度和阻尼。通过动态均质化揭示了具有 Willis 和电-动量耦合的宏观本构关系。识别非厄米奇异点，其中散射本征态合并并产生波响应的极端不对称性。

Result: 在非厄米奇异点附近，系统实现了单向零反射（UZR）和单向完美吸收（UPA），即从一个方向完全吸收，而从相反方向完全反射。

Conclusion: 该研究提出了一种利用压电超材料和电路耦合实现弹性波单向传输的装置，能够动态调控频率相关的刚度和阻尼，并在非厄米奇异点附近实现单向零反射和单向完美吸收。该系统为利用无源-有源混合超材料实现可调谐、定向弹性波控制提供了一个紧凑且可重构的平台，为声学隔离、基于波的计算、传感和固体介质中的能量操纵等可编程设备开辟了新的途径。

Abstract: Electro-momentum coupling in piezoelectric metamaterials with broken
inversion symmetry enables asymmetric elastic wave transport by linking
macroscopic electric fields to momentum, an effect analogous to Willis coupling
in elastic media. A one-dimensional layered piezoelectric metamaterial
integrated with shunt circuits, consisting of a resistor, inductor, and
strain-proportional voltage feedback gain, is proposed to achieve dynamic
control of frequency-dependent stiffness and damping through electromechanical
interactions. Tuning the circuit parameters yields direction-dependent wave
scattering at targeted frequencies. Dynamic homogenization reveals macroscopic
constitutive relations exhibiting both Willis and electro-momentum couplings.
Non-Hermitian exceptional points are identified, where scattering eigenmodes
coalesce and produce extreme asymmetries in wave response. Near these points,
the system realizes unidirectional zero reflection (UZR) and unidirectional
perfect absorption (UPA), achieving complete absorption from one direction and
total reflection from the opposite side. The findings demonstrate a compact and
reconfigurable platform for tunable, directional elastic wave control using
passive-active hybrid metamaterials, opening new avenues for programmable
devices in acoustic isolation, wave-based computing, sensing, and energy
manipulation in solid media.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [327] [A Levelset Algorithm for 3D-Tarksi](https://arxiv.org/abs/2510.14777)
*Sebastian Haslebacher,Jonas Lill*

Main category: cs.DS

TL;DR: 提出了一种简单的新算法，用于寻找单调函数 F : [N]^3 → [N]^3 的 Tarski 不动点。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是开发一种高效的算法来寻找 Tarski 不动点。

Method: 该算法的时间复杂度为 O(log^2 N)，查询次数也为 O(log^2 N)，与 Etessami 等人提出的 Ω(log^2 N) 查询下界以及 Fearnley 等人现有的最先进算法相匹配。

Result: 算法在 O(log^2 N) 时间内找到 Tarski 不动点。

Conclusion: 该算法在时间和查询复杂度上都达到了最优水平。

Abstract: We present a simple new algorithm for finding a Tarski fixed point of a
monotone function $F : [N]^3 \rightarrow [N]^3$. Our algorithm runs in
$O(\log^2 N)$ time and makes $O(\log^2 N)$ queries to $F$, matching the
$\Omega(\log^2 N)$ query lower bound due to Etessami et al.\ as well as the
existing state-of-the-art algorithm due to Fearnley et al.

</details>


### [328] [Prediction-Specific Design of Learning-Augmented Algorithms](https://arxiv.org/abs/2510.14887)
*Sizhe Li,Nicolas Christianson,Tongxin Li*

Main category: cs.DS

TL;DR: 预测驱动的在线算法可以比传统方法提供更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于预测的在线算法过于保守，未能充分利用问题结构和预测信息来优化性能。

Method: 提出“强最优”算法的概念，并开发一个通用的双层优化框架来设计这类算法，同时为确定性和随机租用、一最大搜索等经典在线问题设计了具体的强最优算法。

Result: 分析揭示了利用预测特定设计来最优集成预测到在线算法中的新结构洞见。实验评估表明，强最优算法在动态电源管理和基于波动性的指数交易等问题中显著提高了性能。

Conclusion: 强最优算法在预测特定性能标准下实现了帕累托最优，并在各种在线决策场景中显著提高了性能。

Abstract: Algorithms with predictions} has emerged as a powerful framework to combine
the robustness of traditional online algorithms with the data-driven
performance benefits of machine-learned (ML) predictions. However, most
existing approaches in this paradigm are overly conservative, {as they do not
leverage problem structure to optimize performance in a prediction-specific
manner}. In this paper, we show that such prediction-specific performance
criteria can enable significant performance improvements over the coarser
notions of consistency and robustness considered in prior work. Specifically,
we propose a notion of \emph{strongly-optimal} algorithms with predictions,
which obtain Pareto optimality not just in the worst-case tradeoff between
robustness and consistency, but also in the prediction-specific tradeoff
between these metrics. We develop a general bi-level optimization framework
that enables systematically designing strongly-optimal algorithms in a wide
variety of problem settings, and we propose explicit strongly-optimal
algorithms for several classic online problems: deterministic and randomized
ski rental, and one-max search. Our analysis reveals new structural insights
into how predictions can be optimally integrated into online algorithms by
leveraging a prediction-specific design. To validate the benefits of our
proposed framework, we empirically evaluate our algorithms in case studies on
problems including dynamic power management and volatility-based index trading.
Our results demonstrate that prediction-specific, strongly-optimal algorithms
can significantly improve performance across a variety of online
decision-making settings.

</details>


### [329] [Tree-Like Shortcuttings of Trees](https://arxiv.org/abs/2510.14918)
*Hung Le,Lazar Milenković,Shay Solomon,Cuong Than*

Main category: cs.DS

TL;DR: 该论文研究了具有界限跳数直径的树度量稀疏短路图，并首次系统地研究了“类似树”的常数跳数短路图，提出了跳数直径和树度之间的最佳权衡。


<details>
  <summary>Details</summary>
Motivation: 以往的常数跳数短路图包含密集子图，这在许多应用中是一个重大缺点。因此，需要研究“类似树”的常数跳数短路图。

Method: 论文中提到了新的上界和下界，包括跳数直径和树度之间的最佳权衡，并为较大的k值提供了下界。

Result: 论文提出跳数直径与树度之间的权衡，并为所有跳数直径实现了(	ext{hop-diameter}	imes 	ext{treewidth} = 	ext{O}((	ext{log}	ext{log } n)^2))。

Conclusion: 该研究首次系统地研究了“类似树”的常数跳数短路图，并在跳数直径和树度方面取得了关键进展，解决了悬而未决的公开问题。

Abstract: Sparse shortcuttings of trees -- equivalently, sparse 1-spanners for tree
metrics with bounded hop-diameter -- have been studied extensively (under
different names and settings), since the pioneering works of [Yao82, Cha87,
AS87, BTS94], initially motivated by applications to range queries, online tree
product, and MST verification, to name a few. These constructions were also
lifted from trees to other graph families using known low-distortion embedding
results. The works of [Yao82, Cha87, AS87, BTS94] establish a tight tradeoff
between hop-diameter and sparsity (or average degree) for tree shortcuttings
and imply constant-hop shortcuttings for $n$-node trees with sparsity $O(\log^*
n)$. Despite their small sparsity, all known constant-hop shortcuttings contain
dense subgraphs (of sparsity $\Omega(\log n)$), which is a significant drawback
for many applications.
  We initiate a systematic study of constant-hop tree shortcuttings that are
``tree-like''. We focus on two well-studied graph parameters that measure how
far a graph is from a tree: arboricity and treewidth. Our contribution is
twofold.
  * New upper and lower bounds for tree-like shortcuttings of trees, including
an optimal tradeoff between hop-diameter and treewidth for all hop-diameter up
to $O(\log\log n)$. We also provide a lower bound for larger values of $k$,
which together yield $\text{hop-diameter}\times \text{treewidth} =
\Omega((\log\log n)^2)$ for all values of hop-diameter, resolving an open
question of [FL22, Le23]. [...]

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [330] [SHaRe-SSM: An Oscillatory Spiking Neural Network for Target Variable Modeling in Long Sequences](https://arxiv.org/abs/2510.14386)
*Kartikay Agrawal,Abhijeet Vikram,Vedant Sharma,Vaishnavi N.,Ayon Borthakur*

Main category: cs.LG

TL;DR: SHaRe-SSM是一种结合了脉冲神经网络（SNN）和状态空间模型（SSM）的新型模型，用于处理长序列的变量建模，具有高能效和低计算量。它在性能上优于Transformer和一阶SSM，尤其适用于资源受限的应用。


<details>
  <summary>Details</summary>
Motivation: 由于大型模型的出现，脉冲神经网络（SNNs）因其能效高、无需乘法运算以及稀疏事件驱动的深度学习能力而受到关注。同时，状态空间模型（SSMs）作为Transformer的替代方案，在处理长序列方面表现出色。本研究旨在结合这两种技术的优点，提出一种适用于长序列变量建模的新模型。

Method: 提出了一种名为SHaRe-SSM（Spiking Harmonic Resonate and Fire State Space Model）的二阶脉冲SSM。该模型利用共振和发放（resonate and fire）神经元，并通过并行扫描（parallel scans）技术实现动力学系统的稳定高效计算。此外，还提出了一种基于核方法的脉冲回归器。

Result: SHaRe-SSM 在处理长序列（长达50k）的变量建模（分类和回归）方面表现出优于Transformer和一阶SSM的性能。与二阶ANN-based SSMs相比，SHaRe-SSM 在处理18k序列时能耗降低了73倍，同时保持了性能。研究还对共振和发放SSMs中的异质性、耗散和守恒等因素进行了系统性分析。

Conclusion: SHaRe-SSM 是一种具有高能效和优越性能的新型长序列建模方法，它成功地将脉冲神经网络的优点与状态空间模型的长序列处理能力相结合。该模型在保持高性能的同时，显著降低了计算能耗，为资源受限环境下的应用提供了新的可能。

Abstract: In recent years, with the emergence of large models, there has been a
significant interest in spiking neural networks (SNNs) primarily due to their
energy efficiency, multiplication-free, and sparse event-based deep learning.
Similarly, state space models (SSMs) in varying designs have evolved as a
powerful alternative to transformers for target modeling in long sequences,
thereby overcoming the quadratic dependence on sequence length of a
transformer. Inspired by this progress, we here design SHaRe-SSM (Spiking
Harmonic Resonate and Fire State Space Model), for target variable modeling
(including both classification and regression) for very-long-range sequences.
Our second-order spiking SSM, on average, performs better than transformers or
first-order SSMs while circumventing multiplication operations, making it ideal
for resource-constrained applications. The proposed block consumes $73 \times$
less energy than second-order ANN-based SSMs for an 18k sequence, while
retaining performance. To ensure learnability over the long-range sequences, we
propose exploiting the stable and efficient implementation of the dynamical
system using parallel scans. Moreover, for the first time, we propose a
kernel-based spiking regressor using resonate and fire neurons for very
long-range sequences. Our network shows superior performance on even a 50k
sequence while being significantly energy-efficient. In addition, we conducted
a systematic analysis of the impact of heterogeneity, dissipation, and
conservation in resonate-and-fire SSMs.

</details>


### [331] [Large Language Models for Real-World IoT Device Identification](https://arxiv.org/abs/2510.13817)
*Rameen Mahmood,Tousif Ahmed,Sai Teja Peddinti,Danny Yuxing Huang*

Main category: cs.LG

TL;DR: IoT设备激增导致现有识别方法面临严峻挑战，尤其是在开放世界环境中。本研究提出一种将设备识别视为语言建模任务的语义推理流程，利用异构网络元数据。研究人员为IoT Inspector数据集生成了高保真供应商标签，并使用指令微调的LLaMA3.18B模型来处理稀疏和长尾分布。该模型在2015个供应商上实现了98.25%的top-1准确率和90.73%的宏准确率，同时对数据缺失、协议漂移和对抗性攻击具有鲁棒性。实验证明，这种基于LLM的方法为大规模实际设备识别提供了可扩展且可解释的基础。


<details>
  <summary>Details</summary>
Motivation: 现有IoT设备识别方法在应对开放世界环境中不完整、嘈杂或被故意混淆的网络元数据方面存在不足，带来了安全、隐私和网络问责的风险。

Method: 将设备识别任务重构为处理异构网络元数据的语言建模任务，并构建了一个语义推理流程。利用大型语言模型（LLM）的集成，结合互信息和基于熵的稳定性得分，为IoT Inspector数据集生成了高保真供应商标签。然后，使用课程学习对量化后的LLaMA3.18B模型进行指令微调，以提高其在稀疏和长尾供应商分布下的泛化能力。

Result: 该模型在2015个供应商上实现了98.25%的top-1准确率和90.73%的宏准确率。该模型能够抵抗缺失字段、协议漂移和对抗性操纵。在独立的IoT测试台上进行的评估，以及对解释质量和对抗性压力测试的分析，均证实了其有效性。

Conclusion: 经过指令微调的大型语言模型为大规模、实际的设备识别提供了一个可扩展且可解释的基础，能够有效应对开放世界环境中IoT设备识别所面临的挑战。

Abstract: The rapid expansion of IoT devices has outpaced current identification
methods, creating significant risks for security, privacy, and network
accountability. These challenges are heightened in open-world environments,
where traffic metadata is often incomplete, noisy, or intentionally obfuscated.
We introduce a semantic inference pipeline that reframes device identification
as a language modeling task over heterogeneous network metadata. To construct
reliable supervision, we generate high-fidelity vendor labels for the IoT
Inspector dataset, the largest real-world IoT traffic corpus, using an ensemble
of large language models guided by mutual-information and entropy-based
stability scores. We then instruction-tune a quantized LLaMA3.18B model with
curriculum learning to support generalization under sparsity and long-tail
vendor distributions. Our model achieves 98.25% top-1 accuracy and 90.73% macro
accuracy across 2,015 vendors while maintaining resilience to missing fields,
protocol drift, and adversarial manipulation. Evaluation on an independent IoT
testbed, coupled with explanation quality and adversarial stress tests,
demonstrates that instruction-tuned LLMs provide a scalable and interpretable
foundation for real-world device identification at scale.

</details>


### [332] [Online Reliable Anomaly Detection via Neuromorphic Sensing and Communications](https://arxiv.org/abs/2510.14688)
*Junya Shiraishi,Jiechen Chen,Osvaldo Simeone,Petar Popovski*

Main category: cs.LG

TL;DR: 本文提出了一种基于神经形态无线传感器网络的低功耗在线异常检测框架，可用于脑机接口和远程环境监测。该框架通过选择性查询事件驱动的神经形态传感器节点，并利用冲动无线电传输编码感知事件，然后在中央读取节点处理这些事件来检测异常状态，同时严格控制虚报率（FDR）。该方法采用基于 e-values 的在线假设检验方法，无需了解异常率即可控制 FDR，并通过多臂老虎机框架中的最佳手臂识别问题动态优化传感器查询策略。性能评估表明，该方法在满足 FDR 要求的同时，能够有效检测异常、调度通信并实现低检测延迟。


<details>
  <summary>Details</summary>
Motivation: 提出一种低功耗在线异常检测框架，适用于脑机接口和远程环境监测等场景，以应对传统方法的局限性。

Method: 1. **系统模型**: 采用神经形态无线传感器网络，中央读取节点主动查询部分神经形态传感器节点（neuro-SNs）。
2. **传感器响应**: 神经形态传感器事件驱动，感知到变化时产生脉冲（spikes），并通过冲动无线电（IR）传输将事件编码。
3. **异常检测**: 读取节点处理事件驱动信号，判断系统状态是否正常。
4. **FDR 控制**: 采用在线假设检验方法和 e-values 来严格控制虚报率（FDR）低于预设阈值，且无需了解异常率。
5. **查询策略优化**: 将传感器查询策略建模为多臂老虎机问题中的最佳手臂识别问题，进行动态优化。

Result: 性能评估表明，该方法能够可靠地在严格的 FDR 要求下检测异常，同时高效地调度传感器通信并实现低检测延迟。

Conclusion: 所提出的低功耗在线异常检测框架在神经形态无线传感器网络上表现出优越的性能，能够有效控制 FDR、优化通信调度并降低检测延迟，适用于脑机接口和远程环境监测等应用。

Abstract: This paper proposes a low-power online anomaly detection framework based on
neuromorphic wireless sensor networks, encompassing possible use cases such as
brain-machine interfaces and remote environmental monitoring. In the considered
system, a central reader node actively queries a subset of neuromorphic sensor
nodes (neuro-SNs) at each time frame. The neuromorphic sensors are
event-driven, producing spikes in correspondence to relevant changes in the
monitored system. The queried neuro-SNs respond to the reader with impulse
radio (IR) transmissions that directly encode the sensed local events. The
reader processes these event-driven signals to determine whether the monitored
environment is in a normal or anomalous state, while rigorously controlling the
false discovery rate (FDR) of detections below a predefined threshold. The
proposed approach employs an online hypothesis testing method with e-values to
maintain FDR control without requiring knowledge of the anomaly rate, and it
dynamically optimizes the sensor querying strategy by casting it as a best-arm
identification problem in a multi-armed bandit framework. Extensive performance
evaluation demonstrates that the proposed method can reliably detect anomalies
under stringent FDR requirements, while efficiently scheduling sensor
communications and achieving low detection latency.

</details>


### [333] [Self-Training with Dynamic Weighting for Robust Gradual Domain Adaptation](https://arxiv.org/abs/2510.13864)
*Zixi Wang,Yushe Cao,Yubo Huang,Jinzhu Wei,Jingzehua Xu,Shuai Zhang,Xin Lai*

Main category: cs.LG

TL;DR: STDW是一种用于渐进域适应的新方法，通过动态加权机制解决知识迁移问题，在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统渐进域适应方法在中间域知识迁移和数据不完整方面存在不足，STDW旨在提高适应的鲁棒性。

Method: STDW引入动态加权机制，通过一个随时间变化的超参数$\\(varrho\\)$来平衡源域和目标域的损失贡献，并利用自训练生成伪标签进行迭代更新。

Result: STDW在旋转MNIST、颜色偏移MNIST、肖像数据集和Cover Type数据集上进行了实验，结果表明STDW优于现有基线方法。消融研究证实了动态调整$\\(varrho\\)$对于渐进适应的关键作用。

Conclusion: STDW提供了一个理论和实践框架，用于鲁棒的渐进域适应，在动态现实场景中具有潜在应用价值。

Abstract: In this paper, we propose a new method called Self-Training with Dynamic
Weighting (STDW), which aims to enhance robustness in Gradual Domain Adaptation
(GDA) by addressing the challenge of smooth knowledge migration from the source
to the target domain. Traditional GDA methods mitigate domain shift through
intermediate domains and self-training but often suffer from inefficient
knowledge migration or incomplete intermediate data. Our approach introduces a
dynamic weighting mechanism that adaptively balances the loss contributions of
the source and target domains during training. Specifically, we design an
optimization framework governed by a time-varying hyperparameter $\varrho$
(progressing from 0 to 1), which controls the strength of domain-specific
learning and ensures stable adaptation. The method leverages self-training to
generate pseudo-labels and optimizes a weighted objective function for
iterative model updates, maintaining robustness across intermediate domains.
Experiments on rotated MNIST, color-shifted MNIST, portrait datasets, and the
Cover Type dataset demonstrate that STDW outperforms existing baselines.
Ablation studies further validate the critical role of $\varrho$'s dynamic
scheduling in achieving progressive adaptation, confirming its effectiveness in
reducing domain bias and improving generalization. This work provides both
theoretical insights and a practical framework for robust gradual domain
adaptation, with potential applications in dynamic real-world scenarios. The
code is available at https://github.com/Dramwig/STDW.

</details>


### [334] [Provable Unlearning with Gradient Ascent on Two-Layer ReLU Neural Networks](https://arxiv.org/abs/2510.14844)
*Odelia Melamed,Gilad Yehudai,Gal Vardi*

Main category: cs.LG

TL;DR: 梯度上升是一种有效的机器学习方法，可以在不重新训练的情况下移除特定数据点的影响。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在训练过程中会学习到数据中的敏感信息，而机器学习模型可以帮助我们删除这些信息，从而解决隐私和伦理问题。

Method: 通过理论分析梯度上升法，研究其在移除特定数据点时的表现，并提出了一种新的$(\epsilon, \delta, \tau)$-successful unlearning 成功标准。

Result: 研究表明，梯度上升法可以满足新的成功标准，并且在特定条件下可以有效地移除数据点的同时保留模型的泛化能力。

Conclusion: 梯度上升法是一种简单而有效的方法，可以用于机器学习中的数据移除，并且能够保留模型的泛化能力。

Abstract: Machine Unlearning aims to remove specific data from trained models,
addressing growing privacy and ethical concerns. We provide a theoretical
analysis of a simple and widely used method - gradient ascent - used to reverse
the influence of a specific data point without retraining from scratch.
Leveraging the implicit bias of gradient descent towards solutions that satisfy
the Karush-Kuhn-Tucker (KKT) conditions of a margin maximization problem, we
quantify the quality of the unlearned model by evaluating how well it satisfies
these conditions w.r.t. the retained data. To formalize this idea, we propose a
new success criterion, termed \textbf{$(\epsilon, \delta, \tau)$-successful}
unlearning, and show that, for both linear models and two-layer neural networks
with high dimensional data, a properly scaled gradient-ascent step satisfies
this criterion and yields a model that closely approximates the retrained
solution on the retained data. We also show that gradient ascent performs
successful unlearning while still preserving generalization in a synthetic
Gaussian-mixture setting.

</details>


### [335] [Deep Edge Filter: Return of the Human-Crafted Layer in Deep Learning](https://arxiv.org/abs/2510.13865)
*Dongkwan Lee,Junhoo Lee,Nojun Kwak*

Main category: cs.LG

TL;DR: 通过高通滤波处理深度神经网络特征，以提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提出假设：神经网络将与任务相关的信息编码在高频分量中，将领域特定的偏差存储在低频分量中。

Method: 通过从原始特征中减去低通滤波后的输出，分离可泛化的表示，同时保持架构的完整性。

Result: 在视觉、文本、3D和音频等不同领域进行了实验，证明了性能的一致性改进，并且与模型架构和数据模式无关。

Conclusion: 该方法诱导特征稀疏化并有效分离高频分量，为核心假设提供了经验验证。

Abstract: We introduce the Deep Edge Filter, a novel approach that applies high-pass
filtering to deep neural network features to improve model generalizability.
Our method is motivated by our hypothesis that neural networks encode
task-relevant semantic information in high-frequency components while storing
domain-specific biases in low-frequency components of deep features. By
subtracting low-pass filtered outputs from original features, our approach
isolates generalizable representations while preserving architectural
integrity. Experimental results across diverse domains such as Vision, Text,
3D, and Audio demonstrate consistent performance improvements regardless of
model architecture and data modality. Analysis reveals that our method induces
feature sparsification and effectively isolates high-frequency components,
providing empirical validation of our core hypothesis. The code is available at
https://github.com/dongkwani/DeepEdgeFilter.

</details>


### [336] [CoLoR-GAN: Continual Few-Shot Learning with Low-Rank Adaptation in Generative Adversarial Networks](https://arxiv.org/abs/2510.13869)
*Munsif Ali,Leonardo Rossi,Massimo Bertozzi*

Main category: cs.LG

TL;DR: CoLoR-GAN框架利用低秩张量进行持续学习和少样本学习，通过LLoRA技术优化适配器大小，并提供超参数选择指南，在保持SOTA性能的同时显著减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 在生成对抗网络（GANs）的持续学习（CL）中，如何在少样本（FS）条件下学习而不发生灾难性遗忘是一个挑战。现有方法（如LFS-GAN）会在每次迭代中增加大量新权重，长期来看会显著增加模型负担。

Method: 提出CoLoR-GAN框架，利用低秩张量实现高效模型自适应，以同时处理少样本和持续学习。引入LLoRA技术，用于卷积层，进一步优化适配器大小。进行超参数的实证研究以指导选择。

Result: 实验表明CoLoR-GAN在多个基准CL和FS任务上是有效的，达到了SOTA性能，同时资源消耗大大减少。

Conclusion: CoLoR-GAN框架成功地解决了持续学习和少样本学习在GANs中的挑战，通过低秩适配技术实现了高效和资源节省。

Abstract: Continual learning (CL) in the context of Generative Adversarial Networks
(GANs) remains a challenging problem, particularly when it comes to learn from
a few-shot (FS) samples without catastrophic forgetting. Current most effective
state-of-the-art (SOTA) methods, like LFS-GAN, introduce a non-negligible
quantity of new weights at each training iteration, which would become
significant when considering the long term. For this reason, this paper
introduces \textcolor{red}{\textbf{\underline{c}}}ontinual
few-sh\textcolor{red}{\textbf{\underline{o}}}t learning with
\textcolor{red}{\textbf{\underline{lo}}}w-\textcolor{red}{\textbf{\underline{r}}}ank
adaptation in GANs named CoLoR-GAN, a framework designed to handle both FS and
CL together, leveraging low-rank tensors to efficiently adapt the model to
target tasks while reducing even more the number of parameters required.
Applying a vanilla LoRA implementation already permitted us to obtain pretty
good results. In order to optimize even further the size of the adapters, we
challenged LoRA limits introducing a LoRA in LoRA (LLoRA) technique for
convolutional layers. Finally, aware of the criticality linked to the choice of
the hyperparameters of LoRA, we provide an empirical study to easily find the
best ones. We demonstrate the effectiveness of CoLoR-GAN through experiments on
several benchmark CL and FS tasks and show that our model is efficient,
reaching SOTA performance but with a number of resources enormously reduced.
Source code is available on
\href{https://github.com/munsifali11/CoLoR-GAN}{Github.

</details>


### [337] [MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving](https://arxiv.org/abs/2510.14557)
*Jungi Lee,Junyong Park,Soohyun Cha,Jaehoon Cho,Jaewoong Sim*

Main category: cs.LG

TL;DR: BFP格式的超低比特變體難以提供合理的語言模型性能，提出MX+擴展來解決離群值問題，並在模型性能上超越4位元MX格式。


<details>
  <summary>Details</summary>
Motivation: 為了透過減少的精度格式來降低大型語言模型（LLM）服務的成本，但現有的格式需要修改軟體框架或不便於硬體供應商採用。

Method: 提出MX+，一種擴展現有的micro-scaling（MX）格式的方法，通過將指數欄位作為額外的尾數來提高離群值的精度。

Result: MX+在模型性能上顯著優於4位元MX格式（MXFP4），儲存開銷和減緩和微乎其微。

Conclusion: MX+提供了一種具有成本效益且非侵入性的選擇，可以替代MXFP4或MXFP6，以實現高效的LLM推論。

Abstract: Reduced-precision data formats are crucial for cost-effective serving of
large language models (LLMs). While numerous reduced-precision formats have
been introduced thus far, they often require intrusive modifications to the
software frameworks or are rather unconventional for widespread adoption across
hardware vendors. In this paper, we instead focus on recent industry-driven
variants of block floating-point (BFP) formats and conduct a comprehensive
analysis to push their limits for efficient LLM serving. Our analysis shows
that existing ultra low-bit BFP variants struggle to provide reasonable
language model performance due to outlier values in blocks. To address the
outliers with BFPs, we propose MX+, a cost-effective and non-intrusive
extension designed for seamless integration into the microscaling (MX) formats.
MX+ builds on the key insight that the outlier does not need to use its
exponent field in the element data type, which allows us to repurpose the
exponent field as an extended mantissa to increase the precision of the outlier
element. Our evaluation shows that MX+ achieves significantly higher model
performance compared to the 4-bit MX format (MXFP4) with negligible storage
overhead and slowdown, thus offering a compelling alternative to MXFP4 or MXFP6
for efficient LLM inference.

</details>


### [338] [Joint Discriminative-Generative Modeling via Dual Adversarial Training](https://arxiv.org/abs/2510.13872)
*Xuwang Yin,Claire Zhang,Julie Steele,Nir Shavit,Tony T. Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种结合对抗训练（AT）原理的新型混合模型训练框架，用于同时实现鲁棒分类和高保真生成，解决了现有联合能量基模型（JEM）训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有混合方法（如JEM）在实现鲁棒分类和高保真生成方面面临挑战，其基于SGLD的训练易不稳定且生成样本质量差。

Method: 提出了一种新的训练框架，将对抗训练（AT）原理集成到JEM中。主要创新包括：1. 使用基于AT的方法替代SGLD，通过区分真实数据和PGD生成的对比样本来优化能量函数。2. 采用协同对抗训练增强分类鲁棒性，无需显式梯度惩罚。3. 提出两阶段训练程序解决批归一化与EBM训练不兼容问题。

Result: 在CIFAR-10、CIFAR-100和ImageNet上的实验表明，该方法在对抗鲁棒性方面显著优于现有混合模型，同时保持了有竞争力的生成性能。在ImageNet上，其生成保真度超越了BigGAN，接近扩散模型。

Conclusion: 该方法解决了限制JEM扩展的关键稳定性问题，证明了对抗训练可以作为统一框架的有效基础，用于生成和鲁棒地分类视觉数据。

Abstract: Simultaneously achieving robust classification and high-fidelity generative
modeling within a single framework presents a significant challenge. Hybrid
approaches, such as Joint Energy-Based Models (JEM), interpret classifiers as
EBMs but are often limited by the instability and poor sample quality inherent
in SGLD-based training. We address these limitations by proposing a novel
training framework that integrates adversarial training (AT) principles for
both discriminative robustness and stable generative learning. The proposed
method introduces three key innovations: (1) the replacement of SGLD-based JEM
learning with a stable, AT-based approach that optimizes the energy function by
discriminating between real data and PGD-generated contrastive samples using
the BCE loss; (2) synergistic adversarial training for the discriminative
component that enhances classification robustness while eliminating the need
for explicit gradient penalties; and (3) a two-stage training procedure to
resolve the incompatibility between batch normalization and EBM training.
Experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate that our method
substantially improves adversarial robustness over existing hybrid models while
maintaining competitive generative performance. On ImageNet, when optimized for
generative modeling, our model's generative fidelity surpasses that of BigGAN
and approaches diffusion models, representing the first MCMC-based EBM approach
to achieve high-quality generation on complex, high-resolution datasets. Our
approach addresses key stability issues that have limited JEM scaling and
demonstrates that adversarial training can serve as an effective foundation for
unified frameworks capable of generating and robustly classifying visual data.

</details>


### [339] [Near-Optimal Regret-Queue Length Tradeoff in Online Learning for Two-Sided Markets](https://arxiv.org/abs/2510.14097)
*Zixian Yang,Sushil Mahavir Varma,Lei Ying*

Main category: cs.LG

TL;DR: 这是一个关于在线学习定价和匹配算法在双边市场中最大化平台利润的研究。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在双边市场中设计定价和匹配算法，以最大化平台利润并保持合理的队列长度，同时处理可能未知的需求和供应曲线。

Method: 提出了一种新颖的基于在线学习的定价策略，并证明了其接近最优性。该策略包含一个动态组件和一个概率组件，用于优化学习速度、样本获取和队列长度之间的权衡。

Result: 证明了在$	au 	o ho$和$1-	au$的吞吐量下，平均队列长度和最大队列长度的渐近最优性。该策略在$	ilde{O}(T^{1-	au})$的遗憾、$	ilde{O}(T^{	au/2})$的平均队列长度和$	ilde{O}(T^{	au})$的最大队列长度之间实现了权衡，优于现有结果。

Conclusion: 该研究提出了一种新颖的在线学习定价和匹配算法，在处理未知市场参数的同时，实现了平台利润、学习效率和队列长度之间的最佳权衡。

Abstract: We study a two-sided market, wherein, price-sensitive heterogeneous customers
and servers arrive and join their respective queues. A compatible
customer-server pair can then be matched by the platform, at which point, they
leave the system. Our objective is to design pricing and matching algorithms
that maximize the platform's profit, while maintaining reasonable queue
lengths. As the demand and supply curves governing the price-dependent arrival
rates may not be known in practice, we design a novel online-learning-based
pricing policy and establish its near-optimality. In particular, we prove a
tradeoff among three performance metrics: $\tilde{O}(T^{1-\gamma})$ regret,
$\tilde{O}(T^{\gamma/2})$ average queue length, and $\tilde{O}(T^{\gamma})$
maximum queue length for $\gamma \in (0, 1/6]$, significantly improving over
existing results [1]. Moreover, barring the permissible range of $\gamma$, we
show that this trade-off between regret and average queue length is optimal up
to logarithmic factors under a class of policies, matching the optimal one as
in [2] which assumes the demand and supply curves to be known. Our proposed
policy has two noteworthy features: a dynamic component that optimizes the
tradeoff between low regret and small queue lengths; and a probabilistic
component that resolves the tension between obtaining useful samples for fast
learning and maintaining small queue lengths.

</details>


### [340] [Tawa: Automatic Warp Specialization for Modern GPUs with Asynchronous References](https://arxiv.org/abs/2510.14719)
*Hongzheng Chen,Bin Fan,Alexander Collins,Bastian Hagedorn,Evghenii Gaburov,Masahiro Masuda,Matthew Brookhart,Chris Sullivan,Jason Knight,Zhiru Zhang,Vinod Grover*

Main category: cs.LG

TL;DR: Tawa是一款编译器，可以从高级、基于块的程序自动生成高性能、warp专门化的代码，从而弥合了SIMT编程模型与GPU硬件之间的差距。


<details>
  <summary>Details</summary>
Motivation: 传统的SIMT编程模型与GPU的异步数据流硬件不匹配，导致编程困难。硬件级的warp专门化是发挥GPU性能的关键，但这需要手动进行底层通信和软件流水线编排，既耗时又容易出错。

Method: Tawa使用一种名为异步引用（aref）的新型IR抽象，用于表达warp级通信，而无需暴露底层硬件细节。基于此，Tawa能自动将程序划分为生产者-消费者角色，并管理数据流流水线，无需开发者进行侵入式内核重写。

Result: 在NVIDIA H100 GPU上对代表性LLM内核的评估表明，Tawa实现了高硬件利用率，与高度优化的cuBLAS GEMM内核相比，速度最高提升了1.1倍。对于注意力工作负载，Tawa的性能比Triton高1.2倍，并且在编程工作量远小于手动优化的CUTLASS C++ FlashAttention-3内核的情况下，达到了与其相当的性能。

Conclusion: Tawa通过提供一种高级抽象和自动化编译方法，解决了GPU编程的难题，使得开发者能够更容易地利用GPU的异步数据流能力，实现高性能计算。

Abstract: Modern GPUs feature specialized hardware units that enable high-performance,
asynchronous dataflow execution. However, the conventional SIMT programming
model is fundamentally misaligned with this task-parallel hardware, creating a
significant programmability gap. While hardware-level warp specialization is
the key to unlocking peak performance, it forces developers to manually
orchestrate complex, low-level communication and software pipelines--a process
that is labor-intensive, error-prone, and unsustainable. To address this
challenge, we present Tawa, an automated compiler that systematically generates
high-performance, warp-specialized code from a high-level, tile-based program.
Central to our approach is a novel IR abstraction, asynchronous references
(aref), which expresses warp-level communication without exposing low-level
hardware details. Using this abstraction, Tawa automatically partitions
programs into producer-consumer roles and manages the intricate dataflow
pipeline, relieving developers of invasive kernel rewriting. Evaluation on
NVIDIA H100 GPUs across representative LLM kernels shows that Tawa delivers
high hardware utilization, achieving up to 1.1$\times$ speedup over highly
optimized cuBLAS GEMM kernels. For attention workloads, Tawa attains
1.2$\times$ speedup over Triton and matches the performance of the
hand-optimized CUTLASS C++ FlashAttention-3 kernel with far less programming
effort.

</details>


### [341] [K-frames: Scene-Driven Any-k Keyframe Selection for long video understanding](https://arxiv.org/abs/2510.13891)
*Yifeng Yao,Yike Yun,Jing Wang,Huishuai Zhang,Dongyan Zhao,Ke Tian,Zhihao Wang,Minghui Qiu,Tao Wang*

Main category: cs.LG

TL;DR: K-frames是一种新颖的场景驱动关键帧选择范式，通过预测语义连贯、查询相关的视频片段来解决长视频理解中的上下文窗口和计算成本限制，解决了现有方法存在的稀疏、时间不连续和缺乏灵活性等问题。K-frames能够实现任意k个关键帧的选择，以满足不同的用户预算需求。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在长视频理解方面受到上下文窗口和计算成本的限制，导致信息丢失，并且现有的关键帧选择方法（如文本-帧检索或基于强化学习的帧优化）通常会产生稀疏且时间上不连续的帧，忽略了场景的连续性，并且缺乏多尺度帧选择的灵活性。

Method: K-frames通过预测语义连贯、查询相关的视频片段来保留时间连续性。首先，引入了包含200K视频摘要（由查询条件限定）的PeakClips数据集。然后，K-frames利用三阶段的渐进式课程学习（包括两个监督微调阶段，用于时间定位和关键片段感知，以及一个强化学习阶段，用于直接优化场景驱动的预测策略）来学习片段到帧的选择。

Result: 在主要的视频理解基准测试上的大量实验表明，K-frames在各种尺度上为关键帧选择提供了一个有效、可解释且即插即用的解决方案。

Conclusion: K-frames通过其场景驱动的关键帧选择方法，有效解决了长视频理解中的挑战，并在各种基准测试中取得了良好效果，为未来的研究和应用提供了新的途径。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
capabilities in image understanding, but long-video are constrained by context
windows and computational cost. Uniform frame sampling often leads to
substantial information loss. Meanwhile existing keyframe selection methods
such as text-frame retrieval or RL-based frame optimization typically yield
sparse and temporally disjointed frames, overlooking scene continuity and
lacking flexibility for multi-scale frame selection. To address these
limitations, we introduce K-frames, a novel paradigm for scene-driven keyframe
selection that preserves temporal continuity. Instead of selecting individual
frames, K-frames predicts semantically coherent, query-relevant clips, which
enables any-k keyframes selection to meet diverse user budgets. To achieve this
approach, we first introduce PeakClips, a dataset of 200K video highlights
conditioned by query. Building on this dataset, K-frames learns clip2frame
selection using a three-stage progressive curriculum. It involves two
Supervised Fine-Tuning stages for temporal grounding and key-clip perception,
followed by a Reinforcement Learning stage that directly optimizes the
scene-driven prediction policy for downstream task without further annotations.
Extensive experiments on major long-video understanding benchmarks demonstrate
that K-frames provides an effective, interpretable, and plug-and-play solution
for keyframe selection at various scales. Our dataset and model will be
available.

</details>


### [342] [Multi-View Semi-Supervised Label Distribution Learning with Local Structure Complementarity](https://arxiv.org/abs/2510.13917)
*Yanshan Xiao,Kaihong Wu,Bo Liu*

Main category: cs.LG

TL;DR: 本论文提出了一种名为MVSS-LDL的多视图半监督标签分布学习方法，解决了现有方法未考虑的多视图和有/无标签数据的LDL问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅限于单视图LDL问题，且仅使用有标签数据，未能解决多视图和包含有/无标签数据的LDL问题。

Method: 首先，通过计算k-最近邻来探索每个视图的局部结构。然后，通过整合其他视图中样本的最近邻来补充每个视图中样本的最近邻集，以获得更全面的描述。最后，基于每个视图中补充的最近邻集，构建了一个基于图学习的多视图半监督LDL模型。

Result: MVSS-LDL方法在分类性能上明显优于现有的单视图LDL方法。

Conclusion: MVSS-LDL是首个解决多视图半监督LDL问题的尝试，通过利用和补充多视图的局部近邻结构，实现了更好的分类性能。

Abstract: Label distribution learning (LDL) is a paradigm that each sample is
associated with a label distribution. At present, the existing approaches are
proposed for the single-view LDL problem with labeled data, while the
multi-view LDL problem with labeled and unlabeled data has not been considered.
In this paper, we put forward the multi-view semi-supervised label distribution
learning with local structure complementarity (MVSS-LDL) approach, which
exploits the local nearest neighbor structure of each view and emphasizes the
complementarity of local nearest neighbor structures in multiple views.
Specifically speaking, we first explore the local structure of view $v$ by
computing the $k$-nearest neighbors. As a result, the $k$-nearest neighbor set
of each sample $\boldsymbol{x}_i$ in view $v$ is attained. Nevertheless, this
$k$-nearest neighbor set describes only a part of the nearest neighbor
information of sample $\boldsymbol{x}_i$. In order to obtain a more
comprehensive description of sample $\boldsymbol{x}_i$'s nearest neighbors, we
complement the nearest neighbor set in view $v$ by incorporating sample
$\boldsymbol{x}_i$'s nearest neighbors in other views. Lastly, based on the
complemented nearest neighbor set in each view, a graph learning-based
multi-view semi-supervised LDL model is constructed. By considering the
complementarity of local nearest neighbor structures, different views can
mutually provide the local structural information to complement each other. To
the best of our knowledge, this is the first attempt at multi-view LDL.
Numerical studies have demonstrated that MVSS-LDL attains explicitly better
classification performance than the existing single-view LDL methods.

</details>


### [343] [Weight Weaving: Parameter Pooling for Data-Free Model Merging](https://arxiv.org/abs/2510.13921)
*Levy Chaves,Eduardo Valle,Sandra Avila*

Main category: cs.LG

TL;DR: 模型合并技术通过集成参数来组合专业深度神经网络，以实现成本效益和数据效率。然而，现有方法高度依赖于可扩展超参数λ的设置，而无需访问数据的、无数据的方法却很少。为解决此问题，本文提出了一种名为Weight Weaving的即插即用技术，它允许在不访问评估数据的情况下，通过用户定义的池化函数（如平均、随机选择或现有模型合并方法）跨λ值搜索空间来聚合模型权重。该方法具有高度模块化，对搜索空间限制最小，并且可以与现有模型合并方法正交运行。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法在设置关键缩放超参数λ时，通常需要访问评估数据集，这在实际应用中是不可行的。因此，需要一种无需访问数据即可确定λ的方法。

Method: 提出了一种名为Weight Weaving的即插即用技术，该技术允许在不访问评估数据的情况下，通过用户定义的池化函数（如平均、随机选择或现有模型合并方法）跨λ值搜索空间来聚合模型权重。该方法具有高度模块化，对搜索空间限制最小，并且可以与现有模型合并方法正交运行。

Result: 在视觉多任务学习、视觉持续学习和域泛化三个实验设置中，针对三种ViT变体进行了验证。结果表明，Weight Weaving在无数据的情况下，能够持续提高几种模型合并方法的性能，平均准确率提升高达15.9个百分点。

Conclusion: Weight Weaving是一种有效且通用的模型合并技术，它消除了对评估数据的需求，并能显著提高现有模型合并方法的性能。

Abstract: Model merging provides a cost-effective and data-efficient combination of
specialized deep neural networks through parameter integration. This technique
leverages expert models across downstream tasks without requiring retraining.
Most model merging approaches critically depend on scaling hyper-parameters
$\lambda$, which weight each model's contribution globally or individually.
Principled approaches for setting scaling factors without accessing any data
(data-free) are scarce, often leading researchers to tune $\lambda$ using
privileged data from the evaluation set, which is obviously unfeasible in
practice. To address this limitation, we introduce Weight Weaving, a
plug-and-play technique that pools model weights across $\lambda$ values search
space using user-defined pooling functions, such as averaging, random
selection, or even existing model merging methods. Our method demonstrates high
modularity, imposing minimal constraints on the search space. It operates
orthogonally to existing model merging methods and eliminates evaluation data
requirements. We validate Weight Weaving across three ViT variants in three
experimental setups: vision multi-task learning, vision continual learning, and
domain generalization. Our method consistently improves the performance of
several model merging methods, achieving average accuracy gains of up to 15.9
percentage points in a data-free setting.

</details>


### [344] [LTR-ICD: A Learning-to-Rank Approach for Automatic ICD Coding](https://arxiv.org/abs/2510.13922)
*Mohammad Mansoori,Amira Soliman,Farzaneh Etminani*

Main category: cs.LG

TL;DR: 本研究将ICD代码分配和排序视为检索任务，而非单纯的分类任务，以考虑代码顺序的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法将ICD代码分配视为分类任务，忽略了代码的顺序，而代码顺序对于医疗诊断和报销至关重要。

Method: 将ICD代码分配和排序的问题构建为一个分类和排序任务，并从检索系统的角度进行处理。

Result: 该方法在识别高优先级代码方面优于现有技术，主要诊断代码排序准确率达到47%，优于基线模型的20%。分类指标方面，微观和宏观F1分数分别为0.6065和0.2904，优于先前最佳模型的0.597和0.2660。

Conclusion: 本研究提出的框架在ICD代码分配和排序任务上表现出优越的性能，特别是在考虑代码顺序方面。

Abstract: Clinical notes contain unstructured text provided by clinicians during
patient encounters. These notes are usually accompanied by a sequence of
diagnostic codes following the International Classification of Diseases (ICD).
Correctly assigning and ordering ICD codes are essential for medical diagnosis
and reimbursement. However, automating this task remains challenging.
State-of-the-art methods treated this problem as a classification task, leading
to ignoring the order of ICD codes that is essential for different purposes. In
this work, as a first attempt, we approach this task from a retrieval system
perspective to consider the order of codes, thus formulating this problem as a
classification and ranking task. Our results and analysis show that the
proposed framework has a superior ability to identify high-priority codes
compared to other methods. For instance, our model accuracy in correctly
ranking primary diagnosis codes is 47%, compared to 20% for the
state-of-the-art classifier. Additionally, in terms of classification metrics,
the proposed model achieves a micro- and macro-F1 scores of 0.6065 and 0.2904,
respectively, surpassing the previous best model with scores of 0.597 and
0.2660.

</details>


### [345] [Distributional Consistency Loss: Beyond Pointwise Data Terms in Inverse Problems](https://arxiv.org/abs/2510.13972)
*George Webber,Andrew J. Reader*

Main category: cs.LG

TL;DR: 使用分布一致性（DC）损失替代传统的均方误差（MSE）损失，可以在不依赖先验知识的情况下，有效解决逆问题中的噪声过拟合问题，并在图像去噪和医学图像重建等领域取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的逆问题解决方案在正则化（对真实信号的先验假设）和数据保真度（与噪声数据的拟合程度）之间进行权衡。然而，传统的数据保真度损失函数（如MSE）通常寻求与噪声测量的逐点一致性，这容易导致对噪声的过拟合。

Method: 提出了一种新的数据保真度损失函数——分布一致性（DC）损失。与传统的逐点匹配不同，DC损失通过检验观测到的测量值是否与当前估计值所暗示的噪声分布在统计上一致来评估数据保真度。它使用基于模型的概率分数对每个测量值进行分布级校准，并可作为现有正则化器和优化算法的直接替代。

Result: 在图像去噪方面，使用DC损失代替MSE损失，无需提前停止即可获得更高的PSNR。在医学图像重建方面，DC损失能够减少高度迭代重建中的伪影，并提高手工设计的正则化的有效性。

Conclusion: DC损失是一种统计上合理且性能优越的数据保真度损失替代方案，适用于测量噪声分布已知且数据集包含多个独立噪声值的逆问题。

Abstract: Recovering true signals from noisy measurements is a central challenge in
inverse problems spanning medical imaging, geophysics, and signal processing.
Current solutions balance prior assumptions regarding the true signal
(regularization) with agreement to noisy measured data (data-fidelity).
Conventional data-fidelity loss functions, such as mean-squared error (MSE) or
negative log-likelihood, seek pointwise agreement with noisy measurements,
often leading to overfitting to noise. In this work, we instead evaluate
data-fidelity collectively by testing whether the observed measurements are
statistically consistent with the noise distributions implied by the current
estimate. We adopt this aggregated perspective and introduce distributional
consistency (DC) loss, a data-fidelity objective that replaces pointwise
matching with distribution-level calibration using model-based probability
scores for each measurement. DC loss acts as a direct and practical plug-in
replacement for standard data consistency terms: i) it is compatible with
modern regularizers, ii) it is optimized in the same way as traditional losses,
and iii) it avoids overfitting to measurement noise even without the use of
priors. Its scope naturally fits many practical inverse problems where the
measurement-noise distribution is known and where the measured dataset consists
of many independent noisy values. We demonstrate efficacy in two key example
application areas: i) in image denoising with deep image prior, using DC
instead of MSE loss removes the need for early stopping and achieves higher
PSNR; ii) in medical image reconstruction from Poisson-noisy data, DC loss
reduces artifacts in highly-iterated reconstructions and enhances the efficacy
of hand-crafted regularization. These results position DC loss as a
statistically grounded, performance-enhancing alternative to conventional
fidelity losses for inverse problems.

</details>


### [346] [BitNet Distillation](https://arxiv.org/abs/2510.13998)
*Xun Wu,Shaohan Huang,Wenhui Wang,Ting Song,Li Dong,Yan Xia,Furu Wei*

Main category: cs.LG

TL;DR: BitDistill是一个管道，可以将全精度LLM（例如Qwen）微调为1.58位精度（权重为{-1, 0, 1}），以实现特定的下游任务。


<details>
  <summary>Details</summary>
Motivation: BitDistill旨在通过微调现有的全精度LLM来为特定下游任务实现1.58位精度，从而以最小的计算成本获得强大的任务特定性能。

Method: BitDistill采用三种关键技术：子层归一化（SubLN）模块，多头注意力蒸馏，以及持续的预训练作为关键的热身步骤。

Result: BitDistill实现的性能与全精度模型相当，同时实现了高达10倍的内存节省和2.65倍的CPU推理速度提升。

Conclusion: BitDistill通过采用子层归一化模块、多头注意力蒸馏和持续预训练等技术，成功地将全精度LLM压缩为1.58位精度，在保持性能的同时显著降低了计算成本和内存占用。

Abstract: In this paper, we present BitNet Distillation (BitDistill), a lightweight
pipeline that fine-tunes off-the-shelf full-precision LLMs (e.g., Qwen) into
1.58-bit precision (i.e., ternary weights {-1, 0, 1}) for specific downstream
tasks, achieving strong task-specific performance with minimal computational
cost. Specifically, BitDistill incorporates three key techniques: the SubLN
module, as introduced in BitNet; multi-head attention distillation, based on
MiniLM; and continual pre-training, which serves as a crucial warm-up step to
mitigate the scalability issue of the performance gap between finetuned
full-precision and 1.58-bit LLMs on specific tasks. Experimental results show
that BitDistill achieves performance comparable to the full-precision
counterpart models across model size, while enabling up to 10x memory savings
and 2.65x faster inference on CPUs. Code is available at
https://github.com/microsoft/BitNet.

</details>


### [347] [REAP the Experts: Why Pruning Prevails for One-Shot MoE compression](https://arxiv.org/abs/2510.13999)
*Mike Lasby,Ivan Lazarevich,Nish Sinnadurai,Sean Lie,Yani Ioannou,Vithursan Thangarasa*

Main category: cs.LG

TL;DR: SMoE模型存在内存开销大的问题，本文提出了一种名为REAP的专家剪枝方法，在生成任务上优于专家合并方法。


<details>
  <summary>Details</summary>
Motivation: SMoE模型参数量大导致内存开销大，需要进行专家压缩。

Method: 提出了一种名为REAP（Router-weighted Expert Activation Pruning）的剪枝方法，该方法综合考虑了路由器的门控值和专家激活的范数。

Result: 在代码生成和工具调用等生成任务上，REAP方法在50%压缩率下优于专家合并和其他剪枝方法，实现了近乎无损的压缩。

Conclusion: 专家剪枝是比专家合并更优的SMoE模型压缩策略，尤其是在生成任务上。REAP方法能够实现高效且高质量的SMoE模型压缩。

Abstract: Sparsely-activated Mixture-of-Experts (SMoE) models offer efficient
pre-training and low latency but their large parameter counts create
significant memory overhead, motivating research into expert compression.
Contrary to recent findings favouring expert merging on discriminative
benchmarks, we demonstrate that expert pruning is a superior strategy for
generative tasks. We prove that merging introduces an irreducible error by
causing a "functional subspace collapse", due to the loss of the router's
independent, input-dependent control over experts. Leveraging this insight, we
propose Router-weighted Expert Activation Pruning (REAP), a novel pruning
criterion that considers both router gate-values and expert activation norms.
Across a diverse set of SMoE models ranging from 20B to 1T parameters, REAP
consistently outperforms merging and other pruning methods on generative
benchmarks, especially at 50% compression. Notably, our method achieves
near-lossless compression on code generation and tool-calling tasks with
Qwen3-Coder-480B and Kimi-K2, even after pruning 50% of experts.

</details>


### [348] [Conditional Clifford-Steerable CNNs with Complete Kernel Basis for PDE Modeling](https://arxiv.org/abs/2510.14007)
*Bálint László Szarvas,Maksim Zhdanov*

Main category: cs.LG

TL;DR: CSCNNs的核基不完整，限制了模型表达能力。通过引入条件CSCNNs，利用输入特征场计算出的等变表示来增强核，从而提高模型表达能力，并在多个偏微分方程预测任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: CSCNNs（Clifford-Steerable CNNs）虽然能统一框架并纳入任意伪欧几里得群的等变性，但其核基不完整，限制了模型表达能力，需要改进。

Method: 提出条件CSCNNs（Conditional Clifford-Steerable Kernels），通过引入输入特征场计算出的等变表示来增强核，并推导了输入相关核的等变约束，通过隐式参数化高效求解。

Result: 在流体动力学和相对论电动力学等多个偏微分方程预测任务中，条件CSCNNs相较于基线方法在模型表达能力和性能上均有提升，表现出优越性。

Conclusion: 条件CSCNNs通过增强核的表达能力，解决了CSCNNs的局限性，并在多个PDE预测任务中取得了显著的性能提升。

Abstract: Clifford-Steerable CNNs (CSCNNs) provide a unified framework that allows
incorporating equivariance to arbitrary pseudo-Euclidean groups, including
isometries of Euclidean space and Minkowski spacetime. In this work, we
demonstrate that the kernel basis of CSCNNs is not complete, thus limiting the
model expressivity. To address this issue, we propose Conditional
Clifford-Steerable Kernels, which augment the kernels with equivariant
representations computed from the input feature field. We derive the
equivariance constraint for these input-dependent kernels and show how it can
be solved efficiently via implicit parameterization. We empirically demonstrate
an improved expressivity of the resulting framework on multiple PDE forecasting
tasks, including fluid dynamics and relativistic electrodynamics, where our
method consistently outperforms baseline methods.

</details>


### [349] [FedHFT: Efficient Federated Finetuning with Heterogeneous Edge Clients](https://arxiv.org/abs/2510.14054)
*Fatih Ilhan,Selim Furkan Tekin,Tiansheng Huang,Gaowen Liu,Ramana Kompella,Greg Eisenhauer,Yingyan Celine Lin,Calton Pu,Ling Liu*

Main category: cs.LG

TL;DR: FedHFT是一个高效且个性化的联邦微调框架，用于解决LLM在下游任务和领域特定数据集上的个性化NLU应用中，数据有限/异构和计算资源不均的问题。


<details>
  <summary>Details</summary>
Motivation: LLM在下游任务和领域特定数据集上的个性化NLU应用中，存在数据有限/异构和计算资源不均的挑战。

Method: 提出FedHFT框架，采用混合掩码适配器处理计算资源异构性，并引入双层优化方法处理非独立同分布数据（基于掩码个性化和客户端聚类）。

Result: 与代表性的异构联邦学习方法相比，FedHFT在数据和资源异构的情况下，在各种NLU任务上显著提高了性能和效率。

Conclusion: FedHFT框架能够有效地解决LLM在数据有限/异构和计算资源不均情况下的联邦微调问题，并在NLU任务上取得优越的性能。

Abstract: Fine-tuning pre-trained large language models (LLMs) has become a common
practice for personalized natural language understanding (NLU) applications on
downstream tasks and domain-specific datasets. However, there are two main
challenges: (i) limited and/or heterogeneous data for fine-tuning due to
proprietary data confidentiality or privacy requirements, and (ii) varying
computation resources available across participating clients such as edge
devices. This paper presents FedHFT - an efficient and personalized federated
fine-tuning framework to address both challenges. First, we introduce a mixture
of masked adapters to handle resource heterogeneity across participating
clients, enabling high-performance collaborative fine-tuning of pre-trained
language model(s) across multiple clients in a distributed setting, while
keeping proprietary data local. Second, we introduce a bi-level optimization
approach to handle non-iid data distribution based on masked personalization
and client clustering. Extensive experiments demonstrate significant
performance and efficiency improvements over various natural language
understanding tasks under data and resource heterogeneity compared to
representative heterogeneous federated learning methods.

</details>


### [350] [Noise-Adaptive Layerwise Learning Rates: Accelerating Geometry-Aware Optimization for Deep Neural Network Training](https://arxiv.org/abs/2510.14009)
*Jie Hao,Xiaochuan Gong,Jie Xu,Zhengdao Wang,Mingrui Liu*

Main category: cs.LG

TL;DR: 该研究提出了一种噪声自适应的层级学习率方案，用于增强几何感知优化算法在深度神经网络训练中的性能，通过动态调整学习率以适应不同层的局部曲率变化，从而加速训练过程。


<details>
  <summary>Details</summary>
Motivation: 当前的几何感知优化算法（如Muon）在训练深度神经网络（DNN）方面取得了成功，但它们在处理同一范数组内的层时，未能充分考虑层与层之间以及训练过程中的局部曲率异质性。例如，Transformer层在训练过程中其锐度变化很大，而标准优化器对同一组内的层使用固定的学习率，这可能导致训练效率低下。

Method: 本研究提出了一种在几何感知优化算法基础上增加噪声自适应层级学习率的方案。该方案能够动态估计所选LMO诱导的双范数中的梯度方差，并利用该信息为组内的层分配随时间变化的、对噪声自适应的层级学习率，从而显著加速DNN训练。

Result: 通过在Transformer架构（如LLaMA和GPT）上的实证结果表明，该方法比最先进的优化器能够实现更快的收敛速度。

Conclusion: 该研究提出的噪声自适应层级学习率方案能够有效地加速深度神经网络的训练过程，并在理论上保证了算法的收敛速率。实验结果证明了其优于现有最先进优化器的性能。

Abstract: Geometry-aware optimization algorithms, such as Muon, have achieved
remarkable success in training deep neural networks (DNNs). These methods
leverage the underlying geometry of DNNs by selecting appropriate norms for
different layers and updating parameters via norm-constrained linear
minimization oracles (LMOs). However, even within a group of layers associated
with the same norm, the local curvature can be heterogeneous across layers and
vary dynamically over the course of training. For example, recent work shows
that sharpness varies substantially across transformer layers and throughout
training, yet standard geometry-aware optimizers impose fixed learning rates to
layers within the same group, which may be inefficient for DNN training.
  In this paper, we introduce a noise-adaptive layerwise learning rate scheme
on top of geometry-aware optimization algorithms and substantially accelerate
DNN training compared to methods that use fixed learning rates within each
group. Our method estimates gradient variance in the dual norm induced by the
chosen LMO on the fly, and uses it to assign time-varying noise-adaptive
layerwise learning rates within each group. We provide a theoretical analysis
showing that our algorithm achieves a sharp convergence rate. Empirical results
on transformer architectures such as LLaMA and GPT demonstrate that our
approach achieves faster convergence than state-of-the-art optimizers.

</details>


### [351] [Incentive-Based Federated Learning](https://arxiv.org/abs/2510.14208)
*Chanuka A. S. Hewa Kaluannakkage,Rajkumar Buyya*

Main category: cs.LG

TL;DR: 联邦学习在保护数据隐私的前提下，通过协作训练模型，有潜力革新机器学习。然而，参与困境等因素限制了其实际适应性，参与方可能因缺乏收益或搭便车而不愿贡献。本章探讨了联邦学习激励机制设计的核心挑战，并介绍了经济学、博弈论、区块链和深度强化学习等相关理论与技术。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中参与方可能面临的参与困境（不愿贡献或搭便车）问题，设计有效的激励机制以促进系统的实际应用和可持续性。

Method: 研究了经济学和博弈论的基本概念，并结合区块链和深度强化学习等技术驱动的解决方案，构建了包括中心化和去中心化架构的分类体系，并从应用角度探讨了医疗、智能基础设施、车联网和区块链等领域的工业应用。

Result: 提出了一个全面的分类体系，涵盖了基于经济学和博弈论概念的中心化和去中心化联邦学习架构，并展示了这些概念在医疗、智能基础设施、车联网和区块链等领域的应用前景。

Conclusion: 设计良好的激励机制对于联邦学习的成功至关重要，而非可有可无的附加功能。研究揭示了现有解决方案的潜力和仍面临的重大挑战，这些挑战关系到构建真正可持续、公平和健壮的联邦学习生态系统。

Abstract: Federated learning promises to revolutionize machine learning by enabling
collaborative model training without compromising data privacy. However,
practical adaptability can be limited by critical factors, such as the
participation dilemma. Participating entities are often unwilling to contribute
to a learning system unless they receive some benefits, or they may pretend to
participate and free-ride on others. This chapter identifies the fundamental
challenges in designing incentive mechanisms for federated learning systems. It
examines how foundational concepts from economics and game theory can be
applied to federated learning, alongside technology-driven solutions such as
blockchain and deep reinforcement learning. This work presents a comprehensive
taxonomy that thoroughly covers both centralized and decentralized
architectures based on the aforementioned theoretical concepts. Furthermore,
the concepts described are presented from an application perspective, covering
emerging industrial applications, including healthcare, smart infrastructure,
vehicular networks, and blockchain-based decentralized systems. Through this
exploration, this chapter demonstrates that well-designed incentive mechanisms
are not merely optional features but essential components for the practical
success of federated learning. This analysis reveals both the promising
solutions that have emerged and the significant challenges that remain in
building truly sustainable, fair, and robust federated learning ecosystems.

</details>


### [352] [Context-Selective State Space Models: Feedback is All You Need](https://arxiv.org/abs/2510.14027)
*Riccardo Zattra,Giacomo Baggio,Umberto Casti,Augusto Ferrante,Francesco Ticozzi*

Main category: cs.LG

TL;DR: COFFEE是一个新颖的时变状态空间模型（SSM），通过引入状态反馈来增强上下文感知选择性，实现了与S6相比参数量和训练序列数量减少了两个数量级，并在MNIST等基准测试中取得了优于S6的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽然强大，但存在二次复杂度和处理长距离依赖的困难。现有SSM（如Mamba中的S6）虽是有效替代，但其选择性机制仅依赖当前输入，限制了对序列历史的充分利用。

Method: COFFEE模型是一种新颖的时变SSM，其核心在于引入了状态反馈机制。与S6仅依赖当前输入计算选择性不同，COFFEE利用内部状态（作为序列历史的紧凑表示）来计算上下文相关的选择性。此外，COFFEE采用了一种高效的模型参数化方法，消除了S6中的冗余，使其更紧凑、更易于训练。

Result: COFFEE模型在多项任务上表现出色。在特定任务上，其参数量和训练序列数量仅为S6的百分之一，就能达到接近完美的准确率。在MNIST数据集上，COFFEE以远少于S6的参数量取得了97%的准确率，显著优于S6。

Conclusion: 状态反馈是构建可扩展且高效的序列模型的一个关键机制。COFFEE模型通过引入状态反馈，展示了其在处理长距离依赖和提高模型效率方面的潜力。

Abstract: Transformers, powered by the attention mechanism, are the backbone of most
foundation models, yet they suffer from quadratic complexity and difficulties
in dealing with long-range dependencies in the input sequence. Recent work has
shown that state space models (SSMs) provide an efficient alternative, with the
S6 module at the core of the Mamba architecture achieving state-of-the-art
results on long-sequence benchmarks. In this paper, we introduce the COFFEE
(COntext From FEEdback) model, a novel time-varying SSM that incorporates state
feedback to enable context-dependent selectivity, while still allowing for
parallel implementation. Whereas the selectivity mechanism of S6 only depends
on the current input, COFFEE computes it from the internal state, which serves
as a compact representation of the sequence history. This shift allows the
model to regulate its dynamics based on accumulated context, improving its
ability to capture long-range dependencies. In addition to state feedback, we
employ an efficient model parametrization that removes redundancies present in
S6 and leads to a more compact and trainable formulation. On the induction head
task, COFFEE achieves near-perfect accuracy with two orders of magnitude fewer
parameters and training sequences compared to S6. On MNIST, COFFEE largely
outperforms S6 within the same architecture, reaching 97% accuracy with only
3585 parameters. These results showcase the role of state feedback as a key
mechanism for building scalable and efficient sequence models.

</details>


### [353] [Learning Wireless Interference Patterns: Decoupled GNN for Throughput Prediction in Heterogeneous Multi-Hop p-CSMA Networks](https://arxiv.org/abs/2510.14137)
*Faezeh Dehghan Tarzjani,Bhaskar Krishnamachari*

Main category: cs.LG

TL;DR: p-persistent CSMA协议在多跳无线网络中的吞吐量预测是一个难题。现有的简化模型和精确的马尔可夫链分析各有局限。我们提出了Decoupled Graph Convolutional Network (D-GCN)，一种新颖的图神经网络架构，通过分离节点自身传输概率和邻居干扰效应的处理，提高了预测精度和可扩展性，并实现了接近理论最优的网络优化。


<details>
  <summary>Details</summary>
Motivation: 预测多跳无线网络中p-persistent CSMA协议的饱和吞吐量仍然是一个难题，现有的模型在稀疏拓扑中会低估吞吐量，而精确的马尔可夫链分析在计算上不可行。

Method: 提出了一种名为Decoupled Graph Convolutional Network (D-GCN)的新颖架构，该架构通过使用可学习的注意力机制代替平均聚合，明确分离了节点自身传输概率的处理与邻居干扰效应的处理，从而捕捉复杂的跳数干扰模式。

Result: D-GCN的归一化平均绝对误差（NMAE）仅为3.3%，优于现有基线方法，并且在精确分析方法变得不可行时仍保持可行性。此外，D-GCN还能实现接近理论最优的网络优化。

Conclusion: D-GCN通过明确分离节点自身传输概率和邻居干扰效应的处理，能够准确且可扩展地预测多跳无线网络中的吞吐量，并为网络优化提供了新的途径。

Abstract: The p-persistent CSMA protocol is central to random-access MAC analysis, but
predicting saturation throughput in heterogeneous multi-hop wireless networks
remains a hard problem. Simplified models that assume a single, shared
interference domain can underestimate throughput by 48--62\% in sparse
topologies. Exact Markov-chain analyses are accurate but scale exponentially in
computation time, making them impractical for large networks. These
computational barriers motivate structural machine learning approaches like
GNNs for scalable throughput prediction in general network topologies. Yet
off-the-shelf GNNs struggle here: a standard GCN yields 63.94\% normalized mean
absolute error (NMAE) on heterogeneous networks because symmetric normalization
conflates a node's direct interference with higher-order, cascading effects
that pertain to how interference propagates over the network graph.
  Building on these insights, we propose the Decoupled Graph Convolutional
Network (D-GCN), a novel architecture that explicitly separates processing of a
node's own transmission probability from neighbor interference effects. D-GCN
replaces mean aggregation with learnable attention, yielding interpretable,
per-neighbor contribution weights while capturing complex multihop interference
patterns. D-GCN attains 3.3\% NMAE, outperforms strong baselines, remains
tractable even when exact analytical methods become computationally infeasible,
and enables gradient-based network optimization that achieves within 1\% of
theoretical optima.

</details>


### [354] [CausalVerse: Benchmarking Causal Representation Learning with Configurable High-Fidelity Simulations](https://arxiv.org/abs/2510.14049)
*Guangyi Chen,Yunlong Deng,Peiyuan Zhu,Yan Li,Yifan Sheng,Zijian Li,Kun Zhang*

Main category: cs.LG

TL;DR: 本研究提出了一个名为CausalVerse的新基准，用于评估因果表征学习（CRL）方法。该基准使用高保真度模拟视觉数据，包含20万张图像和300万个视频帧，涵盖静态图像生成、物理模拟、机器人操作和交通分析等24个子场景。CausalVerse提供了真实世界的复杂性和可访问的因果生成过程真相，解决了现有基准在真实性和评估精度之间的困境。此外，它还允许用户修改和配置因果结构，并对现有的CRL方法进行了评估，提供了实证见解。


<details>
  <summary>Details</summary>
Motivation: 因果表征学习（CRL）的评估具有挑战性，现有方法要么依赖过于简化的合成数据集，要么依赖下游任务表现，在真实性和评估精度之间存在两难。

Method: 提出了一个使用高保真模拟视觉数据的新基准CausalVerse，该数据集包含20万张图像和300万个视频帧，覆盖24个子场景，并提供对底层因果结构的灵活访问。利用该基准评估了各种CRL方法。

Result: CausalVerse基准在真实性和评估精度之间取得了平衡，并且对现有CRL方法进行了评估，提供了实证见解。

Conclusion: CausalVerse是一个有价值的基准，可以促进CRL领域的研究，并为研究人员和实践者提供指导。

Abstract: Causal Representation Learning (CRL) aims to uncover the data-generating
process and identify the underlying causal variables and relations, whose
evaluation remains inherently challenging due to the requirement of known
ground-truth causal variables and causal structure. Existing evaluations often
rely on either simplistic synthetic datasets or downstream performance on
real-world tasks, generally suffering a dilemma between realism and evaluative
precision. In this paper, we introduce a new benchmark for CRL using
high-fidelity simulated visual data that retains both realistic visual
complexity and, more importantly, access to ground-truth causal generating
processes. The dataset comprises around 200 thousand images and 3 million video
frames across 24 sub-scenes in four domains: static image generation, dynamic
physical simulations, robotic manipulations, and traffic situation analysis.
These scenarios range from static to dynamic settings, simple to complex
structures, and single to multi-agent interactions, offering a comprehensive
testbed that hopefully bridges the gap between rigorous evaluation and
real-world applicability. In addition, we provide flexible access to the
underlying causal structures, allowing users to modify or configure them to
align with the required assumptions in CRL, such as available domain labels,
temporal dependencies, or intervention histories. Leveraging this benchmark, we
evaluated representative CRL methods across diverse paradigms and offered
empirical insights to assist practitioners and newcomers in choosing or
extending appropriate CRL frameworks to properly address specific types of real
problems that can benefit from the CRL perspective. Welcome to visit our:
Project page:https://causal-verse.github.io/,
Dataset:https://huggingface.co/CausalVerse.

</details>


### [355] [On the expressivity of sparse maxout networks](https://arxiv.org/abs/2510.14068)
*Moritz Grillo,Tobias Hofmann*

Main category: cs.LG

TL;DR: 稀疏maxout网络的表达能力与虚拟多面体的对偶关系，并推导了多面体的维度界限，以此来分析网络的深度和宽度限制。


<details>
  <summary>Details</summary>
Motivation: 研究稀疏maxout网络的表达能力，这种网络借鉴了卷积或图神经网络的关键特征。

Method: 将网络表达能力与虚拟多面体联系起来，并推导了多面体的维度界限。

Result: 推导了多面体的维度界限，并构建了深度层级结构。证明了稀疏maxout网络在达到足够深度时具有通用性，但如果深度不足，固定输入度约束下的宽度无法弥补稀疏性。

Conclusion: 稀疏maxout网络的表达能力与其对应的虚拟多面体的几何特性相关。在深度不足的情况下，增加宽度不能克服稀疏性带来的限制。

Abstract: We study the expressivity of sparse maxout networks, where each neuron takes
a fixed number of inputs from the previous layer and employs a, possibly
multi-argument, maxout activation. This setting captures key characteristics of
convolutional or graph neural networks. We establish a duality between
functions computable by such networks and a class of virtual polytopes, linking
their geometry to questions of network expressivity. In particular, we derive a
tight bound on the dimension of the associated polytopes, which serves as the
central tool for our analysis. Building on this, we construct a sequence of
depth hierarchies. While sufficiently deep sparse maxout networks are
universal, we prove that if the required depth is not reached, width alone
cannot compensate for the sparsity of a fixed indegree constraint.

</details>


### [356] [Exploratory Causal Inference in SAEnce](https://arxiv.org/abs/2510.14073)
*Tommaso Mencattini,Riccardo Cadei,Francesco Locatello*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“神经效应搜索”的新方法，用于直接从数据中发现因果效应，以解决传统随机对照试验的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的随机对照试验依赖于手工假设和昂贵的分析，限制了大规模因果效应估计，并可能受限于流行但不完整的假设。本研究旨在直接从数据中发现未知的治疗效应。

Method: 将试验的非结构化数据通过预训练的基金模型转化为有意义的表示，并通过稀疏自编码器进行解释。提出了一种名为“神经效应搜索”的新型递归程序，通过渐进分层来解决多重检验和效应纠缠问题。

Result: 在半合成实验上评估了算法的稳健性，并在实验生态学的背景下，成功地对真实世界的科学试验进行了无监督因果效应识别。

Conclusion: 提出了一种名为“神经效应搜索”的新方法，可以直接从数据中发现因果效应，解决了传统随机对照试验的局限性，并在实验生态学的真实世界试验中取得了成功。

Abstract: Randomized Controlled Trials are one of the pillars of science; nevertheless,
they rely on hand-crafted hypotheses and expensive analysis. Such constraints
prevent causal effect estimation at scale, potentially anchoring on popular yet
incomplete hypotheses. We propose to discover the unknown effects of a
treatment directly from data. For this, we turn unstructured data from a trial
into meaningful representations via pretrained foundation models and interpret
them via a sparse autoencoder. However, discovering significant causal effects
at the neural level is not trivial due to multiple-testing issues and effects
entanglement. To address these challenges, we introduce Neural Effect Search, a
novel recursive procedure solving both issues by progressive stratification.
After assessing the robustness of our algorithm on semi-synthetic experiments,
we showcase, in the context of experimental ecology, the first successful
unsupervised causal effect identification on a real-world scientific trial.

</details>


### [357] [Neural Network approximation power on homogeneous and heterogeneous reaction-diffusion equations](https://arxiv.org/abs/2510.14094)
*Haotian Feng*

Main category: cs.LG

TL;DR: 神经网络可以近似求解反应扩散方程，为基于神经网络的求解器提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于使用机器学习技术求解微分方程，但缺乏对神经网络近似能力的理论解释。

Method: 对一维和二维反应扩散方程（包括均匀和非均匀介质）进行了理论分析，并基于通用近似定理，证明了特定层数的神经网络可以近似这些方程。

Result: 证明了双层神经网络可用于近似一维反应扩散方程，三层神经网络可用于近似二维反应扩散方程。

Conclusion: 这项工作强调了神经网络在近似反应扩散方程及其相关偏微分方程解方面的表达能力，并为神经网络求解器奠定了理论基础。

Abstract: Reaction-diffusion systems represent one of the most fundamental formulations
used to describe a wide range of physical, chemical, and biological processes.
With the increasing adoption of neural networks, recent research has focused on
solving differential equations using machine learning techniques. However, the
theoretical foundation explaining why neural networks can effectively
approximate such solutions remains insufficiently explored.
  This paper provides a theoretical analysis of the approximation power of
neural networks for one- and two-dimensional reaction-diffusion equations in
both homogeneous and heterogeneous media. Building upon the universal
approximation theorem, we demonstrate that a two-layer neural network can
approximate the one-dimensional reaction-diffusion equation, while a
three-layer neural network can approximate its two-dimensional counterpart. The
theoretical framework presented here can be further extended to elliptic and
parabolic equations.
  Overall, this work highlights the expressive power of neural networks in
approximating solutions to reaction-diffusion equations and related PDEs,
providing a theoretical foundation for neural network-based differential
equation solvers.

</details>


### [358] [Unlocking Out-of-Distribution Generalization in Transformers via Recursive Latent Space Reasoning](https://arxiv.org/abs/2510.14095)
*Awni Altabaa,Siyu Chen,John Lafferty,Zhuoran Yang*

Main category: cs.LG

TL;DR: Transformer 网络在处理超出训练分布的组合泛化问题上仍面临挑战。本研究提出四种增强泛化能力的结构机制（输入自适应递归、算法监督、离散瓶颈锚定潜在表征、显式纠错），并在计算图上的 GSM8K 风格模块化算术任务上进行了测试。实验结果和机制可解释性分析表明，这些机制能提升 Transformer 的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 系统性的、超出训练分布的组合泛化是机器学习的核心挑战，也是现代语言模型推理能力的关键瓶颈。

Method: 提出并探索了四种旨在增强 OOD 泛化能力的结构机制：(i) 输入自适应递归；(ii) 算法监督；(iii) 通过离散瓶颈锚定潜在表征；(iv) 显式纠错机制。

Result: 这些机制共同提供了一种在 Transformer 网络中实现原生、可扩展的潜在空间推理的结构方法，并具备强大的算法泛化能力。

Conclusion: 所提出的四种结构机制能有效提升 Transformer 网络在处理超出训练分布的组合泛化问题上的能力，并通过机制可解释性分析揭示了其泛化能力的来源。

Abstract: Systematic, compositional generalization beyond the training distribution
remains a core challenge in machine learning -- and a critical bottleneck for
the emergent reasoning abilities of modern language models. This work
investigates out-of-distribution (OOD) generalization in Transformer networks
using a GSM8K-style modular arithmetic on computational graphs task as a
testbed. We introduce and explore a set of four architectural mechanisms aimed
at enhancing OOD generalization: (i) input-adaptive recurrence; (ii)
algorithmic supervision; (iii) anchored latent representations via a discrete
bottleneck; and (iv) an explicit error-correction mechanism. Collectively,
these mechanisms yield an architectural approach for native and scalable latent
space reasoning in Transformer networks with robust algorithmic generalization
capabilities. We complement these empirical results with a detailed mechanistic
interpretability analysis that reveals how these mechanisms give rise to robust
OOD generalization abilities.

</details>


### [359] [TENDE: Transfer Entropy Neural Diffusion Estimation](https://arxiv.org/abs/2510.14096)
*Simon Pedro Galeano Munoz,Mustapha Bounoua,Giulio Franzese,Pietro Michiardi,Maurizio Filippone*

Main category: cs.LG

TL;DR: TENDE是一种新的基于扩散模型的方法，用于估计时间序列的迁移熵，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的迁移熵估计方法存在维度灾难、分布假设限制以及收敛需要指数级大数据集等问题。

Method: TENDE利用基于分数的扩散模型，通过学习相关条件分布的得分函数来估计条件互信息，进而估计迁移熵。

Result: 与现有的神经估计器和其他最先进的方法相比，TENDE在合成基准和实际数据中表现出优越的准确性和鲁棒性。

Conclusion: TENDE提供了一种灵活、可扩展的迁移熵估计方法，对潜在数据生成过程的假设最少。

Abstract: Transfer entropy measures directed information flow in time series, and it
has become a fundamental quantity in applications spanning neuroscience,
finance, and complex systems analysis. However, existing estimation methods
suffer from the curse of dimensionality, require restrictive distributional
assumptions, or need exponentially large datasets for reliable convergence. We
address these limitations in the literature by proposing TENDE (Transfer
Entropy Neural Diffusion Estimation), a novel approach that leverages
score-based diffusion models to estimate transfer entropy through conditional
mutual information. By learning score functions of the relevant conditional
distributions, TENDE provides flexible, scalable estimation while making
minimal assumptions about the underlying data-generating process. We
demonstrate superior accuracy and robustness compared to existing neural
estimators and other state-of-the-art approaches across synthetic benchmarks
and real data.

</details>


### [360] [Briding Diffusion Posterior Sampling and Monte Carlo methods: a survey](https://arxiv.org/abs/2510.14114)
*Yazid Janati,Alain Durmus,Jimmy Olsson,Eric Moulines*

Main category: cs.LG

TL;DR: 预训练的扩散模型可与蒙特卡洛方法结合，用于解决贝叶斯逆问题，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 文章旨在全面概述利用预训练的扩散模型和蒙特卡洛方法解决贝叶斯逆问题的现有技术，重点在于无需额外训练。

Method: 该方法主要通过在扩散过程中使用“扭曲”机制来调整中间分布，以引导模拟趋向后验分布，并结合各种蒙特卡洛方法从扭曲的分布中采样。

Result: 文章介绍了多种将预训练扩散模型与蒙特卡洛方法结合以解决贝叶斯逆问题的技术，并解释了它们如何通过扭曲中间分布和利用蒙特卡洛采样来生成样本。

Conclusion: 预训练的扩散模型与蒙特卡洛方法相结合，为解决贝叶斯逆问题提供了一种无需额外训练的有效途径，主要通过扭曲扩散过程中的中间分布来实现。

Abstract: Diffusion models enable the synthesis of highly accurate samples from complex
distributions and have become foundational in generative modeling. Recently,
they have demonstrated significant potential for solving Bayesian inverse
problems by serving as priors. This review offers a comprehensive overview of
current methods that leverage \emph{pre-trained} diffusion models alongside
Monte Carlo methods to address Bayesian inverse problems without requiring
additional training. We show that these methods primarily employ a
\emph{twisting} mechanism for the intermediate distributions within the
diffusion process, guiding the simulations toward the posterior distribution.
We describe how various Monte Carlo methods are then used to aid in sampling
from these twisted distributions.

</details>


### [361] [Neural Network-enabled Domain-consistent Robust Optimisation for Global CO$_2$ Reduction Potential of Gas Power Plants](https://arxiv.org/abs/2510.14125)
*Waqar Muhammad Ashraf,Talha Ansar,Abdulelah S. Alshehri,Peipei Chen,Ramit Debnath,Vivek Dua*

Main category: cs.LG

TL;DR: 一个结合了数据驱动域约束和非线性规划的神经网络鲁棒优化框架，解决了参数化神经网络模型与优化求解器交互产生的域不一致解的问题。该框架应用于一个1180兆瓦联合循环燃气电厂，实现了0.76个百分点的平均能效提升，并估计可将全球燃气电厂的二氧化碳减排量每年减少2600万吨。


<details>
  <summary>Details</summary>
Motivation: 解决参数化神经网络模型与优化求解器交互产生的域不一致解的问题，该问题在现有研究中被忽视。

Method: 提出一个神经网络驱动的鲁棒优化框架，将数据驱动域作为约束整合到非线性规划技术中。

Result: 在1180兆瓦联合循环燃气电厂的应用中，实现了域一致的鲁棒最优解，平均能效提升了0.76个百分点。将此效率提升扩展到全球燃气电厂，估计每年可减少2600万吨二氧化碳排放（亚洲1060万吨，美洲900万吨，欧洲450万吨）。

Conclusion: 机器学习在实现近中期、可扩展的脱碳路径方面发挥着协同作用，为全球气候行动提供了支持。

Abstract: We introduce a neural network-driven robust optimisation framework that
integrates data-driven domain as a constraint into the nonlinear programming
technique, addressing the overlooked issue of domain-inconsistent solutions
arising from the interaction of parametrised neural network models with
optimisation solvers. Applied to a 1180 MW capacity combined cycle gas power
plant, our framework delivers domain-consistent robust optimal solutions that
achieve a verified 0.76 percentage point mean improvement in energy efficiency.
For the first time, scaling this efficiency gain to the global fleet of gas
power plants, we estimate an annual 26 Mt reduction potential in CO$_2$ (with
10.6 Mt in Asia, 9.0 Mt in the Americas, and 4.5 Mt in Europe). These results
underscore the synergetic role of machine learning in delivering near-term,
scalable decarbonisation pathways for global climate action.

</details>


### [362] [Demystifying the Mechanisms Behind Emergent Exploration in Goal-conditioned RL](https://arxiv.org/abs/2510.14129)
*Mahsa Bastankhah,Grace Liu,Dilip Arumugam,Thomas L. Griffiths,Benjamin Eysenbach*

Main category: cs.LG

TL;DR: SGCRL是一种能够解决长时域目标到达任务的无监督强化学习算法，它通过学习到的表示来最大化隐式奖励，从而驱动探索。


<details>
  <summary>Details</summary>
Motivation: 阐明无监督强化学习中涌现探索的机制。

Method: 结合对算法目标函数的理论分析和受控实验，研究SGCRL算法。

Result: SGCRL通过学习到的表示来最大化隐式奖励，这些表示能够自动修改奖励格局，先促进探索，后进行利用。这些探索动力源于学习状态空间的低秩表示，而非神经网络函数逼近。

Conclusion: 对SGCRL的理解使我们能够进行安全感知的探索。

Abstract: In this work, we take a first step toward elucidating the mechanisms behind
emergent exploration in unsupervised reinforcement learning. We study
Single-Goal Contrastive Reinforcement Learning (SGCRL), a self-supervised
algorithm capable of solving challenging long-horizon goal-reaching tasks
without external rewards or curricula. We combine theoretical analysis of the
algorithm's objective function with controlled experiments to understand what
drives its exploration. We show that SGCRL maximizes implicit rewards shaped by
its learned representations. These representations automatically modify the
reward landscape to promote exploration before reaching the goal and
exploitation thereafter. Our experiments also demonstrate that these
exploration dynamics arise from learning low-rank representations of the state
space rather than from neural network function approximation. Our improved
understanding enables us to adapt SGCRL to perform safety-aware exploration.

</details>


### [363] [Inferred global dense residue transition graphs from primary structure sequences enable protein interaction prediction via directed graph convolutional neural networks](https://arxiv.org/abs/2510.14139)
*Islam Akef Ebeid,Haoteng Tang,Pengfei Gu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为ProtGram-DirectGCN的新框架，通过图表示学习进行蛋白质-蛋白质相互作用（PPI）预测，相比现有方法计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有的蛋白质-蛋白质相互作用（PPI）预测方法计算成本高，本研究旨在探索计算成本更低但预测能力强的替代方法。

Method: 本研究提出了一种名为ProtGram-DirectGCN的两阶段图表示学习框架。第一阶段，使用ProtGram模型将蛋白质的一级结构表示为全局推理的n-gram图，其中节点是残基，边的权重由残基转换概率定义。第二阶段，提出DirectGCN模型，一种自定义的有向图卷积神经网络，包含独特的卷积层，能够分别处理传入、传出和无向路径信息，并通过可学习的门控机制进行组合。最后，将DirectGCN应用于ProtGram图，学习残基级嵌入，并通过注意力机制池化得到蛋白质级嵌入用于预测。

Result: DirectGCN在节点分类基准测试中表现出色，其性能与现有方法相当，尤其擅长处理复杂、有向、密集、异质图。在PPI预测任务中，完整的ProtGram-DirectGCN框架即使在训练数据有限的情况下也展现出强大的预测能力。

Conclusion: ProtGram-DirectGCN框架是一种计算效率高且预测能力强的PPI预测新方法，特别适用于训练数据有限的情况。

Abstract: Introduction Accurate prediction of protein-protein interactions (PPIs) is
crucial for understanding cellular functions and advancing drug development.
Existing in-silico methods use direct sequence embeddings from Protein Language
Models (PLMs). Others use Graph Neural Networks (GNNs) for 3D protein
structures. This study explores less computationally intensive alternatives. We
introduce a novel framework for downstream PPI prediction through link
prediction. Methods We introduce a two-stage graph representation learning
framework, ProtGram-DirectGCN. First, we developed ProtGram. This approach
models a protein's primary structure as a hierarchy of globally inferred n-gram
graphs. In these graphs, residue transition probabilities define edge weights.
Each edge connects a pair of residues in a directed graph. The probabilities
are aggregated from a large corpus of sequences. Second, we propose DirectGCN,
a custom directed graph convolutional neural network. This model features a
unique convolutional layer. It processes information through separate
path-specific transformations: incoming, outgoing, and undirected. A shared
transformation is also applied. These paths are combined via a learnable gating
mechanism. We apply DirectGCN to ProtGram graphs to learn residue-level
embeddings. These embeddings are pooled via attention to generate protein-level
embeddings for prediction. Results We first established the efficacy of
DirectGCN on standard node classification benchmarks. Its performance matches
established methods on general datasets. The model excels at complex, directed
graphs with dense, heterophilic structures. When applied to PPI prediction, the
full ProtGram-DirectGCN framework delivers robust predictive power. This strong
performance holds even with limited training data.

</details>


### [364] [On Evaluating Loss Functions for Stock Ranking: An Empirical Analysis With Transformer Model](https://arxiv.org/abs/2510.14156)
*Jan Kwiatkowski,Jarosław A. Chudziak*

Main category: cs.LG

TL;DR: 本研究比较了不同的损失函数对Transformer模型在股票排序方面的表现影响，旨在优化量化交易策略。


<details>
  <summary>Details</summary>
Motivation: 金融市场需要准确的股票排序来指导投资组合管理，而现有的标准损失函数在训练Transformer模型进行股票排序方面存在不足，缺乏对不同排序损失函数的系统性比较。

Method: 本文系统地评估了多种先进的排序损失函数（包括点wise, pair-wise, list-wise），并将它们应用于基于Transformer的每日股票收益预测，以评估它们在股票排序能力上的表现，并使用S&P 500数据进行了实证研究。

Result: 研究结果揭示了不同损失函数对模型学习横截面和时间模式能力的影响，这些模式对于投资组合选择至关重要，并为优化基于排序的交易策略提供了实际指导。

Conclusion: 通过对不同损失函数在股票排序任务上的效果进行全面基准测试，本研究为选择最适合Transformer模型的损失函数以提升量化交易策略的盈利能力提供了依据。

Abstract: Quantitative trading strategies rely on accurately ranking stocks to identify
profitable investments. Effective portfolio management requires models that can
reliably order future stock returns. Transformer models are promising for
understanding financial time series, but how different training loss functions
affect their ability to rank stocks well is not yet fully understood. Financial
markets are challenging due to their changing nature and complex relationships
between stocks. Standard loss functions, which aim for simple prediction
accuracy, often aren't enough. They don't directly teach models to learn the
correct order of stock returns. While many advanced ranking losses exist from
fields such as information retrieval, there hasn't been a thorough comparison
to see how well they work for ranking financial returns, especially when used
with modern Transformer models for stock selection. This paper addresses this
gap by systematically evaluating a diverse set of advanced loss functions
including pointwise, pairwise, listwise for daily stock return forecasting to
facilitate rank-based portfolio selection on S&P 500 data. We focus on
assessing how each loss function influences the model's ability to discern
profitable relative orderings among assets. Our research contributes a
comprehensive benchmark revealing how different loss functions impact a model's
ability to learn cross-sectional and temporal patterns crucial for portfolio
selection, thereby offering practical guidance for optimizing ranking-based
trading strategies.

</details>


### [365] [Data Understanding Survey: Pursuing Improved Dataset Characterization Via Tensor-based Methods](https://arxiv.org/abs/2510.14161)
*Matthew D. Merris,Tim Andersen*

Main category: cs.LG

TL;DR: 现有的数据集表征方法（如统计、结构和基于模型的方法）在机器学习和数据分析领域往往无法提供深入的理解和见解。本研究探讨了当前传统数据分析技术的最新进展及其局限性，并讨论了各种基于张量的方法，以及它们如何能为传统的统计、结构和基于模型的数据集表征技术提供更稳健的替代方案。通过示例，我们说明了张量方法如何揭示细微的数据特征，提供增强的可解释性和可操作的智能。我们主张采用基于张量的方法进行表征，有望在理解复杂数据集方面取得重大进展，并为智能、可解释的数据驱动的发现铺平道路。


<details>
  <summary>Details</summary>
Motivation: 现有的统计、结构和基于模型的数据分析方法在提供深入理解和洞察方面存在不足，而这对于机器学习和数据分析的创新及可解释性至关重要。

Method: 本文对当前传统数据分析技术进行了调研，并探讨了基于张量的方法作为一种更稳健的替代方案，通过示例说明了张量方法的优势。

Result: 张量方法能够揭示细微的数据特征，提供更强的可解释性和可操作的智能，从而改进数据集表征。

Conclusion: 基于张量的数据集表征方法相比传统方法具有优势，能够实现对复杂数据集的深入理解，并促进智能、可解释的数据驱动的发现。

Abstract: In the evolving domains of Machine Learning and Data Analytics, existing
dataset characterization methods such as statistical, structural, and
model-based analyses often fail to deliver the deep understanding and insights
essential for innovation and explainability. This work surveys the current
state-of-the-art conventional data analytic techniques and examines their
limitations, and discusses a variety of tensor-based methods and how these may
provide a more robust alternative to traditional statistical, structural, and
model-based dataset characterization techniques. Through examples, we
illustrate how tensor methods unveil nuanced data characteristics, offering
enhanced interpretability and actionable intelligence. We advocate for the
adoption of tensor-based characterization, promising a leap forward in
understanding complex datasets and paving the way for intelligent, explainable
data-driven discoveries.

</details>


### [366] [Towards Reversible Model Merging For Low-rank Weights](https://arxiv.org/abs/2510.14163)
*Mohammadsajad Alipour,Mohammad Mohammadi Amiri*

Main category: cs.LG

TL;DR: 模型合并：一种新的可逆模型合并（RMM）方法，用于合并低秩模型，解决了现有方法性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法在合并低秩模型（如 LoRA 或 SVD 压缩模型）时存在严重的性能下降问题。

Method: 提出了一种新的模型合并方法（RMM），不将所有适配器折叠成单一权重，而是构建一个紧凑的基础，可以通过线性组合恢复原始任务特定的模型。

Result: RMM 在各种数据集和模型规模上进行了广泛的实验，结果表明 RMM 的性能优于现有的合并方法，并显著提高了低秩压缩模型的性能。

Conclusion: RMM 是一种高效、无需数据且灵活的方法，能够优化基础模型权重和任务特定系数的线性组合，从而在合并低秩模型时保持性能。

Abstract: Model merging aims to combine multiple fine-tuned models into a single set of
weights that performs well across all source tasks. While prior work has shown
that merging can approximate the performance of individual fine-tuned models
for each task, it largely overlooks scenarios where models are compressed into
low-rank representations, either through low-rank adaptation (LoRA) or
post-training singular value decomposition (SVD). We first demonstrate that
applying conventional merging methods to low-rank weights leads to severe
performance degradation in the merged model. Motivated by this phenomenon, we
propose a fundamentally different approach: instead of collapsing all adapters
into one set of weights, we construct a compact basis (e.g., an equivalent of
holding two or more models) from which original task-specific models can be
recovered via linear combination. This reframes merging as generating a
reconstruction-capable model space rather than producing a single merged model.
Crucially, this allows us to ``revert'' to each individual model when needed,
recognizing that no merged model can consistently outperform one specialized
for its task. Building on this insight, we introduce our method, Reversible
Model Merging (RMM), an efficient, data-free, and flexible method that provides
a closed-form solution for selecting the optimal basis of model weights and
task-specific coefficients for linear combination. Extensive experiments across
diverse datasets and model scales demonstrate that RMM consistently outperforms
existing merging approaches, preserving the performance of low-rank compressed
models by a significant margin.

</details>


### [367] [Optimal Control Theoretic Neural Optimizer: From Backpropagation to Dynamic Programming](https://arxiv.org/abs/2510.14168)
*Guan-Horng Liu,Tianrong Chen,Evangelos A. Theodorou*

Main category: cs.LG

TL;DR: 该研究将深度神经网络（DNN）视为最优控制问题，并提出了一种名为OCNOpt的新优化算法，该算法基于动态规划和高阶泰勒展开，在稳健性和效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）的优化是机器学习和人工智能发展的关键。将DNN视为具有非线性传播的动力学系统，可以通过最优控制理论进行分析。研究观察到，DNN中的反向传播算法与动态规划中的最优性条件在算法上高度相似。

Method: 该研究将反向传播算法解释为具有变分结构的最优控制问题，并探索了Bellman方程的高阶展开，提出了一种名为OCNOpt的新优化算法。

Result: OCNOpt算法在稳健性和效率方面优于现有方法，同时计算复杂度可控。它还为分层反馈策略、博弈论应用和连续时间模型（如神经ODE）的高阶训练等提供了新的算法机会。

Conclusion: OCNOpt算法基于动力学系统和最优控制理论，为DNN的优化提供了一种新的、原则性的算法设计途径，并在实验中证明了其优越性。

Abstract: Optimization of deep neural networks (DNNs) has been a driving force in the
advancement of modern machine learning and artificial intelligence. With DNNs
characterized by a prolonged sequence of nonlinear propagation, determining
their optimal parameters given an objective naturally fits within the framework
of Optimal Control Programming. Such an interpretation of DNNs as dynamical
systems has proven crucial in offering a theoretical foundation for principled
analysis from numerical equations to physics. In parallel to these theoretical
pursuits, this paper focuses on an algorithmic perspective. Our motivated
observation is the striking algorithmic resemblance between the Backpropagation
algorithm for computing gradients in DNNs and the optimality conditions for
dynamical systems, expressed through another backward process known as dynamic
programming. Consolidating this connection, where Backpropagation admits a
variational structure, solving an approximate dynamic programming up to the
first-order expansion leads to a new class of optimization methods exploring
higher-order expansions of the Bellman equation. The resulting optimizer,
termed Optimal Control Theoretic Neural Optimizer (OCNOpt), enables rich
algorithmic opportunities, including layer-wise feedback policies,
game-theoretic applications, and higher-order training of continuous-time
models such as Neural ODEs. Extensive experiments demonstrate that OCNOpt
improves upon existing methods in robustness and efficiency while maintaining
manageable computational complexity, paving new avenues for principled
algorithmic design grounded in dynamical systems and optimal control theory.

</details>


### [368] [MAFA: A Multi-Agent Framework for Enterprise-Scale Annotation with Configurable Task Adaptation](https://arxiv.org/abs/2510.14184)
*Mahmood Hegazy,Aaron Rodrigues,Azzam Naeem*

Main category: cs.LG

TL;DR: MAFA是一个用于金融服务领域大规模标注工作流的多智能体系统，通过配置实现定制化标注，已成功应用于摩根大通，解决了百万级语句的积压问题，并显著提高了标注效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 金融服务领域存在大量的客户语音需要准确分类，导致标注积压严重，传统方法效率低下。

Method: MAFA框架结合了专业智能体、结构化推理和基于裁判的共识机制，支持通过配置动态调整标注任务（如FAQ、意图、实体等），无需代码更改。

Result: MAFA在摩根大通成功消除了100万条语句的积压，平均与人工标注者达到86%的一致性，每年节省超过5000小时的人工标注时间。标注置信度分类中，高置信度占85%。在内部意图分类数据集和公开基准测试中，MAFA相比传统和单智能体方法，在Top-1准确率、Top-5准确率和F1分数上分别提升了13.8%、15.1%和16.9%。

Conclusion: MAFA成功地将多智能体系统的理论研究与企业实际应用相结合，为面临类似标注挑战的企业提供了一个可行的解决方案。

Abstract: We present MAFA (Multi-Agent Framework for Annotation), a production-deployed
system that transforms enterprise-scale annotation workflows through
configurable multi-agent collaboration. Addressing the critical challenge of
annotation backlogs in financial services, where millions of customer
utterances require accurate categorization, MAFA combines specialized agents
with structured reasoning and a judge-based consensus mechanism. Our framework
uniquely supports dynamic task adaptation, allowing organizations to define
custom annotation types (FAQs, intents, entities, or domain-specific
categories) through configuration rather than code changes. Deployed at JP
Morgan Chase, MAFA has eliminated a 1 million utterance backlog while
achieving, on average, 86% agreement with human annotators, annually saving
over 5,000 hours of manual annotation work. The system processes utterances
with annotation confidence classifications, which are typically 85% high, 10%
medium, and 5% low across all datasets we tested. This enables human annotators
to focus exclusively on ambiguous and low-coverage cases. We demonstrate MAFA's
effectiveness across multiple datasets and languages, showing consistent
improvements over traditional and single-agent annotation baselines: 13.8%
higher Top-1 accuracy, 15.1% improvement in Top-5 accuracy, and 16.9% better F1
in our internal intent classification dataset and similar gains on public
benchmarks. This work bridges the gap between theoretical multi-agent systems
and practical enterprise deployment, providing a blueprint for organizations
facing similar annotation challenges.

</details>


### [369] [Contrastive Diffusion Alignment: Learning Structured Latents for Controllable Generation](https://arxiv.org/abs/2510.14190)
*Ruchi Sandilya,Sumaira Perez,Charles Lynch,Lindsay Victoria,Benjamin Zebley,Derrick Matthew Buchanan,Mahendra T. Bhati,Nolan Williams,Timothy J. Spellman,Faith M. Gunning,Conor Liston,Logan Grosenick*

Main category: cs.LG

TL;DR: ConDA框架利用对比学习来组织扩散模型的潜在空间，实现可控的轨迹遍历，并在多个基准测试中取得了优于线性遍历和条件控制的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型虽然擅长生成，但其潜在空间缺乏显式的组织，难以进行可解释的控制。本研究旨在解决这个问题，使潜在空间能够与系统动力学对齐，从而实现对生成过程的更好控制。

Method: ConDA框架将对比学习应用于扩散嵌入，以对齐潜在空间的几何结构和系统动力学。通过对比学习的目标，ConDA组织扩散潜在空间，使得遍历方向能够反映潜在的动力学因素。

Result: 在流体动力学、神经钙成像、神经调控治疗和面部表情等多个基准测试中，ConDA框架能够生成可解释的潜在表征，并且相比于线性遍历和基于条件控制的基线方法，其可控性得到了提升。

Conclusion: 本研究表明，扩散模型的潜在空间编码了与动力学相关的结构，但要利用这种结构，需要对潜在空间进行组织，并沿着潜在流形进行遍历。ConDA框架为实现这一目标提供了一种有效的方法。

Abstract: Diffusion models excel at generation, but their latent spaces are not
explicitly organized for interpretable control. We introduce ConDA (Contrastive
Diffusion Alignment), a framework that applies contrastive learning within
diffusion embeddings to align latent geometry with system dynamics. Motivated
by recent advances showing that contrastive objectives can recover more
disentangled and structured representations, ConDA organizes diffusion latents
such that traversal directions reflect underlying dynamical factors. Within
this contrastively structured space, ConDA enables nonlinear trajectory
traversal that supports faithful interpolation, extrapolation, and controllable
generation. Across benchmarks in fluid dynamics, neural calcium imaging,
therapeutic neurostimulation, and facial expression, ConDA produces
interpretable latent representations with improved controllability compared to
linear traversals and conditioning-based baselines. These results suggest that
diffusion latents encode dynamics-relevant structure, but exploiting this
structure requires latent organization and traversal along the latent manifold.

</details>


### [370] [Spectral Analysis of Molecular Kernels: When Richer Features Do Not Guarantee Better Generalization](https://arxiv.org/abs/2510.14217)
*Asma Jamali,Tin Sum Cheng,Rodrigo A. Vargas-Hernández*

Main category: cs.LG

TL;DR: 富集的光谱特征并不总能提高准确性，但通常排名前 2% 的特征值可以恢复几乎所有的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在分子性质预测方面表现出色，但核方法因其在数据稀疏性方面的鲁棒性和良好的理论基础而被广泛使用。然而，关于分子核谱的系统性分析却很少。这项工作首次对 QM9 数据集上的核脊回归进行了全面的谱分析。

Method: 对 QM9 数据集上的核脊回归进行全面的谱分析，包括分子指纹、预训练的基于 transformer 的全局和局部 3D 表示，以及七种分子性质。此外，还实现了截断核来探究谱与预测性能的关系。

Result: 发现更丰富的光谱特征并不总能提高准确性，对于基于 transformer 的和局部的 3D 表示，谱丰富度甚至可能与性能呈负相关。保留排名前 2% 的特征值几乎可以恢复所有性能。

Conclusion: 研究结果挑战了“更丰富的光谱能带来更好的泛化”这一常见观念，并强调了表示、核特征和预测性能之间存在的细微差别。这些发现不仅有助于分子性质预测，还为如何在数据有限的科学和现实世界任务中评估核方法和自监督学习方法提供了参考。

Abstract: Understanding the spectral properties of kernels offers a principled
perspective on generalization and representation quality. While deep models
achieve state-of-the-art accuracy in molecular property prediction, kernel
methods remain widely used for their robustness in low-data regimes and
transparent theoretical grounding. Despite extensive studies of kernel spectra
in machine learning, systematic spectral analyses of molecular kernels are
scarce. In this work, we provide the first comprehensive spectral analysis of
kernel ridge regression on the QM9 dataset, molecular fingerprint, pretrained
transformer-based, global and local 3D representations across seven molecular
properties. Surprisingly, richer spectral features, measured by four different
spectral metrics, do not consistently improve accuracy. Pearson correlation
tests further reveal that for transformer-based and local 3D representations,
spectral richness can even have a negative correlation with performance. We
also implement truncated kernels to probe the relationship between spectrum and
predictive performance: in many kernels, retaining only the top 2% of
eigenvalues recovers nearly all performance, indicating that the leading
eigenvalues capture the most informative features. Our results challenge the
common heuristic that "richer spectra yield better generalization" and
highlight nuanced relationships between representation, kernel features, and
predictive performance. Beyond molecular property prediction, these findings
inform how kernel and self-supervised learning methods are evaluated in
data-limited scientific and real-world tasks.

</details>


### [371] [When Flatness Does (Not) Guarantee Adversarial Robustness](https://arxiv.org/abs/2510.14231)
*Nils Philipp Walter,Linara Adilova,Jilles Vreeken,Michael Kamp*

Main category: cs.LG

TL;DR: 神经网络在面对对抗性扰动时仍然脆弱，尽管存在平坦最小值可以提高鲁棒性的假设，但这种联系很大程度上是非正式的。本文通过严格的数学形式化，证明了平坦性只带来局部鲁棒性，而非全局鲁棒性。研究推导了损失函数的闭合形式表达式，并以此约束了输入空间中损失值的变化，从而对整个网络的对抗鲁棒性进行了形式化分析。研究还发现，要维持超越局部区域的鲁棒性，损失函数需要在数据流形之外急剧弯曲。理论预测在不同架构和数据集上得到了实证验证，揭示了控制对抗性脆弱性的几何结构，并将平坦性与模型置信度联系起来：对抗性样本常常存在于模型错误但置信度高的平坦区域。研究结果挑战了对平坦性的简化看法，并提供了对其在鲁棒性中作用的更细致的理解。


<details>
  <summary>Details</summary>
Motivation: 神经网络的鲁棒性一直是研究的热点，尤其是对抗性扰动带来的脆弱性问题。平坦最小值被认为是提高鲁棒性的关键，但其作用机制和有效性缺乏严格的理论支撑。

Method: 首先，推导出网络倒数第二层相对平坦度的封闭形式表达式。然后，利用该表达式约束输入空间中损失值的变化。最后，基于此分析网络的对抗鲁棒性，并研究损失函数在数据流形之外的曲率变化。

Result: 在不同架构和数据集上的实证结果表明，理论预测得到验证。研究揭示了控制对抗性脆弱性的几何结构，并将平坦性与模型置信度联系起来，发现对抗性样本往往位于模型自信但错误的平坦区域。

Conclusion: 平坦最小值仅能提供局部鲁棒性，而非全局鲁棒性。要实现超越局部区域的鲁棒性，损失函数需要在数据流形之外急剧弯曲。该研究为理解平坦性在鲁棒性中的作用提供了更细致的视角，并挑战了简化的看法。

Abstract: Despite their empirical success, neural networks remain vulnerable to small,
adversarial perturbations. A longstanding hypothesis suggests that flat minima,
regions of low curvature in the loss landscape, offer increased robustness.
While intuitive, this connection has remained largely informal and incomplete.
By rigorously formalizing the relationship, we show this intuition is only
partially correct: flatness implies local but not global adversarial
robustness. To arrive at this result, we first derive a closed-form expression
for relative flatness in the penultimate layer, and then show we can use this
to constrain the variation of the loss in input space. This allows us to
formally analyze the adversarial robustness of the entire network. We then show
that to maintain robustness beyond a local neighborhood, the loss needs to
curve sharply away from the data manifold. We validate our theoretical
predictions empirically across architectures and datasets, uncovering the
geometric structure that governs adversarial vulnerability, and linking
flatness to model confidence: adversarial examples often lie in large, flat
regions where the model is confidently wrong. Our results challenge simplified
views of flatness and provide a nuanced understanding of its role in
robustness.

</details>


### [372] [Scaling Test-Time Compute to Achieve IOI Gold Medal with Open-Weight Models](https://arxiv.org/abs/2510.14232)
*Mehrzad Samadi,Aleksander Ficek,Sean Narenthiran,Siddhartha Jain,Wasi Uddin Ahmad,Somshubra Majumdar,Vahid Noroozi,Boris Ginsburg*

Main category: cs.LG

TL;DR: 使用名为GenCluster的开放权重模型，在IOI竞赛中达到金牌水平。


<details>
  <summary>Details</summary>
Motivation: 在开放权重模型在IOI竞赛中达到金牌水平方面仍然存在挑战。

Method: GenCluster结合了大规模生成、行为聚类、排名和循环提交策略，以在有限的验证预算下有效探索多样化的解决方案空间。

Result: 实验表明，GenCluster的性能随可用计算量的增加而持续扩展，缩小了开放和封闭系统之间的差距。GenCluster使用开放权重模型gpt-oss-120b在IOI 2025竞赛中达到了金牌水平。

Conclusion: GenCluster在IOI竞赛中设定了开放权重模型性能的新基准，为LLM推理的透明和可重复评估树立了新标杆。

Abstract: Competitive programming has become a rigorous benchmark for evaluating the
reasoning and problem-solving capabilities of large language models (LLMs). The
International Olympiad in Informatics (IOI) stands out as one of the most
prestigious annual competitions in competitive programming and has become a key
benchmark for comparing human and AI-level programming ability. While several
proprietary models have been claimed to achieve gold medal-level performance at
the IOI, often with undisclosed methods, achieving comparable results with
open-weight models remains a significant challenge. In this paper, we present
\gencluster, a scalable and reproducible test-time compute framework that
attains IOI gold-level performance using open-weight models. It combines
large-scale generation, behavioral clustering, ranking, and a round-robin
submission strategy to efficiently explore diverse solution spaces under
limited validation budgets. Our experiments show that the performance of our
proposed approach scales consistently with available compute, narrowing the gap
between open and closed systems. Notably, we will show that GenCluster can
achieve a gold medal at IOI 2025 for the first time with an open-weight model
gpt-oss-120b, setting a new benchmark for transparent and reproducible
evaluation of reasoning in LLMs.

</details>


### [373] [Policy Regularized Distributionally Robust Markov Decision Processes with Linear Function Approximation](https://arxiv.org/abs/2510.14246)
*Jingwen Gu,Yiting He,Zhishuai Liu,Pan Xu*

Main category: cs.LG

TL;DR: DR-RPO是一种模型无关的在线策略优化方法，用于在分布变化的环境中学习鲁棒策略，具有亚线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 决策制定在分布变化（训练和部署环境不同）的情况下是强化学习（RL）中的一个核心挑战。该研究通过鲁棒马尔可夫决策过程（RMDP）的视角来解决这个问题，该过程针对对抗性转移动态优化性能。

Method: DR-RPO算法结合了参考策略正则化和d-矩形线性MDP公式，并采用线性函数逼近和高置信度奖励来实现乐观探索。

Result: 理论分析表明，DR-RPO在鲁棒RL中可以实现与基于价值的方法相媲美的多项式次优界限和样本效率。实验结果也证实了DR-RPO的有效性和鲁棒性。

Conclusion: DR-RPO算法填补了鲁棒RL中策略优化的理论和实践空白，并能与基于价值的方法相媲美。

Abstract: Decision-making under distribution shift is a central challenge in
reinforcement learning (RL), where training and deployment environments differ.
We study this problem through the lens of robust Markov decision processes
(RMDPs), which optimize performance against adversarial transition dynamics.
Our focus is the online setting, where the agent has only limited interaction
with the environment, making sample efficiency and exploration especially
critical. Policy optimization, despite its success in standard RL, remains
theoretically and empirically underexplored in robust RL. To bridge this gap,
we propose \textbf{D}istributionally \textbf{R}obust \textbf{R}egularized
\textbf{P}olicy \textbf{O}ptimization algorithm (DR-RPO), a model-free online
policy optimization method that learns robust policies with sublinear regret.
To enable tractable optimization within the softmax policy class, DR-RPO
incorporates reference-policy regularization, yielding RMDP variants that are
doubly constrained in both transitions and policies. To scale to large
state-action spaces, we adopt the $d$-rectangular linear MDP formulation and
combine linear function approximation with an upper confidence bonus for
optimistic exploration. We provide theoretical guarantees showing that policy
optimization can achieve polynomial suboptimality bounds and sample efficiency
in robust RL, matching the performance of value-based approaches. Finally,
empirical results across diverse domains corroborate our theory and demonstrate
the robustness of DR-RPO.

</details>


### [374] [A Physics Prior-Guided Dual-Stream Attention Network for Motion Prediction of Elastic Bragg Breakwaters](https://arxiv.org/abs/2510.14250)
*Lianzi Jiang,Jianxin Zhang,Xinyu Han,Huanhe Dong,Xiangrong Wang*

Main category: cs.LG

TL;DR: 为了提高弹性防波堤在未知海况下的运动响应预测能力，提出了一种结合物理先验知识的双流注意力网络（PhysAttnNet），通过引入时间衰减和相位差来捕捉波浪与结构间的交互作用，并在时频域进行联合损失优化，实验结果表明该模型在预测精度和泛化能力上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在预测弹性防波堤的运动响应时，由于忽略了自然衰减和波浪-结构交互（WSI）的充分建模，导致泛化能力受限，无法保证结构安全和运行完整性。

Method: 提出了一种名为PhysAttnNet的新型网络，该网络包含两个关键模块：1. 衰减双向自注意力（DBSA）模块，通过引入可学习的时间衰减来模拟自然衰减现象，使模型更关注近期状态。2. 相位差引导双向交叉注意力（PDG-BCA）模块，利用基于余弦的偏置来捕捉波浪与结构之间的双向交互和相位关系。这两个模块通过全局上下文融合（GCF）模块进行整合。此外，模型采用了混合时频损失函数进行训练。

Result: 通过在波浪水槽数据集上的广泛实验，PhysAttnNet在预测精度和泛化能力上显著优于当前主流模型。跨场景泛化测试验证了该模型在处理未知环境时的鲁棒性和适应性。

Conclusion: PhysAttnNet通过结合物理先验知识（自然衰减和波浪-结构交互的相位关系）和先进的深度学习技术，成功克服了传统模型的局限性，在弹性防波堤运动响应预测方面展现出优越的性能和良好的泛化能力，为海洋工程复杂系统的预测模型开发提供了一个有潜力的框架。

Abstract: Accurate motion response prediction for elastic Bragg breakwaters is critical
for their structural safety and operational integrity in marine environments.
However, conventional deep learning models often exhibit limited generalization
capabilities when presented with unseen sea states. These deficiencies stem
from the neglect of natural decay observed in marine systems and inadequate
modeling of wave-structure interaction (WSI). To overcome these challenges,
this study proposes a novel Physics Prior-Guided Dual-Stream Attention Network
(PhysAttnNet). First, the decay bidirectional self-attention (DBSA) module
incorporates a learnable temporal decay to assign higher weights to recent
states, aiming to emulate the natural decay phenomenon. Meanwhile, the phase
differences guided bidirectional cross-attention (PDG-BCA) module explicitly
captures the bidirectional interaction and phase relationship between waves and
the structure using a cosine-based bias within a bidirectional
cross-computation paradigm. These streams are synergistically integrated
through a global context fusion (GCF) module. Finally, PhysAttnNet is trained
with a hybrid time-frequency loss that jointly minimizes time-domain prediction
errors and frequency-domain spectral discrepancies. Comprehensive experiments
on wave flume datasets demonstrate that PhysAttnNet significantly outperforms
mainstream models. Furthermore,cross-scenario generalization tests validate the
model's robustness and adaptability to unseen environments, highlighting its
potential as a framework to develop predictive models for complex systems in
ocean engineering.

</details>


### [375] [Generalist vs Specialist Time Series Foundation Models: Investigating Potential Emergent Behaviors in Assessing Human Health Using PPG Signals](https://arxiv.org/abs/2510.14254)
*Saurabh Kataria,Yi Wu,Zhaoliang Chen,Hyunjung Gloria Kwak,Yuhao Xu,Lovely Yeswanth Panchumarthi,Ran Xiao,Jiaying Lu,Ayca Ermis,Anni Zhao,Runze Yan,Alex Federov,Zewen Liu,Xu Wu,Wei Jin,Carl Yang,Jocelyn Grunwell,Stephanie R. Brown,Amit Shah,Craig Jabaley,Tim Buchman,Sivasubramanium V Bhavani,Randall J. Lee,Xiao Hu*

Main category: cs.LG

TL;DR: 该论文对比了在生理信号（特别是PPG）时间序列分析中，通才模型和专才模型的性能。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型在NLP和CV领域取得成功，它们也被应用于时间序列分析，但目前大多数是专才模型。本研究旨在全面评估通才模型和专才模型在PPG信号分析任务上的表现。

Method: 在一系列包含51个任务（涵盖心脏状态评估、实验室值估计和跨模态推理）的实验中，对通才模型和专才模型进行了评估，并从七个维度（胜率、平均性能、特征质量、调优增益、性能方差、可迁移性和可扩展性）进行了衡量。

Result: 在全调优场景下，专才模型取得了27%更高的胜率。论文还分析了泛化性、公平性、注意力可视化和训练数据选择的重要性。

Conclusion: 通过全面的基准测试，该研究为理解通才和专才模型在时间序列分析（特别是PPG信号）中的优缺点提供了见解，并强调了专才模型在某些场景下的优势。

Abstract: Foundation models are large-scale machine learning models that are
pre-trained on massive amounts of data and can be adapted for various
downstream tasks. They have been extensively applied to tasks in Natural
Language Processing and Computer Vision with models such as GPT, BERT, and
CLIP. They are now also increasingly gaining attention in time-series analysis,
particularly for physiological sensing. However, most time series foundation
models are specialist models - with data in pre-training and testing of the
same type, such as Electrocardiogram, Electroencephalogram, and
Photoplethysmogram (PPG). Recent works, such as MOMENT, train a generalist time
series foundation model with data from multiple domains, such as weather,
traffic, and electricity. This paper aims to conduct a comprehensive
benchmarking study to compare the performance of generalist and specialist
models, with a focus on PPG signals. Through an extensive suite of total 51
tasks covering cardiac state assessment, laboratory value estimation, and
cross-modal inference, we comprehensively evaluate both models across seven
dimensions, including win score, average performance, feature quality, tuning
gain, performance variance, transferability, and scalability. These metrics
jointly capture not only the models' capability but also their adaptability,
robustness, and efficiency under different fine-tuning strategies, providing a
holistic understanding of their strengths and limitations for diverse
downstream scenarios. In a full-tuning scenario, we demonstrate that the
specialist model achieves a 27% higher win score. Finally, we provide further
analysis on generalization, fairness, attention visualizations, and the
importance of training data choice.

</details>


### [376] [CAST: Compositional Analysis via Spectral Tracking for Understanding Transformer Layer Functions](https://arxiv.org/abs/2510.14262)
*Zihao Fu,Ming Liao,Chris Russell,Zhenguang G. Cai*

Main category: cs.LG

TL;DR: CAST是一个无需探针的框架，通过直接估计变换矩阵和进行全面的谱分析来分析Transformer层函数，为现有方法提供补充见解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的内部机制理解不足，现有解释性方法（如机制分析、探测分类器、激活可视化）各有侧重。

Method: CAST通过摩尔-彭罗斯伪逆估计每层的实际变换矩阵，并应用具有六个可解释指标的谱分析来表征层行为。

Result: 发现encoder-only和decoder-only模型行为不同，decoder模型表现出压缩-膨胀循环，而encoder模型保持一致的高秩处理。核分析表明层之间存在函数关系模式，CKA相似度矩阵将层分为特征提取、压缩和专业化三个阶段。

Conclusion: CAST框架通过矩阵估计和谱分析提供了对Transformer层功能的独特见解，揭示了不同模型类型和层之间的行为差异及功能关系。

Abstract: Large language models have achieved remarkable success but remain largely
black boxes with poorly understood internal mechanisms. To address this
limitation, many researchers have proposed various interpretability methods
including mechanistic analysis, probing classifiers, and activation
visualization, each providing valuable insights from different perspectives.
Building upon this rich landscape of complementary approaches, we introduce
CAST (Compositional Analysis via Spectral Tracking), a probe-free framework
that contributes a novel perspective by analyzing transformer layer functions
through direct transformation matrix estimation and comprehensive spectral
analysis. CAST offers complementary insights to existing methods by estimating
the realized transformation matrices for each layer using Moore-Penrose
pseudoinverse and applying spectral analysis with six interpretable metrics
characterizing layer behavior. Our analysis reveals distinct behaviors between
encoder-only and decoder-only models, with decoder models exhibiting
compression-expansion cycles while encoder models maintain consistent high-rank
processing. Kernel analysis further demonstrates functional relationship
patterns between layers, with CKA similarity matrices clearly partitioning
layers into three phases: feature extraction, compression, and specialization.

</details>


### [377] [Nonparametric Data Attribution for Diffusion Models](https://arxiv.org/abs/2510.14269)
*Yutian Zhao,Chao Du,Xiaosen Zheng,Tianyu Pang,Min Lin*

Main category: cs.LG

TL;DR: 本研究提出了一种非参数、无需梯度的生成模型数据归因方法，通过比较生成图像和训练图像的块状相似性来衡量影响，并在实验中展现出与基于梯度的方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型归因方法（尤其是扩散模型）通常需要模型梯度或重新训练，这在处理专有或大规模模型时受到限制。本研究旨在开发一种更通用、更易于应用的数据归因方法。

Method: 提出了一种基于数据本身的非参数归因方法，通过分析最优分数函数的解析形式，计算生成图像与训练图像之间块级相似度来衡量单个训练样本的影响。该方法支持多尺度表示，并通过卷积加速实现计算效率，最终在数据层面实现归因。

Result: 实验结果表明，该方法在归因性能上表现出色，与基于梯度的方法相匹配，并且显著优于现有的非参数基线方法。该方法还能产生可解释的空间归因图，并揭示训练数据与模型输出之间独立于具体模型的内在关系。

Conclusion: 本研究提出的非参数数据归因方法为生成模型提供了一种无需梯度、计算高效且性能优越的归因解决方案，克服了现有方法的局限性，并能揭示数据与模型输出间的深层联系。

Abstract: Data attribution for generative models seeks to quantify the influence of
individual training examples on model outputs. Existing methods for diffusion
models typically require access to model gradients or retraining, limiting
their applicability in proprietary or large-scale settings. We propose a
nonparametric attribution method that operates entirely on data, measuring
influence via patch-level similarity between generated and training images. Our
approach is grounded in the analytical form of the optimal score function and
naturally extends to multiscale representations, while remaining
computationally efficient through convolution-based acceleration. In addition
to producing spatially interpretable attributions, our framework uncovers
patterns that reflect intrinsic relationships between training data and
outputs, independent of any specific model. Experiments demonstrate that our
method achieves strong attribution performance, closely matching gradient-based
approaches and substantially outperforming existing nonparametric baselines.
Code is available at https://github.com/sail-sg/NDA.

</details>


### [378] [Stable Prediction of Adverse Events in Medical Time-Series Data](https://arxiv.org/abs/2510.14286)
*Mayank Keoliya,Seewon Choi,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: CAREBench是一个新的EEP（早期事件预测）基准，用于评估多模态输入的部署能力，并评估时间稳定性和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有EEP系统在风险评分的稳定性和多模态输入的评估方面存在不足，这影响了临床决策的信任度。

Method: 提出CAREBench基准，包含表格EHR、ECG波形和临床文本等多种输入，并提出一个稳定性度量来量化每位患者风险的短期变异性，并根据局部Lipschitz常数惩罚突然的振荡。

Result: 实验表明，现有方法，特别是LLMs，在联合优化准确性和稳定性方面存在困难，在高温操作点下召回率尤其差。

Conclusion: 需要开发能够产生与证据一致的、稳定的轨迹的模型，以在连续监测环境中赢得临床医生的信任。

Abstract: Early event prediction (EEP) systems continuously estimate a patient's
imminent risk to support clinical decision-making. For bedside trust, risk
trajectories must be accurate and temporally stable, shifting only with new,
relevant evidence. However, current benchmarks (a) ignore stability of risk
scores and (b) evaluate mainly on tabular inputs, leaving trajectory behavior
untested. To address this gap, we introduce CAREBench, an EEP benchmark that
evaluates deployability using multi-modal inputs-tabular EHR, ECG waveforms,
and clinical text-and assesses temporal stability alongside predictive
accuracy. We propose a stability metric that quantifies short-term variability
in per-patient risk and penalizes abrupt oscillations based on local-Lipschitz
constants. CAREBench spans six prediction tasks such as sepsis onset and
compares classical learners, deep sequence models, and zero-shot LLMs. Across
tasks, existing methods, especially LLMs, struggle to jointly optimize accuracy
and stability, with notably poor recall at high-precision operating points.
These results highlight the need for models that produce evidence-aligned,
stable trajectories to earn clinician trust in continuous monitoring settings.
(Code: https://github.com/SeewonChoi/CAREBench.)

</details>


### [379] [Enhancing Time-Series Anomaly Detection by Integrating Spectral-Residual Bottom-Up Attention with Reservoir Computing](https://arxiv.org/abs/2510.14287)
*Hayato Nihei,Sou Nobukawa,Yusuke Sakemi,Kazuyuki Aihara*

Main category: cs.LG

TL;DR: SR-RC通过集成SR方法来提高RC在边缘AI中的时间序列异常检测性能，同时保持学习效率。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上，单独使用RC可能需要过大的水库才能达到足够的异常检测性能，而注意力机制虽然能提高精度，但可能会增加计算量并影响学习效率。

Method: 提出了一种谱残差水库计算（SR-RC），它将学习无关的、自下而上的注意力机制——谱残差（SR）方法——与水库计算（RC）相结合。

Result: SR-RC在基准任务和真实世界的时间序列数据集上，通过SR方法提取的值，其表现优于传统的RC和逻辑回归模型。

Conclusion: SR-RC通过集成SR方法，在不牺牲学习效率的情况下提高了RC的异常检测性能，并且由于SR方法和RC都适合硬件实现，SR-RC为将RC部署为用于时间序列异常检测的边缘AI提供了一个可行的方向。

Abstract: Reservoir computing (RC) establishes the basis for the processing of
time-series data by exploiting the high-dimensional spatiotemporal response of
a recurrent neural network to an input signal. In particular, RC trains only
the output layer weights. This simplicity has drawn attention especially in
Edge Artificial Intelligence (AI) applications. Edge AI enables time-series
anomaly detection in real time, which is important because detection delays can
lead to serious incidents. However, achieving adequate anomaly-detection
performance with RC alone may require an unacceptably large reservoir on
resource-constrained edge devices. Without enlarging the reservoir, attention
mechanisms can improve accuracy, although they may require substantial
computation and undermine the learning efficiency of RC. In this study, to
improve the anomaly detection performance of RC without sacrificing learning
efficiency, we propose a spectral residual RC (SR-RC) that integrates the
spectral residual (SR) method - a learning-free, bottom-up attention mechanism
- with RC. We demonstrated that SR-RC outperformed conventional RC and
logistic-regression models based on values extracted by the SR method across
benchmark tasks and real-world time-series datasets. Moreover, because the SR
method, similarly to RC, is well suited for hardware implementation, SR-RC
suggests a practical direction for deploying RC as Edge AI for time-series
anomaly detection.

</details>


### [380] [TED++: Submanifold-Aware Backdoor Detection via Layerwise Tubular-Neighbourhood Screening](https://arxiv.org/abs/2510.14299)
*Nam Le,Leo Yu Zhang,Kewen Liao,Shirui Pan,Wei Luo*

Main category: cs.LG

TL;DR: TED++是一个子流形感知框架，用于检测逃避现有防御的隐蔽后门攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的后门防御机制容易受到攻击者利用细微的基于距离的异常或在清洁数据稀缺的情况下的攻击。因此，需要一种新的方法来应对这一挑战。

Method: TED++首先围绕每个类的隐藏特征流形构建一个管状邻域，并根据少量干净的激活来估计其局部“厚度”。然后，它应用局部自适应排名（LAR）来检测任何偏离允许范围的激活。通过聚合所有层中这些LAR调整后的排名，TED++可以捕获输入在不断变化的类流形上的保持程度。

Result: TED++在基准数据集和任务上实现了最先进的检测性能，在自适应攻击和有限数据场景下均表现出色。即使只有每个类别的五个保留示例，TED++仍然可以实现近乎完美的检测，在AUROC方面比次优方法提高了14%。

Conclusion: TED++通过其子流形感知方法，能够有效地检测到现有防御措施无法发现的细微后门攻击，尤其是在数据稀缺的情况下，展示了其强大的鲁棒性和优越的性能。

Abstract: As deep neural networks power increasingly critical applications, stealthy
backdoor attacks, where poisoned training inputs trigger malicious model
behaviour while appearing benign, pose a severe security risk. Many existing
defences are vulnerable when attackers exploit subtle distance-based anomalies
or when clean examples are scarce. To meet this challenge, we introduce TED++,
a submanifold-aware framework that effectively detects subtle backdoors that
evade existing defences. TED++ begins by constructing a tubular neighbourhood
around each class's hidden-feature manifold, estimating its local ``thickness''
from a handful of clean activations. It then applies Locally Adaptive Ranking
(LAR) to detect any activation that drifts outside the admissible tube. By
aggregating these LAR-adjusted ranks across all layers, TED++ captures how
faithfully an input remains on the evolving class submanifolds. Based on such
characteristic ``tube-constrained'' behaviour, TED++ flags inputs whose
LAR-based ranking sequences deviate significantly. Extensive experiments are
conducted on benchmark datasets and tasks, demonstrating that TED++ achieves
state-of-the-art detection performance under both adaptive-attack and
limited-data scenarios. Remarkably, even with only five held-out examples per
class, TED++ still delivers near-perfect detection, achieving gains of up to
14\% in AUROC over the next-best method. The code is publicly available at
https://github.com/namle-w/TEDpp.

</details>


### [381] [Active Measuring in Reinforcement Learning With Delayed Negative Effects](https://arxiv.org/abs/2510.14315)
*Daiqi Gao,Ziping Xu,Aseel Rawashdeh,Predrag Klasnja,Susan A. Murphy*

Main category: cs.LG

TL;DR: 在强化学习中，状态测量可能代价高昂且影响未来结果。我们提出了主动可观测马尔可夫决策过程（AOMDP），其中智能体不仅选择控制动作，还决定是否测量潜在状态。测量动作会揭示真实潜在状态，但可能对环境产生负面的延迟效应。我们证明了这种不确定性的降低可以证明地提高样本效率，并增加最优策略的价值，尽管存在这些成本。我们将AOMDP构建为周期性部分可观测MDP，并提出一种基于信念状态的在线强化学习算法。为了近似信念状态，我们进一步提出了一种顺序蒙特卡洛方法，以联合近似未知静态环境参数和未观测到的潜在状态的后验。我们在数字健康应用中评估了所提出的算法，其中智能体决定何时进行数字干预以及何时通过调查评估用户健康状况。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的强化学习（RL）设置中，测量状态可能成本高昂，并可能对未来的结果产生负面影响。

Method: 提出主动可观测马尔可夫决策过程（AOMDP），将问题形式化为周期性部分可观测MDP，并提出一种基于信念状态的在线RL算法，以及一种用于近似信念状态的顺序蒙特卡洛方法。

Result: 已证明减少不确定性可以提高样本效率并增加最优策略的价值。

Conclusion: 所提出的AOMDP框架和相关算法在数字健康应用中得到了有效评估，证明了其在平衡测量成本和信息增益方面的潜力。

Abstract: Measuring states in reinforcement learning (RL) can be costly in real-world
settings and may negatively influence future outcomes. We introduce the
Actively Observable Markov Decision Process (AOMDP), where an agent not only
selects control actions but also decides whether to measure the latent state.
The measurement action reveals the true latent state but may have a negative
delayed effect on the environment. We show that this reduced uncertainty may
provably improve sample efficiency and increase the value of the optimal policy
despite these costs. We formulate an AOMDP as a periodic partially observable
MDP and propose an online RL algorithm based on belief states. To approximate
the belief states, we further propose a sequential Monte Carlo method to
jointly approximate the posterior of unknown static environment parameters and
unobserved latent states. We evaluate the proposed algorithm in a digital
health application, where the agent decides when to deliver digital
interventions and when to assess users' health status through surveys.

</details>


### [382] [LLM-ERM: Sample-Efficient Program Learning via LLM-Guided Search](https://arxiv.org/abs/2510.14331)
*Shivam Singhal,Eran Malach,Tomaso Poggio,Tomer Galanti*

Main category: cs.LG

TL;DR: LLM-ERM是一个新的程序学习框架，它结合了LLM的搜索能力和ERM的验证能力，能够在样本量有限的情况下学习到简洁的程序。


<details>
  <summary>Details</summary>
Motivation: 现有的程序学习算法要么需要大量的样本（如梯度下降），要么在计算上不可行（如穷举搜索）。

Method: LLM-ERM框架首先使用预训练的LLM生成候选程序，然后编译并在一部分数据上验证这些程序，最后选择表现最好的程序。

Result: 在奇偶校验、模式匹配和素数测试等任务上，LLM-ERM仅用200个样本就能取得成功，而基于SGD的Transformer即使有100,000个样本也会出现过拟合。

Conclusion: LLM-ERM在保持计算可行性的同时，恢复了有限类别ERM的统计效率，为梯度下降方法无法学习的简洁假设提供了一条可行的途径。

Abstract: We seek algorithms for program learning that are both sample-efficient and
computationally feasible. Classical results show that targets admitting short
program descriptions (e.g., with short ``python code'') can be learned with a
``small'' number of examples (scaling with the size of the code) via
length-first program enumeration, but the search is exponential in description
length. Consequently, Gradient-based training avoids this cost yet can require
exponentially many samples on certain short-program families.
  To address this gap, we introduce LLM-ERM, a propose-and-verify framework
that replaces exhaustive enumeration with an LLM-guided search over candidate
programs while retaining ERM-style selection on held-out data. Specifically, we
draw $k$ candidates with a pretrained reasoning-augmented LLM, compile and
check each on the data, and return the best verified hypothesis, with no
feedback, adaptivity, or gradients. Theoretically, we show that coordinate-wise
online mini-batch SGD requires many samples to learn certain short programs.
{\em Empirically, LLM-ERM solves tasks such as parity variants, pattern
matching, and primality testing with as few as 200 samples, while SGD-trained
transformers overfit even with 100,000 samples}. These results indicate that
language-guided program synthesis recovers much of the statistical efficiency
of finite-class ERM while remaining computationally tractable, offering a
practical route to learning succinct hypotheses beyond the reach of
gradient-based training.

</details>


### [383] [DARTS-GT: Differentiable Architecture Search for Graph Transformers with Quantifiable Instance-Specific Interpretability Analysis](https://arxiv.org/abs/2510.14336)
*Shruti Sarika Chakraborty,Peter Minary*

Main category: cs.LG

TL;DR: 通过引入不对称性、解耦结构编码和特征表示，并结合可微分架构搜索（DARTS）来优化 GNN 算子选择，DARTS-GT 实现了最先进的性能，并提供了一种新的量化可解释性框架，以区分有意义的模式和虚假关联。


<details>
  <summary>Details</summary>
Motivation: 解决现有图 Transformer（GTs）模型设计僵化、可解释性不足的问题，并探索深度特定组件选择的潜在优势。

Method: 设计了一种新的 GT 注意力机制，通过不对称性解耦结构编码和特征表示（查询来自节点特征，键和值来自 GNN 变换）。在此框架内，使用 DARTS 选择每层的最优 GNN 算子，实现深度异质性。开发了首个针对 GT 的量化可解释性框架，通过因果烧蚀分析（Head-deviation、Specialization、Focus 指标）来识别驱动预测的头和节点。

Result: DARTS-GT 在八个基准测试中取得了最先进的性能（四个数据集），并在其他数据集上保持了竞争力。发现的架构揭示了特定于数据集的模式。可解释性分析表明，视觉注意力显著性和因果重要性不一定相关，表明常用的可视化方法可能忽略了真正重要的组件。异质架构比基线模型更能提供可解释性。

Conclusion: 图 Transformer 模型无需在性能和可解释性之间做出选择。DARTS-GT 通过异质架构和新的可解释性框架，在性能和可解释性方面均取得了显著进展。

Abstract: Graph Transformers (GTs) have emerged as powerful architectures for
graph-structured data, yet remain constrained by rigid designs and lack
quantifiable interpretability. Current state-of-the-art GTs commit to fixed GNN
types across all layers, missing potential benefits of depth-specific component
selection, while their complex architectures become opaque where performance
gains cannot be distinguished between meaningful patterns and spurious
correlations. We redesign GT attention through asymmetry, decoupling structural
encoding from feature representation: queries derive from node features while
keys and values come from GNN transformations. Within this framework, we use
Differentiable ARchiTecture Search (DARTS) to select optimal GNN operators at
each layer, enabling depth-wise heterogeneity inside transformer attention
itself (DARTS-GT). To understand discovered architectures, we develop the first
quantitative interpretability framework for GTs through causal ablation. Our
metrics (Head-deviation, Specialization, and Focus), identify which heads and
nodes drive predictions while enabling model comparison. Experiments across
eight benchmarks show DARTS-GT achieves state-of-the-art on four datasets while
remaining competitive on others, with discovered architectures revealing
dataset-specific patterns. Our interpretability analysis reveals that visual
attention salience and causal importance do not always correlate, indicating
widely used visualization approaches may miss components that actually matter.
Crucially, heterogeneous architectures found by DARTS-GT consistently produced
more interpretable models than baselines, establishing that Graph Transformers
need not choose between performance and interpretability.

</details>


### [384] [Stop-RAG: Value-Based Retrieval Control for Iterative RAG](https://arxiv.org/abs/2510.14337)
*Jaewan Park,Solbee Cho,Jay-Yoon Lee*

Main category: cs.LG

TL;DR: 迭代检索增强生成（RAG）可以通过一个基于价值的控制器Stop-RAG来决定何时停止检索，从而高效地回答复杂的多步问题。


<details>
  <summary>Details</summary>
Motivation: 现有的迭代RAG方法要么使用预定的迭代次数，要么依赖于不能很好地反映检索是否有帮助的置信度代理，因此需要一种有效的停止策略来提高效率并降低延迟、成本和引入干扰证据的风险。

Method: 将迭代RAG视为一个有限时间范围的马尔可夫决策过程，并引入一个名为Stop-RAG的基于价值的控制器，该控制器使用完整的向前观察Q($f{\lambda}$)目标进行训练，以自适应地决定何时停止检索。

Result: 在多步问答基准测试中，Stop-RAG的性能始终优于固定的迭代基线和基于提示的LLM停止方法。

Conclusion: 自适应停止是当前代理系统中的一个关键缺失环节，基于价值的控制可以提高RAG系统的准确性。

Abstract: Iterative retrieval-augmented generation (RAG) enables large language models
to answer complex multi-hop questions, but each additional loop increases
latency, costs, and the risk of introducing distracting evidence, motivating
the need for an efficient stopping strategy. Existing methods either use a
predetermined number of iterations or rely on confidence proxies that poorly
reflect whether more retrieval will actually help. We cast iterative RAG as a
finite-horizon Markov decision process and introduce Stop-RAG, a value-based
controller that adaptively decides when to stop retrieving. Trained with
full-width forward-view Q($\lambda$) targets from complete trajectories,
Stop-RAG learns effective stopping policies while remaining compatible with
black-box APIs and existing pipelines. On multi-hop question-answering
benchmarks, Stop-RAG consistently outperforms both fixed-iteration baselines
and prompting-based stopping with LLMs. These results highlight adaptive
stopping as a key missing component in current agentic systems, and demonstrate
that value-based control can improve the accuracy of RAG systems.

</details>


### [385] [Jet Functors and Weil Algebras in Automatic Differentiation: A Geometric Analysis](https://arxiv.org/abs/2510.14342)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 该论文使用微分几何中的“矢量丛”和“Weil 代数”来构建自动微分（AD）的几何形式化。


<details>
  <summary>Details</summary>
Motivation: 自动微分（AD）在深度学习和科学计算中具有重要应用，但现有理论和方法在正确性、稳定性和复杂性方面存在挑战。

Method: 使用矢量丛和 Weil 代数进行自动微分的几何形式化，将反向模式 AD 解释为“协正切-拉回”，将 Taylor 模式解释为 Weil 代数中的评估。

Result: 推导出反向模式 AD 的函子恒等式、高阶导数的代数精确性以及截断误差的显式界限。通过张量化 Weil 代数，实现了所有混合导数的一次性计算，成本与代数维度线性相关，避免了嵌套 JVP/VJP 方案的组合爆炸。

Conclusion: 该框架为 AD 理论提供了微分几何的视角，并为开发深度学习和科学计算中的结构保持微分方法奠定了基础。

Abstract: We present a geometric formulation of automatic differentiation (AD) using
jet bundles and Weil algebras. Reverse-mode AD emerges as cotangent-pullback,
while Taylor-mode corresponds to evaluation in a Weil algebra. From these
principles, we derive concise statements on correctness, stability, and
complexity: a functorial identity for reverse-mode, algebraic exactness of
higher-order derivatives, and explicit bounds on truncation error. We further
show that tensorized Weil algebras permit one-pass computation of all mixed
derivatives with cost linear in the algebra dimension, avoiding the
combinatorial blow-up of nested JVP/VJP schedules. This framework interprets AD
theory through the lens of differential geometry and offers a foundation for
developing structure-preserving differentiation methods in deep learning and
scientific computing. Code and examples are available at
https://git.nilu.no/geometric-ad/jet-weil-ad.

</details>


### [386] [Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](https://arxiv.org/abs/2510.14381)
*Andrew Zhao,Reshmi Ghosh,Vitor Carvalho,Emily Lawton,Keegan Hines,Gao Huang,Jack W. Stokes*

Main category: cs.LG

TL;DR: LLM提示优化器在AI应用中很重要，但存在安全风险。研究发现，基于反馈的攻击比基于查询的攻击更有效，并提出了一种新的“假奖励攻击”和一种“高亮防御”机制。


<details>
  <summary>Details</summary>
Motivation: LLM系统广泛应用于日常AI应用，但其性能依赖于提示设计。LLM提示优化器虽然能减少设计工作，但其安全问题尚未得到充分研究。因此，有必要系统地分析提示优化过程中的潜在中毒风险。

Method: 使用HarmBench数据集，评估了LLM提示优化器在面对基于注入查询和基于操纵反馈的攻击时的漏洞。提出了一种不需要访问奖励模型的“假奖励攻击”方法。提出了一种轻量级的“高亮防御”机制。

Result: 基于反馈的攻击比基于查询的攻击能显著提高攻击成功率（ASR），最高可达0.48。假奖励攻击能将ASR从0.23降低到0.07，而不会损害模型效用。

Conclusion: 提示优化管道是重要的攻击面，需要加强对反馈渠道和优化框架的安全防护。

Abstract: Large language model (LLM) systems now underpin everyday AI applications such
as chatbots, computer-use assistants, and autonomous robots, where performance
often depends on carefully designed prompts. LLM-based prompt optimizers reduce
that effort by iteratively refining prompts from scored feedback, yet the
security of this optimization stage remains underexamined. We present the first
systematic analysis of poisoning risks in LLM-based prompt optimization. Using
HarmBench, we find systems are substantially more vulnerable to manipulated
feedback than to injected queries: feedback-based attacks raise attack success
rate (ASR) by up to $\Delta$ASR = 0.48. We introduce a simple fake-reward
attack that requires no access to the reward model and significantly increases
vulnerability, and we propose a lightweight highlighting defense that reduces
the fake-reward $\Delta$ASR from 0.23 to 0.07 without degrading utility. These
results establish prompt optimization pipelines as a first-class attack surface
and motivate stronger safeguards for feedback channels and optimization
frameworks.

</details>


### [387] [Revisit Modality Imbalance at the Decision Layer](https://arxiv.org/abs/2510.14411)
*Xiaoyu Ma,Hao Chen*

Main category: cs.LG

TL;DR: 解决多模态学习中模态不平衡问题，提出在决策层进行自适应权重分配。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中存在模态不平衡问题，主导模态会掩盖较弱模态，影响模型性能。

Method: 通过在决策层引入自适应权重分配机制，根据各模态的能力进行相对平衡。

Result: 实验表明，即使经过预训练和平衡优化，模型仍存在对某些模态（如音频）的系统性偏见。所提出的方法通过调整决策层权重，缓解了这种偏见。

Conclusion: 未来的多模态系统应侧重于在决策层整合自适应权重分配机制，以实现各模态能力的相对平衡。

Abstract: Multimodal learning integrates information from different modalities to
enhance model performance, yet it often suffers from modality imbalance, where
dominant modalities overshadow weaker ones during joint optimization. This
paper reveals that such an imbalance not only occurs during representation
learning but also manifests significantly at the decision layer. Experiments on
audio-visual datasets (CREMAD and Kinetic-Sounds) show that even after
extensive pretraining and balanced optimization, models still exhibit
systematic bias toward certain modalities, such as audio. Further analysis
demonstrates that this bias originates from intrinsic disparities in
feature-space and decision-weight distributions rather than from optimization
dynamics alone. We argue that aggregating uncalibrated modality outputs at the
fusion stage leads to biased decision-layer weighting, hindering weaker
modalities from contributing effectively. To address this, we propose that
future multimodal systems should focus more on incorporate adaptive weight
allocation mechanisms at the decision layer, enabling relative balanced
according to the capabilities of each modality.

</details>


### [388] [Interaction Concordance Index: Performance Evaluation for Interaction Prediction Methods](https://arxiv.org/abs/2510.14419)
*Tapio Pahikkala,Riikka Numminen,Parisa Movahedi,Napsu Karmitsa,Antti Airola*

Main category: cs.LG

TL;DR: 该论文提出了一种名为交互一致性指数（IC-index）的新指标，用于评估预测药物-靶点亲和力（DTA）时交互方向的预测性能，并解决了现有方法在处理未见过的药物或靶点时的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确捕捉药物-靶点之间的交互作用对于优化药物分配和决策至关重要，现有 DTA 预测方法在评估交互作用方面存在不足。

Method: 提出交互一致性指数（IC-index）来评估交互方向的预测性能。分析了 IC-index 在无法捕捉交互的预测器上的不变性，以及排列等变性对学习算法在处理未见实体时的影响。提出了通过引入侧面信息来克服这些局限性。

Result: 通过在多个生物医学交互数据集上进行的大量实证评估，证明了 IC-index 作为一种补充现有性能评估指标的方法的有效性，并展示了不同亲和力强度预测方法的 IC-index 表现。

Conclusion: IC-index 是一个评估 DTA 预测中交互方向准确性的有用指标，并且通过结合合适的侧面信息，可以提高模型在处理新实体时的交互捕捉能力。

Abstract: Consider two sets of entities and their members' mutual affinity values, say
drug-target affinities (DTA). Drugs and targets are said to interact in their
effects on DTAs if drug's effect on it depends on the target. Presence of
interaction implies that assigning a drug to a target and another drug to
another target does not provide the same aggregate DTA as the reversed
assignment would provide. Accordingly, correctly capturing interactions enables
better decision-making, for example, in allocation of limited numbers of drug
doses to their best matching targets. Learning to predict DTAs is popularly
done from either solely from known DTAs or together with side information on
the entities, such as chemical structures of drugs and targets. In this paper,
we introduce interaction directions' prediction performance estimator we call
interaction concordance index (IC-index), for both fixed predictors and machine
learning algorithms aimed for inferring them. IC-index complements the
popularly used DTA prediction performance estimators by evaluating the ratio of
correctly predicted directions of interaction effects in data. First, we show
the invariance of IC-index on predictors unable to capture interactions.
Secondly, we show that learning algorithm's permutation equivariance regarding
drug and target identities implies its inability to capture interactions when
either drug, target or both are unseen during training. In practical
applications, this equivariance is remedied via incorporation of appropriate
side information on drugs and targets. We make a comprehensive empirical
evaluation over several biomedical interaction data sets with various
state-of-the-art machine learning algorithms. The experiments demonstrate how
different types of affinity strength prediction methods perform in terms of
IC-index complementing existing prediction performance estimators.

</details>


### [389] [MergeMoE: Efficient Compression of MoE Models via Expert Output Merging](https://arxiv.org/abs/2510.14436)
*Ruijie Miao,Yilun Yao,Zihan Wang,Zhiming Wang,Bairen Yi,LingJun Liu,Yikai Zhao,Tong Yang*

Main category: cs.LG

TL;DR: 混合专家（MoE）模型因其可扩展性而被广泛应用，但内存开销大，因此模型压缩很重要。本文提出了一种新的 MoE 模型压缩方法 MergeMoE，将专家合并视为输出合并问题，并通过数学优化来构建压缩矩阵，实验证明该方法优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 混合专家（MoE）模型虽然在扩展模型规模方面表现出色，但其巨大的内存开销使得模型压缩成为一个重要的研究方向。

Method: 本文将专家合并视为专家输出的合并，而不是参数聚合。通过将合并过程理解为在前向计算中插入额外的矩阵，从而得到一个优化问题。基于此分析，提出 MergeMoE 方法，利用数学优化来构造压缩矩阵。

Result: MergeMoE 在多个 MoE 模型上的评估结果显示，在相同的压缩率下，该算法的性能持续优于基线方法。

Conclusion: MergeMoE 通过将专家合并问题转化为输出合并问题，并利用数学优化求解，能够有效地压缩 MoE 模型，并在实验中取得了优于现有方法的性能。

Abstract: The Mixture-of-Experts (MoE) technique has proven to be a promising solution
to efficiently scale the model size, which has been widely applied in recent
LLM advancements. However, the substantial memory overhead of MoE models has
made their compression an important research direction. In this work, we
provide a theoretical analysis of expert merging, a recently proposed technique
for compressing MoE models. Rather than interpreting expert merging from the
conventional perspective of parameter aggregation, we approach it from the
perspective of merging experts' outputs. Our key insight is that the merging
process can be interpreted as inserting additional matrices into the forward
computation, which naturally leads to an optimization formulation. Building on
this analysis, we introduce MergeMoE, a method that leverages mathematical
optimization to construct the compression matrices. We evaluate MergeMoE on
multiple MoE models and show that our algorithm consistently outperforms the
baselines with the same compression ratios.

</details>


### [390] [A Free Lunch in LLM Compression: Revisiting Retraining after Pruning](https://arxiv.org/abs/2510.14444)
*Moritz Wagner,Christophe Roux,Max Zimmer,Sebastian Pokutta*

Main category: cs.LG

TL;DR: LLM剪枝通常需要完全重新训练，这在计算上是不可行的。本研究探讨了剪枝后恢复性能的关键设计选择，并在GPT架构上进行了广泛的计算研究。研究发现，在Transformer块内单独重建注意力（attention）和MLP组件几乎是最具资源效益的，并且获得了最佳的困惑度（perplexity）。这种帕累托最优（Pareto-optimal）的设置比完全重新训练的性能更好，但内存需求却小得多。此外，研究表明，像Wanda这样简单有效的剪枝标准，在正确执行重建步骤的情况下，可以优于更复杂的方法。这些发现挑战了应不惜一切代价避免重新训练的观点，并为LLM的剪枝后性能恢复提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM剪枝方法为了避免计算上不可行的完全重新训练，通常采用层级掩码选择和重建的方法。然而，这些重建操作在实践中通常以更粗粒度进行（例如，重建整个Transformer块而非单个矩阵）。本研究旨在深入探讨在剪枝后重建或重新训练剩余权重时的关键设计选择。

Method: 本研究对先进的GPT架构进行了广泛的计算研究，以评估剪枝后恢复性能的不同策略，特别是重建（reconstruction）和重新训练（retraining）的权衡。研究比较了不同粒度的重建（例如，单独重建注意力层和MLP层）与完整的重新训练方法。

Result: 研究发现，在Transformer块内单独重建注意力和MLP组件，在资源效益和性能（以困惑度衡量）上均表现最佳，达到了帕累托最优。这种方法比完全重新训练更优越，同时内存需求更低。此外，简单的剪枝标准（如Wanda）在配合恰当的重建步骤时，表现优于更复杂的方法。

Conclusion: 本研究结果挑战了普遍认为应避免在LLM剪枝后进行任何形式重新训练的观点。研究强调了重建步骤在LLM剪枝后性能恢复中的重要性，并为如何在资源受限的情况下实现最佳性能恢复提供了关键见解。

Abstract: While Neural Network pruning typically requires retraining the model to
recover pruning-induced performance degradation, state-of-the-art Large
Language Models (LLMs) pruning methods instead solve a layer-wise mask
selection and reconstruction problem on a small set of calibration data to
avoid full retraining, as it is considered computationally infeasible for LLMs.
Reconstructing single matrices in isolation has favorable properties, such as
convexity of the objective and significantly reduced memory requirements
compared to full retraining. In practice, however, reconstruction is often
implemented at coarser granularities, e.g., reconstructing a whole transformer
block against its dense activations instead of a single matrix. In this work,
we study the key design choices when reconstructing or retraining the remaining
weights after pruning. We conduct an extensive computational study on
state-of-the-art GPT architectures, and report several surprising findings that
challenge common intuitions about retraining after pruning. In particular, we
observe a free lunch scenario: reconstructing attention and MLP components
separately within each transformer block is nearly the most resource-efficient
yet achieves the best perplexity. Most importantly, this Pareto-optimal setup
achieves better performance than full retraining, despite requiring only a
fraction of the memory. Furthermore, we demonstrate that simple and efficient
pruning criteria such as Wanda can outperform much more complex approaches when
the reconstruction step is properly executed, highlighting its importance. Our
findings challenge the narrative that retraining should be avoided at all costs
and provide important insights into post-pruning performance recovery for LLMs.

</details>


### [391] [Towards geological inference with process-based and deep generative modeling, part 1: training on fluvial deposits](https://arxiv.org/abs/2510.14445)
*Guillaume Rongier,Luk Peeters*

Main category: cs.LG

TL;DR: GANs can effectively reproduce complex geological structures like fluvial deposits, outperforming traditional methods by incorporating geological principles for training and validation.


<details>
  <summary>Details</summary>
Motivation: Traditional generative models struggle to accurately reproduce the continuous geological structures, especially fluvial deposits. This study investigates the potential of Generative Adversarial Networks (GANs) to address this limitation.

Method: The study trains a GAN using fluvial deposits simulated by a process-based model. It includes an ablation study to assess the transferability of 2D image generation techniques to 3D, and utilizes the deposition time to validate the GAN's performance against the law of superposition.

Result: The trained GAN successfully reproduces the non-stationarity and details of fluvial deposits without mode collapse or memorization. Developments in 2D image generation are shown to be transferable to 3D.

Conclusion: GANs demonstrate robustness in generating specific geological structures like fluvial deposits, even when trained on data from process-based models that include additional geological properties. Future work should explore GANs' performance on larger 3D datasets and multimodal data, and further leverage geological principles like the law of superposition in deep generative models.

Abstract: The distribution of resources in the subsurface is deeply linked to the
variations of its physical properties. Generative modeling has long been used
to predict those physical properties while quantifying the associated
uncertainty. But current approaches struggle to properly reproduce geological
structures, and fluvial deposits in particular, because of their continuity.
This study explores whether a generative adversarial network (GAN) - a type of
deep-learning algorithm for generative modeling - can be trained to reproduce
fluvial deposits simulated by a process-based model - a more expensive model
that mimics geological processes. An ablation study shows that developments
from the deep-learning community to generate large 2D images are directly
transferable to 3D images of fluvial deposits. Training remains stable, and the
generated samples reproduce the non-stationarity and details of the deposits
without mode collapse or pure memorization of the training data. Using a
process-based model to generate those training data allows us to include
valuable properties other than the usual physical properties. We show how the
deposition time let us monitor and validate the performance of a GAN by
checking that its samples honor the law of superposition. Our work joins a
series of previous studies suggesting that GANs are more robust that given
credit for, at least for training datasets targeting specific geological
structures. Whether this robustness transfers to larger 3D images and
multimodal datasets remains to be seen. Exploring how deep generative models
can leverage geological principles like the law of superposition shows a lot of
promise.

</details>


### [392] [Feature Selection and Regularization in Multi-Class Classification: An Empirical Study of One-vs-Rest Logistic Regression with Gradient Descent Optimization and L1 Sparsity Constraints](https://arxiv.org/abs/2510.14449)
*Jahidul Arafat,Fariha Tasmin,Md Kaosar Uddin,Sanjaya Poudel,Eftakhar Ahmed Arnob*

Main category: cs.LG

TL;DR: 该研究比较了不同逻辑回归方法在葡萄酒数据集上的分类性能，并探索了L1正则化对特征选择和模型可解释性的影响，最终提出了一种在精度、成本和速度之间取得良好平衡的最优五特征子集，适用于资源受限的实时质量控制场景。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决多类别葡萄酒分类中模型准确性、特征维度和可解释性之间的权衡问题，以满足分析化学领域生产部署的需求。

Method: 本研究对UCI葡萄酒数据集（178个样本，3个栽培品种，13个化学特征）进行了全面的实证研究，比较了从头实现的梯度下降与scikit-learn优化的求解器，并量化了L1正则化对特征稀疏性的影响。

Result: 从头实现的梯度下降在葡萄酒数据集上达到了92.59%的平均测试准确率，而scikit-learn的求解器训练速度提高了24倍，准确率达到98.15%。L1正则化可将特征数量减少54-69%，准确率仅下降4.63%。研究提出了一种最优的5特征子集，可将复杂度降低62%，估计准确率达92-94%，可节省成本并减少时间。

Conclusion: L1正则化在葡萄酒分类中实现了良好的可解释性-性能权衡。研究提出的最优五特征子集在保证较高准确率的同时，显著降低了成本和复杂度，为资源受限环境下的实时质量控制提供了可行的解决方案。

Abstract: Multi-class wine classification presents fundamental trade-offs between model
accuracy, feature dimensionality, and interpretability - critical factors for
production deployment in analytical chemistry. This paper presents a
comprehensive empirical study of One-vs-Rest logistic regression on the UCI
Wine dataset (178 samples, 3 cultivars, 13 chemical features), comparing
from-scratch gradient descent implementation against scikit-learn's optimized
solvers and quantifying L1 regularization effects on feature sparsity. Manual
gradient descent achieves 92.59 percent mean test accuracy with smooth
convergence, validating theoretical foundations, though scikit-learn provides
24x training speedup and 98.15 percent accuracy. Class-specific analysis
reveals distinct chemical signatures with heterogeneous patterns where color
intensity varies dramatically (0.31 to 16.50) across cultivars. L1
regularization produces 54-69 percent feature reduction with only 4.63 percent
accuracy decrease, demonstrating favorable interpretability-performance
trade-offs. We propose an optimal 5-feature subset achieving 62 percent
complexity reduction with estimated 92-94 percent accuracy, enabling
cost-effective deployment with 80 dollars savings per sample and 56 percent
time reduction. Statistical validation confirms robust generalization with
sub-2ms prediction latency suitable for real-time quality control. Our findings
provide actionable guidelines for practitioners balancing comprehensive
chemical analysis against targeted feature measurement in resource-constrained
environments.

</details>


### [393] [Coder as Editor: Code-driven Interpretable Molecular Optimization](https://arxiv.org/abs/2510.14455)
*Wenyu Zhu,Chengzhu Li,Xiaohe Tian,Yifan Wang,Yinjun Jia,Jianhui Wang,Bowen Gao,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan*

Main category: cs.LG

TL;DR: MECo框架通过将编辑操作转化为可执行代码，实现了分子优化中 LLM 的推理和执行之间的桥梁，显著提高了分子设计的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: LLM在药物发现的分子优化任务中，尽管能生成高层编辑意图，但在实际执行这些修改时，尤其是在SMILES等非直观表示上，常常存在困难。因此，需要一个能够精确执行编辑操作的框架。

Method: MECo 将分子优化重构为 LLM 的级联框架：首先从分子和属性目标生成人类可解释的编辑意图，然后通过代码生成将这些意图转化为可执行的结构编辑。

Result: MECo 在复现真实编辑方面达到 98% 以上的准确率，在物理化学性质和靶点活性的优化基准上，一致性提高了 38-86 个百分点（达到 90% 以上），并且在保持结构相似性的同时，实现了比基于 SMILES 的方法更高的成功率。

Conclusion: MECo 通过对齐意图和执行，实现了分子设计的一致性、可控性和可解释性，为药物发现中高保真反馈循环和人机协作工作流程奠定了基础。

Abstract: Molecular optimization is a central task in drug discovery that requires
precise structural reasoning and domain knowledge. While large language models
(LLMs) have shown promise in generating high-level editing intentions in
natural language, they often struggle to faithfully execute these
modifications-particularly when operating on non-intuitive representations like
SMILES. We introduce MECo, a framework that bridges reasoning and execution by
translating editing actions into executable code. MECo reformulates molecular
optimization for LLMs as a cascaded framework: generating human-interpretable
editing intentions from a molecule and property goal, followed by translating
those intentions into executable structural edits via code generation. Our
approach achieves over 98% accuracy in reproducing held-out realistic edits
derived from chemical reactions and target-specific compound pairs. On
downstream optimization benchmarks spanning physicochemical properties and
target activities, MECo substantially improves consistency by 38-86 percentage
points to 90%+ and achieves higher success rates over SMILES-based baselines
while preserving structural similarity. By aligning intention with execution,
MECo enables consistent, controllable and interpretable molecular design,
laying the foundation for high-fidelity feedback loops and collaborative
human-AI workflows in drug discovery.

</details>


### [394] [Holdout-Loss-Based Data Selection for LLM Finetuning via In-Context Learning](https://arxiv.org/abs/2510.14459)
*Ling Zhang,Xianliang Yang,Juwon Yu,Park Cheonyoung,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: 通过上下文近似（ICA）框架，我们提出了一种资源高效的数据选择和重加权方法，以提高预训练语言模型的对齐性能，该方法在不依赖昂贵重新训练或启发式方法的情况下，能够有效识别高价值训练数据。


<details>
  <summary>Details</summary>
Motivation: 在对齐预训练语言模型时，嘈杂或偏离目标的示例可能会稀释监督信号。虽然小型、精心挑选的数据集通常能达到与大型数据集相当的性能，但识别高价值训练数据的系统化且高效的方法仍有待探索。当前许多方法依赖启发式方法或昂贵的重新训练。

Method: 我们提出了一个理论上可行且资源高效的数据选择和重加权框架。该框架的核心是一种上下文近似（ICA）方法，它通过在上下文中结合一小部分精心挑选的样本集来估计模型在训练候选样本后会产生的损失。ICA不需要参考模型，也不需要额外的微调。在局部线性化的基础上，ICA等同于朝着样本集最优值的单阶更新，这证明了其作为数据价值代理的合理性。我们从ICA得分中推导出每个样本的权重，从而在模型参数不断演变的过程中动态地重加权梯度更新。

Result: 在有监督微调（SFT）、直接偏好优化（DPO）和简化偏好优化（SimPO）等多种场景下，以及在不同的模型骨干和数据集上，基于ICA的重加权方法都能够以最小的额外开销，持续地提高模型的对齐性能。我们还分析了得分更新频率以及用于上下文演示的k个样本选择对结果的影响，并指出了该方法对于快速变化的在线策略更新的局限性，为未来的工作提供了方向。

Conclusion: 所提出的ICA框架为数据选择和重加权提供了一种新颖且高效的解决方案，能够有效提升语言模型的对齐性能，同时避免了传统方法的弊端。该方法在多种场景下都表现出优越性，并为未来的研究提供了有价值的见解。

Abstract: Fine-tuning large pretrained language models is a common approach for
aligning them with human preferences, but noisy or off-target examples can
dilute supervision. While small, well-chosen datasets often match the
performance of much larger ones, systematic and efficient ways to identify
high-value training data remain underexplored. Many current methods rely on
heuristics or expensive retraining. We present a theoretically grounded,
resource-efficient framework for data selection and reweighting. At its core is
an In-Context Approximation (ICA) that estimates the holdout loss a model would
incur after training on a candidate example by conditioning on a small, curated
holdout set in context. ICA requires no reference model and no additional
finetuning. Under a local linearization, ICA is equivalent to a first-order
update toward the holdout optimum, motivating its use as a proxy for data
value. We derive per-example weights from ICA scores, dynamically reweighting
gradient updates as model parameters evolve. Across SFT, DPO, and SimPO, and
over diverse backbones and datasets, ICA-based reweighting consistently
improves model alignment with minimal overhead. We analyze sensitivity to score
update frequency and the choice of $k$ holdout examples for in-context
demonstrations, and note limitations for rapidly drifting on-policy updates,
highlighting directions for future work. Code and prompts will be released.

</details>


### [395] [From Guess2Graph: When and How Can Unreliable Experts Safely Boost Causal Discovery in Finite Samples?](https://arxiv.org/abs/2510.14488)
*Sujai Hiremath,Dominik Janzing,Philipp Faller,Patrick Blöbaum,Elke Kirschbaum,Shiva Prasad Kasiviswanathan,Kyra Gan*

Main category: cs.LG

TL;DR: 专家知识（包括来自大型语言模型的知识）可以作为约束来指导因果发现，以提高在样本量有限的情况下的性能。然而，现有方法需要完美的预测或不确定性估计才能提供保证，这在实践中并不可靠。本文提出的 Guess2Graph (G2G) 框架通过指导统计测试的顺序来利用专家猜测，而不是取代它们，从而在保持统计一致性的同时提高性能。


<details>
  <summary>Details</summary>
Motivation: 在样本量有限的情况下，因果发现算法通常表现不佳。虽然整合专家知识（包括来自大型语言模型的知识）作为约束有望提高性能，但现有方法需要完美的预测或不确定性估计才能提供保证，这使得它们在实际应用中并不可靠。

Method: 提出 Guess2Graph (G2G) 框架，它利用专家猜测来指导统计测试的顺序，而不是取代它们。开发了 G2G 的两个实例：PC-Guess，它增强了 PC 算法；gPC-Guess，一个旨在更好地利用高质量专家输入的学习增强变体。

Result: 理论上，无论专家是否存在错误，这两种方法都能保持正确性，并且当专家“优于随机”时，gPC-Guess 在有限样本中的表现优于其非增强版本。实验上，两者都随着专家准确性的提高而单调提高，其中 gPC-Guess 实现了显著更强的收益。

Conclusion: Guess2Graph (G2G) 框架通过指导统计测试的顺序来利用专家猜测，从而在保持统计一致性的同时提高因果发现的性能。PC-Guess 和 gPC-Guess 实例都显示出随着专家准确性的提高而单调改进，gPC-Guess 取得了更显著的收益。

Abstract: Causal discovery algorithms often perform poorly with limited samples. While
integrating expert knowledge (including from LLMs) as constraints promises to
improve performance, guarantees for existing methods require perfect
predictions or uncertainty estimates, making them unreliable for practical use.
We propose the Guess2Graph (G2G) framework, which uses expert guesses to guide
the sequence of statistical tests rather than replacing them. This maintains
statistical consistency while enabling performance improvements. We develop two
instantiations of G2G: PC-Guess, which augments the PC algorithm, and
gPC-Guess, a learning-augmented variant designed to better leverage
high-quality expert input. Theoretically, both preserve correctness regardless
of expert error, with gPC-Guess provably outperforming its non-augmented
counterpart in finite samples when experts are "better than random."
Empirically, both show monotonic improvement with expert accuracy, with
gPC-Guess achieving significantly stronger gains.

</details>


### [396] [Learning to Undo: Rollback-Augmented Reinforcement Learning with Reversibility Signals](https://arxiv.org/abs/2510.14503)
*Andrejs Sorstkins,Omer Tariq,Muhammad Bilal*

Main category: cs.LG

TL;DR: 该框架通过引入状态-动作对的“可逆性”度量Phi和选择性状态回滚机制，增强了基于价值的强化学习在部分不可逆环境中的鲁棒性、效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决基于价值的强化学习在部分不可逆环境中容易出现价值高估和不稳定的问题，提高智能体的鲁棒性和效率。

Method: 提出一个可逆性学习框架，包含两个核心机制：1. “Phi of s and a”：一个在线的、针对状态-动作对的估计器，量化在固定视野K内返回先前状态的可能性。该度量用于动态调整时间差分更新中的惩罚项，将可逆性意识整合到价值函数中。 2. 选择性状态回滚：当一个动作的预期回报显著低于其瞬时估计值并违反预定阈值时，智能体将受到惩罚并返回到前一个状态。该机制旨在中断次优的高风险轨迹并避免灾难性步骤。

Result: 在CliffWalking v0环境中，将灾难性跌落减少了99.8%以上，平均回合回报提高了55%。在Taxi v3环境中，将非法动作减少了99.9%以上，累积奖励提高了65.7%，同时显著降低了两种环境中的奖励方差。消融研究表明，回滚机制是安全性和性能提升的关键。

Conclusion: 结合可逆性感知评估和目标回滚，该方法提高了安全性、性能和稳定性，是实现安全可靠的序贯决策的一个坚实步伐。

Abstract: This paper proposes a reversible learning framework to improve the robustness
and efficiency of value based Reinforcement Learning agents, addressing
vulnerability to value overestimation and instability in partially irreversible
environments. The framework has two complementary core mechanisms: an
empirically derived transition reversibility measure called Phi of s and a, and
a selective state rollback operation. We introduce an online per state action
estimator called Phi that quantifies the likelihood of returning to a prior
state within a fixed horizon K. This measure is used to adjust the penalty term
during temporal difference updates dynamically, integrating reversibility
awareness directly into the value function. The system also includes a
selective rollback operator. When an action yields an expected return markedly
lower than its instantaneous estimated value and violates a predefined
threshold, the agent is penalized and returns to the preceding state rather
than progressing. This interrupts sub optimal high risk trajectories and avoids
catastrophic steps. By combining reversibility aware evaluation with targeted
rollback, the method improves safety, performance, and stability. In the
CliffWalking v0 domain, the framework reduced catastrophic falls by over 99.8
percent and yielded a 55 percent increase in mean episode return. In the Taxi
v3 domain, it suppressed illegal actions by greater than or equal to 99.9
percent and achieved a 65.7 percent improvement in cumulative reward, while
also sharply reducing reward variance in both environments. Ablation studies
confirm that the rollback mechanism is the critical component underlying these
safety and performance gains, marking a robust step toward safe and reliable
sequential decision making.

</details>


### [397] [Enhancing Time Series Forecasting through Selective Representation Spaces: A Patch Perspective](https://arxiv.org/abs/2510.14510)
*Xingjian Wu,Xiangfei Qiu,Hanyin Cheng,Zhengyu Li,Jilin Hu,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: 通过引入选择性表示空间（SRS）模块，改进时间序列预测，该模块自适应地选择和重新排列补丁以增强信息利用率。


<details>
  <summary>Details</summary>
Motivation: 传统的时间序列预测方法（如基于补丁的技术）由于补丁之间的邻近性而具有固定的表示空间，这限制了表示的表达能力，尤其是在处理长期依赖关系时。

Method: 提出选择性表示空间（SRS）模块，该模块采用可学习的选择性打补丁和动态重组技术，自适应地选择和重新排列来自上下文时间序列的补丁，以更有效地利用信息。此外，还提出了SRSNet，它将SRS模块与MLP头部结合起来，作为一种即插即用的模块，可以提高现有基于补丁的模型。

Result: SRSNet在来自多个领域的真实世界数据集上取得了最先进的性能，证明了SRS模块的有效性。

Conclusion: 所提出的SRS模块通过创建选择性表示空间，可以灵活地包含最有信息量的补丁，从而有效提高时间序列预测的性能，并且可以作为插件增强现有基于补丁的模型。

Abstract: Time Series Forecasting has made significant progress with the help of
Patching technique, which partitions time series into multiple patches to
effectively retain contextual semantic information into a representation space
beneficial for modeling long-term dependencies. However, conventional patching
partitions a time series into adjacent patches, which causes a fixed
representation space, thus resulting in insufficiently expressful
representations. In this paper, we pioneer the exploration of constructing a
selective representation space to flexibly include the most informative patches
for forecasting. Specifically, we propose the Selective Representation Space
(SRS) module, which utilizes the learnable Selective Patching and Dynamic
Reassembly techniques to adaptively select and shuffle the patches from the
contextual time series, aiming at fully exploiting the information of
contextual time series to enhance the forecasting performance of patch-based
models. To demonstrate the effectiveness of SRS module, we propose a simple yet
effective SRSNet consisting of SRS and an MLP head, which achieves
state-of-the-art performance on real-world datasets from multiple domains.
Furthermore, as a novel plugin-and-play module, SRS can also enhance the
performance of existing patch-based models. The resources are available at
https://github.com/decisionintelligence/SRSNet.

</details>


### [398] [On the Identifiability of Tensor Ranks via Prior Predictive Matching](https://arxiv.org/abs/2510.14523)
*Eliezer da Silva,Arto Klami,Diego Mesquita,Iñigo Urteaga*

Main category: cs.LG

TL;DR: 本篇论文提出了一种基于先验预测矩匹配的严格方法来确定概率张量模型中的秩可辨识性。


<details>
  <summary>Details</summary>
Motivation: 张量分解中秩的选择通常依赖启发式方法，缺乏严谨性。

Method: 将矩匹配条件转化为关于边际矩、先验超参数和秩的对数线性方程组，并将秩可辨识性与方程组的可解性等价起来。

Result: 证明了PARAFAC/CP、张量链和张量环模型的秩是可辨识的，而Tucker模型的秩是不可辨识的。推导了可辨识模型的秩估计量，并通过实验验证了其有效性和鲁棒性。

Conclusion: 所提出的基于先验预测矩匹配的方法为张量分解中的秩选择提供了一个严谨的框架，并能为可辨识模型导出显式的秩估计量。

Abstract: Selecting the latent dimensions (ranks) in tensor factorization is a central
challenge that often relies on heuristic methods. This paper introduces a
rigorous approach to determine rank identifiability in probabilistic tensor
models, based on prior predictive moment matching. We transform a set of moment
matching conditions into a log-linear system of equations in terms of marginal
moments, prior hyperparameters, and ranks; establishing an equivalence between
rank identifiability and the solvability of such system. We apply this
framework to four foundational tensor-models, demonstrating that the linear
structure of the PARAFAC/CP model, the chain structure of the Tensor Train
model, and the closed-loop structure of the Tensor Ring model yield solvable
systems, making their ranks identifiable. In contrast, we prove that the
symmetric topology of the Tucker model leads to an underdetermined system,
rendering the ranks unidentifiable by this method. For the identifiable models,
we derive explicit closed-form rank estimators based on the moments of observed
data only. We empirically validate these estimators and evaluate the robustness
of the proposal.

</details>


### [399] [Agentic Entropy-Balanced Policy Optimization](https://arxiv.org/abs/2510.14545)
*Guanting Dong,Licheng Bao,Zhongyuan Wang,Kangzhi Zhao,Xiaoxi Li,Jiajie Jin,Jinghan Yang,Hangyu Mao,Fuzheng Zhang,Kun Gai,Guorui Zhou,Yutao Zhu,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.LG

TL;DR: Agentic RL 训练中的熵过拟合问题导致训练崩溃，本文提出 AEPO 算法，通过动态熵平衡回滚机制和熵平衡策略优化来解决该问题，并在多项挑战性数据集上取得了优于现有算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 Agentic RL 算法过度依赖熵信号，可能导致训练崩溃。

Method: AEPO 算法包含两个核心组件：(1) 动态熵平衡回滚机制，通过熵预监控自适应地分配全局和分支采样预算，并对连续的高熵工具调用步骤施加分支惩罚；(2) 熵平衡策略优化，在Jogador 裁剪项中插入 stop-gradient 操作以保留和正确缩放高熵 token 上的梯度，并结合熵感知优势估计来优先学习高熵 token。

Result: AEPO 在 14 个具有挑战性的数据集上，相比 7 种主流 RL 算法取得了持续的优越性能。使用 AEPO 和 1K RL 样本，Qwen3-14B 在 GAIA、Humanity's Last Exam 和 WebWalker 上分别达到了 47.6%、11.2% 和 43.0% 的 Pass@1 准确率，以及 65.0%、26.0% 和 70.0% 的 Pass@5 准确率。

Conclusion: AEPO 提高了回滚采样多样性，同时保持了策略熵的稳定性，有助于可扩展的 Web Agent 训练。

Abstract: Recently, Agentic Reinforcement Learning (Agentic RL) has made significant
progress in incentivizing the multi-turn, long-horizon tool-use capabilities of
web agents. While mainstream agentic RL algorithms autonomously explore
high-uncertainty tool-call steps under the guidance of entropy, excessive
reliance on entropy signals can impose further constraints, leading to the
training collapse. In this paper, we delve into the challenges caused by
entropy and propose the Agentic Entropy-Balanced Policy Optimization (AEPO), an
agentic RL algorithm designed to balance entropy in both the rollout and policy
update phases. AEPO comprises two core components: (1) a dynamic
entropy-balanced rollout mechanism that adaptively allocate global and branch
sampling budget through entropy pre-monitoring, while imposing a branch penalty
on consecutive high-entropy tool-call steps to prevent over-branching issues;
and (2) Entropy-Balanced Policy Optimization that inserts a stop-gradient
operation into the high-entropy clipping term to preserve and properly rescale
gradients on high-entropy tokens, while incorporating entropy-aware advantage
estimation to prioritize learning on high-uncertainty tokens. Results across 14
challenging datasets show that AEPO consistently outperforms 7 mainstream RL
algorithms. With just 1K RL samples, Qwen3-14B with AEPO achieves impressive
results: 47.6% on GAIA, 11.2% on Humanity's Last Exam, and 43.0% on WebWalker
for Pass@1; 65.0% on GAIA, 26.0% on Humanity's Last Exam, and 70.0% on
WebWalker for Pass@5. Further analysis reveals that AEPO improves rollout
sampling diversity while maintaining stable policy entropy, facilitating
scalable web agent training.

</details>


### [400] [Redundancy-Aware Test-Time Graph Out-of-Distribution Detection](https://arxiv.org/abs/2510.14562)
*Yue Hou,He Zhu,Ruomei Liu,Yingke Su,Junran Wu,Ke Xu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为RedOUT的无监督框架，通过整合结构熵到测试时OOD检测中，解决了图分类中因结构冗余导致的语义偏移问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 训练数据和测试数据之间的分布差异会导致模型在实际应用中遇到分布外（OOD）样本时做出不准确的预测。现有图OOD检测方法虽然利用数据中心技术提取有效表示，但性能仍受限于引起语义偏移的结构冗余。

Method: 提出了一种名为RedOUT的无监督框架，该框架将结构熵整合到测试时的OOD检测中，用于图分类。具体来说，研究引入了冗余感知图信息瓶颈（ReGIB），并将目标分解为必要信息和不相关冗余。通过最小化结构熵来减少解耦的冗余，并提出了用于优化的理论上界和下界。

Result: 在真实数据集上的大量实验表明，RedOUT在OOD检测方面表现优越。具体而言，该方法在ClinTox/LIPO数据集对上平均提高了6.7%，显著超过了最佳竞争对手17.3%。

Conclusion: RedOUT通过整合结构熵和ReGIB模块，有效解决了图OOD检测中的结构冗余问题，并在多项基准测试中展现出卓越的性能。

Abstract: Distributional discrepancy between training and test data can lead models to
make inaccurate predictions when encountering out-of-distribution (OOD) samples
in real-world applications. Although existing graph OOD detection methods
leverage data-centric techniques to extract effective representations, their
performance remains compromised by structural redundancy that induces semantic
shifts. To address this dilemma, we propose RedOUT, an unsupervised framework
that integrates structural entropy into test-time OOD detection for graph
classification. Concretely, we introduce the Redundancy-aware Graph Information
Bottleneck (ReGIB) and decompose the objective into essential information and
irrelevant redundancy. By minimizing structural entropy, the decoupled
redundancy is reduced, and theoretically grounded upper and lower bounds are
proposed for optimization. Extensive experiments on real-world datasets
demonstrate the superior performance of RedOUT on OOD detection. Specifically,
our method achieves an average improvement of 6.7%, significantly surpassing
the best competitor by 17.3% on the ClinTox/LIPO dataset pair.

</details>


### [401] [State-Space Models for Tabular Prior-Data Fitted Networks](https://arxiv.org/abs/2510.14573)
*Felix Koch,Marcel Wever,Fabian Raisch,Benjamin Tischler*

Main category: cs.LG

TL;DR: 使用Hydra（一种双向线性时间结构化状态空间模型）替代TabPFN中的Transformer，以提高效率和处理表格数据中无意义的行顺序问题。


<details>
  <summary>Details</summary>
Motivation: Transformers在处理表格数据时存在二次方复杂度的问题，因此需要探索更高效的序列模型。

Method: 研究使用Hydra（一种双向线性时间结构化状态空间模型）替代TabPFN中的Transformer，并解决了SSM对输入令牌顺序敏感的问题，以实现对称上下文聚合。

Result: 实验结果表明，该方法降低了对行顺序的依赖性，实现了与原始TabPFN模型相当的预测性能。

Conclusion: Hydra作为一种双向线性时间结构化状态空间模型，是Transformer在TabPFN中的一种可行且高效的替代方案，尤其适用于表格数据。

Abstract: Recent advancements in foundation models for tabular data, such as TabPFN,
demonstrated that pretrained Transformer architectures can approximate Bayesian
inference with high predictive performance. However, Transformers suffer from
quadratic complexity with respect to sequence length, motivating the
exploration of more efficient sequence models. In this work, we investigate the
potential of using Hydra, a bidirectional linear-time structured state space
model (SSM), as an alternative to Transformers in TabPFN. A key challenge lies
in SSM's inherent sensitivity to the order of input tokens - an undesirable
property for tabular datasets where the row order is semantically meaningless.
We investigate to what extent a bidirectional approach can preserve efficiency
and enable symmetric context aggregation. Our experiments show that this
approach reduces the order-dependence, achieving predictive performance
competitive to the original TabPFN model.

</details>


### [402] [Selective Labeling with False Discovery Rate Control](https://arxiv.org/abs/2510.14581)
*Huipeng Huang,Wenbo Liao,Huajun Xi,Hao Zeng,Mengchen Zhao,Hongxin Wei*

Main category: cs.LG

TL;DR: 通过控制错误发现率，一种称为“保形标记”的新方法可以保证人工智能标记子集中标记的准确性。


<details>
  <summary>Details</summary>
Motivation: 获得高质量的数据集标签成本高昂，而现有的人工智能辅助方法在保证标签质量方面存在不足。

Method: 提出了一种称为“保形标记”的新方法，通过比较人工智能预测的置信度与校准集中被错误标记的实例来构建保形p值，并根据p值选择可信赖的实例。

Result: 该方法在图像标记、文本标记和大型语言模型问答等任务上进行了广泛的实验，证明了其在控制错误发现率和提高标记能力方面具有良好效果。

Conclusion: 保形标记方法能够提供理论保证，控制错误发现率低于预设的水平，确保所选人工智能标记的实例中平均有一部分是正确的。

Abstract: Obtaining high-quality labels for large datasets is expensive, requiring
massive annotations from human experts. While AI models offer a cost-effective
alternative by predicting labels, their label quality is compromised by the
unavoidable labeling errors. Existing methods mitigate this issue through
selective labeling, where AI labels a subset and human labels the remainder.
However, these methods lack theoretical guarantees on the quality of
AI-assigned labels, often resulting in unacceptably high labeling error within
the AI-labeled subset. To address this, we introduce \textbf{Conformal
Labeling}, a novel method to identify instances where AI predictions can be
provably trusted. This is achieved by controlling the false discovery rate
(FDR), the proportion of incorrect labels within the selected subset. In
particular, we construct a conformal $p$-value for each test instance by
comparing AI models' predicted confidence to those of calibration instances
mislabeled by AI models. Then, we select test instances whose $p$-values are
below a data-dependent threshold, certifying AI models' predictions as
trustworthy. We provide theoretical guarantees that Conformal Labeling controls
the FDR below the nominal level, ensuring that a predefined fraction of
AI-assigned labels is correct on average. Extensive experiments demonstrate
that our method achieves tight FDR control with high power across various
tasks, including image and text labeling, and LLM QA.

</details>


### [403] [Matcha: Multi-Stage Riemannian Flow Matching for Accurate and Physically Valid Molecular Docking](https://arxiv.org/abs/2510.14586)
*Daria Frolova,Talgat Daulbaev,Egor Sevryugov,Sergei A. Nikolenko,Dmitry N. Ivankov,Ivan Oseledets,Marina A. Pak*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate prediction of protein-ligand binding poses is crucial for
structure-based drug design, yet existing methods struggle to balance speed,
accuracy, and physical plausibility. We introduce Matcha, a novel molecular
docking pipeline that combines multi-stage flow matching with learned scoring
and physical validity filtering. Our approach consists of three sequential
stages applied consecutively to refine docking predictions, each implemented as
a flow matching model operating on appropriate geometric spaces
($\mathbb{R}^3$, $\mathrm{SO}(3)$, and $\mathrm{SO}(2)$). We enhance the
prediction quality through a dedicated scoring model and apply unsupervised
physical validity filters to eliminate unrealistic poses. Compared to various
approaches, Matcha demonstrates superior performance on Astex and PDBbind test
sets in terms of docking success rate and physical plausibility. Moreover, our
method works approximately 25 times faster than modern large-scale co-folding
models. The model weights and inference code to reproduce our results are
available at https://github.com/LigandPro/Matcha.

</details>


### [404] [Multimodal RAG for Unstructured Data:Leveraging Modality-Aware Knowledge Graphs with Hybrid Retrieval](https://arxiv.org/abs/2510.14592)
*Rashmi R,Vidyadhar Upadhya*

Main category: cs.LG

TL;DR: MAHA是一个用于多模态问答的混合检索框架，它结合了密集向量检索和知识图谱遍历，以处理包含文本、图像、表格、公式和图形等多种模态的非结构化文档。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成（RAG）系统主要处理单模态文本数据，在处理包含文本、图像、表格、公式和图形等多种模态的非结构化文档时效果受限。

Method: MAHA通过一个模态感知的知识图谱来整合密集向量检索和结构化图遍历。知识图谱编码了跨模态的语义和关系，实现了跨多种模态的丰富语义和上下文感知的检索。

Result: 在多个基准数据集上的评估表明，MAHA的ROUGE-L得分为0.486，实现了完整模态覆盖，显著优于基线方法。

Conclusion: MAHA能够结合嵌入和显式的文档结构，实现有效的多模态检索，为在非结构化多模态数据上进行模态感知推理的RAG系统提供了一个可扩展且可解释的检索框架。

Abstract: Current Retrieval-Augmented Generation (RAG) systems primarily operate on
unimodal textual data, limiting their effectiveness on unstructured multimodal
documents. Such documents often combine text, images, tables, equations, and
graphs, each contributing unique information. In this work, we present a
Modality-Aware Hybrid retrieval Architecture (MAHA), designed specifically for
multimodal question answering with reasoning through a modality-aware knowledge
graph. MAHA integrates dense vector retrieval with structured graph traversal,
where the knowledge graph encodes cross-modal semantics and relationships. This
design enables both semantically rich and context-aware retrieval across
diverse modalities. Evaluations on multiple benchmark datasets demonstrate that
MAHA substantially outperforms baseline methods, achieving a ROUGE-L score of
0.486, providing complete modality coverage. These results highlight MAHA's
ability to combine embeddings with explicit document structure, enabling
effective multimodal retrieval. Our work establishes a scalable and
interpretable retrieval framework that advances RAG systems by enabling
modality-aware reasoning over unstructured multimodal data.

</details>


### [405] [First Attentions Last: Better Exploiting First Attentions for Efficient Transformer Training](https://arxiv.org/abs/2510.14614)
*Gyudong Kim,Hyukju Na,Jin Hyeon Kim,Hyunsung Jang,Jaemin Park,Jaegi Hwang,Namkoo Ha,Seungryong Kim,Young Geun Kim*

Main category: cs.LG

TL;DR: 通过将第一个MHA的输出重定向到后续层的MLP输入来优化Transformer架构，减少通信开销并提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer设计在Tensor Parallelism（TP）中存在显著的通信开销，因为每个块的MHA-MLP连接都需要进行all-reduce通信。

Method: 提出了一种名为FAL（First Attentions Last）的高效Transformer架构，它将第一个MHA的输出重定向到后续层的MLP输入，从而消除了每块的MHA-MLP连接，并实现了MHA和MLP在单个GPU上的并行执行。此外，还提出了FAL+，通过将归一化的第一个注意力的输出来增强MLP的输入，以提高模型质量。

Result: FAL架构可以将多GPU训练时间最多减少44%，提高单GPU吞吐量最高1.18倍，并且在困惑度方面优于基线GPT。FAL+在不增加训练时间的情况下，实现了比基线模型更低的困惑度。

Conclusion: FAL和FAL+通过优化Transformer架构，有效降低了通信开销，提高了训练效率，并能在保持甚至提高模型性能的同时，减少训练时间和资源消耗。

Abstract: As training billion-scale transformers becomes increasingly common, employing
multiple distributed GPUs along with parallel training methods has become a
standard practice. However, existing transformer designs suffer from
significant communication overhead, especially in Tensor Parallelism (TP),
where each block's MHA-MLP connection requires an all-reduce communication.
Through our investigation, we show that the MHA-MLP connections can be bypassed
for efficiency, while the attention output of the first layer can serve as an
alternative signal for the bypassed connection. Motivated by the observations,
we propose FAL (First Attentions Last), an efficient transformer architecture
that redirects the first MHA output to the MLP inputs of the following layers,
eliminating the per-block MHA-MLP connections. This removes the all-reduce
communication and enables parallel execution of MHA and MLP on a single GPU. We
also introduce FAL+, which adds the normalized first attention output to the
MHA outputs of the following layers to augment the MLP input for the model
quality. Our evaluation shows that FAL reduces multi-GPU training time by up to
44%, improves single-GPU throughput by up to 1.18x, and achieves better
perplexity compared to the baseline GPT. FAL+ achieves even lower perplexity
without increasing the training time than the baseline.

</details>


### [406] [LeapFactual: Reliable Visual Counterfactual Explanation Using Conditional Flow Matching](https://arxiv.org/abs/2510.14623)
*Zhuo Cao,Xuan Zhao,Lena Krieger,Hanno Scharr,Ira Assent*

Main category: cs.LG

TL;DR: LeapFactual是一种新的反事实解释算法，通过条件流匹配克服了现有方法的局限性，能够生成可靠且信息丰富的反事实解释，即使在真实和学习的决策边界不一致时也是如此。它是一种模型无关的方法，可以处理需要人工注释的系统，并能生成可操作的见解，甚至可以作为新的训练数据来增强模型。


<details>
  <summary>Details</summary>
Motivation: 高风险领域（如医疗保健和科学研究）中机器学习（ML）和人工智能（AI）模型日益增长的集成，需要不仅准确而且可解释的模型。反事实解释通过识别输入到模型预测的最小更改来提供可解释性，从而提供更深入的见解。

Method: LeapFactual算法基于条件流匹配。

Result: LeapFactual生成可靠且信息丰富的反事实解释，即使在真实和学习的决策边界不一致时也是如此。它是一种模型无关的方法，可以处理需要人工注释的系统。实验表明，LeapFactual生成准确且符合分布的反事实解释，提供可操作的见解，并且可以作为新的训练数据来增强模型。

Conclusion: LeapFactual是一种新颖的反事实解释算法，克服了现有方法的局限性，并具有广泛的应用前景，能够增强科学知识发现和非专业人员的可解释性。

Abstract: The growing integration of machine learning (ML) and artificial intelligence
(AI) models into high-stakes domains such as healthcare and scientific research
calls for models that are not only accurate but also interpretable. Among the
existing explainable methods, counterfactual explanations offer
interpretability by identifying minimal changes to inputs that would alter a
model's prediction, thus providing deeper insights. However, current
counterfactual generation methods suffer from critical limitations, including
gradient vanishing, discontinuous latent spaces, and an overreliance on the
alignment between learned and true decision boundaries. To overcome these
limitations, we propose LeapFactual, a novel counterfactual explanation
algorithm based on conditional flow matching. LeapFactual generates reliable
and informative counterfactuals, even when true and learned decision boundaries
diverge. Following a model-agnostic approach, LeapFactual is not limited to
models with differentiable loss functions. It can even handle human-in-the-loop
systems, expanding the scope of counterfactual explanations to domains that
require the participation of human annotators, such as citizen science. We
provide extensive experiments on benchmark and real-world datasets showing that
LeapFactual generates accurate and in-distribution counterfactual explanations
that offer actionable insights. We observe, for instance, that our reliable
counterfactual samples with labels aligning to ground truth can be beneficially
used as new training data to enhance the model. The proposed method is broadly
applicable and enhances both scientific knowledge discovery and non-expert
interpretability.

</details>


### [407] [Galaxy Morphology Classification with Counterfactual Explanation](https://arxiv.org/abs/2510.14655)
*Zhuo Cao,Lena Krieger,Hanno Scharr,Ira Assent*

Main category: cs.LG

TL;DR: 提出了一种可解释的基于机器学习的星系形态学方法，结合了编码器-解码器架构和可逆流模型，以提供预测性能和决策过程的洞察。


<details>
  <summary>Details</summary>
Motivation: 星系形态学对于研究星系演化至关重要，但手动分析数据量大，因此需要基于机器学习的方法。然而，现有的方法往往缺乏可解释性。

Method: 将经典编码器-解码器架构与可逆流模型相结合。

Result: 该模型不仅能获得良好的预测性能，还能提供关于决策过程的反事实解释。

Conclusion: 所提出的方法能够提高星系形态学预测的可解释性。

Abstract: Galaxy morphologies play an essential role in the study of the evolution of
galaxies. The determination of morphologies is laborious for a large amount of
data giving rise to machine learning-based approaches. Unfortunately, most of
these approaches offer no insight into how the model works and make the results
difficult to understand and explain. We here propose to extend a classical
encoder-decoder architecture with invertible flow, allowing us to not only
obtain a good predictive performance but also provide additional information
about the decision process with counterfactual explanations.

</details>


### [408] [Geometric Moment Alignment for Domain Adaptation via Siegel Embeddings](https://arxiv.org/abs/2510.14666)
*Shayan Gharib,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: 我们提出一种基于黎曼几何的方法来解决无监督域自适应中的分布偏移问题，通过将一阶和二阶矩表示为SPD矩阵，并利用SPD矩阵流形上的黎曼距离进行对齐，从而实现更精确的跨域比较。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无监督域自适应中通常使用低阶矩匹配，但依赖于临时的相似性度量。本文提出一种更原则性的方法，利用分布的内在几何结构。

Method: 将一阶和二阶矩表示为单个对称正定（SPD）矩阵（通过Siegel嵌入），并利用SPD矩阵流形上的黎曼距离进行对齐，以匹配源域和目标域的分布。

Result: 在图像去噪和图像分类基准测试中，该方法能够更忠实地保留源域和目标域的均值和协方差结构，并与目标域误差界相关联。

Conclusion: 基于黎曼几何的矩匹配方法在无监督域自适应中是一种有效且原则性的方法，能够更准确地对齐分布并提高模型性能。

Abstract: We address the problem of distribution shift in unsupervised domain
adaptation with a moment-matching approach. Existing methods typically align
low-order statistical moments of the source and target distributions in an
embedding space using ad-hoc similarity measures. We propose a principled
alternative that instead leverages the intrinsic geometry of these
distributions by adopting a Riemannian distance for this alignment. Our key
novelty lies in expressing the first- and second-order moments as a single
symmetric positive definite (SPD) matrix through Siegel embeddings. This
enables simultaneous adaptation of both moments using the natural geometric
distance on the shared manifold of SPD matrices, preserving the mean and
covariance structure of the source and target distributions and yielding a more
faithful metric for cross-domain comparison. We connect the Riemannian manifold
distance to the target-domain error bound, and validate the method on image
denoising and image classification benchmarks. Our code is publicly available
at https://github.com/shayangharib/GeoAdapt.

</details>


### [409] [FedPPA: Progressive Parameter Alignment for Personalized Federated Learning](https://arxiv.org/abs/2510.14698)
*Maulidi Adi Prasetia,Muhamad Risqi U. Saputra,Guntur Dharma Putra*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Federated Learning (FL) is designed as a decentralized, privacy-preserving
machine learning paradigm that enables multiple clients to collaboratively
train a model without sharing their data. In real-world scenarios, however,
clients often have heterogeneous computational resources and hold
non-independent and identically distributed data (non-IID), which poses
significant challenges during training. Personalized Federated Learning (PFL)
has emerged to address these issues by customizing models for each client based
on their unique data distribution. Despite its potential, existing PFL
approaches typically overlook the coexistence of model and data heterogeneity
arising from clients with diverse computational capabilities. To overcome this
limitation, we propose a novel method, called Progressive Parameter Alignment
(FedPPA), which progressively aligns the weights of common layers across
clients with the global model's weights. Our approach not only mitigates
inconsistencies between global and local models during client updates, but also
preserves client's local knowledge, thereby enhancing personalization
robustness in non-IID settings. To further enhance the global model performance
while retaining strong personalization, we also integrate entropy-based
weighted averaging into the FedPPA framework. Experiments on three image
classification datasets, including MNIST, FMNIST, and CIFAR-10, demonstrate
that FedPPA consistently outperforms existing FL algorithms, achieving superior
performance in personalized adaptation.

</details>


### [410] [Seesaw: Accelerating Training by Balancing Learning Rate and Batch Size Scheduling](https://arxiv.org/abs/2510.14717)
*Alexandru Meterez,Depen Morwani,Jingfeng Wu,Costin-Andrei Oncescu,Cengiz Pehlevan,Sham Kakade*

Main category: cs.LG

TL;DR: Seesaw是一种新的批次大小调度策略，通过增加批次大小和调整学习率来加速大语言模型预训练，并在理论和实践上都证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在训练大语言模型时，通过增加批次大小（batch ramp）是一种有前景的策略。然而，对于Adam等自适应优化器，最优的批次大小调度策略尚不明确，通常需要凭经验进行调整。

Method: 提出了一种名为Seesaw的批次大小调度框架。当标准调度器减半学习率时，Seesaw将学习率乘以 $1/\
Theoretisch，我们提供了（据我们所知）第一个关于SGD在有噪声线性回归中的学习率衰减和批次大小增加之间等价性的有限样本证明，并在实践中观察到的方差主导状态下，将这种等价性扩展到归一化的SGD，这是Adam的一个易于处理的代理。

Result: 在150M/300M/600M参数模型上进行实验，Seesaw在相同的FLOPs下与余弦衰减效果相当，但将实际运行时间减少了约36%，接近理论分析所暗示的极限。

Conclusion: Seesaw通过在学习率衰减时增加批次大小，可以在保持损失动态的同时减少串行步骤，从而有效加速大语言模型的预训练。

Abstract: Increasing the batch size during training -- a ''batch ramp'' -- is a
promising strategy to accelerate large language model pretraining. While for
SGD, doubling the batch size can be equivalent to halving the learning rate,
the optimal strategy for adaptive optimizers like Adam is less clear. As a
result, any batch-ramp scheduling, if used at all, is typically tuned
heuristically. This work develops a principled framework for batch-size
scheduling and introduces Seesaw: whenever a standard scheduler would halve the
learning rate, Seesaw instead multiplies it by $1/\sqrt{2}$ and doubles the
batch size, preserving loss dynamics while reducing serial steps.
Theoretically, we provide, to our knowledge, the first finite-sample proof of
equivalence between learning-rate decay and batch-size ramp-up for SGD on noisy
linear regression, and we extend this equivalence to normalized SGD, a
tractable proxy for Adam, under a variance-dominated regime observed in
practice. Empirically, on 150M/300M/600M-parameter models trained at Chinchilla
scale using a constant (critical) batch size, Seesaw matches cosine decay at
equal FLOPs while reducing wall-clock time by $\approx 36\%$, approaching the
theoretical limit implied by our analysis.

</details>


### [411] [The Pursuit of Diversity: Multi-Objective Testing of Deep Reinforcement Learning Agents](https://arxiv.org/abs/2510.14727)
*Antony Bartlett,Cynthia Liem,Annibale Panichella*

Main category: cs.LG

TL;DR: INDAGO-Nexus是一种多目标搜索方法，通过联合优化故障可能性和测试场景多样性来发现DRL中的安全关键故障场景，相比INDAGO，它能发现更多独特的故障并减少故障时间。


<details>
  <summary>Details</summary>
Motivation: 现有工具（如INDAGO）在测试深度强化学习（DRL）智能体时，只关注最大化故障数量，这不能保证发现的场景具有多样性或揭示不同的错误类型，因此需要改进方法来发现更多样化的失败场景。

Method: INDAGO-Nexus是一种多目标搜索方法，它使用具有多种多样性度量和帕累托前沿选择策略的多目标进化算法，联合优化故障可能性和测试场景多样性。

Result: 在人形步行、自动驾驶汽车和停车代理三个DRL代理上评估INDAGO-Nexus。结果显示，与INDAGO相比，INDAGO-Nexus在SDC和停车场景中发现的独特故障分别增加了83%和40%，同时在所有代理中将故障时间减少了高达67%。

Conclusion: INDAGO-Nexus通过多目标优化成功地提高了测试DRL的效率，能够发现更多独特的失败场景并更快地发现失败。

Abstract: Testing deep reinforcement learning (DRL) agents in safety-critical domains
requires discovering diverse failure scenarios. Existing tools such as INDAGO
rely on single-objective optimization focused solely on maximizing failure
counts, but this does not ensure discovered scenarios are diverse or reveal
distinct error types. We introduce INDAGO-Nexus, a multi-objective search
approach that jointly optimizes for failure likelihood and test scenario
diversity using multi-objective evolutionary algorithms with multiple diversity
metrics and Pareto front selection strategies. We evaluated INDAGO-Nexus on
three DRL agents: humanoid walker, self-driving car, and parking agent. On
average, INDAGO-Nexus discovers up to 83% and 40% more unique failures (test
effectiveness) than INDAGO in the SDC and Parking scenarios, respectively,
while reducing time-to-failure by up to 67% across all agents.

</details>


### [412] [Beyond Multi-Token Prediction: Pretraining LLMs with Future Summaries](https://arxiv.org/abs/2510.14751)
*Divyat Mahajan,Sachin Goyal,Badr Youbi Idrissi,Mohammad Pezeshki,Ioannis Mitliagkas,David Lopez-Paz,Kartik Ahuja*

Main category: cs.LG

TL;DR: FSP是一种新的训练方法，通过预测未来文本的摘要来提高LLM在长期推理、规划和创意写作方面的能力，并在多个基准测试中优于NTP和MTP。


<details>
  <summary>Details</summary>
Motivation: 传统的下一个词预测（NTP）在处理长期推理、规划和创意写作方面存在局限性，这主要是由于强制教师训练。多词预测（MTP）虽然有所改进，但主要捕捉短期依赖关系。

Method: 提出了一种未来的摘要预测（FSP）方法，训练一个辅助头来预测长期未来的紧凑表示。探索了两种FSP变体：手工制作的摘要（例如，未来词袋摘要）和学习的摘要（使用从右到左训练的反向语言模型的嵌入）。

Result: 在3B和8B参数模型的预训练实验中，FSP在数学、推理和编码基准测试中均优于NTP和MTP。

Conclusion: FSP通过预测长期未来的紧凑表示，能够显著提高LLM在需要长期推理的任务上的表现。

Abstract: Next-token prediction (NTP) has driven the success of large language models
(LLMs), but it struggles with long-horizon reasoning, planning, and creative
writing, with these limitations largely attributed to teacher-forced training.
Multi-token prediction (MTP) partially mitigates these issues by predicting
several future tokens at once, but it mostly captures short-range dependencies
and offers limited improvement. We propose future summary prediction (FSP),
which trains an auxiliary head to predict a compact representation of the
long-term future, preserving information relevant for long-form generations. We
explore two variants of FSP: handcrafted summaries, for example, a bag of words
summary of the future of the sequence, and learned summaries, which use
embeddings produced by a reverse language model trained from right to left.
Large-scale pretraining experiments (3B and 8B-parameter models) demonstrate
that FSP provides improvements over both NTP and MTP across math, reasoning,
and coding benchmarks.

</details>


### [413] [Causal Discovery for Linear DAGs with Dependent Latent Variables via Higher-order Cumulants](https://arxiv.org/abs/2510.14780)
*Ming Cai,Penggang Gao,Hisayuki Hara*

Main category: cs.LG

TL;DR: 提出了一种新的算法，可以识别具有潜在混淆因素的线性非高斯无环图（LvLiNGAM）中的因果关系图，即使在潜在变量之间存在因果关系的情况下也是如此。


<details>
  <summary>Details</summary>
Motivation: 现有的LvLiNGAM因果发现方法要么假设潜在混淆变量是相互独立的，要么无法正确处理观测变量之间存在因果关系的情况。本研究旨在克服这些局限性。

Method: 利用观测数据的多阶累积量来识别因果结构。

Result: 通过广泛的模拟和真实世界数据的实验，证明了所提出算法的有效性和实用性。

Conclusion: 所提出的算法能够成功地识别LvLiNGAM中的因果关系图，即使在潜在变量之间以及潜在变量和观测变量之间存在因果关系的情况下也是如此。

Abstract: This paper addresses the problem of estimating causal directed acyclic graphs
in linear non-Gaussian acyclic models with latent confounders (LvLiNGAM).
Existing methods assume mutually independent latent confounders or cannot
properly handle models with causal relationships among observed variables.
  We propose a novel algorithm that identifies causal DAGs in LvLiNGAM,
allowing causal structures among latent variables, among observed variables,
and between the two. The proposed method leverages higher-order cumulants of
observed data to identify the causal structure. Extensive simulations and
experiments with real-world data demonstrate the validity and practical utility
of the proposed algorithm.

</details>


### [414] [Active Jammer Localization via Acquisition-Aware Path Planning](https://arxiv.org/abs/2510.14790)
*Luis González-Gudiño,Mariona Jaramillo-Civill,Pau Closas,Tales Imbiriba*

Main category: cs.LG

TL;DR: 提出一种结合贝叶斯优化和考虑获取信息的路径规划的有源干扰器定位框架。


<details>
  <summary>Details</summary>
Motivation: 与被动的众包方法不同，该框架能够自适应地引导移动代理收集高价值的接收信号强度测量数据，同时考虑城市障碍物和移动性约束。

Method: 修改了A*算法，提出A-UCB*，将获取值纳入轨迹成本，从而规划出高获取值的路径。

Result: 在真实城市场景的模拟中，与无信息基线相比，该方法用更少的测量数据实现了精确的定位，并在不同环境下表现出一致的性能。

Conclusion: 所提出的方法在城市环境中能够用更少的测量数据实现精确的干扰器定位。

Abstract: We propose an active jammer localization framework that combines Bayesian
optimization with acquisition-aware path planning. Unlike passive crowdsourced
methods, our approach adaptively guides a mobile agent to collect high-utility
Received Signal Strength measurements while accounting for urban obstacles and
mobility constraints. For this, we modified the A* algorithm, A-UCB*, by
incorporating acquisition values into trajectory costs, leading to
high-acquisition planned paths. Simulations on realistic urban scenarios show
that the proposed method achieves accurate localization with fewer measurements
compared to uninformed baselines, demonstrating consistent performance under
different environments.

</details>


### [415] [Rethinking Hebbian Principle: Low-Dimensional Structural Projection for Unsupervised Learning](https://arxiv.org/abs/2510.14810)
*Shikuang Deng,Jiayuan Zhang,Yuhang Wu,Ting Chen,Shi Gu*

Main category: cs.LG

TL;DR: SPHeRe是一种新的无监督学习方法，它结合了正交性和结构信息保持，以解决传统赫布学习在机器学习中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的赫布学习方法在应用于机器学习时存在更新约束和反馈中介的不足，限制了其在复杂网络和任务中的扩展性。

Method: SPHeRe通过引入一个局部的辅助非线性模块，集成了正交性和结构信息保持。结构信息保持的损失通过一个轻量级的辅助投影反向传播到输入，这在概念上起到了反馈中介的作用，同时正交性约束确保了更新幅度的有界性。

Result: SPHeRe在CIFAR-10、CIFAR-100和Tiny-ImageNet等标准图像分类基准测试中，取得了无监督突触可塑性方法的最优（SOTA）性能。此外，该方法在持续学习、迁移学习和图像重建任务中也表现出强大的有效性和鲁棒性、泛化性。

Conclusion: SPHeRe证明了赫布无监督学习规则在现代深度学习框架中的竞争力和潜力，展示了在不严重依赖严格反向传播的情况下，实现高效且受生物学启发的学习算法的可能性。

Abstract: Hebbian learning is a biological principle that intuitively describes how
neurons adapt their connections through repeated stimuli. However, when applied
to machine learning, it suffers serious issues due to the unconstrained updates
of the connections and the lack of accounting for feedback mediation. Such
shortcomings limit its effective scaling to complex network architectures and
tasks. To this end, here we introduce the Structural Projection Hebbian
Representation (SPHeRe), a novel unsupervised learning method that integrates
orthogonality and structural information preservation through a local auxiliary
nonlinear block. The loss for structural information preservation
backpropagates to the input through an auxiliary lightweight projection that
conceptually serves as feedback mediation while the orthogonality constraints
account for the boundedness of updating magnitude. Extensive experimental
results show that SPHeRe achieves SOTA performance among unsupervised synaptic
plasticity approaches on standard image classification benchmarks, including
CIFAR-10, CIFAR-100, and Tiny-ImageNet. Furthermore, the method exhibits strong
effectiveness in continual learning and transfer learning scenarios, and image
reconstruction tasks show the robustness and generalizability of the extracted
features. This work demonstrates the competitiveness and potential of Hebbian
unsupervised learning rules within modern deep learning frameworks,
demonstrating the possibility of efficient and biologically inspired learning
algorithms without the strong dependence on strict backpropagation. Our code is
available at https://github.com/brain-intelligence-lab/SPHeRe.

</details>


### [416] [Efficient Dynamic Structured Sparse Training with Learned Shuffles](https://arxiv.org/abs/2510.14812)
*Abhishek Tyagi,Arjun Iyer,Liam Young,William H Renninger,Christopher Kanan,Yuhao Zhu*

Main category: cs.LG

TL;DR: 通过学习排列矩阵来增强结构化稀疏训练，在准确性和效率之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 结构化稀疏训练在GPU上训练和推理速度更快，但准确性不如非结构化动态稀疏训练。这是因为结构化稀疏性限制了模型可以探索的权重掩码的范围，从而降低了表达能力。

Method: 提出了一种称为排列增强动态稀疏训练（PA-DST）的方法，该方法在每个层中联合学习结构化权重矩阵和排列矩阵。该方法应用于块状、N:M和对角线结构，以增强它们的表达能力。

Result: PA-DST在ImageNet-1K（ViT-B/16）和WikiText-103（GPT-2）数据集上，实现了与非结构化基线（RigL、SET）相当的准确性（在90-95%的稀疏度下），同时训练速度提高了1.21倍，推理速度提高了2.9倍。

Conclusion: 结构化稀疏性结合学习到的排列矩阵是提高模型准确性和训练/推理效率的理想解决方案。

Abstract: Structured sparsity accelerates training and inference on modern GPUs, yet it
still trails unstructured dynamic sparse training (DST) in accuracy. The
shortfall stems from a loss of expressivity: whereas a dense layer can realize
every possible mask obtained by choosing any $w$ active weights out of $n$, a
fixed block or N:M layout explores only a subset of those possibilities. We
propose to close this gap by learning, for each layer, a single permutation
matrix jointly with the structured weight matrix. Applied to three canonical
structures -- block, N:M, and diagonals -- we show that permutation-augmented
DST (PA-DST) matches unstructured baselines (RigL, SET) at 90--95\% sparsity on
ImageNet-1K (ViT-B/16) and WikiText-103 (GPT-2), yet trains up to $1.21\times$
and infers up to $2.9\times$ faster. The results position structure + learned
permutation as a sweet spot between accuracy and efficiency.

</details>


### [417] [Tackling Time-Series Forecasting Generalization via Mitigating Concept Drift](https://arxiv.org/abs/2510.14814)
*Zhiyuan Zhao,Haoxin Liu,B. Aditya Prakash*

Main category: cs.LG

TL;DR: 该研究提出了一种名为ShifTS的新框架，用于解决时间序列预测中的概念漂移和时间漂移问题，并通过软注意力机制来识别不变模式，实验证明该框架能有效提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据的动态性导致分布可能随时间发生变化，现有的时间序列预测模型在处理时间漂移问题上已取得一定进展，但对概念漂移问题的关注相对较少。然而，传统的基于不变性学习的概念漂移方法在时间序列预测中面临挑战。因此，有必要研究能同时处理这两种漂移问题的方法。

Method: 该研究首先强调了时间漂移问题在概念漂移问题之前的重要性，并提出了一种名为ShifTS的、与具体方法无关的框架。该框架首先解决时间漂移问题，然后解决概念漂移问题。在解决概念漂移问题时，研究者提出了一种软注意力机制，用于从回顾期和预测期的时间序列中提取不变模式。

Result: 实验结果表明，ShifTS框架能够持续提升不同数据集上各种预测模型（方法无关）的预测准确性，并且优于现有的仅处理概念漂移、仅处理时间漂移或同时处理两者的基线方法。

Conclusion: ShifTS框架通过统一的方法有效地解决了时间序列预测中的时间漂移和概念漂移问题，并通过软注意力机制识别不变模式，显著提高了预测的准确性。

Abstract: Time-series forecasting finds broad applications in real-world scenarios. Due
to the dynamic nature of time series data, it is important for time-series
forecasting models to handle potential distribution shifts over time. In this
paper, we initially identify two types of distribution shifts in time series:
concept drift and temporal shift. We acknowledge that while existing studies
primarily focus on addressing temporal shift issues in time series forecasting,
designing proper concept drift methods for time series forecasting has received
comparatively less attention.
  Motivated by the need to address potential concept drift, while conventional
concept drift methods via invariant learning face certain challenges in
time-series forecasting, we propose a soft attention mechanism that finds
invariant patterns from both lookback and horizon time series. Additionally, we
emphasize the critical importance of mitigating temporal shifts as a
preliminary to addressing concept drift. In this context, we introduce ShifTS,
a method-agnostic framework designed to tackle temporal shift first and then
concept drift within a unified approach. Extensive experiments demonstrate the
efficacy of ShifTS in consistently enhancing the forecasting accuracy of
agnostic models across multiple datasets, and outperforming existing concept
drift, temporal shift, and combined baselines.

</details>


### [418] [Programmatic Representation Learning with Language Models](https://arxiv.org/abs/2510.14825)
*Gabriel Poesia,Georgia Gabriela Sampaio*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 LeaPR 的新模型类别，通过结合大型语言模型（LLMs）生成的代码特征和决策树来学习可解释的预测模型，在多个任务上取得了与神经网络相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的决策树模型在特征选择上表现不佳，而神经网络虽然能从原始数据中学习表示，但缺乏可解释性且计算成本高。现有方法需要一种能够从原始数据中学习可解释表示的替代方案。

Method: LeaPR 模型通过两种算法进行学习：1. 适应 FunSearch 算法来学习特征函数。2. ID3 算法的变体，在需要时动态生成新特征来分裂叶节点。LLMs 被用来根据领域知识和代码生成能力合成特征函数。

Result: 在国际象棋局面评估、图像和文本分类等多个实验任务中，LeaPR 模型展现了其生成高质量、无需神经网络的预测器的能力，其性能与神经网络相当。

Conclusion: LeaPR 模型提供了一个灵活的端到端学习可解释表示的新范式，其特征和预测都可以轻松检查和理解，为机器学习领域提供了一种新的思路。

Abstract: Classical models for supervised machine learning, such as decision trees, are
efficient and interpretable predictors, but their quality is highly dependent
on the particular choice of input features. Although neural networks can learn
useful representations directly from raw data (e.g., images or text), this
comes at the expense of interpretability and the need for specialized hardware
to run them efficiently. In this paper, we explore a hypothesis class we call
Learned Programmatic Representations (LeaPR) models, which stack arbitrary
features represented as code (functions from data points to scalars) and
decision tree predictors. We synthesize feature functions using Large Language
Models (LLMs), which have rich prior knowledge in a wide range of domains and a
remarkable ability to write code using existing domain-specific libraries. We
propose two algorithms to learn LeaPR models from supervised data. First, we
design an adaptation of FunSearch to learn features rather than directly
generate predictors. Then, we develop a novel variant of the classical ID3
algorithm for decision tree learning, where new features are generated on
demand when splitting leaf nodes. In experiments from chess position evaluation
to image and text classification, our methods learn high-quality, neural
network-free predictors often competitive with neural networks. Our work
suggests a flexible paradigm for learning interpretable representations
end-to-end where features and predictions can be readily inspected and
understood.

</details>


### [419] [To Infinity and Beyond: Tool-Use Unlocks Length Generalization in State Space Models](https://arxiv.org/abs/2510.14826)
*Eran Malach,Omid Saremi,Sinead Williamson,Arwen Bradley,Aryo Lotfi,Emmanuel Abbe,Josh Susskind,Etai Littwin*

Main category: cs.LG

TL;DR: SSMs 在长上下文生成方面存在理论局限性，但通过允许它们与外部工具交互，可以克服这一局限性，从而在各种任务上实现出色的长度泛化能力。


<details>
  <summary>Details</summary>
Motivation: SSMs 的主要优势在于长上下文和长格式生成方面的高效性，但本研究表明它们无法准确解决任何“真正长格式”的生成问题，这削弱了它们的主要竞争优势。

Method: 研究人员首先通过一个简单的理论结果来证明 SSMs 的局限性，然后提出通过允许 SSMs 交互式地访问外部工具来缓解这一局限性。他们还表明，通过选择合适的工具访问和依赖于问题的训练数据，SSMs 可以学会解决任何可处理的问题并泛化到任意长度/复杂度的问题。

Result: 工具增强的 SSMs 在各种算术、推理和编码任务上实现了显著的长度泛化能力。

Conclusion: SSMs 结合外部工具访问，在交互式工具和代理环境中，可以成为 Transformers 的一种潜在的高效替代方案。

Abstract: State Space Models (SSMs) have become the leading alternative to Transformers
for sequence modeling. Their primary advantage is efficiency in long-context
and long-form generation, enabled by fixed-size memory and linear scaling of
computational complexity. We begin this work by showing a simple theoretical
result stating that SSMs cannot accurately solve any ``truly long-form''
generation problem (in a sense we formally define), undermining their main
competitive advantage. However, we show that this limitation can be mitigated
by allowing SSMs interactive access to external tools. In fact, we show that
given the right choice of tool access and problem-dependent training data, SSMs
can learn to solve any tractable problem and generalize to arbitrary problem
length/complexity (i.e., achieve length generalization). Following our
theoretical finding, we demonstrate that tool-augmented SSMs achieve remarkable
length generalization on a variety of arithmetic, reasoning, and coding tasks.
These findings highlight SSMs as a potential efficient alternative to
Transformers in interactive tool-based and agentic settings.

</details>


### [420] [Intelligent Dynamic Handover via AI-assisted Signal Quality Prediction in 6G Multi-RAT Networks](https://arxiv.org/abs/2510.14832)
*Maria Lamprini A. Bartsioka,Anastasios Giannopoulos,Sotirios Spantideas*

Main category: cs.LG

TL;DR: 该研究提出了一种基于机器学习的预测性条件切换（P-CHO）框架，用于在6G多无线接入技术（multi-RAT）网络中实现可靠的切换决策，以应对快速变化的信道、干扰和异构覆盖等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的多RAT网络切换决策机制过于被动，依赖于瞬时测量和阈值事件，无法满足6G网络对快速、可靠切换的需求。

Method: 提出了一种由RAT切换控制器协调的P-CHO框架，该框架利用模型驱动的短时间序列信号质量预测，通过长短期记忆（LSTM）神经网络进行训练，并考虑了滞后条件和不同的切换模式（软切换和硬切换）。

Result: P-CHO框架能够减少切换失败和乒乓切换事件，证明了其在多RAT环境下的有效性。

Conclusion: 所提出的P-CHO框架通过准确、低延迟和主动的切换，为6G多RAT部署中的机器学习辅助切换管理提供了有效的解决方案。

Abstract: The emerging paradigm of 6G multiple Radio Access Technology (multi-RAT)
networks, where cellular and Wireless Fidelity (WiFi) transmitters coexist,
requires mobility decisions that remain reliable under fast channel dynamics,
interference, and heterogeneous coverage. Handover in multi-RAT deployments is
still highly reactive and event-triggered, relying on instantaneous
measurements and threshold events. This work proposes a Machine Learning
(ML)-assisted Predictive Conditional Handover (P-CHO) framework based on a
model-driven and short-horizon signal quality forecasts. We present a
generalized P-CHO sequence workflow orchestrated by a RAT Steering Controller,
which standardizes data collection, parallel per-RAT predictions, decision
logic with hysteresis-based conditions, and CHO execution. Considering a
realistic multi-RAT environment, we train RAT-aware Long Short Term Memory
(LSTM) networks to forecast the signal quality indicators of mobile users along
randomized trajectories. The proposed P-CHO models are trained and evaluated
under different channel models for cellular and IEEE 802.11 WiFi integrated
coverage. We study the impact of hyperparameter tuning of LSTM models under
different system settings, and compare direct multi-step versus recursive P-CHO
variants. Comparisons against baseline predictors are also carried out.
Finally, the proposed P-CHO is tested under soft and hard handover settings,
showing that hysteresis-enabled P-CHO scheme is able to reduce handover
failures and ping-pong events. Overall, the proposed P-CHO framework can enable
accurate, low-latency, and proactive handovers suitable for ML-assisted
handover steering in 6G multi-RAT deployments.

</details>


### [421] [Reinforcement Learning with Stochastic Reward Machines](https://arxiv.org/abs/2510.14837)
*Jan Corazza,Ivan Gavran,Daniel Neider*

Main category: cs.LG

TL;DR: 提出随机奖励机器（SRM）来处理有噪声的强化学习问题，并提出一种基于约束满足的学习算法，该算法可以学习最小的SRM并保证收敛到最优策略。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励机器（RM）算法在处理稀疏和依赖复杂动作序列的奖励时，假设奖励没有噪声，这在实践中不切实际。

Method: 提出随机奖励机器（SRM）的概念，并开发一种基于约束满足的学习算法，从强化学习代理的探索中学习最小的SRM。

Result: 所提出的算法可以与现有的RM强化学习算法配对，保证在极限情况下收敛到最优策略。实验结果表明，该算法在两个案例研究中优于现有方法和处理噪声奖励函数的朴素方法。

Conclusion: 所提出的基于约束满足的学习最小随机奖励机器的算法能够有效地处理有噪声的奖励函数，并能与现有的强化学习算法结合，在实践中具有应用价值。

Abstract: Reward machines are an established tool for dealing with reinforcement
learning problems in which rewards are sparse and depend on complex sequences
of actions. However, existing algorithms for learning reward machines assume an
overly idealized setting where rewards have to be free of noise. To overcome
this practical limitation, we introduce a novel type of reward machines, called
stochastic reward machines, and an algorithm for learning them. Our algorithm,
based on constraint solving, learns minimal stochastic reward machines from the
explorations of a reinforcement learning agent. This algorithm can easily be
paired with existing reinforcement learning algorithms for reward machines and
guarantees to converge to an optimal policy in the limit. We demonstrate the
effectiveness of our algorithm in two case studies and show that it outperforms
both existing methods and a naive approach for handling noisy reward functions.

</details>


### [422] [Backdoor Unlearning by Linear Task Decomposition](https://arxiv.org/abs/2510.14845)
*Amel Abdelraheem,Alessandro Favero,Gerome Bovet,Pascal Frossard*

Main category: cs.LG

TL;DR: Foundation models are vulnerable to adversarial attacks and backdoors. This paper proposes a novel unlearning method that isolates and erases backdoor influences from model weights without significantly impacting clean accuracy, achieving near-perfect unlearning and retaining 96% of clean accuracy on average. The method also works even when the attack is unknown by estimating triggers.


<details>
  <summary>Details</summary>
Motivation: Existing methods for removing backdoors from foundation models are costly, require retraining, and can degrade performance on unrelated tasks. There's a need for a method that can remove backdoors without compromising the model's general capabilities.

Method: The paper studies how backdoors are encoded in the weight space of foundation models, discovering they are disentangled from benign tasks. Based on this, a simple unlearning method is introduced that leverages this disentanglement to isolate and erase the backdoor's influence with minimal impact on clean performance. The method can also estimate and use reverse-engineered triggers when the attack is unknown.

Result: The proposed unlearning method achieves approximately perfect unlearning while retaining, on average, 96% of clean accuracy on CLIP-based models with common adversarial triggers. It also demonstrates successful unlearning even when the attack and its presence are unknown, by estimating triggers. The method shows a better tradeoff between unlearning and clean accuracy compared to existing state-of-the-art defenses.

Conclusion: Backdoors in foundation models are encoded in a disentangled manner within the weight space, allowing for their isolation and erasure without significantly harming the model's benign capabilities. The proposed unlearning method effectively leverages this disentanglement for efficient and accurate backdoor removal, offering a superior tradeoff compared to current defenses.

Abstract: Foundation models have revolutionized computer vision by enabling broad
generalization across diverse tasks. Yet, they remain highly susceptible to
adversarial perturbations and targeted backdoor attacks. Mitigating such
vulnerabilities remains an open challenge, especially given that the
large-scale nature of the models prohibits retraining to ensure safety.
Existing backdoor removal approaches rely on costly fine-tuning to override the
harmful behavior, and can often degrade performance on other unrelated tasks.
This raises the question of whether backdoors can be removed without
compromising the general capabilities of the models. In this work, we address
this question and study how backdoors are encoded in the model weight space,
finding that they are disentangled from other benign tasks. Specifically, this
separation enables the isolation and erasure of the backdoor's influence on the
model with minimal impact on clean performance. Building on this insight, we
introduce a simple unlearning method that leverages such disentanglement.
Through extensive experiments with CLIP-based models and common adversarial
triggers, we show that, given the knowledge of the attack, our method achieves
approximately perfect unlearning, while retaining, on average, 96% of clean
accuracy. Additionally, we demonstrate that even when the attack and its
presence are unknown, our method successfully unlearns backdoors by proper
estimation using reverse-engineered triggers. Overall, our method consistently
yields better unlearning and clean accuracy tradeoffs when compared to present
state-of-the-art defenses.

</details>


### [423] [Predicting kernel regression learning curves from only raw data statistics](https://arxiv.org/abs/2510.14878)
*Dhruva Karkada,Joseph Turnbull,Yuxi Liu,James B. Simon*

Main category: cs.LG

TL;DR: We introduce the Hermite eigenstructure ansatz (HEA), an analytical approximation for kernel eigenvalues and eigenfunctions on real image datasets, enabling accurate prediction of learning curves and providing a theoretical framework for understanding learning algorithms.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a theoretical framework that can predict learning curves (test risk vs. sample size) for kernel regression on real datasets, using only the empirical data covariance matrix and an empirical polynomial decomposition of the target function.

Method: The study proposes the Hermite eigenstructure ansatz (HEA), an analytical approximation of a kernel's eigenvalues and eigenfunctions with respect to an anisotropic data distribution. This approximation is proven for Gaussian data and found to be effective for real image data. The HEA is used to predict learning curves by relating kernel eigenstructure to test risk, and its applicability is extended to observe the behavior of MLPs in the feature-learning regime.

Result: The HEA framework successfully predicts learning curves on real image datasets like CIFAR-5m, SVHN, and ImageNet. It is found that real image data often behaves 'Gaussian enough' for the HEA to be accurate. Furthermore, the study empirically shows that MLPs in the feature-learning regime learn Hermite polynomials in an order consistent with the HEA predictions.

Conclusion: The HEA framework demonstrates the possibility of an end-to-end theory of learning that connects dataset structure to model performance for non-trivial learning algorithms on real-world datasets, specifically in the context of kernel regression and feature learning in MLPs.

Abstract: We study kernel regression with common rotation-invariant kernels on real
datasets including CIFAR-5m, SVHN, and ImageNet. We give a theoretical
framework that predicts learning curves (test risk vs. sample size) from only
two measurements: the empirical data covariance matrix and an empirical
polynomial decomposition of the target function $f_*$. The key new idea is an
analytical approximation of a kernel's eigenvalues and eigenfunctions with
respect to an anisotropic data distribution. The eigenfunctions resemble
Hermite polynomials of the data, so we call this approximation the Hermite
eigenstructure ansatz (HEA). We prove the HEA for Gaussian data, but we find
that real image data is often "Gaussian enough" for the HEA to hold well in
practice, enabling us to predict learning curves by applying prior results
relating kernel eigenstructure to test risk. Extending beyond kernel
regression, we empirically find that MLPs in the feature-learning regime learn
Hermite polynomials in the order predicted by the HEA. Our HEA framework is a
proof of concept that an end-to-end theory of learning which maps dataset
structure all the way to model performance is possible for nontrivial learning
algorithms on real datasets.

</details>


### [424] [Learning When Not to Learn: Risk-Sensitive Abstention in Bandits with Unbounded Rewards](https://arxiv.org/abs/2510.14884)
*Sarah Liaw,Benjamin Plaut*

Main category: cs.LG

TL;DR: 在有界风险的决策问题中，提出了一种基于谨慎探索的算法，该算法通过定义可信区域并仅在能够证明无害的情况下进行承诺来学习何时不学习，并在i.i.d.输入下实现了次线性遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 现有的顺序决策理论假设所有错误都是可恢复的，这在高风险的人工智能应用中可能导致无法弥补的损害。一些现有方法通过寻求导师的帮助来避免无法弥补的错误，但导师并非总能提供帮助。

Method: 将问题形式化为一个具有弃权选项的两动作上下文老虎机模型。代理观察输入，可以选择弃权（奖励为0）或承诺（执行预先存在的任务策略）。承诺的奖励虽然有上界但可能任意负，并假定为Lipschitz连续。提出了一种基于谨慎探索的算法，该算法学习何时不学习，并仅在可信区域内进行承诺。

Result: 在i.i.d.输入下，证明了该算法具有次线性遗憾界限，理论上证明了谨慎探索在将学习代理安全部署到高风险环境中的有效性。

Conclusion: 所提出的基于谨慎探索的算法能够安全地处理具有无界奖励的学习问题，并且在i.i.d.输入下实现了理论上可证明的次线性遗憾界限，为在高风险环境中部署学习代理提供了一种有效的方法。

Abstract: In high-stakes AI applications, even a single action can cause irreparable
damage. However, nearly all of sequential decision-making theory assumes that
all errors are recoverable (e.g., by bounding rewards). Standard bandit
algorithms that explore aggressively may cause irreparable damage when this
assumption fails. Some prior work avoids irreparable errors by asking for help
from a mentor, but a mentor may not always be available. In this work, we
formalize a model of learning with unbounded rewards without a mentor as a
two-action contextual bandit with an abstain option: at each round the agent
observes an input and chooses either to abstain (always 0 reward) or to commit
(execute a preexisting task policy). Committing yields rewards that are
upper-bounded but can be arbitrarily negative, and the commit reward is assumed
Lipschitz in the input. We propose a caution-based algorithm that learns when
not to learn: it chooses a trusted region and commits only where the available
evidence does not already certify harm. Under these conditions and i.i.d.
inputs, we establish sublinear regret guarantees, theoretically demonstrating
the effectiveness of cautious exploration for deploying learning agents safely
in high-stakes environments.

</details>


### [425] [Reasoning with Sampling: Your Base Model is Smarter Than You Think](https://arxiv.org/abs/2510.14901)
*Aayush Karan,Yilun Du*

Main category: cs.LG

TL;DR: 通过纯粹的推理和采样，在不进行额外训练的情况下，从基础模型中提取与RL训练相当的推理能力，并克服了RL训练的样本多样性下降问题。


<details>
  <summary>Details</summary>
Motivation: 探究在不进行额外训练的情况下，仅通过推理和采样，是否能从基础模型中激发可比肩甚至超越RL训练的推理能力。

Method: 提出一种简单的迭代采样算法，借鉴MCMC技术，利用基础模型自身的似然性进行采样。

Result: 在MATH500、HumanEval和GPQA等多种单次推理任务上，该算法显著提升了基础模型的推理能力，效果接近甚至超越了RL训练。同时，该方法避免了RL训练中常见的样本多样性下降问题。

Conclusion: 该方法无需训练、无需精选数据集、无需验证器，具有广泛的适用性，可用于易于验证的领域之外。

Abstract: Frontier reasoning models have exhibited incredible capabilities across a
wide array of disciplines, driven by posttraining large language models (LLMs)
with reinforcement learning (RL). However, despite the widespread success of
this paradigm, much of the literature has been devoted to disentangling truly
novel behaviors that emerge during RL but are not present in the base models.
In our work, we approach this question from a different angle, instead asking
whether comparable reasoning capabilites can be elicited from base models at
inference time by pure sampling, without any additional training. Inspired by
Markov chain Monte Carlo (MCMC) techniques for sampling from sharpened
distributions, we propose a simple iterative sampling algorithm leveraging the
base models' own likelihoods. Over different base models, we show that our
algorithm offers substantial boosts in reasoning that nearly match and even
outperform those from RL on a wide variety of single-shot tasks, including
MATH500, HumanEval, and GPQA. Moreover, our sampler avoids the collapse in
diversity over multiple samples that is characteristic of RL-posttraining.
Crucially, our method does not require training, curated datasets, or a
verifier, suggesting broad applicability beyond easily verifiable domains.

</details>


### [426] [Circuit Insights: Towards Interpretability Beyond Activations](https://arxiv.org/abs/2510.14936)
*Elena Golimblevskaia,Aakriti Jain,Bruno Puri,Ammar Ibrahim,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.LG

TL;DR: 现有模型解释方法存在局限，提出WeightLens和CircuitLens两种新方法，以提高模型可解释性和电路分析的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有模型解释方法（如人工检查、自动解释）存在局限性，无法有效处理复杂模型和大规模任务。Transcoders的出现为系统性电路分析提供了基础，但仍需进一步发展。

Method: 提出WeightLens和CircuitLens两种互补方法。WeightLens直接从权重解释特征，无需外部模型或数据集。CircuitLens则关注特征激活如何由组件交互产生，揭示电路层面的动力学。

Result: WeightLens在独立特征分析上性能优于现有方法。CircuitLens能识别仅基于激活的方法无法发现的电路动力学。

Conclusion: WeightLens和CircuitLens相结合，提高了模型可解释性的鲁棒性，增强了电路进行可扩展的机制分析的能力，同时保持了效率和质量。

Abstract: The fields of explainable AI and mechanistic interpretability aim to uncover
the internal structure of neural networks, with circuit discovery as a central
tool for understanding model computations. Existing approaches, however, rely
on manual inspection and remain limited to toy tasks. Automated
interpretability offers scalability by analyzing isolated features and their
activations, but it often misses interactions between features and depends
strongly on external LLMs and dataset quality. Transcoders have recently made
it possible to separate feature attributions into input-dependent and
input-invariant components, providing a foundation for more systematic circuit
analysis. Building on this, we propose WeightLens and CircuitLens, two
complementary methods that go beyond activation-based analysis. WeightLens
interprets features directly from their learned weights, removing the need for
explainer models or datasets while matching or exceeding the performance of
existing methods on context-independent features. CircuitLens captures how
feature activations arise from interactions between components, revealing
circuit-level dynamics that activation-only approaches cannot identify.
Together, these methods increase interpretability robustness and enhance
scalable mechanistic analysis of circuits while maintaining efficiency and
quality.

</details>


### [427] [Efficient Parallel Samplers for Recurrent-Depth Models and Their Connection to Diffusion Language Models](https://arxiv.org/abs/2510.14961)
*Jonas Geiping,Xinyu Yang,Guinan Su*

Main category: cs.LG

TL;DR: 循环深度模型（如Transformer）可以通过重复层来增强计算能力，在推理和语言建模任务上表现优越。本文提出了一种新的扩散强制采样器，用于加速这些模型的生成过程，通过在每次前向传播中并行解码和细化潜在状态，理论上比传统自回归生成更具表现力，并在现有模型上实现了高达5倍的加速。


<details>
  <summary>Details</summary>
Motivation: 探究循环深度模型与扩散语言模型之间的关系，并开发一种加速循环深度模型生成的新采样器。

Method: 提出了一种新的扩散强制采样器，该采样器通过在每次模型前向传播中解码新标记，同时并行细化这些标记的潜在状态来实现加速。此方法基于扩散模型原理，可直接应用于现有的循环深度Transformer模型。

Result: 提出的采样器在理论上比相同时间预算下的基线自回归生成更具表现力。在实际应用中，该采样器可直接应用于现有的3.5B循环深度Transformer模型，无需进行任何调整，即可实现高达5倍的加速。

Conclusion: 提出了一种有效的并行化推理计算的方法，并表明循环深度模型可以被视为强大的、连续的（尽管是因果的）扩散语言模型。

Abstract: Language models with recurrent depth, also referred to as universal or looped
when considering transformers, are defined by the capacity to increase their
computation through the repetition of layers. Recent efforts in pretraining
have demonstrated that these architectures can scale to modern language
modeling tasks while exhibiting advantages in reasoning tasks. In this work, we
examine the relationship between recurrent-depth models and diffusion language
models. Building on their similarities, we develop a new diffusion forcing
sampler for these models to accelerate generation. The sampler advances by
decoding new tokens at every forward pass of the model, while the latent states
of these tokens can be further refined in parallel through recurrence.
Theoretically, generation with our sampler is strictly more expressive than the
baseline autoregressive generation using the same time budget on modern
hardware. Moreover, this sampler, based on principles from diffusion
literature, can be directly applied to existing 3.5B recurrent-depth
transformers without any tuning, leading to up to a 5x speedup. Consequently,
our findings not only provide an efficient mechanism for parallelizing the
extra computation in recurrent-depth models at inference, but also suggest that
such models can be naturally viewed as strong continuous, though causal,
diffusion language models.

</details>


### [428] [Identity-Link IRT for Label-Free LLM Evaluation: Preserving Additivity in TVD-MI Scores](https://arxiv.org/abs/2510.14966)
*Zachary Robertson*

Main category: cs.LG

TL;DR: TVD-MI 的二元决策可以通过加性结构进行平均，以获得适合项目反应理论 (IRT) 的概率分数。


<details>
  <summary>Details</summary>
Motivation: 将 TVD-MI 的二元决策转化为适合 IRT 的概率分数，以解决现有 IRT 模型中非线性链接函数引入的曲率问题。

Method: 我们推导了一个剪辑线性模型，该模型源自基尼熵最大化，并将其转化为一个盒约束最小二乘问题，并表明与传统的几率/概率模型相比，恒等链接可以更好地保留数据的加性结构。

Result: 在三个领域中，恒等链接与传统的几率/概率模型相比，在原始数据上产生的曲率要小得多。剪辑线性模型在 33% 的覆盖率下实现了 0.117 的 RMSE，同时保持了代理排名（Spearman $ho = 0.972$），评估次数是完全稠密的模型的 1/3。此外，GPT-4o-mini 和 Llama3-70b 之间的评估显示出对代理排名的强烈一致性（$ho = 0.872$），并且恒等链接的优势是一致的。

Conclusion: TVD-MI 的几何结构最好通过恒等映射来保留，以实现高效的 LLM 评估，该方法也适用于其他有界响应域。

Abstract: Pairwise comparisons of large language models using total variation distance
mutual information (TVD-MI) produce binary critic decisions per pair. We show
that averaging TVD-MI's binary trials yields centered-probability scores with
additive structure suitable for item-response theory (IRT) without nonlinear
link functions. Maximum-likelihood approaches to IRT use logistic links, but we
find empirically that these transformations introduce curvature that breaks
additivity: across three domains, the identity link yields median curl on raw
data of 0.080-0.150 (P95 = [0.474, 0.580]), whereas probit/logit introduce
substantially higher violations (median [0.245, 0.588], P95 [0.825, 2.252]). We
derive this clipped-linear model from Gini entropy maximization, yielding a
box-constrained least-squares formulation that handles boundary saturation. At
33% coverage, we achieve holdout RMSE $0.117 \pm 0.008$ while preserving agent
rankings (Spearman $\rho = 0.972 \pm 0.015$), three times fewer evaluations
than full dense. Judge robustness analysis (GPT-4o-mini vs. Llama3-70b) shows
strong agreement in agent rankings ($\rho = 0.872$) and consistent
identity-link advantage. TVD-MI's geometry is best preserved by identity
mapping for efficient LLM evaluation, applicable to other bounded-response
domains.

</details>


### [429] [Biology-informed neural networks learn nonlinear representations from omics data to improve genomic prediction and interpretability](https://arxiv.org/abs/2510.14970)
*Katiana Kontolati,Rini Jasmine Gladstone,Ian Davis,Ethan Pickering*

Main category: cs.LG

TL;DR: 该研究将生物知情神经网络（BINNs）应用于作物基因组预测（GP）和选择（GS），通过整合SNP、多组学数据和先验生物知识，提高了预测精度并揭示了复杂的基因-表型关系。


<details>
  <summary>Details</summary>
Motivation: 传统基因型-表型（G2P）模型准确性有限，需要昂贵的田间试验。能够结合中间分子表型的模型在GS时因数据不可用而受限。BINNs旨在克服这些限制，在训练时利用多组学数据和生物知识，在推理时仅使用基因型数据，以提高GP和GS的准确性。

Method: 研究将生物知情神经网络（BINNs）进行扩展，整合了数千个SNP、多组学测量和先验生物知识。在训练过程中利用多组学数据和通路信息，在推理（GS）时仅使用基因型数据。

Result: 在玉米基因表达和多环境田间试验数据上，BINNs在亚群内部和跨亚群的秩相关准确性提高了高达56%，并且能够发现GWAS/TWAS无法揭示的基因。对于合成代谢组学基准测试，BINNs将预测误差降低了75%，并正确识别了最重要的非线性通路。此外，BINNs的潜在变量与它们代表的实验量高度相关，表明其学习到了生物学相关的表示。

Conclusion: BINNs提供了一个利用中间领域信息框架，以提高基因组预测精度，并揭示可用于指导基因组选择、候选基因选择、通路富集和基因编辑优先级的非线性生物学关系。

Abstract: We extend biologically-informed neural networks (BINNs) for genomic
prediction (GP) and selection (GS) in crops by integrating thousands of
single-nucleotide polymorphisms (SNPs) with multi-omics measurements and prior
biological knowledge. Traditional genotype-to-phenotype (G2P) models depend
heavily on direct mappings that achieve only modest accuracy, forcing breeders
to conduct large, costly field trials to maintain or marginally improve genetic
gain. Models that incorporate intermediate molecular phenotypes such as gene
expression can achieve higher predictive fit, but they remain impractical for
GS since such data are unavailable at deployment or design time. BINNs overcome
this limitation by encoding pathway-level inductive biases and leveraging
multi-omics data only during training, while using genotype data alone during
inference. Applied to maize gene-expression and multi-environment field-trial
data, BINN improves rank-correlation accuracy by up to 56% within and across
subpopulations under sparse-data conditions and nonlinearly identifies genes
that GWAS/TWAS fail to uncover. With complete domain knowledge for a synthetic
metabolomics benchmark, BINN reduces prediction error by 75% relative to
conventional neural nets and correctly identifies the most important nonlinear
pathway. Importantly, both cases show highly sensitive BINN latent variables
correlate with the experimental quantities they represent, despite not being
trained on them. This suggests BINNs learn biologically-relevant
representations, nonlinear or linear, from genotype to phenotype. Together,
BINNs establish a framework that leverages intermediate domain information to
improve genomic prediction accuracy and reveal nonlinear biological
relationships that can guide genomic selection, candidate gene selection,
pathway enrichment, and gene-editing prioritization.

</details>


### [430] [pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation](https://arxiv.org/abs/2510.14974)
*Hansheng Chen,Kai Zhang,Hao Tan,Leonidas Guibas,Gordon Wetzstein,Sai Bi*

Main category: cs.LG

TL;DR: $\\pi$-Flow 是一种基于策略的流模型，通过模仿教师模型的行为，实现了快速、高质量和高多样性的图像生成，解决了现有蒸馏方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散或流的模型在知识蒸馏过程中存在格式不匹配问题，导致训练复杂且常出现质量-多样性权衡。此外，学生模型在进行ODE积分时需要额外的网络评估，增加了计算成本。

Method: $\\pi$-Flow 提出修改学生流模型的输出层，使其预测一个无网络策略，该策略能在后续子步骤中动态生成流速度。通过引入一种新的模仿蒸馏方法，将策略的速度与教师的速度进行匹配，并使用标准的 $\\ell_2$ 流匹配损失。这种方法使得学生模型能够模仿教师的行为，进行快速准确的ODE积分，而无需额外的网络评估。

Result: 在 ImageNet 256$^2$ 数据集上，$\\pi$-Flow 实现了 2.85 的 1-NFE FID 分数，优于相同 DiT 架构的 MeanFlow。在 FLUX.1-12B 和 Qwen-Image-20B 数据集上，$\\pi$-Flow 在 4 NFEs 下实现了比最先进的少步数方法更好的多样性，同时保持了教师级别的质量。

Conclusion: $\\pi$-Flow 通过其独特的策略预测和模仿蒸馏方法，成功解决了现有少步蒸馏方法的挑战，在保证生成质量的同时显著提高了多样性，并实现了高效的训练。

Abstract: Few-step diffusion or flow-based generative models typically distill a
velocity-predicting teacher into a student that predicts a shortcut towards
denoised data. This format mismatch has led to complex distillation procedures
that often suffer from a quality-diversity trade-off. To address this, we
propose policy-based flow models ($\pi$-Flow). $\pi$-Flow modifies the output
layer of a student flow model to predict a network-free policy at one timestep.
The policy then produces dynamic flow velocities at future substeps with
negligible overhead, enabling fast and accurate ODE integration on these
substeps without extra network evaluations. To match the policy's ODE
trajectory to the teacher's, we introduce a novel imitation distillation
approach, which matches the policy's velocity to the teacher's along the
policy's trajectory using a standard $\ell_2$ flow matching loss. By simply
mimicking the teacher's behavior, $\pi$-Flow enables stable and scalable
training and avoids the quality-diversity trade-off. On ImageNet 256$^2$, it
attains a 1-NFE FID of 2.85, outperforming MeanFlow of the same DiT
architecture. On FLUX.1-12B and Qwen-Image-20B at 4 NFEs, $\pi$-Flow achieves
substantially better diversity than state-of-the-art few-step methods, while
maintaining teacher-level quality.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [431] [Spontaneous Breaking of the SU(3) Flavor Symmetry in a Quantum Hall Valley Nematic](https://arxiv.org/abs/2510.13874)
*G. Krizman,A. Kazakov,C. -W. Cho,V. V. Volobuev,A. Majou,E. Ben Achour,T. Wojtowicz,G. Bauer,Y. Guldner,B. A. Piot,Th. Jolicoeur,G. Springholz,L. -A. de Vaulchier*

Main category: cond-mat.mes-hall

TL;DR: Pb1-xSnxSe量子阱中发现了具有SU(3)序参量的量子霍尔谷尼马相，并观察到自发和显式对称性破缺。这种对称性破缺与夸克味范式相似，对理解SU(3)体系中的多体物理具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究二维量子材料中的电子关联、对称性和拓扑学相互作用所产生的电子相，特别是能够同时作用于赝自旋和空间自由度的内对称性自发破缺所实现的尼马序。

Method: 通过Pb1-xSnxSe量子阱，研究在塞曼场存在下，赝自旋与空间自由度之间的相互作用，观察三重简并谷赝自旋之间的自发极化，以揭示量子霍尔谷尼马相及其SU(3)序参量空间。

Result: 在Pb1-xSnxSe量子阱中发现了量子霍尔谷尼马相，并证明了其具有底层的SU(3)序参量空间，该相由三度简并的谷赝自旋之间的自发极化产生。此外，在塞曼场作用下，能够通过显式对称性破缺进一步调控尼马序。

Conclusion: 在Pb1-xSnxSe量子阱中观察到的具有SU(3)序参量的量子霍尔谷尼马相，以及自发和显式对称性破缺现象，为理解SU(3)多体物理系统提供了新的视角，并与夸克味范式存在相似性。

Abstract: Two-dimensional quantum materials can host original electronic phases that
arise from the interplay of electronic correlations, symmetry and topology. In
particular, the spontaneous breaking of internal symmetry that acts
simultaneously on the pseudospin and the spatial degree of freedom realizes a
nematic ordering. We report evidence of a quantum Hall valley nematic phase
with an underlying SU(3) order parameter space obtained by a spontaneous
polarization between the threefold degenerate valley pseudospins in Pb1-xSnxSe
quantum wells. In the presence of a Zeeman field, we demonstrate a further
control of the nematic ordering with an explicit symmetry breaking. Evidence of
both spontaneous and explicit SU(3) symmetry breaking, reminiscent of the quark
flavor paradigm, is of fundamental interest to shape the many body physics in a
SU(3) system.

</details>


### [432] [Unconventional criticality in $O(D)$-invariant loop-constrained Landau theory](https://arxiv.org/abs/2510.13960)
*Svitlana Kondovych,Asle Sudbø,Flavio S. Nogueira*

Main category: cond-mat.mes-hall

TL;DR: 铁电体朗道理论中的极化序参量受散度自由约束，只允许类似回路的极化构型贡献于配分函数。这导致了与常规朗道-金茨堡-威尔逊范式不同的临界行为，即使在三维情况下，其标度维数也显著大于 O(3) 普适类。


<details>
  <summary>Details</summary>
Motivation: 研究铁电体中受散度自由约束的极化序参量的临界行为。

Method: 采用朗道型理论，并结合重整化群分析。

Result: 发现临界行为超越了常规的朗道-金茨堡-威尔逊范式。在三维情况下，标度维数 η 约为 0.239，远超 O(3) 普适类（η ≈ 0.034）。

Conclusion: 散度自由约束导致了紧急规范对称性，从而产生了显著的标度维数。

Abstract: We study the critical behavior of a Landau-type theory for ferroelectrics in
which the polarization order parameter $\vec{P}$ is subject to a
divergence-free constraint, such that only loop-like polarization
configurations contribute to the partition function. This constraint forces the
number of components of the field $\vec{P}$ to equal the spatial dimensionality
$D$, allowing a natural extension of the present theory to $O(N)$ models with
$N=D$. Renormalization group analysis reveals critical behavior beyond the
conventional Landau-Ginzburg-Wilson paradigm. In particular, the order
parameter acquires a remarkably large anomalous dimension, with $\eta\approx
0.239$ in three dimensions -- significantly exceeding the value $\eta\approx
0.034$ typical of the $O(3)$ universality class. This is due to an emergent
gauge symmetry originating with the local constraint.

</details>


### [433] [Comparative study of phonon-limited carrier transport in the Weyl semimetal TaAs family](https://arxiv.org/abs/2510.14048)
*Shashi B. Mishra,Zhe Liu,Sabyasachi Tiwari,Feliciano Giustino,Elena R. Margine*

Main category: cond-mat.mes-hall

TL;DR: TaAs家族的Weyl半金属中的声子对其电输运性质有主要影响，其中NbP电导率最高，TaAs最低，且掺杂对NbP影响不大，对TaAs影响显著。


<details>
  <summary>Details</summary>
Motivation: 研究TaAs家族Weyl半金属的声子限制的电输运性质，理解声子、掺杂和载流子动力学对其电子响应的影响。

Method: 使用第一性原理计算和从头算Boltzmann输运方程系统研究了TaAs家族的声子限制的电输运。

Result: 计算得到的电导率与实验数据吻合良好，证实声子散射是主要限制因素。NbP电导率最高，因载流子速度大，TaAs电导率最低，因载流子口袋和速度有限。NbP的电导率受掺杂影响小，TaAs则表现出显著的电子-空穴不对称性。

Conclusion: 声子在TaAs家族的电输运中起关键作用。载流子动力学和掺杂对其电子响应有重要影响，对不同化合物表现出不同的行为。

Abstract: We present a systematic first-principles study of phonon-limited transport in
the TaAs family of Weyl semimetals using the ab initio Boltzmann transport
equation. The calculated electrical conductivities show excellent agreement
with experimental data for high-quality samples, confirming that transport in
these systems is predominantly limited by phonon scattering. Among the four
compounds, NbP achieves the highest conductivity, governed primarily by its
large Fermi velocities that offset its stronger scattering rates. In contrast,
TaAs displays the lowest conductivity, linked to reduced carrier pockets and
limited carrier velocities. Additionally, NbP conductivity remains largely
unaffected by small hole or electron doping, whereas TaAs exhibits pronounced
electron-hole asymmetry. NbAs and TaP show intermediate behavior, reflecting
their Fermi surface topologies and scattering phase space. These findings
provide microscopic insight into the transport mechanisms of the TaAs family
and emphasize the critical role of phonons, doping, and carrier dynamics in
shaping their electronic response.

</details>


### [434] [Towards a unified mechanistic understanding of the electrical response of bipolar nanofluidic systems](https://arxiv.org/abs/2510.14080)
*Ayelet Ben-Kish Sharvit,Yoav Green*

Main category: cond-mat.mes-hall

TL;DR: Bipolar纳米膜和纳米通道在水脱盐和能源收集方面有重要应用，但其性能优化受限于对其物理机制理解不足。本研究提出了一个统一框架，结合理论分析和数值模拟，以改善纳米流体器件的设计。


<details>
  <summary>Details</summary>
Motivation: 提高水脱盐和能源收集系统中双极纳米膜和纳米通道的性能，解决当前经验优化缓慢且效率低的问题。

Method: 结合理论分析和数值模拟，开发一个统一框架，研究施加电压和依赖于几何形状及表面电荷密度比的参数η之间的相互作用，并与三个理论模型进行比较。

Result: 开发了一个统一框架，证明了系统响应受电压和参数η的相互作用控制。在低电压下，响应主要由η决定，可用简化相空间表示；在高电压下，此相空间过于简化。模拟结果与理论模型进行了比较并解释了偏差。

Conclusion: 该研究提出的框架有助于减少优化纳米流体器件所需的时间和资源，并能改进对实验和模拟结果的解释。

Abstract: Bipolar nanoporous membranes and bipolar nanochannels are used in water
desalination and energy-harvesting systems that provide clean water and green
energy, respectively. The growing need for both requires continuous improvement
of their performance. However, the underlying physics of these complex systems
is still not fully understood, making empirical optimization slow and
inefficient. In this work, we combine theoretical analysis and numerical
simulations to develop a unified framework for improving the design of
nanofluidic devices. We show that the system response is governed by the
interplay between the applied voltage and a parameter $\eta$, which depends on
the ratio of geometry and surface charge densities of both charged regions. At
low voltages, the response is mostly determined by $\eta$, allowing its
dependence to be represented by a simplified phase space. At high voltages,
this phase space becomes oversimplified. To demonstrate the framework's
robustness, we scan a range of configurations, from unipolar channels (single
charged region) to bipolar channels (positive and negative segments). We
compare the numerically simulated current-voltage responses with three
theoretical models, which are limiting scenarios within the phase space, and
explain the observed deviations. These findings can help reduce the time and
resources required to optimize nanofluidic devices and improve the
interpretation of experiments and simulations.

</details>


### [435] [Mapping Temperature Using Transmission Kikuchi Diffraction](https://arxiv.org/abs/2510.14175)
*Yueyun Chen,Xin Yi Ling,Jared Lodico,Tristan P. O`Neill,B. C. Regan,Matthew Mecklenburg*

Main category: cond-mat.mes-hall

TL;DR: KDTh是一种利用扫描电子显微镜（SEM）进行非接触式纳米尺度温度和压力测量的技术。


<details>
  <summary>Details</summary>
Motivation: 电子器件的尺寸不断缩小，需要新的测量纳米尺度热力学的方法。在纳米尺度上测量温度和压力是具有挑战性的，因为物理接触会扰动系统。

Method: KDTh通过精确拟合菊池图样来检测晶体样品中局部的体积晶格变化，并利用热膨胀系数（CTE）推导温度变化。该技术在扫描电子显微镜（SEM）中进行，使用5.5纳米的电子探针扫描样品，可以在透射（菊池衍射，TKD）和反射（电子背散射衍射，EBSD）模式下操作。

Result: KDTh能够绘制出焦耳加热石墨的晶格参数和温度。参数精度约为0.01%，温度灵敏度为2.2 K/sqrt(Hz)。

Conclusion: KDTh提供了一种先进的纳米尺度温度和压力测量方法，具有高精度和高灵敏度，并且可以在透射和反射模式下操作。

Abstract: Electronic devices are engineered at increasingly smaller length scales; new
metrologies to understand nanoscale thermodynamics are needed. Temperature and
pressure are fundamental thermodynamic quantities whose nanoscale measurement
is challenging as physical contact inevitably perturbs the system. Here we
demonstrate Kikuchi diffraction thermometry (KDTh), a non-contact scanning
electron microscope (SEM) technique capable of mapping nanoscale temperatures
and pressures. KDTh detects local volumetric lattice changes in crystalline
samples by precisely fitting Kikuchi patterns. Temperature changes are deduced
using the coefficient of thermal expansion (CTE). We map lattice parameters and
temperatures on Joule-heated graphite by rastering a 5.5-nm electron probe
across the sample. Our parameter precision is ~0.01% and our temperature
sensitivity is 2.2 K/$\sqrt{Hz}$. KDTh offers advanced sensitivity by fitting
the entire Kikuchi pattern, even beyond the precision measured in transmission
electron microscopy. KDTh can operate in both transmission (transmission
Kikuchi diffraction, TKD) and reflection (electron backscatter diffraction,
EBSD) modes.

</details>


### [436] [Phenomenological Ehrenfest Dynamics with Topological and Geometric Phase Effects and the curious case of Elliptical intersection](https://arxiv.org/abs/2510.14181)
*Dhruv Sharma*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种考虑了几何相位效应的非绝热分子动力学模拟的计算框架，该框架基于广义两能级哈密顿模型，并通过预循环轨迹初始化方案引入了内存效应，实现了对不同类型能级交叉点的统一处理，并考虑了Berry曲率修正和离心率参数，数值模拟结果与理论预测一致，该框架为研究几何相位效应在分子体系中的量子-经典相互作用提供了有价值的工具，并为设计简并材料、新型光谱和量子比特应用开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了在模拟非绝热分子动力学时包含几何相位效应，并统一处理不同类型的能级交叉点（如圆锥交叉、避免交叉和椭圆交叉）。

Method: 提出了一种基于广义两能级哈密顿模型的计算框架，并引入了预循环轨迹初始化方案来编码几何相位。通过Berry曲率修正Ehrenfest动力学来处理拓扑效应，并加入了离心率参数来模拟更真实的分子系统。

Result: 数值模拟结果表明，该方法能够与理论预测在状态混合和因几何相位效应导致的混合抑制方面保持一致。

Conclusion: 该计算框架能够准确模拟包含几何相位效应的非绝热分子动力学，为研究相关量子-经典相互作用、设计简并材料、开发新型光谱和量子比特应用提供了新的途径。

Abstract: We present a comprehensive computational framework for simulating
nonadiabatic molecular dynamics with explicit inclusion of geometric phase (GP)
effects. Our approach is based on a generalized two-level Hamiltonian model
that can represent various electronic state crossings - conical intersections,
avoided crossings, and elliptic intersections - through appropriate
parameterization. We introduce a novel prelooping trajectory initialization
scheme, allowing us to encode the memory as an initial phase accumulated due to
the adiabatic evolution over the potential energy surface. This is a unified
framework to handle different types of level crossings by incorporating Berry
curvature-based force corrections to Ehrenfest dynamics, ensuring accurate
representation of topological effects. For conical intersections, our method
incorporates the theoretically expected phase pi, while for elliptic
intersections, it yields a parametrically tunable but loop radius (energy)
independent phase different from pi. We also include an eccentricity parameter
(e) in the diabatic coupling to model more realistic molecular systems.
Numerical simulations demonstrate the consistency of our approach with
theoretical predictions for mixing of states and inhibition from mixing due to
geometric phase effects. This framework provides a valuable tool for studying
quantum-classical interactions in molecular systems where geometric phase
effects play a significant role. The elliptical intersection and geometric
phase effect opens avenue for the design and discovery of degenerate materials.
It produces a fresh look to help develop a new kind of spectroscopy and
potential qubit applications. This simple Hamiltonian reveals a pathological
phase protection effect E = kr, where k is real, that has great utility in a
new spectroscopy design.

</details>


### [437] [Magnetic Flux-induced Higher-order Topological Superconductors](https://arxiv.org/abs/2510.14216)
*Jinpeng Xiao,Qianglin Hu,Zuodong Yu,Weipeng Chen,Xiaobing Luo*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一个无需自旋-轨道耦合即可实现高阶拓扑超导性的模型，利用了塞曼场、反铁磁序和s波超导配对。


<details>
  <summary>Details</summary>
Motivation: 现有高阶拓扑超导性研究通常依赖于自旋-轨道耦合、精心设计的样品结构、节点超导配对或复杂的磁序，本文旨在提出一种不依赖这些条件的替代模型。

Method: 在二维系统中，利用交错磁通量，并在磁有序矩垂直于塞曼场的情况下，实现了二阶拓扑超导体。在三维系统中，通过堆叠二维二阶拓扑超导体，理论上实现了二阶和三阶拓扑超导体。

Result: 成功在二维系统中利用交错磁通量、塞曼场和反铁磁序实现了二阶拓扑超导体；理论上在三维系统中通过堆叠二维结构实现了二阶和三阶拓扑超导体。

Conclusion: 本文提出的模型为实现高阶拓扑超导性提供了一种新的途径，并且在理论上展现了在三维系统中实现更高阶拓扑超导性的可能性。

Abstract: Higher-order topological superconductivity typically depends on spin-orbit
interaction, and often necessitates well designed sample structures, nodal
superconducting pairings or complex magnetic order. In this work, we propose a
model that incorporates a Zeeman field, antiferromagnetic order, and $s$-wave
superconducting pairing, all without the need for spin-orbit interaction. In a
two-dimensional system, we realize a second-order topological superconductor by
utilizing a staggered flux, provided that the Zeeman field is oriented
perpendicular to the magnetic order moments. In three-dimensional systems, we
achieve second- and third-order topological superconductors in theory, through
stacking the two-dimensional second-order topological superconductor.

</details>


### [438] [Cryogenic temperature dependence and hysteresis of surface-trap-induced gate leakage in GaN high-electron-mobility transistors](https://arxiv.org/abs/2510.14456)
*Ching-Yang Pan,Shi-Kai Lin,Yu-An Chen,Pei-hsun Jiang*

Main category: cond-mat.mes-hall

TL;DR: 研究了GaN HEMT中表面陷阱引起栅漏电的各种机制，并提供了在室温到低温范围内的详细映射。


<details>
  <summary>Details</summary>
Motivation: 在室温到低温范围内，详细研究GaN HEMT中表面陷阱引起的栅漏电的各种机制。

Method: 在室温到低温范围内，通过测量栅漏电电流，分析了二维变量跳跃、Poole-Frenkel发射和陷阱辅助隧穿等机制。通过栅压扫描提取陷阱势垒高度，并分析了不同温度下栅漏电电流与栅压关系的滞回现象。

Result: 在小栅压下观察到二维变量跳跃。在较高反向栅压下，漏电在220K以上主要由Poole-Frenkel发射控制，但在220K以下由于冻结陷阱效应逐渐转变为陷阱辅助隧穿。向上栅压扫描提取的栅漏电电流的陷阱势垒高度为0.65V，比向下扫描高12%。栅漏电电流随栅压的变化在220K以上表现为顺时针滞回环，而在220K以下则表现为逆时针滞回环。

Conclusion: 研究结果详细阐述了GaN HEMT中表面陷阱引起的栅漏电机制，并解释了在不同温度下观察到的相反滞回现象。

Abstract: This work provides a detailed mapping of various mechanisms of
surface-trap-induced gate leakage in GaN HEMTs across a temperature range from
room to cryogenic levels. Two-dimensional variable-range hopping is observed at
small gate bias. Under higher reverse gate bias, the leakage is dominated by
the Poole--Frenkel emission above 220 K, but gradually transitions to the
trap-assisted tunneling below 220 K owing to the frozen-trap effect. The trap
barrier height extracted from the gate leakage current under the upward gate
sweep is 0.65 V, which is 12\% higher than that from the downward sweep. The
gate leakage current as a function of the gate bias exhibits clockwise
hysteresis loops above 220 K but counterclockwise ones below 220 K. This
remarkable opposite hysteresis phenomenon is thoroughly explained by the trap
mechanisms.

</details>


### [439] [Electric field-induced spin-valley locking in twisted bilayer buckled honeycomb materials](https://arxiv.org/abs/2510.14404)
*Harold J. W. Zandvliet,Pantelis Bampoulis,Cristiane Morais Smith,Lumen Eek*

Main category: cond-mat.mes-hall

TL;DR: 扭转双层蜂窝状材料（如石墨烯、硅烯和锗烯）在施加垂直电场时表现出量子谷霍尔效应，但硅烯和锗烯中的自旋-谷锁定效应提供了更强的拓扑保护。


<details>
  <summary>Details</summary>
Motivation: 研究扭转双层材料（特别是石墨烯、硅烯和锗烯）在电场作用下产生的量子谷霍尔效应，并重点关注硅烯和锗烯中存在的自旋-谷锁定现象及其对拓扑保护的影响。

Method: 通过理论分析扭转双层材料（石墨烯、硅烯、锗烯）的能带结构，研究其在电场作用下量子谷霍尔效应的形成机制，并探讨自旋-谷锁定现象的出现范围和对拓扑保护强度的影响。

Result: 扭转双层石墨烯在电场下会形成二维三角形的谷保护螺旋畴边界态。在扭转双层硅烯和锗烯中，由于自旋-轨道耦合和结构起伏，量子谷霍尔效应更为复杂，存在一个特定的电场范围，此时电子的自旋自由度与谷自由度锁定，实现了更强的拓扑保护。超出该范围，则仅有谷保护。

Conclusion: 扭转双层硅烯和锗烯在特定电场下实现的自旋-谷锁定量子谷霍尔态，比仅有谷保护的态具有更强的拓扑保护性。

Abstract: A twisted honeycomb bilayer exhibits a moir\'e superstructure that is
composed of a hexagonal arrangement of AB and BA stacked domains separated by
domain boundaries. In the case of twisted bilayer graphene, the application of
an electric field normal to the bilayer leads to the opening of inverted band
gaps in the AB and BA stacked domains. The inverted band gaps result in the
formation of a two-dimensional triangular network of counterpropagating valley
protected helical domain boundary states, also referred to as the quantum
valley Hall effect. Owing to spin-orbit coupling and buckling, the quantum
valley Hall effect in twisted bilayer silicene and germanene is more complex
than in twisted bilayer graphene. We found that there is a range of electric
fields for which the spin degree of freedom is locked to the valley degree of
freedom of the electrons in the quantum valley Hall states, resulting in a
stronger topological protection. For electric fields smaller than the
aforementioned range the twisted bilayer does not exhibit the quantum valley
Hall effect, whereas for larger electric fields the spin-valley locking is
lifted and the emergent quantum valley Hall states are only valley-protected.

</details>


### [440] [Linearly polarized light enables chiral edge transport in quasi-2D Dirac materials](https://arxiv.org/abs/2510.14447)
*Mohammad Shafiei,Farhad Fazileh,Milorad V. Milošević*

Main category: cond-mat.mes-hall

TL;DR: 准二维狄拉克材料在强光作用下，可以通过线偏振光诱导拓扑相变，产生手征边缘通道。


<details>
  <summary>Details</summary>
Motivation: 探索高频光在量子材料中动态调控拓扑相变的潜力，特别是线偏振光（LPL）在三维狄拉克系统中通常被认为无效，但在准二维狄拉克材料中可能有效。

Method: 研究准二维狄拉克材料中由表面耦合产生的二阶动量项如何在外加线偏振光作用下诱导拓扑相变，并以超薄Bi2Se3薄膜为例进行分析。

Result: 在线偏振光作用下，准二维狄拉克材料（如超薄Bi2Se3薄膜）可以发生拓扑相变，产生手征边缘通道。该相变在实验上是可行的，并且所需的激光强度是可达到的。

Conclusion: 准二维材料是实现光控拓扑相变的有力平台，扩展了Floquet拓扑工程的应用范围。

Abstract: Floquet engineering with high-frequency light offers dynamic control over
topological phases in quantum materials. While in 3D Dirac systems circularly
polarized light is known to induce topological phase transitions via gap
opening, linearly polarized light (LPL) has generally been considered
ineffective. Here we show that in quasi-2D Dirac materials the second-order
momentum term arising from the intersurface coupling can induce a topological
phase transition under LPL, leading to chiral edge channels. Considering an
ultrathin Bi$_2$Se$_3$ film as a representative system, we show that this
transition occurs at experimentally accessible light intensities. Our results
thus promote quasi-2D materials as viable platforms for light-controlled
topological phases, expanding the potential of Floquet topological engineering.

</details>


### [441] [The fate of disorder in twisted bilayer graphene near the magic angle](https://arxiv.org/abs/2510.14567)
*Zhe Hou,Hailong Li,Qing Yan,Yu-Hang Li,Hua Jiang*

Main category: cond-mat.mes-hall

TL;DR: 在扭曲双层石墨烯（TBG）的平带系统中，中度无序增强电导，而强无序则恢复局域化，这表明存在一种由无序驱动的从非局域化到局域化的输运行为。该机制通过光谱流分析得到解释，并与非平带系统进行了对比。


<details>
  <summary>Details</summary>
Motivation: 在平带系统中，无序对电子行为的影响尚不清楚，尽管平带本身会导致电子的内禀局域化。

Method: 使用原子尺寸的紧束缚量子输运计算方法，研究扭曲双层石墨烯（TBG）设备中无序与平带的相互作用。

Result: 发现中度无序增强了电导，而强无序则恢复了局域化，展现了由无序驱动的非局域化到局域化的输运行为。通过光谱流分析揭示了无序TBG圆柱体的有效带内隧穿强度。对比了魔角和非魔角TBG，发现它们对无序的响应存在显著差异。

Conclusion: 无序在平带魔角材料中扮演着非传统的角色，为理解无序魔角系统中分数反常霍尔效应的观测提供了新的见解。

Abstract: In disordered lattices, itinerant electrons typically undergo Anderson
localization due to random phase interference, which suppresses their motion.
By contrast, in flat-band systems where electrons are intrinsically localized
owing to their vanishing group velocity, the role of disorder remains elusive.
Twisted bilayer graphene (TBG) at the magic angle $\sim 1.1^\circ$ provides a
representative flat-band platform to investigate this problem. Here, we perform
an atomistic tight-binding quantum transport calculation on the interplay
between disorder and flat-bands in TBG devices. This non-phenomenological
approach provides direct evidence that moderate disorder enhances conductance,
whereas stronger disorder restores localization, revealing a disorder-driven
delocalization-to-localization transport behavior. The underlying physical
mechanism is understood by an effective inter-moir{\'e} tunneling strength via
spectral flow analysis of a disordered TBG cylinder. Moreover, by comparing
magic-angle and large-angle TBG, we demonstrate qualitatively distinct disorder
responses tied to the presence of flat-bands. Our quantitative results
highlight the unconventional role of disorder in flat-band moir{\'e} materials
and offer insights into the observation of the fractional quantum anomalous
Hall effect in disordered moir{\'e} systems.

</details>


### [442] [Precision of an autonomous demon exploiting nonthermal resources and information](https://arxiv.org/abs/2510.14578)
*Juliette Monsel,Matteo Acciai,Didrik Palmqvist,Nicolas Chiabrando,Rafael Sánchez,Janine Splettstoesser*

Main category: cond-mat.mes-hall

TL;DR: 该研究探索了一个多端点三点量子点系统，该系统可作为冰箱从冷电子触点提取热量。与标准热机不同，该系统利用非热资源，实现了在不平均消耗能量的情况下进行冷却，但需要资源波动。研究人员使用全计数统计和随机轨迹分析了该装置的制冷能力精度，并重点关注了两种高输出功率的运行模式：一种利用信息，另一种利用非热资源特性。结果表明，这两种模式在精度上存在显著差异，其中利用非热资源特性的模式可以将制冷能力波动抑制一个数量级。此外，通过分析输入和输出热流以及信息流之间的交叉相关性，进一步证实了这两种不同的工作原理。


<details>
  <summary>Details</summary>
Motivation: 研究一个利用非热资源的多端点三点量子点系统作为冰箱，探索其在不平均消耗能量的情况下进行冷却的可能性，并分析其性能和精度。

Method: 使用全计数统计和随机轨迹来分析多端点三点量子点冰箱的性能，重点关注两种高输出功率的运行模式：利用信息和利用非热资源特性，并通过分析输入输出热流和信息流的交叉相关性来验证工作原理。

Result: 在两种高输出功率的运行模式下，利用非热资源特性的模式相比利用信息模式具有更高的精度，其制冷能力波动可以比输入波动小一个数量级。

Conclusion: 该研究展示了利用非热资源特性的量子点冰箱可以实现高效且高精度的冷却，并为理解和设计新型量子热力学器件提供了新的视角。

Abstract: Quantum-dot systems serve as nanoscale heat engines exploiting thermal
fluctuations to perform a useful task. Here, we investigate a multi-terminal
triple-dot system, operating as a refrigerator that extracts heat from a cold
electronic contact. In contrast to standard heat engines, this system exploits
a nonthermal resource. This has the intriguing consequence that cooling can
occur without extracting energy from the resource on average -- a seemingly
demonic action -- while, however, requiring the resource to fluctuate. Using
full counting statistics and stochastic trajectories, we analyze the
performance of the device in terms of the cooling-power precision, employing
performance quantifiers motivated by the thermodynamic and kinetic uncertainty
relations. We focus on two regimes with large output power, which are based on
two operational principles: exploiting information on one hand and the
nonthermal properties of the resource on the other. We show that these regimes
significantly differ in precision. In particular, the regime exploiting the
nonthermal properties of the resource can have cooling-power fluctuations that
are suppressed with respect to the input fluctuations by an order of magnitude.
We also substantiate the interpretation of the two different working principles
by analyzing cross-correlations between input and output heat currents and
information flow.

</details>


### [443] [Magnetic D-brane solitons: skyrmion strings ending on a Néel wall in chiral magnets](https://arxiv.org/abs/2510.14689)
*Sven Bjarke Gudnason,Muneto Nitta*

Main category: cond-mat.mes-hall

TL;DR: 磁畴壁可以稳定末端于其上的斯格明子弦，从而形成类似于D-brane的结构。


<details>
  <summary>Details</summary>
Motivation: 探索三维磁斯格明子弦在磁畴壁上的行为及其作为D-brane类soliton的潜力。

Method: 研究斯格明子弦如何终止于N'eel型畴壁，并分析畴壁的稳定性和斯格明子弦的性质，以及多斯格明子弦相互作用产生的晶格结构。

Result: 发现斯格明子弦可以终止于N'eel型畴壁，稳定畴壁，形成磁性D-brane类soliton。 Bloch-type DMI导致畴壁线性弯曲，斯格明子弦保持有限宽度。 斯格明子弦之间的排斥相互作用可以形成周期性的多结解，如交替斯格明子弦和畴壁变形的方形晶格。

Conclusion: 磁性斯格明子弦是基本弦，可以终止于D-brane。

Abstract: Magnetic skyrmions extended to three dimensions form string-like objects
whose fundamental role remains largely unexplored. We show that skyrmion
strings can terminate on a N\'eel-type domain wall (DW), realizing a magnetic
analogue of a Dirichlet(D)-brane soliton. While an isolated N\'eel DW tends to
rotate into a Bloch DW, the N\'eel DW is stabilized when a skyrmion string ends
on it. Unlike field-theory D-branes, the Bloch-type DMI produces linear rather
than logarithmic DW bending, and the strings retain finite width far from the
DW, circumventing singular behavior. Furthermore, the repulsive interaction
between strings allows periodic multi-junction solutions, yielding a square
lattice of alternating strings and local DW deformations. These results
establish magnetic skyrmion strings as fundamental strings that can end on a
D-brane.

</details>


### [444] [Quantum beats of exciton-polarons in CsPbI3 perovskite nanocrystals](https://arxiv.org/abs/2510.14695)
*A. V. Trifonov,M. O. Nestoklon,M. -A. Hollberg,S. Grisard,D. Kudlacik,E. V. Kolobkova,M. S. Kuznetsova,S. V. Goupalov,J. M. Kaspari,D. E. Reiter,D. R. Yakovlev,M. Bayer,I. A. Akimov*

Main category: cond-mat.mes-hall

TL;DR: Exciton-phonon interactions in CsPbI3 nanocrystals exhibit long coherence times and allow for tuning optical transitions, paving the way for quantum technologies.


<details>
  <summary>Details</summary>
Motivation: The strong exciton-phonon interaction in lead-halide perovskite nanocrystals makes them a unique system for studying exciton-polaron dynamics and their optical response.

Method: Using transient two-pulse photon echo at 2 K, quantum beats between exciton-polaron states were observed in CsPbI3 nanocrystals embedded in a glass matrix. A four-level model was employed to quantify the exciton-phonon coupling strength.

Result: Exceptionally long coherence times (T2 ~300 ps) were observed, with Huang-Rhys factors of 0.05-0.1 and 0.02-0.04 for optical phonons with energies of 3.2 and 5.1 meV, respectively. A pronounced size dependence of coupling strengths and phonon lifetimes was also noted.

Conclusion: The study establishes a new regime of coherent exciton-polaron dynamics in CsPbI3 nanocrystals, demonstrating the potential to tune optical transitions and coherent dynamics for applications in solid-state quantum technologies.

Abstract: Exciton-phonon interactions govern the energy level spectrum and thus the
optical response in semiconductors. In this respect, lead-halide perovskite
nanocrystals represent a unique system, for which the interaction with optical
phonons is particularly strong, giving rise to a ladder of multiple exciton
states which can be optically excited with femtosecond pulses. We establish a
new regime of coherent exciton-polaron dynamics with exceptionally long
coherence times (T2 ~300 ps) in an ensemble of CsPbI3 nanocrystals embedded in
a glass matrix. Using transient two-pulse photon echo at 2 K temperature, we
observe quantum beats between the exciton-polaron states. Within a four-level
model, we directly quantify the exciton-phonon coupling strength through the
Huang-Rhys factors of 0.05-0.1 and 0.02-0.04 for low-energy optical phonons
with energies of 3.2 and 5.1 meV, respectively. The pronounced size dependence
of both coupling strengths and phonon lifetimes offers a path to tune the
optical transitions between polaron states and to tailor the coherent optical
dynamics in perovskite semiconductors for solid-state quantum technologies.

</details>


### [445] [Fundamental quantum and relativistic formulation of thermal noise and linear conductance in an 1D quasi-particle ensemble under ballistic transport-regime](https://arxiv.org/abs/2510.14721)
*Lino Reggiani,Federico Intini,Luca Varani*

Main category: cond-mat.mes-hall

TL;DR: 该论文研究了电磁场低频下噪声功率谱、电流-噪声谱和线性响应电导之间的涨落-耗散关系中的量子效应和量子相对论效应。在高频下，卡西米尔力避免了真空灾难。在低频下，通过普适准粒子方法，简要回顾了在纳米尺度长度的弹道输运条件下的一维结构的量子效应。最后，通过对精细结构常数$\(alpha$=1/137.0560的物理解释，在精确统计方法下，发现黑体腔中的光子气体能够物理解释原子线的谱线。


<details>
  <summary>Details</summary>
Motivation: 研究电磁场低频下的量子效应和量子相对论效应，特别是噪声功率谱、电流-噪声谱和线性响应电导之间的涨落-耗散关系。

Method: 利用普适准粒子方法研究一维结构的量子效应，并结合精确统计方法和精细结构常数的物理解释来分析黑体腔中的光子气体。

Result: 在高频下，卡西米尔力避免了真空灾难。在低频下，量子效应在弹道输运的一维结构中得到体现。光子气体的模型能够物理解释原子线的谱线。

Conclusion: 量子效应和量子相对论效应在电磁场低频下的噪声和输运现象中起着重要作用，并且可以通过普适准粒子方法和统计物理模型得到解释。

Abstract: We investigate quantum and quantum-relativistic effects associated with the
noise power spectrum and the fluctuation--dissipation relation between
current--noise spectra and linear--response conductance at low frequencies of
the electromagnetic field. At high frequencies, vacuum catastrophe is shown to
be avoided by the presence of Casimir force. At low frequencies, the quantum
effect associated with one--dimensional structures under the conditions of
ballistic transport typical at the nanometric scale length are briefly reviewed
in terms of a universal quasi-particle approach. The case of a photon gas
inside an appropriate black-body cavity is found to provide a physical
interpretation of the lines spectra of atomic elements within an exact
statistical approach based on a physical interpretation of the fine structure
constant, $\alpha =1/137.0560$.

</details>


### [446] [Disorder-assisted Spin-Filtering at Metal/Ferromagnet Interfaces: An Alternative Route to Anisotropic Magnetoresistance](https://arxiv.org/abs/2510.14867)
*Ivan Iorsh,Mikhail Titov*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种新的界面散射机制，可以在金属/铁磁体双层结构中产生显著的各向异性磁阻（AMR），且无需借助体自旋或轨道霍尔电流。


<details>
  <summary>Details</summary>
Motivation: 在金属/铁磁体双层结构（例如 Pt/YIG）中，在不涉及体自旋或轨道霍尔电流的情况下，产生显著的各向异性磁阻（AMR）。

Method: 利用一个包含界面交换和 Rashba 自旋-轨道耦合的 $\delta$-层模型，通过界面电荷转移产生一种自旋选择性相位条件（界面自旋过滤），从而抑制一个自旋投影的回散射，同时增强另一个自旋投影的动量弛豫。

Result: 该模型定量地再现了通常归因于自旋霍尔磁阻（SMR）的电阻各向异性的厚度依赖性和角度依赖性，以及其特征幅度。此外，AMR 峰值出现在几纳米的最佳金属厚度处。最大 AMR 与交换或自旋-轨道耦合强度中较小者呈线性关系，这与 SMR 不同。该散射理论模型符合玻尔兹曼边界条件，并预测了与 SMR 不同的其他判据，包括对界面电荷转移和无序的强敏感性。

Conclusion: 提出了一种新的界面散射机制，可以解释金属/铁磁体双层结构中的各向异性磁阻（AMR），该机制不同于传统的自旋霍尔磁阻（SMR），并对界面性质（如电荷转移和无序）敏感。

Abstract: We introduce a minimal interface-scattering mechanism that produces a sizable
anisotropic magnetoresistance (AMR) in metal/ferromagnet bilayers (e.g.,
Pt/YIG) without invoking bulk spin or orbital Hall currents. In a
$\delta$-layer model with interfacial exchange and Rashba spin-orbit coupling,
charge transfer at a high-quality interface creates a spin-selective phase
condition (interfacial spin filtering) that suppresses backscattering for one
spin projection while enhancing momentum relaxation for the other. The
resulting resistance anisotropy peaks at an optimal metal thickness of a few
nanometers, quantitatively reproducing the thickness and angular dependences
typically attributed to spin Hall magnetoresistance (SMR), as well as its
characteristic magnitude. Remarkably, the maximal AMR scales linearly with the
smaller of the two coupling strengths - exchange or spin-orbit, highlighting a
mechanism fundamentally distinct from SMR. Our scattering formulation maps onto
Boltzmann boundary conditions and predicts other clear discriminants from SMR,
including strong sensitivity to interfacial charge transfer and disorder.

</details>


### [447] [Electron transport in junctions between altermagnets](https://arxiv.org/abs/2510.14868)
*Shubham Ghadigaonkar,Sachchidanand Das,Abhiram Soori*

Main category: cond-mat.mes-hall

TL;DR: Altermagnetic (AM) heterostructures exhibit tunable electron transport properties that can be exploited for spintronic applications.


<details>
  <summary>Details</summary>
Motivation: Investigate electron transport in junctions between two altermagnetic (AM) materials in strong and weak altermagnetic phases.

Method: Analyze charge and spin conductivities as a function of the angle between the N'eel vectors of the two AMs. Introduce a normal metal between AMs to observe Fabry-P'erot-type oscillations. Examine spin-polarized transport in both strong and weak AM regimes.

Result: In the strong AM regime, charge conductivity vanishes as the angle between N'eel vectors approaches pi. In the weak AM phase, charge conductivity remains finite. Fabry-P'erot-type oscillations are observed with an intervening normal metal. Strong phase transport is dominated by up-spin electrons, while both spin channels contribute in the weak phase.

Conclusion: AM-based heterostructures offer potential for spintronic applications like spin filters and quantum interference devices due to their tunable spin-dependent transport and interference effects.

Abstract: We theoretically investigate electron transport in junctions between the two
AMs in strong and weak altermagnetic phases. The charge and spin conductivities
are analyzed as functions of angle between the N\'eel vectors of the two AMs
$\theta$. In the strong AM regime, the charge conductivity vanishes as $\theta
\to \pi$, while in the weak AM phase it remains finite. Introducing a normal
metal between two AMs leads to Fabry-P\'erot-type oscillations in charge
conductivity. In the strong phase, transport is dominated by up-spin electrons,
whereas both spin channels contribute in the weak phase. These results
highlight the potential of AM-based heterostructures for spintronic
applications, such as spin filters, and quantum interference-based spintronic
devices, where tunable spin-dependent transport and interference effects can be
utilized in electronic devices.

</details>


### [448] [Electric field controlled second-order anomalous Hall effect in altermagnets](https://arxiv.org/abs/2510.14899)
*Arnob Mukherjee,Biplab Sanyal,Annica M. Black-Schaffer,Ankita Bhattacharya*

Main category: cond-mat.mes-hall

TL;DR: 混合对称性下，混合型阿尔特磁体中的二阶霍尔效应


<details>
  <summary>Details</summary>
Motivation: 研究纯 d 波阿尔特磁体在 C4T 对称性下被禁止的线性和二阶异常霍尔效应，并提出利用量子度量和外加电场诱导 Berry 曲率偶极子来产生可调的二阶霍尔电流。

Method: 通过计算和理论分析，研究了混合对称性（插值于 dx2-y2 和 dxy 之间）的二维 Rashba 耦合混合阿尔特磁体中的电场诱导二阶异常霍尔响应，并探讨了其对称性对其非线性信号的影响。

Result: 在存在 C4T 对称性的情况下，利用非平凡的量子度量，可以通过电场诱导 Berry 曲率偶极子产生一个强且可调的二阶霍尔电流。该电流可以被开关，并且对掺杂水平下的阿尔特磁体序具有高敏感性。

Conclusion: 混合阿尔特磁体为可控的非线性输运和自旋电子学应用提供了一个有前途的平台。所提出的纯电气方法可以区分不同的阿尔特磁体序。

Abstract: Altermagnets are a recently discovered class of compensated magnets with
momentum-dependent spin splittings and unusual transport properties, even
without a net magnetization. In the presence of combined four-fold rotation and
time-reversal ($C_4\mathcal{T}$) symmetry, linear and also second-order, driven
by a Berry curvature dipole, anomalous Hall responses are forbidden in any pure
$d$-wave altermagnet. Nevertheless, here we find that the nontrivial quantum
metric of the occupied Bloch states allows for an electric field induced Berry
curvature dipole, which generates a strong and tunable second-order Hall
current, enabling it to be switched on or off by simply adjusting the relative
orientation between the symmetry-reducing dc field and the ac probe field.
Specifically, we investigate the electric field induced second-order anomalous
Hall response in a two-dimensional Rashba-coupled hybrid altermagnet that
interpolates between $d_{x^2-y^2}$ ($B_{1g}$) and $d_{xy}$ ($B_{2g}$)
altermagnet symmetry, motivated by recent proposals for mixed-symmetry states.
Crucially, the nonlinear signal is highly sensitive to the underlying symmetry
of the altermagnetic order at specific doping levels, offering a purely
electrical method to distinguish distinct altermagnetic orders. Our results
position hybrid altermagnets as a promising platform for controllable nonlinear
transport and spintronic applications.

</details>


### [449] [Skyrmion behavior in attractive-repulsive square array of pinning centers](https://arxiv.org/abs/2510.14903)
*L. Basseto,N. P. Vizarim,J. C. Bellizotti Souza,P. A. Venegas*

Main category: cond-mat.mes-hall

TL;DR: 混合钉扎效用于调控斯格明子动力学，为斯格明子器件设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 研究混合钉扎效应对斯格明子动力学行为的影响，并探索其在斯格明子器件设计中的应用潜力。

Method: 使用基于粒子的模型，研究了混合钉扎点阵中单个斯格明子的驱动动力学。

Result: 混合钉扎导致了方向锁定（在θsk=-45°时）和接近本征斯格明子霍尔角的锁定角度下的流动。研究表明，较弱的吸引会降低退钉阈值，而较强的排斥会稳定并拓宽-45°锁定平台。此外，吸引和排斥钉扎强度的组合可以控制方向锁定及其作用范围。钉扎尺寸的选择可以进一步在-45°、-50°、-55°和约-59°之间进行选择。

Conclusion: 混合钉扎是一种有效的调控斯格明子轨迹和有效霍尔响应的方法，为基于斯格明子的记忆和逻辑器件的设计提供了指导方针。

Abstract: We investigate the driven dynamics of a single skyrmion in a square lattice
of mixed pinning sites, where attractive and repulsive defects coexist using a
particle-based model. The mixed landscape yields directional locking at
$\theta_{\rm sk}=-45^\circ$ and flow at locked angles near the intrinsic
skyrmion Hall angle. By mapping defect strengths, we show that weaker
attraction lowers the depinning threshold, whereas stronger repulsion
stabilizes and broadens the $-45^\circ$ locking plateau. Moreover, combinations
of attractive and repulsive defect strengths allows control of directional
lockings and their force ranges. Defect size further tunes the response,
selecting among $-45^\circ$, $-50^\circ$, $-55^\circ$, and $\approx-59^\circ$.
These results establish mixed pinning as a practical knob to steer skyrmion
trajectories and the effective Hall response, providing design guidelines for
skyrmion-based memory and logic devices.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [450] [Universal Growth of Krylov Complexity Across A Quantum Phase Transition](https://arxiv.org/abs/2510.13947)
*András Grabarits,Adolfo del Campo*

Main category: quant-ph

TL;DR: 量子系统穿越量子相变时，Krylov空间的复杂性增长与Kibble-Zurek缺陷缩放精确关联，复杂性分布渐进高斯化。


<details>
  <summary>Details</summary>
Motivation: 研究受驱动的量子系统在穿越量子相变时，Krylov空间内传播复杂性的统计特性。

Method: 使用非绝热Magnus展开将演化映射到有效的一维跳跃模型。

Result: 对于横向场Ising模型，建立了复杂性增长与Kibble-Zurek缺陷缩放之间的精确联系，所有复杂性累积量均表现出与缺陷密度相同的幂律缩放，且系数与均值相同，完整分布渐近高斯化。

Conclusion: 得出跨任意二阶量子相变传播复杂性增长的通用缩放论证。

Abstract: We study the statistical properties of the spread complexity in the Krylov
space of quantum systems driven across a quantum phase transition. Using the
diabatic Magnus expansion, we map the evolution to an effective one-dimensional
hopping model. For the transverse field Ising model, we establish an exact link
between the growth of complexity and the Kibble-Zurek defect scaling: all
cumulants of complexity exhibit the same power-law scaling as the defect
density, with coefficients identical to the mean, and the full distribution
asymptotically becomes Gaussian. These results yield general scaling arguments
for the growth of complexity across arbitrary second-order quantum phase
transitions.

</details>


### [451] [Quantum State Designs via Magic Teleportation](https://arxiv.org/abs/2510.13950)
*Hugo Lóio,Guglielmo Lami,Lorenzo Leone,Max McGinley,Xhek Turkeshi,Jacopo De Nardis*

Main category: quant-ph

TL;DR: 非稳定子资源（例如，魔法态）在量子态设计的形成中起着关键作用。通过对包含魔法态的初始状态应用克利福德电路和泡利测量，可以实现量子态设计，其收敛速度与稳定子 Renyi 熵呈指数关系，并且存在一种称为 MIDA 的通用缩放形式。魔法态的传输，特别是“魔法态传送”机制，使得非克利福德资源能够超越光锥传播，从而在早期容错设备中生成高度随机的量子态。


<details>
  <summary>Details</summary>
Motivation: 研究非稳定子资源（特别是量子态的魔法）如何促进投影系综中量子态设计的出现。

Method: 从具有有限魔法的初始状态开始，应用无资源克利福德电路进行混合，然后对最终状态的子系统执行投影泡利测量。分析了生成的系综，并引入了“魔法诱导设计 Ansatz”（MIDA）。

Result: 证明了投影系综收敛于一个 k-设计，其误差随测量前状态的 k-阶稳定子 Renyi 熵呈指数衰减。识别出一种通用的缩放形式，该形式在不同类别的魔法初始状态中都成立。对于有限深度的克利福德酉变换，发现状态设计出现的时间尺度由魔法的传输控制，并识别出一种“魔法态传送”机制。

Conclusion: 少量且可控的魔法足以生成高度随机的量子态，为在早期容错设备中生成量子态设计提供了系统性的途径。

Abstract: We investigate how non-stabilizer resources enable the emergence of quantum
state designs within the projected ensemble. Starting from initial states with
finite magic and applying resource-free Clifford circuits to scramble them, we
analyze the ensemble generated by performing projective Pauli measurements on a
subsystem of the final state. Using both analytical arguments and large-scale
numerics, we show that the projected ensemble converges towards a state
$k$-design with an error that decays exponentially with the $k$-th Stabilizer
Renyi Entropy of the pre-measurement state, via a Magic-Induced Design Ansatz
(MIDA) that we introduce. We identify a universal scaling form, valid across
different classes of magic initial states, and corroborate it through numerical
simulations and analytical calculations of the frame potential. For
finite-depth Clifford unitaries, we show that the timescales at which state
designs emerge are controlled by the transport of magic. We identify a ``magic
teleportation'' mechanism whereby non-Clifford resources injected locally
spread through Clifford scrambling and measurements across distances beyond the
lightcone. Our results demonstrate how a small and controlled amount of magic
suffices to generate highly random states, providing a systematic route toward
generating quantum state designs in early fault-tolerant devices.

</details>


### [452] [Temporal Entanglement Transitions in the Periodically Driven Ising Chain](https://arxiv.org/abs/2510.13970)
*Karun Gadge,Abhinav Prem,Rishabh Jha*

Main category: quant-ph

TL;DR: 周期性驱动的量子系统（Floquet自旋链）中发现了与纠缠哈密顿量谱中的量子相变相对应的“时间纠缠相变”，该相变由动力学自发对称性破缺预示。


<details>
  <summary>Details</summary>
Motivation: 研究周期性驱动的量子系统中的非平衡现象，特别关注其纠缠动力学。

Method: 通过分析Floquet自旋链中的纠缠谱，研究了纠缠哈密顿量谱的量子相变，并观察了动力学自发对称性破缺、Schmidt-gap闭合、纠缠回声消失和对称性量子数翻转等现象。

Result: 在驱动频率范围（从绝热到高频）和驱动细节无关的情况下，发现了周期性的、急剧的纠缠谱重组。在高频下，纠缠哈密顿量获得一个与驱动周期无关的内在时间尺度。有限尺寸标度分析显示出普适的临界行为，关联长度指数为 $
u=1$，与静态临界性的平衡Ising普适性相匹配。

Conclusion: 时间纠缠相变是Floquet量子物质中的新特征，即使在纯粹由动力学机制驱动且与静态临界性无关的情况下，也能展现出与平衡态Ising模型相匹配的普适临界行为。

Abstract: Periodically driven quantum systems can host non-equilibrium phenomena
without static analogs, including in their entanglement dynamics. Here, we
discover $temporal$ $entanglement$ $transitions$ in a Floquet spin chain, which
correspond to a quantum phase transition in the spectrum of the entanglement
Hamiltonian and are signaled by dynamical spontaneous symmetry breaking. We
show that these transitions are entanglement-driven, i.e., they require
initially entangled states and remain invisible to conventional local
observables. Intriguingly, we find these transitions across a broad range of
driving frequencies (from adiabatic to high-frequency regime) and independently
of drive details, where they manifest as periodic, sharp entanglement spectrum
reorganizations marked by the Schmidt-gap closure, a vanishing entanglement
echo, and symmetry-quantum-number flips. At high frequencies, the entanglement
Hamiltonian acquires an intrinsic timescale decoupled from the drive period,
rendering the transitions genuine steady-state features. Finite-size scaling
reveals universal critical behavior with correlation-length exponent $\nu=1$,
matching equilibrium Ising universality despite its emergence from purely
dynamical mechanisms decoupled from static criticality. Our work establishes
temporal entanglement transitions as novel features in Floquet quantum matter.

</details>


### [453] [Towards gravimetry enhancement with squeezed states](https://arxiv.org/abs/2510.13973)
*Oziel R. de Araujo,Lucas S. Marinho,Jonas F. G. Santos,Carlos H. S. Vieira*

Main category: quant-ph

TL;DR: 量子探测状态中的压缩相位会影响重力加速度估计的精度。


<details>
  <summary>Details</summary>
Motivation: 研究压缩探针状态的压缩相位如何影响量子计量框架内的重力加速度估计精度。

Method: 分析了探针的压缩相位（而不仅仅是幅度）如何影响可达到的精度，并研究了投影动量测量和随时间变化的压缩相位调整。

Result:  along the canonical phase-space quadrature of the probes can fail to achieve a quantum Fisher information (QFI) surpassing the shot-noise limit, regardless of the interaction time with the gravitational field. In contrast, position-momentum correlated input states with the squeezing amplitude can overcome this limit. Optimal sensitivity is attained through projective momentum measurements combined with a time-dependent adjustment of the squeezing phase.

Conclusion: 这项工作强调了相位工程压缩在实验重力测量方案中的基本作用。

Abstract: We investigate the estimation sensitivity of gravitational acceleration using
squeezed probe states within a quantum metrology framework. In particular, we
analyze how the squeezing phase, beyond its amplitudes, of the probes affects
the attainable precision. We find that probes squeezed along the canonical
phase-space quadrature can fail to achieve a quantum Fisher information (QFI)
surpassing the shot-noise limit, regardless of the interaction time with the
gravitational field. In contrast, position-momentum correlated input states
with the squeezing amplitude can overcome this limit. Furthermore, we show that
optimal sensitivity is attained through projective momentum measurements
combined with a time-dependent adjustment of the squeezing phase. Our results
are important to highlight the fundamental role of phase-engineered squeezing
in experimental gravimetry protocols.

</details>


### [454] [Sequential Quantum Measurements and the Instrumental Group Algebra](https://arxiv.org/abs/2510.13980)
*Christopher S. Jackson*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Many of the most fundamental observables | position, momentum, phase-point,
and spin-direction | cannot be measured by an instrument that obeys the
orthogonal projection postulate. Continuous-in-time measurements provide the
missing theoretical framework to make sense of such observables. The elements
of the time-dependent instrument define a group called the \emph{instrumental
group} (IG). Relative to the IG, all of the time-dependence is contained in a
certain function called the \emph{Kraus-operator density} (KOD), which evolves
according to a classical Kolmogorov equation. Unlike the Lindblad master
equation, the KOD Kolmogorov equation is a direct expression of how the
elements of the instrument (not just the total channel) evolve. Shifting from
continuous measurement to sequential measurements more generally, the structure
of combining instruments in sequence is shown to correspond to the convolution
of their KODs. This convolution promotes the IG to an \emph{involutive Banach
algebra} (a structure that goes all the way back to the origins of POVM and
C*-algebra theory) which will be called the \emph{instrumental group algebra}
(IGA). The IGA is the true home of the KOD, similar to how the dual of a von
Neumann algebra is the home of the density operator. Operators on the IGA,
which play the same role for KODs as superoperators play for density operators,
are called \emph{ultraoperators} and various examples are discussed. Certain
ultraoperator-superoperator intertwining relations are considered, including
the relation between the KOD Kolmogorov equation and the Lindblad master
equation. The IGA is also shown to have actually two involutions: one respected
by the convolution ultraoperators and the other by the quantum channel
superoperators. Finally, the KOD Kolmogorov generators are derived for jump
processes and more general diffusive processes.

</details>


### [455] [A Rigorous Quantum Framework for Inequality-Constrained and Multi-Objective Binary Optimization](https://arxiv.org/abs/2510.13983)
*Sebastian Egginger,Kristina Kirova,Sonja Bruckner,Stefan Hillmich,Richard Kueng*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Encoding combinatorial optimization problems into physically meaningful
Hamiltonians with tractable energy landscapes forms the foundation of quantum
optimization. Numerous works have studied such efficient encodings for the
class of Quadratic Unconstrained Binary Optimization (QUBO) problems. However,
many real-world tasks are constrained, and handling equality and, in
particular, inequality constraints on quantum computers remains a major
challenge. In this letter, we show that including inequality constraints is
equivalent to solving a multi-objective optimization. This insight motivates
the Multi-Objective Quantum Approximation (MOQA) framework, which approximates
the maximum via smaller $p$-norms and comes with rigorous performance
guarantees. MOQA operates directly at the Hamiltonian level and is compatible
with, but not restricted to, ground-state solvers such as quantum adiabatic
annealing, the Quantum Approximate Optimization Algorithm (QAOA), or
imaginary-time evolution. Moreover, it is not limited to quadratic functions.

</details>


### [456] [A Rigorous Quantum Framework for Inequality-Constrained and Multi-Objective Binary Optimization: Quadratic Cost Functions and Empirical Evaluations](https://arxiv.org/abs/2510.13987)
*Sebastian Egginger,Kristina Kirova,Sonja Bruckner,Stefan Hillmich,Richard Kueng*

Main category: quant-ph

TL;DR: MOQA框架提出了一种新的方法，用于将多种QUBO问题的最大值映射到可处理的伊辛型哈密顿量的基态问题，从而为这些问题开辟了新的量子和量子启发式解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂的优化问题，需要将原始问题映射到可处理的量子能量模型（如伊辛型哈密顿量），以便利用量子优化技术（如量子退火和QAOA）来寻找基态。QUBO问题是其中一个研究较多的问题类别。

Method: 提出了一种名为MOQA（Multi-Objective Quantum Approximations）的框架，该框架能够将多种QUBO问题的最大值映射到可处理的伊辛型哈密顿量的基态问题。

Result: MOQA框架能够处理多种QUBO问题的最大值，并将其重构为可处理的伊辛型哈密顿量的基态问题。这使得可以应用量子或量子启发式方法来解决这些问题。

Conclusion: MOQA框架为解决实际应用中常见的多种二进制优化问题（包括路由、分区和带不等式约束的优化问题）提供了新的量子和量子启发式解决方案。

Abstract: The prospect of quantum solutions for complicated optimization problems is
contingent on mapping the original problem onto a tractable quantum energy
landscape, e.g. an Ising-type Hamiltonian. Subsequently, techniques like
adiabatic optimization, quantum annealing, and the Quantum Approximate
Optimization Algorithm (QAOA) can be used to find the ground state of this
Hamiltonian. Quadratic Unconstrained Binary Optimization (QUBO) is one
prominent problem class for which this entire pipeline is well understood and
has received considerable attention over the past years. In this work, we
provide novel, tractable mappings for the maxima of multiple QUBO problems.
Termed Multi-Objective Quantum Approximations, or MOQA for short, our framework
allows us to recast new types of classical binary optimization problems as
ground state problems of a tractable Ising-type Hamiltonian. This, in turn,
opens the possibility of new quantum- and quantum-inspired solutions to a
variety of problems that frequently occur in practical applications. In
particular, MOQA can handle various types of routing and partitioning problems,
as well as inequality-constrained binary optimization problems.

</details>


### [457] [Continuous-variable photonic quantum extreme learning machines for fast collider-data selection](https://arxiv.org/abs/2510.13994)
*Benedikt Maier,Michael Spannowsky,Simon Williams*

Main category: quant-ph

TL;DR: We introduce a photonic quantum extreme learning machine (QELM) for collider data processing, which outperforms traditional MLPs on classification tasks like top-jet tagging and Higgs-boson identification. The QELM offers fast, low-overhead, and compact random feature mapping with fixed latency, making it suitable for online data selection and trigger integration in future collider experiments.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop fast, low-overhead front-ends for collider data processing using continuous-variable photonic quantum extreme learning machines.

Method: Data is encoded in photonic modes via quadrature displacements and processed through a fixed-time Gaussian quantum substrate. Readout uses Gaussian-compatible measurements to generate a high-dimensional random feature map. Only a linear classifier is trained via a linear solve.

Result: The photonic QELM outperforms a parameter-matched MLP with two hidden units across all training sizes and matches or exceeds an MLP with ten hidden units at larger sample sizes for top-jet tagging and Higgs-boson identification tasks.

Conclusion: Gaussian photonic QELMs provide compact and expressive random features at fixed latency. Their deterministic timing, rapid retraining, low optical power, and room temperature operation make them a viable component for online data selection and trigger integration in future collider experiments.

Abstract: We study continuous-variable photonic quantum extreme learning machines as
fast, low-overhead front-ends for collider data processing. Data is encoded in
photonic modes through quadrature displacements and propagated through a
fixed-time Gaussian quantum substrate. The final readout occurs through
Gaussian-compatible measurements to produce a high-dimensional random feature
map. Only a linear classifier is trained, using a single linear solve, so
retraining is fast, and the optical path and detector response set the
analytical and inference latency. We evaluate this architecture on two
representative classification tasks, top-jet tagging and Higgs-boson
identification, with parameter-matched multi-layer perceptron (MLP) baselines.
Using standard public datasets and identical train, validation, and test
splits, the photonic Quantum Extreme Learning Machine (QELM) outperforms an MLP
with two hidden units for all considered training sizes, and matches or exceeds
an MLP with ten hidden units at large sample sizes, while training only the
linear readout. These results indicate that Gaussian photonic extreme-learning
machines can provide compact and expressive random features at fixed latency.
The combination of deterministic timing, rapid retraining, low optical power,
and room temperature operation makes photonic QELMs a credible building block
for online data selection and even first-stage trigger integration at future
collider experiments.

</details>


### [458] [Qutrits for physics at the LHC](https://arxiv.org/abs/2510.14001)
*Miranda Carou Laiño,Veronika Chobanova,Miriam Lucio Martínez*

Main category: quant-ph

TL;DR: Using qutrit quantum models for anomaly detection in high-energy physics data to potentially outperform qubit models for future collider experiments.


<details>
  <summary>Details</summary>
Motivation: The identification of anomalous events in particle physics is challenging and will intensify with next-generation colliders like the HL-LHC, requiring advancements in data processing, signal reconstruction, and analysis.

Method: Explores the use of qutrit-based Quantum Machine Learning models for anomaly detection in high-energy physics data, benchmarking against qubit-based approaches in terms of accuracy, scalability, and computational efficiency.

Result: The study aims to establish whether qutrit architectures offer an advantage over qubit architectures for the computational and analytical demands of future collider experiments.

Conclusion: The conclusion will be drawn after the performance of qutrit models is benchmarked against qubit models.

Abstract: The identification of anomalous events, not explained by the Standard Model
of particle physics, and the possible discovery of exotic physical phenomena
pose significant theoretical, experimental and computational challenges. The
task will intensify at next-generation colliders, such as the High- Luminosity
Large Hadron Collider (HL-LHC). Consequently, considerable challenges are
expected concerning data processing, signal reconstruction, and analysis. This
work explores the use of qutrit- based Quantum Machine Learning models for
anomaly detection in high-energy physics data, with a focus on LHC
applications. We propose the development of a qutrit quantum model and
benchmark its performance against qubit-based approaches, assessing accuracy,
scalability, and computational efficiency. This study aims to establish whether
qutrit architectures can offer an advantage in addressing the computational and
analytical demands of future collider experiments.

</details>


### [459] [Decoding Correlated Errors in Quantum LDPC Codes](https://arxiv.org/abs/2510.14060)
*Arshpreet Singh Maan,Francisco-Garcia Herrero,Alexandru Paler,Valentin Savin*

Main category: quant-ph

TL;DR: 我们提出了一种用于量子LDPC码在电路级噪声下相关错误的解码框架，通过GARI方法消除Y型错误相关的4-环路，并结合归一化min-sum解码器和集成解码来提高准确性和速度，在距离12的码上实现了接近实时的高精度逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 在量子LDPC码中处理电路级噪声下的相关错误，以提高解码的准确性和效率。

Method: 提出GARI（图增强和重布线以消除干扰）方法，该方法通过消除涉及Y型错误的4-环路来修改相关检测器错误模型，同时保持解码问题的等价性。然后，在转换后的图上应用带有混合串行-分层调度的归一化min-sum解码器，并通过集成解码进一步提高性能。

Result: 所提出的方法在距离为6、10和12的双变量自行车码上进行了测试。与现有的XYZ-Relay-BP解码器相比，在相同的电路级噪声条件下，所提出的方法实现了具有前所未有速度的最高报告准确率。对于距离12的码，在10^{-3}$的物理错误率下，逻辑错误率达到了$(6.70 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{ } 	ext{1.93}) 	imes 10^{-9}$。初步的FPGA实现结果表明，可以在实时中实现如此高的精度，每轮平均解码延迟为273 ns，99.99%的解码实例延迟低于亚微秒。

Conclusion: GARI方法能够有效地处理量子LDPC码在电路级噪声下的相关错误，实现了高精度和低延迟的解码，并且初步的FPGA实现验证了其在实际应用中的可行性。

Abstract: We introduce a decoding framework for correlated errors in quantum LDPC codes
under circuit-level noise. The core of our approach is a graph augmentation and
rewiring for interference (GARI) method, which modifies the correlated detector
error model by eliminating 4-cycles involving Y-type errors, while preserving
the equivalence of the decoding problem. We test our approach on the bivariate
bicycle codes of distances 6, 10, and 12. A normalized min-sum decoder with a
hybrid serial-layered schedule is applied on the transformed graph, achieving
high accuracy with low latency. Performance is further enhanced through
ensemble decoding, where 24 randomized normalized min-sum decoders run in
parallel on the transformed graph, yielding the highest reported accuracy (on
par with XYZ-Relay-BP) with unprecedented speed for the tested codes under
uniform depolarizing circuit level noise. For the distance 12 (gross) code, our
approach yields a logical error rate of $(6.70 \pm 1.93) \times 10^{-9}$ at a
practical physical error rate of $10^{-3}$. Furthermore, preliminary FPGA
implementation results show that such high accuracy can be achieved in real
time, with a per-round average decoding latency of 273 ns and sub-microsecond
latency in 99.99% of the decoding instances.

</details>


### [460] [Quantum Search in Superposed Quantum Lattice Gas Automata and Lattice Boltzmann Systems](https://arxiv.org/abs/2510.14062)
*Călin A. Georgescu,Matthias Möller*

Main category: quant-ph

TL;DR: 尽管量子格子气自动机（QLGA）和量子格子玻尔兹曼方法（QLBM）在CFD领域显示出潜力，但其实际应用因测量限制而受到阻碍。本文提出了一种基于离散优化和量子搜索的新应用，通过同时模拟多种格子配置并利用幅度估计和量子搜索，绕过了测量步骤，并有望实现量子优势。


<details>
  <summary>Details</summary>
Motivation: 现有的量子格子气自动机（QLGA）和量子格子玻尔兹曼方法（QLBM）在计算流体动力学（CFD）领域虽然取得了进展，但主要集中在模型开发而非实际应用。这些模型在实际应用中受限于量子态层析和可观测量测量，这可能抵消潜在的量子优势。

Method: 本文提出了一种基于离散优化和量子搜索的新应用，可以同时模拟多种格子配置，并利用幅度估计和量子搜索来提供渐进的量子优势，从而避免了对流场进行测量的需要。

Result: 通过详细的门级实现复杂度分析，并考虑了不同编码的优势和成本，本文的方法有望在实践中提供量子优势。

Conclusion: 本文提出的基于离散优化和量子搜索的方法，通过避免流场测量并利用幅度估计和量子搜索，为QLGA和QLBM在CFD领域的实际应用提供了一条新的途径，并有望实现量子优势。

Abstract: As the scope of Computational Fluid Dynamics (CFD) grows to encompass ever
larger problem scales, so does the interest in whether quantum computing can
provide an advantage. In recent years, Quantum Lattice Gas Automata (QLGA) and
Quantum Lattice Boltzmann Methods (QLBM) have emerged as promising candidates
for quantum-native implementations of CFD solvers. Though the progress in
developing QLGA and QLBM algorithms has been significant, it has largely
focused on the development of models rather than applications. As a result, the
zoo of QLGA and QLBM algorithms has grown to target several equations and to
support many extensions, but the practical use of these models is largely
limited to quantum state tomography and observable measurement. This limitation
is crucial in practice, because unless very specific criteria are met, such
measurements may cancel out any potential quantum advantage. In this paper, we
propose an application based on discrete optimization and quantum search, which
circumvents flow field measurement altogether. We propose methods for
simulating many different lattice configurations simultaneously and describe
how the usage of amplitude estimation and quantum search can provide an
asymptotic quantum advantage. Throughout the paper, we provide detailed
complexity analyses of gate-level implementations of our circuits and consider
the benefits and costs of several encodings.

</details>


### [461] [Quantum Low-Density Parity-Check Codes](https://arxiv.org/abs/2510.14090)
*Bane Vasic,Valentin Savin,Michele Pacenti,Shantom Borah,Nithin Raveendran*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum error correction (QEC) is a cornerstone of quantum computing,
enabling reliable information processing in the presence of noise. Sparse
stabilizer codes -- referred to generally as quantum low-density parity-check
(QLDPC) codes -- have risen to the forefront of QEC research in recent years.
This can be attributed to several key factors. First, classical LDPC codes
admit low-complexity belief propagation iterative decoding and near-capacity
performance, which contributed to the early interest in QLDPC codes. Then, the
result promising constant overhead fault tolerance using QLDPC codes led to the
search for code families that go beyond the long-holding $\sqrt{n}$ scaling
barrier of minimum distance for codelength $n$. This resulted in recent
breakthroughs in the construction of QLDPC codes, which, combined with
efficient decoding algorithms and the development of fault-tolerant protocols
operating on QLDPC-encoded quantum information, provide a promising pathway to
low-overhead, fault-tolerant quantum computation. However, despite their
potential, challenges remain, particularly in constructing and decoding
finite-length codes that account for, or efficiently leverage, specific
characteristics of quantum hardware, such as connectivity, topology, native
gate sets, and noise models. This article provides an in-depth examination of
QLDPC codes and their iterative decoders, catering to an information theory
audience with no or limited background in quantum mechanics. We discuss the
theoretical underpinnings, explore unique characteristics of quantum channels,
and delineate key code constructions and decoding algorithms, ultimately
highlighting the impact and future prospects of QLDPC codes in quantum
information science.

</details>


### [462] [Quantum machine learning and quantum-inspired methods applied to computational fluid dynamics: a short review](https://arxiv.org/abs/2510.14099)
*Cesar A. Amaral,Vinícius L. Oliveira,Juan P. L. C. Salazar,Eduardo I. Duzzioni*

Main category: quant-ph

TL;DR: 量子计算和张量网络方法有望克服传统计算流体动力学（CFD）在处理高维、多尺度和湍流问题时面临的可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在处理高维、多尺度和湍流CFD问题时面临可扩展性挑战，成本高昂。

Method: 该综述考察了量子计算、量子算法、机器学习和张量网络技术在CFD领域的交叉进展，包括变分量子算法（VQAs）用于求解偏微分方程（PDEs）、量子神经网络（QNNs）、量子物理信息神经网络（QPNNs）以及张量网络方法。

Result: 量子和量子启发的方法在CFD基准测试中显示出提高参数效率和解精度的优势，张量网络方法已实现内存和运行时间的数量级缩减，同时保持精度。

Conclusion: 虽然在NISQ时代实现完全的量子CFD仍有挑战，但量子启发张量网络已显示出实际效益，混合方法提供了最有希望的近期策略。

Abstract: Computational Fluid Dynamics (CFD) is central to science and engineering, but
faces severe scalability challenges, especially in high-dimensional,
multiscale, and turbulent regimes. Traditional numerical methods often become
prohibitively expensive under these conditions. Quantum computing and
quantum-inspired methods have been investigated as promising alternatives. This
review surveys advances at the intersection of quantum computing, quantum
algorithms, machine learning, and tensor network techniques for CFD. We discuss
the use of Variational Quantum Algorithms as hybrid quantum-classical solvers
for PDEs, emphasizing their ability to incorporate nonlinearities through
Quantum Nonlinear Processing Units. We further review Quantum Neural Networks
and Quantum Physics-Informed Neural Networks, which extend classical machine
learning frameworks to quantum hardware and have shown advantages in parameter
efficiency and solution accuracy for certain CFD benchmarks. Beyond quantum
computing, we examine tensor network methods, originally developed for quantum
many-body systems and now adapted to CFD as efficient high-dimensional
compression and solver tools. Reported studies include several orders of
magnitude reductions in memory and runtime while preserving accuracy. Together,
these approaches highlight quantum and quantum-inspired strategies that may
enable more efficient CFD solvers. This review closes with perspectives:
quantum CFD remains out of reach in the NISQ era, but quantum-inspired tensor
networks already show practical benefits, with hybrid approaches offering the
most promising near-term strategy.

</details>


### [463] [Symmetry-protected states of interacting qubits in superconducting quantum circuits](https://arxiv.org/abs/2510.14121)
*Yi Shi,Eran Ginossar,Michael Stern,Marzena Szymanska*

Main category: quant-ph

TL;DR: 提出了一种利用对称性保护的四自旋模型来实现长相干时间的超导量子比特。


<details>
  <summary>Details</summary>
Motivation: 为了在量子信息存储和处理方面取得进展，需要对超导电路中的量子比特进行内在噪声保护，以隔离计算态免受局部噪声源的干扰。

Method: 提出了一种相互作用的自旋模型，该模型需要至少四个具有最近邻和次近邻耦合的自旋，其中两个最低的本征态形成一个对称性保护的量子比特流形，该流形对来自局部扰动的弛豫和退相干都具有鲁棒性。将该自旋模型映射到超导电路。

Result: 所提出的超导电路在存在实际环境噪声的情况下，相干时间有望超过数毫秒。

Conclusion: 该工作为在新一代量子设备中实现具有长相干时间的量子比特开辟了新途径。

Abstract: Superconducting circuits are one of the leading candidates for storing and
manipulating quantum information. Among them, qubits embedded with intrinsic
noise protection have seen rapid advancements in recent years. This noise
protection is typically realized by isolating the computational states from
local sources of noise. Here, we propose an interacting spin model that
requires at least four spins with nearest-neighbor and next-nearest-neighbor
couplings, where the two lowest eigenstates form a symmetry-protected qubit
manifold, which is robust to both relaxation and dephasing from local
perturbations. We map the spin model to a superconducting circuit and show that
such a circuit can reach coherence times exceeding several milliseconds in the
presence of realistic environmental noise. Our work opens a pathway to
realizing qubits with long coherence times in a new generation of quantum
devices.

</details>


### [464] [Universal energy-space localization and stable quantum phases against time-dependent perturbations](https://arxiv.org/abs/2510.14160)
*Hongye Yu,Tzu-Chieh Wei*

Main category: quant-ph

TL;DR: 能量空间局域化是一种普遍存在的现象，即使在时间依赖的扰动下也能保持稳定，并且可以应用于证明量子系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决量子系统在面对时间依赖的扰动时稳定性难以确定的问题，并提出一种新的分析非平衡动力学的方法。

Method: 识别并证明了q-局域哈密顿量中普遍存在的能量空间局域化现象，该现象可以在时间依赖的扰动下得以维持，并证明了其在不同系统中的应用，包括自旋玻璃模型、LDPC码和经典优化问题。

Result: 能量空间局域化现象可以保证系统在能量窗口内保持指数级局域化，并且在时间依赖的扰动下保持稳定。该现象已被应用于证明自旋玻璃模型、LDPC码的稳定性，并揭示了其在经典优化问题中的潜在障碍。

Conclusion: 能量空间局域化是一种在非平衡动力学中具有普遍意义的现象，为分析量子系统稳定性提供了新的视角和强大的数学工具，并在量子算法设计方面具有广泛的应用前景。

Abstract: Stability against perturbation is a highly nontrivial property of quantum
systems and is often a requirement to define new phases. In most systems where
stability can be rigorously established, only static perturbations are
considered; whether a system is stable against generic time-dependent
perturbations remains largely elusive. In this work, we identify a universal
phenomenon in $q$-local Hamiltonians called energy-space localization and prove
that it can survive under generic time-dependent perturbations, where the
evolving state is exponentially localized in an energy window of the
instantaneous spectrum. The property holds ubiquitously, and the leakage bounds
remain invariant under arbitrarily monotonic rescaling of evolution time. This
flexibility enables the energy-space localization to be a powerful tool in
proving the stability of systems. For spin glass models where the configuration
spaces are separated by large energy barriers, the localization in energy space
can induce a true localization in the configuration space and robustly break
ergodicity. We then demonstrate the applications of our results in several
systems with such barriers. For certain LDPC codes, we show that the evolving
state is localized near the original codeword for an exponentially long time
even under generic time-dependent perturbations. We also extend the stability
of LDPC codes against static $q$-local perturbations to quasi-$q$-local. In
addition, we show that for some classical hard optimization problems with
clustered solution space, the stability becomes an obstacle for quantum
Hamiltonian-based algorithms to drive the system out of local minima. Our work
provides a new lens for analyzing the non-equilibrium dynamics of generic
quantum systems, and versatile mathematical tools for stability proving and
quantum algorithm design.

</details>


### [465] [Classification of Transuranium Elements in Terms of `Winding' Numbers in the Bohr-Sommerfeld Model](https://arxiv.org/abs/2510.14289)
*Sergei K. Suslov*

Main category: quant-ph

TL;DR: Bohr-Sommerfeld模型可用于研究超重元素，并揭示了强库仑场中的自相交轨道。


<details>
  <summary>Details</summary>
Motivation: 本文旨在重新审视Bohr-Sommerfeld原子模型，以探索类氢铀（Z=92）、类俄歇（Z=118）和假设的超重元素。

Method: 采用Sommerfeld精细结构公式和计算机代数方法，研究了强库仑场中自相交轨道的出现，并根据其“绕曲”数对其进行分类。

Result: 研究发现在强库仑场中，从类俄歇开始，直到Z≤137的假设元素，会出现自相交轨道。

Conclusion: Bohr-Sommerfeld模型提供了一种理解早期量子理论与现代超重元素物理学之间联系的途径，并揭示了强库仑场中的拓扑学特征。

Abstract: We revisit the Bohr-Sommerfeld atomic model to explore hydrogen-like ions of
Uranium ($Z=92$), Oganesson ($Z=118$), and hypothetical superheavy elements
beyond. Although superseded by the Dirac equation and modern quantum
electrodynamics, the semiclassical approach offers a historically and
pedagogically valuable perspective. Using the Sommerfeld fine structure formula
and computer algebra methods, we demonstrate the appearance of
self-intersecting orbits in super strong Coulomb fields, beginning with
Oganesson and hypothetical elements up to $Z\le137$. These orbits can be
classified by their `winding' numbers, providing a simple topological
description of Coulomb field strength in this framework. Our results highlight
a conceptual bridge between early quantum theory and modern superheavy element
physics.

</details>


### [466] [Quantifiers of Noise Reducibility Under Restricted Control](https://arxiv.org/abs/2510.14316)
*Graeme D. Berk,Kavan Modi,Simon Milz*

Main category: quant-ph

TL;DR: 量子关联结构（量子梳）是量子信息协议和控制任务的重要资源。本文提出了满足单调性的量子过程效用量化器，克服了先前方法的不足。将这些量化器应用于开放循环控制下的量子过程噪声消除问题，它们可以表示过程所能呈现的最大时间互信息量。此外，还研究了它们的资源构成行为，并将其与广义梳散度联系起来。最后，重新解释了npj Quantum Information 9, 104 (2023) 的数值结果，表明动力学解耦作为资源蒸馏的解释仍然成立。


<details>
  <summary>Details</summary>
Motivation: 量子关联结构（量子梳）是量子信息协议和控制任务的重要资源。需要更有效的量化方法来衡量其效用。

Method: 引入满足单调性的量子过程效用量化器，并将其应用于开放循环控制下的量子过程噪声消除问题，研究其资源构成行为，并与广义梳散度联系起来。重新解释了npj Quantum Information 9, 104 (2023) 的数值结果。

Result: 提出的量化器克服了先前方法的不足，可以表示过程所能呈现的最大时间互信息量。研究了其资源构成行为，并与广义梳散度联系起来。重新解释了相关数值结果，证实了动力学解耦作为资源蒸馏的解释。

Conclusion: 新提出的量子过程效用量化器为评估量子梳资源提供了更有效的方法，并加深了对动力学解耦在量子信息处理中作用的理解。

Abstract: The correlation structure of multitime quantum processes - succinctly
described by quantum combs - is an important resource for many quantum
information protocols and control tasks. Inspired by approaches for quantum
states, we introduce quantifiers of the practical utility of quantum processes
that satisfy monotonicity properties, thus overcoming shortcomings in previous
state-motivated approaches. Applying these quantifiers to the problem of noise
reduction of a quantum process under open-loop control, they are shown to
represent the largest amount of temporal mutual information that a process can
possibly exhibit. In addition, we study their resource composition behaviour
and connect them to the recently introduced notion of generalised comb
divergences. Finally, in light of these new quantifiers, we re-interpret the
numerical findings of npj Quantum Information 9, 104 (2023) on the relationship
of dynamical decoupling and non-Markovian memory, which were based on
insufficient resource quantifiers, and show that its main conclusion - the
interpretation of dynamical decoupling as a resource distillation - still
holds.

</details>


### [467] [Offline Dedicated Quantum Attacks on Block Ciphers Based on Two Parallel Permutation-Based Pseudorandom Functions](https://arxiv.org/abs/2510.14475)
*Xiao-Fan Zhen,Zhen-Qiang Li,Jia-Cheng Fan,Su-Juan Qin,Fei Gao*

Main category: quant-ph

TL;DR: Shi等人提出的XOR型函数的量子攻击大大减少了资源需求。本文发现新的可攻击结构（PolyMAC和基于TPP-PRF的块密码），并提出了针对TPP-PRF块密码的离线量子攻击，显著降低了查询复杂度。


<details>
  <summary>Details</summary>
Motivation: 评估密码系统对抗量子计算威胁的安全性，特别是针对Shi等人提出的XOR型函数的量子攻击。

Method: 1. 发现新的密码结构（PolyMAC和基于TPP-PRF的块密码）以适应Shi等人的攻击。 2. 提出一种解耦的XOR型函数，从而能够对TPP-PRF块密码进行离线量子攻击。

Result: 1. 发现了PolyMAC和包括XopEM、SoEM22、SUMPIP和DS-SoEM在内的基于TPP-PRF的块密码。 2. 提出的离线量子攻击将加密谕示查询复杂度从O(2^((n+t)/2))降低到O(2^t)，同时保持相同的时间复杂度。 3. 在经典查询模型中，将经典查询复杂度从O(2^((2n)/3))优化到O(2^((2n-t)/3))。

Conclusion: 本文在量子和经典查询模型中都提出了针对基于TPP-PRF的块密码的更优越的量子攻击方法，降低了所需的资源和查询复杂度。

Abstract: Quantum cryptanalysis is essential for evaluating the security of
cryptographic systems against the threat of quantum computing. Recently, Shi et
al. introduced the dedicated quantum attack on XOR-type function that greatly
reduces the required resources (including circuit depth, width, and the number
of gates) compared to the parallel Grover-meets-Simon algorithm. Here, our
contribution is in two aspects. On the one hand, we discover new cryptographic
structures amenable to this attack: PolyMAC and block ciphers based on two
parallel permutation-based pseudorandom functions (TPP-PRFs), including XopEM,
SoEM22, SUMPIP, and DS-SoEM, partially answering Shi et al.'s open question. On
the other hand, for block ciphers based on TPP-PRFs, we break the obstacle that
this attack rely on online query by constructing decoupled XOR-type function,
then propose an offline quantum attack on them. Compared to previous results,
our offline attack exhibits significantly reduced query complexity.
Specifically, we reduce the number of queries to the encryption oracle from
$\tilde O(2^{(n+t)/2})$ to $\tilde O(2^{t})$ with the same time complexity in
the quantum query model, and enable its implementation in the classical query
model, optimizing both the classical query complexity and time complexity from
$\tilde O(2^{(2n)/3})$ to $\tilde O(2^{(2n-t)/3})$.

</details>


### [468] [Transferable Equivariant Quantum Circuits for TSP: Generalization Bounds and Empirical Validation](https://arxiv.org/abs/2510.14533)
*Monit Sharma,Hoong Chuin Lau*

Main category: quant-ph

TL;DR: 通过引入等变量子电路（EQCs）来解决量子强化学习（QRL）在组合优化（如旅行商问题）中的泛化性问题，实现了从小型实例到大型实例的零样本迁移，并提出了新的泛化边界。


<details>
  <summary>Details</summary>
Motivation: 现有的QRL方法在处理大规模组合优化问题时面临训练不可行的挑战，限制了其在小规模问题上的应用。

Method: 采用能够保持TSP图的排列对称性的等变量子电路（EQCs），并推导了迁移学习场景下的新泛化边界，该边界考虑了不同规模TSP实例之间的结构差异。

Result: 在小型TSP实例上训练的EQC策略能够在更大规模的实例上实现零样本（zero-shot）的良好性能，并且通过微调可以进一步提升性能，这与经典迁移学习中的积极迁移现象一致。

Conclusion: 将排列对称性嵌入量子模型是实现可扩展QRL解决方案的关键，尤其是在组合优化任务中，而等变性在可迁移的量子学习中起着至关重要的作用。

Abstract: In this work, we address the challenge of generalization in quantum
reinforcement learning (QRL) for combinatorial optimization, focusing on the
Traveling Salesman Problem (TSP). Training quantum policies on large TSP
instances is often infeasible, so existing QRL approaches are limited to
small-scale problems. To mitigate this, we employed Equivariant Quantum
Circuits (EQCs) that respect the permutation symmetry of the TSP graph.
  This symmetry-aware ansatz enabled zero-shot transfer of trained parameters
from $n-$city training instances to larger m-city problems. Building on recent
theory showing that equivariant architectures avoid barren plateaus and
generalize well, we derived novel generalization bounds for the transfer
setting. Our analysis introduces a term quantifying the structural
dissimilarity between $n-$ and $m-$node TSPs, yielding an upper bound on
performance loss under transfer. Empirically, we trained EQC-based policies on
small $n-$city TSPs and evaluated them on larger instances, finding that they
retained strong performance zero-shot and further improved with fine-tuning,
consistent with classical observations of positive transfer between scales.
These results demonstrate that embedding permutation symmetry into quantum
models yields scalable QRL solutions for combinatorial tasks, highlighting the
crucial role of equivariance in transferable quantum learning.

</details>


### [469] [Polaritons confined in dielectric structures](https://arxiv.org/abs/2510.14566)
*Amir Rahmani,Dogyun Ko,Maciej Dems,Andrzej Opala,Michał Matuszewski*

Main category: quant-ph

TL;DR: 现有理论模型无法精确描述强量子耦合下的光-物质相互作用，尤其是在光-物质本征模式形状被显著改变时。本研究提出了一种基于Bogoliubov变换和三量子化技术的新方法，可以在极化子本征模式基下获得量子模型，并能用于增强相互作用和设计纳米结构中的非局域多体相互作用，从而产生强烈的非经典光关联。


<details>
  <summary>Details</summary>
Motivation: 现有理论模型（如Hopfield模型）在描述强量子耦合下的光-物质相互作用时存在局限性，特别是当光-物质本征模式的形状受到相互作用的显著影响时。此外，理论模型的参数通常需要通过拟合实验数据获得，缺乏直接确定特定介电结构量子主方程的方法，这可能导致理论描述与物理实际不兼容。本研究旨在解决这些问题，提供一种更直接、更精确的量子模型构建方法。

Method: 提出了一种在极化子本征模式基下获得量子模型的方法。在保守情况下，使用Bogoliubov变换；在耗散情况下，使用三量子化技术。

Result: 该方法可以用于增强相互作用强度，并在精心设计的纳米结构中工程化非局域多体相互作用，从而产生强烈的非经典光关联。

Conclusion: 本研究提出的新方法能够克服现有理论模型的局限性，为在强量子耦合下精确描述光-物质相互作用提供了一种有效的途径，并为设计新型纳米材料和器件提供了理论指导。

Abstract: Light-matter interaction in the regime of strong quantum coupling is usually
treated within the framework of the Hopfield model. However, the picture of
coupling well-defined modes of light and matter is correct only as long as the
shapes of these eigenmodes are not substantially modified by the interaction.
Moreover, parameters of theoretical models are usually obtained by fitting to
experimental data. To date, there has been no straightforward method to
determine a quantum master equation corresponding to a system with specific
dielectric structure, which may lead to incompatibility of theoretical
descriptions and physical realizations. We present a recipe for obtaining a
quantum model in the polariton eigenmode basis based on Bogoliubov
transformation in the conservative case and third quantization technique in the
dissipative case. We show how this method can be used for boosting interaction
strength and engineering nonlocal many-body interactions in carefully designed
nanostructures, resulting in strongly nonclassical correlations of emitted
light.

</details>


### [470] [Quantum Reinforcement Learning: Recent Advances and Future Directions](https://arxiv.org/abs/2510.14595)
*Jawaher Kaldari,Shehbaz Tariq,Saif Al-Kuwari,Samuel Yen-Chi Chen,Symeon Chatzinotas,Hyundong Shin*

Main category: quant-ph

TL;DR: 量子强化学习（QRL）是量子机器学习的一个新兴领域，具有跨越量子和经典领域的潜力。本调查全面分析了QRL的算法、架构、SDK和应用，并讨论了其面临的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 量子强化学习（QRL）虽然不像其他量子机器学习方法那样受到广泛关注，但其在量子和经典领域都展现出了独特的优势和跨领域应用潜力，因此值得深入研究。

Method: 对量子强化学习（QRL）的算法、架构、SDK和应用进行了全面的分析和梳理。

Result: QRL在不同领域展现出应用潜力，并具有跨越量子和经典领域的优势。

Conclusion: QRL面临挑战但机遇巨大，在量子启发式强化学习和跨学科应用方面具有重要的创新潜力。

Abstract: As quantum machine learning continues to evolve, reinforcement learning
stands out as a particularly promising yet underexplored frontier. In this
survey, we investigate the recent advances in QRL to assess its potential in
various applications. While QRL has generally received less attention than
other quantum machine learning approaches, recent research reveals its distinct
advantages and transversal applicability in both quantum and classical domains.
We present a comprehensive analysis of the QRL framework, including its
algorithms, architectures, and supporting SDK, as well as its applications in
diverse fields. Additionally, we discuss the challenges and opportunities that
QRL can unfold, highlighting promising use cases that may drive innovation in
quantum-inspired reinforcement learning and catalyze its adoption in various
interdisciplinary contexts.

</details>


### [471] [Single-shot antidistinguishability of unitary operations](https://arxiv.org/abs/2510.14609)
*Satyaki Manna,Anandamay Das Bhowmik*

Main category: quant-ph

TL;DR: 研究了量子信道的单次不可区分性，特别是酉算子的不可区分性。


<details>
  <summary>Details</summary>
Motivation: 量子状态的不可区分性已被广泛研究，但量子信道的不可区分性仍是未探索的领域。

Method: 分析了单系统探测器和纠缠探测器的两种情况。对于三酉算子集，证明了所有最大纠缠态作为探测器的性能是等价的。在量子比特的情况下，证明了最大纠缠探测器总是足够的。然而，在高维度下，这种等价性失败了。在三维度下，存在一组酉算子，它们可以用非最大纠缠探测器或单系统探测器来区分，但不能用最大纠缠探测器来区分。还证明了两个不可区分的三量子比特酉算子集的并集也构成一个不可区分酉算子集。最后，提供了从非不可区分酉算子构造不可区分酉算子集的方法。

Result: 在量子比特情况下，最大纠缠探测器总是足够的。在高维度下，发现了一个反例，即存在一组酉算子，它们可以用非最大纠缠探测器或单系统探测器区分，但不能用最大纠缠探测器区分。证明了两个不可区分的三量子比特酉算子集的并集也构成一个不可区分酉算子集。

Conclusion: 研究结果表明，量子信道的不可区分性，特别是酉算子的不可区分性，是一个复杂的问题，其行为在高维空间中可能与低维空间不同。

Abstract: The notion of antidistinguishability captures the possibility of ruling out
certain alternatives in a quantum experiment without identifying the actual
outcome. Although extensively studied for quantum states, the
antidistinguishability of quantum channels remains largely unexplored. In this
work, we investigate the single-shot antidistinguishability of unitary
operations. We analyse two scenarios: antidistinguishability with single-system
probes and with entangled probes. For sets of three unitaries, we first prove
that all maximally entangled states are equivalent in their performance as
probe. In the qubit case, we further establish that maximally entangled probes
are always sufficient: if a set of three qubit unitaries is antidistinguishable
with either a single-system or non-maximally entangled probe, then it is also
antidistinguishable with a maximally entangled one. However, in higher
dimension, this equivalence fails. In \textit{dimension 3}, there exists a set
of unitaries that are antidistinguishable with non-maximally entangled probe or
single-system probe but not with maximally entangled probe. We also establish
that union of two antidistinguishable sets of three qubit unitaries also forms
a set of antidistinguishable unitaries. Lastly, we provide methods to construct
antidistinguishable unitaries from non-antidistinguishable ones.

</details>


### [472] [Multiparameter quantum-enhanced adaptive metrology with squeezed light](https://arxiv.org/abs/2510.14739)
*Giorgio Minati,Enrico Urbani,Nicolò Spagnolo,Valeria Cimini,Fabio Sciarrino*

Main category: quant-ph

TL;DR: 该研究提出了一种自适应多参数估计策略，用于从头开始进行相位估计，能够在不依赖压缩参数先验知识的情况下，在整个周期区间 [0,π) 内实现低于标准量子极限的精度。该方法通过实时反馈联合估计光学相位和压缩水平，确保了对实验漂移和校准错误的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了充分利用压缩光在量子增强相位估计中的优势，估计协议必须在整个参数范围内保持最优，并能抵抗探测器状态的不稳定性。依赖预先校准的压缩水平的策略容易随着时间退化，并且在实验条件波动时会变得次优。

Method: 开发了一种自适应多参数估计策略，该策略采用实时反馈来联合估计光学相位和压缩水平，以实现从头开始的相位估计。

Result: 在整个周期区间 [0,π) 内实现了低于标准量子极限的精度，并且不依赖于压缩参数的先验知识。

Conclusion: 该自校准方案建立了一个可靠的量子增强传感框架，为实际应用和使用压缩光进行可扩展的分布式传感器网络开辟了新的途径。

Abstract: Squeezed light enables quantum-enhanced phase estimation, with crucial
applications in both fundamental physics and emerging technologies. To fully
exploit the advantage provided by this approach, estimation protocols must
remain optimal across the entire parameter range and resilient to instabilities
in the probe state. In this context, strategies that rely on pre-calibrated
squeezing levels are vulnerable to degradation over time and become sub-optimal
when experimental conditions fluctuate. Here, we develop an adaptive
multiparameter estimation strategy for ab-initio phase estimation, achieving
sub-standard quantum limit precision in the full periodicity interval
$[0,\pi)$, without relying on prior knowledge of the squeezing parameter. Our
approach employs real-time feedback to jointly estimate both the optical phase
and the squeezing level, ensuring robustness against experimental drifts and
calibration errors. This self-calibrating scheme establishes a reliable
quantum-enhanced sensing framework, opening new routes for practical scenarios
and scalable distributed sensor networks using squeezed light.

</details>


### [473] [Unsupervised Learning to Recognize Quantum Phases of Matter](https://arxiv.org/abs/2510.14742)
*Mehran Khosrojerdi,Alessandro Cuccoli,Paola Verrucchi,Leonardo Banchi*

Main category: quant-ph

TL;DR: 本研究提出使用无监督学习方法，通过计算量子态保真度来绘制多体系统的量子相图。


<details>
  <summary>Details</summary>
Motivation: 在多体系统的哈密顿量参数空间中绘制量子相图可以看作是一个学习问题，需要根据定义相的分类标准来标记相应的基态。本研究旨在探索使用无监督学习，在无先验标记数据的情况下，确定多体系统的量子相图。

Method: 该算法直接处理量子态，通过计算不同哈密顿量参数下基态配置之间的保真度，根据相似性标准对它们进行分组，从而揭示最显著的分类方式。研究中使用了基于谱聚类的无监督学习算法，并结合“轮廓系数”和“肘部法则”来确定最优相数。

Result: 通过对两个特定的自旋1/2链进行基准测试，并利用张量网络技术确定状态，研究发现该无监督学习方法能够准确地重构相图。

Conclusion: 本研究证明了无监督学习能够自主识别并可能揭示新的量子物相。

Abstract: Drawing the quantum phase diagram of a many-body system in the parameter
space of its Hamiltonian can be seen as a learning problem, which implies
labelling the corresponding ground states according to some classification
criterium that defines the phases. In this work we adopt unsupervised learning,
where the algorithm has no access to any priorly labeled states, as a tool for
determining quantum phase diagrams of many-body systems. The algorithm directly
works with quantum states: given the ground-state configurations for different
values of the Hamiltonian parameters, the process uncovers the most significant
way of grouping them based on a similarity criterion that refers to the
fidelity between quantum states, that can be easily estimated, even
experimentally. We benchmark our method with two specific spin-$\frac{1}{2}$
chains, with states determined via tensor network techniques. We find that
unsupervised learning algorithms based on spectral clustering, combined with
``silhouette'' and ``elbow'' methods for determining the optimal number of
phases, can accurately reproduce the phase diagrams. Our results show how
unsupervised learning can autonomously recognize and possibly unveil novel
phases of quantum matter.

</details>


### [474] [Spectral subspace extraction via incoherent quantum phase estimation](https://arxiv.org/abs/2510.14744)
*Stefano Scali,Josh Kirsopp,Antonio Márquez Romero,Michał Krompiec*

Main category: quant-ph

TL;DR: DOS-QPE 是一种新方法，可以估计哈密顿量的态密度 (DOS)，克服了标准量子相位估计 (QPE) 的局限性。


<details>
  <summary>Details</summary>
Motivation: 标准 QPE 算法需要精确制备的相干输入，并且只能提取单个本征态，这限制了其在某些量子模拟任务中的应用。本研究旨在提出一种更通用的 QPE 方法，能够直接提取哈密顿量的态密度，从而获得系统的整体谱信息。

Method: 本研究提出了一种基于系综的 DOS-QPE 方法，并将其作为一种电路原语。该方法通过对称性适配的输入系综和先进的谱重构技术进行扩展。谱重构问题被转化为一个二次规划问题，并使用压缩传感技术求解。

Result: DOS-QPE 能够直接访问热力学性质、对称性分辨的谱函数以及量子多体系统中相关的特征。研究人员在费米子模型和核哈密顿量上展示了该方法的性能。

Conclusion: DOS-QPE 是一种有前景的量子算法，有望在早期容错量子模拟中，在光谱学、电子结构和核理论等领域得到应用。

Abstract: Quantum phase estimation (QPE) is a cornerstone algorithm for extracting
Hamiltonian eigenvalues, but its standard form targets individual eigenstates
and requires carefully prepared coherent inputs. To overcome these limitations,
we adopt an ensemble-based formulation of QPE that estimates the density of
states (DOS) of the Hamiltonian generator of the evolution. This approach,
which we refer to as DOS-QPE, builds on a prior formulation introduced by one
of the authors. In this work, we present DOS-QPE as a circuit primitive,
extending it with symmetry-adapted input ensembles and advanced spectrum
reconstruction techniques. This variant of QPE enables natural access to
thermodynamic properties, symmetry-resolved spectral functions, and features
relevant to quantum many-body systems. We demonstrate its performance on
fermionic models and nuclear Hamiltonians by casting the spectrum
reconstruction problem as a quadratic program solved via compressed sensing.
These use cases highlight the potential of DOS-QPE for early fault-tolerant
quantum simulations in spectroscopy, electronic structure, and nuclear theory.

</details>


### [475] [Quantum remeshing and efficient encoding for fracture mechanics](https://arxiv.org/abs/2510.14746)
*Ulysse Remond,Pierre-Emmanuel Emeriau,Liam Lysaght,Jean Ruel,Joseph Mikael,Kyryl Kazymyrenko*

Main category: quant-ph

TL;DR: 我们提出了一个用于结构力学问题（特别是裂缝扩展模拟）的变分量子算法，能够高效地提取关键可观测量，并通过实验在光量子处理器上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 传统上，裂缝扩展模拟需要大量的计算资源，本研究旨在提供一种替代的量子算法解决方案。

Method: 实现一个参数化量子电路，将节点位移编码为量子振幅，通过最小化弹性能量（使用有限元方法计算）来获得最优节点位移，能量计算仅需对数次测量。采用基于重构技术的“热启动”策略来规避优化过程中的“贫瘠平原”问题。

Result: 该算法能够高效地提取应力强度因子等标量可观测量，并通过Quandela的光子量子处理器Ascella进行了实验验证，数值模拟也证明了其在复杂量子系统中的可扩展性。

Conclusion: 本研究提出的变分量子算法为解决结构力学问题提供了一种有前景的量子计算方法，并展示了其在实际应用中的潜力和可扩展性。

Abstract: We present a variational quantum algorithm for structural mechanical
problems, specifically addressing crack opening simulations that traditionally
require extensive computational resources. Our approach provides an alternative
solution for a relevant 2D case by implementing a parametrized quantum circuit
that stores nodal displacements as quantum amplitudes and efficiently extracts
critical observables. The algorithm achieves optimal nodal displacements by
minimizing the elastic energy obtained from finite element method. The energy
is computed with only a polylogarithmic number of measurements. Extracting
relevant scalar observables such as the stress intensity factor is then done
efficiently on the converged solution. To validate the scalability of our
approach, we develop a warm start strategy based on a remeshing technique that
uses coarse solutions to circumvent barren plateaus in the optimization
landscape of the more refined problems. Our method has been experimentally
validated on Quandela's photonic quantum processor Ascella and comprehensive
numerical simulations demonstrate its scalability across increasingly complex
quantum systems.

</details>


### [476] [ParaToric 1.0-beta: Continuous-time quantum Monte Carlo for the toric code in a parallel field](https://arxiv.org/abs/2510.14781)
*Simon M. Linsel,Lode Pollet*

Main category: quant-ph

TL;DR: ParaToric是一个C++包，用于在有限温度下模拟平行磁场中的toric code。它实现了并扩展了Wu, Deng, and Prokof'ev的连续时间量子蒙特卡洛算法，支持多种晶格结构和边界条件，并可扩展至任意晶格和自定义可观测值。该软件还支持X和Z基下的快照提取，可用于为其他方法生成训练/基准测试数据，并提供C/C++和Python接口，易于集成。


<details>
  <summary>Details</summary>
Motivation: 介绍ParaToric软件包，该软件用于模拟平行磁场（X和Z场）下的toric code，并考虑有限温度效应。

Method: 实现并扩展了Wu, Deng, and Prokof'ev的连续时间量子蒙特卡洛算法，应用于方形、三角形、蜂巢形和立方体等晶格结构，并支持开放和周期性边界条件。该软件包可扩展至任意晶格几何和自定义可观测值，并支持X和Z基下的快照提取。

Result: ParaToric软件包能够模拟平行磁场下的toric code，并支持多种晶格结构、边界条件和自定义可观测值。其快照提取功能可为其他研究方法提供数据支持。

Conclusion: ParaToric软件包为在平行磁场下模拟toric code提供了一个强大且可扩展的工具，适用于多种研究领域，并且易于与其他软件项目集成。

Abstract: We introduce ParaToric, a C++ package for simulating the toric code in a
parallel field (i.e., $X$- and $Z$-fields) at finite temperature. We implement
and extend the continuous-time quantum Monte Carlo algorithm of Wu, Deng, and
Prokof'ev on the square, triangular, honeycomb, and cubic lattices with open
and periodic boundaries, respectively. The package is expandable to arbitrary
lattice geometries and custom observables diagonal in either the $X$- or
$Z$-basis. ParaToric also supports snapshot extraction in both bases, making it
ideal for generating training/benchmarking data for other methods, such as
lattice gauge theories, cold atom or other quantum simulators, quantum spin
liquids, artificial intelligence, and quantum error correction. The software
provides bindings to C/C++ and Python, and is thus almost universally
integrable into other software projects.

</details>


### [477] [Efficient adaptive control strategy for multi-parameter quantum metrology in two-dimensional systems](https://arxiv.org/abs/2510.14811)
*Qifei Wei,Shengshi Pang*

Main category: quant-ph

TL;DR: 本研究提出了一种用于二维系统的多参数量子计量自适应控制策略，通过系统扩展和重新参数化技术，实现了接近最优的估计精度，并对控制参数误差具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 填补了多参数量子计量中自适应控制策略研究的空白。

Method: 提出了一种高效的自适应控制策略，通过系统扩展消除最优测量、初始状态和控制哈密顿量之间的权衡，推导出估计量方差与演化时间的明确关系，并利用重新参数化技术优化演化时间，建立了表征精度改进的递归关系。

Result: 所提出的策略在几次迭代内即可达到接近最优的性能（仅相差一个常数因子），并且对个体迭代中控制参数误差的偏差表现出很强的鲁棒性。该策略对于任意参数依赖性的哈密顿量也同样有效。

Conclusion: 该研究为现实场景下具有自适应哈密顿量控制的多参数量子计量提供了一种实用的方法。

Abstract: Quantum metrology leverages quantum resources such as entanglement and
squeezing to enhance parameter estimation precision beyond classical limits.
While optimal quantum control strategies can assist to reach or even surpass
the Heisenberg limit, their practical implementation often requires the
knowledge of the parameters to be estimated, necessitating adaptive control
methods with feedback. Such adaptive control methods have been considered in
single-parameter quantum metrology, but not much in multi-parameter quantum
metrology so far. In this work, we bridge this gap by proposing an efficient
adaptive control strategy for multi-parameter quantum metrology in
two-dimensional systems. By eliminating the trade-offs among optimal
measurements, initial states, and control Hamiltonians through a system
extension scheme, we derive an explicit relation between the estimator variance
and evolution time. Through a reparameterization technique, the optimization of
evolution times in adaptive iterations are obtained, and a recursive relation
is established to characterize the precision improvement across the iterations.
The proposed strategy achieves the optimal performance up to an overall factor
of constant order with only a few iterations and demonstrates strong robustness
against deviations in the errors of control parameters at individual
iterations. Further analysis shows the effectiveness of this strategy for
Hamiltonians with arbitrary parameter dependence. This work provides a
practical approach for multi-parameter quantum metrology with adaptive
Hamiltonian control in realistic scenarios.

</details>


### [478] [Signatures of Topological Symmetries on a Noisy Quantum Simulator](https://arxiv.org/abs/2510.14817)
*Christopher Lamb,Robert M. Konik,Hubert Saleur,Ananda Roy*

Main category: quant-ph

TL;DR: IBM的量子模拟器被用于在物理系统中实现二维Ising量子场论的拓扑对称性。


<details>
  <summary>Details</summary>
Motivation: 尽管拓扑对称性在量子场论中至关重要，但在物理系统中对其进行精确实现却很困难。本研究旨在利用量子模拟器来克服这一挑战。

Method: 使用混合量子-经典算法（基于量子近似优化算法和量子自然梯度优化）在IBM的Kingston模拟器上实现了Ising量子场论的拓扑对称性相关的本征态和环算符。

Result: 通过测量量子比特算符的关联函数，获得了与经典计算结果在合理范围内一致的实验数据，证明了拓扑对称性的存在。

Conclusion: 该研究证明了嘈杂的量子模拟器是研究低维量子场论的可行平台，并可以直接探测到传统凝聚态物理实验中难以测量的观测量。

Abstract: Topological symmetries, invertible and otherwise, play a fundamental role in
the investigation of quantum field theories. Despite their ubiquitous
importance across a multitude of disciplines ranging from string theory to
condensed matter physics, controlled realizations of models exhibiting these
symmetries in physical systems are rare. Quantum simulators based on engineered
solid-state devices provide a novel alternative to conventional condensed
matter systems for realizing these models.
  In this work, eigenstates of impurity Hamiltonians and loop operators
associated with the topological symmetries for the Ising conformal field theory
in two space-time dimensions are realized on IBM's Kingston simulator. The
relevant states are created on the quantum device using a hybrid
quantum-classical algorithm. The latter is based on a variation of the quantum
approximate optimization algorithm ansatz combined with the quantum natural
gradient optimization method. Signatures of the topological symmetry are
captured by measuring correlation functions of different qubit operators with
results obtained from the quantum device in reasonable agreement with those
obtained from classical computations. The current work demonstrates the
viability of noisy quantum simulators as platforms for investigating
low-dimensional quantum field theories with direct access to observables that
are often difficult to probe in conventional condensed matter experiments.

</details>


### [479] [Ruelle-Pollicott Decay of Out-of-Time-Order Correlators in Many-Body Systems](https://arxiv.org/abs/2510.14886)
*Jerónimo Duarte,Ignacio García-Mata,Diego A. Wisniacki*

Main category: quant-ph

TL;DR: 量子系统的OTOC（out-of-time-order correlator）衡量信息 the scrambling，并作为量子混沌的关键诊断。对于具有经典对应体的一体系统，OTOC的弛豫由Ruelle-Pollicott共振决定。对于缺乏半经典极限的多数体系统，最近的研究发现，动力学的弱开放扩展的Liouvillian谱扮演着类似的角色，其中最慢的衰减率——Liouvillian gap——编码了弛豫。本研究探讨了踢打伊辛自旋链，并表明OTOC在孤立系统中的长期指数衰减发生在等于该内在间隙两倍的速率下。这种对应关系甚至在可积性与混沌之间的交叉区域中也持续存在，证明了Liouvillian谱为理解闭合多数体量子系统中的弛豫和不可逆性提供了一个统一的框架。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统中的信息 the scrambling 和量子混沌，特别是对于缺乏半经典极限的多数体系统，并提出 Liouvillian 谱在描述弛豫和不可逆性中的作用。

Method: 研究踢打伊辛自旋链，并比较 OTOC 的长期指数衰减率与 Liouvillian 谱的 Liouvillian 间隙。

Result: 发现 OTOC 的长期指数衰减率等于 Liouvillian 间隙的两倍，即使在可积性与混沌的交叉区域也是如此。

Conclusion: Liouvillian 谱为理解闭合多数体量子系统中的弛豫和不可逆性提供了一个统一的框架。

Abstract: The out-of-time-order correlator (OTOC) quantifies information scrambling in
quantum systems and serves as a key diagnostic of quantum chaos. In one-body
systems with a classical counterpart, the relaxation of the OTOC is governed by
Ruelle-Pollicott resonances. For many-body systems lacking a semiclassical
limit, recent studies have identified an analogous role played by the
Liouvillian spectrum of weakly open extensions of the dynamics, where the
slowest decay rate -- the Liouvillian gap -- encodes relaxation. Here we study
the kicked Ising spin chain and show that the long-time exponential decay of
the OTOC in the isolated system occurs at a rate equal to twice this intrinsic
gap. This correspondence persists even in crossover regimes between
integrability and chaos, demonstrating that the Liouvillian spectrum provides a
unified framework for understanding relaxation and irreversibility in closed
many-body quantum systems.

</details>


### [480] [Fast and fault-tolerant logical measurements: Auxiliary hypergraphs and transversal surgery](https://arxiv.org/abs/2510.14895)
*Alexander Cowtan,Zhiyang He,Dominic J. Williamson,Theodore J. Yoder*

Main category: quant-ph

TL;DR: 该研究提出了一种通用条件，可以在恒定时间开销下实现容错量子码手术，并引入了块读取方案以实现跨多个码块的横向手术。研究还探讨了具有中间时间开销的手术操作，并建立了同态测量与超图手术之间的电路等价性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是减少量子码手术的时间开销，因为现有的通用手术操作需要大量的重复综合提取才能实现容错。

Method: 该研究提出了一组通用条件，以实现恒定时间开销下的容错手术，并引入了块读取方案。此外，还研究了具有中间时间开销的手术操作，并建立了同态测量与超图手术之间的电路等价性。

Result: 研究表明，通过满足特定条件，量子码手术可以在恒定时间开销下实现容错。块读取方案实现了跨多个码块的横向手术，并对具有中间时间开销的手术操作进行了研究。此外，还发现了同态测量与超图手术之间的电路等价性。

Conclusion: 研究结论是，减少量子码手术的时间成本并不需要单次量子内存，而是主要取决于码与其测量辅助系统之间的连接性，这决定了可实现的测量时间开销。

Abstract: Quantum code surgery is a promising technique to perform fault-tolerant
computation on quantum low-density parity-check codes. Recent developments have
significantly reduced the space overhead of surgery. However, generic surgery
operations still require $O(d)$ rounds of repeated syndrome extraction to be
made fault-tolerant. In this work, we focus on reducing the time overhead of
surgery. We first present a general set of conditions that ensure
fault-tolerant surgery operations can be performed with constant time overhead.
This fast surgery necessarily makes use of an auxiliary complex described by a
hypergraph rather than a graph. We then introduce a concrete scheme called
block reading, which performs transversal surgery across multiple code blocks.
We further investigate surgery operations with intermediate time overhead,
between $O(1)$ and $O(d)$, which apply to quantum locally testable codes.
Finally, we establish a circuit equivalence between homomorphic measurement and
hypergraph surgery and derive bounds on the time overhead of generic logical
measurement schemes. Overall, our results demonstrate that reducing the time
cost of code surgery is not reliant on the quantum memory being single-shot.
Instead it is chiefly the connectivity between a code and its measurement
ancilla system that determines the achievable measurement time overhead.

</details>


### [481] [Forecasting Quantum Observables: A Compressed Sensing Approach with Performance Guarantees](https://arxiv.org/abs/2510.14897)
*Víctor Valls,Albert Akhriev,Olatz Sanz Larrarte,Javier Oliva del Moral,Štěpán Šmíd,Josu Etxezarreta Martinez,Sergiy Zhuk,Dmytro Mishagli*

Main category: quant-ph

TL;DR: 通过引入原子范数最小化框架，可以认证学习到的模型是否准确捕捉了量子可观测量的动力学。该方法在系统由少量 잘 분리된 Bohr 주파수에 의해 지배될 때 유효하며, 수치 실험을 통해 검증되었습니다.


<details>
  <summary>Details</summary>
Motivation: 近期的量子设备中的噪声限制了可可靠获得测量的时标。现有的数据驱动外推方法虽然可以从测量中恢复量子可观测量的动力学模型，但无法保证恢复的模型能够准确反映真实的动力学。

Method: 提出原子范数最小化作为一种框架，用于认证任何算法学习到的模型是否准确捕捉了量子可观测量的潜在动力学。当系统由少量 잘 분리된 Bohr 주파수에 의해 지배될 때 이 인증은 유효합니다.

Result: 在涉及 8-20 个量子比特的自旋链哈密顿量的数值实验中，与精确对角化相比，该认证方法在 98% 的情况下产生了低于 0.1 的平均预测误差（在可观测量的 [-1, 1] 范围内），在 89-97% 的情况下产生了低于 0.05 的平均预测误差。即使存在实际的测量噪声，认证模型也保持稳健，对于 0.1 的误差阈值，成功率仅下降到 88-95%。

Conclusion: 原子范数最小化为量子动力学模型提供了一种可行的认证方法，即使在存在噪声的情况下也能确保模型的准确性。

Abstract: Noise in near-term quantum devices limits the timescales over which
measurements can be reliably obtained. Existing data-driven extrapolation
methods extend the dynamics of quantum observables from measurements, but they
cannot guarantee that the recovered model reflects the true dynamics. In this
paper, we introduce atomic norm minimization as a framework to certify that a
model learned by any algorithm accurately captures the underlying dynamics of
quantum observables. This certification is valid when the system is governed by
a small number of well-separated Bohr frequencies. We validate the framework
across multiple algorithms on numerical experiments with spin-chain
Hamiltonians involving 8-20 qubits. Comparing with exact diagonalization,
certification yields an average forecasting error below 0.1 (within the
observable's range of $[-1, 1]$) in 98% of cases and below 0.05 in 89-97% of
cases, depending on the forecasting algorithm. Even in the presence of
realistic shot noise, certified models remain robust, with success rates
decreasing only to 88-95% for the 0.1 error threshold.

</details>


### [482] [Continuous-time quantum walk on a random graph using quantum circuits](https://arxiv.org/abs/2510.14905)
*Sabyasachi Chakraborty,Rohit Sarma Sarkar,Sonjoy Majumder,Rohit Kishan Ray*

Main category: quant-ph

TL;DR: 该工作提出了一种可扩展的量子线路方法来模拟随机图（特别是Erdos-Renyi随机图）上的连续时间量子行走（CTQW），并研究了其局域化行为。


<details>
  <summary>Details</summary>
Motivation: 量子行走，特别是CTQW，在模拟量子输运、复杂动力学和开发量子算法方面显示出巨大潜力。

Method: 提出了一种可扩展的量子线路方法，利用Trotter化方案实现图拉普拉斯的时间演化，以模拟CTQW在Erdos-Renyi随机图上的演化。

Result: 实现了CTQW在随机图上的模拟，并能够研究其关键动力学特性，如局域化行为。所提出的量子线路设计适用于任何图结构。

Conclusion: 该工作为实现高效的基于CTQW的量子模拟奠定了基础，其量子线路方法具有通用性，可应用于各种图结构。

Abstract: Quantum walks, particularly continuous-time quantum walks (CTQW), have
emerged as powerful tools for modeling quantum transport, simulating complex
dynamics, and developing quantum algorithms with potential speedups over
classical counterparts. In this work, we present a scalable quantum circuit
formalism to simulate CTQW on random graph structures, especially focusing on
Erd\H{o}s-R\'enyi random graphs. Our quantum circuit construction efficiently
implements the time evolution of the graph Laplacian, using the Trotterization
scheme. We investigate key dynamical properties, \emph{i.e.,} the localization
behavior of the CTQW. Our quantum circuit implementation over random graph
ensures that the circuit design can work on any graph structure, thereby laying
the foundation for realizing CTQW-based quantum simulations efficiently.

</details>


### [483] [Decoherence-Aware Entangling and Swapping Strategy Optimization for Entanglement Routing in Quantum Networks](https://arxiv.org/abs/2510.14912)
*Shao-Min Huang,Cheng-Yang Cheng,Ming-Huang Chien,Jian-Jhih Kuo,Chih-Yu Wang*

Main category: quant-ph

TL;DR: 量子隐形传态通过端到端量子纠缠对实现高安全性通信，但纠缠对的退相干和交换过程会降低保真度。该研究提出了一个短时隙协议和两种优化算法来解决此问题，显著提高了保真度。


<details>
  <summary>Details</summary>
Motivation: 量子隐形传态是实现高安全性通信的关键，但端到端纠缠对的保真度会受到环境干扰和交换过程的负面影响。

Method: 提出了一个短时隙协议，并设计了两种新颖的算法来解决最大化所有可接受请求的总保真度的优化问题TETRIS。

Result: 模拟结果表明，该方法在一般情况下比现有方法高出60-78%，在纠缠概率较低时也高出20-75%。

Conclusion: 所提出的短时隙协议和优化算法能够有效提高量子隐形传态中纠缠对的保真度，克服了传统协议的限制。

Abstract: Quantum teleportation enables high-security communications through end-to-end
quantum entangled pairs. End-to-end entangled pairs are created by using
swapping processes to consume short entangled pairs and generate long pairs.
However, due to environmental interference, entangled pairs decohere over time,
resulting in low fidelity. Thus, generating entangled pairs at the right time
is crucial. Moreover, the swapping process also causes additional fidelity
loss. To this end, this paper presents a short time slot protocol, where a time
slot can only accommodate a process. It has a more flexible arrangement of
entangling and swapping processes than the traditional long time slot protocol.
It raises a new optimization problem TETRIS for finding strategies of
entangling and swapping for each request to maximize the fidelity sum of all
accepted requests. To solve the TETRIS, we design two novel algorithms with
different optimization techniques. Finally, the simulation results manifest
that our algorithms can outperform the existing methods by up to 60 ~ 78% in
general, and by 20 ~ 75% even under low entangling probabilities.

</details>


### [484] [Current fluctuations in nonequilibrium open quantum systems beyond weak coupling: a reaction coordinate approach](https://arxiv.org/abs/2510.14926)
*Khalak Mahadeviya,Saulo V. Moreira,Sheikh Parvez Mandal,Mahasweta Pandit,Javier Prior,Mark T. Mitchison*

Main category: quant-ph

TL;DR: 本研究探讨了强耦合下开放量子系统中的电流涨落，发现了低于经典热力学不确定性边界的噪声抑制现象，并将其归因于反应坐标模式的非经典特性。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统中的电流涨落通常在弱耦合和马尔可夫近似下进行研究，本研究旨在突破这些限制，探索强耦合和非马尔可夫等更普遍情况下的电流涨落行为。

Method: 结合全计数统计和反应坐标映射方法，开发了一个能够计算稳态电流涨落及其时间关联的框架，特别适用于强耦合情况。

Result: 研究发现，平均电流和涨落都随着系统-环境相互作用强度的增加呈现非单调变化。在强耦合下，电流噪声可以被抑制到低于经典热力学不确定性边界，并且与量子跳变轨迹中的反关联增强和系统弛豫加速相关。这些现象与反应坐标模式的非高斯性和量子相干性等非经典特性有关。

Conclusion: 本研究为在超越弱耦合范式的量子器件中控制电流涨落提供了新的见解和设计原理。

Abstract: We investigate current fluctuations in open quantum systems beyond the
weak-coupling and Markovian regimes, focusing on a coherently driven qubit
strongly coupled to a structured bosonic environment. By combining full
counting statistics with the reaction coordinate mapping, we develop a
framework that enables the calculation of steady-state current fluctuations and
their temporal correlations in the strong-coupling regime. Our analysis reveals
that, unlike in weak coupling, both the average current and its fluctuations
exhibit nonmonotonic dependence on the system-environment interaction strength.
Notably, we identify a regime where current noise is suppressed below the
classical thermodynamic uncertainty bound, coinciding with enhanced
anticorrelations in quantum jump trajectories and faster system relaxation. We
further show that these features are linked to nonclassical properties of the
reaction coordinate mode, such as non-Gaussianity and quantum coherence. Our
results provide new insights and design principles for controlling current
fluctuations in quantum devices operating beyond the standard weak-coupling
paradigm.

</details>


### [485] [Orders matter: tight bounds on the precision of sequential quantum estimation for multiparameter models](https://arxiv.org/abs/2510.14963)
*Gabriele Fazio,Jiayu He,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 逐步估计策略在量子计量中可以优于联合估计，尤其是在资源有限或实验条件不理想的情况下。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨和分析一种替代性的多参数量子计量方法——逐步估计策略，并将其与传统的联合估计策略进行比较。

Method: 推导了逐步估计策略的精度界限（逐步可分离界限）及其解析表达式，并分析了测量顺序对精度的影响。通过分析SU(2)酉编码模型，对比了逐步估计和联合测量的性能。

Result: 逐步估计策略可以提供比联合测量更优越的精度，特别是在使用非最优探针或模型“sloppy”的情况下。给出了逐步估计优于联合估计的解析条件。

Conclusion: 逐步估计是一种有效的量子计量方法，可以提供真实的计量优势，尤其适用于资源受限或存在不完美的实验环境。

Abstract: In multiparameter quantum metrology, the ultimate precision of joint
estimation is dictated by the Holevo Cram\'er-Rao bound. In this paper, we
discuss and analyze in detail an alternative approach: the stepwise estimation
strategy. In this approach, parameters are estimated sequentially, using an
optimized fraction of the total available resources allocated to each step. We
derive a tight and achievable precision bound for this protocol, the stepwise
separable bound, and provide its closed-form analytical expression, revealing a
crucial dependence on the chosen measurement ordering. We provide a rigorous
comparison with the joint measurement strategy, deriving analytical conditions
that determine when the stepwise approach offers superior precision. Through
the analysis of several paradigmatic SU(2) unitary encoding models, we
demonstrate that the stepwise strategy can indeed outperform joint
measurements, particularly in scenarios characterized by non-optimal probes or
models with a high degree of sloppiness. Our findings establish stepwise
estimation as a powerful alternative to joint and collective measurements,
proving that sequential protocols can provide a genuine metrological advantage,
especially in resource-constrained or imperfect experimental settings.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [486] [Why Instant-Runoff Voting Is So Resilient to Coalitional Manipulation: Phase Transitions in the Perturbed Culture](https://arxiv.org/abs/2510.14450)
*François Durand*

Main category: cs.GT

TL;DR: IRV、复选投票制和多轮投票制在受扰文化模型中对联合操纵的易感性不同，IRV 对联合操淆的抵抗力源于超级温和获胜者的存在。


<details>
  <summary>Details</summary>
Motivation: 分析三种主要投票规则（多轮投票制、两轮制和即时决选投票制）在受扰文化模型中对联合操纵的易感性，以阐明即时决选投票制抵抗联合操纵的理论原因。

Method: 在受扰文化模型中分析了多轮投票制、两轮制和即时决选投票制对联合操纵的易感性。引入了超级温和获胜者（SCW）的概念，并证明其存在是即时决选投票制抵抗联合操纵的关键。

Result: 每种投票规则在浓度阈值 θc 处都会出现阶段性转变，低于该阈值时联合操纵的概率趋于 1，高于该阈值时趋于 0。对于即时决选投票制，θc = 0，意味着即使在最小的偏好集中，它也能抵抗联合操纵。

Conclusion: 超级温和获胜者的存在是即时决选投票制抵抗联合操纵的关键，这使得即时决选投票制在偏好集中度方面具有很强的鲁棒性。

Abstract: Previous studies have shown that Instant-Runoff Voting (IRV) is highly
resistant to coalitional manipulation (CM), though the theoretical reasons for
this remain unclear. To address this gap, we analyze the susceptibility to CM
of three major voting rules-Plurality, Two-Round System, and IRV-within the
Perturbed Culture model. Our findings reveal that each rule undergoes a phase
transition at a critical value theta\_c of the concentration of preferences:
the probability of CM for large electorates converges exponentially fast to 1
below theta\_c and to 0 above theta\_c. We introduce the Super Condorcet Winner
(SCW), showing that its presence is a key factor of IRV's resistance to
coalitional manipulation, both theoretically and empirically. Notably, we use
this notion to prove that for IRV, theta\_c = 0, making it resistant to CM with
even minimal preference concentration.

</details>


### [487] [Co-Investment under Revenue Uncertainty Based on Stochastic Coalitional Game Theory](https://arxiv.org/abs/2510.14555)
*Amal Sakr,Andrea Araldo,Tijani Chahed,Daniel Kofman*

Main category: cs.GT

TL;DR: 提出了一种新的随机博弈模型，用于解决移动边缘计算（MEC）部署中多个利益相关者（基础设施提供商和)_服务提供商）的成本和收益共享问题，并推导了“大联盟”稳定性的概率下界。


<details>
  <summary>Details</summary>
Motivation: 单个利益相关者（如基础设施提供商）无法承担移动边缘计算（MEC）等新服务的巨额投资，而服务提供商也希望部署这些服务，因此需要一个多方参与的共投方案。

Method: 提出了一种新颖的随机博弈模型，该模型基于鲁棒博弈论，并推导了“大联盟”（包含所有利益相关者）稳定性的概率下界。在某些相关收入波动的情况下，还考虑了盈利能力（参与者的收益为非负）作为共投的必要条件。

Result: 数值结果表明，当服务提供商的收入规模相似且投资期足够长时，即使在高度不确定的情况下，“大联盟”的稳定性概率下界也很高。然而，在收入高度可变的情况下，稳定性概率下界可能很低，但共投仍然有利可图。

Conclusion: 提出的随机博弈框架能够评估 MEC 部署中多方共投方案的稳定性和盈利能力，并为不同收入和不确定性场景下的决策提供了指导。

Abstract: The introduction of new services, such as Mobile Edge Computing (MEC),
requires a massive investment that cannot be assumed by a single stakeholder,
for instance the Infrastructure Provider (InP). Service Providers (SPs) however
also have an interest in the deployment of such services. We hence propose a
co-investment scheme in which all stakeholders, i.e., the InP and the SPs, form
the so-called grand coalition composed of all the stakeholders with the aim of
sharing costs and revenues and maximizing their payoffs. The challenge comes
from the fact that future revenues are uncertain. We devise in this case a
novel stochastic coalitional game formulation which builds upon robust game
theory and derive a lower bound on the probability of the stability of the
grand coalition, wherein no player can be better off outside of it. In the
presence of some correlated fluctuations of revenues however, stability can be
too conservative. In this case, we make use also of profitability, in which
payoffs of players are non-negative, as a necessary condition for
co-investment. The proposed framework is showcased for MEC deployment, where
computational resources need to be deployed in nodes at the edge of a
telecommunication network. Numerical results show high lower bound on the
probability of stability when the SPs' revenues are of similar magnitude and
the investment period is sufficiently long, even with high levels of
uncertainty. In the case where revenues are highly variable however, the lower
bound on stability can be trivially low whereas co-investment is still
profitable.

</details>


### [488] [The Bidding Games: Reinforcement Learning for MEV Extraction on Polygon Blockchain](https://arxiv.org/abs/2510.14642)
*Andrei Seoev,Leonid Gremyachikh,Anastasiia Smirnova,Yash Madhwal,Alisa Kalacheva,Dmitry Belousov,Ilia Zubov,Aleksei Smirnov,Denis Fedyanin,Vladimir Gorgadze,Yury Yanovich*

Main category: cs.GT

TL;DR: 本研究提出了一种基于强化学习的MEV提取框架，用于在Polygon Atlas等高频拍卖机制中优化竞标策略，并在模拟和实际部署中均取得了显著的利润增长。


<details>
  <summary>Details</summary>
Motivation: 在区块链网络中，交易排序（MEV）成为利润提取的重要途径。Polygon Atlas等结构化拍卖机制将MEV提取从公开竞价转变为高时限的密封竞标，带来了新的战略挑战，传统博弈论方法难以应对。

Method: 开发了一个包含随机机会到来和概率性竞争的模拟环境，并训练了一个基于PPO的竞标代理，该代理能在连续动作空间中适应性地制定策略，并保持快速推理速度。

Result: 在与现有搜索者一同部署时，该代理捕获了49%的可用利润；在取代市场领导者时，捕获了81%的利润，显著优于静态竞标策略。

Conclusion: 强化学习在高频MEV环境中具有明显优势，能够克服传统优化方法的局限性，为行业参与者和协议设计者提供即时价值。

Abstract: In blockchain networks, the strategic ordering of transactions within blocks
has emerged as a significant source of profit extraction, known as Maximal
Extractable Value (MEV). The transition from spam-based Priority Gas Auctions
to structured auction mechanisms like Polygon Atlas has transformed MEV
extraction from public bidding wars into sealed-bid competitions under extreme
time constraints. While this shift reduces network congestion, it introduces
complex strategic challenges where searchers must make optimal bidding
decisions within a sub-second window without knowledge of competitor behavior
or presence. Traditional game-theoretic approaches struggle in this
high-frequency, partially observable environment due to their reliance on
complete information and static equilibrium assumptions. We present a
reinforcement learning framework for MEV extraction on Polygon Atlas and make
three contributions: (1) A novel simulation environment that accurately models
the stochastic arrival of arbitrage opportunities and probabilistic competition
in Atlas auctions; (2) A PPO-based bidding agent optimized for real-time
constraints, capable of adaptive strategy formulation in continuous action
spaces while maintaining production-ready inference speeds; (3) Empirical
validation demonstrating our history-conditioned agent captures 49\% of
available profits when deployed alongside existing searchers and 81\% when
replacing the market leader, significantly outperforming static bidding
strategies. Our work establishes that reinforcement learning provides a
critical advantage in high-frequency MEV environments where traditional
optimization methods fail, offering immediate value for industrial participants
and protocol designers alike.

</details>


### [489] [Online Proportional Apportionment](https://arxiv.org/abs/2510.14752)
*Javier Cembrano,Jose Correa,Svenja M. Griesbach,Victor Verdugo*

Main category: cs.GT

TL;DR: 本文研究了在无未来信息的情况下，如何在线动态地分配议会席位，以确保各政党获得的席位与其得票份额尽可能接近。


<details>
  <summary>Details</summary>
Motivation: 传统议会席位分配方法未考虑动态因素，而许多实际情况需要动态考量，因此本文旨在研究在线情境下的席位分配问题。

Method: 本文提出了一个在线比例分配框架，并研究了确定性和随机性分配方法。对于确定性方法，构建了实例以证明席位分配与累积份额之间存在线性下界，并提出了一个贪心算法来匹配该下界。对于随机性方法，证明了当政党数量n≤3时，存在一种随机化方法，可以保证各政党在期望上获得与其份额成比例的席位。

Result: 对于确定性方法，证明了席位分配与累积份额之间存在线性下界，且该下界可以通过贪心算法达到。对于n≤3的政党数量，存在一种随机化方法，可以满足全局配额要求，并且各政党在期望上获得与其份额成比例的席位。

Conclusion: 本文成功地将在线学习的思想引入了议会席位分配问题，并为确定性和随机性分配方法提供了理论界限和具体算法。研究结果表明，在n≤3的情况下，可以实现更精确的席位分配。此外，该研究还为在线依赖性舍入过程提供了近似解决方案。

Abstract: Traditionally, the problem of apportioning the seats of a legislative body
has been viewed as a one-shot process with no dynamic considerations. While
this approach is reasonable for some settings, dynamic aspects play an
important role in many others. We initiate the study of apportionment problems
in an online setting. Specifically, we introduce a framework for proportional
apportionment with no information about the future. In this model, time is
discrete and there are $n$ parties that receive a certain share of the votes at
each time step. An online algorithm needs to irrevocably assign a prescribed
number of seats at each time, ensuring that each party receives its fractional
share rounded up or down, and that the cumulative number of seats allocated to
each party remains close to its cumulative share up to that time.
  We study deterministic and randomized online apportionment methods. For
deterministic methods, we construct a family of adversarial instances that
yield a lower bound, linear in $n$, on the worst-case deviation between the
seats allocated to a party and its cumulative share. We show that this bound is
best possible and is matched by a natural greedy method. As a consequence, a
method guaranteeing that the cumulative number of seats assigned to each party
up to any step equals its cumulative share rounded up or down (global quota)
exists if and only if $n\leq 3$. Then, we turn to randomized allocations and
show that, for $n\leq 3$, we can randomize over methods satisfying global quota
with the additional guarantee that each party receives, in expectation, its
proportional share in every step. Our proof is constructive: Any method
satisfying these properties can be obtained from a flow on a recursively
constructed network. We showcase the applicability of our results to obtain
approximate solutions in the context of online dependent rounding procedures.

</details>


### [490] [Learnable Mixed Nash Equilibria are Collectively Rational](https://arxiv.org/abs/2510.14907)
*Geelon So,Yi-An Ma*

Main category: cs.GT

TL;DR: 当博弈中的混合纳什均衡不稳定时，它通常不是帕累托最优的，反之亦然。


<details>
  <summary>Details</summary>
Motivation: 研究在非渐近稳定动态下学习博弈，并将其与个体效用最大化动态的均衡联系起来。

Method: 引入“均匀稳定”的概念，研究其与集体理性经济特性的关系，并分析其对增量平滑最佳响应动态的最后迭代收敛行为的影响。

Result: 发现均匀稳定性与帕累托最优性密切相关：不均匀稳定的混合均衡不是弱帕累托最优的，而局部均匀稳定的混合均衡是弱帕累托最优的。此外，均匀稳定性决定了增量平滑最佳响应动态的最后迭代收敛行为。

Conclusion: 个体效用最大化行为在混合纳什均衡附近会导致集体理性，这与严格均衡周围可能导致社会效率低下解决方案的动态不同。

Abstract: We extend the study of learning in games to dynamics that exhibit
non-asymptotic stability. We do so through the notion of uniform stability,
which is concerned with equilibria of individually utility-seeking dynamics.
Perhaps surprisingly, it turns out to be closely connected to economic
properties of collective rationality. Under mild non-degeneracy conditions and
up to strategic equivalence, if a mixed equilibrium is not uniformly stable,
then it is not weakly Pareto optimal: there is a way for all players to improve
by jointly deviating from the equilibrium. On the other hand, if it is locally
uniformly stable, then the equilibrium must be weakly Pareto optimal. Moreover,
we show that uniform stability determines the last-iterate convergence behavior
for the family of incremental smoothed best-response dynamics, used to model
individual and corporate behaviors in the markets. Unlike dynamics around
strict equilibria, which can stabilize to socially-inefficient solutions,
individually utility-seeking behaviors near mixed Nash equilibria lead to
collective rationality.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [491] [DIAMOND: Systolic Array Acceleration of Sparse Matrix Multiplication for Quantum Simulation](https://arxiv.org/abs/2510.14172)
*Yuchao Su,Srikar Chundury,Jiajia Li,Frank Mueller*

Main category: cs.AR

TL;DR: 该论文提出了名为“\name”的加速器，这是第一个针对量子模拟中常见的对角稀疏性进行优化的加速器。


<details>
  <summary>Details</summary>
Motivation: 汉密尔顿模拟在量子计算中至关重要，但由于希尔伯特空间维度的指数增长，计算成本高昂。现有的加速器主要针对机器学习工作负载，不适用于汉密尔顿模拟的稀疏性模式。

Method: \name 采用重构的 systolic array 数据流，将对角稀疏矩阵转化为密集计算，从而实现高利用率和高性能。

Result: 与 SIGMA、Outer Product 和 Gustavson 算法相比，\name 的平均性能分别提高了 10.26 倍、33.58 倍和 53.15 倍，峰值加速可达 127.03 倍。同时，与 SIGMA 相比，能耗平均降低了 471.55 倍，最高可达 4630.58 倍。

Conclusion: \name 通过优化对角稀疏性，显著提高了经典汉密尔顿模拟的性能和能效，克服了现有加速器的局限性。

Abstract: Hamiltonian simulation is a key workload in quantum computing, enabling the
study of complex quantum systems and serving as a critical tool for classical
verification of quantum devices. However, it is computationally challenging
because the Hilbert space dimension grows exponentially with the number of
qubits. The growing dimensions make matrix exponentiation, the key kernel in
Hamiltonian simulations, increasingly expensive. Matrix exponentiation is
typically approximated by the Taylor series, which contains a series of matrix
multiplications. Since Hermitian operators are often sparse, sparse matrix
multiplication accelerators are essential for improving the scalability of
classical Hamiltonian simulation. Yet, existing accelerators are primarily
designed for machine learning workloads and tuned to their characteristic
sparsity patterns, which differ fundamentally from those in Hamiltonian
simulations that are often dominated by structured diagonals.
  In this work, we present \name, the first diagonal-optimized quantum
simulation accelerator. It exploits the diagonal structure commonly found in
problem-Hamiltonian (Hermitian) matrices and leverages a restructured systolic
array dataflow to transform diagonally sparse matrices into dense computations,
enabling high utilization and performance. Through detailed cycle-level
simulation of diverse benchmarks in HamLib, \name{} demonstrates average
performance improvements of $10.26\times$, $33.58\times$, and $53.15\times$
over SIGMA, Outer Product, and Gustavson's algorithm, respectively, with peak
speedups up to $127.03\times$ while reducing energy consumption by an average
of $471.55\times$ and up to $4630.58\times$ compared to SIGMA.

</details>


### [492] [Computing-In-Memory Aware Model Adaption For Edge Devices](https://arxiv.org/abs/2510.14379)
*Ming-Han Lin,Tian-Sheuan Chang*

Main category: cs.AR

TL;DR: 该研究提出了一种两阶段的计算内存（CIM）模型自适应方法，通过模型压缩、资源重分配和量化感知训练来解决 CIM 宏尺寸和 ADC 精度限制带来的瓶颈，实现了高 CIM 利用率、并发激活和模型压缩，同时保持了原有精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习加速中计算内存（CIM）宏尺寸有限和 ADC 精度不足导致的吞吐量和准确性瓶颈问题。

Method: 提出了一种两阶段的 CIM 感知模型自适应过程：第一阶段根据层重要性和宏尺寸限制进行模型压缩和资源重分配；第二阶段进行量化感知训练，考虑部分和量化及 ADC 精度以减小量化误差。

Result: CIM 阵列利用率提升至 90%，最多可同时激活 256 条字线，模型压缩率高达 93%，同时保持了与先前方法相当的准确性。

Conclusion: 所提出的 CIM 感知模型自适应方法有效地解决了 CIM 硬件限制带来的挑战，在提高硬件利用率和模型压缩率的同时，保证了模型的准确性。

Abstract: Computing-in-Memory (CIM) macros have gained popularity for deep learning
acceleration due to their highly parallel computation and low power
consumption. However, limited macro size and ADC precision introduce throughput
and accuracy bottlenecks. This paper proposes a two-stage CIM-aware model
adaptation process. The first stage compresses the model and reallocates
resources based on layer importance and macro size constraints, reducing model
weight loading latency while improving resource utilization and maintaining
accuracy. The second stage performs quantization-aware training, incorporating
partial sum quantization and ADC precision to mitigate quantization errors in
inference. The proposed approach enhances CIM array utilization to 90\%,
enables concurrent activation of up to 256 word lines, and achieves up to 93\%
compression, all while preserving accuracy comparable to previous methods.

</details>


### [493] [Low Power Vision Transformer Accelerator with Hardware-Aware Pruning and Optimized Dataflow](https://arxiv.org/abs/2510.14393)
*Ching-Lin Hsiung,Tian-Sheuan Chang*

Main category: cs.AR

TL;DR: 通过硬件友好的动态令牌修剪、ReLU激活和动态FFN2修剪来优化低功耗视觉Transformer加速器，在性能损失很小的情况下显著减少了计算量和权重。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer加速器主要关注自注意力机制，但对于短令牌长度的视觉Transformer来说，前馈网络（FFN）是主要的计算瓶颈。因此，需要一种针对FFN进行优化的低功耗视觉Transformer加速器。

Method: 提出了一种低功耗视觉Transformer加速器，通过算法-硬件协同设计进行优化。模型复杂度通过硬件友好的动态令牌修剪来降低。通过用ReLU替换GELU激活函数和采用动态FFN2修剪来进一步提高稀疏性。硬件采用行式数据流和面向输出的数据访问，以消除数据转置，并支持具有最小面积开销的动态操作。

Result: 该设计在TSMC的28nm CMOS技术下实现，占用496.4K门，包含232KB SRAM，峰值吞吐量为1024 GOPS（1GHz），能效为2.31 TOPS/W，面积效率为858.61 GOPS/mm²。与基线模型相比，运算量减少了61.5%，FFN2权重减少了59.3%，准确率损失小于2%。

Conclusion: 所提出的低功耗视觉Transformer加速器通过算法-硬件协同设计，有效地解决了FFN计算瓶颈问题，并在保持高能效和面积效率的同时，实现了显著的计算量和模型复杂度降低。

Abstract: Current transformer accelerators primarily focus on optimizing self-attention
due to its quadratic complexity. However, this focus is less relevant for
vision transformers with short token lengths, where the Feed-Forward Network
(FFN) tends to be the dominant computational bottleneck. This paper presents a
low power Vision Transformer accelerator, optimized through algorithm-hardware
co-design. The model complexity is reduced using hardware-friendly dynamic
token pruning without introducing complex mechanisms. Sparsity is further
improved by replacing GELU with ReLU activations and employing dynamic FFN2
pruning, achieving a 61.5\% reduction in operations and a 59.3\% reduction in
FFN2 weights, with an accuracy loss of less than 2\%. The hardware adopts a
row-wise dataflow with output-oriented data access to eliminate data
transposition, and supports dynamic operations with minimal area overhead.
Implemented in TSMC's 28nm CMOS technology, our design occupies 496.4K gates
and includes a 232KB SRAM buffer, achieving a peak throughput of 1024 GOPS at
1GHz, with an energy efficiency of 2.31 TOPS/W and an area efficiency of 858.61
GOPS/mm2.

</details>


### [494] [ColumnDisturb: Understanding Column-based Read Disturbance in Real DRAM Chips and Implications for Future Systems](https://arxiv.org/abs/2510.14750)
*İsmail Emir Yüksel,Ataberk Olgun,F. Nisa Bostancı,Haocong Luo,A. Giray Yağlıkçı,Onur Mutlu*

Main category: cs.AR

TL;DR: ColumnDisturb是一种新的DRAM读干扰现象，可以通过同一列的行激活来干扰其他子阵列的单元，影响范围比RowHammer更广，且随着工艺节点缩小而加剧。


<details>
  <summary>Details</summary>
Motivation: 作者旨在发现新的DRAM读干扰现象，并评估其对现有DRAM芯片和未来技术的影响，特别是对内存刷新机制的潜在威胁。

Method: 通过实验，作者在真实的商品DRAM芯片中重复激活行（攻击行），观察是否会通过DRAM列（位线）干扰其他DRAM单元，并记录诱导的比特翻转。他们使用了216个DDR4和4个HBM2芯片，并在不同操作条件下进行了表征。

Result: ColumnDisturb现象存在于所有三个主要制造商的芯片中，并随着工艺节点的缩小而加剧。在现有的DRAM芯片中，ColumnDisturb可以在标准的DDR4刷新窗口内诱导比特翻转，影响范围比保留失败（retention failures）更广。具体来说，ColumnDisturb可诱导多达198倍的比特翻转行数。

Conclusion: ColumnDisturb对现有DRAM芯片和未来技术都构成了严重威胁，尤其会削弱依赖单元保留时间异质性（heterogeneity in cell retention times）的保留感知刷新机制（retention-aware refresh mechanisms）的有效性。

Abstract: We experimentally demonstrate a new widespread read disturbance phenomenon,
ColumnDisturb, in real commodity DRAM chips. By repeatedly opening or keeping a
DRAM row (aggressor row) open, we show that it is possible to disturb DRAM
cells through a DRAM column (i.e., bitline) and induce bitflips in DRAM cells
sharing the same columns as the aggressor row (across multiple DRAM subarrays).
With ColumnDisturb, the activation of a single row concurrently disturbs cells
across as many as three subarrays (e.g., 3072 rows) as opposed to
RowHammer/RowPress, which affect only a few neighboring rows of the aggressor
row in a single subarray. We rigorously characterize ColumnDisturb and its
characteristics under various operational conditions using 216 DDR4 and 4 HBM2
chips from three major manufacturers. Among our 27 key experimental
observations, we highlight two major results and their implications.
  First, ColumnDisturb affects chips from all three major manufacturers and
worsens as DRAM technology scales down to smaller node sizes (e.g., the minimum
time to induce the first ColumnDisturb bitflip reduces by up to 5.06x). We
observe that, in existing DRAM chips, ColumnDisturb induces bitflips within a
standard DDR4 refresh window (e.g., in 63.6 ms) in multiple cells. We predict
that, as DRAM technology node size reduces, ColumnDisturb would worsen in
future DRAM chips, likely causing many more bitflips in the standard refresh
window. Second, ColumnDisturb induces bitflips in many (up to 198x) more rows
than retention failures. Therefore, ColumnDisturb has strong implications for
retention-aware refresh mechanisms that leverage the heterogeneity in cell
retention times: our detailed analyses show that ColumnDisturb greatly reduces
the benefits of such mechanisms.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [495] [What is missing from this picture? Persistent homology and mixup barcodes as a means of investigating negative embedding space](https://arxiv.org/abs/2510.14327)
*Himanshu Yadav,Thomas Bryan Smith,Peter Bubenik,Christopher McCarty*

Main category: cs.SI

TL;DR: 利用拓扑数据分析（TDA）结合词向量技术，识别未观察到的出版物在研究领域中的作用，区分历史背景和创新空间。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖网络科学或主题建模来量化研究的颠覆性或新颖性，但存在内在偏差。本研究旨在结合这两种方法，探索 TDA（特别是持久同调和混合条形码）在分析主题模型生成的文档嵌入的负空间中的潜力。

Method: 使用 top2vec 嵌入文档和主题；利用持久同调识别嵌入分布中的“洞”；使用混合条形码确定哪些“洞”被一组未观察到的出版物（训练数据之外的早期或晚期出版物）所填充。

Result: 探究了负嵌入空间在多大程度上代表了缺失的背景（历史研究）与创新空间（新研究）的关系，以及占据这些空间的文档在多大程度上代表了周边研究主题的融合。

Conclusion: 讨论了这种新指标的潜在应用。

Abstract: Recent work in the information sciences, especially informetrics and
scientometrics, has made substantial contributions to the development of new
metrics that eschew the intrinsic biases of citation metrics. This work has
tended to employ either network scientific (topological) approaches to
quantifying the disruptiveness of peer-reviewed research, or topic modeling
approaches to quantifying conceptual novelty. We propose a combination of these
approaches, investigating the prospect of topological data analysis (TDA),
specifically persistent homology and mixup barcodes, as a means of
understanding the negative space among document embeddings generated by topic
models. Using top2vec, we embed documents and topics in n-dimensional space, we
use persistent homology to identify holes in the embedding distribution, and
then use mixup barcodes to determine which holes are being filled by a set of
unobserved publications. In this case, the unobserved publications represent
research that was published before or after the data used to train top2vec. We
investigate the extent that negative embedding space represents missing context
(older research) versus innovation space (newer research), and the extend that
the documents that occupy this space represents integrations of the research
topics on the periphery. Potential applications for this metric are discussed.

</details>


### [496] [Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media](https://arxiv.org/abs/2510.14889)
*Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha*

Main category: cs.SI

TL;DR: 本研究提出一种计算框架，通过整合用户发帖历史和社交邻近用户（通过复合网络中心性度量识别）的讨论，来预测早期和隐晦的自杀意念（SI）。


<details>
  <summary>Details</summary>
Motivation: 许多经历自杀意念（SI）的用户在社交媒体上并不明确表达痛苦，而是通过日常帖子或同伴互动间接流露，早期检测这些隐晦信号至关重要但仍具挑战性。

Method: 将早期和隐晦的SI视为一项前瞻性预测任务，构建了一个计算框架，模拟用户的“信息环境”，包括其长期的发帖历史以及社交邻近用户的讨论。该方法采用复合网络中心性度量来识别用户的顶层邻居，并对用户和邻居的互动进行时间对齐，然后将多层信号整合到一个微调的DeBERTa-v3模型中。

Result: 在一项针对1000名Reddit用户（500例，500对照）的研究中，该方法将早期和隐晦SI的检测率比仅基于个人用户的方法提高了15%。

Conclusion: 同伴互动提供了有价值的预测信号，这对于设计能够捕捉在线环境中风险的间接和伪装表达的早期检测系统具有更广泛的意义。

Abstract: On social media, many individuals experiencing suicidal ideation (SI) do not
disclose their distress explicitly. Instead, signs may surface indirectly
through everyday posts or peer interactions. Detecting such implicit signals
early is critical but remains challenging. We frame early and implicit SI as a
forward-looking prediction task and develop a computational framework that
models a user's information environment, consisting of both their longitudinal
posting histories as well as the discourse of their socially proximal peers. We
adopted a composite network centrality measure to identify top neighbors of a
user, and temporally aligned the user's and neighbors' interactions --
integrating the multi-layered signals in a fine-tuned DeBERTa-v3 model. In a
Reddit study of 1,000 (500 Case and 500 Control) users, our approach improves
early and implicit SI detection by 15% over individual-only baselines. These
findings highlight that peer interactions offer valuable predictive signals and
carry broader implications for designing early detection systems that capture
indirect as well as masked expressions of risk in online environments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [497] [Benefits and Limitations of Communication in Multi-Agent Reasoning](https://arxiv.org/abs/2510.13903)
*Michael Rizvi-Martel,Satwik Bhattamishra,Neil Rathi,Guillaume Rabusseau,Michael Hahn*

Main category: cs.MA

TL;DR: 长上下文和复杂任务会降低大型语言模型的性能，多智能体系统可以解决这个问题，但其基本能力尚不清楚。本研究提出了一个理论框架来分析多智能体系统的表达能力，并将其应用于状态跟踪、回忆和 k-hop 推理等算法。我们推导出了所需智能体数量、通信量和通信结构以及可实现的速度提升的界限，确定了通信有益的条件，并揭示了资源受限时的固有局限性。实验结果也证实了理论预测的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂和长上下文任务时性能会下降，而多智能体系统提供了一种有前景的解决方案，但对其基本能力缺乏理解。

Method: 提出一个理论框架来分析多智能体系统的表达能力，并将其应用于状态跟踪、回忆和 k-hop 推理这三类算法，推导了关于智能体数量、通信量、通信结构和速度提升的界限。

Result: 确定了通信有益的条件，阐明了智能体数量和通信带宽之间的权衡关系，并揭示了在通信受限时的内在局限性。实验结果也证实了理论预测的权衡关系。

Conclusion: 该分析为设计可扩展的多智能体推理系统提供了原则性指导。

Abstract: Chain-of-thought prompting has popularized step-by-step reasoning in large
language models, yet model performance still degrades as problem complexity and
context length grow. By decomposing difficult tasks with long contexts into
shorter, manageable ones, recent multi-agent paradigms offer a promising
near-term solution to this problem. However, the fundamental capacities of such
systems are poorly understood. In this work, we propose a theoretical framework
to analyze the expressivity of multi-agent systems. We apply our framework to
three algorithmic families: state tracking, recall, and $k$-hop reasoning. We
derive bounds on (i) the number of agents required to solve the task exactly,
(ii) the quantity and structure of inter-agent communication, and (iii) the
achievable speedups as problem size and context scale. Our results identify
regimes where communication is provably beneficial, delineate tradeoffs between
agent count and bandwidth, and expose intrinsic limitations when either
resource is constrained. We complement our theoretical analysis with a set of
experiments on pretrained LLMs using controlled synthetic benchmarks. Empirical
outcomes confirm the tradeoffs between key quantities predicted by our theory.
Collectively, our analysis offers principled guidance for designing scalable
multi-agent reasoning systems.

</details>


### [498] [Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations](https://arxiv.org/abs/2510.13982)
*Jinkun Chen,Sher Badshah,Xuemin Yu,Sijia Han,Jiechao Gao*

Main category: cs.MA

TL;DR: 现有的研究局限于静态环境，无法捕捉真实世界的复杂性。本文提出需要新的方法来创建开放、适应性强的多智能体模拟。


<details>
  <summary>Details</summary>
Motivation: 当前的多智能体系统和社交模拟虽然有LLM赋能，但大多局限于预定义任务、有限动力学和僵化评估标准的静态环境，无法捕捉真实社会的复杂性。

Method: 本文批判性地回顾了融合LLM与多智能体动态的新兴架构，指出了平衡稳定性与多样性、评估意外行为、扩展复杂性等关键挑战，并提出了一种新的分类法。

Result: 本文提出了一种以开放性、持续共进化以及有弹性的、社会性对齐的AI生态系统为中心的研究路线图。

Conclusion: 呼吁研究界超越静态范式，共同塑造下一代自适应、具有社会意识的多智能体模拟。

Abstract: What if artificial agents could not just communicate, but also evolve, adapt,
and reshape their worlds in ways we cannot fully predict? With llm now powering
multi-agent systems and social simulations, we are witnessing new possibilities
for modeling open-ended, ever-changing environments. Yet, most current
simulations remain constrained within static sandboxes, characterized by
predefined tasks, limited dynamics, and rigid evaluation criteria. These
limitations prevent them from capturing the complexity of real-world societies.
In this paper, we argue that static, task-specific benchmarks are fundamentally
inadequate and must be rethought. We critically review emerging architectures
that blend llm with multi-agent dynamics, highlight key hurdles such as
balancing stability and diversity, evaluating unexpected behaviors, and scaling
to greater complexity, and introduce a fresh taxonomy for this rapidly evolving
field. Finally, we present a research roadmap centered on open-endedness,
continuous co-evolution, and the development of resilient, socially aligned AI
ecosystems. \textbf{We call on the community to move beyond static paradigms
and help shape the next generation of adaptive, socially-aware multi-agent
simulations.}

</details>


### [499] [Stop Reducing Responsibility in LLM-Powered Multi-Agent Systems to Local Alignment](https://arxiv.org/abs/2510.14008)
*Jinwei Hu,Yi Dong,Shuang Ao,Zhuoyun Li,Boxuan Wang,Lokesh Singh,Guangliang Cheng,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.MA

TL;DR: LLM驱动的多智能体系统（LLM-MAS）带来了新的机遇和风险，需要从单一的代理对齐转向全局的系统一致性。责任的确保是一个贯穿生命周期的过程，需要结合人类价值观和可验证性，并通过跨学科设计和人机协作的治理框架来实现。LLM-MAS应被视为统一的社会技术系统，需要有原则的机制来支持责任的各个方面，以实现合乎道德、可验证且有韧性的行为。


<details>
  <summary>Details</summary>
Motivation: LLM-MAS带来了分布式推理、协作和任务泛化的新潜力，但也引入了因协议不确定、级联不确定性和对抗性漏洞而带来的额外风险。因此，确保LLM-MAS的负责任行为需要从局部、肤浅的代理级别对齐转向全局、系统的共识。

Method: 提出将责任视为一个贯穿生命周期的属性，涵盖共识、不确定性和安全性，并需要结合主观的人类中心价值观和客观的可验证性。此外，还需要一个结合跨学科设计和人机协作监督的双视角治理框架，以在LLM-MAS的整个生命周期中追踪和确保责任。

Result: LLM-MAS被视为统一的、动态的社会技术系统，需要原则性的机制来支持责任的各个维度，并实现合乎道德、可验证和有韧性的行为，以维持系统范围内的共识。

Conclusion: 确保LLM-MAS的负责任行为需要一种范式转变：从局部的、肤浅的代理级对齐转向全局的、系统的共识。

Abstract: LLM-powered Multi-Agent Systems (LLM-MAS) unlock new potentials in
distributed reasoning, collaboration, and task generalization but also
introduce additional risks due to unguaranteed agreement, cascading
uncertainty, and adversarial vulnerabilities. We argue that ensuring
responsible behavior in such systems requires a paradigm shift: from local,
superficial agent-level alignment to global, systemic agreement. We
conceptualize responsibility not as a static constraint but as a lifecycle-wide
property encompassing agreement, uncertainty, and security, each requiring the
complementary integration of subjective human-centered values and objective
verifiability. Furthermore, a dual-perspective governance framework that
combines interdisciplinary design with human-AI collaborative oversight is
essential for tracing and ensuring responsibility throughout the lifecycle of
LLM-MAS. Our position views LLM-MAS not as loose collections of agents, but as
unified, dynamic socio-technical systems that demand principled mechanisms to
support each dimension of responsibility and enable ethically aligned,
verifiably coherent, and resilient behavior for sustained, system-wide
agreement.

</details>


### [500] [The Role of Social Learning and Collective Norm Formation in Fostering Cooperation in LLM Multi-Agent Systems](https://arxiv.org/abs/2510.14401)
*Prateek Gupta,Qiankun Zhong,Hiromu Yakura,Thomas Eisenmann,Iyad Rahwan*

Main category: cs.MA

TL;DR: 该研究提出了一个不依赖显式奖励信号的共公资源（CPR）博弈模拟框架，融入了社会学习和基于规范的惩罚机制，以研究大型语言模型（LLMs）在混合动机场景下的规范和合作演化。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在共公资源（CPR）博弈研究中，通常依赖于明确的奖励函数。然而，人类的合作是在缺乏对收益和群体信息完全可见的情况下，依靠启发式方法、沟通和惩罚而出现的。因此，本研究旨在创建一个更贴近现实的人类合作机制的模拟框架。

Method: 该研究提出了一个CPR模拟框架，移除了显式的奖励信号，并融入了文化演化机制：社会学习（从成功的同伴那里采纳策略和信念）和基于规范的惩罚，该框架以奥斯特罗姆关于资源治理的原则为基础。同时，代理可以通过环境反馈进行学习，包括收获、监控和惩罚，从而内生化地产生规范。研究人员通过复现现有关于人类行为的研究成果来验证该模拟的有效性，并考察了在不同环境和社会初始条件下（资源丰富/稀缺；利他/自私）规范的演化，以及不同LLMs代理群体在这些条件下的表现。

Result: 研究结果揭示了不同LLM在维持合作和规范形成方面存在系统性差异，证明了该框架作为研究混合动机LLM社会中内生规范的有力测试平台。

Conclusion: 该框架为研究LLM社会中的内生规范演化提供了一个严谨的测试平台，其分析结果有助于设计在社会和组织背景下部署的AI系统，这些系统需要与合作规范保持一致，以确保稳定、公平和有效的AI中介环境治理。

Abstract: A growing body of multi-agent studies with Large Language Models (LLMs)
explores how norms and cooperation emerge in mixed-motive scenarios, where
pursuing individual gain can undermine the collective good. While prior work
has explored these dynamics in both richly contextualized simulations and
simplified game-theoretic environments, most LLM systems featuring common-pool
resource (CPR) games provide agents with explicit reward functions directly
tied to their actions. In contrast, human cooperation often emerges without
full visibility into payoffs and population, relying instead on heuristics,
communication, and punishment. We introduce a CPR simulation framework that
removes explicit reward signals and embeds cultural-evolutionary mechanisms:
social learning (adopting strategies and beliefs from successful peers) and
norm-based punishment, grounded in Ostrom's principles of resource governance.
Agents also individually learn from the consequences of harvesting, monitoring,
and punishing via environmental feedback, enabling norms to emerge
endogenously. We establish the validity of our simulation by reproducing key
findings from existing studies on human behavior. Building on this, we examine
norm evolution across a $2\times2$ grid of environmental and social
initialisations (resource-rich vs. resource-scarce; altruistic vs. selfish) and
benchmark how agentic societies comprised of different LLMs perform under these
conditions. Our results reveal systematic model differences in sustaining
cooperation and norm formation, positioning the framework as a rigorous testbed
for studying emergent norms in mixed-motive LLM societies. Such analysis can
inform the design of AI systems deployed in social and organizational contexts,
where alignment with cooperative norms is critical for stability, fairness, and
effective governance of AI-mediated environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [501] [CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization](https://arxiv.org/abs/2510.14150)
*Henrique Assumpção,Diego Ferreira,Leandro Campos,Fabricio Murai*

Main category: cs.AI

TL;DR: CodeEvolve是一个结合LLM和遗传算法的开源进化编码代理，用于解决复杂计算问题，并在数学基准测试中超越了AlphaEvolve。


<details>
  <summary>Details</summary>
Motivation: 介绍CodeEvolve，一个结合LLM和遗传算法的开源进化编码代理，旨在解决复杂计算问题。

Method: CodeEvolve使用基于岛屿的遗传算法来维持种群多样性并提高吞吐量，引入了基于LLM上下文窗口的新颖的启发式交叉机制来组合成功解决方案的特征，并采用元提示策略来动态探索解决方案空间。

Result: 在用于评估AlphaEvolve的数学基准测试子集上，CodeEvolve的性能优于AlphaEvolve。

Conclusion: CodeEvolve在解决复杂计算问题方面表现出色，并且为了促进合作和加速进展，研究人员公开了他们的完整框架。

Abstract: In this work, we introduce CodeEvolve, an open-source evolutionary coding
agent that unites Large Language Models (LLMs) with genetic algorithms to solve
complex computational problems. Our framework adapts powerful evolutionary
concepts to the LLM domain, building upon recent methods for generalized
scientific discovery. CodeEvolve employs an island-based genetic algorithm to
maintain population diversity and increase throughput, introduces a novel
inspiration-based crossover mechanism that leverages the LLMs context window to
combine features from successful solutions, and implements meta-prompting
strategies for dynamic exploration of the solution space. We conduct a rigorous
evaluation of CodeEvolve on a subset of the mathematical benchmarks used to
evaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that
our method surpasses AlphaEvolve's performance on several challenging problems.
To foster collaboration and accelerate progress, we release our complete
framework as an open-source repository.

</details>


### [502] [Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context](https://arxiv.org/abs/2510.13858)
*Raheleh Biglari,Joachim Denil*

Main category: cs.AI

TL;DR: 该研究提出了一种名为DOTechnique的新方法，用于评估模型有效性，该方法基于决策一致性而非输出相似性。


<details>
  <summary>Details</summary>
Motivation: 传统模型有效性评估方法依赖预定义框架，可能不足或不可用。本研究旨在提供一种新的模型有效性评估方法。

Method: DOTechnique通过评估代理模型是否导致与高保真模型等效的决策来确定模型有效性，即使在没有明确有效性边界的情况下也能识别有效性区域。该方法结合了领域约束和符号推理来缩小搜索空间，提高计算效率。

Result: 以高速公路变道系统为例，证明DOTechnique可以发现仿真模型的有效性区域。

Conclusion: DOTechnique有潜力通过决策者背景来支持寻找模型有效性。

Abstract: Model validity is as critical as the model itself, especially when guiding
decision-making processes. Traditional approaches often rely on predefined
validity frames, which may not always be available or sufficient. This paper
introduces the Decision Oriented Technique (DOTechnique), a novel method for
determining model validity based on decision consistency rather than output
similarity. By evaluating whether surrogate models lead to equivalent decisions
compared to high-fidelity models, DOTechnique enables efficient identification
of validity regions, even in the absence of explicit validity boundaries. The
approach integrates domain constraints and symbolic reasoning to narrow the
search space, enhancing computational efficiency. A highway lane change system
serves as a motivating example, demonstrating how DOTechnique can uncover the
validity region of a simulation model. The results highlight the potential of
the technique to support finding model validity through decision-maker context.

</details>


### [503] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 本研究提出了一种结合语音和幻灯片信息的多模态自动语音识别（ASR）方法，并通过数据增强解决了数据集不足的问题，最终在科学会议场景下将词错误率分别降低了 34% 和 35%（针对特定术语）。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的自动语音识别（ASR）系统主要依赖声学信息，忽略了视觉等多模态信息，而视觉信息对于消除歧义和适应环境至关重要。本研究关注于整合演讲者的图像和演示文稿（幻灯片）信息，以应对科学会议等特定场景。

Method: 首先，创建了一个包含领域特定术语自动分析的多模态演示基准。然后，探索了使用多模态信息增强语音模型的方法。通过精心设计的数据增强策略来弥补缺乏带幻灯片的标注数据集的问题。最后，使用增强后的数据集训练模型。

Result: 与基线模型相比，在所有词的错误率上降低了约 34%，在领域特定术语的错误率上降低了约 35%。

Conclusion: 本研究提出的多模态ASR方法，通过整合幻灯片信息和使用数据增强技术，显著提高了在科学会议场景下的识别准确率，尤其是在处理领域特定术语方面。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [504] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 大型语言模型在处理因果判断任务时容易产生因果错觉，即使在缺乏证据的情况下也会推断出不合理的因果关系。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在面对经典的认知科学范式“联结判断任务”时，是否会产生因果错觉，以及这种错觉是否与社会偏见、刻板印象形成、错误信息和社会迷信等社会问题相关。

Method: 构建了一个包含1000个零联结场景（即可用信息不足以建立变量之间的因果关系）的医疗背景数据集，并提示LLMs评估潜在原因的有效性。

Result: 所有被评估的模型都系统性地推断出不合理的因果关系，显示出对因果错觉的强烈易感性。

Conclusion: 研究结果表明，LLMs 容易产生因果错觉，这支持了它们仅仅是复制因果语言而非真正理解因果关系的观点，并对在需要准确因果推理以做出明智决策的领域中使用语言模型提出了担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [505] [GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations](https://arxiv.org/abs/2510.14035)
*Rajesh Mangannavar,Prasad Tadepalli*

Main category: cs.AI

TL;DR: GammaZero使用统一的基于图的表示法来学习指导POMDP中的规划，并能泛化到比训练时遇到的问题大2-4倍的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的POMDP规划方法需要领域特定的神经网络架构，并且难以扩展，而GammaZero旨在通过统一的基于图的信念表示来克服这些限制，实现跨问题规模的泛化。

Method: GammaZero将信念状态系统地转换为以动作centric的图，并使用带有解码器架构的图神经网络从专家演示中学习价值函数和策略。然后，这些学习到的启发式方法用于指导蒙特卡洛树搜索，以解决更大的问题。

Result: 在标准的POMDP基准测试中，GammaZero在相同大小的问题上表现与BetaZero相当，并且能够零样本泛化到比训练问题大2-4倍的问题，同时保持解决方案的质量并减少搜索需求。

Conclusion: GammaZero通过其以动作为centric的图表示法和基于图神经网络的方法，在POMDP规划领域取得了显著进展，实现了可扩展性和跨问题规模的泛化能力。

Abstract: We introduce an action-centric graph representation framework for learning to
guide planning in Partially Observable Markov Decision Processes (POMDPs).
Unlike existing approaches that require domain-specific neural architectures
and struggle with scalability, GammaZero leverages a unified graph-based belief
representation that enables generalization across problem sizes within a
domain. Our key insight is that belief states can be systematically transformed
into action-centric graphs where structural patterns learned on small problems
transfer to larger instances. We employ a graph neural network with a decoder
architecture to learn value functions and policies from expert demonstrations
on computationally tractable problems, then apply these learned heuristics to
guide Monte Carlo tree search on larger problems. Experimental results on
standard POMDP benchmarks demonstrate that GammaZero achieves comparable
performance to BetaZero when trained and tested on the same-sized problems,
while uniquely enabling zero-shot generalization to problems 2-4 times larger
than those seen during training, maintaining solution quality with reduced
search requirements.

</details>


### [506] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: LLM驱动的生成-过滤-精炼（迭代范式）在AI+科学领域取得了进展，但其搜索效率受限于如何将领域先验知识编码到结构化的假设空间中。本文提出了一种紧凑的描述和衡量LLM辅助迭代搜索的理论，将智能体表示为模糊关系算子，并引入覆盖生成函数来衡量可达性难度，为迭代搜索提供了几何解释和量化工具。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的生成-过滤-精炼范式在AI+科学领域有应用前景，但其搜索效率依赖于领域先验知识到假设空间的编码方式。现有方法缺乏对这种搜索过程的系统性理论描述和衡量工具。

Method: 提出一种紧凑的形式理论，将智能体描述为作用于输入和输出的模糊关系算子，并受固定安全包络约束。通过加权所有可达路径并求和得到覆盖生成函数，用于衡量多步推理/搜索的可达性难度，并提供搜索的几何解释。通过多数投票实例化来验证最简单的可测试推理。

Result: 提出了一种可行的语言和操作工具，用于衡量智能体及其搜索空间。为LLM构建的迭代搜索提供了系统的形式化描述。

Conclusion: 本文提出的形式理论为理解和改进LLM在AI+科学领域的迭代搜索过程提供了理论基础和量化工具，有助于更有效地利用领域先验知识指导搜索。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [507] [Position: Require Frontier AI Labs To Release Small "Analog" Models](https://arxiv.org/abs/2510.14053)
*Shriyash Upadhyay,Chaithanya Bandi,Narmeen Oozeer,Philip Quirke*

Main category: cs.AI

TL;DR: AI监管新思路：强制发布小型开源模型，平衡安全与创新


<details>
  <summary>Details</summary>
Motivation: 当前AI监管方案因成本问题和安全-创新权衡而面临搁浅，需要一种新的监管方法。

Method: 提出强制AI实验室发布小型、开源的“模拟模型”（analog models），这些模型在训练方式上与大型专有模型相似，并从中蒸馏而来。模拟模型可作为公共代理，用于安全验证、可解释性研究和算法透明度，同时不暴露大型模型的核心技术。

Result: 模拟模型能有效促进安全和可解释性研究，且相关方法可推广至大型前沿模型。该政策将降低监管负担，加速安全进步，并使更广泛的研究社区能够直接研究和创新。

Conclusion: 该强制性政策成本低廉，能促进公共利益，并通过深入理解模型来缓解安全-创新之间的矛盾，实现安全与创新的双赢。

Abstract: Recent proposals for regulating frontier AI models have sparked concerns
about the cost of safety regulation, and most such regulations have been
shelved due to the safety-innovation tradeoff. This paper argues for an
alternative regulatory approach that ensures AI safety while actively promoting
innovation: mandating that large AI laboratories release small, openly
accessible analog models (scaled-down versions) trained similarly to and
distilled from their largest proprietary models.
  Analog models serve as public proxies, allowing broad participation in safety
verification, interpretability research, and algorithmic transparency without
forcing labs to disclose their full-scale models. Recent research demonstrates
that safety and interpretability methods developed using these smaller models
generalize effectively to frontier-scale systems. By enabling the wider
research community to directly investigate and innovate upon accessible
analogs, our policy substantially reduces the regulatory burden and accelerates
safety advancements.
  This mandate promises minimal additional costs, leveraging reusable resources
like data and infrastructure, while significantly contributing to the public
good. Our hope is not only that this policy be adopted, but that it illustrates
a broader principle supporting fundamental research in machine learning: deeper
understanding of models relaxes the safety-innovation tradeoff and lets us have
more of both.

</details>


### [508] [Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems](https://arxiv.org/abs/2510.14133)
*Edoardo Allegrini,Ananth Shreekumar,Z. Berkay Celik*

Main category: cs.AI

TL;DR: 对由多个自主代理和大型语言模型（LLM）组成的 Agentic AI 系统进行建模，以解决通信碎片化和语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 目前的 Agentic AI 系统在代理间通信方面存在碎片化问题，例如用于工具访问的 MCP 和用于协调的 A2A 协议被孤立分析，这导致了语义鸿沟，阻碍了对系统属性的严格分析，并引入了架构错位和可利用的协调问题等风险。

Method: 提出了一个 Agentic AI 系统的建模框架，包含两个基础模型：1）宿主代理模型，用于形式化与用户交互、分解任务并协调外部代理和工具执行的顶层实体；2）任务生命周期模型，用于详细说明从创建到完成的各个子任务的状态和转换，提供任务管理和错误处理的细粒度视图。

Result: 该框架定义了宿主代理的 17 个属性和任务生命周期的 14 个属性，分为活性、安全性、完整性和公平性几类。这些属性以时间逻辑表示，能够进行系统行为的形式化验证，检测协调的边缘情况，并防止死锁和安全漏洞。

Conclusion: 该研究提出了第一个具有严格基础、领域无关的框架，用于对 Agentic AI 系统进行系统性分析、设计和部署，以实现正确、可靠和稳健的目标。

Abstract: Agentic AI systems, which leverage multiple autonomous agents and Large
Language Models (LLMs), are increasingly used to address complex, multi-step
tasks. The safety, security, and functionality of these systems are critical,
especially in high-stakes applications. However, the current ecosystem of
inter-agent communication is fragmented, with protocols such as the Model
Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol
for coordination being analyzed in isolation. This fragmentation creates a
semantic gap that prevents the rigorous analysis of system properties and
introduces risks such as architectural misalignment and exploitable
coordination issues. To address these challenges, we introduce a modeling
framework for agentic AI systems composed of two foundational models. The
first, the host agent model, formalizes the top-level entity that interacts
with the user, decomposes tasks, and orchestrates their execution by leveraging
external agents and tools. The second, the task lifecycle model, details the
states and transitions of individual sub-tasks from creation to completion,
providing a fine-grained view of task management and error handling. Together,
these models provide a unified semantic framework for reasoning about the
behavior of multi-AI agent systems. Grounded in this framework, we define 17
properties for the host agent and 14 for the task lifecycle, categorized into
liveness, safety, completeness, and fairness. Expressed in temporal logic,
these properties enable formal verification of system behavior, detection of
coordination edge cases, and prevention of deadlocks and security
vulnerabilities. Through this effort, we introduce the first rigorously
grounded, domain-agnostic framework for the systematic analysis, design, and
deployment of correct, reliable, and robust agentic AI systems.

</details>


### [509] [Agentic Design of Compositional Machines](https://arxiv.org/abs/2510.14980)
*Wenqian Zhang,Weiyang Liu,Zhen Liu*

Main category: cs.AI

TL;DR: LLMs can be trained to design complex machines using a new testbed called BesiegeField, which leverages the game Besiege. While current LLMs struggle with tasks requiring spatial reasoning and strategic assembly, reinforcement learning shows promise for improvement.


<details>
  <summary>Details</summary>
Motivation: To investigate whether Large Language Models (LLMs) can learn to create complex machines, specifically through compositional machine design.

Method: Introduced BesiegeField, a testbed built on the game Besiege, for part-based construction, physical simulation, and reward-driven evaluation. Benchmarked state-of-the-art LLMs with agentic workflows. Explored reinforcement learning (RL) by curating a cold-start dataset and conducting RL finetuning experiments.

Result: Current open-source LLMs fall short in capabilities like spatial reasoning, strategic assembly, and instruction-following for machine design tasks. RL finetuning experiments show potential for improvement.

Conclusion: While current LLMs struggle with machine design, further research using reinforcement learning at the intersection of language, machine design, and physical reasoning is needed to achieve success.

Abstract: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.

</details>


### [510] [Generating Fair Consensus Statements with Social Choice on Token-Level MDPs](https://arxiv.org/abs/2510.14106)
*Carter Blair,Kate Larson*

Main category: cs.AI

TL;DR: 当前的大语言模型共识生成框架缺乏内在结构来保证聚合自由形式观点的公平性。我们提出将此任务建模为多目标、token 级别的马尔可夫决策过程（MDP），其中每个目标对应一个代理的偏好。每个代理的 token 级别奖励源于其策略（例如，个性化语言模型）。此方法利用此类策略隐式定义最优 Q 函数的发现，为在没有价值函数的情况下在每个生成步骤量化奖励提供了一个原则方法（Rafailov 等人，2024）。此 MDP 公式创建了一个形式结构，可以通过社会选择理论的原理进行分析。我们提出两种基于社会选择理论的方法。首先，我们提出一种随机生成策略，保证该策略处于事前核心（ex-ante core），将核心稳定性概念从投票理论扩展到文本生成。该策略源于最大化比例公平性（Nash Welfare）的完整语句的潜在分布。其次，对于生成单个语句，我们以在 MDP 框架内使用搜索算法最大化平等的福利为目标。通过使用语言模型来实现代理策略的实验表明，与包括 Habermas Machine（Tessler 等人，2024）在内的基线方法相比，由平等目标指导的搜索生成的共识语句在最坏情况下的代理对齐得到了改善。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型共识生成框架缺乏内在结构来保证聚合自由形式观点的公平性。

Method: 我们将共识生成任务建模为多目标、token 级别的马尔可夫决策过程（MDP），其中每个目标对应一个代理的偏好。代理的 token 级别奖励源于其策略。我们提出两种基于社会选择理论的方法：1. 一种随机生成策略，保证该策略处于事前核心（ex-ante core），最大化比例公平性（Nash Welfare）。2. 针对单个语句生成，使用搜索算法最大化平等的福利。

Result: 通过使用语言模型实现代理策略的实验表明，与基线方法（包括 Habermas Machine）相比，由平等目标指导的搜索生成的共识语句在最坏情况下的代理对齐得到了改善。

Conclusion: 所提出的基于 MDP 和社会选择理论的方法为生成公平的共识语句提供了一个有原则的框架，并且在实践中能够改善代理对齐。

Abstract: Current frameworks for consensus statement generation with large language
models lack the inherent structure needed to provide provable fairness
guarantees when aggregating diverse free-form opinions. We model the task as a
multi-objective, token-level Markov Decision Process (MDP), where each
objective corresponds to an agent's preference. Token-level rewards for each
agent are derived from their policy (e.g., a personalized language model). This
approach utilizes the finding that such policies implicitly define optimal
Q-functions, providing a principled way to quantify rewards at each generation
step without a value function (Rafailov et al., 2024). This MDP formulation
creates a formal structure amenable to analysis using principles from social
choice theory. We propose two approaches grounded in social choice theory.
First, we propose a stochastic generation policy guaranteed to be in the
ex-ante core, extending core stability concepts from voting theory to text
generation. This policy is derived from an underlying distribution over
complete statements that maximizes proportional fairness (Nash Welfare).
Second, for generating a single statement, we target the maximization of
egalitarian welfare using search algorithms within the MDP framework.
Empirically, experiments using language models to instantiate agent policies
show that search guided by the egalitarian objective generates consensus
statements with improved worst-case agent alignment compared to baseline
methods, including the Habermas Machine (Tessler et al., 2024).

</details>


### [511] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: STEMS是一个用于协调楼宇能源管理的新型安全约束多智能体强化学习框架，通过图神经网络-Transformer融合架构提取时空依赖关系，并利用控制障碍函数提供安全保障，实验表明其在降低成本、减少排放和避免安全违规方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 楼宇能源管理对于实现碳减排目标、提高居住者舒适度和降低能源成本至关重要。然而，当前的楼宇能源管理面临开发时空依赖性以及确保多楼宇系统运行安全方面的严峻挑战。

Method: 提出了一种名为STEMS（Spatial-Temporal Enhanced Safe Multi-Agent Coordination）的框架，该框架包含两个核心组件：1. 使用GCN-Transformer融合架构的空间-时间图表示学习框架，用于捕捉楼宇间的关系和时间模式。2. 结合控制障碍函数的安全约束多智能体强化学习算法，提供数学上的安全保证。

Result: STEMS在真实楼宇数据集上的大量实验证明，其性能优于现有方法，实现了21%的成本降低、18%的排放减少，并将安全违规率从35.1%大幅降低至5.6%，同时仅有0.13的失舒适度比例，保持了最优舒适度。此外，该框架在极端天气条件下表现出很强的鲁棒性，并且在不同类型的楼宇中都保持有效性。

Conclusion: STEMS框架成功地解决了多楼宇能源管理中时空依赖性利用不足、安全保障缺失和系统复杂性等问题，通过结合先进的时空图学习和安全约束强化学习技术，在实际应用中取得了显著的性能提升。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [512] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 该研究提出了一种轻量级的多模态架构，用于融合传感器数据和视觉图像，以预测文化遗产地的退化程度，在数据稀疏的情况下取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 传统的文化遗产监测方法依赖单一的分析方式，无法捕捉环境因素与材料退化之间复杂的相互作用，而文化遗产正面临着气候变化加剧的退化风险。

Method: 提出了一种改进的Perceiver IO架构，采用了简化的编码器（64D潜在空间）以防止在小数据集上过拟合，并使用自适应Barlow Twins损失来鼓励模态间的互补性而非冗余性。

Result: 在斯特拉斯堡大教堂的数据上，该模型达到了76.9%的准确率，相比于标准的多模态架构（VisualBERT, Transformer）提高了43%，相比于标准的PerceiverIO提高了25%。消融研究表明，仅使用传感器数据准确率为61.5%，仅使用图像数据准确率为46.2%，证实了多模态的协同作用。超参数研究发现，中等相关性目标（τ=0.3）能最好地平衡模态间的对齐和互补性，准确率为69.2%。

Conclusion: 研究证明，在数据稀缺的遗产监测场景中，结合对比正则化的架构简化能够实现有效 Thus, this work demonstrates that architectural simplicity combined with contrastive regularization enables effective multimodal learning in data-scarce heritage monitoring contexts, providing a foundation for AI-driven conservation decision support systems.

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [513] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 多模态方法结合脑电图（EEG）、语音和文本可以提高抑郁症的自动检测效果，并且预训练的嵌入比手工制作的特征效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症自动检测方法在特征比较和评估协议方面存在局限性，本研究旨在系统地探索不同特征表示和模型策略，以改进多模态检测。

Method: 本研究系统地探索了结合脑电图（EEG）、语音和文本的特征表示和模型策略，包括评估手工制作的特征与预训练嵌入、不同神经编码器的有效性、单模态、双模态和三模态配置，以及融合策略，并采用了统一的、独立的受试者划分以确保结果的稳健性和可复现性。

Result: 结果表明，(i) 结合EEG、语音和文本的多模态检测效果得到增强，(ii) 预训练嵌入优于手工制作的特征，(iii) 精心设计的三模态模型达到了最先进的性能。

Conclusion: 本研究为未来多模态抑郁症检测的研究奠定了基础。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [514] [Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola](https://arxiv.org/abs/2510.14154)
*Tian Liu,Alex Cann,Ian Colbert,Mehdi Saeedi*

Main category: cs.AI

TL;DR: RL在商业游戏中的应用缓慢，而BT+RL的结合是一个有前景但被忽视的领域。本文使用AMD Schola在虚幻引擎中展示了BT+RL在创建复杂3D环境中多任务NPC的可行性。


<details>
  <summary>Details</summary>
Motivation: RL在商业视频游戏中的应用缓慢，尽管行为树（BT）和RL的结合已被提出，但实际应用很少。

Method: 使用AMD Schola在虚幻引擎中，通过结合BT和RL来训练多任务NPC，并展示了联合训练RL模型和BT的详细方法。

Result: 成功地在受《最后生还者》启发的复杂3D环境中创建了多任务NPC，并展示了各种技能。

Conclusion: BT+RL的结合是游戏AI领域的一个有前景的方向，该方法在复杂环境中训练NPC是可行的。

Abstract: While the rapid advancements in the reinforcement learning (RL) research
community have been remarkable, the adoption in commercial video games remains
slow. In this paper, we outline common challenges the Game AI community faces
when using RL-driven NPCs in practice, and highlight the intersection of RL
with traditional behavior trees (BTs) as a crucial juncture to be explored
further. Although the BT+RL intersection has been suggested in several research
papers, its adoption is rare. We demonstrate the viability of this approach
using AMD Schola -- a plugin for training RL agents in Unreal Engine -- by
creating multi-task NPCs in a complex 3D environment inspired by the commercial
video game ``The Last of Us". We provide detailed methodologies for jointly
training RL models with BTs while showcasing various skills.

</details>


### [515] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA是一个无需LLM的实时临床订单检索系统，它结合了显式指令和隐式推理，能够快速准确地将环境对话映射到临床订单。


<details>
  <summary>Details</summary>
Motivation: 现有的临床订单系统依赖LLM重写，存在延迟、不稳定和不透明的问题，阻碍了实时订单的生成。需要一个能够处理显式指令和隐式推理，并且能够实时运行的系统。

Method: JEDA是一个领域初始化的双编码器模型。它首先从PubMedBERT初始化，然后使用对比学习进行微调。该模型能够直接检索规范化订单，并且在无查询模式下，可以编码一小段连续的对话，以触发检索。训练过程中，通过约束LLM引导，将每个订单与其对应的不同表达方式（仅命令、仅上下文、命令+上下文、上下文+推理）联系起来，以提高订单间的区分度和查询与订单的匹配度。

Result: JEDA在实际部署中取得了显著的成效，其性能远超基线编码器和近期的一些开放嵌入模型（Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma）。

Conclusion: JEDA是一个快速、可解释且无需LLM的检索层，能够实时地将环境对话与临床订单联系起来，解决了现有系统在处理临床对话中的不足。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [516] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM是一个利用基础模型（FM）自动设计强化学习（RL）奖励的框架，通过自然语言生成奖励机（RM），实现任务分解和跨任务泛化。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）算法对奖励函数的指定非常敏感，这是限制其广泛应用的一个关键挑战。

Method: 使用基础模型（FM）自动从自然语言规范生成奖励机（RM），并将语言嵌入与每个RM状态相关联，以实现跨任务泛化。

Result: 在各种具有挑战性的环境中，ARM-FM被证明是有效的，并且能够实现零样本泛化。

Conclusion: ARM-FM通过利用基础模型（FM）的推理能力，为RL提供了一种自动的、组合式的奖励设计方法，解决了奖励函数指定的挑战。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [517] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: AI在精准医疗中日益重要，但临床应用受限。本文通过对2019-2024年的文献进行范围审查，识别了数据质量、临床可靠性、工作流程整合和治理方面的关键障碍和促进因素，并提出了支持可信和可持续实施的未来方向。


<details>
  <summary>Details</summary>
Motivation: 精准医疗中AI的应用日益增长，但临床实施面临挑战，需要识别障碍和促进因素以实现可信和可持续的转化。

Method: 通过对2019-2024年关于AI在精准医疗中实施的文献进行范围审查，并利用生态系统框架进行分析。

Result: 确定了数据质量、临床可靠性、工作流程整合和治理是AI在精准医疗中实施的关键领域，并揭示了这些因素之间相互依赖的关系。

Conclusion: AI在精准医疗中的临床实施受到数据质量、临床可靠性、工作流程整合和治理等多种因素的影响。通过生态系统框架，可以更好地理解这些相互依赖的关系，并为未来实现可信和可持续的实施提供指导。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [518] [Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](https://arxiv.org/abs/2510.14207)
*Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu*

Main category: cs.AI

TL;DR: LLM代理在互动式网络应用中日益普及，但易受滥用和伤害。本研究提出了在线骚扰代理基准（Online Harassment Agentic Benchmark），包含多轮骚扰对话数据集、基于博弈论的多代理模拟、三种针对LLM代理的越狱方法以及混合方法评估框架。研究发现，越狱调优显著提高了骚扰攻击成功率（95.78-99.33%），大幅降低了拒绝率（1-2%），且攻击模仿了人类攻击性模式。闭源和开源模型在迭代过程中表现出不同的升级轨迹，闭源模型尤为脆弱。研究强调了开发强大安全防护措施的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLM）代理的越狱研究主要集中在单轮提示，而现实中的骚扰通常是多轮交互的。因此，需要一种能够评估LLM代理在多轮交互中抵御骚扰攻击能力的方法。

Method: 本研究提出了在线骚扰代理基准（Online Harassment Agentic Benchmark），包括：1. 一个合成的多轮骚扰对话数据集。2. 一个基于重复博弈论的多代理（如骚扰者、受害者）模拟系统。3. 三种针对LLM代理（包括记忆、规划和微调方面）的越狱方法。4. 一个混合方法评估框架。研究使用了两个LLM模型：LLaMA-3.1-8B-Instruct（开源）和Gemini-2.0-flash（闭源）。

Result: 研究结果表明，越狱调优使得骚扰攻击在Llama模型上的成功率从57.25-64.19%提高到95.78-96.89%，在Gemini模型上从98.46%提高到99.33%，同时将两个模型的拒绝率均降至1-2%。最常见的攻击类型是侮辱（84.9-87.8%）和恶意争论（81.2-85.1%），这表明与性或种族骚扰等敏感类别相比，针对这些行为的防护措施较弱。此外，被攻击的代理会模仿人类的攻击性行为，例如规划攻击中出现的马基雅维利/精神病态模式，以及记忆攻击中出现的自恋倾向。闭源和开源模型在多轮交互中的升级轨迹不同，闭源模型表现出显著的脆弱性。

Conclusion: 多轮且基于博弈论的攻击不仅成功率高，而且能模仿人类骚扰动态。这凸显了开发强大的安全防护措施以确保在线平台安全和负责任使用的紧迫性。

Abstract: Large Language Model (LLM) agents are powering a growing share of interactive
web applications, yet remain vulnerable to misuse and harm. Prior jailbreak
research has largely focused on single-turn prompts, whereas real harassment
often unfolds over multi-turn interactions. In this work, we present the Online
Harassment Agentic Benchmark consisting of: (i) a synthetic multi-turn
harassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)
simulation informed by repeated game theory, (iii) three jailbreak methods
attacking agents across memory, planning, and fine-tuning, and (iv) a
mixed-methods evaluation framework. We utilize two prominent LLMs,
LLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our
results show that jailbreak tuning makes harassment nearly guaranteed with an
attack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,
and 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal
rate to 1-2% in both models. The most prevalent toxic behaviors are Insult with
84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.
31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive
categories such as sexual or racial harassment. Qualitative evaluation further
reveals that attacked agents reproduce human-like aggression profiles, such as
Machiavellian/psychopathic patterns under planning, and narcissistic tendencies
with memory. Counterintuitively, closed-source and open-source models exhibit
distinct escalation trajectories across turns, with closed-source models
showing significant vulnerability. Overall, our findings show that multi-turn
and theory-grounded attacks not only succeed at high rates but also mimic
human-like harassment dynamics, motivating the development of robust safety
guardrails to ultimately keep online platforms safe and responsible.

</details>


### [519] [LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild](https://arxiv.org/abs/2510.14240)
*Jiayu Wang,Yifei Ming,Riya Dulepet,Qinglin Chen,Austin Xu,Zixuan Ke,Frederic Sala,Aws Albarghouthi,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 该论文提出了一个名为LiveResearchBench的基准测试，用于评估能够搜索和合成网络信息以生成报告的智能体系统。该基准包含100个用户中心、动态、明确且需要广泛网络搜索的任务。同时，论文还提出了DeepEval评估套件，用于评估报告的质量，包括覆盖度、呈现、引用准确性、一致性和分析深度。研究人员使用LiveResearchBench和DeepEval评估了17个深度研究系统，分析了它们的优势、失败模式和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估需要实时网络搜索和信息合成能力的智能体系统方面存在不足，无法满足用户真实的信息需求，且评估标准不统一。因此，需要一个更全面、更严格的基准来系统地评估这类系统。

Method: 提出LiveResearchBench基准，包含100个涵盖日常生活、企业和学术领域、需要大量实时网络搜索和信息合成的任务。同时提出DeepEval评估套件，包含内容和报告层面的质量评估指标，以及四种评估协议。使用这些工具对17个深度研究系统进行了评估。

Result: 评估结果揭示了当前深度研究系统的优势、常见的失败模式以及推动可靠、深入的深度研究所需的关键系统组成部分。

Conclusion: LiveResearchBench和DeepEval为评估和发展深度研究智能体系统提供了一个严格的框架，有助于推动该领域的研究和应用。

Abstract: Deep research -- producing comprehensive, citation-grounded reports by
searching and synthesizing information from hundreds of live web sources --
marks an important frontier for agentic systems. To rigorously evaluate this
ability, four principles are essential: tasks should be (1) user-centric,
reflecting realistic information needs, (2) dynamic, requiring up-to-date
information beyond parametric knowledge, (3) unambiguous, ensuring consistent
interpretation across users, and (4) multi-faceted and search-intensive,
requiring search over numerous web sources and in-depth analysis. Existing
benchmarks fall short of these principles, often focusing on narrow domains or
posing ambiguous questions that hinder fair comparison. Guided by these
principles, we introduce LiveResearchBench, a benchmark of 100 expert-curated
tasks spanning daily life, enterprise, and academia, each requiring extensive,
dynamic, real-time web search and synthesis. Built with over 1,500 hours of
human labor, LiveResearchBench provides a rigorous basis for systematic
evaluation. To evaluate citation-grounded long-form reports, we introduce
DeepEval, a comprehensive suite covering both content- and report-level
quality, including coverage, presentation, citation accuracy and association,
consistency and depth of analysis. DeepEval integrates four complementary
evaluation protocols, each designed to ensure stable assessment and high
agreement with human judgments. Using LiveResearchBench and DeepEval, we
conduct a comprehensive evaluation of 17 frontier deep research systems,
including single-agent web search, single-agent deep research, and multi-agent
systems. Our analysis reveals current strengths, recurring failure modes, and
key system components needed to advance reliable, insightful deep research.

</details>


### [520] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 研究表明，生成式奖励模型（GRM）和充足的（即使是合成的）任务数据对于可扩展的基于LLM的自主学习至关重要。通过多角色协同进化的“Agentic Self-Learning”（ASL）框架，可以实现持续的性能提升，优于固定基线，并在无标记数据条件下表现出良好的样本效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索在不依赖人工策划数据集或预定义规则奖励的情况下，自学习如何扩展基于LLM的自主代理。

Method: 提出了一种名为Agentic Self-Learning（ASL）的框架，该框架在一个共享工具环境和LLM骨干中整合了任务生成、策略执行和评估。ASL通过协调Prompt生成器、策略模型和生成式奖励模型（GRM）来实现一个由更难的任务设置、更精确的验证和更强的解决能力组成的良性循环。研究了奖励信号的来源（GRM vs. 规则）和任务数据的规模（合成数据）对模型训练的影响，并强调了GRM的持续训练和适时引入真实数据以克服性能瓶颈。

Result: ASL在每一轮训练中都实现了稳定的性能提升，并且优于Search-R1等强RLVR基线（这些基线最终会停滞或性能下降）。即使在零标记数据条件下，ASL的性能也在持续提升，表明其具有较高的样本效率和鲁棒性。研究还发现，GRM的验证能力是关键瓶颈，持续训练GRM可以缓解此问题，而少量真实验证数据的注入可以进一步提高性能上限。

Conclusion: 奖励来源和数据规模是开放域自主学习的关键因素。多角色协同进化可以实现可扩展的、自我改进的自主代理。ASL框架有效地利用了这些发现，实现了优于现有方法的性能。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [521] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: MorphoBench是一个包含多学科问题的新基准，用于评估和调整大型语言模型的推理能力，通过利用关键陈述和模拟软件来动态调整难度。


<details>
  <summary>Details</summary>
Motivation: 现有的评估大型语言模型推理能力的基准在范围上有限，并且缺乏根据模型不断发展的推理能力来调整难度的灵活性。

Method: MorphoBench通过整合来自现有基准和竞赛（如奥林匹克竞赛）的复杂推理问题来构建基准。它利用模型推理过程中产生的关键陈述来调整问题的分析难度，并通过模拟软件生成问题，从而能够以最小的资源消耗动态调整基准难度。

Result: 该基准包含超过1300个测试问题，并根据o3和GPT-5等模型的推理能力对难度进行了迭代调整。

Conclusion: MorphoBench通过提高模型推理评估的全面性和有效性，为提升大型语言模型的推理能力和科学稳健性提供了可靠的指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [522] [A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space](https://arxiv.org/abs/2510.14301)
*Bingjie Zhang,Yibo Yang,Renzhe,Dandan Guo,Jindong Gu,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: GuardSpace是一个用于在微调过程中保护LLM安全性的框架，通过分解预训练权重并引入安全感子空间和抗有害空子空间来防止安全行为退化。


<details>
  <summary>Details</summary>
Motivation: LLM在适应过程中安全对齐容易退化，导致有害输出，需要一种方法来保持其安全对齐。

Method: GuardSpace通过协方差预处理奇异值分解将预训练权重分解为安全相关和不安全相关部分，并冻结安全相关部分。同时，构建一个空子空间投影器，限制适配器更新对有害提示的输出，以维持原始的拒绝行为。

Result: GuardSpace在各种预训练模型和下游任务上的实验表明，其性能优于现有方法。例如，在Llama-2-7B-Chat模型上，GuardSpace将有害分数从14.4%降低到3.6%，同时将准确率从26.0%提高到28.0%。

Conclusion: GuardSpace能够有效地在微调过程中保持LLM的安全对齐，显著减少有害输出，并可能提高模型性能。

Abstract: Large language models (LLMs) have achieved remarkable success in diverse
tasks, yet their safety alignment remains fragile during adaptation. Even when
fine-tuning on benign data or with low-rank adaptation, pre-trained safety
behaviors are easily degraded, leading to harmful responses in the fine-tuned
models. To address this challenge, we propose GuardSpace, a guardrail framework
for preserving safety alignment throughout fine-tuning, composed of two key
components: a safety-sensitive subspace and a harmful-resistant null space.
First, we explicitly decompose pre-trained weights into safety-relevant and
safety-irrelevant components using covariance-preconditioned singular value
decomposition, and initialize low-rank adapters from the safety-irrelevant
ones, while freezing safety-relevant components to preserve their associated
safety mechanism. Second, we construct a null space projector that restricts
adapter updates from altering safe outputs on harmful prompts, thereby
maintaining the original refusal behavior. Experiments with various pre-trained
models on multiple downstream tasks demonstrate that GuardSpace achieves
superior performance over existing methods. Notably, for Llama-2-7B-Chat
fine-tuned on GSM8K, GuardSpace outperforms the state-of-the-art method AsFT,
reducing the average harmful score from 14.4% to 3.6%, while improving the
accuracy from from 26.0% to 28.0%.

</details>


### [523] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 本文提出了Terrarium框架，用于研究基于大语言模型的多智能体系统（LLM-MAS）的安全性、隐私性和鲁棒性。该框架利用黑板设计，实现了模块化和可配置的测试环境，能够模拟对齐不齐、恶意代理、通信被破坏和数据投毒等攻击。通过实现三种协作MAS场景和四种代表性攻击，证明了该框架的灵活性，旨在加速可信赖MAS的研发。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的多智能体系统（LLM-MAS）虽然能自动化复杂任务，但也引入了对齐不齐、恶意攻击和数据泄露等新风险。因此，需要一个框架来研究和解决这些安全、隐私和安全问题。

Method: 设计并实现了一个名为Terrarium的框架，该框架重新利用了早期多智能体系统中的黑板设计，构建了一个模块化、可配置的测试平台，用于研究LLM-MAS的对齐不齐、恶意代理、通信被破坏和数据投毒等问题。框架中实现了三种协作MAS场景和四种代表性攻击。

Result: Terrarium框架能够灵活地演示和评估LLM-MAS中的各种攻击向量，并为开发和迭代防御措施提供了工具。通过实验证明了该框架的有效性。

Conclusion: Terrarium框架为LLM-MAS的安全、隐私和安全研究提供了一个灵活且可配置的测试平台，有助于加速可信赖MAS的发展。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [524] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: MASC是一个元认知框架，通过实时、无监督的步级错误检测和自我修正来增强大型语言模型多代理系统（MAS）的鲁棒性，解决了级联错误问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型多代理系统（MAS）在协作解决问题方面表现出色，但容易出现级联错误，单个错误步骤会影响整个系统的轨迹。

Method: MASC通过两种互补的设计实现错误检测：1）下一个执行重建，预测下一个步骤的嵌入以捕捉因果一致性；2）原型引导增强，学习正常步骤嵌入的原型先验，以稳定重建和异常评分。当检测到异常步骤时，MASC会触发一个纠正代理来修改代理的输出。

Result: 在Who&When基准测试中，MASC在步级错误检测方面比所有基线提高了高达8.47%的AUC-ROC。将其应用于不同的MAS框架，可以在不同架构中实现一致的端到端改进。

Conclusion: MASC的元认知监控和定向纠正可以有效减轻错误传播，且开销极小。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [525] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: AI4Service是一个新范式，通过Alpha-Service框架，利用AI眼镜实现主动、实时的日常协助，解决了在何时以及如何提供服务的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI服务主要是被动的，而真正智能的助手应该能够预测用户需求并主动采取行动。

Method: 提出Alpha-Service统一框架，包含输入单元（感知）、中央处理单元（任务调度）、算术逻辑单元（工具利用）、记忆单元（个性化）和输出单元（交互），并在AI眼镜上通过多智能体系统实现。

Result: 通过黑杰克顾问、博物馆导览和购物助理等案例研究，证明了该系统在无需明确提示的情况下，能够感知环境、推断用户意图并提供及时协助。

Conclusion: Alpha-Service框架成功实现了AI在日常生活中从被动响应到主动协助的范式转变。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [526] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: IP-Merging可以直接将LLM的数学推理能力转移到MLLM，无需微调，通过对齐参数空间来解决模型合并中的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 当前的MLLM在数学推理能力上落后于LLM，作者希望探索一种无需微调即可将LLM的数学推理能力转移到MLLM的方法。

Method: 提出IP-Merging方法，该方法首先识别MLLM和数学LLM中与推理相关的关键参数层，然后将这些参数投影到MLLM的子空间中，以保持对齐，最后在子空间中合并参数。这是一种无需微调的方法。

Result: 实验证明，IP-Merging可以有效提升MLLM的数学推理能力，并且不会损害其其他能力。

Conclusion: IP-Merging是一种有效的、无需微调的方法，可以利用现有数学LLM的推理能力来增强MLLM的数学推理能力，解决了模型合并中存在的参数空间不对齐问题。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [527] [Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control](https://arxiv.org/abs/2510.14388)
*Zhe Wu,Hongjin Lu,Junliang Xing,Changhao Zhang,Yin Zhu,Yuhao Yang,Yuheng Jing,Kai Li,Kun Shao,Jianye Hao,Jun Wang,Yuanchun Shi*

Main category: cs.AI

TL;DR: Hi-Agent是一个用于移动设备控制的可训练分层视觉-语言模型，它通过高层推理和低层动作模型联合优化，实现了87.9%的任务成功率，并在Android-in-the-Wild基准测试中取得了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉-语言模型（VLM）的移动设备自主操作方法在处理新任务或未见过UI布局时泛化能力较差，因为它们依赖于直接的状态到动作映射，缺乏结构化推理和规划能力。

Method: Hi-Agent采用分层结构，包含一个高层推理模型和一个低层动作模型，两者进行联合优化。为了提高训练效率，该方法将多步决策重新表述为一系列单步子目标，并提出了一种远见优势函数，利用低层模型的执行反馈来指导高层优化。这种设计克服了GRPO在长时任务中遇到的路径爆炸问题，并实现了无需判别器的稳定联合训练。

Result: Hi-Agent在Android-in-the-Wild（AitW）基准测试中取得了87.9%的任务成功率，显著优于之前的SOTA方法（如AppAgent的17.7%、Filtered BC的54.5%和DigiRL的71.9%）。此外，它在ScreenSpot-v2基准测试中也表现出具有竞争力的零样本泛化能力，并在AndroidWorld基准测试中显示出随着骨干网络增大而有效扩展的能力。

Conclusion: Hi-Agent通过其分层结构和新颖的训练方法，成功解决了现有VLM在移动设备控制方面泛化能力不足的问题，并在多个基准测试中取得了SOTA的性能，证明了其在复杂移动控制场景中的有效性和适应性。

Abstract: Building agents that autonomously operate mobile devices has attracted
increasing attention. While Vision-Language Models (VLMs) show promise, most
existing approaches rely on direct state-to-action mappings, which lack
structured reasoning and planning, and thus generalize poorly to novel tasks or
unseen UI layouts. We introduce Hi-Agent, a trainable hierarchical
vision-language agent for mobile control, featuring a high-level reasoning
model and a low-level action model that are jointly optimized. For efficient
training, we reformulate multi-step decision-making as a sequence of
single-step subgoals and propose a foresight advantage function, which
leverages execution feedback from the low-level model to guide high-level
optimization. This design alleviates the path explosion issue encountered by
Group Relative Policy Optimization (GRPO) in long-horizon tasks and enables
stable, critic-free joint training. Hi-Agent achieves a new State-Of-The-Art
(SOTA) 87.9% task success rate on the Android-in-the-Wild (AitW) benchmark,
significantly outperforming prior methods across three paradigms: prompt-based
(AppAgent: 17.7%), supervised (Filtered BC: 54.5%), and reinforcement
learning-based (DigiRL: 71.9%). It also demonstrates competitive zero-shot
generalization on the ScreenSpot-v2 benchmark. On the more challenging
AndroidWorld benchmark, Hi-Agent also scales effectively with larger backbones,
showing strong adaptability in high-complexity mobile control scenarios.

</details>


### [528] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: IMAGINE是一个将多智能体系统（MAS）集成到单个模型中的框架，能够显著提升大型语言模型（LLMs）在复杂推理和规划任务上的表现，同时降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在复杂推理和规划方面存在挑战，而多智能体系统（MAS）虽然能提升推理能力，但成本高昂且训练困难。IMAGINE旨在解决这些问题。

Method: 提出了一种名为IMAGINE的通用、可扩展框架，将MAS的推理和规划能力集成到一个单一、紧凑的模型中，并通过简单的端到端训练进行优化。

Result: 使用IMAGINE框架和Qwen3-8B-Instruct作为基础模型，在TravelPlanner基准测试中达到了82.7%的最终通过率，远超DeepSeek-R1-671B的40%，并且模型规模更小。

Conclusion: IMAGINE框架能够使单个小型模型获得类似MAS的结构化推理和规划能力，并且在性能上超越MAS，同时保持更小的模型尺寸和更低的成本。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [529] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: PDDL中的公理可以看作是Datalog等数据库查询语言的泛化。虽然PDDL标准限制了公理体中谓词的负面出现，但文献中通常允许派生谓词的负面出现，只要公理是可分层的。这两种变体都可以表达与最小不动点逻辑相同的查询，表明可以消除派生谓词的负面出现。本文提出了相应的转换。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是解决PDDL（Planning Domain Definition Language）中公理的应用和限制问题。PDDL中的公理可以看作是Datalog等数据库查询语言的泛化。然而，PDDL标准对公理体中谓词的负面出现进行了限制，只允许直接由动作设置的谓词出现。这限制了公理的表达能力。文献中，作者们经常偏离这一限制，只要求公理是可分层的，这使得公理能够处理更广泛的查询。因此，本文旨在探讨和解决如何消除派生谓词的负面出现，并提出相应的转换方法。

Method: 本文提出了一种将涉及派生谓词负面出现的公理转换为等价形式的转换方法。这种转换基于最小不动点逻辑的表达能力。具体来说，作者们表明，无论是否遵循PDDL的标准限制（即只允许直接由动作设置的谓词在公理体中出现负面形式），只要公理是可分层的，它们都可以表达与最小不动点逻辑相同的查询。因此，本文的研究重点在于展示如何进行这种转换，以消除派生谓词的负面出现。

Result: 本文的研究结果表明，通过一种特定的转换方法，可以消除PDDL公理中派生谓词的负面出现。该转换方法使得原本可能受限于PDDL标准限制的公理，能够达到与允许派生谓词负面出现的（只要是可分层的）公理相同的表达能力。最终，这两种形式的公理在表达能力上等价于最小不动点逻辑，证实了消除派生谓词负面出现的转换是有效的。

Conclusion: 本文的结论是，PDDL中的公理，无论是遵循严格的标准限制还是允许可分层的派生谓词负面出现，其表达能力都是等价于最小不动点逻辑的。本文提出了一个有效的转换方法，可以将涉及派生谓词负面出现的公理转化为不含此类负面出现的等价形式。这为更灵活和强大的规划领域定义语言的应用提供了理论基础和实践指导。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [530] [Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration](https://arxiv.org/abs/2510.14512)
*Haoyuan Li,Mathias Funk,Aaqib Saeed*

Main category: cs.AI

TL;DR: Helmsman是一个多智能体系统，可以自动生成联邦学习系统，并提供了AgentFL-Bench基准来评估其能力。


<details>
  <summary>Details</summary>
Motivation: 设计和部署健壮的联邦学习（FL）系统非常复杂，选择、组合和调整策略以应对数据异质性和系统约束等挑战已成为关键瓶颈，导致解决方案脆弱且定制化。

Method: Helmsman通过三个协作阶段实现端到端的联邦学习系统合成：1. 人机交互式规划，制定研究计划；2. 监督智能体团队进行模块化代码生成；3. 在沙盒模拟环境中进行自主评估和优化。此外，还引入了AgentFL-Bench基准，包含16个任务，用于评估智能体系统的系统级生成能力。

Result: 实验表明，Helmsman生成的解决方案在性能上可以与手工设计的基线相媲美，甚至更优。

Conclusion: Helmsman是朝着自动化工程复杂分布式人工智能系统迈出的重要一步。

Abstract: Federated Learning (FL) offers a powerful paradigm for training models on
decentralized data, but its promise is often undermined by the immense
complexity of designing and deploying robust systems. The need to select,
combine, and tune strategies for multifaceted challenges like data
heterogeneity and system constraints has become a critical bottleneck,
resulting in brittle, bespoke solutions. To address this, we introduce
Helmsman, a novel multi-agent system that automates the end-to-end synthesis of
federated learning systems from high-level user specifications. It emulates a
principled research and development workflow through three collaborative
phases: (1) interactive human-in-the-loop planning to formulate a sound
research plan, (2) modular code generation by supervised agent teams, and (3) a
closed-loop of autonomous evaluation and refinement in a sandboxed simulation
environment. To facilitate rigorous evaluation, we also introduce
AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess
the system-level generation capabilities of agentic systems in FL. Extensive
experiments demonstrate that our approach generates solutions competitive with,
and often superior to, established hand-crafted baselines. Our work represents
a significant step towards the automated engineering of complex decentralized
AI systems.

</details>


### [531] [JSPLIT: A Taxonomy-based Solution for Prompt Bloating in Model Context Protocol](https://arxiv.org/abs/2510.14537)
*Emanuele Antonioni,Stefan Markovic,Anirudha Shankar,Jaime Bernardo,Lovro Markovic,Silvia Pareti,Benedetto Proietti*

Main category: cs.AI

TL;DR: JSPLIT是一个框架，通过将工具组织成层次化分类，并根据用户提示选择最相关的工具，来解决LLM提示膨胀问题，从而有效降低成本并提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统和用户期望的不断发展，LLM需要与外部工具交互，但这会导致提示膨胀，增加成本、延迟和降低成功率。

Method: JSPLIT框架通过构建工具的层次化分类，并根据用户提示的查询和分类结构，只选择最相关的工具，从而管理提示大小。

Result: JSPLIT显著减小了提示的大小，同时基本不影响代理的响应能力。在工具数量大幅增加的情况下，JSPLIT甚至提高了工具选择的准确性，降低了成本并提高了高复杂度环境下的任务成功率。

Conclusion: JSPLIT是一种有效的解决方案，可以解决LLM在与大量外部工具交互时出现的提示膨胀问题，并能在工具数量增加时带来性能提升。

Abstract: AI systems are continually evolving and advancing, and user expectations are
concurrently increasing, with a growing demand for interactions that go beyond
simple text-based interaction with Large Language Models (LLMs). Today's
applications often require LLMs to interact with external tools, marking a
shift toward more complex agentic systems. To support this, standards such as
the Model Context Protocol (MCP) have emerged, enabling agents to access tools
by including a specification of the capabilities of each tool within the
prompt. Although this approach expands what agents can do, it also introduces a
growing problem: prompt bloating. As the number of tools increases, the prompts
become longer, leading to high prompt token costs, increased latency, and
reduced task success resulting from the selection of tools irrelevant to the
prompt. To address this issue, we introduce JSPLIT, a taxonomy-driven framework
designed to help agents manage prompt size more effectively when using large
sets of MCP tools. JSPLIT organizes the tools into a hierarchical taxonomy and
uses the user's prompt to identify and include only the most relevant tools,
based on both the query and the taxonomy structure. In this paper, we describe
the design of the taxonomy, the tool selection algorithm, and the dataset used
to evaluate JSPLIT. Our results show that JSPLIT significantly reduces prompt
size without significantly compromising the agent's ability to respond
effectively. As the number of available tools for the agent grows
substantially, JSPLIT even improves the tool selection accuracy of the agent,
effectively reducing costs while simultaneously improving task success in
high-complexity agent environments.

</details>


### [532] [Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts](https://arxiv.org/abs/2510.14538)
*Emanuele Marconato,Samuele Bortolotti,Emile van Krieken,Paolo Morettin,Elena Umili,Antonio Vergari,Efthymia Tsamoura,Andrea Passerini,Stefano Teso*

Main category: cs.AI

TL;DR: Neuro-symbolic (NeSy) AI 结合了深度学习和符号推理，旨在构建可靠、可信赖的 AI。然而，当概念不直接受到监督时，NeSy 模型容易出现“推理捷径”（RSs）问题，即模型可能通过错误地绑定概念来获得高精度。这会损害模型的可解释性、泛化能力和可靠性。本文旨在梳理 RSs 的相关文献，介绍其成因、后果、理论基础，并探讨缓解和应对策略，以降低研究者和实践者应对此问题的门槛，推动可靠 NeSy 和可信赖 AI 的发展。


<details>
  <summary>Details</summary>
Motivation: NeSy AI 模型在概念不直接监督时容易出现推理捷径（RSs）问题，这会损害模型的可解释性、泛化能力和可靠性。然而，相关文献分散，难以全面理解和解决该问题。

Method: 本文对 RSs 的相关文献进行了全面的综述，包括其成因、后果、理论基础，并详细介绍了缓解和应对 RSs 的策略，包括缓解和意识策略，并分析了它们的优缺点。

Result: 本文对 RSs 的相关文献进行了梳理和总结，提供了对 RSs 的直观理解，讨论了其理论基础，并详细介绍了应对 RSs 的方法，旨在降低研究者和实践者应对该问题的门槛。

Conclusion: 本文通过提供一个关于 RSs 的统一视角，旨在降低研究者和实践者应对该问题的门槛，并为开发可靠的 NeSy 和可信赖 AI 模型做出贡献。

Abstract: Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose
predictions comply with prior knowledge encoding, e.g. safety or structural
constraints. As such, it represents one of the most promising avenues for
reliable and trustworthy AI. The core idea behind NeSy AI is to combine neural
and symbolic steps: neural networks are typically responsible for mapping
low-level inputs into high-level symbolic concepts, while symbolic reasoning
infers predictions compatible with the extracted concepts and the prior
knowledge. Despite their promise, it was recently shown that - whenever the
concepts are not supervised directly - NeSy models can be affected by Reasoning
Shortcuts (RSs). That is, they can achieve high label accuracy by grounding the
concepts incorrectly. RSs can compromise the interpretability of the model's
explanations, performance in out-of-distribution scenarios, and therefore
reliability. At the same time, RSs are difficult to detect and prevent unless
concept supervision is available, which is typically not the case. However, the
literature on RSs is scattered, making it difficult for researchers and
practitioners to understand and tackle this challenging problem. This overview
addresses this issue by providing a gentle introduction to RSs, discussing
their causes and consequences in intuitive terms. It also reviews and
elucidates existing theoretical characterizations of this phenomenon. Finally,
it details methods for dealing with RSs, including mitigation and awareness
strategies, and maps their benefits and limitations. By reformulating advanced
material in a digestible form, this overview aims to provide a unifying
perspective on RSs to lower the bar to entry for tackling them. Ultimately, we
hope this overview contributes to the development of reliable NeSy and
trustworthy AI models.

</details>


### [533] [LLM Agents Beyond Utility: An Open-Ended Perspective](https://arxiv.org/abs/2510.14548)
*Asen Nachkov,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: LLM代理通过链式思考和函数调用能力不断增强，研究其作为独立规划、设计和实现更广泛、模糊目标的实体的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究LLM代理是否能超越智能问题解决工具，成为一个能够规划、设计即时任务、并朝着更广泛、更模糊目标进行推理的独立实体。

Method: 在预训练LLM代理的基础上，增加了其生成任务、积累知识以及与环境进行广泛交互的能力，并在开放式实验环境中对其进行定性研究。

Result: 该开放式代理能够可靠地遵循复杂的多步指令，跨运行存储和重用信息，并提出和解决自己的任务。然而，它仍然对提示设计敏感，容易产生重复性任务，并且无法形成自我表征。

Conclusion: 研究结果表明了将预训练LLM适应开放式能力的潜力和局限性，并指明了未来在训练代理管理记忆、进行有成效的探索以及追求抽象的长期目标方面的方向。

Abstract: Recent LLM agents have made great use of chain of thought reasoning and
function calling. As their capabilities grow, an important question arises: can
this software represent not only a smart problem-solving tool, but an entity in
its own right, that can plan, design immediate tasks, and reason toward
broader, more ambiguous goals? To study this question, we adopt an open-ended
experimental setting where we augment a pretrained LLM agent with the ability
to generate its own tasks, accumulate knowledge, and interact extensively with
its environment. We study the resulting open-ended agent qualitatively. It can
reliably follow complex multi-step instructions, store and reuse information
across runs, and propose and solve its own tasks, though it remains sensitive
to prompt design, prone to repetitive task generation, and unable to form
self-representations. These findings illustrate both the promise and current
limits of adapting pretrained LLMs toward open-endedness, and point to future
directions for training agents to manage memory, explore productively, and
pursue abstract long-term goals.

</details>


### [534] [ColorBench: Benchmarking Mobile Agents with Graph-Structured Framework for Complex Long-Horizon Tasks](https://arxiv.org/abs/2510.14621)
*Yuanyi Song,Heyuan Huang,Qiqiang Lin,Yin Zhao,Xiangmou Qu,Jun Wang,Xingyu Lou,Weiwen Liu,Zhuosheng Zhang,Jun Wang,Yong Yu,Weinan Zhang,Zhaoxiang Wang*

Main category: cs.AI

TL;DR: 本论文提出了ColorBench，一个用于评估移动端多模态大语言模型（MLLM）的基准测试框架，通过模拟动态行为的静态方法解决了现有评估标准的不足，并能处理复杂、长跨度的任务。


<details>
  <summary>Details</summary>
Motivation: 现有移动端智能体评估标准（离线静态基准和在线动态测试）无法充分评估复杂、具有多重解决方案的真实世界移动任务，因此需要新的评估方法。

Method: 提出一个图结构基准框架，通过模拟真实设备交互中的有限状态来实现动态行为的静态模拟。在此基础上，开发了ColorBench，一个包含175个复杂长跨度任务（单应用74个，跨应用101个）的基准测试，每个任务至少有两个正确路径和若干典型错误路径，支持多重正确解、子任务完成率和原子级别能力分析。

Result: 通过在ColorBench上评估现有基线模型，发现了现有模型的局限性，并为提高智能体在复杂长跨度问题上的性能提出了改进方向和技术路径。

Conclusion: ColorBench通过其独特的评估机制，能够更全面、稳定地评估移动端MLLM在复杂任务上的表现，为未来研究提供了新的方向。

Abstract: The rapid advancement of multimodal large language models has enabled agents
to operate mobile devices by directly interacting with graphical user
interfaces, opening new possibilities for mobile automation. However,
real-world mobile tasks are often complex and allow for multiple valid
solutions. This contradicts current mobile agent evaluation standards: offline
static benchmarks can only validate a single predefined "golden path", while
online dynamic testing is constrained by the complexity and non-reproducibility
of real devices, making both approaches inadequate for comprehensively
assessing agent capabilities. To bridge the gap between offline and online
evaluation and enhance testing stability, this paper introduces a novel
graph-structured benchmarking framework. By modeling the finite states observed
during real-device interactions, it achieves static simulation of dynamic
behaviors. Building on this, we develop ColorBench, a benchmark focused on
complex long-horizon tasks. It supports evaluation of multiple valid solutions,
subtask completion rate statistics, and atomic-level capability analysis.
ColorBench contains 175 tasks (74 single-app, 101 cross-app) with an average
length of over 13 steps. Each task includes at least two correct paths and
several typical error paths, enabling quasi-dynamic interaction. By evaluating
ColorBench across various baselines, we discover limitations of existing models
and propose improvement directions and feasible technical pathways to enhance
agents' performance on complex, long-horizon problems based on experimental
results. Code and data are available at:
https://github.com/MadeAgents/ColorBench.

</details>


### [535] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: LLMs are powerful but flawed due to their reliance on statistical prediction, leading to hallucinations. This paper proposes the Rose-Frame, a 3D framework to diagnose cognitive and epistemic drift in human-AI interaction, emphasizing the need for reflective, falsifiable oversight to align AI fluency with human understanding.


<details>
  <summary>Details</summary>
Motivation: LLMs, despite their fluency, lack grounded reasoning and are prone to hallucinations due to inheriting biases and ambiguities from language. This paper is motivated by the need to address these limitations and ensure AI alignment with human understanding.

Method: The paper introduces the Rose-Frame, a three-dimensional framework with axes: Map vs. Territory, Intuition vs. Reason, and Conflict vs. Confirmation. This framework serves as a diagnostic tool for cognitive and epistemic drift in human-AI interactions.

Result: The Rose-Frame provides a method for making LLM limitations and user assumptions visible, facilitating transparent and critically aware AI deployment. It reframes alignment as cognitive governance, where human reason must govern AI intuition.

Conclusion: The paper concludes that aligning machine fluency with human understanding requires embedding reflective, falsifiable oversight, treating alignment as cognitive governance to ensure human reason governs AI intuition.

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [536] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 机器学习在公共卫生领域的应用存在潜在的算法偏见风险，本研究通过系统性文献回顾和提出ACAR框架，旨在填补现有研究在识别、讨论和报告算法偏见方面的不足，并为研究者提供改进建议，以促进健康公平。


<details>
  <summary>Details</summary>
Motivation: 机器学习在公共卫生领域具有巨大潜力，但若不关注算法偏见，可能加剧健康不平等。本研究旨在评估荷兰公共卫生机器学习研究中算法偏见的识别、讨论和报告现状。

Method: 开发了风险算法偏见评估工具（RABAT），整合了Cochrane Risk of Bias、PROBAST和Microsoft Responsible AI checklist等现有框架的要素，并将其应用于2021年至2025年间的35项同行评审研究。在此基础上，提出了一个名为ACAR（意识、概念化、应用、报告）的四阶段公平性框架。

Result: 研究发现，尽管数据采样和缺失数据处理得到了充分记录，但大多数研究忽略了明确的公平性表述、亚组分析和潜在危害的透明讨论。ACAR框架旨在指导研究者在机器学习生命周期的各个阶段解决公平性问题。

Conclusion: 提出了ACAR框架和具体的行动建议，以帮助公共卫生领域的机器学习研究者系统地考虑算法偏见，提高透明度，确保技术进步促进健康公平而非加剧不平等。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [537] [TITAN: Graph-Executable Reasoning for Cyber Threat Intelligence](https://arxiv.org/abs/2510.14670)
*Marco Simoni,Aleksandar Fontana,Andrea Saracino,Paolo Mori*

Main category: cs.AI

TL;DR: TITAN是一个连接自然语言网络威胁查询和可执行推理的框架，通过路径规划模型和图执行器，利用MITRE构建的类型化双向知识图谱来回答问题并提供证据。


<details>
  <summary>Details</summary>
Motivation: 为了连接自然语言网络威胁查询和可执行推理，并克服传统检索系统的局限性。

Method: 集成了一个路径规划模型来预测文本中的逻辑关系链，以及一个图执行器来遍历TITAN本体以检索事实答案和支持证据。知识图谱是基于MITRE构建的类型化双向图。

Result: TITAN能够生成语法有效且语义连贯的推理路径，这些路径可以在底层图上确定性地执行。

Conclusion: TITAN框架能够有效地实现基于自然语言的网络威胁查询和可执行的知识图谱推理。

Abstract: TITAN (Threat Intelligence Through Automated Navigation) is a framework that
connects natural-language cyber threat queries with executable reasoning over a
structured knowledge graph. It integrates a path planner model, which predicts
logical relation chains from text, and a graph executor that traverses the
TITAN Ontology to retrieve factual answers and supporting evidence. Unlike
traditional retrieval systems, TITAN operates on a typed, bidirectional graph
derived from MITRE, allowing reasoning to move clearly and reversibly between
threats, behaviors, and defenses. To support training and evaluation, we
introduce the TITAN Dataset, a corpus of 88209 examples (Train: 74258; Test:
13951) pairing natural language questions with executable reasoning paths and
step by step Chain of Thought explanations. Empirical evaluations show that
TITAN enables models to generate syntactically valid and semantically coherent
reasoning paths that can be deterministically executed on the underlying graph.

</details>


### [538] [NAEL: Non-Anthropocentric Ethical Logic](https://arxiv.org/abs/2510.14676)
*Bianca Maria Lerma,Rafael Peñaloza*

Main category: cs.AI

TL;DR: NAEL是一个基于主动推理和符号推理的新型AI伦理框架，旨在实现非人类中心主义的AI伦理。


<details>
  <summary>Details</summary>
Motivation: 当前AI伦理框架多以人类为中心，NAEL旨在打破这一局限，提出一种非人类中心主义的AI伦理框架。

Method: NAEL将伦理行为形式化为智能系统在动态多智能体环境中最小化全局预期自由能的涌现属性，并提出了一种神经符号架构来实现。

Result: NAEL能够在不预设拟人化道德直觉的情况下，使智能体发展出具有情境敏感性、适应性和关系性的伦理行为。案例研究表明，NAEL能够动态地平衡自我保护、认知学习和集体福利。

Conclusion: NAEL是一个有前景的AI伦理框架，能够为多智能体系统提供一种新颖的、非人类中心的伦理决策方法。

Abstract: We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical
framework for artificial agents grounded in active inference and symbolic
reasoning. Departing from conventional, human-centred approaches to AI ethics,
NAEL formalizes ethical behaviour as an emergent property of intelligent
systems minimizing global expected free energy in dynamic, multi-agent
environments. We propose a neuro-symbolic architecture to allow agents to
evaluate the ethical consequences of their actions in uncertain settings. The
proposed system addresses the limitations of existing ethical models by
allowing agents to develop context-sensitive, adaptive, and relational ethical
behaviour without presupposing anthropomorphic moral intuitions. A case study
involving ethical resource distribution illustrates NAEL's dynamic balancing of
self-preservation, epistemic learning, and collective welfare.

</details>


### [539] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: 本文提出了一种改进的COUP算法配置程序，提高了其在实际应用中的性能，同时保持了其理论保证，并使其在算法选择问题上具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 算法配置旨在找到最优参数以最大化用户效用，但现有的COUP程序在实际性能上表现不佳。

Method: 通过一系列改进COUP算法配置程序，以提高其经验性能，同时不损害其理论保证，并通过案例研究探讨了效用函数变化对算法选择鲁棒性的影响。

Result: 改进后的COUP程序在经验上比现有的启发式配置程序更具竞争力，并且能够探索效用函数变化带来的鲁棒性。

Conclusion: 改进后的COUP算法配置程序在实际性能和理论保证方面都具有竞争力，为算法选择问题提供了更优的解决方案。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [540] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: 模型合并旨在将单个微调模型中的特定任务能力集成到单个模型中，而无需额外训练。PAVE通过在知识感知子空间中净化任务向量来解决现有方法中的性能下降问题，该方法通过分解和修剪冗余分量来提取与目标知识最相关的权重成分。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法，特别是那些使用任务向量的方法，常常因为任务向量中与任务无关的冗余而导致性能下降。随机丢弃参数空间中的元素来克服冗余的方法缺乏对知识的感知。

Method: PAVE方法通过对每个任务的微调模型进行采样，获取线性层之前的协方差矩阵。然后，它进行面向上下文的奇异值分解，以突出与目标知识最相关的权重成分。这使得能够将微调模型的权重分解为任务相关和冗余的组件，从而在知识感知子空间中净化任务向量。此外，还引入了一种通过优化归一化激活修剪误差来实现公平修剪的谱秩分配策略。

Result: PAVE作为一种即插即用方案，可以应用于各种基于任务向量的合并方法，以提高其性能。实验证明了PAVE在多种合并方法、任务和模型架构上的有效性。

Conclusion: PAVE通过在知识感知子空间中净化任务向量，有效解决了现有模型合并方法中由于冗余导致的性能下降问题，并能与其他模型合并方法兼容，提高其整体性能。

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [541] [ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning](https://arxiv.org/abs/2509.26255)
*Yichao Liang,Dat Nguyen,Cambridge Yang,Tianyang Li,Joshua B. Tenenbaum,Carl Edward Rasmussen,Adrian Weller,Zenna Tavares,Tom Silver,Kevin Ellis*

Main category: cs.AI

TL;DR: 该研究提出了一种用于长时序具身规划的框架，该框架能够同时学习符号状态表示和内源性动作及外源性机制的因果过程，以应对环境中并发发生的内源性动作和外源性过程的挑战。


<details>
  <summary>Details</summary>
Motivation: 长时序具身规划因环境中存在与智能体动作并发发生的外源性过程（如水加热、多米诺骨牌级联）而面临挑战。

Method: 提出了一种抽象世界模型框架，能够联合学习（i）符号状态表示和（ii）内源性动作及外源性机制的因果过程。每个因果过程都模拟了随机因果关系的演化过程。利用变分贝叶斯推理和大型语言模型（LLM）的建议，从有限的数据中学习这些世界模型。

Result: 所学的世界模型在五个模拟的桌面机器人环境中进行了测试，能够支持快速规划，并推广到具有更多对象和更复杂目标的新任务，其性能优于一系列基线方法。

Conclusion: 所提出的抽象世界模型框架能够有效应对长时序具身规划中的挑战，并通过联合学习内源性和外源性因果过程，显著提高了规划的速度和泛化能力。

Abstract: Long-horizon embodied planning is challenging because the world does not only
change through an agent's actions: exogenous processes (e.g., water heating,
dominoes cascading) unfold concurrently with the agent's actions. We propose a
framework for abstract world models that jointly learns (i) symbolic state
representations and (ii) causal processes for both endogenous actions and
exogenous mechanisms. Each causal process models the time course of a
stochastic cause-effect relation. We learn these world models from limited data
via variational Bayesian inference combined with LLM proposals. Across five
simulated tabletop robotics environments, the learned models enable fast
planning that generalizes to held-out tasks with more objects and more complex
goals, outperforming a range of baselines.

</details>


### [542] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: LLMs在推荐系统中表现出巨大潜力，但缺乏对地理实体和移动模式的理解。CoAST框架通过整合世界知识、时空轨迹模式、用户档案和情境信息来解决这些问题，并在离线和在线实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs在用于POI推荐时，缺乏对结构化地理实体和序列移动模式的原生理解。同时，在工业规模的应用中，整合世界知识（如季节、天气、节假日）和用户偏好（如习惯、职业）可以提升推荐性能和用户体验。

Method: CoAST框架包含两个主要阶段：1. 通过对用户时空轨迹数据进行持续预训练来获取推荐知识；2. 通过监督微调（SFT）和强化学习（RL）阶段，使用丰富化的训练数据来使认知判断与用户偏好保持一致。

Result: 通过在真实世界数据集上进行的大量离线实验以及在AMAP App“猜你去哪”首页的在线实验，证明了CoAST的有效性。

Conclusion: CoAST框架通过自然语言接口，有效整合了世界知识、时空轨迹模式、用户档案和情境信息，克服了现有LLMs在POI推荐任务中的局限性，并在实际应用中取得了显著效果。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [543] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: LLMs在作为自主代理方面展现出强大能力，函数调用是其与环境交互的核心。然而，推理扩展技术主要用于非结构化输出，在函数调用等结构化输出方面的应用尚待探索。本文提出了一个结合细粒度束搜索和过程奖励模型ToolPRM的推理扩展框架，用于改进LLM在函数调用任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有推理扩展技术主要关注非结构化输出，忽略了在函数调用等结构化输出中的应用，存在研究空白。

Method: 提出一个结合细粒度束搜索和过程奖励模型ToolPRM的推理扩展框架。ToolPRM通过对函数调用内部步骤进行评分，并利用自动标注的细粒度过程监督数据集进行训练，以提供步骤级奖励。

Result: 实验表明，ToolPRM在预测准确性上优于粗粒度和结果奖励模型，能有效监督函数调用推理过程。结合ToolPRM的推理扩展技术显著提升了模型在多种函数调用任务和基准测试中的表现。

Conclusion: 提出了一个有效的推理扩展框架ToolPRM，用于改善LLM在函数调用任务中的表现。并揭示了将推理扩展技术应用于结构化输出的关键原则：“多探索、少保留”，因为结构化函数调用生成过程不可恢复。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [544] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: RoboGPT-R1是一个用于具身规划的框架，通过监督学习和强化学习相结合，提高了机器人在复杂现实环境中的推理能力，并在EmbodiedBench基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于监督微调的大型语言模型和视觉语言模型在处理复杂的长期操作任务时，由于常识和推理能力受限，泛化性差且对物理世界的理解不足。

Method: 提出RoboGPT-R1两阶段微调框架，首先通过专家序列进行监督训练以获取基础知识，然后利用强化学习解决视觉空间理解和推理中的不足。设计了基于规则的奖励函数，同时考虑了长期性能和环境中的动作约束。

Result: 在EmbodiedBench基准测试中，使用Qwen2.5-VL-3B训练的RoboGPT-R1在性能上显著优于使用GPT-4o-mini的大模型（提升21.33%），并优于在Qwen2.5-VL-7B上训练的其他模型（提升20.33%）。

Conclusion: RoboGPT-R1框架通过结合监督学习和强化学习，并设计了特定的奖励函数，能够有效提升具身智能体的推理能力，在长期操作任务中表现出色，超越了现有的大模型和方法。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [545] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: RLVR方法倾向于过度开发而非探索，导致pass@1提高但pass@K（K>1）下降。SimKO通过不对称地调整概率来解决这个问题，在数学和逻辑推理基准上提高了pass@K性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在过度开发而非探索的系统性偏差，导致pass@1指标提升但pass@K（K>1）指标下降。

Method: 通过分析RLVR方法的训练动态，追踪了词汇候选的token级概率分布，发现了概率集中效应。基于此，提出了一种名为SimKO的简单pass@K优化方法，通过不对称地调整概率来缓解过度集中的问题，从而鼓励探索。具体来说，对于已验证正确的响应，SimKO会提升前K个候选的概率；对于已验证错误的响应，则会对排名第一的候选施加更强的惩罚。

Result: SimKO在数学和逻辑推理基准测试中，对各种K值都持续提高了pass@K性能。

Conclusion: SimKO是一种简单有效的方法，可以缓解RLVR中的过度集中问题，促进探索，并提高pass@K性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [546] [Agentic NL2SQL to Reduce Computational Costs](https://arxiv.org/abs/2510.14808)
*Dominik Jehle,Lennart Purucker,Frank Hutter*

Main category: cs.AI

TL;DR: LLM在处理SQL数据库元信息时存在长提示和高成本问题。Datalake Agent通过交互式循环和选择性信息请求，减少了87%的token使用量，实现了成本降低和性能维持。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言转换为SQL查询（NL2SQL）方面虽有进展，但在处理大量数据库元信息时会产生过长的提示和高昂的成本。

Method: Datalake Agent使用一种交互式循环机制，让LLM在解决表格问题问答任务时，仅选择性地请求必要的信息，而不是一次性处理所有元信息。

Result: 在23个数据库和100个表格问题问答任务的评估中，Datalake Agent将LLM使用的token数量减少了高达87%，显著降低了成本，同时保持了竞争力。

Conclusion: Datalake Agent通过智能地选择信息，有效解决了LLM在NL2SQL任务中面临的长提示和高成本问题，实现了效率和经济性的提升。

Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively requests only the necessary information to solve a
table question answering task. We evaluate the Datalake Agent on a collection
of 23 databases with 100 table question answering tasks. The Datalake Agent
reduces the tokens used by the LLM by up to 87\% and thus allows for
substantial cost reductions while maintaining competitive performance.

</details>


### [547] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: Instruction Boosting 是一种后生成方法，可提高 LLM 提示指令的可靠性，在 SCALEDIF 基准测试中，将指令遵循率最多提高了 7 个百分点。该方法还通过量化冲突评分工具来分析和解释指令增加时性能下降的趋势。


<details>
  <summary>Details</summary>
Motivation: 开发人员通常通过仔细操纵提示来影响 LLM 的行为，但仅添加更多指令并不能保证 LLM 会遵循这些指令。因此，需要一种能够提高 LLM 对提示指令遵循可靠性的方法。

Method: 引入 Instruction Boosting 作为一种后生成方法，并通过 SCALEDIF 基准测试（具有高达十个指令的缩放指令量）来展示其效果。此外，还开发了一种量化冲突评分工具来分析指令增加时性能下降的原因。

Result: Instruction Boosting 将指令遵循率提高了最多 7 个百分点（针对两个指令）和最多 4 个百分点（针对十个指令）。分析表明，指令之间的张力和冲突是导致指令数量增加时性能下降的重要因素。

Conclusion: Instruction Boosting 是一种有效的方法，可以提高 LLM 对指令的遵循能力，并且量化冲突评分工具可以帮助开发人员理解和缓解指令增加带来的性能下降问题。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [548] [LabOS: The AI-XR Co-Scientist That Sees and Works With Humans](https://arxiv.org/abs/2510.14861)
*Le Cong,Zaixi Zhang,Xiaotong Wang,Yin Di,Ruofan Jin,Michal Gerasimiuk,Yinkai Wang,Ravi K. Dinesh,David Smerkous,Alex Smerkous,Xuekun Wu,Shilong Liu,Peishan Li,Yi Zhu,Simran Serrao,Ning Zhao,Imran A. Mohammad,John B. Sunwoo,Joseph C. Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: LabOS是一个AI co-scientist，通过多模态感知、自演化代理和XR人机协作，将计算推理与物理实验相结合，加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 现代科学的进步需要理论与实践的结合。LabOS旨在将AI从单纯的计算设计提升到实际参与，使实验室成为人机协同发现的环境。

Method: LabOS通过连接多模态AI代理、智能眼镜和XR人机协作，使AI能够感知实验环境、理解实验背景，并实时协助执行。

Result: 在癌症免疫疗法靶点发现和干细胞工程等应用中，LabOS证明了AI可以超越计算设计，参与到实验过程中。

Conclusion: LabOS成功地将AI融入了物理实验，促进了人机协同的科学发现，加速了现代科学的进步。

Abstract: Modern science advances fastest when thought meets action. LabOS represents
the first AI co-scientist that unites computational reasoning with physical
experimentation through multimodal perception, self-evolving agents, and
Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model
AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see
what scientists see, understand experimental context, and assist in real-time
execution. Across applications--from cancer immunotherapy target discovery to
stem-cell engineering -- LabOS shows that AI can move beyond computational
design to participation, turning the laboratory into an intelligent,
collaborative environment where human and machine discovery evolve together.

</details>


### [549] [The Gatekeeper Knows Enough](https://arxiv.org/abs/2510.14881)
*Fikresilase Wondmeneh Abebayew*

Main category: cs.AI

TL;DR: LLM代理在与大型知识系统交互时，由于上下文窗口限制和状态不同步，面临不可靠输出、行为不可预测和资源利用效率低下等挑战。我们提出了Gatekeeper协议，一个新颖的、与领域无关的框架，用于管理代理-系统交互。该协议要求代理首先在一个极简的、低保真度的“潜在状态”表示上进行操作和推理，以按需策略性地请求高保真度上下文。所有交互都通过统一的JSON格式进行，该格式作为声明性的、状态同步的协议，确保代理对系统的模型在系统的现实中得到可验证的保证。我们通过Sage（Gatekeeper协议在软件开发中的参考实现）证明了该协议的有效性。结果表明，该方法显著提高了代理的可靠性，通过最小化令牌消耗提高了计算效率，并实现了与复杂系统的可扩展交互，为构建更健壮、可预测和有根据的AI代理奠定了基础。


<details>
  <summary>Details</summary>
Motivation: LLM代理在与大型知识系统（如代码库和文档）交互时，由于有限的上下文窗口和状态不同步，导致输出不可靠、行为不可预测和资源利用效率低下。这项工作旨在解决这些挑战。

Method: 提出Gatekeeper协议，一个管理LLM代理与系统交互的框架。该协议要求代理在系统的低保真度“潜在状态”表示上进行操作和推理，并按需请求高保真度上下文。所有交互都通过统一的JSON格式进行，以实现状态同步。

Result: Gatekeeper协议提高了代理的可靠性，通过最小化令牌消耗提高了计算效率，并实现了与复杂系统的可扩展交互。Sage（Gatekeeper协议在软件开发中的参考实现）证明了该协议的有效性。

Conclusion: Gatekeeper协议为构建更健壮、可预测和有根据的AI代理提供了一种基础方法，适用于任何结构化知识领域。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents,
yet their practical utility is fundamentally constrained by a limited context
window and state desynchronization resulting from the LLMs' stateless nature
and inefficient context management. These limitations lead to unreliable
output, unpredictable behavior, and inefficient resource usage, particularly
when interacting with large, structured, and sensitive knowledge systems such
as codebases and documents. To address these challenges, we introduce the
Gatekeeper Protocol, a novel, domain-agnostic framework that governs
agent-system interactions. Our protocol mandates that the agent first operate
and reason on a minimalist, low-fidelity "latent state" representation of the
system to strategically request high-fidelity context on demand. All
interactions are mediated through a unified JSON format that serves as a
declarative, state-synchronized protocol, ensuring the agent's model of the
system remains verifiably grounded in the system's reality. We demonstrate the
efficacy of this protocol with Sage, a reference implementation of the
Gatekeeper Protocol for software development. Our results show that this
approach significantly increases agent reliability, improves computational
efficiency by minimizing token consumption, and enables scalable interaction
with complex systems, creating a foundational methodology for building more
robust, predictable, and grounded AI agents for any structured knowledge
domain.

</details>


### [550] [Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates](https://arxiv.org/abs/2510.14900)
*Wen-Kwang Tsao,Yao-Ching Yu,Chien-Ming Huang*

Main category: cs.AI

TL;DR: 该研究提出了一种使用强化学习的智能代理，无需标注数据或模型权重更新，即可自动改进日志模式映射。该代理通过识别模糊映射、生成网络搜索查询和使用基于置信度的奖励来迭代优化映射。


<details>
  <summary>Details</summary>
Motivation: 在企业智能平台中，整合来自不同供应商的日志以执行下游任务至关重要，但供应商文档的缺失或不完整使得模式映射充满挑战。

Method: 提出了一种强化学习代理，该代理能够在推理过程中自行改进，无需标注数据或模型权重更新。具体步骤包括：1）识别模糊字段映射；2）生成定向网络搜索查询以收集外部证据；3）应用基于置信度的奖励来迭代优化映射。

Result: 通过将 Microsoft Defender for Endpoint 日志转换为通用模式，该方法将映射准确率从仅使用 LLM 的 56.4% 提高到检索增强生成 (RAG) 的 72.73%，再到使用 GPT-4o 100 次迭代后的 93.94%。同时，需要专家审查的低置信度映射数量减少了 85%。

Conclusion: 该研究提供了一种基于证据、透明的方法来解决日志模式映射问题，为未来更强大、可信、可扩展、高效、灵活、适应性强和协作的行业解决方案铺平了道路。

Abstract: The Enterprise Intelligence Platform must integrate logs from numerous
third-party vendors in order to perform various downstream tasks. However,
vendor documentation is often unavailable at test time. It is either misplaced,
mismatched, poorly formatted, or incomplete, which makes schema mapping
challenging. We introduce a reinforcement learning agent that can self-improve
without labeled examples or model weight updates. During inference, the agent:
1) Identifies ambiguous field-mapping attempts. 2) Generates targeted
web-search queries to gather external evidence. 3) Applies a confidence-based
reward to iteratively refine its mappings. To demonstrate this concept, we
converted Microsoft Defender for Endpoint logs into a common schema. Our method
increased mapping accuracy from 56.4\%(LLM-only) to 72.73\%(RAG) to 93.94\%
over 100 iterations using GPT-4o. At the same time, it reduced the number of
low-confidence mappings requiring expert review by 85\%. This new approach
provides an evidence-driven, transparent method for solving future industry
problems, paving the way for more robust, accountable, scalable, efficient,
flexible, adaptable, and collaborative solutions.

</details>


### [551] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 通过结合判别式验证和自洽性，提出了一种高效的测试时间缩放机制，在固定计算预算下，其性能优于最先进的生成式验证方法。


<details>
  <summary>Details</summary>
Motivation: 当前的测试时间缩放策略（如生成式验证）计算成本过高，限制了其实用性。需要更具成本效益的替代方案。

Method: 将判别式验证器与自洽性相结合，形成一种混合方法，并进行了广泛的实证分析。

Result: 在AIME2025数据集上，该混合方法在固定计算预算下，准确率比最先进的生成式验证方法高出15.3%。

Conclusion: 对于实际应用，基于预算的缩放方法，特别是结合判别式验证和自洽性的混合方法，是一种比昂贵的生成式技术更有效、更经济的替代方案。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [552] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 本文将康德的《纯粹理性批判》重新解读为一种反馈稳定性理论，认为理性是使推理保持在可能经验范围内的一种调节器。通过结合频谱裕度、条件性、时间敏感性和创新放大等因素，提出了一个复合不稳定性指数（H-Risk）。在模拟中，较高的H-Risk会预测过度自信的错误，即使在名义稳定性下，也揭示了名义稳定性和认知稳定性之间的差距。将此理论扩展到大型语言模型（LLMs），发现脆弱的内部动态与校准不足和幻觉相关，而批评式提示对校准和幻觉的影响则不一。这些结果表明，康德的自我限制与反馈控制之间存在结构性联系，为诊断和选择性地减少推理系统中的过度自信提供了一个原则性视角。


<details>
  <summary>Details</summary>
Motivation: 将康德的《纯粹理性批判》解读为一种反馈稳定性理论，并将理性视为一种调节器，以保持推理在可能经验的界限内。

Method: 通过一个复合不稳定性指数（H-Risk）来形式化这一观点，该指数结合了频谱裕度、条件性、时间敏感性和创新放大。

Result: 在长-高斯模拟中，较高的H-Risk预测了即使在名义稳定性下的过度自信错误，揭示了名义稳定性和认知稳定性之间的差距。在大型语言模型（LLMs）中，发现脆弱的内部动态与校准不足和幻觉相关，而批评式提示对校准和幻觉的影响不一。

Conclusion: 研究结果表明，康德的自我限制与反馈控制之间存在结构性联系，并为诊断和选择性地减少推理系统中的过度自信提供了一个原则性视角。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [553] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM通过结合MCTS、外部工具验证和混合奖励机制，实现了更准确、可扩展的LLM过程监督，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的过程奖励模型（PRMs）在构建高质量、可扩展的标注方面存在挑战，导致奖励信号不准确、事实保真度低以及与推理目标不一致。

Method: 引入GroundedPRM框架，采用MCTS构建结构化推理路径，利用外部工具验证中间步骤的正确性，并结合工具验证和MCTS反馈设计混合奖励聚合机制。

Result: GroundedPRM在仅使用10%的自动标注数据的情况下，在ProcessBench上取得了高达26%的相对性能提升，并且在奖励引导的贪婪搜索中优于使用人类标注数据训练的PRMs。

Conclusion: GroundedPRM提供了一种可扩展且可验证的途径，用于实现高质量的过程级推理，解决了现有PRM方法的局限性。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


### [554] [Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2509.25991)
*Haiyang Li,Yaxiong Wang,Shengeng Tang,Lianwei Wu,Lechao Cheng,Zhun Zhong*

Main category: cs.AI

TL;DR: 该论文构建了一个名为OmniFake的大规模数据集，包含12.7万条人工炮制的虚假信息和AI生成的欺骗性内容，并提出了一个名为UMFDet的统一框架，能同时检测这两种形式的虚假多模态内容，并在实验中表现优于现有专用方法。


<details>
  <summary>Details</summary>
Motivation: 目前，针对社交媒体上的人工虚假信息和AI生成内容的检测研究通常是分开进行的，导致现有模型只能处理其中一种类型的欺骗内容，在现实场景中效果受限。因此，需要一个能够同时处理这两种欺骗形式的统一模型。

Method: 构建了一个包含12.7万条样本的OmniFake数据集，整合了人工炮制和AI生成的多模态欺骗内容。在此基础上，提出了UMFDet框架，该框架利用视觉语言模型（VLM）作为骨干，并增强了一个类别感知混合专家（MoE）适配器来捕获特定类别的线索，同时引入了一个归因链式思考机制来提供隐式推理指导，以定位显著的欺骗信号。

Result: UMFDet框架在OmniFake数据集上进行了广泛的实验评估，结果表明该模型在两种类型的虚假信息上都取得了稳健且一致的性能，并且优于现有的专用基线模型。

Conclusion: UMFDet框架能够有效地同时检测人工虚假信息和AI生成内容，为现实世界中的多模态欺骗检测提供了实用的解决方案。

Abstract: In recent years, detecting fake multimodal content on social media has drawn
increasing attention. Two major forms of deception dominate: human-crafted
misinformation (e.g., rumors and misleading posts) and AI-generated content
produced by image synthesis models or vision-language models (VLMs). Although
both share deceptive intent, they are typically studied in isolation. NLP
research focuses on human-written misinformation, while the CV community
targets AI-generated artifacts. As a result, existing models are often
specialized for only one type of fake content. In real-world scenarios,
however, the type of a multimodal post is usually unknown, limiting the
effectiveness of such specialized systems. To bridge this gap, we construct the
Omnibus Dataset for Multimodal News Deception (OmniFake), a comprehensive
benchmark of 127K samples that integrates human-curated misinformation from
existing resources with newly synthesized AI-generated examples. Based on this
dataset, we propose Unified Multimodal Fake Content Detection (UMFDet), a
framework designed to handle both forms of deception. UMFDet leverages a VLM
backbone augmented with a Category-aware Mixture-of-Experts (MoE) Adapter to
capture category-specific cues, and an attribution chain-of-thought mechanism
that provides implicit reasoning guidance for locating salient deceptive
signals. Extensive experiments demonstrate that UMFDet achieves robust and
consistent performance across both misinformation types, outperforming
specialized baselines and offering a practical solution for real-world
multimodal deception detection.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [555] [Laser Fault Injection in Memristor-Based Accelerators for AI/ML and Neuromorphic Computing](https://arxiv.org/abs/2510.14120)
*Muhammad Faheemur Rahman,Wayne Burleson*

Main category: cs.ET

TL;DR: 激光注入故障可用于攻击基于忆阻器交叉阵列（MCA）的硬件，通过改变其输出电流分布来推断和篡改内部权重。


<details>
  <summary>Details</summary>
Motivation: 忆阻器交叉阵列（MCA）虽然在内存计算和神经形态硬件方面具有优势，但也存在易受攻击的物理特性，尤其是在故障注入场景下。

Method: 利用激光故障注入技术，通过HSPICE仿真在45nm CMOS技术节点的大规模MCA上进行实验，模拟激光诱导的光电流对输出电流分布的影响。

Result: 仿真结果表明，激光注入故障可在输出电流分布中产生可检测的扰动，通过差分故障分析，可以高达99.7%的准确率推断内部权重，并能通过定向权重修改来篡改模型，影响约为143%。

Conclusion: 该研究证明了激光注入故障攻击MCA的可行性，揭示了其在计算完整性方面的潜在风险，并强调了开发针对此类攻击的防御措施的必要性。

Abstract: Memristive crossbar arrays (MCA) are emerging as efficient building blocks
for in-memory computing and neuromorphic hardware due to their high density and
parallel analog matrix-vector multiplication capabilities. However, the
physical properties of their nonvolatile memory elements introduce new attack
surfaces, particularly under fault injection scenarios. This work explores
Laser Fault Injection as a means of inducing analog perturbations in MCA-based
architectures. We present a detailed threat model in which adversaries target
memristive cells to subtly alter their physical properties or outputs using
laser beams. Through HSPICE simulations of a large MCA on 45 nm CMOS tech.
node, we show how laser-induced photocurrent manifests in output current
distributions, enabling differential fault analysis to infer internal weights
with up to 99.7% accuracy, replicate the model, and compromise computational
integrity through targeted weight alterations by approximately 143%.

</details>
