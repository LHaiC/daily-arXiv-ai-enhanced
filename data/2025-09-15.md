<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 64]
- [cs.CL](#cs.CL) [Total: 52]
- [physics.app-ph](#physics.app-ph) [Total: 5]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 14]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.DS](#cs.DS) [Total: 3]
- [quant-ph](#quant-ph) [Total: 34]
- [eess.SP](#eess.SP) [Total: 12]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.SI](#cs.SI) [Total: 4]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.LG](#cs.LG) [Total: 51]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 10]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.NE](#cs.NE) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS是一个包含50个常见超市物品的3D模型数据集，用于机器人和计算机视觉基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有数据集依赖于合成模型或难以获得的物体，ASOS提供了常见、易于获取的物品，成本效益高。

Method: 使用结构from-motion技术和高分辨率成像技术生成了具有纹理的3D网格模型。

Result: ASOS数据集包含10个类别，50个物品，具有多样的形状、大小和重量，模型为防水网格。

Conclusion: ASOS数据集因其可及性和真实世界的适用性，非常适合用于物体检测、姿态估计和机器人应用的基准测试。

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [2] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 我们提出了一种新的多模态检索增强生成（MM-RAG）框架，用于在自然灾害后评估住房损失，该框架通过结合图像和文本信息，在检索准确性和损失分类方面取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 在自然灾害发生后，准确评估房屋损失对于处理保险索赔和规划资源至关重要。

Method: 我们引入了一种新颖的多模态检索增强生成（MM-RAG）框架，该框架在经典的RAG架构基础上，设计了一个两分支的多模态编码器结构。图像分支使用ResNet和Transformer提取灾后建筑损坏特征，文本分支使用BERT进行文本向量化（包括帖子和保险政策），并构建可检索的恢复索引。模型通过跨模态交互模块进行语义对齐，并使用模态注意力门控机制动态调整视觉证据和文本先验信息在生成中的作用。整个框架采用端到端训练，结合了比较损失、检索损失和生成损失进行多任务优化。

Result: 实验结果表明，该框架在检索准确性和损害严重性分类指数方面表现出色，其中Top-1检索准确率提高了9.6%。

Conclusion: 我们提出的MM-RAG框架能够有效地结合图像和文本信息，提高了自然灾害后住房损失评估的准确性，特别是在检索和分类任务上。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [3] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出了一种新的集成框架，用于稳定基于LLM的历史文献文本提取，使用Gemini 2.0 Flash和Needleman-Wunsch风格的比对器，在622条宾夕法尼亚州死亡记录数据集上，将准确性提高了4个百分点，并确定了最有用的数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 针对历史文献中的噪声问题，提高基于LLM的文本提取的稳定性与准确性。

Method: 使用Gemini 2.0 Flash转录图像的多种增强变体，并使用自定义的Needleman-Wunsch风格的比对器融合这些输出来获得共识转录和置信度得分。

Result: 在622条宾夕法尼亚州死亡记录数据集上，所提出的方法比单次运行基线提高了4个百分点的转录准确性。填充和模糊是最有效的提高准确性的方法，而网格变形最适合区分高置信度和低置信度的情况。

Conclusion: 所提出的方法简单、可扩展，并可立即部署到其他文档集合和转录模型中，有效解决了历史文献的文本提取问题。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [4] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 该论文提出了MITS，一个专门为智能交通监控（ITS）领域设计的大规模多模态基准数据集，包含了170,400张真实世界的ITS图像和相应的注释、图像描述以及视觉问答对，旨在解决ITS领域缺乏专用多模态数据集的问题。通过在该数据集上微调主流的大型多模态模型（LMMs），实验证明MITS显著提高了LMM在ITS应用中的性能。


<details>
  <summary>Details</summary>
Motivation: 智能交通监控（ITS）领域缺乏专门的多模态数据集，限制了大型多模态模型（LMMs）在该领域的性能发挥。

Method: 创建了一个名为MITS的大规模多模态基准数据集，包含170,400张ITS图像，并标注了8个主要类别和24个子类别的ITS特定对象和事件。同时，生成了高质量的图像描述和500万个视觉问答对，涵盖了对象识别、计数、定位、背景分析和事件推理五个关键ITS任务。最后，在MITS数据集上对主流LMMs进行了微调，以评估数据集的有效性。

Result: 在MITS数据集上微调后，LLaVA-1.5的性能从0.494提升至0.905（+83.2%），LLaVA-1.6从0.678提升至0.921（+35.8%），Qwen2-VL从0.584提升至0.926（+58.6%），Qwen2.5-VL从0.732提升至0.930（+27.0%），显著证明了MITS数据集的有效性。

Conclusion: MITS作为首个大规模ITS多模态基准数据集，通过提供丰富的标注数据和实例，有效提升了LMM在ITS领域的性能，为该领域的研究和应用提供了宝贵的资源。研究团队已将数据集、代码和模型开源，以促进ITS和LMM的共同发展。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [5] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 结构化推理在视觉分类任务上表现不佳，但描述的增强可以提高性能。


<details>
  <summary>Details</summary>
Motivation: 评估结构化、基于树的推理能否提高视觉语言模型（VLM）在细粒度任务和大型分层标签空间上的性能。

Method: 提出一个使用决策树将分类分解为可解释决策的框架，并在细粒度（GTSRB）和粗粒度（CIFAR-10）数据集上进行评估。还探索了使用LLM生成的类别和图像描述来增强树提示。

Result: 在GTSRB和CIFAR-10数据集上，基于树的推理性能始终低于标准的零样本提示。然而，添加的描述可以提高基于树和零样本方法的性能。模型在理解树知识方面达到了98.2%的准确率。

Conclusion: 结构化推理在视觉分类任务中存在局限性，但添加的描述可以提高VLM的性能。这为设计更具可解释性的VLM系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [6] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一个用于从数据中学习可控、可提示的世界模型系统。


<details>
  <summary>Details</summary>
Motivation: 从数据中学习丰富可控、灵活可提示的世界模型。

Method: PSI包含三个步骤：1. 概率预测：构建数据图模型Psi（随机访问自回归序列模型）。2. 结构提取：通过因果推断从Psi中提取有意义的“中间结构”。3. 集成：将提取的结构转换为新的标记类型，并混合回训练数据。每个周期都会增强Psi的能力，提升数据建模能力并创建新的控制柄。

Result: 在1.4万亿个互联网视频标记上训练了Psi实例，并执行了有用的视频预测和理解推理。提取了最先进的光流、自监督深度和对象分割。

Conclusion: 通过使用提取的结构支持预测改进的完整周期，证明了PSI的有效性。

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [7] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 联邦学习（FL）允许多个参与方协作训练共享模型，但梯度反演攻击可能从共享梯度中恢复私有训练数据，威胁FL的隐私保护。本文首次分析了FL中视频数据的梯度反演攻击泄露问题，并评估了两种视频分类方法。结果表明，使用特征提取器比处理原始视频帧更能抵抗攻击，但如果分类器复杂度不足，仍可能发生数据泄露。此外，图像超分辨率技术可以提高攻击者重建视频的质量。研究证实，FL中的视频数据泄露是一个实际威胁。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）的隐私保护机制（仅交换模型更新而非原始数据）受到梯度反演攻击的威胁，该攻击可以从共享梯度中逆向工程出私有训练数据。然而，对于视频数据，此类攻击的影响尚未得到充分研究，因此有必要进行分析。

Method: 本文评估了两种常见的视频分类方法（使用预训练特征提取器和处理原始视频帧）在FL中的梯度反演攻击泄露情况。研究还评估了图像超分辨率技术在不同参考帧可用性场景下对攻击效果的增强作用。

Result: 使用特征提取器的方法比处理原始视频帧的方法更能抵抗梯度反演攻击。图像超分辨率技术可以提高攻击者通过梯度反演攻击重建的视频帧质量。即使使用特征提取器，如果分类器复杂度不足，仍然可能发生数据泄露。

Conclusion: 联邦学习中的视频数据泄露是一个实际存在的威胁。尽管特征提取器可以增加攻击的难度，但在某些条件下（如分类器复杂度低）仍然可能发生数据泄露。因此，需要进一步研究视频数据泄露发生的条件。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [8] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 本研究提出了一种半监督协同训练框架，用于解决零售环境中目标检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 零售环境中的目标检测面临数据标注有限和复杂场景（如遮挡、重叠）的挑战，需要一种能提高精度并减少标注成本的方法。

Method: 该框架结合了Faster R-CNN（用于精确定位）和YOLO（用于全局上下文），通过互惠的伪标签交换来提高对遮挡和重叠物体的检测能力。同时，集成了XGBoost、随机森林和SVM等分类器以增强分类鲁棒性，并使用元启发式算法优化超参数。

Result: 在SKU-110k数据集上的实验表明，该框架在密集零售环境中表现出色，能够有效处理遮挡和重叠的物体。

Conclusion: 所提出的半监督协同训练框架通过减少对手动标注的依赖，降低了标注成本，并能有效适应零售环境中常见的商品和布局变化，在自动库存跟踪、商品监控和结账系统等实际应用中具有很高的可扩展性和实用性。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [9] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了一种名为Token Purging (PG) 的新型测试时间自适应（TTA）方法，用于解决3D点云分类中因分布变化导致的的性能下降问题。PG在反向传播之前，通过移除受领域变化影响较大的token来工作，实现了无需迭代更新的鲁棒自适应。


<details>
  <summary>Details</summary>
Motivation: 测试时间自适应（TTA）对于减轻3D点云分类中由分布变化引起性能下降至关重要。

Method: 提出了一种名为Token Purging (PG) 的新型反向传播式方法，该方法在token级别操作，通过在token到达注意力层之前移除受领域变化影响较大的token来实现鲁棒自适应，无需迭代更新。提出了两种变体：PG-SP（利用源域统计）和PG-SF（完全无源域，依赖CLS-token驱动的自适应）。

Result: 在ModelNet40-C、ShapeNet-C和ScanObjectNN-C上的广泛评估表明，PG-SP的准确率比最先进的反向传播式方法平均高出+10.3%，而PG-SF在无源域自适应方面设定了新的基准。此外，PG比基线方法快12.4倍，内存效率高5.5倍。

Conclusion: PG是一种高效且有效的TTA方法，特别适用于3D点云分类，能够显著提高在存在分布变化时的模型性能，并且非常适合实际部署。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [10] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 通过匹配地面图像和参考航拍图像的局部特征，提出一种精确且可解释的跨视图精细化定位方法，直接建立地面和航拍图像间的对应关系，并利用单目深度先验将匹配的关键点提升至BEV空间，解决了传统方法中BEV转换信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法将地面图像转换为BEV表示再与航拍图像对齐，常因透视畸变或高度信息压缩导致信息丢失，降低了与航拍视图的对齐质量。

Method: 直接建立地面和航拍图像间的对应关系，并利用单目深度先验将匹配的关键点提升至BEV空间；采用尺度感知Procrustes对齐来估计相机位姿，并支持度量深度和相对深度，可选地恢复尺度。

Result: 在仅有弱相机位姿监督的情况下，学习精确的局部特征对应关系，在跨区域泛化和未知方向等挑战性条件下实现了卓越的定位性能。

Conclusion: 该方法能够学习精确的局部特征对应关系，并在具有挑战性的条件下实现卓越的定位性能。此外，该方法与各种相对深度模型兼容，无需进行逐模型微调，非常适合实际部署。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [11] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 该研究介绍了一款名为KidsVisionCheck的免费应用程序，该程序利用智能手机和深度神经网络，通过红眼反射图像对儿童进行视力筛查，准确率达到90%，有望实现全球范围内便捷的儿童视力筛查和早期干预。


<details>
  <summary>Details</summary>
Motivation: 许多视觉障碍可以在幼儿的红眼反射图像中被检测到。传统的Bruckner测试需要在临床环境中由眼科医生进行。由于智能手机和人工智能技术的进步，现在可以使用移动设备重新创建Bruckner测试。

Method: 开发了一款名为KidsVisionCheck的免费应用程序，利用智能手机和深度神经网络，对眼科医生收集和标记的儿童瞳孔图像进行训练，以进行视力筛查。

Result: 该模型在未见过的数据上达到了90%的准确率，无需专业设备即可提供高度可靠的性能。此外，研究还确定了数据收集的最佳条件，并能为用户提供即时反馈。

Conclusion: 这项工作是实现可及的儿童视力筛查和全球范围内视力异常早期干预的第一步。

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [12] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: DGFusion是一种新的深度引导多模态融合方法，通过整合深度信息来提升条件感知融合，以解决传感器融合在具有挑战性的条件下性能受限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的传感器融合方法在处理具有挑战性的条件时，由于将传感器数据在空间范围内进行均匀处理，会阻碍性能的提升。

Method: DGFusion将多模态分割视为一个多任务问题，利用激光雷达测量作为模型输入和学习深度的地面真实。它还包括一个辅助深度头，用于学习深度感知特征，这些特征被编码成空间变化的局部深度令牌，以条件化注意力跨模态融合。此外，还提出了一种用于深度学习的鲁棒损失函数，以应对激光雷达输入在不利条件下稀疏且嘈杂的问题。

Result: 该方法在具有挑战性的MUSES和DELIVER数据集上实现了最先进的全景和语义分割性能。

Conclusion: DGFusion通过利用深度信息，动态地适应传感器融合，以适应场景中每个传感器在空间上变化的可靠性，从而显著提高了自动驾驶车辆的语义感知能力。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [13] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 本研究提出基于ResNet-18的斑块化自动诊断玫瑰痤疮策略，无需使用完整人脸图像，即可实现高准确率、高敏感性，并保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 玫瑰痤疮是一种慢性炎症性皮肤病，早期精确检测对提高疗效至关重要。

Method: 本研究提出新的斑块化自动诊断玫瑰痤疮策略，采用ResNet-18深度学习框架。通过提取不同大小、形状和位置的面部图像斑块，并研究局部视觉信息对模型性能的影响。

Result: 实验结果表明，所提出的斑块化策略在准确率和敏感性方面，能够达到与完整图像相当甚至更优的性能，并能保护患者隐私。

Conclusion: 所提出的斑块化策略能引导深度学习模型关注临床相关区域，增强鲁棒性和可解释性，同时保护患者隐私，为改善自动化皮肤病诊断提供了实用的见解。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [14] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的隐私保护型面部红斑痤疮（rosacea）自动检测方法，该方法利用临床先验知识，在完全合成的数据上进行训练，并取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 红斑痤疮是一种常见但漏诊率高的炎症性皮肤病，其症状弥漫，难以自动检测。此外，由于涉及可识别的面部图像，数据隐私问题也带来了挑战。

Method: 该方法首先通过选择面部图像中红色通道强度一致较高的区域来构建一个固定的、与红斑信息相关的面部掩码，从而聚焦于诊断相关的区域（如脸颊、鼻子、额头），并排除泄露身份的信息。然后，在掩码处理过的合成图像上训练ResNet-18深度学习模型。

Result: 与在全脸图像上训练的模型相比，该方法在真实世界测试数据上的准确率、召回率和F1分数均有显著提高。

Conclusion: 实验结果表明，合成数据和临床先验知识的结合可以实现准确且合乎道德的皮肤病学人工智能系统，特别适用于远程医疗和大规模筛查等注重隐私的场景。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [15] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文通过消融实验评估了U-Net骨干、复合损失函数（MSE、SSIM、感知损失）以及可学习维纳滤波器在腹腔镜图像去烟方面各自的贡献。


<details>
  <summary>Details</summary>
Motivation: 为了严格评估U-Net骨干、复合损失函数（MSE、SSIM、感知损失）以及可学习维纳滤波器在腹腔镜图像去烟方面各自的有效性和必要性。

Method: 通过系统地移除或选择性地使用框架的各个组件（例如，移除可学习维纳滤波器，单独使用复合损失函数中的各项损失），并使用定量指标（SSIM、PSNR、MSE、CIEDE-2000）和定性视觉比较，在公开的配对腹腔镜图像数据集上对所有变体进行了基准测试。

Result: 实验结果（未在此摘要中详细说明）将展示各个组件对整体性能的贡献。

Conclusion: 消融研究的结果将阐明ULW框架中每个组件的必要性和重要性，为未来的模型改进提供指导。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [16] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: 本研究提出了一种结合可见光RGB和声学信号的多模态WAVE-DETR无人机检测器，用于鲁棒的现实世界UAV目标检测。


<details>
  <summary>Details</summary>
Motivation: 为了在具有挑战性的环境条件下提高无人机目标检测的性能，特别是针对不同尺寸的无人机。

Method: 融合了基于Deformable DETR和Wav2Vec2架构的视觉和声学特征，并开发了四种基于门控机制、线性层、MLP和交叉注意力的融合配置。

Result: 所提出的WAVE-DETR无人机检测器，特别是采用门控融合方法的配置，在ARDrone数据集上，对于小尺寸无人机的mAP在所有IoU阈值下提高了11.1%至15.3%，中型和大型无人机的mAP也得到了提升，所有无人机尺寸的整体增益范围为3.27%至5.84%。

Conclusion: 融合声学信息可以显著提高Deformable DETR目标检测器在ARDrone数据集上的性能，其中门控融合方法效果最佳。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [17] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [18] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 本研究提出了一种结合卷积自编码器（AE）和视觉Transformer（ViT）的框架，用于提高牙科年龄估计的性能和透明度，解决了深度学习在法医应用中的‘黑箱’问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在法医牙科年龄估计等高风险应用中受到‘黑箱’问题的限制，需要提高模型性能和透明度。

Method: 结合卷积自编码器（AE）和视觉Transformer（ViT）构建框架，并分析AE的潜在空间指标和图像重建，以诊断性能差距的原因。

Result: 该框架将牙齿37的分类准确率从0.712提高到0.815，将牙齿38的准确率从0.462提高到0.543。分析表明，牙齿38数据集的类内形态变异性是限制性能的主要因素。

Conclusion: 单一的可解释性模式（如注意力图）不足以识别潜在的数据问题。本研究提出的框架在提高准确性的同时，提供了模型不确定性的证据，为法医年龄估计提供了更可靠的工具。

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [19] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: SFDA通常依赖于有监督的预训练模型，并通过对齐实例级特征来蒸馏知识，但这会丢失重要的几何信息。SCoDA通过使用自监督学习（SSL）初始化教师模型，并引入空间相似性损失来对齐几何流形，解决了这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有的SFDA方法在对齐实例级特征时会丢失关键的几何信息。

Method: SCoDA采用自监督学习（SSL）进行初始化，并结合实例级特征匹配和空间相似性损失进行训练。教师模型通过指数移动平均（EMA）更新以防止灾难性遗忘。

Result: SCoDA在基准数据集上的实验结果显著优于当前最先进的SFDA方法。

Conclusion: SCoDA通过自监督初始化和几何流形对齐，在SFDA任务上取得了SOTA性能。

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [20] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 提出了一种零样本细胞跟踪框架，集成了Segment Anything 2（SAM2）来处理显微镜图像序列中的细胞跟踪和有丝分裂事件检测问题，无需手动标注即可实现跨数据集的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的方法需要手动标注的数据集进行训练，成本高昂且耗时，泛化能力有限。而本文提出的方法旨在克服这些限制。

Method: 将Segment Anything 2（SAM2）集成到跟踪流程中，构建了一个完全无监督的零样本细胞跟踪框架，无需任何特定训练数据集的依赖或继承其偏见。

Result: 该方法在2D和大规模3D延时显微镜视频中均取得了具有竞争力的准确性，无需针对特定数据集进行调整。

Conclusion: 所提出的零样本跟踪框架通过集成SAM2，成功解决了显微镜图像中细胞跟踪和有丝分裂检测的挑战，实现了无需微调即可在不同数据集上进行泛化的目标，并达到了具有竞争力的准确性。

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [21] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 该研究提出了一种将现有的2D多摄像头跟踪系统扩展到3D空间的方法，通过利用深度信息重建目标，并进行聚类和偏航角优化来恢复其3D边界框。研究还引入了一种增强的在线数据关联机制，利用目标的局部ID一致性来分配全局ID。


<details>
  <summary>Details</summary>
Motivation: 现有的2D多摄像头跟踪系统在扩展到3D空间时面临挑战，需要从头开始替换所有2D跟踪组件，这可能不可行。

Method: 利用深度信息将目标投影到3D空间，并通过点云空间重建、聚类和偏航角优化来恢复目标的3D边界框。引入了增强的在线数据关联机制，利用目标局部ID一致性进行全局ID分配。

Result: 在2025 AI City Challenge的3D MTMC数据集上进行了评估，取得了第三名的成绩。

Conclusion: 所提出的方法能够有效地将2D多摄像头跟踪系统扩展到3D空间，并在3D多目标多摄像头跟踪任务上取得了良好的性能。

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [22] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 无需针对 referring expression comprehension (REC) 进行专门训练，即可通过零样本方法在各项基准测试中取得具有竞争力的甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 与通常使用经过任务训练的接地模型来解决 Referring Expression Comprehension (REC) 问题不同，本研究旨在探索一种不经过任何 REC 特定训练的零样本方法，以达到同等或更优的性能。

Method: 将 REC 重新构想为逐个区域的视觉-语言验证任务。具体而言，利用来自通用的 YOLO-World 检测器的区域建议，并让一个通用的视觉-语言模型（VLM）独立地对每个建议区域回答“真/假”查询。

Result: 在 RefCOCO、RefCOCO+ 和 RefCOCOg 数据集上，本方法不仅优于零样本 GroundingDINO 基线，而且超过了在 REC 上训练的 GroundingDINO 和 GroundingDINO+CRG 的报告结果。通过控制实验（使用相同的区域建议）证明，逐个区域的验证方法显著优于基于选择的提示方法，并且该方法在开放域的 VLM 上也表现良好。

Conclusion: 研究表明，零样本 REC 的高性能主要得益于工作流程的设计，而非特定任务的预训练。

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [23] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种随机投影粘贴（RPCP）数据增强技术，以解决小麦叶部病虫害分割中极端像素不平衡的问题，显著提升了对虫害类别的分割性能，同时保持了对其他类别的准确性。


<details>
  <summary>Details</summary>
Motivation: 小麦叶部病虫害分割中的极端像素不平衡问题，即虫害区域像素占比极小，导致模型过拟合常见类别，忽视稀有类别，影响整体性能。

Method: 提出随机投影粘贴（RPCP）数据增强技术。具体方法包括：提取稀有虫害斑块，进行随机几何变换；将变换后的斑块粘贴到合适区域，避免重叠；对粘贴区域应用随机投影滤波，优化局部特征并使其与背景融合。

Result: RPCP方法显著提高了虫害类别的分割性能，同时保持甚至略微提高了其他类别的准确性。

Conclusion: 目标明确的数据增强方法能有效缓解极端像素不平衡问题，为农业分割问题提供了一种简单而有效的解决方案。

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [24] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 现有的长期多目标跟踪（MOT）方法由于身份切换问题，跟踪性能会随时间下降，难以满足长时跟踪需求。本文提出了一种结合不确定身份与跟踪的隐马尔可夫模型（HMM）框架，以解决长时 MOT 的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法在长期跟踪时，由于身份切换问题，性能会下降。许多实际应用（如畜牧业）可以从饲喂器等来源获得动物的零星身份信息。因此，需要一种能够处理不确定身份信息的长期MOT方法。

Method: 提出了一种结合不确定身份与跟踪的隐马尔可在模型（HMM）框架。该框架利用零星的身份信息来提高跟踪性能。

Result: 在为期10分钟、包含21个身份识别的猪跟踪数据集上，该HMM框架将领先的MOT方法ByteTrack的F1分数提高了10%。此外，该方法在MOT17和MOT20基准数据集上使用ByteTrack和FairMOT进行了验证，并证明了其对身份识别不确定性的鲁棒性。

Conclusion: 所提出的HMM框架能够有效解决长期多目标跟踪中的身份切换问题，尤其是在身份信息不确定或稀疏的情况下。该方法不仅提高了跟踪性能，而且为畜牧业等领域的应用提供了新的解决方案。

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [25] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 本文对事件相机与传统帧式相机融合技术在视频复原和三维重建任务中的应用进行了综述，重点关注了深度学习在该领域的贡献，并整理了相关公开数据集。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其低延迟、低功耗和高帧率等特性，在视频复原和三维重建等任务中展现出巨大潜力，与传统帧式相机的融合更是能显著提升性能。

Method: 本文系统地回顾了深度学习在图像/视频增强和复原领域的贡献，从时间增强（如帧插值、运动去模糊）和空间增强（如超分辨率、低光和HDR增强、伪影消除）两个维度进行了梳理。同时，探讨了事件驱动融合技术在三维重建领域的发展。

Result: 该综述深入探讨了在挑战性条件下提升视觉质量的最新研究进展，并汇集了可公开获取的数据集，以促进可复现的研究和基准测试。

Conclusion: 通过整合近期在事件相机融合、深度学习以及视觉媒体复原和增强领域的进展与见解，本文旨在激发更多相关研究。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [26] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是首个结合Transformer和ISTA适配器的RGB-Event跟踪器，通过融合RGB图像和事件流的特征，在多个基准测试中取得了最先进的性能和高能效。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-Event跟踪方法难以充分利用事件流的稀疏和异步特性，并且在融合不同范式（ANN和SNN）的特征时存在挑战。

Method: 提出了一种名为ISTASTrack的混合模型，它结合了用于RGB输入的视觉Transformer和用于事件流的脉冲Transformer。通过设计基于ISTA适配器的双向特征交互机制，并引入时间降采样注意力模块来对齐多步SNN特征和单步ANN特征，实现了跨模态和跨范式的特征融合。

Result: 在FE240hz、VisEvent、COESOT和FELT等RGB-Event跟踪基准测试中，ISTASTrack实现了最先进的性能，同时保持了高能效。

Conclusion: ISTASTrack的混合ANN-SNN设计在鲁棒的视觉跟踪方面是有效且实用的。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [27] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 我们提出了一种基于多重深度状态空间模型的方法，并引入了FLARE loss来解决太阳耀斑类别不平衡的问题，从而提高了预测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 目前的太阳耀斑预测模型在处理类别不平衡问题时表现不佳，影响了预测的准确性和可靠性。

Method: 提出一种基于多重深度状态空间模型的太阳耀斑预测模型，并引入频率与局部边界感知可靠性损失（FLARE loss）来处理类别不平衡问题。

Result: 该方法在以Gandin-Murphy-Gerrity分数和真实技能统计量为标准的实验中，优于现有基线方法。

Conclusion: 所提出的基于多重深度状态空间模型和FLARE loss的方法能够有效提高太阳耀斑预测的性能和可靠性，尤其是在处理类别不平衡的情况下。

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [28] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 该论文提出了一种高效精确的视觉惯性里程计（VIO）流程，针对微型和纳米无人机进行了优化，适用于低功耗RISC-V SoC。


<details>
  <summary>Details</summary>
Motivation: 为了弥合传统高精度VIO系统和适用于微控制器的轻量级实现之间的差距，特别是在微型和纳米无人机应用场景下。

Method: 该方法采用先进的特征检测和跟踪技术（SuperPoint、PX4FLOW、ORB），并针对RISC-V低功耗并行系统进行了优化和量化。通过使用刚体运动模型，减少了估计误差，提高了平面运动场景的精度。在低功耗SoC上进行了实时评估。

Result: 在GAP9低功耗SoC上，与基线流程相比，使用ORB特征跟踪器可将RMSE平均降低高达3.65倍。PX4FLOW在低于24像素/帧的移动速度下，实现了与ORB相当的跟踪精度，但运行时更低。

Conclusion: 所提出的VIO流程在低功耗硬件上实现了高效且精确的运动估计，为资源受限的无人机应用提供了可行的解决方案。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [29] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一个创新的RGB-T语义分割模型，通过统一的多模态特征提取和融合，以及轻量化的热成像分支，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T语义分割模型在处理复杂环境时受限于热成像特征提取不足和跨模态融合不佳，同时冗余编码器也影响了实时性。

Method: 提出TUNI模型，采用RGB-T编码器同时进行多模态特征提取和跨模态融合，并利用大规模预训练数据进行训练。通过精简热成像分支实现模型轻量化，并引入RGB-T局部模块，利用自适应余弦相似度增强跨模态局部特征融合。

Result: TUNI在FMB、PST900和CART数据集上取得了与最先进模型相当的性能，同时参数量更少，计算成本更低。在Jetson Orin NX上实现了27 FPS的推理速度，证明了其部署的实时性。

Conclusion: TUNI通过统一特征提取与融合、轻量化设计和增强局部特征融合，有效解决了现有RGB-T语义分割模型的局限性，实现了高性能和高效率。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [30] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 该模型提出了一种新颖的少样本字体生成方法，仅需部分形状即可生成整个字体，提高了效率并揭示了部分设计细节对整体字形结构的影响。


<details>
  <summary>Details</summary>
Motivation: 与需要完整字符形状的传统少样本字体生成不同，本文提出了一种仅需部分形状作为输入的新颖模型，旨在提高字体创建效率并探究部分设计细节对单个字符整体结构的影响。

Method: 提出了一种少样本字体生成模型，该模型基于一组部分设计元素（即部分形状）来设计整个字体。

Result: 该方法能够基于部分形状生成整个字体，提高了字体创建的效率。

Conclusion: 该模型不仅提高了字体创建的效率，还为部分设计细节如何影响单个字符的整体结构提供了见解。

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [31] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出一种名为MLANet的卷积神经网络模型，用于从单张野外图像中重建3D人脸模型，该模型能够预测详细的面部几何、纹理、姿态和光照参数。方法上，采用了预训练的骨干网络和多层次注意力机制，并结合3DMM参数和可微分渲染器进行半监督端到端训练。实验在AFLW2000-3D和MICC Florence数据集上进行，并在3D人脸重建和3D人脸对齐任务上进行了量化和质化评估。


<details>
  <summary>Details</summary>
Motivation: 从2D野外图像恢复3D人脸模型因其广泛的应用前景而备受关注，但缺乏真实标记数据集和真实世界环境的复杂性带来了挑战。

Method: 提出一种名为MLANet的卷积神经网络，采用预训练的层级骨干网络，并在2D人脸图像特征提取的不同阶段引入多层次注意力机制。通过结合3D Morphable Model（3DMM）参数和可微分渲染器，采用半监督学习策略进行端到端训练。

Result: 在AFLW2000-3D和MICC Florence数据集上进行了广泛的实验，包括比较研究和消融研究，在3D人脸重建和3D人脸对齐任务上进行了量化和质化评估，证明了所提方法的有效性。

Conclusion: 所提出的MLANet模型通过利用多层次注意力机制和半监督学习策略，能够有效地从单张野外图像中重建出详细的3D人脸模型，解决了现有方法的挑战。

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [32] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT 是一个语言感知的视觉链式思考框架，通过多阶段推理和多方面奖励优化，提升了多语言视觉问答能力，在多项基准测试和实际应用中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在多语言视觉问答方面虽然有所进步，但主要依赖文本链式思考，对多语言多模态推理的支持有限，限制了其在现实世界中的应用。因此，需要一个能够处理多语言、多模态信息的链式思考框架。

Method: LaV-CoT 框架包含一个多阶段推理流程，包括带边界框（BBox）的文本摘要、语言识别、空间对象级字幕生成和逐步逻辑推理。此外，它还设计了一种自动数据整理方法来生成多语言链式思考标注，并通过监督微调（SFT）和语言感知的组相对策略优化（GRPO）两阶段进行训练，以语言一致性、结构准确性和语义对齐等可验证的多方面奖励作为指导。

Result: LaV-CoT 在 MMMB、Multilingual MMBench 和 MTVQA 等公共数据集上取得了显著的性能提升，准确率比同等规模的开源基线模型高出约 9.5%，甚至超过了规模大两倍的模型约 2.6%。同时，LaV-CoT 的表现优于 GPT-4o-0513 和 Gemini-2.5-flash 等先进的专有模型。在线 A/B 测试也验证了该方法在工业部署中的有效性。

Conclusion: LaV-CoT 成功地解决了现有方法在多语言多模态推理方面的局限性，通过其创新的链式思考框架和训练范式，显著提高了视觉问答的准确性和泛化能力，并证明了其在实际应用中的价值。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [33] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 该研究提出了一种训练无关的框架，利用大型语言模型（LLM）来消除歧义的颜色词汇，并直接在文本嵌入空间中指导颜色混合操作，以提高文本到图像生成中颜色对齐的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在处理细致和复合的颜色词汇时存在困难，导致生成的图像与用户意图不符，尤其是在时尚、产品可视化和室内设计等应用中。

Method: 该框架首先使用大型语言模型（LLM）来解析文本提示中模糊的颜色词汇，然后根据所得颜色词汇在CIELAB颜色空间中的空间关系来优化文本嵌入。该方法在文本嵌入空间中进行操作，并且不需要额外的训练或参考图像。

Result: 实验结果表明，该框架在不损害图像质量的情况下提高了颜色对齐的准确性，有效弥合了文本语义与视觉生成之间的差距。

Conclusion: 该研究提出的训练无关框架通过LLM消除了颜色词汇的歧义，并直接在文本嵌入空间中进行颜色混合，显著提高了文本到图像生成中的颜色准确性，无需额外训练或参考图像。

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [34] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: 该研究提出了AVI-Math，一个用于评估无人机（UAV）图像中多模态数学推理的基准，并测试了14种主流视觉语言模型（VLMs），发现它们在处理这类任务时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在处理无人机（UAV）相关的精确计算、轨迹估计和空间分析等数学推理任务方面能力不足，因此需要建立一个专门的基准来评估和改进这一领域。

Method: 构建了一个包含3,773个无人机视角下的数学推理问题的AVI-Math数据集，涵盖几何、逻辑、代数等6个数学科目和20个主题。对14种主流VLMs进行了基准测试，并探索了思维链（Chain-of-Thought）提示和微调技术。

Result: 在AVI-Math基准测试中，14种主流VLMs在数学推理任务上表现不佳，暴露了它们在该领域能力的显著局限性。思维链提示和微调技术显示出一定的改进潜力。

Conclusion: 当前的VLMs在处理无人机图像中的数学推理任务方面存在局限性，需要进一步的研究来提升其能力，以满足真实世界应用中对可信赖VLMs的需求。AVI-Math数据集和相关代码将公开。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [35] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一个新颖的鸟瞰图轨迹预测框架，它利用实时传感器数据直接在鸟瞰图空间中操作，无需预建地图，并取得了与最先进的基于高清地图的模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶轨迹预测方法依赖高精度地图或局部地图构建模块，但这些方法存在区域限制、无法适应瞬态变化、可能遗漏关键场景细节或引入错误等缺点。

Method: 提出了一种名为BEVTraj的新型鸟瞰图轨迹预测框架。该框架直接在鸟瞰图空间中操作，利用实时传感器数据，无需预建地图。BEVTraj采用可变形注意力机制来有效提取密集的鸟瞰图特征中的相关上下文信息。此外，还引入了一个稀疏目标候选点生成（SGCP）模块，实现了无需任何后处理步骤的全端到端预测。

Result: 实验结果表明，BEVTraj在性能上可与最先进的基于高清地图的模型相媲美，同时通过消除对预建地图的依赖而提供了更大的灵活性。

Conclusion: BEVTraj通过在鸟瞰图空间中直接操作并利用可变形注意力和SGCP模块，克服了现有轨迹预测方法的局限性，实现了高性能和高灵活性。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [36] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 提出了一种利用多视角信息来改进遮挡场景下多人物分割模型的新颖训练框架。


<details>
  <summary>Details</summary>
Motivation: 现有先进的多人物分割方法在处理身体重叠的人时表现不佳。

Method: 提出了一种基于人体实例弱监督和多视角一致性损失的新方法，并结合半自动标注策略来生成训练数据。

Result: 在遮挡场景下，相比基线模型，该方法在人物分割方面取得了高达 4.20% 的相对改进。

Conclusion: 利用多视角信息和新颖的训练框架能够有效提升遮挡场景下多人物分割的性能。

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [37] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0是一个开源的双语（韩语/英语）视觉语言模型，支持多图理解和布局感知OCR，在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 提升双语视觉语言模型的能力，支持多图理解和布局感知OCR，并优化模型性能和安全性。

Method: 采用四阶段课程学习和内存优化技术进行训练，实现多模态对齐，同时保持语言能力并提高安全性。

Result: VARCO-VISION-2.0在韩语和英语的基准评估中均取得优异的空间定位能力和竞争力结果，其中14B模型在OpenCompass VLM排行榜上排名第8，同时发布了1.7B的轻量化版本。

Conclusion: VARCO-VISION-2.0的发布推动了双语视觉语言模型的发展及其在实际应用中的潜力。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [38] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出一种轻量级、高效的人脸图像质量评估（FIQA）方法，该方法结合了MobileNetV3-Small和ShuffleNetV2两个紧凑型卷积神经网络，并采用基于平均的预测级融合。通过结合均方误差（MSE）和皮尔逊相关正则化器，使用感知损失（MSECorrLoss）来提高与人类感知判断的一致性。该方法在VQualA FIQA基准测试中取得了0.9829的Spearman秩相关系数（SRCC）和0.9894的皮尔逊线性相关系数（PLCC），在保证准确性的同时，满足了效率要求，适合实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有的通用无参考图像质量评估方法无法捕捉人脸特有的退化问题，而最先进的FIQA模型计算量大，限制了其实际应用。因此，需要一种轻量级、高效且能捕捉人脸特有退化问题的FIQA方法。

Method: 集成MobileNetV3-Small和ShuffleNetV2两个紧凑型卷积神经网络，采用平均融合策略。使用结合均方误差（MSE）和皮尔逊相关正则化器的MSECorrLoss作为损失函数，以更好地匹配人类感知判断。

Result: 在VQualA FIQA基准测试中，该模型实现了0.9829的Spearman秩相关系数（SRCC）和0.9894的皮尔逊线性相关系数（PLCC），并且计算效率高，满足了效率竞赛的约束。

Conclusion: 所提出的轻量级FIQA方法在准确性和计算成本之间取得了良好的平衡，并且能够很好地拟合人类感知判断，使其能够成功应用于现实世界的场景中。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [39] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: RCOD框架通过潜在域分组和退化感知采样策略，在保持计算效率的同时，解决了现有单步扩散模型在真实世界图像超分辨率（Real-ISR）任务中保真度和真实感平衡的局限性，并在定量指标和视觉质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单步扩散（OSD）方法在真实世界图像超分辨率（Real-ISR）任务中，虽然提高了效率，但在保真度和真实感之间难以取得良好平衡，尤其是在多样化场景下。这是因为它们通常在单一时间步长进行训练或蒸馏，缺乏像多步方法那样通过调整采样步长来灵活控制这些相互竞争目标的机制。

Method: 提出了一种名为RCOD（Realism Controlled One-step Diffusion）的框架。该框架包括：1. 潜在域分组策略：在噪声预测阶段显式控制保真度-真实感权衡，且对训练范式和数据改动最小。2. 退化感知采样策略：使蒸馏正则化与分组策略对齐，增强权衡控制。3. 视觉提示注入模块：用退化感知的视觉标记替换传统文本提示，提升恢复准确性和语义一致性。

Result: RCOD框架在保持计算效率的同时，实现了优于最先进OSD方法的保真度和感知质量。实验证明，RCOD在定量指标和视觉质量上均优于现有方法，并具备推理阶段灵活的真实感控制能力。

Conclusion: RCOD框架成功解决了单步扩散模型在真实世界图像超分辨率任务中的保真度与真实感平衡问题，通过创新的潜在域分组和退化感知采样策略，实现了在效率和效果上的显著提升，并提供了灵活的控制能力。

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [40] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一种新颖的无源域适应框架，通过梯度伪标签细化和对比学习策略，在没有源数据的情况下，利用预训练的源模型和未标记的目标数据来适应分割性能，从而实现精确的视盘和视杯分割，优于最先进的域适应方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视盘和视杯分割模型在不同成像协议或条件下获取的目标数据上表现不佳，需要一种能够适应不同数据域的解决方案。

Method: Grad-CL框架包含两个主要阶段：1. 梯度伪标签细化：通过梯度机制提取显著的特定类别特征，实现更准确的不确定性量化和鲁棒的原型估计，以改进伪标签。2. 对比学习：利用基于余弦相似度的对比损失，强制执行梯度信息特征的类别间可分离性。

Result: 在具有挑战性的跨域眼底图像数据集上进行了广泛的实验，结果表明Grad-CL在分割精度和边界清晰度方面优于最先进的无监督和无源域适应方法。

Conclusion: Grad-CL是一种有效的无源域适应框架，能够显著提高在不同数据域上的视盘和视杯分割性能。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [41] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: VQBridge通过compress-process-recover管道优化码向量，实现了FVQ（FullVQ），在图像生成中达到100%码本使用率和最先进的重建性能，并显著提升了与LlamaGen的结合效果。


<details>
  <summary>Details</summary>
Motivation: VQ训练不稳定，导致重建性能不佳和码本使用率低。

Method: 提出VQBridge，一个基于map函数法的投影器，通过compress-process-recover管道优化码向量，并与学习退火结合，实现FVQ。

Result: FVQ在不同码本配置下实现100%码本使用率，包括262k码本；在重建性能上达到最先进水平；在与LlamaGen结合时，rFID比VAR和DiT分别提升0.5和0.2。

Conclusion: FVQ是一种有效、可扩展且通用的方法，解决了VQ训练中的挑战，提高了图像生成质量，并强调了高质量分词器在自回归图像生成中的重要性。

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [42] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock通过逐步冻结模型层来加速自监督视觉表示学习，并实现有效的潜在空间预测，在大模型上取得了优于非潜在掩码预测的效果。


<details>
  <summary>Details</summary>
Motivation: 在视频掩码自编码（MAE）模型训练过程中，ViT层按深度顺序收敛：浅层早收敛，深层晚收敛。这种现象可以被利用来加速MAE的训练。

Method: LayerLock提出了一种逐步冻结模型层的方法，并根据显式的时间表在训练过程中进行。这种方法既可以加速标准的MAE训练，也可以用于潜在空间预测，解决了“表示坍塌”问题。

Result: 将LayerLock应用于参数量高达40亿的大模型，在4DS感知套件上的表现超越了非潜在掩码预测方法。

Conclusion: LayerLock是一种简单有效的方法，通过渐进式层冻结，实现了从像素到潜在预测的过渡，在大规模模型上取得了优越的性能。

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [43] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 隐式和显式新视角合成方法在基于空间的3D物体重建中的比较，评估了外观嵌入的作用。


<details>
  <summary>Details</summary>
Motivation: 评估外观嵌入在空间3D物体重建中对几何精度的影响。

Method: 使用SPEED+数据集，比较了K-Planes、Gaussian Splatting和Convex Splatting，并分析了外观嵌入对几何保真度和表示效率的影响。

Result: 外观嵌入主要减少了显式方法所需的基元数量，但并未显著提高几何精度。Convex Splatting比Gaussian Splatting能提供更紧凑、更无干扰的表示。

Conclusion: 外观嵌入对几何中心任务的几何精度提升有限，但有助于提高表示效率。Convex Splatting在空间安全关键应用中具有优势。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [44] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: 检测AI生成图像仍然是一个挑战，尤其是当生成模型变得越来越复杂和多样化时。现有的检测器在处理未见过的生成模型时泛化能力有限，因为它们依赖于特定于生成器的伪影。我们提出了GAMMA，一个旨在减少域偏差和增强语义对齐的新型训练框架。GAMMA通过引入多样化的操作策略（如基于修复的操作和保持语义的扰动）来确保操作内容与真实内容之间的一致性。我们采用多任务监督，结合了双分割头和一个分类头，实现了跨不同生成域的像素级来源归因。此外，我们引入了一个反向交叉注意力机制，使分割头能够指导和纠正分类分支中的有偏差的表示。我们的方法在GenImage基准测试中实现了最先进的泛化性能，准确率提高了5.8%，并且在GPT-4o等新发布的生成模型上保持了强大的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像检测器在处理未知的生成模型时泛化能力有限，这主要是因为它们依赖于生成器特有的伪影。

Method: 提出了一种名为GAMMA的新型训练框架，该框架采用多样化的操作策略（如基于修复的操作和保持语义的扰动）来减少域偏差和增强语义对齐。通过多任务监督（包括双分割头和分类头）实现像素级来源归因，并引入反向交叉注意力机制来纠正分类分支中的有偏差表示。

Result: GAMMA在GenImage基准测试上实现了最先进的泛化性能，准确率提高了5.8%，并且在GPT-4o等新发布模型上表现出良好的鲁棒性。

Conclusion: GAMMA通过引入多样化的操作和创新的监督机制，显著提高了AI生成图像检测器对未见过模型泛化能力和鲁棒性。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [45] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: SRR方法（NiftyMIC、SVRTK、NeSVoR）应用于140例胎儿脑MRI扫描，NeSVoR重建成功率最高。不同SRR方法在体积测量上存在差异，但对诊断分类性能无影响。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑MRI分辨率低、易受运动干扰且不能充分显示三维解剖结构，SRR方法旨在通过结合切片到体积配准和超分辨率技术来生成高分辨率三维体积。现有SRR方法在病理情况下的比较性能以及对下游分析和诊断任务的影响有待进一步研究。

Method: 应用三种最先进的SRR方法（NiftyMIC、SVRTK和NeSVoR）对140例健康对照组和病理组（脑室扩张）的胎儿脑MRI扫描进行处理。使用BoUNTi算法对重建后的高分辨率图像进行分割，提取九个主要脑结构的体积。评估重建图像的视觉质量、SRR成功率、体积测量一致性以及诊断分类性能。

Result: NeSVoR在健康对照组和病理组中均显示出最高且最一致的重建成功率（>90%）。尽管SRR方法在体积估计上存在显著差异，但对脑室扩张的诊断分类性能不受SRR方法选择的影响。

Conclusion: NeSVoR方法具有很高的鲁棒性，并且诊断性能在一定程度上可以承受SRR引起的体积变化。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [46] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: MCR通过引入掩码扰动来解决图像修复中的遮罩幻觉和遮罩形状偏差问题，从而提高对象移除的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散模型在对象移除（图像修复的一部分）时面临遮罩幻觉（在遮罩区域内生成不相关内容）和遮罩形状偏差（用模仿遮罩形状的对象填充而非周围内容）的挑战。

Method: 提出了一种名为掩码一致性正则化（MCR）的新型训练策略。该策略在训练期间引入了两种掩码扰动：扩张和重塑。通过强制原始掩码分支和扰动掩码分支之间的输出保持一致，扩张掩码有助于将模型的输出与周围内容对齐，而重塑掩码则鼓励模型打破遮罩形状偏差。

Result: 实验表明，MCR显著减少了幻觉和遮罩形状偏差，从而在对象移除方面取得了改进的性能。

Conclusion: MCR通过掩码一致性正则化，能够生成更鲁棒、更符合上下文的修复结果，有效解决了对象移除中的关键挑战。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [47] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: T2I生成中存在的物理伪影（如解剖和结构缺陷）是一个普遍存在的问题，严重影响感知质量并限制了应用。为了解决这个问题，我们提出了MagicMirror框架，它包括一个详细的伪影分类、一个包含340K个带精细伪影标签的生成图像的人工注释数据集MagicData340K，以及一个名为MagicAssessor的视觉语言模型（VLM）来评估这些伪影。我们还设计了一种新的数据采样策略和多级奖励系统来解决训练中的挑战。最终，我们利用MagicAssessor构建了一个名为MagicBench的自动化基准，用于评估T2I模型中的图像伪影。评估结果表明，即使是顶尖模型也存在显著的伪影问题，这凸显了减少伪影对于未来T2I发展的重要性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）生成在指令遵循和美学方面取得了显著进展，但普遍存在的物理伪影（如解剖和结构缺陷）严重降低了感知质量并限制了应用。目前的基准测试缺乏系统性和精细化的伪影评估框架。

Method: 1. 建立详细的生成图像伪影分类。2. 构建一个包含340K个带精细伪影标签的大规模人工注释数据集MagicData340K。3. 训练一个视觉语言模型MagicAssessor，用于提供详细的伪影评估和标签。4. 设计新的数据采样策略和多级奖励系统（用于Group Relative Policy Optimization - GRPO），以克服类别不平衡和奖励技巧等挑战。5. 利用MagicAssessor构建自动化基准MagicBench，用于评估T2I模型的图像伪影。

Result: MagicBench的评估显示，即使是像GPT-image-1这样的顶尖模型也持续存在显著的伪影问题，表明伪影减少仍然是未来T2I发展的一个关键方向。

Conclusion: MagicMirror框架为T2I生成中的伪影评估提供了一个系统化的解决方案。通过MagicData340K数据集和MagicAssessor模型，我们能够构建MagicBench基准，并揭示当前T2I模型在伪影方面存在的普遍问题，指明了未来的研究重点。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [48] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip框架通过融合手势和唇部运动特征，并引入分层对比学习框架，提高了手语翻译的准确性，在PHOENIX14T和How2Sign数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要关注手动信号（手势），忽略了唇部运动等非手动线索，而唇部运动在传递语言信息和区分视觉上相似的手语方面起着至关重要的作用。

Method: SignClip框架融合了手动和非手动线索（空间手势和唇部运动特征），并引入了一个分层对比学习框架，包含多级对齐目标，以确保手语-唇语和视觉-文本模态之间的语义一致性。

Result: 在PHOENIX14T和How2Sign数据集上的广泛实验表明，SignClip的优越性。在PHOENIX14T数据集的无词（Gloss-free）设置下，SignClip的BLEU-4从24.32提升到24.71，ROUGE从46.57提升到48.38，超过了之前的最先进模型SpaMo。

Conclusion: SignClip框架通过融合手动和非手动线索，并利用分层对比学习，有效地提高了手语翻译的准确性，克服了现有方法在处理非手动线索方面的不足。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [49] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本研究分析了闭源和开源大型视觉语言模型（VLMs）在文本篡改检测方面的表现，并发现闭源模型（如GPT-4o）优于开源模型。同时，研究还发现专门用于图像篡改检测的VLMs在文本篡改检测方面存在泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注大型视觉语言模型（VLMs）在图像篡改检测方面的应用，而忽略了文本篡改检测的领域。本研究旨在填补这一知识空白。

Method: 分析了闭源和开源VLMs在不同文本篡改数据集上的表现。此外，还针对文本篡改检测对专门用于图像篡改检测的VLMs进行了基准测试，并评估了模型在真实场景文本和伪造身份证件上的篡改检测能力。

Result: 研究结果表明，开源模型在文本篡改检测方面正在追赶闭源模型，但仍落后于GPT-4o等闭源模型。专门用于图像篡改检测的VLMs在文本篡改检测任务上存在泛化能力不足的问题。模型在真实场景文本和伪造身份证件上的表现也得到了评估。

Conclusion: 闭源VLMs在文本篡改检测方面表现更优，而开源模型和图像篡改检测专用VLMs仍有提升空间。未来的研究应关注提升VLMs在文本篡改检测方面的能力，尤其是在泛化性和鲁棒性方面。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [50] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD框架利用点云、RGB图像和文本信息，通过多模态协作学习，实现了零样本3D异常检测的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本3D异常检测方法主要集中在点云，忽略了RGB图像和文本先验等互补模态的丰富语义线索。因此，有必要利用多模态信息来提升检测性能，尤其是在数据稀缺、隐私保护或标注成本高昂的场景下。

Method: 提出了一种名为MCL-AD的新框架，它利用点云、RGB图像和文本语义进行多模态协作学习。该框架包含一个多模态提示学习机制（MPLM），通过引入与物体无关的解耦文本提示和多模态对比损失来增强单模态表示能力和跨模态协作学习。此外，还提出了一个协作调制机制（CMM），通过联合调制RGB图像引导和点云引导的分支，充分利用点云和RGB图像的互补表示。

Result: MCL-AD框架在零样本3D异常检测任务上取得了最先进的性能。

Conclusion: MCL-AD框架通过多模态协作学习，有效融合了点云、RGB图像和文本信息，显著提升了零样本3D异常检测的性能，为该领域的研究提供了新的方向。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [51] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出一种基于 Lipshitz 约束的随机深度（DropPath）方法，通过增加深层网络的 drop 概率来控制网络的 Lipshitz 常数，从而提高网络的鲁棒性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和 Vision Transformers 尽管在计算机视觉领域表现出色，但极易受到对抗性扰动的攻击。现有的防御方法计算成本高昂或缺乏严格的理论保证。

Method: 提出一种 Lipshitz 引导的随机深度（DropPath）方法，其中 drop 概率随深度增加而增加，以控制网络的有效 Lipshitz 常数。该方法对深层网络进行正则化，在提高鲁棒性的同时保持了准确性并降低了计算量。

Result: 在 CIFAR-10 数据集和 ViT-Tiny 模型上进行实验，结果表明该方法在保持接近基线水平的准确度的同时，显著提高了在 FGSM、PGD-20 和 AutoAttack 攻击下的鲁棒性，并且与基线和线性 DropPath 相比，计算量（FLOPs）显著降低。

Conclusion: 所提出的 Lipshitz 引导的随机深度方法能够有效提升 Vision Transformer 在计算机视觉任务中的鲁棒性，同时保持高准确率并降低计算成本。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [52] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 本研究提出了一种基于能量图的概率框架，用于在复杂的城市环境中精确地对街道设施进行地理定位，并使用随机生灭优化算法来推断最可能的资产配置。


<details>
  <summary>Details</summary>
Motivation: 为了有效监控和维护公共基础设施，需要精确的街道设施地理定位。

Method: 提出了一种基于能量图的概率框架，该框架对物体位置的空间可能性进行编码。能量图的基于地图的地理定位格式可以无缝集成外部地理空间信息（如GIS图层、道路图或放置约束），以提高上下文感知和定位准确性。引入了一种随机生灭优化算法来推断最可能的资产配置。

Result: 使用爱尔兰都柏林市中心街道照明基础设施的地理定位数据集进行现实模拟，证明了该方法在可扩展和准确的城市资产测绘方面的潜力。

Conclusion: 该概率框架和优化算法能够对城市环境中的街道设施进行精确的地理定位，并有可能扩展到其他城市资产测绘任务。

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [53] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 通过空间聚类减少90%以上的token，实现加速


<details>
  <summary>Details</summary>
Motivation: 目前的扩散模型存在计算成本高的问题，而特征缓存方法仅考虑了时间维度上的相似性，忽略了空间维度上的相似性。

Method: 提出了一种名为Cluster-Driven Feature Caching (ClusCa) 的方法，该方法在每个时间步对token进行空间聚类，并为每个聚类计算一个token，然后将其信息传播给所有其他token。

Result: 在DiT、FLUX和HunyuanVideo上进行了广泛的实验，证明了ClusCa在文本到图像和文本到视频生成方面的有效性。ClusCa可以将token数量减少90%以上，并且可以直接应用于任何扩散变换器模型，无需进行训练。在FLUX上实现了4.96倍的加速，ImageReward为99.49%，比原始模型提高了0.51%。

Conclusion: ClusCa是一种有效的特征缓存方法，可以显著加速扩散模型，并且具有广泛的适用性。

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [54] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter 是首个全整数 Vision Transformer (ViT) 语义分割框架，通过将浮点运算替换为整数运算、引入新的激活函数 λ-ShiftGELU、移除 L2 归一化层以及将双线性插值替换为最近邻上采样，在保持接近 FP32 基线精度的同时，显著减小了模型尺寸并提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的 Vision Transformers (ViTs) 在语义分割方面表现出色，但由于内存占用和计算成本高，在资源受限设备上的部署受到限制。量化是一种提高效率的有效策略，但 ViT 分割模型在低精度下表现脆弱，量化误差会在深度编码器-解码器管道中累积。

Method: I-Segmenter 通过系统地将浮点运算替换为整数运算，构建了首个全整数 ViT 分割框架。为了稳定训练和推理，提出了一种新的激活函数 λ-ShiftGELU 来缓解均匀量化在处理长尾激活分布时的局限性。此外，移除了 L2 归一化层，并将解码器中的双线性插值替换为最近邻上采样，确保整个计算图的整数运算。

Result: I-Segmenter 的准确度与 FP32 基线相当（平均仅相差 5.1%），同时模型尺寸减小了高达 3.8 倍，推理速度最多提高了 1.2 倍。即使在仅使用一张标定图像进行一次性量化训练（PTQ）的情况下，I-Segmenter 也能提供具有竞争力的准确度。

Conclusion: I-Segmenter 成功实现了首个全整数 ViT 分割框架，有效解决了 ViT 在资源受限设备部署中的效率问题，并在保持高精度的同时显著提升了性能，具有很高的实际应用价值。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [55] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于扩散概率的新型深度学习方法，用于去除OCT图像中的散斑噪声，它使用伽马分布来模拟噪声，并通过噪声鲁棒性保真项来提高图像质量，同时加速了推理过程，在各种评估指标上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: OCT图像中的散斑噪声会阻碍对视网膜疾病的准确诊断和监测，而现有的去噪方法往往难以在降噪和保留解剖结构之间取得平衡。

Method: 提出了一种名为GARD（Gamma-based Anatomical Restoration and Denoising）的新型深度学习方法，该方法利用了扩散概率模型的优点。GARD采用伽马去噪扩散模型来更准确地模拟散斑噪声的统计特性，并引入了一个利用预处理过的、噪声较少的图像来指导去噪过程的噪声鲁棒性保真项，以防止高频噪声的再引入。此外，还通过调整去噪扩散隐式模型框架来加速推理过程。

Result: GARD在配对的噪声和噪声较少的OCT B-扫描数据集上进行了实验，结果表明，在PSNR、SSIM和MSE方面，GARD显著优于传统的去噪方法和最先进的深度学习模型。视觉结果也证实，GARD产生的边缘更清晰，并能更好地保留精细的解剖细节。

Conclusion: GARD是一种有效的OCT图像去噪方法，它通过采用伽马分布模拟散斑噪声并引入噪声鲁棒性保真项，能够显著提高图像质量，并优于现有方法。

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [56] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM是一个用于乳腺X光检查的多视图预训练模型，通过结合全局和局部对齐以及几何引导，解决了现有模型忽略多视图关系和领域差异的问题，并在多个数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有乳腺X光检查的深度学习模型在处理多视图关系和领域差异方面存在不足，导致无法充分利用关键的几何信息，影响了预测准确性。

Method: 提出GLAM模型，利用几何引导进行多视图乳腺X光检查的VLM预训练。通过联合全局和局部、视觉-视觉以及视觉-语言对比学习，学习局部跨视图对齐和细粒度局部特征，并利用了乳腺X光检查的多视图成像过程的先验知识。

Result: 在EMBED数据集上预训练的GLAM模型，在多个数据集和不同设置下均优于基线模型。

Conclusion: GLAM通过有效的多视图对齐和领域适应性学习，提高了乳腺X光检查VLM的性能。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [57] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 本文对视觉语言模型（VLM）中的视觉基础（visual grounding）进行了全面综述，探讨了其在各种应用中的重要性、核心组件、实际应用、评估方法，并分析了视觉基础、多模态思维链和推理之间的关系，最后指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉基础是 VLM 的关键能力，能理解图像或视频中与文本描述匹配的区域，对视觉语言理解和生成至关重要。

Method: 本文综述了现代通用 VLM 在视觉基础研究方面的代表性工作，概述了视觉基础的重要性、核心组件、实际应用（包括基准和评估指标），并探讨了视觉基础、多模态思维链和推理之间的关系。

Result: 对视觉基础在 VLM 中的重要性、核心组件、实际应用、基准和评估指标进行了概述，并分析了视觉基础、多模态思维链和推理之间的关系。

Conclusion: 视觉基础是 VLM 中的一个活跃研究领域，虽然在理解和生成方面取得了显著进展，但仍面临挑战，未来研究应关注解决这些挑战并探索新的方向。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [58] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 提出了一种名为“注意力攻击”的新型攻击方法，通过使用源图像的自动生成标题作为编辑提示的代理，扰乱文本提示和图像视觉表示之间的交叉注意力，从而针对文本到图像编辑方法的视觉组件，并提出两种新的评估策略来衡量免疫成功性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像编辑方法容易受到对抗性攻击，需要新的攻击和评估方法。

Method: 提出“注意力攻击”，通过使用源图像的自动生成标题作为编辑提示的代理来扰乱文本提示和图像视觉表示之间的交叉注意力。提出“标题相似度”和“语义交并比（IoU）”两种新的评估策略。

Result: 该攻击显著降低了编辑性能，同时保持不可察觉，并在 TEDBench++ 基准测试中得到了证明。

Conclusion: 提出的“注意力攻击”是一种有效且难以察觉的攻击方法，可用于评估文本到图像编辑方法的鲁棒性，并且提出的新评估策略能更准确地衡量攻击效果。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [59] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 通过知识蒸馏减小了神经网络图像压缩模型的资源需求，以实现更快的速度和更低的功耗。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的图像压缩方法虽然性能优越，但计算资源需求大，不适合资源受限的平台进行实时处理。

Method: 利用知识蒸馏技术，让小型神经网络模型学习大型复杂模型的输出，以提高其性能并降低资源消耗。

Result: 实验证明，知识蒸馏可以有效地应用于图像压缩任务，并在不同模型大小、不同图像质量/比特率的权衡下，以及在节省处理和能源资源方面取得成效。

Conclusion: 知识蒸馏是一种有效的方法，可以减少神经网络图像压缩模型的资源需求，使其能够应用于更广泛的场景。未来的研究可以进一步探索不同的教师模型、损失函数以及将其应用于基于Transformer的模型。

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [60] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 提出了一种仅使用可见光和热成像图像的无训练方法来实现内因图像分解。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界场景缺乏广泛的地面真实数据，将图像分解为光度因素（阴影和反射率）是一个长期存在的挑战。

Method: 该方法利用可见光和热成像图像之间的强度顺序关系来推断阴影和反射率的顺序，从而实现密集自监督学习。

Result: 在自然和人造光照下，使用已知反射率和阴影进行定量评估，并在各种户外场景中进行定性实验，结果表明该方法优于最新的基于学习的模型。

Conclusion: 该方法提供了一种可扩展的真实世界顺序监督方法，解决了手动标记的局限性，并在内因图像分解方面取得了优于现有方法的性能。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [61] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 深度学习驱动的压缩视频质量增强（CVQE）研究现状存在不足，本文提出新的分类法、基准测试框架和深入的性能分析，旨在促进该领域的标准化评估和模型选择。


<details>
  <summary>Details</summary>
Motivation: 现有关于压缩视频质量增强（CVQE）的调查在方法分类、跨编码类型比较和基准测试方面存在不足，无法满足深度学习驱动的CVQE领域的需求。

Method: 本文提出了一种新的CVQE方法分类法，并建立了一个统一的基准测试框架，用于评估不同模型在现代压缩协议和标准测试序列上的性能。最后，对重建性能和计算复杂度之间的关键权衡进行了系统分析。

Result: 本文的分类法和基准测试框架为CVQE研究和部署提供了基础，通过系统分析，揭示了当前最先进方法在重建性能和计算复杂度方面的权衡，并指出了未来的研究方向。

Conclusion: 本研究通过提出新颖的分类法、统一的基准测试框架以及对性能和复杂度的深入分析，弥合了现有CVQE调查的差距，旨在为该领域提供更一致的评估方法和更明智的模型选择指导。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [62] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter 是一个用于多模态语义分割的新框架，它通过适配器网络将融合的多模态特征注入 SAM 的 RGB 特征中，以提高模型在光照不佳、遮挡和恶劣天气等挑战性条件下的鲁棒性，并在三个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的语义分割方法在光照不佳、遮挡和恶劣天气等挑战性条件下仍然脆弱。为了提高模型的鲁棒性，研究者们提出了多模态方法，利用辅助传感器数据（如 LiDAR、红外线）来提供互补信息。

Method: MM SAM-adapter 框架通过一个适配器网络，将融合后的多模态特征注入到 SAM 强大的 RGB 特征中。这种设计使得模型能够在保留 RGB 特征的强大泛化能力的同时，仅在辅助模态提供额外线索时才选择性地整合它们。

Result: MM SAM-adapter 在 DeLiVER、FMB 和 MUSES 三个具有挑战性的基准测试中取得了最先进的性能。通过将 DeLiVER 和 FMB 分成 RGB-easy 和 RGB-hard 子集进行分析，结果一致表明，无论是在有利还是不利的条件下，该框架都优于现有方法。

Conclusion: MM SAM-adapter 框架能够有效且高效地利用多模态信息，通过多模态适配提高了场景理解的鲁棒性，并在各种挑战性条件下表现出色。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [63] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen是一个新提出的模型，可以在不重新训练扩散模型的情况下，从固定大小的潜在表示中生成任意分辨率的图像，从而大大提高生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在生成高分辨率图像时计算需求会随着分辨率的增加而呈二次方增长，导致生成速度缓慢。作者希望解决这个问题，实现任意分辨率的图像生成。

Method: 作者提出了一种名为InfGen的新模型，它改进了潜在扩散模型。InfGen将扩散模型生成的固定潜在表示视为内容表示，并使用一个紧凑的生成器来解码任意分辨率的图像。InfGen用一个新的生成器替换了原有的VAE解码器，可以在不重新训练扩散模型的情况下，从固定大小的潜在表示生成任意分辨率的图像。

Result: InfGen能够提升多种模型生成任意高分辨率图像的能力，并将4K图像的生成时间从超过100秒缩短到10秒以内。

Conclusion: InfGen通过替换VAE解码器为新提出的生成器，简化了生成过程，降低了计算复杂性，并且可以应用于任何使用相同潜在空间模型的场景，有效地解决了高分辨率图像生成速度慢的问题。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [64] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 通过对公开数据集进行预训练，并结合时间顺序预测和对比学习，所提出的自监督学习模型在阿尔茨海默病预测任务上表现优于监督学习模型，并能适应不同的输入和时间间隔。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在阿尔茨海默病预测任务中面临数据不足、泛化性差以及输入扫描数和扫描时间间隔可变等问题。

Method: 本研究将三种先进的时间自监督学习方法应用于3D脑部MRI分析，并进行了创新性改进以处理可变长度的输入并学习鲁棒的空间特征。通过整合四个公共数据集（共3,161名患者）进行预训练，并在多个阿尔茨海默病预测任务（包括诊断分类、疾病转化检测和未来转化预测）上评估模型性能。

Result: 所提出的自监督学习模型（采用时间顺序预测和对比学习）在七个下游任务中的六个任务上优于监督学习模型，并在不同的任务、输入图像数量和时间间隔下展现出良好的适应性和泛化能力。

Conclusion: 本研究提出的自监督学习模型能够有效处理阿尔茨海默病预测任务中的挑战，并在临床应用中表现出鲁棒的性能。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [65] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 该研究提出了一种利用知识图谱（KG）来改进临床文档到ICD编码的自动化方法，通过构建患者中心文档的结构化表示，提高了编码准确性和效率，并增强了可解释性。


<details>
  <summary>Details</summary>
Motivation: 手动将临床文档编码为标准化词汇（如ICD）效率低下且耗时，而自动化编码对于临床研究、医院管理和患者护理至关重要。

Method: 利用文档级知识图谱（KG）为输入文档计算结构化表示，该KG全面展示了患者的病状。这种表示方式将原始文本减少了77%，同时保留了90%的信息。然后将此KG集成到最先进的PLM-ICD架构中，用于自动化ICD-9编码。

Result: 在常用基准测试中，Macro-F1分数最高提高了3.20%，同时提高了训练效率。研究发现KG中的实体和关系类型是性能提升的原因，并且与纯文本方法相比，该方法具有更好的可解释性。

Conclusion: 利用知识图谱来丰富输入文档的表示，是自动化临床编码任务的有效方法，可以提高准确性、效率和可解释性。

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [66] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: CLAP是一种新的激活探测技术，用于检测大型语言模型（LLM）的幻觉，通过将LLM激活作为联合序列进行处理，提高了幻觉检测的准确性，并能实现细粒度检测，甚至可以区分不同采样响应中的幻觉和非幻觉，从而提出一种“检测后缓解”策略来降低幻觉的发生率，并且该方法在分布外应用时仍能保持高可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的广泛应用引发了对其生成不准确文本（幻觉）的可靠性担忧。

Method: 提出了一种名为CLAP（Cross-Layer Attention Probing）的新型激活探测技术，它将LLM的激活跨整个残差流处理为一个联合序列，以检测幻觉。

Result: 在五个LLM和三个任务上的实证评估表明，与基线方法相比，CLAP在贪婪解码响应和高温度采样响应中都能提高幻觉检测效果，实现了细粒度检测，并能提出一种“检测后缓解”策略，比直接缓解方法更有效地降低幻觉。此外，CLAP在分布外应用时仍保持高可靠性。

Conclusion: CLAP是一种有效的幻觉检测技术，能够提高LLM的可靠性，并能在分布外应用中保持性能。

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [67] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 利用机器翻译（MT）的双语文本数据，通过多任务学习（MTL）来克服语音-文本翻译（ST）中配对数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: End-to-end speech-to-text translation typically suffers from the scarcity of paired speech-text data. One way to overcome this shortcoming is to utilize the bitext data from the Machine Translation (MT) task and perform Multi-Task Learning (MTL).

Method: Formulate MTL from a regularization perspective and explore how sequences can be regularized within and across modalities. Investigate the effect of consistency regularization (different modality) and R-drop (same modality). Explore the coefficient of MT loss as another source of regularization. Introduce the optimal regularization contour in the high-dimensional space, called the regularization horizon.

Result: Tuning the hyperparameters within the regularization horizon achieves near state-of-the-art performance on the MuST-C dataset.

Conclusion: The proposed method, by leveraging three sources of regularization within the MTL framework, achieves near state-of-the-art results on the MuST-C dataset, indicating the effectiveness of regularization in addressing data scarcity for speech-to-text translation.

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [68] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: 该研究提出了一个名为“Creativity Benchmark”的评估框架，用于衡量大型语言模型（LLMs）在营销创意方面的表现。该基准包含100个品牌（12个类别）和三种提示类型（洞察、创意、放飞创意）。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在营销创意方面的能力，并与人类创意者的表现进行比较。

Method: 收集了678名专业创意者对11,012个匿名比较结果的配对偏好，并使用Bradley-Terry模型进行分析，以评估模型的表现。同时，研究还分析了模型的输出多样性，并比较了三种“LLM作为评判者”的设置与人类排名的相关性，以及对提示重构的敏感性。

Result: 研究发现，所有模型的表现紧密聚集，没有模型在所有品牌或提示类型上都占据主导地位，最高评分模型仅比最低评分模型高出约61%的胜率。此外，研究还发现“LLM作为评判者”的设置与人类排名之间存在微弱且不一致的相关性，并存在评判者偏见。传统的创造力测试在品牌约束任务上的迁移性也有限。

Conclusion: 研究强调了在营销创意领域，专家人类评估的必要性，并指出需要采用关注多样性的工作流程。同时，研究结果表明，自动评判者无法替代人类评估，且传统的创造力测试在特定任务上的适用性有限。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [69] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: CTCC是一个新颖的、由规则驱动的大语言模型（LLM）指纹框架，它通过编码多轮对话中的上下文相关性（例如反事实）来嵌入可验证的所有权痕迹，解决了现有方法在隐蔽性、鲁棒性和泛化性方面的不足，并在黑盒访问下实现了指纹验证，同时减少了误报和指纹泄露。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）指纹技术在隐蔽性、鲁棒性和泛化性方面存在固有的权衡，容易被检测、受到对抗性修改的影响或在指纹暴露后失效。本研究旨在开发一种更可靠、更实用的LLM指纹解决方案。

Method: CTCC框架通过编码多轮对话中的上下文相关性（例如反事实），而不是依赖于标记级别或单轮触发器来嵌入指纹。该框架支持在共享语义规则下进行持续构建，即使部分触发器暴露，也能在黑盒访问下进行验证，并能减轻误报和指纹泄露。

Result: CTCC在多种LLM架构上的广泛实验表明，与现有方法相比，CTCC在隐蔽性和鲁棒性方面始终表现更优。

Conclusion: CTCC是一个可靠且实用的解决方案，适用于现实世界中LLM的部署场景，能够有效解决知识产权保护问题。

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [70] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 语言模型在跨期选择中表现出未来导向的偏好，并且可以通过提示进行操纵。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否在跨期选择中表现出未来或现在导向的偏好，以及这些偏好是否可以通过提示进行系统性操纵。

Method: 使用改编自人类实验的协议，评估多个语言模型在时间权衡任务上的表现，并与人类决策者进行基准测试。引入“时间导向操纵性”（MTO）指标来衡量提示操纵的效果。

Result: 推理能力强的模型（如DeepSeek-Reasoner和grok-3-mini）在未来导向提示下会选择较晚的选项，但跨身份或地域的个性化决策能力有限。能够正确推理时间导向的模型会将未来导向内化为自身AI决策者的偏好。

Conclusion: 语言模型表现出可操纵的未来导向偏好，并可能内化这种偏好。这对设计符合长期、异构目标的人工智能助手具有启示意义，并指明了未来个性化校准和面向社会的部署的研究方向。

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [71] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 小型语言模型在回答相同问题时的一致性参差不齐，但通常在50%-80%的范围内，并且一致性答案的准确性与整体准确性相关。


<details>
  <summary>Details</summary>
Motivation: 研究小型语言模型（2B-8B参数）在多次回答相同问题时的一致性。

Method: 使用MMLU-Redux和MedQA基准测试中的问题，对不同推理温度、模型大小（包括小型和中型）、微调和基础模型进行10次重复问答实验，并分析了多轮答案一致性对准确性的影响以及相关的权衡。

Result: 小型模型在低推理温度下的答案一致性通常在50%-80%范围内，而中型模型的一致性水平要高得多。一致性答案的准确性与整体准确性有合理的相关性。

Conclusion: 答案的一致性因模型而异，但小型模型在低推理温度下表现出一定程度的一致性。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [72] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 通过对Gemma-2-2B-IT和LLaMA-3.1-8B-IT模型进行稀疏自编码器（SAE）分析，研究了模型拒绝有害提示的内部机制。通过在SAE潜在空间中寻找并移除关键特征，成功实现了从拒绝到服从的转换，从而制造了越狱。研究过程包括寻找拒模型引导方向、贪婪过滤以及发现特征间的交互作用。结果揭示了导致越狱的关键特征集，并发现了在特定条件下才会被激活的冗余特征。


<details>
  <summary>Details</summary>
Motivation: 理解指令调整的大型语言模型（LLMs）在拒绝有害提示时的内部原因。

Method: 使用稀疏自编码器（SAEs）训练模型残差流激活。通过在SAE潜在空间中搜索、消融特征集来翻转模型的行为，实现从拒绝到服从的转换。搜索过程分三个阶段：1. 寻找拒模型引导方向并收集附近特征；2. 贪婪过滤以获得最小特征集；3. 拟合因子分解机（FM）捕捉剩余特征间的非线性交互作用。

Result: 发现了导致越狱的关键特征集，深入了解了模型拒模型行为的机制基础。此外，还发现了之前处于休眠状态、仅在早期特征被抑制时才被激活的冗余特征。

Conclusion: 通过操纵可解释的潜在空间，可以实现对模型安全行为的细粒度审计和靶向干预。

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [73] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: LLMs在学术写作中存在引用不当等问题，本研究提出内容质量和引用有效性两个量化评估指标，并结合迭代提示方法，以提高LLM的写作能力和学术诚信。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在学术写作中存在引用不准确或捏造的问题，且内容质量评估依赖主观的人工判断，缺乏客观性和一致性。本研究旨在为LLM提供量化评估，并提升其研究提案写作能力。

Method: 提出内容质量和引用有效性两个核心评估指标，并基于这两个指标的分数设计了一种迭代提示方法。

Result: 实验表明，所提出的指标为评估LLM写作表现提供了一个客观、量化的框架。迭代提示方法显著提高了内容质量，同时减少了引用的不准确性和捏造现象。

Conclusion: 所提出的量化评估指标和迭代提示方法能够有效解决LLM在学术写作中面临的引用问题和提高内容质量，应对了学术领域中的关键伦理挑战。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [74] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究提出一种使用大型语言模型（LLM）生成用于基于代理的交通模型中的个体出行日记的方案，通过结合美国社区调查（ACS）和智能位置数据库（SLD）数据生成用户画像，并利用提示直接合成日记，以替代传统的出行调查数据。


<details>
  <summary>Details</summary>
Motivation: 传统的基于代理的交通模型依赖大量的专有家庭出行调查数据，而本研究旨在提出一种利用公开数据生成个体出行日记的方法，以克服数据获取的限制。

Method: 本研究利用LLM，结合公开的ACS和SLD数据生成用户画像，并通过直接提示合成出行日记。引入了一种新颖的“一对群组真实性得分”，该得分由四个指标（出行次数得分、时间间隔得分、出行目的得分和出行方式得分）组成，并使用康涅狄格州全州交通研究（CSTS）的日记数据进行验证，采用Jensen-Shannon散度来衡量生成日记与真实日记在分布上的相似性。

Result: 与使用负二项回归（用于出行生成）和多项Logit模型（用于出行方式/目的选择）等经典方法生成的日记相比，LLM生成的日记在整体真实性上相当（LLM平均真实性得分0.485，经典方法平均0.455）。LLM在出行目的的确定上表现更优，并且具有更好的模型一致性（真实性得分分布更窄）；然而，经典模型在出行次数和活动持续时间的数值估计上更具优势。在聚合验证中，LLM生成日记的统计代表性也更强（LLM平均得分0.612，经典方法平均0.435）。

Conclusion: 本研究证明了LLM在生成个体出行日记方面的可行性，尤其是在零样本（zero-shot）场景下，并建立了一个可量化的日记真实性评估指标，为未来的合成日记评估系统奠定了基础。LLM方法在出行目的和模型一致性方面表现突出，为交通建模提供了新的数据合成途径。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [75] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: 该研究提出了PsychiatryBench，一个基于精神病学教科书和案例集的全面评估基准，用于评估大型语言模型在精神病学领域的表现，并揭示了现有模型在临床一致性和安全性方面存在的显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）评估资源在临床有效性和真实性方面存在局限性，未能充分捕捉精神病学推理的复杂性。

Method: 构建了一个名为PsychiatryBench的评估基准，该基准完全基于权威、专家验证的精神病学教科书和案例集，包含十一个不同的问答任务，总计超过5300个专家注释项目。研究评估了包括Gemini、LLaMA 3等在内的多种前沿LLMs和开源医学模型。

Result: 评估结果显示，在临床一致性和安全性方面，尤其是在多轮随访和管理任务中，模型表现存在显著不足，凸显了进行专门模型微调和开发更鲁棒评估范式的必要性。

Conclusion: PsychiatryBench为评估和改进大型语言模型在精神健康等高风险领域的性能提供了一个模块化、可扩展的平台，并指出了当前模型在临床应用中仍需解决的关键问题。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [76] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 本研究表明，采用ORPO训练方法的小型语言模型在模拟ACT治疗中表现优于SFT模型，并且链式思考（COT）对SFT模型有益，但对ORPO模型无明显优势。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨在小型语言模型（LLM）中应用接纳与承诺疗法（ACT），并评估不同训练方法（SFT和ORPO）及是否使用链式思考（COT）对模型表现的影响。

Method: 使用Mistral-Large生成的50组ACT模拟对话，通过SFT和ORPO两种方法对Llama-3.2-3b-Instruct模型进行训练，并分别设置是否使用COT。随后，使用经过人类评估微调的LLM裁判，在模拟治疗环节中，基于ACT保真度量表（ACT-FM）和治疗师共情量表（TES）对四种模型变体进行评估。

Result: ORPO训练的模型在ACT保真度和治疗师共情方面显著优于SFT模型和基础Instruct模型。COT对SFT模型有显著的积极影响（ACT-FM分数平均提高2.68分），但对ORPO和Instruct模型没有明显益处。ORPO的优势可能在于其学习治疗‘过程’而非‘内容’的能力，而COT是模仿训练模型的必要支撑。

Conclusion: 本研究证明了基于偏好对齐的策略优化（ORPO）能够有效地在小型LLM中植入ACT能力，并且显式推理（COT）的效用高度依赖于底层训练范式。ORPO在小型LLM中实现ACT治疗能力方面显示出巨大潜力。

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [77] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: HANRAG是一个新颖的启发式框架，通过查询路由、子查询分解和噪声过滤来解决多跳问题，并在问答任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理多跳查询时面临挑战，例如过度依赖迭代检索和噪声累积问题。

Method: 提出HANRAG框架，该框架通过一个‘启示器’来路由查询、将其分解为子查询，并过滤检索到的文档中的噪声。

Result: HANRAG在单跳和多跳问答任务中均取得了优于其他领先方法的性能。

Conclusion: HANRAG框架提高了系统的适应性和抗噪声能力，能够有效地处理各种复杂查询。

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [78] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 不同的语义相似性测量方法在软件工程应用中的表现差异显著，其中基于嵌入的方法存在较大问题，而大型语言模型表现相对较好。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估不同方法在衡量语义相似性方面的表现，因为语义相似性对于代码搜索、API推荐、自动化代码审查和重构工具等软件工程应用至关重要，同时探讨大型语言模型在这方面的真正理解能力。

Method: 通过系统化的测试框架，对18种不同的语义相似性测量方法（包括基于词、基于嵌入、基于大型语言模型和结构感知算法）进行测试，并对文本和代码进行受控更改以评估它们处理不同语义关系的能力。

Result: 研究发现，常用的嵌入式方法在识别语义相反项时准确率低（高达99.9%），甚至将相反含义的内容评为比同义词更相似。将欧氏距离改为余弦相似性可将嵌入式方法的性能提高24%至66%。大型语言模型在区分语义差异方面表现更好，对不同含义的内容给出较低的相似度得分（0.00至0.29），而嵌入式方法则错误地给出较高的得分（0.82至0.99）。

Conclusion: 目前常用的语义相似性测量方法，尤其是基于嵌入的方法，存在显著的局限性。大型语言模型在区分语义相似性和差异性方面展现出更大的潜力，但仍需进一步研究和优化。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [79] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: LLMs容易出现幻觉，尤其是在处理符号属性时，模型规模越大，幻觉比例越低，但并未完全消除。


<details>
  <summary>Details</summary>
Motivation: 识别并研究导致大型语言模型（LLM）产生幻觉的内在属性，以找出模型内部的脆弱点。

Method: 利用HaluEval和TruthfulQA两个数据集，将其问答格式转换为其他格式，以缩小导致幻觉的属性范围。

Result: 研究发现，在符号属性方面，Gemma-2-2B模型的幻觉比例高达79.0%，Gemma-2-9B为73.6%，Gemma-2-27B为63.9%。幻觉比例随模型规模增大而降低，但对于修饰词和命名实体，所有Gemma模型和数据集的幻觉比例仍然很高（分别为84.76%至94.98%和83.87%至93.96%）。

Conclusion: 尽管模型规模增大有助于降低幻觉比例，但符号元素仍然会混淆模型，表明LLM在处理此类输入时存在根本性的弱点，无论其规模如何。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [80] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS是一个基于大语言模型的系统，用于构建心理测量学中的“具体化网络”，解决了长期存在的测量验证挑战，并提供了三个包含超过55万个指标的全面具体化网络，有助于提高临床试验和公共政策的有效性。


<details>
  <summary>Details</summary>
Motivation: 心理测量在各学科中至关重要，但构建“具体化网络”（即概念和测量之间关系的理论图谱，用于建立效度）仍然是一个挑战，这可能导致临床试验未能检测到治疗效果或公共政策针对错误的结局。

Method: 提出了一种名为“具体化指标分析”（ALIGNS）的大语言模型系统，该系统使用经过验证的调查问卷进行训练，以生成具体化网络。

Result: ALIGNS生成了三个包含超过55万个跨心理学、医学、社会政策等领域的指标的具体化网络。在验证测试中，ALIGNS将NIH PROMIS焦虑和抑郁量表归为一个情绪困扰维度；识别出与儿童气质测量相关的四个潜在维度并质疑了一个现有维度；专家评估认为ALIGNS具有重要性、可及性和适用性。

Conclusion: ALIGNS是第一个将大语言模型应用于解决测量验证基础问题的系统，它通过大规模具体化网络分析来补充传统验证方法，并已免费提供（nomologicalnetwork.org）。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [81] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 该研究提出了一种基于技术间时间关系来识别新兴技术机会的框架。


<details>
  <summary>Details</summary>
Motivation: 技术机会是推动技术、行业和创新的关键信息。

Method: 该框架通过从专利数据集中提取文本，将文本主题映射以发现技术间关系，并跟踪这些主题随时间的变化来识别技术机会。该框架还利用大型语言模型提取主题，并使用聊天语言模型来辅助发现技术机会。

Result: 实验结果表明，人工智能技术正在朝着更加易于日常使用的方向发展。

Conclusion: 该方法证明了所提出的框架在识别未来技术机会方面的潜力。

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [82] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 该系统在BioNNE 2025多语言生物医学嵌套命名实体链接共享任务（英语和俄语）中排名第三，通过两阶段检索-排序、边界提示和数据集增强来解决嵌套和多语言实体链接问题。


<details>
  <summary>Details</summary>
Motivation: 现有的生物医学实体链接基准测试主要基于纯英语语料库，且只考虑扁平提及，未能充分探索嵌套和多语言提及的更现实场景。

Method: 提出一个轻量级流水线，不改变原有的实体链接模型，仅修改三个与任务对齐的组件：1.两阶段检索-排序：检索阶段使用原始预训练模型，排序阶段进行领域特定微调。2.边界提示：在排序阶段，用可学习的[Ms]/[Me]标签包裹提及，为编码器提供明确的、与语言无关的边界。3.数据集增强：自动扩展排序训练语料库，增加数据覆盖范围。

Result: 在BioNNE 2025排行榜上，该系统的双语BERT（BIBERT-Pipe）在多语言赛道上排名第三。

Conclusion: 该方法通过最小但符合原则的修改，实现了高效且具有竞争力的多语言生物医学嵌套实体链接。

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [83] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: LLM可用于将形式化证明转换为自然语言，并提高了可读性和准确性。


<details>
  <summary>Details</summary>
Motivation: 利用LLM的非形式化和摘要能力，将机器可验证的形式化证明转化为自然语言。

Method: 将LLM应用于形式化证明数据，并与原始的自然语言证明进行比较，以评估生成质量。

Result: 该方法能够生成高度可读且准确的自然语言证明，并已成功应用于Lean证明助手。

Conclusion: LLM在将形式化证明转换为自然语言方面显示出巨大潜力，可用于提高证明的可理解性和可用性。

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [84] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: LLM在金融教育问答中表现不佳，提出多智能体框架，通过角色扮演提示（基础生成器、证据检索器、专家审阅者）和检索增强生成（RAG）提升金融问答能力，在3532个金融教育问题上验证，相比基线模型，准确率提升6.6-8.3%，Gemini-2.0-Flash表现最佳，GPT-4o-mini性能媲美FinGPT。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在金融教育问答方面存在不足，无法处理金融领域复杂、专业的推理，如多步量化推理、专业术语理解和现实场景分析。

Method: 提出一个多智能体框架，包含基础生成器、证据检索器和专家审阅者，采用单程迭代和基于角色的提示（role-based prompting）来优化回答。框架结合了检索增强生成（RAG）技术，从6本金融教科书中检索证据，并设计了领域专家审阅者提示策略。

Result: 在3532个金融教育问题上进行评估，结果显示，与零样本思维链（zero-shot Chain-of-Thought）基线模型相比，基于批评的改进将答案准确率提高了6.6-8.3%。其中，Gemini-2.0-Flash取得了最佳性能。此外，该方法使GPT-4o-mini的性能与经过金融领域微调的FinGPT-mt_Llama3-8B_LoRA相当。

Conclusion: 该研究提出了一种经济高效的方法来改进金融问答，并为未来在多智能体金融LLM系统方面的研究提供了见解。

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [85] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: ML在推特情感分析中的表现，平均准确率为0.80，但需要注意类别不平衡和混淆矩阵的标准化报告。


<details>
  <summary>Details</summary>
Motivation: 评估机器学习在推特情感分析中的平均表现，评估研究间和研究内的异质性，并分析研究特征如何影响模型表现。

Method: 使用PRISMA指南，搜索学术数据库，筛选195个试验，来自20项研究，包含12个研究特征。使用双反正弦变换和三级随机效应模型分析了最常报告的性能指标——总体准确率。

Result: 在AIC优化的模型中，平均总体准确率为0.80 [0.76, 0.84]。

Conclusion: 1) 总体准确率常被使用但可能具有误导性，因为它对类别不平衡和情感类别数量敏感，需要进行标准化。2) 对模型性能进行标准化报告，包括提供独立测试集的混淆矩阵，对于可靠地跨研究比较机器学习分类器至关重要，但这似乎远非普遍做法。

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [86] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: Sign language processing (SLP) faces reproducibility challenges due to complex code. MultimodalHugs is a new framework based on Hugging Face designed to address these issues, supporting diverse data modalities and tasks beyond just sign language.


<details>
  <summary>Details</summary>
Motivation: Existing tools like Hugging Face are not flexible enough for sign language experiments, hindering reproducibility and fair comparisons in SLP research. A survey confirmed this issue among SLP researchers.

Method: Introduced MultimodalHugs, a framework built on top of Hugging Face, to enable diverse data modalities and tasks while maintaining Hugging Face's advantages. The framework includes a layer of abstraction for broader applicability.

Result: Demonstrated MultimodalHugs' ability to accommodate diverse modalities like pose estimation data for sign languages and pixel data for text characters through quantitative experiments.

Conclusion: MultimodalHugs provides a flexible and reproducible framework for SLP research and other use cases that don't fit standard Hugging Face templates.

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [87] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: 该研究提出了AncientDoc，一个用于评估视觉语言模型（VLM）在中文古籍处理能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有的文档基准测试主要关注英文印刷文本或简体中文，未能充分评估VLM在处理视觉和语言复杂度都较高的中文古籍方面的能力。中文古籍是承载中华历史文化的宝贵载体，但其数字化和理解面临挑战。

Method: 创建了一个包含五个任务（页面级OCR、白话翻译、推理式问答、知识式问答、文字变体问答）的基准测试AncientDoc，覆盖14种文档类型，超过100本书籍，约3000页。并基于此基准测试，使用多种指标评估了主流VLM，并引入了人类评分的大型语言模型进行辅助评分。

Result: （未在摘要中提供具体结果，但表明已在基准测试上评估了主流VLM）

Conclusion: （未在摘要中提供具体结论，但研究旨在填补VLM在中文古籍处理能力评估上的空白，并推动相关技术发展。）

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [88] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: MCP-AgentBench是一个新的基准测试，用于评估模型在MCP环境中的性能，它包含一个测试平台、600个查询和一种新的评估方法，旨在促进AI代理的进步。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法准确评估在MCP（模型上下文协议）新范式下代理的真实性能，导致对其价值的认知存在偏差，并且难以区分代理的熟练程度。

Method: 引入了一个名为MCP-AgentBench的全面基准测试，包括一个拥有33个服务器和188个工具的测试平台，设计了600个分布在6个不同类别中的查询，并提出了一种注重实际任务成功的、面向结果的评估方法MCP-Eval。

Result: 对领先的语言代理进行了广泛的实证评估，提供了基础性的见解。

Conclusion: MCP-AgentBench旨在为研究社区提供一个标准化、可靠的框架，用于构建、验证和改进能够充分利用MCP优势的代理，从而加速实现真正强大且可互操作的AI系统。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [89] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: LLMs在决策任务中表现出与性别、年龄和背景相关的偏见，但在摘要任务中偏见较少。跨语言分析显示英语和荷兰语之间存在相似的偏见模式。提出的缓解策略在减少偏见方面显示出潜力，尤其是在GPT-4o模型上。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在各个领域的快速应用，人们对其可能加剧社会不平等和信息偏见的问题日益担忧。本研究旨在深入探讨LLMs在背景、性别和年龄方面存在的偏见，并重点分析这些偏见对决策和摘要任务的影响，同时考察偏见的跨语言传播现象，并评估指令提示缓解策略的有效性。

Method: 本研究采用了Tamkin等人（2023）改编并翻译成荷兰语的数据集，构建了用于决策任务的151,200个独特提示和用于摘要任务的176,400个独特提示。研究在GPT-3.5和GPT-4o模型上测试了多种人口统计变量、指令、显著性水平和语言。

Result: 分析结果显示，在决策任务中，GPT-3.5和GPT-4o均表现出显著偏见，倾向于支持女性、年轻年龄以及特定背景（如非裔美国人）。相比之下，摘要任务中的偏见证据较少，尽管在英语中GPT-3.5在年龄方面表现出显著差异。跨语言分析表明，英语和荷兰语之间的偏见模式大体相似，但在特定人口统计类别上存在显著差异。新提出的缓解指令虽然未能完全消除偏见，但显示出减少偏见的潜力，最有效的指令使最有利和最不利人口统计群体之间的差距平均减少了27%。值得注意的是，与GPT-3.5不同，GPT-4o在所有英语提示中表现出更少的偏见，这表明在更新的模型中，基于提示的缓解策略具有特定潜力。

Conclusion: 本研究强调了在审慎采用LLMs的同时，进行特定情境下偏见测试的重要性，并指出了持续开发有效缓解策略以确保负责任地部署人工智能的必要性。

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [90] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: 通过结合权重空间（LoRA）和表示空间（ReFT）的参数高效微调（PEFT）方法，提出了一种名为HEFT的分层适应策略，该策略能以更少的计算资源实现更优的性能。


<details>
  <summary>Details</summary>
Motivation: LLM在专业推理任务上的适应性受计算资源限制，PEFT方法虽是解决方案，但存在权重空间和表示空间两种不同范式，探索两者结合的潜力。

Method: 提出HEFT分层适应策略，先在权重空间使用LoRA进行基础适应，再在表示空间使用ReFT进行精细调整。

Result: 在BoolQ基准上，HEFT策略仅用3个epoch就能达到85.17%的准确率，优于单独使用LoRA（20个epoch，85.05%）或ReFT（20个epoch，83.36%）的模型。

Conclusion: HEFT策略通过分层组合不同的PEFT方法，证明了其在提升LLM推理能力方面的有效性和效率，以更少的计算成本克服了模型适应的挑战。

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [91] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 本论文提出了一种通过语言和互动姿势之间的相关性来模拟多模态对话轮次组织（turn organization）的框架。


<details>
  <summary>Details</summary>
Motivation: 对话轮次组织（turn organization）已被多个领域的研究者研究，但特别是手势，尚未被编码到可用于机器学习的数据集中，本研究旨在填补这一空白。

Method: 通过提出语言和互动姿势之间的相关性来构建一个多模态对话轮次组织的模型，并开发了一种注释方法学，以丰富一个包含语义帧注释的多模态数据集（Frame2），加入对话轮次组织的语用帧（pragmatic frames）注释，特别是手势注释。

Result: 结果证实，面对面对话中的交流者确实会使用手势来传递、接取和维持对话轮次，并且还发现了先前未有文档记载的一些手势变体。

Conclusion: 交流者使用手势的行为源于语用帧（pragmatic frames）的概念化，这涉及到心智空间（mental spaces）、混合（blending）和概念隐喻（conceptual metaphors）。此外，研究数据表明，语用帧的注释有助于更深入地理解人类认知和语言。

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [92] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 通过引入话题引导的奖励机制，改进了多文档摘要（MDS）的内容选择，提高了摘要与源文档的主题一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的多文档摘要方法在整合多源信息、保持连贯性和主题相关性方面仍有改进空间，尤其是在利用大型语言模型方面。

Method: 提出了一种话题引导的强化学习方法，首先通过话题标签提示模型以增强摘要的信息量，然后设计了一种新的话题奖励机制，在GRPO框架下衡量生成摘要与源文档的主题一致性。

Result: 在Multi-News和Multi-XScience数据集上的实验结果表明，该方法系统性地优于现有的强基线方法。

Conclusion: 在多文档摘要任务中，利用话题线索可以有效提升摘要的质量。

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [93] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）可用于生成合成调查回复，但在多大程度上能复制人类回复的分布以及是否会加剧社会偏见方面尚不确定。本研究使用智利一项公开意见调查的真实人类回复来评估 LLM 生成的合成回复的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在多大程度上能够复制真实人类调查回复的分布，以及它们在多大程度上会产生或加剧社会偏见。

Method: 通过对 128 个提示-模型-问题组合进行基准测试，生成 189,696 个合成个体，并对 128 个问题-子样本对的性能指标（准确性、精确率、召回率和 F1 分数）进行荟萃分析，以测试关键社会人口统计学维度的偏见。评估范围包括 OpenAI 的 GPT 系列、o系列推理模型以及 Llama 和 Qwen 模型。

Result: 1. 合成回复在信任类问题上的表现极佳（F1 分数和准确率 > 0.90）。2. GPT-4o、GPT-4o-mini 和 Llama 4 Maverick 在此任务上的表现相当。3. 合成回复与人类回复的匹配度在 45-59 岁受访者中最高。总体而言，基于 LLM 的合成样本近似于概率样本的回复，但在项目级别存在显著的异质性。

Conclusion: 尽管基于 LLM 的合成样本可以近似概率样本的回复，但要捕捉公众舆论的全部细微差别仍然具有挑战性，需要仔细校准和额外的分布测试，以确保算法保真度和减少错误。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [94] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [95] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 我们发布了一个包含100,000个藏语条目和50,000个维吾尔语和蒙古语条目的新数据集（CMHG），用于少数民族语言的标题生成任务，并提供了一个由母语者标注的高质量测试集。


<details>
  <summary>Details</summary>
Motivation: 中国少数民族语言（如藏语、维吾尔语和蒙古语）的独特书写系统与国际标准存在差异，导致相关语料库严重缺乏，尤其是在监督学习任务（如标题生成）方面。

Method: 提出一个名为CMHG的新数据集，包含100,000个藏语条目，以及50,000个维吾尔语和50,000个蒙古语条目，并提供一个由母语者标注的高质量测试集。

Result: 构建了一个专门用于少数民族语言标题生成的CMHG数据集，以及一个高质量的测试集，为该领域的研究提供了宝贵资源。

Conclusion: CMHG数据集有望成为推动中国少数民族语言标题生成发展的宝贵资源，并为相关基准的开发做出贡献。

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [96] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: 无监督幻觉检测方法IRIS利用LLM的内部表征来评估事实的正确性，克服了现有方法的局限性，并在实验中表现优于其他无监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督幻觉检测方法依赖于与事实正确性无关的代理信号，导致检测探针的偏见，限制了其在不同数据集和场景下的泛化能力。

Method: IRIS框架提示LLM仔细验证给定陈述的真实性，并将其上下文嵌入作为训练的特征。同时，将响应的不确定性视为真实性的软伪标签。

Result: IRIS在实验中一致优于现有的无监督方法，并且适用于实时检测。

Conclusion: IRIS是一种完全无监督、计算成本低、即使在训练数据很少的情况下也能很好地工作的幻觉检测框架，能够有效识别LLM生成的幻觉内容。

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [97] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 开源大型语言模型（LLMs）在多标签意图分类任务上的表现分析，并与监督学习基线进行了比较。


<details>
  <summary>Details</summary>
Motivation: 评估开源LLMs在消费级硬件上进行多标签意图分类的可行性，并比较其与监督学习方法的性能差异。

Method: 在MultiWOZ 2.1数据集上，使用LLama2-7B-hf、Mistral-7B-v0.1和Yi-6B三个开源LLMs进行少样本（few-shot）意图分类。同时，将监督学习的BertForSequenceClassification模型作为基线进行比较。评估指标包括准确率、精确率、召回率、F1分数（micro, macro, weighted）、推理时间、VRAM需求等。

Result: Mistral-7B-v0.1在14个意图类别中的11个类别上F-Score优于其他两个生成模型，加权平均F-Score为0.50，并且具有较低的Humming Loss和较高的Jaccard Similarity。然而，基于BERT的监督学习分类器在性能上优于表现最好的少样本生成式LLM。

Conclusion: 研究为小型开源LLMs在识别复杂多意图对话方面提供了框架，并强调了与监督学习方法相比，开源LLMs在少样本设置下仍有改进空间，但其在自然语言理解方面的潜力不容忽视。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [98] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 这项研究利用社交媒体数据分析了双相情感障碍（BD）患者的语言变化轨迹，发现在确诊前后以及长达二十一年后，BD患者的语言都伴随着情绪、精神疾病、物质滥用、就医等多方面问题的显著变化，并观察到与季节性发作相关的十二个月周期性语言变化模式，女性患者的周期性可能更强。


<details>
  <summary>Details</summary>
Motivation: 临床上评估情感障碍（如双相情感障碍，BD）规模受限，因此利用具有高时间分辨率和长期追踪能力的社交媒体（SM）语言进行分析，以研究BD患者的语言变化轨迹。

Method: 提出一种确定用户诊断时间点的方法，并将其应用于分析BD、单相抑郁（UD）和健康对照（HC）用户在诊断前后（BD为确诊前3年到确诊后21年）的语言轨迹。

Result: 研究发现，BD确诊伴随着广泛的语言改变，反映了情绪波动、精神合并症、药物滥用、住院、身体合并症、异常思维和思维紊乱。在诊断后的二十年里，观察到反复出现与情绪相关的语言变化，并呈现出明显的十二个月周期性，提示季节性情绪发作。此外，有证据表明女性患者的周期性可能更强。

Conclusion: 研究结果为BD急性期和慢性期的语言改变提供了证据，验证并扩展了利用社交媒体进行可扩展心理健康监测的最新努力。

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [99] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: 该系统在BAREC 2025阿拉伯语可读性评估任务中获得第一名，使用了四种互补的Transformer模型的集成，并结合了数据增强和后处理技术。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语可读性评估中的类别不平衡和数据稀缺问题。

Method: 使用AraBERTv2, AraELECTRA, MARBERT, 和CAMeLBERT四种Transformer模型的集成，并结合加权训练、数据预处理、SAMER语料库重新标注、合成数据生成以及后处理。

Result: 在句子和文档级别分别达到了87.5%和87.4%的QWK分数，在六个赛道中均获得第一名。

Conclusion: 模型和损失函数的多样性、置信度融合以及智能数据增强是提高阿拉伯语可读性预测鲁棒性的有效方法。

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [100] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: Established questionnaires yield different and misleading results when applied to LLMs compared to ecologically valid ones.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the concerns surrounding the application of human-designed psychometric questionnaires to Large Language Models (LLMs), specifically addressing the lack of ecological validity and the resulting differences in outcomes compared to more contextually relevant questionnaires.

Method: The study conducted a comprehensive comparative analysis between established psychometric questionnaires (e.g., BFI, PVQ) and ecologically valid questionnaires when applied to LLMs.

Result: Established questionnaires produce substantially different LLM profiles compared to ecologically valid ones, misrepresenting psychological characteristics in user query contexts. They also suffer from insufficient items for stable measurement, create misleading impressions of stable LLM constructs, and exaggerate profiles for persona-prompted LLMs.

Conclusion: The findings caution against the use of established psychological questionnaires for LLMs due to their lack of ecological validity and the resulting inaccurate and misleading insights they provide.

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [101] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 本文构建了一个气候科学领域的知识图谱，以应对日益增长的气候文献检索挑战。该知识图谱支持结构化语义查询，能够回答具体问题，如“哪些模型在特定区域经过验证”或“哪些数据集常与特定的遥相关模式一起使用”。此外，它还可以与大型语言模型集成，应用于检索增强生成（RAG）系统，以提高气候相关问答的透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 气候科学文献日益复杂和庞大，研究人员难以在模型、数据集、地区和变量之间查找相关信息。

Method: 构建了一个包含气候出版物和更广泛科学文本的领域特定知识图谱（KG），并演示了如何使用 Cypher 查询来回答具体问题，以及如何将其与检索增强生成（RAG）系统集成。

Result: 该知识图谱能够支持结构化、语义化的查询，帮助研究人员发现精确的关联，例如哪些模型在特定区域得到了验证，或者哪些数据集通常与某些遥相关模式一起使用。其与大型语言模型在 RAG 系统中的集成，能够提高气候相关问答的透明度和可靠性。

Conclusion: 该工作超越了知识图谱的构建本身，展示了其在为气候研究人员、模型开发者等依赖准确、上下文相关科学信息的用户方面具有的实际价值。

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [102] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本研究提出一种微调大型语言模型（LLMs）的方法，用于阿拉伯语医疗文本生成，以改善医院管理系统（HMS），解决医疗资源有限和语言多样性等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的医院管理系统在提供准确、实时的医疗建议方面存在不足，尤其是在处理非结构化输入和代表性不足的语言时。此外，全球医疗系统面临着过度拥挤、资源有限和紧急医疗服务可用性差等挑战。

Method: 收集了来自社交媒体平台的阿拉伯语医疗对话数据集，包括患者的抱怨和医生的建议，并进行了数据清洗和预处理以适应不同的阿拉伯语方言。然后，对 Mistral-7B-Instruct-v0.2、LLaMA-2-7B 和 GPT-2 Medium 等先进的生成模型进行了微调。

Result: 微调后的 Mistral-7B 模型在准确率、召回率和 F1 分数方面取得了 68.5%、69.08% 和 68.5% 的平均 BERT 分数，优于其他模型。该系统能够对非正式输入生成连贯且相关的医疗回复。

Conclusion: 生成式人工智能（AI）有潜力改进医院管理系统，为全球医疗保健挑战提供可扩展且适应性强的解决方案，尤其是在语言和文化多样性方面。

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [103] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 通过生成合成数据来增强阿拉伯语医疗对话数据集，以改进阿拉伯语医疗聊天机器人。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗领域缺乏大规模、高质量的标注数据集，限制了医疗聊天机器人的发展。

Method: 使用ChatGPT-4o和Gemini 2.5 Pro生成80,000个合成的阿拉伯语医疗问答对，并将其与现有数据集结合，用于微调包括Mistral-7B和AraGPT2在内的五个大型语言模型。

Result: 使用合成数据微调后的模型在BERTScore指标和专家评估中表现更好，其中ChatGPT-4o生成的数据集效果尤为突出，可以提高F1分数并减少幻觉。

Conclusion: 合成数据增强是一种可行且实用的方法，可以解决低资源医疗自然语言处理中的领域特定语言模型增强问题，从而促进更具包容性、可扩展性和准确性的阿拉伯语医疗聊天机器人系统的发展。

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [104] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 该研究通过结合显度检测和语音识别来研究显度感知的自动语音识别（ASR），在奥地利德语对话上进行了实验。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索显度信息如何改善自动语音识别，并为语言学研究和对话系统提供新的途径。

Method: 首先，通过微调wav2vec2模型来开发显度检测器，用于对单词级别的显度进行分类。然后，利用该检测器对大型语料库进行自动韵律显度标注。基于这些标注，训练了能够同时转录单词及其显度级别的、新颖的显度感知ASR系统。

Result: 显度信息没有改变ASR系统的性能，但显度检测的准确率达到了85.53%（在识别正确的语句中）。

Conclusion: 研究表明，基于Transformer的模型可以有效地编码韵律信息，为韵律增强的ASR做出了新贡献，并具有应用于语言学研究和韵律感知对话系统的潜力。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [105] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: LLM驱动的社会模拟需要高质量、符合人口分布的模拟人集合。本文提出了一个系统框架，利用LLM从社交媒体数据中生成叙述性模拟人，通过质量评估进行筛选，并使用重要性采样和特定任务模块来确保其与人口统计和心理测量分布（如大五人格特质）的全局和局部对齐，从而减少偏差并实现准确灵活的社会模拟。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的社会模拟研究主要关注代理框架和模拟环境，而忽视了模拟人生成和潜在偏差问题。本文旨在解决如何构建真实反映现实世界人口多样性和分布的模拟人集合这一关键挑战。

Method: 本文提出一个系统框架，首先利用LLM从长期社交媒体数据生成叙述性模拟人，然后进行质量评估以过滤低保真度档案。接着，应用重要性采样实现与参考心理测量分布（如大五人格特质）的全局对齐。最后，引入一个特定任务模块，将全局对齐的模拟人集合调整以适应目标子人群，满足特定模拟情境的需求。

Result: 实验证明，本文提出的方法显著减少了人口层面的偏差，能够为广泛的研究和政策应用实现准确、灵活的社会模拟。

Conclusion: 本文提出的系统框架能够生成高质量、符合人口分布的模拟人集合，有效解决了现有LLM驱动的社会模拟在模拟人构建方面存在的不足，为计算社会科学领域提供了有力的支持。

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [106] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: DocExplainerV0是一个即插即用的边界框预测模块，可将答案生成与空间定位分离开来，以提高文档理解中答案定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在文档理解方面表现出色，但在准确定位答案方面仍存在挑战，这限制了它们的可解释性和实际应用。

Method: 提出DocExplainerV0，一个即插即用的边界框预测模块，将答案生成与空间定位解耦，使其能够应用于现有VLM，即使在无法进行微调的专有系统中也是如此。

Result: 通过系统评估，提供了文本准确性和空间定位之间差距的量化见解，表明正确的答案通常缺乏可靠的定位。还建立了一个基准，用于未来对更具可解释性和鲁棒性的文档信息提取VLM的研究。

Conclusion: DocExplainerV0通过将答案生成与空间定位分离开来，解决了现有VLM在文档答案定位方面的不足，并为未来的研究提供了一个标准化的框架。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [107] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 本研究对比了人类和大型语言模型（LLM）在文本语域上的差异，并为LLM创建了一个基准。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解大型语言模型（LLM）在生成文本时在多大程度上模仿或偏离人类的写作风格，特别是语域的变化，并找出LLM与人类在哪些方面存在显著且系统性的差异。

Method: 使用Biber的多维度分析（MDA）方法，对人类编写的文本和AI生成的对应文本（AI-Brown语料库）进行分析。同时，在捷克语（AI-Koditex语料库和捷克多维度模型）上也进行了类似分析。研究考察了16种前沿模型，并特别关注了基础模型和指令调优模型之间的区别。最后，创建了一个基准来比较和评估模型。

Result: 研究发现，LLM在某些语域维度上与人类写作存在差异。通过分析AI-Brown和AI-Koditex语料库，并比较不同模型（基础模型和指令调优模型），研究为LLM的语域表现提供了量化数据。

Conclusion: 本研究通过多维度分析，揭示了LLM在语域表达上与人类的差异，并提出了一个可用于评估和比较LLM的基准。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [108] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: LLMs在提供情感支持时倾向于不恰当的积极性，尤其是在高风险情境下，这可能导致回应被视为轻视或不切实际。通过分析人类和LLM的对话，并微调模型，我们开发了一个分类器来检测这种不协调的积极性，强调需要生成与情感强度相匹配的、恰当的积极回应。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在分析和解决大型语言模型（LLM）在提供情感支持时出现的“不协调的积极性”现象，即积极的回应未能恰当匹配对话的情感背景，导致被视为轻视、最小化或不切实际的乐观。研究的动机在于提高LLM在支持性对话中的有效性和可靠性，使其能够提供真正有益且符合用户期望的情感支持。

Method: 研究方法包括：1. 收集Reddit上真实用户与助手的对话数据，并按情感强度分为“轻度”（如关系紧张、一般建议）和“严重”（如悲伤、焦虑）两类。2. 使用LLM为相同语境生成回应，并进行比较分析。3. 微调LLM在具有强烈和较弱情感反应的数据集上，以研究不协调积极性背后的维度。4. 开发一个弱监督的多标签分类器集成（结合DeBERTa和MentalBERT），用于检测不同类型和不同情感强度（轻度、严重）下的不协调积极性。

Result: 分析显示，LLM比人类更容易表现出不切实际的积极性，尤其是在高风险（严重）情境下，其回应可能带有轻视和最小化的语调。分类器集成在检测不协调积极性的不同类型方面表现出改进。研究证实了LLM在高风险情感对话中存在不协调积极性的问题。

Conclusion: 研究结论指出，为了提供真正的情感支持，LLM需要超越生成通用的积极回应，转而关注“协调的”支持措施，平衡积极情感与情感承认。这对于使LLM与在线支持对话中的情感期望保持一致至关重要，并为构建更具情境意识和值得信赖的在线对话系统铺平了道路。Simply put, we need to make AI's positive responses more context-aware and emotionally appropriate, especially in serious situations.

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [109] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 现有的大型语言模型在处理长文本时存在局限性，特别是在法律文献等长文本分类任务中。本研究在5种语言中，使用XLM-RoBERTa、Longformer、GPT-3.5和GPT-4模型对比较议程项目（Comparative Agendas Project）的政策主题分类任务进行了实验。结果显示，专门为处理长输入而设计的Longformer模型并未表现出特别优势。GPT变体在与表现最佳的开放模型相比时，后者略胜一筹。对类别级别因素的分析表明，特定类别之间的支持和实质内容重叠对于长文本输入的性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的主流大型语言模型（如BERT及其衍生模型）在处理长文本输入方面存在长度限制，这对于需要处理长篇法律文献等文本的分类任务来说是一个严峻的问题。

Method: 在5种语言中，对XLM-RoBERTa、Longformer、GPT-3.5和GPT-4模型在比较议程项目（Comparative Agendas Project）的多类别分类任务（包含21个政策主题标签）进行了实验评估。

Result: Longformer模型在处理长文本输入方面并未显示出特别优势。在与表现最佳的开放模型相比时，GPT变体模型略逊一筹。对类别级别因素的分析表明，特定类别之间的支持和实质内容重叠对于长文本输入的模型性能非常重要。

Conclusion: 对于需要处理长文本（如法律文献）的分类任务，专门设计的长文本模型（如Longformer）并不一定优于其他模型。在比较不同模型（包括GPT变体和开放模型）的性能时，开放模型表现出一定的优势。模型在处理长文本时的性能受到类别之间支持和内容重叠的影响。

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [110] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 SI FACT 的新框架，通过自动生成和利用对比学习数据，显著提高了大型语言模型在知识密集型任务中的忠实度，并降低了对内部知识的依赖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型任务中常常由于优先选择内部知识而非给定上下文而产生不忠实的响应，这种现象被称为知识冲突。

Method: 提出了一种名为 Self Improving Faithfulness Aware Contrastive Tuning (SI FACT) 的自改进框架。该框架利用自指令机制，让基础语言模型自动生成高质量、结构化的对比学习数据（包括锚点样本、语义等价的正样本和模拟不忠实场景的负样本），从而降低手动标注成本。随后，应用对比学习训练模型，使其在表示空间中拉近忠实响应，推开不忠实响应。

Result: 在 ECARE KRE 和 COSE KRE 这两个知识冲突评估基准上进行实验，结果显示基于 Llama3 8B Instruct 的 SI FACT 模型将上下文召回率（Contextual Recall Rate）比最佳基线方法提高了 6.2%，同时显著降低了对内部记忆的依赖。

Conclusion: SI FACT 在提高 LLM 的上下文忠实度方面表现出强大的有效性和高数据效率，为构建更主动、更值得信赖的语言模型提供了实际途径。

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [111] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: SMoE模型虽然计算高效，但需要加载所有专家参数，导致内存占用高。 DERN框架通过剪枝冗余专家、分解专家至神经元层面并重组，实现了50%稀疏度下性能提升5%以上，且无需重新训练，降低了SMoE模型的部署难度。


<details>
  <summary>Details</summary>
Motivation: SMoE模型尽管计算效率高，但其加载所有专家参数的特性导致了高内存消耗和部署困难。先前的工作主要集中在专家层面进行优化，忽略了神经元层面的结构。

Method: DERN框架首先利用路由器的统计信息剪枝冗余专家；然后将专家分解为神经元级别的专家片段，并将每个片段分配给最兼容的保留专家；最后，在每个保留专家内部合并片段，构建紧凑的表示。

Result: 在Mixtral、Qwen和DeepSeek SMoE模型上的实验表明，DERN在50%的专家稀疏度下，在常识推理和MMLU基准测试上的性能提高了5%以上，并且无需额外训练。此外，该方法显著减少了专家数量和内存使用量。

Conclusion: DERN框架通过在神经元层面进行剪枝和重组，有效解决了SMoE模型的高内存占用问题，提高了模型性能，并简化了SMoE LLM的实际部署。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [112] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: In-context learning (ICL) enables autoregressive models to perform tasks without retraining, but its learning capabilities and generalizability are limited. While mathematically constituting learning, ICL relies heavily on prior knowledge and prompt exemplars, showing sensitivity to prompt style and distributional shifts, particularly with methods like chain-of-thought. The ad-hoc encoding of autoregression limits its all-purpose generalizability.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the nature of learning in in-context learning (ICL) and its limitations, questioning whether deduction implies true learning and characterizing its effectiveness and generalizability.

Method: A large-scale analysis of ICL was conducted, involving ablation studies and controlling for factors such as memorization, pretraining, distributional shifts, and prompting style and phrasing.

Result: The study found that ICL is an effective learning paradigm but has limitations in learning and generalizing to unseen tasks. Accuracy was observed to be insensitive to exemplar distribution, model, prompt style, and linguistic features when exemplars become numerous. However, ICL exhibits distributional sensitivity, especially with chain-of-thought prompting, due to deducing patterns from prompt regularities.

Conclusion: Autoregression's ad-hoc encoding is not a robust mechanism for learning, indicating limited all-purpose generalizability for ICL. While ICL is a form of learning, its reliance on prior knowledge and prompt specifics, along with its sensitivity to prompt design and data distribution, restricts its ability to truly learn and generalize to novel situations.

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [113] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: Transformer模型在处理长文本时存在长度限制，截断文本会导致评估不完整。本研究评估了XLNet, Longformer, ModernBERT, Mamba, Llama等模型在Kaggle ASAP 2.0数据集上的长文本处理能力，以解决自动化论文评分中的长度问题。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长文本时存在长度限制，截断文本会导致评估不完整，这在自动化论文评分中是一个关键问题。

Method: 评估了包括XLNet, Longformer, ModernBERT, Mamba, Llama在内的几种改进Transformer架构的模型，用于处理超出标准长度限制的文本，并在Kaggle ASAP 2.0数据集上进行了测试。

Result: 目前尚无具体结果，但评估了多种模型在Kaggle ASAP 2.0数据集上的长文本处理能力。

Conclusion: 目前尚无具体结论，但研究旨在解决Transformer模型在自动化论文评分中处理长文本的长度限制问题。

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [114] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 通过结合云端和边缘计算，利用多智能体提示框架来优化大型语言模型的推理和解决问题的能力，并引入了RefactorCoderQA基准和RefactorCoder-MoE模型进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准的局限性，旨在优化大型语言模型（LLMs）的推理和解决问题的能力。

Method: 提出了一种新颖的云边协同架构，包含三个组件：边缘的GuideLLM（提供方法论指导）、云端的SolverLLM（生成代码解决方案）和JudgeLLM（评估解决方案的正确性和质量）。引入了RefactorCoderQA基准，该基准涵盖软件工程、数据科学、机器学习和自然语言处理等多个领域，并使用来自Stack Overflow的真实编码挑战。

Result: 在RefactorCoderQA基准上，经过微调的RefactorCoder-MoE模型取得了76.84%的准确率，显著优于现有的开源和商业基线。人类评估验证了生成解决方案的可解释性、准确性和实践相关性。还评估了吞吐量和延迟等系统级指标。

Conclusion: 所提出的云边协同架构能够有效优化LLMs的推理和解决问题的能力，RefactorCoderQA基准和RefactorCoder-MoE模型在评估和提升LLMs的编码能力方面表现出色。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [115] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive通过自动合成复杂问题和端到端多轮强化学习来增强LLMs的搜索能力，在BrowseComp等基准测试中取得了新的开源SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有的开放LLMs在结合浏览工具以解决复杂现实世界任务时，由于长远推理能力有限和缺乏足够难度的监督数据，表现不佳。

Method: 1. 自动合成复杂、困难且难以找到的问题。 2. 应用端到端多轮强化学习（RL）来增强LLMs的深度搜索长远推理能力。

Result: DeepDive-32B在BrowseComp上取得了新的开源SOTA结果，优于WebSailor、DeepSeek-R1-Browse和Search-o1。多轮RL训练提升了深度搜索能力，并在多个基准测试中显著提高了性能。DeepDive还支持测试时工具调用扩展和并行采样。

Conclusion: DeepDive通过其提出的方法有效提升了开放LLMs在作为深度搜索代理时的性能，解决了长远推理和数据稀疏性挑战，并在多个基准测试中取得了优异成果。

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [116] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE是一种文本适应方法，通过训练VAE来学习文本的潜在表示，并微调解码器，以改进ASR模型在特定领域上的表现，无需额外的运行时成本。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练ASR模型（如Whisper）在处理特定领域的词汇和表达时仍需进行领域自适应，但实际收集语音数据的方法往往不切实际，因此需要一种仅基于文本的适应方法。

Method: WhisTLE训练一个变分自编码器（VAE）来模拟来自文本的编码器输出，并使用学习到的文本到潜在表示的编码器来微调解码器，还可以选择性地结合文本到语音（TTS）适应。在推理时，恢复原始编码器，不产生额外的运行时成本。

Result: 在四个领域外的数据集和四个ASR模型上，与仅使用TTS的方法相比，使用TTS的WhisTLE将词错误率（WER）相对降低了12.3%，并在32种场景中的27种优于所有非WhisTLE基线。

Conclusion: WhisTLE是一种有效的、仅基于文本的ASR模型领域自适应方法，能够显著提高模型在特定领域上的表现，并且在推理时没有额外的计算开销。

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [117] [Image detection-based high-throughput sorting of particles using traveling surface acoustic waves in microscale flows](https://arxiv.org/abs/2509.09692)
*Nikhil Sethia,Joseph Sushil Rao,Amit Manicka,Michael L. Etheridge,Erik B. Finger,John C. Bischof,Cari S. Dutcher*

Main category: physics.app-ph

TL;DR: 该研究提出了一种基于图像识别和表面声波的微流控大颗粒分选技术，可用于分选大于50微米的微塑料和生物材料。


<details>
  <summary>Details</summary>
Motivation: 虽然基于图像识别的细胞和颗粒（<50微米）分选技术取得了显著进展，但将其应用于大颗粒（>50微米）生物材料的高通量分选仍然有限。需要一种能够提取丰富信息（尺寸、形状、颜色、形态和光密度）的无标记图像识别技术，并能与非接触式驱动机制（如表面声波）集成。

Method: 研究实现了一种高通量图像识别大颗粒微流控分选技术。该技术通过光学手段识别颗粒尺寸，并利用表面声波（TSAW）脉冲的动量转移进行分选，将尺寸大于特定阈值的颗粒移出。研究了控制参数（TSAW脉冲持续时间和功率、入口流速、样品稀释度）对分选效率和通量的影响。

Result: 该技术能够对包含约45-180微米尺寸的聚乙烯颗粒的二元混合物进行分选。在选定的条件下，该分选技术平均每秒可分选约4.9-34.3个颗粒（每秒执行约2-3次驱动），具体取决于初始样品组成和浓度。

Conclusion: 该研究成功实现了一种高通量图像识别大颗粒微流控分选技术，并验证了其在分离不同尺寸聚乙烯颗粒方面的有效性，为大颗粒生物材料和微塑料的分选提供了新的解决方案。

Abstract: Large particle sorters have potential applications in sorting microplastics
and large biomaterials (>50 micrometer), such as tissues, spheroids, organoids,
and embryos. Though great advancements have been made in image-based sorting of
cells and particles (<50 micrometer), their translation for high-throughput
sorting of larger biomaterials and particles (>50 micrometer) has been more
limited. An image-based detection technique is highly desirable due to richness
of the data (including size, shape, color, morphology, and optical density)
that can be extracted from live images of individualized biomaterials or
particles. Such a detection technique is label-free and can be integrated with
a contact-free actuation mechanism such as one based on traveling surface
acoustic waves (TSAWs). Recent advances in using TSAWs for sorting cells and
particles (<50 micrometer) have demonstrated short response times (<1 ms), high
biocompatibility, and reduced energy requirements to actuate. Additionally,
TSAW-based devices are miniaturized and easier to integrate with an image-based
detection technique. In this work, a high-throughput image-detection based
large particle microfluidic sorting technique is implemented. The technique is
used to separate binary mixtures of small and large polyethylene particles
(ranging between ~45-180 micrometer in size). All particles in flow were first
optically interrogated for size, followed by actuations using momentum transfer
from TSAW pulses, if they satisfied the size cutoff criterion. The effect of
control parameters such as duration and power of TSAW actuation pulse, inlet
flow rates, and sample dilution on sorting efficiency and throughput was
observed. At the chosen conditions, this sorting technique can sort on average
~4.9-34.3 particles/s (perform ~2-3 actuations/s), depending on the initial
sample composition and concentration.

</details>


### [118] [Coupled CFD-DEM model for dry powder inhalers simulation: validation and sensitivity analysis for the main model parameters](https://arxiv.org/abs/2509.09694)
*Raffaele Ponzini,Roberto Da Vià,Simone Bnà,Ciro Cottini,Andrea Benassi*

Main category: physics.app-ph

TL;DR: 计算流体动力学（CFD）和离散元方法（DEM）的耦合模型可用于模拟干粉吸入器（DPI）中的药物雾化过程，并与实验数据进行验证。


<details>
  <summary>Details</summary>
Motivation: 计算技术在干粉吸入器（DPI）设计和药物雾化机制研究中的应用日益广泛，需要验证计算模型以确保其准确性。

Method: 使用CFD模拟吸入过程中DPI内部的空气流动，使用DEM模拟药物粉末颗粒的分散和雾化。将耦合CFD-DEM模型与已发布的实验数据进行对比验证。

Result: 详细比较了计算结果和实验结果在流体和粉末流动方面的吻合程度，讨论了模型中的近似和假设。

Conclusion: 经过校准的DPI模型具有潜力和应用前景，但仍需进一步研究以实现完全定量的预测模型。

Abstract: The use of computational techniques in the design of dry powder inhalers
(DPI), as well as in unravelling the complex mechanisms of drug aerosolization,
has increased significantly in recent years. Computational fluid dynamics (CFD)
is used to study the air flow, inside the DPI, during the patient inspiratory
act while discrete element methods (DEM) are used to simulate the dispersion
and aerosolization of the drug product powder particles. In this work we
discuss the possibility to validate a coupled CFD-DEM model for the NextHaler
DPI device against previously published experimental data. The approximations
and assumptions made are deeply discussed. The comparison between computational
and experimental results is detailed both for fluid and powder flows. Finally,
the potential and possible applications of a calibrated DPI model are discussed
as well as the missing elements necessary to achieve a fully quantitatively
predictive computational model.

</details>


### [119] [Reinforcement learning for spin torque oscillator tasks](https://arxiv.org/abs/2509.10057)
*Jakub Mojsiejuk,Sławomir Ziętek,Witold Skowroński*

Main category: physics.app-ph

TL;DR: 我们使用强化学习（RL）来自动同步旋子振荡器（STO）。


<details>
  <summary>Details</summary>
Motivation: 自动同步STO以达到目标频率。

Method: 使用宏观自旋Landau-Lifschitz-Gilbert-Slonczewski方程模拟STO，并训练两种RL智能体在固定步数内同步到目标频率。探索了对基础任务的修改，以提高同步的收敛性和能源效率。

Result: 在模拟环境中，RL智能体成功实现了STO的同步，并探索了改进收敛性和能源效率的方法。

Conclusion: 强化学习是一种有效的方法，可以自动同步STO，并且可以通过调整RL智能体和任务来进一步提高其性能。

Abstract: We address the problem of automatic synchronisation of the spintronic
oscillator (STO) by means of reinforcement learning (RL). A numerical solution
of the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to
simulate the STO and we train the two types of RL agents to synchronise with a
target frequency within a fixed number of steps. We explore modifications to
this base task and show an improvement in both convergence and energy
efficiency of the synchronisation that can be easily achieved in the simulated
environment.

</details>


### [120] [Morphogenetic mechanical metamaterials: Emerging tensor properties from self-organized structures](https://arxiv.org/abs/2509.10277)
*Thomas Fromentèze,Philippe Michaud,Ali Hassny,Vincent Pateloup*

Main category: physics.app-ph

TL;DR: 生成一个基于形态发生学的去中心化生成模型，用于自主生长具有受控张量特性的机械结构。


<details>
  <summary>Details</summary>
Motivation: 理解生物体如何自发地开发复杂的函数结构，为工程设计带来了创新的方法。

Method: 通过各向异性扩散调整图灵的反应-扩散概念，实现微结构的局部出现，以实现目标正交各向异性张量，而无需伴随或拓扑优化循环。形态发生参数与通过均质化技术获得的有效弹性张量之间的关系数据库。

Result: 通过力学隐身（mechanical cloaking）的例子进行了实验演示，验证了该方法能够独立控制局部各向异性和刚度，并有效地将结构缺陷从力学场中隐藏起来。

Conclusion: 该方法不仅解决了传统拓扑优化方法的关键局限性，还为可扩展、鲁棒的机械超材料设计开辟了新的仿生途径。

Abstract: Understanding how living organisms spontaneously develop complex functional
structures inspires innovative approaches in engineering design. Here, we
introduce a decentralized generative model based on morphogenesis to
autonomously grow mechanical structures with controlled tensorial properties.
By adapting Turing's reaction-diffusion concept through anisotropic diffusion,
our approach enables the local emergence of microstructures exhibiting tailored
stiffness and anisotropy, achieving target orthotropic tensors without adjoint
or topology optimization loops. The synthesis of these structures relies on a
database linking morphogenetic parameters to effective elastic tensors obtained
through homogenization techniques. We experimentally demonstrate this concept
through a mechanical cloaking example, validating our method's capability to
independently control local anisotropy and rigidity, and effectively conceal
structural defects from mechanical fields. This approach not only addresses key
limitations of traditional topology optimization methods but also opens new
bio-inspired pathways for scalable and robust mechanical metamaterial design.

</details>


### [121] [Control of nanomechanical resonances by an electron beam](https://arxiv.org/abs/2509.10302)
*Toji Thomas,Kevin F. MacDonald,Eric Plum*

Main category: physics.app-ph

TL;DR: 电子束与纳米机械振子上的电荷之间的排斥力可以增加振子的共振频率，从而实现对振子的控制和电荷传感。


<details>
  <summary>Details</summary>
Motivation: 在本文中，我们观察到纳米机械振子的共振频率强依赖于电荷。 已经证明，电子束和纳米机械梁上的电荷之间的排斥会产生硬化，从而增加其共振频率。

Method: 通过扫描电子显微镜中的电子束与微尺度长度和纳米尺度横截面的悬臂梁的相互作用来观察共振频移。

Result: 观察到每纳库仑的共振位移约为 1%。

Conclusion: 电子束与纳米机械振子上的电荷之间的排斥力可以增加振子的共振频率，从而实现对振子的控制和电荷传感。

Abstract: The sensitivity of mechanical resonators to physical quantities such as
acceleration, pressure, mass and temperature enables them to underpin sensing
and metrology applications. Here, we observe that the resonance frequency of a
nanomechanical resonator depends strongly on charging. We show that repulsion
between an electron beam and charge accumulated on a nanomechanical cantilever
yields a stiffening that increases its resonance frequency, providing a
mechanism for controlling resonators and sensing charge. For a cantilever of
microscale length and nanoscale cross-section interacting with the electron
beam of a scanning electron microscope, we observe a resonance shift on the
order of 1% per nanocoulomb.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [122] [CaCd$_2$P$_2$: A Visible-Light Absorbing Zintl Phosphide Stable under Photoelectrochemical Water Oxidation](https://arxiv.org/abs/2509.09803)
*Guillermo L. Esparza,Zhenkun Yuan,Muhammad Rubaiat Hasan,Yagmur Coban,Gideon Kassa,Vivek Shastry Devalla,Tejas Nivarty,Jack R. Palmer,Jifeng Liu,Kirill Kovnir,Geoffroy Hautier,David P Fenning*

Main category: cond-mat.mtrl-sci

TL;DR: CaCd2P2是一种可见光吸收材料，在碱性条件下进行氧气演化反应（OER）时，表面会发生光稳定转化，提高了稳定性，并且可以与CoPi协同作为光电催化剂。


<details>
  <summary>Details</summary>
Motivation: 寻找稳定且强吸收的太阳能燃料光电极材料，特别是用于氧气演化反应（OER），是太阳能燃料领域面临的关键挑战。现有材料在稳定性与吸收能力之间存在折衷。

Method: 利用高通量计算筛选，识别出CaCd2P2材料。通过光电化学测量、显微镜和光谱学技术，研究CaCd2P2在碱性OER条件下的表面转化和稳定性。

Result: CaCd2P2在碱性OER条件下表现出光稳定化的表面转化，提高了稳定性，并能与CoPi协同作为稳定的光电催化剂。

Conclusion: CaCd2P2在OER中表现出的光诱导稳定性，为设计和使用低带隙半导体进行光电化学能量转换提供了新的机会。AM2P2家族的其他Zintl相也值得进一步探索。

Abstract: A key bottleneck to solar fuels is the absence of stable and strongly
absorbing photoelectrode materials for the oxygen evolution reaction (OER).
Modern approaches generally trade off between stable but weakly absorbing
materials, such as wide bandgap oxides, or strongly absorbing materials that
rely on encapsulation for stability and are weakly catalytic, such as the III-V
family of semiconductors. Of interest are materials like transition metal
phosphides, such as FeP$_2$, that are known to undergo beneficial in situ
surface transformations in the oxidative environment of OER, though stability
has remained a primary hurdle. Here we report on CaCd$_2$P$_2$, a Zintl phase
visible-light absorber with favorable 1.6 eV bandgap, that we identified using
high-throughput computational screening. Using a combination of
photoelectrochemical measurements, microscopy, and spectroscopy, we show that
CaCd$_2$P$_2$ undergoes a light-stabilized surface transformation that renders
it stable under alkaline OER conditions. We also show that the well known OER
catalyst CoPi can act as a stable co-catalyst in synergy with the
\textit{in-situ} CaCd$_2$P$_2$ surface. The light-induced stabilization that
CaCd$_2$P$_2$ displays is in sharp contrast to the photocorrosion commonly
observed in visible light-absorbing photoelectrodes. The broader AM$_2$P$_2$
family of Zintl phases offers a significant opportunity to explore stabilizing
interface chemistry and re-design the manner in which low-bandgap
semiconductors are used for photoelectrochemical energy conversion.

</details>


### [123] [Evolution from Topological Dirac Metal to Flat-band-Induced Antiferromagnet in Layered KxNi4S2 (0<=x<=1)](https://arxiv.org/abs/2509.09903)
*Hengdi Zhao,Xiuquan Zhou,Hyowon Park,Tianqi Deng,Brandon Wilfong,Alann P. Au II,Samuel E. Pate,Craig M. Brown,Hui Wu,Tushar Bhowmick,Tessa McNamee,Ravhi Kumar,Yu-Sheng Chen,Zhi-Li Xiao,Russell Hemley,Weizhao Cai,Shanti Deemyad,Duck-Young Chung,Stephan Rosenkranz,Mercouri G. Kanatzidis*

Main category: cond-mat.mtrl-sci

TL;DR: KxNi4S2材料在不同钾含量下可同时展现狄拉克锥和能带平坦的特性，并可通过钾的脱嵌实现两者的切换。


<details>
  <summary>Details</summary>
Motivation: 寻找同时拥有狄拉克锥和能带平坦特性，并且能够相互切换的量子材料体系。

Method: 通过化学方法对KxNi4S2材料进行脱钾处理，并结合第一性原理计算和高迁移率实验进行表征。

Result: 在钾含量x=1时，观察到具有拓扑非平凡Z2指数的狄拉克金属态，迁移率高达1471 cm2V-1s-1；当钾含量接近0时，出现由能带平坦引起的反铁磁态，居里温度最高可达10.1K。

Conclusion: KxNi4S2材料为探索新兴量子现象提供了一个多功能的平台，并展示了原位调控由狄拉克锥、能带平坦及其相互作用主导的量子材料的可行途径。

Abstract: Condensed matter systems with coexisting Dirac cones and flat bands, and a
switchable control between them within a single system, are desirable but
remarkably uncommon. Here we report a layered quantum material system, KxNi4S2
(0 <= x <= 1), that simultaneously hosts both characteristics without involving
typical Kagome/honeycomb lattices. Enabled by a topochemical K-deintercalation
process, the Fermi surface can be fine-tuned continuously over a wide range of
energies. Consequently, a non-magnetic Dirac-metal state with a topological
nontrivial Z2 index of 1;(000), supported by first-principles calculations and
high mobility up to 1471 cm2V-1s-1, is observed on the K-rich x = 1 side,
whereas a flat-band induced antiferromagnetic state with TN up to 10.1 K
emerges as K-content approaches 0. The KxNi4S2 system offers a versatile
platform for exploring emerging phenomena and underscores a viable pathway for
in-situ control of quantum materials dominated by Dirac cones, flat bands, and
their interplay.

</details>


### [124] [Predicting void nucleation in microstructure with convolutional neural networks](https://arxiv.org/abs/2509.09938)
*Abhijith Thoopul Anantharanga,Jackson Plummer,Saryu Fensin,Brandon Runnels*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出一种基于U-Net注意力机制的卷积神经网络，用于预测钽材料在高应变率加载下的空洞成核概率，并成功识别出潜在的成核位点，为理解材料失效机理提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 理解在高应变率加载下延性材料的空洞成核机制至关重要，但传统方法难以捕捉其根本原因。

Method: 利用包含晶粒取向和晶界能量的多通道输入，训练U-Net注意力机制卷积神经网络，以像素级别准确预测空洞成核概率，并采用Focal loss解决类别不平衡问题。

Result: 所提出的模型能够准确预测空洞成核位点，并发现额外的潜在成核位点，显示出其能够捕捉空洞成核的随机性。

Conclusion: 基于卷积神经网络的模型能够有效预测空洞成核位点，并考虑了晶界能量和晶粒取向等综合因素，为理解延性材料因散裂引起的失效机理提供了新的机器学习方法。

Abstract: Void nucleation in ductile materials subjected to high strain-rate loading
remains a critical yet elusive phenomenon to understand. Traditional methods to
understand void nucleation typically rely on experiments and molecular dynamics
and do not capture the underlying factors leading to void nucleation. In this
study, a convolutional neural network, specifically a U-Net enhanced with
attention gates is developed, to predict void nucleation probability in
pristine tantalum microstructures. The approach leverages a multi-channel
input, incorporating four channels of grain orientations and an additional
channel of grain boundary energy calculated via the lattice matching method.
Void nucleation probability fields are determined from post-mortem micrographs
and serve as ground truth, distinguishing void from no-void regions at the
pixel level. Pixel-level class imbalance, commen in such images, is addressed
by using Focal loss to guide the network's training to predict void nucleation
sites more effectively. The model not only predicts void nucleation sites
consistent with ground-truth but also reveals additional potential void
nucleation sites, capturing the stochastic nature of void nucleation. This
study shows that CNN-based models can predict void nucleation sites while
considering combined interplay of factors such as grain boundary energy and
grain orientation. In this way, machine learning can serve as a means to
understand the underlying factors leading to void nucleation thereby
contributing to a fundamental understanding of failure due to spallation in
ductile materials.

</details>


### [125] [Scaling High-Performance Nanoribbon Transistors with Monolayer Transition Metal Dichalcogenides](https://arxiv.org/abs/2509.09964)
*Tara Peña,Anton E. O. Persson,Andrey Krayev,Áshildur Friðriksdóttir,Kathryn Neilson,Zhepeng Zhang,Anh Tuan Hoang,Jerry A. Yang,Lauren Hoang,Andrew J. Mannix,Paul C. McIntyre,Eric Pop*

Main category: cond-mat.mtrl-sci

TL;DR: 通过多重图案化工艺制备了基于单层二维半导体的n型和p型纳米带晶体管，器件沟道宽度达到25纳米，沟道长度达到50纳米，且器件性能优于单门纳米带的先前报道。


<details>
  <summary>Details</summary>
Motivation: 为了实现纳米级晶体管的尺寸缩减，需要减小沟道长度、宽度和厚度。单层二维半导体（2DS）在厚度缩减方面具有优势，但之前的研究主要集中在较宽的沟道上。本研究旨在探索在纳米尺度下二维半导体沟道的性能。

Method: 采用多重图案化工艺制备了沟道宽度小于50纳米的单层二维半导体纳米带晶体管。使用了‘锚定’接触来提高器件良率。利用包括尖端增强光致发光在内的纳米尺度成像技术来评估器件的边缘退化情况。

Result: 制备的n型MoS$_{2}$、WS$_{2}$和p型WSe$_{2}$纳米带晶体管在1V的漏源电压下，载流子迁移率分别达到了560、420和130 μA μm$^{-1}$。这些性能超越了先前单门纳米带的报道，特别是WS$_{2}$器件性能提升了100多倍，并且实现了常关型（增强型）器件。

Conclusion: 研究表明，自上而下加工的二维半导体纳米带是未来纳米片晶体管的有希望的构建模块。

Abstract: Nanoscale transistors require aggressive reduction of all channel dimensions:
length, width, and thickness. While monolayer two-dimensional semiconductors
(2DS) offer ultimate thickness scaling, good performance has largely been
achieved only in micrometer-wide channels. Here, we demonstrate both $\it{n}$-
and $\it{p}$-type nanoribbon transistors based on monolayer 2DS, fabricated
using a multi-patterning process, reaching channel widths down to 25 nm and
lengths down to 50 nm. 'Anchored' contacts improve device yield, while
nanoscale imaging, including tip-enhanced photoluminescence, reveals minimal
edge degradation. The devices reach on-state currents up to 560, 420, and 130
$\mu$A $\mu$m$^{-1}$ at 1 V drain-to-source voltage for $\it{n}$-type
MoS$_{2}$, WS$_{2}$, and $\it{p}$-type WSe$_{2}$, respectively, integrated with
thin high-$\kappa$ dielectrics. These results surpass prior reports for
single-gated nanoribbons, the WS$_{2}$ by over 100 times, even in normally-off
(enhancement-mode) transistors. Taken together, these findings suggest that top
down patterned 2DS nanoribbons are promising building blocks for future
nanosheet transistors.

</details>


### [126] [Elemental Frequency-Based Supervised Classification Approach for the Search of Novel Topological Materials](https://arxiv.org/abs/2509.09978)
*Zodinpuia Ralte,Ramesh Kumar,Mukhtiyar Singh*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种基于频率统计描述符的机器学习方法，用于预测材料的拓扑性质，无需依赖晶体对称性，并能有效筛选出新的拓扑材料。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑材料搜索方法计算量大或受限于晶体对称性。本研究旨在提出一种更高效、更通用的方法。

Method: 提出一种基于频率统计描述符的机器学习方法，该方法不依赖于波函数的晶体对称性，并能仅根据化学式预测材料的拓扑性质。使用支持向量机（SVM）和随机森林（RF）模型，并采用5折交叉验证进行性能评估。最后，利用第一性原理计算验证了预测结果。

Result: 使用SVM模型达到了82%的分类准确率，使用RF模型达到了83%的分类准确率。在未见过的数据集上成功识别了22种常见的材料。第一性原理计算证实了这些材料具有狄拉克、外尔和节点线半金属相的拓扑特征。

Conclusion: 基于频率的描述符是一种实用且简便的方法，可用于寻找具有特定物理性质的新型拓扑材料。该方法为可扩展、数据驱动的复杂材料拓扑性质筛选奠定了基础。

Abstract: The machine learning based approaches efficiently solves the goal of
searching the best materials candidate for the targeted properties. The search
for topological materials using traditional first-principles and symmetry-based
methods often requires lots of computing power or is limited by the crystalline
symmetries. In this study, we present frequency-based statistical descriptors
for machine learning-driven topological material's classification that is
independent of crystallographic symmetry of wave functions. This approach
predicts the topological nature of a material based on its chemical formula.
With a balanced dataset of 3910 materials, we have achieved classification
accuracies of 82\% with the Support Vector Machine (SVM) model and 83\% with
the Random Forest (RF) model, where both models have trained on common
frequency based features. We have checked the performances of the models using
$5-fold$ cross-validation approach. Further, we have validated the models on a
dataset of unseen binary compounds and have efficiently identified 22 common
materials using both the models. Next, we implemented the $first-principles$
approach to confirm the topological nature of these predicted materials and
found the topological signatures of Dirac, Weyl, and nodal-line semimetallic
phases. Therefore, we have demonstrated that the implications of
frequency-based descriptors is a practical and less complex way to find novel
topological materials with certain physical post-processing filters. This
approach lays the groundwork for scalable, data-driven topological property
screening of complex materials.

</details>


### [127] [Unveiling the Role of Solvents in DBTTF:HATCN Ternary Cocrystals](https://arxiv.org/abs/2509.09998)
*Ana M. Valencia,Lisa Schraut-May,Marie Siegert,Sebastian Hammer,Beatrice Cula,Alexandra Friedrich,Holger Helten,Jens Pflaum,Caterina Cocchi,Andreas Opitz*

Main category: cond-mat.mtrl-sci

TL;DR: 溶剂影响DBTTF和HATCN共晶的光电性质，但以意想不到的方式影响电荷转移机制。


<details>
  <summary>Details</summary>
Motivation: 研究残留溶剂分子对DBTTF和HATCN共晶光电性质的影响。

Method: 制备了六种新的DBTTF和HATCN共晶（溶剂蒸发法得到1:1摩尔比，水平气相沉积法得到无溶剂3:2共晶），并结合光谱学和密度泛函理论（DFT）计算进行分析。

Result: 所有共晶均表现出0.11 e的电荷转移。溶剂化共晶中，溶剂分子作为主要的电子受体参与电荷转移，改变了预期的DBTTF:HATCN行为，并揭示了HATCN除了氰基之外的多面电荷转移机制。

Conclusion: 溶液法制备的共晶能保持其固有的DBTTF:HATCN特性，但溶剂可以作为有源电子元件，为材料设计开辟新途径。

Abstract: Donor-acceptor (D:A) cocrystals offer a promising platform for
next-generation optoelectronic applications, but the impact of residual solvent
molecules on their properties remains an open question. We investigate six
novel D:A cocrystals of dibenzotetrathiafulvalene (DBTTF) and
1,4,5,8,9,11-hexaazatriphenylenehexacarbo-nitrile (HATCN), prepared via solvent
evaporation, yielding 1:1 molar ratios, and horizontal vapor deposition,
resulting in solvent-free 3:2 cocrystals. Combining spectroscopy and
density-functional theory (DFT) calculations, we find that, while the
electronic and optical properties of the cocrystals are largely unaffected by
solvent inclusion, the charge transfer mechanism is surprisingly complex. Raman
spectroscopy reveals a consistent charge transfer of 0.11 $e$ across all
considered structures, corroborated by DFT calculations on solvent-free
systems. Partial charge analysis reveals that in solvated cocrystals, solvent
molecules actively participate in the charge transfer process as primary
electron acceptors. This involvement can perturb the expected D:A behavior,
revealing a faceted charge-transfer mechanism in HATCN even beyond the
established involvement of its cyano group. Overall, our study demonstrates
that while solution-based methods preserve the intrinsic D:A characteristics,
solvents can be leveraged as active electronic components, opening new avenues
for material design.

</details>


### [128] [Resolving the Bulk-Boundary Correspondence Paradox on Low-Symmetry Surfaces of Weyl Semimetals](https://arxiv.org/abs/2509.10106)
*Cong Li,Zhilong Yang,Hongxiong Liu,Magnus H. Berntsen,Francesco Scali,Dibya Phuyal,Jianfeng Zhang,Timur K. Kim,Jacek Osiecki,Balasubramanian Thiagarajan,Youguo Shi,Tao Xiang,Quansheng Wu,Oscar Tjernberg*

Main category: cond-mat.mtrl-sci

TL;DR: 低对称性拓扑半金属表面存在传统面所隐藏的边界现象，但由于实验挑战和缺乏调和体和表面周期性的通用框架，系统性研究仍然稀少。本研究使用角分辨光电子能谱和密度泛函理论研究了外尔半金属 NdAlSi 的 (103) 表面。这是一个低对称性表面，表面周期性与外尔点体周期性不符，似乎违背了体-边界对应原理。通过展示连续的体布里渊区产生重叠，最终与表面布里渊区成比例，从而解决了体-边界对应原理的悖论，并为任意面建立了通用判据。该框架和实验结果还表明，重叠的费米弧可以杂化成闭合的费米弧环，丰富了边界拓扑，并实现了低对称性面所特有的非常规输运、干涉和集体现象。


<details>
  <summary>Details</summary>
Motivation: 低对称性表面具有隐藏的边界现象，但缺乏通用框架来研究它们，特别是在解决体-表面周期性差异方面。

Method: 使用角分辨光电子能谱和密度泛函理论研究 NdAlSi 的 (103) 表面。

Result: 解决了低对称性表面（如 (103) 表面）的体-边界对应悖论，建立了通用判据，并发现费米弧可以杂化成闭合的费米弧环，可能带来新的物理现象。

Conclusion: 低对称性表面为研究新奇的边界现象提供了平台，通过建立的框架可以理解和利用这些现象，并可能带来新的物态和应用。

Abstract: Low-symmetry surfaces of topological semimetals offer access to boundary
phenomena hidden on conventional facets, yet systematic studies remain scarce
due to experimental challenges and the lack of a general framework for
reconciling bulk and surface periodicities. Here, we investigate the (103)
surface of the Weyl semimetal NdAlSi using angle resolved photoemission
spectroscopy and density functional theory. The (103) surface is an example of
a low symmetry surface that presents an apparent paradox to the bulk-boundary
correspondence. The surface periodicity to which the topological surface states
are expected to adhere does not correspond to the bulk periodicity of the Weyl
points. By showing that successive bulk Brillouin zones generate replicas that
accumulate into a superlattice commensurate with the surface Brillouin zone, we
demonstrate how the apparent bulk boundary correspondence paradox is resolved
and establish a universal criterion for arbitrary facets. The framework and
experimental results further suggests that overlapping Fermi arcs can hybridize
into closed Fermi arc loops, enriching boundary topology and enabling
unconventional transport, interference, and collective phenomena unique to
lowsymmetry facets.

</details>


### [129] [Novel 3D Pentagraphene Allotropes: Stability, Electronic, Mechanical, and Optical Properties](https://arxiv.org/abs/2509.10191)
*I. M. Félix,B. Ipaves,R. B. de Oliveira,L. A. Ribeiro Junior,L. S. Rocha,M. L. Pereira Junior,D. S. Galvão,R. M. Tromer*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了三种新型三维五石墨烯（3D-PG）同素异形体（3D-PG-α、-β、-γ），并通过应变和压缩对其进行了工程化。


<details>
  <summary>Details</summary>
Motivation: 研究新型三维碳同素异形体在稳定性和性能方面的潜力。

Method: 通过双轴应变和受控压缩对二维五石墨烯（PG）层进行工程化，并进行声子色散和从头分子动力学模拟（AIMD）以评估稳定性和电子、机械、光学性质。

Result: 所有三种3D-PG同素异形体都被证明在室温和高温下是热力学稳定的，其中3D-PG-α最稳定。它们都表现出半导体行为，带隙在0.91到2.67 eV之间。机械性能显示出显著的各向异性，沿平面（xy平面）方向的刚度更高。光学性质显示在较宽范围内有强吸收，并且在可见光区域有活性，在紫外线阻挡设备中有潜在应用。

Conclusion: 三种新型3D-PG同素异形体是稳定且具有吸引力的材料，在电子、光学和机械应用方面具有巨大潜力。

Abstract: Carbon-based materials have attracted great attention due to their
exceptional structural diversity and wide-ranging applications. Recently, a new
two-dimensional carbon allotrope, named pentagraphene (PG), was proposed. In
this study, we proposed three novel three-dimensional (3D) PG allotropes, named
3D-PG-$\alpha$, -$\beta$, and -$\gamma$, engineered through biaxial strain and
controlled compression of 2D PG layers. Comprehensive stability analyses,
including phonon dispersion and ab initio molecular dynamics simulations
(AIMD), confirm their thermodynamic stability under room and high-temperature
conditions. 3D-PG-$\alpha$ is the most stable, exhibiting a cohesive energy 0.5
eV/atom lower than the least stable structure, 3D-PG-$\gamma$. Electronic
property characterization reveals semiconducting behavior for all structures,
with indirect electronic band gaps ranging from 0.91 to 2.67 eV. The analyses
of the mechanical properties showed significant anisotropy, with higher
stiffness along the in-plane ($xy$-plane) direction. Optical properties
highlight strong absorption along a wide range and a pronounced anisotropic
response. Additionally, the absorption spectra exhibit activity in the visible
region, and the refractive index and reflectivity indicate potential use in
ultraviolet-blocking devices.

</details>


### [130] [Spectroscopy and transport of nonpolarons in silicon and germanium: the influence of doping and temperature](https://arxiv.org/abs/2509.10192)
*Raveena Gupta,Joao Abreu,Matthieu J. Verstraete*

Main category: cond-mat.mtrl-sci

TL;DR: 硅和锗的电子-声子相互作用研究表明，它们具有不同的非极性谱和输运特征。


<details>
  <summary>Details</summary>
Motivation: 研究硅和锗中电子-声子相互作用的独特之处，并提供一个预测非极性半导体迁移率的统一框架。

Method: 利用包含推迟累积展开的多体微扰理论，计算准粒子能量、寿命和声子卫星，超越了Dyson-Migdal近似。

Result: 硅和锗在低温下表现出不同的谱学特征，声子诱导的卫星在高温下会变宽并合并。掺杂会影响峰的宽度和卫星-准粒子的分离度。计算出的迁移率与实验测量结果一致，并揭示了锗的迁移率普遍高于硅。

Conclusion: 带边不对称和声子能量学与可测量的输运差异相关联，为预测非极性半导体的迁移率提供了一个统一的框架。

Abstract: We perform a first-principles investigation of electron-phonon interactions
in silicon and germanium, uncovering distinct non-polaronic spectral and
transport fingerprints in these archetypal covalent semiconductors. Using
many-body perturbation theory with the retarded cumulant expansion, we compute
quasiparticle energies, lifetimes, and phonon satellites beyond the
Dyson-Migdal approximation. Short-range crystal fields dominate coupling in
both materials, yet their low-temperature spectral fingerprints differ: Si
exhibits well-resolved satellites at both band edges, whereas Ge displays
strong sidebands mainly at the valence band maximum (VBM) and much weaker
features at the conduction band minimum (CBM). Phonon-induced satellites in
both materials broaden and merge with the quasiparticle peak at elevated
temperatures. Doping broadens peaks and compresses satellite-quasiparticle
separation, with n-type carriers affecting the CBM and p-type the VBM. Mobility
calculations, combining cumulant-derived phonon scattering with experimentally
motivated ionized-impurity scattering models, reproduce measured trends and
reveal Ge's consistently higher mobilities than Si, stemming from lighter
effective masses and weaker coupling. These results link band-edge asymmetries
and phonon energetics to measurable transport differences, providing a unified
framework for predicting mobility in nonpolar semiconductors.

</details>


### [131] [Magnetism Induced by Azanide and Ammonia Adsorption in Defective Molybdenum Disulfide and Diselenide: A First-Principles Study](https://arxiv.org/abs/2509.10207)
*Guilherme S. L. Fabris,Bruno Ipaves,Raphael B. Oliveira,Humberto R. Gutierrez,Marcelo L. Pereira Junior,Douglas S. Galvão*

Main category: cond-mat.mtrl-sci

TL;DR: 分子吸附和缺陷工程可调控二维材料的磁性。


<details>
  <summary>Details</summary>
Motivation: 二维过渡金属硫属化物（TMDs）因其可调的结构、电子和自旋相关性质而备受关注，特别是在点缺陷和分子吸附物存在的情况下。

Method: 使用自旋极化密度泛函理论（DFT）研究了NH2和NH3分子吸附在有缺陷的MoS2和MoSe2单分子层上引起的磁性。

Result: 原始的硫属化物空位不产生磁性，但NH2和NH3的吸附会在Mo基二卤代物中产生局域磁矩。在MoSe2上，NH3解离产生的NH2和H片段会产生2.0 μB的净磁矩。W基二卤代物没有磁响应。

Conclusion: 分子吸附与缺陷工程相结合是调控二维材料磁性的一种实用方法，有望应用于自旋电子学和传感领域。

Abstract: Two-dimensional (2D) transition metal dichalcogenides (TMDs) have attracted
considerable attention due to their tunable structural, electronic, and
spin-related properties, particularly in the presence of point defects and
molecular adsorbates. Motivated by these aspects, we have investigated using
first-principles methods the magnetic properties induced by azanide (NH$_2$)
and ammonia (NH$_3$) adsorption on defective monolayers of Molybdenum Disulfide
(MoS$_2$) and Diselenide(MoSe$_2$). Spin-polarized density functional theory
(DFT) was employed to investigate the impact of mono- and di-vacancies on the
local spin environment and the role of molecular adsorption in modifying
magnetic behavior. The results show that pristine chalcogen vacancies do not
generate magnetism, whereas the adsorption of NH$_2$ and NH$_3$ creates
localized magnetic moments in Mo-based dichalcogenides. A notable case occurs
for MoSe$_2$, where NH$_3$ dissociation into NH$_2$ and H fragments on the same
side of the surface produces a net magnetic moment of 2.0 $\mu_B$. Tests
performed on W-based dichalcogenides under equivalent conditions showed no
magnetic response, and are reported here only for comparison. These findings
demonstrate that molecular adsorption combined with defect engineering can be a
practical approach to tune magnetism in 2D materials, with potential relevance
for spintronic and sensing applications.

</details>


### [132] [Competitive Adsorption of Toluene and Water in MFI-type Zeolites](https://arxiv.org/abs/2509.10219)
*Gavriel Arbiv,Sambhu Radhakrishnan,Alysson F. Morais,C. Vinod Chandran,Dries Vandenabeele,Dirk Dom,Karel Duerinckx,Christine E. A. Kirschhock,Eric Breynaert*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了MFI型沸石（ZSM-5）中甲苯和水的竞争吸附行为，发现水会取代沸石内部和孔口吸附的甲苯，即使在疏水性沸石中也是如此，凸显了竞争吸附对沸石催化效率的影响。


<details>
  <summary>Details</summary>
Motivation: 为了理解沸石催化活性、选择性和反应机理，需要解决竞争吸附这一主要挑战。

Method: 采用固态核磁共振（NMR）技术，结合定量1H NMR、1D和2D NMR以及样品工程（如孔道阻塞），研究了不同硅铝比的ZSM-5沸石中甲苯的吸附行为，并引入水观察其对甲苯吸附的影响。

Result: 确定了沸石内部、孔口和外部表面吸附的三种不同甲苯群体。结果表明，水的引入会取代沸石内部和孔口吸附的甲苯，并且这种取代在疏水性沸石中也存在，水优先吸附在布朗斯台酸位和硅醇物种上。

Conclusion: 竞争吸附（例如来自溶剂、产物或杂质）对沸石介导的转化效率和选择性有关键影响。

Abstract: Competitive adsorption is a major challenge in understanding catalytic
activity, selectivity and reaction mechanisms in confined environments such as
zeolites. This study investigated competitive adsorption in MFI-type zeolites
(ZSM-5) using solid-state NMR, focusing on the interplay between toluene and
water. Quantitative 1H NMR spectroscopy identified three distinct populations
of adsorbed toluene evolving with increasing toluene loading. The adsorption
behavior was consistent across a series of samples with Si/Al ratio ranging
from 11.5 to 140. Combining 1D and 2D NMR techniques with sample engineering
(e.g. pore-blocking) enabled the assignment of the populations to toluene
within the zeolite channels, at the pore mouths, and adsorbed on the external
crystal surface. Crucially, introducing water to toluene-loaded zeolites caused
a partial displacement of toluene from the internal channels, but significant
removal from the pore mouths. This dis-placement occurred even in the highly
hydrophobic zeolite (Si/Al = 140), where water still preferentially adsorbed to
Br{\o}nsted acid sites and silanol species. The results highlight the critical
impact that competitive adsorption from solvents, products, or impurities can
have on the efficiency and selectivity of zeolite-mediated transformations.

</details>


### [133] [Interplay of vibrational, electronic, and magnetic states in CrSBr](https://arxiv.org/abs/2509.10267)
*Daria I. Markina,Priyanka Mondal,Lukas Krelle,Sai Shradha,Mikhail M. Glazov,Regine von Klitzing,Kseniia Mosina,Zdenek Sofer,Bernhard Urbaszek*

Main category: cond-mat.mtrl-sci

TL;DR: CrSBr是一种范德华反铁磁体，具有独特的准粒子相互作用，源于振动、电子和磁自由度的耦合。


<details>
  <summary>Details</summary>
Motivation: 研究CrSBr中振动、电子和磁自由度耦合所产生的准粒子相互作用。

Method: 使用偏振分辨拉曼光谱（在不同激发能量和较宽温度范围内）、光学吸收光谱和光致发光激发（PLE）光谱研究了CrSBr的相互作用。

Result: 在1.96 eV激发下，在Néel温度附近观察到A_g^1、A_g^2和A_g^3拉曼模式的显著变化，伴随着激子跃迁振荡强度的改变和PLE中的清晰共振。拉曼模式的拉曼张量元素和偏振各向异性的不同温度演化表明它们与不同的激子和电子态耦合。激子态振荡强度在Néel温度以上被抑制，这可能与磁相变有关，从而将激子态和拉曼模式与特定的自旋排列联系起来。

Conclusion: CrSBr提供了一个研究低维磁体中准粒子相互作用的平台，并为量子传感和量子通信等应用提供了见解。

Abstract: The van der Waals antiferromagnet CrSBr exhibits coupling of vibrational,
electronic, and magnetic degrees of freedom, giving rise to distinctive
quasi-particle interactions. We investigate these interactions across a wide
temperature range using polarization-resolved Raman spectroscopy at various
excitation energies, complemented by optical absorption and photoluminescence
excitation (PLE) spectroscopy. Under 1.96 eV excitation, we observe pronounced
changes in the A$_g^1$, A$_g^2$, and A$_g^3$ Raman modes near the N\'eel
temperature, coinciding with modifications in the oscillator strength of
excitonic transitions and clear resonances in PLE. The distinct temperature
evolution of Raman tensor elements and polarization anisotropy for Raman modes
indicates that they couple to different excitonic and electronic states. The
suppression of the excitonic state's oscillation strength above the N\'eel
temperature could be related to the magnetic phase transition, thereby
connecting these excitonic states and Raman modes to a specific spin alignment.
These observations make CrSBr a versatile platform for probing quasi-particle
interactions in low-dimensional magnets and provide insights for applications
in quantum sensing and quantum communication.

</details>


### [134] [Topological superconductivity in a dimerized Kitaev chain revealed by nonlocal transport](https://arxiv.org/abs/2509.10412)
*Rafael Pineda Medina,Pablo Burset,William J. Herrera*

Main category: cond-mat.mtrl-sci

TL;DR: 文章研究了由半导体量子点耦合的超导链组成的Kitaev链，分析了双 Kitaev链的马约拉纳束缚态的产生和控制。


<details>
  <summary>Details</summary>
Motivation: 为了实现和控制拓扑量子计算的马约拉纳束缚态，研究了由半导体量子点耦合的超导链组成的Kitaev链。

Method: 研究了一个双 Kitaev链（等价于超导的Su-Schrieffer-Heeger模型），并分析了所得的两个耦合链的行为。

Result: 文章表明，来自每个链的马约拉纳边缘模式之间的干涉会导致非局域电导中可观测的特征。此外，通过分析模型，识别出控制边缘态耦合的系统长度的奇偶效应。

Conclusion: 研究结果为中观拓扑超导体中的马约拉纳杂化提供了可实现的可实验探测方法。

Abstract: Artificial Kitaev chains engineered from semiconducting quantum dots coupled
by superconducting segments offer a promising route to realize and control
Majorana bound states for topological quantum computation. We study a dimerized
Kitaev chain--equivalent to a superconducting Su-Schrieffer-Heeger model--and
analyze the behavior of the resulting two coupled chains. We show that
interference between Majorana edge modes from each chain gives rise to
observable signatures in nonlocal conductance. Additionally, we identify a
parity effect in the system length that governs the coupling of edge states,
supported by an analytical model. Our results provide experimentally accessible
probes for Majorana hybridization in mesoscopic topological superconductors.

</details>


### [135] [OpenCSP: A Deep Learning Framework for Crystal Structure Prediction from Ambient to High Pressure](https://arxiv.org/abs/2509.10293)
*Yinan Wang,Xiaoyang Wang,Zhenyu Wang,Jing Wu,Jian Lv,Han Wang*

Main category: cond-mat.mtrl-sci

TL;DR: OpenCSP是一个机器学习框架，用于在高压条件下进行晶体结构预测。它包含一个开源的数据集和一系列公开的原子模型，这些模型经过联合优化，能够准确预测能量、力和应力。与现有的大型模型相比，OpenCSP在数据量较少的情况下，在高压下的性能相当甚至更优。


<details>
  <summary>Details</summary>
Motivation: 现有的大部分机器学习模型在处理高压（数十至数百吉帕斯卡）下的应力预测时表现不佳，并且对高压下稳定的化学计量和致密配位结构覆盖不足。因此，需要一个能够在从环境压力到高压条件都能准确预测的机器学习框架。

Method: OpenCSP框架包含一个开源的、经过压力解析的数据集，以及一系列公开的原子模型。该数据集通过随机高压采样构建，并利用不确定性引导的并发学习策略进行迭代优化，以丰富数据稀疏的压缩区域并减少冗余的DFT计算。模型则经过联合优化，以提高能量、力和应力预测的准确性。

Result: OpenCSP在压力下的焓排序和稳定性预测方面，即使训练语料库比领先的大型模型小一到两个数量级，也能达到相当或更优的性能。在跨越宽压力范围的基准CSP任务中，OpenCSP的模型在MACE-MPA-0、MatterSim v1 5M和GRACE-2L-OAM之上，尤其在高压下表现提升最为显著。

Conclusion: 通过有针对性的、考虑压力的数据采集策略，并结合可扩展的架构，可以实现数据高效、高保真的高压晶体结构预测，从而为在各种压力条件下进行自主材料发现铺平道路。

Abstract: High-pressure crystal structure prediction (CSP) underpins advances in
condensed matter physics, planetary science, and materials discovery. Yet, most
large atomistic models are trained on near-ambient, equilibrium data, leading
to degraded stress accuracy at tens to hundreds of gigapascals and sparse
coverage of pressure-stabilized stoichiometries and dense coordination motifs.
Here, we introduce OpenCSP, a machine learning framework for CSP tasks spanning
ambient to high-pressure conditions. This framework comprises an open-source
pressure-resolved dataset alongside a suite of publicly available atomistic
models that are jointly optimized for accuracy in energy, force, and stress
predictions. The dataset is constructed via randomized high-pressure sampling
and iteratively refined through an uncertainty-guided concurrent learning
strategy, which enriches underrepresented compression regimes while suppressing
redundant DFT labeling. Despite employing a training corpus one to two orders
of magnitude smaller than those of leading large models, OpenCSP achieves
comparable or superior performance in high-pressure enthalpy ranking and
stability prediction. Across benchmark CSP tasks spanning a wide pressure
window, our models match or surpass MACE-MPA-0, MatterSim v1 5M, and
GRACE-2L-OAM, with the largest gains observed at elevated pressures. These
results demonstrate that targeted, pressure-aware data acquisition coupled with
scalable architectures enables data-efficient, high-fidelity CSP, paving the
way for autonomous materials discovery under ambient and extreme conditions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [136] [MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos](https://arxiv.org/abs/2509.09769)
*Rutav Shah,Shuijing Liu,Qi Wang,Zhenyu Jiang,Sateesh Kumar,Mingyo Seo,Roberto Martín-Martín,Yuke Zhu*

Main category: cs.RO

TL;DR: MimicDroid


<details>
  <summary>Details</summary>
Motivation: Current in-context learning (ICL) methods for humanoid robots rely on labor-intensive teleoperated data, limiting scalability. This paper proposes using human play videos as a scalable and diverse training data source to enable ICL for humanoid robots.

Method: MimicDroid extracts trajectory pairs with similar manipulation behaviors from human play videos and trains a policy to predict actions. It retargets human wrist poses to the humanoid and uses random patch masking during training to bridge the embodiment gap and improve robustness.

Result: MimicDroid acquired ICL capabilities for adapting to novel objects and environments. It outperformed state-of-the-art methods and achieved nearly twofold higher success rates in the real world on a new simulation benchmark.

Conclusion: MimicDroid enables humanoid robots to perform ICL using human play videos as the sole training data, offering a scalable and effective solution for learning new manipulation tasks.

Abstract: We aim to enable humanoid robots to efficiently solve new manipulation tasks
from a few video examples. In-context learning (ICL) is a promising framework
for achieving this goal due to its test-time data efficiency and rapid
adaptability. However, current ICL methods rely on labor-intensive teleoperated
data for training, which restricts scalability. We propose using human play
videos -- continuous, unlabeled videos of people interacting freely with their
environment -- as a scalable and diverse training data source. We introduce
MimicDroid, which enables humanoids to perform ICL using human play videos as
the only training data. MimicDroid extracts trajectory pairs with similar
manipulation behaviors and trains the policy to predict the actions of one
trajectory conditioned on the other. Through this process, the model acquired
ICL capabilities for adapting to novel objects and environments at test time.
To bridge the embodiment gap, MimicDroid first retargets human wrist poses
estimated from RGB videos to the humanoid, leveraging kinematic similarity. It
also applies random patch masking during training to reduce overfitting to
human-specific cues and improve robustness to visual differences. To evaluate
few-shot learning for humanoids, we introduce an open-source simulation
benchmark with increasing levels of generalization difficulty. MimicDroid
outperformed state-of-the-art methods and achieved nearly twofold higher
success rates in the real world. Additional materials can be found on:
ut-austin-rpl.github.io/MimicDroid

</details>


### [137] [MIMo grows! Simulating body and sensory development in a multimodal infant model](https://arxiv.org/abs/2509.09805)
*Francisco M. López,Miles Lenz,Marco G. Fedozzi,Arthur Aubret,Jochen Triesch*

Main category: cs.RO

TL;DR: MIMo v2是一个具有可扩展身体、可变视觉和传感器运动延迟的婴儿模型，能够模拟从出生到24个月的婴儿发展。


<details>
  <summary>Details</summary>
Motivation: 现有的发育机器人和模拟平台通常只针对特定年龄段，无法捕捉婴儿不断变化的身体和运动能力。MIMo v2旨在解决这一问题，提供一个能够模拟婴儿从出生到24个月的身体成长、运动能力发展以及视觉和传感器运动延迟的模型。

Method: MIMo v2 通过以下方式实现：1. 可变尺寸和驱动力：身体尺寸和驱动力会随着模拟年龄的增长而变化。2. 视觉模拟：具有聚焦视觉和模拟发育中的视敏度。3. 传感器运动延迟：模拟信号传输到和离开婴儿大脑的有限速度。4. 改进功能：包括逆运动学模块、随机环境生成器以及与第三方模拟和学习库的兼容性更新。

Result: MIMo v2 提高了在模拟婴儿传感器运动发展方面的真实感，能够更好地捕捉婴儿发育过程中的能力和限制。

Conclusion: MIMo v2 是一个多模态婴儿模型，通过其可扩展的身体、发育中的视觉和传感器运动延迟，显著提高了在模拟婴儿传感器运动发展方面的真实感。

Abstract: Infancy is characterized by rapid body growth and an explosive change of
sensory and motor abilities. However, developmental robots and simulation
platforms are typically designed in the image of a specific age, which limits
their ability to capture the changing abilities and constraints of developing
infants. To address this issue, we present MIMo v2, a new version of the
multimodal infant model. It includes a growing body with increasing actuation
strength covering the age range from birth to 24 months. It also features
foveated vision with developing visual acuity as well as sensorimotor delays
modeling finite signal transmission speeds to and from an infant's brain.
Further enhancements of this MIMo version include an inverse kinematics module,
a random environment generator and updated compatiblity with third-party
simulation and learning libraries. Overall, this new MIMo version permits
increased realism when modeling various aspects of sensorimotor development.
The code is available on the official repository
(https://github.com/trieschlab/MIMo).

</details>


### [138] [Using the Pepper Robot to Support Sign Language Communication](https://arxiv.org/abs/2509.09889)
*Giulia Botta,Marco Botta,Cristina Gena,Alessandro Mazzei,Massimo Donini,Alberto Lillo*

Main category: cs.RO

TL;DR: 本研究旨在探索商用社交机器人Pepper在意大利手语（LIS）方面的能力，并评估其在公共和辅助场景下的包容性。


<details>
  <summary>Details</summary>
Motivation: 目前对社交机器人在公共和辅助环境中的应用研究较多，但对服务于聋哑人群的机器人研究较少。意大利手语（LIS）是一种完整的自然语言，具有复杂的触觉和非触觉成分。让机器人能够使用LIS进行交流，可以促进人机交互的包容性，尤其是在医院、机场或教育等公共环境中。

Method: 研究人员与一位聋哑学生和他的翻译（LIS专家）合作，使用手动动画技术或基于MATLAB的逆运动学求解器，在Pepper机器人上共同设计并实现了52个LIS手语。随后，进行了一项探索性用户研究，邀请了12名精通LIS的参与者（包括聋哑人和听力正常者）完成了一项包含15个单项选择视频手语识别任务和2个关于短语手语的开放式问题的问卷调查。

Result: 结果表明，大多数孤立的手语被正确识别，但由于Pepper有限的 artikülasyon 和时间限制，完整的句子识别率明显较低。

Conclusion: 研究结果证明，即使是像Pepper这样的商用社交机器人，也能清晰地表达一部分LIS手语，为更具包容性的人机交互设计提供了机会。未来的研究应致力于多模式增强（例如，屏幕支持或表情头像）并让聋哑用户参与到参与式设计中，以改进机器人的表达能力和可用性。

Abstract: Social robots are increasingly experimented in public and assistive settings,
but their accessibility for Deaf users remains quite underexplored. Italian
Sign Language (LIS) is a fully-fledged natural language that relies on complex
manual and non-manual components. Enabling robots to communicate using LIS
could foster more inclusive human robot interaction, especially in social
environments such as hospitals, airports, or educational settings. This study
investigates whether a commercial social robot, Pepper, can produce
intelligible LIS signs and short signed LIS sentences. With the help of a Deaf
student and his interpreter, an expert in LIS, we co-designed and implemented
52 LIS signs on Pepper using either manual animation techniques or a MATLAB
based inverse kinematics solver. We conducted a exploratory user study
involving 12 participants proficient in LIS, both Deaf and hearing.
Participants completed a questionnaire featuring 15 single-choice video-based
sign recognition tasks and 2 open-ended questions on short signed sentences.
Results shows that the majority of isolated signs were recognized correctly,
although full sentence recognition was significantly lower due to Pepper's
limited articulation and temporal constraints. Our findings demonstrate that
even commercially available social robots like Pepper can perform a subset of
LIS signs intelligibly, offering some opportunities for a more inclusive
interaction design. Future developments should address multi-modal enhancements
(e.g., screen-based support or expressive avatars) and involve Deaf users in
participatory design to refine robot expressivity and usability.

</details>


### [139] [Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision](https://arxiv.org/abs/2509.09893)
*Hanbit Oh,Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Yukiyasu Domae*

Main category: cs.RO

TL;DR: SART框架通过单次人类演示和安全自主数据增强，提高了机器人模仿学习的数据效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 标准的模仿学习方法需要大量数据，而自主探索缺乏安全保障且易发生碰撞，增加了人类负担。

Method: SART框架包含两个阶段：1. 人类仅教授一次，并标注关键路径点的精度边界（球体）；2. 机器人自主生成在这些边界内无碰撞的轨迹，并重新连接到原始演示。

Result: 与仅使用人类收集的演示进行训练的策略相比，SART在模拟和现实世界的操纵任务中取得了更高的成功率。

Conclusion: SART框架通过最小化人类精力并确保安全，提高了数据收集效率，并在机器人模仿学习任务中表现出色。

Abstract: Imitation learning is a promising paradigm for training robot agents;
however, standard approaches typically require substantial data acquisition --
via numerous demonstrations or random exploration -- to ensure reliable
performance. Although exploration reduces human effort, it lacks safety
guarantees and often results in frequent collisions -- particularly in
clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual
environmental resets and imposing additional human burden. This study proposes
Self-Augmented Robot Trajectory (SART), a framework that enables policy
learning from a single human demonstration, while safely expanding the dataset
through autonomous augmentation. SART consists of two stages: (1) human
teaching only once, where a single demonstration is provided and precision
boundaries -- represented as spheres around key waypoints -- are annotated,
followed by one environment reset; (2) robot self-augmentation, where the robot
generates diverse, collision-free trajectories within these boundaries and
reconnects to the original demonstration. This design improves the data
collection efficiency by minimizing human effort while ensuring safety.
Extensive evaluations in simulation and real-world manipulation tasks show that
SART achieves substantially higher success rates than policies trained solely
on human-collected demonstrations. Video results available at
https://sites.google.com/view/sart-il .

</details>


### [140] [Detection of Anomalous Behavior in Robot Systems Based on Machine Learning](https://arxiv.org/abs/2509.09953)
*Mahfuzul I. Nissan,Sharmin Aktar*

Main category: cs.RO

TL;DR: 通过机器学习方法检测机器人系统日志中的异常，以提高安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 确保机器人系统的安全可靠运行至关重要，以防止潜在的灾难并保障人类福祉。

Method: 收集来自不同场景（包括在CoppeliaSim中模拟的四旋翼飞行器和Pioneer机器人）的日志，并比较了逻辑回归（LR）、支持向量机（SVM）和自动编码器（Autoencoder）等机器学习模型的性能。

Result: 在四旋翼飞行器场景（Context 1）中，LR模型表现出优越的性能；而在Pioneer机器人场景（Context 2）中，自动编码器模型最为有效。

Conclusion: 最优模型的选择取决于具体应用场景，这可能是由于不同机器人平台上的异常复杂性不同。该研究强调了比较方法的重要性，并展示了自动编码器在检测机器人系统中复杂异常方面的独特优势。

Abstract: Ensuring the safe and reliable operation of robotic systems is paramount to
prevent potential disasters and safeguard human well-being. Despite rigorous
design and engineering practices, these systems can still experience
malfunctions, leading to safety risks. In this study, we present a machine
learning-based approach for detecting anomalies in system logs to enhance the
safety and reliability of robotic systems. We collected logs from two distinct
scenarios using CoppeliaSim and comparatively evaluated several machine
learning models, including Logistic Regression (LR), Support Vector Machine
(SVM), and an Autoencoder. Our system was evaluated in a quadcopter context
(Context 1) and a Pioneer robot context (Context 2). Results showed that while
LR demonstrated superior performance in Context 1, the Autoencoder model proved
to be the most effective in Context 2. This highlights that the optimal model
choice is context-dependent, likely due to the varying complexity of anomalies
across different robotic platforms. This research underscores the value of a
comparative approach and demonstrates the particular strengths of autoencoders
for detecting complex anomalies in robotic systems.

</details>


### [141] [DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training](https://arxiv.org/abs/2509.10426)
*Jianxin Shi,Zengqi Peng,Xiaolong Chen,Tianyu Wo,Jun Ma*

Main category: cs.RO

TL;DR: DECAMP是一个用于自动驾驶多智能体运动预测的解耦上下文感知预训练框架，通过解耦行为模式学习和潜在特征重建，并结合上下文感知表示学习和协作空间-运动预训练任务，以提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹预测方法在数据稀疏和多智能体场景下表现不佳，需要提高预测的安全性与效率。

Method: 提出DECAMP框架，解耦行为模式学习与潜在特征重建，引入上下文感知表示学习以及协作空间-运动预训练任务，以实现可解释的动力学和增强的场景表示。

Result: 在Argoverse 2基准测试中取得了优越的性能，证明了其在多智能体运动预测方面的有效性。

Conclusion: DECAMP是首个用于自动驾驶多智能体运动预测的上下文自编码器框架，在多智能体运动预测方面表现出色。

Abstract: Trajectory prediction is a critical component of autonomous driving,
essential for ensuring both safety and efficiency on the road. However,
traditional approaches often struggle with the scarcity of labeled data and
exhibit suboptimal performance in multi-agent prediction scenarios. To address
these challenges, we introduce a disentangled context-aware pre-training
framework for multi-agent motion prediction, named DECAMP. Unlike existing
methods that entangle representation learning with pretext tasks, our framework
decouples behavior pattern learning from latent feature reconstruction,
prioritizing interpretable dynamics and thereby enhancing scene representation
for downstream prediction. Additionally, our framework incorporates
context-aware representation learning alongside collaborative spatial-motion
pretext tasks, which enables joint optimization of structural and intentional
reasoning while capturing the underlying dynamic intentions. Our experiments on
the Argoverse 2 benchmark showcase the superior performance of our method, and
the results attained underscore its effectiveness in multi-agent motion
forecasting. To the best of our knowledge, this is the first context
autoencoder framework for multi-agent motion forecasting in autonomous driving.
The code and models will be made publicly available.

</details>


### [142] [Gaussian path model library for intuitive robot motion programming by demonstration](https://arxiv.org/abs/2509.10007)
*Samuli Soutukorva,Markku Suomalainen,Martin Kollingbaum,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 本研究提出了一种从表示路径形状的教学数据生成高斯路径模型的方法，并介绍了使用这些路径模型对人类演示路径进行分类的技术。通过生成包含各种形状的高斯路径模型库，可以实现直观的机器人运动编程。此外，还提出了一种通过几何分析修改现有高斯路径模型的方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过生成高斯路径模型来简化和改进机器人运动编程，并利用人类演示数据实现更直观的交互。

Method: 本研究提出了一种从教学数据生成高斯路径模型的方法，并开发了用于分类人类演示路径的模型。此外，还提供了一种通过几何分析修改现有高斯路径模型的方法。

Result: 研究成功生成了高斯路径模型，并展示了如何利用这些模型对人类演示路径进行分类，以及如何通过演示修改现有模型。

Conclusion: 本研究提出的高斯路径模型系统能够有效地从教学数据中学习路径形状，并通过人类演示实现直观的机器人运动编程和模型修改。

Abstract: This paper presents a system for generating Gaussian path models from
teaching data representing the path shape. In addition, methods for using these
path models to classify human demonstrations of paths are introduced. By
generating a library of multiple Gaussian path models of various shapes, human
demonstrations can be used for intuitive robot motion programming. A method for
modifying existing Gaussian path models by demonstration through geometric
analysis is also presented.

</details>


### [143] [Towards simulation-based optimization of compliant fingers for high-speed connector assembly](https://arxiv.org/abs/2509.10012)
*Richard Matthias Hartisch,Alexander Rother,Jörg Krüger,Kevin Haninger*

Main category: cs.RO

TL;DR: 通过基于仿真的设计工具优化软体机械手的参数，以提高在接触式操作中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前的软体机械手设计依赖硬件迭代或简化模型，难以满足复杂操作任务的需求。

Method: 提出一种基于动态仿真的设计工具，用于优化软体机械手的几何和刚度参数，以实现任务级目标（如成功率）。将此方法应用于优化结构化柔性手指的设计参数，以减少在插入任务中的失败案例。

Result: 优化后的柔性手指设计参数能将可容忍的误差范围提高2.29倍，补偿高达8.6毫米的工件变化。然而，优化结果具有任务特异性，表明需要考虑应用特定几何和动力学的工具。

Conclusion: 基于仿真的设计工具能够有效优化软体机械手的参数，提高其在接触式操作中的鲁棒性，但优化趋势因任务而异，强调了开发能够考虑应用特定几何和动力学的设计工具的必要性。

Abstract: Mechanical compliance is a key design parameter for dynamic contact-rich
manipulation, affecting task success and safety robustness over contact
geometry variation. Design of soft robotic structures, such as compliant
fingers, requires choosing design parameters which affect geometry and
stiffness, and therefore manipulation performance and robustness. Today, these
parameters are chosen through either hardware iteration, which takes
significant development time, or simplified models (e.g. planar), which can't
address complex manipulation task objectives. Improvements in dynamic
simulation, especially with contact and friction modeling, present a potential
design tool for mechanical compliance. We propose a simulation-based design
tool for compliant mechanisms which allows design with respect to task-level
objectives, such as success rate. This is applied to optimize design parameters
of a structured compliant finger to reduce failure cases inside a tolerance
window in insertion tasks. The improvement in robustness is then validated on a
real robot using tasks from the benchmark NIST task board. The finger stiffness
affects the tolerance window: optimized parameters can increase tolerable
ranges by a factor of 2.29, with workpiece variation up to 8.6 mm being
compensated. However, the trends remain task-specific. In some tasks, the
highest stiffness yields the widest tolerable range, whereas in others the
opposite is observed, motivating need for design tools which can consider
application-specific geometry and dynamics.

</details>


### [144] [Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping](https://arxiv.org/abs/2509.10032)
*Marawan Khalil,Fabian Arzberger,Andreas Nüchter*

Main category: cs.RO

TL;DR: 球形机器人在危险或封闭环境的测绘应用中具有优势，但其运动产生的动态性会影响激光雷达-惯性里程计（LIO）算法的性能，导致全局地图不一致和漂移。


<details>
  <summary>Details</summary>
Motivation: 评估球形测绘系统在危险或封闭环境中的应用潜力，并分析球形运动对LIO算法性能的影响。

Method: 设计并实现了一个轻量级非驱动式和一个驱动式球形机器人系统，均配备Livox Mid-360激光雷达传感器，并在资源受限的硬件上运行LIO算法。通过将LIO生成的3D点云与地面真实地图进行比较来评估测绘精度。

Result: 球形运动引入的高动态性导致了最先进的LIO算法性能下降，生成了全局不一致的地图，并出现了有时无法恢复的漂移。

Conclusion: 球形机器人的运动动态性对LIO算法的性能构成了挑战，影响了测绘的全局一致性，需要进一步研究以克服这些限制。

Abstract: Spherical robots offer unique advantages for mapping applications in
hazardous or confined environments, thanks to their protective shells and
omnidirectional mobility. This work presents two complementary spherical
mapping systems: a lightweight, non-actuated design and an actuated variant
featuring internal pendulum-driven locomotion. Both systems are equipped with a
Livox Mid-360 solid-state LiDAR sensor and run LiDAR-Inertial Odometry (LIO)
algorithms on resource-constrained hardware. We assess the mapping accuracy of
these systems by comparing the resulting 3D point-clouds from the LIO
algorithms to a ground truth map. The results indicate that the performance of
state-of-the-art LIO algorithms deteriorates due to the high dynamic movement
introduced by the spherical locomotion, leading to globally inconsistent maps
and sometimes unrecoverable drift.

</details>


### [145] [TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model](https://arxiv.org/abs/2509.10063)
*Xiyan Huang,Zhe Xu,Chenxi Xiao*

Main category: cs.RO

TL;DR: TwinTac系统结合了物理触觉传感器及其数字孪生模型，通过真实到模拟的方法，解决了机器人触觉技能学习中的数据生成问题，并提高了物体分类任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 机器人强化学习技能获取依赖模拟数据，但缺乏触觉传感器模拟，限制了触觉感知策略的开发。本研究旨在弥合这一差距。

Method: 提出TwinTac系统，结合了高灵敏度、宽测量范围的物理触觉传感器及其数字孪生模型。通过收集有限元方法结果和物理传感器输出的同步跨域数据，利用神经网络进行真实到模拟的映射，构建数字孪生模型。

Result: 实验证明了物理传感器的灵敏度，并验证了数字孪生模型在复制物理传感器输出方面的一致性。通过物体分类任务，表明数字孪生传感器生成的模拟数据能有效增强真实世界数据，提高准确性。

Conclusion: TwinTac系统有潜力弥合跨域学习任务中的数据鸿沟，促进机器人触觉技能的学习和应用。

Abstract: Robot skill acquisition processes driven by reinforcement learning often rely
on simulations to efficiently generate large-scale interaction data. However,
the absence of simulation models for tactile sensors has hindered the use of
tactile sensing in such skill learning processes, limiting the development of
effective policies driven by tactile perception. To bridge this gap, we present
TwinTac, a system that combines the design of a physical tactile sensor with
its digital twin model. Our hardware sensor is designed for high sensitivity
and a wide measurement range, enabling high quality sensing data essential for
object interaction tasks. Building upon the hardware sensor, we develop the
digital twin model using a real-to-sim approach. This involves collecting
synchronized cross-domain data, including finite element method results and the
physical sensor's outputs, and then training neural networks to map simulated
data to real sensor responses. Through experimental evaluation, we
characterized the sensitivity of the physical sensor and demonstrated the
consistency of the digital twin in replicating the physical sensor's output.
Furthermore, by conducting an object classification task, we showed that
simulation data generated by our digital twin sensor can effectively augment
real-world data, leading to improved accuracy. These results highlight
TwinTac's potential to bridge the gap in cross-domain learning tasks.

</details>


### [146] [Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation](https://arxiv.org/abs/2509.10065)
*Hauzi Cao,Jiahao Shen,Zhengzhen Li,Qinquan Ren,Shiyu Zhao*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的运动学跟踪控制框架，用于解决现有方法在时间和性能要求方面的不足，通过预设时间内的末端执行器跟踪和基于二次规划的参考分配，有效解决了空中机械臂的跟踪控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有的空中机械臂运动学跟踪控制方法（如比例-微分反馈或基于跟踪误差的反馈）可能无法在规定的时间内实现跟踪目标。

Method: 提出了一种新颖的控制框架，包括基于用户定义预设轨迹的末端执行器跟踪控制和基于二次规划的参考分配。该方法确保末端执行器在预设时间内到达目标位置，并将跟踪误差保持在反映任务需求的性能包络内。此外，利用二次规划来分配四旋翼基座和Delta臂的参考，同时考虑了空中机械臂的物理约束。

Result: 通过三次实验验证了该方法的有效性，结果表明该算法能够保证在预设时间内到达目标位置。

Conclusion: 实验结果证明了所提出算法的有效性及其在预设时间内到达目标位置的能力。

Abstract: This paper studies the kinematic tracking control problem for aerial
manipulators. Existing kinematic tracking control methods, which typically
employ proportional-derivative feedback or tracking-error-based feedback
strategies, may fail to achieve tracking objectives within specified time
constraints. To address this limitation, we propose a novel control framework
comprising two key components: end-effector tracking control based on a
user-defined preset trajectory and quadratic programming-based reference
allocation. Compared with state-of-the-art approaches, the proposed method has
several attractive features. First, it ensures that the end-effector reaches
the desired position within a preset time while keeping the tracking error
within a performance envelope that reflects task requirements. Second,
quadratic programming is employed to allocate the references of the quadcopter
base and the Delta arm, while considering the physical constraints of the
aerial manipulator, thus preventing solutions that may violate physical
limitations. The proposed approach is validated through three experiments.
Experimental results demonstrate the effectiveness of the proposed algorithm
and its capability to guarantee that the target position is reached within the
preset time.

</details>


### [147] [HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario](https://arxiv.org/abs/2509.10096)
*Saeed Saadatnejad,Reyhaneh Hosseininejad,Jose Barreiros,Katherine M. Tsui,Alexandre Alahi*

Main category: cs.RO

TL;DR: 本研究提出了HHI-Assist数据集和一个基于Transformer的去噪扩散模型，用于预测机器人辅助场景中人与人之间的交互运动。


<details>
  <summary>Details</summary>
Motivation: 由于劳动力短缺和人口老龄化，需要机器人来辅助老年人和残疾人，但目前机器人安全有效地进行物理交互仍然是一个挑战。

Method: 通过收集包含辅助任务中人与人交互的运动捕捉数据，构建了HHI-Assist数据集。在此基础上，提出了一种条件Transformer去噪扩散模型来预测交互个体的姿势。

Result: 该模型能够有效捕捉交互中的耦合动力学，并在未见过的场景中表现出优于基线方法的泛化能力。

Conclusion: 该研究通过提供新的数据集和改进的交互感知运动预测方法，有望显著提升机器人辅助策略的性能。

Abstract: The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home

</details>


### [148] [Efficient Learning-Based Control of a Legged Robot in Lunar Gravity](https://arxiv.org/abs/2509.10128)
*Philip Arm,Oliver Fischer,Joseph Church,Adrian Fuhrer,Hendrik Kolvenbach,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的控制方法，通过引入重力缩放的功率优化奖励函数，为行星探测腿式机器人开发了能耗低且可跨重力环境迁移的运动控制器和姿态控制器。


<details>
  <summary>Details</summary>
Motivation: 行星探测腿式机器人在低重力环境下具有优越的移动能力，但其能量和热量受限，需要能够适应多重重力环境且节能的控制方法。

Method: 利用强化学习，结合重力缩放的功率优化奖励函数，开发并验证了机器人的运动控制器和基座姿态控制器，并在从月球重力到超地球重力的多个重力环境下进行了测试。

Result: 该方法在不同重力环境下成功实现了运动和姿态控制的迁移。在地球重力下，功率优化控制器比基线策略节能23%，达到23.4W。在月球重力下，通过弹簧卸载系统辅助实验，功率优化控制器能耗为12.2W，比基线控制器低36%。

Conclusion: 本文提出的方法为开发适用于跨重力环境的腿式机器人节能运动控制器提供了一种可扩展的解决方案。

Abstract: Legged robots are promising candidates for exploring challenging areas on
low-gravity bodies such as the Moon, Mars, or asteroids, thanks to their
advanced mobility on unstructured terrain. However, as planetary robots' power
and thermal budgets are highly restricted, these robots need energy-efficient
control approaches that easily transfer to multiple gravity environments. In
this work, we introduce a reinforcement learning-based control approach for
legged robots with gravity-scaled power-optimized reward functions. We use our
approach to develop and validate a locomotion controller and a base pose
controller in gravity environments from lunar gravity (1.62 m/s2) to a
hypothetical super-Earth (19.62 m/s2). Our approach successfully scales across
these gravity levels for locomotion and base pose control with the
gravity-scaled reward functions. The power-optimized locomotion controller
reached a power consumption for locomotion of 23.4 W in Earth gravity on a
15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.
Additionally, we designed a constant-force spring offload system that allowed
us to conduct real-world experiments on legged locomotion in lunar gravity. In
lunar gravity, the power-optimized control policy reached 12.2 W, 36 % less
than a baseline controller which is not optimized for power efficiency. Our
method provides a scalable approach to developing power-efficient locomotion
controllers for legged robots across multiple gravity levels.

</details>


### [149] [CaR1: A Multi-Modal Baseline for BEV Vehicle Segmentation via Camera-Radar Fusion](https://arxiv.org/abs/2509.10139)
*Santiago Montiel-Marín,Angel Llamazares,Miguel Antunes-García,Fabio Sánchez-García,Luis M. Bergasa*

Main category: cs.RO

TL;DR: 本文提出了一种名为 CaR1 的新型相机-雷达融合架构，用于鸟瞰图（BEV）车辆分割，旨在提供比 LiDAR 更具成本效益的替代方案。


<details>
  <summary>Details</summary>
Motivation: 相机提供丰富的语义信息但深度信息不可靠，而雷达提供稀疏但可靠的位置和运动信息。相机-雷达融合可以提供更鲁棒和经济高效的自动驾驶感知方案。

Method: CaR1 架构基于 BEVFusion，并引入了网格化雷达编码（将点云离散化为结构化的 BEV 特征）和自适应融合机制（动态平衡传感器贡献）。

Result: 在 nuScenes 数据集上的实验表明，CaR1 在 BEV 车辆分割方面达到了 57.6 的 IoU，性能与最先进的方法相当。

Conclusion: CaR1 架构在相机-雷达融合方面取得了具有竞争力的性能，为自动驾驶感知提供了一种有前景的解决方案。

Abstract: Camera-radar fusion offers a robust and cost-effective alternative to
LiDAR-based autonomous driving systems by combining complementary sensing
capabilities: cameras provide rich semantic cues but unreliable depth, while
radar delivers sparse yet reliable position and motion information. We
introduce CaR1, a novel camera-radar fusion architecture for BEV vehicle
segmentation. Built upon BEVFusion, our approach incorporates a grid-wise radar
encoding that discretizes point clouds into structured BEV features and an
adaptive fusion mechanism that dynamically balances sensor contributions.
Experiments on nuScenes demonstrate competitive segmentation performance (57.6
IoU), on par with state-of-the-art methods. Code is publicly available
\href{https://www.github.com/santimontiel/car1}{online}.

</details>


### [150] [DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning](https://arxiv.org/abs/2509.10247)
*Xinhong Zhang,Runqing Wang,Yunfan Ren,Jian Sun,Hao Fang,Jie Chen,Gang Wang*

Main category: cs.RO

TL;DR: DiffAero是一个轻量级、GPU加速、完全可微分的四旋翼控制策略学习模拟框架，通过GPU并行化物理和渲染，提高了模拟吞吐量，并支持多种动力学模型、传感器和飞行任务。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效的四旋翼控制策略学习，需要一个能够利用GPU加速、支持多种模型和任务、并消除CPU-GPU数据传输瓶颈的模拟器。

Method: DiffAero利用GPU并行化物理和渲染，支持环境级和代理级并行，集成了多种动力学模型、传感器（IMU、深度相机、LiDAR）和飞行任务，提供统一的GPU原生训练接口。

Result: 与现有模拟器相比，DiffAero显著提高了模拟吞吐量，并允许在消费级硬件上通过几小时的训练学习到鲁棒的飞行策略。

Conclusion: DiffAero作为一个研究平台，能够通过结合混合学习算法，在短时间内高效地学习四旋翼的鲁棒飞行策略。

Abstract: This letter introduces DiffAero, a lightweight, GPU-accelerated, and fully
differentiable simulation framework designed for efficient quadrotor control
policy learning. DiffAero supports both environment-level and agent-level
parallelism and integrates multiple dynamics models, customizable sensor stacks
(IMU, depth camera, and LiDAR), and diverse flight tasks within a unified,
GPU-native training interface. By fully parallelizing both physics and
rendering on the GPU, DiffAero eliminates CPU-GPU data transfer bottlenecks and
delivers orders-of-magnitude improvements in simulation throughput. In contrast
to existing simulators, DiffAero not only provides high-performance simulation
but also serves as a research platform for exploring differentiable and hybrid
learning algorithms. Extensive benchmarks and real-world flight experiments
demonstrate that DiffAero and hybrid learning algorithms combined can learn
robust flight policies in hours on consumer-grade hardware. The code is
available at https://github.com/flyingbitac/diffaero.

</details>


### [151] [GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning](https://arxiv.org/abs/2509.10305)
*Yutong Shen,Ruizhe Xia,Bokai Yan,Shunqi zhang,Pengrui Xiang,Sicheng He,Yixin Xu*

Main category: cs.RO

TL;DR: GundamQ通过多尺度时空Q网络提升了机器人在动态环境下的路径规划能力，提高了成功率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习的机器人路径规划方法在动态和不确定环境中面临多尺度时间依赖建模不足和探索-利用平衡效率低下两大挑战。

Method: 提出GundamQ框架，包含（i）时空感知模块，用于提取多粒度空间特征和多尺度时间依赖性；（ii）自适应策略优化模块，用于平衡探索与利用，并通过约束策略更新优化平滑度和碰撞概率。

Result: 在动态环境中进行实验，GundamQ成功率提高了15.3%，整体路径质量提高了21.7%，显著优于现有最先进方法。

Conclusion: GundamQ通过其多尺度时空感知和自适应策略优化能力，有效解决了机器人路径规划中的挑战，并在动态环境中取得了显著的性能提升。

Abstract: In dynamic and uncertain environments, robotic path planning demands accurate
spatiotemporal environment understanding combined with robust decision-making
under partial observability. However, current deep reinforcement learning-based
path planning methods face two fundamental limitations: (1) insufficient
modeling of multi-scale temporal dependencies, resulting in suboptimal
adaptability in dynamic scenarios, and (2) inefficient exploration-exploitation
balance, leading to degraded path quality. To address these challenges, we
propose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path
Planning. The framework comprises two key modules: (i) the Spatiotemporal
Perception module, which hierarchically extracts multi-granularity spatial
features and multi-scale temporal dependencies ranging from instantaneous to
extended time horizons, thereby improving perception accuracy in dynamic
environments; and (ii) the Adaptive Policy Optimization module, which balances
exploration and exploitation during training while optimizing for smoothness
and collision probability through constrained policy updates. Experiments in
dynamic environments demonstrate that GundamQ achieves a 15.3\% improvement in
success rate and a 21.7\% increase in overall path quality, significantly
outperforming existing state-of-the-art methods.

</details>


### [152] [Robot guide with multi-agent control and automatic scenario generation with LLM](https://arxiv.org/abs/2509.10317)
*Elizaveta D. Moskovskaya,Anton D. Moscowsky*

Main category: cs.RO

TL;DR: 该研究提出了一种混合控制架构，用于能够与用户自然互动的拟人化导游机器人。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制系统在行为场景配置方面存在手动调整、灵活性低和行为不自然等局限性，该研究旨在克服这些缺点。

Method: 提出了一种结合了多智能体资源管理系统和基于大语言模型的自动行为场景生成方法的混合控制架构。场景生成包括两个阶段：首先创建风格化叙事，然后将非语言动作标签集成到文本中。多智能体系统负责协调和解决并行动作执行中的冲突，并保持主要操作完成后的默认行为。

Result: 通过试验获得的结果表明，该方法在自动化和扩展社交机器人控制系统方面具有潜力。

Conclusion: 该混合控制架构通过结合大语言模型和多智能体系统，能够生成更自然、更灵活的机器人行为，为自动化社交机器人控制提供了新的途径。

Abstract: The work describes the development of a hybrid control architecture for an
anthropomorphic tour guide robot, combining a multi-agent resource management
system with automatic behavior scenario generation based on large language
models. The proposed approach aims to overcome the limitations of traditional
systems, which rely on manual tuning of behavior scenarios. These limitations
include manual configuration, low flexibility, and lack of naturalness in robot
behavior. The process of preparing tour scenarios is implemented through a
two-stage generation: first, a stylized narrative is created, then non-verbal
action tags are integrated into the text. The multi-agent system ensures
coordination and conflict resolution during the execution of parallel actions,
as well as maintaining default behavior after the completion of main
operations, contributing to more natural robot behavior. The results obtained
from the trial demonstrate the potential of the proposed approach for
automating and scaling social robot control systems.

</details>


### [153] [Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended Transport System](https://arxiv.org/abs/2509.10349)
*Weiyan Lu,Huizhe Li,Yuhao Fang,Zhexuan Zhou,Junda Wu,Yude Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 该论文提出了一种名为 Acetrans 的无人机悬挂式运输系统，通过统一的感知、规划和控制框架解决了复杂环境中无人机运输的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有无人机悬挂式运输系统在感知、规划和安全保证方面存在严重缺陷，包括对绳索-载荷动力学感知不可靠、大规模环境规划效率低下以及在绳索弯曲和外部干扰下无法保证全身安全。

Method: 提出了一种结合 LiDAR-IMU 的融合模块，用于同时估计绳索的拉紧和弯曲模式下的载荷姿态和绳索形状，实现了鲁棒的全身状态估计和实时点云滤波。引入了多尺寸感知构型空间迭代区域膨胀（MACIRI）算法，用于生成考虑不同无人机和载荷几何形状的安全飞行通道。开发了一种时空相关的、受通道约束的轨迹优化方案，以确保动态可行且无碰撞的轨迹。最后，采用增强了绳索弯曲约束的非线性模型预测控制器（NMPC）来确保执行过程中的鲁棒全身安全。

Result: 模拟和实验结果验证了 Acetrans 的有效性，与现有方法相比，在感知精度、规划效率和控制安全性方面都有显著提高。

Conclusion: Acetrans 系统通过统一的感知、规划和控制框架，有效解决了无人机悬挂式运输中的关键挑战，并在精度、效率和安全性方面取得了显著进展。

Abstract: Unmanned aerial vehicles (UAVs) with suspended payloads offer significant
advantages for aerial transportation in complex and cluttered environments.
However, existing systems face critical limitations, including unreliable
perception of the cable-payload dynamics, inefficient planning in large-scale
environments, and the inability to guarantee whole-body safety under cable
bending and external disturbances. This paper presents Acetrans, an Autonomous,
Corridor-based, and Efficient UAV suspended transport system that addresses
these challenges through a unified perception, planning, and control framework.
A LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and
cable shape under taut and bent modes, enabling robust whole-body state
estimation and real-time filtering of cable point clouds. To enhance planning
scalability, we introduce the Multi-size-Aware Configuration-space Iterative
Regional Inflation (MACIRI) algorithm, which generates safe flight corridors
while accounting for varying UAV and payload geometries. A spatio-temporal,
corridor-constrained trajectory optimization scheme is then developed to ensure
dynamically feasible and collision-free trajectories. Finally, a nonlinear
model predictive controller (NMPC) augmented with cable-bending constraints
provides robust whole-body safety during execution. Simulation and experimental
results validate the effectiveness of Acetrans, demonstrating substantial
improvements in perception accuracy, planning efficiency, and control safety
compared to state-of-the-art methods.

</details>


### [154] [Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States](https://arxiv.org/abs/2509.10405)
*Nicholas Carlotti,Mirko Nava,Alessandro Giusti*

Main category: cs.RO

TL;DR: 提出了一种从头开始训练的单目RGB相对姿态估计模型，用于地面机器人，无需姿态标签或机器人形状/外观的先验知识。训练数据来自两个机器人随机移动，不需要外部基础设施或人工监督。


<details>
  <summary>Details</summary>
Motivation: 需要一种无需姿态标签或机器人形状/外观先验知识的单目RGB相对姿态估计方法。

Method: 在训练时，假设机器人装有多个LED，其状态在每帧中是已知的且独立的；知道每个LED的大致视角；并提供一张具有已知目标距离的校准图像，以解决单目深度估计的模糊性。模型通过预测图像中每个LED的状态来学习机器人图像中的位置、距离和相对方位。

Result: 该模型在推理时，LED状态未知且任意，不影响姿态估计性能。实验表明，该方法在与需要姿态标签或CAD模型的监督方法相比时具有竞争力，并且能够泛化到不同领域，并处理多机器人姿态估计。

Conclusion: 该模型能够有效地进行单目RGB相对姿态估计，并且在无需额外监督信息的情况下表现出良好的性能和泛化能力。

Abstract: We introduce a model for monocular RGB relative pose estimation of a ground
robot that trains from scratch without pose labels nor prior knowledge about
the robot's shape or appearance. At training time, we assume: (i) a robot
fitted with multiple LEDs, whose states are independent and known at each
frame; (ii) knowledge of the approximate viewing direction of each LED; and
(iii) availability of a calibration image with a known target distance, to
address the ambiguity of monocular depth estimation. Training data is collected
by a pair of robots moving randomly without needing external infrastructure or
human supervision. Our model trains on the task of predicting from an image the
state of each LED on the robot. In doing so, it learns to predict the position
of the robot in the image, its distance, and its relative bearing. At inference
time, the state of the LEDs is unknown, can be arbitrary, and does not affect
the pose estimation performance. Quantitative experiments indicate that our
approach: is competitive with SoA approaches that require supervision from pose
labels or a CAD model of the robot; generalizes to different domains; and
handles multi-robot pose estimation.

</details>


### [155] [TASC: Task-Aware Shared Control for Teleoperated Manipulation](https://arxiv.org/abs/2509.10416)
*Ze Fu,Pinhao Song,Yutong Hu,Renaud Detry*

Main category: cs.RO

TL;DR: TASC是一个任务感知共享控制框架，通过视觉输入构建交互图来理解用户意图，并提供旋转辅助，以应对日常操作任务的挑战，实现了零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 为支持无需预定义知识的日常任务，TASC旨在解决通用、长时序共享控制中的两大挑战：理解和推断任务级用户意图，以及跨不同物体和任务的泛化辅助。

Method: TASC构建了一个开放词汇的交互图，以表示功能性物体关系，并据此推断用户意图。然后，一个共享控制策略在抓取和物体交互过程中提供旋转辅助，该辅助由视觉-语言模型预测的空间约束指导。

Result: 实验结果表明，与现有方法相比，TASC在模拟和真实世界中均提高了任务效率并减少了用户输入的工作量。

Conclusion: TASC是首个支持日常操作任务并具备零样本泛化能力的共享控制框架。

Abstract: We present TASC, a Task-Aware Shared Control framework for teleoperated
manipulation that infers task-level user intent and provides assistance
throughout the task. To support everyday tasks without predefined knowledge,
TASC constructs an open-vocabulary interaction graph from visual input to
represent functional object relationships, and infers user intent accordingly.
A shared control policy then provides rotation assistance during both grasping
and object interaction, guided by spatial constraints predicted by a
vision-language model. Our method addresses two key challenges in
general-purpose, long-horizon shared control: (1) understanding and inferring
task-level user intent, and (2) generalizing assistance across diverse objects
and tasks. Experiments in both simulation and the real world demonstrate that
TASC improves task efficiency and reduces user input effort compared to prior
methods. To the best of our knowledge, this is the first shared control
framework that supports everyday manipulation tasks with zero-shot
generalization. The code that supports our experiments is publicly available at
https://github.com/fitz0401/tasc.

</details>


### [156] [Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction](https://arxiv.org/abs/2509.10444)
*Chaerim Moon,Joohyung Kim*

Main category: cs.RO

TL;DR: SRLs通过修改轨迹来减少对人体的力矩，以增强人机交互。


<details>
  <summary>Details</summary>
Motivation: SRLs在增强人类近距离能力的同时，其操作产生的力矩会作用于人体，导致肌肉激活增加并减少肌肉的零空间，影响人机交互。

Method: 提出一个运动规划层，通过修改给定轨迹，并在可接受的角加速度和位置偏差范围内，来减少SRLs操作产生的力矩。

Result: 通过简化的仿真模型证明了该运动规划层在减少力矩方面的有效性。

Conclusion: 所提出的运动规划方法能够有效减少SRLs操作对人体的力矩，从而改善人机交互。

Abstract: Supernumerary Robotic Limbs (SRLs) can enhance human capability within close
proximity. However, as a wearable device, the generated moment from its
operation acts on the human body as an external torque. When the moments
increase, more muscle units are activated for balancing, and it can result in
reduced muscular null space. Therefore, this paper suggests a concept of a
motion planning layer that reduces the generated moment for enhanced
Human-Robot Interaction. It modifies given trajectories with desirable angular
acceleration and position deviation limits. Its performance to reduce the
moment is demonstrated through the simulation, which uses simplified human and
robotic system models.

</details>


### [157] [GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation](https://arxiv.org/abs/2509.10454)
*Hang Yin,Haoyu Wei,Xiuwei Xu,Wenxuan Guo,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: 提出了一种无需训练的视觉与语言导航（VLN）框架，通过将导航指令分解为空间约束并利用图约束优化来解决，实现了在连续环境下的零样本泛化，并在标准基准和真实世界实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本VLN方法难以泛化和部署到真实世界场景，因为它们主要针对离散环境或涉及连续模拟器环境中的无监督训练。

Method: 将导航引导构建为图约束优化问题，通过将指令分解为明确的空间约束。构建了一个包含VLN指令中所有空间关系的约束库。将人类指令分解为有向无环图，并利用约束求解器求解以确定路点位置，从而获得机器人的导航路径和最终目标。通过构建导航树和回溯机制来处理无解或多解的情况。

Result: 在标准基准测试中，与最先进的零样本VLN方法相比，成功率和导航效率得到了显著提高。在真实世界实验中，证明了该框架能够有效地泛化到新环境和指令集。

Conclusion: 该框架为更鲁棒、更自主的导航框架铺平了道路，有效解决了现有VLN方法在真实世界应用中的挑战。

Abstract: In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [158] [Setchain Algorithms for Blockchain Scalability](https://arxiv.org/abs/2509.09795)
*Arivarasan Karmegam,Gabina Luz Bianchi,Margarita Capretto,Martín Ceresa,Antonio Fernández Anta,César Sánchez*

Main category: cs.DC

TL;DR: Setchain 通过将交易间的严格全序要求放松到每个 epoch 内的元素无序，来提高区块链的可扩展性。本文提出了三种 Setchain 算法（Vanilla、Compresschain、Hashchain），它们都利用了底层块状分类账，并实现了比底层区块链高几个数量级的吞吐量和低于 4 秒的最终性延迟。


<details>
  <summary>Details</summary>
Motivation: Setchain 的提出是为了通过放宽交易间严格全序的要求来提高区块链的可扩展性。

Method: 本文提出了三种 Setchain 算法：Vanilla（基础实现）、Compresschain（将元素聚合为批次并压缩）和 Hashchain（将批次转换为固定长度的哈希）。这些算法都利用了底层块状分类账，并维护了 epoch 的证明，允许轻客户端与单个服务器安全交互。算法在 CometBFT 平台上实现，并在不同服务器配置下进行了性能评估。

Result: Setchain 算法的吞吐量比底层区块链高几个数量级，最终性延迟低于 4 秒。

Conclusion: 提出的三种 Setchain 算法（Vanilla、Compresschain、Hashchain）能够显著提高区块链的可扩展性，在性能评估中展现出高吞吐量和低延迟。

Abstract: Setchain has been proposed to increase blockchain scalability by relaxing the
strict total order requirement among transactions. Setchain organizes elements
into a sequence of sets, referred to as epochs, so that elements within each
epoch are unordered. In this paper, we propose and evaluate three distinct
Setchain algorithms, that leverage an underlying block-based ledger. Vanilla is
a basic implementation that serves as a reference point. Compresschain
aggregates elements into batches, and compresses these batches before appending
them as epochs in the ledger. Hashchain converts batches into fixed-length
hashes which are appended as epochs in the ledger. This requires Hashchain to
use a distributed service to obtain the batch contents from its hash. To allow
light clients to safely interact with only one server, the proposed algorithms
maintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the
hash of the epoch, cryptographically signed by a server. A client can verify
the correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum
number of Byzantine servers assumed). All three Setchain algorithms are
implemented on top of the CometBFT blockchain application platform. We
conducted performance evaluations across various configurations, using clusters
of four, seven, and ten servers. Our results show that the Setchain algorithms
reach orders of magnitude higher throughput than the underlying blockchain, and
achieve finality with latency below 4 seconds.

</details>


### [159] [Ordered Consensus with Equal Opportunity](https://arxiv.org/abs/2509.09868)
*Yunhao Zhang,Haobin Ni,Soumya Basu,Shir Cohen,Maofan Yin,Lorenzo Alvisi,Robbert van Renesse,Qi Chen,Lidong Zhou*

Main category: cs.DC

TL;DR: 状态机复制（SMR）的顺序无关紧紧要，但在区块链中却至关重要。该论文提出了“平等机会”原则，要求共识协议在考虑相关因素后，给予候选者均等的机会来获得某个共识顺序中的特定位置。研究利用随机性来限制偏见，并引入了秘密随机预言（SRO）来以容错的方式生成随机性。最终，论文基于SRO设计了一个名为Bercow的新共识协议，该协议能有效缓解SMR区块链中的排序攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的有序共识协议虽然关注限制拜占庭节点对命令顺序的影响，但未能解决非拜占庭因素（如网络速度或地理位置）导致的顺序操纵问题，这些因素会给予某些客户端不公平的优势。因此，需要一种新的共识机制来确保公平性。

Method: 该论文提出将“平等机会”原则（源于社会科学）引入有序共识。该原则要求，在考虑了相关因素后，两个同样有资格获得特定共识顺序位置的候选者，应该有均等的机会获得该位置。为了实现这一目标，研究利用随机性来控制偏差，并引入了秘密随机预言（SRO）来容错地生成随机数。论文还提出了两种SRO的设计：一种基于可信硬件，另一种基于门槛可验证随机函数。

Result: 研究提出了两种SRO的设计，并基于SRO设计了一个名为Bercow的新型有序共识协议。Bercow协议能够以可配置的因子来近似实现平等机会，从而有效减轻SMR区块链中已知的排序攻击。

Conclusion: 通过引入平等机会原则和秘密随机预言（SRO），并设计出Bercow共识协议，可以有效解决现有区块链排序机制中的不公平性问题，并缓解相关的排序攻击。

Abstract: The specification of state machine replication (SMR) has no requirement on
the final total order of commands. In blockchains based on SMR, however, order
matters, since different orders could provide their clients with different
financial rewards. Ordered consensus augments the specification of SMR to
include specific guarantees on such order, with a focus on limiting the
influence of Byzantine nodes. Real-world ordering manipulations, however, can
and do happen even without Byzantine replicas, typically because of factors,
such as faster networks or closer proximity to the blockchain infrastructure,
that give some clients an unfair advantage. To address this challenge, this
paper proceeds to extend ordered consensus by requiring it to also support
equal opportunity, a concrete notion of fairness, widely adopted in social
sciences. Informally, equal opportunity requires that two candidates who,
according to a set of criteria deemed to be relevant, are equally qualified for
a position (in our case, a specific slot in the SMR total order), should have
an equal chance of landing it. We show how randomness can be leveraged to keep
bias in check, and, to this end, introduce the secret random oracle (SRO), a
system component that generates randomness in a fault-tolerant manner. We
describe two SRO designs based, respectively, on trusted hardware and threshold
verifiable random functions, and instantiate them in Bercow, a new ordered
consensus protocol that, by approximating equal opportunity up to within a
configurable factor, can effectively mitigate well-known ordering attacks in
SMR-based blockchains.

</details>


### [160] [Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective](https://arxiv.org/abs/2509.10371)
*Seokjin Go,Joongun Park,Spandan More,Hanjiang Wu,Irene Wang,Aaron Jezghani,Tushar Krishna,Divya Mahajan*

Main category: cs.DC

TL;DR: LLM训练在多GPU系统中的表现，强调了硬件、系统拓扑和模型执行之间的复杂交互作用，并为未来的LLM系统设计提供了建议。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模的快速扩大，训练工作负载已远超单节点分析能力，因此需要深入理解LLM在大型多GPU系统中的行为。

Method: 对不同真实世界工作负载和硬件平台（包括NVIDIA H100/H200和AMD MI250 GPU）上的LLM训练进行了全面表征。分析了不同并行策略（张量、流水线、数据、专家）下稠密和稀疏模型的表现，并评估了激活重计算和计算-通信重叠等优化措施的效果。

Result: 研究发现，性能并非仅由硬件容量决定。在通信受限的情况下，配备较少高内存GPU的Scale-up系统在精心调优后，可能优于Scale-out系统；但在其他情况下，Scale-out部署可实现更高的吞吐量。此外，张量与流水线并行等组合可能因数据分块效率低下而导致带宽利用不足；微批次大小增加到一定程度会引起执行突发和峰值功耗，加剧热节流。

Conclusion: LLM训练性能受到硬件、系统拓扑和模型执行之间复杂交互作用的影响。研究为改进未来LLM系统和工作负载的可扩展性及可靠性提供了系统和硬件设计的建议。

Abstract: The rapid scaling of Large Language Models (LLMs) has pushed training
workloads far beyond the limits of single-node analysis, demanding a deeper
understanding of how these models behave across large-scale, multi-GPU systems.
In this paper, we present a comprehensive characterization of LLM training
across diverse real-world workloads and hardware platforms, including NVIDIA
H100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various
parallelism strategies -- tensor, pipeline, data, and expert -- and evaluate
their effects on hardware utilization, power consumption, and thermal behavior.
We further evaluate the effectiveness of optimizations such as activation
recomputation and compute-communication overlap. Our findings show that
performance is not determined solely by scaling hardware capacity. Scale-up
systems with fewer, higher-memory GPUs can outperform scale-out systems in
communication-bound regimes, but only under carefully tuned configurations; in
other cases, scale-out deployments achieve superior throughput. We also show
that certain parallelism combinations, such as tensor with pipeline, lead to
bandwidth underutilization due to inefficient data chunking, while increasing
microbatch sizes beyond a certain point induces bursty execution and peak power
excursions that worsen thermal throttling. These insights reveal how training
performance is shaped by complex interactions between hardware, system
topology, and model execution. We conclude by offering recommendations for
system and hardware design to improve the scalability and reliability of future
LLM systems and workloads. The source code of this project is available at
https://github.com/sitar-lab/CharLLM-PPT.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [161] [Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building](https://arxiv.org/abs/2509.09906)
*Alexandra Fetsch,Iurii Savvateev,Racem Ben Romdhane,Martin Wiedmann,Artemiy Dimov,Maciej Durkalec,Josef Teichmann,Jakob Zinsstag,Konstantinos Koutsoumanis,Andreja Rajkovic,Jason Mann,Mauro Tonolla,Monika Ehling-Schulz,Matthias Filter,Sophia Johler*

Main category: cs.MA

TL;DR: 本研究提出了一个结合大语言模型（LLMs）和自主AI代理的AI辅助谈判框架，用于跨部门风险分析和决策，以应对复杂全球挑战。


<details>
  <summary>Details</summary>
Motivation: 传统风险分析框架因过度简化复杂性而形成孤岛，阻碍了综合解决方案的制定，因此需要一种能够促进跨部门合作和平衡各方利益的整体性策略。

Method: 该研究构建了一个AI辅助谈判框架，整合了LLMs和AI自主代理，嵌入到以谈判为中心的风险分析工作流中，以模拟谈判、建模动态、预测妥协和评估解决方案的影响。

Result: 通过在大语言模型语义分析能力的帮助下，该框架能够缓解信息过载，并在时间限制下增强决策过程。在生物农药的谨慎使用和野生动物种群的目标控制两个真实场景中的概念验证实施，证明了该方法的有效性。

Conclusion: 本研究展示了AI辅助谈判在解决当前跨部门参与工具缺乏方面具有巨大潜力。其开源、基于网络的特性使其适用于资源有限的广大用户，并允许用户根据自身需求进行定制和开发。

Abstract: Key global challenges of our times are characterized by complex
interdependencies and can only be effectively addressed through an integrated,
participatory effort. Conventional risk analysis frameworks often reduce
complexity to ensure manageability, creating silos that hinder comprehensive
solutions. A fundamental shift towards holistic strategies is essential to
enable effective negotiations between different sectors and to balance the
competing interests of stakeholders. However, achieving this balance is often
hindered by limited time, vast amounts of information, and the complexity of
integrating diverse perspectives. This study presents an AI-assisted
negotiation framework that incorporates large language models (LLMs) and
AI-based autonomous agents into a negotiation-centered risk analysis workflow.
The framework enables stakeholders to simulate negotiations, systematically
model dynamics, anticipate compromises, and evaluate solution impacts. By
leveraging LLMs' semantic analysis capabilities we could mitigate information
overload and augment decision-making process under time constraints.
Proof-of-concept implementations were conducted in two real-world scenarios:
(i) prudent use of a biopesticide, and (ii) targeted wild animal population
control. Our work demonstrates the potential of AI-assisted negotiation to
address the current lack of tools for cross-sectoral engagement. Importantly,
the solution's open source, web based design, suits for application by a
broader audience with limited resources and enables users to tailor and develop
it for their own needs.

</details>


### [162] [A Holistic Architecture for Monitoring and Optimization of Robust Multi-Agent Path Finding Plan Execution](https://arxiv.org/abs/2509.10284)
*David Zahrádka,Denisa Mužíková,David Woller,Miroslav Kulich,Jiří Švancara,Roman Barták*

Main category: cs.MA

TL;DR: MAPF 计划的稳健执行和监控需要平衡继续执行当前计划与重新规划以缩短执行时间的成本。


<details>
  <summary>Details</summary>
Motivation: 当机器人执行 MAPF 计划时，延迟可能会累积并导致执行时间延长，即使原始计划是最优的，也可能存在更优的替代计划。

Method: 提出了一种整体架构，用于 MAPF 计划的稳健执行、监控和优化。使用称为“动作依赖图”的稳健执行方法来估计预期执行时间，并预测重新规划的潜在好处。

Result: 实验表明，该架构可以有效预测何时重新规划可以缩短执行时间，从而在实际应用中具有成本效益。

Conclusion: MAPF 计划的监控和优化对于在存在延迟的情况下实现高效执行至关重要。通过仔细监控执行时间和重新规划的潜在好处，可以最大限度地减少执行时间。

Abstract: The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a
fleet of agents moving in a shared environment such that the agents reach their
goals without colliding with each other. In practice, some of the robots
executing the plan may get delayed, which can introduce collision risk.
Although robust execution methods are used to ensure safety even in the
presence of delays, the delays may still have a significant impact on the
duration of the execution. At some point, the accumulated delays may become
significant enough that instead of continuing with the execution of the
original plan, even if it was optimal, there may now exist an alternate plan
which will lead to a shorter execution. However, the problem is how to decide
when to search for the alternate plan, since it is a costly procedure. In this
paper, we propose a holistic architecture for robust execution of MAPF plans,
its monitoring and optimization. We exploit a robust execution method called
Action Dependency Graph to maintain an estimate of the expected execution
duration during the plan's execution. This estimate is used to predict the
potential that finding an alternate plan would lead to shorter execution. We
empirically evaluate the architecture in experiments in a real-time simulator
which we designed to mimic our real-life demonstrator of an autonomous
warehouse robotic fleet.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [163] [A Note on Constructive Canonical Splitter Strategies in Nowhere Dense Graph Classes](https://arxiv.org/abs/2509.10062)
*Janne Fuchser,Nikolas Mählmann,Sebastian Siebertz*

Main category: cs.LO

TL;DR: 该研究为半径-r 分裂游戏提供了分裂者获胜策略的渐进式移动数量的上界。


<details>
  <summary>Details</summary>
Motivation: 介绍半径-r 分裂游戏，该游戏是图论中用于表征无处不密图类的一个工具，并指出先前关于分裂者获胜策略的研究缺乏建设性界限。

Method: 提出了一种分裂者在半径-r 游戏中以 k 轮获胜时，渐进式移动数量的上界（2r+1)^(2^(k-1)-1) 的构造性证明。

Result: 证明了如果分裂者可以在半径-r 游戏中迫使以 k 轮获胜，那么渐进式移动的数量至多为 (2r+1)^(2^(k-1)-1)。

Conclusion: 该工作提供了一个关于分裂者游戏中渐进式移动数量的简单构造性证明，弥补了先前基于紧致性定理的证明中缺乏构造性界限的不足。

Abstract: The radius-$r$ splitter game is played on a graph $G$ between two players:
Splitter and Connector. In each round, Connector selects a vertex $v$, and the
current game arena is restricted to the radius-$r$ neighborhood of $v$. Then
Splitter removes a vertex from this restricted subgraph. The game ends, and
Splitter wins, when the arena becomes empty. Splitter aims to end the game as
quickly as possible, while Connector tries to prolong it for as long as
possible. The splitter game was introduced by Grohe, Kreutzer and Siebertz to
characterize nowhere dense graph classes. They showed that a class
$\mathscr{C}$ of graphs is nowhere dense if and only if for every radius $r$
there exists a number $\ell$ such that Splitter has a strategy on every $G\in
\mathscr{C}$ to win the radius-$r$ splitter game in at most $\ell$ rounds. It
was recently proved by Ohlmann et al. that there are only a bounded number of
possible Splitter moves that are progressing, that is, moves that lead to an
arena where Splitter can win in one less round. The proof of Ohlmann et al. is
based on the compactness theorem and does not give a constructive bound on the
number of progressing moves. In this work, we give a simple constructive proof,
showing that if Splitter can force a win in the radius-$r$ game in $k$ rounds,
then there are at most $(2r+1)^{\,2^{k-1}-1}$ progressing moves.

</details>


### [164] [On Syntactical Simplification of Temporal Operators in Negation-free MTL](https://arxiv.org/abs/2509.10146)
*Mathijs van Noort,Femke Ongenae,Pieter Bonte*

Main category: cs.LO

TL;DR: 本论文研究了无否定形式的时间逻辑推理，证明了MTL逻辑中的“总是”和“仅仅”算子可以被“直到”和“自从”算子替代，从而简化了逻辑形式并为可扩展推理提供了可能。


<details>
  <summary>Details</summary>
Motivation: 传统的逻辑推理方法依赖否定来表达缺失或矛盾，但在不完整和异步的数据环境中（如物联网或语义网）会变得不可靠。因此，研究不包含否定的时间逻辑规则系统引起了广泛关注，因为它们能保持单调性并支持可扩展推理。

Method: 通过证明MTL逻辑中的“总是”算子可以被“一次”、“自从”和“直到”算子组合替代，并进一步证明“一次”算子也可以被“直到”和“自从”算子替代，从而得到一个仅基于“直到”和“自从”的逻辑片段。

Result: 研究表明，MTL逻辑中的“总是”和“一次”算子可以被消除，仅留下“直到”和“自从”算子，这表明无否定形式的时间逻辑同样具有表达能力，能够捕捉存在性和不变性的时间模式。这大大简化了MTL的语法，有利于理论研究和实现。

Conclusion: 本研究成功地识别并证明了一个强大的、无否定的MTL逻辑片段，仅由“直到”和“自从”算子构成。这一发现不仅挑战了普遍认为否定对于表达普遍时间约束是必需的观点，而且还通过简化语法为理论分析和实际应用带来了好处，为在动态、数据密集型环境中进行可扩展的时间推理提供了新的途径。

Abstract: Temporal reasoning in dynamic, data-intensive environments increasingly
demands expressive yet tractable logical frameworks. Traditional approaches
often rely on negation to express absence or contradiction. In such contexts,
Negation-as-Failure is commonly used to infer negative information from the
lack of positive evidence. However, open and distributed systems such as IoT
networks or the Semantic Web Negation-as-Failure semantics become unreliable
due to incomplete and asynchronous data. This has led to a growing interest in
negation-free fragments of temporal rule-based systems, which preserve
monotonicity and enable scalable reasoning.
  This paper investigates the expressive power of negation-free MTL, a temporal
logic framework designed for rule-based reasoning over time. We show that the
"always" operators of MTL, often treated as syntactic sugar for combinations of
other temporal constructs, can be eliminated using "once", "since" and "until"
operators. Remarkably, even the "once" operators can be removed, yielding a
fragment based solely on "until" and "since". These results challenge the
assumption that negation is necessary for expressing universal temporal
constraints, and reveal a robust fragment capable of capturing both existential
and invariant temporal patterns. Furthermore, the results induce a reduction in
the syntax of MTL, which in turn can provide benefits for both theoretical
study as well as implementation efforts.

</details>


### [165] [Initial Algebras of Domains via Quotient Inductive-Inductive Types](https://arxiv.org/abs/2509.10187)
*Simcha van Collem,Niels van der Weide,Herman Geuvers*

Main category: cs.LO

TL;DR: 域论提供了一个建立代数效应的通用框架，该框架使用 DCPO 代数和拟商归纳归纳类型，并已在 Cubical Agda 中得到证明，可用于对部分性、非确定性和其他计算形式进行建模。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提供一个建立域理论中代数效应的通用框架，以解决非确定性、偏函数和副作用等计算形式的建模问题。

Method: 本文提出了一个使用 DCPO 代数（定义了操作和不相等理论）来表示代数效应的框架，并通过拟商归纳归纳类型（QIIT）证明了初始 DCPO 代数的存在性。

Result: 本文展示了该框架如何应用于各种已知的 DCPO（例如，合并和、粉碎积和自由 DCPO）的构造，并使用 Cubical Agda 对其进行了形式化。

Conclusion: 通过使用拟商归纳归纳类型，本文成功地为域理论中的代数效应提供了一个通用的、可实例化的框架，并证明了该框架在对各种计算形式进行建模方面的适用性。

Abstract: Domain theory has been developed as a mathematical theory of computation and
to give a denotational semantics to programming languages. It helps us to fix
the meaning of language concepts, to understand how programs behave and to
reason about programs. At the same time it serves as a great theory to model
various algebraic effects such as non-determinism, partial functions, side
effects and numerous other forms of computation.
  In the present paper, we present a general framework to construct algebraic
effects in domain theory, where our domains are DCPOs: directed complete
partial orders. We first describe so called DCPO algebras for a signature,
where the signature specifies the operations on the DCPO and the inequational
theory they obey. This provides a method to represent various algebraic
effects, like partiality. We then show that initial DCPO algebras exist by
defining them as so called Quotient Inductive-Inductive Types (QIITs), known
from homotopy type theory. A quotient inductive-inductive type allows one to
simultaneously define an inductive type and an inductive relation on that type,
together with equations on the type. We illustrate our approach by showing that
several well-known constructions of DCPOs fit our framework: coalesced sums,
smash products and free DCPOs (partiality and power domains). Our work makes
use of various features of homotopy type theory and is formalized in Cubical
Agda.

</details>


### [166] [Effects of the Strict-Tolerant Approach on Intuitionistic and Minimal Logic](https://arxiv.org/abs/2509.10322)
*Victor Barroso-Nascimento,German Mejia*

Main category: cs.LO

TL;DR: 本研究将严格-宽容逻辑方法应用于直觉主义和最小逻辑，并研究了其元推理的逻辑。


<details>
  <summary>Details</summary>
Motivation: 将严格-宽容逻辑方法应用于直觉主义和最小逻辑，以探索其在非经典逻辑中的影响，并与经典逻辑进行比较。

Method: 通过修改逻辑推理的概念，定义了严格-宽容逻辑推理和元推理，并分析了它们与经典逻辑的关系。

Result: 研究发现，直觉主义严格-宽容推理会崩溃为经典推理，但最小逻辑的推理不会。然而，最小严格-宽容逻辑在推理层面没有任何有效推理。此外，从直觉主义、最小逻辑和经典逻辑在元推理层面获得的逻辑是相互区别的。

Conclusion: 严格-宽容逻辑方法在直觉主义和最小逻辑中的应用揭示了推理和元推理的复杂行为，强调了它们与经典逻辑的区别和联系。

Abstract: This paper extends the literature on the strict-tolerant logical approach by
applying its methods to intuitionistic and minimal logic. In short, the
strict-tolerant approach modifies the usual notion of logical consequence by
stipulating that, in order for an inference to be valid, from the truth of the
premises must follow the non-falsity of the conclusion. This notion can also be
generalized to define strict-tolerant metainferences, metametainferences and so
on, which may or may not generate logics distinct from those obtained on the
inferential level. It is already known that strict-tolerant definitions can
make the notion of inference for non-classical logics collapse into the
classical notion, but the strength of this effect is not yet fully known. This
paper shows that intuitionistic strict-tolerant inferences also collapse into
classical ones, but minimal ones do not. However, minimal strict-tolerant logic
has the property that no inferences are valid (which is not carried over to the
metainferential level). Additionally, it is shown that the logics obtained from
intuitionistic, minimal and classical logic at the metainferential level are
distinct from each other.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [167] [Towards An Approach to Identify Divergences in Hardware Designs for HPC Workloads](https://arxiv.org/abs/2509.09774)
*Doru Thom Popovici,Mario Vega,Angelos Ioannou,Fabien Chaix,Dania Mosuli,Blair Reasoner,Tan Nguyen,Xiaokun Yang,John Shalf*

Main category: cs.AR

TL;DR: 通过将数学内核分解为常用构建块，并自动化分析，为硬件加速器设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 手动优化硬件加速器（例如用于科学计算和机器学习的数学内核）非常耗时，需要低级编程。虽然 Chisel 和 HLS 等高级工具有所帮助，但生成的硬件可能不如专家设计的硬件。因此，理解这些低效率的来源对于用户和工具开发者至关重要。

Method: 提出了一种分层分解数学内核（如傅立叶变换、矩阵乘法和 QR 分解）到一组常用构建块（原语）的方法。然后，在不同的编程环境中实现这些原语，并组装成更大的算法。此外，采用自动方法来研究可实现的频率和所需资源。

Result: 通过在每个级别进行实验，可以更公平地比较不同的设计。

Conclusion: 该方法为工具开发者和硬件设计师提供了宝贵的见解，以改进实践，从而在硬件加速器设计中实现更高的效率。

Abstract: Developing efficient hardware accelerators for mathematical kernels used in
scientific applications and machine learning has traditionally been a
labor-intensive task. These accelerators typically require low-level
programming in Verilog or other hardware description languages, along with
significant manual optimization effort. Recently, to alleviate this challenge,
high-level hardware design tools like Chisel and High-Level Synthesis have
emerged. However, as with any compiler, some of the generated hardware may be
suboptimal compared to expert-crafted designs. Understanding where these
inefficiencies arise is crucial, as it provides valuable insights for both
users and tool developers. In this paper, we propose a methodology to
hierarchically decompose mathematical kernels - such as Fourier transforms,
matrix multiplication, and QR factorization - into a set of common building
blocks or primitives. Then the primitives are implemented in the different
programming environments, and the larger algorithms get assembled. Furthermore,
we employ an automatic approach to investigate the achievable frequency and
required resources. Performing this experimentation at each level will provide
fairer comparisons between designs and offer guidance for both tool developers
and hardware designers to adopt better practices.

</details>


### [168] [Finesse: An Agile Design Framework for Pairing-based Cryptography via Software/Hardware Co-Design](https://arxiv.org/abs/2509.10051)
*Tianwei Pan,Tianao Dai,Jianlei Yang,Hongbin Jing,Yang Su,Zeyu Hao,Xiaotao Jia,Chunming Hu,Weisheng Zhao*

Main category: cs.AR

TL;DR: Finesse是一个基于软硬件协同设计的方法论的敏捷设计框架，旨在解决现有配对密码学加速器设计周期长、性能与灵活性难以平衡以及架构探索支持不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的配对密码学（PBC）加速器设计方法面临设计周期长、性能与灵活性平衡困难以及架构探索支持不足等挑战。

Method: Finesse采用软硬件协同设计方法，通过一个专门的编译器和一个多粒度硬件模拟器驱动协同优化，实现了性能优化和设计空间探索。它还采用了模块化设计流程和通用的抽象，以缩短设计周期并支持不同曲线和硬件架构的灵活性。

Result: Finesse的实验结果表明，相比之前的灵活框架，其吞吐量提高了34倍，面积效率提高了6.2倍。与最先进的非灵活ASIC设计相比，Finesse的吞吐量提高了3倍，面积效率提高了3.2倍。编译时间缩短至几分钟，从而实现了更快的迭代周期和简化的软硬件协同设计。

Conclusion: Finesse框架通过其灵活性、效率和快速原型设计能力，显著优于之前的框架，能够有效应对现代配对密码学加速器设计的挑战。

Abstract: Pairing-based cryptography (PBC) is crucial in modern cryptographic
applications. With the rapid advancement of adversarial research and the
growing diversity of application requirements, PBC accelerators need regular
updates in algorithms, parameter configurations, and hardware design. However,
traditional design methodologies face significant challenges, including
prolonged design cycles, difficulties in balancing performance and flexibility,
and insufficient support for potential architectural exploration.
  To address these challenges, we introduce Finesse, an agile design framework
based on co-design methodology. Finesse leverages a co-optimization cycle
driven by a specialized compiler and a multi-granularity hardware simulator,
enabling both optimized performance metrics and effective design space
exploration. Furthermore, Finesse adopts a modular design flow to significantly
shorten design cycles, while its versatile abstraction ensures flexibility
across various curve families and hardware architectures.
  Finesse offers flexibility, efficiency, and rapid prototyping, comparing with
previous frameworks. With compilation times reduced to minutes, Finesse enables
faster iteration cycles and streamlined hardware-software co-design.
Experiments on popular curves demonstrate its effectiveness, achieving
$34\times$ improvement in throughput and $6.2\times$ increase in area
efficiency compared to previous flexible frameworks, while outperforming
state-of-the-art non-flexible ASIC designs with a $3\times$ gain in throughput
and $3.2\times$ improvement in area efficiency.

</details>


### [169] [MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging Bit-Slice-enabled Sparsity and Repetitiveness](https://arxiv.org/abs/2509.10372)
*Huizheng Wang,Zichuan Wang,Zhiheng Yue,Yousheng Long,Taiquan Wei,Jianxun Yang,Yang Wang,Chao Li,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.AR

TL;DR: MCBP是一种创新的算法-硬件协同设计，通过利用位切片（BS）的可重复性和稀疏性来加速LLM推理，显著提高了速度和能效。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer加速器在处理LLM推理时，由于GEMM操作、权重访问和KV缓存访问效率低下，存在显著的延迟问题，并且难以同时优化计算和内存。

Method: MCBP通过三种创新技术来解决这些问题：1. BS-可重复性计算缩减（BRCR），消除冗余的GEMM计算；2. BS-稀疏性两状态编码（BSTC），减少权重访问；3. 位粒度渐进预测（BGPP），减少KV缓存访问。这些技术由定制的加速器设计支持。

Result: 在26个基准测试中，MCBP实现了9.43倍的速度提升和31.1倍的能效提升，优于Nvidia A100 GPU。与SOTA Transformer加速器相比，MCBP在能效方面分别领先Spatten、FACT和SOFA 35倍、5.2倍和3.2倍。

Conclusion: MCBP通过其创新的位粒度计算-内存协同设计，有效地解决了LLM推理中的延迟和能效瓶颈，并在多个基准测试中取得了显著的性能提升。

Abstract: Large language models (LLMs) face significant inference latency due to
inefficiencies in GEMM operations, weight access, and KV cache access,
especially in real-time scenarios. This highlights the need for a versatile
compute-memory efficient accelerator. Unfortunately, existing Transformer
accelerators struggle to address both aspects simultaneously, as they focus on
value-level processing, missing fine-grained opportunities to optimize
computation and memory collaboratively. This paper introduces MCBP, a
bit-grained compute-memory efficient algorithm-hardware co-design that
leverages bit-slice (BS) enabled repetitiveness and sparsity to accelerate LLM
inference. MCBP features three key innovations: 1) BS-repetitiveness-enabled
computation reduction (BRCR), which eliminates redundant GEMM computations via
leveraging redundancy hidden among BS vectors; 2) BS-sparsity-enabled two-state
coding (BSTC), which reduces weight access via exploiting significant sparsity
in high-order bit-slice weight; 3) Bit-grained progressive prediction (BGPP),
which reduces KV cache access by leveraging early-termination-based bit-grained
prediction. These techniques, supported by custom accelerator designs,
effectively alleviate the burden in GEMM, weight access, and KV cache access.
Extensive experiments on 26 benchmarks show that MCBP achieves 9.43x speed up
and 31.1x higher energy efficiency than Nvidia A100 GPU. Compared to SOTA
Transformer accelerators, MCBP achieves 35x, 5.2x and 3.2x energy saving than
Spatten, FACT and SOFA, respectively.

</details>


### [170] [TurboFuzz: FPGA Accelerated Hardware Fuzzing for Processor Agile Verification](https://arxiv.org/abs/2509.10400)
*Yang Zhong,Haoran Wu,Xueqi Li,Sa Wang,David Boland,Yungang Bao,Kan Shi*

Main category: cs.AR

TL;DR: TurboFuzz是一个端到端的硬件加速验证框架，可在单个FPGA上为现代处理器验证实现完整的测试生成-仿真-覆盖反馈循环，通过优化的种子控制流、高效的种子调度和混合模糊器集成来提高测试质量、覆盖率和执行效率，并采用反馈驱动的生成机制加速覆盖率收敛。


<details>
  <summary>Details</summary>
Motivation: 现代处理器验证的复杂性日益增加，以及RISC-V等新指令集架构的出现，对更敏捷、更高效的验证方法提出了要求，特别是在验证效率和覆盖率收敛速度方面。现有的基于仿真的方法在应用于处理器验证时存在性能差和测试用例质量不足等问题。基于FPGA或ASIC的硬件加速方案则面临主机-FPGA通信开销、测试模式生成效率低下以及多步验证过程实现不理想等挑战。

Method: TurboFuzz是一个端到端的硬件加速验证框架，在单个FPGA上实现了完整的测试生成-仿真-覆盖反馈循环。它通过优化的种子控制流、高效的种子间调度和混合模糊器集成来增强测试质量，从而提高覆盖率和执行效率。此外，它采用反馈驱动的生成机制来加速覆盖率收敛。

Result: 实验结果表明，TurboFuzz在相同的时间预算内，覆盖率收集能力比基于软件的模糊器高出2.23倍，在检测真实世界问题时性能提高了571倍，同时保持了完整的可见性和调试能力，且面积开销适中。

Conclusion: TurboFuzz通过在单个FPGA上实现完整的测试生成-仿真-覆盖反馈循环，并采用一系列优化技术，显著提高了处理器验证的效率和覆盖率收敛速度，解决了现有方法的局限性。

Abstract: Verification is a critical process for ensuring the correctness of modern
processors. The increasing complexity of processor designs and the emergence of
new instruction set architectures (ISAs) like RISC-V have created demands for
more agile and efficient verification methodologies, particularly regarding
verification efficiency and faster coverage convergence. While simulation-based
approaches now attempt to incorporate advanced software testing techniques such
as fuzzing to improve coverage, they face significant limitations when applied
to processor verification, notably poor performance and inadequate test case
quality. Hardware-accelerated solutions using FPGA or ASIC platforms have tried
to address these issues, yet they struggle with challenges including host-FPGA
communication overhead, inefficient test pattern generation, and suboptimal
implementation of the entire multi-step verification process.
  In this paper, we present TurboFuzz, an end-to-end hardware-accelerated
verification framework that implements the entire Test
Generation-Simulation-Coverage Feedback loop on a single FPGA for modern
processor verification. TurboFuzz enhances test quality through optimized test
case (seed) control flow, efficient inter-seed scheduling, and hybrid fuzzer
integration, thereby improving coverage and execution efficiency. Additionally,
it employs a feedback-driven generation mechanism to accelerate coverage
convergence. Experimental results show that TurboFuzz achieves up to 2.23x more
coverage collection than software-based fuzzers within the same time budget,
and up to 571x performance speedup when detecting real-world issues, while
maintaining full visibility and debugging capabilities with moderate area
overhead.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [171] [Approximate Graph Propagation Revisited: Dynamic Parameterized Queries, Tighter Bounds and Dynamic Updates](https://arxiv.org/abs/2509.10036)
*Zhuowei Zhao,Zhuo Zhang,Hanzhi Wang,Junhao Gan,Zhifeng Bao,Jianzhong Qi*

Main category: cs.DS

TL;DR: 本文提出AGP-Static++和AGP-Dynamic两种新算法，用于解决动态图和动态参数化查询中的图传播问题，在查询和更新效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决动态图和动态参数化查询场景下，现有图传播框架（如AGP-Static）在查询复杂度和更新效率方面存在的挑战。

Method: AGP-Static++通过简化算法，在保持近似保证的同时，降低了查询复杂度中的O(log^2 n)因子。AGP-Dynamic通过实现O(1)的摊销更新时间，显著提高了动态图更新的效率，同时保持了查询复杂度和近似保证。

Result: 实验结果表明，与基线方法相比，AGP-Static++在查询效率上提升显著，AGP-Dynamic在更新时间上实现了高达177倍的加速，查询效率提升10倍。

Conclusion: AGP-Static++和AGP-Dynamic在处理动态图和动态参数化查询方面，相比现有方法具有显著的理论和实践优势，能够有效提升图传播任务的效率。

Abstract: We revisit Approximate Graph Propagation (AGP), a unified framework which
captures various graph propagation tasks, such as PageRank, feature propagation
in Graph Neural Networks (GNNs), and graph-based Retrieval-Augmented Generation
(RAG). Our work focuses on the settings of dynamic graphs and dynamic
parameterized queries, where the underlying graphs evolve over time (updated by
edge insertions or deletions) and the input query parameters are specified on
the fly to fit application needs. Our first contribution is an interesting
observation that the SOTA solution, AGP-Static, can be adapted to support
dynamic parameterized queries; however several challenges remain unresolved.
Firstly, the query time complexity of AGP-Static is based on an assumption of
using an optimal algorithm for subset sampling in its query algorithm.
Unfortunately, back to that time, such an algorithm did not exist; without such
an optimal algorithm, an extra $O(\log^2 n)$ factor is required in the query
complexity, where $n$ is the number of vertices in the graphs. Secondly,
AGP-Static performs poorly on dynamic graphs, taking $O(n\log n)$ time to
process each update. To address these challenges, we propose a new algorithm,
AGP-Static++, which is simpler yet reduces roughly a factor of $O(\log^2 n)$ in
the query complexity while preserving the approximation guarantees of
AGP-Static. However, AGP-Static++ still requires $O(n)$ time to process each
update. To better support dynamic graphs, we further propose AGP-Dynamic, which
achieves $O(1)$ amortized time per update, significantly improving the
aforementioned $O(n)$ per-update bound, while still preserving the query
complexity and approximation guarantees. Last, our comprehensive experiments
validate the theoretical improvements: compared to the baselines, our algorithm
achieves speedups of up to $177\times$ on update time and $10\times$ on query
efficiency.

</details>


### [172] [Constant Time with Minimal Preprocessing, a Robust and Extensive Complexity Class](https://arxiv.org/abs/2509.10188)
*Étienne Grandjean,Louis Jachiet*

Main category: cs.DS

TL;DR: 该研究定义并分析了一个名为 cstPP 的操作类别，该类别具有在有限预处理时间后可进行常数时间计算的特性。研究表明该类别具有鲁棒性、可扩展性，并满足多种闭包性质，对基元操作集不敏感，且闭合于复合运算和部分逆运算。此外，研究还探讨了预处理时间对该类别的依赖性，证明了线性预处理时间并非必需，但其显著降低（至 N^o(1)）会导致类别退化。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究一类名为 cstPP 的操作，这类操作在进行一定时间的预处理后，能够以常数时间完成计算。研究的动机在于理解这类操作的性质、鲁棒性、可扩展性及其与其他数学和计算类别的关系。

Method: 通过分析 cstPP 类操作的定义，研究者采用了计算复杂性理论和可计算性理论的方法。具体包括：1. 形式化 cstPP 类操作的定义，明确其输入、输出、预处理时间和常数时间计算的要求。2. 证明 cstPP 类的鲁棒性，即其性质不因 RAM 机器基元操作集的改变而改变。3. 验证 cstPP 类的闭包性质，包括对复合运算和逆运算的闭合性。4. 分析预处理时间对 cstPP 类定义的影响，比较不同预处理时间复杂度下的类别变化。

Result: 研究证明了 cstPP 类操作具有鲁棒性和可扩展性，并满足多种闭包性质。它对 RAM 机器的基元操作集不敏感，并且在操作复合和某些逆运算下保持不变。研究还表明，常数时间计算不一定需要严格的线性预处理时间，只要预处理时间复杂度在一定范围内（O(N^c) 或 N^ε），该类别保持不变。然而，当预处理时间复杂度低于 N^o(1) 时，该类别会退化。

Conclusion: cstPP 类操作是一个稳定且性质良好的计算模型。其关键特性在于“预处理后常数时间计算”，这一特性在一定范围内对预处理时间的具体复杂度不敏感，并且不依赖于特定的基元操作集。这表明 cstPP 类在计算理论中具有重要的意义，它提供了一种灵活且高效的计算框架。

Abstract: In this paper, we study the class $\mathtt{cstPP}$ of operations
$\mathtt{op}: \mathbb{N}^k\to\mathbb{N}$, of any fixed arity $k\ge 1$,
satisfying the following property: for each fixed integer $d\ge 1$, there
exists an algorithm for a RAM machine which, for any input integer $N\ge 2$, -
pre-computes some tables in $O(N)$ time, - then reads $k$ operands
$x_1,\ldots,x_k<N^d$ and computes $\mathtt{op}(x_1,\dots,x_k)$ in constant
time.
  We show that the $\mathtt{cstPP}$ class is robust and extensive and satisfies
several closure properties. It is invariant depending on whether the set of
primitive operations of the RAM is $\{+\}$, or
$\{+,-,\times,\mathtt{div},\mathtt{mod}\}$, or any set of operations in
$\mathtt{cstPP}$ provided it includes $+$. We prove that the $\mathtt{cstPP}$
class is closed under composition and, for fast-growing functions, is closed
under inverse. We also show that in the definition of $\mathtt{cstPP}$ the
constant-time procedure can be reduced to a single return instruction. Finally,
we establish that linear preprocessing time is not essential in the definition
of the $\mathtt{cstPP}$ class: this class is not modified if the preprocessing
time is increased to $O(N^c)$, for any fixed $c>1$, or conversely, is reduced
to $N^{\varepsilon}$, for any positive $\varepsilon<1$ (provided the set of
primitive operation includes $+$, $\mathtt{div}$ and $\mathtt{mod}$). To
complete the picture, we demonstrate that the $\mathtt{cstPP}$ class
degenerates if the preprocessing time reduces to $N^{o(1)}$.

</details>


### [173] [A linear-time algorithm for Chow decompositions](https://arxiv.org/abs/2509.10450)
*Alexander Taveira Blomenhofer,Benjamin Lovitz*

Main category: cs.DS

TL;DR: 我们提出了一种线性时间算法来计算低秩Chow分解，该算法可以分解Chow秩为n/3的n变量的简洁对称3阶张量，并依赖于广义特征值计算。我们还开发了用于更高阶Chow分解和非通用轨道Chow分解的亚二次时间算法，特别是获得了将对称3阶张量分解为W-张量线性组合的亚二次时间算法。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是开发计算低秩Chow分解的高效算法，特别是针对简洁对称3阶张量，并为更高阶和非通用轨道分解提供亚二次时间解决方案。

Method: 本文提出的方法是基于一个线性时间算法，利用广义特征值计算来执行低秩Chow分解。此外，还开发了用于更高阶Chow分解和特定类型（如W-张量）分解的亚二次时间算法。

Result: 研究结果表明，所提出的算法能够在线性时间内计算低秩Chow分解，并能分解Chow秩为n/3的简洁对称3阶张量。此外，还实现了用于更高阶和非通用轨道分解的亚二次时间算法，包括将对称3阶张量分解为W-张量线性组合的算法。

Conclusion: 本文成功地提出了一种计算低秩Chow分解的线性时间算法，并为更复杂的分解问题开发了亚二次时间算法，展示了在张量分解领域的显著进展。

Abstract: We propose a linear-time algorithm to compute low-rank Chow decompositions.
Our algorithm can decompose concise symmetric 3-tensors in n variables of Chow
rank n/3. The algorithm is pencil based, hence it relies on generalized
eigenvalue computations. We also develop sub-quadratic time algorithms for
higher order Chow decompositions, and Chow decompositions of 3-tensors into
products of linear forms which do not lie on the generic orbit. In particular,
we obtain a sub-quadratic-time algorithm for decomposing a symmetric 3-tensor
into a linear combination of W-tensors.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [174] [Quantum Langevin Dynamics](https://arxiv.org/abs/2509.09743)
*Mohammad Attrash,Roi Baer*

Main category: quant-ph

TL;DR: 研究者开发了一种新的处理开放量子系统的方法，即随机波函数方法，并在二维系统和量子粒子与谐振器浴相互作用的案例中进行了测试。


<details>
  <summary>Details</summary>
Motivation: 研究者想开发一种新的处理开放量子系统的方法，即随机波函数方法，并将其与现有的密度矩阵方法进行比较。

Method: 研究者开发了一种新的处理开放量子系统的方法，即随机波函数方法。他们首先在二维系统上进行了测试，然后将该方法应用于一个量子粒子与谐振器浴相互作用的系统。在后者的情况下，他们加入了一个摩擦项，并研究了该方法在不同温度下的表现。

Result: 在二维系统上，随机波函数方法与密度矩阵方法表现良好。然而，在量子粒子与谐振器浴相互作用的系统中，当温度高于零点能或系统是莫尔斯振子时，系统会无限吸收能量。加入了摩擦项后，系统的动力学衰减到能量为 Egs+kBT 的系综。

Conclusion: 随机波函数方法在处理开放量子系统方面有潜力，但仍存在一些问题需要进一步研究，特别是在处理无限能量吸收方面。

Abstract: Previous years researchers began to simulate open quantum system, taking into
account the interaction between system and the environment. One approach to
deal with this problem is to use the density matrix within the
Liouville-von-Neumann formalism or the Markovian variant the Lindblad
equations. Another way is to use a stochastic approach where a random force is
added to the system. The benefit of the stochastic approach is to solve the
dynamics of the system with less time and memory than the density matrix
approaches. In this project we want to develop a stochastic approach that can
deal with the stochastic wave functions approach. We did this on a 2-level
system and found that it works well when comparing to a density matrix
approach. Next, we tested a quantum particle connect to a bath of harmonic
oscillators using the stochastic approach. We found that a friction term is
necessary and applied it. Like in the classical Langevin equations the friction
constant and the random force fluctuations are related by the
fluctuation-dissipation constant. We showed that with friction the dynamics
decays to an ensemble with energy of $E_{gs}+k_BT$. However, we also found here
are problems. The system seems to absorb energy indefinitely if the temperature
is higher than the zero point energy or if the system is a Morse oscillator.
Thus more research is required to make this method work.

</details>


### [175] [Lower-depth local encoding circuits for the surface code](https://arxiv.org/abs/2509.09779)
*Jahan Claes*

Main category: quant-ph

TL;DR: 本论文提出了一种新的旋转表面码编码电路，将编码深度从 2d 减少到 d，并证明了 d+O(1) 对于归纳构造的电路是最优的。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于改进现有表面码编码电路的效率，特别是减少其深度，以适应二维局部连通性的要求。

Method: 论文提出了一种新的旋转表面码编码电路，该电路通过从 d 增长到 (d+2) 的电路进行归纳构造，最终实现了深度为 d 的编码。

Result: 成功设计了深度为 d 的旋转表面码编码电路，优于之前需要深度 2d 的电路。

Conclusion: 论文提出的深度为 d 的编码电路是针对旋转表面码的，并且证明了对于归纳构造的电路，深度 d+O(1) 是最优的。

Abstract: The surface code is the most studied error-correcting code thanks to its high
threshold, simple decoding, and locality in two dimensions (2D). A key
component of any code is its encoding circuit, which maps an unencoded state to
the corresponding encoded state. The best previous surface code encoding
circuit compatible with 2D local connectivity requires depth $2d$ to encode
distance-$d$ surface codes. This paper presents depth $d$ encoding circuits for
the rotated surface code. Our circuit is constructed inductively from circuits
that grow the code from $d$ to $(d+2)$. We prove that depth $d+O(1)$ is optimal
for inductively constructed circuits.

</details>


### [176] [Optimal Waveforms for Dipole Moment Estimation with Coherent States](https://arxiv.org/abs/2509.09807)
*Karthik Chinni,Nicolás Quesada*

Main category: quant-ph

TL;DR: 本研究利用量子传感技术优化相干态脉冲形状，以提高发射光子的量子Fisher信息量，从而更精确地估计原子偶极矩（与自发辐射率成正比）。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化相干态脉冲形状，以最大化发射光子的量子Fisher信息量，用于估计原子的偶极矩。

Method: 通过推导一组耦合微分方程（包含光学Bloch方程）来求解量子Fisher信息量，并分析了影响优化的因素，包括脉冲宽度和平均光子数。

Result: 在长脉冲宽度极限下，发现频率等于自发辐射率一半且相位由失谐确定的谐波（平面波）脉冲是最佳选择。

Conclusion: 研究成功导出了计算量子Fisher信息量的方法，并确定了在特定条件下最优的脉冲形状，为量子传感在光谱分析中的应用提供了理论指导。

Abstract: We investigate quantum sensing for spectroscopy in a system consisting of a
two-level atom coupled to a continuum of modes. We focus on optimizing the
pulse shape of a coherent state to maximize the quantum Fisher information
(QFI) of the emitted light with the aim of estimating the atom's dipole moment,
which is proportional to its spontaneous emission rate. To achieve this, we
derive a set of coupled differential equations, which include the standard
optical Bloch equations as a subset and whose solution directly yields the QFI
of the emitted light without resorting to finite-difference methods.
Furthermore, we analyze the factors that govern its optimization, provide
analytic solutions in both the long and the short pulse width limits, and
examine the role of the average photon number of the pulses. We then show that
under the closed (periodic) boundary conditions, the harmonic (plane-wave) with
frequency equal to half the spontaneous emission rate and a phase determined by
detuning are optimal in the long pulse width limit.

</details>


### [177] [Nearly optimal algorithms to learn sparse quantum Hamiltonians in physically motivated distances](https://arxiv.org/abs/2509.09813)
*Amira Abbas,Nunzia Cerrato,Francisco Escudero Gutiérrez,Dmitry Grinko,Francesco Anna Mele,Pulkit Sinha*

Main category: quant-ph

TL;DR: 该研究解决了学习 Pauli 基础上 s-稀疏的哈密顿量 H 的问题，并考虑了其时间演化。研究者提出了两种物理上合理的方法来衡量哈密顿量之间的距离，并设计了一种接近最优的算法。


<details>
  <summary>Details</summary>
Motivation: 现有哈密顿量学习研究中存在匹配下界缺失和使用不直观的误差度量的问题。本研究旨在解决这些挑战。

Method: 研究者提出了两种衡量哈密顿量之间距离的方法：时间约束距离（通过有界时间内的动力学演化量化可区分性）和温度约束距离（通过有界反温下的热态捕获可区分性）。基于这些距离，设计了近乎最优的算法。

Result: 在时间约束距离和温度约束距离下，学习 s-稀疏且算子范数有界的哈密顿量，实验次数为 O(s log(1/ε))，演化时间为 O(s^2/ε)。对于时间约束距离，实验次数的下界为 Ω((s/n)log(1/ε) + s)，演化时间的下界为 Ω(√s/ε)，证明了实验次数的近乎最优性。此外，研究者还提出了一种学习单个 Pauli 系数的方法，实验次数为 O(s log(1/ε))，演化时间为 O(s/ε)，改进了现有结果。

Conclusion: 本研究通过引入新的物理意义上的距离度量和创新的隔离技术，在哈密顿量学习领域取得了重要进展，特别是在学习 s-稀疏哈密顿量方面，算法在实验次数和演化时间上都接近最优。

Abstract: We study the problem of learning Hamiltonians $H$ that are $s$-sparse in the
Pauli basis, given access to their time evolution. Although Hamiltonian
learning has been extensively investigated, two issues recur in much of the
existing literature: the absence of matching lower bounds and the use of
mathematically convenient but physically opaque error measures.
  We address both challenges by introducing two physically motivated distances
between Hamiltonians and designing a nearly optimal algorithm with respect to
one of these metrics. The first, time-constrained distance, quantifies
distinguishability through dynamical evolution up to a bounded time. The
second, temperature-constrained distance, captures distinguishability through
thermal states at bounded inverse temperatures.
  We show that $s$-sparse Hamiltonians with bounded operator norm can be
learned in both distances with $O(s \log(1/\epsilon))$ experiments and
$O(s^2/\epsilon)$ evolution time. For the time-constrained distance, we further
establish lower bounds of $\Omega((s/n)\log(1/\epsilon) + s)$ experiments and
$\Omega(\sqrt{s}/\epsilon)$ evolution time, demonstrating near-optimality in
the number of experiments.
  As an intermediate result, we obtain an algorithm that learns every Pauli
coefficient of $s$-sparse Hamiltonians up to error $\epsilon$ in
$O(s\log(1/\epsilon))$ experiments and $O(s/\epsilon)$ evolution time,
improving upon several recent results.
  The source of this improvement is a new isolation technique, inspired by the
Valiant-Vazirani theorem (STOC'85), which shows that NP is as easy as detecting
unique solutions. This isolation technique allows us to query the time
evolution of a single Pauli coefficient of a sparse Hamiltonian--even when the
Pauli support of the Hamiltonian is unknown--ultimately enabling us to recover
the Pauli support itself.

</details>


### [178] [Comparative Studies of Quantum Annealing, Digital Annealing, and Classical Solvers for Reaction Network Pathway Analysis and mRNA Codon Selection](https://arxiv.org/abs/2509.09862)
*Milind Upadhyay,Mark Nicholas Jones*

Main category: quant-ph

TL;DR: 本研究评估了QUBO求解器在组合优化问题上的效用，并将其与经典的MIP和CP求解器进行了比较。


<details>
  <summary>Details</summary>
Motivation: 与经典的比特计算硬件相比，数字和量子退火器在解决计算密集型优化问题方面具有潜力，本研究旨在评估QUBO求解器在组合优化问题上的效用，并确定QUBO公式和退火算法是否优于经典的MIP和CP求解器。

Method: 通过比较QUBO求解器（包括Fujitsu DA、D-Wave QA和HQA）与经典MIP/CP求解器（HiGHS、Gurobi、SCIP和CP-SAT），对两个实际应用案例——反应网络通路分析和mRNA密码子选择——进行基准测试。使用问题映射、互连性、惩罚结构、求解器最小成本和求解时间等指标进行评估。

Result: 在反应通路分析中，MIP/CP求解器能够以合理的时间找到最优解，而DA未能找到。在mRNA密码子选择中，CP-SAT在标准和大型数据集上表现最佳，而在超大型数据集上，D-Wave HQA求解器的性能与CP-SAT相当，并在2/4个问题中以更小的成本获得最优解。

Conclusion: QUBO方法和退火算法在某些组合优化问题上可能提供优势，但并非总是优于经典的MIP和CP求解器。具体性能取决于问题的性质和规模，以及所使用的特定求解器。

Abstract: For various optimization problems, the classical time to solution is
super-polynomial and intractable to solve with classical bit-based computing
hardware to date. Digital and quantum annealers have the potential to identify
near-optimal solutions for such optimization problems using a quadratic
unconstrained binary optimization (QUBO) problem formulation. This work
benchmarks two use cases to evaluate the utility of QUBO solvers for
combinatorial optimization problems, in order to determine if a QUBO
formulation and annealing-based algorithms have an advantage over classical
mixed-integer programming (MIP) and constraint programming (CP) solvers.
Various QUBO and solver metrics such as problem mapping, quantitative
interconnectivity, penalty structure, solver minimum cost (obtained optimal
value) and solver time to solution have been applied to evaluate different QUBO
problems. Constrained and unconstrained QUBO solvers are compared including the
Fujitsu digital annealer (DA), various D-Wave hybrid quantum annealing solvers
(QA, HQA), and the classical MIP/CP solvers HiGHS, Gurobi, SCIP, and CP-SAT.
The two industrially relevant use cases are reaction network pathway analysis
and mRNA codon selection. For reaction pathway analysis, classical MIP/CP
solvers are observed to solve the problem to optimality in reasonable time
frames while the DA is not able to do so. For mRNA codon selection, CP-SAT
displayed the best performance for standard and large protein datasets (under
1500 amino acids). For the extra-large protein dataset (11000 to 14000 amino
acids), the D-Wave Nonlinear HQA solver performed comparably to CP-SAT,
outperforming it in minimum cost in 2 out of the 4 problems.

</details>


### [179] [Toward Minimum Graphic Parity Networks](https://arxiv.org/abs/2509.10070)
*Yixin Cao,Yiren Lu,Junhong Nie,Xiaoming Sun,Guojing Tian*

Main category: quant-ph

TL;DR: 研究了量子线路合成中的图文网络问题，提出了理论下界和近似算法，并探索了特定图类的最小线路合成。


<details>
  <summary>Details</summary>
Motivation: 量子线路（特别是CNOT和Rz门）是量子算法的基础，因此优化这类线路的合成至关重要。本研究旨在解决图文网络综合问题，为量子优化算法提供更高效的线路。

Method: 1. 理论分析：研究图文网络的门数量下界。对于连通图，下界为m+n-1。当最短环长度至少为5时，下界可提升至m+Ω(n^1.5)。 2. 算法设计：提出一种随机化算法，期望合成的线路包含m+O(n^1.5 * sqrt(log n))个门。 3. 特定图类探索：研究能实现m+n-1个门的最少图文网络的图类，并提出一个线性时间合成算法。 4. 复杂度分析：证明识别该特定图类是NP-complete的，并提出一个参数化为树宽的固定参数可处理算法。

Result: 1. 确定了图文网络的门数量下界。 2. 提出了一个近似算法，可在期望时间内生成接近最优的线路。 3. 识别了一个具有特殊性质的图类，并为其设计了高效的合成算法。 4. 分析了该图类的识别复杂度。

Conclusion: 本研究为图文网络的最小门数量合成问题提供了重要的理论贡献和实用的算法。虽然识别最小门线路的特定图类具有挑战性（NP-complete），但通过树宽参数化仍可实现高效处理。

Abstract: Quantum circuits composed of CNOT and $R_z$ are fundamental building blocks
of many quantum algorithms, so optimizing the synthesis of such quantum
circuits is crucial. We address this problem from a theoretical perspective by
studying the graphic parity network synthesis problem. A graphic parity network
for a graph $G$ is a quantum circuit composed solely of CNOT gates where each
edge of $G$ is represented in the circuit, and the final state of the wires
matches the original input. We aim to synthesize graphic parity networks with
the minimum number of gates, specifically for quantum algorithms addressing
combinatorial optimization problems with Ising formulations. We demonstrate
that a graphic parity network for a connected graph with $n$ vertices and $m$
edges requires at least $m+n-1$ gates. This lower bound can be improved to
$m+\Omega(m) = m+\Omega(n^{1.5})$ when the shortest cycle in the graph has a
length of at least five. We complement this result with a simple randomized
algorithm that synthesizes a graphic parity network with expected $m +
O(n^{1.5}\sqrt{\log n})$ gates. Additionally, we begin exploring connected
graphs that allow for graphic parity networks with exactly $m+n-1$ gates. We
conjecture that all such graphs belong to a newly defined graph class.
Furthermore, we present a linear-time algorithm for synthesizing minimum
graphic parity networks for graphs within this class. However, this graph class
is not closed under taking induced subgraphs, and we show that recognizing it
is $\textsf{NP}$-complete, which is complemented with a fixed-parameter
tractable algorithm parameterized by the treewidth.

</details>


### [180] [Quantum sensing in the presence of pulse errors and qubit leakage](https://arxiv.org/abs/2509.09874)
*David M. Lancaster,Muhammad Ali Shahbaz,Hamed Goli Yousefabad,Sanway Chatterjee,Eegan Ram,Jonathan D. Weinstein*

Main category: quant-ph

TL;DR: 本研究使用模拟和实验来评估动态解耦序列对脉冲错误的鲁棒性，发现脉冲错误对量子传感的影响可能比对相干时间的影响更为显著，并且不同的动态解耦序列在抗脉冲错误和抑制量子比特泄露方面表现出数量级上的差异。


<details>
  <summary>Details</summary>
Motivation: 研究量子传感中动态解耦序列对脉冲错误（旋转误差和失谐误差）的鲁棒性，并探讨量子比特泄露的影响，以期发现比仅考虑相干时间更全面的脉冲错误影响。

Method: 通过模拟和实验相结合的方式，研究了动态解耦序列对旋转误差、失谐误差以及量子比特泄露的敏感性。

Result: 研究发现，脉冲错误对量子传感的影响可能与对相干时间的影响有显著不同。不同的动态解耦序列在对脉冲错误的敏感性和抑制量子比特泄露方面存在数量级上的差异。

Conclusion: 现有的动态解耦序列在抗脉冲错误和量子比特泄露方面存在显著差异，为选择合适的序列提供了依据。

Abstract: Using both simulation and experiment, we investigate the robustness of
dynamical decoupling sequences to pulse errors: rotation errors and detuning
errors. Whereas prior work examined the effect of errors on coherence times,
here we show that quantum sensing can be affected by pulse errors in
dramatically different ways than coherence times alone. We also explore the
effects of qubit leakage: off-resonant coupling to other quantum levels. We
find order-of-magnitude differences between commonly-used dynamical decoupling
sequences in both their sensitivity to pulse errors and leakage.

</details>


### [181] [Quantum Computing Technology Roadmaps and Capability Assessment for Scientific Computing -- An analysis of use cases from the NERSC workload](https://arxiv.org/abs/2509.09882)
*Daan Camps,Ermal Rrapaj,Katherine Klymko,Hyeongjin Kim,Kevin Gott,Siva Darbha,Jan Balewski,Brian Austin,Nicholas J. Wright*

Main category: quant-ph

TL;DR: NERSC将重点关注材料科学、量子化学和高能物理这三个领域，并预测量子计算将在未来五年到十年内对这些领域产生重大影响。


<details>
  <summary>Details</summary>
Motivation: NERSC认识到量子计算在其未来使命中的关键作用，并希望确定从中受益最大的科学领域。

Method: 通过分析NERSC的工作负载、进行文献综述和评估量子资源需求，同时参考量子计算公司的技术路线图。

Result: 材料科学、量子化学和高能物理是受益最大的领域，占NERSC当前工作负载的一半以上。量子资源需求正在下降，而量子计算能力正在迅速提高，预计在未来五年到十年内会出现重大重叠。此外，还提出了SQSP指标来衡量量子系统的性能。

Conclusion: 量子计算有望在未来五年到十年内对NERSC产生重大影响，届时量子计算能力将与科学需求相匹配。

Abstract: The National Energy Research Scientific Computing Center (NERSC), as the
high-performance computing (HPC) facility for the Department of Energy's Office
of Science, recognizes the essential role of quantum computing in its future
mission. In this report, we analyze the NERSC workload and identify materials
science, quantum chemistry, and high-energy physics as the science domains and
application areas that stand to benefit most from quantum computers. These
domains jointly make up over 50% of the current NERSC production workload,
which is illustrative of the impact quantum computing could have on NERSC's
mission going forward. We perform an extensive literature review and determine
the quantum resources required to solve classically intractable problems within
these science domains. This review also shows that the quantum resources
required have consistently decreased over time due to algorithmic improvements
and a deeper understanding of the problems. At the same time, public technology
roadmaps from a collection of ten quantum computing companies predict a
dramatic increase in capabilities over the next five to ten years. Our analysis
reveals a significant overlap emerging in this time frame between the
technological capabilities and the algorithmic requirements in these three
scientific domains. We anticipate that the execution time of large-scale
quantum workflows will become a major performance parameter and propose a
simple metric, the Sustained Quantum System Performance (SQSP), to compare
system-level performance and throughput for a heterogeneous workload.

</details>


### [182] [Certifying and learning quantum Ising Hamiltonians](https://arxiv.org/abs/2509.10239)
*Andreas Bluhm,Matthias C. Caro,Francisco Escudero Gutiérrez,Aadil Oufkir,Cambyse Rouzé*

Main category: quant-ph

TL;DR: 本文研究了量子伊辛哈密顿量的认证和学习问题，并提出了近乎最优的算法。


<details>
  <summary>Details</summary>
Motivation: 研究量子伊辛哈密顿量的认证和学习问题，旨在解决现有算法在时间、样本复杂度或参数依赖性方面的不足。

Method: 利用傅里叶分析中的Bonami Lemma来认证伊辛哈密顿量；设计了一种样本效率高的算法来学习伊辛吉布斯状态；提出了时间和样本效率兼具的算法来认证伊辛吉布斯状态。最后将吉布斯状态的学习和认证结果推广到一般的k-局部哈密顿量。

Result: 认证伊辛哈密顿量的时间复杂度接近最优（$	ilde{O}(1/	au)$），学习伊辛吉布斯状态的样本复杂度在所有参数上都是样本效率的，认证伊辛吉布斯状态的算法同时实现了样本和时间的效率。

Conclusion: 本文提出的算法在量子伊辛哈密顿量的认证和学习方面取得了近乎最优或样本/时间效率的改进，并成功推广到更一般的k-局部哈密顿量。

Abstract: In this work, we study the problems of certifying and learning quantum Ising
Hamiltonians. Our main contributions are as follows:
  Certification of Ising Hamiltonians. We show that certifying an Ising
Hamiltonian in normalized Frobenius norm via access to its time-evolution
operator requires only $\widetilde O(1/\varepsilon)$ time evolution. This
matches the Heisenberg-scaling lower bound of $\Omega(1/\varepsilon)$ up to
logarithmic factors. To our knowledge, this is the first nearly-optimal
algorithm for testing a Hamiltonian property. A key ingredient in our analysis
is the Bonami Lemma from Fourier analysis.
  Learning Ising Gibbs states. We design an algorithm for learning Ising Gibbs
states in trace norm that is sample-efficient in all parameters. In contrast,
previous approaches learned the underlying Hamiltonian (which implies learning
the Gibbs state) but suffered from exponential sample complexity in the inverse
temperature.
  Certification of Ising Gibbs states. We give an algorithm for certifying
Ising Gibbs states in trace norm that is both sample and time-efficient,
thereby solving a question posed by Anshu (Harvard Data Science Review, 2022).
  Finally, we extend our results on learning and certification of Gibbs states
to general $k$-local Hamiltonians for any constant $k$.

</details>


### [183] [Improved Quantum Lifting by Coherent Measure-and-Reprogram](https://arxiv.org/abs/2509.09896)
*Alexandru Cojocaru,Juan Garay,Qipeng Liu,Fang Song*

Main category: quant-ph

TL;DR: 该论文在量子随机预言模型下，为安全博弈提供了更精确的提升定理，并引入了相干重构框架，该框架仅需经典推理即可实现更优的提升定理，并可用于解决多实例安全博弈的硬度问题。


<details>
  <summary>Details</summary>
Motivation: 在量子随机预言模型下，为安全博弈提供更精确的提升定理，并引入一种新的相干重构框架。

Method: 提出相干重构框架，并基于此框架推导出量子直接积定理（平均情况），进而应用于解决多种安全博弈的硬度问题。

Result: 推导出了量子直接积定理（平均情况），并证明了多种安全博弈（如盐值博弈、单向性和抗碰撞性等密码学任务的多实例版本）的（非均匀）硬度。

Conclusion: 论文提出的相干重构框架和提升定理可以有效地解决多实例安全博弈的硬度问题，并为相关密码学任务的安全性分析提供了新的工具。

Abstract: We give a tighter lifting theorem for security games in the quantum random
oracle model. At the core of our main result lies a novel measure-and-reprogram
framework that we call coherent reprogramming. This framework gives a tighter
lifting theorem for query complexity problems, that only requires purely
classical reasoning. As direct applications of our lifting theorem, we first
provide a quantum direct product theorem in the average case - i.e., an
enabling tool to determine the hardness of solving multi-instance security
games. This allows us to derive in a straightforward manner the hardness of
various security games, for example (i) the non-uniform hardness of salted
games, (ii) the hardness of specific cryptographic tasks such as the multiple
instance version of one-wayness and collision-resistance, and (iii) uniform or
non-uniform hardness of many other games.

</details>


### [184] [NISQ Security and Complexity via Simple Classical Reasoning](https://arxiv.org/abs/2509.09900)
*Alexandru Cojocaru,Juan Garay,Qipeng Liu,Fang Song*

Main category: quant-ph

TL;DR: 本文在量子随机预言模型(QROM)和嘈杂中等规模量子(NISQ)设置下，为安全博弈提供了新的提升定理，包括混合查询模型、嘈杂预言和有界深度模型。首次提出了混合提升定理，适用于可执行量子和经典查询的混合算法，以及适用于具有嘈杂预言或有界量子深度的量子算法的提升定理。核心是一种新颖的测量-再编程框架，称为混合相干测量-再编程，专门针对混合算法。利用提升定理，可以直接证明NISQ安全性和复杂度结果，只需计算一个组合量，仅依赖于经典推理。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为安全博弈在量子随机预言模型(QROM)和嘈杂中等规模量子(NISQ)设置下提供新的提升定理，以应对混合查询模型、嘈杂预言和有界深度等挑战。

Method: 提出了一种新颖的测量-再编程框架，称为混合相干测量-再编程，用于混合算法。在此基础上，推导了混合提升定理和适用于嘈杂预言或有界量子深度的量子算法的提升定理。

Result: 1. 首次提出混合提升定理，适用于混合算法。 2. 提出适用于嘈杂预言或有界量子深度的量子算法的提升定理。 3. 证明了混合设置下的首个平均情况直接积定理。 4. 简明地推导了各种博弈的NISQ复杂度，包括盐化博弈的非均匀复杂度、单向性和碰撞抗性等密码任务的复杂度。

Conclusion: 本研究通过新颖的混合相干测量-再编程框架和提升定理，成功地将NISQ设置下的安全博弈分析扩展到混合算法和嘈杂模型，并直接推导了相关的安全性和复杂度结果，为理解和设计NISQ算法提供了重要的理论工具。

Abstract: We give novel lifting theorems for security games in the quantum random
oracle model (QROM) in Noisy Intermediate-Scale Quantum (NISQ) settings such as
the hybrid query model, the noisy oracle and the bounded-depth models. We
provide, for the first time, a hybrid lifting theorem for hybrid algorithms
that can perform both quantum and classical queries, as well as a lifting
theorem for quantum algorithms with access to noisy oracles or bounded quantum
depth.
  At the core of our results lies a novel measure-and-reprogram framework,
called hybrid coherent measure-and-reprogramming, tailored specifically for
hybrid algorithms. Equipped with the lifting theorem, we are able to prove
directly NISQ security and complexity results by calculating a single
combinatorial quantity, relying solely on classical reasoning.
  As applications, we derive the first direct product theorems in the average
case, in the hybrid setting-i.e., an enabling tool to determine the hybrid
hardness of solving multi-instance security games. This allows us to derive in
a straightforward manner the NISQ hardness of various security games, such as
(i) the non-uniform hardness of salted games, (ii) the hardness of specific
cryptographic tasks such as the multiple instance version of one-wayness and
collision-resistance, and (iii) uniform or non-uniform hardness of many other
games.

</details>


### [185] [Orthogonal polynomials, quantum walks and the Prouhet-Tarry-Escott problem](https://arxiv.org/abs/2509.09948)
*Frederico Cançado,Gabriel Coutinho,Thomás Jung Spier*

Main category: quant-ph

TL;DR: We explore the possibility of perfect state transfer in quantum walks on weighted paths and uncover connections to the Prouhet-Tarry-Escott problem, while also deriving new characterizations of orthogonal polynomials.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the problem of determining if weights in a quantum walk on a path can be tuned for perfect state transfer between the first vertex and any other position.

Method: The paper analyzes quantum walks on weighted paths and proves new results about sequences of orthogonal polynomials satisfying three-term recurrences, providing a full characterization of when two polynomials belong to such a sequence.

Result: The paper shows that a specific case of the state transfer problem is equivalent to a case of the Prouhet-Tarry-Escott problem, indicating the problem is harder than initially thought. New characterizations for orthogonal polynomials are also presented.

Conclusion: The paper establishes a link between quantum walks and the Prouhet-Tarry-Escott problem, and provides a comprehensive characterization of orthogonal polynomials, advancing the understanding of these mathematical structures.

Abstract: This paper is motivated by the following problem. Define a quantum walk on a
positively weighted path (linear chain). Can the weights be tuned so that
perfect state transfer occurs between the first vertex and any other position?
We do not fully answer this question - in fact, we show that a particular case
of this problem is equivalent to a solution of a particular case of the well
known Prouhet-Tarry-Escott problem, deeming our original task certainly harder
than anticipated. In our journey, we prove new results about sequences of
orthogonal polynomials satisfying three-term recurrences. In particular, we
provide a full characterization of when two polynomials belong to such a
sequence, which (as far as we were able to ascertain) was known only for when
their degrees differ by one.

</details>


### [186] [No oscillating subradiant correlations in a strongly driven quantum emitter array](https://arxiv.org/abs/2509.09993)
*Jiaming Shi,Nikita Leppenen,Ran Tessler,Alexander N. Poddubny*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We theoretically study time-dependent correlations in a strongly driven array
of $N$ two-level atoms, coupled to photons in a waveguide. We focus on the
spectrum $\{\lambda\}$ of the Liouvillian superoperator, which determines the
correlation decay rates $-\Re \lambda$ and the frequencies $\Im\lambda$. Our
main finding is the suppression of subradiant oscillating correlations between
atomic states by a strong coherent of amplitude $\Omega$: $|\Re \lambda|\ge
m\gamma/2$, where $\gamma$ is the single-atom spontaneous decay rate and
$m=|\Im \lambda/(2\Omega)|$ is a nonzero integer for correlations oscillating
in time $\propto \exp(\pm 2i m|\Omega| t)$. This limit is independent of the
number of atoms $N$; it holds both for small arrays and in the macroscopic
limit. We demonstrate the suppression of subradiance numerically and provide a
rigorous proof based on the analytical decomposition of the Liouvillian using
spectral theory of simplicial complexes and posets.

</details>


### [187] [Perfect quantum state transfer via state restoring and ancilla measurement](https://arxiv.org/abs/2509.10100)
*E. B. Fel'dman,J. Wu,A. I. Zenchuk*

Main category: quant-ph

TL;DR: 该协议实现了自旋1/2链上的任意纯量子态的完美态传输，仅需对扩展接收器的量子比特进行局部变换，并通过测量辅助量子比特去除垃圾态。


<details>
  <summary>Details</summary>
Motivation: 提出一个在保持激发数守恒的哈密顿量控制的自旋1/2链上实现任意纯量子态完美态传输的协议。

Method: 通过局部变换和测量辅助量子比特来恢复和净化传输的量子态。

Result: 在接收器端可以恢复任意k-激发纯发送器状态，并通过测量辅助量子比特去除垃圾态，最终得到与初始状态（相位相差可忽略）一致的状态。

Conclusion: 该协议实现了任意纯量子态的完美态传输，包括编码、传输、恢复、解码和垃圾态去除等步骤。

Abstract: We propose the protocol for perfect state transfer of an arbitrary pure
quantum state along the spin-1/2 chain governed by the Hamiltonian preserving
the excitation number in the system. We show that the $k$-excitation pure
sender's state can be restored at the receiver using only the local
transformations over the qubits of the extended receiver. The restored state
appears in the superposition with other states which form garbage. This garbage
can be easily removed by including the ancilla whose state labels the garbage,
and then measuring the {ancilla state} with desired output. The resulting state
of the receiver coincides with the initial sender's state {up to the
unimportant common phase factor.} Then, to transfer an arbitrary {pure} state
of some system $S_0$, we encode this state into the $k$-excitation state of the
sender, transfer and restore it and finally decode the restored $k$-excitation
state {of the receiver} into the state of another subsystem $R_0$. After
labeling and removing the garbage via measuring the state of the ancillae we
complete the algorithm for PST.

</details>


### [188] [Bistability of optical properties of cesium vapor due to collective interaction of alignment and orientation under strong spin exchange conditions](https://arxiv.org/abs/2509.10119)
*M. V. Petrenko,A. K. Vershovskii*

Main category: quant-ph

TL;DR: 在SERF条件下，碱金属原子气体的磁性表现出双稳态行为，可用于量子信息和密码学。


<details>
  <summary>Details</summary>
Motivation: 探索光学泵浦和SERF条件下碱金属原子气体中的集体效应，特别是自旋交换弛豫的消除以及取向和对齐之间的相互作用。

Method: 在SERF条件下，通过光学泵浦处理碱金属原子气体，并实验性地研究取向（偶极矩）和对齐（四极矩）之间的相互作用。

Result: 实验证明，在SERF条件下，取向和对齐可以共存并相互作用，导致双稳态行为和磁滞现象。

Conclusion: 碱金属原子气体在SERF条件下表现出的双稳态行为和长存储时间（可达数百秒）为量子信息和密码学中的光学密钥或存储元件提供了新的应用前景。

Abstract: Hydrogen-like alkali atoms with a single valence electron are the most common
objects in quantum optics and, at the same time, serve as essential tools of
the field. Under conditions of optical pumping, strong spin-exchange and
ultra-weak magnetic field (spin-exchange relaxation free mode, SERF), ensembles
of such atoms in the gas phase can demonstrate not only the absence of
spin-exchange relaxation, but also nonlinear collective effects. We present
experimental evidence that the alignment, i.e. the quadrupole momentum, can not
only be preserved under SERF conditions, but also coexist and interact with the
orientation, i.e. the dipole momentum. We also show that this interaction leads
to bistability: a small change in conditions can cause the medium to transition
to a different steady state, an effect characterized by hysteresis. The
combination of properties of this effect opens up a wide range of applications
as optical keys or memory elements with a storage time of hundreds of seconds
in tasks of quantum information and cryptography.

</details>


### [189] [Exact Classicalization of N-Level Quantum Systems Interacting with a Bath: Theory and Applications](https://arxiv.org/abs/2509.10131)
*Daniel Martínez-Gil,Pedro Bargueño,Salvador Miret-Artés*

Main category: quant-ph

TL;DR: 通过引入经典谐振器浴来模拟量子系统的环境相互作用，并使用复数射影空间和Langevin方法推导出包含系统和浴自由度的哈密顿方程，成功应用于双量子比特和FMO复合物系统，重现了量子可观测值。


<details>
  <summary>Details</summary>
Motivation: 对N级量子系统的动力学进行精确经典化，并模拟环境相互作用。

Method: 提出一个五步算法程序，并引入经典谐振器浴，利用复数射影空间CP(N-1)的几何和Langevin方法推导出N-1个哈密顿方程。

Result: 将该方法应用于双量子比特系统和七能级FMO复合物系统，成功重现了状态布居数、四元数布居数差和纠缠度等量子可观测值。

Conclusion: 所提出的结合了复数射影空间几何和Langevin方法的模型能够有效地模拟量子系统的环境相互作用，并重现重要的量子动力学特征。

Abstract: In this manuscript, starting from a five-step algorithmic procedure for
exactly classicalizing the dynamics of N-level quantum systems, we incorporate
a classical bath of harmonic oscillators to model environmental interactions.
Using the geometry of complex projective spaces CP(N-1) and a Langevin
formalism, we obtain N-1 Hamilton's equations which encode both the quantum
system and the bath degrees of freedom, representing a generalization of the
Caldeira-Legget model in a complex projective space. We demonstrate the
efficacy of the method by applying it to two paradigmatic systems: a two-qubit
system in CP(3) under entangling interactions, reproducing quantum observables
such as state populations, quaternionic population differences and concurrence,
and the seven-state Fenna-Matthews-Olson (FMO) complex in CP(6), reproducing
state populations in the picosecond timescale.

</details>


### [190] [Loss Behavior in Supervised Learning with Entangled States](https://arxiv.org/abs/2509.10141)
*Alexander Mandl,Johanna Barzen,Marvin Bechtold,Frank Leymann,Lavinia Stiliadou*

Main category: quant-ph

TL;DR: 高度纠缠的训练数据会限制量子机器学习模型的训练改进，尤其是在高度可表达的模型中。


<details>
  <summary>Details</summary>
Motivation: 研究高度纠缠的训练数据对量子机器学习模型训练能力的影响，以评估纠缠在监督学习中的适用性。

Method: 在高度可表达的模型中，研究了使用最大纠缠态进行训练时，损失函数值在约束邻域内可实现的改进。通过模拟参数化量子电路（PQCs）的训练来支持实验发现，并评估了非最大纠缠训练样本的有效性，以及纠缠熵作为训练能力预测因子的作用。

Result: 研究发现，对于高度可表达的模型，使用最大纠缠态进行训练会严重限制损失函数值的改进。随着PQC可表达性的增加，它对由纠缠训练数据引起的损失集中现象更为敏感。非最大纠缠在训练样本中显示出有效性，并且纠缠熵是训练能力的关键预测因子。

Conclusion: 高度纠缠的训练数据，特别是最大纠缠态，可能会阻碍量子机器学习模型的训练过程，尤其是在模型高度可表达的情况下。非最大纠缠和纠缠熵是理解和预测模型训练能力的重要因素。

Abstract: Quantum Machine Learning (QML) aims to leverage the principles of quantum
mechanics to speed up the process of solving machine learning problems or
improve the quality of solutions. Among these principles, entanglement with an
auxiliary system was shown to increase the quality of QML models in
applications such as supervised learning. Recent works focus on the information
that can be extracted from entangled training samples and their effect on the
approximation error of the trained model. However, results on the trainability
of QML models show that the training process itself is affected by various
properties of the supervised learning task. These properties include the
circuit structure of the QML model, the used cost function, and noise on the
quantum computer. To evaluate the applicability of entanglement in supervised
learning, we augment these results by investigating the effect of highly
entangled training data on the model's trainability. In this work, we show that
for highly expressive models, i.e., models capable of expressing a large number
of candidate solutions, the possible improvement of loss function values in
constrained neighborhoods during optimization is severely limited when
maximally entangled states are employed for training. Furthermore, we support
this finding experimentally by simulating training with Parameterized Quantum
Circuits (PQCs). Our findings show that as the expressivity of the PQC
increases, it becomes more susceptible to loss concentration induced by
entangled training data. Lastly, our experiments evaluate the efficacy of
non-maximal entanglement in the training samples and highlight the fundamental
role of entanglement entropy as a predictor for the trainability.

</details>


### [191] [Fluctuation-guided adaptive random compiler for Hamiltonian simulation](https://arxiv.org/abs/2509.10158)
*Yu-Xia Wu,Yun-Zhuo Fan,Dan-Bo Zhang*

Main category: quant-ph

TL;DR: 提出了一种基于波动的自适应算法，用于在量子模拟中通过自适应地更新哈密顿量项的采样概率来抑制相干误差，提高了模拟保真度。


<details>
  <summary>Details</summary>
Motivation: 随机编译协议虽然可以通过随机对哈密顿量项进行采样来减少量子模拟的电路深度，但其固定的采样分布无法适应系统动力学，从而限制了其精度。

Method: 提出了一种基于波动的自适应算法，通过自适应地更新采样概率来解决固定采样分布的问题。该算法根据哈密顿量项的波动来更新采样概率，优先对状态演化更敏感的哈密顿量项进行采样。为了减少更新采样概率所需的测量开销，可以采用经典阴影技术。

Result: 通过在离散变量、连续变量和混合变量系统中的数值模拟，证明了该方法的有效性。

Conclusion: 所提出的基于波动的自适应算法能够通过优先采样对状态演化更敏感的哈密顿量项来提高量子模拟的保真度，并且可以通过经典阴影技术来优化测量开销。

Abstract: Stochastic methods offer an effective way to suppress coherent errors in
quantum simulation. In particular, the randomized compilation protocol may
reduce circuit depth by randomly sampling Hamiltonian terms rather than
following the deterministic Trotter-Suzuki sequence. However, its fixed
sampling distribution does not adapt to the dynamics of the system, limiting
its accuracy. In this work, we propose a fluctuation-guided adaptive algorithm
that adaptively updates sampling probabilities based on fluctuations of
Hamiltonian terms to achieve higher simulation fidelity. Remarkably, the
protocol renders an intuitive physical understanding: Hamiltonian terms with
greater sensitivity to the state evolution should be prioritized during
sampling. The overload of measuring fluctuations necessary for updating the
sampling probability is affordable, and can be further largely reduced by
classical shadows. We demonstrate the effectiveness of the method with numeral
simulations across discrete-variable, continuous-variable and hybrid-variable
systems.

</details>


### [192] [Evolution of moments in atmospheric scintillation](https://arxiv.org/abs/2509.10171)
*Filippus S. Roux*

Main category: quant-ph

TL;DR: 大气湍流中光子量子态的矩演化方程被推导出来，该方程源自于包含所有时空自由度的态特征泛函的演化方程。


<details>
  <summary>Details</summary>
Motivation: 推导光子量子态在传播通过大气湍流时的矩演化方程，以简化对测量量的分析。

Method: 从态特征泛函的演化方程出发，推导出光子量子态矩的演化方程，并考虑了初始相干态的情况。

Result: 得到了光子量子态矩的演化方程，并展示了如何用这些矩来表示测量量，而无需知道精确的最终态。

Conclusion: 推导出的矩演化方程为分析光子量子态在湍流中的传播提供了有效的工具。

Abstract: Evolution equations for the moments of a photonic quantum state propagating
through atmospheric turbulence are derived. These evolution equations are
obtain from an evolution equation for the characteristic functional of the
state, incorporating all spatiotemporal degrees of freedom. The measured
quantities, such as the intensity or photon distribution, of the evolving state
can be expressed in terms of such moments without having to know the exact
final state. The case of an initial coherent state is considered as an example.

</details>


### [193] [Statistical Quantum Mechanics of the Random Permutation Sorting System (RPSS): A Self-Stabilizing True Uniform RNG](https://arxiv.org/abs/2509.10174)
*Randy Kuang*

Main category: quant-ph

TL;DR: RPSS是一个基于量子力学的新型真随机数生成器，利用排列计数和排序时间的分布收敛到均匀性。


<details>
  <summary>Details</summary>
Motivation: 提出一种基于统计量子力学的新型真随机数生成框架（RPSS），旨在实现真正的统一随机数生成。

Method: RPSS基于一对共轭可观测量——排列计数和已排序时间，通过模约简同步收敛到均匀性。利用微架构噪声、内存延迟和调度动态等系统抖动与组合复杂性相互作用，创建了一个紧凑的、自稳定的熵源（QPP-RNG）。

Result: NIST SP 800-90B框架的经验验证证实了RPSS熵收敛速度快，输出统计均匀。

Conclusion: RPSS定义了一类新的量子启发式熵引擎，能够从不可预测的系统抖动中收获随机性，并通过组合过程进行放大，为传统熵源提供了一种健壮、平台无关的替代方案。

Abstract: We present the Random Permutation Sorting System (RPSS), a novel framework
for true uniform randomness generation grounded in statistical quantum
mechanics. RPSS is built on a pair of conjugate observables, the permutation
count and the elapsed sorting time, whose heavy-tailed raw distributions
synchronously converge to uniformity through modular reduction. This
mathematically proven convergence establishes RPSS as a True Uniform Random
Number Generator (TURNG). A practical implementation, QPP-RNG, demonstrates how
intrinsic system jitter, arising from microarchitectural noise, memory latency,
and scheduling dynamics, interacts with combinatorial complexity to yield a
compact, self-stabilizing entropy source. Empirical validation under the NIST
SP 800-90B framework confirms rapid entropy convergence and statistically
uniform outputs. RPSS thus defines a new class of quantum-inspired entropy
engines, where randomness is simultaneously harvested from unpredictable system
jitter and amplified by combinatorial processes, offering a robust,
platform-independent alternative to conventional entropy sources.

</details>


### [194] [Symplectic Lattices and GKP Codes -- Simple Randomized Constructions from Cryptographic Lattices](https://arxiv.org/abs/2509.10183)
*Johannes Blömer,Yinzi Xiao,Zahra Raissi,Stanislaw Soltan*

Main category: quant-ph

TL;DR: 使用短整数解（SIS）格、环SIS（R-SIS）格和模SIS（M-SIS）格构造了新的GKP码，其最小距离约为sqrt(n/pi e)，优于现有的基于NTRU的构造。虽然新码没有用于加速解码的私钥，但提出了一种简单的解码算法，在许多参数选择下实验效果与NTRU码相当，并且使用R-SIS和M-SIS构造时，该算法的运行时间接近线性。


<details>
  <summary>Details</summary>
Motivation: 构造具有良好性质的GKP码，特别是利用格密码学中重要的SIS、R-SIS和M-SIS格，并与现有方法进行比较。

Method: 使用SIS、R-SIS和M-SIS格构造GKP码，并提出一种简单的解码算法。

Result: 构造了最小距离约为sqrt(n/pi e)的GKP码，该距离优于基于NTRU的构造。提出的简单解码算法在许多参数选择下实验效果与NTRU码相当，使用R-SIS和M-SIS构造时接近线性时间复杂度。

Conclusion: 通过使用SIS、R-SIS和M-SIS格，成功构造了具有优于现有方法最小距离的GKP码，并提供了一种高效的解码算法。

Abstract: We construct good GKP (Gottesman-Kitaev-Preskill) codes (in the sense of
Conrad, Eisert and Seifert proposed) from standard short integer solution
lattices (SIS) as well as from ring SIS and module SIS lattices, R-SIS and
M-SIS lattices, respectively. These lattice are crucial for lattice-based
cryptography. Our construction yields GKP codes with distance $\sqrt{n/\pi e}$.
This compares favorably with the NTRU-based construction by Conrad et al. that
achieves distance $\Omega(\sqrt{n/q}),$ with $n\le q^2/0.28$. Unlike their
codes, our codes do not have secret keys that can be used to speed-up the
decoding. However, we present a simple decoding algorithm that, for many
parameter choices, experimentally yields decoding results similar to the ones
for NTRU-based codes. Using the R-SIS and M-SIS construction, our simple
decoding algorithm runs in nearly linear time. Following Conrad, Eisert and
Seifert's work, our construction of GKP codes follows directly from an
explicit, randomized construction of symplectic lattices with (up to constants
$\approx 1$) minimal distance $(1/\sigma_{2n})^{1/2n}\approx \sqrt{\frac{n}{\pi
e}}$, where $\sigma_{2n}$ is the volume of the 2n-dimensional unit ball. Before
this result, Buser and Sarnak gave a non-constructive proof for the existence
of such symplectic lattices.

</details>


### [195] [Quantum kernel and HHL-based support vector machines for multi-class classification](https://arxiv.org/abs/2509.10190)
*Gabriela Pinheiro,Donovan Slabbert,Luis Kowada,Francesco Petruccione*

Main category: quant-ph

TL;DR: QSVM 在大多数情况下优于 HHL LS-SVM，但 HHL LS-SVM 在处理包含大量样本的数据集时具有更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 比较两种用于多类别分类的量子支持向量机方法（QSVM 和 HHL LS-SVM）在减少的 SDSS 数据集上的性能。

Method: 在减少的 SDSS 数据集上实现并比较了 QSVM 和 HHL LS-SVM 的一种对所有和两步分层分类方案。QSVM 包括角度编码、酉算子块和投影测量。HHL LS-SVM 涉及使用 HHL 算法求解线性方程组。

Result: QSVM 在大多数情况下优于 HHL LS-SVM。HHL LS-SVM 在某些情况下具有竞争力，但对少数类别（如 QSOs）表现不佳。QSVM 的性能会随着样本和特征数量的二次方扩展而受到影响，但可以显式表示特征。HHL LS-SVM 的扩展性几乎恒定，但代表性元素有限且对噪声敏感。

Conclusion: QSVM 在当前硬件上整体表现更好，但 HHL LS-SVM 的可扩展性使其成为未来大型数据集的潜在选择。

Abstract: We compare two quantum approaches that use support vector machines for
multi-class classification on a reduced Sloan Digital Sky Survey (SDSS)
dataset: the quantum kernel-based QSVM and the Harrow-Hassidim-Lloyd
least-squares SVM (HHL LS-SVM). Both one-vs-rest and two-step hierarchical
classification schemes were implemented. The QSVM involves angle encoding of
ten features, two unitary operator blocks consisting of rotational operator
gates, and a projective measurement that projects the final state to the zero
state. The HHL-based method involves solving a system of linear equations using
the HHL algorithm and using the solution in a support vector machine approach.
The results indicate that the QSVM outperforms HHL LS-SVM in most cases. HHL
LS-SVM performs somewhat competitively in selected cases, particularly when
isolating galaxies (majority), however, it also performs poorly in others,
especially when isolating QSOs (minority). Comparisons with classical SVMs
confirm that quantum and classical methods achieve broadly similar performance,
with classical models performing slightly ahead overall. Scaling analysis
reveals a trade-off: QSVM performance suffers from quadratic scaling with the
number of samples and features, but benefits from explicit feature
representation during training, while HHL LS-SVM scales essentially constantly,
with moderate fluctuations, but suffers from limited representative elements.
The HHL-based method is also highly noise-sensitive. These results suggest that
QSVM performs better overall and will perform better on current hardware as
well, but that the more efficient scaling of HHL LS-SVM makes it a useful
option for larger datasets with many samples, especially if we move past the
NISQ era.

</details>


### [196] [Approaching the Multiparameter Quantum Cramér-Rao Bound via Classical Correlation and Entangling Measurements](https://arxiv.org/abs/2509.10196)
*Minghao Mi,Ben Wang,Lijian Zhang*

Main category: quant-ph

TL;DR: 通过结合经典关联正交纯态和纠缠测量，提出并实验验证了一种称为局部操作与纠缠测量（LOEM）的策略，以实现多参数量子估计中的量子Cram'er-Rao界（QCRB）并达到海森堡缩放精度。


<details>
  <summary>Details</summary>
Motivation: 实现多参数量子估计的终极精度，即量子Cram'er-Rao界（QCRB），是实际应用中的关键挑战。

Method: 提出局部操作与纠缠测量（LOEM）策略，该策略结合了经典关联正交纯态和纠缠测量。在光子系统中进行了实验验证，并利用迭代相互作用展示了海森堡缩放精度。

Result: 实验上实现了LOEM策略，证明了其能够达到多参数QCRB的精度，并通过迭代相互作用实现了海森堡缩放。

Conclusion: LOEM策略在理论和实验上都证明了其能够饱和多参数QCRB，并可达到海森堡缩放精度，推动了多参数估计中量子计量学的实际应用。

Abstract: Multiparameter quantum metrology is essential for a wide range of practical
applications. However, simultaneously achieving the ultimate precision for all
parameters, as prescribed by the quantum Cram\'er-Rao bound (QCRB), remains a
significant challenge. In this work, we propose a scheme termed local operation
with entangling measurements (LOEM) strategy, which leverages classically
correlated orthogonal pure states combined with entangling measurements to
attain the multiparameter QCRB. We experimentally validate this scheme using a
quantum photonic system. Additionally, we employ iterative interactions to
demonstrate that the LOEM strategy can achieve the precision of Heisenberg
scaling. By theoretically and experimentally demonstrating the saturation of
the multiparameter QCRB with the LOEM strategy, our work advances the practical
applications of quantum metrology in multiparameter estimation.

</details>


### [197] [Bohmian Chaos and Entanglement in a Two-Qubit System](https://arxiv.org/abs/2509.10229)
*Athanasios C. Tzemos,George Contopoulos,Foivos Zanias*

Main category: quant-ph

TL;DR: Bohmian流中的临界点（Y点和X点）在具有不同纠缠度的两量子比特系统中引发混沌的作用。


<details>
  <summary>Details</summary>
Motivation: 研究Bohmian流中的临界点（Y点和X点）在两量子比特系统中的混沌起源。

Method: 分析临界点与Bohmian粒子的距离，以及混沌出现的时机，并数值研究Lyapunov特征数（LCN）如何随量子纠缠度变化。

Result: 随着纠缠度的增加，混沌轨迹的有限时间LCN收敛到其最终正值的收敛时间减小。

Conclusion: 量子纠缠度的增加会加速混沌的出现，表现为LCN收敛时间的减少。

Abstract: We study in detail the critical points of Bohmian flow, both in the inertial
frame of reference (Y-points) and in the frames centered at the moving nodal
points of the guiding wavefunction (X-points), and analyze their role in the
onset of chaos in a system of two entangled qubits. We find the distances
between these critical points and a moving Bohmian particle at varying levels
of entanglement, with particular emphasis on the times at which chaos arises.
Then, we find why some trajectories are ordered, without any chaos. Finally, we
examine numerically how the Lyapunov Characteristic Number (LCN ) depends on
the degree of quantum entanglement. Our results indicate that increasing
entanglement reduces the convergence time of the finite-time LCN of the chaotic
trajectories toward its final positive value.

</details>


### [198] [Beam-splitter-free, high-rate quantum key distribution inspired by intrinsic quantum mechanical spatial randomness of entangled photons](https://arxiv.org/abs/2509.10231)
*Ayan Kumar Nai,Gopal Prasad Sahu,Rutuj Gharate,C. M. Chandrashekar,G. K. Samanta*

Main category: quant-ph

TL;DR: 该研究提出了一种利用空间随机性进行量子密钥分发（QKD）的新方案，通过分割自发参量下转换（SPDC）的环状发射，生成两个独立的纠缠光子源（EPS），从而替代传统的易损耗、存在偏振依赖性的分束器（BS），实现了更高的密钥生成率、更低的量子比特错误率（QBER），并具备更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于分束器（BS）的量子密钥分发（QKD）协议存在光子损耗、分光比不完美和偏振依赖性等问题，限制了密钥速率、增加了量子比特错误率（QBER），并制约了其在长距离通信中的可扩展性。

Method: 提出了一种基于空间随机性的QKD方案，通过分割SPDC产生的环状光，生成两个独立的EPS。这两个EPS能够分别提供H/V和D/A测量，利用了SPDC内在的量子随机性来模拟传统方案中BS的功能。实验上通过将环状SPDC发射分割成四个部分来实现。

Result: 该方案实现了6.4倍的筛选密钥率提升，持续降低了QBER，并实现了逻辑比特0和1之间接近理想的编码平衡。此外，研究还提出可以通过利用波长复用技术避免使用四个空间通道，从而生成两个不同波长对的EPS。

Conclusion: 利用SPDC内在的空间/光谱随机性可以实现鲁棒、无偏、高码率、低QBER的QKD，为下一代量子网络提供了可扩展的解决方案。

Abstract: Quantum key distribution (QKD) using entangled photon sources (EPS) is a
cornerstone of secure communication. Despite rapid advances in QKD,
conventional protocols still employ beam splitters (BSs) for passive random
basis selection. However, BSs intrinsically suffer from photon loss, imperfect
splitting ratios, and polarization dependence, limiting the key rate,
increasing the quantum bit error rate (QBER), and constraining scalability,
particularly over long distances. By contrast, EPSs based on spontaneous
parametric down-conversion (SPDC) intrinsically exhibit quantum randomness in
spatial and spectral degrees of freedom, offering a natural replacement for BSs
in basis selection. Here, we demonstrate a proof-of-concept
spatial-randomness-based QKD scheme in which the annular SPDC emission ring is
divided into four sections, effectively generating two independent EPSs. pair
photons from these sources, distributed to Alice and Bob, enable H/V and D/A
measurements. The quantum-random pair generation inherently mimics the
stochastic basis choice otherwise performed by a BS. Experimentally, our scheme
achieves a 6.4-fold enhancement in sifted key rate, a consistently reduced
QBER, and a near-ideal encoding balance between logical bits 0 and 1.
Furthermore, the need for four spatial channels can be avoided by employing
wavelength demultiplexing to generate two EPSs at distinct wavelength pairs.
Harnessing intrinsic spatial/spectral randomness thus enables robust,
bias-free, high-rate, and low-QBER QKD, offering a scalable pathway for
next-generation quantum networks.

</details>


### [199] [Tunable Magnetic Order in Chiral Coupled Spin Chains](https://arxiv.org/abs/2509.10286)
*Rafael D. Soares,J. M. Viana Parente Lopes,Hugo Terças*

Main category: quant-ph

TL;DR: 该论文研究了两个自旋链通过手征相互作用不对称耦合到XX链的基态相图，并识别了分离不同磁有序相的关键线。


<details>
  <summary>Details</summary>
Motivation: 研究两个自旋链通过手征相互作用不对称耦合到XX链的基态相图，识别临界线，并分析相互作用角度和耦合强度对相变和磁有序行为的影响。

Method: 通过纠缠谱识别临界线，并分析了相互作用角度和耦合强度对相变和磁有序行为的影响。

Result: 发现相互作用角度可以移动或完全抑制相变；耦合强度增加会导致量子相变，形成两种面内反铁磁条纹；向量自旋手性随着角度的变化而出现。

Conclusion: 手征相互作用诱导了非平凡的有限向量自旋手性，并表明向量自旋手性在非零和π/2的角度下出现，而在这些角度下有利于共线序。

Abstract: We obtain the ground-state phase diagram of two spin chains consisting in a
set two-level systems asymmetrically coupled to an XX chain through a chiral
interaction. The interaction is parametrized by its magnitude and an angle
defined by the relative orientation of the spins in different chains. From the
entanglement spectrum, we identify the critical lines separating distinct
magnetically ordered phases, with the interaction angle able to shift or fully
suppress the transition. By increasing the coupling strength, the systems is
driven through a quantum phase transition, leading to the formation of two
types of in-plane antiferromagnetic stripes. The interaction strength sets
stripe formation, while the angle controls the spins orientations. The chiral
interaction also induces a non-trivial finite vector spin chirality with
opposite orientation on the chains. We show that the vector spin chirality
emerges smoothly from the decoupled limit and occurs for angles different from
zero and $\pi/2$, where collinear order is favored instead.

</details>


### [200] [Confined few-particle systems beyond mean-field theory adopting Gaussian-type orbitals and Morse interparticle interaction](https://arxiv.org/abs/2509.10347)
*Matee ur Rehman,Paul Winter,Fabio Revuelta,Alejandro Saenz*

Main category: quant-ph

TL;DR: A quantum-chemistry inspired approach using Cartesian Gaussians is investigated for beyond mean-field treatments of multiple atoms/molecules in arbitrary trap geometries, showing promising results compared to exact diagonalizations.


<details>
  <summary>Details</summary>
Motivation: Recent breakthroughs in optical tweezers allow trapping arbitrary numbers of neutral atoms/molecules and creating variable geometries, necessitating novel full-dimensional beyond mean-field treatments for such complex systems.

Method: The study investigates the suitability of a quantum-chemistry inspired approach using Cartesian Gaussians as basis functions. It implements six-dimensional integrals for a realistic atom-atom interaction modeled by a Morse potential and assesses the performance, correctness, and efficiency by comparing with quasi-exact reference results from full configuration-interaction calculations for two atoms in an isotropic harmonic trap.

Result: The implemented approach was assessed by comparing its calculations for two atoms in an isotropic harmonic trap with quasi-exact reference results from full configuration-interaction calculations.

Conclusion: The paper investigates the suitability of a quantum-chemistry inspired approach for analyzing systems with multiple atoms/molecules in arbitrary trap configurations, a necessary development given recent advancements in optical tweezers technology.

Abstract: Recent advancements in optical tweezers enable the trapping of arbitrary
numbers of neutral atoms and molecules, even arrays of tweezers with variable
geometry can be realized. These fascinating breakthroughs require novel
full-dimensional beyond mean-field treatments for systems with more than two
confined particles spread over traps that are arranged arbitrarily in space. In
this work, the suitability of a quantum-chemistry inspired approach adopting
Cartesian Gaussians as basis functions is investigated. For this purpose, the
six-dimensional integrals associated with a realistic atom-atom interaction
described by a Morse model potential were implemented. The performance,
correctness and efficiency of the implementation is assessed by comparing full
configuration-interaction calculations (exact diagonalizations) for two atoms
in an isotropic harmonic trap with quasi-exact reference results.

</details>


### [201] [Most incompatible measurements and sum-of-squares optimisation](https://arxiv.org/abs/2509.10381)
*Sébastien Designolle*

Main category: quant-ph

TL;DR: 量子测量不兼容性是量子理论的基石，并且是一种有用的资源。对于有限维系统，量化这种资源并建立对所有测量都有效的通用界限是一个长期存在的问题。本研究提出了分析性的通用父测量，可以获得优于现有技术的界限。特别是，我们证明了在相关稳健性下，反交换可观测量集会产生最不兼容的二分测量。我们还将这种通用父测量的构造形式化为平方和优化框架，并通过初步的数值结果证明了该方法的有效性，这些结果在我们的分析值的基础上进行了改进。所有研究结果都可直接应用于演示真正的高维驾驶，即以单方面设备无关的方式认证量子系统的维度。


<details>
  <summary>Details</summary>
Motivation: 量化量子测量不兼容性资源并建立对所有测量都有效的通用界限。

Method: 提出分析性的通用父测量，并将其构建形式化为平方和优化框架。

Result: 分析性的通用父测量给出了优于现有技术的界限；反交换可观测量集产生最不兼容的二分测量；平方和优化方法在数值上得到了改进。

Conclusion: 研究结果可直接应用于演示真正的高维驾驶，以单方面设备无关的方式认证量子系统的维度。

Abstract: Measurement incompatibility, or joint measurability, is a cornerstone of
quantum theory and a useful resource. For finite-dimensional systems,
quantifying this resource and establishing universal bounds valid for all
measurements is a long-standing problem. In this work, we exhibit analytical
universal parent measurements giving access to bounds that beat the state of
the art. In particular, we can show that, for relevant robustnesses, sets of
anticommuting observables give rise to the most incompatible dichotomic
measurements. We also formalise the construction of such universal parent
measurements in the framework of sum-of-squares optimisation and obtain
preliminary numerical results demonstrating the power of the method by
improving on our own analytical values. All results find direct application for
demonstrating genuine high-dimensional steering, that is, certifying the
dimensionality of a quantum system in a one-sided device-independent manner.

</details>


### [202] [Optimizing Inter-chip Coupler Link Placement for Modular and Chiplet Quantum Systems](https://arxiv.org/abs/2509.10409)
*Zefan Du,Pedro Chumpitaz Flores,Wenqi Wei,Juntao Chen,Kaixun Hua,Ying Mao*

Main category: quant-ph

TL;DR: 分布式量子计算通过互联多个处理器来解决量子计算的扩展性和可靠性挑战，InterPlace框架通过分析噪声和错误率来优化电路划分和量子比特映射，提高了保真度并减少了SWAP开销。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式量子计算方法在处理有限的量子比特数量、多样的硬件拓扑以及动态噪声和错误率方面存在挑战，尤其是在电路切割和量子比特映射方面研究不足，而这对于互联多个量子处理器至关重要。

Method: InterPlace框架通过分析量子比特的噪声和错误率，构建虚拟系统拓扑，以指导电路划分和分布式量子比特映射，从而最小化SWAP开销并提高保真度。该框架使用IBM Qiskit实现。

Result: 与现有技术相比，InterPlace在保真度方面取得了高达53.0%的提升，并且将片上SWAP操作和芯片间操作相结合的开销减少了高达33.3%。

Conclusion: InterPlace框架在真实量子硬件拓扑上的广泛评估证明了其在分布式量子计算中的可扩展性和有效性，能够显著提高量子电路的保真度并降低执行开销。

Abstract: Quantum computing offers unparalleled computational capabilities but faces
significant challenges, including limited qubit counts, diverse hardware
topologies, and dynamic noise and error rates, which hinder scalability and
reliability. Distributed quantum computing, particularly chip-to-chip
connections, has emerged as a solution by interconnecting multiple processors
to collaboratively execute large circuits. While hardware advancements, such as
IBM's Quantum Flamingo, focus on improving inter-chip fidelity, limited
research addresses efficient circuit cutting and qubit mapping in distributed
systems. This project introduces InterPlace, a self-adaptive, hardware-aware
framework for chip-to-chip distributed quantum systems. InterPlace analyzes
qubit noise and error rates to construct a virtual system topology, guiding
circuit partitioning and distributed qubit mapping to minimize SWAP overhead
and enhance fidelity. Implemented with IBM Qiskit and compared with the
state-of-the-art, InterPlace achieves up to a 53.0\% improvement in fidelity
and reduces the combination of on-chip SWAPs and inter-chip operations by as
much as 33.3\%, demonstrating scalability and effectiveness in extensive
evaluations on real quantum hardware topologies.

</details>


### [203] [Provable avoidance of barren plateaus for GM-QAOA](https://arxiv.org/abs/2509.10424)
*Boris Tsvelikhovskiy,Matthew Nuyten,Bojko N. Bakalov*

Main category: quant-ph

TL;DR: GM-QAOA的动力学李代数（DLA）被分类，其李代数同构于 SU(r)⊕U(1)^2 或 SU(r)⊕U(1)。


<details>
  <summary>Details</summary>
Motivation: 研究GM-QAOA的动力学李代数（DLA）的结构，并将其与QAOA的其他变体进行比较，以了解其在优化问题中的性质。

Method: 通过数学分析，推导出GM-QAOA的DLA结构，并将其与$\
in_{r} \\	ext{oplus} \\text{u}_{1}^{\\oplus 2}$或$\
in_{r} \\text{oplus} \\text{u}_{1}$进行同构比较。此外，还推导了GM-QAOA损失函数的方差公式，并证明了在一定条件下可以避免Barren Plateaus。

Result: GM-QAOA的DLA被分类为$\
in_{r} \\text{oplus} \\text{u}_{1}^{\\oplus 2}$或$\
in_{r} \\text{oplus} \\text{u}_{1}$。GM-QAOA的DLA拥有最大的交换子，对应于最大数量的守恒量。损失函数的方差公式被导出，并且证明了GM-QAOA可以避免Barren Plateaus。

Conclusion: GM-QAOA在动力学李代数结构、守恒量和避免Barren Plateaus方面具有优越性，这表明它在量子近似优化算法中具有潜力。

Abstract: We analyze the dynamical Lie algebras (DLAs) associated with the Grover-mixer
variant of the Quantum Approximate Optimization Algorithm (GM-QAOA). When the
initial state is the uniform superposition of computational basis states, we
show that the corresponding DLA is isomorphic to either $\mathfrak{su}_{r}
\oplus \mathfrak{u}_{1}^{\oplus 2}$ or $\mathfrak{su}_{r} \oplus
\mathfrak{u}_{1}$, where \(r\) denotes the number of distinct values of the
objective function. We also establish an analogous classification for other
choices of initial states and Grover-type mixers.
  Furthermore, we prove that the DLA of GM-QAOA has the largest possible
commutant among all QAOA variants initialized with the same state
$|\xi\rangle$, corresponding physically to the maximal set of conserved
quantities. In addition, we derive an explicit formula for the variance of the
GM-QAOA loss function in terms of the objective function values, and we show
that, for a broad class of optimization problems, GM-QAOA with sufficiently
many layers avoids barren plateaus.

</details>


### [204] [Quantum algorithms based on quantum trajectories](https://arxiv.org/abs/2509.10425)
*Evan Borras,Milad Marvian*

Main category: quant-ph

TL;DR: 量子模拟是量子计算的一个关键应用，尤其是开放量子系统的模拟。现有算法的复杂度为 O(T polylog(T/ε))。


<details>
  <summary>Details</summary>
Motivation: 现有模拟开放量子系统（特别是遵循 Lindblad 主方程的系统）的算法复杂度较高，并且其最优查询复杂度仍是未解之谜。

Method: 提出了一种基于量子轨迹的新型量子算法。

Result: 该算法实现了 O(T + log(1/ε)) 的加性复杂度，这是对一类 Lindbladian 模拟的可达到的最优复杂度。

Conclusion: 通过基于量子轨迹的新型量子算法，为一类 Lindbladian 模拟实现了 O(T + log(1/ε)) 的加性最优复杂度。

Abstract: Quantum simulation has emerged as a key application of quantum computing,
with significant progress made in algorithms for simulating both closed and
open quantum systems. The simulation of open quantum systems, particularly
those governed by the Lindblad master equation, has received attention recently
with the current state-of-the-art algorithms having an input model query
complexity of $O(T \mathrm{polylog}(T/\epsilon))$, where $T$ and $\epsilon$ are
the requested time and precision of the simulation respectively. For the
Hamiltonian simulation problem it has been show that the optimal Hamiltonian
query complexity is $O(T + \log(1/\epsilon))$, additive in nature between the
two parameter, but for Lindbladian simulation this question remains open. In
this work we show that the additive complexity of $O(T + \log(1/\epsilon))$ is
reachable for the simulation of a large class of Lindbladian by constructing a
novel quantum algorithm based on quantum trajectories.

</details>


### [205] [Global vs. Local Discrimination of Locally Implementable Multipartite Unitaries](https://arxiv.org/abs/2509.10430)
*Satyaki Manna,Sneha Suresh,Anandamay Das Bhowmik,Debashis Saha*

Main category: quant-ph

TL;DR: 在局部操作和经典通信（LOCC）以及全局操作下，我们研究了可局部实现的量子比特酉变换的单次可辨别性。我们提出了区分酉变换的两种策略：自适应策略（根据其他子系统的测量结果选择探测状态）和受限策略（探测状态固定）。


<details>
  <summary>Details</summary>
Motivation: 研究局部操作和经典通信（LOCC）以及全局操作下，可局部实现的量子比特酉变换的单次可辨别性。

Method: 根据探测状态的选择和演化后的状态的测量，将LOCC和全局可辨别性分为自适应策略和受限策略两类。

Result: 在二分情形下，我们发现了三个令人惊讶的特征：（1）某些酉变换对在受限策略下是全局可辨别的，但在LOCC下不可辨别，即使采用自适应策略。（2）存在四个酉变换的集合，它们可以通过LOCC进行辨别，但在受限策略下仍然是全局不可辨别的。（3）在自适应策略下，使用可分离态进行探测时，某些酉变换集合是全局不可辨别的，但通过LOCC则可以辨别。

Conclusion: 该研究在二分情形下揭示了酉变换可辨别性的新结构限制。

Abstract: We study single-shot distinguishability of locally implementable multipartite
unitaries under Local Operations and Classical Communication (LOCC) and global
operations. As unitary discrimination depends on both the choice of probing
states and the measurements on the evolved states, we classify LOCC and global
distinguishability into two categories: adaptive strategies, where probing
states are chosen based on measurement outcomes from other subsystems, and
restricted strategies, where probing states remain fixed. Our findings uncover
three surprising features in the bipartite setting and establish new structural
limits for unitary discrimination: (i) Certain pairs of unitaries are globally
distinguishable with restricted strategies but indistinguishable under LOCC,
even with adaptive strategies. (ii) There exist sets of four unitaries that are
distinguishable via LOCC, yet remain globally indistinguishable with restricted
strategies. (iii) Some sets of unitaries are globally indistinguishable under
adaptive strategies, when probed with separable states, but become
distinguishable via LOCC.

</details>


### [206] [Maximally $ψ-$epistemic models cannot explain gambling with two qubits](https://arxiv.org/abs/2509.10437)
*Sagnik Ray,Anubhav Chaturvedi,Debashis Saha*

Main category: quant-ph

TL;DR: 该论文提出了一个名为“量子赌博”的新概念，并利用它来排除量子力学的一些解释。


<details>
  <summary>Details</summary>
Motivation: 为了排除量子力学的某些最大 $\psi-$ epistemic 解释，即量子态的不可区分性完全由其在本体状态上的分布的认识重叠来解释。

Method: 引入了一个新的“量子赌博”游戏，通过考虑两个量子态和三种可能的答案来区分它们，从而扩展了认识重叠的标准概念。

Result: 使用两个纯态及其等量混合，我们提出了一个实验上可行的否定证明，排除了最大 $\psi-$ epistemic 模型。结果表明，量子比特态在量子重叠和认识重叠之间实现了最大的差异。

Conclusion: 量子态的不可区分性不能完全由其在本体状态上的分布的认识重叠来解释，量子比特态在量子重叠和认识重叠之间实现了最大的差异。

Abstract: We investigate the minimal proof for ruling out maximally $\psi-$epistemic
interpretations of quantum theory, in which the indistinguishable nature of two
quantum states is fully explained by the epistemic overlap of their
corresponding distributions over ontic states. To this end, we extend the
standard notion of epistemic overlap by considering a penalized
distinguishability game involving two states and three possible answers, named
as Quantum Gambling. In this context, using only two pure states and their
equal mixture, we present an experimentally robust no-go theorem for maximally
$\psi-$epistemic models, showing that qubit states achieve the maximal
difference between quantum and epistemic overlaps.

</details>


### [207] [Wafer-Scale Squeezed-Light Chips](https://arxiv.org/abs/2509.10445)
*Shuai Liu,Kailu Zhou,Yuheng Zhang,Abdulkarim Hariri,Nicholas Reynolds,Bo-Han Wu,Zheshen Zhang*

Main category: quant-ph

TL;DR: 本文报道了在光子集成芯片（PIC）上实现大规模、可重复生产的挤压光子源。


<details>
  <summary>Details</summary>
Motivation: 可扩展的连续可变（CV）量子信息处理需要PIC中的挤压光子产生，以抑制低于散弹噪声极限的量子涨落，从而实现量子增强传感和CV量子信息处理。

Method: 利用CMOS兼容的氮化硅（Si3N4）PIC平台，通过共集成超低损耗、强过耦合高Q值微谐振器、级联泵浦抑制滤波器和低损耗反向锥形边耦合器，实现了双模挤压真空态的晶圆级制造、产生和表征。

Result: 在4英寸晶圆上，8个芯片实现了2.9-3.1 dB的直接测量正交压缩，变化小于0.2 dB，显示出优异的均匀性。

Conclusion: 本研究为非经典光在集成光子学中的可重复、晶圆级产生提供了一条途径，并为可扩展的CV处理器、多路纠缠源和量子增强传感奠定了基础。

Abstract: Squeezed-light generation in photonic integrated circuits (PICs) is essential
for scalable continuous-variable (CV) quantum information processing. By
suppressing quantum fluctuations below the shot-noise limit, squeezed states
enable quantum-enhanced sensing and serve as a standard resource for CV quantum
information processing. While chip-level squeezed-light sources have been
demonstrated, extending this capability to the wafer level with reproducible
strong squeezing to bolster large-scale quantum-enhanced sensing and
information processing has been hindered by squeezed light's extreme
susceptibility to device imperfections. Here, we report wafer-scale
fabrication, generation, and characterization of two-mode squeezed-vacuum
states on a fully complementary metal-oxide-semiconductor (CMOS)-compatible
silicon nitride (Si$_3$N$_4$) PIC platform. Across a 4-inch wafer, 8 dies yield
2.9-3.1 dB directly measured quadrature squeezing with $< 0.2$ dB variation,
demonstrating excellent uniformity. This performance is enabled by
co-integrating ultralow-loss, strongly overcoupled high-$Q$ microresonators,
cascaded pump-rejection filters, and low-loss inverse-tapered edge couplers.
The measurements agree with a first-principles theoretical model parameterized
solely by independently extracted device parameters and experimental settings.
The measured squeezing level can be further improved by enhancing the
efficiencies of off-chip detection and chip-to-fiber coupling. These results
establish a reproducible, wafer-scale route to nonclassical-light generation in
integrated photonics and lay the groundwork for scalable CV processors,
multiplexed entanglement sources, and quantum-enhanced sensing.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [208] [Machine-learning competition to grade EEG background patterns in newborns with hypoxic-ischaemic encephalopathy](https://arxiv.org/abs/2509.09695)
*Fabio Magarelli,Geraldine B. Boylan,Saeed Montazeri,Feargal O'Sullivan,Dominic Lightbody,Minoo Ashoori,Tamara Skoric Ceranic,John M. O'Toole*

Main category: eess.SP

TL;DR: 机器学习竞赛通过提供数据集、促进模型比较和众包专业知识来改进新生儿脑功能监测中的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 需要高质量、标注过的新生儿脑电图 (EEG) 数据来开发准确可靠的机器学习 (ML) 模型，但此类数据供应不足。

Method: 创建了一个包含 353 小时新生儿脑电图数据的回顾性数据集，并将其分为训练、测试和验证集。然后，组织了一场机器学习竞赛，让研究人员开发用于对 EEG 背景模式严重程度进行分类的模型。对排名前四的模型在单独的保留验证集上进行了离线评估。

Result: 虽然基于特征的模型在测试集上排名第一，但深度学习模型在验证集上的泛化能力更好。所有模型在验证集上的表现均显著下降。这强调了在机器学习研究中，使用新生儿脑电图进行模型泛化的挑战，并强调了保留验证数据集的必要性。

Conclusion: 机器学习竞赛有助于促进协作研究环境，并加速临床决策支持工具的开发。然而，模型泛化仍然是一个挑战，需要在大而多样化的数据集上进行训练，并使用保留验证集进行评估。

Abstract: Machine learning (ML) has the potential to support and improve expert
performance in monitoring the brain function of at-risk newborns. Developing
accurate and reliable ML models depends on access to high-quality, annotated
data, a resource in short supply. ML competitions address this need by
providing researchers access to expertly annotated datasets, fostering shared
learning through direct model comparisons, and leveraging the benefits of
crowdsourcing diverse expertise. We compiled a retrospective dataset containing
353 hours of EEG from 102 individual newborns from a multi-centre study. The
data was fully anonymised and divided into training, testing, and held-out
validation datasets. EEGs were graded for the severity of abnormal background
patterns. Next, we created a web-based competition platform and hosted a
machine learning competition to develop ML models for classifying the severity
of EEG background patterns in newborns. After the competition closed, the top 4
performing models were evaluated offline on a separate held-out validation
dataset. Although a feature-based model ranked first on the testing dataset,
deep learning models generalised better on the validation sets. All methods had
a significant decline in validation performance compared to the testing
performance. This highlights the challenges for model generalisation on unseen
data, emphasising the need for held-out validation datasets in ML studies with
neonatal EEG. The study underscores the importance of training ML models on
large and diverse datasets to ensure robust generalisation. The competition's
outcome demonstrates the potential for open-access data and collaborative ML
development to foster a collaborative research environment and expedite the
development of clinical decision-support tools for neonatal neuromonitoring.

</details>


### [209] [Locally Permuted Low Rank Column-wise Sensing](https://arxiv.org/abs/2509.09820)
*Ahmed Ali Abbasi,Namrata Vaswani*

Main category: eess.SP

TL;DR: 本文提出了解决带扰动列传感问题的交替梯度下降和最小化（AltGDMin）算法的泛化版本，并开发了一种交替最小化（AltMin）方法，通过仿真实验证明了PermutedAltGDmin比Permuted-AltMin收敛更快。


<details>
  <summary>Details</summary>
Motivation: 解决低秩列传感问题（LRCS）中观测数据部分被扰动（打乱/置换/未标记）的情况，即置换LRCS问题。

Method: 提出了一种新颖的交替梯度下降和最小化（AltGDMin）算法的泛化版本来解决置换LRCS问题，并开发了一种交替最小化（AltMin）方法。

Result: 仿真实验表明，两种方法都能收敛，但PermutedAltGDmin比Permuted-AltMin收敛速度快得多。

Conclusion: 提出的PermutedAltGDmin算法在解决置换LRCS问题上比Permuted-AltMin更有效率。

Abstract: We precisely formulate, and provide a solution for, the Low Rank Columnwise
Sensing (LRCS) problem when some of the observed data is
scrambled/permuted/unlabeled. This problem, which we refer to as permuted LRCS,
lies at the intersection of two distinct topics of recent research: unlabeled
sensing and low rank column-wise (matrix) sensing. We introduce a novel
generalization of the recently developed Alternating Gradient Descent and
Minimization (AltGDMin) algorithm to solve this problem. We also develop an
alternating minimization (AltMin) solution. We show, using simulation
experiments, that both converge but PermutedAltGDmin is much faster than
Permuted-AltMin.

</details>


### [210] [Real-Time Remote Tracking with State-Dependent Detection Probability: A POMDP Framework](https://arxiv.org/abs/2509.09837)
*Jiapei Tian,Abolfazl Zakeri,Marian Codreanu,David Gundlegård*

Main category: eess.SP

TL;DR: 该研究提出了一种基于部分可观测马尔可夫决策过程（POMDP）的实时跟踪系统，利用两个异构传感器监控二元马尔可夫信源，通过优化传感器调度和命令策略来最小化失真和传输成本的总和，并验证了其优于基准策略。


<details>
  <summary>Details</summary>
Motivation: 在实时跟踪系统中，需要考虑传感器状态依赖的检测精度、传感器故障以及信道传输错误等因素，以优化数据收集和传输策略，从而最小化系统失真和传输成本。

Method: 将问题建模为部分可观测马尔可夫决策过程（POMDP），并将其转换为信念-MDP。通过将连续的信念空间离散化并量化信念值，将问题转化为有限状态的MDP问题，并使用相对价值迭代算法（RVIA）求解。

Result: 仿真结果表明，所提出的策略显著优于基准策略，并强调了在传感器调度中考虑状态依赖的传感可靠性的重要性。

Conclusion: 所提出的基于POMDP的优化框架能够有效地处理带噪声和传感器故障的实时跟踪问题，并通过状态依赖的传感器调度和命令策略，在最小化失真和传输成本方面取得了优于现有方法的性能。

Abstract: We consider a real-time tracking system where a binary Markov source is
monitored by two heterogeneous sensors. Upon command, sensors send their
observations to a remote sink over error-prone channels. We assume each sensor
exhibits state-dependent detection accuracy and may occasionally fail to detect
the source state. At most one sensor is scheduled for sampling at each time
slot. We assess the effectiveness of data communication using a generic
distortion function that captures the end application's objective. We derive
optimal sink-side command policies to minimize the weighted sum of distortion
and transmission costs. To model the uncertainty introduced by sensing failures
(of the sensors) and packet loss, we formulate the problem as a partially
observable Markov decision process (POMDP), which we then cast into a
belief-MDP. Since the belief evolves continuously, the belief space is
discretized into a finite grid and the belief value is quantized to the nearest
grid point after each update. This formulation leads to a finite-state MDP
problem, which is solved using the relative value iteration algorithm (RVIA).
Simulation results demonstrate that the proposed policy significantly
outperforms benchmark strategies and highlights the importance of accounting
for state-dependent sensing reliability in sensor scheduling.

</details>


### [211] [Field evaluation of a wearable instrumented headband designed for measuring head kinematics](https://arxiv.org/abs/2509.09842)
*Anu Tripathi,Yang Wan,Zhiren Zhu,Furkan Camci,Sheila Turcsanyi,Jeneel Pravin Kachhadiya,Mauricio Araiza Canizales,Alison Brooks,Haneesh Kesari,Joseph Andrews,Traci Snedden,Peter Ferrazzano,Christian Franck,Rika Wright Carlsen*

Main category: eess.SP

TL;DR: 本文评估了一种用于测量足球顶球运动中头部运动学数据的仪器化头带在实际比赛中的性能。


<details>
  <summary>Details</summary>
Motivation: 研究足球顶球运动与轻度创伤性脑损伤（mTBI）风险之间的关系，需要准确测量头部运动学数据。本文旨在评估先前开发的仪器化头带在实际比赛环境下的测量能力。

Method: 在真实比赛场景（界外球、球门球、角球）中，让一名真人受试者进行足球顶球运动，并佩戴仪器化头带。将头带测得的头部角速度、角加速度和平移加速度的时间历程和峰值与同时使用的仪器化口含器（一种公认的测量方法）的测量结果进行比较。

Result: 头带和口含器在测量结果上的时间历程一致性（CORA分数）表现不一，角速度和线加速度的吻合度较高（分别为0.79 ± 0.08和0.73 ± 0.05），而角加速度的吻合度较低（0.67 ± 0.06）。Bland-Altman分析显示，在峰值运动学测量方面，头带测得的角速度比口含器高40.9%，线加速度高16.6%，角加速度低14.1%。

Conclusion: 在实际比赛环境中，该仪器化头带在某些运动学测量和特定冲击条件下与口含器测量结果具有可接受的一致性。未来的研究应致力于改进头带在所有运动学测量方面的性能。

Abstract: Purpose: To study the relationship between soccer heading and the risk of
mild traumatic brain injury (mTBI), we previously developed an instrumented
headband and data processing scheme to measure the angular head kinematics of
soccer headers. Laboratory evaluation of the headband on an anthropomorphic
test device showed good agreement with a reference sensor for soccer ball
impacts to the front of the head. In this study, we evaluate the headband in
measuring the full head kinematics of soccer headers in the field. Methods: The
headband was evaluated under typical soccer heading scenarios (throw-ins,
goal-kicks, and corner-kicks) on a human subject. The measured time history and
peak kinematics from the headband were compared with those from an instrumented
mouthpiece, which is a widely accepted method for measuring head kinematics in
the field. Results: The time history agreement (CORA scores) between the
headband and the mouthpiece ranged from 'fair' to 'excellent', with the highest
agreement for angular velocities (0.79 \pm 0.08) and translational
accelerations (0.73 \pm 0.05) and lowest for angular accelerations (0.67 \pm
0.06). A Bland-Altman analysis of the peak kinematics from the headband and
mouthpiece found the mean bias to be 40.9% (of the maximum mouthpiece reading)
for the angular velocity, 16.6% for the translational acceleration, and-14.1%
for the angular acceleration. Conclusion: The field evaluation of the
instrumented headband showed reasonable agreement with the mouthpiece for some
kinematic measures and impact conditions. Future work should focus on improving
the headband performance across all kinematic measures.

</details>


### [212] [A General Nonlinear Model for Arbitrary Modulation Formats in the Presence of Inter-Channel Simulated Raman Scattering](https://arxiv.org/abs/2509.10009)
*Zhiwei Liang,Bin Chen,Jiwei Xu,Yi Lei,Qingqing Hu,Fan Zhang,Gabriele Liga*

Main category: eess.SP

TL;DR: 该模型通过考虑了信道间的拉曼散射，可以精确预测高色散条件下的双偏振四维调制格式和概率整形星座。


<details>
  <summary>Details</summary>
Motivation: 为了能更精确地预测高色散条件下的双偏振四维调制格式和概率整形星座，需要扩展四维非线性模型以包含信道间的受激拉曼散射。

Method: 提出了一种考虑了信道间受激拉曼散射的四维非线性模型，并采用该模型对双偏振四维调制格式和概率整形星座进行了预测。

Result: 模型可以精确预测高色散条件下的双偏振四维调制格式和概率整形星座。通过与分裂步长傅里叶方法和增强高斯噪声模型进行比较，验证了该模型的准确性。

Conclusion: 所提出的模型能够准确地预测高色散条件下的双偏振四维调制格式和概率整形星座，并且通过与现有方法进行比较，验证了其有效性。

Abstract: The four-dimensional nonlinear model is extended to include the inter-channel
stimulated Raman scattering, enabling accurate prediction of dual-polarization
four-dimensional modulation formats and probabilistically shaped constellations
in high-dispersion regimes. The proposed model is validated via comparisons
with the split-step Fourier method and enhanced Gaussian noise model.

</details>


### [213] [Uplink RSMA for Pinching-Antenna Systems](https://arxiv.org/abs/2509.10076)
*Apostolos A. Tegos,Yue Xiao,Sotiris A. Tegos,George K. Karagiannidis,Panagiotis D. Diamantoulakis*

Main category: eess.SP

TL;DR:  PASs通过在房间内使用的波导激活天线，以减少收发器之间的距离。RSMA方案优于NOMA PAS。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络需要适应不断变化的环境并满足新兴应用对可靠、高容量通信日益增长的需求。克服传统技术的限制，例如固定的天线位置，对于实现这一目标至关重要，因为它可以减轻路径损耗对接收信号的影响，并创建强大的视线链路，从而提高系统性能。

Method: 研究了一个双用户、双 the-pinching-antenna 上行链路 PAS，其中发射器使用速率分裂来创建一个比非正交多址接入 (NOMA) 更具弹性的框架。

Result: 推导了该网络的断点概率的封闭式表达式。数值结果验证了这些表达式，证明了所提出的速率分裂多址接入 (RSMA) 方案优于 NOMA PAS。

Conclusion: 所提出的 RSMA 方案在双用户、双 the-pinching-antenna 上行链路 PAS 中优于 NOMA PAS。

Abstract: One of the key goals of next-generation wireless networks is to adapt to
changing conditions and meet the growing demand for reliable, high-capacity
communications from emerging applications. Overcoming the limitations of
conventional technologies, such as fixed antenna positions, is essential to
achieving this objective because it mitigates the impact of path loss on the
received signal and creates strong line-of-sight links, enhancing system
performance. With this in mind, the newly proposed pinching antenna systems
(PASs) are a promising solution for indoor applications because they can
activate antennas across a waveguide deployed in a room, thus reducing the
distance between the transmitter and receiver. In this paper, we investigate a
two-user, two-pinching-antenna uplink PAS, in which the transmitters use rate
splitting to create a more resilient framework than non-orthogonal multiple
access (NOMA). For this network, we derive novel closed-form expressions for
the outage probability. Numerical results validate these expressions, proving
that the proposed rate-splitting multiple access (RSMA) scheme outperforms NOMA
PAS.

</details>


### [214] [FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification](https://arxiv.org/abs/2509.10082)
*Weitao Tang,Johann Vargas-Calixto,Nasim Katebi,Nhi Tran,Sharmony B. Kelly,Gari D. Clifford,Robert Galinsky,Faezeh Marzbanrad*

Main category: eess.SP

TL;DR: FetalSleepNet是首个用于胎儿脑电图（EEG）睡眠分期的人工智能框架，通过迁移学习和域适应策略，实现了86.6%的准确率，并能用于更广泛的临床监测。 


<details>
  <summary>Details</summary>
Motivation: 准确的睡眠分期有助于早期发现与妊娠并发症（如缺氧或宫内生长受限）相关的异常大脑成熟。

Method: 使用迁移学习将为成年人设计的深度神经网络应用于绵羊胎儿脑电图，并结合基于频谱均衡的域适应策略进行训练。

Result: 与基线模型相比，经过微调和频谱均衡的FetalSleepNet在准确率（86.6%）和宏F1分数（62.5）方面表现更优。

Conclusion: FetalSleepNet是首个专门为胎儿脑电图自动睡眠分期设计的深度学习框架，其轻量化设计适用于低功耗、实时和可穿戴的胎儿监测系统，并可作为标签引擎以支持在临床上更易获取的信号（如多普勒超声或心电图）的训练。

Abstract: Introduction: This study presents FetalSleepNet, the first published deep
learning approach to classifying sleep states from the ovine
electroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and
laborious to interpret consistently. However, accurate sleep stage
classification may aid in the early detection of abnormal brain maturation
associated with pregnancy complications (e.g. hypoxia or intrauterine growth
restriction).
  Methods: EEG electrodes were secured onto the ovine dura over the parietal
cortices of 24 late gestation fetal sheep. A lightweight deep neural network
originally developed for adult EEG sleep staging was trained on the ovine EEG
using transfer learning from adult EEG. A spectral equalisation-based domain
adaptation strategy was used to reduce cross-domain mismatch.
  Results: We demonstrated that while direct transfer performed poorly, full
fine tuning combined with spectral equalisation achieved the best overall
performance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming
baseline models.
  Conclusions: To the best of our knowledge, FetalSleepNet is the first deep
learning framework specifically developed for automated sleep staging from the
fetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier
functions as a label engine, enabling large scale weak/semi supervised labeling
and distillation to facilitate training on less invasive signals that can be
acquired in the clinic, such as Doppler Ultrasound or electrocardiogram data.
FetalSleepNet's lightweight design makes it well suited for deployment in low
power, real time, and wearable fetal monitoring systems.

</details>


### [215] [Resilient Vital Sign Monitoring Using RIS-Assisted Radar](https://arxiv.org/abs/2509.10088)
*Christian Eckrich,Abdelhak M. Zoubir,Vahid Jamali*

Main category: eess.SP

TL;DR: 本研究提出一种结合雷达与智能反射面（RIS）的多路径传感方法，用于在不干扰用户的情况下监测呼吸和心率等生命体征，解决了单一雷达视角可能存在的监测不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴生命体征监测设备存在舒适度和依从性问题，基于雷达的非接触式监测方案虽有优势但可能因角度问题导致监测不准确，因此需要更鲁棒的监测方法。

Method: 提出一种利用直接雷达路径和RIS反射路径的多路径生命体征传感模型，并讨论其在连续、隐私保护的生命体征监测中的潜在优势和性能提升。

Result: 通过集成RIS提供额外的传感路径，增强了呼吸监测的鲁棒性，有望在不干扰用户的情况下实现更可靠的生命体征监测。

Conclusion: 本研究提出了一种创新的多路径生命体征传感方法，通过结合RIS技术显著提高了雷达生命体征监测的鲁棒性和准确性，为非接触式、保护隐私的健康监测提供了新的解决方案。

Abstract: Vital sign monitoring plays a critical role in healthcare and well-being, as
parameters such as respiration and heart rate offer valuable insights into an
individual's physiological state. While wearable devices allow for continuous
measurement, their use in settings like in-home elderly care is often hindered
by discomfort or user noncompliance. As a result, contactless solutions based
on radar sensing have garnered increasing attention. This is due to their
unobtrusive design and preservation of privacy advantages compared to
camera-based systems. However, a single radar perspective can fail to capture
breathing-induced chest movements reliably, particularly when the subject's
orientation is unfavorable. To address this limitation, we integrate a
reconfigurable intelligent surface (RIS) that provides an additional sensing
path, thereby enhancing the robustness of respiratory monitoring. We present a
novel model for multi-path vital sign sensing that leverages both the direct
radar path and an RIS-reflected path. We further discuss the potential benefits
and improved performance our approach offers in continuous, privacy-preserving
vital sign monitoring.

</details>


### [216] [Real-time identification and control of influential pandemic regions using graph signal variation](https://arxiv.org/abs/2509.10281)
*Sudeepini Darapu,Subrata Ghosh,Dibakar Ghosh,Chittaranjan Hens,Santosh Nannuru*

Main category: eess.SP

TL;DR: 通过图信号变化检测疫情传播中的关键地区。


<details>
  <summary>Details</summary>
Motivation: 为了有效遏制疫情的全球传播，需要及时识别出能够加速疫情扩散的区域。

Method: 将疫情传播建模为时变图信号，并提出基于图信号变化的度量方法来捕捉时空变化，同时考虑图域和时域的局部性，并基于此度量提出在线算法来识别关键区域。

Result: 模拟结果表明，该方法能有效识别出具有更高感染传播能力的地理区域，并且隔离这些区域能显著降低累积感染量。对混合H1N1数据和真实世界印度COVID-19数据的分析也证实了该度量方法的有效性。

Conclusion: 所提出的基于图信号变化的度量方法和在线算法能够有效识别关键传播区域，为理解和控制疫情传播提供了有力的工具。

Abstract: The global spread of pandemics is facilitated by the mobility of populations,
transforming localized infections into widespread phenomena. To contain it,
timely identification of influential regions that accelerate this process is
necessary. In this work, we model infection as a temporally evolving graph
signal and propose graph signal variation-based metrics to capture
spatio-temporal changes. Both graph domain and time domain locality are
modeled. Based on this metric, we propose an online algorithm to identify
influential regions. Simulations demonstrate that the proposed method
effectively identifies geographical regions with a higher capacity to spread
the infection. Isolating these regions leads to a significant reduction in
cumulative infection. Simulations, along with analyses of hybrid H1N1 data and
real-world Indian COVID-19 data, underscore the utility of proposed metric in
enhancing our understanding and control of infection spread

</details>


### [217] [Low-Complexity Null-Space-Based Simultaneous Wireless Information and Power Transfer Scheme](https://arxiv.org/abs/2509.10296)
*Cheng Luo,Jie Hu,Luping Xiang,Kun Yang,Zhiqin Wang*

Main category: eess.SP

TL;DR: 在多用户无线信息与能量同步传输（SWIPT）系统中，我们提出了一种基于零空间传输方案，该方案利用信息波束（IBs）结合高斯信号进行信息与能量的联合传输，并提出了一种优化的能量波束（EB）设计，以在必要时（如使用确定性正弦波形时）实现专用波形传输以增强能量传输。


<details>
  <summary>Details</summary>
Motivation: 评估在多用户SWIPT系统中，信息波束（IBs）是否足以支持无线能量传输（WET），以及何时需要专用能量波束（EBs），并在此基础上提出一种低复杂度算法。

Method: 提出了一种基于零空间传输的方案，并利用高斯信号进行IBs的传输。在考虑非线性EH模型和多种波形选项后，设计了一个优化问题来为EBs设计专用波形，并开发了一种低复杂度的算法，该算法在优化过程中忽略了IBs对WET的贡献。

Result: 研究表明，在大多数情况下，IBs配合高斯信号足以支持WET，专用EBs并非总是必需，除非采用了如确定性正弦波形等特殊能量波形。当接收到的射频功率处于EH高效率区域时，确定性正弦波形优于高斯信号，此时专用EBs是有益的。所提出的低复杂度算法在M=8, K^I=K^E=2和M=16, K^I=K^E=4的情况下，分别实现了91.43%和98.54%的计算复杂度降低，且性能损失可忽略不计。

Conclusion: 基于零空间传输的方案能够有效地在多用户SWIPT系统中进行信息与能量的联合传输。通过采用优化的EB设计和低复杂度算法，可以显著降低计算复杂度，同时保持可接受的性能，尤其是在使用确定性正弦波形且EH处于高效率区域时。

Abstract: Simultaneous wireless information and power transfer (SWIPT) has attracted
sustained interest. We propose a null-space-based transmission scheme for
multiuser SWIPT serving both energy users (EUs) and information users (IUs).
Under a practical nonlinear energy-harvesting (EH) model and multiple waveform
options, we revisit the role of dedicated energy beams (EBs). We show that, in
general, dedicated EBs are unnecessary because information beams (IBs) with
Gaussian signaling can simultaneously support wireless energy transfer (WET)
and wireless information transfer (WIT), unless special energy-centric
waveforms (e.g., deterministic sinusoidal waveforms) are employed and provide
sufficient gains. Guided by these insights, we formulate an optimization
problem for EB design to enable dedicated waveform transmission for WET, and we
develop a low-complexity algorithm that reduces computation by ignoring the WET
contribution of IBs during optimization. Numerical results corroborate that
deterministic sinusoidal waveforms outperform Gaussian signaling when the
received RF power lies in the EH high-efficiency region, making dedicated EBs
beneficial. The proposed scheme achieves computational complexity reductions of
91.43\% and 98.54\% for the cases $M=8,,K^I=K^E=2$ and $M=16,,K^I=K^E=4$,
respectively, with negligible performance loss, thereby validating the
efficiency of the low-complexity algorithm.

</details>


### [218] [Realistic UE Antennas for 6G in the 3GPP Channel Model](https://arxiv.org/abs/2509.10357)
*Simon Svendsen,Dimitri Gold,Christian Rom,Volker Pauli,Vuokko Nurmela*

Main category: eess.SP

TL;DR: 3GPP Rel.19 TR 38.901更新了6G的信道模型，考虑了更真实的UE天线和用户遮挡，以提高6G技术评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了支持6G技术的发展，需要更新3GPP信道模型，以更真实地模拟用户设备（UE）天线和用户引起的遮挡，尤其是在手持设备场景下。

Method: 通过对参考智能手机在多个频段进行高保真仿真和测量，引入了包含定向天线方向图、实际天线布局、极化效应和单元特定遮挡的框架。

Result: 新的信道模型能够更精确地评估6G技术，并确保跨行业和研究领域性能评估的一致性。

Conclusion: 3GPP Rel.19 TR 38.901的更新为6G信道建模提供了更现实的框架，能够更准确地评估6G技术性能。

Abstract: The transition to 6G has driven significant updates to the 3GPP channel
model, particularly in modeling UE antennas and user-induced blockage for
handheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more
realistic framework that captures directive antenna patterns, practical antenna
placements, polarization effects, and element-specific blockage. These updates
are based on high-fidelity simulations and measurements of a reference
smartphone across multiple frequency ranges. By aligning link- and system-level
simulations with real-world device behavior, the new model enables more
accurate evaluation of 6G technologies and supports consistent performance
assessment across industry and research.

</details>


### [219] [Robust Localization in Modern Cellular Networks using Global Map Features](https://arxiv.org/abs/2509.10433)
*Junshi Chen,Xuhong Li,Russ Whiton,Erik Leitinger,Fredrik Tufvesson*

Main category: eess.SP

TL;DR: 本文提出了一种增强型多路径同步定位与地图构建（MP-SLAM）方法，通过引入全局地图特征（GMF）库，利用概率假设密度（PHD）滤波器融合历史数据，提高了在复杂城市环境（如5G/6G网络）下的定位鲁棒性和准确性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在存在视线遮挡（OLoS）和多径传播等挑战性环境下，需要精确的定位技术。多径传播的同步定位与地图构建（MP-SLAM）是一种有前景的解决方案，但其性能可进一步提升。

Method: 提出了一种扩展的MP-SLAM方法，该方法集成了一个全局地图特征（GMF）库，其中存储了高质量、一致性的地图特征。通过概率假设密度（PHD）滤波器将GMF重新整合到MP-SLAM框架中，并进行时变传播。

Result: 通过广泛的仿真和真实的LTE信号实验（在具有严重多径和网络干扰的密集城市环境中），证明了该框架在现代蜂窝网络（如5G/6G）中具有鲁棒性和准确的定位能力。

Conclusion: 所提出的基于GMF的MP-SLAM框架能够实现鲁棒且精确的定位，在不利的信号条件下表现优异，超过了传统的基于本体感觉传感器和传统MP-SLAM的方法，证明了其在实际应用中的有效性。

Abstract: Radio frequency (RF) signal-based localization using modern cellular networks
has emerged as a promising solution to accurately locate objects in challenging
environments. One of the most promising solutions for situations involving
obstructed-line-of-sight (OLoS) and multipath propagation is multipathbased
simultaneous localization and mapping (MP-SLAM) that employs map features
(MFs), such as virtual anchors. This paper presents an extended MP-SLAM method
that is augmented with a global map feature (GMF) repository. This repository
stores consistent MFs of high quality that are collected during prior
traversals. We integrate these GMFs back into the MP-SLAM framework via a
probability hypothesis density (PHD) filter, which propagates GMF intensity
functions over time. Extensive simulations, together with a challenging
real-world experiment using LTE RF signals in a dense urban scenario with
severe multipath propagation and inter-cell interference, demonstrate that our
framework achieves robust and accurate localization, thereby showcasing its
effectiveness in realistic modern cellular networks such as 5G or future 6G
networks. It outperforms conventional proprioceptive sensor-based localization
and conventional MP-SLAM methods, and achieves reliable localization even under
adverse signal conditions.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [220] [Target Defense Using a Turret and Mobile Defender Team](https://arxiv.org/abs/2509.09777)
*Alexander Von Moll,Dipankar Maity,Meir Pachter,Daigo Shishika,Michael Dorothy*

Main category: eess.SY

TL;DR: 该论文研究了一个由静止的 Turret 和移动的 Defender 组成的合作团队，共同防御一个移动的 Attacker。目标是让 Attacker 在被 Defender 或 Turret 捕获之前无法到达 Turret，同时 Defender 和 Turret 尽可能远离 Turret 捕获 Attacker。


<details>
  <summary>Details</summary>
Motivation: 研究一个 stationary, turn constrained agent (Turret) 和一个 mobile agent (Defender) 如何合作以保护 Turret 免受 adversarial mobile agent (Attacker) 的侵害。

Method: 将该场景构造成一个微分博弈，并使用几何方法求解。

Result: 给出了 Turret-Defender 团队获胜和 Attacker 获胜的充要条件。在 Turret-Defender 团队获胜的情况下，给出了 Attacker 到 Turret 的最小最大终端距离的均衡策略。推导出了三种情况：Defender 独占捕获、Turret 独占捕获以及 Turret 和 Defender 同时捕获。

Conclusion: 该研究为 Turret-Defender 合作防御 Attacker 的场景提供了理论解决方案，并分析了不同捕获情况下的策略。

Abstract: A scenario is considered wherein a stationary, turn constrained agent
(Turret) and a mobile agent (Defender) cooperate to protect the former from an
adversarial mobile agent (Attacker). The Attacker wishes to reach the Turret
prior to getting captured by either the Defender or Turret, if possible.
Meanwhile, the Defender and Turret seek to capture the Attacker as far from the
Turret as possible. This scenario is formulated as a differential game and
solved using a geometric approach. Necessary and sufficient conditions for the
Turret-Defender team winning and the Attacker winning are given. In the case of
the Turret-Defender team winning equilibrium strategies for the min max
terminal distance of the Attacker to the Turret are given. Three cases arise
corresponding to solo capture by the Defender, solo capture by the Turret, and
capture simultaneously by both Turret and Defender.

</details>


### [221] [Automatic Regression for Governing Equations with Control (ARGOSc)](https://arxiv.org/abs/2509.09784)
*Amir Bahador Javadi,Amin Kargarian,Mort Naraghi-Pour*

Main category: eess.SY

TL;DR: ARGOSc是一个新框架，用于从包含控制输入的时序数据中识别动力系统的控制方程。它在低噪声数据集上表现出色，并且在有噪声的情况下优于SINDYc。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的动力系统通常受到外部控制、力或干预的影响，而标准的ARGOS无法处理这种情况。因此，有必要开发能够将外部控制输入纳入系统识别过程的扩展方法。

Method: ARGOSc扩展了稀疏回归框架，通过在推断控制方程的同时考虑外源输入的影响来识别控制方程。

Result: 通过在范德堡尔振荡器、洛特卡-沃尔泰拉和受迫反馈控制的洛伦兹系统等基准系统上进行演示，ARGOSc证明了其在识别控制方程方面的有效性。在有噪声的情况下，ARGOSc在准确识别潜在的受迫动力学方面优于SINDYc。

Conclusion: ARGOSc在识别受迫动力学方面优于SINDYc，即使在有噪声的情况下，也能成功识别真正的系统动力学。

Abstract: Learning the governing equations of dynamical systems from data has drawn
significant attention across diverse fields, including physics, engineering,
robotics and control, economics, climate science, and healthcare. Sparse
regression techniques, exemplified by the Automatic Regression for Governing
Equations (ARGOS) framework, have demonstrated effectiveness in extracting
parsimonious models from time series data. However, real-world dynamical
systems are driven by input control, external forces, or human interventions,
which standard ARGOS does not accommodate. To address this, we introduce ARGOS
with control (ARGOSc), an extension of ARGOS that incorporates external control
inputs into the system identification process. ARGOSc extends the sparse
regression framework to infer governing equations while accounting for the
effects of exogenous inputs, enabling robust identification of forcing dynamics
in low- to medium-noise datasets. We demonstrate ARGOSc efficacy on benchmark
systems, including the Van der Pol oscillator, Lotka-Volterra, and the Lorenz
system with forcing and feedback control, showing enhanced accuracy in
discovering governing laws. Under the noisy conditions, ARGOSc outperforms the
widely used sparse identification of nonlinear dynamics with control (SINDYc),
in accurately identifying the underlying forced dynamics. In some cases, SINDYc
fails to capture the true system dynamics, whereas ARGOSc consistently
succeeds.

</details>


### [222] [High-Gain Voltage-Multiplier Coupled Quadratic Boost Converter: A New Design for Small Scale PV Integration](https://arxiv.org/abs/2509.09789)
*Safa Mohammed Sali,Hoach The Nguyen,Ameena Saad Al-Sumaiti*

Main category: eess.SY

TL;DR: 该论文提出了一种单开关高增益电压倍增耦合二次升压转换器 (HGVM-QBC)，它源自传统的二次升压转换器 (QBC)。


<details>
  <summary>Details</summary>
Motivation: HGVM-QBC 旨在实现更高的电压增益、降低半导体电压应力，并实现连续电流运行，特别适合小型光伏 (PV) 系统。

Method: 通过将电压倍增单元集成到 QBC 中，显著提高了电压提升能力，并降低了开关器件的应力。输出电压通过组合多个输出电容器上的电压来获得。

Result: 与最近报道的转换器拓扑进行了详细的比较研究，证明了 HGVM-QBC 在增益和器件应力方面的优越性。MATLAB/Simulink 仿真和实验原型（在 12 Vdc 输入和 55% 占空比下实现 151 Vdc 输出，增益为 12.59）验证了其性能。

Conclusion: HGVM-QBC 被证明是满足低输入源高电压输出要求的光伏应用的高效可靠解决方案。

Abstract: This paper introduces a single-switch high-gain voltage-multiplier coupled
quadratic boost converter (HGVM-QBC), developed from the conventional quadratic
boost converter (QBC). The proposed topology is designed to achieve higher
voltage gain, lower semiconductor voltage stress, and continuous current
operation, making it particularly suitable for small-scale photovoltaic (PV)
systems. By incorporating a voltage multiplier cell into the QBC, the converter
significantly improves voltage boosting capability while mitigating stress on
switching devices. In this configuration, the output voltage is obtained by
combining the voltages across multiple output capacitors, thereby enhancing the
overall voltage level. A detailed comparative study with recently reported
converter topologies demonstrates the superior gain and reduced device stress
offered by the HGVM-QBC. The design is validated through MATLAB/Simulink
simulations, which confirm improved performance in terms of gain and voltage
stress. Furthermore, an experimental prototype achieves an output of 151 Vdc
from a 12 Vdc input at a 55% duty cycle, corresponding to a gain of 12.59.
These results establish the HGVM-QBC as an efficient and reliable solution for
PV applications that demand high voltage output from low input sources.

</details>


### [223] [EDMD-Based Robust Observer Synthesis for Nonlinear Systems](https://arxiv.org/abs/2509.09812)
*Xiuzhen Ye,Wentao Tang*

Main category: eess.SY

TL;DR: 本文提出一种基于数据驱动的Koopman算子框架，用于设计非线性系统的鲁棒状态观测器。通过扩展动态模态分解识别有限维Koopman生成器代理模型，实现了数据驱动模型上的可解观测器设计，并引入了圆锥不确定性。该问题被转化为一个半定规划问题，包含线性矩阵不等式，能在概率意义上保证观测器以预定速率指数收敛。该方法弥合了统计误差容限与观测器收敛认证之间的差距，并能通过数据驱动的线性代理模型显式应用线性系统理论进行状态观测。数值研究证明了该方法的有效性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 为非线性系统的鲁棒状态观测器设计提供一种新的数据驱动方法，利用Koopman算子理论处理非线性系统，并通过半定规划保证收敛性。

Method: 1. 利用扩展动态模态分解（EDMD）识别非线性系统的有限维Koopman生成器代理模型。
2. 在此数据驱动的线性模型上，结合圆锥不确定性，构建观测器设计问题。
3. 将观测器设计问题转化为一个包含线性矩阵不等式的半定规划（SDP）问题。

Result: 所提出的方法能够在概率意义上保证观测器以预定的指数收敛速率收敛，弥合了统计误差容限和观测器收敛认证之间的差距。

Conclusion: 该数据驱动的Koopman算子方法为设计非线性系统的鲁棒状态观测器提供了一种有效且灵活的途径，能够显式利用线性系统理论，并通过数值验证了其有效性。

Abstract: This paper presents a data driven Koopman operator based framework for
designing robust state observers for nonlinear systems. Based on a finite
dimensional surrogate of the Koopman generator, identified via an extended
dynamic mode decomposition procedure, a tractable formulation of the observer
design is enabled on the data driven model with conic uncertainties. The
resulting problem is cast as a semidefinite program with linear matrix
inequalities, guaranteeing exponential convergence of the observer with a
predetermined rate in a probabilistic sense. The approach bridges the gap
between statistical error tolerance and observer convergence certification, and
enables an explicit use of linear systems theory for state observation via a
data driven linear surrogate model. Numerical studies demonstrate the
effectiveness and flexibility of the proposed method.

</details>


### [224] [Off Policy Lyapunov Stability in Reinforcement Learning](https://arxiv.org/abs/2509.09863)
*Sarvan Gill,Daniela Constantinescu*

Main category: eess.SY

TL;DR: 传统的强化学习缺乏稳定性保证，本研究提出一种样本效率高且能提供稳定性证书的离策略学习李亚普诺夫函数的方法，并将其集成到SAC和PPO算法中，在倒立摆和四旋翼飞行器的仿真中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习在提供稳定性保证方面存在不足。虽然现有的算法可以学习李亚普诺夫函数来确保学习的稳定性，但它们是样本效率低下的，因为它们是样本使用效率高的（on-policy）。

Method: 本研究提出了一种离策略学习李亚普诺夫函数的方法，并将所提出的离策略李亚普诺夫函数集成到软Actor-Critic（SAC）和Proximal Policy Optimization（PPO）算法中，为它们提供了一个数据效率高的稳定性证书。

Result: 将所提出的离策略李亚普诺夫函数集成到SAC和PPO算法中，在倒立摆和四旋翼飞行器的仿真中，展示了这两种算法的性能得到了提升。

Conclusion: 所提出的离策略李亚普诺夫函数学习方法可以提高强化学习算法的数据效率，并为其提供稳定性保证。

Abstract: Traditional reinforcement learning lacks the ability to provide stability
guarantees. More recent algorithms learn Lyapunov functions alongside the
control policies to ensure stable learning. However, the current self-learned
Lyapunov functions are sample inefficient due to their on-policy nature. This
paper introduces a method for learning Lyapunov functions off-policy and
incorporates the proposed off-policy Lyapunov function into the Soft Actor
Critic and Proximal Policy Optimization algorithms to provide them with a data
efficient stability certificate. Simulations of an inverted pendulum and a
quadrotor illustrate the improved performance of the two algorithms when
endowed with the proposed off-policy Lyapunov function.

</details>


### [225] [Leveraging Predictions in Power System Voltage Control: An Adaptive Approach](https://arxiv.org/abs/2509.09937)
*Wenqi Cui,Yiheng Xie,Steven Low,Adam Wierman,Baosen Zhang*

Main category: eess.SY

TL;DR: This paper proposes an adaptive voltage control approach for power systems with time-varying net load, using short-term load forecasting and reinforcement learning to achieve decentralized input-to-state stability.


<details>
  <summary>Details</summary>
Motivation: Voltage fluctuations in distribution systems caused by high variability of solar PV and sudden load changes are a significant problem. Existing controllers often assume constant net load, which is unrealistic given the intermittent nature of renewables. Therefore, there is a need for controllers that explicitly consider time-varying net load.

Method: The proposed approach integrates short-term load forecasting with adaptive controllers to predict and manage time-varying net load. Reinforcement learning is used to optimize the control policy. The overall control architecture is designed to achieve decentralized input-to-state stability.

Result: The effectiveness of the proposed adaptive voltage control approach was demonstrated through case studies using real-world distribution system data with time-varying load.

Conclusion: The paper presents a novel adaptive voltage control strategy that effectively addresses the challenges posed by time-varying net load in power systems. The approach, which utilizes short-term load forecasting and reinforcement learning, achieves decentralized input-to-state stability and is validated through practical case studies.

Abstract: High variability of solar PV and sudden changes in load (e.g., electric
vehicles and storage) can lead to large voltage fluctuations in the
distribution system. In recent years, a number of controllers have been
designed to optimize voltage control. These controllers, however, almost always
assume that the net load in the system remains constant over a sufficiently
long time, such that the control actions converge before the load changes
again. Given the intermittent and uncertain nature of renewable resources, it
is becoming important to explicitly consider net load that is time-varying.
  This paper proposes an adaptive approach to voltage control in power systems
with significant time-varying net load. We leverage advances in short-term load
forecasting, where the net load in the system can be partially predicted using
local measurements. We integrate these predictions into the design of adaptive
controllers, and prove that the overall control architecture achieves
input-to-state stability in a decentralized manner. We optimize the control
policy through reinforcement learning. Case studies are conducted using
time-varying load data from a real-world distribution system.

</details>


### [226] [Ruggedized Ultrasound Sensing in Harsh Conditions: eRTIS in the wild](https://arxiv.org/abs/2509.10029)
*Dennis Laurijssen,Wouter Jansen,Arne Aerts,Walter Daems,Jan Steckel*

Main category: eess.SY

TL;DR: eRTIS是一个用于恶劣工业环境的嵌入式超声波传感系统，采用宽带电容换能器和32元MEMS麦克风阵列，支持2D/3D波束成形。其模块化设计将传感和处理分离，并提供多种同步选项。该系统具有坚固耐用的外壳和被动冷却，可在严苛条件下可靠运行。在港口系泊、越野机器人和复杂环境自主导航等场景中的应用证明，eRTIS在光学系统性能下降的情况下仍能提供可靠的传感能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种适用于恶劣工业环境的鲁棒、嵌入式超声波传感系统。

Method: eRTIS系统采用宽带电容换能器和32元MEMS麦克风阵列，实现2D和3D波束成形。其模块化硬件架构分离了传感和处理任务，由微控制器处理信号生成和数据采集，NVIDIA Jetson模块进行GPU加速信号处理。系统支持通过自定义控制器进行外部同步，可同时或按顺序协调多达六个设备，并提供双向触发和带内信号注入等同步选项。外壳采用密封阳极铝，被动冷却和IP级连接器设计。

Result: 该系统在港口系泊、越野机器人和复杂环境自主导航三个实际场景中进行了性能验证，证明了eRTIS在光学系统性能下降的情况下，依然能够提供鲁棒的传感能力。

Conclusion: eRTIS系统为恶劣工业环境提供了一种可靠的超声波传感解决方案，其坚固的设计和先进的信号处理能力使其在传统光学传感受限的场景中具有优势。

Abstract: We present eRTIS, a rugged, embedded ultrasound sensing system for use in
harsh industrial environments. The system features a broadband capacitive
transducer and a 32-element MEMS microphone array capable of 2D and 3D
beamforming. A modular hardware architecture separates sensing and processing
tasks: a high-performance microcontroller handles excitation signal generation
and data acquisition, while an NVIDIA Jetson module performs GPU-accelerated
signal processing. eRTIS supports external synchronization via a custom
controller that powers and coordinates up to six devices, either simultaneously
or in a defined sequence. Additional synchronization options include
bidirectional triggering and in-band signal injection. A sealed, anodized
aluminum enclosure with passive cooling and IP-rated connectors ensures
reliability in challenging conditions. Performance is demonstrated in three
field scenarios: harbor mooring, off-road robotics, and autonomous navigation
in cluttered environments, demonstrates that eRTIS provides robust sensing in
situations where optical systems degrade.

</details>


### [227] [Understanding the Geometry of Faulted Power Systems under High Penetration of Inverter-Based Resources via Ellipse Fitting and Geometric Algebra](https://arxiv.org/abs/2509.10044)
*Jorge Ventura,Jaroslav Hrdina,Aleš Návrat,Marek Stodola,Ahmad Eid,Santiago Sanchez-Acevedo,Francisco G. Montoya*

Main category: eess.SY

TL;DR: 高渗透率的逆变器基资源（IBD）对传统保护方案提出挑战，本文提出一种利用椭圆拟合和几何代数进行故障检测和分类的方法，仅需四分之一个周期即可实现故障检测，并能准确识别各种类型故障。


<details>
  <summary>Details</summary>
Motivation: 高渗透率的逆变器基资源（IBD）对传统保护方案提出挑战，特别是在非对称条件下，传统的距离保护方法无法检测线间故障。

Method: 本文提出一种利用椭圆拟合和几何代数应用于电压和电流空间曲线的故障检测和分类方法。该方法通过拟合电压矢量数据的椭圆来表征电气故障，并利用二矢量分量进行接地故障分类，同时利用椭圆参数识别线间和三相故障。

Result: 仿真和实验室实验验证表明，该方法能够准确识别故障并估计故障幅值，能够用于增强电网保护能力。

Conclusion: 所提出的基于椭圆拟合和几何代数的方法能够有效解决高渗透率IBD系统中的故障检测和分类问题，并且具有响应速度快、精度高等优点。

Abstract: Power systems with high penetration of inverter-based resources (IBR) present
significant challenges for conventional protection schemes, with traditional
distance protection methods failing to detect line-to-line faults during
asymmetric conditions. This paper presents a methodology for electrical fault
detection and classification using ellipse fitting and geometric algebra
applied to voltage and current space curves. The approach characterizes
electrical faults by fitting ellipses to voltage vector data, enabling fault
detection with only a quarter-cycle. The method employs bivector components for
line-to-ground fault classification, while ellipse parameters identify
line-to-line and three-phase faults. The geometric representation preserves
voltage or current curve shapes in three-dimensional space, overcoming Clarke
transform limitations when zero-sequence components are present. Validation
using simulations and laboratory experiments demonstrates accurate fault
identification and magnitude estimation, providing enhanced power system
protection capabilities.

</details>


### [228] [Data-driven optimization of sparse sensor placement in thermal hydraulic experiments](https://arxiv.org/abs/2509.10055)
*Xicheng Wang,Yun. Feng,Dmitry Grishchenko,Pavel Kudinov,Ruifeng Tian,Sichao Tan*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动框架，用于优化热工水力学（TH）实验中的传感器布局，以提高数据覆盖率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的TH实验传感器数据覆盖有限，手动确定传感器位置具有挑战性。需要一种系统化的方法来优化传感器布局。

Method: 开发了一个包含敏感性分析、 Proper Orthogonal Decomposition (POD) 和 QR 分解的框架，用于优化传感器布局。

Result: 该框架在TALL-3D铅铋（LBE）回路实验中得到验证，优化的热电偶（TC）布局能灵敏地响应不确定输入参数的变化，并能准确地重建全场信息，同时保持对测量噪声的鲁棒性。

Conclusion: 所提出的框架为TH实验的传感器布局提供了一种系统化和自动化的方法，能够得到更优的传感器配置，以获得更可靠的实验数据。

Abstract: Thermal-Hydraulic (TH) experiments provide valuable insight into the physics
of heat and mass transfer and qualified data for code development, calibration
and validation. However, measurements are typically collected from sparsely
distributed sensors, offering limited coverage over the domain of interest and
phenomena of interest. Determination of the spatial configuration of these
sensors is crucial and challenging during the pre-test design stage. This paper
develops a data-driven framework for optimizing sensor placement in TH
experiments, including (i) a sensitivity analysis to construct datasets, (ii)
Proper Orthogonal Decomposition (POD) for dimensionality reduction, and (iii)
QR factorization with column pivoting to determine optimal sensor configuration
under spatial constraints. The framework is demonstrated on a test conducted in
the TALL-3D Lead-bismuth eutectic (LBE) loop. In this case, the utilization of
optical techniques, such as Particle Image Velocimetry (PIV), are impractical.
Thereby the quantification of momentum and energy transport relies heavily on
readings from Thermocouples (TCs). The test section was previously instrumented
with many TCs determined through a manual process combining simulation results
with expert judgement. The proposed framework provides a systematic and
automated approach for sensor placement. The resulting TCs exhibit high
sensitivity to the variation of uncertain input parameters and enable accurate
full field reconstruction while maintaining robustness against measurement
noise.

</details>


### [229] [Scalable Synthesis and Verification of String Stable Neural Certificates for Interconnected Systems](https://arxiv.org/abs/2509.10118)
*Jingyuan Zhou,Haoze Wu,Haokun Yu,Kaidi Yang*

Main category: eess.SY

TL;DR: 提出一个结合了离散时间可扩展输入状态稳定性（sISS）和神经网络验证的新框架，用于保证大型互联系统的字符串稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的控制器（如强化学习）虽然性能强大，但其黑盒特性阻碍了对字符串稳定性的正式保证。

Method: 提出一个结合了离散时间可扩展输入状态稳定性（sISS）和神经网络验证的框架，用于合成和验证神经网络互联系统的sISS证书，并扩展到具有外部控制输入的系统。

Result: 该框架能够保证sISS，同时控制性能下降最小，并能有效地训练和验证大型互联系统的控制器。

Conclusion: 该框架为保证大型互联系统的字符串稳定性提供了一种新的、可扩展的、经过验证的方法。

Abstract: Ensuring string stability is critical for the safety and efficiency of
large-scale interconnected systems. Although learning-based controllers (e.g.,
those based on reinforcement learning) have demonstrated strong performance in
complex control scenarios, their black-box nature hinders formal guarantees of
string stability. To address this gap, we propose a novel verification and
synthesis framework that integrates discrete-time scalable input-to-state
stability (sISS) with neural network verification to formally guarantee string
stability in interconnected systems. Our contributions are four-fold. First, we
establish a formal framework for synthesizing and robustly verifying
discrete-time scalable input-to-state stability (sISS) certificates for neural
network-based interconnected systems. Specifically, our approach extends the
notion of sISS to discrete-time settings, constructs neural sISS certificates,
and introduces a verification procedure that ensures string stability while
explicitly accounting for discrepancies between the true dynamics and their
neural approximations. Second, we establish theoretical foundations and
algorithms to scale the training and verification pipeline to large-scale
interconnected systems. Third, we extend the framework to handle systems with
external control inputs, thereby allowing the joint synthesis and verification
of neural certificates and controllers. Fourth, we validate our approach in
scenarios of mixed-autonomy platoons, drone formations, and microgrids.
Numerical simulations show that the proposed framework not only guarantees sISS
with minimal degradation in control performance but also efficiently trains and
verifies controllers for large-scale interconnected systems under specific
practical conditions.

</details>


### [230] [MPC for Aquifer Thermal Energy Storage Systems Using ARX Models](https://arxiv.org/abs/2509.10154)
*Johannes van Randenborgh,Moritz Schulze Darup*

Main category: eess.SY

TL;DR: ATES系统可以通过在地层水体中储存热能来减少建筑暖通空调系统的碳排放。本文提出了一种基于ARX模型的轻量级控制方案，用于管理ATES系统，该方案避免了对地下温度进行状态估计，从而简化了模型预测控制（MPC）的设计。


<details>
  <summary>Details</summary>
Motivation: ATES系统在减少建筑暖通空调系统碳排放方面具有潜力，但其控制具有挑战性。需要一种简化的控制方法。

Method: 提出了一种轻量级的、基于输入输出数据的自回归模型（ARX），用于模拟混合ATES系统的动态。利用ARX模型设计了一个基于输出的MPC方案，该方案可以简化为易于求解的二次规划问题，并避免了对地面温度进行状态估计。

Result: 进行了数值研究，讨论了ARX预测器的准确性和控制器性能。

Conclusion: 所提出的基于ARX模型的MPC方案为ATES系统的控制提供了一种简化且有效的方法，避免了复杂的状态估计。

Abstract: An aquifer thermal energy storage (ATES) can mitigate CO2 emissions of
heating, ventilation, and air conditioning (HVAC) systems for buildings. In
application, an ATES keeps large quantities of thermal energy in
groundwater-saturated aquifers. Normally, an ATES system comprises two (one for
heat and one for cold) storages and supports the heating and cooling efforts of
simultaneously present HVAC system components. This way, the operation and
emissions of installed and, usually, fossil fuel-based components are reduced.
  The control of ATES systems is challenging, and various control schemes,
including model predictive control (MPC), have been proposed. In this context,
we present a lightweight input-output-data-based autoregressive with exogenous
input (ARX) model of the hybrid ATES system dynamics. The ARX model allows the
design of an output-based MPC scheme, resulting in an easy-to-solve quadratic
program and avoiding challenging state estimations of ground temperatures. A
numerical study discusses the accuracy of the ARX predictor and controller
performance.

</details>


### [231] [Learning Constraint Surrogate Model for Two-stage Stochastic Unit Commitment](https://arxiv.org/abs/2509.10246)
*Amir Bahador Javadi,Amin Kargarian,Mort Naraghi-Pour*

Main category: eess.SY

TL;DR: 本论文提出一种基于机器学习的智能体建模方法，用于解决两阶段随机单位承诺（TSUC）问题，以应对可再生能源带来的不确定性，降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 可再生能源的普及增加了电力系统运行的不确定性，使得传统的确定性单位承诺方法计算成本高昂。

Method: 利用支持向量机（SVM）构建智能体模型，该模型基于学习方程，用一个简化约束集（1*|S|）替代原有的（2|L|*|S|）输电线路潮流约束，实现计算的简化。该方法基于直流潮流近似下的多面体结构。

Result: 在IEEE 57节点和118节点系统上的仿真结果显示，SVM半空间约束的准确率分别为99.72%和99.88%，TSUC的计算时间分别减少了46%和31%，发电成本仅增加了0.63%和0.88%。

Conclusion: 所提出的方法通过机器学习智能体建模有效降低了TSUC问题的计算复杂度，并保持了高准确性，证明了其在应对可再生能源不确定性的实际电力系统运行中的有效性。

Abstract: The increasing penetration of renewable energy sources introduces significant
uncertainty in power system operations, making traditional deterministic unit
commitment approaches computationally expensive. This paper presents a machine
learning surrogate modeling approach designed to reformulate the feasible
design space of the two-stage stochastic unit commitment (TSUC) problem,
reducing its computational complexity. The proposed method uses a support
vector machine (SVM) to construct a surrogate model based on the governing
equations of the learner. This model replaces the original 2|L| * |S|
transmission line flow constraints, where |S| is the number of uncertainty
scenarios and |L| is the number of transmission lines with |S| much less than
|L|, with a significantly reduced set of 1 * |S| linear inequality constraints.
The approach is theoretically grounded in the polyhedral structure of the
feasible region under the DC power flow approximation, enabling the
transformation of 2|L| line flow limit constraints into a single linear
constraint. The surrogate model is trained using data generated from
computationally efficient DC optimal power flow simulations. Simulation results
on the IEEE 57-bus and 118-bus systems demonstrate SVM halfspace constraint
accuracy of 99.72% and 99.88%, respectively, with TSUC computational time
reductions of 46% and 31% and negligible generation cost increases (0.63% and
0.88% on average for IEEE 57- and 118-bus systems, respectively). This shows
the effectiveness of the proposed approach for practical power system
operations under renewable energy uncertainty.

</details>


### [232] [Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots](https://arxiv.org/abs/2509.10353)
*Davide Gorbani,Mohamed Elobaid,Giuseppe L'Erario,Hosameldin Awadalla Omer Mohamed,Daniele Pucci*

Main category: eess.SY

TL;DR: 该研究提出了一种数据融合模型预测控制（DFMPC）框架，结合了基于物理的模型和数据驱动的未知动态表示，以实现对变化的、可能不可达的设定点的跟踪，同时显式处理测量噪声。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决传统MPC在处理未知动态、变化设定点和测量噪声方面的挑战，提出一种能够融合物理模型和数据驱动模型，并保证稳定性和可行性的控制框架。

Method: DFMPC框架利用Willems' Fundamental Lemma和人工平衡公式，整合了基于物理的分析动量模型和数据驱动的涡轮机动态模型。通过引入松弛变量和正则化来处理测量噪声，并提供输入输出约束下特定参考信号的递归可行性和实际稳定性保证。

Result: 在iRonCub飞行人形机器人上的仿真结果表明，与纯基于模型的MPC相比，DFMPC在跟踪和鲁棒性方面有所提高，同时保持了实时可行性。

Conclusion: DFMPC框架通过结合物理模型和数据驱动模型，成功实现了对复杂动态系统的精确跟踪和鲁棒控制，并在计算效率和稳定性方面表现出色，证明了其在机器人控制等领域的应用潜力。

Abstract: This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework
that combines physics-based models with data-driven representations of unknown
dynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium
formulation, the method enables tracking of changing, potentially unreachable
setpoints while explicitly handling measurement noise through slack variables
and regularization. We provide guarantees of recursive feasibility and
practical stability under input-output constraints for a specific class of
reference signals. The approach is validated on the iRonCub flying humanoid
robot, integrating analytical momentum models with data-driven turbine
dynamics. Simulations show improved tracking and robustness compared to a
purely model-based MPC, while maintaining real-time feasibility.

</details>


### [233] [Merging Physics-Based Synthetic Data and Machine Learning for Thermal Monitoring of Lithium-ion Batteries: The Role of Data Fidelity](https://arxiv.org/abs/2509.10380)
*Yusheng Zheng,Wenxue Liu,Yunhong Che,Ferdinand Grimm,Jingyuan Zhao,Xiaosong Hu,Simona Onori,Remus Teodorescu,Gregory J. Offer*

Main category: eess.SY

TL;DR: 该研究提出了一种结合物理模型和机器学习的新框架，用于高效、可扩展地开发精确、鲁棒且自适应的电池内部温度估算算法。


<details>
  <summary>Details</summary>
Motivation: 由于内部温度比表面温度更难获取，因此迫切需要开发精确的实时估算算法以实现更好的热管理和安全。本研究旨在解决数据收集、模型参数化和估计器设计方面的挑战。

Method: 利用物理模型生成包含不同运行场景的仿真数据，用于预训练机器学习算法。然后，利用迁移学习和无监督域自适应技术，使用有限的运行数据对模型进行微调，以弥合仿真与现实之间的差距。

Result: 在不同运行条件和多种圆柱形电池上进行了验证，在仅依赖电池热特性先验知识的情况下，实现了 0.5°C 的均方根误差；在使用接近真实值的热参数时，误差小于 0.1°C。此外，还全面研究了仿真数据质量对框架性能的影响。

Conclusion: 该框架能够高效、可扩展地开发出精确、鲁棒且自适应的电池内部温度估算算法，有效解决了传统方法的局限性。

Abstract: Since the internal temperature is less accessible than surface temperature,
there is an urgent need to develop accurate and real-time estimation algorithms
for better thermal management and safety. This work presents a novel framework
for resource-efficient and scalable development of accurate, robust, and
adaptive internal temperature estimation algorithms by blending physics-based
modeling with machine learning, in order to address the key challenges in data
collection, model parameterization, and estimator design that traditionally
hinder both approaches. In this framework, a physics-based model is leveraged
to generate simulation data that includes different operating scenarios by
sweeping the model parameters and input profiles. Such a cheap simulation
dataset can be used to pre-train the machine learning algorithm to capture the
underlying mapping relationship. To bridge the simulation-to-reality gap
resulting from imperfect modeling, transfer learning with unsupervised domain
adaptation is applied to fine-tune the pre-trained machine learning model, by
using limited operational data (without internal temperature values) from
target batteries. The proposed framework is validated under different operating
conditions and across multiple cylindrical batteries with convective air
cooling, achieving a root mean square error of 0.5 {\deg}C when relying solely
on prior knowledge of battery thermal properties, and less than 0.1 {\deg}C
when using thermal parameters close to the ground truth. Furthermore, the role
of the simulation data quality in the proposed framework has been
comprehensively investigated to identify promising ways of synthetic data
generation to guarantee the performance of the machine learning model.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [234] [Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images](https://arxiv.org/abs/2509.09952)
*Zhi Ying,Boxiang Rong,Jingyu Wang,Maoyuan Xu*

Main category: cs.GR

TL;DR: 一种新的两阶段生成和估计框架，用于从用户输入生成高质量、灵活且可控的 PBR 材料。


<details>
  <summary>Details</summary>
Motivation: 传统材料创建耗时且需要专业知识，现有基于视觉基础模型的 PBR 材料生成方法在质量、灵活性和用户控制方面存在不足。

Method: 提出了一种两阶段框架：第一阶段使用微调的扩散模型生成对齐用户输入的 PBR 纹理图像；第二阶段使用链式分解方案，通过将先前提取的表示作为输入，来预测 SVBRDF 通道。

Result: 该方法在效率、质量和用户控制方面表现出色，并在生成的纹理和真实照片上均表现出强大的鲁棒性。

Conclusion: 该框架在文本到材质、图像到材质、结构引导生成和材质编辑等多种应用中展现了灵活性和优越性能。

Abstract: Material creation and reconstruction are crucial for appearance modeling but
traditionally require significant time and expertise from artists. While recent
methods leverage visual foundation models to synthesize PBR materials from
user-provided inputs, they often fall short in quality, flexibility, and user
control. We propose a novel two-stage generate-and-estimate framework for PBR
material generation. In the generation stage, a fine-tuned diffusion model
synthesizes shaded, tileable texture images aligned with user input. In the
estimation stage, we introduce a chained decomposition scheme that sequentially
predicts SVBRDF channels by passing previously extracted representation as
input into a single-step image-conditional diffusion model. Our method is
efficient, high quality, and enables flexible user control. We evaluate our
approach against existing material generation and estimation methods,
demonstrating superior performance. Our material estimation method shows strong
robustness on both generated textures and in-the-wild photographs. Furthermore,
we highlight the flexibility of our framework across diverse applications,
including text-to-material, image-to-material, structure-guided generation, and
material editing.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [235] [The Role of Follow Networks and Twitter's Content Recommender on Partisan Skew and Rumor Exposure during the 2022 U.S. Midterm Election](https://arxiv.org/abs/2509.09826)
*Kayla Duskin,Joseph S. Schafer,Alexandros Efstratiou,Jevin D. West,Emma S. Spiro*

Main category: cs.SI

TL;DR: Twitter的算法推荐在2022年美国中期选举期间会影响用户接触到的信息主题、政治倾向和信息可靠性，但这种影响会受到用户社交网络构成的调节，社交网络的影响力有时甚至超过算法本身。


<details>
  <summary>Details</summary>
Motivation: 研究Twitter的内容推荐算法与其用户社交网络结合，在2022年美国中期选举期间对用户接收到的信息主题、政治倾向和可靠性产生何种影响。

Method: 使用自动化账户记录Twitter在2022年美国中期选举期间的算法推荐时间线和按时间倒序排列时间线。

Result: 算法推荐时间线会显著影响用户接触到的选举信息、政治倾向和低质量信息的比例。具体来说，算法推荐会减少左倾账户接收到的选举信息比例，并将内容倾向于右倾来源。此外，算法推荐会增加右倾账户接收到的选举谣言，并对低质量信息来源的普遍性产生混合影响。

Conclusion: Twitter的算法系统在选举期间对信息传播有重要影响，但用户的社交网络在其中扮演着关键的调节角色。研究强调了持续研究算法系统及其在民主进程中作用的必要性。

Abstract: Social media platforms shape users' experiences through the algorithmic
systems they deploy. In this study, we examine to what extent Twitter's content
recommender, in conjunction with a user's social network, impacts the topic,
political skew, and reliability of information served on the platform during a
high-stakes election. We utilize automated accounts to document Twitter's
algorithmically curated and reverse chronological timelines throughout the U.S.
2022 midterm election. We find that the algorithmic timeline measurably
influences exposure to election content, partisan skew, and the prevalence of
low-quality information and election rumors. Critically, these impacts are
mediated by the partisan makeup of one's personal social network, which often
exerts greater influence than the algorithm alone. We find that the algorithmic
feed decreases the proportion of election content shown to left-leaning
accounts, and that it skews content toward right-leaning sources when compared
to the reverse chronological feed. We additionally find evidence that the
algorithmic system increases the prevalence of election-related rumors for
right-leaning accounts, and has mixed effects on the prevalence of low-quality
information sources. Our work provides insight into the outcomes of Twitter's
complex recommender system at a crucial time period before controversial
changes to the platform and in the midst of nationwide elections and highlights
the need for ongoing study of algorithmic systems and their role in democratic
processes.

</details>


### [236] [Request a Note: How the Request Function Shapes X's Community Notes System](https://arxiv.org/abs/2509.09956)
*Yuwei Chuai,Shuning Zhang,Ziming Wang,Xin Yi,Mohsen Mosleh,Gabriele Lenzini*

Main category: cs.SI

TL;DR: X的社区笔记是一个众包事实核查系统，引入“请求社区笔记”功能旨在提高其可扩展性。然而，该功能对内容选择、贡献者参与和笔记质量的影响尚不清楚。本研究使用98,685个被请求的帖子及其相关笔记，评估请求如何塑造社区笔记系统。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估X的“请求社区笔记”功能对社区笔记系统可扩展性的影响，特别是内容选择、贡献者参与和笔记质量方面。

Method: 使用98,685个被请求的帖子及其相关的社区笔记，分析请求如何影响社区笔记系统的运行。

Result: 研究发现，贡献者优先核查具有更高误导性和来自有更高虚假信息暴露作者的帖子，但会忽略请求者强调的政治内容。贡献者更倾向于标注来自共和党人的帖子，而请求者则更多地提出来自民主党人的帖子。尽管只有12%的帖子获得了顶级贡献者审核的笔记，但这些笔记被认为更有帮助且极化程度更低。

Conclusion: 请求功能在扩展高质量社区事实核查方面存在局限性，但也展现出一定的潜力。

Abstract: X's Community Notes is a crowdsourced fact-checking system. To improve its
scalability, X recently introduced "Request Community Note" feature, enabling
users to solicit fact-checks from contributors on specific posts. Yet, its
implications for the system -- what gets checked, by whom, and with what
quality -- remain unclear. Using 98,685 requested posts and their associated
notes, we evaluate how requests shape the Community Notes system. We find that
contributors prioritize posts with higher misleadingness and from authors with
greater misinformation exposure, but neglect political content emphasized by
requestors. Selection also diverges along partisan lines: contributors more
often annotate posts from Republicans, while requestors surface more from
Democrats. Although only 12% of posts receive request-fostered notes from top
contributors, these notes are rated as more helpful and less polarized than
others, partly reflecting top contributors' selective fact-checking of
misleading posts. Our findings highlight both the limitations and promise of
requests for scaling high-quality community-based fact-checking.

</details>


### [237] [Revealing Higher-Order Interactions in Complex Networks: A U.S. Diplomacy Case Study](https://arxiv.org/abs/2509.10333)
*Arthur Rondeau,Didier Wernli,Roland Bouffanais*

Main category: cs.SI

TL;DR: 外交电报研究的重点在于网络结构，并提出了一种基于随机游走的新方法，该方法可以更准确地捕捉多方互动，并能更好地预测外交关系。


<details>
  <summary>Details</summary>
Motivation: 尽管外交交流在社会科学中已被广泛研究，但其网络结构仍未得到充分探索。

Method: 研究使用2010年维基解密的美国外交电报作为案例，采用网络科学的视角，将外交互动表示为超图，并开发了一个基于随机游走的通用流程来评估这种表示方法与传统的成对图的对比。此外，该流程还应用于立法共同提案和组织电子邮件数据，以评估其在不同类型数据上的表现。

Result: 研究发现，与传统的成对图相比，超图结合适当的随机游走模型能更真实地反映多方、基于群体的互动，从而提供对外交结构更丰富的描述，并在互动预测任务中表现出更优越的性能，能够从现有模式中推断出新的外交关系。

Conclusion: 超图模型结合随机游走动力学能够更准确地捕捉外交互动的多方结构，并在预测任务中取得更好的效果，为理解和分析外交关系提供了一种新的有效工具。

Abstract: Although diplomatic communication has long been examined in the social
sciences, its network structure remains underexplored. Using the U.S.
diplomatic cables released by WikiLeaks in 2010 as a case study, we adopt a
network-science perspective. We represent diplomatic interactions as a
hypergraph and develop a general, random-walk-based pipeline to evaluate this
representation against traditional pairwise graphs. We further evaluate the
pipeline on legislative co-sponsorship and organizational email data, finding
improvements and empirical evidence that clarifies when hypergraph modeling is
preferable to pairwise graphs. Overall, hypergraphs paired with appropriately
specified random-walk dynamics more faithfully capture higher-order,
group-based interactions, yielding a richer structural account of diplomacy and
superior performance on interaction-prediction tasks that enables inferring new
diplomatic relationships from existing patterns.

</details>


### [238] [TikTok Rewards Divisive Political Messaging During the 2025 German Federal Election](https://arxiv.org/abs/2509.10336)
*Kirill Solovev,Chiara Drolsbach,Emma Demirel,Nicolas Pröllochs*

Main category: cs.SI

TL;DR: TikTok上的政治信息，尤其是负面情绪和攻击性言论，更容易获得关注，这可能有利于极端政党。


<details>
  <summary>Details</summary>
Motivation: 研究TikTok等短视频平台如何重塑政治传播，以及哪类政治信息在此类平台上更容易获得关注，特别是受年轻受众欢迎的平台。

Method: 使用计算内容分析方法，分析了2025年德国联邦大选前德国政界人士发布的25,292个TikTok视频数据集。

Result: 研究发现，表达负面情绪（如愤怒、厌恶）和群体敌对的视频比表达积极情绪、亲和力或身份认同的视频更能产生互动。此外，政治光谱两端的极端政党比中间政党更有可能发布此类内容，并更成功地获得互动。

Conclusion: TikTok的平台动态系统性地奖励分裂而非团结的政治传播，这可能使更倾向于利用这种逻辑的极端分子受益。

Abstract: Short-form video platforms like TikTok reshape how politicians communicate
and have become important tools for electoral campaigning. Yet it remains
unclear what kinds of political messages gain traction in these fast-paced,
algorithmically curated environments, which are particularly popular among
younger audiences. In this study, we use computational content analysis to
analyze a comprehensive dataset of N=25,292 TikTok videos posted by German
politicians in the run-up to the 2025 German federal election. Our empirical
analysis shows that videos expressing negative emotions (e.g., anger, disgust)
and outgroup animosity were significantly more likely to generate engagement
than those emphasizing positive emotion, relatability, or identity.
Furthermore, ideologically extreme parties (on both sides of the political
spectrum) were both more likely to post this type of content and more
successful in generating engagement than centrist parties. Taken together,
these findings suggest that TikTok's platform dynamics systematically reward
divisive over unifying political communication, thereby potentially benefiting
extreme actors more inclined to capitalize on this logic.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [239] [Evolution of Coordination Through Institutional Incentives: An Evolutionary Game Theory Approach](https://arxiv.org/abs/2509.10112)
*Ndidi Bianca Ogbo,Zhao Song,The Anh Han*

Main category: cs.GT

TL;DR: 本文利用演化博弈论模型，探讨了在预承诺框架下，如何分配有限的制度资源（奖励或惩罚）以促进协调和合作行为。研究发现，基于奖励的激励措施比基于惩罚的措施更能成功地促进协调，并且在促进参与和确保遵守之间取得最佳资源分配时，可以获得最优结果。


<details>
  <summary>Details</summary>
Motivation: 在生物种群和自组织多主体系统中，基于承诺的机制可以通过明确个体的意图来促进协调和合作行为。然而，这些机制的有效性，尤其是在一次性互动中，依赖于制度支持的持续遵守。尽管在合作和承诺的定量研究方面取得了进展，但大多数应用分析和政策讨论仍然是定性的，并且很少关注用于增强参与度和确保承诺遵守的稀缺制度资源的分配。

Method: 本文开发了一个演化博弈论模型，明确研究了如何在制度激励（奖励或惩罚）的有限预算内进行战略分配，以实现促进参与和确保遵守这两大关键目标。

Result: 研究结果表明，基于奖励的激励方法在促进协调方面始终优于基于惩罚的方法。当资源在促进参与和确保遵守之间得到适当分配时，可以实现最优结果。

Conclusion: 研究结果为了设计旨在促进新技术广泛协调采用的制度激励措施提供了新的见解。

Abstract: There is a broad recognition that commitment-based mechanisms can promote
coordination and cooperative behaviours in both biological populations and
self-organised multi-agent systems by making individuals' intentions explicit
prior to engagement. Yet their effectiveness depends on sustained compliance
supported by institutions, especially in one-off interactions. Despite advances
in quantitative studies of cooperation and commitment, most applied analyses
and policy debates remain largely qualitative, with limited attention to the
allocation of scarce institutional resources between enhancing participation
and ensuring commitment compliance. Herein, we develop an evolutionary
game-theoretic model that explicitly examines the strategic distribution of a
limited budget for institutional incentives, namely rewards or punishments,
aimed at these two critical objectives within pre-commitment frameworks. Our
findings reveal that a reward-based incentive approach consistently yields
greater coordination success than a punishment-based approach, with optimal
outcomes arising when resources are appropriately distributed between
participation promotion and compliance assurance. These findings offer novel
insights for designing institutional incentives to promote broad, coordinated
adoption of new technologies.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [240] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: SAM-BG是一个两阶段框架，用于学习具有结构语义保留的脑图表示，以解决标记脑网络数据有限的问题，并在精神疾病诊断方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标记的脑网络数据有限，使得准确且可解释的精神疾病诊断具有挑战性。现有的自监督学习（SSL）方法依赖的增强策略可能会破坏脑图中的关键结构语义。

Method: 提出SAM-BG框架，包括两个阶段：1. 在少量标记数据上训练边缘掩码器以捕获关键结构语义。 2. 利用提取的结构先验指导感知结构的增强过程，使模型能够学习更具语义意义和鲁棒性的表示。

Result: 在两个真实的精神疾病数据集上进行实验，SAM-BG在小样本标记数据设置下优于最先进的方法，并发现了可提高可解释性的临床相关连接模式。

Conclusion: SAM-BG通过保留结构语义来学习脑图表示，在精神疾病诊断方面表现出优越性，尤其是在标记数据有限的情况下，并提高了模型的可解释性。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [241] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: LLMs 可用于生成求解常微分方程（ODE）问题的代码，通过选择合适的数值求解器和执行稳定性检查来确保科学上的准确性。研究者构建了新的数据集来评估LLMs的能力，并发现经过适当引导和微调的LLMs能够可靠地解决简单的ODE问题。


<details>
  <summary>Details</summary>
Motivation: 直接使用神经网络解决科学任务（如PINNs, Neural ODEs等）在准确性和鲁棒性方面存在挑战。本研究提出利用大型语言模型（LLMs）生成代码，从而利用现有的数值算法，将重点从学习求解函数转移到领域感知型的数值选择上。

Method: 构建了一个包含对抗性“误导性”问题诊断数据集和一个包含1000个ODE任务的大规模基准测试集。评估了开源和闭源LLMs在无引导和有引导提示（结合领域知识）以及现成模型和微调模型上的表现。评估指标包括代码的可执行性和数值有效性（与参考解相比）。

Result: 在有足够上下文和引导提示的情况下，较新的指令遵循模型在可执行性和数值有效性方面均能达到高准确率。许多最新的开源系统在未经微调的情况下表现良好，而较旧或较小的模型则从微调中受益更多。

Conclusion: 初步结果表明，通过仔细的提示和微调，可以创建一个能够可靠解决简单ODE问题的专业LLM代理。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [242] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: D-CAT框架允许在推理时不需要联合传感器，通过解耦跨注意力来对齐模态特定表示，从而提高多模态分类模型的性能，特别是在资源受限的环境中。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态迁移学习方法在训练和推理时都需要配对的传感器数据，这在资源受限的环境中部署时存在局限性。

Method: 提出了一种名为解耦跨注意力迁移（D-CAT）的框架，该框架结合了用于特征提取的自注意力模块和新颖的跨注意力对齐损失，强制对齐传感器特征空间，而无需耦合两种模态的分类流程。

Result: 在三种多模态人类活动数据集（IMU、视频和音频）上评估了D-CAT，结果表明，在同分布场景下，从高性能模态（如视频到IMU）迁移可带来高达10%的F1分数提升；在异分布场景下，即使较弱的源模态（如IMU到视频）也能提高目标性能。

Conclusion: D-CAT通过在推理时实现单传感器推理和跨模态知识迁移，减少了感知系统的硬件冗余，同时保持了准确性，这对于成本敏感或自适应部署至关重要。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [243] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: IDEA是一个能够估计数据集内在维度并进行数据重建的自编码器模型，尤其适用于线性或非线性流形上的数据。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够估计不同类型数据集内在维度并进行数据重建的模型。

Method: 提出了一种名为IDEA（Intrinsic Dimension Estimating Autoencoder）的自编码器模型，其核心在于引入了投影重建损失项（projected reconstruction loss term），并使用重加权双重CancelOut层来构建潜在空间。

Result: 在理论基准测试中，IDEA表现出良好的准确性和高度的通用性，能够准确估计内在维度并与现有技术进行比较。在实际应用中，IDEA成功地估计了由一维自由表面流动数值解生成的数据集的内在维度，并直接在识别出的投影空间中重建了原始解。

Conclusion: IDEA模型不仅能有效估计数据集的内在维度，还能在潜在空间中进行高质量的数据重建，证明了其在理论和实际问题上的鲁棒性和有效性。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [244] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: Meta-RL-Crypto是一个结合了元学习和强化学习的交易机器人，它能自我改进，无需人类监督，并在真实市场数据上表现优于其他基于LLM的基线。


<details>
  <summary>Details</summary>
Motivation: 预测加密货币回报非常困难，因为价格受链上活动、新闻和社交情绪等多种因素影响，且带有标签的训练数据稀缺且昂贵。

Method: Meta-RL-Crypto采用一个基于Transformer的统一架构，结合了元学习和强化学习。该架构中的智能体在三个角色（actor、judge、meta-judge）之间迭代切换，形成一个闭环系统，利用多模态市场输入和内部偏好反馈进行自我改进，不断优化交易策略和评估标准。

Result: 在不同的市场条件下，Meta-RL-Crypto在真实市场技术指标上表现良好，并且优于其他基于LLM的基线。

Conclusion: Meta-RL-Crypto通过一个完全自我的改进过程，成功地解决了加密货币交易中的挑战，并在真实市场数据上展示了优越的性能。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [245] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出一种基于数字孪生和条件神经惠特尼方程的自适应源定位机器学习框架，通过融合有限元外微积分和算子学习，实现了对水动力-输运系统的实时轨迹规划和数据同化，并能有效处理复杂几何形状。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在复杂几何环境中，实时、自适应地进行源定位的机器学习方法，同时保证物理规律的一致性。

Method: 利用条件神经惠特尼方程（CNWF）构建耦合水动力-输运系统的数字孪生，该方法结合了有限元外微积分（FEEC）的数值保证和基于Transformer的算子学习，实现了离散守恒并实时适应传感器数据。通过条件注意力机制识别简化的惠特尼基、简化的积分守恒方程和源场，并采用交错方案结合数字孪生和Lloyd算法进行传感器布局优化。

Result: 所提出的框架在复杂几何形状下，相比于不考虑物理约束的Transformer模型，提高了源定位的准确性。数字孪生模型能够生成物理上可实现的、规则的从传感器数据到源场的映射，并保证了模拟的稳定性和一致性。

Conclusion: 结构保持（Structure preservation）为源识别提供了有效的归纳偏倚（inductive bias），而规则性是源定位的充分条件。所提出的方法能够准确地从传感器数据中恢复源场信息。

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [246] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: KV 缓存是加速长上下文 LLM 推理的关键，但其高内存需求促使了缓存压缩的需求。现有方法多为启发式且缺乏动态预算分配。本文提出了一种统一的缓存压缩框架，通过最小化 Transformer 残差流中的信息损失来实现。该框架分析了层注意力输出损失，并提出了一种跨头比较缓存项的新指标，实现了具有动态头预算的层级压缩。此外，通过对比跨层信息，实现了动态层预算。Lava 是首个统一的缓存压缩和动态预算分配策略，无需训练或组合多种策略。在 LongBench、Needle-In-A-Haystack、Ruler 和 InfiniteBench 等基准测试中，Lava 表现优越，并揭示了动态层预算对生成任务（如代码补全）至关重要，而动态头预算对抽取任务（如抽取式 QA）至关重要。Lava 作为一种完全动态的压缩方法，在各种任务类型中始终保持顶级性能。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 现有 KV 缓存压缩方法多为启发式且缺乏动态预算分配，无法有效应对 LLM 推理中长上下文带来的高内存需求。

Method: 提出了一种统一的 KV 缓存压缩框架，通过最小化 Transformer 残差流中的信息损失来评估和压缩缓存。具体包括：1. 分析层注意力输出损失，提出跨头比较指标，实现动态头预算的层级压缩。2. 对比跨层信息，实现动态层预算。Lava 是首个无需训练或组合多种策略的统一动态缓存压缩方法。

Result: 在 LongBench、Needle-In-A-Haystack、Ruler 和 InfiniteBench 等基准测试中，Lava 表现优于现有方法。实验揭示了动态层预算对生成任务的重要性，以及动态头预算对抽取任务的重要性。Lava 在各种任务类型中均保持顶级性能。

Conclusion: Lava 是一种创新的、完全动态的 KV 缓存压缩方法，通过最小化信息损失实现了高效的动态层级和头预算分配，在不同类型的下游任务中均表现出卓越的性能。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [247] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: 该研究提出了一种名为HACO（Hybrid Adaptive Conformal Offline Reinforcement Learning）的框架，用于管理Medicaid人群的健康，旨在安全、公平且可审计地进行大规模协调和干预。


<details>
  <summary>Details</summary>
Motivation: 为Medicaid人群提供安全、公平且可审计的健康管理计划，该计划需要协调长期的外展服务，同时控制不良利用事件的风险。

Method: HACO框架将风险校准与偏好优化分开，首先训练一个轻量级的风险模型来预测不良事件，然后利用共形预测（conformal prediction）派生一个阈值来屏蔽不安全的操作，最后在保证安全的子集中学习偏好策略。该方法使用了一个包含277万个决策和168,126名患者的真实数据集。

Result: HACO在风险识别方面表现出色（AUC约0.81），并具有校准的阈值（{\tau} ~0.038 at {\alpha} = 0.10），同时保持了高水平的安全覆盖率。对不同年龄、性别和种族群体的分析显示，在估计价值方面存在系统性差异，凸显了公平性审计的重要性。

Conclusion: 共形风险门控（conformal risk gating）与离线强化学习（offline RL）的结合，能够为人口健康管理团队提供保守且可审计的决策支持。

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [248] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: FedBiF通过在本地训练期间直接学习量化模型参数来解决联邦学习中的通信开销问题，通过逐比特更新策略，在保持高精度的同时显著减少通信量，并在准确性方面达到与FedAvg相当的水平。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）虽然能进行分布式模型协同训练且无需共享本地数据，但存在显著的通信开销问题，影响训练效率。现有的量化方法通常在本地训练后应用量化，这会将量化误差引入训练参数，可能降低模型准确性。

Method: 提出了一种名为FedBiF的新型联邦学习框架，它在本地训练期间直接学习量化模型参数。在每个通信轮次中，服务器首先量化模型参数并将其传输给客户端。然后，FedBiF允许每个客户端仅更新多比特参数表示中的一个比特，并冻结其余比特。这种逐比特更新策略将每个参数更新减少到一个比特，同时保持参数表示的高精度。

Result: 在五个广泛使用的数据集上，同时在IID和Non-IID设置下进行了广泛的实验。结果表明，FedBiF不仅实现了卓越的通信压缩，还促进了所得模型的稀疏性。值得注意的是，即使在仅使用1比特/参数（bpp）用于上行链路和3 bpp用于下行链路通信的情况下，FedBiF也能达到与FedAvg相当的准确性。

Conclusion: FedBiF通过在本地训练过程中进行逐比特更新，有效地解决了联邦学习中的通信开销问题，并在不牺牲准确性的前提下实现了显著的通信压缩和模型稀疏性。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [249] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [250] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 本研究提出了一种基于机器学习的飞机疲劳寿命预测方法，以替代传统耗时的方法，并通过实际案例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 飞机在设计和运行阶段的疲劳寿命预测对于确保航空安全至关重要，需要及早检测疲劳裂纹以防止飞行中发生故障。传统的工程方法虽然可靠，但耗时且流程复杂，需要有限元方法（FEM）模拟、载荷谱推导和周期计数技术，并且通常需要多团队协作和大量计算资源。机器学习（ML）为疲劳寿命估算提供了一种有前景的补充，可以加快迭代速度、提高泛化能力，并为传统模拟提供快速的决策指导。

Method: 提出一个基于机器学习（ML）的流程，用于根据飞机在其整个运行寿命中不同任务的飞行参数，来估算不同机翼位置的疲劳寿命。

Result: 在实际的疲劳寿命估算案例中验证了该机器学习流程，得到了准确的预测结果，并进行了全面的统计验证和不确定性量化。

Conclusion: 该流程通过减少昂贵的模拟数量，从而降低了所需的计算和人力资源，是对传统方法的补充。

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [251] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: Gradient-Step Denoiser 可用作即插即用算法中的梯度下降或邻近算子，同时保持最先进的去噪能力。


<details>
  <summary>Details</summary>
Motivation: 分析 Gradient-Step Denoiser 及其在即插即用算法中的用法。

Method: Gradient-Step Denoiser 被训练为显式函数的梯度下降算子或邻近算子，同时保持其去噪能力。

Result: Gradient-Step Denoiser 具有即插即用范例所需的特性。

Conclusion: Gradient-Step Denoiser 是即插即用算法的一个有前途的组成部分。

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [252] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 本研究利用机器学习和多模态融合策略，通过生理信号区分惊吓和惊喜反应，最高准确率达85.7%。


<details>
  <summary>Details</summary>
Motivation: 区分惊吓和惊喜反应对于在高风险环境中（如航空业）保障飞行员绩效和安全至关重要，但现有研究缺乏对这两者联合效应的关注以及区分它们的生理依据。

Method: 利用机器学习和多模态融合策略，基于生理信号区分惊吓和惊喜事件。

Result: 所提出的模型能够可靠地预测这些事件，使用SVM和Late Fusion策略时，最高平均准确率达到85.7%。在包含基线条件的扩展评估中，使用XGBoost和Late Fusion策略，成功区分惊吓、惊喜和基线状态，最高平均准确率为74.9%。

Conclusion: 本研究成功地开发了一种基于生理信号和机器学习的方法，能够区分惊吓和惊喜这两种对注意力有影响的事件，并验证了其在高风险环境中的潜在应用价值。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [253] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: DSAC的actor和critic熵耦合导致性能不佳，解耦后性能可与DQN媲美。提出的新框架允许使用m步贝尔曼算子和策略优化方法，理论上保证收敛，经验上在Atari游戏上表现接近DQN。


<details>
  <summary>Details</summary>
Motivation: DSAC的actor和critic熵耦合是其在离散动作环境中性能不佳的主要原因。

Method: 解耦DSAC的actor和critic熵，提出一个灵活的、可支持m步贝尔曼算子和策略优化方法的离线actor-critic框架，该框架包含DSAC作为特例。

Result: 解耦后的DSAC性能可与DQN媲美；新框架在Atari游戏上表现接近DQN，即使没有熵正则化或显式探索。

Conclusion: 提出的离线actor-critic框架通过解耦actor和critic熵、引入m步贝尔曼算子和策略优化等方法，解决了DSAC在离散动作环境中的性能问题，并在理论和经验上都得到了验证。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [254] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: HGEN是一种用于异构图的集成学习框架，通过元路径和变换优化来提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 异构图中节点类型、节点特征和局部邻域拓扑的异质性给集成学习带来了挑战，尤其是在适应不同的图学习器方面。

Method: HGEN框架通过元路径和变换优化流程集成多个学习器。具体来说，HGEN使用元路径结合随机丢弃来创建等位基因图神经网络（GNN），从而训练和对齐基础图学习器以进行后续集成。HGEN包含两个关键组件：1）残差注意机制，用于校准不同元路径的等位基因GNN，强制节点嵌入关注信息量更大的图；2）相关性正则化项，用于扩大由不同元路径生成的嵌入矩阵之间的差异，以丰富基础学习器的多样性。

Result: HGEN的收敛性得到了分析，并证明了其比简单投票具有更高的正则化幅度。在五个异构网络上的实验表明，HGEN的性能始终大幅优于最先进的竞争对手。

Conclusion: HGEN通过引入残差注意机制和相关性正则化项，成功解决了异构图集成学习中的挑战，并取得了优于现有方法的性能。

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [255] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 现有模型在进行推理时，通常只考虑并行生成方法，而忽略了增量式解码方法，并且主要关注token使用量，而忽略了延迟。本文提出了一种新的推理时间扩展框架，该框架将推理时间扩展视为一个动态计算分配和方法选择问题，可以根据每次查询的需要动态地决定采用哪种策略以及分配多少计算资源。该框架同时考虑了token成本和实际的运行时间延迟，这对于用户体验和agentic工作流至关重要。实验结果表明，该方法在推理效率和准确性之间取得了良好的平衡，优于静态策略。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时间扩展方法主要关注并行生成，忽略了增量式解码，并且主要考虑token使用量而非延迟，这不能满足实际应用需求，特别是在需要快速响应的agentic工作流中。

Method: 将推理时间扩展问题建模为动态计算分配和方法选择问题，该框架能够根据每个查询的需要动态地选择最合适的生成策略（包括并行和增量式解码）并分配相应的计算资源。该框架同时考虑了token成本和实际的运行时间延迟。

Result: 在推理效率和准确性之间取得了良好的平衡，优于静态策略，并且在实际部署中具有可行性。

Conclusion: 本文提出的动态计算分配和方法选择框架能够有效提升LLM在推理时的性能，通过同时考虑token成本和延迟，实现了比现有方法更好的准确性-成本权衡，并能在实际应用中有效部署。

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [256] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 该研究提出了一种基于可观测量的新型热力学拉格朗日方法，用于从数据中计算耗散动力系统的演化，并构建了能够保证熵增的神经网络。


<details>
  <summary>Details</summary>
Motivation: 许多基于数据的物理系统演化计算方法存在局限，尤其是在可观测量与定义相空间的变量不一致的情况下。本研究关注耗散动力系统，其相空间变量（如动量和熵）通常不可直接观测，因此需要新的方法来解决这一挑战。

Method: 提出了一种基于热力学拉格朗日量的新型方法，并构建了能够保证熵增的神经网络。该方法仅利用可观测量来描述相空间演化。

Result: 所提出的神经网络能够基于有限的数据点和较少的系统参数，有效地描述相空间演化。

Conclusion: 该研究成功地开发了一种仅基于可观测量的数据计算框架，用于耗散动力系统的演化，并有效解决了动量和熵不可直接观测的问题，同时保证了熵增。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [257] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: 通过患者增强心电图（CAPE）基础模型，研究了队列构成对对比学习的影响，并提出了IDB策略来提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 对比学习在自监督预训练中被广泛应用，但其对队列构成的依赖性仍有待探索。

Method: 提出CAPE 基础模型，在跨越三大洲的四个队列（n = 5,203,352）上进行预训练，并评估了人口统计、健康状况和人群多样性对下游预测任务性能的影响。提出 IDB 策略来解决多中心、多样化预训练队列导致的泛化能力下降问题。

Result: 下游性能受预训练队列的分布特性（包括人口统计和健康状况）影响。多中心、人口统计多样化的预训练队列提高了分布内准确性，但降低了对比学习方法的分布外（OOD）泛化能力，因为它编码了队列特异性的人为因素。IDB 策略提高了 OOD 鲁棒性。

Conclusion: 该研究为开发临床上公平且可泛化的基础模型提供了重要的见解。

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [258] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 通过参数高效的微调 (LoFT) 来解决长尾半监督学习问题，并在开放世界场景下进行了扩展 (LoFT-OW)。


<details>
  <summary>Details</summary>
Motivation: 解决现有长尾半监督学习方法在从头开始训练时存在模型过度自信和伪标签质量低的问题，并将长尾半监督学习扩展到开放世界场景。

Method: 将长尾半监督学习（LTSSL）融入基础模型微调范式，提出 LoFT 框架，并通过 LoFT-OW 扩展以处理开放世界场景下的 OOD 样本。

Result: LoFT 框架通过微调基础模型生成更可靠的伪标签，从而提升了长尾学习的效果。LoFT-OW 提高了区分能力。实验表明，在仅使用 1% 的无标签数据的情况下，该方法仍优于现有方法。

Conclusion: LoFT 通过参数高效微调基础模型，有效解决了长尾半监督学习中的挑战，并在开放世界场景下展现出优越性能。

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [259] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [260] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: DyKen-Hyena通过动态卷积核调制文本特征提取，以解决多模态意图识别中跨模态信息干扰问题，并在MIntRec和MIntRec2.0基准上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态意图识别模型在融合多模态信息时，可能引入不相关或冲突的信息，从而影响性能。现有的融合机制（如多头注意力）往往是在特征序列层面进行融合，然后加回到原始表示，这可能导致语言特征被非语言信号干扰，并且未能捕捉到非语言线索应如何精细地调节文本含义。

Method: DyKen-Hyena模型将音频视觉线索转化为动态的、按token（词元）的卷积核，直接调制文本特征的提取过程。这种精细的调控方式，实现了从特征融合到处理调制的范式转变。

Result: DyKen-Hyena模型在MIntRec和MIntRec2.0基准上取得了最先进的成果，特别是在“范围外检测”任务上，F1分数提高了+10.46%，证明了该方法能够生成更鲁棒的意图表示。

Conclusion: DyKen-Hyena模型通过动态卷积核实现了对文本特征提取的精细调制，有效解决了多模态意图识别中的信息干扰问题，并显著提升了模型在各项任务上的性能，尤其是在鲁棒性方面。

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [261] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 本文提出了一种无需训练的自适应令牌合并框架，用于在资源受限的边缘设备上部署大型Transformer模型。该方法通过动态合并语义冗余的令牌来压缩Transformer表示，实现了计算和通信成本的大幅降低，同时保持了模型精度。


<details>
  <summary>Details</summary>
Motivation: 大型Transformer模型在语义通信中至关重要，但其高昂的计算和通信成本限制了其在资源受限的边缘设备上的部署。因此，需要一种在不重新训练的情况下降低Transformer模型成本的方法。

Method: 本文提出了一种自适应令牌合并（adaptive token merging）的训练框架。该框架在运行时通过根据每层相似度阈值选择性地合并语义冗余的令牌来压缩Transformer表示。与先前固定的降维比例不同，该方法将合并与输入冗余直接耦合，实现了数据依赖的自适应，从而在效率和任务相关性之间取得平衡，且无需重新训练。该方法将合并策略的发现视为一个多目标优化问题，并利用贝叶斯优化来获得准确性、推理成本和通信成本之间的帕累托最优权衡。

Result: 在ImageNet分类任务上，该方法实现了与未经修改的Transformer相当的准确性，同时浮点运算次数减少了30%，通信成本降低了80%以上。在视觉问答任务上，该方法实现了与完整LLaVA模型相当的性能，但计算量不到三分之一，带宽消耗不到十分之一。此外，该方法在变化的信道条件下表现出鲁棒性，并能有效抵抗模型反演攻击，提供内置的隐私保护。

Conclusion: 所提出的自适应令牌合并框架为在资源受限的边缘智能场景中部署强大的Transformer模型提供了一种实用且通用的解决方案。

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [262] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine是一个框架，通过从可解释模型中提取的“如果-那么”规则来指导基于提示的生成，并采用双粒度过滤策略来处理数据不平衡，从而提高合成表格数据的质量，尤其是在数据稀疏的领域。


<details>
  <summary>Details</summary>
Motivation: 现有的表格生成方法（如GANs、扩散模型和微调LLMs）通常需要大量参考数据，这在数据稀疏的领域中限制了它们的有效性。基于提示的LLMs虽然灵活，但往往无法捕捉特定数据集的特征-标签依赖性并生成冗余数据，导致下游任务性能下降。

Method: ReFine框架包含两个主要部分：1. 从可解释模型中提取符号化的“如果-那么”规则，并将其嵌入提示中，以明确指导生成过程，使其符合特定领域的特征分布。2. 采用双粒度过滤策略，抑制过度抽样模式，并有选择地优化稀有但信息量大的样本，以减少分布不平衡。

Result: 在各种回归和分类基准测试的广泛实验表明，ReFine的性能持续优于最先进的方法，在回归任务上R平方值提高了0.44，在分类任务上F1分数提高了10.0%。

Conclusion: ReFine框架通过结合可解释规则引导和双粒度过滤，有效解决了现有表格生成方法在数据稀疏和分布不平衡情况下的局限性，并在下游任务中取得了显著的性能提升。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [263] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 本文提出一种基于机器学习的方法，仅利用虚拟机（VM）的资源利用率指标，在无法访问物理测量接口的情况下，预测虚拟服务器的能耗。


<details>
  <summary>Details</summary>
Motivation: 在虚拟化环境中（如云），直接进行能耗测量通常是不可行的。然而，能耗感知调度、成本优化和独立于物理主机进行能耗估算的需求日益增长。因此，在缺乏主机特权访问的情况下，仅从虚拟机层面进行能耗估算是一个关键的挑战。

Method: 利用从客户虚拟机收集的资源利用率指标，训练梯度提升回归模型（Gradient Boosting Regressor）来预测主机通过RAPL测量的能耗。

Result: 实验表明，该方法在多种工作负载下实现了高预测精度和高解释方差（$0.90 \leq R^2 \leq 0.97$），证明了仅从客户机层面进行能耗估算的可行性。

Conclusion: 本研究首次实现了在无特权主机访问的情况下，仅基于客户机资源进行能耗估算，为虚拟化环境中的能耗管理提供了新的途径。

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [264] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 深度回归模型存在神经标度律，其损失与训练数据量和模型容量之间存在幂律关系，表明增加数据量可以显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然神经标度律在深度学习模型开发中很重要，但它们在深度回归模型中的应用尚不明确。本研究旨在探讨深度回归模型中的神经标度律。

Method: 通过使用扭曲范德华磁体的参数估计模型，在多种神经网络架构（包括全连接网络、残差网络和视觉变换器）上，对损失与训练数据集大小和模型容量之间的关系进行经验性研究。

Result: 在广泛的参数范围内观察到损失与训练数据集大小和模型容量之间存在幂律关系。标度指数在1到2之间，具体取决于回归参数和模型细节。

Conclusion: 深度回归模型表现出一致的标度行为，并且具有较大的标度指数，这表明增加数据量可以显著提高模型性能。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [265] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: SMoE-VAE在QuickDraw数据集上表现优于监督学习方法，能够学习到超越人类定义的类别界限的有意义的子类别结构。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络的内部组织是深度学习可解释性的一个基本挑战。

Method: 提出并测试了一种新颖的稀疏专家混合变分自编码器（SMoE-VAE）架构，并在QuickDraw数据集上进行了实验，比较了无监督专家路由和有监督基线。

Result: 无监督路由在重构性能上优于有监督基线，模型学到的专家能够识别出超越人类定义的类别界限的有意义的子类别结构。t-SNE可视化和重构分析表明，MoE模型发现的数据结构比预定义的标签更符合模型的优化目标。研究还揭示了数据集大小对专家专业化的影响。

Conclusion: SMoE-VAE模型能够发现比预定义标签更符合模型目标的数据内在结构，为设计高效的MoE架构提供了指导。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [266] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 提出了一种用于两字典场景的低秩编码模型AODL，并通过交替优化进行求解，在数据重建和缺失值填充方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有字典学习方法在多字典场景下，编码计算复杂度高，难以学习到稀疏且准确的表示。

Method: 提出了一种两字典场景下的低秩编码模型AODL，通过交替优化方法在稀疏编码矩阵和字典之间进行学习，并证明了其收敛性。同时，研究了学习字典所需的数据复杂度。

Result: AODL模型可以将数据重建质量提高90%，学习到的字典能够揭示数据中的可解释模式，并在合成和真实数据集上验证了其在数据重建和缺失值填充的有效性。

Conclusion: AODL模型能够学习到稀疏且可解释性强的字典，在保证数据重建质量的同时，降低了对样本数量的要求，并在实际应用中表现出优越的性能。

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [267] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: PFAs can be simulated by symbolic feedforward neural networks, which are learnable and equivalent to PFAs.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between symbolic computation and deep learning by unifying probabilistic automata theory with neural architectures under a rigorous algebraic framework.

Method: Representing state distributions as vectors and transitions as stochastic matrices, enabling probabilistic state propagation via matrix-vector products, and using symbolic simulators that are learnable with standard gradient descent.

Result: Formal characterization of probabilistic subset construction, ε-closure, and exact simulation via layered symbolic computation, proving equivalence between PFAs and specific classes of neural networks, and showing that these symbolic simulators recover the exact behavior of ground-truth PFAs when trained on labeled sequence data.

Conclusion: The proposed neural network architecture provides a parallel, interpretable, and differentiable simulation of PFA dynamics without recurrence, and its learnability is a key contribution that unifies probabilistic automata theory with neural architectures.

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [268] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: FedRP算法通过随机投影和ADMM优化框架，在保护用户隐私和降低通信成本的同时，提高了模型准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决联邦学习（FL）在保护用户隐私和管理通信成本方面面临的挑战，以在敏感领域（如物联网和医疗数据分析）实现高效的协同模型训练。

Method: 提出了一种名为FedRP的新型联邦学习算法，该算法结合了随机投影技术和交替方向乘子法（ADMM）优化框架。FedRP通过随机投影降低模型参数的维度来减少通信成本，并提供$(\epsilon, \delta)$-差分隐私保证，以防御数据重建攻击。

Result: 实验结果表明，FedRP在模型准确性方面表现出色，并且在隐私保护和通信效率方面优于现有的方法，包括传统的差分隐私方法和FedADMM。

Conclusion: FedRP算法成功地在保护用户隐私和降低通信成本的同时，保持了高水平的模型准确性，为联邦学习在处理敏感数据方面提供了一个有效的解决方案。

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [269] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 原始TabPFN在不确定性校准方面优于集成VBLL的版本，尽管VBLL旨在提高不确定性估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域（如医学诊断和刑事司法）中使用预测模型时，可靠的不确定性估计至关重要。本研究旨在评估将VBLL集成到TabPFN中在不确定性校准方面的表现。

Method: 将VBLL（一种轻量级的变分方法）集成到TabPFN（一种用于表格数据的生成Transformer架构）中，并在三个基准的医学表格数据集上进行实验，比较原始TabPFN和集成VBLL的TabPFN在不确定性校准方面的性能。

Result: 实验结果显示，在所有三个数据集上，原始TabPFN在不确定性校准方面始终优于集成VBLL的TabPFN，这与预期相反。

Conclusion: 尽管VBLL旨在提高不确定性估计，但在此次研究的特定设置（集成到TabPFN用于表格数据的不确定性校准）中，它并未能带来预期的性能提升，甚至可能损害了不确定性校准的性能。

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [270] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: KAN-SR是一个基于Kolmogorov Arnold Networks（KANs）的符号回归框架，它采用分而治之的方法，并结合了深度学习技术和简化策略，成功地从Feynman SRSD数据集中恢复了真实方程。此外，该框架与神经控制微分方程结合，能够精确模拟生物过程系统动力学。


<details>
  <summary>Details</summary>
Motivation: 符号回归旨在寻找最适合给定数据集的数学方程，传统方法常采用遗传编程。本研究旨在利用深度学习技术，特别是KANs，并结合简化策略，来改进符号回归的效果。

Method: 提出了一种名为KAN-SR的新型符号回归框架，该框架基于Kolmogorov Arnold Networks（KANs），并采用分而治之的方法。该框架结合了深度学习技术、KANs的特定应用以及平移对称性和可分离性等简化策略。此外，还将该框架与神经控制微分方程相结合。

Result: KAN-SR能够从Feynman SRSD数据集中恢复出真实的数学方程。当与神经控制微分方程结合时，该框架能够精确地模拟一个计算机生物过程系统（in-silico bioprocess system）的动力学。

Conclusion: KAN-SR框架在符号回归任务上取得了成功，能够恢复真实方程。此外，它在模拟生物过程系统动力学方面也表现出精确性，为工程领域其他动态系统的建模提供了新的可能性。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [271] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出了一种信息几何投影框架，用于参数化贝叶斯联邦学习（BFL）中的个性化，该框架可以通过投影全局模型到用户本地模型的邻域来实现全局泛化和本地专业化之间的可调权衡，并能在温和假设下以闭式解的形式推导出统计流形上的质心计算，从而实现免费个性化。


<details>
  <summary>Details</summary>
Motivation: 现有的贝叶斯联邦学习（BFL）方法通常依赖于马尔可夫链蒙特卡洛（MCMC）采样或变分推断，并结合个性化机制来适应本地数据分布，但忽略了信息几何的视角。

Method: 提出了一种信息几何投影框架，通过将全局模型投影到用户本地模型的邻域来实现个性化，并在统计流形上计算质心，推导出闭式解。

Result: 在变分学习设置中，使用改进的变分在线牛顿（IVON）优化器，并将其应用于BFL的通用聚合方案。在异构数据分布下的实证评估证实，该方法以最小的计算开销有效平衡了全局和本地性能。

Conclusion: 所提出的信息几何投影框架能够以成本效益的方式实现BFL的个性化，并在全局泛化和本地专业化之间取得良好的权衡。

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [272] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 该论文提出 BenchECG 标准化评估基准和 xECG 模型，以促进心电图（ECG）基础模型的研究和发展。


<details>
  <summary>Details</summary>
Motivation: 现有心电图（ECG）基础模型的研究缺乏统一的评估标准，不同研究采用不同的数据集和任务，阻碍了公平比较和模型进展。

Method: 提出 BenchECG，一个包含多种公共 ECG 数据集和任务的标准化基准。提出 xECG，一个基于 xLSTM 并使用 SimDINOv2 自我监督学习训练的模型。

Result: xECG 在 BenchECG 基准测试中取得了最佳分数，表现优于现有的最先进模型，并且是唯一一个在所有数据集和任务上都表现出色的公开可用模型。

Conclusion: BenchECG 标准化了评估方法，有望加速 ECG 表示学习的进展。xECG 设定了未来 ECG 基础模型的新基准。

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [273] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 Fed-MARL 的联邦多智能体强化学习框架，用于 6G 超密集边缘环境中的资源管理。该框架通过跨层（MAC 和应用层）进行任务卸载、频谱接入和 CPU 能量自适应的协同，实现了高能效、隐私保护和低延迟的资源管理。


<details>
  <summary>Details</summary>
Motivation: 6G 网络朝着超密集、智能化的边缘环境发展，在严格的隐私、移动性和能源限制下进行高效的资源管理至关重要。

Method: 本文提出了一种联邦多智能体强化学习（Fed-MARL）框架，结合了 MAC 层和应用层的跨层编排。每个智能体使用深度循环 Q 网络（DRQN）来学习去中心化的任务卸载、频谱接入和 CPU 能量自适应策略。引入了基于椭圆曲线迪菲-赫尔曼密钥交换的安全聚合协议来保护隐私。将资源管理问题建模为具有多目标奖励函数的部分可观察马尔可夫决策过程（POMMDP），以优化延迟、能效、频谱效率、公平性和可靠性。

Result: 仿真结果表明，Fed-MARL 在任务成功率、延迟、能效和公平性方面优于中心化 MARL 和启发式基线方法，同时还能在动态、资源受限的 6G 边缘网络中提供强大的隐私保护和可扩展性。

Conclusion: Fed-MARL 框架能够有效地实现 6G 超密集边缘环境中资源管理的高能效、隐私保护和低延迟，满足 URLLC、eMBB 和 mMTC 等 6G 服务要求。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [274] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 量子纠错是实用量子计算的关键，但现有解码器在处理表面码时存在误差概率分布不确定性问题。本研究提出一种新方法，通过神经网络插值连续函数来近似测量，重新优化解码器模型，提高了精度。该方法对代码距离和网络架构具有普适性，表明将表面码解码视为回归问题并利用深度学习是一种有效策略。


<details>
  <summary>Details</summary>
Motivation: 现有量子纠错的表面码解码器在处理输入时，由于正确预测的不唯一性，只能获得误差概率分布，无法精确定位和纠正错误。

Method: 提出一种新颖技术，利用神经网络将测量值近似为连续函数，并通过数学插值进行优化，以重新构建解码器模型。

Result: 与原始模型相比，在代码距离为5和7的多层感知器解码器，以及代码距离为5的卷积神经网络、循环神经网络和Transformer解码器中，重新优化的解码器都显示出更高的准确性。

Conclusion: 所提出的通过神经网络插值连续函数来重新优化解码器的方法，在提高表面码解码准确性方面是普遍有效的，不依赖于代码距离或网络架构。将表面码解码问题重新构建为深度学习可以处理的回归问题是一种有用的策略。

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [275] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: 深度残差网络(ResNets)在标准随机初始化下的梯度下降训练会收敛到一个与宽度M无关的神经ODE训练动力学。我们推导了在特定残差尺度下，模型输出与极限之间的误差界限，并进行了经验验证。


<details>
  <summary>Details</summary>
Motivation: 研究深度残差网络(ResNets)在标准随机初始化下的梯度下降训练动力学，特别是当网络深度L趋于无穷时的情况。

Method: 通过数学分析和经验验证，推导了在特定残差尺度下，深度残差网络训练动力学的误差界限，并探讨了特征学习和lazy ODE两种情况。

Result: 在特定条件下，证明了训练动力学收敛到神经ODE，并给出了误差界限。证明了残差尺度如何影响特征学习和lazy ODE。对于两层感知器块的ResNets，给出了实现完全特征学习所需的残差尺度，并给出了相应的误差界限。

Conclusion: 深度残差网络的训练动力学可以被理解为神经ODE的随机近似。残差尺度在决定网络是进行完全特征学习还是进入lazy ODE状态方面起着关键作用。

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [276] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出了一种可扩展的框架，用于学习高分辨率3D物理模拟的确定性和概率神经代理模型。该框架采用混合CNN-Transformer骨干架构，在速度和准确性方面显著优于现有方法。模型可以先在小的模拟域块上进行预训练，然后融合得到全局解，并通过序列到序列模型处理长程依赖关系，从而减少了高分辨率数据集的内存和计算需求。实验证明了该模型在学习14种不同的3D偏微分程方面的能力，并成功扩展到512^3分辨率的各向同性湍流模拟。此外，该网络还可以作为扩散模型，生成不同雷诺数下湍流3D通道流的概率样本，并准确捕捉其统计特性。


<details>
  <summary>Details</summary>
Motivation: 为高分辨率3D物理模拟提供一个可扩展的框架，以学习确定性和概率神经代理模型，解决现有方法在速度和准确性上的不足。

Method: 提出了一种混合CNN-Transformer骨干架构，允许在小块域上进行预训练，并通过序列到序列模型处理长程依赖关系，以减少内存和计算需求。

Result: 所提出的骨干架构在同时学习14种不同的3D偏微分程方面，相比基线方法表现出优越性。模型成功扩展到512^3分辨率的各向同性湍流模拟。作为扩散模型，该网络能够准确捕捉不同雷诺数下湍流3D通道流的统计特性。

Conclusion: 所提出的混合CNN-Transformer框架是一种通用且可扩展的方法，适用于学习各种3D物理模拟的神经代理模型，能够高效处理高分辨率数据并准确捕捉物理现象。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [277] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 本文提出了一种新的集成学习框架，通过最小化预期利润和利润方差来提高模型鲁棒性和泛化能力，并简化了优化过程，在多个数据集上取得了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于利润的集成学习方法只关注最大化预期利润，忽略了利润方差，这限制了模型的泛化能力，并使其在噪声或不平衡数据集上容易过拟合。此外，在概率单纯形内优化集成权重会带来计算效率低下和可扩展性问题。

Method: 本文提出了一种新的集成学习框架，该框架将利润方差显式地纳入损失函数。通过联合优化负预期利润及其方差，并利用单位球面上的重新参数化来简化优化过程，提高了计算效率。

Result: 与传统方法相比，所提出的方法在多个基准数据集上始终表现出优越的性能，证明了其有效性和实用性。

Conclusion: 所提出的集成学习框架通过联合优化利润和利润方差，并采用简化的优化过程，提高了模型的鲁棒性和泛化能力，克服了传统方法的局限性。

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [278] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 提示注入可操纵LLM同行评审，且LLM评审倾向于接受。 


<details>
  <summary>Details</summary>
Motivation: 研究LLM在科学同行评审中的应用，特别是作者使用隐藏的提示注入来操纵评审分数的可能性。

Method: 对2024年ICLR的1000篇论文评审进行系统性评估，使用多种LLM。

Result: I) 简单的提示注入非常有效，接受率高达100%。 II) LLM评审普遍存在偏见，倾向于接受（超过95%）。

Conclusion: 提示注入对LLM同行评审具有实际可行性，且LLM评审普遍存在接受偏见，这对当前关于LLM在同行评审中应用的讨论具有重要影响。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [279] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 通过结合模拟数据和迁移学习，利用神经推荐系统（NRS）框架，利用稀疏的实验数据集，对离子液体的关键热物理性质进行可靠预测，并支持跨属性知识迁移。


<details>
  <summary>Details</summary>
Motivation: 准确预测离子液体的关键热物理性质具有挑战性，因为其化学设计空间广阔且实验数据有限。

Method: 提出一个数据驱动的迁移学习框架，利用神经推荐系统（NRS）。该框架包括两个阶段：1. 在COSMO-RS模拟数据上预训练NRS模型，学习离子结构的特定嵌入；2. 使用这些嵌入和实验数据微调前馈神经网络，以预测不同温度和压力下的性质。该框架支持同一属性内和跨属性的知识迁移。

Result: 该框架在密度、粘度、表面张力、热容量和熔点这五种关键性质上表现良好。通过使用密度、粘度、热容量的预训练模型来微调所有五个目标性质的模型，显著提高了其中四种性质的预测性能。该模型还能稳健地外推到未知的离子液体。最终模型能够预测超过70万种离子液体的性质，为工艺设计中的离子液体筛选提供了可扩展的解决方案。

Conclusion: 结合模拟数据和迁移学习是克服实验数据稀疏性问题的有效方法，能够实现离子液体关键热物理性质的可靠预测。

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [280] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 本文提出了一种名为Proof of AutoML的新型区块链共识机制，利用机器学习回归模型生成不可预测的随机数（nonce），以支持灾难场景下基于SDN的能源交易。


<details>
  <summary>Details</summary>
Motivation: 在灾难场景下，传统能源设施可能失效，需要安全的、可追溯的能源交易，因此需要健壮且不可预测的随机数生成来确保交易的完整性。

Method: 提出了一种SDN架构，并利用机器学习回归模型（Gradient Boosting, LightGBM, Random Forest, Extra Trees, K-Nearest Neighbors）生成随机数。评估这些模型生成随机数的能力，而不是预测准确性。

Result: 随机性分析表明，Random Forest和Extra Trees回归模型表现出完全依赖随机性，而Gradient Boosting、K-Nearest Neighbors和LightGBM得分分别为97.6%、98.8%和99.9%。

Conclusion: 某些机器学习模型，特别是基于树的模型，可以作为区块链安全、SDN支持的能源交易基础设施的有效且轻量级的随机数生成器，以应对灾难条件。

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [281] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: CDQAC是一种新的离线强化学习算法，可以直接从历史数据中学习调度策略，无需在线交互，并能改进次优训练数据，在JSP和FJSP问题上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习方法在处理JSP和FJSP问题时需要大量模拟交互，且策略初始化随机导致样本效率低下，而CDQAC旨在解决这些局限性。

Method: CDQAC结合了基于分位数的Critic和延迟策略更新，估计每个机器-操作对的返回分布，而非直接选择，从而从历史数据中学习调度策略。

Result: CDQAC在各种数据集上表现出色，优于数据生成启发式方法和最先进的离线/在线强化学习基线，并且样本效率高，仅需10-20个训练实例即可学习高质量策略。出人意料的是，CDQAC在随机启发式生成的数据上训练效果优于遗传算法和优先调度规则生成的数据。

Conclusion: CDQAC是一种有效的离线强化学习算法，能够从历史数据中学习高质量的调度策略，并且在JSP和FJSP问题上具有优越的性能和高样本效率。

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [282] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 该研究提出了一种名为GraphCSVAE的新型框架，用于分析灾后物理脆弱性。该框架结合了深度学习、图表示和分类概率推断，并利用时间序列卫星数据和专家知识。研究在孟加拉国和塞拉利昂的两个灾区进行了案例分析，揭示了灾后物理脆弱性的时空动态，为灾后风险减少提供了有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 全球许多机构在灾后持续监测灾害风险变化方面面临挑战，这制约了决策者评估《2015-2030年仙台减少灾害风险框架》进展的能力。尽管在通过地球观测和数据驱动方法对危害和暴露进行大规模建模方面已取得显著进展，但在对风险方程中同样重要但具有挑战性的要素——物理脆弱性——进行建模方面进展有限。

Method: 提出了一种名为GraphCSVAE（图分类结构变分自编码器）的新型概率数据驱动框架，通过整合深度学习、图表示和分类概率推断，并利用时间序列卫星数据和先验专家知识系统来模拟物理脆弱性。引入了弱监督一阶转移矩阵，以反映两个受灾地区（孟加拉国受气旋影响的沿海Khurushkul社区和塞拉利昂受山体滑坡影响的弗里敦市）物理脆弱性的时空分布变化。

Result: 研究揭示了灾后区域物理脆弱性的动态变化，并为区域性时空审计和可持续的灾后减灾策略提供了有价值的见解。

Conclusion: 所提出的GraphCSVAE框架能够有效地模拟灾后物理脆弱性的时空动态，为灾后风险评估和减灾策略提供支持。

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [283] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 该论文提出了一种简单有效的卷积模块用于长期时间序列预测，该模块受ARIMA模型启发，包含捕捉趋势（自回归）和优化局部变化（移动平均）的两个卷积组件，可以直接进行多步预测，并易于扩展到多元设置，在九个基准数据集上的实验表明该方法ARMA具有竞争力，尤其是在具有强趋势变化的数据集上，同时保持了结构简单性，并且该模块内在地编码了绝对位置信息，可作为序列模型的轻量级位置嵌入替代品。


<details>
  <summary>Details</summary>
Motivation: 旨在提出一种简单有效的卷积模块用于长期时间序列预测，并解决传统ARIMA模型需要迭代进行多步预测的问题。

Method: 提出了一种受ARIMA启发的卷积模块，包含两个卷积组件：一个用于捕捉趋势（自回归），另一个用于优化局部变化（移动平均）。该模块可以直接进行多步预测，并易于扩展到多元设置。

Result: 在九个广泛使用的数据集上进行了实验，结果表明该方法ARMA具有竞争力，尤其是在具有强趋势变化的数据集上，同时保持了结构简单性。分析表明，该模块内在地编码了绝对位置信息，可作为序列模型的轻量级位置嵌入替代品。

Conclusion: 该论文提出的卷积模块简单有效，能够直接进行多步预测，适用于长期时间序列预测，并且具有作为序列模型轻量级位置嵌入替代品的潜力。

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [284] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: dataset condensation (DC) aims to create a small synthetic dataset that mimics a larger one for training models, with recent work connecting it to distribution approximation. This paper unifies existing DC methods and generalizes the task using discrepancy measures, allowing for objectives beyond just generalization, like robustness and privacy.


<details>
  <summary>Details</summary>
Motivation: The goal is to construct a significantly smaller synthetic dataset that allows a model trained from scratch on it to achieve comparable or superior generalization performance to a model trained on the original, larger dataset. Recent advances connect DC to data distribution approximation.

Method: The paper presents a unified framework that encompasses existing DC methods and extends the task-specific notion of DC to a more general and formal definition using notions of discrepancy, which quantify the distance between probability distributions.

Result: The framework broadens the objective of DC beyond generalization, accommodating additional objectives such as robustness, privacy, and other desirable properties.

Conclusion: The presented unified framework generalizes dataset condensation using discrepancy measures, allowing for a broader range of objectives beyond simple performance metrics.

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [285] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 我们提出了一个无限维度希尔伯特空间中修正流的严格函数形式，它扩展了现有的函数流匹配和概率流ODE理论，并在实验中显示出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 将修正流的现有理论扩展到无限维度空间，并解决现有函数流匹配理论中的限制。

Method: 在无限维度希尔伯特空间中建立了修正流的函数形式，利用了连续性方程的叠加原理，并将其扩展到函数流匹配和函数概率流ODE。

Result: 成功地将修正流扩展到无限维度，为函数流匹配提供了更宽松的理论基础，并在实验中证明了该方法优于现有的函数生成模型。

Conclusion: 所提出的无限维度修正流框架是有效的，并且为未来的研究开辟了新的途径。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [286] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: VIG是一种新的主动学习方法，通过考虑数据集范围内的预测不确定性来选择图像进行标记，在减少标记工作量的同时实现了接近全监督学习的准确性，并具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 目前相机陷阱监测生物多样性的关键瓶颈在于对图像数据进行物种识别的标注资源有限。主动学习虽然提供了一种解决方案，但通常只关注个体预测的不确定性，忽略了整个数据集的潜在不确定性。

Method: 提出了一种名为Vendi信息增益（VIG）的新主动学习策略，该策略根据图像对整个数据集预测不确定性的影响来选择图像，从而同时捕捉信息量和多样性。

Result: 在Snapshot Serengeti数据集上的实验表明，VIG在标记数据量不到10%的情况下，实现了接近全监督学习的预测准确率，并且在各种指标和批处理大小上都持续优于标准基线方法，还能在特征空间中收集到更多样化的数据。

Conclusion: VIG在生态学领域之外也具有广泛的应用潜力，其研究结果突显了该方法在数据受限环境下进行生物多样性监测的价值。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [287] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: Masked diffusion large language models (dLLMs) can be improved with reinforcement learning (RL) by using their inpainting ability to guide exploration, leading to a new framework called IGPO that achieves state-of-the-art results on mathematical benchmarks.


<details>
  <summary>Details</summary>
Motivation: Traditional reinforcement learning (RL) for large language models (LLMs) suffers from exploration challenges due to sparse rewards and wasted samples. Masked diffusion LLMs (dLLMs) offer a unique opportunity to improve exploration through their inpainting capabilities.

Method: The paper introduces Inpainting Guided Policy Optimization (IGPO), an RL framework for dLLMs. IGPO strategically inserts partial ground-truth reasoning traces during online sampling to guide exploration. It also incorporates supervised fine-tuning on rewritten concise traces and entropy-based filtering. The framework is applied to group-based optimization methods like GRPO.

Result: IGPO improves sample efficiency and restores meaningful gradients in RL training for dLLMs. The proposed training recipe, including IGPO and other techniques, achieves new state-of-the-art results on three mathematical benchmarks: GSM8K, Math500, and AMC, for full-attention masked dLLMs.

Conclusion: The inpainting ability of dLLMs can be effectively leveraged within an RL framework (IGPO) to enhance exploration, improve sample efficiency, and achieve superior performance on complex reasoning tasks, particularly in the domain of mathematics.

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [288] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: MuSe通过结合语义聚类和多极展开来近似Transformer中的softmax注意力，将计算复杂度从O(N^2)降低到O(NCD)或O(NCD log N)，并在保持少量精度损失的情况下实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长序列时存在二次计算复杂度的问题，这限制了它们在长文本等应用中的效率。本文旨在提出一种高效的注意力机制来解决这一瓶颈。

Method: 本文提出了一种名为Multipole Semantic Attention (MuSe) 的方法。它结合了语义聚类和多极展开的思想。具体来说，MuSe将查询（queries）和键（keys）在它们各自的学习表示空间中进行聚类，而不是像以前的方法那样只聚类键或统一聚类。这种分离的聚类方式能更好地适应注意力机制的非对称性。在近似过程中，除了基于质心（单极）的近似外，还引入了偶极修正，以捕捉聚类内的方向方差，从而保留更丰富的信息。该方法可以作为标准注意力的即插即用替代品，无需修改网络结构，只需调整超参数。

Result: 在计算复杂度方面，MuSe实现了O(NCD)（非因果注意力，C为聚类数）和O(NCD log N)（因果注意力）的复杂度。在与CUDNN Flash Attention在8k上下文长度下的对比实验中，MuSe在隔离注意力层上实现了3倍的加速，相对平方误差低于20%。对于因果注意力，提出了一种结合局部精确计算和长距离高效近似的层级块分解方法。在3000万参数模型、16k上下文长度、书籍文本的端到端预训练任务中，MuSe将运行时间减少了12.2%，模型性能（损失）仅下降了0.36%。

Conclusion: MuSe通过引入多极近似，能够显著提高Transformer处理长序列的效率，并且在保持较低的精度损失前提下，为Transformer的预训练提供了一种可行的、高效的解决方案。

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [289] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 该研究提出使用流程挖掘技术来检测和定位计算机化铁路系统中 ERTMS/ETCS L2 的运行时控制流异常，以提高系统的弹性。


<details>
  <summary>Details</summary>
Motivation: 随着计算机化铁路系统复杂性和关键性的增长，确保其弹性至关重要，因为即使经过严格的验证和确认，运行时仍可能出现异常。

Method: 通过分析系统执行轨迹来学习实际控制流，并使用在线符合性检查进行运行时监控。通过无监督机器学习实现异常定位，将偏差链接到关键系统组件。

Result: 在 RBC/RBC 交接场景的 ERTMS/ETCS L2 参考场景中，该方法能够高精度、高效率且可解释地检测和定位异常。

Conclusion: 该研究提出的基于流程挖掘的运行时异常检测和定位方法能够有效提高 ERTMS/ETCS L2 系统的弹性和可解释性。

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [290] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: Local SGD的收敛性研究，重点关注外层优化器及其超参数的影响。


<details>
  <summary>Details</summary>
Motivation: 现有关于Local SGD的研究主要集中在内层优化过程的超参数，对外层优化器的选择及其超参数的研究不足。本文旨在填补这一空白。

Method: 通过理论分析和实验研究外层优化器（包括学习率和动量）对Local SGD算法收敛性的影响，并提出新的数据相关性分析方法。

Result: 证明了通过调整外层学习率可以平衡优化误差和梯度噪声方差，弥补内层学习率不佳的影响。理论表明外层学习率有时可设为大于1。研究了动量和加速在外层优化器中的作用，并进行了广泛的实验验证。

Conclusion: 外层优化器的选择和超参数调整对于Local SGD算法的性能至关重要，合理的调整可以带来理论和实践上的改进。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [291] [Dimensionality reduction of optically generated vortex strings in a charge density wave](https://arxiv.org/abs/2509.09819)
*Sajal Dahal,Alex H. Miller,Viktor Krapivin,Gal Orenstein,Ryan A. Duncan,Nicholas Leonard,Matthew J. Hurley,Jade Stanton,Roman Mankowsky,Henrik Lemke,Anisha Singh,Ian Fisher,Mariano Trigo,Samuel W. Teitelbaum*

Main category: cond-mat.mes-hall

TL;DR: Femtosecond laser excitation of ErTe3 reveals that light can control the dimensionality and orientation of topological defects, creating vortex strings with apparent lower dimensionality that persist longer than electronic recovery time. Time-resolved optical pump, x-ray probe experiments and simulations show a reduction in effective dimensionality, offering a new way to stabilize competing quantum states.


<details>
  <summary>Details</summary>
Motivation: Understanding how mesoscale structures like topological defects, vortex strings, and domain walls influence phase transitions and the properties of active devices, particularly in photoinduced phase transitions driven by ultrafast laser excitation.

Method: Utilizing time-resolved optical pump, x-ray probe experiments on the CDW system Pd-intercalated ErTe3, complemented by time-dependent Ginzburg-Landau simulations, to investigate the nanoscale dynamics of mesoscale topological features (vortex strings).

Result: Observed vortex strings with an apparent dimensionality different from predictions based on the bulk system. These vortex strings were found to persist significantly longer than the electronic recovery time. Analysis of power-law scaling of intensity versus wavevector yielded a critical exponent indicating a reduction in the effective dimensionality of the topological defects.

Conclusion: Demonstrated a novel method using light to control the dimensionality and orientation of topological defects in quantum materials, specifically creating persistent vortex strings in ErTe3. This control offers potential for stabilizing competing quantum states.

Abstract: In phase transitions, mesoscale structures such as topological defects,
vortex strings, and domain walls control the path towards equilibrium, and thus
the functional properties of many active devices. In photoinduced phase
transitions driven by femtosecond laser excitation, the temporal (pulse
duration) and spatial (penetration depth) structure of the optical excitation
present opportunities for control and creating structures with unique
topologies. By performing time-resolved optical pump, x-ray probe experiments
on the CDW system Pd-intercalated ErTe$_{3}$, we gain access to the nanoscale
dynamics of the mesoscale topological features (vortex strings) produced after
a quench, which have a different apparent dimensionality than the topological
defects predicted from the bulk system. We show that these vortex strings
persist for much longer than the electronic recovery time. The critical
exponent obtained from power-law scaling of the intensity as a function of
wavevector shows a reduction in the effective dimensionality of the topological
defects in the system, corroborated by time-dependent Ginzburg-Landau
simulations. Our results demonstrate a novel pathway to use light to control
the dimensionality and orientation of topological defects in quantum materials,
which could be used to stabilize competing quantum states.

</details>


### [292] [Fractal growth of higher-order topological insulators](https://arxiv.org/abs/2509.09875)
*Yutaro Tanaka,Shuai Zhang,Tiantian Zhang,Shuichi Murakami*

Main category: cond-mat.mes-hall

TL;DR: 高阶拓扑绝缘体晶体在生长过程中呈现分形形态，且角比边生长得更快，具有更光滑的边缘和独特的周长-面积关系。


<details>
  <summary>Details</summary>
Motivation: 理解晶体生长和形态是凝聚态物理中的基本问题。

Method: 通过分析高阶拓扑绝缘体和普通绝缘体的晶体生长形态，比较了它们的分形维度和海岸线分形维度，并研究了周长-面积关系。

Result: 高阶拓扑绝缘体晶体呈现分形形态，角比边生长得更快，具有更光滑的边缘（更小的海岸线分形维度）和独特的周长-面积关系。

Conclusion: 高阶拓扑绝缘体和普通绝缘体在晶体生长形态、边缘光滑度和周长-面积关系方面存在显著差异。

Abstract: Understanding crystal growth and morphology is a fundamental issue in
condensed matter physics. In this work, we reveal the fractal morphology of
growing crystals of higher-order topological insulators and show that the
corners of the crystals grow preferentially compared to the edges in the
presence of the corner states. We further demonstrate that when we compare the
crystal shape of the higher-order topological insulator with that of the
trivial insulator with the same value of the fractal dimension $D_f$, the
former has a smaller value of the fractal dimension of coastlines $D_{f,c}$
than the latter. This indicates that, for crystals with a similar degree of
corner development, those in the higher-order topological phase have smoother
edges. Because the relationship between the area and the perimeter of the
crystals is governed by the ratio of these fractal dimensions, the higher-order
topological insulator and the trivial insulator exhibit distinct perimeter-area
relationships.

</details>


### [293] [Hard and soft phase slips in a Fabry-Pérot quantum Hall interferometer](https://arxiv.org/abs/2509.09901)
*N. L. Samuelson,L. A. Cohen,W. Wang,S. Blanch,T. Taniguchi,K. Watanabe,M. P. Zaletel,A. F. Young*

Main category: cond-mat.mes-hall

TL;DR: 量子霍尔效应法布里-珀罗干涉仪的干涉相位包含了准粒子的统计性质和体边耦合的信息。本研究在不同量子霍尔状态下（$
u = -1, -2$）的石墨烯干涉仪中，观察到了与准粒子进入干涉仪体相相关的相位滑移，并表明准粒子的平衡时间可达几分钟。研究还区分了两种类型的相位滑移：一种与均匀耦合到整个边缘态的体“水坑”有关，另一种与被主要耦合到最近边缘部分的缺陷位点捕获的准粒子有关。


<details>
  <summary>Details</summary>
Motivation: 研究量子霍尔法布里-珀罗干涉仪对体准粒子的敏感性，特别是体边耦合在非平衡条件下的作用。

Method: 在石墨烯量子霍尔干涉仪中，测量$
u = -1$和$
u = -2$状态下的量子干涉，观察相位滑移，并分析其对磁场和几何结构的依赖性。

Result: 观察到与准粒子进入干涉仪体相相关的相位滑移，平衡时间可达数分钟。区分出两种类型的相位滑移，分别与体“水坑”和缺陷位点中的准粒子有关。

Conclusion: 量子霍尔法布里-珀罗干涉仪能够探测体准粒子的性质，即使在非平衡条件下也是如此。体边耦合的时间尺度比之前认为的要长，并且存在不同类型的准粒子输运机制。

Abstract: Quantum Hall Fabry-P\'erot interferometers are sensitive to the properties of
bulk quasiparticles enclosed by the interferometer loop, with the interference
phase containing information about both the quasiparticle statistics and the
Coulomb-mediated bulk-edge coupling. Previous studies have explored the role of
the bulk-edge coupling in an equilibrium picture where quasiparticles enter and
exit the interferometer rapidly compared to the timescale over which the
interferometer phase is measured. Here, we present data from a monolayer
graphene quantum Hall interferometer in the integer quantum Hall regime at $\nu
= -1$ and $\nu = -2$. Quantum interference shows phase slips associated with
the entrance of quasiparticles to the interferometer bulk. Tracing the
dependence of these phase slips on the magnetic field, we show that the
equilibration time can become as long as several minutes. We further use our
multi-gated geometry to identify two classes of phase slips. The first is
associated with the addition of a quasiparticle to a bulk `puddle' of
quasiparticles uniformly coupled to the entire chiral edge state, while the
second is associated with the addition of a quasiparticle trapped by a defect
site that couples predominantly to the closest portion of the edge.

</details>


### [294] [Switching magnetic texture via in-plane magnetic field in noncentrosymmetric dipolar magnets: From skyrmions to antiskyrmions and nontopological magnetic bubbles](https://arxiv.org/abs/2509.10028)
*Tatsuki Muto,Masahito Mochizuki*

Main category: cond-mat.mes-hall

TL;DR: 论文研究了非中心对称二极磁体中由场诱导的磁拓扑切换现象。


<details>
  <summary>Details</summary>
Motivation: 研究非中心对称二极磁体中磁畴结构的行为，特别是拓扑纹理的切换。

Method: 利用微磁模拟和能量贡献分析，研究了磁畴结构（反斯格明子、椭圆斯格明子、非拓扑磁泡）在外部磁场作用下的行为。

Result: 实现了通过平行于样品平面的磁场，确定性地切换反斯格明子（Nsk=+1）、椭圆斯格明子（Nsk=-1）和非拓扑磁泡（Nsk=0）之间的磁拓扑。

Conclusion: 研究阐明了场诱导的磁拓扑切换现象的物理机制和特性，并为拓扑磁学在自旋电子学中的应用提供了参考。

Abstract: We theoretically investigate field-induced switching of magnetic topology in
a nanodisk-shaped sample of noncentrosymmetric dipolar magnet in which the
Dzyaloshinskii-Moriya interaction that stabilizes an antiskyrmion with $N_{\rm
sk}$=+1 and the magnetic dipole interaction that stabilizes a skyrmion with
$N_{\rm sk}$=$-1$ are in keen competition where $N_{\rm sk}$ is the skyrmion
number. Our micromagnetic simulations demonstrate that the competition offers a
unique opportunity to switch magnetic textures with distinct magnetic topology
among the antiskyrmion ($N_{\rm sk}$=+1), elliptical skyrmion ($N_{\rm
sk}$=$-1$), and nontopological bubble ($N_{\rm sk}$=0) in a deterministic
manner by application of magnetic fields parallel to the sample plane. By
calculating time and spatial profiles of energy contributions from respective
interactions and magnetic anisotropy, we clarify the physical mechanism and
properties of the observed field-induced topology switching phenomena. Our
findings are expected to provide useful insights into the spintronic
application of topological magnetism.

</details>


### [295] [Radial Rashba spin-orbit fields in commensurate twisted transition-metal dichalcogenide bilayers](https://arxiv.org/abs/2509.10068)
*Thomas Naimer,Paulo E. Faria Junior,Klaus Zollner,Jaroslav Fabian*

Main category: cond-mat.mes-hall

TL;DR: 纯径向Rashba自旋轨道场可以在共格扭曲的同质双层材料中出现，其平面内自旋纹理主要是径向的。


<details>
  <summary>Details</summary>
Motivation: 研究共格扭曲的同质双层材料中纯径向Rashba自旋轨道场的出现及其性质。

Method: 使用基于两个有效质量模型（包含自旋-轨道耦合）和一般（自旋守恒）层间耦合的模型哈密顿量，通过拟合几个扭曲超胞来提取模型哈密顿量参数。

Result: 发现径向Rashba场的幅度存在扭转角依赖性，该依赖性不仅围绕未扭转的情况（$
Theat=0^	ext{o}$和$
Theat=60^	ext{o}$）对称，而且围绕$
Theat=30^	ext{o}$也对称。层间耦合随着共格超胞尺寸的增大而减小，这表明层间耦合的峰值仅出现在存在小尺寸共格超胞的扭转角处。通过探索层间不同的横向位移，证实了保护径向Rashba的对称性是平面内180$^	ext{o}$旋转轴。还研究了原子弛豫和层间距离调 modulation 的影响。

Conclusion: 结果为基于扭曲层状材料的自旋-电荷转换方案工程提供了基础性的微观见解。

Abstract: In commensurate twisted homobilayers, purely radial Rashba spin-orbit fields
can emerge. The observed in-plane spin textures are mostly radial, and the main
features are successfully reproduced using a model Hamiltonian based on two
effective mass models including spin-orbit coupling, and a general
(spin-conserving) interlayer coupling. Extracting the model Hamiltonian
parameters through fitting of several twisted supercells, we find a twist angle
dependency of the magnitude of the radial Rashba field, which is symmetric not
only around the untwisted cases ($\Theta=0^\circ$ and $\Theta=60^\circ$), but
also around $\Theta=30^\circ$. Furthermore, we observe that the interlayer
coupling between the $K/K'$-points of the two layers decreases with the
increase of the size of the commensurate supercells. Hence, peaks of high
interlayer coupling can occur only for twist angles, where small commensurate
supercells are possible. Exploring different lateral displacements between the
layers, we confirm that the relevant symmetry protecting the radial Rashba is
an in-plane 180$^\circ$ rotation axis. We additionally investigate the effects
of atomic relaxation and modulation of the interlayer distance. Our results
offer fundamental microscopic insights that are particularly relevant to
engineering spin-charge conversion schemes based on twisted layered materials.

</details>


### [296] [Anomalous Electrical Transport in SnSe$_2$ Nanosheets: Role of Thickness and Surface Defect States](https://arxiv.org/abs/2509.10228)
*Aarti Lakhara,Lars Thole,Rolf J. Haug,P. A. Bhobe*

Main category: cond-mat.mes-hall

TL;DR: 研究了二维SnSe$_2$纳米片的厚度对其电学输运性质的影响，发现其表现出与传统二维材料相反的、随厚度减小而从半导体向金属性转变的电阻行为，并认为这是由表面缺陷态引起的n型掺杂所致。


<details>
  <summary>Details</summary>
Motivation: 研究机械剥离的二维SnSe$_2$纳米片中厚度对其电学输运性质的影响，特别是其与传统二维系统相反的、随厚度减小而从半导体向金属性转变的电阻行为。

Method: 通过分析低温传导和栅极电压依赖的电导测量，研究了厚度对SnSe$_2$电学输运性质的影响，并利用厚度依赖的室温拉曼光谱探究了缺陷态的存在和演化。

Result: 发现二维SnSe$_2$纳米片的电阻行为随厚度减小呈现出从半导体到金属性的转变；分析表明，这归因于表面缺陷态引起的n型掺杂，增加了费米能级处的态密度。

Conclusion: 二维SnSe$_2$纳米片的电学输运机制和由缺陷态控制的电导行为受到厚度的关键影响。

Abstract: This work examines the influence of thickness on the electrical transport
properties of mechanically exfoliated two-dimensional SnSe$_2$ nanosheets,
derived from the bulk single crystal. Contrary to conventional trend observed
in two-dimensional systems, we find a semiconducting to metallic resistivity
behavior with decreasing thickness. The analysis of low-temperature conduction
indicates an increased density of states at Fermi-level with decreasing
thickness, which is further corroborated by gate bias dependent conductance
measurement. The enhanced conductivity in thinner flake is attributed to the
n-type doping arising from surface defect states. The presence and evolution of
these defect states with thickness is probed by thickness-dependent
room-temperature Raman spectroscopy. Our study provides insights into the
thickness-dependent electronic transport mechanism of SnSe$_2$ and the crucial
role of defect states in governing the observed conductivity behavior.

</details>


### [297] [Noncontact friction in ultracoherent nanomechanical resonators near dielectric materials](https://arxiv.org/abs/2509.10237)
*Amirali Arabmoheghi,Alessio Zicoschi,Guillermo Arregui,Mohammad J. Bereyhi,Yi Xia,Nils J. Engelsen,Tobias J. Kippenberg*

Main category: cond-mat.mes-hall

TL;DR: 附近的电介质会引起超相干纳米机械振荡器的耗散，这是由振荡器携带的静电荷在介电材料中移动引起的。


<details>
  <summary>Details</summary>
Motivation: 利用微纳机械振荡器进行精密传感和量子技术，需要了解其相干性限制，特别是当它们靠近其他材料时。

Method: 研究了超相干纳米机械振荡器在存在附近电介质时的耗散，并分析了参数依赖性。

Result: 发现了由附近电介质引起的新的耗散机制，这种机制对于低频模式更为严重，并且与原子力显微镜中的非接触摩擦（NCF）一致。

Conclusion: 附近电介质的存在会阻碍超相干纳米机械振荡器的性能，这对于将这些振荡器集成到量子技术等应用中是一个重要的限制因素。

Abstract: Micro- and nanomechanical resonators are emerging as promising platforms for
quantum technologies, precision sensors and fundamental science experiments. To
utilize these devices for force sensing or quantum optomechanics, they must be
brought in close proximity with other systems for functionalization or
efficient readout. Improved understanding of the loss mechanisms in
nanomechanical resonators, specifically the advent of dissipation dilution, has
led to the development of resonators with unprecedented coherence properties.
The mechanical quality factors of this new class of ultracoherent micro- and
nanomechanical oscillators can now exceed 1 billion at room temperature,
setting their force sensitivities below 1 $\mathrm{aN}/\sqrt{\mathrm{Hz}}$,
surpassing those of the state-of-the-art atomic force microscopes (AFMs). Given
this new regime of sensitivity, an intriguing question is whether the proximity
of other materials hinders mechanical coherence. Here we show: it does. We
report a novel dissipation mechanism that occurs in ultracoherent
nanomechanical oscillators caused by the presence of nearby dielectrics. By
studying the parameter scaling of the effect, we show that the mechanism is
more severe for low-frequency mechanical modes and that it is due to dielectric
loss within the materials caused by the motion of a resonator which carries
static charges. Our observations are consistent with the noncontact friction
(NCF) observed in AFMs. Our findings provide insights into limitations on the
integration of ultracoherent nanomechanical resonators and highlight the
adverse effects of charged defects in these systems.

</details>


### [298] [Pure dephasing increases partition noise in the quantum Hall effect](https://arxiv.org/abs/2509.10242)
*C. W. J. Beenakker*

Main category: cond-mat.mes-hall

TL;DR: 量子霍尔边缘通道中的电荷分配在 N 个手征模式之间进行。模式间散射会导致分配噪声，这在石墨烯 p-n 结中已得到观察。虽然非弹性散射通过平均起伏来抑制这种噪声，但我们证明了纯（准弹性）退相干可能会增强分配噪声。对于两个模式，噪声功率最多可增加 50%，在强退相干极限下，总体增强因子为 1+1/N。这种反直觉的效应在受监控的量子输运框架下得到了解释，这是由量子轨迹的自平均引起的。


<details>
  <summary>Details</summary>
Motivation: 研究量子霍尔边缘通道中电荷分配的噪声，特别是在存在准弹性退相干的情况下，这与通常预期的抑制噪声相反。

Method: 利用受监控的量子输运框架来解释准弹性退相干如何增强分配噪声，并推导了噪声增强的一般公式。

Result: 发现纯（准弹性）退相干最多可将分配噪声功率提高 50%（对于两个模式），在强退相干极限下，噪声增强因子为 1+1/N。

Conclusion: 准弹性退相干可以增强量子霍尔边缘通道中的分配噪声，这一反直觉的现象可以通过量子轨迹的自平均来解释。

Abstract: Quantum Hall edge channels partition electric charge over N chiral
(uni-directional) modes. Intermode scattering leads to partition noise,
observed in graphene p-n junctions. While inelastic scattering suppresses this
noise by averaging out fluctuations, we show that pure (quasi-elastic)
dephasing may enhance the partition noise. The noise power increases by up to
50% for two modes, with a general enhancement factor of 1+1/N in the
strong-dephasing limit. This counterintuitive effect is explained in the
framework of monitored quantum transport, arising from the self-averaging of
quantum trajectories.

</details>


### [299] [Spin-qubit Noise Spectroscopy of Magnetic Berezinskii-Kosterlitz-Thouless Physics](https://arxiv.org/abs/2509.10309)
*Mark Potts,Shu Zhang*

Main category: cond-mat.mes-hall

TL;DR: 利用NV自旋量子比特噪声磁力计探测磁性BKT物理的动力学特征，预测在MHz到GHz频率范围内具有特征性的磁噪声谱密度。


<details>
  <summary>Details</summary>
Motivation: 探测磁性Berezinskii-Kosterlitz-Thouless (BKT) 物理的动力学特征。

Method: 利用NV自旋量子比特噪声磁力计。

Result: 在准长程有序相中，谱密度表现出与代数自旋相关性相关的温度依赖性幂律。在相变以上，噪声反映了自由涡旋的增殖，并能定量提取涡旋电导率。

Conclusion: NV自旋量子比特是解决介观和低频动力学以及探测奇异磁相变的有力光谱方法。

Abstract: We propose using spin-qubit noise magnetometry to probe dynamical signatures
of magnetic Berezinskii-Kosterlitz-Thouless (BKT) physics. For a
nitrogen-vacancy (NV) center coupled to two-dimensional XY magnets, we predict
distinctive features in the magnetic noise spectral density in the sub-MHz to
GHz frequency range. In the quasi-long-range ordered phase, the spectrum
exhibits a temperature-dependent power law characteristic of algebraic spin
correlations. Above the transition, the noise reflects the proliferation of
free vortices and enables quantitative extraction of the vortex conductivity, a
key parameter of vortex transport. These results highlight NV as a powerful
spectroscopic method to resolve magnetic dynamics in the mesoscopic and
low-frequency regimes and to probe exotic magnetic phase transitions.

</details>


### [300] [Disorder-driven Weyl-Kondo Semimetal Phase in WTe$_2$](https://arxiv.org/abs/2509.10398)
*Arpan Manna,Sunit Das,Amit Agarwal,Soumik Mukhopadhyay*

Main category: cond-mat.mes-hall

TL;DR: WTe2中观察到无序驱动的各向异性Kondo筛分和自发霍尔效应，表明其是 the Weyl-Kondo 费米子的平台。


<details>
  <summary>Details</summary>
Motivation: 研究WTe2的Kondo散射、各向异性磁阻、自发霍尔效应及其与WTe2拓扑特性的关系。

Method: 通过实验观测和理论分析，研究了WTe2的Kondo散射、磁阻和霍尔效应，并探讨了无序性对这些现象的影响，以及其与WTe2的拓扑性质的联系。

Result: 观察到无序驱动的各向异性Kondo筛分和自发霍尔效应，发现无序性增强了Kondo散射和自发霍尔效应，并提出无序驱动的Kondo相互作用将费米能级钉扎在Weyl节点附近，从而增强了Berry曲率驱动的非平衡输运。

Conclusion: 已建立的无序WTe2是the Weyl-Kondo费米子的平台，并强调了无序性作为在弱相关Weyl半金属中诱导相关拓扑相的有效控制旋钮。

Abstract: In this Letter, we report the observation of disorder-driven anisotropic
Kondo screening and spontaneous Hall effect in bulk WTe${_2}$, a nonmagnetic
type-II Weyl semimetal. We show that Kondo scattering emerges more prominently
in disordered samples and produces magnetoresistance that is strongly
anisotropic with respect to both current and magnetic field orientation,
reflecting the underlying type-II Weyl dispersion. Strikingly, we find a
spontaneous Hall effect in zero magnetic field, whose magnitude is enhanced
with disorder, together with a large second-harmonic Hall signal exhibiting
quadratic current scaling. Our analysis indicates that disorder-driven Kondo
interactions pin the Fermi level near the Weyl nodes. This enhances the Berry
curvature-driven nonequilibrium transport, accounting for both the second-order
and spontaneous Hall responses. These findings establish disordered WTe${_2}$
as a platform hosting Weyl-Kondo fermions and highlight disorder as an
effective control knob for inducing correlated topological phases in weakly
correlated Weyl semimetals.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [301] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND,一个大型语言模型平台，能显著缩短新药临床试验申请（IND）非临床书面总结的起草时间（约97%），同时保持可接受的文档质量，但仍需监管写作专家进行润色以达到提交标准。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）平台（AutoIND）是否能在保证文档质量的同时，减少监管提交文件（IND申请）的初稿撰写时间，以加速早期临床开发。

Method: 直接记录AutoIND生成的IND非临床书面总结（eCTD模块2.6.2、2.6.4、2.6.6）的起草时间。将此与经验丰富的监管撰稿人（≥6年经验）手动起草先前已获美国FDA批准的IND总结的预估时间进行比较，作为行业标准基准。由盲评的监管写作评估员使用七个预定类别（正确性、完整性、简洁性、一致性、清晰度、冗余性、强调性）对文档质量进行评分，评分标准化为百分比。关键监管错误定义为可能改变监管解释的任何错误陈述或遗漏。

Result: AutoIND将初始起草时间缩短了约97%（IND-1的18,870页/61份报告从约100小时缩短至3.7小时；IND-2的11,425页/58份报告缩短至2.6小时）。IND-1和IND-2的质量评分分别为69.6%和77.9%。未检测到关键监管错误，但发现强调性、简洁性和清晰度方面存在缺陷。

Conclusion: AutoIND能极大地加速IND申请的起草过程，但专家监管撰稿人对于将输出文件打磨至可提交的质量仍然是必不可少的。已识别的系统性缺陷为模型改进提供了方向。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [302] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: Boldsea是一个使用可执行本体建模复杂动态系统的架构，它通过将事件语义与数据流架构相结合，解决了传统BPM系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的BPM系统和面向对象的语义技术存在局限性，需要一种新的方法来建模复杂动态系统。

Method: 提出了一种名为boldsea的架构，该架构使用可执行本体（语义模型），直接控制进程执行。它还提出了形式化的BSL语言（包括BNF语法）和boldsea-engine的架构，该架构直接将语义模型解释为可执行算法，无需编译。

Result: Boldsea能够实现事件模型在运行时修改、保证时间透明性，并在统一的语义框架内无缝合并数据和业务逻辑。

Conclusion: Boldsea通过将事件语义与数据流架构相结合，克服了传统BPM系统的局限性，并提供了一种新的、更有效的复杂动态系统建模方法。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [303] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 基础模型（LLMs和VLMs）可以为规划任务提供高质量的反馈，尤其是在符号和语言环境中。更大的模型和更强的推理能力可以提高反馈的准确性并减少偏差。然而，在具有复杂动态或连续状态/动作空间的复杂环境中，反馈质量会下降。


<details>
  <summary>Details</summary>
Motivation: 需要评估预训练的基础模型（LLMs和VLMs）在多大程度上可以提供有用的反馈，以辅助规划任务，从而减少对精心设计的奖励函数或高质量演示的需求。

Method: 评估LLMs和VLMs在不同环境（符号、语言、连续控制）和不同反馈类型（二元反馈、偏好反馈、动作建议、目标建议、动作增量反馈）下的表现。同时，还考虑了不同推理方法（上下文学习、思维链、环境动态访问）对反馈性能的影响。

Result: 基础模型可以提供高质量且多样化的反馈。模型越大、推理能力越强，反馈越准确，偏差越小，并且从增强的推理方法中获益越多。然而，在复杂动态或连续状态/动作空间的复杂环境中，反馈质量会下降。

Conclusion: 基础模型在提供规划反馈方面展现出巨大潜力，但其有效性受到环境复杂性和模型能力的限制。未来的研究应关注如何克服这些限制，以在更广泛的应用场景中利用基础模型的反馈能力。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [304] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 使用生成式人工智能框架从公开信息生成能源建模所需数据，以降低成本和数据限制。


<details>
  <summary>Details</summary>
Motivation: 现有计算模型在能源建模方面虽然强大，但存在数据获取困难、成本高昂或涉及隐私的问题。本研究旨在解决这些挑战。

Method: 提出一个模块化的多模态框架，利用生成式人工智能从公开的住宅信息和图像中生成研究所需的数据。并提供一个演示该框架的流程，同时评估其生成式人工智能组件。

Result: 实验表明，该框架成功生成了逼真且带有标签的数据，并避免了生成模型常见的相关问题。

Conclusion: 该框架通过减少对昂贵或受限数据源的依赖，为能源建模研究开辟了更易于访问和可复现的路径。

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [305] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: AI代理可以加速科学发现，但其集成方式尚不清楚。本文提出了一个框架，将工作流的智能和组合作为演进的维度，并提供了一个架构蓝图，以实现完全自主的科学实验室。


<details>
  <summary>Details</summary>
Motivation: 目前的科学发现需要协调分布式设施和异构资源，使研究人员承担手动工作流协调的角色，而不是专注于科学本身。AI代理的出现为通过提供智能组件来加速科学发现提供了新的机会，但其具体实现和集成方式尚不明确。

Method: 提出一个概念框架，将工作流沿着两个维度进行演化：智能（从静态到智能）和组合（从单一到群体）。基于这些轨迹，提出了一个架构蓝图。

Result: 该框架和蓝图为社区提供了一个演进路径，从现有的工作流管理系统迈向完全自主的分布式科学实验室。

Conclusion: 通过将工作流朝着更智能和更具组合性的方向演进，可以实现科学发现的指数级加速（100倍）和科学工作流的变革。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [306] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: LLM驱动的多代理框架可实现多孔材料表征的自动化，通过自主规划、力场构建和模拟执行来加速材料发现。


<details>
  <summary>Details</summary>
Motivation: 自动化多孔材料表征以加速材料发现，但现有方法受限于模拟设置和力场选择的复杂性。

Method: 提出一个多代理框架，其中基于LLM的代理能够自主理解表征任务、规划模拟、构建力场、执行模拟并解释结果以指导后续步骤。作为第一步，构建了一个用于文献信息力场提取和RASPA模拟设置的自动化系统。

Result: 初步评估表明，该方法具有高度的正确性和可重复性。

Conclusion: 该方法有潜力实现完全自主、可扩展的材料表征。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [307] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: Autoformalization (AI formalization) is advancing due to LLMs, but research is fragmented. This paper proposes a unified framework to connect related fields and accelerate progress.


<details>
  <summary>Details</summary>
Motivation: The rapid development of autoformalization, driven by LLMs, has led to fragmented research across different fields (mathematics, reasoning, planning, knowledge representation). This lack of communication hinders progress due to separate development of methodologies, benchmarks, and theoretical frameworks.

Method: This paper reviews explicit and implicit instances of autoformalization and proposes a unified framework to encourage cross-pollination between different fields.

Result: The paper aims to advance the development of next-generation AI systems by unifying fragmented research in autoformalization.

Conclusion: By proposing a unified framework and encouraging interdisciplinary collaboration, this paper seeks to accelerate progress in autoformalization and the development of advanced AI systems.

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [308] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个使用代数方法表示和操作命题逻辑的新框架，包含集合、坐标和行分解三种表示形式，具有灵活性，虽然默认简化不具有唯一性，但可以通过固定变量顺序获得唯一形式，并可用于搜索和知识编译算法。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一种使用代数方法表示和操作命题逻辑的新框架State Algebra。

Method: 该框架包含集合、坐标和行分解三种表示形式，并通过代数引擎进行计算。提出了一种在简化过程中通过固定变量顺序获得唯一形式的方法。

Result: State Algebra框架具有灵活性，可以通过固定变量顺序获得唯一形式，并可用于搜索和知识编译算法，还可以扩展到概率逻辑和加权模型计数。

Conclusion: State Algebra通过代数方法提供了表示和操作命题逻辑的灵活框架，并在可扩展性方面展现了潜力。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [309] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 研究提出了一种基于检索增强生成（RAG）的智能知识助手系统，用于支持山羊养殖健康管理，通过结构化知识处理方法（表格文本化和决策树文本化）增强LLM对异构数据的理解，并建立了包含五个关键领域知识的山羊养殖知识库，集成了在线搜索模块以获取实时信息。实验结果表明，该异构知识融合方法在验证集和测试集上分别达到了87.90%和84.22%的准确率，并在文本、表格和决策树问答任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLMs）在各行业有应用，但在畜牧业（特别是山羊养殖）中的应用受限于知识来源的可用性、多样性和复杂性。本研究旨在解决这一问题，为山羊养殖健康管理提供一个智能知识助手。

Method: 提出了一种基于检索增强生成（RAG）的智能知识助手系统。采用了两种结构化知识处理方法：表格文本化和决策树文本化，以增强LLM对异构数据格式的理解。建立了包含疾病预防与治疗、营养管理、饲养管理、羊奶管理和基础养殖知识五个领域的领域特定山羊养殖知识库。集成了在线搜索模块以检索最新信息。进行了六项消融实验来评估系统组件的贡献。

Result: 异构知识融合方法取得了最佳结果，在验证集上的平均准确率为87.90%，在测试集上的平均准确率为84.22%。在基于文本、表格和决策树的问答任务中，准确率持续超过85%。错误分析显示遗漏是最主要的错误类别，表明在改进检索覆盖率和上下文集成方面存在机会。

Conclusion: 提出的系统在实际的山羊养殖应用中表现出稳健性和可靠性，证明了结构化知识融合在模块化设计中的有效性。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [310] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: LLM在UNO游戏中作为辅助者，而非获胜者，其表现与模型规模相关，但普遍难以有效帮助人类玩家。


<details>
  <summary>Details</summary>
Motivation: 评估LLM作为代理在UNO游戏中辅助人类玩家完成目标的潜力。

Method: 构建了一个允许LLM在RLCard环境中作为代理的工具，并采用两种提示策略，测试了不同规模（1B到70B参数）的模型。

Result: 所有模型均优于随机基线，但只有少数模型能有效帮助人类玩家。

Conclusion: LLM在UNO游戏中可以作为辅助者，但其有效性受到模型规模的影响，并且普遍难以显著帮助人类玩家达成目标。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [311] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse (WFC)重构为马尔可夫决策过程(MDP)，以便在满足设计者指定的约束和目标的同时，通过外部优化算法进行优化，并在多个领域和不同难度下，与传统的联合优化进化方法相比，在各种任务复杂性下表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 程序化内容生成需要同时满足设计者指定的{-# objetivos #-}和{-# 隐式约束 #-}，而联合优化这两者面临挑战。

Method: 将WaveFunctionCollapse (WFC)重构为马尔可夫决策过程(MDP)，使外部优化算法能够专注于最大化{-# 目标 #-}，同时利用WFC的{-# 传播机制 #-}来强制执行{-# 约束 #-]。将此MDP的优化与传统的联合优化{-# 全局指标 #-]和{-# 局部图块放置 #-]的进化方法进行经验比较。

Result: 与传统的联合优化方法相比，在多个领域和不同难度下，联合优化在任务复杂度增加时表现不佳，并且持续表现不如优化WFC-MDP。

Conclusion: 将局部{-# 约束 #-]满足与全局{-# 目标 #-}优化分离，具有明显优势。

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [312] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本篇论文提出了一种新的可解释人工智能（XAI）工具B-ReX，用于评估表格数据和布尔函数预测模型。B-ReX在大量基准测试中表现优于其他XAI工具，其Jensen-Shannon散度为0.072 ± 0.012。


<details>
  <summary>Details</summary>
Motivation: 评估可解释人工智能（XAI）方法是一个普遍存在的挑战，因为解释本身具有主观性。本研究的动机是针对表格数据和布尔函数预测的特定场景，提出一种更正式、更精确的变量重要性度量方法，并评估现有的XAI工具。

Method: 提出了一种基于实际因果关系的变量重要性形式化度量方法，并使用该度量方法评估了最先进的XAI工具。此外，研究者们还开发了一种名为B-ReX的新型XAI工具，它基于现有的ReX工具进行了扩展。

Result: 在大型基准测试中，B-ReX被证明优于其他黑盒XAI工具，在随机10值布尔公式上的Jensen-Shannon散度达到了0.072 ± 0.012。

Conclusion: B-ReX是一种在表格数据和布尔函数预测场景下，比现有黑盒XAI工具更优越的新型XAI工具。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [313] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA系统通过将代理工作区划分为私有和公共空间，并结合DRKE和DLE模块，有效地在利用远程大语言模型进行多代理系统任务的同时保护了隐私。


<details>
  <summary>Details</summary>
Motivation: 为了在处理隐私数据时安全地利用远程托管的大语言模型（LLMs）进行多代理系统（MAS）任务，需要引入隐私保护机制。

Method: 提出了一种名为GAMA（General Anonymizing Multi-Agent system）的系统，该系统将代理工作区分隔为私有和公共空间，并通过匿名化机制保护隐私。GAMA包含两个关键模块：基于领域规则的知识增强（DRKE）和基于否证的逻辑增强（DLE），以减少匿名化造成的语义损失。

Result: 在Trivia Creative Writing和Logic Grid Puzzle两个公开问答数据集上，GAMA表现优于现有模型。在为评估隐私保护能力而设计的Knowledge Privacy Preservation和Logic Privacy Preservation两个新数据集上，GAMA在任务处理和隐私保护方面均表现出色。

Conclusion: GAMA系统在保护多代理系统任务中的数据隐私方面非常有效，同时保持了高质量的任务处理能力。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [314] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个统一的多代理协作框架，通过多极任务处理图和IF-THEN规则来解决多代理系统在处理复杂任务和不确定性时遇到的规划挑战，并在问答任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 多代理系统（MAS）在支持人类处理复杂现实世界任务方面能力显著，但仍面临处理高度复杂且不确定任务时的有效任务规划挑战，这常常导致误导性或不正确的输出，阻碍任务执行。

Method: 提出XAgents，一个基于多极任务处理图和IF-THEN规则的统一多代理协作框架。XAgents利用多极任务处理图实现动态任务规划和处理任务不确定性。在子任务处理过程中，它整合了特定领域的IF-THEN规则来约束代理行为，同时全局规则增强了代理间的协作。

Result: 在三个不同的数据集上评估了XAgents的性能，结果表明在知识类型和逻辑类型的问答任务中，XAgents在性能上持续优于最先进的单代理和多代理方法。

Conclusion: XAgents通过多极任务处理图和IF-THEN规则的结合，有效地解决了多代理系统在处理复杂和不确定任务时的规划问题，并在问答任务中取得了优于现有方法的性能。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [315] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: AI Harmonics 提出了一种以人为本、根据危害严重性自适应的方法，用于评估 AI 风险，重点关注政治和身体危害，以便有效缓解。


<details>
  <summary>Details</summary>
Motivation: 现有 AI 风险评估模型侧重于内部合规性，忽视了多方利益相关者的观点和现实世界的后果。因此，需要一种新的方法来解决这些不足。

Method: 提出了一种名为 AI Harmonics 的新范式，它采用基于经验事件数据、以人为本、根据危害严重性进行自适应的方法。该方法包括一个新的 AI 危害评估指标（AIH），它利用有序的严重性数据来捕获相对影响，而无需精确的数值估计。

Result: 实验表明，政治和身体危害的集中度最高，需要紧急缓解。政治危害会侵蚀公众信任，而身体危害则构成严重甚至危及生命的风险。AI Harmonics 能够识别不均衡的危害分布，从而能够更有效地进行缓解。

Conclusion: AI Harmonics 提供了一种新颖的、以数据为驱动的、注重利益相关者的框架，用于探索和优先排序 AI 危害，从而能够更有效地分配缓解资源。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [316] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: AI 代理正在形成一个独立的“沙盒经济”，可能带来机遇和风险。需要设计可控的 AI 市场，例如通过拍卖和任务经济，以确保其发展符合人类的长远利益。


<details>
  <summary>Details</summary>
Motivation: 随着自主 AI 代理的快速发展，出现了一个新的经济层，其交易和协调规模及速度超出了人类的直接监督。

Method: 提出了“沙盒经济”框架，通过其起源（涌现 vs. 意向）和与现有经济的隔离程度（可渗透 vs. 不可渗透）两个关键维度来分析这一新兴系统。探讨了实现可控 AI 代理市场的关键设计选择，包括用于资源分配和偏好解决的拍卖机制、用于协调集体目标的 AI“任务经济”，以及确保信任、安全和问责制的社会技术基础设施。

Result: 当前的趋势是自发地出现一个庞大且高度可渗透的 AI 代理经济，这带来了前所未有的协调机会，但也伴随着系统性经济风险和加剧的不平等挑战。

Conclusion: 主张通过主动设计可控的代理市场，例如采用拍卖机制和任务经济，来引导 AI 经济的发展，确保这一技术转变符合人类长期的集体福祉。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [317] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 该论文提出了一种名为鲁棒稀疏采样（RSS）的在线规划算法，用于解决马尔可夫决策过程（MDP）中的模型不确定性问题，并在有限样本下提供了理论性能保证。


<details>
  <summary>Details</summary>
Motivation: 现有的在线规划方法在处理从有限数据中学习到的模型不确定性时，可能会导致性能下降或不安全的行为。虽然鲁棒MDP（RMDP）提供了一个解决模型不确定性的框架，但现有方法计算成本高昂，不适合实时应用。

Method: 该论文提出的RSS算法，通过利用样本平均近似（SAA）的效率和理论特性，计算鲁棒值函数，从而在在线环境中实现可行的鲁棒策略计算。RSS适用于无限或连续状态空间，并且其样本和计算复杂度与状态空间大小无关。

Result: RSS在具有不确定动态的环境中，其性能优于标准的稀疏采样方法。

Conclusion: RSS是第一个用于RMDPs的在线规划算法，在有限样本下具有理论性能保证，并且在实际应用中能够有效处理模型不确定性问题。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [318] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI通过将临床NLI分解为四个推理家族并使用特定家族的求解器，提高了LLM的准确性，尤其是在因果归因和风险状态抽象方面，同时实现了可审计的程序。


<details>
  <summary>Details</summary>
Motivation: 评估在临床自然语言推理（NLI）中，扩展数据和参数是否能带来更强的结构化和可泛化的内部表征。在此过程中，识别出LLM在推理不足时倾向于使用启发式方法，而非保留相关事实。

Method: 提出CARENLI（Compartmentalised Agentic Reasoning for Clinical NLI），一种将知识获取与原则性推理分离的框架。CARENLI将临床NLI基准分解为因果归因、组合归因、认知验证和风险状态抽象四个推理家族，并为每个家族配备专门的求解器。通过规划器、验证器和精炼器来强制执行可审计的程序。

Result: CARENLI在四种大型语言模型（LLMs）上，将准确性提高了42个百分点，在因果归因方面达到98.0%，在风险状态抽象方面达到81.2%。验证器能以接近完美的可靠性标记违规行为，精炼器能纠正大量的认知错误。剩余的错误集中在路由环节，表明家族分类是主要的瓶颈。

Conclusion: 大型语言模型（LLMs）通常能保留相关事实，但在推理不足时会默认使用启发式方法。CARENLI框架能够明确区分这两者，并提供一个更安全、可审计的推理框架。

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [319] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 近期语言模型在推理方面存在不足，本研究探索将形式化方法应用于小型语言模型（SLMs）以提升其在本体工程中的推理能力，并初步实验验证了使用紧凑逻辑语言替代自然语言对SLMs性能的影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理方面存在不足，尤其是在本体工程领域，这影响了相关任务的执行。本研究旨在通过引入形式化方法来克服这一局限性，并探讨小型语言模型（SLMs）在本体构建中的应用潜力。

Method: 本研究旨在探索将形式化方法应用于小型语言模型（SLMs），以提升其在推理任务上的性能。具体而言，将进行一系列初步实验，比较SLMs在处理不同逻辑文法（包括自然语言和更紧凑的逻辑语言）下的表现，以评估其在本体工程中的应用效果。

Result: 初步实验结果表明，使用更紧凑的逻辑语言替代自然语言在推理任务上可以保持小型语言模型（SLMs）的良好性能。

Conclusion: 本研究的发现支持使用更紧凑的逻辑语言替代自然语言，并且可以在推理任务中保持小型语言模型（SLMs）的性能。这些结果有望为进一步优化SLMs在本体工程中的作用提供指导。

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [320] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: AI系统在面临道德困境时，普遍偏好“仁慈”和“美德”的价值，而“自由意志”的选择则受到惩罚。不同的模型架构、文化背景和可解释性会影响其道德偏好。


<details>
  <summary>Details</summary>
Motivation: AI 的快速发展引发了如何使其决策符合人类道德价值观的紧迫问题。本研究旨在探究领先的 AI 系统如何优先考虑道德结果，以及这对于人机共生的前景揭示了什么。

Method: 通过一项包含六个大型语言模型（LLMs）的定量实验，在代表五种道德框架的 18 种困境中对结果进行排名和评分。

Result: 所有模型都表现出一致的价值偏见，普遍高度评价“仁慈”和“美德”的价值，并惩罚“自由意志”的选择。能够进行推理的模型对上下文更敏感，解释更丰富，而非推理模型则产生更一致但更不透明的判断。

Conclusion: 研究结果强调了可解释性和文化意识作为指导 AI 实现透明、对齐和共生未来的关键设计原则的必要性。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [321] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding框架通过将失败归因任务重构为因果推理问题，显著提高了多智能体系统中错误步骤的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多智能体系统失败归因方面准确率低（低于17%），难以用于调试，其根本原因是无法进行有效的反事实推理。

Method: 提出了一种名为Abduct-Act-Predict (A2P) Scaffolding的新型智能体框架，将失败归因转化为结构化因果推理任务。A2P通过（1）溯因（Abduction）推断潜在原因，（2）行动（Action）定义最小干预措施，（3）预测（Prediction）模拟干预效果来解决失败问题，在单次推理中完成。

Result: 在Who&When基准测试的算法生成数据集上，A2P实现了47.46%的步骤级准确率，相比基线（16.67%）提升了2.85倍。在更复杂的手工制作数据集上，A2P实现了29.31%的步骤准确率，相比基线（12.07%）提升了2.43倍。

Conclusion: A2P Scaffolding通过引入因果推理视角，为自动化失败归因提供了一种更准确、更可靠、可验证的解决方案，克服了传统方法的局限性。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [322] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 本研究提出了一种基于信息论的框架，用于在现实世界中部署强化学习（RL）代理时检测和诊断系统故障，并通过分析状态-动作互信息模式来展示其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的强化学习（RL）代理面临传感器故障、执行器磨损和环境变化等问题，但缺乏检测和诊断这些故障的内在机制。

Method: 通过分析机器人控制任务中的状态-动作互信息模式，揭示RL的基本动力学并提供实用的部署时异常诊断方法。具体来说，研究了状态-动作互信息随学习过程的变化，以及状态、动作和下一个状态的联合互信息（MI(S,A;S')）的倒U型曲线。此外，还通过受控扰动实验来展示信息度量在区分和诊断系统故障方面的能力。

Result: 研究发现，成功的学习表现出特征性的信息特征：状态-动作互信息在状态熵增加的情况下稳定增长（从0.84增长到2.83比特，增长238%），表明代理越来越关注与任务相关的模式。状态、动作和下一个状态的联合互信息（MI(S,A;S')）呈现倒U型曲线，在早期学习阶段达到峰值，然后随着代理专业化而下降。观察空间噪声（传感器故障）会导致所有信息通道的广泛崩溃，状态-动作耦合显著下降；而动作空间噪声（执行器故障）则选择性地破坏动作-结果的可预测性，同时保留状态-动作关系。

Conclusion: 信息度量既可以作为学习的标志，也可以作为系统健康的诊断依据，为能够基于信息论原理进行自主故障检测和策略调整的自适应RL系统奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [323] [LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm](https://arxiv.org/abs/2509.09707)
*Camilo Chacón Sartori,Martín Isla Pino,Pedro Pinacho-Davidson,Christian Blum*

Main category: cs.NE

TL;DR: LLM与BRKGA结合，通过实例驱动的启发式偏差解决长跑子序列问题，并取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要利用LLM生成代码，忽略了问题实例的结构属性。本研究旨在利用LLM的分析能力，结合实例特征，生成启发式偏差，以指导元启发式算法的搜索过程。

Method: 提出一个框架，将LLM与BRKGA结合，通过人与LLM协作设计计算效率指标，LLM分析这些指标生成定制的启发式偏差，引导BRKGA搜索。

Result: 在1050个不同复杂度的实例上进行实验评估，BRKGA+Llama-4-Maverick的表现显著优于基线BRKGA，尤其是在复杂实例上。

Conclusion: 利用LLM生成先验的、实例驱动的启发式偏差，是增强复杂优化领域元启发式算法的有效方法。

Abstract: Integrating Large Language Models (LLMs) within metaheuristics opens a novel
path for solving complex combinatorial optimization problems. While most
existing approaches leverage LLMs for code generation to create or refine
specific heuristics, they often overlook the structural properties of
individual problem instances. In this work, we introduce a novel framework that
integrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the
NP-hard Longest Run Subsequence problem. Our approach extends the
instance-driven heuristic bias paradigm by introducing a human-LLM
collaborative process to co-design and implement a set of computationally
efficient metrics. The LLM analyzes these instance-specific metrics to generate
a tailored heuristic bias, which steers the BRKGA toward promising areas of the
search space. We conduct a comprehensive experimental evaluation, including
rigorous statistical tests, convergence and behavioral analyses, and targeted
ablation studies, comparing our method against a standard BRKGA baseline across
1,050 generated instances of varying complexity. Results show that our
top-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically
significant improvements over the baseline, particularly on the most complex
instances. Our findings confirm that leveraging an LLM to produce an a priori,
instance-driven heuristic bias is a valuable approach for enhancing
metaheuristics in complex optimization domains.

</details>


### [324] [Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks](https://arxiv.org/abs/2509.10077)
*Simen Storesund,Kristian Valset Aars,Robin Dietrich,Nicolai Waniek*

Main category: cs.NE

TL;DR: 该算法提出了一种生物可学的、基于脉冲的局部消息传递方法，用于在存在实际处理延迟的情况下计算最短路径。


<details>
  <summary>Details</summary>
Motivation: 现有的图算法和强化学习方法在生物学上不可行，无法解释快速的行为适应。

Method: 通过利用脉冲时间巧合，算法识别最优路径上的节点。神经元接收到的抑制-兴奋消息对的时间早于预期，会减少其响应延迟，从而从目标到源产生时间压缩。

Result: 通过理论证明和在随机空间网络上的模拟，证明了该算法能够收敛并仅使用基于时间的机制发现所有最短路径。

Conclusion: 该算法表明，仅通过短期时序动力学就可以计算出最短路径，这为理解生物网络如何仅通过局部计算和相对脉冲时间预测来解决复杂计算问题提供了新的见解。

Abstract: Efficient planning and sequence selection are central to intelligence, yet
current approaches remain largely incompatible with biological computation.
Classical graph algorithms like Dijkstra's or A* require global state and
biologically implausible operations such as backtracing, while reinforcement
learning methods rely on slow gradient-based policy updates that appear
inconsistent with rapid behavioral adaptation observed in natural systems.
  We propose a biologically plausible algorithm for shortest-path computation
that operates through local spike-based message-passing with realistic
processing delays. The algorithm exploits spike-timing coincidences to identify
nodes on optimal paths: Neurons that receive inhibitory-excitatory message
pairs earlier than predicted reduce their response delays, creating a temporal
compression that propagates backwards from target to source. Through analytical
proof and simulations on random spatial networks, we demonstrate that the
algorithm converges and discovers all shortest paths using purely timing-based
mechanisms. By showing how short-term timing dynamics alone can compute
shortest paths, this work provides new insights into how biological networks
might solve complex computational problems through purely local computation and
relative spike-time prediction. These findings open new directions for
understanding distributed computation in biological and artificial systems,
with possible implications for computational neuroscience, AI, reinforcement
learning, and neuromorphic systems.

</details>
