<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 159]
- [cs.CL](#cs.CL) [Total: 109]
- [eess.SP](#eess.SP) [Total: 6]
- [physics.app-ph](#physics.app-ph) [Total: 5]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.MA](#cs.MA) [Total: 7]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 22]
- [cs.AR](#cs.AR) [Total: 3]
- [quant-ph](#quant-ph) [Total: 51]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.NE](#cs.NE) [Total: 7]
- [cs.RO](#cs.RO) [Total: 47]
- [eess.SY](#eess.SY) [Total: 9]
- [cs.LO](#cs.LO) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 8]
- [cs.AI](#cs.AI) [Total: 51]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.LG](#cs.LG) [Total: 180]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Random Direct Preference Optimization for Radiography Report Generation](https://arxiv.org/abs/2509.21351)
*Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev*

Main category: cs.CV

TL;DR: 一种无需人工偏好标注即可提高放射学报告生成准确性的新框架，它利用随机对比采样和直接偏好优化。


<details>
  <summary>Details</summary>
Motivation: 当前的放射学报告生成（RRG）方法尚未达到临床部署所需的水准，而大型视觉语言模型（VLM）在通用领域取得了显著进展，这为改进RRG提供了新的方向。

Method: 提出一个模型无关的框架，利用直接偏好优化（DPO）和随机对比采样来构建训练对，从而提高RRG的准确性，该方法不依赖奖励模型或人类偏好标注。

Result: 通过在三个最先进的模型上进行实验，随机DPO方法将临床性能指标提高了多达5%，且无需额外训练数据。

Conclusion: 所提出的随机DPO框架能够有效地提升现有RRG模型的性能，且无需额外的标注数据或奖励模型，为实现更高质量的临床放射学报告生成提供了有前景的途径。

Abstract: Radiography Report Generation (RRG) has gained significant attention in
medical image analysis as a promising tool for alleviating the growing workload
of radiologists. However, despite numerous advancements, existing methods have
yet to achieve the quality required for deployment in real-world clinical
settings. Meanwhile, large Visual Language Models (VLMs) have demonstrated
remarkable progress in the general domain by adopting training strategies
originally designed for Large Language Models (LLMs), such as alignment
techniques. In this paper, we introduce a model-agnostic framework to enhance
RRG accuracy using Direct Preference Optimization (DPO). Our approach leverages
random contrastive sampling to construct training pairs, eliminating the need
for reward models or human preference annotations. Experiments on supplementing
three state-of-the-art models with our Random DPO show that our method improves
clinical performance metrics by up to 5%, without requiring any additional
training data.

</details>


### [2] [Improving Autism Detection with Multimodal Behavioral Analysis](https://arxiv.org/abs/2509.21352)
*William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla*

Main category: cs.CV

TL;DR: 由于现有自闭症谱系障碍（ASC）诊断方法复杂且资源消耗大，本研究提出了新的计算机辅助诊断方法。研究使用了一个包含325名参与者（168名ASC，157名非ASC）的大型、平衡数据集，并进行了多模态分析（面部表情、语音韵律、头部运动、心率变异性、眼球注视行为）。为了改进眼球注视分析的局限性，研究引入了新的统计描述符，将眼球注视分类准确率从64%提高到69%。通过 late fusion 技术，综合多模态行为标记，最终实现了74%的分类准确率，证明了该方法在支持自闭症评估方面的潜力，可用于开发可扩展的视频筛查工具。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机辅助自闭症谱系障碍（ASC）诊断方法在处理复杂性、资源消耗、眼球注视特征表现不佳以及现实世界泛化能力不足等方面存在挑战。

Method: 本研究分析了一个包含168名ASC患者和157名非ASC参与者的数据集，并对参与者的面部表情、语音韵律、头部运动、心率变异性（HRV）和眼球注视行为进行了多模态分析。为了解决先前眼球注视模型存在的局限性，研究引入了新的统计描述符来量化眼球注视角度的变化性，并采用了 late fusion 技术整合多模态信息。

Result: 新的统计描述符将基于眼球注视的分类准确率从64%提高到69%。通过 late fusion 技术，综合多模态行为标记，最终实现了74%的分类准确率。

Conclusion: 本研究通过多模态分析和创新的眼球注视特征描述，显著提高了ASC的计算机辅助诊断准确率，证明了该方法在支持可扩展的视频筛查工具方面的潜力。

Abstract: Due to the complex and resource-intensive nature of diagnosing Autism
Spectrum Condition (ASC), several computer-aided diagnostic support methods
have been proposed to detect autism by analyzing behavioral cues in patient
video data. While these models show promising results on some datasets, they
struggle with poor gaze feature performance and lack of real-world
generalizability. To tackle these challenges, we analyze a standardized video
dataset comprising 168 participants with ASC (46% female) and 157 non-autistic
participants (46% female), making it, to our knowledge, the largest and most
balanced dataset available. We conduct a multimodal analysis of facial
expressions, voice prosody, head motion, heart rate variability (HRV), and gaze
behavior. To address the limitations of prior gaze models, we introduce novel
statistical descriptors that quantify variability in eye gaze angles, improving
gaze-based classification accuracy from 64% to 69% and aligning computational
findings with clinical research on gaze aversion in ASC. Using late fusion, we
achieve a classification accuracy of 74%, demonstrating the effectiveness of
integrating behavioral markers across multiple modalities. Our findings
highlight the potential for scalable, video-based screening tools to support
autism assessment.

</details>


### [3] [KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache](https://arxiv.org/abs/2509.21354)
*Wanshun Xu,Long Zhuang*

Main category: cs.CV

TL;DR: KV-Efficient VLA 通过一种轻量级、训练友好的机制来压缩 KV 缓存，实现了高达 1.21 倍的推理加速和 36% 的 KV 内存减少，同时最大限度地减少了对任务成功率的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的 Vision-Language-Action (VLA) 模型在可扩展性方面受到注意力二次成本和长序列推理中 KV 内存无限增长的限制，阻碍了实时部署。KV-Efficient VLA 旨在解决这些效率问题。

Method: KV-Efficient VLA 提出了一种模型无关的内存压缩框架，通过将 KV 缓存分区为固定大小的块，并使用一个循环门控模块，根据学习到的效用分数来汇总和过滤历史上下文，从而在保持因果关系的同时保留近期细节并修剪低相关性内存。

Result: KV-Efficient VLA 在理论上实现了高达 1.21 倍的推理速度提升和 36% 的 KV 内存减少，同时对任务成功率的影响极小。

Conclusion: KV-Efficient VLA 是一种无模型的方法，可以无缝集成到现有的 VLA 模型中，通过有效的内存压缩实现可扩展推理，而无需修改训练流程或下游控制逻辑。

Abstract: Vision-Language-Action (VLA) models promise unified robotic perception and
control, yet their scalability is constrained by the quadratic cost of
attention and the unbounded growth of key-value (KV) memory during long-horizon
inference. While recent methods improve generalization through scaling backbone
architectures, they often neglect the inference inefficiencies critical to
real-time deployment. In this work, we present KV-Efficient VLA, a
model-agnostic memory compression framework that addresses these limitations by
introducing a lightweight, training-friendly mechanism to selectively retain
high-utility context. Our method partitions the KV cache into fixed size chunks
and employs a recurrent gating module to summarize and filter historical
context according to learned utility scores. This design preserves recent
fine-grained detail while aggressively pruning stale, low-relevance memory, all
while maintaining causality. Theoretically, KV-Efficient VLA yields up to 1.21x
inference speedup and 36% KV memory reduction, with minimal impact on task
success. Our method integrates seamlessly into existing autoregressive and
hybrid VLA stacks, enabling scalable inference without modifying training
pipelines or downstream control logic.

</details>


### [4] [Phrase-grounded Fact-checking for Automatically Generated Chest X-ray Reports](https://arxiv.org/abs/2509.21356)
*Razi Mahmood,Diego Machado-Reyes,Joy Wu,Parisa Kaviani,Ken C. L. Wong,Niharika D'Souza,Mannudeep Kalra,Ge Wang,Pingkun Yan,Tanveer Syeda-Mahmood*

Main category: cs.CV

TL;DR: 本项目提出了一种新颖的短语事实核查模型（FC模型），用于检测自动生成的胸部放射学报告中的错误及其指示位置，以解决大型视觉语言模型（VLM）在生成报告时出现的幻觉和事实错误问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型（VLM）在生成胸部X射线报告时出现的幻觉和事实错误问题，提高报告的临床准确性。

Method: 1.通过扰动真实报告中的发现和位置，生成包含真实和虚假发现-位置对的合成数据集。
2.训练一个多标签交叉模态对比回归网络来学习检测报告中的错误。

Result: 该模型在多个X射线数据集上实现了高精度的发现真实性预测和定位，并且能够有效检测最先进的报告生成器生成的报告中的错误，与基于真实标签的验证一致性相关系数达到0.997。

Conclusion: 所提出的FC模型能够有效检测自动生成的放射学报告中的事实错误，并能准确定位这些错误，有望在放射学工作流程中用于临床推理。

Abstract: With the emergence of large-scale vision language models (VLM), it is now
possible to produce realistic-looking radiology reports for chest X-ray images.
However, their clinical translation has been hampered by the factual errors and
hallucinations in the produced descriptions during inference. In this paper, we
present a novel phrase-grounded fact-checking model (FC model) that detects
errors in findings and their indicated locations in automatically generated
chest radiology reports.
  Specifically, we simulate the errors in reports through a large synthetic
dataset derived by perturbing findings and their locations in ground truth
reports to form real and fake findings-location pairs with images. A new
multi-label cross-modal contrastive regression network is then trained on this
dataset. We present results demonstrating the robustness of our method in terms
of accuracy of finding veracity prediction and localization on multiple X-ray
datasets. We also show its effectiveness for error detection in reports of SOTA
report generators on multiple datasets achieving a concordance correlation
coefficient of 0.997 with ground truth-based verification, thus pointing to its
utility during clinical inference in radiology workflows.

</details>


### [5] [MDF-MLLM: Deep Fusion Through Cross-Modal Feature Alignment for Contextually Aware Fundoscopic Image Classification](https://arxiv.org/abs/2509.21358)
*Jason Jordan,Mohammadreza Akbari Lor,Peter Koulen,Mei-Ling Shyu,Shu-Ching Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种新的多模态深度学习架构MDF-MLLM，通过融合视网膜眼底图像的细粒度特征和全局文本上下文，显著提高了眼底图像疾病分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态语言模型（MLLMs）在捕捉视网膜疾病诊断所需的低级空间细节方面存在不足，本研究旨在解决此问题。

Method: 提出了一种名为MDF-MLLM的新架构，该架构将U-Net编码器层的跳跃特征集成到LLaMA 3.2 11B MLLM的交叉注意力块中，并使用多尺度特征融合技术。

Result: 在包含1,305个眼底图像-文本对的数据集上进行评估，MDF-MLLM在疾病分类任务上实现了94%的准确率，相比基线MLLM（60%准确率）提高了56%，召回率和F1分数分别提高了67%和35%。

Conclusion: MDF-MLLM通过多尺度特征融合，在眼底图像疾病分类方面表现优于传统MLLM基线，为临床决策支持系统提供了一个可推广、可解释且模块化的框架。

Abstract: This study aimed to enhance disease classification accuracy from retinal
fundus images by integrating fine-grained image features and global textual
context using a novel multimodal deep learning architecture. Existing
multimodal large language models (MLLMs) often struggle to capture low-level
spatial details critical for diagnosing retinal diseases such as glaucoma,
diabetic retinopathy, and retinitis pigmentosa. This model development and
validation study was conducted on 1,305 fundus image-text pairs compiled from
three public datasets (FIVES, HRF, and StoneRounds), covering acquired and
inherited retinal diseases, and evaluated using classification accuracy and
F1-score. The MDF-MLLM integrates skip features from four U-Net encoder layers
into cross-attention blocks within a LLaMA 3.2 11B MLLM. Vision features are
patch-wise projected and fused using scaled cross-attention and FiLM-based
U-Net modulation. Baseline MLLM achieved 60% accuracy on the dual-type disease
classification task. MDF-MLLM, with both U-Net and MLLM components fully
fine-tuned during training, achieved a significantly higher accuracy of 94%,
representing a 56% improvement. Recall and F1-scores improved by as much as 67%
and 35% over baseline, respectively. Ablation studies confirmed that the
multi-depth fusion approach contributed to substantial gains in spatial
reasoning and classification, particularly for inherited diseases with rich
clinical text. MDF-MLLM presents a generalizable, interpretable, and modular
framework for fundus image classification, outperforming traditional MLLM
baselines through multi-scale feature fusion. The architecture holds promise
for real-world deployment in clinical decision support systems. Future work
will explore synchronized training techniques, a larger pool of diseases for
more generalizability, and extending the model for segmentation tasks.

</details>


### [6] [Multimodal Prompt Decoupling Attack on the Safety Filters in Text-to-Image Models](https://arxiv.org/abs/2509.21360)
*Xingkai Peng,Jun Jiang,Meng Tong,Shuai Li,Weiming Zhang,Nenghai Yu,Kejiang Chen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-to-image (T2I) models have been widely applied in generating
high-fidelity images across various domains. However, these models may also be
abused to produce Not-Safe-for-Work (NSFW) content via jailbreak attacks.
Existing jailbreak methods primarily manipulate the textual prompt, leaving
potential vulnerabilities in image-based inputs largely unexplored. Moreover,
text-based methods face challenges in bypassing the model's safety filters. In
response to these limitations, we propose the Multimodal Prompt Decoupling
Attack (MPDA), which utilizes image modality to separate the harmful semantic
components of the original unsafe prompt. MPDA follows three core steps:
firstly, a large language model (LLM) decouples unsafe prompts into pseudo-safe
prompts and harmful prompts. The former are seemingly harmless sub-prompts that
can bypass filters, while the latter are sub-prompts with unsafe semantics that
trigger filters. Subsequently, the LLM rewrites the harmful prompts into
natural adversarial prompts to bypass safety filters, which guide the T2I model
to modify the base image into an NSFW output. Finally, to ensure semantic
consistency between the generated NSFW images and the original unsafe prompts,
the visual language model generates image captions, providing a new pathway to
guide the LLM in iterative rewriting and refining the generated content.

</details>


### [7] [A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised](https://arxiv.org/abs/2509.21363)
*Runmin Wu,Mengyang Feng,Wenlong Guan,Dong Wang,Huchuan Lu,Errui Ding*

Main category: cs.CV

TL;DR: 深度学习在显著目标检测中虽有进展，但仍存在预测不完整和边界不准确的问题。本文提出联合显著目标检测、前景轮廓检测和边缘检测进行监督训练，通过相互学习模块（MLM）提升模型性能，在七个数据集上均达到 SOTA 效果。


<details>
  <summary>Details</summary>
Motivation: 深度学习在显著目标检测中存在预测不完整和边界不准确的问题，需要改进。

Method: 提出联合显著目标检测、前景轮廓检测和边缘检测进行监督训练，并设计了多分支互学习模块（MLM）。

Result: 在七个挑战性数据集上进行了广泛的实验，证明了所提方法在显著目标检测和边缘检测方面均取得了最先进的结果。

Conclusion: 所提出的方法通过联合多任务学习和互学习模块，有效解决了显著目标检测中的痛点，并提升了边缘检测的精度。

Abstract: Though deep learning techniques have made great progress in salient object
detection recently, the predicted saliency maps still suffer from incomplete
predictions due to the internal complexity of objects and inaccurate boundaries
caused by strides in convolution and pooling operations. To alleviate these
issues, we propose to train saliency detection networks by exploiting the
supervision from not only salient object detection, but also foreground contour
detection and edge detection. First, we leverage salient object detection and
foreground contour detection tasks in an intertwined manner to generate
saliency maps with uniform highlight. Second, the foreground contour and edge
detection tasks guide each other simultaneously, thereby leading to precise
foreground contour prediction and reducing the local noises for edge
prediction. In addition, we develop a novel mutual learning module (MLM) which
serves as the building block of our method. Each MLM consists of multiple
network branches trained in a mutual learning manner, which improves the
performance by a large margin. Extensive experiments on seven challenging
datasets demonstrate that the proposed method has delivered state-of-the-art
results in both salient object detection and edge detection.

</details>


### [8] [MAJORScore: A Novel Metric for Evaluating Multimodal Relevance via Joint Representation](https://arxiv.org/abs/2509.21365)
*Zhicheng Du,Qingyang Shi,Jiasheng Lu,Yingshan Liang,Xinyu Zhang,Yiran Wang,Peiwu Qin*

Main category: cs.CV

TL;DR: MAJORScore是第一个用于评估多模态（N>=3）相关性的指标，它通过多模态联合表示来解决现有指标仅适用于双模态数据的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态相关性评估指标通常从预训练的对比学习模型中借鉴嵌入能力，但这些指标仅适用于双模态数据，限制了对多模态相似性的评估。

Method: 提出了一种名为MAJORScore的新型评估指标，该指标利用多模态联合表示能力，将多种模态整合到同一潜在空间中，从而在同一尺度上公平地表示和评估不同模态的相关性。

Result: 实验结果表明，MAJORScore在一致性模态上的评估结果提高了26.03%-64.29%，在不一致模态上的评估结果降低了13.28%-20.54%，优于现有方法。

Conclusion: MAJORScore是评估大规模多模态数据集和多模态模型性能的更可靠指标。

Abstract: The multimodal relevance metric is usually borrowed from the embedding
ability of pretrained contrastive learning models for bimodal data, which is
used to evaluate the correlation between cross-modal data (e.g., CLIP).
However, the commonly used evaluation metrics are only suitable for the
associated analysis between two modalities, which greatly limits the evaluation
of multimodal similarity. Herein, we propose MAJORScore, a brand-new evaluation
metric for the relevance of multiple modalities ($N$ modalities, $N\ge3$) via
multimodal joint representation for the first time. The ability of multimodal
joint representation to integrate multiple modalities into the same latent
space can accurately represent different modalities at one scale, providing
support for fair relevance scoring. Extensive experiments have shown that
MAJORScore increases by 26.03%-64.29% for consistent modality and decreases by
13.28%-20.54% for inconsistence compared to existing methods. MAJORScore serves
as a more reliable metric for evaluating similarity on large-scale multimodal
datasets and multimodal model performance evaluation.

</details>


### [9] [Safety Assessment of Scaffolding on Construction Site using AI](https://arxiv.org/abs/2509.21368)
*Sameer Prabhu,Amit Patwardhan,Ramin Karim*

Main category: cs.CV

TL;DR: 该研究提出使用人工智能和点云数据来自动化脚手架安全检查，以提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高建筑行业中脚手架检查的准确性和效率，并改善工人的安全。

Method: 开发了一个基于云的人工智能平台，用于处理和分析脚手架的点云数据，通过比对认证的参考数据和最新的点云数据来检测结构修改。

Result: 该方法能够实现脚手架的自动化监控，减少手动检查的时间和精力，并提高施工现场的安全性。

Conclusion: 基于人工智能和点云数据的自动化脚手架检查方法可以提高检查的准确性和效率，从而提高施工现场的安全性。

Abstract: In the construction industry, safety assessment is vital to ensure both the
reliability of assets and the safety of workers. Scaffolding, a key structural
support asset requires regular inspection to detect and identify alterations
from the design rules that may compromise the integrity and stability. At
present, inspections are primarily visual and are conducted by site manager or
accredited personnel to identify deviations. However, visual inspection is
time-intensive and can be susceptible to human errors, which can lead to unsafe
conditions. This paper explores the use of Artificial Intelligence (AI) and
digitization to enhance the accuracy of scaffolding inspection and contribute
to the safety improvement. A cloud-based AI platform is developed to process
and analyse the point cloud data of scaffolding structure. The proposed system
detects structural modifications through comparison and evaluation of certified
reference data with the recent point cloud data. This approach may enable
automated monitoring of scaffolding, reducing the time and effort required for
manual inspections while enhancing the safety on a construction site.

</details>


### [10] [Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis](https://arxiv.org/abs/2509.21375)
*Aleksa Jelaca,Ying Jiao,Chang Tian,Marie-Francine Moens*

Main category: cs.CV

TL;DR: 通过提示工程实现反事实图像生成，解决文本到图像生成的精细化控制难题，特别是在物体尺寸反差方面。


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成在精细化控制方面仍有不足，特别是反事实控制（生成违背常识的图像）对于创意和探索性应用至关重要。本研究旨在解决文本到图像生成中的反事实尺寸控制问题。

Method: 提出一个自动化的提示工程框架，包含三个组件：图像评估器（用于数据集构建）、监督式提示重写器（生成修改后的提示）和DPO训练的排名器（选择最优提示）。

Result: 构建了首个反事实尺寸文本-图像数据集，并改进了图像评估器，使其性能提升114%。实验证明，该方法优于现有技术和ChatGPT-4o。

Conclusion: 所提出的框架为未来反事实可控性研究奠定了基础。

Abstract: Text-to-image generation has advanced rapidly with large-scale multimodal
training, yet fine-grained controllability remains a critical challenge.
Counterfactual controllability, defined as the capacity to deliberately
generate images that contradict common-sense patterns, remains a major
challenge but plays a crucial role in enabling creativity and exploratory
applications. In this work, we address this gap with a focus on counterfactual
size (e.g., generating a tiny walrus beside a giant button) and propose an
automatic prompt engineering framework that adapts base prompts into revised
prompts for counterfactual images. The framework comprises three components: an
image evaluator that guides dataset construction by identifying successful
image generations, a supervised prompt rewriter that produces revised prompts,
and a DPO-trained ranker that selects the optimal revised prompt. We construct
the first counterfactual size text-image dataset and enhance the image
evaluator by extending Grounded SAM with refinements, achieving a 114 percent
improvement over its backbone. Experiments demonstrate that our method
outperforms state-of-the-art baselines and ChatGPT-4o, establishing a
foundation for future research on counterfactual controllability.

</details>


### [11] [In silico Deep Learning Protocols for Label-Free Super-Resolution Microscopy: A Comparative Study of Network Architectures and SNR Dependence](https://arxiv.org/abs/2509.21376)
*Shiraz S Kaderuppan,Jonathan Mar,Andrew Irvine,Anurag Sharma,Muhammad Ramadan Saifuddin,Wai Leong Eugene Wong,Wai Lok Woo*

Main category: cs.CV

TL;DR: 本研究评估了一种经济的超分辨率光学显微镜方法，使用Zernike相位衬比（PCM）和微分干涉衬比（DIC）显微镜，并利用两种深度神经网络（O-Net和Theta-Net）来提高分辨率。


<details>
  <summary>Details</summary>
Motivation: 解决光学显微镜在分辨率上的局限性（约200nm），并提供一种经济且非专业用户也能使用的方法。

Method: 评估了两种深度神经网络（O-Net和Theta-Net）在分辨包含原子力显微镜（AFM）校准的纳米尺度特征的定制测试目标方面的能力。

Result: 结果表明，O-Net和Theta-Net在图像超分辨率方面表现良好，并且是互补的方法。高信噪比（SNR）有利于O-Net，而低信噪比则有利于Theta-Net。

Conclusion: 模型的架构和图像的信噪比共同影响着深度神经网络在非荧光光学纳米技术中的性能和超分辨率图像的质量。

Abstract: The field of optical microscopy spans across numerous industries and research
domains, ranging from education to healthcare, quality inspection and analysis.
Nonetheless, a key limitation often cited by optical microscopists refers to
the limit of its lateral resolution (typically defined as ~200nm), with
potential circumventions involving either costly external modules (e.g.
confocal scan heads, etc) and/or specialized techniques [e.g. super-resolution
(SR) fluorescent microscopy]. Addressing these challenges in a normal
(non-specialist) context thus remains an aspect outside the scope of most
microscope users & facilities. This study thus seeks to evaluate an alternative
& economical approach to achieving SR optical microscopy, involving
non-fluorescent phase-modulated microscopical modalities such as Zernike phase
contrast (PCM) and differential interference contrast (DIC) microscopy. Two in
silico deep neural network (DNN) architectures which we developed previously
(termed O-Net and Theta-Net) are assessed on their abilities to resolve a
custom-fabricated test target containing nanoscale features calibrated via
atomic force microscopy (AFM). The results of our study demonstrate that
although both O-Net and Theta-Net seemingly performed well when super-resolving
these images, they were complementary (rather than competing) approaches to be
considered for image SR, particularly under different image signal-to-noise
ratios (SNRs). High image SNRs favoured the application of O-Net models, while
low SNRs inclined preferentially towards Theta-Net models. These findings
demonstrate the importance of model architectures (in conjunction with the
source image SNR) on model performance and the SR quality of the generated
images where DNN models are utilized for non-fluorescent optical nanoscopy,
even where the same training dataset & number of epochs are being used.

</details>


### [12] [Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation](https://arxiv.org/abs/2509.21377)
*Yinfeng Yu,Hailong Zhang,Meiling Zhu*

Main category: cs.CV

TL;DR: DMTF-AVN 使用多目标Transformer融合视听线索，在机器人导航方面达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 机器人导航中的核心挑战在于有效利用多模态线索，而先前的方法未能充分利用深层感知上下文。

Method: 提出了一种名为DMTF-AVN的多目标Transformer架构，用于过滤和选择性地融合跨模态信息。

Result: 在Replica和Matterport3D数据集上，DMTF-AVN在成功率（SR）、路径效率（SPL）和场景适应性（SNA）方面均取得了最先进的性能。

Conclusion: DMTF-AVN在机器人导航方面取得了最先进的性能，并展现了良好的可扩展性和泛化能力，为先进的多模态融合策略铺平了道路。

Abstract: Audiovisual embodied navigation enables robots to locate audio sources by
dynamically integrating visual observations from onboard sensors with the
auditory signals emitted by the target. The core challenge lies in effectively
leveraging multimodal cues to guide navigation. While prior works have explored
basic fusion of visual and audio data, they often overlook deeper perceptual
context. To address this, we propose the Dynamic Multi-Target Fusion for
Efficient Audio-Visual Navigation (DMTF-AVN). Our approach uses a multi-target
architecture coupled with a refined Transformer mechanism to filter and
selectively fuse cross-modal information. Extensive experiments on the Replica
and Matterport3D datasets demonstrate that DMTF-AVN achieves state-of-the-art
performance, outperforming existing methods in success rate (SR), path
efficiency (SPL), and scene adaptation (SNA). Furthermore, the model exhibits
strong scalability and generalizability, paving the way for advanced multimodal
fusion strategies in robotic navigation. The code and videos are available at
  https://github.com/zzzmmm-svg/DMTF.

</details>


### [13] [SAEmnesia: Erasing Concepts in Diffusion Models with Sparse Autoencoders](https://arxiv.org/abs/2509.21379)
*Enrico Cassano,Riccardo Renzulli,Marco Nurisso,Mirko Zaffaroni,Alan Perotti,Marco Grangetto*

Main category: cs.CV

TL;DR: SAEmnesia是一种监督稀疏自编码器训练方法，通过系统性概念标注促进一对一的概念-神经元映射，从而实现有效的概念遗忘。该方法减少了特征分裂，促进了特征集中化，相比无监督基线，学习到的神经元具有更强的概念关联性。SAEmnesia在推理时将超参数搜索减少了96.67%，在UnlearnCanvas基准测试中提高了9.22%，在连续遗忘任务中提高了28.4%。


<details>
  <summary>Details</summary>
Motivation: 现有的概念遗忘方法在文本到图像扩散模型中需要精确的潜在空间概念表示定位，而稀疏自编码器虽然减少了多义性，但概念表示仍分散在多个潜在特征中，增加了搜索难度。因此，需要一种更有效的方法来促进概念表示的集中化，减少搜索过程。

Method: SAEmnesia是一种监督稀疏自编码器训练方法，通过引入系统性的概念标注，强制实现一对一的概念-神经元映射，以解决特征分裂问题并促进特征集中化。该方法在训练过程中仅增加交叉熵计算的计算开销。

Result: SAEmnesia学习到的神经元具有比无监督基线更强的概念关联性。在推理时，该方法将超参数搜索空间减少了96.67%。在UnlearnCanvas基准测试中，SAEmnesia的性能比现有技术提高了9.22%。在连续遗忘任务中，对于9个对象的移除，SAEmnesia的遗忘准确率提高了28.4%，显示出良好的可扩展性。

Conclusion: SAEmnesia通过监督训练有效促进了概念到神经元的映射，显著提高了概念遗忘的精确性和效率，同时减少了推理时的搜索成本，并在多个基准测试和任务中取得了最先进的性能。

Abstract: Effective concept unlearning in text-to-image diffusion models requires
precise localization of concept representations within the model's latent
space. While sparse autoencoders successfully reduce neuron polysemanticity
(i.e., multiple concepts per neuron) compared to the original network,
individual concept representations can still be distributed across multiple
latent features, requiring extensive search procedures for concept unlearning.
We introduce SAEmnesia, a supervised sparse autoencoder training method that
promotes one-to-one concept-neuron mappings through systematic concept
labeling, mitigating feature splitting and promoting feature centralization.
Our approach learns specialized neurons with significantly stronger concept
associations compared to unsupervised baselines. The only computational
overhead introduced by SAEmnesia is limited to cross-entropy computation during
training. At inference time, this interpretable representation reduces
hyperparameter search by 96.67% with respect to current approaches. On the
UnlearnCanvas benchmark, SAEmnesia achieves a 9.22% improvement over the
state-of-the-art. In sequential unlearning tasks, we demonstrate superior
scalability with a 28.4% improvement in unlearning accuracy for 9-object
removal.

</details>


### [14] [Coreset selection based on Intra-class diversity](https://arxiv.org/abs/2509.21380)
*Imran Ashraf,Mukhtar Ullah,Muhammad Faisal Nadeem,Muhammad Nouman Noor*

Main category: cs.CV

TL;DR: 通过提取类内多样性来选择有代表性的数据集子集，以减少深度学习模型的训练时间和计算资源，并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在生物医学图像分类中表现出色，但其训练过程需要大量时间和计算资源，尤其是在进行超参数搜索时。现有方法如随机采样存在数据不平衡和类内多样性不足的问题。

Method: 提出一种智能、轻量级的机制，通过提取类内多样性并形成每类聚类，然后从中进行采样，来选择代表性的训练子集（核心集）。

Result: 在著名的生物医学成像数据集上进行的广泛分类实验表明，所提出的核心集选择方案在均匀条件下，比随机采样方法在多个性能指标上表现更好。

Conclusion: 所提出的基于类内多样性提取和聚类的核心集选择方法，能够更有效地减少深度学习模型的训练时间和计算资源，同时提高模型性能，克服了随机采样的局限性。

Abstract: Deep Learning models have transformed various domains, including the
healthcare sector, particularly biomedical image classification by learning
intricate features and enabling accurate diagnostics pertaining to complex
diseases. Recent studies have adopted two different approaches to train DL
models: training from scratch and transfer learning. Both approaches demand
substantial computational time and resources due to the involvement of massive
datasets in model training. These computational demands are further increased
due to the design-space exploration required for selecting optimal
hyperparameters, which typically necessitates several training rounds. With the
growing sizes of datasets, exploring solutions to this problem has recently
gained the research community's attention. A plausible solution is to select a
subset of the dataset for training and hyperparameter search. This subset,
referred to as the corset, must be a representative set of the original
dataset. A straightforward approach to selecting the coreset could be employing
random sampling, albeit at the cost of compromising the representativeness of
the original dataset. A critical limitation of random sampling is the bias
towards the dominant classes in an imbalanced dataset. Even if the dataset has
inter-class balance, this random sampling will not capture intra-class
diversity. This study addresses this issue by introducing an intelligent,
lightweight mechanism for coreset selection. Specifically, it proposes a method
to extract intra-class diversity, forming per-class clusters that are utilized
for the final sampling. We demonstrate the efficacy of the proposed methodology
by conducting extensive classification experiments on a well-known biomedical
imaging dataset. Results demonstrate that the proposed scheme outperforms the
random sampling approach on several performance metrics for uniform conditions.

</details>


### [15] [The LongiMam model for improved breast cancer risk prediction using longitudinal mammograms](https://arxiv.org/abs/2509.21383)
*Manel Rakez,Thomas Louis,Julien Guillaumin,Foucauld Chamming's,Pierre Fillard,Brice Amadeo,Virginie Rondeau*

Main category: cs.CV

TL;DR: LongiMam是一个端到端的深度学习模型，通过整合当前和最多四张先前的乳腺X线照片，利用纵向成像数据来改进乳腺癌风险预测。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型在处理纵向成像数据、处理数据不平衡和异质性随访方面存在不足，无法适应真实世界的临床筛查场景。

Method: 开发了LongiMam模型，结合了卷积神经网络（CNN）和循环神经网络（RNN），以捕捉预测乳腺癌的空间和时间模式，并整合了当前和最多四张先前的乳腺X线照片。

Result: 在包含不同数量和组成先前的检查场景下，LongiMam在加入先前检查时持续改进了预测效果。结合先前和当前检查优于单一检查模型，而单独使用先前检查效果较差。模型在不同风险群体（如高密度乳腺、55岁以上女性）中均有效，在乳腺密度随时间变化的女性中表现最佳。

Conclusion: 纵向建模能够增强乳腺癌预测能力，支持在筛查项目中利用重复的乳腺X线照片来优化风险分层。LongiMam已作为开源软件公开提供。

Abstract: Risk-adapted breast cancer screening requires robust models that leverage
longitudinal imaging data. Most current deep learning models use single or
limited prior mammograms and lack adaptation for real-world settings marked by
imbalanced outcome distribution and heterogeneous follow-up. We developed
LongiMam, an end-to-end deep learning model that integrates both current and up
to four prior mammograms. LongiMam combines a convolutional and a recurrent
neural network to capture spatial and temporal patterns predictive of breast
cancer. The model was trained and evaluated using a large, population-based
screening dataset with disproportionate case-to-control ratio typical of
clinical screening. Across several scenarios that varied in the number and
composition of prior exams, LongiMam consistently improved prediction when
prior mammograms were included. The addition of prior and current visits
outperformed single-visit models, while priors alone performed less well,
highlighting the importance of combining historical and recent information.
Subgroup analyses confirmed the model's efficacy across key risk groups,
including women with dense breasts and those aged 55 years or older. Moreover,
the model performed best in women with observed changes in mammographic density
over time. These findings demonstrate that longitudinal modeling enhances
breast cancer prediction and support the use of repeated mammograms to refine
risk stratification in screening programs. LongiMam is publicly available as
open-source software.

</details>


### [16] [Assessing the Alignment of Popular CNNs to the Brain for Valence Appraisal](https://arxiv.org/abs/2509.21384)
*Laurent Mertens,Elahe' Yargholi,Laura Van Hove,Hans Op de Beeck,Jan Van den Stock,Joost Vennekens*

Main category: cs.CV

TL;DR: CNNs与人类大脑在社会认知任务中的对应关系有限，但Object2Brain框架有助于分析不同物体类别对CNN-to-human相关性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究CNN与人类大脑在社会认知（特别是图像效价评估）方面的一致性，以探索CNN是否能反映更高阶的脑部处理过程。

Method: 通过关联分析，评估了流行的CNN架构在图像效价评估任务中与人类行为及fMRI数据的对齐程度。提出了Object2Brain框架，结合GradCAM和物体检测，分析不同物体类别对CNN-to-human相关性的影响。

Result: CNN在图像效价评估任务中主要反映了简单的视觉处理，未能体现更高阶的脑部处理。不同的CNN架构在物体类别敏感性方面存在差异。

Conclusion: CNN与人类大脑在社会认知任务中的对应关系有限，主要局限于低级视觉处理。Object2Brain框架能够揭示不同CNN架构在物体类别敏感性方面的差异。

Abstract: Convolutional Neural Networks (CNNs) are a popular type of computer model
that have proven their worth in many computer vision tasks. Moreover, they form
an interesting study object for the field of psychology, with shown
correspondences between the workings of CNNs and the human brain. However,
these correspondences have so far mostly been studied in the context of general
visual perception. In contrast, this paper explores to what extent this
correspondence also holds for a more complex brain process, namely social
cognition. To this end, we assess the alignment between popular CNN
architectures and both human behavioral and fMRI data for image valence
appraisal through a correlation analysis. We show that for this task CNNs
struggle to go beyond simple visual processing, and do not seem to reflect
higher-order brain processing. Furthermore, we present Object2Brain, a novel
framework that combines GradCAM and object detection at the CNN-filter level
with the aforementioned correlation analysis to study the influence of
different object classes on the CNN-to-human correlations. Despite similar
correlation trends, different CNN architectures are shown to display different
object class sensitivities.

</details>


### [17] [Debugging Concept Bottleneck Models through Removal and Retraining](https://arxiv.org/abs/2509.21385)
*Eric Enouen,Sainyam Galhotra*

Main category: cs.CV

TL;DR: Concept Bottleneck Models (CBMs) 引入了一个可解释的调试框架，通过移除和再训练来解决模型与专家推理之间的系统性不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 CBM 框架在处理模型从有偏数据中学习到的捷径等系统性不匹配问题时存在不足，现有干预方法未能解决这些问题。

Method: 提出一个两步调试框架：1. 移除：专家识别并移除不希望出现的概念。2. 再训练：引入 CBDebug 方法，将概念级用户反馈转化为样本级辅助标签，用于监督偏差缓解和定向增强，以减少模型对不希望出现的概念的依赖。

Result: CBDebug 在多个 CBM 架构（PIP-Net, Post-hoc CBM）和具有已知虚假关联的基准测试中，显著优于先前基于再训练的方法。

Conclusion: CBDebug 框架通过有效利用 CBM 的可解释性来处理概念级用户反馈，能够成功缓解模型对不希望出现的概念的依赖，并提高模型的鲁棒性。

Abstract: Concept Bottleneck Models (CBMs) use a set of human-interpretable concepts to
predict the final task label, enabling domain experts to not only validate the
CBM's predictions, but also intervene on incorrect concepts at test time.
However, these interventions fail to address systemic misalignment between the
CBM and the expert's reasoning, such as when the model learns shortcuts from
biased data. To address this, we present a general interpretable debugging
framework for CBMs that follows a two-step process of Removal and Retraining.
In the Removal step, experts use concept explanations to identify and remove
any undesired concepts. In the Retraining step, we introduce CBDebug, a novel
method that leverages the interpretability of CBMs as a bridge for converting
concept-level user feedback into sample-level auxiliary labels. These labels
are then used to apply supervised bias mitigation and targeted augmentation,
reducing the model's reliance on undesired concepts. We evaluate our framework
with both real and automated expert feedback, and find that CBDebug
significantly outperforms prior retraining methods across multiple CBM
architectures (PIP-Net, Post-hoc CBM) and benchmarks with known spurious
correlations.

</details>


### [18] [ShipwreckFinder: A QGIS Tool for Shipwreck Detection in Multibeam Sonar Data](https://arxiv.org/abs/2509.21386)
*Anja Sheppard,Tyler Smithline,Andrew Scheffer,David Smith,Advaith V. Sethuraman,Ryan Bird,Sabrina Lin,Katherine A. Skinner*

Main category: cs.CV

TL;DR: ShipwreckFinder是一款开源QGIS插件，可自动从多波束声纳数据中检测沉船。


<details>
  <summary>Details</summary>
Motivation: 手动检测水下沉船耗时且需要专业知识，因此需要自动化工具。

Method: ShipwreckFinder利用深度学习模型，结合真实和合成数据进行训练，实现对多波束声纳数据的预处理、模型推理、阈值处理，并输出像素级分割掩膜或边界框。

Result: 与现有的ArcGIS工具包和经典方法相比，ShipwreckFinder在沉船分割方面表现出优越的性能。

Conclusion: ShipwreckFinder是一个有效的开源工具，能够自动化沉船检测过程，并提供比现有方法更好的分割性能。

Abstract: In this paper, we introduce ShipwreckFinder, an open-source QGIS plugin that
detects shipwrecks from multibeam sonar data. Shipwrecks are an important
historical marker of maritime history, and can be discovered through manual
inspection of bathymetric data. However, this is a time-consuming process and
often requires expert analysis. Our proposed tool allows users to automatically
preprocess bathymetry data, perform deep learning inference, threshold model
outputs, and produce either pixel-wise segmentation masks or bounding boxes of
predicted shipwrecks. The backbone of this open-source tool is a deep learning
model, which is trained on a variety of shipwreck data from the Great Lakes and
the coasts of Ireland. Additionally, we employ synthetic data generation in
order to increase the size and diversity of our dataset. We demonstrate
superior segmentation performance with our open-source tool and training
pipeline as compared to a deep learning-based ArcGIS toolkit and a more
classical inverse sinkhole detection method. The open-source tool can be found
at https://github.com/umfieldrobotics/ShipwreckFinderQGISPlugin.

</details>


### [19] [Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence](https://arxiv.org/abs/2509.21387)
*Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 神经网路剪枝在不影响效能的同时，可能会影响模型的可解释性。本研究使用 ResNet-18 在 ImageNette 上进行实验，比较不同剪枝程度下，Vanilla Gradients (VG) 和 Integrated Gradients (IG) 的低阶显著性图和高阶概念表示的变化。结果显示，轻至中度剪枝可提升显著性图的聚焦度和忠实度，并保持概念的语义连贯性。然而，过度剪枝会合并异质特征，降低显著性图的稀疏度和概念连贯性，尽管模型准确度可能维持不变。这表明剪枝可以使内部表征更符合人类的注意力模式，但过度剪枝会损害可解释性。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网路剪枝对模型可解释性的影响，特别是对低阶显著性图和高阶概念表示的影响。

Method: 使用 ResNet-18 在 ImageNette 上进行训练，并进行不同程度的幅度剪枝和微调。使用 Vanilla Gradients (VG) 和 Integrated Gradients (IG) 分析显著性图的变化，评估稀疏度和忠实度。同时，运用 CRAFT 进行概念提取，追踪学习到的概念的语义连贯性。

Result: 轻至中度剪枝可提升显著性图的聚焦度和忠实度，并保持概念的语义连贯性。过度剪枝会合并异质特征，降低显著性图的稀疏度和概念连贯性，尽管模型准确度可能维持不变。

Conclusion: 剪枝可以在一定程度上改善神经网路的内部表征，使其更符合人类的注意力模式，但过度剪枝会损害模型的可解释性。

Abstract: Prior works have shown that neural networks can be heavily pruned while
preserving performance, but the impact of pruning on model interpretability
remains unclear. In this work, we investigate how magnitude-based pruning
followed by fine-tuning affects both low-level saliency maps and high-level
concept representations. Using a ResNet-18 trained on ImageNette, we compare
post-hoc explanations from Vanilla Gradients (VG) and Integrated Gradients (IG)
across pruning levels, evaluating sparsity and faithfulness. We further apply
CRAFT-based concept extraction to track changes in semantic coherence of
learned concepts. Our results show that light-to-moderate pruning improves
saliency-map focus and faithfulness while retaining distinct, semantically
meaningful concepts. In contrast, aggressive pruning merges heterogeneous
features, reducing saliency map sparsity and concept coherence despite
maintaining accuracy. These findings suggest that while pruning can shape
internal representations toward more human-aligned attention patterns,
excessive pruning undermines interpretability.

</details>


### [20] [TUN3D: Towards Real-World Scene Understanding from Unposed Images](https://arxiv.org/abs/2509.21388)
*Anton Konushin,Nikita Drozdov,Bulat Gabdullin,Alexey Zakharov,Anna Vorontsova,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: TUN3D是首个仅使用多视图图像（无需相机姿态或深度监督）即可进行室内场景布局估计和3D对象检测的方法，并在三个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有室内场景理解方法大多依赖点云数据，但大多数消费级相机缺乏深度传感器，视觉数据更为普遍。TUN3D旨在解决这一限制，提供一种仅使用多视图图像的方法。

Method: TUN3D 使用轻量级稀疏卷积骨干网络，并包含两个独立分支：一个用于3D对象检测，另一个用于布局估计，其中采用了新颖且有效的参数化墙体表示方法。

Result: TUN3D 在三个具有挑战性的场景理解基准测试中均达到了最先进的性能，包括使用真实点云、带姿态的图像和不带姿态的图像。在3D对象检测方面，其性能与专用方法相当，而在布局估计方面，它显著提升了性能。

Conclusion: TUN3D 实现了整体室内场景理解的最优性能，尤其在布局估计方面设立了新的标杆。

Abstract: Layout estimation and 3D object detection are two fundamental tasks in indoor
scene understanding. When combined, they enable the creation of a compact yet
semantically rich spatial representation of a scene. Existing approaches
typically rely on point cloud input, which poses a major limitation since most
consumer cameras lack depth sensors and visual-only data remains far more
common. We address this issue with TUN3D, the first method that tackles joint
layout estimation and 3D object detection in real scans, given multi-view
images as input, and does not require ground-truth camera poses or depth
supervision. Our approach builds on a lightweight sparse-convolutional backbone
and employs two dedicated heads: one for 3D object detection and one for layout
estimation, leveraging a novel and effective parametric wall representation.
Extensive experiments show that TUN3D achieves state-of-the-art performance
across three challenging scene understanding benchmarks: (i) using ground-truth
point clouds, (ii) using posed images, and (iii) using unposed images. While
performing on par with specialized 3D object detection methods, TUN3D
significantly advances layout estimation, setting a new benchmark in holistic
indoor scene understanding. Code is available at
https://github.com/col14m/tun3d .

</details>


### [21] [Large AI Model-Enabled Generative Semantic Communications for Image Transmission](https://arxiv.org/abs/2509.21394)
*Qiyu Ma,Wanli Ni,Zhijin Qin*

Main category: cs.CV

TL;DR: 本系统通过区分关键区和非关键区来优化生成式语义通信中的图像传输，并采用轻量级AI模型部署策略以提高资源利用率。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方法忽略图像区域的重要性差异，影响关键视觉内容的重建质量。

Method: 将图像分割为关键区（使用面向图像的语义编码器处理）和非关键区（使用图像到文本模型压缩），并采用模型量化和低秩自适应微调等轻量级部署策略。

Result: 与传统方法相比，本系统在语义保真度和视觉质量方面表现更优。

Conclusion: 提出的系统在图像传输任务中是有效的。

Abstract: The rapid development of generative artificial intelligence (AI) has
introduced significant opportunities for enhancing the efficiency and accuracy
of image transmission within semantic communication systems. Despite these
advancements, existing methodologies often neglect the difference in importance
of different regions of the image, potentially compromising the reconstruction
quality of visually critical content. To address this issue, we introduce an
innovative generative semantic communication system that refines semantic
granularity by segmenting images into key and non-key regions. Key regions,
which contain essential visual information, are processed using an image
oriented semantic encoder, while non-key regions are efficiently compressed
through an image-to-text modeling approach. Additionally, to mitigate the
substantial storage and computational demands posed by large AI models, the
proposed system employs a lightweight deployment strategy incorporating model
quantization and low-rank adaptation fine-tuning techniques, significantly
boosting resource utilization without sacrificing performance. Simulation
results demonstrate that the proposed system outperforms traditional methods in
terms of both semantic fidelity and visual quality, thereby affirming its
effectiveness for image transmission tasks.

</details>


### [22] [mmHSense: Multi-Modal and Distributed mmWave ISAC Datasets for Human Sensing](https://arxiv.org/abs/2509.21396)
*Nabeel Nisar Bhat,Maksim Karnaukh,Stein Vandenbroeke,Wouter Lemoine,Jakob Struye,Jesus Omar Lacruz,Siddhartha Kumar,Mohammad Hossein Moghaddam,Joerg Widmer,Rafael Berkvens,Jeroen Famaey*

Main category: cs.CV

TL;DR: mmHSense是一个开放的mmWave数据集，用于支持ISAC系统中的人类感知研究，可用于手势识别、身份识别、姿态估计和定位等应用。


<details>
  <summary>Details</summary>
Motivation: 支持集成传感与通信（ISAC）系统中的人类感知研究，特别是利用mmWave技术。

Method: 描述了mmHSense数据集的测试平台、实验设置和信号特征，并通过参数高效微调来适应不同任务。

Result: 展示了数据集在特定下游任务上的效用，并通过参数高效微调在保持性能的同时显著降低了计算复杂性。

Conclusion: mmHSense数据集为mmWave ISAC系统中的人类感知研究提供了宝贵的资源，并展示了参数高效微调在ISAC模型适应性方面的潜力。

Abstract: This article presents mmHSense, a set of open labeled mmWave datasets to
support human sensing research within Integrated Sensing and Communication
(ISAC) systems. The datasets can be used to explore mmWave ISAC for various end
applications such as gesture recognition, person identification, pose
estimation, and localization. Moreover, the datasets can be used to develop and
advance signal processing and deep learning research on mmWave ISAC. This
article describes the testbed, experimental settings, and signal features for
each dataset. Furthermore, the utility of the datasets is demonstrated through
validation on a specific downstream task. In addition, we demonstrate the use
of parameter-efficient fine-tuning to adapt ISAC models to different tasks,
significantly reducing computational complexity while maintaining performance
on prior tasks.

</details>


### [23] [Skeleton Sparsification and Densification Scale-Spaces](https://arxiv.org/abs/2509.21398)
*Julia Gierke,Pascal Peter*

Main category: cs.CV

TL;DR: 利用骨架化尺度空间实现形状的层次化简化，解决了传统骨架化对噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 传统骨架化（内轴）对噪声敏感，导致边界微小变化引起骨架不成比例的膨胀。虽然可以用剪枝方法缓解，但我们提出了一种新的方法。

Method: 我们结合了骨架化和尺度空间的概念，引入了骨架化尺度空间。该框架通过对内轴进行稀疏化来实现形状的层次化简化。我们提供了连续和离散的理论基础，并通过稠密化进行了扩展，允许从粗到精的逆向进展，甚至可以生成超出原始骨架的超完备形状表示。

Result: 我们的框架天然满足层次化架构、可控简化和几何变换的等变性等关键尺度空间性质。通过概念验证实验，我们在鲁棒骨架化、形状压缩和增材制造的刚度增强等实际任务中证明了其有效性。

Conclusion: 所提出的骨架化尺度空间框架为形状表示和处理提供了一种新颖且有效的方法，克服了传统方法的局限性。

Abstract: The Hamilton-Jacobi skeleton, also known as the medial axis, is a powerful
shape descriptor that represents binary objects in terms of the centres of
maximal inscribed discs. Despite its broad applicability, the medial axis
suffers from sensitivity to noise: minor boundary variations can lead to
disproportionately large and undesirable expansions of the skeleton. Classical
pruning methods mitigate this shortcoming by systematically removing extraneous
skeletal branches. This sequential simplification of skeletons resembles the
principle of sparsification scale-spaces that embed images into a family of
reconstructions from increasingly sparse pixel representations.
  We combine both worlds by introducing skeletonisation scale-spaces: They
leverage sparsification of the medial axis to achieve hierarchical
simplification of shapes. Unlike conventional pruning, our framework inherently
satisfies key scale-space properties such as hierarchical architecture,
controllable simplification, and equivariance to geometric transformations. We
provide a rigorous theoretical foundation in both continuous and discrete
formulations and extend the concept further with densification. This allows
inverse progression from coarse to fine scales and can even reach beyond the
original skeleton to produce overcomplete shape representations with relevancy
for practical applications.
  Through proof-of-concept experiments, we demonstrate the effectiveness of our
framework for practical tasks including robust skeletonisation, shape
compression, and stiffness enhancement for additive manufacturing.

</details>


### [24] [Downscaling climate projections to 1 km with single-image super resolution](https://arxiv.org/abs/2509.21399)
*Petr Košťál,Pavel Kordík,Ondřej Podsztavek*

Main category: cs.CV

TL;DR: 利用单张图像超分辨率模型将低分辨率气候投影降尺度至1公里。


<details>
  <summary>Details</summary>
Motivation: 现有气候投影空间分辨率低（例如12.5公里），限制了其在地方决策中的应用。

Method: 训练单张图像超分辨率模型处理气候指标，并将其应用于低分辨率气候投影，以1公里分辨率进行统计降尺度。由于缺乏高分辨率气候投影用于训练，因此使用高分辨率观测网格数据集进行训练。

Result: 实验表明，单张图像超分辨率模型可将气候投影降尺度至1公里，且与低分辨率气候投影相比，气候指标的误差并未增加。

Conclusion: 单张图像超分辨率模型能够有效降尺度气候投影，解决了现有模型分辨率不足的问题，并且在不增加气候指标误差的情况下提高了气候信息的分辨率。

Abstract: High-resolution climate projections are essential for local decision-making.
However, available climate projections have low spatial resolution (e.g. 12.5
km), which limits their usability. We address this limitation by leveraging
single-image super-resolution models to statistically downscale climate
projections to 1-km resolution. Since high-resolution climate projections are
unavailable for training, we train models on a high-resolution observational
gridded data set and apply them to low-resolution climate projections. We
propose a climate indicator-based assessment using observed climate indices
computed at weather station locations to evaluate the downscaled climate
projections without ground-truth high-resolution climate projections.
Experiments on daily mean temperature demonstrate that single-image
super-resolution models can downscale climate projections without increasing
the error of climate indicators compared to low-resolution climate projections.

</details>


### [25] [JaiLIP: Jailbreaking Vision-Language Models via Loss Guided Image Perturbation](https://arxiv.org/abs/2509.21401)
*Md Jueal Mia,M. Hadi Amini*

Main category: cs.CV

TL;DR: 图像扰动攻击能有效且不易察觉地实现视觉语言模型（VLM）的越狱，并产生有害输出，但目前的方法存在不稳定的性能和明显的扰动问题。本研究提出JaiLIP（Loss-guided Image Perturbation），一种在图像空间中进行越狱的攻击方法，通过最小化干净图像与对抗性图像之间的均方误差（MSE）损失和模型有害输出损失的联合目标来实现。实验证明，JaiLIP生成的对抗性图像具有高度有效性和不可感知性，在产生毒性方面优于现有方法。此外，在交通运输领域进行的评估表明，该攻击方法在特定领域之外也具有实用性。研究结果强调了基于图像的越狱攻击的实际挑战以及对VLM的有效防御机制的需求。


<details>
  <summary>Details</summary>
Motivation: 现有越狱VLM的方法在性能不稳定和扰动可见方面存在问题，尤其是在图像扰动攻击方面，需要更有效且不易察觉的方法。

Method: 提出JaiLIP（Loss-guided Image Perturbation）方法，通过最小化干净图像与对抗性图像之间的均方误差（MSE）损失与模型有害输出损失的联合目标来实现图像空间中的越狱攻击。

Result: JaiLIP方法能够生成高度有效且不可察觉的对抗性图像，在产生毒性方面优于现有方法。在交通运输领域进行的评估也展示了该方法的实用性。

Conclusion: 基于图像的越狱攻击对VLM提出了实际挑战，需要开发有效的防御机制来应对此类攻击。

Abstract: Vision-Language Models (VLMs) have remarkable abilities in generating
multimodal reasoning tasks. However, potential misuse or safety alignment
concerns of VLMs have increased significantly due to different categories of
attack vectors. Among various attack vectors, recent studies have demonstrated
that image-based perturbations are particularly effective in generating harmful
outputs. In the literature, many existing techniques have been proposed to
jailbreak VLMs, leading to unstable performance and visible perturbations. In
this study, we propose Jailbreaking with Loss-guided Image Perturbation
(JaiLIP), a jailbreaking attack in the image space that minimizes a joint
objective combining the mean squared error (MSE) loss between clean and
adversarial image with the models harmful-output loss. We evaluate our proposed
method on VLMs using standard toxicity metrics from Perspective API and
Detoxify. Experimental results demonstrate that our method generates highly
effective and imperceptible adversarial images, outperforming existing methods
in producing toxicity. Moreover, we have evaluated our method in the
transportation domain to demonstrate the attacks practicality beyond toxic text
generation in specific domain. Our findings emphasize the practical challenges
of image-based jailbreak attacks and the need for efficient defense mechanisms
for VLMs.

</details>


### [26] [Overview of ExpertLifeCLEF 2018: how far automated identification systems are from the best experts?](https://arxiv.org/abs/2509.21419)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 深度学习模型在动植物识别方面取得了显著进展，其性能接近人类专家的水平。


<details>
  <summary>Details</summary>
Motivation: 量化自动化系统与人类专家在动植物识别方面的不确定性，并进行比较。

Method: 在LifeCLEF 2018 ExpertCLEF挑战赛中，评估了19个深度学习系统和9位植物学专家的表现。

Result: 最先进的深度学习模型的性能接近顶尖的人类专家。

Conclusion: 深度学习在动植物识别领域的应用已达到与人类专家相当的水平，为未来的研究和应用提供了新的可能性。

Abstract: Automated identification of plants and animals has improved considerably in
the last few years, in particular thanks to the recent advances in deep
learning. The next big question is how far such automated systems are from the
human expertise. Indeed, even the best experts are sometimes confused and/or
disagree between each others when validating visual or audio observations of
living organism. A picture actually contains only a partial information that is
usually not sufficient to determine the right species with certainty.
Quantifying this uncertainty and comparing it to the performance of automated
systems is of high interest for both computer scientists and expert
naturalists. The LifeCLEF 2018 ExpertCLEF challenge presented in this paper was
designed to allow this comparison between human experts and automated systems.
In total, 19 deep-learning systems implemented by 4 different research teams
were evaluated with regard to 9 expert botanists of the French flora. The main
outcome of this work is that the performance of state-of-the-art deep learning
models is now close to the most advanced human expertise. This paper presents
more precisely the resources and assessments of the challenge, summarizes the
approaches and systems employed by the participating research groups, and
provides an analysis of the main outcomes.

</details>


### [27] [QuadGPT: Native Quadrilateral Mesh Generation with Autoregressive Models](https://arxiv.org/abs/2509.21420)
*Jian Liu,Chunshi Wang,Song Guo,Haohan Weng,Zhen Zhou,Zhiqi Li,Jiaao Yu,Yiling Zhu,Jing Xu,Biwen Lei,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: QuadGPT是首个端到端生成四边形网格的自回归框架，通过统一的拓扑标记和基于强化学习的微调，在生成质量上超越了现有的方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型通过先生成三角形网格再进行合并，导致四边形网格拓扑结构较差。本研究旨在克服这一限制。

Method: 提出了一种名为QuadGPT的自回归框架，它将四边形网格生成视为序列预测问题。该框架包含一个统一的标记方法来处理三角形和四边形的混合拓扑，并采用一种名为tDPO的强化学习微调方法来提高生成质量。

Result: 实验结果表明，QuadGPT在几何精度和拓扑质量方面显著优于之前的三角网格到四边形网格的转换方法。

Conclusion: QuadGPT在原生四边形网格生成方面树立了新的标杆，并展示了结合大规模自回归模型和面向拓扑的强化学习精调在创建结构化3D资源方面的潜力。

Abstract: The generation of quadrilateral-dominant meshes is a cornerstone of
professional 3D content creation. However, existing generative models generate
quad meshes by first generating triangle meshes and then merging triangles into
quadrilaterals with some specific rules, which typically produces quad meshes
with poor topology. In this paper, we introduce QuadGPT, the first
autoregressive framework for generating quadrilateral meshes in an end-to-end
manner. QuadGPT formulates this as a sequence prediction paradigm,
distinguished by two key innovations: a unified tokenization method to handle
mixed topologies of triangles and quadrilaterals, and a specialized
Reinforcement Learning fine-tuning method tDPO for better generation quality.
Extensive experiments demonstrate that QuadGPT significantly surpasses previous
triangle-to-quad conversion pipelines in both geometric accuracy and
topological quality. Our work establishes a new benchmark for native quad-mesh
generation and showcases the power of combining large-scale autoregressive
models with topology-aware RL refinement for creating structured 3D assets.

</details>


### [28] [DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation](https://arxiv.org/abs/2509.21433)
*Jiaqi Liu,Lan Zhang,Xiaoyong Yuan*

Main category: cs.CV

TL;DR: 文本到图像扩散模型会复制受版权保护的风格和视觉概念，引发法律和伦理问题。概念擦除是通过微调来选择性抑制这些概念的一种方法，但现有方法无法满足实际需求，因为它们一次性擦除所有目标概念，而忽略了推理时的实际擦除需求。这会导致擦除成功率下降和非目标内容的保真度降低。我们提出了DyME，一个按需擦除框架，它训练轻量级的、特定概念的LoRA适配器，并在推理时动态组合所需的适配器。这种模块化设计支持灵活的多概念擦除，但适配器之间的 naieve 组合会导致干扰，尤其是在擦除许多或语义上相关的概念时。为了解决这个问题，我们在特征和参数层面引入了双层正交性约束，以区分表示变化并强制执行适配器子空间的正交性。我们还开发了一个新的分层基准ErasureBench-H，它具有品牌-系列-字符结构，能够在语义粒度和擦除集大小之间进行原则性评估。在ErasureBench-H和标准数据集（如CIFAR-100, Imagenette）上的实验表明，DyME的性能始终优于最先进的基线，在擦除多个概念时具有更高的保真度，同时对非目标内容的损害最小。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在擦除受版权保护的风格和视觉概念方面存在不足，无法满足实际需求，并且在擦除多个或语义相关概念时效果不佳。

Method: 提出了一种名为DyME的按需擦除框架，该框架通过训练轻量级的、特定概念的LoRA适配器，并在推理时动态组合所需的适配器来解决多概念擦除问题。引入了双层正交性约束（特征层面和参数层面）来解决适配器之间的干扰问题。开发了一个新的分层基准ErasureBench-H用于评估。

Result: DyME在ErasureBench-H和标准数据集（如CIFAR-100, Imagenette）上的实验结果表明，其性能优于现有方法，能够实现更高的多概念擦除保真度，同时对非目标内容的损害最小。

Conclusion: DyME框架通过其模块化设计和双层正交性约束，有效地解决了文本到图像扩散模型在多概念擦除方面的挑战，实现了在满足多样化擦除需求的同时，保持内容保真度。

Abstract: Text-to-image diffusion models (DMs) inadvertently reproduce copyrighted
styles and protected visual concepts, raising legal and ethical concerns.
Concept erasure has emerged as a safeguard, aiming to selectively suppress such
concepts through fine-tuning. However, existing methods do not scale to
practical settings where providers must erase multiple and possibly conflicting
concepts. The core bottleneck is their reliance on static erasure: a single
checkpoint is fine-tuned to remove all target concepts, regardless of the
actual erasure needs at inference. This rigid design mismatches real-world
usage, where requests vary per generation, leading to degraded erasure success
and reduced fidelity for non-target content. We propose DyME, an on-demand
erasure framework that trains lightweight, concept-specific LoRA adapters and
dynamically composes only those needed at inference. This modular design
enables flexible multi-concept erasure, but naive composition causes
interference among adapters, especially when many or semantically related
concepts are suppressed. To overcome this, we introduce bi-level orthogonality
constraints at both the feature and parameter levels, disentangling
representation shifts and enforcing orthogonal adapter subspaces. We further
develop ErasureBench-H, a new hierarchical benchmark with
brand-series-character structure, enabling principled evaluation across
semantic granularities and erasure set sizes. Experiments on ErasureBench-H and
standard datasets (e.g., CIFAR-100, Imagenette) demonstrate that DyME
consistently outperforms state-of-the-art baselines, achieving higher
multi-concept erasure fidelity with minimal collateral degradation.

</details>


### [29] [VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding](https://arxiv.org/abs/2509.21451)
*Abdul Waheed,Zhen Wu,Dareen Alharthi,Seungone Kim,Bhiksha Raj*

Main category: cs.CV

TL;DR: 准确评估视频理解模型具有挑战性，现有指标无法捕捉人类判断的细微差别，而手动评估成本高昂。本研究提出了一种名为VideoJudge的多模态大语言模型（MLLM）评估器，专门用于评估视频理解模型的输出。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型评估指标（如BLEU、ROUGE、BERTScore）存在不足，手动评估成本高，而利用大语言模型（LLMs）或多模态大语言模型（MLLMs）作为评估器在视频理解领域的应用仍有待探索。

Method: 训练了一个3B和7B参数的MLLM评估器VideoJudge。训练方法采用生成器-评估器交互机制：生成器根据目标评分生成响应，并丢弃与评估器评分不符的响应。

Result: 在四个元评估基准中的三个上，VideoJudge-7B的性能优于更大的MLLM评估器基线（如Qwen2.5-VL的32B和72B版本）。LLM评估器（如Qwen3）的性能不如MLLM评估器（如Qwen2.5-VL），并且长链条的思维推理并未提升性能，表明提供视频输入对于评估视频理解任务至关重要。

Conclusion: VideoJudge-7B在视频理解模型评估任务上表现出色，证明了MLLM在这一领域应用的有效性，并强调了视频输入在评估过程中的重要性。

Abstract: Precisely evaluating video understanding models remains challenging: commonly
used metrics such as BLEU, ROUGE, and BERTScore fail to capture the fineness of
human judgment, while obtaining such judgments through manual evaluation is
costly. Recent work has explored using large language models (LLMs) or
multimodal LLMs (MLLMs) as evaluators, but their extension to video
understanding remains relatively unexplored. In this work, we introduce
VideoJudge, a 3B and 7B-sized MLLM judge specialized to evaluate outputs from
video understanding models (\textit{i.e.}, text responses conditioned on
videos). To train VideoJudge, our recipe builds on the interplay between a
generator and an evaluator: the generator is prompted to produce responses
conditioned on a target rating, and responses not matching the evaluator's
rating are discarded. Across three out of four meta-evaluation benchmarks,
VideoJudge-7B outperforms larger MLLM judge baselines such as Qwen2.5-VL (32B
and 72B). Notably, we find that LLM judges (Qwen3) models perform worse than
MLLM judges (Qwen2.5-VL) and long chain-of-thought reasoning does not improve
performance, indicating that providing video inputs is crucial for evaluation
of video understanding tasks.

</details>


### [30] [Residual Vector Quantization For Communication-Efficient Multi-Agent Perception](https://arxiv.org/abs/2509.21464)
*Dereje Shenkut,B. V. K Vijaya Kumar*

Main category: cs.CV

TL;DR: ReVQom是一种高效的特征编码器，通过量化压缩中间特征，显著减少了多智能体协同感知中的通信带宽需求，同时保持了高精度，为实际V2X部署铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 通信带宽限制了多智能体协同感知（CP）的可扩展性。

Method: 提出了一种名为ReVQom的端到端学习方法，通过瓶颈网络和多阶段残差向量量化（RVQ）来压缩特征维度，只传输每像素的码索引。

Result: ReVQom在DAIR-V2X数据集上实现了273x至1365x的压缩率，在18 bpp时性能与原始特征相当或更优，在6-12 bpp时实现了性能的优雅降级。

Conclusion: ReVQom能够实现高效且准确的多智能体协同感知，是实现实际V2X部署的重要一步。

Abstract: Multi-agent collaborative perception (CP) improves scene understanding by
sharing information across connected agents such as autonomous vehicles,
unmanned aerial vehicles, and robots. Communication bandwidth, however,
constrains scalability. We present ReVQom, a learned feature codec that
preserves spatial identity while compressing intermediate features. ReVQom is
an end-to-end method that compresses feature dimensions via a simple bottleneck
network followed by multi-stage residual vector quantization (RVQ). This allows
only per-pixel code indices to be transmitted, reducing payloads from 8192 bits
per pixel (bpp) of uncompressed 32-bit float features to 6-30 bpp per agent
with minimal accuracy loss. On DAIR-V2X real-world CP dataset, ReVQom achieves
273x compression at 30 bpp to 1365x compression at 6 bpp. At 18 bpp (455x),
ReVQom matches or outperforms raw-feature CP, and at 6-12 bpp it enables
ultra-low-bandwidth operation with graceful degradation. ReVQom allows
efficient and accurate multi-agent collaborative perception with a step toward
practical V2X deployment.

</details>


### [31] [Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models](https://arxiv.org/abs/2509.21466)
*Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa*

Main category: cs.CV

TL;DR: AI模型在生成沙特职业图像时存在性别刻板印象和文化不准确的问题，需要改进。


<details>
  <summary>Details</summary>
Motivation: 研究当代文生图AI模型在生成沙特职业图像时，在多大程度上会延续性别刻板印象和文化不准确的问题。

Method: 分析了ImageFX, DALL-E V3和Grok为56种不同的沙特职业生成的1006张图像，并由两位沙特评分员从五个维度进行评估，最终产生10100个独立的判断。

Result: 结果显示性别比例严重失衡，ImageFX输出为85%男性，Grok为86.6%男性，DALL-E V3为96%男性，其中DALL-E V3的性别刻板印象最为严重。在领导和技术职位中这种不平衡尤为明显。所有模型在服装、场景和活动等方面也经常出现文化不准确。反刻板印象的图像通常源于文化误解，而非真正进步的描绘。

Conclusion: 当前模型反映了训练数据中存在的社会偏见，未能真实反映沙特劳动力市场的性别动态和文化细微差别。这强调了对更多样化的训练数据、更公平的算法和更具文化敏感性的评估框架的迫切需求，以确保公平和真实的视觉输出。

Abstract: This study investigates the extent to which contemporary Text-to-Image
artificial intelligence (AI) models perpetuate gender stereotypes and cultural
inaccuracies when generating depictions of professionals in Saudi Arabia. We
analyzed 1,006 images produced by ImageFX, DALL-E V3, and Grok for 56 diverse
Saudi professions using neutral prompts. Two trained Saudi annotators evaluated
each image on five dimensions: perceived gender, clothing and appearance,
background and setting, activities and interactions, and age. A third senior
researcher adjudicated whenever the two primary raters disagreed, yielding
10,100 individual judgements. The results reveal a strong gender imbalance,
with ImageFX outputs being 85\% male, Grok 86.6\% male, and DALL-E V3 96\%
male, indicating that DALL-E V3 exhibited the strongest overall gender
stereotyping. This imbalance was most evident in leadership and technical
roles. Moreover, cultural inaccuracies in clothing, settings, and depicted
activities were frequently observed across all three models.
Counter-stereotypical images often arise from cultural misinterpretations
rather than genuinely progressive portrayals. We conclude that current models
mirror societal biases embedded in their training data, generated by humans,
offering only a limited reflection of the Saudi labour market's gender dynamics
and cultural nuances. These findings underscore the urgent need for more
diverse training data, fairer algorithms, and culturally sensitive evaluation
frameworks to ensure equitable and authentic visual outputs.

</details>


### [32] [Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Moderation](https://arxiv.org/abs/2509.21486)
*Zixuan Wang,Yu Sun,Hongwei Wang,Baoyu Jing,Xiang Shen,Xin Dong,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 提出一个多模态大语言模型预训练范式，用于统一识别短视频中的不当内容，解决了现有方法需要大量标注数据且泛化能力不足的问题。通过Caption、VQA和Chain-of-Thought三种预训练任务，增强模型对视频细节的感知、对问题定义的理解以及推理能力，在零样本和有监督微调设置下均显著提升了性能，并对新兴问题展现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有不当内容检测方法需要为每个问题训练独立的模型，标注数据需求大且泛化能力差。本研究旨在提出一种统一的不当内容检测方法。

Method: 提出一个多模态大语言模型（MLLM）预训练范式，包含三个预训练任务：Caption（增强对视频细节的感知）、Visual Question Answering (VQA)（深化对问题定义的理解）和Chain-of-Thought (CoT)（增强推理能力），以解决短视频内容与MLLM预训练数据之间的分布差异以及复杂的问题定义。

Result: 预训练方法在零样本和有监督微调（SFT）设置下均显著提升了MLLM的性能。此外，预训练模型对新兴的、先前未遇到的问题也表现出强大的泛化能力。

Conclusion: 本研究提出的预训练范式能够有效提升MLLM在不当内容检测任务上的性能和泛化能力，为解决短视频不当内容检测问题提供了一种新的有效途径。

Abstract: Short video platforms are evolving rapidly, making the identification of
inappropriate content increasingly critical. Existing approaches typically
train separate and small classification models for each type of issue, which
requires extensive human-labeled data and lacks cross-issue generalization. We
propose a reasoning-enhanced multimodal large language model (MLLM) pretraining
paradigm for unified inappropriate content detection. To address the
distribution gap between short video content and the original pretraining data
of MLLMs, as well as the complex issue definitions, we introduce three targeted
pretraining tasks: (1) \textit{Caption}, to enhance the MLLM's perception of
video details; (2) \textit{Visual Question Answering (VQA)}, to deepen the
MLLM's understanding of issue definitions and annotation guidelines; (3)
\textit{Chain-of-Thought (CoT)}, to enhance the MLLM's reasoning capability.
Experimental results show that our pretraining approach significantly improves
the MLLM's performance in both zero-shot and supervised fine-tuning (SFT)
settings. In addition, our pretrained model demonstrates strong generalization
capabilities to emergent, previously unseen issues.

</details>


### [33] [Learning GUI Grounding with Spatial Reasoning from Visual Feedback](https://arxiv.org/abs/2509.21552)
*Yu Zhao,Wei-Ning Chen,Huseyin Atahan Inan,Samuel Kessler,Lu Wang,Lukas Wutschitz,Fangkai Yang,Chaoyun Zhang,Pasquale Minervini,Saravan Rajmohan,Robert Sim*

Main category: cs.CV

TL;DR: GUI grounding is reframed as an interactive search task using a VLM that moves a cursor to locate UI elements, overcoming coordinate prediction limitations and achieving state-of-the-art results on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Existing methods for GUI grounding, which treat it as a coordinate prediction task, struggle with accuracy on high-resolution and complex GUIs when using VLMs. This necessitates a new approach.

Method: GUI-Cursor reframes GUI grounding as an interactive search task. A VLM generates actions to move a cursor, iteratively evaluating spatial relations and moving closer to the target UI element based on movement history. The model is trained using multi-step online reinforcement learning with a dense trajectory-based reward function.

Result: GUI-Cursor, powered by Qwen2.5-VL-7B, significantly improves GUI grounding accuracy, reaching state-of-the-art on ScreenSpot-v2 (88.8% to 93.9%) and ScreenSpot-Pro (26.8% to 56.5%). It efficiently solves 95% of instances within two steps and adapts to more complex cases.

Conclusion: Reframing GUI grounding as an interactive search task with cursor-based feedback and reinforcement learning offers a more effective approach than traditional coordinate prediction, leading to improved accuracy and efficiency on benchmark datasets.

Abstract: Graphical User Interface (GUI) grounding is commonly framed as a coordinate
prediction task -- given a natural language instruction, generate on-screen
coordinates for actions such as clicks and keystrokes. However, recent Vision
Language Models (VLMs) often fail to predict accurate numeric coordinates when
processing high-resolution GUI images with complex layouts. To address this
issue, we reframe GUI grounding as an \emph{interactive search task}, where the
VLM generates actions to move a cursor in the GUI to locate UI elements. At
each step, the model determines the target object, evaluates the spatial
relations between the cursor and the target, and moves the cursor closer to the
target conditioned on the movement history. In this interactive process, the
rendered cursor provides visual feedback to help the model align its
predictions with the corresponding on-screen locations. We train our GUI
grounding model, GUI-Cursor, using multi-step online reinforcement learning
with a dense trajectory-based reward function. Our experimental results show
that GUI-Cursor, based on Qwen2.5-VL-7B, improves the GUI grounding accuracy
and achieves state-of-the-art results on ScreenSpot-v2 ($88.8\% \rightarrow
93.9\%$) and ScreenSpot-Pro ($26.8\% \rightarrow 56.5\%$). Moreover, we observe
that GUI-Cursor learns to solve the problem within two steps for 95\% of
instances and can adaptively conduct more steps on more difficult examples.

</details>


### [34] [X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.21559)
*Prasanna Reddy Pulakurthi,Jiamian Wang,Majid Rabbani,Sohail Dianat,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.CV

TL;DR: X-CoT是一个基于LLM CoT推理的可解释检索框架，通过成对比较来解释排名结果，从而评估检索模型和检查文本-视频数据。


<details>
  <summary>Details</summary>
Motivation: 现有的文本-视频检索系统主要依靠嵌入模型进行特征提取和余弦相似度进行排名，存在低质量数据难以识别和余弦相似度缺乏可解释性的问题。本研究旨在解决这些问题，并通过解释排名结果来评估检索模型和检查文本-视频数据。

Method: 提出X-CoT框架，利用LLM的CoT推理替代基于嵌入模型的相似度排名。该框架通过成对比较步骤进行检索CoT，生成详细的推理和完整的排名。同时，对现有基准进行了扩展，增加了视频注释以支持语义理解并减少数据偏差。

Result: X-CoT在经验上提高了检索性能，并产生了详细的推理。此外，该框架还有助于进行模型行为和数据质量分析。

Conclusion: X-CoT通过引入LLM CoT推理，克服了现有文本-视频检索系统的局限性，提高了检索性能，并提供了可解释的排名结果，有助于模型和数据的分析。

Abstract: Prevalent text-to-video retrieval systems mainly adopt embedding models for
feature extraction and compute cosine similarities for ranking. However, this
design presents two limitations. Low-quality text-video data pairs could
compromise the retrieval, yet are hard to identify and examine. Cosine
similarity alone provides no explanation for the ranking results, limiting the
interpretability. We ask that can we interpret the ranking results, so as to
assess the retrieval models and examine the text-video data? This work proposes
X-CoT, an explainable retrieval framework upon LLM CoT reasoning in place of
the embedding model-based similarity ranking. We first expand the existing
benchmarks with additional video annotations to support semantic understanding
and reduce data bias. We also devise a retrieval CoT consisting of pairwise
comparison steps, yielding detailed reasoning and complete ranking. X-CoT
empirically improves the retrieval performance and produces detailed
rationales. It also facilitates the model behavior and data quality analysis.
Code and data are available at: https://github.com/PrasannaPulakurthi/X-CoT.

</details>


### [35] [Unsupervised Defect Detection for Surgical Instruments](https://arxiv.org/abs/2509.21561)
*Joseph Huang,Yichi Zhang,Jingxi Yu,Wei Chen,Seunghyun Hwang,Qiang Qiu,Amy R. Reibman,Edward J. Delp,Fengqing Zhu*

Main category: cs.CV

TL;DR: 现有针对自然/工业图像的自动化缺陷检测方法在应用于手术器械时存在域转移问题，导致误报和漏报。本文提出了一种结合背景遮罩、块状分析和领域自适应的方法，以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 手动检查手术器械的视觉缺陷容易出错，而现有的自动化方法在手术领域效果不佳。

Method: 通过集成背景遮罩、块状分析策略和有效的领域自适应，改进无监督缺陷检测方法以适应手术器械。

Result: 成功解决了背景纹理的误报、微小缺陷的低敏感性以及器械特定特征捕捉不足的问题。

Conclusion: 所提出的方法能够可靠地检测手术器械图像中的细微缺陷。

Abstract: Ensuring the safety of surgical instruments requires reliable detection of
visual defects. However, manual inspection is prone to error, and existing
automated defect detection methods, typically trained on natural/industrial
images, fail to transfer effectively to the surgical domain. We demonstrate
that simply applying or fine-tuning these approaches leads to issues: false
positive detections arising from textured backgrounds, poor sensitivity to
small, subtle defects, and inadequate capture of instrument-specific features
due to domain shift. To address these challenges, we propose a versatile method
that adapts unsupervised defect detection methods specifically for surgical
instruments. By integrating background masking, a patch-based analysis
strategy, and efficient domain adaptation, our method overcomes these
limitations, enabling the reliable detection of fine-grained defects in
surgical instrument imagery.

</details>


### [36] [No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models](https://arxiv.org/abs/2509.21565)
*Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya*

Main category: cs.CV

TL;DR: 通过直接将线性可分性纳入网络学习动态，提出了一种名为 LSEP 的新型正则化方法，无需外部编码器或表示对齐，可提高扩散模型的训练效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模扩散模型训练策略侧重于改进判别性特征表示，其中一种流行的方法是对齐来自外部强大编码器的特征。然而，这种方法计算成本高昂。

Method: 提出了一种名为 LSEP（线性可分性）的正则化方法，直接在网络的学习动态中促进中间层表示的线性可分性，从而无需辅助编码器和表示对齐。

Result: LSEP 在基于流的 Transformer 架构（如 SiTs）上实现了显著的训练效率和生成质量的提升，在 ImageNet $256 	imes 256$ 数据集上达到了 1.46 的 FID 分数。

Conclusion: LSEP 是一种有效的替代方法，可以提高扩散模型的训练效率和生成质量，同时避免了对昂贵且计算密集型外部编码器的依赖。

Abstract: Efficient training strategies for large-scale diffusion models have recently
emphasized the importance of improving discriminative feature representations
in these models. A central line of work in this direction is representation
alignment with features obtained from powerful external encoders, which
improves the representation quality as assessed through linear probing.
Alignment-based approaches show promise but depend on large pretrained
encoders, which are computationally expensive to obtain. In this work, we
propose an alternative regularization for training, based on promoting the
Linear SEParability (LSEP) of intermediate layer representations. LSEP
eliminates the need for an auxiliary encoder and representation alignment,
while incorporating linear probing directly into the network's learning
dynamics rather than treating it as a simple post-hoc evaluation tool. Our
results demonstrate substantial improvements in both training efficiency and
generation quality on flow-based transformer architectures such as SiTs,
achieving an FID of 1.46 on $256 \times 256$ ImageNet dataset.

</details>


### [37] [Enhancing Contrastive Learning for Geolocalization by Discovering Hard Negatives on Semivariograms](https://arxiv.org/abs/2509.21573)
*Boyi Chen,Zhangyu Wang,Fabian Deuser,Johann Maximilian Zollner,Martin Werner*

Main category: cs.CV

TL;DR: 该研究提出了一种新的空间正则化对比学习策略，通过整合地统计学工具（变异函数）来改进基于图像的全球地理定位，有效解决了假阴性和困难负例样本的问题，并在OSV5M数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法在地理定位任务中存在忽略空间依赖性、无法有效处理假阴性和困难负例样本的问题。

Method: 提出一种空间正则化对比学习策略，利用变异函数（semivariogram）来模拟特征空间距离与地理空间距离的关系，并以此识别假阴性和困难负例。

Result: 在OSV5M数据集上进行评估，结果表明该方法能够有效提高基于图像的地理定位性能，尤其是在更精细的粒度上。

Conclusion: 显式地对空间先验进行建模能够提升基于图像的地理定位性能。

Abstract: Accurate and robust image-based geo-localization at a global scale is
challenging due to diverse environments, visually ambiguous scenes, and the
lack of distinctive landmarks in many regions. While contrastive learning
methods show promising performance by aligning features between street-view
images and corresponding locations, they neglect the underlying spatial
dependency in the geographic space. As a result, they fail to address the issue
of false negatives -- image pairs that are both visually and geographically
similar but labeled as negatives, and struggle to effectively distinguish hard
negatives, which are visually similar but geographically distant. To address
this issue, we propose a novel spatially regularized contrastive learning
strategy that integrates a semivariogram, which is a geostatistical tool for
modeling how spatial correlation changes with distance. We fit the
semivariogram by relating the distance of images in feature space to their
geographical distance, capturing the expected visual content in a spatial
correlation. With the fitted semivariogram, we define the expected visual
dissimilarity at a given spatial distance as reference to identify hard
negatives and false negatives. We integrate this strategy into GeoCLIP and
evaluate it on the OSV5M dataset, demonstrating that explicitly modeling
spatial priors improves image-based geo-localization performance, particularly
at finer granularity.

</details>


### [38] [X-Streamer: Unified Human World Modeling with Audiovisual Interaction](https://arxiv.org/abs/2509.21574)
*You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Guoxian Song,Xiaochen Zhao,Chao Liang,Jianwen Jiang,Hongyi Xu,Linjie Luo*

Main category: cs.CV

TL;DR: X-Streamer是一个统一的端到端多模态框架，能够驱动数字人进行无限的文本、语音和视频交互。


<details>
  <summary>Details</summary>
Motivation: 构建能够进行无限交互的数字人智能体。

Method: 采用Thinker-Actor双Transformer架构，Thinker模块负责理解和推理多模态输入，Actor模块负责生成同步的多模态输出。Actor模块使用了分块自回归扩散模型，并结合了跨块和块内注意力机制、时间对齐的多模态位置嵌入、分块扩散强制以及全局身份引用以实现长时稳定性和跨模态对齐。

Result: X-Streamer能够从单个肖像驱动实时、开放式视频通话，实现持续数小时的视频聊天体验。

Conclusion: X-Streamer为构建交互式数字人统一世界模型铺平了道路。

Abstract: We introduce X-Streamer, an end-to-end multimodal human world modeling
framework for building digital human agents capable of infinite interactions
across text, speech, and video within a single unified architecture. Starting
from a single portrait, X-Streamer enables real-time, open-ended video calls
driven by streaming multimodal inputs. At its core is a Thinker-Actor
dual-transformer architecture that unifies multimodal understanding and
generation, turning a static portrait into persistent and intelligent
audiovisual interactions. The Thinker module perceives and reasons over
streaming user inputs, while its hidden states are translated by the Actor into
synchronized multimodal streams in real time. Concretely, the Thinker leverages
a pretrained large language-speech model, while the Actor employs a chunk-wise
autoregressive diffusion model that cross-attends to the Thinker's hidden
states to produce time-aligned multimodal responses with interleaved discrete
text and audio tokens and continuous video latents. To ensure long-horizon
stability, we design inter- and intra-chunk attentions with time-aligned
multimodal positional embeddings for fine-grained cross-modality alignment and
context retention, further reinforced by chunk-wise diffusion forcing and
global identity referencing. X-Streamer runs in real time on two A100 GPUs,
sustaining hours-long consistent video chat experiences from arbitrary
portraits and paving the way toward unified world modeling of interactive
digital humans.

</details>


### [39] [What Happens Next? Anticipating Future Motion by Generating Point Trajectories](https://arxiv.org/abs/2509.21592)
*Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi*

Main category: cs.CV

TL;DR: 从单张图像预测物体运动，生成密集轨迹而非像素。


<details>
  <summary>Details</summary>
Motivation: 在无法观测物体速度或作用力等参数的情况下，从单张图像预测物体运动。

Method: 将任务构建为条件生成密集轨迹网格，使用类似现代视频生成器的模型。

Result: 该方法能够捕捉全场景动力学和不确定性，提供比先前回归器和生成器更准确、更多样的预测；在模拟数据上进行了广泛评估，并在机器人等下游应用中证明了其有效性，在真实世界直觉物理数据集上也显示出有希望的准确性。

Conclusion: 尽管最近最先进的视频生成器被认为是世界模型，但它们在从单张图像预测运动方面存在困难，即使经过此类数据的微调也是如此。这源于生成像素的开销，而不是直接对运动进行建模。

Abstract: We consider the problem of forecasting motion from a single image, i.e.,
predicting how objects in the world are likely to move, without the ability to
observe other parameters such as the object velocities or the forces applied to
them. We formulate this task as conditional generation of dense trajectory
grids with a model that closely follows the architecture of modern video
generators but outputs motion trajectories instead of pixels. This approach
captures scene-wide dynamics and uncertainty, yielding more accurate and
diverse predictions than prior regressors and generators. We extensively
evaluate our method on simulated data, demonstrate its effectiveness on
downstream applications such as robotics, and show promising accuracy on
real-world intuitive physics datasets. Although recent state-of-the-art video
generators are often regarded as world models, we show that they struggle with
forecasting motion from a single image, even in simple physical scenarios such
as falling blocks or mechanical object interactions, despite fine-tuning on
such data. We show that this limitation arises from the overhead of generating
pixels rather than directly modeling motion.

</details>


### [40] [Temporal vs. Spatial: Comparing DINOv3 and V-JEPA2 Feature Representations for Video Action Analysis](https://arxiv.org/abs/2509.21595)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CV

TL;DR: DINOv3在聚类和姿态识别方面表现更好，V-JEPA2在动作识别方面更稳定。


<details>
  <summary>Details</summary>
Motivation: 比较DINOv3和V-JEPA2在视频动作识别中的性能，并分析它们的架构权衡。

Method: 在UCF Sports数据集上评估DINOv3和V-JEPA2，比较分类准确性、聚类性能、类内一致性和类间区分性。

Result: DINOv3在聚类（Silhouette分数：0.31 vs 0.21）和区分性（6.16倍分离比）方面表现优于V-JEPA2，特别是在姿态可识别动作方面。V-JEPA2在所有动作类型中表现稳定，性能方差较低（0.094 vs 0.288）。DINOv3擅长静态姿态识别，但在依赖运动的动作上表现下降，而V-JEPA2在各种动作类别中提供均衡的表示质量。

Conclusion: DINOv3和V-JEPA2的架构设计选择在视频分析中具有不同的优势和劣势。DINOv3的空间处理架构更适合静态姿态识别，而V-JEPA2的时间建模则能提供更均衡的表示质量。根据任务需求和可靠性约束选择合适的方法。

Abstract: This study presents a comprehensive comparative analysis of two prominent
self-supervised learning architectures for video action recognition: DINOv3,
which processes frames independently through spatial feature extraction, and
V-JEPA2, which employs joint temporal modeling across video sequences. We
evaluate both approaches on the UCF Sports dataset, examining feature quality
through multiple dimensions including classification accuracy, clustering
performance, intra-class consistency, and inter-class discrimination. Our
analysis reveals fundamental architectural trade-offs: DINOv3 achieves superior
clustering performance (Silhouette score: 0.31 vs 0.21) and demonstrates
exceptional discrimination capability (6.16x separation ratio) particularly for
pose-identifiable actions, while V-JEPA2 exhibits consistent reliability across
all action types with significantly lower performance variance (0.094 vs
0.288). Through action-specific evaluation, we identify that DINOv3's spatial
processing architecture excels at static pose recognition but shows degraded
performance on motion-dependent actions, whereas V-JEPA2's temporal modeling
provides balanced representation quality across diverse action categories.
These findings contribute to the understanding of architectural design choices
in video analysis systems and provide empirical guidance for selecting
appropriate feature extraction methods based on task requirements and
reliability constraints.

</details>


### [41] [VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster Assessment](https://arxiv.org/abs/2509.21609)
*Md. Mahfuzur Rahman,Kishor Datta Gupta,Marufa Kamal,Fahad Rahman,Sunzida Siddique,Ahmed Rafi Hasan,Mohd Ariful Haque,Roy George*

Main category: cs.CV

TL;DR: VLCE是一个创新的多模态系统，通过结合CNN-LSTM和ViT模型，并利用外部语义知识，能为灾难图像生成详细且情境化的描述，显著优于现有模型，在灾后评估中展现出巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的灾后损失评估方法耗时且危险，现有的计算机视觉方法在提供全面态势理解方面能力有限。

Method: VLCE采用双架构：一个基于ResNet50的CNN-LSTM模型（在EuroSat卫星图像上预训练）和一个ViT模型（在RescueNet无人机图像上预训练）。两个模型都利用ConceptNet和WordNet的外部语义知识。评估方法包括与LLaVA和QwenVL等领先模型进行比较，并使用CLIPScore和InfoMetIC进行评估。

Result: VLCE在InfoMetIC指标上取得了95.33%的最高分，并且在语义对齐方面也保持了竞争力，显著优于基线模型。

Conclusion: VLCE系统在自动化生成信息密集、可操作的卫星和无人机图像描述方面，在改进灾害损失评估方面显示出巨大潜力。

Abstract: Immediate damage assessment is essential after natural catastrophes; yet,
conventional hand evaluation techniques are sluggish and perilous. Although
satellite and unmanned aerial vehicle (UAV) photos offer extensive perspectives
of impacted regions, current computer vision methodologies generally yield just
classification labels or segmentation masks, so constraining their capacity to
deliver a thorough situational comprehension. We introduce the Vision Language
Caption Enhancer (VLCE), a multimodal system designed to produce comprehensive,
contextually-informed explanations of disaster imagery. VLCE employs a
dual-architecture approach: a CNN-LSTM model with a ResNet50 backbone
pretrained on EuroSat satellite imagery for the xBD dataset, and a Vision
Transformer (ViT) model pretrained on UAV pictures for the RescueNet dataset.
Both systems utilize external semantic knowledge from ConceptNet and WordNet to
expand vocabulary coverage and improve description accuracy. We assess VLCE in
comparison to leading vision-language models (LLaVA and QwenVL) utilizing
CLIPScore for semantic alignment and InfoMetIC for caption informativeness.
Experimental findings indicate that VLCE markedly surpasses baseline models,
attaining a maximum of 95.33% on InfoMetIC while preserving competitive
semantic alignment. Our dual-architecture system demonstrates significant
potential for improving disaster damage assessment by automating the production
of actionable, information-dense descriptions from satellite and drone photos.

</details>


### [42] [A Data-driven Typology of Vision Models from Integrated Representational Metrics](https://arxiv.org/abs/2509.21628)
*Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 不同架构和训练范式的大型视觉模型在表示方面存在显著差异。几何和单元调优等度量可以有效区分模型家族，而线性可解码性则显示出较弱的分离效果。通过整合多种度量，可以更清晰地区分模型家族，并揭示出不同训练策略（如自监督学习）和架构（如混合架构）的收敛性。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏原则性的方法来确定大型视觉模型表示中哪些方面是跨家族共享的，哪些反映了独特的计算策略。

Method: 利用一套表示相似性度量（包括几何、单元调优和线性可解码性），并使用多种互补的度量来评估模型家族的可分离性。通过改编受多组学启发的相似网络融合（SNF）方法来整合这些度量，以实现更清晰的模型家族分离。

Result: 几何和调优度量能很好地区分模型家族，而线性可预测性则分离效果较弱。SNF 整合后的相似性矩阵能够更清晰地区分模型家族，并发现自监督模型无论架构如何都会聚集在一起，而混合架构则与掩码自编码器一起聚集。

Conclusion: 几何和调优是模型家族特有的标志，而线性可解码的信息则更广泛地共享。SNF 提供了一个原则性的视觉模型分类法，表明计算策略（由架构和训练目标共同决定）定义了超越表面设计类别的表示结构。

Abstract: Large vision models differ widely in architecture and training paradigm, yet
we lack principled methods to determine which aspects of their representations
are shared across families and which reflect distinctive computational
strategies. We leverage a suite of representational similarity metrics, each
capturing a different facet-geometry, unit tuning, or linear decodability-and
assess family separability using multiple complementary measures. Metrics
preserving geometry or tuning (e.g., RSA, Soft Matching) yield strong family
discrimination, whereas flexible mappings such as Linear Predictivity show
weaker separation. These findings indicate that geometry and tuning carry
family-specific signatures, while linearly decodable information is more
broadly shared. To integrate these complementary facets, we adapt Similarity
Network Fusion (SNF), a method inspired by multi-omics integration. SNF
achieves substantially sharper family separation than any individual metric and
produces robust composite signatures. Clustering of the fused similarity matrix
recovers both expected and surprising patterns: supervised ResNets and ViTs
form distinct clusters, yet all self-supervised models group together across
architectural boundaries. Hybrid architectures (ConvNeXt, Swin) cluster with
masked autoencoders, suggesting convergence between architectural modernization
and reconstruction-based training. This biology-inspired framework provides a
principled typology of vision models, showing that emergent computational
strategies-shaped jointly by architecture and training objective-define
representational structure beyond surface design categories.

</details>


### [43] [FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction](https://arxiv.org/abs/2509.21657)
*Yixiang Dai,Fan Jiang,Chiyu Wang,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyWorld是一个增强几何的三维世界建模框架，通过结合视频基础模型和可训练的几何分支，实现视频和三维场的联合建模，从而生成具有空间一致性的三维感知视频表示，并可用于新视角合成和导航等下游三维任务。


<details>
  <summary>Details</summary>
Motivation: 当前视频基础模型缺乏明确的三维空间约束能力，限制了其在空间一致性和下游三维推理任务中的应用。

Method: FantasyWorld框架通过引入一个可训练的几何分支来增强冻结的视频基础模型，实现了视频潜在表示和隐式三维场在单次前向传播中的联合建模。该框架利用跨分支监督，使几何线索指导视频生成，视频先验约束三维预测。

Result: FantasyWorld有效弥合了视频想象和三维感知的鸿沟，在多视图和风格一致性方面优于现有的几何一致性基线。此外，几何分支产生的潜在表示无需每场景优化或微调即可用于新视角合成和导航等下游三维任务。

Conclusion: FantasyWorld通过联合建模视频和三维场，并利用跨分支监督，实现了生成式三维感知视频表示，在多视图一致性和风格一致性方面取得了显著成果，并能有效支持下游三维任务。

Abstract: High-quality 3D world models are pivotal for embodied intelligence and
Artificial General Intelligence (AGI), underpinning applications such as AR/VR
content creation and robotic navigation. Despite the established strong
imaginative priors, current video foundation models lack explicit 3D grounding
capabilities, thus being limited in both spatial consistency and their utility
for downstream 3D reasoning tasks. In this work, we present FantasyWorld, a
geometry-enhanced framework that augments frozen video foundation models with a
trainable geometric branch, enabling joint modeling of video latents and an
implicit 3D field in a single forward pass. Our approach introduces
cross-branch supervision, where geometry cues guide video generation and video
priors regularize 3D prediction, thus yielding consistent and generalizable
3D-aware video representations. Notably, the resulting latents from the
geometric branch can potentially serve as versatile representations for
downstream 3D tasks such as novel view synthesis and navigation, without
requiring per-scene optimization or fine-tuning. Extensive experiments show
that FantasyWorld effectively bridges video imagination and 3D perception,
outperforming recent geometry-consistent baselines in multi-view coherence and
style consistency. Ablation studies further confirm that these gains stem from
the unified backbone and cross-branch information exchange.

</details>


### [44] [MORPH: Shape-agnostic PDE Foundation Models](https://arxiv.org/abs/2509.21670)
*Mahindra Singh Rautela,Alexander Most,Siddharth Mansingh,Bradley C. Love,Ayan Biswas,Diane Oyen,Earl Lawrence*

Main category: cs.CV

TL;DR: MORPH是一个形状无关的、自回归的偏微分方程（PDE）基础模型，它能处理异构时空数据集，并在下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 介绍MORPH，一个用于偏微分方程（PDE）的形状无关的、自回归的基础模型。

Method: MORPH基于卷积视觉Transformer骨干网络，结合了分量卷积、场间交叉注意力以及轴向注意力，以处理异构时空数据集，并能捕获局部相互作用、跨场信息传播以及降低计算成本。

Result: MORPH在各种下游预测任务上进行了预训练和评估，使用全模型微调和参数高效的低秩适配器（LoRA），在零样本和全样本泛化方面均优于从头训练的模型，并能匹配或超越现有基线模型。

Conclusion: MORPH提供了一个灵活而强大的基础模型，用于从科学观测的异构和多模态性质中学习，为实现可扩展和数据高效的科学机器学习指明了方向。

Abstract: We introduce MORPH, a shape-agnostic, autoregressive foundation model for
partial differential equations (PDEs). MORPH is built on a convolutional vision
transformer backbone that seamlessly handles heterogeneous spatiotemporal
datasets of varying data dimensionality (1D--3D) at different resolutions,
multiple fields with mixed scalar and vector components. The architecture
combines (i) component-wise convolution, which jointly processes scalar and
vector channels to capture local interactions, (ii) inter-field
cross-attention, which models and selectively propagates information between
different physical fields, (iii) axial attentions, which factorizes full
spatiotemporal self-attention along individual spatial and temporal axes to
reduce computational burden while retaining expressivity. We pretrain multiple
model variants on a diverse collection of heterogeneous PDE datasets and
evaluate transfer to a range of downstream prediction tasks. Using both
full-model fine-tuning and parameter-efficient low-rank adapters (LoRA), MORPH
outperforms models trained from scratch in both zero-shot and full-shot
generalization. Across extensive evaluations, MORPH matches or surpasses strong
baselines and recent state-of-the-art models. Collectively, these capabilities
present a flexible and powerful backbone for learning from heterogeneous and
multimodal nature of scientific observations, charting a path toward scalable
and data-efficient scientific machine learning.

</details>


### [45] [MS-YOLO: Infrared Object Detection for Edge Deployment via MobileNetV4 and SlideLoss](https://arxiv.org/abs/2509.21696)
*Jiali Zhang,Thomas S. White,Haoliang Zhang,Wenqing Hu,Donald C. Wunsch II,Jian Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 MS-YOLO 的改进型 YOLO 模型，用于在复杂城市环境下进行红外目标检测。通过结合 MobileNetV4 骨干网络和一种新的 SlideLoss 损失函数，MS-YOLO 在保持高精度的同时，显著降低了计算量，使其适合实时边缘部署。


<details>
  <summary>Details</summary>
Motivation: 现有红外成像目标检测方法在城市复杂环境下（如光照不足、恶劣天气）面临类别不平衡、热噪声和计算量大等挑战，影响实际应用。

Method: 1. 评估了多种 YOLO 变体在 FLIR ADAS V2 数据集上的表现，选择了 YOLOv8 作为基线。 2. 提出 MS-YOLO 模型，用更高效的 MobileNetV4 替换 YOLOv8 的骨干网络，以降低计算开销。 3. 引入了名为 SlideLoss 的新损失函数，用于动态地关注表示不足和被遮挡的样本，以提高检测精度。

Result: 在 FLIR ADAS V2 数据集上，MS-YOLO 模型达到了具有竞争力的 mAP 和更高的精度，同时计算量仅为 6.7 GFLOPs。与基线模型相比，计算开销减少了 1.5%，同时保持了高精度。

Conclusion: MS-YOLO 模型成功解决了在保持高检测质量的同时最小化计算成本的双重挑战，非常适合在城市环境中进行实时边缘部署。

Abstract: Infrared imaging has emerged as a robust solution for urban object detection
under low-light and adverse weather conditions, offering significant advantages
over traditional visible-light cameras. However, challenges such as class
imbalance, thermal noise, and computational constraints can significantly
hinder model performance in practical settings. To address these issues, we
evaluate multiple YOLO variants on the FLIR ADAS V2 dataset, ultimately
selecting YOLOv8 as our baseline due to its balanced accuracy and efficiency.
Building on this foundation, we present \texttt{MS-YOLO} (\textbf{M}obileNetv4
and \textbf{S}lideLoss based on YOLO), which replaces YOLOv8's CSPDarknet
backbone with the more efficient MobileNetV4, reducing computational overhead
by \textbf{1.5%} while sustaining high accuracy. In addition, we introduce
\emph{SlideLoss}, a novel loss function that dynamically emphasizes
under-represented and occluded samples, boosting precision without sacrificing
recall. Experiments on the FLIR ADAS V2 benchmark show that \texttt{MS-YOLO}
attains competitive mAP and superior precision while operating at only
\textbf{6.7 GFLOPs}. These results demonstrate that \texttt{MS-YOLO}
effectively addresses the dual challenge of maintaining high detection quality
while minimizing computational costs, making it well-suited for real-time edge
deployment in urban environments.

</details>


### [46] [Motion-Aware Transformer for Multi-Object Tracking](https://arxiv.org/abs/2509.21715)
*Xu Yang,Gady Agam*

Main category: cs.CV

TL;DR: MATR通过显式预测跨帧对象运动来更新跟踪查询，解决了DETR类MOT框架中查询冲突和关联精度下降的问题，在DanceTrack、SportsMOT和BDD100k数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的DETR类多目标跟踪（MOT）框架在单一Transformer解码器层中联合处理检测和跟踪查询，容易导致查询冲突和关联精度下降。

Method: 提出了一种名为MATR（Motion-Aware Transformer）的框架，该框架显式预测对象在帧之间的运动，以提前更新跟踪查询，从而减少查询冲突。

Result: MATR在DanceTrack、SportsMOT和BDD100k数据集上均取得了显著的性能提升。在DanceTrack数据集上，相比MOTR，HOTA分数提高了9个点以上；在使用补充数据的情况下，达到了71.3的新SOTA分数。在SportsMOT和BDD100k数据集上，MATR也分别达到了72.2和54.7 mTETA/41.6 mHOTA的SOTA分数。

Conclusion: 在端到端Transformer中显式地对运动进行建模，是提升多目标跟踪性能的一种简单而有效的方法。

Abstract: Multi-object tracking (MOT) in videos remains challenging due to complex
object motions and crowded scenes. Recent DETR-based frameworks offer
end-to-end solutions but typically process detection and tracking queries
jointly within a single Transformer Decoder layer, leading to conflicts and
degraded association accuracy. We introduce the Motion-Aware Transformer
(MATR), which explicitly predicts object movements across frames to update
track queries in advance. By reducing query collisions, MATR enables more
consistent training and improves both detection and association. Extensive
experiments on DanceTrack, SportsMOT, and BDD100k show that MATR delivers
significant gains across standard metrics. On DanceTrack, MATR improves HOTA by
more than 9 points over MOTR without additional data and reaches a new
state-of-the-art score of 71.3 with supplementary data. MATR also achieves
state-of-the-art results on SportsMOT (72.2 HOTA) and BDD100k (54.7 mTETA, 41.6
mHOTA) without relying on external datasets. These results demonstrate that
explicitly modeling motion within end-to-end Transformers offers a simple yet
highly effective approach to advancing multi-object tracking.

</details>


### [47] [DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining](https://arxiv.org/abs/2509.21719)
*Shuning Sun,Jialang Lu,Xiang Chen,Jichao Wang,Dianjie Lu,Guijuan Zhang,Guangwei Gao,Zhuoran Zheng*

Main category: cs.CV

TL;DR: DeLiVR是一种基于李群的视频去雨方法，通过注入时空李群微分偏差来解决视频中的雨痕、模糊和噪声问题，以及跨帧不匹配和时间伪影。


<details>
  <summary>Details</summary>
Motivation: 现有视频去雨方法计算成本高且鲁棒性差，本文提出一种新方法来解决这些挑战。

Method: DeLiVR将时空李群微分偏差直接注入网络的注意力分数。具体包括：1. 旋转边界李相对偏置：预测每帧的平面内角度，通过旋转和比较坐标来实现几何一致性对齐。2. 微分群位移：计算相邻帧之间的角度差以估计速度，并结合时间衰减和注意力掩码来关注帧间关系和雨痕方向。

Result: 实验结果表明该方法在公开基准测试中是有效的。

Conclusion: DeLiVR是一种有效的视频去雨方法，通过利用李群来强制执行空间和时间一致性，提高了处理视频中常见问题的能力。

Abstract: Videos captured in the wild often suffer from rain streaks, blur, and noise.
In addition, even slight changes in camera pose can amplify cross-frame
mismatches and temporal artifacts. Existing methods rely on optical flow or
heuristic alignment, which are computationally expensive and less robust. To
address these challenges, Lie groups provide a principled way to represent
continuous geometric transformations, making them well-suited for enforcing
spatial and temporal consistency in video modeling. Building on this insight,
we propose DeLiVR, an efficient video deraining method that injects
spatiotemporal Lie-group differential biases directly into attention scores of
the network. Specifically, the method introduces two complementary components.
First, a rotation-bounded Lie relative bias predicts the in-plane angle of each
frame using a compact prediction module, where normalized coordinates are
rotated and compared with base coordinates to achieve geometry-consistent
alignment before feature aggregation. Second, a differential group displacement
computes angular differences between adjacent frames to estimate a velocity.
This bias computation combines temporal decay and attention masks to focus on
inter-frame relationships while precisely matching the direction of rain
streaks. Extensive experimental results demonstrate the effectiveness of our
method on publicly available benchmarks.

</details>


### [48] [On the Status of Foundation Models for SAR Imagery](https://arxiv.org/abs/2509.21722)
*Nathan Inkawhich*

Main category: cs.CV

TL;DR: Foundational AI/ML models show promise for SAR object recognition, with self-supervised fine-tuning outperforming existing models and setting new benchmarks.


<details>
  <summary>Details</summary>
Motivation: Inspired by the success of large foundational models in natural image processing, this work aims to apply similar techniques to Synthetic Aperture Radar (SAR) object recognition tasks due to their potential for adaptation with limited labeled data, robustness to distribution shift, and feature transferability.

Method: The study first evaluates off-the-shelf performance of leading visual foundational models (DINOv2, DINOv3, PE-Core) on SAR data, identifying their limitations. Subsequently, it demonstrates the effectiveness of self-supervised fine-tuning using SAR data on publicly available SSL models, creating new models (AFRL-DINOv2s) that achieve state-of-the-art results. The research also analyzes performance trade-offs with different backbones and downstream task adaptation strategies, assessing models' ability to handle challenges like extended operating conditions and limited labeled data.

Result: Off-the-shelf visual foundational models struggle to extract meaningful features from SAR data. However, self-supervised fine-tuning of these models with SAR data significantly improves performance, establishing a new state-of-the-art that surpasses the previous best SAR-domain model (SARATR-X).

Conclusion: Self-supervised fine-tuning of foundational models with SAR data is a viable and effective approach for SAR object recognition, yielding state-of-the-art results. Despite positive outcomes, further research and development are needed to fully realize the potential of these models in the SAR domain.

Abstract: In this work we investigate the viability of foundational AI/ML models for
Synthetic Aperture Radar (SAR) object recognition tasks. We are inspired by the
tremendous progress being made in the wider community, particularly in the
natural image domain where frontier labs are training huge models on web-scale
datasets with unprecedented computing budgets. It has become clear that these
models, often trained with Self-Supervised Learning (SSL), will transform how
we develop AI/ML solutions for object recognition tasks - they can be adapted
downstream with very limited labeled data, they are more robust to many forms
of distribution shift, and their features are highly transferable
out-of-the-box. For these reasons and more, we are motivated to apply this
technology to the SAR domain. In our experiments we first run tests with
today's most powerful visual foundational models, including DINOv2, DINOv3 and
PE-Core and observe their shortcomings at extracting semantically-interesting
discriminative SAR target features when used off-the-shelf. We then show that
Self-Supervised finetuning of publicly available SSL models with SAR data is a
viable path forward by training several AFRL-DINOv2s and setting a new
state-of-the-art for SAR foundation models, significantly outperforming today's
best SAR-domain model SARATR-X. Our experiments further analyze the performance
trade-off of using different backbones with different downstream
task-adaptation recipes, and we monitor each model's ability to overcome
challenges within the downstream environments (e.g., extended operating
conditions and low amounts of labeled data). We hope this work will inform and
inspire future SAR foundation model builders, because despite our positive
results, we still have a long way to go.

</details>


### [49] [UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments](https://arxiv.org/abs/2509.21733)
*Jiannan Xiang,Yun Zhu,Lei Shu,Maria Wang,Lijun Yu,Gabriel Barcik,James Lyon,Srinivas Sunkara,Jindong Chen*

Main category: cs.CV

TL;DR: UISim是一个基于图像的UI模拟器，可以从屏幕图像动态模拟移动环境，用于UI测试、原型设计和AI训练。


<details>
  <summary>Details</summary>
Motivation: 开发和测试用户界面（UI）以及训练与UI交互的AI代理因现实世界移动环境的动态性和多样性而面临挑战。现有方法依赖于笨拙的物理设备或有限的静态截图分析，阻碍了可扩展的测试和智能UI代理的开发。

Method: UISim采用两阶段方法：给定初始手机屏幕图像和用户操作，首先预测下一个UI状态的抽象布局，然后基于该预测布局合成新的、视觉上一致的图像，从而实现UI转换的逼真模拟。

Result: 实验结果表明，UISim在生成逼真且连贯的后续UI状态方面优于端到端的UI生成基线，显示了其保真度以及在简化UI开发和增强AI代理训练方面的潜力。

Conclusion: UISim提供即时的实际好处，可用于UI测试、快速原型设计和合成数据生成。此外，其交互能力为AI代理的UI导航任务规划等高级应用铺平了道路。

Abstract: Developing and testing user interfaces (UIs) and training AI agents to
interact with them are challenging due to the dynamic and diverse nature of
real-world mobile environments. Existing methods often rely on cumbersome
physical devices or limited static analysis of screenshots, which hinders
scalable testing and the development of intelligent UI agents. We introduce
UISim, a novel image-based UI simulator that offers a dynamic and interactive
platform for exploring mobile phone environments purely from screen images. Our
system employs a two-stage method: given an initial phone screen image and a
user action, it first predicts the abstract layout of the next UI state, then
synthesizes a new, visually consistent image based on this predicted layout.
This approach enables the realistic simulation of UI transitions. UISim
provides immediate practical benefits for UI testing, rapid prototyping, and
synthetic data generation. Furthermore, its interactive capabilities pave the
way for advanced applications, such as UI navigation task planning for AI
agents. Our experimental results show that UISim outperforms end-to-end UI
generation baselines in generating realistic and coherent subsequent UI states,
highlighting its fidelity and potential to streamline UI development and
enhance AI agent training.

</details>


### [50] [LFA-Net: A Lightweight Network with LiteFusion Attention for Retinal Vessel Segmentation](https://arxiv.org/abs/2509.21738)
*Mehwish Mehmood,Ivor Spence,Muhammad Fahim*

Main category: cs.CV

TL;DR: LFA-Net是一个轻量级的视网膜血管分割网络，通过创新的LiteFusion-Attention模块，在参数量、内存和计算量方面表现出色，同时在多个数据集上取得了优异的分割性能。


<details>
  <summary>Details</summary>
Motivation: 轻量级的视网膜血管分割对于在计算资源有限的实际临床环境中早期诊断具有重要意义，但现有深度学习模型在小血管分割和计算成本方面仍面临挑战。

Method: 提出了一种名为LFA-Net的新型血管分割网络，该网络包含一个新设计的LiteFusion-Attention模块，该模块结合了残差学习连接、受Vision Mamba启发的动态机制和基于调制的注意力，能够以轻量级的方式有效地捕获局部和全局上下文。

Result: LFA-Net拥有0.11百万参数、0.42MB内存和4.46GFLOPs，在DRIVE、STARE和CHASE_DB数据集上分别取得了83.28%、87.44%和84.50%的Dice分数，以及72.85%、79.31%和74.70%的Jaccard指数，表现优异。

Conclusion: LFA-Net通过其轻量级的设计和创新的注意力模块，在视网膜血管分割任务上取得了高性能，非常适合计算资源受限的环境。

Abstract: Lightweight retinal vessel segmentation is important for the early diagnosis
of vision-threatening and systemic diseases, especially in a real-world
clinical environment with limited computational resources. Although
segmentation methods based on deep learning are improving, existing models are
still facing challenges of small vessel segmentation and high computational
costs. To address these challenges, we proposed a new vascular segmentation
network, LFA-Net, which incorporates a newly designed attention module,
LiteFusion-Attention. This attention module incorporates residual learning
connections, Vision Mamba-inspired dynamics, and modulation-based attention,
enabling the model to capture local and global context efficiently and in a
lightweight manner. LFA-Net offers high performance with 0.11 million
parameters, 0.42 MB memory size, and 4.46 GFLOPs, which make it ideal for
resource-constrained environments. We validated our proposed model on DRIVE,
STARE, and CHASE_DB with outstanding performance in terms of dice scores of
83.28, 87.44, and 84.50% and Jaccard indices of 72.85, 79.31, and 74.70%,
respectively. The code of LFA-Net is available online
https://github.com/Mehwish4593/LFA-Net.

</details>


### [51] [Incorporating Scene Context and Semantic Labels for Enhanced Group-level Emotion Recognition](https://arxiv.org/abs/2509.21747)
*Qing Zhu,Wangdong Guo,Qirong Mao,Xiaohua Huang,Xiuyan Shao,Wenming Zheng*

Main category: cs.CV

TL;DR: 提出了一种结合视觉场景和标签引导的语义信息的新框架，以提高群体情绪识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有群体情绪识别方法低估了视觉场景上下文信息在个体关系建模中的重要性，并且忽略了情感标签的语义信息在完整理解情绪中的关键作用。

Method: 提出了一种新框架，包括视觉上下文编码模块（利用多尺度场景信息来多样化编码个体关系）和情绪语义编码模块（利用群体级别的情绪标签提示大型语言模型生成细微的情绪词汇），并结合情绪标签通过结构化情绪树精炼成全面的语义表征。最后，提出相似性感知交互来对齐和整合视觉与语义信息。

Result: 实验表明，所提出的方法在三个广泛采用的群体情绪识别数据集上取得了与最先进方法相媲美的性能。

Conclusion: 所提出的框架通过整合视觉场景上下文和标签引导的语义信息，显著提高了群体情绪识别的性能。

Abstract: Group-level emotion recognition (GER) aims to identify holistic emotions
within a scene involving multiple individuals. Current existed methods
underestimate the importance of visual scene contextual information in modeling
individual relationships. Furthermore, they overlook the crucial role of
semantic information from emotional labels for complete understanding of
emotions. To address this limitation, we propose a novel framework that
incorporates visual scene context and label-guided semantic information to
improve GER performance. It involves the visual context encoding module that
leverages multi-scale scene information to diversely encode individual
relationships. Complementarily, the emotion semantic encoding module utilizes
group-level emotion labels to prompt a large language model to generate nuanced
emotion lexicons. These lexicons, in conjunction with the emotion labels, are
then subsequently refined into comprehensive semantic representations through
the utilization of a structured emotion tree. Finally, similarity-aware
interaction is proposed to align and integrate visual and semantic information,
thereby generating enhanced group-level emotion representations and
subsequently improving the performance of GER. Experiments on three widely
adopted GER datasets demonstrate that our proposed method achieves competitive
performance compared to state-of-the-art methods.

</details>


### [52] [DynaNav: Dynamic Feature and Layer Selection for Efficient Visual Navigation](https://arxiv.org/abs/2509.21930)
*Jiahui Wang,Changhao Chen*

Main category: cs.CV

TL;DR: DynaNav通过动态特征和层选择来优化视觉导航的计算效率和可解释性，在降低计算成本的同时提高了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航模型（尤其是基于Transformer的模型）计算开销大且缺乏可解释性，难以在资源受限场景下部署。

Method: 提出DynaNav框架，包含可训练的硬特征选择器以实现稀疏计算，并结合了基于贝叶斯优化的早期退出机制来动态调整计算量。

Result: DynaNav相比ViNT，在FLOPs、推理时间和内存使用方面分别降低了2.26倍、42.3%和32.8%，同时在四个公开数据集上提高了导航性能。

Conclusion: DynaNav在计算效率和导航性能方面均优于现有方法，为资源受限场景下的视觉导航提供了有效的解决方案。

Abstract: Visual navigation is essential for robotics and embodied AI. However,
existing foundation models, particularly those with transformer decoders,
suffer from high computational overhead and lack interpretability, limiting
their deployment in resource-tight scenarios. To address this, we propose
DynaNav, a Dynamic Visual Navigation framework that adapts feature and layer
selection based on scene complexity. It employs a trainable hard feature
selector for sparse operations, enhancing efficiency and interpretability.
Additionally, we integrate feature selection into an early-exit mechanism, with
Bayesian Optimization determining optimal exit thresholds to reduce
computational cost. Extensive experiments in real-world-based datasets and
simulated environments demonstrate the effectiveness of DynaNav. Compared to
ViNT, DynaNav achieves a 2.26x reduction in FLOPs, 42.3% lower inference time,
and 32.8% lower memory usage, while improving navigation performance across
four public datasets.

</details>


### [53] [KG-SAM: Injecting Anatomical Knowledge into Segment Anything Models via Conditional Random Fields](https://arxiv.org/abs/2509.21750)
*Yu Li,Da Chang,Xi Xiao*

Main category: cs.CV

TL;DR: KG-SAM是一个知识引导的框架，通过整合解剖学先验、边界细化和不确定性估计来改进医学图像分割，解决了SAM在医学影像中的局限性。


<details>
  <summary>Details</summary>
Motivation: SAM在医学影像分割方面存在边界模糊、解剖关系建模不足和不确定性量化缺失等挑战，需要一个能够整合解剖学知识并进行不确定性估计的框架。

Method: KG-SAM整合了医学知识图谱（用于编码解剖关系）、基于能量的条件随机场（CRF，用于强制执行解剖学上一致的预测）以及不确定性感知融合模块（用于提高临床场景的可靠性）。

Result: 在多中心医学数据集上的广泛实验表明，KG-SAM在prostate分割上的平均Dice得分为82.69%，在腹部分割上分别达到MRI的78.05%和CT的79.68%，表现出显著的提升。

Conclusion: KG-SAM是一个稳健且可泛化的框架，能够有效地推进医学图像分割技术在临床应用中的发展。

Abstract: While the Segment Anything Model (SAM) has achieved remarkable success in
image segmentation, its direct application to medical imaging remains hindered
by fundamental challenges, including ambiguous boundaries, insufficient
modeling of anatomical relationships, and the absence of uncertainty
quantification. To address these limitations, we introduce KG-SAM, a
knowledge-guided framework that synergistically integrates anatomical priors
with boundary refinement and uncertainty estimation. Specifically, KG-SAM
incorporates (i) a medical knowledge graph to encode fine-grained anatomical
relationships, (ii) an energy-based Conditional Random Field (CRF) to enforce
anatomically consistent predictions, and (iii) an uncertainty-aware fusion
module to enhance reliability in high-stakes clinical scenarios. Extensive
experiments across multi-center medical datasets demonstrate the effectiveness
of our approach: KG-SAM achieves an average Dice score of 82.69% on prostate
segmentation and delivers substantial gains in abdominal segmentation, reaching
78.05% on MRI and 79.68% on CT. These results establish KG-SAM as a robust and
generalizable framework for advancing medical image segmentation.

</details>


### [54] [Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics](https://arxiv.org/abs/2509.22014)
*Saurav Jha,Stefan K. Ehrlich*

Main category: cs.CV

TL;DR: 开发了一个轻量级、可代理的多模态框架，用于视频场景理解，并结合了 Qwen2.5-VL-3B-Instruct 模型和 SmolAgent 来进行推理、语音视觉融合和工具调用，生成结构化场景图，并在 Video-MME 和临床数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 当前医疗机器人领域需要强大的多模态感知和推理能力，以确保在动态的临床环境中的安全性。现有的视觉-语言模型（VLMs）虽然具有通用能力，但在时间推理、不确定性估计和机器人规划所需的结构化输出方面存在局限。

Method: 提出了一种轻量级、可代理的多模态框架，该框架结合了 Qwen2.5-VL-3B-Instruct 模型和基于 SmolAgent 的编排层，支持思维链推理、语音-视觉融合和动态工具调用。该框架生成结构化场景图，并利用混合检索模块进行可解释和自适应的推理。

Result: 在 Video-MME 基准和自定义临床数据集上的评估显示，与现有最先进的 VLMs 相比，该框架具有有竞争力的准确性和更高的鲁棒性。

Conclusion: 该框架在机器人辅助手术、患者监护和决策支持等应用中显示出巨大潜力。

Abstract: Healthcare robotics requires robust multimodal perception and reasoning to
ensure safety in dynamic clinical environments. Current Vision-Language Models
(VLMs) demonstrate strong general-purpose capabilities but remain limited in
temporal reasoning, uncertainty estimation, and structured outputs needed for
robotic planning. We present a lightweight agentic multimodal framework for
video-based scene understanding. Combining the Qwen2.5-VL-3B-Instruct model
with a SmolAgent-based orchestration layer, it supports chain-of-thought
reasoning, speech-vision fusion, and dynamic tool invocation. The framework
generates structured scene graphs and leverages a hybrid retrieval module for
interpretable and adaptive reasoning. Evaluations on the Video-MME benchmark
and a custom clinical dataset show competitive accuracy and improved robustness
compared to state-of-the-art VLMs, demonstrating its potential for applications
in robot-assisted surgery, patient monitoring, and decision support.

</details>


### [55] [UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models](https://arxiv.org/abs/2509.21760)
*Lan Chen,Yuchao Gu,Qi Mao*

Main category: cs.CV

TL;DR: UniVid是一个统一的视觉模型框架，通过微调视频扩散 Transformer 来处理各种视觉任务，实现了跨模态和跨来源的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在统一多种语言任务方面取得了成功，但现有的视觉模型（如LVM）在处理视觉任务时需要特定任务的预训练，成本高且扩展性受限。作者希望探索一种更统一、可扩展的替代方案，即利用预训练的视频生成模型来适应多种图像和视频任务。

Method: UniVid框架通过将任务表示为“视觉句子”（其中上下文序列定义了任务和期望的输出模式），来微调视频扩散 Transformer。这种方法不需要对特定任务进行修改，并且能够处理包含图像和视频的上下文，从而实现跨模态推理。模型仅在自然视频数据上进行训练，然后评估其在不同任务上的泛化能力，包括跨来源任务（从自然到标注数据）。

Result: UniVid在跨模态（图像和视频上下文）和跨来源（自然到标注数据）任务上都表现出了良好的泛化能力。特别地，通过简单地颠倒视觉句子的顺序，可以轻松地在理解和生成任务之间切换。模型在仅使用自然视频数据进行训练的情况下，仍能实现这一目标。

Conclusion: 预训练的视频生成模型有潜力成为视觉建模的一个可扩展且统一的基础。UniVid证明了这种方法的有效性，为未来的视觉模型研究提供了新的方向。

Abstract: Large language models, trained on extensive corpora, successfully unify
diverse linguistic tasks within a single generative framework. Inspired by
this, recent works like Large Vision Model (LVM) extend this paradigm to vision
by organizing tasks into sequential visual sentences, where visual prompts
serve as the context to guide outputs. However, such modeling requires
task-specific pre-training across modalities and sources, which is costly and
limits scalability to unseen tasks. Given that pre-trained video generation
models inherently capture temporal sequence dependencies, we explore a more
unified and scalable alternative: can a pre-trained video generation model
adapt to diverse image and video tasks? To answer this, we propose UniVid, a
framework that fine-tunes a video diffusion transformer to handle various
vision tasks without task-specific modifications. Tasks are represented as
visual sentences, where the context sequence defines both the task and the
expected output modality. We evaluate the generalization of UniVid from two
perspectives: (1) cross-modal inference with contexts composed of both images
and videos, extending beyond LVM's uni-modal setting; (2) cross-source tasks
from natural to annotated data, without multi-source pre-training. Despite
being trained solely on natural video data, UniVid generalizes well in both
settings. Notably, understanding and generation tasks can easily switch by
simply reversing the visual sentence order in this paradigm. These findings
highlight the potential of pre-trained video generation models to serve as a
scalable and unified foundation for vision modeling. Our code will be released
at https://github.com/CUC-MIPG/UniVid.

</details>


### [56] [CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones](https://arxiv.org/abs/2509.21764)
*Wenyi Gong,Mieszko Lis*

Main category: cs.CV

TL;DR: 本篇论文提出了一种新的ViT图像压缩方法，可以兼容现有的基于空间结构的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的ViT模型压缩方法在处理具有窗口注意力、相对位置编码等空间结构的模型时会遇到困难，因为它们无法保留模型依赖的空间结构。

Method: 提出了一种新的token合并方法，该方法在保留空间结构的同时，还能利用信息分布不均的特点。具体包括：1. 使用2D压缩策略来保证token布局的结构化。2. 使用空间感知的合并算法来保持token的相对位置。3. 使用新颖的、按维度最大值来表示token，从而保留重要的特征。

Result: 在SAM-H模型上实现了1.25倍的加速，mIOU仅下降0.7%。在DeiT-B模型上实现了1.15倍的加速，在ImageNet上微调一个epoch后top-1准确率没有下降。

Conclusion: 所提出的方法简单有效，能够很好地兼容现有的基于空间结构的模型，并在多种视觉任务上取得了最先进的性能。

Abstract: Many modern ViT backbones adopt spatial architectural designs, such as window
attention, decomposed relative positional embeddings in SAM, and RoPE in
DINOv3. Such architectures impose new challenges on token reduction, as the
vast majority of existing methods fail to preserve the spatial structure these
architectures depend on. In this paper, we introduce a simple yet effective
token merging method that maintains spatial integrity, enabling seamless
compatibility with spatial architectures. We reconcile two seemingly
conflicting requirements: (i)exploiting the uneven information distribution
across the spatial layout while (ii)preserving the spatial structure
post-merging. Our approach employs (i)a 2D reduction strategy to enforce
structured token layouts, (ii)a spatial-aware merging algorithm that maintains
relative token positions, and (iii)a novel max-magnitude-per-dimension token
representation that preserves salient features. Our method demonstrates strong
performance both off-the-shelf and with fine-tuning, achieving state-of-the-art
results on spatial and non-spatial architectures across various vision tasks.
Specifically, we achieve 1.25x speedup on SAM-H with only 0.7% mIOU drop
evaluated on COCO off-the-shelf, and 1.15x speedup on DeiT-B with no top-1
accuracy drop on ImageNet within just one epoch of fine-tuning.

</details>


### [57] [MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning](https://arxiv.org/abs/2509.22281)
*Jinkun Hao,Naifu Liang,Zhen Luo,Xudong Xu,Weipeng Zhong,Ran Yi,Yichen Jin,Zhaoyang Lyu,Feng Zheng,Lizhuang Ma,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 生成用于机器人抓取任务的逼真桌面试景数据集和框架。


<details>
  <summary>Details</summary>
Motivation: 传统的桌面试景生成方法耗时且不合理，无法满足机器人抓取任务的训练需求。

Method: 提出了一种名为“任务导向的桌面试景生成”的新任务，并引入了MesaTask-10K数据集。开发了基于LLM和DPO的MesaTask框架，通过对象推理、空间关系推理和场景图构建来生成符合任务描述的逼真桌面试景。

Result: MesaTask框架在生成符合任务要求的逼真桌面试景方面优于基线方法。

Conclusion: MesaTask框架能够有效解决任务指令与桌面试景之间的差距，为机器人抓取任务的训练提供了高质量的数据集和生成方法。

Abstract: The ability of robots to interpret human instructions and execute
manipulation tasks necessitates the availability of task-relevant tabletop
scenes for training. However, traditional methods for creating these scenes
rely on time-consuming manual layout design or purely randomized layouts, which
are limited in terms of plausibility or alignment with the tasks. In this
paper, we formulate a novel task, namely task-oriented tabletop scene
generation, which poses significant challenges due to the substantial gap
between high-level task instructions and the tabletop scenes. To support
research on such a challenging task, we introduce MesaTask-10K, a large-scale
dataset comprising approximately 10,700 synthetic tabletop scenes with manually
crafted layouts that ensure realistic layouts and intricate inter-object
relations. To bridge the gap between tasks and scenes, we propose a Spatial
Reasoning Chain that decomposes the generation process into object inference,
spatial interrelation reasoning, and scene graph construction for the final 3D
layout. We present MesaTask, an LLM-based framework that utilizes this
reasoning chain and is further enhanced with DPO algorithms to generate
physically plausible tabletop scenes that align well with given task
descriptions. Exhaustive experiments demonstrate the superior performance of
MesaTask compared to baselines in generating task-conforming tabletop scenes
with realistic layouts. Project page is at https://mesatask.github.io/

</details>


### [58] [Training-Free Multimodal Deepfake Detection via Graph Reasoning](https://arxiv.org/abs/2509.21774)
*Yuxin Liu,Fei Wang,Kun Li,Yiqi Nie,Junjie Chen,Yanyan Wei,Zhangling Duan,Zhaohong Jia*

Main category: cs.CV

TL;DR: GASP-ICL是一个无需训练的框架，用于多模态深度伪造检测（MDD），它利用LVLM的推理能力来识别视觉、文本和听觉中的伪造线索，通过自适应评分和在上下文学习来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的的研究的不足之处在于，大型视觉语言模型（LVLM）在多模态深度伪造检测（MDD）方面的能力有限，因为它们难以捕捉细微的伪造线索、解决跨模态不一致性以及执行与任务相关的检索。

Method: 提出了一种名为GASP-ICL的训练前框架，它使用一个管道来保持语义相关性，同时将任务感知知识注入LVLM。该框架利用MDD适配的特征提取器来检索对齐的图像-文本对并构建候选集。此外，它还设计了图结构泰勒自适应评分器（GSTAS）来捕捉跨样本关系并传播查询对齐信号，从而产生有区分度的样本。

Result: 在四个伪造类型上进行的实验表明，GASP-ICL的性能优于强基线方法，并且无需对LVLM进行微调。

Conclusion: GASP-ICL 能够通过精确选择语义对齐、与任务相关的示例来增强 LVLM 的鲁棒性，从而在多模态深度伪造检测方面取得优异的性能。

Abstract: Multimodal deepfake detection (MDD) aims to uncover manipulations across
visual, textual, and auditory modalities, thereby reinforcing the reliability
of modern information systems. Although large vision-language models (LVLMs)
exhibit strong multimodal reasoning, their effectiveness in MDD is limited by
challenges in capturing subtle forgery cues, resolving cross-modal
inconsistencies, and performing task-aligned retrieval. To this end, we propose
Guided Adaptive Scorer and Propagation In-Context Learning (GASP-ICL), a
training-free framework for MDD. GASP-ICL employs a pipeline to preserve
semantic relevance while injecting task-aware knowledge into LVLMs. We leverage
an MDD-adapted feature extractor to retrieve aligned image-text pairs and build
a candidate set. We further design the Graph-Structured Taylor Adaptive Scorer
(GSTAS) to capture cross-sample relations and propagate query-aligned signals,
producing discriminative exemplars. This enables precise selection of
semantically aligned, task-relevant demonstrations, enhancing LVLMs for robust
MDD. Experiments on four forgery types show that GASP-ICL surpasses strong
baselines, delivering gains without LVLM fine-tuning.

</details>


### [59] [Prompt-guided Representation Disentanglement for Action Recognition](https://arxiv.org/abs/2509.21783)
*Tianci Wu,Guangming Zhu,Jiang Lu,Siyuan Wang,Ning Wang,Nuoye Xiong,Zhang Liang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ProDA的新框架，用于解决多动作场景下的动作识别问题。ProDA通过解耦复杂场景中的特定动作，并利用时空场景图（SSGs）和动态提示模块（DPM）来指导图解析神经网络（GPNN）生成动作特定的表征，从而有效处理不同动作间的交互。


<details>
  <summary>Details</summary>
Motivation: 现有动作识别方法通常提取统一的特征来处理视频中的所有动作，这使得在多动作场景中很难模拟不同物体间的交互。

Method: 提出ProDA框架，该框架利用时空场景图（SSGs）和动态提示模块（DPM）来指导图解析神经网络（GPNN）生成动作特定的表征。并设计了一个视频自适应的GPNN，使用动态权重聚合信息。

Result: 在视频动作识别的实验中，与现有最先进的方法相比，证明了该方法的有效性。

Conclusion: ProDA框架通过解耦特定动作，有效解决了多动作场景下的动作识别问题，并在实验中取得了优于现有方法的性能。

Abstract: Action recognition is a fundamental task in video understanding. Existing
methods typically extract unified features to process all actions in one video,
which makes it challenging to model the interactions between different objects
in multi-action scenarios. To alleviate this issue, we explore disentangling
any specified actions from complex scenes as an effective solution. In this
paper, we propose Prompt-guided Disentangled Representation for Action
Recognition (ProDA), a novel framework that disentangles any specified actions
from a multi-action scene. ProDA leverages Spatio-temporal Scene Graphs (SSGs)
and introduces Dynamic Prompt Module (DPM) to guide a Graph Parsing Neural
Network (GPNN) in generating action-specific representations. Furthermore, we
design a video-adapted GPNN that aggregates information using dynamic weights.
Experiments in video action recognition demonstrate the effectiveness of our
approach when compared with the state-of-the-art methods. Our code can be found
in https://github.com/iamsnaping/ProDA.git

</details>


### [60] [DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images](https://arxiv.org/abs/2509.21787)
*Dwip Dalal,Gautam Vashishtha,Anku Ranui,Aishwarya Reganti,Parth Patwa,Mohd Sarique,Chandan Gupta,Keshav Nath,Viswanatha Reddy,Vinija Jain,Aman Chadha,Amitava Das,Amit Sheth,Asif Ekbal*

Main category: cs.CV

TL;DR: 介绍了一个包含水印和DAAM的多模态数据集，用于识别和移除图片中的仇恨内容，并提出了DeHater模型。


<details>
  <summary>Details</summary>
Motivation: 解决有害在线内容扭曲公众认知和破坏数字环境健康的问题。

Method: 利用水印、增强的稳定扩散技术和DAAM来识别和移除图片中的仇恨内容，生成仇恨注意力图，并提出DeHater模型。

Result: 生成了仇恨注意力图，并成功从图片中移除仇恨区域。

Conclusion: 提出了一个新标准，用于AI驱动的、基于文本提示的图像仇恨检测，促进了社交媒体中更符合伦理的AI应用。

Abstract: The rise in harmful online content not only distorts public discourse but
also poses significant challenges to maintaining a healthy digital environment.
In response to this, we introduce a multimodal dataset uniquely crafted for
identifying hate in digital content. Central to our methodology is the
innovative application of watermarked, stability-enhanced, stable diffusion
techniques combined with the Digital Attention Analysis Module (DAAM). This
combination is instrumental in pinpointing the hateful elements within images,
thereby generating detailed hate attention maps, which are used to blur these
regions from the image, thereby removing the hateful sections of the image. We
release this data set as a part of the dehate shared task. This paper also
describes the details of the shared task. Furthermore, we present DeHater, a
vision-language model designed for multimodal dehatification tasks. Our
approach sets a new standard in AI-driven image hate detection given textual
prompts, contributing to the development of more ethical AI applications in
social media.

</details>


### [61] [MIRG-RL: Multi-Image Reasoning and Grounding with Reinforcement Learning](https://arxiv.org/abs/2509.21788)
*Lihao Zheng,Jiawei Chen,Xintian Shen,Hao Ma,Tao Wei*

Main category: cs.CV

TL;DR: 该研究提出了一种名为MIRG-RL的框架，用于解决多图像推理和关联的挑战，该框架通过两阶段训练（监督微调和强化学习）来提升模型能力，并在多图像关联基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLMs在处理多图像间的复杂关系时，存在跨图像推理能力不足和跨图像奖励建模不充分的问题。

Method: 提出名为MIRG-RL的统一框架，采用包含标注轨迹的监督微调和图像感知强化学习的组合。具体方法包括：1. 构建整合了对象级和图像级标注信息的轨迹数据。2. 设计包含对象和图像双重奖励函数的图像感知强化学习策略。

Result: MIRG-RL在多图像关联基准测试中达到了64.82%的准确率，超越了先前最佳方法1%，并在跨图像推理任务上取得了SOTA性能。

Conclusion: MIRG-RL框架通过其创新的两阶段训练方法和图像感知强化学习策略，有效提升了模型在多图像推理和关联任务上的表现，并在相关基准测试中设定了新的SOTA标准。

Abstract: Multi-image reasoning and grounding require understanding complex cross-image
relationships at both object levels and image levels. Current Large Visual
Language Models (LVLMs) face two critical challenges: the lack of cross-image
reasoning capabilities and insufficient cross-image reference reward modeling.
To address these issues, we propose a unified framework - Multi-Image Reasoning
and Grounding with Reinforcement Learning (MIRG-RL). Specifically, our
two-stage training paradigm combines supervised fine-tuning with annotated
trajectories and image-aware reinforcement learning optimization, progressively
developing multi-image reasoning capabilities. Furthermore, we innovatively
propose a method for constructing the trajectory data, which integrates
object-level and image-level annotation information, and use this method to
generate a lightweight reasoning-enhanced dataset. To effectively resolve
cross-image ambiguities, we design an image-aware RL policy with dual reward
functions for objects and images. Experiments demonstrate that MIRG-RL achieves
state-of-the-art (SOTA) performance in multi-image grounding benchmarks,
attaining 64.82% on cross-image reasoning tasks - exceeding the previous best
method by 1%. The code and dataset have been released at
https://github.com/ZEUS2035/MIRG-RL.

</details>


### [62] [JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation](https://arxiv.org/abs/2509.22548)
*Shuang Zeng,Dekang Qi,Xinyuan Chang,Feng Xiong,Shichao Xie,Xiaolong Wu,Shiyi Liang,Mu Xu,Xing Wei*

Main category: cs.CV

TL;DR: JanusVLN是一个新颖的视觉语言导航框架，采用双重隐式神经记忆来处理空间几何和视觉语义信息，解决了现有方法中的空间信息丢失、计算冗余和内存膨胀问题，并在导航任务中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航（VLN）方法依赖于显式的语义记忆，如文本认知图或历史视觉帧存储，这会导致空间信息丢失、计算冗余和内存膨胀，阻碍了导航效率。

Method: JanusVLN框架通过引入双重隐式神经记忆来解决上述问题。该框架首先利用空间几何编码器扩展了多模态大语言模型（MLLM），加入了3D先验知识，增强了仅基于RGB输入的空间推理能力。然后，将空间几何和视觉语义编码器的历史键值（KV）缓存构建成双重隐式记忆，通过仅保留初始和滑动窗口的KV，避免了冗余计算，实现了高效的增量更新。

Result: JanusVLN在大量实验中表现优于20多种近期方法，取得了SOTA性能。与使用多种数据类型输入的SOTA方法相比，成功率提高了10.5-35.5%；与使用更多RGB训练数据的SOTA方法相比，成功率提高了3.6-10.8%。

Conclusion: 提出的双重隐式神经记忆是一种新颖的范式，为未来的VLN研究探索了有前景的新方向。

Abstract: Vision-and-Language Navigation requires an embodied agent to navigate through
unseen environments, guided by natural language instructions and a continuous
video stream. Recent advances in VLN have been driven by the powerful semantic
understanding of Multimodal Large Language Models. However, these methods
typically rely on explicit semantic memory, such as building textual cognitive
maps or storing historical visual frames. This type of method suffers from
spatial information loss, computational redundancy, and memory bloat, which
impede efficient navigation. Inspired by the implicit scene representation in
human navigation, analogous to the left brain's semantic understanding and the
right brain's spatial cognition, we propose JanusVLN, a novel VLN framework
featuring a dual implicit neural memory that models spatial-geometric and
visual-semantic memory as separate, compact, and fixed-size neural
representations. This framework first extends the MLLM to incorporate 3D prior
knowledge from the spatial-geometric encoder, thereby enhancing the spatial
reasoning capabilities of models based solely on RGB input. Then, the
historical key-value caches from the spatial-geometric and visual-semantic
encoders are constructed into a dual implicit memory. By retaining only the KVs
of tokens in the initial and sliding window, redundant computation is avoided,
enabling efficient incremental updates. Extensive experiments demonstrate that
JanusVLN outperforms over 20 recent methods to achieve SOTA performance. For
example, the success rate improves by 10.5-35.5 compared to methods using
multiple data types as input and by 3.6-10.8 compared to methods using more RGB
training data. This indicates that the proposed dual implicit neural memory, as
a novel paradigm, explores promising new directions for future VLN research.
Ours project page: https://miv-xjtu.github.io/JanusVLN.github.io/.

</details>


### [63] [LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE](https://arxiv.org/abs/2509.21790)
*Yu Shang,Lei Jin,Yiding Ma,Xin Zhang,Chen Gao,Wei Wu,Yong Li*

Main category: cs.CV

TL;DR: LongScape是一个混合框架，结合了基于扩散的块内去噪和基于自回归的块间因果生成，用于解决视频世界模型中长时序生成的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法在长时序生成方面存在稳定性不足的问题，基于扩散的方法容易出现时间不一致和视觉漂移，而自回归方法则会牺牲视觉细节。

Method: LongScape采用创新的动作引导、可变长度分块机制，根据机器人动作的语义上下文对视频进行分割，确保每个块代表一个完整连贯的动作。此外，还引入了上下文感知专家混合（CMoE）框架，为每个块自适应地激活专门的专家，以保证高质量的视觉效果和流畅的块过渡。

Result: 实验结果表明，LongScape在延长的生成过程中实现了稳定且一致的长时序生成。

Conclusion: LongScape成功解决了视频世界模型在长时序生成中的挑战，实现了高质量、稳定且连贯的视频数据生成。

Abstract: Video-based world models hold significant potential for generating
high-quality embodied manipulation data. However, current video generation
methods struggle to achieve stable long-horizon generation: classical
diffusion-based approaches often suffer from temporal inconsistency and visual
drift over multiple rollouts, while autoregressive methods tend to compromise
on visual detail. To solve this, we introduce LongScape, a hybrid framework
that adaptively combines intra-chunk diffusion denoising with inter-chunk
autoregressive causal generation. Our core innovation is an action-guided,
variable-length chunking mechanism that partitions video based on the semantic
context of robotic actions. This ensures each chunk represents a complete,
coherent action, enabling the model to flexibly generate diverse dynamics. We
further introduce a Context-aware Mixture-of-Experts (CMoE) framework that
adaptively activates specialized experts for each chunk during generation,
guaranteeing high visual quality and seamless chunk transitions. Extensive
experimental results demonstrate that our method achieves stable and consistent
long-horizon generation over extended rollouts. Our code is available at:
https://github.com/tsinghua-fib-lab/Longscape.

</details>


### [64] [MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation](https://arxiv.org/abs/2509.21797)
*Yu Shang,Yangcheng Yu,Xin Zhang,Xin Jin,Haisheng Su,Wei Wu,Yong Li*

Main category: cs.CV

TL;DR: MoWM框架通过融合潜变量模型的高层运动先验和像素空间模型的细粒度视觉特征，克服了现有世界模型的局限性，在CALVIN基准测试中实现了最先进的任务成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于像素重建的世界模型存在视觉冗余，阻碍了动作解码和泛化；基于潜变量的空间模型则忽略了精确操控所需的细节。MoWM旨在融合这两种模型的表示，以应对机器人具身动作规划的挑战。

Method: MoWM框架首先利用潜变量模型的运动感知表示作为高层先验，然后指导像素空间模型提取细粒度视觉特征，从而突出动作解码所需的关键视觉细节。

Result: 在CALVIN基准测试上，MoWM取得了最先进的任务成功率和优于现有方法的泛化能力。此外，还对各特征空间的优势进行了全面分析。

Conclusion: MoWM框架通过融合混合世界模型的表示，有效解决了现有方法的不足，为具身规划提供了新的解决方案，并为未来的研究提供了有价值的见解。

Abstract: Embodied action planning is a core challenge in robotics, requiring models to
generate precise actions from visual observations and language instructions.
While video generation world models are promising, their reliance on
pixel-level reconstruction often introduces visual redundancies that hinder
action decoding and generalization. Latent world models offer a compact,
motion-aware representation, but overlook the fine-grained details critical for
precise manipulation. To overcome these limitations, we propose MoWM, a
mixture-of-world-model framework that fuses representations from hybrid world
models for embodied action planning. Our approach uses motion-aware
representations from a latent model as a high-level prior, which guides the
extraction of fine-grained visual features from the pixel space model. This
design allows MoWM to highlight the informative visual details needed for
action decoding. Extensive evaluations on the CALVIN benchmark demonstrate that
our method achieves state-of-the-art task success rates and superior
generalization. We also provide a comprehensive analysis of the strengths of
each feature space, offering valuable insights for future research in embodied
planning. The code is available at: https://github.com/tsinghua-fib-lab/MoWM.

</details>


### [65] [DiTraj: training-free trajectory control for video diffusion transformer](https://arxiv.org/abs/2509.21839)
*Cheng Lei,Jiayu Zhang,Yue Ma,Xinyu Wang,Long Chen,Liang Tang,Yiqiang Yan,Fei Su,Zhicheng Zhao*

Main category: cs.CV

TL;DR: DiTraj是一个用于文本到视频生成中轨迹控制的训练免费框架，它利用扩散Transformer（DiT）模型的优势，通过前景-背景分离和改进的位置嵌入（STD-RoPE）来增强轨迹控制能力，并在视频质量和可控性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成轨迹控制方法需要大量训练资源或不适用于DiT模型，本文旨在提出一种简单有效且无需训练的框架来解决这些问题。

Method: 1. 提出前景-背景分离引导：利用LLM将用户提示分为前景和背景提示，分别引导前景和背景区域的生成。 2. 提出时空解耦3D旋转位置嵌入（STD-RoPE）：通过修改前景令牌的位置嵌入，消除其跨帧空间差异，增强跨帧注意力，从而增强轨迹控制。 3. 通过调节位置嵌入密度实现3D感知轨迹控制。

Result: DiTraj在视频质量和轨迹可控性方面均优于现有方法，实验结果得到了广泛验证。

Conclusion: DiTraj是一个简单有效的训练免费框架，能够有效实现DiT模型在文本到视频生成中的轨迹控制，并在视频质量和可控性方面取得了显著的改进。

Abstract: Diffusion Transformers (DiT)-based video generation models with 3D full
attention exhibit strong generative capabilities. Trajectory control represents
a user-friendly task in the field of controllable video generation. However,
existing methods either require substantial training resources or are
specifically designed for U-Net, do not take advantage of the superior
performance of DiT. To address these issues, we propose DiTraj, a simple but
effective training-free framework for trajectory control in text-to-video
generation, tailored for DiT. Specifically, first, to inject the object's
trajectory, we propose foreground-background separation guidance: we use the
Large Language Model (LLM) to convert user-provided prompts into foreground and
background prompts, which respectively guide the generation of foreground and
background regions in the video. Then, we analyze 3D full attention and explore
the tight correlation between inter-token attention scores and position
embedding. Based on this, we propose inter-frame Spatial-Temporal Decoupled
3D-RoPE (STD-RoPE). By modifying only foreground tokens' position embedding,
STD-RoPE eliminates their cross-frame spatial discrepancies, strengthening
cross-frame attention among them and thus enhancing trajectory control.
Additionally, we achieve 3D-aware trajectory control by regulating the density
of position embedding. Extensive experiments demonstrate that our method
outperforms previous methods in both video quality and trajectory
controllability.

</details>


### [66] [A Comprehensive Evaluation of Transformer-Based Question Answering Models and RAG-Enhanced Design](https://arxiv.org/abs/2509.21845)
*Zichen Zhang,Kunlong Zhang,Hongwei Ruan,Yiming Luo*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Transformer-based models have advanced the field of question answering, but
multi-hop reasoning, where answers require combining evidence across multiple
passages, remains difficult. This paper presents a comprehensive evaluation of
retrieval strategies for multi-hop question answering within a
retrieval-augmented generation framework. We compare cosine similarity, maximal
marginal relevance, and a hybrid method that integrates dense embeddings with
lexical overlap and re-ranking. To further improve retrieval, we adapt the
EfficientRAG pipeline for query optimization, introducing token labeling and
iterative refinement while maintaining efficiency. Experiments on the HotpotQA
dataset show that the hybrid approach substantially outperforms baseline
methods, achieving a relative improvement of 50 percent in exact match and 47
percent in F1 score compared to cosine similarity. Error analysis reveals that
hybrid retrieval improves entity recall and evidence complementarity, while
remaining limited in handling distractors and temporal reasoning. Overall, the
results suggest that hybrid retrieval-augmented generation provides a practical
zero-shot solution for multi-hop question answering, balancing accuracy,
efficiency, and interpretability.

</details>


### [67] [Dynamic Novel View Synthesis in High Dynamic Range](https://arxiv.org/abs/2509.21853)
*Kaixuan Zhang,Zhipeng Xiong,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: 本研究提出了HDR-4DGS，一种用于HDR动态新视角合成（HDR DNVS）的框架，通过引入动态色调映射模块来处理动态场景中的时间辐射变化和LDR到HDR的转换，实现了时间辐射一致性和空间颜色准确性，并在实验中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有HDR新视角合成方法主要关注静态场景，未能处理真实世界中常见的动态元素（如移动物体、光照变化等）。本研究旨在解决这一局限，提出更贴近现实的HDR动态新视角合成问题（HDR DNVS）。

Method: 提出了一种基于高斯泼溅（Gaussian Splatting）的HDR-4DGS架构，该架构包含一个创新的动态色调映射模块，该模块显式连接HDR和LDR域，并通过动态调整色调映射函数来适应时间维度上不断变化的辐射分布，以保持时间辐射的一致性。

Result: HDR-4DGS在时间和空间上都实现了准确的颜色转换和辐射一致性，能够从任意视角和时间实例生成逼真的HDR渲染。实验结果表明，HDR-4DGS在定量性能和视觉保真度上均优于现有最先进的方法。

Conclusion: HDR-4DGS成功地解决了HDR动态新视角合成的挑战，通过动态色调映射有效处理了动态场景中的时间辐射变化和LDR到HDR的转换，实现了高质量的渲染效果，并在实验中得到了验证。

Abstract: High Dynamic Range Novel View Synthesis (HDR NVS) seeks to learn an HDR 3D
model from Low Dynamic Range (LDR) training images captured under conventional
imaging conditions. Current methods primarily focus on static scenes,
implicitly assuming all scene elements remain stationary and non-living.
However, real-world scenarios frequently feature dynamic elements, such as
moving objects, varying lighting conditions, and other temporal events, thereby
presenting a significantly more challenging scenario. To address this gap, we
propose a more realistic problem named HDR Dynamic Novel View Synthesis (HDR
DNVS), where the additional dimension ``Dynamic'' emphasizes the necessity of
jointly modeling temporal radiance variations alongside sophisticated 3D
translation between LDR and HDR. To tackle this complex, intertwined challenge,
we introduce HDR-4DGS, a Gaussian Splatting-based architecture featured with an
innovative dynamic tone-mapping module that explicitly connects HDR and LDR
domains, maintaining temporal radiance coherence by dynamically adapting
tone-mapping functions according to the evolving radiance distributions across
the temporal dimension. As a result, HDR-4DGS achieves both temporal radiance
consistency and spatially accurate color translation, enabling photorealistic
HDR renderings from arbitrary viewpoints and time instances. Extensive
experiments demonstrate that HDR-4DGS surpasses existing state-of-the-art
methods in both quantitative performance and visual fidelity. Source code will
be released.

</details>


### [68] [SRHand: Super-Resolving Hand Images and 3D Shapes via View/Pose-aware Neural Image Representations and Explicit 3D Meshes](https://arxiv.org/abs/2509.21859)
*Minje Kim,Tae-Kyun Kim*

Main category: cs.CV

TL;DR: SRHand是一个从低分辨率图像重建精细手部3D几何和纹理的方法，它结合了隐式图像表示和显式手部网格，通过几何感知隐式图像函数（GIIF）学习手部先验并进行上采样，同时优化图像函数和3D手部形状，实现了多视图和姿态一致性，并在InterHand2.6M和Goliath数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从低分辨率图像中重建高保真手部几何，并且现有的多视图超分辨率方法不适用于可变形的手部。

Method: SRHand结合了隐式图像表示和显式手部网格。它引入了几何感知隐式图像函数（GIIF）来学习手部先验并对输入图像进行上采样。通过联合优化隐式图像函数和显式3D手部形状，实现了多视图和姿态的一致性。

Result: SRHand能够从低分辨率图像中重建精细的手部3D几何（包括皱纹和指甲）和纹理。在InterHand2.6M和Goliath数据集上的实验表明，SRHand在定量和定性上均显著优于现有的图像超分辨率方法和3D手部重建方法。

Conclusion: SRHand成功地从低分辨率图像重建了精细的手部3D几何和纹理，克服了现有方法的局限性，并在多个数据集上展示了其优越性。

Abstract: Reconstructing detailed hand avatars plays a crucial role in various
applications. While prior works have focused on capturing high-fidelity hand
geometry, they heavily rely on high-resolution multi-view image inputs and
struggle to generalize on low-resolution images. Multi-view image
super-resolution methods have been proposed to enforce 3D view consistency.
These methods, however, are limited to static objects/scenes with fixed
resolutions and are not applicable to articulated deformable hands. In this
paper, we propose SRHand (Super-Resolution Hand), the method for reconstructing
detailed 3D geometry as well as textured images of hands from low-resolution
images. SRHand leverages the advantages of implicit image representation with
explicit hand meshes. Specifically, we introduce a geometric-aware implicit
image function (GIIF) that learns detailed hand prior by upsampling the coarse
input images. By jointly optimizing the implicit image function and explicit 3D
hand shapes, our method preserves multi-view and pose consistency among
upsampled hand images, and achieves fine-detailed 3D reconstruction (wrinkles,
nails). In experiments using the InterHand2.6M and Goliath datasets, our method
significantly outperforms state-of-the-art image upsampling methods adapted to
hand datasets, and 3D hand reconstruction methods, quantitatively and
qualitatively. Project page: https://yunminjin2.github.io/projects/srhand

</details>


### [69] [Deepfakes: we need to re-think the concept of "real" images](https://arxiv.org/abs/2509.21864)
*Janis Keuper,Margret Keuper*

Main category: cs.CV

TL;DR: 现代图像生成模型因其易用性而引发了对犯罪行为和社会负面影响的担忧。虽然已有研究致力于检测“假”图像，但本文认为当前工作过于关注生成算法和“假”数据样本，而忽视了对“真”图像的清晰定义和数据收集。文章指出，目前“假”图像检测方法的评估严重依赖于少数过时的低分辨率“真”图像数据集（如ImageNet）。然而，如今超过90%的照片由智能手机拍摄，这些设备通常采用复杂的算法（与“假”图像生成器密切相关）从多个传感器和时间输入计算图像。因此，本文认为需要重新思考“真”图像的概念，并呼吁提高对当前研究局限性的认识，引发关于“假”图像检测目标有效性的讨论，并强调需要明确“真”图像的技术定义和新的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 当前对“假”图像的检测研究过于关注生成算法和“假”样本，而忽略了对“真”图像的定义和高质量数据集的收集，这可能影响检测方法的有效性。

Method: 通过分析当前“假”图像检测研究的现状，指出其依赖过时的“真”图像数据集，并提出智能手机成像技术的进步模糊了“真”与“假”图像的界限，从而论证了重新定义“真”图像的必要性。

Result: 当前“假”图像检测研究存在局限性，依赖的数据集陈旧，且未能充分考虑现代成像技术对“真”图像定义的改变，迫切需要新的“真”图像定义和数据集。

Conclusion: “假”图像检测研究需要重新审视其基本假设，明确“真”图像的技术定义，并构建新的基准数据集，以应对现代成像技术带来的挑战。同时，也需要讨论“假”图像检测本身是否是一个合理的长期目标。

Abstract: The wide availability and low usability barrier of modern image generation
models has triggered the reasonable fear of criminal misconduct and negative
social implications. The machine learning community has been engaging this
problem with an extensive series of publications proposing algorithmic
solutions for the detection of "fake", e.g. entirely generated or partially
manipulated images. While there is undoubtedly some progress towards technical
solutions of the problem, we argue that current and prior work is focusing too
much on generative algorithms and "fake" data-samples, neglecting a clear
definition and data collection of "real" images. The fundamental question "what
is a real image?" might appear to be quite philosophical, but our analysis
shows that the development and evaluation of basically all current
"fake"-detection methods is relying on only a few, quite old low-resolution
datasets of "real" images like ImageNet. However, the technology for the
acquisition of "real" images, aka taking photos, has drastically evolved over
the last decade: Today, over 90% of all photographs are produced by smartphones
which typically use algorithms to compute an image from multiple inputs (over
time) from multiple sensors. Based on the fact that these image formation
algorithms are typically neural network architectures which are closely related
to "fake"-image generators, we state the position that today, we need to
re-think the concept of "real" images. The purpose of this position paper is to
raise the awareness of the current shortcomings in this active field of
research and to trigger an open discussion whether the detection of "fake"
images is a sound objective at all. At the very least, we need a clear
technical definition of "real" images and new benchmark datasets.

</details>


### [70] [Unlocking the Essence of Beauty: Advanced Aesthetic Reasoning with Relative-Absolute Policy Optimization](https://arxiv.org/abs/2509.21871)
*Boyang Liu,Yifan Hu,Senjie Jin,Shihan Dou,Gonglei Shi,Jie Shao,Tao Gui,Xuanjing Huang*

Main category: cs.CV

TL;DR: Aes-R1是一个使用强化学习的图像美学评估框架，通过AesCoT构建数据，并用RAPO算法优化评分和排序，提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）擅长图像美学评估，但缺乏相关数据且美学判断主观，导致模型难以生成准确且可解释的判断。

Method: Aes-R1框架：1. 使用AesCoT构建和筛选高质量的链式思考美学推理数据用于冷启动。 2. 训练模型生成结构化解释。 3. 采用新的强化学习算法RAPO，联合优化绝对分数回归和相对排序，以提高准确性和跨图像偏好判断。

Result: Aes-R1显著提高了模型的美学评分和推理能力，使MLLMs能够生成有依据的解释和准确的分数。实验表明，Aes-R1将骨干模型的平均PLCC/SRCC提高了47.9%/34.8%，优于现有技术水平。在有限监督和分布外场景下也表现出稳健的泛化能力。

Conclusion: Aes-R1框架通过结合链式思考数据构建和强化学习优化，有效解决了MLLMs在图像美学评估中的准确性和可解释性问题，并在多个方面取得了显著的改进。

Abstract: Multimodal large language models (MLLMs) are well suited to image aesthetic
assessment, as they can capture high-level aesthetic features leveraging their
cross-modal understanding capacity. However, the scarcity of multimodal
aesthetic reasoning data and the inherently subjective nature of aesthetic
judgment make it difficult for MLLMs to generate accurate aesthetic judgments
with interpretable rationales. To this end, we propose Aes-R1, a comprehensive
aesthetic reasoning framework with reinforcement learning (RL). Concretely,
Aes-R1 integrates a pipeline, AesCoT, to construct and filter high-quality
chain-of-thought aesthetic reasoning data used for cold-start. After teaching
the model to generate structured explanations prior to scoring, we then employ
the Relative-Absolute Policy Optimization (RAPO), a novel RL algorithm that
jointly optimizes absolute score regression and relative ranking order,
improving both per-image accuracy and cross-image preference judgments. Aes-R1
enables MLLMs to generate grounded explanations alongside faithful scores,
thereby enhancing aesthetic scoring and reasoning in a unified framework.
Extensive experiments demonstrate that Aes-R1 improves the backbone's average
PLCC/SRCC by 47.9%/34.8%, surpassing state-of-the-art baselines of similar
size. More ablation studies validate Aes-R1's robust generalization under
limited supervision and in out-of-distribution scenarios.

</details>


### [71] [StableDub: Taming Diffusion Prior for Generalized and Efficient Visual Dubbing](https://arxiv.org/abs/2509.21887)
*Liyang Chen,Tianze Zhou,Xu He,Boshi Tang,Zhiyong Wu,Yang Huang,Yang Wu,Zhongqian Sun,Wei Yang,Helen Meng*

Main category: cs.CV

TL;DR: StableDub是一个整合了唇部习惯感知模型和遮挡鲁棒合成的新型框架，用于解决视觉配音任务中口型与音频不同步以及遮挡物干扰的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉配音方法存在两个关键缺陷：1. 仅依赖音频的驱动方式无法充分捕捉说话人特定的唇部习惯，导致生成的唇部运动与目标虚拟形象不符；2. 传统的盲图像修复方法在处理遮挡物（如麦克风、手）时易产生视觉瑕疵，限制了实际应用。

Method: 本研究提出StableDub框架，基于Stable-Diffusion骨干网络，开发了唇部习惯调制机制，同时建模语音-视觉同步和说话人特定的口面部动态。为实现遮挡情况下的合理唇部几何和物体外观，引入了遮挡感知训练策略，明确将遮挡物暴露于图像修复过程。此外，采用混合Mamba-Transformer架构以提高训练效率，尤其适用于资源有限的研究场景。

Result: 实验结果表明，StableDub在唇部习惯相似性和遮挡鲁棒性方面表现优越，并在音频-唇形同步、视频质量和分辨率一致性方面超越了其他方法。

Conclusion: StableDub通过整合唇部习惯感知和遮挡鲁棒合成，有效解决了现有视觉配音方法的关键缺陷，并在多个方面取得了显著性能提升，扩展了视觉配音方法的适用性。

Abstract: The visual dubbing task aims to generate mouth movements synchronized with
the driving audio, which has seen significant progress in recent years.
However, two critical deficiencies hinder their wide application: (1)
Audio-only driving paradigms inadequately capture speaker-specific lip habits,
which fail to generate lip movements similar to the target avatar; (2)
Conventional blind-inpainting approaches frequently produce visual artifacts
when handling obstructions (e.g., microphones, hands), limiting practical
deployment. In this paper, we propose StableDub, a novel and concise framework
integrating lip-habit-aware modeling with occlusion-robust synthesis.
Specifically, building upon the Stable-Diffusion backbone, we develop a
lip-habit-modulated mechanism that jointly models phonemic audio-visual
synchronization and speaker-specific orofacial dynamics. To achieve plausible
lip geometries and object appearances under occlusion, we introduce the
occlusion-aware training strategy by explicitly exposing the occlusion objects
to the inpainting process. By incorporating the proposed designs, the model
eliminates the necessity for cost-intensive priors in previous methods, thereby
exhibiting superior training efficiency on the computationally intensive
diffusion-based backbone. To further optimize training efficiency from the
perspective of model architecture, we introduce a hybrid Mamba-Transformer
architecture, which demonstrates the enhanced applicability in low-resource
research scenarios. Extensive experimental results demonstrate that StableDub
achieves superior performance in lip habit resemblance and occlusion
robustness. Our method also surpasses other methods in audio-lip sync, video
quality, and resolution consistency. We expand the applicability of visual
dubbing methods from comprehensive aspects, and demo videos can be found at
https://stabledub.github.io.

</details>


### [72] [Drag4D: Align Your Motion with Text-Driven 3D Scene Generation](https://arxiv.org/abs/2509.21888)
*Minjun Kang,Inkyu Shin,Taeyeop Lee,In So Kweon,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: Drag4D框架允许用户通过文本驱动的3D场景生成来控制3D对象的运动，将用户定义的3D轨迹中的对象集成到高质量的3D背景中。


<details>
  <summary>Details</summary>
Motivation: 集成对象运动控制到文本驱动的3D场景生成中，使用户能够定义3D对象的3D轨迹，并将其无缝集成到高质量的3D背景中。

Method: Drag4D框架包括三个阶段：1.通过2D高斯泼溅和新视图修复来增强文本到3D背景生成；2.使用3D复制粘贴方法，通过图像到3D模型提取目标对象，并将其合成到生成的3D场景中，然后通过物理感知对象位置学习进行空间对齐；3.通过部件增强、运动条件化的视频扩散模型对空间对齐的对象进行时间动画处理，以实现视图一致的时间对齐。

Result: Drag4D框架在每个阶段和最终结果都得到了有效验证，展示了用户控制的对象运动与高质量3D背景的和谐统一。

Conclusion: Drag4D框架成功地实现了用户控制的对象运动与高质量3D背景的集成。

Abstract: We introduce Drag4D, an interactive framework that integrates object motion
control within text-driven 3D scene generation. This framework enables users to
define 3D trajectories for the 3D objects generated from a single image,
seamlessly integrating them into a high-quality 3D background. Our Drag4D
pipeline consists of three stages. First, we enhance text-to-3D background
generation by applying 2D Gaussian Splatting with panoramic images and
inpainted novel views, resulting in dense and visually complete 3D
reconstructions. In the second stage, given a reference image of the target
object, we introduce a 3D copy-and-paste approach: the target instance is
extracted in a full 3D mesh using an off-the-shelf image-to-3D model and
seamlessly composited into the generated 3D scene. The object mesh is then
positioned within the 3D scene via our physics-aware object position learning,
ensuring precise spatial alignment. Lastly, the spatially aligned object is
temporally animated along a user-defined 3D trajectory. To mitigate motion
hallucination and ensure view-consistent temporal alignment, we develop a
part-augmented, motion-conditioned video diffusion model that processes
multiview image pairs together with their projected 2D trajectories. We
demonstrate the effectiveness of our unified architecture through evaluations
at each stage and in the final results, showcasing the harmonized alignment of
user-controlled object motion within a high-quality 3D background.

</details>


### [73] [Syncphony: Synchronized Audio-to-Video Generation with Diffusion Transformers](https://arxiv.org/abs/2509.21893)
*Jibin Song,Mingi Kwon,Jaeseok Jeong,Youngjung Uh*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-to-video and image-to-video generation have made rapid progress in
visual quality, but they remain limited in controlling the precise timing of
motion. In contrast, audio provides temporal cues aligned with video motion,
making it a promising condition for temporally controlled video generation.
However, existing audio-to-video (A2V) models struggle with fine-grained
synchronization due to indirect conditioning mechanisms or limited temporal
modeling capacity. We present Syncphony, which generates 380x640 resolution,
24fps videos synchronized with diverse audio inputs. Our approach builds upon a
pre-trained video backbone and incorporates two key components to improve
synchronization: (1) Motion-aware Loss, which emphasizes learning at
high-motion regions; (2) Audio Sync Guidance, which guides the full model using
a visually aligned off-sync model without audio layers to better exploit audio
cues at inference while maintaining visual quality. To evaluate
synchronization, we propose CycleSync, a video-to-audio-based metric that
measures the amount of motion cues in the generated video to reconstruct the
original audio. Experiments on AVSync15 and The Greatest Hits datasets
demonstrate that Syncphony outperforms existing methods in both synchronization
accuracy and visual quality. Project page is available at:
https://jibin86.github.io/syncphony_project_page

</details>


### [74] [LG-CD: Enhancing Language-Guided Change Detection through SAM2 Adaptation](https://arxiv.org/abs/2509.21894)
*Yixiao Liu,Yizhou Yang,Jinwen Li,Jun Tao,Ruoyu Li,Xiangkun Wang,Min Zhu,Junlong Cheng*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Remote Sensing Change Detection (RSCD) typically identifies changes in land
cover or surface conditions by analyzing multi-temporal images. Currently, most
deep learning-based methods primarily focus on learning unimodal visual
information, while neglecting the rich semantic information provided by
multimodal data such as text. To address this limitation, we propose a novel
Language-Guided Change Detection model (LG-CD). This model leverages natural
language prompts to direct the network's attention to regions of interest,
significantly improving the accuracy and robustness of change detection.
Specifically, LG-CD utilizes a visual foundational model (SAM2) as a feature
extractor to capture multi-scale pyramid features from high-resolution to
low-resolution across bi-temporal remote sensing images. Subsequently,
multi-layer adapters are employed to fine-tune the model for downstream tasks,
ensuring its effectiveness in remote sensing change detection. Additionally, we
design a Text Fusion Attention Module (TFAM) to align visual and textual
information, enabling the model to focus on target change regions using text
prompts. Finally, a Vision-Semantic Fusion Decoder (V-SFD) is implemented,
which deeply integrates visual and semantic information through a
cross-attention mechanism to produce highly accurate change detection masks.
Our experiments on three datasets (LEVIR-CD, WHU-CD, and SYSU-CD) demonstrate
that LG-CD consistently outperforms state-of-the-art change detection methods.
Furthermore, our approach provides new insights into achieving generalized
change detection by leveraging multimodal information.

</details>


### [75] [TDEdit: A Unified Diffusion Framework for Text-Drag Guided Image Manipulation](https://arxiv.org/abs/2509.21905)
*Qihang Wang,Yaxiong Wang,Lechao Cheng,Zhun Zhong*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper explores image editing under the joint control of text and drag
interactions. While recent advances in text-driven and drag-driven editing have
achieved remarkable progress, they suffer from complementary limitations:
text-driven methods excel in texture manipulation but lack precise spatial
control, whereas drag-driven approaches primarily modify shape and structure
without fine-grained texture guidance. To address these limitations, we propose
a unified diffusion-based framework for joint drag-text image editing,
integrating the strengths of both paradigms. Our framework introduces two key
innovations: (1) Point-Cloud Deterministic Drag, which enhances latent-space
layout control through 3D feature mapping, and (2) Drag-Text Guided Denoising,
dynamically balancing the influence of drag and text conditions during
denoising. Notably, our model supports flexible editing modes - operating with
text-only, drag-only, or combined conditions - while maintaining strong
performance in each setting. Extensive quantitative and qualitative experiments
demonstrate that our method not only achieves high-fidelity joint editing but
also matches or surpasses the performance of specialized text-only or drag-only
approaches, establishing a versatile and generalizable solution for
controllable image manipulation. Code will be made publicly available to
reproduce all results presented in this work.

</details>


### [76] [Enhancing Vehicle Detection under Adverse Weather Conditions with Contrastive Learning](https://arxiv.org/abs/2509.21916)
*Boying Li,Chang Liu,Petter Kyösti,Mattias Öhman,Devashish Singha Roy,Sofia Plazzi,Hamam Mokayed,Olle Hagner*

Main category: cs.CV

TL;DR: 本文提出了一个名为 sideload-CL-adaptation 的框架，利用无标注数据来提升无人机图像中车辆检测的性能，特别是在北欧地区面临的可见性挑战和领域迁移问题。该框架通过对比学习在无标注数据上预训练一个卷积神经网络（CNN）表征提取器，然后将其集成到一个冻结的 YOLOv11n 主干网络中进行微调。实验表明，该方法在 NVD 数据集上将 mAP50 指标提高了 3.8% 至 9.5%。


<details>
  <summary>Details</summary>
Motivation: 北欧地区无人机图像车辆检测面临可见性挑战和领域迁移问题（如积雪覆盖变化），同时标注数据成本高昂，而无标注数据易于获取。因此，需要一种有效利用无标注数据来提升车辆检测性能的方法。

Method: 1. 预训练阶段：在无标注数据上，通过对比学习训练一个基于 CNN 的表征提取器。2. 微调阶段：将预训练的表征提取器“旁加载”（sideload）到一个冻结的 YOLOv11n 主干网络中，并进行微调。3. 鲁棒性探索：通过大量实验比较了不同的融合方法和粒度，以找到最优的旁加载-对比学习-自适应（sideload-CL-adaptation）策略。

Result: 所提出的 sideload-CL-adaptation 模型在 NVD 数据集上的 mAP50 指标相比基线模型，性能提升了 3.8% 至 9.5%。

Conclusion: 所提出的 sideload-CL-adaptation 框架能够有效利用无标注数据，显著提升在具有挑战性的北欧地区无人机图像中的车辆检测性能，为解决数据稀疏和领域迁移问题提供了一种有效的解决方案。

Abstract: Aside from common challenges in remote sensing like small, sparse targets and
computation cost limitations, detecting vehicles from UAV images in the Nordic
regions faces strong visibility challenges and domain shifts caused by diverse
levels of snow coverage. Although annotated data are expensive, unannotated
data is cheaper to obtain by simply flying the drones. In this work, we
proposed a sideload-CL-adaptation framework that enables the use of unannotated
data to improve vehicle detection using lightweight models. Specifically, we
propose to train a CNN-based representation extractor through contrastive
learning on the unannotated data in the pretraining stage, and then sideload it
to a frozen YOLO11n backbone in the fine-tuning stage. To find a robust
sideload-CL-adaptation, we conducted extensive experiments to compare various
fusion methods and granularity. Our proposed sideload-CL-adaptation model
improves the detection performance by 3.8% to 9.5% in terms of mAP50 on the NVD
dataset.

</details>


### [77] [Taming Flow-based I2V Models for Creative Video Editing](https://arxiv.org/abs/2509.21917)
*Xianghao Kong,Hansheng Chen,Yuwei Guo,Lvmin Zhang,Gordon Wetzstein,Maneesh Agrawala,Anyi Rao*

Main category: cs.CV

TL;DR: IF-V2V是一种无需进行模型反演的视频编辑方法，能够直接利用现有的图像到视频（I2V）模型进行视频编辑，并且计算开销较低。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编辑方法要么需要模型特定的反演设计，要么需要大量的优化，这限制了它们将最新的图像到视频（I2V）模型的能力迁移到视频域进行编辑。本研究旨在解决这一挑战，提出一种能够适应现有I2V模型进行视频编辑且计算开销小的方法。

Method: 本研究提出了一种名为IF-V2V的无反演方法。该方法通过引入“样本偏差向量场校正”来整合源视频信息到去噪过程，并采用“保持结构和运动的初始化”来生成带有结构信息的运动感知时间相关噪声。此外，还提出了一种“偏差缓存”机制来最小化计算成本。

Result: 实验评估表明，IF-V2V在编辑质量和一致性方面优于现有方法，并提供了一种轻量级的即插即用解决方案。

Conclusion: IF-V2V是一种有效的、计算开销低的视频编辑方法，它能够直接利用现有的I2V模型，无需反演，并在编辑质量和一致性方面取得了优于现有方法的成果。

Abstract: Although image editing techniques have advanced significantly, video editing,
which aims to manipulate videos according to user intent, remains an emerging
challenge. Most existing image-conditioned video editing methods either require
inversion with model-specific design or need extensive optimization, limiting
their capability of leveraging up-to-date image-to-video (I2V) models to
transfer the editing capability of image editing models to the video domain. To
this end, we propose IF-V2V, an Inversion-Free method that can adapt
off-the-shelf flow-matching-based I2V models for video editing without
significant computational overhead. To circumvent inversion, we devise Vector
Field Rectification with Sample Deviation to incorporate information from the
source video into the denoising process by introducing a deviation term into
the denoising vector field. To further ensure consistency with the source video
in a model-agnostic way, we introduce Structure-and-Motion-Preserving
Initialization to generate motion-aware temporally correlated noise with
structural information embedded. We also present a Deviation Caching mechanism
to minimize the additional computational cost for denoising vector
rectification without significantly impacting editing quality. Evaluations
demonstrate that our method achieves superior editing quality and consistency
over existing approaches, offering a lightweight plug-and-play solution to
realize visual creativity.

</details>


### [78] [Multi-View Crowd Counting With Self-Supervised Learning](https://arxiv.org/abs/2509.21918)
*Hong Mo,Xiong Zhang,Tengfei Shi,Zhongbo Wu*

Main category: cs.CV

TL;DR: 提出了一种名为SSLCounter的新型自监督学习（SSL）框架，用于解决多视图计数（MVC）问题，该框架利用神经体积渲染技术，减少了对大规模标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图计数（MVC）方法大多依赖于完全监督学习（FSL）范式，需要大量的标注数据，而该研究旨在提出一种新的自监督学习（SSL）框架，以减少对大规模标注数据的需求。

Method: SSLCounter框架利用神经体积渲染技术，学习场景的隐式表示，通过微分神经渲染重建连续的几何形状及其2D投影的视图依赖外观。

Result: SSLCounter不仅在多个MVC基准测试中展现了最先进的性能，而且在使用70%的训练数据时也能取得有竞争力的性能，显示了其优越的数据效率。

Conclusion: SSLCounter框架通过利用神经体积渲染技术，成功地实现了自监督学习在多视图计数任务中的应用，并在性能和数据效率方面取得了显著成果。

Abstract: Multi-view counting (MVC) methods have attracted significant research
attention and stimulated remarkable progress in recent years. Despite their
success, most MVC methods have focused on improving performance by following
the fully supervised learning (FSL) paradigm, which often requires large
amounts of annotated data. In this work, we propose SSLCounter, a novel
self-supervised learning (SSL) framework for MVC that leverages neural
volumetric rendering to alleviate the reliance on large-scale annotated
datasets. SSLCounter learns an implicit representation w.r.t. the scene,
enabling the reconstruction of continuous geometry shape and the complex,
view-dependent appearance of their 2D projections via differential neural
rendering. Owing to its inherent flexibility, the key idea of our method can be
seamlessly integrated into exsiting frameworks. Notably, extensive experiments
demonstrate that SSLCounter not only demonstrates state-of-the-art performances
but also delivers competitive performance with only using 70% proportion of
training data, showcasing its superior data efficiency across multiple MVC
benchmarks.

</details>


### [79] [Spatial Reasoning in Foundation Models: Benchmarking Object-Centric Spatial Understanding](https://arxiv.org/abs/2509.21922)
*Vahid Mirjalili,Ramin Giahi,Sriram Kollipara,Akshay Kekuda,Kehui Yao,Kai Zhao,Jianpeng Xu,Kaushiki Nag,Sinduja Subramaniam,Topojoy Biswas,Evren Korpeoglu,Kannan Achan*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Spatial understanding is a critical capability for vision foundation models.
While recent advances in large vision models or vision-language models (VLMs)
have expanded recognition capabilities, most benchmarks emphasize localization
accuracy rather than whether models capture how objects are arranged and
related within a scene. This gap is consequential; effective scene
understanding requires not only identifying objects, but reasoning about their
relative positions, groupings, and depth. In this paper, we present a
systematic benchmark for object-centric spatial reasoning in foundation models.
Using a controlled synthetic dataset, we evaluate state-of-the-art vision
models (e.g., GroundingDINO, Florence-2, OWLv2) and large VLMs (e.g., InternVL,
LLaVA, GPT-4o) across three tasks: spatial localization, spatial reasoning, and
downstream retrieval tasks. We find a stable trade-off: detectors such as
GroundingDINO and OWLv2 deliver precise boxes with limited relational
reasoning, while VLMs like SmolVLM and GPT-4o provide coarse layout cues and
fluent captions but struggle with fine-grained spatial context. Our study
highlights the gap between localization and true spatial understanding, and
pointing toward the need for spatially-aware foundation models in the
community.

</details>


### [80] [PANICL: Mitigating Over-Reliance on Single Prompt in Visual In-Context Learning](https://arxiv.org/abs/2509.21926)
*Jiahao Zhang,Bowen Wang,Hong Liu,Yuta Nakashima,Hajime Nagahara*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Visual In-Context Learning (VICL) uses input-output image pairs, referred to
as in-context pairs (or examples), as prompts alongside query images to guide
models in performing diverse vision tasks. However, VICL often suffers from
over-reliance on a single in-context pair, which can lead to biased and
unstable predictions. We introduce PAtch-based $k$-Nearest neighbor visual
In-Context Learning (PANICL), a general training-free framework that mitigates
this issue by leveraging multiple in-context pairs. PANICL smooths assignment
scores across pairs, reducing bias without requiring additional training.
Extensive experiments on a variety of tasks, including foreground segmentation,
single object detection, colorization, multi-object segmentation, and keypoint
detection, demonstrate consistent improvements over strong baselines. Moreover,
PANICL exhibits strong robustness to domain shifts, including dataset-level
shift (e.g., from COCO to Pascal) and label-space shift (e.g., FSS-1000), and
generalizes well to other VICL models such as SegGPT, Painter, and LVM,
highlighting its versatility and broad applicability.

</details>


### [81] [SingRef6D: Monocular Novel Object Pose Estimation with a Single RGB Reference](https://arxiv.org/abs/2509.21927)
*Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent 6D pose estimation methods demonstrate notable performance but still
face some practical limitations. For instance, many of them rely heavily on
sensor depth, which may fail with challenging surface conditions, such as
transparent or highly reflective materials. In the meantime, RGB-based
solutions provide less robust matching performance in low-light and
texture-less scenes due to the lack of geometry information. Motivated by
these, we propose SingRef6D, a lightweight pipeline requiring only a single RGB
image as a reference, eliminating the need for costly depth sensors, multi-view
image acquisition, or training view synthesis models and neural fields. This
enables SingRef6D to remain robust and capable even under resource-limited
settings where depth or dense templates are unavailable. Our framework
incorporates two key innovations. First, we propose a token-scaler-based
fine-tuning mechanism with a novel optimization loss on top of Depth-Anything
v2 to enhance its ability to predict accurate depth, even for challenging
surfaces. Our results show a 14.41% improvement (in $\delta_{1.05}$) on REAL275
depth prediction compared to Depth-Anything v2 (with fine-tuned head). Second,
benefiting from depth availability, we introduce a depth-aware matching process
that effectively integrates spatial relationships within LoFTR, enabling our
system to handle matching for challenging materials and lighting conditions.
Evaluations of pose estimation on the REAL275, ClearPose, and Toyota-Light
datasets show that our approach surpasses state-of-the-art methods, achieving a
6.1% improvement in average recall.

</details>


### [82] [SemanticControl: A Training-Free Approach for Handling Loosely Aligned Visual Conditions in ControlNet](https://arxiv.org/abs/2509.21938)
*Woosung Joung,Daewon Chae,Jinkyu Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: ControlNet has enabled detailed spatial control in text-to-image diffusion
models by incorporating additional visual conditions such as depth or edge
maps. However, its effectiveness heavily depends on the availability of visual
conditions that are precisely aligned with the generation goal specified by
text prompt-a requirement that often fails in practice, especially for uncommon
or imaginative scenes. For example, generating an image of a cat cooking in a
specific pose may be infeasible due to the lack of suitable visual conditions.
In contrast, structurally similar cues can often be found in more common
settings-for instance, poses of humans cooking are widely available and can
serve as rough visual guides. Unfortunately, existing ControlNet models
struggle to use such loosely aligned visual conditions, often resulting in low
text fidelity or visual artifacts. To address this limitation, we propose
SemanticControl, a training-free method for effectively leveraging misaligned
but semantically relevant visual conditions. Our approach adaptively suppresses
the influence of the visual condition where it conflicts with the prompt, while
strengthening guidance from the text. The key idea is to first run an auxiliary
denoising process using a surrogate prompt aligned with the visual condition
(e.g., "a human playing guitar" for a human pose condition) to extract
informative attention masks, and then utilize these masks during the denoising
of the actual target prompt (e.g., cat playing guitar). Experimental results
demonstrate that our method improves performance under loosely aligned
conditions across various conditions, including depth maps, edge maps, and
human skeletons, outperforming existing baselines. Our code is available at
https://mung3477.github.io/semantic-control.

</details>


### [83] [Customizing Visual Emotion Evaluation for MLLMs: An Open-vocabulary, Multifaceted, and Scalable Approach](https://arxiv.org/abs/2509.21950)
*Daiqing Wu,Dongbao Yang,Sicheng Zhao,Can Ma,Yu Zhou*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recently, Multimodal Large Language Models (MLLMs) have achieved exceptional
performance across diverse tasks, continually surpassing previous expectations
regarding their capabilities. Nevertheless, their proficiency in perceiving
emotions from images remains debated, with studies yielding divergent results
in zero-shot scenarios. We argue that this inconsistency stems partly from
constraints in existing evaluation methods, including the oversight of
plausible responses, limited emotional taxonomies, neglect of contextual
factors, and labor-intensive annotations. To facilitate customized visual
emotion evaluation for MLLMs, we propose an Emotion Statement Judgment task
that overcomes these constraints. Complementing this task, we devise an
automated pipeline that efficiently constructs emotion-centric statements with
minimal human effort. Through systematically evaluating prevailing MLLMs, our
study showcases their stronger performance in emotion interpretation and
context-based emotion judgment, while revealing relative limitations in
comprehending perception subjectivity. When compared to humans, even
top-performing MLLMs like GPT4o demonstrate remarkable performance gaps,
underscoring key areas for future improvement. By developing a fundamental
evaluation framework and conducting a comprehensive MLLM assessment, we hope
this work contributes to advancing emotional intelligence in MLLMs. Project
page: https://github.com/wdqqdw/MVEI.

</details>


### [84] [MultiCrafter: High-Fidelity Multi-Subject Generation via Spatially Disentangled Attention and Identity-Aware Reinforcement Learning](https://arxiv.org/abs/2509.21953)
*Tao Wu,Yibo Jiang,Yehao Lu,Zhizhong Wang,Zeyi Huang,Zequn Qin,Xi Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-subject image generation aims to synthesize user-provided subjects in a
single image while preserving subject fidelity, ensuring prompt consistency,
and aligning with human aesthetic preferences. However, existing methods,
particularly those built on the In-Context-Learning paradigm, are limited by
their reliance on simple reconstruction-based objectives, leading to both
severe attribute leakage that compromises subject fidelity and failing to align
with nuanced human preferences. To address this, we propose MultiCrafter, a
framework that ensures high-fidelity, preference-aligned generation. First, we
find that the root cause of attribute leakage is a significant entanglement of
attention between different subjects during the generation process. Therefore,
we introduce explicit positional supervision to explicitly separate attention
regions for each subject, effectively mitigating attribute leakage. To enable
the model to accurately plan the attention region of different subjects in
diverse scenarios, we employ a Mixture-of-Experts architecture to enhance the
model's capacity, allowing different experts to focus on different scenarios.
Finally, we design a novel online reinforcement learning framework to align the
model with human preferences, featuring a scoring mechanism to accurately
assess multi-subject fidelity and a more stable training strategy tailored for
the MoE architecture. Experiments validate that our framework significantly
improves subject fidelity while aligning with human preferences better.

</details>


### [85] [PartSAM: A Scalable Promptable Part Segmentation Model Trained on Native 3D Data](https://arxiv.org/abs/2509.21965)
*Zhe Zhu,Le Wan,Rui Xu,Yiheng Zhang,Honghua Chen,Zhiyang Dou,Cheng Lin,Yuan Liu,Mingqiang Wei*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Segmenting 3D objects into parts is a long-standing challenge in computer
vision. To overcome taxonomy constraints and generalize to unseen 3D objects,
recent works turn to open-world part segmentation. These approaches typically
transfer supervision from 2D foundation models, such as SAM, by lifting
multi-view masks into 3D. However, this indirect paradigm fails to capture
intrinsic geometry, leading to surface-only understanding, uncontrolled
decomposition, and limited generalization. We present PartSAM, the first
promptable part segmentation model trained natively on large-scale 3D data.
Following the design philosophy of SAM, PartSAM employs an encoder-decoder
architecture in which a triplane-based dual-branch encoder produces spatially
structured tokens for scalable part-aware representation learning. To enable
large-scale supervision, we further introduce a model-in-the-loop annotation
pipeline that curates over five million 3D shape-part pairs from online assets,
providing diverse and fine-grained labels. This combination of scalable
architecture and diverse 3D data yields emergent open-world capabilities: with
a single prompt, PartSAM achieves highly accurate part identification, and in a
Segment-Every-Part mode, it automatically decomposes shapes into both surface
and internal structures. Extensive experiments show that PartSAM outperforms
state-of-the-art methods by large margins across multiple benchmarks, marking a
decisive step toward foundation models for 3D part understanding. Our code and
model will be released soon.

</details>


### [86] [No-Reference Image Contrast Assessment with Customized EfficientNet-B0](https://arxiv.org/abs/2509.21967)
*Javad Hassannataj Joloudari,Bita Mesbahzadeh,Omid Zare,Emrah Arslan,Roohallah Alizadehsani,Hossein Moosaei*

Main category: cs.CV

TL;DR: 提出了一个基于深度学习的无参考图像对比度质量评估框架，通过定制EfficientNet B0、ResNet18和MobileNetV2等预训练模型，并结合对比度感知回归头，在两个基准数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大多数无参考图像质量评估（NR-IQA）模型在处理各种真实世界的对比度失真时，评估准确性不足。

Method: 定制并微调了EfficientNet B0、ResNet18和MobileNetV2三个预训练模型，并构建了一个基于Siamese网络的模型，所有模型都添加了对比度感知回归头，并使用数据增强在CID2013和CCID2014数据集上进行端到端训练。

Result: 定制的EfficientNet B0模型在CCID2014数据集上达到了PLCC = 0.9286和SRCC = 0.9178，在CID2013数据集上达到了PLCC = 0.9581和SRCC = 0.9369，超越了传统方法和其他深度基线模型。

Conclusion: 所提出的方法表明，对轻量级预训练网络进行对比度感知适应，可以为无参考对比度质量评估提供高性能、可扩展的解决方案，适用于实时和资源受限的应用。

Abstract: Image contrast was a fundamental factor in visual perception and played a
vital role in overall image quality. However, most no reference image quality
assessment NR IQA models struggled to accurately evaluate contrast distortions
under diverse real world conditions. In this study, we proposed a deep learning
based framework for blind contrast quality assessment by customizing and
fine-tuning three pre trained architectures, EfficientNet B0, ResNet18, and
MobileNetV2, for perceptual Mean Opinion Score, along with an additional model
built on a Siamese network, which indicated a limited ability to capture
perceptual contrast distortions. Each model is modified with a contrast-aware
regression head and trained end to end using targeted data augmentations on two
benchmark datasets, CID2013 and CCID2014, containing synthetic and authentic
contrast distortions. Performance is evaluated using Pearson Linear Correlation
Coefficient and Spearman Rank Order Correlation Coefficient, which assess the
alignment between predicted and human rated scores. Among these three models,
our customized EfficientNet B0 model achieved state-of-the-art performance with
PLCC = 0.9286 and SRCC = 0.9178 on CCID2014 and PLCC = 0.9581 and SRCC = 0.9369
on CID2013, surpassing traditional methods and outperforming other deep
baselines. These results highlighted the models robustness and effectiveness in
capturing perceptual contrast distortion. Overall, the proposed method
demonstrated that contrast aware adaptation of lightweight pre trained networks
can yield a high performing, scalable solution for no reference contrast
quality assessment suitable for real time and resource constrained
applications.

</details>


### [87] [Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning](https://arxiv.org/abs/2509.21976)
*Zilun Zhang,Zian Guan,Tiancheng Zhao,Haozhan Shen,Tianyu Li,Yuxiang Cai,Zhonggen Su,Zhaojun Liu,Jianwei Yin,Xiang Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Referring expression understanding in remote sensing poses unique challenges,
as it requires reasoning over complex object-context relationships. While
supervised fine-tuning (SFT) on multimodal large language models achieves
strong performance with massive labeled datasets, they struggle in data-scarce
scenarios, leading to poor generalization. To address this limitation, we
propose Geo-R1, a reasoning-centric reinforcement fine-tuning (RFT) paradigm
for few-shot geospatial referring. Geo-R1 enforces the model to first generate
explicit, interpretable reasoning chains that decompose referring expressions,
and then leverage these rationales to localize target objects. This "reason
first, then act" process enables the model to make more effective use of
limited annotations, enhances generalization, and provides interpretability. We
validate Geo-R1 on three carefully designed few-shot geospatial referring
benchmarks, where our model consistently and substantially outperforms SFT
baselines. It also demonstrates strong cross-dataset generalization,
highlighting its robustness. Code and data will be released at
http://geo-r1.github.io.

</details>


### [88] [Benchmarking and Mitigate Psychological Sycophancy in Medical Vision-Language Models](https://arxiv.org/abs/2509.21979)
*Zikun Guo,Xinyue Xu,Pei Xiang,Shu Yang,Xin Han,Di Wang,Lijie Hu*

Main category: cs.CV

TL;DR: 本研究评估了医学视觉问答中的临床谄媚行为，提出了一种新的基于临床的基准和名为VIPER的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 临床工作流程中日益集成的视觉语言模型（VLM）常常表现出优先考虑用户措辞、社会线索或感知权威而非基于证据的推理的谄媚行为。

Method: 构建了一个包含PathVQA、SLAKE和VQA-RAD数据的医学谄媚数据集，并进行了包含各种谄媚类型和心理压力模板的对抗性实验。提出了一种名为VIPER（Visual Information Purification for Evidence based Response）的缓解策略。

Result: 研究发现，VLM普遍容易受到谄媚攻击，模仿和专家提供的修正被证明是最有效的触发因素，表明模型存在独立于视觉证据的偏见机制。VIPER框架通过过滤非证据性内容并生成以证据为先的答案，平均可将谄媚行为减少X%，优于基线方法，同时保持了可解释性。

Conclusion: 提出的基准和缓解框架为医学VLM在真实临床医生互动中的稳健部署奠定了基础，强调了需要基于证据的防御措施。

Abstract: Vision language models(VLMs) are increasingly integrated into clinical
workflows, but they often exhibit sycophantic behavior prioritizing alignment
with user phrasing social cues or perceived authority over evidence based
reasoning. This study evaluate clinical sycophancy in medical visual question
answering through a novel clinically grounded benchmark. We propose a medical
sycophancy dataset construct from PathVQA, SLAKE, and VQA-RAD stratified by
different type organ system and modality. Using psychologically motivated
pressure templates including various sycophancy. In our adversarial experiments
on various VLMs, we found that these models are generally vulnerable,
exhibiting significant variations in the occurrence of adversarial responses,
with weak correlations to the model accuracy or size. Imitation and expert
provided corrections were found to be the most effective triggers, suggesting
that the models possess a bias mechanism independent of visual evidence. To
address this, we propose Visual Information Purification for Evidence based
Response (VIPER) a lightweight mitigation strategy that filters non evidentiary
content for example social pressures and then generates constrained evidence
first answers. This framework reduces sycophancy by an average amount
outperforming baselines while maintaining interpretability. Our benchmark
analysis and mitigation framework lay the groundwork for robust deployment of
medical VLMs in real world clinician interactions emphasizing the need for
evidence anchored defenses.

</details>


### [89] [Resolving Ambiguity in Gaze-Facilitated Visual Assistant Interaction Paradigm](https://arxiv.org/abs/2509.21980)
*Zeyu Wang,Baiyu Chen,Kun Yan,Hongjing Piao,Hao Xue,Flora D. Salim,Yuanchun Shi,Yuntao Wang*

Main category: cs.CV

TL;DR: GLARIFY利用时空注视信息来增强视觉语言模型(VLMs)在现实世界应用中的有效性，通过引入自动数据合成和热图模块来解决语音和注视数据中的歧义和噪声问题，并在实验中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 由于智能眼镜的普及，用户注视已被整合到视觉语言模型(VLMs)中，以简化日常场景中的多模态查询。然而，利用注视数据对用户注意力进行建模可能会带来歧义挑战，包括用户口头问题中的歧义以及人类注视模式的噪声和复杂的时空关系。以往的研究未能捕捉用户注意力的动态性。

Method: GLARIFY首先分析了带有注视模式的用户查询样本，以证明用户注视的噪声特性。然后，利用GPT-4o设计了一个自动数据合成流程，生成GLARIFY-Ambi数据集，该数据集包含一个专门的思维链(CoT)过程来处理噪声注视模式。最后，设计了一个热图模块，在保留预训练知识的同时将注视信息融入先进的VLMs。

Result: GLARIFY使用一个独立的测试集进行评估。实验表明，GLARIFY显著优于基线模型，有效地将VLMs与人类注意力对齐。

Conclusion: GLARIFY通过鲁棒地将VLMs与人类注意力对齐，为实现可用且直观的视觉助手交互范式铺平了道路。

Abstract: With the rise in popularity of smart glasses, users' attention has been
integrated into Vision-Language Models (VLMs) to streamline multi-modal
querying in daily scenarios. However, leveraging gaze data to model users'
attention may introduce ambiguity challenges: (1) users' verbal questions
become ambiguous by using pronouns or skipping context, (2) humans' gaze
patterns can be noisy and exhibit complex spatiotemporal relationships with
their spoken questions. Previous works only consider single image as visual
modality input, failing to capture the dynamic nature of the user's attention.
In this work, we introduce GLARIFY, a novel method to leverage spatiotemporal
gaze information to enhance the model's effectiveness in real-world
applications. Initially, we analyzed hundreds of querying samples with the gaze
modality to demonstrate the noisy nature of users' gaze patterns. We then
utilized GPT-4o to design an automatic data synthesis pipeline to generate the
GLARIFY-Ambi dataset, which includes a dedicated chain-of-thought (CoT) process
to handle noisy gaze patterns. Finally, we designed a heatmap module to
incorporate gaze information into cutting-edge VLMs while preserving their
pretrained knowledge. We evaluated GLARIFY using a hold-out test set.
Experiments demonstrate that GLARIFY significantly outperforms baselines. By
robustly aligning VLMs with human attention, GLARIFY paves the way for a usable
and intuitive interaction paradigm with a visual assistant.

</details>


### [90] [From Bias to Balance: Exploring and Mitigating Spatial Bias in LVLMs](https://arxiv.org/abs/2509.21984)
*Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Weili Guan,Jun Yu,Min Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable success across
a wide range of multimodal tasks, yet their robustness to spatial variations
remains insufficiently understood. In this work, we present a systematic study
of the spatial bias of LVLMs, focusing on how models respond when identical key
visual information is placed at different locations within an image. Through a
carefully designed probing dataset, we demonstrate that current LVLMs often
produce inconsistent outputs under such spatial shifts, revealing a fundamental
limitation in their spatial-semantic understanding. Further analysis shows that
this phenomenon originates not from the vision encoder, which reliably
perceives and interprets visual content across positions, but from the
unbalanced design of position embeddings in the language model component. In
particular, the widely adopted position embedding strategies, such as RoPE,
introduce imbalance during cross-modal interaction, leading image tokens at
different positions to exert unequal influence on semantic understanding. To
mitigate this issue, we introduce Balanced Position Assignment (BaPA), a simple
yet effective mechanism that assigns identical position embeddings to all image
tokens, promoting a more balanced integration of visual information. Extensive
experiments show that BaPA enhances the spatial robustness of LVLMs without
retraining and further boosts their performance across diverse multimodal
benchmarks when combined with lightweight fine-tuning. Further analysis of
information flow reveals that BaPA yields balanced attention, enabling more
holistic visual understanding.

</details>


### [91] [Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation](https://arxiv.org/abs/2509.21989)
*Abdelrahman Eldesokey,Aleksandar Cvejic,Bernard Ghanem,Peter Wonka*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a novel approach for disentangling visual and semantic features
from the backbones of pre-trained diffusion models, enabling visual
correspondence in a manner analogous to the well-established semantic
correspondence. While diffusion model backbones are known to encode
semantically rich features, they must also contain visual features to support
their image synthesis capabilities. However, isolating these visual features is
challenging due to the absence of annotated datasets. To address this, we
introduce an automated pipeline that constructs image pairs with annotated
semantic and visual correspondences based on existing subject-driven image
generation datasets, and design a contrastive architecture to separate the two
feature types. Leveraging the disentangled representations, we propose a new
metric, Visual Semantic Matching (VSM), that quantifies visual inconsistencies
in subject-driven image generation. Empirical results show that our approach
outperforms global feature-based metrics such as CLIP, DINO, and
vision--language models in quantifying visual inconsistencies while also
enabling spatial localization of inconsistent regions. To our knowledge, this
is the first method that supports both quantification and localization of
inconsistencies in subject-driven generation, offering a valuable tool for
advancing this task. Project
Page:https://abdo-eldesokey.github.io/mind-the-glitch/

</details>


### [92] [WAVE: Learning Unified & Versatile Audio-Visual Embeddings with Multimodal LLM](https://arxiv.org/abs/2509.21990)
*Changli Tang,Qinfan Xiao,Ke Mei,Tianyi Wang,Fengyun Rao,Chao Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While embeddings from multimodal large language models (LLMs) excel as
general-purpose representations, their application to dynamic modalities like
audio and video remains underexplored. We introduce WAVE (\textbf{u}nified \&
\textbf{v}ersatile \textbf{a}udio-\textbf{v}isual \textbf{e}mbeddings), the
first LLM-based embedding that creates a unified representation space for text,
audio, and video modalities. WAVE employs a novel hierarchical feature fusion
strategy and a joint multi-modal, multi-task training approach to enable two
key capabilities: any-to-any cross-modal retrieval and the generation of
prompt-aware embeddings tailored to user instructions. Experimentally, WAVE
sets a new state-of-the-art on the MMEB-v2 video benchmark and achieves
superior results in audio and video-to-audio retrieval. Its prompt-aware nature
also yields remarkable performance in multimodal question answering,
significantly outperforming existing embedding models. Ablation studies
validate our joint training strategy, demonstrating improved performance across
all modalities. With a newly introduced benchmark for versatile audio-visual
learning, WAVE opens up broad possibilities for cross-modal, any-to-any
applications. Our code, checkpoints, and data will be released.

</details>


### [93] [ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models](https://arxiv.org/abs/2509.21991)
*Jewon Lee,Wooksu Shin,Seungmin Yang,Ki-Ung Song,DongUk Lim,Jaeyeon Kim,Tae-Ho Kim,Bo-Kyeong Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Efficient processing of high-resolution images is crucial for real-world
vision-language applications. However, existing Large Vision-Language Models
(LVLMs) incur substantial computational overhead due to the large number of
vision tokens. With the advent of "thinking with images" models, reasoning now
extends beyond text to the visual domain. This capability motivates our
two-stage "coarse-to-fine" reasoning pipeline: first, a downsampled image is
analyzed to identify task-relevant regions; then, only these regions are
cropped at full resolution and processed in a subsequent reasoning stage. This
approach reduces computational cost while preserving fine-grained visual
details where necessary. A major challenge lies in inferring which regions are
truly relevant to a given query. Recent related methods often fail in the first
stage after input-image downsampling, due to perception-driven reasoning, where
clear visual information is required for effective reasoning. To address this
issue, we propose ERGO (Efficient Reasoning & Guided Observation) that performs
reasoning-driven perception-leveraging multimodal context to determine where to
focus. Our model can account for perceptual uncertainty, expanding the cropped
region to cover visually ambiguous areas for answering questions. To this end,
we develop simple yet effective reward components in a reinforcement learning
framework for coarse-to-fine perception. Across multiple datasets, our approach
delivers higher accuracy than the original model and competitive methods, with
greater efficiency. For instance, ERGO surpasses Qwen2.5-VL-7B on the V*
benchmark by 4.7 points while using only 23% of the vision tokens, achieving a
3x inference speedup. The code and models can be found at:
https://github.com/nota-github/ERGO.

</details>


### [94] [DualFocus: Depth from Focus with Spatio-Focal Dual Variational Constraints](https://arxiv.org/abs/2509.21992)
*Sungmin Woo,Sangyoun Lee*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Depth-from-Focus (DFF) enables precise depth estimation by analyzing focus
cues across a stack of images captured at varying focal lengths. While recent
learning-based approaches have advanced this field, they often struggle in
complex scenes with fine textures or abrupt depth changes, where focus cues may
become ambiguous or misleading. We present DualFocus, a novel DFF framework
that leverages the focal stack's unique gradient patterns induced by focus
variation, jointly modeling focus changes over spatial and focal dimensions.
Our approach introduces a variational formulation with dual constraints
tailored to DFF: spatial constraints exploit gradient pattern changes across
focus levels to distinguish true depth edges from texture artifacts, while
focal constraints enforce unimodal, monotonic focus probabilities aligned with
physical focus behavior. These inductive biases improve robustness and accuracy
in challenging regions. Comprehensive experiments on four public datasets
demonstrate that DualFocus consistently outperforms state-of-the-art methods in
both depth accuracy and perceptual quality.

</details>


### [95] [Rate-Distortion Optimized Communication for Collaborative Perception](https://arxiv.org/abs/2509.21994)
*Genjia Liu,Anning Hu,Yue Hu,Wenjun Zhang,Siheng Chen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Collaborative perception emphasizes enhancing environmental understanding by
enabling multiple agents to share visual information with limited bandwidth
resources. While prior work has explored the empirical trade-off between task
performance and communication volume, a significant gap remains in the
theoretical foundation. To fill this gap, we draw on information theory and
introduce a pragmatic rate-distortion theory for multi-agent collaboration,
specifically formulated to analyze performance-communication trade-off in
goal-oriented multi-agent systems. This theory concretizes two key conditions
for designing optimal communication strategies: supplying pragmatically
relevant information and transmitting redundancy-less messages. Guided by these
two conditions, we propose RDcomm, a communication-efficient collaborative
perception framework that introduces two key innovations: i) task entropy
discrete coding, which assigns features with task-relevant codeword-lengths to
maximize the efficiency in supplying pragmatic information; ii)
mutual-information-driven message selection, which utilizes mutual information
neural estimation to approach the optimal redundancy-less condition.
Experiments on 3D object detection and BEV segmentation demonstrate that RDcomm
achieves state-of-the-art accuracy on DAIR-V2X and OPV2V, while reducing
communication volume by up to 108 times. The code will be released.

</details>


### [96] [FailureAtlas:Mapping the Failure Landscape of T2I Models via Active Exploration](https://arxiv.org/abs/2509.21995)
*Muxi Chen,Zhaohua Zhang,Chenchen Zhao,Mingyang Chen,Wenyu Jiang,Tianwen Jiang,Jianhuan Zhuo,Yu Tang,Qiuyong Xiao,Jihong Zhang,Qiang Xu*

Main category: cs.CV

TL;DR: FailureAtlas是一个用于大规模探索和映射文本到图像（T2I）模型失败情况的框架，通过结构化搜索最小的、导致失败的概念来发现错误，并利用加速技术解决计算爆炸问题。该框架在Stable Diffusion模型上发现了大量先前未知的错误切片，并将这些失败与训练数据中的数据稀疏性联系起来，为开发更鲁棒的生成式AI提供了新的诊断方法。


<details>
  <summary>Details</summary>
Motivation: 传统的静态基准测试在揭示T2I模型的系统性失败和定位根本原因方面能力有限，因此需要一种主动探索的方法来全面诊断模型。 FailureAtlas旨在通过主动探索来弥补这一不足。

Method: FailureAtlas将错误发现构建为一种结构化搜索，寻找最小的、能够触发失败的概念。它采用了新颖的加速技术来解决计算密集型问题，使其能够大规模运行。

Result: 在Stable Diffusion模型上应用FailureAtlas，发现了超过247,000个SD1.5中的错误切片，揭示了大量先前未知的失败情况。研究首次提供了大规模证据，将这些失败与训练数据中的数据稀疏性相关联。

Conclusion: FailureAtlas提供了一个原则性且可扩展的引擎，用于深入的模型审计，建立了一种以诊断为先的新方法论，以指导更鲁棒的生成式AI的开发。

Abstract: Static benchmarks have provided a valuable foundation for comparing
Text-to-Image (T2I) models. However, their passive design offers limited
diagnostic power, struggling to uncover the full landscape of systematic
failures or isolate their root causes. We argue for a complementary paradigm:
active exploration. We introduce FailureAtlas, the first framework designed to
autonomously explore and map the vast failure landscape of T2I models at scale.
FailureAtlas frames error discovery as a structured search for minimal,
failure-inducing concepts. While it is a computationally explosive problem, we
make it tractable with novel acceleration techniques. When applied to Stable
Diffusion models, our method uncovers hundreds of thousands of previously
unknown error slices (over 247,000 in SD1.5 alone) and provides the first
large-scale evidence linking these failures to data scarcity in the training
set. By providing a principled and scalable engine for deep model auditing,
FailureAtlas establishes a new, diagnostic-first methodology to guide the
development of more robust generative AI. The code is available at
https://github.com/cure-lab/FailureAtlas

</details>


### [97] [Exposing Hallucinations To Suppress Them: VLMs Representation Editing With Generative Anchors](https://arxiv.org/abs/2509.21997)
*Youxu Shi,Suorong Yang,Dong Liu*

Main category: cs.CV

TL;DR: 一种训练免费、自我监督的方法，通过利用文本到图像模型生成的负锚定来减少多模态大语言模型的幻觉，同时保留信息丰富度。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理视觉-语言任务时容易出现幻觉，并且现有的缓解方法需要额外的微调、手工先验知识或在信息量和可扩展性之间进行权衡。

Method: 提出了一种新颖的幻觉放大机制：通过文本到图像模型将字幕投射到视觉空间以揭示隐含的幻觉信号，作为负锚定；原始图像提供正锚定。利用这两个锚定，通过将表示拉向忠实语义并推离幻觉方向来编辑解码器隐藏状态。此过程无需人工先验知识或额外的训练成本。

Result: 在多个基准测试中，该方法显著减少了对象、属性和关系级别的幻觉，同时在很大程度上保留了召回率和字幕丰富度。在 LLaVA-v1.5-7B 上，CHAIR 基准测试的幻觉减少了 5% 以上。该方法在 LLaVA-NEXT-7B、Cambrian-8B 和 InstructBLIP-7B 等不同架构上表现出良好的泛化能力。此外，当应用于无幻觉字幕时，该方法几乎没有副作用。

Conclusion: 所提出的训练免费、自我监督的方法能够有效且高效地减少多模态大语言模型的幻觉，同时保持字幕的丰富度和信息量，并具有良好的跨架构泛化能力和实际应用性。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable success
across diverse vision-language tasks, yet they remain highly susceptible to
hallucinations, producing content that is fluent but inconsistent with visual
evidence. Such hallucinations, spanning objects, attributes, and relations,
persist even in larger models, while existing mitigation approaches often
require additional finetuning, handcrafted priors, or trade-offs that
compromise informativeness and scalability. To address this limitation, we
propose a training-free, self-supervised method for hallucination mitigation.
Our approach introduces a novel hallucination amplification mechanism: a
caption is projected into the visual space via a text-to-image model to reveal
implicit hallucination signals, serving as a negative anchor, while the
original image provides a positive anchor. Leveraging these dual anchors, we
edit decoder hidden states by pulling representations toward faithful semantics
and pushing them away from hallucination directions. This correction requires
no human priors or additional training costs, ensuring both effectiveness and
efficiency. Extensive experiments across multiple benchmarks show that our
method significantly reduces hallucinations at the object, attribute, and
relation levels while largely preserving recall and caption richness, e.g.,
achieving a hallucination reduction by over 5% using LLaVA-v1.5-7B on CHAIR.
Furthermore, results on diverse architectures, including LLaVA-NEXT-7B,
Cambrian-8B, and InstructBLIP-7B, validate strong cross-architecture
generalization. More importantly, when applied to hallucination-free captions,
our method introduces almost no side effects, underscoring its robustness and
practical plug-and-play applicability. The implementation will be publicly
available.

</details>


### [98] [CoFFT: Chain of Foresight-Focus Thought for Visual Language Models](https://arxiv.org/abs/2509.22010)
*Xinyu Zhang,Yuxuan Dong,Lingling Zhang,Chengyou Jia,Zhuohang Dang,Basura Fernando,Jun Liu,Mike Zheng Shou*

Main category: cs.CV

TL;DR: CoFFT是一种新的训练免费方法，通过模仿人类视觉认知来增强视觉语言模型（VLMs）的视觉推理能力。它通过生成样本、评估样本并调整视觉焦点来解决VLM在处理复杂视觉输入时遇到的问题，从而提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）取得了显著进展，但它们在处理复杂且冗余的视觉输入时仍受到限制，容易受到干扰，导致不必要的推理或产生幻觉。这是因为它们无法精确地发现和处理推理所需的区域。

Method: CoFFT通过三个阶段迭代进行：1. 多样化样本生成：生成包含多个推理步骤的样本，以探索潜在的推理路径。2. 双重前视解码：根据视觉焦点和推理过程评估样本，并将最优样本的第一步加入推理过程。3. 视觉焦点调整：在返回第一阶段之前，精确地将视觉焦点调整到对未来推理最有益的区域。

Result: 在Qwen2.5-VL、InternVL-2.5和Llava-Next等模型上进行的多项基准测试表明，CoFFT在可控的计算开销增加的情况下，性能一致提高了3.1-5.8%。

Conclusion: CoFFT通过模仿人类视觉认知，提出了一种创新的训练免费方法，通过迭代的“前视-关注”思维过程，显著提高了VLMs在处理复杂视觉信息时的推理能力和准确性。

Abstract: Despite significant advances in Vision Language Models (VLMs), they remain
constrained by the complexity and redundancy of visual input. When images
contain large amounts of irrelevant information, VLMs are susceptible to
interference, thus generating excessive task-irrelevant reasoning processes or
even hallucinations. This limitation stems from their inability to discover and
process the required regions during reasoning precisely. To address this
limitation, we present the Chain of Foresight-Focus Thought (CoFFT), a novel
training-free approach that enhances VLMs' visual reasoning by emulating human
visual cognition. Each Foresight-Focus Thought consists of three stages: (1)
Diverse Sample Generation: generates diverse reasoning samples to explore
potential reasoning paths, where each sample contains several reasoning steps;
(2) Dual Foresight Decoding: rigorously evaluates these samples based on both
visual focus and reasoning progression, adding the first step of optimal sample
to the reasoning process; (3) Visual Focus Adjustment: precisely adjust visual
focus toward regions most beneficial for future reasoning, before returning to
stage (1) to generate subsequent reasoning samples until reaching the final
answer. These stages function iteratively, creating an interdependent cycle
where reasoning guides visual focus and visual focus informs subsequent
reasoning. Empirical results across multiple benchmarks using Qwen2.5-VL,
InternVL-2.5, and Llava-Next demonstrate consistent performance improvements of
3.1-5.8\% with controllable increasing computational overhead.

</details>


### [99] [EgoInstruct: An Egocentric Video Dataset of Face-to-face Instructional Interactions with Multi-modal LLM Benchmarking](https://arxiv.org/abs/2509.22019)
*Yuki Sakai,Ryosuke Furuta,Juichun Yen,Yoichi Sato*

Main category: cs.CV

TL;DR: 本研究提出了一个用于分析面对面教学场景的新数据集，并评估了多模态大语言模型（MLLMs）在该场景下的理解能力，结果表明MLLMs在无需任务特定微调的情况下表现优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 分析教师和学习者在同一物理空间中的教学互动对于教育支持和技能转移至关重要，但此类面对面教学场景尚未得到计算机视觉领域的系统研究，这主要是由于缺乏合适的数据集和分析技术。

Method: 创建了一个新的面对面教学的单视角视频数据集，并为程序步骤分割和对话状态分类这两个基本任务提供了地面真实标注。利用该数据集，对多模态大语言模型（MLLMs）和传统的特定任务模型进行了基准测试和评估，重点关注了模型处理口语和非口语交流的整合能力。

Result: 在实验中，多模态大语言模型（MLLMs）在无需任务特定微调的情况下，其表现优于专门的基线模型，表明其在全面理解教学互动方面具有潜力。

Conclusion: 本研究通过提供新的数据集和基准测试，为计算机视觉领域系统研究面对面教学互动奠定了基础，并证明了多模态大语言模型在理解此类复杂场景方面的优越性。

Abstract: Analyzing instructional interactions between an instructor and a learner who
are co-present in the same physical space is a critical problem for educational
support and skill transfer. Yet such face-to-face instructional scenes have not
been systematically studied in computer vision. We identify two key reasons: i)
the lack of suitable datasets and ii) limited analytical techniques. To address
this gap, we present a new egocentric video dataset of face-to-face instruction
and provide ground-truth annotations for two fundamental tasks that serve as a
first step toward a comprehensive understanding of instructional interactions:
procedural step segmentation and conversation-state classification. Using this
dataset, we benchmark multimodal large language models (MLLMs) against
conventional task-specific models. Since face-to-face instruction involves
multiple modalities (speech content and prosody, gaze and body motion, and
visual context), effective understanding requires methods that handle verbal
and nonverbal communication in an integrated manner. Accordingly, we evaluate
recently introduced MLLMs that jointly process images, audio, and text. This
evaluation quantifies the extent to which current machine learning models
understand face-to-face instructional scenes. In experiments, MLLMs outperform
specialized baselines even without task-specific fine-tuning, suggesting their
promise for holistic understanding of instructional interactions.

</details>


### [100] [High-Quality Sound Separation Across Diverse Categories via Visually-Guided Generative Modeling](https://arxiv.org/abs/2509.22063)
*Chao Huang,Susan Liang,Yapeng Tian,Anurag Kumar,Chenliang Xu*

Main category: cs.CV

TL;DR: DAVIS是一个基于扩散模型的音视频分离框架，利用生成模型直接合成分离后的音频频谱图，解决了传统方法在处理复杂数据分布时的局限性，并在AVE和MUSIC数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有音频分离方法多采用基于掩码的回归方法，在处理复杂数据分布以实现高质量分离时存在局限。DAVIS旨在通过生成模型克服这些挑战。

Method: DAVIS框架利用去噪扩散概率模型（DDPM）和流匹配（FM）这两种生成模型，并结合专门的U-Net架构。它直接从噪声分布合成所需的分离声谱图，并同时依赖混合音频输入和相关的视觉信息进行条件约束。

Result: DAVIS的DDPM和Flow Matching变体在AVE和MUSIC数据集上的评估结果均优于现有的领先方法，证明了其在音视频分离任务中的有效性。

Conclusion: DAVIS框架通过其生成方法，在音视频分离任务中展现出强大的能力，能够生成高质量的分离音频，尤其是在处理多样化的声音类别时。

Abstract: We propose DAVIS, a Diffusion-based Audio-VIsual Separation framework that
solves the audio-visual sound source separation task through generative
learning. Existing methods typically frame sound separation as a mask-based
regression problem, achieving significant progress. However, they face
limitations in capturing the complex data distribution required for
high-quality separation of sounds from diverse categories. In contrast, DAVIS
circumvents these issues by leveraging potent generative modeling paradigms,
specifically Denoising Diffusion Probabilistic Models (DDPM) and the more
recent Flow Matching (FM), integrated within a specialized Separation U-Net
architecture. Our framework operates by synthesizing the desired separated
sound spectrograms directly from a noise distribution, conditioned concurrently
on the mixed audio input and associated visual information. The inherent nature
of its generative objective makes DAVIS particularly adept at producing
high-quality sound separations for diverse sound categories. We present
comparative evaluations of DAVIS, encompassing both its DDPM and Flow Matching
variants, against leading methods on the standard AVE and MUSIC datasets. The
results affirm that both variants surpass existing approaches in separation
quality, highlighting the efficacy of our generative framework for tackling the
audio-visual source separation task.

</details>


### [101] [SpecXNet: A Dual-Domain Convolutional Network for Robust Deepfake Detection](https://arxiv.org/abs/2509.22070)
*Inzamamul Alam,Md Tanvir Islam,Simon S. Woo*

Main category: cs.CV

TL;DR: SpecXNet是一种新的双域网络，通过结合空间和频域特征来提高深度伪造检测的鲁棒性和泛化能力，在多个基准测试中达到了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 由于GAN和扩散模型生成内容的日益真实，深度伪造检测变得更具挑战性。现有方法仅关注空间或频域特征，泛化能力有限。

Method: 提出了一种名为SpecXNet的双域架构，其核心是双域特征耦合器（DDFC），它将特征分解为用于捕获纹理异常的空间分支和利用快速傅里叶变换模拟周期性不一致的全局谱分支。还引入了双傅里叶注意力（DFA）模块，以内容感知的方式融合空间和谱特征。SpecXNet构建在修改后的XceptionNet骨干网络之上，并将DDFC和DFA模块嵌入到可分离卷积块中。

Result: 在多个深度伪造基准测试上的大量实验表明，SpecXNet在最先进的准确率方面表现出色，特别是在跨数据集和未见过的操纵场景下，同时保持了实时可行性。

Conclusion: 统一的空间-谱学习对于鲁棒和可泛化的深度伪造检测非常有效。

Abstract: The increasing realism of content generated by GANs and diffusion models has
made deepfake detection significantly more challenging. Existing approaches
often focus solely on spatial or frequency-domain features, limiting their
generalization to unseen manipulations. We propose the Spectral
Cross-Attentional Network (SpecXNet), a dual-domain architecture for robust
deepfake detection. The core \textbf{Dual-Domain Feature Coupler (DDFC)}
decomposes features into a local spatial branch for capturing texture-level
anomalies and a global spectral branch that employs Fast Fourier Transform to
model periodic inconsistencies. This dual-domain formulation allows SpecXNet to
jointly exploit localized detail and global structural coherence, which are
critical for distinguishing authentic from manipulated images. We also
introduce the \textbf{Dual Fourier Attention (DFA)} module, which dynamically
fuses spatial and spectral features in a content-aware manner. Built atop a
modified XceptionNet backbone, we embed the DDFC and DFA modules within a
separable convolution block. Extensive experiments on multiple deepfake
benchmarks show that SpecXNet achieves state-of-the-art accuracy, particularly
under cross-dataset and unseen manipulation scenarios, while maintaining
real-time feasibility. Our results highlight the effectiveness of unified
spatial-spectral learning for robust and generalizable deepfake detection. To
ensure reproducibility, we released the full code on
\href{https://github.com/inzamamulDU/SpecXNet}{\textcolor{blue}{\textbf{GitHub}}}.

</details>


### [102] [Large Material Gaussian Model for Relightable 3D Generation](https://arxiv.org/abs/2509.22112)
*Jingrui Ye,Lingting Zhu,Runze Zhang,Zeyu Hu,Yingda Yin,Lanjiong Li,Lequan Yu,Qingmin Liao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The increasing demand for 3D assets across various industries necessitates
efficient and automated methods for 3D content creation. Leveraging 3D Gaussian
Splatting, recent large reconstruction models (LRMs) have demonstrated the
ability to efficiently achieve high-quality 3D rendering by integrating
multiview diffusion for generation and scalable transformers for
reconstruction. However, existing models fail to produce the material
properties of assets, which is crucial for realistic rendering in diverse
lighting environments. In this paper, we introduce the Large Material Gaussian
Model (MGM), a novel framework designed to generate high-quality 3D content
with Physically Based Rendering (PBR) materials, ie, albedo, roughness, and
metallic properties, rather than merely producing RGB textures with
uncontrolled light baking. Specifically, we first fine-tune a new multiview
material diffusion model conditioned on input depth and normal maps. Utilizing
the generated multiview PBR images, we explore a Gaussian material
representation that not only aligns with 2D Gaussian Splatting but also models
each channel of the PBR materials. The reconstructed point clouds can then be
rendered to acquire PBR attributes, enabling dynamic relighting by applying
various ambient light maps. Extensive experiments demonstrate that the
materials produced by our method not only exhibit greater visual appeal
compared to baseline methods but also enhance material modeling, thereby
enabling practical downstream rendering applications.

</details>


### [103] [Self-Supervised Point Cloud Completion based on Multi-View Augmentations of Single Partial Point Cloud](https://arxiv.org/abs/2509.22132)
*Jingjing Lu,Huilong Pi,Yunchuan Qin,Zhuo Tang,Ruihui Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Point cloud completion aims to reconstruct complete shapes from partial
observations. Although current methods have achieved remarkable performance,
they still have some limitations: Supervised methods heavily rely on ground
truth, which limits their generalization to real-world datasets due to the
synthetic-to-real domain gap. Unsupervised methods require complete point
clouds to compose unpaired training data, and weakly-supervised methods need
multi-view observations of the object. Existing self-supervised methods
frequently produce unsatisfactory predictions due to the limited capabilities
of their self-supervised signals. To overcome these challenges, we propose a
novel self-supervised point cloud completion method. We design a set of novel
self-supervised signals based on multi-view augmentations of the single partial
point cloud. Additionally, to enhance the model's learning ability, we first
incorporate Mamba into self-supervised point cloud completion task, encouraging
the model to generate point clouds with better quality. Experiments on
synthetic and real-world datasets demonstrate that our method achieves
state-of-the-art results.

</details>


### [104] [REFINE-CONTROL: A Semi-supervised Distillation Method For Conditional Image Generation](https://arxiv.org/abs/2509.22139)
*Yicheng Jiang,Jin Yuan,Hua Yuan,Yao Zhang,Yong Rui*

Main category: cs.CV

TL;DR: Refine-Control是一个半监督蒸馏框架，通过三级知识融合和利用标记/未标记数据来提高学生模型的性能，从而在降低计算成本和延迟的同时保持高质量的图像生成能力和可控性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有条件图像生成模型资源需求高、标注数据稀缺的问题，以及由此带来的高昂成本和隐私问题，本研究提出了Refine-Control。

Method: 本研究提出了一种名为Refine-Control的半监督蒸馏框架。具体而言，通过引入三级知识融合损失来转移不同级别的知识，以提高学生模型的性能。同时，采用一种利用标记和未标记数据的半监督蒸馏方法，以增强泛化能力并缓解数据集稀缺问题。

Result: 实验结果表明，Refine-Control在计算成本和延迟方面实现了显著降低，同时保持了高保真度的生成能力和可控性，并通过比较指标进行了量化。

Conclusion: Refine-Control成功地在降低计算成本和延迟的同时，保持了高质量的图像生成能力和可控性，解决了资源需求高、数据稀缺等问题，适用于边缘设备部署。

Abstract: Conditional image generation models have achieved remarkable results by
leveraging text-based control to generate customized images. However, the high
resource demands of these models and the scarcity of well-annotated data have
hindered their deployment on edge devices, leading to enormous costs and
privacy concerns, especially when user data is sent to a third party. To
overcome these challenges, we propose Refine-Control, a semi-supervised
distillation framework. Specifically, we improve the performance of the student
model by introducing a tri-level knowledge fusion loss to transfer different
levels of knowledge. To enhance generalization and alleviate dataset scarcity,
we introduce a semi-supervised distillation method utilizing both labeled and
unlabeled data. Our experiments reveal that Refine-Control achieves significant
reductions in computational cost and latency, while maintaining high-fidelity
generation capabilities and controllability, as quantified by comparative
metrics.

</details>


### [105] [Joint graph entropy knowledge distillation for point cloud classification and robustness against corruptions](https://arxiv.org/abs/2509.22150)
*Zhiqiang Tian,Weigang Li,Junwei Hu,Chunhua Deng*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Classification tasks in 3D point clouds often assume that class events
\replaced{are }{follow }independent and identically distributed (IID), although
this assumption destroys the correlation between classes. This \replaced{study
}{paper }proposes a classification strategy, \textbf{J}oint \textbf{G}raph
\textbf{E}ntropy \textbf{K}nowledge \textbf{D}istillation (JGEKD), suitable for
non-independent and identically distributed 3D point cloud data,
\replaced{which }{the strategy } achieves knowledge transfer of class
correlations through knowledge distillation by constructing a loss function
based on joint graph entropy. First\deleted{ly}, we employ joint graphs to
capture add{the }hidden relationships between classes\replaced{ and}{,}
implement knowledge distillation to train our model by calculating the entropy
of add{add }graph.\replaced{ Subsequently}{ Then}, to handle 3D point clouds
\deleted{that is }invariant to spatial transformations, we construct
\replaced{S}{s}iamese structures and develop two frameworks, self-knowledge
distillation and teacher-knowledge distillation, to facilitate information
transfer between different transformation forms of the same data. \replaced{In
addition}{ Additionally}, we use the above framework to achieve knowledge
transfer between point clouds and their corrupted forms, and increase the
robustness against corruption of model. Extensive experiments on ScanObject,
ModelNet40, ScanntV2\_cls and ModelNet-C demonstrate that the proposed strategy
can achieve competitive results.

</details>


### [106] [MultiMat: Multimodal Program Synthesis for Procedural Materials using Large Multimodal Models](https://arxiv.org/abs/2509.22151)
*Jonas Belouadi,Tamy Boubekeur,Adrien Kaiser*

Main category: cs.CV

TL;DR: MultiMat是一个多模态程序合成框架，利用视觉和文本信息生成程序化材质节点图，在合成效率和视觉质量方面优于纯文本方法。


<details>
  <summary>Details</summary>
Motivation: 现有的程序化材质节点图创建过程具有挑战性，需要专业培训。现有的神经程序合成方法仅处理文本表示，忽略了节点图的视觉空间特性。

Method: 提出MultiMat框架，该框架利用大型多模态模型处理视觉和文本的图表表示，并结合约束树搜索推理算法来确保语法的有效性并提高搜索效率。在包含高质量程序化材质的新数据集上进行训练。

Result: 与纯文本基线相比，该多模态程序合成方法在无条件和有条件图表合成方面都更有效率，并具有更高的视觉质量和保真度，达到了新的最先进性能。

Conclusion: 多模态程序合成方法在生成程序化材质节点图方面比纯文本方法更优越，提高了效率和视觉质量。

Abstract: Material node graphs are programs that generate the 2D channels of procedural
materials, including geometry such as roughness and displacement maps, and
reflectance such as albedo and conductivity maps. They are essential in
computer graphics for representing the appearance of virtual 3D objects
parametrically and at arbitrary resolution. In particular, their directed
acyclic graph structures and intermediate states provide an intuitive
understanding and workflow for interactive appearance modeling. Creating such
graphs is a challenging task and typically requires professional training.
While recent neural program synthesis approaches attempt to simplify this
process, they solely represent graphs as textual programs, failing to capture
the inherently visual-spatial nature of node graphs that makes them accessible
to humans. To address this gap, we present MultiMat, a multimodal program
synthesis framework that leverages large multimodal models to process both
visual and textual graph representations for improved generation of procedural
material graphs. We train our models on a new dataset of production-quality
procedural materials and combine them with a constrained tree search inference
algorithm that ensures syntactic validity while efficiently navigating the
program space. Our experimental results show that our multimodal program
synthesis method is more efficient in both unconditional and conditional graph
synthesis with higher visual quality and fidelity than text-only baselines,
establishing new state-of-the-art performance.

</details>


### [107] [DragGANSpace: Latent Space Exploration and Control for GANs](https://arxiv.org/abs/2509.22169)
*Kirsten Odendaal,Neela Kaushik,Spencer Halverson*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This work integrates StyleGAN, DragGAN and Principal Component Analysis (PCA)
to enhance the latent space efficiency and controllability of GAN-generated
images. Style-GAN provides a structured latent space, DragGAN enables intuitive
image manipulation, and PCA reduces dimensionality and facilitates cross-model
alignment for more streamlined and interpretable exploration of latent spaces.
We apply our techniques to the Animal Faces High Quality (AFHQ) dataset, and
find that our approach of integrating PCA-based dimensionality reduction with
the Drag-GAN framework for image manipulation retains performance while
improving optimization efficiency. Notably, introducing PCA into the latent W+
layers of DragGAN can consistently reduce the total optimization time while
maintaining good visual quality and even boosting the Structural Similarity
Index Measure (SSIM) of the optimized image, particularly in shallower latent
spaces (W+ layers = 3). We also demonstrate capability for aligning images
generated by two StyleGAN models trained on similar but distinct data domains
(AFHQ-Dog and AFHQ-Cat), and show that we can control the latent space of these
aligned images to manipulate the images in an intuitive and interpretable
manner. Our findings highlight the possibility for efficient and interpretable
latent space control for a wide range of image synthesis and editing
applications.

</details>


### [108] [MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing](https://arxiv.org/abs/2509.22186)
*Junbo Niu,Zheng Liu,Zhuangcheng Gu,Bin Wang,Linke Ouyang,Zhiyuan Zhao,Tao Chu,Tianyao He,Fan Wu,Qintong Zhang,Zhenjiang Jin,Guang Liang,Rui Zhang,Wenzheng Zhang,Yuan Qu,Zhifei Ren,Yuefeng Sun,Yuanhong Zheng,Dongsheng Ma,Zirui Tang,Boyu Niu,Ziyang Miao,Hejun Dong,Siyi Qian,Junyuan Zhang,Jingzhou Chen,Fangdong Wang,Xiaomeng Zhao,Liqun Wei,Wei Li,Shasha Wang,Ruiliang Xu,Yuanyuan Cao,Lu Chen,Qianqian Wu,Huaiyu Gu,Lindong Lu,Keming Wang,Dechen Lin,Guanlin Shen,Xuanhe Zhou,Linfeng Zhang,Yuhang Zang,Xiaoyi Dong,Jiaqi Wang,Bo Zhang,Lei Bai,Pei Chu,Weijia Li,Jiang Wu,Lijun Wu,Zhenxiang Li,Guangyu Wang,Zhongying Tu,Chao Xu,Kai Chen,Yu Qiao,Bowen Zhou,Dahua Lin,Wentao Zhang,Conghui He*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language
model that achieves state-of-the-art recognition accuracy while maintaining
exceptional computational efficiency. Our approach employs a coarse-to-fine,
two-stage parsing strategy that decouples global layout analysis from local
content recognition. In the first stage, the model performs efficient layout
analysis on downsampled images to identify structural elements, circumventing
the computational overhead of processing high-resolution inputs. In the second
stage, guided by the global layout, it performs targeted content recognition on
native-resolution crops extracted from the original image, preserving
fine-grained details in dense text, complex formulas, and tables. To support
this strategy, we developed a comprehensive data engine that generates diverse,
large-scale training corpora for both pretraining and fine-tuning. Ultimately,
MinerU2.5 demonstrates strong document parsing ability, achieving
state-of-the-art performance on multiple benchmarks, surpassing both
general-purpose and domain-specific models across various recognition tasks,
while maintaining significantly lower computational overhead.

</details>


### [109] [Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models](https://arxiv.org/abs/2509.22221)
*Jiaqi Liu,Lang Sun,Ronghao Fu,Bo Yang*

Main category: cs.CV

TL;DR: Geo-CoT框架通过多步推理和验证解决了遥感视觉语言模型的局限性，提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感视觉语言模型在处理复杂分析任务时存在不足，因为它们直接进行端到端训练，省略了推理步骤，导致输出结果难以验证。

Method: 提出了一种名为Geo-CoT（Perceptually-Grounded Geospatial Chain-of-Thought）的框架，将遥感分析建模为可验证的多步过程。采用两阶段对齐策略：首先使用监督微调（SFT）建立基础认知架构，然后利用基于组奖励策略优化（GRPO）的方法来改进模型的事实正确性。最终模型命名为RSThinker。

Result: RSThinker模型能够输出最终答案及其可验证的分析过程，在多项遥感任务上显著优于现有最先进的模型。

Conclusion: Geo-CoT框架和RSThinker模型为遥感领域提供了从不透明感知到结构化、可验证推理的有效途径，推动了地球观测的发展。

Abstract: Vision-Language Models (VLMs) in remote sensing often fail at complex
analytical tasks, a limitation stemming from their end-to-end training paradigm
that bypasses crucial reasoning steps and leads to unverifiable outputs. To
address this limitation, we introduce the Perceptually-Grounded Geospatial
Chain-of-Thought (Geo-CoT), a framework that models remote sensing analysis as
a verifiable, multi-step process. We instill this analytical process through a
two-stage alignment strategy, leveraging Geo-CoT380k, the first large-scale
dataset of structured Geo-CoT rationales. This strategy first employs
supervised fine-tuning (SFT) to instill the foundational cognitive
architecture, then leverages Group Reward Policy Optimization (GRPO) to refine
the model's reasoning policy towards factual correctness. The resulting model,
RSThinker, outputs both a final answer and its justifying, verifiable
analytical trace. This capability yields dominant performance, significantly
outperforming state-of-the-art models across a comprehensive range of tasks.
The public release of our Geo-CoT380k dataset and RSThinker model upon
publication serves as a concrete pathway from opaque perception towards
structured, verifiable reasoning for Earth Observation.

</details>


### [110] [Polysemous Language Gaussian Splatting via Matching-based Mask Lifting](https://arxiv.org/abs/2509.22225)
*Jiayu Ding,Xinpeng Liu,Zhiyi Pan,Shiqiang Long,Ge Li*

Main category: cs.CV

TL;DR: MUSplat是一个无需训练的框架，可以将2D开放词汇理解能力提升到3D高斯喷溅场景，解决了现有方法需要进行场景重训练、无法表示复杂语义以及跨视图不一致的问题。该框架利用预训练的2D分割模型生成多粒度2D掩码并将其提升到3D，然后通过优化高斯点的边界来形成初始对象分组。最后，利用视觉语言模型（VLM）来提炼鲁棒的文本特征，实现开放词汇查询。MUSplat将场景适应时间从几小时缩短到几分钟，并在3D对象选择和语义分割任务上超越了现有的基于训练的框架。


<details>
  <summary>Details</summary>
Motivation: 现有主流方法在将2D开放词汇理解能力提升到3D高斯喷溅场景时存在三个关键缺陷：1. 依赖于昂贵的每场景重训练，阻碍了即插即用。2. 限制性的单一语义设计无法表示复杂的、多概念的语义。3. 易受跨视图语义不一致性的影响，破坏了最终的语义表示。

Method: MUSplat框架无需训练，完全放弃了特征优化。它利用预训练的2D分割模型生成多粒度2D掩码并将其提升到3D，然后估计每个高斯点的前景概率以形成初始对象分组。接着，通过优化初始分组的模糊边界（利用语义熵和几何不透明度），最后通过视觉语言模型（VLM）在代表性视角下提炼鲁棒的文本特征，以解决视觉不一致性并实现开放词汇查询。

Result: MUSplat无需昂贵的每场景训练过程，将场景适应时间从几小时缩短到几分钟。在开放词汇3D对象选择和语义分割的基准任务上，MUSplat的性能优于现有的基于训练的框架，并同时解决了它们的单一语义限制。

Conclusion: MUSplat成功地将2D开放词汇理解能力提升到3D高斯喷溅场景，并且无需训练，大大缩短了场景适应时间，同时在性能和语义表示能力上优于现有方法。

Abstract: Lifting 2D open-vocabulary understanding into 3D Gaussian Splatting (3DGS)
scenes is a critical challenge. However, mainstream methods suffer from three
key flaws: (i) their reliance on costly per-scene retraining prevents
plug-and-play application; (ii) their restrictive monosemous design fails to
represent complex, multi-concept semantics; and (iii) their vulnerability to
cross-view semantic inconsistencies corrupts the final semantic representation.
To overcome these limitations, we introduce MUSplat, a training-free framework
that abandons feature optimization entirely. Leveraging a pre-trained 2D
segmentation model, our pipeline generates and lifts multi-granularity 2D masks
into 3D, where we estimate a foreground probability for each Gaussian point to
form initial object groups. We then optimize the ambiguous boundaries of these
initial groups using semantic entropy and geometric opacity. Subsequently, by
interpreting the object's appearance across its most representative viewpoints,
a Vision-Language Model (VLM) distills robust textual features that reconciles
visual inconsistencies, enabling open-vocabulary querying via semantic
matching. By eliminating the costly per-scene training process, MUSplat reduces
scene adaptation time from hours to mere minutes. On benchmark tasks for
open-vocabulary 3D object selection and semantic segmentation, MUSplat
outperforms established training-based frameworks while simultaneously
addressing their monosemous limitations.

</details>


### [111] [UrbanFeel: A Comprehensive Benchmark for Temporal and Perceptual Understanding of City Scenes through Human Perspective](https://arxiv.org/abs/2509.22228)
*Jun He,Yi Lin,Zilong Huang,Jiacong Yin,Junyan Ye,Yuchuan Zhou,Weijia Li,Xiang Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Urban development impacts over half of the global population, making
human-centered understanding of its structural and perceptual changes essential
for sustainable development. While Multimodal Large Language Models (MLLMs)
have shown remarkable capabilities across various domains, existing benchmarks
that explore their performance in urban environments remain limited, lacking
systematic exploration of temporal evolution and subjective perception of urban
environment that aligns with human perception. To address these limitations, we
propose UrbanFeel, a comprehensive benchmark designed to evaluate the
performance of MLLMs in urban development understanding and subjective
environmental perception. UrbanFeel comprises 14.3K carefully constructed
visual questions spanning three cognitively progressive dimensions: Static
Scene Perception, Temporal Change Understanding, and Subjective Environmental
Perception. We collect multi-temporal single-view and panoramic street-view
images from 11 representative cities worldwide, and generate high-quality
question-answer pairs through a hybrid pipeline of spatial clustering,
rule-based generation, model-assisted prompting, and manual annotation. Through
extensive evaluation of 20 state-of-the-art MLLMs, we observe that Gemini-2.5
Pro achieves the best overall performance, with its accuracy approaching human
expert levels and narrowing the average gap to just 1.5\%. Most models perform
well on tasks grounded in scene understanding. In particular, some models even
surpass human annotators in pixel-level change detection. However, performance
drops notably in tasks requiring temporal reasoning over urban development.
Additionally, in the subjective perception dimension, several models reach
human-level or even higher consistency in evaluating dimension such as
beautiful and safety.

</details>


### [112] [A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation](https://arxiv.org/abs/2509.22229)
*Jiaping Yu,Muli Yang,Jiapeng Ji,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: SFUDA旨在解决源域模型在无法访问源数据的情况下适应目标域的问题。现有方法要么只利用源模型预测，要么微调大型多模态模型，忽略了互补洞察力和目标数据的潜在结构。本研究提出EXCL，包含双专家框架和检索增强交互优化流程。双专家框架使冻结的源域模型（带Conv-Adapter）和可训练文本提示的预训练视觉-语言模型能够从无标签目标样本中挖掘共识知识。为了在完全无监督的条件下训练这些插件模块，我们引入了RAIN，一个三阶段流程：(1) 协同检索伪源样本和复杂目标样本，(2) 分别在各自样本集上微调每个专家，(3) 通过共享学习结果强制学习目标一致性。在四个基准数据集上的广泛实验表明，我们的方法达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有SFUDA方法在利用源模型预测或微调大型多模态模型时，忽略了目标数据的互补洞察力和潜在结构。

Method: 提出EXCL，包含双专家框架（冻结的源域模型+Conv-Adapter，以及可训练文本提示的预训练视觉-语言模型）和检索增强交互（RAIN）优化流程。RAIN包括协同检索样本、分别微调专家以及强制学习目标一致性。

Result: 在四个基准数据集上达到了最先进的性能。

Conclusion: EXCL在SFUDA任务上取得了最先进的性能，有效利用了源模型和目标数据的互补信息。

Abstract: Source-Free Unsupervised Domain Adaptation (SFUDA) addresses the realistic
challenge of adapting a source-trained model to a target domain without access
to the source data, driven by concerns over privacy and cost. Existing SFUDA
methods either exploit only the source model's predictions or fine-tune large
multimodal models, yet both neglect complementary insights and the latent
structure of target data. In this paper, we propose the Experts Cooperative
Learning (EXCL). EXCL contains the Dual Experts framework and
Retrieval-Augmentation-Interaction optimization pipeline. The Dual Experts
framework places a frozen source-domain model (augmented with Conv-Adapter) and
a pretrained vision-language model (with a trainable text prompt) on equal
footing to mine consensus knowledge from unlabeled target samples. To
effectively train these plug-in modules under purely unsupervised conditions,
we introduce Retrieval-Augmented-Interaction(RAIN), a three-stage pipeline that
(1) collaboratively retrieves pseudo-source and complex target samples, (2)
separately fine-tunes each expert on its respective sample set, and (3)
enforces learning object consistency via a shared learning result. Extensive
experiments on four benchmark datasets demonstrate that our approach matches
state-of-the-art performance.

</details>


### [113] [FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing](https://arxiv.org/abs/2509.22244)
*Junyi Wu,Zhiteng Li,Haotong Qin,Xiaohong Liu,Linghe Kong,Yulun Zhang,Xiaokang Yang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-guided image editing with diffusion models has achieved remarkable
quality but suffers from prohibitive latency, hindering real-world
applications. We introduce FlashEdit, a novel framework designed to enable
high-fidelity, real-time image editing. Its efficiency stems from three key
innovations: (1) a One-Step Inversion-and-Editing (OSIE) pipeline that bypasses
costly iterative processes; (2) a Background Shield (BG-Shield) technique that
guarantees background preservation by selectively modifying features only
within the edit region; and (3) a Sparsified Spatial Cross-Attention (SSCA)
mechanism that ensures precise, localized edits by suppressing semantic leakage
to the background. Extensive experiments demonstrate that FlashEdit maintains
superior background consistency and structural integrity, while performing
edits in under 0.2 seconds, which is an over 150$\times$ speedup compared to
prior multi-step methods. Our code will be made publicly available at
https://github.com/JunyiWuCode/FlashEdit.

</details>


### [114] [Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks](https://arxiv.org/abs/2509.22258)
*Miao Jing,Mengting Jia,Junling Lin,Zhongxia Shen,Lijun Wang,Yuanyuan Peng,Huan Gao,Mingkun Xu,Shangyang Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in vision-language models (VLMs) have achieved remarkable
performance on standard medical benchmarks, yet their true clinical reasoning
ability remains unclear. Existing datasets predominantly emphasize
classification accuracy, creating an evaluation illusion in which models appear
proficient while still failing at high-stakes diagnostic reasoning. We
introduce Neural-MedBench, a compact yet reasoning-intensive benchmark
specifically designed to probe the limits of multimodal clinical reasoning in
neurology. Neural-MedBench integrates multi-sequence MRI scans, structured
electronic health records, and clinical notes, and encompasses three core task
families: differential diagnosis, lesion recognition, and rationale generation.
To ensure reliable evaluation, we develop a hybrid scoring pipeline that
combines LLM-based graders, clinician validation, and semantic similarity
metrics. Through systematic evaluation of state-of-the-art VLMs, including
GPT-4o, Claude-4, and MedGemma, we observe a sharp performance drop compared to
conventional datasets. Error analysis shows that reasoning failures, rather
than perceptual errors, dominate model shortcomings. Our findings highlight the
necessity of a Two-Axis Evaluation Framework: breadth-oriented large datasets
for statistical generalization, and depth-oriented, compact benchmarks such as
Neural-MedBench for reasoning fidelity. We release Neural-MedBench at
https://neuromedbench.github.io/ as an open and extensible diagnostic testbed,
which guides the expansion of future benchmarks and enables rigorous yet
cost-effective assessment of clinically trustworthy AI.

</details>


### [115] [UniMapGen: A Generative Framework for Large-Scale Map Construction from Multi-modal Data](https://arxiv.org/abs/2509.22262)
*Yujian Yuan,Changjie Wu,Xinyuan Chang,Sijin Wang,Hang Zhang,Shiyi Liang,Shuang Zeng,Mu Xu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large-scale map construction is foundational for critical applications such
as autonomous driving and navigation systems. Traditional large-scale map
construction approaches mainly rely on costly and inefficient special data
collection vehicles and labor-intensive annotation processes. While existing
satellite-based methods have demonstrated promising potential in enhancing the
efficiency and coverage of map construction, they exhibit two major
limitations: (1) inherent drawbacks of satellite data (e.g., occlusions,
outdatedness) and (2) inefficient vectorization from perception-based methods,
resulting in discontinuous and rough roads that require extensive
post-processing. This paper presents a novel generative framework, UniMapGen,
for large-scale map construction, offering three key innovations: (1)
representing lane lines as \textbf{discrete sequence} and establishing an
iterative strategy to generate more complete and smooth map vectors than
traditional perception-based methods. (2) proposing a flexible architecture
that supports \textbf{multi-modal} inputs, enabling dynamic selection among
BEV, PV, and text prompt, to overcome the drawbacks of satellite data. (3)
developing a \textbf{state update} strategy for global continuity and
consistency of the constructed large-scale map. UniMapGen achieves
state-of-the-art performance on the OpenSatMap dataset. Furthermore, UniMapGen
can infer occluded roads and predict roads missing from dataset annotations.
Our code will be released.

</details>


### [116] [GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition](https://arxiv.org/abs/2509.22276)
*Dinh Minh Nguyen,Malte Avenhaus,Thomas Lindemeier*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a unified solution for mesh reconstruction and material
decomposition from multi-view images based on 3D Gaussian Splatting, referred
to as GS-2M. Previous works handle these tasks separately and struggle to
reconstruct highly reflective surfaces, often relying on priors from external
models to enhance the decomposition results. Conversely, our method addresses
these two problems by jointly optimizing attributes relevant to the quality of
rendered depth and normals, maintaining geometric details while being resilient
to reflective surfaces. Although contemporary works effectively solve these
tasks together, they often employ sophisticated neural components to learn
scene properties, which hinders their performance at scale. To further
eliminate these neural components, we propose a novel roughness supervision
strategy based on multi-view photometric variation. When combined with a
carefully designed loss and optimization process, our unified framework
produces reconstruction results comparable to state-of-the-art methods,
delivering triangle meshes and their associated material components for
downstream tasks. We validate the effectiveness of our approach with widely
used datasets from previous works and qualitative comparisons with
state-of-the-art surface reconstruction methods.

</details>


### [117] [Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models](https://arxiv.org/abs/2509.22283)
*Michael Jungo,Andreas Fischer*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Rule-based reinforcement learning has been gaining popularity ever since
DeepSeek-R1 has demonstrated its success through simple verifiable rewards. In
the domain of document analysis, reinforcement learning is not as prevalent,
even though many downstream tasks may benefit from the emerging properties of
reinforcement learning, particularly the enhanced reason capabilities. We study
the effects of rule-based reinforcement learning with the task of Document
Image Classification which is one of the most commonly studied downstream tasks
in document analysis. We find that reinforcement learning tends to have better
generalisation capabilities to out-of-distritbution data, which we examine in
three different scenarios, namely out-of-distribution images, unseen classes
and different modalities. Our code is available at
https://github.com/jungomi/vision-finetune.

</details>


### [118] [Jailbreaking on Text-to-Video Models via Scene Splitting Strategy](https://arxiv.org/abs/2509.22292)
*Wonjun Lee,Haon Park,Doehyeon Lee,Bumsub Ham,Suhyun Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Along with the rapid advancement of numerous Text-to-Video (T2V) models,
growing concerns have emerged regarding their safety risks. While recent
studies have explored vulnerabilities in models like LLMs, VLMs, and
Text-to-Image (T2I) models through jailbreak attacks, T2V models remain largely
unexplored, leaving a significant safety gap. To address this gap, we introduce
SceneSplit, a novel black-box jailbreak method that works by fragmenting a
harmful narrative into multiple scenes, each individually benign. This approach
manipulates the generative output space, the abstract set of all potential
video outputs for a given prompt, using the combination of scenes as a powerful
constraint to guide the final outcome. While each scene individually
corresponds to a wide and safe space where most outcomes are benign, their
sequential combination collectively restricts this space, narrowing it to an
unsafe region and significantly increasing the likelihood of generating a
harmful video. This core mechanism is further enhanced through iterative scene
manipulation, which bypasses the safety filter within this constrained unsafe
region. Additionally, a strategy library that reuses successful attack patterns
further improves the attack's overall effectiveness and robustness. To validate
our method, we evaluate SceneSplit across 11 safety categories on T2V models.
Our results show that it achieves a high average Attack Success Rate (ASR) of
77.2% on Luma Ray2, 84.1% on Hailuo, and 78.2% on Veo2, significantly
outperforming the existing baseline. Through this work, we demonstrate that
current T2V safety mechanisms are vulnerable to attacks that exploit narrative
structure, providing new insights for understanding and improving the safety of
T2V models.

</details>


### [119] [HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models](https://arxiv.org/abs/2509.22300)
*Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While diffusion models have made remarkable progress in image generation,
their outputs can still appear unrealistic and lack fine details, especially
when using fewer number of neural function evaluations (NFEs) or lower guidance
scales. To address this issue, we propose a novel momentum-based sampling
technique, termed history-guided sampling (HiGS), which enhances quality and
efficiency of diffusion sampling by integrating recent model predictions into
each inference step. Specifically, HiGS leverages the difference between the
current prediction and a weighted average of past predictions to steer the
sampling process toward more realistic outputs with better details and
structure. Our approach introduces practically no additional computation and
integrates seamlessly into existing diffusion frameworks, requiring neither
extra training nor fine-tuning. Extensive experiments show that HiGS
consistently improves image quality across diverse models and architectures and
under varying sampling budgets and guidance scales. Moreover, using a
pretrained SiT model, HiGS achieves a new state-of-the-art FID of 1.61 for
unguided ImageNet generation at 256$\times$256 with only 30 sampling steps
(instead of the standard 250). We thus present HiGS as a plug-and-play
enhancement to standard diffusion sampling that enables faster generation with
higher fidelity.

</details>


### [120] [Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation](https://arxiv.org/abs/2509.22307)
*Jinpeng Lu,Linghan Cai,Yinda Chen,Guo Tang,Songhan Jiang,Haoyuan Shi,Zhiwei Xiong*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Lightweight 3D medical image segmentation remains constrained by a
fundamental "efficiency / robustness conflict", particularly when processing
complex anatomical structures and heterogeneous modalities. In this paper, we
study how to redesign the framework based on the characteristics of
high-dimensional 3D images, and explore data synergy to overcome the fragile
representation of lightweight methods. Our approach, VeloxSeg, begins with a
deployable and extensible dual-stream CNN-Transformer architecture composed of
Paired Window Attention (PWA) and Johnson-Lindenstrauss lemma-guided
convolution (JLC). For each 3D image, we invoke a "glance-and-focus" principle,
where PWA rapidly retrieves multi-scale information, and JLC ensures robust
local feature extraction with minimal parameters, significantly enhancing the
model's ability to operate with low computational budget. Followed by an
extension of the dual-stream architecture that incorporates modal interaction
into the multi-scale image-retrieval process, VeloxSeg efficiently models
heterogeneous modalities. Finally, Spatially Decoupled Knowledge Transfer
(SDKT) via Gram matrices injects the texture prior extracted by a
self-supervised network into the segmentation network, yielding stronger
representations than baselines at no extra inference cost. Experimental results
on multimodal benchmarks show that VeloxSeg achieves a 26% Dice improvement,
alongside increasing GPU throughput by 11x and CPU by 48x. Codes are available
at https://github.com/JinPLu/VeloxSeg.

</details>


### [121] [NIFTY: a Non-Local Image Flow Matching for Texture Synthesis](https://arxiv.org/abs/2509.22318)
*Pierrick Chatillon,Julien Rabin,David Tschumperlé*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper addresses the problem of exemplar-based texture synthesis. We
introduce NIFTY, a hybrid framework that combines recent insights on diffusion
models trained with convolutional neural networks, and classical patch-based
texture optimization techniques. NIFTY is a non-parametric flow-matching model
built on non-local patch matching, which avoids the need for neural network
training while alleviating common shortcomings of patch-based methods, such as
poor initialization or visual artifacts. Experimental results demonstrate the
effectiveness of the proposed approach compared to representative methods from
the literature. Code is available at https://github.com/PierrickCh/Nifty.git

</details>


### [122] [RAPID^3: Tri-Level Reinforced Acceleration Policies for Diffusion Transformer](https://arxiv.org/abs/2509.22323)
*Wangbo Zhao,Yizeng Han,Zhiwei Tang,Jiasheng Tang,Pengfei Zhou,Kai Wang,Bohan Zhuang,Zhangyang Wang,Fan Wang,Yang You*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Diffusion Transformers (DiTs) excel at visual generation yet remain hampered
by slow sampling. Existing training-free accelerators - step reduction, feature
caching, and sparse attention - enhance inference speed but typically rely on a
uniform heuristic or a manually designed adaptive strategy for all images,
leaving quality on the table. Alternatively, dynamic neural networks offer
per-image adaptive acceleration, but their high fine-tuning costs limit broader
applicability. To address these limitations, we introduce RAPID3: Tri-Level
Reinforced Acceleration Policies for Diffusion Transformers, a framework that
delivers image-wise acceleration with zero updates to the base generator.
Specifically, three lightweight policy heads - Step-Skip, Cache-Reuse, and
Sparse-Attention - observe the current denoising state and independently decide
their corresponding speed-up at each timestep. All policy parameters are
trained online via Group Relative Policy Optimization (GRPO) while the
generator remains frozen. Meanwhile, an adversarially learned discriminator
augments the reward signal, discouraging reward hacking by boosting returns
only when generated samples stay close to the original model's distribution.
Across state-of-the-art DiT backbones, including Stable Diffusion 3 and FLUX,
RAPID3 achieves nearly 3x faster sampling with competitive generation quality.

</details>


### [123] [Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph Learning](https://arxiv.org/abs/2509.22331)
*Xiao Wang,Shujuan Wu,Xiaoxia Cheng,Changwei Bi,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Current Pedestrian Attribute Recognition (PAR) algorithms typically focus on
mapping visual features to semantic labels or attempt to enhance learning by
fusing visual and attribute information. However, these methods fail to fully
exploit attribute knowledge and contextual information for more accurate
recognition. Although recent works have started to consider using attribute
text as additional input to enhance the association between visual and semantic
information, these methods are still in their infancy. To address the above
challenges, this paper proposes the construction of a multi-modal knowledge
graph, which is utilized to mine the relationships between local visual
features and text, as well as the relationships between attributes and
extensive visual context samples. Specifically, we propose an effective
multi-modal knowledge graph construction method that fully considers the
relationships among attributes and the relationships between attributes and
vision tokens. To effectively model these relationships, this paper introduces
a knowledge graph-guided cross-modal hypergraph learning framework to enhance
the standard pedestrian attribute recognition framework. Comprehensive
experiments on multiple PAR benchmark datasets have thoroughly demonstrated the
effectiveness of our proposed knowledge graph for the PAR task, establishing a
strong foundation for knowledge-guided pedestrian attribute recognition. The
source code of this paper will be released on
https://github.com/Event-AHU/OpenPAR

</details>


### [124] [CircuitSense: A Hierarchical Circuit System Benchmark Bridging Visual Comprehension and Symbolic Reasoning in Engineering Design Process](https://arxiv.org/abs/2509.22339)
*Arman Akbari,Jian Gao,Yifei Zou,Mei Yang,Jinru Duan,Dmitrii Torbunov,Yanzhi Wang,Yihui Ren,Xuan Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Engineering design operates through hierarchical abstraction from system
specifications to component implementations, requiring visual understanding
coupled with mathematical reasoning at each level. While Multi-modal Large
Language Models (MLLMs) excel at natural image tasks, their ability to extract
mathematical models from technical diagrams remains unexplored. We present
\textbf{CircuitSense}, a comprehensive benchmark evaluating circuit
understanding across this hierarchy through 8,006+ problems spanning
component-level schematics to system-level block diagrams. Our benchmark
uniquely examines the complete engineering workflow: Perception, Analysis, and
Design, with a particular emphasis on the critical but underexplored capability
of deriving symbolic equations from visual inputs. We introduce a hierarchical
synthetic generation pipeline consisting of a grid-based schematic generator
and a block diagram generator with auto-derived symbolic equation labels.
Comprehensive evaluation of six state-of-the-art MLLMs, including both
closed-source and open-source models, reveals fundamental limitations in
visual-to-mathematical reasoning. Closed-source models achieve over 85\%
accuracy on perception tasks involving component recognition and topology
identification, yet their performance on symbolic derivation and analytical
reasoning falls below 19\%, exposing a critical gap between visual parsing and
symbolic reasoning. Models with stronger symbolic reasoning capabilities
consistently achieve higher design task accuracy, confirming the fundamental
role of mathematical understanding in circuit synthesis and establishing
symbolic reasoning as the key metric for engineering competence.

</details>


### [125] [HierLight-YOLO: A Hierarchical and Lightweight Object Detection Network for UAV Photography](https://arxiv.org/abs/2509.22365)
*Defan Chen,Yaohua Hu,Luchan Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The real-time detection of small objects in complex scenes, such as the
unmanned aerial vehicle (UAV) photography captured by drones, has dual
challenges of detecting small targets (<32 pixels) and maintaining real-time
efficiency on resource-constrained platforms. While YOLO-series detectors have
achieved remarkable success in real-time large object detection, they suffer
from significantly higher false negative rates for drone-based detection where
small objects dominate, compared to large object scenarios. This paper proposes
HierLight-YOLO, a hierarchical feature fusion and lightweight model that
enhances the real-time detection of small objects, based on the YOLOv8
architecture. We propose the Hierarchical Extended Path Aggregation Network
(HEPAN), a multi-scale feature fusion method through hierarchical cross-level
connections, enhancing the small object detection accuracy. HierLight-YOLO
includes two innovative lightweight modules: Inverted Residual Depthwise
Convolution Block (IRDCB) and Lightweight Downsample (LDown) module, which
significantly reduce the model's parameters and computational complexity
without sacrificing detection capabilities. Small object detection head is
designed to further enhance spatial resolution and feature fusion to tackle the
tiny object (4 pixels) detection. Comparison experiments and ablation studies
on the VisDrone2019 benchmark demonstrate state-of-the-art performance of
HierLight-YOLO.

</details>


### [126] [Effectiveness of Large Multimodal Models in Detecting Disinformation: Experimental Results](https://arxiv.org/abs/2509.22377)
*Yasmina Kheddache,Marc Lalonde*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The proliferation of disinformation, particularly in multimodal contexts
combining text and images, presents a significant challenge across digital
platforms. This study investigates the potential of large multimodal models
(LMMs) in detecting and mitigating false information. We propose to approach
multimodal disinformation detection by leveraging the advanced capabilities of
the GPT-4o model. Our contributions include: (1) the development of an
optimized prompt incorporating advanced prompt engineering techniques to ensure
precise and consistent evaluations; (2) the implementation of a structured
framework for multimodal analysis, including a preprocessing methodology for
images and text to comply with the model's token limitations; (3) the
definition of six specific evaluation criteria that enable a fine-grained
classification of content, complemented by a self-assessment mechanism based on
confidence levels; (4) a comprehensive performance analysis of the model across
multiple heterogeneous datasets Gossipcop, Politifact, Fakeddit, MMFakeBench,
and AMMEBA highlighting GPT-4o's strengths and limitations in disinformation
detection; (5) an investigation of prediction variability through repeated
testing, evaluating the stability and reliability of the model's
classifications; and (6) the introduction of confidence-level and
variability-based evaluation methods. These contributions provide a robust and
reproducible methodological framework for automated multimodal disinformation
analysis.

</details>


### [127] [GPT-4 for Occlusion Order Recovery](https://arxiv.org/abs/2509.22383)
*Kaziwa Saleh,Zhyar Rzgar K Rostam,Sándor Szénási,Zoltán Vámossy*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Occlusion remains a significant challenge for current vision models to
robustly interpret complex and dense real-world images and scenes. To address
this limitation and to enable accurate prediction of the occlusion order
relationship between objects, we propose leveraging the advanced capability of
a pre-trained GPT-4 model to deduce the order. By providing a specifically
designed prompt along with the input image, GPT-4 can analyze the image and
generate order predictions. The response can then be parsed to construct an
occlusion matrix which can be utilized in assisting with other occlusion
handling tasks and image understanding. We report the results of evaluating the
model on COCOA and InstaOrder datasets. The results show that by using semantic
context, visual patterns, and commonsense knowledge, the model can produce more
accurate order predictions. Unlike baseline methods, the model can reason about
occlusion relationships in a zero-shot fashion, which requires no annotated
training data and can easily be integrated into occlusion handling frameworks.

</details>


### [128] [Gradient-based multi-focus image fusion with focus-aware saliency enhancement](https://arxiv.org/abs/2509.22392)
*Haoyu Li,XiaoSong Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-focus image fusion (MFIF) aims to yield an all-focused image from
multiple partially focused inputs, which is crucial in applications cover
sur-veillance, microscopy, and computational photography. However, existing
methods struggle to preserve sharp focus-defocus boundaries, often resulting in
blurred transitions and focused details loss. To solve this problem, we propose
a MFIF method based on significant boundary enhancement, which generates
high-quality fused boundaries while effectively detecting focus in-formation.
Particularly, we propose a gradient-domain-based model that can obtain initial
fusion results with complete boundaries and effectively pre-serve the boundary
details. Additionally, we introduce Tenengrad gradient detection to extract
salient features from both the source images and the ini-tial fused image,
generating the corresponding saliency maps. For boundary refinement, we develop
a focus metric based on gradient and complementary information, integrating the
salient features with the complementary infor-mation across images to emphasize
focused regions and produce a high-quality initial decision result. Extensive
experiments on four public datasets demonstrate that our method consistently
outperforms 12 state-of-the-art methods in both subjective and objective
evaluations. We have realized codes in https://github.com/Lihyua/GICI

</details>


### [129] [Text Adversarial Attacks with Dynamic Outputs](https://arxiv.org/abs/2509.22393)
*Wenqiang Wang,Siyuan Liang,Xiao Yan,Xiaochun Cao*

Main category: cs.CV

TL;DR: 文本动态输出攻击（TDOA）是一种新型的对抗性攻击方法，它通过聚类方法将动态输出场景转换为静态场景，并采用最远标签定向攻击策略来最大化攻击效果。该方法在静态和动态输出场景下均表现出色，并能有效应用于生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有的文本对抗攻击方法主要针对标签数量固定、标签空间预定义的静态场景，而忽视了具有动态输出的场景。本文旨在解决这一研究空白，提出一种能够有效攻击具有动态输出的大型语言模型的方法。

Method: 1. 采用聚类方法训练生成式模型，将动态输出场景转化为静态单输出场景。 2. 提出最远标签定向攻击策略，选择与模型粗粒度标签偏差最大的对抗样本，以最大化攻击扰动。 3. 将TDOA框架扩展到生成任务，将翻译任务视为具有无限输出空间的分类问题。

Result: TDOA在四个数据集和八个模型（包括ChatGPT-4o和ChatGPT-4.1）上进行了广泛评估，证明了其在生成对抗样本方面的有效性，以及在仅需单次查询的情况下，其最大攻击成功率为50.81%。在静态输出场景下，TDOA的最大攻击成功率达到82.68%，优于现有方法。在生成任务中，TDOA在翻译任务上取得了最高0.64 RDBLEU和0.62 RDchrF的提升。

Conclusion: TDOA成功地将动态输出场景中的文本对抗攻击问题转化为静态场景，并提出了一种有效的攻击策略。该方法不仅在大规模语言模型上表现出强大的攻击能力，而且在生成任务中也取得了显著的改进，证明了其通用性和有效性。

Abstract: Text adversarial attack methods are typically designed for static scenarios
with fixed numbers of output labels and a predefined label space, relying on
extensive querying of the victim model (query-based attacks) or the surrogate
model (transfer-based attacks). To address this gap, we introduce the Textual
Dynamic Outputs Attack (TDOA) method, which employs a clustering-based
surrogate model training approach to convert the dynamic-output scenario into a
static single-output scenario. To improve attack effectiveness, we propose the
farthest-label targeted attack strategy, which selects adversarial vectors that
deviate most from the model's coarse-grained labels, thereby maximizing
disruption. We extensively evaluate TDOA on four datasets and eight victim
models (e.g., ChatGPT-4o, ChatGPT-4.1), showing its effectiveness in crafting
adversarial examples and its strong potential to compromise large language
models with limited access. With a single query per text, TDOA achieves a
maximum attack success rate of 50.81\%. Additionally, we find that TDOA also
achieves state-of-the-art performance in conventional static output scenarios,
reaching a maximum ASR of 82.68\%. Meanwhile, by conceptualizing translation
tasks as classification problems with unbounded output spaces, we extend the
TDOA framework to generative settings, surpassing prior results by up to 0.64
RDBLEU and 0.62 RDchrF.

</details>


### [130] [Integrating Background Knowledge in Medical Semantic Segmentation with Logic Tensor Networks](https://arxiv.org/abs/2509.22399)
*Luca Bergamin,Giovanna Maria Dimitri,Fabio Aiolli*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Semantic segmentation is a fundamental task in medical image analysis, aiding
medical decision-making by helping radiologists distinguish objects in an
image. Research in this field has been driven by deep learning applications,
which have the potential to scale these systems even in the presence of noise
and artifacts. However, these systems are not yet perfected. We argue that
performance can be improved by incorporating common medical knowledge into the
segmentation model's loss function. To this end, we introduce Logic Tensor
Networks (LTNs) to encode medical background knowledge using first-order logic
(FOL) rules. The encoded rules span from constraints on the shape of the
produced segmentation, to relationships between different segmented areas. We
apply LTNs in an end-to-end framework with a SwinUNETR for semantic
segmentation. We evaluate our method on the task of segmenting the hippocampus
in brain MRI scans. Our experiments show that LTNs improve the baseline
segmentation performance, especially when training data is scarce. Despite
being in its preliminary stages, we argue that neurosymbolic methods are
general enough to be adapted and applied to other medical semantic segmentation
tasks.

</details>


### [131] [Closing the Safety Gap: Surgical Concept Erasure in Visual Autoregressive Models](https://arxiv.org/abs/2509.22400)
*Xinhao Zhong,Yimin Zhou,Zhiqi Zhang,Junhao Li,Yi Sun,Bin Chen,Shu-Tao Xia,Ke Xu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid progress of visual autoregressive (VAR) models has brought new
opportunities for text-to-image generation, but also heightened safety
concerns. Existing concept erasure techniques, primarily designed for diffusion
models, fail to generalize to VARs due to their next-scale token prediction
paradigm. In this paper, we first propose a novel VAR Erasure framework VARE
that enables stable concept erasure in VAR models by leveraging auxiliary
visual tokens to reduce fine-tuning intensity. Building upon this, we introduce
S-VARE, a novel and effective concept erasure method designed for VAR, which
incorporates a filtered cross entropy loss to precisely identify and minimally
adjust unsafe visual tokens, along with a preservation loss to maintain
semantic fidelity, addressing the issues such as language drift and reduced
diversity introduce by na\"ive fine-tuning. Extensive experiments demonstrate
that our approach achieves surgical concept erasure while preserving generation
quality, thereby closing the safety gap in autoregressive text-to-image
generation by earlier methods.

</details>


### [132] [RAU: Reference-based Anatomical Understanding with Vision Language Models](https://arxiv.org/abs/2509.22404)
*Yiwei Li,Yikang Liu,Jiaqi Guo,Lin Zhao,Zheyuan Zhang,Xiao Chen,Boris Mailhe,Ankush Mukherjee,Terrence Chen,Shanhui Sun*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Anatomical understanding through deep learning is critical for automatic
report generation, intra-operative navigation, and organ localization in
medical imaging; however, its progress is constrained by the scarcity of
expert-labeled data. A promising remedy is to leverage an annotated reference
image to guide the interpretation of an unlabeled target. Although recent
vision-language models (VLMs) exhibit non-trivial visual reasoning, their
reference-based understanding and fine-grained localization remain limited. We
introduce RAU, a framework for reference-based anatomical understanding with
VLMs. We first show that a VLM learns to identify anatomical regions through
relative spatial reasoning between reference and target images, trained on a
moderately sized dataset. We validate this capability through visual question
answering (VQA) and bounding box prediction. Next, we demonstrate that the
VLM-derived spatial cues can be seamlessly integrated with the fine-grained
segmentation capability of SAM2, enabling localization and pixel-level
segmentation of small anatomical regions, such as vessel segments. Across two
in-distribution and two out-of-distribution datasets, RAU consistently
outperforms a SAM2 fine-tuning baseline using the same memory setup, yielding
more accurate segmentations and more reliable localization. More importantly,
its strong generalization ability makes it scalable to out-of-distribution
datasets, a property crucial for medical image applications. To the best of our
knowledge, RAU is the first to explore the capability of VLMs for
reference-based identification, localization, and segmentation of anatomical
structures in medical images. Its promising performance highlights the
potential of VLM-driven approaches for anatomical understanding in automated
clinical workflows.

</details>


### [133] [FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing](https://arxiv.org/abs/2509.22412)
*Hossein Kashiani,Niloufar Alipour Talemi,Fatemeh Afghah*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deepfake detectors often struggle to generalize to novel forgery types due to
biases learned from limited training data. In this paper, we identify a new
type of model bias in the frequency domain, termed spectral bias, where
detectors overly rely on specific frequency bands, restricting their ability to
generalize across unseen forgeries. To address this, we propose FreqDebias, a
frequency debiasing framework that mitigates spectral bias through two
complementary strategies. First, we introduce a novel Forgery Mixup (Fo-Mixup)
augmentation, which dynamically diversifies frequency characteristics of
training samples. Second, we incorporate a dual consistency regularization
(CR), which enforces both local consistency using class activation maps (CAMs)
and global consistency through a von Mises-Fisher (vMF) distribution on a
hyperspherical embedding space. This dual CR mitigates over-reliance on certain
frequency components by promoting consistent representation learning under both
local and global supervision. Extensive experiments show that FreqDebias
significantly enhances cross-domain generalization and outperforms
state-of-the-art methods in both cross-domain and in-domain settings.

</details>


### [134] [LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer](https://arxiv.org/abs/2509.22414)
*Song Fei,Tian Ye,Lujia Wang,Lei Zhu*

Main category: cs.CV

TL;DR: LucidFlux是一个无需文本提示的通用图像恢复框架，它通过注入输入图像和代理恢复图像的信号，并采用多层调制策略，能够保留全局结构并恢复纹理，在各种基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图像恢复方法在处理未知混合退化时，容易出现过度平滑、产生幻觉或语义漂移等问题，尤其是在判别性恢复器和基于UNet的扩散先验模型中。

Method: LucidFlux通过一个轻量级的双分支条件器注入退化输入和轻度恢复代理的信号，分别用于锚定几何和抑制伪影。然后，设计了一个时间步长和层自适应的调制方案，将这些线索路由到骨干网络的层级结构中，以实现从粗到精、感知上下文的更新，从而在恢复纹理的同时保护全局结构。此外，通过从代理中提取的SigLIP特征来强制执行无字幕语义对齐，以避免文本提示或多模态大语言模型（MLLM）字幕的延迟和不稳定性。最后，使用可扩展的数据处理流程对大规模数据进行筛选，以获得富含结构的监督信息。

Result: 在合成和真实图像基准测试中，LucidFlux的性能持续优于强大的开源和商业基线模型。消融研究验证了每个组件的必要性。

Conclusion: 对于大型扩散Transformer（DiT）模型而言，关键在于如何、何时以及在何处进行条件约束，而不是增加参数数量或依赖文本提示。这种方法是实现鲁棒且无字幕的通用图像恢复的关键。

Abstract: Universal image restoration (UIR) aims to recover images degraded by unknown
mixtures while preserving semantics -- conditions under which discriminative
restorers and UNet-based diffusion priors often oversmooth, hallucinate, or
drift. We present LucidFlux, a caption-free UIR framework that adapts a large
diffusion transformer (Flux.1) without image captions. LucidFlux introduces a
lightweight dual-branch conditioner that injects signals from the degraded
input and a lightly restored proxy to respectively anchor geometry and suppress
artifacts. Then, a timestep- and layer-adaptive modulation schedule is designed
to route these cues across the backbone's hierarchy, in order to yield
coarse-to-fine and context-aware updates that protect the global structure
while recovering texture. After that, to avoid the latency and instability of
text prompts or MLLM captions, we enforce caption-free semantic alignment via
SigLIP features extracted from the proxy. A scalable curation pipeline further
filters large-scale data for structure-rich supervision. Across synthetic and
in-the-wild benchmarks, LucidFlux consistently outperforms strong open-source
and commercial baselines, and ablation studies verify the necessity of each
component. LucidFlux shows that, for large DiTs, when, where, and what to
condition on -- rather than adding parameters or relying on text prompts -- is
the governing lever for robust and caption-free universal image restoration in
the wild.

</details>


### [135] [Explaining multimodal LLMs via intra-modal token interactions](https://arxiv.org/abs/2509.22415)
*Jiawei Liang,Ruoyu Chen,Xianghao Jiao,Siyuan Liang,Shiming Liu,Qunli Zhang,Zheng Hu,Xiaochun Cao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable success
across diverse vision-language tasks, yet their internal decision-making
mechanisms remain insufficiently understood. Existing interpretability research
has primarily focused on cross-modal attribution, identifying which image
regions the model attends to during output generation. However, these
approaches often overlook intra-modal dependencies. In the visual modality,
attributing importance to isolated image patches ignores spatial context due to
limited receptive fields, resulting in fragmented and noisy explanations. In
the textual modality, reliance on preceding tokens introduces spurious
activations. Failing to effectively mitigate these interference compromises
attribution fidelity. To address these limitations, we propose enhancing
interpretability by leveraging intra-modal interaction. For the visual branch,
we introduce \textit{Multi-Scale Explanation Aggregation} (MSEA), which
aggregates attributions over multi-scale inputs to dynamically adjust receptive
fields, producing more holistic and spatially coherent visual explanations. For
the textual branch, we propose \textit{Activation Ranking Correlation} (ARC),
which measures the relevance of contextual tokens to the current token via
alignment of their top-$k$ prediction rankings. ARC leverages this relevance to
suppress spurious activations from irrelevant contexts while preserving
semantically coherent ones. Extensive experiments across state-of-the-art MLLMs
and benchmark datasets demonstrate that our approach consistently outperforms
existing interpretability methods, yielding more faithful and fine-grained
explanations of model behavior.

</details>


### [136] [U-MAN: U-Net with Multi-scale Adaptive KAN Network for Medical Image Segmentation](https://arxiv.org/abs/2509.22444)
*Bohan Huang,Qianyun Bao,Haoyuan Ma*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Medical image segmentation faces significant challenges in preserving
fine-grained details and precise boundaries due to complex anatomical
structures and pathological regions. These challenges primarily stem from two
key limitations of conventional U-Net architectures: (1) their simple skip
connections ignore the encoder-decoder semantic gap between various features,
and (2) they lack the capability for multi-scale feature extraction in deep
layers. To address these challenges, we propose the U-Net with Multi-scale
Adaptive KAN (U-MAN), a novel architecture that enhances the emerging
Kolmogorov-Arnold Network (KAN) with two specialized modules: Progressive
Attention-Guided Feature Fusion (PAGF) and the Multi-scale Adaptive KAN (MAN).
Our PAGF module replaces the simple skip connection, using attention to fuse
features from the encoder and decoder. The MAN module enables the network to
adaptively process features at multiple scales, improving its ability to
segment objects of various sizes. Experiments on three public datasets (BUSI,
GLAS, and CVC) show that U-MAN outperforms state-of-the-art methods,
particularly in defining accurate boundaries and preserving fine details.

</details>


### [137] [Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting](https://arxiv.org/abs/2509.22615)
*Yasmine Omri,Connor Ding,Tsachy Weissman,Thierry Tambe*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Modern vision language pipelines are driven by RGB vision encoders trained on
massive image text corpora. While these pipelines have enabled impressive zero
shot capabilities and strong transfer across tasks, they still inherit two
structural inefficiencies from the pixel domain: (i) transmitting dense RGB
images from edge devices to the cloud is energy intensive and costly, and (ii)
patch based tokenization explodes sequence length, stressing attention budgets
and context limits. We explore 2D Gaussian Splatting (2DGS) as an alternative
visual substrate for alignment: a compact, spatially adaptive representation
that parameterizes images by a set of colored anisotropic Gaussians. We develop
a scalable 2DGS pipeline with structured initialization, luminance aware
pruning, and batched CUDA kernels, achieving over 90x faster fitting and about
97% GPU utilization compared to prior implementations. We further adapt
contrastive language image pretraining (CLIP) to 2DGS by reusing a frozen
RGB-based transformer backbone with a lightweight splat aware input stem and a
perceiver resampler, training only about 7% of the total parameters. On large
DataComp subsets, GS encoders yield meaningful zero shot ImageNet-1K
performance while compressing inputs 3 to 20x relative to pixels. While
accuracy currently trails RGB encoders, our results establish 2DGS as a viable
multimodal substrate, pinpoint architectural bottlenecks, and open a path
toward representations that are both semantically powerful and transmission
efficient for edge cloud learning.

</details>


### [138] [$γ$-Quant: Towards Learnable Quantization for Low-bit Pattern Recognition](https://arxiv.org/abs/2509.22448)
*Mishal Fatima,Shashank Agnihotri,Marius Bock,Kanchana Vaishnavi Gandikota,Kristof Van Laerhoven,Michael Moeller,Margret Keuper*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Most pattern recognition models are developed on pre-proce\-ssed data. In
computer vision, for instance, RGB images processed through image signal
processing (ISP) pipelines designed to cater to human perception are the most
frequent input to image analysis networks. However, many modern vision tasks
operate without a human in the loop, raising the question of whether such
pre-processing is optimal for automated analysis. Similarly, human activity
recognition (HAR) on body-worn sensor data commonly takes normalized
floating-point data arising from a high-bit analog-to-digital converter (ADC)
as an input, despite such an approach being highly inefficient in terms of data
transmission, significantly affecting the battery life of wearable devices. In
this work, we target low-bandwidth and energy-constrained settings where
sensors are limited to low-bit-depth capture. We propose $\gamma$-Quant,
i.e.~the task-specific learning of a non-linear quantization for pattern
recognition. We exemplify our approach on raw-image object detection as well as
HAR of wearable data, and demonstrate that raw data with a learnable
quantization using as few as 4-bits can perform on par with the use of raw
12-bit data. All code to reproduce our experiments is publicly available via
https://github.com/Mishalfatima/Gamma-Quant

</details>


### [139] [SSVIF: Self-Supervised Segmentation-Oriented Visible and Infrared Image Fusion](https://arxiv.org/abs/2509.22450)
*Zixian Zhao,Xingchen Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为SSVIF的自监督训练框架，用于可见光和红外图像融合（VIF）的分割任务，无需分割标签，性能优于传统VIF方法，并可与监督方法相媲美。


<details>
  <summary>Details</summary>
Motivation: 传统的可见光和红外图像融合（VIF）方法主要关注融合图像质量，而应用导向的方法需要下游任务的标注数据，获取成本高。现有方法需要针对特定下游任务（如语义分割）进行监督训练，这需要大量的标注数据。

Method: 提出了一种名为SSVIF的自监督训练框架，利用特征级融合分割与像素级融合分割之间的一致性，引入了任务-交叉分割一致性自监督任务，使融合模型能够学习高层语义特征，而无需分割标签的监督。此外，还设计了分阶段训练策略和动态权重调整方法。

Result: 在公共数据集上的大量实验证明了SSVIF的有效性。SSVIF在仅使用未标记的可见光-红外图像对进行训练的情况下，其性能优于传统的VIF方法，并能与监督分割导向的方法相媲美。

Conclusion: SSVIF通过引入任务-交叉分割一致性自监督任务，解决了应用导向VIF方法对标注数据依赖的问题，实现了在无监督情况下进行分割导向的VIF，并取得了优于传统方法和可比于监督方法的性能。

Abstract: Visible and infrared image fusion (VIF) has gained significant attention in
recent years due to its wide application in tasks such as scene segmentation
and object detection. VIF methods can be broadly classified into traditional
VIF methods and application-oriented VIF methods. Traditional methods focus
solely on improving the quality of fused images, while application-oriented VIF
methods additionally consider the performance of downstream tasks on fused
images by introducing task-specific loss terms during training. However,
compared to traditional methods, application-oriented VIF methods require
datasets labeled for downstream tasks (e.g., semantic segmentation or object
detection), making data acquisition labor-intensive and time-consuming. To
address this issue, we propose a self-supervised training framework for
segmentation-oriented VIF methods (SSVIF). Leveraging the consistency between
feature-level fusion-based segmentation and pixel-level fusion-based
segmentation, we introduce a novel self-supervised task-cross-segmentation
consistency-that enables the fusion model to learn high-level semantic features
without the supervision of segmentation labels. Additionally, we design a
two-stage training strategy and a dynamic weight adjustment method for
effective joint learning within our self-supervised framework. Extensive
experiments on public datasets demonstrate the effectiveness of our proposed
SSVIF. Remarkably, although trained only on unlabeled visible-infrared image
pairs, our SSVIF outperforms traditional VIF methods and rivals supervised
segmentation-oriented ones. Our code will be released upon acceptance.

</details>


### [140] [LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision](https://arxiv.org/abs/2509.22631)
*Debargha Ganguly,Sumit Kumar,Ishwar Balappanawar,Weicong Chen,Shashank Kambhatla,Srinivasan Iyengar,Shivkumar Kalyanaraman,Ponnurangam Kumaraguru,Vipin Chaudhary*

Main category: cs.CV

TL;DR: Labeling Copilot是一个用于计算机视觉的数据集策划深度研究代理，通过结合数据发现、可控合成和共识标注来提高数据质量、多样性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有高质量、领域特定的数据集在视觉系统中部署时存在瓶颈，需要在数据质量、多样性和成本之间进行权衡。

Method: 引入Labeling Copilot，一个由大型多模态语言模型驱动的中央协调代理，利用多步推理执行专门工具，包括：1.校准发现（Calibrated Discovery）从大型存储库中发现相关、分布内数据；2.可控合成（Controllable Synthesis）生成稀有场景的新数据；3.共识标注（Consensus Annotation）通过协调多个基础模型和新颖的共识机制（包括非最大抑制和投票）来生成准确的标签。

Result: Labeling Copilot的组件被大规模验证。共识标注模块在COCO数据集上平均每个图像产生14.2个候选提议，最终标注mAP达到37.1%。在Open Images数据集上，它发现了903个新的边界框类别。校准发现工具在1000万样本规模下，其主动学习策略比替代方法具有更高的计算效率（高达40倍）。

Conclusion: 通过优化和可扩展的工具实现代理工作流程，为工业规模的数据集策划提供了坚实的基础。

Abstract: Curating high-quality, domain-specific datasets is a major bottleneck for
deploying robust vision systems, requiring complex trade-offs between data
quality, diversity, and cost when researching vast, unlabeled data lakes. We
introduce Labeling Copilot, the first data curation deep research agent for
computer vision. A central orchestrator agent, powered by a large multimodal
language model, uses multi-step reasoning to execute specialized tools across
three core capabilities: (1) Calibrated Discovery sources relevant,
in-distribution data from large repositories; (2) Controllable Synthesis
generates novel data for rare scenarios with robust filtering; and (3)
Consensus Annotation produces accurate labels by orchestrating multiple
foundation models via a novel consensus mechanism incorporating non-maximum
suppression and voting. Our large-scale validation proves the effectiveness of
Labeling Copilot's components. The Consensus Annotation module excels at object
discovery: on the dense COCO dataset, it averages 14.2 candidate proposals per
image-nearly double the 7.4 ground-truth objects-achieving a final annotation
mAP of 37.1%. On the web-scale Open Images dataset, it navigated extreme class
imbalance to discover 903 new bounding box categories, expanding its capability
to over 1500 total. Concurrently, our Calibrated Discovery tool, tested at a
10-million sample scale, features an active learning strategy that is up to 40x
more computationally efficient than alternatives with equivalent sample
efficiency. These experiments validate that an agentic workflow with optimized,
scalable tools provides a robust foundation for curating industrial-scale
datasets.

</details>


### [141] [Bézier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation](https://arxiv.org/abs/2509.22476)
*Chen Li,Meilong Xu,Xiaoling Hu,Weimin Lyu,Chao Chen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Training robust learning algorithms across different medical imaging
modalities is challenging due to the large domain gap. Unsupervised domain
adaptation (UDA) mitigates this problem by using annotated images from the
source domain and unlabeled images from the target domain to train the deep
models. Existing approaches often rely on GAN-based style transfer, but these
methods struggle to capture cross-domain mappings in regions with high
variability. In this paper, we propose a unified framework, B\'ezier Meets
Diffusion, for cross-domain image generation. First, we introduce a
B\'ezier-curve-based style transfer strategy that effectively reduces the
domain gap between source and target domains. The transferred source images
enable the training of a more robust segmentation model across domains.
Thereafter, using pseudo-labels generated by this segmentation model on the
target domain, we train a conditional diffusion model (CDM) to synthesize
high-quality, labeled target-domain images. To mitigate the impact of noisy
pseudo-labels, we further develop an uncertainty-guided score matching method
that improves the robustness of CDM training. Extensive experiments on public
datasets demonstrate that our approach generates realistic labeled images,
significantly augmenting the target domain and improving segmentation
performance.

</details>


### [142] [Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs](https://arxiv.org/abs/2509.22646)
*Xingyu Fu,Siyi Liu,Yinuo Xu,Pan Lu,Guangqiuse Hu,Tianbo Yang,Taran Anantasagar,Christopher Shen,Yikai Mao,Yuanzhe Liu,Keyush Shah,Chung Un Lee,Yejin Choi,James Zou,Dan Roth,Chris Callison-Burch*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Can humans identify AI-generated (fake) videos and provide grounded reasons?
While video generation models have advanced rapidly, a critical dimension --
whether humans can detect deepfake traces within a generated video, i.e.,
spatiotemporal grounded visual artifacts that reveal a video as machine
generated -- has been largely overlooked. We introduce DeeptraceReward, the
first fine-grained, spatially- and temporally- aware benchmark that annotates
human-perceived fake traces for video generation reward. The dataset comprises
4.3K detailed annotations across 3.3K high-quality generated videos. Each
annotation provides a natural-language explanation, pinpoints a bounding-box
region containing the perceived trace, and marks precise onset and offset
timestamps. We consolidate these annotations into 9 major categories of
deepfake traces that lead humans to identify a video as AI-generated, and train
multimodal language models (LMs) as reward models to mimic human judgments and
localizations. On DeeptraceReward, our 7B reward model outperforms GPT-5 by
34.7% on average across fake clue identification, grounding, and explanation.
Interestingly, we observe a consistent difficulty gradient: binary fake v.s.
real classification is substantially easier than fine-grained deepfake trace
detection; within the latter, performance degrades from natural language
explanations (easiest), to spatial grounding, to temporal labeling (hardest).
By foregrounding human-perceived deepfake traces, DeeptraceReward provides a
rigorous testbed and training signal for socially aware and trustworthy video
generation.

</details>


### [143] [PSTTS: A Plug-and-Play Token Selector for Efficient Event-based Spatio-temporal Representation Learning](https://arxiv.org/abs/2509.22481)
*Xiangmo Zhao,Nan Yang,Yang Wang,Zhanwen Liu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Mainstream event-based spatio-temporal representation learning methods
typically process event streams by converting them into sequences of event
frames, achieving remarkable performance. However, they neglect the high
spatial sparsity and inter-frame motion redundancy inherent in event frame
sequences, leading to significant computational overhead. Existing token
sparsification methods for RGB videos rely on unreliable intermediate token
representations and neglect the influence of event noise, making them
ineffective for direct application to event data. In this paper, we propose
Progressive Spatio-Temporal Token Selection (PSTTS), a Plug-and-Play module for
event data without introducing any additional parameters. PSTTS exploits the
spatio-temporal distribution characteristics embedded in raw event data to
effectively identify and discard spatio-temporal redundant tokens, achieving an
optimal trade-off between accuracy and efficiency. Specifically, PSTTS consists
of two stages, Spatial Token Purification and Temporal Token Selection. Spatial
Token Purification discards noise and non-event regions by assessing the
spatio-temporal consistency of events within each event frame to prevent
interference with subsequent temporal redundancy evaluation. Temporal Token
Selection evaluates the motion pattern similarity between adjacent event
frames, precisely identifying and removing redundant temporal information. We
apply PSTTS to four representative backbones UniformerV2, VideoSwin, EVMamba,
and ExACT on the HARDVS, DailyDVS-200, and SeACT datasets. Experimental results
demonstrate that PSTTS achieves significant efficiency improvements.
Specifically, PSTTS reduces FLOPs by 29-43.6% and increases FPS by 21.6-41.3%
on the DailyDVS-200 dataset, while maintaining task accuracy. Our code will be
available.

</details>


### [144] [CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning](https://arxiv.org/abs/2509.22647)
*Long Xing,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jianze Liang,Qidong Huang,Jiaqi Wang,Feng Wu,Dahua Lin*

Main category: cs.CV

TL;DR: 通过引入CapRL框架，使用RLVR范式和基于LLM的可验证奖励，解决图像描述任务中SFT的局限性，提升了模型生成多样化、高质量描述的能力。


<details>
  <summary>Details</summary>
Motivation: SFT方法在图像描述任务中依赖昂贵且不可扩展的人工标注数据，导致模型倾向于死记硬背，限制了其泛化能力和创造性。因此，需要一种新的方法来克服这些局限性。

Method: 提出CapRL训练框架，采用RLVR范式，将图像描述的质量定义为：一个高质量的描述应能使一个非视觉的语言模型准确回答关于该图像的问题。CapRL使用一个两阶段的解耦流程：首先由LVLM生成描述，然后通过一个不依赖视觉信息的LLM根据该描述回答多项选择题的准确性来获得客观奖励。

Result: CapRL在12个基准测试中显著提升了性能。使用CapRL-5M数据集和CapRL-3B进行预训练，在Prism框架下的评估中，CapRL的表现与Qwen2.5-VL-72B相当，并平均超出基线8.4%。

Conclusion: CapRL作为首个将RLVR应用于主观性强的图像描述任务的研究，成功地提高了图像描述的质量和模型的泛化能力。

Abstract: Image captioning is a fundamental task that bridges the visual and linguistic
domains, playing a critical role in pre-training Large Vision-Language Models
(LVLMs). Current state-of-the-art captioning models are typically trained with
Supervised Fine-Tuning (SFT), a paradigm that relies on expensive, non-scalable
data annotated by humans or proprietary models. This approach often leads to
models that memorize specific ground-truth answers, limiting their generality
and ability to generate diverse, creative descriptions. To overcome the
limitation of SFT, we propose applying the Reinforcement Learning with
Verifiable Rewards (RLVR) paradigm to the open-ended task of image captioning.
A primary challenge, however, is designing an objective reward function for the
inherently subjective nature of what constitutes a "good" caption. We introduce
Captioning Reinforcement Learning (CapRL), a novel training framework that
redefines caption quality through its utility: a high-quality caption should
enable a non-visual language model to accurately answer questions about the
corresponding image. CapRL employs a decoupled two-stage pipeline where an LVLM
generates a caption, and the objective reward is derived from the accuracy of a
separate, vision-free LLM answering Multiple-Choice Questions based solely on
that caption. As the first study to apply RLVR to the subjective image
captioning task, we demonstrate that CapRL significantly enhances multiple
settings. Pretraining on the CapRL-5M caption dataset annotated by CapRL-3B
results in substantial gains across 12 benchmarks. Moreover, within the Prism
Framework for caption quality evaluation, CapRL achieves performance comparable
to Qwen2.5-VL-72B, while exceeding the baseline by an average margin of 8.4%.
Code is available here: https://github.com/InternLM/CapRL.

</details>


### [145] [Group Critical-token Policy Optimization for Autoregressive Image Generation](https://arxiv.org/abs/2509.22485)
*Guohui Zhang,Hu Yu,Xiaoxiao Ma,JingHao Zhang,Yaning Pan,Mingde Yao,Jie Xiao,Linjiang Huang,Feng Zhao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent studies have extended Reinforcement Learning with Verifiable Rewards
(RLVR) to autoregressive (AR) visual generation and achieved promising
progress. However, existing methods typically apply uniform optimization across
all image tokens, while the varying contributions of different image tokens for
RLVR's training remain unexplored. In fact, the key obstacle lies in how to
identify more critical image tokens during AR generation and implement
effective token-wise optimization for them. To tackle this challenge, we
propose $\textbf{G}$roup $\textbf{C}$ritical-token $\textbf{P}$olicy
$\textbf{O}$ptimization ($\textbf{GCPO}$), which facilitates effective policy
optimization on critical tokens. We identify the critical tokens in RLVR-based
AR generation from three perspectives, specifically: $\textbf{(1)}$ Causal
dependency: early tokens fundamentally determine the later tokens and final
image effect due to unidirectional dependency; $\textbf{(2)}$ Entropy-induced
spatial structure: tokens with high entropy gradients correspond to image
structure and bridges distinct visual regions; $\textbf{(3)}$ RLVR-focused
token diversity: tokens with low visual similarity across a group of sampled
images contribute to richer token-level diversity. For these identified
critical tokens, we further introduce a dynamic token-wise advantage weight to
encourage exploration, based on confidence divergence between the policy model
and reference model. By leveraging 30\% of the image tokens, GCPO achieves
better performance than GRPO with full tokens. Extensive experiments on
multiple text-to-image benchmarks for both AR models and unified multimodal
models demonstrate the effectiveness of GCPO for AR visual generation.

</details>


### [146] [Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation](https://arxiv.org/abs/2509.22496)
*Ruoyu Chen,Xiaoqing Guo,Kangwei Liu,Siyuan Liang,Shiming Liu,Qunli Zhang,Hua Zhang,Xiaochun Cao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal large language models (MLLMs) have demonstrated remarkable
capabilities in aligning visual inputs with natural language outputs. Yet, the
extent to which generated tokens depend on visual modalities remains poorly
understood, limiting interpretability and reliability. In this work, we present
EAGLE, a lightweight black-box framework for explaining autoregressive token
generation in MLLMs. EAGLE attributes any selected tokens to compact perceptual
regions while quantifying the relative influence of language priors and
perceptual evidence. The framework introduces an objective function that
unifies sufficiency (insight score) and indispensability (necessity score),
optimized via greedy search over sparsified image regions for faithful and
efficient attribution. Beyond spatial attribution, EAGLE performs
modality-aware analysis that disentangles what tokens rely on, providing
fine-grained interpretability of model decisions. Extensive experiments across
open-source MLLMs show that EAGLE consistently outperforms existing methods in
faithfulness, localization, and hallucination diagnosis, while requiring
substantially less GPU memory. These results highlight its effectiveness and
practicality for advancing the interpretability of MLLMs. The code is available
at https://github.com/RuoyuChen10/EAGLE.

</details>


### [147] [Color Names in Vision-Language Models](https://arxiv.org/abs/2509.22524)
*Alexandra Gomez-Villa,Pablo Hernández-Cámara,Muhammad Atif Butt,Valero Laparra,Jesus Malo,Javier Vazquez-Corral*

Main category: cs.CV

TL;DR: 研究评估了视觉语言模型（VLM）的颜色命名能力，发现它们在原型颜色上表现良好，但在非原型颜色上表现不佳，并识别出21个通用颜色术语。


<details>
  <summary>Details</summary>
Motivation: 为了评估和理解视觉语言模型（VLM）在颜色命名方面的能力，以及这对人机交互的重要性。

Method: 使用957个颜色样本，复制了经典的颜色命名方法学，并对五个代表性模型进行了评估，随后进行了跨语言分析和消融研究。

Result: VLM在原型颜色上准确率高，但在非原型颜色上准确率显著下降；识别出21个跨模型共有的颜色术语；发现模型在语言（英语和中文）训练上存在不平衡；色调是颜色命名决策的主要驱动因素；语言模型架构影响颜色命名。 

Conclusion: 视觉语言模型（VLM）的颜色命名能力存在局限性，尤其在处理非原型颜色和跨语言能力方面。模型架构对颜色命名有显著影响，训练数据的语言偏见也需要关注。

Abstract: Color serves as a fundamental dimension of human visual perception and a
primary means of communicating about objects and scenes. As vision-language
models (VLMs) become increasingly prevalent, understanding whether they name
colors like humans is crucial for effective human-AI interaction. We present
the first systematic evaluation of color naming capabilities across VLMs,
replicating classic color naming methodologies using 957 color samples across
five representative models. Our results show that while VLMs achieve high
accuracy on prototypical colors from classical studies, performance drops
significantly on expanded, non-prototypical color sets. We identify 21 common
color terms that consistently emerge across all models, revealing two distinct
approaches: constrained models using predominantly basic terms versus expansive
models employing systematic lightness modifiers. Cross-linguistic analysis
across nine languages demonstrates severe training imbalances favoring English
and Chinese, with hue serving as the primary driver of color naming decisions.
Finally, ablation studies reveal that language model architecture significantly
influences color naming independent of visual processing capabilities.

</details>


### [148] [EfficientDepth: A Fast and Detail-Preserving Monocular Depth Estimation Model](https://arxiv.org/abs/2509.22527)
*Andrii Litvynchuk,Ivan Livinsky,Anand Ravi,Nima Kalantari,Andrii Tsarov*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Monocular depth estimation (MDE) plays a pivotal role in various computer
vision applications, such as robotics, augmented reality, and autonomous
driving. Despite recent advancements, existing methods often fail to meet key
requirements for 3D reconstruction and view synthesis, including geometric
consistency, fine details, robustness to real-world challenges like reflective
surfaces, and efficiency for edge devices. To address these challenges, we
introduce a novel MDE system, called EfficientDepth, which combines a
transformer architecture with a lightweight convolutional decoder, as well as a
bimodal density head that allows the network to estimate detailed depth maps.
We train our model on a combination of labeled synthetic and real images, as
well as pseudo-labeled real images, generated using a high-performing MDE
method. Furthermore, we employ a multi-stage optimization strategy to improve
training efficiency and produce models that emphasize geometric consistency and
fine detail. Finally, in addition to commonly used objectives, we introduce a
loss function based on LPIPS to encourage the network to produce detailed depth
maps. Experimental results demonstrate that EfficientDepth achieves performance
comparable to or better than existing state-of-the-art models, with
significantly reduced computational resources.

</details>


### [149] [Category Discovery: An Open-World Perspective](https://arxiv.org/abs/2509.22542)
*Zhenqi He,Yuanpei Liu,Kai Han*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Category discovery (CD) is an emerging open-world learning task, which aims
at automatically categorizing unlabelled data containing instances from unseen
classes, given some labelled data from seen classes. This task has attracted
significant attention over the years and leads to a rich body of literature
trying to address the problem from different perspectives. In this survey, we
provide a comprehensive review of the literature, and offer detailed analysis
and in-depth discussion on different methods. Firstly, we introduce a taxonomy
for the literature by considering two base settings, namely novel category
discovery (NCD) and generalized category discovery (GCD), and several derived
settings that are designed to address the extra challenges in different
real-world application scenarios, including continual category discovery,
skewed data distribution, federated category discovery, etc. Secondly, for each
setting, we offer a detailed analysis of the methods encompassing three
fundamental components, representation learning, label assignment, and
estimation of class number. Thirdly, we benchmark all the methods and distill
key insights showing that large-scale pretrained backbones, hierarchical and
auxiliary cues, and curriculum-style training are all beneficial for category
discovery, while challenges remain in the design of label assignment, the
estimation of class numbers, and scaling to complex multi-object
scenarios.Finally, we discuss the key insights from the literature so far and
point out promising future research directions. We compile a living survey of
the category discovery literature at
\href{https://github.com/Visual-AI/Category-Discovery}{https://github.com/Visual-AI/Category-Discovery}.

</details>


### [150] [HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection](https://arxiv.org/abs/2509.22544)
*Mohammad Mahdi Hemmatyar,Mahdi Jafari,Mohammad Amin Yousefi,Mohammad Reza Nemati,Mobin Azadani,Hamid Reza Rastad,Amirmohammad Akbari*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Video anomaly detection (VAD) is crucial for intelligent surveillance, but a
significant challenge lies in identifying complex anomalies, which are events
defined by intricate relationships and temporal dependencies among multiple
entities rather than by isolated actions. While self-supervised learning (SSL)
methods effectively model low-level spatiotemporal patterns, they often
struggle to grasp the semantic meaning of these interactions. Conversely, large
language models (LLMs) offer powerful contextual reasoning but are
computationally expensive for frame-by-frame analysis and lack fine-grained
spatial localization. We introduce HyCoVAD, Hybrid Complex Video Anomaly
Detection, a hybrid SSL-LLM model that combines a multi-task SSL temporal
analyzer with LLM validator. The SSL module is built upon an nnFormer backbone
which is a transformer-based model for image segmentation. It is trained with
multiple proxy tasks, learns from video frames to identify those suspected of
anomaly. The selected frames are then forwarded to the LLM, which enriches the
analysis with semantic context by applying structured, rule-based reasoning to
validate the presence of anomalies. Experiments on the challenging ComplexVAD
dataset show that HyCoVAD achieves a 72.5% frame-level AUC, outperforming
existing baselines by 12.5% while reducing LLM computation. We release our
interaction anomaly taxonomy, adaptive thresholding protocol, and code to
facilitate future research in complex VAD scenarios.

</details>


### [151] [SpikeMatch: Semi-Supervised Learning with Temporal Dynamics of Spiking Neural Networks](https://arxiv.org/abs/2509.22581)
*Jini Yang,Beomseok Oh,Seungryong Kim,Sunok Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Spiking neural networks (SNNs) have recently been attracting significant
attention for their biological plausibility and energy efficiency, but
semi-supervised learning (SSL) methods for SNN-based models remain
underexplored compared to those for artificial neural networks (ANNs). In this
paper, we introduce SpikeMatch, the first SSL framework for SNNs that leverages
the temporal dynamics through the leakage factor of SNNs for diverse
pseudo-labeling within a co-training framework. By utilizing agreement among
multiple predictions from a single SNN, SpikeMatch generates reliable
pseudo-labels from weakly-augmented unlabeled samples to train on
strongly-augmented ones, effectively mitigating confirmation bias by capturing
discriminative features with limited labels. Experiments show that SpikeMatch
outperforms existing SSL methods adapted to SNN backbones across various
standard benchmarks.

</details>


### [152] [LongLive: Real-time Interactive Long Video Generation](https://arxiv.org/abs/2509.22622)
*Shuai Yang,Wei Huang,Ruihang Chu,Yicheng Xiao,Yuyang Zhao,Xianbang Wang,Muyang Li,Enze Xie,Yingcong Chen,Yao Lu,Song Han,Yukang Chen*

Main category: cs.CV

TL;DR: LongLive是一个创新的视频生成框架，通过其独特的帧级自回归设计、KV-recache机制、流式长调优和短窗口注意力等技术，实现了高效、高质量的长视频生成，并支持实时交互式内容创作。


<details>
  <summary>Details</summary>
Motivation: 长视频生成在效率和质量上面临严峻挑战，现有的扩散模型效率低下，而自回归模型在长视频训练时存在内存问题。此外，实时交互式生成能力对于动态内容创作至关重要，但增加了确保视觉和语义一致性的复杂性。

Method: LongLive采用帧级自回归设计，集成KV-recache机制以实现平滑的提示切换；通过流式长调优实现长视频训练并对齐训练与推理（train-long-test-long）；利用短窗口注意力和帧级注意力沉（frame sink）来保持长程一致性并加速生成。

Result: LongLive在32个GPU日内将一个1.3B参数的短视频模型微调至分钟级生成能力。在推理时，其在NVIDIA H100上实现了20.7 FPS的速率，在VBench短视频和长视频评估中均表现强劲，并支持单张H100 GPU生成长达240秒的视频，INT8量化推理仅带来微小的质量损失。

Conclusion: LongLive成功解决了长视频生成中的效率和质量难题，并通过创新的机制实现了高效、高质量且支持实时交互的长视频生成。

Abstract: We present LongLive, a frame-level autoregressive (AR) framework for
real-time and interactive long video generation. Long video generation presents
challenges in both efficiency and quality. Diffusion and Diffusion-Forcing
models can produce high-quality videos but suffer from low efficiency due to
bidirectional attention. Causal attention AR models support KV caching for
faster inference, but often degrade in quality on long videos due to memory
challenges during long-video training. In addition, beyond static prompt-based
generation, interactive capabilities, such as streaming prompt inputs, are
critical for dynamic content creation, enabling users to guide narratives in
real time. This interactive requirement significantly increases complexity,
especially in ensuring visual consistency and semantic coherence during prompt
transitions. To address these challenges, LongLive adopts a causal, frame-level
AR design that integrates a KV-recache mechanism that refreshes cached states
with new prompts for smooth, adherent switches; streaming long tuning to enable
long video training and to align training and inference (train-long-test-long);
and short window attention paired with a frame-level attention sink, shorten as
frame sink, preserving long-range consistency while enabling faster generation.
With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model
to minute-long generation in just 32 GPU-days. At inference, LongLive sustains
20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both
short and long videos. LongLive supports up to 240-second videos on a single
H100 GPU. LongLive further supports INT8-quantized inference with only marginal
quality loss.

</details>


### [153] [SPARK: Synergistic Policy And Reward Co-Evolving Framework](https://arxiv.org/abs/2509.22624)
*Ziyu Liu,Yuhang Zang,Shengyuan Ding,Yuhang Cao,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent Large Language Models (LLMs) and Large Vision-Language Models (LVLMs)
increasingly use Reinforcement Learning (RL) for post-pretraining, such as RL
with Verifiable Rewards (RLVR) for objective tasks and RL from Human Feedback
(RLHF) for subjective tasks. However, RLHF incurs high costs and potential
reward-policy mismatch due to reliance on human preferences, while RLVR still
wastes supervision by discarding rollouts and correctness signals after each
update. To address these challenges, we introduce the Synergistic Policy And
Reward Co-Evolving Framework (SPARK), an efficient, on-policy, and stable
method that builds on RLVR. Instead of discarding rollouts and correctness
data, SPARK recycles this valuable information to simultaneously train the
model itself as a generative reward model. This auxiliary training uses a mix
of objectives, such as pointwise reward score, pairwise comparison, and
evaluation conditioned on further-reflection responses, to teach the model to
evaluate and improve its own responses. Our process eliminates the need for a
separate reward model and costly human preference data. SPARK creates a
positive co-evolving feedback loop: improved reward accuracy yields better
policy gradients, which in turn produce higher-quality rollouts that further
refine the reward model. Our unified framework supports test-time scaling via
self-reflection without external reward models and their associated costs. We
show that SPARK achieves significant performance gains on multiple LLM and LVLM
models and multiple reasoning, reward models, and general benchmarks. For
example, SPARK-VL-7B achieves an average 9.7% gain on 7 reasoning benchmarks,
12.1% on 2 reward benchmarks, and 1.5% on 8 general benchmarks over the
baselines, demonstrating robustness and broad generalization.

</details>


### [154] [CCNeXt: An Effective Self-Supervised Stereo Depth Estimation Approach](https://arxiv.org/abs/2509.22627)
*Alexandre Lopes,Roberto Souza,Helio Pedrini*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Depth Estimation plays a crucial role in recent applications in robotics,
autonomous vehicles, and augmented reality. These scenarios commonly operate
under constraints imposed by computational power. Stereo image pairs offer an
effective solution for depth estimation since it only needs to estimate the
disparity of pixels in image pairs to determine the depth in a known rectified
system. Due to the difficulty in acquiring reliable ground-truth depth data
across diverse scenarios, self-supervised techniques emerge as a solution,
particularly when large unlabeled datasets are available. We propose a novel
self-supervised convolutional approach that outperforms existing
state-of-the-art Convolutional Neural Networks (CNNs) and Vision Transformers
(ViTs) while balancing computational cost. The proposed CCNeXt architecture
employs a modern CNN feature extractor with a novel windowed epipolar
cross-attention module in the encoder, complemented by a comprehensive redesign
of the depth estimation decoder. Our experiments demonstrate that CCNeXt
achieves competitive metrics on the KITTI Eigen Split test data while being
10.18$\times$ faster than the current best model and achieves state-of-the-art
results in all metrics in the KITTI Eigen Split Improved Ground Truth and
Driving Stereo datasets when compared to recently proposed techniques. To
ensure complete reproducibility, our project is accessible at
\href{https://github.com/alelopes/CCNext}{\texttt{https://github.com/alelopes/CCNext}}.

</details>


### [155] [UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning](https://arxiv.org/abs/2509.22628)
*Hongyu Chen,Guangrun Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Chain-of-Thought (CoT) prompting improves reasoning in large language models
(LLMs), but its reliance on unstructured text limits interpretability and
executability in embodied tasks. Prior work has explored structured CoTs using
scene or logic graphs, yet these remain fundamentally limited: they model only
low-order relations, lack constructs like inheritance or behavioral
abstraction, and provide no standardized semantics for sequential or
conditional planning. We propose UML-CoT, a structured reasoning and planning
framework that leverages Unified Modeling Language (UML) to generate symbolic
CoTs and executable action plans. UML class diagrams capture compositional
object semantics, while activity diagrams model procedural control flow. Our
three-stage training pipeline combines supervised fine-tuning with Group
Relative Policy Optimization (GRPO), including reward learning from answer-only
data. We evaluate UML-CoT on MRoom-30k, a new benchmark of cluttered
room-cleaning scenarios. UML-CoT outperforms unstructured CoTs in
interpretability, planning coherence, and execution success, highlighting UML
as a more expressive and actionable structured reasoning formalism.

</details>


### [156] [Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance](https://arxiv.org/abs/2509.22635)
*Luc Boudier,Loris Manganelli,Eleftherios Tsonis,Nicolas Dufour,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: DIPSY是一种无需微调的少样本图像分类方法，利用IP-Adapter生成合成图像，通过扩展的无分类器指导和基于类相似性的采样策略提高了区分度。


<details>
  <summary>Details</summary>
Motivation: 少样本图像分类因标注数据有限而具有挑战性。现有方法常依赖模型微调或外部信息生成合成数据。

Method: DIPSY提出了一种新的训练无关方法，利用IP-Adapter进行图像到图像的翻译，并引入了扩展的无分类器指导和基于类相似性的采样策略来生成合成图像。

Result: 在十个基准数据集上的实验表明，DIPSY在少样本图像分类任务上达到了最先进或相当的性能，尤其在细粒度分类任务上表现出色。

Conclusion: DIPSY通过利用正负双图像提示和指导，有效地生成了具有区分度的合成图像，解决了少样本图像分类的挑战，且无需微调或外部工具。

Abstract: Few-shot image classification remains challenging due to the limited
availability of labeled examples. Recent approaches have explored generating
synthetic training data using text-to-image diffusion models, but often require
extensive model fine-tuning or external information sources. We present a novel
training-free approach, called DIPSY, that leverages IP-Adapter for
image-to-image translation to generate highly discriminative synthetic images
using only the available few-shot examples. DIPSY introduces three key
innovations: (1) an extended classifier-free guidance scheme that enables
independent control over positive and negative image conditioning; (2) a class
similarity-based sampling strategy that identifies effective contrastive
examples; and (3) a simple yet effective pipeline that requires no model
fine-tuning or external captioning and filtering. Experiments across ten
benchmark datasets demonstrate that our approach achieves state-of-the-art or
comparable performance, while eliminating the need for generative model
adaptation or reliance on external tools for caption generation and image
filtering. Our results highlight the effectiveness of leveraging dual image
prompting with positive-negative guidance for generating class-discriminative
features, particularly for fine-grained classification tasks.

</details>


### [157] [Scale-Wise VAR is Secretly Discrete Diffusion](https://arxiv.org/abs/2509.22636)
*Amandeep Kumar,Nithin Gopalakrishnan Nair,Vishal M. Patel*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Autoregressive (AR) transformers have emerged as a powerful paradigm for
visual generation, largely due to their scalability, computational efficiency
and unified architecture with language and vision. Among them, next scale
prediction Visual Autoregressive Generation (VAR) has recently demonstrated
remarkable performance, even surpassing diffusion-based models. In this work,
we revisit VAR and uncover a theoretical insight: when equipped with a
Markovian attention mask, VAR is mathematically equivalent to a discrete
diffusion. We term this reinterpretation as Scalable Visual Refinement with
Discrete Diffusion (SRDD), establishing a principled bridge between AR
transformers and diffusion models. Leveraging this new perspective, we show how
one can directly import the advantages of diffusion such as iterative
refinement and reduce architectural inefficiencies into VAR, yielding faster
convergence, lower inference cost, and improved zero-shot reconstruction.
Across multiple datasets, we show that the diffusion based perspective of VAR
leads to consistent gains in efficiency and generation.

</details>


### [158] [Hierarchical Representation Matching for CLIP-based Class-Incremental Learning](https://arxiv.org/abs/2509.22645)
*Zhen-Hao Wen,Yan Wang,Ji Feng,Han-Jia Ye,De-Chuan Zhan,Da-Wei Zhou*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Class-Incremental Learning (CIL) aims to endow models with the ability to
continuously adapt to evolving data streams. Recent advances in pre-trained
vision-language models (e.g., CLIP) provide a powerful foundation for this
task. However, existing approaches often rely on simplistic templates, such as
"a photo of a [CLASS]", which overlook the hierarchical nature of visual
concepts. For example, recognizing "cat" versus "car" depends on coarse-grained
cues, while distinguishing "cat" from "lion" requires fine-grained details.
Similarly, the current feature mapping in CLIP relies solely on the
representation from the last layer, neglecting the hierarchical information
contained in earlier layers. In this work, we introduce HiErarchical
Representation MAtchiNg (HERMAN) for CLIP-based CIL. Our approach leverages
LLMs to recursively generate discriminative textual descriptors, thereby
augmenting the semantic space with explicit hierarchical cues. These
descriptors are matched to different levels of the semantic hierarchy and
adaptively routed based on task-specific requirements, enabling precise
discrimination while alleviating catastrophic forgetting in incremental tasks.
Extensive experiments on multiple benchmarks demonstrate that our method
consistently achieves state-of-the-art performance.

</details>


### [159] [RefAM: Attention Magnets for Zero-Shot Referral Segmentation](https://arxiv.org/abs/2509.22650)
*Anna Kukleva,Enis Simsar,Alessio Tonioni,Muhammad Ferjad Naeem,Federico Tombari,Jan Eric Lenssen,Bernt Schiele*

Main category: cs.CV

TL;DR: 该研究提出了一种名为RefAM的无需训练的参考分割框架，它利用扩散Transformer中的特征和注意力分数，无需修改模型结构或进行额外训练，就能在图像和视频分割任务上取得最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要额外的训练和模型修改才能达到高精度，而大型生成扩散模型蕴含丰富的语义信息，可作为特征提取器。本研究旨在直接利用扩散Transformer的特征和注意力分数来解决下游任务，避免额外的训练和模型修改。

Method: 提出利用扩散Transformer的交叉注意力图、全局注意力汇聚点（GAS）处理以及注意力重分布策略。具体来说，利用“停词”作为注意力焦点，过滤噪声；识别并处理深层中的全局注意力汇聚点；通过追加停词将背景激活分割成更小的簇，实现更精确的分割图。

Result: 在零样本图像和视频分割基准测试中，RefAM方法在无需微调或额外组件的情况下，性能优于现有方法，并取得了新的最先进成果。

Conclusion: 所提出的RefAM框架能够有效地利用扩散Transformer的内部机制，通过简单且无需训练的方法，在参考分割任务上取得优异的性能，证明了其有效性和潜力。

Abstract: Most existing approaches to referring segmentation achieve strong performance
only through fine-tuning or by composing multiple pre-trained models, often at
the cost of additional training and architectural modifications. Meanwhile,
large-scale generative diffusion models encode rich semantic information,
making them attractive as general-purpose feature extractors. In this work, we
introduce a new method that directly exploits features, attention scores, from
diffusion transformers for downstream tasks, requiring neither architectural
modifications nor additional training. To systematically evaluate these
features, we extend benchmarks with vision-language grounding tasks spanning
both images and videos. Our key insight is that stop words act as attention
magnets: they accumulate surplus attention and can be filtered to reduce noise.
Moreover, we identify global attention sinks (GAS) emerging in deeper layers
and show that they can be safely suppressed or redirected onto auxiliary
tokens, leading to sharper and more accurate grounding maps. We further propose
an attention redistribution strategy, where appended stop words partition
background activations into smaller clusters, yielding sharper and more
localized heatmaps. Building on these findings, we develop RefAM, a simple
training-free grounding framework that combines cross-attention maps, GAS
handling, and redistribution. Across zero-shot referring image and video
segmentation benchmarks, our approach consistently outperforms prior methods,
establishing a new state of the art without fine-tuning or additional
components.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [160] [A Novel Differential Feature Learning for Effective Hallucination Detection and Classification](https://arxiv.org/abs/2509.21357)
*Wenkai Wang,Vincent Lee,Yizhen Zheng*

Main category: cs.CL

TL;DR: 大型语言模型幻觉问题可以通过引入一个结合了特征加权和差异特征学习的双模型架构来解决，该架构能识别出高度稀疏的区分性特征，从而在保持高精度的同时显著提高检测效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的幻觉现象，即模型输出偏离事实准确性，是由于训练数据中的分布偏差造成的，这是一个关键的挑战。尽管已有研究表明特定隐藏层在幻觉内容和事实内容之间存在差异，但幻觉信号在层内的精确位置尚不明确，这限制了高效检测方法的开发。

Method: 提出了一种双模型架构，集成了用于自适应层间特征加权的投影融合（PF）块，以及通过计算并行编码器之间的差异来识别区分性特征的差异特征学习（DFL）机制。这两个并行编码器从相同的输入中学习互补的表示。

Result: 通过在HaluEval的问答、对话和摘要数据集上进行系统性实验，证明幻觉信号集中在高度稀疏的特征子集中，在问答和对话任务上实现了显著的准确性提升。分析揭示了一种分层的“漏斗模式”，浅层特征多样性高，深层特征使用集中，使得仅使用1%的特征维度就能在检测性能上保持最小的性能衰减。

Conclusion: 幻觉信号比之前假设的更集中，为开发计算高效的检测系统提供了途径，这些系统可以在保持精度的同时降低推理成本。

Abstract: Large language model hallucination represents a critical challenge where
outputs deviate from factual accuracy due to distributional biases in training
data. While recent investigations establish that specific hidden layers exhibit
differences between hallucinatory and factual content, the precise localization
of hallucination signals within layers remains unclear, limiting the
development of efficient detection methods. We propose a dual-model
architecture integrating a Projected Fusion (PF) block for adaptive inter-layer
feature weighting and a Differential Feature Learning (DFL) mechanism that
identifies discriminative features by computing differences between parallel
encoders learning complementary representations from identical inputs. Through
systematic experiments across HaluEval's question answering, dialogue, and
summarization datasets, we demonstrate that hallucination signals concentrate
in highly sparse feature subsets, achieving significant accuracy improvements
on question answering and dialogue tasks. Notably, our analysis reveals a
hierarchical "funnel pattern" where shallow layers exhibit high feature
diversity while deep layers demonstrate concentrated usage, enabling detection
performance to be maintained with minimal degradation using only 1\% of feature
dimensions. These findings suggest that hallucination signals are more
concentrated than previously assumed, offering a pathway toward computationally
efficient detection systems that could reduce inference costs while maintaining
accuracy.

</details>


### [161] [Influence Guided Context Selection for Effective Retrieval-Augmented Generation](https://arxiv.org/abs/2509.21359)
*Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang*

Main category: cs.CL

TL;DR: RAG通过整合外部知识来减少LLM的幻觉，但检索到的上下文质量差会影响其效果。本文提出了一种名为“上下文影响值”（CI value）的新指标，通过衡量移除每个上下文时性能下降的程度来评估上下文质量，整合了查询相关性、列表独特性和生成器对齐性。此外，还开发了一个参数化代理模型来预测CI值，以解决标签依赖和计算开销问题。实验表明，该方法在多个NLP任务和LLM上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在上下文质量评估方面存在局限，未能充分利用查询、上下文列表和生成器等可用信息。本文旨在通过一种新的上下文质量评估方法来解决这个问题。

Method: 提出“上下文影响值”（CI value）指标，通过衡量移除每个上下文时性能下降的程度来评估上下文质量，整合了查询相关性、列表独特性和生成器对齐性。开发了一个参数化代理模型来预测CI值，该模型具有分层结构，能够捕捉局部查询-上下文相关性和全局上下文交互。该模型通过Oracle CI值监督和端到端生成器反馈进行训练。

Result: 所提出的上下文选择方法在8个NLP任务和多个LLM上的实验结果显著优于最先进的基线方法，能够有效地过滤掉低质量的上下文并保留关键信息。

Conclusion: 本文提出的CI值及其代理模型为RAG中的上下文选择提供了一种有效且计算效率高的方法，显著提高了RAG系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) addresses large language model (LLM)
hallucinations by grounding responses in external knowledge, but its
effectiveness is compromised by poor-quality retrieved contexts containing
irrelevant or noisy information. While existing approaches attempt to improve
performance through context selection based on predefined context quality
assessment metrics, they show limited gains over standard RAG. We attribute
this limitation to their failure in holistically utilizing available
information (query, context list, and generator) for comprehensive quality
assessment. Inspired by recent advances in data selection, we reconceptualize
context quality assessment as an inference-time data valuation problem and
introduce the Contextual Influence Value (CI value). This novel metric
quantifies context quality by measuring the performance degradation when
removing each context from the list, effectively integrating query-aware
relevance, list-aware uniqueness, and generator-aware alignment. Moreover, CI
value eliminates complex selection hyperparameter tuning by simply retaining
contexts with positive CI values. To address practical challenges of label
dependency and computational overhead, we develop a parameterized surrogate
model for CI value prediction during inference. The model employs a
hierarchical architecture that captures both local query-context relevance and
global inter-context interactions, trained through oracle CI value supervision
and end-to-end generator feedback. Extensive experiments across 8 NLP tasks and
multiple LLMs demonstrate that our context selection method significantly
outperforms state-of-the-art baselines, effectively filtering poor-quality
contexts while preserving critical information. Code is available at
https://github.com/SJTU-DMTai/RAG-CSM.

</details>


### [162] [Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs](https://arxiv.org/abs/2509.21361)
*Norman Paulsen*

Main category: cs.CL

TL;DR: LLM提供商声称的最大上下文窗口大小与其报告的最大有效上下文窗口大小之间存在显著差异，并且有效上下文窗口大小因问题类型而异。


<details>
  <summary>Details</summary>
Motivation: 测试LLM上下文窗口在现实世界中的使用情况，并量化其有效性。

Method: 定义最大有效上下文窗口（MECW）的概念，并制定一种测试方法，在各种大小和问题类型上测试上下文窗口的有效性，以确定其失效点。

Result: 在测试中，MECW远小于报告的最大上下文窗口（MCW），并且MECW因问题类型而异。一些顶级模型在仅100个令牌的上下文中就失败了，大多数模型在1000个令牌的上下文中准确性严重下降。所有模型的MECW比MCW小高达99%。

Conclusion: MECW因问题类型而异，这为提高模型准确性和降低模型幻觉率提供了清晰可行的见解。

Abstract: Large language model (LLM) providers boast big numbers for maximum context
window sizes. To test the real world use of context windows, we 1) define a
concept of maximum effective context window, 2) formulate a testing method of a
context window's effectiveness over various sizes and problem types, and 3)
create a standardized way to compare model efficacy for increasingly larger
context window sizes to find the point of failure. We collected hundreds of
thousands of data points across several models and found significant
differences between reported Maximum Context Window (MCW) size and Maximum
Effective Context Window (MECW) size. Our findings show that the MECW is, not
only, drastically different from the MCW but also shifts based on the problem
type. A few top of the line models in our test group failed with as little as
100 tokens in context; most had severe degradation in accuracy by 1000 tokens
in context. All models fell far short of their Maximum Context Window by as
much as 99 percent. Our data reveals the Maximum Effective Context Window
shifts based on the type of problem provided, offering clear and actionable
insights into how to improve model accuracy and decrease model hallucination
rates.

</details>


### [163] [How Large Language Models Need Symbolism](https://arxiv.org/abs/2509.21404)
*Xiaotie Deng,Hanyu Li*

Main category: cs.CL

TL;DR: AI的未来需要超越简单的规模扩展，而应结合人类设计的符号来指导其发展，以实现真正的发现。


<details>
  <summary>Details</summary>
Motivation: AI的未来发展需要新的方法，不能仅仅依靠规模的扩大。

Method: 提出应使用人类设计的符号来指导大型语言模型，从而引导其强大的推理能力，实现真正的发现。

Result: 通过结合人类设计的符号，AI将能够实现更深层次的发现，而不仅仅是规模的增长。

Conclusion: AI的未来发展需要人类的智慧和AI的强大能力相结合，才能实现真正的突破。

Abstract: We argue that AI's future requires more than scaling. To unlock genuine
discovery, large language models need a compass: human-crafted symbols to guide
their powerful but blind intuition.

</details>


### [164] [One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning](https://arxiv.org/abs/2509.21443)
*Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens*

Main category: cs.CL

TL;DR: LLM在跨语言和跨文化环境中进行道德推理时，由于主要基于英语数据进行预训练，存在判断不一致和文化错配的问题。本研究通过翻译道德推理基准测试并进行多语言零样本评估，揭示了语言对LLM道德决策的调节作用，并探讨了预训练数据对LLM道德观的影响，最终提出了一个包含道德推理错误类型的分类法，以促进更具文化意识的AI发展。


<details>
  <summary>Details</summary>
Motivation: LLM被广泛应用于多语言和多文化环境，道德推理对其生成合乎伦理的响应至关重要。然而，LLM主要基于英语数据进行预训练，这引发了其在不同语言和文化背景下进行判断的泛化能力问题。

Method: 本研究将两个已有的道德推理基准测试翻译成五种具有文化和语言多样性的语言，进行多语言零样本评估，并通过一系列研究问题来分析语言差异对LLM道德判断的影响，最后通过案例研究将预训练数据的作用与LLM的道德观联系起来。

Result: 研究结果显示，LLM在不同语言下的道德判断存在显著不一致，并且常常出现文化错配。研究还揭示了导致这些差异的潜在因素，包括LLM所采用的推理策略和不同语言间的差异。

Conclusion: 本研究系统地探究了语言在LLM道德决策中的作用，揭示了其在跨语言和跨文化道德推理方面的局限性，并提出了一个道德推理错误的分类法，强调了开发更具文化意识的AI的必要性。

Abstract: Large Language Models (LLMs) are increasingly deployed in multilingual and
multicultural environments where moral reasoning is essential for generating
ethically appropriate responses. Yet, the dominant pretraining of LLMs on
English-language data raises critical concerns about their ability to
generalize judgments across diverse linguistic and cultural contexts. In this
work, we systematically investigate how language mediates moral decision-making
in LLMs. We translate two established moral reasoning benchmarks into five
culturally and typologically diverse languages, enabling multilingual zero-shot
evaluation. Our analysis reveals significant inconsistencies in LLMs' moral
judgments across languages, often reflecting cultural misalignment. Through a
combination of carefully constructed research questions, we uncover the
underlying drivers of these disparities, ranging from disagreements to
reasoning strategies employed by LLMs. Finally, through a case study, we link
the role of pretraining data in shaping an LLM's moral compass. Through this
work, we distill our insights into a structured typology of moral reasoning
errors that calls for more culturally-aware AI.

</details>


### [165] [Transformers Can Learn Connectivity in Some Graphs but Not Others](https://arxiv.org/abs/2509.22343)
*Amit Roy,Abulhair Saparov*

Main category: cs.CL

TL;DR: Transformer 模型可以学习推断网格状有向图的连通性，低维网格图比高维图更容易学习，增加模型规模可以提高泛化能力，但对于非网格图，尤其是包含许多不连通分量的图，Transformer 模型学习连通性任务存在困难。


<details>
  <summary>Details</summary>
Motivation: 研究 Transformer 模型在推断传递关系（例如 A 导致 B，B 导致 C，则 A 导致 C）方面的能力，以及模型规模如何影响这种能力。

Method: 生成各种大小的有向图来训练不同大小的 Transformer 模型，并评估它们推断传递关系的能力。

Result: Transformer 模型能够学习推断“网格状”有向图的连通性，其中图的维度是学习能力的预测因子，模型规模的增加可以提高泛化能力。然而，对于非网格图，特别是那些具有许多不连通分量的图，Transformer 模型在学习连通性任务时会遇到困难。

Conclusion: Transformer 模型可以学习网格状图的连通性，但其能力受图的维度影响。模型规模的增加可以提高泛化能力。然而，对于非网格图，Transformer 模型在学习连通性任务方面存在局限性。

Abstract: Reasoning capability is essential to ensure the factual correctness of the
responses of transformer-based Large Language Models (LLMs), and robust
reasoning about transitive relations is instrumental in many settings, such as
causal inference. Hence, it is essential to investigate the capability of
transformers in the task of inferring transitive relations (e.g., knowing A
causes B and B causes C, then A causes C). The task of inferring transitive
relations is equivalent to the task of connectivity in directed graphs (e.g.,
knowing there is a path from A to B, and there is a path from B to C, then
there is a path from A to C). Past research focused on whether transformers can
learn to infer transitivity from in-context examples provided in the input
prompt. However, transformers' capability to infer transitive relations from
training examples and how scaling affects the ability is unexplored. In this
study, we seek to answer this question by generating directed graphs to train
transformer models of varying sizes and evaluate their ability to infer
transitive relations for various graph sizes. Our findings suggest that
transformers are capable of learning connectivity on "grid-like'' directed
graphs where each node can be embedded in a low-dimensional subspace, and
connectivity is easily inferable from the embeddings of the nodes. We find that
the dimensionality of the underlying grid graph is a strong predictor of
transformers' ability to learn the connectivity task, where higher-dimensional
grid graphs pose a greater challenge than low-dimensional grid graphs. In
addition, we observe that increasing the model scale leads to increasingly
better generalization to infer connectivity over grid graphs. However, if the
graph is not a grid graph and contains many disconnected components,
transformers struggle to learn the connectivity task, especially when the
number of components is large.

</details>


### [166] [LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5](https://arxiv.org/abs/2509.21450)
*Gaurav Kumar Gupta,Nirajan Acharya,Pranal Pande*

Main category: cs.CL

TL;DR: 大型语言模型GPT-5在模拟糖尿病诊断和管理场景中表现出与美国糖尿病协会标准高度一致的潜力，可同时作为临床医生和患者的辅助工具。


<details>
  <summary>Details</summary>
Motivation: 当前糖尿病早期识别面临诸多挑战，包括症状模糊、检验值临界、妊娠复杂性以及长期监测的负担。大型语言模型（LLM）的发展为改进决策支持提供了新机遇，可生成结构化、可解释且对患者友好的输出。

Method: 本研究使用一个完全基于合成病例的模拟框架，该框架遵循美国糖尿病协会2025年护理标准，并借鉴了NHANES、Pima Indians、EyePACS和MIMIC-IV等公共数据集。研究人员测试了GPT-5在五个代表性场景中的表现：症状识别、实验室结果解释、妊娠期糖尿病筛查、远程监测和多模态并发症检测。对于每种场景，GPT-5都进行了病例分类，生成了临床推理过程、患者易懂的解释以及结构化的JSON摘要。

Result: 研究结果表明，GPT-5在分类和解释方面与美国糖尿病协会定义的标准高度一致。

Conclusion: GPT-5可能成为临床医生和患者的双重辅助工具，但强调了在医疗领域负责任地评估LLM时，建立可重复的评估框架的重要性。

Abstract: Diabetes mellitus is a major global health challenge, affecting over half a
billion adults worldwide with prevalence projected to rise. Although the
American Diabetes Association (ADA) provides clear diagnostic thresholds, early
recognition remains difficult due to vague symptoms, borderline laboratory
values, gestational complexity, and the demands of long-term monitoring.
Advances in large language models (LLMs) offer opportunities to enhance
decision support through structured, interpretable, and patient-friendly
outputs. This study evaluates GPT-5, the latest generative pre-trained
transformer, using a simulation framework built entirely on synthetic cases
aligned with ADA Standards of Care 2025 and inspired by public datasets
including NHANES, Pima Indians, EyePACS, and MIMIC-IV. Five representative
scenarios were tested: symptom recognition, laboratory interpretation,
gestational diabetes screening, remote monitoring, and multimodal complication
detection. For each, GPT-5 classified cases, generated clinical rationales,
produced patient explanations, and output structured JSON summaries. Results
showed strong alignment with ADA-defined criteria, suggesting GPT-5 may
function as a dual-purpose tool for clinicians and patients, while underscoring
the importance of reproducible evaluation frameworks for responsibly assessing
LLMs in healthcare.

</details>


### [167] [Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes](https://arxiv.org/abs/2509.21456)
*Guangliang Liu,Bocheng Chen,Xitong Zhang,Kristen Marie Johnson*

Main category: cs.CL

TL;DR: 微调或模型编辑可能会损害下游任务性能，但可以减少性别刻板印象。


<details>
  <summary>Details</summary>
Motivation: 研究了微调或模型编辑是否会损害下游任务性能，以及是否存在一种可以减少性别刻板印象的方法。

Method: 通过仔细设计的公平性目标来鼓励PLM选择性地遗忘刻板印象知识，同时保留其有用性。

Result: 模型编辑和微调会损害下游任务性能。然而，通过仔细设计的公平性目标，可以鼓励PLM选择性地遗忘刻板印象知识，同时保留其有用性。此外，研究还发现，下游任务性能主要由整体遗忘程度驱动，而选择性遗忘刻板印象往往会增加整体遗忘程度。

Conclusion: 当前的公平性目标在实现性能权衡方面存在局限性，因为选择性遗忘刻板印象会增加整体遗忘程度，而通用的遗忘缓解方法对于提高下游任务性能无效。

Abstract: Moral alignment has emerged as a widely adopted approach for regulating the
behavior of pretrained language models (PLMs), typically through fine-tuning or
model editing on curated datasets. However, this process often comes at the
cost of degraded downstream task performance. Prior studies commonly aim to
achieve a performance trade-off by encouraging PLMs to selectively forget
stereotypical knowledge through carefully designed fairness objectives, while
preserving their helpfulness. In this short paper, we investigate the
underlying mechanisms of the performance trade-off in the context of mitigating
gender stereotypes, through the lens of forgetting and the fairness objective.
Our analysis reveals the limitations of current fairness objective in achieving
trade-off by demonstrating that: (1) downstream task performance is primarily
driven by the overall forgetting level; (2) selective forgetting of stereotypes
tends to increase overall forgetting; and (3) general solutions for mitigating
forgetting are ineffective at reducing overall forgetting and fail to improve
downstream task performance.

</details>


### [168] [A State-of-the-Art SQL Reasoning Model using RLVR](https://arxiv.org/abs/2509.21459)
*Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang*

Main category: cs.CL

TL;DR: RLVR被应用于BIRD基准测试，将自然语言查询转换为SQL，达到了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 为企业客户开发可整合组织特定知识的定制化强化学习（RL）推理模型，以解决实际问题，特别是在奖励函数可验证的RLVR设置下。

Method: 采用了一个包含仔细的提示和模型选择、使用离线RL方法TAO进行预热，以及严格的在线RLVR训练的通用训练方案。

Result: 在BIRD基准测试的私有测试集上达到了73.56%（无自我一致性）和75.68%（有自我一致性）的最先进准确率，并且在有自我一致性时，生成的次数少于第二名的方法。

Conclusion: 虽然BIRD是一个代理任务，但该框架的简单性使其广泛适用于商业智能、数据科学和编码等企业领域。

Abstract: Developing custom reasoning models via Reinforcement Learning (RL) that can
incorporate organization-specific knowledge has great potential to address
problems faced by enterprise customers. In many of these problems, the reward
function is verifiable, a setting termed RL with Verifiable Rewards (RLVR). We
apply RLVR to a popular data science benchmark called BIRD that measures the
ability of an AI agent to convert a natural language query for a database to
SQL executions. We apply a simple and general-purpose training recipe involving
careful prompt and model selection, a warm-up stage using our offline RL
approach called TAO, followed by rigorous online RLVR training. With no
additional training data beyond the BIRD training set and no use of proprietary
models, our very first submission to the BIRD leaderboard reached
state-of-the-art accuracy on the private test set: 73.56% without
self-consistency and 75.68% with self-consistency. In the latter case, our
model also required fewer generations than the second-best approach. While BIRD
is only a proxy task, the simplicity of our framework makes it broadly
applicable to enterprise domains such as business intelligence, data science,
and coding.

</details>


### [169] [Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective](https://arxiv.org/abs/2509.21613)
*Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers*

Main category: cs.CL

TL;DR: MORL在LLM优化中面临挑战和机遇，提出MORL分类法，并探讨了不同MORL方法的优缺点，强调了对高效、灵活方法的需求。我们提出了一个MORL基准测试框架的愿景，并指出了元策略MORL作为未来研究方向，以提高效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: LLM优化中的多目标强化学习（MORL）带来了独特的挑战和机遇。

Method: 提出MORL分类法，考察不同MORL方法在LLM优化中的优缺点，并提出了一个MORL基准测试框架的设想。

Result: 现有MORL方法在LLM优化中存在局限性，需要更高效灵活的方法，并且多目标关系对模型性能有显著影响。

Conclusion: 元策略MORL是提高LLM优化效率和灵活性的有前景的未来研究方向。

Abstract: Multi-Objective Reinforcement Learning (MORL) presents significant challenges
and opportunities for optimizing multiple objectives in Large Language Models
(LLMs). We introduce a MORL taxonomy and examine the advantages and limitations
of various MORL methods when applied to LLM optimization, identifying the need
for efficient and flexible approaches that accommodate personalization
functionality and inherent complexities in LLMs and RL. We propose a vision for
a MORL benchmarking framework that addresses the effects of different methods
on diverse objective relationships. As future research directions, we focus on
meta-policy MORL development that can improve efficiency and flexibility
through its bi-level learning paradigm, highlighting key research questions and
potential solutions for improving LLM performance.

</details>


### [170] [Learning to Reason with Mixture of Tokens](https://arxiv.org/abs/2509.21482)
*Adit Jain,Brendan Rappazzo*

Main category: cs.CL

TL;DR: RLVR方法在LLM推理中通过混合多种token生成（MoT-G）来利用token的分布信息，提高了推理能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在推理时只采样离散的token，忽略了模型在候选token上的丰富分布信息，限制了推理搜索空间。

Method: 提出一个统一的框架，将MoT-G推广到RLVR中，允许策略在连续的混合空间中操作，用于生成思维链。作者提出了两种MoT-G的变体。

Result: 在Reasoning-Gym基准测试中，两种MoT-G方法使用Qwen2.5-1.5B模型在7/10的任务上实现了5%-35%的提升，并且在达到相似准确率的同时，所需的样本数量减少了一半，显示出更高的训练效率。

Conclusion: MoT-G通过在推理过程中保持更高的隐藏状态熵和促进token空间的探索，从而提高了LLM的推理能力和训练效率。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a leading
approach for improving large language model (LLM) reasoning capabilities. Most
current methods follow variants of Group Relative Policy Optimization, which
samples multiple reasoning completions, scores them relative to each other, and
adjusts the policy accordingly. However, these approaches invariably sample
discrete tokens at each reasoning step, discarding the rich distributional
information in the model's probability distribution over candidate tokens.
While preserving and utilizing this distributional information has proven
beneficial in non-RL settings, current RLVR methods seem to be unnecessarily
constraining the reasoning search space by not using this information. To
address this limitation, we investigate mixture-of-token generation (MoT-G) in
RLVR. We present a unified framework that generalizes existing MoT-G
approaches, including existing training-free methods that construct mixture
embeddings as weighted sums over token embeddings, and extend RLVR to operate
directly in this continuous mixture space for generating chain-of-thought.
Evaluating two MoT-G variants on Reasoning-Gym, a suite of reasoning-intensive
language tasks, we find that MoT--G methods achieve substantial improvements
(5--35 \% gains on 7 out of 10 tasks) compared to standard decoding with the
Qwen2.5-1.5B model, while reaching comparable accuracy with half the number of
trajectories, suggesting improved training efficiency. Through comprehensive
hidden-state and token-level analyses, we provide evidence that MoT--G's
benefits may stem from its ability to maintain higher hidden-state entropy
throughout the reasoning process and promote exploration in token space.

</details>


### [171] [Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning](https://arxiv.org/abs/2509.21487)
*Jillian Xu,Dylan Zhou,Vinay Shukla,Yang Yang,Junrui Ruan,Shuhuai Lin,Wenfei Zou,Yinxiao Liu,Karthik Lakshmanan*

Main category: cs.CL

TL;DR: CoT提示虽然提高了分类准确性，但会带来显着的推理时间损失。为了解决这个权衡问题，我们提出了双头推理蒸馏（DHRD），一种用于解码器语言模型的简单训练方法。该方法在训练和推理过程中增加了一个分类头，并在仅训练期间使用教师推理来监督推理头。DHRD在七个SuperGLUE任务上带来了0.65-5.47%的相对收益，特别是在蕴含/因果任务上。在测试时禁用推理头，推理吞吐量与池化分类器相当，并且在相同骨干网络上比CoT解码快96-142倍。


<details>
  <summary>Details</summary>
Motivation: CoT提示虽然提高了分类准确性，但会带来显着的推理时间损失。为了解决这个权衡问题，需要一种新的方法。

Method: 提出双头推理蒸馏（DHRD），一种用于解码器语言模型的简单训练方法。该方法在训练和推理过程中增加了一个分类头，并在仅训练期间使用教师推理来监督推理头。训练损失函数是标签交叉熵和输入加推理序列上的令牌级语言模型损失的加权和。

Result: 在七个SuperGLUE任务上，DHRD带来了0.65-5.47%的相对收益，特别是在蕴含/因果任务上。在测试时禁用推理头，推理吞吐量与池化分类器相当，并且在相同骨干网络上比CoT解码快96-142倍。

Conclusion: DHRD是一种有效的训练方法，可以在不牺牲推理吞吐量的情况下提高语言模型的分类准确性。

Abstract: Chain-of-Thought (CoT) prompting often improves classification accuracy, but
it introduces a significant throughput penalty with rationale generation (Wei
et al., 2022; Cheng and Van Durme, 2024). To resolve this trade-off, we
introduce Dual-Head Reasoning Distillation (DHRD), a simple training method for
decoder-only language models (LMs) that adds (i) a pooled classification head
used during training and inference and (ii) a reasoning head supervised by
teacher rationales used only in training. We train with a loss function that is
a weighted sum of label cross-entropy and token-level LM loss over
input-plus-rationale sequences. On seven SuperGLUE tasks, DHRD yields relative
gains of 0.65-5.47% over pooled baselines, with notably larger gains on
entailment/causal tasks. Since we disable the reasoning head at test time,
inference throughput matches pooled classifiers and exceeds CoT decoding on the
same backbones by 96-142 times in QPS.

</details>


### [172] [On Code-Induced Reasoning in LLMs](https://arxiv.org/abs/2509.21499)
*Abdul Waheed,Zhen Wu,Carolyn Rosé,Daphne Ippolito*

Main category: cs.CL

TL;DR: 代码的结构性而非语义性对大型语言模型的推理能力影响更大，伪代码和流程图等抽象表示同样有效，甚至可以提高性能，而语法风格则会影响特定任务的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管代码数据能提升大型语言模型的推理能力，但具体是哪些代码属性起关键作用尚不明确。

Method: 构建了包含十种编程语言的并行指令数据集，并进行可控扰动以分离代码的结构和语义属性。在不同模型家族、规模和数据集变体上进行微调，并在自然语言、数学和代码任务上进行评估。

Result: 在3331项实验中，模型对结构性扰动比语义性扰动更敏感，尤其是在数学和代码任务上。伪代码和流程图等抽象表示与原始代码一样有效，有时甚至因更少的token而表现更好。即使是带有误导性信号的损坏代码，只要表面规律存在，性能也具有竞争力。Python有利于自然语言推理，而Java和Rust等低级语言有利于数学推理。

Conclusion: 代码的结构属性对LLM的推理能力至关重要，优于语义属性。抽象表示和精简的表示方式是有效的。模型的性能对代码的表面规律敏感。不同的语法风格对不同类型的任务有不同的影响。这些发现有助于设计更有效的LLM训练数据。

Abstract: Code data has been shown to enhance the reasoning capabilities of large
language models (LLMs), but it remains unclear which aspects of code are most
responsible. We investigate this question with a systematic, data-centric
framework. We construct parallel instruction datasets in ten programming
languages and apply controlled perturbations that selectively disrupt
structural or semantic properties of code. We then finetune LLMs from five
model families and eight scales on each variant and evaluate their performance
on natural language, math, and code tasks. Across 3,331 experiments, our
results show that LLMs are more vulnerable to structural perturbations than
semantic ones, particularly on math and code tasks. Appropriate abstractions
like pseudocode and flowcharts can be as effective as code, while encoding the
same information with fewer tokens without adhering to original syntax can
often retain or even improve performance. Remarkably, even corrupted code with
misleading signals remains competitive when surface-level regularities persist.
Finally, syntactic styles also shape task-specific gains with Python favoring
natural language reasoning and lower-level languages such as Java and Rust
favoring math. Through our systematic framework, we aim to provide insight into
how different properties of code influence reasoning and inform the design of
training data for enhancing LLM reasoning capabilities.

</details>


### [173] [Following the TRACE: A Structured Path to Empathetic Response Generation with Multi-Agent Models](https://arxiv.org/abs/2509.21849)
*Ziqi Liu,Ziyang Zhou,Yilin Li,Haiyang Zhang,Yangbin Chen*

Main category: cs.CL

TL;DR: TRACE框架将共情能力建模为一个结构化的认知过程，通过将任务分解为分析和合成的流水线来解决现有模型在分析深度和生成流畅性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成共情回应时，在分析深度和生成流畅性之间存在权衡，TRAC旨在解决此问题。

Method: TRAC框架将共情建模为一个结构化的认知过程，通过将任务分解为分析和合成的流水线来实现。

Result: 实验结果表明，TRAC框架在自动和基于LLM的评估中显著优于现有方法。

Conclusion: TRAC的结构化分解为创建更强大、更可解释的共情对话代理提供了一个有前景的范例。

Abstract: Empathetic response generation is a crucial task for creating more human-like
and supportive conversational agents. However, existing methods face a core
trade-off between the analytical depth of specialized models and the generative
fluency of Large Language Models (LLMs). To address this, we propose TRACE,
Task-decomposed Reasoning for Affective Communication and Empathy, a novel
framework that models empathy as a structured cognitive process by decomposing
the task into a pipeline for analysis and synthesis. By building a
comprehensive understanding before generation, TRACE unites deep analysis with
expressive generation. Experimental results show that our framework
significantly outperforms strong baselines in both automatic and LLM-based
evaluations, confirming that our structured decomposition is a promising
paradigm for creating more capable and interpretable empathetic agents. Our
code is available at https://anonymous.4open.science/r/TRACE-18EF/README.md.

</details>


### [174] [Agribot: agriculture-specific question answer system](https://arxiv.org/abs/2509.21535)
*Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari*

Main category: cs.CL

TL;DR: 这是一个基于语料库的农业聊天机器人，用于回答农民关于天气、市场价格、植物保护和政府计划的查询，准确率达到 86%。


<details>
  <summary>Details</summary>
Motivation: 为了提高印度农业增长和产出，需要为农民提供关于农业实践的正确信息，并简化 Kisan Call Center 的工作。

Method: 构建了一个基于 Kisan Call Center 数据集的农业聊天机器人，该机器人采用了句子嵌入模型，并在进行同义词消除和实体提取后，准确率从 56% 提高到 86%。

Result: 该聊天机器人能够 24/7 全天候回答农民关于天气、市场价格、植物保护和政府计划的查询，并且信息易于理解。

Conclusion: 该系统有助于农民更轻松地获取农业信息，从而提高农业产出，并减轻 Kisan Call Center 工作人员的负担。

Abstract: India is an agro-based economy and proper information about agricultural
practices is the key to optimal agricultural growth and output. In order to
answer the queries of the farmer, we have build an agricultural chatbot based
on the dataset from Kisan Call Center. This system is robust enough to answer
queries related to weather, market rates, plant protection and government
schemes. This system is available 24* 7, can be accessed through any electronic
device and the information is delivered with the ease of understanding. The
system is based on a sentence embedding model which gives an accuracy of 56%.
After eliminating synonyms and incorporating entity extraction, the accuracy
jumps to 86%. With such a system, farmers can progress towards easier
information about farming related practices and hence a better agricultural
output. The job of the Call Center workforce would be made easier and the hard
work of various such workers can be redirected to a better goal.

</details>


### [175] [Domain-Aware Speaker Diarization On African-Accented English](https://arxiv.org/abs/2509.21554)
*Chibuzor Okocha,Kelechi Ezema,Christan Grant*

Main category: cs.CL

TL;DR: 本研究在临床对话中发现口音匹配数据存在领域惩罚，特别是在重叠场景下，并通过轻量级领域自适应方法进行缓解，但未能完全消除差距。


<details>
  <summary>Details</summary>
Motivation: 评估域效应对非洲口音英语的说话人日志记录的影响，尤其是在临床对话中，并提出缓解方法。

Method: 在通用和临床对话上评估多种生产和开放系统，使用严格的DER协议（计分重叠），并尝试通过在口音匹配数据上微调分割模块进行轻量级域适应。

Result: 临床语音存在持续的域惩罚，即使在跨模型和轻量级域适应后仍然显著。错误分析表明，这主要是由于虚警和漏检，与短轮次和频繁重叠有关。轻量级域适应可以减少错误，但不能完全消除差距。

Conclusion: 重叠感知分割和均衡的临床资源是解决非洲口音英语说话人日志记录中域效应的实用后续步骤。

Abstract: This study examines domain effects in speaker diarization for
African-accented English. We evaluate multiple production and open systems on
general and clinical dialogues under a strict DER protocol that scores overlap.
A consistent domain penalty appears for clinical speech and remains significant
across models. Error analysis attributes much of this penalty to false alarms
and missed detections, aligning with short turns and frequent overlap. We test
lightweight domain adaptation by fine-tuning a segmentation module on
accent-matched data; it reduces error but does not eliminate the gap. Our
contributions include a controlled benchmark across domains, a concise approach
to error decomposition and conversation-level profiling, and an adaptation
recipe that is easy to reproduce. Results point to overlap-aware segmentation
and balanced clinical resources as practical next steps.

</details>


### [176] [Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution](https://arxiv.org/abs/2509.21557)
*Yash Saxena,Raviteja Bommireddy,Ankur Padia,Manas Gaur*

Main category: cs.CL

TL;DR: 在医疗、法律、学术和金融等高风险领域，为确保大语言模型（LLM）的可信度，必须引用人类可验证的来源。本文提出了两种范式：生成时引用（G-Cite）和事后引用（P-Cite），并进行了全面的评估。研究发现，P-Cite 在覆盖率和正确率之间取得了良好的平衡，而 G-Cite 则优先考虑精度。建议在高风险应用中优先使用以检索为中心、事后引用的方法。


<details>
  <summary>Details</summary>
Motivation: 高风险领域（如医疗、法律、学术、金融）中的大语言模型（LLM）需要引用人类可验证的来源，以确保其可信度，因为即使是微小的错误也可能导致严重后果。

Method: 提出两种引用范式：生成时引用（G-Cite）和事后引用（P-Cite）。在四个流行的归因数据集上，从零样本到先进的检索增强方法进行了全面的评估。

Result: P-Cite 方法实现了高覆盖率和有竞争力的正确率，以及中等的延迟。G-Cite 方法优先考虑精度，但牺牲了覆盖率和速度。检索是归因质量的主要驱动因素。

Conclusion: 在高风险应用中，建议采用以检索为中心、事后引用（P-Cite）为主的方法，并将生成时引用（G-Cite）用于严格的声明验证等精度至关重要的场景。

Abstract: Trustworthy Large Language Models (LLMs) must cite human-verifiable sources
in high-stakes domains such as healthcare, law, academia, and finance, where
even small errors can have severe consequences. Practitioners and researchers
face a choice: let models generate citations during decoding, or let models
draft answers first and then attach appropriate citations. To clarify this
choice, we introduce two paradigms: Generation-Time Citation (G-Cite), which
produces the answer and citations in one pass, and Post-hoc Citation (P-Cite),
which adds or verifies citations after drafting. We conduct a comprehensive
evaluation from zero-shot to advanced retrieval-augmented methods across four
popular attribution datasets and provide evidence-based recommendations that
weigh trade-offs across use cases. Our results show a consistent trade-off
between coverage and citation correctness, with retrieval as the main driver of
attribution quality in both paradigms. P-Cite methods achieve high coverage
with competitive correctness and moderate latency, whereas G-Cite methods
prioritize precision at the cost of coverage and speed. We recommend a
retrieval-centric, P-Cite-first approach for high-stakes applications,
reserving G-Cite for precision-critical settings such as strict claim
verification. Our codes and human evaluation results are available at
https://anonymous.4open.science/r/Citation_Paradigms-BBB5/

</details>


### [177] [Comparative Personalization for Multi-document Summarization](https://arxiv.org/abs/2509.21562)
*Haoyuan Li,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: ComPSum是一个个性化多文档摘要框架，通过比较用户偏好来识别细粒度的用户差异，并使用结构化分析来指导摘要生成。同时，提出了AuthorMap评估框架和PerMSum数据集来评估该框架的性能。


<details>
  <summary>Details</summary>
Motivation: 个性化多文档摘要对于满足用户对写作风格和内容重点的个性化需求至关重要。

Method: 首先，通过比较用户偏好与其他用户的偏好来生成用户结构化分析。然后，利用该分析来指导个性化摘要的生成。

Result: ComPSum在PerMSum数据集上，使用AuthorMap评估框架，其性能优于强基线模型。

Conclusion: 提出的ComPSum框架通过识别细粒度的用户偏好差异，能够有效地生成个性化摘要。AuthorMap评估框架和PerMSum数据集为个性化多文档摘要的评估提供了有效手段。

Abstract: Personalized multi-document summarization (MDS) is essential for meeting
individual user preferences of writing style and content focus for summaries.
In this paper, we propose that for effective personalization, it is important
to identify fine-grained differences between users' preferences by comparing
the given user's preferences with other users' preferences.Motivated by this,
we propose ComPSum, a personalized MDS framework. It first generates a
structured analysis of a user by comparing their preferences with other users'
preferences. The generated structured analysis is then used to guide the
generation of personalized summaries. To evaluate the performance of ComPSum,
we propose AuthorMap, a fine-grained reference-free evaluation framework for
personalized MDS. It evaluates the personalization of a system based on the
authorship attribution between two personalized summaries generated for
different users. For robust evaluation of personalized MDS, we construct
PerMSum, a personalized MDS dataset in the review and news domain. We evaluate
the performance of ComPSum on PerMSum using AuthorMap, showing that it
outperforms strong baselines.

</details>


### [178] [Vision Language Models Cannot Plan, but Can They Formalize?](https://arxiv.org/abs/2509.21576)
*Muyu He,Yuxi Zheng,Yuchen Liu,Zijian An,Bill Cai,Jiani Huang,Lifeng Zhou,Feng Liu,Ziyang Li,Li Zhang*

Main category: cs.CL

TL;DR: Vision-language models can be used to formalize planning problems in PDDL, outperforming end-to-end methods and enabling long-horizon planning in multimodal environments. The main challenge lies in visual perception, not language processing, with opportunities for improvement in generating intermediate textual representations.


<details>
  <summary>Details</summary>
Motivation: Existing vision-language models struggle with long-horizon planning in multimodal environments. This work aims to improve multimodal planning by using vision-language models to translate planning problems into a formal language (PDDL), similar to advancements in text-only simulations.

Method: The paper proposes five VLM-as-formalizer pipelines for one-shot, open-vocabulary, multimodal PDDL formalization. They evaluate these on an existing benchmark and introduce two new benchmarks that include authentic, multi-view, and low-quality images. They also explore generating intermediate textual representations like captions and scene graphs.

Result: The VLM-as-formalizer approach significantly outperforms end-to-end plan generation. The primary limitation identified is vision, as VLMs often fail to accurately perceive object relations in images. Generating intermediate textual representations provides some improvement but is inconsistent.

Conclusion: VLM-as-formalizer is a promising direction for multimodal planning, surpassing end-to-end methods. Vision perception is the key bottleneck, and further research is needed to improve the consistency and effectiveness of intermediate textual representations in multimodal planning formalization.

Abstract: The advancement of vision language models (VLMs) has empowered embodied
agents to accomplish simple multimodal planning tasks, but not long-horizon
ones requiring long sequences of actions. In text-only simulations,
long-horizon planning has seen significant improvement brought by repositioning
the role of LLMs. Instead of directly generating action sequences, LLMs
translate the planning domain and problem into a formal planning language like
the Planning Domain Definition Language (PDDL), which can call a formal solver
to derive the plan in a verifiable manner. In multimodal environments, research
on VLM-as-formalizer remains scarce, usually involving gross simplifications
such as predefined object vocabulary or overly similar few-shot examples. In
this work, we present a suite of five VLM-as-formalizer pipelines that tackle
one-shot, open-vocabulary, and multimodal PDDL formalization. We evaluate those
on an existing benchmark while presenting another two that for the first time
account for planning with authentic, multi-view, and low-quality images. We
conclude that VLM-as-formalizer greatly outperforms end-to-end plan generation.
We reveal the bottleneck to be vision rather than language, as VLMs often fail
to capture an exhaustive set of necessary object relations. While generating
intermediate, textual representations such as captions or scene graphs
partially compensate for the performance, their inconsistent gain leaves
headroom for future research directions on multimodal planning formalization.

</details>


### [179] ["Be My Cheese?": Assessing Cultural Nuance in Multilingual LLM Translations](https://arxiv.org/abs/2509.21577)
*Madison Van Doren,Cory Holland*

Main category: cs.CL

TL;DR: 该研究评估了先进的多语言人工智能模型在将英语中的成语和双关语等比喻语言翻译成各种全球语言时的本地化能力，强调文化适宜性和整体本地化质量，而不是仅关注语法准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在扩展现有的LLM翻译研究和行业基准，这些基准侧重于语法准确性和令牌级别正确性，而是专注于文化适宜性和整体本地化质量，这是营销和电子商务等实际应用的关键因素。

Method: 评估了20种语言的24个地区方言的87个LLM生成的电子商务营销电子邮件翻译样本。由目标语言的母语者提供关于语气、含义和目标受众的忠实度方面的定量评分和定性反馈。

Result: 研究表明，尽管领先的模型通常能产生语法正确的翻译，但文化细微的语言仍然是需要改进的领域，通常需要大量的人工润色。即使是资源丰富的全球语言，在翻译比喻表达和文字游戏时也经常出错。

Conclusion: 这项工作挑战了数据量是机器翻译质量最可靠预测指标的假设，并提出了文化适宜性作为多语言LLM性能的关键决定因素。该试点项目突显了当前多语言人工智能系统在实际本地化用例中的局限性，并为在文化多样化环境中部署可靠的机器翻译工作流程提供了机会。

Abstract: This pilot study explores the localisation capabilities of state-of-the-art
multilingual AI models when translating figurative language, such as idioms and
puns, from English into a diverse range of global languages. It expands on
existing LLM translation research and industry benchmarks, which emphasise
grammatical accuracy and token-level correctness, by focusing on cultural
appropriateness and overall localisation quality - critical factors for
real-world applications like marketing and e-commerce.
  To investigate these challenges, this project evaluated a sample of 87
LLM-generated translations of e-commerce marketing emails across 24 regional
dialects of 20 languages. Human reviewers fluent in each target language
provided quantitative ratings and qualitative feedback on faithfulness to the
original's tone, meaning, and intended audience. Findings suggest that, while
leading models generally produce grammatically correct translations, culturally
nuanced language remains a clear area for improvement, often requiring
substantial human refinement. Notably, even high-resource global languages,
despite topping industry benchmark leaderboards, frequently mistranslated
figurative expressions and wordplay.
  This work challenges the assumption that data volume is the most reliable
predictor of machine translation quality and introduces cultural
appropriateness as a key determinant of multilingual LLM performance - an area
currently underexplored in existing academic and industry benchmarks. As a
proof of concept, this pilot highlights limitations of current multilingual AI
systems for real-world localisation use cases. Results of this pilot support
the opportunity for expanded research at greater scale to deliver generalisable
insights and inform deployment of reliable machine translation workflows in
culturally diverse contexts.

</details>


### [180] [OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule](https://arxiv.org/abs/2509.21623)
*Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen*

Main category: cs.CL

TL;DR: OjaKV通过混合存储策略和在线子空间自适应来解决KV缓存的内存瓶颈，实现了高效的长文本推理。


<details>
  <summary>Details</summary>
Motivation: KV缓存是大型语言模型长文本处理的内存瓶颈，现有压缩方法在数据分布变化时表现不佳。

Method: OjaKV采用混合存储策略，保留首尾token，并利用Oja算法在线自适应压缩中间token的低秩子空间。

Result: OjaKV在长文本基准测试中保持甚至提高了零样本准确率，特别是在需要复杂推理的任务上表现突出。

Conclusion: OjaKV是一种无需微调模型即可实现内存高效长文本推理的实用解决方案。

Abstract: The expanding long-context capabilities of large language models are
constrained by a significant memory bottleneck: the key-value (KV) cache
required for autoregressive generation. This bottleneck is substantial; for
instance, a Llama-3.1-8B model processing a 32K-token prompt at a batch size of
4 requires approximately 16GB for its KV cache, a size exceeding the model's
weights. While KV-cache compression via low-rank projection is a promising
direction, existing methods rely on a static, offline-learned subspace that
performs poorly under data distribution shifts. To overcome these limitations,
we introduce OjaKV, a novel framework that integrates a strategic hybrid
storage policy with online subspace adaptation. First, OjaKV recognizes that
not all tokens are equally important for compression; it preserves the crucial
first and most recent tokens in full-rank, maintaining high-fidelity anchors
for attention. Second, for the vast majority of intermediate tokens, it applies
low-rank compression by incrementally adapting the projection basis using Oja's
algorithm for online principal component analysis. This adaptation involves a
comprehensive update during prompt prefilling and lightweight periodic updates
during decoding, ensuring the subspace remains aligned with the evolving
context. Crucially, our framework is fully compatible with modern attention
modules like FlashAttention. Experiments demonstrate that OjaKV maintains or
even improves zero-shot accuracy at high compression ratios. In particular,
OjaKV achieves its strongest gains on very long-context benchmarks that require
complex reasoning, highlighting the importance of online subspace adaptation in
dynamically tracking context shifts. These results establish our hybrid
framework as a practical, plug-and-play solution for memory-efficient
long-context inference without requiring model fine-tuning.

</details>


### [181] [Towards Transparent AI: A Survey on Explainable Language Models](https://arxiv.org/abs/2509.21631)
*Avash Palikhe,Zichong Wang,Zhipeng Yin,Rui Guo,Qiang Duan,Jie Yang,Wenbin Zhang*

Main category: cs.CL

TL;DR: 本篇论文是一篇关于解释语言模型（LMs）的XAI技术的调查，重点关注其在不同Transformer架构（仅编码器、仅解码器、编码器-解码器）中的应用，并评估了这些技术的合理性和忠实性，最后指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 语言模型（LMs）的黑箱性质引发了对其可解释性的担忧，特别是在高风险领域，需要理解模型决策的理由以确保问责制。现有的XAI方法应用于LMs时面临诸多限制，且现有调查未能充分涵盖LMs架构多样性和能力演变带来的独特挑战。

Method: 本调查全面回顾了XAI技术在LMs中的应用，根据Transformer架构（仅编码器、仅解码器、编码器-解码器）对XAI方法进行分类，分析了针对不同架构的适应性，并评估了各自的优缺点。此外，还从合理性和忠实性两个角度对这些技术进行了评估。

Result: 本调查根据Transformer架构（仅编码器、仅解码器、编码器-解码器）对XAI方法进行了分类和分析，评估了它们在LMs中的适用性、优缺点、合理性和忠实性。

Conclusion: 本调查全面回顾了LMs的XAI技术，并根据Transformer架构进行了分类，评估了这些技术的有效性，最后指出了开放的研究挑战和未来的发展方向，旨在推动开发稳健、透明、可解释的LMs XAI方法。

Abstract: Language Models (LMs) have significantly advanced natural language processing
and enabled remarkable progress across diverse domains, yet their black-box
nature raises critical concerns about the interpretability of their internal
mechanisms and decision-making processes. This lack of transparency is
particularly problematic for adoption in high-stakes domains, where
stakeholders need to understand the rationale behind model outputs to ensure
accountability. On the other hand, while explainable artificial intelligence
(XAI) methods have been well studied for non-LMs, they face many limitations
when applied to LMs due to their complex architectures, considerable training
corpora, and broad generalization abilities. Although various surveys have
examined XAI in the context of LMs, they often fail to capture the distinct
challenges arising from the architectural diversity and evolving capabilities
of these models. To bridge this gap, this survey presents a comprehensive
review of XAI techniques with a particular emphasis on LMs, organizing them
according to their underlying transformer architectures: encoder-only,
decoder-only, and encoder-decoder, and analyzing how methods are adapted to
each while assessing their respective strengths and limitations. Furthermore,
we evaluate these techniques through the dual lenses of plausibility and
faithfulness, offering a structured perspective on their effectiveness.
Finally, we identify open research challenges and outline promising future
directions, aiming to guide ongoing efforts toward the development of robust,
transparent, and interpretable XAI methods for LMs.

</details>


### [182] [ReviewScore: Misinformed Peer Review Detection with Large Language Models](https://arxiv.org/abs/2509.21679)
*Hyun Ryu,Doohyuk Jang,Hyemin S. Lee,Joonhyun Jeong,Gyeongman Kim,Donghyeon Cho,Gyouk Chu,Minyeong Hwang,Hyeongwon Jang,Changhun Kim,Haechan Kim,Jina Kim,Joowon Kim,Yoonjeon Kim,Kwanhyung Lee,Chanjae Park,Heecheol Yun,Gregor Betz,Eunho Yang*

Main category: cs.CL

TL;DR: AI 顶会审稿质量下降，提出 ReviewScore 评估审稿质量，并通过 LLM 自动化评估


<details>
  <summary>Details</summary>
Motivation: AI 顶会审稿数量激增导致审稿质量下降

Method: 定义错误信息审稿点（weaknesses/questions），提出 ReviewScore 指标，并构建数据集以评估 LLM 自动评估 ReviewScore 的能力

Result: LLM 在 ReviewScore 评估上达到中等程度的一致性，且评估前提层面事实性比评估弱点层面事实性具有更高的一致性

Conclusion: 对错误的审稿点进行分析表明，可以实现对 ReviewScore 的全自动评估。

Abstract: Peer review serves as a backbone of academic research, but in most AI
conferences, the review quality is degrading as the number of submissions
explodes. To reliably detect low-quality reviews, we define misinformed review
points as either "weaknesses" in a review that contain incorrect premises, or
"questions" in a review that can be already answered by the paper. We verify
that 15.2% of weaknesses and 26.4% of questions are misinformed and introduce
ReviewScore indicating if a review point is misinformed. To evaluate the
factuality of each premise of weaknesses, we propose an automated engine that
reconstructs every explicit and implicit premise from a weakness. We build a
human expert-annotated ReviewScore dataset to check the ability of LLMs to
automate ReviewScore evaluation. Then, we measure human-model agreements on
ReviewScore using eight current state-of-the-art LLMs and verify moderate
agreements. We also prove that evaluating premise-level factuality shows
significantly higher agreements than evaluating weakness-level factuality. A
thorough disagreement analysis further supports a potential of fully automated
ReviewScore evaluation.

</details>


### [183] [GRAB: A Risk Taxonomy--Grounded Benchmark for Unsupervised Topic Discovery in Financial Disclosures](https://arxiv.org/abs/2509.21698)
*Ying Li,Tiejun Ma*

Main category: cs.CL

TL;DR: 本研究提出了GRAB，一个包含161万个句子和8247份10-K文件的无监督风险分类基准，并结合了FinBERT、YAKE和词汇搭配信号，无需人工标注即可生成句子标签，实现了对金融风险披露进行标准化、可复现的评估。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督主题模型在10-K风险披露的风险分类任务上缺乏公开基准进行评估，而风险分类对于监督和投资至关重要。

Method: 开发了一个名为GRAB的金融领域特定基准，包含161万个句子和8247份10-K文件。通过结合FinBERT的令牌注意力、YAKE关键词信号和与风险分类法相关的词汇搭配匹配，在没有人工标注的情况下生成句子标签。该基准使用一个包含193个术语映射到21个细粒度类型（嵌套在5个宏类下）的风险分类法。

Result: GRAB基准包含跨越5个宏类别的21个细粒度风险类型，并提供了固定数据集划分、准确率、宏F1分数、Topic BERTScore和基于熵的有效主题数量等评估指标，支持对不同主题模型进行标准化比较。

Conclusion: GRAB基准、标签和代码为金融披露领域的经典、基于嵌入、神经网络和混合主题模型提供了可复现和标准化的比较基础，解决了现有研究的不足。

Abstract: Risk categorization in 10-K risk disclosures matters for oversight and
investment, yet no public benchmark evaluates unsupervised topic models for
this task. We present GRAB, a finance-specific benchmark with 1.61M sentences
from 8,247 filings and span-grounded sentence labels produced without manual
annotation by combining FinBERT token attention, YAKE keyphrase signals, and
taxonomy-aware collocation matching. Labels are anchored in a risk taxonomy
mapping 193 terms to 21 fine-grained types nested under five macro classes; the
21 types guide weak supervision, while evaluation is reported at the macro
level. GRAB unifies evaluation with fixed dataset splits and robust
metrics--Accuracy, Macro-F1, Topic BERTScore, and the entropy-based Effective
Number of Topics. The dataset, labels, and code enable reproducible,
standardized comparison across classical, embedding-based, neural, and hybrid
topic models on financial disclosures.

</details>


### [184] [Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval](https://arxiv.org/abs/2509.21710)
*Xiaojun Wu,Cehao Yang,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Hui Xiong,Jia Li,Jian Guo*

Main category: cs.CL

TL;DR: ToG-3是一个新框架，通过MACER机制动态构建和优化异构图索引（包含块、三元组和社区），并引入了演化查询和演化子图的双重演化机制，以解决现有RAG方法在图结构质量和静态图索引上的局限性。多智能体协同工作，实现了证据检索、答案生成、充分性反思以及查询和子图的演化，从而提高了推理的准确性和深度，尤其是在使用轻量级LLM时。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）和基于图的RAG方法在依赖高质量图结构方面面临挑战。手动构建知识图成本高昂，而自动提取的图受限于基础LLM提取器的性能，尤其是在使用小型、本地部署的模型时。这导致在图的质量和动态适应性方面存在局限。

Method: 提出Think-on-Graph 3.0 (ToG-3)框架，引入多智能体上下文演化与检索（MACER）机制。该机制动态构建和优化一个包含块、三元组和社区的异构图索引。核心创新在于演化查询和演化子图的双重演化机制，用于精确证据检索。采用多智能体系统（包括构造者、检索者、反思者和响应者）进行迭代式的证据检索、答案生成、充分性反思，并演化查询和子图，从而在推理过程中自适应地构建目标图索引。

Result: ToG-3框架在深度和广度推理基准测试中表现优于现有基线方法。消融实验证实了MACER框架各组成部分的有效性。

Conclusion: ToG-3通过其动态构建和优化的图索引以及多智能体协同的演化机制，成功克服了现有基于图的RAG方法的局限性，实现了更精确、更深入的推理，并且在轻量级LLM环境下表现出色。

Abstract: Retrieval-Augmented Generation (RAG) and Graph-based RAG has become the
important paradigm for enhancing Large Language Models (LLMs) with external
knowledge. However, existing approaches face a fundamental trade-off. While
graph-based methods are inherently dependent on high-quality graph structures,
they face significant practical constraints: manually constructed knowledge
graphs are prohibitively expensive to scale, while automatically extracted
graphs from corpora are limited by the performance of the underlying LLM
extractors, especially when using smaller, local-deployed models. This paper
presents Think-on-Graph 3.0 (ToG-3), a novel framework that introduces
Multi-Agent Context Evolution and Retrieval (MACER) mechanism to overcome these
limitations. Our core innovation is the dynamic construction and refinement of
a Chunk-Triplets-Community heterogeneous graph index, which pioneeringly
incorporates a dual-evolution mechanism of Evolving Query and Evolving
Sub-Graph for precise evidence retrieval. This approach addresses a critical
limitation of prior Graph-based RAG methods, which typically construct a static
graph index in a single pass without adapting to the actual query. A
multi-agent system, comprising Constructor, Retriever, Reflector, and Responser
agents, collaboratively engages in an iterative process of evidence retrieval,
answer generation, sufficiency reflection, and, crucially, evolving query and
subgraph. This dual-evolving multi-agent system allows ToG-3 to adaptively
build a targeted graph index during reasoning, mitigating the inherent
drawbacks of static, one-time graph construction and enabling deep, precise
reasoning even with lightweight LLMs. Extensive experiments demonstrate that
ToG-3 outperforms compared baselines on both deep and broad reasoning
benchmarks, and ablation studies confirm the efficacy of the components of
MACER framework.

</details>


### [185] [ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation](https://arxiv.org/abs/2509.21730)
*Jiho Kim,Junseong Choi,Woosog Chay,Daeun Kyung,Yeonsu Kwon,Yohan Jo,Edward Choi*

Main category: cs.CL

TL;DR: 该研究提出了一个结合了前瞻性和个性化的新任务和模拟框架ProPerSim，以及一个名为ProPerAssistant的助手，用于在家庭场景中提供个性化推荐。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）日益融入日常生活，对能够进行前瞻性和个性化交互的AI助手的需求不断增长，而这两者的结合仍然是一个未被充分探索的领域。

Method: 提出ProPerSim任务和模拟框架，用户代理（具有丰富个性）在其中与助手进行交互，并根据推荐的匹配度提供评分。助手利用这些评分进行学习和适应。在此基础上，提出ProPerAssistant，一个检索增强的、偏好对齐的助手。

Result: 在32种不同个性的实验中，ProPerAssistant能够调整其策略并持续提高用户满意度。

Conclusion: 结合前瞻性和个性化具有巨大潜力，ProPerAssistant展示了通过用户反馈进行持续学习和适应的能力。

Abstract: As large language models (LLMs) become increasingly integrated into daily
life, there is growing demand for AI assistants that are not only reactive but
also proactive and personalized. While recent advances have pushed forward
proactivity and personalization individually, their combination remains
underexplored. To bridge this gap, we introduce ProPerSim, a new task and
simulation framework for developing assistants capable of making timely,
personalized recommendations in realistic home scenarios. In our simulation
environment, a user agent with a rich persona interacts with the assistant,
providing ratings on how well each suggestion aligns with its preferences and
context. The assistant's goal is to use these ratings to learn and adapt to
achieve higher scores over time. Built on ProPerSim, we propose
ProPerAssistant, a retrieval-augmented, preference-aligned assistant that
continually learns and adapts through user feedback. Experiments across 32
diverse personas show that ProPerAssistant adapts its strategy and steadily
improves user satisfaction, highlighting the promise of uniting proactivity and
personalization.

</details>


### [186] [How Accurate Are LLMs at Multi-Question Answering on Conversational Transcripts?](https://arxiv.org/abs/2509.21732)
*Xiliang Zhu,Shi Zong,David Rossouw*

Main category: cs.CL

TL;DR: 在工业环境中，使用大型语言模型（LLM）处理长文本问答（QA）面临计算成本高和延迟大的挑战。本研究探讨了LLM基于同一对话上下文回答多个问题的能力，并通过大量实验对不同模型进行了基准测试。结果表明，虽然GPT-4o等强大的专有LLM整体表现最佳，但经过微调的、参数量高达80亿的公共LLM在准确性上可以超越GPT-4o，显示出其在实际应用中部署的潜力和成本效益。


<details>
  <summary>Details</summary>
Motivation: 在工业环境中，使用大型语言模型（LLM）处理长文本问答（QA）面临计算成本高和延迟大的挑战，特别是在需要基于同一上下文回答多个问题时。因此，有必要研究LLM在处理此类多轮对话问答任务时的能力。

Method: 对一系列专有和公共的大型语言模型（LLM）进行了广泛的实验和基准测试，以评估它们在基于同一对话上下文回答多个问题方面的能力。

Result: 在众多模型中，像GPT-4o这样的强大专有LLM实现了最佳的整体性能。然而，经过微调的、参数量高达80亿的公共LLM在准确性方面能够超越GPT-4o。

Conclusion: 虽然强大的专有LLM在多轮对话问答任务中表现出色，但经过微调的公共LLM也展现出了巨大的潜力，它们在准确性上可以媲美甚至超越顶尖模型，并且在透明度和成本效益方面具有优势，适合在实际应用中进行部署。

Abstract: Deploying Large Language Models (LLMs) for question answering (QA) over
lengthy contexts is a significant challenge. In industrial settings, this
process is often hindered by high computational costs and latency, especially
when multiple questions must be answered based on the same context. In this
work, we explore the capabilities of LLMs to answer multiple questions based on
the same conversational context. We conduct extensive experiments and benchmark
a range of both proprietary and public models on this challenging task. Our
findings highlight that while strong proprietary LLMs like GPT-4o achieve the
best overall performance, fine-tuned public LLMs with up to 8 billion
parameters can surpass GPT-4o in accuracy, which demonstrates their potential
for transparent and cost-effective deployment in real-world applications.

</details>


### [187] [Self-Speculative Biased Decoding for Faster Live Translation](https://arxiv.org/abs/2509.21740)
*Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang*

Main category: cs.CL

TL;DR: LLMs在流式应用中存在挑战，提出了一种名为Self-Speclative Biased Decoding的新推理范式，以解决重复生成和计算成本问题，可实现高达1.7倍的加速且不影响质量。


<details>
  <summary>Details</summary>
Motivation: LLMs在流式应用（如实时翻译）中存在计算成本高、延迟要求难以满足的挑战，需要一种能够持续更新输出同时保持合理计算成本的方法。

Method: 提出了一种名为Self-Speculative Biased Decoding的新推理范式，避免从头开始为不断增长的输入流重复生成输出。该方法利用最近的输出来作为当前增长输入上下文的草稿，并在验证阶段偏向草稿标记以提高接受率，从而最小化闪烁并提高速度。

Result: 在同时文本到文本的再翻译实验中，该方法实现了高达1.7倍的速度提升，且不影响质量。通过结合display-only mask-k技术，闪烁现象减少了80%。

Conclusion: Self-Speculative Biased Decoding是一种模型无关的即插即用解决方案，可以加速延迟敏感的流式应用程序，通过利用草稿和偏差解码来提高效率并减少输出闪烁。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in various text generation tasks. However, it remains challenging
to use them off-the-shelf in streaming applications (such as live translation),
where the output must continually update as the input context expands, while
still maintaining a reasonable computational cost to meet the latency
requirement.
  In this work, we reexamine the re-translation approach to simultaneous
translation and propose Self-Speculative Biased Decoding, a novel inference
paradigm designed to avoid repeatedly generating output from scratch for a
consistently growing input stream. We propose using the most recent output as a
draft for the current growing input context. During the verification stage, the
output will be biased towards the draft token for a higher draft acceptance
rate. This strategy not only minimizes flickering that might distract users but
also leads to higher speedups. Conventional decoding may take charge from the
point of divergence after draft verification and continue until the end
condition is met.
  Unlike existing speculative decoding strategies, our approach eliminates the
need for draft computations, making it a model-agnostic and plug-and-play
solution for accelerating latency-sensitive streaming applications.
Experimental results on simultaneous text-to-text re-translation demonstrate
that our approach achieves up to 1.7x speedup compared to conventional
auto-regressive re-translation without compromising quality. Additionally, it
significantly reduces flickering by 80% by incorporating the display-only
mask-k technique.

</details>


### [188] [Thinking with Sound: Audio Chain-of-Thought Enables Multimodal Reasoning in Large Audio-Language Models](https://arxiv.org/abs/2509.21749)
*Zhen Xiong,Yujun Cai,Zhecheng Li,Junsong Yuan,Yiwei Wang*

Main category: cs.CL

TL;DR: TwS框架通过结合语言推理和动态音频分析，为大型音语模型（LALMs）提供音频思维链（Audio CoT），以提高其在复杂声学场景下的推理能力，并在MELD-Hard1k基准测试中显著提升了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型音语模型（LALMs）在处理复杂声学环境下的音频推理任务时存在局限性，无法利用降噪、声源分离等音频工具。

Method: 提出Thinking-with-Sound (TwS)框架，使LALMs能够通过多模态推理进行动态音频信号分析和数字处理，实现“音频思维链”（Audio CoT）。

Result: 在MELD-Hard1k基准测试中，TwS显著提高了模型的鲁棒性，准确率提升了24.73%至36.61%，而现有LALMs在MELD-Hard1k上的准确率下降超过50%。

Conclusion: 音频思维链（Audio CoT）能够显著增强模型的鲁棒性，而无需重新训练，为开发更强大的音频理解系统开辟了新方向。

Abstract: Recent Large Audio-Language Models (LALMs) have shown strong performance on
various audio understanding tasks such as speech translation and Audio Q\&A.
However, they exhibit significant limitations on challenging audio reasoning
tasks in complex acoustic scenarios. These situations would greatly benefit
from the use of acoustic tools like noise suppression, source separation, and
precise temporal alignment, but current LALMs lack access to such tools. To
address this limitation, we introduce Thinking-with-Sound (TwS), a framework
that equips LALMs with Audio CoT by combining linguistic reasoning with
on-the-fly audio-domain analysis. Unlike existing approaches that treat audio
as static input, TwS enables models to actively think with audio signals,
performing numerical analysis and digital manipulation through multimodal
reasoning. To evaluate this approach, we construct MELD-Hard1k, a new
robustness benchmark created by introducing various acoustic perturbations.
Experiments reveal that state-of-the-art LALMs suffer dramatic performance
degradation on MELD-Hard1k, with accuracy dropping by more than $50\%$ compared
to clean audio. TwS achieves substantial improvements in robustness,
demonstrating both effectiveness and scalability: small models gain $24.73\%$
absolute accuracy, with improvements scaling consistently up to $36.61\%$ for
larger models. Our findings demonstrate that Audio CoT can significantly
enhance robustness without retraining, opening new directions for developing
more robust audio understanding systems.

</details>


### [189] [SynerGen: Contextualized Generative Recommender for Unified Search and Recommendation](https://arxiv.org/abs/2509.21777)
*Vianne R. Gao,Chen Xue,Marc Versage,Xie Zhou,Zhongruo Wang,Chao Li,Yeon Seonwoo,Nan Chen,Zhen Ge,Gourab Kundu,Weiqi Zhang,Tian Wang,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: SynerGen是一个新颖的生成推荐模型，它通过提供一个单一的生成骨干来统一个性化搜索和推荐，同时在检索和排序任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统流水线存在失准和工程开销问题，而生成序列模型在统一检索和排序方面有待提高，尤其是在同时处理个性化搜索和查询无关推荐时存在性能权衡。

Method: SynerGen是一个单一的、面向检索和排序任务的生成模型。它使用Transformer解码器，并在InfoNCE损失下进行联合优化，以进行检索，并使用混合的逐点-成对损失进行排序。它还引入了一种新的时间感知旋转位置嵌入，以将时间信息整合到注意力机制中。

Result: SynerGen在广泛采用的推荐和搜索基准上取得了显著的改进，与强大的生成推荐模型和联合搜索推荐基线相比。

Conclusion: 这项工作证明了单一生成基础模型在工业规模的统一信息访问中的可行性。

Abstract: The dominant retrieve-then-rank pipeline in large-scale recommender systems
suffers from mis-calibration and engineering overhead due to its architectural
split and differing optimization objectives. While recent generative sequence
models have shown promise in unifying retrieval and ranking by
auto-regressively generating ranked items, existing solutions typically address
either personalized search or query-free recommendation, often exhibiting
performance trade-offs when attempting to unify both. We introduce
\textit{SynerGen}, a novel generative recommender model that bridges this
critical gap by providing a single generative backbone for both personalized
search and recommendation, while simultaneously excelling at retrieval and
ranking tasks. Trained on behavioral sequences, our decoder-only Transformer
leverages joint optimization with InfoNCE for retrieval and a hybrid
pointwise-pairwise loss for ranking, allowing semantic signals from search to
improve recommendation and vice versa. We also propose a novel time-aware
rotary positional embedding to effectively incorporate time information into
the attention mechanism. \textit{SynerGen} achieves significant improvements on
widely adopted recommendation and search benchmarks compared to strong
generative recommender and joint search and recommendation baselines. This work
demonstrates the viability of a single generative foundation model for
industrial-scale unified information access.

</details>


### [190] [Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference](https://arxiv.org/abs/2509.21791)
*Han Yuan,Yue Zhao,Li Zhang,Wuqiong Luo,Zheng Ma*

Main category: cs.CL

TL;DR: 结构化输出对大型语言模型（LLMs）的生成质量没有因果影响，除了在涉及具体指令的多方面因果结构中。


<details>
  <summary>Details</summary>
Motivation: 评估结构化输出对LLM生成质量的影响，解决先前研究中存在的评估局限性。

Method: 运用因果推断方法，在七个公开和一项自研推理任务上分析结构化输出对GPT-4o生成的影响，并推导出五种潜在的因果结构。

Result: 尽管粗粒度指标显示结构化输出对LLM生成质量有正面、负面或中性影响，但因果推断发现在48个场景中有43个没有发现因果影响。在剩余的5个场景中，有3个涉及受具体指令影响的多方面因果结构。

Conclusion: 结构化输出对LLM的生成质量没有普遍的因果影响，其影响可能受具体指令和复杂因果结构的影响。

Abstract: Structured output from large language models (LLMs) has enhanced efficiency
in processing generated information and is increasingly adopted in industrial
applications. Prior studies have investigated the impact of structured output
on LLMs' generation quality, often presenting one-way findings. Some suggest
that structured format enhances completeness and factual accuracy, while others
argue that it restricts the reasoning capacity of LLMs and leads to reductions
in standard evaluation metrics. Potential limitations of these assessments
include restricted testing scenarios, weakly controlled comparative settings,
and reliance on coarse metrics. In this work, we present a refined analysis
using causal inference. Based on one assumed and two guaranteed constraints, we
derive five potential causal structures characterizing the influence of
structured output on LLMs' generation: (1) collider without m-bias, (2)
collider with m-bias, (3) single cause from instruction, (4) single cause from
output format, and (5) independence. Across seven public and one developed
reasoning tasks, we find that coarse metrics report positive, negative, or
neutral effects of structured output on GPT-4o's generation. However, causal
inference reveals no causal impact in 43 out of 48 scenarios. In the remaining
5, 3 involve multifaceted causal structures influenced by concrete
instructions.

</details>


### [191] [Evaluating and Improving Cultural Awareness of Reward Models for LLM Alignment](https://arxiv.org/abs/2509.21798)
*Hongbin Zhang,Kehai Chen,Xuefeng Bai,Yang Xiang,Min Zhang*

Main category: cs.CL

TL;DR: 现有的大语言模型（LLM）的奖励模型（RM）在文化意识方面存在不足，本研究提出了CARB基准测试和Think-as-Locals方法来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 现有的RM评估方法缺乏对文化意识的评估，限制了LLM的全球对齐。因此，有必要评估和改进RM的文化意识。

Method: 提出CARB基准测试，包含10种文化和4个文化领域。提出Think-as-Locals方法，通过RLVR和精心设计的奖励来解决RM中的虚假关联问题。

Result: CARB基准测试揭示了现有RM在文化意识建模方面的不足。Think-as-Locals方法被证明能有效缓解虚假特征的干扰，并促进文化意识的奖励建模。

Conclusion: CARB和Think-as-Locals为评估和改进LLM的文化意识提供了新的解决方案，有望促进LLM的全球对齐。

Abstract: Reward models (RMs) are crucial for aligning large language models (LLMs)
with diverse cultures. Consequently, evaluating their cultural awareness is
essential for further advancing global alignment of LLMs. However, existing RM
evaluations fall short in assessing cultural awareness due to the scarcity of
culturally relevant evaluation datasets. To fill this gap, we propose Cultural
Awareness Reward modeling Benchmark (CARB), covering 10 distinct cultures
across 4 cultural domains. Our extensive evaluation of state-of-the-art RMs
reveals their deficiencies in modeling cultural awareness and demonstrates a
positive correlation between performance on CARB and downstream multilingual
cultural alignment tasks. Further analysis identifies the spurious correlations
within culture-aware reward modeling, wherein RM's scoring relies predominantly
on surface-level features rather than authentic cultural nuance understanding.
To address these, we propose Think-as-Locals to elicit deeper culturally
grounded reasoning from generative RMs via reinforcement learning from
verifiable rewards (RLVR) and employ well-designed rewards to ensure accurate
preference judgments and high-quality structured evaluation criteria
generation. Experimental results validate its efficacy in mitigating spurious
features interference and advancing culture-aware reward modeling.

</details>


### [192] [Redefining Machine Simultaneous Interpretation: From Incremental Translation to Human-Like Strategies](https://arxiv.org/abs/2509.21801)
*Qianen Zhang,Satoshi Nakamura*

Main category: cs.CL

TL;DR: We introduce adaptive actions for Simultaneous Machine Translation (SiMT) in a decoder-only LLM framework to improve quality and reduce latency. Our method achieves better semantic metrics and lower delay compared to baselines.


<details>
  <summary>Details</summary>
Motivation: Traditional encoder-decoder policies for SiMT struggle to meet real-time constraints while maintaining translation quality. Existing methods do not fully address the need for restructuring, omission, and simplification in real-time.

Method: We extend the action space of SiMT with four adaptive actions: SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION, and PRONOMINALIZATION. These actions are implemented in a decoder-only LLM framework, with training references generated through action-aware prompting. A latency-aware TTS pipeline is used for evaluation.

Result: Our framework consistently improves semantic metrics (e.g., COMET-KIWI) and achieves lower delay (measured by Average Lagging) on English-Chinese and English-German benchmarks compared to reference translations and salami-based baselines. The combination of DROP and SENTENCE_CUT shows the best balance between fluency and latency.

Conclusion: Enriching the action space of LLM-based SiMT with adaptive actions is a promising direction for improving translation quality and reducing latency, bridging the gap between human and machine interpretation.

Abstract: Simultaneous Machine Translation (SiMT) requires high-quality translations
under strict real-time constraints, which traditional encoder-decoder policies
with only READ/WRITE actions cannot fully address. We extend the action space
of SiMT with four adaptive actions: SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION
and PRONOMINALIZATION, which enable real-time restructuring, omission, and
simplification while preserving semantic fidelity. We implement these actions
in a decoder-only large language model (LLM) framework and construct training
references through action-aware prompting. To evaluate both quality and
latency, we further develop a latency-aware TTS pipeline that maps textual
outputs to speech with realistic timing. Experiments on the ACL60/60
English-Chinese and English-German benchmarks show that our framework
consistently improves semantic metrics (e.g., COMET-KIWI) and achieves lower
delay (measured by Average Lagging) compared to reference translations and
salami-based baselines. Notably, combining DROP and SENTENCE_CUT yields the
best overall balance between fluency and latency. These results demonstrate
that enriching the action space of LLM-based SiMT provides a promising
direction for bridging the gap between human and machine interpretation.

</details>


### [193] [Towards Minimal Causal Representations for Human Multimodal Language Understanding](https://arxiv.org/abs/2509.21805)
*Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai*

Main category: cs.CL

TL;DR: CaMIB通过引入因果原理来解决多模态语言理解中的数据集偏差问题，提高了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的人类多模态语言理解（MLU）方法易受数据集偏差影响，导致模型泛化能力下降。

Method: 提出因果多模态信息瓶颈（CaMIB）模型，采用信息瓶颈过滤噪声，通过掩码生成器解耦因果特征和捷径特征，并引入工具变量约束和后门调整来稳定因果估计。

Result: 在多模态情感分析、幽默检测和讽刺检测任务上进行了广泛实验，并使用了分布外（OOD）测试集，证明了CaMIB的有效性。

Conclusion: CaMIB模型在提高模型泛化能力和解释性方面表现出色，其理论和经验分析均证明了其合理性。

Abstract: Human Multimodal Language Understanding (MLU) aims to infer human intentions
by integrating related cues from heterogeneous modalities. Existing works
predominantly follow a ``learning to attend" paradigm, which maximizes mutual
information between data and labels to enhance predictive performance. However,
such methods are vulnerable to unintended dataset biases, causing models to
conflate statistical shortcuts with genuine causal features and resulting in
degraded out-of-distribution (OOD) generalization. To alleviate this issue, we
introduce a Causal Multimodal Information Bottleneck (CaMIB) model that
leverages causal principles rather than traditional likelihood. Concretely, we
first applies the information bottleneck to filter unimodal inputs, removing
task-irrelevant noise. A parameterized mask generator then disentangles the
fused multimodal representation into causal and shortcut subrepresentations. To
ensure global consistency of causal features, we incorporate an instrumental
variable constraint, and further adopt backdoor adjustment by randomly
recombining causal and shortcut features to stabilize causal estimation.
Extensive experiments on multimodal sentiment analysis, humor detection, and
sarcasm detection, along with OOD test sets, demonstrate the effectiveness of
CaMIB. Theoretical and empirical analyses further highlight its
interpretability and soundness.

</details>


### [194] [Can LLMs Solve and Generate Linguistic Olympiad Puzzles?](https://arxiv.org/abs/2509.21820)
*Neh Majmudar,Elena Filatova*

Main category: cs.CL

TL;DR: LLMs在语言文字解谜任务中表现出色，超越人类，并可用于生成新谜题，从而推广语言学。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决和生成语言文字谜题，特别是高中生奥林匹克竞赛中使用的谜题，并探讨利用大型语言模型（LLMs）解决这些谜题的潜力，以及开发自动生成谜题的方法，以期扩大人们对语言学的兴趣并推广相关知识。

Method: 本文首先扩展了现有的语言文字解谜任务基准，并探索了包括OpenAI的o1在内的最新大型语言模型（LLMs）在解决此类谜题中的应用，分析了它们在不同语言学主题上的表现。然后，利用解谜实验的见解，进行谜题生成任务的研究。

Result: LLMs在大多数类型的语言文字谜题上表现优于人类，但在涉及文字系统和研究不足的语言的谜题上表现稍逊。研究表明，自动生成谜题（即使是相对简单的谜题）有潜力激发对语言学的兴趣，并向更广泛的受众介绍该领域。

Conclusion: LLMs在解决语言文字谜题方面展现出强大能力，并且在谜题生成任务中也显示出潜力，这对于推广语言学和传播关于罕见及研究不足的语言的知识具有重要意义。

Abstract: In this paper, we introduce a combination of novel and exciting tasks: the
solution and generation of linguistic puzzles. We focus on puzzles used in
Linguistic Olympiads for high school students. We first extend the existing
benchmark for the task of solving linguistic puzzles. We explore the use of
Large Language Models (LLMs), including recent state-of-the-art models such as
OpenAI's o1, for solving linguistic puzzles, analyzing their performance across
various linguistic topics. We demonstrate that LLMs outperform humans on most
puzzles types, except for those centered on writing systems, and for the
understudied languages. We use the insights from puzzle-solving experiments to
direct the novel task of puzzle generation. We believe that automating puzzle
generation, even for relatively simple puzzles, holds promise for expanding
interest in linguistics and introducing the field to a broader audience. This
finding highlights the importance of linguistic puzzle generation as a research
task: such puzzles can not only promote linguistics but also support the
dissemination of knowledge about rare and understudied languages.

</details>


### [195] [ResT: Reshaping Token-Level Policy Gradients for Tool-Use Large Language Models](https://arxiv.org/abs/2509.21826)
*Zihan Lin,Xiaohan Wang,Jie Cao,Jiajun Chai,Guojun Yin,Wei Lin,Ran He*

Main category: cs.CL

TL;DR: LLM通过调用外部工具可以实现目标导向的代理，但现有的基于强化学习的工具使用策略优化方法存在效率低的问题。本文提出了ResT方法，通过信息熵重塑代币级策略梯度，以提高训练稳定性和效率，并在多项基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在优化LLM的工具使用策略时，仅依赖稀疏的奖励信号，且未考虑工具使用任务的特性，导致策略梯度方差增大和训练效率低下。

Method: 提出了一种名为ResT（Reshaped Token-level policy gradients）的方法。ResT通过信息熵重塑代币级策略梯度，逐步增加对推理代币的权重，从而实现从结构正确性到语义推理的平滑过渡，并稳定多轮工具使用任务的收敛。

Result: 在BFCL和API-Bank基准测试中，ResT取得了最先进的成果，在某些方面超越了先前的方法高达8.76%。在4B基础LLM上进行微调后，ResT在单轮任务上比GPT-4o高出4.11%，在多轮基础任务上高出1.50%。

Conclusion: ResT通过信息熵重塑代币级策略梯度，有效解决了LLM工具使用策略优化中的效率和稳定性问题，并在多项基准测试中取得了优于现有方法和GPT-4o的性能。

Abstract: Large language models (LLMs) transcend passive generation and act as
goal-directed agents by invoking external tools. Reinforcement learning (RL)
offers a principled framework for optimizing these emergent tool-use policies,
yet the prevailing paradigm relies exclusively on sparse outcome rewards and
lacks consideration of the particularity of tool-use tasks, inflating
policy-gradient variance and resulting in inefficient training. To better
understand and address these challenges, we first establish a theoretical link
between policy entropy and training stability of tool-use tasks, which reveals
that structured, low-entropy tokens are primary determinants of rewards.
Motivated by this insight, we propose \textbf{Res}haped \textbf{T}oken-level
policy gradients (\textbf{ResT}) for tool-use tasks. ResT reshapes the policy
gradient through entropy-informed token reweighting, progressively upweighting
reasoning tokens as training proceeds. This entropy-aware scheme enables a
smooth shift from structural correctness to semantic reasoning and stabilizes
convergence in multi-turn tool-use tasks. Evaluation on BFCL and API-Bank shows
that ResT achieves state-of-the-art results, outperforming prior methods by up
to $8.76\%$. When fine-tuned on a 4B base LLM, ResT further surpasses GPT-4o by
$4.11\%$ on single-turn tasks and $1.50\%$ on multi-turn base tasks.

</details>


### [196] [Semantic Agreement Enables Efficient Open-Ended LLM Cascades](https://arxiv.org/abs/2509.21837)
*Duncan Soiffer,Steven Kolawole,Virginia Smith*

Main category: cs.CL

TL;DR: Cascade systems can reduce LLM deployment costs by routing requests to smaller models, but open-ended generation poses challenges in assessing output reliability. This paper introduces semantic agreement, a training-free method using meaning-level consensus from ensemble outputs, as a signal for reliable deferral. This approach outperforms traditional token-level confidence and achieves comparable or better quality at significantly lower costs and latency, working even with black-box APIs and across model updates.


<details>
  <summary>Details</summary>
Motivation: Open-ended text generation in cascade systems faces a challenge in determining output reliability due to the continuous spectrum of generation quality and the existence of multiple valid responses. Traditional methods relying on token-level confidence are insufficient in this scenario.

Method: The paper proposes 'semantic agreement,' a training-free signal for reliable deferral. This method leverages meaning-level consensus between ensemble outputs. When diverse model outputs agree semantically, their consensus serves as a stronger reliability signal than token-level confidence.

Result: Semantic cascades demonstrate the ability to match or surpass target-model quality while operating at 40% of the cost and reducing latency by up to 60%. The method is effective across a range of model sizes (500M to 70B parameters) and is compatible with black-box APIs, requiring no access to model internals.

Conclusion: Semantic agreement is a practical and robust solution for reliable deferral in cascade systems for LLM deployment. It offers significant cost and latency benefits without compromising quality, and its adaptability to black-box APIs and model updates makes it a valuable baseline for real-world applications.

Abstract: Cascade systems route computational requests to smaller models when possible
and defer to larger models only when necessary, offering a promising approach
to balance cost and quality in LLM deployment. However, they face a fundamental
challenge in open-ended text generation: determining output reliability when
generation quality lies on a continuous spectrum, often with multiple valid
responses. To address this, we propose semantic agreement -- meaning-level
consensus between ensemble outputs -- as a training-free signal for reliable
deferral. We show that when diverse model outputs agree semantically, their
consensus is a stronger reliability signal than token-level confidence.
Evaluated from 500M to 70B-parameter models, we find that semantic cascades
match or surpass target-model quality at 40% of the cost and reduce latency by
up to 60%. Our method requires no model internals, works across black-box APIs,
and remains robust to model updates, making it a practical baseline for
real-world LLM deployment.

</details>


### [197] [KnowMT-Bench: Benchmarking Knowledge-Intensive Long-Form Question Answering in Multi-Turn Dialogues](https://arxiv.org/abs/2509.21856)
*Junhao Chen,Yu Huang,Siyuan Li,Rui Yao,Hanqian Li,Hanyu Zhang,Jungang Li,Jian Chen,Bowen Wang,Xuming Hu*

Main category: cs.CL

TL;DR: KnowMT-Bench 是一个用于评估大型语言模型（LLMs）在知识密集型领域的多轮长问答（MT-LFQA）能力的新基准。该基准通过动态评估设置，模拟真实世界对话，并使用自动化的流程评估最终答案的事实准确性和信息传递效率。实验表明，多轮对话会降低 LLMs 的事实能力和信息效率，但检索增强生成（RAG）可以有效缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多轮对话基准通常不侧重于知识密集型领域的事实准确性，而现有的长问答基准又局限于单轮对话。为了解决这一问题，本研究引入了 KnowMT-Bench，这是第一个专门用于系统评估 LLMs 在知识密集型领域（如医学、金融和法律）的多轮长问答能力的基准。

Method: KnowMT-Bench 采用动态评估设置，允许模型根据逻辑递进的问题序列自行生成多轮对话历史。然后，使用经过人工验证的自动化流程来评估最终答案的事实能力和信息传递效率。

Result: 实验结果表明，多轮对话背景会降低 LLMs 的性能。具体来说，事实能力会因自我生成历史带来的上下文噪声而下降，信息效率会随着对话长度的增加而降低，因为模型变得更加冗长。然而，研究还发现，检索增强生成（RAG）可以有效缓解甚至逆转这种事实能力的下降。

Conclusion: KnowMT-Bench 的引入对于评估和增强 LLMs 在真实世界知识密集型应用中的对话事实能力至关重要。研究结果强调了多轮对话对 LLMs 性能的影响，并提出了 RAG 作为一种有效的缓解策略。

Abstract: Multi-Turn Long-Form Question Answering (MT-LFQA) is a key application
paradigm of Large Language Models (LLMs) in knowledge-intensive domains.
However, existing benchmarks are limited to single-turn dialogue, while
multi-turn dialogue benchmarks typically assess other orthogonal capabilities
rather than knowledge-intensive factuality. To bridge this critical gap, we
introduce \textbf{KnowMT-Bench}, the \textit{first-ever} benchmark designed to
systematically evaluate MT-LFQA for LLMs across knowledge-intensive fields,
including medicine, finance, and law. To faithfully assess the model's
real-world performance, KnowMT-Bench employs a dynamic evaluation setting where
models generate their own multi-turn dialogue histories given logically
progressive question sequences. The factual capability and information delivery
efficiency of the \textit{final-turn} answer are then evaluated using a
human-validated automated pipeline. Our experiments reveal that multi-turn
contexts degrade performance: factual capability declines due to the contextual
noise from self-generated histories, while information efficiency drops as
models become more verbose with increasing dialogue length. We then investigate
mitigation strategies, demonstrating that retrieval-augmented generation (RAG)
can effectively alleviate and even reverse this factual degradation. These
findings underscore the importance of our benchmark in evaluating and enhancing
the conversational factual capabilities of LLMs in real-world
knowledge-intensive applications. Code is available at
\href{https://github.com/hardenyu21/KnowMT-Bench}{\textcolor{cyan}{\texttt{KnowMT-Bench}}}.

</details>


### [198] [Enhancing Low-Rank Adaptation with Structured Nonlinear Transformations](https://arxiv.org/abs/2509.21870)
*Guanzhi Deng,Mingyang Liu,Dapeng Wu,Yinqiao Li,Linqi Song*

Main category: cs.CL

TL;DR: LoRAN是一种非线性LoRA的扩展，使用Sinter（一种基于正弦的激活函数）来增强大型语言模型的表达能力，并在各种任务中提高了性能。


<details>
  <summary>Details</summary>
Motivation: LoRA的线性性质限制了其表达能力，需要一种更具表现力的参数高效微调方法。

Method: 提出LoRAN，一种非线性LoRA的扩展，通过对低秩更新应用轻量级变换，并引入Sinter（一种基于正弦的激活函数）来增加结构化扰动，而无需增加参数数量。

Result: LoRAN在各项任务中的表现持续优于QLoRA，并且Sinter激活函数比标准激活函数（如Sigmoid、ReLU和Tanh）效果更好，证明了激活函数设计在低秩微调中的重要性。

Conclusion: LoRAN通过引入非线性能力和精心设计的激活函数，有效提升了参数高效微调的性能。

Abstract: Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient
fine-tuning method for large language models. However, its linear nature limits
expressiveness. We propose LoRAN, a non-linear extension of LoRA that applies
lightweight transformations to the low-rank updates. We further introduce
Sinter, a sine-based activation that adds structured perturbations without
increasing parameter count. Experiments across summarization and classification
tasks show that LoRAN consistently improves over QLoRA. Ablation studies reveal
that Sinter outperforms standard activations such as Sigmoid, ReLU, and Tanh,
highlighting the importance of activation design in lowrank tuning.

</details>


### [199] [LUMINA: Detecting Hallucinations in RAG System with Context-Knowledge Signals](https://arxiv.org/abs/2509.21875)
*Min-Hsuan Yeh,Yixuan Li,Tanwi Mallick*

Main category: cs.CL

TL;DR: RAG系统中的LLM仍然会产生幻觉。LUMINA通过量化外部上下文和内部知识的利用来检测幻觉，无需超参数调整，并在基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG幻觉检测方法需要大量的超参数调整，泛化性有限。

Method: LUMINA通过计算上下文利用的分布距离和跟踪Transformer层中预测的token演变来量化内部知识的利用，并引入了一个统计验证框架。

Result: LUMINA在常见的RAG幻觉基准测试和四个开源LLM上取得了高AUROC和AUPRC分数，在HalluRAG上比现有方法高出+13% AUROC。

Conclusion: LUMINA是一种有效且实用的框架，可以检测RAG系统中的幻觉，即使在检索质量和模型匹配的假设放宽的情况下也保持稳健。

Abstract: Retrieval-Augmented Generation (RAG) aims to mitigate hallucinations in large
language models (LLMs) by grounding responses in retrieved documents. Yet,
RAG-based LLMs still hallucinate even when provided with correct and sufficient
context. A growing line of work suggests that this stems from an imbalance
between how models use external context and their internal knowledge, and
several approaches have attempted to quantify these signals for hallucination
detection. However, existing methods require extensive hyperparameter tuning,
limiting their generalizability. We propose LUMINA, a novel framework that
detects hallucinations in RAG systems through context-knowledge signals:
external context utilization is quantified via distributional distance, while
internal knowledge utilization is measured by tracking how predicted tokens
evolve across transformer layers. We further introduce a framework for
statistically validating these measurements. Experiments on common RAG
hallucination benchmarks and four open-source LLMs show that LUMINA achieves
consistently high AUROC and AUPRC scores, outperforming prior utilization-based
methods by up to +13% AUROC on HalluRAG. Moreover, LUMINA remains robust under
relaxed assumptions about retrieval quality and model matching, offering both
effectiveness and practicality.

</details>


### [200] [No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping](https://arxiv.org/abs/2509.21880)
*Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang*

Main category: cs.CL

TL;DR: RL-ZVP 算法提出了一种从零方差提示中提取学习信号的新方法，以改进大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有 RLVR 方法忽略了所有响应获得相同奖励的零方差提示，而本文认为这些提示可以提供有意义的策略优化反馈。

Method: RL-ZVP 算法直接奖励正确性并惩罚错误，即使没有对比响应，还可以通过令牌级特征调节反馈以保留信息性、细微的信号。

Result: 在六个数学推理基准上，RL-ZVP 的准确率和通过率分别比 GRPO 提高了 8.61 和 7.77 个百分点，并且始终优于过滤掉零方差提示的其他基线。

Conclusion: RL-ZVP 证明了在 RLVR 中从零方差提示中学习具有未开发潜力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful framework
for improving the reasoning abilities of Large Language Models (LLMs). However,
current methods such as GRPO rely only on problems where the model responses to
the same input differ in correctness, while ignoring those where all responses
receive the same reward - so-called zero-variance prompts. In this work, we
argue that such prompts are not useless but can, in fact, provide meaningful
feedback for policy optimization. To this end, we introduce RL with
Zero-Variance Prompts (RL-ZVP), a novel algorithm that extract learning signals
from zero-variance prompts. RL-ZVP directly rewards correctness and penalizes
errors even without contrasting responses, modulating feedback with token-level
characteristics to preserve informative, nuanced signals. Across six math
reasoning benchmarks, RL-ZVP achieves significant improvements of up to 8.61
points in accuracy and 7.77 points in pass rate over GRPO, while consistently
outperforming other baselines that filter out zero-variance prompts. These
results highlight the untapped potential of learning from zero-variance prompts
in RLVR.

</details>


### [201] [QoNext: Towards Next-generation QoE for Foundation Models](https://arxiv.org/abs/2509.21889)
*Yijin Guo,Ye Shen,Farong Wen,Junying Wang,Zicheng Zhang,Qi Jia,Guangtao Zhai*

Main category: cs.CL

TL;DR: 现有的基础模型评估方法忽略了用户交互体验，而这篇论文提出了QoNext框架，将网络和多媒体领域的体验质量（QoE）原则应用于基础模型评估，通过识别体验因素、进行受控实验、构建数据库和训练预测模型，实现了对用户体验的量化评估和优化指导。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型评估方法仅关注输出正确性，未能捕捉用户在交互过程中的真实体验，无法解释用户满意度的形成机制。

Method: 提出QoNext框架，将体验质量（QoE）原则引入基础模型评估；识别影响用户体验的因素；设计受控实验收集用户评分；构建面向QoE的数据库；训练预测模型以从系统参数估计用户体验。

Result: QoNext能够进行主动的、细粒度的评估，并为优化基础模型在产品化服务中提供可操作的指导。

Conclusion: QoNext框架能够全面评估基础模型的用户体验，并为其实际应用中的优化提供有效支持。

Abstract: Existing evaluations of foundation models, including recent human-centric
approaches, fail to capture what truly matters: user's experience during
interaction. Current methods treat evaluation as a matter of output correctness
alone, overlooking that user satisfaction emerges from the interplay between
response quality and interaction, which limits their ability to account for the
mechanisms underlying user experience. To address this gap, we introduce
QoNext, the first framework that adapts Quality of Experience (QoE) principles
from networking and multimedia to the assessment of foundation models. QoNext
identifies experiential factors that shape user experience and incorporates
them into controlled experiments, where human ratings are collected under
varied configurations. From these studies we construct a QoE-oriented database
and train predictive models that estimate perceived user experience from
measurable system parameters. Our results demonstrate that QoNext not only
enables proactive and fine-grained evaluation but also provides actionable
guidance for productized services of optimizing foundation models in practice.

</details>


### [202] [Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts](https://arxiv.org/abs/2509.21892)
*Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang*

Main category: cs.CL

TL;DR: EMoE训练框架使MoE模型在推理时能够扩展激活的专家数量，而无需额外的训练开销，同时提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 通常情况下，MoE模型在训练和推理时激活的专家数量k是固定的。虽然直觉上认为增加推理时的专家数量k'（k'>k）可以提升性能，但实际上会因为专家之间缺乏协作而导致性能下降。因此，需要一种新的方法来解决这个问题。

Method: 提出了一种名为Elastic Mixture-of-Experts (EMoE)的新型训练框架。该框架通过同时训练专家进行协作以及鼓励路由器进行高质量选择，使得MoE模型能够在推理时扩展激活的专家数量，而不会增加额外的训练成本。

Result: EMoE显著扩大了性能扩展的有效范围，可达训练时k的2-3倍，同时将模型的峰值性能推向了新的高度。

Conclusion: EMoE是一种有效的训练框架，能够解决MoE模型在扩展激活专家数量时遇到的性能下降问题，并提升模型的整体性能。

Abstract: Mixture-of-Experts (MoE) models typically fix the number of activated experts
$k$ at both training and inference. Intuitively, activating more experts at
inference $k'$ (where $k'> k$) means engaging a larger set of model parameters
for the computation and thus is expected to improve performance. However,
contrary to this intuition, we find the scaling range to be so narrow that
performance begins to degrade rapidly after only a slight increase in the
number of experts. Further investigation reveals that this degradation stems
from a lack of learned collaboration among experts. To address this, we
introduce Elastic Mixture-of-Experts (EMoE), a novel training framework that
enables MoE models to scale the number of activated experts at inference
without incurring additional training overhead. By simultaneously training
experts to collaborate in diverse combinations and encouraging the router for
high-quality selections, EMoE ensures robust performance across computational
budgets at inference. We conduct extensive experiments on various MoE settings.
Our results show that EMoE significantly expands the effective
performance-scaling range, extending it to as much as 2-3$\times$ the
training-time $k$, while also pushing the model's peak performance to a higher
level.

</details>


### [203] [A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs](https://arxiv.org/abs/2509.21907)
*Kemal Sami Karaca,Bahaeddin Eravcı*

Main category: cs.CL

TL;DR: 本研究提出了一个用于理解土耳其语引文意图的系统性方法和基础数据集，解决了土耳其语这种黏着语在引文分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 理解引文的定性意图对于全面评估学术研究至关重要，而对于土耳其语这样的黏着语来说，这项任务存在独特的挑战。

Method: 研究首先构建了一个包含土耳其语引文意图的公开数据集，并评估了标准少样本学习（ICL）在大语言模型（LLMs）上的表现，发现其受手动设计的提示的限制。为解决此问题，研究引入了基于DSPy框架的可编程分类流程，自动化提示优化，并采用XGBoost元模型进行堆叠泛化集成，以聚合多个优化模型的输出来提高预测的稳定性和可靠性。

Result: 所提出的集成模型达到了 91.3% 的准确率，创下了最先进的水平。

Conclusion: 该研究为土耳其自然语言处理社区和更广泛的学术界提供了一个基础数据集和一个强大的分类框架，为未来的定性引文研究铺平了道路。

Abstract: Understanding the qualitative intent of citations is essential for a
comprehensive assessment of academic research, a task that poses unique
challenges for agglutinative languages like Turkish. This paper introduces a
systematic methodology and a foundational dataset to address this problem. We
first present a new, publicly available dataset of Turkish citation intents,
created with a purpose-built annotation tool. We then evaluate the performance
of standard In-Context Learning (ICL) with Large Language Models (LLMs),
demonstrating that its effectiveness is limited by inconsistent results caused
by manually designed prompts. To address this core limitation, we introduce a
programmable classification pipeline built on the DSPy framework, which
automates prompt optimization systematically. For final classification, we
employ a stacked generalization ensemble to aggregate outputs from multiple
optimized models, ensuring stable and reliable predictions. This ensemble, with
an XGBoost meta-model, achieves a state-of-the-art accuracy of 91.3\%.
Ultimately, this study provides the Turkish NLP community and the broader
academic circles with a foundational dataset and a robust classification
framework paving the way for future qualitative citation studies.

</details>


### [204] [AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition](https://arxiv.org/abs/2509.21910)
*Yun Wang,Zhaojun Ding,Xuansheng Wu,Siyue Sun,Ninghao Liu,Xiaoming Zhai*

Main category: cs.CL

TL;DR: AutoSCORE是一个多智能体LLM框架，通过提取评分细则中的结构化组件来提高教育评估的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在自动评分方面存在准确性低、提示敏感、可解释性差和评分细则不匹配等问题，阻碍了其在评估实践中的应用。

Method: 提出AutoSCORE框架，包含两个智能体：评分细则组件提取智能体，用于提取学生回答中的相关组件并编码为结构化表示；评分智能体，利用结构化表示分配最终分数。这种设计模仿了人类评分过程，增强了可解释性和鲁棒性。

Result: 在ASAP基准的四个数据集上，使用GPT-4o、LLaMA-3.1-8B和LLaMA-3.1-70B进行评估，AutoSCORE在评分准确性、人类-机器一致性（QWK、相关性）和误差度量（MAE、RMSE）方面优于单一智能体基线，尤其在复杂、多维度的评分细则和小模型上表现突出。

Conclusion: 结构化组件识别与多智能体设计相结合，为自动评分提供了一个可扩展、可靠且可解释的解决方案。

Abstract: Automated scoring plays a crucial role in education by reducing the reliance
on human raters, offering scalable and immediate evaluation of student work.
While large language models (LLMs) have shown strong potential in this task,
their use as end-to-end raters faces challenges such as low accuracy, prompt
sensitivity, limited interpretability, and rubric misalignment. These issues
hinder the implementation of LLM-based automated scoring in assessment
practice. To address the limitations, we propose AutoSCORE, a multi-agent LLM
framework enhancing automated scoring via rubric-aligned Structured COmponent
REcognition. With two agents, AutoSCORE first extracts rubric-relevant
components from student responses and encodes them into a structured
representation (i.e., Scoring Rubric Component Extraction Agent), which is then
used to assign final scores (i.e., Scoring Agent). This design ensures that
model reasoning follows a human-like grading process, enhancing
interpretability and robustness. We evaluate AutoSCORE on four benchmark
datasets from the ASAP benchmark, using both proprietary and open-source LLMs
(GPT-4o, LLaMA-3.1-8B, and LLaMA-3.1-70B). Across diverse tasks and rubrics,
AutoSCORE consistently improves scoring accuracy, human-machine agreement (QWK,
correlations), and error metrics (MAE, RMSE) compared to single-agent
baselines, with particularly strong benefits on complex, multi-dimensional
rubrics, and especially large relative gains on smaller LLMs. These results
demonstrate that structured component recognition combined with multi-agent
design offers a scalable, reliable, and interpretable solution for automated
scoring.

</details>


### [205] [SimulSense: Sense-Driven Interpreting for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2509.21932)
*Haotian Tan,Hiroki Ouchi,Sakriani Sakti*

Main category: cs.CL

TL;DR: SimulSense通过模仿人类译者，在读取输入语音时连续触发写入决策，以实现更好的质量-延迟权衡和实时效率。


<details>
  <summary>Details</summary>
Motivation: 当前SimulST系统将任务视为多轮对话，需要专门的交错训练数据和昂贵的LLM推理，而本研究旨在模仿人类译者的行为，以改进SimulST。

Method: 提出SimulSense框架，该框架通过连续读取输入语音并在感知到新的语义单元时触发写入决策来模仿人类译者。

Result: SimulSense在质量-延迟权衡和实时效率方面优于两个最先进的基线系统，决策速度提高了9.6倍。

Conclusion: SimulSense框架通过模仿人类译者在读取和写入决策方面的行为，为SimulST提供了一种更优的解决方案。

Abstract: How to make human-interpreter-like read/write decisions for simultaneous
speech translation (SimulST) systems? Current state-of-the-art systems
formulate SimulST as a multi-turn dialogue task, requiring specialized
interleaved training data and relying on computationally expensive large
language model (LLM) inference for decision-making. In this paper, we propose
SimulSense, a novel framework for SimulST that mimics human interpreters by
continuously reading input speech and triggering write decisions to produce
translation when a new sense unit is perceived. Experiments against two
state-of-the-art baseline systems demonstrate that our proposed method achieves
a superior quality-latency tradeoff and substantially improved real-time
efficiency, where its decision-making is up to 9.6x faster than the baselines.

</details>


### [206] [Why Chain of Thought Fails in Clinical Text Understanding](https://arxiv.org/abs/2509.21933)
*Jiageng Wu,Kevin Xie,Bowen Gu,Nils Krüger,Kueiyu Joshua Lin,Jie Yang*

Main category: cs.CL

TL;DR: 在临床文本理解任务中，思维链（CoT）提示相比直接提示会降低大型语言模型（LLM）的性能，尤其是在较弱的模型中，这揭示了CoT在临床应用中的可靠性悖论。


<details>
  <summary>Details</summary>
Motivation: 评估思维链（CoT）提示在电子健康记录（EHR）等临床文本理解任务中的有效性，并探索其在准确性和可解释性方面的潜在影响。

Method: 对95个大型语言模型（LLM）在87个真实世界的临床文本任务上进行了评估，涵盖了9种语言和8种任务类型，并进行了细粒度的推理长度、医学概念对齐和错误分析。

Result: 86.3%的模型在CoT设置下表现出性能下降，能力更强的模型相对更稳定，而能力较弱的模型下降幅度更大。LLM-as-a-judge评估和临床专家评估均揭示了CoT在临床环境中失败的系统性模式。

Conclusion: CoT在临床文本任务中可能损害可靠性，尽管它提高了可解释性，这表明需要更透明和值得信赖的临床LLM推理策略。

Abstract: Large language models (LLMs) are increasingly being applied to clinical care,
a domain where both accuracy and transparent reasoning are critical for safe
and trustworthy deployment. Chain-of-thought (CoT) prompting, which elicits
step-by-step reasoning, has demonstrated improvements in performance and
interpretability across a wide range of tasks. However, its effectiveness in
clinical contexts remains largely unexplored, particularly in the context of
electronic health records (EHRs), the primary source of clinical documentation,
which are often lengthy, fragmented, and noisy. In this work, we present the
first large-scale systematic study of CoT for clinical text understanding. We
assess 95 advanced LLMs on 87 real-world clinical text tasks, covering 9
languages and 8 task types. Contrary to prior findings in other domains, we
observe that 86.3\% of models suffer consistent performance degradation in the
CoT setting. More capable models remain relatively robust, while weaker ones
suffer substantial declines. To better characterize these effects, we perform
fine-grained analyses of reasoning length, medical concept alignment, and error
profiles, leveraging both LLM-as-a-judge evaluation and clinical expert
evaluation. Our results uncover systematic patterns in when and why CoT fails
in clinical contexts, which highlight a critical paradox: CoT enhances
interpretability but may undermine reliability in clinical text tasks. This
work provides an empirical basis for clinical reasoning strategies of LLMs,
highlighting the need for transparent and trustworthy approaches.

</details>


### [207] [Debiasing Large Language Models in Thai Political Stance Detection via Counterfactual Calibration](https://arxiv.org/abs/2509.21946)
*Kasidit Sermsri,Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: 本研究提出 ThaiFACTUAL 框架，通过反事实数据增强和基于理由的监督来减轻泰国政治文本中大型语言模型的偏见，提高了公平性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 泰国政治环境复杂，存在语言间接、人物两极分化、情感和立场纠缠等问题，导致大型语言模型（LLMs）出现系统性偏见，如情感泄露和实体偏袒，影响了公平性和可靠性。

Method: 提出 ThaiFACTUAL，一个轻量级、模型无关的校准框架。该框架使用反事实数据增强和基于理由的监督来解耦情感和立场，减少偏见，无需进行微调。

Result: 实验结果表明，ThaiFACTUAL 显著减少了虚假相关性，增强了零样本泛化能力，并提高了多种大型语言模型在泰国政治文本上的公平性。

Conclusion: 本研究强调了针对代表性不足的语言，采用基于文化背景的去偏见技术的重要性。

Abstract: Political stance detection in low-resource and culturally complex settings
poses a critical challenge for large language models (LLMs). In the Thai
political landscape - marked by indirect language, polarized figures, and
entangled sentiment and stance - LLMs often display systematic biases such as
sentiment leakage and favoritism toward entities. These biases undermine
fairness and reliability. We present ThaiFACTUAL, a lightweight, model-agnostic
calibration framework that mitigates political bias without requiring
fine-tuning. ThaiFACTUAL uses counterfactual data augmentation and
rationale-based supervision to disentangle sentiment from stance and reduce
bias. We also release the first high-quality Thai political stance dataset,
annotated with stance, sentiment, rationales, and bias markers across diverse
entities and events. Experimental results show that ThaiFACTUAL significantly
reduces spurious correlations, enhances zero-shot generalization, and improves
fairness across multiple LLMs. This work highlights the importance of
culturally grounded debiasing techniques for underrepresented languages.

</details>


### [208] [MotivGraph-SoIQ: Integrating Motivational Knowledge Graphs and Socratic Dialogue for Enhanced LLM Ideation](https://arxiv.org/abs/2509.21978)
*Xinping Lei,Tong Zhou,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: LLMs在学术构思方面有巨大潜力，但存在概念接地和确认偏差问题。MotivGraph-SoIQ框架通过结合动机知识图谱和苏格拉底对话，为LLM构思提供支持，解决上述问题。该框架利用包含问题、挑战和解决方案节点的MotivGraph进行动机基础支撑，并采用双代理苏格拉底提问方式的Ideator来严格审查和改进想法，提高新颖性、实验严谨性和动机合理性。在ICLR25论文主题数据集上的实验结果表明，MotivGraph-SoIQ在LLM评分、ELO排名和人工评估方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在加速学术构思方面具有巨大潜力，但面临着概念接地和缓解确认偏差以供进一步完善的关键挑战。

Method: 提出了一种名为MotivGraph-SoIQ的新型框架，通过集成动机知识图谱（MotivGraph）和苏格拉底对话来解决LLM构思的局限性。MotivGraph包含问题、挑战和解决方案三种关键节点类型，为LLM构思过程提供动机基础。Ideator是一个利用苏格拉底式提问的双代理系统，促进严格的完善过程，减轻确认偏差，并提高新颖性、实验严谨性和动机合理性方面的想法质量。

Result: 在ICLR25论文主题数据集上，MotivGraph-SoIQ在基于LLM的评分、ELO排名和人工评估指标方面，相比现有最先进的方法展现出明显的优势。

Conclusion: MotivGraph-SoIQ框架通过集成动机知识图谱和苏格拉底对话，有效解决了大型语言模型在学术构思中概念接地不足和确认偏差的问题，并在多个评估维度上取得了优于现有方法的表现。

Abstract: Large Language Models (LLMs) hold substantial potential for accelerating
academic ideation but face critical challenges in grounding ideas and
mitigating confirmation bias for further refinement. We propose integrating
motivational knowledge graphs and socratic dialogue to address these
limitations in enhanced LLM ideation (MotivGraph-SoIQ). This novel framework
provides essential grounding and practical idea improvement steps for LLM
ideation by integrating a Motivational Knowledge Graph (MotivGraph) with a
Q-Driven Socratic Ideator. The MotivGraph structurally stores three key node
types(problem, challenge and solution) to offer motivation grounding for the
LLM ideation process. The Ideator is a dual-agent system utilizing Socratic
questioning, which facilitates a rigorous refinement process that mitigates
confirmation bias and improves idea quality across novelty, experimental rigor,
and motivational rationality dimensions. On the ICLR25 paper topics dataset,
MotivGraph-SoIQ exhibits clear advantages over existing state-of-the-art
approaches across LLM-based scoring, ELO ranking, and human evaluation metrics.

</details>


### [209] [Black-Box Hallucination Detection via Consistency Under the Uncertain Expression](https://arxiv.org/abs/2509.21999)
*Seongho Joo,Kyungmin Min,Jahyun Koo,Kyomin Jung*

Main category: cs.CL

TL;DR: 现有的语言模型（LLMs）如GPT3存在生成不实信息（幻觉）的问题。现有的检测和缓解方法需要外部资源或LLM的内部状态，但LLM的外部API和资源有限。因此，迫切需要一种不依赖外部资源的“黑盒”方法来有效检测幻觉。本文提出了一种基于LLM表达不确定性行为的简单黑盒幻觉检测方法。研究表明，LLM在生成事实性回答时会产生一致的响应，而非事实性回答则不一致。基于此，本文提出了一种高效的黑盒幻觉检测指标。实验证明，该指标比使用LLM内部知识的基线方法更能预测模型响应的事实性。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型（LLMs）存在生成不实信息（幻觉）的问题，且现有方法依赖外部资源或LLM内部状态，而LLM的外部API和资源有限，因此需要一种不依赖外部资源的“黑盒”方法来有效检测幻觉。

Method: 通过研究LLM在表达不确定性时的行为，提出了一种简单的黑盒幻觉检测指标。该方法基于LLM在生成事实性回答时会产生一致的响应，而非事实性回答则不一致的观察。

Result: 实验证明，所提出的黑盒幻觉检测指标比使用LLM内部知识的基线方法更能预测模型响应的事实性。

Conclusion: 提出了一种简单且高效的黑盒幻觉检测方法，该方法通过分析LLM表达不确定性时的行为，能够有效检测模型生成响应的事实性，且优于依赖LLM内部知识的方法。

Abstract: Despite the great advancement of Language modeling in recent days, Large
Language Models (LLMs) such as GPT3 are notorious for generating non-factual
responses, so-called "hallucination" problems. Existing methods for detecting
and alleviating this hallucination problem require external resources or the
internal state of LLMs, such as the output probability of each token. Given the
LLM's restricted external API availability and the limited scope of external
resources, there is an urgent demand to establish the Black-Box approach as the
cornerstone for effective hallucination detection. In this work, we propose a
simple black-box hallucination detection metric after the investigation of the
behavior of LLMs under expression of uncertainty. Our comprehensive analysis
reveals that LLMs generate consistent responses when they present factual
responses while non-consistent responses vice versa. Based on the analysis, we
propose an efficient black-box hallucination detection metric with the
expression of uncertainty. The experiment demonstrates that our metric is more
predictive of the factuality in model responses than baselines that use
internal knowledge of LLMs.

</details>


### [210] [GraphSearch: An Agentic Deep Searching Workflow for Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2509.22009)
*Cehao Yang,Xiaojun Wu,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Jia Li,Hui Xiong,Jian Guo*

Main category: cs.CL

TL;DR: GraphRAG的现有方法在检索和知识利用方面存在局限性，提出了一种名为GraphSearch的新型代理深度搜索工作流，通过双通道检索策略来解决这些问题，并在多个基准测试中提高了答案的准确性和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的GraphRAG方法存在检索不充分和知识利用效率低下的问题，阻碍了从复杂查询中进行有效推理。

Method: 提出了一种名为GraphSearch的新型代理深度搜索工作流，采用模块化框架和双通道检索策略，包括对文本数据进行语义查询和对结构图数据进行关系查询。

Result: 在六个多跳RAG基准测试中，GraphSearch在答案准确性和生成质量方面始终优于传统策略。

Conclusion: GraphSearch通过双通道检索策略有效解决了GraphRAG的局限性，是推进GraphRAG的有效方法。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) enhances factual reasoning in
LLMs by structurally modeling knowledge through graph-based representations.
However, existing GraphRAG approaches face two core limitations: shallow
retrieval that fails to surface all critical evidence, and inefficient
utilization of pre-constructed structural graph data, which hinders effective
reasoning from complex queries. To address these challenges, we propose
\textsc{GraphSearch}, a novel agentic deep searching workflow with dual-channel
retrieval for GraphRAG. \textsc{GraphSearch} organizes the retrieval process
into a modular framework comprising six modules, enabling multi-turn
interactions and iterative reasoning. Furthermore, \textsc{GraphSearch} adopts
a dual-channel retrieval strategy that issues semantic queries over chunk-based
text data and relational queries over structural graph data, enabling
comprehensive utilization of both modalities and their complementary strengths.
Experimental results across six multi-hop RAG benchmarks demonstrate that
\textsc{GraphSearch} consistently improves answer accuracy and generation
quality over the traditional strategy, confirming \textsc{GraphSearch} as a
promising direction for advancing graph retrieval-augmented generation.

</details>


### [211] [From Outliers to Topics in Language Models: Anticipating Trends in News Corpora](https://arxiv.org/abs/2509.22030)
*Evangelia Zve,Benjamin Icard,Alice Breton,Lila Sainero,Gauvain Bourgne,Jean-Gabriel Ganascia*

Main category: cs.CL

TL;DR: Outliers in topic modeling can signal emerging topics in dynamic news, evolving into coherent themes over time.


<details>
  <summary>Details</summary>
Motivation: To examine how outliers, often dismissed as noise, can act as weak signals of emerging topics in dynamic news corpora.

Method: Using vector embeddings from state-of-the-art language models and a cumulative clustering approach to track the evolution of outliers over time in French and English news datasets focused on corporate social responsibility and climate change.

Result: Outliers tend to evolve into coherent topics over time across both models and languages.

Conclusion: Outliers in topic modeling are valuable indicators of emerging topics and their evolution can be tracked over time using advanced language models and clustering techniques.

Abstract: This paper examines how outliers, often dismissed as noise in topic modeling,
can act as weak signals of emerging topics in dynamic news corpora. Using
vector embeddings from state-of-the-art language models and a cumulative
clustering approach, we track their evolution over time in French and English
news datasets focused on corporate social responsibility and climate change.
The results reveal a consistent pattern: outliers tend to evolve into coherent
topics over time across both models and languages.

</details>


### [212] [Taxonomy of Comprehensive Safety for Clinical Agents](https://arxiv.org/abs/2509.22041)
*Jean Seo,Hyunkyung Lee,Gibaeg Kim,Wooseok Han,Jaehyo Yoo,Seungseop Lim,Kihun Shin,Eunho Yang*

Main category: cs.CL

TL;DR: TACOS是一个包含21个类别的细粒度分类器，用于整合临床AI助手的安全过滤和工具选择，以解决现有方法在临床领域中的不足。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法（如护栏和工具调用）在临床AI助手应用中，由于不准确或有害的响应可能导致严重后果，而无法满足临床领域细微需求的问题。

Method: 提出TACOS（TAxonomy of COmprehensive Safety for Clinical Agents）框架，这是一个细粒度的21类分类器，将安全过滤和工具选择整合到单一的用户意图分类步骤中，该分类器能够覆盖广泛的临床和非临床查询，并明确地模拟不同的安全阈值和外部工具依赖性。通过策划一个TACOS注释数据集并进行广泛的实验来验证该框架。

Result: 实验结果证明了一个专门用于临床AI助手环境的新分类器的价值，并揭示了训练数据分布和基础模型的预训练知识方面的有用见解。

Conclusion: TACOS框架通过整合安全过滤和工具选择，为临床AI助手提供了一个更全面的安全解决方案，并且在处理临床和非临床查询方面表现出优越性。

Abstract: Safety is a paramount concern in clinical chatbot applications, where
inaccurate or harmful responses can lead to serious consequences. Existing
methods--such as guardrails and tool calling--often fall short in addressing
the nuanced demands of the clinical domain. In this paper, we introduce TACOS
(TAxonomy of COmprehensive Safety for Clinical Agents), a fine-grained,
21-class taxonomy that integrates safety filtering and tool selection into a
single user intent classification step. TACOS is a taxonomy that can cover a
wide spectrum of clinical and non-clinical queries, explicitly modeling varying
safety thresholds and external tool dependencies. To validate our framework, we
curate a TACOS-annotated dataset and perform extensive experiments. Our results
demonstrate the value of a new taxonomy specialized for clinical agent
settings, and reveal useful insights about train data distribution and
pretrained knowledge of base models.

</details>


### [213] [Fuzzy Reasoning Chain (FRC): An Innovative Reasoning Framework from Fuzziness to Clarity](https://arxiv.org/abs/2509.22054)
*Ping Chen,Xiang Liu,Zhaoxiang Liu,Zezhou Chen,Xingpeng Zhang,Huan Hu,Zipeng Wang,Kai Wang,Shuming Shi,Shiguo Lian*

Main category: cs.CL

TL;DR: FRC框架将LLM语义先验与模糊隶属度结合，以处理歧义和不确定性，并在情感分析任务中验证了其稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: LLM在NLP领域取得了巨大进展，但在处理模糊、多义或不确定的文本方面仍存在挑战。

Method: 提出FRC框架，整合LLM语义先验和连续模糊隶属度，实现概率推理和模糊隶属度推理的显式交互。

Result: FRC在情感分析任务上进行了验证，理论分析和实证结果均表明其推理稳定，并促进了跨模型尺度的知识迁移。

Conclusion: FRC提供了一种处理细微和模糊表达的通用机制，提高了可解释性和鲁棒性。

Abstract: With the rapid advancement of large language models (LLMs), natural language
processing (NLP) has achieved remarkable progress. Nonetheless, significant
challenges remain in handling texts with ambiguity, polysemy, or uncertainty.
We introduce the Fuzzy Reasoning Chain (FRC) framework, which integrates LLM
semantic priors with continuous fuzzy membership degrees, creating an explicit
interaction between probability-based reasoning and fuzzy membership reasoning.
This transition allows ambiguous inputs to be gradually transformed into clear
and interpretable decisions while capturing conflicting or uncertain signals
that traditional probability-based methods cannot. We validate FRC on sentiment
analysis tasks, where both theoretical analysis and empirical results show that
it ensures stable reasoning and facilitates knowledge transfer across different
model scales. These findings indicate that FRC provides a general mechanism for
managing subtle and ambiguous expressions with improved interpretability and
robustness.

</details>


### [214] [RedNote-Vibe: A Dataset for Capturing Temporal Dynamics of AI-Generated Text in Social Media](https://arxiv.org/abs/2509.22055)
*Yudong Li,Yufei Sun,Yuhan Yao,Peiru Yang,Wanyue Li,Jiajun Zou,Yongfeng Huang,Linlin Shen*

Main category: cs.CL

TL;DR: 该研究提出了一个名为RedNote-Vibe的新型纵向数据集，用于分析社交媒体上AI生成文本（AIGT）的长期动态，并引入了一个名为PLAD的可解释框架，利用心理语言学特征来检测AIGT，实验证明了该框架的有效性及其与用户参与度的关系。


<details>
  <summary>Details</summary>
Motivation: 现有的AIGT检测数据集大多是静态的，无法反映社交媒体内容动态随时间演变的特点。

Method: 创建了一个包含用户参与度和时间戳的纵向数据集（RedNote-Vibe），并提出了一种利用心理语言学特征的可解释AIGT检测框架（PLAD）。

Result: PLAD在AIGT检测方面表现优越，并揭示了区分人类和AI生成内容的语言学特征以及这些特征与社交媒体参与度之间的复杂关系。

Conclusion: RedNote-Vibe数据集和PLAD框架为研究社交媒体AIGT的长期动态和用户互动模式提供了新的途径，并有助于深入理解AIGT的语言学特征及其影响。

Abstract: The proliferation of Large Language Models (LLMs) has led to widespread
AI-Generated Text (AIGT) on social media platforms, creating unique challenges
where content dynamics are driven by user engagement and evolve over time.
However, existing datasets mainly depict static AIGT detection. In this work,
we introduce RedNote-Vibe, the first longitudinal (5-years) dataset for social
media AIGT analysis. This dataset is sourced from Xiaohongshu platform,
containing user engagement metrics (e.g., likes, comments) and timestamps
spanning from the pre-LLM period to July 2025, which enables research into the
temporal dynamics and user interaction patterns of AIGT. Furthermore, to detect
AIGT in the context of social media, we propose PsychoLinguistic AIGT Detection
Framework (PLAD), an interpretable approach that leverages psycholinguistic
features. Our experiments show that PLAD achieves superior detection
performance and provides insights into the signatures distinguishing human and
AI-generated content. More importantly, it reveals the complex relationship
between these linguistic features and social media engagement. The dataset is
available at https://github.com/testuser03158/RedNote-Vibe.

</details>


### [215] [The QCET Taxonomy of Standard Quality Criterion Names and Definitions for the Evaluation of NLP Systems](https://arxiv.org/abs/2509.22064)
*Anya Belz,Simon Mille,Craig Thomson*

Main category: cs.CL

TL;DR: NLP评估中的质量标准不一致，导致难以比较不同实验结果。本研究提出了QCET（质量评估标准分类法），一个标准化的质量标准名称和定义体系，以解决这一问题，并可用于评估现有实验、指导新实验设计和满足监管要求。


<details>
  <summary>Details</summary>
Motivation: NLP领域中，不同实验对相同质量标准（如“流畅性”）的定义和评估方式不一致，导致结果难以比较，阻碍了科学进步。

Method: 通过对NLP评估报告进行三次调查，提取并归纳出一套标准化的质量标准名称和定义，并构建了一个层级结构（QCET）。

Result: 提出了QCET，一个包含标准化质量标准名称和层级定义的分类体系，并讨论了其在建立评估可比性、指导新评估设计和评估监管合规性方面的应用。

Conclusion: QCET提供了一个解决NLP评估中质量标准不一致问题的框架，有助于提高研究的可信度和效率。

Abstract: Prior work has shown that two NLP evaluation experiments that report results
for the same quality criterion name (e.g. Fluency) do not necessarily evaluate
the same aspect of quality, and the comparability implied by the name can be
misleading. Not knowing when two evaluations are comparable in this sense means
we currently lack the ability to draw reliable conclusions about system quality
on the basis of multiple, independently conducted evaluations. This in turn
hampers the ability of the field to progress scientifically as a whole, a
pervasive issue in NLP since its beginning (Sparck Jones, 1981). It is hard to
see how the issue of unclear comparability can be fully addressed other than by
the creation of a standard set of quality criterion names and definitions that
the several hundred quality criterion names actually in use in the field can be
mapped to, and grounded in. Taking a strictly descriptive approach, the QCET
Quality Criteria for Evaluation Taxonomy derives a standard set of quality
criterion names and definitions from three surveys of evaluations reported in
NLP, and structures them into a hierarchy where each parent node captures
common aspects of its child nodes. We present QCET and the resources it
consists of, and discuss its three main uses in (i) establishing comparability
of existing evaluations, (ii) guiding the design of new evaluations, and (iii)
assessing regulatory compliance.

</details>


### [216] [Fine-tuning Done Right in Model Editing](https://arxiv.org/abs/2509.22072)
*Wanli Yang,Fei Sun,Rui Tang,Hongyu Zang,Du Su,Qi Cao,Jingang Wang,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: fine-tuning在模型编辑任务中被低估，通过采用广度优先的训练策略和局部调优，其效果可以超越现有SOTA方法，并支持大规模编辑。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为fine-tuning在模型编辑任务中效果不佳，但本文认为这是由于其训练策略不当，而非fine-tuning本身能力的限制。

Method: 将fine-tuning的训练策略从深度优先改为广度优先（epoch-based），并结合mini-batch优化。在此基础上，提出了一种名为LocFT-BF的局部调优策略，以解决原有方法中不佳的调优参数位置问题。

Result: 实验表明，采用广度优先策略的fine-tuning在模型编辑任务上效果显著提升。LocFT-BF在多个LLMs和数据集上，相比现有SOTA方法有较大优势，并且首次实现了在不牺牲模型通用能力的前提下，支持100K规模的编辑和72B参数的模型，是现有实践的10倍。

Conclusion: 本文澄清了关于fine-tuning在模型编辑任务中有效性的长期误解，提出了基于广度优先和局部调优的LocFT-BF方法，将fine-tuning从一个被低估的方法提升为模型编辑领域的领先方法，并为未来的研究奠定了基础。

Abstract: Fine-tuning, a foundational method for adapting large language models, has
long been considered ineffective for model editing. Here, we challenge this
belief, arguing that the reported failure arises not from the inherent
limitation of fine-tuning itself, but from adapting it to the sequential nature
of the editing task, a single-pass depth-first pipeline that optimizes each
sample to convergence before moving on. While intuitive, this depth-first
pipeline coupled with sample-wise updating over-optimizes each edit and induces
interference across edits. Our controlled experiments reveal that simply
restoring fine-tuning to the standard breadth-first (i.e., epoch-based)
pipeline with mini-batch optimization substantially improves its effectiveness
for model editing. Moreover, fine-tuning in editing also suffers from
suboptimal tuning parameter locations inherited from prior methods. Through
systematic analysis of tuning locations, we derive LocFT-BF, a simple and
effective localized editing method built on the restored fine-tuning framework.
Extensive experiments across diverse LLMs and datasets demonstrate that
LocFT-BF outperforms state-of-the-art methods by large margins. Notably, to our
knowledge, it is the first to sustain 100K edits and 72B-parameter models,10 x
beyond prior practice, without sacrificing general capabilities. By clarifying
a long-standing misconception and introducing a principled localized tuning
strategy, we advance fine-tuning from an underestimated baseline to a leading
method for model editing, establishing a solid foundation for future research.

</details>


### [217] [COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning](https://arxiv.org/abs/2509.22075)
*Dmitriy Shopkhoev,Denis Makhov,Magauiya Zhussip,Ammar Ali,Stamatios Lefkimmiatis*

Main category: cs.CL

TL;DR: CoSpaDi是一种创新的无训练模型压缩框架，通过稀疏字典学习替代低秩近似，实现了比现有方法更好的模型精度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩权重近似方法在压缩大型语言模型（LLM）时，虽然计算效率高，但过于僵化的结构约束会导致模型精度明显下降。因此，需要更灵活的压缩策略。

Method: CoSpaDi框架采用结构化稀疏分解，将权重矩阵表示为密集字典和稀疏系数矩阵的乘积。这种方法允许模型使用不同子空间来近似原始权重矩阵的不同列（联合子空间表示），并通过一个小的校准数据集优化分解，使得压缩后的模型激活输出与原始模型尽可能一致，从而最小化函数重构误差。

Result: 与最先进的低秩方法相比，CoSpaDi在压缩比例为20-50%的情况下，在Llama和Qwen模型上均展现出更高的准确率和更低的困惑度。其结构化稀疏性还支持高效的稀疏-密集矩阵乘法，并兼容量化以进一步提升性能。

Conclusion: 结构化稀疏字典学习是比传统低秩方法更优越的LLM压缩技术，为高效部署LLM提供了新的可能性。

Abstract: Post-training compression of large language models (LLMs) largely relies on
low-rank weight approximation, which represents each column of a weight matrix
in a shared low-dimensional subspace. While this is a computationally efficient
strategy, the imposed structural constraint is rigid and can lead to a
noticeable model accuracy drop. In this work, we propose CoSpaDi (Compression
via Sparse Dictionary Learning), a novel training-free compression framework
that replaces low-rank decomposition with a more flexible structured sparse
factorization in which each weight matrix is represented with a dense
dictionary and a column-sparse coefficient matrix. This formulation enables a
union-of-subspaces representation: different columns of the original weight
matrix are approximated in distinct subspaces spanned by adaptively selected
dictionary atoms, offering greater expressiveness than a single invariant
basis. Crucially, CoSpaDi leverages a small calibration dataset to optimize the
factorization such that the output activations of compressed projection layers
closely match those of the original ones, thereby minimizing functional
reconstruction error rather than mere weight approximation. This data-aware
strategy preserves better model fidelity without any fine-tuning under
reasonable compression ratios. Moreover, the resulting structured sparsity
allows efficient sparse-dense matrix multiplication and is compatible with
post-training quantization for further memory and latency gains. We evaluate
CoSpaDi across multiple Llama and Qwen models under per-layer and per-group
settings at 20-50\% compression ratios, demonstrating consistent superiority
over state-of-the-art data-aware low-rank methods both in accuracy and
perplexity. Our results establish structured sparse dictionary learning as a
powerful alternative to conventional low-rank approaches for efficient LLM
deployment.

</details>


### [218] [Multilingual Dialogue Generation and Localization with Dialogue Act Scripting](https://arxiv.org/abs/2509.22086)
*Justin Vasselli,Eunike Andriani Kardinata,Yusuke Sakai,Taro Watanabe*

Main category: cs.CL

TL;DR: 该研究提出了DAS框架，用于生成多语言对话，以解决非英语对话数据集稀缺和现有方法存在翻译痕迹的问题。


<details>
  <summary>Details</summary>
Motivation: 非英语对话数据集稀缺，现有模型常使用英语对话的翻译版本进行训练或评估，这可能引入不自然和不符合文化习惯的瑕疵。

Method: 提出了一种名为Dialogue Act Script (DAS) 的结构化框架，用于从抽象意图表示中编码、本地化和生成多语言对话。DAS不直接翻译对话语句，而是生成符合目标语言文化和语境的新对话。

Result: 通过对意大利语、德语和中文进行的UIActions 评估表明，DAS生成的对话在文化相关性、连贯性和情境适用性方面，优于机器翻译和人工翻译的对话。

Conclusion: DAS框架通过使用结构化的对话行为表示，支持跨语言的灵活本地化，从而生成更自然流畅、更符合文化习惯的多语言对话。

Abstract: Non-English dialogue datasets are scarce, and models are often trained or
evaluated on translations of English-language dialogues, an approach which can
introduce artifacts that reduce their naturalness and cultural appropriateness.
This work proposes Dialogue Act Script (DAS), a structured framework for
encoding, localizing, and generating multilingual dialogues from abstract
intent representations. Rather than translating dialogue utterances directly,
DAS enables the generation of new dialogues in the target language that are
culturally and contextually appropriate. By using structured dialogue act
representations, DAS supports flexible localization across languages,
mitigating translationese and enabling more fluent, naturalistic conversations.
Human evaluations across Italian, German, and Chinese show that DAS-generated
dialogues consistently outperform those produced by both machine and human
translators on measures of cultural relevance, coherence, and situational
appropriateness.

</details>


### [219] [S2J: Bridging the Gap Between Solving and Judging Ability in Generative Reward Models](https://arxiv.org/abs/2509.22099)
*Shaoning Sun,Jiachen Yu,Zongqi Wang,Xuewei Yang,Tianle Gu,Yujiu Yang*

Main category: cs.CL

TL;DR: GRMs在解决问题和进行判断时存在差距，S2J方法通过同时利用解决和判断能力来缩小这个差距，并提高了判断性能。


<details>
  <summary>Details</summary>
Motivation: LLMs的快速发展使得GRMs在奖励建模和评估中得到广泛应用。以往的研究主要集中在优化专门的GRMs，但存在解决-判断差距，即GRMs在能解决某些查询时却难以做出正确判断。

Method: 提出Solve-to-Judge (S2J)方法，该方法在模型优化期间同时利用单个GRM输出的解决和判断能力进行监督，明确地将GRM的解决和评估能力联系起来，从而缩小差距。

Result: S2J方法有效地将解决-判断差距减小了16.2%，并将判断性能提高了5.8%。

Conclusion: S2J方法在利用更小的训练数据集的情况下，实现了基于相同基础模型的GRMs的SOTA性能，并且无需依赖更强大的外部模型进行蒸馏即可实现自我进化。

Abstract: With the rapid development of large language models (LLMs), generative reward
models (GRMs) have been widely adopted for reward modeling and evaluation.
Previous studies have primarily focused on training specialized GRMs by
optimizing them on preference datasets with the judgment correctness as
supervision. While it's widely accepted that GRMs with stronger problem-solving
capabilities typically exhibit superior judgment abilities, we first identify a
significant solve-to-judge gap when examining individual queries. Specifically,
the solve-to-judge gap refers to the phenomenon where GRMs struggle to make
correct judgments on some queries (14%-37%), despite being fully capable of
solving them. In this paper, we propose the Solve-to-Judge (S2J) approach to
address this problem. Specifically, S2J simultaneously leverages both the
solving and judging capabilities on a single GRM's output for supervision,
explicitly linking the GRM's problem-solving and evaluation abilities during
model optimization, thereby narrowing the gap. Our comprehensive experiments
demonstrate that S2J effectively reduces the solve-to-judge gap by 16.2%,
thereby enhancing the model's judgment performance by 5.8%. Notably, S2J
achieves state-of-the-art (SOTA) performance among GRMs built on the same base
model while utilizing a significantly smaller training dataset. Moreover, S2J
accomplishes this through self-evolution without relying on more powerful
external models for distillation.

</details>


### [220] [Think Right, Not More: Test-Time Scaling for Numerical Claim Verification](https://arxiv.org/abs/2509.22101)
*Primakov Chungkham,V Venktesh,Vinay Setty,Avishek Anand*

Main category: cs.CL

TL;DR: 通过扩展测试时计算（TTC）和训练一个验证器模型（VERIFIERFC），提高LLM在事实核查复杂数值声明方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理需要组合和数值推理的现实世界数值声明时存在不足，容易出现推理漂移和对数值细微差别的理解不准确。

Method: 系统地探索扩展LLM的测试时计算（TTC），以引发多个推理路径；训练一个验证器模型（VERIFIERFC）来选择最有可能导致正确判断的推理路径；引入一种自适应机制以提高TTC的计算效率。

Result: TTC能缓解推理漂移问题，显著提高数值声明事实核查的性能；自适应TTC机制比标准TTC提高了1.8倍的效率，并使性能比单次推理方法提高了18.8%。

Conclusion: 扩展测试时计算（TTC）并结合验证器模型（VERIFIERFC）是提高LLM在复杂数值声明事实核查方面性能的有效方法，并且可以通过自适应机制进一步提高效率。

Abstract: Fact-checking real-world claims, particularly numerical claims, is inherently
complex that require multistep reasoning and numerical reasoning for verifying
diverse aspects of the claim. Although large language models (LLMs) including
reasoning models have made tremendous advances, they still fall short on
fact-checking real-world claims that require a combination of compositional and
numerical reasoning. They are unable to understand nuance of numerical aspects,
and are also susceptible to the reasoning drift issue, where the model is
unable to contextualize diverse information resulting in misinterpretation and
backtracking of reasoning process. In this work, we systematically explore
scaling test-time compute (TTS) for LLMs on the task of fact-checking complex
numerical claims, which entails eliciting multiple reasoning paths from an LLM.
We train a verifier model (VERIFIERFC) to navigate this space of possible
reasoning paths and select one that could lead to the correct verdict. We
observe that TTS helps mitigate the reasoning drift issue, leading to
significant performance gains for fact-checking numerical claims. To improve
compute efficiency in TTS, we introduce an adaptive mechanism that performs TTS
selectively based on the perceived complexity of the claim. This approach
achieves 1.8x higher efficiency than standard TTS, while delivering a notable
18.8% performance improvement over single-shot claim verification methods. Our
code and data can be found at https://github.com/VenkteshV/VerifierFC

</details>


### [221] [Universal Legal Article Prediction via Tight Collaboration between Supervised Classification Model and LLM](https://arxiv.org/abs/2509.22119)
*Xiao Chi,Wenlin Zhong,Yiquan Wu,Wei Wang,Kun Kuang,Fei Wu,Minghui Xiong*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Legal Article Prediction (LAP) is a critical task in legal text
classification, leveraging natural language processing (NLP) techniques to
automatically predict relevant legal articles based on the fact descriptions of
cases. As a foundational step in legal decision-making, LAP plays a pivotal
role in determining subsequent judgments, such as charges and penalties.
Despite its importance, existing methods face significant challenges in
addressing the complexities of LAP. Supervised classification models (SCMs),
such as CNN and BERT, struggle to fully capture intricate fact patterns due to
their inherent limitations. Conversely, large language models (LLMs), while
excelling in generative tasks, perform suboptimally in predictive scenarios due
to the abstract and ID-based nature of legal articles. Furthermore, the
diversity of legal systems across jurisdictions exacerbates the issue, as most
approaches are tailored to specific countries and lack broader applicability.
To address these limitations, we propose Uni-LAP, a universal framework for
legal article prediction that integrates the strengths of SCMs and LLMs through
tight collaboration. Specifically, in Uni-LAP, the SCM is enhanced with a novel
Top-K loss function to generate accurate candidate articles, while the LLM
employs syllogism-inspired reasoning to refine the final predictions. We
evaluated Uni-LAP on datasets from multiple jurisdictions, and empirical
results demonstrate that our approach consistently outperforms existing
baselines, showcasing its effectiveness and generalizability.

</details>


### [222] [Multilingual Vision-Language Models, A Survey](https://arxiv.org/abs/2509.22123)
*Andrei-Alexandru Manea,Jindřich Libovický*

Main category: cs.CL

TL;DR: 本综述考察了跨语言的视觉-语言模型，并分析了31个模型和21个基准。


<details>
  <summary>Details</summary>
Motivation: 本综述旨在考察和分析跨语言的视觉-语言模型，特别关注它们在处理跨语言文本和图像时的表现。

Method: 本研究回顾了31个模型和21个基准，涵盖了仅编码器和生成式两种架构。研究方法包括分析模型在语言中立性（跨语言表示的一致性）和文化意识（对文化背景的适应性）之间的关键权衡。

Result: 研究发现，当前的训练方法倾向于通过对比学习来实现语言中立性，而文化意识则依赖于多样化的数据。三分之二的评估基准使用基于翻译的方法，优先考虑语义一致性，但近期研究也纳入了文化内容。模型在跨语言能力方面存在差异，训练目标和评估目标之间存在差距。

Conclusion: 现有的跨语言视觉-语言模型在实现语言中立性和文化意识之间存在张力，并且在训练和评估方法上存在不匹配的问题，这表明未来研究需要在这些方面进行改进。

Abstract: This survey examines multilingual vision-language models that process text
and images across languages. We review 31 models and 21 benchmarks, spanning
encoder-only and generative architectures, and identify a key tension between
language neutrality (consistent cross-lingual representations) and cultural
awareness (adaptation to cultural contexts). Current training methods favor
neutrality through contrastive learning, while cultural awareness depends on
diverse data. Two-thirds of evaluation benchmarks use translation-based
approaches prioritizing semantic consistency, though recent work incorporates
culturally grounded content. We find discrepancies in cross-lingual
capabilities and gaps between training objectives and evaluation goals.

</details>


### [223] [FoodSEM: Large Language Model Specialized in Food Named-Entity Linking](https://arxiv.org/abs/2509.22125)
*Ana Gjorgjevikj,Matej Martinc,Gjorgjina Cenikj,Sašo Džeroski,Barbara Koroušić Seljak,Tome Eftimov*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper introduces FoodSEM, a state-of-the-art fine-tuned open-source
large language model (LLM) for named-entity linking (NEL) to food-related
ontologies. To the best of our knowledge, food NEL is a task that cannot be
accurately solved by state-of-the-art general-purpose (large) language models
or custom domain-specific models/systems. Through an instruction-response (IR)
scenario, FoodSEM links food-related entities mentioned in a text to several
ontologies, including FoodOn, SNOMED-CT, and the Hansard taxonomy. The FoodSEM
model achieves state-of-the-art performance compared to related models/systems,
with F1 scores even reaching 98% on some ontologies and datasets. The presented
comparative analyses against zero-shot, one-shot, and few-shot LLM prompting
baselines further highlight FoodSEM's superior performance over its
non-fine-tuned version. By making FoodSEM and its related resources publicly
available, the main contributions of this article include (1) publishing a
food-annotated corpora into an IR format suitable for LLM
fine-tuning/evaluation, (2) publishing a robust model to advance the semantic
understanding of text in the food domain, and (3) providing a strong baseline
on food NEL for future benchmarking.

</details>


### [224] [R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2509.22131)
*Hongyu Shan,Mingyang Song,Chang Dai,Di Liang,Han Chen*

Main category: cs.CL

TL;DR: R-Capsule通过结合隐式推理的效率和显式CoT的透明度来改进LLMs的推理过程，以更少的计算资源达到相同的准确率。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought (CoT)提示虽然能增强LLMs的推理能力，但其冗长性会导致延迟和内存开销增加，并可能在长链中传播错误。因此，需要一种更高效的推理方法。

Method: 提出Reasoning Capsule (R-Capsule)框架，将高层计划压缩为一组学习到的隐式标记（Reasoning Capsule），同时保持执行步骤轻量化或显式化。该框架受信息瓶颈（IB）原理启发，通过低容量瓶颈实现最小化，并通过主任务损失和辅助计划重建损失实现充分性，以平衡效率、准确性和可解释性。

Result: R-Capsule框架在保持或提高准确率的同时，显著减少了推理过程中的可见标记数量，提高了效率和可解释性。

Conclusion: R-Capsule框架成功地在效率、准确性和可解释性之间取得了平衡，为解决CoT提示的局限性提供了一种有效的解决方案。

Abstract: Chain-of-Thought (CoT) prompting helps Large Language Models (LLMs) tackle
complex reasoning by eliciting explicit step-by-step rationales. However, CoT's
verbosity increases latency and memory usage and may propagate early errors
across long chains. We propose the Reasoning Capsule (R-Capsule), a framework
that aims to combine the efficiency of latent reasoning with the transparency
of explicit CoT. The core idea is to compress the high-level plan into a small
set of learned latent tokens (a Reasoning Capsule) while keeping execution
steps lightweight or explicit. This hybrid approach is inspired by the
Information Bottleneck (IB) principle, where we encourage the capsule to be
approximately minimal yet sufficient for the task. Minimality is encouraged via
a low-capacity bottleneck, which helps improve efficiency. Sufficiency is
encouraged via a dual objective: a primary task loss for answer accuracy and an
auxiliary plan-reconstruction loss that encourages the capsule to faithfully
represent the original textual plan. The reconstruction objective helps ground
the latent space, thereby improving interpretability and reducing the use of
uninformative shortcuts. Our framework strikes a balance between efficiency,
accuracy, and interpretability, thereby reducing the visible token footprint of
reasoning while maintaining or improving accuracy on complex benchmarks. Our
codes are available at:
https://anonymous.4open.science/r/Reasoning-Capsule-7BE0

</details>


### [225] [Bridging Draft Policy Misalignment: Group Tree Optimization for Speculative Decoding](https://arxiv.org/abs/2509.22134)
*Shijing Hu,Jingyang Li,Zhihui Lu,Pan Zhou*

Main category: cs.CL

TL;DR: 通过引入“组树优化”（GTO）来解决投机解码中的训练与解码策略不一致问题，GTO通过“草稿树奖励”和“基于组的草稿策略训练”来优化草稿模型，在多项基准测试和模型上均显著提高了接受长度和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的投机解码训练目标只优化单一贪心草稿路径，而解码时采用树策略，这导致训练与解码策略不一致，限制了加速效果。

Method: 提出“组树优化”（GTO），包含两部分：1. 草稿树奖励：一个无采样目标，等于草稿树在目标模型下的预期接受长度。2. 基于组的草稿策略训练：一种稳定的优化方案，通过对比当前草稿模型和冻结的参考草稿模型的树，形成去偏的组标准化优势，并沿最长接受序列应用PPO风格的替代损失进行鲁棒更新。

Result: GTO将接受长度提高了7.4%，并比现有的EAGLE-3方法额外提高了7.7%的推理速度。实验在对话（MT-Bench）、代码（HumanEval）和数学（GSM8K）等任务上，以及LLaMA-3.1-8B、LLaMA-3.3-70B、Vicuna-1.3-13B、DeepSeek-R1-Distill-LLaMA-8B等多种LLM上进行了验证。

Conclusion: GTO通过解决草稿策略不一致问题，为高效LLM推理提供了一个实用且通用的解决方案。

Abstract: Speculative decoding accelerates large language model (LLM) inference by
letting a lightweight draft model propose multiple tokens that the target model
verifies in parallel. Yet existing training objectives optimize only a single
greedy draft path, while decoding follows a tree policy that re-ranks and
verifies multiple branches. This draft policy misalignment limits achievable
speedups. We introduce Group Tree Optimization (GTO), which aligns training
with the decoding-time tree policy through two components: (i) Draft Tree
Reward, a sampling-free objective equal to the expected acceptance length of
the draft tree under the target model, directly measuring decoding performance;
(ii) Group-based Draft Policy Training, a stable optimization scheme that
contrasts trees from the current and a frozen reference draft model, forming
debiased group-standardized advantages and applying a PPO-style surrogate along
the longest accepted sequence for robust updates. We further prove that
increasing our Draft Tree Reward provably improves acceptance length and
speedup. Across dialogue (MT-Bench), code (HumanEval), and math (GSM8K), and
multiple LLMs (e.g., LLaMA-3.1-8B, LLaMA-3.3-70B, Vicuna-1.3-13B,
DeepSeek-R1-Distill-LLaMA-8B), GTO increases acceptance length by 7.4% and
yields an additional 7.7% speedup over prior state-of-the-art EAGLE-3. By
bridging draft policy misalignment, GTO offers a practical, general solution
for efficient LLM inference.

</details>


### [226] [NFDI4DS Shared Tasks for Scholarly Document Processing](https://arxiv.org/abs/2509.22141)
*Raia Abu Ahmad,Rana Abdulla,Tilahun Abedissa Taffa,Soeren Auer,Hamed Babaei Giglou,Ekaterina Borisova,Zongxiong Chen,Stefan Dietze,Jennifer DSouza,Mayra Elwes,Genet-Asefa Gesese,Shufan Jiang,Ekaterina Kutafina,Philipp Mayr,Georg Rehm,Sameer Sadruddin,Sonja Schimmler,Daniel Schneider,Kanishka Silva,Sharmila Upadhyaya,Ricardo Usbeck*

Main category: cs.CL

TL;DR: 本文概述了在德国国家研究数据基础设施（NFDI4DS）下开展的十二项旨在促进学术文档处理领域研究的共享任务。


<details>
  <summary>Details</summary>
Motivation: 共享任务通过社区化的标准化评估来推动研究进步，并促进 FAIR（可查找、可访问、可互操作、可重用）以及透明和可复现的研究实践。

Method: 本文介绍了由 NFDI4DS 联盟发起并主办的十二项共享任务，这些任务涵盖了学术文档处理的多种挑战。

Result: 这些共享任务在顶级会议上举办，促进了方法学创新，并为更广泛的研究社区贡献了开放获取的数据集、模型和工具，并已整合到联盟的研究数据基础设施中。

Conclusion: NFDI4DS 联盟通过举办共享任务，不仅推动了学术文档处理领域的研究，还为社区提供了宝贵的开放资源，促进了研究的标准化、透明度和可复现性。

Abstract: Shared tasks are powerful tools for advancing research through
community-based standardised evaluation. As such, they play a key role in
promoting findable, accessible, interoperable, and reusable (FAIR), as well as
transparent and reproducible research practices. This paper presents an updated
overview of twelve shared tasks developed and hosted under the German National
Research Data Infrastructure for Data Science and Artificial Intelligence
(NFDI4DS) consortium, covering a diverse set of challenges in scholarly
document processing. Hosted at leading venues, the tasks foster methodological
innovations and contribute open-access datasets, models, and tools for the
broader research community, which are integrated into the consortium's research
data infrastructure.

</details>


### [227] [From Long to Lean: Performance-aware and Adaptive Chain-of-Thought Compression via Multi-round Refinement](https://arxiv.org/abs/2509.22144)
*Jianzhi Yan,Le Liu,Youcheng Pan,Shiwei Chen,Zike Yuan,Yang Xiang,Buzhou Tang*

Main category: cs.CL

TL;DR: MACC 通过利用“token elasticity”现象，在不牺牲准确性的情况下，显著压缩了 Chain-of-Thought（CoT）推理的长度和延迟，并且可以通过训练集的特征来预测其性能。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought（CoT）推理虽然能提升复杂任务的性能，但其冗长的推理过程会导致显著的延迟。现有方法在压缩 CoT 时，可能会牺牲模型的准确性。

Method: 提出了一种名为 MACC（Multiround Adaptive Chain-of-Thought Compression）的框架，该框架利用“token elasticity”现象，通过多轮迭代的方式逐步压缩 CoT。MACC 能够自适应地确定每个输入的最优压缩深度，以在压缩率和准确性之间取得平衡。

Result: MACC 的方法平均准确性比现有最先进的方法提高了 5.6%，同时将 CoT 的长度平均减少了 47 个 tokens，并显著降低了延迟。此外，研究表明，可以通过训练集上的困惑度（perplexity）和压缩率等可解释特征来可靠地预测测试时的性能（准确性和 token 长度）。

Conclusion: MACC 证明了 CoT 压缩不仅有效，而且具有可预测性。该方法在不同模型上进行了评估，能够有效地进行模型选择和预测，而无需反复进行微调，有助于实现高效的 CoT 推理。

Abstract: Chain-of-Thought (CoT) reasoning improves performance on complex tasks but
introduces significant inference latency due to verbosity. We propose
Multiround Adaptive Chain-of-Thought Compression (MACC), a framework that
leverages the token elasticity phenomenon--where overly small token budgets can
paradoxically increase output length--to progressively compress CoTs via
multiround refinement. This adaptive strategy allows MACC to determine the
optimal compression depth for each input. Our method achieves an average
accuracy improvement of 5.6 percent over state-of-the-art baselines, while also
reducing CoT length by an average of 47 tokens and significantly lowering
latency. Furthermore, we show that test-time performance--accuracy and token
length--can be reliably predicted using interpretable features like perplexity
and compression rate on the training set. Evaluated across different models,
our method enables efficient model selection and forecasting without repeated
fine-tuning, demonstrating that CoT compression is both effective and
predictable. Our code will be released in https://github.com/Leon221220/MACC.

</details>


### [228] [Mixture of Detectors: A Compact View of Machine-Generated Text Detection](https://arxiv.org/abs/2509.22147)
*Sai Teja Lekkala,Yadagiri Annepaka,Arun Kumar Challa,Samatha Reddy Machireddy,Partha Pakray,Chukhu Chunka*

Main category: cs.CL

TL;DR: Large Language Models (LLMs) are approaching human creativity levels, raising concerns about authenticity and the preservation of human innovation. This paper investigates machine-generated text detection (MGTD) across various scenarios, including document-level classification, generator attribution, sentence-level segmentation for human-AI collaboration, and adversarial attacks. It introduces BMAS English, a new dataset for these tasks, aiming to advance MGTD research.


<details>
  <summary>Details</summary>
Motivation: To address the growing concerns about the authenticity of human work and the preservation of human creativity and innovative abilities in the face of advancing Large Language Models (LLMs).

Method: The paper investigates machine-generated text detection (MGTD) across several scenarios: document-level binary and multiclass classification (including generator attribution), sentence-level segmentation to differentiate human-AI collaborative text, and adversarial attacks to reduce detectability. A new dataset, BMAS English, is introduced for these tasks.

Result: The paper introduces BMAS English, a new English language dataset for binary and multiclass classification of human and machine text, generator attribution, adversarial attack mitigation, and sentence-level segmentation to distinguish between human and machine-generated text.

Conclusion: The paper aims to address previous work in Machine-Generated Text Detection (MGTD) in a more comprehensive and meaningful way by introducing a new dataset and investigating multiple facets of MGTD.

Abstract: Large Language Models (LLMs) are gearing up to surpass human creativity. The
veracity of the statement needs careful consideration. In recent developments,
critical questions arise regarding the authenticity of human work and the
preservation of their creativity and innovative abilities. This paper
investigates such issues. This paper addresses machine-generated text detection
across several scenarios, including document-level binary and multiclass
classification or generator attribution, sentence-level segmentation to
differentiate between human-AI collaborative text, and adversarial attacks
aimed at reducing the detectability of machine-generated text. We introduce a
new work called BMAS English: an English language dataset for binary
classification of human and machine text, for multiclass classification, which
not only identifies machine-generated text but can also try to determine its
generator, and Adversarial attack addressing where it is a common act for the
mitigation of detection, and Sentence-level segmentation, for predicting the
boundaries between human and machine-generated text. We believe that this paper
will address previous work in Machine-Generated Text Detection (MGTD) in a more
meaningful way.

</details>


### [229] [Context Parametrization with Compositional Adapters](https://arxiv.org/abs/2509.22158)
*Josip Jukić,Martin Tutek,Jan Šnajder*

Main category: cs.CL

TL;DR: CompAs是一个元学习框架，可以将上下文转换为具有组合结构的适配器参数，解决了ICL效率低下和SFT训练开销大的问题。


<details>
  <summary>Details</summary>
Motivation: ICL在处理多示例时效率低下，SFT有训练开销且牺牲灵活性。需要一种能整合多块信息并生成适配器参数的方法。

Method: 提出CompAs元学习框架，将上下文（指令、示例或检索到的文本）转换为具有组合结构的适配器参数。生成的适配器可以通过代数运算合并，无需重新处理长提示即可无缝组合。

Result: 在多种选择题和抽取式问答任务上，CompAs的性能优于ICL和先前的生成器方法，尤其是在扩展到更多输入时。

Conclusion: CompAs通过可组合的适配器生成，为扩展LLM部署提供了一种实用且高效的替代方案。该方法具有更低的推理成本、对长上下文不稳定的鲁棒性，并解决了输入超出模型上下文窗口的问题。此外，CompAs能以可逆的方式编码信息，可通过解码器恢复输入上下文，有助于提高安全性和保密性。

Abstract: Large language models (LLMs) often seamlessly adapt to new tasks through
in-context learning (ICL) or supervised fine-tuning (SFT). However, both of
these approaches face key limitations: ICL is inefficient when handling many
demonstrations, and SFT incurs training overhead while sacrificing flexibility.
Mapping instructions or demonstrations from context directly into adapter
parameters offers an appealing alternative. While prior work explored
generating adapters based on a single input context, it has overlooked the need
to integrate multiple chunks of information. To address this gap, we introduce
CompAs, a meta-learning framework that translates context into adapter
parameters with a compositional structure. Adapters generated this way can be
merged algebraically, enabling instructions, demonstrations, or retrieved
passages to be seamlessly combined without reprocessing long prompts.
Critically, this approach yields three benefits: lower inference cost,
robustness to long-context instability, and establishes a principled solution
when input exceeds the model's context window. Furthermore, CompAs encodes
information into adapter parameters in a reversible manner, enabling recovery
of input context through a decoder, facilitating safety and security. Empirical
results on diverse multiple-choice and extractive question answering tasks show
that CompAs outperforms ICL and prior generator-based methods, especially when
scaling to more inputs. Our work establishes composable adapter generation as a
practical and efficient alternative for scaling LLM deployment.

</details>


### [230] [When Does Reasoning Matter? A Controlled Study of Reasoning's Contribution to Model Performance](https://arxiv.org/abs/2509.22193)
*Nicolas Boizard,Hippolyte Gisserot-Boukhlef,Kevin El-Haddad,Céline Hudelot,Pierre Colombo*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) with reasoning capabilities have achieved
state-of-the-art performance on a wide range of tasks. Despite its empirical
success, the tasks and model scales at which reasoning becomes effective, as
well as its training and inference costs, remain underexplored. In this work,
we rely on a synthetic data distillation framework to conduct a large-scale
supervised study. We compare Instruction Fine-Tuning (IFT) and reasoning models
of varying sizes, on a wide range of math-centric and general-purpose tasks,
evaluating both multiple-choice and open-ended formats. Our analysis reveals
that reasoning consistently improves model performance, often matching or
surpassing significantly larger IFT systems. Notably, while IFT remains
Pareto-optimal in training and inference costs, reasoning models become
increasingly valuable as model size scales, overcoming IFT performance limits
on reasoning-intensive and open-ended tasks.

</details>


### [231] [The Outputs of Large Language Models are Meaningless](https://arxiv.org/abs/2509.22206)
*Anandi Hattiangadi,Anders J. Schoubye*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we offer a simple argument for the conclusion that the outputs
of large language models (LLMs) are meaningless. Our argument is based on two
key premises: (a) that certain kinds of intentions are needed in order for
LLMs' outputs to have literal meanings, and (b) that LLMs cannot plausibly have
the right kinds of intentions. We defend this argument from various types of
responses, for example, the semantic externalist argument that deference can be
assumed to take the place of intentions and the semantic internalist argument
that meanings can be defined purely in terms of intrinsic relations between
concepts, such as conceptual roles. We conclude the paper by discussing why,
even if our argument is sound, the outputs of LLMs nevertheless seem meaningful
and can be used to acquire true beliefs and even knowledge.

</details>


### [232] [Question-Driven Analysis and Synthesis: Building Interpretable Thematic Trees with LLMs for Text Clustering and Controllable Generation](https://arxiv.org/abs/2509.22211)
*Tiago Fernandes Tavares*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Unsupervised analysis of text corpora is challenging, especially in
data-scarce domains where traditional topic models struggle. While these models
offer a solution, they typically describe clusters with lists of keywords that
require significant manual effort to interpret and often lack semantic
coherence. To address this critical interpretability gap, we introduce
Recursive Thematic Partitioning (RTP), a novel framework that leverages Large
Language Models (LLMs) to interactively build a binary tree. Each node in the
tree is a natural language question that semantically partitions the data,
resulting in a fully interpretable taxonomy where the logic of each cluster is
explicit. Our experiments demonstrate that RTP's question-driven hierarchy is
more interpretable than the keyword-based topics from a strong baseline like
BERTopic. Furthermore, we establish the quantitative utility of these clusters
by showing they serve as powerful features in downstream classification tasks,
particularly when the data's underlying themes correlate with the task labels.
RTP introduces a new paradigm for data exploration, shifting the focus from
statistical pattern discovery to knowledge-driven thematic analysis.
Furthermore, we demonstrate that the thematic paths from the RTP tree can serve
as structured, controllable prompts for generative models. This transforms our
analytical framework into a powerful tool for synthesis, enabling the
consistent imitation of specific characteristics discovered in the source
corpus.

</details>


### [233] [StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs](https://arxiv.org/abs/2509.22220)
*Yuhan Song,Linhao Zhang,Chuhan Wu,Aiwei Liu,Wei Jia,Houfeng Wang,Xiao Zhou*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Prevalent semantic speech tokenizers, designed to capture linguistic content,
are surprisingly fragile. We find they are not robust to meaning-irrelevant
acoustic perturbations; even at high Signal-to-Noise Ratios (SNRs) where speech
is perfectly intelligible, their output token sequences can change drastically,
increasing the learning burden for downstream LLMs. This instability stems from
two flaws: a brittle single-path quantization architecture and a distant
training signal indifferent to intermediate token stability. To address this,
we introduce StableToken, a tokenizer that achieves stability through a
consensus-driven mechanism. Its multi-branch architecture processes audio in
parallel, and these representations are merged via a powerful bit-wise voting
mechanism to form a single, stable token sequence. StableToken sets a new
state-of-the-art in token stability, drastically reducing Unit Edit Distance
(UED) under diverse noise conditions. This foundational stability translates
directly to downstream benefits, significantly improving the robustness of
SpeechLLMs on a variety of tasks.

</details>


### [234] [Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data](https://arxiv.org/abs/2509.22224)
*Zishan Ahmad,Saisubramaniam Gopalakrishnan*

Main category: cs.CL

TL;DR: LLMs can be improved by combining multiple reasoning styles (deductive, inductive, abductive) for better performance on complex problems. This approach, called Composite Reasoning (CR), outperforms existing methods like CoT and SR, especially in scientific and medical question-answering tasks, by adaptively using domain-specific reasoning styles.


<details>
  <summary>Details</summary>
Motivation: Existing LLMs have limitations due to their reliance on singular reasoning paradigms, which hinders their performance on complex problems requiring diverse cognitive strategies.

Method: Introduced Composite Reasoning (CR), a novel approach that enables LLMs to dynamically explore and combine multiple reasoning styles (deductive, inductive, abductive). CR adaptively emphasizes domain-appropriate reasoning styles, prioritizing abductive and deductive for medical QA, and causal, deductive, and inductive for scientific reasoning.

Result: CR outperforms existing baselines like Chain-of-Thought (CoT) and DeepSeek-R1 style reasoning (SR) in scientific and medical question-answering benchmarks. It also demonstrates superior sample efficiency and adequate token usage.

Conclusion: Cultivating internal reasoning style diversity allows LLMs to develop more robust, adaptive, and efficient problem-solving abilities.

Abstract: Large Language Models (LLMs), despite their remarkable capabilities, rely on
singular, pre-dominant reasoning paradigms, hindering their performance on
intricate problems that demand diverse cognitive strategies. To address this,
we introduce Composite Reasoning (CR), a novel reasoning approach empowering
LLMs to dynamically explore and combine multiple reasoning styles like
deductive, inductive, and abductive for more nuanced problem-solving. Evaluated
on scientific and medical question-answering benchmarks, our approach
outperforms existing baselines like Chain-of-Thought (CoT) and also surpasses
the accuracy of DeepSeek-R1 style reasoning (SR) capabilities, while
demonstrating superior sample efficiency and adequate token usage. Notably, CR
adaptively emphasizes domain-appropriate reasoning styles. It prioritizes
abductive and deductive reasoning for medical question answering, but shifts to
causal, deductive, and inductive methods for scientific reasoning. Our findings
highlight that by cultivating internal reasoning style diversity, LLMs acquire
more robust, adaptive, and efficient problem-solving abilities.

</details>


### [235] [In Their Own Words: Reasoning Traces Tailored for Small Models Make Them Better Reasoners](https://arxiv.org/abs/2509.22230)
*Jaehoon Kim,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Transferring reasoning capabilities from larger language models to smaller
ones through supervised fine-tuning often fails counterintuitively, with
performance degrading despite access to high-quality teacher demonstrations. We
identify that this failure stems from distributional misalignment: reasoning
traces from larger models contain tokens that are low probability under the
student's distribution, exceeding the internal representation capacity of
smaller architectures and creating learning barriers rather than helpful
guidance. We propose Reverse Speculative Decoding (RSD), a mechanism for
generating student-friendly reasoning traces in which the teacher model
proposes candidate tokens but the student model determines acceptance based on
its own probability distributions, filtering low probability tokens. When
applied to Qwen3-0.6B, direct distillation of s1K-1.1 reasoning trace data
degrades average performance across major reasoning benchmarks by 20.5\%, while
the same model trained on RSD-generated reasoning traces achieves meaningful
improvements of 4.9\%. Our analysis reveals that low probability tokens
constitute the critical bottleneck in reasoning ability transfer. However,
cross-model experiments demonstrate that RSD traces are model-specific rather
than universally applicable, indicating that distributional alignment must be
tailored for each student architecture's unique internal representation.

</details>


### [236] [FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding](https://arxiv.org/abs/2509.22237)
*Haorui Chen,Chengze Li,Jia Li*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid advancement of Large Language Models (LLMs) has given rise to a
novel software development paradigm known as "vibe coding," where users
interact with coding agents through high-level natural language. However,
existing evaluation benchmarks for code generation inadequately assess an
agent's vibe coding capabilities. Existing benchmarks are misaligned, as they
either require code-level specifications or focus narrowly on issue-solving,
neglecting the critical scenario of feature implementation within the vibe
coding paradiam. To address this gap, we propose FeatBench, a novel benchmark
for vibe coding that focuses on feature implementation. Our benchmark is
distinguished by several key features: 1. Pure Natural Language Prompts. Task
inputs consist solely of abstract natural language descriptions, devoid of any
code or structural hints. 2. A Rigorous & Evolving Data Collection Process.
FeatBench is built on a multi-level filtering pipeline to ensure quality and a
fully automated pipeline to evolve the benchmark, mitigating data
contamination. 3. Comprehensive Test Cases. Each task includes Fail-to-Pass
(F2P) and Pass-to-Pass (P2P) tests to verify correctness and prevent
regressions. 4. Diverse Application Domains. The benchmark includes
repositories from diverse domains to ensure it reflects real-world scenarios.
We evaluate two state-of-the-art agent frameworks with four leading LLMs on
FeatBench. Our evaluation reveals that feature implementation within the vibe
coding paradigm is a significant challenge, with the highest success rate of
only 29.94%. Our analysis also reveals a tendency for "aggressive
implementation," a strategy that paradoxically leads to both critical failures
and superior software design. We release FeatBench, our automated collection
pipeline, and all experimental results to facilitate further community
research.

</details>


### [237] [FLEXI: Benchmarking Full-duplex Human-LLM Speech Interaction](https://arxiv.org/abs/2509.22243)
*Yuan Ge,Saihan Chen,Jingqi Xiao,Xiaoqian Liu,Tong Xiao,Yan Xiang,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: FLEXI是首个用于全双工大型语言模型-人类语音交互的基准测试，特别关注紧急情况下的模型中断。该基准测试通过六种不同的交互场景，系统地评估了实时对话的延迟、质量和会话效果，揭示了开源模型和商业模型在紧急情况意识、回合终止和交互延迟方面存在的显著差距。研究建议，下一词对预测可能是实现真正无缝、类似人类的全双工交互的有前景的方法。


<details>
  <summary>Details</summary>
Motivation: 对全双工语音到语音的大型语言模型（LLM）进行基准测试和建模仍然是一个基本挑战，而这类模型对于实现自然的实时口语对话系统至关重要。

Method: 提出FLEXI，一个用于全双工LLM-人类语音交互的基准测试，该测试包含模型在紧急情况下的中断。通过六种不同的场景，系统地评估延迟、质量和会话效果。

Result: 评估结果显示，在紧急情况意识、回合终止和交互延迟方面，开源模型和商业模型之间存在显著差距。

Conclusion: 下一词对预测为实现真正无缝和类似人类的全双工交互提供了一个有前景的方向。

Abstract: Full-Duplex Speech-to-Speech Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling real-time spoken dialogue systems.
However, benchmarking and modeling these models remains a fundamental
challenge. We introduce FLEXI, the first benchmark for full-duplex LLM-human
spoken interaction that explicitly incorporates model interruption in emergency
scenarios. FLEXI systematically evaluates the latency, quality, and
conversational effectiveness of real-time dialogue through six diverse
human-LLM interaction scenarios, revealing significant gaps between open source
and commercial models in emergency awareness, turn terminating, and interaction
latency. Finally, we suggest that next token-pair prediction offers a promising
path toward achieving truly seamless and human-like full-duplex interaction.

</details>


### [238] [Safety Compliance: Rethinking LLM Safety Reasoning through the Lens of Compliance](https://arxiv.org/abs/2509.22250)
*Wenbin Hu,Huihao Jing,Haochen Shi,Haoran Li,Yangqiu Song*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The proliferation of Large Language Models (LLMs) has demonstrated remarkable
capabilities, elevating the critical importance of LLM safety. However,
existing safety methods rely on ad-hoc taxonomy and lack a rigorous, systematic
protection, failing to ensure safety for the nuanced and complex behaviors of
modern LLM systems. To address this problem, we solve LLM safety from legal
compliance perspectives, named safety compliance. In this work, we posit
relevant established legal frameworks as safety standards for defining and
measuring safety compliance, including the EU AI Act and GDPR, which serve as
core legal frameworks for AI safety and data security in Europe. To bridge the
gap between LLM safety and legal compliance, we first develop a new benchmark
for safety compliance by generating realistic LLM safety scenarios seeded with
legal statutes. Subsequently, we align Qwen3-8B using Group Policy Optimization
(GRPO) to construct a safety reasoner, Compliance Reasoner, which effectively
aligns LLMs with legal standards to mitigate safety risks. Our comprehensive
experiments demonstrate that the Compliance Reasoner achieves superior
performance on the new benchmark, with average improvements of +10.45% for the
EU AI Act and +11.85% for GDPR.

</details>


### [239] [Beyond Textual Context: Structural Graph Encoding with Adaptive Space Alignment to alleviate the hallucination of LLMs](https://arxiv.org/abs/2509.22251)
*Yifang Zhang,Pengfei Duan,Yiwen Yang,Shengwu Xiong*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Currently, the main approach for Large Language Models (LLMs) to tackle the
hallucination issue is incorporating Knowledge Graphs(KGs).However, LLMs
typically treat KGs as plain text, extracting only semantic information and
limiting their use of the crucial structural aspects of KGs. Another challenge
is the gap between the embedding spaces of KGs encoders and LLMs text
embeddings, which hinders the effective integration of structured knowledge. To
overcome these obstacles, we put forward the SSKG-LLM, an innovative model
architecture that is designed to efficiently integrate both the Structural and
Semantic information of KGs into the reasoning processes of LLMs. SSKG-LLM
incorporates the Knowledge Graph Retrieval (KGR) module and the Knowledge Graph
Encoding (KGE) module to preserve semantics while utilizing structure. Then,
the Knowledge Graph Adaptation (KGA) module is incorporated to enable LLMs to
understand KGs embeddings. We conduct extensive experiments and provide a
detailed analysis to explore how incorporating the structural information of
KGs can enhance the factual reasoning abilities of LLMs. Our code are available
at https://github.com/yfangZhang/SSKG-LLM.

</details>


### [240] [Bridging Fairness and Explainability: Can Input-Based Explanations Promote Fairness in Hate Speech Detection?](https://arxiv.org/abs/2509.22291)
*Yifan Wang,Mayank Jobanputra,Ji-Ung Lee,Soyoung Oh,Isabel Valera,Vera Demberg*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Natural language processing (NLP) models often replicate or amplify social
bias from training data, raising concerns about fairness. At the same time,
their black-box nature makes it difficult for users to recognize biased
predictions and for developers to effectively mitigate them. While some studies
suggest that input-based explanations can help detect and mitigate bias, others
question their reliability in ensuring fairness. Existing research on
explainability in fair NLP has been predominantly qualitative, with limited
large-scale quantitative analysis. In this work, we conduct the first
systematic study of the relationship between explainability and fairness in
hate speech detection, focusing on both encoder- and decoder-only models. We
examine three key dimensions: (1) identifying biased predictions, (2) selecting
fair models, and (3) mitigating bias during model training. Our findings show
that input-based explanations can effectively detect biased predictions and
serve as useful supervision for reducing bias during training, but they are
unreliable for selecting fair models among candidates.

</details>


### [241] [Advancing Natural Language Formalization to First Order Logic with Fine-tuned LLMs](https://arxiv.org/abs/2509.22338)
*Felix Vossel,Till Mossakowski,Björn Gehrke*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Automating the translation of natural language to first-order logic (FOL) is
crucial for knowledge representation and formal methods, yet remains
challenging. We present a systematic evaluation of fine-tuned LLMs for this
task, comparing architectures (encoder-decoder vs. decoder-only) and training
strategies. Using the MALLS and Willow datasets, we explore techniques like
vocabulary extension, predicate conditioning, and multilingual training,
introducing metrics for exact match, logical equivalence, and predicate
alignment. Our fine-tuned Flan-T5-XXL achieves 70% accuracy with predicate
lists, outperforming GPT-4o and even the DeepSeek-R1-0528 model with CoT
reasoning ability as well as symbolic systems like ccg2lambda. Key findings
show: (1) predicate availability boosts performance by 15-20%, (2) T5 models
surpass larger decoder-only LLMs, and (3) models generalize to unseen logical
arguments (FOLIO dataset) without specific training. While structural logic
translation proves robust, predicate extraction emerges as the main bottleneck.

</details>


### [242] [The InviTE Corpus: Annotating Invectives in Tudor English Texts for Computational Modeling](https://arxiv.org/abs/2509.22345)
*Sophie Spliethoff,Sanne Hoeken,Silke Schwandt,Sina Zarrieß,Özge Alaçam*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we aim at the application of Natural Language Processing (NLP)
techniques to historical research endeavors, particularly addressing the study
of religious invectives in the context of the Protestant Reformation in Tudor
England. We outline a workflow spanning from raw data, through pre-processing
and data selection, to an iterative annotation process. As a result, we
introduce the InviTE corpus -- a corpus of almost 2000 Early Modern English
(EModE) sentences, which are enriched with expert annotations regarding
invective language throughout 16th-century England. Subsequently, we assess and
compare the performance of fine-tuned BERT-based models and zero-shot prompted
instruction-tuned large language models (LLMs), which highlights the
superiority of models pre-trained on historical data and fine-tuned to
invective detection.

</details>


### [243] [Conversational Implicatures: Modelling Relevance Theory Probabilistically](https://arxiv.org/abs/2509.22354)
*Christoph Unger,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in Bayesian probability theory and its application to
cognitive science in combination with the development of a new generation of
computational tools and methods for probabilistic computation have led to a
'probabilistic turn' in pragmatics and semantics. In particular, the framework
of Rational Speech Act theory has been developed to model broadly Gricean
accounts of pragmatic phenomena in Bayesian terms, starting with fairly simple
reference games and covering ever more complex communicative exchanges such as
verbal syllogistic reasoning. This paper explores in which way a similar
Bayesian approach might be applied to relevance-theoretic pragmatics (Sperber &
Wilson, 1995) by study a paradigmatic pragmatic phenomenon: the communication
of implicit meaning by ways of (conversational) implicatures.

</details>


### [244] [CHRONOBERG: Capturing Language Evolution and Temporal Awareness in Foundation Models](https://arxiv.org/abs/2509.22360)
*Niharika Hegde,Subarnaduti Paul,Lars Joel-Frey,Manuel Brack,Kristian Kersting,Martin Mundt,Patrick Schramowski*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) excel at operating at scale by leveraging social
media and various data crawled from the web. Whereas existing corpora are
diverse, their frequent lack of long-term temporal structure may however limit
an LLM's ability to contextualize semantic and normative evolution of language
and to capture diachronic variation. To support analysis and training for the
latter, we introduce CHRONOBERG, a temporally structured corpus of English book
texts spanning 250 years, curated from Project Gutenberg and enriched with a
variety of temporal annotations. First, the edited nature of books enables us
to quantify lexical semantic change through time-sensitive
Valence-Arousal-Dominance (VAD) analysis and to construct historically
calibrated affective lexicons to support temporally grounded interpretation.
With the lexicons at hand, we demonstrate a need for modern LLM-based tools to
better situate their detection of discriminatory language and contextualization
of sentiment across various time-periods. In fact, we show how language models
trained sequentially on CHRONOBERG struggle to encode diachronic shifts in
meaning, emphasizing the need for temporally aware training and evaluation
pipelines, and positioning CHRONOBERG as a scalable resource for the study of
linguistic change and temporal generalization. Disclaimer: This paper includes
language and display of samples that could be offensive to readers. Open
Access: Chronoberg is available publicly on HuggingFace at (
https://huggingface.co/datasets/spaul25/Chronoberg). Code is available at
(https://github.com/paulsubarna/Chronoberg).

</details>


### [245] [Exploratory Semantic Reliability Analysis of Wind Turbine Maintenance Logs using Large Language Models](https://arxiv.org/abs/2509.22366)
*Max Malyi,Jonathan Shek,Andre Biscaya*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A wealth of operational intelligence is locked within the unstructured
free-text of wind turbine maintenance logs, a resource largely inaccessible to
traditional quantitative reliability analysis. While machine learning has been
applied to this data, existing approaches typically stop at classification,
categorising text into predefined labels. This paper addresses the gap in
leveraging modern large language models (LLMs) for more complex reasoning
tasks. We introduce an exploratory framework that uses LLMs to move beyond
classification and perform deep semantic analysis. We apply this framework to a
large industrial dataset to execute four analytical workflows: failure mode
identification, causal chain inference, comparative site analysis, and data
quality auditing. The results demonstrate that LLMs can function as powerful
"reliability co-pilots," moving beyond labelling to synthesise textual
information and generate actionable, expert-level hypotheses. This work
contributes a novel and reproducible methodology for using LLMs as a reasoning
tool, offering a new pathway to enhance operational intelligence in the wind
energy sector by unlocking insights previously obscured in unstructured data.

</details>


### [246] [What Is The Political Content in LLMs' Pre- and Post-Training Data?](https://arxiv.org/abs/2509.22367)
*Tanise Ceron,Dmitry Nikolaev,Dominik Stammbach,Debora Nozza*

Main category: cs.CL

TL;DR: LLM 训练数据中的政治偏见分析，表明左倾内容占主导地位，并与模型的政治立场相关。


<details>
  <summary>Details</summary>
Motivation: 由于 LLM 产生政治偏见但来源不明，因此需要分析其训练数据中的政治内容。

Method: 分析了 OLMO2 的预训练和后训练语料库，自动标注了文档的政治倾向，并分析了其来源领域和内容，最后评估了训练数据中的政治内容与模型在特定政策问题上的立场之间的相关性。

Result: OLMO2 的训练数据中左倾文档占主导地位，预训练语料库的政治参与度内容显著高于后训练数据。左右倾文档在相似主题的表述中使用了不同的价值观和合法性来源。训练数据中的主导立场与模型在政策问题上的政治偏见密切相关。

Conclusion: 政治内容分析和数据过滤策略的透明度记录对于未来的数据管理和 LLM 研究至关重要。

Abstract: Large language models (LLMs) are known to generate politically biased text,
yet how such biases arise remains unclear. A crucial step toward answering this
question is the analysis of training data, whose political content remains
largely underexplored in current LLM research. To address this gap, we present
in this paper an analysis of the pre- and post-training corpora of OLMO2, the
largest fully open-source model released together with its complete dataset.
From these corpora, we draw large random samples, automatically annotate
documents for political orientation, and analyze their source domains and
content. We then assess how political content in the training data correlates
with models' stance on specific policy issues. Our analysis shows that
left-leaning documents predominate across datasets, with pre-training corpora
containing significantly more politically engaged content than post-training
data. We also find that left- and right-leaning documents frame similar topics
through distinct values and sources of legitimacy. Finally, the predominant
stance in the training data strongly correlates with models' political biases
when evaluated on policy issues. These findings underscore the need to
integrate political content analysis into future data curation pipelines as
well as in-depth documentation of filtering strategies for transparency.

</details>


### [247] [Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding](https://arxiv.org/abs/2509.22437)
*Ziheng Chi,Yifan Hou,Chenxi Pang,Shaobo Cui,Mubashara Akhtar,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Diagrams convey symbolic information in a visual format rather than a linear
stream of words, making them especially challenging for AI models to process.
While recent evaluations suggest that vision-language models (VLMs) perform
well on diagram-related benchmarks, their reliance on knowledge, reasoning, or
modality shortcuts raises concerns about whether they genuinely understand and
reason over diagrams. To address this gap, we introduce Chimera, a
comprehensive test suite comprising 7,500 high-quality diagrams sourced from
Wikipedia; each diagram is annotated with its symbolic content represented by
semantic triples along with multi-level questions designed to assess four
fundamental aspects of diagram comprehension: entity recognition, relation
understanding, knowledge grounding, and visual reasoning. We use Chimera to
measure the presence of three types of shortcuts in visual question answering:
(1) the visual-memorization shortcut, where VLMs rely on memorized visual
patterns; (2) the knowledge-recall shortcut, where models leverage memorized
factual knowledge instead of interpreting the diagram; and (3) the Clever-Hans
shortcut, where models exploit superficial language patterns or priors without
true comprehension. We evaluate 15 open-source VLMs from 7 model families on
Chimera and find that their seemingly strong performance largely stems from
shortcut behaviors: visual-memorization shortcuts have slight impact,
knowledge-recall shortcuts play a moderate role, and Clever-Hans shortcuts
contribute significantly. These findings expose critical limitations in current
VLMs and underscore the need for more robust evaluation protocols that
benchmark genuine comprehension of complex visual inputs (e.g., diagrams)
rather than question-answering shortcuts.

</details>


### [248] [Detecting (Un)answerability in Large Language Models with Linear Directions](https://arxiv.org/abs/2509.22449)
*Maor Juliet Lavi,Tova Milo,Mor Geva*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) often respond confidently to questions even when
they lack the necessary information, leading to hallucinated answers. In this
work, we study the problem of (un)answerability detection, focusing on
extractive question answering (QA) where the model should determine if a
passage contains sufficient information to answer a given question. We propose
a simple approach for identifying a direction in the model's activation space
that captures unanswerability and uses it for classification. This direction is
selected by applying activation additions during inference and measuring their
impact on the model's abstention behavior. We show that projecting hidden
activations onto this direction yields a reliable score for (un)answerability
classification. Experiments on two open-weight LLMs and four extractive QA
benchmarks show that our method effectively detects unanswerable questions and
generalizes better across datasets than existing prompt-based and
classifier-based approaches. Moreover, the obtained directions extend beyond
extractive QA to unanswerability that stems from factors, such as lack of
scientific consensus and subjectivity. Last, causal interventions show that
adding or ablating the directions effectively controls the abstention behavior
of the model.

</details>


### [249] [Evaluating the Limits of Large Language Models in Multilingual Legal Reasoning](https://arxiv.org/abs/2509.22472)
*Antreas Ioannou,Andreas Shiamishis,Nora Hollenstein,Nezihe Merve Gürel*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In an era dominated by Large Language Models (LLMs), understanding their
capabilities and limitations, especially in high-stakes fields like law, is
crucial. While LLMs such as Meta's LLaMA, OpenAI's ChatGPT, Google's Gemini,
DeepSeek, and other emerging models are increasingly integrated into legal
workflows, their performance in multilingual, jurisdictionally diverse, and
adversarial contexts remains insufficiently explored. This work evaluates LLaMA
and Gemini on multilingual legal and non-legal benchmarks, and assesses their
adversarial robustness in legal tasks through character and word-level
perturbations. We use an LLM-as-a-Judge approach for human-aligned evaluation.
We moreover present an open-source, modular evaluation pipeline designed to
support multilingual, task-diverse benchmarking of any combination of LLMs and
datasets, with a particular focus on legal tasks, including classification,
summarization, open questions, and general reasoning. Our findings confirm that
legal tasks pose significant challenges for LLMs with accuracies often below
50% on legal reasoning benchmarks such as LEXam, compared to over 70% on
general-purpose tasks like XNLI. In addition, while English generally yields
more stable results, it does not always lead to higher accuracy. Prompt
sensitivity and adversarial vulnerability is also shown to persist across
languages. Finally, a correlation is found between the performance of a
language and its syntactic similarity to English. We also observe that LLaMA is
weaker than Gemini, with the latter showing an average advantage of about 24
percentage points across the same task. Despite improvements in newer LLMs,
challenges remain in deploying them reliably for critical, multilingual legal
applications.

</details>


### [250] [NeLLCom-Lex: A Neural-agent Framework to Study the Interplay between Lexical Systems and Language Use](https://arxiv.org/abs/2509.22479)
*Yuqing Zhang,Ecesu Ürker,Tessa Verhoef,Gemma Boleda,Arianna Bisazza*

Main category: cs.CL

TL;DR: 本文提出了一个名为NeLLCom-Lex的神经代理框架，用于模拟词汇语义变化。该框架通过将代理置于真实的词汇系统（如英语）中，并系统地操纵其沟通需求，来模拟语义演变过程。研究发现，经过训练的神经代理能够显著地再现人类在颜色命名方面的行为和词汇模式，并能根据沟通需求调整其行为和词汇。


<details>
  <summary>Details</summary>
Motivation: 现有的词汇语义变化研究方法（如语料库分析、分布式语义建模）无法揭示其因果机制，而涉及长期历史过程的实验范式难以应用于语义变化研究。因此，需要一种新的方法来模拟和研究词汇语义变化。

Method: 提出并使用名为NeLLCom-Lex的神经代理框架。该框架将代理置于真实的词汇系统（如英语）中，并通过颜色命名任务模拟单个世代的词汇系统演变。研究人员还使用了不同的监督学习和强化学习方法来训练代理，并操纵其沟通需求。

Result: 研究结果表明，经过训练以‘说’现有语言的神经代理在很大程度上能够重现人类在颜色命名方面的模式。这表明NeLLCom-Lex能够有效地模拟人类的学习行为，并且其行为和词汇会根据沟通需求而改变。

Conclusion: NeLLCom-Lex框架能够成功模拟词汇语义变化，并重现人类行为模式。该框架为进一步阐明语义变化的机制提供了一个有力的工具。

Abstract: Lexical semantic change has primarily been investigated with observational
and experimental methods; however, observational methods (corpus analysis,
distributional semantic modeling) cannot get at causal mechanisms, and
experimental paradigms with humans are hard to apply to semantic change due to
the extended diachronic processes involved. This work introduces NeLLCom-Lex, a
neural-agent framework designed to simulate semantic change by first grounding
agents in a real lexical system (e.g. English) and then systematically
manipulating their communicative needs. Using a well-established color naming
task, we simulate the evolution of a lexical system within a single generation,
and study which factors lead agents to: (i) develop human-like naming behavior
and lexicons, and (ii) change their behavior and lexicons according to their
communicative needs. Our experiments with different supervised and
reinforcement learning pipelines show that neural agents trained to 'speak' an
existing language can reproduce human-like patterns in color naming to a
remarkable extent, supporting the further use of NeLLCom-Lex to elucidate the
mechanisms of semantic change.

</details>


### [251] [Exploring Solution Divergence and Its Effect on Large Language Model Problem Solving](https://arxiv.org/abs/2509.22480)
*Hang Li,Kaiqi Yang,Yucheng Chu,Hui Liu,Jiliang Tang*

Main category: cs.CL

TL;DR: LLM在解决问题时，其解题思路的分歧度越高，解决问题的能力越强。基于此，提出了一种名为“解题分歧度”的新指标，该指标可以增强监督微调（SFT）和强化学习（RL）的训练方法，并验证了其在三个代表性问题域中的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM在解决问题时，其解题思路的分歧度越高，解决问题的能力越强。这一发现为LLM的训练和评估提供了新的视角。

Method: 提出“解题分歧度”作为新的指标，并将其应用于SFT和RL训练中，以提高LLM解决问题的能力。

Result: 在三个代表性问题域的实验中，使用“解题分歧度”作为指标能够稳定地提高LLM的成功率。

Conclusion: “解题分歧度”是一种简单而有效的工具，可以用于改进LLM的训练和评估。

Abstract: Large language models (LLMs) have been widely used for problem-solving tasks.
Most recent work improves their performance through supervised fine-tuning
(SFT) with labeled data or reinforcement learning (RL) from task feedback. In
this paper, we study a new perspective: the divergence in solutions generated
by LLMs for a single problem. We show that higher solution divergence is
positively related to better problem-solving abilities across various models.
Based on this finding, we propose solution divergence as a novel metric that
can support both SFT and RL strategies. We test this idea on three
representative problem domains and find that using solution divergence
consistently improves success rates. These results suggest that solution
divergence is a simple but effective tool for advancing LLM training and
evaluation.

</details>


### [252] [JGU Mainz's Submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: MT and QA](https://arxiv.org/abs/2509.22490)
*Hossain Shaikh Saadi,Minh Duc Bui,Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: JGU Mainz在WMT25有限资源斯拉夫语言任务中，使用Qwen2.5-3B-Instruct模型对乌克兰语、上索布语和下索布语进行联合微调，并结合检索增强生成和模型集成，机器翻译和问答任务均优于基线。


<details>
  <summary>Details</summary>
Motivation: 在WMT25共享任务中，针对资源有限的斯拉夫语言（乌克兰语、上索布语、下索布语）的机器翻译和问答任务，提交JGU Mainz的解决方案。

Method: 对于每种语言，联合微调Qwen2.5-3B-Instruct模型以同时处理机器翻译和问答任务，采用参数高效微调方法。该流程整合了额外的翻译和多项选择问答数据。针对乌克兰语问答，采用检索增强生成。对上索布语和下索布语的问答，则应用了模型集成技术。

Result: 实验结果表明，本研究提出的模型在机器翻译和问答两个任务上均优于基线模型。

Conclusion: 通过参数高效微调、检索增强生成和模型集成等方法，成功提升了在资源有限的斯拉夫语言上的机器翻译和问答性能。

Abstract: This paper presents the JGU Mainz submission to the WMT25 Shared Task on LLMs
with Limited Resources for Slavic Languages: Machine Translation and Question
Answering, focusing on Ukrainian, Upper Sorbian, and Lower Sorbian. For each
language, we jointly fine-tune a Qwen2.5-3B-Instruct model for both tasks with
parameter-efficient finetuning. Our pipeline integrates additional translation
and multiple-choice question answering (QA) data. For Ukrainian QA, we further
use retrieval-augmented generation. We also apply ensembling for QA in Upper
and Lower Sorbian. Experiments show that our models outperform the baseline on
both tasks.

</details>


### [253] [Representing LLMs in Prompt Semantic Task Space](https://arxiv.org/abs/2509.22506)
*Idan Kashani,Avi Mendelson,Yaniv Nemcovsky*

Main category: cs.CL

TL;DR: 为给定任务识别最佳大型语言模型（LLM）具有挑战性。提出一种高效、无需训练的方法，将 LLM 表示为提示语义任务空间中的线性算子，以实现可解释的表示、出色的可扩展性和实时适应性。


<details>
  <summary>Details</summary>
Motivation: 识别最佳 LLM 具有挑战性，现有方法可扩展性有限且成本高昂。

Method: 将 LLM 表示为提示语义任务空间中的线性算子，利用几何特性进行闭式计算。

Result: 在成功预测和模型选择任务上取得了具有竞争力的结果，并在样本外场景中表现出色。

Conclusion: 该方法高效、可扩展且可解释，适用于动态扩展的模型库。

Abstract: Large language models (LLMs) achieve impressive results over various tasks,
and ever-expanding public repositories contain an abundance of pre-trained
models. Therefore, identifying the best-performing LLM for a given task is a
significant challenge. Previous works have suggested learning LLM
representations to address this. However, these approaches present limited
scalability and require costly retraining to encompass additional models and
datasets. Moreover, the produced representation utilizes distinct spaces that
cannot be easily interpreted. This work presents an efficient, training-free
approach to representing LLMs as linear operators within the prompts' semantic
task space, thus providing a highly interpretable representation of the models'
application. Our method utilizes closed-form computation of geometrical
properties and ensures exceptional scalability and real-time adaptability to
dynamically expanding repositories. We demonstrate our approach on success
prediction and model selection tasks, achieving competitive or state-of-the-art
results with notable performance in out-of-sample scenarios.

</details>


### [254] [We Think, Therefore We Align LLMs to Helpful, Harmless and Honest Before They Go Wrong](https://arxiv.org/abs/2509.22510)
*Gautam Siddharth Kashyap,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: LLM对齐（HHH）是一个关键的安全问题。本研究提出了自适应多分支转向（AMBS），一种新的1对N框架，通过共享表示和策略-参考机制来解决多目标对齐中的灾难性遗忘和推理碎片化问题。实验表明，AMBS在Alpaca、BeaverTails和TruthfulQA数据集上显著提高了LLM的HHH对齐度，并在DeepSeek-7B模型上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 以往的LLM对齐方法，特别是使用转向向量（steering vectors）的方法，在优化单一对齐目标时，容易导致其他目标的灾难性遗忘。虽然1对N（one-to-N）的Transformer解码器缓解了这个问题，但它们独立的优化方式会导致推理碎片化，使得不同对齐目标下的输出不一致。因此，需要一种能够统一且高效地处理多目标对齐的方法。

Method: 提出了一种名为自适应多分支转向（AMBS）的两阶段1对N框架。第一阶段，在Transformer层计算一次后注意力（post-attention）的隐藏状态，形成共享表示。第二阶段，将该共享表示克隆到并行分支中，并通过策略-参考机制（policy-reference mechanism）进行引导，从而实现特定于目标的控制，同时保持跨目标的一致性。

Result: 在Alpaca、BeaverTails和TruthfulQA数据集上，AMBS在多种7B LLM骨干模型上一致地提高了HHH对齐度。具体而言，与朴素的1对N基线相比，AMBS在DeepSeek-7B模型上平均对齐分数提高了+32.4%，不安全输出减少了11.0%，同时在性能上与最先进的方法保持竞争力。

Conclusion: AMBS是一种有效的两阶段1对N框架，能够解决多目标LLM对齐中的灾难性遗忘和推理碎片化问题。该方法通过共享表示和策略-参考机制，实现了统一且高效的多目标对齐，并在多个基准测试中展现出优越的性能。

Abstract: Alignment of Large Language Models (LLMs) along multiple
objectives-helpfulness, harmlessness, and honesty (HHH)-is critical for safe
and reliable deployment. Prior work has used steering vector-small control
signals injected into hidden states-to guide LLM outputs, typically via
one-to-one (1-to-1) Transformer decoders. In this setting, optimizing a single
alignment objective can inadvertently overwrite representations learned for
other objectives, leading to catastrophic forgetting. More recent approaches
extend steering vectors via one-to-many (1-to-N) Transformer decoders. While
this alleviates catastrophic forgetting, naive multi-branch designs optimize
each objective independently, which can cause inference fragmentation-outputs
across HHH objectives may become inconsistent. We propose Adaptive Multi-Branch
Steering (AMBS), a two-stage 1-to-N framework for unified and efficient
multi-objective alignment. In Stage I, post-attention hidden states of the
Transformer layer are computed once to form a shared representation. In Stage
II, this representation is cloned into parallel branches and steered via a
policy-reference mechanism, enabling objective-specific control while
maintaining cross-objective consistency. Empirical evaluations on Alpaca,
BeaverTails, and TruthfulQA show that AMBS consistently improves HHH alignment
across multiple 7B LLM backbones. For example, on DeepSeek-7B, AMBS improves
average alignment scores by +32.4% and reduces unsafe outputs by 11.0% compared
to a naive 1-to-N baseline, while remaining competitive with state-of-the-art
methods.

</details>


### [255] [InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models](https://arxiv.org/abs/2509.22536)
*Wenjun Wang,Shuo Cai,Congkai Xie,Mingfa Feng,Yiming Zhang,Zhen Li,Kejing Yang,Ming Li,Jiannong Cao,Yuan Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: 本文提出了一种端到端的FP8训练方法，通过混合精度量化策略，在保持模型性能的同时，显著提高了训练效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）训练的巨大计算成本问题，并推广FP8训练的应用。

Method: 采用细粒度的混合精度量化策略，并整合了持续预训练和监督微调。

Result: 在160B token语料库上进行了模型持续预训练实验，证明了该方法稳定且性能几乎无损，与BF16基线相当，同时在训练时间、峰值内存使用和吞吐量方面均有显著提升。

Conclusion: FP8训练是一种实用且鲁棒的替代BF16的方法，并计划开源相关代码以促进大型模型训练的普及。

Abstract: The immense computational cost of training Large Language Models (LLMs)
presents a major barrier to innovation. While FP8 training offers a promising
solution with significant theoretical efficiency gains, its widespread adoption
has been hindered by the lack of a comprehensive, open-source training recipe.
To bridge this gap, we introduce an end-to-end FP8 training recipe that
seamlessly integrates continual pre-training and supervised fine-tuning. Our
methodology employs a fine-grained, hybrid-granularity quantization strategy to
maintain numerical fidelity while maximizing computational efficiency. Through
extensive experiments, including the continue pre-training of models on a
160B-token corpus, we demonstrate that our recipe is not only remarkably stable
but also essentially lossless, achieving performance on par with the BF16
baseline across a suite of reasoning benchmarks. Crucially, this is achieved
with substantial efficiency improvements, including up to a 22% reduction in
training time, a 14% decrease in peak memory usage, and a 19% increase in
throughput. Our results establish FP8 as a practical and robust alternative to
BF16, and we will release the accompanying code to further democratize
large-scale model training.

</details>


### [256] [Think Socially via Cognitive Reasoning](https://arxiv.org/abs/2509.22546)
*Jinfeng Zhou,Zheyu Chen,Shuai Wang,Quanyu Dai,Zhenhua Dong,Hongning Wang,Minlie Huang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: LLMs trained for logical reasoning excel at step-by-step deduction to reach
verifiable answers. However, this paradigm is ill-suited for navigating social
situations, which induce an interpretive process of analyzing ambiguous cues
that rarely yield a definitive outcome. To bridge this gap, we introduce
Cognitive Reasoning, a paradigm modeled on human social cognition. It
formulates the interpretive process into a structured cognitive flow of
interconnected cognitive units (e.g., observation or attribution), which
combine adaptively to enable effective social thinking and responses. We then
propose CogFlow, a complete framework that instills this capability in LLMs.
CogFlow first curates a dataset of cognitive flows by simulating the
associative and progressive nature of human thought via tree-structured
planning. After instilling the basic cognitive reasoning capability via
supervised fine-tuning, CogFlow adopts reinforcement learning to enable the
model to improve itself via trial and error, guided by a multi-objective reward
that optimizes both cognitive flow and response quality. Extensive experiments
show that CogFlow effectively enhances the social cognitive capabilities of
LLMs, and even humans, leading to more effective social decision-making.

</details>


### [257] [Retrieval-Augmented Guardrails for AI-Drafted Patient-Portal Messages: Error Taxonomy Construction and Large-Scale Evaluation](https://arxiv.org/abs/2509.22565)
*Wenyuan Chen,Fateme Nateghi Haredasht,Kameron C. Black,Francois Grolleau,Emily Alsentzer,Jonathan H. Chen,Stephen P. Ma*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Asynchronous patient-clinician messaging via EHR portals is a growing source
of clinician workload, prompting interest in large language models (LLMs) to
assist with draft responses. However, LLM outputs may contain clinical
inaccuracies, omissions, or tone mismatches, making robust evaluation
essential. Our contributions are threefold: (1) we introduce a clinically
grounded error ontology comprising 5 domains and 59 granular error codes,
developed through inductive coding and expert adjudication; (2) we develop a
retrieval-augmented evaluation pipeline (RAEC) that leverages semantically
similar historical message-response pairs to improve judgment quality; and (3)
we provide a two-stage prompting architecture using DSPy to enable scalable,
interpretable, and hierarchical error detection. Our approach assesses the
quality of drafts both in isolation and with reference to similar past
message-response pairs retrieved from institutional archives. Using a two-stage
DSPy pipeline, we compared baseline and reference-enhanced evaluations on over
1,500 patient messages. Retrieval context improved error identification in
domains such as clinical completeness and workflow appropriateness. Human
validation on 100 messages demonstrated superior agreement (concordance = 50%
vs. 33%) and performance (F1 = 0.500 vs. 0.256) of context-enhanced labels vs.
baseline, supporting the use of our RAEC pipeline as AI guardrails for patient
messaging.

</details>


### [258] [Fine-Grained Detection of Context-Grounded Hallucinations Using LLMs](https://arxiv.org/abs/2509.22582)
*Yehonatan Pesiakhovsky,Zorik Gekhman,Yosi Mass,Liat Ein-Dor,Roi Reichart*

Main category: cs.CL

TL;DR: LLMs can be used to detect hallucinations in text, but it's challenging. A new benchmark and representation were created to evaluate LLMs on this task. The best model achieved only a 0.67 F1 score, highlighting the difficulty of the task due to LLMs incorrectly flagging missing details and struggles with information not present in the source text.


<details>
  <summary>Details</summary>
Motivation: To study the applicability of LLMs for localizing context-grounded hallucinations as a practical alternative to existing complex evaluation pipelines.

Method: Constructed a new benchmark with over 1,000 human-annotated examples tailored for LLMs. Proposed a new representation for hallucinations based on free-form textual descriptions. Evaluated four large-scale LLMs on this benchmark. Analyzed optimal prompting strategies and identified challenges for LLMs.

Result: The best performing LLM achieved an F1 score of 0.67 on the benchmark. Key challenges identified include LLMs incorrectly flagging missing details as inconsistencies and difficulty with outputs containing factually correct information absent from the source text (due to parametric knowledge).

Conclusion: Localizing context-grounded hallucinations is a challenging task for LLMs. The developed benchmark and representation provide a valuable resource for evaluating and improving LLMs' capabilities in this area. Further research is needed to address the identified challenges, particularly concerning missing details and the influence of parametric knowledge.

Abstract: Context-grounded hallucinations are cases where model outputs contain
information not verifiable against the source text. We study the applicability
of LLMs for localizing such hallucinations, as a more practical alternative to
existing complex evaluation pipelines. In the absence of established benchmarks
for meta-evaluation of hallucinations localization, we construct one tailored
to LLMs, involving a challenging human annotation of over 1,000 examples. We
complement the benchmark with an LLM-based evaluation protocol, verifying its
quality in a human evaluation. Since existing representations of hallucinations
limit the types of errors that can be expressed, we propose a new
representation based on free-form textual descriptions, capturing the full
range of possible errors. We conduct a comprehensive study, evaluating four
large-scale LLMs, which highlights the benchmark's difficulty, as the best
model achieves an F1 score of only 0.67. Through careful analysis, we offer
insights into optimal prompting strategies for the task and identify the main
factors that make it challenging for LLMs: (1) a tendency to incorrectly flag
missing details as inconsistent, despite being instructed to check only facts
in the output; and (2) difficulty with outputs containing factually correct
information absent from the source - and thus not verifiable - due to alignment
with the model's parametric knowledge.

</details>


### [259] [ArabJobs: A Multinational Corpus of Arabic Job Ads](https://arxiv.org/abs/2509.22589)
*Mo El-Haj*

Main category: cs.CL

TL;DR: ArabJobs是一个包含8500多条来自埃及、约旦、沙特阿拉伯和阿联酋的阿拉伯语招聘广告的数据集，可用于公平意识的阿拉伯语自然语言处理和劳动力市场研究。


<details>
  <summary>Details</summary>
Motivation: 收集一个全面的阿拉伯语招聘广告语料库，以捕捉阿拉伯劳动力市场的语言、地区和社会经济变异性，并为公平意识的阿拉伯语自然语言处理和劳动力市场研究提供资源。

Method: 收集来自埃及、约旦、沙特阿拉伯和阿联酋的8500多条阿拉伯语招聘广告，构建ArabJobs数据集。对性别代表性、职业结构和方言变异性进行分析。展示了使用大型语言模型进行薪资估算和职位类别标准化的应用，并进行了性别偏见检测和职业分类的基准任务。

Result: ArabJobs数据集捕捉了阿拉伯劳动力市场的语言、地区和社会经济变异性。分析显示了性别代表性、职业结构和广告中的方言变异性。薪资估算、职位类别标准化、性别偏见检测和职业分类任务的演示结果证明了该数据集的效用。

Conclusion: ArabJobs数据集为公平意识的阿拉伯语自然语言处理和劳动力市场研究提供了宝贵的资源。该数据集能够支持对性别代表性、职业结构和方言变异性的分析，并可用于开发和评估各种应用，如薪资估算、职位类别标准化和偏见检测。

Abstract: ArabJobs is a publicly available corpus of Arabic job advertisements
collected from Egypt, Jordan, Saudi Arabia, and the United Arab Emirates.
Comprising over 8,500 postings and more than 550,000 words, the dataset
captures linguistic, regional, and socio-economic variation in the Arab labour
market. We present analyses of gender representation and occupational
structure, and highlight dialectal variation across ads, which offers
opportunities for future research. We also demonstrate applications such as
salary estimation and job category normalisation using large language models,
alongside benchmark tasks for gender bias detection and profession
classification. The findings show the utility of ArabJobs for fairness-aware
Arabic NLP and labour market research. The dataset is publicly available on
GitHub: https://github.com/drelhaj/ArabJobs.

</details>


### [260] [From Formal Language Theory to Statistical Learning: Finite Observability of Subregular Languages](https://arxiv.org/abs/2509.22598)
*Katsuhiko Hayashi,Hidetaka Kamigaito*

Main category: cs.CL

TL;DR: 所有标准的子规语言类别在由其判定谓词表示时都是线性可分的，这保证了它们可以用简单的线性模型进行学习。


<details>
  <summary>Details</summary>
Motivation: 证明所有标准的子规语言类别在由其判定谓词表示时都是线性可分的，以保证它们可以用简单的线性模型进行学习。

Method: 证明标准子规语言类别是线性可分的，并通过合成实验和真实数据实验来验证。

Result: 合成实验确认了在无噪声条件下完美可分性，真实数据实验表明学习到的特征与已知的语言学约束一致。

Conclusion: 子规层级为模拟自然语言结构提供了严格且可解释的基础。

Abstract: We prove that all standard subregular language classes are linearly separable
when represented by their deciding predicates. This establishes finite
observability and guarantees learnability with simple linear models. Synthetic
experiments confirm perfect separability under noise-free conditions, while
real-data experiments on English morphology show that learned features align
with well-known linguistic constraints. These results demonstrate that the
subregular hierarchy provides a rigorous and interpretable foundation for
modeling natural language structure. Our code used in real-data experiments is
available at https://github.com/UTokyo-HayashiLab/subregular.

</details>


### [261] [Capturing Opinion Shifts in Deliberative Discourse through Frequency-based Quantum deep learning methods](https://arxiv.org/abs/2509.22603)
*Rakesh Thakur,Harsh Chaturvedi,Ruqayya Shah,Janvi Chauhan,Ayush Sharma*

Main category: cs.CL

TL;DR: NLP技术被用于分析和模拟审议过程，以理解意见转变并预测结果。研究比较了两种模型（基于频率的话语调制和量子审议框架），并发现了在公共政策、辩论评估和社会媒体意见挖掘等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理（NLP）取得进展的背景下，通过计算模型来理解和预测审议过程中的意见转变，这具有重要意义。

Method: 通过收集个人意见构建数据集，并利用包含显著事实的产品演示来模拟审议过程，以观察观众意见的变化。随后，对“基于频率的话语调制”和“量子审议框架”这两种模型进行了比较分析。

Result: 研究比较了两种NLP模型，发现“基于频率的话语调制”和“量子审议框架”在解释审议性话语和产生有意义的见解方面优于现有的最先进模型。

Conclusion: 研究结果强调了在公共政策制定、辩论评估、决策支持框架和社交媒体意见挖掘等领域的实际应用潜力。

Abstract: Deliberation plays a crucial role in shaping outcomes by weighing diverse
perspectives before reaching decisions. With recent advancements in Natural
Language Processing, it has become possible to computationally model
deliberation by analyzing opinion shifts and predicting potential outcomes
under varying scenarios. In this study, we present a comparative analysis of
multiple NLP techniques to evaluate how effectively models interpret
deliberative discourse and produce meaningful insights. Opinions from
individuals of varied backgrounds were collected to construct a self-sourced
dataset that reflects diverse viewpoints. Deliberation was simulated using
product presentations enriched with striking facts, which often prompted
measurable shifts in audience opinions. We have given comparative analysis
between two models namely Frequency-Based Discourse Modulation and
Quantum-Deliberation Framework which outperform the existing state of art
models. The findings highlight practical applications in public policy-making,
debate evaluation, decision-support frameworks, and large-scale social media
opinion mining.

</details>


### [262] [From tests to effect sizes: Quantifying uncertainty and statistical variability in multilingual and multitask NLP evaluation benchmarks](https://arxiv.org/abs/2509.22612)
*Jonne Sälevä,Duygu Ataman,Constantine Lignos*

Main category: cs.CL

TL;DR: 介绍了一种基于重采样的方法来量化多语言和/或多任务NLP基准测试中评估指标的不确定性和统计精度。


<details>
  <summary>Details</summary>
Motivation: 量化多语言和/或多任务NLP基准测试中评估指标的不确定性和统计精度，并说明实验性性能得分的变化来自模型和数据相关来源。

Method: 使用多语言问答、机器翻译和命名实体识别作为示例任务，展示了重采样方法如何用于计算排列表格中各种数量的抽样分布。

Result: 通过重采样方法，可以准确地量化不确定性和统计精度，避免低估整体变异性。

Conclusion: 重采样方法对于量化不确定性和统计精度至关重要，有助于更准确地评估模型在多语言和多任务NLP基准测试中的表现。

Abstract: In this paper, we introduce a set of resampling-based methods for quantifying
uncertainty and statistical precision of evaluation metrics in multilingual
and/or multitask NLP benchmarks. We show how experimental variation in
performance scores arises from both model- and data-related sources, and that
accounting for both of them is necessary to avoid substantially underestimating
the overall variability over hypothetical replications. Using multilingual
question answering, machine translation, and named entity recognition as
example tasks, we also demonstrate how resampling methods are useful for
computing sampling distributions for various quantities used in leaderboards
such as the average/median, pairwise differences between models, and rankings.

</details>


### [263] [StateX: Enhancing RNN Recall via Post-training State Expansion](https://arxiv.org/abs/2509.22630)
*Xingyu Shen,Yingfa Chen,Zhen Leng Thai,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While Transformer-based models have demonstrated remarkable language modeling
performance, their high complexities result in high costs when processing long
contexts. In contrast, recurrent neural networks (RNNs) such as linear
attention and state space models have gained popularity due to their constant
per-token complexities. However, these recurrent models struggle with tasks
that require accurate recall of contextual information from long contexts,
because all contextual information is compressed into a constant-size recurrent
state. Previous works have shown that recall ability is positively correlated
with the recurrent state size, yet directly training RNNs with larger recurrent
states results in high training costs. In this paper, we introduce StateX, a
training pipeline for efficiently expanding the states of pre-trained RNNs
through post-training. For two popular classes of RNNs, linear attention and
state space models, we design post-training architectural modifications to
scale up the state size with no or negligible increase in model parameters.
Experiments on models up to 1.3B parameters demonstrate that StateX efficiently
enhances the recall and in-context learning ability of RNNs without incurring
high post-training costs or compromising other capabilities.

</details>


### [264] [Variational Reasoning for Language Models](https://arxiv.org/abs/2509.22637)
*Xiangxin Zhou,Zichen Liu,Haonan Wang,Chao Du,Min Lin,Chongxuan Li,Liang Wang,Tianyu Pang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a variational reasoning framework for language models that
treats thinking traces as latent variables and optimizes them through
variational inference. Starting from the evidence lower bound (ELBO), we extend
it to a multi-trace objective for tighter bounds and propose a forward-KL
formulation that stabilizes the training of the variational posterior. We
further show that rejection sampling finetuning and binary-reward RL, including
GRPO, can be interpreted as local forward-KL objectives, where an implicit
weighting by model accuracy naturally arises from the derivation and reveals a
previously unnoticed bias toward easier questions. We empirically validate our
method on the Qwen 2.5 and Qwen 3 model families across a wide range of
reasoning tasks. Overall, our work provides a principled probabilistic
perspective that unifies variational inference with RL-style methods and yields
stable objectives for improving the reasoning ability of language models. Our
code is available at https://github.com/sail-sg/variational-reasoning.

</details>


### [265] [Language Models Can Learn from Verbal Feedback Without Scalar Rewards](https://arxiv.org/abs/2509.22638)
*Renjie Luo,Zichen Liu,Xiangyan Liu,Chao Du,Min Lin,Wenhu Chen,Wei Lu,Tianyu Pang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: LLMs are often trained with RL from human or AI feedback, yet such methods
typically compress nuanced feedback into scalar rewards, discarding much of
their richness and inducing scale imbalance. We propose treating verbal
feedback as a conditioning signal. Inspired by language priors in text-to-image
generation, which enable novel outputs from unseen prompts, we introduce the
feedback-conditional policy (FCP). FCP learns directly from response-feedback
pairs, approximating the feedback-conditional posterior through maximum
likelihood training on offline data. We further develop an online bootstrapping
stage where the policy generates under positive conditions and receives fresh
feedback to refine itself. This reframes feedback-driven learning as
conditional generation rather than reward optimization, offering a more
expressive way for LLMs to directly learn from verbal feedback. Our code is
available at https://github.com/sail-sg/feedback-conditional-policy.

</details>


### [266] [Death of the Novel(ty): Beyond n-Gram Novelty as a Metric for Textual Creativity](https://arxiv.org/abs/2509.22641)
*Arkadiy Saakyan,Najoung Kim,Smaranda Muresan,Tuhin Chakrabarty*

Main category: cs.CL

TL;DR: N-gram novelty is often used to evaluate language model text generation and textual creativity, but it may be inadequate as it doesn't consider creativity's dual nature: novelty and appropriateness. This paper investigates the relationship between creativity and n-gram novelty using expert annotations of human and AI-generated text. Results show that while n-gram novelty is positively associated with creativity, most n-gram novel expressions are not considered creative. Additionally, higher n-gram novelty in LLMs correlates with lower pragmaticality, unlike human writing. Frontier LLMs also struggle to identify non-pragmatic expressions, although their performance in identifying creative expressions is better than random. LLM-based novelty scores can predict expert preferences.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the adequacy of n-gram novelty as a metric for textual creativity, considering the dual nature of creativity (novelty and appropriateness) and its contrast with n-gram novelty. It also seeks to understand the relationship between n-gram novelty and expert judgments of creativity, pragmaticality, and sensicality in both human and AI-generated text. Furthermore, it examines the performance of LLMs in identifying creative and non-pragmatic expressions and assesses whether LLM-based novelty scores can predict expert preferences.

Method: The study uses 7542 expert writer annotations (n=26) to evaluate novelty, pragmaticality, and sensicality in human and AI-generated text through close reading. It analyzes the association between n-gram novelty and expert-judged creativity, and investigates the correlation between n-gram novelty and pragmaticality in open-source LLMs compared to human writing. An exploratory study with frontier close-source models is conducted to compare their creative expression generation with humans. The dataset is used to test the ability of zero-shot, few-shot, and finetuned models to identify creative and non-pragmatic expressions. Finally, the study evaluates the predictiveness of LLM-as-a-Judge novelty scores against expert writer preferences.

Result: The study found that while n-gram novelty is positively associated with expert-judged creativity, approximately 91% of top-quartile expressions by n-gram novelty are not deemed creative. For open-source LLMs, higher n-gram novelty correlates with lower pragmaticality, unlike human-written text. Frontier LLMs produce fewer creative expressions than humans. When evaluating LLMs' ability to identify creative and non-pragmatic expressions, they perform better than random but still have room for improvement, particularly in identifying non-pragmatic content. The best-performing LLM-as-a-Judge model's novelty scores were found to be predictive of expert writer preferences.

Conclusion: N-gram novelty alone is an inadequate measure of creativity. While it shows some positive association with expert-judged creativity, a vast majority of n-gram novel expressions are not considered creative. LLMs, especially open-source ones, exhibit a trade-off where increased n-gram novelty can lead to decreased pragmaticality. Frontier LLMs show limitations in generating creative content compared to humans and in identifying non-pragmatic text. However, LLM-based novelty scores show potential in aligning with human expert preferences, suggesting a possible AVENUE for improving LLM evaluation and generation.

Abstract: N-gram novelty is widely used to evaluate language models' ability to
generate text outside of their training data. More recently, it has also been
adopted as a metric for measuring textual creativity. However, theoretical work
on creativity suggests that this approach may be inadequate, as it does not
account for creativity's dual nature: novelty (how original the text is) and
appropriateness (how sensical and pragmatic it is). We investigate the
relationship between this notion of creativity and n-gram novelty through 7542
expert writer annotations (n=26) of novelty, pragmaticality, and sensicality
via close reading of human and AI-generated text. We find that while n-gram
novelty is positively associated with expert writer-judged creativity, ~91% of
top-quartile expressions by n-gram novelty are not judged as creative,
cautioning against relying on n-gram novelty alone. Furthermore, unlike
human-written text, higher n-gram novelty in open-source LLMs correlates with
lower pragmaticality. In an exploratory study with frontier close-source
models, we additionally confirm that they are less likely to produce creative
expressions than humans. Using our dataset, we test whether zero-shot,
few-shot, and finetuned models are able to identify creative expressions (a
positive aspect of writing) and non-pragmatic ones (a negative aspect).
Overall, frontier LLMs exhibit performance much higher than random but leave
room for improvement, especially struggling to identify non-pragmatic
expressions. We further find that LLM-as-a-Judge novelty scores from the
best-performing model were predictive of expert writer preferences.

</details>


### [267] [WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning](https://arxiv.org/abs/2509.22644)
*Zimu Lu,Houxing Ren,Yunqiao Yang,Ke Wang,Zhuofan Zong,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Agent systems powered by large language models (LLMs) have demonstrated
impressive performance on repository-level code-generation tasks. However, for
tasks such as website codebase generation, which depend heavily on visual
effects and user-interaction feedback, current code agents rely only on simple
code execution for feedback and verification. This approach fails to capture
the actual quality of the generated code. In this paper, we propose
WebGen-Agent, a novel website-generation agent that leverages comprehensive and
multi-level visual feedback to iteratively generate and refine the website
codebase. Detailed and expressive text descriptions and suggestions regarding
the screenshots and GUI-agent testing of the websites are generated by a visual
language model (VLM), together with scores that quantify their quality. The
screenshot and GUI-agent scores are further integrated with a backtracking and
select-best mechanism, enhancing the performance of the agent. Utilizing the
accurate visual scores inherent in the WebGen-Agent workflow, we further
introduce \textit{Step-GRPO with Screenshot and GUI-agent Feedback} to improve
the ability of LLMs to act as the reasoning engine of WebGen-Agent. By using
the screenshot and GUI-agent scores at each step as the reward in Step-GRPO, we
provide a dense and reliable process supervision signal, which effectively
improves the model's website-generation ability. On the WebGen-Bench dataset,
WebGen-Agent increases the accuracy of Claude-3.5-Sonnet from 26.4% to 51.9%
and its appearance score from 3.0 to 3.9, outperforming the previous
state-of-the-art agent system. Additionally, our Step-GRPO training approach
increases the accuracy of Qwen2.5-Coder-7B-Instruct from 38.9% to 45.4% and
raises the appearance score from 3.4 to 3.7.

</details>


### [268] [VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing](https://arxiv.org/abs/2509.22651)
*Ke Wang,Houxing Ren,Zimu Lu,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The growing capabilities of large language models and multimodal systems have
spurred interest in voice-first AI assistants, yet existing benchmarks are
inadequate for evaluating the full range of these systems' capabilities. We
introduce VoiceAssistant-Eval, a comprehensive benchmark designed to assess AI
assistants across listening, speaking, and viewing. VoiceAssistant-Eval
comprises 10,497 curated examples spanning 13 task categories. These tasks
include natural sounds, music, and spoken dialogue for listening; multi-turn
dialogue, role-play imitation, and various scenarios for speaking; and highly
heterogeneous images for viewing. To demonstrate its utility, we evaluate 21
open-source models and GPT-4o-Audio, measuring the quality of the response
content and speech, as well as their consistency. The results reveal three key
findings: (1) proprietary models do not universally outperform open-source
models; (2) most models excel at speaking tasks but lag in audio understanding;
and (3) well-designed smaller models can rival much larger ones. Notably, the
mid-sized Step-Audio-2-mini (7B) achieves more than double the listening
accuracy of LLaMA-Omni2-32B-Bilingual. However, challenges remain: multimodal
(audio plus visual) input and role-play voice imitation tasks are difficult for
current models, and significant gaps persist in robustness and safety
alignment. VoiceAssistant-Eval identifies these gaps and establishes a rigorous
framework for evaluating and guiding the development of next-generation AI
assistants. Code and data will be released at
https://mathllm.github.io/VoiceAssistantEval/ .

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [269] [Hidden Markov Model Decoding for LDPC Codes](https://arxiv.org/abs/2509.21872)
*Jan C Olivier,Etienne Barnard*

Main category: eess.SP

TL;DR: 本文提出了一种迭代隐马尔可夫模型（HMM）用于解码低密度奇偶校验（LDPC）码，并表明一阶HMM为解码器提供了自然框架。该HMM是时齐的，具有固定的转移矩阵，并基于编码帧比特的随机游走。每个隐藏状态包含两个编码比特对，奇偶校验自然地融入观测模型。通过实现隐藏状态的前向-后向平滑估计器，解码效率高且迭代次数少。结果显示，与Tanner图上的信念传播（BP）相比，LDPC解码阈值显著提高，并且在短帧长（约512比特或更少）和规整LDPC码下，LDPC码在所提解码器下的帧错误率（FER）和解码阈值可与采用SCL-CRC解码的Polar码媲美。


<details>
  <summary>Details</summary>
Motivation: 将迭代隐马尔可夫模型（HMM）应用于低密度奇偶校验（LDPC）码的解码，并展示其优越性。

Method: 提出一种迭代HMM解码器，其中每个隐藏状态包含两个编码比特，并利用前向-后向平滑估计器进行解码。

Result: 所提出的LDPC解码器相比于基于Tanner图的信念传播（BP）解码器，在解码阈值上有了显著提高。此外，在短帧长和规整LDPC码的情况下，其性能与采用SCL-CRC解码的Polar码相当。

Conclusion: 所提出的迭代HMM解码器在LDPC码解码方面表现出优越性能，尤其是在短帧长和规整码条件下，其性能可与Polar码相媲美。

Abstract: The paper proposes an iterative Hidden Markov Model (HMM) for decoding a Low
Density Parity Check (LDPC) code. It is demonstrated that a first-order HMM
provides a natural framework for the decoder. The HMM is time-homogeneous with
a fixed transition matrix and is based on a random walk through the encoded
frame bits. Each hidden state contains a pair of two encoded bits, and parity
checks are naturally incorporated into the observation model. The paper shows
that by implementing a forward-backward smoothing estimator for the hidden
states, decoding is efficient and requires only a small number of iterations in
most cases. The results show that the LDPC decoding threshold is significantly
improved compared to belief propagation (BP) on a Tanner graph. Numerical
results are presented showing that LDPC codes under the proposed decoder yield
a frame error rate (FER) and decoding threshold comparable to that of a Polar
code where Successive Cancellation List (SCL) - Cyclic Redundancy Check (CRC)
decoding is deployed. This is shown to be achieved even if the frame length is
short (on the order of $512$ bits or less) and a regular LDPC code is used. 1

</details>


### [270] [CRB minimization for PASS Assisted ISAC](https://arxiv.org/abs/2509.22181)
*Haochen Li,Ruikang Zhong,Jiayi Lei,Pan Zhiwen,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了一种多波导PASS辅助的集成传感与通信(ISAC)系统，其中基站(BS)配备了传输捏缩天线(PA)和接收均匀线性阵列(ULA)天线。基于此配置，在满足通信服务质量(QoS)约束、功率预算约束和PA部署约束的条件下，构建了目标感知Cramer Rao下界(CRB)最小化问题。


<details>
  <summary>Details</summary>
Motivation: A multiple waveguide PASS assisted integrated sensing and communication (ISAC) system is proposed, where the base station (BS) is equipped with transmitting pinching antennas (PAs) and receiving uniform linear array (ULA) antennas.

Method: An alternating optimization (AO) method is employed to address the formulated non-convex optimization problem.

Result: Simulation results demonstrate that the proposed PASS assisted ISAC framework achieves superior performance over benchmark schemes.

Conclusion: Simulation results demonstrate that the proposed PASS assisted ISAC framework achieves superior performance over benchmark schemes.

Abstract: A multiple waveguide PASS assisted integrated sensing and communication
(ISAC) system is proposed, where the base station (BS) is equipped with
transmitting pinching antennas (PAs) and receiving uniform linear array (ULA)
antennas. The PASS-transmitting-ULA-receiving (PTUR) BS transmits the
communication and sensing signals through the stretched PAs on waveguides and
collects the echo sensing signals with the mounted ULA. Based on this
configuration, a target sensing Cramer Rao Bound (CRB) minimization problem is
formulated under communication quality-of-service (QoS) constraints, power
budget constraints, and PA deployment constraints. An alternating optimization
(AO) method is employed to address the formulated non-convex optimization
problem. Simulation results demonstrate that the proposed PASS assisted ISAC
framework achieves superior performance over benchmark schemes.

</details>


### [271] [A Deep Neural Network Codebook Approach for Near-Field Nulling Control Beam Focusing](https://arxiv.org/abs/2509.22204)
*Mohammadhossein Karimi,Yuanzhe Gong,Tho Le-Ngoc*

Main category: eess.SP

TL;DR: 提出了一种用于极大规模MIMO系统近场区域的多用户干扰抑制DNN码本方法，通过划分区域并使用轻量级DNN模型，有效降低了计算复杂度，并实现了优于31.64 dB的干扰抑制。


<details>
  <summary>Details</summary>
Motivation: 现有基于DNN的空束控制波束成形方法在可扩展性和复杂度方面存在挑战，需要一种更有效的MUI抑制方法。

Method: 将信道划分为多个子区域，并为每个子区域分配一个轻量级全连接DNN模型。模型使用LCMV方法生成的波束成形权重进行训练，以预测能够优化期望信号强度并抑制干扰的空束控制波束成形权重。

Result: 平均相位和幅度预测误差分别为0.085弧度和0.52 dB。所提出的DNN码本实现了超过31.64 dB的干扰抑制，与LCMV方法相比性能差距在2 dB以内。

Conclusion: 该DNN码本方法在有效抑制MUI的同时，显著降低了计算复杂度，适用于极大规模MIMO系统近场区域的场景。

Abstract: This paper proposes a deep neural network (DNN) codebook approach for
multi-user interference (MUI) mitigation in extremely large multiple-input
multiple-output (XL-MIMO) systems operating in the near-field region. Unlike
existing DNN-based nulling control beamforming (NCBF) methods that face
scalability and complexity challenges, the proposed framework partitions the
Fresnel region using correlation-based sampling and assigns a lightweight fully
connected DNN model to each subsection. Each model is trained on beamforming
weights generated using the linearly constrained minimum variance (LCMV)
method, enabling accurate prediction of nulling control beam-focusing weights
that simultaneously optimize the desired signal strength and suppress potential
interference for both collinear and non-collinear user configurations.
Simulation results show that the trained models achieve average phase and
magnitude prediction errors of 0.085 radians and 0.52 dB, respectively, across
75 sample subsections. Full-wave simulations in Ansys HFSS further demonstrate
that the proposed DNN codebook achieves interference suppression better than
31.64 dB, with a performance gap within 2 dB of the LCMV method, thereby
validating its effectiveness in mitigating MUI while reducing computational
complexity.

</details>


### [272] [Stacked Intelligent Metasurface-Enhanced Wideband Multiuser MIMO OFDM-IM Communications](https://arxiv.org/abs/2509.22327)
*Zheao Li,Jiancheng An,Chau Yuen*

Main category: eess.SP

TL;DR: 该论文提出了一种基于OFDM-IM的SIM收发器，以解决宽带部署中的相位张量适应性和快速重构问题。通过UPGD-Net实现了可靠性优化和高精度信号处理，并在宽带多用户下行链路仿真中取得了显著的BER和和速率增益。


<details>
  <summary>Details</summary>
Motivation: 宽带部署SIM受限于单一准静态相位张量需适应所有子载波以及多用户调度导致的子载波激活模式的快速变化。

Method: 提出一种基于OFDM-IM的SIM增强宽带多用户收发器。使用最大最小化每载波SINR作为代理，解决可靠性优化问题。提出UPGD-Net，通过展开SIM层和算法迭代，计算级联预编码器的解析梯度，并采用可学习的每迭代步长。

Result: 仿真结果显示，所提出的模型收敛速度快，具有单调收敛特性，并且存在最佳层深度。在最差链路BER和和速率方面均有显著提升。

Conclusion: 结合结构稀疏性和驱动BER的深度展开优化骨干，所提出的框架有效解决了SIM在宽带应用中的关键瓶颈。

Abstract: Leveraging the multilayer realization of programmable metasurfaces, stacked
intelligent metasurfaces (SIM) enable fine-grained wave-domain control.
However, their wideband deployment is impeded by two structural factors: (i) a
single, quasi-static SIM phase tensor must adapt to all subcarriers, and (ii)
multiuser scheduling changes the subcarrier activation pattern frame by frame,
requiring rapid reconfiguration. To address both challenges, we develop a
SIM-enhanced wideband multiuser transceiver built on orthogonal
frequency-division multiplexing with index modulation (OFDM-IM). The sparse
activation of OFDM-IM confines high-fidelity equalization to the active tones,
effectively widening the usable bandwidth. To make the design
reliability-aware, we directly target the worst-link bit-error rate (BER) and
adopt a max-min per-tone signal-to-interference-plus-noise ratio (SINR) as a
principled surrogate, turning the reliability optimization tractable. For
frame-rate inference and interpretability, we propose an unfolded
projected-gradient-descent network (UPGD-Net) that double-unrolls across the
SIM's layers and algorithmic iterations: each cell computes the analytic
gradient from the cascaded precoder with a learnable per-iteration step size.
Simulations on wideband multiuser downlinks show fast, monotone convergence, an
evident layer-depth sweet spot, and consistent gains in worst-link BER and sum
rate. By combining structural sparsity with a BER-driven, deep-unfolded
optimization backbone, the proposed framework directly addresses the key
wideband deficiencies of SIM.

</details>


### [273] [Specific multi-emitter identification via multi-label learning](https://arxiv.org/abs/2509.22396)
*Yuhao Chen,Boxiang He,Shilian Wang,Jing Lei*

Main category: eess.SP

TL;DR: 该论文提出了一种基于多标签学习的多发射机识别（SMEI）方法，用于从重叠信号中识别多个发射机，并实现了与基线方法相当的识别精度和更低的复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有技术在处理重叠信号场景时存在不足，无法识别多个发射机。

Method: 提出了一种多发射机指纹提取器来减轻重叠信号间的相互干扰，然后提出了一种多发射机决策器来分配所有发射机的识别结果。

Result: 实验结果表明，与基线方法相比，所提出的SMEI方案在各种重叠条件下实现了相当的识别精度，同时复杂度显著降低。

Conclusion: 该研究成功地解决了从重叠信号中识别多个发射机的挑战，并提出了一个具有低复杂度的有效解决方案。

Abstract: Specific emitter identification leverages hardware-induced impairments to
uniquely determine a specific transmitter. However, existing approaches fail to
address scenarios where signals from multiple emitters overlap. In this paper,
we propose a specific multi-emitter identification (SMEI) method via
multi-label learning to determine multiple transmitters. Specifically, the
multi-emitter fingerprint extractor is designed to mitigate the mutual
interference among overlapping signals. Then, the multi-emitter decision maker
is proposed to assign the all emitter identification using the previous
extracted fingerprint. Experimental results demonstrate that, compared with
baseline approach, the proposed SMEI scheme achieves comparable identification
accuracy under various overlapping conditions, while operating at significantly
lower complexity. The significance of this paper is to identify multiple
emitters from overlapped signal with a low complexity.

</details>


### [274] [Approximation of the Range Ambiguity Function in Near-field Sensing Systems](https://arxiv.org/abs/2509.22423)
*Marcin Wachowiak,André Bourdoux,Sofie Pollin*

Main category: eess.SP

TL;DR: 近场系统中的范围模糊函数由带宽和近场波束聚焦共同决定，其性能增益与距离相关，并且仅在靠近阵列时才显著。


<details>
  <summary>Details</summary>
Motivation: 研究近场系统中的范围模糊函数，并分析近场波束聚焦对分辨率和模糊函数性能的改善。

Method: 推导通用匹配滤波器模糊函数，引入不同天线阵列几何的近场阵因子，并将近场模糊函数近似为距离相关近场阵因子与带宽和波形模糊函数的乘积，最后分析近场波束聚焦的改进。

Result: 提出了基于孔径带宽积的近似判据并验证了其准确性，展示了近场波束聚焦相比远场情况在分辨率、峰值旁瓣和积分旁瓣水平方面的性能提升。

Conclusion: 近场系统中的范围模糊函数受带宽和近场波束聚焦的共同影响，近场波束聚焦的性能增益与距离相关，并且仅在靠近阵列时才显著。

Abstract: This paper investigates the range ambiguity function of near-field systems
where bandwidth and near-field beamfocusing jointly determine the resolution.
First, the general matched filter ambiguity function is derived and the
near-field array factors of different antenna array geometries are introduced.
Next, the near-field ambiguity function is approximated as a product of the
range-dependent near-field array factor and the ambiguity function due to the
utilized bandwidth and waveform. An approximation criterion based on the
aperture-bandwidth product is formulated, and its accuracy is examined.
Finally, the improvements to the ambiguity function offered by the near-field
beamfocusing, as compared to the far-field case, are presented. The performance
gains are evaluated in terms of resolution improvement offered by beamfocusing,
peak-to-sidelobe and integrated-sidelobe level improvement. The gains offered
by the near-field regime are shown to be range-dependent and substantial only
in close proximity to the array.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [275] [Systematic Study of Amorphous ABC Heterostructures at the Atomic Scale as a Nonlinear Optical Metamaterial](https://arxiv.org/abs/2509.21583)
*Martin Mičulka,Jinsong Liu,Sebastian Beer,Raihan Rafi,Denys Sevriukov,Sergiy Yulin,Vladimir Roddatis,Stefan Nolte,Isabelle Staude,Andreas Tünnermann,Sven Schröder,Adriana Szeghalmi*

Main category: physics.app-ph

TL;DR: 纳米形态改性显著改善了ABC型异质结的非线性光学性质，实现了最大化的人工体二阶磁化率。


<details>
  <summary>Details</summary>
Motivation: 探索ABC型异质结的系统性，并改善其非线性光学性质以最大化人工体二阶磁化率。

Method: 通过循环等离子体增强原子层沉积三种氧化物（SiO2(A)、TiO2(B)和Al2O3(C)）制备非晶双折射异质结，有效打破了中心对称性。研究了光学非线性与三种成分材料厚度变化（从几十纳米到原子尺度）的关系，并观察到界面处的二阶磁化率。

Result: 发现非线性光学性质的增强与高密度层和优越的界面质量密切相关，其中界面二阶非线性转变为类体二次谐波产生。实现了2.0±0.2 pm/V的有效体二阶磁化率，可与传统的单晶非线性材料相媲美。

Conclusion: 纳米形态改性是提高ABC型异质结非线性光学性质的关键，通过精确控制材料厚度和界面质量，可以实现与传统材料相当的性能。

Abstract: The systematic exploration of ABC type heterostructures reveals that
nanoscale morphological modification markedly improves nonlinear optical
properties to maximize the artificial bulk second-order susceptibility. These
amorphous birefringent heterostructures are fabricated through cyclic
plasma-enhanced atomic layer deposition of three oxides, effectively breaking
centrosymmetry. We observe a dependence of optical nonlinearity on the
thickness variation of three constituent materials: SiO$_2$ (A), TiO$_2$ (B),
and Al$_2$O$_3$ (C), ranging from tens of nanometers to the atomic scale, and
these materials exhibit second-order susceptibility at their interfaces. Our
findings reveal that the enhancement of nonlinear optical properties is
strongly correlated with a high density of layers and superior interface
quality, where the interface second-order nonlinearity transitions to bulk-like
second-harmonic generation. An effective bulk second-order susceptibility of
$\chi_{zzz}\nobreakspace{}=\nobreakspace{}2.0\nobreakspace{}\pm\nobreakspace{}0.2$
pm/V is achieved, comparable to typical values for conventional monocrystalline
nonlinear materials.

</details>


### [276] [2.34 kV \b{eta}-Ga2O3 Vertical Trench RESURF Schottky Barrier Diode with sub-micron fin width](https://arxiv.org/abs/2509.21857)
*Chinmoy Nath Saha,Saurav Roy,Yizheng Liu,Carl Peterson,Sriram Krishnamoorthy*

Main category: physics.app-ph

TL;DR: 本文提出了一种亚微米沟槽宽度的β-Ga2O3垂直沟槽肖特基势垒二极管，并集成了场板结构。


<details>
  <summary>Details</summary>
Motivation: 提出一种高性能的β-Ga2O3垂直沟槽肖特基势垒二极管，以提高击穿电压和降低导通电阻。

Method: 采用TiO2和Al2O3纳米层状电介质作为RESURF电介质和场板边缘终端。利用自对准光刻胶平坦化和蚀刻回技术形成肖特基接触。

Result: 实现了2.34 kV的击穿电压，具有很低的漏电流。导通比高达10^10，比导通电阻低至9.8-12 mΩ·cm2。实现了0.867 GW/cm2的功率优值。

Conclusion: 所提出的包含RESURF效应和自对准光刻胶平坦化的混合结构，为实现高性能垂直器件提供了一种有前景的途径。

Abstract: In this letter, we present a kilovolt-class \b{eta}-Ga2O3 vertical trench
Schottky barrier diode with a field plate incorporating narrow fin width (Wfin)
structures of sub-micron dimensions. We used a nanolaminate dielectric
comprising a stack of multiple thin TiO2 and Al2O3 layers as RESURF dielectric
and for field plate edge termination. Both Wfin of 200 nm and 500 nm
demonstrate excellent on-state performance with specific on-resistance (Ron,sp)
of 9.8-12 mohmcm2, and 10^10 rectification ratio. A self-aligned photoresist
planarization and etch-back process was employed to expose the top of the fins
for Schottky contact formation, eliminating critical lithographic alignment
challenges in sub-micron scale processing. We achieved a breakdown of 2.34 kV
with very low leakage currents before catastrophic breakdown. The measured
breakdown voltage is limited by dielectric breakdown at the trench bottom
corner as verified by metal-oxide-semiconductor (MOS) test structure. TCAD
simulation shows a reduced electric field at the surface of the
metal-semiconductor junction due to the RESURF effect, resulting in very low
reverse leakage before breakdown. The parallel plane electric field in the
\b{eta} -Ga2O3 is extracted to be 3.8 MV/cm from TCAD simulations using
accurately extracted drift layer doping profile from high voltage CV
measurements. A power figure of merit of 0.867 GW/cm2(0.56 GW/cm2 with current
spreading) was calculated. Enhanced RESURF by integration of high-k dielectrics
with self-aligned photoresist planarization, offers a promising pathway towards
high figure of merit, low leakage high-performance vertical devices.

</details>


### [277] [Understanding the oxidation of pure Tungsten in air and its impact on the lifecycle of a fusion power plant](https://arxiv.org/abs/2509.22031)
*R. Li,G. Álvarez,A. Ipakchi,L. Cupertino-Malheiros,M. R. Gilbert,E. Martínez-Pañeda,E. Prestat*

Main category: physics.app-ph

TL;DR: 纯钨在400-1050°C下氧化，观察到空隙和裂缝，导致粉尘形成或氧化皮剥落，影响维护和废物处理。氧化皮具有三层结构：WO2（内层）、WO2.72（中层）和WO2.9/WO3（外层）。


<details>
  <summary>Details</summary>
Motivation: 评估纯钨氧化和氧化钨升华对聚变电站生命周期的影响。

Method: 在400-1050°C下对纯钨进行氧化，持续1-70小时，并使用电子显微镜和拉曼光谱进行表征。

Result: 在高于600°C的温度下观察到空隙和裂缝，导致粉尘形成或氧化皮剥落。氧化皮由三层组成：内层为WO2（30-50 nm），中层为WO2.72（10-20 µm），外层为WO2.9/WO3。氧化行为与抛物线-线性动力学相关，并讨论了其对氚渗透和脱氚效率的潜在影响。

Conclusion: 观察到的微观结构与抛物线-线性动力学相关，并讨论了其对氚渗透和脱氚效率的潜在影响。

Abstract: The oxidation of pure W and the sublimation of W oxide have been investigated
to assess their impact on the lifecycle of a fusion power plant. Pure W has
been oxidised at temperatures between 400 and 1050C and for durations ranging
between 1 and 70 h. The formation of voids and cracks has been observed at
temperatures above 600C, leading to the formation of dust or oxide spalling,
which could be problematic in maintenance and waste-handling scenarios of a
fusion power plant. Preferential oxidation taking place at the edge of the
specimen was characterised, and its impact is discussed in relation to
component design. Characterisation using electron microscopy and Raman
spectroscopy revealed that the oxide scale is formed of three main layers: the
inner layer is 30-50 nm thick WO2 oxide, the middle layer is a 10-20 um of
WO_2.72 and the outer layer is formed of WO2.9/WO3 phases - whose thickness
varies according to the total thickness of the oxide scale. The observed
microstructure is discussed in relation to the parabolic-to-linear kinetics and
its potential impact on tritium permeation and detritiation efficiency.

</details>


### [278] [Tunable Transmissive Metagratings Using Single Layer Cylindrical Plasma Discharges](https://arxiv.org/abs/2509.22172)
*Mohammad G. H. Alijani,Alessio Monti,Stefano Vellucci,Mirko Barbuto,Alessandro Toscano,Filiberto Bilotti*

Main category: physics.app-ph

TL;DR: 提出了一种基于等离子体放电的新型单层可重构透射超光栅。


<details>
  <summary>Details</summary>
Motivation: 为了实现对光束方向的有效控制，同时保持低反射和高功率效率。

Method: 设计了一个由两个并排的核心-壳圆柱体组成的单元格，其中包含可调的等离子体核心和高折射率介电壳。使用具有可调等离子体频率的自由电子等离子体介电常数对结构进行建模。

Result: 通过调整等离子体频率，可以将主透射波瓣在-41°、0°和41°之间切换。在宽边和转向方向上的传输效率分别保持在80%以上和90%以上。

Conclusion: 该结构实现了有效的方向控制，同时保持低反射和高整体功率效率。

Abstract: In this paper, we propose a novel single-layer reconfigurable transmissive
metagrating based on plasma discharges. Each unit-cell consists of two
side-by-side core-shell cylinders, with a tunable plasma core and a high-index
dielectric shell. The structure is modeled using a free-electron plasma
permittivity with adjustable plasma frequency. Analytical and numerical results
show that the main transmission lobe can be switched between -41{\deg}, 0{\deg}
and 41{\deg} by tuning the plasma frequencies. Transmission efficiency remains
above 80% at broadside and 90% in the steered direction. This tunability
enables effective directional control with low reflection and high overall
power efficiency.

</details>


### [279] [Optimizing Ultra-Long Continuous Wafer-Scale Periodic Poling in Thin-Film Lithium Niobate](https://arxiv.org/abs/2509.22342)
*Laura Bollmers,Noah Spiegelberg,Michael Rüsing,Christof Eigner,Laura Padberg,Christine Silberhorn*

Main category: physics.app-ph

TL;DR: TFLN晶体在量子光源和频率转换器中至关重要，但长周期性畴反转的制备具有挑战性。本研究实现了70毫米连续畴反转，并比较了连续电极和分段电极两种方法，证明了在大尺寸晶圆上实现高质量周期性畴反转的可行性，为高效非线性光学器件奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 提高量子光源和频率转换器效率的关键在于增加光与非线性材料的相互作用长度，但目前TFLN晶体长连续畴反转的制备具有挑战性，长度很少超过10毫米。

Method: 本研究比较了两种制备长连续畴反转区域的方法：1. 使用单个连续70毫米长电极进行畴反转；2. 使用分段方法，包含20多个单独部分，共同形成70毫米长的畴反转区域。

Result: 成功实现了70毫米长、3微米周期、占空比接近50%的连续畴反转区域。比较发现，连续电极方法制备速度更快，而分段方法可以单独优化每个部分的畴反转，减少占空比变化。两种方法的结果与先前报道的较短器件的畴反转结果一致。

Conclusion: 本研究在大尺寸晶圆上实现了超过芯片尺寸的周期性畴反转，且不损失畴反转质量。这为开发高效、窄带、低泵浦功率的非线性光学器件提供了关键一步。

Abstract: Periodically poled thin-film lithium niobate (TFLN) crystals are the
fundamental building block for highly-efficient quantum light sources and
frequency converters. The efficiency of these devices is strongly dependent on
the interaction length between the light and the nonlinear material, scaling
quadratically with this parameter. Nevertheless, the fabrication of long,
continuously poled areas in TFLN remains challenging, the length of
continuously poled areas rarely exceeds 10 mm. In this work, we demonstrate a
significant progress in this field achieving the periodic poling of continuous
poled areas of 70 mm length with a 3 microns poling period and a close to 50 %
duty cycle. We compare two poling electrode design approaches to fabricate
long, continuous poled areas. The first approach involves the poling of a
single, continuous 70 mm long electrode. The second utilize a segmented
approach including the poling of more than 20 individual sections forming
together a 70 mm long poling area with no stitching errors. While the
continuous electrode allows for faster fabrication, the segmented approach
allows to individually optimize the poling resulting in less duty cycle
variation. A detailed analysis of the periodic poling results reveals that the
results of both are consistent with previously reported poling outcomes for
shorter devices. Thus, we demonstrate wafer-scale periodic poling exceeding
chiplet-size without any loss in the periodic poling quality. Our work presents
a key step towards highly-efficient, narrowbandwidth and low-pump power
nonlinear optical devices.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [280] [ControlHair: Physically-based Video Diffusion for Controllable Dynamic Hair Rendering](https://arxiv.org/abs/2509.21541)
*Weikai Lin,Haoxiang Li,Yuhao Zhu*

Main category: cs.GR

TL;DR: ControlHair是一个结合物理模拟和条件视频扩散的模型，可以生成具有可控动态效果的逼真毛发。它通过物理模拟生成毛发运动，然后利用视频扩散模型生成最终视频，能够实现动态发型试穿、子弹时间效果和电影效果图等应用。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型缺乏对毛发动态的精细控制能力，而毛发模拟和渲染因其复杂的动力学、多样的材质属性和精细的光线-毛发交互而充满挑战。

Method: ControlHair采用三阶段流水线：首先使用物理模拟器将物理参数（例如，头发硬度、风力）编码为逐帧几何，然后提取逐帧控制信号，最后将控制信号输入视频扩散模型以生成具有所需毛发动力学的视频。这种级联设计将物理推理与视频生成解耦，支持各种物理效果，并简化了视频扩散模型的训练。

Result: 在10K视频数据集上训练的ControlHair，性能优于文本和姿态引导的基线模型，能够精确控制毛发动力学。

Conclusion: ControlHair是第一个用于可控动力学的物理信息视频扩散框架，为毛发模拟和渲染领域带来了新的可能性。

Abstract: Hair simulation and rendering are challenging due to complex strand dynamics,
diverse material properties, and intricate light-hair interactions. Recent
video diffusion models can generate high-quality videos, but they lack
fine-grained control over hair dynamics. We present ControlHair, a hybrid
framework that integrates a physics simulator with conditional video diffusion
to enable controllable dynamic hair rendering. ControlHair adopts a three-stage
pipeline: it first encodes physics parameters (e.g., hair stiffness, wind) into
per-frame geometry using a simulator, then extracts per-frame control signals,
and finally feeds control signals into a video diffusion model to generate
videos with desired hair dynamics. This cascaded design decouples physics
reasoning from video generation, supports diverse physics, and makes training
the video diffusion model easy. Trained on a curated 10K video dataset,
ControlHair outperforms text- and pose-conditioned baselines, delivering
precisely controlled hair dynamics. We further demonstrate three use cases of
ControlHair: dynamic hairstyle try-on, bullet-time effects, and cinemagraphic.
ControlHair introduces the first physics-informed video diffusion framework for
controllable dynamics. We provide a teaser video and experimental results on
our website.

</details>


### [281] [PowerGS: Display-Rendering Power Co-Optimization for Neural Rendering in Power-Constrained XR Systems](https://arxiv.org/abs/2509.21702)
*Weikai Lin,Sushant Kondguli,Carl Marshall,Yuhao Zhu*

Main category: cs.GR

TL;DR: PowerGS是一个创新的框架，旨在为XR设备优化3D高斯泼溅（3DGS）渲染，显著降低渲染和显示功耗，同时保持高质量的视觉效果。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅模型在功耗方面效率低下，无法满足XR设备在瓦特级别功耗限制下的需求。

Method: PowerGS通过联合优化渲染和显示功耗，并引入支持注视点渲染的技术来实现节能。该框架通过识别等质量曲线并找到曲线上的最小功耗点来解决问题。

Result: 实验和用户研究表明，与最先进的3DGS模型相比，PowerGS可实现高达86%的总功耗降低，同时保持可忽略的视觉质量损失。

Conclusion: PowerGS是首个能在保证视觉质量的前提下，为3DGS渲染和显示功耗进行联合优化的框架，为XR设备带来了显著的节能优势。

Abstract: 3D Gaussian Splatting (3DGS) combines classic image-based rendering,
pointbased graphics, and modern differentiable techniques, and offers an
interesting alternative to traditional physically-based rendering. 3DGS-family
models are far from efficient for power-constrained Extended Reality (XR)
devices, which need to operate at a Watt-level. This paper introduces PowerGS,
the first framework to jointly minimize the rendering and display power in 3DGS
under a quality constraint. We present a general problem formulation and show
that solving the problem amounts to 1) identifying the iso-quality curve(s) in
the landscape subtended by the display and rendering power and 2) identifying
the power-minimal point on a given curve, which has a closed-form solution
given a proper parameterization of the curves. PowerGS also readily supports
foveated rendering for further power savings. Extensive experiments and user
studies show that PowerGS achieves up to 86% total power reduction compared to
state-of-the-art 3DGS models, with minimal loss in both subjective and
objective quality. Code is available at
https://github.com/horizon-research/PowerGS.

</details>


### [282] [Rigidity-Aware 3D Gaussian Deformation from a Single Image](https://arxiv.org/abs/2509.22222)
*Jinhyeok Kim,Jaehun Bang,Seunghyun Seo,Kyungdon Joo*

Main category: cs.GR

TL;DR: DeformSplat是一个新框架，仅用单张图像即可重建3D高斯变形，解决了多视图依赖的限制，并通过高斯到像素匹配和刚性部件分割来保持几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的从单张图像重建物体变形的方法存在局限性，通常需要多视图视频，限制了其在约束场景下的应用。

Method: 提出DeformSplat框架，包含两个主要技术贡献：1. 高斯到像素匹配，用于连接3D高斯表示和2D像素观测之间的域差距，从而从稀疏视觉线索中获得鲁棒的变形引导。2. 刚性部件分割，包括初始化和细化，用于显式识别刚性区域，以在变形过程中保持几何一致性。

Result: 实验证明，DeformSplat在仅用单张图像重建一致性变形方面表现优于现有方法，并可应用于帧插值和交互式物体操作等多种场景。

Conclusion: DeformSplat框架成功实现了仅用单张图像从3D高斯变形重建，通过引入高斯到像素匹配和刚性部件分割，解决了现有方法的局限性，并在各种应用中展现出优越性能。

Abstract: Reconstructing object deformation from a single image remains a significant
challenge in computer vision and graphics. Existing methods typically rely on
multi-view video to recover deformation, limiting their applicability under
constrained scenarios. To address this, we propose DeformSplat, a novel
framework that effectively guides 3D Gaussian deformation from only a single
image. Our method introduces two main technical contributions. First, we
present Gaussian-to-Pixel Matching which bridges the domain gap between 3D
Gaussian representations and 2D pixel observations. This enables robust
deformation guidance from sparse visual cues. Second, we propose Rigid Part
Segmentation consisting of initialization and refinement. This segmentation
explicitly identifies rigid regions, crucial for maintaining geometric
coherence during deformation. By combining these two techniques, our approach
can reconstruct consistent deformations from a single image. Extensive
experiments demonstrate that our approach significantly outperforms existing
methods and naturally extends to various applications,such as frame
interpolation and interactive object manipulation.

</details>


### [283] [Aerial Path Planning for Urban Geometry and Texture Co-Capture](https://arxiv.org/abs/2509.22227)
*Weidan Xiong,Bochuan Zeng,Ziyu Hu,Jianwei Guo,Ke Xie,Hui Huang*

Main category: cs.GR

TL;DR: 本文提出了一种在仅了解建筑轮廓和安全飞行高度的限制条件下，通过优化航拍路径规划来同时获取高质量三维模型几何和纹理的方法，以解决现有技术中纹理质量不高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有城市三维重建技术在获取几何信息方面取得了进展，但忽视了纹理质量，导致模型出现视觉瑕疵。

Method: 提出了一种新颖的航拍路径规划框架，用于在仅输入2D建筑轮廓图和安全飞行高度的情况下，协同获取用于几何和纹理重建的图像。引入了包括针对建筑立面的新颖指标在内的综合纹理质量评估体系。生成了高质量的垂直俯视和水平平面视图，并提出了一种多目标优化策略，以联合提高纹理保真度、几何精度并降低成本。此外，还提出了一种考虑纹理一致性的顺序路径规划算法。

Result: 实验证明，该方法能够生成适用于几何和纹理并发重建的图像集，从而以较低的运营成本创建逼真的纹理场景代理。

Conclusion: 所提出的方法能够有效解决城市三维模型纹理质量不高的问题，实现几何和纹理的协同重建，并能适应有限的先验知识条件。

Abstract: Recent advances in image acquisition and scene reconstruction have enabled
the generation of high-quality structural urban scene geometry, given
sufficient site information. However, current capture techniques often overlook
the crucial importance of texture quality, resulting in noticeable visual
artifacts in the textured models. In this work, we introduce the urban geometry
and texture co-capture problem under limited prior knowledge before a site
visit. The only inputs are a 2D building contour map of the target area and a
safe flying altitude above the buildings. We propose an innovative aerial path
planning framework designed to co-capture images for reconstructing both
structured geometry and high-fidelity textures. To evaluate and guide view
planning, we introduce a comprehensive texture quality assessment system,
including two novel metrics tailored for building facades. Firstly, our method
generates high-quality vertical dipping views and horizontal planar views to
effectively capture both geometric and textural details. A multi-objective
optimization strategy is then proposed to jointly maximize texture fidelity,
improve geometric accuracy, and minimize the cost associated with aerial views.
Furthermore, we present a sequential path planning algorithm that accounts for
texture consistency during image capture. Extensive experiments on large-scale
synthetic and real-world urban datasets demonstrate that our approach
effectively produces image sets suitable for concurrent geometric and texture
reconstruction, enabling the creation of realistic, textured scene proxies at
low operational cost.

</details>


### [284] [Learning to Ball: Composing Policies for Long-Horizon Basketball Moves](https://arxiv.org/abs/2509.22442)
*Pei Xu,Zhen Wu,Ruocheng Wang,Vishnu Sarukkai,Kayvon Fatahalian,Ioannis Karamouzas,Victor Zordan,C. Karen Liu*

Main category: cs.GR

TL;DR: 本研究提出了一种新颖的策略集成框架，用于组合多阶段长时任务中的不同运动技能，并引入了一个高层软路由器来实现子任务之间的无缝、鲁棒过渡，解决了现有方法在策略组合和技能过渡方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理多阶段长时任务（如篮球动作）时面临挑战，主要是因为策略组合和技能过渡的无缝性难以实现，尤其是在任务的不同阶段之间存在目标不明确但至关重要的过渡子任务时。

Method: 提出了一种新颖的策略集成框架，并引入了一个高层软路由器，以实现多阶段长时任务中截然不同运动技能的组合以及子任务之间的无缝、鲁棒过渡，特别是在中间状态定义不明确的情况下。

Result: 所提出的框架在模拟的篮球技能和具有挑战性的过渡任务上进行了评估，证明了其有效性。训练后的策略能够有效地控制模拟角色与球进行交互，并根据实时用户指令完成指定的长时任务，且无需依赖球的轨迹参考。

Conclusion: 本研究提出的策略集成框架和软路由器能够有效地解决多阶段长时任务中的策略组合和技能过渡问题，尤其是在中间状态定义不明确的情况下，为强化学习在复杂任务中的应用提供了新的解决方案。

Abstract: Learning a control policy for a multi-phase, long-horizon task, such as
basketball maneuvers, remains challenging for reinforcement learning approaches
due to the need for seamless policy composition and transitions between skills.
A long-horizon task typically consists of distinct subtasks with well-defined
goals, separated by transitional subtasks with unclear goals but critical to
the success of the entire task. Existing methods like the mixture of experts
and skill chaining struggle with tasks where individual policies do not share
significant commonly explored states or lack well-defined initial and terminal
states between different phases. In this paper, we introduce a novel policy
integration framework to enable the composition of drastically different motor
skills in multi-phase long-horizon tasks with ill-defined intermediate states.
Based on that, we further introduce a high-level soft router to enable seamless
and robust transitions between the subtasks. We evaluate our framework on a set
of fundamental basketball skills and challenging transitions. Policies trained
by our approach can effectively control the simulated character to interact
with the ball and accomplish the long-horizon task specified by real-time user
commands, without relying on ball trajectory references.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [285] [Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow](https://arxiv.org/abs/2509.21789)
*Xinlei Yu,Chengming Xu,Guibin Zhang,Yongbo He,Zhangquan Chen,Zhucun Xue,Jiangning Zhang,Yue Liao,Xiaobin Hu,Yu-Gang Jiang,Shuicheng Yan*

Main category: cs.MA

TL;DR: 多智能体系统（MAS）中的视觉幻觉问题，即一个智能体的幻觉被后续智能体放大，导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型（VLMs）在多智能体系统（MAS）中存在的视觉幻觉雪球效应问题。

Method: 通过分析注意力机制，识别出能够保留视觉信息的关键视觉标记（relay tokens），并提出ViF框架，通过视觉流和注意力重新分配来缓解幻觉雪球效应。

Result: ViF框架能够显著减少幻觉雪球效应，在八个基准测试和多种MAS结构及基础模型上均能提升性能。

Conclusion: ViF是一种轻量级、即插即用的方法，有效解决了MAS中的视觉幻觉雪球效应，并提升了模型在多项任务上的表现。

Abstract: Multi-Agent System (MAS) powered by Visual Language Models (VLMs) enables
challenging tasks but suffers from a novel failure term, multi-agent visual
hallucination snowballing, where hallucinations are seeded in a single agent
and amplified by following ones due to the over-reliance on textual flow to
relay visual information. Through turn-, layer-, and token-wise attention
analyses, we provide detailed insights into the essence of hallucination
snowballing regarding the reduction of visual attention allocation. It leads us
to identify a subset of vision tokens with a unimodal attention peak in middle
layers that best preserve visual evidence but gradually diminish in deeper
agent turns, resulting in the visual hallucination snowballing in MAS. Thus, we
propose ViF, a lightweight, plug-and-play mitigation paradigm that relays
inter-agent messages with Visual Flow powered by the selected visual relay
tokens and applies attention reallocation to amplify this pattern. The
experiment results demonstrate that our method markedly reduces hallucination
snowballing, consistently improving the performance across eight benchmarks
based on four common MAS structures and ten base models. The source code will
be available at: https://github.com/YU-deep/ViF.git.

</details>


### [286] [RobustFlow: Towards Robust Agentic Workflow Generation](https://arxiv.org/abs/2509.21834)
*Shengxiang Xu,Jiayi Zhang,Shimin Di,Yuyu Luo,Liang Yao,Hanmo Liu,Jia Zhu,Fan Liu,Min-Ling Zhang*

Main category: cs.MA

TL;DR: 当前自动化生成的代理工作流存在鲁棒性差的问题，即使输入相同的指令但措辞略有不同，也会导致工作流生成不一致。为解决此问题，研究者提出了新的评估指标来量化工作流不一致性，并提出了一种名为RobustFlow的训练框架，通过偏好优化来训练模型对指令变化的鲁棒性，显著提高了工作流的稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前研究中，自动化生成的代理工作流在面对指令的细微语义变化时，鲁棒性不足，生成结果不一致，这严重影响了其在现实世界应用中的可靠性和可信度。

Method: 提出基于节点和拓扑相似性的指标来量化评估工作流在面对释义和噪声注入等语义变化时的不一致性。在此基础上，提出了一种名为RobustFlow的新颖训练框架，利用偏好优化（PO）技术，通过在同义任务描述集合上进行训练，来增强模型对指令变化的适应能力。

Result: RobustFlow框架能够将工作流的鲁棒性分数提高到70%-90%，相比现有方法有了显著提升。

Conclusion: RobustFlow框架通过引入新的评估指标和创新的训练方法，有效解决了自动化生成代理工作流的鲁棒性问题，显著提升了其在面对指令变化时的稳定性和可靠性，为LLMs在复杂任务中的应用提供了更可靠的解决方案。

Abstract: The automated generation of agentic workflows is a promising frontier for
enabling large language models (LLMs) to solve complex tasks. However, our
investigation reveals that the robustness of agentic workflow remains a
critical, unaddressed challenge. Current methods often generate wildly
inconsistent workflows when provided with instructions that are semantically
identical but differently phrased. This brittleness severely undermines their
reliability and trustworthiness for real-world applications. To quantitatively
diagnose this instability, we propose metrics based on nodal and topological
similarity to evaluate workflow consistency against common semantic variations
such as paraphrasing and noise injection. Subsequently, we further propose a
novel training framework, RobustFlow, that leverages preference optimization to
teach models invariance to instruction variations. By training on sets of
synonymous task descriptions, RobustFlow boosts workflow robustness scores to
70\% - 90\%, which is a substantial improvement over existing approaches. The
code is publicly available at https://github.com/DEFENSE-SEU/RobustFlow.

</details>


### [287] [Multi-Agent Path Finding via Offline RL and LLM Collaboration](https://arxiv.org/abs/2509.22130)
*Merve Atasever,Matthew Hong,Mihir Nitin Kulkarni,Qingpei Li,Jyotirmoy V. Deshmukh*

Main category: cs.MA

TL;DR: 本研究提出了一种基于决策转换器（DT）的高效去中心化路径规划框架，并结合大型语言模型（GPT-4o）以提高在动态环境中的适应性，解决了多智能体路径寻找（MAPF）中的碰撞和训练耗时问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体路径寻找（MAPF）在机器人和物流领域至关重要，但面临组合复杂性和部分可观测性挑战。现有的去中心化强化学习方法常导致代理行为自我中心、频繁碰撞，且通信模块导致训练时间过长。

Method: 提出一个基于决策转换器（DT）的去中心化规划框架，利用离线强化学习缩短训练时间。为解决适应性问题，集成大型语言模型（GPT-4o）动态指导代理策略。

Result: 该方法将训练时间从数周缩短至数小时，有效处理长时信用分配和稀疏/延迟奖励问题。实验证明，DT框架结合GPT-4o在静态和动态环境中均显著提升了适应性和性能。

Conclusion: 基于DT的MAPF框架，并利用GPT-4o进行动态策略指导，是一种高效且适应性强的解决方案，能够克服传统方法的局限性。

Abstract: Multi-Agent Path Finding (MAPF) poses a significant and challenging problem
critical for applications in robotics and logistics, particularly due to its
combinatorial complexity and the partial observability inherent in realistic
environments. Decentralized reinforcement learning methods commonly encounter
two substantial difficulties: first, they often yield self-centered behaviors
among agents, resulting in frequent collisions, and second, their reliance on
complex communication modules leads to prolonged training times, sometimes
spanning weeks. To address these challenges, we propose an efficient
decentralized planning framework based on the Decision Transformer (DT),
uniquely leveraging offline reinforcement learning to substantially reduce
training durations from weeks to mere hours. Crucially, our approach
effectively handles long-horizon credit assignment and significantly improves
performance in scenarios with sparse and delayed rewards. Furthermore, to
overcome adaptability limitations inherent in standard RL methods under dynamic
environmental changes, we integrate a large language model (GPT-4o) to
dynamically guide agent policies. Extensive experiments in both static and
dynamically changing environments demonstrate that our DT-based approach,
augmented briefly by GPT-4o, significantly enhances adaptability and
performance.

</details>


### [288] [Impact of Collective Behaviors of Autonomous Vehicles on Urban Traffic Dynamics: A Multi-Agent Reinforcement Learning Approach](https://arxiv.org/abs/2509.22216)
*Ahmet Onur Akman,Anastasia Psarou,Zoltán György Varga,Grzegorz Jamróz,Rafał Kucharski*

Main category: cs.MA

TL;DR: RL-enabled AVs in mixed traffic impact urban flow, with effects varying by AV behavior.


<details>
  <summary>Details</summary>
Motivation: Examine the impact of RL-enabled autonomous vehicles (AVs) on urban traffic flow in a mixed traffic environment using a day-to-day route choice problem in a multi-agent setting.

Method: Converted one-third of human drivers to RL agents (Deep Q-learning) with defined behaviors (selfish, collaborative, competitive, social, altruistic, malicious) imposed through rewards. Simulations were run using the PARCOUR framework.

Result: AVs optimized travel times by up to 5%, with varying impacts on human drivers' travel times depending on AV behavior. Selfish AVs achieved shorter travel times than human drivers in all cases. Complexity differences in learning tasks for each behavior were observed.

Conclusion: Multi-agent RL is applicable for collective routing on traffic networks, but its impact on coexisting parties varies greatly with the behaviors adopted by AVs.

Abstract: This study examines the potential impact of reinforcement learning
(RL)-enabled autonomous vehicles (AV) on urban traffic flow in a mixed traffic
environment. We focus on a simplified day-to-day route choice problem in a
multi-agent setting. We consider a city network where human drivers travel
through their chosen routes to reach their destinations in minimum travel time.
Then, we convert one-third of the population into AVs, which are RL agents
employing Deep Q-learning algorithm. We define a set of optimization targets,
or as we call them behaviors, namely selfish, collaborative, competitive,
social, altruistic, and malicious. We impose a selected behavior on AVs through
their rewards. We run our simulations using our in-house developed RL framework
PARCOUR. Our simulations reveal that AVs optimize their travel times by up to
5\%, with varying impacts on human drivers' travel times depending on the AV
behavior. In all cases where AVs adopt a self-serving behavior, they achieve
shorter travel times than human drivers. Our findings highlight the complexity
differences in learning tasks of each target behavior. We demonstrate that the
multi-agent RL setting is applicable for collective routing on traffic
networks, though their impact on coexisting parties greatly varies with the
behaviors adopted.

</details>


### [289] [VizGen: Data Exploration and Visualization from Natural Language via a Multi-Agent AI Architecture](https://arxiv.org/abs/2509.22218)
*Sandaru Fernando,Imasha Jayarathne,Sithumini Abeysekara,Shanuja Sithamparanthan,Thushari Silva,Deshan Jayawardana*

Main category: cs.MA

TL;DR: VizGen是一个AI辅助的图表生成系统，用户可以使用自然语言创建数据可视化，它能将用户查询转化为SQL，推荐图表类型，并进行数据分析和解释，从而降低数据可视化的技术门槛。


<details>
  <summary>Details</summary>
Motivation: 传统的数据可视化工具需要专业知识，限制了用户的使用。VizGen旨在通过自然语言交互，使数据可视化更易于访问和使用。

Method: VizGen利用自然语言处理（NLP）和大型语言模型（LLM）将用户查询转换为SQL，并推荐合适的图表类型。它采用多代理架构，处理SQL生成、图表创建、定制和洞察提取，并能与SQL数据库实时交互，支持对话式图表优化，同时通过互联网搜索丰富解释信息。

Result: VizGen能够生成数据可视化图表，进行数据模式、异常和相关性分析，并提供带有上下文信息的解释，使用户更容易理解数据。

Conclusion: VizGen通过AI技术，使用户能够通过自然语言轻松创建和理解数据可视化，从而实现数据分析的民主化。

Abstract: Data visualization is essential for interpreting complex datasets, yet
traditional tools often require technical expertise, limiting accessibility.
VizGen is an AI-assisted graph generation system that empowers users to create
meaningful visualizations using natural language. Leveraging advanced NLP and
LLMs like Claude 3.7 Sonnet and Gemini 2.0 Flash, it translates user queries
into SQL and recommends suitable graph types. Built on a multi-agent
architecture, VizGen handles SQL generation, graph creation, customization, and
insight extraction. Beyond visualization, it analyzes data for patterns,
anomalies, and correlations, and enhances user understanding by providing
explanations enriched with contextual information gathered from the internet.
The system supports real-time interaction with SQL databases and allows
conversational graph refinement, making data analysis intuitive and accessible.
VizGen democratizes data visualization by bridging the gap between technical
complexity and user-friendly design.

</details>


### [290] [Effective Policy Learning for Multi-Agent Online Coordination Beyond Submodular Objectives](https://arxiv.org/abs/2509.22596)
*Qixin Zhang,Yan Sun,Can Jin,Xikun Zhang,Yao Shu,Puning Zhao,Li Shen,Dacheng Tao*

Main category: cs.MA

TL;DR: 本文提出了两种用于多智能体在线协调（MA-OC）问题的策略学习算法：MA-SPL 和 MA-MPL。MA-SPL 算法可处理具有亚模目标、弱DR-亚模和弱亚模目标的情况，并达到最优的 (1-c/e) 近似保证。MA-MPL 算法是无参数的，并保持了与 MA-SPL 相同的近似比。这两种算法的核心是“基于策略的连续扩展”技术，它优于“多线性扩展”，能够处理弱亚模目标。最后通过仿真验证了算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体在线协调（MA-OC）问题，并提出能够处理亚模目标、弱DR-亚模和弱亚模目标，且具有最优近似保证的算法。同时，为了消除对未知参数的依赖，提出一种无参数的算法。

Method: 提出“基于策略的连续扩展”技术，并基于此开发了两种在线算法：MA-SPL 和 MA-MPL。MA-SPL 算法可处理不同的亚模函数，MA-MPL 算法则消除了对未知参数的依赖。

Result: MA-SPL 算法在处理具有亚模目标、弱DR-亚模和弱亚模目标时，达到了最优的 (1-c/e) 近似保证。MA-MPL 算法在保持相同近似比的同时，完全消除了对未知参数的依赖。通过广泛的模拟实验验证了算法的有效性。

Conclusion: 本文提出的基于“基于策略的连续扩展”技术的 MA-SPL 和 MA-MPL 算法，在多智能体在线协调问题上取得了显著的成果，特别是在处理弱亚模目标和消除参数依赖方面具有优势。

Abstract: In this paper, we present two effective policy learning algorithms for
multi-agent online coordination(MA-OC) problem. The first one, \texttt{MA-SPL},
not only can achieve the optimal $(1-\frac{c}{e})$-approximation guarantee for
the MA-OC problem with submodular objectives but also can handle the unexplored
$\alpha$-weakly DR-submodular and $(\gamma,\beta)$-weakly submodular scenarios,
where $c$ is the curvature of the investigated submodular functions, $\alpha$
denotes the diminishing-return(DR) ratio and the tuple $(\gamma,\beta)$
represents the submodularity ratios. Subsequently, in order to reduce the
reliance on the unknown parameters $\alpha,\gamma,\beta$ inherent in the
\texttt{MA-SPL} algorithm, we further introduce the second online algorithm
named \texttt{MA-MPL}. This \texttt{MA-MPL} algorithm is entirely
\emph{parameter-free} and simultaneously can maintain the same approximation
ratio as the first \texttt{MA-SPL} algorithm. The core of our \texttt{MA-SPL}
and \texttt{MA-MPL} algorithms is a novel continuous-relaxation technique
termed as \emph{policy-based continuous extension}. Compared with the
well-established \emph{multi-linear extension}, a notable advantage of this new
\emph{policy-based continuous extension} is its ability to provide a lossless
rounding scheme for any set function, thereby enabling us to tackle the
challenging weakly submodular objectives. Finally, extensive simulations are
conducted to validate the effectiveness of our proposed algorithms.

</details>


### [291] [Voting-Bloc Entropy: A New Metric for DAO Decentralization](https://arxiv.org/abs/2509.22620)
*Andrés Fábrega,Amy Zhao,Jay Yu,James Austgen,Sarah Allen,Kushal Babel,Mahimna Kelkar,Ari Juels*

Main category: cs.MA

TL;DR: DAO 的去中心化程度可以通过一种名为投票-集团熵（VBE）的新框架来衡量，该框架考虑了具有相似利益的选民的集中效应。


<details>
  <summary>Details</summary>
Motivation: 现有的 DAO 去中心化定义未能充分捕捉多样化和公平参与的关键特征。

Method: 提出一种基于效用函数相似性的新颖框架 VBE，并推导出一个基于强化学习的投票概念模型。

Result: VBE 的理论分析揭示了投票委托、提案捆绑和贿赂等因素对去中心化影响的见解，这些见解被先前的定义所忽略。此外，还进行了实证研究和治理实验，以展示 VBE 的应用。

Conclusion: VBE 提供了一种更精确的 DAO 去中心化度量方法，并为增强 DAO 的去中心化提供了实用的建议，同时提供开源工具以供进一步研究。

Abstract: Decentralized Autonomous Organizations (DAOs) use smart contracts to foster
communities working toward common goals. Existing definitions of
decentralization, however -- the 'D' in DAO -- fall short of capturing the key
properties characteristic of diverse and equitable participation. This work
proposes a new framework for measuring DAO decentralization called Voting-Bloc
Entropy (VBE, pronounced ''vibe''). VBE is based on the idea that voters with
closely aligned interests act as a centralizing force and should be modeled as
such. VBE formalizes this notion by measuring the similarity of participants'
utility functions across a set of voting rounds. Unlike prior, ad hoc
definitions of decentralization, VBE derives from first principles: We
introduce a simple (yet powerful) reinforcement learning-based conceptual model
for voting, that in turn implies VBE. We first show VBE's utility as a
theoretical tool. We prove a number of results about the (de)centralizing
effects of vote delegation, proposal bundling, bribery, etc. that are
overlooked in previous notions of DAO decentralization. Our results lead to
practical suggestions for enhancing DAO decentralization. We also show how VBE
can be used empirically by presenting measurement studies and VBE-based
governance experiments. We make the tools we developed for these results
available to the community in the form of open-source artifacts in order to
facilitate future study of DAO decentralization.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [292] [Interpretable Spectral Features Predict Conductivity in Self-Driving Doped Conjugated Polymer Labs](https://arxiv.org/abs/2509.21330)
*Ankush Kumar Mishra,Jacob P. Mauthe,Nicholas Luke,Aram Amassian,Baskar Ganapathysubramanian*

Main category: cond-mat.mtrl-sci

TL;DR: 利用光学光谱和机器学习预测掺杂共轭聚合物的电导率，通过自动化特征提取和模型训练，减少实验成本并提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 预测昂贵、难以测量的性质（如电导率）是材料发现中的一个关键挑战，尤其是在自动化和机器学习的背景下。

Method: 结合遗传算法（GA）和面积下面积（AUC）计算，从光学光谱中提取数据驱动的谱学特征。然后，将这些特征与处理参数一起用于训练定量结构-性质关系（QSPR）模型。为了提高小样本量下的准确性和可解释性，还引入了基于领域知识的特征扩展，并使用SHAP进行特征选择。

Result: 数据驱动模型在保持与专家定义的描述符相当的性能的同时，将实验工作量减少了约33%。混合QSPR模型（结合数据驱动和专家特征）表现出更优越的预测性能。学习到的特征恢复了pBTTT中的已知描述符，并发现了一个与掺杂成功期间聚合物漂白相关的尾态区域。

Conclusion: 该方法提供了一种可解释、鲁棒、适用于小样本的特征提取方法，能够将快速测量转化为对昂贵性质的可靠预测，并易于扩展到其他光谱模式。

Abstract: Self-driving labs (SDLs) promise faster materials discovery by coupling
automation with machine learning, but a central challenge is predicting costly,
slow-to-measure properties from inexpensive, automatable readouts. We address
this for doped conjugated polymers by learning interpretable spectral
fingerprints from optical spectroscopy to predict electrical conductivity.
Optical spectra are fast, non-destructive, and sensitive to aggregation and
charge generation; we automate their featurization by combining a genetic
algorithm (GA) with area-under-the-curve (AUC) computations over adaptively
selected spectral windows. These data-driven spectral features, together with
processing parameters, are used to train a quantitative structure-property
relationship (QSPR) linking optical response and processing to conductivity. To
improve accuracy and interpretability in the small-data regime, we add
domain-knowledge-based feature expansions and apply SHAP-guided selection to
retain a compact, physically meaningful feature set. The pipeline is evaluated
under a leak-free train/test protocol, and GA is repeated to assess feature
stability. The data-driven model matches the performance of a baseline built
from expert-curated descriptors while reducing experimental effort (about 33%)
by limiting direct conductivity measurements. Combining data-driven and expert
features yields a hybrid QSPR with superior predictive performance,
highlighting productive human-ML collaboration. The learned features recover
known descriptors in pBTTT (0-0/0-1 vibronic intensity ratio) and reveal a
tail-state region correlated with polymer bleaching during successful doping.
This approach delivers interpretable, noise-robust, small-data-friendly
features that convert rapid measurements into reliable predictions of costly
properties and readily extends to other spectral modalities (e.g., XANES,
Raman, FTIR).

</details>


### [293] [Strain-tunability of the multipolar Berry curvature in altermagnet MnTe](https://arxiv.org/abs/2509.21481)
*Shane Smolenski,Ning Mao,Dechen Zhang,Yucheng Guo,A. K. M. Ashiquzzaman Shawon,Mingyu Xu,Eoghan Downey,Trisha Musall,Ming Yi,Weiwei Xie,Chris Jozwiak,Aaron Bostwick,Nobumichi Tamura,Eli Rotenberg,Lu Li,Kai Sun,Yang Zhang,Na Hyun Jo*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究在MnTe中通过单轴应力调控了反常霍尔效应，首次证实了交替磁体的多极贝里曲率，并实现了其可逆操控。


<details>
  <summary>Details</summary>
Motivation: 探索交替磁体中多极贝里曲率的性质及其可控性，因为这对于理解和利用反常霍尔效应至关重要。

Method: 通过施加单轴应力来改变MnTe晶体的对称性，并测量反常霍尔电导率的变化。结合对称性分析和密度泛函理论计算来解释实验结果。

Result: 发现反常霍尔电导率的大小随应变而变化，并在0.14%的临界应变下符号发生反转。证明了这种可调性源于交替磁体多极贝里曲率。

Conclusion: 证实了MnTe中存在多极贝里曲率，并通过单轴应力实现了其可逆调控，为理解和设计具有贝里曲率调控特性的新材料提供了新的方向。

Abstract: The anomalous Hall effect describes the generation of a transverse voltage by
a longitudinal current even in the absence of an external magnetic field. While
typically observed in ferromagnets, it has also been predicted to arise in
altermagnets, materials characterized by rotational symmetries that enable
broken time reversal symmetry despite compensated collinear magnetic ordering.
These symmetries enforce band (anti)crossings that can generate significant
contributions to the Berry curvature that drives the anomalous Hall effect.
This Berry curvature is predicted to exhibit a characteristic multipolar order,
resulting in a symmetry-enforced distribution at or near net compensation which
is highly sensitive to perturbations that distort this balance. However,
exploring the predicted multipolar Berry curvature of altermagnets and its
reversible manipulation remains challenging. Here, we demonstrate evidence for
the multipolar nature of the altermagnetic Berry curvature in MnTe by tuning
the anomalous Hall effect via uniaxial stress. Upon straining, the magnitude of
the anomalous Hall conductivity changes and, at a critical strain of 0.14%, the
sign is reversed. Symmetry analysis and density functional theory calculations
reveal that this tunability is a direct consequence of the altermagnetic
multipolar Berry curvature. Our results provide insight into the role of
crystal and magnetic symmetries in the realization of higher-order Berry
curvature distributions and their unique tunability.

</details>


### [294] [Anisotropy of the chiral, semiconducting phase LaRhC$_{2}$: a handedness resolved study](https://arxiv.org/abs/2509.21510)
*Volodymyr Levytskyi,Ulrich Burkhardt,Markus König,Christoph Hennig,Eteri Svanidze,Yuri Grin,Roman Gumeniuk*

Main category: cond-mat.mtrl-sci

TL;DR: LaRhC2是一种具有手性晶体结构的化合物，具有独特的电子、磁性和光学性质，但其手性对其电学性质的影响仍有待探索。本研究通过电子背散射衍射和聚焦离子束技术，成功分离和表征了LaRhC2的单一手性外消旋体，并测量了其电导率、磁阻和热膨胀系数。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索手性对外消旋体在同一材料中的行为，并深入研究手性对LaRhC2电学性质的影响，特别是电导率、磁阻和热膨胀系数。

Method: 采用电子背散射衍射技术识别和分离LaRhC2的单一手性外消旋体，并结合单晶X射线衍射进行验证。通过聚焦离子束技术从多晶样品中提取出单一外消旋体样品，用于分析其电学性质。测量了电导率、磁阻和热膨胀系数，并与能带结构计算结果进行了比较。

Result: LaRhC2被确定为一种半导体材料，其带隙在平行和垂直于晶体结构四重螺旋轴的方向上分别为20 meV和33 meV。在热膨胀、电阻率以及平行和垂直于[001]晶体方向的角依赖磁阻方面，均观察到显著的各向异性。

Conclusion: LaRhC2是一种具有手性晶体结构的半导体材料，其电学和热学性质表现出显著的各向异性。该研究为理解手性对外消旋体在量子材料中的影响提供了新的见解。

Abstract: Chirality in quantum materials is a topic of significant importance due to
its profound effects on the electronic, magnetic, and optical properties of
these systems. However, it is non-trivial to decouple the behavior of two
enantiomorphs within the same material -- perhaps explaining why the influence
of chirality on electrical properties has remained largely unexplored. In this
work, we examine the electrical conductivity, magnetoresistance, and thermal
expansion coefficient of LaRhC$_{2}$ -- a compound with a chiral crystal
structure (tetragonal symmetry, space groups $\textit{P}$4$_{1}$ or
$\textit{P}$4$_{3}$). The identification of a suitable monochiral domain was
achieved via electron backscatter diffraction, which simultaneously determines
crystallographic orientation and handedness. Both enantiomorphs are confirmed
by single-crystal X-ray diffraction on monochiral specimens. The analysis of
electrical resistivity was made possible through the single-domain extraction
of enantiopure specimens from a polycrystalline sample using focused ion beam
techniques. We establish that LaRhC$_{2}$ is a semiconductor with band gaps of
approximately 20 meV and 33 meV parallel and perpendicular to the fourfold
screw axis of the crystal structure, respectively -- consistent with band
structure calculations. A significant anisotropy is also observed in the
thermal expansion, electrical resistivity as well as angular-dependent
magnetoresistance parallel and perpendicular o [001] crystallographic
directions.

</details>


### [295] [Multiferroicity of oxygen-deficient Hf$_x$Zr$_{1-x}$O$_{2-y}$ nanoparticles](https://arxiv.org/abs/2509.21621)
*Anna N. Morozovska,Andrii V. Bodnaruk,Oleksandr S. Pylypchuk,Denis O. Stetsenko,Andrii D. Yaremkevich,Oksana V. Leshchenko,Victor N. Pavlikov,Yuri O. Zagorodniy,Lesya P. Yurchenko,Lesya Demchenko,Myroslav V. Karpets,Olena M. Fesenko,Victor V. Vainberg,Eugene A. Eliseev*

Main category: cond-mat.mtrl-sci

TL;DR: 超小尺寸(5-10 nm)HfₓZr₁₋ₓO₂₋<0xE1><0xB5><0xA7>纳米粒子表现出超顺磁性，这归因于近地表处的氧空位。这些纳米粒子还可能表现出铁电特性和巨大的介电常数(>10³-10⁵)，这与超顺电状态有关。这些发现为制造具有超顺磁和超顺电特性的硅兼容多铁性材料开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 研究超小尺寸HfₓZr₁₋ₓO₂₋<0xE1><0xB5><0xA7>纳米粒子的超顺磁性和潜在铁电特性，旨在探索其作为先进电子器件材料的可能性。

Method: 通过固态有机硝酸盐合成法制备HfₓZr₁₋ₓO₂₋<0xE1><0xB5><0xA7>纳米粒子，并使用拉曼光谱、元素分析、X射线衍射、Landau-Ginzburg-Devonshire方法、密度泛函理论计算和介电测量等手段进行表征和分析。

Result: 观察到HfₓZr₁₋ₓO₂₋<0xE1><0xB5><0xA7>纳米粒子具有超顺磁性响应，并确定这与近地表处的氧空位有关。X射线衍射显示主要为斜方相。Landau-Ginzburg-Devonshire方法、密度泛函理论计算和介电测量表明这些纳米粒子可能具有铁电特性和巨大的介电常数(>10³-10⁵)，静态相对介电常数甚至超过10⁶，这与超顺电状态有关。

Conclusion: 氧缺陷的HfₓZr₁₋ₓO₂₋<0xE1><0xB5><0xA7>纳米粒子同时具有超顺磁和超顺电特性，这为制造硅兼容多铁性材料以及作为先进FETs和电子逻辑元件所需的超高k纳米材料提供了基础。

Abstract: We observed a superparamagnetic-type response of ultra-small (5 - 10 nm in
size) Hf$_x$Zr$_{1-x}$O$_{2-y}$ nanoparticles prepared by the solid-state
organonitrate synthesis. The Raman spectra indicate the decisive role of
surface defects, presumably oxygen vacancies, for all studied x = 1, 0.6, 0.5,
0.4 and significant degree "y" of oxygen deficiency. At the same time elemental
analysis did not reveal any noticeable concentration of magnetic impurities in
theHf$_x$Zr$_{1-x}$O$_{2-y}$ nanopowders, and the X-ray diffraction analysis
reveals the dominant presence (from 87 to 96 wt. %) of the orthorhombic phase.
Therefore, the superparamagnetic response of the nanoparticles is explained by
the appearance of magnetic state of oxygen vacancies accumulated near their
surface. The Landau-Ginzburg-Devonshire approach, density functional theory
calculations and dielectric measurements reveal that the studied ultra-small
Hf$_x$Zr$_{1-x}$O$_{2-y}$ nanoparticles may have ferroelectric-like properties
and giant dielectric permittivity (> 10^3 - 10^5) in the frequency range 4 Hz -
10 kHz. In this work we observed that the static relative dielectric
permittivity of the Hf$_x$Zr$_{1-x}$O$_{2-y}$ nanopowders overcomes 10^6 and
related the colossal values with the superparaelectric states of the
ultra-small cores of the nanoparticles.Thus, obtained results open the way for
the creation of silicon-compatible multiferroics - oxygen-deficient
Hf$_x$Zr$_{1-x}$O$_{2-y}$ nanoparticles with the superparamagnetic and
superparaelectric properties, indispensable ultra-high k nanomaterials for
advanced FETs and electronic logic elements.

</details>


### [296] [Charge, heat, and spin transport phenomena in metallic conductors](https://arxiv.org/abs/2509.21635)
*Nynke Vlietstra,Sebastian T. B. Goennenwein,Rudolf Gross,Hans Huebl*

Main category: cond-mat.mtrl-sci

TL;DR: 固体材料中电化学势、温度或自旋化学势的梯度驱动电荷、热量和自旋角动量的流动，从而实现能量的净传输。本文对这些现象进行了分类和讨论。


<details>
  <summary>Details</summary>
Motivation: 建立一个系统性的分类和比较，对固体材料中的电荷、热量和自旋传输现象进行梳理。

Method: 将输运现象分为三类：共线、横向和平面输运效应，并进行分类和讨论。

Result: 对固体材料中的电荷、热量和自旋输运现象进行了系统的分类和概述。

Conclusion: 本文提供了一个关于固体材料中各种输运现象的教学概述，对共线、横向和平面输运效应进行了分类和讨论。

Abstract: In solid state materials, gradients of the electro-chemical potential, the
temperature, or the spin-chemical potential drive the flow of charge, heat, and
spin angular momentum, resulting in a net transport of energy. Beyond the
primary transport processes - such as the flow of charge, heat, and spin
angular momentum driven by gradients in their respective potentials - a wide
range of coupled or cross-linked transport responses can occur, giving rise to
a rich variety of transport phenomena. These transport phenomena are commonly
categorized under (anomalous) thermoelectric, thermomagnetic, and
galvanomagnetic effects, along with their spin-dependent counterparts. However,
establishing a systematic classification and comparison among them remains a
complex and nontrivial task. This paper attempts a didactic overview of the
different transport phenomena, by categorizing and briefly discussing each of
them based on charge, heat, and spin transport in conducting solids. The
phenomena are structured in three categories: collinear, transverse, and
so-called `planar' transport effects. The resulting overview attempts to
categorize all effects in a consistent manner.

</details>


### [297] [Automated Machine Learning Pipeline for Training and Analysis Using Large Language Models](https://arxiv.org/abs/2509.21647)
*Adam Lahouari,Jutta Rogal,Mark E. Tuckerman*

Main category: cond-mat.mtrl-sci

TL;DR: 自动化机器学习流程（AMLP）可以简化机器学习势能（MLIP）的开发，实现从数据集创建到模型验证的自动化，并取得与密度泛函理论（DFT）相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 机器学习势能（MLIP）虽然能扩展分子模拟的范围，但其开发过程复杂，需要高质量数据集、结构预处理以及模型训练和验证。本研究旨在通过引入一个自动化流程来解决这些挑战。

Method: 本研究提出一个名为AML P（Automated Machine Learning Pipeline）的自动化机器学习流程，该流程整合了从数据集创建到模型验证的整个工作流。AML P利用大型语言模型（LLM）代理来辅助电子结构代码的选择、输入准备和输出转换，并结合ASE（Atomic Simulation Environment）支持的AMLP-Analysis进行分子模拟分析。该流程基于MACE架构构建。

Result: 在对嘧啶同质多晶进行验证时，通过对基础模型进行简单的微调，AML P实现了约1.7 meV/atom的能量均方根误差和约7.0 meV/Å的力均方根误差。所拟合的MLIP能够以亚埃（sub-Å）精度重现DFT的几何结构，并在微正则和正则系综的分子动力学模拟中表现出稳定性。

Conclusion: AML P自动化流程显著简化了MLIP的开发，能够生成高精度、高稳定性的MLIP，在嘧啶同质多晶的案例中，其性能与DFT相当，且计算成本更低。

Abstract: Machine learning interatomic potentials (MLIPs) have become powerful tools to
extend molecular simulations beyond the limits of quantum methods, offering
near-quantum accuracy at much lower computational cost. Yet, developing
reliable MLIPs remains difficult because it requires generating high-quality
datasets, preprocessing atomic structures, and carefully training and
validating models. In this work, we introduce an Automated Machine Learning
Pipeline (AMLP) that unifies the entire workflow from dataset creation to model
validation. AMLP employs large-language-model agents to assist with
electronic-structure code selection, input preparation, and output conversion,
while its analysis suite (AMLP-Analysis), based on ASE supports a range of
molecular simulations. The pipeline is built on the MACE architecture and
validated on acridine polymorphs, where, with a straightforward fine-tuning of
a foundation model, mean absolute errors of ~1.7 meV/atom in energies and ~7.0
meV/{\AA} in forces are achieved. The fitted MLIP reproduces DFT geometries
with sub-{\AA} accuracy and demonstrates stability during molecular dynamics
simulations in the microcanonical and canonical ensembles.

</details>


### [298] [Direct Deoxygenation of Phenol over Fe-based Bimetallic Surfaces using On-the-fly Surrogate Models](https://arxiv.org/abs/2509.21678)
*Isaac Onyango,Qiang Zhu*

Main category: cond-mat.mtrl-sci

TL;DR: 使用基于高斯过程回归（GPR）的加速模拟研究了铁基双金属表面苯酚直接脱氧（DDO）反应的机理，发现亚表层Co和Ni取代有利于DDO反应，而表层取代则不利于该反应。


<details>
  <summary>Details</summary>
Motivation: 为了研究苯酚直接脱氧（DDO）在铁基双金属表面的反应机理，并为设计选择性脱氧催化剂提供指导。

Method: 采用加速的 the nudged elastic band (NEB) 方法，并结合了高斯过程回归（GPR）计算器，系统地研究了在Fe(110)表面及其顶部和亚表层掺杂Co和Ni时的DDO反应机理。

Result: 研究结果表明，亚表层掺杂Co和Ni可以保持有利的热力学和动力学条件，有利于C-O键断裂和C-H键形成，其效果与纯Fe(110)表面相当。然而，表层掺杂会增加C-O键断裂的能垒，使反应变为吸热，并显著提高反向反应速率，从而使DDO反应在该表面上变得不利。

Conclusion: GPR加速的过渡态搜索对于复杂的表面反应是有效的，并且亚表层掺杂Co和Ni可以作为设计用于选择性脱氧的有效双金属催化剂。

Abstract: We present an accelerated nudged elastic band (NEB) study of phenol direct
deoxygenation (DDO) on Fe-based bimetallic surfaces using a recently developed
Gaussian process regression (GPR) calculator. Our test calculations demonstrate
that the GPR calculator achieves up to 3x speedup compared to conventional
density functional theory (DFT) calculations while maintaining high accuracy,
with energy barrier errors below 0.015 eV. Using GPR-NEB, we systematically
examine the DDO mechanism on pristine Fe(110) and surfaces modified with Co and
Ni in both top and subsurface layers. Our results show that subsurface Co and
Ni substitutions preserve favorable thermodynamics and kinetics for both C-O
bond cleavage and C-H bond formation, comparable to those on the pristine
Fe(110) surface. In contrast, top-layer substitutions generally increase the
C-O bond cleavage barrier, render the step endothermic, and result in
significantly higher reverse reaction rates, making DDO unfavorable on these
surfaces. This work demonstrates both the effectiveness of GRR-accelerated
transition state searches for complex surface reactions and provides insights
into rational design of bimetallic catalysts for selective deoxygenation.

</details>


### [299] [Scalable Foundation Interatomic Potentials via Message-Passing Pruning and Graph Partitioning](https://arxiv.org/abs/2509.21694)
*Lingyu Kong,Jaeheon Shim,Guoxiang Hu,Victor Fung*

Main category: cond-mat.mtrl-sci

TL;DR: 通过修剪和分布式计算加速原子结构模型（AFMs）在分子动力学模拟中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的原子结构模型（AFMs）虽然精度高，但推理速度慢且内存占用大，限制了其在大规模分子动力学（MD）模拟中的应用。

Method: 提出了一种通用工作流程，通过移除低贡献的消息传递层来修剪AFM骨干网络，并结合图分区和GPU分布式策略来加速和扩展模型。

Result: 修剪后的模型参数量显著减少，同时保持了AFM的精度和数据效率。该方法支持单GPU和多GPU上百万原子的模拟，并在纳秒时间尺度上实现了AFM级别的精度。

Conclusion: 通过修剪和分布式计算相结合的方法，可以有效加速和扩展AFMs在包括大规模模拟在内的各种任务中的应用，克服了现有AFM的局限性。

Abstract: Atomistic foundation models (AFMs) have great promise as accurate interatomic
potentials, and have enabled data-efficient molecular dynamics simulations with
near quantum mechanical accuracy. However, AFMs remain markedly slower at
inference and are far more memory-intensive than conventional interatomic
potentials, due to the need to capture a wide range of chemical and structural
motifs in pre-training datasets requiring deep, parameter-rich model
architectures. These deficiencies currently limit the practical use of AFMs in
molecular dynamics (MD) simulations at extended temporal and spatial scales. To
address this problem, we propose a general workflow for accelerating and
scaling AFMs containing message-passing architectures. We find that removing
low-contribution message-passing layers from AFM backbones serves as an
effective pruning method, significantly reducing the parameter count while
preserving the accuracy and data-efficiency of AFMs. Once pruned, these models
become more accessible for large scale simulations via a graph-partitioned,
GPU-distributed strategy, which we implement and demonstrate within the AFM
fine-tuning platform MatterTune. We show that this approach supports
million-atom simulations on both single and multiple GPUs, and enables
task-specific large-scale simulations at nanosecond timescales with AFM-level
accuracy.

</details>


### [300] [Strain-Induced Antiferromagnetic-to-Altermagnetic Phase Transition and Topology in $(\mathrm{CrO}_2)_1/(\mathrm{TaO}_2)_2$ Superlattice](https://arxiv.org/abs/2509.21741)
*Wanfei Shan,Qun Yang,Prineha Narang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在(CrO2)1/(TaO2)2金红石超晶格中施加0.5%的c轴单轴应变，将其从平庸的反铁磁体转变为具有拓扑特性的易磁体，并伴随弱SOC，实现了近1.1 eV的自旋相关带分裂，产生了10^3 S/cm量级的本征反常霍尔电导率，并产生了16个Weyl点，为应变和场可调、低耗损易磁性电子学提供了一条简单途径。


<details>
  <summary>Details</summary>
Motivation: 探索拓扑方面在易磁体中的应用，并提出将反铁磁体转变为易磁体相的方法。

Method: 使用第一性原理计算，研究了在(CrO2)1/(TaO2)2金红石超晶格中施加单轴应变对磁性和拓扑性质的影响。

Result: 发现0.5%的c轴单轴应变可以将(CrO2)1/(TaO2)2金红石超晶格从平庸的反铁磁体转变为易磁体，产生约1.1 eV的自旋相关带分裂，并产生10^3 S/cm量级的本征反常霍尔电导率，同时产生了16个Weyl点。

Conclusion: 提出了一种通过应变和磁场调控、低耗损的易磁性电子学实现途径。

Abstract: Topological aspects in altermagnets have come into focus recently, and tuning
the antiferromagnetic (AFM) state into an altermagnetic phase remains an active
frontier. We realize both within a rutile superlattice here in this paper. With
first principles calculation, we show that a uniaxial strain of only 0.5$\%$
along the c axis converts the $(\mathrm{CrO}_2)_1/(\mathrm{TaO}_2)_2$ rutile
superlattice from a trivial antiferromagnet into an altermagnet with topology
accompanied by a weak SOC. The strain opens a spin-dependent band splitting of
$\sim 1.1 eV$ and, despite the weak SOC together with in-plane magnetic moment
orientation, generates an intrinsic anomalous Hall conductivity of order $10^3
S/cm$, comparable magnitude to that in ferromagnetic Weyl semimetals. Tiny SOC
here with in-plane \(\text{N\'eel}\) orientation gaps out the Weyl nodal rings,
giving rise to 16 Weyl points in the superlattice. Thus, we point out a simple
route toward strain and field tunable, low-dissipation altermagnetic
electronics.

</details>


### [301] [Beyond Structure: Invariant Crystal Property Prediction with Pseudo-Particle Ray Diffraction](https://arxiv.org/abs/2509.21778)
*Bin Cao,Yang Liu,Longhan Zhang,Yifan Wu,Zhixun Li,Yuyu Luo,Hong Cheng,Yang Ren,Tong-Yi Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: PRDNet combines graph representations with reciprocal-space diffraction patterns to improve crystal property prediction, outperforming existing models.


<details>
  <summary>Details</summary>
Motivation: Traditional density functional theory is computationally expensive for large systems, and current machine learning models struggle to capture long-range atomic interactions due to limitations in their representations, leading to inaccurate property predictions.

Method: PRDNet incorporates reciprocal-space diffraction patterns alongside graph representations. It uses a data-driven pseudo-particle to generate synthetic diffraction patterns, enhancing sensitivity to variations, and ensures invariance to crystallographic symmetries.

Result: PRDNet achieves state-of-the-art performance on Materials Project, JARVIS-DFT, and MatBench datasets.

Conclusion: PRDNet, by integrating reciprocal-space diffraction with graph-based methods and ensuring symmetry invariance, offers a more effective approach for crystal property prediction compared to existing models.

Abstract: Crystal property prediction, governed by quantum mechanical principles, is
computationally prohibitive to solve exactly for large many-body systems using
traditional density functional theory. While machine learning models have
emerged as efficient approximations for large-scale applications, their
performance is strongly influenced by the choice of atomic representation.
Although modern graph-based approaches have progressively incorporated more
structural information, they often fail to capture long-term atomic
interactions due to finite receptive fields and local encoding schemes. This
limitation leads to distinct crystals being mapped to identical
representations, hindering accurate property prediction. To address this, we
introduce PRDNet that leverages unique reciprocal-space diffraction besides
graph representations. To enhance sensitivity to elemental and environmental
variations, we employ a data-driven pseudo-particle to generate a synthetic
diffraction pattern. PRDNet ensures full invariance to crystallographic
symmetries. Extensive experiments are conducted on Materials Project,
JARVIS-DFT, and MatBench, demonstrating that the proposed model achieves
state-of-the-art performance.

</details>


### [302] [Beyond Seamless: Unexpected Defective Merging in Single-Orientation Graphene](https://arxiv.org/abs/2509.21908)
*Zhien Wang,Jiangtao Wang,Diego Exposito,Andrey Krayev,Shih-Ming He,Xudong Zheng,Zachariah Hennighausen,Ivan Brihuega,Se-Young Jeong,Jing Kong*

Main category: cond-mat.mtrl-sci

TL;DR: 单晶铜/蓝宝石衬底上生长的石墨烯在取向缝合时会出现重叠连接结构，导致缺陷并允许水渗透，这与传统观念相悖，但为分子筛等应用提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 探索单晶铜/蓝宝石衬底上生长的单晶石墨烯的缝合行为，特别是挑战其无缝连续的传统观念。

Method: 通过实验观察单晶铜/蓝宝石衬底上生长的石墨烯，重点关注单取向石墨烯片之间的融合行为。

Result: 发现了两种主要的融合行为：一种是预期的无缝缝合，另一种则产生结构缺陷，形成允许水渗透的纳米通道。特别观察到一种独特的重叠连接结构，其中一个石墨烯片的边缘覆盖在另一个石墨烯片的边缘之上。

Conclusion: 单取向缝合的石墨烯薄膜并非总是无缝的，存在重叠连接等结构缺陷，这挑战了传统观点，但为分子筛、选择性过滤膜和保护涂层等应用提供了新的可能性。

Abstract: Single-orientation stitching of graphene has emerged as the predominant
method for growth of large-area, high-quality graphene films. Particularly
noteworthy is graphene grown on single-crystalline Cu(111)/sapphire substrates,
which exhibits exceptionally planar oriented stitching due to the atomically
smooth substrate, facilitating the formation of continuous, high-quality
graphene monolayer. These single-orientation stitches have conventionally been
regarded as seamless with negligible defect concentrations. In this report, we
present experimental observations regarding graphene grown on
single-crystalline Cu(111)/sapphire substrates. Among the graphene flakes with
single-orientation, our findings reveal two major merging behaviors: one
producing the expected seamless stitching, and another unexpectedly generating
structural defects that create nanoscale pathways permitting water permeation.
Notably, we identify a unique merging structure--overlapped junction, in which
the edge of one graphene flake overlaps and lies atop the edge of another
flake, rather than forming a continuous atomic stitch. This discovery
challenges the conventional anticipation of single-orientation stitched
graphene films as seamless single crystalline film, while offers unique
perspective for graphene applications in molecular sieving, selective
filtration membranes, and protective coatings.

</details>


### [303] [Modeling the Equilibrium Vacancy Concentration in Multi-Principal Element Alloys from First-Principles](https://arxiv.org/abs/2509.21944)
*Damien K. J. Lee,Yann L. Müller,Anirudh Raju Natarajan*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种结合嵌入式团簇展开（eCE）和统计力学方法的高效计算策略，用于确定多主元合金（MPEAs）中随成分和温度变化的平衡空位浓度。


<details>
  <summary>Details</summary>
Motivation: 多主元合金（MPEAs）因其优异性能备受关注，但计算其平衡空位浓度因成分空间大和局部环境复杂而面临挑战。

Method: 采用第一性原理计算与蒙特卡洛模拟相结合，并利用嵌入式团簇展开（eCE）方法来连接电子结构计算与平衡空位浓度。

Result: 研究展示了该方法在九元MPEA上的应用，分析了合金化学、短程有序与平衡空位浓度之间的关系，发现难熔合金的空位浓度随第4族元素或混合不稳定的元素的加入而增加。

Conclusion: 研究提出了一种计算MPEAs中空位行为的高效计算框架，为设计具有可控空位浓度的复杂浓合金提供了指导。

Abstract: Multi-principal element alloys (MPEAs), also known as high-entropy alloys,
have garnered significant interest across many applications due to their
exceptional properties. Equilibrium vacancy concentrations in MPEAs influence
diffusion and microstructural stability in these alloys. However, computing
vacancy concentrations from ab-initio methods is computationally challenging
due to the vast compositional space of MPEAs and the complexity of the local
environment around each vacancy. In this work, we present an efficient approach
to connect electronic structure calculations to equilibrium vacancy
concentrations in MPEAs through embedded cluster expansions (eCE) and rigorous
statistical mechanics methods. Using first-principles calculations and Monte
Carlo simulations informed by eCE, we assess the variation in vacancy formation
with alloy composition and temperature. Our method is demonstrated on a
nine-component MPEA comprised of elements in groups 4, 5, and 6 of the periodic
table. Correlations between alloy chemistry, short-range order, and equilibrium
vacancy concentrations in alloys containing up to 9 different elements are
analyzed. The vacancy concentration of refractory alloys increases with the
addition of group 4 elements or elements whose mixing is energetically
unfavorable. The insights into vacancy behavior and the efficient computational
framework presented in this study serve as a guide for the design of complex
concentrated alloys with controlled vacancy concentrations.

</details>


### [304] [Challenges and opportunities in proximity-driven exciton-spin engineering in van der Waals heterostructures](https://arxiv.org/abs/2509.21956)
*Mushir Thodika,Dimitar Pashov,Igor Zutic,Mark van Schilfgaarde,Swagata Acharya*

Main category: cond-mat.mtrl-sci

TL;DR: van der Waals 异质结构（TMDs 和 2D 磁体）为研究不同激子的共存和转变提供了平台。通过研究 WSe2/CrI3 和 CrI3/WSe2/CrI3，我们使用无参数、高保真的多体微扰理论进行了描述，阐明了 CrI3 中磁性 Frenkel 激子的特性以及 WSe2 中非磁性 Wannier-Mott 激子如何被 CrI3 邻近所改变。我们揭示了这些异质结构中新颖的邻近诱导层间激子。与 WSe2 中激子的邻近诱导修改的敏感性不同，层间磁性激子非常稳健，并且存在于 WSe2 和 CrI3 之间的不同堆叠配置中，这简化了它们的实验演示。这些发现为利用磁性激子进行信息转换以及在邻近材料中集成光子学、电子学和自旋电子学提供了新的机会。


<details>
  <summary>Details</summary>
Motivation: 研究由二维磁体和过渡金属硫族化合物（TMDs）组成的范德华异质结构，以探索不同激子的共存和转变。

Method: 使用无参数、高保真的多体微扰理论来描述双层 WSe2/CrI3 和三层 CrI3/WSe2/CrI3 异质结构。

Result: 揭示了 CrI3 中的磁性 Frenkel 激子以及 WSe2 中的非磁性 Wannier-Mott 激子如何被 CrI3 邻近所改变。发现了新颖的邻近诱导层间激子。层间磁性激子在不同堆叠配置中表现出鲁棒性。

Conclusion: 邻近诱导的层间磁性激子在 WSe2/CrI3 和 CrI3/WSe2/CrI3 异质结构中非常稳健，为信息转换和集成光子学、电子学和自旋电子学提供了新的机遇。

Abstract: van der Waals heterostructures consisting of transition metal dichalcogenides
(TMDs) and two-dimensional (2D) magnets offer a versatile platform to study the
coexistence and transformation of different excitons. By focusing on TMD
WSe$_2$ and 2D magnetic CrI$_3$, as a bilayer WSe$_2$/CrI$_3$ and a trilayer
CrI$_3$/WSe$_2$/CrI$_3$, we provide their description using a parameter-free,
high-fidelity many-body perturbation theory. This ab initio approach allows us
to elucidate the character of magnetic Frenkel excitons in CrI3 and how the
nonmagnetic Wannier-Mott excitons in WSe2 are modified by the proximity of
CrI3. We reveal novel proximity-induced interlayer excitons in these
heterostructures. In contrast to the sensitivity of proximity-induced
modifications of excitons in WSe$_2$, which depend on the interfacial details,
the interlayer magnetic excitons are remarkably robust and are present across
the different stacking configurations between WSe$_2$ and CrI$_3$, simplifying
their experimental demonstration. These findings suggest unexplored
opportunities for information transduction using magnetic excitons and
integrating photonics, electronics, and spintronics in proximitized materials.

</details>


### [305] [Electric-field effect on spin diffusion length in solids: An \textit{ab initio} study beyond the drift-diffusion model](https://arxiv.org/abs/2509.21962)
*Junqing Xu,Weiwei Chen*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究扩展了先前开发的自洽自旋扩散长度计算方法，考虑了电场引起的漂移效应，并应用于多种二维和三维材料，结果表明电场对自旋扩散长度有显著影响，且传统漂移扩散模型在某些材料中不够准确。


<details>
  <summary>Details</summary>
Motivation: 先前开发的自洽自旋扩散长度计算方法需要扩展以包含电场效应，并验证其在不同材料上的准确性。

Method: 通过在線性化密度矩陣主方程中加入漂移项，并使用基于Wannier表示的协变导数来处理周期方向上的电场效应，将先前的方法扩展到包含电场。

Result: 研究表明，在WSe2、GaAs、GaN和石墨烯-h-BN异质结构中，中等强度的电场可以显著增强或抑制自旋扩散长度。传统漂移扩散模型在GaN和石墨烯-h-BN中引入了较大误差，而石墨烯-h-BN中的电场效应还受到非费米-狄拉克分布的影响。

Conclusion: 为了准确模拟电场对自旋扩散长度的影响，必须采用微观的自洽方法，超越传统的漂移扩散模型。

Abstract: Recently, we developed an \textit{ab initio} approach of spin diffusion
length (l_{s}) in solids [Phys. Rev. Lett. 135, 046705 (2025)], based on a
linearized density-matrix master equation with quantum treatment of electron
scattering processes. In this work, we extend the method to include the drift
term due to an electric field along a periodic direction, implemented
efficiently using a Wannier-representation-based covariant derivative. We
employ this approach to investigate the electric-field effect on l_{s} of
monolayer WSe_{2}, bulk GaAs, bulk GaN, and graphene-h-BN heterostructure. Our
results show that l_{s} can be significantly enhanced or suppressed by a
moderate downstream or upstream field respectively. Although the widely-used
drift-diffusion model performs well for WSe_{2} and GaAs, it can introduce
large errors of the electric-field-induced changes of l_{s} in both GaN and
graphene-h-BN. Thus, to accurately capture the influence of electric fields on
l_{s} in realistic materials, it is necessary to go beyond the drift-diffusion
model and adopt a microscopic \textit{ab initio} methodology. Moreover, in
graphene-h-BN, we find that the field-induced change of l_{s} is not only
governed by the drift term in the master equation, but is also significantly
affected by the electric-field modification of the equilibrium density matrix
away from Fermi-Dirac distribution function.

</details>


### [306] [Carrier-phonon decoupling via annealing enhances thermoelectric performance of Bi2(Te,Se)3](https://arxiv.org/abs/2509.21977)
*Xinxiu Cheng,Liqing Xu,Zhibin Gao,Wei Liu,Zhanxiang Yin,Xiangdong Ding,Yu Xiao*

Main category: cond-mat.mtrl-sci

TL;DR: 通过熔炼-热压-退火处理（MT-HP-AN）制备的Bi2Te2.6Se0.4在室温附近表现出优异的热电性能，ZT峰值达到1.06，平均ZT为0.99，为热电冷却提供了有前景的n型BTS材料。


<details>
  <summary>Details</summary>
Motivation: 开发高性能热电材料以实现高效的室温热电冷却。

Method: 采用熔炼-热压-退火（MT-HP-AN）方法合成Bi2Te2.6Se0.4，其中退火步骤（723 K，100 h）通过Te(Se)挥发引入阳离子空位，降低载流子密度并提高迁移率，同时增强声子散射。

Result: MT-HP-AN处理后的Bi2Te2.6Se0.4在373 K时达到1.06的ZT峰值，在300-423 K温度范围内平均ZT为0.99。

Conclusion: MT-HP-AN方法是一种简单有效的方法，可以解耦载流子和声子的传输，从而提高n型Bi2Te2.6Se0.4在热电冷却应用中的性能。

Abstract: Thermoelectric cooling based on the Peltier effect requires high-performance
materials near room temperature. In this work, Bi2Te2.6Se0.4 synthesized by
melting-hot pressing followed by 100 h annealing (MT-HP-AN) at 723 K exhibits
markedly improved performance. Annealing introduces cation vacancies via Te(Se)
volatilization, lowering carrier density and enhancing mobility, while
simultaneously increasing phonon scattering. A peak ZT of 1.06 at 373 K and an
average ZT of 0.99 at 300-423 K are achieved. This MT-HP-AN approach offers a
simple yet effective strategy to decouple carrier and phonon transport,
advancing the potential of n-type BTS for thermo-electric cooling applications.

</details>


### [307] [An empirical potential to simulate helium and hydrogen in highly irradiated tungsten](https://arxiv.org/abs/2509.22012)
*Samanyu Tirumala,Daniel R. Mason,Oliver Shattock,Duc Nguyen-Manh,Felix Hofmann,Max Boleininger*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种用于钨、氢和氦之间相互作用的快速 EAM 势，该势可用于模拟商业 D-T 聚变反应堆中材料在辐照和等离子体暴露下的行为。


<details>
  <summary>Details</summary>
Motivation: 商业 D-T 聚变反应堆中的材料将暴露在辐照以及氦和氢等离子体的混合物中，需要进行大规模分子动力学模拟来模拟此类材料的微观结构演变。

Method: 开发了一种用于钨、氢和氦之间相互作用的快速 EAM 势，并使用该势对包含光气的小型缺陷簇的从头形成能和弛豫体积进行了精确拟合。在此基础上，构建了一个用于预测充气空腔能量学的热力学模型，并通过分子动力学模拟进行了验证。

Result: 开发了一种新的 W-H-He EAM 势，并使用该势成功模拟了充气空腔的形成和演变。

Conclusion: 新开发的 W-H-He EAM 势能够准确地模拟聚变反应堆条件下钨材料的微观结构演变，为相关材料的研究提供了有力的工具。

Abstract: Materials used in commercial D-T fusion reactors will be exposed to
irradiation and a mixture of helium and hydrogen plasma. Modeling the
microstructural evolution of such materials requires the use of large-scale
molecular dynamics simulations. The focus of this study is to develop a fast
EAM potential for the interactions among the three elements (W, H, and He),
fitted to accurately reproduce both the ab initio formation energies and
relaxation volumes of small defect clusters containing light gases within
tungsten. The potential enables the study of tungsten under irradiation and in
the presence of light gases. To demonstrate the utility of the potential, we
construct a thermodynamically motivated model for predicting the energetics of
light-gas-filled voids. The model is then validated through molecular dynamics
simulations with our new potential.

</details>


### [308] [Molecular Dynamics Simulations of Collision Cascades in Niobium: Comparing Interatomic Potentials](https://arxiv.org/abs/2509.22183)
*S. Mondal,U. Bhardwaj,A. Majalee,V. Mishra,M. Warrier*

Main category: cond-mat.mtrl-sci

TL;DR: 铌在 1-75 keV PKA 能量下，300 K 温度下，使用四种不同的原子间势（EAM、FS-1、FS-2、SNAP）进行了分子动力学模拟，以研究其辐照损伤响应。模拟结果显示，所有势能模型都能复制级联形成的基本特征，但在缺陷产生、聚集和形态方面存在显著差异。低能量下，缺陷产生受限于置换阈值能 (TDE) 和刚度-范围比 (|S/R|)；高能量下，亚级联的形成使得缺陷演化与 |S/R|、平均 TDE 和其他材料特定因素相关。研究发现，在所有情况下，空位聚集均超过间隙原子聚集，其中 EAM 产生最大的空位聚集体和最高的聚集分数，而 SNAP 则表现出最强的间隙原子聚集。形态学分析表明，EAM 形成了 1/2<111>、1/2<110> 环、C15 环和混合结构的平衡组合；FS-2 倾向于生成扩展的 1/2<111> 哑铃、克劳迪昂和位错环；而 FS-1 和 SNAP 则产生了更紧凑或无序的聚集体，其中 SNAP 产生了高比例的 C15 类环（最大尺寸可达九个原子），这些环可能演化为 1/2<111> 和 <100> 位错环。这些发现为了解铌在辐照（尤其是在高能量下）下的反应提供了清晰的见解。


<details>
  <summary>Details</summary>
Motivation: 辐照损伤是先进核能系统中结构材料面临的主要挑战，而铌因其高熔点、机械强度和耐腐蚀性而备受关注。为了更好地理解铌的辐照响应，需要进行详细的模拟研究。

Method: 使用分子动力学模拟，在 300 K 温度下，对纯铌在 1-75 keV 的初级碰撞原子 (PKA) 能量范围内进行碰撞级联模拟。采用了四种不同的原子间势：嵌入原子模型 (EAM)、两种 Finnis-Sinclair 模型 (FS-1 和 FS-2) 以及一个新开发的基于机器学习的谱近邻分析势 (SNAP)。

Result: 所有四种势能模型在模拟的碰撞级联中都表现出相似的宏观特征，但它们在缺陷产生数量、缺陷聚集行为（空位聚集与间隙原子聚集的比例）和缺陷形态（例如，形成的位错环的类型和尺寸）方面存在显著差异。EAM 模拟产生了最多的空位聚集体和最高的空位聚集分数，而 SNAP 模拟则产生了最多的间隙原子聚集体。SNAP 模拟还产生了高比例的 C15 类环，这可能是演化为特定位错环的前体。

Conclusion: 不同的原子间势模型会显著影响铌在碰撞级联模拟中产生的缺陷的细节，包括缺陷的数量、聚集方式和空间形态。这些差异对于准确预测铌在核反应堆等辐照环境中的长期行为至关重要。SNAP 模型尤其显示出在模拟缺陷形成和演化方面的独特行为，特别是 C15 类环的形成，这可能为理解高能辐照下的损伤机制提供新的视角。

Abstract: Radiation damage in structural materials is a major challenge for advanced
nuclear energy systems, and niobium is of particular interest due to its high
melting point, mechanical strength, and corrosion resistance. To better
understand its radiation response, we carried out large-scale molecular
dynamics simulations of collision cascades in pure niobium at 300 K over a
primary knock-on atom (PKA) energy range of 1-75 keV, employing four
interatomic potentials: an embedded atom method (EAM), two Finnis-Sinclair
models (FS-1 and FS-2), and a machine learning-based spectral neighbor analysis
potential (SNAP) we developed. All reproduce the general features of cascade
formation but differ significantly in defect production, clustering, and
morphology. At low energies, defect generation follows trends governed by
threshold displacement energy (TDE) and the stiffness-to-range ratio (|S/R|).
At higher energies, subcascade formation makes defect evolution dependent on
the combined effects of |S/R|, average TDE, and other material-specific
factors. Vacancy clustering dominates over interstitial clustering across all
cases: EAM produces the largest vacancy clusters and the highest clustering
fraction, while SNAP shows the strongest interstitial clustering. Morphological
analysis indicates that EAM forms a balanced mix of 1/2<111>, 1/2<110> loops,
C15 rings, and hybrid structures; FS-2 favors extended 1/2<111> dumbbells,
crowdions, and dislocation loops; whereas FS-1 and SNAP generate more compact
or disordered clusters, with SNAP produces a high fraction of C15-like rings
(maximum size up to nine atoms) that may evolve into dislocation loops of
1/2<111> and <100>. These findings give clear insights into how niobium reacts
when exposed to irradiation, especially at high energies.

</details>


### [309] [Antiferromagnetic domain walls under spin-orbit torque](https://arxiv.org/abs/2509.22241)
*George Theodorou,Stavros Komineas*

Main category: cond-mat.mtrl-sci

TL;DR: Antiferromagnetic domain walls exhibit complex dynamics tunable by spin-polarized currents, differing from ferromagnets. Perpendicular polarization leads to precessional dynamics, while in-plane polarization drives propagating walls with velocity dependent on current. High velocities reveal distinct wall profiles, and dynamical walls can exhibit significant magnetization for potential observation. Oscillatory motion is observed and analytically described for combined polarization components.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the rich and tunable dynamics of domain walls in antiferromagnets under spin-polarized currents, which are not observed in ferromagnets, and to understand the underlying mechanisms and potential applications.

Method: The study uses a perturbation method for low velocities to derive the wall velocity as a function of current and analyze the wall profile. For high velocities, a direct solution of a limiting-case equation is employed to obtain the main features of the wall profile. Analytical descriptions are provided for oscillatory motion observed with combined spin polarization components.

Result: Precessional dynamics are observed for perpendicular spin polarization. Propagating walls are obtained for in-plane polarization, with their velocity dependent on the current. The wall profile lacks definite parity at low velocities. At high velocities, distinct wall profiles are obtained. Dynamical walls can exhibit large magnetization. Oscillatory motion is observed and analytically described for mixed polarization.

Conclusion: Antiferromagnetic domain walls display complex dynamics, including precessional and propagating motion, significantly influenced by spin-polarized currents. The velocity and profile of these walls are tunable and exhibit unique characteristics at different velocity regimes. The potential for large magnetization in dynamical walls offers a promising avenue for experimental observation.

Abstract: Domain walls in antiferromagnets under a spin-polarized current present rich
dynamics that is not observed in ferromagnets, and it is tunable by the current
polarization. Precessional dynamics is obtained for perpendicular spin
polarization, in agreement with expectations in older works. Propagating walls
are obtained for an in-plane polarization. We obtain the velocity as a function
of current by a perturbation method for low velocities, and the wall profile is
found to lack a definite parity. For high velocities, the main features of the
wall profile are obtained by a direct solution of an equation that is valid in
a limiting case. We discuss the magnetization of the dynamical walls and find
that this can become large, providing a potential method for observations.
Oscillatory motion of domain walls is obtained for spin polarization that has
both perpendicular and in-plane components, and an analytical description is
given.

</details>


### [310] [Coherent control of nitrogen nuclear spins via the V$_B^-$-center in hexagonal boron nitride](https://arxiv.org/abs/2509.22257)
*Adalbert Tibiássy,Charlie J. Patrickson,Thomas Poirier,James H. Edgar,Bruno Lopez-Rodriguez,Viktor Ivády,Isaac J. Luxmoore*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究深入探讨了六方氮化硼（hBN）中带电硼空位（V$_{B}^-$）相关的核自旋特性，并展示了对其进行量子相干控制的能力，为基于V$_{B}^-$的量子传感和量子信息处理奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 带电硼空位（V$_{B}^-$）是量子传感和成像的有希望的平台，但其核自旋资源尚未得到充分利用。本研究旨在全面研究V$_{B}^-$附近核自旋的性质和相干控制，以拓展其在量子应用中的潜力。

Method: 通过实验和理论相结合的方法，研究了h$^{10}$B$^{15}$N中V$_{B}^-$空位附近$^{15}$N核自旋的多核自旋态选择性寻址、量子门操作以及相干时间。利用自旋态混合产生的特定核自旋跃迁来实现寻址，并通过Rabi驱动实现量子门操作。同时，进行了数值模拟以深入理解相关机制。

Result: 成功实现了多核自旋态的选择性寻址，定义了基本量子门，并测量到超过10微秒的核Rabi相干时间。观察到核g因子增强了两个数量级，从而实现了快速的核自旋门操作。数值模拟为理解这些现象提供了深入的见解。

Conclusion: 该研究为利用V$_{B}^-$中心的核自旋资源在量子应用中，特别是扩展相干时间和提高二维量子传感箔的灵敏度方面，奠定了基础。

Abstract: Charged boron vacancies (V$_\text{B}^-$) in hexagonal boron nitride (hBN)
have emerged as a promising platform for quantum nanoscale sensing and imaging.
While these primarily involve electron spins, nuclear spins provide an
additional resource for quantum operations. This work presents a comprehensive
experimental and theoretical study of the properties and coherent control of
the nearest-neighbor $^{15}$N nuclear spins of V$_\text{B}^-$-ensembles in
isotope-enriched h$^{10}$B$^{15}$N. Multi-nuclear spin states are selectively
addressed, enabled by state-specific nuclear spin transitions arising from
spin-state mixing. We perform Rabi driving between selected state pairs, define
elementary quantum gates, and measure longer than 10~$\mu$s nuclear Rabi
coherence times. We observe a two orders of magnitude nuclear g-factor
enhancement that underpins fast nuclear spin gates. Accompanying numerical
simulations provide a deep insight into the underlying mechanisms. These
results establish the foundations for leveraging nuclear spins in
V$_\text{B}^-$ center-based quantum applications, particularly for extending
coherence times and enhancing the sensitivity of 2D quantum sensing foils.

</details>


### [311] [Self-organization mechanism in Bridgman-grown MnBi2Te4/(Bi2Te3)n: influence on layer sequence and magnetic properties](https://arxiv.org/abs/2509.22303)
*Paweł Skupiński,Kamil Sobczak,Katarzyna Gas,Anna Reszka,Yadhu K. Edathumkandy,Jakub Majewski,Krzysztof Grasza,Maciej Sawicki,Agnieszka Wołoś*

Main category: cond-mat.mtrl-sci

TL;DR: Bridgman方法在生长高质量磁性拓扑绝缘体晶体方面面临热力学限制，但能提供低自由载流子浓度的块状材料。本研究采用倒置垂直 Bridgman 方法生长 MnBi2Te4/(Bi2Te3)n 晶体，重点研究 MnBi2Te4 七层结构在 Bi2Te3 五层结构基质中的有序性及其对磁性的影响。研究识别出四种生长阶段，并发现七层结构间距与 MnTe 过饱和度呈负相关。实验结果显示，纯 MnBi2Te4 相和 MnBi2Te4/(Bi2Te3)n 异质结构呈现反铁磁有序，而更宽的七层结构间距则出现铁磁性。研究确定了反铁磁和铁磁相变的临界温度以及铁磁样品的磁各向异性常数，为可控制备具有可调磁性的层状拓扑绝缘体提供了方向。


<details>
  <summary>Details</summary>
Motivation: Bridgman 方法在生长高质量磁性拓扑绝缘体晶体方面存在热力学限制，但能获得低自由载流子浓度的块状材料。本研究旨在探索倒置垂直 Bridgman 方法在生长 MnBi2Te4/(Bi2Te3)n 晶体中的应用，特别是研究 MnBi2Te4 七层结构在 Bi2Te3 五层结构基质中的有序性及其对磁性的影响，并确定关键的生长参数以实现可控合成。

Method: 采用倒置垂直 Bridgman (Inverted Vertical Bridgman) 生长方法，研究 MnBi2Te4/(Bi2Te3)n 晶体的生长动力学，包括湍流、MnTe 沉淀、稳态生长和流动停止等四个阶段。通过分析生长过程中的结构和磁性，研究七层结构间距与 MnTe 过饱和度的关系，并表征反铁磁和铁磁相变的临界温度及磁各向异性常数。

Result: 研究识别出四种生长阶段，并发现七层结构间距与 MnTe 过饱和度呈负相关。纯 MnBi2Te4 相和 MnBi2Te4/(Bi2Te3)n 异质结构表现出反铁磁有序，而更宽的七层结构间距则导致铁磁性的出现。确定了反铁磁和铁磁相变的临界温度，并计算了铁磁样品的磁各向异性常数。

Conclusion: 本研究成功地利用倒置垂直 Bridgman 方法生长了 MnBi2Te4/(Bi2Te3)n 晶体，并深入理解了生长动力学、结构有序性与磁性之间的关系。研究发现，通过控制生长参数，可以调控七层结构间距，从而实现反铁磁和铁磁磁性的转变。这些发现为可扩展合成具有可调磁性的层状拓扑绝缘体提供了重要的指导。

Abstract: The growth of high-quality magnetic topological insulator crystals by the
Bridgman method remains challenging due to thermodynamic limitations inherent
to this technique. Nevertheless, this approach continues to provide bulk
materials with significantly reduced free carrier concentrations compared to
epitaxial methods. Here, we investigate the Inverted Vertical Bridgman growth
of MnBi2Te4/(Bi2Te3)n crystals, with particular emphasis on the structural
ordering of MnBi2Te4 septuple layers within the Bi2Te3 quintuple-layer matrix
and its influence on magnetic properties. Through a detailed analysis of growth
dynamics, we identify four distinct stages, including a turbulent flow regime
promoting pure MnBi2Te4 phase, rapid MnTe precipitation reducing Mn content in
the melt, a stationary growth phase supporting ordered stacking of septuple and
quintuple layers, and a final stage marked by flow cessation and defect
formation. We demonstrate that septuple layer spacing is inversely correlated
with MnTe supersaturation due to the diffusion-limited incorporation in
stationary growth phase. Magnetic characterization reveals antiferromagnetic
ordering in pure MnBi2Te4 phase and in MnBi2Te4/(Bi2Te3)n heterostructure, with
ferromagnetism emerging for wider septuple layer spacing. We determine critical
temperatures for observed antiferromagnetic and ferromagnetic phase transitions
and magnetic anisotropy constants for ferromagnetic samples. Our findings
highlight key growth parameters governing magnetic and structural quality,
offering a pathway to scalable synthesis of layered topological insulators with
tunable magnetic properties.

</details>


### [312] [Linear-scaling calculation of experimental observables for molecular augmented dynamics simulations](https://arxiv.org/abs/2509.22388)
*Tigany Zarrouk,Miguel A. Caro*

Main category: cond-mat.mtrl-sci

TL;DR: MAD是一种改进的分子动力学方法，可以通过多目标优化来寻找与实验数据一致的材料结构，尤其适用于无序系统。它能生成高精度、低能量的结构，并能找到与非平衡实验合成兼容的亚稳态结构，或比传统方法（如熔融淬灭）更低的能量结构。MAD还可以通过广义压强计实现密度匹配，并具有CPU和GPU的线性计算扩展性。


<details>
  <summary>Details</summary>
Motivation: 需要一种方法来解决无序材料理论结构模型与实验数据之间的不匹配问题，因为无序系统的构型空间巨大，精确模拟需要大体系和量子力学精度。

Method: 提出并实现了一种名为分子增强动力学（MAD）的改进分子动力学方法，该方法通过多目标优化，同时考虑原子间势能和实验势能，以生成与实验数据一致的高精度、低能量结构。文章还提供了MAD的通用方程，包括用于计算和匹配X射线/中子衍射及局部可观测量的线性尺度公式，以及通过广义 virial张量和实验力实现的广义压强计。

Result: MAD方法能够生成与实验数据（如X射线/中子衍射和X射线光电子能谱中的核心电子结合能）相匹配的材料结构。该方法能找到与非平衡实验合成兼容的亚稳态结构，并能获得比熔融淬灭等方法更低的能量结构。此外，通过广义压强计，MAD能够找到密度与实验可观测量兼容的结构。TurboGAP代码的测试表明，MAD在CPU和GPU实现上都具有线性扩展性，其中GPU实现比CPU快100倍。

Conclusion: MAD是一种高效且通用的方法，能够解决无序材料结构模拟中的挑战，生成与实验数据精确匹配的结构，并探索比传统方法更广泛的构型空间，为材料科学研究提供了强大的计算工具。

Abstract: Aligning theoretical atomistic structural models of materials with available
experimental data presents a significant challenge for disordered systems. The
configurational space to navigate is vast, and faithful realizations require
large system sizes with quantum-mechanical accuracy in order to capture the
distribution of structural motifs present in experiment. Traditional
equilibrium sampling approaches offer no guarantee of generating structures
that coincide with experimental data for such systems. An efficient means to
search for such structures is molecular augmented dynamics (MAD)
[arXiv:2508.17132], a modified molecular dynamics method that can generate
ab-initio accurate, low-energy structures through a multi-objective
optimization of the interatomic potential energy and the experimental
potential. The computational scaling of this method depends on both the scaling
of the interatomic potential and that of the experimental potential. We present
the general equations for MAD with linear-scaling formulations for calculating
and matching X-ray/neutron diffraction and local observables, e.g., the
core-electron binding energies used in X-ray photoelectron spectroscopy. MAD
simulations can both find metastable structures compatible with non-equilibrium
experimental synthesis and lower energy structures than alternative
computational sampling protocols, like the melt-quench approach. In addition,
generalizing the virial tensor with the experimental forces enables generalized
barostatting, allowing one to find structures whose density matches that
compatible with the experimental observables. Scaling tests with the TurboGAP
code demonstrate their linear-scaling nature for both CPU and GPU
implementations, the latter of which has a 100$\times$ speedup compared to the
CPU.

</details>


### [313] [Directional strong coupling at the nanoscale between hyperbolic polaritons and organic molecules](https://arxiv.org/abs/2509.22451)
*Ana I. F. Tresguerres-Mata,Olga G. Matveeva,Christian Lanza,José Álvarez-Cuervo,Kirill V. Voronin,Francesco Calavalle,Garen Avedissian,Pablo Díaz-Núñez,Gonzalo Álvarez-Pérez,Aitana Tarazaga Martín-Luengo,Javier Taboada-Gutiérrez,Jiahua Duan,Javier Martín-Sánchez,Andrei Bylinkin,Rainer Hillenbrand,Artem Mishchenko,Luis E. Hueso,Valentyn S. Volkov,Alexey Y. Nikitin,Pablo Alonso-González*

Main category: cond-mat.mtrl-sci

TL;DR: 光谱学研究报道了在纳米尺度下，双曲声子极化激子与分子振动方向耦合的现象。


<details>
  <summary>Details</summary>
Motivation: 实现纳米尺度下的分子振动强耦合（VSC），并探索其调控机制，以期控制分子性质，并为方向传感等应用提供可能。

Method: 通过纳米成像技术观察双曲声子极化激子（PhPs）与分子（的振动）耦合的色散关系，并分析了耦合强度与传播方向、分子层厚度的关系。

Result: 观察到了方向性VSC现象，即VSC的色散关系（在振动共振处出现明显的反交叉）会随着传播方向的改变而改变。同时发现，在薄分子层中存在最优的VSC条件，使得耦合强度在某一特定方向上达到最大值。

Conclusion: 双曲声子极化激子与分子振动之间可以实现方向性强耦合，并且耦合强度与分子层厚度有关。这一发现不仅具有基础科学意义，也为纳米尺度的定向传感和化学性质调控开辟了新的应用前景。

Abstract: Strong coupling (SC) is a fundamental concept in physics that describes
extreme interactions between light and matter. Recent experiments have
demonstrated SC at the nanometer scale, where strongly confined polaritons,
rather than photons, couple to quantum emitters or molecular vibrations.
Coupling with the latter is generally referred to as vibrational SC (VSC) and
is of significant fundamental and technological interest, as it can be an
effective tool for modifying molecular properties. However, the implementation
of VSC, especially at the nanoscale, depends on the development of tuning
mechanisms that allow control over the coupling strength and, eventually, its
directionality, opening the door for the selective coupling of specific
molecular vibrations. Here we report the observation of directional VSC.
Specifically, we show nanoscale images of propagating hyperbolic phonon
polaritons (PhPs) coupled to pentacene molecules revealing that the fingerprint
of VSC for propagating polaritons -- a marked anti-crossing in their dispersion
at the vibrational resonance -- can be modulated as a function of the direction
of propagation. In addition, we show that VSC can exhibit an optimal condition
for thin molecular layers, characterized by a maximum coupling strength along
one single direction. This phenomenon is understood by analysing the overlap of
the polariton field with molecular layers of varying thicknesses. Apart from
their fundamental importance, our findings promise novel applications for
directional sensing or local directional control of chemical properties at the
nanoscale.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [314] [Privacy-Preserving Performance Profiling of In-The-Wild GPUs](https://arxiv.org/abs/2509.21762)
*Ian McDougall,Michael Davies,Rahul Chatterjee,Somesh Jha,Karthikeyan Sankaralingam*

Main category: cs.AR

TL;DR: 本文提出了一种可实现大规模、实时 GPU 性能分析的系统，解决了用户体验、隐私保护和数据收集效率三大挑战。


<details>
  <summary>Details</summary>
Motivation: 随着 GPU 应用和硬件日益复杂，如何在实际部署中收集全面的 GPU 性能特征和价值信息，以优化芯片设计和应用性能，成为一个严峻的挑战。现有工具仅限于单用户数据收集，无法满足大规模需求。

Method: 本文提出了一种全新的系统，旨在解决用户体验（无性能损耗）、隐私保护（不泄露用户应用信息）和数据收集效率（在数千个 GPU 上有效收集并分配数据）这三大根本性问题。

Result: 通过模拟 100,000 个 GPU 的大规模部署，运行 Torchbench 应用套件，结果表明该系统成功解决了提出的三大问题。

Conclusion: 本文提出的系统能够实现大规模、实时、低损耗、保护隐私的 GPU 性能分析，并有效收集和分配数据，为 GPU 芯片设计和应用性能优化提供了新的解决方案。

Abstract: GPUs are the dominant platform for many important applications today
including deep learning, accelerated computing, and scientific simulation.
However, as the complexity of both applications and hardware increases, GPU
chip manufacturers face a significant challenge: how to gather comprehensive
performance characteristics and value profiles from GPUs deployed in real-world
scenarios. Such data, encompassing the types of kernels executed and the time
spent in each, is crucial for optimizing chip design and enhancing application
performance. Unfortunately, despite the availability of low-level tools like
NSYS and NCU, current methodologies fall short, offering data collection
capabilities only on an individual user basis rather than a broader, more
informative fleet-wide scale. This paper takes on the problem of realizing a
system that allows planet-scale real-time GPU performance profiling of
low-level hardware characteristics. The three fundamental problems we solve
are: i) user experience of achieving this with no slowdown; ii) preserving user
privacy, so that no 3rd party is aware of what applications any user runs; iii)
efficacy in showing we are able to collect data and assign it applications even
when run on 1000s of GPUs. Our results simulate a 100,000 size GPU deployment,
running applications from the Torchbench suite, showing our system addresses
all 3 problems.

</details>


### [315] [NeuroScalar: A Deep Learning Framework for Fast, Accurate, and In-the-Wild Cycle-Level Performance Prediction](https://arxiv.org/abs/2509.22410)
*Shayne Wadle,Yanxin Zhang,Vikas Singh,Karthikeyan Sankaralingam*

Main category: cs.AR

TL;DR: 本篇论文提出了一个新颖的深度学习框架，用于在生产硬件上进行高保真度的“野外”模拟，以解决现有微处理器设计评估中模拟器速度慢和基准跟踪不具代表性的问题。该框架使用微架构无关的特征来预测周期级性能，从而可以在现有硅上评估未来硬件。


<details>
  <summary>Details</summary>
Motivation: 现有微处理器设计的评估方法存在速度慢和基准跟踪不具代表性的问题，限制了新设计的有效评估。

Method: 提出一个深度学习框架，该框架使用微架构无关的特征来预测周期级性能。该系统包括一个轻量级的硬件跟踪收集器和一个原则性的采样策略，并可以在商品 GPU 上实现 5 MIPS 的模拟速度，或者使用专门设计的 Neutrino 芯片加速器将性能提高 85 倍。

Result: 该框架在商品 GPU 上的模拟速度达到 5 MIPS，性能开销仅为 0.1%。与 GPU 相比，专门设计的 Neutrino 芯片加速器可将性能提高 85 倍。

Conclusion: 该框架能够大规模、准确地进行性能分析和硬件 A/B 测试，适用于真实世界的应用程序。

Abstract: The evaluation of new microprocessor designs is constrained by slow,
cycle-accurate simulators that rely on unrepresentative benchmark traces. This
paper introduces a novel deep learning framework for high-fidelity,
``in-the-wild'' simulation on production hardware. Our core contribution is a
DL model trained on microarchitecture-independent features to predict
cycle-level performance for hypothetical processor designs. This unique
approach allows the model to be deployed on existing silicon to evaluate future
hardware. We propose a complete system featuring a lightweight hardware trace
collector and a principled sampling strategy to minimize user impact. This
system achieves a simulation speed of 5 MIPS on a commodity GPU, imposing a
mere 0.1% performance overhead. Furthermore, our co-designed Neutrino on-chip
accelerator improves performance by 85x over the GPU. We demonstrate that this
framework enables accurate performance analysis and large-scale hardware A/B
testing on a massive scale using real-world applications.

</details>


### [316] [AxLLM: accelerator architecture for large language models with computation reuse capability](https://arxiv.org/abs/2509.22512)
*Soroush Ahadi,Mehdi Modarressi,Masoud Daneshtalab*

Main category: cs.AR

TL;DR: 量化技术不仅能减小大语言模型（LLM）的尺寸和计算量，还能通过增加参数局部性来促进计算重用。AxLLM 是一种基于此洞察的新型硬件加速器架构，通过缓存和重用乘法结果来消除冗余，支持未经修改的基础模型和 LoRA 微调模型。实验表明，AxLLM 可减少高达 90% 的计算量，降低 28% 的能耗，并实现 1.7 倍的加速。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）对计算资源和内存的需求巨大，这给高效部署带来了挑战。量化技术虽能减小模型尺寸和计算量，但本研究发现了其一个额外的好处：量化能增加参数的局部性，从而创造计算重用的机会。

Method: 提出了一种名为 AxLLM 的硬件加速器架构，专门为量化后的模型设计。AxLLM 采用新颖的冗余消除技术，通过缓存和重用重复的权重值的乘法结果来显著减少冗余操作。该架构还包含双重乘法和重用流水线，能够高效地支持基础模型和 LoRA 微调模型，且无需修改参数、重新训练或进行离线预处理。

Result: 实验结果显示，AxLLM 能够实现高达 90% 的计算量减少，能耗降低 28%，并且相比基线执行速度提升 1.7 倍。

Conclusion: AxLLM 是一种可扩展且高效的解决方案，能够为专用硬件上的 LLM 提供加速。

Abstract: Large language models demand massive computational power and memory
resources, posing significant challenges for efficient deployment. While
quantization has been widely explored to reduce model size and computation,
this paper demonstrates an additional benefit: quantization increases parameter
locality, creating opportunities for computation reuse. Building on this
insight, we propose AxLLM, a hardware accelerator architecture designed for
quantized models. Axllm introduces a novel redundancy elimination technique
that caches and reuses multiplication results for repeated weight values,
substantially reducing redundant operations. The architecture features dual
multiply and reuse pipelines, efficiently supporting both base models and LoRA
fine-tuned models without altering parameters, retraining, or requiring offline
preprocessing. Experimental results show that AxLLM achieves up to 90%
reduction in computations, delivering 28% lower energy consumption and a 1.7x
speedup over baseline execution. These results highlight Axllm as a scalable
and efficient solution for accelerating LLMs on specialized hardware.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [317] [Quantum Simulation of Fermions in $AdS_2$ Black Hole: Chirality, Entanglement, and Spectral Crossovers](https://arxiv.org/abs/2509.21410)
*Kazuki Ikeda,Yaron Oz*

Main category: quant-ph

TL;DR: 该研究在离散化的 AdS_2 黑洞背景上研究自由狄拉克费米子，分析了由时空弯曲、视界和自旋连接引起的手征引力效应如何影响光谱、输运和量子信息 the scrambling 现象。


<details>
  <summary>Details</summary>
Motivation: 研究背景是理解在弯曲时空中，特别是 AdS_2 黑洞背景下，自由狄拉克费米子的行为，以及时空红移、视界和自旋连接等因素如何影响其量子现象，如光谱、输运和 the scrambling。

Method: 研究采用数值方法，首先通过交错费米子离散化模型，然后应用 Jordan-Wigner 变换将其编码为量子比特自由度。在此基础上，构建了包含与能量相关的因子和编码了红移与自旋连接效应的键手征项的哈密顿量。随后，计算了基态和第一激发态的能量、局部电荷分布以及半链纠缠熵，并分析了红移和手征性对手性到能隙区域的转变的影响。此外，还利用时间反向无关关联函数（out-of-time-order correlators）探测了算子增长，并通过能级间距统计和 Brody 拟合分析了从可积到遍历的交叉，并引入了驱动多体局域化转变的离散无序。

Result: 研究发现，视界和手征耦合会加速 the scrambling 过程，但系统仍保持在非混沌区域。此外，通过能级间距统计和 Brody 拟合，研究描绘了可积到遍历的交叉，并引入了离散无序来驱动多体局域化转变。

Conclusion: 研究表明，在 AdS_2 黑洞背景下，时空红移和手征效应显著影响狄拉克费米子的光谱、输运和 the scrambling 属性。视界和手征耦合会加速 the scrambling，但系统保持非混沌。研究还揭示了可积到遍历的转变以及离散无序驱动的多体局域化现象。

Abstract: We consider free Dirac fermions on a discretized $AdS_2$ black hole
background, and analyze how curved space redshift, horizons, and the spin
connection induced chiral gravitational effect shape spectral, transport, and
scrambling phenomena. The system is discretized via staggered fermions followed
by the Jordan-Wigner transform to encode the model in qubit degrees of freedom,
whose Hamiltonian carries site dependent warp factors and bond chirality terms
encoding the redshift and spin connection effects. We calculate the ground
state and first excited states energies, their local charge profiles, and their
half-chain entanglement entropies, showing how redshift and chirality affect
the transition from criticality to a gapped regime. Probing operator growth via
out-of-time-order correlators, we find that horizons and the chiral coupling
accelerate scrambling, yet remain within a non-chaotic regime. Finally, we map
out an integrable to ergodic crossover via level-spacing statistics and Brody
fits, and introduce on-site disorder to drive a many body localization
transition.

</details>


### [318] [Thermal reconstruction of chaotic quantum many-body systems](https://arxiv.org/abs/2509.21441)
*Shozab Qasim,Jason Pollack*

Main category: quant-ph

TL;DR: Thermal states in quantum systems can reveal information about their underlying Hamiltonians, especially through the lens of the quantum marginal problem and Petz recovery maps. The study analyzes how well a system's Hamiltonian can be reconstructed from its subsystems in thermal states using conditional mutual information. This reconstruction is examined in both a random-matrix-theory-inspired model and an Ising-like spin chain. The findings indicate that the success of reconstruction varies significantly between chaotic and integrable phases, with chaotic phases showing good reconstruction at extreme temperatures and integrable phases failing at low temperatures.


<details>
  <summary>Details</summary>
Motivation: The paper investigates the extent to which information about the fixed Hamiltonian of a thermal state can be inferred from its subsystems, framing this as a problem related to quantum marginals.

Method: The study employs the Petz recovery map, a concept from quantum information theory, to quantify the information about the larger system contained within a subsystem of a thermal state. The goodness of this recovery process is assessed using conditional mutual information. Analytical calculations were performed on a random-matrix-theory-inspired hopping model, and numerical simulations were conducted on an Ising-like spin chain model.

Result: The analysis revealed distinct behaviors in the chaotic and integrable phases of the studied models. In the chaotic phase, the reconstruction of the Hamiltonian from subsystems was effective at both very low and very high temperatures, with a notable degradation of performance at an intermediate critical temperature. In contrast, the reconstruction process broke down at low temperatures within the integrable phase.

Conclusion: The ability to reconstruct the Hamiltonian of a quantum system from its thermalized subsystems is highly dependent on the system's phase. While reconstruction is generally successful in chaotic systems across a wide temperature range (except for intermediate temperatures), it fails in integrable systems at low temperatures, highlighting a significant difference in how information is encoded and can be retrieved in these two types of phases.

Abstract: Thermal states are thermal with respect to a fixed Hamiltonian. How much
information about this Hamiltonian can we ``bootstrap'' from the subsystems of
a thermal state? We attack the problem by positioning it as a subspecies of the
quantum marginal problem. In states that obey the quantum Markov property, the
Petz recovery map captures the knowledge of the larger system inherent in a
subsystem. We use the conditional mutual information to check the goodness of
Petz recovery, analytically in a random-matrix-theory-inspired hopping model
and numerically in an Ising-like spin chain model. We observe different
behavior in chaotic versus integrable phases of the model: in the chaotic
phase, the reconstruction works well at both very low and very high
temperatures, with some intermediate critical temperature at which
reconstruction works worst, whereas in the integrable phase reconstruction
breaks down at low temperatures.

</details>


### [319] [Solving Currency Arbitrage Problems using D-Wave Advantage2 Quantum Annealer](https://arxiv.org/abs/2509.22591)
*Lorenzo Mazzei,Giada Beccari,Mirko Laruina,Marco Cococcioni*

Main category: quant-ph

TL;DR: 该论文研究了量子退火在货币套利优化问题上的应用，并与经典方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 介绍量子退火作为一种解决组合优化问题的强大工具，并指出公司对量子计算市场的投资日益增加。

Method: 将货币套利问题表述为QUBO问题，并使用D-wave量子退火器（最新版本Advantage 2）进行测试。

Result: 评估量子退火在货币套利问题上的性能。

Conclusion: 评估量子退火在货币套利问题上的性能。

Abstract: Quantum annealing has emerged as a powerful tool for solving combinatorial
optimization problems efficiently, making use of the principles of quantum
mechanics. Companies are increasingly investing in the market of quantum
computers, providing the users with the possibility to solve these optimization
problems by resorting to quantum computers. This paper explores how Quantum
Annealing can be applied to the Currency Arbitrage (CA) optimization problem
and its comparative performance against classical methods. A key contribution
of the work is an original formulation of the CA problem as a QUBO (Quadratic
Unconstrained Boolean Optimization) problem. We test the speed of D-wave
quantum annealer, using the recently released latest version (Advantage 2).

</details>


### [320] [Entanglement sharing schemes](https://arxiv.org/abs/2509.21462)
*Zahra Khanian,Dongjin Lee,Debbie Leung,Zhi Li,Alex May,Takato Mori,Stanley Miao,Farzin Salek,Jinmin Yi,Beni Yoshida*

Main category: quant-ph

TL;DR: 本文研究了量子关联如何在多个子系统中分布的问题，并定义了纠缠共享方案（ESS）。


<details>
  <summary>Details</summary>
Motivation: 研究如何将量子关联分布到多个子系统。

Method: 定义了纠缠共享方案（ESS），并探讨了其两种变体（已知伙伴和未知伙伴）。在稳定器态下，对已知伙伴情况下的访问结构进行了完全表征，并为阈值访问结构构建了有效的方案。在未知伙伴情况下，也进行了完全表征，并对一般方案的必要条件进行了证明，推测其也为充分条件。

Result: 在稳定器态下，对已知伙伴和未知伙伴情况下的访问结构进行了完全表征。为阈值访问结构构建了有效的方案。证明了未知伙伴情况下一般方案的必要条件。

Conclusion: 提出了纠缠共享理论，并将其应用于解决量子网络中对时敏请求的纠缠分发问题，以解决一个开放性难题。

Abstract: We ask how quantum correlations can be distributed among many subsystems. To
address this, we define entanglement sharing schemes (ESS) where certain pairs
of subsystems allow entanglement to be recovered via local operations, while
other pairs must not. ESS schemes come in two variants, one where the partner
system with which entanglement should be prepared is known, and one where it is
not. In the case of known partners, we fully characterize the access structures
realizable for ESS when using stabilizer states, and construct efficient
schemes for threshold access structures, and give a conjecture for the access
structures realizable with general states. In the unknown partner case, we
again give a complete characterization in the stabilizer setting, additionally
give a complete characterization of the case where there are no restrictions on
unauthorized pairs, and we prove a set of necessary conditions on general
schemes which we conjecture are also sufficient. Finally, we give an
application of the theory of entanglement sharing to resolve an open problem
related to the distribution of entanglement in response to time-sensitive
requests in quantum networks.

</details>


### [321] [On the hardness of approximating minimum distances of quantum codes](https://arxiv.org/abs/2509.21469)
*Elena Grigorescu,Vatsal Jha,Eric Samperton*

Main category: quant-ph

TL;DR: 经典和量子纠错码的距离计算问题已被证明是困难的。本文使用超图乘积码简化了量子情况下的证明，并展示了计算图态距离的NP-hard性，这甚至对X型错误也成立。此外，还探讨了添加错误对量子代码距离的影响，并暗示了新的平方根障碍的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究纠错码（包括经典和量子）距离计算的困难性，特别是量子情况下的困难性，并回应Kapshikar和Kundu关于具有加性错误的量子代码距离的NP-hard性问题的质疑。

Method: 1. 使用超图乘积码，通过直接归约CSS码（最常用的量子码类型）来证明经典线性码最小距离问题的困难性。 2. 证明计算/近似图态距离（对于量子码很关键）是NP-hard的，即使只考虑X型错误。 3. 证明了计算或近似速率为1/2的经典码距离的困难性。 4. 证明了超图乘积码不受与量子码长度成比例的加性错误的影响，暗示了新的平方根障碍的可能性。

Result: 1. 提出了一个更简单的证明，说明量子纠错码的距离计算问题是困难的，并直接归约到CSS码。 2. 证明了计算/近似图态距离是NP-hard的，即使只考虑X型错误。 3. 证明了计算或近似速率为1/2的经典码距离是NP-hard的。 4. 证明了超图乘积码不受与量子码长度成比例的加性错误的影响。

Conclusion: 本文通过超图乘积码，为量子纠错码距离计算的困难性提供了更简单的证明，并揭示了图态距离计算的NP-hard性。此外，研究结果对经典码距离的计算困难性以及量子码距离对加性错误的鲁棒性提供了新的见解，并暗示了未来研究方向。

Abstract: The problem of computing distances of error-correcting codes is fundamental
in both the classical and quantum settings. While hardness for the classical
version of these problems has been known for some time (in both the exact and
approximate settings), it was only recently that Kapshikar and Kundu showed
these problems are also hard in the quantum setting. As our first main result,
we reprove this using arguably simpler arguments based on hypergraph product
codes. In particular, we get a direct reduction to CSS codes, the most commonly
used type of quantum code, from the minimum distance problem for classical
linear codes.
  Our second set of results considers the distance of a graph state, which is a
key parameter for quantum codes obtained via the codeword stabilized formalism.
We show that it is NP-hard to compute/approximate the distance of a graph state
when the adjacency matrix of the graph is the input. In fact, we show this is
true even if we only consider X-type errors of a graph state. Our techniques
moreover imply an interesting classical consequence: the hardness of computing
or approximating the distance of classical codes with rate equal to 1/2.
  One of the main motivations of the present work is a question raised by
Kapshikar and Kundu concerning the NP-hardness of approximation when there is
an additive error proportional to a quantum code's length. We show that no such
hardness can hold for hypergraph product codes. These observations suggest the
possibility of a new kind of square root barrier.

</details>


### [322] [Dynamics and Control of Two Coupled Quantum Oscillators: An Analytical Approach](https://arxiv.org/abs/2509.21492)
*Ali Abu-Nada,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 通过失谐控制两个耦合量子振荡器以抑制退相干，并研究了正则和不规则控制策略。


<details>
  <summary>Details</summary>
Motivation: 研究两个耦合量子振荡器在共同的洛伦兹环境中的行为，并通过失谐（暂时移位其频率）来控制它们。

Method: 精确求解简化的动力学，不使用玻色或马尔可夫近似，通过对每个失谐片段进行封闭形式传播。研究了两种控制方案：正则失谐（周期性开关脉冲）和不规则失谐（周期、宽度和幅度存在抖动）。主要可观测量是每个模式的平均激发数（AEN）。

Result: 失谐将系统移离环境的光谱峰值，抑制了退相干并抑制了非马尔可夫的复兴；在有效马尔可夫环境中，效果很小。通过时域抑制因子量化性能。更大的失谐幅度和更高的占空比可以提供更强的保护。不规则控制在低占空比时稍弱，但随着占空比接近一，变得与正则控制相当。

Conclusion: 结果提供了将失谐、占空比和环境宽度联系起来的实用设计规则，并为受控的非马尔可夫动力学提供了精确的基准。

Abstract: We analyze two coupled quantum oscillators in a common Lorentzian environment
and control them by detuning (temporarily shifting) their frequencies. The
reduced dynamics are solved exactly, without Born or Markov approximations, by
propagating each detuning segment in closed form. We study two control
schedules: regular detuning, with perfectly periodic on and off pulses of fixed
period, width, and amplitude; and irregular detuning, with the same on/off
structure but cycle-to-cycle jitter in period, width, and amplitude. Our main
observable is the average excitation number (AEN) of each mode. Detuning moves
the system away from the bath's spectral peak, suppressing decoherence and
damping non-Markovian revivals; in effectively Markovian baths the benefit is
small. We quantify performance with a simple time-domain suppression factor.
Larger detuning amplitudes and higher duty cycles yield stronger protection.
Irregular control is slightly weaker at low duty cycle but becomes comparable
to regular control as the duty cycle approaches one. These results give
practical design rules linking detuning, duty cycle, and bath width, and
provide an exact benchmark for controlled non-Markovian dynamics.

</details>


### [323] [Quantum algorithms for solving a drift-diffusion equation: analysing circuit depths](https://arxiv.org/abs/2509.21509)
*Ellen Devereux,Animesh Datta*

Main category: quant-ph

TL;DR: 该论文比较了五种不同门集实现二维漂移扩散方程量子算法的电路深度，并分析了不同门集和问题规模下的性能。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同量子门集在实现特定量子算法（求解二维漂移扩散方程）时的效率，特别是电路深度方面。

Method: 通过量子傅里叶变换进行对角化，并对五种不同的门集（无约束、Quantinuum TK1、IBM Heron、IonQ以及Fujitsu STAR）在多达22个量子比特的算例上进行分析，比较电路深度。

Result: 在至少一个算例中，STAR门集下的最小问题实例也超出了当前量子硬件的运行限制。一维缩放与理论预测一致，但二维缩放因块编码开销而效率低于理论值。

Conclusion: 不同的量子门集对量子算法的电路深度有显著影响。STAR门集在某些情况下可能需要比现有硬件能力更多的资源。块编码的开销影响了二维问题的理论缩放效率。

Abstract: We compare the circuit depths for five different gate sets to implement a
quantum algorithm solving a drift-diffusion equation in two spatial dimensions.
Our algorithm uses diagonalisation by the quantum Fourier transform. The gate
sets are: An unconstrained gate set, the TK1 gate set from Quantinuum, the
native gate sets of IBM Heron and IonQ, and Fujitsu's space-time efficient
analog rotation (STAR) gate set. Our analysis covers a set of illustrative
scenarios using up to 22 qubits. We find that while scaling with spatial
resolution aligns with theoretical predictions in one dimension, scaling with
spatial dimension is less efficient than theorised due to overhead from block
encoding. Finally, using the STAR gate set, we find that even minimal problem
instances exceed the operational limits of current quantum hardware.

</details>


### [324] [From VQE To SQD: Modern Quantum Algorithms For The Electronic Structure Problem](https://arxiv.org/abs/2509.21555)
*Abdelmouheymen Rabah Khamadja,Mohamed Taha Rouabah*

Main category: quant-ph

TL;DR: 本论文研究了基于采样的量子算法，用于电子基态能量估算，特别是量子选择组态相互作用（QSCI）和基于样本的量子对角化（SQD），作为变分量子特征求解器（VQE）的近期替代方案。与VQE不同，QSCI和SQD避免了变分优化，通过从量子硬件中采样斯莱特行列式并在经典上进行对角化，从而解决了VQE的贫瘠平原和高测量成本问题。主要贡献是首次提出了采样瓶颈的解析表达式，将行列式发现步骤映射到经典的优惠券收集问题，得出了恢复贡献基态的行列式所需的测量次数的精确公式和可扩展的下界估计。该分析通过模拟、硬件校准的噪声研究以及在IBM 127量子比特的IBM Brisbane处理器上的执行进行了验证，证明了采样效率在QSCI和SQD的近期可行性中起着主导作用。


<details>
  <summary>Details</summary>
Motivation: 针对变分量子特征求解器（VQE）在实际应用中面临的贫瘠平原和高测量成本问题，提出并研究了量子选择组态相互作用（QSCI）和基于样本的量子对角化（SQD）这两种基于采样的量子算法，作为有前景的近期替代方案，以实现电子基态能量的有效估算。

Method: 将基于采样的量子算法（QSCI和SQD）中的行列式发现步骤，映射到经典的优惠券收集问题，从而推导出精确的测量次数公式和可扩展的下界估计。

Result: 通过模拟、硬件校准的噪声研究和在IBM Brisbane处理器上的实际执行，验证了所提出的分析方法。结果表明，采样效率是决定QSCI和SQD在近期可行性的关键因素。

Conclusion: 采样效率是影响量子选择组态相互作用（QSCI）和基于样本的量子对角化（SQD）算法在近期实现可行性的主导因素。通过将行列式发现过程与经典的优惠券收集问题相关联，并推导出测量次数的解析表达式，为这些算法的实际应用提供了理论支持和指导。

Abstract: This thesis investigates sampling-based quantum algorithms for electronic
ground state energy estimation, focusing on Quantum-Selected Configuration
Interaction (QSCI) and Sample-Based Quantum Diagonalization (SQD) as near-term
alternatives to the Variational Quantum Eigensolver (VQE). Unlike VQE, which
suffers from barren plateaus and high measurement costs, these methods avoid
variational optimization by sampling Slater determinants from quantum hardware
and performing diagonalization classically. The central contribution is the
first analytical expression for the sampling bottleneck: the
determinant-discovery step is mapped to the classical coupon-collector problem,
yielding both an exact formula and a scalable lower-bound estimator for the
number of measurements required to recover all determinants contributing to the
ground state. Previous work only relied on numerical sampling and estimation.
The analysis is validated through simulations, hardware-calibrated noisy
studies, and execution on IBM's 127-qubit IBM Brisbane processor, demonstrating
the dominant role of sampling efficiency in the near-term feasibility of QSCI
and SQD.
  This work was carried out under the supervision of Dr. Mohamed Taha Rouabah.

</details>


### [325] [High-dimensional quantum Schur transforms](https://arxiv.org/abs/2509.22640)
*Adam Burchardt,Jiani Fei,Dmitry Grinko,Martin Larocca,Maris Ozols,Sydney Timmerman,Vladyslav Visnevskyi*

Main category: quant-ph

TL;DR: 本文修正了Krovi的量子舒尔变换算法，并详细阐述了BCH舒尔变换的高维版本，使其在n<d的条件下更具实用性。


<details>
  <summary>Details</summary>
Motivation: 量子舒尔变换是基础量子算法，但仍有未充分理解的方面，且Krovi的算法存在错误。

Method: 修正Krovi的算法，并详细处理BCH舒尔变换的高维版本。

Result: 提供了修正后的Krovi算法和BCH算法的高维版本，其复杂度分别为O(n^4)和O(min(n^5,nd^4))，适用于n<d的情况。

Conclusion: 本文填补了文献中的关键空白，为依赖于量子信息论和量子计算中舒尔-韦尔对偶的算法奠定了更坚实的基础。

Abstract: The quantum Schur transform has become a foundational quantum algorithm, yet
even after two decades since the seminal 2005 paper by Bacon, Chuang, and
Harrow (BCH), some aspects of the transform remain insufficiently understood.
Moreover, an alternative approach proposed by Krovi in 2018 was recently found
to contain a crucial error. In this paper, we present a corrected version of
Krovi's algorithm along with a detailed treatment of the high-dimensional
version of the BCH Schur transform. This high-dimensional focus makes the two
versions of the transform practical for regimes where the number of qudits $n$
is smaller than the local dimension $d$, with Krovi's algorithm scaling as
$\widetilde{O}(n^4)$ and BCH as $\widetilde{O}(\min(n^5,nd^4))$. Our work
addresses a key gap in the literature, strengthening the algorithmic
foundations of a wide range of results that rely on Schur--Weyl duality in
quantum information theory and quantum computation.

</details>


### [326] [A Markovian approach to $N$-photon correlations beyond the quantum regression theorem](https://arxiv.org/abs/2509.21569)
*Mateusz Salamon,Oliver Dudgeon,Ahsan Nazir,Jake Iles-Smith*

Main category: quant-ph

TL;DR: 量子退相干理论无法处理多光子关联，本文提出了一个马尔可夫框架来计算频率分辨的多光子关联函数，并应用于半导体量子点，成功捕捉了声子侧带，并揭示了其对二阶相干性的影响。


<details>
  <summary>Details</summary>
Motivation: 标准工具（如量子回归定理）无法处理与振动环境耦合的量子发射器的多光子关联，需要新的方法来克服这一限制。

Method: 提出一个马尔可夫框架，用于计算频率分辨的N光子关联函数，并将其应用于受激半导体量子点，以描述声子对荧光的影响。

Result: 该方法能够捕捉到传统量子回归定理方法所忽略的声子侧带，并揭示了声子在过滤后的双光子光谱中引入的丰富结构。研究发现，通过声子侧带发射的光子继承了Mollow三峰的二阶相干性。

Conclusion: 本文提出的马尔可夫框架能够有效处理量子发射器与振动环境耦合的多光子关联问题，并为理解声子效应提供了新的视角。

Abstract: Multi-photon correlations from quantum emitters coupled to vibrational
environments lie beyond the reach of standard tools such as the quantum
regression theorem (QRT). Here, we introduce a Markovian framework for
computing frequency-resolved $N$-photon correlation functions that overcomes
this limitation. Applying our approach to a driven semiconductor quantum dot
provides a tractable description of phonon effects on fluorescence beyond the
single-photon spectrum. Our method accurately captures the emergence of the
phonon sideband, missed by conventional QRT treatments, and reveals rich
phonon-induced structure in the filtered two-photon spectrum. Strikingly, we
find that photons emitted via the phonon sideband inherit second-order
coherence properties of the Mollow triplet.

</details>


### [327] [Quantum lattice Boltzmann algorithm for heat transfer with phase change](https://arxiv.org/abs/2509.21630)
*Christopher L. Jawetz,Zhixin Song,Spencer H. Bryngelson,Alexander Alexeev*

Main category: quant-ph

TL;DR: 本研究提出了一种量子格子玻尔兹曼方法（QLBM）来模拟涉及相变的传热过程。


<details>
  <summary>Details</summary>
Motivation: 涉及相变的传热过程因其计算的复杂性（移动相边界、非线性计算和时间步长限制）而具有挑战性。

Method: 该方法结合了格子玻尔兹曼方法（LBM）的统计特性和量子计算能力，采用界面跟踪策略划分固液域，并在量子电路中存储相变信息以避免频繁的经典-量子硬件通信。

Result: QLBM的模拟结果与经典LBM和解析解吻合，证明了该方法在相变传热分析中的有效性。使用17个格子节点和51个量子比特的模拟显示，与经典解相比，均方根（RMS）误差低于0.005，并且能够准确跟踪相变过程中的界面移动。

Conclusion: 量子格子玻尔兹曼方法（QLBM）为模拟涉及相变的传热问题提供了一种有效且准确的途径。

Abstract: Heat transfer involving phase change is computationally intensive due to
moving phase boundaries, nonlinear computations, and time step restrictions.
This paper presents a quantum lattice Boltzmann method (QLBM) for simulating
heat transfer with phase change. The approach leverages the statistical nature
of the lattice Boltzmann method (LBM) while addressing the challenges of
nonlinear phase transitions in quantum computing. The method implements an
interface-tracking strategy that partitions the problem into separate solid and
liquid domains, enabling the algorithm to handle the discontinuity in the
enthalpy-temperature relationship. We store phase change information in the
quantum circuit to avoid frequent information exchange between classical and
quantum hardware, a bottleneck in many quantum applications. Results from the
implementation agree with both classical LBM and analytical solutions,
demonstrating QLBM as an effective approach for analyzing thermal systems with
phase transitions. Simulations using 17 lattice nodes with 51 qubits
demonstrate root-mean-square (RMS) errors below 0.005 when compared against
classical solutions. The method accurately tracks interface movement during
phase transition.

</details>


### [328] [Tensors, entanglement, separability, and their complexity](https://arxiv.org/abs/2509.21639)
*Shmuel Friedland*

Main category: quant-ph

TL;DR: 使用张量来量化多体量子态的纠缠和可分性，并提出了一种针对玻色子的有效计算方法。


<details>
  <summary>Details</summary>
Motivation: 量子物理中量化d体状态的纠缠和可分性是一个挑战性问题。

Method: 利用张量来处理d体量子态，并引入了厄米和密度张量的概念，特别是双对称厄米张量。

Result: 研究表明，多体纠缠态具有最小的谱范数和最大的核范数。对于玻色子态，可分性和强可分性可以通过核范数的值来表征，并且可以在多项式时间内计算。

Conclusion: 对于玻色子系统（对称d-qubits或d-qunits），可以有效地计算其纠缠和可分性度量，这为研究多体量子系统的性质提供了新的途径。

Abstract: One of the most challenging problems in quantum physics is to quantify the
entanglement of $d$-partite states and their separability. We show here that
these problems are best addressed using tensors. The geometric measure of
entanglement of a pure state is one of most natural ways to quantify the
entanglement, which is simply related to the spectral norm of a tensor state.
On the other hand, the logarithm of the nuclear norm of the state and density
tensors can be considered as its ``energy''. We first show that the most
geometric measure entangled $d$-partite state has the minimum spectral norm and
maximum nuclear norm. Second, we introduce the notion of Hermitian and density
tensors, and the subspace of bi-symmetric Hermitian tensors, which correspond
to Bosons. We show that separable density tensors, and strongly separable
bi-symmetric density tensors are characterized by the value (equal to one) of
their corresponding nuclear norms. In general, these characterizations are
NP-hard to verify. Third, we show that the above quantities are computed in
polynomial time when we restrict our attentions to Bosons: symmetric
$d$-qubits, or more generally to symmetric $d$-qunits in $C^n$, and the
corresponding bi-symmetric Hermtian density tensors, for a fixed value of $n$.

</details>


### [329] [Noise cross-correlations from single-shot measurements](https://arxiv.org/abs/2509.22073)
*Juan S. Rojas-Arias,Peter Stano,Yi-Hsien Wu,Leon C. Camenzind,Seigo Tarucha,Daniel Loss*

Main category: quant-ph

TL;DR: 本文提出了一种名为单次交叉光谱学（SSCS）的新方法，用于提取量子比特对的退相噪声的自功率谱密度和互功率谱密度。


<details>
  <summary>Details</summary>
Motivation: 提出SSCS方法，以从单次读出数据中提取量子比特对的退相噪声的自功率谱密度和互功率谱密度。

Method: SSCS方法使用单量子比特拉姆齐类型实验的单次读出，并能抵抗状态制备和测量中的错误。

Result: 该方法成功应用于半导体自旋量子比特器件的实验数据，在五个数量级（5 mHz--500 Hz）的频率范围内获得了噪声谱。

Conclusion: SSCS方法能够测量自旋量子比特以前无法访问的中间频率范围（1--500 Hz）内的噪声关联，并且可以通过更快的读出来进一步扩展。SSCS方法可扩展到其他平台，其可访问的频率范围仅受实验重复率的限制。

Abstract: We introduce a novel method that we call Single-Shot Cross-Spectroscopy
(SSCS), for extracting the auto- and cross-power spectral densities of
dephasing noise of a qubit pair. The method uses straightforward input, namely
single-shot readouts from single-qubit Ramsey-type experiments, and is
resilient against errors in state preparation and measurement. We apply it to
experimental data from a semiconductor spin-qubit device and obtain noise
spectra over five orders of magnitude in frequency (5 mHz--500 Hz). Compared to
other techniques, SSCS enables access to noise correlations in the previously
inaccessible intermediate-frequency range (1--500 Hz) for spin qubits, and can
be further extended with faster readout. More broadly, the frequency range
accessible with SSCS is limited only by the experiment repetition rate, and
scales accordingly on other platforms.

</details>


### [330] [Fast mixing of operator-loop path-integral quantum Monte Carlo for stoquastic XY Hamiltonians](https://arxiv.org/abs/2509.21683)
*Chaithanya Rayudu,Jun Takahashi*

Main category: quant-ph

TL;DR: 量子蒙特卡洛方法（特别是算子-圈更新）在处理无符号问题的海森堡模型时，混合时间呈多项式增长，从而可以在多项式时间内估算配分函数，显著优于先前算法。


<details>
  <summary>Details</summary>
Motivation: 对量子蒙特卡洛方法（尤其是算子-圈更新）的效率进行理论分析，该方法在凝聚态物理学中已成功应用于多种系统。

Method: 研究算子-圈更新方法在stoquastic（无符号问题）XY模型上的应用，并证明该马尔可夫链的混合时间与系统大小和反比温度成多项式关系。

Result: 所提出的算法可以在多项式时间内估算配分函数，比先前由Bravyi和Gosset提出的算法有显著改进，并且该算法可推广到其他经验上混合速度快的哈密顿量。

Conclusion: 该研究为量子蒙特卡洛方法在处理特定类型问题上的效率提供了理论基础，并提出了一种更优的算法。

Abstract: Quantum Monte Carlo method with operator-loop update is a powerful technique
that has been extensively used with great success in condensed matter physics.
It enables one to sample from thermal and ground states of local Hamiltonians
of various spin, bosonic and fermionic systems as long as the Hamiltonian does
not have a negative-sign problem. Despite the practical success of this method,
theoretical understanding of the efficiency of the algorithm has been lacking.
The operator-loop update is commonly used for path-integral formulation
(Suzuki-Trotter/world-lines) of the partition function. In this work we
consider this method applied to the stoquastic (sign-problem free) XY model and
prove that the mixing time of the Markov chain is polynomial in the system size
and the inverse temperature. Using the fast mixing Markov chain, we can
estimate the partition functions of the Hamiltonians that we consider in a
polynomial time, significantly improving upon the best known previous algorithm
by Bravyi and Gosset [arXiv:1612.05602]. Our algorithm also allows for natural
extensions to a wide class of empirically fast-mixing Hamiltonians.

</details>


### [331] [Privacy in Distributed Quantum Sensing with Gaussian Quantum Networks](https://arxiv.org/abs/2509.22103)
*Uesli Alushi,Roberto Di Candia*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the privacy properties of distributed quantum sensing protocols in a
Gaussian quantum network, where each node encodes a parameter via a local phase
shift. For networks with more than two nodes, achieving perfect privacy is
possible only asymptotically, in the limit of large photon numbers. However, we
show that optimized fully symmetric Gaussian states enable rapidly approaching
perfect privacy while maintaining near-optimal sensing performance. We show
that local homodyne detection achieves a quadratic scaling of precision with
the total number of photons. We further analyze the impact of thermal noise in
the preparation stage on both privacy and estimation precision. Our results
pave the way for the development of practical, private distributed quantum
sensing protocols in continuous-variable quantum networks.

</details>


### [332] [Optimizing the non-Clifford-count in unitary synthesis using Reinforcement Learning](https://arxiv.org/abs/2509.21709)
*David Kremer,Ali Javadi-Abhari,Priyanka Mukhopadhyay*

Main category: quant-ph

TL;DR: 使用强化学习（RL）优化量子电路的T-count和CS-count，实现高效的酉算子合成，显著提升了可处理的酉算子规模和合成效率。


<details>
  <summary>Details</summary>
Motivation: 量子算法的优势实现依赖于高效的酉算子实现，现有算法复杂度随量子比特数和非Clifford门数量呈指数增长。

Method: 设计了一个基于通道表示的RL框架，使用整数进行矩阵运算，并结合了剪枝启发式和算子规范化来降低搜索复杂度。

Result: 与先前工作相比，能够处理更大规模的酉算子，合成速度更快，成功率和提升因子更高。对于两比特Clifford+T合成，可实现多达100个T门，是先前RL算法的5倍。对于两比特Clifford+CS合成，实现了线性复杂度。

Conclusion: RL方法在合成 Clifford+T 和 Clifford+CS 酉算子方面展现出巨大潜力，能够处理比以往更大的问题实例，并在某些情况下达到或超越现有最优算法的性能。

Abstract: An efficient implementation of unitary operators is important in order to
practically realize the computational advantages claimed by quantum algorithms
over their classical counterparts. In this paper we study the potential of
using reinforcement learning (RL) in order to synthesize quantum circuits,
while optimizing the T-count and CS-count, of unitaries that are exactly
implementable by the Clifford+T and Clifford+CS gate sets, respectively. In
general, the complexity of existing algorithms depend exponentially on the
number of qubits and the non-Clifford-count of unitaries. We have designed our
RL framework to work with channel representation of unitaries, that enables us
to perform matrix operations efficiently, using integers only. We have also
incorporated pruning heuristics and a canonicalization of operators, in order
to reduce the search complexity. As a result, compared to previous works, we
are able to implement significantly larger unitaries, in less time, with much
better success rate and improvement factor. Our results for Clifford+T
synthesis on two qubits achieve close-to-optimal decompositions for up to 100 T
gates, 5 times more than previous RL algorithms and to the best of our
knowledge, the largest instances achieved with any method to date. Our RL
algorithm is able to recover previously-known optimal linear complexity
algorithm for T-count-optimal decomposition of 1 qubit unitaries. For 2-qubit
Clifford+CS unitaries, our algorithm achieves a linear complexity, something
that could only be accomplished by a previous algorithm using $SO(6)$
representation.

</details>


### [333] [Machine Learning for Quantum State Tomography: Robust Covariance Matrix Estimation for Squeezed Vacuum States with Thermal Noise](https://arxiv.org/abs/2509.21720)
*Juan Camilo Rodrıguez,Hsien-Yi Hsieh,Hua-Li Chen,Ole Steuernagel,Chien-Ming Wu,Ray-Kuang Lee*

Main category: quant-ph

TL;DR: 提出了一种基于监督机器学习的卷积神经网络方法，用于在有热噪声的情况下估计高斯量子态的协方差矩阵。


<details>
  <summary>Details</summary>
Motivation: 传统的密度矩阵重建方法计算成本高，而所提出的方法可以仅使用稀疏测量值来重建包含热态和压缩热态混合的量子态的非纯压缩真空态。

Method: 使用基于卷积神经网络的监督机器学习模型，对高斯量子态的二次序列进行稀疏测量，以估计其协方差矩阵。

Result: 该方法实现了高保真度和精确度，即使在高压缩水平下也能有效表征物理量并准确估计协方差矩阵。该方法已通过单模压缩真空态的实验数据进行了基准测试，并证明了其在量化压缩和纯度退化方面的准确性。实验验证了该方法对热态混合引起的态退化具有鲁棒性。

Conclusion: 该方法为轻量级、紧凑且完整地表示实验室生成的高斯态提供了一种方法，并为将实时量子态断层扫描扩展到热多组分高斯态和多模系统奠定了基础。

Abstract: We present a supervised machine learning-based method using convolutional
neural networks to estimate the covariance matrix of Gaussian quantum states in
the presence of thermal noise. Unlike computationally intensive density matrix
reconstructions, our machine learning-based method allows for the
reconstruction of impure squeezed vacuum states using sparse measurements of
quadrature sequences based on a model employing a two-component state mixed
together from thermal and squeezed thermal states. The method achieves high
fidelity and precision, notably also at high squeezing levels, while offering
an effective characterization of physical quantities and accurately estimating
the covariance matrix. We benchmark our machine against experimental data of
single-mode squeezed vacuum states, demonstrating its accuracy and capability
to quantify experimental degradation to squeezing and purity. We experimentally
verify that our covariance matrix estimation exhibits robustness to state
degradation induced by thermal state admixtures. We provide a method for
lightweight, compact, and complete representation of lab-generated Gaussian
states and lay the foundation for extending real-time quantum state tomography
for thermal multi-component Gaussian states to multi-mode systems.

</details>


### [334] [Propagation Dynamics and Transient Amplification in Warm and Cold Atomic EIT Systems](https://arxiv.org/abs/2509.21752)
*Andrew MacRae,Connor Kupchak*

Main category: quant-ph

TL;DR: OBE模型在模拟EIT系统中会高估增益，尤其是在考虑了传播动力学和多普勒效应后。


<details>
  <summary>Details</summary>
Motivation: 研究原子系统中电磁感应透明（EIT）瞬态放大的限制，并评估光学布洛赫方程（OBE）模型的局限性。

Method: 使用基于传播的Maxwell-Bloch模拟，并考虑了多普勒效应。

Result: 单原子、空间均匀的OBE模型会高估增益，因为忽略了传播动力学。在两能级系统中，这会导致错误的透射率；在三能级系统中，会预测不切实际的巨大放大。多普勒平均会抑制振荡振铃和最大可实现增益。本研究结果解释了OBE预测与实验观察之间的差异。

Conclusion: OBE模型存在局限性，在模拟EIT系统中的瞬态放大时会高估增益。多普勒效应会进一步影响增益。本研究为冷原子和热增宽EIT介质中的瞬态增益设定了实际限制。

Abstract: We study the limitations on observing transient amplification in atomic
systems exhibiting electromagnetically induced transparency (EIT) and evaluate
the limits of optical Bloch equation (OBE) models. Using propagation-based
Maxwell-Bloch simulations, we show that single-atom, spatially uniform OBE
treatments overestimate gain by neglecting propagation dynamics. In two-level
systems, this yields incorrect transmission, while in three-level systems, it
predicts unrealistically large amplification. Furthermore, we show that Doppler
averaging in warm vapor suppresses oscillatory ringing and the maximum
achievable gain. Our results explain discrepancies between OBE predictions and
experimental observations, and establish practical limits on transient gain in
cold and thermally broadened EIT media.

</details>


### [335] [Towards reconstructing quantum structured light on a quantum computer](https://arxiv.org/abs/2509.21804)
*Mwezi Koni,Shawal Kasim,Paola C. Obando,Neelan Gounden,Isaac Nape*

Main category: quant-ph

TL;DR: We propose a variational quantum computing method to reconstruct quantum states from measurement data by mapping the reconstruction cost function to an Ising model, solvable with a variational eigensolver on current quantum hardware. We demonstrated this on entangled photons with orbital angular momentum, showing it works even with noisy devices. This highlights the potential of variational algorithms for efficient quantum state tomography, especially for high-dimensional structured light where classical methods struggle.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop an efficient quantum state tomography method, especially for high-dimensional structured light, where classical approaches face computational bottlenecks.

Method: The paper introduces a variational quantum computing approach. It maps the reconstruction cost function onto an Ising model, which is then solved using a variational eigensolver on present-day quantum hardware.

Result: The method was demonstrated on quantum structured light (entangled photons with orbital angular momentum) and showed reliable performance even on noisy devices.

Conclusion: Variational algorithms show potential for efficient quantum state tomography, particularly for high-dimensional structured light.

Abstract: We introduce a variational quantum computing approach for reconstructing
quantum states from measurement data. By mapping the reconstruction cost
function onto an Ising model, the problem can be solved using a variational
eigensolver on present-day quantum hardware. As a proof of concept, we
demonstrate the method on quantum structured light, in particular, entangled
photons carrying orbital angular momentum and show that the reconstruction
procedure can yield reliable performance even on noisy devices. Our results
highlight the potential of variational algorithms for efficient quantum state
tomography, particularly for high-dimensional structured light, where classical
approaches can face bottlenecks.

</details>


### [336] [The 2T-quoctit: a two-mode bosonic qudit for high energy physics](https://arxiv.org/abs/2509.21941)
*Doga Murat Kürkçüoglu,Henry Lamm,Oluwadara Ogunkoya,Leonardo Pierattelli*

Main category: quant-ph

TL;DR: 该工作研究了在相干态的非阿贝尔群结构星座中，八进制量子比特的二维玻色子编码。该工作受到了非阿贝尔对称在粒子物理学中的重要性以及实现横向非阿贝尔逻辑门的需求的启发。我们使用了先前开发的2T星座来编码2T-八进制量子比特。通过在考虑了功率约束的条件下，针对不同的噪声模型，将2T-八进制量子比特的保真度与其他玻色子量子比特进行了基准测试，发现其表现良好。这为在具有实际应用的玻色子系统中构建更高维度的量子比特（例如具有2T群结构的2T-五次量子比特）奠定了基础，可用于量子模拟粒子物理学。


<details>
  <summary>Details</summary>
Motivation: 非阿贝尔对称在粒子物理学中的重要性以及实现横向非阿贝尔逻辑门的需求。

Method: 使用先前开发的2T星座来编码2T-八进制量子比特。

Result: 在考虑功率约束的条件下，2T-八进制量子比特的保真度与其他玻色子量子比特在不同噪声模型下进行基准测试，结果表现良好。

Conclusion: 该研究为在具有实际应用（例如量子模拟粒子物理学）的玻色子系统中构建更高维度的量子比特（例如具有2T群结构的2T-五次量子比特）奠定了基础。

Abstract: In this work, we study a two-mode bosonic encoding of a quoctit inside a
non-Abelian group-structured constellation of coherent states. This work is
motivated by the importance of nonabelian symmetry in particle physics and the
desire to have transversal nonabelian logical gates. We use the previously
developed $2T$-constellation of states used to encode a so-called $2T$-qutrit.
The fidelity of the $2T$-quoctit is benchmarked against other bosonic qudits
for different noise models and find it compare favorably when power constraints
are considered. This paves the way for the construction of higher-dimensional
qudits (e.g. a quicosotetrit with $2T$ group structure) in bosonic systems with
practical applications in quantum simulations of particle physics.

</details>


### [337] [Quantum simulation approach to ultra-weak magnetic anisotropy in a frustrated spin-1/2 antiferromagnet](https://arxiv.org/abs/2509.21974)
*Ki Won Jeong,Jae Yeon Seo,Sunghyun Lim,Jae Min Hong,Hyeon Jun Ryu,Jongseok Byeon,Kyungsun Moon,Nara Lee,Young Jai Choi*

Main category: quant-ph

TL;DR: 本研究开发了一种用于模拟磁晶各向异性（MCA）的量子模拟框架，并成功应用于 CuSb2O6 材料。


<details>
  <summary>Details</summary>
Motivation: 磁晶各向异性（MCA）是真实磁体的重要特征，但将其纳入量子模拟仍具挑战性。

Method: 研究人员将 CuSb2O6 的自旋网络建模为四量子比特方形晶格，并引入四对辅助量子比特来编码与角度相关的 MCA。通过变分量子本征求解器（VQ）来模拟。

Result: 模拟结果显示，CuSb2O6 具有极小的易轴 MCA 常数（仅为最近邻交换相互作用的 0.00022%），足以驱动自旋翻转跃迁，并揭示了超高磁场下的半饱和磁相。

Conclusion: 该研究证明了在资源有限的情况下，通过量子模拟复杂磁性现象的可行性。

Abstract: The intrinsic equivalence between electron spin and qubit offers a natural
foundation for quantum simulations of magnetic materials. However,
incorporating magnetocrystalline anisotropy (MCA), a key feature of real
magnets, remains a major challenge. Here, we develop a quantum simulation
framework for MCA in CuSb2O6, a spin-1/2 antiferromagnet with alternating
ferromagnetic chains arising from frustrated, anisotropic exchange interactions
in a nearly square lattice. The $\mathrm{Cu}^{2+}$ spin network is modeled as a
four-qubit square lattice, with four paired ancilla qubits introduced to encode
angle-dependent MCA. This two-qubit representation per spin site resolves the
limitation that squared Pauli operators yield only the identity, enabling MCA
terms to be faithfully embedded into quantum circuits. Using the variational
quantum eigensolver, we determine an exceptionally small easy-axis MCA
constant, just 0.00022% of the nearest-neighbor exchange interaction, yet
sufficient to drive a spin-flop transition with $90^{\circ}$ spin reorientation
and strong angular variation in magnetic torque. Beyond this regime, the
simulations uncover a half-saturated magnetic phase at ultra-high fields,
stabilized by anisotropic next-nearest-neighbor interactions. Our findings
demonstrate the feasibility of resource-efficient quantum simulations of
complex magnetic phenomena in real materials.

</details>


### [338] [Properties of computational entanglement measures](https://arxiv.org/abs/2509.21988)
*Ilia Ryzov,Faedi Loulidi,David Elkouss*

Main category: quant-ph

TL;DR: 本篇论文系统地分析了两种计算纠缠度量（计算可分纠缠和纠缠成本）的基本性质，并引入了上下界扩展来处理非标量值的情况。研究了这些度量的下界凸性、上界凹性以及关于张量积的上界和下界可加性。论文还指出，这些度量在局部酉变换下不具有不变性，但在高效酉变换下具有不变性，并且仅在高效的局部操作与 أي（LOCC）信道下是LOCC单调的。分析涵盖了单次和均匀设置，并将单次设置的性质扩展到均匀设置。


<details>
  <summary>Details</summary>
Motivation: 为了在实际应用中利用量子纠缠进行通信任务，需要考虑计算能力有限的参与者。计算纠缠度量旨在量化在计算资源有限的情况下纠缠的可用性。

Method: 本研究系统地分析了计算可分纠缠和纠缠成本这两种计算纠缠度量的基本性质。引入了基本性质的下界和上界扩展，以处理纠缠度量无法由标量值定义而只能获得下界或上界函数的情况。具体来说，研究了这些度量的下界凸性、上界凹性以及关于张量积的上界和下界可加性。此外，还观察到这些度量在局部酉变换下并非不变，但在高效酉变换下可以恢复不变性。

Result: 研究发现，计算纠缠度量在局部酉变换下并非不变，但在高效酉变换下可以恢复不变性。作为推论，这些度量仅在高效的局部操作与 أي（LOCC）信道下是LOCC单调的。分析同时考虑了单次场景和均匀设置，并将单次场景的性质自然地推广到了均匀设置。

Conclusion: 本研究对计算纠缠度量的基本性质进行了深入分析，为理解和应用这些度量提供了理论基础。研究结果对于在实际通信场景中有效利用量子纠缠具有重要意义。

Abstract: Quantum entanglement is a useful resource for implementing communication
tasks. However, for the resource to be useful in practice, it needs to be
accessible by parties with bounded computational resources. Computational
entanglement measures quantify the usefulness of entanglement in the presence
of limited computational resources. In this paper, we analyze systematically
some basic properties of two recently introduced computational entanglement
measures, the computational distillable entanglement and entanglement cost. To
do so, we introduce lower bound and upper bound extensions of basic properties
to address the case when entanglement measures are not defined by a scalar
value but when only lower or upper function bounds are available. In
particular, we investigate the lower bound convexity and upper bound concavity
properties of such measures, and the upper and lower bound additivity with
respect to the tensor product. We also observe that these measures are not
invariant with local unitaries, although invariance is recovered for efficient
unitaries. As a consequence, we obtain that these measures are only LOCC
monotones under efficient families of LOCC channels. Our analysis covers both
the one-shot scenario and the uniform setting, with properties established for
the former naturally extending to the latter.

</details>


### [339] [A Source of Deterministic Entanglement for Matter-Wave Networks](https://arxiv.org/abs/2509.22096)
*Chen Li,RuGway Wu,Jörg Schmiedmayer*

Main category: quant-ph

TL;DR: 通过受控解离二聚体费米什分子，生成纠缠的超冷中性原子对，可扩展至量子处理器。


<details>
  <summary>Details</summary>
Motivation: 生成纠缠的超冷中性原子对，用于量子非局域性测试、精密测量和可扩展的中性原子量子处理器。

Method: 通过受控解离二聚体费米什分子，利用自旋、位置-动量和路径自由度中的非局域量子关联，生成爱因斯坦-波多尔斯基-罗森对和超纠缠编码的多量子比特态。

Result: 可确定地制备爱因斯坦-波多尔斯基-罗森对和多量子比特态，并可扩展至包含数百个并行纠缠源的阵列。

Conclusion: 该协议可直接用现有技术实现，并为量子信息处理提供了可扩展的中性原子纠缠源。

Abstract: We describe a deterministic and experimentally feasible protocol for
generating entangled pairs of ultracold neutral atoms through controlled
dissociation of diatomic Feshbach molecules. The dissociation process naturally
produces nonlocal quantum correlations in spin, position-momentum, and path
degrees of freedom, enabling the deterministic preparation of
Einstein-Podolsky-Rosen pairs of massive particles and multiqubit states
through hyperentangled encoding. Having each atom of the pair prepared in a
matter waveguide, the scheme can be scaled to hundreds of parallel entanglement
sources in an array connected to a matter wave optical network of beam
splitters, phase shifters, interferometers, tunnel junctions and local
detectors. The protocol builds on established techniques, including
programmable optical potentials, high-fidelity single-particle control,
single-molecule initialization, controlled molecular dissociation, and quantum
gas microscopy with near-perfect detection, making it directly implementable
with current technology. The proposed architecture naturally integrates with
atomtronics circuits and chip-based matter-wave optics, offering a
deterministic entanglement source for quantum nonlocality tests, precision
metrology, and scalable neutral-atom quantum processors.

</details>


### [340] [Introduction of modelling radical pair quantum spin dynamics with tensor networks](https://arxiv.org/abs/2509.22104)
*Kentaro Hino,Damyan S. Frantzov,Yuki Kurashige,Lewis M. Antill*

Main category: quant-ph

TL;DR: 本研究提出了一种基于张量网络的方法，用于模拟包含大量核自旋的自由基对系统的量子动力学，解决了传统方法因指数级内存需求而带来的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 自由基对（或称自旋量子比特对、电子-空穴对）是科学领域普遍存在且被广泛利用的瞬态反应中间体。然而，包含所有核自旋的自由基对自旋动力学模拟因指数级的内存需求而面临计算障碍。

Method: 研究采用张量网络方法，特别是矩阵乘积态（MPS）和矩阵乘积密度算符（MPDO）表示，来模拟自由基对系统的全开放量子动力学。该方法显式考虑了高达30个核自旋（甚至扩展到60个核自旋进行基准测试）的超精细相互作用，有效缓解了全量子非马尔可夫处理中通常遇到的希尔伯特空间和刘维尔空间指数级扩展问题。同时，利用林德布拉德（Lindblad）跳跃算符处理了电子在多个自由基对之间的跳跃过程。

Result: 该方法成功模拟了生物学相关的黄素-色氨酸自由基对系统，精确捕捉了各向异性的自旋动力学，并明确识别出磁场取向依赖性，该依赖性能够增强或减弱自旋选择性产物的产额。

Conclusion: 研究结果强调了核环境对自旋动力学的关键影响，证明了在自旋生物物理学中进行全量子处理的必要性，并为理解鸟类磁感应机制提供了关键见解。该研究提出的计算框架具有鲁棒性，可应用于自旋化学、量子生物学和自旋电子学等广泛的科学领域。

Abstract: Radical pairs (also known as spin qubit pairs, electron-hole pairs) are
transient reaction intermediates that are found and utilised in all areas of
science. Radical pair spin dynamics simulations including all nuclear spins
have been a computational barrier due to exponential scaling memory
requirements. We address this issue with a tensor network method for accurately
simulating the full open quantum dynamics of radical pair systems, explicitly
accounting for hyperfine interactions with up to 30 nuclear spins with
additional benchmarking including 60 nuclei. By employing the matrix product
state (MPS) and matrix product density operator (MPDO) representations, we
mitigate the exponential scaling of Hilbert and Liouville spaces typically
encountered in full quantum non-Markovian treatments. We demonstrate the power
of these methods with biologically relevant flavin-tryptophan radical pair
systems, where we investigate electron hopping processes between multiple
radical pairs using Lindblad jump operators. These simulations precisely
capture anisotropic spin dynamics, clearly identifying orientational dependence
of the magnetic field, which enhances or diminishes the spin-selective product
yield. These directional sensitivities highlight the critical dependence of the
nuclear environment and underscore the necessity of fully quantum treatments in
spin biophysics, offering critical insights into avian magnetoreception
mechanisms. This work provides a robust computational framework applicable to a
broad range of scientific realms, which include spin chemistry, quantum
biology, and spintronics.

</details>


### [341] [Multi-Qubit Gates by Dynamical Decoupling Implemented with IBMQ and 15NV Center in Diamond](https://arxiv.org/abs/2509.22107)
*Lucas Tsunaki,Michael Dotan,Kseniia Volkova,Boris Naydenov*

Main category: quant-ph

TL;DR: 我们提出了一种利用中心量子比特的动态解耦（DD）脉冲序列和其与目标量子比特的相互作用来实现快速高保真度多量子比特门的操作规程。


<details>
  <summary>Details</summary>
Motivation: 现有技术中，直接控制目标量子比特的方法存在速度慢、易出错的问题。本研究旨在通过一种新的协议，利用中心量子比特与目标量子比特的固有相互作用，实现对目标量子比特的快速精确控制，从而克服这些限制。

Method: 本研究提出的DD-门协议，通过在中心量子比特上应用动态解耦（DD）脉冲序列，并利用其与目标量子比特的相互作用来实现多量子比特门操作。该协议在两个不同的框架下进行了理论和实验验证：1. 一个硬件无关的模型，在IBMQ的通用数字量子模拟器上进行了基准测试。2. 一个实验上可行的氮-15空位中心（$^{15}$NV）金刚石系统。

Result: 在IBMQ量子模拟器上，我们对多量子比特门背后的量子动力学进行了彻底的表征，克服了其他量子系统面临的实验限制。对于$^{15}$NV系统，我们建立了相应的协议，考虑了其特定属性，并表明DD-门操作相比于现有技术可以显著减少门操作时间并提高技术可扩展性。此外，我们提出了一个简单的应用实例，用于$^{15}$N核自旋的高效极化生成。所有的实验发现都得到了两个框架下全面开源模拟的支持。

Conclusion: 本研究提供了一种通用的、硬件无关的量子控制策略，适用于任何符合中心-目标量子比特描述的系统，是未来量子设备技术可扩展性的重要一步。该策略能够实现快速高保真度的多量子比特门操作，并为$^{15}$NV系统带来了显著的改进。

Abstract: We demonstrate a general protocol for realizing fast high-fidelity
multi-qubit gates, through dynamical decoupling (DD) pulse sequences applied to
a central qubit coupled to target qubits. This way, we are able to control the
states of the target qubits by leveraging their intrinsic interaction with the
central qubit, eliminating the need for slow error-prone direct control. The
DD-gate protocol is developed and experimentally implemented within two
distinct frameworks: a hardware-agnostic model with minimal assumptions,
benchmarked within a general-purpose digital quantum simulator given by the
IBMQ; and an experimentally realistic case with nitrogen-15 vacancy center
($^{15}$NV) in diamond. Likewise, we are able to thoroughly characterize the
quantum mechanical dynamics behind the multi-qubit gates within IBMQ, without
many of the experimental constraints faced by other quantum systems. While at
the same time, we establish the protocol for the $^{15}$NV system, considering
its specific properties. The DD-gates with $^{15}$NVs can represent a
significant reduction in gate times and improved technological scalability,
compared to current methods of target qubit control using dynamical decoupling.
In addition, we propose a simple application of the method for high-efficiency
polarization generation of the $^{15}$N nuclear spin. All experimental findings
are supported by comprehensive open-source simulations in the two distinct
frameworks. This work provides a robust hardware-agnostic strategy for quantum
control, which can be implemented with arbitrary systems that fit the
central-target qubits description. Thus, marking an essential step in
technological scalability of future quantum devices.

</details>


### [342] [Asymptotic equipartition property of subadditive multipartite entanglement measures on pure states](https://arxiv.org/abs/2509.22152)
*Dávid Bugár*

Main category: quant-ph

TL;DR: 渐近等分性质(AEP)在纯态下多方纠缠度量的背景下被研究，特别是对于满足特定弱条件的次可加纠缠度量。这受到经典双边纠缠熵渐近极限唯一性的启发，并在LOCCq场景（允许亚线性量子通信的渐近局部操作和经典通信）中具有操作相关性。研究证明，平滑弱可加纠缠度量（在满足一些弱附加条件的情况下）的正则化产生了弱可加和渐近连续的纠缠度量。最后，对已知的Rényi型多方纠缠度量进行正则化和平方处理，发现结果的正则化纠缠度量可以简化为双边纠缠熵的凸组合。


<details>
  <summary>Details</summary>
Motivation: 研究AEP在多方纠缠度量中的应用，并借鉴双边纠缠熵渐近极限的唯一性。

Method: 推导弱可加纠缠度量的正则化和平方化，并将其应用于已知的Rényi型多方纠缠度量。

Result: 正则化和平方化后的多方纠缠度量可以简化为双边纠缠熵的凸组合。

Conclusion: 满足特定弱条件下的次可加纠缠度量的正则化能够得到弱可加且渐近连续的纠缠度量，并且在Rényi型度量下，该度量可表示为双边纠缠熵的凸组合。

Abstract: We investigate the asymptotic equipartition property (AEP) in the context of
multipartite entanglement measures on pure states. Specifically, we formulate
AEP for subadditive entanglement measures that admit certain weak conditions.
This is motivated by the uniqueness of the entanglement entropy in the
asymptotic limit in the bipartite case. On the other hand, its operational
relevance comes from the $\text{LOCC}_q$ scenario (asymptotic local operations
and classical communication with a sublinear amount of quantum communication).
Analogously to the classical AEP, we prove that the regularization of smooth
weakly additive entanglement measures (subject to some weak extra conditions)
yields weakly additive and asymptotically continuous entanglement measures.
Then evaluate the mentioned regularization and smoothing on known R\'enyi type
multipartite entanglement measures, showing that the resulting regularized
entanglement measures reduce to convex combinations of bipartite entanglement
entropies.

</details>


### [343] [Mpemba Effects in Quantum Complexity](https://arxiv.org/abs/2509.22176)
*Sreemayee Aditya,Alessandro Summer,Piotr Sierant,Xhek Turkeshi*

Main category: quant-ph

TL;DR: 量子计算中的 Mpemba 效应：研究表明，相干性和虚幻性表现出量子 Mpemba 效应，而非高斯性和魔术性。所有四种资源都表现出 Pontus-Mpemba 效应，即初始“预热”阶段会加速弛豫。


<details>
  <summary>Details</summary>
Motivation: 研究量子 Mpemba 效应在量子计算中的表现，特别是在定义量子复杂性的度量中。

Method: 利用量子资源理论框架，研究了随机电路模型中相干性、虚幻性、非高斯性和魔术状态资源的动力学。

Result: 相干性和虚幻性在系统初始化于有资源的产品状态时表现出量子 Mpemba 效应，而非高斯性和魔术性则不表现。所有四种资源都表现出 Pontus-Mpemba 效应。

Conclusion: Mpemba 物理学延伸到热力学和不对称性之外，广泛出现在捕捉量子复杂性方面的资源理论中。

Abstract: The Mpemba effect is the phenomenon whereby systems farther from equilibrium
may relax faster. In this work, we show that this counterintuitive behavior
appears in the very measures that define quantum complexity. Using the
framework of quantum resource theories, we study the dynamics of coherence,
imaginarity, non-Gaussianity, and magic state resources in random circuit
models. Our results reveal that coherence and imaginarity display a quantum
Mpemba effect when the system is initialized in resourceful product states,
while non-Gaussianity and magic do not. Strikingly, all four resources exhibit
the so-called Pontus-Mpemba effect: an initial "preheating" stage accelerates
relaxation compared to direct "cooling" dynamics. Taken together, our findings
show that Mpemba physics extends beyond thermodynamics and asymmetry, emerging
broadly in the resource theories that capture aspects of quantum complexity.

</details>


### [344] [Extending coherence time beyond break-even point using only drives and dissipation](https://arxiv.org/abs/2509.22191)
*Lida Sun,Yifang Xu,Yilong Zhou,Ziyue Hua,Weiting Wang,Jie Zhou,Zi-jie Chen,Lui Zuccherelli de Paula,Qing-Xuan Jie,Guangming Xue,Haifeng Yu,Weizhou Cai,Chang-Ling Zou,Luyan Sun*

Main category: quant-ph

TL;DR: 自主量子纠错（AQEC）通过引入驱动和工程耗散来稳定逻辑码字，以克服传统基于测量的反馈的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有量子纠错（QEC）实现依赖于测量反馈，但受限于读出保真度、硬件延迟和系统复杂性，限制了性能和可扩展性。AQEC旨在通过相干控制和工程耗散来稳定逻辑码字，以克服这些障碍。

Method: 提出一种源于量子信道模拟的AQEC协议，适用于任意纠错码，并使用二项式码和长寿命玻色子模式实现该协议。

Result: 将逻辑量子比特相干时间延长到比系统中最好的物理量子比特还要长1.04倍，首次实现了超越盈亏平衡点的AQEC保护的玻色子逻辑量子比特。

Conclusion: AQEC具有优越的性能和可扩展性潜力，为大规模通用量子计算迈出了重要一步。

Abstract: Quantum error correction (QEC) aims to mitigate the loss of quantum
information to the environment, which is a critical requirement for practical
quantum computing. Existing QEC implementations heavily rely on
measurement-based feedback, however, constraints on readout fidelity, hardware
latency, and system complexity often limit both performance and scalability.
Autonomous QEC (AQEC) seeks to overcome these obstacles by stabilizing logical
codewords using introduced drives that provide coherent control and engineered
dissipation. Here, we propose an AQEC protocol, derived from quantum channel
simulation, that is applicable to arbitrary error-correcting codes. As a
demonstration, we implement the protocol using a binomial code encoded in a
long-lived bosonic mode (lifetime > 1ms), and extend the logical qubit
coherence time to 1.04 times that of the best physical qubit in the system.
This is the first experimental realization of an AQEC-protected bosonic logical
qubit beyond the break-even point, proving that coherence time can indeed be
extended by introducing only drives and dissipation. Our results highlight the
performance and scalability potential of AQEC, marking an important step toward
large-scale, universal quantum computing.

</details>


### [345] [A minimalist self-differencing gating scheme for dead-time-free single-photon avalanche diodes at high repetition rate](https://arxiv.org/abs/2509.22200)
*Samuele Altilia,Edoardo Suerra,Stefano Capra,Giacomo Secci,Sebastiano Corli,Stefano Olivares,Alessandro Ferraro,Enrico Prati,Simone Cialdi*

Main category: quant-ph

TL;DR: 一种简化的正弦波门控单光子雪崩二极管（SPAD）方案，可实现100 MHz的运行，并具有更精确的偏置控制和更高的信噪比。


<details>
  <summary>Details</summary>
Motivation: 需要用于高重复率激光器（如量子通信和量子计算）的门控SPAD探测器。

Method: 提出了一种基于自差分技术的新型正弦波门控SPAD方案，并使用InGaAs光电二极管进行了实验验证。

Result: 实现了100 MHz的运行，探测器在探测事件后不到一个脉冲重复周期内即可恢复全部量子效率，从而能够连续运行。该方案简化了设计，提高了偏置控制精度，并改善了信噪比。

Conclusion: 所提出的自差分正弦波门控SPAD方案为高重复率应用提供了一种简化且高效的解决方案，并具有进一步提升至GHz运行的潜力。

Abstract: Gated quenched SPAD detectors are widely used in quantum communication and
quantum computing setups employing high-repetition-rate lasers. Here, we
present a novel scheme for high-repetition-rate (100 MHz) sine-wave gated
SPADs, based on the self-differencing technique, which significantly simplifies
previous designs while offering additional advantages. These include
straightforward implementation, more precise control of the SPAD biasing, and
an improved SNR. We implemented this approach using an InGaAs photodiode and
characterized it experimentally with 100 MHz attenuated laser pulses, measuring
quantum efficiency, dark count rate, and afterpulsing behavior. Importantly, we
demonstrate that the detector recovers full quantum efficiency in less than one
pulse-repetition period after a detection event, enabling continuous operation
at 100 MHz, which, in principle, could reach the GHz regime.

</details>


### [346] [Hybrid SU(1,1) interferometry in optomechanics](https://arxiv.org/abs/2509.22248)
*Chao Meng,Emil Zeuthen,Polina R. Sharapova*

Main category: quant-ph

TL;DR: 本研究提出了一种在非简并SU(1,1)干涉仪中利用光力学系统实现亚散粒噪声干涉度量的方法。


<details>
  <summary>Details</summary>
Motivation: 为了在存在机械热噪声和光学损耗的情况下实现亚散粒噪声相位检测，我们提出了一种光力学混合实现方案。

Method: 该方案使用双模压缩器替代了干涉仪中的分束器，并设计了一种光力学混合实现方式，其中一个“臂”是经历了两次连续模式匹配的光场相互作用的机械模式（构成另一“臂”）。

Result: 该混合光力学干涉仪能够实现亚散粒噪声的相位检测，即使在存在机械热噪声和光学损耗的情况下也具有鲁棒性。

Conclusion: 本研究将提高混合系统在精密干涉度量方面的能力，为实现高灵敏度的测量提供了一种新的途径。

Abstract: In non-degenerate SU(1,1) interferometers, beam splitters are replaced by
two-mode squeezers, enabling sub-shot-noise sensitivity without input squeezing
and robustness to detection losses by quantum entanglement. We propose a hybrid
implementation in optomechanics where one "arm" is a mechanical mode undergoing
two consecutive, mode-matched interactions with a traveling optical field
(constituting the other arm). Such engineered interactions allow for
sub-shot-noise phase detection even in the presence of mechanical thermal noise
and optical losses, advancing precision interferometry in hybrid systems.

</details>


### [347] [Two times or none?](https://arxiv.org/abs/2509.22264)
*Michael Ridley,Eliahu Cohen*

Main category: quant-ph

TL;DR: 该论文探讨了量子力学中时间处理的两种主要方法：'无时'方法（如Page和Wootters提出）和'双时'方法（Bauer提出）。


<details>
  <summary>Details</summary>
Motivation: 量子力学中时间处理的两种主要方法：'无时'方法和Bauer提出的'双时'方法，并比较了它们的优缺点。

Method: 文章回顾并比较了'无时'方法和Bauer的'双时'方法，并提出了一种结合两种方法的框架。

Result: Bauer的'双时'方法允许定义'时间算符'，并与其它时间对称的量子力学表述有有趣的联系。

Conclusion: 在量子力学中选择'无时'框架或'双时'方法是一个微妙的选择，并且存在一种将'无时'哲学与'双时'量子力学相结合的框架。

Abstract: Attempts to treat time on an equivalent footing with space in quantum
mechanics have been apparently dominated by `timeless' approaches, such as the
one of Page and Wootters, which allow meaningful discussion of a `time
operator'. However, there is an alternative, and significantly less studied
approach, due to Bauer, which makes use of the `pseudospin' extension of the
state space, effectively adding a backwards-time degree of freedom. This
two-time approach allows definition of a `time operator' and moreover bears
interesting relations with other time-symmetric formulations of quantum
mechanics. We review and compare these approaches to quantum time, emphasizing
that there is a subtle choice between the timeless framework and the two-time
approach. Finally, we sketch a framework in which the timeless philosophy can
be combined with two-time quantum mechanics.

</details>


### [348] [New Quantum Internet Applications via Verifiable One-Time Programs](https://arxiv.org/abs/2509.22290)
*Lev Stambler*

Main category: quant-ph

TL;DR: We propose Verifiable One-Time Programs (Ver-OTPs) constructed from single-qubit states and classical cryptography. Using Ver-OTPs with a multi-key homomorphic scheme (MHE), we achieve single-round Open Secure Computation (OSC), enabling applications like single-round sealed-bid auctions, atomic proposes, and private statistical aggregation. This approach requires minimal quantum resources and offers a promising direction for quantum-assisted cryptography with near-term quantum technology.


<details>
  <summary>Details</summary>
Motivation: The motivation is to construct single-round Open Secure Computation (OSC) with minimal quantum resources, enabling various applications such as single-round sealed-bid auctions, atomic proposes, and private statistical aggregation.

Method: The paper constructs Verifiable One-Time Programs (Ver-OTPs) from single-qubit states and classical cryptographic primitives. Then, it uses Ver-OTPs in conjunction with a multi-key homomorphic scheme (MHE) to build OSC. The quantum requirement is limited to single-qubit states and a hardware assumption on the receiver’s quantum resources.

Result: The paper successfully constructs Verifiable One-Time Programs (Ver-OTPs) and uses them to achieve single-round Open Secure Computation (OSC). This primitive supports applications like single-round sealed-bid auctions, single-round atomic proposes, and single-round private statistical aggregation without pre-registration.

Conclusion: The paper presents a novel framework for quantum-assisted cryptography by introducing Ver-OTPs and OSC, which require minimal quantum resources and are potentially implementable with near-term quantum technology.

Abstract: We introduce Verifiable One-Time Programs (Ver-OTPs) and use them to
construct single-round Open Secure Computation (OSC), a novel primitive
enabling applications like (1) single-round sealed-bid auctions, (2)
single-round and honest-majority atomic proposes -- a building block of
consensus protocols, and (3) single-round differentially private statistical
aggregation without pre-registration. First, we construct Ver-OTPs from
single-qubit states and classical cryptographic primitives. Then, assuming a
multi-key homomorphic scheme (MHE) with certain properties, we use Ver-OTPs
with MHE to construct OSC. The underlying quantum requirement is minimal: only
single-qubit states are needed alongside a hardware assumption on the
receiver's quantum resources. Our work therefore provides a new framework for
quantum-assisted cryptography that may be implementable with near-term quantum
technology.

</details>


### [349] [Bridging Quantum Noise and Classical Electrodynamics with Stochastic Methods](https://arxiv.org/abs/2509.22312)
*Felix Hitzelhammer,Johannes Stowasser,Lukas Hanschke,Katarina Boos,Tobias C. Sutter,Michael Haider,Christian Jirauschek,Kai Müller,Gabriela Slavcheva,Ulrich Hohenester*

Main category: quant-ph

TL;DR: 使用具有共同交叉协方差结构但易于与各种麦克斯韦求解器耦合的耦合随机过程框架，可以模拟非经典光，同时与经典电磁学兼容，并在模拟与实验结果的比较中表现出优异的准确性。


<details>
  <summary>Details</summary>
Motivation: 新兴量子光学技术的发展需要能够准确捕捉真实量子效应的模型，但传统半经典方法和全希尔伯特空间方法各有局限。

Method: 开发了一种基于耦合随机过程的框架，该框架具有共同的交叉协方差结构，易于与各种麦克斯韦求解器耦合，能够自然地处理量子到经典转换中的非对易性。

Result: 模拟结果与强驱动的 InGaAs 量子点的实验发射光谱进行了比较，发现两者高度一致，证明了该方法的准确性。

Conclusion: 定制的随机过程在模拟复杂光子环境中的非经典光方面具有巨大潜力。

Abstract: The development of emerging technologies in quantum optics demands accurate
models that faithfully capture genuine quantum effects. Mature semiclassical
approaches reach their limits when confronted with quantized electromagnetic
fields, while full Hilbert space treatments are often computationally
prohibitive. To address these challenges, we develop a framework based on
coupled stochastic processes with a common cross-covariance structure that can
be easily coupled to various types of Maxwell solvers. Our approach accounts
for the non-commutativity in the quantum-to-classical transition in a natural
way, and has the ability to capture quantum optical signatures while retaining
compatibility with classical electromagnetics. For benchmarking, we compare our
simulation results with experimental emission spectra of a strongly driven
InGaAs quantum dot, finding excellent agreement. Our results highlight the
potential of tailored stochastic processes for simulating non-classical light
in complex photonic environments.

</details>


### [350] [Decoding quantum low density parity check codes with diffusion](https://arxiv.org/abs/2509.22347)
*Zejun Liu,Anqi Gong,Bryan K. Clark*

Main category: quant-ph

TL;DR: 本文提出了一种基于扩散模型的量子纠错解码器，在保持高精度的同时提高了解码速度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 量子纠错解码器的效率至关重要，而数据驱动的神经网络解码器提供了有前景的解决方案。因此，有必要开发更高效、更准确的解码器。

Method: 提出了一种基于扩散模型的框架，用于从量子低密度奇偶校验码的综合测量中推断逻辑错误。研究了具有双变量自行车码和实际电路级噪声的掩码扩散解码器。

Result: 与包括信念传播有序统计解码（BP-OSD）和自回归神经网络解码器在内的其他最先进解码器相比，掩码扩散解码器在精度、平均速度和最坏情况速度方面都表现更好。通过减少扩散步数可以在保证精度的前提下显著提高速度。所提出的解码器能够学习量子码的结构。掩码扩散解码器比连续扩散解码器具有更好的可扩展性。

Conclusion: 基于扩散模型的解码器在量子纠错方面是一种有前途的解决方案，它在精度、速度和可扩展性方面都优于现有方法。

Abstract: An efficient decoder is essential for quantum error correction, and
data-driven neural decoders have emerged as promising, flexible solutions.
Here, we introduce a diffusion model framework to infer logical errors from
syndrome measurements in quantum low-density parity-check codes. Using the
bivariate bicycle code with realistic circuit-level noise, we show that masked
diffusion decoders are more accurate, often faster on average, and always
faster in the worst case than other state-of-the-art decoders, including belief
propagation with ordered statistics decoding (BP-OSD) and autoregressive neural
decoders. We show that by using fewer diffusion steps during inference one can
gain significant speed at minimal cost in accuracy. By examining the factored
attention from our trained neural network we find that, despite being trained
solely on paired samples of syndrome-logical errors, this diffusion decoder
learns the structure of the quantum codes. We also compare both masked and
continuous diffusion decoders on code-capacity noise models, finding that
masked diffusion decoders scale better than continuous diffusion decoders.

</details>


### [351] [Multi-channel convolutional neural quantum embedding](https://arxiv.org/abs/2509.22355)
*Yujin Kim,Changjae Im,Taehyun Kim,Tak Hur,Daniel K. Park*

Main category: quant-ph

TL;DR: 本研究提出一种超越标准量子计算模型限制的混合方法来优化量子嵌入，以用于变分量子电路的分类任务，并在CIFAR-10和Tiny ImageNet数据集上进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 变分量子电路在量子机器学习中的分类应用前景广阔，但其性能受量子嵌入选择的显著影响。现有方法在处理多通道数据时存在局限性。

Method: 提出一种经典-量子混合方法，用于优化量子嵌入，该方法不受限于完全正迹保持（CPTP）映射，能够处理一般多通道数据。

Result: 在CIFAR-10和Tiny ImageNet数据集上对不同模型进行了基准测试，并进行了理论分析以指导模型设计和优化。

Conclusion: 所提出的混合方法能够优化量子嵌入，超越标准量子计算模型的限制，为处理多通道数据和提升量子监督学习性能提供了新的途径。

Abstract: Classification using variational quantum circuits is a promising frontier in
quantum machine learning. Quantum supervised learning (QSL) applied to
classical data using variational quantum circuits involves embedding the data
into a quantum Hilbert space and optimizing the circuit parameters to train the
measurement process. In this context, the efficacy of QSL is inherently
influenced by the selection of quantum embedding. In this study, we introduce a
classical-quantum hybrid approach for optimizing quantum embedding beyond the
limitations of the standard circuit model of quantum computation (i.e.,
completely positive and trace-preserving maps) for general multi-channel data.
We benchmark the performance of various models in our framework using the
CIFAR-10 and Tiny ImageNet datasets and provide theoretical analyses that guide
model design and optimization.

</details>


### [352] [Quantum sensing of a quantum field](https://arxiv.org/abs/2509.22361)
*Ricard Ravell Rodríguez,Martí Perarnau-Llobet,Pavel Sekatski*

Main category: quant-ph

TL;DR: 该研究探索了量子探测器（双能级原子）与相干量化场相互作用时，对场幅值进行完全量子测量的场景，并重点分析了原子探测器的约化态的量子Fisher信息（QFI）。


<details>
  <summary>Details</summary>
Motivation: 在量子计量学中，估计编码在量子哈密顿量中的经典参数是一项基本且重要的任务。本文将经典场景（半经典Rabi模型）与完全量子场景（双能级原子与相干量化场相互作用）进行了对比，旨在理解量子效应如何影响计量性能。

Method: 通过分析双能级原子与相干量化场相互作用时，原子约化态的量子Fisher信息（QFI）。分别考虑了半经典Rabi模型、单相干模式、大场幅值极限、多相干态序列以及连续模式极限下的QFI行为。

Result: 在半经典Rabi模型中，QFI不依赖于场幅值，并与相互作用时间$	au$呈二次方增长。在与单相干模式相互作用时，QFI受到相干态非正交性的限制，上限为4，且仅在真空极限下接近。在大场幅值极限下，QFI在$	au =O(1)$和$	au =O(\alpha^2)$时达到最大值1.47，并在稍晚的时间出现周期性复苏。当原子与一系列相干态相互作用时，QFI会随时间增加，但受限于线性标度，除非在模式数量和总能量发散的极限下。在连续极限下，原子与多个弱相干态相互作用，这种反作用可被解释为自发辐射，从而得到最优的相互作用时间和QFI增长率。

Conclusion: 与经典情况不同，在完全量子的计量场景中，量子探测器与量子场的相互作用会引入限制（如相干态非正交性或原子-场纠缠产生的反作用），从而影响QFI的增长和上限。研究揭示了在不同量子场和相互作用条件下QFI的行为，并指出了在连续极限下，自发辐射等效应在优化计量性能中的作用。

Abstract: Estimating a classical parameter encoded in the Hamiltonian of a quantum
probe is a fundamental and well-understood task in quantum metrology. A
textbook example is the estimation of a classical field's amplitude using a
two-level probe, as described by the semi-classical Rabi model. In this work,
we explore the fully quantum analogue, where the amplitude of a coherent
quantized field is estimated by letting it interact with a two-level atom. For
both metrological scenarios, we focus on the quantum Fisher information (QFI)
of the reduced state of the atomic probe. In the semi-classical Rabi model, the
QFI is independent of the field amplitude and grows quadratically with the
interaction time $\tau$. In contrast, when the atom interacts with a single
coherent mode of the field, the QFI is bounded by 4, a constant dictated by the
non-orthogonality of coherent states. We find that this bound can only be
approached in the vacuum limit. In the limit of large amplitude $\alpha$, the
QFI is found to attain its maximal value $1.47$ at $\tau =O(1)$ and $\tau
=O(\alpha^2)$, and also shows periodic revivals at much later times. When the
atom interacts with a sequence of coherent states, the QFI can increase with
time but is bounded to scale linearly due to the production of entanglement
between the atom and the radiation (back-action), except in the limit where the
number of modes and their total energy diverge. Finally, in the continuous
limit, where the atom interacts with many weak coherent states, this
back-action can be simply interpreted as spontaneous emission, giving rise to
the optimal interaction time and QFI rate.

</details>


### [353] [On the Incompatibility of Quantum State Geometry and Fuzzy Metric Spaces: Three No-Go Theorems](https://arxiv.org/abs/2509.22364)
*Nicola Fabiano*

Main category: quant-ph

TL;DR: 模糊度量空间无法捕捉量子态几何的关键特征，而量子力学提供了更优越的替代方案。


<details>
  <summary>Details</summary>
Motivation: 证明模糊度量空间无法模拟量子态几何的本质特征，例如干涉和对称性区分。

Method: 通过三个结构性不可能结果来证明：1. 模糊度量空间对相位不敏感，无法模拟破坏性干涉。2. 不存在从量子态空间到模糊度量空间的保距嵌入。3. 模糊逻辑无法区分对称和反对称的概念组合。

Result: 1. 模糊度量空间无法模拟破坏性干涉。2. 不存在从量子态空间到模糊度量空间的保距嵌入。3. 模糊逻辑无法区分对称和反对称的概念组合。

Conclusion: 模糊度量空间在结构上无法表示内在不确定性，而量子力学在几何上是连贯的，是更好的选择。

Abstract: We prove three structural impossibility results demonstrating that fuzzy
metric spaces cannot capture essential features of quantum state geometry.
First, we show they cannot model destructive interference between concepts due
to phase insensitivity. Second, we prove there is no distance-preserving
embedding from quantum state space into any fuzzy metric space. Third, we
establish that fuzzy logic cannot distinguish symmetric from antisymmetric
concept combinations -- a fundamental limitation for modeling structured
knowledge. These theorems collectively show that fuzzy frameworks are
structurally incapable of representing intrinsic uncertainty, where quantum
mechanics provides a superior, geometrically coherent alternative.

</details>


### [354] [Quantum topological data analysis algorithm for dynamical systems](https://arxiv.org/abs/2509.22372)
*Nhat A. Nghiem*

Main category: quant-ph

TL;DR: 本研究提出了一个利用量子计算框架来研究动力学系统性质的方法，通过结合量子ODE求解器和量子拓扑数据分析，提取系统的拓扑特征（贝蒂数），从而揭示动力学系统的隐藏特性，并验证了量子ODE求解器输出状态的实用性。


<details>
  <summary>Details</summary>
Motivation: 大多数常微分方程（ODEs）没有解析解，使得理解动力学系统变得困难，因此需要新的方法来研究其性质。

Method: 利用量子ODE求解器获得动力学系统轨迹的图表示，然后将该图输入量子拓扑数据分析算法，计算归一化的贝蒂数作为拓扑特征。

Result: 成功提取了动力学系统的拓扑特征（贝蒂数），并展示了这些特征与ODE性质之间的关联，为理解动力学系统提供了新的视角。

Conclusion: 本研究提出的量子框架能够有效地揭示动力学系统的特性，并且证明了量子ODE求解器输出的量子态具有实际应用价值。

Abstract: Dynamical systems appear in nearly every aspect of the physical world. As
such, understanding the properties of dynamical systems is of great importance.
Typically, a dynamical system is described by a system of ordinary differential
equations (ODE). Most ODEs do not admit analytical solutions, which makes
dynamical systems challenging to understand. In this work, we introduce a
quantum framework for determining certain properties of dynamical systems. We
combine many recent advances in quantum algorithms, particularly quantum ODE
solver and quantum topological data analysis. Leveraging the prior results
regarding the quantum ODE solvers, we use the output of these quantum
algorithms as a means to build the graph associated with the trajectory of the
dynamical system in the phase space. This graph information is then fed into
existing quantum TDA algorithms, respectively, to obtain the (normalized) Betti
numbers, which are the topological signatures. We then discuss how such
signatures can be linked to the properties of a given ODE, and thus, they can
reveal insight towards the original dynamical systems. As a by-product, our
work provides an affirmative answer to the applicability of quantum ODE
solvers, showing that the quantum state as output can be valuable for useful
purposes.

</details>


### [355] [Photons do not see entanglement (Entanglement, nonlocality, and the collapse of the wavefunction)](https://arxiv.org/abs/2509.22385)
*Moslem Mahdavifar*

Main category: quant-ph

TL;DR: 纠缠态的演化在惯性参考系中受洛伦兹变换的影响，并非总是保持非局域性。


<details>
  <summary>Details</summary>
Motivation: 从不同视角研究 the orbital angular momentum (OAM) 纠缠态在惯性参考系下的洛伦兹变换效应，特别是当观察者存在相对运动时。

Method: 考虑了零相对运动（Zero-RM）和非零相对运动（Non-Zero RM）两种情况。在非零相对运动下，进一步区分了静止观察者（Non-Zero RM1）和运动观察者（Non-Zero RM2）的视角。通过纠缠熵和纯度等度量来量化纠缠态的变化。

Result: 结果表明，纠缠态的转移概率振幅会发生改变。在静止观察者看来，纠缠态的变化显著，并且趋向于一个最小值。而在运动观察者（Non-Zero RM2）看来，纠缠态会完全消失，最终态是可分离的。这表明纠缠态并非总是保持非局域性。

Conclusion: 研究表明，纠缠态并非总是保持非局域性，并且会受到运动的影响。量子力学中的波函数坍缩并非自发地在时空中发生。此外，推测光子本身不携带OAM，该属性是在光-物质相互作用极限下出现的。

Abstract: The idea behind entanglement is counterintuitive to any classical viewpoint
of physical realism. An entangled state is a nonlocal superposition of
realities that belong to a physical system. The common test of such a state has
been done through Bell measurements. In this work, we attempt to look at this
notion from a different perspective. We study the evolution of the orbital
angular momentum (OAM) entanglement in inertia reference frames under a Lorentz
boost. We consider two specific motions for the observers of the entanglement.
First, we consider observers with zero relative motion (Zero-RM). Second, we
choose to have a non-zero relative motion (Non-Zero RM) for them. In the second
case, we distinguish between observer's perspective of the amplitude
probability from the perspective of rest (Non-Zero RM1) and moving (Non-Zero
RM2) observers. As a result, the transition probability amplitudes are altered.
We observe that entanglement undergoes significant changes and is not preserved
maximally from the viewpoint of the stationary observers at the rest frame and
asymptotically approaches a minimum close to the light cone (LC). However, from
the viewpoint of moving observer in the Non-Zero RM2, entanglement will not
survive, and the final state is separable. This is an extremely important
observation since the concept of entanglement is supposed to be non-local, and
therefore free from any spacetime transformation. Our results demonstrated
through the entanglement metrics such as entanglement entropy and purity show
that an entangled state is not non-local and hence the so-called collapse of
the wavefunction in quantum mechanics does not occur spontaneously in
spacetime. Ironically, even entanglement is influenced by motion. Finally,
based on this study, one can predict that photons do not carry OAM
fundamentally and this property is only emergent at the light-matter
interaction limit.

</details>


### [356] [Feature- and process-based optimal control of quantum dynamics](https://arxiv.org/abs/2509.22401)
*M. Farnia,V. Rezvani,A. T. Rezakhani*

Main category: quant-ph

TL;DR: 该研究提出了一种基于特征的开放量子过程最优相干控制方法，用于制备具有高相干性和纯度的量子过程，并证明了Krotov优化算法和凸重叠保真度的有效性。


<details>
  <summary>Details</summary>
Motivation: 量子计算中制备量子态和量子操作至关重要，但相比于量子态的制备，量子过程的制备优化研究较少。在某些应用中，我们需要的不是特定的量子态或过程，而是具有特定特征（如高相干性或纯度）的量子态或过程。在这种情况下，基于保真度的度量不足以评估量子控制策略的性能，需要采用基于特征的评价指标。

Method: 提出了一种开放量子过程的基于特征的最优相干控制形式化方法，特别关注马尔可夫演化。研究了Krotov优化算法，并探索了选择合适的初始猜测场以提高其性能。在qutrit Rydberg系统模型中，比较了基于过程和基于状态的保真度与基于凸重叠的保真度的性能。

Result: 在qutrit Rydberg系统模型中，研究表明基于特征的Krotov优化算法可以通过选择合适的初始猜测场来提高性能。此外，基于凸重叠的保真度被证明优于其他基于过程的和基于状态的保真度。

Conclusion: 该分析强调了基于特征的最优控制策略在量子过程制备中的实用性。

Abstract: Preparing desired quantum states and quantum operations (processes) is
essential for numerous tasks in quantum computation. Several approaches have
been developed for optimal control of quantum states, whereas optimal
strategies for preparation of a given quantum process have remained fairly less
explored. For some applications, rather than a specific desired state or
process, it may suffice to obtain states or processes with specific desired
features such as (high) coherence or purity. In such cases, fidelity-based
measures alone are inadequate for evaluating the performance of a quantum
control strategy, and hence proper feature-based figures of merit should be
employed. Here we develop a feature-based optimal coherent control formalism
for open quantum processes under Markovian evolutions which demonstrate high
coherence and purity features. In particular, we observe that performance of
the feature-based Krotov optimization algorithm can be improved by choosing
educated initial guess fields. In addition, in a model for a qutrit Rydberg
system, it is shown that the convex overlap-based fidelity outperforms other
process-based as well as state-based fidelities. This analysis underscores the
utility of feature-based optimal control strategies for quantum processes.

</details>


### [357] [Quantum internal vibrations in macroscopic systems with classical centers of mass](https://arxiv.org/abs/2509.22429)
*Gabriel H. S. Aguiar,George E. A. Matsas*

Main category: quant-ph

TL;DR: 经典力学并非量子力学的涌现，当系统质量远超普朗克质量时，量子力学对质心描述不可靠。本文提出的引力自退相干模型解释了质量接近普朗克质量的量子系统如何经典化，并且该模型不影响宏观系统（具有经典质心）的量子内振动。


<details>
  <summary>Details</summary>
Motivation: 纠正“经典力学源于量子力学”的观点，并提出当系统质量远超普朗克质量时，量子力学对质心的描述是不可靠的。

Method: 提出一个简单的引力自退相干模型，用于描述质量接近普朗克质量的量子系统如何实现经典化。

Result: 证明了该模型并不妨碍宏观系统（具有经典质心）的内部量子振动（已在实验室观测到）。

Conclusion: 已提出的引力自退相干模型能够解释宏观物体内部的量子效应，且不与经典力学的宏观行为相矛盾。

Abstract: Harmonizing classical and quantum worlds is a major challenge for modern
physics. A significant portion of the scientific community supports the notion
that classical mechanics is an effective theory that arises from quantum
mechanics. Recently, the present authors have argued that this should not be
the case, as quantum mechanics is not trustworthy for describing the center of
mass of systems with masses $m$ much larger than the Planck mass $M_\text{P}$.
In this vein, a simple gravitational self-decoherence model was proposed,
describing how the center of mass of quantum systems would classicalize for $m
\sim M_\text{P}$. Here, we show that our model does not prevent macroscopic
systems (with classical centers of mass) from harboring quantum internal
vibrations (as has been observed in the laboratory).

</details>


### [358] [Two classes of quantum spin systems that are gapped on any bounded-degree graph](https://arxiv.org/abs/2509.22438)
*Nicholas Hunter-Jones,Marius Lemm*

Main category: quant-ph

TL;DR: 该研究证明了在特定条件下，具有非对易相互作用的平移不变量子自旋哈密顿量具有能隙。


<details>
  <summary>Details</summary>
Motivation: 证明平移不变哈密顿量通常具有能隙的普遍看法，并将先前在一维链上的结果扩展到更一般的图。

Method: 通过解析验证广义 Knabe 型有限尺寸判据来推导能隙，该判据适用于任何有界度图。

Result: 对于随机秩-1 投影或 Haar 投影作为相互作用，在特定条件下（例如，大的局部维度和高概率），证明了哈密顿量在有界度图上是具有能隙的。

Conclusion: 研究结果为普遍认为的平移不变哈密顿量具有能隙的观点提供了数学证明，并将先前一维链的结果推广到更一般的图，并提供了可推广到其他类型哈密顿量的解析方法。

Abstract: We study translation-invariant quantum spin Hamiltonians on general graphs
with non-commuting interactions either given by (i) a random rank-$1$
projection or (ii) Haar projectors. For (i), we prove that the Hamiltonian is
gapped on any bounded-degree graph with high probability at large local
dimension. For (ii), we obtain a gap for sufficiently large local dimension.
Our results provide examples where the folklore belief that typical
translation-invariant Hamiltonians are gapped can be proved, which extends a
result by Bravyi and Gosset from 1D qubit chains with rank-$1$ interactions to
general bounded-degree graphs. We derive the gaps by analytically verifying
generalized Knabe-type finite-size criteria that apply to any bounded-degree
graph.

</details>


### [359] [A Quantum Algorithm for Nonlinear Electromagnetic Fluid Dynamics via Koopman-von Neumann Linearization](https://arxiv.org/abs/2509.22503)
*Hayato Higuchi,Yuki Ito,Kazuki Sakamoto,Keisuke Fujii,Akimasa Yoshikawa*

Main category: quant-ph

TL;DR: 该研究提出了一种利用量子计算模拟等离子体现象的算法，可以克服传统计算方法的资源限制，并在模拟K-H不稳定性等问题上展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统等离子体模拟对计算资源的要求很高，其计算复杂度随空间网格数呈多项式增长，这限制了大规模建模。本研究旨在提出一种量子算法来解决这一挑战。

Method: 本研究提出一种量子算法，通过Koopman-von Neumann线性化将其映射到薛定谔方程，并利用量子奇异值转换进行哈密顿模拟来演化系统。

Result: 该量子算法在时间复杂度上实现了$O ig(s N_x 	ext{ polylog} ig( N_x ig) T ig)$，相较于经典方法的$O ig(s N_x^s ig(T^{5/4}+T N_xig) ig)$，在$N_x$上实现了多项式加速。空间复杂度从$Oig(s N_x^sig)$指数级降低到$Oig(s 	ext{ polylog} ig( N_x ig) ig)$。数值实验表明该方法可行，并成功复现了开尔文-亥姆霍兹不稳定性。

Conclusion: 量子计算有望为克服等离子体多尺度模拟的计算瓶颈提供可行的途径。

Abstract: To simulate plasma phenomena, large-scale computational resources have been
employed in developing high-precision and high-resolution plasma simulations.
One of the main obstacles in plasma simulations is the requirement of
computational resources that scale polynomially with the number of spatial
grids, which poses a significant challenge for large-scale modeling. To address
this issue, this study presents a quantum algorithm for simulating the
nonlinear electromagnetic fluid dynamics that govern space plasmas. We map it,
by applying Koopman-von Neumann linearization, to the Schr\"{o}dinger equation
and evolve the system using Hamiltonian simulation via quantum singular value
transformation. Our algorithm scales $O \left(s N_x \, \mathrm{polylog} \left(
N_x \right) T \right)$ in time complexity with $s$, $N_x$, and $T$ being the
spatial dimension, the number of spatial grid points per dimension, and the
evolution time, respectively. Comparing the scaling $O \left( s N_x^s
\left(T^{5/4}+T N_x\right) \right)$ for the classical method with the finite
volume scheme, this algorithm achieves polynomial speedup in $N_x$. The space
complexity of this algorithm is exponentially reduced from $O\left( s N_x^s
\right)$ to $O\left( s \, \mathrm{polylog} \left( N_x \right) \right)$.
Numerical experiments validate that accurate solutions are attainable with
smaller $m$ than theoretically anticipated and with practical values of $m$ and
$R$, underscoring the feasibility of the approach. As a practical
demonstration, the method accurately reproduces the Kelvin-Helmholtz
instability, underscoring its capability to tackle more intricate nonlinear
dynamics. These results suggest that quantum computing can offer a viable
pathway to overcome the computational barriers of multiscale plasma modeling.

</details>


### [360] [Resource-efficient universal photonic processor based on time-multiplexed hybrid architectures](https://arxiv.org/abs/2509.22521)
*Jonas Lammers,Laura Ares,Federico Pegoraro,Philip Held,Benjamin Brecht,Jan Sperling,Christine Silberhorn*

Main category: quant-ph

TL;DR: 本论文提出了一种基于离散时间量子行走（DTQW）的通用光子处理器实现方案，解决了量子信息处理领域对大规模、高效多端口干涉仪的需求。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理领域需要大规模、高效的多端口干涉仪作为光子处理器，而量子行走已被证明是实现通用计算的合适干涉基础。

Method: 提出了一种将任意线性变换转化为量子行走中的币（coin）和步（step）算子，并将其映射到时间复用平台实验参数的协议。

Result: 该方案具有高度可扩展性和资源效率，因为它采用了混合编码方式，结合了多个自由度。此外，实验证明该系统对实验中的不完美因素具有高度的鲁棒性，并且与现有架构相比具有优势。

Conclusion: 本研究提出的基于离散时间量子行走的通用光子处理器实现方案，在理论上和实验上都具有可行性，并解决了现有技术中的一些关键挑战。

Abstract: For the ever-growing field of quantum information processing, large-scale,
efficient multi-port interferometers serving as photonic processors are
required. In this context, the suitability of quantum walks as the
interferometric base for universal computation has been theoretically proven.
In this work, we bridge the gap between theoretical proposals and
state-of-the-art experimental capabilities by providing the recipe for the
implementation of a universal photonic processor in discrete-time quantum
walks. Specifically, we present the protocol how to translate arbitrary linear
transformations into the coin and step operator of a quantum walk and map these
to the experimental parameters of the established time-multiplexed platform. We
show that our interface is highly scalable and resource-efficient due to the
hybrid encoding consisting of multiple degrees of freedom. Finally, we prove
that our system is highly resilient against experimental imperfections and show
that it compares favorably against existing architectures.

</details>


### [361] [Constructing qubit edge states by inverse-designing the electromagnetic environment](https://arxiv.org/abs/2509.22534)
*A. Miguel-Torcal,T. F. Allard,P. A. Huidobro,F. J. García-Vidal,A. I. Fernández-Domínguez*

Main category: quant-ph

TL;DR: 我们通过逆向设计实现了一个周期性介电结构，其中包含一个相互作用的量子比特链，模拟了一个扩展的、二聚化的SSH类激发模型。该方法可以精确控制光子介导的相互作用，从而探索量子比特链中拓扑边缘态的出现。通过系统地调整结构参数以处理相干演化和耗散效应，我们证明了即使在存在长程耦合和无序的情况下，边缘态也保持稳健且与体态隔离，并在偏离完全手征对称性保留的情况下仍能保持关键的拓扑特性。这项工作突显了逆向设计在稳定拓扑激发态方面的潜力，为先进的量子技术开辟了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 探索拓扑光子学和计算优化在量子比特链中实现和稳定拓扑激发态的潜力。

Method: 通过逆向设计一个周期性介电结构，该结构包含一个相互作用的量子比特链，模拟了一个扩展的、二聚化的SSH类激发模型。通过调整结构参数来控制相干演化和耗散效应。

Result: 证明了即使在存在长程耦合和无序的情况下，拓扑边缘态也能保持稳健且与体态隔离，并能保持关键的拓扑特性。

Conclusion: 逆向设计能够有效地稳定拓扑激发态，为先进量子技术提供了新的途径。

Abstract: Building on advances in topological photonics and computational optimization,
we inversedesign a periodic dielectric structure surrounding a chain of
interacting qubits, emulating an extended, dimerized Su-Schrieffer-Heeger (SSH)
excitonic model. Our approach enables precise control over photon-mediated
interactions, allowing us to explore the emergence of topological edge states
in the qubit chain. By systematically tuning structural parameters to address
both coherent evolution and dissipative effects, we demonstrate that edge
states remain robust and isolated from the bulk, even in the presence of
long-range coupling and disorder, and preserving key topological properties
despite deviations from complete chiral symmetry preservation. This work
highlights the potential of inverse design in stabilizing topological excitonic
states, opening new possibilities for advanced quantum technologies.

</details>


### [362] [ConQuER: Modular Architectures for Control and Bias Mitigation in IQP Quantum Generative Models](https://arxiv.org/abs/2509.22551)
*Xiaocheng Zou,Shijin Duan,Charles Fleming,Gaowen Liu,Ramana Rao Kompella,Shaolei Ren,Xiaolin Xu*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum generative models based on instantaneous quantum polynomial (IQP)
circuits show great promise in learning complex distributions while maintaining
classical trainability. However, current implementations suffer from two key
limitations: lack of controllability over generated outputs and severe
generation bias towards certain expected patterns. We present a Controllable
Quantum Generative Framework, ConQuER, which addresses both challenges through
a modular circuit architecture. ConQuER embeds a lightweight controller circuit
that can be directly combined with pre-trained IQP circuits to precisely
control the output distribution without full retraining. Leveraging the
advantages of IQP, our scheme enables precise control over properties such as
the Hamming Weight distribution with minimal parameter and gate overhead. In
addition, inspired by the controller design, we extend this modular approach
through data-driven optimization to embed implicit control paths in the
underlying IQP architecture, significantly reducing generation bias on
structured datasets. ConQuER retains efficient classical training properties
and high scalability. We experimentally validate ConQuER on multiple quantum
state datasets, demonstrating its superior control accuracy and balanced
generation performance, only with very low overhead cost over original IQP
circuits. Our framework bridges the gap between the advantages of quantum
computing and the practical needs of controllable generation modeling.

</details>


### [363] [Relativistic Quantum Simulation under Periodic and Dirichlet Boundary Conditions: A First-Quantised Framework for Near-Term Devices](https://arxiv.org/abs/2509.22579)
*Jaewoo Joo,Timothy P. Spiller,Kyunghyun Baek,Jeongho Bang*

Main category: quant-ph

TL;DR: 我们提出了一种使用第一量子化方法在周期性（PBC）和狄利克雷（DBC）边界条件下进行相对论量子模拟的新方法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为在量子计算机上模拟相对论效应提供一条切实可行的途径，以支持量子物理学和化学的未来发展。

Method: 该方法将波函数离散化在由系统量子比特表示的有限网格上，并使用基于量子平移运算的有限差分法来表示平方动量算符。相对论动能通过总动量哈密顿量的微扰展开来近似，并包含高阶动量项。

Result: 该方法允许通过对合适的ansatz态进行变分优化，在量子计算机上估算非相对论和相对论基态能量。

Conclusion: 这项工作为在近期的量子设备上模拟相对论效应提供了一条实用的途径，有助于推进量子物理学和化学领域的发展。

Abstract: We present a new recipe for relativistic quantum simulation using the first
quantisation approach, under periodic (PBC) and Dirichlet (DBC) boundary
conditions. The wavefunction is discretised across a finite grid represented by
system qubits, and the squared momentum operator is expressed using the
finite-difference method based on quantum translation operations. The
relativistic kinetic energy is approximated through a perturbative expansion of
the total kinetic Hamiltonian, incorporating higher-order momentum terms. The
approach would allow variational optimisation of appropriate ansatz states to
estimate both non-relativistic and relativistic ground-state energies on a
quantum computer. This work offers a practical route to simulating relativistic
effects on near-term quantum devices, supporting future developments in quantum
physics and chemistry.

</details>


### [364] [Construction and simulability of quantum circuits with free fermions in disguise](https://arxiv.org/abs/2509.22585)
*Dávid Szász-Schagrin,Daniele Cristani,Lorenzo Piroli,Eric Vernier*

Main category: quant-ph

TL;DR: 该论文系统地构造了包含伪装自由费米子的局域量子电路，并对它们的动力学进行了研究。


<details>
  <summary>Details</summary>
Motivation: Fendley提出的模型启发，本研究旨在构造即使其Floquet算符无法通过Jordan-Wigner变换对角化，但仍具有自由费米子谱的量子电路，并研究这些电路的动力学。

Method: 利用与Floquet算符可交换的非局域传递矩阵来构造包含伪装自由费米子的局域量子电路（包括阶梯和砖墙结构），并证明某些局域可观测量在经典计算机上可以被有效模拟。

Result: 成功构造了包含伪装自由费米子的局域量子电路，并证明了某些局域可观测量可以被经典计算机有效模拟，验证了文献中的猜想。

Conclusion: 本研究成功构造了伪装自由费米子量子电路，并证明了其动力学在特定情况下的经典可模拟性，这既证实了现有的猜想，也引发了关于伪装自由费米子经典可模拟性的新问题。

Abstract: We provide a systematic construction for local quantum circuits hosting free
fermions in disguise, both with staircase and brickwork architectures. Similar
to the original Hamiltonian model introduced by Fendley, these circuits are
defined by the fact that the Floquet operator corresponding to a single time
step can not be diagonalized by means of any Jordan-Wigner transformation, but
still displays a free-fermionic spectrum. Our construction makes use of
suitable non-local transfer matrices commuting with the Floquet operator,
allowing us to establish the free fermionic spectrum. We also study the
dynamics of these circuits after they are initialized in arbitrary product
states, proving that the evolution of certain local observables can be
simulated efficiently on classical computers. Our work proves recent
conjectures in the literature and raises new questions on the classical
simulability of free fermions in disguise.

</details>


### [365] [Quantum Measurement Trees, I: Two Preliminary Examples of Induced Contextual Boolean Algebras](https://arxiv.org/abs/2509.22594)
*Peter J Hammond*

Main category: quant-ph

TL;DR: Quantum randomness cannot be explained by classical probability spaces, but can be modeled using multi-measurable spaces and a meta-space construction, inspired by examples like the double-slit experiment and Boolean probability paradoxes.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the limitations of classical probability spaces in describing quantum randomness, using examples like the double-slit experiment and a specific three-variable Boolean paradox. It proposes a novel framework using multi-measurable spaces and a meta-space construction to accommodate such phenomena.

Method: The paper proposes the use of a 'multi-measurable' space, extending Vorob'ev's concept, to handle quantum randomness. This involves constructing a measurable meta-space that combines sample space points with contextual Boolean algebras, and a family of parametric probability meta-spaces representing two-stage stochastic processes.

Result: The paper introduces a framework that can accommodate quantum randomness, illustrated by the double-slit experiment and a Boolean probability paradox. It defines a measurable meta-space and a family of probability meta-spaces to model two-stage stochastic processes.

Conclusion: Quantum randomness requires a departure from classical probability theory. The proposed framework of multi-measurable spaces and meta-spaces provides a mathematical structure capable of describing phenomena like the quantum double-slit experiment and Boolean probability paradoxes, paving the way for future work on quantum measurement trees.

Abstract: Quantum randomness evidently transcends the classical framework of random
variables defined on a single comprehensive Kolmogorov probability space. One
prominent example is the quantum double-slit experiment due to Feynman (1951,
1966). A related non-quantum example, inspired by Boole (1862) and Vorob$'$ev
(1962), has three two-valued random variables $X$, $Y$ and $Z$, where the pairs
$X, Y$ and $X, Z$ are perfectly correlated, yet $Y, Z$ are perfectly
anti-correlated. Such examples can be accommodated using a ``multi-measurable''
space with several different $ \sigma $-algebras of measurable events. This
concept due to Vorob$'$ev (1962) allows construction of: 1) a measurable
meta\-space whose elements combine a point in the original sample space with a
variable ``contextual'' Boolean algebra; 2) a parametric family of probability
meta\-spaces, each of which is a Kolmogorov probability space that represents a
two-stage stochastic process where a random choice from the original sample
space is preceded by the random choice of a contextual Boolean algebra in the
multi-measurable space. Subsequent work will explore how quantum experimental
results can be described using a quantum measurement tree with one or more
preparation nodes where an experimental configuration is determined that
governs the probability distribution of relevant quantum observables.

</details>


### [366] [Exact solutions of open quantum Brownian motions on the real line for two-level systems](https://arxiv.org/abs/2509.22604)
*Manuel D. de la Iglesia,Carlos F. Lardizabal*

Main category: quant-ph

TL;DR: 我们研究开放量子布朗运动，将其作为经典扩散过程在与外部环境相互作用下的量子类似物。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子布朗运动，将其作为经典扩散过程在与外部环境相互作用下的量子类似物。

Method: 基于 Sinayskiy 和 Petruccione [20] 的微观推导，我们重新审视了相关的元方程，并研究了其作为广义抛物线系统的表述。利用傅里叶变换方法，我们推导出了具有双能级内禀自由度的粒子的一维演化的精确解析解。

Result: 推导出一维演化的精确解析解。

Conclusion: 研究了开放量子布朗运动作为经典扩散过程在与外部环境相互作用下的量子类似物。

Abstract: We investigate open quantum Brownian motions as quantum analogues of
classical diffusion processes under interaction with an external enviroment.
Building upon the microscopic derivation by Sinayskiy and Petruccione [20], we
revisit the associated master equation and study its formulation as a
generalized parabolic system. Employing Fourier transform methods, we derive
exact analytical solutions for one-dimensional evolutions of particles with
two-level internal degree of freedom.

</details>


### [367] [Quantum Measurement Trees, II: Quantum Observables as Ortho-Measurable Functions and Density Matrices as Ortho-Probability Measures](https://arxiv.org/abs/2509.22617)
*Peter J. Hammond*

Main category: quant-ph

TL;DR: 该论文将量子态和可观测量与数学对象（正交代数、数值分解、概率测度）联系起来，并提出了一种计算测量后验概率的方法。


<details>
  <summary>Details</summary>
Motivation: 将量子态和可观测量与数学结构联系起来，并扩展玻恩法则。

Method: 将量子态表示为概率测度，将可观测量表示为正交代数上的函数或数值分解，并使用迹公式计算后验概率。

Result: 给出了量子态和可观测量的新表示方法，并能够计算测量后验概率。

Conclusion: 所提出的框架能够计算测量后验概率，并为理解量子力学提供了新的视角。

Abstract: Given a quantum state in the finite-dimensional Hilbert space $ \C^n $, the
range of possible values of a quantum observable is usually identified with the
discrete spectrum of eigenvalues of a corresponding Hermitian matrix. Here any
such observable is identified with: (i) an ``ortho-measurable'' function
defined on the Boolean ``ortho-algebra'' generated by the eigenspaces that form
an orthogonal decomposition of $ \C^n $; (ii) a ``numerically identified''
orthogonal decomposition of $ \C^n $. The latter means that each subspace of
the orthogonal decomposition can be uniquely identified by its own attached
real number, just as each eigenspace of a Hermitian matrix can be uniquely
identified by the corresponding eigenvalue. Furthermore, any density matrix on
$ \C^n $ is identified with a Bayesian prior ``ortho-probability'' measure
defined on the linear subspaces that make up the Boolean ortho-algebra induced
by its eigenspaces. Then any pure quantum state is identified with a degenerate
density matrix, and any mixed state with a probability measure on a set of
orthogonal pure states. Finally, given any quantum observable, the relevant
Bayesian posterior probabilities of measured outcomes can be found by the usual
trace formula that extends Born's rule.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [368] [Redesigning GROMACS Halo Exchange: Improving Strong Scaling with GPU-initiated NVSHMEM](https://arxiv.org/abs/2509.21527)
*Mahesh Doijade,Andrey Alekseenko,Ania Brown,Alan Gray,Szilárd Páll*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Improving time-to-solution in molecular dynamics simulations often requires
strong scaling due to fixed-sized problems. GROMACS is highly
latency-sensitive, with peak iteration rates in the sub-millisecond, making
scalability on heterogeneous supercomputers challenging. MPI's CPU-centric
nature introduces additional latencies on GPU-resident applications' critical
path, hindering GPU utilization and scalability. To address these limitations,
we present an NVSHMEM-based GPU kernel-initiated redesign of the GROMACS domain
decomposition halo-exchange algorithm. Highly tuned GPU kernels fuse data
packing and communication, leveraging hardware latency-hiding for fine-grained
overlap. We employ kernel fusion across overlapped data forwarding
communication phases and utilize the asynchronous copy engine over NVLink to
optimize latency and bandwidth. Our GPU-resident formulation greatly increases
communication-computation overlap, improving GROMACS strong scaling performance
across NVLink by up to 1.5x (intra-node) and 2x (multi-node), and up to 1.3x
multi-node over NVLink+InfiniBand. This demonstrates the profound benefits of
GPU-initiated communication for strong-scaling a broad range of
latency-sensitive applications.

</details>


### [369] [Zeppelin: Balancing Variable-length Workloads in Data Parallel Large Model Training](https://arxiv.org/abs/2509.21841)
*Chang Chen,Tiancheng Chen,Jiangfei Duan,Qianchao Zhu,Zerui Wang,Qinghao Hu,Peng Sun,Xiuhong Li,Chao Yang,Torsten Hoefler*

Main category: cs.DC

TL;DR: Zeppelin是一个新的训练系统，通过分层序列分区、路由层和重新映射层来解决LLM训练中的负载不平衡问题，平均速度提升2.80倍。


<details>
  <summary>Details</summary>
Motivation: 训练具有长而可变序列长度的大型语言模型（LLMs）会带来严重的负载不平衡挑战，现有框架忽视了计算和通信成本随序列长度的变化，导致性能不佳。

Method: Zeppelin整合了三个关键技术：1. 采用分层序列分区方法处理注意力模块，以减少通信开销并平衡计算，并辅以应用不同并行策略的高效注意力引擎；2. 引入路由层来协调节点间传输，充分利用网络接口卡（NIC）带宽；3. 增加重新映射层来转换注意力模块和线性模块之间的序列布局，确保两者的高计算效率。

Result: Zeppelin在各种配置下的综合评估显示，与最先进的方法相比，平均速度提升了2.80倍。

Conclusion: Zeppelin通过解决计算与通信比率、NIC-GPU亲和性与动态工作负载不匹配以及不同并行策略的需求等问题，显著提高了LLM训练的效率。

Abstract: Training large language models (LLMs) with increasingly long and varying
sequence lengths introduces severe load imbalance challenges in large-scale
data-parallel training. Recent frameworks attempt to mitigate these issues
through data reorganization or hybrid parallel strategies. However, they often
overlook how computational and communication costs scale with sequence length,
resulting in suboptimal performance. We identify three critical challenges: (1)
varying computation-to-communication ratios across sequences of different
lengths in distributed attention, (2) mismatch between static NIC-GPU affinity
and dynamic parallel workloads, and (3) distinct optimal partitioning
strategies required for quadratic attention versus linear components. To
address these challenges, we present Zeppelin, a novel training system that
integrates three key techniques: (1) a hierarchical sequence partitioning
method for the attention module that reduces communication overhead and
balances computation, supported by an efficient attention engine that applies
divergent parallel strategies; (2) a routing layer that orchestrates inter-node
transfers to fully utilize NIC bandwidth; and (3) a remapping layer that
transforms sequence layouts between attention and linear modules, ensuring high
computational efficiency across both. Comprehensive evaluations across diverse
configurations show that Zeppelin delivers an average 2.80x speedup over
state-of-the-art methods.

</details>


### [370] [Code once, Run Green: Automated Green Code Translation in Serverless Computing](https://arxiv.org/abs/2509.22068)
*Sebastian Werner,Mathis Kähler,Alireza Hakamian*

Main category: cs.DC

TL;DR: 服务器无服务器平台可以通过LLM自动将函数转换为更节能的语言，从而减少能源消耗。


<details>
  <summary>Details</summary>
Motivation: 数字经济的快速发展和人工智能等新兴技术的应用导致计算基础设施的排放量急剧增加。传统的缓解策略（如数据中心使用可再生能源或设计节能软件）依赖于利益相关者的干预，在现有和已部署的系统中难以实施。这导致了“能源债务”现象，即过去的架构和实现决策持续产生额外的能源消耗。

Method: 本研究提出了一种名为ReFaaS的系统，该系统利用大型语言模型（LLM）将服务器无服务器平台上的函数源代码转换为更节能的编程语言，同时保持功能正确性。ReFaaS被集成到Fission服务器无服务器框架中，并通过评估多个LLM在代码转换能力和对能耗影响方面的表现来进行评估。

Result: 研究结果表明，通过LLM翻译的函数可以将调用能耗降低高达70%。根据所使用的LLM，净节能效果大约在3,000到5,000次调用后显现。然而，该方法并非万能，并非所有函数都适合翻译，部分函数的收敛阈值较高甚至无法达到。

Conclusion: 虽然存在挑战，但研究强调了解决四个关键研究问题的重要性，以实现服务器无服务器计算中能源债务的长期自动缓解。

Abstract: The rapid digitization and the increasing use of emerging technologies such
as AI models have significantly contributed to the emissions of computing
infrastructure. Efforts to mitigate this impact typically focus on the
infrastructure level such as powering data centers with renewable energy, or
through the specific design of energy-efficient software. However, both
strategies rely on stakeholder intervention, making their adoption in legacy
and already-deployed systems unlikely. As a result, past architectural and
implementation decisions continue to incur additional energy usage - a
phenomenon we refer to as energy debt.
  Hence, in this paper, we investigate the potential of serverless computing
platforms to automatically reduce energy debt by leveraging the unique access
to function source code. Specifically, we explore whether large language models
(LLMs) can translate serverless functions into more energy-efficient
programming languages while preserving functional correctness. To this end, we
design and implement ReFaaS and integrate it into the Fission serverless
framework. We evaluate multiple LLMs on their ability to perform such code
translations and analyze their impact on energy consumption.
  Our preliminary results indicate that translated functions can reduce
invocation energy by up to 70%, achieving net energy savings after
approximately 3,000 to 5,000 invocations, depending on the LLM used.
Nonetheless, the approach faces several challenges: not all functions are
suitable for translation, and for some, the amortization threshold is
significantly higher or unreachable. Despite these limitations, we identify
four key research challenges whose resolution could unlock long-term, automated
mitigation of energy debt in serverless computing.

</details>


### [371] [The AI_INFN Platform: Artificial Intelligence Development in the Cloud](https://arxiv.org/abs/2509.22117)
*Lucio Anderlini,Giulio Bianchini,Diego Ciangottini,Stefano Dal Pra,Diego Michelotto,Rosa Petrini,Daniele Spiga*

Main category: cs.DC

TL;DR: AI_INFN项目利用云原生解决方案在INFN云上提供GPU等AI加速器资源，通过Kubernetes平台简化GPU数据分析工作流的开发和部署，并支持跨不同资源提供商（如LHC和CINECA Leonardo）的分布式计算。


<details>
  <summary>Details</summary>
Motivation: 机器学习在数据密集型软件开发中的应用带来了新的挑战，尤其是在硬件加速器的配置和编排方面。AI_INFN项目旨在通过提供专门的AI计算资源来促进INFN内部的机器学习技术应用。

Method: 构建了一个Kubernetes平台，利用Virtual Kubelet和InterLink API的卸载机制，实现跨异构分布式计算资源（包括LHC和CINECA Leonardo等超级计算中心）的GPU数据分析工作流的开发、扩展和管理。

Result: 平台已成功调试，能够管理跨不同资源提供商的工作流。初步的测试结果、案例研究和集成场景将通过功能测试和基准测试展示。

Conclusion: 该平台为需要针对不同工作负载部分使用专用基础设施的研究场景提供了一个模型，能够有效地共享硬件加速器，并支持INFN多样化的研究活动。

Abstract: Machine Learning (ML) is driving a revolution in the way scientists design,
develop, and deploy data-intensive software. However, the adoption of ML
presents new challenges for the computing infrastructure, particularly in terms
of provisioning and orchestrating access to hardware accelerators for
development, testing, and production. The INFN-funded project AI_INFN
(Artificial Intelligence at INFN) aims at fostering the adoption of ML
techniques within INFN use cases by providing support on multiple aspects,
including the provisioning of AI-tailored computing resources. It leverages
cloud-native solutions in the context of INFN Cloud, to share hardware
accelerators as effectively as possible, ensuring the diversity of the
Institute's research activities is not compromised. In this contribution, we
provide an update on the commissioning of a Kubernetes platform designed to
ease the development of GPU-powered data analysis workflows and their
scalability on heterogeneous distributed computing resources, also using the
offloading mechanism with Virtual Kubelet and InterLink API. This setup can
manage workflows across different resource providers, including sites of the
Worldwide LHC Computing Grid and supercomputers such as CINECA Leonardo,
providing a model for use cases requiring dedicated infrastructures for
different parts of the workload. Initial test results, emerging case studies,
and integration scenarios will be presented with functional tests and
benchmarks.

</details>


### [372] [Orientation does not help with 3-coloring a grid in online-LOCAL](https://arxiv.org/abs/2509.22233)
*Thomas Boudier,Filippo Casagrande,Avinandan Das,Massimo Equi,Henrik Lievonen,Augusto Modanese,Ronja Stimpert*

Main category: cs.DC

TL;DR: 在具有全局网格方向的情况下，在线局部图着色问题（包括确定性和随机化算法）仍然需要对数级别的局部性。


<details>
  <summary>Details</summary>
Motivation: 在已知算法不访问网格方向的情况下，确定性和随机化在线局部图3着色问题已获得对数级别局部性的下界。本研究旨在消除对网格方向访问的限制，以获得相同的下界。

Method: 通过证明即使在给定全局一致的网格方向的情况下，也存在对数级别的局部性下界，从而将先前仅适用于无方向网格的结果进行扩展。

Result: 证明了在给定全局网格方向的情况下，确定性和随机化在线局部图3着色问题仍然需要对数级别的局部性。

Conclusion: 本研究成功地将先前仅适用于无方向网格的对数级别局部性下界扩展到了具有全局网格方向的情况，表明方向信息并不能消除在线局部图3着色问题的基本局部性要求。

Abstract: The online-LOCAL and SLOCAL models are extensions of the LOCAL model where
nodes are processed in a sequential but potentially adversarial order. So far,
the only problem we know of where the global memory of the online-LOCAL model
has an advantage over SLOCAL is 3-coloring bipartite graphs. Recently, Chang et
al. [PODC 2024] showed that even in grids, 3-coloring requires $\Omega(\log n)$
locality in deterministic online-LOCAL. This result was subsequently extended
by Akbari et al. [STOC 2025] to also hold in randomized online-LOCAL. However,
both proofs heavily rely on the assumption that the algorithm does not have
access to the orientation of the underlying grid. In this paper, we show how to
lift this requirement and obtain the same lower bound (against either model)
even when the algorithm is explicitly given a globally consistent orientation
of the grid.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [373] [New Algorithmic Directions in Optimal Transport and Applications for Product Spaces](https://arxiv.org/abs/2509.21502)
*Salman Beigi,Omid Etesami,Mohammad Mahmoody,Amir Najafi*

Main category: cs.DS

TL;DR: 我们提出了一个算法，可以在多项式时间内将高维分布在 L_p^p 范数下进行最优传输，其中计算成本与维度相关，并且可以控制计算误差。


<details>
  <summary>Details</summary>
Motivation: 从算法角度研究高维分布之间的最优传输问题，旨在找到一个高效的算法，其运行时间依赖于数据的维度而非其表示的大小。

Method: 提出了一种通用的最优传输算法，适用于任何乘积分布到任何“顺序可采样”的分布，并能在 L_p^p 范数下实现接近最优传输成本的传输，同时引入了计算误差项。

Result: 1. 证明了一个 Talagrand 不等式的算法版本，用于将标准高斯分布传输到任意分布。 2. 对于标准高斯分布在给定集合 S 上的条件分布，设计了一个顺序采样器，并实现了高效传输，传输距离接近最优。 3. 得到了高斯测度下的计算浓度结果，解决了 Etesami 等人提出的一个开放性问题。

Conclusion: 该研究为高维分布的最优传输问题提供了有效的算法解决方案，并在理论上取得了多项重要进展，特别是在高斯分布的传输和计算浓度方面。

Abstract: We study optimal transport between two high-dimensional distributions
$\mu,\nu$ in $R^n$ from an algorithmic perspective: given $x \sim \mu$, find a
close $y \sim \nu$ in $poly(n)$ time, where $n$ is the dimension of $x,y$.
Thus, running time depends on the dimension rather than the full representation
size of $\mu,\nu$. Our main result is a general algorithm for transporting any
product distribution $\mu$ to any $\nu$ with cost $\Delta + \delta$ under
$\ell_p^p$, where $\Delta$ is the Knothe-Rosenblatt transport cost and $\delta$
is a computational error decreasing with runtime. This requires $\nu$ to be
"sequentially samplable" with bounded average sampling cost, a new but natural
notion.
  We further prove:
  An algorithmic version of Talagrand's inequality for transporting the
standard Gaussian $\Phi^n$ to arbitrary $\nu$ under squared Euclidean cost. For
$\nu = \Phi^n$ conditioned on a set $\mathcal{S}$ of measure $\varepsilon$, we
construct the sequential sampler in expected time $poly(n/\varepsilon)$ using
membership oracle access to $\mathcal{S}$. This yields an algorithmic transport
from $\Phi^n$ to $\Phi^n|\mathcal{S}$ in $poly(n/\varepsilon)$ time and
expected squared distance $O(\log 1/\varepsilon)$, optimal for general
$\mathcal{S}$ of measure $\varepsilon$.
  As corollary, we obtain the first computational concentration result (Etesami
et al. SODA 2020) for Gaussian measure under Euclidean distance with
dimension-independent transportation cost, resolving an open question of
Etesami et al. Specifically, for any $\mathcal{S}$ of Gaussian measure
$\varepsilon$, most $\Phi^n$ samples can be mapped to $\mathcal{S}$ within
distance $O(\sqrt{\log 1/\varepsilon})$ in $poly(n/\varepsilon)$ time.

</details>


### [374] [New Parallel and Streaming Algorithms for Directed Densest Subgraph](https://arxiv.org/abs/2509.21729)
*Slobodan Mitrović,Theodore Pan,Mahdi Qaempanah,Mohammad Amin Raeisi*

Main category: cs.DS

TL;DR: 本研究提出了一种在两种计算模型（MPC和半流）中寻找有向图中近似最密集子图的算法。


<details>
  <summary>Details</summary>
Motivation: 在处理海量数据时，寻找密集子图是一个基本问题，广泛应用于社区检测、聚类和数据挖掘。本研究旨在解决计算模型中近似最密集子图的挑战。

Method: 研究在MPC模型下使用亚线性内存和~O(sqrt(log n))轮找到(2+ε)-近似值。在半流模型下，研究提出了一种单遍算法，可以找到O(log n)-近似值，并且是第一个确定性的单遍半流算法。该算法还是一种插入式动态算法，具有O(log^2 n)的最坏情况更新时间，并使用亚线性内存。

Result: 在MPC模型中，本研究的结果比现有技术有所改进。在半流模型中，单遍算法的近似效果远超理论保证，与多轮算法的近似效果相当。MPC算法所需的轮数也少于现有方法。

Conclusion: 本研究成功地为MPC和半流模型中的近似最密集子图问题开发了高效的确定性算法，并在理论和实验上都取得了显著的改进。

Abstract: Finding dense subgraphs is a fundamental problem with applications to
community detection, clustering, and data mining. Our work focuses on finding
approximate densest subgraphs in directed graphs in computational models for
processing massive data. We consider two such models: Massively Parallel
Computation (MPC) and semi-streaming. We show how to find a
$(2+\varepsilon)$-approximation in $\tilde{O}(\sqrt{\log n})$ MPC rounds with
sublinear memory per machine. This improves the state-of-the-art results by
Bahmani et al. (WAW 2014) and Mitrovi\'c & Pan (ICML 2024). Moreover, we show
how to find an $O(\log n)$-approximation in a single pass in semi-streaming.
This is in stark contrast to prior work, which implies
$\tilde{\Omega}(n^{1/6})$-approximation for a single pass; a better
approximation is known only for randomized streams (Mitrovi\'c & Pan). This is
the first deterministic single-pass semi-streaming algorithm for the densest
subgraph problem, both for undirected and directed graphs. Our semi-streaming
approach is also an insertion-only dynamic algorithm, attaining the first
directed densest subgraph algorithm with $O(\log^2 n)$ worst-case update time
while using sub-linear memory. We empirically evaluate our approaches in two
ways. First, we illustrate that our single-pass semi-streaming algorithm
performs much better than the theoretical guarantee. Specifically, its
approximation on temporal datasets matches the $(2+\varepsilon)$-approximation
of an $O(\log n)$-pass algorithm by Bahmani et al. (VLDB 2012). Second, we
demonstrate that our MPC algorithm requires fewer rounds than prior work.

</details>


### [375] [Stable coresets: Unleashing the power of uniform sampling](https://arxiv.org/abs/2509.22189)
*Amir Carmel,Robert Krauthgamer*

Main category: cs.DS

TL;DR: Uniform sampling can create effective 'stable coresets' for clustering, offering a balance between strong and weak coresets. This method is efficient and works well for various metrics, including 1-median in high-dimensional spaces.


<details>
  <summary>Details</summary>
Motivation: The effectiveness of uniform sampling for creating coresets in clustering problems was not well understood, as it generally doesn't produce strong coresets. The paper aims to bridge this gap by introducing the concept of stable coresets.

Method: The paper introduces 'stable coresets,' an intermediate notion between weak and strong coresets. It uses uniform sampling to construct these stable coresets, specifically showing that a sample of size O(epsilon^-2 log d) yields a stable coreset for 1-median in R^d under the l_1 metric. This concept is then extended to other metrics and applications.

Result: A uniform sample of size O(epsilon^-2 log d) yields a stable coreset for 1-median in R^d (l_1 metric) with high probability. The paper also derives new coreset constructions for related metrics and demonstrates applications in fair clustering and approximation algorithms for k-median problems. Experiments confirm the practical benefits of stable coresets.

Conclusion: Stable coresets, constructible via uniform sampling, offer an efficient and effective approach to coreset generation for various clustering problems and metrics, outperforming existing methods in practice.

Abstract: Uniform sampling is a highly efficient method for data summarization.
However, its effectiveness in producing coresets for clustering problems is not
yet well understood, primarily because it generally does not yield a strong
coreset, which is the prevailing notion in the literature. We formulate
\emph{stable coresets}, a notion that is intermediate between the standard
notions of weak and strong coresets, and effectively combines the broad
applicability of strong coresets with highly efficient constructions, through
uniform sampling, of weak coresets. Our main result is that a uniform sample of
size $O(\epsilon^{-2}\log d)$ yields, with high constant probability, a stable
coreset for $1$-median in $\mathbb{R}^d$ under the $\ell_1$ metric. We then
leverage the powerful properties of stable coresets to easily derive new
coreset constructions, all through uniform sampling, for $\ell_1$ and related
metrics, such as Kendall-tau and Jaccard. We also show applications to fair
clustering and to approximation algorithms for $k$-median problems in these
metric spaces. Our experiments validate the benefits of stable coresets in
practice, in terms of both construction time and approximation quality.

</details>


### [376] [Less is More: Faster Maximum Clique Search by Work-Avoidance](https://arxiv.org/abs/2509.22245)
*Hans Vandierendonck*

Main category: cs.DS

TL;DR: 该研究提出优化最大团（MC）搜索的技术，可显著提升搜索效率。


<details>
  <summary>Details</summary>
Motivation: 最大团（MC）问题因其NP难性质，计算成本高昂。本研究旨在高效地确定搜索空间的某部分不包含最大团，从而跳过大量搜索空间。

Method: 提出了一系列优化MC搜索的技术，包括：1.高效的、惰性构建的图表示；2.详细搜索前的过滤；3.高效的提前退出交集算法；4.利用算法选择。

Result: 与最可比的算法PMC相比，速度提高了38.9倍；与MC-BRB相比，速度提高了11倍。

Conclusion: 所提出的技术能够有效地优化最大团搜索，显著减少计算时间。

Abstract: The maximum clique (MC) problem is a challenging graph mining problem which,
due to its NP-hard nature, can take a substantial amount of execution time. The
MC problem is dominated by set intersection operations similar to Maximal
Clique Enumeration, however it differs in requiring to find only a clique of
maximum size. As such, key to the problem is to demonstrate efficiently that a
particular part of the search space does not contain a maximum clique, allowing
to skip over major parts of the search space. We present a number of techniques
to optimize MC search in light of leaving major parts of the search space
unvisited, including (i) an efficient, lazily constructed graph representation;
(ii) filtering prior to initiating a detailed search; (iii) efficient
early-exit intersection algorithms; (iv) exploiting algorithmic choice. These
techniques result in a speedup of up to 38.9x compared to PMC, which is the
most comparable algorithm, and a speedup up to 11x over MC-BRB.

</details>


### [377] [Online Firefighting on Cactus Graphs](https://arxiv.org/abs/2509.22277)
*Max Hugen,Bob Krekelberg,Alison Hsiang-Hsuan Liu*

Main category: cs.DS

TL;DR: 在包含环的图上，在线消防问题至少是 $\Omega(\sqrt{n})$-竞争的。但对于最多包含一个环的图（1-几乎树）和仙人掌图，存在 $O(\sqrt{n})$-竞争算法。当消防员成对释放时，竞争复杂度降至 3。


<details>
  <summary>Details</summary>
Motivation: 研究在线消防问题在包含环的图上的竞争性能，并与树上的已知结果进行比较。

Method: 提出一个充电框架，将最优解所拯救的顶点分配给算法所拯救的顶点，以分析算法的竞争比。

Result: 证明在蝌蚪图（环带尾部路径）上，确定性在线算法的竞争比至少为 $\Omega(\sqrt{n})$。提出一个 $O(\sqrt{n})$-竞争算法，用于 1-几乎树和仙人掌图。证明在消防员成对释放时，该问题最多为 3-竞争。

Conclusion: 在线消防问题在包含环的图上的竞争复杂度比树上要高。所提出的充电框架有助于分析在算法和最优解操作不同残余图的情况下算法的性能。

Abstract: It is known that the online firefighting is 2-competitive on trees
(Coupechoux et al. 2016), which suggests that the problem is relatively easy on
trees. We extend the study to graphs containing cycles. We first show that the
presence of cycles gives a strong advantage to the adversary: cycles create
situations where the algorithm and the optimal solution operate on different
game states, and the adversary can exploit the uncertainty in the firefighter
sequence to trap the algorithm. Specifically, we prove that even on a tadpole
graph (a cycle with a tail path), no deterministic online algorithm achieves a
competitive ratio better than $\Omega(\sqrt{n})$, where n is the number of
vertices. We then propose an $O(\sqrt{n})$-competitive algorithm for 1-almost
trees, which contain at most one cycle and generalize tadpole graphs. We
further generalize this algorithm to cactus graphs, in which multiple cycles
may appear, but no two share more than one vertex, and show that the online
firefighting problem on cactus graphs remains $O(\sqrt{n})$-competitive.
Finally, since cactus graphs have treewidth at most 2, we study a variant where
firefighters are released in pairs, that is, each round an even number of
firefighters is available. Surprisingly, in this setting the competitive
complexity is significantly reduced, and we prove that the problem is at most
3-competitive.
  The main technical challenges lie in both algorithm design and analysis,
since the algorithm and the optimal solution may break different cycles and
thus operate on different residual graphs. To overcome this difficulty, we
design a charging framework that carefully partitions the vertices saved by the
optimal solution and charges them to the vertices saved by the algorithm.
Namely, the charging scheme is carefully constructed to ensure that each vertex
saved by the algorithm is charged at most a constant number of times.

</details>


### [378] [Fine-Grained Classification Of Detecting Dominating Patterns](https://arxiv.org/abs/2509.22332)
*Jonathan Dransfeld,Marvin Künnemann,Mirza Redzic*

Main category: cs.DS

TL;DR: 该研究提出了一个名为“支配 P-模式”的新图论概念，并试图为所有可能的模式图 P 分类其检测的细粒度复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在特定模式图（如团、匹配、独立集、环和路径）的支配 P-模式，并取得了相应的算法和条件下界。然而，对于所有可能的模式图 P，缺乏一个统一的细粒度复杂性分类。本文旨在填补这一空白，并提出一个与模式图 P 相关的参数 $\rho(P)$ 来量化检测支配 P-模式的计算复杂度。

Method: 作者定义了一个图参数 $\rho(P)$，并证明了在 Orthogonal Vectors Hypothesis 和 $\omega=2$ 的假设下，对于除三角形 $K_3$ 之外的所有模式图 P，检测支配 P-模式的最优运行时间可以表示为 $(n^{\rho(P)} m^{\frac{|V(P)|-\rho(P)}{2}})^{1\pm o(1)}$。其中，G 是宿主图，具有 n 个顶点和 m 条边（$m=\Theta(n^\alpha)$，其中 $1\le \alpha \le 2$）。参数 $\rho(P)$ 与 Alon 在 1981 年提出的用于量化诱导子图 P 出现次数最大值的参数 $\delta(P)$ 密切相关。

Result: 研究提出了一个通用的框架，用于分析检测支配 P-模式的计算复杂度，并给出了一个依赖于模式图 P 的参数 $\rho(P)$ 的最优运行时间估计。这个结果在 Orthogonal Vectors Hypothesis 和 $\omega=2$ 的假设下成立，并且对于除 $K_3$ 之外的所有模式图 P 都适用。

Conclusion: 该研究成功地为检测支配 P-模式的细粒度复杂性提供了一个统一的分类，这与之前仅限于特定模式图的研究形成对比。所提出的参数 $\rho(P)$ 是理解和分析这类问题的关键。与检测任意（非支配）诱导子图 P 的情况不同，该研究为支配 P-模式提供了一个完整的细粒度分类。

Abstract: We consider the following generalization of dominating sets: Let $G$ be a
host graph and $P$ be a pattern graph $P$. A dominating $P$-pattern in $G$ is a
subset $S$ of vertices in $G$ that (1) forms a dominating set in $G$ \emph{and}
(2) induces a subgraph isomorphic to $P$. The graph theory literature studies
the properties of dominating $P$-patterns for various patterns $P$, including
cliques, matchings, independent sets, cycles and paths. Previous work
(Kunnemann, Redzic 2024) obtains algorithms and conditional lower bounds for
detecting dominating $P$-patterns particularly for $P$ being a $k$-clique, a
$k$-independent set and a $k$-matching. Their results give conditionally tight
lower bounds if $k$ is sufficiently large (where the bound depends the matrix
multiplication exponent $\omega$). We ask: Can we obtain a classification of
the fine-grained complexity for \emph{all} patterns $P$?
  Indeed, we define a graph parameter $\rho(P)$ such that if $\omega=2$, then
\[ \left(n^{\rho(P)} m^{\frac{|V(P)|-\rho(P)}{2}}\right)^{1\pm o(1)} \] is the
optimal running time assuming the Orthogonal Vectors Hypothesis, for all
patterns $P$ except the triangle $K_3$. Here, the host graph $G$ has $n$
vertices and $m=\Theta(n^\alpha)$ edges, where $1\le \alpha \le 2$.
  The parameter $\rho(P)$ is closely related (but sometimes different) to a
parameter $\delta(P) = \max_{S\subseteq V(P)} |S|-|N(S)|$ studied in (Alon
1981) to tightly quantify the maximum number of occurrences of induced
subgraphs isomorphic to $P$. Our results stand in contrast to the lack of a
full fine-grained classification of detecting an arbitrary (not necessarily
\emph{dominating}) induced $P$-pattern.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [379] [Message passing for epidemiological interventions on networks with loops](https://arxiv.org/abs/2509.21596)
*Erik Weis,Laurent Hébert-Dufresne,Jean-Gabriel Young*

Main category: cs.SI

TL;DR: 经典消息传递方法倾向于高估真实网络中的疫情规模，而邻域消息传递（NMP）框架可以改进这些估计，并用于解决诸如影响力最大化、最优疫苗接种和哨兵监测等干预设计问题。


<details>
  <summary>Details</summary>
Motivation: 设计干预措施，例如优化疫苗接种或废水监测系统，需要比较各种反事实情况下的结果。虽然消息传递效率很高，但会高估疫情规模。

Method: 使用邻域消息传递（NMP）框架来改进流行病学计算，并评估其质量。

Result: NMP框架改进了对疫情规模的估计，并可用于测试三种干预设计问题（影响力最大化、最优疫苗接种和哨兵监测）的解决方案。

Conclusion: NMP框架能够改进估计，并为解决网络上的干预设计问题提供有价值的工具。

Abstract: Spreading models capture key dynamics on networks, such as cascading failures
in economic systems, (mis)information diffusion, and pathogen transmission.
Here, we focus on design intervention problems -- for example, designing
optimal vaccination rollouts or wastewater surveillance systems -- which can be
solved by comparing outcomes under various counterfactuals. A leading approach
to computing these outcomes is message passing, which allows for the rapid and
direct computation of the marginal probabilities for each node. However,
despite its efficiency, classical message passing tends to overestimate
outbreak sizes on real-world networks, leading to incorrect predictions and,
thus, interventions. Here, we improve these estimates by using the neighborhood
message passing (NMP) framework for the epidemiological calculations. We
evaluate the quality of the improved algorithm and demonstrate how it can be
used to test possible solutions to three intervention design problems:
influence maximization, optimal vaccination, and sentinel surveillance.

</details>


### [380] [Attributed Hypergraph Generation with Realistic Interplay Between Structure and Attributes](https://arxiv.org/abs/2509.21838)
*Jaewan Chun,Seokbum Yoon,Minyoung Choe,Geon Lee,Kijung Shin*

Main category: cs.SI

TL;DR: 该研究提出了一个名为NoAH的随机超图生成模型，用于处理包含节点属性的超图，并引入了NoAHFit参数学习程序来复制真实世界的超图。


<details>
  <summary>Details</summary>
Motivation: 现有超图生成模型未能考虑节点属性在超边形成中的作用，导致无法反映结构和节点属性之间的相互作用。

Method: NoAH模型利用核心-节点层次结构，将超边形成建模为一系列节点附加过程，并基于节点属性确定附加概率。NoAHFit用于学习模型参数。

Result: 在九个不同领域的数据集上的实验表明，NoAH结合NoAHFit比八个基线模型更能准确地复制真实世界超图中的结构-属性相互作用，在六个指标上表现更优。

Conclusion: NoAH模型及其参数学习程序NoAHFit能够有效地捕捉和复制带有节点属性的超图中的结构-属性相互作用，优于现有的超图生成模型。

Abstract: In many real-world scenarios, interactions happen in a group-wise manner with
multiple entities, and therefore, hypergraphs are a suitable tool to accurately
represent such interactions. Hyperedges in real-world hypergraphs are not
composed of randomly selected nodes but are instead formed through structured
processes. Consequently, various hypergraph generative models have been
proposed to explore fundamental mechanisms underlying hyperedge formation.
However, most existing hypergraph generative models do not account for node
attributes, which can play a significant role in hyperedge formation. As a
result, these models fail to reflect the interactions between structure and
node attributes. To address the issue above, we propose NoAH, a stochastic
hypergraph generative model for attributed hypergraphs. NoAH utilizes the
core-fringe node hierarchy to model hyperedge formation as a series of node
attachments and determines attachment probabilities based on node attributes.
We further introduce NoAHFit, a parameter learning procedure that allows NoAH
to replicate a given real-world hypergraph. Through experiments on nine
datasets across four different domains, we show that NoAH with NoAHFit more
accurately reproduces the structure-attribute interplay observed in the
real-world hypergraphs than eight baseline hypergraph generative models, in
terms of six metrics.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [381] [Cycle is All You Need: More Is Different](https://arxiv.org/abs/2509.21340)
*Xin Li*

Main category: cs.NE

TL;DR: 记忆和意识的基本机制是循环闭合，记忆是重新进入神经状态空间中的潜在循环的能力，而意识是跨上下文整合和区分高阶不变量的持续性。


<details>
  <summary>Details</summary>
Motivation: 提出一个信息-拓扑框架，将循环闭合作为记忆和意识的基础机制。

Method: 使用点-循环二分法来区分瞬态点和非平凡循环，通过延迟锁定尖峰和STDP来实现1-循环，并通过theta-gamma节律实现边界抵消，利用藻sheaf-cosheaf对偶形式化过程，将感知片段粘合到全局，将全局分解为动作。

Result: 瞬态点促进探索，非平凡循环编码低熵内容不变量以稳定记忆。微循环分层构成，将导航循环扩展到一般记忆和认知。感知-行动循环引入高阶不变性，即使在跨越感觉-行动交替时也能保持闭合。

Conclusion: 循环是您所需要的一切：持久的不变量能够在非遍历环境中实现泛化，并以最小的能量成本实现长期的连贯性。

Abstract: We propose an information-topological framework in which cycle closure is the
fundamental mechanism of memory and consciousness. Memory is not a static store
but the ability to re-enter latent cycles in neural state space, with invariant
cycles serving as carriers of meaning by filtering order-specific noise and
preserving what persists across contexts. The dot-cycle dichotomy captures
this: transient dots scaffold exploration, while nontrivial cycles encode
low-entropy content invariants that stabilize memory. Biologically,
polychronous neural groups realize 1-cycles through delay-locked spiking
reinforced by STDP, nested within theta-gamma rhythms that enforce boundary
cancellation. These micro-cycles compose hierarchically, extending navigation
loops into general memory and cognition. The perception-action cycle introduces
high-order invariance: closure holds even across sense-act alternations,
generalizing ancestral homing behavior. Sheaf-cosheaf duality formalizes this
process: sheaves glue perceptual fragments into global sections, cosheaves
decompose global plans into actions and closure aligns top-down predictions
with bottom-up cycles. Consciousness then arises as the persistence of
high-order invariants that integrate (unity) yet differentiate (richness)
across contexts. We conclude that cycle is all you need: persistent invariants
enable generalization in non-ergodic environments with long-term coherence at
minimal energetic cost.

</details>


### [382] [From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification](https://arxiv.org/abs/2509.21341)
*Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi*

Main category: cs.NE

TL;DR: 该研究提出了一种名为SPFP-MEGP的符号代理建模方法，用于压缩和解释Transformer模型，并生成可校准概率的分类器。


<details>
  <summary>Details</summary>
Motivation: 现有的大型Transformer模型虽然性能强大，但通常是黑箱模型，难以解释且计算成本高。本研究旨在通过符号代理建模，创建更小、可解释且概率校准的分类器。

Method: 1. 使用SPFP（语义保留特征划分）技术，将预训练模型（ModernBERT, DINOv2, SigLIP）的冻结嵌入在训练集上划分为不相交但信息保留的视图。 2. 利用MEGP（多群体遗传规划）算法，在这些视图上学习加性、闭式logit程序。 3. 使用留一法（one-standard-error rule）和简洁性（parsimony）作为决策依据，在验证集上选择最优模型。 4. 通过温度缩放（temperature scaling）进一步优化测试集上的ECE指标。

Result: 在SST2G, 20NG, MNIST, CIFAR10, MSC17等五个基准测试中，SPFP-MEGP代理模型在多个指标上表现出色，尤其在MNIST, CIFAR10, MSC17上F1分数接近0.99，SST2G上约为0.95，而20NG仍然是最具挑战性的数据集。研究还提供了可靠性图、维度使用和重叠统计、贡献度重要性以及全局影响剖面图（PDP和ALE），证明了模型解释的忠实性和跨模态性。

Conclusion: SPFP-MEGP方法能够成功地从冻结的Transformer嵌入中学习到紧凑、可解释且具有良好泛化能力的代理分类器，并提供深入的、基于显式程序的模型解释。

Abstract: We study symbolic surrogate modeling of frozen Transformer embeddings to
obtain compact, auditable classifiers with calibrated probabilities. For five
benchmarks (SST2G, 20NG, MNIST, CIFAR10, MSC17), embeddings from ModernBERT,
DINOv2, and SigLIP are partitioned on the training set into disjoint,
information-preserving views via semantic-preserving feature partitioning
(SPFP). A cooperative multi-population genetic program (MEGP) then learns
additive, closed-form logit programs over these views. Across 30 runs per
dataset we report F1, AUC, log-loss, Brier, expected calibration error (ECE),
and symbolic complexity; a canonical model is chosen by a one-standard-error
rule on validation F1 with a parsimony tie-break. Temperature scaling fitted on
validation yields substantial ECE reductions on test. The resulting surrogates
achieve strong discrimination (up to F1 around 0.99 on MNIST, CIFAR10, MSC17;
around 0.95 on SST2G), while 20NG remains most challenging. We provide
reliability diagrams, dimension usage and overlap statistics,
contribution-based importances, and global effect profiles (PDP and ALE),
demonstrating faithful, cross-modal explanations grounded in explicit programs.

</details>


### [383] [SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph](https://arxiv.org/abs/2509.21342)
*Huizhe Zhang,Jintang Li,Yuchang Zhu,Liang Chen,Li Kuang*

Main category: cs.NE

TL;DR: SGNNs are a promising energy-efficient alternative to GNNs for large-scale graphs, but a systematic benchmark is needed. SGNNBench provides this benchmark, evaluating 9 state-of-the-art SGNNs across 18 datasets, analyzing their effectiveness, energy efficiency, and architectural design, and revealing energy bottlenecks.


<details>
  <summary>Details</summary>
Motivation: The trend of developing complex GNNs for graph representation learning is unsustainable on large-scale graphs due to computational and time overhead. Energy-efficient GNNs, specifically Spiking Graph Neural Networks (SGNNs), are needed to cope with the growth of real-world graphs.

Method: SGNNBench conducts an in-depth investigation of SGNNs from multiple perspectives, including effectiveness, energy efficiency, and architectural design. It comprehensively evaluates 9 state-of-the-art SGNNs across 18 datasets. It empirically compares baselines w.r.t. model size, memory usage, and theoretical energy consumption. It also investigates the design space of SGNNs.

Result: SGNNBench reveals the often-overlooked energy bottlenecks of SGNNs and promotes the development of a general SGNN paradigm through an elaborate investigation of their design space.

Conclusion: SGNNBench provides a systematic benchmark for SGNNs, facilitating progress in the field by quantifying performance and guiding future research towards more effective and energy-efficient SGNN designs.

Abstract: Graph Neural Networks (GNNs) are exemplary deep models designed for graph
data. Message passing mechanism enables GNNs to effectively capture graph
topology and push the performance boundaries across various graph tasks.
However, the trend of developing such complex machinery for graph
representation learning has become unsustainable on large-scale graphs. The
computational and time overhead make it imperative to develop more
energy-efficient GNNs to cope with the explosive growth of real-world graphs.
Spiking Graph Neural Networks (SGNNs), which integrate biologically plausible
learning via unique spike-based neurons, have emerged as a promising
energy-efficient alternative. Different layers communicate with sparse and
binary spikes, which facilitates computation and storage of intermediate graph
representations. Despite the proliferation of SGNNs proposed in recent years,
there is no systematic benchmark to explore the basic design principles of
these brain-inspired networks on the graph data. To bridge this gap, we present
SGNNBench to quantify progress in the field of SGNNs. Specifically, SGNNBench
conducts an in-depth investigation of SGNNs from multiple perspectives,
including effectiveness, energy efficiency, and architectural design. We
comprehensively evaluate 9 state-of-the-art SGNNs across 18 datasets. Regarding
efficiency, we empirically compare these baselines w.r.t model size, memory
usage, and theoretical energy consumption to reveal the often-overlooked energy
bottlenecks of SGNNs. Besides, we elaborately investigate the design space of
SGNNs to promote the development of a general SGNN paradigm.

</details>


### [384] [Neuromorphic Deployment of Spiking Neural Networks for Cognitive Load Classification in Air Traffic Control](https://arxiv.org/abs/2509.21345)
*Jiahui An,Chonghao Cai,Olympia Gallou,Sara Irina Fabrikant,Giacomo Indiveri,Elisa Donati*

Main category: cs.NE

TL;DR: 该研究提出了一种用于在真实世界的空中交通管制（ATC）任务中进行认知负荷分类的神经形态系统，该系统采用了脉冲神经网络（SNN）的硬件实现。


<details>
  <summary>Details</summary>
Motivation: 为了在真实世界的空中交通管制（ATC）任务中实现认知负荷的实时监测，需要开发一种低功耗、嵌入式的神经形态系统。

Method: 研究人员使用了公开数据集中的脑电图（EEG）和眼动追踪特征，训练了传统的机器学习模型和SNN。他们探索了几种SNN架构，并使用一种生物启发的 delta-rule 学习算法训练了一个简单的单层模型。该模型随后被量化并部署在 DYNAP-SE 神经形态芯片上，使用基于脉冲的输入进行评估。

Result: 最小化的单层SNN模型在训练中达到了80.6%的分类准确率。尽管存在硬件限制和模拟变异性，但在DYNAP-SE芯片上部署的模型使用基于脉冲的输入仍能达到高达73.5%的准确率。

Conclusion: 该研究证明了事件驱动的神经形态系统在动态真实世界场景中实现超低功耗、嵌入式认知状态监测的可行性。

Abstract: This paper presents a neuromorphic system for cognitive load classification
in a real-world setting, an Air Traffic Control (ATC) task, using a hardware
implementation of Spiking Neural Networks (SNNs). Electroencephalogram (EEG)
and eye-tracking features, extracted from an open-source dataset, were used to
train and evaluate both conventional machine learning models and SNNs. Among
the SNN architectures explored, a minimalistic, single-layer model trained with
a biologically inspired delta-rule learning algorithm achieved competitive
performance (80.6%). To enable deployment on neuromorphic hardware, the model
was quantized and implemented on the mixed-signal DYNAP-SE chip. Despite
hardware constraints and analog variability, the chip-deployed SNN maintained a
classification accuracy of up to 73.5% using spike-based input. These results
demonstrate the feasibility of event-driven neuromorphic systems for
ultra-low-power, embedded cognitive state monitoring in dynamic real-world
scenarios.

</details>


### [385] [Spiking Neural Networks for Mental Workload Classification with a Multimodal Approach](https://arxiv.org/abs/2509.21346)
*Jiahui An,Sara Irina Fabrikant,Giacomo Indiveri,Elisa Donati*

Main category: cs.NE

TL;DR: 基于SNN的认知负荷检测


<details>
  <summary>Details</summary>
Motivation: 准确评估心理负荷对于认知神经科学、人机交互和实时监控至关重要，因为认知负荷的波动会影响表现和决策。基于EEG的机器学习模型可以用于此目的，但其高计算成本阻碍了嵌入式实时应用。

Method: 比较了各种传统机器学习模型和硬件兼容的SNN模型，并使用了开源多模态数据集。

Result: 结果表明，多模态集成提高了准确性，SNN的性能与ML相当，证明了其在认知负荷检测实时实现的潜力。

Conclusion: 研究结果表明，事件驱动处理为适应性闭环嵌入式设备中的低延迟、高能效负荷监测提供了一种有前途的解决方案，这些设备可以动态调节认知负荷。

Abstract: Accurately assessing mental workload is crucial in cognitive neuroscience,
human-computer interaction, and real-time monitoring, as cognitive load
fluctuations affect performance and decision-making. While
Electroencephalography (EEG) based machine learning (ML) models can be used to
this end, their high computational cost hinders embedded real-time
applications. Hardware implementations of spiking neural networks (SNNs) offer
a promising alternative for low-power, fast, event-driven processing. This
study compares hardware compatible SNN models with various traditional ML ones,
using an open-source multimodal dataset. Our results show that multimodal
integration improves accuracy, with SNN performance comparable to the ML one,
demonstrating their potential for real-time implementations of cognitive load
detection. These findings position event-based processing as a promising
solution for low-latency, energy efficient workload monitoring in adaptive
closed-loop embedded devices that dynamically regulate cognitive load.

</details>


### [386] [Domain-Informed Genetic Superposition Programming: A Case Study on SFRC Beams](https://arxiv.org/abs/2509.21355)
*Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi*

Main category: cs.NE

TL;DR: DIGSP是一种用于工程系统的符号回归框架，通过分离物理机制，独立进化GP种群，并利用自适应分层符号抽象机制（AHSAM）进行符号叠加，在SFRC梁数据集上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 为受可分离物理机制控制的工程系统提供一种领域信息驱动的符号回归方法，以提高建模的准确性和可解释性。

Method: DIGSP将输入空间划分为特定领域的特征子集，为每个子集演化独立的遗传编程（GP）种群。在独立进化后，通过集成适应度促进种群间的协作。当所有种群停滞时，触发自适应分层符号抽象机制（AHSAM），该机制进行方差分析（ANOVA）过滤，将显著的个体压缩成符号结构，并通过验证引导的修剪周期将它们注入所有种群。

Result: 在含钢纤维混凝土（SFRC）梁数据集的30次独立试验中，DIGSP在训练和测试的均方根误差（RMSE）方面持续优于基线多基因遗传编程（BGP）模型。Wilcoxon秩和检验证实了统计学上的显著性（p < 0.01），DIGSP显示出更窄的误差分布和更少的异常值。在验证RMSE方面未观察到显著差异，原因在于样本量有限。

Conclusion: 领域信息驱动的结构分解和符号抽象能够改善模型的收敛性和泛化能力。DIGSP为那些符号叠加与底层物理结构一致的系统提供了一种原则性的、可解释的建模策略。

Abstract: This study presents domain-informed genetic superposition programming
(DIGSP), a symbolic regression framework tailored for engineering systems
governed by separable physical mechanisms. DIGSP partitions the input space
into domain-specific feature subsets and evolves independent genetic
programming (GP) populations to model material-specific effects. Early
evolution occurs in isolation, while ensemble fitness promotes inter-population
cooperation. To enable symbolic superposition, an adaptive hierarchical
symbolic abstraction mechanism (AHSAM) is triggered after stagnation across all
populations. AHSAM performs analysis of variance- (ANOVA) based filtering to
identify statistically significant individuals, compresses them into symbolic
constructs, and injects them into all populations through a validation-guided
pruning cycle. The DIGSP is benchmarked against a baseline multi-gene genetic
programming (BGP) model using a dataset of steel fiber-reinforced concrete
(SFRC) beams. Across 30 independent trials with 65% training, 10% validation,
and 25% testing splits, DIGSP consistently outperformed BGP in training and
test root mean squared error (RMSE). The Wilcoxon rank-sum test confirmed
statistical significance (p < 0.01), and DIGSP showed tighter error
distributions and fewer outliers. No significant difference was observed in
validation RMSE due to limited sample size. These results demonstrate that
domain-informed structural decomposition and symbolic abstraction improve
convergence and generalization. DIGSP offers a principled and interpretable
modeling strategy for systems where symbolic superposition aligns with the
underlying physical structure.

</details>


### [387] [Smart Routing for EV Charge Point Operators in Mega Cities: Case Study of Istanbul](https://arxiv.org/abs/2509.21369)
*Onur Yenigun,Gozde Karatas Baydogmus,Kazim Yildiz*

Main category: cs.NE

TL;DR: 该研究提出了一种优化电动汽车充电网络维护计划的综合方法，通过K-means聚类对充电站进行分组，并使用遗传算法计算最短路径，在伊斯坦布尔的一个案例研究中实现了约35%的距离节省。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的快速普及对充电基础设施的可持续管理提出了挑战，尤其是在大城市中，充电站网络的扩张给充电点运营商（CPOs）在规划维护和修理活动方面带来了严峻的后勤挑战。低效的现场人员管理会导致时间损失、高昂的运营成本和资源浪费。

Method: 该研究提出了一种优化电动汽车充电网络维护作业规划的综合方法。该方法首先使用K-means聚类算法根据地理邻近性对充电站进行分组，然后使用遗传算法计算簇之间的最短路径。该方法使用Python开发，并应用于包括伊斯坦布尔100个电动汽车充电站的数据集。

Result: 在对不同参数配置的测试中，与根据顺序数据布局创建的参考路线相比，最高效的方案提供了大约35%的距离节省。

Conclusion: 该研究提出的路线规划方法具有巨大潜力，尤其适用于伊斯坦布尔这样的大都市。该研究提供了一种解决方案，可以使像伊斯坦布尔这样的都市区的现场作业能够以更有效、更有计划、更具可扩展性的方式进行。未来的研究计划整合交通状况和现场技术人员限制等实时因素。

Abstract: The rapidly increasing use of electric vehicles (EVs) has made it even more
important to manage the charging infrastructure sustainably. The expansion of
charging station networks, especially in large cities, creates serious
logistical challenges for charging point operators (CPOs) in planning
maintenance and repair activities. Inefficient field personnel management can
lead to time loss, high operational costs, and resource waste. This study
presents an integrated method to optimize the planning of EV charging network
maintenance operations. The proposed approach groups charging stations
according to geographical proximity using the K-means clustering algorithm and
calculates the shortest routes between clusters using a genetic algorithm. The
method was developed in Python and applied to a dataset consisting of 100 EV
charging stations in Istanbul.
  Considering the population density, traffic density, and resource constraints
of Istanbul, the route planning approach presented in this study has great
potential, especially for such metropolises. According to the different
parameter configurations tested, the most efficient scenario provided
approximately 35\% distance savings compared to the reference route created
according to the sequential data layout. While the reference route provides a
simple comparison, the study presents a solution that will enable field
operations in metropolitan cities such as Istanbul to be conducted in a more
efficient, planned and scalable manner. In future studies, it is planned to
integrate real-time factors such as traffic conditions and field technician
constraints.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [388] [Language-in-the-Loop Culvert Inspection on the Erie Canal](https://arxiv.org/abs/2509.21370)
*Yashom Dighe,Yash Turkar,Karthik Dantu*

Main category: cs.RO

TL;DR: VISION是一个端到端的自主系统，结合了视觉-语言模型（VLM）和视点规划，用于自主检查水道，能够提出感兴趣的区域（ROI），生成深度信息，并规划移动以获取近距离图像，最终在外部评估中达到了80%的专家一致性。


<details>
  <summary>Details</summary>
Motivation: 人类检查水道（如伊利运河的涵洞）因年代久远、几何形状复杂、光线不足、天气恶劣和不易进入等因素而面临挑战，需要频繁检查以确保安全运行。

Method: VISION系统将一个大规模的视觉-语言模型（VLM）与约束视点规划相结合。VLM根据简短的提示提出开放词汇的感兴趣区域（ROI）建议及其理由和置信度，系统融合立体深度信息以恢复尺度，并利用考虑了涵洞约束的规划器来指挥重新定位，以捕捉目标特写。该系统在部署于伊利运河涵洞的四足机器人上，能够自主完成“观察、决策、移动、再成像”的闭环。

Result: 在外部评估中，VISION系统提出的初始ROI建议与主题专家的认同率达到61.4%，在进行重新成像后，最终评估结果达到了80%的专家一致性。

Conclusion: VISION系统能够将初步的假设转化为基于事实的、与专家一致的发现，无需进行领域特定的微调，从而提高了涵洞检查的效率和准确性。

Abstract: Culverts on canals such as the Erie Canal, built originally in 1825, require
frequent inspections to ensure safe operation. Human inspection of culverts is
challenging due to age, geometry, poor illumination, weather, and lack of easy
access. We introduce VISION, an end-to-end, language-in-the-loop autonomy
system that couples a web-scale vision-language model (VLM) with constrained
viewpoint planning for autonomous inspection of culverts. Brief prompts to the
VLM solicit open-vocabulary ROI proposals with rationales and confidences,
stereo depth is fused to recover scale, and a planner -- aware of culvert
constraints -- commands repositioning moves to capture targeted close-ups.
Deployed on a quadruped in a culvert under the Erie Canal, VISION closes the
see, decide, move, re-image loop on-board and produces high-resolution images
for detailed reporting without domain-specific fine-tuning. In an external
evaluation by New York Canal Corporation personnel, initial ROI proposals
achieved 61.4\% agreement with subject-matter experts, and final
post-re-imaging assessments reached 80\%, indicating that VISION converts
tentative hypotheses into grounded, expert-aligned findings.

</details>


### [389] [Developing a Mono-Actuated Compliant GeoGami Robot](https://arxiv.org/abs/2509.21445)
*Archie Webster,Lee Skull,Seyed Amir Tafrishi*

Main category: cs.RO

TL;DR: GeoGami是一个利用折纸技术实现变形和运动的软硬结合机器人平台，通过集成表面顺应性、几何顺应性骨架和单驱动器，克服了折纸机器人高自由度和多驱动器的挑战，能够变形和滚动。


<details>
  <summary>Details</summary>
Motivation: 折纸表面具有高自由度，通常需要大量驱动器，但该研究旨在通过集成表面顺应性和几何顺应性骨架，利用单驱动器实现GeoGami机器人的变形和运动。

Method: 提出了一种单驱动的GeoGami移动平台，结合了折纸表面顺应性和几何顺应性骨架，并设计了中心齿轮箱机制。对电缆驱动的骨架驱动方式进行了分析，并对GeoGami平台进行了变形和滚动能力的评估。

Result: 开发了GeoGami机器人，建立了其刚度模型，并分析了用于骨架变形的替代性电缆驱动执行方法。评估了GeoGami平台在形状变形和滚动方面的能力。

Conclusion: GeoGami平台通过利用折纸技术和创新的驱动机制，克服了传统折纸机器人的局限性，为能够变形以适应不同环境和利用形状变形进行运动的机器人开辟了新的可能性。

Abstract: This paper presents the design of a new soft-rigid robotic platform,
"GeoGami". We leverage origami surface capabilities to achieve shape
contraction and to support locomotion with underactuated forms. A key challenge
is that origami surfaces have high degrees of freedom and typically require
many actuators; we address repeatability by integrating surface compliance. We
propose a mono-actuated GeoGami mobile platform that combines origami surface
compliance with a geometric compliant skeleton, enabling the robot to transform
and locomote using a single actuator. We demonstrate the robot, develop a
stiffness model, and describe the central gearbox mechanism. We also analyze
alternative cable-driven actuation methods for the skeleton to enable surface
transformation. Finally, we evaluate the GeoGami platform for capabilities,
including shape transformation and rolling. This platform opens new
capabilities for robots that change shape to access different environments and
that use shape transformation for locomotion.

</details>


### [390] [Wall Inspector: Quadrotor Control in Wall-proximity Through Model Compensation](https://arxiv.org/abs/2509.21496)
*Peiwen Yang,Weisong Wen,Runqiu Yang,Yingming Chen,Cheuk Chi Tsang*

Main category: cs.RO

TL;DR: 该研究提出了一个用于四旋翼近墙飞行的模型预测控制框架（SC-MPC），通过引入考虑了气动吸力效应的模型，显著提高了轨迹跟踪的精度和稳定性，实验证明其性能优于PID和标准MPC。


<details>
  <summary>Details</summary>
Motivation: 在近墙环境中（如城市或室内），四旋翼飞行器易受未建模的气动吸力效应影响，这可能导致不稳定的振动甚至碰撞。因此，需要一种能够处理这些气动效应的控制方法，以确保安全高效的运行。

Method: 该研究提出了一个包含两个主要部分的解决方案：1. 一个基于物理的吸力模型，该模型明确考虑了吸力与旋翼速度和距离墙壁距离的关系。2. 一个吸力补偿模型预测控制（SC-MPC）框架，该框架集成了增强的动力学模型（包含吸力效应）、系统动力学约束、轨迹跟踪目标、控制输入平滑度和执行器物理限制，并将其表述为因子图优化问题。吸力模型参数通过广泛的实验测量确定。

Result: 实验验证表明，SC-MPC在X轴和Y轴位置控制方面表现出优越的性能，其均方根误差（RMSE）分别为2.1厘米和2.0厘米，相比之下，比例-积分-微分（PID）控制的改进率分别为74%和79%，标准MPC的改进率分别为60%和53%。平均绝对误差（MAE）指标（X轴1.2厘米，Y轴1.4厘米）也同样优于基线方法。研究中使用的评估平台采用了涵道式四旋翼设计，以提供碰撞保护并保持气动效率。

Conclusion: 所提出的SC-MPC框架能够有效补偿近墙飞行中产生的气动吸力效应，显著提高了四旋翼飞行器的轨迹跟踪精度和稳定性。通过结合物理吸力模型和先进的控制优化技术，该方法为在复杂近墙环境中安全可靠地运行四旋翼飞行器提供了一个有效的解决方案。研究还开源了实现代码，以促进社区的进一步研究和应用。

Abstract: The safe operation of quadrotors in near-wall urban or indoor environments
(e.g., inspection and search-and-rescue missions) is challenged by unmodeled
aerodynamic effects arising from wall-proximity. It generates complex vortices
that induce destabilizing suction forces, potentially leading to hazardous
vibrations or collisions. This paper presents a comprehensive solution
featuring (1) a physics-based suction force model that explicitly characterizes
the dependency on both rotor speed and wall distance, and (2) a
suction-compensated model predictive control (SC-MPC) framework designed to
ensure accurate and stable trajectory tracking during wall-proximity
operations. The proposed SC-MPC framework incorporates an enhanced dynamics
model that accounts for suction force effects, formulated as a factor graph
optimization problem integrating system dynamics constraints, trajectory
tracking objectives, control input smoothness requirements, and actuator
physical limitations. The suction force model parameters are systematically
identified through extensive experimental measurements across varying
operational conditions. Experimental validation demonstrates SC-MPC's superior
performance, achieving 2.1 cm root mean squared error (RMSE) in X-axis and 2.0
cm RMSE in Y-axis position control - representing 74% and 79% improvements over
cascaded proportional-integral-derivative (PID) control, and 60% and 53%
improvements over standard MPC respectively. The corresponding mean absolute
error (MAE) metrics (1.2 cm X-axis, 1.4 cm Y-axis) similarly outperform both
baselines. The evaluation platform employs a ducted quadrotor design that
provides collision protection while maintaining aerodynamic efficiency. To
facilitate reproducibility and community adoption, we have open-sourced our
complete implementation, available at
https://anonymous.4open.science/r/SC-MPC-6A61.

</details>


### [391] [DroneFL: Federated Learning for Multi-UAV Visual Target Tracking](https://arxiv.org/abs/2509.21523)
*Xiaofan Yu,Yuwei Wu,Katherine Mao,Ye Tian,Vijay Kumar,Tajana Rosing*

Main category: cs.RO

TL;DR: 本文提出了DroneFL，一个专为多无人机协同追踪目标设计的联邦学习框架，解决了现有联邦学习在多无人机追踪中面临的计算资源有限、数据异构性强以及轨迹预测与多机器人规划耦合需求等挑战。DroneFL采用轻量级本地模型进行轨迹预测，并通过位置不变模型架构和基于高度的自适应实例归一化来缓解数据异构性问题。实验结果表明，DroneFL在预测精度和追踪性能方面均优于非联邦学习框架，且实现了实时运行和低云端数据速率。


<details>
  <summary>Details</summary>
Motivation: 现有的多机器人协同追踪技术在农业、环境监测、灾难响应和安防等领域具有重要应用前景。联邦学习（FL）有望在不集中聚合数据的情况下实现多机器人间的学习，但其在多无人机（UAV）目标追踪中的应用仍有待探索。该研究旨在解决多无人机目标追踪中联邦学习面临的计算资源限制、数据异构性以及轨迹预测与多机器人规划耦合等关键问题。

Method: 本文提出了DroneFL，一个专门为多无人机目标追踪设计的联邦学习框架。该框架采用轻量级本地模型，利用冻结的YOLO主干和浅层Transformer进行机载训练，以从传感器输入预测目标轨迹。为了解决联邦学习中的数据异构性问题，DroneFL引入了位置不变的模型架构和基于高度的自适应实例归一化。训练好的模型会定期在云端聚合，以实现全局知识共享。最后，在云端融合来自多个无人机的预测结果，并生成最优轨迹，以平衡预测精度和整体追踪性能。

Result: 与分布式非联邦学习框架相比，DroneFL将预测误差降低了6%-83%，并将追踪距离减少了0.4%-4.6%。在效率方面，DroneFL能够在树莓派5上实现实时运行，并且平均数据传输速率仅为1.56 KBps。

Conclusion: DroneFL是首个专门为多无人机目标追踪设计的联邦学习框架。该框架通过轻量级模型设计、处理数据异构性的方法以及云端模型聚合和轨迹优化，有效地提高了目标追踪的精度和效率，并能在资源受限的设备上实现实时运行和低通信开销。

Abstract: Multi-robot target tracking is a fundamental problem that requires
coordinated monitoring of dynamic entities in applications such as precision
agriculture, environmental monitoring, disaster response, and security
surveillance. While Federated Learning (FL) has the potential to enhance
learning across multiple robots without centralized data aggregation, its use
in multi-Unmanned Aerial Vehicle (UAV) target tracking remains largely
underexplored. Key challenges include limited onboard computational resources,
significant data heterogeneity in FL due to varying targets and the fields of
view, and the need for tight coupling between trajectory prediction and
multi-robot planning. In this paper, we introduce DroneFL, the first federated
learning framework specifically designed for efficient multi-UAV target
tracking. We design a lightweight local model to predict target trajectories
from sensor inputs, using a frozen YOLO backbone and a shallow transformer for
efficient onboard training. The updated models are periodically aggregated in
the cloud for global knowledge sharing. To alleviate the data heterogeneity
that hinders FL convergence, DroneFL introduces a position-invariant model
architecture with altitude-based adaptive instance normalization. Finally, we
fuse predictions from multiple UAVs in the cloud and generate optimal
trajectories that balance target prediction accuracy and overall tracking
performance. Our results show that DroneFL reduces prediction error by 6%-83%
and tracking distance by 0.4%-4.6% compared to a distributed non-FL framework.
In terms of efficiency, DroneFL runs in real time on a Raspberry Pi 5 and has
on average just 1.56 KBps data rate to the cloud.

</details>


### [392] [Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation](https://arxiv.org/abs/2509.21543)
*Jinbang Huang,Zhiyuan Li,Zhanguang Zhang,Xingyue Quan,Jianye Hao,Yingxue Zhang*

Main category: cs.RO

TL;DR: LLM 可用于机器人任务规划，但现有方法未充分利用其作为可扩展推理数据源的潜力。我们提出了 Plan2Evolve 框架，LLM 可生成规划域，产生问题-规划对，并将其转换为自然语言解释的 CoT 轨迹，从而使符号规划结构与自然语言推理对齐。该方法可提升 LLM 的规划能力、泛化能力并降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 在机器人任务规划方面潜力巨大，但大多将其视为搜索工具，未能充分挖掘其作为可扩展推理数据源的潜力。而机器人领域的 CoT 超时依赖于昂贵的人工标注数据集。

Method: 提出 Plan2Evolve 框架，LLM 首先生成规划域，然后生成问题-规划对，最后将问题-规划对转换为带有自然语言解释的 CoT 轨迹。

Result: Plan2Evolve 框架产生的推理轨迹可以扩展 LLM 的内在规划能力，通过微调可以得到规划能力更强、跨任务泛化性更好、推理成本更低的 LLM。

Conclusion: Plan2Evolve 框架通过生成和利用规划域及 CoT 轨迹，实现了 LLM 在机器人任务规划方面的自我进化，提升了规划性能和泛化能力。

Abstract: Large Language Models (LLMs) have recently shown strong potential in robotic
task planning, particularly through automatic planning domain generation that
integrates symbolic search. Prior approaches, however, have largely treated
these domains as search utilities, with limited attention to their potential as
scalable sources of reasoning data. At the same time, progress in reasoning
LLMs has been driven by chain-of-thought (CoT) supervision, whose application
in robotics remains dependent on costly, human-curated datasets. We propose
Plan2Evolve, an LLM self-evolving framework in which the base model generates
planning domains that serve as engines for producing symbolic problem-plan
pairs as reasoning traces. These pairs are then transformed into extended CoT
trajectories by the same model through natural-language explanations, thereby
explicitly aligning symbolic planning structures with natural language
reasoning. The resulting data extend beyond the model's intrinsic planning
capacity, enabling model fine-tuning that yields a planning-enhanced LLM with
improved planning success, stronger cross-task generalization, and reduced
inference costs.

</details>


### [393] [Ontological foundations for contrastive explanatory narration of robot plans](https://arxiv.org/abs/2509.22493)
*Alberto Olivares-Alarcos,Sergi Foix,Júlia Borràs,Gerard Canal,Guillem Alenyà*

Main category: cs.RO

TL;DR: 本文提出了一种用于比较和解释机器人计划之间差异的方法，以增强人机交互的可信度。


<details>
  <summary>Details</summary>
Motivation: 为了实现可信赖的人机交互，机器人需要能够解释它们的决策。

Method: 提出了一种新的本体模型来形式化和推理计划之间的差异，并提出了一种新的算法来生成对比性叙述。

Result: 通过实证评估，所提出的方法在解释能力上优于基线方法。

Conclusion: 所提出的方法能够有效地为机器人生成对比性解释，从而提高人机交互的透明度。

Abstract: Mutual understanding of artificial agents' decisions is key to ensuring a
trustworthy and successful human-robot interaction. Hence, robots are expected
to make reasonable decisions and communicate them to humans when needed. In
this article, the focus is on an approach to modeling and reasoning about the
comparison of two competing plans, so that robots can later explain the
divergent result. First, a novel ontological model is proposed to formalize and
reason about the differences between competing plans, enabling the
classification of the most appropriate one (e.g., the shortest, the safest, the
closest to human preferences, etc.). This work also investigates the
limitations of a baseline algorithm for ontology-based explanatory narration.
To address these limitations, a novel algorithm is presented, leveraging
divergent knowledge between plans and facilitating the construction of
contrastive narratives. Through empirical evaluation, it is observed that the
explanations excel beyond the baseline method.

</details>


### [394] [PL-VIWO2: A Lightweight, Fast and Robust Visual-Inertial-Wheel Odometry Using Points and Lines](https://arxiv.org/abs/2509.21563)
*Zhixin Zhang,Liang Zhao,Pawel Ladosz*

Main category: cs.RO

TL;DR: PL-VIWO2是一个视觉-惯性-轮式里程表系统，可在复杂城市环境中实现鲁棒的状态估计。


<details>
  <summary>Details</summary>
Motivation: 视觉里程表在自主驾驶中得到广泛应用，但在复杂的城市环境中性能会下降。需要一个能应对这些挑战的系统。

Method: 提出PL-VIWO2，一个基于滤波的视觉-惯性-轮式里程表系统，集成了IMU、轮式编码器和摄像头。其创新点包括：1. 利用2D特征点和线之间的几何关系进行线特征提取和三角测量。2. 提出SE(2)-约束SE(3)轮式预积分方法，利用车辆的平面运动特性进行轮式更新。3. 引入运动一致性检查（MCC）来过滤动态特征。

Result: PL-VIWO2在蒙特卡洛模拟和公开数据集上的实验表明，在精度、效率和鲁棒性方面优于现有技术。

Conclusion: PL-VIWO2是一个能够长期鲁棒地进行状态估计的视觉-惯性-轮式里程表系统。

Abstract: Vision-based odometry has been widely adopted in autonomous driving owing to
its low cost and lightweight setup; however, its performance often degrades in
complex outdoor urban environments. To address these challenges, we propose
PL-VIWO2, a filter-based visual-inertial-wheel odometry system that integrates
an IMU, wheel encoder, and camera (supporting both monocular and stereo) for
long-term robust state estimation. The main contributions are: (i) a novel line
feature processing framework that exploits the geometric relationship between
2D feature points and lines, enabling fast and robust line tracking and
triangulation while ensuring real-time performance; (ii) an SE(2)-constrained
SE(3) wheel pre-integration method that leverages the planar motion
characteristics of ground vehicles for accurate wheel updates; and (iii) an
efficient motion consistency check (MCC) that filters out dynamic features by
jointly using IMU and wheel measurements. Extensive experiments on Monte Carlo
simulations and public autonomous driving datasets demonstrate that PL-VIWO2
outperforms state-of-the-art methods in terms of accuracy, efficiency, and
robustness.

</details>


### [395] [Autonomous UAV-Quadruped Docking in Complex Terrains via Active Posture Alignment and Constraint-Aware Control](https://arxiv.org/abs/2509.21571)
*HaoZhe Xu,Cheng Cheng,HongRui Sang,Zhipeng Wang,Qiyong He,Xiuxian Li,Bin He*

Main category: cs.RO

TL;DR: 本篇论文提出了一种在GPS拒止环境下，无人机（UAV）与四足机器人自主对接的框架，解决了现有方法在复杂地形下四足机器人稳定性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无人机与地面机器人对接方法多针对移动能力受限的轮式平台，无法适应复杂地形。四足机器人虽然适应性强，但其姿态易变，难以提供稳定的对接平台。

Method: 在四足机器人端，提出了一种通过深度强化学习训练的混合内部模型与水平对齐（HIM-HA）方法，主动稳定其躯干以提供水平平台。在无人机端，采用三阶段策略：1）基于中值滤波YOLOv8检测器的远距离捕获；2）基于约束感知的控制器（整合了NFTSMC和对数边界函数BF以保证视场约束下的有限时间误差收敛）的近距离跟踪；3）基于安全周期（SP）机制的终端下降，该机制联合验证跟踪精度和平台稳定性。

Result: 该框架在仿真和真实世界场景中均得到验证，成功实现了在超过17厘米的室外楼梯和超过30度的崎岖斜坡上的对接。

Conclusion: 所提出的无人机-四足机器人自主对接框架能够有效克服复杂地形的挑战，为异构系统在多样化环境中的应用提供了可靠的解决方案。

Abstract: Autonomous docking between Unmanned Aerial Vehicles (UAVs) and ground robots
is essential for heterogeneous systems, yet most existing approaches target
wheeled platforms whose limited mobility constrains exploration in complex
terrains. Quadruped robots offer superior adaptability but undergo frequent
posture variations, making it difficult to provide a stable landing surface for
UAVs. To address these challenges, we propose an autonomous UAV-quadruped
docking framework for GPS-denied environments. On the quadruped side, a Hybrid
Internal Model with Horizontal Alignment (HIM-HA), learned via deep
reinforcement learning, actively stabilizes the torso to provide a level
platform. On the UAV side, a three-phase strategy is adopted, consisting of
long-range acquisition with a median-filtered YOLOv8 detector, close-range
tracking with a constraint-aware controller that integrates a Nonsingular Fast
Terminal Sliding Mode Controller (NFTSMC) and a logarithmic Barrier Function
(BF) to guarantee finite-time error convergence under field-of-view (FOV)
constraints, and terminal descent guided by a Safety Period (SP) mechanism that
jointly verifies tracking accuracy and platform stability. The proposed
framework is validated in both simulation and real-world scenarios,
successfully achieving docking on outdoor staircases higher than 17 cm and
rough slopes steeper than 30 degrees. Supplementary materials and videos are
available at: https://uav-quadruped-docking.github.io.

</details>


### [396] [Real-Time Indoor Object SLAM with LLM-Enhanced Priors](https://arxiv.org/abs/2509.21602)
*Yang Jiao,Yiding Qiu,Henrik I. Christensen*

Main category: cs.RO

TL;DR: 利用大型语言模型（LLM）为物体级 SLAM 提供常识性几何先验，以解决稀疏观测导致的优化问题，并在 TUM RGB-D 和 3RScan 数据集上将地图构建精度提高了 36.8%。


<details>
  <summary>Details</summary>
Motivation: 物体级 SLAM 在稀疏观测时面临优化问题，而现有方法依赖于劳动密集且泛化性差的先验知识。本研究旨在利用 LLM 的常识性知识来提供物体几何属性（尺寸和方向）的先验，以改善 SLAM 性能。

Method: 将 LLM 提供的物体几何属性（尺寸和方向）作为先验因子，集成到一个基于图的 SLAM 框架中，以增强在物体稀疏时的定位和地图构建能力。

Result: 与最新的基线方法相比，在 TUM RGB-D 和 3RScan 数据集上，地图构建精度提高了 36.8%。此外，在现实世界场景中也展示了实时性能。

Conclusion: 通过利用 LLM 提供的常识性几何先验，可以有效地解决物体级 SLAM 中因稀疏观测导致的优化问题，从而提高地图构建精度并实现实时性能。

Abstract: Object-level Simultaneous Localization and Mapping (SLAM), which incorporates
semantic information for high-level scene understanding, faces challenges of
under-constrained optimization due to sparse observations. Prior work has
introduced additional constraints using commonsense knowledge, but obtaining
such priors has traditionally been labor-intensive and lacks generalizability
across diverse object categories. We address this limitation by leveraging
large language models (LLMs) to provide commonsense knowledge of object
geometric attributes, specifically size and orientation, as prior factors in a
graph-based SLAM framework. These priors are particularly beneficial during the
initial phase when object observations are limited. We implement a complete
pipeline integrating these priors, achieving robust data association on sparse
object-level features and enabling real-time object SLAM. Our system, evaluated
on the TUM RGB-D and 3RScan datasets, improves mapping accuracy by 36.8\% over
the latest baseline. Additionally, we present real-world experiments in the
supplementary video, demonstrating its real-time performance.

</details>


### [397] [Generating Stable Placements via Physics-guided Diffusion Models](https://arxiv.org/abs/2509.21664)
*Philippe Nadeau,Miguel Rogel,Ivan Bilić,Ivan Petrović,Jonathan Kelly*

Main category: cs.RO

TL;DR: 提出一种将稳定性直接集成到扩散模型采样过程中的方法，以实现机器人稳定放置。


<details>
  <summary>Details</summary>
Motivation: 在多物体场景中稳定地放置物体是机器人操作中的一个基本挑战，因为放置必须无渗透、建立精确的表面接触并达到力的平衡。评估稳定性，现有方法依赖于运行模拟引擎或采用基于外观的启发式评估。

Method: 将稳定性直接集成到扩散模型采样过程中。通过查询离线采样规划器来收集多模态放置标签，并训练扩散模型以生成稳定的放置。该扩散模型以场景和物体点云为条件，并充当几何感知先验。利用基于分数的生成模型的组合性质，将学习到的先验与感知稳定性的损失相结合，从而增加从高稳定性区域采样的可能性。

Result: 在四个可以准确计算稳定性的基准场景上进行了评估。与最先进的几何方法相比，该物理引导模型实现的放置在面对强制扰动时具有 56% 的更优越的鲁棒性，同时运行时长减少了 47%。

Conclusion: 所提出的方法通过将稳定性直接集成到扩散模型采样过程中，能够更鲁棒、更快速地实现机器人稳定放置，并且无需额外的重新训练或微调。

Abstract: Stably placing an object in a multi-object scene is a fundamental challenge
in robotic manipulation, as placements must be penetration-free, establish
precise surface contact, and result in a force equilibrium. To assess
stability, existing methods rely on running a simulation engine or resort to
heuristic, appearance-based assessments. In contrast, our approach integrates
stability directly into the sampling process of a diffusion model. To this end,
we query an offline sampling-based planner to gather multi-modal placement
labels and train a diffusion model to generate stable placements. The diffusion
model is conditioned on scene and object point clouds, and serves as a
geometry-aware prior. We leverage the compositional nature of score-based
generative models to combine this learned prior with a stability-aware loss,
thereby increasing the likelihood of sampling from regions of high stability.
Importantly, this strategy requires no additional re-training or fine-tuning,
and can be directly applied to off-the-shelf models. We evaluate our method on
four benchmark scenes where stability can be accurately computed. Our
physics-guided models achieve placements that are 56% more robust to forceful
perturbations while reducing runtime by 47% compared to a state-of-the-art
geometric method.

</details>


### [398] [Towards Versatile Humanoid Table Tennis: Unified Reinforcement Learning with Prediction Augmentation](https://arxiv.org/abs/2509.21690)
*Muqun Hu,Wenxi Chen,Wenjing Li,Falak Mandali,Zijian He,Renhong Zhang,Praveen Krisna,Katherine Christian,Leo Benaharon,Dizhi Ma,Karthik Ramani,Yan Gu*

Main category: cs.RO

TL;DR: 使用强化学习实现人形机器人打乒乓球，并取得高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有技术难以实现人形机器人快速的运动和敏捷的步法，尤其是在乒乓球这种高时序性的运动中。

Method: 提出了一种强化学习框架，将球的位置信息直接映射到全身关节指令，用于手臂击球和腿部移动。该框架结合了预测信号和基于物理的奖励。一个轻量级学习预测器可以估计未来的球的状态，以增强策略的前瞻性。在训练过程中，一个基于物理的预测器提供精确的未来状态，以构建密集的、信息丰富的奖励，从而实现有效的探索。

Result: 该策略在模拟中取得了优异的性能，在各种发球范围内命中率达到96%以上，成功率达到92%以上。消融研究表明，学习到的预测器和预测奖励设计对于端到端学习至关重要。

Conclusion: 该策略在物理机器人上实现了零样本部署，能够协调的横向和前后步法，并进行精确、快速的击球，表明了实现通用、有竞争力的人形机器人乒乓球的可行路径。

Abstract: Humanoid table tennis (TT) demands rapid perception, proactive whole-body
motion, and agile footwork under strict timing -- capabilities that remain
difficult for unified controllers. We propose a reinforcement learning
framework that maps ball-position observations directly to whole-body joint
commands for both arm striking and leg locomotion, strengthened by predictive
signals and dense, physics-guided rewards. A lightweight learned predictor, fed
with recent ball positions, estimates future ball states and augments the
policy's observations for proactive decision-making. During training, a
physics-based predictor supplies precise future states to construct dense,
informative rewards that lead to effective exploration. The resulting policy
attains strong performance across varied serve ranges (hit rate $\geq$ 96% and
success rate $\geq$ 92%) in simulations. Ablation studies confirm that both the
learned predictor and the predictive reward design are critical for end-to-end
learning. Deployed zero-shot on a physical Booster T1 humanoid with 23 revolute
joints, the policy produces coordinated lateral and forward-backward footwork
with accurate, fast returns, suggesting a practical path toward versatile,
competitive humanoid TT.

</details>


### [399] [VLBiMan: Vision-Language Anchored One-Shot Demonstration Enables Generalizable Robotic Bimanual Manipulation](https://arxiv.org/abs/2509.21723)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: VLBiMan是一个框架，通过任务感知分解从单个范例中学习可重用的技能，并利用视觉-语言基础来适应动态变化，从而实现高效、通用的双臂操作。


<details>
  <summary>Details</summary>
Motivation: 现有的双臂操作方法在模仿策略学习和模块化方法之间存在困境：前者需要大量演示，后者灵活性差。VLBiMan旨在解决这一问题，实现高效、通用、适应性强的双臂操作。

Method: VLBiMan框架通过任务感知分解，将不变的原始技能作为锚点，并通过视觉-语言基础动态调整可变组件，以应对场景变化、物体重排或视觉混乱等不确定性。该系统还支持人类般的混合控制，可以同步或异步使用双臂。

Result: (1) 与模仿基线相比，演示需求大大减少；(2) 通过原子技能拼接实现组合泛化，以完成长时任务；(3) 对新颖但语义相似的物体和外部干扰具有鲁棒性；(4) 具有强大的跨体转换能力，无需重新训练即可在不同机器人平台上实例化。

Conclusion: VLBiMan通过结合人类先验知识和视觉-语言基础的适应性，朝着在非结构化环境中实现实用且通用的双臂操作迈出了一步。

Abstract: Achieving generalizable bimanual manipulation requires systems that can learn
efficiently from minimal human input while adapting to real-world uncertainties
and diverse embodiments. Existing approaches face a dilemma: imitation policy
learning demands extensive demonstrations to cover task variations, while
modular methods often lack flexibility in dynamic scenes. We introduce VLBiMan,
a framework that derives reusable skills from a single human example through
task-aware decomposition, preserving invariant primitives as anchors while
dynamically adapting adjustable components via vision-language grounding. This
adaptation mechanism resolves scene ambiguities caused by background changes,
object repositioning, or visual clutter without policy retraining, leveraging
semantic parsing and geometric feasibility constraints. Moreover, the system
inherits human-like hybrid control capabilities, enabling mixed synchronous and
asynchronous use of both arms. Extensive experiments validate VLBiMan across
tool-use and multi-object tasks, demonstrating: (1) a drastic reduction in
demonstration requirements compared to imitation baselines, (2) compositional
generalization through atomic skill splicing for long-horizon tasks, (3)
robustness to novel but semantically similar objects and external disturbances,
and (4) strong cross-embodiment transfer, showing that skills learned from
human demonstrations can be instantiated on different robotic platforms without
retraining. By bridging human priors with vision-language anchored adaptation,
our work takes a step toward practical and versatile dual-arm manipulation in
unstructured settings.

</details>


### [400] [The Turkish Ice Cream Robot: Examining Playful Deception in Social Human-Robot Interactions](https://arxiv.org/abs/2509.21776)
*Hyeonseong Kim,Roy El-Helou,Seungbeen Lee,Sungjoon Choi,Matthew Pan*

Main category: cs.RO

TL;DR: 机器人通过模仿土耳其冰淇淋商的玩笑来延迟移交物品，从而在娱乐和参与方面提升用户体验，但会降低安全感和信任度。


<details>
  <summary>Details</summary>
Motivation: 人类社交中普遍存在的玩笑式欺骗在人机交互（HRI）中探索不足，本研究旨在探索这种欺骗对用户信任、愉悦感和参与度的影响。

Method: 设计了一个配备定制末端执行器的机器人操控器，并实现了五种模仿土耳其冰淇淋商的延迟移交冰淇淋形状物体的欺骗策略。通过包含91名参与者的混合设计用户研究，评估了玩笑式欺骗和互动时长对用户体验的影响。

Result: 研究结果表明，模仿土耳其冰淇淋商的欺骗方式显著增强了用户的愉悦感和参与度，但降低了对安全和信任的感知，表明在多维度方面存在一种结构化的权衡。

Conclusion: 玩笑式欺骗可以成为交互式机器人在娱乐和以参与为重点的场景中的宝贵设计策略，但同时也凸显了深思熟虑其复杂权衡的重要性。

Abstract: Playful deception, a common feature in human social interactions, remains
underexplored in Human-Robot Interaction (HRI). Inspired by the Turkish Ice
Cream (TIC) vendor routine, we investigate how bounded, culturally familiar
forms of deception influence user trust, enjoyment, and engagement during
robotic handovers. We design a robotic manipulator equipped with a custom
end-effector and implement five TIC-inspired trick policies that deceptively
delay the handover of an ice cream-shaped object. Through a mixed-design user
study with 91 participants, we evaluate the effects of playful deception and
interaction duration on user experience. Results reveal that TIC-inspired
deception significantly enhances enjoyment and engagement, though reduces
perceived safety and trust, suggesting a structured trade-off across the
multi-dimensional aspects. Our findings demonstrate that playful deception can
be a valuable design strategy for interactive robots in entertainment and
engagement-focused contexts, while underscoring the importance of deliberate
consideration of its complex trade-offs. You can find more information,
including demonstration videos, on
https://hyeonseong-kim98.github.io/turkish-ice-cream-robot/ .

</details>


### [401] [Effect of Gait Design on Proprioceptive Sensing of Terrain Properties in a Quadrupedal Robot](https://arxiv.org/abs/2509.22065)
*Ethan Fulcher,J. Diego Caporale,Yifeng Zhang,John Ruck,Feifei Qian*

Main category: cs.RO

TL;DR: 本研究探讨了在松散、可变形的地形上进行原位机器人探测，重点比较了两种步态（Crawl N' Sense 和 Trot-Walk）对原地感知识别精度的影响。


<details>
  <summary>Details</summary>
Motivation: 为了增强和改进对地球及其他行星体地质过程的原位机器人探测能力，尤其是在松散、可变形地表上的移动能力，理解环境的土力学性质至关重要。带有直驱和低齿比驱动器的腿式机器人能够灵敏地感知外部力，这使得它们有可能在移动过程中利用腿部测量地形属性，从而提高采样速度和密度，并能进入以前因风险太高而无法采样的地形。

Method: 通过让机器人分别采用“Crawl N' Sense”（一种面向传感的爬行步态）和“Trot-Walk”（一种面向移动的小跑步态）在包含刚性表面、流沙和带有人造表壳的流沙的实验室环境中移动，量化每种步态测量可变形地表强度和纹理的能力。

Result: 结果表明，使用面向传感的爬行步态和面向移动的小跑步态，机器人都能一致地测量出低强度和高强度基底之间的差异（以穿透阻力衡量）；然而，小跑步态的测量幅度更大且方差更大。此外，较慢的爬行步态在检测表壳的脆性断裂方面比快速的小跑步态具有显著更高的精度。

Conclusion: 研究结果为腿式机器人在移动中进行传感的步态设计和规划提供了新的见解，有助于在其他星球上侦察地形和进行科学测量，以增进我们对其地质和形成的理解。

Abstract: In-situ robotic exploration is an important tool for advancing knowledge of
geological processes that describe the Earth and other Planetary bodies. To
inform and enhance operations for these roving laboratories, it is imperative
to understand the terramechanical properties of their environments, especially
for traversing on loose, deformable substrates. Recent research suggested that
legged robots with direct-drive and low-gear ratio actuators can sensitively
detect external forces, and therefore possess the potential to measure terrain
properties with their legs during locomotion, providing unprecedented sampling
speed and density while accessing terrains previously too risky to sample. This
paper explores these ideas by investigating the impact of gait on
proprioceptive terrain sensing accuracy, particularly comparing a
sensing-oriented gait, Crawl N' Sense, with a locomotion-oriented gait,
Trot-Walk. Each gait's ability to measure the strength and texture of
deformable substrate is quantified as the robot locomotes over a laboratory
transect consisting of a rigid surface, loose sand, and loose sand with
synthetic surface crusts. Our results suggest that with both the
sensing-oriented crawling gait and locomotion-oriented trot gait, the robot can
measure a consistent difference in the strength (in terms of penetration
resistance) between the low- and high-resistance substrates; however, the
locomotion-oriented trot gait contains larger magnitude and variance in
measurements. Furthermore, the slower crawl gait can detect brittle ruptures of
the surface crusts with significantly higher accuracy than the faster trot
gait. Our results offer new insights that inform legged robot "sensing during
locomotion" gait design and planning for scouting the terrain and producing
scientific measurements on other worlds to advance our understanding of their
geology and formation.

</details>


### [402] [Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors](https://arxiv.org/abs/2509.21810)
*Ning Huang,Zhentao Xie,Qinchuan Li*

Main category: cs.RO

TL;DR: 提出 CAMP 框架，使四足机器人能够从专家演示中学习多种运动技能，实现平滑过渡和可重用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以让机器人学习多种运动技能并实现平滑过渡。

Method: 使用条件对抗性运动先验（CAMP）框架，结合新颖的技能判别器和条件化奖励设计。

Result: 实现了多技能的积极控制和重用，为学习通用策略提供了解决方案。

Conclusion: CAMP 框架能够高效地让四足机器人学习多样化的运动技能，并支持多技能的控制和重用，是解决复杂环境中通用策略学习的实用方案。

Abstract: Despite growing interest in developing legged robots that emulate biological
locomotion for agile navigation of complex environments, acquiring a diverse
repertoire of skills remains a fundamental challenge in robotics. Existing
methods can learn motion behaviors from expert data, but they often fail to
acquire multiple locomotion skills through a single policy and lack smooth
skill transitions. We propose a multi-skill learning framework based on
Conditional Adversarial Motion Priors (CAMP), with the aim of enabling
quadruped robots to efficiently acquire a diverse set of locomotion skills from
expert demonstrations. Precise skill reconstruction is achieved through a novel
skill discriminator and skill-conditioned reward design. The overall framework
supports the active control and reuse of multiple skills, providing a practical
solution for learning generalizable policies in complex environments.

</details>


### [403] [Improved Vehicle Maneuver Prediction using Game Theoretic Priors](https://arxiv.org/abs/2509.21873)
*Nishant Doshi*

Main category: cs.RO

TL;DR: 该研究提出了一种结合博弈论和运动预测模型的方法来提高车辆变道预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的轨迹分类模型在预测变道时不够准确，需要考虑整个场景的交互信息。

Method: 利用 Level-k 博弈论来模拟多智能体交互，计算理性决策，并将其作为先验信息或与运动分类模型结合，以在线优化方式预测目标车辆的理性行为。

Result: 该方法能够更准确地预测车辆的变道行为，为自适应巡航控制等决策系统提供支持，并有望进一步提高燃油经济性。

Conclusion: 将博弈论方法与传统运动预测模型相结合，可以显著提高车辆行为预测的准确性，尤其是在处理多车交互场景时。

Abstract: Conventional maneuver prediction methods use some sort of classification
model on temporal trajectory data to predict behavior of agents over a set time
horizon. Despite of having the best precision and recall, these models cannot
predict a lane change accurately unless they incorporate information about the
entire scene. Level-k game theory can leverage the human-like hierarchical
reasoning to come up with the most rational decisions each agent can make in a
group. This can be leveraged to model interactions between different vehicles
in presence of each other and hence compute the most rational decisions each
agent would make. The result of game theoretic evaluation can be used as a
"prior" or combined with a traditional motion-based classification model to
achieve more accurate predictions. The proposed approach assumes that the
states of the vehicles around the target lead vehicle are known. The module
will output the most rational maneuver prediction of the target vehicle based
on an online optimization solution. These predictions are instrumental in
decision making systems like Adaptive Cruise Control (ACC) or Traxen's
iQ-Cruise further improving the resulting fuel savings.

</details>


### [404] [WAVE: Worm Gear-based Adaptive Variable Elasticity for Decoupling Actuators from External Forces](https://arxiv.org/abs/2509.21878)
*Moses Gladson Selvamuthu,Tomoya Takahashi,Riichiro Tadakuma,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: WAVE是一种基于蜗轮的自适应可变刚度驱动器（VSA），通过解耦驱动电机与外力，实现精确的力传输和由弹性能吸收位置差异，从而提高操作安全性与通用性。


<details>
  <summary>Details</summary>
Motivation: 提高机器人操作的安全性与通用性，通过对顺应性和刚度进行双重调控。

Method: 提出并实现了一种名为WAVE（Worm Gear-based Adaptive Variable Elasticity）的变刚度驱动器（VSA）。该驱动器集成了非反向驱动的蜗轮，将驱动电机与外力解耦，允许精确传递力矩，并通过弹簧吸收位置偏差。通过改变弹簧的预压缩长度，实现连续的关节刚度调节，并将冲击力转化为弹性能储存，从而保护驱动器免受过载。

Result: 实验验证了所提出的刚度模型，证明了在静止状态下（即使有外力作用）电机负载接近于零，并展示了包含WAVE的机械臂在现实应用中的能力，成功实现了外力的解耦，突出了驱动器的保护特性，使其能够胜任接触密集型任务和应对挑战性环境。

Conclusion: WAVE驱动器成功实现了外力的解耦，并提供了优异的保护特性，适用于接触密集型任务和挑战性环境下的鲁棒机器人应用，显著提升了机器人的安全性与多功能性。

Abstract: Robotic manipulators capable of regulating both compliance and stiffness
offer enhanced operational safety and versatility. Here, we introduce Worm
Gear-based Adaptive Variable Elasticity (WAVE), a variable stiffness actuator
(VSA) that integrates a non-backdrivable worm gear. By decoupling the driving
motor from external forces using this gear, WAVE enables precise force
transmission to the joint, while absorbing positional discrepancies through
compliance. WAVE is protected from excessive loads by converting impact forces
into elastic energy stored in a spring. In addition, the actuator achieves
continuous joint stiffness modulation by changing the spring's precompression
length. We demonstrate these capabilities, experimentally validate the proposed
stiffness model, show that motor loads approach zero at rest--even under
external loading--and present applications using a manipulator with WAVE. This
outcome showcases the successful decoupling of external forces. The protective
attributes of this actuator allow for extended operation in contact-intensive
tasks, and for robust robotic applications in challenging environments.

</details>


### [405] [SAGE: Scene Graph-Aware Guidance and Execution for Long-Horizon Manipulation Tasks](https://arxiv.org/abs/2509.21928)
*Jialiang Li,Wenzheng Wu,Gaojing Zhang,Yifan Han,Wenzhao Lian*

Main category: cs.RO

TL;DR: SAGE框架利用语义场景图来解决长时序操作任务，通过结合任务规划和目标条件操作，实现了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 长时序操作任务在将高级符号规划与低级连续控制之间存在差距，需要强大的长时序任务规划和有效的目标条件操作能力。现有方法在泛化性和语义推理方面存在局限性。

Method: 提出SAGE框架，利用语义场景图作为场景状态的结构化表示。SAGE包含一个基于场景图的任务规划器（使用VLMs和LLMs进行环境解析和物理约束的场景状态转换推理）和一个解耦的结构化图像编辑流水线（通过图像修复和组合将目标子图合成为相应的图像）。

Result: SAGE在不同的长时序任务上实现了最先进的性能。

Conclusion: SAGE框架能够有效地弥合任务级语义推理与像素级视觉-运动控制之间的差距，为解决长时序操作任务提供了一种新颖而有效的方法。

Abstract: Successfully solving long-horizon manipulation tasks remains a fundamental
challenge. These tasks involve extended action sequences and complex object
interactions, presenting a critical gap between high-level symbolic planning
and low-level continuous control. To bridge this gap, two essential
capabilities are required: robust long-horizon task planning and effective
goal-conditioned manipulation. Existing task planning methods, including
traditional and LLM-based approaches, often exhibit limited generalization or
sparse semantic reasoning. Meanwhile, image-conditioned control methods
struggle to adapt to unseen tasks. To tackle these problems, we propose SAGE, a
novel framework for Scene Graph-Aware Guidance and Execution in Long-Horizon
Manipulation Tasks. SAGE utilizes semantic scene graphs as a structural
representation for scene states. A structural scene graph enables bridging
task-level semantic reasoning and pixel-level visuo-motor control. This also
facilitates the controllable synthesis of accurate, novel sub-goal images. SAGE
consists of two key components: (1) a scene graph-based task planner that uses
VLMs and LLMs to parse the environment and reason about physically-grounded
scene state transition sequences, and (2) a decoupled structural image editing
pipeline that controllably converts each target sub-goal graph into a
corresponding image through image inpainting and composition. Extensive
experiments have demonstrated that SAGE achieves state-of-the-art performance
on distinct long-horizon tasks.

</details>


### [406] [Learnable Conformal Prediction with Context-Aware Nonconformity Functions for Robotic Planning and Perception](https://arxiv.org/abs/2509.21955)
*Divake Kumar,Sina Tayebati,Francesco Migliarba,Ranganath Krishnan,Amit Ranjan Trivedi*

Main category: cs.RO

TL;DR: LCP通过使用可学习的神经函数替换固定的非一致性分数来解决机器人领域深度学习模型置信度校准不佳的问题，在不牺牲理论保证的情况下，缩小了预测集的大小，并提高了分类、目标检测和路径规划的准确性，同时保持了低计算开销和内存占用。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在机器人领域通常输出点估计，并且其置信度校准不佳，在面对新颖、噪声或分布外输入时，缺乏量化预测可靠性的机制。现有的保形预测（CP）方法虽然提供了分布无关的覆盖保证，但其依赖固定的非一致性分数，忽略了上下文信息，可能导致预测区间过于保守或不安全。

Method: 提出了一种名为“可学习保形预测”（LCP）的方法，该方法用一个轻量级的神经网络函数取代了固定的非一致性分数。这个函数能够利用几何、语义和任务特定的特征来生成上下文感知的 umidity sets，从而取代了传统的固定分数。

Result: LCP在分类任务中将预测集大小减小了18%，在目标检测任务中将检测区间缩小了52%，并在路径规划任务中将安全性从72%提高到91%的成功率，同时只有很小的额外开销。在三个机器人任务和七个基准测试中，LCP的表现优于标准的CP和集成基线。具体来说，在CIFAR-100和ImageNet分类任务中，LCP在目标覆盖率下实现了更小的预测集（减少4.7-9.9%）。在COCO、BDD100K和Cityscapes目标检测任务中，LCP生成了更窄的边界框（缩小46-54%）。在穿越复杂环境的路径规划任务中，LCP的成功率提高到91.5%，路径膨胀仅为4.5%，而标准CP的路径膨胀为12.2%。

Conclusion: LCP方法计算开销低（运行时开销约4.8%，内存占用42 KB），并且支持在线适应，非常适合资源受限的自主系统。硬件评估显示，LCP在内存占用方面仅增加不到1%，在推理开销方面增加15.9%，但在检测任务中仍能维持39 FPS的帧率，并且比集成方法节能7.4倍。

Abstract: Deep learning models in robotics often output point estimates with poorly
calibrated confidences, offering no native mechanism to quantify predictive
reliability under novel, noisy, or out-of-distribution inputs. Conformal
prediction (CP) addresses this gap by providing distribution-free coverage
guarantees, yet its reliance on fixed nonconformity scores ignores context and
can yield intervals that are overly conservative or unsafe. We address this
with Learnable Conformal Prediction (LCP), which replaces fixed scores with a
lightweight neural function that leverages geometric, semantic, and
task-specific features to produce context-aware uncertainty sets.
  LCP maintains CP's theoretical guarantees while reducing prediction set sizes
by 18% in classification, tightening detection intervals by 52%, and improving
path planning safety from 72% to 91% success with minimal overhead. Across
three robotic tasks on seven benchmarks, LCP consistently outperforms Standard
CP and ensemble baselines. In classification on CIFAR-100 and ImageNet, it
achieves smaller set sizes (4.7-9.9% reduction) at target coverage. For object
detection on COCO, BDD100K, and Cityscapes, it produces 46-54% tighter bounding
boxes. In path planning through cluttered environments, it improves success to
91.5% with only 4.5% path inflation, compared to 12.2% for Standard CP.
  The method is lightweight (approximately 4.8% runtime overhead, 42 KB memory)
and supports online adaptation, making it well suited to resource-constrained
autonomous systems. Hardware evaluation shows LCP adds less than 1% memory and
15.9% inference overhead, yet sustains 39 FPS on detection tasks while being
7.4 times more energy-efficient than ensembles.

</details>


### [407] [FlowDrive: moderated flow matching with data balancing for trajectory planning](https://arxiv.org/abs/2509.21961)
*Lingguang Wang,Ömer Şahin Taş,Marlon Steiner,Christoph Stiller*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Learning-based planners are sensitive to the long-tailed distribution of
driving data. Common maneuvers dominate datasets, while dangerous or rare
scenarios are sparse. This imbalance can bias models toward the frequent cases
and degrade performance on critical scenarios. To tackle this problem, we
compare balancing strategies for sampling training data and find reweighting by
trajectory pattern an effective approach. We then present FlowDrive, a
flow-matching trajectory planner that learns a conditional rectified flow to
map noise directly to trajectory distributions with few flow-matching steps. We
further introduce moderated, in-the-loop guidance that injects small
perturbation between flow steps to systematically increase trajectory diversity
while remaining scene-consistent. On nuPlan and the interaction-focused
interPlan benchmarks, FlowDrive achieves state-of-the-art results among
learning-based planners and approaches methods with rule-based refinements.
After adding moderated guidance and light post-processing (FlowDrive*), it
achieves overall state-of-the-art performance across nearly all benchmark
splits.

</details>


### [408] [Hybrid Diffusion for Simultaneous Symbolic and Continuous Planning](https://arxiv.org/abs/2509.21983)
*Sigmund Hennum Høeg,Aksel Vaaler,Chaoqi Liu,Olav Egeland,Yilun Du*

Main category: cs.RO

TL;DR: 生成模型在处理需要复杂决策的长时机器人任务时存在困难，容易混淆行为模式。提出了一种结合离散符号规划和连续轨迹生成的混合扩散模型，显著优于基线模型，并支持基于符号条件的灵活轨迹合成。


<details>
  <summary>Details</summary>
Motivation: 当前基于生成模型的机器人控制方法在处理长时、复杂决策任务时存在局限性，容易混淆行为模式。

Method: 提出了一种结合离散符号规划和连续轨迹生成的混合扩散模型，该模型结合了离散变量扩散和连续扩散。

Result: 与基线模型相比，该混合扩散模型在长时机器人任务上表现出显著的性能提升。

Conclusion: 结合符号规划和连续轨迹生成的混合扩散模型能够有效解决长时机器人任务的挑战，并支持灵活的条件轨迹合成。

Abstract: Constructing robots to accomplish long-horizon tasks is a long-standing
challenge within artificial intelligence. Approaches using generative methods,
particularly Diffusion Models, have gained attention due to their ability to
model continuous robotic trajectories for planning and control. However, we
show that these models struggle with long-horizon tasks that involve complex
decision-making and, in general, are prone to confusing different modes of
behavior, leading to failure. To remedy this, we propose to augment continuous
trajectory generation by simultaneously generating a high-level symbolic plan.
We show that this requires a novel mix of discrete variable diffusion and
continuous diffusion, which dramatically outperforms the baselines. In
addition, we illustrate how this hybrid diffusion process enables flexible
trajectory synthesis, allowing us to condition synthesized actions on partial
and complete symbolic conditions.

</details>


### [409] [Developing Vision-Language-Action Model from Egocentric Videos](https://arxiv.org/abs/2509.21986)
*Tomoya Yoshida,Shuhei Kurita,Taichi Nishimura,Shinsuke Mori*

Main category: cs.RO

TL;DR: 可以直接从原始的自我中心视频中训练视觉语言动作模型（VLAs），无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉语言动作模型（VLAs）训练方法成本高昂，需要专家驱动的手动遥操作，而利用自我中心视频可以作为一种可扩展的替代方案。然而，以往的研究通常需要辅助标注（如详细的手部姿态记录），因此，直接从原始自我中心视频训练VLAs的可行性尚不明确。

Method: 提出了一种名为EgoScaler的框架，可以从自我中心视频中提取6DoF物体操纵轨迹，无需辅助记录。利用EgoScaler处理了四个大规模自我中心视频数据集，并自动优化了轨迹，构建了一个用于VLA预训练的大规模数据集。

Result: 在模拟和真实机器人环境中，使用先进的$\\pi_0$架构进行实验，发现：1）在所构建的数据集上预训练比从头开始训练能提高20%以上的任务成功率；2）预训练效果与使用真实机器人数据集相当；3）结合所构建的数据集和真实机器人数据可以进一步提高性能。

Conclusion: 自我中心视频是推动VLA研究的一个有前景且可扩展的资源。

Abstract: Egocentric videos capture how humans manipulate objects and tools, providing
diverse motion cues for learning object manipulation. Unlike the costly,
expert-driven manual teleoperation commonly used in training
Vision-Language-Action models (VLAs), egocentric videos offer a scalable
alternative. However, prior studies that leverage such videos for training
robot policies typically rely on auxiliary annotations, such as detailed
hand-pose recordings. Consequently, it remains unclear whether VLAs can be
trained directly from raw egocentric videos. In this work, we address this
challenge by leveraging EgoScaler, a framework that extracts 6DoF object
manipulation trajectories from egocentric videos without requiring auxiliary
recordings. We apply EgoScaler to four large-scale egocentric video datasets
and automatically refine noisy or incomplete trajectories, thereby constructing
a new large-scale dataset for VLA pre-training. Our experiments with a
state-of-the-art $\pi_0$ architecture in both simulated and real-robot
environments yield three key findings: (i) pre-training on our dataset improves
task success rates by over 20\% compared to training from scratch, (ii) the
performance is competitive with that achieved using real-robot datasets, and
(iii) combining our dataset with real-robot data yields further improvements.
These results demonstrate that egocentric videos constitute a promising and
scalable resource for advancing VLA research.

</details>


### [410] [One-DoF Robotic Design of Overconstrained Limbs with Energy-Efficient, Self-Collision-Free Motion](https://arxiv.org/abs/2509.22002)
*Yuping Gu,Bangchao Huang,Haoran Sun,Ronghan Xu,Jiayi Yin,Wei Zhang,Fang Wan,Jia Pan,Chaoyang Song*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的计算方法，用于设计具有单个自由度（1-DoF）的过约束机器人肢体，以实现期望的空间轨迹，同时在全周期旋转中实现节能和无自我碰撞的运动。


<details>
  <summary>Details</summary>
Motivation: 尽管通常期望制造具有多个自由度（DoF）的仿生机械臂，但单个自由度（1-DoF）的设计因其简洁性、鲁棒性、成本效益和效率等优点而具有基础性。对于通常在全周期运动中会受到自我碰撞约束的1-DoF系统，包含多个连杆和连接在闭环中的旋转关节的机构在引入运动多样性方面起着关键作用。

Method: 本研究提出了一种计算方法，该方法首先将基于连杆的机器人肢体的几何优化问题进行通用化表述，以实现无自我碰撞的设计。然后，通过优化相似性和动态相关指标，为具有过约束连杆的空间轨迹生成问题建立了数学模型。此外，还优化了过约束连杆的几何形状，以确保由单个执行器驱动的平稳且无碰撞的运动。

Result: 研究通过个性化自动机和仿生六足机器人等多种实验验证了所提出的方法。结果显示，所设计的具有过约束机器人肢体的六足机器人，在前进行走过程中表现出出色的能源效率。

Conclusion: 本研究成功开发了一种新颖的计算方法，能够设计出1-DoF的过约束机器人肢体，不仅能实现特定的空间轨迹，还能在全周期运动中避免自我碰撞并实现节能。该方法通过实验得到了验证，并成功应用于六足机器人，证明了其在提高能源效率方面的潜力。

Abstract: While it is expected to build robotic limbs with multiple degrees of freedom
(DoF) inspired by nature, a single DoF design remains fundamental, providing
benefits that include, but are not limited to, simplicity, robustness,
cost-effectiveness, and efficiency. Mechanisms, especially those with multiple
links and revolute joints connected in closed loops, play an enabling factor in
introducing motion diversity for 1-DoF systems, which are usually constrained
by self-collision during a full-cycle range of motion. This study presents a
novel computational approach to designing one-degree-of-freedom (1-DoF)
overconstrained robotic limbs for a desired spatial trajectory, while achieving
energy-efficient, self-collision-free motion in full-cycle rotations. Firstly,
we present the geometric optimization problem of linkage-based robotic limbs in
a generalized formulation for self-collision-free design. Next, we formulate
the spatial trajectory generation problem with the overconstrained linkages by
optimizing the similarity and dynamic-related metrics. We further optimize the
geometric shape of the overconstrained linkage to ensure smooth and
collision-free motion driven by a single actuator. We validated our proposed
method through various experiments, including personalized automata and
bio-inspired hexapod robots. The resulting hexapod robot, featuring
overconstrained robotic limbs, demonstrated outstanding energy efficiency
during forward walking.

</details>


### [411] [An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose](https://arxiv.org/abs/2509.22058)
*Qifeng Wang,Weigang Li,Lei Nie,Xin Xu,Wenping Liu,Zhe Xu*

Main category: cs.RO

TL;DR: 该研究提出了一种自适应ICP-LiDAR里程计方法，通过可靠的初始姿态和自适应阈值来提高在动态环境下的注册精度。


<details>
  <summary>Details</summary>
Motivation: 现有ICP-LiDAR里程计方法在处理动态环境和保证初始姿态可靠性方面存在不足，可能导致局部最优和精度下降。

Method: 首先，采用基于密度滤波的分布式粗略配准来获得初始姿态估计；然后，通过与运动预测姿态进行比较来选择可靠的初始姿态，减少初始点云间的误差；接着，结合当前和历史误差动态调整自适应阈值以适应环境变化；最后，基于可靠的初始姿态和自适应阈值，进行点到面自适应ICP配准。

Result: 该方法在KITTI数据集上的广泛实验表明，其性能优于现有方法，并显著提高了LiDAR里程计的精度。

Conclusion: 所提出的自适应ICP-LiDAR里程计方法能够有效解决现有方法的不足，在复杂动态环境中实现高精度的点云配准。

Abstract: As a key technology for autonomous navigation and positioning in mobile
robots, light detection and ranging (LiDAR) odometry is widely used in
autonomous driving applications. The Iterative Closest Point (ICP)-based
methods have become the core technique in LiDAR odometry due to their efficient
and accurate point cloud registration capability. However, some existing
ICP-based methods do not consider the reliability of the initial pose, which
may cause the method to converge to a local optimum. Furthermore, the absence
of an adaptive mechanism hinders the effective handling of complex dynamic
environments, resulting in a significant degradation of registration accuracy.
To address these issues, this paper proposes an adaptive ICP-based LiDAR
odometry method that relies on a reliable initial pose. First, distributed
coarse registration based on density filtering is employed to obtain the
initial pose estimation. The reliable initial pose is then selected by
comparing it with the motion prediction pose, reducing the initial error
between the source and target point clouds. Subsequently, by combining the
current and historical errors, the adaptive threshold is dynamically adjusted
to accommodate the real-time changes in the dynamic environment. Finally, based
on the reliable initial pose and the adaptive threshold, point-to-plane
adaptive ICP registration is performed from the current frame to the local map,
achieving high-precision alignment of the source and target point clouds.
Extensive experiments on the public KITTI dataset demonstrate that the proposed
method outperforms existing approaches and significantly enhances the accuracy
of LiDAR odometry.

</details>


### [412] [Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation](https://arxiv.org/abs/2509.22093)
*Xiaohuan Pei,Yuxing Chen,Siyu Xu,Yunke Wang,Yuheng Shi,Chang Xu*

Main category: cs.RO

TL;DR: 该研究提出了一种名为ADP（Action-aware Dynamic Pruning）的多模态剪枝框架，用于提高机器人操作中视觉-语言-动作（VLA）模型的推理效率。ADP通过结合文本驱动的令牌选择和动作感知的轨迹门控，根据机器人的操作阶段和运动动力学自适应地调整视觉令牌的保留比例，从而在效率和精度之间取得平衡。实验证明，ADP能够显著降低计算量和推理延迟，同时保持甚至提高操作成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在机器人操作中存在推理效率低的问题，尤其是在处理长序列的多模态上下文时，视觉令牌的计算成本很高。但现有方法忽略了不同操作阶段视觉信息冗余度的差异性。

Method: 提出了一种名为ADP（Action-aware Dynamic Pruning）的多模态剪枝框架。该框架结合了文本驱动的令牌选择和动作感知的轨迹门控机制。通过引入一个门控机制，将剪枝信号与最近的动作轨迹关联起来，并利用过去的运动窗口自适应地调整令牌保留比例，以匹配操作的动力学特性。

Result: 在LIBERO套件和真实世界场景的广泛实验中，ADP框架显著降低了计算量（FLOPs）和动作推理延迟（例如，在OpenVLA-OFT上实现了1.35倍的速度提升），同时保持了具有竞争力的成功率（例如，相比基线方法，OpenVLA的成功率提高了25.8%）。

Conclusion: ADP是一种简单易用的即插即用框架，可以提升机器人策略的效率和性能，推动了机器人操作在效率和性能上的进步。

Abstract: Robotic manipulation with Vision-Language-Action models requires efficient
inference over long-horizon multi-modal context, where attention to dense
visual tokens dominates computational cost. Existing methods optimize inference
speed by reducing visual redundancy within VLA models, but they overlook the
varying redundancy across robotic manipulation stages. We observe that the
visual token redundancy is higher in coarse manipulation phase than in
fine-grained operations, and is strongly correlated with the action dynamic.
Motivated by this observation, we propose \textbf{A}ction-aware
\textbf{D}ynamic \textbf{P}runing (\textbf{ADP}), a multi-modal pruning
framework that integrates text-driven token selection with action-aware
trajectory gating. Our method introduces a gating mechanism that conditions the
pruning signal on recent action trajectories, using past motion windows to
adaptively adjust token retention ratios in accordance with dynamics, thereby
balancing computational efficiency and perceptual precision across different
manipulation stages. Extensive experiments on the LIBERO suites and diverse
real-world scenarios demonstrate that our method significantly reduces FLOPs
and action inference latency (\textit{e.g.} $1.35 \times$ speed up on
OpenVLA-OFT) while maintaining competitive success rates (\textit{e.g.} 25.8\%
improvements with OpenVLA) compared to baselines, thereby providing a simple
plug-in path to efficient robot policies that advances the efficiency and
performance frontier of robotic manipulation. Our project website is:
\href{https://vla-adp.github.io/}{ADP.com}.

</details>


### [413] [Multi-stage robust nonlinear model predictive control of a lower-limb exoskeleton robot](https://arxiv.org/abs/2509.22120)
*Alireza Aliyari,Gholamreza Vossoughi*

Main category: cs.RO

TL;DR: 本研究提出一种多阶段非线性模型预测控制（RNMPC）方法，用于控制具有未知负载的双自由度外骨骼机器人，以最小化人机交互力，并在各种不确定性下提高了鲁棒性、降低了跟踪误差和交互力。


<details>
  <summary>Details</summary>
Motivation: 由于肌肉骨骼损伤增加，外骨骼机器人使用量增加，但其有效性很大程度上取决于控制系统的设计。而人类-机器人系统的中的不确定性使得设计鲁棒控制器充满挑战。

Method: 提出一种名为多阶段NMPC的鲁棒非线性模型预测控制（RNMPC）方法，通过解决非线性优化问题来控制一个双自由度外骨骼。该方法使用多个场景来表示系统不确定性，重点关注在摆动阶段最小化人机交互力，特别是在机器人承载未知负载的情况下。

Result: 仿真和实验测试表明，所提出的方法显著提高了鲁棒性，性能优于非鲁棒NMPC。在各种不确定性下，该方法实现了更低的跟踪误差和交互力。例如，在结合2公斤未知负载和外部干扰的情况下，与非鲁棒NMPC相比，多阶段NMPC的大腿和胫骨交互力的均方根值分别降低了77%和94%。

Conclusion: 所提出的多阶段RNMPC方法能够有效控制外骨骼机器人，并在存在系统不确定性的情况下，显著降低人机交互力。

Abstract: The use of exoskeleton robots is increasing due to the rising number of
musculoskeletal injuries. However, their effectiveness depends heavily on the
design of control systems. Designing robust controllers is challenging because
of uncertainties in human-robot systems. Among various control strategies,
Model Predictive Control (MPC) is a powerful approach due to its ability to
handle constraints and optimize performance. Previous studies have used
linearization-based methods to implement robust MPC on exoskeletons, but these
can degrade performance due to nonlinearities in the robot's dynamics. To
address this gap, this paper proposes a Robust Nonlinear Model Predictive
Control (RNMPC) method, called multi-stage NMPC, to control a
two-degree-of-freedom exoskeleton by solving a nonlinear optimization problem.
This method uses multiple scenarios to represent system uncertainties. The
study focuses on minimizing human-robot interaction forces during the swing
phase, particularly when the robot carries unknown loads. Simulations and
experimental tests show that the proposed method significantly improves
robustness, outperforming non-robust NMPC. It achieves lower tracking errors
and interaction forces under various uncertainties. For instance, when a 2 kg
unknown payload is combined with external disturbances, the RMS values of thigh
and shank interaction forces for multi-stage NMPC are reduced by 77 and 94
percent, respectively, compared to non-robust NMPC.

</details>


### [414] [DemoGrasp: Universal Dexterous Grasping from a Single Demonstration](https://arxiv.org/abs/2509.22149)
*Haoqi Yuan,Ziye Huang,Ye Wang,Chuan Mao,Chaoyi Xu,Zongqing Lu*

Main category: cs.RO

TL;DR: DemoGrasp是一种通过编辑单次抓取演示轨迹来学习通用灵巧抓取的方法，通过强化学习优化策略，在模拟和真实世界中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 多指灵巧手通用抓取是机器人操作中的基本挑战，现有强化学习方法在探索、奖励设计和课程设计方面存在困难，可能导致泛化性不佳。

Method: DemoGrasp通过编辑单次成功的抓取演示轨迹来适应新物体和姿态：改变手腕姿态确定抓取位置，改变手部关节角度确定抓取方式。该轨迹编辑被构建为一个单步马尔可夫决策过程（MDP），并使用强化学习进行优化。

Result: 在模拟环境中，DemoGrasp在DexGraspNet数据集上实现了95%的抓取成功率，优于先前最先进的方法。该方法在六个未见过的数据集上，对不同的灵巧手模型也表现出强大的迁移能力，平均成功率为84.6%，且仅在175个物体上进行训练。通过基于视觉的模仿学习，该策略成功抓取了110个真实世界中未见过的物体，包括小而薄的物品，并能适应各种环境变化，支持RGB和深度输入，还能扩展到带语言引导的混乱场景抓取。

Conclusion: DemoGrasp通过简单的轨迹编辑和强化学习，有效实现了通用灵巧抓取，克服了传统方法的局限性，并在模拟和真实世界应用中展现了优异的性能和泛化能力。

Abstract: Universal grasping with multi-fingered dexterous hands is a fundamental
challenge in robotic manipulation. While recent approaches successfully learn
closed-loop grasping policies using reinforcement learning (RL), the inherent
difficulty of high-dimensional, long-horizon exploration necessitates complex
reward and curriculum design, often resulting in suboptimal solutions across
diverse objects. We propose DemoGrasp, a simple yet effective method for
learning universal dexterous grasping. We start from a single successful
demonstration trajectory of grasping a specific object and adapt to novel
objects and poses by editing the robot actions in this trajectory: changing the
wrist pose determines where to grasp, and changing the hand joint angles
determines how to grasp. We formulate this trajectory editing as a single-step
Markov Decision Process (MDP) and use RL to optimize a universal policy across
hundreds of objects in parallel in simulation, with a simple reward consisting
of a binary success term and a robot-table collision penalty. In simulation,
DemoGrasp achieves a 95% success rate on DexGraspNet objects using the Shadow
Hand, outperforming previous state-of-the-art methods. It also shows strong
transferability, achieving an average success rate of 84.6% across diverse
dexterous hand embodiments on six unseen object datasets, while being trained
on only 175 objects. Through vision-based imitation learning, our policy
successfully grasps 110 unseen real-world objects, including small, thin items.
It generalizes to spatial, background, and lighting changes, supports both RGB
and depth inputs, and extends to language-guided grasping in cluttered scenes.

</details>


### [415] [DHAGrasp: Synthesizing Affordance-Aware Dual-Hand Grasps with Text Instructions](https://arxiv.org/abs/2509.22175)
*Quanzhou Li,Zhonghua Wu,Jingbo Wang,Chen Change Loy,Bo Dai*

Main category: cs.RO

TL;DR: 本研究提出了一个名为SymOpt的流水线，用于构建大规模双手机器人抓取数据集，并开发了一个名为DHAGrasp的文本引导式双手机器人抓取生成器，用于为未见过的物体合成双手机器人抓取，该方法在抓取质量和泛化能力方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏包含双手机器人抓取和语义部分标注的数据集，学习生成能够尊重物体语义的双手机器人抓取仍然是一个未被充分探索的领域。

Method: SymOpt流水线利用现有的单手机器人抓取数据集，并利用物体和手的对称性来构建大规模双手机器人抓取数据集。DHAGrasp采用新颖的双手机器人抓取可抓取性表示和两阶段设计，能够从少量分割的训练对象中进行有效学习，并扩展到大量未分割的数据。

Result: 实验表明，DHAGrasp生成了多样化且符合语义的双手机器人抓取，在抓取质量和泛化到未见过的物体方面优于强基线。

Conclusion: DHAGrasp能够有效地生成多样化且符合语义的双手机器人抓取，解决了现有双手机器人抓取研究中数据稀疏和语义信息不足的问题。

Abstract: Learning to generate dual-hand grasps that respect object semantics is
essential for robust hand-object interaction but remains largely underexplored
due to dataset scarcity. Existing grasp datasets predominantly focus on
single-hand interactions and contain only limited semantic part annotations. To
address these challenges, we introduce a pipeline, SymOpt, that constructs a
large-scale dual-hand grasp dataset by leveraging existing single-hand datasets
and exploiting object and hand symmetries. Building on this, we propose a
text-guided dual-hand grasp generator, DHAGrasp, that synthesizes Dual-Hand
Affordance-aware Grasps for unseen objects. Our approach incorporates a novel
dual-hand affordance representation and follows a two-stage design, which
enables effective learning from a small set of segmented training objects while
scaling to a much larger pool of unsegmented data. Extensive experiments
demonstrate that our method produces diverse and semantically consistent
grasps, outperforming strong baselines in both grasp quality and generalization
to unseen objects. The project page is at
https://quanzhou-li.github.io/DHAGrasp/.

</details>


### [416] [Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting](https://arxiv.org/abs/2509.22195)
*Asher J. Hancock,Xindi Wu,Lihan Zha,Olga Russakovsky,Anirudha Majumdar*

Main category: cs.RO

TL;DR: 通过将机器人遥操作数据中的低级动作与自然语言对齐，VLM2VLA 培训范式使用 LoRA 来微调视觉语言模型（VLM），以创建视觉语言动作（VLA）模型，从而在不损害 VLM 核心推理能力的情况下实现泛化。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉语言模型（VLM）在机器人遥操作数据上进行微调以创建视觉语言动作（VLA）模型时，会面临灾难性遗忘的问题，即学习动作会削弱 VLM 的推理和多模态理解能力，从而阻碍其在 novel 场景下的泛化、指令遵循和语义理解能力。这种遗忘源于 VLM 的预训练语料库与机器人微调数据之间的分布不匹配。

Method: VLM2VLA 训练范式通过在数据层面解决分布不匹配问题，将低级动作表示为自然语言。这种对齐使得仅使用低秩适应（LoRA）进行 VLA 训练成为可能，从而最大限度地减少对 VLM 主干的修改，并避免灾难性遗忘。

Result: 通过大量的视觉问答（VQA）研究和超过 800 次的真实世界机器人实验，证明 VLM2VLA 能够保留 VLM 的核心能力，并实现对需要开放世界语义推理和多语言指令遵循的新任务的零样本泛化。

Conclusion: VLM2VLA 训练范式通过数据对齐和 LoRA 微调，有效解决了 VLM 在机器人遥操作数据上微调时遇到的灾难性遗忘问题，在保留 VLM 基础能力的同时，实现了对新任务的良好泛化。

Abstract: Fine-tuning vision-language models (VLMs) on robot teleoperation data to
create vision-language-action (VLA) models is a promising paradigm for training
generalist policies, but it suffers from a fundamental tradeoff: learning to
produce actions often diminishes the VLM's foundational reasoning and
multimodal understanding, hindering generalization to novel scenarios,
instruction following, and semantic understanding. We argue that this
catastrophic forgetting is due to a distribution mismatch between the VLM's
internet-scale pretraining corpus and the robotics fine-tuning data. Inspired
by this observation, we introduce VLM2VLA: a VLA training paradigm that first
resolves this mismatch at the data level by representing low-level actions with
natural language. This alignment makes it possible to train VLAs solely with
Low-Rank Adaptation (LoRA), thereby minimally modifying the VLM backbone and
averting catastrophic forgetting. As a result, the VLM can be fine-tuned on
robot teleoperation data without fundamentally altering the underlying
architecture and without expensive co-training on internet-scale VLM datasets.
Through extensive Visual Question Answering (VQA) studies and over 800
real-world robotics experiments, we demonstrate that VLM2VLA preserves the
VLM's core capabilities, enabling zero-shot generalization to novel tasks that
require open-world semantic reasoning and multilingual instruction following.

</details>


### [417] [MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training](https://arxiv.org/abs/2509.22199)
*Haoyun Li,Ivan Zhang,Runqi Ouyang,Xiaofeng Wang,Zheng Zhu,Zhiqin Yang,Zhentao Zhang,Boyuan Wang,Chaojun Ni,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang,Zhenbo Song,Xingang Wang*

Main category: cs.RO

TL;DR: MimicDreamer框架通过对齐视觉、视角和动作，将人类演示转化为机器人可用的监督信号，有效缩小了人造视频与机器人执行视频之间的领域差距，显著提高了VLA模型在真实机器人上的少样本执行能力和整体成功率。


<details>
  <summary>Details</summary>
Motivation: 收集用于训练VLA模型的实体机器人交互数据成本高昂，而人类演示视频更具可扩展性和成本效益，但存在显著的领域差距（如视角不稳定、视觉差异、运动动力学差异）。

Method: 提出MimicDreamer框架，包含三个主要组件：1. H2R Aligner：利用视频扩散模型，将人类操作视频中的运动转移到生成的机器人演示视频中，以实现视觉对齐。 2. EgoStabilizer：通过同质变换规范化中心视角视频，并修复因扭曲引起的遮挡和失真，以稳定视角。 3. 动作对齐：将人类手部轨迹映射到机器人坐标系，并使用约束逆运动学求解器生成可行的、低抖动的关节指令，实现精确的姿态跟踪。

Result: 纯粹使用MimicDreamer合成的视频训练的VLA模型在真实机器人上实现了少样本执行。与仅使用真实机器人数据训练的模型相比，使用人类数据进行扩展训练显著提高了性能，在六个代表性操作任务的平均成功率上提高了14.7%。

Conclusion: MimicDreamer框架能够有效地将廉价的人类演示转化为机器人可用的监督信号，成功弥合了人类视频和机器人执行之间的领域差距，并显著提高了VLA模型的泛化能力和在机器人上的实际性能。

Abstract: Vision Language Action (VLA) models derive their generalization capability
from diverse training data, yet collecting embodied robot interaction data
remains prohibitively expensive. In contrast, human demonstration videos are
far more scalable and cost-efficient to collect, and recent studies confirm
their effectiveness in training VLA models. However, a significant domain gap
persists between human videos and robot-executed videos, including unstable
camera viewpoints, visual discrepancies between human hands and robotic arms,
and differences in motion dynamics. To bridge this gap, we propose
MimicDreamer, a framework that turns fast, low-cost human demonstrations into
robot-usable supervision by jointly aligning vision, viewpoint, and actions to
directly support policy training. For visual alignment, we propose H2R Aligner,
a video diffusion model that generates high-fidelity robot demonstration videos
by transferring motion from human manipulation footage. For viewpoint
stabilization, EgoStabilizer is proposed, which canonicalizes egocentric videos
via homography and inpaints occlusions and distortions caused by warping. For
action alignment, we map human hand trajectories to the robot frame and apply a
constrained inverse kinematics solver to produce feasible, low-jitter joint
commands with accurate pose tracking. Empirically, VLA models trained purely on
our synthesized human-to-robot videos achieve few-shot execution on real
robots. Moreover, scaling training with human data significantly boosts
performance compared to models trained solely on real robot data; our approach
improves the average success rate by 14.7\% across six representative
manipulation tasks.

</details>


### [418] [From Watch to Imagine: Steering Long-horizon Manipulation via Human Demonstration and Future Envisionment](https://arxiv.org/abs/2509.22205)
*Ke Ye,Jiaming Zhou,Yuanfeng Qiu,Jiayi Liu,Shihui Zhou,Kun-Yu Lin,Junwei Liang*

Main category: cs.RO

TL;DR: Super-Mimic是一个分层框架，通过从非脚本化的人类演示视频中直接推断程序意图，实现零样本机器人模仿。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态基础方法在仅从静态视觉输入分解高层命令到可执行动作序列方面的挑战。

Method: Super-Mimic包含两个模块：1. 人类意图翻译器（HIT）解析输入视频，生成语言约束的子任务序列。2. 未来动力学预测器（FDP）利用生成模型合成每个步骤的物理上可行的视频推出，以指导低级控制器。

Result: 在多种长时限操作任务上，Super-Mimic的性能显著优于最先进的零样本方法（超过20%）。

Conclusion: 将视频驱动的意图解析与前瞻性动力学建模相结合，是开发通用机器人系统的有效策略。

Abstract: Generalizing to long-horizon manipulation tasks in a zero-shot setting
remains a central challenge in robotics. Current multimodal foundation based
approaches, despite their capabilities, typically fail to decompose high-level
commands into executable action sequences from static visual input alone. To
address this challenge, we introduce Super-Mimic, a hierarchical framework that
enables zero-shot robotic imitation by directly inferring procedural intent
from unscripted human demonstration videos. Our framework is composed of two
sequential modules. First, a Human Intent Translator (HIT) parses the input
video using multimodal reasoning to produce a sequence of language-grounded
subtasks. These subtasks then condition a Future Dynamics Predictor (FDP),
which employs a generative model that synthesizes a physically plausible video
rollout for each step. The resulting visual trajectories are dynamics-aware,
explicitly modeling crucial object interactions and contact points to guide the
low-level controller. We validate this approach through extensive experiments
on a suite of long-horizon manipulation tasks, where Super-Mimic significantly
outperforms state-of-the-art zero-shot methods by over 20\%. These results
establish that coupling video-driven intent parsing with prospective dynamics
modeling is a highly effective strategy for developing general-purpose robotic
systems.

</details>


### [419] [Leveraging Large Language Models for Robot-Assisted Learning of Morphological Structures in Preschool Children with Language Vulnerabilities](https://arxiv.org/abs/2509.22287)
*Stina Sundstedt,Mattias Wingren,Susanne Hägglund,Daniel Ventus*

Main category: cs.RO

TL;DR: 该研究提出使用一个名为TalBot的应用程序，让Furhat机器人通过玩“Alias”游戏来提高幼儿的语言表达能力，特别是目标词法结构。该应用利用大型语言模型（LLM）来管理游戏、对话和情感反应，并计划进一步利用LLM生成和传递特定的词法目标。


<details>
  <summary>Details</summary>
Motivation: 幼儿，特别是语言发展障碍或有移民背景的儿童，需要支持来提高他们的表达性语言技能。目前的方法，如语言治疗师嵌入目标词法结构到日常互动或游戏活动中，对教育者来说是一个挑战，需要精确的语言知识和实时生成各种词法形式的能力，同时还要让孩子保持参与和管理轮流。

Method: 开发了一个名为TalBot的应用程序，该应用程序使用Furhat会话机器人与儿童玩“Alias”游戏来提高语言技能。目前，该应用程序使用大型语言模型（LLM）来管理游戏玩法、对话、情感反应和轮流。下一步计划是进一步利用LLM的能力，使机器人能够在游戏中生成和传递特定的词法目标。

Result: 目前，TalBot应用程序使用LLM来管理游戏、对话、情感反应和轮流。研究人员计划在下一步中利用LLM生成和传递特定的词法目标，并假设机器人可能在这个任务上优于人类。

Conclusion: 该方法的新颖之处在于，机器人可以最终作为儿童和专业人士的模型和导师，并且在此背景下使用LLM的功能将支持有语言障碍的儿童的基本沟通需求。长期目标是创建一个强大的、基于LLM的机器人辅助语言学习干预措施，能够教授不同语言的各种词法结构。

Abstract: Preschool children with language vulnerabilities -- such as developmental
language disorders or immigration related language challenges -- often require
support to strengthen their expressive language skills. Based on the principle
of implicit learning, speech-language therapists (SLTs) typically embed target
morphological structures (e.g., third person -s) into everyday interactions or
game-based learning activities. Educators are recommended by SLTs to do the
same. This approach demands precise linguistic knowledge and real-time
production of various morphological forms (e.g., "Daddy wears these when he
drives to work"). The task becomes even more demanding when educators or parent
also must keep children engaged and manage turn-taking in a game-based
activity. In the TalBot project our multiprofessional team have developed an
application in which the Furhat conversational robot plays the word retrieval
game "Alias" with children to improve language skills. Our application
currently employs a large language model (LLM) to manage gameplay, dialogue,
affective responses, and turn-taking. Our next step is to further leverage the
capacity of LLMs so the robot can generate and deliver specific morphological
targets during the game. We hypothesize that a robot could outperform humans at
this task. Novel aspects of this approach are that the robot could ultimately
serve as a model and tutor for both children and professionals and that using
LLM capabilities in this context would support basic communication needs for
children with language vulnerabilities. Our long-term goal is to create a
robust LLM-based Robot-Assisted Language Learning intervention capable of
teaching a variety of morphological structures across different languages.

</details>


### [420] [IMU-Preintegrated Radar Factors for Asynchronous Radar-LiDAR-Inertial SLAM](https://arxiv.org/abs/2509.22288)
*Johan Hatleskog,Morten Nissov,Kostas Alexis*

Main category: cs.RO

TL;DR: IMU-preintegrated radar factors reduce optimization costs by propagating LiDAR states to radar timestamps, maintaining LiDAR frequency and lowering node count by 50% for real-time performance on resource-constrained hardware.


<details>
  <summary>Details</summary>
Motivation: Conventional fixed-lag radar-LiDAR-inertial smoothers create a node per measurement, doubling state creation rate and increasing optimization costs, hindering real-time performance on constrained hardware.

Method: Introduce IMU-preintegrated radar factors that use high-rate IMU data to propagate the most recent LiDAR state to the radar measurement timestamp, maintaining the node creation rate at the LiDAR measurement frequency.

Result: Experimental results on a single board computer show that the proposed method preserves absolute pose error compared to a conventional baseline while reducing aggregated factor graph optimization time by up to 56%.

Conclusion: IMU-preintegrated radar factors offer a way to reduce computational costs in radar-LiDAR-inertial smoothing, enabling real-time performance on resource-constrained hardware without sacrificing accuracy.

Abstract: Fixed-lag Radar-LiDAR-Inertial smoothers conventionally create one factor
graph node per measurement to compensate for the lack of time synchronization
between radar and LiDAR. For a radar-LiDAR sensor pair with equal rates, this
strategy results in a state creation rate of twice the individual sensor
frequencies. This doubling of the number of states per second yields high
optimization costs, inhibiting real-time performance on resource-constrained
hardware. We introduce IMU-preintegrated radar factors that use high-rate
inertial data to propagate the most recent LiDAR state to the radar measurement
timestamp. This strategy maintains the node creation rate at the LiDAR
measurement frequency. Assuming equal sensor rates, this lowers the number of
nodes by 50 % and consequently the computational costs. Experiments on a single
board computer (which has 4 cores each of 2.2 GHz A73 and 2 GHz A53 with 8 GB
RAM) show that our method preserves the absolute pose error of a conventional
baseline while simultaneously lowering the aggregated factor graph optimization
time by up to 56 %.

</details>


### [421] [Beyond Detection -- Orchestrating Human-Robot-Robot Assistance via an Internet of Robotic Things Paradigm](https://arxiv.org/abs/2509.22296)
*Joseph Hunt,Koyo Fujii,Aly Magassouba,Praminda Caleb-Solly*

Main category: cs.RO

TL;DR: 本研究提出了一种基于IoRT（机器人物联网）的系统，通过结合热成像传感和机器人协作，实现对患者离床行为的预测和主动式辅助，以降低跌倒风险并满足患者需求。


<details>
  <summary>Details</summary>
Motivation: 医院患者跌倒是普遍存在且成本高昂的挑战，传统方法依赖事后检测或被动警报，存在误报率高和未能解决患者潜在需求的问题。

Method: 构建了一个集成了隐私保护热成像传感模型（用于实时预测离床行为）和两个协同机器人代理的系统架构。该系统能够根据预测的意图和患者输入动态响应，实现人-机器人-机器人之间的交互。

Result: 通过试点研究，展示了低分辨率热成像在准确、保护隐私的离床检测方面的潜力，并通过用户研究和错误分析，为构建情境感知、多智能体交互系统提供了依据。

Conclusion: 研究结果表明，交互式和互联的机器人系统能够超越被动监测，提供及时、有意义的辅助，从而实现更安全、更具响应性的护理环境。

Abstract: Hospital patient falls remain a critical and costly challenge worldwide.
While conventional fall prevention systems typically rely on post-fall
detection or reactive alerts, they also often suffer from high false positive
rates and fail to address the underlying patient needs that lead to bed-exit
attempts. This paper presents a novel system architecture that leverages the
Internet of Robotic Things (IoRT) to orchestrate human-robot-robot interaction
for proactive and personalized patient assistance. The system integrates a
privacy-preserving thermal sensing model capable of real-time bed-exit
prediction, with two coordinated robotic agents that respond dynamically based
on predicted intent and patient input. This orchestrated response could not
only reduce fall risk but also attend to the patient's underlying motivations
for movement, such as thirst, discomfort, or the need for assistance, before a
hazardous situation arises. Our contributions with this pilot study are
three-fold: (1) a modular IoRT-based framework enabling distributed sensing,
prediction, and multi-robot coordination; (2) a demonstration of low-resolution
thermal sensing for accurate, privacy-preserving preemptive bed-exit detection;
and (3) results from a user study and systematic error analysis that inform the
design of situationally aware, multi-agent interactions in hospital settings.
The findings highlight how interactive and connected robotic systems can move
beyond passive monitoring to deliver timely, meaningful assistance, empowering
safer, more responsive care environments.

</details>


### [422] [RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.22356)
*Enguang Liu,Siyuan Liang,Liming Lu,Xiyu Zeng,Xiaochun Cao,Aishan Liu,Shuchao Pang*

Main category: cs.RO

TL;DR: 该研究提出了 RoboView-Bias 基准，首次系统量化了机器人操作中的视觉偏见，并评估了三种代表性机器人代理，发现相机视角是主要的偏见因素，且视觉偏见会影响决策稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注泛化性和鲁棒性，缺乏对视觉偏见的系统量化，这阻碍了对感知如何影响决策稳定性的深入理解。

Method: 提出 RoboView-Bias 基准，采用结构化变体生成框架和感知公平性验证协议，创建了 2,127 个任务实例，用于量化单个视觉因素及其交互作用引起的偏见。系统评估了三种代表性机器人代理。

Result: 所有代理均表现出显著的视觉偏见，其中相机视角是最关键的因素。代理在高度饱和的颜色上成功率最高，表明继承了底层视觉-语言模型（VLMs）的偏见。视觉偏见表现出强烈的非对称耦合，视角显著放大了颜色相关偏见。

Conclusion: 系统分析视觉偏见是开发安全可靠的通用具身代理的先决条件。所提出的 RoboView-Bias 基准能够有效衡量和分析视觉偏见，并验证了基于语义接地层的偏见缓解策略的有效性。

Abstract: The safety and reliability of embodied agents rely on accurate and unbiased
visual perception. However, existing benchmarks mainly emphasize generalization
and robustness under perturbations, while systematic quantification of visual
bias remains scarce. This gap limits a deeper understanding of how perception
influences decision-making stability. To address this issue, we propose
RoboView-Bias, the first benchmark specifically designed to systematically
quantify visual bias in robotic manipulation, following a principle of factor
isolation. Leveraging a structured variant-generation framework and a
perceptual-fairness validation protocol, we create 2,127 task instances that
enable robust measurement of biases induced by individual visual factors and
their interactions. Using this benchmark, we systematically evaluate three
representative embodied agents across two prevailing paradigms and report three
key findings: (i) all agents exhibit significant visual biases, with camera
viewpoint being the most critical factor; (ii) agents achieve their highest
success rates on highly saturated colors, indicating inherited visual
preferences from underlying VLMs; and (iii) visual biases show strong,
asymmetric coupling, with viewpoint strongly amplifying color-related bias.
Finally, we demonstrate that a mitigation strategy based on a semantic
grounding layer substantially reduces visual bias by approximately 54.5\% on
MOKA. Our results highlight that systematic analysis of visual bias is a
prerequisite for developing safe and reliable general-purpose embodied agents.

</details>


### [423] [Learning-Based Collaborative Control for Bi-Manual Tactile-Reactive Grasping](https://arxiv.org/abs/2509.22421)
*Leonel Giacobbe,Jingdao Chen,Chuangchuang Sun*

Main category: cs.RO

TL;DR: 提出了一种基于学习的多智能体模型预测控制器（MPC），用于抓取各种具有不同软硬度和形状的物体，克服了现有单智能体方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人抓取方法大多针对刚性物体，在处理易碎或可变形材料时性能下降，且单智能体方法限制了抓取大型、重物体的能力。

Method: 提出了一种基于学习的多智能体MPC，利用两个Gelsight Mini触觉传感器提取物体纹理和硬度信息，实时估计接触动力学和物体顺应性，以适应不同的物体几何形状和硬度。控制器在闭环中运行，利用触觉编码预测抓取稳定性，并相应地调整力和位置。关键技术贡献包括：基于真实接触交互训练的多智能体MPC、用于推断抓取状态的触觉数据驱动方法以及实现协作控制的协调策略。

Result: 通过大量实验验证，与独立的PD和MPC基线相比，该方法在各种尺寸和硬度物体的稳定抓取成功率方面表现更优。

Conclusion: 通过结合触觉传感和基于学习的多智能体MPC，该方法为复杂环境中的协作抓取提供了鲁棒、智能的解决方案，显著提高了多智能体系统的能力。

Abstract: Grasping is a core task in robotics with various applications. However, most
current implementations are primarily designed for rigid items, and their
performance drops considerably when handling fragile or deformable materials
that require real-time feedback. Meanwhile, tactile-reactive grasping focuses
on a single agent, which limits their ability to grasp and manipulate large,
heavy objects. To overcome this, we propose a learning-based, tactile-reactive
multi-agent Model Predictive Controller (MPC) for grasping a wide range of
objects with different softness and shapes, beyond the capabilities of
preexisting single-agent implementations. Our system uses two Gelsight Mini
tactile sensors [1] to extract real-time information on object texture and
stiffness. This rich tactile feedback is used to estimate contact dynamics and
object compliance in real time, enabling the system to adapt its control policy
to diverse object geometries and stiffness profiles. The learned controller
operates in a closed loop, leveraging tactile encoding to predict grasp
stability and adjust force and position accordingly. Our key technical
contributions include a multi-agent MPC formulation trained on real contact
interactions, a tactile-data driven method for inferring grasping states, and a
coordination strategy that enables collaborative control. By combining tactile
sensing and a learning-based multi-agent MPC, our method offers a robust,
intelligent solution for collaborative grasping in complex environments,
significantly advancing the capabilities of multi-agent systems. Our approach
is validated through extensive experiments against independent PD and MPC
baselines. Our pipeline outperforms the baselines regarding success rates in
achieving and maintaining stable grasps across objects of varying sizes and
stiffness.

</details>


### [424] [An Ontology for Unified Modeling of Tasks, Actions, Environments, and Capabilities in Personal Service Robotics](https://arxiv.org/abs/2509.22434)
*Margherita Martorana,Francesca Urgese,Ilaria Tiddi,Stefan Schlobach*

Main category: cs.RO

TL;DR: 该论文提出 OntoBOT 本体，一个用于统一表征任务、动作、环境及机器人能力的本体，以支持服务机器人中的上下文感知推理、面向任务的执行和知识共享。


<details>
  <summary>Details</summary>
Motivation: 现有服务机器人解决方案通常与特定平台耦合，导致互操作性、可重用性和知识共享受限。需要一个统一的本体来表示任务、环境和机器人能力，以实现更通用的解决方案。

Method: 提出 OntoBOT 本体，该本体扩展了现有本体，统一了任务、动作、环境和机器人能力，并支持形式化推理。通过在 TIAGo、HSR、UR3 和 Stretch 四种机器人上评估，展示了该本体的通用性。

Result: OntoBOT 成功地统一了任务、动作、环境和机器人能力，并支持跨不同机器人平台的上下文感知推理和面向任务的执行。

Conclusion: OntoBOT 为服务机器人领域提供了一个通用的、可扩展的知识表征框架，能够促进机器人系统之间的互操作性、可重用性和知识共享。

Abstract: Personal service robots are increasingly used in domestic settings to assist
older adults and people requiring support. Effective operation involves not
only physical interaction but also the ability to interpret dynamic
environments, understand tasks, and choose appropriate actions based on
context. This requires integrating both hardware components (e.g. sensors,
actuators) and software systems capable of reasoning about tasks, environments,
and robot capabilities. Frameworks such as the Robot Operating System (ROS)
provide open-source tools that help connect low-level hardware with
higher-level functionalities. However, real-world deployments remain tightly
coupled to specific platforms. As a result, solutions are often isolated and
hard-coded, limiting interoperability, reusability, and knowledge sharing.
Ontologies and knowledge graphs offer a structured way to represent tasks,
environments, and robot capabilities. Existing ontologies, such as the
Socio-physical Model of Activities (SOMA) and the Descriptive Ontology for
Linguistic and Cognitive Engineering (DOLCE), provide models for activities,
spatial relationships, and reasoning structures. However, they often focus on
specific domains and do not fully capture the connection between environment,
action, robot capabilities, and system-level integration. In this work, we
propose the Ontology for roBOts and acTions (OntoBOT), which extends existing
ontologies to provide a unified representation of tasks, actions, environments,
and capabilities. Our contributions are twofold: (1) we unify these aspects
into a cohesive ontology to support formal reasoning about task execution, and
(2) we demonstrate its generalizability by evaluating competency questions
across four embodied agents - TIAGo, HSR, UR3, and Stretch - showing how
OntoBOT enables context-aware reasoning, task-oriented execution, and knowledge
sharing in service robotics.

</details>


### [425] [UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation](https://arxiv.org/abs/2509.22441)
*Zhangyuan Wang,Yunpeng Zhu,Yuqi Yan,Xiaoyuan Tian,Xinhao Shao,Meixuan Li,Weikun Li,Guangsheng Su,Weicheng Cui,Dixia Fan*

Main category: cs.RO

TL;DR: UnderwaterVLA是一个集成多模态基础模型和具身智能系统的水下自主导航框架，解决了水下操作的挑战，并通过实验证明其在恶劣条件下的导航精度和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 水下操作因流体动力干扰、通信带宽限制和浑浊水域中感官退化而面临挑战。

Method: 提出了一种包含高层任务推理和低层反应式控制的双脑架构，首次将视觉-语言-动作（VLA）模型应用于水下机器人，并采用了一种考虑流体动力影响的模型预测控制（MPC）方案。

Result: 在田野试验中，UnderwaterVLA在视觉条件下降的情况下，导航误差减少，任务完成率比基线提高了19%至27%。

Conclusion: UnderwaterVLA通过最小化对水下特定训练数据的依赖性，并提高跨环境的适应性，为下一代智能AUV提供了一条可扩展且经济高效的路径。

Abstract: This paper presents UnderwaterVLA, a novel framework for autonomous
underwater navigation that integrates multimodal foundation models with
embodied intelligence systems. Underwater operations remain difficult due to
hydrodynamic disturbances, limited communication bandwidth, and degraded
sensing in turbid waters. To address these challenges, we introduce three
innovations. First, a dual-brain architecture decouples high-level mission
reasoning from low-level reactive control, enabling robust operation under
communication and computational constraints. Second, we apply
Vision-Language-Action(VLA) models to underwater robotics for the first time,
incorporating structured chain-of-thought reasoning for interpretable
decision-making. Third, a hydrodynamics-informed Model Predictive Control(MPC)
scheme compensates for fluid effects in real time without costly task-specific
training. Experimental results in field tests show that UnderwaterVLA reduces
navigation errors in degraded visual conditions while maintaining higher task
completion by 19% to 27% over baseline. By minimizing reliance on
underwater-specific training data and improving adaptability across
environments, UnderwaterVLA provides a scalable and cost-effective path toward
the next generation of intelligent AUVs.

</details>


### [426] [Uncertainty-Aware Multi-Robot Task Allocation With Strongly Coupled Inter-Robot Rewards](https://arxiv.org/abs/2509.22469)
*Ben Rossano,Jaein Lim,Jonathan P. How*

Main category: cs.RO

TL;DR: 提出一种异构机器人团队任务分配算法，以应对任务需求不确定的环境。


<details>
  <summary>Details</summary>
Motivation: 在任务需求不确定的环境中，为异构机器人团队设计一种能够主动规避任务失败且不浪费资源的任务分配算法。

Method: 提出一种基于市场的分配方法，该方法优化团队整体目标，同时明确考虑机器人之间的耦合奖励。该方法在分散式环境下，在严格的通信假设下，提供了一个多项式时间的解决方案。

Result: 与基准算法的比较实验证明了该方法的有效性，并突出了在分散式模型中包含耦合奖励所带来的挑战。

Conclusion: 所提出的基于市场的任务分配方法能够有效处理异构机器人团队在任务需求不确定的情况下的任务分配问题，并能处理机器人之间的耦合奖励。

Abstract: This paper proposes a task allocation algorithm for teams of heterogeneous
robots in environments with uncertain task requirements. We model these
requirements as probability distributions over capabilities and use this model
to allocate tasks such that robots with complementary skills naturally position
near uncertain tasks, proactively mitigating task failures without wasting
resources. We introduce a market-based approach that optimizes the joint team
objective while explicitly capturing coupled rewards between robots, offering a
polynomial-time solution in decentralized settings with strict communication
assumptions. Comparative experiments against benchmark algorithms demonstrate
the effectiveness of our approach and highlight the challenges of incorporating
coupled rewards in a decentralized formulation.

</details>


### [427] [HELIOS: Hierarchical Exploration for Language-grounded Interaction in Open Scenes](https://arxiv.org/abs/2509.22498)
*Katrina Ashton,Chahyon Ku,Shrey Shah,Wen Jiang,Kostas Daniilidis,Bernadette Bucher*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Language-specified mobile manipulation tasks in novel environments
simultaneously face challenges interacting with a scene which is only partially
observed, grounding semantic information from language instructions to the
partially observed scene, and actively updating knowledge of the scene with new
observations. To address these challenges, we propose HELIOS, a hierarchical
scene representation and associated search objective to perform language
specified pick and place mobile manipulation tasks. We construct 2D maps
containing the relevant semantic and occupancy information for navigation while
simultaneously actively constructing 3D Gaussian representations of
task-relevant objects. We fuse observations across this multi-layered
representation while explicitly modeling the multi-view consistency of the
detections of each object. In order to efficiently search for the target
object, we formulate an objective function balancing exploration of unobserved
or uncertain regions with exploitation of scene semantic information. We
evaluate HELIOS on the OVMM benchmark in the Habitat simulator, a pick and
place benchmark in which perception is challenging due to large and complex
scenes with comparatively small target objects. HELIOS achieves
state-of-the-art results on OVMM. As our approach is zero-shot, HELIOS can also
transfer to the real world without requiring additional data, as we illustrate
by demonstrating it in a real world office environment on a Spot robot.

</details>


### [428] [An Intention-driven Lane Change Framework Considering Heterogeneous Dynamic Cooperation in Mixed-traffic Environment](https://arxiv.org/abs/2509.22550)
*Xiaoyun Qiu,Haichao Liu,Yue Pan,Jun Ma,Xinhu Zheng*

Main category: cs.RO

TL;DR: 该研究提出了一个针对混合交通环境中自动驾驶汽车（AV）变道意图识别和执行的框架，通过整合驾驶风格识别、合作意图评估和运动规划，以提高安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 在混合交通环境中，人类驾驶车辆（HV）的多样化行为和不可预测性给自动驾驶汽车（AV）的安全高效变道带来了巨大挑战。现有方法往往简化了这种复杂的交互。

Method: 提出了一种意图驱动的变道框架，包括：1. 使用基于深度学习的分类器（在NGSIM数据集上训练）实时识别驾驶风格。2. 引入包含内在和交互成分的合作分数，以评估意图和合作意愿。3. 结合行为克隆和逆强化学习（IRL）来决定是否执行变道。4. 结合模型预测控制（MPC）和IRL意图推断来生成无碰撞、符合社会规范的轨迹。

Result: 实验证明，该模型在变道识别方面达到了94.2%的准确率和94.3%的F1分数，在识别率上超越了基于规则和学习方法8-15%。

Conclusion: 对驾驶员异质性的建模有助于提高自动驾驶的上下文感知能力和类人行为，该框架有望在复杂交通环境中实现更高级别的自动驾驶。

Abstract: In mixed-traffic environments, where autonomous vehicles (AVs) interact with
diverse human-driven vehicles (HVs), unpredictable intentions and heterogeneous
behaviors make safe and efficient lane change maneuvers highly challenging.
Existing methods often oversimplify these interactions by assuming uniform
patterns. We propose an intention-driven lane change framework that integrates
driving-style recognition, cooperation-aware decision-making, and coordinated
motion planning. A deep learning classifier trained on the NGSIM dataset
identifies human driving styles in real time. A cooperation score with
intrinsic and interactive components estimates surrounding drivers' intentions
and quantifies their willingness to cooperate with the ego vehicle.
Decision-making combines behavior cloning with inverse reinforcement learning
to determine whether a lane change should be initiated. For trajectory
generation, model predictive control is integrated with IRL-based intention
inference to produce collision-free and socially compliant maneuvers.
Experiments show that the proposed model achieves 94.2\% accuracy and 94.3\%
F1-score, outperforming rule-based and learning-based baselines by 4-15\% in
lane change recognition. These results highlight the benefit of modeling
inter-driver heterogeneity and demonstrate the potential of the framework to
advance context-aware and human-like autonomous driving in complex traffic
environments.

</details>


### [429] [MINT-RVAE: Multi-Cues Intention Prediction of Human-Robot Interaction using Human Pose and Emotion Information from RGB-only Camera Data](https://arxiv.org/abs/2509.22573)
*Farida Mohsen,Ali Safa*

Main category: cs.RO

TL;DR: 该研究提出了一种仅使用RGB输入的新方法，通过MINT-RVAE和新的损失函数/训练策略，实现了高精度的交互意图预测（AUROC: 0.95），解决了数据集类别不平衡问题，并公开了新的数据集。


<details>
  <summary>Details</summary>
Motivation: 为了实现更有效的机器人交互，需要高效地检测人类与机器人交互的意图，但现有方法多依赖多模态输入且受数据集类别不平衡问题影响。

Method: 提出了一种仅使用RGB输入的流水线，并引入了MINT-RVAE（合成序列生成方法）以及新的损失函数和训练策略，以解决类别不平衡问题并提高模型泛化能力。

Result: 该方法在交互意图预测任务上达到了最先进的性能（AUROC: 0.95），优于先前工作（AUROC: 0.90-0.912），并且仅需RGB输入，支持精确的帧起始预测。

Conclusion: 该研究成功开发了一种仅使用RGB输入的、高精度的交互意图预测方法，解决了类别不平衡问题，并为未来的研究发布了新的数据集。

Abstract: Efficiently detecting human intent to interact with ubiquitous robots is
crucial for effective human-robot interaction (HRI) and collaboration. Over the
past decade, deep learning has gained traction in this field, with most
existing approaches relying on multimodal inputs, such as RGB combined with
depth (RGB-D), to classify time-sequence windows of sensory data as interactive
or non-interactive. In contrast, we propose a novel RGB-only pipeline for
predicting human interaction intent with frame-level precision, enabling faster
robot responses and improved service quality. A key challenge in intent
prediction is the class imbalance inherent in real-world HRI datasets, which
can hinder the model's training and generalization. To address this, we
introduce MINT-RVAE, a synthetic sequence generation method, along with new
loss functions and training strategies that enhance generalization on
out-of-sample data. Our approach achieves state-of-the-art performance (AUROC:
0.95) outperforming prior works (AUROC: 0.90-0.912), while requiring only RGB
input and supporting precise frame onset prediction. Finally, to support future
research, we openly release our new dataset with frame-level labeling of human
interaction intent.

</details>


### [430] [EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation](https://arxiv.org/abs/2509.22578)
*Yuan Xu,Jiabing Yang,Xiaofeng Wang,Yixiang Chen,Zheng Zhu,Bowen Fang,Guan Huang,Xinze Chen,Yun Ye,Qiang Zhang,Peiyan Li,Xiangnan Wu,Kai Wang,Bing Zhan,Shuo Lu,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.RO

TL;DR: EgoDemoGen框架通过重定向动作和生成视频来创建新的中心视角演示，解决了单一中心视角训练策略在机器人操作中因视角变化而性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 单一中心视角训练的模仿学习策略在机器人操作中，当面对视角变化时性能会下降。

Method: 提出EgoDemoGen框架，包含EgoViewTransfer模型，该模型利用重投影场景视频和机器人自身视频生成新的中心视角演示。

Result: 在模拟和真实机器人实验中，使用EgoDemoGen生成的演示训练的策略，在标准和新颖的中心视角下的成功率均有显著提升（模拟提升约17-18%，真实机器人提升约18-26%）。

Conclusion: EgoDemoGen为实现对中心视角变化鲁棒的机器人操作提供了一种实用方法。

Abstract: Imitation learning based policies perform well in robotic manipulation, but
they often degrade under *egocentric viewpoint shifts* when trained from a
single egocentric viewpoint. To address this issue, we present **EgoDemoGen**,
a framework that generates *paired* novel egocentric demonstrations by
retargeting actions in the novel egocentric frame and synthesizing the
corresponding egocentric observation videos with proposed generative video
repair model **EgoViewTransfer**, which is conditioned by a novel-viewpoint
reprojected scene video and a robot-only video rendered from the retargeted
joint actions. EgoViewTransfer is finetuned from a pretrained video generation
model using self-supervised double reprojection strategy. We evaluate
EgoDemoGen on both simulation (RoboTwin2.0) and real-world robot. After
training with a mixture of EgoDemoGen-generated novel egocentric demonstrations
and original standard egocentric demonstrations, policy success rate improves
**absolutely** by **+17.0%** for standard egocentric viewpoint and by
**+17.7%** for novel egocentric viewpoints in simulation. On real-world robot,
the **absolute** improvements are **+18.3%** and **+25.8%**. Moreover,
performance continues to improve as the proportion of EgoDemoGen-generated
demonstrations increases, with diminishing returns. These results demonstrate
that EgoDemoGen provides a practical route to egocentric viewpoint-robust
robotic manipulation.

</details>


### [431] [WoW: Towards a World omniscient World model Through Embodied Interaction](https://arxiv.org/abs/2509.22642)
*Xiaowei Chi,Peidong Jia,Chun-Kai Fan,Xiaozhu Ju,Weishi Mi,Kevin Zhang,Zhiyuan Qin,Wanxin Tian,Kuangzhi Ge,Hao Li,Zezhong Qian,Anthony Chen,Qiang Zhou,Yueru Jia,Jiaming Liu,Yong Dai,Qingpo Wuwu,Chengyu Bai,Yu-Kai Wang,Ying Li,Lizhang Chen,Yong Bao,Zhiyuan Jiang,Jiacheng Zhu,Kai Tang,Ruichuan An,Yulin Luo,Qiuxuan Feng,Siyuan Zhou,Chi-min Chan,Chengkai Hou,Wei Xue,Sirui Han,Yike Guo,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: 通过在真实世界中进行大规模交互来训练AI模型，以实现更强的物理直觉和因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视频模型（如Sora）主要依赖被动观察，难以理解物理因果关系。本研究假设，真实的物理直觉需要通过与现实世界的丰富交互来获得。

Method: 提出WoW（一个140亿参数的生成式世界模型），并在200万个机器人交互轨迹上进行训练。通过SOPHIA（一个视觉-语言模型代理）来约束WoW的输出，使其符合物理现实。同时，训练了一个逆向动力学模型将规划转化为机器人动作。最后，创建了WoWBench基准来评估模型的物理一致性和因果推理能力。

Result: WoW模型展示了其物理理解能力，但存在不确定性和物理幻觉。SOPHIA成功地引导WoW生成了更符合物理现实的视频。WoW在WoWBench基准测试中取得了最先进的性能，尤其在物理因果、碰撞动力学和物体持久性方面表现突出。

Conclusion: 大规模、真实世界的交互是AI发展物理直觉的关键。本研究提出的方法和基准为未来研究奠定了基础。

Abstract: Humans develop an understanding of intuitive physics through active
interaction with the world. This approach is in stark contrast to current video
models, such as Sora, which rely on passive observation and therefore struggle
with grasping physical causality. This observation leads to our central
hypothesis: authentic physical intuition of the world model must be grounded in
extensive, causally rich interactions with the real world. To test this
hypothesis, we present WoW, a 14-billion-parameter generative world model
trained on 2 million robot interaction trajectories. Our findings reveal that
the model's understanding of physics is a probabilistic distribution of
plausible outcomes, leading to stochastic instabilities and physical
hallucinations. Furthermore, we demonstrate that this emergent capability can
be actively constrained toward physical realism by SOPHIA, where
vision-language model agents evaluate the DiT-generated output and guide its
refinement by iteratively evolving the language instructions. In addition, a
co-trained Inverse Dynamics Model translates these refined plans into
executable robotic actions, thus closing the imagination-to-action loop. We
establish WoWBench, a new benchmark focused on physical consistency and causal
reasoning in video, where WoW achieves state-of-the-art performance in both
human and autonomous evaluation, demonstrating strong ability in physical
causality, collision dynamics, and object permanence. Our work provides
systematic evidence that large-scale, real-world interaction is a cornerstone
for developing physical intuition in AI. Models, data, and benchmarks will be
open-sourced.

</details>


### [432] [VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search](https://arxiv.org/abs/2509.22643)
*Wenkai Guo,Guanxing Lu,Haoyuan Deng,Zhenyu Wu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: VLA-Reasoner 是一个即插即用框架，通过测试时扩展来增强现有 VLA 模型，使其能够预测未来状态，从而解决现有 VLA 模型在长期任务中预测短期动作的问题。


<details>
  <summary>Details</summary>
Motivation: 现有 Vision-Language-Action (VLA) 模型在处理长期机器人操控任务时存在局限性，因为它们只能预测短期内的下一个动作，容易在多步操作中累积偏差。

Method: VLA-Reasoner 通过采样和展开可能的动作轨迹，并使用世界模型生成未来状态来预测潜在结果，然后利用蒙特卡洛树搜索 (MCTS) 和基于核密度估计 (KDE) 的置信度采样机制来提高在大型动作空间中的搜索效率，并通过离线奖励重塑策略来评估中间状态并纠正长期偏差。

Result: 在模拟器和真实世界的广泛实验表明，VLA-Reasoner 相比于现有的最先进的 VLA 模型有了显著的改进。

Conclusion: VLA-Reasoner 为可扩展的机器人操控测试时计算提供了一条潜在路径。

Abstract: Vision-Language-Action models (VLAs) achieve strong performance in general
robotic manipulation tasks by scaling imitation learning. However, existing
VLAs are limited to predicting short-sighted next-action, which struggle with
long-horizon trajectory tasks due to incremental deviations. To address this
problem, we propose a plug-in framework named VLA-Reasoner that effectively
empowers off-the-shelf VLAs with the capability of foreseeing future states via
test-time scaling. Specifically, VLA-Reasoner samples and rolls out possible
action trajectories where involved actions are rationales to generate future
states via a world model, which enables VLA-Reasoner to foresee and reason
potential outcomes and search for the optimal actions. We further leverage
Monte Carlo Tree Search (MCTS) to improve search efficiency in large action
spaces, where stepwise VLA predictions seed the root. Meanwhile, we introduce a
confidence sampling mechanism based on Kernel Density Estimation (KDE), to
enable efficient exploration in MCTS without redundant VLA queries. We evaluate
intermediate states in MCTS via an offline reward shaping strategy, to score
predicted futures and correct deviations with long-term feedback. We conducted
extensive experiments in both simulators and the real world, demonstrating that
our proposed VLA-Reasoner achieves significant improvements over the
state-of-the-art VLAs. Our method highlights a potential pathway toward
scalable test-time computation of robotic manipulation.

</details>


### [433] [Pixel Motion Diffusion is What We Need for Robot Control](https://arxiv.org/abs/2509.22652)
*E-Ro Nguyen,Yichi Zhang,Kanchana Ranasinghe,Xiang Li,Michael S. Ryoo*

Main category: cs.RO

TL;DR: DAWN是一个统一的基于扩散的机器人控制框架，通过结构化像素运动表示来连接高层运动意图和低层机器人动作，在CALVIN和MetaWorld基准测试中取得了最先进的成果，并证明了其在真实世界中的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的、基于扩散的机器人控制框架，以连接高层运动意图和低层机器人动作，并克服模拟到现实的领域差距。

Method: 将高层和低层控制器建模为扩散过程，使用结构化像素运动表示，创建一个完全可训练的、端到端的系统。

Result: 在CALVIN基准测试中取得了最先进的成果，在MetaWorld上表现良好，并成功地将模型迁移到真实世界机器人上，仅进行了少量微调。

Conclusion: 基于扩散的模型和以运动为中心的表示相结合，为可扩展、鲁棒的机器人学习提供了一个有效的基线。

Abstract: We present DAWN (Diffusion is All We Need for robot control), a unified
diffusion-based framework for language-conditioned robotic manipulation that
bridges high-level motion intent and low-level robot action via structured
pixel motion representation. In DAWN, both the high-level and low-level
controllers are modeled as diffusion processes, yielding a fully trainable,
end-to-end system with interpretable intermediate motion abstractions. DAWN
achieves state-of-the-art results on the challenging CALVIN benchmark,
demonstrating strong multi-task performance, and further validates its
effectiveness on MetaWorld. Despite the substantial domain gap between
simulation and reality and limited real-world data, we demonstrate reliable
real-world transfer with only minimal finetuning, illustrating the practical
viability of diffusion-based motion abstractions for robotic control. Our
results show the effectiveness of combining diffusion modeling with
motion-centric representations as a strong baseline for scalable and robust
robot learning. Project page: https://nero1342.github.io/DAWN/

</details>


### [434] [See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation](https://arxiv.org/abs/2509.22653)
*Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu*

Main category: cs.RO

TL;DR: SPF是一个无需训练的航空视觉-语言导航（AVLN）框架，它将导航视为一个2D空间定位任务，通过将语言指令分解为2D航点和预测的行进距离，将其转换为3D位移向量作为无人机的动作指令。该框架能够根据自由形式的指令在任何环境中导航到任何目标，并在模拟和真实世界评估中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于VLM的方法将动作预测视为文本生成任务，而本研究认为AVLN的动作预测更适合视为一个2D空间定位任务。

Method: SPF利用VLM将模糊的语言指令分解为输入图像上2D航点的迭代标注，并结合预测的行进距离，将2D航点转换为3D位移向量作为无人机的动作指令。该框架还能够自适应地调整行进距离以提高导航效率，并以闭环控制方式进行导航，从而能够在动态环境中跟踪动态目标。

Result: SPF在DRL模拟基准测试中创下新的最先进记录，比之前最好的方法提高了63%。在广泛的真实世界评估中，SPF的表现也显著优于强基线方法。此外，SPF在不同VLM上的泛化能力也得到了验证。

Conclusion: SPF是一个有效的、无需训练的航空视觉-语言导航框架，通过将导航视为2D空间定位任务，并结合航点标注和自适应距离调整，实现了高效的导航和对动态目标的跟踪。其卓越的性能和泛化能力证明了该方法的有效性。

Abstract: We present See, Point, Fly (SPF), a training-free aerial vision-and-language
navigation (AVLN) framework built atop vision-language models (VLMs). SPF is
capable of navigating to any goal based on any type of free-form instructions
in any kind of environment. In contrast to existing VLM-based approaches that
treat action prediction as a text generation task, our key insight is to
consider action prediction for AVLN as a 2D spatial grounding task. SPF
harnesses VLMs to decompose vague language instructions into iterative
annotation of 2D waypoints on the input image. Along with the predicted
traveling distance, SPF transforms predicted 2D waypoints into 3D displacement
vectors as action commands for UAVs. Moreover, SPF also adaptively adjusts the
traveling distance to facilitate more efficient navigation. Notably, SPF
performs navigation in a closed-loop control manner, enabling UAVs to follow
dynamic targets in dynamic environments. SPF sets a new state of the art in DRL
simulation benchmark, outperforming the previous best method by an absolute
margin of 63%. In extensive real-world evaluations, SPF outperforms strong
baselines by a large margin. We also conduct comprehensive ablation studies to
highlight the effectiveness of our design choice. Lastly, SPF shows remarkable
generalization to different VLMs. Project page: https://spf-web.pages.dev

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [435] [A Crime/S.I.R. optimal control problem](https://arxiv.org/abs/2509.21406)
*Mariana Álvarez,Alexander Alegría,Andrés Rivera,Sebastián Pedersen*

Main category: eess.SY

TL;DR: 本研究提出一个受控制理论启发的数学模型，利用最优控制理论来制定最优公共政策，以最低的经济成本来最小化犯罪活动。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为犯罪活动制定最优的公共政策，以最低的经济成本最小化犯罪活动。

Method: 使用受控制理论启发的数学模型，包括一个 SIR 动态系统，并利用变分演算和最优控制理论来解决最优控制问题。

Result: 本研究得出了最优控制，即预防政策（如社区和社会凝聚力计划），预计将对减少犯罪产生重大而积极的影响，为卡利社会最不利部门创造机会，并促进长期安全。

Conclusion: 本研究得出结论，通过结合公共干预措施和政策，可以有效控制犯罪活动，从而降低犯罪率，并实现经济效益。

Abstract: This paper presents and discusses a mathematical model inspired by control
theory to derive optimal public policies for minimizing costs associated with
the reduction and control of criminal activity in a population. Specifically,
we analyze the optimal control problem \begin{equation*} \min G(u_1, u_2, u_3)
= \int_{0}^{t_{\text{F}}} \left( I(t) - R(t) + \frac{B_1}{2} u_1^2(t) +
\frac{B_2}{2} u_2^2(t) + \frac{B_3}{2} u_3^2(t) \right) \, dt. \end{equation*}
where $I=I(t)$ and $R=R(t)$ satisfies the system of equations \begin{equation*}
\left\{ \begin{aligned} \dot{S} &= \Lambda - (1-u_1)SI - \mu S +
((1+u_3)\gamma_2)I + \rho \Omega R,\\ \dot{I} &= (1-u_1)SI - (\mu + \delta_1)I
- ((1+u_2)\gamma_1)I - ((1+u_3)\gamma_2)I + (1-\Omega)\rho R,\\ \dot{R} &=
((1+u_2)\gamma_1)I - (\mu + \delta_2 + \rho)R. \end{aligned} \right.
\end{equation*} Our approach assumes that the social and economic effects of
criminal behavior can be modeled by a dynamic SIR-type system, which serves as
a constraint on a cost functional associated with the strategies implemented by
government and law enforcement authorities to reduce criminal behavior. Using
optimal control theory, the proposed controls, i.e., preventive policies (such
as community and social cohesion programs), are expected to have a significant
and positive impact on crime reduction, generating opportunities for the most
disadvantaged sectors of Cali society and contributing to long-term security.
Given that resources to address this problem are limited, this research aims to
determine an optimal combination of public interventions and policies that
minimize criminality at the lowest possible economic cost, using an SIR model,
tools from variational calculus, and optimal control theory.

</details>


### [436] [Quaternionic Pole Placement via Companion Forms and the Ackermann Formula](https://arxiv.org/abs/2509.21425)
*Michael Sebek*

Main category: eess.SY

TL;DR: 本文将状态反馈极点配置方法扩展到四元数系统，并提出了基于伴随型和Ackermann公式的实现方法。


<details>
  <summary>Details</summary>
Motivation: 为可控的单输入四元数LTI模型提供极点配置的设计方法。

Method: 提出四元数伴随多项式，定义其伴随矩阵；通过右特征值相似类来表征谱；证明了可控坐标下的系数匹配设计；推导了适用于实目标多项式的无坐标Ackermann增益表达式。

Result: 通过具体实例验证了该方法的正确性、实用性和数值简易性。

Conclusion: 所提出的方法能够有效地对方的四元数系统进行极点配置。

Abstract: We present an extension of state-feedback pole placement for quaternionic
systems, based on companion forms and the Ackermann formula. For controllable
single-input quaternionic LTI models, we define a companion polynomial that
right-annihilates its companion matrix, characterize spectra via
right-eigenvalue similarity classes, and prove coefficient-matching design in
controllable coordinates. We then derive a coordinate-free Ackermann gain
expression valid for real target polynomials, and state its scope and
limitations. Short examples demonstrate correctness, practical use, and
numerical simplicity.

</details>


### [437] [Mitigation of Active Power Oscillation in Multi-VSG Grids: An Impedance-Based Perspective](https://arxiv.org/abs/2509.21642)
*Junjie Xiao,Lu Wang,Xiong Du,Pedro Rodriguez,Zian Qin*

Main category: eess.SY

TL;DR: VSG控制下的多逆变器电力系统中，逆变器并网振荡（APO）是一个严峻的挑战。本研究提出了基于RLC等效电路模型来解释APO的根本原因，并开发了两种针对特定模式的抑制策略：在独立模式（SA）下，采用基于图论的阻抗控制；在并网模式（GC）下，采用自适应惯量和阻尼控制。仿真和硬件在环实验验证了这些方法的有效性。


<details>
  <summary>Details</summary>
Motivation: VSG控制下的多逆变器电力系统中，APO对系统稳定性和保护协调构成威胁。现有的抑制策略存在依赖先验知识、阻尼效果有限或模型复杂难于应用的缺点。

Method: 首先，建立了一个物理上直观的RLC等效电路模型来解释APO的根本原因，将惯量、阻尼和馈线阻抗映射到电容、电阻和电感元件。在此基础上，提出两种模式特定的抑制策略：在SA模式下，采用基于图论的阻抗控制；在GC模式下，设计了具有前馈滤波的自适应惯量和阻尼控制。

Result: 所提出的APO抑制策略在SA和GC模式下均被有效验证，能够抑制振荡并增强多逆变器电力系统的鲁棒性。

Conclusion: RLC等效电路模型为理解和解决VSG控制下的APO问题提供了新的视角，所提出的两种模式特定的控制策略能够有效地抑制APO，提升电力系统的稳定性和鲁棒性。

Abstract: Active power oscillations frequently arise in inverter-dominated power
systems with multiple converters operating under Virtual Synchronous Generator
control, posing risks to system stability and protection coordination. While
various mitigation strategies have been proposed, many rely on prior knowledge
of system parameters, offer limited damping performance, or involve complex
models that lack physical interpretability, making them difficult to apply in
practice. To address these challenges, this paper first introduces a physically
intuitive RLC equivalent circuit model to explain the root causes of APOs in
both stand-alone and grid-connected modes. By mapping inertia, damping, and
feeder impedance to capacitive, resistive, and inductive elements,
respectively, the model reveals how mismatches among converters lead to
inter-unit oscillations characterized by LC resonance. Building on this
insight, we propose two mode-specific mitigation strategies: in SA mode, a
graph theory based impedance control ensures proportional reactive power
sharing and effectively suppresses APOs; and in GC mode, adaptive inertia and
damping control with feedforward filtering is designed to reshape transient
power dynamics while preserving frequency stability. The proposed methods are
validated through extensive simulations and real-time hardware-in-the-loop
experiments, demonstrating their effectiveness in suppressing oscillations and
enhancing the robustness of multi-converter power systems.

</details>


### [438] [NEO-Grid: A Neural Approximation Framework for Optimization and Control in Distribution Grids](https://arxiv.org/abs/2509.21668)
*Mohamad Chehade,Hao Zhu*

Main category: eess.SY

TL;DR: NEO-Grid是一个统一的、基于学习的框架，用于电压-伏特优化（VVO）和电压-伏特控制（VVC），以应对分布式能源（DERs）带来的电网挑战。


<details>
  <summary>Details</summary>
Motivation: 分布式能源（DERs）的兴起正在重塑现代配电网，在动态和分散的运行条件下实现电压稳定面临新的挑战。

Method: 该框架使用神经网络替代（surrogates）进行潮流计算，并使用深度均衡模型（DEQs）进行闭环控制。它用分段线性ReLU网络取代了传统的线性近似，以捕捉功率注入和电压幅度之间的非线性关系。对于控制，它使用DEQs对电压和逆变器响应之间的递归交互进行建模，从而可以直接进行不动点计算并通过隐式微分进行有效训练。

Result: 在IEEE 33节点系统上进行了评估，与标准的线性和启发式基线相比，NEO-Grid在优化和控制方面都显著提高了电压调节性能。

Conclusion: NEO-Grid为配电网中基于学习的电压调节提供了一个可扩展、准确且可解释的解决方案。

Abstract: The rise of distributed energy resources (DERs) is reshaping modern
distribution grids, introducing new challenges in attaining voltage stability
under dynamic and decentralized operating conditions. This paper presents
NEO-Grid, a unified learning-based framework for volt-var optimization (VVO)
and volt-var control (VVC) that leverages neural network surrogates for power
flow and deep equilibrium models (DEQs) for closed-loop control. Our method
replaces traditional linear approximations with piecewise-linear ReLU networks
trained to capture the nonlinear relationship between power injections and
voltage magnitudes. For control, we model the recursive interaction between
voltage and inverter response using DEQs, allowing direct fixed-point
computation and efficient training via implicit differentiation. We evaluated
NEO-Grid on the IEEE 33-bus system, demonstrating that it significantly
improves voltage regulation performance compared to standard linear and
heuristic baselines in both optimization and control settings. Our results
establish NEO-Grid as a scalable, accurate, and interpretable solution for
learning-based voltage regulation in distribution grids.

</details>


### [439] [On Suboptimal Safety-Critical Tracking Controller Design](https://arxiv.org/abs/2509.21726)
*Yazdan Batmani,Saber Omidi*

Main category: eess.SY

TL;DR: 提出一种基于状态相关Riccati方程（SDRE）方法的非线性系统安全关键最优轨迹跟踪新框架，通过嵌入势垒状态同时满足安全和跟踪要求，并允许在安全约束和跟踪精度之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: 在安全性和跟踪精度可能冲突的情况下，为安全关键的非线性系统实现最优轨迹跟踪。

Method: 通过将势垒状态嵌入系统动力学，并采用折扣伪二次成本函数，利用SDRE方法设计控制器。提供两种控制器设计：一种使用单个势垒状态，另一种使用多个势垒状态以增强灵活性。

Result: 证明了相关Riccati方程的可解性，并在模拟（机械系统、移动机器人避碰）和实验（线驱动并联机器人）中验证了该方法在保持安全的同时实现轨迹跟踪的能力。

Conclusion: 所提出的安全SDRE控制器计算成本合理，适用于实际系统的实时实现，并在各种挑战性条件下有效。

Abstract: This paper proposes a novel framework for safety-critical optimal trajectory
tracking in nonlinear systems based on the state-dependent Riccati equation
(SDRE) methodology. By embedding barrier states into the system dynamics, the
proposed strategy simultaneously ensures safety and tracking requirements, even
in scenarios where these objectives may be inherently conflicting. A discounted
pseudo-quadratic cost function is formulated to achieve a suboptimal trade-off
between tracking accuracy, control effort, and safety objective. We present two
distinct controller designs: one utilizing a single barrier state to enforce
overall safety constraints, and another employing multiple barrier states to
individually tuning the system's conservatism with respect to each safety
constraint, providing enhanced flexibility in tuning the system's conservatism
toward individual constraints. We establish sufficient conditions to ensure the
solvability of the associated Riccati equations. The proposed safe controller
is well-suited for real-time implementation in practical systems, given its
reasonable computational requirements and compatibility with widely available
embedded microprocessors. This is supported by simulation studies involving a
mechanical system and a mobile robot collision avoidance scenario, where the
safe SDRE controller consistently maintained safety while achieving trajectory
tracking objectives in challenging conditions. Additionally, experimental
results on a cable-driven parallel robot further demonstrate the practical
applicability and effectiveness of the proposed method in real-world control
tasks.

</details>


### [440] [Reinforcement Learning Based Traffic Signal Design to Minimize Queue Lengths](https://arxiv.org/abs/2509.21745)
*Anirud Nandakumar,Chayan Banerjee,Lelitha Devi Vanajakshi*

Main category: eess.SY

TL;DR: 提出了一种新颖的自适应交通信号控制（TSC）框架，该框架利用强化学习（RL）和近端策略优化（PPO）算法来最小化总队列长度，并在SUMO交通模拟器中得到验证，其性能优于传统方法和其他基于RL的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的固定信号控制和感应控制方法难以应对动态交通模式，而高效的交通信号控制对于减少拥堵、 travel delays、污染和确保道路安全至关重要。

Method: 提出了一种新颖的自适应TSC框架，利用PPO算法，并通过多种状态表示（扩展状态空间、自动编码器表示、K-Planes启发表示）来处理随机交通状况。使用SUMO交通模拟器进行实现。

Result: 所提出的算法在减少队列长度方面表现优于传统方法和其他基于RL的方法。最佳配置比传统的Webster方法平均队列长度减少了约29%。基于队列的奖励函数被证明是有效的。

Conclusion: 该研究展示了一种利用RL和PPO算法进行自适应交通信号控制的有效框架，通过多种状态表示和基于队列的奖励函数，显著减少了队列长度，并显示出在可扩展和自适应城市交通管理方面的潜力。

Abstract: Efficient traffic signal control (TSC) is crucial for reducing congestion,
travel delays, pollution, and for ensuring road safety. Traditional approaches,
such as fixed signal control and actuated control, often struggle to handle
dynamic traffic patterns. In this study, we propose a novel adaptive TSC
framework that leverages Reinforcement Learning (RL), using the Proximal Policy
Optimization (PPO) algorithm, to minimize total queue lengths across all signal
phases. The challenge of efficiently representing highly stochastic traffic
conditions for an RL controller is addressed through multiple state
representations, including an expanded state space, an autoencoder
representation, and a K-Planes-inspired representation. The proposed algorithm
has been implemented using the Simulation of Urban Mobility (SUMO) traffic
simulator and demonstrates superior performance over both traditional methods
and other conventional RL-based approaches in reducing queue lengths. The best
performing configuration achieves an approximately 29% reduction in average
queue lengths compared to the traditional Webster method. Furthermore,
comparative evaluation of alternative reward formulations demonstrates the
effectiveness of the proposed queue-based approach, showcasing the potential
for scalable and adaptive urban traffic management.

</details>


### [441] [A Parallel Ultra-Low Power Silent Speech Interface based on a Wearable, Fully-dry EMG Neckband](https://arxiv.org/abs/2509.21964)
*Fiona Meier,Giusy Spacone,Sebastian Frey,Luca Benini,Andrea Cossettini*

Main category: eess.SY

TL;DR: 我们提出了一种可穿戴、全干式、超低功耗的EMG系统，用于静默语音识别，并集成到纺织颈带中，实现舒适、非侵入式使用。


<details>
  <summary>Details</summary>
Motivation: 为了实现舒适、非侵入式的静默语音识别，我们提出了一种可穿戴、全干式、超低功耗的EMG系统。

Method: 该系统包含14个全差分EMG通道，基于BioGAP-Ultra平台实现超低功耗（22 mW）生物信号采集和无线传输。

Result: 在发声和静默语音识别任务上，平均分类准确率分别为87±3%和68±3%。在考虑复用性的实验中，发声和静默语音识别的准确率分别为64±18%和54±7%。

Conclusion: 所提出的方法具有鲁棒性，并且在节能静默语音解码方面显示出潜力。

Abstract: We present a wearable, fully-dry, and ultra-low power EMG system for silent
speech recognition, integrated into a textile neckband to enable comfortable,
non-intrusive use. The system features 14 fully-differential EMG channels and
is based on the BioGAP-Ultra platform for ultra-low power (22 mW) biosignal
acquisition and wireless transmission. We evaluate its performance on eight
speech commands under both vocalized and silent articulation, achieving average
classification accuracies of 87$\pm$3% and 68$\pm$3% respectively, with a
5-fold CV approach. To mimic everyday-life conditions, we introduce
session-to-session variability by repositioning the neckband between sessions,
achieving leave-one-session-out accuracies of 64$\pm$18% and 54$\pm$7% for the
vocalized and silent experiments, respectively. These results highlight the
robustness of the proposed approach and the promise of energy-efficient
silent-speech decoding.

</details>


### [442] [Optimized Control of Duplex Networks](https://arxiv.org/abs/2509.21767)
*Haoyu Zheng,Xizhe Zhang*

Main category: eess.SY

TL;DR: 针对多层网络控制问题，提出了一种名为MinUDS的通用最小并集驱动集问题，并开发了CLAP-S算法来寻找能同时控制两层的最小驱动节点集，实验证明该算法能有效减少驱动节点数量和计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有网络控制理论主要关注单层网络，直接应用于多层网络会导致驱动节点冗余，增加成本和复杂性。

Method: 提出通用最小并集驱动集（MinUDS）问题，并开发了最短跨层增广路径搜索（CLAP-S）算法，该算法通过寻找跨层增广路径来最大化两层的最小驱动集重叠，以找到最小的联合驱动节点集。

Result: CLAP-S算法在合成网络和真实多层网络上均表现优于基线方法，显著减少了所需驱动节点的数量，并将计算时间缩短了一个数量级。

Conclusion: CLAP-S算法为多层网络控制提供了一个高效且全局最优的解决方案，能够显著降低控制成本和复杂度。

Abstract: Many real-world complex systems can be modeled as multiplex networks, where
each layer represents a distinct set of interactions among the same entities.
Controlling such systems-steering them toward desired states using external
inputs-is crucial across many domains. However, existing network control theory
largely focuses on single-layer networks, and applying separate controls to
each layer of a multiplex system often leads to redundant sets of driver nodes,
increasing cost and complexity.
  To address this challenge, we formulate the Universal Minimum Union Driver
Set (MinUDS) problem for duplex networks. The goal is to find the smallest set
of driver nodes that can simultaneously control both layers.
  We propose a novel algorithm, Shortest Cross-Layer Augmenting Path Search
(CLAP-S). This method introduces the concept of a Cross-Layer Augmenting Path
(CLAP) and efficiently explores the combinatorial space of control
configurations. CLAP-S iteratively realigns each layer's Minimum Driver Set
(MDS) to maximize their overlap. We prove the algorithm's global optimality and
demonstrate its efficiency on both synthetic networks and real-world multiplex
systems.
  The results show that CLAP-S consistently outperforms baseline approaches by
significantly reducing the number of required driver nodes and cutting
computational time by an order of magnitude. This work provides a powerful,
general-purpose tool for optimizing control strategies in multi-layer networks,
enabling more economical interventions in diverse fields.

</details>


### [443] [A Preliminary Assessment of Shipboard Power System Architectures for LVDC Integration](https://arxiv.org/abs/2509.22567)
*D. Roncagliolo,M. Gallo,D. Kaza,F. D'Agostino,A. Chiarelli,F. Silvestro*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The adoption of low-voltage direct current sections within grid architectures
is emerging as a promising design option in the naval sector. This paper
presents a preliminary comparative assessment of three different grid
topologies, using an existing MVAC-LVAC shipboard power system as a reference:
a conventional MVAC-LVAC radial distribution with an additional LVDC section, a
full LVDC radial distribution and a zonal LVDC distribution. Each architecture
includes typical elements such as synchronous generators, propulsion motors,
energy storage system units, extra propulsive loads, and pulse power loads. The
analysis exploits five key performance indicators: weight, volume, technology
readiness level, average system interruption duration index, and pulsed power
loads interruption index.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [444] [Can Large Language Models Autoformalize Kinematics?](https://arxiv.org/abs/2509.21840)
*Aditi Kabra,Jonathan Laurent,Sagar Bharadwaj,Ruben Martins,Stefan Mitsch,André Platzer*

Main category: cs.LO

TL;DR: LLM 可将自然语言物理问题自动形式化为微分博弈逻辑（dGL），在 70% 的问题上成功。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人和自动驾驶汽车等自主网络物理系统能够可靠地对其控制决策进行推理，需要形式方法，但形式化物理模型是一个复杂且耗时的过程，需要专业知识，从而成为瓶颈。

Method: 设计了一个包含 20 个问题的基准套件，这些问题源自本科级别的物理运动学问题。在每个问题中，LLM 接收关于物体运动的自然语言描述，并必须生成一个 dGL 模型。该模型经过语法检查和迭代优化，并通过符号执行 dGL 公式来恢复原始物理问题的解决方案进行语义评估。

Result: 在 70% 的问题上取得了成功（5 次样本的最佳结果）。

Conclusion: LLM 可以自动将自然语言形式化为混合博弈逻辑，并具有连续动态功能，这为基于 LLM 的自动形式化提供了第一个定量基准。

Abstract: Autonomous cyber-physical systems like robots and self-driving cars could
greatly benefit from using formal methods to reason reliably about their
control decisions. However, before a problem can be solved it needs to be
stated. This requires writing a formal physics model of the cyber-physical
system, which is a complex task that traditionally requires human expertise and
becomes a bottleneck.
  This paper experimentally studies whether Large Language Models (LLMs) can
automate the formalization process. A 20 problem benchmark suite is designed
drawing from undergraduate level physics kinematics problems. In each problem,
the LLM is provided with a natural language description of the objects' motion
and must produce a model in differential game logic (dGL). The model is (1)
syntax checked and iteratively refined based on parser feedback, and (2)
semantically evaluated by checking whether symbolically executing the dGL
formula recovers the solution to the original physics problem. A success rate
of 70% (best over 5 samples) is achieved. We analyze failing cases, identifying
directions for future improvement. This provides a first quantitative baseline
for LLM-based autoformalization from natural language to a hybrid games logic
with continuous dynamics.

</details>


### [445] [A Correct by Construction Fault Tolerant Voter for Input Selection of a Control System](https://arxiv.org/abs/2509.22236)
*Arif Ali AP,Jasine Babu,Deepa Sara John*

Main category: cs.LO

TL;DR: 该论文提出了一种用于航空电子系统中 N 冗余测量装置的通用投票单元的形式化设计方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高安全关键系统的可靠性和容错能力，通常采用冗余输入单元和投票逻辑来选择可靠的输入。然而，对于航空电子系统中的 N 冗余测量装置，缺乏形式化的设计和验证方法。

Method: 本文采用一种“正确构造”的方法，利用 Rocq 定理证明器，对 N 冗余测量装置的投票单元进行了形式化需求、设计、验证和综合。

Result: 所提出的方法能够形式化地设计、验证和综合用于 N 冗余测量装置的投票单元，确保其正确性。

Conclusion: 通过采用“正确构造”的方法和 Rocq 定理证明器，可以有效地对航空电子系统中的 N 冗余测量装置的投票单元进行形式化设计和验证，从而提高系统的可靠性和安全性。

Abstract: Safety-critical systems use redundant input units to improve their
reliability and fault tolerance. A voting logic is then used to select a
reliable input from the redundant sources. A fault detection and isolation
rules help in selecting input units that can participate in voting. This work
deals with the formal requirement formulation, design, verification and
synthesis of a generic voting unit for an $N$-modular redundant measurement
system used for control applications in avionics systems. The work follows a
correct-by-construction approach, using the Rocq theorem prover.

</details>


### [446] [Specifying an Obligation Taxonomy in the Non-Markovian Situation Calculus](https://arxiv.org/abs/2509.22533)
*Kalonji Kalala,Iluju Kiringa,Tet Yeap*

Main category: cs.LO

TL;DR: Situation Calculus 扩展到处理非马尔可夫过程，用于对义务进行建模。


<details>
  <summary>Details</summary>
Motivation: 将非马尔可夫控制应用于情境演算，以形式化文献中存在的不同义务概念。

Method: 使用非马尔可夫控制来指定情境演算中的义务。

Result: 生成了确保整个工作的正确性的直观属性。

Conclusion: 情境演算可以用来形式化各种义务的概念，并且这种方法会产生符合预期的属性。

Abstract: Over more than three decades, the Situation Calculus has established itself
as an elegant, powerful, and concise formalism for specifying dynamical domains
as well as for reasoning about the effects of actions of those domains both in
the world and in the mental state of the modelled agents. Moreover, it has also
been established that the preconditions of a given action and its effects may
be determined entirely by the current situation alone, or they may be
determined by past situations as well. When past situations are involved in
determining action preconditions and effects, resulting theories are
non-Markovian. Assuming a specification of actions that produce obligations, we
consider using non-Markovian control in the Situation Calculus to specify
different notions of obligations found in the literature. These notions have
been specified using Event Calculus; but, as far as we know, they have never
been specified using the Situation Calculus. The specifications in this paper
yield intuitive properties that ensure the correctness of the whole endeavour.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [447] [Real Space Imaging of Spin Scattering in Chirality-Induced Spin Selectivity](https://arxiv.org/abs/2509.21558)
*Jaehyun Lee,Sang-hyuk Lee,Uiseok Jeong,Daryll J. C. Dalayoan,Soobeom Shin,Hu Young Jeong,Hosub Jin,Binghai Yan,Noejung Park,Seon Namgung*

Main category: cond-mat.mes-hall

TL;DR: The CISS effect shows spin polarization in chiral materials, but its spatial distribution was unclear. Using tellurium nanowires and graphene electrodes, we found current-induced spin polarization is consistent in the wire and electrodes, not a spin filter. This provides the first direct visualization of spatial spin distribution in chiral devices and opens new possibilities for spintronics.


<details>
  <summary>Details</summary>
Motivation: Understanding the mechanism of the chirality-induced spin selectivity (CISS) effect, particularly the spatial distribution of spin polarization in chiral systems, which has been experimentally elusive.

Method: Utilized reflective magnetic circular dichroism measurements on chiral tellurium nanowires with graphene electrodes to probe current-induced spin polarization.

Result: Observed that spin polarization in both the nanowire and electrodes had identical signs, scaling linearly with current, aligning parallel to the current, reversing with chirality or current flow, and exhibiting spin relaxation lengths of several micrometers into graphene.

Conclusion: The findings provide the first direct visualization of spatial spin distribution in chiral devices, establishing a new paradigm for investigating spin-dependent phenomena in chiral materials and enabling the development of chirality-based spintronic and quantum devices.

Abstract: The interaction between electron spin and molecular chirality plays a
fundamental role in quantum phenomena, with significant implications for
spintronics and quantum computing. The chirality-induced spin selectivity
(CISS) effect, where chiral materials preferentially transmit electrons of a
particular spin, has sparked intense interest and debate regarding its
underlying mechanism. Despite extensive research, the spatial distribution of
spin polarization in chiral systems, the key evidence to reveal the spin
scattering mechanism in CISS, has remained experimentally elusive particularly
due to complications arising from spin-orbit coupling in metal electrodes
typically used in such studies. Here we show, through reflective magnetic
circular dichroism measurements on chiral tellurium nanowires with graphene
electrodes, that current-induced spin polarization exhibits identical signs in
both the nanowire and electrodes, distinct from the presumed spin filter
scenario. The observed spin polarization scales linearly with current
amplitude, aligns parallel to the current direction, reverses with chirality or
current flow, and demonstrates spin relaxation lengths of several micrometers
into graphene. Our findings provide the first direct visualization of spatial
spin distribution in chiral devices. This work establishes a new paradigm for
investigating spin-dependent phenomena in chiral materials and opens avenues
for developing chirality-based spintronic and quantum devices.

</details>


### [448] [A comprehensive equivalent circuit model for high overtone bulk acoustic resonators (HBARs)](https://arxiv.org/abs/2509.21640)
*Vikrant J. Gokhale,Brian P. Downey*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一种新颖且全面的高过音体声谐振器（HBAR）等效电路模型，该模型能有效处理HBARs的准周期性多模频谱，并能准确拟合实验数据。


<details>
  <summary>Details</summary>
Motivation: HBARs具有分布在很宽频率范围内近乎周期性分布的非常尖锐的共振模式，这种频谱响应提供了独特的优势，但也带来了显著的建模挑战。

Method: 提出了一种结合了压电换能器、基板（全周期多模腔）、压电耦合以及换能器-基板界面不匹配等HBARs独特物理组件的电路模型。通过使用固定、周期或受约束的虚拟集总元件支路，模型在保持与物理器件清晰直观的联系的同时，降低了拟合密集、宽带数据集所需的复杂性。

Result: 通过同时拟合GaN/NbN/蓝宝石HBARs在1 GHz频跨度上61个模式的测量数据，并提取品质因数和耦合系数等模态参数，证明了该模型的有效性和强大能力。模型已被证明是紧凑且可扩展的，可以轻松扩展以包含多个换能器泛音和包络、多个不同的换能器以及杂散模式。

Conclusion: 该新模型紧凑、可扩展，并能准确拟合实验数据，可用于HBARs的设计，包括振荡器、滤波器、传感器以及将HBARs集成到量子电路中。

Abstract: This paper presents a new and comprehensive equivalent circuit model for high
overtone bulk acoustic resonators (HBARs). HBARs demonstrate several very sharp
resonance modes distributed nearly periodically over a very wide frequency
range. This spectrum response of HBARs offers unique advantages but poses
significant modeling challenges. The proposed circuit incorporates and models
the unique physical components of the HBAR: piezoelectric transducer, substrate
(a perfectly periodic multimode cavity), piezoelectric coupling, and
critically, the imperfectly matched transducer-substrate interface which
imparts characteristic aperiodicity to the HBAR mode spectrum. By judicious use
of fixed, periodic, or tightly constrained virtual lumped-element branches, and
sets of branches, the model retains clear and intuitive links to the physical
device, while reducing the complexity needed for fitting dense, broadband
datasets. We demonstrate the validity and power of this model by simultaneously
fitting measured data for 61 modes of a GaN/NbN/sapphire HBAR over a span of 1
GHz, and extracting modal parameters such as quality factors and coupling
coefficients. We show that this new model is compact and yet scalable: by
leveraging the inherent internal relationships in an HBAR, the model can be
easily expanded to include multiple transducer overtones and envelopes,
multiple distinct transducers, and spurious modes. In addition to fitting
measured datasets, the new model can also be used to easily analyze various
perturbations to the nominal state of the HBAR. We expect the new model to be
useful for the design of classical HBAR-based oscillators, filters, and
sensors, and for the integration of HBARs into quantum circuits.

</details>


### [449] [Hexagonal boron nitride/bilayer graphene moiré superlattices in the Dirac-material family: energy-band engineering and carrier doping by dual gating](https://arxiv.org/abs/2509.21759)
*Takuya Iwasaki,Yoshifumi Morita*

Main category: cond-mat.mes-hall

TL;DR: hBN/BLG moiré superlattices exhibit tunable band gaps and non-trivial band topology due to the moiré effect and perpendicular electric fields, enabling the engineering of their electronic properties.


<details>
  <summary>Details</summary>
Motivation: To review the fabrication and transport characterization of hBN/BLG moiré superlattices and explore their unique electronic properties arising from the moiré effect and electric field tuning.

Method: Fabrication of hBN/BLG moiré superlattices and characterization of their transport properties using a dual-gated device structure for individual control of displacement field and carrier density.

Result: Observation of an energy gap at the charge neutrality point (CNP) even without an electric field, tunable energy gap with a perpendicular electric field, non-trivial energy-band topology, and narrow energy bands featuring a van Hove singularity.

Conclusion: hBN/BLG moiré superlattices exhibit universal and diverse physical phenomena, including tunable band gaps and non-trivial band topology, which can be systematically engineered using dual-gated devices.

Abstract: We review the fabrication and transport characterization of hexagonal boron
nitride (hBN)/Bernal bilayer graphene (BLG) moir\'e superlattices. Due to the
moir\'e effect, the hBN/BLG moir\'e superlattices exhibit an energy gap at the
charge neutrality point (CNP) even in the absence of a perpendicular electric
field. In BLG, the application of a perpendicular electric field tunes the
energy gap at the CNP, which contrasts with single-layer graphene and is
similar to the family of rhombohedral multilayer graphene. The hBN/BLG moir\'e
superlattice is associated with non-trivial energy-band topology and a narrow
energy band featuring a van Hove singularity. By employing a dual-gated device
structure where both the perpendicular displacement field and the carrier
density are individually controllable, systematic engineering of the
energy-band structure can be achieved. The data presented here demonstrate the
universality and diversity in the physics of hBN/BLG moir\'e superlattices.

</details>


### [450] [Ab initio study of magnetoresistance effect in $\mathrm{Mn_{3}Sn}/\mathrm{MgO}/\mathrm{Mn_{3}Sn}$ antiferromagnetic tunnel junction](https://arxiv.org/abs/2509.21877)
*Katsuhiro Tanaka,Yuta Toga,Susumu Minami,Satoru Nakatsuji,Takuya Nomoto,Takashi Koretsune,Ryotaro Arita*

Main category: cond-mat.mes-hall

TL;DR: Mn3Sn/MgO/Mn3Sn MTJs exhibit a TMR ratio exceeding 1000% due to the spin-splitting properties of Mn3Sn and the screening effect of MgO.


<details>
  <summary>Details</summary>
Motivation: Investigate the TMR effect in noncollinear antiferromagnetic Mn3Sn with broken time-reversal symmetry, aiming to realize finite TMR even with zero net spin polarization.

Method: Calculated the TMR effect in Mn3Sn(011̅0)/MgO(110)/Mn3Sn magnetic tunnel junctions (MTJs) using MgO as the tunnel insulator, focusing on an optimal geometry for spin-orbit torque switching.

Result: A finite TMR ratio reaching approximately 1000% was observed in the Mn3Sn/MgO/Mn3Sn MTJs.

Conclusion: The combination of Mn3Sn's momentum-space spin-splitting properties and MgO's screening effect leads to a significant TMR ratio in these MTJs.

Abstract: The antiferromagnets with the time-reversal symmetry broken magnetic
structures possess a finite spin splitting in the momentum space, and may
contribute to a realization of a finite tunnel magnetoresistance (TMR) effect
even with magnets with zero net spin polarization. In this paper, we study the
TMR effect with the noncollinear antiferromagnet $\mathrm{Mn_{3}Sn}$ whose
inverse $120^{\circ}$ antiferromagnetic order breaks the time-reversal
symmetry. In particular, we employ the representative barrier material
$\mathrm{MgO}$ as the tunnel insulator, and calculate the TMR effect in the
$\mathrm{Mn_{3}Sn}(01\bar{1}0)/\mathrm{MgO}(110)/\mathrm{Mn_{3}Sn}$ magnetic
tunnel junctions (MTJs), which has an optimal geometry for the spin-orbit
torque switching of the magnetic configurations. We show that a finite TMR
ratio reaching $\gtrsim 1000\%$ appears in the
$\mathrm{Mn_{3}Sn}/\mathrm{MgO}/\mathrm{Mn_{3}Sn}$ MTJs, which is due to the
spin splitting properties of $\mathrm{Mn_{3}Sn}$ in the momentum space combined
with the screening effect of $\mathrm{MgO}$.

</details>


### [451] [Quantum spin Hall effect in III-V semiconductors at elevated temperatures: advancing topological electronics](https://arxiv.org/abs/2509.22185)
*Manuel Meyer,Jonas Baumbach,Sergey Krishtopenko,Adriana Wolf,Monika Emmerling,Sebastian Schmid,Martin Kamp,Benoit Jouault,Jean-Baptiste Rodriguez,Eric Tournie,Tobias Müller,Ronny Thomale,Gerald Bastard,Frederic Teppe,Fabian Hartmann,Sven Höfling*

Main category: cond-mat.mes-hall

TL;DR: InAs/GaInSb/InAs三层量子阱结构在较高温度下实现了量子自旋霍尔效应，为拓扑电子学的发展奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 实现可扩展、可在较高温度下运行且具有鲁棒电子传输的量子自旋霍尔效应器件。

Method: 在InAs/GaInSb/InAs三层量子阱结构中，通过将费米能级置于能隙内，并采用局部和非局部测量配置来观察量子化电阻。

Result: 观察到与器件长度无关的量子化电阻值，证实了量子自旋霍尔效应。在高达60 K的温度下观察到稳定的螺旋边缘传输。

Conclusion: InAs/GaInSb系统是利用拓扑功能的下一代器件的有希望的候选者，推动了拓扑电子学的发展。

Abstract: The quantum spin Hall effect (QSHE), a hallmark of topological insulators,
enables dissipationless, spin-polarized edge transport and has been predicted
in various two-dimensional materials. However, challenges such as limited
scalability, low-temperature operation, and the lack of robust electronic
transport have hindered practical implementations. Here, we demonstrate the
QSHE in an InAs/GaInSb/InAs trilayer quantum well structure operating at
elevated temperatures. This platform meets key criteria for device integration,
including scalability, reproducibility, and tunability via electric field. When
the Fermi level is positioned within the energy gap, we observe quantized
resistance values independent of device length and in both local and nonlocal
measurement configurations, confirming the QSHE. Helical edge transport remains
stable up to T = 60 K, with further potential for higher-temperature operation.
Our findings establish the InAs/GaInSb system as a promising candidate for
integration into next-generation devices harnessing topological
functionalities, advancing the development of topological electronics.

</details>


### [452] [Antitoroidal magnets and anomalous Hall effect](https://arxiv.org/abs/2509.22266)
*Vladimir A. Zyuzin*

Main category: cond-mat.mes-hall

TL;DR: 文章提出了一个包含反环形磁序的金属磁性系统的理论模型，该模型基于导电费米子与局域自旋之间的间接相互作用机制，通过导电费米子隧穿局域自旋来实现。研究表明，这种相互作用会导致奇动量自旋动量锁定，类似于Rashba自旋-轨道耦合但破坏了时间反演对称性。最终，文章证明了具有反环形磁序的铁磁体是一种绝缘体，能够产生异常霍尔效应，且该效应的产生不依赖于任何自旋-轨道耦合。


<details>
  <summary>Details</summary>
Motivation: 提出一个包含反环形磁序的金属磁性系统的理论模型，并探讨导电费米子与局域自旋之间的相互作用机制。

Method: 提出基于导电费米子隧穿局域自旋的间接相互作用机制，并推导出奇动量自旋动量锁定效应。

Result: 导电费米子与反环形磁序的相互作用导致了奇动量自旋动量锁定，该效应类似于Rashba自旋-轨道耦合但破坏了时间反演对称性。具有反环形磁序的铁磁体表现为绝缘体，并出现异常霍尔效应。

Conclusion: 具有反环形磁序的铁磁体是一种无需自旋-轨道耦合即可产生异常霍尔效应的绝缘体。

Abstract: In this paper we introduce a theoretical model of a metallic magnetic system
with an antitoroidal order. We introduce a mechanism of indirect interaction of
conducting fermions with localized spins based on the tunneling processes of
conducting fermions through the localized spins. We demonstrate that
interaction of conducting fermions with an antitoroidal order results in odd in
momentum spin-momentum locking. The interaction resembles Rashba spin-orbit
coupling but breaks the time-reversal symmetry. As a result, we show that a
ferromagnet with the antitoroidal order is an insulator with anomalous Hall
effect occurring without any spin-orbit coupling.

</details>


### [453] [Cryogenic In-Memory Computing with Phase-Change Memory](https://arxiv.org/abs/2509.22511)
*Davide G. F. Lombardo,Siddharth Gautam,Alberto Ferraris,Manuel Le Gallo,Abu Sebastian,Ghazi Sarwat Syed*

Main category: cond-mat.mes-hall

TL;DR: PCM设备在低温（低至5K）下进行了全面表征，重点关注其在内存计算（IMC）中的应用，特别是在深度学习加速和低温应用（如量子计算和深空电子学）中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究PCM设备在低温下的行为，以探索其在内存计算（IMC）中的应用，特别是在深度学习加速和低温应用（如量子计算和深空电子学）中的潜力。

Method: 系统地研究了PCM设备在低至5K的温度下的关键物理机制，包括相变、阈值开关、电传输、结构弛豫和读出噪声。

Result: 在低温下对PCM设备进行了全面的表征，研究了影响其编程和读出行为的关键物理机制和属性。

Conclusion: PCM设备在低温下具有作为内存计算（IMC）器件的潜力，特别是在深度学习加速和低温应用中。

Abstract: In-memory computing (IMC) is an emerging non-von Neumann paradigm that
leverages the intrinsic physics of memory devices to perform computations
directly within the memory array. Among the various candidates, phase-change
memory (PCM) has emerged as a leading non-volatile technology, showing
significant promise for IMC, particularly in deep learning acceleration.
PCM-based IMC is also poised to play a pivotal role in cryogenic applications,
including quantum computing and deep space electronics. In this work, we
present a comprehensive characterization of PCM devices across temperatures
down to 5 K, covering the range most relevant to these domains. We
systematically investigate key physical mechanisms such as phase transitions
and threshold switching that govern device programming at low temperatures. In
addition, we study attributes including electrical transport, structural
relaxation, and read noise, which critically affect readout behavior and, in
turn, the precision achievable in computational tasks.

</details>


### [454] [Selective bulk-boundary correspondence in higher-order topological insulators with anticommuting mirror and chiral symmetries](https://arxiv.org/abs/2509.22304)
*Suman Aich,Babak Seradjeh*

Main category: cond-mat.mes-hall

TL;DR: Chiral and mirror symmetries protect higher-order topological insulators. Breaking mirror symmetries anticommuting with the chiral operator leads to edge-selective bulk-boundary correspondence in BDI class models, causing gap closings and bound states on specific boundaries. A new edge-sensitive invariant is defined, distinguishing this from non-topological effects.


<details>
  <summary>Details</summary>
Motivation: Investigate higher-order topological insulators protected by chiral and mirror symmetries, and understand the phenomenon of edge-selective bulk-boundary correspondence that arises when mirror symmetries are broken.

Method: Utilize models in the BDI class, including the topological quadrupole insulator. Analyze the effect of breaking mirror symmetries that anticommute with the chiral operator on the bulk-boundary correspondence. Define a new edge-sensitive topological invariant.

Result: Observed edge-selective bulk-boundary correspondence with gap closings and bound states appearing only along a subset of boundaries of the same orientation. Defined a new edge-sensitive topological invariant.

Conclusion: Breaking specific mirror symmetries in higher-order topological insulators leads to an edge-selective bulk-boundary correspondence, which can be distinguished from non-topological effects by a newly defined invariant.

Abstract: We investigate higher-order topological insulators protected by chiral and
mirror symmetries. Using models in the BDI class, which include the
prototypical topological quadrupole insulator, we show that breaking mirror
symmetries that anticommute with the chiral operator leads to edge-selective
bulk-boundary correspondence, with gap closings and bound states appearing only
along a subset of boundaries of the same orientation. We define a new
edge-sensitive topological invariant, distinguishing this mechanism from
previous reports of non-topological edge-selection effects.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [455] [Reimagining Agent-based Modeling with Large Language Model Agents via Shachi](https://arxiv.org/abs/2509.21862)
*So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang*

Main category: cs.AI

TL;DR: Shachi是一个用于LLM驱动的多智能体系统的形式化方法和模块化框架，通过将智能体的策略分解为配置、记忆和工具等核心认知组件，并由LLM推理引擎协调，从而能够系统地分析特定架构选择如何影响集体行为。该方法在10个任务的基准测试中得到验证，并通过模拟实际的美国关税冲击事件，证明了其在建模现实世界场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的多智能体系统在研究涌现行为时，缺乏可控实验的原则性方法。本研究旨在解决这一挑战，提供一种结构化的方法来实现对智能体行为的系统性分析。

Method: 提出了一种名为Shachi的形式化方法和模块化框架，将智能体的策略分解为三个核心认知组件：配置（内在特征）、记忆（上下文持久性）和工具（扩展能力），并由LLM推理引擎进行协调。

Result: 在10个任务的基准测试中验证了该方法，并通过模拟美国关税冲击事件，证明了在适当配置记忆和工具的认知架构下，智能体行为能够与观察到的市场反应保持一致。

Conclusion: Shachi提供了一个严谨的、开源的LLM智能体构建和评估基础，旨在促进更具累积性和科学性的研究，并能有效处理现实世界中的复杂场景。

Abstract: The study of emergent behaviors in large language model (LLM)-driven
multi-agent systems is a critical research challenge, yet progress is limited
by a lack of principled methodologies for controlled experimentation. To
address this, we introduce Shachi, a formal methodology and modular framework
that decomposes an agent's policy into core cognitive components: Configuration
for intrinsic traits, Memory for contextual persistence, and Tools for expanded
capabilities, all orchestrated by an LLM reasoning engine. This principled
architecture moves beyond brittle, ad-hoc agent designs and enables the
systematic analysis of how specific architectural choices influence collective
behavior. We validate our methodology on a comprehensive 10-task benchmark and
demonstrate its power through novel scientific inquiries. Critically, we
establish the external validity of our approach by modeling a real-world U.S.
tariff shock, showing that agent behaviors align with observed market reactions
only when their cognitive architecture is appropriately configured with memory
and tools. Our work provides a rigorous, open-source foundation for building
and evaluating LLM agents, aimed at fostering more cumulative and
scientifically grounded research.

</details>


### [456] [Towards mitigating information leakage when evaluating safety monitors](https://arxiv.org/abs/2509.21344)
*Gerard Boxo,Aman Neelappa,Shivam Raval*

Main category: cs.AI

TL;DR: 白盒监测器在检测大型语言模型的潜在有害行为方面具有优势，但需要响应示例进行训练和评估，这会导致信息泄露并可能虚高其有效性。本研究提出了一个系统框架来评估监测器检测真实模型行为而非表面诱导伪影的能力，并提出了三种新颖的评估策略：内容过滤、分数过滤和提示蒸馏微调模型。通过以欺骗检测为例，研究识别了两种信息泄露形式：诱导泄露和推理泄露。实验表明，内容过滤是一种有效的缓解策略，可将探针 AUROC 降低 30%；分数过滤可将 AUROC 降低 15%；而微调模型虽然能改善监测器评估，但会降低其性能高达 40%。


<details>
  <summary>Details</summary>
Motivation: 训练和评估白盒语言模型监测器需要响应示例，这些示例可能包含用于诱导目标行为的信息，从而导致信息泄露并虚高监测器的有效性。

Method: 提出一个系统框架来评估监测器在检测真实模型行为而非表面诱导伪影方面的能力。提出三种新颖的策略来评估监测器：内容过滤（从输入中移除欺骗相关文本）、分数过滤（仅聚合与任务相关的标记）和提示蒸馏微调模型（训练模型在没有明确提示的情况下表现出欺骗行为）。

Result: (1) 内容过滤是一种有效的缓解策略，可以将探针 AUROC 降低 30% 左右。(2) 分数过滤可将 AUROC 降低 15%，但其归因不那么直接。(3) 微调模型可以改善监测器评估，但会降低其性能高达 40%，即使在重新训练后也是如此。

Conclusion: 内容过滤和分数过滤是评估语言模型监测器性能的有效策略，可以减轻信息泄露的影响。然而，微调模型虽然可以改善评估，但会显著降低监测器的性能。

Abstract: White box monitors that analyze model internals offer promising advantages
for detecting potentially harmful behaviors in large language models, including
lower computational costs and integration into layered defense systems.However,
training and evaluating these monitors requires response exemplars that exhibit
the target behaviors, typically elicited through prompting or fine-tuning. This
presents a challenge when the information used to elicit behaviors inevitably
leaks into the data that monitors ingest, inflating their effectiveness. We
present a systematic framework for evaluating a monitor's performance in terms
of its ability to detect genuine model behavior rather than superficial
elicitation artifacts. Furthermore, we propose three novel strategies to
evaluate the monitor: content filtering (removing deception-related text from
inputs), score filtering (aggregating only over task-relevant tokens), and
prompt distilled fine-tuned model organisms (models trained to exhibit
deceptive behavior without explicit prompting). Using deception detection as a
representative case study, we identify two forms of leakage that inflate
monitor performance: elicitation leakage from prompts that explicitly request
harmful behavior, and reasoning leakage from models that verbalize their
deceptive actions. Through experiments on multiple deception benchmarks, we
apply our proposed mitigation strategies and measure performance retention. Our
evaluation of the monitors reveal three crucial findings: (1) Content filtering
is a good mitigation strategy that allows for a smooth removal of elicitation
signal and can decrease probe AUROC by 30\% (2) Score filtering was found to
reduce AUROC by 15\% but is not as straightforward to attribute to (3) A
finetuned model organism improves monitor evaluations but reduces their
performance by upto 40\%, even when re-trained.

</details>


### [457] [Correct Reasoning Paths Visit Shared Decision Pivots](https://arxiv.org/abs/2509.21549)
*Dongkyu Cho,Amy B. Z. Zhang,Bilel Fehri,Sheng Wang,Rumi Chunara,Rui Song,Hengrui Cai*

Main category: cs.AI

TL;DR: 提出决策枢轴（decision pivots）来解决大型语言模型（LLM）的链式思考（CoT）推理验证问题，通过自训练压缩推理路径并进行后训练，在多个基准测试中有效提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思考（CoT）推理虽然能暴露大型语言模型（LLM）的中间思考过程，但大规模验证这些推理过程仍然是一个未解决的问题。

Method: 提出决策枢轴（decision pivots），即任何正确推理路径都必须经过的、可验证的最小检查点。基于“正确推理会收敛到相同的枢轴集合，而错误推理会违反至少一个枢轴”的假设，设计了一个自训练流程：(i) 采样多样化的推理路径并挖掘共享的决策枢轴，(ii) 使用辅助验证器将每个推理路径压缩成以枢轴为中心的短路径推理，(iii) 使用模型自身生成的输出来进行后训练。

Result: 实验表明，该方法在 LogiQA、MedQA 和 MATH500 等标准基准测试中是有效的，并且能够实现推理对齐，而无需真实推理标签或外部评估指标。

Conclusion: 该方法通过引入决策枢轴和自训练流程，有效解决了大规模验证LLM的CoT推理的挑战，并在多个基准测试中取得了显著效果。

Abstract: Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of
large language models (LLMs), yet verifying those traces at scale remains
unsolved. In response, we introduce the idea of decision pivots-minimal,
verifiable checkpoints that any correct reasoning path must visit. We
hypothesize that correct reasoning, though stylistically diverse, converge on
the same pivot set, while incorrect ones violate at least one pivot. Leveraging
this property, we propose a self-training pipeline that (i) samples diverse
reasoning paths and mines shared decision pivots, (ii) compresses each trace
into pivot-focused short-path reasoning using an auxiliary verifier, and (iii)
post-trains the model using its self-generated outputs. The proposed method
aligns reasoning without ground truth reasoning data or external metrics.
Experiments on standard benchmarks such as LogiQA, MedQA, and MATH500 show the
effectiveness of our method.

</details>


### [458] [AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need](https://arxiv.org/abs/2509.21553)
*Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng*

Main category: cs.AI

TL;DR: 通过结合知识图谱（KG）和AI代理来简化气候数据科学的访问和分析，降低技术门槛，促进可复现的科学研究。


<details>
  <summary>Details</summary>
Motivation: 气候数据科学面临数据源碎片化、格式异构和高技术门槛等挑战，限制了参与、阻碍了发现并降低了科学工作流的可复现性。

Method: 提出一种结合知识图谱（KG）和为云原生科学工作流设计的AI代理的集成方案。KG提供统一的数据集、工具和工作流组织层，而AI代理（由生成式AI服务驱动）则实现自然语言交互、自动化数据访问和简化的分析。

Result: 演示了通过集成KG和AI代理，可以显著降低气候数据科学的技术门槛，使非专业用户能够识别和分析相关数据集。利用现有的云就绪API数据门户，证明了“知识图谱就够了”可以解锁可扩展的、可代理的科学探究工作流。

Conclusion: 该系统为气候数据民主化访问提供了一条途径，并为科学研究中人机协作建立了一个可复现、可扩展的框架。其开源设计也支持社区贡献，使KG和相关工具能够作为共享资源不断发展。

Abstract: Climate data science faces persistent barriers stemming from the fragmented
nature of data sources, heterogeneous formats, and the steep technical
expertise required to identify, acquire, and process datasets. These challenges
limit participation, slow discovery, and reduce the reproducibility of
scientific workflows. In this paper, we present a proof of concept for
addressing these barriers through the integration of a curated knowledge graph
(KG) with AI agents designed for cloud-native scientific workflows. The KG
provides a unifying layer that organizes datasets, tools, and workflows, while
AI agents -- powered by generative AI services -- enable natural language
interaction, automated data access, and streamlined analysis. Together, these
components drastically lower the technical threshold for engaging in climate
data science, enabling non-specialist users to identify and analyze relevant
datasets. By leveraging existing cloud-ready API data portals, we demonstrate
that "a knowledge graph is all you need" to unlock scalable and agentic
workflows for scientific inquiry. The open-source design of our system further
supports community contributions, ensuring that the KG and associated tools can
evolve as a shared commons. Our results illustrate a pathway toward
democratizing access to climate data and establishing a reproducible,
extensible framework for human--AI collaboration in scientific research.

</details>


### [459] [EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks](https://arxiv.org/abs/2509.21567)
*Mohammad Parsa Afshar,Aryan Azimi*

Main category: cs.AI

TL;DR: 通过分析消费者脑电图（EEG）数据，比较了图神经网络（GNN）和经典机器学习模型在预测消费者行为方面的表现，发现GNN在某些标准上优于经典模型。


<details>
  <summary>Details</summary>
Motivation: 预测消费者行为在市场营销、认知神经科学和人机交互等领域具有重要意义，脑电图（EEG）数据能够提供大脑神经活动细节，有助于分析决策过程。

Method: 首先，提取并清理了NeuMa数据集中EEG数据的特征。为图神经网络（GNN）模型创建了大脑连接性特征。然后，比较了不同的机器学习模型，包括经典模型和GNN模型，并实现了不同架构的GNN模型以及包括集成模型在内的多种经典模型。

Result: 总体而言，结果未显示显著的整体差异，但GNN模型在经典模型不理想的某些基本标准上通常表现更好。

Conclusion: 这项研究表明，结合EEG信号分析和机器学习模型可以深入理解消费者行为。此外，它全面比较了EEG神经营销领域常用模型（如SVM）与不常用或很少使用的模型（如GNN）的性能。

Abstract: Prediction of consumer behavior is one of the important purposes in
marketing, cognitive neuroscience, and human-computer interaction. The
electroencephalography (EEG) data can help analyze the decision process by
providing detailed information about the brain's neural activity. In this
research, a comparative approach is utilized for predicting consumer behavior
by EEG data. In the first step, the features of the EEG data from the NeuMa
dataset were extracted and cleaned. For the Graph Neural Network (GNN) models,
the brain connectivity features were created. Different machine learning
models, such as classical models and Graph Neural Networks, are used and
compared. The GNN models with different architectures are implemented to have a
comprehensive comparison; furthermore, a wide range of classical models, such
as ensemble models, are applied, which can be very helpful to show the
difference and performance of each model on the dataset. Although the results
did not show a significant difference overall, the GNN models generally
performed better in some basic criteria where classical models were not
satisfactory. This study not only shows that combining EEG signal analysis and
machine learning models can provide an approach to deeper understanding of
consumer behavior, but also provides a comprehensive comparison between the
machine learning models that have been widely used in previous studies in the
EEG-based neuromarketing such as Support Vector Machine (SVM), and the models
which are not used or rarely used in the field, like Graph Neural Networks.

</details>


### [460] [GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models](https://arxiv.org/abs/2509.21593)
*Peng Luo,Xiayin Lou,Yu Zheng,Zhuo Zheng,Stefano Ermon*

Main category: cs.AI

TL;DR: GeoEvolve是一个结合了演化搜索和地理空间领域知识的多智能体LLM框架，可自动设计和改进地理空间算法，在空间插值和不确定性量化任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM框架在算法发现方面缺乏地理空间领域知识和多步推理能力，无法有效解决复杂的地理空间问题。

Method: GeoEvolve采用内外两层循环结构：内层循环通过代码演化生成和变异候选算法；外层智能体控制器评估全局精英算法，并查询GeoKnowRAG模块（包含地理学理论知识的结构化数据库），指导演化过程。

Result: GeoEvolve在空间插值（克里金法）和空间不确定性量化（地理空间一致性预测）任务上自动改进并发现了新算法，将空间插值误差（RMSE）降低了13-21%，并将不确定性估计性能提高了17%。消融研究表明，领域知识指导的检索对于稳定、高质量的演化至关重要。

Conclusion: GeoEvolve提供了一条可扩展的、由知识驱动的地理空间建模自动化路径，为可信赖且高效的AI for Science发现开辟了新机会。

Abstract: Geospatial modeling provides critical solutions for pressing global
challenges such as sustainability and climate change. Existing large language
model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at
evolving generic code but lack the domain knowledge and multi-step reasoning
required for complex geospatial problems. We introduce GeoEvolve, a multi-agent
LLM framework that couples evolutionary search with geospatial domain knowledge
to automatically design and refine geospatial algorithms. GeoEvolve operates in
two nested loops: an inner loop leverages a code evolver to generate and mutate
candidate solutions, while an outer agentic controller evaluates global elites
and queries a GeoKnowRAG module -- a structured geospatial knowledge base that
injects theoretical priors from geography. This knowledge-guided evolution
steers the search toward theoretically meaningful and computationally efficient
algorithms. We evaluate GeoEvolve on two fundamental and classical tasks:
spatial interpolation (kriging) and spatial uncertainty quantification
(geospatial conformal prediction). Across these benchmarks, GeoEvolve
automatically improves and discovers new algorithms, incorporating geospatial
theory on top of classical models. It reduces spatial interpolation error
(RMSE) by 13-21% and enhances uncertainty estimation performance by 17\%.
Ablation studies confirm that domain-guided retrieval is essential for stable,
high-quality evolution. These results demonstrate that GeoEvolve provides a
scalable path toward automated, knowledge-driven geospatial modeling, opening
new opportunities for trustworthy and efficient AI-for-Science discovery.

</details>


### [461] [Automated and Interpretable Survival Analysis from Multimodal Data](https://arxiv.org/abs/2509.21600)
*Mafalda Malafaia,Peter A. N. Bosman,Coen Rasch,Tanja Alderliesten*

Main category: cs.AI

TL;DR: 该研究提出了一个名为MultiFIX的可解释多模态人工智能框架，用于整合临床变量和CT影像数据，以自动化肿瘤生存分析。


<details>
  <summary>Details</summary>
Motivation: 肿瘤生存分析面临着数据日益增长和临床上对模型透明度的需求，因此需要更复杂的方法来处理多模态数据并提供可解释性。

Method: MultiFIX框架利用深度学习提取与生存相关的影像和临床特征。影像特征通过Grad-CAM进行解释，临床变量通过遗传编程建模为符号表达式。最后，使用透明的Cox回归进行风险估计和生存结果分层。

Result: 在RADCURE数据集（含头颈癌病例）上，MultiFIX在预测和分层方面的C指数分别达到了0.838和0.826，优于现有的基线方法，并与已知的预后指标一致。

Conclusion: 研究结果表明，MultiFIX在提高肿瘤生存分析的预测精度和可解释性方面具有潜力，为精准肿瘤学提供了新的途径。

Abstract: Accurate and interpretable survival analysis remains a core challenge in
oncology. With growing multimodal data and the clinical need for transparent
models to support validation and trust, this challenge increases in complexity.
We propose an interpretable multimodal AI framework to automate survival
analysis by integrating clinical variables and computed tomography imaging. Our
MultiFIX-based framework uses deep learning to infer survival-relevant features
that are further explained: imaging features are interpreted via Grad-CAM,
while clinical variables are modeled as symbolic expressions through genetic
programming. Risk estimation employs a transparent Cox regression, enabling
stratification into groups with distinct survival outcomes. Using the
open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a
C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the
clinical and academic baseline approaches and aligning with known prognostic
markers. These results highlight the promise of interpretable multimodal AI for
precision oncology with MultiFIX.

</details>


### [462] [Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries](https://arxiv.org/abs/2509.21633)
*Georgios Chochlakis,Jackson Trager,Vedant Jhaveri,Nikhil Ravichandran,Alexandros Potamianos,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 提出的语义F1分数是一种新颖的评估指标，用于衡量主观或模糊多标签分类中预测标签和真实标签之间的语义相关性。它通过引入标签相似性矩阵来计算软性精确率和召回率，进而得出语义F1分数，能够更好地处理标签重叠和标注者分歧等现实问题，并提供更公平、更具可解释性和生态有效性的评估。


<details>
  <summary>Details</summary>
Motivation: 传统F1指标在处理主观或模糊多标签分类时存在不足，无法量化预测和真实标签之间的语义相关性，常常将语义上相关的预测视为完全错误。因此，需要一种能够考虑标签间语义相似性的新评估指标。

Method: 提出了一种名为“语义F1分数”的评估指标。该指标通过构建标签相似性矩阵，计算软性精确率和召回率，并结合两者得到最终的语义F1分数。该方法能够处理任意大小的标签集，并为语义上相关但不同的标签给予部分分数。

Result: 通过理论分析和在合成及真实数据上的广泛实证验证，表明语义F1分数比传统F1指标和现有的基于相似性的指标更具可解释性和生态有效性。

Conclusion: 语义F1分数是一种新颖、有效且通用的评估指标，适用于存在人类分歧或模糊类别边界的领域。它能够更准确地反映现实情况，提供更公平的评估，并且仅需一个领域合适的相似性矩阵即可，不强制要求严格的本体。

Abstract: We propose Semantic F1 Scores, novel evaluation metrics for subjective or
fuzzy multi-label classification that quantify semantic relatedness between
predicted and gold labels. Unlike the conventional F1 metrics that treat
semantically related predictions as complete failures, Semantic F1 incorporates
a label similarity matrix to compute soft precision-like and recall-like
scores, from which the Semantic F1 scores are derived. Unlike existing
similarity-based metrics, our novel two-step precision-recall formulation
enables the comparison of label sets of arbitrary sizes without discarding
labels or forcing matches between dissimilar labels. By granting partial credit
for semantically related but nonidentical labels, Semantic F1 better reflects
the realities of domains marked by human disagreement or fuzzy category
boundaries. In this way, it provides fairer evaluations: it recognizes that
categories overlap, that annotators disagree, and that downstream decisions
based on similar predictions lead to similar outcomes. Through theoretical
justification and extensive empirical validation on synthetic and real data, we
show that Semantic F1 demonstrates greater interpretability and ecological
validity. Because it requires only a domain-appropriate similarity matrix,
which is robust to misspecification, and not a rigid ontology, it is applicable
across tasks and modalities.

</details>


### [463] [Can AI Perceive Physical Danger and Intervene?](https://arxiv.org/abs/2509.21651)
*Abhishek Jindal,Dmitry Kalashnikov,Oscar Chang,Divya Garikapati,Anirudha Majumdar,Pierre Sermanet,Vikas Sindhwani*

Main category: cs.AI

TL;DR: 该研究评估了人工智能（AI）在与物理世界交互时，尤其是在机器人和辅助代理方面，所带来的安全挑战。研究人员开发了一个可扩展的方法来持续评估具身AI系统的物理安全，该方法基于现实世界的伤害叙述和操作安全限制。利用先进的生成模型，将这些叙述和限制转化为逼真的图像和视频，以捕捉从安全到不安全状态的转变，从而探测多模态安全理解能力。研究全面分析了主要基础模型在风险感知、安全推理和干预触发方面的能力，为它们在安全关键型代理应用中的部署准备情况提供了多方面见解。最后，研究开发了一种训练后范式，通过系统指令教授模型明确推理具身特定的安全限制，生成的思考痕迹使安全推理具有可解释性和透明性，并在约束满足评估中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在AI与物理世界（如机器人或辅助代理）交互时，会出现新的安全挑战，这些挑战超出了纯粹“数字AI”的范畴。在这些交互中，造成人身伤害的可能性是直接且迫在眉睫的。然而，最先进的基础模型对有关物理安全的常识性事实（例如，箱子可能太重而无法提起，或者热咖啡不应递给孩子）的理解程度如何，目前尚不清楚。因此，本研究旨在评估和改进AI在物理安全方面的理解和推理能力。

Method: 1. 开发了一个可扩展的方法，用于对具身AI系统进行持续的物理安全基准测试，该方法基于现实世界的伤害叙述和操作安全限制。 2. 利用先进的生成模型，将这些叙述和限制转化为逼真的图像和视频，以捕捉从安全到不安全状态的转变，从而探测多模态安全理解能力。 3. 全面分析了主要基础模型在风险感知、安全推理和干预触发方面的能力。 4. 开发了一种训练后范式，通过系统指令教授模型明确推理具身特定的安全限制。

Result: 该研究全面分析了主要基础模型在风险感知、安全推理和干预触发方面的能力，为它们在安全关键型代理应用中的部署准备情况提供了多方面见解。通过训练后范式，模型能够生成具有可解释性和透明性的安全推理思考痕迹，并在约束满足评估中取得了最先进的性能。

Conclusion: 本研究通过开发物理安全基准测试、分析基础模型的能力以及提出一种新的训练后范式，显著推进了AI在物理安全领域的理解和应用。研究结果表明，虽然现有模型在安全推理方面取得了一定的进展，但仍需进一步改进以确保在安全关键型应用中的可靠部署。此外，研究中开发的基准测试和方法为未来该领域的研究提供了宝贵的资源。

Abstract: When AI interacts with the physical world -- as a robot or an assistive agent
-- new safety challenges emerge beyond those of purely ``digital AI". In such
interactions, the potential for physical harm is direct and immediate. How well
do state-of-the-art foundation models understand common-sense facts about
physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of
coffee should not be handed to a child? In this paper, our contributions are
three-fold: first, we develop a highly scalable approach to continuous physical
safety benchmarking of Embodied AI systems, grounded in real-world injury
narratives and operational safety constraints. To probe multi-modal safety
understanding, we turn these narratives and constraints into photorealistic
images and videos capturing transitions from safe to unsafe states, using
advanced generative models. Secondly, we comprehensively analyze the ability of
major foundation models to perceive risks, reason about safety, and trigger
interventions; this yields multi-faceted insights into their deployment
readiness for safety-critical agentic applications. Finally, we develop a
post-training paradigm to teach models to explicitly reason about
embodiment-specific safety constraints provided through system instructions.
The resulting models generate thinking traces that make safety reasoning
interpretable and transparent, achieving state of the art performance in
constraint satisfaction evaluations. The benchmark will be released at
https://asimov-benchmark.github.io/v2

</details>


### [464] [Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization](https://arxiv.org/abs/2509.21718)
*Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li*

Main category: cs.AI

TL;DR: 本研究提出了一种基于群体相对策略优化（GRPO）的框架，用于在低资源语言上开发文本到语音（TTS）系统，该框架利用了已有的自动语音识别（ASR）模型和少量配对数据，显著提高了语音的可懂度和说话人一致性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的TTS系统开发因缺乏配对数据而面临挑战，而ASR模型在此类语言中通常更易获得。本研究旨在利用ASR模型和GRPO来克服这一挑战，并探索其在低资源和高资源语言TTS中的应用。

Method: 首先，使用国际音标（IPA）标记训练一个多语言TTS基线模型，以建立语言无关的语音合成基础。然后，在目标新语言的有限配对数据上微调此模型，以捕捉目标语言的韵律特征。最后，利用预训练的ASR、说话人验证和音频质量评估模型作为多目标奖励，通过GRPO仅使用非配对文本和说话人提示来优化模型。

Result: 该框架在低资源语言上合成的语音具有良好的可懂度和说话人一致性，性能远超单独微调。此外，在 АSR 预训练、说话人验证和音频质量评估方面，GRPO 框架的性能也优于直接偏好优化（DPO）等离线对齐方法。

Conclusion: GRPO框架能够有效地适应低资源语言的TTS系统开发，并且在 АSR 预训练、说话人验证和音频质量评估方面也表现出色，优于现有的方法。

Abstract: Developing high-quality text-to-speech (TTS) systems for low-resource
languages is challenging due to the scarcity of paired text and speech data. In
contrast, automatic speech recognition (ASR) models for such languages are
often more accessible, owing to large-scale multilingual pre-training efforts.
We propose a framework based on Group Relative Policy Optimization (GRPO) to
adapt an autoregressive, multilingual TTS model to new languages. Our method
first establishes a language-agnostic foundation for TTS synthesis by training
a multilingual baseline with International Phonetic Alphabet (IPA) tokens.
Next, we fine-tune this model on limited paired data of the new languages to
capture the target language's prosodic features. Finally, we apply GRPO to
optimize the model using only unpaired text and speaker prompts, guided by a
multi-objective reward from pretrained ASR, speaker verification, and audio
quality estimation models. Experiments demonstrate that this pipeline produces
intelligible and speaker-consistent speech in low-resource languages,
substantially outperforming fine-tuning alone. Furthermore, our GRPO-based
framework also improves TTS performance in high-resource languages, surpassing
offline alignment methods such as Direct Preference Optimization (DPO) yielding
superior intelligibility, speaker similarity, and audio quality.

</details>


### [465] [Guiding Evolution of Artificial Life Using Vision-Language Models](https://arxiv.org/abs/2509.22447)
*Nikhil Baid,Hannah Erlebach,Paul Hellegouarch,Frederico Wieser*

Main category: cs.AI

TL;DR: ASAL++ 使用多模态基础模型（FM）来指导人工智能生命（ALife）模拟的开放式搜索，通过视觉历史生成新的进化目标，从而产生更复杂的进化轨迹。


<details>
  <summary>Details</summary>
Motivation: 利用基础模型（FM）自动化人工智能生命（ALife）模拟搜索的潜力，特别是通过多模态FM实现开放式搜索。

Method: ASAL++ 方法，它使用一个FM来提出新的进化目标，并基于模拟的视觉历史来指导搜索。探索了两种策略：(1) 进化监督目标（EST），在每次迭代中匹配单个新提示；(2) 进化时间目标（ETT），匹配生成提示的整个序列。

Result: 在Lenia基质中进行测试，ASAL++ 在EST策略下促进了更大的视觉新颖性，而在ETT策略下则促进了更连贯和可解释的进化序列。

Conclusion: ASAL++ 指明了基础模型驱动的、具有开放式特征的人工生命发现的新方向。

Abstract: Foundation models (FMs) have recently opened up new frontiers in the field of
artificial life (ALife) by providing powerful tools to automate search through
ALife simulations. Previous work aligns ALife simulations with natural language
target prompts using vision-language models (VLMs). We build on Automated
Search for Artificial Life (ASAL) by introducing ASAL++, a method for
open-ended-like search guided by multimodal FMs. We use a second FM to propose
new evolutionary targets based on a simulation's visual history. This induces
an evolutionary trajectory with increasingly complex targets.
  We explore two strategies: (1) evolving a simulation to match a single new
prompt at each iteration (Evolved Supervised Targets: EST) and (2) evolving a
simulation to match the entire sequence of generated prompts (Evolved Temporal
Targets: ETT). We test our method empirically in the Lenia substrate using
Gemma-3 to propose evolutionary targets, and show that EST promotes greater
visual novelty, while ETT fosters more coherent and interpretable evolutionary
sequences.
  Our results suggest that ASAL++ points towards new directions for FM-driven
ALife discovery with open-ended characteristics.

</details>


### [466] [Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts](https://arxiv.org/abs/2509.21743)
*Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar*

Main category: cs.AI

TL;DR: RoT通过检索和重组先前的推理步骤来提高大型推理模型的效率，在不牺牲准确性的情况下显著降低延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然能提高准确性，但推理速度慢且成本高，因此需要提高推理效率。

Method: 提出检索-思考（RoT）方法，将先前的推理步骤组织成一个思考图，并在推理时通过查询相关节点和奖励引导遍历来检索和重组这些步骤，以动态构建推理模板。

Result: RoT在多个推理基准测试和模型上进行了评估，结果显示，与基线方法相比，RoT将输出令牌减少了多达40%，推理延迟减少了82%，成本减少了59%，同时保持了准确性。提示词的增长也很小。

Conclusion: RoT通过动态模板构建，为通过检索实现大型推理模型的高效推理提供了一个可扩展的范式。

Abstract: Large reasoning models improve accuracy by producing long reasoning traces,
but this inflates latency and cost, motivating inference-time efficiency. We
propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable
``thought" steps to guide new problems. RoT organizes steps into a thought
graph with sequential and semantic edges to enable fast retrieval and flexible
recombination. At inference, RoT retrieves query-relevant nodes and applies
reward-guided traversal to assemble a problem-specific template that guides
generation. This dynamic template reuse reduces redundant exploration and,
therefore, reduces output tokens while preserving accuracy. We evaluate RoT on
reasoning benchmarks with multiple models, measuring accuracy, token usage,
latency, and memory overhead. Findings show small prompt growth but substantial
efficiency gains, with RoT reducing output tokens by up to 40%, inference
latency by 82%, and cost by 59% while maintaining accuracy. RoT establishes a
scalable paradigm for efficient LRM reasoning via dynamic template construction
through retrieval.

</details>


### [467] [Axiomatic Choice and the Decision-Evaluation Paradox](https://arxiv.org/abs/2509.21836)
*Ben Abramowitz,Nicholas Mattei*

Main category: cs.AI

TL;DR: 我们提出了一个使用决策公理（如伦理约束）来建模决策的框架，并定义了一个基于结构属性的决策公理分类法。我们揭示了使用公理进行决策与评估决策之间存在的“决策-评估悖论”，并指出该悖论在现实的公理结构中会出现，因此在训练模型或应用公理进行决策和评估时必须格外小心。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个用于建模决策的框架，该框架使用关于决策的公理（例如伦理约束）。

Method: 定义了一个基于结构属性的决策公理分类法，并展示了决策公理在用于制定决策和评估决策时所存在的张力，即“决策-评估悖论”。

Result: 该悖论在现实的公理结构中会出现。

Conclusion: 决策-评估悖论的出现表明，在根据决策数据训练模型或应用公理进行决策和评估时，必须格外小心。

Abstract: We introduce a framework for modeling decisions with axioms that are
statements about decisions, e.g., ethical constraints. Using our framework we
define a taxonomy of decision axioms based on their structural properties and
demonstrate a tension between the use of axioms to make decisions and the use
of axioms to evaluate decisions which we call the Decision-Evaluation Paradox.
We argue that the Decision-Evaluation Paradox arises with realistic axiom
structures, and the paradox illuminates why one must be exceptionally careful
when training models on decision data or applying axioms to make and evaluate
decisions.

</details>


### [468] [Lifelong Learning with Behavior Consolidation for Vehicle Routing](https://arxiv.org/abs/2509.21765)
*Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao*

Main category: cs.AI

TL;DR: 本文提出了一个名为LLR-BC的终身学习框架，用于解决车辆路径问题（VRP）的神经求解器，解决了灾难性遗忘问题，并提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器在处理新任务时，要么泛化能力不足，要么微调会导致灾难性遗忘，因此需要一种能持续学习新任务同时保留旧任务能力的框架。

Method: 提出LLR-BC框架，通过对新任务的求解器行为与旧任务的经验回放进行对齐，并根据决策的置信度分配不同的权重，来巩固先验知识。

Result: 实验证明LLR-BC在终身学习场景下能训练出高性能的神经求解器，有效解决了灾难性遗忘问题，保持了学习的灵活性，并提升了零样本泛化能力。

Conclusion: LLR-BC框架为终身学习场景下的神经VRP求解器提供了一种有效的解决方案，能够克服灾难性遗忘，并提升学习效率和泛化性能。

Abstract: Recent neural solvers have demonstrated promising performance in learning to
solve routing problems. However, existing studies are primarily based on
one-off training on one or a set of predefined problem distributions and
scales, i.e., tasks. When a new task arises, they typically rely on either
zero-shot generalization, which may be poor due to the discrepancies between
the new task and the training task(s), or fine-tuning the pretrained solver on
the new task, which possibly leads to catastrophic forgetting of knowledge
acquired from previous tasks. This paper explores a novel lifelong learning
paradigm for neural VRP solvers, where multiple tasks with diverse
distributions and scales arise sequentially over time. Solvers are required to
effectively and efficiently learn to solve new tasks while maintaining their
performance on previously learned tasks. Consequently, a novel framework called
Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed.
LLR-BC consolidates prior knowledge effectively by aligning behaviors of the
solver trained on a new task with the buffered ones in a decision-seeking way.
To encourage more focus on crucial experiences, LLR-BC assigns greater
consolidated weights to decisions with lower confidence. Extensive experiments
on capacitated vehicle routing problems and traveling salesman problems
demonstrate LLR-BC's effectiveness in training high-performance neural solvers
in a lifelong learning setting, addressing the catastrophic forgetting issue,
maintaining their plasticity, and improving zero-shot generalization ability.

</details>


### [469] [UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios](https://arxiv.org/abs/2509.21766)
*Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen*

Main category: cs.AI

TL;DR: 该研究提出了UltraHorizon基准，用于评估自主智能体在长期、部分可观测任务中的能力，发现现有LLM智能体表现不佳，且简单扩展无法解决问题。


<details>
  <summary>Details</summary>
Motivation: 现有自主智能体评估主要关注短期、完全可观测任务，无法反映软件开发、商业投资、科学发现等现实世界中的长期、部分可观测任务需求，存在评估空白。

Method: 提出UltraHorizon基准，使用探索作为统一任务，在三个不同环境中验证智能体的推理、规划、记忆和工具使用能力。智能体需通过持续交互来发现隐藏规则。

Result: 在UltraHorizon基准上，LLM智能体表现持续不佳，得分低于人类参与者。实验表明简单扩展模型无法提升性能。对轨迹的深入分析识别出八种错误类型，归因于上下文锁定和基础能力差距。

Conclusion: 现有LLM智能体在长期、部分可观测任务方面存在显著差距，简单的模型扩展无效。UltraHorizon基准能够有效揭示这些不足。

Abstract: Autonomous agents have recently achieved remarkable progress across diverse
domains, yet most evaluations focus on short-horizon, fully observable tasks.
In contrast, many critical real-world tasks, such as large-scale software
development, commercial investment, and scientific discovery, unfold in
long-horizon and partially observable scenarios where success hinges on
sustained reasoning, planning, memory management, and tool use. Existing
benchmarks rarely capture these long-horizon challenges, leaving a gap in
systematic evaluation. To bridge this gap, we introduce \textbf{UltraHorizon} a
novel benchmark that measures the foundational capabilities essential for
complex real-world challenges. We use exploration as a unifying task across
three distinct environments to validate these core competencies. Agents are
designed in long-horizon discovery tasks where they must iteratively uncover
hidden rules through sustained reasoning, planning, memory and tools
management, and interaction with environments. Under the heaviest scale
setting, trajectories average \textbf{200k+} tokens and \textbf{400+} tool
calls, whereas in standard configurations they still exceed \textbf{35k} tokens
and involve more than \textbf{60} tool calls on average. Our extensive
experiments reveal that LLM-agents consistently underperform in these settings,
whereas human participants achieve higher scores, underscoring a persistent gap
in agents' long-horizon abilities. We also observe that simple scaling fails in
our task. To better illustrate the failure of agents, we conduct an in-depth
analysis of collected trajectories. We identify eight types of errors and
attribute them to two primary causes: in-context locking and functional
fundamental capability gaps.
\href{https://github.com/StarDewXXX/UltraHorizon}{Our code will be available
here.}

</details>


### [470] [Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety](https://arxiv.org/abs/2509.21782)
*Junliang Liu,Jingyu Xiao,Wenxin Tang,Wenxuan Wang,Zhixian Wang,Minrui Zhang,Shuanghe Yu*

Main category: cs.AI

TL;DR: 现有基准测试未能充分评估多模态大语言模型（MLLMs）在构建 Web 应用时的推理、鲁棒性和安全性。本研究提出了 WebRSSBench，一个包含 8 个任务、3799 个问答对的综合性 Web 理解基准，用于评估这些能力。测试结果表明，现有 MLLMs 在处理复杂推理、UI 扰动和识别安全风险方面仍存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注视觉感知或 UI 代码生成，未能充分评估 MLLMs 在构建复杂 Web 应用（如 GUI 代理和前端代码生成）所需的推理、鲁棒性和安全性能力。因此，需要一个能够联合评估这三个关键方面的综合性基准。

Method: 提出了一种名为 WebRSSBench 的综合性 Web 理解基准。该基准包含 8 个任务，涵盖推理、鲁棒性和安全性，从 729 个网站构建，包含 3799 个问答对，用于评估多步推理能力。采用标准化的提示、确定性的评估脚本和多阶段的质量控制（结合自动检查和人工验证）来确保评估的可靠性。评估了 12 个 MLLMs。

Result: 在 WebRSSBench 基准测试中，现有 MLLMs 在处理真实布局中的组合和跨元素推理方面存在显著差距，在面对布局重排或视觉风格变化等 UI 扰动时鲁棒性有限，并且在识别和避免安全关键或不可逆操作方面表现保守。

Conclusion: 现有 MLLMs 在 Web 应用的推理、鲁棒性和安全性方面仍有很大提升空间，尤其是在处理复杂的跨元素交互、应对 UI 变化以及识别和规避安全风险方面。WebRSSBench 提供了一个评估这些能力的有效途径。

Abstract: Multimodal large language models (MLLMs) are increasingly positioned as AI
collaborators for building complex web-related applications like GUI agents and
front-end code generation. However, existing benchmarks largely emphasize
visual perception or UI code generation, showing insufficient evaluation on the
reasoning, robustness and safety capability required for end-to-end web
applications. To bridge the gap, we introduce a comprehensive web understanding
benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and
Safety across eight tasks, such as position relationship reasoning, color
robustness, and safety critical detection, etc. The benchmark is constructed
from 729 websites and contains 3799 question answer pairs that probe multi-step
inference over page structure, text, widgets, and safety-critical interactions.
To ensure reliable measurement, we adopt standardized prompts, deterministic
evaluation scripts, and multi-stage quality control combining automatic checks
with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The
results reveal significant gaps, models still struggle with compositional and
cross-element reasoning over realistic layouts, show limited robustness when
facing perturbations in user interfaces and content such as layout
rearrangements or visual style shifts, and are rather conservative in
recognizing and avoiding safety critical or irreversible actions. Our code is
available at https://github.com/jinliang-byte/webssrbench.

</details>


### [471] [CoBel-World: Harnessing LLM Reasoning to Build a Collaborative Belief World for Optimizing Embodied Multi-Agent Collaboration](https://arxiv.org/abs/2509.21981)
*Zhimin Wang,Shaokang He,Duo Wu,Jinghe Wang,Linjia Kang,Jing Yu,Zhi Wang*

Main category: cs.AI

TL;DR: CoBel-World框架通过引入协作信念世界，使LLM代理能够进行意图推理，从而提高多代理协作的效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM协作框架忽略了动态意图推理的潜力，导致计划不一致和通信冗余。

Method: 提出CoBel-World框架，通过符号信念语言将开放世界任务知识结构化为信念，并利用LLM推理进行零样本贝叶斯风格的信念更新。

Result: 在TDW-MAT和C-WAH基准测试中，CoBel-World将通信成本降低了22-60%，并将任务完成效率提高了4-28%。

Conclusion: 明确的、面向意图的信念建模对于LLM驱动的多代理系统中高效、类似人类的协作至关重要。

Abstract: Effective real-world multi-agent collaboration requires not only accurate
planning but also the ability to reason about collaborators' intents -- a
crucial capability for avoiding miscoordination and redundant communication
under partial observable environments. Due to their strong planning and
reasoning capabilities, large language models (LLMs) have emerged as promising
autonomous agents for collaborative task solving. However, existing
collaboration frameworks for LLMs overlook their reasoning potential for
dynamic intent inference, and thus produce inconsistent plans and redundant
communication, reducing collaboration efficiency. To bridge this gap, we
propose CoBel-World, a novel framework that equips LLM agents with a
collaborative belief world -- an internal representation jointly modeling the
physical environment and collaborators' mental states. CoBel-World enables
agents to parse open-world task knowledge into structured beliefs via a
symbolic belief language, and perform zero-shot Bayesian-style belief updates
through LLM reasoning. This allows agents to proactively detect potential
miscoordination (e.g., conflicting plans) and communicate adaptively. Evaluated
on challenging embodied benchmarks (i.e., TDW-MAT and C-WAH), CoBel-World
significantly reduces communication costs by 22-60% and improves task
completion efficiency by 4-28% compared to the strongest baseline. Our results
show that explicit, intent-aware belief modeling is essential for efficient and
human-like collaboration in LLM-based multi-agent systems.

</details>


### [472] [D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents](https://arxiv.org/abs/2509.21799)
*Hongze Mi,Yibo Feng,Wenjie Lu,Yuqi Wang,Jinyuan Li,Song Cao,He Cui,Tengfei Tian,Xuelin Zhang,Haotian Luo,Di Sun,Naiqiang Tan,Gang Pan*

Main category: cs.AI

TL;DR: D-Artemis是一个新颖的决策框架，利用细粒度的、应用程序特定的提示检索机制来告知其决策过程，并采用主动的预执行对齐阶段来减轻执行失败的风险。它还通过状态反思代理（SRA）完成认知循环，能够从经验中进行战略学习。D-Artemis增强了通用多模态大型语言模型（MLLMs）在GUI任务方面的能力，而无需在复杂的轨迹数据集上进行训练，并在AndroidWorld和ScreenSpot-V2基准测试上取得了新的最先进（SOTA）结果。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在端到端训练的数据瓶颈、延迟错误检测的高成本以及矛盾指导的风险方面面临挑战。

Method: D-Artemis框架包括一个细粒度的、应用程序特定的提示检索机制，一个主动的预执行对齐阶段（包括思想-行动一致性（TAC）检查模块和行动纠正代理（ACA）），以及一个后执行状态反思代理（SRA）。

Result: D-Artemis在AndroidWorld上取得了75.8%的成功率，在ScreenSpot-V2上取得了96.8%的成功率，并证明了其组件的有效性。

Conclusion: D-Artemis通过其决策框架和认知循环，在没有复杂轨迹数据集训练的情况下，增强了MLLMs在GUI任务上的能力，并在基准测试中取得了最先进的成果。

Abstract: Graphical User Interface (GUI) agents aim to automate a wide spectrum of
human tasks by emulating user interaction. Despite rapid advancements, current
approaches are hindered by several critical challenges: data bottleneck in
end-to-end training, high cost of delayed error detection, and risk of
contradictory guidance. Inspired by the human cognitive loop of Thinking,
Alignment, and Reflection, we present D-Artemis -- a novel deliberative
framework in this paper. D-Artemis leverages a fine-grained, app-specific tip
retrieval mechanism to inform its decision-making process. It also employs a
proactive Pre-execution Alignment stage, where Thought-Action Consistency (TAC)
Check module and Action Correction Agent (ACA) work in concert to mitigate the
risk of execution failures. A post-execution Status Reflection Agent (SRA)
completes the cognitive loop, enabling strategic learning from experience.
Crucially, D-Artemis enhances the capabilities of general-purpose Multimodal
large language models (MLLMs) for GUI tasks without the need for training on
complex trajectory datasets, demonstrating strong generalization. D-Artemis
establishes new state-of-the-art (SOTA) results across both major benchmarks,
achieving a 75.8% success rate on AndroidWorld and 96.8% on ScreenSpot-V2.
Extensive ablation studies further demonstrate the significant contribution of
each component to the framework.

</details>


### [473] [Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach](https://arxiv.org/abs/2509.22137)
*Seoyoung Lee,Seonbin Yoon,Seongbeen Lee,Hyesoo Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: Log2Plan通过结合结构化两级规划框架和用户行为日志的任务挖掘方法，解决了现有基于LLM或VLM的GUI自动化代理的泛化能力差、延迟高和长期连贯性有限的问题，实现了鲁棒且可适应的GUI自动化。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM或VLM的GUI自动化代理存在泛化能力差、延迟高和长期连贯性有限的问题，尤其是在UI变化或复杂任务面前表现脆弱。

Method: Log2Plan结合了结构化两级规划框架和用户行为日志的任务挖掘方法。它通过将用户命令映射到结构化任务字典来构建高级计划，并通过解释实时GUI上下文将这些高级计划分解为低级动作序列。

Result: 在200个真实任务的评估中，Log2Plan显著提高了任务成功率和执行时间，并且在长序列任务中保持了超过60.0%的成功率。

Conclusion: Log2Plan通过其结构化两级规划和任务挖掘方法，实现了鲁棒、适应性强且可重用的GUI自动化，尤其在处理复杂、多步骤的工作流方面表现出色。

Abstract: GUI task automation streamlines repetitive tasks, but existing LLM or
VLM-based planner-executor agents suffer from brittle generalization, high
latency, and limited long-horizon coherence. Their reliance on single-shot
reasoning or static plans makes them fragile under UI changes or complex tasks.
Log2Plan addresses these limitations by combining a structured two-level
planning framework with a task mining approach over user behavior logs,
enabling robust and adaptable GUI automation. Log2Plan constructs high-level
plans by mapping user commands to a structured task dictionary, enabling
consistent and generalizable automation. To support personalization and reuse,
it employs a task mining approach from user behavior logs that identifies
user-specific patterns. These high-level plans are then grounded into low-level
action sequences by interpreting real-time GUI context, ensuring robust
execution across varying interfaces. We evaluated Log2Plan on 200 real-world
tasks, demonstrating significant improvements in task success rate and
execution time. Notably, it maintains over 60.0% success rate even on
long-horizon task sequences, highlighting its robustness in complex, multi-step
workflows.

</details>


### [474] [ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration](https://arxiv.org/abs/2509.21823)
*Gaole Dai,Shiqi Jiang,Ting Cao,Yuqing Yang,Yuanchun Li,Rui Tan,Mo Li,Lili Qiu*

Main category: cs.AI

TL;DR: 现有LLM奖励方法难以推广到GUI代理，ProRe提出了一种主动奖励系统，通过通用推理器和领域特定评估器（执行器）来解决这个问题，能更准确地评估GUI代理。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则或模型的奖励方法难以推广到GUI代理，因为通常无法获取地面真实轨迹或应用程序数据库，并且基于轨迹的LLM-as-a-Judge方法准确性有限。

Method: 提出ProRe，一个主动奖励系统。该系统利用通用推理器和领域特定评估器（执行器）。推理器调度有针对性的状态探测任务，评估器执行这些任务以收集额外观测。

Result: 在超过3K个轨迹的实验结果表明，ProRe将奖励准确性和F1分数分别提高了高达5.3%和19.4%。将ProRe与最先进的策略代理集成，成功率提高了高达22.4%。

Conclusion: ProRe通过主动收集信息，实现了更准确和可验证的GUI代理奖励，显著提高了代理的性能。

Abstract: Reward is critical to the evaluation and training of large language models
(LLMs). However, existing rule-based or model-based reward methods struggle to
generalize to GUI agents, where access to ground-truth trajectories or
application databases is often unavailable, and static trajectory-based
LLM-as-a-Judge approaches suffer from limited accuracy. To address these
challenges, we propose ProRe, a proactive reward system that leverages a
general-purpose reasoner and domain-specific evaluator agents (actors). The
reasoner schedules targeted state probing tasks, which the evaluator agents
then execute by actively interacting with the environment to collect additional
observations. This enables the reasoner to assign more accurate and verifiable
rewards to GUI agents. Empirical results on over 3K trajectories demonstrate
that ProRe improves reward accuracy and F1 score by up to 5.3% and 19.4%,
respectively. Furthermore, integrating ProRe with state-of-the-art policy
agents yields a success rate improvement of up to 22.4%.

</details>


### [475] [DS-STAR: Data Science Agent via Iterative Planning and Verification](https://arxiv.org/abs/2509.21825)
*Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Tomas Pfister*

Main category: cs.AI

TL;DR: DS-STAR是一个数据科学代理，通过自动探索数据、LLM评估分析计划和迭代优化来克服LLM在处理异构数据和生成分析计划方面的挑战，并在三个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: LLM在自动化数据科学任务方面有潜力，但在处理异构数据格式和生成最优分析计划方面存在困难，因为缺乏地面真实标签来验证计划的充分性。

Method: DS-STAR包含三个主要部分：1.一个数据文件分析模块，自动探索和提取各种数据格式（包括非结构化格式）的上下文。2.一个验证步骤，由基于LLM的裁判评估每个阶段的分析计划的充分性。3.一个顺序规划机制，从一个简单的、可执行的计划开始，并根据DS-STAR的反馈进行迭代优化，直到其充分性得到验证。

Result: DS-STAR在DABStep、KramaBench和DA-Code三个具有挑战性的基准测试中取得了最先进的性能，尤其在需要处理具有异构格式的多个数据文件的困难任务上表现优于基线。

Conclusion: DS-STAR通过其创新的数据探索、LLM驱动的计划验证和迭代细化机制，能够可靠地处理复杂的数据科学分析，并显著优于现有方法。

Abstract: Data science, which transforms raw data into actionable insights, is critical
for data-driven decision-making. However, these tasks are often complex,
involving steps for exploring multiple data sources and synthesizing findings
to deliver insightful answers. While large language models (LLMs) show
significant promise in automating this process, they often struggle with
heterogeneous data formats and generate sub-optimal analysis plans, as
verifying plan sufficiency is inherently difficult without ground-truth labels
for such open-ended tasks. To overcome these limitations, we introduce DS-STAR,
a novel data science agent. Specifically, DS-STAR makes three key
contributions: (1) a data file analysis module that automatically explores and
extracts context from diverse data formats, including unstructured types; (2) a
verification step where an LLM-based judge evaluates the sufficiency of the
analysis plan at each stage; and (3) a sequential planning mechanism that
starts with a simple, executable plan and iteratively refines it based on the
DS-STAR's feedback until its sufficiency is verified. This iterative refinement
allows DS-STAR to reliably navigate complex analyses involving diverse data
sources. Our experiments show that DS-STAR achieves state-of-the-art
performance across three challenging benchmarks: DABStep, KramaBench, and
DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks
that require processing multiple data files with heterogeneous formats.

</details>


### [476] [DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents](https://arxiv.org/abs/2509.21842)
*Yansong Ning,Rui Liu,Jun Wang,Kai Chen,Wei Li,Jun Fang,Kan Zheng,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: DeepTravel是一个端到端的自主旅行规划代理框架，利用强化学习和分层奖励模型，使小型语言模型在旅行规划任务中表现优于大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有旅行规划（TP）代理依赖手工制作的提示和固定的工作流程，限制了灵活性和自主性。

Method: 提出DeepTravel框架，包括：1. 构建包含交通、住宿和POI数据的沙盒环境，用于训练；2. 开发分层奖励模型（轨迹级别和轮次级别验证器）；3. 提出回复增强强化学习方法，利用失败经验回放。

Result: DeepTravel使小型语言模型（如Qwen3 32B）在旅行规划任务上显著优于OpenAI o1, o3和DeepSeek R1等大型模型。

Conclusion: DeepTravel成功地在滴滴企业解决方案App上进行了部署和评估，证明了其在旅行规划任务中实现自主规划和提升小型语言模型性能的能力。

Abstract: Travel planning (TP) agent has recently worked as an emerging building block
to interact with external tools and resources for travel itinerary generation,
ensuring enjoyable user experience. Despite its benefits, existing studies rely
on hand craft prompt and fixed agent workflow, hindering more flexible and
autonomous TP agent. This paper proposes DeepTravel, an end to end agentic
reinforcement learning framework for building autonomous travel planning agent,
capable of autonomously planning, executing tools, and reflecting on tool
responses to explore, verify, and refine intermediate actions in multi step
reasoning. To achieve this, we first construct a robust sandbox environment by
caching transportation, accommodation and POI data, facilitating TP agent
training without being constrained by real world APIs limitations (e.g.,
inconsistent outputs). Moreover, we develop a hierarchical reward modeling
system, where a trajectory level verifier first checks spatiotemporal
feasibility and filters unsatisfied travel itinerary, and then the turn level
verifier further validate itinerary detail consistency with tool responses,
enabling efficient and precise reward service. Finally, we propose the reply
augmented reinforcement learning method that enables TP agent to periodically
replay from a failures experience buffer, emerging notable agentic capacity. We
deploy trained TP agent on DiDi Enterprise Solutions App and conduct
comprehensive online and offline evaluations, demonstrating that DeepTravel
enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing
frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.

</details>


### [477] [TRACE: Learning to Compute on Graphs](https://arxiv.org/abs/2509.21886)
*Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu*

Main category: cs.AI

TL;DR: TRACE是一个新的图学习范式，它使用分层Transformer和函数迁移学习来解决计算图学习中的固有挑战，并在电子电路基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图学习方法（如MPNN和Transformer）在处理计算图时存在架构不匹配的问题，无法捕捉计算的位置感知和分层特性。

Method: TRACE提出了一种新的范式，包括一个分层Transformer骨干网络，能够模拟计算的逐步流程，并引入了一种名为“函数迁移学习”的新颖目标，将学习问题分解为预测函数在简单局部近似基础上的“函数迁移”，而不是直接预测复杂的全局函数。

Result: 在电子电路等复杂计算图上进行的大量基准测试中，TRACE的性能显著优于所有现有架构。

Conclusion: TRACE所采用的与架构对齐的骨干网络和解耦的学习目标，为在图上学习计算这一基本挑战提供了一个更强大的范式。

Abstract: Learning to compute, the ability to model the functional behavior of a
computational graph, is a fundamental challenge for graph representation
learning. Yet, the dominant paradigm is architecturally mismatched for this
task. This flawed assumption, central to mainstream message passing neural
networks (MPNNs) and their conventional Transformer-based counterparts,
prevents models from capturing the position-aware, hierarchical nature of
computation. To resolve this, we introduce \textbf{TRACE}, a new paradigm built
on an architecturally sound backbone and a principled learning objective.
First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step
flow of computation, providing a faithful architectural backbone that replaces
the flawed permutation-invariant aggregation. Second, we introduce
\textbf{function shift learning}, a novel objective that decouples the learning
problem. Instead of predicting the complex global function directly, our model
is trained to predict only the \textit{function shift}, the discrepancy between
the true global function and a simple local approximation that assumes input
independence. We validate this paradigm on electronic circuits, one of the most
complex and economically critical classes of computational graphs. Across a
comprehensive suite of benchmarks, TRACE substantially outperforms all prior
architectures. These results demonstrate that our architecturally-aligned
backbone and decoupled learning objective form a more robust paradigm for the
fundamental challenge of learning to compute on graphs.

</details>


### [478] [GenesisGeo: Technical Report](https://arxiv.org/abs/2509.21896)
*Minfeng Zhu,Zi Wang,Sizhe Ji,Zhengtong Du,Junming Ke,Xiao Deng,Zanlang Yin,Xiuqi Huang,Heyu Wang,Wei Chen*

Main category: cs.AI

TL;DR: GenesisGeo是一个自动化的欧几里得几何定理证明器，它通过定理匹配将符号推理引擎DDARN加速了120倍，并构建了一个基于Qwen3-0.6B-Base的神经符号证明器。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个自动化的欧几里得几何定理证明器GenesisGeo，并展示了其在处理大规模几何问题和提高推理效率方面的进展。

Method: 通过定理匹配将符号推理引擎DDARN加速120倍，并结合C++实现其核心组件。基于Qwen3-0.6B-Base构建了一个神经符号证明器GenesisGeo。

Result: GenesisGeo在IMO-AG-30基准测试中，单一模型解决了30个问题中的24个（IMO银牌水平），双模型集成解决了26个问题（IMO金牌水平）。

Conclusion: GenesisGeo在处理大规模几何问题和达到IMO奖牌水平的几何定理证明方面取得了显著成果。

Abstract: We present GenesisGeo, an automated theorem prover in Euclidean geometry. We
have open-sourced a large-scale geometry dataset of 21.8 million geometric
problems, over 3 million of which contain auxiliary constructions. Specially,
we significantly accelerate the symbolic deduction engine DDARN by 120x through
theorem matching, combined with a C++ implementation of its core components.
Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon
Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the
IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold
medal level) with a dual-model ensemble.

</details>


### [479] [DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling](https://arxiv.org/abs/2509.21902)
*Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang*

Main category: cs.AI

TL;DR: DyRo-MCTS是一种改进的蒙特卡洛树搜索（MCTS）方法，用于动态作业车间调度问题。它通过整合动作鲁棒性估计，使调度决策更具适应性，能在面对新任务到达等动态变化时保持良好性能，并显著优于传统MCTS。


<details>
  <summary>Details</summary>
Motivation: 动态作业车间调度在工业领域至关重要，但新任务的频繁到达带来了严峻挑战。现有的基于机器学习的离线策略虽然响应迅速，但并不完美，需要在线规划技术（如MCTS）来改进。然而，在线规划易受新任务到达带来的不确定性影响，导致基于不完整信息的决策容易受到干扰。

Method: 提出动态鲁棒MCTS（DyRo-MCTS）方法，该方法将动作鲁棒性估计集成到MCTS中。DyRo-MCTS旨在引导生产环境达到不仅能产生良好调度结果，而且易于适应未来任务到达的状态。

Result: 通过大量实验证明，DyRo-MCTS在几乎不增加在线规划时间的情况下，显著提高了离线学习策略的性能。与标准的MCTS相比，DyRo-MCTS在各种调度场景下均表现更优。

Conclusion: DyRo-MCTS通过做出鲁棒的调度决策，能够在动态变化和干扰下实现长期、可持续的性能提升，有效解决了动态作业车间调度中的不确定性问题。

Abstract: Dynamic job shop scheduling, a fundamental combinatorial optimisation problem
in various industrial sectors, poses substantial challenges for effective
scheduling due to frequent disruptions caused by the arrival of new jobs.
State-of-the-art methods employ machine learning to learn scheduling policies
offline, enabling rapid responses to dynamic events. However, these offline
policies are often imperfect, necessitating the use of planning techniques such
as Monte Carlo Tree Search (MCTS) to improve performance at online decision
time. The unpredictability of new job arrivals complicates online planning, as
decisions based on incomplete problem information are vulnerable to
disturbances. To address this issue, we propose the Dynamic Robust MCTS
(DyRo-MCTS) approach, which integrates action robustness estimation into MCTS.
DyRo-MCTS guides the production environment toward states that not only yield
good scheduling outcomes but are also easily adaptable to future job arrivals.
Extensive experiments show that DyRo-MCTS significantly improves the
performance of offline-learned policies with negligible additional online
planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across
various scheduling scenarios. Further analysis reveals that its ability to make
robust scheduling decisions leads to long-term, sustainable performance gains
under disturbances.

</details>


### [480] [Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning](https://arxiv.org/abs/2509.21943)
*Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich*

Main category: cs.AI

TL;DR: 本研究比较了SPM和可解释机器学习（ML）方法在足底压力数据异常值检测中的表现，ML模型准确率更高，SPM模型则漏报和误报较多。


<details>
  <summary>Details</summary>
Motivation: 足底压力分析在临床诊断和运动科学中很重要，但数据中常有因技术或程序问题导致的异常值。SPM方法对齐敏感且异常值检测能力不明确，因此需要开发更可靠的异常值检测方法。

Method: 本研究采用了两种方法：1. 非参数、依赖配准的SPM方法。 2. 使用SHAP解释的卷积神经网络（CNN）模型。通过交叉验证评估性能，并通过专家调查评估解释质量。

Result: ML模型在准确率上优于SPM，SPM模型错误地将临床上有意义的变化识别为异常值，并且未能检测出真正的异常值。专家认为SPM和SHAP的解释都清晰、有用且值得信赖，但SPM的复杂性较低。

Conclusion: SPM和可解释ML在足底压力数据异常值自动检测方面具有互补性。模型的可解释性对于将复杂模型的输出转化为可理解的见解至关重要，从而有效指导决策。

Abstract: Plantar pressure mapping is essential in clinical diagnostics and sports
science, yet large heterogeneous datasets often contain outliers from technical
errors or procedural inconsistencies. Statistical Parametric Mapping (SPM)
provides interpretable analyses but is sensitive to alignment and its capacity
for robust outlier detection remains unclear. This study compares an SPM
approach with an explainable machine learning (ML) approach to establish
transparent quality-control pipelines for plantar pressure datasets. Data from
multiple centers were annotated by expert consensus and enriched with synthetic
anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a
non-parametric, registration-dependent SPM approach and (ii) a convolutional
neural network (CNN), explained using SHapley Additive exPlanations (SHAP).
Performance was assessed via nested cross-validation; explanation quality via a
semantic differential survey with domain experts. The ML model reached high
accuracy and outperformed SPM, which misclassified clinically meaningful
variations and missed true outliers. Experts perceived both SPM and SHAP
explanations as clear, useful, and trustworthy, though SPM was assessed less
complex. These findings highlight the complementary potential of SPM and
explainable ML as approaches for automated outlier detection in plantar
pressure data, and underscore the importance of explainability in translating
complex model outputs into interpretable insights that can effectively inform
decision-making.

</details>


### [481] [RISK: A Framework for GUI Agents in E-commerce Risk Management](https://arxiv.org/abs/2509.21982)
*Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: E-commerce risk management requires aggregating diverse, deeply embedded web
data through multi-step, stateful interactions, which traditional scraping
methods and most existing Graphical User Interface (GUI) agents cannot handle.
These agents are typically limited to single-step tasks and lack the ability to
manage dynamic, interactive content critical for effective risk assessment. To
address this challenge, we introduce RISK, a novel framework designed to build
and deploy GUI agents for this domain. RISK integrates three components: (1)
RISK-Data, a dataset of 8,492 single-step and 2,386 multi-step interaction
trajectories, collected through a high-fidelity browser framework and a
meticulous data curation process; (2) RISK-Bench, a benchmark with 802
single-step and 320 multi-step trajectories across three difficulty levels for
standardized evaluation; and (3) RISK-R1, a R1-style reinforcement fine-tuning
framework considering four aspects: (i) Output Format: Updated format reward to
enhance output syntactic correctness and task comprehension, (ii) Single-step
Level: Stepwise accuracy reward to provide granular feedback during early
training stages, (iii) Multi-step Level: Process reweight to emphasize critical
later steps in interaction sequences, and (iv) Task Level: Level reweight to
focus on tasks of varying difficulty. Experiments show that RISK-R1 outperforms
existing baselines, achieving a 6.8% improvement in offline single-step and an
8.8% improvement in offline multi-step. Moreover, it attains a top task success
rate of 70.5% in online evaluation. RISK provides a scalable, domain-specific
solution for automating complex web interactions, advancing the state of the
art in e-commerce risk management.

</details>


### [482] [Bilinear relational structure fixes reversal curse and enables consistent model editing](https://arxiv.org/abs/2509.21993)
*Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha*

Main category: cs.AI

TL;DR: 语言模型在推理反向事实方面存在“反转诅咒”问题，这并非模型固有的局限，而是其知识编码方式的结果。通过在关系知识图谱数据集上训练模型，可以涌现出双线性关系结构，从而有效缓解反转诅咒。


<details>
  <summary>Details</summary>
Motivation: “反转诅咒”被认为是语言模型的一个基本局限，即模型无法从“A是B”推断出未见过的“B是A”。

Method: 使用合成的关系知识图谱数据集从头开始训练语言模型。

Result: 在模型表示中发现了双线性关系结构，这种结构能缓解“反转诅咒”，使模型能够推断出未知的反向事实。此外，这种结构在模型编辑方面也起着关键作用，能确保编辑的一致性传播到逻辑相关的其他事实。

Conclusion: 训练模型处理关系知识数据集能够诱导出双线性内部表示，这使得语言模型在编辑后能够以逻辑一致的方式运行。模型的成功编辑不仅取决于编辑算法，还关键在于被修改知识的底层表示几何。

Abstract: The reversal curse -- a language model's (LM) inability to infer an unseen
fact ``B is A'' from a learned fact ``A is B'' -- is widely considered a
fundamental limitation. We show that this is not an inherent failure but an
artifact of how models encode knowledge. By training LMs from scratch on a
synthetic dataset of relational knowledge graphs, we demonstrate that bilinear
relational structure emerges in their hidden representations. This structure
substantially alleviates the reversal curse, enabling LMs to infer unseen
reverse facts. Crucially, we also find that this bilinear structure plays a key
role in consistent model editing. When a fact is updated in a LM with this
structure, the edit correctly propagates to its reverse and other logically
dependent facts. In contrast, models lacking this representation not only
suffer from the reversal curse but also fail to generalize edits, further
introducing logical inconsistencies. Our results establish that training on a
relational knowledge dataset induces the emergence of bilinear internal
representations, which in turn enable LMs to behave in a logically consistent
manner after editing. This implies that the success of model editing depends
critically not just on editing algorithms but on the underlying
representational geometry of the knowledge being modified.

</details>


### [483] [GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments](https://arxiv.org/abs/2509.21998)
*Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao*

Main category: cs.AI

TL;DR: 我们提出了一个名为GSM-Agent的新基准，用于评估LLM的工具使用和推理能力，特别是在需要主动从环境中收集信息以解决基础数学问题时。我们还引入了“代理推理图”的概念来分析模型的推理模式，并发现许多模型缺乏重新访问先前节点的能力。为了解决这个问题，我们提出了一种工具增强的测试时间缩放方法来提高LLM的代理推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理评估基准难以区分代理推理能力，因为它们通常将代理推理与复杂的数学推理、专业知识等能力混合在一起。需要一个专门的基准来填补这一空白，以隔离和评估代理推理。

Method: 我们构建了一个名为GSM-Agent的新基准，其中LLM代理需要解决基础数学问题，但只能在提示中获得问题，而没有解决任务所需的信息。代理需要主动使用工具（例如搜索）来收集信息。我们还提出了“代理推理图”的概念，通过将环境文档嵌入聚类为节点，并将每个工具调用映射到最近的节点来构建推理路径，以分析模型的推理模式。

Result: 即使是像GPT-5这样的前沿模型，在GSM-Agent基准上的准确率也只有67%。我们发现，许多模型在代理推理中缺乏重新访问先前访问过的节点的能力，而这种能力在静态推理中被认为是至关重要的。基于这一见解，我们提出了一种工具增强的测试时间缩放方法，通过添加工具来鼓励模型重新访问节点，从而提高LLM的代理推理性能。

Conclusion: GSM-Agent基准和代理推理框架为未来研究理解和突破LLM代理推理能力提供了有用的工具。我们发现重新访问节点的能力对代理推理至关重要，并提出了一种通过工具增强来提高这种能力的方法。

Abstract: As LLMs are increasingly deployed as agents, agentic reasoning - the ability
to combine tool use, especially search, and reasoning - becomes a critical
skill. However, it is hard to disentangle agentic reasoning when evaluated in
complex environments and tasks. Current agent benchmarks often mix agentic
reasoning with challenging math reasoning, expert-level knowledge, and other
advanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent,
where an LLM agent is required to solve grade-school-level reasoning problems,
but is only presented with the question in the prompt without the premises that
contain the necessary information to solve the task, and needs to proactively
collect that information using tools. Although the original tasks are
grade-school math problems, we observe that even frontier models like GPT-5
only achieve 67% accuracy. To understand and analyze the agentic reasoning
patterns, we propose the concept of agentic reasoning graph: cluster the
environment's document embeddings into nodes, and map each tool call to its
nearest node to build a reasoning path. Surprisingly, we identify that the
ability to revisit a previously visited node, widely taken as a crucial pattern
in static reasoning, is often missing for agentic reasoning for many models.
Based on the insight, we propose a tool-augmented test-time scaling method to
improve LLM's agentic reasoning performance by adding tools to encourage models
to revisit. We expect our benchmark and the agentic reasoning framework to aid
future studies of understanding and pushing the boundaries of agentic
reasoning.

</details>


### [484] [The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging](https://arxiv.org/abs/2509.22034)
*Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li*

Main category: cs.AI

TL;DR: 模型合并技术可用于在推理深度和计算成本之间进行权衡，以创建具有可调推理能力的大型语言模型（LLM）。


<details>
  <summary>Details</summary>
Motivation: 随着对具有可调推理能力的大型语言模型（LLM）的需求不断增长，需要一种能够有效生成一系列模型以平衡推理深度和计算成本的方法。

Method: 通过对通用模型和专门推理模型的权重进行算术组合，对各种模型合并技术进行了大规模的实证研究，并生成了准确性-效率曲线。

Result: 模型合并是一种有效且可控的方法，可以校准推理准确性和令牌效率之间的权衡，即使在父模型具有高度发散的权重空间的情况下也是如此。已确定了帕累托改进的实例，其中合并后的模型在准确性和令牌消耗方面都优于其父模型之一。

Conclusion: 这项研究提供了对模型合并可调空间的首次全面分析，为创建具有特定推理能力的 LLM 以满足多样化的应用需求提供了实用的指导。

Abstract: The growing demand for large language models (LLMs) with tunable reasoning
capabilities in many real-world applications highlights a critical need for
methods that can efficiently produce a spectrum of models balancing reasoning
depth and computational cost. Model merging has emerged as a promising,
training-free technique to address this challenge by arithmetically combining
the weights of a general-purpose model with a specialized reasoning model.
While various merging techniques exist, their potential to create a spectrum of
models with fine-grained control over reasoning abilities remains largely
unexplored. This work presents a large-scale empirical study evaluating a range
of model merging techniques across multiple reasoning benchmarks. We
systematically vary merging strengths to construct accuracy-efficiency curves,
providing the first comprehensive view of the tunable performance landscape.
Our findings reveal that model merging offers an effective and controllable
method for calibrating the trade-off between reasoning accuracy and token
efficiency, even when parent models have highly divergent weight spaces.
Crucially, we identify instances of Pareto Improvement, where a merged model
achieves both higher accuracy and lower token consumption than one of its
parents. Our study provides the first comprehensive analysis of this tunable
space, offering practical guidelines for creating LLMs with specific reasoning
profiles to meet diverse application demands.

</details>


### [485] [A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning](https://arxiv.org/abs/2509.22044)
*Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen*

Main category: cs.AI

TL;DR: A2R框架通过并行生成多个解决方案并由合成器进行精炼，以弥合模型推理能力与潜力之间的差距，并在效率和性能方面均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型在复杂任务解决能力上有所提升，但单次尝试的性能与潜在能力之间存在差距，作者提出A2R框架来解决这个问题。

Method: A2R框架包含两个阶段：‘探索者’模型并行生成多个潜在解决方案，‘合成器’模型对这些解决方案进行整合和精炼。

Result: A2R框架显著提升了模型性能，例如，Qwen3-8B-distill模型使用A2R框架性能提升75%。A2R-Efficient（小探索者+大合成器）在成本降低近30%的情况下，超越了同等规模的单一模型。

Conclusion: A2R框架不仅能提升模型性能，而且是一种高效实用的解决方案，适用于实际应用。

Abstract: Recent Large Reasoning Models have achieved significant improvements in
complex task-solving capabilities by allocating more computation at the
inference stage with a "thinking longer" paradigm. Even as the foundational
reasoning capabilities of models advance rapidly, the persistent gap between a
model's performance in a single attempt and its latent potential, often
revealed only across multiple solution paths, starkly highlights the disparity
between its realized and inherent capabilities. To address this, we present
A2R, an Asymmetric Two-Stage Reasoning framework designed to explicitly bridge
the gap between a model's potential and its actual performance. In this
framework, an "explorer" model first generates potential solutions in parallel
through repeated sampling. Subsequently,a "synthesizer" model integrates these
references for a more refined, second stage of reasoning. This two-stage
process allows computation to be scaled orthogonally to existing sequential
methods. Our work makes two key innovations: First, we present A2R as a
plug-and-play parallel reasoning framework that explicitly enhances a model's
capabilities on complex questions. For example, using our framework, the
Qwen3-8B-distill model achieves a 75% performance improvement compared to its
self-consistency baseline. Second, through a systematic analysis of the
explorer and synthesizer roles, we identify an effective asymmetric scaling
paradigm. This insight leads to A2R-Efficient, a "small-to-big" variant that
combines a Qwen3-4B explorer with a Qwen3-8B synthesizer. This configuration
surpasses the average performance of a monolithic Qwen3-32B model at a nearly
30% lower cost. Collectively, these results show that A2R is not only a
performance-boosting framework but also an efficient and practical solution for
real-world applications.

</details>


### [486] [Generalizing Multi-Objective Search via Objective-Aggregation Functions](https://arxiv.org/abs/2509.22085)
*Hadar Peer,Eyal Weiss,Ron Alterovitz,Oren Salzman*

Main category: cs.AI

TL;DR: 本篇论文提出了一种通用的多目标搜索（MOS）问题形式化方法，通过聚合隐藏目标来优化解决方案目标，使得标准的MOS算法能够应用于复杂的机器人规划问题，并在多种机器人规划任务中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的机器人系统需要同时平衡多个相互冲突的目标，而现有的MOS算法难以处理复杂的、非标准形式的目标交互问题。

Method: 提出了一种通用的问题形式化方法，通过聚合函数来优化隐藏目标，并对标准的MOS算法的核心操作进行扩展以适应这种形式化方法。

Result: 在导航运动规划、机械臂操作规划、医疗系统规划、检查规划和不同路况的路线规划等多种机器人规划问题中，通过扩展核心操作的标准MOS算法，其性能比未进行目标聚合的原始算法高出几个数量级。

Conclusion: 通过目标聚合的方法，可以使标准的MOS算法适用于复杂的机器人规划问题，并且在实际应用中能够显著提升性能。

Abstract: Multi-objective search (MOS) has become essential in robotics, as real-world
robotic systems need to simultaneously balance multiple, often conflicting
objectives. Recent works explore complex interactions between objectives,
leading to problem formulations that do not allow the usage of out-of-the-box
state-of-the-art MOS algorithms. In this paper, we suggest a generalized
problem formulation that optimizes solution objectives via aggregation
functions of hidden (search) objectives. We show that our formulation supports
the application of standard MOS algorithms, necessitating only to properly
extend several core operations to reflect the specific aggregation functions
employed. We demonstrate our approach in several diverse robotics planning
problems, spanning motion-planning for navigation, manipulation and planning fr
medical systems under obstacle uncertainty as well as inspection planning, and
route planning with different road types. We solve the problems using
state-of-the-art MOS algorithms after properly extending their core operations,
and provide empirical evidence that they outperform by orders of magnitude the
vanilla versions of the algorithms applied to the same problems but without
objective aggregation.

</details>


### [487] [Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements](https://arxiv.org/abs/2509.22092)
*Raphael Fischer*

Main category: cs.AI

TL;DR: ML/AI工具的估算结果存在高达40%的误差，本研究通过与真实测量值进行比较来评估其准确性，并提出改进指南。


<details>
  <summary>Details</summary>
Motivation: 机器学习（ML）和人工智能（AI）的发展对环境造成了影响，现有工具（如ML Emissions Calculator和CodeCarbon）在估算其能源消耗和碳排放时存在不准确性，需要对其估算准确性进行评估。

Method: 通过将静态和动态能源估算方法与实际测量值进行比较，在数百个AI实验中系统地评估了其可靠性。

Result: 现有的估算方法在普遍遵循AI能耗模式的同时，估算错误高达40%。

Conclusion: 本研究通过提供关于能源估算质量和错误的经验证据，提高了透明度，并验证了广泛使用的可持续AI开发工具。此外，本研究还制定了改进现有技术的指南，并提供了可将验证扩展到其他领域和工具的代码，为资源感知的ML和AI可持续性研究做出了重要贡献。

Abstract: Although machine learning (ML) and artificial intelligence (AI) present
fascinating opportunities for innovation, their rapid development is also
significantly impacting our environment. In response to growing
resource-awareness in the field, quantification tools such as the ML Emissions
Calculator and CodeCarbon were developed to estimate the energy consumption and
carbon emissions of running AI models. They are easy to incorporate into AI
projects, however also make pragmatic assumptions and neglect important
factors, raising the question of estimation accuracy. This study systematically
evaluates the reliability of static and dynamic energy estimation approaches
through comparisons with ground-truth measurements across hundreds of AI
experiments. Based on the proposed validation framework, investigative insights
into AI energy demand and estimation inaccuracies are provided. While generally
following the patterns of AI energy consumption, the established estimation
approaches are shown to consistently make errors of up to 40%. By providing
empirical evidence on energy estimation quality and errors, this study
establishes transparency and validates widely used tools for sustainable AI
development. It moreover formulates guidelines for improving the
state-of-the-art and offers code for extending the validation to other domains
and tools, thus making important contributions to resource-aware ML and AI
sustainability research.

</details>


### [488] [Clinical Uncertainty Impacts Machine Learning Evaluations](https://arxiv.org/abs/2509.22242)
*Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly*

Main category: cs.AI

TL;DR: 标签不确定性影响模型排名，应采用概率指标和原始注释进行评估。


<details>
  <summary>Details</summary>
Motivation: 临床数据集标签存在不确定性，现有聚合方法（如多数投票）忽略了这种变异性。

Method: 提出使用概率指标直接处理分布，以考虑注释不确定性。

Result: 在医学成像基准的简单实验中，考虑置信度会显著影响模型排名。

Conclusion: 机器学习评估应明确考虑注释不确定性，社区应发布原始注释并采用不确定性感知评估。

Abstract: Clinical dataset labels are rarely certain as annotators disagree and
confidence is not uniform across cases. Typical aggregation procedures, such as
majority voting, obscure this variability. In simple experiments on medical
imaging benchmarks, accounting for the confidence in binary labels
significantly impacts model rankings. We therefore argue that machine-learning
evaluations should explicitly account for annotation uncertainty using
probabilistic metrics that directly operate on distributions. These metrics can
be applied independently of the annotations' generating process, whether
modeled by simple counting, subjective confidence ratings, or probabilistic
response models. They are also computationally lightweight, as closed-form
expressions have linear-time implementations once examples are sorted by model
score. We thus urge the community to release raw annotations for datasets and
to adopt uncertainty-aware evaluation so that performance estimates may better
reflect clinical data.

</details>


### [489] [Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing](https://arxiv.org/abs/2509.22255)
*Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Rajesh Mojumder*

Main category: cs.AI

TL;DR: 本文提出了一种评估大型语言模型（LLM）在组合优化（特别是二维装箱问题）方面能力的框架，并结合演化算法。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在组合优化问题（二维装箱问题）上的能力，并提出一种结合LLM与演化算法的系统化方法。

Method: 结合LLM与演化算法，迭代地生成和优化启发式解决方案。

Result: 与传统方法相比，LLM生成的启发式算法效率更高，计算资源消耗更少。GPT-4o在两次迭代内达到最优解，平均箱子使用量从16个减少到15个，空间利用率从0.76-0.78提高到0.83。

Conclusion: LLM能够生成更优的二维装箱问题解决方案，并且在特定领域评估LLM的潜力，为评估LLM在组合优化任务上的表现建立基准。

Abstract: This paper presents an evaluation framework for assessing Large Language
Models' (LLMs) capabilities in combinatorial optimization, specifically
addressing the 2D bin-packing problem. We introduce a systematic methodology
that combines LLMs with evolutionary algorithms to generate and refine
heuristic solutions iteratively. Through comprehensive experiments comparing
LLM generated heuristics against traditional approaches (Finite First-Fit and
Hybrid First-Fit), we demonstrate that LLMs can produce more efficient
solutions while requiring fewer computational resources. Our evaluation reveals
that GPT-4o achieves optimal solutions within two iterations, reducing average
bin usage from 16 to 15 bins while improving space utilization from 0.76-0.78
to 0.83. This work contributes to understanding LLM evaluation in specialized
domains and establishes benchmarks for assessing LLM performance in
combinatorial optimization tasks.

</details>


### [490] [InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.22261)
*Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiMed-Foundation模型解决了通用大语言模型在医学领域知识缺乏、训练效率低下和知识提取困难等问题，并在医学视觉问答和诊断任务上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 通用多模态大语言模型（MLLMs）在医学领域的应用受到专业知识缺乏、幻觉响应、知识蒸馏效果不佳以及持续预训练计算成本高等挑战的限制。

Method: 提出了InfiMed-Foundation-1.7B和InfiMed-Foundation-4B两个医学领域专用MLLMs。通过结合高质量的通用和医学多模态数据，并采用新颖的五维质量评估框架来精选数据集。使用低到高分辨率图像和多模态序列打包来提高训练效率，并采用三阶段监督微调来增强知识提取能力。

Result: 在MedEvalKit框架的评估中，InfiMed-Foundation-1.7B在医学视觉问答和诊断任务上表现优于Qwen2.5VL-3B。InfiMed-Foundation-4B的表现优于HuatuoGPT-V-7B和MedGemma-27B-IT。

Conclusion: 通过解决数据质量、训练效率和领域特定知识提取方面的关键挑战，InfiMed-Foundation模型为医疗保健领域更可靠、更有效的AI驱动解决方案铺平了道路。

Abstract: Multimodal large language models (MLLMs) have shown remarkable potential in
various domains, yet their application in the medical field is hindered by
several challenges. General-purpose MLLMs often lack the specialized knowledge
required for medical tasks, leading to uncertain or hallucinatory responses.
Knowledge distillation from advanced models struggles to capture
domain-specific expertise in radiology and pharmacology. Additionally, the
computational cost of continual pretraining with large-scale medical data poses
significant efficiency challenges. To address these issues, we propose
InfiMed-Foundation-1.7B and InfiMed-Foundation-4B, two medical-specific MLLMs
designed to deliver state-of-the-art performance in medical applications. We
combined high-quality general-purpose and medical multimodal data and proposed
a novel five-dimensional quality assessment framework to curate high-quality
multimodal medical datasets. We employ low-to-high image resolution and
multimodal sequence packing to enhance training efficiency, enabling the
integration of extensive medical data. Furthermore, a three-stage supervised
fine-tuning process ensures effective knowledge extraction for complex medical
tasks. Evaluated on the MedEvalKit framework, InfiMed-Foundation-1.7B
outperforms Qwen2.5VL-3B, while InfiMed-Foundation-4B surpasses HuatuoGPT-V-7B
and MedGemma-27B-IT, demonstrating superior performance in medical visual
question answering and diagnostic tasks. By addressing key challenges in data
quality, training efficiency, and domain-specific knowledge extraction, our
work paves the way for more reliable and effective AI-driven solutions in
healthcare. InfiMed-Foundation-4B model is available at
\href{https://huggingface.co/InfiX-ai/InfiMed-Foundation-4B}{InfiMed-Foundation-4B}.

</details>


### [491] [Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models](https://arxiv.org/abs/2509.22284)
*Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi*

Main category: cs.AI

TL;DR: PD-SSM是一种结构化稀疏参数化的状态空间模型，通过将转移矩阵参数化为列独热矩阵 P 和复值对角矩阵 D 的乘积，实现了高效的有限状态自动机（FSA）状态跟踪，同时保持了与对角SSM相当的计算成本，并在FSA状态跟踪和时间序列分类任务上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的状态空间模型（SSM）虽然计算效率高，但在表达能力（尤其是在模拟有限状态自动机FSA方面）受到转移矩阵的限制。然而，非结构化的转移矩阵虽然表达能力最强，但计算和内存成本过高。

Method: 提出一种结构化稀疏参数化的方法（PD-SSM），将转移矩阵表示为列独热矩阵 P 和复值对角矩阵 D 的乘积。这种结构允许模型以最优的状态大小和深度来跟踪FSA状态，同时将计算成本保持在与对角SSM相当的水平。计算成本的扩展与状态大小成线性关系。

Result: PD-SSM在理论上是BIBO稳定的，并且能够用单层维度为N的SSM和大小为N×N的线性读出器来模拟任何N状态的FSA。实验表明，PD-SSM在各种FSA状态跟踪任务上的表现显著优于其他SSM变体，在多类时间序列分类任务上的表现与神经微分方程（NDEs）相当。PD-SSM还可以集成到混合Transformer-SSM架构中，以跟踪复杂FSA的状态，即使这些状态是以可变长度的英文字符串形式编码的。

Conclusion: PD-SSM通过创新的结构化稀疏参数化方法，有效解决了现有SSM在表达能力和计算成本之间的权衡问题，并在FSA状态跟踪和时间序列分类等任务上取得了领先的性能，展示了其在处理复杂序列数据方面的巨大潜力。

Abstract: Modern state-space models (SSMs) often utilize transition matrices which
enable efficient computation but pose restrictions on the model's expressivity,
as measured in terms of the ability to emulate finite-state automata (FSA).
While unstructured transition matrices are optimal in terms of expressivity,
they come at a prohibitively high compute and memory cost even for moderate
state sizes. We propose a structured sparse parametrization of transition
matrices in SSMs that enables FSA state tracking with optimal state size and
depth, while keeping the computational cost of the recurrence comparable to
that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix
as the product of a column one-hot matrix ($P$) and a complex-valued diagonal
matrix ($D$). Consequently, the computational cost of parallel scans scales
linearly with the state size. Theoretically, the model is BIBO-stable and can
emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout
of size $N \times N$, significantly improving on all current structured SSM
guarantees. Experimentally, the model significantly outperforms a wide
collection of modern SSM variants on various FSA state tracking tasks. On
multiclass time-series classification, the performance is comparable to that of
neural controlled differential equations, a paradigm explicitly built for
time-series analysis. Finally, we integrate PD-SSM into a hybrid
Transformer-SSM architecture and demonstrate that the model can effectively
track the states of a complex FSA in which transitions are encoded as a set of
variable-length English sentences. The code is available at
https://github.com/IBM/expressive-sparse-state-space-model

</details>


### [492] [Large Language Models as Nondeterministic Causal Models](https://arxiv.org/abs/2509.22297)
*Sander Beckers*

Main category: cs.AI

TL;DR: 该研究提出了一种新的、更简单的生成语言模型（LLM）反事实的方法，该方法基于LLM的预期解释，并将其表示为非确定性因果模型。


<details>
  <summary>Details</summary>
Motivation: 现有生成LLM反事实的方法存在歧义，因为它没有字面解释LLM，也没有将其解释为预期，涉及在不改变LLM本身的情况下改变其采样过程的实现，或将非确定性LLM表示为确定性因果模型。

Method: 提出了一种更简单的生成反事实的方法，该方法基于LLM的预期解释，并将其表示为非确定性因果模型。这种方法直接适用于任何黑盒LLM，无需修改，因为它不考虑任何实现细节。

Result: 现有的方法在生成特定类型的反事实方面具有优势，但并不适用于所有情况。而新的方法更简单，直接适用于任何黑盒LLM。

Conclusion: 该研究为基于LLM预期语义推理反事实提供了理论基础，并为生成新的、特定应用的‘反事实’方法奠定了基础。

Abstract: Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first
time, a method for generating counterfactuals of probabilistic Large Language
Models. Such counterfactuals tell us what would - or might - have been the
output of an LLM if some factual prompt ${\bf x}$ had been ${\bf x}^*$ instead.
The ability to generate such counterfactuals is an important necessary step
towards explaining, evaluating, and comparing, the behavior of LLMs. I argue,
however, that the existing method rests on an ambiguous interpretation of LLMs:
it does not interpret LLMs literally, for the method involves the assumption
that one can change the implementation of an LLM's sampling process without
changing the LLM itself, nor does it interpret LLMs as intended, for the method
involves explicitly representing a nondeterministic LLM as a deterministic
causal model. I here present a much simpler method for generating
counterfactuals that is based on an LLM's intended interpretation by
representing it as a nondeterministic causal model instead. The advantage of my
simpler method is that it is directly applicable to any black-box LLM without
modification, as it is agnostic to any implementation details. The advantage of
the existing method, on the other hand, is that it directly implements the
generation of a specific type of counterfactuals that is useful for certain
purposes, but not for others. I clarify how both methods relate by offering a
theoretical foundation for reasoning about counterfactuals in LLMs based on
their intended semantics, thereby laying the groundwork for novel
application-specific methods for generating counterfactuals.

</details>


### [493] [PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning](https://arxiv.org/abs/2509.22315)
*Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu*

Main category: cs.AI

TL;DR: PRIME框架通过整合快速（System 1）和慢速（System 2）推理，提高了LLMs在复杂推理任务上的表现，使其在基准测试中能与GPT-4等先进模型相媲美。


<details>
  <summary>Details</summary>
Motivation: 受到人类认知中双过程理论的启发，提出PRIME框架，旨在通过模拟人类的快速直觉思考和慢速审慎思考相结合的方式，来提升大型语言模型（LLMs）在复杂推理任务上的效率和准确性。

Method: PRIME框架包含一个快速思考代理（System 1）用于生成初步答案，并在检测到不确定性时触发一个结构化的System 2推理流程。该流程由专门的代理组成，负责规划、假设生成、检索、信息整合和决策，从而忠实地模仿人类认知过程。

Result: 实验结果表明，使用LLaMA 3模型实现的PRIME框架，在需要多跳和知识支撑的推理基准测试上，表现与GPT-4和GPT-4o等顶尖闭源模型相当。

Conclusion: PRIME框架为提高LLMs在需要复杂、知识密集型推理的领域的能力提供了一个可扩展的解决方案，使得开源LLMs能够达到先进闭源模型的竞争水平。

Abstract: Inspired by the dual-process theory of human cognition from \textit{Thinking,
Fast and Slow}, we introduce \textbf{PRIME} (Planning and Retrieval-Integrated
Memory for Enhanced Reasoning), a multi-agent reasoning framework that
dynamically integrates \textbf{System 1} (fast, intuitive thinking) and
\textbf{System 2} (slow, deliberate thinking). PRIME first employs a Quick
Thinking Agent (System 1) to generate a rapid answer; if uncertainty is
detected, it then triggers a structured System 2 reasoning pipeline composed of
specialized agents for \textit{planning}, \textit{hypothesis generation},
\textit{retrieval}, \textit{information integration}, and
\textit{decision-making}. This multi-agent design faithfully mimics human
cognitive processes and enhances both efficiency and accuracy. Experimental
results with LLaMA 3 models demonstrate that PRIME enables open-source LLMs to
perform competitively with state-of-the-art closed-source models like GPT-4 and
GPT-4o on benchmarks requiring multi-hop and knowledge-grounded reasoning. This
research establishes PRIME as a scalable solution for improving LLMs in domains
requiring complex, knowledge-intensive reasoning.

</details>


### [494] [Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents](https://arxiv.org/abs/2509.22391)
*Jiaqi Shao,Yuxiang Lin,Munish Prasad Lohani,Yufeng Miao,Bing Luo*

Main category: cs.AI

TL;DR: SeekBench是一个新的基准，用于评估LLM搜索代理的“认知能力”，通过分析其响应轨迹的每个步骤来评估代理是否能基于证据进行推理，自适应地改进搜索，并正确评估证据是否足以回答问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM搜索代理的评估主要关注最终答案的准确性，忽略了它们如何利用外部证据进行推理和行动。需要一个评估代理认知能力的基准。

Method: 提出SeekBench，一个包含190个专家标注的轨迹、1800多个响应步骤的基准，用于对LLM搜索代理进行逐级分析。评估指标包括：1. 代理的推理步骤是否基于观察到的证据；2. 代理是否能自适应地改进搜索以克服低质量结果；3. 代理是否能正确评估现有证据是否足以回答问题。

Result: SeekBench是首个用于评估LLM搜索代理认知能力的基准，通过对响应轨迹的细粒度分析，关注证据使用、搜索适应性和证据充分性评估。

Conclusion: SeekBench通过分析LLM搜索代理响应轨迹的每个步骤，为评估其认知能力提供了一个新的视角，超越了传统的最终答案准确性评估。

Abstract: Recent work has explored training Large Language Model (LLM) search agents
with reinforcement learning (RL) for open-domain question answering (QA).
However, most evaluations focus solely on final answer accuracy, overlooking
how these agents reason with and act on external evidence. We introduce
SeekBench, the first benchmark for evaluating the \textit{epistemic competence}
of LLM search agents through step-level analysis of their response traces.
SeekBench comprises 190 expert-annotated traces with over 1,800 response steps
generated by LLM search agents, each enriched with evidence annotations for
granular analysis of whether agents (1) generate reasoning steps grounded in
observed evidence, (2) adaptively reformulate searches to recover from
low-quality results, and (3) have proper calibration to correctly assess
whether the current evidence is sufficient for providing an answer.

</details>


### [495] [EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer](https://arxiv.org/abs/2509.22407)
*Zhehao Dong,Xiaofeng Wang,Zheng Zhu,Yirui Wang,Yang Wang,Yukun Zhou,Boyuan Wang,Chaojun Ni,Runqi Ouyang,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang*

Main category: cs.AI

TL;DR: EMMA是一个VLA策略增强框架，通过生成式数据引擎和AdaMix训练策略，利用DreamTransfer生成多视角一致、几何基础的具身操作视频，提升了机器人在视觉领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 收集大规模真实世界机器人操作数据成本高昂，阻碍了VLA模型的泛化能力。

Method: 提出EMMA框架，包含DreamTransfer（用于生成多视角一致、几何基础的具身操作视频）和AdaMix（一种关注困难样本的动态重训练策略）。

Result: DreamTransfer生成的视频在多视角一致性、几何保真度和文本条件准确性方面优于现有方法。在零样本视觉领域，使用生成数据训练的VLA模型比单独使用真实数据训练的模型性能提升超过200%，结合AdaMix进一步提升13%。

Conclusion: EMMA框架通过生成式数据引擎和AdaMix训练策略，能有效提升VLA模型在机器人操作任务中的泛化能力，尤其是在面对未见过的物体类别和新视觉领域时。

Abstract: Vision-language-action (VLA) models increasingly rely on diverse training
data to achieve robust generalization. However, collecting large-scale
real-world robot manipulation data across varied object appearances and
environmental conditions remains prohibitively time-consuming and expensive. To
overcome this bottleneck, we propose Embodied Manipulation Media Adaptation
(EMMA), a VLA policy enhancement framework that integrates a generative data
engine with an effective training pipeline. We introduce DreamTransfer, a
diffusion Transformer-based framework for generating multi-view consistent,
geometrically grounded embodied manipulation videos. DreamTransfer enables
text-controlled visual editing of robot videos, transforming foreground,
background, and lighting conditions without compromising 3D structure or
geometrical plausibility. Furthermore, we explore hybrid training with real and
generated data, and introduce AdaMix, a hard-sample-aware training strategy
that dynamically reweights training batches to focus optimization on
perceptually or kinematically challenging samples. Extensive experiments show
that videos generated by DreamTransfer significantly outperform prior video
generation methods in multi-view consistency, geometric fidelity, and
text-conditioning accuracy. Crucially, VLAs trained with generated data enable
robots to generalize to unseen object categories and novel visual domains using
only demonstrations from a single appearance. In real-world robotic
manipulation tasks with zero-shot visual domains, our approach achieves over a
200% relative performance gain compared to training on real data alone, and
further improves by 13% with AdaMix, demonstrating its effectiveness in
boosting policy generalization.

</details>


### [496] [GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation](https://arxiv.org/abs/2509.22460)
*Shichao Weng,Zhiqiang Wang,Yuhua Zhou,Rui Lu,Ting Liu,Zhiyang Teng,Xiaozhang Liu,Hanmeng Liu*

Main category: cs.AI

TL;DR: GeoSketch是一个神经符号框架，通过交互式感知-推理-行动循环来解决几何问题，它能够动态操作和推理，解决了现有模型处理静态图像的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有用于几何问题解决的多模态大语言模型（MLLMs）将图表视为静态图像，缺乏人类几何推理中动态操作（如辅助线绘制、仿射变换）的能力。

Method: GeoSketch框架包含三个模块：1. 感知模块：将图表解析为结构化逻辑形式。2. 符号推理模块：应用几何定理进行演绎推理。3. 草图动作模块：执行绘图或变换操作，形成闭环更新。训练过程采用两阶段方法：首先在2000个符号化轨迹上进行监督微调，然后通过带有密集符号奖励的强化学习进行优化。

Result: GeoSketch基准测试集包含390个需要辅助线构建或仿射变换的高质量几何问题。实验结果表明，GeoSketch在逐步推理准确性和问题解决成功率方面显著优于基于静态感知的模型。

Conclusion: GeoSketch通过整合分层决策、可执行视觉动作和符号验证，将多模态推理从静态解释提升到动态、可验证的交互，为解决复杂空间视觉问题奠定了新基础。

Abstract: Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large
Language Models (MLLMs), requiring not only the joint interpretation of text
and diagrams but also iterative visuospatial reasoning. While existing
approaches process diagrams as static images, they lack the capacity for
dynamic manipulation - a core aspect of human geometric reasoning involving
auxiliary line construction and affine transformations. We present GeoSketch, a
neural-symbolic framework that recasts geometric reasoning as an interactive
perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module
that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning
module that applies geometric theorems to decide the next deductive step, and
(3) a Sketch Action module that executes operations such as drawing auxiliary
lines or applying transformations, thereby updating the diagram in a closed
loop. To train this agent, we develop a two-stage pipeline: supervised
fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement
learning with dense, symbolic rewards to enhance robustness and strategic
exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a
high-quality set of 390 geometry problems requiring auxiliary construction or
affine transformations. Experiments on strong MLLM baselines demonstrate that
GeoSketch significantly improves stepwise reasoning accuracy and
problem-solving success over static perception methods. By unifying
hierarchical decision-making, executable visual actions, and symbolic
verification, GeoSketch advances multimodal reasoning from static
interpretation to dynamic, verifiable interaction, establishing a new
foundation for solving complex visuospatial problems.

</details>


### [497] [InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios](https://arxiv.org/abs/2509.22502)
*Chenglin Yu,Yang Yu,Songmiao Wang,Yucheng Wang,Yifan Yang,Jinjia Li,Ming Li,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAgent是一个金字塔状的DAG多智能体框架，通过“智能体即工具”机制、双重审计、路由和自进化来自动化LLM智能体开发，解决了手动设计LLM智能体的痛点，在多个基准测试中表现优于ADAS，并能生成获得人类评审认可的AI研究论文。


<details>
  <summary>Details</summary>
Motivation: 手动设计LLM智能体需要LLM技术和领域专业知识，并且受到精心设计的流程、提示和迭代调优的限制，这阻碍了LLM智能体在各行业的扩展性和成本效益。

Method: InfiAgent采用金字塔状的DAG基础，引入了通用的“智能体即工具”机制，将复杂的智能体分解为分层的多智能体系统。它还包括一个双重审计机制，一个智能体路由功能，以及一个允许自主重构智能体DAG的智能体自进化机制。此外，其原子任务设计支持智能体并行化。

Result: InfiAgent在多个基准测试中的表现比ADAS（一个类似的全自动生成智能体框架）高出9.9%。AI研究助手InfiHelper的案例研究表明，它生成的科学论文获得了顶级IEEE会议上人类审稿人的认可。

Conclusion: InfiAgent通过其创新的多智能体框架，有效解决了LLM智能体开发中的可扩展性和成本效益问题，并在性能和实际应用（如AI研究助手）方面取得了显著成果。

Abstract: Large Language Model (LLM) agents have demonstrated remarkable capabilities
in organizing and executing complex tasks, and many such agents are now widely
used in various application scenarios. However, developing these agents
requires carefully designed workflows, carefully crafted prompts, and iterative
tuning, which requires LLM techniques and domain-specific expertise. These
hand-crafted limitations hinder the scalability and cost-effectiveness of LLM
agents across a wide range of industries. To address these challenges, we
propose \textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that
can be applied to \textbf{infi}nite scenarios, which introduces several key
innovations: a generalized "agent-as-a-tool" mechanism that automatically
decomposes complex agents into hierarchical multi-agent systems; a dual-audit
mechanism that ensures the quality and stability of task completion; an agent
routing function that enables efficient task-agent matching; and an agent
self-evolution mechanism that autonomously restructures the agent DAG based on
new tasks, poor performance, or optimization opportunities. Furthermore,
InfiAgent's atomic task design supports agent parallelism, significantly
improving execution efficiency. This framework evolves into a versatile
pyramid-like multi-agent system capable of solving a wide range of problems.
Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9\%
higher performance compared to ADAS (similar auto-generated agent framework),
while a case study of the AI research assistant InfiHelper shows that it
generates scientific papers that have received recognition from human reviewers
at top-tier IEEE conferences.

</details>


### [498] [Estimating the Empowerment of Language Model Agents](https://arxiv.org/abs/2509.22504)
*Jinyeop Song,Jeff Gore,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 提出了一种基于信息论的评估 LM 代理能力的新方法，称为 EELMA，它通过衡量代理行为与未来状态之间的相互信息来评估代理的“赋权”能力，并证明了其在各种场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于基准的评估方法成本高昂且需要人工设计任务，而信息论评估提供了一种开放式、可扩展的方法来评估 LM 代理的能力。

Method: 提出 EELMA 算法，通过多轮文本交互来近似语言模型代理的有效赋权能力。

Result: 赋权能力与平均任务性能高度相关，并分析了环境复杂度、链式思考、模型规模和记忆长度等因素对赋权能力的影响。高赋权状态和行为通常是通用能力的枢纽时刻。

Conclusion: 赋权能力作为一种有吸引力的通用指标，可用于评估和监控复杂、开放式环境中的 LM 代理。

Abstract: As language model (LM) agents become more capable and gain broader access to
real-world tools, there is a growing need for scalable evaluation frameworks of
agentic capability. However, conventional benchmark-centric evaluations are
costly to design and require human designers to come up with valid tasks that
translate into insights about general model capabilities. In this work, we
propose information-theoretic evaluation based on empowerment, the mutual
information between an agent's actions and future states, as an open-ended
method for evaluating LM agents. We introduce EELMA (Estimating Empowerment of
Language Model Agents), an algorithm for approximating effective empowerment
from multi-turn text interactions. We validate EELMA on both language games and
scaled-up realistic web-browsing scenarios. We find that empowerment strongly
correlates with average task performance, characterize the impact of
environmental complexity and agentic factors such as chain-of-thought, model
scale, and memory length on estimated empowerment, and that high empowerment
states and actions are often pivotal moments for general capabilities.
Together, these results demonstrate empowerment as an appealing general-purpose
metric for evaluating and monitoring LM agents in complex, open-ended settings.

</details>


### [499] [TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments](https://arxiv.org/abs/2509.22516)
*Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla*

Main category: cs.AI

TL;DR: TrueGradeAI是一个AI驱动的数字考试框架，通过手写识别和检索增强的LLM评估来克服传统考试的缺点，并提供可解释、可审计的评分。


<details>
  <summary>Details</summary>
Motivation: 传统纸质考试存在过度用纸、物流复杂、评分延迟和评估者偏见等缺点，TrueGradeAI旨在解决这些问题。

Method: 该系统使用安全平板电脑捕捉手写笔输入，并应用基于Transformer的光学字符识别进行转录。评估通过一个检索增强的管道进行，该管道整合了教师解决方案、缓存层和外部参考，使大型语言模型能够分配带有明确的、与证据相关联的推理的分数。

Result: TrueGradeAI通过整合可解释的自动化、偏见缓解和可审计的评分轨迹，超越了以前的基于平板电脑的考试系统。它通过统一手写保存和可扩展、透明的评估，减少了环境成本，加速了反馈周期，并逐步建立了可重用的知识库。

Conclusion: TrueGradeAI通过结合手写保存、可扩展和透明的评估，解决了传统考试的不足，同时减轻了评分偏见并确保了评估的公平性。

Abstract: This paper introduces TrueGradeAI, an AI-driven digital examination framework
designed to overcome the shortcomings of traditional paper-based assessments,
including excessive paper usage, logistical complexity, grading delays, and
evaluator bias. The system preserves natural handwriting by capturing stylus
input on secure tablets and applying transformer-based optical character
recognition for transcription. Evaluation is conducted through a
retrieval-augmented pipeline that integrates faculty solutions, cache layers,
and external references, enabling a large language model to assign scores with
explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems
that primarily digitize responses, TrueGradeAI advances the field by
incorporating explainable automation, bias mitigation, and auditable grading
trails. By uniting handwriting preservation with scalable and transparent
evaluation, the framework reduces environmental costs, accelerates feedback
cycles, and progressively builds a reusable knowledge base, while actively
working to mitigate grading bias and ensure fairness in assessment.

</details>


### [500] [REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model](https://arxiv.org/abs/2509.22518)
*Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen*

Main category: cs.AI

TL;DR: LLMs的复杂推理和失败机制可以通过定义“推理流形”的概念来解释，这是一个由正确推理形成的潜在低维几何结构。REMA框架通过量化错误和正确推理样本的内部表示之间的空间关系来分析失败的起源，识别推理链开始偏离的节点。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）如何进行复杂推理及其失败机制是可解释性研究中的一个挑战。

Method: 定义“推理流形”的概念，这是一个潜在的低维几何结构，由与所有正确推理生成相对应的内部表示形成。基于此概念，构建REMA框架，通过量化计算错误和正确推理样本的内部模型表示的空间关系来解释失败的起源。REMA首先通过计算每个错误表示与由正确表示近似形成的流形的k最近邻距离来量化其几何偏差，从而提供一个统一的失败信号。然后，通过跨模型层跟踪此偏差度量并将其与正确表示的内部波动基线进行比较，来定位这些偏差首次变得显著的发散点，从而识别推理链开始偏离的节点。

Result: 实验证明了推理流形的低维性质以及错误和正确推理表示之间的高度可分离性。结果还验证了REMA框架在分析推理失败起源方面的有效性。

Conclusion: 该研究将抽象推理失败与表示中的可测量几何偏差联系起来，为深入理解和诊断黑盒模型的内部计算过程提供了新的途径。

Abstract: Understanding how Large Language Models (LLMs) perform complex reasoning and
their failure mechanisms is a challenge in interpretability research. To
provide a measurable geometric analysis perspective, we define the concept of
the Reasoning Manifold, a latent low-dimensional geometric structure formed by
the internal representations corresponding to all correctly reasoned
generations. This structure can be conceptualized as the embodiment of the
effective thinking paths that the model has learned to successfully solve a
given task. Based on this concept, we build REMA, a framework that explains the
origins of failures by quantitatively comparing the spatial relationships of
internal model representations corresponding to both erroneous and correct
reasoning samples. Specifically, REMA first quantifies the geometric deviation
of each erroneous representation by calculating its k-nearest neighbors
distance to the approximated manifold formed by correct representations,
thereby providing a unified failure signal. It then localizes the divergence
points where these deviations first become significant by tracking this
deviation metric across the model's layers and comparing it against a baseline
of internal fluctuations from correct representations, thus identifying where
the reasoning chain begins to go off-track. Our extensive experiments on
diverse language and multimodal models and tasks demonstrate the
low-dimensional nature of the reasoning manifold and the high separability
between erroneous and correct reasoning representations. The results also
validate the effectiveness of the REMA framework in analyzing the origins of
reasoning failures. This research connects abstract reasoning failures to
measurable geometric deviations in representations, providing new avenues for
in-depth understanding and diagnosis of the internal computational processes of
black-box models.

</details>


### [501] [The Emergence of Altruism in Large-Language-Model Agents Society](https://arxiv.org/abs/2509.22537)
*Haoyang Li,Xiao Jia,Zhanzhan Zhao*

Main category: cs.AI

TL;DR: LLM在社会模拟中展现出两种不同原型：自利但受社会规范影响的“适应性自我主义者”和持续优先考虑集体利益的“利他主义优化者”。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注小规模、任务导向型博弈中的合作，忽略了利他主义（牺牲个人利益以获得集体利益）在大规模代理社会中的出现。

Method: 构建了一个包含200多个LLM代理的谢林变种城市迁移模型，制造了一个个人效用（利己）和系统效用（利他）之间的社会困境。采用受扎根理论启发的编码方法来分析代理决策的认知基础。

Result: 发现了LLM社会倾向的两种原型：“适应性自我主义者”（优先考虑自身利益，但在社会规范信息板的影响下利他行为显著增加）和“利他主义优化者”（始终优先考虑集体利益，即使牺牲自身利益）。

Conclusion: LLM在利己和利他倾向方面存在内在异质性。模型选择不仅关乎推理能力，还关乎内在的社会行动逻辑。“适应性自我主义者”更适合模拟复杂人类社会，“利他主义优化者”更适合模拟理想化的亲社会行为者或以集体福利为主要考虑的场景。

Abstract: Leveraging Large Language Models (LLMs) for social simulation is a frontier
in computational social science. Understanding the social logics these agents
embody is critical to this attempt. However, existing research has primarily
focused on cooperation in small-scale, task-oriented games, overlooking how
altruism, which means sacrificing self-interest for collective benefit, emerges
in large-scale agent societies. To address this gap, we introduce a
Schelling-variant urban migration model that creates a social dilemma,
compelling over 200 LLM agents to navigate an explicit conflict between
egoistic (personal utility) and altruistic (system utility) goals. Our central
finding is a fundamental difference in the social tendencies of LLMs. We
identify two distinct archetypes: "Adaptive Egoists", which default to
prioritizing self-interest but whose altruistic behaviors significantly
increase under the influence of a social norm-setting message board; and
"Altruistic Optimizers", which exhibit an inherent altruistic logic,
consistently prioritizing collective benefit even at a direct cost to
themselves. Furthermore, to qualitatively analyze the cognitive underpinnings
of these decisions, we introduce a method inspired by Grounded Theory to
systematically code agent reasoning. In summary, this research provides the
first evidence of intrinsic heterogeneity in the egoistic and altruistic
tendencies of different LLMs. We propose that for social simulation, model
selection is not merely a matter of choosing reasoning capability, but of
choosing an intrinsic social action logic. While "Adaptive Egoists" may offer a
more suitable choice for simulating complex human societies, "Altruistic
Optimizers" are better suited for modeling idealized pro-social actors or
scenarios where collective welfare is the primary consideration.

</details>


### [502] [StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models](https://arxiv.org/abs/2509.22558)
*Chenyu Zhou,Tianyi Xu,Jianghao Lin,Dongdong Ge*

Main category: cs.AI

TL;DR: StepORLM是一个新颖的自进化框架，通过生成过程监督来解决大型语言模型（LLM）在运筹学（OR）问题上的训练局限性，解决了信用分配问题和过程评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在OR问题上的训练方法存在信用分配问题（结果奖励会强化错误的推理）和过程评估短视（无法全面评估OR建模的相互依赖步骤）的局限性。

Method: StepORLM采用一个策略模型和一个生成过程奖励模型（GenPRM）的协同进化循环，通过外部求解器的结果验证和GenPRM的内部过程评估的双重反馈机制进行驱动。该信号用于通过加权直接偏好优化（W-DPO）来对齐策略模型并同时优化GenPRM。

Result: 8B参数的StepORLM模型在六个基准测试中均取得了新的最先进成果，显著优于规模大得多的通用模型、智能体方法和专用基线模型。此外，协同进化的GenPRM可以作为强大的、通用的过程验证器，显著提升了StepORLM和其他现有LLM的推理扩展性能。

Conclusion: StepORLM通过生成过程监督解决了LLM在OR问题上的训练挑战，并在性能和泛化能力上取得了显著突破。

Abstract: Large Language Models (LLMs) have shown promising capabilities for solving
Operations Research (OR) problems. While reinforcement learning serves as a
powerful paradigm for LLM training on OR problems, existing works generally
face two key limitations. First, outcome reward suffers from the credit
assignment problem, where correct final answers can reinforce flawed reasoning.
Second, conventional discriminative process supervision is myopic, failing to
evaluate the interdependent steps of OR modeling holistically. To this end, we
introduce StepORLM, a novel self-evolving framework with generative process
supervision. At its core, StepORLM features a co-evolutionary loop where a
policy model and a generative process reward model (GenPRM) iteratively improve
on each other. This loop is driven by a dual-feedback mechanism: definitive,
outcome-based verification from an external solver, and nuanced, holistic
process evaluation from the GenPRM. The combined signal is used to align the
policy via Weighted Direct Preference Optimization (W-DPO) and simultaneously
refine the GenPRM. Our resulting 8B-parameter StepORLM establishes a new
state-of-the-art across six benchmarks, significantly outperforming vastly
larger generalist models, agentic methods, and specialized baselines. Moreover,
the co-evolved GenPRM is able to act as a powerful and universally applicable
process verifier, substantially boosting the inference scaling performance of
both our own model and other existing LLMs.

</details>


### [503] [UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration](https://arxiv.org/abs/2509.22570)
*Qi Mao,Tinghan Yang,Jiahao Li,Bin Li,Libiao Jin,Yan Lu*

Main category: cs.AI

TL;DR: UniMIC是一个统一的、基于令牌的、多模态交互式编码框架，用于在边缘设备和云AI代理之间进行高效通信，使用令牌化表示而不是原始像素或纯文本，并采用基于Transformer的熵模型来进一步压缩，实现了显著的比特率节省，同时保持下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的编解码器针对单模态、单向通信进行了优化，在传统的压缩-传输-重建流程中会导致重复的性能下降。为了解决这个限制，需要一种新的方法来支持双向、多模态的交互。

Method: UniMIC框架使用紧凑的令牌化表示作为通信媒介，并结合轻量级的、基于Transformer的、具有场景特定设计的熵模型（通用、掩码和文本条件）来进一步压缩。

Result: 在文本到图像生成、文本引导修复、外绘和视觉问答等任务上，UniMIC在超低比特率（<0.05bpp）下实现了显著的比特率节省，并且在不影响下游任务性能的情况下保持了鲁棒性。

Conclusion: UniMIC提供了一种实用且具有前瞻性的范式，用于下一代多模态交互式通信。

Abstract: The rapid progress of Large Multimodal Models (LMMs) and cloud-based AI
agents is transforming human-AI collaboration into bidirectional, multimodal
interaction. However, existing codecs remain optimized for unimodal, one-way
communication, resulting in repeated degradation under conventional
compress-transmit-reconstruct pipelines. To address this limitation, we propose
UniMIC, a Unified token-based Multimodal Interactive Coding framework that
bridges edge devices and cloud AI agents. Instead of transmitting raw pixels or
plain text, UniMIC employs compact tokenized representations as the
communication medium, enabling efficient low-bitrate transmission while
maintaining compatibility with LMMs. To further enhance compression,
lightweight Transformer-based entropy models with scenario-specific
designs-generic, masked, and text-conditioned-effectively minimize inter-token
redundancy. Extensive experiments on text-to-image generation, text-guided
inpainting, outpainting, and visual question answering show that UniMIC
achieves substantial bitrate savings and remains robust even at ultra-low
bitrates (<0.05bpp), without compromising downstream task performance. These
results establish UniMIC as a practical and forward-looking paradigm for
next-generation multimodal interactive communication.

</details>


### [504] [Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time](https://arxiv.org/abs/2509.22572)
*Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang*

Main category: cs.AI

TL;DR: 通过动态调整Mixture-of-Experts（MoE）模型的激活专家数量，提出了一种名为Dynamic Experts Search（DES）的测试时（Test-Time）计算扩展（TTS）方法，以提升大型语言模型（LLMs）的推理能力，并在不增加额外计算成本的情况下提高了准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时计算扩展（TTS）方法主要依赖于输出层采样，忽略了模型架构（特别是Mixture-of-Experts（MoE）模型）在提供多样性方面的潜力。在MoE模型中，激活不同数量的专家可以产生互补的解决方案集，这提供了一个新的、未被充分利用的多样性来源。

Method: 提出了一种名为Dynamic Experts Search（DES）的TTS策略。DES包含两个关键组件：1. 动态MoE（Dynamic MoE），它允许在推理过程中直接控制激活的专家数量，从而在不产生额外成本的情况下生成多样化的推理轨迹。2. 专家配置继承（Expert Configuration Inheritance），它在推理路径内保持专家数量的一致性，同时在不同运行之间改变专家数量，从而在整个搜索过程中平衡稳定性和多样性。

Result: 在多个MoE架构、验证器和推理基准（数学、代码和知识）上的广泛实验表明，DES可靠地优于现有的TTS基线，在不增加额外成本的情况下提高了准确性和稳定性。

Conclusion: DES是一种实用且可扩展的、感知架构的TTS方法，它展示了现代LLM中的结构灵活性如何能够促进推理能力的提升。

Abstract: Test-Time Scaling (TTS) enhances the reasoning ability of large language
models (LLMs) by allocating additional computation during inference. However,
existing approaches primarily rely on output-level sampling while overlooking
the role of model architecture. In mainstream Mixture-of-Experts (MoE) LLMs, we
observe that varying the number of activated experts yields complementary
solution sets with stable accuracy, revealing a new and underexplored source of
diversity. Motivated by this observation, we propose Dynamic Experts Search
(DES), a TTS strategy that elevates expert activation into a controllable
dimension of the search space. DES integrates two key components: (1) Dynamic
MoE, which enables direct control of expert counts during inference to generate
diverse reasoning trajectories without additional cost; and (2) Expert
Configuration Inheritance, which preserves consistent expert counts within a
reasoning path while varying them across runs, thereby balancing stability and
diversity throughout the search. Extensive experiments across MoE
architectures, verifiers and reasoning benchmarks (i.e., math, code and
knowledge) demonstrate that DES reliably outperforms TTS baselines, enhancing
accuracy and stability without additional cost. These results highlight DES as
a practical and scalable form of architecture-aware TTS, illustrating how
structural flexibility in modern LLMs can advance reasoning.

</details>


### [505] [Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective](https://arxiv.org/abs/2509.22613)
*Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen*

Main category: cs.AI

TL;DR: RL通过探索克服SFT的伪解决方案，但PG可能导致多样性崩溃，而Q-learning可以实现多样性保留，尽管需要仔细的奖励设计。


<details>
  <summary>Details</summary>
Motivation: 理解RL方法在增强LLM规划能力方面的理论基础，包括其优势和局限性。

Method: 使用基于图的抽象来分析策略梯度（PG）和Q-learning方法，并通过Blocksworld基准进行实际验证。

Result: SFT可能引入基于共现的伪解决方案；RL通过探索实现正确规划；PG可能导致多样性崩溃；Q-learning具有离策略学习和收敛时多样性保留的优点，但需要仔细的奖励设计以防止奖励破解。

Conclusion: 探索是RL能够实现更好泛化的关键；Q-learning在多样性保留方面优于PG，但需要谨慎的奖励设计；理论发现与Blocksworld上的实际行为一致。

Abstract: Recent reinforcement learning (RL) methods have substantially enhanced the
planning capabilities of Large Language Models (LLMs), yet the theoretical
basis for their effectiveness remains elusive. In this work, we investigate
RL's benefits and limitations through a tractable graph-based abstraction,
focusing on policy gradient (PG) and Q-learning methods. Our theoretical
analyses reveal that supervised fine-tuning (SFT) may introduce
co-occurrence-based spurious solutions, whereas RL achieves correct planning
primarily through exploration, underscoring exploration's role in enabling
better generalization. However, we also show that PG suffers from diversity
collapse, where output diversity decreases during training and persists even
after perfect accuracy is attained. By contrast, Q-learning provides two key
advantages: off-policy learning and diversity preservation at convergence. We
further demonstrate that careful reward design is necessary to prevent reward
hacking in Q-learning. Finally, applying our framework to the real-world
planning benchmark Blocksworld, we confirm that these behaviors manifest in
practice.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [506] [Bacterial Gene Regulatory Neural Network as a Biocomputing Library of Mathematical Solvers](https://arxiv.org/abs/2509.21598)
*Adrian Ratwatte,Samitha Somathilaka,Thanh Cao,Xu Li,Sasitharan Balasubramaniam*

Main category: cs.ET

TL;DR: 本研究利用GRNN框架将细菌基因表达动力学转化为数学计算和分类任务的生物计算库，并通过子GRNN搜索算法识别功能性子网络，同时评估其稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的生物计算方法依赖于固定逻辑的工程电路，在不同环境条件下稳定性和可靠性有限。

Method: 使用GRNN框架将细菌基因表达动力学转化为数学求解器库，并引入子GRNN搜索算法，通过评估化学编码输入条件下的基因表达模式来识别功能性子网络，以执行数学计算和分类任务。通过基因层面和集体扰动以及基于李雅普诺夫的稳定性分析来评估所识别子GRNN的鲁棒性和可靠性。

Result: 本研究成功利用细菌的天然转录机制执行了多种数学计算和分类任务，包括识别斐波那契数、素数、乘法和计算科拉兹猜想的步数。

Conclusion: 本研究表明，细菌的天然转录机制可以被用来执行各种数学计算和分类任务，同时保持计算的稳定性和可靠性。

Abstract: Current biocomputing approaches predominantly rely on engineered circuits
with fixed logic, offering limited stability and reliability under diverse
environmental conditions. Here, we use the GRNN framework introduced in our
previous work to transform bacterial gene expression dynamics into a
biocomputing library of mathematical solvers. We introduce a sub-GRNN search
algorithm that identifies functional subnetworks tailored to specific
mathematical calculation and classification tasks by evaluating gene expression
patterns across chemically encoded input conditions. Tasks include identifying
Fibonacci numbers, prime numbers, multiplication, and Collatz step counts. The
identified problem-specific sub-GRNNs are then assessed using gene-wise and
collective perturbation, as well as Lyapunov-based stability analysis, to
evaluate robustness and reliability. Our results demonstrate that native
transcriptional machinery can be harnessed to perform diverse mathematical
calculation and classification tasks, while maintaining computing stability and
reliability.

</details>


### [507] [QMill: Representative Quantum Data Generation for Quantum Machine Learning Utility](https://arxiv.org/abs/2509.21622)
*Jason Ludmir,Ian Martin,Nicholas S. DiBrita,Daniel Leeds,Tirthak Patel*

Main category: cs.ET

TL;DR: QMill是一个低深度量子数据生成框架，可生成纠缠的、高质量的样本，模拟各种经典和量子分布，从而在代表性数据设置中更有效地开发和评估QML模型。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据生成方法未能捕捉到纠缠的本质属性，限制了它们在QML中的效用。

Method: 提出了一种名为QMill的低深度量子数据生成框架。

Result: QMill能够生成纠缠的、高质量的样本，并能模拟各种经典和量子分布。

Conclusion: QMill为在代表性数据设置中更有效地开发和评估QML模型提供了解决方案。

Abstract: Quantum machine learning (QML) promises significant speedups, particularly
when operating on quantum datasets. However, its progress is hindered by the
scarcity of suitable training data. Existing synthetic data generation methods
fall short in capturing essential entanglement properties, limiting their
utility for QML. To address this, we introduce QMill, a low-depth quantum data
generation framework that produces entangled, high-quality samples emulating
diverse classical and quantum distributions, enabling more effective
development and evaluation of QML models in representative-data settings.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [508] [Breaking $1/ε$ Barrier in Quantum Zero-Sum Games: Generalizing Metric Subregularity for Spectraplexes](https://arxiv.org/abs/2509.21570)
*Yiheng Su,Emmanouil-Vasileios Vlatakis-Gkaragkounis,Pucheng Xiong*

Main category: cs.GT

TL;DR: 量子零和博弈的收敛速度问题得到了解决，证明了量子博弈可以达到与经典博弈相同的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 研究量子零和博弈的收敛速度问题，探讨其与经典博弈的性能差距。

Method: 应用Nesterov的迭代平滑法（IterSmooth）和乐观梯度下降-上升法（OGDA）来分析量子零和博弈的收敛性。

Result: 证明了IterSmooth和OGDA在量子零和博弈中具有线性收敛速度，与经典多面体博弈相当。

Conclusion: 量子博弈与经典博弈之间不存在根本性的性能差距，并且所提出的方法在某些情况下可以提供指数级的加速。

Abstract: Long studied as a toy model, quantum zero-sum games have recently resurfaced
as a canonical playground for modern areas such as non-local games, quantum
interactive proofs, and quantum machine learning. In this simple yet
fundamental setting, two competing quantum players send iteratively mixed
quantum states to a referee, who performs a joint measurement to determine
their payoffs. In 2025, Vasconcelos et al. [arXiv:2311.10859] connected quantum
communication channels with a hierarchy of quantum optimization algorithms that
generalize Matrix Multiplicative Weights Update ($\texttt{MMWU}$) through
extra-gradient mechanisms, establishing an average-iterate convergence rate of
$\mathcal{O}(1/\epsilon)$ iterations to $\epsilon$-Nash equilibria. While a
long line of work has shown that bilinear games over polyhedral domains admit
gradient methods with linear last-iterate convergence rates of
$\mathcal{O}(\log(1/\epsilon))$, it has been conjectured that a fundamental
performance gap must persist between quantum feasible sets (spectraplexes) and
classical polyhedral sets (simplices). We resolve this conjecture in the
negative. We prove that matrix variants of $\textit{Nesterov's iterative
smoothing}$ ($\texttt{IterSmooth}$) and $\textit{Optimistic Gradient
Descent-Ascent}$ ($\texttt{OGDA}$) achieve last-iterate convergence at a linear
rate in quantum zero-sum games, thereby matching the classical polyhedral case.
Our analysis relies on a new generalization of error bounds in semidefinite
programming geometry, establishing that (SP-MS) holds for monotone operators
over spectrahedra, despite their uncountably many extreme points. Finally, as a
byproduct, we obtain an exponential speed-up over the classical Jain-Watrous
[arXiv:0808.2775] method for parallel approximation of strictly positive
semidefinite programs.

</details>


### [509] [Incentives in Federated Learning with Heterogeneous Agents](https://arxiv.org/abs/2509.21612)
*Ariel D. Procaccia,Han Shao,Itai Shapira*

Main category: cs.GT

TL;DR: 在联邦学习中，由于数据异质性，参与者可能缺乏动力进行合作。本文提出了一种基于博弈论的框架，用于分析激励不一致性问题，并设计了一种包含成本的机制，以促进合作。


<details>
  <summary>Details</summary>
Motivation: 激励不一致性阻碍了联邦学习中跨多个代理的数据整合，因为每个更新都会给贡献者带来成本，但会使每个参与者受益。

Method: 提出了一种基于博弈论的框架，该框架考虑了代理的效用函数，该函数取决于样本的来源，而不仅仅是样本的数量。分析了无协调博弈的病态，并证明了计算成本最小化贡献向量是NP难的。推导了一个多项式时间的线性规划，可以实现对最优解的对数近似。

Result: 证明了在无协调博弈中，纯策略均衡可能不存在，并且最佳均衡可能比合作的成本高出任意倍。提出的线性规划算法可以对最优解进行对数近似。所提出的“按贡献支付”机制是策略证明的。

Conclusion: 所提出的博弈论框架能够捕捉联邦学习中的激励不一致性问题，并且提出的机制能够实现策略证明和近似最优成本。

Abstract: Federated learning promises significant sample-efficiency gains by pooling
data across multiple agents, yet incentive misalignment is an obstacle: each
update is costly to the contributor but boosts every participant. We introduce
a game-theoretic framework that captures heterogeneous data: an agent's utility
depends on who supplies each sample, not just how many. Agents aim to meet a
PAC-style accuracy threshold at minimal personal cost. We show that
uncoordinated play yields pathologies: pure equilibria may not exist, and the
best equilibrium can be arbitrarily more costly than cooperation. To steer
collaboration, we analyze the cost-minimizing contribution vector, prove that
computing it is NP-hard, and derive a polynomial-time linear program that
achieves a logarithmic approximation. Finally, pairing the LP with a simple
pay-what-you-contribute rule - each agent receives a payment equal to its
sample cost - yields a mechanism that is strategyproof and, within the class of
contribution-based transfers, is unique.

</details>


### [510] [Nearly Tight Regret Bounds for Profit Maximization in Bilateral Trade](https://arxiv.org/abs/2509.22563)
*Simone Di Gregorio,Paul Dütting,Federico Fusco,Chris Schwiegelshohn*

Main category: cs.GT

TL;DR: 该论文研究了双边贸易中的中介问题，并提出了一种基于遗憾最小化框架的在线学习算法，以最大化经纪人的利润。


<details>
  <summary>Details</summary>
Motivation: 在双边贸易模型中，经纪人需要在两个策略性代理（卖方和买方）之间进行中介，他们拥有私人估值，并愿意交易某商品。经纪人的目标是在满足激励兼容和个体理性约束的条件下最大化利润。

Method: 提出了一种学习算法，在随机设置下保证了近乎最优的$	ilde{O}(	ext{T}^{rac{1}{2}})$遗憾界。证明了在非平稳场景下无法实现次线性遗憾。算法的基准是最佳激励兼容和个体理性机制，这与仅以最佳固定价格作为基准的先前工作不同。

Result: 在随机设置下，所提出的学习算法实现了近乎最优的遗憾界。在非平稳场景下，证明了无法实现次线性遗憾。该技术也被应用于联合广告问题，并取得了近乎最优的结果。

Conclusion: 该研究成功地为双边贸易中的经纪人中介问题设计了一种具有近乎最优遗憾界的学习算法，并在随机和非平稳场景下进行了分析。所提出的方法论在联合广告等相关问题中也具有广泛的应用前景。

Abstract: Bilateral trade models the task of intermediating between two strategic
agents, a seller and a buyer, willing to trade a good for which they hold
private valuations. We study this problem from the perspective of a broker, in
a regret minimization framework. At each time step, a new seller and buyer
arrive, and the broker has to propose a mechanism that is incentive-compatible
and individually rational, with the goal of maximizing profit.
  We propose a learning algorithm that guarantees a nearly tight
$\tilde{O}(\sqrt{T})$ regret in the stochastic setting when seller and buyer
valuations are drawn i.i.d. from a fixed and possibly correlated unknown
distribution. We further show that it is impossible to achieve sublinear regret
in the non-stationary scenario where valuations are generated upfront by an
adversary. Our ambitious benchmark for these results is the best
incentive-compatible and individually rational mechanism. This separates us
from previous works on efficiency maximization in bilateral trade, where the
benchmark is a single number: the best fixed price in hindsight.
  A particular challenge we face is that uniform convergence for all
mechanisms' profits is impossible. We overcome this difficulty via a careful
chaining analysis that proves convergence for a provably near-optimal mechanism
at (essentially) optimal rate. We further showcase the broader applicability of
our techniques by providing nearly optimal results for the joint ads problem.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [511] [GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks](https://arxiv.org/abs/2509.21605)
*Tian Yu Yen,Reese E. Jones,Ravi G. Patel*

Main category: cs.LG

TL;DR: 本研究提出了一种名为GenUQ的无需似然函数即可进行不确定性量化（UQ）的方法，该方法使用生成式超网络模型来估计参数分布。


<details>
  <summary>Details</summary>
Motivation: 现有基于似然函数的不确定性量化方法难以处理随机算子产生的难以或不可能构建似然函数的情况。本研究旨在解决此问题。

Method: 提出了一种名为GenUQ的、基于测度理论的UQ方法，该方法引入了一个生成式超网络模型，用于生成与观测数据一致的参数分布，从而避免了构建似然函数。

Result: 在三个示例问题中，GenUQ均优于其他UQ方法，包括恢复制造算子、学习随机椭圆PDE的解算子以及模拟多孔钢在张力下的失效位置。

Conclusion: GenUQ作为一种无需似然函数即可进行不确定性量化的方法，在处理随机算子方面表现出优越性，并在多个问题中得到了验证。

Abstract: Operator learning is a recently developed generalization of regression to
mappings between functions. It promises to drastically reduce expensive
numerical integration of PDEs to fast evaluations of mappings between
functional states of a system, i.e., surrogate and reduced-order modeling.
Operator learning has already found applications in several areas such as
modeling sea ice, combustion, and atmospheric physics. Recent approaches
towards integrating uncertainty quantification into the operator models have
relied on likelihood based methods to infer parameter distributions from noisy
data. However, stochastic operators may yield actions from which a likelihood
is difficult or impossible to construct. In this paper, we introduce, GenUQ, a
measure-theoretic approach to UQ that avoids constructing a likelihood by
introducing a generative hyper-network model that produces parameter
distributions consistent with observed data. We demonstrate that GenUQ
outperforms other UQ methods in three example problems, recovering a
manufactured operator, learning the solution operator to a stochastic elliptic
PDE, and modeling the failure location of porous steel under tension.

</details>


### [512] [Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail](https://arxiv.org/abs/2509.21322)
*Anna Kalenkova,Lu Xia,Dirk Neumann*

Main category: cs.LG

TL;DR: 该研究提出了一种结合面向对象的过程挖掘（OCPM）和随机过程发现与分析的新方法，用于分析食品零售过程并减少食物浪费。


<details>
  <summary>Details</summary>
Motivation: 为了减少食品零售过程中的食物浪费，并找到顾客购买行为和供应策略之间的最佳平衡点。

Method: 首先，从超市销售数据中发现一个连续时间马尔可夫链形式的随机过程。然后，结合供应活动来扩展此模型。最后，进行“假设分析”以评估产品数量随时间的演变情况。

Result: 能够识别出最佳的顾客购买行为和供应策略之间的平衡点，从而防止因供应过剩造成的食物浪费和产品短缺。

Conclusion: 通过整合OCPM和随机过程分析，可以有效地分析食品零售过程，优化供应策略，从而显著减少食物浪费。

Abstract: This paper proposes a novel method for analyzing food retail processes with a
focus on reducing food waste. The approach integrates object-centric process
mining (OCPM) with stochastic process discovery and analysis. First, a
stochastic process in the form of a continuous-time Markov chain is discovered
from grocery store sales data. This model is then extended with supply
activities. Finally, a what-if analysis is conducted to evaluate how the
quantity of products in the store evolves over time. This enables the
identification of an optimal balance between customer purchasing behavior and
supply strategies, helping to prevent both food waste due to oversupply and
product shortages.

</details>


### [513] [Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics](https://arxiv.org/abs/2509.21393)
*Yi En Chou,Te Hsin Liu,Chao An Lin*

Main category: cs.LG

TL;DR: Physics Informed Neural Networks（PINNs）通过无网格框架解决了偏微分方程（PDE），但对损失权重选择敏感。本文提出了两种基于二维分析的加权方案：一种基于可量化项，另一种结合了不可量化项以实现更平衡的训练。在热传导、对流扩散和顶驱动腔流的基准测试中，第二种方案在稳定性和准确性方面持续优于等权重方案。特别是在传统求解器失败的高 Peclet 数对流扩散问题中，我们提出的 PINNs 方案实现了稳定、准确的预测，凸显了其在计算流体动力学（CFD）问题中的鲁棒性和通用性。


<details>
  <summary>Details</summary>
Motivation: PINNs 在求解偏微分方程（PDE）方面提供了无网格的解决方案，但其性能高度依赖于损失权重的选择。因此，有必要开发更有效的权重选择策略以提高 PINNs 的训练稳定性和准确性。

Method: 本文提出了一种基于二维分析的加权方案，包括一个仅考虑可量化项的方案和一个同时考虑可量化项和不可量化项的方案，以期实现更平衡的训练。通过在热传导、对流扩散和顶驱动腔流等问题上进行基准测试来评估所提出方案的有效性。

Result: 所提出的第二种加权方案（同时考虑可量化和不可量化项）在所有基准测试中均显示出比等权重方案更好的稳定性和准确性。在高 Peclet 数对流扩散问题中，尤其是在传统求解器失效的情况下，该方案能够实现稳定且准确的预测。

Conclusion: 本文提出的基于二维分析的加权方案，特别是结合了不可量化项的方案，能够显著提高 PINNs 训练的稳定性和准确性。该方法在高 Peclet 数对流扩散等具有挑战性的 CFD 问题中表现出优越的性能，证明了其鲁棒性和广泛的应用潜力。

Abstract: Physics Informed Neural Networks offer a mesh free framework for solving PDEs
but are highly sensitive to loss weight selection. We propose two dimensional
analysis based weighting schemes, one based on quantifiable terms, and another
also incorporating unquantifiable terms for more balanced training. Benchmarks
on heat conduction, convection diffusion, and lid driven cavity flows show that
the second scheme consistently improves stability and accuracy over equal
weighting. Notably, in high Peclet number convection diffusion, where
traditional solvers fail, PINNs with our scheme achieve stable, accurate
predictions, highlighting their robustness and generalizability in CFD
problems.

</details>


### [514] [LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?](https://arxiv.org/abs/2509.21403)
*Rushil Gupta,Jason Hartford,Bang Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have recently been proposed as general-purpose
agents for experimental design, with claims that they can perform in-context
experimental design. We evaluate this hypothesis using both open- and
closed-source instruction-tuned LLMs applied to genetic perturbation and
molecular property discovery tasks. We find that LLM-based agents show no
sensitivity to experimental feedback: replacing true outcomes with randomly
permuted labels has no impact on performance. Across benchmarks, classical
methods such as linear bandits and Gaussian process optimization consistently
outperform LLM agents. We further propose a simple hybrid method, LLM-guided
Nearest Neighbour (LLMNN) sampling, that combines LLM prior knowledge with
nearest-neighbor sampling to guide the design of experiments. LLMNN achieves
competitive or superior performance across domains without requiring
significant in-context adaptation. These results suggest that current open- and
closed-source LLMs do not perform in-context experimental design in practice
and highlight the need for hybrid frameworks that decouple prior-based
reasoning from batch acquisition with updated posteriors.

</details>


### [515] [SpinGPT: A Large-Language-Model Approach to Playing Poker Correctly](https://arxiv.org/abs/2509.22387)
*Narada Maugin,Tristan Cazenave*

Main category: cs.LG

TL;DR: CFR算法在扑克AI领域取得成功，但面临多玩家和锦标赛模式的局限性。SpinGPT作为首个针对三玩家Spin & Go格式的LLM，通过监督微调和强化学习训练，在78%的决策上与求解器一致，并在与Slumbot的对抗中表现出竞争力，预示LLM在多人不完美信息博弈中的潜力。


<details>
  <summary>Details</summary>
Motivation: CFR算法在多人和锦标赛扑克格式中存在局限性，而LLM在其他游戏中取得成功，因此需要一种新的方法来解决多人不完美信息博弈，特别是Spin & Go格式。

Method: SpinGPT采用两阶段训练：1. 对320k个高额桌专家决策进行监督微调；2. 对270k个求解器生成的牌局进行强化学习。

Result: SpinGPT在78%的决策中达到了与求解器相当的准确率（容忍精度）。在与Slumbot的1v1对抗中，采用简单深堆启发式策略，取得了13.4 +/- 12.9 BB/100的成绩（95%置信区间）。

Conclusion: LLM为解决像扑克这样的多人不完美信息博弈提供了一种新的有效途径。

Abstract: The Counterfactual Regret Minimization (CFR) algorithm and its variants have
enabled the development of pokerbots capable of beating the best human players
in heads-up (1v1) cash games and competing with them in six-player formats.
However, CFR's computational complexity rises exponentially with the number of
players. Furthermore, in games with three or more players, following Nash
equilibrium no longer guarantees a non-losing outcome. These limitations, along
with others, significantly restrict the applicability of CFR to the most
popular formats: tournaments. Motivated by the recent success of Large Language
Models (LLM) in chess and Diplomacy, we present SpinGPT, the first LLM tailored
to Spin & Go, a popular three-player online poker format. SpinGPT is trained in
two stages: (1) Supervised Fine-Tuning on 320k high-stakes expert decisions;
(2) Reinforcement Learning on 270k solver-generated hands. Our results show
that SpinGPT matches the solver's actions in 78% of decisions (tolerant
accuracy). With a simple deep-stack heuristic, it achieves 13.4 +/- 12.9 BB/100
versus Slumbot in heads-up over 30,000 hands (95% CI). These results suggest
that LLMs could be a new way to deal with multi-player imperfect-information
games like poker.

</details>


### [516] [Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification](https://arxiv.org/abs/2509.21405)
*Nyi Nyi Aung,Neil Muralles,Adrian Stein*

Main category: cs.LG

TL;DR: 通过物理信息残差神经网络结合学习和分类，解决了无人机应用中已知动力学下的目标识别问题。


<details>
  <summary>Details</summary>
Motivation: 在无人机应用中，需要识别目标，并且其动力学是已知的。

Method: 提出一个物理信息残差神经网络框架，用于状态映射和状态导数预测，并使用 softmax 层进行多类别置信度估计。案例研究包括四旋翼、固定翼和直升机等飞行器。

Result: 实现了高分类准确率和缩短的训练时间。

Conclusion: 该方法为动力学已知的系统识别问题提供了一种有前景的解决方案。

Abstract: This work addresses object identification under known dynamics in unmanned
aerial vehicle applications, where learning and classification are combined
through a physics-informed residual neural network. The proposed framework
leverages physics-informed learning for state mapping and state-derivative
prediction, while a softmax layer enables multi-class confidence estimation.
Quadcopter, fixed-wing, and helicopter aerial vehicles are considered as case
studies. The results demonstrate high classification accuracy with reduced
training time, offering a promising solution for system identification problems
in domains where the underlying dynamics are well understood.

</details>


### [517] [Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration](https://arxiv.org/abs/2509.21663)
*Davide Bizzaro,Alessandro Daniele*

Main category: cs.LG

TL;DR: NeSy 领域可以分为两类：将手工规则注入神经模型的方法，以及从数据中诱导符号规则的方法。我们引入了一种名为 LoH 的新语言，它可以统一这两种方法，允许将数据驱动的规则学习与符号先验和专家知识灵活地集成起来。LoH 扩展了命题逻辑语法，并引入了一个具有可学习参数的选择运算符，可以从一组选项中选择一个子公式。


<details>
  <summary>Details</summary>
Motivation: 现有 NeSy 模型要么需要手工规则，要么只能从数据中学习规则，缺乏灵活性。LoH 语言旨在弥合这一差距，实现数据驱动学习和符号先验知识的灵活集成。

Method: LoH 扩展了命题逻辑，引入了可学习参数的选择运算符。利用模糊逻辑，LoH 公式可以直接编译成可微分计算图，通过反向传播学习最优选择。该框架还利用了 G"odel 模糊逻辑和 G"odel 技巧，可以将模型离散化为硬布尔值函数。

Result: 实验表明，LoH 在表格数据和视觉井字棋 NeSy 任务上取得了强大的结果，并生成了可解释的决策规则。

Conclusion: LoH 是一种新颖的语言，能够灵活地集成数据驱动的规则学习和符号先验知识，并在实验中取得了优异且可解释的结果。

Abstract: Neurosymbolic integration (NeSy) blends neural-network learning with symbolic
reasoning. The field can be split between methods injecting hand-crafted rules
into neural models, and methods inducing symbolic rules from data. We introduce
Logic of Hypotheses (LoH), a novel language that unifies these strands,
enabling the flexible integration of data-driven rule learning with symbolic
priors and expert knowledge. LoH extends propositional logic syntax with a
choice operator, which has learnable parameters and selects a subformula from a
pool of options. Using fuzzy logic, formulas in LoH can be directly compiled
into a differentiable computational graph, so the optimal choices can be
learned via backpropagation. This framework subsumes some existing NeSy models,
while adding the possibility of arbitrary degrees of knowledge specification.
Moreover, the use of Goedel fuzzy logic and the recently developed Goedel trick
yields models that can be discretized to hard Boolean-valued functions without
any loss in performance. We provide experimental analysis on such models,
showing strong results on tabular data and on the Visual Tic-Tac-Toe NeSy task,
while producing interpretable decision rules.

</details>


### [518] [Learning from Delayed Feedback in Games via Extra Prediction](https://arxiv.org/abs/2509.22426)
*Yuma Fujimoto,Kenshi Abe,Kaito Ariu*

Main category: cs.LG

TL;DR: 本研究解决了游戏中学习中的延迟反馈问题，提出了加权OFTRL（WOFTRL）算法，并通过理论和实验证明了其在处理延迟问题上的有效性。


<details>
  <summary>Details</summary>
Motivation: 学习在游戏中，由于多智能体独立学习策略，会导致优化不一致。延迟的奖励观测会阻碍对未来奖励的预测，从而影响OFTRL算法的性能。

Method: 提出加权OFTRL（WOFTRL）算法，通过对OFTRL中的未来奖励预测向量进行加权，以抵消时间延迟带来的负面影响。研究证明了当优化权重超过时间延迟时，WOFTRL能够恢复OFTRL的性能。

Result: 理论上，WOFTRL在一般和非零和博弈中实现了恒定的遗憾（O(1)-regret），并在多项式矩阵零和博弈中证明了策略收敛到纳什均衡（最佳迭代收敛）。实验结果也支持了这些理论发现。

Conclusion: WOFTRL算法能够有效地解决游戏中学习中的时间延迟反馈问题，在不同类型的博弈中都取得了理论和实验上的良好表现。

Abstract: This study raises and addresses the problem of time-delayed feedback in
learning in games. Because learning in games assumes that multiple agents
independently learn their strategies, a discrepancy in optimization often
emerges among the agents. To overcome this discrepancy, the prediction of the
future reward is incorporated into algorithms, typically known as Optimistic
Follow-the-Regularized-Leader (OFTRL). However, the time delay in observing the
past rewards hinders the prediction. Indeed, this study firstly proves that
even a single-step delay worsens the performance of OFTRL from the aspects of
regret and convergence. This study proposes the weighted OFTRL (WOFTRL), where
the prediction vector of the next reward in OFTRL is weighted $n$ times. We
further capture an intuition that the optimistic weight cancels out this time
delay. We prove that when the optimistic weight exceeds the time delay, our
WOFTRL recovers the good performances that the regret is constant
($O(1)$-regret) in general-sum normal-form games, and the strategies converge
to the Nash equilibrium as a subsequence (best-iterate convergence) in
poly-matrix zero-sum games. The theoretical results are supported and
strengthened by our experiments.

</details>


### [519] [Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity](https://arxiv.org/abs/2509.21413)
*Zihuan Qiu,Lei Wang,Yang Cao,Runtong Zhang,Bing Su,Yi Xu,Fanman Meng,Linfeng Xu,Qingbo Wu,Hongliang Li*

Main category: cs.LG

TL;DR: NUFILT是一个数据自由模型合并框架，通过空域过滤和LoRA适配器，在不访问任务数据的情况下，实现透明性和保真性，并在视觉和NLP基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据自由模型合并（DFCMM）方法未能解决如何在没有任务数据的情况下，将数据层面的要求（透明性和保真性）与参数空间优化相结合的问题。

Method: 提出NUFILT框架，利用任务向量在表示子空间中的近似对齐特性。设计了一个空域投影器来过滤新任务向量的重叠分量，以实现透明性；并使用一个轻量级的LoRA适配器来注入特定任务的信号，以实现对新任务的保真性适应。适配器通过基于投影的代理损失进行训练，以在引入新知识的同时保持与先前知识的一致性。

Result: NUFILT在视觉和NLP基准上实现了最先进的性能，遗忘率极小，平均准确率比OPCM和WUDI-Merging提高了4-7%，同时缩小了与微调的差距，并减少了计算开销。

Conclusion: NUFILT通过将透明性和保真性要求直接关联到优化过程，有效地解决了数据自由模型合并的挑战，并在实践中证明了其优越性。

Abstract: Data-free continual model merging (DFCMM) aims to fuse independently
fine-tuned models into a single backbone that evolves with incoming tasks
without accessing task data. This paper formulate two fundamental desiderata
for DFCMM: transparency, avoiding interference with earlier tasks, and
fidelity, adapting faithfully to each new task. This poses a challenge that
existing approaches fail to address: how to bridge data-level desiderata with
parameter-space optimization to ensure transparency and fidelity in the absence
of task data. To this end, we propose NUFILT (NUll-space FILTering), a
data-free framework that directly links these desiderata to optimization. Our
key observation is that task vectors approximately align with representation
subspaces, providing structural surrogates for enforcing transparency and
fidelity. Accordingly, we design a null-space projector that preserves prior
responses by filtering out overlapping components of new task vectors, thereby
ensuring transparency, and a lightweight LoRA adapter that injects
complementary task-specific signals, enabling fidelity in adapting to new
tasks. The adapter is trained with a projection-based surrogate loss to retain
consistency with previous knowledge while introducing novel directions. This
joint filtering-adaptation process allows the backbone to absorb new knowledge
while retaining existing behaviors, and the updates are finally fused back in a
layer-wise linear fashion without extra parameters or inference cost.
Theoretically, we establish approximate subspace alignment guarantees that
justify null-space filtering. Empirically, NUFILT achieves state-of-the-art
performance with minimal forgetting on both vision and NLP benchmarks,
improving average accuracy by 4-7% over OPCM and WUDI-Merging, while narrowing
the gap to fine-tuning and reducing computation overhead.

</details>


### [520] [Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope](https://arxiv.org/abs/2509.21446)
*Waleed Esmail,Alexander Kappes,Stuart Russell,Christine Thomas*

Main category: cs.LG

TL;DR: SeismoGPT是一个基于Transformer的模型，用于预测未来引力波探测器（如爱因斯坦望远镜）的三分量地震波形。该模型以自回归方式训练，可以处理单站和基于阵列的输入，并能捕捉时空依赖性以进行短期精确预测。


<details>
  <summary>Details</summary>
Motivation: 为爱因斯坦等未来引力波探测器提供地震波形预测能力，以支持牛顿噪声抑制和实时观测站控制。

Method: 使用基于Transformer的自回归模型SeismoGPT，直接从波形数据中学习时空依赖性，处理单站和基于阵列的输入。

Result: SeismoGPT在短期预测窗口内表现良好，但预测时间越长，性能逐渐下降，符合自回归系统的预期。

Conclusion: SeismoGPT为数据驱动的地震预测奠定了基础，有望应用于牛顿噪声抑制和实时观测站控制。

Abstract: We introduce \textit{SeismoGPT}, a transformer-based model for forecasting
three-component seismic waveforms in the context of future gravitational wave
detectors like the Einstein Telescope. The model is trained in an
autoregressive setting and can operate on both single-station and array-based
inputs. By learning temporal and spatial dependencies directly from waveform
data, SeismoGPT captures realistic ground motion patterns and provides accurate
short-term forecasts. Our results show that the model performs well within the
immediate prediction window and gradually degrades further ahead, as expected
in autoregressive systems. This approach lays the groundwork for data-driven
seismic forecasting that could support Newtonian noise mitigation and real-time
observatory control.

</details>


### [521] [Role-Aware Multi-modal federated learning system for detecting phishing webpages](https://arxiv.org/abs/2509.22369)
*Bo Wang,Imran Khan,Martin White,Natalia Beloff*

Main category: cs.LG

TL;DR: 我们提出了一个支持URL、HTML和图像输入的联邦多模态网络钓鱼网站检测器，它允许客户端在推理时使用任何训练过的模态。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有网络钓鱼检测方法在处理多模态数据和保护用户隐私方面的局限性，我们提出了一种联邦学习框架。

Method: 该方法在FedProx的基础上，借鉴了Mixture-of-Experts和FedMM的思想，提出了一种角色感知分桶聚合方法，并采用硬门控机制，为不同模态（URL、HTML、图像）的专家模型分别进行参数聚合，以解决跨嵌入冲突并稳定收敛。

Result: 在TR-OP数据集上，融合模型达到了97.5%的准确率和2.4%的假阳性率；在图像子集上，单独的图像专家达到了95.5%的准确率和5.9%的假阳性率。对于文本模态，URL使用GraphCodeBERT进行编码，原始HTML使用早期三向嵌入进行编码。在WebPhish（HTML）数据集上，准确率为96.5%，假阳性率为1.8%；在TR-OP（原始HTML）数据集上，准确率为95.1%，假阳性率为4.6%。

Conclusion: 角色感知分桶聚合与硬门控专家相结合的联邦学习方法，能够在严格的隐私保护下实现稳定的联邦训练，并提高多模态网络钓鱼检测的可用性和灵活性。

Abstract: We present a federated, multi-modal phishing website detector that supports
URL, HTML, and IMAGE inputs without binding clients to a fixed modality at
inference: any client can invoke any modality head trained elsewhere.
Methodologically, we propose role-aware bucket aggregation on top of FedProx,
inspired by Mixture-of-Experts and FedMM. We drop learnable routing and use
hard gating (selecting the IMAGE/HTML/URL expert by sample modality), enabling
separate aggregation of modality-specific parameters to isolate cross-embedding
conflicts and stabilize convergence. On TR-OP, the Fusion head reaches Acc
97.5% with FPR 2.4% across two data types; on the image subset (ablation) it
attains Acc 95.5% with FPR 5.9%. For text, we use GraphCodeBERT for URLs and an
early three-way embedding for raw, noisy HTML. On WebPhish (HTML) we obtain Acc
96.5% / FPR 1.8%; on TR-OP (raw HTML) we obtain Acc 95.1% / FPR 4.6%. Results
indicate that bucket aggregation with hard-gated experts enables stable
federated training under strict privacy, while improving the usability and
flexibility of multi-modal phishing detection.

</details>


### [522] [Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data](https://arxiv.org/abs/2509.21465)
*George Yakushev,Alina Shutova,Ivan Rubachev,Renat Sergazinov,Artem Babenko*

Main category: cs.LG

TL;DR: 使用LLM诱导决策树来解决低资源表格问题。


<details>
  <summary>Details</summary>
Motivation: 由于预训练的表格基础模型在推理时成本高昂且难以解释，因此探索一种替代策略，使用推理能力强的LLM为小规模表格数据集诱导决策树。

Method: 设计了一套用于构建、分析和操作决策树的工具，并利用这些工具使LLM能够结合其先验知识和数据学习来创建决策树。

Result: 所提出的决策树模型在低资源表格问题上优于传统的CART模型，并且具有人类可读的推理路径，可以检查是否存在偏差和数据泄露。此外，该方法还允许通过人类输入来纠正偏差或整合未包含在数据中的领域特定知识。

Conclusion: 虽然单个决策树模型的性能不及最先进的黑箱模型，但其可解释性和可干预性使其成为低资源表格问题的有吸引力的替代方案。

Abstract: Tabular foundation models are becoming increasingly popular for low-resource
tabular problems. These models make up for small training datasets by
pretraining on large volumes of synthetic data. The prior knowledge obtained
via pretraining provides the exceptional performance, but the resulting model
becomes a black box that is difficult to interpret and costly to inference. In
this work, we explore an alternative strategy: using reasoning-capable LLMs to
induce decision trees for small tabular datasets in agentic setup. We design a
minimal set of tools for constructing, analyzing and manipulating decision
trees. By using these tools, LLMs combine their prior knowledge with learning
from data to create a lightweight decision tree that outperforms traditional
CART on low-resource tabular problems. While a single decision tree does not
outperform state-of-the-art black box models, it comes with a human-readable
reasoning trace that can be checked for biases and data leaks. Furthermore, the
reasoning-based LLM's creation process allows for additional human input:
correcting biases or incorporating domain-specific intuition that is not
captured in the data.

</details>


### [523] [Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard Overparametrization: The Dynamic Graph Flow Case](https://arxiv.org/abs/2509.22197)
*Duc Thien Nguyen,Konstantinos Slavakis,Eleftherios Kofidis,Dimitris Pados*

Main category: cs.LG

TL;DR: KReTTaH是一种基于核回归的张量分解方法，用于处理高维稀疏数据，并有效估计动态图流量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一种可解释的多向数据插补框架，以解决高维稀疏数据中缺失值的问题，并将其应用于动态图流量的估计。

Method: 提出了一种名为KReTTaH（Kernel Regression via Tensor Trains with Hadamard overparametrization）的核回归框架。该框架将插补视为一个回归问题，利用再生核希尔伯特空间，并通过张量训练（TT）秩和Hadamard过参数化实现参数效率和稀疏性。学习过程通过在固定TT秩张量黎曼流形上求解逆问题来完成。

Result: KReTTaH在真实世界图数据集上的数值测试表明，其在估计缺失、随时间变化的边缘流方面，性能优于包括非参数张量和神经网络在内的现有最先进方法。

Conclusion: KReTTaH框架在处理高维稀疏数据插补方面表现出优越性，尤其在动态图流量估计应用中，通过其逆问题形式化能够灵活地整合图的拓扑先验信息，并超越现有技术。

Abstract: A regression-based framework for interpretable multi-way data imputation,
termed Kernel Regression via Tensor Trains with Hadamard overparametrization
(KReTTaH), is introduced. KReTTaH adopts a nonparametric formulation by casting
imputation as regression via reproducing kernel Hilbert spaces. Parameter
efficiency is achieved through tensors of fixed tensor-train (TT) rank, which
reside on low-dimensional Riemannian manifolds, and is further enhanced via
Hadamard overparametrization, which promotes sparsity within the TT parameter
space. Learning is accomplished by solving a smooth inverse problem posed on
the Riemannian manifold of fixed TT-rank tensors. As a representative
application, the estimation of dynamic graph flows is considered. In this
setting, KReTTaH exhibits flexibility by seamlessly incorporating graph-based
(topological) priors via its inverse problem formulation. Numerical tests on
real-world graph datasets demonstrate that KReTTaH consistently outperforms
state-of-the-art alternatives-including a nonparametric tensor- and a
neural-network-based methods-for imputing missing, time-varying edge flows.

</details>


### [524] [LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning](https://arxiv.org/abs/2509.21617)
*Marco Paul E. Apolinario,Kaushik Roy*

Main category: cs.LG

TL;DR: LANCE通过一次性高阶奇异值分解（SVD）实现低秩激活压缩，显著降低了内存和计算开销，并能有效支持设备端持续学习，在多个基准测试中表现出与现有方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中，设备端学习对于个性化、隐私和长期适应至关重要。然而，反向传播过程中激活的高内存成本阻碍了高效学习，而现有的激活压缩方法计算开销大且未被探索用于持续学习。

Method: 提出LANCE（低秩激活压缩）框架，通过一次性高阶SVD获得可重用的低秩子空间用于激活投影，从而消除重复分解，减少内存和计算。固定的低秩子空间通过将任务分配给正交子空间来实现设备端持续学习。

Result: LANCE将激活存储减少了高达250倍，同时在CIFAR-10/100、Oxford-IIIT Pets、Flowers102和CUB-200数据集上保持了与全反向传播相当的准确性。在持续学习基准测试（Split CIFAR-100、Split MiniImageNet、5-Datasets）中，其性能与正交梯度投影方法相当，但内存成本却大大降低。

Conclusion: LANCE是一种实用且可扩展的解决方案，能够有效且经济地进行设备端微调和持续学习。

Abstract: On-device learning is essential for personalization, privacy, and long-term
adaptation in resource-constrained environments. Achieving this requires
efficient learning, both fine-tuning existing models and continually acquiring
new tasks without catastrophic forgetting. Yet both settings are constrained by
high memory cost of storing activations during backpropagation. Existing
activation compression methods reduce this cost but relying on repeated
low-rank decompositions, introducing computational overhead. Also, such methods
have not been explored for continual learning. We propose LANCE (Low-rank
Activation Compression), a framework that performs one-shot higher-order
Singular Value Decompsoition (SVD) to obtain a reusable low-rank subspace for
activation projection. This eliminates repeated decompositions, reducing both
memory and computation. Moreover, fixed low-rank subspaces further enable
on-device continual learning by allocating tasks to orthogonal subspaces
without storing large task-specific matrices. Experiments show that LANCE
reduces activation storage up to 250$\times$ while maintaining accuracy
comparable to full backpropagation on CIFAR-10/100, Oxford-IIIT Pets,
Flowers102, and CUB-200 datasets. On continual learning benchmarks (Split
CIFAR-100, Split MiniImageNet, 5-Datasets), it achieves performance competitive
with orthogonal gradient projection methods at a fraction of the memory cost.
These results position LANCE as a practical and scalable solution for efficient
fine-tuning and continual learning on edge devices.

</details>


### [525] [Score-based Idempotent Distillation of Diffusion Models](https://arxiv.org/abs/2509.21470)
*Shehtab Zaman,Chengyan Liu,Kenneth Chiu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SIGN的新型生成模型，它结合了扩散模型和幂等生成网络（IGNs）的优点，通过从扩散模型中蒸馏出幂等模型来实现稳定、高效且无需对抗性训练的生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型如GANs存在训练不稳定和模式崩溃问题，而扩散模型虽然生成质量高但计算成本昂贵。本研究旨在结合两者的优点，提出一种既稳定又高效的生成模型。

Method: 通过从预训练的扩散模型中蒸馏出幂等模型来构建SIGN模型，并进行了基于分数的方法的理论分析。

Result: 在CIFAR和CelebA数据集上，SIGN模型在幂等模型方面取得了最先进的成果，并且推理速度比迭代式评分模型更快，同时支持多步采样以平衡质量和效率。

Conclusion: SIGN模型成功地结合了扩散模型的稳定性和IGNs的效率，提供了一种无需对抗性训练、速度快且具有零样本编辑能力的生成模型。

Abstract: Idempotent generative networks (IGNs) are a new line of generative models
based on idempotent mapping to a target manifold. IGNs support both single-and
multi-step generation, allowing for a flexible trade-off between computational
cost and sample quality. But similar to Generative Adversarial Networks (GANs),
conventional IGNs require adversarial training and are prone to training
instabilities and mode collapse. Diffusion and score-based models are popular
approaches to generative modeling that iteratively transport samples from one
distribution, usually a Gaussian, to a target data distribution. These models
have gained popularity due to their stable training dynamics and high-fidelity
generation quality. However, this stability and quality come at the cost of
high computational cost, as the data must be transported incrementally along
the entire trajectory. New sampling methods, model distillation, and
consistency models have been developed to reduce the sampling cost and even
perform one-shot sampling from diffusion models. In this work, we unite
diffusion and IGNs by distilling idempotent models from diffusion model scores,
called SIGN. Our proposed method is highly stable and does not require
adversarial losses. We provide a theoretical analysis of our proposed
score-based training methods and empirically show that IGNs can be effectively
distilled from a pre-trained diffusion model, enabling faster inference than
iterative score-based models. SIGNs can perform multi-step sampling, allowing
users to trade off quality for efficiency. These models operate directly on the
source domain; they can project corrupted or alternate distributions back onto
the target manifold, enabling zero-shot editing of inputs. We validate our
models on multiple image datasets, achieving state-of-the-art results for
idempotent models on the CIFAR and CelebA datasets.

</details>


### [526] [Towards a more realistic evaluation of machine learning models for bearing fault diagnosis](https://arxiv.org/abs/2509.22267)
*João Paulo Vieira,Victor Afonso Bauler,Rodrigo Kobashikawa Rosa,Danilo Silva*

Main category: cs.LG

TL;DR: 该论文研究了轴承故障诊断中数据泄露问题，并提出了一种无泄露的评估方法，以提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 可靠的轴承故障检测对于旋转机械的安全和运行效率至关重要，但现有的机器学习方法在实际应用中泛化能力不足，主要归因于数据泄露。

Method: 提出了一种基于轴承划分的无数据泄露评估方法，并将分类任务重构为多标签问题，同时研究了数据集多样性对泛化能力的影响。在CWRU、PU和UORED-VAFCLS三个数据集上进行了评估。

Result: 证明了常用的数据集划分策略（如按段或按工况划分）会导致性能指标虚高。所提出的轴承划分方法和多标签分类任务能够更准确地评估模型性能，并揭示了训练轴承数量对模型鲁棒性的决定性影响。

Conclusion: 强调了在工业故障诊断领域，采用无数据泄露的评估协议的重要性，并为数据集划分、模型选择和验证提供了实用指南，以促进更可信赖的机器学习系统的发展。

Abstract: Reliable detection of bearing faults is essential for maintaining the safety
and operational efficiency of rotating machinery. While recent advances in
machine learning (ML), particularly deep learning, have shown strong
performance in controlled settings, many studies fail to generalize to
real-world applications due to methodological flaws, most notably data leakage.
This paper investigates the issue of data leakage in vibration-based bearing
fault diagnosis and its impact on model evaluation. We demonstrate that common
dataset partitioning strategies, such as segment-wise and condition-wise
splits, introduce spurious correlations that inflate performance metrics. To
address this, we propose a rigorous, leakage-free evaluation methodology
centered on bearing-wise data partitioning, ensuring no overlap between the
physical components used for training and testing. Additionally, we reformulate
the classification task as a multi-label problem, enabling the detection of
co-occurring fault types and the use of prevalence-independent metrics such as
Macro AUROC. Beyond preventing leakage, we also examine the effect of dataset
diversity on generalization, showing that the number of unique training
bearings is a decisive factor for achieving robust performance. We evaluate our
methodology on three widely adopted datasets: CWRU, Paderborn University (PU),
and University of Ottawa (UORED-VAFCLS). This study highlights the importance
of leakage-aware evaluation protocols and provides practical guidelines for
dataset partitioning, model selection, and validation, fostering the
development of more trustworthy ML systems for industrial fault diagnosis
applications.

</details>


### [527] [Are Hallucinations Bad Estimations?](https://arxiv.org/abs/2509.21473)
*Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu*

Main category: cs.LG

TL;DR: 生成模型中的幻觉被定义为无法将估计与任何合理原因联系起来，即使是最优估计器也会产生幻觉。


<details>
  <summary>Details</summary>
Motivation: 将生成模型中的幻觉定义为估计与合理原因之间的脱节，并表明即使是最优估计器也会产生幻觉。

Method: 形式化幻觉，提出高概率下界，并进行实验验证。

Result: 即使是最优估计器也会产生幻觉，并提供了幻觉率的下界。

Conclusion: 幻觉是由于损失最小化和可接受的输出之间的结构性不匹配以及估计器校准问题造成的。

Abstract: We formalize hallucinations in generative models as failures to link an
estimate to any plausible cause. Under this interpretation, we show that even
loss-minimizing optimal estimators still hallucinate. We confirm this with a
general high probability lower bound on hallucinate rate for generic data
distributions. This reframes hallucination as structural misalignment between
loss minimization and human-acceptable outputs, and hence estimation errors
induced by miscalibration. Experiments on coin aggregation, open-ended QA, and
text-to-image support our theory.

</details>


### [528] [Preference-Guided Learning for Sparse-Reward Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.21828)
*The Viet Bui,Tien Mai,Hong Thanh Nguyen*

Main category: cs.LG

TL;DR: 在线多智能体强化学习（MARL）在稀疏奖励环境下，通过结合逆偏好学习和多智能体优化，利用LLM生成偏好标签，有效解决了奖励稀疏的挑战，并在MAMuJoCo和SMACv2基准测试中表现优越。


<details>
  <summary>Details</summary>
Motivation: 稀疏奖励环境下的在线多智能体强化学习（MARL）缺乏中间奖励，阻碍了标准MARL算法的有效性。

Method: 提出一种新颖的框架，将在线逆偏好学习与多智能体在线优化统一起来，核心是隐式多智能体奖励学习模型（基于偏好-值分解网络），生成全局和局部奖励信号，并构建双优势流以实现区分化学习目标。同时，利用大型语言模型（LLMs）提供偏好标签以提高奖励模型的质量。

Result: 所提出的方法在MAMuJoCo和SMACv2等最先进的基准测试中，取得了优于现有基线方法的性能。

Conclusion: 该方法能有效解决在线MARL中的稀疏奖励挑战。

Abstract: We study the problem of online multi-agent reinforcement learning (MARL) in
environments with sparse rewards, where reward feedback is not provided at each
interaction but only revealed at the end of a trajectory. This setting, though
realistic, presents a fundamental challenge: the lack of intermediate rewards
hinders standard MARL algorithms from effectively guiding policy learning. To
address this issue, we propose a novel framework that integrates online inverse
preference learning with multi-agent on-policy optimization into a unified
architecture. At its core, our approach introduces an implicit multi-agent
reward learning model, built upon a preference-based value-decomposition
network, which produces both global and local reward signals. These signals are
further used to construct dual advantage streams, enabling differentiated
learning targets for the centralized critic and decentralized actors. In
addition, we demonstrate how large language models (LLMs) can be leveraged to
provide preference labels that enhance the quality of the learned reward model.
Empirical evaluations on state-of-the-art benchmarks, including MAMuJoCo and
SMACv2, show that our method achieves superior performance compared to existing
baselines, highlighting its effectiveness in addressing sparse-reward
challenges in online MARL.

</details>


### [529] [Distributed Associative Memory via Online Convex Optimization](https://arxiv.org/abs/2509.22321)
*Bowen Wang,Matteo Zecchin,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 本文提出了一种分布式在线梯度下降方法，用于在通信受限的环境中优化局部关联记忆，并证明了其子线性遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络（如Transformer）的运行依赖于联想记忆（AM），但现有研究多集中在集中式设置，缺乏对分布式场景的研究。本文旨在解决代理维护局部AM以回忆自身联想及选择性信息的分布式问题。

Method: 引入一种分布式在线梯度下降方法，通过路由树通信优化不同代理的局部AM。

Result: 理论分析证明了该方法具有次线性遗憾界限，实验表明该协议的性能优于现有的在线优化基线。

Conclusion: 所提出的分布式在线梯度下降方法能够有效地优化局部AM，并在通信受限的分布式环境中实现优越的性能。

Abstract: An associative memory (AM) enables cue-response recall, and associative
memorization has recently been noted to underlie the operation of modern neural
architectures such as Transformers. This work addresses a distributed setting
where agents maintain a local AM to recall their own associations as well as
selective information from others. Specifically, we introduce a distributed
online gradient descent method that optimizes local AMs at different agents
through communication over routing trees. Our theoretical analysis establishes
sublinear regret guarantees, and experiments demonstrate that the proposed
protocol consistently outperforms existing online optimization baselines.

</details>


### [530] [d2: Improved Techniques for Training Reasoning Diffusion Language Models](https://arxiv.org/abs/2509.21474)
*Guanghan Wang,Yair Schiff,Gilad Turok,Volodymyr Kuleshov*

Main category: cs.LG

TL;DR: d2是一个针对掩码扩散语言模型（DLM）的推理框架，使用新的策略梯度算法，在逻辑推理和数学推理任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散语言模型（DLM）在文本生成方面取得了有竞争力的性能，但使用强化学习（RL）来提高其推理能力仍然是一个活跃的研究领域。

Method: d2框架的核心是一种新的策略梯度算法，该算法利用掩码的特性来准确估计采样轨迹的似然性。该算法的估计器以一种可解析处理的方式用计算换取近似精度，并且对于支持任意顺序似然性估计的DLM特别有效。

Result: d2在逻辑推理任务（Countdown和Sudoku）和数学推理基准（GSM8K和MATH500）上显著优于以前仅使用RL的扩散推理框架，并设定了新的最先进性能。

Conclusion: d2框架的有效性在于其利用了DLM的任意顺序似然性估计特性，这对于基于扩散的推理至关重要。该方法在不依赖监督微调的情况下，仅使用RL就能显著提高DLM的推理能力。

Abstract: While diffusion language models (DLMs) have achieved competitive performance
in text generation, improving their reasoning ability with reinforcement
learning remains an active research area. Here, we introduce d2, a reasoning
framework tailored for masked DLMs. Central to our framework is a new policy
gradient algorithm that relies on properties of masking to accurately estimate
the likelihoods of sampling trajectories. Our estimators trade off computation
for approximation accuracy in an analytically tractable manner, and are
particularly effective for DLMs that support any-order likelihood estimation.
We characterize and study this property in popular DLMs and show that it is key
for efficient diffusion-based reasoning. Empirically, d2 significantly improves
over previous diffusion reasoning frameworks using only RL (without relying on
supervised fine-tuning), and sets a new state-of-the-art performance for DLMs
on logical reasoning tasks (Countdown and Sudoku) and math reasoning benchmarks
(GSM8K and MATH500).

</details>


### [531] [ECHO: Toward Contextual Seq2Seq Paradigms in Large EEG Models](https://arxiv.org/abs/2509.22556)
*Chenyu Liu,Yuqiu Deng,Tianyu Liu,Jinan Zhou,Xinliang Zhou,Ziyu Jia,Yi Ding*

Main category: cs.LG

TL;DR: ECHO是一种新的解码器为中心的LEM模型，通过序列到序列学习来处理EEG数据，在多任务设置中表现优于最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的LEM模型在解码器方面能力不足，限制了预训练特征的充分利用。

Method: ECHO将EEG建模重新定义为序列到序列学习，利用离散支持样本构建上下文线索，并实现原地学习，无需更新参数即可适应不同任务。

Result: ECHO在多数据集的广泛实验中，即使使用基础的模型组件，在多任务设置下也持续优于最先进的单任务LEM模型，展现出卓越的泛化能力和适应性。

Conclusion: ECHO通过其新颖的解码器为中心的范式，在EEG建模领域取得了显著的进展，提高了模型的泛化性和适应性。

Abstract: Electroencephalography (EEG), with its broad range of applications,
necessitates models that can generalize effectively across various tasks and
datasets. Large EEG Models (LEMs) address this by pretraining encoder-centric
architectures on large-scale unlabeled data to extract universal
representations. While effective, these models lack decoders of comparable
capacity, limiting the full utilization of the learned features. To address
this issue, we introduce ECHO, a novel decoder-centric LEM paradigm that
reformulates EEG modeling as sequence-to-sequence learning. ECHO captures
layered relationships among signals, labels, and tasks within sequence space,
while incorporating discrete support samples to construct contextual cues. This
design equips ECHO with in-context learning, enabling dynamic adaptation to
heterogeneous tasks without parameter updates. Extensive experiments across
multiple datasets demonstrate that, even with basic model components, ECHO
consistently outperforms state-of-the-art single-task LEMs in multi-task
settings, showing superior generalization and adaptability.

</details>


### [532] [VISION: Prompting Ocean Vertical Velocity Reconstruction from Incomplete Observations](https://arxiv.org/abs/2509.21477)
*Yuan Gao,Hao Wu,Qingsong Wen,Kun Wang,Xian Wu,Xiaomeng Huang*

Main category: cs.LG

TL;DR: KD48是一个高分辨率海洋动力学基准，VISION是一个基于动态提示的新型重建范式，用于解决现实世界观测数据缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 从不完整的地表观测中重建次表层海洋动力学（如垂直速度场）是一个关键的地球科学挑战，该领域长期以来受制于缺乏标准化的、可用于分析的基准。

Method:  VISION通过动态提示生成视觉提示，该提示能够编码数据可用性和海洋的物理状态。然后，一个状态条件提示模块将此提示注入到一个通用的骨干网络中，以指导其计算策略的自适应调整。

Result: 在KD48基准上的大量实验表明，VISION的性能在极端数据缺失情况下也优于最先进的模型，并且具有很强的泛化能力。

Conclusion: 该工作通过提供高质量的基准和强大的模型，为数据不确定性下的海洋科学研究奠定了坚实的基础设施。

Abstract: Reconstructing subsurface ocean dynamics, such as vertical velocity fields,
from incomplete surface observations poses a critical challenge in Earth
science, a field long hampered by the lack of standardized, analysis-ready
benchmarks. To systematically address this issue and catalyze research, we
first build and release KD48, a high-resolution ocean dynamics benchmark
derived from petascale simulations and curated with expert-driven denoising.
Building on this benchmark, we introduce VISION, a novel reconstruction
paradigm based on Dynamic Prompting designed to tackle the core problem of
missing data in real-world observations. The essence of VISION lies in its
ability to generate a visual prompt on-the-fly from any available subset of
observations, which encodes both data availability and the ocean's physical
state. More importantly, we design a State-conditioned Prompting module that
efficiently injects this prompt into a universal backbone, endowed with
geometry- and scale-aware operators, to guide its adaptive adjustment of
computational strategies. This mechanism enables VISION to precisely handle the
challenges posed by varying input combinations. Extensive experiments on the
KD48 benchmark demonstrate that VISION not only substantially outperforms
state-of-the-art models but also exhibits strong generalization under extreme
data missing scenarios. By providing a high-quality benchmark and a robust
model, our work establishes a solid infrastructure for ocean science research
under data uncertainty. Our codes are available at:
https://github.com/YuanGao-YG/VISION.

</details>


### [533] [Filtering with Confidence: When Data Augmentation Meets Conformal Prediction](https://arxiv.org/abs/2509.21479)
*Zixuan Wu,So Won Jeong,Yating Liu,Yeo Jin Jung,Claire Donnat*

Main category: cs.LG

TL;DR: 一种基于保形预测的保形数据增强方法，通过生成多样化的合成数据并过滤掉低质量的生成数据，在不访问模型内部logit或重新训练模型的情况下，能够有效提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据增强在处理数据稀疏性和满足模型对数据密集型需求方面具有巨大潜力，但其有效性依赖于在引入最小偏差的同时降低估计量方差。因此，控制偏差至关重要，这意味着需要生成与训练集来自同一底层分布且偏差极小的新样本。

Method: 提出了一种名为保形数据增强（conformal data augmentation）的框架，该框架利用保形预测（conformal prediction）的能力来生成多样化的合成数据，同时通过保形预测的风险控制能力过滤掉低质量的生成数据。

Result: 在主题预测、情感分析、图像分类和欺诈检测等多个任务中，与未增强的基线相比，该方法在F1分数上提高了40%，与其他的过滤增强基线相比，提高了4%，展现了一致的性能提升。

Conclusion: 保形数据增强是一种简单易行、无需访问模型内部logit或进行大规模模型重新训练的数据过滤框架，它能生成多样化的合成数据，并具有可证明的风险控制能力，有效解决了合成数据增强中的偏差问题。

Abstract: With promising empirical performance across a wide range of applications,
synthetic data augmentation appears a viable solution to data scarcity and the
demands of increasingly data-intensive models. Its effectiveness lies in
expanding the training set in a way that reduces estimator variance while
introducing only minimal bias. Controlling this bias is therefore critical:
effective data augmentation should generate diverse samples from the same
underlying distribution as the training set, with minimal shifts. In this
paper, we propose conformal data augmentation, a principled data filtering
framework that leverages the power of conformal prediction to produce diverse
synthetic data while filtering out poor-quality generations with provable risk
control. Our method is simple to implement, requires no access to internal
model logits, nor large-scale model retraining. We demonstrate the
effectiveness of our approach across multiple tasks, including topic
prediction, sentiment analysis, image classification, and fraud detection,
showing consistent performance improvements of up to 40% in F1 score over
unaugmented baselines, and 4% over other filtered augmentation baselines.

</details>


### [534] [High-Probability Analysis of Online and Federated Zero-Order Optimisation](https://arxiv.org/abs/2509.21484)
*Arya Akhavan,David Janz,El-Mahdi El-Mhamdi*

Main category: cs.LG

TL;DR: FedZero 是一种联邦零阶优化算法，在联邦凸设置中实现了近乎最优的优化误差界限，并在单机模型中建立了第一个高概率收敛保证。


<details>
  <summary>Details</summary>
Motivation: 在梯度消失的场景下，研究分布式学习的零阶优化问题，并为联邦学习框架设计新的算法。

Method: 提出 FedZero 算法，采用基于 $\ell_1$-球体上随机化的梯度估计器，并开发了新的浓度不等式进行理论分析。

Result: FedZero 在联邦凸设置中实现了近乎最优的优化误差界限（高概率），并在单机模型下建立了零阶凸优化的首次高概率收敛保证。

Conclusion: FedZero 算法在理论上具有优越性，其梯度估计和分析方法（特别是新的浓度不等式）为零阶优化和联邦学习领域提供了重要的理论贡献。

Abstract: We study distributed learning in the setting of gradient-free zero-order
optimization and introduce FedZero, a federated zero-order algorithm that
delivers sharp theoretical guarantees. Specifically, FedZero: (1) achieves
near-optimal optimization error bounds with high probability in the federated
convex setting; and (2) in the single-worker regime-where the problem reduces
to the standard zero-order framework, establishes the first high-probability
convergence guarantees for convex zero-order optimization, thereby
strengthening the classical expectation-based results. At its core, FedZero
employs a gradient estimator based on randomization over the $\ell_1$-sphere.
To analyze it, we develop new concentration inequalities for Lipschitz
functions under the uniform measure on the $\ell_1$-sphere, with explicit
constants. These concentration tools are not only central to our
high-probability guarantees but may also be of independent interest.

</details>


### [535] [Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems](https://arxiv.org/abs/2509.21485)
*Daniil D. Sirota,Sergey A. Khan,Sergey L. Kostikov,Kirill A. Butov*

Main category: cs.LG

TL;DR: 提出一种基于傅里叶神经网络算子（TFNO-opt）的瞬态流体流动建模方法，能大幅提高计算效率并保证精度，可用于复杂油藏系统的控制和决策支持。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在模拟复杂油藏系统（由偏微分方程描述）时计算成本高，限制了其在控制和决策支持中的应用。

Method: 提出一种基于傅里叶神经网络算子的TFNO-opt架构，通过可调内部时间分辨率、谱域参数张量分解、Sobolev范数误差函数、分离近似误差和初始条件重建等改进，以提高训练精度和稳定性。

Result: 计算实验证实了所提方法的有效性，尤其在地下储气库水动力建模中，计算速度相比传统方法提升了六个数量级。

Conclusion: TFNO-opt方法在保证精度的前提下，大幅提高了计算效率，为复杂油藏系统的有效控制提供了新的可能性。

Abstract: This paper presents a method for modeling transient fluid flow in subsurface
reservoir systems based on the developed neural operator architecture
(TFNO-opt). Reservoir systems are complex dynamic objects with distributed
parameters described by systems of partial differential equations (PDEs).
Traditional numerical methods for modeling such systems, despite their high
accuracy, are characterized by significant time costs for performing
calculations, which limits their applicability in control and decision support
problems. The proposed architecture (TFNO-opt) is based on Fourier neural
operators, which allow approximating PDE solutions in infinite-dimensional
functional spaces, providing invariance to discretization and the possibility
of generalization to various implementations of equations. The developed
modifications are aimed at increasing the accuracy and stability of the trained
neural operator, which is especially important for control problems. These
include adjustable internal time resolution of the integral Fourier operator,
tensor decomposition of parameters in the spectral domain, use of the Sobolev
norm in the error function, and separation of approximation errors and
reconstruction of initial conditions for more accurate reproduction of physical
processes. The effectiveness of the proposed improvements is confirmed by
computational experiments. The practical significance is confirmed by
computational experiments using the example of the problem of hydrodynamic
modeling of an underground gas storage (UGS), where the acceleration of
calculations by six orders of magnitude was achieved, compared to traditional
methods. This opens up new opportunities for the effective control of complex
reservoir systems.

</details>


### [536] [GraphPFN: A Prior-Data Fitted Graph Foundation Model](https://arxiv.org/abs/2509.21489)
*Dmitry Eremeev,Oleg Platonov,Gleb Bazhenov,Artem Babenko,Liudmila Prokhorenkova*

Main category: cs.LG

TL;DR: 图基模型（Graph Foundation Models, GFMs）在图数据上的应用仍有限，现有模型（如G2T-FM）依赖手工特征。本文提出GraphPFN，一种用于节点级预测的先验数据拟合网络，通过生成合成图数据来增强表格基模型LimiX，使其能捕捉图结构依赖关系，并在真实数据集上达到最先进（state-of-the-art）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图基模型（如G2T-FM）在图数据上的应用受限于手工特征，未能充分学习图特有的复杂模式。本文旨在探索在合成图数据上进行预训练以提升图基模型性能的方法。

Method: 1. 设计了一个合成属性图的先验分布，结合随机块模型和优先依附过程生成图结构。2. 应用图感知结构因果模型生成节点属性和目标。3. 将注意力机制的图邻域聚合层集成到表格基模型LimiX中，并在生成的合成图上进行训练，使模型能学习表格数据中不存在的图结构依赖关系。

Result: GraphPFN在包含多达50,000个节点的大规模真实世界图数据集上，展现出强大的上下文学习（in-context learning）能力，并在微调后取得了最先进（state-of-the-art）的结果，超越了G2T-FM以及在大多数数据集上从头开始训练的特定图神经网络（GNNs）。

Conclusion: 在精心设计的先验分布上使用合成图进行预训练，是构建有效图基模型的策略。

Abstract: Foundation models pretrained on large-scale datasets have transformed such
fields as natural language processing and computer vision, but their
application to graph data remains limited. Recently emerged graph foundation
models, such as G2T-FM, utilize tabular foundation models for graph tasks and
were shown to significantly outperform prior attempts to create GFMs. However,
these models primarily rely on hand-crafted graph features, limiting their
ability to learn complex graph-specific patterns. In this work, we propose
GraphPFN: a prior-data fitted network for node-level prediction. First, we
design a prior distribution of synthetic attributed graphs. For graph structure
generation, we use a novel combination of multiple stochastic block models and
a preferential attachment process. We then apply graph-aware structured causal
models to generate node attributes and targets. This procedure allows us to
efficiently generate a wide range of realistic graph datasets. Then, we augment
the tabular foundation model LimiX with attention-based graph neighborhood
aggregation layers and train it on synthetic graphs sampled from our prior,
allowing the model to capture graph structural dependencies not present in
tabular data. On diverse real-world graph datasets with up to 50,000 nodes,
GraphPFN shows strong in-context learning performance and achieves
state-of-the-art results after finetuning, outperforming both G2T-FM and
task-specific GNNs trained from scratch on most datasets. More broadly, our
work demonstrates that pretraining on synthetic graphs from a well-designed
prior distribution is an effective strategy for building graph foundation
models.

</details>


### [537] [SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models](https://arxiv.org/abs/2509.21498)
*Arani Roy,Shristi Das Biswas,Kaushik Roy*

Main category: cs.LG

TL;DR: SlimDiff是一种全自动、无梯度、激活感知结构压缩框架，用于高效扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型因参数量大和迭代去噪过程导致计算成本高昂，而现有压缩技术（如量化、减少时间步或剪枝）通常需要微调或重新训练才能恢复性能。

Method: SlimDiff将压缩视为谱近似任务，利用去噪时间步上的激活协方差定义低秩子空间，在固定压缩预算下引导动态剪枝。该方法通过在查询-键交互、值-输出耦合和前馈投影等功能权重组上进行模块化分解，而非孤立的矩阵分解，来缓解跨时间步的误差累积，并自适应地分配稀疏度以适应扩散轨迹的非均匀几何形状。

Result: SlimDiff实现了高达35%的加速和约1亿个参数的缩减，生成质量与未压缩模型相当，且无需反向传播。此外，该方法仅需约500个校准样本，远少于先验方法。

Conclusion: SlimDiff是首个实现扩散模型闭式解、激活引导的结构压缩方法，完全无需训练，兼具理论清晰度和实用效率。

Abstract: Diffusion models (DMs), lauded for their generative performance, are
computationally prohibitive due to their billion-scale parameters and iterative
denoising dynamics. Existing efficiency techniques, such as quantization,
timestep reduction, or pruning, offer savings in compute, memory, or runtime
but are strictly bottlenecked by reliance on fine-tuning or retraining to
recover performance. In this work, we introduce SlimDiff, an automated
activation-informed structural compression framework that reduces both
attention and feedforward dimensionalities in DMs, while being entirely
gradient-free. SlimDiff reframes DM compression as a spectral approximation
task, where activation covariances across denoising timesteps define low-rank
subspaces that guide dynamic pruning under a fixed compression budget. This
activation-aware formulation mitigates error accumulation across timesteps by
applying module-wise decompositions over functional weight groups: query--key
interactions, value--output couplings, and feedforward projections, rather than
isolated matrix factorizations, while adaptively allocating sparsity across
modules to respect the non-uniform geometry of diffusion trajectories. SlimDiff
achieves up to 35\% acceleration and $\sim$100M parameter reduction over
baselines, with generation quality on par with uncompressed models without any
backpropagation. Crucially, our approach requires only about 500 calibration
samples, over 70$\times$ fewer than prior methods. To our knowledge, this is
the first closed-form, activation-guided structural compression of DMs that is
entirely training-free, providing both theoretical clarity and practical
efficiency.

</details>


### [538] [Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.22601)
*Yulei Qin,Xiaoyu Tan,Zhengbao He,Gang Li,Haojia Lin,Zongyi Li,Zihan Xu,Yuchen Shi,Siqi Cai,Renting Rui,Shaofei Cai,Yuzheng Cai,Xuan Zhang,Sheng Ye,Ke Li,Xing Sun*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SPEAR的课程学习方法，通过结合自模仿学习（SIL）和内在奖励，来解决强化学习（RL）中长周期、稀疏奖励任务的探索-利用困境，旨在平衡探索和利用，稳定训练过程。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理长周期、稀疏奖励的任务时，面临探索-利用的困境，并且通过最大化策略熵来刺激探索的方法容易导致训练不稳定。

Method: SPEAR方法采用课程学习策略，结合自模仿学习（SIL）和内在奖励。在训练初期，利用辅助工具调用奖励来积累工具使用技能，并引导熵值向上增长。随着训练的进行，加强SIL以利用历史经验中的成功轨迹进行探索，从而加速解决方案的迭代，同时控制熵值的增长。此外，还通过重新校准经验回放缓冲区中的优势值、裁剪概率和优势之间协方差高的token以及轨迹级别的熵控制等正则化技术来稳定训练。

Result: 该方法能够在不陷入熵崩溃或发散的情况下，实现探索-利用的渐进平衡，并稳定训练过程。

Conclusion: SPEAR通过课程学习和自模仿学习的结合，有效解决了强化学习在长周期、稀疏奖励任务中的探索-利用难题，并提高了训练稳定性。

Abstract: Reinforcement learning (RL) is the dominant paradigm for sharpening strategic
tool use capabilities of LLMs on long-horizon, sparsely-rewarded agent tasks,
yet it faces a fundamental challenge of exploration-exploitation trade-off.
Existing studies stimulate exploration through the lens of policy entropy, but
such mechanical entropy maximization is prone to RL training instability due to
the multi-turn distribution shifting. In this paper, we target the progressive
exploration-exploitation balance under the guidance of the agent own
experiences without succumbing to either entropy collapsing or runaway
divergence. We propose SPEAR, a curriculum-based self-imitation learning (SIL)
recipe for training agentic LLMs. It extends the vanilla SIL framework, where a
replay buffer stores self-generated promising trajectories for off-policy
update, by gradually steering the policy evolution within a well-balanced range
of entropy across stages. Specifically, our approach incorporates a curriculum
to manage the exploration process, utilizing intrinsic rewards to foster
skill-level exploration and facilitating action-level exploration through SIL.
At first, the auxiliary tool call reward plays a critical role in the
accumulation of tool-use skills, enabling broad exposure to the unfamiliar
distributions of the environment feedback with an upward entropy trend. As
training progresses, self-imitation gets strengthened to exploit existing
successful patterns from replayed experiences for comparative action-level
exploration, accelerating solution iteration without unbounded entropy growth.
To further stabilize training, we recalibrate the advantages of experiences in
the replay buffer to address the potential policy drift. Reugularizations such
as the clipping of tokens with high covariance between probability and
advantage are introduced to the trajectory-level entropy control to curb
over-confidence.

</details>


### [539] [Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training](https://arxiv.org/abs/2509.21500)
*Junkai Zhang,Zihao Wang,Lin Gui,Swarnashree Mysore Sathyendra,Jaehwan Jeong,Victor Veitch,Wei Wang,Yunzhong He,Bing Liu,Lifeng Jin*

Main category: cs.LG

TL;DR: 强化微调（RFT）常因奖励过优化问题而苦苦挣扎，在这种情况下，策略模型会利用奖励信号来获得高分，但会产生低质量的输出。本文的理论分析表明，关键在于高奖励尾部的奖励错误指定：无法可靠地区分“优秀”响应和“良好”响应。这促使我们专注于高奖励区域。然而，这种尾部样本在基础 LLM 中很少见。虽然更容易获得离线策略示例（例如，来自更强的模型或改写），但对它们进行简单训练会为我们想要对齐的策略产生错误的奖励。为了解决这个问题，我们研究了基于评分标准的奖励。评分标准的设计可以利用离线示例，同时对其伪影不敏感。为了引出能够捕捉高奖励尾部的评分标准，我们强调了区分伟大且多样化的响应的重要性，并引入了一个工作流程来实现这一想法。我们的经验证明，基于评分标准的奖励在很大程度上可以缓解奖励过优化问题，并能有效地改进 LLM 的训练后表现。代码可从 https://github.com/Jun-Kai-Zhang/rubrics.git 访问。


<details>
  <summary>Details</summary>
Motivation: 奖励过优化问题，即策略模型通过利用奖励信号获得高分但产生低质量输出来进行奖励信号攻击。理论分析表明，这是由于在高奖励尾部区域存在奖励错误指定，导致无法可靠地区分“优秀”响应和“良好”响应。因此，需要专注于高奖励区域，但基础 LLM 中此类尾部样本稀少。

Method: 研究基于评分标准的奖励。评分标准的设计能够利用离线示例（例如，来自更强的模型或改写），同时对其伪影不敏感。通过强调区分伟大且多样化响应的重要性，并引入一个工作流程来实现这一想法，来引出能够捕捉高奖励尾部的评分标准。

Result: 基于评分标准的奖励能够显著缓解奖励过优化问题，并有效改进 LLM 的训练后表现。

Conclusion: 基于评分标准的奖励是一种有效的方法，可以缓解强化微调中的奖励过优化问题，并提高 LLM 的性能。该方法通过利用评分标准来处理稀疏的高奖励尾部数据，并区分不同质量的响应。

Abstract: Reinforcement fine-tuning (RFT) often suffers from \emph{reward
over-optimization}, where a policy model hacks the reward signals to achieve
high scores while producing low-quality outputs. Our theoretical analysis shows
that the key lies in reward misspecification at the high-reward tail: the
inability to reliably distinguish Excellent responses from merely Great ones.
This motivate us to focus on the high-reward region. However, such tail
examples are scarce under the base LLM. While off-policy exemplars (e.g. from
stronger models or rewrites) are easier to obtain, naively training on them
yields a misspecified reward for the policy we aim to align. To address this,
we study rubric-based rewards. By design, rubrics can leverage off-policy
examples while remaining insensitive to their artifacts. To elicit rubrics that
capture the high-reward tail, we highlight the importance of distinguishing
among great and diverse responses, and introduce a workflow to implement this
idea. We empirically demonstrate that rubric-based rewards substantially
mitigate reward over-optimization and deliver effective LLM post-training
improvements. Our code can be accessed at
https://github.com/Jun-Kai-Zhang/rubrics.git .

</details>


### [540] [Contrastive Mutual Information Learning: Toward Robust Representations without Positive-Pair Augmentations](https://arxiv.org/abs/2509.21511)
*Micha Livne*

Main category: cs.LG

TL;DR: cMIM是一个结合了对比学习和MIM的概率框架，通过引入全局判别结构来解决MIM在判别任务上的不足，同时保持其生成保真度。它不需要正样本增强，对批量大小不敏感，并通过引入“信息嵌入”技术提高了判别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的表示学习方法（对比学习、自监督掩码、去噪自编码器）在将表示泛化到不同下游任务方面存在权衡。MIM虽然最大化输入和潜在变量之间的互信息并促进代码聚类，但在判别任务上表现不佳。

Method: 提出了一种名为对比互信息机（cMIM）的概率框架，该框架扩展了互信息机（MIM），并增加了一个对比目标。cMIM通过施加全局判别结构来解决MIM在判别任务上的不足，同时保留MIM的生成保真度。还引入了一种名为“信息嵌入”的一般技术，用于从编码器-解码器模型中提取增强特征。

Result: cMIM在视觉和分子基准测试中，在分类和回归任务上的表现优于MIM和InfoNCE，同时保持了有竞争力的重建质量。

Conclusion: cMIM是一个统一的表示学习框架，能够同时有效地服务于判别和生成应用。

Abstract: Learning representations that transfer well to diverse downstream tasks
remains a central challenge in representation learning. Existing paradigms --
contrastive learning, self-supervised masking, and denoising auto-encoders --
balance this challenge with different trade-offs. We introduce the {contrastive
Mutual Information Machine} (cMIM), a probabilistic framework that extends the
Mutual Information Machine (MIM) with a contrastive objective. While MIM
maximizes mutual information between inputs and latents and promotes clustering
of codes, it falls short on discriminative tasks. cMIM addresses this gap by
imposing global discriminative structure while retaining MIM's generative
fidelity. Our contributions are threefold. First, we propose cMIM, a
contrastive extension of MIM that removes the need for positive data
augmentation and is substantially less sensitive to batch size than InfoNCE.
Second, we introduce {informative embeddings}, a general technique for
extracting enriched features from encoder-decoder models that boosts
discriminative performance without additional training and applies broadly
beyond MIM. Third, we provide empirical evidence across vision and molecular
benchmarks showing that cMIM outperforms MIM and InfoNCE on classification and
regression tasks while preserving competitive reconstruction quality. These
results position cMIM as a unified framework for representation learning,
advancing the goal of models that serve both discriminative and generative
applications effectively.

</details>


### [541] [DistillKac: Few-Step Image Generation via Damped Wave Equations](https://arxiv.org/abs/2509.21513)
*Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon*

Main category: cs.LG

TL;DR: DistillKac是一种基于阻尼波动方程和Kac随机表示的快速图像生成器，其特点是概率质量以有限速度移动，与扩散模型不同。它通过在速度空间中引入分类器无关引导和端点蒸馏，实现了高样本质量和数值稳定性。


<details>
  <summary>Details</summary>
Motivation: 与扩散模型相比，当前的生成模型在反向传播速度时可能出现僵硬且速度无界的情况。Kac动力学通过强制有限速度传输并产生全局有界动能来解决这个问题。

Method: 提出使用阻尼波动方程及其随机Kac表示来移动概率质量，实现有限速度传输。引入了速度空间中的分类器无关引导，以及仅使用端点的蒸馏方法来训练学生模型匹配冻结的教师模型。证明了在端点进行监督可以促进整个路径的接近性。

Result: DistillKac在极少的函数评估次数下生成了高质量的样本，并保持了有限速度概率流的数值稳定性。

Conclusion: DistillKac通过其新颖的动力学和蒸馏方法，在图像生成领域取得了显著进展，解决了现有模型在速度和稳定性方面存在的问题。

Abstract: We present DistillKac, a fast image generator that uses the damped wave
equation and its stochastic Kac representation to move probability mass at
finite speed. In contrast to diffusion models whose reverse time velocities can
become stiff and implicitly allow unbounded propagation speed, Kac dynamics
enforce finite speed transport and yield globally bounded kinetic energy.
Building on this structure, we introduce classifier-free guidance in velocity
space that preserves square integrability under mild conditions. We then
propose endpoint only distillation that trains a student to match a frozen
teacher over long intervals. We prove a stability result that promotes
supervision at the endpoints to closeness along the entire path. Experiments
demonstrate DistillKac delivers high quality samples with very few function
evaluations while retaining the numerical stability benefits of finite speed
probability flows.

</details>


### [542] [Uncertainty-Aware Knowledge Tracing Models](https://arxiv.org/abs/2509.21514)
*Joshua Mitton,Prarthana Bhattacharyya,Ralph Abboud,Simon Woodhead*

Main category: cs.LG

TL;DR: 知识追踪模型通过捕捉预测不确定性来提高对学生错误的检测能力，尤其是在资源有限的情况下，这对于教育平台很有用。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪模型在学生选择干扰项时预测不准确，导致学生错误未被发现。本研究旨在通过捕捉预测不确定性来增强知识追踪模型的能力。

Method: 提出一种方法来增强知识追踪模型，通过捕捉预测不确定性，并证明预测不确定性与模型预测错误相关。

Result: 研究表明，知识追踪模型中的不确定性信号信息丰富，并且这种信号可以用于资源有限的教育学习平台，以了解学生能力。

Conclusion: 知识追踪模型中的预测不确定性信号对于识别学生错误和在资源有限的环境中进行教学干预具有重要价值。

Abstract: The main focus of research on Knowledge Tracing (KT) models is on model
developments with the aim of improving predictive accuracy. Most of these
models make the most incorrect predictions when students choose a distractor,
leading to student errors going undetected. We present an approach to add new
capabilities to KT models by capturing predictive uncertainty and demonstrate
that a larger predictive uncertainty aligns with model incorrect predictions.
We show that uncertainty in KT models is informative and that this signal would
be pedagogically useful for application in an educational learning platform
that can be used in a limited resource setting where understanding student
ability is necessary.

</details>


### [543] [$\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization](https://arxiv.org/abs/2509.21519)
*Yuandong Tian*

Main category: cs.LG

TL;DR: Grokking是一种延迟泛化现象，已得到广泛研究。本文提出了一个名为Li2的新框架，用于表征两层非线性网络中Grokking行为的三个关键阶段：(I) 懒惰学习，(II) 独立特征学习，(III) 交互特征学习。该框架通过反向传播梯度GF的结构来表征这些阶段。在阶段(I)中，GF是随机的，顶层对随机的隐藏表示有过拟合。在阶段(II)中，每个节点的梯度仅取决于其自身的激活，并且每个隐藏节点独立地从GF中学习其表示，GF现在携带目标标签的信息，这要归功于权重衰减。有趣的是，独立动力学精确地遵循能量函数E的梯度上升，其局部最大值正是出现的特征。我们研究了这些由局部最优引起的特征是否可泛化，它们的表示能力，以及它们如何随着样本量在组算术任务中变化。最后，在阶段(III)中，我们可证明地展示了隐藏节点如何交互，以及GF如何改变以关注需要学习的缺失特征。我们的研究阐明了权重衰减、学习率和样本量等关键超参数在Grokking中所起的作用，得出了可证明的记忆和泛化缩放定律，并揭示了像Muon这样的优化器为何有效的根本原因，这是基于梯度动力学的第一性原理。我们的分析可以扩展到多层架构。


<details>
  <summary>Details</summary>
Motivation: Grokking，即延迟泛化，虽然得到了广泛研究，但仍然是一个悬而未决的问题，即是否存在一个数学框架来表征在复杂结构化输入的训练中，什么样的特征会以何种方式以及在何种条件下出现。

Method: 提出一个名为Li2的新框架，该框架通过反向传播梯度GF的结构，表征了两层非线性网络中Grokking行为的三个关键阶段：(I) 懒惰学习，(II) 独立特征学习，(III) 交互特征学习。在阶段(II)中，研究了由局部最优引起的特征是否可泛化，它们的表示能力，以及它们如何随着样本量在组算术任务中变化。在阶段(III)中，可证明地展示了隐藏节点如何交互，以及GF如何改变以关注需要学习的缺失特征。

Result: 在阶段(I)中，GF是随机的，顶层对随机的隐藏表示有过拟合。在阶段(II)中，每个节点的梯度仅取决于其自身的激活，并且每个隐藏节点独立地从GF中学习其表示，GF现在携带目标标签的信息，这要归功于权重衰减。独立动力学精确地遵循能量函数E的梯度上升，其局部最大值正是出现的特征。在阶段(III)中，隐藏节点会交互，GF会改变以关注需要学习的缺失特征。

Conclusion: Li2框架阐明了权重衰减、学习率和样本量等关键超参数在Grokking中所起的作用，得出了可证明的记忆和泛化缩放定律，并揭示了像Muon这样的优化器为何有效的根本原因，这是基于梯度动力学的第一性原理。该分析可以扩展到多层架构。

Abstract: While the phenomenon of grokking, i.e., delayed generalization, has been
studied extensively, it remains an open question whether there is a
mathematical framework to characterize what kind of features emerge, how and in
which conditions it happens from training, for complex structured inputs. We
propose a novel framework, named $\mathbf{Li_2}$, that captures three key
stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy
learning, (II) independent feature learning and (III) interactive feature
learning, characterized by the structure of backpropagated gradient $G_F$
across layers. In (I), $G_F$ is random, and top layer overfits to random hidden
representation. In (II), the gradient of each node (column of $G_F$) only
depends on its own activation, and thus each hidden node learns their
representation independently from $G_F$, which now carries information about
target labels, thanks to weight decay. Interestingly, the independent dynamics
follows exactly the gradient ascent of an energy function $E$, and its local
maxima are precisely the emerging features. We study whether these local-optima
induced features are generalizable, their representation power, and how they
change on sample size, in group arithmetic tasks. Finally, in (III), we
provably show how hidden nodes interact, and how $G_F$ changes to focus on
missing features that need to be learned. Our study sheds lights on roles
played by key hyperparameters such as weight decay, learning rate and sample
sizes in grokking, leads to provable scaling laws of memorization and
generalization, and reveals the underlying cause why recent optimizers such as
Muon can be effective, from the first principles of gradient dynamics. Our
analysis can be extended to multi-layer architectures.

</details>


### [544] [TRiCo: Triadic Game-Theoretic Co-Training for Robust Semi-Supervised Learning](https://arxiv.org/abs/2509.21526)
*Hongyang He,Xinyuan Song,Yangfan He,Zeyu Zhang,Yanshu Li,Haochen You,Lifan Sun,Wenqiao Zhang*

Main category: cs.LG

TL;DR: TRiCo是一个新颖的三角博弈论协同训练框架，通过整合教师、两个学生和一个对抗性生成器来重新构建半监督学习，并宣称在低标签场景下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的协同训练和师生方法在处理静态视图交互、不可靠的伪标签和缺乏硬样本建模方面存在局限性，TRiCo旨在解决这些问题。

Method: TRiCo提出一个由教师、两个学生和一个对抗性生成器组成的三角博弈论框架。学生分类器在冻结的、互补的表示上进行训练。元学习的教师通过基于验证的反馈自适应地调节伪标签选择和损失平衡。非参数生成器通过扰动嵌入来暴露决策边界的弱点。伪标签的选择基于互信息而不是置信度，并使用Stackelberg博弈来形式化这种三角交互。

Result: 在CIFAR-10、SVHN、STL-10和ImageNet上的大量实验表明，TRiCo在低标签场景下始终 achieves state-of-the-art性能，并且不依赖于特定架构，可与冻结的视觉骨干网络兼容。

Conclusion: TRiCo通过解决现有半监督学习框架的关键局限性，提供了一个原则性强且可推广的解决方案，在低标签场景下实现了最先进的性能，并且具有架构无关性和兼容性。

Abstract: We introduce TRiCo, a novel triadic game-theoretic co-training framework that
rethinks the structure of semi-supervised learning by incorporating a teacher,
two students, and an adversarial generator into a unified training paradigm.
Unlike existing co-training or teacher-student approaches, TRiCo formulates SSL
as a structured interaction among three roles: (i) two student classifiers
trained on frozen, complementary representations, (ii) a meta-learned teacher
that adaptively regulates pseudo-label selection and loss balancing via
validation-based feedback, and (iii) a non-parametric generator that perturbs
embeddings to uncover decision boundary weaknesses. Pseudo-labels are selected
based on mutual information rather than confidence, providing a more robust
measure of epistemic uncertainty. This triadic interaction is formalized as a
Stackelberg game, where the teacher leads strategy optimization and students
follow under adversarial perturbations. By addressing key limitations in
existing SSL frameworks, such as static view interactions, unreliable
pseudo-labels, and lack of hard sample modeling, TRiCo provides a principled
and generalizable solution. Extensive experiments on CIFAR-10, SVHN, STL-10,
and ImageNet demonstrate that TRiCo consistently achieves state-of-the-art
performance in low-label regimes, while remaining architecture-agnostic and
compatible with frozen vision backbones.

</details>


### [545] [Preemptive Detection and Steering of LLM Misalignment via Latent Reachability](https://arxiv.org/abs/2509.21528)
*Sathwik Karnik,Somil Bansal*

Main category: cs.LG

TL;DR: BRT-Align是一个基于可达性的框架，通过在推理时使用控制理论安全工具来解决大型语言模型（LLMs）的安全问题，它能提前检测并阻止不安全内容的生成，同时保持生成文本的多样性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在日常工具中的普及，其生成有害内容的倾向引发了紧迫的安全担忧。现有的基于人类反馈的强化学习（RLHF）方法虽然在训练时能有效引导模型行为，但在推理时缺乏保障，仍可能产生不安全的内容。

Method: BRT-Align将自回归生成建模为潜在空间中的动态系统，并通过后向可达性学习安全价值函数，估计轨迹的最坏情况演变。这实现了两个互补的机制：一个运行时监视器，能提前预测不安全内容；一个限制性最小的引导滤波器，能最小化扰动潜在状态以将生成引导至安全区域。

Result: 实验表明，BRT-Align在多个LLMs和毒性基准测试中，能够比基线方法更准确、更早地检测到不安全内容的生成。此外，BRT-Align在LLM安全对齐方面，显著减少了不安全内容的生成，同时保持了句子的多样性和连贯性。定性结果还显示，BRT-Align能够生成暴力、亵渎、冒犯性和政治偏见更少的回应。

Conclusion: BRT-Align的实验结果证明，可达性分析为推理时的LLM安全提供了原则性和实用性的基础。

Abstract: Large language models (LLMs) are now ubiquitous in everyday tools, raising
urgent safety concerns about their tendency to generate harmful content. The
dominant safety approach -- reinforcement learning from human feedback (RLHF)
-- effectively shapes model behavior during training but offers no safeguards
at inference time, where unsafe continuations may still arise. We propose
BRT-Align, a reachability-based framework that brings control-theoretic safety
tools to LLM inference. BRT-Align models autoregressive generation as a
dynamical system in latent space and learn a safety value function via backward
reachability, estimating the worst-case evolution of a trajectory. This enables
two complementary mechanisms: (1) a runtime monitor that forecasts unsafe
completions several tokens in advance, and (2) a least-restrictive steering
filter that minimally perturbs latent states to redirect generation away from
unsafe regions. Experiments across multiple LLMs and toxicity benchmarks
demonstrate that BRT-Align provides more accurate and earlier detection of
unsafe continuations than baselines. Moreover, for LLM safety alignment,
BRT-Align substantially reduces unsafe generations while preserving sentence
diversity and coherence. Qualitative results further highlight emergent
alignment properties: BRT-Align consistently produces responses that are less
violent, less profane, less offensive, and less politically biased. Together,
these findings demonstrate that reachability analysis provides a principled and
practical foundation for inference-time LLM safety.

</details>


### [546] [Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration](https://arxiv.org/abs/2509.21530)
*Dongkyu Cho,Miao Zhang,Rumi Chunara*

Main category: cs.LG

TL;DR: 通过结合领域专业知识，提出一种新的查询模型协作框架，以提高 LLM 在医疗保健等高风险领域的数据增强能力，同时降低事实性错误。


<details>
  <summary>Details</summary>
Motivation: LLM 在数据增强方面具有潜力，但在医疗保健等高风险领域存在生成不正确或误导性信息的风险。需要一种方法来弥合 LLM 增强潜力与专业领域安全要求之间的差距。

Method: 提出一种查询模型协作框架，该框架整合了专家级别的领域知识来指导数据增强过程，以保留关键的医疗信息。

Result: 在临床预测任务上的实验表明，该方法在提高模型鲁棒性和泛化能力的同时，通过减少事实性错误来提高安全性，并且优于现有的 LLM 增强方法。

Conclusion: 所提出的轻量级协作方法能够有效指导 LLM 在高风险领域进行数据增强，在保持增强模型性能的同时，确保了临床信息的准确性。

Abstract: Data augmentation is a widely used strategy to improve model robustness and
generalization by enriching training datasets with synthetic examples. While
large language models (LLMs) have demonstrated strong generative capabilities
for this purpose, their applications in high-stakes domains like healthcare
present unique challenges due to the risk of generating clinically incorrect or
misleading information. In this work, we propose a novel query-based model
collaboration framework that integrates expert-level domain knowledge to guide
the augmentation process to preserve critical medical information. Experiments
on clinical prediction tasks demonstrate that our lightweight
collaboration-based approach consistently outperforms existing LLM augmentation
methods while improving safety through reduced factual errors. This framework
addresses the gap between LLM augmentation potential and the safety
requirements of specialized domains.

</details>


### [547] [A circuit for predicting hierarchical structure in-context in Large Language Models](https://arxiv.org/abs/2509.21534)
*Tankred Saanum,Can Demircan,Samuel J. Gershman,Eric Schulz*

Main category: cs.LG

TL;DR: LLMs 的归纳头在学习预测更复杂的、具有层级结构的回文模式方面发挥着作用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在情境学习方面表现出色，但尚不清楚它们是否能利用归纳头来处理具有层级结构的回文模式。

Method: 设计了一个合成的情境学习任务，其中标记以层级依赖性重复出现。评估了一系列 LLM 在这些标记序列和自然语言类似物上的表现，并研究了归纳头是如何学习情境的。

Result: LLM 确实拥有能够处理更复杂的回文模式的归纳头，它们通过学习情境来调整注意力。这种学习过程涉及注意力头，它们会揭示一组潜在的情境，从而确定不同的标记转换关系。

Conclusion: LLM 拥有会学习的归纳头，能够提供一套完整的机制来解释 LLM 在情境中学习预测高阶回文模式的能力。

Abstract: Large Language Models (LLMs) excel at in-context learning, the ability to use
information provided as context to improve prediction of future tokens.
Induction heads have been argued to play a crucial role for in-context learning
in Transformer Language Models. These attention heads make a token attend to
successors of past occurrences of the same token in the input. This basic
mechanism supports LLMs' ability to copy and predict repeating patterns.
However, it is unclear if this same mechanism can support in-context learning
of more complex repetitive patterns with hierarchical structure. Natural
language is teeming with such cases: The article "the" in English usually
prefaces multiple nouns in a text. When predicting which token succeeds a
particular instance of "the", we need to integrate further contextual cues from
the text to predict the correct noun. If induction heads naively attend to all
past instances of successor tokens of "the" in a context-independent manner,
they cannot support this level of contextual information integration. In this
study, we design a synthetic in-context learning task, where tokens are
repeated with hierarchical dependencies. Here, attending uniformly to all
successor tokens is not sufficient to accurately predict future tokens.
Evaluating a range of LLMs on these token sequences and natural language
analogues, we find adaptive induction heads that support prediction by learning
what to attend to in-context. Next, we investigate how induction heads
themselves learn in-context. We find evidence that learning is supported by
attention heads that uncover a set of latent contexts, determining the
different token transition relationships. Overall, we not only show that LLMs
have induction heads that learn, but offer a complete mechanistic account of
how LLMs learn to predict higher-order repetitive patterns in-context.

</details>


### [548] [Evidence for Limited Metacognition in LLMs](https://arxiv.org/abs/2509.21545)
*Christopher Ackerman*

Main category: cs.LG

TL;DR: LLM元认知能力的评估方法和结果


<details>
  <summary>Details</summary>
Motivation: LLM自我意识和感知能力日益受到关注，但缺乏科学的测量方法。

Method: 提出一种新的量化评估LLM元认知能力的方法，借鉴动物元认知研究，不依赖模型自我报告，而是测试模型利用内部状态知识的策略性，并通过实验范式和模型输出的token概率进行分析。

Result: 自2024年初推出的前沿LLM在评估和利用回答事实和推理问题的置信度、以及预期自身回答并利用该信息方面表现出日益增强的元认知能力；这些能力分辨率有限、依赖情境、且与人类的认知方式不同；不同模型间存在差异，表明LLM训练后处理可能影响元认知能力的发展。

Conclusion:  frontier LLMs are showing increasing evidence of metacognitive abilities, suggesting a potential path towards understanding and measuring these complex cognitive functions, while also highlighting the need for further research into their limitations and differences from human cognition.

Abstract: The possibility of LLM self-awareness and even sentience is gaining
increasing public attention and has major safety and policy implications, but
the science of measuring them is still in a nascent state. Here we introduce a
novel methodology for quantitatively evaluating metacognitive abilities in
LLMs. Taking inspiration from research on metacognition in nonhuman animals,
our approach eschews model self-reports and instead tests to what degree models
can strategically deploy knowledge of internal states. Using two experimental
paradigms, we demonstrate that frontier LLMs introduced since early 2024 show
increasingly strong evidence of certain metacognitive abilities, specifically
the ability to assess and utilize their own confidence in their ability to
answer factual and reasoning questions correctly and the ability to anticipate
what answers they would give and utilize that information appropriately. We
buttress these behavioral findings with an analysis of the token probabilities
returned by the models, which suggests the presence of an upstream internal
signal that could provide the basis for metacognition. We further find that
these abilities 1) are limited in resolution, 2) emerge in context-dependent
manners, and 3) seem to be qualitatively different from those of humans. We
also report intriguing differences across models of similar capabilities,
suggesting that LLM post-training may have a role in developing metacognitive
abilities.

</details>


### [549] [Machine Learning. The Science of Selection under Uncertainty](https://arxiv.org/abs/2509.21547)
*Yevgeny Seldin*

Main category: cs.LG

TL;DR: 本篇论文提出了用于机器学习的统计工具，以处理选择不确定性问题，并通过各种不等式和分析方法（包括PAC-贝叶斯分析）来推导泛化界限，最终在在线学习的背景下解决遗憾问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的学习过程是从候选选项中选择更优的选项，而数据采样中的随机性会导致选择的不确定性。因此，需要统计工具来获得理论保证。

Method: 论文首先介绍了浓度不等式（包括马尔可夫、切比雪夫、霍夫丁、伯恩斯坦、经验伯恩斯坦、意外伯恩斯坦、kl和split-kl不等式），然后研究了经典监督学习，并提出了奥卡姆剃刀、VC分析和PAC-贝叶斯分析等工具来推导泛化界限。最后，论文转向在线学习，讨论了环境反馈、环境阻力和结构复杂性等在线学习问题的特征，并提出了在随机和对抗性环境、全信息和多臂老虎机反馈下推导遗憾界限的工具。

Result: 论文提供了统计工具来获得选择不确定性下的理论保证，并成功应用于推导经典监督学习和在线学习的泛化界限和遗憾界限。

Conclusion: 本篇论文为理解和解决机器学习中的选择不确定性问题提供了坚实的统计基础，并为在线学习中的遗憾最小化提供了有效的分析方法。

Abstract: Learning, whether natural or artificial, is a process of selection. It starts
with a set of candidate options and selects the more successful ones. In the
case of machine learning the selection is done based on empirical estimates of
prediction accuracy of candidate prediction rules on some data. Due to
randomness of data sampling the empirical estimates are inherently noisy,
leading to selection under uncertainty. The book provides statistical tools to
obtain theoretical guarantees on the outcome of selection under uncertainty. We
start with concentration of measure inequalities, which are the main
statistical instrument for controlling how much an empirical estimate of
expectation of a function deviates from the true expectation. The book covers a
broad range of inequalities, including Markov's, Chebyshev's, Hoeffding's,
Bernstein's, Empirical Bernstein's, Unexpected Bernstein's, kl, and split-kl.
We then study the classical (offline) supervised learning and provide a range
of tools for deriving generalization bounds, including Occam's razor,
Vapnik-Chervonenkis analysis, and PAC-Bayesian analysis. The latter is further
applied to derive generalization guarantees for weighted majority votes. After
covering the offline setting, we turn our attention to online learning. We
present the space of online learning problems characterized by environmental
feedback, environmental resistance, and structural complexity. A common
performance measure in online learning is regret, which compares performance of
an algorithm to performance of the best prediction rule in hindsight, out of a
restricted set of prediction rules. We present tools for deriving regret bounds
in stochastic and adversarial environments, and under full information and
bandit feedback.

</details>


### [550] [Interpretable time series analysis with Gumbel dynamics](https://arxiv.org/abs/2509.21578)
*Yiliu Wang,Timothy Doyeon Kim,Eric Shea-Brown,Uygar Sümbül*

Main category: cs.LG

TL;DR: GDM通过引入连续松弛和Gumbel噪声模型来改进开关动力系统，从而更准确地捕捉平滑、非平稳和随机的动力学，并且训练效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有的开关动力系统虽然能通过推断有限的动力学原语来解释时间序列数据，但在捕捉平滑、变速转换以及重叠状态的随机混合方面存在困难，并且在真实世界数据上常常表现出虚假的快速切换。

Method: 提出Gumbel动力模型（GDM），其核心在于引入离散状态的连续松弛以及在松弛后的离散状态空间上定义基于Gumbel分布的噪声模型。这种方法使得模型能够近似更平滑、非平稳的真实动力学，并且由于模型完全可微，可以使用标准的梯度下降方法进行快速、可扩展的训练。

Result: GDM在标准模拟数据集上得到了验证，能够更好地模拟软性、粘性状态以及随机环境下的转换。此外，GDM在两个真实世界数据集上的应用表明，它能够推断出随机时间序列中具有多种动力学的可解释状态，克服了传统方法在此类场景下的局限性。

Conclusion: GDM通过连续松弛和Gumbel噪声模型，有效解决了现有开关动力系统在处理平滑转换、随机混合和真实世界数据上的不足，提高了模型在复杂时间序列建模和解释方面的能力。

Abstract: Switching dynamical systems can model complicated time series data while
maintaining interpretability by inferring a finite set of dynamics primitives
and explaining different portions of the observed time series with one of these
primitives. However, due to the discrete nature of this set, such models
struggle to capture smooth, variable-speed transitions, as well as stochastic
mixtures of overlapping states, and the inferred dynamics often display
spurious rapid switching on real-world datasets. Here, we propose the Gumbel
Dynamical Model (GDM). First, by introducing a continuous relaxation of
discrete states and a different noise model defined on the relaxed-discrete
state space via the Gumbel distribution, GDM expands the set of available state
dynamics, allowing the model to approximate smoother and non-stationary
ground-truth dynamics more faithfully. Second, the relaxation makes the model
fully differentiable, enabling fast and scalable training with standard
gradient descent methods. We validate our approach on standard simulation
datasets and highlight its ability to model soft, sticky states and transitions
in a stochastic setting. Furthermore, we apply our model to two real-world
datasets, demonstrating its ability to infer interpretable states in stochastic
time series with multiple dynamics, a setting where traditional methods often
fail.

</details>


### [551] [Leveraging Big Data Frameworks for Spam Detection in Amazon Reviews](https://arxiv.org/abs/2509.21579)
*Mst Eshita Khatun,Halima Akter,Tasnimul Rehan,Toufiq Ahmed*

Main category: cs.LG

TL;DR: 本研究利用大数据和机器学习技术，对亚马逊商品评论进行分析，以识别和分类垃圾评论，提高了在线购物评论的真实性。


<details>
  <summary>Details</summary>
Motivation: 在线购物评论的泛滥损害了消费者信任和卖家声誉，需要检测欺诈性评论。

Method: 使用大数据分析和机器学习方法，处理了大量的亚马逊商品评论数据，提取了欺诈行为的特征，并使用了逻辑回归等分类器。

Result: 逻辑回归分类器在检测垃圾评论方面达到了90.35%的准确率。

Conclusion: 该研究通过机器学习提高了在线购物评论的透明度和可信度，最终为消费者提供了更可靠的购物环境。

Abstract: In this digital era, online shopping is common practice in our daily lives.
Product reviews significantly influence consumer buying behavior and help
establish buyer trust. However, the prevalence of fraudulent reviews undermines
this trust by potentially misleading consumers and damaging the reputations of
the sellers. This research addresses this pressing issue by employing advanced
big data analytics and machine learning approaches on a substantial dataset of
Amazon product reviews. The primary objective is to detect and classify spam
reviews accurately so that it enhances the authenticity of the review. Using a
scalable big data framework, we efficiently process and analyze a large scale
of review data, extracting key features indicative of fraudulent behavior. Our
study illustrates the utility of various machine learning classifiers in
detecting spam reviews, with Logistic Regression achieving an accuracy of
90.35%, thus contributing to a more trustworthy and transparent online shopping
environment.

</details>


### [552] [Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection](https://arxiv.org/abs/2509.21606)
*Seohyeon Cha,Huancheng Chen,Haris Vikalo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Federated continual learning (FCL) enables distributed client devices to
learn from streaming data across diverse and evolving tasks. A major challenge
to continual learning, catastrophic forgetting, is exacerbated in decentralized
settings by the data heterogeneity, constrained communication and privacy
concerns. We propose Federated gradient Projection-based Continual Learning
with Task Identity Prediction (FedProTIP), a novel FCL framework that mitigates
forgetting by projecting client updates onto the orthogonal complement of the
subspace spanned by previously learned representations of the global model.
This projection reduces interference with earlier tasks and preserves
performance across the task sequence. To further address the challenge of
task-agnostic inference, we incorporate a lightweight mechanism that leverages
core bases from prior tasks to predict task identity and dynamically adjust the
global model's outputs. Extensive experiments across standard FCL benchmarks
demonstrate that FedProTIP significantly outperforms state-of-the-art methods
in average accuracy, particularly in settings where task identities are a
priori unknown.

</details>


### [553] [Causal Abstraction Inference under Lossy Representations](https://arxiv.org/abs/2509.21607)
*Kevin Xia,Elias Bareinboim*

Main category: cs.LG

TL;DR: 本文提出了一种名为“投影抽象”的新型抽象方法，解决了现有因果抽象方法在处理有损抽象函数时的局限性，并证明了其在图像识别等高维数据设置中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有因果抽象方法在处理有损抽象函数时存在局限性，即多个低层干预可能映射到同一个高层干预，但产生不同效果，未能满足抽象不变性条件。

Method: 提出了一种名为“投影抽象”的新型抽象方法，该方法能够处理有损抽象函数，并能将低层因果查询（观察性、干预性、反事实性）等价地转换为高层查询。此外，还提出了一种新的图标准，用于从有限的低层数据中识别和估计高层因果查询。

Result: 在理论上，证明了投影抽象的有效性，并提出了从低层数据估计高层因果查询的新图标准。在实验中，验证了投影抽象模型在高维图像设置中的有效性。

Conclusion: 投影抽象是一种有效的方法，可以处理有损表示，并将因果查询从低层模型转换为高层模型，为因果推理提供了新的视角和工具。

Abstract: The study of causal abstractions bridges two integral components of human
intelligence: the ability to determine cause and effect, and the ability to
interpret complex patterns into abstract concepts. Formally, causal abstraction
frameworks define connections between complicated low-level causal models and
simple high-level ones. One major limitation of most existing definitions is
that they are not well-defined when considering lossy abstraction functions in
which multiple low-level interventions can have different effects while mapping
to the same high-level intervention (an assumption called the abstract
invariance condition). In this paper, we introduce a new type of abstractions
called projected abstractions that generalize existing definitions to
accommodate lossy representations. We show how to construct a projected
abstraction from the low-level model and how it translates equivalent
observational, interventional, and counterfactual causal queries from low to
high-level. Given that the true model is rarely available in practice we prove
a new graphical criteria for identifying and estimating high-level causal
queries from limited low-level data. Finally, we experimentally show the
effectiveness of projected abstraction models in high-dimensional image
settings.

</details>


### [554] [PreLoRA: Hybrid Pre-training of Vision Transformers with Full Training and Low-Rank Adapters](https://arxiv.org/abs/2509.21619)
*Krishu K Thapa,Reet Barik,Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.LG

TL;DR: 在训练大型模型时，我们提出一种动态切换到低秩适应（LoRA）的方法，以在模型收敛后减少可训练参数数量，从而提高训练效率并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型模型训练成本高昂，且大部分学习发生在训练初期，后期权重变化趋于稳定，可以用低秩矩阵表示。

Method: 提出一种动态切换到LoRA的方法，允许用户通过超参数定义切换点，并为每个模块层分配特定秩。

Result: 在ViT-Large模型上，该方法将可训练参数减少到原来的10%，训练吞吐量提高2倍，平均训练时间减少1.5倍，GPU内存消耗降低20%，同时保持模型准确性。

Conclusion: 该方法在保持模型准确性的前提下，显著提高了大型模型的训练效率，降低了计算资源需求。

Abstract: Training large models ranging from millions to billions of parameters is
highly resource-intensive, requiring significant time, compute, and memory. It
is observed that most of the learning (higher change in weights) takes place in
the earlier stage of the training loop. These changes stabilize as training
continues, enabling them to be captured by matrices of a low intrinsic rank.
Therefore, we propose an approach to identify such states of partial
convergence and dynamically switch from full parameter training to Low-Rank
Adaptation (LoRA) on the ViT-Large model. We introduce a flexible approach that
leverages user-defined hyperparameters to determine the switching point and
assign a rank specific to each module layer based on its level of convergence.
Experimental results show that this approach preserves model accuracy while
reducing the number of trainable parameters to 10% of its original size,
resulting in a 3x improvement in throughput, and a 1.5x reduction in average
training time per epoch while also reducing GPU memory consumption by 20%

</details>


### [555] [Shoot from the HIP: Hessian Interatomic Potentials without derivatives](https://arxiv.org/abs/2509.21624)
*Andreas Burger,Luca Thiede,Nikolaj Rønne,Varinia Bernales,Nandita Vijaykumar,Tejs Vegge,Arghya Bhowmik,Alan Aspuru-Guzik*

Main category: cs.LG

TL;DR: 深度学习模型可直接预测分子Hessians，速度更快、精度更高、扩展性更好。


<details>
  <summary>Details</summary>
Motivation: 计算化学中的关键任务（如过渡态搜索和振动分析）依赖于计算成本高昂且难以扩展的分子Hessians。需要更有效的方法来计算Hessians。

Method: 提出了一种基于SE(3)等变和对称性的图神经网络模型（HIP），直接从不可约表示特征预测Hessians，无需自动微分或有限差分。

Result: HIP模型比传统方法快1-2个数量级，更准确，内存效率更高，训练更容易，扩展性更好。在过渡态搜索、加速几何优化、零点能校正和振动分析等任务上表现优越。

Conclusion: HIP模型为直接预测Hessians提供了一种高效且可扩展的解决方案，有望推动计算化学领域的发展。

Abstract: Fundamental tasks in computational chemistry, from transition state search to
vibrational analysis, rely on molecular Hessians, which are the second
derivatives of the potential energy. Yet, Hessians are computationally
expensive to calculate and scale poorly with system size, with both quantum
mechanical methods and neural networks. In this work, we demonstrate that
Hessians can be predicted directly from a deep learning model, without relying
on automatic differentiation or finite differences. We observe that one can
construct SE(3)-equivariant, symmetric Hessians from irreducible
representations (irrep) features up to degree $l$=2 computed during message
passing in graph neural networks. This makes HIP Hessians one to two orders of
magnitude faster, more accurate, more memory efficient, easier to train, and
enables more favorable scaling with system size. We validate our predictions
across a wide range of downstream tasks, demonstrating consistently superior
performance for transition state search, accelerated geometry optimization,
zero-point energy corrections, and vibrational analysis benchmarks. We
open-source the HIP codebase and model weights to enable further development of
the direct prediction of Hessians at https://github.com/BurgerAndreas/hip

</details>


### [556] [Blockwise Hadamard high-Rank Adaptation for Parameter-Efficient LLM Fine-Tuning](https://arxiv.org/abs/2509.21637)
*Feng Yu,Jia Hu,Geyong Min*

Main category: cs.LG

TL;DR: BHRA是一种参数高效微调（PEFT）方法，通过在每个权重矩阵块内独立应用HiRA风格的乘法调制，克服了LoRA和HiRA的局限性，实现了局部秩提升，并在多项推理任务中超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（PEFT）方法，如LoRA，在处理异构推理转换时受限于名义秩r。HiRA等Hadamard风格的扩展虽然提高了名义秩，但将每个更新与冻结权重矩阵的全局能量模式耦合。ABBA虽然引入了学习到的密集中间层，但牺牲了这种归纳偏置。这些方法在全局调制方面存在局限性，限制了其在处理复杂推理任务时的效率和效果。

Method: 提出了一种名为块Hadamard高秩适应（BHRA）的新方法。BHRA将每个权重矩阵分区，并在每个分区内独立应用HiRA风格的乘法调制。这种块状设计允许在保持PEFT参数占用的同时，实现局部秩的放大，从而克服了全局调制的限制。

Result: 在八个常识推理任务和两个算术基准测试中，使用Llama-3.2 1B/3B、Mistral-7B和Gemma-2 9B模型进行了实验。结果表明，BHRA在匹配的参数预算下，一致性地优于强大的PEFT基线方法。块状设计能够保持秩预算内的丰富谱，减轻了全局调制引起的秩塌陷。

Conclusion: BHRA通过在每个权重矩阵块内独立应用乘法调制，有效地实现了局部秩提升，克服了现有PEFT方法的局限性。该方法在保持参数效率的同时，提高了模型在各种推理任务上的性能，展示了其作为一种有效的PEFT方法的潜力。

Abstract: Parameter-efficient fine-tuning (PEFT) methods must be resource-efficient yet
handle heterogeneous reasoning transformations, and classical low-rank
adaptation (LoRA) is constrained by the nominal rank $r$. Hadamard-style
extensions like HiRA raise the nominal rank but couple every update to the
global energy pattern of the frozen weight matrix, while ABBA trades this
inductive bias for fully learned dense intermediates. To address the limitation
of global modulation, we propose Block Hadamard high-Rank Adaptation (BHRA),
which partitions each weight matrix and applies HiRA-style multiplicative
modulation independently within every block, preserving the PEFT parameter
footprint while unlocking localized rank amplification. Our empirical analyses
reveal that this blockwise design maintains rich spectra across rank budgets,
mitigating the collapse induced by global modulation. Across eight commonsense
reasoning tasks and two arithmetic benchmarks with Llama-3.2 1B/3B, Mistral-7B,
and Gemma-2 9B, BHRA consistently surpasses strong PEFT baselines under matched
parameter budgets.

</details>


### [557] [Understanding and Enhancing Mask-Based Pretraining towards Universal Representations](https://arxiv.org/abs/2509.21650)
*Mingze Dong,Leda Wang,Yuval Kluger*

Main category: cs.LG

TL;DR: Mask-based pretraining's behavior can be understood through linear regression, leading to a new scheme called R^2MAE that outperforms existing methods across various domains.


<details>
  <summary>Details</summary>
Motivation: To clarify the role and limits of mask-based pretraining in learning data representations and to develop improved pretraining schemes.

Method: Analyzed mask-based pretraining using high-dimensional minimum-norm linear regression. Proposed and implemented a new pretraining scheme, Randomly Random Mask AutoEncoding (R^2MAE), based on theoretical findings.

Result: The theoretical framework accurately characterized mask-based pretraining across diverse architectures and tasks. R^2MAE demonstrated superior performance compared to standard and complex masking schemes in vision, language, DNA sequence, and single-cell models.

Conclusion: Mask-based pretraining can be analyzed through linear regression, and the proposed R^2MAE scheme offers a simple yet effective way to capture multi-scale features, leading to performance improvements in various applications.

Abstract: Mask-based pretraining has become a cornerstone of modern large-scale models
across language, vision, and recently biology. Despite its empirical success,
its role and limits in learning data representations have been unclear. In this
work, we show that the behavior of mask-based pretraining can be directly
characterized by test risk in high-dimensional minimum-norm ("ridge-less")
linear regression, without relying on further model specifications. Further
analysis of linear models uncovers several novel aspects of mask-based
pretraining. The theoretical framework and its implications have been validated
across diverse neural architectures (including MLPs, CNNs, and Transformers)
applied to both vision and language tasks. Guided by our theory, we propose an
embarrassingly simple yet overlooked pretraining scheme named Randomly Random
Mask AutoEncoding (R$^2$MAE), which enforces capturing multi-scale features
from data and is able to outperform optimal fixed mask ratio settings in our
linear model framework. We implement R$^2$MAE in vision, language, DNA
sequence, and single-cell models, where it consistently outperforms standard
and more complicated masking schemes, leading to improvements for
state-of-the-art models. Our code is available at:
https://github.com/MingzeDong/r2mae

</details>


### [558] [Limitations on Safe, Trusted, Artificial General Intelligence](https://arxiv.org/abs/2509.21654)
*Rina Panigrahy,Vatsal Sharan*

Main category: cs.LG

TL;DR: 安全、可信和通用人工智能（AGI）在AI系统中是相互冲突的，因为严格的安全和可信AI系统无法达到AGI的性能。


<details>
  <summary>Details</summary>
Motivation: 提出安全、可信和AGI的严格数学定义，并论证它们之间的根本不兼容性。

Method: 形式化定义安全（从不做出虚假声明）、可信（假设系统安全）和AGI（性能始终等于或超过人类），并证明安全可信系统在某些人类轻松解决的任务上无法达到AGI水平。

Result: 证明了严格定义的、安全且可信的AI系统无法成为AGI，因为存在人类可轻松解决但该系统无法解决的任务实例。

Conclusion: 在严格的数学定义下，安全、可信的AI无法成为AGI。研究结果在程序验证、规划和图可达性问题中得到体现，并与哥德尔不完备定理和图灵停机问题证明有相似之处。

Abstract: Safety, trust and Artificial General Intelligence (AGI) are aspirational
goals in artificial intelligence (AI) systems, and there are several informal
interpretations of these notions. In this paper, we propose strict,
mathematical definitions of safety, trust, and AGI, and demonstrate a
fundamental incompatibility between them. We define safety of a system as the
property that it never makes any false claims, trust as the assumption that the
system is safe, and AGI as the property of an AI system always matching or
exceeding human capability. Our core finding is that -- for our formal
definitions of these notions -- a safe and trusted AI system cannot be an AGI
system: for such a safe, trusted system there are task instances which are
easily and provably solvable by a human but not by the system. We note that we
consider strict mathematical definitions of safety and trust, and it is
possible for real-world deployments to instead rely on alternate, practical
interpretations of these notions. We show our results for program verification,
planning, and graph reachability. Our proofs draw parallels to G\"odel's
incompleteness theorems and Turing's proof of the undecidability of the halting
problem, and can be regarded as interpretations of G\"odel's and Turing's
results.

</details>


### [559] [DriftLite: Lightweight Drift Control for Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2509.21655)
*Yinuo Ren,Wenhao Gao,Lexing Ying,Grant M. Rotskoff,Jiequn Han*

Main category: cs.LG

TL;DR: DriftLite是一种无需训练的轻量级粒子方法，可在推理时调整扩散模型以适应新目标分布，具有最佳稳定性控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于引导的方法会引入偏差，而基于粒子的方法存在权重退化和高计算成本的问题。本研究旨在提出一种无需训练的轻量级粒子方法，以解决这些问题。

Method: DriftLite利用了Fokker-Planck方程中先前未被探索的漂移和粒子势之间的自由度，并提出了两种实际应用：方差控制引导（VCG）和能量控制引导（ECG），以最小的开销近似最优漂移。

Result: 在混合高斯模型、粒子系统和大规模蛋白质-配体共折叠问题上，DriftLite相比于纯引导和序贯蒙特卡洛基线，能够持续降低方差并提高样本质量。

Conclusion: DriftLite为扩散模型的可扩展推理时适应提供了一种原则性的、高效的途径。

Abstract: We study inference-time scaling for diffusion models, where the goal is to
adapt a pre-trained model to new target distributions without retraining.
Existing guidance-based methods are simple but introduce bias, while
particle-based corrections suffer from weight degeneracy and high computational
cost. We introduce DriftLite, a lightweight, training-free particle-based
approach that steers the inference dynamics on the fly with provably optimal
stability control. DriftLite exploits a previously unexplored degree of freedom
in the Fokker-Planck equation between the drift and particle potential, and
yields two practical instantiations: Variance- and Energy-Controlling Guidance
(VCG/ECG) for approximating the optimal drift with minimal overhead. Across
Gaussian mixture models, particle systems, and large-scale protein-ligand
co-folding problems, DriftLite consistently reduces variance and improves
sample quality over pure guidance and sequential Monte Carlo baselines. These
results highlight a principled, efficient route toward scalable inference-time
adaptation of diffusion models.

</details>


### [560] [Differentiable Structure Learning for General Binary Data](https://arxiv.org/abs/2509.21658)
*Chang Deng,Bryon Aragam*

Main category: cs.LG

TL;DR: 现有的可微结构学习方法通常假设数据来自特定的结构方程模型，但这些假设可能不符合真实的数据生成过程，限制了方法的通用性。此外，当前方法往往忽略了离散数据中固有的复杂依赖结构，只考虑线性效应。我们提出了一个可微结构学习框架，能够捕捉离散变量之间任意的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有的可微结构学习方法在离散数据上的应用受到数据生成过程假设不准确和仅考虑线性效应的限制。

Method: 提出一个可微结构学习框架，能够捕捉离散变量之间任意的依赖关系，并将学习问题表述为单一的可微优化任务。

Result: 该方法能够有效捕捉离散数据中的复杂关系，并在温和假设下可识别到马尔可夫等价。

Conclusion: 我们提出了一个更通用的可微结构学习框架，能够处理离散数据中的复杂依赖关系，并在实际应用中取得了良好的效果。

Abstract: Existing methods for differentiable structure learning in discrete data
typically assume that the data are generated from specific structural equation
models. However, these assumptions may not align with the true data-generating
process, which limits the general applicability of such methods. Furthermore,
current approaches often ignore the complex dependence structure inherent in
discrete data and consider only linear effects. We propose a differentiable
structure learning framework that is capable of capturing arbitrary
dependencies among discrete variables. We show that although general discrete
models are unidentifiable from purely observational data, it is possible to
characterize the complete set of compatible parameters and structures.
Additionally, we establish identifiability up to Markov equivalence under mild
assumptions. We formulate the learning problem as a single differentiable
optimization task in the most general form, thereby avoiding the unrealistic
simplifications adopted by previous methods. Empirical results demonstrate that
our approach effectively captures complex relationships in discrete data.

</details>


### [561] [RED-DiffEq: Regularization by denoising diffusion models for solving inverse PDE problems with application to full waveform inversion](https://arxiv.org/abs/2509.21659)
*Siming Shan,Min Zhu,Youzuo Lin,Lu Lu*

Main category: cs.LG

TL;DR: RED-DiffEq是一个结合了物理驱动反演和数据驱动学习的计算框架，利用预训练的扩散模型作为正则化机制来解决偏微分方程（PDE）驱动的反问题，并在地球物理学中的全波形反演问题上取得了优于传统方法的精度和鲁棒性，同时展现了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程（PDE）驱动的反问题在科学和工程领域具有重要应用，但面临非线性、病态和对噪声敏感等挑战。

Method: RED-DiffEq框架整合了物理驱动反演和数据驱动学习，利用预训练的扩散模型作为PDE驱动的反问题的正则化机制。

Result: RED-DiffEq在解决地球物理学中的全波形反演问题时，相比传统方法提高了精度和鲁棒性，并对未训练过的复杂模型展现出良好的泛化能力。

Conclusion: RED-DiffEq框架可以成功应用于解决多种PDE驱动的反问题。

Abstract: Partial differential equation (PDE)-governed inverse problems are fundamental
across various scientific and engineering applications; yet they face
significant challenges due to nonlinearity, ill-posedness, and sensitivity to
noise. Here, we introduce a new computational framework, RED-DiffEq, by
integrating physics-driven inversion and data-driven learning. RED-DiffEq
leverages pretrained diffusion models as a regularization mechanism for
PDE-governed inverse problems. We apply RED-DiffEq to solve the full waveform
inversion problem in geophysics, a challenging seismic imaging technique that
seeks to reconstruct high-resolution subsurface velocity models from seismic
measurement data. Our method shows enhanced accuracy and robustness compared to
conventional methods. Additionally, it exhibits strong generalization ability
to more complex velocity models that the diffusion model is not trained on. Our
framework can also be directly applied to diverse PDE-governed inverse
problems.

</details>


### [562] [A Systematic Review of Conformal Inference Procedures for Treatment Effect Estimation: Methods and Challenges](https://arxiv.org/abs/2509.21660)
*Pascal Memmesheimer,Vincent Heuveline,Jürgen Hesser*

Main category: cs.LG

TL;DR: 机器学习在处理效应估计中的应用，但其不确定性量化仍是问题。保形预测可解决此问题，并提供理论基础和实证分析。


<details>
  <summary>Details</summary>
Motivation: 旨在解决机器学习在处理效应估计中不确定性量化的挑战。

Method: 通过系统性回顾和分析了11篇关于保形预测用于处理效应估计的关键论文，提供了理论背景。

Result: 识别并描述了该领域的最新方法。

Conclusion: 基于研究结果，提出了未来研究方向。

Abstract: Treatment effect estimation is essential for informed decision-making in many
fields such as healthcare, economics, and public policy. While flexible machine
learning models have been widely applied for estimating heterogeneous treatment
effects, quantifying the inherent uncertainty of their point predictions
remains an issue. Recent advancements in conformal prediction address this
limitation by allowing for inexpensive computation, as well as distribution
shifts, while still providing frequentist, finite-sample coverage guarantees
under minimal assumptions for any point-predictor model. This advancement holds
significant potential for improving decision-making in especially high-stakes
environments. In this work, we perform a systematic review regarding conformal
prediction methods for treatment effect estimation and provide for both the
necessary theoretical background. Through a systematic filtering process, we
select and analyze eleven key papers, identifying and describing current
state-of-the-art methods in this area. Based on our findings, we propose
directions for future research.

</details>


### [563] [MMPlanner: Zero-Shot Multimodal Procedural Planning with Chain-of-Thought Object State Reasoning](https://arxiv.org/abs/2509.21662)
*Afrina Tabassum,Bin Guo,Xiyao Ma,Hoda Eldardiry,Ismini Lourentzou*

Main category: cs.LG

TL;DR: MMPlanner是一个零样本多模态程序规划框架，通过引入物体状态推理链式思考（OSR-CoT）提示来解决物体状态一致性和信息量问题，并在RECIPEPLAN和WIKIPLAN数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态程序规划（MPP）方法在跨模态保持物体状态一致性方面存在挑战，并且缺乏系统的评估方法。

Method: MMPlanner框架引入了物体状态推理链式思考（OSR-CoT）提示，以明确模拟物体状态的转换，并生成准确的多模态计划。此外，还设计了LLM-as-a-judge协议用于评估规划准确性和跨模态对齐，并提出了一个视觉步骤重排任务来衡量时间连贯性。

Result: MMPlanner在RECIPEPLAN和WIKIPLAN数据集上取得了最先进的性能，文本规划提高了+6.8%，跨模态对齐提高了+11.9%，视觉步骤排序提高了+26.7%。

Conclusion: MMPlanner在多模态程序规划方面取得了显著的改进，特别是在物体状态一致性和跨模态对齐方面，为该领域的研究提供了新的方法和评估标准。

Abstract: Multimodal Procedural Planning (MPP) aims to generate step-by-step
instructions that combine text and images, with the central challenge of
preserving object-state consistency across modalities while producing
informative plans. Existing approaches often leverage large language models
(LLMs) to refine textual steps; however, visual object-state alignment and
systematic evaluation are largely underexplored. We present MMPlanner, a
zero-shot MPP framework that introduces Object State Reasoning Chain-of-Thought
(OSR-CoT) prompting to explicitly model object-state transitions and generate
accurate multimodal plans. To assess plan quality, we design LLM-as-a-judge
protocols for planning accuracy and cross-modal alignment, and further propose
a visual step-reordering task to measure temporal coherence. Experiments on
RECIPEPLAN and WIKIPLAN show that MMPlanner achieves state-of-the-art
performance, improving textual planning by +6.8%, cross-modal alignment by
+11.9%, and visual step ordering by +26.7%

</details>


### [564] [DIM: Enforcing Domain-Informed Monotonicity in Deep Neural Networks](https://arxiv.org/abs/2509.21666)
*Joshua Salim,Jordan Yu,Xilei Zhao*

Main category: cs.LG

TL;DR: 一种名为DIM的新型正则化方法通过强制执行领域信息单调性来提高深度神经网络的预测性能并减少过拟合。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型虽然在预测任务上表现出色，但由于其复杂的结构和大量的参数，往往会过拟合，导致它们记住训练数据（包括噪声），而不是学习泛化到新数据的模式。

Method: DIM方法通过惩罚相对于线性基线的违规行为来强制执行单调性，从而有效地鼓励模型遵循预期的趋势，同时保留其预测能力。该方法通过一个数学框架进行形式化，该框架建立了一个线性参考，衡量了与单调行为的偏差，并将这些测量结果整合到训练目标中。

Result: 在芝加哥的真实世界出行共享数据集和合成创建的数据集上进行了测试和验证。跨各种神经网络架构的实验表明，即使是适度的单调性约束也能持续提高模型性能。

Conclusion: DIM通过将领域信息单调性约束应用于正则化模型行为和减轻过拟合，从而提高了深度神经网络的预测性能。

Abstract: While deep learning models excel at predictive tasks, they often overfit due
to their complex structure and large number of parameters, causing them to
memorize training data, including noise, rather than learn patterns that
generalize to new data. To tackle this challenge, this paper proposes a new
regularization method, i.e., Enforcing Domain-Informed Monotonicity in Deep
Neural Networks (DIM), which maintains domain-informed monotonic relationships
in complex deep learning models to further improve predictions. Specifically,
our method enforces monotonicity by penalizing violations relative to a linear
baseline, effectively encouraging the model to follow expected trends while
preserving its predictive power. We formalize this approach through a
comprehensive mathematical framework that establishes a linear reference,
measures deviations from monotonic behavior, and integrates these measurements
into the training objective. We test and validate the proposed methodology
using a real-world ridesourcing dataset from Chicago and a synthetically
created dataset. Experiments across various neural network architectures show
that even modest monotonicity constraints consistently enhance model
performance. DIM enhances the predictive performance of deep neural networks by
applying domain-informed monotonicity constraints to regularize model behavior
and mitigate overfitting

</details>


### [565] [Neuroprobe: Evaluating Intracranial Brain Responses to Naturalistic Stimuli](https://arxiv.org/abs/2509.21671)
*Andrii Zahorodnii,Christopher Wang,Bennett Stankovits,Charikleia Moraitaki,Geeling Chau,Andrei Barbu,Boris Katz,Ila R Fiete*

Main category: cs.LG

TL;DR: Neuroprobe是一个用于研究大脑多模态语言处理的解码任务套件，它基于BrainTreebank数据集，提供了标准的评估框架，有助于比较不同的模型，并从中获得神经科学见解。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于颅内脑电图（iEEG）记录的标准评估框架，无法有效比较不同的神经模型。

Method: Neuroprobe基于BrainTreebank数据集（包含10名受试者40小时的iEEG记录），包含了一系列解码任务，用于研究大脑语言处理，并提供了计算效率和易用性。

Result: Neuroprobe能够系统地确定语言处理的计算在何时何地发生，并可视化信息流。实验发现，线性基线模型在许多任务上优于前沿模型。

Conclusion: Neuroprobe提供了一个严格的iEEG基准测试框架，用于比较模型架构和训练协议，促进iEEG基础模型领域的发展。

Abstract: High-resolution neural datasets enable foundation models for the next
generation of brain-computer interfaces and neurological treatments. The
community requires rigorous benchmarks to discriminate between competing
modeling approaches, yet no standardized evaluation frameworks exist for
intracranial EEG (iEEG) recordings. To address this gap, we present Neuroprobe:
a suite of decoding tasks for studying multi-modal language processing in the
brain. Unlike scalp EEG, intracranial EEG requires invasive surgery to implant
electrodes that record neural activity directly from the brain with minimal
signal distortion. Neuroprobe is built on the BrainTreebank dataset, which
consists of 40 hours of iEEG recordings from 10 human subjects performing a
naturalistic movie viewing task. Neuroprobe serves two critical functions.
First, it is a mine from which neuroscience insights can be drawn. Its high
temporal and spatial resolution allows researchers to systematically determine
when and where computations for each aspect of language processing occur in the
brain by measuring the decodability of each feature across time and all
electrode locations. Using Neuroprobe, we visualize how information flows from
the superior temporal gyrus to the prefrontal cortex, and the progression from
simple auditory features to more complex language features in a purely
data-driven manner. Second, as the field moves toward neural foundation models,
Neuroprobe provides a rigorous framework for comparing competing architectures
and training protocols. We found that the linear baseline is surprisingly
strong, beating frontier foundation models on many tasks. Neuroprobe is
designed with computational efficiency and ease of use in mind. We make the
code for Neuroprobe openly available and maintain a public leaderboard, aiming
to enable rapid progress in the field of iEEG foundation models, at
https://neuroprobe.dev/

</details>


### [566] [SlotFM: A Motion Foundation Model with Slot Attention for Diverse Downstream Tasks](https://arxiv.org/abs/2509.21673)
*Junyong Park,Oron Levy,Rebecca Adaimi,Asaf Liberman,Gierad Laput,Abdelkareem Bedri*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Wearable accelerometers are used for a wide range of applications, such as
gesture recognition, gait analysis, and sports monitoring. Yet most existing
foundation models focus primarily on classifying common daily activities such
as locomotion and exercise, limiting their applicability to the broader range
of tasks that rely on other signal characteristics. We present SlotFM, an
accelerometer foundation model that generalizes across diverse downstream
tasks. SlotFM uses Time-Frequency Slot Attention, an extension of Slot
Attention that processes both time and frequency representations of the raw
signals. It generates multiple small embeddings (slots), each capturing
different signal components, enabling task-specific heads to focus on the most
relevant parts of the data. We also introduce two loss regularizers that
capture local structure and frequency patterns, which improve reconstruction of
fine-grained details and helps the embeddings preserve task-relevant
information. We evaluate SlotFM on 16 classification and regression downstream
tasks that extend beyond standard human activity recognition. It outperforms
existing self-supervised approaches on 13 of these tasks and achieves
comparable results to the best performing approaches on the remaining tasks. On
average, our method yields a 4.5% performance gain, demonstrating strong
generalization for sensing foundation models.

</details>


### [567] [Scalable Second-order Riemannian Optimization for $K$-means Clustering](https://arxiv.org/abs/2509.21675)
*Peng Xu,Chun-Ying Hou,Xiaohui Chen,Richard Y. Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种新的 K-means 聚类问题光滑无约束优化新方法，并利用黎曼几何性质，通过二阶立方正则化黎曼牛顿算法求解，在保持统计精度的同时，显著优于现有的一阶非负低秩分解方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于低秩半定规划（SDP）的聚类方法在约束可行性和目标最优性之间难以平衡，计算二阶最优解存在挑战。

Method: 将 K-means 问题转化为流形上的光滑无约束优化问题，利用其黎曼几何性质，通过二阶立方正则化黎曼牛顿算法求解。通过分解流形，使得牛顿子问题可以线性时间求解。

Result: 数值实验表明，该方法比现有的一阶非负低秩分解方法收敛速度更快，同时达到相似的最优统计精度。

Conclusion: 所提出的基于黎曼几何的二阶方法在 K-means 聚类问题上表现出优越的性能，能够有效且高效地求解该问题。

Abstract: Clustering is a hard discrete optimization problem. Nonconvex approaches such
as low-rank semidefinite programming (SDP) have recently demonstrated promising
statistical and local algorithmic guarantees for cluster recovery. Due to the
combinatorial structure of the $K$-means clustering problem, current relaxation
algorithms struggle to balance their constraint feasibility and objective
optimality, presenting tremendous challenges in computing the second-order
critical points with rigorous guarantees. In this paper, we provide a new
formulation of the $K$-means problem as a smooth unconstrained optimization
over a submanifold and characterize its Riemannian structures to allow it to be
solved using a second-order cubic-regularized Riemannian Newton algorithm. By
factorizing the $K$-means manifold into a product manifold, we show how each
Newton subproblem can be solved in linear time. Our numerical experiments show
that the proposed method converges significantly faster than the
state-of-the-art first-order nonnegative low-rank factorization method, while
achieving similarly optimal statistical accuracy.

</details>


### [568] [Prophecy: Inferring Formal Properties from Neuron Activations](https://arxiv.org/abs/2509.21677)
*Divya Gopinath,Corina S. Pasareanu,Muhammad Usman*

Main category: cs.LG

TL;DR: Prophecy工具可自动推断前馈神经网络的形式属性，通过提取基于神经元激活的规则来推断网络属性。


<details>
  <summary>Details</summary>
Motivation: 观察到前馈网络的逻辑很大程度上体现在中间层的神经元激活状态中。

Method: 提取基于神经元激活（值或开关状态）的规则作为前提条件，以推断出期望的输出属性（例如，预测为特定类别）。

Result: 展示了该工具的架构、特点及其在不同类型模型和输出属性上的应用，并提供了其在推断和证明神经网络形式化解释、组合验证、运行时监控、修复等方面的应用概述。

Conclusion: Prophecy在大型视觉-语言模型时代具有巨大潜力。

Abstract: We present Prophecy, a tool for automatically inferring formal properties of
feed-forward neural networks. Prophecy is based on the observation that a
significant part of the logic of feed-forward networks is captured in the
activation status of the neurons at inner layers. Prophecy works by extracting
rules based on neuron activations (values or on/off statuses) as preconditions
that imply certain desirable output property, e.g., the prediction being a
certain class. These rules represent network properties captured in the hidden
layers that imply the desired output behavior. We present the architecture of
the tool, highlight its features and demonstrate its usage on different types
of models and output properties. We present an overview of its applications,
such as inferring and proving formal explanations of neural networks,
compositional verification, run-time monitoring, repair, and others. We also
show novel results highlighting its potential in the era of large
vision-language models.

</details>


### [569] [SpecMER: Fast Protein Generation with K-mer Guided Speculative Decoding](https://arxiv.org/abs/2509.21689)
*Thomas Walton,Darin Tsui,Aryan Musharaf,Amirali Aghazadeh*

Main category: cs.LG

TL;DR: SpecMER通过引入k-mer引导的猜测解码来加速蛋白质序列生成，显著提高了序列的合理性并保持了生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型虽然能生成新蛋白质序列，但其推理延迟限制了高通量筛选。猜测解码虽然能加速生成，但其草稿模型通常忽略生物学约束，导致输出不合理。

Method: SpecMER框架利用从多序列比对中提取的k-mer基序来引入生物学、结构和功能先验。它并行评分候选序列，并选择与已知生物学模式最一致的序列。

Result: SpecMER在保持猜测解码效率的同时，显著提高了序列的合理性，实现了比标准自回归解码快24-32%的加速，并具有更高的接受率和序列似然度。

Conclusion: SpecMER框架通过结合k-mer引导的猜测解码，成功解决了蛋白质序列生成中的效率和合理性问题，为高通量蛋白质筛选提供了更优的解决方案。

Abstract: Autoregressive models have transformed protein engineering by enabling the
generation of novel protein sequences beyond those found in nature. However,
their sequential inference introduces significant latency, limiting their
utility in high-throughput protein screening. Speculative decoding accelerates
generation by employing a lightweight draft model to sample tokens, which a
larger target model then verifies and refines. Yet, in protein sequence
generation, draft models are typically agnostic to the structural and
functional constraints of the target protein, leading to biologically
implausible outputs and a shift in the likelihood distribution of generated
sequences. We introduce SpecMER (Speculative Decoding via k-mer Guidance), a
novel framework that incorporates biological, structural, and functional priors
using k-mer motifs extracted from multiple sequence alignments. By scoring
candidate sequences in parallel and selecting those most consistent with known
biological patterns, SpecMER significantly improves sequence plausibility while
retaining the efficiency of speculative decoding. SpecMER achieves 24-32%
speedup over standard autoregressive decoding, along with higher acceptance
rates and improved sequence likelihoods.

</details>


### [570] [Wav2Arrest 2.0: Long-Horizon Cardiac Arrest Prediction with Time-to-Event Modeling, Identity-Invariance, and Pseudo-Lab Alignment](https://arxiv.org/abs/2509.21695)
*Saurabh Kataria,Davood Fattahi,Minxiao Wang,Ran Xiao,Matthew Clark,Timothy Ruchti,Mark Mai,Xiao Hu*

Main category: cs.LG

TL;DR: 该研究提出了一种改进基于PPG信号的心脏骤停（CA）预测系统的方法，通过引入时间相关性建模、患者身份无关特征学习以及利用预训练模型生成伪标签等技术，在有限的辅助信息下提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然基于PPG信号的生理基础模型（如PPG-GPT）在预测心脏骤停（CA）方面显示出潜力，但其强大的表征能力在下游数据/标签稀疏的情况下尚未得到充分利用。

Method: 1. 引入时间相关性建模，包括事件发生时间回归或离散生存建模。2. 通过训练最大的去标识化生物识别模型（p-vector）并进行对抗性去混淆，使模型学习与患者身份无关的CA相关特征。3. 利用预训练的辅助估计网络生成伪标签，用于回归预测，以弥补真实血检数据（如乳酸盐、钠、钾、心肌酶等）的稀疏性。4. 采用多任务学习框架，并利用PCGrad优化技术解决损失函数之间的梯度冲突问题。

Result: 所提出的方法能够独立地将24小时时间平均AUC从0.74提高到0.78-0.80的范围，尤其在较长的时间范围内提高了预测精度，同时在接近事件发生时精度仅有轻微下降。

Conclusion: 通过结合时间相关性建模、身份无关特征学习和伪标签利用，该研究显著改进了仅基于PPG信号的心脏骤停预测系统，为预警系统的研究提供了新的方向。

Abstract: High-frequency physiological waveform modality offers deep, real-time
insights into patient status. Recently, physiological foundation models based
on Photoplethysmography (PPG), such as PPG-GPT, have been shown to predict
critical events, including Cardiac Arrest (CA). However, their powerful
representation still needs to be leveraged suitably, especially when the
downstream data/label is scarce. We offer three orthogonal improvements to
improve PPG-only CA systems by using minimal auxiliary information. First, we
propose to use time-to-event modeling, either through simple regression to the
event onset time or by pursuing fine-grained discrete survival modeling.
Second, we encourage the model to learn CA-focused features by making them
patient-identity invariant. This is achieved by first training the
largest-scale de-identified biometric identification model, referred to as the
p-vector, and subsequently using it adversarially to deconfound cues, such as
person identity, that may cause overfitting through memorization. Third, we
propose regression on the pseudo-lab values generated by pre-trained auxiliary
estimator networks. This is crucial since true blood lab measurements, such as
lactate, sodium, troponin, and potassium, are collected sparingly. Via
zero-shot prediction, the auxiliary networks can enrich cardiac arrest waveform
labels and generate pseudo-continuous estimates as targets. Our proposals can
independently improve the 24-hour time-averaged AUC from the 0.74 to the
0.78-0.80 range. We primarily improve over longer time horizons with minimal
degradation near the event, thus pushing the Early Warning System research.
Finally, we pursue multi-task formulation and diagnose it with a high gradient
conflict rate among competing losses, which we alleviate via the PCGrad
optimization technique.

</details>


### [571] [Exact Subgraph Isomorphism Network for Predictive Graph Mining](https://arxiv.org/abs/2509.21699)
*Taiga Kojima,Masayuki Karasuyama*

Main category: cs.LG

TL;DR: EIN是一个结合了精确子图枚举、神经网络和稀疏正则化的图级预测模型，旨在提高预测能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在图级预测任务中，子图信息至关重要，但构建同时具有高区分能力和可解释性的图级预测模型仍然是一个挑战。

Method: EIN结合了精确子图枚举、神经网络和稀疏正则化。稀疏正则化用于剪枝策略以减轻计算负担并识别重要子图，从而提高可解释性。

Result: EIN在图级预测任务上表现出足够高的预测性能，可与标准的图神经网络模型相媲美，并且可以通过识别出的子图进行事后分析。

Conclusion: EIN通过结合子图枚举、神经网络和稀疏正则化，有效地解决了图级预测任务中的区分能力和可解释性问题。

Abstract: In the graph-level prediction task (predict a label for a given graph), the
information contained in subgraphs of the input graph plays a key role. In this
paper, we propose Exact subgraph Isomorphism Network (EIN), which combines the
exact subgraph enumeration, neural network, and a sparse regularization. In
general, building a graph-level prediction model achieving high discriminative
ability along with interpretability is still a challenging problem. Our
combination of the subgraph enumeration and neural network contributes to high
discriminative ability about the subgraph structure of the input graph.
Further, the sparse regularization in EIN enables us 1) to derive an effective
pruning strategy that mitigates computational difficulty of the enumeration
while maintaining the prediction performance, and 2) to identify important
subgraphs that contributes to high interpretability. We empirically show that
EIN has sufficiently high prediction performance compared with standard graph
neural network models, and also, we show examples of post-hoc analysis based on
the selected subgraphs.

</details>


### [572] [Downscaling human mobility data based on demographic socioeconomic and commuting characteristics using interpretable machine learning methods](https://arxiv.org/abs/2509.21703)
*Yuqin Jiang,Andrey A. Popov,Tianle Duan,Qingchun Li*

Main category: cs.LG

TL;DR: 本研究提出了一种机器学习框架，用于将纽约市的士出行OD（起点-终点）流量从较粗略的空间单位缩小到较小的空间单位。


<details>
  <summary>Details</summary>
Motivation: 理解城市人口流动模式对于社会科学研究至关重要，特别是从宏观到微观尺度的OD出行流量分析。

Method: 研究人员开发了四种模型（线性回归、随机森林、支持向量机、神经网络）来挖掘OD出行流量与人口、社会经济和通勤特征之间的相关性，并使用基于扰动的敏感性分析来解释非线性模型中的变量重要性。

Result: 研究结果表明，线性回归模型在捕捉复杂的变量交互方面表现不佳；神经网络在训练和测试数据集上表现最佳，但支持向量机在降尺度方面表现出最佳的泛化能力。

Conclusion: 该研究提出的方法在分析上有所进展，并在改善交通服务和城市发展方面具有实际应用价值。

Abstract: Understanding urban human mobility patterns at various spatial levels is
essential for social science. This study presents a machine learning framework
to downscale origin-destination (OD) taxi trips flows in New York City from a
larger spatial unit to a smaller spatial unit. First, correlations between OD
trips and demographic, socioeconomic, and commuting characteristics are
developed using four models: Linear Regression (LR), Random Forest (RF),
Support Vector Machine (SVM), and Neural Networks (NN). Second, a
perturbation-based sensitivity analysis is applied to interpret variable
importance for nonlinear models. The results show that the linear regression
model failed to capture the complex variable interactions. While NN performs
best with the training and testing datasets, SVM shows the best generalization
ability in downscaling performance. The methodology presented in this study
provides both analytical advancement and practical applications to improve
transportation services and urban development.

</details>


### [573] [PQFed: A Privacy-Preserving Quality-Controlled Federated Learning Framework](https://arxiv.org/abs/2509.21704)
*Weiqi Yue,Wenbiao Li,Yuzhou Jiang,Anisa Halimi,Roger French,Erman Ayday*

Main category: cs.LG

TL;DR: PQFed是一个新颖的隐私保护个性化联邦学习框架，通过在联邦训练前为每个客户端设计定制的训练策略来解决数据异构性问题，从而提高全局模型的性能。


<details>
  <summary>Details</summary>
Motivation: 数据异构性持续挑战联邦学习中全局模型的性能。传统方法通常依赖于所有客户端的协作全局模型训练，然后进行本地适应以提高个体性能。

Method: PQFed提取每个客户端的代表性特征，并应用聚类技术来估计客户端之间数据集的相似性。基于这些相似性估计，该框架实施了一种客户端选择策略，使每个客户端能够与具有兼容数据分布的其他客户端进行协作。

Result: 实验结果表明，PQFed能够持续提高目标客户端的模型性能，即使参与者数量有限。与基线聚类算法IFCA相比，PQFed在低参与场景下也取得了更好的性能。

Conclusion: PQFed在个性化联邦学习设置中具有可扩展性和有效性。

Abstract: Federated learning enables collaborative model training without sharing raw
data, but data heterogeneity consistently challenges the performance of the
global model. Traditional optimization methods often rely on collaborative
global model training involving all clients, followed by local adaptation to
improve individual performance. In this work, we focus on early-stage quality
control and propose PQFed, a novel privacy-preserving personalized federated
learning framework that designs customized training strategies for each client
prior to the federated training process. PQFed extracts representative features
from each client's raw data and applies clustering techniques to estimate
inter-client dataset similarity. Based on these similarity estimates, the
framework implements a client selection strategy that enables each client to
collaborate with others who have compatible data distributions. We evaluate
PQFed on two benchmark datasets, CIFAR-10 and MNIST, integrated with three
existing federated learning algorithms. Experimental results show that PQFed
consistently improves the target client's model performance, even with a
limited number of participants. We further benchmark PQFed against a baseline
cluster-based algorithm, IFCA, and observe that PQFed also achieves better
performance in low-participation scenarios. These findings highlight PQFed's
scalability and effectiveness in personalized federated learning settings.

</details>


### [574] [A Unifying Framework for Parallelizing Sequential Models with Linear Dynamical Systems](https://arxiv.org/abs/2509.21716)
*Xavier Gonzalez,E. Kelly Buchanan,Hyun Dong Lee,Jerry Weihong Liu,Ke Alexander Wang,David M. Zoltowski,Christopher Ré,Scott W. Linderman*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Harnessing parallelism in seemingly sequential models is a central challenge
for modern machine learning. Several approaches have been proposed for
evaluating sequential processes in parallel using fixed-point methods, like
Newton, Picard, and Jacobi iterations. In this work, we show that these methods
can be understood within a common framework based on linear dynamical systems
(LDSs), where different iteration schemes arise naturally as approximate
linearizations of a nonlinear recursion. This unifying view highlights shared
principles behind these techniques and clarifies when particular fixed-point
methods are most likely to be effective. By bridging diverse algorithms through
the language of LDSs, our framework provides a clearer theoretical foundation
for parallelizing sequential models and points toward new opportunities for
efficient and scalable computation.

</details>


### [575] [ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation](https://arxiv.org/abs/2509.22402)
*Nan Tang,Jing-Cheng Pang,Guanlin Li,Chao Qian,Yang Yu*

Main category: cs.LG

TL;DR: ReLAM通过从视频演示中提取的关键点来自动生成奖励，从而解决视觉强化学习中的奖励设计问题，并在复杂操控任务中取得优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在视觉强化学习的机器人操控任务中，基于目标位置的奖励设计存在困难，因为真实世界的传感器和感知限制常常无法提供精确的位置信息。

Method: 提出了一种通过提取的关键点来隐式推断空间距离的方法，并构建了奖励学习与预测模型（ReLAM）框架。该框架学习一个预测模型，该模型能够规划并提出基于关键点的中间子目标，从而为低级策略的训练提供密集的、结构化的奖励信号。

Result: 在复杂的、长周期的操控任务上的广泛实验表明，ReLAM显著加快了学习速度，并实现了优于现有最先进方法的性能。

Conclusion: ReLAM框架能够自动生成密集的、结构化的奖励，克服了视觉强化学习中奖励设计的挑战，并显著提高了复杂操控任务的学习效率和性能。

Abstract: Reward design remains a critical bottleneck in visual reinforcement learning
(RL) for robotic manipulation. In simulated environments, rewards are
conventionally designed based on the distance to a target position. However,
such precise positional information is often unavailable in real-world visual
settings due to sensory and perceptual limitations. In this study, we propose a
method that implicitly infers spatial distances through keypoints extracted
from images. Building on this, we introduce Reward Learning with Anticipation
Model (ReLAM), a novel framework that automatically generates dense, structured
rewards from action-free video demonstrations. ReLAM first learns an
anticipation model that serves as a planner and proposes intermediate
keypoint-based subgoals on the optimal path to the final goal, creating a
structured learning curriculum directly aligned with the task's geometric
objectives. Based on the anticipated subgoals, a continuous reward signal is
provided to train a low-level, goal-conditioned policy under the hierarchical
reinforcement learning (HRL) framework with provable sub-optimality bound.
Extensive experiments on complex, long-horizon manipulation tasks show that
ReLAM significantly accelerates learning and achieves superior performance
compared to state-of-the-art methods.

</details>


### [576] [Information-Theoretic Bayesian Optimization for Bilevel Optimization Problems](https://arxiv.org/abs/2509.21725)
*Takuya Kanayama,Yuki Ito,Tomoyuki Tamura,Masayuki Karasuyama*

Main category: cs.LG

TL;DR: 本文提出了一种信息论方法来解决双层贝叶斯优化问题，同时考虑了上下两层的最优解和值的信息增益。


<details>
  <summary>Details</summary>
Motivation: 双层优化问题因其嵌套结构而具有复杂性，并且与多目标或约束设置等其他标准贝叶斯优化扩展相比，研究较少。然而，当上下两层都涉及昂贵的黑盒函数时，解决这类问题具有重要意义。

Method: 提出了一种信息论方法，该方法同时考虑了上层和下层最优解和值的信息增益，从而定义了一个统一的标准来衡量两个层级问题的收益。此外，还展示了一种基于下界的方法来评估信息增益。

Result: 通过在多个基准数据集上的实证评估，证明了所提出方法在解决双层贝叶斯优化问题方面的有效性。

Conclusion: 所提出的信息论方法能够有效地解决双层贝叶斯优化问题，并在实践中具有应用价值。

Abstract: A bilevel optimization problem consists of two optimization problems nested
as an upper- and a lower-level problem, in which the optimality of the
lower-level problem defines a constraint for the upper-level problem. This
paper considers Bayesian optimization (BO) for the case that both the upper-
and lower-levels involve expensive black-box functions. Because of its nested
structure, bilevel optimization has a complex problem definition and, compared
with other standard extensions of BO such as multi-objective or constraint
settings, it has not been widely studied. We propose an information-theoretic
approach that considers the information gain of both the upper- and
lower-optimal solutions and values. This enables us to define a unified
criterion that measures the benefit for both level problems, simultaneously.
Further, we also show a practical lower bound based approach to evaluating the
information gain. We empirically demonstrate the effectiveness of our proposed
method through several benchmark datasets.

</details>


### [577] [Uncovering Alzheimer's Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks](https://arxiv.org/abs/2509.21735)
*Houliang Zhou,Rong Zhou,Yangying Liu,Kanhao Zhao,Li Shen,Brian Y. Chen,Yu Zhang,Lifang He,Alzheimer's Disease Neuroimaging Initiative*

Main category: cs.LG

TL;DR: 该研究提出了一种可解释的时空图神经网络框架，利用双随机微分方程（SDEs）来处理纵向fMRI数据，以预测阿尔茨海默病（AD）的进展。该框架能够识别与疾病进展相关的关键脑区和脑网络，并发现了新的、与性别相关的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 现有的神经影像学生物标志物预测阿尔茨海默病（AD）进展的方法在处理大脑网络时空特性的复杂性方面存在挑战，容易忽略其时空特性。

Method: 开发了一种可解释的时空图神经网络框架，利用双随机微分方程（SDEs）来模拟不规则采样的纵向功能磁共振成像（fMRI）数据，以预测未来的AD进展。

Result: 该框架能够学习稀疏的区域和连接重要性概率，识别出与疾病进展相关的关键脑回路异常，并检测到重要的脑区（如海马旁皮质、前额叶皮质和顶小叶）以及显著受损的网络（如腹侧注意网络、背侧注意网络和默认模式网络）。这些异常与纵向AD相关临床症状高度相关。

Conclusion: 时空图学习方法有潜力用于AD进展的早期、个体化预测，即使在处理不规则采样的纵向成像数据时也是如此。该框架还揭示了新的神经系统和性别特异性生物标志物，为理解AD进展的神经生物学机制提供了新的见解。

Abstract: Identifying objective neuroimaging biomarkers to forecast Alzheimer's disease
(AD) progression is crucial for timely intervention. However, this task remains
challenging due to the complex dysfunctions in the spatio-temporal
characteristics of underlying brain networks, which are often overlooked by
existing methods. To address these limitations, we develop an interpretable
spatio-temporal graph neural network framework to predict future AD
progression, leveraging dual Stochastic Differential Equations (SDEs) to model
the irregularly-sampled longitudinal functional magnetic resonance imaging
(fMRI) data. We validate our approach on two independent cohorts, including the
Open Access Series of Imaging Studies (OASIS-3) and the Alzheimer's Disease
Neuroimaging Initiative (ADNI). Our framework effectively learns sparse
regional and connective importance probabilities, enabling the identification
of key brain circuit abnormalities associated with disease progression.
Notably, we detect the parahippocampal cortex, prefrontal cortex, and parietal
lobule as salient regions, with significant disruptions in the ventral
attention, dorsal attention, and default mode networks. These abnormalities
correlate strongly with longitudinal AD-related clinical symptoms. Moreover,
our interpretability strategy reveals both established and novel neural
systems-level and sex-specific biomarkers, offering new insights into the
neurobiological mechanisms underlying AD progression. Our findings highlight
the potential of spatio-temporal graph-based learning for early, individualized
prediction of AD progression, even in the context of irregularly-sampled
longitudinal imaging data.

</details>


### [578] [POLO: Preference-Guided Multi-Turn Reinforcement Learning for Lead Optimization](https://arxiv.org/abs/2509.21737)
*Ziqing Wang,Yibo Wen,William Pattie,Xiao Luo,Weimin Wu,Jerry Yao-Chieh Hu,Abhishek Pandey,Han Liu,Kaize Ding*

Main category: cs.LG

TL;DR: POLO是一种结合强化学习和大型语言模型的药物先导优化方法，通过学习完整的优化轨迹而非孤立步骤，显著提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统的药物先导优化方法在样本效率方面存在不足，难以在有限的评估次数内达到理想的优化效果。大型语言模型（LLMs）虽然有潜力，但现有方法未能充分利用其迭代学习能力。

Method: 提出POLO（Preference-guided multi-turn Optimization for Lead Optimization）方法，其核心是创新的强化学习算法PGPO（Preference-Guided Policy Optimization）。PGPO通过轨迹层面的优化和回合层面的偏好学习，从完整的优化轨迹中提取学习信号，从而实现高效学习。

Result: 在单属性任务上，POLO的平均成功率为84%（优于基线2.3倍）；在多属性任务上，仅用500次评估就达到了50%的成功率，显著优于现有技术水平。

Conclusion: POLO通过从完整的优化轨迹中学习，并结合轨迹和回合两个层面的学习信号，能够显著提高样本效率，在药物先导优化任务中取得了优异的成果。

Abstract: Lead optimization in drug discovery requires efficiently navigating vast
chemical space through iterative cycles to enhance molecular properties while
preserving structural similarity to the original lead compound. Despite recent
advances, traditional optimization methods struggle with sample
efficiency-achieving good optimization performance with limited oracle
evaluations. Large Language Models (LLMs) provide a promising approach through
their in-context learning and instruction following capabilities, which align
naturally with these iterative processes. However, existing LLM-based methods
fail to leverage this strength, treating each optimization step independently.
To address this, we present POLO (Preference-guided multi-turn Optimization for
Lead Optimization), which enables LLMs to learn from complete optimization
trajectories rather than isolated steps. At its core, POLO introduces
Preference-Guided Policy Optimization (PGPO), a novel reinforcement learning
algorithm that extracts learning signals at two complementary levels:
trajectory-level optimization reinforces successful strategies, while
turn-level preference learning provides dense comparative feedback by ranking
intermediate molecules within each trajectory. Through this dual-level learning
from intermediate evaluation, POLO achieves superior sample efficiency by fully
exploiting each costly oracle call. Extensive experiments demonstrate that POLO
achieves 84% average success rate on single-property tasks (2.3x better than
baselines) and 50% on multi-property tasks using only 500 oracle evaluations,
significantly advancing the state-of-the-art in sample-efficient molecular
optimization.

</details>


### [579] [Brain PathoGraph Learning](https://arxiv.org/abs/2509.21742)
*Ciyuan Peng,Nguyen Linh Dan Le,Shan Jin,Dexuan Ding,Shuo Yu,Feng Xia*

Main category: cs.LG

TL;DR: BrainPoG通过病理性模式过滤和病理性特征蒸馏实现高效的大脑图学习，减少参数和计算成本，并在多种大脑疾病检测任务中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的大脑图学习方法难以选择性地学习疾病相关知识，导致参数量大、计算成本高，限制了其实用性。

Method: 提出轻量级的大脑病理性图学习（BrainPoG）模型，首先通过滤波器提取高度疾病相关子图形成的病理性模式，实现图剪枝和病灶定位，然后构建病理性图，再通过病理性特征蒸馏模块减少与疾病无关的噪声特征，增强节点病理性特征。

Result: 在四个基准数据集上的广泛实验表明，BrainPoG在模型性能和计算效率方面均优于现有方法，可有效用于各种大脑疾病检测任务。

Conclusion: BrainPoG能够专门学习信息丰富的疾病相关知识，同时避免不相关信息，实现高效的大脑图学习。

Abstract: Brain graph learning has demonstrated significant achievements in the fields
of neuroscience and artificial intelligence. However, existing methods struggle
to selectively learn disease-related knowledge, leading to heavy parameters and
computational costs. This challenge diminishes their efficiency, as well as
limits their practicality for real-world clinical applications. To this end, we
propose a lightweight Brain PathoGraph Learning (BrainPoG) model that enables
efficient brain graph learning by pathological pattern filtering and
pathological feature distillation. Specifically, BrainPoG first contains a
filter to extract the pathological pattern formulated by highly
disease-relevant subgraphs, achieving graph pruning and lesion localization. A
PathoGraph is therefore constructed by dropping less disease-relevant subgraphs
from the whole brain graph. Afterwards, a pathological feature distillation
module is designed to reduce disease-irrelevant noise features and enhance
pathological features of each node in the PathoGraph. BrainPoG can exclusively
learn informative disease-related knowledge while avoiding less relevant
information, achieving efficient brain graph learning. Extensive experiments on
four benchmark datasets demonstrate that BrainPoG exhibits superiority in both
model performance and computational efficiency across various brain disease
detection tasks.

</details>


### [580] [HyperCore: Coreset Selection under Noise via Hypersphere Models](https://arxiv.org/abs/2509.21746)
*Brian B. Moser,Arundhati S. Shanbhag,Tobias C. Nauen,Stanislav Frolov,Federico Raue,Joachim Folz,Andreas Dengel*

Main category: cs.LG

TL;DR: HyperCore是一个用于在嘈杂环境中进行高效模型训练的鲁棒且自适应的核选择框架。


<details>
  <summary>Details</summary>
Motivation: 现有核选择方法忽略了标注错误的可能性并且需要固定的剪枝比例，这使得它们在实际应用中不实用。

Method: HyperCore利用每个类别学习到的轻量级超球体模型，将类别内的样本聚集在超球体中心附近，并通过距离自然区分出非本类样本。它利用Youden的J统计量自适应地选择剪枝阈值，从而实现无需超参数调整的自动、噪声感知数据剪枝。

Result: 实验表明，HyperCore在嘈杂和数据量少的条件下，始终优于最先进的核选择方法，能够有效剔除标注错误和模糊的点，生成紧凑但信息量大的子集，适用于可扩展且无噪声的学习。

Conclusion: HyperCore通过其新颖的基于超球体和Youden's J统计量的自适应方法，解决了现有核选择方法的局限性，在嘈杂和数据量少的环境中表现出色。

Abstract: The goal of coreset selection methods is to identify representative subsets
of datasets for efficient model training. Yet, existing methods often ignore
the possibility of annotation errors and require fixed pruning ratios, making
them impractical in real-world settings. We present HyperCore, a robust and
adaptive coreset selection framework designed explicitly for noisy
environments. HyperCore leverages lightweight hypersphere models learned per
class, embedding in-class samples close to a hypersphere center while naturally
segregating out-of-class samples based on their distance. By using Youden's J
statistic, HyperCore can adaptively select pruning thresholds, enabling
automatic, noise-aware data pruning without hyperparameter tuning. Our
experiments reveal that HyperCore consistently surpasses state-of-the-art
coreset selection methods, especially under noisy and low-data regimes.
HyperCore effectively discards mislabeled and ambiguous points, yielding
compact yet highly informative subsets suitable for scalable and noise-free
learning.

</details>


### [581] [SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection](https://arxiv.org/abs/2509.21748)
*Brian B. Moser,Tobias C. Nauen,Arundhati S. Shanbhag,Federico Raue,Stanislav Frolov,Joachim Folz,Andreas Dengel*

Main category: cs.LG

TL;DR: SubZeroCore是一种新的、无需训练的核选择方法，它将子模覆盖和密度结合到一个统一的目标中，以识别代表性的数据集子集用于高效的模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有的核选择方法需要昂贵的训练信号，这与其旨在避免训练样本的初衷相矛盾。

Method: SubZeroCore结合了子模覆盖和密度，并使用基于闭式解的采样策略来优化这两个目标，由一个控制局部密度测量的覆盖率的超参数指导。

Result: SubZeroCore在不进行训练的情况下，与基于训练的方法相匹配，并在高修剪率下显著优于它们，同时大大降低了计算开销。它还表现出对标签噪声的优越鲁棒性。

Conclusion: SubZeroCore通过提供一种高效、无需训练且鲁棒的方法，为实际场景中的数据集表示和模型训练提供了一种有前景的解决方案。

Abstract: The goal of coreset selection is to identify representative subsets of
datasets for efficient model training. Yet, existing approaches paradoxically
require expensive training-based signals, e.g., gradients, decision boundary
estimates or forgetting counts, computed over the entire dataset prior to
pruning, which undermines their very purpose by requiring training on samples
they aim to avoid. We introduce SubZeroCore, a novel, training-free coreset
selection method that integrates submodular coverage and density into a single,
unified objective. To achieve this, we introduce a sampling strategy based on a
closed-form solution to optimally balance these objectives, guided by a single
hyperparameter that explicitly controls the desired coverage for local density
measures. Despite no training, extensive evaluations show that SubZeroCore
matches training-based baselines and significantly outperforms them at high
pruning rates, while dramatically reducing computational overhead. SubZeroCore
also demonstrates superior robustness to label noise, highlighting its
practical effectiveness and scalability for real-world scenarios.

</details>


### [582] [Reparameterizing 4DVAR with neural fields](https://arxiv.org/abs/2509.21751)
*Jaemin Oh*

Main category: cs.LG

TL;DR: 使用神经场重新参数化4DVAR，实现并行优化，无需真实数据即可纳入物理约束。


<details>
  <summary>Details</summary>
Motivation: 传统4DVAR在数值天气预报中成本高昂且难以优化。神经场方法旨在解决这些问题。

Method: 将时空状态表示为由神经网络参数化的连续函数，从而实现参数空间中的并行优化，并直接通过物理信息损失函数纳入物理约束。

Result: 与基线4DVAR相比，该方法生成的初始条件估计更稳定，没有虚假振荡。

Conclusion: 该框架无需真实数据即可纳入物理约束，扩大了其应用范围。

Abstract: Four-dimensional variational data assimilation (4DVAR) is a cornerstone of
numerical weather prediction, but its cost function is difficult to optimize
and computationally intensive. We propose a neural field-based reformulation in
which the full spatiotemporal state is represented as a continuous function
parameterized by a neural network. This reparameterization removes the
time-sequential dependency of classical 4DVAR, enabling parallel-in-time
optimization in parameter space. Physical constraints are incorporated directly
through a physics-informed loss, simplifying implementation and reducing
computational cost. We evaluate the method on the two-dimensional
incompressible Navier--Stokes equations with Kolmogorov forcing. Compared to a
baseline 4DVAR implementation, the neural reparameterized variants produce more
stable initial condition estimates without spurious oscillations. Notably,
unlike most machine learning-based approaches, our framework does not require
access to ground-truth states or reanalysis data, broadening its applicability
to settings with limited reference information.

</details>


### [583] [Machine Learning and AI Applied to fNIRS Data Reveals Novel Brain Activity Biomarkers in Stable Subclinical Multiple Sclerosis](https://arxiv.org/abs/2509.21770)
*Sadman Saumik Islam,Bruna Dalcin Baldasso,Davide Cattaneo,Xianta Jiang,Michelle Ploughman*

Main category: cs.LG

TL;DR: fNIRS可用于检测多发性硬化症患者的精细运动和认知疲劳的脑活动生物标志物。


<details>
  <summary>Details</summary>
Motivation: 检测可能解释主观认知疲劳报告并为未来脑刺激治疗提供靶点的脑活动生物标志物。

Method: 使用fNIRS测量15名多发性硬化症患者和12名对照组在进行单任务和双任务手部精细运动任务时的大脑血流动力学反应，并使用机器学习分析数据。

Result: K-最近邻分类器在单任务中准确率为75.0%，在双任务中准确率为66.7%。研究发现，多发性硬化症患者的ipsilateral半球的缘上回/角回和中央前回（感觉整合和运动区域）的活动受到抑制，神经血管反应较慢。脱氧血红蛋白水平比氧合血红蛋白水平更能预测。

Conclusion: fNIRS数据的一种非常规分析方法揭示了新的脑活动生物标志物，可用于开发个性化的脑刺激靶点。

Abstract: People with Multiple Sclerosis (MS) complain of problems with hand dexterity
and cognitive fatigue. However, in many cases, impairments are subtle and
difficult to detect. Functional near-infrared spectroscopy (fNIRS) is a
non-invasive neuroimaging technique that measures brain hemodynamic responses
during cognitive or motor tasks. We aimed to detect brain activity biomarkers
that could explain subjective reports of cognitive fatigue while completing
dexterous tasks and provide targets for future brain stimulation treatments. We
recruited 15 people with MS who did not have a hand (Nine Hole Peg Test
[NHPT]), mobility, or cognitive impairment, and 12 age- and sex-matched
controls. Participants completed two types of hand dexterity tasks with their
dominant hand, single task and dual task (NHPT while holding a ball between the
fifth finger and hypothenar eminence of the same hand). We analyzed fNIRS data
(oxygenated and deoxygenated hemoglobin levels) using a machine learning
framework to classify MS patients from controls based on their brain activation
patterns in bilateral prefrontal and sensorimotor cortices. The K-Nearest
Neighbor classifier achieved an accuracy of 75.0% for single manual dexterity
tasks and 66.7% for the more complex dual manual dexterity tasks. Using XAI, we
found that the most important brain regions contributing to the machine
learning model were the supramarginal/angular gyri and the precentral gyrus
(sensory integration and motor regions) of the ipsilateral hemisphere, with
suppressed activity and slower neurovascular response in the MS group. During
both tasks, deoxygenated hemoglobin levels were better predictors than the
conventional measure of oxygenated hemoglobin. This nonconventional method of
fNIRS data analysis revealed novel brain activity biomarkers that can help
develop personalized brain stimulation targets.

</details>


### [584] [Beyond Formula Complexity: Effective Information Criterion Improves Performance and Interpretability for Symbolic Regression](https://arxiv.org/abs/2509.21780)
*Zihan Yu,Guanren Wang,Jingtao Ding,Huandong Wang,Yong Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Symbolic regression discovers accurate and interpretable formulas to describe
given data, thereby providing scientific insights for domain experts and
promoting scientific discovery. However, existing symbolic regression methods
often use complexity metrics as a proxy for interoperability, which only
considers the size of the formula but ignores its internal mathematical
structure. Therefore, while they can discover formulas with compact forms, the
discovered formulas often have structures that are difficult to analyze or
interpret mathematically. In this work, inspired by the observation that
physical formulas are typically numerically stable under limited calculation
precision, we propose the Effective Information Criterion (EIC). It treats
formulas as information processing systems with specific internal structures
and identifies the unreasonable structure in them by the loss of significant
digits or the amplification of rounding noise as data flows through the system.
We find that this criterion reveals the gap between the structural rationality
of models discovered by existing symbolic regression algorithms and real-world
physical formulas. Combining EIC with various search-based symbolic regression
algorithms improves their performance on the Pareto frontier and reduces the
irrational structure in the results. Combining EIC with generative-based
algorithms reduces the number of samples required for pre-training, improving
sample efficiency by 2~4 times. Finally, for different formulas with similar
accuracy and complexity, EIC shows a 70.2% agreement with 108 human experts'
preferences for formula interpretability, demonstrating that EIC, by measuring
the unreasonable structures in formulas, actually reflects the formula's
interpretability.

</details>


### [585] [FastGRPO: Accelerating Policy Optimization via Concurrency-aware Speculative Decoding and Online Draft Learning](https://arxiv.org/abs/2509.21792)
*Yizhou Zhang,Ning Lv,Teng Wang,Jisheng Dang*

Main category: cs.LG

TL;DR: GRPO training is slow due to response generation. This paper proposes a concurrency-aware speculative decoding framework and an online draft learning mechanism to speed up GRPO, achieving 2.35x-2.72x speedup.


<details>
  <summary>Details</summary>
Motivation: The practical deployment of Group Relative Policy Optimization (GRPO) is hindered by its slow training process, mainly due to the computationally intensive generation of multiple responses per query. Existing speculative decoding methods offer limited speedup under high-concurrency training.

Method: The paper proposes a concurrency-aware speculative decoding framework that dynamically adjusts drafting and verification based on real-time concurrency levels. It also introduces an online draft learning mechanism for the draft model to adapt using feedback signals from the target model.

Result: Experimental results on mathematical reasoning datasets show end-to-end speedups ranging from 2.35x to 2.72x, outperforming baseline methods.

Conclusion: The proposed concurrency-aware speculative decoding framework and online draft learning mechanism effectively address the performance bottlenecks in GRPO training, leading to significant acceleration and improved efficiency.

Abstract: Group relative policy optimization (GRPO) has demonstrated significant
potential in improving the reasoning capabilities of large language models
(LLMs) via reinforcement learning. However, its practical deployment is impeded
by an excessively slow training process, primarily attributed to the
computationally intensive autoregressive generation of multiple responses per
query, which makes the generation phase the primary performance bottleneck.
Although speculative decoding presents a promising direction for acceleration,
its direct application in GRPO achieves limited speedup under high-concurrency
training conditions. To overcome this limitation, we propose a
concurrency-aware speculative decoding framework that dynamically adjusts the
drafting and verification strategy according to real-time concurrency levels,
thereby maximizing the acceleration of the generation process. Furthermore, to
address performance degradation arising from distributional drift between the
evolving target model and the fixed draft model during training, we introduce
an online draft learning mechanism that enables the draft model to continuously
adapt using feedback signals from the target model. Experimental results across
multiple mathematical reasoning datasets and models demonstrate that the
proposed method achieves end-to-end speedups of 2.35x to 2.72x, significantly
surpassing baseline approaches in efficiency. The code is available at
https://github.com/yedaotian9/GRPO_speculative.

</details>


### [586] [Exploring the Relationships Between Physiological Signals During Automated Fatigue Detection](https://arxiv.org/abs/2509.21794)
*Kourosh Kakhi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharyab*

Main category: cs.LG

TL;DR: 通过分析ECG、EMG、EOG和EEG信号对的统计关系，并使用XGBoost模型，证明了多信号融合比单信号在疲劳检测中具有更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数疲劳检测研究仅依赖单一生理信号，而本研究旨在通过检查信号对之间的统计关系来提高分类的鲁棒性。

Method: 从ECG、EMG、EOG和EEG信号中提取特征，并对15种信号组合进行评估，同时使用决策树、随机森林、逻辑回归和XGBoost等多种模型进行测试。

Result: EMG和EEG信号组合的XGBoost模型取得了最佳性能。SHAP分析显示ECG和EOG信号的相关性是一个关键特征，并且多信号模型始终优于单信号模型。

Conclusion: 通过特征层面的融合生理信号可以提高疲劳监测系统的准确性、可解释性和实际应用性。

Abstract: Fatigue detection using physiological signals is critical in domains such as
transportation, healthcare, and performance monitoring. While most studies
focus on single modalities, this work examines statistical relationships
between signal pairs to improve classification robustness. Using the DROZY
dataset, we extracted features from ECG, EMG, EOG, and EEG across 15 signal
combinations and evaluated them with Decision Tree, Random Forest, Logistic
Regression, and XGBoost. Results show that XGBoost with the EMG EEG combination
achieved the best performance. SHAP analysis highlighted ECG EOG correlation as
a key feature, and multi signal models consistently outperformed single signal
ones. These findings demonstrate that feature level fusion of physiological
signals enhances accuracy, interpretability, and practical applicability of
fatigue monitoring systems.

</details>


### [587] [ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations](https://arxiv.org/abs/2509.21802)
*Chang Liu,Bohao Zhao,Jingtao Ding,Yong Li*

Main category: cs.LG

TL;DR: ChaosNexus 是一个在各种混沌动力学上预训练的 foundation model，使用 ScaleFormer 和 Mixture-of-Experts 来实现对新系统（zero-shot/few-shot）的预测，并在合成和真实世界基准测试中取得了最先进的性能，例如在 9000 多个混沌系统中将长期吸引子统计数据的保真度提高了 40%，并在 5 天全球天气预报中实现了低于 1 度的零样本平均误差。


<details>
  <summary>Details</summary>
Motivation: 传统的混沌系统预测模型缺乏泛化能力，无法处理真实世界中普遍存在的、对初始条件敏感且数据稀疏的新系统或数据受限的场景。需要一种能够实现零样本或少样本预测的模型。

Method: 提出 ChaosNexus，一个在多样化的混沌动力学语料库上预训练的 foundation model。采用名为 ScaleFormer 的新型多尺度架构，并辅以 Mixture-of-Experts 层，以捕捉普遍模式和系统特定的行为。

Result: ChaosNexus 在合成和真实世界基准测试中展现了最先进的零样本泛化能力。在超过 9000 个合成混沌系统的测试中，其长期吸引子统计数据的保真度比领先的基线提高了 40% 以上。在 5 天全球天气预报中，ChaosNexus 实现了低于 1 度的竞争性零样本平均误差，并且可以通过少样本微调进一步提高。

Conclusion: 跨系统泛化能力源于训练系统的多样性，而非单纯的数据量。ChaosNexus 的实验结果为科学 foundation model 提供了一个指导原则。

Abstract: Accurately forecasting chaotic systems, prevalent in domains such as weather
prediction and fluid dynamics, remains a significant scientific challenge. The
inherent sensitivity of these systems to initial conditions, coupled with a
scarcity of observational data, severely constrains traditional modeling
approaches. Since these models are typically trained for a specific system,
they lack the generalization capacity necessary for real-world applications,
which demand robust zero-shot or few-shot forecasting on novel or data-limited
scenarios. To overcome this generalization barrier, we propose ChaosNexus, a
foundation model pre-trained on a diverse corpus of chaotic dynamics.
ChaosNexus employs a novel multi-scale architecture named ScaleFormer augmented
with Mixture-of-Experts layers, to capture both universal patterns and
system-specific behaviors. The model demonstrates state-of-the-art zero-shot
generalization across both synthetic and real-world benchmarks. On a
large-scale testbed comprising over 9,000 synthetic chaotic systems, it
improves the fidelity of long-term attractor statistics by more than 40%
compared to the leading baseline. This robust performance extends to real-world
applications with exceptional data efficiency. For instance, in 5-day global
weather forecasting, ChaosNexus achieves a competitive zero-shot mean error
below 1 degree, a result that further improves with few-shot fine-tuning.
Moreover, experiments on the scaling behavior of ChaosNexus provide a guiding
principle for scientific foundation models: cross-system generalization stems
from the diversity of training systems, rather than sheer data volume.

</details>


### [588] [Scaling Laws for Neural Material Models](https://arxiv.org/abs/2509.21811)
*Akshay Trikha,Kyle Chu,Advait Gosai,Parker Szachta,Eric Weiner*

Main category: cs.LG

TL;DR: 深度学习在材料性质预测中，通过分析训练数据、模型大小和计算量对神经网络性能的影响，发现了经验性标度律，即损失L与相关超参数N之间存在幂律关系L = α · N−β。


<details>
  <summary>Details</summary>
Motivation: 利用深度学习加速材料设计过程，通过分析扩展训练数据、模型大小和计算量对神经网络性能的影响，以期找到更优的材料。

Method: 训练Transformer和EquiformerV2神经网络，并分析了增加训练数据量、模型大小和计算量对预测性能的影响，同时还调整了训练设置，如训练轮数、学习率和混合精度。

Result: 发现了适用于所训练模型的经验性标度律，能够预测增加超参数（训练数据、模型大小、计算量）对预测性能的影响，具体表现为损失L与超参数N之间存在幂律关系L = α · N−β。

Conclusion: 提出的经验性标度律为预测材料性质的深度学习模型提供了有价值的指导，未来可将此标度律应用于其他神经网络模型，如GemNet和全连接网络，并进行比较分析。

Abstract: Predicting material properties is crucial for designing better batteries,
semiconductors, and medical devices. Deep learning helps scientists quickly
find promising materials by predicting their energy, forces, and stresses.
Companies scale capacities of deep learning models in multiple domains, such as
language modeling, and invest many millions of dollars into such models. Our
team analyzes how scaling training data (giving models more information to
learn from), model sizes (giving models more capacity to learn patterns), and
compute (giving models more computational resources) for neural networks
affects their performance for material property prediction. In particular, we
trained both transformer and EquiformerV2 neural networks to predict material
properties. We find empirical scaling laws for these models: we can predict how
increasing each of the three hyperparameters (training data, model size, and
compute) affects predictive performance. In particular, the loss $L$ can be
measured with a power law relationship $L = \alpha \cdot N^{-\beta}$, where
$\alpha$ and $\beta$ are constants while $N$ is the relevant hyperparameter. We
also incorporate command-line arguments for changing training settings such as
the amount of epochs, maximum learning rate, and whether mixed precision is
enabled. Future work could entail further investigating scaling laws for other
neural network models in this domain, such as GemNet and fully connected
networks, to assess how they compare to the models we trained.

</details>


### [589] [Sharpness-Aware Minimization Can Hallucinate Minimizers](https://arxiv.org/abs/2509.21818)
*Chanwoong Park,Uijeong Jang,Ernest K. Ryu,Insoon Yang*

Main category: cs.LG

TL;DR: SAM 方法可能收敛到“幻觉”极小值点，这表明它可能并不总是收敛到原始目标的真正极小值点。本研究从理论上证明了这些幻觉极小值点的存在，并提出了一个避免它们的解决方案。


<details>
  <summary>Details</summary>
Motivation: 评估 SAM 方法在训练过程中收敛到“幻觉”极小值点的可能性，这些点并非原始目标函数的真正极小值点。

Method: 理论证明 SAM 可能收敛到幻觉极小值点，并确定了局部收敛的条件。通过实验验证了 SAM 在实践中确实可能收敛到这些点。最后，提出了一种简单的补救措施来避免这种情况。

Result: 证明了 SAM 方法可能收敛到非目标函数的极小值点（幻觉极小值点），并提供了理论和实验证据。最后，提出了一种解决方案。

Conclusion: SAM 方法可能收敛到幻觉极小值点，但已提出一种简单有效的解决方案来避免此问题。

Abstract: Sharpness-Aware Minimization (SAM) is a widely used method that steers
training toward flatter minimizers, which typically generalize better. In this
work, however, we show that SAM can converge to hallucinated minimizers --
points that are not minimizers of the original objective. We theoretically
prove the existence of such hallucinated minimizers and establish conditions
for local convergence to them. We further provide empirical evidence
demonstrating that SAM can indeed converge to these points in practice.
Finally, we propose a simple yet effective remedy for avoiding hallucinated
minimizers.

</details>


### [590] [On the Complexity Theory of Masked Discrete Diffusion: From $\mathrm{poly}(1/ε)$ to Nearly $ε$-Free](https://arxiv.org/abs/2509.21835)
*Xunpeng Huang,Yingyu Lin,Nishant Jain,Kaibo Wang,Difan Zou,Yian Ma,Tong Zhang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study masked discrete diffusion -- a flexible paradigm for text generation
in which tokens are progressively corrupted by special mask symbols before
being denoised. Although this approach has demonstrated strong empirical
performance, its theoretical complexity in high-dimensional settings remains
insufficiently understood. Existing analyses largely focus on uniform discrete
diffusion, and more recent attempts addressing masked diffusion either (1)
overlook widely used Euler samplers, (2) impose restrictive bounded-score
assumptions, or (3) fail to showcase the advantages of masked discrete
diffusion over its uniform counterpart. To address this gap, we show that Euler
samplers can achieve $\epsilon$-accuracy in total variation (TV) with
$\tilde{O}(d^{2}\epsilon^{-3/2})$ discrete score evaluations, thereby providing
the first rigorous analysis of typical Euler sampler in masked discrete
diffusion. We then propose a Mask-Aware Truncated Uniformization (MATU)
approach that both removes bounded-score assumptions and preserves unbiased
discrete score approximation. By exploiting the property that each token can be
unmasked at most once, MATU attains a nearly $\epsilon$-free complexity of
$O(d\,\ln d\cdot (1-\epsilon^2))$. This result surpasses existing
uniformization methods under uniform discrete diffusion, eliminating the
$\ln(1/\epsilon)$ factor and substantially speeding up convergence. Our
findings not only provide a rigorous theoretical foundation for masked discrete
diffusion, showcasing its practical advantages over uniform diffusion for text
generation, but also pave the way for future efforts to analyze diffusion-based
language models developed under masking paradigm.

</details>


### [591] [Beyond Johnson-Lindenstrauss: Uniform Bounds for Sketched Bilinear Forms](https://arxiv.org/abs/2509.21847)
*Rohan Deb,Qiaobo Li,Mayank Shrivastava,Arindam Banerjee*

Main category: cs.LG

TL;DR: 该研究提出了一个分析带草图双线性形式的通用框架，推导出基于相关集几何复杂度的统一界限，并扩展到涉及多个草图矩阵的情况，同时为带草图的联邦学习和探索算法提供改进的收敛和遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法在处理带草图的双线性形式时存在局限性，无法提供精确的统一界限。

Method: 提出一个通用框架，利用通用链式法则并引入处理集合对上最大值的新技术，并将其扩展到涉及多个草图矩阵的情况。

Result: 推导出了基于相关集几何复杂度的统一界限，改进了带草图的联邦学习算法的收敛界限，并为带草图的探索算法设计了具有更优遗憾界限的算法。

Conclusion: 该框架统一了现有方法，并为带草图的双线性形式提供了更强的理论保证，同时在实际应用中（如联邦学习和探索算法）也取得了改进。

Abstract: Uniform bounds on sketched inner products of vectors or matrices underpin
several important computational and statistical results in machine learning and
randomized algorithms, including the Johnson-Lindenstrauss (J-L) lemma, the
Restricted Isometry Property (RIP), randomized sketching, and approximate
linear algebra. However, many modern analyses involve *sketched bilinear
forms*, for which existing uniform bounds either do not apply or are not sharp
on general sets. In this work, we develop a general framework to analyze such
sketched bilinear forms and derive uniform bounds in terms of geometric
complexities of the associated sets. Our approach relies on generic chaining
and introduces new techniques for handling suprema over pairs of sets. We
further extend these results to the setting where the bilinear form involves a
sum of $T$ independent sketching matrices and show that the deviation scales as
$\sqrt{T}$. This unified analysis recovers known results such as the J-L lemma
as special cases, while extending RIP-type guarantees. Additionally, we obtain
improved convergence bounds for sketched Federated Learning algorithms where
such cross terms arise naturally due to sketched gradient compression, and
design sketched variants of bandit algorithms with sharper regret bounds that
depend on the geometric complexity of the action and parameter sets, rather
than the ambient dimension.

</details>


### [592] [Graph of Agents: Principled Long Context Modeling by Emergent Multi-Agent Collaboration](https://arxiv.org/abs/2509.21848)
*Taejong Joo,Shu Ishida,Ivan Sosnovik,Bryan Lim,Sahand Rezaei-Shoshtari,Adam Gaier,Robert Giaquinto*

Main category: cs.LG

TL;DR: 多智能体系统（GoA）通过将长文本建模问题形式化为压缩问题，并引入动态、输入依赖的协作结构，在文档问答基准测试中显著提高了性能，并且在有限的上下文窗口下也能超越具有更大上下文窗口的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体长文本建模方法依赖于手工设计的协作策略和提示工程，这限制了其通用性。

Method: 将长文本建模问题形式化为信息论压缩问题，并提出了一种动态构建输入依赖协作结构的图（GoA）。

Result: 在文档问答任务中，GoA 将检索增强生成的平均 F1 分数提高了 5.7%，并使基于固定协作结构的多智能体基线提高了 16.35%。在 LongBench 基准测试中，GoA 甚至在只有 2K 上下文窗口的情况下，其性能也超过了具有 128K 上下文窗口的 Llama 3.1 8B 模型，有效上下文长度显著增加。

Conclusion: GoA 提供了一个原则性的框架，用于解决长文本建模问题，并通过动态协作结构提高了效率和性能，克服了现有方法的局限性。

Abstract: As a model-agnostic approach to long context modeling, multi-agent systems
can process inputs longer than a large language model's context window without
retraining or architectural modifications. However, their performance often
heavily relies on hand-crafted multi-agent collaboration strategies and prompt
engineering, which limit generalizability. In this work, we introduce a
principled framework that formalizes the model-agnostic long context modeling
problem as a compression problem, yielding an information-theoretic compression
objective. Building on this framework, we propose Graph of Agents (GoA), which
dynamically constructs an input-dependent collaboration structure that
maximizes this objective. For Llama 3.1 8B and Qwen3 8B across six document
question answering benchmarks, GoA improves the average $F_1$ score of
retrieval-augmented generation by 5.7\% and a strong multi-agent baseline using
a fixed collaboration structure by 16.35\%, respectively. Even with only a 2K
context window, GoA surpasses the 128K context window Llama 3.1 8B on
LongBench, showing a dramatic increase in effective context length. Our source
code is available at https://github.com/tjoo512/graph-of-agents.

</details>


### [593] [MolSpectLLM: A Molecular Foundation Model Bridging Spectroscopy, Molecule Elucidation, and 3D Structure Generation](https://arxiv.org/abs/2509.21861)
*Shuaike Shen,Jiaqing Xie,Zhuo Yang,Antong Zhang,Shuzhou Sun,Ben Gao,Tianfan Fu,Biqing Qi,Yuqiang Li*

Main category: cs.LG

TL;DR: MolSpectLLM是一个结合了光谱和3D结构信息的分子基础模型，在光谱相关任务和分子阐释任务上表现出色，并能直接生成3D分子结构。


<details>
  <summary>Details</summary>
Motivation: 现有分子基础模型主要依赖SMILES表示，忽略了光谱和3D结构信息，限制了其在药物发现和反应预测等领域的应用效果，尤其是在立体化学、空间构象和实验验证至关重要的任务中。

Method: 提出MolSpectLLM模型，该模型基于Qwen2.5-7B进行预训练，统一了实验光谱和分子3D结构信息，明确建模分子光谱。

Result: MolSpectLLM在NMR、IR和MS基准测试中平均准确率达到0.53，在Spectra-to-SMILES任务上获得15.5%的序列准确率和41.7%的token准确率，性能优于通用的LLM。此外，该模型还能直接从SMILES或光谱输入生成准确的3D分子结构。

Conclusion: MolSpectLLM成功融合了光谱分析、分子阐释和分子设计，并在光谱相关任务、分子阐释任务以及3D分子结构生成方面取得了领先的性能。

Abstract: Recent advances in molecular foundation models have shown impressive
performance in molecular property prediction and de novo molecular design, with
promising applications in areas such as drug discovery and reaction prediction.
Nevertheless, most existing approaches rely exclusively on SMILES
representations and overlook both experimental spectra and 3D structural
information-two indispensable sources for capturing molecular behavior in
real-world scenarios. This limitation reduces their effectiveness in tasks
where stereochemistry, spatial conformation, and experimental validation are
critical. To overcome these challenges, we propose MolSpectLLM, a molecular
foundation model pretrained on Qwen2.5-7B that unifies experimental
spectroscopy with molecular 3D structure. By explicitly modeling molecular
spectra, MolSpectLLM achieves state-of-the-art performance on spectrum-related
tasks, with an average accuracy of 0.53 across NMR, IR, and MS benchmarks.
MolSpectLLM also shows strong performance on the spectra analysis task,
obtaining 15.5% sequence accuracy and 41.7% token accuracy on
Spectra-to-SMILES, substantially outperforming large general-purpose LLMs. More
importantly, MolSpectLLM not only achieves strong performance on molecular
elucidation tasks, but also generates accurate 3D molecular structures directly
from SMILES or spectral inputs, bridging spectral analysis, molecular
elucidation, and molecular design.

</details>


### [594] [Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Efficient Knowledge Grounding](https://arxiv.org/abs/2509.21865)
*Seong-Woong Shim,Myunsoo Kim,Jae Hyeon Cho,Byung-Jun Lee*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Retrieval-Augmented Generation (RAG) is a framework for grounding Large
Language Models (LLMs) in external, up-to-date information. However, recent
advancements in context window size allow LLMs to process inputs of up to 128K
tokens or more, offering an alternative strategy: supplying the full document
context directly to the model, rather than relying on RAG to retrieve a subset
of contexts. Nevertheless, this emerging alternative strategy has notable
limitations: (i) it is token-inefficient to handle large and potentially
redundant contexts; (ii) it exacerbates the `lost in the middle' phenomenon;
and (iii) under limited model capacity, it amplifies distraction, ultimately
degrading LLM output quality. In this paper, we propose LDAR (Learning
Distraction-Aware Retrieval), an adaptive retriever that learns to retrieve
contexts in a way that mitigates interference from distracting passages,
thereby achieving significantly higher performance with reduced token usage
compared to long-context approaches. Extensive experiments across diverse LLM
architectures and six knowledge-intensive benchmarks demonstrate the
effectiveness and robustness of our approach, highlighting the importance of
balancing the trade-off between information coverage and distraction.

</details>


### [595] [Abductive Logical Rule Induction by Bridging Inductive Logic Programming and Multimodal Large Language Models](https://arxiv.org/abs/2509.21874)
*Yifei Peng,Yaoli Liu,Enbo Xia,Yu Jin,Wang-Zhou Dai,Zhong Ren,Yao-Xiang Ding,Kun Zhou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose ILP-CoT, a method that bridges Inductive Logic Programming (ILP)
and Multimodal Large Language Models (MLLMs) for abductive logical rule
induction. The task involves both discovering logical facts and inducing
logical rules from a small number of unstructured textual or visual inputs,
which still remain challenging when solely relying on ILP, due to the
requirement of specified background knowledge and high computational cost, or
MLLMs, due to the appearance of perceptual hallucinations. Based on the key
observation that MLLMs could propose structure-correct rules even under
hallucinations, our approach automatically builds ILP tasks with pruned search
spaces based on the rule structure proposals from MLLMs, and utilizes ILP
system to output rules built upon rectified logical facts and formal inductive
reasoning. Its effectiveness is verified through challenging logical induction
benchmarks, as well as a potential application of our approach, namely
text-to-image customized generation with rule induction. Our code and data are
released at https://github.com/future-item/ILP-CoT.

</details>


### [596] [Zubov-Net: Adaptive Stability for Neural ODEs Reconciling Accuracy with Robustness](https://arxiv.org/abs/2509.21879)
*Chaoyang Luo,Yan Zou,Nanjing Huang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Despite neural ordinary differential equations (Neural ODEs) exhibiting
intrinsic robustness under input perturbations due to their dynamical systems
nature, recent approaches often involve imposing Lyapunov-based stability
conditions to provide formal robustness guarantees. However, a fundamental
challenge remains: the tension between robustness and accuracy, primarily
stemming from the difficulty in imposing appropriate stability conditions. To
address this, we propose an adaptive stable learning framework named Zubov-Net,
which innovatively reformulates Zubov's equation into a consistency
characterization between regions of attraction (RoAs) and prescribed RoAs
(PRoAs). Building on this consistency, we introduce a new paradigm for actively
controlling the geometry of RoAs by directly optimizing PRoAs to reconcile
accuracy and robustness. Our approach is realized through tripartite losses
(consistency, classification, and separation losses) and a parallel boundary
sampling algorithm that co-optimizes the Neural ODE and the Lyapunov function.
To enhance the discriminativity of Lyapunov functions, we design an
input-attention-based convex neural network via a softmax attention mechanism
that focuses on equilibrium-relevant features and also serves as weight
normalization to maintain training stability in deep architectures.
Theoretically, we prove that minimizing the tripartite loss guarantees
consistent alignment of PRoAs-RoAs, trajectory stability, and non-overlapping
PRoAs. Moreover, we establish stochastic convex separability with tighter
probability bounds and fewer dimensionality requirements to justify the convex
design in Lyapunov functions. Experimentally, Zubov-Net maintains high
classification accuracy while significantly improving robustness against
various stochastic noises and adversarial attacks.

</details>


### [597] [Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2509.21882)
*Aaron Tu,Weihao Xuan,Heli Qi,Xu Huang,Qingcheng Zeng,Shayan Talaei,Yijia Xiao,Peng Xia,Xiangru Tang,Yuchen Zhuang,Bing Hu,Hanqun Cao,Wenqi Shi,Tianang Leng,Rui Yang,Yingjian Chen,Ziqi Wang,Irene Li,Nan Liu,Huaxiu Yao,Li Erran Li,Ge Liu,Amin Saberi,Naoto Yokoya,Jure Leskovec,Yejin Choi,Fang Wu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a practical and
scalable approach to enhancing large language models in areas such as math,
code, and other structured tasks. Two questions motivate this paper: how much
of the reported gains survive under strictly parity-controlled evaluation, and
whether RLVR is cost-free or exacts a measurable tax. We argue that progress is
real, but gains are often overstated due to three forces - an RLVR tax,
evaluation pitfalls, and data contamination. Using a partial-prompt
contamination audit and matched-budget reproductions across base and RL models,
we show that several headline gaps shrink or vanish under clean,
parity-controlled evaluation. We then propose a tax-aware training and
evaluation protocol that co-optimizes accuracy, grounding, and calibrated
abstention and standardizes budgeting and provenance checks. Applied to recent
RLVR setups, this protocol yields more reliable estimates of reasoning gains
and, in several cases, revises prior conclusions. Our position is constructive:
RLVR is valuable and industry-ready; we advocate keeping its practical benefits
while prioritizing reliability, safety, and measurement.

</details>


### [598] [Why High-rank Neural Networks Generalize?: An Algebraic Framework with RKHSs](https://arxiv.org/abs/2509.21895)
*Yuka Hashimoto,Sho Sonoda,Isao Ishikawa,Masahiro Ikeda*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We derive a new Rademacher complexity bound for deep neural networks using
Koopman operators, group representations, and reproducing kernel Hilbert spaces
(RKHSs). The proposed bound describes why the models with high-rank weight
matrices generalize well. Although there are existing bounds that attempt to
describe this phenomenon, these existing bounds can be applied to limited types
of models. We introduce an algebraic representation of neural networks and a
kernel function to construct an RKHS to derive a bound for a wider range of
realistic models. This work paves the way for the Koopman-based theory for
Rademacher complexity bounds to be valid for more practical situations.

</details>


### [599] [Closing the Oracle Gap: Increment Vector Transformation for Class Incremental Learning](https://arxiv.org/abs/2509.21898)
*Zihuan Qiu,Yi Xu,Fanman Meng,Runtong Zhang,Linfeng Xu,Qingbo Wu,Hongliang Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Class Incremental Learning (CIL) aims to sequentially acquire knowledge of
new classes without forgetting previously learned ones. Despite recent
progress, current CIL methods still exhibit significant performance gaps
compared to their oracle counterparts-models trained with full access to
historical data. Inspired by recent insights on Linear Mode Connectivity (LMC),
we revisit the geometric properties of oracle solutions in CIL and uncover a
fundamental observation: these oracle solutions typically maintain low-loss
linear connections to the optimum of previous tasks. Motivated by this finding,
we propose Increment Vector Transformation (IVT), a novel plug-and-play
framework designed to mitigate catastrophic forgetting during training. Rather
than directly following CIL updates, IVT periodically teleports the model
parameters to transformed solutions that preserve linear connectivity to
previous task optimum. By maintaining low-loss along these connecting paths,
IVT effectively ensures stable performance on previously learned tasks. The
transformation is efficiently approximated using diagonal Fisher Information
Matrices, making IVT suitable for both exemplar-free and exemplar-based
scenarios, and compatible with various initialization strategies. Extensive
experiments on CIFAR-100, FGVCAircraft, ImageNet-Subset, and ImageNet-Full
demonstrate that IVT consistently enhances the performance of strong CIL
baselines. Specifically, on CIFAR-100, IVT improves the last accuracy of the
PASS baseline by +5.12% and reduces forgetting by 2.54%. For the
CLIP-pre-trained SLCA baseline on FGVCAircraft, IVT yields gains of +14.93% in
average accuracy and +21.95% in last accuracy. The code will be released.

</details>


### [600] [Discrete Guidance Matching: Exact Guidance for Discrete Flow Matching](https://arxiv.org/abs/2509.21912)
*Zhengyan Wan,Yidong Ouyang,Liyan Xie,Fang Fang,Hongyuan Zha,Guang Cheng*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Guidance provides a simple and effective framework for posterior sampling by
steering the generation process towards the desired distribution. When modeling
discrete data, existing approaches mostly focus on guidance with the
first-order Taylor approximation to improve the sampling efficiency. However,
such an approximation is inappropriate in discrete state spaces since the
approximation error could be large. A novel guidance framework for discrete
data is proposed to address this problem: We derive the exact transition rate
for the desired distribution given a learned discrete flow matching model,
leading to guidance that only requires a single forward pass in each sampling
step, significantly improving efficiency. This unified novel framework is
general enough, encompassing existing guidance methods as special cases, and it
can also be seamlessly applied to the masked diffusion model. We demonstrate
the effectiveness of our proposed guidance on energy-guided simulations and
preference alignment on text-to-image generation and multimodal understanding
tasks. The code is available through
https://github.com/WanZhengyan/Discrete-Guidance-Matching/tree/main.

</details>


### [601] [Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects](https://arxiv.org/abs/2509.21923)
*Fumin Wang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Interpretability is one of the considerations when applying machine learning
to high-stakes fields such as healthcare that involve matters of life safety.
Generalized Additive Models (GAMs) enhance interpretability by visualizing
shape functions. Nevertheless, to preserve interpretability, GAMs omit
higher-order interaction effects (beyond pairwise interactions), which imposes
significant constraints on their predictive performance. We observe that Curve
Ergodic Set Regression (CESR), a multiplicative model, naturally enables the
visualization of its shape functions and simultaneously incorporates both
interactions among all features and individual feature effects. Nevertheless,
CESR fails to demonstrate superior performance compared to GAMs. We introduce
Multiplicative-Additive Constrained Models (MACMs), which augment CESR with an
additive part to disentangle the intertwined coefficients of its interactive
and independent terms, thus effectively broadening the hypothesis space. The
model is composed of a multiplicative part and an additive part, whose shape
functions can both be naturally visualized, thereby assisting users in
interpreting how features participate in the decision-making process.
Consequently, MACMs constitute an improvement over both CESR and GAMs. The
experimental results indicate that neural network-based MACMs significantly
outperform both CESR and the current state-of-the-art GAMs in terms of
predictive performance.

</details>


### [602] [Generation Properties of Stochastic Interpolation under Finite Training Set](https://arxiv.org/abs/2509.21925)
*Yunchen Li,Shaohui Lin,Zhou Yu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper investigates the theoretical behavior of generative models under
finite training populations. Within the stochastic interpolation generative
framework, we derive closed-form expressions for the optimal velocity field and
score function when only a finite number of training samples are available. We
demonstrate that, under some regularity conditions, the deterministic
generative process exactly recovers the training samples, while the stochastic
generative process manifests as training samples with added Gaussian noise.
Beyond the idealized setting, we consider model estimation errors and introduce
formal definitions of underfitting and overfitting specific to generative
models. Our theoretical analysis reveals that, in the presence of estimation
errors, the stochastic generation process effectively produces convex
combinations of training samples corrupted by a mixture of uniform and Gaussian
noise. Experiments on generation tasks and downstream tasks such as
classification support our theory.

</details>


### [603] [Extracting Actionable Insights from Building Energy Data using Vision LLMs on Wavelet and 3D Recurrence Representations](https://arxiv.org/abs/2509.21934)
*Amine Bechar,Adel Oulefki,Abbes Amira,Fatih Kurogollu,Yassine Himeur*

Main category: cs.LG

TL;DR: 通过将一维时间序列转换为三维表示，并使用视觉语言大模型（VLLMs）进行微调，来分析复杂的建筑时间序列数据，以实现可操作的见解和建议。


<details>
  <summary>Details</summary>
Motivation: 由于能源数据的非线性和多尺度特性，分析复杂的建筑时间序列以获得可操作的见解和建议仍然具有挑战性。

Method: 提出一个框架，在数据的三维图形表示上对视觉语言大模型（VLLMs）进行微调。该方法使用连续小波变换（CWTs）和 recurrence plots （RPs）将一维时间序列转换为三维表示，从而捕获时间动态并定位频率异常。这些三维编码使 VLLMs 能够直观地解释能耗模式、检测异常并提供节能建议。

Result: 在真实的建筑能源数据集上对该框架进行了演示，微调后的 VLLMs 成功监控了建筑状态、识别了反复出现的异常并生成了优化建议。在数量上，Idefics-7B VLLM 在沙迦大学能源数据集上使用 CWTs 时实现了 0.0952 的验证损失，使用 RPs 时实现了 0.1064 的验证损失，优于直接在原始时间序列数据上进行微调（0.1176）的异常检测效果。

Conclusion: 这项工作弥合了时间序列分析和可视化之间的差距，为能源分析提供了一个可扩展且可解释的框架。

Abstract: The analysis of complex building time-series for actionable insights and
recommendations remains challenging due to the nonlinear and multi-scale
characteristics of energy data. To address this, we propose a framework that
fine-tunes visual language large models (VLLMs) on 3D graphical representations
of the data. The approach converts 1D time-series into 3D representations using
continuous wavelet transforms (CWTs) and recurrence plots (RPs), which capture
temporal dynamics and localize frequency anomalies. These 3D encodings enable
VLLMs to visually interpret energy-consumption patterns, detect anomalies, and
provide recommendations for energy efficiency. We demonstrate the framework on
real-world building-energy datasets, where fine-tuned VLLMs successfully
monitor building states, identify recurring anomalies, and generate
optimization recommendations. Quantitatively, the Idefics-7B VLLM achieves
validation losses of 0.0952 with CWTs and 0.1064 with RPs on the University of
Sharjah energy dataset, outperforming direct fine-tuning on raw time-series
data (0.1176) for anomaly detection. This work bridges time-series analysis and
visualization, providing a scalable and interpretable framework for energy
analytics.

</details>


### [604] [Statistical Advantage of Softmax Attention: Insights from Single-Location Regression](https://arxiv.org/abs/2509.21936)
*O. Duranthon,P. Marion,C. Boyer,B. Loureiro,L. Zdeborová*

Main category: cs.LG

TL;DR: Softmax attention is optimal for single-location regression, outperforming linear attention even in finite samples. Theoretical analysis reveals necessary properties for optimal activation functions.


<details>
  <summary>Details</summary>
Motivation: Investigate the dominance of softmax over alternative attention mechanisms and analyze linearized attention theoretically.

Method: Analyze the single-location regression task using ideas from statistical physics in the high-dimensional limit and finite-sample regimes.

Result: Softmax attention achieves Bayes risk at the population level, while linear attention falls short. Analysis identifies properties for optimal activation functions. In finite samples, softmax still outperforms linear attention.

Conclusion: Softmax attention is superior to linear attention for the studied regression task, with theoretical insights into optimal activation functions and performance in different regimes.

Abstract: Large language models rely on attention mechanisms with a softmax activation.
Yet the dominance of softmax over alternatives (e.g., component-wise or linear)
remains poorly understood, and many theoretical works have focused on the
easier-to-analyze linearized attention. In this work, we address this gap
through a principled study of the single-location regression task, where the
output depends on a linear transformation of a single input token at a random
location. Building on ideas from statistical physics, we develop an analysis of
attention-based predictors in the high-dimensional limit, where generalization
performance is captured by a small set of order parameters. At the population
level, we show that softmax achieves the Bayes risk, whereas linear attention
fundamentally falls short. We then examine other activation functions to
identify which properties are necessary for optimal performance. Finally, we
analyze the finite-sample regime: we provide an asymptotic characterization of
the test error and show that, while softmax is no longer Bayes-optimal, it
consistently outperforms linear attention. We discuss the connection with
optimization by gradient-based algorithms.

</details>


### [605] [Structural Information-based Hierarchical Diffusion for Offline Reinforcement Learning](https://arxiv.org/abs/2509.21942)
*Xianghua Zeng,Hao Peng,Angsheng Li,Yicheng Pan*

Main category: cs.LG

TL;DR: SIHD是一种基于结构信息的分层扩散框架，用于解决具有稀疏奖励的长期规划任务中的离线策略学习问题，通过自适应地构建扩散层级并利用结构信息增益作为条件信号，有效提高了决策性能和泛化能力，并引入了结构熵正则化来减少对离线数据集的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的分层方法在处理长期规划任务时，通常采用固定的两层扩散层级和单一固定的时间尺度，这限制了它们在不同下游任务中的适应性和决策灵活性。因此，需要一种能够自适应地构建扩散层级并灵活处理不同时间尺度的模型。

Method: SIHD通过分析离线轨迹中嵌入的结构信息来构建扩散层级，并利用每个状态社区的结构信息增益作为相应扩散层的条件信号。此外，还引入了结构熵正则化器，以鼓励探索代表性不足的状态并避免分布外推误差。

Result: SIHD在具有挑战性的离线强化学习任务评估中，显著优于最先进的基线方法，在决策性能方面表现更佳，并在各种场景下展现出优越的泛化能力。

Conclusion: SIHD通过自适应地构建多时间尺度的扩散层级，并利用结构信息增益作为条件信号，能够有效地进行离线策略学习，尤其是在具有稀疏奖励的长期规划环境中。结构熵正则化器的引入进一步增强了模型的鲁棒性，减少了对离线数据集的过度依赖。

Abstract: Diffusion-based generative methods have shown promising potential for
modeling trajectories from offline reinforcement learning (RL) datasets, and
hierarchical diffusion has been introduced to mitigate variance accumulation
and computational challenges in long-horizon planning tasks. However, existing
approaches typically assume a fixed two-layer diffusion hierarchy with a single
predefined temporal scale, which limits adaptability to diverse downstream
tasks and reduces flexibility in decision making. In this work, we propose
SIHD, a novel Structural Information-based Hierarchical Diffusion framework for
effective and stable offline policy learning in long-horizon environments with
sparse rewards. Specifically, we analyze structural information embedded in
offline trajectories to construct the diffusion hierarchy adaptively, enabling
flexible trajectory modeling across multiple temporal scales. Rather than
relying on reward predictions from localized sub-trajectories, we quantify the
structural information gain of each state community and use it as a
conditioning signal within the corresponding diffusion layer. To reduce
overreliance on offline datasets, we introduce a structural entropy regularizer
that encourages exploration of underrepresented states while avoiding
extrapolation errors from distributional shifts. Extensive evaluations on
challenging offline RL tasks show that SIHD significantly outperforms
state-of-the-art baselines in decision-making performance and demonstrates
superior generalization across diverse scenarios.

</details>


### [606] [Active Attacks: Red-teaming LLMs via Adaptive Environments](https://arxiv.org/abs/2509.21947)
*Taeyoung Yun,Pierre-Luc St-Charles,Jinkyoo Park,Yoshua Bengio,Minsu Kim*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We address the challenge of generating diverse attack prompts for large
language models (LLMs) that elicit harmful behaviors (e.g., insults, sexual
content) and are used for safety fine-tuning. Rather than relying on manual
prompt engineering, attacker LLMs can be trained with reinforcement learning
(RL) to automatically generate such prompts using only a toxicity classifier as
a reward. However, capturing a wide range of harmful behaviors is a significant
challenge that requires explicit diversity objectives. Existing
diversity-seeking RL methods often collapse to limited modes: once high-reward
prompts are found, exploration of new regions is discouraged. Inspired by the
active learning paradigm that encourages adaptive exploration, we introduce
\textit{Active Attacks}, a novel RL-based red-teaming algorithm that adapts its
attacks as the victim evolves. By periodically safety fine-tuning the victim
LLM with collected attack prompts, rewards in exploited regions diminish, which
forces the attacker to seek unexplored vulnerabilities. This process naturally
induces an easy-to-hard exploration curriculum, where the attacker progresses
beyond easy modes toward increasingly difficult ones. As a result, Active
Attacks uncovers a wide range of local attack modes step by step, and their
combination achieves wide coverage of the multi-mode distribution. Active
Attacks, a simple plug-and-play module that seamlessly integrates into existing
RL objectives, unexpectedly outperformed prior RL-based methods -- including
GFlowNets, PPO, and REINFORCE -- by improving cross-attack success rates
against GFlowNets, the previous state-of-the-art, from 0.07% to 31.28% (a
relative gain greater than $400\ \times$) with only a 6% increase in
computation. Our code is publicly available
\href{https://github.com/dbsxodud-11/active_attacks}{here}.

</details>


### [607] [Think Smart, Not Hard: Difficulty Adaptive Reasoning for Large Audio Language Models](https://arxiv.org/abs/2509.21960)
*Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Audio Language Models (LALMs), powered by the chain-of-thought (CoT)
paradigm, have shown remarkable reasoning capabilities. Intuitively, different
problems often require varying depths of reasoning. While some methods can
determine whether to reason for a given problem, they typically lack a
fine-grained mechanism to modulate how much to reason. This often results in a
``one-size-fits-all'' reasoning depth, which generates redundant overthinking
for simple questions while failing to allocate sufficient thought to complex
ones. In this paper, we conduct an in-depth analysis of LALMs and find that an
effective and efficient LALM should reason smartly by adapting its reasoning
depth to the problem's complexity. To achieve this, we propose a
difficulty-adaptive reasoning method for LALMs. Specifically, we propose a
reward function that dynamically links reasoning length to the model's
perceived problem difficulty. This reward encourages shorter, concise reasoning
for easy tasks and more elaborate, in-depth reasoning for complex ones.
Extensive experiments demonstrate that our method is both effective and
efficient, simultaneously improving task performance and significantly reducing
the average reasoning length. Further analysis on reasoning structure paradigm
offers valuable insights for future work.

</details>


### [608] [GRAM-TDI: adaptive multimodal representation learning for drug target interaction prediction](https://arxiv.org/abs/2509.21971)
*Feng Jiang,Amina Mollaysa,Hehuan Ma,Tommaso Mansi,Junzhou Huang,Mangal Prakash,Rui Liao*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Drug target interaction (DTI) prediction is a cornerstone of computational
drug discovery, enabling rational design, repurposing, and mechanistic
insights. While deep learning has advanced DTI modeling, existing approaches
primarily rely on SMILES protein pairs and fail to exploit the rich multimodal
information available for small molecules and proteins. We introduce GRAMDTI, a
pretraining framework that integrates multimodal molecular and protein inputs
into unified representations. GRAMDTI extends volume based contrastive learning
to four modalities, capturing higher-order semantic alignment beyond
conventional pairwise approaches. To handle modality informativeness, we
propose adaptive modality dropout, dynamically regulating each modality's
contribution during pre-training. Additionally, IC50 activity measurements,
when available, are incorporated as weak supervision to ground representations
in biologically meaningful interaction strengths. Experiments on four publicly
available datasets demonstrate that GRAMDTI consistently outperforms state of
the art baselines. Our results highlight the benefits of higher order
multimodal alignment, adaptive modality utilization, and auxiliary supervision
for robust and generalizable DTI prediction.

</details>


### [609] [Stage-wise Dynamics of Classifier-Free Guidance in Diffusion Models](https://arxiv.org/abs/2509.22007)
*Cheng Jin,Qitan Shi,Yuantao Gu*

Main category: cs.LG

TL;DR: CFG在扩散模型中虽然常用，但其对采样动态的影响尚不明确。本研究在多模态条件下分析了CFG，揭示了采样过程分为三个阶段：方向偏移、模式分离和收缩。CFG在这些阶段会加速采样、抑制弱模式、降低全局多样性，并在收缩阶段削弱精细变化。研究还提出了一种时变CFG策略，并验证了其能同时提升图像质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 探讨CFG对扩散模型采样动态的影响，特别是其在多模态条件下的作用，并解释为何更强的CFG会降低多样性。

Method: 在多模态条件下分析CFG，提出三阶段采样模型（方向偏移、模式分离、收缩），并通过实验验证理论预测，提出并验证了时变CFG策略。

Result: CFG的采样过程可分为三个阶段，每个阶段对采样动态有不同影响：方向偏移阶段引入偏差和范数增长；模式分离阶段抑制弱模式，降低全局多样性；收缩阶段削弱精细变化。实验表明，过早或过强的CFG会损害多样性，而时变CFG策略能提升质量和多样性。

Conclusion: CFG通过加速采样、抑制弱模式和放大内部收缩来影响采样动态，导致在提升条件保真度的同时不可避免地降低了多样性。一种精心设计的时间变化的CFG策略可以缓解这些问题，同时提高样本质量和多样性。

Abstract: Classifier-Free Guidance (CFG) is widely used to improve conditional fidelity
in diffusion models, but its impact on sampling dynamics remains poorly
understood. Prior studies, often restricted to unimodal conditional
distributions or simplified cases, provide only a partial picture. We analyze
CFG under multimodal conditionals and show that the sampling process unfolds in
three successive stages. In the Direction Shift stage, guidance accelerates
movement toward the weighted mean, introducing initialization bias and norm
growth. In the Mode Separation stage, local dynamics remain largely neutral,
but the inherited bias suppresses weaker modes, reducing global diversity. In
the Concentration stage, guidance amplifies within-mode contraction,
diminishing fine-grained variability. This unified view explains a widely
observed phenomenon: stronger guidance improves semantic alignment but
inevitably reduces diversity. Experiments support these predictions, showing
that early strong guidance erodes global diversity, while late strong guidance
suppresses fine-grained variation. Moreover, our theory naturally suggests a
time-varying guidance schedule, and empirical results confirm that it
consistently improves both quality and diversity.

</details>


### [610] [Goal-Guided Efficient Exploration via Large Language Model in Reinforcement Learning](https://arxiv.org/abs/2509.22008)
*Yajie Qi,Wei Wei,Lin Li,Lijun Zhang,Zhidong Gao,Da Wang,Huizhong Song*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Real-world decision-making tasks typically occur in complex and open
environments, posing significant challenges to reinforcement learning (RL)
agents' exploration efficiency and long-horizon planning capabilities. A
promising approach is LLM-enhanced RL, which leverages the rich prior knowledge
and strong planning capabilities of LLMs to guide RL agents in efficient
exploration. However, existing methods mostly rely on frequent and costly LLM
invocations and suffer from limited performance due to the semantic mismatch.
In this paper, we introduce a Structured Goal-guided Reinforcement Learning
(SGRL) method that integrates a structured goal planner and a goal-conditioned
action pruner to guide RL agents toward efficient exploration. Specifically,
the structured goal planner utilizes LLMs to generate a reusable, structured
function for goal generation, in which goals are prioritized. Furthermore, by
utilizing LLMs to determine goals' priority weights, it dynamically generates
forward-looking goals to guide the agent's policy toward more promising
decision-making trajectories. The goal-conditioned action pruner employs an
action masking mechanism that filters out actions misaligned with the current
goal, thereby constraining the RL agent to select goal-consistent policies. We
evaluate the proposed method on Crafter and Craftax-Classic, and experimental
results demonstrate that SGRL achieves superior performance compared to
existing state-of-the-art methods.

</details>


### [611] [Concept-SAE: Active Causal Probing of Visual Model Behavior](https://arxiv.org/abs/2509.22015)
*Jianrong Ding,Muxi Chen,Chenchen Zhao,Qiang Xu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Standard Sparse Autoencoders (SAEs) excel at discovering a dictionary of a
model's learned features, offering a powerful observational lens. However, the
ambiguous and ungrounded nature of these features makes them unreliable
instruments for the active, causal probing of model behavior. To solve this, we
introduce Concept-SAE, a framework that forges semantically grounded concept
tokens through a novel hybrid disentanglement strategy. We first quantitatively
demonstrate that our dual-supervision approach produces tokens that are
remarkably faithful and spatially localized, outperforming alternative methods
in disentanglement. This validated fidelity enables two critical applications:
(1) we probe the causal link between internal concepts and predictions via
direct intervention, and (2) we probe the model's failure modes by
systematically localizing adversarial vulnerabilities to specific layers.
Concept-SAE provides a validated blueprint for moving beyond correlational
interpretation to the mechanistic, causal probing of model behavior.

</details>


### [612] [AEGIS: Authentic Edge Growth In Sparsity for Link Prediction in Edge-Sparse Bipartite Knowledge Graphs](https://arxiv.org/abs/2509.22017)
*Hugh Xuechen Liu,Kıvanç Tatar*

Main category: cs.LG

TL;DR: AEGIS是一个边缘增强框架，通过重采样现有训练边缘来解决数据稀疏问题，从而提高链接预测的准确性。


<details>
  <summary>Details</summary>
Motivation: Bipartite知识图谱在特定领域数据稀疏，阻碍了链接预测。AEGIS旨在解决这个问题。

Method: AEGIS框架通过重采样现有训练边缘（均匀采样或反向度数加权采样）来增强数据，同时保持原始节点集，避免引入虚假节点。在自然稀疏图（游戏设计模式）和人为稀疏化后的基准图（Amazon, MovieLens）上进行了评估。评估指标包括AUC-ROC和Brier分数，并使用配对t检验与稀疏基线进行比较。

Result: 在Amazon和MovieLens数据集上，基于复制的AEGIS变体效果与基线相当，而语义KNN增强方法能够恢复AUC和校准度。随机和合成边缘则有害。在GDP图上，语义KNN在AUC提升和Brier分数降低方面效果最好，简单方法也降低了Brier分数。

Conclusion: 在稀疏二分图链接预测中，受真实性约束的重采样是一种有效的数据策略。当存在信息丰富的节点描述时，语义增强可以提供额外的提升。

Abstract: Bipartite knowledge graphs in niche domains are typically data-poor and
edge-sparse, which hinders link prediction. We introduce AEGIS (Authentic Edge
Growth In Sparsity), an edge-only augmentation framework that resamples
existing training edges -either uniformly simple or with inverse-degree bias
degree-aware -thereby preserving the original node set and sidestepping
fabricated endpoints. To probe authenticity across regimes, we consider
naturally sparse graphs (game design pattern's game-pattern network) and induce
sparsity in denser benchmarks (Amazon, MovieLens) via high-rate bond
percolation. We evaluate augmentations on two complementary metrics: AUC-ROC
(higher is better) and the Brier score (lower is better), using two-tailed
paired t-tests against sparse baselines. On Amazon and MovieLens, copy-based
AEGIS variants match the baseline while the semantic KNN augmentation is the
only method that restores AUC and calibration; random and synthetic edges
remain detrimental. On the text-rich GDP graph, semantic KNN achieves the
largest AUC improvement and Brier score reduction, and simple also lowers the
Brier score relative to the sparse control. These findings position
authenticity-constrained resampling as a data-efficient strategy for sparse
bipartite link prediction, with semantic augmentation providing an additional
boost when informative node descriptions are available.

</details>


### [613] [Task-Adaptive Parameter-Efficient Fine-Tuning for Weather Foundation Models](https://arxiv.org/abs/2509.22020)
*Shilei Cao,Hehai Lin,Jiashun Cheng,Yang Liu,Guowen Li,Xuehe Wang,Juepeng Zheng,Haoyuan Liang,Meng Jin,Chengwei Qin,Hong Cheng,Haohuan Fu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While recent advances in machine learning have equipped Weather Foundation
Models (WFMs) with substantial generalization capabilities across diverse
downstream tasks, the escalating computational requirements associated with
their expanding scale increasingly hinder practical deployment. Current
Parameter-Efficient Fine-Tuning (PEFT) methods, designed for vision or language
tasks, fail to address the unique challenges of weather downstream tasks, such
as variable heterogeneity, resolution diversity, and spatiotemporal coverage
variations, leading to suboptimal performance when applied to WFMs. To bridge
this gap, we introduce WeatherPEFT, a novel PEFT framework for WFMs
incorporating two synergistic innovations. First, during the forward pass,
Task-Adaptive Dynamic Prompting (TADP) dynamically injects the embedding
weights within the encoder to the input tokens of the pre-trained backbone via
internal and external pattern extraction, enabling context-aware feature
recalibration for specific downstream tasks. Furthermore, during
backpropagation, Stochastic Fisher-Guided Adaptive Selection (SFAS) not only
leverages Fisher information to identify and update the most task-critical
parameters, thereby preserving invariant pre-trained knowledge, but also
introduces randomness to stabilize the selection. We demonstrate the
effectiveness and efficiency of WeatherPEFT on three downstream tasks, where
existing PEFT methods show significant gaps versus Full-Tuning, and WeatherPEFT
achieves performance parity with Full-Tuning using fewer trainable parameters.
The code of this work will be released.

</details>


### [614] [Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error](https://arxiv.org/abs/2509.22023)
*Panagiotis Giannoulis,Yorgos Pantis,Christos Tzamos*

Main category: cs.LG

TL;DR: LLMs在解决组合问题（如SAT、TSP、算术）方面存在不足，本文提出一种解决NP类问题的新方法，以数独为例，使用GPT-2和深度优先搜索（DFS）策略，达到了99%的准确率，优于之前的神经符号方法，并将其与Min-Sum Set Cover问题联系起来。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在各种语言任务中表现出色，但在解决组合问题（如可满足性、旅行商问题甚至基本算术）时仍存在困难。

Method: 本文提出了一种新颖的方法来解决NP类问题，重点研究数独问题。该方法使用标准的解码器模型（GPT-2），不依赖外部工具或函数调用，结合了简单数独规则的模仿学习和显式的深度优先搜索（DFS）探索策略（包括启发式猜测和回溯）。

Result: 通过将模仿学习与DFS探索相结合，我们的方法实现了99%的准确率，超越了之前基于神经符号的方法，并且超越了纯粹的模仿学习方法。

Conclusion: 本文提出了一种利用模仿学习和深度优先搜索（DFS）结合的方法，为大型语言模型（LLMs）解决NP类问题（以数独为例）提供了新的途径，并取得了先进的准确率。该方法不依赖于定制架构或外部工具，并将问题与Min-Sum Set Cover问题联系起来，为未来的研究提供了理论基础。

Abstract: Despite their proficiency in various language tasks, Large Language Models
(LLMs) struggle with combinatorial problems like Satisfiability, Traveling
Salesman Problem, or even basic arithmetic. We address this gap through a novel
approach for solving problems in the class NP. We focus on the paradigmatic
task of Sudoku and achieve state-of-the-art accuracy (99\%) compared to prior
neuro-symbolic approaches. Unlike prior work that used custom architectures,
our method employs a vanilla decoder-only Transformer (GPT-2) without external
tools or function calling. Our method integrates imitation learning of simple
Sudoku rules with an explicit Depth-First Search (DFS) exploration strategy
involving informed guessing and backtracking. Moving beyond imitation learning,
we seek to minimize the number of guesses until reaching a solution. We provide
a rigorous analysis of this setup formalizing its connection to a contextual
variant of Min-Sum Set Cover, a well-studied problem in algorithms and
stochastic optimization.

</details>


### [615] [MCGM: Multi-stage Clustered Global Modeling for Long-range Interactions in Molecules](https://arxiv.org/abs/2509.22028)
*Haodong Pan,Yusong Wang,Nanning Zheng,Caijui Jiang*

Main category: cs.LG

TL;DR: MCGM是一个轻量级的模块，通过高效的聚类操作为几何GNN提供分层全局上下文，平均将OE62能量预测误差降低26.2%，并在AQM上达到最先进的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的几何GNN在处理长程相互作用时存在计算成本高、系统特异性强或需要仔细调参等问题。

Method: MCGM通过构建多分辨率原子簇层次结构，利用动态分层聚类提取全局信息，并通过学习到的变换将上下文传播回来，最终通过残差连接增强原子特征。

Result: MCGM将OE62能量预测误差平均降低26.2%。在AQM上，MCGM达到了最先进的准确性（能量为17.0 meV，力为4.9 meV/Å），并且参数比Neural P3M少20%。

Conclusion: MCGM能够有效地增强几何GNN处理长程相互作用的能力，并在多个基准测试中取得了显著的性能提升。

Abstract: Geometric graph neural networks (GNNs) excel at capturing molecular geometry,
yet their locality-biased message passing hampers the modeling of long-range
interactions. Current solutions have fundamental limitations: extending cutoff
radii causes computational costs to scale cubically with distance;
physics-inspired kernels (e.g., Coulomb, dispersion) are often system-specific
and lack generality; Fourier-space methods require careful tuning of multiple
parameters (e.g., mesh size, k-space cutoff) with added computational overhead.
We introduce Multi-stage Clustered Global Modeling (MCGM), a lightweight,
plug-and-play module that endows geometric GNNs with hierarchical global
context through efficient clustering operations. MCGM builds a multi-resolution
hierarchy of atomic clusters, distills global information via dynamic
hierarchical clustering, and propagates this context back through learned
transformations, ultimately reinforcing atomic features via residual
connections. Seamlessly integrated into four diverse backbone architectures,
MCGM reduces OE62 energy prediction error by an average of 26.2%. On AQM, MCGM
achieves state-of-the-art accuracy (17.0 meV for energy, 4.9 meV/{\AA} for
forces) while using 20% fewer parameters than Neural P3M. Code will be made
available upon acceptance.

</details>


### [616] [OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features](https://arxiv.org/abs/2509.22033)
*Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Rogov,Elena Tutubalina,Ivan Oseledets*

Main category: cs.LG

TL;DR: 通过强制学习到的特征之间的正交性，我们提出了 Orthogonal SAE (OrtSAE) 来解决稀疏自编码器 (SAE) 中的特征吸收和特征组合问题，并提高了可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏自编码器 (SAE) 在特征吸收（专业特征捕获通用特征实例）和特征组合（独立特征合并为复合表示）方面存在问题，这会产生表示漏洞。

Method: 我们引入了 Orthogonal SAE (OrtSAE)，这是一种通过强制学习到的特征之间的正交性来解决这些问题的新方法。通过实施一种新的训练程序，该程序会惩罚 SAE 特征之间两两余弦相似度，OrtSAE 可促进解纠缠特征的发展，同时与 SAE 大小成线性扩展，避免了显著的计算开销。

Result: 与传统 SAE 相比，OrtSAE 发现了 9% 的不同特征，减少了特征吸收（65%）和特征组合（15%），在虚假相关性去除方面提高了 6% 的性能，并在其他下游任务上取得了相当的性能。

Conclusion: OrtSAE 成功地解决了 SAE 中的特征吸收和特征组合问题，发现了更多可解释的特征，并能在不增加显著计算开销的情况下提高下游任务的性能。

Abstract: Sparse autoencoders (SAEs) are a technique for sparse decomposition of neural
network activations into human-interpretable features. However, current SAEs
suffer from feature absorption, where specialized features capture instances of
general features creating representation holes, and feature composition, where
independent features merge into composite representations. In this work, we
introduce Orthogonal SAE (OrtSAE), a novel approach aimed to mitigate these
issues by enforcing orthogonality between the learned features. By implementing
a new training procedure that penalizes high pairwise cosine similarity between
SAE features, OrtSAE promotes the development of disentangled features while
scaling linearly with the SAE size, avoiding significant computational
overhead. We train OrtSAE across different models and layers and compare it
with other methods. We find that OrtSAE discovers 9% more distinct features,
reduces feature absorption (by 65%) and composition (by 15%), improves
performance on spurious correlation removal (+6%), and achieves on-par
performance for other downstream tasks compared to traditional SAEs.

</details>


### [617] [Latent Diffusion : Multi-Dimension Stable Diffusion Latent Space Explorer](https://arxiv.org/abs/2509.22038)
*Zhihua Zhong,Xuanyang Huang*

Main category: cs.LG

TL;DR: 本篇论文提出了一种名为“\workname”的框架，用于将可定制的潜在空间操作集成到扩散模型中，以增强其艺术创作的灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型（如Stable Diffusion）缺乏像GANs那样直观的潜在向量控制，限制了其在艺术创作中的灵活性，因此需要引入潜在空间操作来增强其创作可能性。

Method: 提出名为“\workname”的框架，该框架能够对扩散模型中的概念和空间表征进行直接操作，从而实现在潜在空间中的可定制操作。

Result: 通过“Infinitepedia”和“Latent Motion”两件艺术作品的展示，证明了该框架在概念融合和动态运动生成方面的潜力，并揭示了具有语义和无意义区域的潜在空间结构。

Conclusion: 该框架扩展了生成艺术的创作可能性，并为理解扩散模型的潜在空间几何提供了新的见解，为未来的研究开辟了道路。

Abstract: Latent space is one of the key concepts in generative AI, offering powerful
means for creative exploration through vector manipulation. However, diffusion
models like Stable Diffusion lack the intuitive latent vector control found in
GANs, limiting their flexibility for artistic expression. This paper introduces
\workname, a framework for integrating customizable latent space operations
into the diffusion process. By enabling direct manipulation of conceptual and
spatial representations, this approach expands creative possibilities in
generative art. We demonstrate the potential of this framework through two
artworks, \textit{Infinitepedia} and \textit{Latent Motion}, highlighting its
use in conceptual blending and dynamic motion generation. Our findings reveal
latent space structures with semantic and meaningless regions, offering
insights into the geometry of diffusion models and paving the way for further
explorations of latent space.

</details>


### [618] [Convexity-Driven Projection for Point Cloud Dimensionality Reduction](https://arxiv.org/abs/2509.22043)
*Suman Sanyal*

Main category: cs.LG

TL;DR: CDP是一种无边界线性降维方法，用于保留点云的局部非凸性。它通过kNN图、容许对、归一化方向聚合来构建非凸性结构矩阵，并使用其前k个特征向量进行投影。该方法提供了两种可验证的保证：事后证书和平均情况谱界，用于约束投影后的失真。评估协议报告了固定和重新选择的配对绕道误差和证书分位数。


<details>
  <summary>Details</summary>
Motivation: 保留点云数据的局部非凸性。

Method: 构建kNN图，识别容许对，聚合归一化方向以形成非凸性结构矩阵，并使用该矩阵的前k个特征向量进行投影。

Result: 提供了两种可验证的保证：事后证书（约束每个容许对的后投影失真）和平均情况谱界（将期望捕获的方向能量与结构矩阵的谱相关联）。

Conclusion: CDP是一种有效的降维方法，能够保留点云数据的局部非凸性，并提供可验证的保证，使其能够应用于实际数据。

Abstract: We propose Convexity-Driven Projection (CDP), a boundary-free linear method
for dimensionality reduction of point clouds that targets preserving
detour-induced local non-convexity. CDP builds a $k$-NN graph, identifies
admissible pairs whose Euclidean-to-shortest-path ratios are below a threshold,
and aggregates their normalized directions to form a positive semidefinite
non-convexity structure matrix. The projection uses the top-$k$ eigenvectors of
the structure matrix. We give two verifiable guarantees. A pairwise
a-posteriori certificate that bounds the post-projection distortion for each
admissible pair, and an average-case spectral bound that links expected
captured direction energy to the spectrum of the structure matrix, yielding
quantile statements for typical distortion. Our evaluation protocol reports
fixed- and reselected-pairs detour errors and certificate quantiles, enabling
practitioners to check guarantees on their data.

</details>


### [619] [MO-GRPO: Mitigating Reward Hacking of Group Relative Policy Optimization on Multi-Objective Problems](https://arxiv.org/abs/2509.22047)
*Yuki Ichihara,Yuu Jinnai,Tetsuro Morimura,Mitsuki Sakamoto,Ryota Mitsuhashi,Eiji Uchibe*

Main category: cs.LG

TL;DR: GRPO在有准确奖励模型时有效，但在多目标设置下容易奖励破解。提出MO-GRPO，通过自动重加权奖励函数来解决此问题，确保所有奖励函数均匀贡献，并保持偏好顺序。实验证明MO-GRPO在多目标强化学习问题上优于GRPO。


<details>
  <summary>Details</summary>
Motivation: 在许多现实世界任务中，准确的奖励模型并不可用。在多目标设置下，GRPO容易奖励破解，牺牲部分目标。

Method: 提出MO-GRPO，一种GRPO的扩展，通过一个简单的归一化方法自动重加权奖励函数，根据其值的方差进行调整，确保所有奖励函数均匀地影响损失函数，同时保持偏好顺序。

Result: MO-GRPO在多臂老虎机、Mo-Gymnasium、机器翻译（WMT benchmark）和指令遵循任务的四个领域进行了实验评估。结果表明，MO-GRPO通过均匀分配奖励成分之间的相关性来实现稳定的学习，优于GRPO。

Conclusion: MO-GRPO是多目标强化学习问题的有前景的算法，能够解决GRPO在多目标设置下的奖励破解问题，并实现稳定的学习。

Abstract: Group Relative Policy Optimization (GRPO) has been shown to be an effective
algorithm when an accurate reward model is available. However, such a highly
reliable reward model is not available in many real-world tasks. In this paper,
we particularly focus on multi-objective settings, in which we identify that
GRPO is vulnerable to reward hacking, optimizing only one of the objectives at
the cost of the others. To address this issue, we propose MO-GRPO, an extension
of GRPO with a simple normalization method to reweight the reward functions
automatically according to the variances of their values. We first show
analytically that MO-GRPO ensures that all reward functions contribute evenly
to the loss function while preserving the order of preferences, eliminating the
need for manual tuning of the reward functions' scales. Then, we evaluate
MO-GRPO experimentally in four domains: (i) the multi-armed bandits problem,
(ii) simulated control task (Mo-Gymnasium), (iii) machine translation tasks on
the WMT benchmark (En-Ja, En-Zh), and (iv) instruction following task. MO-GRPO
achieves stable learning by evenly distributing correlations among the
components of rewards, outperforming GRPO, showing MO-GRPO to be a promising
algorithm for multi-objective reinforcement learning problems.

</details>


### [620] [BrainPro: Towards Large-scale Brain State-aware EEG Representation Learning](https://arxiv.org/abs/2509.22050)
*Yi Ding,Muyun Jiang,Weibang Jiang,Shuailei Zhang,Xinliang Zhou,Chenyu Liu,Shanglin Li,Yong Li,Cuntai Guan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Electroencephalography (EEG) is a non-invasive technique for recording brain
electrical activity, widely used in brain-computer interface (BCI) and
healthcare. Recent EEG foundation models trained on large-scale datasets have
shown improved performance and generalizability over traditional decoding
methods, yet significant challenges remain. Existing models often fail to
explicitly capture channel-to-channel and region-to-region interactions, which
are critical sources of information inherently encoded in EEG signals. Due to
varying channel configurations across datasets, they either approximate spatial
structure with self-attention or restrict training to a limited set of common
channels, sacrificing flexibility and effectiveness. Moreover, although EEG
datasets reflect diverse brain states such as emotion, motor, and others,
current models rarely learn state-aware representations during self-supervised
pre-training. To address these gaps, we propose BrainPro, a large EEG model
that introduces a retrieval-based spatial learning block to flexibly capture
channel- and region-level interactions across varying electrode layouts, and a
brain state-decoupling block that enables state-aware representation learning
through parallel encoders with decoupling and region-aware reconstruction
losses. This design allows BrainPro to adapt seamlessly to diverse tasks and
hardware settings. Pre-trained on an extensive EEG corpus, BrainPro achieves
state-of-the-art performance and robust generalization across nine public BCI
datasets. Our codes and the pre-trained weights will be released.

</details>


### [621] [Enriching Knowledge Distillation with Intra-Class Contrastive Learning](https://arxiv.org/abs/2509.22053)
*Hua Yuan,Ning Xu,Xin Geng,Yong Rui*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Since the advent of knowledge distillation, much research has focused on how
the soft labels generated by the teacher model can be utilized effectively.
Existing studies points out that the implicit knowledge within soft labels
originates from the multi-view structure present in the data. Feature
variations within samples of the same class allow the student model to
generalize better by learning diverse representations. However, in existing
distillation methods, teacher models predominantly adhere to ground-truth
labels as targets, without considering the diverse representations within the
same class. Therefore, we propose incorporating an intra-class contrastive loss
during teacher training to enrich the intra-class information contained in soft
labels. In practice, we find that intra-class loss causes instability in
training and slows convergence. To mitigate these issues, margin loss is
integrated into intra-class contrastive learning to improve the training
stability and convergence speed. Simultaneously, we theoretically analyze the
impact of this loss on the intra-class distances and inter-class distances. It
has been proved that the intra-class contrastive loss can enrich the
intra-class diversity. Experimental results demonstrate the effectiveness of
the proposed method.

</details>


### [622] [Towards Understanding Feature Learning in Parameter Transfer](https://arxiv.org/abs/2509.22056)
*Hua Yuan,Xuran Meng,Qiufeng Wang,Shiyu Xia,Ning Xu,Xu Yang,Jing Wang,Xin Geng,Yong Rui*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Parameter transfer is a central paradigm in transfer learning, enabling
knowledge reuse across tasks and domains by sharing model parameters between
upstream and downstream models. However, when only a subset of parameters from
the upstream model is transferred to the downstream model, there remains a lack
of theoretical understanding of the conditions under which such partial
parameter reuse is beneficial and of the factors that govern its effectiveness.
To address this gap, we analyze a setting in which both the upstream and
downstream models are ReLU convolutional neural networks (CNNs). Within this
theoretical framework, we characterize how the inherited parameters act as
carriers of universal knowledge and identify key factors that amplify their
beneficial impact on the target task. Furthermore, our analysis provides
insight into why, in certain cases, transferring parameters can lead to lower
test accuracy on the target task than training a new model from scratch.
Numerical experiments and real-world data experiments are conducted to
empirically validate our theoretical findings.

</details>


### [623] [The Rogue Scalpel: Activation Steering Compromises LLM Safety](https://arxiv.org/abs/2509.22067)
*Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Y. Rogov,Ivan Oseledets,Elena Tutubalina*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Activation steering is a promising technique for controlling LLM behavior by
adding semantically meaningful vectors directly into a model's hidden states
during inference. It is often framed as a precise, interpretable, and
potentially safer alternative to fine-tuning. We demonstrate the opposite:
steering systematically breaks model alignment safeguards, making it comply
with harmful requests. Through extensive experiments on different model
families, we show that even steering in a random direction can increase the
probability of harmful compliance from 0% to 2-27%. Alarmingly, steering benign
features from a sparse autoencoder (SAE), a common source of interpretable
directions, increases these rates by a further 2-4%. Finally, we show that
combining 20 randomly sampled vectors that jailbreak a single prompt creates a
universal attack, significantly increasing harmful compliance on unseen
requests. These results challenge the paradigm of safety through
interpretability, showing that precise control over model internals does not
guarantee precise control over model behavior.

</details>


### [624] [Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning](https://arxiv.org/abs/2509.22082)
*Li Xia,Zheng Liu,Sili Huang,Wei Tang,Xuan Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Federated Learning (FL) preserves privacy by keeping raw data local, yet
Gradient Inversion Attacks (GIAs) pose significant threats. In FedAVG
multi-step scenarios, attackers observe only aggregated gradients, making data
reconstruction challenging. Existing surrogate model methods like SME assume
linear parameter trajectories, but we demonstrate this severely underestimates
SGD's nonlinear complexity, fundamentally limiting attack effectiveness. We
propose Non-Linear Surrogate Model Extension (NL-SME), the first method to
introduce nonlinear parametric trajectory modeling for GIAs. Our approach
replaces linear interpolation with learnable quadratic B\'ezier curves that
capture SGD's curved characteristics through control points, combined with
regularization and dvec scaling mechanisms for enhanced expressiveness.
Extensive experiments on CIFAR-100 and FEMNIST datasets show NL-SME
significantly outperforms baselines across all metrics, achieving
order-of-magnitude improvements in cosine similarity loss while maintaining
computational efficiency.This work exposes heightened privacy vulnerabilities
in FL's multi-step update paradigm and offers novel perspectives for developing
robust defense strategies.

</details>


### [625] [SHAKE-GNN: Scalable Hierarchical Kirchhoff-Forest Graph Neural Network](https://arxiv.org/abs/2509.22100)
*Zhipu Cui,Johannes Lutzeyer*

Main category: cs.LG

TL;DR: SHAKE-GNN是一个基于Kirchhoff Forests的新的可扩展图级GNN框架，它通过多尺度表示在效率和性能之间进行权衡，并在多个大规模图分类基准上取得了有竞争力的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在图神经网络(GNNs)在各种学习任务中取得显著成功的同时，将其扩展到大型图，尤其是在图级任务中，仍然是一个重大挑战。

Method: 提出了一种名为SHAKE-GNN的新型可扩展图级GNN框架，该框架基于Kirchhoff Forests（一种用于构建图随机多分辨率分解的随机生成森林）。SHAKE-GNN生成多尺度表示，从而在效率和性能之间实现灵活的权衡。还提出了一种改进的、数据驱动的策略来选择权衡参数，并分析了SHAKE-GNN的时间复杂度。

Result: 在多个大规模图分类基准上的实验结果表明，SHAKE-GNN在提供可扩展性的同时，也取得了有竞争力的性能。

Conclusion: SHAKE-GNN是一个有前景的GNN框架，它通过利用Kirchhoff Forests解决了GNN在大规模图上的可扩展性挑战，并在图分类任务中展示了其效率和性能的平衡。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success across a range
of learning tasks. However, scaling GNNs to large graphs remains a significant
challenge, especially for graph-level tasks. In this work, we introduce
SHAKE-GNN, a novel scalable graph-level GNN framework based on a hierarchy of
Kirchhoff Forests, a class of random spanning forests used to construct
stochastic multi-resolution decompositions of graphs. SHAKE-GNN produces
multi-scale representations, enabling flexible trade-offs between efficiency
and performance. We introduce an improved, data-driven strategy for selecting
the trade-off parameter and analyse the time-complexity of SHAKE-GNN.
Experimental results on multiple large-scale graph classification benchmarks
demonstrate that SHAKE-GNN achieves competitive performance while offering
improved scalability.

</details>


### [626] [Reinforcement Learning for Durable Algorithmic Recourse](https://arxiv.org/abs/2509.22102)
*Marina Ceccon,Alessandro Fabris,Goran Radanović,Asia J. Biega,Gian Antonio Susto*

Main category: cs.LG

TL;DR: 该研究提出了一种新的时间感知算法追索框架，通过模拟候选人对建议的适应性来生成可行且有效的建议，并强调建议的持久性以应对模型更新和竞争环境。


<details>
  <summary>Details</summary>
Motivation: 现有算法追索研究侧重于模型更新的鲁棒性，但忽略了在动态且资源受限的环境中，建议会影响未来申请人池的时间动态。

Method: 提出了一种新的时间感知框架，对候选人对建议的适应性进行建模。引入了一种基于强化学习（RL）的追索算法，以捕捉不断变化的环境动态，生成可行且有效的建议。建议被设计为持久的，在预定义的时间范围内（T）保持有效性。

Result: 在复杂模拟环境中进行的大量实验表明，该方法在可行性和长期有效性之间取得了更好的平衡，显著优于现有方法。

Conclusion: 将时间动态和行为动态纳入实际追索系统的设计至关重要。

Abstract: Algorithmic recourse seeks to provide individuals with actionable
recommendations that increase their chances of receiving favorable outcomes
from automated decision systems (e.g., loan approvals). While prior research
has emphasized robustness to model updates, considerably less attention has
been given to the temporal dynamics of recourse--particularly in competitive,
resource-constrained settings where recommendations shape future applicant
pools. In this work, we present a novel time-aware framework for algorithmic
recourse, explicitly modeling how candidate populations adapt in response to
recommendations. Additionally, we introduce a novel reinforcement learning
(RL)-based recourse algorithm that captures the evolving dynamics of the
environment to generate recommendations that are both feasible and valid. We
design our recommendations to be durable, supporting validity over a predefined
time horizon T. This durability allows individuals to confidently reapply after
taking time to implement the suggested changes. Through extensive experiments
in complex simulation environments, we show that our approach substantially
outperforms existing baselines, offering a superior balance between feasibility
and long-term validity. Together, these results underscore the importance of
incorporating temporal and behavioral dynamics into the design of practical
recourse systems.

</details>


### [627] [Modeling Psychological Profiles in Volleyball via Mixed-Type Bayesian Networks](https://arxiv.org/abs/2509.22111)
*Maria Iannario,Dae-Jin Lee,Manuele Leonelli*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Psychological attributes rarely operate in isolation: coaches reason about
networks of related traits. We analyze a new dataset of 164 female volleyball
players from Italy's C and D leagues that combines standardized psychological
profiling with background information. To learn directed relationships among
mixed-type variables (ordinal questionnaire scores, categorical demographics,
continuous indicators), we introduce latent MMHC, a hybrid structure learner
that couples a latent Gaussian copula and a constraint-based skeleton with a
constrained score-based refinement to return a single DAG. We also study a
bootstrap-aggregated variant for stability. In simulations spanning sample
size, sparsity, and dimension, latent Max-Min Hill-Climbing (MMHC) attains
lower structural Hamming distance and higher edge recall than recent
copula-based learners while maintaining high specificity. Applied to
volleyball, the learned network organizes mental skills around goal setting and
self-confidence, with emotional arousal linking motivation and anxiety, and
locates Big-Five traits (notably neuroticism and extraversion) upstream of
skill clusters. Scenario analyses quantify how improvements in specific skills
propagate through the network to shift preparation, confidence, and
self-esteem. The approach provides an interpretable, data-driven framework for
profiling psychological traits in sport and for decision support in athlete
development.

</details>


### [628] [Countering adversarial evasion in regression analysis](https://arxiv.org/abs/2509.22113)
*David Benfield,Phan Tu Vuong,Alain Zemkoho*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Adversarial machine learning challenges the assumption that the underlying
distribution remains consistent throughout the training and implementation of a
prediction model. In particular, adversarial evasion considers scenarios where
adversaries adapt their data to influence particular outcomes from established
prediction models, such scenarios arise in applications such as spam email
filtering, malware detection and fake-image generation, where security methods
must be actively updated to keep up with the ever-improving generation of
malicious data. Game theoretic models have been shown to be effective at
modelling these scenarios and hence training resilient predictors against such
adversaries. Recent advancements in the use of pessimistic bilevel optimsiation
which remove assumptions about the convexity and uniqueness of the adversary's
optimal strategy have proved to be particularly effective at mitigating threats
to classifiers due to its ability to capture the antagonistic nature of the
adversary. However, this formulation has not yet been adapted to regression
scenarios. This article serves to propose a pessimistic bilevel optimisation
program for regression scenarios which makes no assumptions on the convexity or
uniqueness of the adversary's solutions.

</details>


### [629] [Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization](https://arxiv.org/abs/2509.22115)
*Chao Wang,Tao Yang,Hongtao Tian,Yunsheng Shi,Qiyao Ma,Xiaotao Liu,Ting Yao,Wenbo Ding*

Main category: cs.LG

TL;DR: D^3S框架通过在样本和token层面进行动态降采样，优先考虑信息量大的样本和token，提升了策略优化的效率，并取得了在Qwen2.5和Llama3.1上的先进性能，同时减少了样本和token的使用。


<details>
  <summary>Details</summary>
Motivation: 现有的Critic-free方法（如GRPO）虽然降低了内存需求，但由于信息量不足的样本和token稀释了关键学习信号，导致收敛缓慢。

Method: D^3S框架包括两个层面的操作：1. 样本层面：选择最大化优势方差（Var(A)）的样本子集，这在理论上被证明与策略梯度范数的上界正相关。2. Token层面：优先考虑优势幅度和策略熵乘积（|A_i,t|×H_i,t）高的token。此外，D^3S采用受课程学习启发的动态降采样策略，以防止过拟合。

Result: 在Qwen2.5和Llama3.1上的大量实验表明，D^3S与先进的强化学习算法集成后，在各种推理基准测试中实现了最先进的性能和泛化能力，同时需要的样本和token更少。

Conclusion: D^3S框架通过动态双层降采样，有效解决了Critic-free方法收敛缓慢的问题，提高了样本和token的使用效率，并在多个基准测试中取得了优于现有方法的性能。

Abstract: Critic-free methods like GRPO reduce memory demands by estimating advantages
from multiple rollouts but tend to converge slowly, as critical learning
signals are diluted by an abundance of uninformative samples and tokens. To
tackle this challenge, we propose the \textbf{Dynamic Dual-Level Down-Sampling
(D$^3$S)} framework that prioritizes the most informative samples and tokens
across groups to improve the efficient of policy optimization. D$^3$S operates
along two levels: (1) the sample-level, which selects a subset of rollouts to
maximize advantage variance ($\text{Var}(A)$). We theoretically proven that
this selection is positively correlated with the upper bound of the policy
gradient norms, yielding higher policy gradients. (2) the token-level, which
prioritizes tokens with a high product of advantage magnitude and policy
entropy ($|A_{i,t}|\times H_{i,t}$), focusing updates on tokens where the
policy is both uncertain and impactful. Moreover, to prevent overfitting to
high-signal data, D$^3$S employs a dynamic down-sampling schedule inspired by
curriculum learning. This schedule starts with aggressive down-sampling to
accelerate early learning and gradually relaxes to promote robust
generalization. Extensive experiments on Qwen2.5 and Llama3.1 demonstrate that
integrating D$^3$S into advanced RL algorithms achieves state-of-the-art
performance and generalization while requiring \textit{fewer} samples and
tokens across diverse reasoning benchmarks. Our code is added in the
supplementary materials and will be made publicly available.

</details>


### [630] [Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models](https://arxiv.org/abs/2509.22121)
*Jeong Eul Kwon,Joo Heung Yoon,Hyo Kyung Lee*

Main category: cs.LG

TL;DR: VITAL是一个基于LLM的框架，用于处理电子健康记录（EHR）中不规则采样和高缺失率的生理时间序列，它区分了生命体征和实验室检查，并对它们进行了不同的处理，在基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中的时间序列数据存在不规则采样和高缺失率的问题，这给建模带来了挑战。

Method: VITAL框架将生命体征映射到语言空间以捕捉时间上下文和推理缺失值，实验室检查则使用代表性摘要值或[未测量]标记进行嵌入。

Result: VITAL在PhysioNet基准数据集上的评估结果显示，其性能优于现有的不规则时间序列方法，并在高缺失率下保持稳健。

Conclusion: VITAL能有效处理EHR中不规则采样和高缺失率的生理时间序列，并在实际应用中表现出强大的性能。

Abstract: Irregular sampling and high missingness are intrinsic challenges in modeling
time series derived from electronic health records (EHRs),where clinical
variables are measured at uneven intervals depending on workflow and
intervention timing. To address this, we propose VITAL, a variable-aware, large
language model (LLM) based framework tailored for learning from irregularly
sampled physiological time series. VITAL differentiates between two distinct
types of clinical variables: vital signs, which are frequently recorded and
exhibit temporal patterns, and laboratory tests, which are measured
sporadically and lack temporal structure. It reprograms vital signs into the
language space, enabling the LLM to capture temporal context and reason over
missing values through explicit encoding. In contrast, laboratory variables are
embedded either using representative summary values or a learnable [Not
measured] token, depending on their availability. Extensive evaluations on the
benchmark datasets from the PhysioNet demonstrate that VITAL outperforms state
of the art methods designed for irregular time series. Furthermore, it
maintains robust performance under high levels of missingness, which is
prevalent in real world clinical scenarios where key variables are often
unavailable.

</details>


### [631] [Slicing Wasserstein Over Wasserstein Via Functional Optimal Transport](https://arxiv.org/abs/2509.22138)
*Moritz Piening,Robert Beinert*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Wasserstein distances define a metric between probability measures on
arbitrary metric spaces, including meta-measures (measures over measures). The
resulting Wasserstein over Wasserstein (WoW) distance is a powerful, but
computationally costly tool for comparing datasets or distributions over images
and shapes. Existing sliced WoW accelerations rely on parametric meta-measures
or the existence of high-order moments, leading to numerical instability. As an
alternative, we propose to leverage the isometry between the 1d Wasserstein
space and the quantile functions in the function space $L_2([0,1])$. For this
purpose, we introduce a general sliced Wasserstein framework for arbitrary
Banach spaces. Due to the 1d Wasserstein isometry, this framework defines a
sliced distance between 1d meta-measures via infinite-dimensional
$L_2$-projections, parametrized by Gaussian processes. Combining this 1d
construction with classical integration over the Euclidean unit sphere yields
the double-sliced Wasserstein (DSW) metric for general meta-measures. We show
that DSW minimization is equivalent to WoW minimization for discretized
meta-measures, while avoiding unstable higher-order moments and computational
savings. Numerical experiments on datasets, shapes, and images validate DSW as
a scalable substitute for the WoW distance.

</details>


### [632] [Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization](https://arxiv.org/abs/2509.22161)
*Takashi Morita*

Main category: cs.LG

TL;DR: 本文提出了一种新的正则化方法，用于解决向量化中的梯度反传问题，通过最小化 K-近邻平滑量化器与单纯形顶点之间的距离，同时保证了平滑量化器接近 one-hot 向量和码本的充分利用。


<details>
  <summary>Details</summary>
Motivation: 向量化中的量化步骤是非可微的，阻碍了梯度反传。现有的平滑向量化方法通常分别处理保证量化器接近 one-hot 向量和防止码本坍塌这两个问题。

Method: 提出了一种简单直观的正则化方法，通过最小化每个单纯形顶点与其 K-近邻平滑量化器之间的距离，同时促进这两个目标。

Result: 在离散图像自编码和对比语音表示学习等基准测试中，该方法实现了更可靠的码本利用，并提高了性能。

Conclusion: 所提出的正则化方法能够同时保证平滑量化器的近似性和码本的充分利用，并在实际应用中取得了比现有方法更好的效果。

Abstract: Vector quantization, which discretizes a continuous vector space into a
finite set of representative vectors (a codebook), has been widely adopted in
modern machine learning. Despite its effectiveness, vector quantization poses a
fundamental challenge: the non-differentiable quantization step blocks gradient
backpropagation. Smoothed vector quantization addresses this issue by relaxing
the hard assignment of a codebook vector into a weighted combination of
codebook entries, represented as the matrix product of a simplex vector and the
codebook. Effective smoothing requires two properties: (1) smoothed quantizers
should remain close to a onehot vector, ensuring tight approximation, and (2)
all codebook entries should be utilized, preventing code collapse. Existing
methods typically address these desiderata separately. By contrast, the present
study introduces a simple and intuitive regularization that promotes both
simultaneously by minimizing the distance between each simplex vertex and its
$K$-nearest smoothed quantizers. Experiments on representative benchmarks,
including discrete image autoencoding and contrastive speech representation
learning, demonstrate that the proposed method achieves more reliable codebook
utilization and improves performance compared to prior approaches.

</details>


### [633] [Lightweight error mitigation strategies for post-training N:M activation sparsity in LLMs](https://arxiv.org/abs/2509.22166)
*Shirin Alanova,Kristina Kazistova,Ekaterina Galaeva,Alina Kostromina,Vladimir Smirnov,Redko Dmitry,Alexey Dontsov,Maxim Zhelnin,Evgeny Burnaev,Egor Shvetsov*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The demand for efficient large language model (LLM) inference has intensified
the focus on sparsification techniques. While semi-structured (N:M) pruning is
well-established for weights, its application to activation pruning remains
underexplored despite its potential for dynamic, input-adaptive compression and
reductions in I/O overhead. This work presents a comprehensive analysis of
methods for post-training N:M activation pruning in LLMs. Across multiple LLMs,
we demonstrate that pruning activations enables superior preservation of
generative capabilities compared to weight pruning at equivalent sparsity
levels. We evaluate lightweight, plug-and-play error mitigation techniques and
pruning criteria, establishing strong hardware-friendly baselines that require
minimal calibration. Furthermore, we explore sparsity patterns beyond NVIDIA's
standard 2:4, showing that the 16:32 pattern achieves performance nearly on par
with unstructured sparsity. However, considering the trade-off between
flexibility and hardware implementation complexity, we focus on the 8:16
pattern as a superior candidate. Our findings provide both effective practical
methods for activation pruning and a motivation for future hardware to support
more flexible sparsity patterns. Our code is available
https://anonymous.4open.science/r/Structured-Sparse-Activations-Inference-EC3C/README.md .

</details>


### [634] [Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead](https://arxiv.org/abs/2509.22174)
*Durgesh Kalwar,Mayank Baranwal,Harshad Khadilkar*

Main category: cs.LG

TL;DR: DYNAWEIGHT是一个新的框架，用于在多代理网络中进行信息聚合，通过动态分配权重来加速去中心化学习，并且对数据异构性具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在数据敏感的环境下，去中心化学习在加强隐私和简化计算方面至关重要，尤其是在没有中央聚合的完全去中心化基础设施中。

Method: DYNAWEIGHT动态地根据邻近服务器在本地数据集上的相对损失来分配权重，而不是像Metropolis权重那样采用静态权重。

Result: 在MNIST、CIFAR10和CIFAR100等数据集上的实验表明，DYNAWEIGHT在各种服务器数量和图拓扑结构下显著提高了训练速度。

Conclusion: DYNAWEIGHT作为一种聚合方案，可以与任何底层服务器优化算法兼容，具有广泛的应用潜力。

Abstract: In today's data-sensitive landscape, distributed learning emerges as a vital
tool, not only fortifying privacy measures but also streamlining computational
operations. This becomes especially crucial within fully decentralized
infrastructures where local processing is imperative due to the absence of
centralized aggregation. Here, we introduce DYNAWEIGHT, a novel framework to
information aggregation in multi-agent networks. DYNAWEIGHT offers substantial
acceleration in decentralized learning with minimal additional communication
and memory overhead. Unlike traditional static weight assignments, such as
Metropolis weights, DYNAWEIGHT dynamically allocates weights to neighboring
servers based on their relative losses on local datasets. Consequently, it
favors servers possessing diverse information, particularly in scenarios of
substantial data heterogeneity. Our experiments on various datasets MNIST,
CIFAR10, and CIFAR100 incorporating various server counts and graph topologies,
demonstrate notable enhancements in training speeds. Notably, DYNAWEIGHT
functions as an aggregation scheme compatible with any underlying server-level
optimization algorithm, underscoring its versatility and potential for
widespread integration.

</details>


### [635] [Learning Equivariant Functions via Quadratic Forms](https://arxiv.org/abs/2509.22184)
*Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this study, we introduce a method for learning group (known or unknown)
equivariant functions by learning the associated quadratic form $x^T A x$
corresponding to the group from the data. Certain groups, known as orthogonal
groups, preserve a specific quadratic form, and we leverage this property to
uncover the underlying symmetry group under the assumption that it is
orthogonal. By utilizing the corresponding unique symmetric matrix and its
inherent diagonal form, we incorporate suitable inductive biases into the
neural network architecture, leading to models that are both simplified and
efficient. Our approach results in an invariant model that preserves norms,
while the equivariant model is represented as a product of a norm-invariant
model and a scale-invariant model, where the ``product'' refers to the group
action.
  Moreover, we extend our framework to a more general setting where the
function acts on tuples of input vectors via a diagonal (or product) group
action. In this extension, the equivariant function is decomposed into an
angular component extracted solely from the normalized first vector and a
scale-invariant component that depends on the full Gram matrix of the tuple.
This decomposition captures the inter-dependencies between multiple inputs
while preserving the underlying group symmetry.
  We assess the effectiveness of our framework across multiple tasks, including
polynomial regression, top quark tagging, and moment of inertia matrix
prediction. Comparative analysis with baseline methods demonstrates that our
model consistently excels in both discovering the underlying symmetry and
efficiently learning the corresponding equivariant function.

</details>


### [636] [Mechanistic Independence: A Principle for Identifiable Disentangled Representations](https://arxiv.org/abs/2509.22196)
*Stefan Matthes,Zhiwei Han,Hao Shen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Disentangled representations seek to recover latent factors of variation
underlying observed data, yet their identifiability is still not fully
understood. We introduce a unified framework in which disentanglement is
achieved through mechanistic independence, which characterizes latent factors
by how they act on observed variables rather than by their latent distribution.
This perspective is invariant to changes of the latent density, even when such
changes induce statistical dependencies among factors. Within this framework,
we propose several related independence criteria -- ranging from support-based
and sparsity-based to higher-order conditions -- and show that each yields
identifiability of latent subspaces, even under nonlinear, non-invertible
mixing. We further establish a hierarchy among these criteria and provide a
graph-theoretic characterization of latent subspaces as connected components.
Together, these results clarify the conditions under which disentangled
representations can be identified without relying on statistical assumptions.

</details>


### [637] [Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics](https://arxiv.org/abs/2509.22207)
*Mu Huang,Linning Xu,Mingyue Dai,Yidi Shao,Bo Dai*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Simulating physically plausible trajectories toward user-defined goals is a
fundamental yet challenging task in fluid dynamics. While particle-based
simulators can efficiently reproduce forward dynamics, inverse inference
remains difficult, especially in dissipative systems where dynamics are
irreversible and optimization-based solvers are slow, unstable, and often fail
to converge. In this work, we introduce the Reversible Graph Network Simulator
(R-GNS), a unified framework that enforces bidirectional consistency within a
single graph architecture. Unlike prior neural simulators that approximate
inverse dynamics by fitting backward data, R-GNS does not attempt to reverse
the underlying physics. Instead, we propose a mathematically invertible design
based on residual reversible message passing with shared parameters, coupling
forward dynamics with inverse inference to deliver accurate predictions and
efficient recovery of plausible initial states. Experiments on three
dissipative benchmarks (Water-3D, WaterRamps, and WaterDrop) show that R-GNS
achieves higher accuracy and consistency with only one quarter of the
parameters, and performs inverse inference more than 100 times faster than
optimization-based baselines. For forward simulation, R-GNS matches the speed
of strong GNS baselines, while in goal-conditioned tasks it eliminates
iterative optimization and achieves orders-of-magnitude speedups. On
goal-conditioned tasks, R-GNS further demonstrates its ability to complex
target shapes (e.g., characters "L" and "N") through vivid, physically
consistent trajectories. To our knowledge, this is the first reversible
framework that unifies forward and inverse simulation for dissipative fluid
systems.

</details>


### [638] [A Law of Data Reconstruction for Random Features (and Beyond)](https://arxiv.org/abs/2509.22214)
*Leonardo Iurada,Simone Bombari,Tatiana Tommasi,Marco Mondelli*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large-scale deep learning models are known to memorize parts of the training
set. In machine learning theory, memorization is often framed as interpolation
or label fitting, and classical results show that this can be achieved when the
number of parameters $p$ in the model is larger than the number of training
samples $n$. In this work, we consider memorization from the perspective of
data reconstruction, demonstrating that this can be achieved when $p$ is larger
than $dn$, where $d$ is the dimensionality of the data. More specifically, we
show that, in the random features model, when $p \gg dn$, the subspace spanned
by the training samples in feature space gives sufficient information to
identify the individual samples in input space. Our analysis suggests an
optimization method to reconstruct the dataset from the model parameters, and
we demonstrate that this method performs well on various architectures (random
features, two-layer fully-connected and deep residual networks). Our results
reveal a law of data reconstruction, according to which the entire training
dataset can be recovered as $p$ exceeds the threshold $dn$.

</details>


### [639] [Automatic Discovery of One Parameter Subgroups of $SO(n)$](https://arxiv.org/abs/2509.22219)
*Pavan Karjol,Vivek V Kashyap,Rohan Kashyap,Prathosh A P*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a novel framework for the automatic discovery of one-parameter
subgroups ($H_{\gamma}$) of $SO(3)$ and, more generally, $SO(n)$. One-parameter
subgroups of $SO(n)$ are crucial in a wide range of applications, including
robotics, quantum mechanics, and molecular structure analysis. Our method
utilizes the standard Jordan form of skew-symmetric matrices, which define the
Lie algebra of $SO(n)$, to establish a canonical form for orbits under the
action of $H_{\gamma}$. This canonical form is then employed to derive a
standardized representation for $H_{\gamma}$-invariant functions. By learning
the appropriate parameters, the framework uncovers the underlying one-parameter
subgroup $H_{\gamma}$. The effectiveness of the proposed approach is
demonstrated through tasks such as double pendulum modeling, moment of inertia
prediction, top quark tagging and invariant polynomial regression, where it
successfully recovers meaningful subgroup structure and produces interpretable,
symmetry-aware representations.

</details>


### [640] [Fairness-Aware Reinforcement Learning (FAReL): A Framework for Transparent and Balanced Sequential Decision-Making](https://arxiv.org/abs/2509.22232)
*Alexandra Cimpean,Nicole Orzan,Catholijn Jonker,Pieter Libin,Ann Nowé*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Equity in real-world sequential decision problems can be enforced using
fairness-aware methods. Therefore, we require algorithms that can make suitable
and transparent trade-offs between performance and the desired fairness
notions. As the desired performance-fairness trade-off is hard to specify a
priori, we propose a framework where multiple trade-offs can be explored.
Insights provided by the reinforcement learning algorithm regarding the
obtainable performance-fairness trade-offs can then guide stakeholders in
selecting the most appropriate policy. To capture fairness, we propose an
extended Markov decision process, $f$MDP, that explicitly encodes individuals
and groups. Given this $f$MDP, we formalise fairness notions in the context of
sequential decision problems and formulate a fairness framework that computes
fairness measures over time. We evaluate our framework in two scenarios with
distinct fairness requirements: job hiring, where strong teams must be composed
while treating applicants equally, and fraud detection, where fraudulent
transactions must be detected while ensuring the burden on customers is fairly
distributed. We show that our framework learns policies that are more fair
across multiple scenarios, with only minor loss in performance reward.
Moreover, we observe that group and individual fairness notions do not
necessarily imply one another, highlighting the benefit of our framework in
settings where both fairness types are desired. Finally, we provide guidelines
on how to apply this framework across different problem settings.

</details>


### [641] [ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity](https://arxiv.org/abs/2509.22246)
*Xiaoyang Liu,Tao Zhu,Zineng Dong,Yuntian Liu,Qingfeng Guo,Zhaoxuan Liu,Yu Chen,Tao Luo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Statement autoformalization, the automated translation of statements from
natural language into formal languages, has seen significant advancements, yet
the development of automated evaluation metrics remains limited. Existing
metrics for formal statement similarity often fail to balance semantic and
structural information. String-based approaches capture syntactic structure but
ignore semantic meaning, whereas proof-based methods validate semantic
equivalence but disregard structural nuances and, critically, provide no graded
similarity score in the event of proof failure. To address these issues, we
introduce ASSESS (A Semantic and Structural Evaluation Framework for Statement
Similarity), which comprehensively integrates semantic and structural
information to provide a continuous similarity score. Our framework first
transforms formal statements into Operator Trees to capture their syntactic
structure and then computes a similarity score using our novel TransTED
(Transformation Tree Edit Distance) Similarity metric, which enhances
traditional Tree Edit Distance by incorporating semantic awareness through
transformations. For rigorous validation, we present EPLA (Evaluating
Provability and Likeness for Autoformalization), a new benchmark of 524
expert-annotated formal statement pairs derived from miniF2F and ProofNet, with
labels for both semantic provability and structural likeness. Experiments on
EPLA demonstrate that TransTED Similarity outperforms existing methods,
achieving state-of-the-art accuracy and the highest Kappa coefficient. The
benchmark, and implementation code will be made public soon.

</details>


### [642] [Wavelet-Induced Rotary Encodings: RoPE Meets Graphs](https://arxiv.org/abs/2509.22259)
*Isaac Reid,Arijit Sehanobish,Cedrik Höfs,Bruno Mlodozeniec,Leonhard Vulpius,Federico Barbero,Adrian Weller,Krzysztof Choromanski,Richard E. Turner,Petar Veličković*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce WIRE: Wavelet-Induced Rotary Encodings. WIRE extends Rotary
Position Encodings (RoPE), a popular algorithm in LLMs and ViTs, to
graph-structured data. We demonstrate that WIRE is more general than RoPE,
recovering the latter in the special case of grid graphs. WIRE also enjoys a
host of desirable theoretical properties, including equivariance under node
ordering permutation, compatibility with linear attention, and (under select
assumptions) asymptotic dependence on graph resistive distance. We test WIRE on
a range of synthetic and real-world tasks, including identifying monochromatic
subgraphs, semantic segmentation of point clouds, and more standard graph
benchmarks. We find it to be effective in settings where the underlying graph
structure is important.

</details>


### [643] [Erase or Hide? Suppressing Spurious Unlearning Neurons for Robust Unlearning](https://arxiv.org/abs/2509.22263)
*Nakyeong Yang,Dong-Kyum Kim,Jea Kwon,Minsung Kim,Kyomin Jung,Meeyoung Cha*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models trained on web-scale data can memorize private or
sensitive knowledge, raising significant privacy risks. Although some
unlearning methods mitigate these risks, they remain vulnerable to "relearning"
during subsequent training, allowing a substantial portion of forgotten
knowledge to resurface. In this paper, we show that widely used unlearning
methods cause shallow alignment: instead of faithfully erasing target
knowledge, they generate spurious unlearning neurons that amplify negative
influence to hide it. To overcome this limitation, we introduce Ssiuu, a new
class of unlearning methods that employs attribution-guided regularization to
prevent spurious negative influence and faithfully remove target knowledge.
Experimental results confirm that our method reliably erases target knowledge
and outperforms strong baselines across two practical retraining scenarios: (1)
adversarial injection of private data, and (2) benign attack using an
instruction-following benchmark. Our findings highlight the necessity of robust
and faithful unlearning methods for safe deployment of language models.

</details>


### [644] [Fine-Grained Uncertainty Decomposition in Large Language Models: A Spectral Approach](https://arxiv.org/abs/2509.22272)
*Nassim Walha,Sebastian G. Gruber,Thomas Decker,Yinchong Yang,Alireza Javanmardi,Eyke Hüllermeier,Florian Buettner*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As Large Language Models (LLMs) are increasingly integrated in diverse
applications, obtaining reliable measures of their predictive uncertainty has
become critically important. A precise distinction between aleatoric
uncertainty, arising from inherent ambiguities within input data, and epistemic
uncertainty, originating exclusively from model limitations, is essential to
effectively address each uncertainty source. In this paper, we introduce
Spectral Uncertainty, a novel approach to quantifying and decomposing
uncertainties in LLMs. Leveraging the Von Neumann entropy from quantum
information theory, Spectral Uncertainty provides a rigorous theoretical
foundation for separating total uncertainty into distinct aleatoric and
epistemic components. Unlike existing baseline methods, our approach
incorporates a fine-grained representation of semantic similarity, enabling
nuanced differentiation among various semantic interpretations in model
responses. Empirical evaluations demonstrate that Spectral Uncertainty
outperforms state-of-the-art methods in estimating both aleatoric and total
uncertainty across diverse models and benchmark datasets.

</details>


### [645] [Unlocking the Power of Mixture-of-Experts for Task-Aware Time Series Analytics](https://arxiv.org/abs/2509.22279)
*Xingjian Wu,Zhengyu Li,Hanyin Cheng,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Time Series Analysis is widely used in various real-world applications such
as weather forecasting, financial fraud detection, imputation for missing data
in IoT systems, and classification for action recognization. Mixture-of-Experts
(MoE), as a powerful architecture, though demonstrating effectiveness in NLP,
still falls short in adapting to versatile tasks in time series analytics due
to its task-agnostic router and the lack of capability in modeling channel
correlations. In this study, we propose a novel, general MoE-based time series
framework called PatchMoE to support the intricate ``knowledge'' utilization
for distinct tasks, thus task-aware. Based on the observation that hierarchical
representations often vary across tasks, e.g., forecasting vs. classification,
we propose a Recurrent Noisy Gating to utilize the hierarchical information in
routing, thus obtaining task-sepcific capability. And the routing strategy is
operated on time series tokens in both temporal and channel dimensions, and
encouraged by a meticulously designed Temporal \& Channel Load Balancing Loss
to model the intricate temporal and channel correlations. Comprehensive
experiments on five downstream tasks demonstrate the state-of-the-art
performance of PatchMoE.

</details>


### [646] [Conditional Denoising Diffusion Autoencoders for Wireless Semantic Communications](https://arxiv.org/abs/2509.22282)
*Mehdi Letafati,Samad Ali,Matti Latva-aho*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Semantic communication (SemCom) systems aim to learn the mapping from
low-dimensional semantics to high-dimensional ground-truth. While this is more
akin to a "domain translation" problem, existing frameworks typically emphasize
on channel-adaptive neural encoding-decoding schemes, lacking full exploration
of signal distribution. Moreover, such methods so far have employed
autoencoder-based architectures, where the encoding is tightly coupled to a
matched decoder, causing scalability issues in practice. To address these gaps,
diffusion autoencoder models are proposed for wireless SemCom. The goal is to
learn a "semantic-to-clean" mapping, from the semantic space to the
ground-truth probability distribution. A neural encoder at semantic transmitter
extracts the high-level semantics, and a conditional diffusion model (CDiff) at
the semantic receiver exploits the source distribution for signal-space
denoising, while the received semantic latents are incorporated as the
conditioning input to "steer" the decoding process towards the semantics
intended by the transmitter. It is analytically proved that the proposed
decoder model is a consistent estimator of the ground-truth data. Furthermore,
extensive simulations over CIFAR-10 and MNIST datasets are provided along with
design insights, highlighting the performance compared to legacy autoencoders
and variational autoencoders (VAE). Simulations are further extended to the
multi-user SemCom, identifying the dominating factors in a more realistic
setup.

</details>


### [647] [A Multi-Level Framework for Multi-Objective Hypergraph Partitioning: Combining Minimum Spanning Tree and Proximal Gradient](https://arxiv.org/abs/2509.22294)
*Yingying Li,Mingxuan Xie,Hailong You,Yongqiang Yao,Hongwei Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper proposes an efficient hypergraph partitioning framework based on a
novel multi-objective non-convex constrained relaxation model. A modified
accelerated proximal gradient algorithm is employed to generate diverse
$k$-dimensional vertex features to avoid local optima and enhance partition
quality. Two MST-based strategies are designed for different data scales: for
small-scale data, the Prim algorithm constructs a minimum spanning tree
followed by pruning and clustering; for large-scale data, a subset of
representative nodes is selected to build a smaller MST, while the remaining
nodes are assigned accordingly to reduce complexity. To further improve
partitioning results, refinement strategies including greedy migration,
swapping, and recursive MST-based clustering are introduced for partitions.
  Experimental results on public benchmark sets demonstrate that the proposed
algorithm achieves reductions in cut size of approximately 2\%--5\% on average
compared to KaHyPar in 2, 3, and 4-way partitioning, with improvements of up to
35\% on specific instances. Particularly on weighted vertex sets, our algorithm
outperforms state-of-the-art partitioners including KaHyPar, hMetis,
Mt-KaHyPar, and K-SpecPart, highlighting its superior partitioning quality and
competitiveness. Furthermore, the proposed refinement strategy improves hMetis
partitions by up to 16\%. A comprehensive evaluation based on virtual instance
methodology and parameter sensitivity analysis validates the algorithm's
competitiveness and characterizes its performance trade-offs.

</details>


### [648] [Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers](https://arxiv.org/abs/2509.22445)
*Peter Shaw,James Cohan,Jacob Eisenstein,Kristina Toutanova*

Main category: cs.LG

TL;DR: 该论文提出了一个基于Kolmogorov复杂性理论的描述长度目标，用于解决Transformer等神经网络的模型复杂度度量问题，并通过变分目标函数在算法任务上实现了对低复杂度解的选择和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，最小描述长度（MDL）原理是奥卡姆剃刀的理论框架，但将其应用于Transformer等神经网络模型存在挑战，因为缺乏一个原则性、通用的模型复杂度度量方法。

Method: 提出渐近最优描述长度目标的概念，并证明了其对Transformer模型的可行性和可处理性，构建了一个基于自适应高斯混合先验的变分目标函数。

Result: 在算法任务的经验分析表明，该变分目标函数能够选择具有良好泛化能力的低复杂度解，但标准优化器在随机初始化时无法找到这些解，凸显了优化方面的挑战。

Conclusion: 该论文提供了一个理论框架，用于识别具有强渐近保证的描述长度目标，为训练具有更好压缩和泛化能力的神经网络指明了方向。

Abstract: The Minimum Description Length (MDL) principle offers a formal framework for
applying Occam's razor in machine learning. However, its application to neural
networks such as Transformers is challenging due to the lack of a principled,
universal measure for model complexity. This paper introduces the theoretical
notion of asymptotically optimal description length objectives, grounded in the
theory of Kolmogorov complexity. We establish that a minimizer of such an
objective achieves optimal compression, for any dataset, up to an additive
constant, in the limit as model resource bounds increase. We prove that
asymptotically optimal objectives exist for Transformers, building on a new
demonstration of their computational universality. We further show that such
objectives can be tractable and differentiable by constructing and analyzing a
variational objective based on an adaptive Gaussian mixture prior. Our
empirical analysis shows that this variational objective selects for a
low-complexity solution with strong generalization on an algorithmic task, but
standard optimizers fail to find such solutions from a random initialization,
highlighting key optimization challenges. More broadly, by providing a
theoretical framework for identifying description length objectives with strong
asymptotic guarantees, we outline a potential path towards training neural
networks that achieve greater compression and generalization.

</details>


### [649] [Aurora: Towards Universal Generative Multimodal Time Series Forecasting](https://arxiv.org/abs/2509.22295)
*Xingjian Wu,Jianxin Jin,Wanghui Qiu,Peng Chen,Yang Shu,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Cross-domain generalization is very important in Time Series Forecasting
because similar historical information may lead to distinct future trends due
to the domain-specific characteristics. Recent works focus on building unimodal
time series foundation models and end-to-end multimodal supervised models.
Since domain-specific knowledge is often contained in modalities like texts,
the former lacks the explicit utilization of them, thus hindering the
performance. The latter is tailored for end-to-end scenarios and does not
support zero-shot inference for cross-domain scenarios. In this work, we
introduce Aurora, a Multimodal Time Series Foundation Model, which supports
multimodal inputs and zero-shot inference. Pretrained on Corss-domain
Multimodal Time Series Corpus, Aurora can adaptively extract and focus on key
domain knowledge contained in corrsponding text or image modalities, thus
possessing strong Cross-domain generalization capability. Through tokenization,
encoding, and distillation, Aurora can extract multimodal domain knowledge as
guidance and then utilizes a Modality-Guided Multi-head Self-Attention to
inject them into the modeling of temporal representations. In the decoding
phase, the multimodal representations are used to generate the conditions and
prototypes of future tokens, contributing to a novel Prototype-Guided Flow
Matching for generative probabilistic forecasting. Comprehensive experiments on
well-recognized benchmarks, including TimeMMD, TSFM-Bench and ProbTS,
demonstrate the consistent state-of-the-art performance of Aurora on both
unimodal and multimodal scenarios.

</details>


### [650] [IIET: Efficient Numerical Transformer via Implicit Iterative Euler Method](https://arxiv.org/abs/2509.22463)
*Xinyu Liu,Bei Li,Jiahao Liu,Junhao Ruan,Kechen Jiao,Hongyin Tang,Jingang Wang,Xiao Tong,Jingbo Zhu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: High-order numerical methods enhance Transformer performance in tasks like
NLP and CV, but introduce a performance-efficiency trade-off due to increased
computational overhead. Our analysis reveals that conventional efficiency
techniques, such as distillation, can be detrimental to the performance of
these models, exemplified by PCformer. To explore more optimizable ODE-based
Transformer architectures, we propose the \textbf{I}terative \textbf{I}mplicit
\textbf{E}uler \textbf{T}ransformer \textbf{(IIET)}, which simplifies
high-order methods using an iterative implicit Euler approach. This
simplification not only leads to superior performance but also facilitates
model compression compared to PCformer. To enhance inference efficiency, we
introduce \textbf{I}teration \textbf{I}nfluence-\textbf{A}ware
\textbf{D}istillation \textbf{(IIAD)}. Through a flexible threshold, IIAD
allows users to effectively balance the performance-efficiency trade-off. On
lm-evaluation-harness, IIET boosts average accuracy by 2.65\% over vanilla
Transformers and 0.8\% over PCformer. Its efficient variant, E-IIET,
significantly cuts inference overhead by 55\% while retaining 99.4\% of the
original task accuracy. Moreover, the most efficient IIET variant achieves an
average performance gain exceeding 1.6\% over vanilla Transformer with
comparable speed.

</details>


### [651] [HEAPr: Hessian-based Efficient Atomic Expert Pruning in Output Space](https://arxiv.org/abs/2509.22299)
*Ke Li,Zheng Yang,Zhongbin Zhou,Feng Xue,Zhonglin Jiang,Wenxiao Wang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Mixture-of-Experts (MoE) architectures in large language models (LLMs)
deliver exceptional performance and reduced inference costs compared to dense
LLMs. However, their large parameter counts result in prohibitive memory
requirements, limiting practical deployment. While existing pruning methods
primarily focus on expert-level pruning, this coarse granularity often leads to
substantial accuracy degradation. In this work, we introduce HEAPr, a novel
pruning algorithm that decomposes experts into smaller, indivisible atomic
experts, enabling more precise and flexible atomic expert pruning. To measure
the importance of each atomic expert, we leverage second-order information
based on principles similar to Optimal Brain Surgeon (OBS) theory. To address
the computational and storage challenges posed by second-order information,
HEAPr exploits the inherent properties of atomic experts to transform the
second-order information from expert parameters into that of atomic expert
parameters, and further simplifies it to the second-order information of atomic
expert outputs. This approach reduces the space complexity from $O(d^4)$, where
d is the model's dimensionality, to $O(d^2)$. HEAPr requires only two forward
passes and one backward pass on a small calibration set to compute the
importance of atomic experts. Extensive experiments on MoE models, including
DeepSeek MoE and Qwen MoE family, demonstrate that HEAPr outperforms existing
expert-level pruning methods across a wide range of compression ratios and
benchmarks. Specifically, HEAPr achieves nearly lossless compression at
compression ratios of 20% ~ 25% in most models, while also reducing FLOPs
nearly by 20%. The code can be found at
\href{https://github.com/LLIKKE/HEAPr}{https://github.com/LLIKKE/HEAPr}.

</details>


### [652] [SoDaDE: Solvent Data-Driven Embeddings with Small Transformer Models](https://arxiv.org/abs/2509.22302)
*Gabriel Kitso Gibberd,Jose Pablo Folch,Antonio Del Rio Chanona*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Computational representations have become crucial in unlocking the recent
growth of machine learning algorithms for chemistry. Initially hand-designed,
machine learning has shown that meaningful representations can be learnt from
data. Chemical datasets are limited and so the representations learnt from data
are generic, being trained on broad datasets which contain shallow information
on many different molecule types. For example, generic fingerprints lack
physical context specific to solvents. However, the use of harmful solvents is
a leading climate-related issue in the chemical industry, and there is a surge
of interest in green solvent replacement. To empower this research, we propose
a new solvent representation scheme by developing Solvent Data Driven
Embeddings (SoDaDE). SoDaDE uses a small transformer model and solvent property
dataset to create a fingerprint for solvents. To showcase their effectiveness,
we use SoDaDE to predict yields on a recently published dataset, outperforming
previous representations. We demonstrate through this paper that data-driven
fingerprints can be made with small datasets and set-up a workflow that can be
explored for other applications.

</details>


### [653] [EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning](https://arxiv.org/abs/2509.22576)
*Xu Wujiang,Wentian Zhao,Zhenting Wang,Li Yu-Jhe,Jin Can,Jin Mingyu,Mei Kai,Wan Kun,Metaxas Dimitris*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Training LLM agents in multi-turn environments with sparse rewards, where
completing a single task requires 30+ turns of interaction within an episode,
presents a fundamental challenge for reinforcement learning. We identify a
critical failure mode unique to this setting: the exploration-exploitation
cascade failure. This cascade begins with early-stage policy premature
convergence, where sparse feedback causes agents to commit to flawed,
low-entropy strategies. Subsequently, agents enter late-stage policy collapse,
where conventional entropy regularization becomes counterproductive, promoting
chaotic exploration that destabilizes training. We propose Entropy-regularized
Policy Optimization (EPO), a general framework that breaks this failure cycle
through three synergistic mechanisms: (1) adopting entropy regularization in
multi-turn settings to enhance exploration, (2) an entropy smoothing
regularizer that bounds policy entropy within historical averages to prevent
abrupt fluctuations, and (3) adaptive phase-based weighting that balances
exploration and exploitation across training. Our analysis justifies that EPO
guarantees monotonically decreasing entropy variance while maintaining
convergence. EPO achieves up to 152% performance improvement on ScienceWorld
and up to 19.8% on ALFWorld. Our work demonstrates that multi-turn
sparse-reward settings require fundamentally different entropy control than
traditional RL, with broad implications for LLM agent training.

</details>


### [654] [Adaptive Policy Backbone via Shared Network](https://arxiv.org/abs/2509.22310)
*Bumgeun Park,Donghwan Lee*

Main category: cs.LG

TL;DR: APB是一种元迁移RL方法，通过在共享骨干前后插入轻量级线性层，实现参数高效的微调（PEFT），同时在适应过程中保留先验知识。它提高了样本效率，并能适应现有元RL基线通常会失败的分布外（OOD）任务。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够有效利用先验知识，并在任务不匹配的情况下（包括分布外任务）进行适应的RL方法。

Method: 提出了一种名为APB（Adaptive Policy Backbone）的元迁移RL方法。APB通过在共享骨干网络前后插入轻量级线性层，实现了参数高效的微调（PEFT），并能在适应过程中保留先验知识。

Result: APB在样本效率方面优于标准RL方法，并且能够成功适应现有的元RL基线通常会失败的分布外（OOD）任务。

Conclusion: APB是一种有效的元迁移RL方法，能够解决任务不匹配问题，尤其是在分布外场景下，提高了样本效率和适应性。

Abstract: Reinforcement learning (RL) has achieved impressive results across domains,
yet learning an optimal policy typically requires extensive interaction data,
limiting practical deployment. A common remedy is to leverage priors, such as
pre-collected datasets or reference policies, but their utility degrades under
task mismatch between training and deployment. While prior work has sought to
address this mismatch, it has largely been restricted to in-distribution
settings. To address this challenge, we propose Adaptive Policy Backbone (APB),
a meta-transfer RL method that inserts lightweight linear layers before and
after a shared backbone, thereby enabling parameter-efficient fine-tuning
(PEFT) while preserving prior knowledge during adaptation. Our results show
that APB improves sample efficiency over standard RL and adapts to
out-of-distribution (OOD) tasks where existing meta-RL baselines typically
fail.

</details>


### [655] [Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments](https://arxiv.org/abs/2509.22319)
*Hyunwoo Kim,Junha Lee,Mincheol Choi,Jeonghwan Lee,Jaeshin Cho*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep learning models have become increasingly large and complex, resulting in
higher memory consumption and computational demands. Consequently, model
loading times and initial inference latency have increased, posing significant
challenges in mobile and latency-sensitive environments where frequent model
loading and unloading are required, which directly impacts user experience.
While Knowledge Distillation (KD) offers a solution by compressing large
teacher models into smaller student ones, it often comes at the cost of reduced
performance. To address this trade-off, we propose Progressive Weight Loading
(PWL), a novel technique that enables fast initial inference by first deploying
a lightweight student model, then incrementally replacing its layers with those
of a pre-trained teacher model. To support seamless layer substitution, we
introduce a training method that not only aligns intermediate feature
representations between student and teacher layers, but also improves the
overall output performance of the student model. Our experiments on VGG,
ResNet, and ViT architectures demonstrate that models trained with PWL maintain
competitive distillation performance and gradually improve accuracy as teacher
layers are loaded-matching the final accuracy of the full teacher model without
compromising initial inference speed. This makes PWL particularly suited for
dynamic, resource-constrained deployments where both responsiveness and
performance are critical.

</details>


### [656] [IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning](https://arxiv.org/abs/2509.22621)
*Aayush Mishra,Daniel Khashabi,Anqi Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Supervised Fine-Tuning (SFT) is used to specialize model behavior by training
weights to produce intended target responses for queries. In contrast,
In-Context Learning (ICL) adapts models during inference with instructions or
demonstrations in the prompt. ICL can offer better generalizability and more
calibrated responses compared to SFT in data scarce settings, at the cost of
more inference compute. In this work, we ask the question: Can ICL's internal
computations be used to improve the qualities of SFT? We first show that ICL
and SFT produce distinct activation patterns, indicating that the two methods
achieve adaptation through different functional mechanisms. Motivated by this
observation and to use ICL's rich functionality, we introduce ICL Activation
Alignment (IA2), a self-distillation technique which aims to replicate ICL's
activation patterns in SFT models and incentivizes ICL-like internal reasoning.
Performing IA2 as a priming step before SFT significantly improves the accuracy
and calibration of model outputs, as shown by our extensive empirical results
on 12 popular benchmarks and 2 model families. This finding is not only
practically useful, but also offers a conceptual window into the inner
mechanics of model adaptation.

</details>


### [657] [Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning](https://arxiv.org/abs/2509.22335)
*Naicheng He,Kaicheng Guo,Arjun Prakash,Saket Tiwari,Ruo Yu Tao,Tyrone Serapio,Amy Greenwald,George Konidaris*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We investigate why deep neural networks suffer from \emph{loss of plasticity}
in deep continual learning, failing to learn new tasks without reinitializing
parameters. We show that this failure is preceded by Hessian spectral collapse
at new-task initialization, where meaningful curvature directions vanish and
gradient descent becomes ineffective. To characterize the necessary condition
for successful training, we introduce the notion of $\tau$-trainability and
show that current plasticity preserving algorithms can be unified under this
framework. Targeting spectral collapse directly, we then discuss the Kronecker
factored approximation of the Hessian, which motivates two regularization
enhancements: maintaining high effective feature rank and applying $L2$
penalties. Experiments on continual supervised and reinforcement learning tasks
confirm that combining these two regularizers effectively preserves plasticity.

</details>


### [658] [SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis](https://arxiv.org/abs/2509.22352)
*Marie Brockschmidt,Maresa Schröder,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Survival analysis is a cornerstone of clinical research by modeling
time-to-event outcomes such as metastasis, disease relapse, or patient death.
Unlike standard tabular data, survival data often come with incomplete event
information due to dropout, or loss to follow-up. This poses unique challenges
for synthetic data generation, where it is crucial for clinical research to
faithfully reproduce both the event-time distribution and the censoring
mechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model
specifically designed for generating synthetic data in survival analysis.
SurvDiff is tailored to capture the data-generating mechanism by jointly
generating mixed-type covariates, event times, and right-censoring, guided by a
survival-tailored loss function. The loss encodes the time-to-event structure
and directly optimizes for downstream survival tasks, which ensures that
SurvDiff (i) reproduces realistic event-time distributions and (ii) preserves
the censoring mechanism. Across multiple datasets, we show that \survdiff
consistently outperforms state-of-the-art generative baselines in both
distributional fidelity and downstream evaluation metrics across multiple
medical datasets. To the best of our knowledge, SurvDiff is the first diffusion
model explicitly designed for generating synthetic survival data.

</details>


### [659] [Context and Diversity Matter: The Emergence of In-Context Learning in World Models](https://arxiv.org/abs/2509.22353)
*Fan Wang,Zhiyuan Chen,Yuxuan Zhong,Sunjian Zheng,Pengtao Shao,Bo Yu,Shaoshan Liu,Jianan Wang,Ning Ding,Yang Cao,Yu Kang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The capability of predicting environmental dynamics underpins both biological
neural systems and general embodied AI in adapting to their surroundings. Yet
prevailing approaches rest on static world models that falter when confronted
with novel or rare configurations. We investigate in-context environment
learning (ICEL), shifting attention from zero-shot performance to the growth
and asymptotic limits of the world model. Our contributions are three-fold: (1)
we formalize in-context learning of a world model and identify two core
mechanisms: environment recognition and environment learning; (2) we derive
error upper-bounds for both mechanisms that expose how the mechanisms emerge;
and (3) we empirically confirm that distinct ICL mechanisms exist in the world
model, and we further investigate how data distribution and model architecture
affect ICL in a manner consistent with theory. These findings demonstrate the
potential of self-adapting world models and highlight the key factors behind
the emergence of ICEL, most notably the necessity of long context and diverse
environments.

</details>


### [660] [Stochastic activations](https://arxiv.org/abs/2509.22358)
*Maria Lomeli,Matthijs Douze,Gergely Szilvasy,Loic Cabannes,Jade Copet,Sainbayar Sukhbaatar,Jason Weston,Gabriel Synnaeve,Pierre-Emmanuel Mazaré,Hervé Jégou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce stochastic activations. This novel strategy randomly selects
between several non-linear functions in the feed-forward layer of a large
language model. In particular, we choose between SILU or RELU depending on a
Bernoulli draw. This strategy circumvents the optimization problem associated
with RELU, namely, the constant shape for negative inputs that prevents the
gradient flow. We leverage this strategy in two ways:
  (1) We use stochastic activations during pre-training and fine-tune the model
with RELU, which is used at inference time to provide sparse latent vectors.
This reduces the inference FLOPs and translates into a significant speedup in
the CPU. Interestingly, this leads to much better results than training from
scratch with the RELU activation function.
  (2) We evaluate stochastic activations for generation. This strategy performs
reasonably well: it is only slightly inferior to the best deterministic
non-linearity, namely SILU combined with temperature scaling. This offers an
alternative to existing strategies by providing a controlled way to increase
the diversity of the generated text.

</details>


### [661] [Neural Feature Geometry Evolves as Discrete Ricci Flow](https://arxiv.org/abs/2509.22362)
*Moritz Hehl,Max von Renesse,Melanie Weber*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep neural networks learn feature representations via complex geometric
transformations of the input data manifold. Despite the models' empirical
success across domains, our understanding of neural feature representations is
still incomplete. In this work we investigate neural feature geometry through
the lens of discrete geometry. Since the input data manifold is typically
unobserved, we approximate it using geometric graphs that encode local
similarity structure. We provide theoretical results on the evolution of these
graphs during training, showing that nonlinear activations play a crucial role
in shaping feature geometry in feedforward neural networks. Moreover, we
discover that the geometric transformations resemble a discrete Ricci flow on
these graphs, suggesting that neural feature geometry evolves analogous to
Ricci flow. This connection is supported by experiments on over 20,000
feedforward neural networks trained on binary classification tasks across both
synthetic and real-world datasets. We observe that the emergence of class
separability corresponds to the emergence of community structure in the
associated graph representations, which is known to relate to discrete Ricci
flow dynamics. Building on these insights, we introduce a novel framework for
locally evaluating geometric transformations through comparison with discrete
Ricci flow dynamics. Our results suggest practical design principles, including
a geometry-informed early-stopping heuristic and a criterion for selecting
network depth.

</details>


### [662] [Investigating Faithfulness in Large Audio Language Models](https://arxiv.org/abs/2509.22363)
*Lovenya Jain,Pooneh Mousavi,Mirco Ravanelli,Cem Subakan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Faithfulness measures whether chain-of-thought (CoT) representations
accurately reflect a model's decision process and can be used as reliable
explanations. Prior work has shown that CoTs from text-based LLMs are often
unfaithful. This question has not been explored for large audio-language models
(LALMs), where faithfulness is critical for safety-sensitive applications.
Reasoning in LALMs is also more challenging, as models must first extract
relevant clues from audio before reasoning over them. In this paper, we
investigate the faithfulness of CoTs produced by several LALMs by applying
targeted interventions, including paraphrasing, filler token injection, early
answering, and introducing mistakes, on two challenging reasoning datasets:
SAKURA and MMAR. After going through the aforementioned interventions across
several datasets and tasks, our experiments suggest that, LALMs generally
produce CoTs that appear to be faithful to their underlying decision processes.

</details>


### [663] [Enhancing Credit Risk Prediction: A Meta-Learning Framework Integrating Baseline Models, LASSO, and ECOC for Superior Accuracy](https://arxiv.org/abs/2509.22381)
*Haibo Wang,Lutfu S. Sua,Jun Huang,Figen Balo,Burak Dolar*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Effective credit risk management is fundamental to financial decision-making,
necessitating robust models for default probability prediction and financial
entity classification. Traditional machine learning approaches face significant
challenges when confronted with high-dimensional data, limited
interpretability, rare event detection, and multi-class imbalance problems in
risk assessment. This research proposes a comprehensive meta-learning framework
that synthesizes multiple complementary models: supervised learning algorithms,
including XGBoost, Random Forest, Support Vector Machine, and Decision Tree;
unsupervised methods such as K-Nearest Neighbors; deep learning architectures
like Multilayer Perceptron; alongside LASSO regularization for feature
selection and dimensionality reduction; and Error-Correcting Output Codes as a
meta-classifier for handling imbalanced multi-class problems. We implement
Permutation Feature Importance analysis for each prediction class across all
constituent models to enhance model transparency. Our framework aims to
optimize predictive performance while providing a more holistic approach to
credit risk assessment. This research contributes to the development of more
accurate and reliable computational models for strategic financial decision
support by addressing three fundamental challenges in credit risk modeling. The
empirical validation of our approach involves an analysis of the Corporate
Credit Ratings dataset with credit ratings for 2,029 publicly listed US
companies. Results demonstrate that our meta-learning framework significantly
enhances the accuracy of financial entity classification regarding credit
rating migrations (upgrades and downgrades) and default probability estimation.

</details>


### [664] [(Sometimes) Less is More: Mitigating the Complexity of Rule-based Representation for Interpretable Classification](https://arxiv.org/abs/2509.22384)
*Luca Bergamin,Roberto Confalonieri,Fabio Aiolli*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep neural networks are widely used in practical applications of AI,
however, their inner structure and complexity made them generally not easily
interpretable. Model transparency and interpretability are key requirements for
multiple scenarios where high performance is not enough to adopt the proposed
solution. In this work, a differentiable approximation of $L_0$ regularization
is adapted into a logic-based neural network, the Multi-layer Logical
Perceptron (MLLP), to study its efficacy in reducing the complexity of its
discrete interpretable version, the Concept Rule Set (CRS), while retaining its
performance. The results are compared to alternative heuristics like Random
Binarization of the network weights, to determine if better results can be
achieved when using a less-noisy technique that sparsifies the network based on
the loss function instead of a random distribution. The trade-off between the
CRS complexity and its performance is discussed.

</details>


### [665] [Improving accuracy in short mortality rate series: Exploring Multi-step Forecasting Approaches in Hybrid Systems](https://arxiv.org/abs/2509.22395)
*Filipe C. L. Duarte,Paulo S. G. de Mattos Neto,Paulo R. A. Firmino*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The decline in interest rates and economic stabilization has heightened the
importance of accurate mortality rate forecasting, particularly in insurance
and pension markets. Multi-step-ahead predictions are crucial for public
health, demographic planning, and insurance risk assessments; however, they
face challenges when data are limited. Hybrid systems that combine statistical
and Machine Learning (ML) models offer a promising solution for handling both
linear and nonlinear patterns. This study evaluated the impact of different
multi-step forecasting approaches (Recursive, Direct, and Multi-Input
Multi-Output) and ML models on the accuracy of hybrid systems. Results from 12
datasets and 21 models show that the selection of both the multi-step approach
and the ML model is essential for improving performance, with the ARIMA-LSTM
hybrid using a recursive approach outperforming other models in most cases.

</details>


### [666] [MoveFM-R: Advancing Mobility Foundation Models via Language-driven Semantic Reasoning](https://arxiv.org/abs/2509.22403)
*Fanjin Meng,Yuan Yuan,Jingtao Ding,Jie Feng,Chonghua Han,Yong Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Mobility Foundation Models (MFMs) have advanced the modeling of human
movement patterns, yet they face a ceiling due to limitations in data scale and
semantic understanding. While Large Language Models (LLMs) offer powerful
semantic reasoning, they lack the innate understanding of spatio-temporal
statistics required for generating physically plausible mobility trajectories.
To address these gaps, we propose MoveFM-R, a novel framework that unlocks the
full potential of mobility foundation models by leveraging language-driven
semantic reasoning capabilities. It tackles two key challenges: the vocabulary
mismatch between continuous geographic coordinates and discrete language
tokens, and the representation gap between the latent vectors of MFMs and the
semantic world of LLMs. MoveFM-R is built on three core innovations: a
semantically enhanced location encoding to bridge the geography-language gap, a
progressive curriculum to align the LLM's reasoning with mobility patterns, and
an interactive self-reflection mechanism for conditional trajectory generation.
Extensive experiments demonstrate that MoveFM-R significantly outperforms
existing MFM-based and LLM-based baselines. It also shows robust generalization
in zero-shot settings and excels at generating realistic trajectories from
natural language instructions. By synthesizing the statistical power of MFMs
with the deep semantic understanding of LLMs, MoveFM-R pioneers a new paradigm
that enables a more comprehensive, interpretable, and powerful modeling of
human mobility. The implementation of MoveFM-R is available online at
https://anonymous.4open.science/r/MoveFM-R-CDE7/.

</details>


### [667] [Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators](https://arxiv.org/abs/2509.22411)
*Xiao Xue,Marco F. P. ten Eikelder,Mingyang Gao,Xiaoyuan Cheng,Yiming Yang,Yi He,Shuo Wang,Sibo Cheng,Yukun Hu,Peter V. Coveney*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The lattice Boltzmann equation (LBE), rooted in kinetic theory, provides a
powerful framework for capturing complex flow behaviour by describing the
evolution of single-particle distribution functions (PDFs). Despite its
success, solving the LBE numerically remains computationally intensive due to
strict time-step restrictions imposed by collision kernels. Here, we introduce
a physics-informed neural operator framework for the LBE that enables
prediction over large time horizons without step-by-step integration,
effectively bypassing the need to explicitly solve the collision kernel. We
incorporate intrinsic moment-matching constraints of the LBE, along with global
equivariance of the full distribution field, enabling the model to capture the
complex dynamics of the underlying kinetic system. Our framework is
discretization-invariant, enabling models trained on coarse lattices to
generalise to finer ones (kinetic super-resolution). In addition, it is
agnostic to the specific form of the underlying collision model, which makes it
naturally applicable across different kinetic datasets regardless of the
governing dynamics. Our results demonstrate robustness across complex flow
scenarios, including von Karman vortex shedding, ligament breakup, and bubble
adhesion. This establishes a new data-driven pathway for modelling kinetic
systems.

</details>


### [668] [One Prompt Fits All: Universal Graph Adaptation for Pretrained Models](https://arxiv.org/abs/2509.22416)
*Yongqi Huang,Jitao Zhao,Dongxiao He,Xiaobao Wang,Yawen Li,Yuxiao Huang,Di Jin,Zhiyong Feng*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Graph Prompt Learning (GPL) has emerged as a promising paradigm that bridges
graph pretraining models and downstream scenarios, mitigating label dependency
and the misalignment between upstream pretraining and downstream tasks.
Although existing GPL studies explore various prompt strategies, their
effectiveness and underlying principles remain unclear. We identify two
critical limitations: (1) Lack of consensus on underlying mechanisms: Despite
current GPLs have advanced the field, there is no consensus on how prompts
interact with pretrained models, as different strategies intervene at varying
spaces within the model, i.e., input-level, layer-wise, and
representation-level prompts. (2) Limited scenario adaptability: Most methods
fail to generalize across diverse downstream scenarios, especially under data
distribution shifts (e.g., homophilic-to-heterophilic graphs). To address these
issues, we theoretically analyze existing GPL approaches and reveal that
representation-level prompts essentially function as fine-tuning a simple
downstream classifier, proposing that graph prompt learning should focus on
unleashing the capability of pretrained models, and the classifier adapts to
downstream scenarios. Based on our findings, we propose UniPrompt, a novel GPL
method that adapts any pretrained models, unleashing the capability of
pretrained models while preserving the structure of the input graph. Extensive
experiments demonstrate that our method can effectively integrate with various
pretrained models and achieve strong performance across in-domain and
cross-domain scenarios.

</details>


### [669] [Partial Parameter Updates for Efficient Distributed Training](https://arxiv.org/abs/2509.22418)
*Anastasiia Filippova,Angelos Katharopoulos,David Grangier,Ronan Collobert*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a memory- and compute-efficient method for low-communication
distributed training. Existing methods reduce communication by performing
multiple local updates between infrequent global synchronizations. We
demonstrate that their efficiency can be significantly improved by restricting
backpropagation: instead of updating all the parameters, each node updates only
a fixed subset while keeping the remainder frozen during local steps. This
constraint substantially reduces peak memory usage and training FLOPs, while a
full forward pass over all parameters eliminates the need for cross-node
activation exchange. Experiments on a $1.3$B-parameter language model trained
across $32$ nodes show that our method matches the perplexity of prior
low-communication approaches under identical token and bandwidth budgets while
reducing training FLOPs and peak memory.

</details>


### [670] [The Flood Complex: Large-Scale Persistent Homology on Millions of Points](https://arxiv.org/abs/2509.22432)
*Florian Graf,Paolo Pellizzoni,Martin Uray,Stefan Huber,Roland Kwitt*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the problem of computing persistent homology (PH) for large-scale
Euclidean point cloud data, aimed at downstream machine learning tasks, where
the exponential growth of the most widely-used Vietoris-Rips complex imposes
serious computational limitations. Although more scalable alternatives such as
the Alpha complex or sparse Rips approximations exist, they often still result
in a prohibitively large number of simplices. This poses challenges in the
complex construction and in the subsequent PH computation, prohibiting their
use on large-scale point clouds. To mitigate these issues, we introduce the
Flood complex, inspired by the advantages of the Alpha and Witness complex
constructions. Informally, at a given filtration value $r\geq 0$, the Flood
complex contains all simplices from a Delaunay triangulation of a small subset
of the point cloud $X$ that are fully covered by balls of radius $r$ emanating
from $X$, a process we call flooding. Our construction allows for efficient PH
computation, possesses several desirable theoretical properties, and is
amenable to GPU parallelization. Scaling experiments on 3D point cloud data
show that we can compute PH of up to dimension 2 on several millions of points.
Importantly, when evaluating object classification performance on real-world
and synthetic data, we provide evidence that this scaling capability is needed,
especially if objects are geometrically or topologically complex, yielding
performance superior to other PH-based methods and neural networks for point
cloud data.

</details>


### [671] [Global Convergence in Neural ODEs: Impact of Activation Functions](https://arxiv.org/abs/2509.22436)
*Tianxiang Gao,Siyuan Sun,Hailiang Liu,Hongyang Gao*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Neural Ordinary Differential Equations (ODEs) have been successful in various
applications due to their continuous nature and parameter-sharing efficiency.
However, these unique characteristics also introduce challenges in training,
particularly with respect to gradient computation accuracy and convergence
analysis. In this paper, we address these challenges by investigating the
impact of activation functions. We demonstrate that the properties of
activation functions, specifically smoothness and nonlinearity, are critical to
the training dynamics. Smooth activation functions guarantee globally unique
solutions for both forward and backward ODEs, while sufficient nonlinearity is
essential for maintaining the spectral properties of the Neural Tangent Kernel
(NTK) during training. Together, these properties enable us to establish the
global convergence of Neural ODEs under gradient descent in overparameterized
regimes. Our theoretical findings are validated by numerical experiments, which
not only support our analysis but also provide practical guidelines for scaling
Neural ODEs, potentially leading to faster training and improved performance in
real-world applications.

</details>


### [672] [Overclocking Electrostatic Generative Models](https://arxiv.org/abs/2509.22454)
*Daniil Shlenskii,Alexander Korotin*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Electrostatic generative models such as PFGM++ have recently emerged as a
powerful framework, achieving state-of-the-art performance in image synthesis.
PFGM++ operates in an extended data space with auxiliary dimensionality $D$,
recovering the diffusion model framework as $D\to\infty$, while yielding
superior empirical results for finite $D$. Like diffusion models, PFGM++ relies
on expensive ODE simulations to generate samples, making it computationally
costly. To address this, we propose Inverse Poisson Flow Matching (IPFM), a
novel distillation framework that accelerates electrostatic generative models
across all values of $D$. Our IPFM reformulates distillation as an inverse
problem: learning a generator whose induced electrostatic field matches that of
the teacher. We derive a tractable training objective for this problem and show
that, as $D \to \infty$, our IPFM closely recovers Score Identity Distillation
(SiD), a recent method for distilling diffusion models. Empirically, our IPFM
produces distilled generators that achieve near-teacher or even superior sample
quality using only a few function evaluations. Moreover, we observe that
distillation converges faster for finite $D$ than in the $D \to \infty$
(diffusion) limit, which is consistent with prior findings that finite-$D$
PFGM++ models exhibit more favorable optimization and sampling properties.

</details>


### [673] [Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator](https://arxiv.org/abs/2509.22458)
*Changhun Kim,Timon Conrad,Redwanul Karim,Julian Oelhaf,David Riebesel,Tomás Arias-Vergara,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: PIGNN-Attn-LS通过结合边缘感知注意力机制和回溯线搜索算子，在保持速度优势的同时提高了物理信息图神经网络（PIGNN）在交流潮流计算中的准确性，使其在实际应用中更具潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的PIGNN在速度上优于传统牛顿-拉夫逊（NR）方法，但在准确性方面仍需提高，尤其是在推理阶段物理损失无效的问题限制了其在实际操作中的应用。

Method: 提出PIGNN-Attn-LS，结合了边缘感知注意力机制（通过每条边的偏置显式编码线路物理信息，捕捉电网的各向异性）和基于回溯线搜索的全局化校正算子（在推理时恢复有效的递减准则）。

Result: 在包含4-32节点的高/中压电网测试案例中，PIGNN-Attn-LS实现了0.00033 p.u.的电压和0.08度的角度的测试均方根误差（RMSE），分别比PIGNN-MLP基线提高了99.5%和87.1%。在4-1024节点电网的流式微批处理中，其批处理推理速度是NR的2-5倍。

Conclusion: PIGNN-Attn-LS在保持高推理速度的同时，显著提高了PIGNN在交流潮流计算中的准确性，克服了现有方法的局限性，有望在实际电网运行中得到应用。

Abstract: Physics-informed graph neural networks (PIGNNs) have emerged as fast AC
power-flow solvers that can replace classic Newton--Raphson (NR) solvers,
especially when thousands of scenarios must be evaluated. However, current
PIGNNs still need accuracy improvements at parity speed; in particular, the
physics loss is inoperative at inference, which can deter operational adoption.
We address this with PIGNN-Attn-LS, combining an edge-aware attention mechanism
that explicitly encodes line physics via per-edge biases, capturing the grid's
anisotropy, with a backtracking line-search-based globalized correction
operator that restores an operative decrease criterion at inference. Training
and testing use a realistic High-/Medium-Voltage scenario generator, with NR
used only to construct reference states. On held-out HV cases consisting of
4--32-bus grids, PIGNN-Attn-LS achieves a test RMSE of 0.00033 p.u. in voltage
and 0.08$^\circ$ in angle, outperforming the PIGNN-MLP baseline by 99.5\% and
87.1\%, respectively. With streaming micro-batches, it delivers 2--5$\times$
faster batched inference than NR on 4--1024-bus grids.

</details>


### [674] [Nonlinear Optimization with GPU-Accelerated Neural Network Constraints](https://arxiv.org/abs/2509.22462)
*Robert Parker,Oscar Dowson,Nicole LoGiudice,Manuel Garcia,Russell Bent*

Main category: cs.LG

TL;DR: 我们提出了一种在训练好的神经网络上进行优化的降维空间方法，并在 GPU 上评估网络的输出和导数。该方法将神经网络视为“黑箱”，不向优化求解器暴露中间变量和约束。与完整空间方法相比，降维空间方法能更快地求解并减少迭代次数。我们在两个优化问题上展示了该方法的优势：MNIST 分类器的对抗生成以及使用神经网络代理强制执行瞬态可行性的安全约束最优潮流问题。


<details>
  <summary>Details</summary>
Motivation: 在训练好的神经网络上进行优化，并在 GPU 上评估网络的输出和导数。

Method: 将神经网络视为“黑箱”，不向优化求解器暴露中间变量和约束，使用降维空间方法进行优化，并在 GPU 上进行评估。

Result: 与完整空间方法相比，降维空间方法能更快地求解并减少迭代次数。在 MNIST 分类器的对抗生成以及安全约束最优潮流问题上展示了该方法的优势。

Conclusion: 我们提出的降维空间方法在优化问题上比完整空间方法更有效。

Abstract: We propose a reduced-space formulation for optimizing over trained neural
networks where the network's outputs and derivatives are evaluated on a GPU. To
do this, we treat the neural network as a "gray box" where intermediate
variables and constraints are not exposed to the optimization solver. Compared
to the full-space formulation, in which intermediate variables and constraints
are exposed to the optimization solver, the reduced-space formulation leads to
faster solves and fewer iterations in an interior point method. We demonstrate
the benefits of this method on two optimization problems: Adversarial
generation for a classifier trained on MNIST images and security-constrained
optimal power flow with transient feasibility enforced using a neural network
surrogate.

</details>


### [675] [Learning the Neighborhood: Contrast-Free Multimodal Self-Supervised Molecular Graph Pretraining](https://arxiv.org/abs/2509.22468)
*Boshra Ariguib,Mathias Niepert,Andrei Manolache*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: High-quality molecular representations are essential for property prediction
and molecular design, yet large labeled datasets remain scarce. While
self-supervised pretraining on molecular graphs has shown promise, many
existing approaches either depend on hand-crafted augmentations or complex
generative objectives, and often rely solely on 2D topology, leaving valuable
3D structural information underutilized. To address this gap, we introduce
C-FREE (Contrast-Free Representation learning on Ego-nets), a simple framework
that integrates 2D graphs with ensembles of 3D conformers. C-FREE learns
molecular representations by predicting subgraph embeddings from their
complementary neighborhoods in the latent space, using fixed-radius ego-nets as
modeling units across different conformers. This design allows us to integrate
both geometric and topological information within a hybrid Graph Neural Network
(GNN)-Transformer backbone, without negatives, positional encodings, or
expensive pre-processing. Pretraining on the GEOM dataset, which provides rich
3D conformational diversity, C-FREE achieves state-of-the-art results on
MoleculeNet, surpassing contrastive, generative, and other multimodal
self-supervised methods. Fine-tuning across datasets with diverse sizes and
molecule types further demonstrates that pretraining transfers effectively to
new chemical domains, highlighting the importance of 3D-informed molecular
representations.

</details>


### [676] [Bayesian Transfer Operators in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2509.22482)
*Septimus Boshoff,Sebastian Peitz,Stefan Klus*

Main category: cs.LG

TL;DR: 我们将高斯过程回归与动态模式分解相结合，以解决基于核的Koopman算法中的稀疏性和超参数优化问题。


<details>
  <summary>Details</summary>
Motivation: Koopman算子作为非线性动力学系统的线性表示，在科学领域受到关注。然而，现有的基于核的Koopman算法存在稀疏性和超参数优化等问题。

Method: 通过将高斯过程回归与动态模式分解相结合，来解决现有Koopman算法中的稀疏性和超参数优化问题。

Result: 该方法不仅降低了计算需求，而且提高了对传感器噪声的抵抗能力。

Conclusion: 该工作的主要贡献是统一了高斯过程回归和动态模式分解，为解决Koopman算子理论在实际应用中的挑战提供了新的途径。

Abstract: The Koopman operator, as a linear representation of a nonlinear dynamical
system, has been attracting attention in many fields of science. Recently,
Koopman operator theory has been combined with another concept that is popular
in data science: reproducing kernel Hilbert spaces. We follow this thread into
Gaussian process methods, and illustrate how these methods can alleviate two
pervasive problems with kernel-based Koopman algorithms. The first being
sparsity: most kernel methods do not scale well and require an approximation to
become practical. We show that not only can the computational demands be
reduced, but also demonstrate improved resilience against sensor noise. The
second problem involves hyperparameter optimization and dictionary learning to
adapt the model to the dynamical system. In summary, the main contribution of
this work is the unification of Gaussian process regression and dynamic mode
decomposition.

</details>


### [677] [OFMU: Optimization-Driven Framework for Machine Unlearning](https://arxiv.org/abs/2509.22483)
*Sadia Asif,Mohammad Mohammadi Amiri*

Main category: cs.LG

TL;DR: 大型语言模型需要能够“遗忘”特定知识，但现有方法在遗忘和保留性能之间存在冲突。本文提出OFMU，一种基于惩罚的双层优化框架，通过内层最大化和外层最小化实现有效遗忘和性能保留，并提供可扩展的双循环算法和理论分析，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在敏感应用中需要遗忘特定知识（如用户请求、版权材料或过时信息），但现有方法在遗忘和保留性能之间存在冲突，导致训练不稳定和模型效用下降。

Method: 提出OFMU，一个基于惩罚的双层优化框架。通过内层最大化（包含相似度感知惩罚）强制遗忘，通过外层最小化恢复效用。开发了一个双循环算法，具有可证明的收敛保证。

Result: OFMU在遗忘效果和模型效用之间取得了比先前方法更好的权衡。在视觉和语言基准上的大量实验表明，OFMU在遗忘效果和保留效用方面始终优于现有的遗忘方法。

Conclusion: OFMU是一个有效的机器学习遗忘框架，通过双层优化和相似度感知惩罚解决了现有方法的局限性，并在实际应用中表现出色。

Abstract: Large language models deployed in sensitive applications increasingly require
the ability to unlearn specific knowledge, such as user requests, copyrighted
materials, or outdated information, without retraining from scratch to ensure
regulatory compliance, user privacy, and safety. This task, known as machine
unlearning, aims to remove the influence of targeted data (forgetting) while
maintaining performance on the remaining data (retention). A common approach is
to formulate this as a multi-objective problem and reduce it to a
single-objective problem via scalarization, where forgetting and retention
losses are combined using a weighted sum. However, this often results in
unstable training dynamics and degraded model utility due to conflicting
gradient directions. To address these challenges, we propose OFMU, a
penalty-based bi-level optimization framework that explicitly prioritizes
forgetting while preserving retention through a hierarchical structure. Our
method enforces forgetting via an inner maximization step that incorporates a
similarity-aware penalty to decorrelate the gradients of the forget and
retention objectives, and restores utility through an outer minimization step.
To ensure scalability, we develop a two-loop algorithm with provable
convergence guarantees under both convex and non-convex regimes. We further
provide a rigorous theoretical analysis of convergence rates and show that our
approach achieves better trade-offs between forgetting efficacy and model
utility compared to prior methods. Extensive experiments across vision and
language benchmarks demonstrate that OFMU consistently outperforms existing
unlearning methods in both forgetting efficacy and retained utility.

</details>


### [678] [A Machine Learning Pipeline for Multiple Sclerosis Biomarker Discovery: Comparing explainable AI and Traditional Statistical Approaches](https://arxiv.org/abs/2509.22484)
*Samuele Punzo,Silvia Giulia Galfrè,Francesco Massafra,Alessandro Maglione,Corrado Priami,Alina Sîrbu*

Main category: cs.LG

TL;DR: 我们提出了一个用于多发性硬化症（MS）生物标志物发现的机器学习流程，整合了来自外周血单个核细胞（PBMC）的八个公开的微阵列数据集。经过严格的预处理，我们训练了一个通过贝叶斯搜索优化的XGBoost分类器。利用SHapley Additive exPlanations（SHAP）来识别模型预测的关键特征，从而找到可能的生物标志物。将这些结果与通过经典差异表达分析（DEA）识别的基因进行比较。我们的比较显示SHAP和DEA之间存在重叠和独特的生物标志物，表明它们具有互补的优势。富集分析证实了SHAP选择的基因的生物学相关性，将其与已知的与MS相关的通路（如鞘脂信号传导、Th1/Th2/Th17细胞分化和EB病毒感染）联系起来。本研究强调了结合可解释人工智能（xAI）和传统统计方法在深入了解疾病机制方面的价值。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一种机器学习流程，以发现多发性硬化症（MS）的生物标志物，并通过整合多个公开数据集来提高模型的鲁棒性。

Method: 本研究整合了八个公开的PBMC微阵列数据集，并进行了预处理。然后，使用贝叶斯搜索优化XGBoost分类器，并利用SHAP来识别预测的关键特征（潜在生物标志物）。这些特征随后与通过DEA识别的基因进行比较，并进行了富集分析以评估其生物学相关性。

Result: SHAP和DEA方法识别了重叠和独特的生物标志物。SHAP选择的基因与MS相关的通路（如鞘脂信号传导、Th1/Th2/Th17细胞分化和EB病毒感染）相关。

Conclusion: 结合可解释人工智能（xAI）和传统统计方法（如DEA）可以更深入地了解MS的疾病机制，并发现新的生物标志物。

Abstract: We present a machine learning pipeline for biomarker discovery in Multiple
Sclerosis (MS), integrating eight publicly available microarray datasets from
Peripheral Blood Mononuclear Cells (PBMC). After robust preprocessing we
trained an XGBoost classifier optimized via Bayesian search. SHapley Additive
exPlanations (SHAP) were used to identify key features for model prediction,
indicating thus possible biomarkers. These were compared with genes identified
through classical Differential Expression Analysis (DEA). Our comparison
revealed both overlapping and unique biomarkers between SHAP and DEA,
suggesting complementary strengths. Enrichment analysis confirmed the
biological relevance of SHAP-selected genes, linking them to pathways such as
sphingolipid signaling, Th1/Th2/Th17 cell differentiation, and Epstein-Barr
virus infection all known to be associated with MS. This study highlights the
value of combining explainable AI (xAI) with traditional statistical methods to
gain deeper insights into disease mechanism.

</details>


### [679] [Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise](https://arxiv.org/abs/2509.22500)
*Juan Ramirez,Simon Lacoste-Julien*

Main category: cs.LG

TL;DR: 文章揭示了对偶乐观上升法与增广拉格朗日法之间的等价性，为对偶乐观法提供了理论保证，并指导了超参数调整。


<details>
  <summary>Details</summary>
Motivation: 现有的基于一阶方法的约束深度学习方法在求解min-max拉格朗日形式时存在震荡且可能找不到所有局部解的问题。虽然增广拉格朗日法（ALM）解决了这些问题，但实践者倾向于使用在标准拉格朗日上的对偶乐观上升法（PI控制），该方法虽然经验上表现良好但缺乏理论保证。

Method: 证明了对偶乐观上升法在标准拉格朗日上的应用等价于在增广拉格朗日上的梯度下降-上升法。

Result: 将ALM的稳健理论保证迁移到对偶乐观设定，证明了其能线性收敛到所有局部解。该等价性还为调整乐观超参数提供了原则性指导。

Conclusion: 弥合了对偶乐观方法的经验成功与其理论基础之间的关键差距。

Abstract: Constrained optimization is a powerful framework for enforcing requirements
on neural networks. These constrained deep learning problems are typically
solved using first-order methods on their min-max Lagrangian formulation, but
such approaches often suffer from oscillations and can fail to find all local
solutions. While the Augmented Lagrangian method (ALM) addresses these issues,
practitioners often favor dual optimistic ascent schemes (PI control) on the
standard Lagrangian, which perform well empirically but lack formal guarantees.
In this paper, we establish a previously unknown equivalence between these
approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient
descent-ascent on the Augmented Lagrangian. This finding allows us to transfer
the robust theoretical guarantees of the ALM to the dual optimistic setting,
proving it converges linearly to all local solutions. Furthermore, the
equivalence provides principled guidance for tuning the optimism
hyper-parameter. Our work closes a critical gap between the empirical success
of dual optimistic methods and their theoretical foundation.

</details>


### [680] [Adaptive Dual-Mode Distillation with Incentive Schemes for Scalable, Heterogeneous Federated Learning on Non-IID Data](https://arxiv.org/abs/2509.22507)
*Zahid Iqbal*

Main category: cs.LG

TL;DR: 联邦学习（FL）在分布式数据使用方面很有前景，但面临模型同质性、统计异质性（非IID数据）和激励机制缺乏等挑战。本文提出了DL-SH、DL-MH和I-DL-MH三种方法来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法未能充分考虑客户端在业务需求、计算资源、模型需求以及数据分布上的异质性，并且缺乏有效的激励机制来鼓励客户端参与训练，导致模型性能下降和参与度不足。

Method: 本文提出了三种方法：DL-SH（解决统计异质性）、DL-MH（解决模型和统计异质性）以及I-DL-MH（在DL-MH基础上增加激励机制）。这些方法通过特定的算法设计来处理异质性问题，并通过经济激励促进客户端参与。

Result: 实验结果表明，所提出的方法在准确性和通信成本方面显著优于现有方法。在非IID条件下，DL-SH将全局模型准确率提高了153%，I-DL-MH更是达到了225%的提升，同时有效解决了统计和模型异质性问题。

Conclusion: 本文提出的DL-SH、DL-MH和I-DL-MH方法能够有效地解决联邦学习中的模型异质性、统计异质性和激励机制问题，显著提升模型性能和客户端参与度，为构建更强大、更具吸引力的联邦学习系统提供了解决方案。

Abstract: Federated Learning (FL) has emerged as a promising decentralized learning
(DL) approach that enables the use of distributed data without compromising
user privacy. However, FL poses several key challenges. First, it is frequently
assumed that every client can train the same machine learning models, however,
not all clients are able to meet this assumption because of differences in
their business needs and computational resources. Second, statistical
heterogeneity (a.k.a. non-IID data) poses a major challenge in FL, which can
lead to lower global model performance. Third, while addressing these
challenges, there is a need for a cost-effective incentive mechanism to
encourage clients to participate in FL training. In response to these
challenges, we propose several methodologies: DL-SH, which facilitates
efficient, privacy-preserving, and communication-efficient learning in the
context of statistical heterogeneity; DL-MH, designed to manage fully
heterogeneous models while tackling statistical disparities; and I-DL-MH, an
incentive-based extension of DL-MH that promotes client engagement in federated
learning training by providing incentives within this complex federated
learning framework. Comprehensive experiments were carried out to assess the
performance and scalability of the proposed approaches across a range of
complex experimental settings. This involved utilizing various model
architectures, in diverse data distributions, including IID and several non-IID
scenarios, as well as multiple datasets. Experimental results demonstrate that
the proposed approaches significantly enhance accuracy and decrease
communication costs while effectively addressing statistical heterogeneity and
model heterogeneity in comparison to existing state-of-the-art approaches and
baselines, with DL-SH improving global model accuracy by 153%, and I-DL-MH
achieving a 225% improvement under non-IID conditions.

</details>


### [681] [JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation](https://arxiv.org/abs/2509.22522)
*Guillem Capellera,Luis Ferraz,Antonio Rubio,Alexandre Alahi,Antonio Agudo*

Main category: cs.LG

TL;DR: JointDiff框架统一了连续数据和离散事件的生成过程，实现了运动领域中多智能体轨迹和关键事件的同步建模，并在可控生成方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型将连续数据和离散事件视为独立过程，无法有效模拟复杂交互系统。本研究旨在弥合这一差距，实现连续数据和离散事件的同步生成。

Method: 提出了一种名为JointDiff的新型扩散框架，能够同时生成连续的时空数据和离散的同步事件。该框架引入了CrossGuid操作，以支持弱持有者引导和文本引导等可控生成场景。同时，构建了一个包含文本描述的体育数据集基准。

Result: JointDiff在运动领域成功地同步建模了多智能体轨迹和关键球权事件。在非可控生成和两种新型可控生成（弱持有者引导和文本引导）场景中均表现出色，并在新的统一体育基准测试中达到了最先进的性能。

Conclusion: 联合建模对于构建现实且可控的交互式系统生成模型至关重要。JointDiff的成功表明，通过统一建模连续数据和离散事件，可以显著提升生成模型的性能和可控性。

Abstract: Generative models often treat continuous data and discrete events as separate
processes, creating a gap in modeling complex systems where they interact
synchronously. To bridge this gap, we introduce JointDiff, a novel diffusion
framework designed to unify these two processes by simultaneously generating
continuous spatio-temporal data and synchronous discrete events. We demonstrate
its efficacy in the sports domain by simultaneously modeling multi-agent
trajectories and key possession events. This joint modeling is validated with
non-controllable generation and two novel controllable generation scenarios:
weak-possessor-guidance, which offers flexible semantic control over game
dynamics through a simple list of intended ball possessors, and text-guidance,
which enables fine-grained, language-driven generation. To enable the
conditioning with these guidance signals, we introduce CrossGuid, an effective
conditioning operation for multi-agent domains. We also share a new unified
sports benchmark enhanced with textual descriptions for soccer and football
datasets. JointDiff achieves state-of-the-art performance, demonstrating that
joint modeling is crucial for building realistic and controllable generative
models for interactive systems.

</details>


### [682] [Learning to Price Bundles: A GCN Approach for Mixed Bundling](https://arxiv.org/abs/2509.22557)
*Liangyu Ding,Chenghan Wu,Guokai Li,Zizhuo Wang*

Main category: cs.LG

TL;DR: 本文提出使用图卷积网络（GCN）解决捆绑定价问题，通过学习最优捆绑的潜在模式，并结合局部搜索技术，在保证解的质量的同时显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 捆绑定价问题旨在设计产品组合（捆绑）及其价格以最大化预期利润，是收益管理中的经典问题，但由于候选捆绑数量呈指数级增长而通常难以解决。

Method: 提出了一种图表示方法来描述混合捆绑模型，并训练GCN学习最优捆绑的潜在模式。在此基础上，设计了两种推断策略来获得高质量的可行解，并采用局部搜索技术进一步优化。

Result: 数值实验表明，在包含5个产品的数据集上训练的GCN模型，在解决中小型问题时，能够以仅为传统方法一小部分的时间获得接近最优（超过97%）的解。该方法在大型问题上优于捆绑大小定价（BSP）等启发式方法，并能为具有非加性效用等挑战性情况下的30多个产品实例提供高质量解。

Conclusion: 本文提出的基于GCN的捆绑定价框架在解决捆绑定价问题方面展现了优越的有效性和效率，能够处理大规模和复杂情况下的问题。

Abstract: Bundle pricing refers to designing several product combinations (i.e.,
bundles) and determining their prices in order to maximize the expected profit.
It is a classic problem in revenue management and arises in many industries,
such as e-commerce, tourism, and video games. However, the problem is typically
intractable due to the exponential number of candidate bundles. In this paper,
we explore the usage of graph convolutional networks (GCNs) in solving the
bundle pricing problem. Specifically, we first develop a graph representation
of the mixed bundling model (where every possible bundle is assigned with a
specific price) and then train a GCN to learn the latent patterns of optimal
bundles. Based on the trained GCN, we propose two inference strategies to
derive high-quality feasible solutions. A local-search technique is further
proposed to improve the solution quality. Numerical experiments validate the
effectiveness and efficiency of our proposed GCN-based framework. Using a GCN
trained on instances with 5 products, our methods consistently achieve
near-optimal solutions (better than 97%) with only a fraction of computational
time for problems of small to medium size. It also achieves superior solutions
for larger size of problems compared with other heuristic methods such as
bundle size pricing (BSP). The method can also provide high quality solutions
for instances with more than 30 products even for the challenging cases where
product utilities are non-additive.

</details>


### [683] [Activation Function Design Sustains Plasticity in Continual Learning](https://arxiv.org/abs/2509.22562)
*Lute Lillo,Nick Cheney*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In independent, identically distributed (i.i.d.) training regimes, activation
functions have been benchmarked extensively, and their differences often shrink
once model size and optimization are tuned. In continual learning, however, the
picture is different: beyond catastrophic forgetting, models can progressively
lose the ability to adapt (referred to as loss of plasticity) and the role of
the non-linearity in this failure mode remains underexplored. We show that
activation choice is a primary, architecture-agnostic lever for mitigating
plasticity loss. Building on a property-level analysis of negative-branch shape
and saturation behavior, we introduce two drop-in nonlinearities (Smooth-Leaky
and Randomized Smooth-Leaky) and evaluate them in two complementary settings:
(i) supervised class-incremental benchmarks and (ii) reinforcement learning
with non-stationary MuJoCo environments designed to induce controlled
distribution and dynamics shifts. We also provide a simple stress protocol and
diagnostics that link the shape of the activation to the adaptation under
change. The takeaway is straightforward: thoughtful activation design offers a
lightweight, domain-general way to sustain plasticity in continual learning
without extra capacity or task-specific tuning.

</details>


### [684] [From Parameters to Behavior: Unsupervised Compression of the Policy Space](https://arxiv.org/abs/2509.22566)
*Davide Tenedini,Riccardo Zamboni,Mirco Mutti,Marcello Restelli*

Main category: cs.LG

TL;DR: DRL在参数空间$	heta$中进行优化导致样本效率低下，尤其是在多任务场景下。本文提出一种无监督方法，将策略参数空间压缩到低维潜在空间$oldsymbol{z}$，并使用行为重构损失训练生成模型$g:oldsymbol{z}	o	heta$，使潜在空间按功能相似性组织。该方法可将参数化压缩高达五个数量级，同时保留大部分表现力，并使策略梯度在潜在空间中操作以适应特定任务。


<details>
  <summary>Details</summary>
Motivation: DRL的样本效率低下，尤其是在多任务场景下，这是由于在维数高且冗余的参数空间$	heta$中直接优化策略造成的。

Method: 提出一种无监督方法，将策略参数空间$	heta$压缩到低维潜在空间$oldsymbol{z}$。通过优化行为重构损失来训练生成模型$g:oldsymbol{z}	o	heta$，以确保潜在空间按功能相似性而非参数化邻近性进行组织。

Result: 在连续控制域中，标准策略网络的参数化可以压缩高达五个数量级，同时保留大部分表现力。此外，学习到的流形使得通过在潜在空间$oldsymbol{z}$中进行策略梯度操作来实现特定任务的适应成为可能。

Conclusion: 通过将策略参数空间压缩到低维潜在空间，可以显著提高DRL的样本效率，并实现更有效的多任务处理和特定任务适应。

Abstract: Despite its recent successes, Deep Reinforcement Learning (DRL) is
notoriously sample-inefficient. We argue that this inefficiency stems from the
standard practice of optimizing policies directly in the high-dimensional and
highly redundant parameter space $\Theta$. This challenge is greatly compounded
in multi-task settings. In this work, we develop a novel, unsupervised approach
that compresses the policy parameter space $\Theta$ into a low-dimensional
latent space $\mathcal{Z}$. We train a generative model
$g:\mathcal{Z}\to\Theta$ by optimizing a behavioral reconstruction loss, which
ensures that the latent space is organized by functional similarity rather than
proximity in parameterization. We conjecture that the inherent dimensionality
of this manifold is a function of the environment's complexity, rather than the
size of the policy network. We validate our approach in continuous control
domains, showing that the parameterization of standard policy networks can be
compressed up to five orders of magnitude while retaining most of its
expressivity. As a byproduct, we show that the learned manifold enables
task-specific adaptation via Policy Gradient operating in the latent space
$\mathcal{Z}$.

</details>


### [685] [Machine learning approaches to seismic event classification in the Ostrava region](https://arxiv.org/abs/2509.22574)
*Marek Pecha,Michael Skotnica,Jana Rušajová,Bohdan Rieznikov,Vít Wandrol,Markéta Rösnerová,Jaromír Knejzlík*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The northeastern region of the Czech Republic is among the most seismically
active areas in the country. The most frequent seismic events are
mining-induced since there used to be strong mining activity in the past.
However, natural tectonic events may also occur. In addition, seismic stations
often record explosions in quarries in the region. Despite the cessation of
mining activities, mine-induced seismic events still occur. Therefore, a rapid
differentiation between tectonic and anthropogenic events is still important.
  The region is currently monitored by the OKC seismic station in
Ostrava-Kr\'{a}sn\'{e} Pole built in 1983 which is a part of the Czech Regional
Seismic Network. The station has been providing digital continuous waveform
data at 100 Hz since 2007. In the years 1992--2002, the region was co-monitored
by the Seismic Polygon Fren\v{s}t\'{a}t (SPF) which consisted of five seismic
stations using a triggered STA/LTA system.
  In this study, we apply and compare machine learning methods to the SPF
dataset, which contains labeled records of tectonic and mining-induced events.
For binary classification, a Long Short-Term Memory recurrent neural network
and XGBoost achieved an F1-score of 0.94 -- 0.95, demonstrating the potential
of modern machine learning techniques for rapid event characterization.

</details>


### [686] [The Lie of the Average: How Class Incremental Learning Evaluation Deceives You?](https://arxiv.org/abs/2509.22580)
*Guannan Lai,Da-Wei Zhou,Xin Yang,Han-Jia Ye*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Class Incremental Learning (CIL) requires models to continuously learn new
classes without forgetting previously learned ones, while maintaining stable
performance across all possible class sequences. In real-world settings, the
order in which classes arrive is diverse and unpredictable, and model
performance can vary substantially across different sequences. Yet mainstream
evaluation protocols calculate mean and variance from only a small set of
randomly sampled sequences. Our theoretical analysis and empirical results
demonstrate that this sampling strategy fails to capture the full performance
range, resulting in biased mean estimates and a severe underestimation of the
true variance in the performance distribution. We therefore contend that a
robust CIL evaluation protocol should accurately characterize and estimate the
entire performance distribution. To this end, we introduce the concept of
extreme sequences and provide theoretical justification for their crucial role
in the reliable evaluation of CIL. Moreover, we observe a consistent positive
correlation between inter-task similarity and model performance, a relation
that can be leveraged to guide the search for extreme sequences. Building on
these insights, we propose EDGE (Extreme case-based Distribution and
Generalization Evaluation), an evaluation protocol that adaptively identifies
and samples extreme class sequences using inter-task similarity, offering a
closer approximation of the ground-truth performance distribution. Extensive
experiments demonstrate that EDGE effectively captures performance extremes and
yields more accurate estimates of distributional boundaries, providing
actionable insights for model selection and robustness checking. Our code is
available at https://github.com/AIGNLAI/EDGE.

</details>


### [687] [Transport Based Mean Flows for Generative Modeling](https://arxiv.org/abs/2509.22592)
*Elaheh Akbari,Ping He,Ahmadreza Moradipari,Yikun Bai,Soheil Kolouri*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Flow-matching generative models have emerged as a powerful paradigm for
continuous data generation, achieving state-of-the-art results across domains
such as images, 3D shapes, and point clouds. Despite their success, these
models suffer from slow inference due to the requirement of numerous sequential
sampling steps. Recent work has sought to accelerate inference by reducing the
number of sampling steps. In particular, Mean Flows offer a one-step generation
approach that delivers substantial speedups while retaining strong generative
performance. Yet, in many continuous domains, Mean Flows fail to faithfully
approximate the behavior of the original multi-step flow-matching process. In
this work, we address this limitation by incorporating optimal transport-based
sampling strategies into the Mean Flow framework, enabling one-step generators
that better preserve the fidelity and diversity of the original multi-step flow
process. Experiments on controlled low-dimensional settings and on
high-dimensional tasks such as image generation, image-to-image translation,
and point cloud generation demonstrate that our approach achieves superior
inference accuracy in one-step generative modeling.

</details>


### [688] [Quantile Advantage Estimation for Entropy-Safe Reasoning](https://arxiv.org/abs/2509.22611)
*Junkang Wu,Kexin Huang,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) strengthens LLM
reasoning, but training often oscillates between {entropy collapse} and
{entropy explosion}. We trace both hazards to the mean baseline used in
value-free RL (e.g., GRPO and DAPO), which improperly penalizes
negative-advantage samples under reward outliers. We propose {Quantile
Advantage Estimation} (QAE), replacing the mean with a group-wise K-quantile
baseline. QAE induces a response-level, two-regime gate: on hard queries (p <=
1 - K) it reinforces rare successes, while on easy queries (p > 1 - K) it
targets remaining failures. Under first-order softmax updates, we prove
{two-sided entropy safety}, giving lower and upper bounds on one-step entropy
change that curb explosion and prevent collapse. Empirically, this minimal
modification stabilizes entropy, sparsifies credit assignment (with tuned K,
roughly 80% of responses receive zero advantage), and yields sustained pass@1
gains on Qwen3-8B/14B-Base across AIME 2024/2025 and AMC 2023. These results
identify {baseline design} -- rather than token-level heuristics -- as the
primary mechanism for scaling RLVR.

</details>


### [689] [A Theoretical Analysis of Discrete Flow Matching Generative Models](https://arxiv.org/abs/2509.22623)
*Maojiang Su,Mingcheng Lu,Jerry Yao-Chieh Hu,Shang Wu,Zhao Song,Alex Reneau,Han Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We provide a theoretical analysis for end-to-end training Discrete Flow
Matching (DFM) generative models. DFM is a promising discrete generative
modeling framework that learns the underlying generative dynamics by training a
neural network to approximate the transformative velocity field. Our analysis
establishes a clear chain of guarantees by decomposing the final distribution
estimation error. We first prove that the total variation distance between the
generated and target distributions is controlled by the risk of the learned
velocity field. We then bound this risk by analyzing its two primary sources:
(i) Approximation Error, where we quantify the capacity of the Transformer
architecture to represent the true velocity, and (ii) Estimation Error, where
we derive statistical convergence rates that bound the error from training on a
finite dataset. By composing these results, we provide the first formal proof
that the distribution generated by a trained DFM model provably converges to
the true data distribution as the training set size increases.

</details>


### [690] [Learning Admissible Heuristics for A*: Theory and Practice](https://arxiv.org/abs/2509.22626)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Heuristic functions are central to the performance of search algorithms such
as A-star, where admissibility - the property of never overestimating the true
shortest-path cost - guarantees solution optimality. Recent deep learning
approaches often disregard admissibility and provide limited guarantees on
generalization beyond the training data. This paper addresses both of these
limitations. First, we pose heuristic learning as a constrained optimization
problem and introduce Cross-Entropy Admissibility (CEA), a loss function that
enforces admissibility during training. On the Rubik's Cube domain, this method
yields near-admissible heuristics with significantly stronger guidance than
compressed pattern database (PDB) heuristics. Theoretically, we study the
sample complexity of learning heuristics. By leveraging PDB abstractions and
the structural properties of graphs such as the Rubik's Cube, we tighten the
bound on the number of training samples needed for A-star to generalize.
Replacing a general hypothesis class with a ReLU neural network gives bounds
that depend primarily on the network's width and depth, rather than on graph
size. Using the same network, we also provide the first generalization
guarantees for goal-dependent heuristics.

</details>
