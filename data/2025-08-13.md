<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 72]
- [cs.CL](#cs.CL) [Total: 62]
- [cs.SI](#cs.SI) [Total: 3]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.AR](#cs.AR) [Total: 4]
- [quant-ph](#quant-ph) [Total: 34]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.LG](#cs.LG) [Total: 29]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.DC](#cs.DC) [Total: 4]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [eess.SY](#eess.SY) [Total: 7]
- [cs.GT](#cs.GT) [Total: 4]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 11]
- [cs.GR](#cs.GR) [Total: 11]
- [cs.ET](#cs.ET) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 18]
- [cs.AI](#cs.AI) [Total: 41]
- [eess.SP](#eess.SP) [Total: 19]
- [cs.RO](#cs.RO) [Total: 25]
- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection](https://arxiv.org/abs/2508.08317)
*Saptarshi Banerjee,Tausif Mallick,Amlan Chakroborty,Himadri Nath Saha,Nityananda T. Takur*

Main category: cs.CV

TL;DR: 本研究对计算机视觉在植物病虫害检测中的应用进行了综述，重点介绍了 AI 和深度学习方法的最新进展，特别是 Transformer 模型，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决植物病和虫害对于提高作物产量和防止经济损失至关重要。人工智能 (AI)、机器学习 (ML) 和深度学习 (DL) 的最新进展已显著提高了检测方法的精度和效率，克服了手动识别的局限性。

Method: 本研究将检测方法分为五类：高光谱成像、非可视化技术、可视化方法、修改后的深度学习架构和 Transformer 模型。

Result: AI 方法在速度和准确性方面持续优于旧的图像分析方法。像分层视觉 Transformer (HvT) 这样的视觉 Transformer 在植物病检测方面的准确率超过了 99.3%，优于 MobileNetV3 等架构。

Conclusion: 本研究总结了现代基于计算机的技术，用于从图像中检测植物病和害虫，包括最近的 AI 发展。本研究通过将方法分为五类来提供对其进行分类的详细见解：高光谱成像、非可视化技术、可视化方法、修改后的深度学习架构和 Transformer 模型。最新的 AI 方法，特别是像分层视觉 Transformer (HvT) 这样的视觉 Transformer，在植物病检测方面的准确率超过了 99.3%，优于 MobileNetV3 等架构。研究最后讨论了系统设计挑战，提出了解决方案，并概述了未来研究的有希望的方向。

Abstract: Addressing plant diseases and pests is critical for enhancing crop production
and preventing economic losses. Recent advances in artificial intelligence
(AI), machine learning (ML), and deep learning (DL) have significantly improved
the precision and efficiency of detection methods, surpassing the limitations
of manual identification. This study reviews modern computer-based techniques
for detecting plant diseases and pests from images, including recent AI
developments. The methodologies are organized into five categories:
hyperspectral imaging, non-visualization techniques, visualization approaches,
modified deep learning architectures, and transformer models. This structured
taxonomy provides researchers with detailed, actionable insights for selecting
advanced state-of-the-art detection methods. A comprehensive survey of recent
work and comparative studies demonstrates the consistent superiority of modern
AI-based approaches, which often outperform older image analysis methods in
speed and accuracy. In particular, vision transformers such as the Hierarchical
Vision Transformer (HvT) have shown accuracy exceeding 99.3% in plant disease
detection, outperforming architectures like MobileNetV3. The study concludes by
discussing system design challenges, proposing solutions, and outlining
promising directions for future research.

</details>


### [2] [ImageDDI: Image-enhanced Molecular Motif Sequence Representation for Drug-Drug Interaction Prediction](https://arxiv.org/abs/2508.08338)
*Yuqin He,Tengfei Ma,Chaoyi Li,Pengsen Ma,Hongxin Xiang,Jianmin Wang,Yiping Liu,Bosheng Song,Xiangxiang Zeng*

Main category: cs.CV

TL;DR: ImageDDI improves drug-drug interaction prediction by using a transformer model on functional motifs and enhancing representations with molecular image information, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for DDI prediction suffer from limited functional motif-based representation learning, as DDIs are caused by motif interactions rather than overall drug structures. This paper aims to improve DDI prediction by incorporating both local and global structure representations, including molecular image information.

Method: ImageDDI framework which tokenizes molecules into functional motifs, combines them into a single sequence, embeds them using a transformer-based encoder, and enhances spatial representation using global molecular image information through Adaptive Feature Fusion.

Result: Experimental results show that ImageDDI outperforms state-of-the-art methods on widely used datasets and achieves competitive performance in both 2D and 3D image-enhanced scenarios.

Conclusion: ImageDDI outperforms state-of-the-art methods in DDI prediction, achieving competitive performance in both 2D and 3D image-enhanced scenarios.

Abstract: To mitigate the potential adverse health effects of simultaneous multi-drug
use, including unexpected side effects and interactions, accurately identifying
and predicting drug-drug interactions (DDIs) is considered a crucial task in
the field of deep learning. Although existing methods have demonstrated
promising performance, they suffer from the bottleneck of limited functional
motif-based representation learning, as DDIs are fundamentally caused by motif
interactions rather than the overall drug structures. In this paper, we propose
an Image-enhanced molecular motif sequence representation framework for
\textbf{DDI} prediction, called ImageDDI, which represents a pair of drugs from
both global and local structures. Specifically, ImageDDI tokenizes molecules
into functional motifs. To effectively represent a drug pair, their motifs are
combined into a single sequence and embedded using a transformer-based encoder,
starting from the local structure representation. By leveraging the
associations between drug pairs, ImageDDI further enhances the spatial
representation of molecules using global molecular image information (e.g.
texture, shadow, color, and planar spatial relationships). To integrate
molecular visual information into functional motif sequence, ImageDDI employs
Adaptive Feature Fusion, enhancing the generalization of ImageDDI by
dynamically adapting the fusion process of feature representations.
Experimental results on widely used datasets demonstrate that ImageDDI
outperforms state-of-the-art methods. Moreover, extensive experiments show that
ImageDDI achieved competitive performance in both 2D and 3D image-enhanced
scenarios compared to other models.

</details>


### [3] [Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions](https://arxiv.org/abs/2508.08352)
*Christophe EL Zeinaty,Wassim Hamidouche,Glenn Herrou,Daniel Menard*

Main category: cs.CV

TL;DR: 本综述全面介绍了在资源受限的物联网设备上部署对象检测模型的优化技术，并评估了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于物联网设备数量的快速增长以及其计算能力的限制，在资源受限的物联网设备上部署对象检测模型面临巨大挑战。因此，有必要对优化技术进行详细分析，以实现高效的边缘计算。

Method: 本研究通过对现有对象检测模型在微控制器设备上的实现进行关键性能指标（包括预测准确性和效率）的比较，来评估其成熟度。

Result: 本综述对在微控制器设备上部署对象检测模型的优化技术进行了全面的分析，并对现有实现的关键性能指标进行了比较，以评估其成熟度。

Conclusion: 本综述详细分析了在资源受限设备上部署对象检测模型的关键优化技术，包括量化、剪枝、知识蒸馏和神经架构搜索，并探讨了理论方法和实际应用，旨在弥合学术研究与现实世界边缘人工智能部署之间的差距。

Abstract: Object detection (OD) has become vital for numerous computer vision
applications, but deploying it on resource-constrained IoT devices presents a
significant challenge. These devices, often powered by energy-efficient
microcontrollers, struggle to handle the computational load of deep
learning-based OD models. This issue is compounded by the rapid proliferation
of IoT devices, predicted to surpass 150 billion by 2030. TinyML offers a
compelling solution by enabling OD on ultra-low-power devices, paving the way
for efficient and real-time processing at the edge. Although numerous survey
papers have been published on this topic, they often overlook the optimization
challenges associated with deploying OD models in TinyML environments. To
address this gap, this survey paper provides a detailed analysis of key
optimization techniques for deploying OD models on resource-constrained
devices. These techniques include quantization, pruning, knowledge
distillation, and neural architecture search. Furthermore, we explore both
theoretical approaches and practical implementations, bridging the gap between
academic research and real-world edge artificial intelligence deployment.
Finally, we compare the key performance indicators (KPIs) of existing OD
implementations on microcontroller devices, highlighting the achieved maturity
level of these solutions in terms of both prediction accuracy and efficiency.
We also provide a public repository to continually track developments in this
fast-evolving field:
https://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.

</details>


### [4] [Neural Tangent Knowledge Distillation for Optical Convolutional Networks](https://arxiv.org/abs/2508.08421)
*Jinlin Xiang,Minho Choi,Yubo Zhang,Zhihao Zhou,Arka Majumdar,Eli Shlizerman*

Main category: cs.CV

TL;DR: 提出了一种新的流水线，通过NTKD和微调解决了混合光学神经网络的准确性问题，实现了跨任务和跨硬件的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决混合光学神经网络在训练中的准确性差距和仿真与制造系统之间的差异等挑战，并提高其在不同任务和硬件设计中的泛化能力。

Method: 提出了一种任务和硬件无关的流水线，该流水线包括用于预训练的神经元切线知识蒸馏（NTKD）和用于校正实现误差的微调。

Result: 在MNIST、CIFAR和Carvana Masking等多个数据集和硬件配置上，该流水线持续提高了混合光学神经网络的性能，并实现了预制造模拟和物理实现的实际部署。

Conclusion: 该方法在多个数据集和硬件配置上持续改进了混合光学神经网络的性能，并实现了从预制造模拟到物理实现的实际部署。

Abstract: Hybrid Optical Neural Networks (ONNs, typically consisting of an optical
frontend and a digital backend) offer an energy-efficient alternative to fully
digital deep networks for real-time, power-constrained systems. However, their
adoption is limited by two main challenges: the accuracy gap compared to
large-scale networks during training, and discrepancies between simulated and
fabricated systems that further degrade accuracy. While previous work has
proposed end-to-end optimizations for specific datasets (e.g., MNIST) and
optical systems, these approaches typically lack generalization across tasks
and hardware designs. To address these limitations, we propose a task-agnostic
and hardware-agnostic pipeline that supports image classification and
segmentation across diverse optical systems. To assist optical system design
before training, we estimate achievable model accuracy based on user-specified
constraints such as physical size and the dataset. For training, we introduce
Neural Tangent Knowledge Distillation (NTKD), which aligns optical models with
electronic teacher networks, thereby narrowing the accuracy gap. After
fabrication, NTKD also guides fine-tuning of the digital backend to compensate
for implementation errors. Experiments on multiple datasets (e.g., MNIST,
CIFAR, Carvana Masking) and hardware configurations show that our pipeline
consistently improves ONN performance and enables practical deployment in both
pre-fabrication simulations and physical implementations.

</details>


### [5] [MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling](https://arxiv.org/abs/2508.08487)
*Qian Wang,Ziqi Huang,Ruoxi Jia,Paul Debevec,Ning Yu*

Main category: cs.CV

TL;DR: MAViS是一个创新的长序列视频生成框架，通过多代理协作和“探索、检查、增强”原则，解决了现有方法的不足，能生成高质量、富有表现力的含音频故事视频，是目前唯一的多模态输出框架。


<details>
  <summary>Details</summary>
Motivation: 现有长序列视频生成框架存在辅助能力差、视觉质量不高和表现力有限等问题。为了解决这些限制，需要提出新的框架来提升视频生成的整体质量和用户体验。

Method: MAViS是一个端到端的、多主体协作的框架，通过专门的代理（agents）在脚本编写、镜头设计、角色建模、关键帧生成、视频动画和音频生成等多个阶段进行协调。每个阶段的代理都遵循“探索、检查、增强”（Explore, Examine, Enhance）的三三原则来确保中间输出的完整性。为了优化脚本与生成工具的兼容性，还提出了脚本编写指南。

Result: 实验结果表明，MAViS在辅助能力、视觉质量和视频表现力方面均优于现有技术，达到了最先进的水平。该框架还具有良好的可扩展性。

Conclusion: MAViS是一个端到端的长序列视频故事生成框架，在辅助能力、视觉质量和视频表现力方面均达到最先进的水平。其模块化框架易于扩展，能够兼容各种生成模型和工具。只需简单的用户提示，MAViS就能生成高质量、富有表现力的长序列视频故事，激发用户的灵感和创造力。MAViS是目前唯一能提供多模态设计输出（带有叙事和背景音乐的视频）的框架。

Abstract: Despite recent advances, long-sequence video generation frameworks still
suffer from significant limitations: poor assistive capability, suboptimal
visual quality, and limited expressiveness. To mitigate these limitations, we
propose MAViS, an end-to-end multi-agent collaborative framework for
long-sequence video storytelling. MAViS orchestrates specialized agents across
multiple stages, including script writing, shot designing, character modeling,
keyframe generation, video animation, and audio generation. In each stage,
agents operate under the 3E Principle -- Explore, Examine, and Enhance -- to
ensure the completeness of intermediate outputs. Considering the capability
limitations of current generative models, we propose the Script Writing
Guidelines to optimize compatibility between scripts and generative tools.
Experimental results demonstrate that MAViS achieves state-of-the-art
performance in assistive capability, visual quality, and video expressiveness.
Its modular framework further enables scalability with diverse generative
models and tools. With just a brief user prompt, MAViS is capable of producing
high-quality, expressive long-sequence video storytelling, enriching
inspirations and creativity for users. To the best of our knowledge, MAViS is
the only framework that provides multimodal design output -- videos with
narratives and background music.

</details>


### [6] [MuGa-VTON: Multi-Garment Virtual Try-On via Diffusion Transformers with Prompt Customization](https://arxiv.org/abs/2508.08488)
*Ankan Deria,Dwarikanath Mahapatra,Behzad Bozorgtabar,Mohna Chakraborty,Snehashis Chakraborty,Sudipta Roy*

Main category: cs.CV

TL;DR: MuGa-VTON is a new virtual try-on framework that unifies upper and lower garments, preserves identity, and allows for prompt-based customization, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing virtual try-on methods typically handle upper and lower garments separately, rely on heavy preprocessing, and often fail to preserve person-specific cues such as tattoos, accessories, and body shape, resulting in limited realism and flexibility. MuGa-VTON aims to address these limitations.

Method: MuGa-VTON introduces three key modules: the Garment Representation Module (GRM) for capturing garment semantics, the Person Representation Module (PRM) for encoding identity and pose cues, and the A-DiT fusion module, which integrates garment, person, and text-prompt features through a diffusion transformer. This architecture supports prompt-based customization for fine-grained garment modifications.

Result: Extensive experiments on the VITON-HD and DressCode benchmarks demonstrate that MuGa-VTON outperforms existing methods in both qualitative and quantitative evaluations, producing high-fidelity, identity-preserving results.

Conclusion: MuGa-VTON is a unified multi-garment diffusion framework that jointly models upper and lower garments together with person identity in a shared latent space, outperforming existing methods in both qualitative and quantitative evaluations and producing high-fidelity, identity-preserving results suitable for real-world virtual try-on applications.

Abstract: Virtual try-on seeks to generate photorealistic images of individuals in
desired garments, a task that must simultaneously preserve personal identity
and garment fidelity for practical use in fashion retail and personalization.
However, existing methods typically handle upper and lower garments separately,
rely on heavy preprocessing, and often fail to preserve person-specific cues
such as tattoos, accessories, and body shape-resulting in limited realism and
flexibility. To this end, we introduce MuGa-VTON, a unified multi-garment
diffusion framework that jointly models upper and lower garments together with
person identity in a shared latent space. Specifically, we proposed three key
modules: the Garment Representation Module (GRM) for capturing both garment
semantics, the Person Representation Module (PRM) for encoding identity and
pose cues, and the A-DiT fusion module, which integrates garment, person, and
text-prompt features through a diffusion transformer. This architecture
supports prompt-based customization, allowing fine-grained garment
modifications with minimal user input. Extensive experiments on the VITON-HD
and DressCode benchmarks demonstrate that MuGa-VTON outperforms existing
methods in both qualitative and quantitative evaluations, producing
high-fidelity, identity-preserving results suitable for real-world virtual
try-on applications.

</details>


### [7] [CObL: Toward Zero-Shot Ordinal Layering without User Prompting](https://arxiv.org/abs/2508.08498)
*Aneel Damaraju,Dean Hazineh,Todd Zickler*

Main category: cs.CV

TL;DR: CObL是一种新的扩散模型，可以从图像中识别和重建多个被遮挡的物体，而无需预先知道物体的数量或进行用户提示。它在合成数据上进行训练，并在真实世界的数据上表现良好。


<details>
  <summary>Details</summary>
Motivation: 为了从图像中推断出包含隔离的、非模态完成的物体的“物体层”堆栈的场景表示，其中每个物体层都按遮挡顺序排列。

Method: 提出了一种名为CObL的基于扩散的架构，该架构可以并行生成物体层堆叠，并使用Stable Diffusion作为自然物体的先验，以及推理时引导来确保推断的层能够复合回输入图像。

Result: CObL可以对多个被遮挡的物体进行重建，而无需用户提示，也无需预先知道物体的数量。此外，CObL没有像以前的无监督学习方法那样局限于其训练数据的世界。

Conclusion: CObL可以在不知道物体数量的情况下，对多个被遮挡的物体进行重建，并且在零次试验中可以泛化到真实世界的平板场景。

Abstract: Vision benefits from grouping pixels into objects and understanding their
spatial relationships, both laterally and in depth. We capture this with a
scene representation comprising an occlusion-ordered stack of "object layers,"
each containing an isolated and amodally-completed object. To infer this
representation from an image, we introduce a diffusion-based architecture named
Concurrent Object Layers (CObL). CObL generates a stack of object layers in
parallel, using Stable Diffusion as a prior for natural objects and
inference-time guidance to ensure the inferred layers composite back to the
input image. We train CObL using a few thousand synthetically-generated images
of multi-object tabletop scenes, and we find that it zero-shot generalizes to
photographs of real-world tabletops with varying numbers of novel objects. In
contrast to recent models for amodal object completion, CObL reconstructs
multiple occluded objects without user prompting and without knowing the number
of objects beforehand. Unlike previous models for unsupervised object-centric
representation learning, CObL is not limited to the world it was trained in.

</details>


### [8] [Re:Verse -- Can Your VLM Read a Manga?](https://arxiv.org/abs/2508.08508)
*Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: 当前的视觉语言模型在理解漫画等长篇视觉叙事方面存在重大缺陷，尤其是在因果关系和跨面板连贯性方面。本研究提出了一种新的评估框架，发现模型在叙事理解上缺乏深层智能，仅能进行表面识别。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在处理视觉故事叙述时，在表面识别和深层叙事推理之间存在关键差距。本研究旨在通过对漫画叙事理解进行全面调查，揭示现有大型多模态模型在理解独立图像面板方面的优势，以及它们在时间因果关系和跨面板连贯性方面的系统性失败，而这些是理解连贯故事的核心要求。

Method: 本研究引入了一个新的评估框架，结合了细粒度的多模态标注、跨模态嵌入分析和检索增强评估。具体方法包括：1) 链接视觉元素和叙事结构的严格标注协议（通过匹配轻小说文本）；2) 在多种推理范式（直接推理和检索增强生成）下的综合评估；3) 跨模态相似性分析，揭示当前VLMs联合表示的基本不匹配。该框架应用于《Re:Zero》漫画的11个章节（308个标注面板），从三个核心评估维度（生成式叙事、上下文对话基础和时间推理）系统地研究了VLMs的长篇叙事理解能力。

Result: 研究发现，当前的VLMs在理解长篇视觉叙事方面能力不足，尤其是在处理非线性叙事、角色一致性以及跨越长序列的因果推理方面存在显著困难。这表明它们缺乏真正的故事层面的智能。

Conclusion: 目前的研究表明，当前的视觉语言模型（VLMs）在处理长篇视觉叙事方面，尤其是在跨面板的因果关系和连贯性方面，与对叙事的深层理解能力之间存在显著差距。模型在理解非线性叙事、角色一致性和跨序列因果推理方面存在困难，表明它们缺乏真正的故事层面的智能。

Abstract: Current Vision Language Models (VLMs) demonstrate a critical gap between
surface-level recognition and deep narrative reasoning when processing
sequential visual storytelling. Through a comprehensive investigation of manga
narrative understanding, we reveal that while recent large multimodal models
excel at individual panel interpretation, they systematically fail at temporal
causality and cross-panel cohesion, core requirements for coherent story
comprehension. We introduce a novel evaluation framework that combines
fine-grained multimodal annotation, cross-modal embedding analysis, and
retrieval-augmented assessment to systematically characterize these
limitations.
  Our methodology includes (i) a rigorous annotation protocol linking visual
elements to narrative structure through aligned light novel text, (ii)
comprehensive evaluation across multiple reasoning paradigms, including direct
inference and retrieval-augmented generation, and (iii) cross-modal similarity
analysis revealing fundamental misalignments in current VLMs' joint
representations. Applying this framework to Re:Zero manga across 11 chapters
with 308 annotated panels, we conduct the first systematic study of long-form
narrative understanding in VLMs through three core evaluation axes: generative
storytelling, contextual dialogue grounding, and temporal reasoning. Our
findings demonstrate that current models lack genuine story-level intelligence,
struggling particularly with non-linear narratives, character consistency, and
causal inference across extended sequences. This work establishes both the
foundation and practical methodology for evaluating narrative intelligence,
while providing actionable insights into the capability of deep sequential
understanding of Discrete Visual Narratives beyond basic recognition in
Multimodal Models.

</details>


### [9] [VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models](https://arxiv.org/abs/2508.08521)
*Mansi Phute,Ravikumar Balakrishnan*

Main category: cs.CV

TL;DR: VISOR是一种新颖的视觉输入引导方法，可有效控制VLM行为，无需访问模型内部，并且能绕过文本防御，存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM行为控制方法（如系统提示）易于检测且效果不佳，而基于激活的引导向量需要侵入性的运行时访问模型内部，这对于API服务和闭源部署是不兼容的。因此，需要一种新的方法来实现无需运行时访问的模型行为控制。

Method: VISOR通过创建通用的引导图像来诱导目标激活模式，从而实现对视觉语言模型（VLM）的行为控制。

Result: VISOR在LLaVA-1.5-7B模型上进行了验证，在拒绝、奉承和生存本能任务上，单个150KB的引导图像在正向行为转移方面性能与引导向量相当（在1-2%的范围内），在负向引导方面表现远超引导向量，实现了高达25%的基线转变。VISOR在14,000个不相关的MMLU任务上保持了99.9%的性能，并能进行强大的双向控制。

Conclusion: VISOR是一种新颖的、仅通过优化视觉输入来实现复杂行为控制的方法。它通过创建通用的引导图像来诱导目标激活模式，可以在所有视觉语言模型（VLM）服务模式下进行实际部署，并且与显式文本指令相比，其引导图像几乎不可察觉。VISOR在LLaVA-1.5-7B模型上针对拒绝、奉承和生存本能三个关键对齐任务进行了验证。单个150KB的引导图像在正向行为转移方面，性能与引导向量相当（在1-2%的范围内），但在负向引导方面表现远超引导向量，实现了高达25%的基线转变，而引导向量的改变幅度有限。与系统提示（3-4%的转变）不同，VISOR提供了强大的双向控制，同时在14,000个不相关的MMLU任务上保持了99.9%的性能。VISOR不仅消除了运行时开销和模型访问要求，还揭示了一个关键的安全漏洞：攻击者可以通过视觉通道单独实现复杂的行为操纵，绕过基于文本的防御。我们的工作从根本上重塑了多模态模型的控制方式，并强调了防御视觉引导攻击的迫切需求。

Abstract: Vision Language Models (VLMs) are increasingly being used in a broad range of
applications, bringing their security and behavioral control to the forefront.
While existing approaches for behavioral control or output redirection, like
system prompting in VLMs, are easily detectable and often ineffective,
activation-based steering vectors require invasive runtime access to model
internals--incompatible with API-based services and closed-source deployments.
We introduce VISOR (Visual Input-based Steering for Output Redirection), a
novel method that achieves sophisticated behavioral control through optimized
visual inputs alone. By crafting universal steering images that induce target
activation patterns, VISOR enables practical deployment across all VLM serving
modalities while remaining imperceptible compared to explicit textual
instructions. We validate VISOR on LLaVA-1.5-7B across three critical alignment
tasks: refusal, sycophancy and survival instinct. A single 150KB steering image
matches steering vector performance within 1-2% for positive behavioral shifts
while dramatically exceeding it for negative steering--achieving up to 25%
shifts from baseline compared to steering vectors' modest changes. Unlike
system prompting (3-4% shifts), VISOR provides robust bidirectional control
while maintaining 99.9% performance on 14,000 unrelated MMLU tasks. Beyond
eliminating runtime overhead and model access requirements, VISOR exposes a
critical security vulnerability: adversaries can achieve sophisticated
behavioral manipulation through visual channels alone, bypassing text-based
defenses. Our work fundamentally re-imagines multimodal model control and
highlights the urgent need for defenses against visual steering attacks.

</details>


### [10] [Training Kindai OCR with parallel textline images and self-attention feature distance-based loss](https://arxiv.org/abs/2508.08537)
*Anh Le,Asanobu Kitamoto*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Kindai documents, written in modern Japanese from the late 19th to early 20th
century, hold significant historical value for researchers studying societal
structures, daily life, and environmental conditions of that period. However,
transcribing these documents remains a labor-intensive and time-consuming task,
resulting in limited annotated data for training optical character recognition
(OCR) systems. This research addresses this challenge of data scarcity by
leveraging parallel textline images - pairs of original Kindai text and their
counterparts in contemporary Japanese fonts - to augment training datasets. We
introduce a distance-based objective function that minimizes the gap between
self-attention features of the parallel image pairs. Specifically, we explore
Euclidean distance and Maximum Mean Discrepancy (MMD) as domain adaptation
metrics. Experimental results demonstrate that our method reduces the character
error rate (CER) by 2.23% and 3.94% over a Transformer-based OCR baseline when
using Euclidean distance and MMD, respectively. Furthermore, our approach
improves the discriminative quality of self-attention representations, leading
to more effective OCR performance for historical documents.

</details>


### [11] [Calibration Attention: Instance-wise Temperature Scaling for Vision Transformers](https://arxiv.org/abs/2508.08547)
*Wenhao Liang,Wei Emma Zhang,Lin Yue,Miao Xu,Olaf Maennel,Weitong Chen*

Main category: cs.CV

TL;DR: CalAttn是一种用于Vision Transformers的即插即用概率校准模块，可显著减少校准误差，同时保持高效且不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决Vision Transformers在风险敏感应用中部署时概率校准的关键问题，并改进现有的需要全局标量和额外验证集的温度缩放方法。

Method: 提出了一种名为CalAttn的即插即用模块，该模块直接从ViT的CLS token中学习自适应的、每实例的温度，用于概率校准。

Result: 在CIFAR-10/100、MNIST、Tiny-ImageNet和ImageNet-1K等数据集上，CalAttn将ViT-224、DeiT和Swin的校准误差降低了高达4倍，同时仅增加了不到0.1%的额外参数。此外，学习到的温度值紧密地聚集在1.0左右，与标准的温度缩放方法形成对比。

Conclusion: CalAttn是一种简单、高效且与架构无关的即插即用模块，可在不牺牲准确性的情况下提供更值得信赖的概率。

Abstract: Probability calibration is critical when Vision Transformers are deployed in
risk-sensitive applications. The standard fix, post-hoc temperature scaling,
uses a single global scalar and requires a held-out validation set. We
introduce Calibration Attention (CalAttn), a drop-in module that learns an
adaptive, per-instance temperature directly from the ViT's CLS token. Across
CIFAR-10/100, MNIST, Tiny-ImageNet, and ImageNet-1K, CalAttn reduces
calibration error by up to 4x on ViT-224, DeiT, and Swin, while adding under
0.1 percent additional parameters. The learned temperatures cluster tightly
around 1.0, in contrast to the large global values used by standard temperature
scaling. CalAttn is simple, efficient, and architecture-agnostic, and yields
more trustworthy probabilities without sacrificing accuracy. Code:
[https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-](https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-)

</details>


### [12] [Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation](https://arxiv.org/abs/2508.08549)
*Wei Li,Pengcheng Zhou,Linye Ma,Wenyi Zhao,Huihua Yang*

Main category: cs.CV

TL;DR: 提出DTLP-Net框架，通过教师-学生模型和数据增强技术，有效解决了医学图像分割中的有限标注和域转移问题，提升了SSMIS、UMDA和Semi-MDG任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中有限标注和域转移的挑战，这些挑战导致了半监督医学图像分割（SSMIS）、半监督医学域泛化（Semi-MDG）和无监督医学域自适应（UMDA）等衍生场景。传统方法通常孤立地针对特定任务进行定制，容易产生误差累积，阻碍了未标记数据的有效利用，并限制了进一步的改进。

Method: 提出了一种名为DTLP-Net的通用框架，该框架包含一个学生模型和两个不同的教师模型，用于生成可靠的伪标签。其中，第一个教师模型将标记数据和未标记数据的训练过程解耦；第二个教师模型进行周期性的动量更新，从而生成可靠且多样化的伪标签。此外，采用跨样本和类内样本数据增强来学习全局和局部知识，并通过标签传播来增强模型的鲁棒性。

Result: DTLP-Net在SSMIS、UMDA和Semi-MDG任务的五个基准数据集上进行了评估，结果显示与最先进的方法相比，在所有设置下均取得了显著的改进。

Conclusion: 所提出的框架在SSMIS、UMDA和Semi-MDG任务的五个基准数据集上进行了评估，并在所有五种设置下与最先进的方法相比均取得了显著改进，表明该框架有潜力应对更具挑战性的SSL场景。

Abstract: Both limited annotation and domain shift are significant challenges
frequently encountered in medical image segmentation, leading to derivative
scenarios like semi-supervised medical (SSMIS), semi-supervised medical domain
generalization (Semi-MDG) and unsupervised medical domain adaptation (UMDA).
Conventional methods are generally tailored to specific tasks in isolation, the
error accumulation hinders the effective utilization of unlabeled data and
limits further improvements, resulting in suboptimal performance when these
issues occur. In this paper, we aim to develop a generic framework that masters
all three tasks. We found that the key to solving the problem lies in how to
generate reliable pseudo labels for the unlabeled data in the presence of
domain shift with labeled data and increasing the diversity of the model. To
tackle this issue, we employ a Diverse Teaching and Label Propagation Network
(DTLP-Net) to boosting the Generic Semi-Supervised Medical Image Segmentation.
Our DTLP-Net involves a single student model and two diverse teacher models,
which can generate reliable pseudo-labels for the student model. The first
teacher model decouple the training process with labeled and unlabeled data,
The second teacher is momentum-updated periodically, thus generating reliable
yet divers pseudo-labels. To fully utilize the information within the data, we
adopt inter-sample and intra-sample data augmentation to learn the global and
local knowledge. In addition, to further capture the voxel-level correlations,
we propose label propagation to enhance the model robust. We evaluate our
proposed framework on five benchmark datasets for SSMIS, UMDA, and Semi-MDG
tasks. The results showcase notable improvements compared to state-of-the-art
methods across all five settings, indicating the potential of our framework to
tackle more challenging SSL scenarios.

</details>


### [13] [Unlocking the Potential of Diffusion Priors in Blind Face Restoration](https://arxiv.org/abs/2508.08556)
*Yunqi Miao,Zhiyu Qu,Mingqi Gao,Changrui Chen,Jifei Song,Jungong Han,Jiankang Deng*

Main category: cs.CV

TL;DR: FLIPNET通过在恢复和退化模式之间切换，解决了扩散模型在盲人脸恢复中的应用问题。


<details>
  <summary>Details</summary>
Motivation: 解决扩散先验模型在盲人脸恢复（BFR）任务中的应用瓶颈，这些瓶颈源于原始扩散模型与BFR设置之间的差异，包括高质量（HQ）和低质量（LQ）图像之间的差异，以及合成图像和真实世界图像之间的差异。

Method: FLIPNET使用一个统一的网络，通过在恢复模式和退化模式之间切换来解决图像恢复中的退化问题。在恢复模式下，模型整合了低质量图像中的退化特定特征和人脸嵌入，以实现真实和忠实的人脸恢复。在退化模式下，模型利用从真实世界退化数据集中学到的知识来合成类似真实世界的退化图像。

Result: FLIPNET在真实世界退化建模方面优于朴素的退化模型，并且在真实性、保真度方面优于先前基于扩散先验的BFR方法。

Conclusion: FLIPNET在真实世界退化建模方面优于朴素的退化模型。

Abstract: Although diffusion prior is rising as a powerful solution for blind face
restoration (BFR), the inherent gap between the vanilla diffusion model and BFR
settings hinders its seamless adaptation. The gap mainly stems from the
discrepancy between 1) high-quality (HQ) and low-quality (LQ) images and 2)
synthesized and real-world images. The vanilla diffusion model is trained on
images with no or less degradations, whereas BFR handles moderately to severely
degraded images. Additionally, LQ images used for training are synthesized by a
naive degradation model with limited degradation patterns, which fails to
simulate complex and unknown degradations in real-world scenarios. In this
work, we use a unified network FLIPNET that switches between two modes to
resolve specific gaps. In Restoration mode, the model gradually integrates
BFR-oriented features and face embeddings from LQ images to achieve authentic
and faithful face restoration. In Degradation mode, the model synthesizes
real-world like degraded images based on the knowledge learned from real-world
degradation datasets. Extensive evaluations on benchmark datasets show that our
model 1) outperforms previous diffusion prior based BFR methods in terms of
authenticity and fidelity, and 2) outperforms the naive degradation model in
modeling the real-world degradations.

</details>


### [14] [Think as Cardiac Sonographers: Marrying SAM with Left Ventricular Indicators Measurements According to Clinical Guidelines](https://arxiv.org/abs/2508.08566)
*Tuo Liu,Qinghan Yang,Yu Zhang,Rongjun Ge,Yang Chen,Guangquan Zhou*

Main category: cs.CV

TL;DR: AutoSAME框架结合SAM的分割能力和关键解剖点定位，通过FCBA和SGPA技术提升左心室量化精度，在超声心动图数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自动左心室量化算法由于训练数据集通常较小，难以捕捉通用的视觉表示。虽然现有的视觉基础模型（VFMs）如SAM在分割方面表现强大，但无法精确定位对左心室指标测量至关重要的关键解剖点。

Method: 提出了一种名为AutoSAME的新框架，结合了SAM的分割能力和关键解剖点定位任务。引入了过滤交叉分支注意力（FCBA）机制，从频域增强关键点的热图回归。提出了空间引导提示对齐（SGPA）技术，以空间属性为指导自动生成提示嵌入，提高密集预测的准确性。

Result: 在超声心动图数据集上的大量实验证明了AutoSAME在左心室分割、标志点定位和指标测量方面的效率和优越性。

Conclusion: AutoSAME框架在左心室分割、标志点定位和指标测量方面表现出优越性，并且其设计的有效性得到了充分验证。

Abstract: Left ventricular (LV) indicator measurements following clinical
echocardiog-raphy guidelines are important for diagnosing cardiovascular
disease. Alt-hough existing algorithms have explored automated LV
quantification, they can struggle to capture generic visual representations due
to the normally small training datasets. Therefore, it is necessary to
introduce vision founda-tional models (VFM) with abundant knowledge. However,
VFMs represented by the segment anything model (SAM) are usually suitable for
segmentation but incapable of identifying key anatomical points, which are
critical in LV indicator measurements. In this paper, we propose a novel
framework named AutoSAME, combining the powerful visual understanding of SAM
with seg-mentation and landmark localization tasks simultaneously.
Consequently, the framework mimics the operation of cardiac sonographers,
achieving LV indi-cator measurements consistent with clinical guidelines. We
further present fil-tered cross-branch attention (FCBA) in AutoSAME, which
leverages relatively comprehensive features in the segmentation to enhance the
heatmap regression (HR) of key points from the frequency domain perspective,
optimizing the vis-ual representation learned by the latter. Moreover, we
propose spatial-guided prompt alignment (SGPA) to automatically generate prompt
embeddings guid-ed by spatial properties of LV, thereby improving the accuracy
of dense pre-dictions by prior spatial knowledge. The extensive experiments on
an echocar-diography dataset demonstrate the efficiency of each design and the
superiori-ty of our AutoSAME in LV segmentation, landmark localization, and
indicator measurements. The code will be available at
https://github.com/QC-LIU-1997/AutoSAME.

</details>


### [15] [Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation](https://arxiv.org/abs/2508.08570)
*Chenruo Liu,Hongjun Liu,Zeyu Lai,Yiqiu Shen,Chen Zhao,Qi Lei*

Main category: cs.CV

TL;DR: 提出一种利用超类信息和基于梯度的注意力来提高模型对伪相关性的鲁棒性的方法，无需额外标注即可实现更好的领域泛化。


<details>
  <summary>Details</summary>
Motivation: 为了增强群体对伪相关性的鲁棒性，现有工作通常依赖于用于群体或伪特征的辅助注释，并假设源域和目标域中的群体相同。这两种要求在现实世界环境中既不自然又不切实际。

Method: 提出一种利用类别标签固有的语义结构（特别是超类信息）的方法，以自然地减少对伪特征的依赖。模型采用由预训练的视觉-语言模型引导的基于梯度的注意力来分离超类相关特征和与超类无关的特征。然后，通过促进使用所有与超类相关的特征进行预测，该方法在无需标注任何源样本的情况下，实现了对更复杂的伪相关性的鲁棒性。

Result: 实验表明，该方法在跨领域泛化任务中显著优于基线方法，在定量指标和定性可视化方面都有明显改进。

Conclusion: 该方法在跨领域泛化任务中显著优于基线方法，在定量指标和定性可视化方面都有明显改进。

Abstract: To enhance group robustness to spurious correlations, prior work often relies
on auxiliary annotations for groups or spurious features and assumes identical
sets of groups across source and target domains. These two requirements are
both unnatural and impractical in real-world settings. To overcome these
limitations, we propose a method that leverages the semantic structure inherent
in class labels--specifically, superclass information--to naturally reduce
reliance on spurious features. Our model employs gradient-based attention
guided by a pre-trained vision-language model to disentangle
superclass-relevant and irrelevant features. Then, by promoting the use of all
superclass-relevant features for prediction, our approach achieves robustness
to more complex spurious correlations without the need to annotate any source
samples. Experiments across diverse datasets demonstrate that our method
significantly outperforms baselines in domain generalization tasks, with clear
improvements in both quantitative metrics and qualitative visualizations.

</details>


### [16] [RealisMotion: Decomposed Human Motion Control and Video Generation in the World Space](https://arxiv.org/abs/2508.08588)
*Jingyun Liang,Jingkai Zhou,Shikai Li,Chenjie Cao,Lei Sun,Yichen Qian,Weihua Chen,Fan Wang*

Main category: cs.CV

TL;DR: A new framework decouples motion from appearance, subject from background, and action from trajectory for controllable human video generation using a 3D coordinate system and diffusion models. It allows flexible composition of video elements and achieves state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing methods for generating human videos struggle with separate control over foreground subject, background video, human trajectory, and action patterns, despite generating visually compelling videos. The motivation is to enable flexible mix-and-match composition of these elements for more controllable video generation.

Method: The framework decouples motion from appearance, subject from background, and action from trajectory. It involves building a ground-aware 3D coordinate system for motion editing, unprojecting 2D trajectories into 3D, and incorporating motion control signals into text-to-video diffusion transformer models by injecting the subject as tokens, concatenating the background, and adding motion signals.

Result: Extensive experiments on benchmark datasets and real-world cases demonstrate that the method achieves state-of-the-art performance on both element-wise controllability and overall video quality.

Conclusion: The proposed method achieves state-of-the-art performance in element-wise controllability and overall video quality, enabling the generation of realistic videos with flexible composition of foreground subject, background video, human trajectory, and action patterns.

Abstract: Generating human videos with realistic and controllable motions is a
challenging task. While existing methods can generate visually compelling
videos, they lack separate control over four key video elements: foreground
subject, background video, human trajectory and action patterns. In this paper,
we propose a decomposed human motion control and video generation framework
that explicitly decouples motion from appearance, subject from background, and
action from trajectory, enabling flexible mix-and-match composition of these
elements. Concretely, we first build a ground-aware 3D world coordinate system
and perform motion editing directly in the 3D space. Trajectory control is
implemented by unprojecting edited 2D trajectories into 3D with focal-length
calibration and coordinate transformation, followed by speed alignment and
orientation adjustment; actions are supplied by a motion bank or generated via
text-to-motion methods. Then, based on modern text-to-video diffusion
transformer models, we inject the subject as tokens for full attention,
concatenate the background along the channel dimension, and add motion
(trajectory and action) control signals by addition. Such a design opens up the
possibility for us to generate realistic videos of anyone doing anything
anywhere. Extensive experiments on benchmark datasets and real-world cases
demonstrate that our method achieves state-of-the-art performance on both
element-wise controllability and overall video quality.

</details>


### [17] [DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding](https://arxiv.org/abs/2508.08589)
*Wenwen Yu,Zhibo Yang,Yuliang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: DocThinker是一个基于规则的强化学习框架，用于改进多模态大语言模型（MLLM）在文档理解中的推理过程，通过自主学习策略和生成可解释的中间结果，提高了模型的适应性、透明度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLM）在文档理解方面能力出色，但其推理过程很大程度上是黑箱，尤其是在法律、金融和医疗文档分析等高风险领域，难以确保可靠性和可信度。现有的方法使用固定的思维链（CoT）推理与监督微调（SFT），但存在灾难性遗忘、适应性差和领域任务泛化能力有限的问题。

Method: 提出DocThinker，一个基于规则的强化学习（RL）框架，用于动态推理时推理。DocThinker通过策略学习自主改进推理策略，生成可解释的中间结果，包括结构化推理过程、改写的问题、支持答案的感兴趣区域（RoI）以及最终答案。通过集成多目标基于规则的奖励和KL约束优化，我们的方法减轻了灾难性遗忘，并增强了适应性和透明度。

Result: DocThinker在多个基准测试上进行了广泛的实验，结果表明该方法显著提高了泛化能力，并产生了更具可解释性和人类可理解性的推理步骤。

Conclusion: RL是增强MLLM文档理解的可解释性和适应性的强大替代方案。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in document understanding. However, their reasoning processes
remain largely black-box, making it difficult to ensure reliability and
trustworthiness, especially in high-stakes domains such as legal, financial,
and medical document analysis. Existing methods use fixed Chain-of-Thought
(CoT) reasoning with supervised fine-tuning (SFT) but suffer from catastrophic
forgetting, poor adaptability, and limited generalization across domain tasks.
In this paper, we propose DocThinker, a rule-based Reinforcement Learning (RL)
framework for dynamic inference-time reasoning. Instead of relying on static
CoT templates, DocThinker autonomously refines reasoning strategies via policy
learning, generating explainable intermediate results, including structured
reasoning processes, rephrased questions, regions of interest (RoI) supporting
the answer, and the final answer. By integrating multi-objective rule-based
rewards and KL-constrained optimization, our method mitigates catastrophic
forgetting and enhances both adaptability and transparency. Extensive
experiments on multiple benchmarks demonstrate that DocThinker significantly
improves generalization while producing more explainable and
human-understandable reasoning steps. Our findings highlight RL as a powerful
alternative for enhancing explainability and adaptability in MLLM-based
document understanding. Code will be available at
https://github.com/wenwenyu/DocThinker.

</details>


### [18] [QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection](https://arxiv.org/abs/2508.08590)
*Yuxiao Wang,Wolin Liang,Yu Lei,Weiying Xue,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: QueryCraft通过ACTOR（动作感知跨模态Transformer）和PDQD（感知蒸馏查询解码器）改进了HOI检测，使用语义先验和引导式特征学习来初始化查询，从而提高了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: DETR类HOI检测方法存在一个关键限制：随机初始化的查询缺乏明确的语义信息，导致检测性能不佳。

Method: 提出了一种名为QueryCraft的新型即插即用HOI检测框架，通过基于Transformer的查询初始化来整合语义先验和引导式特征学习。该框架的核心是ACTOR（Action-aware Cross-modal TRansfORmer），它是一种跨模态Transformer编码器，可以同时关注视觉区域和文本提示以提取与动作相关的特征。此外，还引入了PDQD（Perceptual Distilled Query Decoder），用于从预训练检测器中提取对象类别感知信息，作为对象查询的初始化。

Result: QueryCraft在HICO-Det和V-COCO数据集上取得了最先进的性能和强大的泛化能力。

Conclusion: QueryCraft通过ACTOR和PDQD实现了最先进的HOI检测性能，并在HICO-Det和V-COCO基准测试中展示了强大的泛化能力。

Abstract: Human-Object Interaction (HOI) detection aims to localize human-object pairs
and recognize their interactions in images. Although DETR-based methods have
recently emerged as the mainstream framework for HOI detection, they still
suffer from a key limitation: Randomly initialized queries lack explicit
semantics, leading to suboptimal detection performance. To address this
challenge, we propose QueryCraft, a novel plug-and-play HOI detection framework
that incorporates semantic priors and guided feature learning through
transformer-based query initialization. Central to our approach is
\textbf{ACTOR} (\textbf{A}ction-aware \textbf{C}ross-modal
\textbf{T}ransf\textbf{OR}mer), a cross-modal Transformer encoder that jointly
attends to visual regions and textual prompts to extract action-relevant
features. Rather than merely aligning modalities, ACTOR leverages
language-guided attention to infer interaction semantics and produce
semantically meaningful query representations. To further enhance object-level
query quality, we introduce a \textbf{P}erceptual \textbf{D}istilled
\textbf{Q}uery \textbf{D}ecoder (\textbf{PDQD}), which distills object category
awareness from a pre-trained detector to serve as object query initiation. This
dual-branch query initialization enables the model to generate more
interpretable and effective queries for HOI detection. Extensive experiments on
HICO-Det and V-COCO benchmarks demonstrate that our method achieves
state-of-the-art performance and strong generalization. Code will be released
upon publication.

</details>


### [19] [Yan: Foundational Interactive Video Generation](https://arxiv.org/abs/2508.08601)
*Yan Team*

Main category: cs.CV

TL;DR: Yan是一个集模拟、生成和编辑于一体的交互式视频生成框架，能实现高质量、可控的视频创作。


<details>
  <summary>Details</summary>
Motivation: 提出一个用于交互式视频生成的综合性AI驱动框架，实现从模拟、生成到编辑的完整流程，超越现有孤立的功能，推动创意工具、媒体和娱乐的发展。

Method: Yan框架包含三个核心模块：1. AAA级模拟：采用高度压缩、低延迟的3D-VAE和基于KV缓存的移窗去噪推理过程，实现实时1080P/60FPS交互式模拟。2. 多模态生成：提出一种分层自回归字幕方法，将游戏特定知识注入开放域多模态视频扩散模型（VDMs），并将其转化为逐帧、动作可控、实时无限的交互式视频生成器，能够灵活融合不同领域的用户提示。3. 多粒度编辑：提出一个混合模型，将交互机制模拟与视觉渲染分离，支持通过文本进行交互式视频内容编辑。

Result:  Yan框架成功集成了模拟、生成和编辑模块，实现了实时的1080P/60FPS交互式模拟，并且能够融合不同领域（文本和视觉提示）的风格和机制，支持通过文本进行多粒度的视频内容编辑。

Conclusion: Yan是一个全面的、由AI驱动的交互式视频生成框架，集成了模拟、生成和编辑功能，为下一代创意工具、媒体和娱乐奠定了基础。

Abstract: We present Yan, a foundational framework for interactive video generation,
covering the entire pipeline from simulation and generation to editing.
Specifically, Yan comprises three core modules. AAA-level Simulation: We design
a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based
shift-window denoising inference process, achieving real-time 1080P/60FPS
interactive simulation. Multi-Modal Generation: We introduce a hierarchical
autoregressive caption method that injects game-specific knowledge into
open-domain multi-modal video diffusion models (VDMs), then transforming the
VDM into a frame-wise, action-controllable, real-time infinite interactive
video generator. Notably, when the textual and visual prompts are sourced from
different domains, the model demonstrates strong generalization, allowing it to
blend and compose the style and mechanics across domains flexibly according to
user prompts. Multi-Granularity Editing: We propose a hybrid model that
explicitly disentangles interactive mechanics simulation from visual rendering,
enabling multi-granularity video content editing during interaction through
text. Collectively, Yan offers an integration of these modules, pushing
interactive video generation beyond isolated capabilities toward a
comprehensive AI-driven interactive creation paradigm, paving the way for the
next generation of creative tools, media, and entertainment. The project page
is: https://greatx3.github.io/Yan/.

</details>


### [20] [Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization](https://arxiv.org/abs/2508.08604)
*Jihwan Park,Taehoon song,Sanghyeok Lee,Miso Choi,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出 TransMiter，一种无需反向传播即可转移视觉语言模型知识的轻量级适配器，可提高模型性能并降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLMs）尺寸和复杂性的增加，微调成本高昂，需要一种方法来重用“较弱”模型的适应性知识来有效地增强“较强”模型。现有的方法存在模型特定设计和高计算需求导致的可转移性有限的问题。

Method: 提出了一种名为 Transferable Model-agnostic adapter (TransMiter) 的轻量级适配器，该适配器无需反向传播即可改进视觉语言模型。TransMiter 以无监督方式捕获预训练和微调的 VLMs 之间的知识差距，训练后可无缝转移知识。该适配器仅包含少量层，对推理成本的影响可忽略不计。使用少量标记数据进行补充可以进一步提高性能。

Result: TransMiter 能够有效且高效地转移适应性知识，同时在不同尺寸和架构的视觉语言模型（VLMs）的视觉识别任务中保持泛化能力。在补充少量标记数据后，其性能甚至超过了微调后的较强模型，而训练成本却很小。

Conclusion: TransMiter 能够有效且高效地转移适应性知识，同时在不同尺寸和架构的视觉语言模型（VLMs）的视觉识别任务中保持泛化能力。

Abstract: Vision-Language Models (VLMs) have been widely used in various visual
recognition tasks due to their remarkable generalization capabilities. As these
models grow in size and complexity, fine-tuning becomes costly, emphasizing the
need to reuse adaptation knowledge from 'weaker' models to efficiently enhance
'stronger' ones. However, existing adaptation transfer methods exhibit limited
transferability across models due to their model-specific design and high
computational demands. To tackle this, we propose Transferable Model-agnostic
adapter (TransMiter), a light-weight adapter that improves vision-language
models 'without backpropagation'. TransMiter captures the knowledge gap between
pre-trained and fine-tuned VLMs, in an 'unsupervised' manner. Once trained,
this knowledge can be seamlessly transferred across different models without
the need for backpropagation. Moreover, TransMiter consists of only a few
layers, inducing a negligible additional inference cost. Notably, supplementing
the process with a few labeled data further yields additional performance gain,
often surpassing a fine-tuned stronger model, with a marginal training cost.
Experimental results and analyses demonstrate that TransMiter effectively and
efficiently transfers adaptation knowledge while preserving generalization
abilities across VLMs of different sizes and architectures in visual
recognition tasks.

</details>


### [21] [SelfHVD: Self-Supervised Handheld Video Deblurring for Mobile Phones](https://arxiv.org/abs/2508.08605)
*Honglei Xu,Zhilu Zhang,Junjie Fan,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: This paper introduces a self-supervised method (SEVD and SCSCM) to deblur handheld phone videos by using sharp clues within the video itself, addressing the domain gap and improving quality, outperforming prior methods.


<details>
  <summary>Details</summary>
Motivation: Handheld mobile phone videos often suffer from blurriness due to hand shaking and other instability. Existing video deblurring methods struggle with real-world handheld videos because of the blur domain gap between training and testing data.

Method: The paper proposes a self-supervised method for handheld video deblurring. Key techniques include extracting sharp clues as misalignment labels, a novel Self-Enhanced Video Deblurring (SEVD) method for creating higher-quality paired data, and a Self-Constrained Spatial Consistency Maintenance (SCSCM) method to prevent position shifts.

Result: The method was evaluated on synthetic and real-world handheld video datasets, demonstrating significant improvements over existing self-supervised methods.

Conclusion: The proposed method significantly outperforms existing self-supervised methods on both synthetic and real-world handheld video deblurring tasks, and the code and datasets are publicly available.

Abstract: Shooting video with a handheld mobile phone, the most common photographic
device, often results in blurry frames due to shaking hands and other
instability factors. Although previous video deblurring methods have achieved
impressive progress, they still struggle to perform satisfactorily on
real-world handheld video due to the blur domain gap between training and
testing data. To address the issue, we propose a self-supervised method for
handheld video deblurring, which is driven by sharp clues in the video. First,
to train the deblurring model, we extract the sharp clues from the video and
take them as misalignment labels of neighboring blurry frames. Second, to
improve the model's ability, we propose a novel Self-Enhanced Video Deblurring
(SEVD) method to create higher-quality paired video data. Third, we propose a
Self-Constrained Spatial Consistency Maintenance (SCSCM) method to regularize
the model, preventing position shifts between the output and input frames.
Moreover, we construct a synthetic and a real-world handheld video dataset for
handheld video deblurring. Extensive experiments on these two and other common
real-world datasets demonstrate that our method significantly outperforms
existing self-supervised ones. The code and datasets are publicly available at
https://github.com/cshonglei/SelfHVD.

</details>


### [22] [Neural Artistic Style and Color Transfer Using Deep Learning](https://arxiv.org/abs/2508.08608)
*Justin London*

Main category: cs.CV

TL;DR: 提出一种结合神经风格迁移和颜色迁移的方法，并用KL散度量化评估了多种颜色迁移算法。


<details>
  <summary>Details</summary>
Motivation: 为了探索神经艺术风格迁移与颜色迁移的结合，并量化评估不同颜色迁移算法在其中表现。

Method: 提出一种结合神经艺术风格迁移和颜色迁移的方法，并使用KL散度量化评估了Reinhard全局颜色迁移、迭代分布迁移（IDT）、带 पुनurgrain的IDT、Cholesky和PCA等算法在风格迁移中的表现。

Result: 通过实验评估了不同颜色迁移算法的KL散度和颜色直方图匹配情况，为风格迁移中的颜色处理提供了参考。

Conclusion: 本研究介绍了一种结合神经艺术风格迁移和颜色迁移的方法，并使用KL散度量化评估了多种颜色和亮度直方图匹配算法在风格迁移中的表现。

Abstract: Neural artistic style transfers and blends the content and style
representation of one image with the style of another. This enables artists to
create unique innovative visuals and enhances artistic expression in various
fields including art, design, and film. Color transfer algorithms are an
important in digital image processing by adjusting the color information in a
target image based on the colors in the source image. Color transfer enhances
images and videos in film and photography, and can aid in image correction. We
introduce a methodology that combines neural artistic style with color
transfer. The method uses the Kullback-Leibler (KL) divergence to
quantitatively evaluate color and luminance histogram matching algorithms
including Reinhard global color transfer, iteration distribution transfer
(IDT), IDT with regrain, Cholesky, and PCA between the original and neural
artistic style transferred image using deep learning. We estimate the color
channel kernel densities. Various experiments are performed to evaluate the KL
of these algorithms and their color histograms for style to content transfer.

</details>


### [23] [Hierarchical Visual Prompt Learning for Continual Video Instance Segmentation](https://arxiv.org/abs/2508.08612)
*Jiahua Dong,Hui Yin,Wenqi Liang,Hanbin Zhao,Henghui Ding,Nicu Sebe,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 提出了一种名为HVPL的新模型，用于解决视频实例分割中的类别固定和灾难性遗忘问题。该模型通过帧级和视频级的提示学习机制，能够有效学习新类别而不会遗忘旧类别。


<details>
  <summary>Details</summary>
Motivation: 现有的视频实例分割（VIS）方法通常假设对象实例的类别在视频中是固定的，并且在学习新类别时会遗忘旧类别。

Method: 提出了一种新颖的层级视觉提示学习（HVPL）模型，包括任务特定的帧提示、正交梯度校正（OGC）模块、任务特定的视频提示和视频上下文解码器，以解决类别固定假设和灾难性遗忘问题。

Result: HVPL模型通过帧级和视频级的机制有效克服了灾难性遗忘，并在严格的比较中证明了其有效性。

Conclusion: HVPL模型被证明比基线方法更有效。

Abstract: Video instance segmentation (VIS) has gained significant attention for its
capability in tracking and segmenting object instances across video frames.
However, most of the existing VIS approaches unrealistically assume that the
categories of object instances remain fixed over time. Moreover, they
experience catastrophic forgetting of old classes when required to continuously
learn object instances belonging to new categories. To resolve these
challenges, we develop a novel Hierarchical Visual Prompt Learning (HVPL) model
that overcomes catastrophic forgetting of previous categories from both
frame-level and video-level perspectives. Specifically, to mitigate forgetting
at the frame level, we devise a task-specific frame prompt and an orthogonal
gradient correction (OGC) module. The OGC module helps the frame prompt encode
task-specific global instance information for new classes in each individual
frame by projecting its gradients onto the orthogonal feature space of old
classes. Furthermore, to address forgetting at the video level, we design a
task-specific video prompt and a video context decoder. This decoder first
embeds structural inter-class relationships across frames into the frame prompt
features, and then propagates task-specific global video contexts from the
frame prompt features to the video prompt. Through rigorous comparisons, our
HVPL model proves to be more effective than baseline approaches. The code is
available at https://github.com/JiahuaDong/HVPL.

</details>


### [24] [AME: Aligned Manifold Entropy for Robust Vision-Language Distillation](https://arxiv.org/abs/2508.08644)
*Guiming Cao,Yuming Ou*

Main category: cs.CV

TL;DR: Knowledge distillation for vision-language models (VLMs) usually needs lots of data. This paper proposes AME, a plug-and-play module that uses entropy minimization on a shared manifold to improve distillation, even with limited data, leading to better performance.


<details>
  <summary>Details</summary>
Motivation: Current vision-language knowledge distillation methods require large amounts of training data for robust generalization, especially for ambiguous or boundary-adjacent representations with high predictive uncertainty. Collecting such data is often impractical in real-world scenarios. AME aims to address this challenge by enabling robust generalization under low-data regimes.

Method: AME applies entropy minimization over a reconfigured shared manifold, where multi-modal data are bridged through a pair of projection functions for structural compression of cross-modal feature representations. This approach requires no architectural modifications to the backbone and can serve as a plug-and-play module.

Result: Extensive experiments demonstrate that AME consistently facilitates robust knowledge distillation, resulting in superior generalization performance across a wide spectrum of downstream tasks. Theoretical analysis also shows that integrating knowledge distillation with entropy minimization over the shared manifold leads to a tighter generalization error bound.

Conclusion: AME enables robust knowledge distillation under low-data regimes by applying entropy minimization over a reconfigured shared manifold, leading to superior generalization performance across a wide spectrum of downstream tasks.

Abstract: Knowledge distillation is a long-established technique for knowledge
transfer, and has regained attention in the context of the recent emergence of
large vision-language models (VLMs). However, vision-language knowledge
distillation often requires sufficient training data to achieve robust
generalization on amples with ambiguous or boundary-adjacent representations,
which are associated with high predictive uncertainty. Critically, collecting
such large-scale, task-specific data for training is often impractical in
real-world scenarios. To address this major challenge arising from the
entanglement of uncertainty and cross-modal feature representation, we propose
Aligned Manifold Entropy for Robust Vision-Language Distillation (AME), aiming
to achieve robust generalization under real-world conditions. AME applies
entropy minimization over a reconfigured shared manifold, where multi-modal
data (i.e., image and text) are bridged through a pair of projection functions,
conducive to structural compression for cross-modal feature representations.
This enables robust knowledge distillation under low-data regimes, while
requiring no architectural modifications to the backbone. As a result, it can
serve as a plug-and-play module compatible with a wide range of vision-language
distillation frameworks. Notably, our theoretical analysis reveals that
integrating knowledge distillation with entropy minimization over the shared
manifold leads to a tighter generalization error bound. Extensive experiments
across diverse distillation architectures and training settings demonstrate
that AME consistently facilitates robust knowledge distillation, resulting in
superior generalization performance across a wide spectrum of downstream tasks.

</details>


### [25] [Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation](https://arxiv.org/abs/2508.08660)
*Xin Wang,Yin Guo,Jiamin Xia,Kaiyu Zhang,Niranjan Balu,Mahmud Mossa-Basha,Linda Shapiro,Chun Yuan*

Main category: cs.CV

TL;DR: 本研究提出了一个统一的框架，用于医学图像分割的无监督域自适应，该框架可以同时处理源可访问和源自由场景。它通过学习一个域不变的概率流形来捕捉解剖规律，并将图像内容解耦为典型解剖结构和个体几何形状。实验证明，该方法在多个数据集上均取得了最先进的性能，并且具有良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域自适应方法在医学图像分割中要么只适用于源可访问场景，要么只适用于源自由场景，这暴露了在构建能够跨域和跨场景泛化的解剖知识方面存在缺陷。因此，需要一个能够桥接这两种场景的统一框架。

Method: 提出了一种统一的、语义驱动的框架，该框架能够同时支持源可访问和源自由的域自适应。该模型学习一个域不变的概率流形作为解剖规律的全局空间，并将结构内容解释为从流形中检索到的典型解剖结构和捕捉个体几何形状的空间变换。

Result: 该框架在源可访问和源自由的域自适应设置下均取得了最先进的结果，并且在源自由设置下的性能与源可访问设置下的性能非常接近。

Conclusion: 该框架在具有挑战性的心脏和腹部数据集上实现了最先进的结果，并且在源自由设置下的性能与源可访问设置下的性能非常接近，这在以往的研究中很少见。此外，该框架的可解释性得到了验证，可以通过流形遍历实现平滑的形状操控。

Abstract: Most prior unsupervised domain adaptation approaches for medical image
segmentation are narrowly tailored to either the source-accessible setting,
where adaptation is guided by source-target alignment, or the source-free
setting, which typically resorts to implicit supervision mechanisms such as
pseudo-labeling and model distillation. This substantial divergence in
methodological designs between the two settings reveals an inherent flaw: the
lack of an explicit, structured construction of anatomical knowledge that
naturally generalizes across domains and settings. To bridge this longstanding
divide, we introduce a unified, semantically grounded framework that supports
both source-accessible and source-free adaptation. Fundamentally distinct from
all prior works, our framework's adaptability emerges naturally as a direct
consequence of the model architecture, without the need for any handcrafted
adaptation strategies. Specifically, our model learns a domain-agnostic
probabilistic manifold as a global space of anatomical regularities, mirroring
how humans establish visual understanding. Thus, the structural content in each
image can be interpreted as a canonical anatomy retrieved from the manifold and
a spatial transformation capturing individual-specific geometry. This
disentangled, interpretable formulation enables semantically meaningful
prediction with intrinsic adaptability. Extensive experiments on challenging
cardiac and abdominal datasets show that our framework achieves
state-of-the-art results in both settings, with source-free performance closely
approaching its source-accessible counterpart, a level of consistency rarely
observed in prior works. Beyond quantitative improvement, we demonstrate strong
interpretability of the proposed framework via manifold traversal for smooth
shape manipulation.

</details>


### [26] [Learning Generalizable and Efficient Image Watermarking via Hierarchical Two-Stage Optimization](https://arxiv.org/abs/2508.08667)
*Ke Liu,Xuanhan Wang,Qilong Zhang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

TL;DR: A new method called HiWL addresses limitations in deep image watermarking by improving invisibility, robustness, and speed through a two-stage optimization process.


<details>
  <summary>Details</summary>
Motivation: Existing deep image watermarking methods face limitations in simultaneously satisfying invisibility, robustness, and broad applicability (low latency).

Method: HiWL is a two-stage optimization method. Stage 1: Distribution alignment learning with constraints for visual consistency and information invariance to represent multi-modal inputs. Stage 2: Generalized watermark representation learning with a disentanglement policy to separate watermarks from image content in RGB space.

Result: HiWL achieves 7.6% higher accuracy in watermark extraction compared to existing methods and processes 100K images in 8s, demonstrating effectiveness and low latency.

Conclusion: HiWL effectively learns generalizable latent-space watermark representations while maintaining broad applicability, achieving 7.6% higher accuracy in watermark extraction than existing methods, while maintaining extremely low latency (100K images processed in 8s).

Abstract: Deep image watermarking, which refers to enable imperceptible watermark
embedding and reliable extraction in cover images, has shown to be effective
for copyright protection of image assets. However, existing methods face
limitations in simultaneously satisfying three essential criteria for
generalizable watermarking: 1) invisibility (imperceptible hide of watermarks),
2) robustness (reliable watermark recovery under diverse conditions), and 3)
broad applicability (low latency in watermarking process). To address these
limitations, we propose a Hierarchical Watermark Learning (HiWL), a two-stage
optimization that enable a watermarking model to simultaneously achieve three
criteria. In the first stage, distribution alignment learning is designed to
establish a common latent space with two constraints: 1) visual consistency
between watermarked and non-watermarked images, and 2) information invariance
across watermark latent representations. In this way, multi-modal inputs
including watermark message (binary codes) and cover images (RGB pixels) can be
well represented, ensuring the invisibility of watermarks and robustness in
watermarking process thereby. The second stage employs generalized watermark
representation learning to establish a disentanglement policy for separating
watermarks from image content in RGB space. In particular, it strongly
penalizes substantial fluctuations in separated RGB watermarks corresponding to
identical messages. Consequently, HiWL effectively learns generalizable
latent-space watermark representations while maintaining broad applicability.
Extensive experiments demonstrate the effectiveness of proposed method. In
particular, it achieves 7.6\% higher accuracy in watermark extraction than
existing methods, while maintaining extremely low latency (100K images
processed in 8s).

</details>


### [27] [MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion](https://arxiv.org/abs/2508.08679)
*Tao Luo,Weihua Xu*

Main category: cs.CV

TL;DR: MMIF-AMIN是一种新颖的多模态医学图像融合方法，它使用可逆密集网络（IDN）和多尺度互补特征提取模块（MCFEM）来提取独特和互补的特征，并使用自适应损失函数进行训练。实验证明该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态医学图像融合（MMIF）旨在整合来自不同模态的图像，以产生全面的图像，通过精确描绘器官结构、组织纹理和代谢信息来增强医学诊断。同时捕获跨越多个模态的独特和互补信息是MMIF的一个关键研究挑战。

Method: 提出了一种新颖的图像融合方法MMIF-AMIN，该方法采用一种新的架构，可以有效地提取这些独特和互补的特征。具体来说，采用可逆密集网络（IDN）对单个模态进行无损特征提取。为了提取模态间的互补信息，设计了一个多尺度互补特征提取模块（MCFEM），其中包含混合注意力机制、不同大小的卷积层和Transformer。引入自适应损失函数来指导模型学习，解决了传统手动设计损失函数的局限性，并增强了数据挖掘的深度。

Result: MMIF-AMIN在定量和定性分析方面均优于九种最先进的MMIF方法。消融实验证实了所提出方法的每个组成部分的有效性。此外，将MMIF-AMIN扩展到其他图像融合任务也取得了可观的性能。

Conclusion: MMIF-AMIN在定量和定性分析方面均优于九种最先进的MMIF方法。消融实验证实了所提出方法的每个组成部分的有效性。此外，将MMIF-AMIN扩展到其他图像融合任务也取得了可观的性能。

Abstract: Multimodal medical image fusion (MMIF) aims to integrate images from
different modalities to produce a comprehensive image that enhances medical
diagnosis by accurately depicting organ structures, tissue textures, and
metabolic information. Capturing both the unique and complementary information
across multiple modalities simultaneously is a key research challenge in MMIF.
To address this challenge, this paper proposes a novel image fusion method,
MMIF-AMIN, which features a new architecture that can effectively extract these
unique and complementary features. Specifically, an Invertible Dense Network
(IDN) is employed for lossless feature extraction from individual modalities.
To extract complementary information between modalities, a Multi-scale
Complementary Feature Extraction Module (MCFEM) is designed, which incorporates
a hybrid attention mechanism, convolutional layers of varying sizes, and
Transformers. An adaptive loss function is introduced to guide model learning,
addressing the limitations of traditional manually-designed loss functions and
enhancing the depth of data mining. Extensive experiments demonstrate that
MMIF-AMIN outperforms nine state-of-the-art MMIF methods, delivering superior
results in both quantitative and qualitative analyses. Ablation experiments
confirm the effectiveness of each component of the proposed method.
Additionally, extending MMIF-AMIN to other image fusion tasks also achieves
promising performance.

</details>


### [28] [Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions](https://arxiv.org/abs/2508.08923)
*Miruna-Alexandra Gafencu,Reem Shaban,Yordanka Velikova,Mohammad Farid Azampour,Nassir Navab*

Main category: cs.CV

TL;DR: 通过机器人超声和AI驱动的形状补全，改善脊柱手术的可视化和精度。


<details>
  <summary>Details</summary>
Motivation: 超声成像在脊柱手术中应用日益广泛，但其在显示深层组织结构时存在阴影伪像的限制。传统方法（如CT到超声配准）虽然可以利用CT图像提供解剖信息，但存在配准复杂、脊柱曲度差异和需要近期CT扫描等局限性。现有的形状补全方法虽然可以重建超声数据中的脊柱结构，但通常是离线操作且可重复性有限。

Method: 本研究提出的新颖集成系统结合了机器人超声和实时形状补全技术。该机器人平台可自主获取腰椎的超声扫面，从超声数据中提取椎体表面，并利用基于深度学习的形状补全网络重建完整的解剖结构。

Result: 该框架提供了交互式的实时可视化，能够自主重复扫描，并能够导航至目标位置。通过在幻影模型上进行定量实验评估形状补全精度和多种脊柱扫描协议，以及在志愿者扫描中进行定性结果展示，验证了该方法的有效性。

Conclusion: 该系统通过结合机器人超声和实时形状补全，增强了脊柱可视化效果，有助于提高操作的一致性、可重复性，并加深对潜在解剖结构的理解。

Abstract: Ultrasound (US) imaging is increasingly used in spinal procedures due to its
real-time, radiation-free capabilities; however, its effectiveness is hindered
by shadowing artifacts that obscure deeper tissue structures. Traditional
approaches, such as CT-to-US registration, incorporate anatomical information
from preoperative CT scans to guide interventions, but they are limited by
complex registration requirements, differences in spine curvature, and the need
for recent CT imaging. Recent shape completion methods can offer an alternative
by reconstructing spinal structures in US data, while being pretrained on large
set of publicly available CT scans. However, these approaches are typically
offline and have limited reproducibility. In this work, we introduce a novel
integrated system that combines robotic ultrasound with real-time shape
completion to enhance spinal visualization. Our robotic platform autonomously
acquires US sweeps of the lumbar spine, extracts vertebral surfaces from
ultrasound, and reconstructs the complete anatomy using a deep learning-based
shape completion network. This framework provides interactive, real-time
visualization with the capability to autonomously repeat scans and can enable
navigation to target locations. This can contribute to better consistency,
reproducibility, and understanding of the underlying anatomy. We validate our
approach through quantitative experiments assessing shape completion accuracy
and evaluations of multiple spine acquisition protocols on a phantom setup.
Additionally, we present qualitative results of the visualization on a
volunteer scan.

</details>


### [29] [PADReg: Physics-Aware Deformable Registration Guided by Contact Force for Ultrasound Sequences](https://arxiv.org/abs/2508.08685)
*Yimeng Geng,Mingyang Zhao,Fan Xu,Guanglin Cao,Gaofeng Meng,Hongbin Liu*

Main category: cs.CV

TL;DR: PADReg是一个利用接触力来提高超声图像大形变配准精度的框架，在解剖对齐和物理合理性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 超声图像固有的低对比度、重噪声和模糊的组织边界严重阻碍了可靠的特征提取和对应匹配，导致现有方法在解剖对齐和物理可解释性方面存在不足，尤其是在大形变的情况下。

Method: 提出了一种名为PADReg的物理感知可变形配准框架，该框架利用机器人超声系统测量的同步接触力作为物理先验来约束配准。具体来说，首先利用接触力和超声图像的多模态信息构建像素级刚度图，然后将刚度图与力数据结合，通过受胡克定律启发的轻量级物理感知模块来估计稠密的形变场。

Result: PADReg框架的HD95为12.90，比现有最先进的方法提高了21.34%。

Conclusion: PADReg框架通过利用接触力作为物理先验来约束配准，实现了物理上合理的配准，并比以往仅依赖图像相似性的方法具有更好的解剖对齐效果。在体数据集上的实验表明，该框架的HD95为12.90，比现有最先进的方法提高了21.34%。

Abstract: Ultrasound deformable registration estimates spatial transformations between
pairs of deformed ultrasound images, which is crucial for capturing
biomechanical properties and enhancing diagnostic accuracy in diseases such as
thyroid nodules and breast cancer. However, ultrasound deformable registration
remains highly challenging, especially under large deformation. The inherently
low contrast, heavy noise and ambiguous tissue boundaries in ultrasound images
severely hinder reliable feature extraction and correspondence matching.
Existing methods often suffer from poor anatomical alignment and lack physical
interpretability. To address the problem, we propose PADReg, a physics-aware
deformable registration framework guided by contact force. PADReg leverages
synchronized contact force measured by robotic ultrasound systems as a physical
prior to constrain the registration. Specifically, instead of directly
predicting deformation fields, we first construct a pixel-wise stiffness map
utilizing the multi-modal information from contact force and ultrasound images.
The stiffness map is then combined with force data to estimate a dense
deformation field, through a lightweight physics-aware module inspired by
Hooke's law. This design enables PADReg to achieve physically plausible
registration with better anatomical alignment than previous methods relying
solely on image similarity. Experiments on in-vivo datasets demonstrate that it
attains a HD95 of 12.90, which is 21.34\% better than state-of-the-art methods.
The source code is available at https://github.com/evelynskip/PADReg.

</details>


### [30] [Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding](https://arxiv.org/abs/2508.09032)
*Maxim A. Patratskiy,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.CV

TL;DR: 提出了一种通过视觉提示整合空间和时间理解的方法，在SimplerEnv上取得了比SpatialVLA和TraceVLA更好的结果，并且所需数据量少。


<details>
  <summary>Details</summary>
Motivation: 为了整合空间和时间理解，并解决现有模型各自关注这些方面的问题。

Method: 提出了一种将关键点的视觉轨迹投影到深度图上的方法，以同时捕捉空间和时间信息。

Result: 在SimplerEnv的实验中，与SpatialVLA和TraceVLA相比，成功解决任务的平均数量分别提高了4%和19%。

Conclusion: 该方法能够同时捕捉空间和时间信息，并且在数据收集具有挑战性的现实世界应用中具有优势，因为它只需要最少量的训练数据。

Abstract: Vision-Language-Action models have demonstrated remarkable capabilities in
predicting agent movements within virtual environments and real-world scenarios
based on visual observations and textual instructions. Although recent research
has focused on enhancing spatial and temporal understanding independently, this
paper presents a novel approach that integrates both aspects through visual
prompting. We introduce a method that projects visual traces of key points from
observations onto depth maps, enabling models to capture both spatial and
temporal information simultaneously. The experiments in SimplerEnv show that
the mean number of tasks successfully solved increased for 4% compared to
SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this
enhancement can be achieved with minimal training data, making it particularly
valuable for real-world applications where data collection is challenging. The
project page is available at https://ampiromax.github.io/ST-VLA.

</details>


### [31] [ROD: RGB-Only Fast and Efficient Off-road Freespace Detection](https://arxiv.org/abs/2508.08697)
*Tong Sun,Hongliang Ye,Jilin Mei,Liang Chen,Fangzhou Zhao,Leiqiang Zong,Yu Hu*

Main category: cs.CV

TL;DR: 提出ROD，一种仅用RGB数据的越野自由空间检测方法，解决了多模态方法的实时性问题，并在ORFD和RELLIS-3D数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 以往的SOTA方法依赖RGB图像和LiDAR数据进行多模态融合，但LiDAR数据计算表面法线图会显著增加推理时间，不适用于需要高FPS的实时应用。因此，需要一种不依赖LiDAR且计算需求低的解决方案。

Method: 该方法利用预训练的Vision Transformer（ViT）提取RGB图像特征，并设计了一个轻量级的高效解码器，实现了仅使用RGB数据进行越野自由空间检测。

Result: ROD在ORFD和RELLIS-3D数据集上建立了新的SOTA，推理速度达到50 FPS，显著优于先前模型。

Conclusion: 该研究提出了一种名为ROD的新型仅RGB方法，用于越野自由空间检测，通过利用预训练的ViT和轻量级解码器，在ORFD和RELLIS-3D数据集上取得了新的SOTA，同时实现了50 FPS的推理速度，解决了多模态方法在实时应用中的计算需求问题。

Abstract: Off-road freespace detection is more challenging than on-road scenarios
because of the blurred boundaries of traversable areas. Previous
state-of-the-art (SOTA) methods employ multi-modal fusion of RGB images and
LiDAR data. However, due to the significant increase in inference time when
calculating surface normal maps from LiDAR data, multi-modal methods are not
suitable for real-time applications, particularly in real-world scenarios where
higher FPS is required compared to slow navigation. This paper presents a novel
RGB-only approach for off-road freespace detection, named ROD, eliminating the
reliance on LiDAR data and its computational demands. Specifically, we utilize
a pre-trained Vision Transformer (ViT) to extract rich features from RGB
images. Additionally, we design a lightweight yet efficient decoder, which
together improve both precision and inference speed. ROD establishes a new SOTA
on ORFD and RELLIS-3D datasets, as well as an inference speed of 50 FPS,
significantly outperforming prior models.

</details>


### [32] [Subjective and Objective Quality Assessment of Banding Artifacts on Compressed Videos](https://arxiv.org/abs/2508.08700)
*Qi Zheng,Li-Heng Chen,Chenlong He,Neil Berkbeck,Yilin Wang,Balu Adsumilli,Alan C. Bovik,Yibo Fan,Zhengzhong Tu*

Main category: cs.CV

TL;DR: A new dataset (LIVE-YT-Banding) and a faster, more accurate no-reference model (CBAND) for detecting and measuring video banding artifacts were introduced. CBAND improves quality assessment and can optimize debanding models.


<details>
  <summary>Details</summary>
Motivation: Banding artifacts are a serious issue affecting the perceptual quality of compressed videos, especially on smooth regions of high-definition content viewed on high-end displays. Existing datasets are limited to still images, failing to capture temporal banding dynamics, thus necessitating systematic investigation and resources for advanced video codecs.

Method: Introduced a new no-reference (NR) video quality evaluator called CBAND, which leverages the statistical properties of natural images learned by deep neural networks. Tested and compared various models for detecting banding occurrences and measuring their impact on perceived quality using the newly created LIVE-YT-Banding dataset.

Result: CBAND achieved significantly better perceptual banding prediction performance compared to previous state-of-the-art models and demonstrated a substantial improvement in speed. The effectiveness of CBAND was validated on the new LIVE-YT-Banding dataset.

Conclusion: CBAND, a novel no-reference video quality assessment model, significantly outperforms previous state-of-the-art models in perceptual banding prediction, is orders of magnitude faster, and can be used as a differentiable loss function for video debanding model optimization. The LIVE-YT-Banding dataset, code, and pre-trained model are publicly available.

Abstract: Although there have been notable advancements in video compression
technologies in recent years, banding artifacts remain a serious issue
affecting the quality of compressed videos, particularly on smooth regions of
high-definition videos. Noticeable banding artifacts can severely impact the
perceptual quality of videos viewed on a high-end HDTV or high-resolution
screen. Hence, there is a pressing need for a systematic investigation of the
banding video quality assessment problem for advanced video codecs. Given that
the existing publicly available datasets for studying banding artifacts are
limited to still picture data only, which cannot account for temporal banding
dynamics, we have created a first-of-a-kind open video dataset, dubbed
LIVE-YT-Banding, which consists of 160 videos generated by four different
compression parameters using the AV1 video codec. A total of 7,200 subjective
opinions are collected from a cohort of 45 human subjects. To demonstrate the
value of this new resources, we tested and compared a variety of models that
detect banding occurrences, and measure their impact on perceived quality.
Among these, we introduce an effective and efficient new no-reference (NR)
video quality evaluator which we call CBAND. CBAND leverages the properties of
the learned statistics of natural images expressed in the embeddings of deep
neural networks. Our experimental results show that the perceptual banding
prediction performance of CBAND significantly exceeds that of previous
state-of-the-art models, and is also orders of magnitude faster. Moreover,
CBAND can be employed as a differentiable loss function to optimize video
debanding models. The LIVE-YT-Banding database, code, and pre-trained model are
all publically available at https://github.com/uniqzheng/CBAND.

</details>


### [33] [SafeFix: Targeted Model Repair via Controlled Image Generation](https://arxiv.org/abs/2508.08701)
*Ouyang Xu,Baoming Zhang,Ruiyu Mao,Yunhui Guo*

Main category: cs.CV

TL;DR: 该研究提出了一种新的模型修复方法，通过生成和过滤合成数据来解决视觉识别中的系统性错误，从而提高模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在视觉识别中常因代表性不足的语义子群体而出现系统性错误，而现有调试框架难以有效修复这些故障。

Method: 提出一个基于可解释的失败归因流程的模型修复模块，使用条件文本到图像模型生成针对失败案例的语义保真图像，并利用大型视觉语言模型过滤生成的样本。

Result: 通过用包含罕见案例的增强合成数据集重新训练视觉模型，显著减少了与罕见案例相关的错误，同时提高了模型鲁棒性。

Conclusion: 通过使用条件文本到图像模型生成语义保真的目标图像来修复视觉识别模型中的系统性错误，并使用大型视觉语言模型过滤生成的样本以保持语义一致性，这种方法可以提高模型的鲁棒性而不引入新错误。

Abstract: Deep learning models for visual recognition often exhibit systematic errors
due to underrepresented semantic subpopulations. Although existing debugging
frameworks can pinpoint these failures by identifying key failure attributes,
repairing the model effectively remains difficult. Current solutions often rely
on manually designed prompts to generate synthetic training images -- an
approach prone to distribution shift and semantic errors. To overcome these
challenges, we introduce a model repair module that builds on an interpretable
failure attribution pipeline. Our approach uses a conditional text-to-image
model to generate semantically faithful and targeted images for failure cases.
To preserve the quality and relevance of the generated samples, we further
employ a large vision-language model (LVLM) to filter the outputs, enforcing
alignment with the original data distribution and maintaining semantic
consistency. By retraining vision models with this rare-case-augmented
synthetic dataset, we significantly reduce errors associated with rare cases.
Our experiments demonstrate that this targeted repair strategy improves model
robustness without introducing new bugs. Code is available at
https://github.com/oxu2/SafeFix

</details>


### [34] [Adaptive Confidence-Wise Loss for Improved Lens Structure Segmentation in AS-OCT](https://arxiv.org/abs/2508.08705)
*Zunjie Xiao,Xiao Wu,Tianhang Liu,Lingxi Hu,Yinling Zhang,Xiaoqing Zhang,Risa Higashita,Jiang Liu*

Main category: cs.CV

TL;DR: 通过引入自适应置信度加权（ACW）损失和边界预期校准误差（BECE）度量，改进了眼内镜结构分割的准确性和校准性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度分割网络在交叉熵（CE）损失下对所有像素同等加权，忽略了眼内镜结构子区域（如边界区域）的不均匀性以及边界区域像素级分割校准不佳的问题。临床上，专家在标注时会根据子区域比例、边界模糊性和结构形状等因素，对不同子区域赋予不同的置信度。

Method: 提出了一种自适应置信度加权（ACW）损失函数，将专家标注的置信度先验应用于眼内镜（IOL）结构的分割。ACW通过置信度阈值将每个目标区域划分为低置信度和高置信度两组，并应用区域加权损失重新加权每个置信度组。此外，还设计了一种自适应置信度阈值优化算法来动态调整置信度阈值。同时，为了更好地量化边界区域分割中的失准误差，提出了一种新的度量标准BECE。

Result: 在眼内镜结构AS-OCT数据集和其他多结构数据集上的大量实验表明，ACW在多种深度分割网络（如MedSAM）上显著优于其他分割损失方法。

Conclusion: 提出的ACW损失在U-Net等分割网络中显著优于传统的交叉熵损失，在眼内镜结构分割任务上，IoU提升6.13%，DSC提升4.33%，BECE降低4.79%。

Abstract: Precise lens structure segmentation is essential for the design of
intraocular lenses (IOLs) in cataract surgery. Existing deep segmentation
networks typically weight all pixels equally under cross-entropy (CE) loss,
overlooking the fact that sub-regions of lens structures are inhomogeneous
(e.g., some regions perform better than others) and that boundary regions often
suffer from poor segmentation calibration at the pixel level. Clinically,
experts annotate different sub-regions of lens structures with varying
confidence levels, considering factors such as sub-region proportions,
ambiguous boundaries, and lens structure shapes. Motivated by this observation,
we propose an Adaptive Confidence-Wise (ACW) loss to group each lens structure
sub-region into different confidence sub-regions via a confidence threshold
from the unique region aspect, aiming to exploit the potential of expert
annotation confidence prior. Specifically, ACW clusters each target region into
low-confidence and high-confidence groups and then applies a region-weighted
loss to reweigh each confidence group. Moreover, we design an adaptive
confidence threshold optimization algorithm to adjust the confidence threshold
of ACW dynamically. Additionally, to better quantify the miscalibration errors
in boundary region segmentation, we propose a new metric, termed Boundary
Expected Calibration Error (BECE). Extensive experiments on a clinical lens
structure AS-OCT dataset and other multi-structure datasets demonstrate that
our ACW significantly outperforms competitive segmentation loss methods across
different deep segmentation networks (e.g., MedSAM). Notably, our method
surpasses CE with 6.13% IoU gain, 4.33% DSC increase, and 4.79% BECE reduction
in lens structure segmentation under U-Net. The code of this paper is available
at https://github.com/XiaoLing12138/Adaptive-Confidence-Wise-Loss.

</details>


### [35] [Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation](https://arxiv.org/abs/2508.08765)
*Andrea Montibeller,Dasara Shullani,Daniele Baracchi,Alessandro Piva,Giulia Boato*

Main category: cs.CV

TL;DR: 该研究提出了一种模拟社交网络视频压缩的框架，解决了深度伪fake检测器在真实世界场景中的泛化能力问题，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于YouTube和Facebook等平台应用了专有的压缩技术，使得在受控条件下训练的深度伪fake检测器在真实场景中表现不佳，因为这些压缩会消除低级取证线索。而大规模复制这些转换过程又受到API限制和数据共享约束的阻碍。

Method: 提出一个能够模拟视频分享平台（如YouTube和Facebook）的视频分享流程的框架，通过估计一小部分上传视频中的压缩和调整大小参数，并利用这些参数在本地构建一个能够复现特定平台伪影的模拟器，从而在没有直接API访问的情况下，在大型数据集上进行复现。

Result: 实验结果表明，在社交网络上分享的FaceForensics++视频中，模拟数据在退化模式上与真实上传的视频高度相似。此外，在模拟视频上进行微调的检测器，其性能与在实际分享媒体上训练的检测器相当。

Conclusion: 该方法为深度伪造检测提供了一个可扩展且实用的解决方案，能够有效弥合实验室训练与真实世界部署之间的差距，尤其是在压缩视频内容这一未被充分探索的领域。

Abstract: The growing presence of AI-generated videos on social networks poses new
challenges for deepfake detection, as detectors trained under controlled
conditions often fail to generalize to real-world scenarios. A key factor
behind this gap is the aggressive, proprietary compression applied by platforms
like YouTube and Facebook, which launder low-level forensic cues. However,
replicating these transformations at scale is difficult due to API limitations
and data-sharing constraints. For these reasons, we propose a first framework
that emulates the video sharing pipelines of social networks by estimating
compression and resizing parameters from a small set of uploaded videos. These
parameters enable a local emulator capable of reproducing platform-specific
artifacts on large datasets without direct API access. Experiments on
FaceForensics++ videos shared via social networks demonstrate that our emulated
data closely matches the degradation patterns of real uploads. Furthermore,
detectors fine-tuned on emulated videos achieve comparable performance to those
trained on actual shared media. Our approach offers a scalable and practical
solution for bridging the gap between lab-based training and real-world
deployment of deepfake detectors, particularly in the underexplored domain of
compressed video content.

</details>


### [36] [SHREC 2025: Retrieval of Optimal Objects for Multi-modal Enhanced Language and Spatial Assistance (ROOMELSA)](https://arxiv.org/abs/2508.08781)
*Trong-Thuan Nguyen,Viet-Tham Huynh,Quang-Thuc Nguyen,Hoang-Phuc Nguyen,Long Le Bao,Thai Hoang Minh,Minh Nguyen Anh,Thang Nguyen Tien,Phat Nguyen Thuan,Huy Nguyen Phong,Bao Huynh Thai,Vinh-Tiep Nguyen,Duc-Vu Nguyen,Phu-Hoa Pham,Minh-Huy Le-Hoang,Nguyen-Khang Le,Minh-Chinh Nguyen,Minh-Quan Ho,Ngoc-Long Tran,Hien-Long Le-Hoang,Man-Khoi Tran,Anh-Duong Tran,Kim Nguyen,Quan Nguyen Hung,Dat Phan Thanh,Hoang Tran Van,Tien Huynh Viet,Nhan Nguyen Viet Thien,Dinh-Khoi Vo,Van-Loc Nguyen,Trung-Nghia Le,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: ROOMELSA is a new benchmark for 3D retrieval in complex scenes, evaluating natural language understanding for object recognition using panoramic images and 3D models. Current models struggle with subtle details, highlighting the need for integrated visual and language understanding.


<details>
  <summary>Details</summary>
Motivation: Real-world scenarios often require the recognition of an object in a cluttered scene based on a vague, free-form description, unlike simpler, controlled scenarios.

Method: ROOMELSA attends to a specific region within a panoramic room image and accurately retrieves the corresponding 3D model from a large database.

Result: While coarse object retrieval is largely solved, only one top-performing model consistently ranked the correct match first across nearly all test cases. A lightweight CLIP-based model also performed well but struggled with subtle variations.

Conclusion: ROOMELSA establishes a new benchmark for advancing robust, real-world 3D recognition systems by bridging the gap between scene-level grounding and fine-grained 3D retrieval.

Abstract: Recent 3D retrieval systems are typically designed for simple, controlled
scenarios, such as identifying an object from a cropped image or a brief
description. However, real-world scenarios are more complex, often requiring
the recognition of an object in a cluttered scene based on a vague, free-form
description. To this end, we present ROOMELSA, a new benchmark designed to
evaluate a system's ability to interpret natural language. Specifically,
ROOMELSA attends to a specific region within a panoramic room image and
accurately retrieves the corresponding 3D model from a large database. In
addition, ROOMELSA includes over 1,600 apartment scenes, nearly 5,200 rooms,
and more than 44,000 targeted queries. Empirically, while coarse object
retrieval is largely solved, only one top-performing model consistently ranked
the correct match first across nearly all test cases. Notably, a lightweight
CLIP-based model also performed well, although it struggled with subtle
variations in materials, part structures, and contextual cues, resulting in
occasional errors. These findings highlight the importance of tightly
integrating visual and language understanding. By bridging the gap between
scene-level grounding and fine-grained 3D retrieval, ROOMELSA establishes a new
benchmark for advancing robust, real-world 3D recognition systems.

</details>


### [37] [DiffPose-Animal: A Language-Conditioned Diffusion Framework for Animal Pose Estimation](https://arxiv.org/abs/2508.08783)
*Tianyu Xiong,Dayi Tan,Wei Tian*

Main category: cs.CV

TL;DR: DiffPose-Animal 是一种利用大型语言模型和扩散模型进行动物姿态估计的新框架，能有效处理多样化物种和不完整关键点等挑战。


<details>
  <summary>Details</summary>
Motivation: 动物姿态估计在生态监测、行为分析和智能牲畜管理方面日益重要，但与人类姿态估计相比，由于物种形态多样性、复杂身体结构和有限的标注数据，动物姿态估计更具挑战性。

Method: DiffPose-Animal 提出了一种新颖的基于扩散模型的自上而下动物姿态估计框架，将姿态估计重新构建为扩散模型的生成框架下的去噪过程。该方法利用大型语言模型（LLMs）提取与物种相关的全局解剖学先验和局部关键点语义，并通过交叉注意力机制融合到图像特征中，为去噪过程提供生物学约束。此外，还设计了一个基于扩散的关键点解码器来逐步优化姿态预测。

Result: 实验结果表明，DiffPose-Animal 在公开的动物姿态数据集上表现优越，尤其是在处理多样化物种、杂乱背景和不完整关键点等挑战性场景时，显示出强大的有效性和泛化能力。

Conclusion: DiffPose-Animal 在具有多样化物种、杂乱背景和不完整关键点的挑战性场景下，展现出优越的性能和泛化能力。

Abstract: Animal pose estimation is a fundamental task in computer vision, with growing
importance in ecological monitoring, behavioral analysis, and intelligent
livestock management. Compared to human pose estimation, animal pose estimation
is more challenging due to high interspecies morphological diversity, complex
body structures, and limited annotated data. In this work, we introduce
DiffPose-Animal, a novel diffusion-based framework for top-down animal pose
estimation. Unlike traditional heatmap regression methods, DiffPose-Animal
reformulates pose estimation as a denoising process under the generative
framework of diffusion models. To enhance semantic guidance during keypoint
generation, we leverage large language models (LLMs) to extract both global
anatomical priors and local keypoint-wise semantics based on species-specific
prompts. These textual priors are encoded and fused with image features via
cross-attention modules to provide biologically meaningful constraints
throughout the denoising process. Additionally, a diffusion-based keypoint
decoder is designed to progressively refine pose predictions, improving
robustness to occlusion and annotation sparsity. Extensive experiments on
public animal pose datasets demonstrate the effectiveness and generalization
capability of our method, especially under challenging scenarios with diverse
species, cluttered backgrounds, and incomplete keypoints.

</details>


### [38] [Region-Adaptive Video Sharpening via Rate-Perception Optimization](https://arxiv.org/abs/2508.08794)
*Yingxue Pang,Shijie Zhao,Mengxi Guo,Junlin Li,Li Zhang*

Main category: cs.CV

TL;DR: RPO-AdaSharp是一种创新的视频锐化模型，通过CTU分区掩码实现区域自适应，提升视频质量并节省比特。


<details>
  <summary>Details</summary>
Motivation: 传统的视频锐化方法忽略了纹理的变化，导致视频质量下降，并且会增加比特率，但现有技术缺乏在不同区域优化比特分配的策略。因此，需要一种能够适应区域纹理变化并实现比特节省的视频锐化方法。

Method: 提出了一种名为RPO-AdaSharp的端到端区域自适应视频锐化模型，该模型利用编码树单元（CTU）分区掩码作为先验信息，指导和约束比特的分配，以实现对纹理变化的自适应处理。

Result: 实验结果表明，RPO-AdaSharp模型在定性和定量上都有效，能够在提高视频感知质量的同时节省比特率。

Conclusion: 本研究提出的RPO-AdaSharp模型能够实现区域自适应视频锐化，在提升视频感知质量的同时实现比特节省。

Abstract: Sharpening is a widely adopted video enhancement technique. However, uniform
sharpening intensity ignores texture variations, degrading video quality.
Sharpening also increases bitrate, and there's a lack of techniques to
optimally allocate these additional bits across diverse regions. Thus, this
paper proposes RPO-AdaSharp, an end-to-end region-adaptive video sharpening
model for both perceptual enhancement and bitrate savings. We use the coding
tree unit (CTU) partition mask as prior information to guide and constrain the
allocation of increased bits. Experiments on benchmarks demonstrate the
effectiveness of the proposed model qualitatively and quantitatively.

</details>


### [39] [MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields](https://arxiv.org/abs/2508.08798)
*Yao Lu,Jiawei Li,Ming Jiang*

Main category: cs.CV

TL;DR: MonoPartNeRF通过双向变形模型、部件化姿态嵌入和注意力机制，解决了单目动态人体重建中的姿态变化和遮挡问题，实现了更平滑的过渡和更准确的重建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于部件的渲染方法在处理复杂的姿态变化时仍然存在挑战，容易在部件边界产生不自然的过渡，并且在单目设置下难以准确重建被遮挡的区域。

Method: 提出了一种名为MonoPartNeRF的新型框架，采用双向变形模型结合刚性和非刚性变换，实现观察空间到规范空间的可逆映射。通过将采样点投影到参数化表面-时间空间（u, v, t）来捕捉非刚性运动。引入了基于身体区域分解的部件化姿态嵌入机制，并结合关键帧姿态检索和插值，以及可学习的注意力机制来整合外观编码，以有效模拟动态纹理变化。

Result: 实验表明，MonoPartNeRF在ZJU-MoCap和MonoCap数据集上，尤其是在复杂姿态和遮挡条件下，相比现有方法取得了更好的性能，具体体现在关节对齐、纹理保真度和结构连续性方面。

Conclusion: MonoPartNeRF在复杂姿态和遮挡条件下显著优于先前方法，实现了卓越的关节对齐、纹理保真度和结构连续性。

Abstract: In recent years, Neural Radiance Fields (NeRF) have achieved remarkable
progress in dynamic human reconstruction and rendering. Part-based rendering
paradigms, guided by human segmentation, allow for flexible parameter
allocation based on structural complexity, thereby enhancing representational
efficiency. However, existing methods still struggle with complex pose
variations, often producing unnatural transitions at part boundaries and
failing to reconstruct occluded regions accurately in monocular settings. We
propose MonoPartNeRF, a novel framework for monocular dynamic human rendering
that ensures smooth transitions and robust occlusion recovery. First, we build
a bidirectional deformation model that combines rigid and non-rigid
transformations to establish a continuous, reversible mapping between
observation and canonical spaces. Sampling points are projected into a
parameterized surface-time space (u, v, t) to better capture non-rigid motion.
A consistency loss further suppresses deformation-induced artifacts and
discontinuities. We introduce a part-based pose embedding mechanism that
decomposes global pose vectors into local joint embeddings based on body
regions. This is combined with keyframe pose retrieval and interpolation, along
three orthogonal directions, to guide pose-aware feature sampling. A learnable
appearance code is integrated via attention to model dynamic texture changes
effectively. Experiments on the ZJU-MoCap and MonoCap datasets demonstrate that
our method significantly outperforms prior approaches under complex pose and
occlusion conditions, achieving superior joint alignment, texture fidelity, and
structural continuity.

</details>


### [40] [Identity-Preserving Aging and De-Aging of Faces in the StyleGAN Latent Space](https://arxiv.org/abs/2508.08808)
*Luis S. Luevano,Pavel Korshunov,Sebastien Marcel*

Main category: cs.CV

TL;DR: 本研究提出了一种新的人脸年龄/反年龄合成方法，通过编辑StyleGAN2潜在空间，利用支持向量建模和特征选择来保持身份信息，并提供参数估计公式。生成的合成数据集可用于相关系统测试。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸年龄/反年龄合成方法大多依赖条件生成对抗网络（GAN）、扩散模型或视觉语言模型，这些方法需要复杂的训练、大量数据，并且难以生成一致的结果。此外，在这些方法中，身份保持很少被考虑或仅在一个面部识别系统上进行评估，缺乏对生成的人脸是否保持身份的控制和保证。因此，本研究旨在提出一种新的方法，能够在保持身份信息的同时，对人脸进行年龄/反年龄合成。

Method: 本研究提出了一种通过编辑StyleGAN2的潜在空间来合成不同年龄人脸的方法。具体来说，该方法利用支持向量建模和特征选择来确定年龄变化的方向，并通过两个最先进的人脸识别系统来寻找StyleGAN2潜在空间中保持身份信息的子空间。在此基础上，研究人员提出了一种简单的公式来估计保证身份保持的年龄/反年龄参数。

Result: 通过使用支持向量建模和特征选择，本研究在StyleGAN2的潜在空间中找到了一个保持身份信息的子空间，能够改变人脸的表观年龄，同时保持身份。此外，还提出了一种用于估计确保身份保持的年龄/反年龄参数的实用公式。该方法生成的合成人脸数据集可用于跨年龄人脸识别、年龄验证系统或合成图像检测系统的基准测试。

Conclusion: 本研究提出了一种通过编辑StyleGAN2的潜在空间来合成不同年龄人脸的方法，利用支持向量建模和特征选择来确定年龄变化方向，并通过人脸识别系统验证了身份保持的子空间。此外，还提出了一种用于估计确保身份保持的年龄/反年龄参数的实用公式。该方法生成的合成人脸数据集可用于跨年龄人脸识别、年龄验证系统或合成图像检测系统的基准测试。

Abstract: Face aging or de-aging with generative AI has gained significant attention
for its applications in such fields like forensics, security, and media.
However, most state of the art methods rely on conditional Generative
Adversarial Networks (GANs), Diffusion-based models, or Visual Language Models
(VLMs) to age or de-age faces based on predefined age categories and
conditioning via loss functions, fine-tuning, or text prompts. The reliance on
such conditioning leads to complex training requirements, increased data needs,
and challenges in generating consistent results. Additionally, identity
preservation is rarely taken into accountor evaluated on a single face
recognition system without any control or guarantees on whether identity would
be preserved in a generated aged/de-aged face. In this paper, we propose to
synthesize aged and de-aged faces via editing latent space of StyleGAN2 using a
simple support vector modeling of aging/de-aging direction and several feature
selection approaches. By using two state-of-the-art face recognition systems,
we empirically find the identity preserving subspace within the StyleGAN2
latent space, so that an apparent age of a given face can changed while
preserving the identity. We then propose a simple yet practical formula for
estimating the limits on aging/de-aging parameters that ensures identity
preservation for a given input face. Using our method and estimated parameters
we have generated a public dataset of synthetic faces at different ages that
can be used for benchmarking cross-age face recognition, age assurance systems,
or systems for detection of synthetic images. Our code and dataset are
available at the project page https://www.idiap.ch/paper/agesynth/

</details>


### [41] [Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment](https://arxiv.org/abs/2508.08811)
*Shi-Chen Zhang,Yunheng Li,Yu-Huan Wu,Qibin Hou,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 为了解决现有语义分割方法中存在的类别表示与图像特征不匹配的问题，提出了一种新的耦合双分支偏移学习范式，该范式能够动态地调整类别表示和空间图像特征，从而在资源受限的设备上实现更高效的部署。


<details>
  <summary>Details</summary>
Motivation: 现有的实时语义分割方法虽然轻量化，但存在类别表示与图像特征不匹配的问题，这是由逐像素分类范式引起的。该范式对效率场景提出了一个苛刻的假设：同一类别的图像像素特征在不同图像中不应发生变化。

Method: 提出了一种耦合的双分支偏移学习范式，通过显式学习特征和类别偏移来动态地调整类别表示和空间图像特征。

Result: 所提出的偏移学习范式在ADE20K、Cityscapes、COCO-Stuff-164K和Pascal Context等四个数据集上进行了广泛的实验，结果显示在参数增加极少的情况下，性能持续提升。例如，在ADE20K数据集上，与SegFormer-B0、SegNeXt-T和Mask2Former-Tiny相比，该范式分别提升了2.7%、1.9%和2.6%的mIoU，而额外参数仅增加了0.1-0.2M。

Conclusion: 所提出的偏移学习范式可以集成到现有方法中，而无需进行额外的架构更改，并在各种数据集上实现了持续的性能提升，同时仅需增加极少量的参数。

Abstract: Semantic segmentation is fundamental to vision systems requiring pixel-level
scene understanding, yet deploying it on resource-constrained devices demands
efficient architectures. Although existing methods achieve real-time inference
through lightweight designs, we reveal their inherent limitation: misalignment
between class representations and image features caused by a per-pixel
classification paradigm. With experimental analysis, we find that this paradigm
results in a highly challenging assumption for efficient scenarios: Image pixel
features should not vary for the same category in different images. To address
this dilemma, we propose a coupled dual-branch offset learning paradigm that
explicitly learns feature and class offsets to dynamically refine both class
representations and spatial image features. Based on the proposed paradigm, we
construct an efficient semantic segmentation network, OffSeg. Notably, the
offset learning paradigm can be adopted to existing methods with no additional
architectural changes. Extensive experiments on four datasets, including
ADE20K, Cityscapes, COCO-Stuff-164K, and Pascal Context, demonstrate consistent
improvements with negligible parameters. For instance, on the ADE20K dataset,
our proposed offset learning paradigm improves SegFormer-B0, SegNeXt-T, and
Mask2Former-Tiny by 2.7%, 1.9%, and 2.6% mIoU, respectively, with only 0.1-0.2M
additional parameters required.

</details>


### [42] [TARA: Token-Aware LoRA for Composable Personalization in Diffusion Models](https://arxiv.org/abs/2508.08812)
*Yuqi Peng,Lingtao Zheng,Yufeng Yang,Yi Huang,Mingfu Yan,Jianzhuang Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: TARA 是一种用于文本到图像生成的新方法，通过解决 LoRA 模块之间的 token 干扰和空间不对齐问题，实现了高效的多概念组合。


<details>
  <summary>Details</summary>
Motivation: 当前基于 LoRA 的多概念生成方法存在身份缺失和视觉特征泄漏的问题，主要是由于 token 之间的干扰以及稀有 token 的注意图与其对应概念区域之间的空间不对齐。

Method: TARA 通过引入 token 掩码来约束每个模块专注于其关联的稀有 token，以避免干扰；并通过一个训练目标来鼓励稀有 token 的空间注意力与其概念区域对齐。

Result: 实验结果表明，TARA 实现了高效的多概念推理，并通过避免 LoRA 模块之间的相互干扰，有效保留了每个概念的视觉身份。

Conclusion: TARA 是一种无需训练即可组合多个概念的方法，可直接在推理时注入多个独立训练的 TARA 模块，有效避免了 LoRA 模块之间的相互干扰，从而实现了高效的多概念推理，并有效保留了每个概念的视觉身份。

Abstract: Personalized text-to-image generation aims to synthesize novel images of a
specific subject or style using only a few reference images. Recent methods
based on Low-Rank Adaptation (LoRA) enable efficient single-concept
customization by injecting lightweight, concept-specific adapters into
pre-trained diffusion models. However, combining multiple LoRA modules for
multi-concept generation often leads to identity missing and visual feature
leakage. In this work, we identify two key issues behind these failures: (1)
token-wise interference among different LoRA modules, and (2) spatial
misalignment between the attention map of a rare token and its corresponding
concept-specific region. To address these issues, we propose Token-Aware LoRA
(TARA), which introduces a token mask to explicitly constrain each module to
focus on its associated rare token to avoid interference, and a training
objective that encourages the spatial attention of a rare token to align with
its concept region. Our method enables training-free multi-concept composition
by directly injecting multiple independently trained TARA modules at inference
time. Experimental results demonstrate that TARA enables efficient
multi-concept inference and effectively preserving the visual identity of each
concept by avoiding mutual interference between LoRA modules. The code and
models are available at https://github.com/YuqiPeng77/TARA.

</details>


### [43] [3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs](https://arxiv.org/abs/2508.08821)
*Noor Ahmed,Cameron Braunstein,Steffen Eger,Eddy Ilg*

Main category: cs.CV

TL;DR: 3DFroMLLM框架可以通过多模态大型语言模型生成3D对象原型，无需额外数据，并能提升图像分类和部件分割任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大型语言模型在空间推理方面能力有限。本研究旨在通过3DFroMLLM框架解决这一问题，使其能够直接从多模态大型语言模型生成3D对象原型。

Method: 该框架包含一个由设计师、编码员和视觉检查员组成的迭代优化循环，直接从多模态大型语言模型生成3D对象原型（包括几何和部件标签）。

Result: 1. 使用该框架生成的渲染图像进行图像分类预训练，效果优于先前方法15%。
2. 使用渲染的、带部件标签的原型来微调CLIP，实现了55%的准确率提升，用于部件分割，而无需任何额外的人工标注数据。

Conclusion: 3DFroMLLM框架可以直接从多模态大型语言模型生成3D对象原型（包括几何和部件标签），并且不需要额外的训练数据或详细的用户指令。该框架通过设计师、编码员和视觉检查员的迭代优化循环实现。此外，通过使用该框架生成的渲染图像进行图像分类预训练，其效果优于先前方法15%。在实际应用中，使用渲染的、带部件标签的原型来微调CLIP，可以实现55%的准确率提升，用于部件分割，而无需任何额外的人工标注数据。

Abstract: Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong
capabilities in learning joint representations from text and images. However,
their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel
framework that enables the generation of 3D object prototypes directly from
MLLMs, including geometry and part labels. Our pipeline is agentic, comprising
a designer, coder, and visual inspector operating in a refinement loop.
Notably, our approach requires no additional training data or detailed user
instructions. Building on prior work in 2D generation, we demonstrate that
rendered images produced by our framework can be effectively used for image
classification pretraining tasks and outperforms previous methods by 15%. As a
compelling real-world use case, we show that the generated prototypes can be
leveraged to improve fine-grained vision-language models by using the rendered,
part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a
55% accuracy improvement without relying on any additional human-labeled data.

</details>


### [44] [A Parametric Bi-Directional Curvature-Based Framework for Image Artifact Classification and Quantification](https://arxiv.org/abs/2508.08824)
*Diego Frias*

Main category: cs.CV

TL;DR: 该论文提出了一种基于方向图像曲率分析的新型无参考图像质量评估（NR-IQA）框架。该框架通过计算各向异性纹理丰富度（ATR）来量化图像质量。该系统能够准确地对图像失真类型（模糊或噪声）进行分类，并量化图像质量，在预测人类评分方面表现出高精度。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于无参考图像质量评估（NR-IQA）的新颖框架。

Method: 该框架基于方向图像曲率分析，定义了一种各向异性纹理丰富度（ATR）的度量，该度量在像素级别使用两个可调阈值计算，以量化正交纹理抑制。系统利用ATR对各种失真的差异响应，首先使用两个特定ATR配置的签名对主要失真类型（模糊与噪声）进行分类，准确率超过97%；其次，在分类后，采用专门的回归模型，将相关的ATR分数映射到质量等级以量化退化。

Result: 在LIVE数据集上，ATR分数在针对高斯模糊时达到约-0.93的斯皮尔曼相关性，在针对白噪声时达到约-0.95的斯皮尔曼相关性。在组合数据集上，整个系统以0.892的决定系数（R2）和5.17 DMOS点的均方根误差（RMSE）预测人类分数，该误差仅占数据集总质量范围的7.4%。

Conclusion: 该框架是一个强大的、双功能的工具，用于图像退化的分类和随后的量化。

Abstract: This work presents a novel framework for No-Reference Image Quality
Assessment (NR-IQA) founded on the analysis of directional image curvature.
Within this framework, we define a measure of Anisotropic Texture Richness
(ATR), which is computed at the pixel level using two tunable thresholds -- one
permissive and one restrictive -- that quantify orthogonal texture suppression.
When its parameters are optimized for a specific artifact, the resulting ATR
score serves as a high-performance quality metric, achieving Spearman
correlations with human perception of approximately -0.93 for Gaussian blur and
-0.95 for white noise on the LIVE dataset. The primary contribution is a
two-stage system that leverages the differential response of ATR to various
distortions. First, the system utilizes the signature from two specialist ATR
configurations to classify the primary artifact type (blur vs. noise) with over
97% accuracy. Second, following classification, it employs a dedicated
regression model mapping the relevant ATR score to a quality rating to quantify
the degradation. On a combined dataset, the complete system predicts human
scores with a coefficient of determination (R2) of 0.892 and a Root Mean Square
Error (RMSE) of 5.17 DMOS points. This error corresponds to just 7.4% of the
dataset's total quality range, demonstrating high predictive accuracy. This
establishes our framework as a robust, dual-purpose tool for the classification
and subsequent quantification of image degradation.

</details>


### [45] [Adaptive High-Frequency Preprocessing for Video Coding](https://arxiv.org/abs/2508.08849)
*Yingxue Pang,Shijie Zhao,Junlin Li,Li Zhang*

Main category: cs.CV

TL;DR: 通过基于深度学习的框架，利用FFPN预测最优高频预处理策略，从而在视频编码中实现视觉质量提升和比特率节省。


<details>
  <summary>Details</summary>
Motivation: 高频分量对视频清晰度和真实感至关重要，但也会显著增加编码比特率，导致带宽和存储成本上升。因此，需要一种方法来优化高频分量处理，以在保证视觉质量的同时节省比特率。

Method: 提出了一种端到端的学习框架，利用频域注意力特征金字塔预测网络（FFPN）来预测最优高频预处理策略，并指导后续的滤波操作。FFPN的训练通过比较不同预处理类型和强度下的率失真（RD）性能进行伪标签，并使用最新的质量评估指标来衡量失真。

Result: 通过在多个数据集上进行评估，证明了该框架能够实现视觉上的显著提升和比特率的节省。

Conclusion: 该框架通过FFPN预测最优高频预处理策略，平衡比特率与压缩后质量，并在多个数据集上进行了评估，证明了其在提升视觉效果和节省比特率方面的能力。

Abstract: High-frequency components are crucial for maintaining video clarity and
realism, but they also significantly impact coding bitrate, resulting in
increased bandwidth and storage costs. This paper presents an end-to-end
learning-based framework for adaptive high-frequency preprocessing to enhance
subjective quality and save bitrate in video coding. The framework employs the
Frequency-attentive Feature pyramid Prediction Network (FFPN) to predict the
optimal high-frequency preprocessing strategy, guiding subsequent filtering
operators to achieve the optimal tradeoff between bitrate and quality after
compression. For training FFPN, we pseudo-label each training video with the
optimal strategy, determined by comparing the rate-distortion (RD) performance
across different preprocessing types and strengths. Distortion is measured
using the latest quality assessment metric. Comprehensive evaluations on
multiple datasets demonstrate the visually appealing enhancement capabilities
and bitrate savings achieved by our framework.

</details>


### [46] [GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing Environments](https://arxiv.org/abs/2508.08867)
*Lin Zeng,Boming Zhao,Jiarui Hu,Xujie Shen,Ziqiang Dang,Hujun Bao,Zhaopeng Cui*

Main category: cs.CV

TL;DR: GaussianUpdate利用3D高斯表示和持续学习，通过多阶段更新和可见性感知生成式回放，有效处理场景变化并支持实时渲染，无需存储旧数据。


<details>
  <summary>Details</summary>
Motivation: 现有神经模型在处理新视角合成方面取得了显著进展，但如何适应场景变化仍然是一个开放性问题。现有的方法要么需要大量的人工干预（如模型重新训练），要么无法捕捉随时间变化的详细场景类型。

Method: 本文提出了一种名为GaussianUpdate的新方法，该方法结合了3D高斯表示（3D Gaussian representation）和持续学习（continual learning）技术。具体来说，它采用了一种新颖的多阶段更新策略来明确地建模不同类型的场景变化，并通过一种可见性感知（visibility-aware）的持续学习方法，结合生成式回放（generative replay）技术，实现了在无需存储图像的情况下进行自我感知更新。

Result: 实验结果表明，GaussianUpdate方法在基准数据集上实现了优于现有方法的性能，能够进行实时渲染，并能可视化不同时间点的场景变化。

Conclusion: 该研究提出了一种名为GaussianUpdate的新方法，结合了3D高斯表示和持续学习，能够有效更新高斯辐射场并保留历史场景信息，同时通过多阶段更新策略和可见性感知持续学习（包含生成式回放）来处理不同类型的场景变化，实现了无需存储图像即可进行自我感知更新，并在基准数据集上取得了优于现有方法且支持实时渲染的性能。

Abstract: Novel view synthesis with neural models has advanced rapidly in recent years,
yet adapting these models to scene changes remains an open problem. Existing
methods are either labor-intensive, requiring extensive model retraining, or
fail to capture detailed types of changes over time. In this paper, we present
GaussianUpdate, a novel approach that combines 3D Gaussian representation with
continual learning to address these challenges. Our method effectively updates
the Gaussian radiance fields with current data while preserving information
from past scenes. Unlike existing methods, GaussianUpdate explicitly models
different types of changes through a novel multi-stage update strategy.
Additionally, we introduce a visibility-aware continual learning approach with
generative replay, enabling self-aware updating without the need to store
images. The experiments on the benchmark dataset demonstrate our method
achieves superior and real-time rendering with the capability of visualizing
changes over different times

</details>


### [47] [Preview WB-DH: Towards Whole Body Digital Human Bench for the Generation of Whole-body Talking Avatar Videos](https://arxiv.org/abs/2508.08891)
*Chaoyi Wang,Yifan Yang,Jun Pei,Lijie Xia,Jianpo Liu,Xiaobing Yuan,Xinhan Di*

Main category: cs.CV

TL;DR: 本研究提出了WB-DH数据集，旨在解决从单张肖像生成全身可驱动虚拟人模型的评估难题。该数据集包含多模态标注和评估框架，并已开源。


<details>
  <summary>Details</summary>
Motivation: 目前，从单张肖像照片创建完全可驱动的全身虚拟人模型面临诸多挑战，主要源于捕捉细微表情、肢体动作和动态背景的局限性。现有的评估数据集和指标在应对这些复杂性方面存在不足。

Method: 为了解决上述问题，我们提出了一个名为WB-DH（Whole-Body Benchmark Dataset）的开源多模态数据集。该数据集包含详细的多模态标注信息，能够为模型的生成提供精细的指导。此外，我们还设计了一个灵活的评估框架，用于全面评估模型的性能。

Result: WB-DH数据集的特点包括：1. 提供详细的多模态标注，以实现细粒度的指导；2. 包含一个多功能的评估框架；3. 数据集和相关工具均已开源，并可在https://github.com/deepreasonings/WholeBodyBenchmark获取。

Conclusion: 创建包含精细表情、肢体动作和动态背景的全身可驱动虚拟人模型，是目前虚拟人生成领域面临的挑战。现有的数据集和评估指标难以全面评估模型的性能。

Abstract: Creating realistic, fully animatable whole-body avatars from a single
portrait is challenging due to limitations in capturing subtle expressions,
body movements, and dynamic backgrounds. Current evaluation datasets and
metrics fall short in addressing these complexities. To bridge this gap, we
introduce the Whole-Body Benchmark Dataset (WB-DH), an open-source, multi-modal
benchmark designed for evaluating whole-body animatable avatar generation. Key
features include: (1) detailed multi-modal annotations for fine-grained
guidance, (2) a versatile evaluation framework, and (3) public access to the
dataset and tools at https://github.com/deepreasonings/WholeBodyBenchmark.

</details>


### [48] [A Robust Epipolar-Domain Regularization Algorithm for Light Field Depth Estimation](https://arxiv.org/abs/2508.08900)
*Noor Islam S. Mohammad*

Main category: cs.CV

TL;DR: 提出了一种新颖轻量级的深度估计方法，通过结合光场视差和随机游走细化，无需大量训练即可提高深度图的一致性，计算成本低，准确性具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 为了应对现有方法计算成本高和在嘈杂的真实世界环境中表现不佳的挑战，提出了一种新的轻量级深度估计方法。

Method: 提出了一种集成了光场视差信息和定向随机游走细化算法的新颖轻量级深度估计流程。

Result: 与最先进的深度学习模型相比，该算法在保持低计算复杂度和竞争力的准确性方面表现一致，尽管在无控制条件下的性能略有下降。

Conclusion: 该方法为光场成像中的鲁棒深度估计提供了一种轻量级且计算效率高的方法，并为将概率图模型与深度传感框架相结合开辟了新的方向。

Abstract: Robust depth estimation in light field imaging remains a critical challenge
for pattern recognition applications such as augmented reality, biomedical
imaging, and scene reconstruction. While existing approaches often rely heavily
on deep convolutional neural networks, they tend to incur high computational
costs and struggle in noisy real-world environments. This paper proposes a
novel lightweight depth estimation pipeline that integrates light field-based
disparity information with a directed random walk refinement algorithm. Unlike
traditional CNN-based methods, our approach enhances depth map consistency
without requiring extensive training or large-scale datasets. The proposed
method was evaluated on the 4D Light Field Benchmark dataset and a diverse set
of real-world images. Experimental results indicate that while performance
slightly declines under uncontrolled conditions, the algorithm consistently
maintains low computational complexity and competitive accuracy compared to
state-of-the-art deep learning models. These findings highlight the potential
of our method as a robust and efficient alternative for depth estimation and
segmentation in light field imaging. The work provides insights into practical
algorithm design for light field-based pattern recognition and opens new
directions for integrating probabilistic graph models with depth sensing
frameworks.

</details>


### [49] [Masked Clustering Prediction for Unsupervised Point Cloud Pre-training](https://arxiv.org/abs/2508.08910)
*Bin Ren,Xiaoshui Huang,Mengyuan Liu,Hong Liu,Fabio Poiesi,Nicu Sebe,Guofeng Mei*

Main category: cs.CV

TL;DR: MaskClu是一种用于3D点云的ViT无监督预训练方法，通过掩码点建模、聚类学习和对比学习来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的ViT在3D点云理解方面，虽然广泛应用了掩码自编码预训练，但从点云中学习密集和信息丰富的语义特征的挑战仍然探索不足。

Method: MaskClu是一种新颖的无监督预训练方法，通过重构掩码点云的聚类分配和聚类中心，以及对比学习机制来增强实例级特征学习。

Result: MaskClu在部件分割、语义分割、目标检测和分类等多个3D任务上取得了新的、有竞争力的结果。

Conclusion: MaskClu通过结合掩码点建模和基于聚类的学习，并引入全局对比学习机制，能够使ViT从3D点云中学习到更丰富、更具语义意义的表示，并在多个3D任务上取得了具有竞争力的结果。

Abstract: Vision transformers (ViTs) have recently been widely applied to 3D point
cloud understanding, with masked autoencoding as the predominant pre-training
paradigm. However, the challenge of learning dense and informative semantic
features from point clouds via standard ViTs remains underexplored. We propose
MaskClu, a novel unsupervised pre-training method for ViTs on 3D point clouds
that integrates masked point modeling with clustering-based learning. MaskClu
is designed to reconstruct both cluster assignments and cluster centers from
masked point clouds, thus encouraging the model to capture dense semantic
information. Additionally, we introduce a global contrastive learning mechanism
that enhances instance-level feature learning by contrasting different masked
views of the same point cloud. By jointly optimizing these complementary
objectives, i.e., dense semantic reconstruction, and instance-level contrastive
learning. MaskClu enables ViTs to learn richer and more semantically meaningful
representations from 3D point clouds. We validate the effectiveness of our
method via multiple 3D tasks, including part segmentation, semantic
segmentation, object detection, and classification, where MaskClu sets new
competitive results. The code and models will be released
at:https://github.com/Amazingren/maskclu.

</details>


### [50] [Automatic and standardized surgical reporting for central nervous system tumors](https://arxiv.org/abs/2508.08916)
*David Bouget,Mathilde Gajda Faanes,Asgeir Store Jakola,Frederik Barkhof,Hilko Ardon,Lorenzo Bello,Mitchel S. Berger,Shawn L. Hervey-Jumper,Julia Furtner,Albert J. S. Idema,Barbara Kiesel,Georg Widhalm,Rishi Nandoe Tewarie,Emmanuel Mandonnet,Pierre A. Robe,Michiel Wagemakers,Timothy R. Smith,Philip C. De Witt Hamer,Ole solheim,Ingerid Reinertsen*

Main category: cs.CV

TL;DR: 本研究提出了一个用于中枢神经系统肿瘤术后报告的自动化流程，集成了分割和分类模型，提高了术后评估的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管在术前自动分割和报告生成方面取得了进展，但术后影像分析的研究仍然有限。本研究旨在解决这一问题，为中枢神经系统肿瘤提供标准化的术后报告。

Method: 该研究利用Attention U-Net架构训练了用于肿瘤核心、术后增强残余肿瘤和切除腔分割的模型，并使用DenseNet架构探索了MR序列分类和肿瘤类型识别。模型在包含2000至7000名患者的多中心数据集上进行了5倍交叉验证训练，并根据RANO 2.0指南进行了评估。

Result: 分割模型的平均Dice分数分别为：肿瘤核心87%，非增强肿瘤核心66%，增强残余肿瘤70%，切除腔77%。分类模型在MR序列分类中达到了99.5%的平衡准确率，在肿瘤类型分类中达到了80%的准确率。

Conclusion: 该研究提出了一个用于中枢神经系统肿瘤标准化术后报告的综合流程，集成了自动分割、MR序列分类和肿瘤类型识别，并符合RANO 2.0指南。所提出的模型和方法已集成到开源软件Raidionics中，为术后评估和临床决策提供了支持。

Abstract: Magnetic resonance (MR) imaging is essential for evaluating central nervous
system (CNS) tumors, guiding surgical planning, treatment decisions, and
assessing postoperative outcomes and complication risks. While recent work has
advanced automated tumor segmentation and report generation, most efforts have
focused on preoperative data, with limited attention to postoperative imaging
analysis. This study introduces a comprehensive pipeline for standardized
postsurtical reporting in CNS tumors. Using the Attention U-Net architecture,
segmentation models were trained for the preoperative (non-enhancing) tumor
core, postoperative contrast-enhancing residual tumor, and resection cavity.
Additionally, MR sequence classification and tumor type identification for
contrast-enhancing lesions were explored using the DenseNet architecture. The
models were integrated into a reporting pipeline, following the RANO 2.0
guidelines. Training was conducted on multicentric datasets comprising 2000 to
7000 patients, using a 5-fold cross-validation. Evaluation included patient-,
voxel-, and object-wise metrics, with benchmarking against the latest BraTS
challenge results. The segmentation models achieved average voxel-wise Dice
scores of 87%, 66%, 70%, and 77% for the tumor core, non-enhancing tumor core,
contrast-enhancing residual tumor, and resection cavity, respectively.
Classification models reached 99.5% balanced accuracy in MR sequence
classification and 80% in tumor type classification. The pipeline presented in
this study enables robust, automated segmentation, MR sequence classification,
and standardized report generation aligned with RANO 2.0 guidelines, enhancing
postoperative evaluation and clinical decision-making. The proposed models and
methods were integrated into Raidionics, open-source software platform for CNS
tumor analysis, now including a dedicated module for postsurgical analysis.

</details>


### [51] [A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition](https://arxiv.org/abs/2508.08917)
*Jintao Cheng,Jiehao Luo,Xieyuanli Chen,Jin Wu,Rui Fan,Xiaoyu Tang,Wei Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的点云定位方法，使用跨视图网络和基于SPD矩阵的马氏距离度量，以更好地处理复杂环境中的非线性数据分布和类内方差，实验证明其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于欧氏距离度量的点云定位方法忽略了特征空间的内在结构和类内方差，这种以欧氏距离为中心的方法限制了模型捕捉非线性数据分布的能力，导致在复杂环境和时间变化场景下的性能不佳。

Method: 提出了一种新颖的跨视图网络，采用了创新的融合范式，并引入了伪全局信息引导机制来协调多模态分支在一个统一的语义空间中进行特征学习。同时，提出了一种流形自适应和成对方差-局部性学习度量，该度量构建了一个对称正定（SPD）矩阵来计算马氏距离，取代了传统的欧氏距离度量。

Result: 通过将流形自适应和成对方差-局部性学习度量（基于SPD矩阵计算马氏距离）与跨视图网络和伪全局信息引导机制相结合，该模型能够准确地表征内在数据分布并捕捉特征空间中复杂的类间依赖性。

Conclusion: 实验结果表明，所提出的算法具有竞争力，尤其在复杂环境条件下表现出色。

Abstract: LiDAR-based Place Recognition (LPR) remains a critical task in Embodied
Artificial Intelligence (AI) and Autonomous Driving, primarily addressing
localization challenges in GPS-denied environments and supporting loop closure
detection. Existing approaches reduce place recognition to a Euclidean
distance-based metric learning task, neglecting the feature space's intrinsic
structures and intra-class variances. Such Euclidean-centric formulation
inherently limits the model's capacity to capture nonlinear data distributions,
leading to suboptimal performance in complex environments and temporal-varying
scenarios. To address these challenges, we propose a novel cross-view network
based on an innovative fusion paradigm. Our framework introduces a
pseudo-global information guidance mechanism that coordinates multi-modal
branches to perform feature learning within a unified semantic space.
Concurrently, we propose a Manifold Adaptation and Pairwise Variance-Locality
Learning Metric that constructs a Symmetric Positive Definite (SPD) matrix to
compute Mahalanobis distance, superseding traditional Euclidean distance
metrics. This geometric formulation enables the model to accurately
characterize intrinsic data distributions and capture complex inter-class
dependencies within the feature space. Experimental results demonstrate that
the proposed algorithm achieves competitive performance, particularly excelling
in complex environmental conditions.

</details>


### [52] [Accelerated Volumetric Compression without Hierarchies: A Fourier Feature Based Implicit Neural Representation Approach](https://arxiv.org/abs/2508.08937)
*Leona Žůrková,Petr Strakoš,Michal Kravčenko,Tomáš Brzobohatý,Lubomír Říha*

Main category: cs.CV

TL;DR: 提出了一种结合傅里叶特征编码和选择性体素采样的无结构神经压缩方法，实现了高效的体积数据压缩，并将训练时间缩短了 63.7%。


<details>
  <summary>Details</summary>
Motivation: 为医学成像、科学模拟和娱乐等领域提供关键的体积数据压缩。

Method: 提出了一种结合傅里叶特征编码和选择性体素采样的无结构神经压缩方法。动态体素选择使用形态学膨胀来优先处理活动区域，从而减少冗余计算，且无需任何分层元数据。

Result: 稀疏训练将训练时间减少了 63.7%（从 30 分钟减少到 11 分钟），仅有轻微的质量损失：PSNR 下降了 0.59 dB（从 32.60 降至 32.01），SSIM 下降了 0.008（从 0.948 降至 0.940）。生成的神经表示仅存储为网络权重，压缩率为 14，并且消除了传统的数据加载开销。

Conclusion: 这项工作将基于坐标的神经表示与高效的体积压缩联系起来，为实际应用提供了一种可扩展、无结构解决方案。

Abstract: Volumetric data compression is critical in fields like medical imaging,
scientific simulation, and entertainment. We introduce a structure-free neural
compression method combining Fourierfeature encoding with selective voxel
sampling, yielding compact volumetric representations and faster convergence.
Our dynamic voxel selection uses morphological dilation to prioritize active
regions, reducing redundant computation without any hierarchical metadata. In
the experiment, sparse training reduced training time by 63.7 % (from 30 to 11
minutes) with only minor quality loss: PSNR dropped 0.59 dB (from 32.60 to
32.01) and SSIM by 0.008 (from 0.948 to 0.940). The resulting neural
representation, stored solely as network weights, achieves a compression rate
of 14 and eliminates traditional data-loading overhead. This connects
coordinate-based neural representation with efficient volumetric compression,
offering a scalable, structure-free solution for practical applications.

</details>


### [53] [MADPromptS: Unlocking Zero-Shot Morphing Attack Detection with Multiple Prompt Aggregation](https://arxiv.org/abs/2508.08939)
*Eduarda Caldeira,Fadi Boutros,Naser Damer*

Main category: cs.CV

TL;DR: 本研究提出了一种利用CLIP模型进行面部伪造攻击检测（MAD）的零样本方法。通过设计和聚合多个文本提示，并在不进行任何微调的情况下，显著提高了检测性能，证明了通过有效的提示工程来利用基础模型的内置多模态知识是有效的。


<details>
  <summary>Details</summary>
Motivation: 面部伪造攻击（MAD）是面部识别安全中的一个关键挑战，攻击者可以通过将两个或多个个体的身份信息插值到单个面部图像中来欺骗系统。本研究旨在探索一种纯粹的零样本方法来解决MAD问题，并利用CLIP模型强大的零样本能力。

Method: 利用CLIP模型进行零样本面部伪造攻击检测，不进行任何额外的训练或微调，而是侧重于为每个类别设计和聚合多个文本提示。

Result: 通过聚合多种提示的嵌入，能够更好地使模型的内部表示与MAD任务保持一致，从而捕捉到指示真实样本或攻击样本的更丰富、更多样的线索。实验结果表明，提示聚合能显著提高零样本检测性能。

Conclusion: 通过聚合多种提示的嵌入，可以提高CLIP在面部伪造攻击检测任务上的零样本检测性能。

Abstract: Face Morphing Attack Detection (MAD) is a critical challenge in face
recognition security, where attackers can fool systems by interpolating the
identity information of two or more individuals into a single face image,
resulting in samples that can be verified as belonging to multiple identities
by face recognition systems. While multimodal foundation models (FMs) like CLIP
offer strong zero-shot capabilities by jointly modeling images and text, most
prior works on FMs for biometric recognition have relied on fine-tuning for
specific downstream tasks, neglecting their potential for direct, generalizable
deployment. This work explores a pure zero-shot approach to MAD by leveraging
CLIP without any additional training or fine-tuning, focusing instead on the
design and aggregation of multiple textual prompts per class. By aggregating
the embeddings of diverse prompts, we better align the model's internal
representations with the MAD task, capturing richer and more varied cues
indicative of bona-fide or attack samples. Our results show that prompt
aggregation substantially improves zero-shot detection performance,
demonstrating the effectiveness of exploiting foundation models' built-in
multimodal knowledge through efficient prompt engineering.

</details>


### [54] [UniSTFormer: Unified Spatio-Temporal Lightweight Transformer for Efficient Skeleton-Based Action Recognition](https://arxiv.org/abs/2508.08944)
*Wenhan Wu,Zhishuai Guo,Chen Chen,Aidong Lu*

Main category: cs.CV

TL;DR: 提出了一种统一的时空轻量级Transformer框架，用于骨骼动作识别，通过将时空建模集成到单个注意力模块和简化的多尺度池化融合，实现了高效率和有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于骨骼的动作识别（SAR）方法通常依赖于复杂的模块组合和繁重的设计，导致参数量增加、计算成本高昂且可扩展性有限。

Method: 提出了一种统一的时空轻量级Transformer框架，将空间和时间建模集成到单个注意力模块中，无需单独的时间建模块。此外，还引入了一个简化的多尺度池化融合模块，结合了局部和全局池化路径。

Result: 通过在基准数据集上的广泛实验证明，该轻量级模型实现了准确性和效率之间的优异平衡，参数复杂性降低了58%以上，计算成本降低了60%以上，同时保持了有竞争力的识别性能。

Conclusion: 提出的轻量级Transformer框架在准确性和效率之间取得了优异的平衡，与最先进的基于Transformer的基线相比，参数复杂性降低了58%以上，计算成本降低了60%以上，同时保持了有竞争力的识别性能。

Abstract: Skeleton-based action recognition (SAR) has achieved impressive progress with
transformer architectures. However, existing methods often rely on complex
module compositions and heavy designs, leading to increased parameter counts,
high computational costs, and limited scalability. In this paper, we propose a
unified spatio-temporal lightweight transformer framework that integrates
spatial and temporal modeling within a single attention module, eliminating the
need for separate temporal modeling blocks. This approach reduces redundant
computations while preserving temporal awareness within the spatial modeling
process. Furthermore, we introduce a simplified multi-scale pooling fusion
module that combines local and global pooling pathways to enhance the model's
ability to capture fine-grained local movements and overarching global motion
patterns. Extensive experiments on benchmark datasets demonstrate that our
lightweight model achieves a superior balance between accuracy and efficiency,
reducing parameter complexity by over 58% and lowering computational cost by
over 60% compared to state-of-the-art transformer-based baselines, while
maintaining competitive recognition performance.

</details>


### [55] [Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation](https://arxiv.org/abs/2508.08949)
*Ao Ma,Jiasong Feng,Ke Cao,Jing Wang,Yun Wang,Quanwei Zhang,Zhanjie Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Lay2Story的新方法，用于解决故事生成中主题一致性和细节控制的挑战。研究人员引入了“布局可切换的故事叙述”任务，并发布了一个包含超过一百万张图像的数据集Lay2Story-1M和一个评估基准Lay2Story-Bench。他们基于Diffusion Transformers（DiTs）架构开发了Lay2Story框架，并通过实验证明该方法在一致性、语义相关性和美学质量方面均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的故事叙述方法在保持主题一致性方面面临挑战，因为缺乏细粒度指导和帧间交互，并且难以精确控制主题的各种细节（如位置、外观、服装、表情和姿势）。

Method: 提出了一种基于Diffusion Transformers (DiTs) 架构的Lay2Story框架，用于布局可切换的故事叙述任务。

Result: 通过定性和定量实验，证明了Lay2Story框架在故事叙述任务中的优越性，其在一致性、语义相关性和美学质量方面均取得了SOTA结果。

Conclusion: 所提出的Lay2Story框架在一致性、语义相关性和美学质量方面优于先前最先进的技术，实现了最佳结果。

Abstract: Storytelling tasks involving generating consistent subjects have gained
significant attention recently. However, existing methods, whether
training-free or training-based, continue to face challenges in maintaining
subject consistency due to the lack of fine-grained guidance and inter-frame
interaction. Additionally, the scarcity of high-quality data in this field
makes it difficult to precisely control storytelling tasks, including the
subject's position, appearance, clothing, expression, and posture, thereby
hindering further advancements. In this paper, we demonstrate that layout
conditions, such as the subject's position and detailed attributes, effectively
facilitate fine-grained interactions between frames. This not only strengthens
the consistency of the generated frame sequence but also allows for precise
control over the subject's position, appearance, and other key details.
Building on this, we introduce an advanced storytelling task: Layout-Togglable
Storytelling, which enables precise subject control by incorporating layout
conditions. To address the lack of high-quality datasets with layout
annotations for this task, we develop Lay2Story-1M, which contains over 1
million 720p and higher-resolution images, processed from approximately 11,300
hours of cartoon videos. Building on Lay2Story-1M, we create Lay2Story-Bench, a
benchmark with 3,000 prompts designed to evaluate the performance of different
methods on this task. Furthermore, we propose Lay2Story, a robust framework
based on the Diffusion Transformers (DiTs) architecture for Layout-Togglable
Storytelling tasks. Through both qualitative and quantitative experiments, we
find that our method outperforms the previous state-of-the-art (SOTA)
techniques, achieving the best results in terms of consistency, semantic
correlation, and aesthetic quality.

</details>


### [56] [Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering](https://arxiv.org/abs/2508.08974)
*Elman Ghazaei,Erchan Aptoula*

Main category: cs.CV

TL;DR: 本研究提出了TCSSM模型和BrightVQA数据集，以解决CDVQA中的域漂移问题，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的CDVQA方法在训练和测试数据集具有相似分布的假设下进行开发，这在实际应用中往往不成立，因为域漂移问题普遍存在。为了让非专业用户能够更广泛、更灵活地获取变化信息，需要解决CDVQA中的域漂移问题。

Method: 提出了一种名为TCSSM（Text-Conditioned State Space Model）的新型状态空间模型，该模型能够统一利用双时相遥感影像和地理灾害相关的文本信息，提取跨域不变特征。TCSSM通过动态预测输入相关的参数，利用双时相影像和文本描述来促进视觉数据和文本描述之间的一致性。

Result: 与现有最先进的模型相比，TCSSM在实验中始终表现出更优越的性能。同时，引入的BrightVQA数据集为CDVQA领域的研究提供了支持。

Conclusion: 本文提出的TCSSM框架通过结合双时相遥感影像和地理灾害相关文本信息，并引入新的多模态、多域数据集BrightVQA，有效解决了CDVQA领域中的域漂移问题，并在实验中展现出优于现有方法的性能。

Abstract: The Earth's surface is constantly changing, and detecting these changes
provides valuable insights that benefit various aspects of human society. While
traditional change detection methods have been employed to detect changes from
bi-temporal images, these approaches typically require expert knowledge for
accurate interpretation. To enable broader and more flexible access to change
information by non-expert users, the task of Change Detection Visual Question
Answering (CDVQA) has been introduced. However, existing CDVQA methods have
been developed under the assumption that training and testing datasets share
similar distributions. This assumption does not hold in real-world
applications, where domain shifts often occur. In this paper, the CDVQA task is
revisited with a focus on addressing domain shift. To this end, a new
multi-modal and multi-domain dataset, BrightVQA, is introduced to facilitate
domain generalization research in CDVQA. Furthermore, a novel state space
model, termed Text-Conditioned State Space Model (TCSSM), is proposed. The
TCSSM framework is designed to leverage both bi-temporal imagery and
geo-disaster-related textual information in an unified manner to extract
domain-invariant features across domains. Input-dependent parameters existing
in TCSSM are dynamically predicted by using both bi-temporal images and
geo-disaster-related description, thereby facilitating the alignment between
bi-temporal visual data and the associated textual descriptions. Extensive
experiments are conducted to evaluate the proposed method against
state-of-the-art models, and superior performance is consistently demonstrated.
The code and dataset will be made publicly available upon acceptance at
https://github.com/Elman295/TCSSM.

</details>


### [57] [TaoCache: Structure-Maintained Video Generation Acceleration](https://arxiv.org/abs/2508.08978)
*Zhentao Fan,Zongzuo Wang,Weiwei Zhang*

Main category: cs.CV

TL;DR: TaoCache是一种创新的视频扩散模型加速方法，通过固定点去噪和结构校准，解决了现有方法在图像质量和一致性方面的问题，并在多个模型上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于缓存的视频扩散模型加速方法主要跳过早期或中期去噪步骤，这往往会导致与完整时间步生成在结构上存在差异，并可能影响指令遵循和角色一致性。

Method: TaoCache是一种无需训练、即插即用的缓存策略，它采用固定点视角来预测模型的噪声输出，而不是基于残差的缓存，特别是在去噪的后期阶段效果显著。

Result: TaoCache能够实现 substantially higher visual quality (LPIPS, SSIM, PSNR) than prior caching methods under the same speedups.

Conclusion: TaoCache通过校准连续噪声增量的余弦相似度和范数比率，在实现激进跳帧的同时保持了高分辨率结构，并且在相同的加速下，与现有的缓存方法相比，在Latte-1、OpenSora-Plan v110和Wan2.1上实现了更高的视觉质量（LPIPS、SSIM、PSNR）。

Abstract: Existing cache-based acceleration methods for video diffusion models
primarily skip early or mid denoising steps, which often leads to structural
discrepancies relative to full-timestep generation and can hinder instruction
following and character consistency. We present TaoCache, a training-free,
plug-and-play caching strategy that, instead of residual-based caching, adopts
a fixed-point perspective to predict the model's noise output and is
specifically effective in late denoising stages. By calibrating cosine
similarities and norm ratios of consecutive noise deltas, TaoCache preserves
high-resolution structure while enabling aggressive skipping. The approach is
orthogonal to complementary accelerations such as Pyramid Attention Broadcast
(PAB) and TeaCache, and it integrates seamlessly into DiT-based frameworks.
Across Latte-1, OpenSora-Plan v110, and Wan2.1, TaoCache attains substantially
higher visual quality (LPIPS, SSIM, PSNR) than prior caching methods under the
same speedups.

</details>


### [58] [ColorGPT: Leveraging Large Language Models for Multimodal Color Recommendation](https://arxiv.org/abs/2508.08987)
*Ding Xia,Naoto Inoue,Qianru Qiu,Kotaro Kikuchi*

Main category: cs.CV

TL;DR: ColorGPT, using LLMs, offers superior color recommendations for vector graphics compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Investigated the use of pretrained LLMs and their commonsense reasoning for color recommendation in vector graphics, addressing limitations of traditional methods in data availability and complexity.

Method: Developed ColorGPT, a pipeline using pretrained LLMs and prompt engineering, testing multiple color representations. Targeted color palette completion and full palette generation from text descriptions.

Result: Experimental results showed ColorGPT outperformed existing methods in color suggestion accuracy and color distribution for palette completion, and improved color diversity and similarity for full palette generation.

Conclusion: LLM-based pipeline outperformed existing methods in color suggestion accuracy and color distribution for palette completion, and yielded improvements in color diversity and similarity for full palette generation.

Abstract: Colors play a crucial role in the design of vector graphic documents by
enhancing visual appeal, facilitating communication, improving usability, and
ensuring accessibility. In this context, color recommendation involves
suggesting appropriate colors to complete or refine a design when one or more
colors are missing or require alteration. Traditional methods often struggled
with these challenges due to the complex nature of color design and the limited
data availability. In this study, we explored the use of pretrained Large
Language Models (LLMs) and their commonsense reasoning capabilities for color
recommendation, raising the question: Can pretrained LLMs serve as superior
designers for color recommendation tasks? To investigate this, we developed a
robust, rigorously validated pipeline, ColorGPT, that was built by
systematically testing multiple color representations and applying effective
prompt engineering techniques. Our approach primarily targeted color palette
completion by recommending colors based on a set of given colors and
accompanying context. Moreover, our method can be extended to full palette
generation, producing an entire color palette corresponding to a provided
textual description. Experimental results demonstrated that our LLM-based
pipeline outperformed existing methods in terms of color suggestion accuracy
and the distribution of colors in the color palette completion task. For the
full palette generation task, our approach also yielded improvements in color
diversity and similarity compared to current techniques.

</details>


### [59] [KFFocus: Highlighting Keyframes for Enhanced Video Understanding](https://arxiv.org/abs/2508.08989)
*Ming Nie,Chunwei Wang,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: KFFocus 通过智能关键帧提取和时空建模，解决了长视频理解中的压缩效率和信息丢失问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型（Vid-LLMs）在处理长视频时，由于计算成本高，通常采用帧间（如均匀采样）和帧内（如将视觉标记压缩到有限数量）的压缩策略，但这可能忽略信息在时间上的不均匀分布，导致遗漏包含关键时空和语义信息的关键帧。

Method: KFFocus 提出了一种新的视频压缩方法，通过借鉴经典视频压缩原理识别关键帧来替代均匀采样，并根据帧的上下文相关性分配不同的压缩率，以减少冗余并保留关键信息。此外，还引入了一个时空建模模块来编码帧间关系和帧内空间结构。

Result: KFFocus 显著提高了计算效率和准确性，尤其在长视频理解任务中表现优于现有方法。

Conclusion: KFFocus 在视频理解基准测试，尤其是在长视频场景下，显著优于现有方法，在计算效率和准确性方面都有大幅提升。

Abstract: Recently, with the emergence of large language models, multimodal LLMs have
demonstrated exceptional capabilities in image and video modalities. Despite
advancements in video comprehension, the substantial computational demands of
long video sequences lead current video LLMs (Vid-LLMs) to employ compression
strategies at both the inter-frame level (e.g., uniform sampling of video
frames) and intra-frame level (e.g., condensing all visual tokens of each frame
into a limited number). However, this approach often neglects the uneven
temporal distribution of critical information across frames, risking the
omission of keyframes that contain essential temporal and semantic details. To
tackle these challenges, we propose KFFocus, a method designed to efficiently
compress video tokens and emphasize the informative context present within
video frames. We substitute uniform sampling with a refined approach inspired
by classic video compression principles to identify and capture keyframes based
on their temporal redundancy. By assigning varying condensation ratios to
frames based on their contextual relevance, KFFocus efficiently reduces token
redundancy while preserving informative content details. Additionally, we
introduce a spatiotemporal modeling module that encodes both the temporal
relationships between video frames and the spatial structure within each frame,
thus providing Vid-LLMs with a nuanced understanding of spatial-temporal
dynamics. Extensive experiments on widely recognized video understanding
benchmarks, especially long video scenarios, demonstrate that KFFocus
significantly outperforms existing methods, achieving substantial computational
efficiency and enhanced accuracy.

</details>


### [60] [Spatial-Temporal Multi-Scale Quantization for Flexible Motion Generation](https://arxiv.org/abs/2508.08991)
*Zan Wang,Jingze Zhang,Yixin Chen,Baoxiong Jia,Wei Liang,Siyuan Huang*

Main category: cs.CV

TL;DR: 提出了一种名为MSQ的新型运动表示方法，通过多尺度离散化解决了现有方法的局限性，并提升了运动生成、编辑和控制的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动生成方法在运动表示方面存在两个关键局限：无法从多尺度角度捕捉运动，限制了复杂模式建模能力；缺乏组合灵活性，这对于模型在不同生成任务中的泛化至关重要。

Method: 提出了一种名为MSQ的新型量化方法，将运动序列压缩为跨空间和时间维度的多尺度离散令牌。MSQ采用不同的编码器来捕捉不同空间粒度的身体部位，并在量化为离散令牌之前将编码特征进行多尺度时间插值。在此表示的基础上，建立了一个生成掩码建模模型，以有效支持运动编辑、运动控制和条件运动生成。

Result: 所提出的量化方法能够实现运动令牌的无缝组合，且无需专门设计或重新训练。此外，大量的评估表明，该方法在各种基准测试中优于现有的基线方法。

Conclusion: 该方法通过多尺度离散化表示，实现了运动的无缝组合，无需专门设计或重新训练，并在各种基准测试中表现优于现有方法。

Abstract: Despite significant advancements in human motion generation, current motion
representations, typically formulated as discrete frame sequences, still face
two critical limitations: (i) they fail to capture motion from a multi-scale
perspective, limiting the capability in complex patterns modeling; (ii) they
lack compositional flexibility, which is crucial for model's generalization in
diverse generation tasks. To address these challenges, we introduce MSQ, a
novel quantization method that compresses the motion sequence into multi-scale
discrete tokens across spatial and temporal dimensions. MSQ employs distinct
encoders to capture body parts at varying spatial granularities and temporally
interpolates the encoded features into multiple scales before quantizing them
into discrete tokens. Building on this representation, we establish a
generative mask modeling model to effectively support motion editing, motion
control, and conditional motion generation. Through quantitative and
qualitative analysis, we show that our quantization method enables the seamless
composition of motion tokens without requiring specialized design or
re-training. Furthermore, extensive evaluations demonstrate that our approach
outperforms existing baseline methods on various benchmarks.

</details>


### [61] [UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale](https://arxiv.org/abs/2508.09000)
*Yuhao Wang,Wei Xi*

Main category: cs.CV

TL;DR: 通过组合小卷积核来扩大有效感受野（ERF）并保持其渐近高斯分布（AGD），提出了一种名为UniConvNet的新型卷积神经网络，在各种视觉识别任务中表现优于现有模型，同时保持了可比的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的具有大有效感受野（ERF）的卷积神经网络（ConvNets）存在参数量大、计算量（FLOPs）高以及ERF的渐近高斯分布（AGD）被破坏等问题。

Method: 提出了一种通过组合小卷积核（如7x7, 9x9, 11x11）来扩大感受野（ERF）并保持其渐近高斯分布（AGD）的新范式，引入了三层感受野聚合器（Three-layer Receptive Field Aggregator）和层算子（Layer Operator）。

Result: UniConvNet模型在ImageNet-1K、COCO2017和ADE20K数据集上进行了广泛实验，结果表明UniConvNet在准确性和效率上均优于现有模型。

Conclusion: UniConvNet在各种视觉识别任务中，无论是在轻量级还是大规模模型方面，都优于最先进的CNN和ViT，并且具有可比的吞吐量。UniConvNet-T在ImageNet上取得了84.2%的准确率，UniConvNet-XL在ImageNet上取得了88.4%的准确率。

Abstract: Convolutional neural networks (ConvNets) with large effective receptive field
(ERF), still in their early stages, have demonstrated promising effectiveness
while constrained by high parameters and FLOPs costs and disrupted
asymptotically Gaussian distribution (AGD) of ERF. This paper proposes an
alternative paradigm: rather than merely employing extremely large ERF, it is
more effective and efficient to expand the ERF while maintaining AGD of ERF by
proper combination of smaller kernels, such as $7\times{7}$, $9\times{9}$,
$11\times{11}$. This paper introduces a Three-layer Receptive Field Aggregator
and designs a Layer Operator as the fundamental operator from the perspective
of receptive field. The ERF can be expanded to the level of existing
large-kernel ConvNets through the stack of proposed modules while maintaining
AGD of ERF. Using these designs, we propose a universal model for ConvNet of
any scale, termed UniConvNet. Extensive experiments on ImageNet-1K, COCO2017,
and ADE20K demonstrate that UniConvNet outperforms state-of-the-art CNNs and
ViTs across various vision recognition tasks for both lightweight and
large-scale models with comparable throughput. Surprisingly, UniConvNet-T
achieves $84.2\%$ ImageNet top-1 accuracy with $30M$ parameters and $5.1G$
FLOPs. UniConvNet-XL also shows competitive scalability to big data and large
models, acquiring $88.4\%$ top-1 accuracy on ImageNet. Code and models are
publicly available at https://github.com/ai-paperwithcode/UniConvNet.

</details>


### [62] [Towards Perfection: Building Inter-component Mutual Correction for Retinex-based Low-light Image Enhancement](https://arxiv.org/abs/2508.09009)
*Luyang Cao,Han Xu,Jian Zhang,Lei Qi,Jiayi Ma,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: IRetinex模型通过引入互校正机制来处理Retinex分解中的跨组件残差（ICR），提高了低光图像增强的质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于Retinex的深度学习方法在处理低光图像时，虽然具有良好的可解释性，但在光照和反射率分解时会产生残留（ICR），影响最终图像质量。ICR被低估了，它不仅影响分解精度，还导致增强分量偏离理想结果。

Method: 提出了一种新颖的互校正Retinex模型（IRetinex），在分解阶段利用互校正残差约简模块来降低光照和反射率分量之间的特征相似性；在增强阶段，利用两个分量之间的特征相似性来检测和减轻每个增强单元中ICR的影响。

Result: 所提出的IRetinex模型通过减少ICR，在定性和定量方面均优于最先进的方法，并在三个低光基准数据集上进行了广泛的实验。

Conclusion: 所提出的IRetinex模型通过减少跨组件残差（ICR）在图像增强方面优于最先进的方法，并在三个低光数据集上进行了广泛的实验验证，实现了定性和定量的改进。

Abstract: In low-light image enhancement, Retinex-based deep learning methods have
garnered significant attention due to their exceptional interpretability. These
methods decompose images into mutually independent illumination and reflectance
components, allows each component to be enhanced separately. In fact, achieving
perfect decomposition of illumination and reflectance components proves to be
quite challenging, with some residuals still existing after decomposition. In
this paper, we formally name these residuals as inter-component residuals
(ICR), which has been largely underestimated by previous methods. In our
investigation, ICR not only affects the accuracy of the decomposition but also
causes enhanced components to deviate from the ideal outcome, ultimately
reducing the final synthesized image quality. To address this issue, we propose
a novel Inter-correction Retinex model (IRetinex) to alleviate ICR during the
decomposition and enhancement stage. In the decomposition stage, we leverage
inter-component residual reduction module to reduce the feature similarity
between illumination and reflectance components. In the enhancement stage, we
utilize the feature similarity between the two components to detect and
mitigate the impact of ICR within each enhancement unit. Extensive experiments
on three low-light benchmark datasets demonstrated that by reducing ICR, our
method outperforms state-of-the-art approaches both qualitatively and
quantitatively.

</details>


### [63] [Uncertainty-aware Cross-training for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2508.09014)
*Kaiwen Huang,Tao Zhou,Huazhu Fu,Yizhe Zhang,Yi Zhou,Xiao-Jun Wu*

Main category: cs.CV

TL;DR: UC-Seg是一种用于半监督医学图像分割的新框架，通过引入两个子网和不确定性感知伪标签生成来克服现有方法的局限性，并在多项任务中取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于均值教师（MT）的半监督方法在利用无标签数据时，往往过度依赖学生模型，忽视了模型认知偏差的影响。此外，一些使用伪标签的协同训练方法在训练过程中从扰动输入生成高置信度伪标签仍然是一个挑战。

Method: 提出了一种名为UC-Seg的不确定性感知交叉训练框架，该框架包含两个不同的子网，并通过交叉子网一致性保持（CCP）策略来增强特征表示能力和确保子网之间的一致性。同时，提出了一种不确定性感知伪标签生成（UPG）组件，利用两个子网的分割结果和相应的不确定性图来生成高置信度的伪标签。

Result: UC-Seg在包括MRI、CT、超声、结肠镜等不同模态的医学图像分割任务上进行了广泛评估，结果表明该方法实现了优越的分割精度和泛化性能。

Conclusion: UC-Seg在多种医学图像分割任务上取得了优于其他最先进的半监督方法的分割精度和泛化性能。

Abstract: Semi-supervised learning has gained considerable popularity in medical image
segmentation tasks due to its capability to reduce reliance on expert-examined
annotations. Several mean-teacher (MT) based semi-supervised methods utilize
consistency regularization to effectively leverage valuable information from
unlabeled data. However, these methods often heavily rely on the student model
and overlook the potential impact of cognitive biases within the model.
Furthermore, some methods employ co-training using pseudo-labels derived from
different inputs, yet generating high-confidence pseudo-labels from perturbed
inputs during training remains a significant challenge. In this paper, we
propose an Uncertainty-aware Cross-training framework for semi-supervised
medical image Segmentation (UC-Seg). Our UC-Seg framework incorporates two
distinct subnets to effectively explore and leverage the correlation between
them, thereby mitigating cognitive biases within the model. Specifically, we
present a Cross-subnet Consistency Preservation (CCP) strategy to enhance
feature representation capability and ensure feature consistency across the two
subnets. This strategy enables each subnet to correct its own biases and learn
shared semantics from both labeled and unlabeled data. Additionally, we propose
an Uncertainty-aware Pseudo-label Generation (UPG) component that leverages
segmentation results and corresponding uncertainty maps from both subnets to
generate high-confidence pseudo-labels. We extensively evaluate the proposed
UC-Seg on various medical image segmentation tasks involving different modality
images, such as MRI, CT, ultrasound, colonoscopy, and so on. The results
demonstrate that our method achieves superior segmentation accuracy and
generalization performance compared to other state-of-the-art semi-supervised
methods. Our code will be released at https://github.com/taozh2017/UCSeg.

</details>


### [64] [When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges](https://arxiv.org/abs/2508.09022)
*Zhiqiang Yang,Renshuai Tao,Xiaolong Zheng,Guodong Yang,Chunjie Zhang*

Main category: cs.CV

TL;DR: DPGNet通过文本引导的跨域对齐和课程驱动的伪标签生成，有效利用未标记数据，解决了深度伪造检测中的标注难题，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法严重依赖标记训练数据，但随着AI生成内容的逼真度提高，人类标注者也难以区分真伪，导致标注过程耗时且不可靠。因此，需要能够有效利用在线社交网络中大规模未标记数据的方法。AI生成的人脸与真实图像分布高度相似，对传统方法造成性能下降。

Method: DPGNet包含两个核心模块：1.文本引导的跨域对齐：利用可学习的提示将视觉和文本嵌入统一到域不变特征空间。2.课程驱动的伪标签生成：动态利用信息量更大的未标记样本。此外，通过跨域知识蒸馏促进域之间的桥梁，以防止灾难性遗忘。

Result: DPGNet outperformed SoTA approaches by 6.3% on 11 popular datasets.

Conclusion: DPGNet在11个人脸数据集上的实验结果表明，其性能比现有最佳方法高出6.3%，有效解决了日益逼真的深度伪造图像带来的标注挑战，并能有效利用未标记数据。

Abstract: Existing deepfake detection methods heavily depend on labeled training data.
However, as AI-generated content becomes increasingly realistic, even
\textbf{human annotators struggle to distinguish} between deepfakes and
authentic images. This makes the labeling process both time-consuming and less
reliable. Specifically, there is a growing demand for approaches that can
effectively utilize large-scale unlabeled data from online social networks.
Unlike typical unsupervised learning tasks, where categories are distinct,
AI-generated faces closely mimic real image distributions and share strong
similarities, causing performance drop in conventional strategies. In this
paper, we introduce the Dual-Path Guidance Network (DPGNet), to tackle two key
challenges: (1) bridging the domain gap between faces from different generation
models, and (2) utilizing unlabeled image samples. The method features two core
modules: text-guided cross-domain alignment, which uses learnable prompts to
unify visual and textual embeddings into a domain-invariant feature space, and
curriculum-driven pseudo label generation, which dynamically exploit more
informative unlabeled samples. To prevent catastrophic forgetting, we also
facilitate bridging between domains via cross-domain knowledge distillation.
Extensive experiments on \textbf{11 popular datasets}, show that DPGNet
outperforms SoTA approaches by \textbf{6.3\%}, highlighting its effectiveness
in leveraging unlabeled data to address the annotation challenges posed by the
increasing realism of deepfakes.

</details>


### [65] [Per-Query Visual Concept Learning](https://arxiv.org/abs/2508.09045)
*Ori Malca,Dvir Samuel,Gal Chechik*

Main category: cs.CV

TL;DR: By adding a prompt/seed-specific personalization step with attention-based losses and PDM features, this method significantly boosts text-to-image personalization across various existing techniques and models.


<details>
  <summary>Details</summary>
Motivation: Visual concept learning, or text-to-image personalization, is crucial for applications like product placement, entertainment, and personalized design. The motivation is to enhance the capabilities of pretrained models by teaching them new concepts, thereby improving the quality and relevance of generated images for specific users or purposes.

Method: The method involves adding a personalization step that is specific to the prompt and noise seed. This step utilizes two loss terms based on self- and cross-attention, capturing the identity of the personalized concept. PDM features, designed to capture identity, are leveraged to improve personalized semantic similarity. The effectiveness of this approach is evaluated by applying it to six different personalization methods and several base text-to-image models (UNet- and DiT-based).

Result: The proposed method provides significant improvements when applied on top of six different personalization methods and several base text-to-image models (UNet- and DiT-based). These improvements are substantial, even surpassing previous per-query personalization methods.

Conclusion: This paper demonstrates that incorporating a prompt and noise seed-specific personalization step, utilizing self- and cross-attention loss terms based on PDM features, can significantly improve existing text-to-image personalization methods. The proposed approach enhances personalized semantic similarity and yields substantial improvements even over previous per-query personalization techniques.

Abstract: Visual concept learning, also known as Text-to-image personalization, is the
process of teaching new concepts to a pretrained model. This has numerous
applications from product placement to entertainment and personalized design.
Here we show that many existing methods can be substantially augmented by
adding a personalization step that is (1) specific to the prompt and noise
seed, and (2) using two loss terms based on the self- and cross- attention,
capturing the identity of the personalized concept. Specifically, we leverage
PDM features -- previously designed to capture identity -- and show how they
can be used to improve personalized semantic similarity. We evaluate the
benefit that our method gains on top of six different personalization methods,
and several base text-to-image models (both UNet- and DiT-based). We find
significant improvements even over previous per-query personalization methods.

</details>


### [66] [ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds](https://arxiv.org/abs/2508.09058)
*Shanle Yao,Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 该研究提出了一种用于视频异常检测（VAD）的主动学习框架，通过“人在回路”机制适应动态环境变化，并在模拟实验中取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的视频异常检测（VAD）方法在真实世界设置中应用困难，因为人类行为、环境变化和领域转移具有动态性。传统的评估指标无法有效区分动态场景中的正常和异常行为，因此需要一种能够适应不断变化的现实世界条件的VAD框架。

Method: 提出了一种主动学习框架，用于视频异常检测（VAD）。该框架包含一个“人在回路”机制，用于从AI生成的伪标签结果中识别真实的正异常和负异常实例。通过持续选择信息量最大的数据点进行标注，并利用收集到的数据定义自适应阈值，以应对现实世界中不断变化的条件和领域转移。

Result: 实验结果显示，该方法在模拟的真实世界场景中实现了68.91的EBI（Error Balance Index），证明了其在动态环境下的有效性，显著提高了VAD的适用性。

Conclusion: 所提出的方法通过引入主动学习和“人在回路”机制，能够持续学习并适应环境变化，为视频异常检测提供了有效的解决方案。实验结果表明，该方法在模拟的真实世界场景中取得了显著的性能提升（Q3的EBI达到68.91），增强了VAD在动态环境中的适用性。

Abstract: Video Anomaly Detection (VAD) can play a key role in spotting unusual
activities in video footage. VAD is difficult to use in real-world settings due
to the dynamic nature of human actions, environmental variations, and domain
shifts. Traditional evaluation metrics often prove inadequate for such
scenarios, as they rely on static assumptions and fall short of identifying a
threshold that distinguishes normal from anomalous behavior in dynamic
settings. To address this, we introduce an active learning framework tailored
for VAD, designed for adapting to the ever-changing real-world conditions. Our
approach leverages active learning to continuously select the most informative
data points for labeling, thereby enhancing model adaptability. A critical
innovation is the incorporation of a human-in-the-loop mechanism, which enables
the identification of actual normal and anomalous instances from
pseudo-labeling results generated by AI. This collected data allows the
framework to define an adaptive threshold tailored to different environments,
ensuring that the system remains effective as the definition of 'normal' shifts
across various settings. Implemented within a lab-based framework that
simulates real-world conditions, our approach allows rigorous testing and
refinement of VAD algorithms with a new metric. Experimental results show that
our method achieves an EBI (Error Balance Index) of 68.91 for Q3 in real-world
simulated scenarios, demonstrating its practical effectiveness and
significantly enhancing the applicability of VAD in dynamic environments.

</details>


### [67] [VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception](https://arxiv.org/abs/2508.09061)
*Fuhao Chang,Shuxin Li,Yabei Li,Lei He*

Main category: cs.CV

TL;DR: VLM-3D is a novel end-to-end framework that uses VLMs for 3D perception in autonomous driving, outperforming existing methods by improving accuracy by 12.8% through efficient adaptation and a joint semantic-geometric loss.


<details>
  <summary>Details</summary>
Motivation: Open-set perception in complex traffic environments is crucial for autonomous driving safety, particularly for identifying unseen object categories. Existing methods struggle with multi-stage error propagation when using VLMs with traditional object detectors.

Method: VLM-3D uses Low-Rank Adaptation (LoRA) to adapt VLMs for driving tasks efficiently and employs a joint semantic-geometric loss, including token-level semantic loss for stable convergence and 3D IoU loss for refining 3D bounding box accuracy.

Result: The proposed joint semantic-geometric loss in VLM-3D achieved a 12.8% improvement in perception accuracy on the nuScenes dataset.

Conclusion: VLM-3D is the first end-to-end framework that enables VLMs to perform 3D geometric perception in autonomous driving scenarios. Evaluations on the nuScenes dataset show a 12.8% improvement in perception accuracy.

Abstract: Open-set perception in complex traffic environments poses a critical
challenge for autonomous driving systems, particularly in identifying
previously unseen object categories, which is vital for ensuring safety. Visual
Language Models (VLMs), with their rich world knowledge and strong semantic
reasoning capabilities, offer new possibilities for addressing this task.
However, existing approaches typically leverage VLMs to extract visual features
and couple them with traditional object detectors, resulting in multi-stage
error propagation that hinders perception accuracy. To overcome this
limitation, we propose VLM-3D, the first end-to-end framework that enables VLMs
to perform 3D geometric perception in autonomous driving scenarios. VLM-3D
incorporates Low-Rank Adaptation (LoRA) to efficiently adapt VLMs to driving
tasks with minimal computational overhead, and introduces a joint
semantic-geometric loss design: token-level semantic loss is applied during
early training to ensure stable convergence, while 3D IoU loss is introduced in
later stages to refine the accuracy of 3D bounding box predictions. Evaluations
on the nuScenes dataset demonstrate that the proposed joint semantic-geometric
loss in VLM-3D leads to a 12.8% improvement in perception accuracy, fully
validating the effectiveness and advancement of our method.

</details>


### [68] [Scaling Learned Image Compression Models up to 1 Billion](https://arxiv.org/abs/2508.09075)
*Yuqi Li,Haotian Zhang,Li Li,Dong Liu,Feng Wu*

Main category: cs.CV

TL;DR: 研究表明，扩展学习图像压缩模型（如HPCM）的规模可以提高其性能，特别是1B参数的模型达到了SOTA水平，并发现了模型性能与规模之间的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 探究扩展模型规模对学习图像压缩性能的影响，以及揭示其中的缩放规律。

Method: 通过将HPCM模型参数从68.5百万扩展到10亿，并拟合测试损失与模型大小、最优训练计算等关键缩放变量之间的幂律关系，揭示了性能趋势。

Result: 模型规模的扩展呈现出一种缩放趋势，能够推断到更大规模的模型。实验结果证明，HPCM-1B模型实现了最先进的率失真性能。

Conclusion: 该研究展示了扩展学习图像压缩模型（HPCM）可以带来性能的提升，其中HPCM-1B模型达到了最先进的率失真性能。

Abstract: Recent advances in large language models (LLMs) highlight a strong connection
between intelligence and compression. Learned image compression, a fundamental
task in modern data compression, has made significant progress in recent years.
However, current models remain limited in scale, restricting their
representation capacity, and how scaling model size influences compression
performance remains unexplored. In this work, we present a pioneering study on
scaling up learned image compression models and revealing the performance
trends through scaling laws. Using the recent state-of-the-art HPCM model as
baseline, we scale model parameters from 68.5 millions to 1 billion and fit
power-law relations between test loss and key scaling variables, including
model size and optimal training compute. The results reveal a scaling trend,
enabling extrapolation to larger scale models. Experimental results demonstrate
that the scaled-up HPCM-1B model achieves state-of-the-art rate-distortion
performance. We hope this work inspires future exploration of large-scale
compression models and deeper investigations into the connection between
compression and intelligence.

</details>


### [69] [Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision](https://arxiv.org/abs/2508.09087)
*Ahsan Habib Akash,Greg Murray,Annahita Amireskandari,Joel Palko,Carol Laxson,Binod Bhattarai,Prashnna Gyawali*

Main category: cs.CV

TL;DR: 提出了一种用于自动青光眼筛查的去偏视觉-语言模型方法，该方法通过无监督聚类和梯度相似性加权来解决群体偏见问题，并在评估中显示出公平的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉-语言模型（VLMs）在没有明确受保护属性的情况下，在自动青光眼筛查等关键应用中可能表现出的群体偏见问题。青光眼是不可逆性失明的主要原因，并且不成比例地影响服务不足的人群。

Method: 通过结合对比学习框架和梯度相似性加权，提出了一种新颖的属性不可知去偏方法。具体而言，该方法首先利用无监督聚类技术从图像嵌入中推断出代理亚组，然后计算多模态损失（如CLIP）与图像对比损失（如SimCLR）之间的梯度相似性权重，最后在联合的top-k加权目标函数中应用这些权重，以增强表现较差的亚组，从而达到减少亚组间差异的目的。

Result: 在哈佛FairVLMed青光眼子集上进行了评估，并使用了多种指标（如EOD、ES AUC和Groupwise AUC）来证明所提出的方法在推断的群体亚组之间实现了公平的性能。

Conclusion: 该研究提出了一种属性不可知的去偏方法，通过无监督聚类推断代理亚组，计算梯度相似性权重，并在联合的、top-k加权的目标中应用这些权重，以加强表现不佳的亚组，从而减少亚组差异。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success on multimodal
tasks such as image-text retrieval and zero-shot classification, yet they can
exhibit demographic biases even when explicit protected attributes are absent
during training. In this work, we focus on automated glaucoma screening from
retinal fundus images, a critical application given that glaucoma is a leading
cause of irreversible blindness and disproportionately affects underserved
populations. Building on a reweighting-based contrastive learning framework, we
introduce an attribute-agnostic debiasing method that (i) infers proxy
subgroups via unsupervised clustering of image-image embeddings, (ii) computes
gradient-similarity weights between the CLIP-style multimodal loss and a
SimCLR-style image-pair contrastive loss, and (iii) applies these weights in a
joint, top-$k$ weighted objective to upweight underperforming clusters. This
label-free approach adaptively targets the hardest examples, thereby reducing
subgroup disparities. We evaluate our method on the Harvard FairVLMed glaucoma
subset, reporting Equalized Odds Distance (EOD), Equalized Subgroup AUC (ES
AUC), and Groupwise AUC to demonstrate equitable performance across inferred
demographic subgroups.

</details>


### [70] [Deep Learning Models for Robust Facial Liveness Detection](https://arxiv.org/abs/2508.09094)
*Oleksandr Kuznetsov,Emanuele Frontoni,Luca Romeo,Riccardo Rosati,Andrea Maranesi,Alessandro Muscatello*

Main category: cs.CV

TL;DR: 深度学习模型通过纹理和反射分析，大幅提升面部识别抗欺骗能力，准确率达99.9%。


<details>
  <summary>Details</summary>
Motivation: 当前的面部识别系统容易受到深度伪造等高级欺骗攻击的影响，现有的活体检测方法无法有效应对这些威胁，因此需要更鲁棒的解决方案。

Method: 提出了一种结合纹理分析和反射特性的新型深度学习模型来检测面部欺骗攻击，并在五个多样化的数据集上进行了广泛评估。

Result: 研究表明，所提出的模型在对抗欺骗攻击方面取得了显著进展，其中最佳模型（AttackNet V2.2）在组合数据训练下平均准确率达到了99.9%，并且揭示了欺骗攻击行为的关键模式。

Conclusion: 这项研究通过创新的深度学习模型，结合纹理分析和反射特性，显著提高了面部识别系统的抗欺骗能力，为生物识别安全提供了更强的保障。

Abstract: In the rapidly evolving landscape of digital security, biometric
authentication systems, particularly facial recognition, have emerged as
integral components of various security protocols. However, the reliability of
these systems is compromised by sophisticated spoofing attacks, where imposters
gain unauthorized access by falsifying biometric traits. Current literature
reveals a concerning gap: existing liveness detection methodologies - designed
to counteract these breaches - fall short against advanced spoofing tactics
employing deepfakes and other artificial intelligence-driven manipulations.
This study introduces a robust solution through novel deep learning models
addressing the deficiencies in contemporary anti-spoofing techniques. By
innovatively integrating texture analysis and reflective properties associated
with genuine human traits, our models distinguish authentic presence from
replicas with remarkable precision. Extensive evaluations were conducted across
five diverse datasets, encompassing a wide range of attack vectors and
environmental conditions. Results demonstrate substantial advancement over
existing systems, with our best model (AttackNet V2.2) achieving 99.9% average
accuracy when trained on combined data. Moreover, our research unveils critical
insights into the behavioral patterns of impostor attacks, contributing to a
more nuanced understanding of their evolving nature. The implications are
profound: our models do not merely fortify the authentication processes but
also instill confidence in biometric systems across various sectors reliant on
secure access.

</details>


### [71] [Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices](https://arxiv.org/abs/2508.09136)
*Ya Zou,Jingfeng Yao,Siyuan Yu,Shuai Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Turbo-VAED的低成本解决方案，用于在移动设备上高效部署视频VAE。通过引入3D深度分离卷积和解耦3D像素重排方案，显著减少了模型参数量并缩短了推理延迟。此外，还提出了一种高效的训练方法，仅需蒸馏解码器即可快速适应移动端。该方法首次实现了移动设备上的实时720p视频VAE解码，并在多项指标上取得了显著提升，同时保持了高重建质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型生成式AI模型在移动设备部署时，VAE遇到的计算瓶颈问题，提出了一种低成本的解决方案，用于将视频VAE高效地迁移到移动设备上。

Method: 1.通过集成3D深度分离卷积来减少参数量；2.提出解耦3D像素重排方案来缩短端到端延迟；3.提出了一种高效的VAE解码器训练方法，仅需蒸馏解码器至Turbo-VAED，即可实现快速移动适应且性能损失最小。

Result: Turbo-VAED实现了在移动设备上实时720p视频VAE解码，在GPU上将原始VAE加速高达84.5倍，参数量减少至原来的17.5%，同时保留96.9%的重建质量。在iPhone 16 Pro上，Turbo-VAED实现了2.9倍的帧率提升和更好的重建质量。

Conclusion: 该方法首次实现了在移动设备上对视频VAE进行实时720p解码，并且该方法可以广泛应用于大多数视频VAE。当与四个代表性模型集成时，该模型的训练成本低至95美元，在GPU上将原始VAE在720p分辨率下加速高达84.5倍，参数量仅为原始模型的17.5%，同时保留了96.9%的原始重建质量。与移动优化VAE相比，Turbo-VAED在iPhone 16 Pro上实现了2.9倍的帧率提升，并具有更好的重建质量。

Abstract: There is a growing demand for deploying large generative AI models on mobile
devices. For recent popular video generative models, however, the Variational
AutoEncoder (VAE) represents one of the major computational bottlenecks. Both
large parameter sizes and mismatched kernels cause out-of-memory errors or
extremely slow inference on mobile devices. To address this, we propose a
low-cost solution that efficiently transfers widely used video VAEs to mobile
devices. (1) We analyze redundancy in existing VAE architectures and get
empirical design insights. By integrating 3D depthwise separable convolutions
into our model, we significantly reduce the number of parameters. (2) We
observe that the upsampling techniques in mainstream video VAEs are poorly
suited to mobile hardware and form the main bottleneck. In response, we propose
a decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building
upon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3)
We propose an efficient VAE decoder training method. Since only the decoder is
used during deployment, we distill it to Turbo-VAED instead of retraining the
full VAE, enabling fast mobile adaptation with minimal performance loss. To our
knowledge, our method enables real-time 720p video VAE decoding on mobile
devices for the first time. This approach is widely applicable to most video
VAEs. When integrated into four representative models, with training cost as
low as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on
GPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of
the original reconstruction quality. Compared to mobile-optimized VAEs,
Turbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on
the iPhone 16 Pro. The code and models will soon be available at
https://github.com/hustvl/Turbo-VAED.

</details>


### [72] [HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis](https://arxiv.org/abs/2508.09137)
*Timo Teufel,Pulkit Gera,Xilong Zhou,Umar Iqbal,Pramod Rao,Jan Kautz,Vladislav Golyanik,Christian Theobalt*

Main category: cs.CV

TL;DR: 介绍HumanOLAT数据集，这是第一个用于全身人体捕捉的大规模多视图单次光照数据集，旨在解决现有数据集的不足，并促进重新照明和渲染技术的研究。


<details>
  <summary>Details</summary>
Motivation: 在公开的高质量数据集方面存在不足，尤其是在全身人体捕捉方面，这严重限制了该领域的研究进展。

Method: 提出HumanOLAT数据集，这是第一个公开访问的大规模多视图单次光照（OLAT）捕捉的全身人类的数据集。

Result: 评估表明，该数据集对最先进的重新照明和新视图合成方法具有价值，并突显了在模拟复杂的人类中心外观和光照相互作用方面仍然存在重大挑战。

Conclusion: HumanOLAT将极大地促进未来的研究，能够对通用和特定于人类的重新照明和渲染技术进行严格的基准测试和改进。

Abstract: Simultaneous relighting and novel-view rendering of digital human
representations is an important yet challenging task with numerous
applications. Progress in this area has been significantly limited due to the
lack of publicly available, high-quality datasets, especially for full-body
human captures. To address this critical gap, we introduce the HumanOLAT
dataset, the first publicly accessible large-scale dataset of multi-view
One-Light-at-a-Time (OLAT) captures of full-body humans. The dataset includes
HDR RGB frames under various illuminations, such as white light, environment
maps, color gradients and fine-grained OLAT illuminations. Our evaluations of
state-of-the-art relighting and novel-view synthesis methods underscore both
the dataset's value and the significant challenges still present in modeling
complex human-centric appearance and lighting interactions. We believe
HumanOLAT will significantly facilitate future research, enabling rigorous
benchmarking and advancements in both general and human-specific relighting and
rendering techniques.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [73] [Argument Quality Annotation and Gender Bias Detection in Financial Communication through Large Language Models](https://arxiv.org/abs/2508.08262)
*Alaa Alhamzeh,Mays Al Rebdawi*

Main category: cs.CL

TL;DR: This paper evaluates LLMs (GPT-4o, Llama 3.1, Gemma 2) for annotating argument quality in financial texts using the FinArgQuality dataset. LLMs showed better consistency than humans but exhibited gender bias. The study also tested model robustness against gender bias using an adversarial attack and analyzed the impact of temperature settings.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the poorly studied area of assessing argument quality in financial communications, which are critical for investment decisions and public trust. It seeks to examine the capabilities of state-of-the-art LLMs in this task and to analyze their fairness and robustness against gender bias.

Method: The paper evaluates GPT-4o, Llama 3.1, and Gemma 2 on the FinArgQuality dataset for annotating argument quality in financial communications. It assesses annotation consistency across multiple runs and benchmarks against human annotations. An adversarial attack is introduced to test for gender bias and model fairness/robustness. Experiments are conducted across three temperature settings to analyze their influence on annotation stability and alignment with human labels.

Result: LLM-based annotations achieved higher inter-annotator agreement compared to human annotations. However, the models demonstrated varying levels of gender bias.

Conclusion: LLM-based annotations show higher inter-annotator agreement than human annotations, but models still exhibit varying degrees of gender bias. The paper offers recommendations for future research into reliable, cost-effective, and bias-aware annotation methodologies.

Abstract: Financial arguments play a critical role in shaping investment decisions and
public trust in financial institutions. Nevertheless, assessing their quality
remains poorly studied in the literature. In this paper, we examine the
capabilities of three state-of-the-art LLMs GPT-4o, Llama 3.1, and Gemma 2 in
annotating argument quality within financial communications, using the
FinArgQuality dataset. Our contributions are twofold. First, we evaluate the
consistency of LLM-generated annotations across multiple runs and benchmark
them against human annotations. Second, we introduce an adversarial attack
designed to inject gender bias to analyse models responds and ensure model's
fairness and robustness. Both experiments are conducted across three
temperature settings to assess their influence on annotation stability and
alignment with human labels. Our findings reveal that LLM-based annotations
achieve higher inter-annotator agreement than human counterparts, though the
models still exhibit varying degrees of gender bias. We provide a multifaceted
analysis of these outcomes and offer practical recommendations to guide future
research toward more reliable, cost-effective, and bias-aware annotation
methodologies.

</details>


### [74] [Putnam-AXIOM: A Functional and Static Benchmark](https://arxiv.org/abs/2508.08292)
*Aryan Gulati,Brando Miranda,Eric Chen,Emily Xia,Kai Fronsdal,Bruno Dumont,Elyas Obbad,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 引入了Putnam-AXIOM基准测试，用于评估大型语言模型（LLM）的数学推理能力，该基准测试包含大学水平的竞赛问题及其变体，以避免训练数据污染。结果显示，现有模型在变体问题上的表现显著下降，表明存在记忆现象，并强调了动态基准测试的重要性。同时引入了TFA指标来评估推理过程。


<details>
  <summary>Details</summary>
Motivation: 当前的数学推理基准测试对大型语言模型（LLM）的饱和度已接近饱和，准确率超过90%，并且越来越受到训练数据污染的损害。因此，需要新的、可避免污染的基准测试。

Method: 引入了Putnam-AXIOM基准，包含522个大学水平的竞赛问题，以及Putnam-AXIOM Variation，一个包含100个通过程序化扰动变量和常数生成的功能性变体的集合。该变体协议产生了无限数量的、难度相当的、未见过的问题实例，从而形成了一个可避免污染的测试平台。评估了OpenAI的o1-preview及其他18个模型。引入了教师强制准确率（TFA）指标，直接评估推理过程并自动化自然语言证明的评估。

Result: 在原始数据集上，OpenAI的o1-preview模型得分41.9%，但在配对的变体数据集上准确率下降了19.6%（相对下降46.8%）。其他18个模型也呈现同样的下降趋势，其中10个模型的95%置信区间没有重叠。这表明模型存在记忆现象，并凸显了动态基准测试的必要性。

Conclusion: Putnam-AXIOM提供了一个严格的、可避免训练数据污染的评估框架，用于评估LLM的高级数学推理能力。

Abstract: Current mathematical reasoning benchmarks for large language models (LLMs)
are approaching saturation, with some achieving > 90% accuracy, and are
increasingly compromised by training-set contamination. We introduce
Putnam-AXIOM, a benchmark of 522 university-level competition problems drawn
from the prestigious William Lowell Putnam Mathematical Competition, and
Putnam-AXIOM Variation, an unseen companion set of 100 functional variants
generated by programmatically perturbing variables and constants. The variation
protocol produces an unlimited stream of equally difficult, unseen instances --
yielding a contamination-resilient test bed. On the Original set, OpenAI's
o1-preview -- the strongest evaluated model -- scores 41.9%, but its accuracy
drops by 19.6% (46.8% relative decrease) on the paired Variations. The
remaining eighteen models show the same downward trend, ten of them with
non-overlapping 95% confidence intervals. These gaps suggest memorization and
highlight the necessity of dynamic benchmarks. We complement "boxed" accuracy
with Teacher-Forced Accuracy (TFA), a lightweight metric that directly scores
reasoning traces and automates natural language proof evaluations. Putnam-AXIOM
therefore provides a rigorous, contamination-resilient evaluation framework for
assessing advanced mathematical reasoning of LLMs. Data and evaluation code are
publicly available at https://github.com/brando90/putnam-axiom.

</details>


### [75] [TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection](https://arxiv.org/abs/2508.08265)
*Tarık Saraç,Selin Mergen,Mucahid Kutlu*

Main category: cs.CL

TL;DR: 提出了一种委员会辩论方法，用于科学网络话语检测，在检测科学研究引用方面取得了第一名，但在其他方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 为 CheckThat! 2025 的科学网络话语检测任务（任务 4a）开发工作。

Method: 提出了一种新颖的委员会辩论方法，模拟多个大型语言模型之间的结构化学术讨论，以识别推文中是否包含科学主张、科学研究引用或科学实体提及。探索了三种辩论方法：单辩、团队辩论和委员会辩论，其中委员会辩论表现最佳。

Result: 在检测科学研究引用方面排名第一，但在识别科学主张（排名第 8/10）和科学实体提及（排名第 9/10）方面排名不佳。

Conclusion: 在检测科学研究引用方面排名第一，但在识别科学主张和科学实体提及方面排名不佳。

Abstract: In this paper, we present our work developed for the scientific web discourse
detection task (Task 4a) of CheckThat! 2025. We propose a novel council debate
method that simulates structured academic discussions among multiple large
language models (LLMs) to identify whether a given tweet contains (i) a
scientific claim, (ii) a reference to a scientific study, or (iii) mentions of
scientific entities. We explore three debating methods: i) single debate, where
two LLMs argue for opposing positions while a third acts as a judge; ii) team
debate, in which multiple models collaborate within each side of the debate;
and iii) council debate, where multiple expert models deliberate together to
reach a consensus, moderated by a chairperson model. We choose council debate
as our primary model as it outperforms others in the development test set.
Although our proposed method did not rank highly for identifying scientific
claims (8th out of 10) or mentions of scientific entities (9th out of 10), it
ranked first in detecting references to scientific studies.

</details>


### [76] [MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language](https://arxiv.org/abs/2508.08283)
*Andres Garcia Rincon,Eliseo Ferrante*

Main category: cs.CL

TL;DR: MinionsLLM是一个结合LLM、行为树和形式语法的框架，用于多智能体系统的自然语言控制，通过微调提升性能，尤其对小模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 为了实现对任意用户定义环境中多智能体系统的自然语言控制，本研究提出了MinionsLLM框架。

Method: MinionsLLM框架集成了大型语言模型（LLMs）、行为树（BTs）和形式语法，用于自然语言控制多智能体系统。它提供了定义环境、智能体和行为原语的标准接口，并提出了两种合成数据集生成方法（方法A和方法B）来微调LLMs，以提高句法有效性和语义任务相关性。

Result: 使用Google的Gemma 3模型系列（1B、4B和12B参数）进行了验证。方法B将句法有效性提高到92.6%，并将平均任务性能提高了33%。较小模型从微调中获益最多。

Conclusion: MinionsLLM通过结合LLM、行为树和形式语法，实现了对任意用户定义环境中多智能体系统的自然语言控制。该框架提供了标准接口，并引入了两种数据集生成方法以改进LLM的句法有效性和语义相关性。实验证明，尤其是在较小规模的模型上，微调能带来显著的性能提升，为在资源受限场景下部署紧凑型本地LLM提供了方向。

Abstract: This paper presents MinionsLLM, a novel framework that integrates Large
Language Models (LLMs) with Behavior Trees (BTs) and Formal Grammars to enable
natural language control of multi-agent systems within arbitrary, user-defined
environments. MinionsLLM provides standardized interfaces for defining
environments, agents, and behavioral primitives, and introduces two synthetic
dataset generation methods (Method A and Method B) to fine-tune LLMs for
improved syntactic validity and semantic task relevance. We validate our
approach using Google's Gemma 3 model family at three parameter scales (1B, 4B,
and 12B) and demonstrate substantial gains: Method B increases syntactic
validity to 92.6% and achieves a mean task performance improvement of 33% over
baseline. Notably, our experiments show that smaller models benefit most from
fine-tuning, suggesting promising directions for deploying compact, locally
hosted LLMs in resource-constrained multi-agent control scenarios. The
framework and all resources are released open-source to support reproducibility
and future research.

</details>


### [77] [Heartificial Intelligence: Exploring Empathy in Language Models](https://arxiv.org/abs/2508.08271)
*Victoria Williams,Benjamin Rosman*

Main category: cs.CL

TL;DR: 大型语言模型在理解他人想法和情绪（认知共情）方面比人类做得更好，但在分享他人感受（情感共情）方面则不如人类。这表明大型语言模型在提供情感支持方面有巨大潜力，并且由于它们不会感到情绪疲劳或带有偏见，因此可以提供客观的支持。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在日常生活中日益普及，它们在虚拟助手和伴侣方面的应用也越来越广泛。为了更好地理解它们在人际交往中的作用，本研究旨在评估这些模型在认知和情感共情方面的能力。

Method: 本研究采用标准化的心理学测试，对几个人工智能语言模型（包括小型和大型语言模型）进行了认知共情和情感共情的评估。

Result: 研究结果显示，大型语言模型在认知共情任务上的表现优于人类（包括心理学专业学生）。然而，与人类参与者相比，小型和大型语言模型在情感共情方面的表现明显较弱。

Conclusion: 大型语言模型在认知共情方面表现出色，但情感共情能力有待提高。它们在认知共情上的优势使其有潜力成为有效的虚拟伴侣和提供个性化情感支持，同时避免了情绪疲劳和偏见。

Abstract: Large language models have become increasingly common, used by millions of
people worldwide in both professional and personal contexts. As these models
continue to advance, they are frequently serving as virtual assistants and
companions. In human interactions, effective communication typically involves
two types of empathy: cognitive empathy (understanding others' thoughts and
emotions) and affective empathy (emotionally sharing others' feelings). In this
study, we investigated both cognitive and affective empathy across several
small (SLMs) and large (LLMs) language models using standardized psychological
tests. Our results revealed that LLMs consistently outperformed humans -
including psychology students - on cognitive empathy tasks. However, despite
their cognitive strengths, both small and large language models showed
significantly lower affective empathy compared to human participants. These
findings highlight rapid advancements in language models' ability to simulate
cognitive empathy, suggesting strong potential for providing effective virtual
companionship and personalized emotional support. Additionally, their high
cognitive yet lower affective empathy allows objective and consistent emotional
support without running the risk of emotional fatigue or bias.

</details>


### [78] [Real-time News Story Identification](https://arxiv.org/abs/2508.08272)
*Tadej Škvorc,Nikola Ivačič,Sebastjan Hribar,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 该研究提出了一种实时识别新闻故事（按事件、地点、人物组织的新闻合集）的方法，结合了文本表示、聚类和在线主题建模技术。实验结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 为了改善阅读体验，新闻网站通常会将新闻组织成名为“故事”的专题合集。这项工作提出了一种为新闻监控系统实现实时故事识别的方法，该系统可以自动收集在线新闻并进行处理。故事识别的目标是将每篇新闻文章分配给它所涵盖的特定故事，这需要根据特定事件、地点和人物对文章进行分组，而不是像聚类那样基于一般的文本相似性，也不是像主题建模那样基于一般的（预定义的）主题。

Method: 该方法结合了文本表示技术、聚类算法和在线主题建模方法。具体来说，它结合了多种文本表示方法来提取事件和命名实体，并展示了像 BERTopic、DBStream 和 TextClust 这样的在线主题建模方法可以适应故事发现。

Result: 所提出的方法能够实时运行，并在文章在线发布时将其分配给相应的故事。

Conclusion: 该方法在包含斯洛文尼亚媒体一个月数据的 nazionali 数据集上进行了评估，结果表明该实时方法能够产生人类评估者认可的合理结果。

Abstract: To improve the reading experience, many news sites organize news into topical
collections, called stories. In this work, we present an approach for
implementing real-time story identification for a news monitoring system that
automatically collects news articles as they appear online and processes them
in various ways. Story identification aims to assign each news article to a
specific story that the article is covering. The process is similar to text
clustering and topic modeling, but requires that articles be grouped based on
particular events, places, and people, rather than general text similarity (as
in clustering) or general (predefined) topics (as in topic modeling). We
present an approach to story identification that is capable of functioning in
real time, assigning articles to stories as they are published online. In the
proposed approach, we combine text representation techniques, clustering
algorithms, and online topic modeling methods. We combine various text
representation methods to extract specific events and named entities necessary
for story identification, showing that a mixture of online topic-modeling
approaches such as BERTopic, DBStream, and TextClust can be adapted for story
discovery. We evaluate our approach on a news dataset from Slovene media
covering a period of 1 month. We show that our real-time approach produces
sensible results as judged by human evaluators.

</details>


### [79] [TT-XAI: Trustworthy Clinical Text Explanations via Keyword Distillation and LLM Reasoning](https://arxiv.org/abs/2508.08273)
*Kristian Miok,Blaz Škrlj,Daniela Zaharie,Marko Robnik Šikonja*

Main category: cs.CL

TL;DR: TT-XAI框架通过关键词蒸馏和LLM推理，提升了临床模型在处理电子病历时的预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 临床语言模型在处理冗长、非结构化的电子健康记录（EHR）时，在提供可信赖的预测和解释方面存在困难。

Method: TT-XAI框架结合了两种关键技术：1. 关键词蒸馏：将冗长的电子健康记录（EHR）浓缩为简洁的关键词表示，以提升BERT分类器的性能，并通过LIME的变体提高局部解释的保真度。2. LLM推理：利用关键词引导的提示，生成链式思维的临床解释，使LLM的推理过程更简洁、临床相关性更高。

Result: 评估结果显示，所有评估方法（包括基于删除的保真度指标、LLaMA-3评分的自我评估以及领域专家进行的盲人研究）均一致认为关键词增强方法更优，证实了关键词蒸馏能够同时提升机器和人类的可解释性。

Conclusion: TT-XAI框架通过领域感知关键词蒸馏和LLM推理，在提升临床预测性能和可解释性方面表现出色，为构建可信赖、可审计的临床决策支持AI提供了可扩展的途径。

Abstract: Clinical language models often struggle to provide trustworthy predictions
and explanations when applied to lengthy, unstructured electronic health
records (EHRs). This work introduces TT-XAI, a lightweight and effective
framework that improves both classification performance and interpretability
through domain-aware keyword distillation and reasoning with large language
models (LLMs). First, we demonstrate that distilling raw discharge notes into
concise keyword representations significantly enhances BERT classifier
performance and improves local explanation fidelity via a focused variant of
LIME. Second, we generate chain-of-thought clinical explanations using
keyword-guided prompts to steer LLMs, producing more concise and clinically
relevant reasoning. We evaluate explanation quality using deletion-based
fidelity metrics, self-assessment via LLaMA-3 scoring, and a blinded human
study with domain experts. All evaluation modalities consistently favor the
keyword-augmented method, confirming that distillation enhances both machine
and human interpretability. TT-XAI offers a scalable pathway toward
trustworthy, auditable AI in clinical decision support.

</details>


### [80] [Distilling Knowledge from Large Language Models: A Concept Bottleneck Model for Hate and Counter Speech Recognition](https://arxiv.org/abs/2508.08274)
*Roberto Labadie-Tamayo,Djordje Slijepčević,Xihui Chen,Adrian Jaques Böck,Andreas Babic,Liz Freimann,Christiane Atzmüller Matthias Zeppelzauer*

Main category: cs.CL

TL;DR: 提出了一种名为 SCBM 的透明方法，使用形容词作为中间表示，用于识别仇恨言论。该方法在多个数据集上表现优于现有技术，并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了应对社交媒体上日益增长的仇恨言论问题，开发了自动检测方法。与之前的黑盒模型不同，该研究旨在提供一种透明且可解释的方法。

Method: 提出了一种名为“语音概念瓶颈模型”（SCBM）的新型透明方法，该方法使用形容词作为人类可解释的瓶颈概念。SCBM利用大型语言模型（LLMs）将输入文本映射到基于形容词的抽象表示，然后将其发送到轻量级分类器以进行下游任务。

Result: SCBM在五个跨语言和跨平台的基准数据集上实现了平均宏观 F1 分数 0.69，在五个数据集中的四个上优于文献中最近报告的结果。此外，该方法提供了高度的本地和全局可解释性。将基于形容词的概念表示与transformer嵌入相结合，平均性能提高了 1.8%。

Conclusion: 通过使用“语音概念瓶颈模型”（SCBM）和以形容词为基础的表示，可以实现高效且可解释的仇恨言论和反击言论识别。该方法在多个基准数据集上均优于现有技术，并且通过融合变压器嵌入，性能进一步提高，表明该表示捕获了互补信息。该方法具有广泛的应用前景，可适应其他自然语言处理任务。

Abstract: The rapid increase in hate speech on social media has exposed an
unprecedented impact on society, making automated methods for detecting such
content important. Unlike prior black-box models, we propose a novel
transparent method for automated hate and counter speech recognition, i.e.,
"Speech Concept Bottleneck Model" (SCBM), using adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to map input texts to an abstract adjective-based representation, which
is then sent to a light-weight classifier for downstream tasks. Across five
benchmark datasets spanning multiple languages and platforms (e.g., Twitter,
Reddit, YouTube), SCBM achieves an average macro-F1 score of 0.69 which
outperforms the most recently reported results from the literature on four out
of five datasets. Aside from high recognition accuracy, SCBM provides a high
level of both local and global interpretability. Furthermore, fusing our
adjective-based concept representation with transformer embeddings, leads to a
1.8% performance increase on average across all datasets, showing that the
proposed representation captures complementary information. Our results
demonstrate that adjective-based concept representations can serve as compact,
interpretable, and effective encodings for hate and counter speech recognition.
With adapted adjectives, our method can also be applied to other NLP tasks.

</details>


### [81] [MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis](https://arxiv.org/abs/2508.08275)
*Haiyun Guo,ZhiYan Hou,Yu Chen,Jinghan He,Yandu Sun,Yuzhe Zhou,Shujing Guo,Kuan Zhu,Jinqiao Wang*

Main category: cs.CL

TL;DR: 本研究提出了 MLLM-CTBench，一个用于评估多模态大语言模型（MLLMs）持续指令调优的基准。该基准通过多维度评估（答案准确性和 CoT 推理质量）、广泛的算法和训练范式比较（8种持续学习算法，4个类别，RL vs SFT）以及精心挑选的任务（16个数据集，6个领域）来解决现有评估方法的不足。研究发现，模型能力、推理链的稳定性、算法与模型/任务的匹配度以及 RL 中的 KL 散度约束对于有效进行持续学习至关重要。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态大语言模型（MLLMs）在持续指令调优方面缺乏严格和系统的基准的问题，该研究提出了 MLLM-CTBench。

Method: 提出 MLLM-CTBench 评估基准，包含最终答案准确性和细粒度的思维链（CoT）推理质量评估，并训练了一个专门的 CoT 评估器。对八种持续学习算法和四种主要类别进行基准测试，并系统比较了强化学习与监督微调范式。从现有工作中筛选和组织了涵盖六个挑战性领域的16个数据集。

Result: （i）更强的模型通用能力在持续学习中表现出更强的抗遗忘能力；（ii）推理链比最终答案下降得更慢，支持了遗忘的层级假设；（iii）持续学习算法的有效性高度依赖于模型能力和任务顺序；（iv）在强化学习设置中，结合 KL 散度约束有助于维持策略稳定性，并在减轻遗忘方面发挥关键作用。

Conclusion: MLLM-CTBench 为多模态大语言模型（MLLMs）的持续指令调优建立了严格的标准，并为算法设计和评估提供了实际指导。研究结果表明，更强的模型通用能力、推理链的稳定性以及持续学习算法与模型能力和任务顺序的匹配度，对于有效缓解遗忘至关重要。在强化学习设置中，KL散度约束对于维持策略稳定性和减轻遗忘起着关键作用。

Abstract: Multimodal Large Language Models (MLLMs) rely on continual instruction tuning
to adapt to the evolving demands of real-world applications. However, progress
in this area is hindered by the lack of rigorous and systematic benchmarks. To
address this gap, we present MLLM-CTBench, a comprehensive evaluation benchmark
with three key contributions: (1) Multidimensional Evaluation: We combine final
answer accuracy with fine-grained CoT reasoning quality assessment, enabled by
a specially trained CoT evaluator; (2) Comprehensive Evaluation of Algorithms
and Training Paradigms: We benchmark eight continual learning algorithms across
four major categories and systematically compare reinforcement learning with
supervised fine-tuning paradigms; (3) Carefully Curated Tasks: We select and
organize 16 datasets from existing work, covering six challenging domains. Our
key findings include: (i) Models with stronger general capabilities exhibit
greater robustness to forgetting during continual learning; (ii) Reasoning
chains degrade more slowly than final answers, supporting the hierarchical
forgetting hypothesis; (iii) The effectiveness of continual learning algorithms
is highly dependent on both model capability and task order; (iv) In
reinforcement learning settings, incorporating KL-divergence constraints helps
maintain policy stability and plays a crucial role in mitigating forgetting.
MLLM-CTBench establishes a rigorous standard for continual instruction tuning
of MLLMs and offers practical guidance for algorithm design and evaluation.

</details>


### [82] [A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models](https://arxiv.org/abs/2508.08712)
*Lingzhe Zhang,Liancheng Fang,Chiming Duan,Minghua He,Leyi Pan,Pei Xiao,Shiyu Huang,Yunpeng Zhai,Xuming Hu,Philip S. Yu,Aiwei Liu*

Main category: cs.CL

TL;DR: 本论文对旨在提高文本生成速度的并行文本生成技术进行了全面的分析和分类。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的LLM依赖自回归（AR）生成，其速度受限于顺序过程。为了解决这个效率问题，越来越多的研究人员开始探索并行文本生成技术，但目前缺乏对这些技术的全面分析。

Method: 对现有方法进行分类（AR-和非AR-）、评估它们的理论权衡（速度、质量、效率）、检查它们的组合潜力以及与替代加速策略的比较。

Result: 对并行文本生成技术进行了分类和评估，并指出了需要进一步研究的领域。

Conclusion: 本论文对并行文本生成方法进行了系统性调查，对现有方法进行了分类，评估了它们的理论权衡，并指出了未来的研究方向。

Abstract: As text generation has become a core capability of modern Large Language
Models (LLMs), it underpins a wide range of downstream applications. However,
most existing LLMs rely on autoregressive (AR) generation, producing one token
at a time based on previously generated context-resulting in limited generation
speed due to the inherently sequential nature of the process. To address this
challenge, an increasing number of researchers have begun exploring parallel
text generation-a broad class of techniques aimed at breaking the
token-by-token generation bottleneck and improving inference efficiency.
Despite growing interest, there remains a lack of comprehensive analysis on
what specific techniques constitute parallel text generation and how they
improve inference performance. To bridge this gap, we present a systematic
survey of parallel text generation methods. We categorize existing approaches
into AR-based and Non-AR-based paradigms, and provide a detailed examination of
the core techniques within each category. Following this taxonomy, we assess
their theoretical trade-offs in terms of speed, quality, and efficiency, and
examine their potential for combination and comparison with alternative
acceleration strategies. Finally, based on our findings, we highlight recent
advancements, identify open challenges, and outline promising directions for
future research in parallel text generation.

</details>


### [83] [Evaluating Contrast Localizer for Identifying Causal Unitsin Social & Mathematical Tasks in Language Models](https://arxiv.org/abs/2508.08276)
*Yassine Jamaa,Badr AlKhamissi,Satrajit Ghosh,Martin Schrimpf*

Main category: cs.CL

TL;DR: 研究人员试图定位LLMs和VLMs中对心智理论（ToM）和数学推理任务有因果作用的单元，但发现基于对比的定位器可能并不如预期的那样有效，并且需要改进方法。


<details>
  <summary>Details</summary>
Motivation: 这项工作的动机是想了解在大型语言模型（LLMs）和视觉语言模型（VLMs）中，哪些单元对于心智理论（ToM）和数学推理任务具有因果作用。

Method: 该研究采用了一种神经科学对比定位器来精确定位大型语言模型（LLMs）和视觉语言模型（VLMs）中对心智理论（ToM）和数学推理任务有因果作用的单元。研究人员在11个LLM和5个VLM上进行了实验，模型的参数量从3B到90B不等。他们使用对比刺激集来定位激活度最高的单元，并通过有针对性的消融实验来评估这些单元的因果作用。研究人员将功能选择单元的损伤效果与低激活度和随机选择单元的损伤效果进行了比较，以评估它们对下游任务准确性的影响。

Result: 研究发现，与预期相反，低激活度单元有时比高激活度单元导致更大的性能下降。此外，源自数学定位器的单元通常比源自ToM定位器的单元对ToM性能的损害更大。

Conclusion: 该研究的结果对基于对比的定位器的因果相关性提出了质疑，并强调需要更广泛的刺激集和更准确地捕获特定于任务的单元。

Abstract: This work adapts a neuroscientific contrast localizer to pinpoint causally
relevant units for Theory of Mind (ToM) and mathematical reasoning tasks in
large language models (LLMs) and vision-language models (VLMs). Across 11 LLMs
and 5 VLMs ranging in size from 3B to 90B parameters, we localize top-activated
units using contrastive stimulus sets and assess their causal role via targeted
ablations. We compare the effect of lesioning functionally selected units
against low-activation and randomly selected units on downstream accuracy
across established ToM and mathematical benchmarks. Contrary to expectations,
low-activation units sometimes produced larger performance drops than the
highly activated ones, and units derived from the mathematical localizer often
impaired ToM performance more than those from the ToM localizer. These findings
call into question the causal relevance of contrast-based localizers and
highlight the need for broader stimulus sets and more accurately capture
task-specific units.

</details>


### [84] [Objective Metrics for Evaluating Large Language Models Using External Data Sources](https://arxiv.org/abs/2508.08277)
*Haoze Du,Richard Li,Edward Gehringer*

Main category: cs.CL

TL;DR: 该研究提出了一个利用课堂文本材料的主观指标来评估LLM性能的框架，以实现客观、可重复和减少偏差的测量。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的性能是一项关键但充满挑战的任务，尤其是在需要避免主观评估的情况下。

Method: 提出一个利用跨不同学期课堂文本材料提取的主观指标的框架，并结合明确定义的基准、事实数据集和结构化评估流程来实现LLM性能评估。

Result: 该框架强调自动评分和透明度，减少对人类解释的依赖，同时确保与现实世界应用的兼容性，为教育、科学和其他高风险领域提供了一种可扩展的性能评估解决方案。

Conclusion: 该框架通过利用跨不同学期的课堂文本材料中提取的主观指标，为评估大型语言模型（LLMs）在各种任务上的输出提供了一种可扩展的、减少偏差的解决方案，解决了主观评估方法的局限性。

Abstract: Evaluating the performance of Large Language Models (LLMs) is a critical yet
challenging task, particularly when aiming to avoid subjective assessments.
This paper proposes a framework for leveraging subjective metrics derived from
the class textual materials across different semesters to assess LLM outputs
across various tasks. By utilizing well-defined benchmarks, factual datasets,
and structured evaluation pipelines, the approach ensures consistent,
reproducible, and bias-minimized measurements. The framework emphasizes
automation and transparency in scoring, reducing reliance on human
interpretation while ensuring alignment with real-world applications. This
method addresses the limitations of subjective evaluation methods, providing a
scalable solution for performance assessment in educational, scientific, and
other high-stakes domains.

</details>


### [85] [The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs](https://arxiv.org/abs/2508.08285)
*Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Schwartz-Ziv,Tomasz Kajdanowicz*

Main category: cs.CL

TL;DR: 现有LLM幻觉检测方法的评估指标（如ROUGE）与人类判断不一致，导致评估结果失准。通过人类研究发现，简单的方法（如响应长度）效果良好，并提出应采用更鲁棒的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有的幻觉检测方法的评估严重依赖ROUGE指标，该指标与人类判断不一致，导致对模型性能的估计具有误导性。

Method: 通过全面的`LLM-as-Judge`人类研究，评估了ROUGE指标的局限性，并提出了一种新的评估方法。

Result: 研究表明，ROUGE指标的低准确率会导致性能估计失准，即使是复杂的检测方法，在使用人类对齐指标时性能也会下降高达45.9%。此外，基于响应长度的简单启发式方法在检测效果上可以媲美复杂的技术。

Conclusion: 应采用语义感知和鲁棒的评估框架，以准确衡量幻觉检测方法的真实性能，并最终确保LLM输出的可靠性。

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their tendency to hallucinate poses serious challenges for reliable
deployment. Despite numerous hallucination detection methods, their evaluations
often rely on ROUGE, a metric based on lexical overlap that misaligns with
human judgments. Through comprehensive human studies, we demonstrate that while
ROUGE exhibits high recall, its extremely low precision leads to misleading
performance estimates. In fact, several established detection methods show
performance drops of up to 45.9\% when assessed using human-aligned metrics
like LLM-as-Judge. Moreover, our analysis reveals that simple heuristics based
on response length can rival complex detection techniques, exposing a
fundamental flaw in current evaluation practices. We argue that adopting
semantically aware and robust evaluation frameworks is essential to accurately
gauge the true performance of hallucination detection methods, ultimately
ensuring the trustworthiness of LLM outputs.

</details>


### [86] [Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions](https://arxiv.org/abs/2508.08287)
*Farah Atif,Nursultan Askarbekuly,Kareem Darwish,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本研究首次提出了FiqhQA基准，用于评估LLM在生成细粒度的、特定伊斯兰教法流派的判例方面的能力，并评估了其在伊斯兰教法查询中的弃权能力。研究结果表明，LLM在这一领域的表现存在差异，尤其是在阿拉伯语方面，需要谨慎使用。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分考察LLM在宗教领域（特别是伊斯兰教法）的可靠性和准确性，并且忽略了不同教法流派的区别以及对模型“弃权”能力的评估。

Method: 提出FiqhQA基准，评估LLM生成伊斯兰教法判例的准确性和弃权能力，涵盖四个主要的逊尼派思想流派，并分别使用阿拉伯语和英语进行测试。

Result: GPT-4o在准确性方面表现最佳，而Gemini和Fanar在弃权行为方面表现更优。所有模型在阿拉伯语上的表现均有下降，表明在非英语语言上的宗教推理能力存在局限性。

Conclusion: LLM在伊斯兰教法判例生成方面的表现存在显著差异，尤其是在阿拉伯语方面，需要进行特定任务的评估和谨慎部署。

Abstract: Despite the increasing usage of Large Language Models (LLMs) in answering
questions in a variety of domains, their reliability and accuracy remain
unexamined for a plethora of domains including the religious domains. In this
paper, we introduce a novel benchmark FiqhQA focused on the LLM generated
Islamic rulings explicitly categorized by the four major Sunni schools of
thought, in both Arabic and English. Unlike prior work, which either overlooks
the distinctions between religious school of thought or fails to evaluate
abstention behavior, we assess LLMs not only on their accuracy but also on
their ability to recognize when not to answer. Our zero-shot and abstention
experiments reveal significant variation across LLMs, languages, and legal
schools of thought. While GPT-4o outperforms all other models in accuracy,
Gemini and Fanar demonstrate superior abstention behavior critical for
minimizing confident incorrect answers. Notably, all models exhibit a
performance drop in Arabic, highlighting the limitations in religious reasoning
for languages other than English. To the best of our knowledge, this is the
first study to benchmark the efficacy of LLMs for fine-grained Islamic school
of thought specific ruling generation and to evaluate abstention for Islamic
jurisprudence queries. Our findings underscore the need for task-specific
evaluation and cautious deployment of LLMs in religious applications.

</details>


### [87] [CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation](https://arxiv.org/abs/2508.08386)
*Shuzhou Yuan,William LaCroix,Hardik Ghoshal,Ercong Nie,Michael Färber*

Main category: cs.CL

TL;DR: CoDAE通过CoT数据增强改进AI助教，解决其教学适应性、推理支持和抗干扰能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现成的LLM作为AI助教存在诸多问题，例如：过早给出答案、无法根据学生不确定性调整回应、容易受到情感操控等，因此需要改进LLM以适应教育场景。

Method: 通过链式思考（CoT）数据增强，利用真实师生对话数据，并设计针对性对话案例来解决LLM在教育中的三大局限性（过早泄露答案、未能适应学生不确定性、易受情感操控），然后对四种开源LLM进行微调，并使用自动指标和LLM评估方法进行测试。

Result: CoDAE框架能够生成更具教学适宜性的指导、更好地支持推理过程，并有效防止过早泄露答案。

Conclusion: CoDAE框架通过链式思考（CoT）数据增强，有效解决了现成LLM在教育场景下的不足，提高了AI助教的教学适应性、推理支持和抗干扰能力。

Abstract: Large Language Models (LLMs) are increasingly employed as AI tutors due to
their scalability and potential for personalized instruction. However,
off-the-shelf LLMs often underperform in educational settings: they frequently
reveal answers too readily, fail to adapt their responses to student
uncertainty, and remain vulnerable to emotionally manipulative prompts. To
address these challenges, we introduce CoDAE, a framework that adapts LLMs for
educational use through Chain-of-Thought (CoT) data augmentation. We collect
real-world dialogues between students and a ChatGPT-based tutor and enrich them
using CoT prompting to promote step-by-step reasoning and pedagogically aligned
guidance. Furthermore, we design targeted dialogue cases to explicitly mitigate
three key limitations: over-compliance, low response adaptivity, and threat
vulnerability. We fine-tune four open-source LLMs on different variants of the
augmented datasets and evaluate them in simulated educational scenarios using
both automatic metrics and LLM-as-a-judge assessments. Our results show that
models fine-tuned with CoDAE deliver more pedagogically appropriate guidance,
better support reasoning processes, and effectively resist premature answer
disclosure.

</details>


### [88] [Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery](https://arxiv.org/abs/2508.08401)
*Jiatong Li,Weida Wang,Qinggang Zhang,Junxian Li,Di Zhang,Changmeng Zheng,Shufei Zhang,Xiaoyong Wei,Qing Li*

Main category: cs.CL

TL;DR: Mol-R1是一个改进大型语言模型在分子发现领域推理能力的新框架，通过PRID数据集和MoIA训练策略，提高了模型在分子生成任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 目前的语言模型在知识密集型领域（如分子发现）的能力和效率有限，难以准确理解分子结构和化学原理等领域知识。

Method: 提出了一种名为Mol-R1的新框架，该框架包括一个通过“先验正则化通过上下文蒸馏”（PRID）策略生成的高质量推理数据集，以及一种名为“分子迭代适应”（MoIA）的训练策略，该策略结合了监督微调（SFT）和强化策略优化（RPO）。

Result: Mol-R1在基于文本的分子推理生成任务中展现出优越的性能，超越了现有的基线方法。

Conclusion: Mol-R1在基于文本的分子推理生成任务中表现出色，优于现有基线。

Abstract: Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT)
reasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning
capabilities, achieving impressive performance in commonsense reasoning and
mathematical inference. Despite their effectiveness, Long-CoT reasoning models
are often criticized for their limited ability and low efficiency in
knowledge-intensive domains such as molecule discovery. Success in this field
requires a precise understanding of domain knowledge, including molecular
structures and chemical principles, which is challenging due to the inherent
complexity of molecular data and the scarcity of high-quality expert
annotations. To bridge this gap, we introduce Mol-R1, a novel framework
designed to improve explainability and reasoning performance of R1-like
Explicit Long-CoT reasoning LLMs in text-based molecule generation. Our
approach begins with a high-quality reasoning dataset curated through Prior
Regulation via In-context Distillation (PRID), a dedicated distillation
strategy to effectively generate paired reasoning traces guided by prior
regulations. Building upon this, we introduce MoIA, Molecular Iterative
Adaptation, a sophisticated training strategy that iteratively combines
Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO),
tailored to boost the reasoning performance of R1-like reasoning models for
molecule discovery. Finally, we examine the performance of Mol-R1 in the
text-based molecule reasoning generation task, showing superior performance
against existing baselines.

</details>


### [89] [Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment](https://arxiv.org/abs/2508.08424)
*Saketh Reddy Vemula,Dipti Mishra Sharma,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 研究评估了词法对齐分词法对复杂词法语言模型性能的影响，发现词法对齐有积极作用，但分词算法本身更关键。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有语言模型在处理具有复杂词法结构语言时，词法对齐分词方法是否能提高性能的结论不一致的问题。

Method: 选择印地语、泰卢固语和英语这几种词法结构多样化的语言，并进行了从分词器训练到下游任务评估的全面评估。为了解释跨分词器变体的性能差异，研究重点关注了词法对齐和分词质量这两个关键因素。在词法对齐方面，研究人员为泰卢固语创建了一个包含600个派生词和7000个屈折词形式的词法分割数据集。

Result: 实验发现，词法对齐与基于语法的任务表现呈中度正相关，但分词算法（BPE vs. Unigram）的影响更大。Unigram 分词器在大多数情况下表现最佳，而结合了词法分割的混合分词器在 BPE 框架内能显著提升性能。语料库分词数（CTC）和 Rényi 熵等内在指标与下游任务表现无关。

Conclusion: 该研究表明，在词法结构复杂的语言中，更好的词法对齐与基于语法的任务（如词性标注、命名实体识别和依存关系解析）的表现呈中度正相关。然而，分词算法（BPE vs. Unigram）对下游任务表现的影响比单纯的词法对齐更显著。

Abstract: Prior work on language modeling showed conflicting findings about whether
morphologically aligned approaches to tokenization improve performance,
particularly for languages with complex morphology. To investigate this, we
select a typologically diverse set of languages: Telugu (agglutinative), Hindi
(primarily fusional with some agglutination), and English (fusional). We
conduct a comprehensive evaluation of language models -- starting from
tokenizer training and extending through the finetuning and downstream task
evaluation. To account for the consistent performance differences observed
across tokenizer variants, we focus on two key factors: morphological alignment
and tokenization quality. To assess morphological alignment of tokenizers in
Telugu, we create a dataset containing gold morpheme segmentations of 600
derivational and 7000 inflectional word forms.
  Our experiments reveal that better morphological alignment correlates
positively -- though moderately -- with performance in syntax-based tasks such
as Parts-of-Speech tagging, Named Entity Recognition and Dependency Parsing.
However, we also find that the tokenizer algorithm (Byte-pair Encoding vs.
Unigram) plays a more significant role in influencing downstream performance
than morphological alignment alone. Naive Unigram tokenizers outperform others
across most settings, though hybrid tokenizers that incorporate morphological
segmentation significantly improve performance within the BPE framework. In
contrast, intrinsic metrics like Corpus Token Count (CTC) and R\'enyi entropy
showed no correlation with downstream performance.

</details>


### [90] [Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints](https://arxiv.org/abs/2508.08466)
*Daren Yao,Jinsong Yuan,Ruike Chen*

Main category: cs.CL

TL;DR: 提出APO-hinge-zero等轻量化方法，通过引入边界和选择性更新机制，有效提升了小型语言模型在资源受限情况下的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（LLMs）在输出对齐人类偏好方面存在困难，尤其是在性能差距较大的情况下。

Method: 提出两种基于DPO的轻量化方法：自适应边界-Sigmoid损失和APO-hinge-zero。APO-hinge-zero结合了边界诱导硬样本挖掘和APO-zero的选定样本优化。

Result: APO-hinge-zero在AlpacaEval上将胜率提高了+2.0，长度受控胜率提高了+1.4。在MT-Bench上，方法在STEM和人文任务中表现尤为出色。

Conclusion: 轻量化方法能有效提升小模型在资源受限情况下的对齐能力，为高效部署提供了可行路径。

Abstract: Small large language models (LLMs) often face difficulties in aligning output
to human preferences, particularly when operating under severe performance
gaps. In this work, we propose two lightweight DPO-based variants -- Adaptive
Margin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance
scenarios by introducing margin-based objectives and selective update
mechanisms.
  Our APO-hinge-zero method, which combines hinge-induced hard-example mining
with the chosen-focused optimization of APO-zero, achieves strong results. In
AlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the
length-controlled win rate by +1.4 points compared to the APO-zero baseline. In
MT-Bench, our methods maintain competitive performance in diverse categories,
particularly excelling in STEM and Humanities tasks.
  These results demonstrate that simple modifications to preference-based
objectives can significantly enhance small LLM alignment under resource
constraints, offering a practical path toward more efficient deployment.

</details>


### [91] [Momentum Point-Perplexity Mechanics in Large Language Models](https://arxiv.org/abs/2508.08492)
*Lorenzo Tomaz,Judd Rosenblatt,Thomas Berry Jones,Diogo Schwerz de Lucena*

Main category: cs.CL

TL;DR: Transformer 的隐藏状态变化类似于物理系统的能量守恒。一种名为 Jacobian steering 的新方法利用这种洞察力来更可控地引导模型生成文本，提高了文本的语义质量。这项工作为理解和控制 LLM 提供了一个新的视角。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLM）的内部隐藏状态如何随 token 的变化，以期获得对模型行为的更深层次理解，并开发可控、可解释的模型。

Method: 提出了一种基于物理学的方法来研究 Transformer 在推理过程中隐藏状态的逐个 token 的变化。引入了“log-Lagrangian”视角，并推导了一种称为“Jacobian steering”的控制方法，通过最小化扰动来引导模型生成目标 token。

Result: 发现一个结合了隐藏状态变化率和模型下一 token 置信度的量（类似于物理中的能量）在模型推理过程中几乎保持恒定。随机权重模型比预训练模型更能维持这种“能量”的恒定性。训练会使模型进入一个变化更快、决策更明确的状态。Jacobian steering 方法在两个测试模型中保持了接近恒定的能量，并生成了语义质量更高的文本。

Conclusion: 通过将 Transformer 视为一个物理系统，可以为可解释性、异常检测和低风险引导提供原则性的基础，有助于使强大的模型更可预测并与人类意图保持一致。

Abstract: We take a physics-based approach to studying how the internal hidden states
of large language models change from token to token during inference. Across 20
open-source transformer models (135M-3B parameters), we find that a quantity
combining the rate of change in hidden states and the model's next-token
certainty, analogous to energy in physics, remains nearly constant.
Random-weight models conserve this "energy" more tightly than pre-trained ones,
while training shifts models into a faster, more decisive regime with greater
variability. Using this "log-Lagrangian" view, we derive a control method
called Jacobian steering, which perturbs hidden states in the minimal way
needed to favor a target token. This approach maintained near-constant energy
in two tested models and produced continuations rated higher in semantic
quality than the models' natural outputs. Viewing transformers through this
mechanics lens offers a principled basis for interpretability, anomaly
detection, and low-risk steering. This could help make powerful models more
predictable and aligned with human intent.

</details>


### [92] [Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression](https://arxiv.org/abs/2508.08509)
*Jadie Adams,Brian Hu,Emily Veenhuis,David Joy,Bharadwaj Ravichandran,Aaron Bray,Anthony Hoogs,Arslan Basharat*

Main category: cs.CL

TL;DR: 该研究提出了一种新颖的可控多类型对齐方法，使用少样本比较回归来适应用户偏好，解决了现有LLM对齐方法的局限性，并在新基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM对齐技术（如RLHF）使用单一标量奖励，无法反映用户偏好的多样性。多类型对齐旨在捕捉用户在不同属性上的偏好，超越了单纯的有用性和无害性。

Method: 提出了一种基于少样本比较回归的可控多样性对齐模型，利用上下文学习和推理，以细粒度属性为基础，对响应选项进行比较并做出对齐选择。

Result: 所提出的方法在两个新的可控多类型基准（改编自MIC和HelpSteer2数据集）上进行了评估，结果表明该方法在价值对齐决策和奖励建模方面具有适用性，并且优于多个基线和最先进的方法。

Conclusion: 该研究提出了一种基于少样本比较回归的可控多样性对齐模型，该模型能够适应个体用户偏好，并通过新的基准测试证明了其在价值对齐决策和奖励建模方面的适用性。该方法具有可解释性，可兼容不同的属性和LLM，并且优于多个基线和最先进的方法，为LLM的公平和代表性使用以及道德AI的进步提供了新的见解和研究方向。

Abstract: Large language models (LLMs) are currently aligned using techniques such as
reinforcement learning from human feedback (RLHF). However, these methods use
scalar rewards that can only reflect user preferences on average. Pluralistic
alignment instead seeks to capture diverse user preferences across a set of
attributes, moving beyond just helpfulness and harmlessness. Toward this end,
we propose a steerable pluralistic model based on few-shot comparative
regression that can adapt to individual user preferences. Our approach
leverages in-context learning and reasoning, grounded in a set of fine-grained
attributes, to compare response options and make aligned choices. To evaluate
our algorithm, we also propose two new steerable pluralistic benchmarks by
adapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets,
demonstrating the applicability of our approach to value-aligned
decision-making and reward modeling, respectively. Our few-shot comparative
regression approach is interpretable and compatible with different attributes
and LLMs, while outperforming multiple baseline and state-of-the-art methods.
Our work provides new insights and research directions in pluralistic
alignment, enabling a more fair and representative use of LLMs and advancing
the state-of-the-art in ethical AI.

</details>


### [93] [DeCAL Tokenwise Compression](https://arxiv.org/abs/2508.08514)
*Sameer Panwar*

Main category: cs.CL

TL;DR: DeCAL是一种tokenwise压缩方法，通过encoder-decoder模型学习压缩表示，可在高压缩率下保持良好性能，实现显著的资源节省。


<details>
  <summary>Details</summary>
Motivation: 为实现高效的tokenwise压缩，同时尽量保持数据质量和下游任务性能。

Method: DeCAL 使用经过去噪预训练的 encoder-decoder 语言模型来学习生成高质量、通用的压缩表示。DeCAL 对 encoder 进行了少量修改，重点在于最大化压缩质量，即使牺牲计算量也在所不惜。

Result: DeCAL 在2倍压缩下就能在许多下游任务上匹配未压缩数据，在高达8倍压缩率下通常 only 导致指标 only 略有下降，在问答、摘要和多向量检索等任务中表现尤为如此。

Conclusion: DeCAL在2倍压缩下就能在许多下游任务上达到与未压缩数据相当的性能，在高达8倍压缩率下通常 only 导致指标 only 略有下降，在问答、摘要和多向量检索等任务中表现尤为如此。DeCAL 在可利用预计算密集表示的情况下能显著节省资源，并且其方法有潜力被进一步开发以实现更广泛的应用。

Abstract: This paper introduces DeCAL, a new method for tokenwise compression. DeCAL
uses an encoder-decoder language model pretrained with denoising to learn to
produce high-quality, general-purpose compressed representations by the
encoder. DeCAL applies small modifications to the encoder, with the emphasis on
maximizing compression quality, even at the expense of compute. We show that
DeCAL at 2x compression can match uncompressed on many downstream tasks, with
usually only minor dropoff in metrics up to 8x compression, among
question-answering, summarization, and multi-vector retrieval tasks. DeCAL
offers significant savings where pre-computed dense representations can be
utilized, and we believe the approach can be further developed to be more
broadly applicable.

</details>


### [94] [DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives](https://arxiv.org/abs/2508.08591)
*Sehwan Moon,Aram Lee,Jeong Eun Kim,Hee-Ju Kang,Il-Seon Shin,Sung-Wan Kim,Jae-Min Kim,Min Jhon,Ju-Wan Kim*

Main category: cs.CL

TL;DR: DepressLLM是一个在3,699个自传体叙述上训练的新模型，用于抑郁症预测，AUC为0.789（高置信度下为0.904），并提供可解释的预测和置信度估计。


<details>
  <summary>Details</summary>
Motivation: 抑郁症预测受到缺乏大规模、高质量和经过严格注释的数据集的限制。

Method: 本研究引入了DepressLLM，该模型在一个包含3,699个反映快乐和痛苦的自传体叙述的新语料库上进行了训练和评估。DepressLLM提供可解释的抑郁症预测，并通过其得分引导标记概率总和（SToPS）模块，实现改进的分类性能和可靠的置信度估计。

Result: DepressLLM的分类性能AUC为0.789，在置信度≥0.95的样本上提高到0.904。在内部数据集（包括生态瞬时评估（EMA）语料库和公共临床访谈数据）上进行了评估，以验证其对异类数据的鲁棒性。

Conclusion: DepressLLM的发现表明，可解释的人工智能可以实现抑郁症的早期诊断，并强调了精神病学中医学人工智能的潜力。

Abstract: Advances in large language models (LLMs) have enabled a wide range of
applications. However, depression prediction is hindered by the lack of
large-scale, high-quality, and rigorously annotated datasets. This study
introduces DepressLLM, trained and evaluated on a novel corpus of 3,699
autobiographical narratives reflecting both happiness and distress. DepressLLM
provides interpretable depression predictions and, via its Score-guided Token
Probability Summation (SToPS) module, delivers both improved classification
performance and reliable confidence estimates, achieving an AUC of 0.789, which
rises to 0.904 on samples with confidence $\geq$ 0.95. To validate its
robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets,
including an Ecological Momentary Assessment (EMA) corpus of daily stress and
mood recordings, and on public clinical interview data. Finally, a psychiatric
review of high-confidence misclassifications highlighted key model and data
limitations that suggest directions for future refinements. These findings
demonstrate that interpretable AI can enable earlier diagnosis of depression
and underscore the promise of medical AI in psychiatry.

</details>


### [95] [Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review](https://arxiv.org/abs/2508.08610)
*David Santandreu Calonge,Linda Smail*

Main category: cs.CL

TL;DR: 本综述探讨了参数高效微调（PEFT），特别是低秩自适应（LoRA），在优化检索增强生成（RAG）系统（如 Qwen3、DeepSeek 和 Kimi）方面的最新进展，以提高其在粤语等方言环境下的性能。研究发现，动态和集成 LoRA 方法可以有效减少参数并提高准确性，但仍存在处理细微语言差别和实时适应性的挑战。


<details>
  <summary>Details</summary>
Motivation: 本综述旨在优化 Qwen3、DeepSeek 和 Kimi 等检索增强生成（RAG）系统，重点关注参数高效微调（PEFT），特别是低秩自适应（LoRA），以解决这些系统在理解和生成正宗粤语口语表达方面面临的挑战，这些挑战源于标注数据有限和语言可变性。

Method: 本综述系统地分析了采用不同 LoRA 变体、合成数据生成、用户反馈集成和自适应参数分配的近期研究，以评估它们对计算效率、检索精度、语言真实性和可扩展性的影响。

Result: 研究结果表明，动态和集成 LoRA 适应显著减少了可训练参数，同时在方言背景下不牺牲检索准确性和生成质量。然而，在完全保留细粒度语言细微差别方面仍然存在局限性，尤其是在粤语等低资源环境。实时用户反馈和特定领域数据的集成仍不完善，限制了模型的适应性和个性化。虽然选择性参数冻结和非线性适应方法在效率和准确性之间提供了更好的权衡，但它们在大规模应用中的鲁棒性仍然是一个有待解决的挑战。

Conclusion: PEFT-enhanced RAG 系统在领域特定语言任务方面显示出前景，但仍需在粤语方言的真实性、动态适应和可扩展的微调管道方面进行未来工作。

Abstract: This review examines recent advances in Parameter-Efficient Fine-Tuning
(PEFT), with a focus on Low-Rank Adaptation (LoRA), to optimize
Retrieval-Augmented Generation (RAG) systems like Qwen3, DeepSeek, and Kimi.
These systems face challenges in understanding and generating authentic
Cantonese colloquial expressions due to limited annotated data and linguistic
variability. The review evaluates the integration of LoRA within RAG
frameworks, benchmarks PEFT methods for retrieval and generation accuracy,
identify domain adaptation strategies under limited data, and compares
fine-tuning techniques aimed at improving semantic fidelity under data-scarce
conditions. A systematic analysis of recent studies employing diverse LoRA
variants, synthetic data generation, user feedback integration, and adaptive
parameter allocation was conducted to assess their impact on computational
efficiency, retrieval precision, linguistic authenticity, and scalability.
Findings reveal that dynamic and ensemble LoRA adaptations significantly reduce
trainable parameters without sacrificing retrieval accuracy and generation
quality in dialectal contexts. However, limitations remain in fully preserving
fine-grained linguistic nuances, especially for low-resource settings like
Cantonese. The integration of real-time user feedback and domain-specific data
remains underdeveloped, limiting model adaptability and personalization. While
selective parameter freezing and nonlinear adaptation methods offer better
trade-offs between efficiency and accuracy, their robustness at scale remains
an open challenge. This review highlights the promise of PEFT-enhanced RAG
systems for domain-specific language tasks and calls for future work targeting
dialectal authenticity, dynamic adaptation, and scalable fine-tuning pipelines.

</details>


### [96] [InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling](https://arxiv.org/abs/2508.08636)
*Peiji Li,Jiasheng Ye,Yongkang Chen,Yichuan Ma,Zijie Yu,Kedi Chen,Ganqu Cui,Haozhan Li,Jiacheng Chen,Chengqi Lyu,Wenwei Zhang,Linyang Li,Qipeng Guo,Dahua Lin,Bowen Zhou,Kai Chen*

Main category: cs.CL

TL;DR: InternBootcamp是一个包含1000多个多样化任务环境的开源框架，用于LLM推理研究。它能自动生成训练/测试案例并进行评估，通过任务扩展可显著提升模型性能，培养通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习（RL）研究主要集中在特定领域的推理任务，无法完全覆盖现实世界复杂多变的推理场景。需要一个能够处理多样化环境并进行客观评估的基础设施来弥补这一差距。

Method: 提出了一种名为InternBootcamp的开源框架，该框架包含1000多个特定领域任务环境，并具备自动生成训练/测试案例和集成验证模块的功能，以加速LLM推理研究和优化。

Result: InternBootcamp框架能够显著提升LLM在推理任务上的性能，其32B模型在Bootcamp-EVAL基准测试和其他已建立的基准测试中取得了最先进的成果。研究还表明，增加训练任务数量（任务扩展）是实现持续性能提升的有效途径。

Conclusion: LLMs在现实世界的复杂推理任务中仍有提升空间，而InternBootcamp框架能有效提升其性能，其包含的大量多样化任务环境和自动化评估功能为RL研究提供了基础。通过任务扩展（task scaling）可以实现持续的性能提升，从而培养出能够进行推理的通才模型。

Abstract: Large language models (LLMs) have revolutionized artificial intelligence by
enabling complex reasoning capabilities. While recent advancements in
reinforcement learning (RL) have primarily focused on domain-specific reasoning
tasks (e.g., mathematics or code generation), real-world reasoning scenarios
often require models to handle diverse and complex environments that
narrow-domain benchmarks cannot fully capture. To address this gap, we present
InternBootcamp, an open-source framework comprising 1000+ domain-diverse task
environments specifically designed for LLM reasoning research. Our codebase
offers two key functionalities: (1) automated generation of unlimited
training/testing cases with configurable difficulty levels, and (2) integrated
verification modules for objective response evaluation. These features make
InternBootcamp fundamental infrastructure for RL-based model optimization,
synthetic data generation, and model evaluation. Although manually developing
such a framework with enormous task coverage is extremely cumbersome, we
accelerate the development procedure through an automated agent workflow
supplemented by manual validation protocols, which enables the task scope to
expand rapidly. % With these bootcamps, we further establish Bootcamp-EVAL, an
automatically generated benchmark for comprehensive performance assessment.
Evaluation reveals that frontier models still underperform in many reasoning
tasks, while training with InternBootcamp provides an effective way to
significantly improve performance, leading to our 32B model that achieves
state-of-the-art results on Bootcamp-EVAL and excels on other established
benchmarks. In particular, we validate that consistent performance gains come
from including more training tasks, namely \textbf{task scaling}, over two
orders of magnitude, offering a promising route towards capable reasoning
generalist.

</details>


### [97] [Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents](https://arxiv.org/abs/2508.08645)
*Zheng Wu,Heyuan Huang,Yanjia Yang,Yuanyi Song,Xingyu Lou,Weiwen Liu,Weinan Zhang,Jun Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: IFRAgent 框架通过识别显式和隐式意图流，提升了移动端智能体与人类意图的对齐能力，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有移动端智能体方法主要关注人类显式意图流（如步骤序列），而忽略了隐式意图流（如个人偏好），这使得构建个性化移动端智能体变得困难。因此，需要一种新的方法来评估和提升移动端智能体与人类意图的对齐率。

Method: 本文提出了 IFRAgent 框架，该框架首先收集了包含人类意图对齐动作和真实动作的 MobileIAR 数据集，用于评估意图对齐率。然后，IFRAgent 分析人类演示中的显式意图流以构建标准操作程序（SOP）的查询级向量库，并分析隐式意图流以构建用户级习惯存储库。最后，IFRAgent 利用 SOP 提取器、检索增强生成和查询重写器，从模糊查询生成个性化查询和 SOP，以增强智能体与人类意图的对齐。

Result: 实验结果表明，IFRAgent 在人类意图对齐率方面比基线方法平均高出 6.79%（相对提高 32.06%），在步骤完成率方面平均提高 5.30%（相对提高 26.34%）。

Conclusion: IFRAgent 框架通过分析显式和隐式意图流，显著提高了移动端智能体与人类意图的对齐率（平均提高 6.79%）和任务完成率（平均提高 5.30%），优于现有基线方法。

Abstract: As multimodal large language models advance rapidly, the automation of mobile
tasks has become increasingly feasible through the use of mobile-use agents
that mimic human interactions from graphical user interface. To further enhance
mobile-use agents, previous studies employ demonstration learning to improve
mobile-use agents from human demonstrations. However, these methods focus
solely on the explicit intention flows of humans (e.g., step sequences) while
neglecting implicit intention flows (e.g., personal preferences), which makes
it difficult to construct personalized mobile-use agents. In this work, to
evaluate the \textbf{I}ntention \textbf{A}lignment \textbf{R}ate between
mobile-use agents and humans, we first collect \textbf{MobileIAR}, a dataset
containing human-intent-aligned actions and ground-truth actions. This enables
a comprehensive assessment of the agents' understanding of human intent. Then
we propose \textbf{IFRAgent}, a framework built upon \textbf{I}ntention
\textbf{F}low \textbf{R}ecognition from human demonstrations. IFRAgent analyzes
explicit intention flows from human demonstrations to construct a query-level
vector library of standard operating procedures (SOP), and analyzes implicit
intention flows to build a user-level habit repository. IFRAgent then leverages
a SOP extractor combined with retrieval-augmented generation and a query
rewriter to generate personalized query and SOP from a raw ambiguous query,
enhancing the alignment between mobile-use agents and human intent.
Experimental results demonstrate that IFRAgent outperforms baselines by an
average of 6.79\% (32.06\% relative improvement) in human intention alignment
rate and improves step completion rates by an average of 5.30\% (26.34\%
relative improvement). The codes are available at
https://github.com/MadeAgents/Quick-on-the-Uptake.

</details>


### [98] [LLaMA-Based Models for Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.08649)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 微调LLM（如Orca 2）在复合ABSA任务上表现出色，超越SOTA，但在零样本/少样本场景下仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多种任务中表现出巨大潜力，但其在复合ABSA任务上的表现却落后于微调模型。然而，针对ABSA任务微调LLM的潜力尚未被充分探索。

Method: 本文评估了针对ABSA任务微调的开源LLM（特别是LLaMA系列模型）在四项任务和八个英文数据集上的表现，并进行了错误分析。

Result: 微调后的Orca 2模型在所有测试任务上均超越了现有SOTA结果。但在零样本和少样本场景下，所有模型的表现均不及完全微调的模型。

Conclusion: 微调后的开源LLM在复合ABSA任务上展现出巨大潜力，其中Orca 2模型在所有测试任务上均超越了现有SOTA结果。然而，所有模型在零样本和少样本场景下的表现仍不及完全微调的模型，且在错误分析中暴露出一些挑战。

Abstract: While large language models (LLMs) show promise for various tasks, their
performance in compound aspect-based sentiment analysis (ABSA) tasks lags
behind fine-tuned models. However, the potential of LLMs fine-tuned for ABSA
remains unexplored. This paper examines the capabilities of open-source LLMs
fine-tuned for ABSA, focusing on LLaMA-based models. We evaluate the
performance across four tasks and eight English datasets, finding that the
fine-tuned Orca~2 model surpasses state-of-the-art results in all tasks.
However, all models struggle in zero-shot and few-shot scenarios compared to
fully fine-tuned ones. Additionally, we conduct error analysis to identify
challenges faced by fine-tuned models.

</details>


### [99] [UWB at WASSA-2024 Shared Task 2: Cross-lingual Emotion Detection](https://arxiv.org/abs/2508.08650)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 本研究提出了一种结合量化大语言模型、多语言Transformer模型、低秩适配、机器翻译和触发词切换的跨语言情感检测方法，并在WASSA-2024共享任务中取得了领先的成果。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决WASSA-2024跨语言情感检测共享任务，该任务包括从六种可能类别中为五种语言的推文评估情感标签，以及以二元和数值格式预测触发情感的词语。

Method: 本研究提出了一种结合量化大语言模型（Orca 2）和多语言Transformer模型（XLM-R, mT5）的微调方法，并利用低秩适配（LoRA）技术进行优化。此外，该方法还采用了机器翻译和触发词切换等技术来增强模型在两个子任务上的性能。

Result: 该系统在WASSA-2024跨语言情感检测共享任务中表现出色，在数值触发词检测中获得第一名，二元触发词检测中获得第三名，情感检测中获得第七名。

Conclusion: 该系统在WASSA-2024跨语言情感检测共享任务中取得了优异的成绩，在数值触发词检测中排名第一，二元触发词检测中排名第三，情感检测中排名第七。

Abstract: This paper presents our system built for the WASSA-2024 Cross-lingual Emotion
Detection Shared Task. The task consists of two subtasks: first, to assess an
emotion label from six possible classes for a given tweet in one of five
languages, and second, to predict words triggering the detected emotions in
binary and numerical formats. Our proposed approach revolves around fine-tuning
quantized large language models, specifically Orca~2, with low-rank adapters
(LoRA) and multilingual Transformer-based models, such as XLM-R and mT5. We
enhance performance through machine translation for both subtasks and trigger
word switching for the second subtask. The system achieves excellent
performance, ranking 1st in numerical trigger words detection, 3rd in binary
trigger words detection, and 7th in emotion detection.

</details>


### [100] [Prompt-Based Approach for Czech Sentiment Analysis](https://arxiv.org/abs/2508.08651)
*Jakub Šmíd,Pavel Přibáň*

Main category: cs.CL

TL;DR: This paper presents a new prompt-based approach for sentiment analysis in Czech, outperforming traditional methods, especially with limited data. Pre-training helps even more in zero-shot settings.


<details>
  <summary>Details</summary>
Motivation: To explore prompt-based methods for aspect-based sentiment analysis and sentiment classification in Czech, addressing the limitations of traditional fine-tuning, particularly with limited data.

Method: The paper introduces prompt-based sequence-to-sequence models for aspect-based sentiment analysis and sentiment classification in Czech. It compares this approach to traditional fine-tuning, conducting zero-shot and few-shot learning experiments.

Result: Prompt-based methods show superiority over traditional fine-tuning. In zero-shot and few-shot sentiment classification, prompting yields significantly better results with limited examples. Pre-training on target domain data enhances zero-shot performance.

Conclusion: Prompting methods outperform traditional fine-tuning for Czech aspect-based sentiment analysis and sentiment classification, especially in zero-shot and few-shot scenarios. Pre-training on target domain data further improves zero-shot performance.

Abstract: This paper introduces the first prompt-based methods for aspect-based
sentiment analysis and sentiment classification in Czech. We employ the
sequence-to-sequence models to solve the aspect-based tasks simultaneously and
demonstrate the superiority of our prompt-based approach over traditional
fine-tuning. In addition, we conduct zero-shot and few-shot learning
experiments for sentiment classification and show that prompting yields
significantly better results with limited training examples compared to
traditional fine-tuning. We also demonstrate that pre-training on data from the
target domain can lead to significant improvements in a zero-shot scenario.

</details>


### [101] [LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement](https://arxiv.org/abs/2508.08653)
*Rajmohan C,Sarthak Harne,Arvind Agarwal*

Main category: cs.CL

TL;DR: 提出了一种通过任务分解和迭代自我反馈来改进 LLM 驱动的文本到表格生成的系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在处理不确定的或特定领域的数据、维护表格结构、管理长输入以及进行数字推理时遇到的困难。

Method: 提出了一种高效的 LLM 驱动的文本到表格生成系统，利用了新颖的提示技术，包括将任务分解为可管理的子任务和通过迭代的自我反馈来改进生成的表格。

Result: 该方法允许模型以阶梯式的方式解决问题，并提高了生成表格的质量。

Conclusion: 该方法在两个公开的复杂文本到表格生成数据集上取得了强于基线的结果。

Abstract: Transforming unstructured text into structured data is a complex task,
requiring semantic understanding, reasoning, and structural comprehension.
While Large Language Models (LLMs) offer potential, they often struggle with
handling ambiguous or domain-specific data, maintaining table structure,
managing long inputs, and addressing numerical reasoning. This paper proposes
an efficient system for LLM-driven text-to-table generation that leverages
novel prompting techniques. Specifically, the system incorporates two key
strategies: breaking down the text-to-table task into manageable, guided
sub-tasks and refining the generated tables through iterative self-feedback. We
show that this custom task decomposition allows the model to address the
problem in a stepwise manner and improves the quality of the generated table.
Furthermore, we discuss the benefits and potential risks associated with
iterative self-feedback on the generated tables while highlighting the
trade-offs between enhanced performance and computational cost. Our methods
achieve strong results compared to baselines on two complex text-to-table
generation datasets available in the public domain.

</details>


### [102] [TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation](https://arxiv.org/abs/2508.08680)
*Armel Zebaze,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: LLM在低资源语言翻译方面表现不佳，但可以通过TopXGen生成高质量、多样化的数据来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的低资源语言机器翻译方法，如示例选择和监督微调，其改进效果受到可用平行数据集的大小、质量和多样性的限制。而常用的合成数据创建技术（如反翻译）依赖于高质量、相关的目标语言文本，这在许多低资源语言中难以获得。

Method: 提出了一种名为TopXGen的基于LLM的方法，用于生成低资源语言（LRLs）的高质量和主题多样的数据。该方法首先利用LLM的优势（尤其是在高资源语言上的翻译能力和多语言能力）生成目标语言文本，然后通过反翻译技术生成平行文本，用于LLM的上下文学习和微调。

Result: TopXGen成功提升了LLM在低资源语言机器翻译任务中的性能，无论是在微调还是在上下文学习的场景下。

Conclusion: LLM在低资源语言机器翻译任务中，通过使用TopXGen生成高质量、主题多样的目标语言文本，并进行反翻译，可以显著提升其在模型微调和上下文学习中的翻译性能。

Abstract: LLMs have been shown to perform well in machine translation (MT) with the use
of in-context learning (ICL), rivaling supervised models when translating into
high-resource languages (HRLs). However, they lag behind when translating into
low-resource language (LRLs). Example selection via similarity search and
supervised fine-tuning help. However the improvements they give are limited by
the size, quality and diversity of existing parallel datasets. A common
technique in low-resource MT is synthetic parallel data creation, the most
frequent of which is backtranslation, whereby existing target-side texts are
automatically translated into the source language. However, this assumes the
existence of good quality and relevant target-side texts, which are not readily
available for many LRLs. In this paper, we present \textsc{TopXGen}, an
LLM-based approach for the generation of high quality and topic-diverse data in
multiple LRLs, which can then be backtranslated to produce useful and diverse
parallel texts for ICL and fine-tuning. Our intuition is that while LLMs
struggle to translate into LRLs, their ability to translate well into HRLs and
their multilinguality enable them to generate good quality, natural-sounding
target-side texts, which can be translated well into a high-resource source
language. We show that \textsc{TopXGen} boosts LLM translation performance
during fine-tuning and in-context learning. Code and outputs are available at
https://github.com/ArmelRandy/topxgen.

</details>


### [103] [Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults](https://arxiv.org/abs/2508.08684)
*Bram van Dijk,Tiberon Kuiper,Sirin Aoulad si Ahmed,Armel Levebvre,Jake Johnson,Jan Duin,Simon Mooijaart,Marco Spruit*

Main category: cs.CL

TL;DR: 研究发现，先进的ASR模型在老年荷兰语使用者方面表现良好，无需针对性微调。截断模型有助于提高速度，但需注意幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 语音控制接口可以支持老年人在临床环境中使用，聊天机器人是一个主要例子，但对于代表性不足的群体，可靠的自动语音识别（ASR）仍然是一个瓶颈。

Method: 本研究评估了最先进的ASR模型在老年荷兰语使用者语言使用方面的表现，这些使用者与为老年病学背景设计的Welzijn.AI聊天机器人进行了交互。我们对通用的多语言ASR模型和针对老年荷兰语使用者进行微调的模型进行了基准测试，同时考虑了处理速度。

Result: 研究结果显示，通用的多语言模型优于经过微调的模型，这表明ASR模型能够很好地适应现实数据集。此外，研究结果表明，截断现有架构有助于平衡准确性和速度的权衡，但也发现了一些由于幻觉导致的高词错误率（WER）的情况。

Conclusion: 本研究表明，先进的自动语音识别（ASR）模型能够很好地泛化到老年荷兰语使用者的现实数据集，并且截断现有模型架构有助于平衡准确性-速度的权衡，但仍存在由于幻觉导致的高词错误率（WER）。

Abstract: Voice-controlled interfaces can support older adults in clinical contexts,
with chatbots being a prime example, but reliable Automatic Speech Recognition
(ASR) for underrepresented groups remains a bottleneck. This study evaluates
state-of-the-art ASR models on language use of older Dutch adults, who
interacted with the Welzijn.AI chatbot designed for geriatric contexts. We
benchmark generic multilingual ASR models, and models fine-tuned for Dutch
spoken by older adults, while also considering processing speed. Our results
show that generic multilingual models outperform fine-tuned models, which
suggests recent ASR models can generalise well out of the box to realistic
datasets. Furthermore, our results suggest that truncating existing
architectures is helpful in balancing the accuracy-speed trade-off, though we
also identify some cases with high WER due to hallucinations.

</details>


### [104] [IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization](https://arxiv.org/abs/2508.08719)
*Yuzhuo Bai,Shitong Duan,Muhua Huang,Jing Yao,Zhenghao Liu,Peng Zhang,Tun Lu,Xiaoyuan Yi,Maosong Sun,Xing Xie*

Main category: cs.CL

TL;DR: IRTOE通过提供文本自我反思，克服了LLM模仿人类特质时浅层和不稳定的问题，实现了稳定且可迁移的特质诱导。


<details>
  <summary>Details</summary>
Motivation: 现有方法在诱导LLM模仿人类特质时存在浅层和不稳定的问题，无法精确且一致地实现所需特质。

Method: IRTOE是一种新的上下文方法，通过自动生成和优化包含自我感知经验的文本自我反思来刺激LLM产生由特质驱动的行为。优化过程通过迭代最大化一个信息论目标来实现，该目标旨在增强LLM行为与目标特质之间的联系，同时减少反思中的噪声冗余，且无需进行任何微调。

Result: IRTOE生成的单一自我反思能够稳定地诱导LLM模仿目标特质，并在多样化下游任务（超越简单的问卷回答）中表现出一致性，优于现有基线方法。

Conclusion: IRTOE通过生成和优化文本自我反思来稳定地诱导语言模型（LLM）模仿目标特质，实验表明其在多样化下游任务中表现优于现有方法。

Abstract: Trained on various human-authored corpora, Large Language Models (LLMs) have
demonstrated a certain capability of reflecting specific human-like traits
(e.g., personality or values) by prompting, benefiting applications like
personalized LLMs and social simulations. However, existing methods suffer from
the superficial elicitation problem: LLMs can only be steered to mimic shallow
and unstable stylistic patterns, failing to embody the desired traits precisely
and consistently across diverse tasks like humans. To address this challenge,
we propose IROTE, a novel in-context method for stable and transferable trait
elicitation. Drawing on psychological theories suggesting that traits are
formed through identity-related reflection, our method automatically generates
and optimizes a textual self-reflection within prompts, which comprises
self-perceived experience, to stimulate LLMs' trait-driven behavior. The
optimization is performed by iteratively maximizing an information-theoretic
objective that enhances the connections between LLMs' behavior and the target
trait, while reducing noisy redundancy in reflection without any fine-tuning,
leading to evocative and compact trait reflection. Extensive experiments across
three human trait systems manifest that one single IROTE-generated
self-reflection can induce LLMs' stable impersonation of the target trait
across diverse downstream tasks beyond simple questionnaire answering,
consistently outperforming existing strong baselines.

</details>


### [105] [Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation](https://arxiv.org/abs/2508.08730)
*Weibin Liao,Tianlong Wang,Yinghao Zhu,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.CL

TL;DR: Magical is a new LoRA method for medical lay language generation that improves semantic fidelity and diverse style generation on heterogeneous datasets, outperforming existing methods with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Existing LoRA methods struggle with multi-source heterogeneous MLLG datasets, failing to meet requirements for semantic fidelity and diverse lay-style generation.

Method: Magical employs a shared matrix A for abstractive summarization and multiple isolated matrices B for diverse lay-style generation. It includes a Semantic Invariance Constraint to preserve semantic fidelity and a Recommendation-guided Switch to manage different matrices B.

Result: Experimental results on three real-world datasets show Magical consistently outperforms prompt-based methods, vanilla LoRA, and its variants, reducing trainable parameters by 31.66%.

Conclusion: Magical, an asymmetric LoRA architecture tailored for MLLG under heterogeneous data scenarios, outperforms existing methods and reduces trainable parameters.

Abstract: Medical Lay Language Generation (MLLG) plays a vital role in improving the
accessibility of complex scientific content for broader audiences. Recent
literature to MLLG commonly employ parameter-efficient fine-tuning methods such
as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using
paired expert-lay language datasets. However, LoRA struggles with the
challenges posed by multi-source heterogeneous MLLG datasets. Specifically,
through a series of exploratory experiments, we reveal that standard LoRA fail
to meet the requirement for semantic fidelity and diverse lay-style generation
in MLLG task. To address these limitations, we propose Magical, an asymmetric
LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical
employs a shared matrix $A$ for abstractive summarization, along with multiple
isolated matrices $B$ for diverse lay-style generation. To preserve semantic
fidelity during the lay language generation process, Magical introduces a
Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix
$A$. Furthermore, to better adapt to diverse lay-style generation, Magical
incorporates the Recommendation-guided Switch, an externally interface to
prompt the LLM to switch between different matrices $B$. Experimental results
on three real-world lay language generation datasets demonstrate that Magical
consistently outperforms prompt-based methods, vanilla LoRA, and its recent
variants, while also reducing trainable parameters by 31.66%.

</details>


### [106] [SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs](https://arxiv.org/abs/2508.08742)
*Haotian Chen,Qingqing Long,Meng Xiao,Xiao Luo,Wei Ju,Chengrui Wang,Xuezhi Wang,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.CL

TL;DR: A new benchmark, SciRerankBench, evaluates rerankers in RAG-LLMs for scientific QA, identifying strengths and weaknesses of existing models.


<details>
  <summary>Details</summary>
Motivation: To explore the potential and limitations of two-stage retrieval-augmented generated large language models (RAG-LLMs) in scientific literature question answering, particularly the reranker stage, which is crucial for handling subtle terminology differences in factual-oriented answers.

Method: Developed SciRerankBench, a benchmark for evaluating rerankers in RAG-LLMs, comprising three types of Q-C-A pairs (Noisy Contexts, Semantically Similar but Logically Irrelevant Contexts, Counterfactual Contexts) across five scientific subjects. Systematically evaluated 13 rerankers on five LLM families.

Result: Provided detailed insights into the strengths and limitations of 13 widely used rerankers through systematic evaluation.

Conclusion: SciRerankBench is the first benchmark for evaluating rerankers in RAG-LLMs, providing insights and guidance for future development.

Abstract: Scientific literature question answering is a pivotal step towards new
scientific discoveries. Recently, \textit{two-stage} retrieval-augmented
generated large language models (RAG-LLMs) have shown impressive advancements
in this domain. Such a two-stage framework, especially the second stage
(reranker), is particularly essential in the scientific domain, where subtle
differences in terminology may have a greatly negative impact on the final
factual-oriented or knowledge-intensive answers. Despite this significant
progress, the potential and limitations of these works remain unexplored. In
this work, we present a Scientific Rerank-oriented RAG Benchmark
(SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning
five scientific subjects. To rigorously assess the reranker performance in
terms of noise resilience, relevance disambiguation, and factual consistency,
we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy
Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI),
and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely
used rerankers on five families of LLMs, we provide detailed insights into
their relative strengths and limitations. To the best of our knowledge,
SciRerankBench is the first benchmark specifically developed to evaluate
rerankers within RAG-LLMs, which provides valuable observations and guidance
for their future development.

</details>


### [107] [DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation](https://arxiv.org/abs/2508.08761)
*Stavros Doropoulos,Stavros Vologiannidis,Ioannis Magnisalis*

Main category: cs.CL

TL;DR: DevNous 是一个基于 LLM 的多智能体系统，可以自动将非结构化团队对话转换为结构化的 IT 项目管理信息，并在新的基准测试中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 现代信息系统管理中的一个关键瓶颈是将非结构化的团队对话手动翻译成信息技术 (IT) 项目治理所需的结构化工件。

Method: DevNous 是一个基于大语言模型 (LLM) 的多智能体专家系统，用于自动化将非结构化对话转化为结构化项目治理工件的过程。它集成到团队聊天环境中，识别非正式对话中的可操作意图，并管理状态化的多轮工作流以完成诸如自动化任务形式化和进度摘要综合等核心管理任务。

Result: DevNous 在新基准测试中实现了 81.3% 的精确匹配轮次准确率和 0.845 的多集 F1 分数。

Conclusion: DevNous 在新基准测试中实现了 81.3% 的精确匹配轮次准确率和 0.845 的多集 F1 分数，证明了其可行性。

Abstract: The manual translation of unstructured team dialogue into the structured
artifacts required for Information Technology (IT) project governance is a
critical bottleneck in modern information systems management. We introduce
DevNous, a Large Language Model-based (LLM) multi-agent expert system, to
automate this unstructured-to-structured translation process. DevNous
integrates directly into team chat environments, identifying actionable intents
from informal dialogue and managing stateful, multi-turn workflows for core
administrative tasks like automated task formalization and progress summary
synthesis. To quantitatively evaluate the system, we introduce a new benchmark
of 160 realistic, interactive conversational turns. The dataset was manually
annotated with a multi-label ground truth and is publicly available. On this
benchmark, DevNous achieves an exact match turn accuracy of 81.3\% and a
multiset F1-Score of 0.845, providing strong evidence for its viability. The
primary contributions of this work are twofold: (1) a validated architectural
pattern for developing ambient administrative agents, and (2) the introduction
of the first robust empirical baseline and public benchmark dataset for this
challenging problem domain.

</details>


### [108] [Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering](https://arxiv.org/abs/2508.08785)
*Yunfeng Ning,Mayi Xu,Jintao Wen,Qiankun Pi,Yuanyuan Zhu,Ming Zhong,Jiawei Jiang,Tieyun Qian*

Main category: cs.CL

TL;DR: ARoG框架通过关系中心抽象和结构导向抽象策略，解决了在LLM实体匿名化的情况下，RAG系统利用私有知识图谱进行有效检索的隐私和技术挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决在RAG系统中利用私有知识图谱（KGs）带来的隐私风险，特别是当LLM实体匿名化时，检索相关的知识。

Method: 提出了一种名为ARoG的新框架，包含关系中心抽象和结构导向抽象策略，以解决匿名实体知识检索的挑战。

Result: ARoG框架能够有效地将匿名实体转化为可检索的信息，并通过将问题转化为结构化路径来检索与问题相关的匿名实体，实验证明了其有效性。

Conclusion: ARoG框架在隐私保护的RAG场景下实现了强大的性能和隐私鲁棒性。

Abstract: LLMs often suffer from hallucinations and outdated or incomplete knowledge.
RAG is proposed to address these issues by integrating external knowledge like
that in KGs into LLMs. However, leveraging private KGs in RAG systems poses
significant privacy risks due to the black-box nature of LLMs and potential
insecure data transmission, especially when using third-party LLM APIs lacking
transparency and control. In this paper, we investigate the privacy-protected
RAG scenario for the first time, where entities in KGs are anonymous for LLMs,
thus preventing them from accessing entity semantics. Due to the loss of
semantics of entities, previous RAG systems cannot retrieve question-relevant
knowledge from KGs by matching questions with the meaningless identifiers of
anonymous entities. To realize an effective RAG system in this scenario, two
key challenges must be addressed: (1) How can anonymous entities be converted
into retrievable information. (2) How to retrieve question-relevant anonymous
entities. Hence, we propose a novel ARoG framework including relation-centric
abstraction and structure-oriented abstraction strategies. For challenge (1),
the first strategy abstracts entities into high-level concepts by dynamically
capturing the semantics of their adjacent relations. It supplements meaningful
semantics which can further support the retrieval process. For challenge (2),
the second strategy transforms unstructured natural language questions into
structured abstract concept paths. These paths can be more effectively aligned
with the abstracted concepts in KGs, thereby improving retrieval performance.
To guide LLMs to effectively retrieve knowledge from KGs, the two strategies
strictly protect privacy from being exposed to LLMs. Experiments on three
datasets demonstrate that ARoG achieves strong performance and
privacy-robustness.

</details>


### [109] [Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments](https://arxiv.org/abs/2508.08791)
*Junjie Ye,Changhao Jiang,Zhengyin Du,Yufei Xu,Xuesong Yao,Zhiheng Xi,Xiaoran Fan,Qi Zhang,Xuanjing Huang,Jiecao Chen*

Main category: cs.CL

TL;DR: 本研究提出了一种自动化的环境构建流程和可验证的奖励机制，以解决大型语言模型（LLMs）在工具使用方面的强化学习（RL）挑战，并实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在与环境进行有意义的交互时，有效的工具使用至关重要。然而，由于缺乏专门为工具使用设计的有效强化学习（RL）框架，以及稳定训练环境构建和可验证奖励机制设计的挑战，这方面的进展受到限制。

Method: 提出了一种自动化的环境构建流程，包括场景分解、文档生成、函数集成、复杂度扩展和本地化部署。同时，引入了一种可验证的奖励机制，用于评估工具使用的精确度和任务完成的完整性。

Result: 构建了高质量的训练环境，提供了详细且可衡量的反馈，无需依赖外部工具。该方法能够显著提升LLMs的工具使用性能。

Conclusion: 实验表明，该方法在不同规模的语言模型上显著提高了其工具使用性能，且不影响其通用能力，无论是在推理模式还是训练算法上。分析表明，这些改进源于上下文理解和推理能力的提升，这得益于模型底层MLP参数的更新。

Abstract: Effective tool use is essential for large language models (LLMs) to interact
meaningfully with their environment. However, progress is limited by the lack
of efficient reinforcement learning (RL) frameworks specifically designed for
tool use, due to challenges in constructing stable training environments and
designing verifiable reward mechanisms. To address this, we propose an
automated environment construction pipeline, incorporating scenario
decomposition, document generation, function integration, complexity scaling,
and localized deployment. This enables the creation of high-quality training
environments that provide detailed and measurable feedback without relying on
external tools. Additionally, we introduce a verifiable reward mechanism that
evaluates both the precision of tool use and the completeness of task
execution. When combined with trajectory data collected from the constructed
environments, this mechanism integrates seamlessly with standard RL algorithms
to facilitate feedback-driven model training. Experiments on LLMs of varying
scales demonstrate that our approach significantly enhances the models'
tool-use performance without degrading their general capabilities, regardless
of inference modes or training algorithms. Our analysis suggests that these
gains result from improved context understanding and reasoning, driven by
updates to the lower-layer MLP parameters in models.

</details>


### [110] [TiMoE: Time-Aware Mixture of Language Experts](https://arxiv.org/abs/2508.08827)
*Robin Faro,Dongyang Fan,Tamar Alphaidze,Martin Jaggi*

Main category: cs.CL

TL;DR: LLM 训练数据过时，存在时间泄漏问题。我们提出了 TiMoE，一种时间感知专家混合模型，通过结合不同时间段训练的专家来解决此问题。TiMoE 确保模型只使用查询时间之前的信息，并在保持性能的同时减少时间错误。我们还发布了 TSQA 基准测试来评估时间幻觉。实验。


<details>
  <summary>Details</summary>
Motivation: LLM 通常在固定的 Web 快照上进行训练，导致知识陈旧并存在时间泄漏风险，即依赖于相对于查询的未来信息。

Method: 通过 TiMoE（一种时间感知语言专家混合模型）结合在 2013-2024 年语料库不重叠时间段上预训练的 GPT 风格专家，来解决 LLM 知识陈旧和时间泄漏问题。在推理时，TiMoE 会屏蔽训练窗口晚于查询时间戳的专家，并在共享空间中合并剩余的对数概率，确保严格的因果有效性并保留多时期知识的广度。

Result: 在八项标准 NLP 任务和 TSQA 基准测试中，TiMoE 的协同适应变体性能匹配或超过了最佳的单时期专家，并将未来知识错误减少了高达 15%。

Conclusion: LLMs 的模块化、时间分段预训练与因果路由是实现 LLM 时间一致性且不显著牺牲通用性能的有效途径。

Abstract: Large language models (LLMs) are typically trained on fixed snapshots of the
web, which means that their knowledge becomes stale and their predictions risk
temporal leakage: relying on information that lies in the future relative to a
query. We tackle this problem by pre-training from scratch a set of GPT-style
experts on disjoint two-year slices of a 2013-2024 corpus and combining them
through TiMoE, a Time-aware Mixture of Language Experts. At inference time,
TiMoE masks all experts whose training window ends after the query timestamp
and merges the remaining log-probabilities in a shared space, guaranteeing
strict causal validity while retaining the breadth of multi-period knowledge.
We also release TSQA, a 10k-question benchmark whose alternatives are
explicitly labelled as past, future or irrelevant, allowing fine-grained
measurement of temporal hallucinations. Experiments on eight standard NLP tasks
plus TSQA show that a co-adapted TiMoE variant matches or exceeds the best
single-period expert and cuts future-knowledge errors by up to 15%. Our results
demonstrate that modular, time-segmented pre-training paired with causal
routing is a simple yet effective path toward LLMs that stay chronologically
grounded without sacrificing general performance much. We open source our code
at TiMoE (Github): https://github.com/epfml/TiMoE

</details>


### [111] [An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems](https://arxiv.org/abs/2508.08833)
*Yuren Hao,Xiang Wan,Chengxiang Zhai*

Main category: cs.CL

TL;DR: 提出了一种新的框架和数据集PutnamGAP来评估LLM的数学推理鲁棒性，发现现有模型在面对经过语言和参数变化的等价数学问题时性能会显著下降。


<details>
  <summary>Details</summary>
Motivation: 为了评估LLM在面对非数学扰动时的敏感度，从而更准确地评估其数学推理能力，需要一种超越传统方法的系统性框架。

Method: 提出了一种系统性框架，通过对具有语言和参数变化的数学上等价的高级数学问题进行压力测试，来评估LLM的数学推理鲁棒性。创建了一个包含竞赛级别数学问题多个数学上等价变体的基准数据集PutnamGAP。

Result: 在18个商业和开源模型上进行的评估显示，模型在面对变体问题时性能急剧下降。例如，O3模型在原始问题上的得分率为49%，但在表面变体问题上下降了4个百分点，在核心步骤变体问题上则下降了10.5个百分点，而较小的模型表现更差。

Conclusion: 该研究提出的评估方法能有效加深对LLM数学推理鲁棒性的理解，并为进一步改进其能力提供新的见解。

Abstract: In this paper, we introduce a systematic framework beyond conventional method
to assess LLMs' mathematical-reasoning robustness by stress-testing them on
advanced math problems that are mathematically equivalent but with linguistic
and parametric variation. These transformations allow us to measure the
sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more
accurate evaluation of their mathematical reasoning capabilities. Using this
new evaluation methodology, we created PutnamGAP, a new benchmark dataset with
multiple mathematically-equivalent variations of competition-level math
problems. With the new dataset, we evaluate multiple families of representative
LLMs and examine their robustness. Across 18 commercial and open-source models
we observe sharp performance degradation on the variants. OpenAI's flagship
reasoning model, O3, scores 49 % on the originals but drops by 4 percentage
points on surface variants, and by 10.5 percentage points on core-step-based
variants, while smaller models fare far worse. Overall, the results show that
the proposed new evaluation methodology is effective for deepening our
understanding of the robustness of LLMs and generating new insights for further
improving their mathematical reasoning capabilities.

</details>


### [112] [Steering Towards Fairness: Mitigating Political Bias in LLMs](https://arxiv.org/abs/2508.08846)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR:  LLMs encode ideological biases. This paper proposes a framework using the Political Compass Test and contrastive learning on model activations to probe and mitigate these biases in LLMs like Mistral and DeepSeek, showing they systematically encode bias that can be reduced.


<details>
  <summary>Details</summary>
Motivation:  LLMs have concerns about their tendency to encode and reproduce ideological biases, particularly along political and economic dimensions.

Method:  Grounded in the Political Compass Test (PCT), our method uses contrastive pairs to extract and compare hidden layer activations from models like Mistral and DeepSeek. We introduce a comprehensive activation extraction pipeline capable of layer-wise analysis across multiple ideological axes, revealing meaningful disparities linked to political framing.

Result:  Our results show that decoder LLMs systematically encode representational bias across layers, which can be leveraged for effective steering vector-based mitigation.

Conclusion:  decoder LLMs systematically encode representational bias across layers, which can be leveraged for effective steering vector-based mitigation. This work provides new insights into how political bias is encoded in LLMs and offers a principled approach to debiasing beyond surface-level output interventions.

Abstract: Recent advancements in large language models (LLMs) have enabled their
widespread use across diverse real-world applications. However, concerns remain
about their tendency to encode and reproduce ideological biases, particularly
along political and economic dimensions. In this paper, we propose a framework
for probing and mitigating such biases in decoder-based LLMs through analysis
of internal model representations. Grounded in the Political Compass Test
(PCT), our method uses contrastive pairs to extract and compare hidden layer
activations from models like Mistral and DeepSeek. We introduce a comprehensive
activation extraction pipeline capable of layer-wise analysis across multiple
ideological axes, revealing meaningful disparities linked to political framing.
Our results show that decoder LLMs systematically encode representational bias
across layers, which can be leveraged for effective steering vector-based
mitigation. This work provides new insights into how political bias is encoded
in LLMs and offers a principled approach to debiasing beyond surface-level
output interventions.

</details>


### [113] [BiasGym: Fantastic Biases and How to Find (and Remove) Them](https://arxiv.org/abs/2508.08855)
*Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein*

Main category: cs.CL

TL;DR: BiasGym is a new framework to inject, analyze, and mitigate biases in LLMs. It helps identify and fix biased behavior without harming performance and works even for biases not seen during training.


<details>
  <summary>Details</summary>
Motivation: Understanding and mitigating biases and stereotypes encoded in LLMs is crucial, but biased behavior is often subtle and challenging to isolate, making systematic analysis and debiasing difficult.

Method: BiasGym is a framework with two components: BiasInject, which injects specific biases into LLMs via token-based fine-tuning while keeping the model frozen, and BiasScope, which uses these injected signals to identify and steer the components responsible for biased behavior.

Result: BiasGym effectively reduces real-world stereotypes (e.g., people from a country being `reckless drivers') and probes fictional associations (e.g., people from a country having `blue skin').

Conclusion: BiasGym enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during training. It is effective in reducing real-world stereotypes and probing fictional associations, showing its utility for both safety interventions and interpretability research.

Abstract: Understanding biases and stereotypes encoded in the weights of Large Language
Models (LLMs) is crucial for developing effective mitigation strategies. Biased
behaviour is often subtle and non-trivial to isolate, even when deliberately
elicited, making systematic analysis and debiasing particularly challenging. To
address this, we introduce BiasGym, a simple, cost-effective, and generalizable
framework for reliably injecting, analyzing, and mitigating conceptual
associations within LLMs. BiasGym consists of two components: BiasInject, which
injects specific biases into the model via token-based fine-tuning while
keeping the model frozen, and BiasScope, which leverages these injected signals
to identify and steer the components responsible for biased behavior. Our
method enables consistent bias elicitation for mechanistic analysis, supports
targeted debiasing without degrading performance on downstream tasks, and
generalizes to biases unseen during training. We demonstrate the effectiveness
of BiasGym in reducing real-world stereotypes (e.g., people from a country
being `reckless drivers') and in probing fictional associations (e.g., people
from a country having `blue skin'), showing its utility for both safety
interventions and interpretability research.

</details>


### [114] [Weakly Supervised Fine-grained Span-Level Framework for Chinese Radiology Report Quality Assurance](https://arxiv.org/abs/2508.08876)
*Kaiyu Wang,Lin Mu,Zhiyao Yang,Ximing Li,Xiaotang Zhou Wanfu Gao,Huimao Zhang*

Main category: cs.CL

TL;DR: Sqator is a model that automatically marks QA scores for radiology reports by analyzing fine-grained text spans, addressing the labor costs and potential inaccuracies of manual QA.


<details>
  <summary>Details</summary>
Motivation: Quality Assurance (QA) for radiology reports requires intensive labor costs for senior doctors. Additionally, the QA scores may be inaccurate for reasons like diagnosis bias, the ability of senior doctors, and so on. To address this issue, we propose a Span-level Quality Assurance EvaluaTOR (Sqator) to mark QA scores automatically.

Method: Sqator measures QA scores by measuring the importance of revised spans between junior and senior reports, and outputs the final QA scores by merging all revised span scores.

Result: Sqator can achieve competitive QA scores. Moreover, the importance scores of revised spans can be also consistent with the judgments of senior doctors.

Conclusion: Sqator

Abstract: Quality Assurance (QA) for radiology reports refers to judging whether the
junior reports (written by junior doctors) are qualified. The QA scores of one
junior report are given by the senior doctor(s) after reviewing the image and
junior report. This process requires intensive labor costs for senior doctors.
Additionally, the QA scores may be inaccurate for reasons like diagnosis bias,
the ability of senior doctors, and so on. To address this issue, we propose a
Span-level Quality Assurance EvaluaTOR (Sqator) to mark QA scores
automatically. Unlike the common document-level semantic comparison method, we
try to analyze the semantic difference by exploring more fine-grained text
spans. Unlike the common document-level semantic comparison method, we try to
analyze the semantic difference by exploring more fine-grained text spans.
Specifically, Sqator measures QA scores by measuring the importance of revised
spans between junior and senior reports, and outputs the final QA scores by
merging all revised span scores. We evaluate Sqator using a collection of
12,013 radiology reports. Experimental results show that Sqator can achieve
competitive QA scores. Moreover, the importance scores of revised spans can be
also consistent with the judgments of senior doctors.

</details>


### [115] [Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models](https://arxiv.org/abs/2508.08879)
*Haeun Yu,Seogyeong Jeong,Siddhesh Pawar,Jisu Shin,Jiho Jin,Junho Myung,Alice Oh,Isabelle Augenstein*

Main category: cs.CL

TL;DR: Culturescope通过探测LLM内部表征来分析文化偏见，发现LLM存在西方主导偏见和文化扁平化，而低资源文化受偏见影响较小。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解LLM在不同文化背景下的表现，以及LLM内部机制如何导致文化（错误）表征，弥补了以往仅进行外在评估的不足。

Method: 提出了一种名为Culturescope的机制可解释性方法，通过探测LLM的内部表征来提取文化知识，并引入文化扁平化得分作为衡量内在文化偏见的指标。

Result: 实验结果表明，LLM在文化知识空间中编码了西方主导偏见和文化扁平化，低资源文化不太容易受到文化偏见的影响。

Conclusion: LLM在文化知识空间中编码了西方主导偏见和文化扁平化，低资源文化不太容易受到文化偏见的影响，这可能是由于其有限的训练资源。该研究为未来减轻文化偏见和增强LLM的文化理解能力奠定了基础。

Abstract: The growing deployment of large language models (LLMs) across diverse
cultural contexts necessitates a better understanding of how the
overgeneralization of less documented cultures within LLMs' representations
impacts their cultural understanding. Prior work only performs extrinsic
evaluation of LLMs' cultural competence, without accounting for how LLMs'
internal mechanisms lead to cultural (mis)representation. To bridge this gap,
we propose Culturescope, the first mechanistic interpretability-based method
that probes the internal representations of LLMs to elicit the underlying
cultural knowledge space. CultureScope utilizes a patching method to extract
the cultural knowledge. We introduce a cultural flattening score as a measure
of the intrinsic cultural biases. Additionally, we study how LLMs internalize
Western-dominance bias and cultural flattening, which allows us to trace how
cultural biases emerge within LLMs. Our experimental results reveal that LLMs
encode Western-dominance bias and cultural flattening in their cultural
knowledge space. We find that low-resource cultures are less susceptible to
cultural biases, likely due to their limited training resources. Our work
provides a foundation for future research on mitigating cultural biases and
enhancing LLMs' cultural understanding. Our codes and data used for experiments
are publicly available.

</details>


### [116] [ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs](https://arxiv.org/abs/2508.08895)
*Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun*

Main category: cs.CL

TL;DR: ASPD通过并行化LLM的自回归解码过程，在不损害模型性能的情况下显著提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）的自回归解码范式带来的高推理延迟问题，作者发现了模型输出中存在的内在并行性。

Method: 提出了一种自适应串行-并行解码（ASPD）方法，包括自动提取和验证可并行化结构，以及一个能够实现串行和并行解码模式无缝切换并复用KV缓存的混合解码引擎。

Result: ASPD在通用任务、检索增强生成和数学推理任务上均表现出优越的性能和效率。在Vicuna Bench上，实现了高达3.19倍（平均1.85倍）的加速，同时响应质量损失在1%以内。

Conclusion: ASPD通过自适应串行-并行解码在LLM推理中实现了显著的加速，同时保持了响应质量，为延迟敏感应用铺平了道路。

Abstract: The increasing scale and complexity of large language models (LLMs) pose
significant inference latency challenges, primarily due to their autoregressive
decoding paradigm characterized by the sequential nature of next-token
prediction. By re-examining the outputs of autoregressive models, we observed
that some segments exhibit parallelizable structures, which we term intrinsic
parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel
decoding) can significantly improve the overall inference speed of LLMs. In
this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which
addresses two core challenges: automated construction of parallelizable data
and efficient parallel decoding mechanism. More specifically, we introduce a
non-invasive pipeline that automatically extracts and validates parallelizable
structures from the responses of autoregressive models. To empower efficient
adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which
enables seamless transitions between serial and parallel decoding modes while
maintaining a reusable KV cache, maximizing computational efficiency. Extensive
evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical
Reasoning, demonstrate that ASPD achieves unprecedented performance in both
effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up
to 3.19x speedup (1.85x on average) while maintaining response quality within
1% difference compared to autoregressive models, realizing significant
acceleration without compromising generation quality. Our framework sets a
groundbreaking benchmark for efficient LLM parallel inference, paving the way
for its deployment in latency-sensitive applications such as AI-powered
customer service bots and answer retrieval engines.

</details>


### [117] [Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning](https://arxiv.org/abs/2508.08912)
*Mahmoud Salhab,Shameed Sait,Mohammad Abusheikh,Hasan Abusheikh*

Main category: cs.CL

TL;DR: 针对数据稀疏和语言复杂性问题，通过结合弱监督学习和微调，成功开发了高质量的阿拉伯语自动语音识别模型，并在相关竞赛中取得领先地位。


<details>
  <summary>Details</summary>
Motivation: 开发准确的阿拉伯语自动语音识别系统是一个重大挑战，因为其标记数据有限，并且存在多种方言导致的语言复杂性。

Method: 本研究提出了一种可扩展的训练流程，结合了弱监督学习和监督微调，用于开发强大的阿拉伯语自动语音识别模型。首先，在包含现代标准阿拉伯语和多种方言阿拉伯语的15000小时弱标注语音数据上对模型进行预训练。随后，在过滤后的弱标注数据和少量高质量标注数据集的混合数据上，进行持续的监督微调。

Result: 该方法在多方言阿拉伯语自动语音识别挑战赛中取得了最先进的成果，排名第一。

Conclusion: 本研究展示了弱监督学习与微调相结合的方法能够有效克服数据稀疏性问题，并为低资源、多方言的语言提供高质量的自动语音识别。

Abstract: Automatic speech recognition (ASR) plays a vital role in enabling natural
human-machine interaction across applications such as virtual assistants,
industrial automation, customer support, and real-time transcription. However,
developing accurate ASR systems for low-resource languages like Arabic remains
a significant challenge due to limited labeled data and the linguistic
complexity introduced by diverse dialects. In this work, we present a scalable
training pipeline that combines weakly supervised learning with supervised
fine-tuning to develop a robust Arabic ASR model. In the first stage, we
pretrain the model on 15,000 hours of weakly labeled speech covering both
Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the
subsequent stage, we perform continual supervised fine-tuning using a mixture
of filtered weakly labeled data and a small, high-quality annotated dataset.
Our approach achieves state-of-the-art results, ranking first in the
multi-dialectal Arabic ASR challenge. These findings highlight the
effectiveness of weak supervision paired with fine-tuning in overcoming data
scarcity and delivering high-quality ASR for low-resource, dialect-rich
languages.

</details>


### [118] [Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation](https://arxiv.org/abs/2508.08933)
*Khondoker Ittehadul Islam,Gabriele Sarti*

Main category: cs.CL

TL;DR: 一项关于评估语言模型在孟加拉语多步推理任务中的表现的研究。


<details>
  <summary>Details</summary>
Motivation: 语言模型在复杂的多步推理任务方面表现出色，但它们的评估主要局限于英语等高资源语言。在本研究中，我们引入了一个源自英文Reveal数据集的手动翻译的孟加拉文多步推理数据集，其中包含二元和非二元问题类型。

Method: 我们进行了一项对照评估，评估了英语中心和孟加拉语中心的英语和孟加拉语多语言小型语言模型在原始数据集和我们翻译的版本上的表现，以比较它们利用相关推理步骤产生正确答案的能力。

Result: 研究结果表明，在可比设置下，推理上下文对更具挑战性的非二元问题有益，但模型难以有效利用相关的孟加拉语推理步骤。

Conclusion: 研究表明，在可比设置下，推理上下文对更具挑战性的非二元问题有益，但模型难以有效利用相关的孟加拉语推理步骤。最后，我们探讨了推理步骤如何促成模型的预测，并强调了不同模型和语言之间的不同趋势。

Abstract: Language models have demonstrated remarkable performance on complex
multi-step reasoning tasks. However, their evaluation has been predominantly
confined to high-resource languages such as English. In this paper, we
introduce a manually translated Bangla multi-step reasoning dataset derived
from the English Reveal dataset, featuring both binary and non-binary question
types. We conduct a controlled evaluation of English-centric and Bangla-centric
multilingual small language models on the original dataset and our translated
version to compare their ability to exploit relevant reasoning steps to produce
correct answers. Our results show that, in comparable settings, reasoning
context is beneficial for more challenging non-binary questions, but models
struggle to employ relevant Bangla reasoning steps effectively. We conclude by
exploring how reasoning steps contribute to models' predictions, highlighting
different trends across models and languages.

</details>


### [119] [Train Long, Think Short: Curriculum Learning for Efficient Reasoning](https://arxiv.org/abs/2508.08940)
*Hasan Abed Al Kader Hammoud,Kumail Alhamoud,Abed Hammoud,Elie Bou-Zeid,Marzyeh Ghassemi,Bernard Ghanem*

Main category: cs.CL

TL;DR: 通过分组相对策略优化（GRPO）和课程学习策略，逐步收紧代币预算，以提高LLM的推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于固定的长度训练预算，未能利用学习过程中从探索到压缩的自然进展。

Method: 使用分组相对策略优化（GRPO）的课程学习策略，并结合任务正确性（通过验证器反馈）、长度效率和格式依从性（通过结构标签）的奖励函数。

Result: 实验表明，课程学习策略在GSM8K、MATH500、SVAMP、College Math和GSM+上一致优于固定预算基线。

Conclusion: 课程学习策略在固定预算基线上表现更好，在相同的最终预算下实现了更高的准确性和显著提高的代币效率。

Abstract: Recent work on enhancing the reasoning abilities of large language models
(LLMs) has introduced explicit length control as a means of constraining
computational cost while preserving accuracy. However, existing approaches rely
on fixed-length training budgets, which do not take advantage of the natural
progression from exploration to compression during learning. In this work, we
propose a curriculum learning strategy for length-controlled reasoning using
Group Relative Policy Optimization (GRPO). Our method starts with generous
token budgets and gradually tightens them over training, encouraging models to
first discover effective solution strategies and then distill them into more
concise reasoning traces. We augment GRPO with a reward function that balances
three signals: task correctness (via verifier feedback), length efficiency, and
formatting adherence (via structural tags). Experiments on GSM8K, MATH500,
SVAMP, College Math, and GSM+ demonstrate that curriculum-based training
consistently outperforms fixed-budget baselines at the same final budget,
achieving higher accuracy and significantly improved token efficiency. We
further ablate the impact of reward weighting and decay schedule design,
showing that progressive constraint serves as a powerful inductive bias for
training efficient reasoning models. Our code and checkpoints are released at:
https://github.com/hammoudhasan/curriculum_grpo.

</details>


### [120] [Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens](https://arxiv.org/abs/2508.08942)
*Lucas Albarede,Jose Moreno,Lynda Tamine,Luce Lefeuvre*

Main category: cs.CL

TL;DR: LoDIT 是一种在 RAG 中联合生成答案和进行忠实归因的新方法，通过利用生成过程中的 token logits 来估计文档贡献，解决了现有方法的延迟和对齐问题，并在实验中取得了优于 SOTA 的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在生成答案时容易出现幻觉，以及现有方法在提高忠实度方面存在额外延迟和对齐 token 生成与归因生成存在局限性的问题。

Method: LoDIT 方法包括两个步骤：(1) 使用特定的 token 标识符标记文档，并利用这些 token 的 logits 来估计每个文档在生成过程中对答案的贡献；(2) 将这些贡献聚合为文档归因。

Result: LoDIT 在 Trust-Align 基准测试上显著优于最先进的模型，并在延迟和鲁棒性方面表现出效率和稳健性。

Conclusion: LoDIT 方法在 RAG 中通过利用生成过程中的特定 token logits，能够联合生成答案并忠实地归因，显著优于最先进的模型，并且在延迟和鲁棒性方面表现出效率和稳健性。

Abstract: Despite their impressive performances, Large Language Models (LLMs) remain
prone to hallucination, which critically undermines their trustworthiness.
While most of the previous work focused on tackling answer and attribution
correctness, a recent line of work investigated faithfulness, with a focus on
leveraging internal model signals to reflect a model's actual decision-making
process while generating the answer. Nevertheless, these methods induce
additional latency and have shown limitations in directly aligning token
generation with attribution generation. In this paper, we introduce LoDIT, a
method that jointly generates and faithfully attributes answers in RAG by
leveraging specific token logits during generation. It consists of two steps:
(1) marking the documents with specific token identifiers and then leveraging
the logits of these tokens to estimate the contribution of each document to the
answer during generation, and (2) aggregating these contributions into document
attributions. Experiments on a trustworthiness-focused attributed
text-generation benchmark, Trust-Align, show that LoDIT significantly
outperforms state-of-the-art models on several metrics. Finally, an in-depth
analysis of LoDIT shows both its efficiency in terms of latency and its
robustness in different settings.

</details>


### [121] [Retrospective Sparse Attention for Efficient Long-Context Generation](https://arxiv.org/abs/2508.09001)
*Seonghwan Choi,Beomseok Kang,Dongwon Jo,Jae-Joon Kim*

Main category: cs.CL

TL;DR: RetroAttention通过回顾性更新KV缓存来提高长上下文任务的效率和准确性，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 长上下文任务中的KV缓存内存占用随序列长度线性增长，并在每个解码步骤中成为延迟瓶颈。现有的KV缓存压缩方法主要关注输入上下文，未能解决长解码过程中累积的注意力错误。

Method: RetroAttention是一种新颖的KV缓存更新技术，它利用后续解码步骤中新到达的KV条目来回顾性地修改过去的注意力输出。

Result: RetroAttention在长文本生成基准测试中表现优于最先进的KV压缩方法，有效KV暴露率提高高达1.6倍，准确率提高高达21.9%。

Conclusion: RetroAttention通过回顾性地修改过去的注意力输出来解决长上下文任务中的KV缓存瓶颈，并取得了优于最先进KV压缩方法的成果。

Abstract: Large Language Models (LLMs) are increasingly deployed in long-context tasks
such as reasoning, code generation, and multi-turn dialogue. However, inference
over extended contexts is bottlenecked by the Key-Value (KV) cache, whose
memory footprint grows linearly with sequence length and dominates latency at
each decoding step. While recent KV cache compression methods identify and load
important tokens, they focus predominantly on input contexts and fail to
address the cumulative attention errors that arise during long decoding. In
this paper, we introduce RetroAttention, a novel KV cache update technique that
retrospectively revises past attention outputs using newly arrived KV entries
from subsequent decoding steps. By maintaining a lightweight output cache,
RetroAttention enables past queries to efficiently access more relevant
context, while incurring minimal latency overhead. This breaks the
fixed-attention-output paradigm and allows continual correction of prior
approximations. Extensive experiments on long-generation benchmarks show that
RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression
methods, increasing effective KV exposure by up to 1.6$\times$ and accuracy by
up to 21.9\%.

</details>


### [122] [LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA](https://arxiv.org/abs/2508.09012)
*Adrián Gude,Roi Santos-Ríos,Francisco Prado-Valiño,Ana Ezquerro,Jesús Vilares*

Main category: cs.CL

TL;DR: 本研究提出了一种零样本表格问答方法，利用大型语言模型生成代码，并通过迭代优化提高鲁棒性，在SemEval 2025 Task 8中取得了第33名的成绩。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索零样本学习在表格问答任务中的应用，并通过开发一个利用大型语言模型生成代码的流水线来解决表格数据提取的挑战。

Method: 我们开发了一个零样本流水线，利用大型语言模型生成功能代码，根据输入问题从表格数据中提取相关信息。该方法包括一个代码生成模块，并辅以识别最相关列和分析其数据类型的组件以提高提取准确性。当生成的代码失败时，会触发一个迭代细化过程，将错误反馈纳入新的生成提示中以增强鲁棒性。

Result: 零样本代码生成是一种可行的表格问答方法，在测试阶段取得了第33名的成绩（共53个队伍），证明了该方法在没有特定任务微调情况下的潜力。

Conclusion: 零样本代码生成是一种可行的表格问答方法，尽管在测试阶段没有进行特定任务的微调，但仍取得了53个参赛队伍中的第33名的成绩。

Abstract: This paper describes our participation in SemEval 2025 Task 8, focused on
Tabular Question Answering. We developed a zero-shot pipeline that leverages an
Large Language Model to generate functional code capable of extracting the
relevant information from tabular data based on an input question. Our approach
consists of a modular pipeline where the main code generator module is
supported by additional components that identify the most relevant columns and
analyze their data types to improve extraction accuracy. In the event that the
generated code fails, an iterative refinement process is triggered,
incorporating the error feedback into a new generation prompt to enhance
robustness. Our results show that zero-shot code generation is a valid approach
for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of
task-specific fine-tuning.

</details>


### [123] [A Survey on Training-free Alignment of Large Language Models](https://arxiv.org/abs/2508.09016)
*Birong Pan,Yongqi Li,Weiyu Zhang,Wenpeng Lu,Mayi Xu,Shen Zhou,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.CL

TL;DR: 该论文对训练无关（TF）的 LLM 对齐方法进行了首次系统性审查，涵盖了预解码、解码中和后解码技术，旨在为实践者提供指导并推动更安全、更可靠的 LLM 的发展。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统微调（FT）对齐方法资源密集、可能导致知识退化以及在模型可访问性或计算资源受限的情况下存在挑战的问题，本文提出了对 TF 对齐方法的首次系统性审查。

Method: 通过对预解码、解码中和后解码阶段的 TF 对齐方法进行详细检查，从 LLM 和多模态 LLM（MLLM）的角度进行了审查。

Result: 对 TF 对齐方法进行了分类，并从 LLM 和 MLLM 的角度进行了详细审查，重点介绍了它们的机制和局限性。

Conclusion: 该论文系统地回顾了训练无关（TF）的对齐方法，对它们进行了分类，并指出了挑战和未来方向，为更具包容性和有效的 TF 对齐技术铺平了道路。

Abstract: The alignment of large language models (LLMs) aims to ensure their outputs
adhere to human values, ethical standards, and legal norms. Traditional
alignment methods often rely on resource-intensive fine-tuning (FT), which may
suffer from knowledge degradation and face challenges in scenarios where the
model accessibility or computational resources are constrained. In contrast,
training-free (TF) alignment techniques--leveraging in-context learning,
decoding-time adjustments, and post-generation corrections--offer a promising
alternative by enabling alignment without heavily retraining LLMs, making them
adaptable to both open-source and closed-source environments. This paper
presents the first systematic review of TF alignment methods, categorizing them
by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we
provide a detailed examination from the viewpoint of LLMs and multimodal LLMs
(MLLMs), highlighting their mechanisms and limitations. Furthermore, we
identify key challenges and future directions, paving the way for more
inclusive and effective TF alignment techniques. By synthesizing and organizing
the rapidly growing body of research, this survey offers a guidance for
practitioners and advances the development of safer and more reliable LLMs.

</details>


### [124] [LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback](https://arxiv.org/abs/2508.09042)
*Chen Xu,Zhenyu Lv,Tian Lan,Xianyang Wang,Luyao Ji,Leyang Cui,Minqiang Yang,Jian Shen,Qunxi Dong,Xiuling Liu,Juan Wang,Bin Hu*

Main category: cs.CL

TL;DR: Instead of using LLMs directly with patients, this research trains therapists using an LLM supervisor. They created a dataset of common therapy mistakes and feedback to train the LLM, which proved effective in providing quality guidance for therapists.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the ethical and safety concerns of directly applying LLMs in patient-facing psychotherapy scenarios. Instead, this work focuses on using LLMs as supervisors to train real therapists. The challenge lies in the contradiction between the need for clear feedback standards in a controlled training system and the lack of an absolute "gold standard" for therapeutic behaviors. However, common and identifiable therapeutic mistakes can serve as effective triggers for targeted feedback.

Method: The researchers developed a novel therapist-training paradigm involving three steps: 1. Establishing standards by defining guidelines for mistaken behaviors and targeted correction strategies. 2. Constructing a human-in-the-loop dialogue-feedback dataset where a mistake-prone agent intentionally makes common therapeutic errors, and a supervisor agent identifies these mistakes and provides feedback. 3. Fine-tuning a supervisor model on this dataset for real therapist training.

Result: Automated, human, and downstream assessments indicate that models fine-tuned on the MATE dataset can deliver high-quality feedback consistent with clinical guidelines, highlighting their potential for therapist training.

Conclusion: The study demonstrates that LLMs fine-tuned on the MATE dataset can provide high-quality feedback for therapist training, aligning with clinical guidelines and showing significant potential in this domain.

Abstract: Although large language models (LLMs) hold significant promise in
psychotherapy, their direct application in patient-facing scenarios raises
ethical and safety concerns. Therefore, this work shifts towards developing an
LLM as a supervisor to train real therapists. In addition to the privacy of
clinical therapist training data, a fundamental contradiction complicates the
training of therapeutic behaviors: clear feedback standards are necessary to
ensure a controlled training system, yet there is no absolute "gold standard"
for appropriate therapeutic behaviors in practice. In contrast, many common
therapeutic mistakes are universal and identifiable, making them effective
triggers for targeted feedback that can serve as clearer evidence. Motivated by
this, we create a novel therapist-training paradigm: (1) guidelines for
mistaken behaviors and targeted correction strategies are first established as
standards; (2) a human-in-the-loop dialogue-feedback dataset is then
constructed, where a mistake-prone agent intentionally makes standard mistakes
during interviews naturally, and a supervisor agent locates and identifies
mistakes and provides targeted feedback; (3) after fine-tuning on this dataset,
the final supervisor model is provided for real therapist training. The
detailed experimental results of automated, human and downstream assessments
demonstrate that models fine-tuned on our dataset MATE, can provide
high-quality feedback according to the clinical guideline, showing significant
potential for the therapist training scenario.

</details>


### [125] [MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions](https://arxiv.org/abs/2508.09057)
*Zeyu Huang,Juyuan Wang,Longfeng Chen,Boyi Xiao,Leng Cai,Yawen Zeng,Jin Xu*

Main category: cs.CL

TL;DR: 该研究提出了MVISU-Bench基准和Aider模块，以改善移动代理处理用户指令的能力，特别是在处理模糊和不道德指令方面。


<details>
  <summary>Details</summary>
Motivation: 现有的移动代理评估基准与现实脱节，未能充分满足用户多样化和复杂化的需求。

Method: 提出了一种名为MVISU-Bench的双语基准，包含404个跨越137个移动应用的测试用例，涵盖了多应用、模糊、交互、单应用和不道德指令五类任务。同时，提出了一种名为Aider的即插即用模块，作为动态提示改进器，用于缓解风险和明确用户意图。

Result: MVISU-Bench基准包含了404个任务，涵盖137个移动应用。Aider模块在MVISU-Bench基准上将整体成功率提高了19.55%，在处理不道德指令时提高了53.52%，在处理交互式指令时提高了29.41%。

Conclusion: 该研究提出了MVISU-Bench基准和Aider模块，以解决现有移动代理评估的不足，并提高了代理处理复杂和模糊指令的能力，尤其是在处理不道德和交互式指令方面。

Abstract: Given the significant advances in Large Vision Language Models (LVLMs) in
reasoning and visual understanding, mobile agents are rapidly emerging to meet
users' automation needs. However, existing evaluation benchmarks are
disconnected from the real world and fail to adequately address the diverse and
complex requirements of users. From our extensive collection of user
questionnaire, we identified five tasks: Multi-App, Vague, Interactive,
Single-App, and Unethical Instructions. Around these tasks, we present
\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137
mobile applications. Furthermore, we propose Aider, a plug-and-play module that
acts as a dynamic prompt prompter to mitigate risks and clarify user intent for
mobile agents. Our Aider is easy to integrate into several frameworks and has
successfully improved overall success rates by 19.55\% compared to the current
state-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate
improvements of 53.52\% and 29.41\% for unethical and interactive instructions,
respectively. Through extensive experiments and analysis, we highlight the gap
between existing mobile agents and real-world user expectations.

</details>


### [126] [READER: Retrieval-Assisted Drafter for Efficient LLM Inference](https://arxiv.org/abs/2508.09072)
*Maxim Divilkovskiy,Vitaly Malygin,Sergey Zlobin,Sultan Isali,Vasily Kalugin,Stanislav Ilyushin,Nuriza Aitassova,Yi Fei,Zeng Weidi*

Main category: cs.CL

TL;DR: READER 是一种新的、无需额外训练的投机解码方法，通过利用文本自重复和统计搜索来加速 LLM 推理，在大批量和基于搜索的任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: LLM 的自回归性质使其推理过程难以加速，对高效部署提出了重大挑战。本研究旨在通过引入一种新的投机解码方法来解决这个问题。

Method: READER (Retrieval-Assisted Drafter for Efficient LLM Inference) 是一种新颖的、无损的投机解码方法，它通过利用文本中的自重复来增强基于模型的方法。该算法使用通过统计搜索获得的 token 来扩展投机解码树。重点关注大批量大小（>= 8）并分析了投机解码过程中的键值（KV）缓存大小，最后提出了一种优化方案以提高大批量的性能。

Result: READER 的性能优于现有的投机解码方法，速度提高了 40% 以上，在检索增强生成等任务上速度提高了 10 倍以上。

Conclusion: READER 是一种新颖的、无损的投机解码方法，通过利用文本中的自重复来增强基于模型的方法，并且在不进行额外训练的情况下，可将速度提高 40% 以上。在检索增强生成等基于搜索的任务上，READER 的表现尤为出色，速度提高了 10 倍以上。

Abstract: Large Language Models (LLMs) generate tokens autoregressively, with each
token depending on the preceding context. This sequential nature makes the
inference process inherently difficult to accelerate, posing a significant
challenge for efficient deployment. In recent years, various methods have been
proposed to address this issue, with the most effective approaches often
involving the training of additional draft models. In this paper, we introduce
READER (Retrieval-Assisted Drafter for Efficient LLM Inference), a novel
lossless speculative decoding method that enhances model-based approaches by
leveraging self-repetitions in the text. Our algorithm expands the speculative
decoding tree using tokens obtained through statistical search. This work
focuses on large batch sizes (>= 8), an underexplored yet important area for
industrial applications. We also analyze the key-value (KV) cache size during
speculative decoding and propose an optimization to improve performance for
large batches. As a result, READER outperforms existing speculative decoding
methods. Notably, READER requires no additional training and can reuse
pre-trained speculator models, increasing the speedup by over 40\%. Our method
demonstrates particularly strong performance on search-based tasks, such as
retrieval-augmented generation, where we achieve more than 10x speedup.

</details>


### [127] [CPO: Addressing Reward Ambiguity in Role-playing Dialogue via Comparative Policy Optimization](https://arxiv.org/abs/2508.09074)
*Xinge Ye,Rui Wang,Yuchuan Wu,Victor Ma,Feiteng Fang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: CPO通过比较评估改进角色扮演对话的RLFT，效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习微调（RLFT）在开放式主观任务（如角色扮演对话）中存在的不足，传统奖励建模方法在主观评估标准和不稳定的奖励信号方面面临挑战。

Method: 提出了一种名为比较策略优化（CPO）的新方法，该方法将奖励评估从样本级评分改为比较组级评分。此外，还引入了CharacterArena评估框架，包括上下文多轮角色扮演模拟和轨迹级比较评估。

Result: CPO在CharacterEval、CharacterBench和CharacterArena等数据集上取得了实证结果，证明其有效性。

Conclusion: CPO通过将奖励评估范式从样本级评分转变为比较组级评分，有效缓解了奖励模糊性，并在对话质量方面取得了显著改进。

Abstract: Reinforcement Learning Fine-Tuning (RLFT) has achieved notable success in
tasks with objectively verifiable answers (e.g., code generation, mathematical
reasoning), yet struggles with open-ended subjective tasks like role-playing
dialogue. Traditional reward modeling approaches, which rely on independent
sample-wise scoring, face dual challenges: subjective evaluation criteria and
unstable reward signals.Motivated by the insight that human evaluation
inherently combines explicit criteria with implicit comparative judgments, we
propose Comparative Policy Optimization (CPO). CPO redefines the reward
evaluation paradigm by shifting from sample-wise scoring to comparative
group-wise scoring.Building on the same principle, we introduce the
CharacterArena evaluation framework, which comprises two stages:(1)
Contextualized Multi-turn Role-playing Simulation, and (2) Trajectory-level
Comparative Evaluation. By operationalizing subjective scoring via objective
trajectory comparisons, CharacterArena minimizes contextual bias and enables
more robust and fair performance evaluation. Empirical results on
CharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively
mitigates reward ambiguity and leads to substantial improvements in dialogue
quality.

</details>


### [128] [Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages](https://arxiv.org/abs/2508.09091)
*Imalsha Puranegedara,Themira Chathumina,Nisal Ranathunga,Nisansa de Silva,Surangika Ranathunga,Mokanarangan Thayaparan*

Main category: cs.CL

TL;DR: LLM在低资源语言上的表现不佳。本研究提出了一种新的Transformer Softmax模型，通过融合多语言编码器的所有中间层来丰富语言信息，并仅用英语数据进行训练，在多项任务上显著优于现有方法，尤其是在低资源语言上。


<details>
  <summary>Details</summary>
Motivation: LLM在低资源语言（LRLs）上的表现由于以英语为中心的训练而显著下降。现有的LangBridge等方法虽然能将LLM与多语言编码器（如mT5）对齐，但通常只使用最后的编码器层。

Method: 提出了一种新颖的架构，融合了所有中间层，以丰富传递给LLM的语言信息。该方法采用两种策略：1）全局Softmax加权，用于整体层的重要性；2）Transformer Softmax模型，用于学习特定于token的权重。融合后的表示被映射到LLM的嵌入空间，使其能够处理多语言输入。该模型仅使用英语数据进行训练，不使用任何并行或多语言数据。

Result: Transformer Softmax模型在XNLI、IndicXNLI、僧伽罗语新闻分类和亚马逊评论等任务上显著优于LangBridge基线。在低资源语言方面表现出强劲的性能提升，僧伽罗语分类准确率从71.66%提高到75.86%，在泰米尔语、孟加拉语和马拉雅拉姆语等印度语言上也有明显改进，整体XNLI准确率从70.36%提高到71.50%。

Conclusion: 该方法为构建更强大、更公平的多语言LLM提供了一条可扩展、数据高效的途径。

Abstract: Large Language Models (LLMs) excel in English, but their performance degrades
significantly on low-resource languages (LRLs) due to English-centric training.
While methods like LangBridge align LLMs with multilingual encoders such as the
Massively Multilingual Text-to-Text Transfer Transformer (mT5), they typically
use only the final encoder layer. We propose a novel architecture that fuses
all intermediate layers, enriching the linguistic information passed to the
LLM. Our approach features two strategies: (1) a Global Softmax weighting for
overall layer importance, and (2) a Transformer Softmax model that learns
token-specific weights. The fused representations are mapped into the LLM's
embedding space, enabling it to process multilingual inputs. The model is
trained only on English data, without using any parallel or multilingual data.
Evaluated on XNLI, IndicXNLI, Sinhala News Classification, and Amazon Reviews,
our Transformer Softmax model significantly outperforms the LangBridge
baseline. We observe strong performance gains in LRLs, improving Sinhala
classification accuracy from 71.66% to 75.86% and achieving clear improvements
across Indic languages such as Tamil, Bengali, and Malayalam. These specific
gains contribute to an overall boost in average XNLI accuracy from 70.36% to
71.50%. This approach offers a scalable, data-efficient path toward more
capable and equitable multilingual LLMs.

</details>


### [129] [Link Prediction for Event Logs in the Process Industry](https://arxiv.org/abs/2508.09096)
*Anastasia Zhukova,Thomas Walton,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 通过将跨文档共指消解（CDCR）应用于流程工业的轮班日志，解决了记录碎片化问题， RL模型在记录链接方面表现优于NLI和STS方法。


<details>
  <summary>Details</summary>
Motivation: 流程工业中事件日志（如轮班日志）的碎片化问题，导致相关的记录（如设备问题及其解决方案）相互分离，阻碍了解决方案的推荐。知识管理（KM）在流程工业中至关重要，需要有效利用操作数据和过往的经验。

Method: 将记录链接（RL）问题视为链接预测，并将其构建为跨文档共指消解（CDCR）任务，同时利用自然语言推断（NLI）和语义文本相似度（STS）的增强，并通过因果推理（CI）进行转变。适应了CDCR模型以处理流程工业的特定文本格式（包含非结构化文本和结构化记录属性），并能在段落级别上操作。

Result: 所提出的RL模型在性能上超越了基于NLI和STS的基线模型，分别提高了28%（11.43个百分点）和27%（11.21个百分点）。

Conclusion: 该研究展示了如何通过引入领域适应和因果推理能力，将最先进的跨文档共指消解（CDCR）模型有效地应用于流程工业，以改进轮班日志中的数据质量和连接性。

Abstract: Knowledge management (KM) is vital in the process industry for optimizing
operations, ensuring safety, and enabling continuous improvement through
effective use of operational data and past insights. A key challenge in this
domain is the fragmented nature of event logs in shift books, where related
records, e.g., entries documenting issues related to equipment or processes and
the corresponding solutions, may remain disconnected. This fragmentation
hinders the recommendation of previous solutions to the users. To address this
problem, we investigate record linking (RL) as link prediction, commonly
studied in graph-based machine learning, by framing it as a cross-document
coreference resolution (CDCR) task enhanced with natural language inference
(NLI) and semantic text similarity (STS) by shifting it into the causal
inference (CI). We adapt CDCR, traditionally applied in the news domain, into
an RL model to operate at the passage level, similar to NLI and STS, while
accommodating the process industry's specific text formats, which contain
unstructured text and structured record attributes. Our RL model outperformed
the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and
27% (11.21 points), respectively. Our work demonstrates how domain adaptation
of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can
be effectively tailored to the process industry, improving data quality and
connectivity in shift logs.

</details>


### [130] [AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators](https://arxiv.org/abs/2508.09101)
*Jason Chou,Ao Liu,Yuchi Deng,Zhiying Zeng,Tao Zhang,Haotian Zhu,Jianwei Cai,Yue Mao,Chenchen Zhang,Lingyun Tan,Ziyan Xu,Bohui Zhai,Hengyi Liu,Speed Zhu,Wiggin Zhou,Fengzong Lian*

Main category: cs.CL

TL;DR: 提出 AutoCodeGen 自动生成多语言、高难度代码生成数据集，解决了现有基准的局限性。新基准 AutoCodeBench 包含 20 种语言的 3,920 个问题，评估显示顶尖 LLMs 在此上面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）代码生成评估基准存在一些关键限制：1. 依赖手动标注，耗时且难以扩展到不同编程语言和复杂性。2. 大多数基准主要关注 Python，多语言基准在难度和语言分布上存在不足。为了解决这些问题，需要一种能够自动生成高难度、多语言代码生成数据集的方法。

Method: 提出了一种名为 AutoCodeGen 的自动化方法，用于生成高难度、多语言的代码生成数据集，无需手动标注。该方法通过 LLMs 生成测试输入，并利用多语言沙箱获取测试输出来确保测试用例的正确性和完整性。同时，通过逆序问题生成和多重过滤步骤来保证数据质量。基于此方法构建了 AutoCodeBench 和 AutoCodeBench-Lite 等基准测试集。

Result: 使用 AutoCodeGen 方法构建了 AutoCodeBench（包含 3,920 个问题，分布在 20 种编程语言中）和 AutoCodeBench-Lite。在这些基准上评估了超过 30 个领先的 LLMs，结果显示即使是最先进的模型在处理这些任务的复杂性、多样性和多语言性方面也存在困难。此外，还提出了 AutoCodeBench-Complete 用于评估模型的少样本代码生成能力。

Conclusion: 该研究提出了 AutoCodeGen 方法，用于自动生成高难度、多语言的代码生成数据集，解决了现有基准测试在手动标注、语言覆盖和难度分布上的局限性。新基准 AutoCodeBench 包含了 3,920 个问题，分布在 20 种编程语言中，用于评估大型语言模型（LLMs）在复杂、多样化和多语言代码生成任务上的表现。实验结果表明，即使是顶尖的 LLMs 在这些任务上也面临挑战。此外，还提出了 AutoCodeBench-Complete 用于评估模型的少样本代码生成能力。该系列基准旨在推动社区在更具挑战性和实用性的多语言代码生成领域的研究。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, with code generation emerging as a key area of focus. While
numerous benchmarks have been proposed to evaluate their code generation
abilities, these benchmarks face several critical limitations. First, they
often rely on manual annotations, which are time-consuming and difficult to
scale across different programming languages and problem complexities. Second,
most existing benchmarks focus primarily on Python, while the few multilingual
benchmarks suffer from limited difficulty and uneven language distribution. To
address these challenges, we propose AutoCodeGen, an automated method for
generating high-difficulty multilingual code generation datasets without manual
annotations. AutoCodeGen ensures the correctness and completeness of test cases
by generating test inputs with LLMs and obtaining test outputs through a
multilingual sandbox, while achieving high data quality through reverse-order
problem generation and multiple filtering steps. Using this novel method, we
introduce AutoCodeBench, a large-scale code generation benchmark comprising
3,920 problems evenly distributed across 20 programming languages. It is
specifically designed to evaluate LLMs on challenging, diverse, and practical
multilingual tasks. We evaluate over 30 leading open-source and proprietary
LLMs on AutoCodeBench and its simplified version AutoCodeBench-Lite. The
results show that even the most advanced LLMs struggle with the complexity,
diversity, and multilingual nature of these tasks. Besides, we introduce
AutoCodeBench-Complete, specifically designed for base models to assess their
few-shot code generation capabilities. We hope the AutoCodeBench series will
serve as a valuable resource and inspire the community to focus on more
challenging and practical multilingual code generation scenarios.

</details>


### [131] [SinLlama -- A Large Language Model for Sinhala](https://arxiv.org/abs/2508.09115)
*H. W. K. Aravinda,Rashad Sirajudeen,Samith Karunathilake,Nisansa de Silva,Surangika Ranathunga,Rishemjit Kaur*

Main category: cs.CL

TL;DR: 使用僧伽罗语数据和词汇增强Llama-3-8B，创建了SinLlama模型，并在文本分类任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如僧伽罗语）在开源LLM中被忽视的问题。

Method: 通过向Llama-3-8B模型添加僧伽罗语词汇来增强其分词器，并使用1000万僧伽罗语语料库进行持续预训练。

Result: SinLlama在指令微调后的文本分类任务中，性能显著优于Llama-3-8B基础模型和指令微调版本。

Conclusion: SinLlama是首个支持僧伽罗语的开源解码器LLM，在文本分类任务上表现优于Llama-3-8B基础模型和指令微调版本。

Abstract: Low-resource languages such as Sinhala are often overlooked by open-source
Large Language Models (LLMs). In this research, we extend an existing
multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM
tokenizer with Sinhala specific vocabulary and perform continual pre-training
on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This
is the very first decoder-based open-source LLM with explicit Sinhala support.
When SinLlama was instruction fine-tuned for three text classification tasks,
it outperformed base and instruct variants of Llama-3-8B by a significant
margin.

</details>


### [132] [OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows](https://arxiv.org/abs/2508.09124)
*Weixuan Wang,Dongge Han,Daniel Madrigal Diaz,Jin Xu,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: Evaluated LLM agents on complex, real-world office tasks using OdysseyBench, a new benchmark designed for long-horizon workflows. A framework called HomerAgents was developed to create these benchmarks automatically. The results show OdysseyBench is better than existing benchmarks for assessing LLM agents' real-world capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks focus on atomic tasks, failing to capture the long-term contextual dependencies and multi-interaction coordination required for LLM agents in complex, long-horizon workflows found in real-world applications.

Method: Introduced OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications (Word, Excel, PDF, Email, Calendar). The benchmark includes OdysseyBench+ (300 real-world tasks) and OdysseyBench-Neo (302 synthesized complex tasks). Proposed HomerAgents, a multi-agent framework to automate benchmark creation through environment exploration, task generation, and dialogue synthesis.

Result: Extensive evaluation showed that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessments of their capabilities in complex, real-world contexts than existing benchmarks.

Conclusion: OdysseyBench is an effective benchmark for evaluating LLM agents on long-horizon workflows, offering a more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. The release of OdysseyBench and HomerAgents aims to foster further research in this area.

Abstract: Autonomous agents powered by large language models (LLMs) are increasingly
deployed in real-world applications requiring complex, long-horizon workflows.
However, existing benchmarks predominantly focus on atomic tasks that are
self-contained and independent, failing to capture the long-term contextual
dependencies and multi-interaction coordination required in realistic
scenarios. To address this gap, we introduce OdysseyBench, a comprehensive
benchmark for evaluating LLM agents on long-horizon workflows across diverse
office applications including Word, Excel, PDF, Email, and Calendar. Our
benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks
derived from real-world use cases, and OdysseyBench-Neo with 302 newly
synthesized complex tasks. Each task requires agent to identify essential
information from long-horizon interaction histories and perform multi-step
reasoning across various applications. To enable scalable benchmark creation,
we propose HomerAgents, a multi-agent framework that automates the generation
of long-horizon workflow benchmarks through systematic environment exploration,
task generation, and dialogue synthesis. Our extensive evaluation demonstrates
that OdysseyBench effectively challenges state-of-the-art LLM agents, providing
more accurate assessment of their capabilities in complex, real-world contexts
compared to existing atomic task benchmarks. We believe that OdysseyBench will
serve as a valuable resource for advancing the development and evaluation of
LLM agents in real-world productivity scenarios. In addition, we release
OdysseyBench and HomerAgents to foster research along this line.

</details>


### [133] [Complex Logical Instruction Generation](https://arxiv.org/abs/2508.09125)
*Mian Zhang,Shujian Liu,Sixun Dong,Ming Yin,Yebowen Hu,Xun Wang,Steven Ma,Song Wang,Sathish Reddy Indurthi,Haoyun Deng,Zhiyu Zoey Chen,Kaiqiang Song*

Main category: cs.CL

TL;DR: LLMs在遵循复杂逻辑指令方面表现不佳，需要改进。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在处理日益复杂的、富含逻辑的自然语言指令方面的表现。

Method: 提出LogicIFGen框架，可从代码函数自动生成可验证的、包含丰富逻辑（如条件、嵌套、递归、函数调用）的指令；并构建了包含426个指令的LogicIFEval基准。

Result: 在LogicIFEval基准上的实验表明，当前最先进的LLMs在遵循逻辑丰富指令方面的能力仍然有限，暴露出其在指令遵循能力方面的重大缺陷。

Conclusion: 大型语言模型（LLMs）在遵循复杂逻辑指令方面仍存在显著不足，即使是目前最先进的模型也只能正确遵循不到60%的指令。

Abstract: Instruction following has catalyzed the recent era of Large Language Models
(LLMs) and is the foundational skill underpinning more advanced capabilities
such as reasoning and agentic behaviors. As tasks grow more challenging, the
logic structures embedded in natural language instructions becomes increasingly
intricate. However, how well LLMs perform on such logic-rich instructions
remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a
scalable, automated framework for generating verifiable instructions from code
functions, which can naturally express rich logic such as conditionals,
nesting, recursion, and function calls. We further curate a collection of
complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark
comprising 426 verifiable logic-rich instructions. Our experiments demonstrate
that current state-of-the-art LLMs still struggle to correctly follow the
instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the
instructions, revealing significant deficiencies in the instruction-following
ability. Code and Benchmark: https://github.com/mianzhang/LogicIF

</details>


### [134] [Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models](https://arxiv.org/abs/2508.09138)
*Wen Wang,Bozhen Fang,Chenchen Jing,Yongliang Shen,Yangyi Shen,Qiuyu Wang,Hao Ouyang,Hao Chen,Chunhua Shen*

Main category: cs.CL

TL;DR: dLLM生成文本时存在“时间振荡”，正确答案可能被覆盖。本文提出“时间自洽投票”和“时间一致性增强”两种方法，利用中间预测的时间一致性来提升生成效果，实验证明了这些方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前dLLM的解码策略倾向于丢弃中间预测，只保留最终输出，但研究发现正确答案可能出现在中间过程，随后被覆盖。因此，需要新的方法来利用这些被忽视的中间信息。

Method: 1. 时间自洽投票：一种无需训练、在测试时聚合不同去噪步骤预测以选择最一致输出的解码策略。 2. 时间一致性增强：一种后训练方法，利用时间语义熵（TSE）作为奖励信号，鼓励模型生成更稳定的文本。

Result: 在Countdown数据集上，单独使用负TSE奖励比现有dLLM有显著的24.7%的平均提升。结合准确率奖励后，在GSM8K、MATH500、SVAMP和Countdown数据集上分别实现了2.0%、4.3%、6.6%和25.3%的绝对增益。

Conclusion: 本文的研究揭示了扩散大语言模型（dLLM）在生成文本过程中存在“时间振荡”现象，即正确答案可能在中间步骤出现但被后续步骤覆盖。为了解决这个问题，我们提出了两种利用时间一致性的方法：1）时间自洽投票（一种无需训练的测试时解码策略）和2）时间一致性增强（一种后训练方法，利用时间语义熵（TSE）作为奖励信号来鼓励稳定的生成）。实验结果表明，我们的方法能够有效利用dLLM的时间动态潜力。

Abstract: Diffusion large language models (dLLMs) generate text through iterative
denoising, yet current decoding strategies discard rich intermediate
predictions in favor of the final output. Our work here reveals a critical
phenomenon, temporal oscillation, where correct answers often emerge in the
middle process, but are overwritten in later denoising steps. To address this
issue, we introduce two complementary methods that exploit temporal
consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time
decoding strategy that aggregates predictions across denoising steps to select
the most consistent output; and 2) a post-training method termed Temporal
Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a
measure of semantic stability across intermediate predictions, as a reward
signal to encourage stable generations. Empirical results across multiple
benchmarks demonstrate the effectiveness of our approach. Using the negative
TSE reward alone, we observe a remarkable average improvement of 24.7% on the
Countdown dataset over an existing dLLM. Combined with the accuracy reward, we
achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and
25.3% on Countdown, respectively. Our findings underscore the untapped
potential of temporal dynamics in dLLMs and offer two simple yet effective
tools to harness them.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [135] [How Conversational Structure and Style Shape Online Community Experiences](https://arxiv.org/abs/2508.08596)
*Galen Weld,Carl Pearson,Bradley Spahn,Tim Althoff,Amy X. Zhang,Sanjay Kairam*

Main category: cs.SI

TL;DR: 本研究通过大规模调查和量化分析，探索了在线社区的对话结构和语言风格如何影响虚拟社区归属感（SOVC）。研究结果揭示了特定的互动模式（如互惠回复和亲社会语言）与更强的社区归属感相关，并确定了SOVC的三个关键维度。该研究为理解和促进在线社区提供了实用的见解和可推广的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管社交互动越来越多地在线上进行，但对于这些互动的性质与虚拟社区归属感（SOVC）之间的具体关系仍然知之甚少。本研究旨在解决这一差距。

Method: 本研究利用对281个不同子版块的2,826名Reddit用户的进行大规模调查，探索了对话结构和语言风格如何预测在线社区的虚拟社区归属感（SOVC）。研究开发了一种分层模型，用于根据自动量化、高度可推广且与社区主题无关的特征来预测自我报告的SOVC，这些特征描述了个人用户和整个社区。

Result: 研究确定了特定的互动模式（例如，互惠回复链、亲社会语言的使用）与更强的社区相关联，并识别了Reddit中SOVC的三个主要维度——成员资格与归属感、合作与共同价值观、以及联系与影响力。

Conclusion: 本研究提供了首个将社交互动模式与虚拟社区归属感（SOVC）联系起来的量化证据，并强调了培养更强社区归属感的实用策略。所采用的方法能够推广到不同的社区主题、语言和平台。

Abstract: Sense of Community (SOC) is vital to individual and collective well-being.
Although social interactions have moved increasingly online, still little is
known about the specific relationships between the nature of these interactions
and Sense of Virtual Community (SOVC). This study addresses this gap by
exploring how conversational structure and linguistic style predict SOVC in
online communities, using a large-scale survey of 2,826 Reddit users across 281
varied subreddits. We develop a hierarchical model to predict self-reported
SOVC based on automatically quantifiable and highly generalizable features that
are agnostic to community topic and that describe both individual users and
entire communities. We identify specific interaction patterns (e.g., reciprocal
reply chains, use of prosocial language) associated with stronger communities
and identify three primary dimensions of SOVC within Reddit -- Membership &
Belonging, Cooperation & Shared Values, and Connection & Influence. This study
provides the first quantitative evidence linking patterns of social interaction
to SOVC and highlights actionable strategies for fostering stronger community
attachment, using an approach that can generalize readily across community
topics, languages, and platforms. These insights offer theoretical implications
for the study of online communities and practical suggestions for the design of
features to help more individuals experience the positive benefits of online
community participation.

</details>


### [136] [Effective and Efficient Attributed Hypergraph Embedding on Nodes and Hyperedges](https://arxiv.org/abs/2508.08807)
*Yiran Li,Gongyao Guo,Chen Feng,Jieming Shi*

Main category: cs.SI

TL;DR: SAHE是一种高效且有效的AHNEE方法，通过统一节点和超边嵌入，并引入高阶相似性度量和优化算法，解决了现有方法的局限性，并在嵌入质量和效率上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有属性超图节点和超边嵌入（AHNEE）方法在处理复杂属性超图和嵌入节点与超边方面存在挑战，尤其是在大规模数据上。现有解决方案往往只关注节点，或缺乏对属性超图的原生支持，导致质量不佳，并且难以在大规模属性超图中实现可扩展性。

Method: SAHE通过两种高阶相似性度量（HMS-N和HMS-E）来统一节点和超边嵌入，分别捕获节点对和超边对之间的相似性。它通过联合保留所有节点对和超边对的HMS-N和HMS-E相似性来构建AHNEE目标。为解决直接优化的计算成本问题，SAHE对所有节点对和超边对的HMS-N和HMS-N的核心近似进行了分析和统一。为了提高效率，SAHE还设计了几种避免迭代实现大型稠密矩阵的优化方法，同时保持了高质量的结果。

Result: SAHE在嵌入质量方面始终优于现有方法，并且速度提高了几个数量级。

Conclusion: SAHE在真实属性超图和三个下游任务上的广泛实验表明，与11个基线相比，SAHE在嵌入质量方面始终优于现有方法，并且速度提高了几个数量级。

Abstract: An attributed hypergraph comprises nodes with attributes and hyperedges that
connect varying numbers of nodes. Attributed hypergraph node and hyperedge
embedding (AHNEE) maps nodes and hyperedges to compact vectors for use in
important tasks such as node classification, hyperedge link prediction, and
hyperedge classification. Generating high-quality embeddings is challenging due
to the complexity of attributed hypergraphs and the need to embed both nodes
and hyperedges, especially in large-scale data. Existing solutions often fall
short by focusing only on nodes or lacking native support for attributed
hypergraphs, leading to inferior quality, and struggle with scalability on
large attributed hypergraphs.
  We propose SAHE, an efficient and effective approach that unifies node and
hyperedge embeddings for AHNEE computation, advancing the state of the art via
comprehensive embedding formulations and algorithmic designs. First, we
introduce two higher-order similarity measures, HMS-N and HMS-E, to capture
similarities between node pairs and hyperedge pairs, respectively. These
measures consider multi-hop connections and global topology within an extended
hypergraph that incorporates attribute-based hyperedges. SAHE formulates the
AHNEE objective to jointly preserve all-pair HMS-N and HMS-N similarities.
Direct optimization is computationally expensive, so we analyze and unify core
approximations of all-pair HMS-N and HMS-N to solve them simultaneously. To
enhance efficiency, we design several non-trivial optimizations that avoid
iteratively materializing large dense matrices while maintaining high-quality
results. Extensive experiments on diverse attributed hypergraphs and 3
downstream tasks, compared against 11 baselines, show that SAHE consistently
outperforms existing methods in embedding quality and is up to orders of
magnitude faster.

</details>


### [137] [The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents](https://arxiv.org/abs/2508.08837)
*Nicholas Sukiennik,Yichuan Xu,Yuqing Kan,Jinghua Piao,Yuwei Yan,Chen Gao,Yong Li*

Main category: cs.SI

TL;DR: 本研究首次使用大语言模型模拟了美国民众对中国长达20年的态度演变。研究提出的框架整合了数据收集、用户画像和认知架构，成功复现了真实趋势。通过引入去偏见媒体曝光和‘魔鬼代言人’，揭示了偏见和信息获取方式对观点形成的影响。该研究为LLM在跨境社会背景下的认知行为建模提供了新思路，有助于理解国际偏见并促进跨文化理解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的兴起为模拟意见演变提供了新的可能性，这是一项模拟领域的长期任务。通过利用其先进的推理能力，可以重现复杂、大规模的人类认知趋势。本研究旨在填补现有研究在模拟特定孤立事件或单一国家内部观点演变方面的空白，开创性地模拟了代表整个国家的人口对另一个国家（美国民众对中国的视角）的态度演变。

Method: 提出一个整合了媒体数据收集、用户画像创建和用于观点更新的认知架构的框架，成功重现了美国民众在20年间（2005年至今）对中国态度的真实演变趋势。利用大语言模型的能力，引入了去偏见的媒体曝光，从主观的新闻内容中提取中立事件，并设立了‘魔鬼代言人’代理，以解释态度从负面到正面的罕见转变，这与美国民众获取中国相关信息方式的改变相对应。

Result: 模拟结果验证了所提出的框架架构，并揭示了偏见性表述和选择性偏差在塑造态度方面的影响。

Conclusion: 本研究为基于大语言模型（LLM）的认知行为建模提供了新范例，适用于大规模、长期、跨境的社会背景。研究揭示了国际偏见形成的规律，并为媒体消费者提供了有价值的见解，以更好地理解塑造其观点的因素，最终有助于减少偏见和促进跨文化宽容。

Abstract: The rise of LLMs poses new possibilities in modeling opinion evolution, a
long-standing task in simulation, by leveraging advanced reasoning abilities to
recreate complex, large-scale human cognitive trends. While most prior works
focus on opinion evolution surrounding specific isolated events or the views
within a country, ours is the first to model the large-scale attitude evolution
of a population representing an entire country towards another -- US citizens'
perspectives towards China. To tackle the challenges of this broad scenario, we
propose a framework that integrates media data collection, user profile
creation, and cognitive architecture for opinion updates to successfully
reproduce the real trend of US attitudes towards China over a 20-year period
from 2005 to today. We also leverage LLMs' capabilities to introduce debiased
media exposure, extracting neutral events from typically subjective news
contents, to uncover the roots of polarized opinion formation, as well as a
devils advocate agent to help explain the rare reversal from negative to
positive attitudes towards China, corresponding with changes in the way
Americans obtain information about the country. The simulation results, beyond
validating our framework architecture, also reveal the impact of biased framing
and selection bias in shaping attitudes. Overall, our work contributes to a new
paradigm for LLM-based modeling of cognitive behaviors in a large-scale,
long-term, cross-border social context, providing insights into the formation
of international biases and offering valuable implications for media consumers
to better understand the factors shaping their perspectives, and ultimately
contributing to the larger social need for bias reduction and cross-cultural
tolerance.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [138] [SharpXR: Structure-Aware Denoising for Pediatric Chest X-Rays](https://arxiv.org/abs/2508.08518)
*Ilerioluwakiiye Abolade,Emmanuel Idoko,Solomon Odelola,Promise Omoigui,Adetola Adebanwo,Aondana Iorumbur,Udunna Anazodo,Alessandro Crimi,Raymond Confidence*

Main category: eess.IV

TL;DR: SharpXR 是一种用于低剂量儿科 X 光片的去噪 U-Net，它能在去除噪声的同时保留关键细节，并通过模拟噪声数据进行训练，在肺炎检测任务上取得了显著的性能提升，特别适用于资源匮乏的地区。


<details>
  <summary>Details</summary>
Motivation: 低剂量儿科胸部 X 光检查对于早期诊断至关重要，尤其是在缺乏先进成像技术的低资源地区。然而，低剂量方案会引入可能掩盖关键解剖细节的噪声，而传统去噪方法可能会损害精细细节，影响诊断准确性。

Method: SharpXR 采用一种结构感知双解码器 U-Net，结合了拉普拉斯引导的边缘保持解码器和可学习的融合模块，以在降噪的同时保留诊断相关特征。为了解决配对训练数据稀缺的问题，在儿科肺炎胸部 X 光数据集上模拟了泊松-高斯噪声。

Result: SharpXR 在所有评估指标上均优于最先进的方法，同时保持了适合资源受限环境的计算效率。SharpXR 去噪后的图像将下游肺炎分类准确性从 88.8% 提高到 92.5%。

Conclusion: SharpXR 在低资源环境下提高了肺炎分类准确性，为儿科护理提供了诊断价值。

Abstract: Pediatric chest X-ray imaging is essential for early diagnosis, particularly
in low-resource settings where advanced imaging modalities are often
inaccessible. Low-dose protocols reduce radiation exposure in children but
introduce substantial noise that can obscure critical anatomical details.
Conventional denoising methods often degrade fine details, compromising
diagnostic accuracy. In this paper, we present SharpXR, a structure-aware
dual-decoder U-Net designed to denoise low-dose pediatric X-rays while
preserving diagnostically relevant features. SharpXR combines a
Laplacian-guided edge-preserving decoder with a learnable fusion module that
adaptively balances noise suppression and structural detail retention. To
address the scarcity of paired training data, we simulate realistic
Poisson-Gaussian noise on the Pediatric Pneumonia Chest X-ray dataset. SharpXR
outperforms state-of-the-art baselines across all evaluation metrics while
maintaining computational efficiency suitable for resource-constrained
settings. SharpXR-denoised images improved downstream pneumonia classification
accuracy from 88.8% to 92.5%, underscoring its diagnostic value in low-resource
pediatric care.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [139] [XDMA: A Distributed, Extensible DMA Architecture for Layout-Flexible Data Movements in Heterogeneous Multi-Accelerator SoCs](https://arxiv.org/abs/2508.08396)
*Fanchen Kong,Yunhao Deng,Xiaoling Yi,Ryan Antonio,Marian Verhelst*

Main category: cs.AR

TL;DR: XDMA是一种创新的DMA架构，通过硬件数据流、分布式设计和灵活插件，解决了异构加速器数据移动的效率和灵活性问题，显著提高了性能并降低了开销。


<details>
  <summary>Details</summary>
Motivation: 现代AI工作负载日益依赖异构加速器，确保加速器内存之间的高带宽和布局灵活数据移动是一个紧迫的挑战。传统的DMA引擎虽然能保证高带宽利用率，但通常只对连续内存访问最优，需要额外的软件循环进行数据布局转换，导致过多的控制开销和低效的片上互连。

Method: 提出了一种分布式和可扩展的DMA架构XDMA，包含三个关键创新：1.一个数据流引擎作为XDMA前端，用硬件地址生成器取代软件地址生成器；2.一种分布式的DMA架构，最大化链路利用率并分离配置与数据传输；3.用于XDMA的灵活插件，可在数据传输期间进行动态数据操作。

Result: XDMA在合成工作负载中显示出比基于软件的实现高出151.2倍/8.2倍的链路利用率，并在实际应用中实现了比SoTA DMA加速器平均2.3倍的加速。设计面积开销仅比SoTA DMA解决方案高不到2%，功耗为系统功耗的17%。

Conclusion: XDMA通过共同优化内存访问、布局转换和互连协议，解锁了异构多加速器SoC的性能。

Abstract: As modern AI workloads increasingly rely on heterogeneous accelerators,
ensuring high-bandwidth and layout-flexible data movements between accelerator
memories has become a pressing challenge. Direct Memory Access (DMA) engines
promise high bandwidth utilization for data movements but are typically optimal
only for contiguous memory access, thus requiring additional software loops for
data layout transformations. This, in turn, leads to excessive control overhead
and underutilized on-chip interconnects. To overcome this inefficiency, we
present XDMA, a distributed and extensible DMA architecture that enables
layout-flexible data movements with high link utilization. We introduce three
key innovations: (1) a data streaming engine as XDMA Frontend, replacing
software address generators with hardware ones; (2) a distributed DMA
architecture that maximizes link utilization and separates configuration from
data transfer; (3) flexible plugins for XDMA enabling on-the-fly data
manipulation during data transfers. XDMA demonstrates up to 151.2x/8.2x higher
link utilization than software-based implementations in synthetic workloads and
achieves 2.3x average speedup over accelerators with SoTA DMA in real-world
applications. Our design incurs <2% area overhead over SoTA DMA solutions while
consuming 17% of system power. XDMA proves that co-optimizing memory access,
layout transformation, and interconnect protocols is key to unlocking
heterogeneous multi-accelerator SoC performance.

</details>


### [140] [Architecting Long-Context LLM Acceleration with Packing-Prefetch Scheduler and Ultra-Large Capacity On-Chip Memories](https://arxiv.org/abs/2508.08457)
*Ming-Yen Lee,Faaiq Waqar,Hanchen Yang,Muhammed Ahosan Ul Karim,Harsono Simka,Shimeng Yu*

Main category: cs.AR

TL;DR: 为了解决长上下文LLM推理中的HBM带宽瓶颈问题，提出了一种结合打包、预取和M3D BEOL嵌入式存储器的架构，实现了显著的加速和效率提升。


<details>
  <summary>Details</summary>
Motivation: 长上下文大语言模型（LLM）推理面临计算瓶颈，主要是由于注意力计算随上下文长度扩展，导致KV-cache传输开销增大并使高带宽内存（HBM）饱和。

Method: 提出了一种打包-预取调度架构，并结合具有超大片上容量的单片3D（M3D）后端线（BEOL）兼容嵌入式存储器，以加速长上下文LLM推理。

Result: 在Llama3.1-8B模型上，使用TPUv6e类硬件和额外的512MB BEOL内存，实现了8.06倍的解码速度提升和1.83倍的整体延迟降低。在多请求工作负载下，与仅使用打包的方法相比，吞吐量提高了1.7倍-2.4倍，HBM带宽降低了1.5倍-2.4倍。

Conclusion: 该方法通过结合打包、预取和单片3D（M3D）后端线（BEOL）嵌入式存储器，有效缓解了HBM带宽瓶颈，实现了长上下文大语言模型（LLM）推理的加速。

Abstract: Long-context Large Language Model (LLM) inference faces increasing compute
bottlenecks as attention calculations scale with context length, primarily due
to the growing KV-cache transfer overhead that saturates High Bandwidth Memory
(HBM). While prefetching techniques mitigate cache misses by fetching KV data
in advance, their spatial and temporal benefits present new opportunities to
exploit. This work proposes a packing-prefetch scheduling architecture with
monolithic 3D (M3D) back-end-of-line (BEOL) compatible embedded memories with
ultra-large on-chip capacity to accelerate long-context LLM inference. Our
optimizations demonstrate 8.06x decode speedup and 1.83x overall latency
reduction on Llama3.1-8B using TPUv6e-like hardware with additional 512MB BEOL
memories over the serial execution. Evaluations of multi-request workloads on
TPU-like architectures show 1.7x-2.4x throughput improvement and 1.5x-2.4x HBM
bandwidth reduction compared to packing-only methods on Llama3.1-8B and
Llama3.1-70B models. With the co-design of packing, prefetching, and BEOL
memories, our approach alleviates HBM constraints and enables efficient
long-context LLM inference.

</details>


### [141] [JSPIM: A Skew-Aware PIM Accelerator for High-Performance Databases Join and Select Operations](https://arxiv.org/abs/2508.08503)
*Sabiha Tajdari,Anastasia Ailamaki,Sandhya Dwarkadas*

Main category: cs.AR

TL;DR: JSPIM是一种内存处理（PIM）模块，通过算法-硬件协同设计（并行搜索引擎、优化的哈希表、子阵列并行和秩级处理）显著加速哈希连接查询，解决了数据倾斜问题，并实现了比DuckDB高出400-1000倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 数据库应用日益受到内存带宽和延迟的瓶颈影响，特别是对于需要密集内存访问的分析工作负载中的连接查询。现有的内存处理（PIM）设计通常复用面向CPU的连接算法，限制了并行性并导致昂贵的芯片间通信。此外，数据倾斜这一CPU端连接的主要挑战在当前的PIM架构中仍未得到解决。

Method: JSPIM是一种处理内存（PIM）模块，通过算法-硬件协同设计来加速哈希连接。其设计包括在每个子阵列内部署并行搜索引擎，并重新设计哈希表以实现O(1)查找，充分利用PIM的细粒度并行性。为缓解数据倾斜，该设计整合了子阵列级并行和秩级处理，消除了不必要的片外传输。

Result: 与DuckDB相比，JSPIM在连接查询方面实现了400倍至1000倍的加速。当与DuckDB结合用于完整的SSB基准测试时，JSPIM实现了2.5倍的总体吞吐量提升（单个查询增益为1.1倍至28倍），数据开销仅为7%，每个秩的PIM芯片面积增加了2.1%。

Conclusion: JSPIM通过算法-硬件协同设计，利用并行搜索引擎和优化的哈希表实现了O(1)查找，并结合子阵列级并行和秩级处理来缓解数据倾斜，从而加速哈希连接。

Abstract: Database applications are increasingly bottlenecked by memory bandwidth and
latency due to the memory wall and the limited scalability of DRAM. Join
queries, central to analytical workloads, require intensive memory access and
are particularly vulnerable to inefficiencies in data movement. While
Processing-in-Memory (PIM) offers a promising solution, existing designs
typically reuse CPU-oriented join algorithms, limiting parallelism and
incurring costly inter-chip communication. Additionally, data skew, a main
challenge in CPU-based joins, remains unresolved in current PIM architectures.
  We introduce JSPIM, a PIM module that accelerates hash join and, by
extension, corresponding select queries through algorithm-hardware co-design.
JSPIM deploys parallel search engines within each subarray and redesigns hash
tables to achieve O(1) lookups, fully exploiting PIM's fine-grained
parallelism. To mitigate skew, our design integrates subarray-level parallelism
with rank-level processing, eliminating redundant off-chip transfers.
Evaluations show JSPIM delivers 400x to 1000x speedup on join queries versus
DuckDB. When paired with DuckDB for the full SSB benchmark, JSPIM achieves an
overall 2.5x throughput improvement (individual query gains of 1.1x to 28x), at
just a 7% data overhead and 2.1% per-rank PIM-enabled chip area increase.

</details>


### [142] [OISMA: On-the-fly In-memory Stochastic Multiplication Architecture for Matrix-Multiplication Workloads](https://arxiv.org/abs/2508.08822)
*Shady Agwa,Yihan Pan,Georgios Papandroulidakis,Themis Prodromakis*

Main category: cs.AR

TL;DR: OISMA是一种新的内存计算架构，通过利用准随机计算域（Bent-Pyramid系统）将内存读取操作转换为随机乘法运算，从而解决了AI模型中的计算瓶颈。该架构在保持高效率和可扩展性的同时，显著提高了矩阵乘法的准确性和性能，并在不同工艺节点下表现出优越的能效和面积效率。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能模型面临着计算瓶颈，主要是大规模矩阵乘法工作负载。为解决冯·诺依曼瓶颈，提出了内存计算架构，但数字/二元和模拟内存计算架构均存在性能和能效方面的限制。因此，需要一种新的内存计算架构。

Method: 提出了一种名为OISMA的新型内存计算架构，利用准随机计算域（Bent-Pyramid系统）进行内存计算。该架构通过将内存读取操作转换为原位随机乘法运算，并使用累加外围设备累加输出比特流来实现矩阵乘法功能。

Result: 在4x4到512x512的矩阵维度下进行的基准测试表明，Bent-Pyramid系统的准确性显著提高，平均相对Frobenius误差从4x4的9.42%降低到512x512的1.81%。使用商用180nm和自研RRAM技术实现的4KB容量的1T1R OISMA阵列，在50MHz下实现了0.891 TOPS/W的能效和3.98 GOPS/mm²的面积效率。将OISMA从180nm扩展到22nm技术节点，其能效和面积效率相较于密集矩阵乘法内存计算架构分别提高了两个数量级和一个数量级。

Conclusion: OISMA通过利用准随机计算域（Bent-Pyramid系统）的计算简单性，并保持数字内存的效率、可扩展性和生产力，提出了一种新颖的内存计算架构。该架构将普通的内存读取操作转化为具有可忽略成本的原位随机乘法运算，并通过累加外围设备累加输出乘法比特流，实现了矩阵乘法功能。与64位双精度浮点格式相比，OISMA的精度结果显示平均相对Frobenius误差显著降低，从4x4矩阵的9.42%降至512x512矩阵的1.81%。在50 MHz频率下，OISMA实现了0.891 TOPS/W的能效和3.98 GOPS/mm²的面积效率，有效计算面积为0.804241 mm²。OISMA从180nm扩展到22nm技术节点，在能效和面积效率方面比密集矩阵乘法内存计算架构有显著的提升，前者提高了两个数量级，后者提高了一个数量级。

Abstract: Artificial Intelligence models are currently driven by a significant
up-scaling of their complexity, with massive matrix multiplication workloads
representing the major computational bottleneck. In-memory computing
architectures are proposed to avoid the Von Neumann bottleneck. However, both
digital/binary-based and analogue in-memory computing architectures suffer from
various limitations, which significantly degrade the performance and energy
efficiency gains. This work proposes OISMA, a novel in-memory computing
architecture that utilizes the computational simplicity of a quasi-stochastic
computing domain (Bent-Pyramid system), while keeping the same efficiency,
scalability, and productivity of digital memories. OISMA converts normal memory
read operations into in-situ stochastic multiplication operations with a
negligible cost. An accumulation periphery then accumulates the output
multiplication bitstreams, achieving the matrix multiplication functionality.
Extensive matrix multiplication benchmarking was conducted to analyze the
accuracy of the Bent-Pyramid system, using matrix dimensions ranging from 4x4
to 512x512. The accuracy results show a significant decrease in the average
relative Frobenius error, from 9.42% (for 4x4) to 1.81% (for 512x512), compared
to 64-bit double precision floating-point format. A 1T1R OISMA array of 4 KB
capacity was implemented using a commercial 180nm technology node and in-house
RRAM technology. At 50 MHz, OISMA achieves 0.891 TOPS/W and 3.98 GOPS/mm2 for
energy and area efficiency, respectively, occupying an effective computing area
of 0.804241 mm2. Scaling OISMA from 180nm to 22nm technology shows a
significant improvement of two orders of magnitude in energy efficiency and one
order of magnitude in area efficiency, compared to dense matrix multiplication
in-memory computing architectures.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [143] [Deconfined quantum criticality on a triangular Rydberg array](https://arxiv.org/abs/2508.08366)
*Lisa Bombieri,Torsten V. Zache,Gabriele Calliari,Mikhail D. Lukin,Hannes Pichler,Daniel González-Cuadra*

Main category: quant-ph

TL;DR: 本研究利用里德堡原子系统探索了DQCP，并在理论和数值上证实了其存在和特征，为实验研究提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 尽管DQCP在理论上被预测了几十年，但实验证据仍然难以捉摸。本研究旨在通过里德堡原子系统提供实验证据。

Method: 本研究采用场论分析方法，并结合数值模拟来预测临界指数和DQCP的特征。

Result: 本研究预测了DQCP在里德堡原子系统中的存在，并预测了临界指数和扩大的U(1)对称性。这些预测已通过数值模拟得到证实。

Conclusion: 本研究表明，在具有范德华相互作用的三角晶格中的里德堡原子系统可以探索DQCP。研究预测了无限长圆柱体在临界指数和临界附近共形场论的出现，以及扩大的U(1)对称性，这是DQCP的一个特征。研究还将在梯子几何形状中扩展这些结果，并展示如何使用有限的镊子阵列来探测U(1)对称性。

Abstract: Fluctuations can drive continuous phase transitions between two distinct
ordered phases -- so-called Deconfined Quantum Critical points (DQCPs) -- which
lie beyond the Landau-Ginzburg-Wilson paradigm. Despite several theoretical
predictions over the past decades, experimental evidence of DQCPs remains
elusive. We show that a DQCP can be explored in a system of Rydberg atoms
arranged on a triangular lattice and coupled through van der Waals
interactions. Specifically, we investigate the nature of the phase transition
between two ordered phases at 1/3 and at 2/3 Rydberg excitation density, which
were recently probed experimentally in [P. Scholl et al., Nature 595, 233
(2021)]. Using a field-theoretical analysis, we predict both the critical
exponents for infinitely long cylinders of increasing circumference and the
emergence of a conformal field theory near criticality showing an enlarged U(1)
symmetry -- a signature of DQCPs -- and confirm these predictions numerically.
Finally, we extend these results to ladder geometries and show how the emergent
U(1) symmetry could be probed experimentally using finite tweezer arrays.

</details>


### [144] [Exponentially Improved Constant in Quantum Solution Extraction](https://arxiv.org/abs/2508.08375)
*Gumaro Rendon*

Main category: quant-ph

TL;DR: A new algorithm extracts a crucial function from quantum memory, solving a major problem in using quantum computers for tasks like modeling heat or fluid flow.


<details>
  <summary>Details</summary>
Motivation: The motivation is to remove a significant bottleneck in fully solving an important class of differential equations on quantum computers, namely the extraction of solution information. This class of problems includes solutions to the heat equation and other diffusive equations used in fluid dynamics and finance.

Method: The paper presents an algorithm for extracting a smooth and positive definite function $\psi(x)$ encoded in quantum memory of size $2^n$. The algorithm is designed to avoid the problem of exponentially suppressed sub-normalization.

Result: The algorithm successfully extracts the function $\psi(x)$ without encountering exponentially suppressed sub-normalization, thereby removing a critical bottleneck in quantum solution information extraction for specific differential equations.

Conclusion: We have developed an algorithm to extract a smooth and positive definite function $\psi(x)$ from quantum memory, overcoming the issue of exponentially suppressed sub-normalization. This addresses a key challenge in extracting solution information from quantum computations, specifically for solving differential equations like the heat equation and other diffusive equations relevant to fluid dynamics and finance.

Abstract: We have provided an algorithm to extract a smooth and positive definite
function $\psi(x)$ encoded in quantum memory of size $2^n$ without running into
the problem of exponentially suppressed sub-normalization. Through this, we
remove an important bottleneck of solution information extraction, the last
step, in fully solving an important class of differential equations on quantum
computers. This class of problems includes solutions to the heat equation or
other diffusive equations in fluid dynamics and finance.

</details>


### [145] [Derivation from classical Majorana--Bloch equation to quantum von Neumann equation for any angular momenta in coherent states](https://arxiv.org/abs/2508.08414)
*Lihong V. Wang*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: After publishing the derivation from the classical Bloch equation to the
quantum von Neumann equation to the Schr\"odinger--Pauli equation for spin-1/2,
we proposed renaming the Bloch equation to the Majorana--Bloch equation because
Majorana's work predated Bloch's in the presentation of the Bloch equation by
14 years. Here, we generalize our previous derivation to higher spins or
angular momenta in coherent pure states. Using the polynomial representation of
the coherent-state projector, we derive an invertible mapping from the
Majorana--Bloch equation to the von Neumann equation, establishing a one-to-one
correspondence between these two formalisms. Application of the Ehrenfest
theorem also shows that expectation values in these states reproduce the
classical equation of motion.

</details>


### [146] [Cold atomic ensembles as quantum antennas for distributed networks of single-atom arrays](https://arxiv.org/abs/2508.08439)
*Xiaoshui Lin,Yefeng Mei,Chuanwei Zhang*

Main category: quant-ph

TL;DR: 为实现分布式量子计算，利用冷原子系作为量子天线，提高原子-光子纠缠效率，并支持量子存储。


<details>
  <summary>Details</summary>
Motivation: 在分布式量子网络中，由于原子-光耦合的固有弱耦合，实现远程节点间的纠缠仍然具有挑战性。

Method: 利用强原子-光相互作用的冷原子系作为量子天线，将单原子量子比特与飞行光子进行接口，实现高效率的原子-光子纠缠生成。

Result: 使用真实的实验参数，估计原子-光纠缠生成的效率约为$"0.548"$，原子-原子纠缠生成的概率约为$"6%"$，远程纠缠生成率为$"16.6 kHz"$。该性能超越了现有技术，并具有简单、可调和易于实验等优点。此外，该方案还集成了长寿命量子存储器，为量子中继器的设计提供了优势。

Conclusion: 该方案结合了单原子量子比特的局部操作和冷原子系的组网优势，为可扩展的分布式量子计算和传感铺平了道路。

Abstract: Single neutral atoms in optical tweezer arrays offer a promising platform for
high-fidelity quantum computing at local nodes. Nonetheless, creating
entanglement between remote nodes in a distributed quantum network remains
challenging due to inherently weak atom-light coupling. Here, we design a
distributed quantum network architecture in which cold atomic ensembles with
strong atom-light interactions act as quantum antennas, interfacing single-atom
qubits with flying photons to enable high-efficiency atom-photon entanglement
generation -- analogous to the role of antennas in classical communication.
Using realistic experimental parameters, we estimate an efficiency of $\eta
\simeq 0.548$ for generating atom-photon entanglement, a probability of $P_{E}
\simeq 6 \%$ for generating atom-atom entanglement, and a remote entanglement
generation rate of $16.6 $ kHz. This performance not only surpasses that of
state-of-the-art cavity-based or high-numerical-aperture-lens-based
architectures but also offers notable advantages in simplicity, tunability, and
experimental accessibility. Our scheme also integrates a long-lived quantum
memory, providing a storage advantage for quantum repeater design. By
leveraging the complementary strengths of single-atom qubits for local
operations and cold atomic ensembles for networking, this approach paves the
way for scalable distributed quantum computing and sensing.

</details>


### [147] [From free-evolution to tomographic representation](https://arxiv.org/abs/2508.08456)
*Sergio Cordero,Ramón López-Peña,Eduardo Nahmad-Achar,Octavio Castaños,Julio Aberto López-Saldívar,Vladimir I. Man'ko*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We use the free evolution propagator to determine the quantum probability
representation (i.e., the general expression of the tomogram) of any
one-dimensional system described by a density state. The evolution operator for
the considered quantum system is additionally used to establish the
corresponding time dependent tomogram. Applications are given for a Gaussian
wave packet, the quantum shutter related with the phenomenon of diffraction in
time, the double quantum shutter, and a finite potential. A generalisation to
describe $N$ particle systems is also presented and, in particular, we find the
tomogram associated to the 2 particle case occupying in general non-orthogonal
states. In the latter case, for a bipartite quantum system, the entanglement
properties are established by considering quantum information concepts such as
the linear entropy.

</details>


### [148] [Single-gate, multipartite entanglement on a room-temperature quantum register](https://arxiv.org/abs/2508.08465)
*Joseph D. Minnella,Mathieu Ouellet,Amelia R. Klein,Lee C. Bassett*

Main category: quant-ph

TL;DR: 通过并行化多量子比特纠缠门，显著提高了固态量子系统中纠缠态的生成速度和保真度。


<details>
  <summary>Details</summary>
Motivation: 固态量子寄存器（如金刚石中的NV中心）通常使用顺序、成对的门操作在中心电子和各个核量子比特之间创建纠缠态，但这种方法速度慢且存在串扰错误。

Method: 提出了一种并行的多量子比特纠缠门，用于在室温氮-空位（NV）中心生成四量子比特GHZ态。

Result: 在14.8微秒内生成了四量子比特GHZ态，速度比使用两量子比特门序列快10倍。两量子比特纠缠门的平均保真度为0.96(1)，四量子比特并行门的保真度为0.92(4)，而顺序四量子比特门的保真度仅为0.69(3)。

Conclusion: 该方法为可扩展的纠缠生成和控制奠定了基础，可推广到其他固态平台。

Abstract: Multipartite entanglement is an essential aspect of quantum systems, needed
to execute quantum algorithms, implement error correction, and achieve
quantum-enhanced sensing. In solid-state quantum registers such
nitrogen-vacancy (NV) centers in diamond, entangled states are typically
created using sequential, pairwise gates between the central electron and
individual nuclear qubits. This sequential approach is slow and suffers from
crosstalk errors. Here, we demonstrate a parallelized multi-qubit entangling
gate to generate a four-qubit GHZ state using a room-temperature NV center in
only 14.8 $\mu$s $-$ 10 times faster than using sequences of two-qubit gates.
The entangled states are verified by measuring multiple quantum coherences.
Two-qubit entangling gates have an average fidelity of 0.96(1), and the
four-qubit parallel gate has a fidelity of 0.92(4), whereas the sequential
four-qubit gate fidelity is only 0.69(3). The approach is generalizable to
other solid-state platforms, and it lays the foundation for scalable generation
and control of entanglement in practical devices.

</details>


### [149] [Simultaneous control of populations and coherence phase of open two-level quantum systems with a single pulse](https://arxiv.org/abs/2508.08532)
*Gustavo Fernandes da Costa,Emanuel Fernandes de Lima*

Main category: quant-ph

TL;DR: 通过逆转运动方程，设计了用于控制开放量子系统布居数和相干相位的单场控制方法。


<details>
  <summary>Details</summary>
Motivation: 控制开放两能级量子系统的布居数和相干相位动力学，只使用一个外部控制场。

Method: 通过逆转运动方程来设计控制场，得到一个解析表达式，该表达式将控制场表示为用户指定的、依赖于时间的布居数和相干相位函数。

Result: 提供了一种能够精确控制布居数和相干相位动力学的方法，并允许用户指定所需的时间演化路径，但需满足特定约束条件。

Conclusion: 该方法能够精确控制开放两能级量子系统的布居数和相干相位动力学，并能预测给定初始条件和环境噪声参数下的可能跃迁。

Abstract: We address the control of the dynamics of both population and coherence phase
in an open two-level quantum system employing a single external control field.
The system dynamics is described by a Markovian master equation that takes into
account dephasing and thermal noise. The control is engineered by inverting the
underlying equations of motion, which yields an analytical expression for the
control field in terms of user-specified time-dependent functions for the
population and coherence phase. Our approach allows to dictate not only the
initial and final populations and phases, but the full dynamics of these
quantities. The chosen functions for population and phase have to conform to
certain constraints indicated in our analysis. Our methodology also reveals the
possible transitions for given initial conditions and environmental noise
parameters.

</details>


### [150] [Quantum entanglement and extractable work for Gaussian states](https://arxiv.org/abs/2508.08584)
*Jaewon Lee,Changsuk Noh,Kabgyun Jeong,Hyunchul Nha*

Main category: quant-ph

TL;DR: 研究量化了可提取功与两模式高斯态（可分离、纠缠、可操纵）的量子关联之间的关系，发现不同类别的状态具有不同的可提取功。


<details>
  <summary>Details</summary>
Motivation: 旨在阐明量子原理在量子热力学过程的涌现特征中所起的作用，特别是理解量子关联如何在不同参与方之间实现与经典热力学不同的热力学特征。

Method: 通过分析两模式高斯态，研究了其中一方的局域能量变化与其另一方高斯测量之间的关系，并将此与两模式状态（可分离、纠缠、可操纵）的量子关联进行关联。

Result: 分析显示，可提取功存在明显的定量差异，具体取决于两模式状态所属的类别。

Conclusion: 该研究揭示了可提取功与量子关联之间的定量关系，并且这种关系因两模式状态的类别（可分离、纠缠、可操纵）而异。

Abstract: The study of quantum thermodynamics aims to elucidate the role played by
quantum principles in the emergent features of quantum thermodynamic processes.
Specifically, it is of fundamental importance to understand how quantum
correlation among different parties enables thermodynamic features
distinguishable from those arising in classical thermodynamics. In this work,
we investigate the relation between extractable work and quantum correlations
for two-mode Gaussian states. We examine the change in local energy occurring
at one party due to a Gaussian measurement performed on the other in relation
to the quantum correlations of two-mode states classified as separable,
entangled, and steerable states. Our analysis reveals a clear quantitative
difference in the extractable work, depending on the class of states to which
the two-mode state belongs.

</details>


### [151] [Can randomly structured metasurfaces be used for quantum tomography of high-dimensional spatial qudits?](https://arxiv.org/abs/2508.08597)
*Yuming Niu,Kai Wang*

Main category: quant-ph

TL;DR: 随机超表面在量子态层析成像中表现良好，可用于构建量子测量平台。


<details>
  <summary>Details</summary>
Motivation: 探索随机超表面是否足以用于高维qudit层析成像，以实现量子态层析成像的简化、小型化和可扩展性。

Method: 利用大规模模拟，对超过11,000个独特的、尺寸超过200个波长的随机超表面进行测试。

Result: 随机超表面在高达约10个状态的量子光子空间qudit层析成像中表现良好，并且讨论了多光子情况下的优化。

Conclusion: 通过数值实验表明，随机超表面在量子光子空间qudit状态层析成像中表现良好，可用于构建计算高效、小型化和容错的量子测量平台。

Abstract: Reconstructing the density matrix of the quantum state of photons through a
tomographically complete set of measurements, known as quantum state
tomography, is an essential task in nearly all applications of quantum science
and technology, from quantum sensing to quantum communications. Recent advances
in optical metasurfaces enable the design of ultra-thin nanostructured optical
elements performing such state tomography tasks, promising greater simplicity,
miniaturization, and scalability. However, reported metasurfaces on this goal
were limited to a small Hilbert dimension, e.g., polarization qubits or spatial
qudits with only a few states. When scaling up to higher-dimensional qudit
tomography problems, especially those involving spatial qudits, a natural
question arises: whether a metasurface with randomized nanostructures is
sufficient to perform such qudit tomography, achieving optimal conditions. In
this work, we attempt to answer this question through a set of numerical
experiments with random metasurfaces, utilizing large-scale simulations of over
11,000 distinct metasurfaces each exceeding 200 wavelengths in size. We show
that with sufficient redundancy in the number of detectors, random metasurfaces
perform reasonably well in quantum photonic spatial qudit tomography encoded in
Hermite-Gaussian states for up to approximately 10 states. Furthermore, we
discuss additional considerations for optimizing metasurfaces in multi-photon
cases. Our work opens a pathway toward computationally efficient, miniaturized,
and error-tolerant quantum measurement platforms.

</details>


### [152] [Stokes Parameters and Dual Classical-Quantum Signaling](https://arxiv.org/abs/2508.08630)
*Anjali Dhiman,Ziqing Wang,Timothy C. Ralph,Ryan Aguinaldo,Robert Malaney*

Main category: quant-ph

TL;DR: 提出了一种新的量子-经典通信协议，可用于卫星FSO网络，支持安全量子通信和高速经典通信，并具有更高的实用性、无需本地振荡器，且易于信息读取。


<details>
  <summary>Details</summary>
Motivation: 为了满足新兴的基于卫星的自由空间光（FSO）通信网络的需求，并利用偏振编码通过斯托克斯算子。

Method: 提出了一种新颖的量子-经典通信（SQCC）协议，该协议利用偏振编码和斯托克斯算子，实现了安全量子通信和高吞吐量经典通信的共存。

Result: 与传统的SQCC协议相比，新方法具有更优越的实际应用性，消除了对本地振荡器的需求，并允许使用直接检测简单地读出量子和经典信息，同时最大限度地减少了量子和经典通信部分之间不期望的相互作用。

Conclusion: 该协议为结合了量子通信和经典通信的自由空间光（FSO）通信网络提供了一种实用且高效的解决方案。

Abstract: Catering to emerging satellite-based free-space optical (FSO) communication
networks and exploiting polarization encoding via Stokes operators, we propose
a novel simultaneous quantum-classical communications (SQCC) protocol. The
protocol enables the coexistence of secure quantum communications and
high-throughput classical communications with minimal alterations in both the
infrastructure and the energy input. Compared to the conventional SQCC
protocol, our new approach provides superior practicality in the real world,
eliminates the need for a separate local oscillator, and allows for the simple
readout of both quantum and classical information using direct detection. The
protocol also minimizes the undesirable interplay between the quantum and the
classical parts of communication. We provide a detailed mathematical
formulation of the protocol, along with theoretical and numerical analysis of
its performance, illustrating a promising path to practical and effective
realization of combined classical-quantum communications

</details>


### [153] [Detecting Entanglement via Split Spectroscopy in Many-Body Systems](https://arxiv.org/abs/2508.08704)
*Hao-Yue Qi,Wei Zheng*

Main category: quant-ph

TL;DR: A new method called split spectroscopy can experimentally detect entanglement in quantum many-body systems. It works by observing a delta-function peak, and the spectral entropy can indicate phase transitions and entanglement scaling. An experiment using Rydberg atoms is proposed.


<details>
  <summary>Details</summary>
Motivation: Quantum entanglement is crucial for quantum information processing and understanding quantum many-body physics, but experimentally detecting it, especially in many-particle systems, is challenging. This work addresses this challenge by proposing a new detection technique.

Method: Split spectroscopy is proposed as an experimental technique to detect entanglement in quantum many-body systems. The method's effectiveness is demonstrated using two paradigmatic spin models, and its ability to capture entanglement scaling and indicate quantum phase transitions is shown through spectral entropy analysis. An experimental protocol using Rydberg atom arrays is also presented.

Result: The proposed split spectroscopy technique exhibits a single delta-function peak if and only if the investigated eigenstate is triseparable. Spectral entropy is shown to be a powerful indicator of quantum phase transitions and captures the scaling behavior of entanglement.

Conclusion: The study proposes split spectroscopy as a feasible method for detecting entanglement in quantum many-body systems, demonstrating its effectiveness using spin models and an experimental protocol with Rydberg atom arrays. The spectral entropy is identified as a key indicator for quantum phase transitions and entanglement scaling.

Abstract: Quantum entanglement is recognized as a fundamental resource in quantum
information processing and is essential for understanding quantum many-body
physics. However, experimentally detecting entanglement, particularly in
many-particle quantum states, remains a significant challenge. Here, we propose
split spectroscopy as an experimentally feasible technique for detecting
entanglement of eigenstates in quantum many-body systems. We demonstrate the
split spectroscopy exhibits a single delta-function peak if and only if the
investigated eigenstate is triseparable. Our framework is illustrated using two
paradigmatic spin models that undergo quantum phase transitions. Furthermore,
we show that the spectral entropy serves as a powerful indicator of quantum
phase transitions and captures the scaling behavior of entanglement. Finally,
we present an experimental protocol using Rydberg atom arrays.

</details>


### [154] [Continuous-variable quantum key distribution over 50.4 km fiber using integrated silicon photonic transmitter and receiver](https://arxiv.org/abs/2508.08722)
*Shuaishuai Liu,Yanxiang Jia,Yuqi Shi,Yizhuo Hou,Pu Wang,Yu Zhang,Shiwei Yang,Zhenguo Lu,Xuyang Wang,Yongmin Li*

Main category: quant-ph

TL;DR: 本文介绍了一种基于硅光子技术的集成式连续可变量子密钥分发（CV-QKD）系统，该系统具有高速率和长距离传输能力，为构建城域量子安全通信网络提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了克服量子密钥分发（QKD）成本高、体积大等实际部署中的主要障碍，本文探索了光子集成技术在量子密钥分发中的应用。

Method: 通过采用高速硅光集成锁相环调制器、低噪声高带宽硅光集成外差探测器和数字信号处理，实现了高达1.5625 GBaud的符号率。

Result: 实现了25.8公里和50.4公里标准单模光纤上的渐近密钥生成速率分别为31.05 Mbps和5.05 Mbps。

Conclusion: 该集成光学相干量子密钥分发系统为大都会地区量子安全通信网络奠定了基础。

Abstract: Quantum key distribution (QKD) is the fastest-growing and relatively mature
technology in the field of quantum information, enabling
information-theoretically secure key distribution between two remote users.
Although QKD based on off-the-shelf telecom components has been validated in
both laboratory and field tests, its high cost and large volume remain major
obstacles to large-scale deployment. Photonic integration, featured by its
compact size and low cost, offers an effective approach to addressing the above
challenges faced by QKD. Here, we implement a high-performance, integrated
local local oscillator continuous-variable (CV) QKD system based on an
integrated silicon photonic transmitter and receiver. By employing a high-speed
silicon photonic integrated in-phase and quadrature modulator, a low-noise and
high bandwidth silicon photonic integrated heterodyne detector, and digital
signal processing, our CV-QKD system achieves a symbol rate of up to 1.5625
GBaud. Furthermore, the system achieves asymptotic secret key rates of 31.05
and 5.05 Mbps over 25.8 and 50.4 km standard single-mode fiber, respectively,
using an 8-phase-shift keying discrete modulation. Our integrated CV-QKD system
with high symbol rate and long transmission distance pays the way for the
quantum secure communication network at metropolitan area.

</details>


### [155] [Generalized Kennedy Receivers Enhanced CV-QKD in Turbulent Channels for Endogenous Security of Space-Air-Ground Integrated Network](https://arxiv.org/abs/2508.08732)
*Shouye Miao,Renzhi Yuan,Bin Cao,Mufei Zhao,Zhifeng Wang,Mugen Peng*

Main category: quant-ph

TL;DR: 本文提出了一种CD-Kennedy接收器和EGC方法来提高CV-QKD在有损信道中的性能，并推导了相应的安全密钥率。结果表明CD-Kennedy接收器优于单模鉴别器，但需要根据传输率选择不同的系统设置。


<details>
  <summary>Details</summary>
Motivation: 为了提高相干状态在有损信道中的检测性能，并推导和优化后选择CV-QKD协议在有损信道中的安全密钥率。

Method: 本文采用广义Kennedy接收器（CD-Kennedy接收器）来增强相干状态在有损信道中的检测性能，并使用等增益合并（EGC）方法合并CD-Kennedy接收器的输出。此外，推导了在有损信道中使用CD-Kennedy接收器和单模鉴别器以及EGC的后选择CV-QKD协议的安全密钥率。还提出了一种等效传输方法来简化比特误率（BER）和安全密钥率（SKR）的计算。

Result: 数值结果表明，CD-Kennedy接收器在有损信道中的比特误率和安全密钥率性能优于单模鉴别器。CD-Kennedy接收器相对于单模鉴别器的误比特率和安全密钥率性能优势随着平均传输率的增加呈现出相反的趋势。CD-Kennedy接收器的安全密钥率性能在有损信道中比单模鉴别器鲁棒性更强。

Conclusion: CD-Kennedy接收器在有损信道中比单模鉴别器具有更好的误比特率和安全密钥率性能，并且其性能优势随着平均传输率的增加呈现出相反的趋势，这表明应为通信和密钥分发目的采用两个单独的系统设置。此外，CD-Kennedy接收器的安全密钥率性能在有损信道中比单模鉴别器鲁棒性更强。

Abstract: Endogenous security in next-generation wireless communication systems
attracts increasing attentions in recent years. A typical solution to
endogenous security problems is the quantum key distribution (QKD), where
unconditional security can be achieved thanks to the inherent properties of
quantum mechanics. Continuous variable-quantum key distribution (CV-QKD) enjoys
high secret key rate (SKR) and good compatibility with existing optical
communication infrastructure. Traditional CV-QKD usually employ coherent
receivers to detect coherent states, whose detection performance is restricted
to the standard quantum limit. In this paper, we employ a generalized Kennedy
receiver called CD-Kennedy receiver to enhance the detection performance of
coherent states in turbulent channels, where equal-gain combining (EGC) method
is used to combine the output of CD-Kennedy receivers. Besides, we derive the
SKR of a post-selection based CV-QKD protocol using both CD-Kennedy receiver
and homodyne receiver with EGC in turbulent channels. We further propose an
equivalent transmittance method to facilitate the calculation of both the
bit-error rate (BER) and SKR. Numerical results show that the CD-Kennedy
receiver can outperform the homodyne receiver in turbulent channels in terms of
both BER and SKR performance. We find that BER and SKR performance advantage of
CD-Kennedy receiver over homodyne receiver demonstrate opposite trends as the
average transmittance increases, which indicates that two separate system
settings should be employed for communication and key distribution purposes.
Besides, we also demonstrate that the SKR performance of a CD-Kennedy receiver
is much robust than that of a homodyne receiver in turbulent channels.

</details>


### [156] [Digital Quantum Simulation of Flat-Band and All-Bands-Flat Dynamics for Tunable Quantum Transport](https://arxiv.org/abs/2508.08734)
*Mrinal Kanti Giri,Pochung Chen*

Main category: quant-ph

TL;DR: 通过数字量子模拟和电路压缩技术，研究了平带格子上的动力学行为，并证明了其在量子控制和技术应用中的可行性。


<details>
  <summary>Details</summary>
Motivation: 研究平带（FB）和全带平（AFB）格子上的动力学行为，并探索其在量子控制和新兴量子技术中的应用潜力。

Method: 利用张量网络方法压缩量子电路，以克服NISQ设备的局限性，从而实现高保真度的长时间演化模拟。

Result: 在FB格子中观察到离域现象，在AFB格子中观察到阿哈罗诺夫-玻姆（Aharonov-Bohm） जेव्हा现象，并研究了FB和ABF格子结合对量子输运的控制作用，以及ABF格子对单粒子和双粒子动力学的影响。

Conclusion: 数字量子模拟在控制量子输运方面具有潜力，并且在当前的量子设备上是可行的。

Abstract: We study the dynamics on the flat-band (FB) and all-bands-flat (AFB) lattices
using a digital quantum computer. By utilizing an advanced tensor network
method to compress the quantum circuit, we overcome the intrinsic limitations
of current noisy intermediate-scale quantum (NISQ) computers. This enables
high-fidelity simulations of time evolution over extended timescales and
various interesting dynamical behaviours are observed in our digital quantum
simulation. We start from the quantum simulation of the single-particle quantum
walk on the FB and AFB lattices, which are realized by tuning the magnetic flux
per plaquette to $\phi=0$ and $\phi=\pi$ respectively. With compressed quantum
circuit, we are able to simulate the delocalization in FB lattice and the
Aharonov-Bohm caging in AFB lattice. Next, we integrate FB and ABF lattices
within a one-dimensional lattice structure and study how these lattices can be
utilized to control quantum transport. Moreover, we investigate the
effectiveness of a single ABF lattice in controlling the two particles dynamics
without and with interaction. We find that the hopping amplitude remains an
effective and tunable parameter for controlling particle transport even in the
presence of interactions. Our results show that digital quantum simulations of
flat-band physics are feasible on current digital NISQ devices through circuit
compression. Moreover, this capability enables us to study the potential
applications of flat-band systems in quantum control and emerging quantum
technologies.

</details>


### [157] [Subsampling Factorization Machine Annealing](https://arxiv.org/abs/2508.08778)
*Yusuke Hama,Tadashi Kadowaki*

Main category: quant-ph

TL;DR: SFMA通过使用子数据集训练因子分解机模型，提高了解决黑盒优化问题的探索-利用平衡能力和效率，尤其在大规模问题上表现更佳。


<details>
  <summary>Details</summary>
Motivation: 量子计算和机器学习的混合技术有望成为解决复杂问题的有力工具。本研究旨在通过改进FMA来解决黑盒优化问题，以提高其探索解空间的性能。

Method: 提出了一种改进的因子分解机退火（FMA）的算法，称为子采样因子分解机退火（SFMA），该算法通过使用子数据集而不是整个数据集来训练因子分解机模型，从而解决黑盒优化问题。SFMA通过顺序使用不同大小的子采样数据集（后一个数据集远小于前一个数据集）可以进一步提高性能。

Result: SFMA展示了良好的探索-利用平衡功能，并在速度和准确性方面优于FMA。此外，通过顺序使用不同大小的子采样数据集，SFMA的性能可以得到进一步提升，尤其是在处理大规模问题时，计算成本较低。

Conclusion: SFMA在解决特定类别的大规模黑盒优化问题方面是有效的，并且具有良好的可扩展性，计算成本低。

Abstract: Quantum computing and machine learning are state-of-the-art technologies
which have been investigated intensively in both academia and industry. The
hybrid technology of these two ingredients is expected to be a powerful tool to
solve complex problems in many branches of science and engineering such as
combinatorial optimization problems and accelerate the creation of
next-generation technologies. In this work, we develop an algorithm to solve a
black-box optimization problem by improving Factorization Machine Annealing
(FMA) such that the training of a machine learning model called Factorization
Machine is performed not by a full dataset but by a subdataset which is sampled
from a full dataset: Subsampling Factorization Machine Annealing (SFMA).
According to such a probabilistic training process, the performance of FMA on
exploring a solution space gets enhanced. As a result, SFMA exhibits balanced
performance of exploration and exploitation which we call
exploitation-exploration functionality. We conduct numerical benchmarking tests
to compare the performance of SFMA with that of FMA. Consequently, SFMA
certainly exhibits the exploration-exploitation functionality and outperforms
FMA in speed and accuracy. In addition, the performance of SFMA can be further
improved by sequentially using two subsampling datasets with different sizes
such that the size of the latter dataset is substantially smaller than the
former. Such a substantial reduction not only enhances the exploration
performance of SFMA but also enables us to run it with correspondingly low
computational cost even for a large-scale problem. These results indicate the
effectiveness of SFMA in a certain class of black-box optimization problems of
significant size: the potential scalability of SFMA in solving large-scale
problems with correspondingly low computational cost.

</details>


### [158] [Measurement-Based Quantum Diffusion Models](https://arxiv.org/abs/2508.08799)
*Xinyu Liu,Jingze Zhuang,Wanda Hou,Yi-Zhuang You*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce measurement-based quantum diffusion models that bridge classical
and quantum diffusion theory through randomized weak measurements. The
measurement-based approach naturally generates stochastic quantum trajectories
while preserving purity at the trajectory level and inducing depolarization at
the ensemble level. We address two quantum state generation problems:
trajectory-level recovery of pure state ensembles and ensemble-average recovery
of mixed states. For trajectory-level recovery, we establish that quantum score
matching is mathematically equivalent to learning unitary generators for the
reverse process. For ensemble-average recovery, we introduce local Petz
recovery maps for states with finite correlation length and classical shadow
reconstruction for general states, both with rigorous error bounds. Our
framework establishes Petz recovery maps as quantum generalizations of reverse
Fokker-Planck equations, providing a rigorous bridge between quantum recovery
channels and classical stochastic reversals. This work enables new approaches
to quantum state generation with potential applications in quantum information
science.

</details>


### [159] [Extended Parameter Shift Rules with Minimal Derivative Variance for Parameterized Quantum Circuits](https://arxiv.org/abs/2508.08802)
*Zhijian Lai,Jiang Hu,Dong An,Zaiwen Wen*

Main category: quant-ph

TL;DR: 提出了一种新的参数移位规则EPSR，可以提高量子导数估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了计算参数化量子电路中成本函数的任意阶导数，并提高导数估计的准确性。

Method: 提出了一种扩展参数移位规则（EPSR），泛化了现有的大部分参数移位规则，并证明了其有效性。

Result: 通过数值模拟证明了EPSR的有效性，并表明使用最优参数移位确实能得到更准确的导数估计。

Conclusion: EPSRs可以处理任意厄米算子H，并提供无限多的参数移位选择，以最小化最终导数方差，从而在量子资源有限的情况下获得更准确的导数估计。

Abstract: Parameter shift rules (PSRs) are useful methods for computing arbitrary-order
derivatives of the cost function in parameterized quantum circuits. The basic
idea of PSRs is to evaluate the cost function at different parameter shifts,
then use specific coefficients to combine them linearly to obtain the exact
derivatives. In this work, we propose an extended parameter shift rule (EPSR)
which generalizes a broad range of existing PSRs and has the following two
advantages. First, EPSR offers an infinite number of possible parameter shifts,
allowing the selection of the optimal parameter shifts to minimize the final
derivative variance and thereby obtaining the more accurate derivative
estimates with limited quantum resources. Second, EPSR extends the scope of the
PSRs in the sense that EPSR can handle arbitrary Hermitian operator $H$ in gate
$U(x) = \exp (iHx)$ in the parameterized quantum circuits, while existing PSRs
are valid only for simple Hermitian generators $H$ such as simple Pauli words.
Additionally, we show that the widely used ``general PSR'', introduced by
Wierichs et al. (2022), is a special case of our EPSR, and we prove that it
yields globally optimal shifts for minimizing the derivative variance under the
weighted-shot scheme. Finally, through numerical simulations, we demonstrate
the effectiveness of EPSR and show that the usage of the optimal parameter
shifts indeed leads to more accurate derivative estimates.

</details>


### [160] [A Brief Introduction to Quantum Query Complexity](https://arxiv.org/abs/2508.08852)
*Yassine Hamoudi*

Main category: quant-ph

TL;DR: This document introduces quantum query lower bounds using four methods (hybrid, polynomial, recording, adversary) and discusses the adversary method's dual role, suitable for those with basic quantum computing knowledge and researchers.


<details>
  <summary>Details</summary>
Motivation: To provide a structured introduction to quantum query lower bounds, covering key techniques and their applications, making it accessible to readers with a basic quantum computing background and serving as an entry point for researchers.

Method: The paper introduces four major techniques for quantum query lower bounds: the hybrid method, the polynomial method, the recording method, and the adversary method. It also discusses the adversary method's application in deriving upper bounds.

Result: The analysis covers four major techniques for quantum query lower bounds and discusses the dual role of the adversary method. It aims to be a self-contained exposition.

Conclusion: The document provides a structured introduction to quantum query lower bounds using four major techniques (hybrid, polynomial, recording, and adversary methods), discusses the adversary method's dual role in deriving upper bounds, and aims to be accessible to those with a basic quantum computing background while serving as an entry point for researchers.

Abstract: Quantum query complexity is a fundamental model for analyzing the
computational power of quantum algorithms. It has played a key role in
characterizing quantum speedups, from early breakthroughs such as Grover's and
Simon's algorithms to more recent developments in quantum cryptography and
complexity theory. This document provides a structured introduction to quantum
query lower bounds, focusing on four major techniques: the hybrid method, the
polynomial method, the recording method, and the adversary method. Each method
is developed from first principles and illustrated through canonical problems.
Additionally, the document discusses how the adversary method can be used to
derive upper bounds, highlighting its dual role in quantum query complexity.
The goal is to offer a self-contained exposition accessible to readers with a
basic background in quantum computing, while also serving as an entry point for
researchers interested in the study of quantum lower bounds.

</details>


### [161] [Dicke-Stark model, coherent state space, superradiant phase transition, equilibrium state, quantum entanglement](https://arxiv.org/abs/2508.08860)
*Weilin Wang,Ronghai Liu,Fangcheng Qiu,Mingshu Zhao,Jinying Ma,Zhanyuan Yan*

Main category: quant-ph

TL;DR: 该研究通过数值和解析方法分析了迪克-斯塔克模型，发现了光场聚集/反聚集行为、斯塔克场对关联函数的影响以及温度对纠缠和自旋压缩的作用，为理解相关量子现象提供了基础。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解强耦合光-原子系统中的量子现象，特别是迪克-斯塔克模型中由耦合强度和斯塔克场引起的多体相变和量子关联行为。

Method: 通过数值方法求解耦合光-原子系统的缀饰主方程，获得有限尺寸迪克-斯塔克模型的能量谱和热平衡态。利用平均场方法解析推导出无限尺寸迪克-斯塔克模型的超辐射相变临界点，并通过数值计算进行验证。分析了有限尺寸模型中的负熵、零延迟两光子关联函数以及原子-自旋压缩参数。

Result: 在耦合强度增加时，光场从光子聚集转变为反聚集再转变为聚集。斯塔克场能够调节两光子关联函数的最大值、最小值及其对应的耦合强度。低温下系统存在纠缠和自旋压缩，但随温度升高而减弱，强耦合有助于维持纠缠。原子-自旋压缩对温度敏感，随温度升高迅速消失。

Conclusion: 该研究对有限尺寸的迪克-斯塔克模型在扩展相干态空间中的能量谱和热平衡态进行了数值分析，并通过平均场方法和数值计算验证了无限尺寸模型中超辐射相变的关键点。研究还分析了有限尺寸模型中的负熵、零延迟两光子关联函数和原子-自旋压缩参数，发现在耦合强度增加时，光场会经历从光子聚集到反聚集再到聚集的转变。斯塔克场可以调节两光子关联函数的最大值和最小值及其对应的耦合强度。在低温下，系统表现出纠缠和自旋压缩；随着温度升高，纠缠逐渐减弱，但强耦合有助于维持系统态中的纠缠。原子-自旋压缩对温度非常敏感，并随着温度升高而迅速消失。此项工作有助于加深对迪克-斯塔克系统中量子现象的理解。

Abstract: In this study, the energy spectrum and thermal equilibrium states of the
finite-size Dicke-Stark model were numerically obtained within the extended
coherent state space by solving the dressed master equation for strongly
coupled light-atom systems. The critical point of the superradiant phase
transition in the infinite-size Dicke-Stark model was analytically derived
using the mean-field approach and confirmed with numerical calculation. Under
thermal equilibrium conditions, analyses of the negativity, zero-time-delay
two-photon correlation function, and atom-spin squeezing parameters in the
finite-size Dicke-Stark model reveal that as the coupling strength increases,
the light field undergoes a transition from photon bunching to anti-bunching
and then back to bunching. The Stark field can modulate both the maximum and
minimum values of the two-photon correlation function and their corresponding
coupling strengths. At low temperatures, the system exhibits entanglement and
spin squeezing. As temperature rises, entanglement gradually diminishes, while
strong coupling facilitates the preservation of entanglement in the system
state. Atom-spin squeezing spin squeezing is highly sensitive to temperature
and vanishes rapidly with increasing temperature. This work contributes to the
fundamental understanding of quantum phenomena in Dicke-Stark systems.

</details>


### [162] [Evidence of scaling advantage on an NP-Complete problem with enhanced quantum solvers](https://arxiv.org/abs/2508.08869)
*Quanfeng Lu,Shijie Wei,Keren Li,Pan Gao,Bao Yan,Muxi Zheng,Haoran Zhang,Jinfeng Zeng,Gui-Lu Long*

Main category: quant-ph

TL;DR: 通过约束空间缩减算法（RSRA）增强QAOA和QAA，在处理NP完全问题时展现出优于经典算法的性能和扩展优势，并在实际量子硬件上得到验证，为量子计算在解决复杂问题上的应用提供了重要实证。


<details>
  <summary>Details</summary>
Motivation: 为了在嘈杂中等规模量子（NISQ）时代实现量子优势，需要解决诸如NP完全问题等经典难题，并证明量子算法的扩展优势。现有量子优化算法尚未直接在经典难以处理的问题上展示出这种优势。

Method: 提出约束空间缩减算法（RSRA），以优化搜索空间维度，减少量子比特和时间复杂度；开发增强型QAOA和QAA量子求解器；在包含多达65个变量的问题实例上进行数值模拟；在13个量子比特的超导量子处理器上进行实验实现。

Result: 增强型QAOA和QAA求解器在处理大规模（高达65个变量）一中布尔可满足性问题时，表现优于最先进的经典求解器。QAA求解器展示了扩展优势。实验结果证实了预测的性能提升，为NP完全问题提供了量子加速的实证证据。

Conclusion: 该研究通过提出一种约束空间缩减算法（RSRA）来增强量子优化算法（QAOA）和量子绝热算法（QAA）在处理NP完全问题（一中布尔可满足性问题）上的性能，并在包含多达65个变量的问题实例上进行了数值验证，证明了其优于现有经典算法的性能，特别是QAA算法展示了扩展优势。此外，研究团队在13个量子比特的超导量子处理器上进行了实验验证，为NP完全问题提供了量子加速的实证证据。

Abstract: Achieving quantum advantage remains a key milestone in the noisy
intermediate-scale quantum era. Without rigorous complexity proofs, scaling
advantage-where quantum resource requirements grow more slowly than their
classical counterparts-serves as the primary indicator. However, direct
applications of quantum optimization algorithms to classically intractable
problems have yet to demonstrate this advantage. To address this challenge, we
develop enhanced quantum solvers for the NP-complete one-in-three Boolean
satisfiability problem. We propose a restricting space reduction algorithm
(RSRA) that achieves optimal search space dimensionality, thereby reducing both
qubits and time complexity for various quantum solvers. Extensive numerical
investigations on problem instances with up to 65 variables demonstrate that
our enhanced quantum approximate optimization algorithm (QAOA) and quantum
adiabatic algorithm (QAA)-based solvers outperform state-of-the-art classical
solvers, with the QAA-based solver providing a lower bound for our method while
exhibiting scaling advantage. Furthermore, we experimentally implement our
enhanced solvers on a superconducting quantum processor with 13 qubits,
confirming the predicted performance improvements. Collectively, our results
provide empirical evidence of quantum speedup for an NP-complete problem.

</details>


### [163] [Statistical analysis of barren plateaus in variational quantum algorithms](https://arxiv.org/abs/2508.08915)
*Le Bin Ho,Jesus Urbaneja,Sahel Ashhab*

Main category: quant-ph

TL;DR: 本研究区分了三种贫瘠平原现象，发现其在VQE中普遍存在，并提出使用基因算法进行优化以提高量子算法性能。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法（VQAs）在量子计算中具有广泛应用前景，但其优化过程中常遇到“贫瘠平原”现象，即成本函数梯度消失，阻碍了有效优化。本研究旨在深入理解贫瘠平原现象的成因，并探索缓解该问题的方法。

Method: 本研究采用了统计方法，并使用高斯函数模型来说明三种贫瘠平原的类型：局部下降点、局部峡谷线和平坦区域。随后，将该分析方法应用于变分量子特征求解器（VQE），并考察了硬件高效量子线路和随机泡利量子线路两种模型。最后，使用基因算法优化随机门以减轻贫瘠平原现象。

Result: 研究识别出三种贫瘠平原：局部下降点、局部峡谷线和平坦区域。在VQE的硬件高效和随机泡利量子线路模型中，仅观察到平坦区域类型的贫瘠平原。基因算法的应用有效改善了优化效率。

Conclusion: 本研究通过统计方法研究了变分量子算法中的“贫瘠平原”现象，区分了三种类型的贫瘠平原：局部下降点、局部峡谷线和平坦区域。研究发现，在硬件高效和随机泡利两种量子线路模型中，主要存在平坦区域类型的贫瘠平原。通过基因算法优化随机门，可以重塑成本函数，提高优化效率和算法的可扩展性与可靠性。

Abstract: We investigate the barren plateau (BP) phenomenon in variational quantum
algorithms using a statistical approach. Using Gaussian function models, we
identify three distinct types of BPs. The first type, which we called
localized-dip BPs, occurs in landscapes that are mostly flat but contain a dip
point where the gradient is large in a small region around the minimum. The
second type, called localized-gorge BPs, which are somewhat similar to the
localized-dip BPs but contain a gorge line. The third type, called
everywhere-flat BPs, appears when the entire landscape is uniformly flat with
almost vanishing gradients, making optimization significantly more difficult.
After illustrating these behaviors in the Gaussian function models, we extend
the analysis to the variational quantum eigensolver (VQE). We consider two
types of ans\"atze: the hardware-efficient ansatz and the random Pauli ansatz.
For both ans\"atze, we only observe the everywhere-flat BPs. Using our
statistical approach, we searched for localized-dip and localized-gorge BPs but
found no evidence of such features in the examples studied, suggesting that
everywhere-flat BPs dominate in these ans\"atze. Our method effectively probes
landscape features by capturing the gradient scaling across parameter space,
making it a useful tool for diagnosing BPs in variational algorithms. To
mitigate BPs in the VQE, we employ a genetic algorithm (GA) to optimize the
random gates generated in the ans\"atze, thereby reshaping the cost function
landscape to enhance the optimization efficiency. A comparison with an
unoptimized ansatz shows how the ansatz design can improve the scalability and
reliability of variational quantum algorithms.

</details>


### [164] [Neural quantum states for emitter dynamics in waveguide QED](https://arxiv.org/abs/2508.08964)
*Tatiana Vovk,Anka Van de Walle,Hannes Pichler,Annabelle Bohrdt*

Main category: quant-ph

TL;DR: 提出了一种新的数值方法（扩展的t-NQS框架）来研究量子发光器与一维波导耦合的系统动力学，解决了传统方法在发光器任意间隔时无法获得解析解的问题，并证明了该方法在模拟开放量子多体系统方面的有效性和竞争力。


<details>
  <summary>Details</summary>
Motivation: 解决量子发光器与一维波导耦合系统中，当发光器任意间隔时，传统Dicke模型对称性丢失导致解析解失效的问题

Method: 利用扩展的t-NQS框架研究开放量子系统的动力学

Result: t-NQS方法在模拟该类系统时与张量网络计算等其他数值方法具有竞争力，并展示了其在研究非平衡态开放量子多体系统方面的能力。 论文通过一系列波导量子电动力学（QED）设置对该方法进行了基准测试和性能比较。 

Conclusion: t-NQS 方法在研究开放量子多体系统方面具有潜力

Abstract: Quantum emitters coupled to one-dimensional waveguides constitute a
paradigmatic quantum-optical platform for exploring collective phenomena in
open quantum many-body systems. For appropriately spaced emitters, they realize
the Dicke model, whose characteristic permutation symmetry allows for efficient
exact solutions featuring superradiance. When the emitters are arbitrarily
spaced, however, this symmetry is lost and general analytical solutions are no
longer available. In this work, we introduce a novel numerical method to study
the dynamics of such systems by extending the time-dependent neural quantum
state (t-NQS) framework to open quantum systems. We benchmark our approach
across a range of waveguide QED settings and compare its performance with
tensor-network calculations. Our results demonstrate that the t-NQS approach is
competitive with other numerical methods and highlight the potential of t-NQSs
for studying open quantum many-body systems out of equilibrium.

</details>


### [165] [Mutually equi-biased bases](https://arxiv.org/abs/2508.08969)
*Seyed Javad Akhtarshenas,Saman Karimi,Mahdi Salehi*

Main category: quant-ph

TL;DR: 本文放宽了互无偏基（MUBs）的无信息条件，提出了互等偏基（MEBs），并推导了$d=2,3$的MEBs。研究了MEBs对概率分布的约束，并构建了相关的纠缠见证。


<details>
  <summary>Details</summary>
Motivation: 在互无偏基（MUBs）框架中，一个基中的测量给出了关于另一个基中测量结果的“无信息”。本文放宽了这个条件，允许测量结果根据预定义的概率分布$q$来预测。

Method: 在互无偏基（MUBs）框架中，我们放宽了无信息条件，允许根据预定义的概率分布$q=(q_0,\cdots,q_{d-1})$来预测测量结果。我们定义了“互等偏基”（MEBs），使得基内的状态对于其他基的状态是等偏的，并且各基之间也互为等偏。

Result: 我们导出了$d=2,3$的$d+1$个MEBs的完备集。对于$d=3$，我们发现$\\mu=\\sum_{k=0}^{2}q_k^2$的取值范围必须在$[1/3, 1/2]$之间。我们推导了一个不等式来捕获MEBs中测量的不可兼容性，并构建了与MEBs相关的正映射和纠缠见证。最后，我们展示了使用MEBs的纠缠见证在某些情况下可以比使用MUBs的见证更精细。

Conclusion: MEBs通过允许预定义的概率分布$q$来放宽了MUBs的无信息条件，并保持了互无偏性。对于$d=2,3$，我们推导出了$d+1$个MEBs的完备集。MEBs对$q$施加了约束，例如对于$d=3$，$\mu=\sum_{k=0}^{2}q_k^2$的取值范围为$[1/3, 1/2]$。我们还推导了一个用于捕获MEBs中测量不相容性的不等式，并基于MEBs构建了正映射和相关的纠缠见证。

Abstract: In the framework of mutually unbiased bases (MUBs), a measurement in one
basis gives \emph{no information} about the outcomes of measurements in another
basis. Here, we relax the no-information condition by allowing the $d$ outcomes
to be predicted according to a predefined probability distribution
$q=(q_0,\cdots,q_{d-1})$. The notion of mutual unbiasedness, however, is
preserved by requiring that the extracted information is the same for any
preparation and any measurement; regardless of which state from which basis is
chosen to prepare the system, the outcomes of measuring the system with respect
to the other basis generate the same probability distribution. In the light of
this, we define the notion of \emph{mutually equi-biased bases} (MEBs) such
that within each basis the states are equi-biased with respect to the states of
the other basis and that the bases are mutually equi-biased with respect to
each other. For $d=2,3$, we derive a complete set of $d+1$ MEBs. The mutual
equi-biasedness imposes nontrivial constraints on the distribution $q$, leading
for $d=3$ to the restriction $1/3\le\mu \le 1/2$ where
$\mu=\sum_{k=0}^{2}q_k^2$. To capture the incompatibility of the measurements
in MEBs, we derive an inequality for the probabilities of projective
measurements in a qudit system, which yields an associated entropic uncertainty
inequality. Finally, we construct a class of positive maps and their associated
entanglement witnesses based on MEBs. While an entanglement witness constructed
from MUBs is generally finer than one based on MEBs when both use the same
number of bases, for certain values of the index $\mu$, employing a larger set
of MEBs can yield a finer witness. We illustrate this behavior using isotropic
states of a $3\times 3$ system.

</details>


### [166] [Realizing the Petz Recovery Map on an NMR Quantum Processor](https://arxiv.org/abs/2508.08998)
*Gayatri Singh,Ram Sagar Sahani,Vinayak Jagadish,Lea Lautenbacher,Nadja K. Bernardes,Kavita Dorai*

Main category: quant-ph

TL;DR: 本研究在NMR量子处理器上使用DQC算法成功实现了Petz恢复图，恢复的量子态与理论预测一致，证明了其在近期纠错策略中的潜力。


<details>
  <summary>Details</summary>
Motivation: Petz恢复图是量子信息理论中的一个基本协议，能够实现对因噪声过程丢失的量子信息的检索。

Method: 利用对偶量子计算（DQC）算法在核磁共振（NMR）量子处理器上进行实验。

Result: 实验重点关注了两种典型的单量子比特通道，即相位阻尼和幅度阻尼，所恢复的量子态与理论预测高度吻合。

Conclusion: 实验结果验证了基于Petz的恢复图在现有量子平台上的可行性，并强调了其在近期纠错策略中的相关性。

Abstract: The Petz recovery map is a fundamental protocol in quantum information
theory, enabling the retrieval of quantum information lost due to noisy
processes. Here, we experimentally implement the Petz recovery map on a nuclear
magnetic resonance (NMR) quantum processor using the duality quantum computing
(DQC) algorithm. Focusing on two paradigmatic single-qubit channels, namely
phase damping and amplitude damping, we demonstrate that the recovered states
closely match theoretical predictions. Our results validate the feasibility of
the Petz-based recovery map in current quantum platforms and highlight its
relevance for near-term error mitigation strategies.

</details>


### [167] [Finite-dimensional approximations of generalized squeezing](https://arxiv.org/abs/2508.09041)
*Sahel Ashhab,Felix Fischer,Davide Lonigro,Daniel Braak,Daniel Burgarth*

Main category: quant-ph

TL;DR: 模拟广义压缩时，有限维度截断的奇偶性会影响结果，这与哈密顿量的自伴性质有关。加入Kerr相互作用项可以解决这个问题，使模拟结果具有物理意义。


<details>
  <summary>Details</summary>
Motivation: 研究广义压缩在有限维度截断模拟中的行为，特别是截断维度奇偶性对结果的影响，并探究其物理意义和可行的解决方案。

Method: 通过有限维度的Fock空间截断模拟广义压缩，分析了截断维度奇偶性对模拟结果的影响，并研究了对应奇偶截断的压缩算符的谱，以阐明两种不同自伴扩延的性质。最后，引入Kerr相互作用项，研究其对哈密顿量自伴性质及模拟收敛性的影响。

Result: 模拟结果表明，有限维度截断的Fock空间中广义压缩的行为表现出与截断维度奇偶性相关的意外行为。即使在极大的状态空间维度下，结果也依赖于截断维度的奇偶性。这表明截断可能对应于两种不同的酉演化。引入Kerr相互作用项后，模拟结果不再依赖于截断维度的奇偶性，并且模拟收敛，表明Kerr项使哈密顿量自伴且物理解释明确。

Conclusion: 模拟结果的有效性取决于截断空间的奇偶性，这源于广义压缩哈密顿量在有限激发态下的非自伴性质及其多种自伴扩延。通过引入Kerr相互作用项，可以使哈密顿量自伴，从而得到与截断空间奇偶性无关且物理解释明确的模拟结果。

Abstract: We show unexpected behaviour in simulations of generalized squeezing
performed with finite-dimensional truncations of the Fock space: even for
extremely large dimension of the state space, the results depend on whether the
truncation dimension is even or odd. This situation raises the question whether
the simulation results are physically meaningful. We demonstrate that, in fact,
the two truncation schemes correspond to two well-defined, distinct unitary
evolutions whose generators are defined on different subsets of the
infinite-dimensional Fock space. This is a consequence of the fact that the
generalized squeezing Hamiltonian is not self-adjoint on states with finite
excitations, but possesses multiple self-adjoint extensions. Furthermore, we
present results on the spectrum of the squeezing operators corresponding to
even and odd truncation size that elucidate the properties of the two different
self-adjoint extensions corresponding to the even and odd truncation scheme. To
make the squeezing operator applicable to a physical system, we must regularize
it by other terms that depend on the specifics of the experimental
implementation. We show that the addition of a Kerr interaction term in the
Hamiltonian leads to uniquely converging simulations, with no dependence on the
parity of the truncation size, and demonstrate that the Kerr term indeed
renders the Hamiltonian self-adjoint and thus physically interpretable.

</details>


### [168] [Weak measurement in strong laser field physics](https://arxiv.org/abs/2508.09048)
*Philipp Stammer,Javier Rivera-Dean,Marcelo F. Ciappina,Maciej Lewenstein*

Main category: quant-ph

TL;DR: 阿秒干涉实验等同于弱测量，揭示了其与强场物理和阿秒科学的联系。电子轨迹因弱测量获得新相位，影响光谱特征。非经典驱动场产生的谐波具有特殊的量子态和光子统计特性。


<details>
  <summary>Details</summary>
Motivation: 阿秒测量的优势在于能够进行时间分辨的超快量子现象（如电子动力学）的测量。许多此类测量具有干涉性质，能够获取相位信息。弱测量本质上也是干涉性的，并且能提取相位信息。因此，本研究旨在揭示阿秒干涉实验与弱测量的联系，并探索其在强场物理学和阿秒科学中的应用。

Method: 本研究将阿秒干涉实验视为弱测量，并分析了电子轨迹如何获得由于弱测量过程产生的新相位，特别是在存在光谱特征的情况下。此外，研究还将该方法扩展到非经典驱动场，分析了产生的谐波的量子态和光子统计特征。

Result: 研究表明，阿秒干涉实验可以被视为弱测量，电子轨迹会获得新的相位，该相位在存在光谱特征时会产生显著影响。当使用非经典驱动场时，产生的谐波会表现出非平凡的量子态和光子统计特征。

Conclusion: 该研究将阿秒干涉实验视为弱测量，揭示了其与强场物理学和阿秒科学的联系，并展示了电子轨迹如何获得由于弱测量过程产生的新相位，该相位在存在光谱特征时可能具有显著贡献。此外，将该方法扩展到非经典驱动场，发现在产生的谐波中存在非平凡的量子态和光子统计特征，这为阿秒量子干涉实验的研究开辟了道路。

Abstract: The advantage of attosecond measurements is the possibility of time-resolving
ultrafast quantum phenomena of electron dynamics. Many such measurements are of
interferometric nature, and therefore give access to the phase. Likewise, weak
measurements are intrinsically interferometric and specifically take advantage
of interfering probability amplitudes, therefore encoding the phase information
of the process. In this work, we show that attosecond interferometry
experiments can be seen as a weak measurement, which unveils how this notion is
connected to strong field physics and attosecond science. In particular, we
show how the electron trajectory picks up a new phase, which occurs due to the
weak measurement of the process. This phase can show significant contributions
in the presence of spectral features of the measured system. Furthermore,
extending this approach to include non-classical driving fields shows that the
generated harmonics exhibit non-trivial features in their quantum state and
photon statistics. This opens the path towards investigations of attosecond
quantum interferometry experiments.

</details>


### [169] [Quantum stochastic analysis of non-linear driven light emission](https://arxiv.org/abs/2508.09049)
*Philipp Stammer*

Main category: quant-ph

TL;DR: 本研究将量子光学高次谐波生成模型扩展到开放系统，发现强驱动腔的发射特性与高次谐波生成同构，并为连接相关方法提供了途径。


<details>
  <summary>Details</summary>
Motivation: 本研究的目的是将量子光学高次谐波生成模型扩展到考虑与环境耦合的场模式的量子随机分析，以研究开放系统的动力学，并为将当前方法与驱动耗散系统联系起来提供途径。

Method: 本研究采用量子随机分析方法，通过求解非线性驱动耦合腔与环境的量子朗之万方程来研究开放系统的动力学，并利用量子回归定理应用于马尔可夫动力学。

Result: 研究表明，在无记忆的非结构化环境中，强驱动腔的发射特性与高次谐波生成和非线性天线的发射过程同构，并获得了由发射体涨落引起的辐射功率上限。

Conclusion: 本研究将量子光学高次谐波生成模型扩展到考虑了与环境耦合的场模式的量子随机分析。通过求解非线性驱动耦合腔与环境的量子朗之万方程，研究了开放系统的动力学。对于无记忆的非结构化环境，我们证明了强驱动腔的发射特性与高次谐波生成和非线性天线的发射过程是同构的。这通过量子回归定理应用于马尔可夫动力学得以实现，并进一步允许获得由发射体涨落引起的辐射功率上限。这为将当前量子光学高次谐波生成方法与开放系统描述以及非线性区域的驱动耗散系统联系起来铺平了道路。

Abstract: This work extends quantum optical models of high harmonic generation by
considering a quantum stochastic analysis of the field modes coupled to an
environment. In particular, we study the open system dynamics by solving the
quantum Langevin equation for a non-linear driven cavity coupled to the
environment. For an unstructured environment without memory, we show that the
emission characteristics of the intense driven cavity is isomorphic to the
process of high harmonic generation and a non-linear antenna. This is achieved
by using the quantum regression theorem for the Markovian dynamics, and further
allows to obtain the upper bound of the radiated power due to the emitter
fluctuations. This opens the path to connect current quantum optical approaches
of HHG with open system descriptions and towards driven-dissipative systems in
the non-linear regime.

</details>


### [170] [Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware](https://arxiv.org/abs/2508.09050)
*Germán Díaz Agreda,Carlos Andres Duran Paredes,Mateo Buenaventura Samboni,Jhon Alejandro Andrade,Sebastián Andrés Cajas Ordoñez*

Main category: quant-ph

TL;DR: 本研究在IBM量子处理器上成功实现了“男女难题”的量子博弈，并提出了一种改进的GCM方法来处理现实世界的噪声问题，实验结果证实了量子博弈的潜在优势。


<details>
  <summary>Details</summary>
Motivation: 在真实的量子硬件上实现量子博弈理论面临噪声、退相干和量子比特连接性有限的挑战，但这类实验对于验证理论预测至关重要。

Method: 本研究介绍了在IBM量子处理器的ibm sherbrooke超导处理器上，使用Eisert-Wilkens-Lewenstein（EWL）框架对“男女难题”进行实验实现的细节。研究评估了四种量子策略（I, H, R(π/4), R(π)）在31个纠缠值γ∈[0, π]下的表现，每次配置使用2048次采样。为缓解噪声和可变性，提出了一种引导电路映射（GCM）方法，该方法根据实时拓扑和校准数据动态选择量子比特对和优化路由。

Result: 实验结果显示，尽管存在硬件引起的偏差，但通过GCM方法实现的实验结果与分析预测的相比，在预期的支付趋势上保持了3.5%至12%的相对误差。分析模型预测支付收益可比经典均衡提高高达108%。

Conclusion: 量子博弈在现实NISQ（含噪声中等规模量子）条件下的量子优势在战略协调方面依然存在，为量子博弈在多主体、经济和分布式决策系统中的实际应用提供了途径。

Abstract: Implementing quantum game theory on real hardware is challenging due to
noise, decoherence, and limited qubit connectivity, yet such demonstrations are
essential to validate theoretical predictions. We present one of the first full
experimental realizations of the Battle of the Sexes game under the
Eisert-Wilkens-Lewenstein (EWL) framework on IBM Quantum's ibm sherbrooke
superconducting processor. Four quantum strategies (I, H, $R(\pi/4)$, $R(\pi)$)
were evaluated across 31 entanglement values $\gamma \in [0, \pi]$ using 2048
shots per configuration, enabling a direct comparison between analytical
predictions and hardware execution. To mitigate noise and variability, we
introduce a Guided Circuit Mapping (GCM) method that dynamically selects qubit
pairs and optimizes routing based on real-time topology and calibration data.
The analytical model forecasts up to $108\%$ payoff improvement over the
classical equilibrium, and despite hardware-induced deviations, experimental
results with GCM preserve the expected payoff trends within $3.5\%$-$12\%$
relative error. These findings show that quantum advantages in strategic
coordination can persist under realistic NISQ conditions, providing a pathway
toward practical applications of quantum game theory in multi-agent, economic,
and distributed decision-making systems.

</details>


### [171] [Robust quantum computational advantage with programmable 3050-photon Gaussian boson sampling](https://arxiv.org/abs/2508.09092)
*Hua-Liang Liu,Hao Su,Si-Qiu Gong,Yi-Chao Gu,Hao-Yang Tang,Meng-Hao Jia,Qian Wei,Yukun Song,Dongzhou Wang,Mingyang Zheng,Faxi Chen,Libo Li,Siyu Ren,Xuezhi Zhu,Meihong Wang,Yaojian Chen,Yanfei Liu,Longsheng Song,Pengyu Yang,Junshi Chen,Hong An,Lei Zhang,Lin Gan,Guangwen Yang,Jia-Min Xu,Yu-Ming He,Hui Wang,Han-Sen Zhong,Ming-Cheng Chen,Xiao Jiang,Li Li,Nai-Le Liu,Yu-Hao Deng,Xiao-Long Su,Qiang Zhang,Chao-Yang Lu,Jian-Wei Pan*

Main category: quant-ph

TL;DR: Jiuzhang 4.0 实验成功，在量子计算优势方面取得了重大进展，克服了光子损耗的挑战，并且在性能上远超经典计算机。


<details>
  <summary>Details</summary>
Motivation: 克服光量子计算（QCA）实验中的最大挑战——光子损耗，并进一步证明量子计算优势。

Method: 通过 1024 个高效率压缩态注入到 8176 模的混合时空编码可编程光量子处理器 Jiuzhang 4.0，并进行了高斯玻色采样实验，产生了高达 3050 个光子探测事件。

Result: 实验结果超越了包括矩阵乘积态（MPS）在内的所有经典模拟算法。使用最强大的超级计算机（EI Capitan）运行顶尖 MPS 算法需要超过 1042 年来构建模拟所需的张量网络，而 Jiuzhang 4.0 仅需 25.6 微秒即可生成一个样本。

Conclusion:  Jiuzhang 4.0 突破了光量子计算的局限，在抗噪声和与经典算法竞争方面取得了显著进展，为容错光量子计算奠定了基础。

Abstract: The creation of large-scale, high-fidelity quantum computers is not only a
fundamental scientific endeavour in itself, but also provides increasingly
robust proofs of quantum computational advantage (QCA) in the presence of
unavoidable noise and the dynamic competition with classical algorithm
improvements. To overcome the biggest challenge of photon-based QCA
experiments, photon loss, we report new Gaussian boson sampling (GBS)
experiments with 1024 high-efficiency squeezed states injected into a hybrid
spatial-temporal encoded, 8176-mode, programmable photonic quantum processor,
Jiuzhang 4.0, which produces up to 3050 photon detection events. Our
experimental results outperform all classical spoofing algorithms, particularly
the matrix product state (MPS) method, which was recently proposed to utilise
photon loss to reduce the classical simulation complexity of the GBS. Using the
state-of-the-art MPS algorithm on the most powerful supercomputer EI Capitan,
it would take > 1042 years to construct the required tensor network for
simulation, while our Jiuzhang 4.0 quantum computer takes 25.6 {\mu}s to
produce a sample. This work establishes a new frontier of QCA and paves the way
to fault-tolerant photonic quantum computing hardware.

</details>


### [172] [Simulating single-photon experiments with a quantum computer](https://arxiv.org/abs/2508.09095)
*Priyasheel Prasad,Marco Russo,Bartolomeo Montrucchio*

Main category: quant-ph

TL;DR: Quantum computer simulations of photon experiments show efficiency insights.


<details>
  <summary>Details</summary>
Motivation: To examine how efficient quantum computers are in simulating actual physical systems as the amount of computation increases.

Method: Simulating photon behavior in a laboratory experiment using a quantum computer, including protective and non-protective measurements, and comparing the results with theoretical predictions.

Result: The simulation provides insights into the efficiency of quantum computers for simulating physical systems.

Conclusion: This paper examines the efficiency of quantum computers in simulating physical systems by comparing simulation results with theoretical predictions for photon behavior in a laboratory experiment involving protective and non-protective measurements.

Abstract: In this work, we simulate the behavior of photons in a laboratory experiment
using a quantum computer and examine how the simulation results compare with
the theoretical predictions. The experiment involves both protective and
non-protective measurements. While the latter involves complete wavefunction
collapse, the former combines weak interactions with a protective mechanism
thereby preserving the photon wave function coherence until its final
detection. The simulation gives insights as to how efficient quantum computers
can be in simulating actual physical systems as the amount of computation
increases.

</details>


### [173] [Constrained free energy minimization for the design of thermal states and stabilizer thermodynamic systems](https://arxiv.org/abs/2508.09103)
*Michele Minervini,Madison Chin,Jacob Kupperman,Nana Liu,Ivy Luo,Meghan Ly,Soorya Rethinasamy,Kathie Wang,Mark M. Wilde*

Main category: quant-ph

TL;DR: 本文在量子海森堡模型和稳定器热力学系统上对现有算法进行了基准测试，并提出了一种新的算法，可用于在固定温度下将量子比特编码到稳定器码中。


<details>
  <summary>Details</summary>
Motivation: 确定在约束条件下系统的最小能量，以及将算法解释为设计可控哈密顿量的基态和热态的方法。

Method: 对Liu等人提出的经典和混合量子-经典算法在量子海森堡模型和稳定器热力学系统上进行了基准测试。

Result: 在量子海森堡模型和稳定器热力学系统上对算法进行了基准测试，并观察到混合算法可以作为一种将量子比特编码到稳定器码的替代方法。

Conclusion: 文中提出的混合量子-经典算法可用于在固定温度下将量子比特编码到稳定器码中，并提供了一种有效的预热启动方法。

Abstract: A quantum thermodynamic system is described by a Hamiltonian and a list of
conserved, non-commuting charges, and a fundamental goal is to determine the
minimum energy of the system subject to constraints on the charges. Recently,
[Liu et al., arXiv:2505.04514] proposed first- and second-order classical and
hybrid quantum-classical algorithms for solving a dual chemical potential
maximization problem, and they proved that these algorithms converge to global
optima by means of gradient-ascent approaches. In this paper, we benchmark
these algorithms on several problems of interest in thermodynamics, including
one- and two-dimensional quantum Heisenberg models with nearest and
next-to-nearest neighbor interactions and with the charges set to the total
$x$, $y$, and $z$ magnetizations. We also offer an alternative compelling
interpretation of these algorithms as methods for designing ground and thermal
states of controllable Hamiltonians, with potential applications in molecular
and material design. Furthermore, we introduce stabilizer thermodynamic systems
as thermodynamic systems based on stabilizer codes, with the Hamiltonian
constructed from a given code's stabilizer operators and the charges
constructed from the code's logical operators. We benchmark the aforementioned
algorithms on several examples of stabilizer thermodynamic systems, including
those constructed from the one-to-three-qubit repetition code, the perfect
one-to-five-qubit code, and the two-to-four-qubit error-detecting code.
Finally, we observe that the aforementioned hybrid quantum-classical
algorithms, when applied to stabilizer thermodynamic systems, can serve as
alternative methods for encoding qubits into stabilizer codes at a fixed
temperature, and we provide an effective method for warm-starting these
encoding algorithms whenever a single qubit is encoded into multiple physical
qubits.

</details>


### [174] [Random Party Distillation on a Superconducting Processor](https://arxiv.org/abs/2508.09110)
*Alexander C. B. Greenwood,Jackson Russett,Hoi-Kwong Lo,Li Qian*

Main category: quant-ph

TL;DR: 本研究在IBM_Quebec超导硬件上成功实现了随机博弈蒸馏协议，速率优于现有技术，并解决了测量错误问题。


<details>
  <summary>Details</summary>
Motivation: 在多方纠缠态的单副本中，通过多次执行正算子值测量操作来随机提取贝尔态对。

Method: 提出并演示了一种基于量子比特的随机博弈蒸馏协议，在IBM_Quebec超导硬件上实现了4轮协议。

Result: 在IBM_Quebec的超导硬件上实现了4轮协议，蒸馏率优于现有技术，并探讨了协议的动力学特性以及如何缓解由中间电路测量引入的错误。

Conclusion: 使用IBM_Quebec上的超导硬件成功实现了基于量子比特的随机博弈蒸馏协议，并且蒸馏率（0.81对/W量子态）优于现有技术。

Abstract: Random party distillation refers to the process by which
Einstein-Podolsky-Rosen pairs are randomly extracted from a single copy of a
multipartite entangled state after multiple rounds of performing positive
operator value measure operations. In this work, we propose a qubit-based
implementation of a random party distillation protocol and demonstrate its
efficacy on the superconducting hardware device, ibm_quebec. We demonstrate a
4-round implementation of the protocol, showing distillation rates superior
(0.81 pairs/ W state) to the state of the art. Finally, we explore the
dynamical properties of the protocol when implemented on superconducting
hardware, and how errors introduced by mid-circuit measurements can be
mitigated.

</details>


### [175] [Coherent control of interacting solid-state spins below the diffraction limit](https://arxiv.org/abs/2508.09122)
*Haitong Xu,Mehmet T. Uysal,Lukasz Dusanowski,Adam Turflinger,Ashwin Boddeti,Joseph Alexander,Jeff D. Thompson*

Main category: quant-ph

TL;DR: 利用稀土离子（Er$^{3+}$）实现了对相互作用的电子自旋和核自旋的相干控制，包括两比特门操作、量子非破坏性测量和量子信息存储，为构建可扩展的量子网络节点奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 固态原子缺陷在量子网络中用作单光子源和存储器，但难以在纳米尺度上可靠地寻址相互作用的单个自旋。稀土离子具有窄的均匀光学线宽，可以在频率域中分辨大量发射体，克服了空间分离的限制。

Method: 通过相干光和自旋控制一对相互作用的Er$^{3+}$离子，以及一个附近的核自旋辅助，实现了两比特电子-电子门和电子-核门操作，并进行了量子非破坏性测量和量子比特信息的相干存储与读取。

Result: 成功实现了两比特电子-电子门和电子-核门操作，进行了量子非破坏性测量，并实现了核自旋相干存储与读取，同时证明了核自旋相干性在电子自旋读出后依然存在。

Conclusion: 这项工作演示了在稀土离子中进行相干光和自旋控制，为构建可扩展的量子网络节点提供了基础。

Abstract: Optically addressed atomic defects in the solid-state are widely used as
single-photon sources and memories for quantum network applications. The
solid-state environment allows for a high density of electron and nuclear spins
with the potential to form registers for coherent information processing.
However, it is challenging to reliably address individual spins at nanometer
separations where interactions are large. Rare-earth ions offer a unique
solution, as their narrow homogeneous optical linewidth allows frequency-domain
resolution of a large number of emitters without regard to their spatial
separation. In this work, we realize coherent optical and spin control of a
pair of interacting Er$^{3+}$ ions, together with a nearby nuclear spin
ancilla. We demonstrate two-qubit electron-electron gates and use them to
perform repeated quantum non-demolition measurements on one of the Er$^{3+}$
ions. We also demonstrate electron-nuclear gates to allow coherent storage and
retrieval of qubit information in a nuclear spin, and show that the nuclear
spin coherence survives readout of the electron spin. These techniques can be
readily scaled to larger numbers of electron and nuclear spins, paving the way
for massively multiplexed quantum network nodes.

</details>


### [176] [Instrument-based quantum resources: quantification, hierarchies and towards constructing resource theories](https://arxiv.org/abs/2508.09134)
*Jatin Ghai,Arindam Mitra*

Main category: quant-ph

TL;DR: 本工作研究了信息可保存性、纠缠可保存性、不相容性可保存性等基于量子仪器的资源理论，并提供了量化它们的度量和层级。


<details>
  <summary>Details</summary>
Motivation: 量子资源理论提供了一个研究量子资源框架。然而，尽管基于状态的量子资源理论已经被广泛研究，基于测量的资源理论也有所探索，但基于量子仪器的资源理论仍然很大程度上未被探索。量子仪器对于多方顺序作用于量子系统特别重要，因为它们同时提供了测量诱导的经典结果和测量后的量子态。

Method: 本工作研究了几个基于量子仪器的资源理论，包括信息可保存性、（强）纠缠可保存性、（强）不相容性可保存性、传统不相容性以及并行不相容性。

Result: 本工作研究了信息可保存性、（强）纠缠可保存性、（强）不相容性可保存性、传统不相容性以及并行不相容性这几种基于量子仪器的资源理论，并概述了它们的层级和量化度量。

Conclusion: 本工作为几种基于量子仪器的资源理论提供了详细的框架，并概述了这些基于量子仪器的资源层级，还提供了量化它们的度量。

Abstract: Quantum resources are certain features of the quantum world that provide
advantages in certain information-theoretic, thermodynamic, or any other useful
operational tasks that are outside the realm of what classical theories can
achieve. Quantum resource theories provide us with an elegant framework for
studying these resources quantitatively and rigorously. While numerous
state-based quantum resource theories have already been investigated, and to
some extent, measurement-based resource theories have also been explored,
instrument-based resource theories remain largely unexplored, with only a few
notable exceptions. As quantum instruments are devices that provide both the
classical outcomes of induced measurements and the post-measurement quantum
states, they are quite important, especially for scenarios where multiple
parties sequentially act on a quantum system. In this work, we study several
instrument-based resource theories, namely (1) the resource theory of
information preservability, (2) the resource theory of (strong) entanglement
preservability, (3) the resource theory of (strong) incompatibility
preservability, (4) the resource theory of traditional incompatibility, and (5)
the resource theory of parallel incompatibility. Furthermore, we outline the
hierarchies of these instrument-based resources and provide measures to
quantify them. In short, we provide a detailed framework for several
instrument-based quantum resource theories.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [177] [Competitive Online Transportation Simplified](https://arxiv.org/abs/2508.08381)
*Stephen Arndt,Benjamin Moseley,Kirk Pruhs,Marc Uetz*

Main category: cs.DS

TL;DR: 一个更简单的O(m)竞争比在线交通问题算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决在线交通问题，并试图找到一个比现有算法更简单的解决方案，以实现$(2m-1)$的竞争比。

Method: 提出了一种新的算法设计和分析方法，用于解决在线交通问题。

Result: 提出了一种新的算法，其竞争比为O(m)，并且比之前的方法更简单。

Conclusion: 该论文提供了一个新的在线交通问题算法，该算法比先前的方法更简单。

Abstract: The setting for the online transportation problem is a metric space $M$,
populated by $m$ parking garages of varying capacities. Over time cars arrive
in $M$, and must be irrevocably assigned to a parking garage upon arrival in a
way that respects the garage capacities. The objective is to minimize the
aggregate distance traveled by the cars. In 1998, Kalyanasundaram and Pruhs
conjectured that there is a $(2m-1)$-competitive deterministic algorithm for
the online transportation problem, matching the optimal competitive ratio for
the simpler online metric matching problem. Recently, Harada and Itoh presented
the first $O(m)$-competitive deterministic algorithm for the online
transportation problem. Our contribution is an alternative algorithm design and
analysis that we believe is simpler.

</details>


### [178] [Two for One, One for All: Deterministic LDC-based Robust Computation in Congested Clique](https://arxiv.org/abs/2508.08740)
*Keren Censor-Hillel,Orr Fischer,Ran Gelles,Pedro Soto*

Main category: cs.DS

TL;DR: 该研究通过设计一种确定性编译器，利用局部可解码码（LDCs）和自适应加倍策略，成功地使“拥塞 আবশ্যক”模型中的计算在面对大量节点崩溃故障时仍能保持稳健，并优化了计算的回合复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了在“拥塞 আবশ্যক”模型中设计出能够抵御节点崩溃故障的计算方法，特别是在存在高达 $\alpha<1$ 比例的节点崩溃时。

Method: 研究利用局部可解码码（LDCs）来应对节点崩溃，通过编码网络中的信息来保持低复杂度开销，仅通过查询小部分码字即可恢复所需信息。该方法的主要技术贡献在于，由于擦除发生在已知位置（崩溃的节点），研究人员通过确定性地选择查询集来规避大量擦除，从而实现了对经典 LDC 构建的去随机化。此外，在并行解码多个码字时，该方法能均衡每个节点的查询负载，避免拥塞并保持低回合复杂度。为应对确定性解码 LDCs 的挑战，即对手可以精确地针对解码特定码字的少数节点，研究采用了自适应加倍策略：如果解码尝试失败，节点会加倍其解码尝试次数；如果解码节点本身崩溃，则由两个未崩溃的节点动态替换。这两种加倍过程的结合，成功应对了确定性 LDC 与最坏情况崩溃模式相结合所带来的挑战。

Result: 设计了一个确定性编译器，能够使“拥塞 আবশ্যক”模型中的计算在面临高达 $\alpha<1$ 的节点崩溃故障时依然稳健。具体来说，该编译器可以在 $d\cdot\lceil\frac{\omega}{n^2}+\frac{\Delta}{n}\rceil\cdot 2^{O(\sqrt{\log{n}}\log\log{n})}$ 回合内完成深度为 $d$、宽度为 $\omega$、门总扇入为 $\Delta$ 的电路计算。作为推论，任何 $T$ 回合的“拥塞 আবশ্যক”算法可以被编译成在该模型下可在 $T^2 n^{o(1)}$ 回合内完成的算法。

Conclusion: 该研究设计了一个确定性编译器，可在“拥塞 আবশ্যক”模型中抵御高达 $\alpha<1$ 的节点崩溃故障。对于由 $d$ 层、宽度 $\omega$ 和总扇入 $\Delta$ 组成的电路，该编译器能在 $d\cdot\lceil\frac{\omega}{n^2}+\frac{\Delta}{n}\rceil\cdot 2^{O(\sqrt{\log{n}}\log\log{n})}$ 回合内完成计算。此外，任何 $T$ 回合的“拥塞 আবশ্যক”算法都可以被编译成在该模型下能在 $T^2 n^{o(1)}$ 回合内完成的算法。

Abstract: We design a deterministic compiler that makes any computation in the
Congested Clique model robust to a constant fraction $\alpha<1$ of adversarial
crash faults. In particular, we show how a network of $n$ nodes can compute any
circuit of depth $d$, width $\omega$, and gate total fan $\Delta$, in
$d\cdot\lceil\frac{\omega}{n^2}+\frac{\Delta}{n}\rceil\cdot
2^{O(\sqrt{\log{n}}\log\log{n})}$ rounds in such a faulty model. As a
corollary, any $T$-round Congested Clique algorithm can be compiled into an
algorithm that completes in $T^2 n^{o(1)}$ rounds in this model.
  Our compiler obtains resilience to node crashes by coding information across
the network, where we leverage locally-decodable codes (LDCs) to maintain a low
complexity overhead, as these allow recovering the information needed at each
computational step by querying only small parts of the codeword.
  The main technical contribution is that because erasures occur in known
locations, which correspond to crashed nodes, we can derandomize classical LDC
constructions by deterministically selecting query sets that avoid sufficiently
many erasures. Moreover, when decoding multiple codewords in parallel, our
derandomization load-balances the queries per-node, thereby preventing
congestion and maintaining a low round complexity.
  Deterministic decoding of LDCs presents a new challenge: the adversary can
target precisely the (few) nodes that are queried for decoding a certain
codeword. We overcome this issue via an adaptive doubling strategy: if a
decoding attempt for a codeword fails, the node doubles the number of its
decoding attempts. Similarly, when the adversary crashes the decoding node
itself, we replace it dynamically with two other non-crashed nodes. By
carefully combining these two doubling processes, we overcome the challenges
posed by the combination of a deterministic LDC with a worst case pattern of
crashes.

</details>


### [179] [Robust Scheduling on Uniform Machines -- New Results Using a Relaxed Approximation Guarantee](https://arxiv.org/abs/2508.08979)
*Hauke Brinkop,David Fischer,Klaus Jansen*

Main category: cs.DS

TL;DR: 在线统一机调度：通过 EPTAS 和 EPAS 解决 Q||Cmax 和 Q||Cmin 问题，同时有界迁移。


<details>
  <summary>Details</summary>
Motivation: 在在线设置中，任务会随着时间的推移被插入或删除，目标是计算一个近似最优解，同时将重新分配任务的总处理时间（迁移）限制为某个因子 β 乘以添加或删除任务的处理时间。

Method: 提出了有效的多项式时间近似方案（EPTAS），具有额外的负载误差 O(ε p_max)，并具有恒定的摊销迁移因子 β。

Result: 对 Q||Cmax 和 Q||Cmin 问题都提出了具有恒定摊销迁移因子 β 的 EPTAS，其中 p_max 是所有步骤中实例的最大处理时间。作为中间步骤，获得了这两种问题的有效参数化近似方案（EPAS）。

Conclusion: 这是第一个关于统一机在线调度具有有界重新分配的区间内的多项式时间近似方案的结果。

Abstract: We consider the problem of scheduling $n$ jobs on $m$ uniform machines while
minimizing the makespan ($Q||C_{\max}$) and maximizing the minimum completion
time ($Q||C_{\min}$) in an online setting with migration of jobs. In this
online setting, the jobs are inserted or deleted over time, and at each step,
the goal is to compute a near-optimal solution while reassigning some jobs,
such that the overall processing time of reassigned jobs, called migration, is
bounded by some factor $\beta$ times the processing time of the job added or
removed.
  We propose Efficient Polynomial Time Approximation Schemes (EPTASs) with an
additional load error of $\mathcal{O}(\varepsilon p_{\max})$ for both problems,
with constant amortized migration factor $\beta$, where $p_{\max}$ is the
maximum processing time in the instance over all steps. As an intermediate
step, we obtain Efficient Parameterized Approximation Schemes (EPASs) for both
problems, $(1+\varepsilon)$-competitive algorithms parameterized by $p_{\max}$
and the number of different processing times $d$ in an instance, with $\beta$
bounded in a function of $p_{\max}$, $d$ and $\varepsilon$.
  This is the first result in the direction of a polynomial time approximation
scheme in the field of online scheduling with bounded reassignment on uniform
machines; before, such results were known only for the considered problems on
identical machines. Crucial to our result is a division of the machines into
large and small machines depending on the current approximate objective value,
allowing for different approaches on either machine set, as well as a new way
of rounding the instance that does not depend on the current objective value.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [180] [Towards Scalable Lottery Ticket Networks using Genetic Algorithms](https://arxiv.org/abs/2508.08877)
*Julian Schönberger,Maximilian Zorn,Jonas Nüßlein,Thomas Gabor,Philipp Altmann*

Main category: cs.LG

TL;DR: 本研究提出了一种利用遗传算法寻找“强抽奖彩票”子网络的方法，该方法无需训练即可达到高精度和高稀疏度，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了构建高效且有效的深度学习系统，需要探索新的模型训练和神经架构设计范式，以替代传统的过参数化网络及其压缩技术。

Method: 通过使用遗传算法来寻找满足特定标准的子网络，避免了传统训练方法中的梯度计算和参数更新。

Result: 所提出的方法在二元分类和多类别分类任务上取得了优于现有技术水平的准确率和稀疏度，且无需梯度信息。此外，研究还强调了在扩展到更复杂的网络架构和学习任务时，需要适当的评估指标。

Conclusion: 利用遗传算法在不进行任何训练的情况下，发现并利用大型稀疏子网络，可以达到与密集网络相媲美甚至更好的准确率和稀疏度。

Abstract: Building modern deep learning systems that are not just effective but also
efficient requires rethinking established paradigms for model training and
neural architecture design. Instead of adapting highly overparameterized
networks and subsequently applying model compression techniques to reduce
resource consumption, a new class of high-performing networks skips the need
for expensive parameter updates, while requiring only a fraction of parameters,
making them highly scalable. The Strong Lottery Ticket Hypothesis posits that
within randomly initialized, sufficiently overparameterized neural networks,
there exist subnetworks that can match the accuracy of the trained original
model-without any training. This work explores the usage of genetic algorithms
for identifying these strong lottery ticket subnetworks. We find that for
instances of binary and multi-class classification tasks, our approach achieves
better accuracies and sparsity levels than the current state-of-the-art without
requiring any gradient information. In addition, we provide justification for
the need for appropriate evaluation metrics when scaling to more complex
network architectures and learning tasks.

</details>


### [181] [Meta-learning optimizes predictions of missing links in real-world networks](https://arxiv.org/abs/2508.09069)
*Bisman Singh,Lucy Van Kleunen,Aaron Clauset*

Main category: cs.LG

TL;DR: 本研究系统地评估了模型堆叠和图神经网络在链接预测任务中的表现，发现没有万能的最佳算法。研究结果表明，模型堆叠（特别是随机森林）在可扩展性和准确性方面表现良好，但算法选择应根据网络特性进行。研究还提出了一种元学习算法，通过选择特定网络的最佳算法来优化链接预测性能，并证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 在网络链接预测任务中，现有研究对于哪种方法（模型堆叠或图神经网络）在没有节点属性的网络中效果最好，以及最佳算法的选择是否以及如何依赖于输入网络的特征，仍不清楚。

Method: 通过大规模、结构多样的550个真实网络基准，在两种标准的准确性度量（AUC和Top-k）下，比较了四种堆叠算法（包括两个新引入的拓扑链接预测器）和两种图神经网络算法。

Result: 没有一种算法能在所有输入网络上表现最佳。大多数算法在社交网络上表现良好，但在经济和生物网络上表现不佳。模型堆叠与随机森林的组合具有良好的可扩展性，在AUC方面表现突出，或在Top-k准确性方面与图神经网络相当。算法性能与网络的度分布、三角形密度和度相关性等特征密切相关。

Conclusion: 模型堆叠（特别是随机森林）在AUC方面表现优异且易于扩展，在Top-k准确性方面能与图神经网络媲美。然而，算法性能很大程度上取决于网络特征（如度分布、三角形密度和度相关性）。本研究引入了一种元学习算法，通过为特定网络选择最佳算法来优化链接预测，该算法超越了所有现有算法，并且能够扩展到大型网络。

Abstract: Relational data are ubiquitous in real-world data applications, e.g., in
social network analysis or biological modeling, but networks are nearly always
incompletely observed. The state-of-the-art for predicting missing links in the
hard case of a network without node attributes uses model stacking or neural
network techniques. It remains unknown which approach is best, and whether or
how the best choice of algorithm depends on the input network's
characteristics. We answer these questions systematically using a large,
structurally diverse benchmark of 550 real-world networks under two standard
accuracy measures (AUC and Top-k), comparing four stacking algorithms with 42
topological link predictors, two of which we introduce here, and two graph
neural network algorithms. We show that no algorithm is best across all input
networks, all algorithms perform well on most social networks, and few perform
well on economic and biological networks. Overall, model stacking with a random
forest is both highly scalable and surpasses on AUC or is competitive with
graph neural networks on Top-k accuracy. But, algorithm performance depends
strongly on network characteristics like the degree distribution, triangle
density, and degree assortativity. We introduce a meta-learning algorithm that
exploits this variability to optimize link predictions for individual networks
by selecting the best algorithm to apply, which we show outperforms all
state-of-the-art algorithms and scales to large networks.

</details>


### [182] [SHEFL: Resource-Aware Aggregation and Sparsification in Heterogeneous Ensemble Federated Learning](https://arxiv.org/abs/2508.08552)
*Keumseo Ryum,Jinu Gong,Joonhyuk Kang*

Main category: cs.LG

TL;DR: SHEFL是一个全局集成式联邦学习框架，通过根据客户端资源分配不同数量的全局模型和采用新颖的聚合方案，有效解决了计算异构性问题，提高了公平性和整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法在处理数据和系统异构性方面存在不足，尤其是在通信效率和模型预测多样性方面。本研究旨在提出一种能够适应具有不同计算能力的客户端的联邦学习框架。

Method: 提出了一种名为SHEFL的全局集成式联邦学习框架，根据客户端的可用资源分配不同数量的全局模型，并引入了一种新的聚合方案来处理不同计算能力客户端之间的偏差。为了降低训练深度集合的计算负担并减轻数据偏差，SHEFL动态调整客户端之间的资源比例，在受限情况下积极降低弱势客户端的影响，在相反情况下增加其权重。

Result: SHEFL在真实通信场景下，有效地解决了计算异构性问题，显著提高了公平性和整体性能。

Conclusion: SHEFL有效解决了计算异构性问题，在公平性和整体性能方面均显著优于现有方法。

Abstract: Federated learning enables distributed training with private data of clients,
but its convergence is hindered by data and system heterogeneity in realistic
communication scenarios. Most existing system heterogeneous FL schemes utilize
global pruning or ensemble distillation, yet they often overlook typical
constraints required for communication efficiency. Meanwhile, deep ensembles
can aggregate predictions from individually trained models to improve
performance, but current ensemble-based FL methods fall short in fully
capturing the diversity of model predictions. In this work, we propose SHEFL, a
global ensemble-based federated learning framework suited for clients with
diverse computational capacities. We allocate different numbers of global
models to clients based on their available resources. We further introduce a
novel aggregation scheme that accounts for bias between clients with different
computational capabilities. To reduce the computational burden of training deep
ensembles and mitigate data bias, we dynamically adjust the resource ratio
across clients - aggressively reducing the influence of underpowered clients in
constrained scenarios, while increasing their weight in the opposite case.
Extensive experiments demonstrate that our method effectively addresses
computational heterogeneity, significantly improving both fairness and overall
performance compared to existing approaches.

</details>


### [183] [FetFIDS: A Feature Embedding Attention based Federated Network Intrusion Detection Algorithm](https://arxiv.org/abs/2508.09056)
*Shreya Ghosh,Abu Shafin Mohammad Mahdee Jameel,Aly El Gamal*

Main category: cs.LG

TL;DR: FetFIDS 利用特征嵌入和联邦学习来改进边缘设备上的入侵检测。


<details>
  <summary>Details</summary>
Motivation: 为了提高入侵检测系统的性能，特别是在边缘学习场景中，同时确保隐私和本地化性能改进。

Method: 提出了一种名为 FetFIDS 的新模型，该模型使用特征嵌入而不是位置嵌入来改进基于 Transformer 的深度学习系统的入侵检测性能，并专门针对边缘学习场景进行开发，利用联邦学习来确保隐私和本地化性能改进。

Result: FetFIDS 在联邦环境中优于多个最先进的入侵检测系统，并证明其高度适用于联邦学习。

Conclusion: FetFIDS 在联邦环境中优于多个最先进的入侵检测系统，并证明其高度适用于联邦学习。

Abstract: Intrusion Detection Systems (IDS) have an increasingly important role in
preventing exploitation of network vulnerabilities by malicious actors. Recent
deep learning based developments have resulted in significant improvements in
the performance of IDS systems. In this paper, we present FetFIDS, where we
explore the employment of feature embedding instead of positional embedding to
improve intrusion detection performance of a transformer based deep learning
system. Our model is developed with the aim of deployments in edge learning
scenarios, where federated learning over multiple communication rounds can
ensure both privacy and localized performance improvements. FetFIDS outperforms
multiple state-of-the-art intrusion detection systems in a federated
environment and demonstrates a high degree of suitability to federated
learning. The code for this work can be found at
https://github.com/ghosh64/fetfids.

</details>


### [184] [Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants](https://arxiv.org/abs/2508.08266)
*Ryan Mioduski*

Main category: cs.LG

TL;DR: LLMs can accurately convert historical land patent descriptions into geographic coordinates, with top models achieving 23km mean error and outperforming traditional GIS methods.


<details>
  <summary>Details</summary>
Motivation: Virginia's seventeenth- and eighteenth-century land patents survive primarily as narrative metes-and-bounds descriptions, limiting spatial analysis.

Method: This study systematically evaluates current-generation large language models (LLMs) in converting prose abstracts of Virginia

Result: The top single-call model, o3-2025-04-16, achieved a mean error of 23 km (median 14 km), outperforming the median LLM (37.4 km) by 37.5%, the weakest LLM (50.3 km) by 53.5%, and external baselines by 67% (GIS analyst) and 70% (Stanford NER). A five-call ensemble further reduced errors to 19 km (median 12 km) at minimal additional cost (approx. USD 0.20 per grant), outperforming the median LLM by 48.6%.

Conclusion: LLMs have significant potential for scalable, accurate, and cost-effective historical georeferencing.

Abstract: Virginia's seventeenth- and eighteenth-century land patents survive primarily
as narrative metes-and-bounds descriptions, limiting spatial analysis. This
study systematically evaluates current-generation large language models (LLMs)
in converting these prose abstracts into geographically accurate
latitude/longitude coordinates within a focused evaluation context. A digitized
corpus of 5,471 Virginia patent abstracts (1695-1732) is released, with 43
rigorously verified test cases serving as an initial, geographically focused
benchmark. Six OpenAI models across three architectures (o-series, GPT-4-class,
and GPT-3.5) were tested under two paradigms: direct-to-coordinate and
tool-augmented chain-of-thought invoking external geocoding APIs. Results were
compared with a GIS-analyst baseline, the Stanford NER geoparser, Mordecai-3,
and a county-centroid heuristic.
  The top single-call model, o3-2025-04-16, achieved a mean error of 23 km
(median 14 km), outperforming the median LLM (37.4 km) by 37.5%, the weakest
LLM (50.3 km) by 53.5%, and external baselines by 67% (GIS analyst) and 70%
(Stanford NER). A five-call ensemble further reduced errors to 19 km (median 12
km) at minimal additional cost (approx. USD 0.20 per grant), outperforming the
median LLM by 48.6%. A patentee-name-redaction ablation increased error by
about 9%, indicating reliance on textual landmark and adjacency descriptions
rather than memorization. The cost-efficient gpt-4o-2024-08-06 model maintained
a 28 km mean error at USD 1.09 per 1,000 grants, establishing a strong
cost-accuracy benchmark; external geocoding tools offered no measurable benefit
in this evaluation.
  These findings demonstrate the potential of LLMs for scalable, accurate, and
cost-effective historical georeferencing.

</details>


### [185] [Doctor Sun: A Bilingual Multimodal Large Language Model for Biomedical AI](https://arxiv.org/abs/2508.08270)
*Dong Xue,Ziyao Shao,Zhaoyang Duan,Fangzhou Liu,Bing Li,Zhongheng Zhang*

Main category: cs.LG

TL;DR: Doctor Sun is a new medical LMM that improves upon existing models by better integrating medical data. A new dataset, SunMed-VL, and resources are also released to aid research.


<details>
  <summary>Details</summary>
Motivation: Existing multimodal biomedical AI based on foundation LLMs struggles with intricate medical concepts due to limited medical training data. Recent LLaVA-induced medical LMMs also have difficulty capturing the relationship between texts and images.

Method: Doctor Sun integrates a pre-trained vision encoder with a medical LLM and conducts two-stage training on various medical datasets, focusing on feature alignment and instruction tuning.

Result: The paper introduces Doctor Sun, a specialized medical LMM, and releases the SunMed-VL dataset and associated models and code.

Conclusion: Doctor Sun, a large multimodal generative model specialized in medicine, encodes, integrates, and interprets diverse biomedical data modalities. The model is trained in two stages on various medical datasets, focusing on feature alignment and instruction tuning. The SunMed-VL dataset and associated resources are released to support biomedical multimodal research.

Abstract: Large multimodal models (LMMs) have demonstrated significant potential in
providing innovative solutions for various biomedical tasks, including
pathology analysis, radiology report generation, and biomedical assistance.
However, the existing multimodal biomedical AI is typically based on foundation
LLMs, thus hindering the understanding of intricate medical concepts with
limited medical training data. Moreover, recent LLaVA-induced medical LMMs
struggle to effectively capture the intricate relationship between the texts
and the images. Therefore, we introduce Doctor Sun, a large multimodal
generative model specialized in medicine, developed to encode, integrate, and
interpret diverse biomedical data modalities such as text and images. In
particular, Doctor Sun integrates a pre-trained vision encoder with a medical
LLM and conducts two-stage training on various medical datasets, focusing on
feature alignment and instruction tuning. Moreover, we release SunMed-VL, a
wide-range bilingual medical multimodal dataset, along with all associated
models, code, and resources, to freely support the advancement of biomedical
multimodal research.

</details>


### [186] [Towards Heterogeneity-Aware and Energy-Efficient Topology Optimization for Decentralized Federated Learning in Edge Environment](https://arxiv.org/abs/2508.08278)
*Yuze Liu,Tiehua Zhang,Zhishu Shen,Libing Wu,Shiping Chen,Jiong Jin*

Main category: cs.LG

TL;DR: Hat-DFed是一个新的去中心化联邦学习框架，用于边缘计算。它通过解决一个复杂的优化问题来智能地构建通信拓扑，以提高性能和能效，并有一个特殊的机制来处理数据差异。


<details>
  <summary>Details</summary>
Motivation: 当前的去中心化联邦学习（DFL）方法在处理由模型复杂性、参与者数量、动态拓扑（稀疏性和连通性）以及边缘环境中的资源和数据异质性引起的成本和性能问题方面存在不足。

Method: 提出了一种名为Hat-DFed的框架，该框架利用对偶优化和两阶段算法来动态构建通信拓扑，同时考虑模型性能和能耗。此外，还引入了一种注重重要性的模型聚合机制来处理数据异质性。

Result: Hat-DFed框架能够最大化模型性能并最小化累积能耗，同时减轻数据异质性导致的问题。

Conclusion: Hat-DFed通过将拓扑构建制定为对偶优化问题并设计一个两阶段算法来解决异构和成本效益问题，从而克服了边缘计算中去中心化联邦学习的挑战。

Abstract: Federated learning (FL) has emerged as a promising paradigm within edge
computing (EC) systems, enabling numerous edge devices to collaboratively train
artificial intelligence (AI) models while maintaining data privacy. To overcome
the communication bottlenecks associated with centralized parameter servers,
decentralized federated learning (DFL), which leverages peer-to-peer (P2P)
communication, has been extensively explored in the research community.
Although researchers design a variety of DFL approach to ensure model
convergence, its iterative learning process inevitably incurs considerable cost
along with the growth of model complexity and the number of participants. These
costs are largely influenced by the dynamic changes of topology in each
training round, particularly its sparsity and connectivity conditions.
Furthermore, the inherent resources heterogeneity in the edge environments
affects energy efficiency of learning process, while data heterogeneity
degrades model performance. These factors pose significant challenges to the
design of an effective DFL framework for EC systems. To this end, we propose
Hat-DFed, a heterogeneity-aware and coset-effective decentralized federated
learning (DFL) framework. In Hat-DFed, the topology construction is formulated
as a dual optimization problem, which is then proven to be NP-hard, with the
goal of maximizing model performance while minimizing cumulative energy
consumption in complex edge environments. To solve this problem, we design a
two-phase algorithm that dynamically constructs optimal communication
topologies while unbiasedly estimating their impact on both model performance
and energy cost. Additionally, the algorithm incorporates an importance-aware
model aggregation mechanism to mitigate performance degradation caused by data
heterogeneity.

</details>


### [187] [XFMNet: Decoding Cross-Site and Nonstationary Water Patterns via Stepwise Multimodal Fusion for Long-Term Water Quality Forecasting](https://arxiv.org/abs/2508.08279)
*Ziqi Wang,Hailiang Zhao,Cheng Bao,Wenzhuo Qian,Yuhao Yang,Xueqiang Sun,Shuiguang Deng*

Main category: cs.LG

TL;DR: XFMNet 是一个分步多模态融合网络，通过整合遥感降水图像来提供河流网络中的空间和环境背景，以应对长期时间序列预测的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决多站点场景中由生态因素引起的复杂周期性、非平稳性和突然波动性带来的水质预测挑战，同时模拟时间与空间动态。

Method: XFMNet首先通过自适应下采样来对齐水质系列和遥感输入之间的时间分辨率，然后通过局部自适应分解来分离趋势和周期分量。跨注意力门控融合模块动态地将时间模式与空间和生态线索相结合，以提高对非平稳性和站点特定异常的鲁棒性。通过渐进式和递归式融合，XFMNet 能够捕获长期趋势和短期波动。

Result: XFMNet 能够捕捉长期趋势和短期波动，并在州级艺术基线上实现了显著的改进。

Conclusion: XFMNet在真实世界数据集上的广泛实验证明了其在空间分布式时间序列预测方面的有效性，并在州级艺术基线上实现了显著的改进。

Abstract: Long-term time-series forecasting is critical for environmental monitoring,
yet water quality prediction remains challenging due to complex periodicity,
nonstationarity, and abrupt fluctuations induced by ecological factors. These
challenges are further amplified in multi-site scenarios that require
simultaneous modeling of temporal and spatial dynamics. To tackle this, we
introduce XFMNet, a stepwise multimodal fusion network that integrates remote
sensing precipitation imagery to provide spatial and environmental context in
river networks. XFMNet first aligns temporal resolutions between water quality
series and remote sensing inputs via adaptive downsampling, followed by locally
adaptive decomposition to disentangle trend and cycle components. A
cross-attention gated fusion module dynamically integrates temporal patterns
with spatial and ecological cues, enhancing robustness to nonstationarity and
site-specific anomalies. Through progressive and recursive fusion, XFMNet
captures both long-term trends and short-term fluctuations. Extensive
experiments on real-world datasets demonstrate substantial improvements over
state-of-the-art baselines, highlighting the effectiveness of XFMNet for
spatially distributed time series prediction.

</details>


### [188] [MoSSDA: A Semi-Supervised Domain Adaptation Framework for Multivariate Time-Series Classification using Momentum Encoder](https://arxiv.org/abs/2508.08280)
*Seonyoung Kim,Dongil Kim*

Main category: cs.LG

TL;DR: MoSSDA是一种新颖的两步动量编码器框架，用于半监督时间序列分类，通过域不变编码和增强对比学习来处理域偏移，并在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在训练和测试数据分布不同（域偏移）时性能会下降。半监督域适应（SSDA）是解决此问题的主要方法，但时间序列数据对噪声敏感，并且域偏移导致性能严重下降。因此，需要一种能够获得鲁棒的、域不变的和类判别的表示的方法。

Method: 提出了一种新颖的两步动量编码器利用的半监督域适应（SSDA）框架MoSSDA，用于多元时间序列分类。该框架使用域不变编码器从源域和目标域学习特征，然后将学习到的特征输入到由在线动量编码器组成的增强对比模块。通过将编码器和分类器之间的梯度流分离来实现两阶段过程，以获得丰富而复杂的表示，并且无需数据增强即可使用有限标记的目标域数据训练最终分类器。

Result: MoSSDA在三种不同的骨干网络和目标域数据的各种未标记比率下，在六个不同的数据集上实现了最先进的性能。

Conclusion: MoSSDA在六个不同的数据集上取得了最先进的性能，在三种不同的骨干网络和目标域数据的各种未标记比率下均表现优异。消融研究证实了包括两阶段学习在内的每个模块都能有效提高性能。

Abstract: Deep learning has emerged as the most promising approach in various fields;
however, when the distributions of training and test data are different (domain
shift), the performance of deep learning models can degrade. Semi-supervised
domain adaptation (SSDA) is a major approach for addressing this issue,
assuming that a fully labeled training set (source domain) is available, but
the test set (target domain) provides labels only for a small subset. In this
study, we propose a novel two-step momentum encoder-utilized SSDA framework,
MoSSDA, for multivariate time-series classification. Time series data are
highly sensitive to noise, and sequential dependencies cause domain shifts
resulting in critical performance degradation. To obtain a robust,
domain-invariant and class-discriminative representation, MoSSDA employs a
domain-invariant encoder to learn features from both source and target domains.
Subsequently, the learned features are fed to a mixup-enhanced positive
contrastive module consisting of an online momentum encoder. The final
classifier is trained with learned features that exhibit consistency and
discriminability with limited labeled target domain data, without data
augmentation. We applied a two-stage process by separating the gradient flow
between the encoders and the classifier to obtain rich and complex
representations. Through extensive experiments on six diverse datasets, MoSSDA
achieved state-of-the-art performance for three different backbones and various
unlabeled ratios in the target domain data. The Ablation study confirms that
each module, including two-stage learning, is effective in improving the
performance. Our code is available at https://github.com/seonyoungKimm/MoSSDA

</details>


### [189] [Multi-grained spatial-temporal feature complementarity for accurate online cellular traffic prediction](https://arxiv.org/abs/2508.08281)
*Ningning Fu,Shengheng Liu,Weiliang Xie,Yongming Huang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为MGSTC的在线蜂窝流量预测方法，通过结合多粒度的时空特征（粗粒度时间注意力和细粒度空间注意力）以及在线学习策略来处理概念漂移，以实现高精度的预测。实验证明，MGSTC的性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电信行业的数据分析和预测对于优化蜂窝流量调度和资源分配至关重要。然而，现有研究忽视了蜂窝流量的内在特性（如零星和爆发性），并且概念漂移对预测精度提出了挑战。因此，需要一种能够处理这些问题的在线预测方法。

Method: MGSTC方法首先将历史数据分块，并利用粗粒度的时间注意力来为预测范围提供趋势参考。随后，利用细粒度的空间注意力来捕捉网络元素之间的详细相关性，从而对已建立的趋势进行本地化优化。此外，为满足持续预测的需求，我们实施了一种在线学习策略，该策略能够实时检测概念漂移并及时切换到适当的参数更新阶段。

Result: MGSTC在四个真实世界数据集上的实验结果表明，与现有的十一种最先进的基线方法相比，MGSTC在预测精度上表现出持续的优越性。

Conclusion: MGSTC方法在四个真实世界的数据集上进行实验，结果表明其性能持续优于十一种最先进的基线方法。

Abstract: Knowledge discovered from telecom data can facilitate proactive understanding
of network dynamics and user behaviors, which in turn empowers service
providers to optimize cellular traffic scheduling and resource allocation.
Nevertheless, the telecom industry still heavily relies on manual expert
intervention. Existing studies have been focused on exhaustively explore the
spatial-temporal correlations. However, they often overlook the underlying
characteristics of cellular traffic, which are shaped by the sporadic and
bursty nature of telecom services. Additionally, concept drift creates
substantial obstacles to maintaining satisfactory accuracy in continuous
cellular forecasting tasks. To resolve these problems, we put forward an online
cellular traffic prediction method grounded in Multi-Grained Spatial-Temporal
feature Complementarity (MGSTC). The proposed method is devised to achieve
high-precision predictions in practical continuous forecasting scenarios.
Concretely, MGSTC segments historical data into chunks and employs the
coarse-grained temporal attention to offer a trend reference for the prediction
horizon. Subsequently, fine-grained spatial attention is utilized to capture
detailed correlations among network elements, which enables localized
refinement of the established trend. The complementarity of these multi-grained
spatial-temporal features facilitates the efficient transmission of valuable
information. To accommodate continuous forecasting needs, we implement an
online learning strategy that can detect concept drift in real-time and
promptly switch to the appropriate parameter update stage. Experiments carried
out on four real-world datasets demonstrate that MGSTC outperforms eleven
state-of-the-art baselines consistently.

</details>


### [190] [Understanding Transformers through the Lens of Pavlovian Conditioning](https://arxiv.org/abs/2508.08289)
*Mu Qiao*

Main category: cs.LG

TL;DR: Transformer 的注意力机制可以被理解为一种类似巴甫洛夫条件反射的计算过程，这种原理可能在生物进化中已被优化。


<details>
  <summary>Details</summary>
Motivation: Transformer 架构在人工智能领域取得了巨大成功，但其底层的计算原理尚不明确。

Method: 提出了一种新的理论框架，将 Transformer 的核心计算（注意力机制）重新解释为巴甫洛夫条件反射。通过将注意力中的查询（queries）、键（keys）和值（values）映射到经典条件反射的三个要素（测试刺激、条件刺激、无条件刺激），并证明注意力操作通过赫布学习规则构建了瞬时的联想记忆。

Result: 该框架提出了三个理论洞见：1. 注意力头在干扰损害检索之前可以存储 O(sqrt(dk)) 个关联的容量定理；2. 解释了模型深度、宽度和头冗余的权衡以维持可靠性的误差传播分析；3. 阐述了生物学上合理的学习规则如何增强 Transformer 架构。

Conclusion: Transformer 架构的成功可能源于其实现的计算原理与生物进化优化过的原理相似，而非仅仅是架构新颖性。

Abstract: Transformer architectures have revolutionized artificial intelligence (AI)
through their attention mechanisms, yet the computational principles underlying
their success remain opaque. We present a novel theoretical framework that
reinterprets the core computation of attention as Pavlovian conditioning. Our
model finds a direct mathematical analogue in linear attention, which
simplifies the analysis of the underlying associative process. We demonstrate
that attention's queries, keys, and values can be mapped to the three elements
of classical conditioning: test stimuli that probe associations, conditional
stimuli (CS) that serve as retrieval cues, and unconditional stimuli (US) that
contain response information. Through this lens, we suggest that each attention
operation constructs a transient associative memory via a Hebbian rule, where
CS-US pairs form dynamic associations that test stimuli can later retrieve. Our
framework yields several theoretical insights grounded in this linearized
model: (1) a capacity theorem showing that attention heads can store
O($\sqrt{d_k}$) associations before interference degrades retrieval; (2) an
error propagation analysis revealing fundamental architectural trade-offs of
balancing model depth, width, and head redundancy to maintain reliability; and
(3) an understanding of how biologically plausible learning rules could enhance
transformer architectures. By establishing this deep connection, we suggest
that the success of modern AI may stem not from architectural novelty alone,
but from implementing computational principles that biology optimized over
millions of years of evolution.

</details>


### [191] [Channel-Wise MLPs Improve the Generalization of Recurrent Convolutional Networks](https://arxiv.org/abs/2508.08298)
*Nathan Breslow*

Main category: cs.LG

TL;DR: DAMP 架构通过 MLP 通道混合，比 DARC 架构具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究通道混合（通过 MLP）对循环卷积网络泛化能力的影响。

Method: 比较了两种循环卷积网络架构：DARC（深度感知循环卷积）和 DAMP（深度感知多层感知机）。DAMP 在 DARC 的基础上增加了门控 MLP 用于通道混合。

Result: 在 Re-ARC 基准测试中，DAMP 在精确匹配评估标准下，在分布内和分布外泛化方面均显著优于 DARC。

Conclusion: 通过多层感知机（MLP）进行通道混合可以增强循环卷积网络的泛化能力，DAMP 架构（包含门控 MLP）明显优于 DARC 架构。

Abstract: We investigate the impact of channel-wise mixing via multi-layer perceptrons
(MLPs) on the generalization capabilities of recurrent convolutional networks.
Specifically, we compare two architectures: DARC (Depth Aware Recurrent
Convolution), which employs a simple recurrent convolutional structure, and
DAMP (Depth Aware Multi-layer Perceptron), which extends DARC with a gated MLP
for channel mixing. Using the Re-ARC benchmark, we find that DAMP significantly
outperforms DARC in both in-distribution and out-of-distribution generalization
under exact-match grading criteria. These results suggest that explicit channel
mixing through MLPs enables recurrent convolutional networks to learn more
robust and generalizable computational patterns. Our findings have implications
for neural program synthesis and highlight the potential of DAMP as a target
architecture for hypernetwork approaches.

</details>


### [192] [HSA-Net: Hierarchical and Structure-Aware Framework for Efficient and Scalable Molecular Language Modeling](https://arxiv.org/abs/2508.08334)
*Zihang Shao,Wentao Lei,Lei Wang,Wencai Ye,Li Liu*

Main category: cs.LG

TL;DR: HSA-Net通过结合跨注意力和图-Mamba的优势，解决了GNN的过平滑问题，并在分子表示学习任务中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络(GNN)投影方法在处理深层特征时性能不佳。Mamba虽然能处理复杂序列并保留全局拓扑信息，但忽略了浅层中的精细细节。为了解决Mamba和交叉注意力之间的全局-局部权衡问题，我们提出了HSA-Net。

Method: 提出了一种名为HSA-Net的新颖框架，包含两个模块：1. 层次自适应投影(HAP)模块，它学习动态切换跨注意力投影（用于浅层）和结构感知图-Mamba投影（用于深层），以处理不同图层特征。2. 源感知融合(SAF)模块，它根据聚合特征的特性灵活选择融合专家，以自适应地合并这些多层次特征。

Result: HSA-Net框架在定量和定性方面均优于当前最先进(SOTA)的方法。

Conclusion: HSA-Net框架在定量和定性方面均优于当前最先进(SOTA)的方法。

Abstract: Molecular representation learning, a cornerstone for downstream tasks like
molecular captioning and molecular property prediction, heavily relies on Graph
Neural Networks (GNN). However, GNN suffers from the over-smoothing problem,
where node-level features collapse in deep GNN layers. While existing feature
projection methods with cross-attention have been introduced to mitigate this
issue, they still perform poorly in deep features. This motivated our
exploration of using Mamba as an alternative projector for its ability to
handle complex sequences. However, we observe that while Mamba excels at
preserving global topological information from deep layers, it neglects
fine-grained details in shallow layers. The capabilities of Mamba and
cross-attention exhibit a global-local trade-off. To resolve this critical
global-local trade-off, we propose Hierarchical and Structure-Aware Network
(HSA-Net), a novel framework with two modules that enables a hierarchical
feature projection and fusion. Firstly, a Hierarchical Adaptive Projector (HAP)
module is introduced to process features from different graph layers. It learns
to dynamically switch between a cross-attention projector for shallow layers
and a structure-aware Graph-Mamba projector for deep layers, producing
high-quality, multi-level features. Secondly, to adaptively merge these
multi-level features, we design a Source-Aware Fusion (SAF) module, which
flexibly selects fusion experts based on the characteristics of the aggregation
features, ensuring a precise and effective final representation fusion.
Extensive experiments demonstrate that our HSA-Net framework quantitatively and
qualitatively outperforms current state-of-the-art (SOTA) methods.

</details>


### [193] [Fuzzy-Pattern Tsetlin Machine](https://arxiv.org/abs/2508.08350)
*Artem Hnilov*

Main category: cs.LG

TL;DR: 本文提出模糊模式Tsetlin机（FPTM），通过模糊子模式匹配策略，显著减少模型复杂度、训练时间和内存占用，同时提高准确性。FPTM在多个数据集上表现优于现有Tsetlin机及其变体，实现了更高效、更鲁棒的模式识别。


<details>
  <summary>Details</summary>
Motivation: 标准的Tsetlin Machine (TM) 及其变体依赖于“all-or-nothing”的子模式评估策略，即一个子模式中的任何一个文字（literal）不匹配，整个子模式就无法投票。这种严格的限制导致TM需要成千上万个子模式才能达到有竞争力的准确率。本文旨在通过引入模糊的子模式评估机制来克服这一局限性，从而减少模型所需的子模式数量、内存占用和训练时间，并提高其准确性和效率。

Method: 本文提出了一种名为模糊模式Tsetlin机（Fuzzy-Pattern Tsetlin Machine, FPTM）的新型Tsetlin机变体。与标准的Tsetlin机（TM）及其变体采用严格的“all-or-nothing”子模式评估策略不同，FPTM 引入了模糊的子模式评估机制。在该机制下，即使子模式中的部分文字（literal）不匹配，其余匹配的文字仍然可以按比例贡献分数，从而允许每个子模式独立适应输入数据。这种方法提高了模式匹配的灵活性、效率和鲁棒性。

Result: FPTM 在多个数据集上展现出优越性能。在 IMDb 数据集上，FPTM 使用单个子模式（每个类别一个）达到了 90.15% 的准确率，子模式数量和内存占用比 Coalesced Tsetlin Machine 减少了 50 倍，训练速度提高了 316 倍（45 秒），模型大小为 50 KB，支持微控制器上的在线学习，推理吞吐量达到 3450 万次/秒。在 Fashion-MNIST 数据集上，FPTM 在子模式数量为 2 时准确率为 92.18%，子模式数量为 20 时为 93.19%，子模式数量为 8000 时为 94.68%，与 Composite TM 的 93.00%（8000 个子模式）相比，子模式数量减少了约 400 倍。在含有 20% 噪声的 Amazon Sales 数据集上，FPTM 准确率为 85.22%，显著优于 Graph Tsetlin Machine (78.17%) 和 Graph Convolutional Neural Network (66.23%)。

Conclusion: Fuzzy-Pattern Tsetlin Machine (FPTM) 通过引入模糊的子模式匹配机制，克服了 Tsetlin Machine (TM) 及其变体在处理“all-or-nothing”子模式匹配时的局限性。FPTM 能够更灵活、更高效、更鲁棒地进行模式匹配，显著减少了所需的子模式数量、内存占用和训练时间，同时提高了准确性。在 IMDb 数据集上，FPTM 仅用每个类别一个子模式就达到了 90.15% 的准确率，子模式数量和内存占用相较于 Coalesced Tsetlin Machine 减少了 50 倍。训练速度提升高达 316 倍（45 秒对 4 小时），模型大小仅为 50 KB，可在微控制器上进行在线学习，推理吞吐量高达 3450 万次/秒。在 Fashion-MNIST 数据集上，FPTM 在子模式数量仅为 2 时准确率达到 92.18%，子模式数量为 20 时准确率达到 93.19%，子模式数量为 8000 时准确率达到 94.68%，相比 Composite TM 在 8000 个子模式下 93.00% 的准确率，子模式数量减少了约 400 倍。在包含 20% 噪声的 Amazon Sales 数据集上，FPTM 的准确率为 85.22%，显著优于 Graph Tsetlin Machine (78.17%) 和 Graph Convolutional Neural Network (66.23%)。

Abstract: The "all-or-nothing" clause evaluation strategy is a core mechanism in the
Tsetlin Machine (TM) family of algorithms. In this approach, each clause - a
logical pattern composed of binary literals mapped to input data - is
disqualified from voting if even a single literal fails. Due to this strict
requirement, standard TMs must employ thousands of clauses to achieve
competitive accuracy. This paper introduces the Fuzzy-Pattern Tsetlin Machine
(FPTM), a novel variant where clause evaluation is fuzzy rather than strict. If
some literals in a clause fail, the remaining ones can still contribute to the
overall vote with a proportionally reduced score. As a result, each clause
effectively consists of sub-patterns that adapt individually to the input,
enabling more flexible, efficient, and robust pattern matching. The proposed
fuzzy mechanism significantly reduces the required number of clauses, memory
footprint, and training time, while simultaneously improving accuracy. On the
IMDb dataset, FPTM achieves 90.15% accuracy with only one clause per class, a
50x reduction in clauses and memory over the Coalesced Tsetlin Machine. FPTM
trains up to 316x faster (45 seconds vs. 4 hours) and fits within 50 KB,
enabling online learning on microcontrollers. Inference throughput reaches 34.5
million predictions/second (51.4 GB/s). On Fashion-MNIST, accuracy reaches
92.18% (2 clauses), 93.19% (20 clauses) and 94.68% (8000 clauses), a ~400x
clause reduction compared to the Composite TM's 93.00% (8000 clauses). On the
Amazon Sales dataset with 20% noise, FPTM achieves 85.22% accuracy,
significantly outperforming the Graph Tsetlin Machine (78.17%) and a Graph
Convolutional Neural Network (66.23%).

</details>


### [194] [Fast weight programming and linear transformers: from machine learning to neurobiology](https://arxiv.org/abs/2508.08435)
*Kazuki Irie,Samuel J. Gershman*

Main category: cs.LG

TL;DR: FWPs are RNNs with 2D matrix hidden states that act as dynamic short-term memory, programmed by another network. This primer reviews their foundations, computational aspects, and connections to transformers, state space models, and brain plasticity, suggesting a convergence of natural and artificial intelligence.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive overview of FWPs, which use 2D matrix-form hidden states unlike conventional RNNs, and their relationship to other neural network architectures and biological systems.

Method: Review of technical foundations, computational characteristics, and connections of FWPs to transformers and state space models.

Result: Detailed review of FWPs, highlighting their interpretation as networks with dynamically changing synaptic weights, and their links to transformers, state space models, and models of synaptic plasticity.

Conclusion: FWPs suggest a convergence of natural and artificial intelligence, with connections to synaptic plasticity in the brain.

Abstract: Recent advances in artificial neural networks for machine learning, and
language modeling in particular, have established a family of recurrent neural
network (RNN) architectures that, unlike conventional RNNs with vector-form
hidden states, use two-dimensional (2D) matrix-form hidden states. Such
2D-state RNNs, known as Fast Weight Programmers (FWPs), can be interpreted as a
neural network whose synaptic weights (called fast weights) dynamically change
over time as a function of input observations, and serve as short-term memory
storage; corresponding synaptic weight modifications are controlled or
programmed by another network (the programmer) whose parameters are trained
(e.g., by gradient descent). In this Primer, we review the technical
foundations of FWPs, their computational characteristics, and their connections
to transformers and state space models. We also discuss connections between
FWPs and models of synaptic plasticity in the brain, suggesting a convergence
of natural and artificial intelligence.

</details>


### [195] [MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time](https://arxiv.org/abs/2508.08641)
*Peter Phan,Dhruv Agarwal,Kavitha Srinivas,Horst Samulowitz,Pavan Kapanipathi,Andrew McCallum*

Main category: cs.LG

TL;DR: MiGrATe 是一种在线 TTT 方法，通过 GRPO 搜索和混合策略（包括 On-policy 采样、贪婪采样、邻近采样）在推理时调整 LLM，无需外部数据，解决了现有方法在探索与利用平衡以及数据定制化的问题，并在多项任务中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 在黑盒优化任务中，如程序综合和分子设计，虽然能通过上下文学习迭代指导模型，但难以平衡探索新解空间和利用高回报区域。而现有的 TTT 方法需要为每个任务定制手动创建的训练数据，限制了其在不同领域的应用和扩展性。因此，需要一种无需外部训练数据即可进行在线 TTT 的方法。

Method: MiGrATe 使用 GRPO 作为搜索算法，通过混合策略组建过程（包括 On-policy 采样、贪婪采样和邻近采样）在推理时进行在线测试时间训练 (TTT)。

Result: 在词搜索、分子优化和 ARC 数据集的假设+程序归纳三个具有挑战性的领域，MiGrATe 均持续优于仅推理和 TTT 的基线方法，证明了在线 TTT 在复杂搜索任务中无需外部监督的潜力。

Conclusion: MiGrATe通过混合策略组建过程，结合了 On-policy 采样与两种 Off-policy 数据选择技术（贪婪采样和邻近采样），在推理时无需外部训练数据即可调整 LLM。该方法通过优先利用有前景的解空间，并保持 On-policy 采样的探索性，在一系列具有挑战性的任务中持续优于仅推理和 TTT 方法。

Abstract: Large language models (LLMs) are increasingly being applied to black-box
optimization tasks, from program synthesis to molecule design. Prior work
typically leverages in-context learning to iteratively guide the model towards
better solutions. Such methods, however, often struggle to balance exploration
of new solution spaces with exploitation of high-reward ones. Recently,
test-time training (TTT) with synthetic data has shown promise in improving
solution quality. However, the need for hand-crafted training data tailored to
each task limits feasibility and scalability across domains. To address this
problem, we introduce MiGrATe-a method for online TTT that uses GRPO as a
search algorithm to adapt LLMs at inference without requiring external training
data. MiGrATe operates via a mixed-policy group construction procedure that
combines on-policy sampling with two off-policy data selection techniques:
greedy sampling, which selects top-performing past completions, and
neighborhood sampling (NS), which generates completions structurally similar to
high-reward ones. Together, these components bias the policy gradient towards
exploitation of promising regions in solution space, while preserving
exploration through on-policy sampling. We evaluate MiGrATe on three
challenging domains-word search, molecule optimization, and hypothesis+program
induction on the Abstraction and Reasoning Corpus (ARC)-and find that it
consistently outperforms both inference-only and TTT baselines, demonstrating
the potential of online TTT as a solution for complex search tasks without
external supervision.

</details>


### [196] [$\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models](https://arxiv.org/abs/2508.08657)
*Jiaxin Ju,Yizhen Zheng,Huan Yee Koh,Can Wang,Shirui Pan*

Main category: cs.LG

TL;DR: $	ext{M}^{2}$LLM is a novel framework that utilizes LLMs to create advanced molecular representations by integrating structure, task, and rule perspectives, outperforming existing methods in property prediction.


<details>
  <summary>Details</summary>
Motivation: Leverage the reasoning abilities and prior knowledge of large language models (LLMs) to generate rich molecular representations by guiding them to reason in multiple perspectives, addressing the gap where existing methods overlook accumulated semantic and contextual knowledge.

Method: A multi-view framework, $	ext{M}^{2}$LLM, integrates three perspectives: molecular structure, molecular task, and molecular rules, which are dynamically fused to adapt to task requirements.

Result: Experiments demonstrate that $	ext{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks. LLM-derived representation shows exceptional performance by generating molecular embeddings and curating molecular features through reasoning.

Conclusion: $	ext{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks across classification and regression tasks, and the representation derived from LLM achieves exceptional performance by leveraging its encoding and reasoning capabilities.

Abstract: Accurate molecular property prediction is a critical challenge with
wide-ranging applications in chemistry, materials science, and drug discovery.
Molecular representation methods, including fingerprints and graph neural
networks (GNNs), achieve state-of-the-art results by effectively deriving
features from molecular structures. However, these methods often overlook
decades of accumulated semantic and contextual knowledge. Recent advancements
in large language models (LLMs) demonstrate remarkable reasoning abilities and
prior knowledge across scientific domains, leading us to hypothesize that LLMs
can generate rich molecular representations when guided to reason in multiple
perspectives. To address these gaps, we propose $\text{M}^{2}$LLM, a multi-view
framework that integrates three perspectives: the molecular structure view, the
molecular task view, and the molecular rules view. These views are fused
dynamically to adapt to task requirements, and experiments demonstrate that
$\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks
across classification and regression tasks. Moreover, we demonstrate that
representation derived from LLM achieves exceptional performance by leveraging
two core functionalities: the generation of molecular embeddings through their
encoding capabilities and the curation of molecular features through advanced
reasoning processes.

</details>


### [197] [M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction](https://arxiv.org/abs/2508.08543)
*Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang*

Main category: cs.LG

TL;DR: M3-Net是一种基于MLP的交通预测模型，通过引入时间序列/时空嵌入和MLP-Mixer（带MoE）来解决现有方法的局限性，并在实验中展现了优越的性能和轻量级部署能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图神经网络或注意力机制的深度学习方法在处理交通预测任务时，要么依赖于完整的交通网络结构，要么需要复杂的设计来捕捉时空依赖性，这给模型在大型数据集上的部署和操作带来了挑战。

Method: 提出了一种基于成本效益的无图多层感知器（MLP）模型M3-Net，并采用了时间序列和时空嵌入进行特征处理，以及一种新颖的包含专家混合（MoE）机制的MLP-Mixer架构。

Result: M3-Net在预测性能和轻量级部署方面表现优于现有方法。

Conclusion: 该模型在多个真实数据集上的大量实验证明了其在预测性能和轻量级部署方面的优越性。

Abstract: Achieving accurate traffic prediction is a fundamental but crucial task in
the development of current intelligent transportation systems.Most of the
mainstream methods that have made breakthroughs in traffic prediction rely on
spatio-temporal graph neural networks, spatio-temporal attention mechanisms,
etc. The main challenges of the existing deep learning approaches are that they
either depend on a complete traffic network structure or require intricate
model designs to capture complex spatio-temporal dependencies. These
limitations pose significant challenges for the efficient deployment and
operation of deep learning models on large-scale datasets. To address these
challenges, we propose a cost-effective graph-free Multilayer Perceptron (MLP)
based model M3-Net for traffic prediction. Our proposed model not only employs
time series and spatio-temporal embeddings for efficient feature processing but
also first introduces a novel MLP-Mixer architecture with a mixture of experts
(MoE) mechanism. Extensive experiments conducted on multiple real datasets
demonstrate the superiority of the proposed model in terms of prediction
performance and lightweight deployment.

</details>


### [198] [UQGNN: Uncertainty Quantification of Graph Neural Networks for Multivariate Spatiotemporal Prediction](https://arxiv.org/abs/2508.08551)
*Dahai Yu,Dingyi Zhuang,Lin Jiang,Rongchao Xu,Xinyue Ye,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

TL;DR: UQGNN是一种用于多元时空预测的新型图神经网络，通过交互感知时空嵌入和多元概率预测模块，能够同时准确预测期望值和量化不确定性，并在多个真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数时空预测模型是确定性的，仅预测期望均值而不量化不确定性，这可能导致不可靠和不准确的结果。尽管近期研究引入了概率模型来量化不确定性，但它们通常只关注单一现象，忽略了异构城市现象之间固有的相关性。本研究旨在解决这一研究空白。

Method: 提出了一种新颖的图神经网络与不确定性量化（UQGNN），用于多元时空预测。UQGNN包含两个关键创新：(i) 交互感知时空嵌入模块，集成了多元扩散图卷积网络和交互感知时间卷积网络，以有效捕捉复杂空间和时间交互模式；(ii) 一个多元概率预测模块，用于估计期望均值和相关不确定性。

Result: 在深圳、纽约和芝加哥的四个真实世界多元时空数据集上的大量实验表明，UQGNN在预测准确性和不确定性量化方面始终优于最先进的基线。

Conclusion: UQGNN在深圳数据集上实现了5%的预测准确性和不确定性量化提升，在预测准确性和不确定性量化方面均优于最先进的基线。

Abstract: Spatiotemporal prediction plays a critical role in numerous real-world
applications such as urban planning, transportation optimization, disaster
response, and pandemic control. In recent years, researchers have made
significant progress by developing advanced deep learning models for
spatiotemporal prediction. However, most existing models are deterministic,
i.e., predicting only the expected mean values without quantifying uncertainty,
leading to potentially unreliable and inaccurate outcomes. While recent studies
have introduced probabilistic models to quantify uncertainty, they typically
focus on a single phenomenon (e.g., taxi, bike, crime, or traffic crashes),
thereby neglecting the inherent correlations among heterogeneous urban
phenomena. To address the research gap, we propose a novel Graph Neural Network
with Uncertainty Quantification, termed UQGNN for multivariate spatiotemporal
prediction. UQGNN introduces two key innovations: (i) an Interaction-aware
Spatiotemporal Embedding Module that integrates a multivariate diffusion graph
convolutional network and an interaction-aware temporal convolutional network
to effectively capture complex spatial and temporal interaction patterns, and
(ii) a multivariate probabilistic prediction module designed to estimate both
expected mean values and associated uncertainties. Extensive experiments on
four real-world multivariate spatiotemporal datasets from Shenzhen, New York
City, and Chicago demonstrate that UQGNN consistently outperforms
state-of-the-art baselines in both prediction accuracy and uncertainty
quantification. For example, on the Shenzhen dataset, UQGNN achieves a 5%
improvement in both prediction accuracy and uncertainty quantification.

</details>


### [199] [Enhanced Liver Tumor Detection in CT Images Using 3D U-Net and Bat Algorithm for Hyperparameter Optimization](https://arxiv.org/abs/2508.08452)
*Nastaran Ghorbani,Bitasadat Jamshidi,Mohsen Rostamy-Malkhalifeh*

Main category: cs.LG

TL;DR: "本研究提出了一种结合3D U-Net和蝙蝠算法来优化超参数以提高肝脏CT图像分割精度的自动分割方法，并在公开数据集上取得了良好的效果。"


<details>
  <summary>Details</summary>
Motivation: "肝脏癌是最常见的癌症之一，早期检测对其治疗至关重要。"

Method: "本研究提出了一种在CT图像中自动分割肝脏肿瘤的新方法，该方法将3D U-Net架构与蝙蝠算法相结合，用于超参数优化。"

Result: "在公开数据集上的评估表明，该模型在较低的预测阈值下表现出高F1分数，能够很好地平衡精确率和召回率。"

Conclusion: "该研究表明，结合强大的深度学习架构和元启发式优化算法可以为复杂的分割任务提供高效的解决方案."

Abstract: Liver cancer is one of the most prevalent and lethal forms of cancer, making
early detection crucial for effective treatment. This paper introduces a novel
approach for automated liver tumor segmentation in computed tomography (CT)
images by integrating a 3D U-Net architecture with the Bat Algorithm for
hyperparameter optimization. The method enhances segmentation accuracy and
robustness by intelligently optimizing key parameters like the learning rate
and batch size. Evaluated on a publicly available dataset, our model
demonstrates a strong ability to balance precision and recall, with a high
F1-score at lower prediction thresholds. This is particularly valuable for
clinical diagnostics, where ensuring no potential tumors are missed is
paramount. Our work contributes to the field of medical image analysis by
demonstrating that the synergy between a robust deep learning architecture and
a metaheuristic optimization algorithm can yield a highly effective solution
for complex segmentation tasks.

</details>


### [200] [Multi-level Collaborative Distillation Meets Global Workspace Model: A Unified Framework for OCIL](https://arxiv.org/abs/2508.08677)
*Shibin Su,Guoqiang Liang,De Cheng,Shizhou Zhang,Lingyan Ran,Yanning Zhang*

Main category: cs.LG

TL;DR: 通过全局工作模型（GWM）和多层次协作蒸馏，在OCIL中实现稳定性和适应性的平衡。


<details>
  <summary>Details</summary>
Motivation: 在线类别增量学习（OCIL）面临在严格的内存限制下保持模型稳定性和确保适应新任务的挑战。现有基于重放的方法在更严格的内存限制下效果不佳，而集成方法虽然提高了适应性，但通常在稳定性方面存在问题。

Method: 提出了一种新颖的方法，通过全局工作模型（GWM）增强集成学习。GWM 通过在每个训练批次中融合所有学生模型的参数来形成，捕捉历史学习轨迹并作为知识巩固的动态锚点。然后，该融合模型会定期重新分发给学生模型，以稳定学习并促进跨任务一致性。此外，还引入了多层次协作蒸馏机制，强制学生模型之间的对等一致性，并通过将每个学生模型与GWM对齐来保留历史知识。

Result: 该方法在三个标准的OCIL基准测试上进行了广泛的实验，结果表明，在各种内存预算下，该方法显著提高了多种OCIL模型的性能。

Conclusion: 该方法通过全局工作模型（GWM）增强了集成学习，GWM 通过融合学生模型参数形成，作为动态锚点以巩固知识，并通过多层次协作蒸馏机制强制学生模型之间的对等一致性，并使每个学生模型与GWM对齐，以在保持稳定性的同时提高适应新任务的能力。

Abstract: Online Class-Incremental Learning (OCIL) enables models to learn continuously
from non-i.i.d. data streams and samples of the data streams can be seen only
once, making it more suitable for real-world scenarios compared to offline
learning. However, OCIL faces two key challenges: maintaining model stability
under strict memory constraints and ensuring adaptability to new tasks. Under
stricter memory constraints, current replay-based methods are less effective.
While ensemble methods improve adaptability (plasticity), they often struggle
with stability. To overcome these challenges, we propose a novel approach that
enhances ensemble learning through a Global Workspace Model (GWM)-a shared,
implicit memory that guides the learning of multiple student models. The GWM is
formed by fusing the parameters of all students within each training batch,
capturing the historical learning trajectory and serving as a dynamic anchor
for knowledge consolidation. This fused model is then redistributed
periodically to the students to stabilize learning and promote cross-task
consistency. In addition, we introduce a multi-level collaborative distillation
mechanism. This approach enforces peer-to-peer consistency among students and
preserves historical knowledge by aligning each student with the GWM. As a
result, student models remain adaptable to new tasks while maintaining
previously learned knowledge, striking a better balance between stability and
plasticity. Extensive experiments on three standard OCIL benchmarks show that
our method delivers significant performance improvement for several OCIL models
across various memory budgets.

</details>


### [201] [Generative Modeling for Robust Deep Reinforcement Learning on the Traveling Salesman Problem](https://arxiv.org/abs/2508.08718)
*Michael Li,Eric Bae,Christopher Haberland,Natasha Jaques*

Main category: cs.LG

TL;DR: COGS通过生成采样来提高神经TSP求解器的鲁棒性，并在真实世界分布的数据集上表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有的神经TSP求解器在处理现实世界中遇到的、与训练数据分布不同的问题时，泛化能力不足，导致在某些情况下表现不佳。

Method: 提出了一种名为COGS（Combinatorial Optimization with Generative Sampling）的方法，使用生成模型采样训练数据，以提高神经求解器在不同TSP分布上的鲁棒性。同时，创建了一个名为TSPLib50的新数据集，用于测试真实世界分布下的泛化能力。

Result: COGS在各种合成数据集和TSPLib50上均优于最先进的神经基线方法，特别是在提高分布鲁棒性方面，大部分性能提升来自于最坏情况下的改进。

Conclusion: COGS通过使用生成模型进行采样来解决TSP的分布鲁棒性问题，并在TSPLib50等数据集上展示了比现有基线方法更好的性能，尤其是在最坏情况下的表现。

Abstract: The Traveling Salesman Problem (TSP) is a classic NP-hard combinatorial
optimization task with numerous practical applications. Classic heuristic
solvers can attain near-optimal performance for small problem instances, but
become computationally intractable for larger problems. Real-world logistics
problems such as dynamically re-routing last-mile deliveries demand a solver
with fast inference time, which has led researchers to investigate specialized
neural network solvers. However, neural networks struggle to generalize beyond
the synthetic data they were trained on. In particular, we show that there
exist TSP distributions that are realistic in practice, which also consistently
lead to poor worst-case performance for existing neural approaches. To address
this issue of distribution robustness, we present Combinatorial Optimization
with Generative Sampling (COGS), where training data is sampled from a
generative TSP model. We show that COGS provides better data coverage and
interpolation in the space of TSP training distributions. We also present
TSPLib50, a dataset of realistically distributed TSP samples, which tests
real-world generalization ability without conflating this issue with instance
size. We evaluate our method on various synthetic datasets as well as TSPLib50,
and compare to state-of-the-art neural baselines. We demonstrate that COGS
improves distribution robustness, with most performance gains coming from
worst-case scenarios.

</details>


### [202] [TechOps: Technical Documentation Templates for the AI Act](https://arxiv.org/abs/2508.08804)
*Laura Lucaj,Alex Loosley,Hakan Jonsson,Urs Gasser,Patrick van der Smagt*

Main category: cs.LG

TL;DR: 本研究提出了TechOps，一套开源的AI系统文档模板和示例，旨在满足欧盟《人工智能法案》的要求，确保AI系统的透明度、可追溯性和合规性。该工具已在多个真实场景中得到验证，能够有效支持监管合规和负责任的AI开发。


<details>
  <summary>Details</summary>
Motivation: 为确保人工智能系统透明、可追溯和负责任，欧盟《人工智能法案》的实施需要清晰的技术文档。现有的AI系统文档模板未能完全涵盖AI生命周期，也未能满足《人工智能法案》的技术文档要求。

Method: 本研究通过引入开源模板和示例来记录数据、模型和应用程序，以满足“人工智能法案”的技术文档要求。这些模板可跟踪整个AI生命周期中的系统状态，确保可追溯性、可重复性和合规性。研究还评估和改进了模板的可用性和可实施性，并在真实场景中验证了该方法，包括皮肤色调数据集、人体剪影分割神经网络以及用于建筑工地安全系统的应用程序。

Result: TechOps模板和示例已成功应用于皮肤色调数据集、人体剪影分割神经网络以及建筑工地安全系统等真实场景，证明了其作为监管合规和负责任AI开发实用工具的有效性。

Conclusion: 该研究提出了一个名为TechOps的实用工具，可作为监管合规和负责任人工智能开发的监督工具。

Abstract: Operationalizing the EU AI Act requires clear technical documentation to
ensure AI systems are transparent, traceable, and accountable. Existing
documentation templates for AI systems do not fully cover the entire AI
lifecycle while meeting the technical documentation requirements of the AI Act.
  This paper addresses those shortcomings by introducing open-source templates
and examples for documenting data, models, and applications to provide
sufficient documentation for certifying compliance with the AI Act. These
templates track the system status over the entire AI lifecycle, ensuring
traceability, reproducibility, and compliance with the AI Act. They also
promote discoverability and collaboration, reduce risks, and align with best
practices in AI documentation and governance.
  The templates are evaluated and refined based on user feedback to enable
insights into their usability and implementability. We then validate the
approach on real-world scenarios, providing examples that further guide their
implementation: the data template is followed to document a skin tones dataset
created to support fairness evaluations of downstream computer vision models
and human-centric applications; the model template is followed to document a
neural network for segmenting human silhouettes in photos. The application
template is tested on a system deployed for construction site safety using
real-time video analytics and sensor data. Our results show that TechOps can
serve as a practical tool to enable oversight for regulatory compliance and
responsible AI development.

</details>


### [203] [TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks](https://arxiv.org/abs/2508.08814)
*Sathiyanaryanan Sampath,Pratyush Uppuluri,Thirumaran Ekambaram*

Main category: cs.LG

TL;DR: 提出了一种名为 TempOpt 的无监督告警关联学习技术，用于识别电信网络中的根告警。该技术在真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了有效识别根告警，有必要学习告警之间的关系，以实现准确和快速的解析。现有的方法（时间依赖方法）存在局限性。

Method: 提出了一种名为 TempOpt 的新颖的无监督告警关联学习技术，该技术旨在克服现有的基于时间依赖的方法的局限性。

Result: 实验证明，TempOpt 学习到的告警关系质量优于时间依赖方法。

Conclusion: TempOpt 是一种实用的无监督告警关联学习技术，在真实网络数据集上的实验表明，其学习到的告警关系质量优于现有的时间依赖方法。

Abstract: In a telecommunications network, fault alarms generated by network nodes are
monitored in a Network Operations Centre (NOC) to ensure network availability
and continuous network operations. The monitoring process comprises of tasks
such as active alarms analysis, root alarm identification, and resolution of
the underlying problem. Each network node potentially can generate alarms of
different types, while nodes can be from multiple vendors, a network can have
hundreds of nodes thus resulting in an enormous volume of alarms at any time.
Since network nodes are inter-connected, a single fault in the network would
trigger multiple sequences of alarms across a variety of nodes and from a
monitoring point of view, it is a challenging task for a NOC engineer to be
aware of relations between the various alarms, when trying to identify, for
example, a root alarm on which an action needs to be taken. To effectively
identify root alarms, it is essential to learn relation among the alarms for
accurate and faster resolution. In this work we propose a novel unsupervised
alarm relation learning technique Temporal Optimization (TempOpt) that is
practical and overcomes the limitations of an existing class of alarm
relational learning method-temporal dependency methods. Experiments have been
carried on real-world network datasets, that demonstrate the improved quality
of alarm relations learned by TempOpt as compared to temporal dependency
method.

</details>


### [204] [Wavelet Mixture of Experts for Time Series Forecasting](https://arxiv.org/abs/2508.08825)
*Zheng Zhou,Yu-Jie Xiong,Jia-Chen Zhang,Chun-Ming Xia,Xi-Jiong Xie*

Main category: cs.LG

TL;DR: WaveTS系列模型（包括WaveTS-B和WaveTS-M）通过结合小波变换、MLP和MoE框架，在时间序列预测任务中取得了SOTA性能，同时减少了参数量，特别是在处理多通道数据方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的Transformer模型因参数量大和捕捉数据平稳性的能力有限而受到限制。MLP模型在有效处理多通道依赖性方面存在困难。为了解决这些局限性，需要新的模型。

Method: 提出了一种结合小波变换和MLP的新型轻量级时间序列预测模型WaveTS-B，用于捕捉数据在小波域中的周期性和非平稳特征。在此基础上，提出了一种结合MoE框架的通道聚类策略，利用门控机制和专家网络高效处理多通道依赖性，形成了WaveTS-M模型。

Result: WaveTS系列模型在八个真实世界时间序列数据集上实现了最先进（SOTA）的性能，并且参数量显著减少。WaveTS-M在多通道数据集上显示出显著的改进。

Conclusion: WaveTS系列模型在八个真实世界时间序列数据集上的实证评估表明，它们以显著减少的参数实现了最先进（SOTA）的性能，其中WaveTS-M在多通道数据集上表现出显著的改进，凸显了其有效性。

Abstract: The field of time series forecasting is rapidly advancing, with recent
large-scale Transformers and lightweight Multilayer Perceptron (MLP) models
showing strong predictive performance. However, conventional Transformer models
are often hindered by their large number of parameters and their limited
ability to capture non-stationary features in data through smoothing.
Similarly, MLP models struggle to manage multi-channel dependencies
effectively. To address these limitations, we propose a novel, lightweight time
series prediction model, WaveTS-B. This model combines wavelet transforms with
MLP to capture both periodic and non-stationary characteristics of data in the
wavelet domain. Building on this foundation, we propose a channel clustering
strategy that incorporates a Mixture of Experts (MoE) framework, utilizing a
gating mechanism and expert network to handle multi-channel dependencies
efficiently. We propose WaveTS-M, an advanced model tailored for multi-channel
time series prediction. Empirical evaluation across eight real-world time
series datasets demonstrates that our WaveTS series models achieve
state-of-the-art (SOTA) performance with significantly fewer parameters.
Notably, WaveTS-M shows substantial improvements on multi-channel datasets,
highlighting its effectiveness.

</details>


### [205] [Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models](https://arxiv.org/abs/2508.08875)
*Fuyao Zhang,Xinyu Yan,Tiantong Wu,Wenjie Li,Tianxiang Chen,Yang Cao,Ran Yan,Longtao Huang,Wei Yang Bryan Lim,Qiang Yang*

Main category: cs.LG

TL;DR: Oblivionis通过整合联邦学习和反学习，解决了在联合LLM训练中移除私人数据以满足隐私和合规性需求的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联合LLM框架缺乏像GDPR的被遗忘权这样的法规遵从机制，并且在选择性地移除特定客户端的贡献方面存在不足。

Method: 将FL和反学习统一为双重优化目标，并纳入6种FL算法和5种反学习算法进行评估。

Result: 实验证明，Oblivionis在遗忘效果和模型效用之间取得了稳衡，优于本地训练，并为未来的LLM发展提供了明确的方向。

Conclusion: Oblivionis是一个轻量级的学习和反学习框架，它使客户能够在联合LLM训练期间选择性地删除特定的私有数据，从而增强了可信度和法规遵从性。通过将FL和反学习统一为双重优化目标，我们纳入了6种FL算法和5种反学习算法进行全面的评估和比较分析，为联合LLM反学习建立了强大的流程。

Abstract: Large Language Models (LLMs) increasingly leverage Federated Learning (FL) to
utilize private, task-specific datasets for fine-tuning while preserving data
privacy. However, while federated LLM frameworks effectively enable
collaborative training without raw data sharing, they critically lack built-in
mechanisms for regulatory compliance like GDPR's right to be forgotten.
Integrating private data heightens concerns over data quality and long-term
governance, yet existing distributed training frameworks offer no principled
way to selectively remove specific client contributions post-training. Due to
distributed data silos, stringent privacy constraints, and the intricacies of
interdependent model aggregation, federated LLM unlearning is significantly
more complex than centralized LLM unlearning. To address this gap, we introduce
Oblivionis, a lightweight learning and unlearning framework that enables
clients to selectively remove specific private data during federated LLM
training, enhancing trustworthiness and regulatory compliance. By unifying FL
and unlearning as a dual optimization objective, we incorporate 6 FL and 5
unlearning algorithms for comprehensive evaluation and comparative analysis,
establishing a robust pipeline for federated LLM unlearning. Extensive
experiments demonstrate that Oblivionis outperforms local training, achieving a
robust balance between forgetting efficacy and model utility, with
cross-algorithm comparisons providing clear directions for future LLM
development.

</details>


### [206] [Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption](https://arxiv.org/abs/2508.08883)
*Audrey Poinsot,Panayiotis Panayiotou,Alessandro Leite,Nicolas Chesneau,Özgür Şimşek,Marc Schoenauer*

Main category: cs.LG

TL;DR: Synthetic experiments are crucial for reliable causal ML evaluation; this paper provides guidelines for their effective use.


<details>
  <summary>Details</summary>
Motivation: Current empirical evaluations of causal machine learning methods do not permit assessment of their reliability and robustness, hindering their adoption by the broader machine learning community due to the extensive use of synthetic experiments.

Method: Critically review current evaluation practices and propose a set of principles for conducting rigorous empirical analyses with synthetic data.

Result: Proposing principles for rigorous empirical analyses with synthetic data will enable comprehensive evaluations that build trust in causal machine learning methods, driving their broader adoption and impactful real-world use.

Conclusion: The paper argues that synthetic experiments are essential for evaluating causal machine learning methods and proposes principles for rigorous empirical analyses with synthetic data to build trust and drive adoption.

Abstract: Causal machine learning has the potential to revolutionize decision-making by
combining the predictive power of machine learning algorithms with the theory
of causal inference. However, these methods remain underutilized by the broader
machine learning community, in part because current empirical evaluations do
not permit assessment of their reliability and robustness, undermining their
practical utility. Specifically, one of the principal criticisms made by the
community is the extensive use of synthetic experiments. We argue, on the
contrary, that synthetic experiments are essential and necessary to precisely
assess and understand the capabilities of causal machine learning methods. To
substantiate our position, we critically review the current evaluation
practices, spotlight their shortcomings, and propose a set of principles for
conducting rigorous empirical analyses with synthetic data. Adopting the
proposed principles will enable comprehensive evaluations that build trust in
causal machine learning methods, driving their broader adoption and impactful
real-world use.

</details>


### [207] [Generalising Traffic Forecasting to Regions without Traffic Observations](https://arxiv.org/abs/2508.08947)
*Xinyu Su,Majid Sarvi,Feng Liu,Egemen Tanin,Jianzhong Qi*

Main category: cs.LG

TL;DR: GenCast forecasts traffic in sensorless regions by using external data (weather) and physics-informed neural networks to compensate for missing observations, improving accuracy.


<details>
  <summary>Details</summary>
Motivation: To forecast traffic for regions without traffic sensors, where the lack of historical traffic observations challenges the generalisability of existing models.

Method: GenCast integrates physics-informed neural networks and an external signal learning module to explore correlations between traffic states and external signals, along with a spatial grouping module to filter localized features.

Result: The proposed model, GenCast, improves generalisability and reduces forecasting errors.

Conclusion: GenCast consistently reduces forecasting errors on multiple real-world datasets by exploiting external knowledge and integrating physics-informed neural networks.

Abstract: Traffic forecasting is essential for intelligent transportation systems.
Accurate forecasting relies on continuous observations collected by traffic
sensors. However, due to high deployment and maintenance costs, not all regions
are equipped with such sensors. This paper aims to forecast for regions without
traffic sensors, where the lack of historical traffic observations challenges
the generalisability of existing models. We propose a model named GenCast, the
core idea of which is to exploit external knowledge to compensate for the
missing observations and to enhance generalisation. We integrate
physics-informed neural networks into GenCast, enabling physical principles to
regularise the learning process. We introduce an external signal learning
module to explore correlations between traffic states and external signals such
as weather conditions, further improving model generalisability. Additionally,
we design a spatial grouping module to filter localised features that hinder
model generalisability. Extensive experiments show that GenCast consistently
reduces forecasting errors on multiple real-world datasets.

</details>


### [208] [Towards Universal Neural Inference](https://arxiv.org/abs/2508.09100)
*Shreyas Bhat Brahmavar,Yang Li,Junier Oliva*

Main category: cs.LG

TL;DR: ASPIRE 是一个能够处理多样化、不相干的结构化数据的通用神经网络推理模型。它使用基于集合的、置换不变的 Transformer 和语义对齐模块来学习跨数据集的特征依赖性，从而实现语义推理和预测。ASPIRE 可以在没有额外调整的情况下泛化到新的推理任务，并支持成本感知的主动特征获取。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据通常以多样化、不相干的形式出现，具有不同的模式、不一致的语义和固定的特征顺序，这使得构建能够跨数据集利用信息的通用模型具有挑战性。

Method: ASPIRE 结合了基于集合的、置换不变的 Transformer 和语义对齐模块，该模块利用自然语言描述、数据集元数据和上下文示例来学习跨数据集的特征依赖性。

Result: ASPIRE 在各种基准测试中都取得了强大的成果，并自然地支持在开放世界设置中进行成本感知的主动特征获取，在测试时预算约束下为任意未见的数据集选择信息特征。

Conclusion: ASPIRE 是一个通用的、语义感知的结构化数据推理引擎，能够处理异构结构化数据，并在新任务上进行泛化，同时支持成本感知的主动特征获取。

Abstract: Real-world data often appears in diverse, disjoint forms -- with varying
schemas, inconsistent semantics, and no fixed feature ordering -- making it
challenging to build general-purpose models that can leverage information
across datasets. We introduce ASPIRE, Arbitrary Set-based Permutation-Invariant
Reasoning Engine, a Universal Neural Inference model for semantic reasoning and
prediction over heterogeneous structured data. ASPIRE combines a
permutation-invariant, set-based Transformer with a semantic grounding module
that incorporates natural language descriptions, dataset metadata, and
in-context examples to learn cross-dataset feature dependencies. This
architecture allows ASPIRE to ingest arbitrary sets of feature--value pairs and
support examples, align semantics across disjoint tables, and make predictions
for any specified target. Once trained, ASPIRE generalizes to new inference
tasks without additional tuning. In addition to delivering strong results
across diverse benchmarks, ASPIRE naturally supports cost-aware active feature
acquisition in an open-world setting, selecting informative features under
test-time budget constraints for an arbitrary unseen dataset. These
capabilities position ASPIRE as a step toward truly universal, semantics-aware
inference over structured data.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [209] [Solving Set Constraints with Comprehensions and Bounded Quantifiers](https://arxiv.org/abs/2508.08496)
*Mudathir Mohamed,Nick Feng,Andrew Reynolds,Cesare Tinelli,Clark Barrett,Marsha Chechik*

Main category: cs.LO

TL;DR: Set-bounded quantifiers using a filter operator improve SMT solving for certain problems and offer a decidable subclass of constraints.


<details>
  <summary>Details</summary>
Motivation: SMT solvers struggle with quantified formulas from real-world applications, despite existing strategies and instantiation techniques. This paper explores set-bounded quantifiers as a potential solution.

Method: Implementing set-bounded quantifiers using the quantifier-free fragment of the theory of finite relations with a filter operator.

Result: The proposed approach with set-bounded quantifiers outperforms other techniques on satisfiable SLEEC benchmarks and is competitive on unsatisfiable benchmarks against LEGOS. Unrestricted use of the filter operator leads to undecidability, but a decidable subclass was identified.

Conclusion: set-bounded quantifiers, implemented using the theory of finite relations with a filter operator, outperform other quantification techniques on satisfiable benchmarks from SLEEC and are competitive on unsatisfiable benchmarks compared to LEGOS. A decidable class of constraints with restricted filter operator use was identified.

Abstract: Many real applications problems can be encoded easily as quantified formulas
in SMT. However, this simplicity comes at the cost of difficulty during solving
by SMT solvers. Different strategies and quantifier instantiation techniques
have been developed to tackle this. However, SMT solvers still struggle with
quantified formulas generated by some applications. In this paper, we discuss
the use of set-bounded quantifiers, quantifiers whose variable ranges over a
finite set. These quantifiers can be implemented using quantifier-free fragment
of the theory of finite relations with a filter operator, a form of restricted
comprehension, that constructs a subset from a finite set using a predicate. We
show that this approach outperforms other quantification techniques in
satisfiable problems generated by the SLEEC tool, and is very competitive on
unsatisfiable benchmarks compared to LEGOS, a specialized solver for SLEEC. We
also identify a decidable class of constraints with restricted applications of
the filter operator, while showing that unrestricted applications lead to
undecidability.

</details>


### [210] [Behavioural Theory of Reflective Algorithms II: Reflective Parallel Algorithms](https://arxiv.org/abs/2508.09053)
*Klaus-Dieter Schewe,Flavio Ferrarotti*

Main category: cs.LO

TL;DR: A behavioural theory for reflective parallel algorithms (RAs) is developed, featuring an abstract machine model (rASMs) that captures RAs by allowing them to modify their own behavior through linguistic reflection.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a behavioural theory for reflective parallel algorithms (RAs), which are synchronous parallel algorithms that can modify their own behavior. This theory aims to provide a formal framework for understanding and analyzing such algorithms.

Method: The method involves developing a behavioural theory for reflective parallel algorithms (RAs). This includes defining postulates for RAs, creating an abstract machine model (rASMs), and proving that all RAs are captured by this model. The theory utilizes multiset comprehension terms to preserve bounded exploration and extends Abstract State Machines (ASMs) with reflective capabilities.

Result: The result is a behavioural theory for reflective parallel algorithms (RAs), including a set of postulates, an abstract machine model (rASMs), and a proof of capture. This theory enables RAs to be sequential-time, parallel algorithms where states include a representation of the algorithm, allowing for linguistic reflection and preserving bounded exploration.

Conclusion: We develop a behavioural theory of reflective parallel algorithms (RAs), which are synchronous parallel algorithms capable of modifying their own behavior. The theory includes postulates defining RAs, an abstract machine model, and a proof of capture. RAs are sequential-time, parallel algorithms where each state contains a representation of the algorithm, enabling linguistic reflection. Bounded exploration is maintained through multiset comprehension terms. The abstract machine model is based on reflective Abstract State Machines (rASMs), which enhance ASMs with extended states containing an updatable representation of the main ASM rule for execution.

Abstract: We develop a behavioural theory of reflective parallel algorithms (RAs), i.e.
synchronous parallel algorithms that can modify their own behaviour. The theory
comprises a set of postulates defining the class of RAs, an abstract machine
model, and the proof that all RAs are captured by this machine model. RAs are
sequential-time, parallel algorithms, where every state includes a
representation of the algorithm in that state, thus enabling linguistic
reflection. Bounded exploration is preserved using multiset comprehension terms
as values. The abstract machine model is defined by reflective Abstract State
Machines (rASMs), which extend ASMs using extended states that include an
updatable representation of the main ASM rule to be executed by the machine in
that state.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [211] [CARES: Collaborative Agentic Reasoning for Error Detection in Surgery](https://arxiv.org/abs/2508.08764)
*Chang Han Low,Zhu Zhuo,Ziyue Wang,Jialang Xu,Haofeng Liu,Nazir Sirajudeen,Matthew Boal,Philip J. Edwards,Danail Stoyanov,Nader Francis,Jiehui Zhong,Di Gu,Evangelos B. Mazomenos,Yueming Jin*

Main category: cs.MA

TL;DR: 本研究提出了CARES框架和MERP数据集，用于机器人辅助前列腺手术中的多类别错误检测。CARES是一种创新的零样本学习方法，通过多智能体协作和风险分层推理，实现了高精度的错误检测，无需预先训练。实验证明，CARES在性能上超越了现有方法，并具有良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前手术错误检测方法在机器人辅助手术（RAS）中面临挑战，原因在于训练数据有限和方法学限制。因此，需要新的方法来有效检测机器人前列腺手术中的错误。

Method: 提出了一种名为CARES（Collaborative Agentic Reasoning for Error Detection in Surgery）的新型零样本、临床信息驱动、风险分层的 agentic 推理架构，用于多类别手术错误检测。该框架通过多专业水平的自适应生成、医学信息驱动、错误特定的链式思考（CoT）提示，并结合风险感知路由，将错误任务分配给匹配专业水平的推理路径。每个路径进一步分解为三个专业代理（时间、空间、程序），并使用针对分配的专业水平和错误类型量身定制的动态提示进行分析，生成详细透明的推理痕迹。

Result: CARES在RARP数据集上达到了54.3%的mF1分数，在MERP数据集上达到了52.0%的mF1分数，相比现有零样本方法提高了14%，并且能够与经过训练的模型相媲美。消融研究也验证了该方法的有效性。

Conclusion: 提出的CARES框架在机器人辅助前列腺切除术的零样本错误检测任务上表现出色，优于现有零样本方法，并且在RARP和MERP数据集上分别取得了54.3%和52.0%的mF1分数。

Abstract: Robotic-assisted surgery (RAS) introduces complex challenges that current
surgical error detection methods struggle to address effectively due to limited
training data and methodological constraints. Therefore, we construct MERP
(Multi-class Error in Robotic Prostatectomy), a comprehensive dataset for error
detection in robotic prostatectomy with frame-level annotations featuring six
clinically aligned error categories. In addition, we propose CARES
(Collaborative Agentic Reasoning for Error Detection in Surgery), a novel
zero-shot clinically-informed and risk-stratified agentic reasoning
architecture for multi-class surgical error detection. CARES implements
adaptive generation of medically informed, error-specific Chain-of-Thought
(CoT) prompts across multiple expertise levels. The framework employs
risk-aware routing to assign error task to expertise-matched reasoning pathways
based on complexity and clinical impact. Subsequently, each pathway decomposes
surgical error analysis into three specialized agents with temporal, spatial,
and procedural analysis. Each agent analyzes using dynamically selected prompts
tailored to the assigned expertise level and error type, generating detailed
and transparent reasoning traces. By incorporating clinically informed
reasoning from established surgical assessment guidelines, CARES enables
zero-shot surgical error detection without prior training. Evaluation
demonstrates superior performance with 54.3 mF1 on RARP and 52.0 mF1 on MERP
datasets, outperforming existing zero-shot approaches by up to 14% while
remaining competitive with trained models. Ablation studies demonstrate the
effectiveness of our method. The dataset and code will be publicly available.

</details>


### [212] [Fault Tolerant Multi-Agent Learning with Adversarial Budget Constraints](https://arxiv.org/abs/2508.08800)
*David Mguni,Yaqi Sun,Haojun Chen,Amir Darabi,Larry Olanrewaju Orimoloye,Yaodong Yang*

Main category: cs.MA

TL;DR: MARTA 是一种用于训练 MARL 智能体的即插即用框架，使其能够容忍故障。它通过一个对抗性游戏来工作，在该游戏中，一个对手会针对性地禁用智能体，而其他智能体则学会应对这些故障。MARTA 即使在发生故障时也能实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，确保智能体在计算组件不可避免地发生故障时，多智能体强化学习（MARL）策略仍然有效，这是一个关键挑战。

Method: MARTA 提出了一种新颖的对抗性马尔可夫博弈，其中一个对手通过马尔可夫开关控制来学习在危险状态区域禁用智能体，而其余智能体则被训练成对这些目标性故障进行联合最佳响应。MARTA 还强制执行了故障预算，将对手限制在固定数量的故障内，并据此学习鲁棒策略。

Result: MARTA 学习识别对系统性能最不利的故障场景，并为智能体提供减轻其影响的策略。MARTA 算法收敛到马尔可夫完美均衡，确保智能体能最佳地抵御最坏情况下的故障。

Conclusion: MARTA 在多智能体强化学习中实现了最先进的容错性能，并在多智能体粒子世界和基于级别的觅食等基准环境中得到了证明。

Abstract: In multi-agent systems, the safe and reliable execution of tasks often
depends on agents correctly coordinating their actions. However, in real-world
deployments, failures of computational components are inevitable, presenting a
critical challenge: ensuring that multi-agent reinforcement learning (MARL)
policies remain effective even when some agents malfunction. We propose the
Multi-Agent Robust Training Algorithm (MARTA), a plug-and-play framework for
training MARL agents to be resilient to potentially severe faults. MARTA
operates in cooperative multi-agent settings where agents may lose the ability
to execute their intended actions. It learns to identify failure scenarios that
are especially detrimental to system performance and equips agents with
strategies to mitigate their impact. At the heart of MARTA is a novel
adversarial Markov game in which an adversary -- modelled via \emph{Markov
switching controls} -- learns to disable agents in high-risk state regions,
while the remaining agents are trained to \emph{jointly} best-respond to such
targeted malfunctions. To ensure practicality, MARTA enforces a malfunction
budget, constraining the adversary to a fixed number of failures and learning
robust policies accordingly. We provide theoretical guarantees that MARTA
converges to a Markov perfect equilibrium, ensuring agents optimally counteract
worst-case faults. Empirically, we show that MARTA achieves state-of-the-art
fault-tolerant performance across benchmark environments, including Multi-Agent
Particle World and Level-Based Foraging.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [213] [Profiling Concurrent Vision Inference Workloads on NVIDIA Jetson -- Extended](https://arxiv.org/abs/2508.08430)
*Abhinaba Chakraborty,Wouter Tavernier,Akis Kourtis,Mario Pickavet,Andreas Oikonomakis,Didier Colle*

Main category: cs.DC

TL;DR: GPU在边缘计算中常未被充分利用，瓶颈在于低级别资源利用率低和CPU事件干扰。本研究通过分析NVIDIA Jetson设备上的视觉推理任务，发现SM和张量核利用率仅15%-30%，CPU调度是主要限制因素，并为优化提供了见解。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备和网络技术的发展，对网络边缘的实时数据处理需求日益增强。尽管低功耗AI加速器（尤其是GPU）被广泛部署用于推理任务，但它们在实际应用中常常处于未被充分利用的状态，尤其是在边缘计算场景下，对GPU资源共享的理解有限。

Method: 通过整合多个分析工具的追踪信息，对NVIDIA Jetson边缘设备在并发视觉推理工作负载下的GPU利用率、内存使用、流式多处理器（SM）利用率和张量核使用率等高低级别指标进行详细分析，以识别瓶颈并指导硬件感知优化。

Result: 研究发现，虽然GPU利用率在特定优化下可达100%，但SM和张量核等关键低级别资源利用率仅为15%-30%。CPU端的事件（如线程调度、上下文切换）是限制GPU性能的关键瓶颈。研究为在NVIDIA边缘设备上运行视觉推理工作负载的用户提供了关键的见解。

Conclusion: GPU在边缘计算场景下存在利用率不足的问题，主要瓶颈在于低级别资源（如SM和张量核）的利用率低，以及CPU端的线程调度、上下文切换等事件。需要通过硬件感知优化来解决这些问题。

Abstract: The proliferation of IoT devices and advancements in network technologies
have intensified the demand for real-time data processing at the network edge.
To address these demands, low-power AI accelerators, particularly GPUs, are
increasingly deployed for inference tasks, enabling efficient computation while
mitigating cloud-based systems' latency and bandwidth limitations. Despite
their growing deployment, GPUs remain underutilised even in computationally
intensive workloads. This underutilisation stems from the limited understanding
of GPU resource sharing, particularly in edge computing scenarios. In this
work, we conduct a detailed analysis of both high- and low-level metrics,
including GPU utilisation, memory usage, streaming multiprocessor (SM)
utilisation, and tensor core usage, to identify bottlenecks and guide
hardware-aware optimisations. By integrating traces from multiple profiling
tools, we provide a comprehensive view of resource behaviour on NVIDIA Jetson
edge devices under concurrent vision inference workloads. Our findings indicate
that while GPU utilisation can reach $100\%$ under specific optimisations,
critical low-level resources, such as SMs and tensor cores, often operate only
at $15\%$ to $30\%$ utilisation. Moreover, we observe that certain CPU-side
events, such as thread scheduling, context switching, etc., frequently emerge
as bottlenecks, further constraining overall GPU performance. We provide
several key observations for users of vision inference workloads on NVIDIA edge
devices.

</details>


### [214] [Benchmarking Federated Learning for Throughput Prediction in 5G Live Streaming Applications](https://arxiv.org/abs/2508.08479)
*Yuvraj Dutta,Soumyajit Chatterjee,Sandip Chakraborty,Basabdatta Palit*

Main category: cs.DC

TL;DR: 本研究在5G边缘场景下对联邦学习（FL）策略进行了基准测试，以预测网络吞吐量。研究评估了不同的聚合算法和时间序列模型，发现FedBN在非IID数据下表现最佳，而LSTM和Transformer模型优于CNN。将FL模型集成到流媒体管道中，可提高QoE分数。


<details>
  <summary>Details</summary>
Motivation: 为了在5G和新兴的6G网络中实现对延迟敏感和带宽密集型应用的网络吞吐量进行准确和自适应的预测，但现有的集中式方法在异构的移动环境中面临数据分布非IID的限制。

Method: 本研究评估了三种聚合算法（FedAvg、FedProx和FedBN）在四种时间序列架构（LSTM、CNN、CNN+LSTM和Transformer）上的性能，并使用五个真实世界的数据集，分析了客户异质性、群体大小和历史窗口长度对预测性能的影响。

Result: FedBN在非IID条件下表现稳健。LSTM和Transformer模型比CNN基线模型在R2分数上高出80%。Transformer收敛速度快于LSTM，但需要更长的历史窗口。LSTM在准确性、收敛速度和时间占用方面取得了良好的平衡。FedBN-LSTM和FedBN-Transformer模型相比FedAvg，将平均QoE分数提高了11.7%和11.4%，并减少了方差。

Conclusion: 本研究对5G边缘场景下的联邦学习（FL）策略进行了全面的基准测试，用于网络吞吐量预测，并验证了FL在自适应流媒体管道中的端到端适用性，证明了FL在可扩展、注重隐私和支持边缘计算的网络吞吐量预测系统中具有实际应用价值。

Abstract: Accurate and adaptive network throughput prediction is essential for
latency-sensitive and bandwidth-intensive applications in 5G and emerging 6G
networks. However, most existing methods rely on centralized training with
uniformly collected data, limiting their applicability in heterogeneous mobile
environments with non-IID data distributions. This paper presents the first
comprehensive benchmarking of federated learning (FL) strategies for throughput
prediction in realistic 5G edge scenarios. We evaluate three aggregation
algorithms - FedAvg, FedProx, and FedBN - across four time-series
architectures: LSTM, CNN, CNN+LSTM, and Transformer, using five diverse
real-world datasets. We systematically analyze the effects of client
heterogeneity, cohort size, and history window length on prediction
performance. Our results reveal key trade-offs among model complexities,
convergence rates, and generalization. It is found that FedBN consistently
delivers robust performance under non-IID conditions. On the other hand, LSTM
and Transformer models outperform CNN-based baselines by up to 80% in R2
scores. Moreover, although Transformers converge in half the rounds of LSTM,
they require longer history windows to achieve a high R2, indicating higher
context dependence. LSTM is, therefore, found to achieve a favorable balance
between accuracy, rounds, and temporal footprint. To validate the end-to-end
applicability of the framework, we have integrated our FL-based predictors into
a live adaptive streaming pipeline. It is seen that FedBN-based LSTM and
Transformer models improve mean QoE scores by 11.7% and 11.4%, respectively,
over FedAvg, while also reducing the variance. These findings offer actionable
insights for building scalable, privacy-preserving, and edge-aware throughput
prediction systems in next-generation wireless networks.

</details>


### [215] [A Reinforcement Learning-Driven Task Scheduling Algorithm for Multi-Tenant Distributed Systems](https://arxiv.org/abs/2508.08525)
*Xiaopei Zhang,Xingang Wang,Xin Wang*

Main category: cs.DC

TL;DR: 提出一种基于PPO的强化学习调度方法，用于解决多租户分布式系统的任务调度问题，通过优化延迟、资源利用和公平性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多租户分布式系统中动态资源变化、异构租户需求以及公平性保证等关键挑战。

Method: 提出了一种基于强化学习（Proximal Policy Optimization - PPO）的自适应调度方法，将调度过程建模为马尔可夫决策过程，并通过策略网络和价值网络的协同学习来优化调度策略。

Result: 实验结果表明，所提出的方法在任务延迟控制、资源效率、策略稳定性和公平性方面优于现有调度方法，并表现出良好的稳定性和泛化能力。

Conclusion: 该研究提出的基于强化学习的自适应调度方法在多租户分布式系统的任务调度方面表现出色，能够有效优化任务延迟、资源利用率和租户公平性，并具有良好的稳定性和泛化能力，为实际工程应用提供了价值。

Abstract: This paper addresses key challenges in task scheduling for multi-tenant
distributed systems, including dynamic resource variation, heterogeneous tenant
demands, and fairness assurance. An adaptive scheduling method based on
reinforcement learning is proposed. By modeling the scheduling process as a
Markov decision process, the study defines the state space, action space, and
reward function. A scheduling policy learning framework is designed using
Proximal Policy Optimization (PPO) as the core algorithm. This enables dynamic
perception of complex system states and real-time decision-making. Under a
multi-objective reward mechanism, the scheduler jointly optimizes task latency,
resource utilization, and tenant fairness. The coordination between the policy
network and the value network continuously refines the scheduling strategy.
This enhances overall system performance. To validate the effectiveness of the
proposed method, a series of experiments were conducted in multi-scenario
environments built using a real-world public dataset. The experiments evaluated
task latency control, resource efficiency, policy stability, and fairness. The
results show that the proposed method outperforms existing scheduling
approaches across multiple evaluation metrics. It demonstrates strong stability
and generalization ability. The proposed scheduling framework provides
practical and engineering value in policy design, dynamic resource modeling,
and multi-tenant service assurance. It effectively improves scheduling
efficiency and resource management in distributed systems under complex
conditions.

</details>


### [216] [P/D-Device: Disaggregated Large Language Model between Cloud and Devices](https://arxiv.org/abs/2508.09035)
*Yibo Jin,Yixu Xu,Yue Chen,Chengbin Wang,Tao Wang,Jiaqi Huang,Rongfei Zhang,Yiming Dong,Yuting Yan,Ke Cheng,Yingjie Zhu,Shulan Wang,Qianqian Tang,Shuaishuai Meng,Guanxin Cheng,Ze Wang,Shuyan Miao,Ketao Wang,Wen Liu,Yifan Yang,Tong Zhang,Anran Wang,Chengzhou Lu,Tiantian Dong,Yongsheng Zhang,Zhe Wang,Hefei Guo,Hongjie Liu,Wei Lu,Zhengyong Zhang*

Main category: cs.DC

TL;DR: 该研究提出了一种名为 P/D-Device 的模型分离方案，通过将大型语言模型的部分计算放在云端，部分放在设备端，显著提高了响应速度和系统吞吐量，并优化了资源利用率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在云端因生成过多令牌导致资源占用时间长，以及在设备端因提示长度增加导致首次响应时间（TTFT）显著增加的问题，提出了一种云端与设备分离的方案。

Method: 提出了一种将大型语言模型在云端和设备之间分离的方案（P/D-Device），其中云端在预填（prefill）阶段为设备提供部分内容，设备在接收到第一个令牌后立即响应用户，并通过速度控制器逐步接收后续令牌，直至设备跟上进度。在此过程中，设备上的预填被分摊，云端的资源使用得到控制，并且云端的提示可以通过中间生成的数据进行优化。

Result: 实验结果表明，P/D-Device 方案将 TTFT 降低了至少 60%，最大输出令牌时间（TPOT）约为几十毫秒，云端吞吐量最高提升了 15 倍。

Conclusion: 通过云和设备之间的模型分离，P/D-Device 方案在降低首次响应时间（TTFT）和提高云吞吐量方面表现出色，同时通过使用速度控制器平滑输出令牌时间和对提示进行优化来控制资源使用。

Abstract: Serving disaggregated large language models has been widely adopted in
industrial practice for enhanced performance. However, too many tokens
generated in decoding phase, i.e., occupying the resources for a long time,
essentially hamper the cloud from achieving a higher throughput. Meanwhile, due
to limited on-device resources, the time to first token (TTFT), i.e., the
latency of prefill phase, increases dramatically with the growth on prompt
length. In order to concur with such a bottleneck on resources, i.e., long
occupation in cloud and limited on-device computing capacity, we propose to
separate large language model between cloud and devices. That is, the cloud
helps a portion of the content for each device, only in its prefill phase.
Specifically, after receiving the first token from the cloud, decoupling with
its own prefill, the device responds to the user immediately for a lower TTFT.
Then, the following tokens from cloud are presented via a speed controller for
smoothed TPOT (the time per output token), until the device catches up with the
progress. On-device prefill is then amortized using received tokens while the
resource usage in cloud is controlled. Moreover, during cloud prefill, the
prompt can be refined, using those intermediate data already generated, to
further speed up on-device inference. We implement such a scheme P/D-Device,
and confirm its superiority over other alternatives. We further propose an
algorithm to decide the best settings. Real-trace experiments show that TTFT
decreases at least 60%, maximum TPOT is about tens of milliseconds, and cloud
throughput increases by up to 15x.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [217] [Low-density InGaAs/AlGaAs Quantum Dots in Droplet-Etched Nanoholes](https://arxiv.org/abs/2508.08400)
*Saimon F. Covre Da Silva,Ailton J. Garcia Jr,Maximilian Aigner,Christian Weidinger,Tobias M. Krieger,Gabriel Undeutsch,Christoph Deneke,Ishrat Bashir,Santanu Manna,Melina Peter,Ievgen Brytavskyi,Johannes Aberl,Armando Rastelli*

Main category: physics.app-ph

TL;DR: Epitaxial semiconductor quantum dots (QDs) are promising for quantum photonics. Local droplet etching was used to grow In(Ga)As QDs in AlGaAs, achieving emission up to ~920 nm with desirable properties like low density and small fine structure splitting. These QDs are suitable for integrated quantum photonics.


<details>
  <summary>Details</summary>
Motivation: To extend the achievable emission wavelength range beyond GaAs/AlGaAs QDs while retaining the advantages of low/controllable surface densities, small FSS, and fast radiative decays offered by droplet etching epitaxy.

Method: Local droplet etching technique extended to In(Ga)As QDs in AlGaAs.

Result: Achieved QD densities of ~0.2 um^-2, FSS values as small as 3 μeV, short radiative lifetimes of ~300 ps, and extended the emission range to ~920 nm at cryogenic temperatures.

Conclusion: In(Ga)As QDs in AlGaAs have been grown by local droplet etching, extending the emission wavelength to ~920 nm with low density, small FSS, and fast radiative decay, making them suitable for integrated quantum photonics.

Abstract: Over the past two decades, epitaxial semiconductor quantum dots (QDs) have
demonstrated very promising properties as sources of single photons and
entangled photons on-demand. Among different growth methods, droplet etching
epitaxy has allowed the growth of almost strain-free QDs, with low and
controllable surface densities, small excitonic fine structure splitting (FSS),
and fast radiative decays. Here, we extend the local droplet etching technique
to In(Ga)As QDs in AlGaAs, thereby increasing the achievable emission
wavelength range beyond that accessible to GaAs/AlGaAs QDs, while benefiting
from the aforementioned advantages of this growth method. We observe QD
densities of $\sim 0.2\ \mu\mathrm{m}^{-2}$, FSS values as small as $3\
\mu\mathrm{eV}$, and short radiative lifetimes of $\sim 300\ \mathrm{ps}$,
while extending the achievable emission range to $\sim 920\ \mathrm{nm}$ at
cryogenic temperatures. We envision these QDs to be particularly suitable for
integrated quantum photonics applications.

</details>


### [218] [Comparative Study of Lateral and Vertical Beta-Ga2O3 Photoconductive Switches via Intrinsic and Extrinsic Optical Triggering](https://arxiv.org/abs/2508.08522)
*Vikash K. Jangir,Sudip K. Mazumder*

Main category: physics.app-ph

TL;DR: 本研究比较了横向和垂直 beta-Ga2O3 PCSS 在不同光激发下的性能，发现在内源性激发下横向器件表现更好，而在外源性激发下垂直器件表现更好，这为优化 Ga2O3 PCSS 性能提供了指导。


<details>
  <summary>Details</summary>
Motivation: 氧化镓（Ga2O3）因其超宽带隙和高击穿场强，是高功率、高速度脉冲应用中光电导半导体开关（PCSS）的领先候选材料。为了优化 Ga2O3 PCSS 的性能，本研究旨在系统地比较横向和垂直结构的 PCSS 在不同光激发条件下的表现。

Method: 本研究采用系统性的实验比较方法，在内源性（245 nm）和外源性（280 nm、300 nm 和 445 nm）光激发下，对横向和垂直 beta-Ga2O3 压电陶瓷开关（PCSS）的性能进行了测试和分析。

Result: 在内源性激发下，横向 PCSS 的光电流性能优于垂直结构。在通过外源性激发（允许光线更深地穿透到体材料中）时，垂直 PCSS 由于在整个器件体积中具有更均匀的电场分布，因此表现出更优越的开关性能。

Conclusion: 该研究首次对横向和垂直 beta-Ga2O3 压电陶瓷开关在内源性（245 nm）和外源性（280 nm、300 nm 和 445 nm）光激发下的特性进行了系统实验比较。研究结果表明，在内源性激发下，横向压电陶瓷开关表现出比垂直结构更高的光电流性能；而在外源性激发下，垂直压电陶瓷开关由于更均匀的电场分布而表现出更优越的开关性能。这些结果强调了器件几何形状和载流子产生机制在优化 Ga2O3 压电陶瓷开关性能方面起着至关重要的作用，并为开发高效、经济的髙压压电陶瓷开关提供了宝贵的指导。

Abstract: Gallium oxide (Ga2O3), with its ultra-wide bandgap (approximately 4.8 eV) and
high breakdown field (approximately 8 MV per cm), is a leading candidate for
photoconductive semiconductor switches (PCSSs) in high-power and high-speed
pulsed applications. This work, for the first time, presents a systematic
experimental comparison of lateral and vertical beta-Ga2O3 PCSS under both
intrinsic (245 nm) and extrinsic (280 nm, 300 nm, and 445 nm) optical
excitation. Under intrinsic excitation, where carrier generation is confined
near the surface due to the shallow absorption depth (approximately between 0.1
and 1 um), the lateral PCSS demonstrated higher photocurrent performance
compared to the vertical structure. In contrast, under extrinsic excitation,
which enables deeper penetration into the bulk, the vertical PCSS exhibited
enhanced switching performance due to a more uniform electric-field
distribution across the device volume. These results highlight the critical
role of device geometry and carrier generation mechanism in optimizing Ga2O3
PCSS performance and provide valuable guidance for developing efficient and
cost-effective high-voltage PCSSs.

</details>


### [219] [Multimodal learning enables instant ionizing radiation alerts on unmodified mobile phones for real-world emergency response](https://arxiv.org/abs/2508.08541)
*Yanfeng Xie,Xingzhi Cheng*

Main category: physics.app-ph

TL;DR: 该研究提出了一种无需摄像头或额外硬件修改的、基于手机的辐射检测方法，利用深度学习技术，能够在几秒钟内检测危险辐射，并有潜力成为实用的辐射应急检测工具。


<details>
  <summary>Details</summary>
Motivation: 在辐射紧急情况下，公众几乎无法获得专用的监测设备，因此需要一种实用的、基于手机的辐射检测方法。

Method: 利用多模态深度学习方法，整合稀疏的辐射诱导信号分布与亮度模式，并通过混合3D-2D卷积神经网络（CNN）识别原始手机视频中的辐射诱导点，同时利用多层感知器（MLP）融合辐射信号和亮度图以估计剂量率。

Result: 该方法可在六秒内快速检测到危险剂量率（25-280 mRem/h），准确率为86-96%；在延长的测量时间内，能以87%的准确率检测到低水平辐射（-0.6 mRem/h）。

Conclusion: 该方法极大地提高了手机辐射检测的实用性，并作为一种可访问的辐射应急检测工具展现出巨大潜力。

Abstract: In a radiation emergency, every second counts, yet the public rarely has
immediate access to dedicated monitoring devices when they are needed most.
Here, the first practical mobile phone-based emergency ionizing radiation
detection method is presented that operates entirely without requiring camera
coverage or additional hardware modifications. Utilizing a multimodal deep
learning approach that integrates sparse radiation-induced signal distributions
with the brightness patterns, the proposed framework effectively isolates
subtle radiation signals from overwhelming visual interference. A hybrid 3D-2D
convolutional neural network (CNN) identifies radiation-induced spots from raw
mobile phone video, while a multi-layer perceptron (MLP) fuses the radiation
signal and brightness maps for the dose rate estimation. The method detects
hazardous dose rates (25-280 mRem/h) rapidly within six seconds (accuracy
86-96%), and low-level radiation (-0.6 mRem/h) with extended measurement
durations achieves 87% accuracy. The developed method greatly enhances mobile
phone radiation detection practicality and shows substantial potential as an
accessible radiation emergency detection tool.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [220] [DeePConverter: A Data-Driven Optimal Control Architecture for Grid-Connected Power Converters](https://arxiv.org/abs/2508.08578)
*Ruohan Leng,Linbin Huang,Huanhai Xin,Ping Ju,Xiongfei Wang,Eduardo Prieto-Araujo,Florian Dörfler*

Main category: eess.SY

TL;DR: DeePConverters use data-enabled predictive control (DeePC) for robust and optimal control of power converters, outperforming traditional PID methods by adapting to complex grid conditions.


<details>
  <summary>Details</summary>
Motivation: Conventional PID regulators in grid-connected power converters are tuned based on simplified grid models, leading to inferior performance or instabilities in practice due to the complexity and variability of real power grids.

Method: A data-enabled predictive control (DeePC) is employed to perform data-driven, optimal, and robust control for power converters.

Result: DeePConverters, operated using DeePC, demonstrate optimal and robust performance by adapting to grid characteristics.

Conclusion: DeePConverters can implicitly perceive the characteristics of the power grid from data and adjust its control strategy to achieve optimal and robust performance. High-fidelity simulations and hardware-in-the-loop (HIL) tests validate the effectiveness of DeePConverters.

Abstract: Grid-connected power converters are ubiquitous in modern power systems,
acting as grid interfaces of renewable energy sources, energy storage systems,
electric vehicles, high-voltage DC systems, etc. Conventionally, power
converters use multiple PID regulators to achieve different control objectives
such as grid synchronization and voltage/power regulations, where the PID
parameters are usually tuned based on a presumed (and often overly-simplified)
power grid model. However, this may lead to inferior performance or even
instabilities in practice, as the real power grid is highly complex, variable,
and generally unknown. To tackle this problem, we employ a data-enabled
predictive control (DeePC) to perform data-driven, optimal, and robust control
for power converters. We call the converters that are operated in this way
\textit{DeePConverters}. A DeePConverter can implicitly perceive the
characteristics of the power grid from data and adjust its control strategy to
achieve optimal and robust performance. We present the modular configurations,
generalized structure, control behavior specification, detailed implementation,
and computation of DeePConverters. High-fidelity simulations and
hardware-in-the-loop (HIL) tests are provided to validate the effectiveness of
DeePConverters.

</details>


### [221] [XR Reality Check: What Commercial Devices Deliver for Spatial Tracking](https://arxiv.org/abs/2508.08642)
*Tianyi Hu,Tianyuan Du,Zhehan Qu,Maria Gorlatova*

Main category: eess.SY

TL;DR: 本研究为XR设备追踪性能评估提供了标准化的测试框架和基准数据集。结果表明，追踪精度受环境、运动和硬件规格影响，并对Apple Vision Pro作为地面真实参考的可行性进行了探讨。


<details>
  <summary>Details</summary>
Motivation: 不精确的空间追踪会限制XR设备的沉浸式体验和自然交互。本研究旨在通过实证评估和基准测试来解决XR设备追踪不精确的问题。

Method: 引入了一个新的测试平台，能够同时、同步地评估多个XR设备在相同的环境和运动条件下的性能。利用该平台，对五种最先进的XR设备在16种不同场景下进行了全面的实证基准测试。

Result: 结果显示，设备性能存在显著的内部差异，在无特征环境中误差最多增加101%。追踪精度与视觉条件和运动动力学密切相关。设备之间也存在显著差异，性能差异最大可达2.8倍，这与传感器配置和专用处理单元等硬件规格密切相关。Apple Vision Pro在相对姿态误差估计方面表现良好（R^2 = 0.830），但在绝对姿态误差估计方面能力有限（R^2 = 0.387）。

Conclusion: 该工作建立了一个标准化的框架，用于对XR设备进行比较追踪评估，为研究社区提供了可重现的方法、全面的基准数据集和开源工具，能够系统地分析跨设备和跨条件的追踪性能，从而加速XR系统更鲁棒的空间传感技术的发展。

Abstract: Inaccurate spatial tracking in extended reality (XR) devices leads to virtual
object jitter, misalignment, and user discomfort, fundamentally limiting
immersive experiences and natural interactions. In this work, we introduce a
novel testbed that enables simultaneous, synchronized evaluation of multiple XR
devices under identical environmental and kinematic conditions. Leveraging this
platform, we present the first comprehensive empirical benchmarking of five
state-of-the-art XR devices across 16 diverse scenarios. Our results reveal
substantial intra-device performance variation, with individual devices
exhibiting up to 101\% increases in error when operating in featureless
environments. We also demonstrate that tracking accuracy strongly correlates
with visual conditions and motion dynamics. We also observe significant
inter-device disparities, with performance differences of up to 2.8$\times$,
which are closely linked to hardware specifications such as sensor
configurations and dedicated processing units. Finally, we explore the
feasibility of substituting a motion capture system with the Apple Vision Pro
as a practical ground truth reference. While the Apple Vision Pro delivers
highly accurate relative pose error estimates ($R^2 = 0.830$), its absolute
pose error estimation remains limited ($R^2 = 0.387$), highlighting both its
potential and its constraints for rigorous XR evaluation. This work establishes
the first standardized framework for comparative XR tracking evaluation,
providing the research community with reproducible methodologies, comprehensive
benchmark datasets, and open-source tools that enable systematic analysis of
tracking performance across devices and conditions, thereby accelerating the
development of more robust spatial sensing technologies for XR systems.

</details>


### [222] [Architecture and FPGA Implementation of Digital Time-to-Digital Converter for Sensing Applications](https://arxiv.org/abs/2508.08725)
*Zeinab Hijazi,Fatima Bzeih,Ali Ibrahim*

Main category: eess.SY

TL;DR: 本研究设计了一种基于FPGA的数字时间-数字转换器，以降低功耗和硬件复杂性，并有效处理高精度时间转换任务。


<details>
  <summary>Details</summary>
Motivation: 为了应对嵌入式机器学习和边缘计算领域中高功耗和高计算需求的挑战，需要设计应用专用电路来降低硬件复杂度和功耗。

Method: 基于多种延迟线拓扑设计数字时间-数字转换器（DTDC），并使用VHDL语言在Xilinx Artix-7 AC701 FPGA器件上实现。

Result: 仿真结果表明，该DTDC电路能够有效转换高达1ps的输入周期，并且资源利用率低于目标FPGA器件的1%。

Conclusion: 所设计的数字时间-数字转换器（DTDC）在目标FPGA器件上实现了较低的资源利用率（不到1%），并能在宽范围内（高达1ps）有效地转换输入周期。

Abstract: Many application domains face the challenges of high-power consumption and
high computational demands, especially with the advancement in embedded machine
learning and edge computing. Designing application-specific circuits is crucial
to reducing hardware complexity and power consumption. In these perspectives,
this paper presents the design of a Digital Time-to-Digital converter (DTDC)
based on multiple delay line topologies. The DTDC is implemented in VHDL for
the Xilinx Artix-7 AC701 FPGA device. Simulation results demonstrate the
effectiveness of the circuit in converting the input period along a wide range
up to 1ps. The designed circuit is implemented with less than 1% of the
resource utilization on the target FPGA device.

</details>


### [223] [Smart Residential Community Simulator for Developing and Benchmarking Energy Management Systems](https://arxiv.org/abs/2508.09106)
*Ninad Gaikwad,Anamika Dubey*

Main category: eess.SY

TL;DR: 提出了一种灵活且可扩展的HEMS模拟器，该模拟器可以处理任意数量的房屋和DER配置，并支持在网和离网模式。


<details>
  <summary>Details</summary>
Motivation: 现有的家庭能源管理系统（HEMS）模拟器通常针对特定的分布式能源（DER）配置和固定的房屋数量进行定制，这限制了灵活性和可扩展性。

Method: 提出了一种可扩展的模拟器，该模拟器能够将任何数量的房屋建模为 Gymnasium 环境，并支持单户和社区模拟，以及在网和离网模式。

Result: 模拟器可以对具有异构DER的单户和四户社区进行模拟，并对控制器进行基准测试，展示了其在不同系统配置下评估控制策略性能的能力。

Conclusion: 该模拟器能够系统地评估不同系统配置下控制策略的性能。

Abstract: Home Energy Management Systems (HEMS) are being actively developed for both
individual houses and communities to support demand response in on-grid
operation, and ensure resilience during off-grid scenarios. However, most
simulators used for closed-loop HEMS testing are tailored to a specific
distributed energy resource (DER) configuration with a fixed number of houses,
limiting flexibility and scalability. This leads to additional development
efforts to support diverse DER configurations across any number of houses and
to integrate appropriate weather and load data pipelines. To address these
limitations, we present a scalable simulator capable of modeling any number of
houses in both on-grid and off-grid modes as a Gymnasium environment. Each
house can have a unique DER configuration - Rooftop Solar Photovoltaics (PV),
Battery-only, PV-only, or no DER - and includes models for air-conditioning and
eight grouped circuit-level loads. The simulator integrates National Solar
Radiation Database (NSRDB) weather and Pecan Street load datasets, supports
three default controllers (two for off-grid, and one for on-grid scenarios),
and includes performance metrics and visualization tools. We demonstrate its
flexibility through simulations on individual houses and a four-house community
with heterogeneous DERs, benchmarking the controllers across built-in metrics
and computation time. The results highlight the simulator's capability to
systematically evaluate control policy performance under varying system
configurations.

</details>


### [224] [Comparing Building Thermal Dynamics Models and Estimation Methods for Grid-Edge Applications](https://arxiv.org/abs/2508.09118)
*Ninad Gaikwad,Kunal Shankar,Anamika Dubey,Alan Love,Olvar Bergland*

Main category: eess.SY

TL;DR: This paper compares different methods for modeling building thermal dynamics to find efficient and accurate options for grid-edge applications.


<details>
  <summary>Details</summary>
Motivation: There is a need for computationally efficient and accurate building thermal dynamics models for grid-edge applications.

Method: The study uses Nonlinear Least Squares, Batch Estimation, and Maximum Likelihood Estimation for RC-network models, and Almon Lag Structure with Linear Least Squares for structured regression models.

Result: The performance of these models and methods is evaluated on simulated data from a house and a commercial building under three different simulation types.

Conclusion: The paper evaluates RC-network models and structured regression models for building thermal dynamics, comparing different parameter estimation methods for RC-networks and using Almon Lag Structure with Linear Least Squares for structured regression models.

Abstract: We need computationally efficient and accurate building thermal dynamics
models for use in grid-edge applications. This work evaluates two grey-box
approaches for modeling building thermal dynamics: RC-network models and
structured regression models. For RC-network models, we compare parameter
estimation methods including Nonlinear Least Squares, Batch Estimation, and
Maximum Likelihood Estimation. We use the Almon Lag Structure with Linear Least
Squares for estimating the structured regression models. The performance of
these models and methods is evaluated on simulated house and commercial
building data across three different simulation types.

</details>


### [225] [A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions](https://arxiv.org/abs/2508.09128)
*Dhruv S. Kushwaha,Zoleikha A. Biron*

Main category: eess.SY

TL;DR: This review explores how Lyapunov and barrier functions, commonly used in control theory, can be adapted for safe reinforcement learning (RL) to guarantee system stability and constraint satisfaction, addressing a key limitation of traditional RL methods.


<details>
  <summary>Details</summary>
Motivation: The key motivation for this review is to discuss current theoretical approaches for safety and stability guarantees in RL, drawing parallels with control-theoretic methods that utilize Lyapunov and barrier functions.

Method: This review discusses different approaches used in safe reinforcement learning that leverage Lyapunov and barrier functions to ensure safety and stability, analyzing their shortcomings and benefits to suggest future research directions.

Result: The review provides an overview of safe RL techniques using Lyapunov and barrier functions, highlighting their potential and scope in ensuring safety for dynamical systems with constraints.

Conclusion: Safe reinforcement learning techniques using Lyapunov and barrier functions can provide safety and stability guarantees for complex dynamical systems with operational constraints, using both model-based and model-free RL.

Abstract: Reinforcement learning (RL) has proven to be particularly effective in
solving complex decision-making problems for a wide range of applications. From
a control theory perspective, RL can be considered as an adaptive optimal
control scheme. Lyapunov and barrier functions are the most commonly used
certificates to guarantee system stability for a proposed/derived controller
and constraint satisfaction guarantees, respectively, in control theoretic
approaches. However, compared to theoretical guarantees available in control
theoretic methods, RL lacks closed-loop stability of a computed policy and
constraint satisfaction guarantees. Safe reinforcement learning refers to a
class of constrained problems where the constraint violations lead to partial
or complete system failure. The goal of this review is to provide an overview
of safe RL techniques using Lyapunov and barrier functions to guarantee this
notion of safety discussed (stability of the system in terms of a computed
policy and constraint satisfaction during training and deployment). The
different approaches employed are discussed in detail along with their
shortcomings and benefits to provide critique and possible future research
directions. Key motivation for this review is to discuss current theoretical
approaches for safety and stability guarantees in RL similar to control
theoretic approaches using Lyapunov and barrier functions. The review provides
proven potential and promising scope of providing safety guarantees for complex
dynamical systems with operational constraints using model-based and model-free
RL.

</details>


### [226] [An Open-Source Simulation and Data Management Tool for EnergyPlus Building Models](https://arxiv.org/abs/2508.09130)
*Ninad Gaikwad,Kasey Dettlaff,Athul Jose P,Anamika Dubey*

Main category: eess.SY

TL;DR: An open-source GUI application with a PostgreSQL database is presented to simplify and manage EnergyPlus building simulation data, addressing limitations of existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing approaches for generating, managing, and analyzing EnergyPlus simulation data are cumbersome, especially with numerous models and varying simulation setups.

Method: Developed an open-source, GUI-based application using Plotly-Dash with an integrated PostgreSQL-based relational database.

Result: The integrated framework simplifies EnergyPlus simulations, manages simulation data, enables data analysis, and supports data-driven modeling tasks.

Conclusion: The developed application and database streamline EnergyPlus building model simulation workflows, simplifying data generation, aggregation, visualization, management, and analysis for engineers and researchers.

Abstract: We present a new open-source, GUI-based application created using
Plotly-Dash, along with an integrated PostgreSQL-based relational database,
developed to streamline EnergyPlus building model simulation workflows. The
application facilitates data generation, aggregation (across thermal zones),
and visualization based on customizable user preferences, while the database
efficiently stores and retrieves complex simulation data generated by
EnergyPlus. We demonstrate the need for this application and database,
emphasizing how existing approaches for generating, managing, and analyzing
EnergyPlus simulation data can be cumbersome, particularly when handling a
large number of building models with varying simulation setups. This integrated
framework enables building energy engineers and researchers to simplify their
EnergyPlus simulations, manage generated simulation data, perform data
analyses, and support data-driven modeling tasks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [227] [Convergent Q-Learning for Infinite-Horizon General-Sum Markov Games through Behavioral Economics](https://arxiv.org/abs/2508.08669)
*Yizhou Zhang,Eric Mazumdar*

Main category: cs.GT

TL;DR: 该研究分析了风险厌恶型量化响应均衡（RQE）在不同博弈类型中的计算方法，并为相关算法提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: 为了更真实地描绘人类在策略环境中的决策，引入了风险厌恶型量化响应均衡（RQE）作为一种解决方案概念，它结合了风险厌恶和有界理性特征。

Method: 对于标准型博弈，研究采用了基于单调性的方法，证明了RQE在单调性假设下关于支付矩阵的唯一性和Lipschitz连续性，并确定了确保单调性的风险厌恶和有界理性条件。对于贴现无限期马尔可夫博弈，研究定义了风险厌恶型量化响应贝尔曼算子，并在特定条件下证明了其收缩性。

Result: 研究为标准型博弈中的RQE的唯一性和Lipschitz连续性提供了条件，并为无限期马尔可夫博弈中的Q学习算法提供了收敛保证。

Conclusion: 该研究扩展了风险厌恶型量化响应均衡（RQE）的研究，分析了其在两人标准型博弈和贴现无限期马尔可夫博弈中的计算。

Abstract: Risk-aversion and bounded rationality are two key characteristics of human
decision-making. Risk-averse quantal-response equilibrium (RQE) is a solution
concept that incorporates these features, providing a more realistic depiction
of human decision making in various strategic environments compared to a Nash
equilibrium. Furthermore a class of RQE has recently been shown in
arXiv:2406.14156 to be universally computationally tractable in all
finite-horizon Markov games, allowing for the development of multi-agent
reinforcement learning algorithms with convergence guarantees. In this paper,
we expand upon the study of RQE and analyze their computation in both
two-player normal form games and discounted infinite-horizon Markov games. For
normal form games we adopt a monotonicity-based approach allowing us to
generalize previous results. We first show uniqueness and Lipschitz continuity
of RQE with respect to player's payoff matrices under monotonicity assumptions,
and then provide conditions on the players' degrees of risk aversion and
bounded rationality that ensure monotonicity. We then focus on discounted
infinite-horizon Markov games. We define the risk-averse quantal-response
Bellman operator and prove its contraction under further conditions on the
players' risk-aversion, bounded rationality, and temporal discounting. This
yields a Q-learning based algorithm with convergence guarantees for all
infinite-horizon general-sum Markov games.

</details>


### [228] [How to Resolve Envy by Adding Goods](https://arxiv.org/abs/2508.08682)
*Matthias Bentert,Robert Bredereck,Eva Deltl,Pallavi Jain,Leon Kellerhals*

Main category: cs.GT

TL;DR: 这篇论文研究了如何通过添加物品来消除分配中的嫉妒，并开发了一个多项式时间算法来解决这个问题。研究还探讨了在物品数量受限时问题的计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过添加物品来解决初始分配中存在的嫉妒问题，并探索在不同约束条件下问题的计算复杂度。

Method: 提出了一种基于嫉妒消除的分配解决方案，并通过实例验证了其有效性。推导了一个多项式时间算法来寻找解决方案。

Result: 当物品数量或添加物品总数受限时，即使在受限情况下，问题也变得计算上难以处理。通过参数化复杂性分析，特别关注代理数量和物品池大小。值得注意的是，虽然并非所有实例都允许无嫉妒的解决方案，但该方法能够有效地在多项式时间内确定是否存在解决方案。

Conclusion: 该方法能够有效识别是否存在可消除嫉妒的解决方案，并且在特定条件下可行。

Abstract: We consider the problem of resolving the envy of a given initial allocation
by adding elements from a pool of goods. We give a characterization of the
instances where envy can be resolved by adding an arbitrary number of copies of
the items in the pool. From this characterization, we derive a polynomial-time
algorithm returning a respective solution if it exists. If the number of copies
or the total number of added items are bounded, the problem becomes
computationally intractable even in various restricted cases. We perform a
parameterized complexity analysis, focusing on the number of agents and the
pool size as parameters. Notably, although not every instance admits an
envy-free solution, our approach allows us to efficiently determine, in
polynomial time, whether a solution exists-an aspect that is both theoretically
interesting and far from trivial.

</details>


### [229] [Optimal Boost Design for Auto-bidding Mechanism with Publisher Quality Constraints](https://arxiv.org/abs/2508.08772)
*Huanyu Yan,Yu Huo,Min Lu,Weitong Ou,Xingyan Shi,Ruihe Shi,Xiaoying Tang*

Main category: cs.GT

TL;DR: 本研究通过引入质量价值和设计q-Boost算法，优化了在线竞价中的提升因子，从而提高了广告分配效率和经济效益。


<details>
  <summary>Details</summary>
Motivation: 在线竞价在移动生态系统中至关重要，需要优化性能和用户体验，已有研究长期致力于提高广告分配效率，以增强所有参与者的经济效益。本研究着重于在考虑了质量价值（展示广告对发布者长期利益的影响）的在线竞价中设计最佳提升因子。

Method: 设计了一种新的质量因素增强（q-Boost）算法，用于计算最佳提升因子，并推导了第二价单一拍卖中C竞争性提升的理论效率下界。

Result: 实验验证表明，与传统方法相比，该方法在阿里巴巴的AuctionNet数据集上可将福利提高2%-6%。

Conclusion: 本研究为C竞争性定价的第二价单一拍卖设计了一种新的质量因素增强（q-Boost）算法，该算法在阿里巴巴的AuctionNet数据集上进行了实验验证，与传统方法相比，福利提高了2%-6%，证明了该方法在现实世界中的有效性。

Abstract: Online bidding is crucial in mobile ecosystems, enabling real-time ad
allocation across billions of devices to optimize performance and user
experience. Improving ad allocation efficiency is a long-standing research
problem, as it directly enhances the economic outcomes for all participants in
advertising platforms. This paper investigates the design of optimal boost
factors in online bidding while incorporating quality value (the impact of
displayed ads on publishers' long-term benefits). To address the divergent
interests on quality, we establish a three-party auction framework with a
unified welfare metric of advertiser and publisher. Within this framework, we
derive the theoretical efficiency lower bound for C-competitive boost in
second-price single-slot auctions, then design a novel quality-involved
Boosting (q-Boost) algorithm for computing the optimal boost factor.
Experimental validation on Alibaba's public dataset (AuctionNet) demonstrates
2%-6% welfare improvements over conventional approaches, proving our method's
effectiveness in real-world settings.

</details>


### [230] [Not in My Backyard! Temporal Voting Over Public Chores](https://arxiv.org/abs/2508.08810)
*Edith Elkind,Tzeh Yuan Neoh,Nicholas Teh*

Main category: cs.GT

TL;DR: 本研究分析了一个动态投票模型，研究了优化和最小化福利的计算复杂性，并探讨了时间公平性、在线算法和代理战略行为。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在分析一个动态投票模型，其中选民对一系列公共事务（使社会受益但对其影响者施加个人成本的项目）持有动态偏好。

Method: 该研究使用计算复杂性理论来分析动态投票模型，并探讨了功利性和平均福利的优化。此外，还研究了时间公平性、在线算法的竞争率以及代理的战略行为。

Result: 研究结果表明，虽然优化功利性福利在计算上很简单，但最小化平均福利在计算上是棘手的，即使在非常受限制的情况下也是如此。然而，研究确定了一些可以有效解决此问题（无论是精确地还是通过近似算法）的设置。

Conclusion: 该研究表明，在动态投票模型中，虽然优化功利性福利在计算上很简单，但最小化平均福利在计算上是棘手的。然而，研究确定了一些可以有效解决此问题（无论是精确地还是通过近似算法）的设置。此外，研究还探讨了强制执行时间公平性及其对社会福利的影响，并分析了在线算法的竞争率。最后，研究深入探讨了代理的战略行为，并评估了各种公平性措施的适用性。

Abstract: We study a temporal voting model where voters have dynamic preferences over a
set of public chores -- projects that benefit society, but impose individual
costs on those affected by their implementation. We investigate the
computational complexity of optimizing utilitarian and egalitarian welfare. Our
results show that while optimizing the former is computationally
straightforward, minimizing the latter is computationally intractable, even in
very restricted cases. Nevertheless, we identify several settings where this
problem can be solved efficiently, either exactly or by an approximation
algorithm. We also examine the effects of enforcing temporal fairness and its
impact on social welfare, and analyze the competitive ratio of online
algorithms. We then explore the strategic behavior of agents, providing
insights into potential malfeasance in such decision-making environments.
Finally, we discuss a range of fairness measures and their suitability for our
setting.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [231] [Characterizing Topological Phase Transition in Non-Hermitian Systems](https://arxiv.org/abs/2508.08316)
*ZhaoXiang Fang,Yongxu Fu,Guang-Can Guo,Long Xiong*

Main category: cond-mat.mes-hall

TL;DR: 提出拓扑距离（TD）用于表征非厄米系统拓扑相变，并通过算例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了以新颖的方式表征非厄米拓扑，并为理解拓扑物理学提供新视角。

Method: 提出并阐述了拓扑距离（TD）的概念，该距离通过对广义布里渊区进行迹距离积分得到，用于表征非厄米系统的拓扑跃迁。 TD 被用来衡量遍历所有可能的物质态时本征波函数之间的整体差异性，并通过观察 TD 及其偏导数发散来确认相边界。

Result: 该方法在1D非厄米Kitaev系统、周期性或开放边界条件下的非厄米哈密顿量中，甚至在更高阶拓扑系统中都显示出其普遍性和有效性。

Conclusion: 所提出的拓扑距离（TD）能够有效表征非厄米系统的拓扑相变，并通过其发散性确认相边界，该方法具有普遍性和有效性，并为理解拓扑物理学提供了新视角。

Abstract: We propose and present a concept of Topological Distance (TD), obtained from
the integration of trace distance over the generalized Brillouin zone, in order
to characterize the topological transitions of non-Hermitian systems.
Specifically, such a quantity is used to measure the overall dissimilarity
between eigen wavefunctions upon traversing all possible matter states, and
confirms the phase boundaries through observing the divergences of both TD and
its partial derivatives; we clarify its origin and also offer a theoretical
explanation. The method is developed to characterize the non-Hermitian topology
in a novel way, and shows its generality and effectiveness in 1D non-Hermitian
Kitaev systems, non-Hermitian Hamiltonians under periodic or open boundary
conditions, and even generalizable to higher-order topological systems,
providing a novel perspective to understand topological physics.

</details>


### [232] [Flux Response of Rotation-Invariant Topological Insulators](https://arxiv.org/abs/2508.08357)
*Yechen Xun,Rui-Xing Zhang*

Main category: cond-mat.mes-hall

TL;DR: Cn symmetry in 3D insulators leads to new topological classifications and flux responses, enabling the creation of Majorana modes in nanowires.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand how magnetic flux threading topological phases can reveal intrinsic properties of the ground state, specifically in 3D Z2 topological insulators. The work aims to extend this understanding to systems with even-fold rotation symmetry and explore potential applications in realizing novel topological phases.

Method: This paper theoretically analyzes the behavior of magnetic flux within 3D band insulators, particularly focusing on the influence of even-fold rotation symmetry (Cn). It identifies distinct types of helical flux-bound modes based on angular momentum and relates their coexistence to the classification of topological crystalline insulators. The study then proposes a practical application using flux-threaded nanowires for realizing specific topological superconducting states.

Result: The research demonstrates that 3D band insulators with even-fold rotation symmetry exhibit a Z2 x Z2 classification of flux response, supporting two types of helical flux-bound modes based on angular momentum. The coexistence of these modes indicates a Cn-protected topological crystalline insulator. This finding enables the proposal of flux-threaded nanowires as a platform for 1D crystalline topological superconductors with multiple Cn-protected Majorana modes.

Conclusion: The presence of even-fold rotation symmetry (Cn) in 3D band insulators leads to a refined Z2 x Z2 classification of flux response, allowing for two distinct types of helical flux-bound modes distinguished by their angular momentum. When both types coexist, the system is identified as a Cn-protected topological crystalline insulator, not a strong topological insulator. Flux-threaded nanowires of this phase are proposed as a platform for realizing 1D crystalline topological superconductors with multiple Cn-protected Majorana modes.

Abstract: Threading magnetic flux into topological phases can induce bound states that
reveal intrinsic properties of the ground state. In a 3D $\mathbb{Z}_2$
topological insulator, a quantized $\pi$ flux traps a pair of 1D helical modes,
whereas a trivial insulator hosts none. In this work, we show that in the
presence of even-fold rotation symmetry $C_n$, a 3D band insulator features a
refined $\mathbb{Z}_2 \times \mathbb{Z}_2$ classification of the flux response.
Specifically, it can host two distinct types of helical flux-bound modes that
are distinguished by their angular momentum. When both types of flux modes
coexist, the system is not a strong topological insulator, but a
$C_n$-protected topological crystalline insulator. Building on this result, we
propose that flux-threaded nanowires of such topological phase provide a
natural platform for realizing 1D crystalline topological superconductors with
multiple $C_n$-protected Majorana modes.

</details>


### [233] [Proximity superconductivity in chiral kagome antiferromagnets](https://arxiv.org/abs/2508.08372)
*Adam Yanis Chaou,Gal Lemut,Felix von Oppen,Piet W. Brouwer*

Main category: cond-mat.mes-hall

TL;DR: Mn3Ge的邻近诱导超导性为实现外来超导性提供了一条有前景的途径。


<details>
  <summary>Details</summary>
Motivation: 近期在手征kagome反铁磁体Mn3Ge上的实验提供了邻近诱导的自旋极化超导性的有力证据。

Method: 我们引入并探索了一个最小模型，该模型根据化学势和自旋倾斜表现出丰富的相图。

Result: 我们发现一个谷单重态超导相，其化学势和倾斜与实验体系一致。该相在更大的倾斜下转变为Chern绝缘体，并在其他化学势下转变为Chern数为C_BdG = ±1, ±3 的拓扑超导相。

Conclusion: Mn3Ge等手征kagome反铁磁体中的邻近诱导超导性是有望实现具有自旋极化Cooper对的外来超导性的途径，在自旋电子学领域具有潜在应用。

Abstract: Recent experiments on the chiral kagome antiferromagnet Mn$_3$Ge have
provided strong evidence of proximity-induced spin-polarized superconductivity.
We introduce and explore a minimal model which exhibits a rich phase diagram as
a function of chemical potential and spin canting. We find a valley-singlet
superconducting phase for chemical potentials and canting consistent with the
experimental system. This phase transitions into a Chern insulator at larger
canting and gives way to topological superconducting phases with Chern numbers
${\cal C}_{\rm BdG} = \pm 1, \pm 3$ at other chemical potentials. Our results
show that proximity-induced superconductivity in kagome antiferromagnets is a
promising route towards exotic superconductivity with spin-polarized Cooper
pairs, with potential applications in spintronics.

</details>


### [234] [Spin-orbit-enabled realization of arbitrary two-qubit gates on moving spins](https://arxiv.org/abs/2508.08394)
*D. Fernández-Fernández,Y. Matsumoto,L. M. K. Vandersypen,G. Platero,S. Bosco*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种利用量子比特的移动和自旋-轨道耦合（SOI）来执行高保真度双量子比特门的新方法，这可以简化量子计算的控制，并为可扩展的量子计算提供一条实际途径。


<details>
  <summary>Details</summary>
Motivation: 为了克服在具有大SOI的系统中移动自旋量子比特时可能出现的错误，并探索SOI在实现高保真度双量子比特门中的应用。

Method: 通过控制量子比特的移动速度和等待时间，并利用强的内禀或外禀自旋-轨道耦合（SOI），在半导体双量子点中实现了任意高保真度的双量子比特门。

Result: 研究表明，通过控制量子比特的移动速度和等待时间，并利用强的SOI，可以在半导体双量子点中实现任意高保真度的双量子比特门。与使用静态量子点相比，在量子比特传输过程中执行双量子比特操作可以一步实现多种双量子比特门。

Conclusion: 该研究证明了利用自旋转移来执行任意高保真度双量子比特门是可行的，并且可以大大减少量子计算架构的控制开销。

Abstract: Shuttling spin qubits in systems with large spin-orbit interaction (SOI) can
cause errors during motion. However, in this work, we demonstrate that SOI can
be harnessed to implement an arbitrary high-fidelity two-qubit (2Q) gate. We
consider two spin qubits defined in a semiconductor double quantum dot that are
smoothly moved toward each other by gate voltages. We show that an arbitrary
high-fidelity 2Q gate can be realized by controlling the shuttling speed and
waiting times, and leveraging strong intrinsic or extrinsic SOI. Crucially,
performing 2Q operations during qubit transport enables a one-step realization
of a wide range of 2Q gates, which often involve several steps when implemented
using static dots. Our findings establish a practical route toward direct
implementation of any 2Q gate via spin shuttling, significantly reducing
control overhead in scalable quantum computing architectures.

</details>


### [235] [Translation Groups for arbitrary Gauge Fields in Synthetic Crystals with real hopping amplitudes](https://arxiv.org/abs/2508.08461)
*Marco Marciani*

Main category: cond-mat.mes-hall

TL;DR: 本文介绍了Cayley-crystals，这是一类具有对称哈密顿量的合成晶格，它们可以推广磁场变换群的概念，并为在超材料等领域提供新的应用途径。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是研究一类称为Cayley-crystals的合成晶格，它们具有由通用离散群G的简单传递作用对称的哈密顿量，并探讨它们在物理系统中的潜在应用。

Method: 本文研究了Cayley-crystals的性质，重点关注了它们与磁场变换群的联系，以及由群的换位子子群决定的规范场的类型。研究还分析了其他子群在塑造晶格几何和动力学中的作用。

Result: 研究表明，Cayley-crystals能够实现磁场变换群向任意离散规范群的推广，并且其单体动力学模仿了携带多种电荷的粒子的行为。研究还确定了规范场的类型由G的换位子子群C的不可约表示决定，而Wilson-loop构型由C在G中的嵌入固定。

Conclusion: Cayley-crystals可以只用实数跃迁振幅在可扩展的几何形状中实现，这些几何形状可以适应高于3D的动力学，从而能够进行实验探索和最终在超材料、cQED和其他合成平台中利用。

Abstract: The Cayley-crystals introduced in [F. R. Lux and E. Prodan, Annales Henri
Poincar\'e 25(8), 3563 (2024)] are a class of synthetic lattices whose
Hamiltonians are symmetric under the simply transitive action of a generic
discrete group G. We show that these systems naturally realize the
generalization of the so-called magnetic translation groups to arbitrary
discrete gauge groups. The one-body dynamics mimics that of a particle carrying
multiple charges, each experiencing a distinct static gauge-field
configuration. The possible types of gauge fields are determined by the
irreducible representations of the commutator subgroup C of G, while the
Wilson-loop configurations - which need not be homogeneous - are fixed by the
embedding of C in G. We analyze in depth the role of other subgroups in shaping
both the lattice geometry and the dynamics. For engineering relevance, we
discuss a theorem that constructs all Cayley-crystals for a given abelian gauge
group, and we provide two-dimensional examples corresponding to crystals
threaded by inhomogeneous magnetic fluxes. Moreover, Cayley-crystals can be
realized with only real hopping amplitudes and in scalable geometries that can
fit higher-than-3D dynamics, enabling experimental exploration and eventual
exploitation in metamaterials, cQED, and other synthetic platforms.

</details>


### [236] [Magnetic field-induced chiral soliton lattice in the bulk magnetoelectric helimagnet Cu$_2$OSeO$_3$](https://arxiv.org/abs/2508.08817)
*Victor Ukleev,Arnaud Magrez,Jonathan S. White*

Main category: cond-mat.mes-hall

TL;DR: 在Cu$_2$OSeO$_3$中观察到了手征孤子晶格，这是一种非线性磁结构，具有在电场控制的自旋电子器件中应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 在单轴手征磁体中通常发现的非线性磁结构——手征孤子晶格（CSLs）——的性质研究。

Method: 使用小角中子散射（SANS）实验。

Result: 在Cu$_2$OSeO$_3$中观察到了由立方各向异性与磁场竞争驱动的CSLs，并观察到SANS信号中的高次谐波证实了其非线性特征。

Conclusion: Cu$_2$OSeO$_3$中存在手征孤子晶格，这表明了其复杂的磁相互作用，并为在电场控制的自旋电子器件中应用手征孤子晶格提供了可能。

Abstract: Chiral soliton lattices (CSLs) are anharmonic magnetic structures typically
found in uniaxial chiral magnets. In this study, we report the observation of
CSL in bulk Cu$_2$OSeO$_3$, a chiral insulator known for its magnetoelectric
properties. Using small-angle neutron scattering (SANS) experiments, we
demonstrate the formation of CSLs in Cu$_2$OSeO$_3$ at low temperatures, driven
by the competition between cubic anisotropy and magnetic field. Our
observations of higher harmonics in the SANS signal clearly indicate the
anharmonic nature of the spiral. This finding underscores the complex interplay
between magnetic interactions in Cu$_2$OSeO$_3$, offering insights for
potential applications of CSLs in electric-field controlled spintronic devices.

</details>


### [237] [Epitaxial graphene integrated with a monolayer magnet](https://arxiv.org/abs/2508.08901)
*Ivan S. Sokolov,Dmitry V. Averyanov,Oleg E. Parfenov,Alexey N. Mihalyuk,Alexander N. Taldenkov,Oleg A. Kondratev,Ilya A. Eliseyev,Sergey P. Lebedev,Alexander A. Lebedev,Andrey M. Tokmachev,Vyacheslav G. Storchak*

Main category: cond-mat.mes-hall

TL;DR: 通过铕插层将磁性印刷到外延石墨烯中，实现了二维磁性，并展示了在自旋电子学方面的应用前景。


<details>
  <summary>Details</summary>
Motivation: 为了将磁性印刷到石墨烯中，以用于自旋电子学应用，通过将石墨烯与二维磁体进行邻近耦合是一种有前景的方法。然而，外延石墨烯在获得磁性方面仍然存在问题。

Method: 通过铕（Eu）插层形成的磁性原子规则晶格与外延石墨烯的异质结构。

Result: 该材料具有面内二维磁性，居里温度可以通过低磁场控制。观察到的负磁阻和霍尔效应表明石墨烯载流子具有自旋极化。在顺磁性相中，石墨烯的磁阻表现出临界指数行为。该插层并未损害石墨烯的电子结构，量子振荡揭示了低质量载流子。将结果与基于锶（Sr）插层的类似材料进行比较。

Conclusion: 该研究扩展了二维磁体的家族，并为基于石墨烯的自旋电子学建立了一个有前景的材料。

Abstract: Imprinting magnetism into graphene makes an important step to its
applications in spintronics. An actively explored approach is proximity
coupling of graphene to a 2D magnet. In these endeavors, the use of epitaxial
graphene may bring significant advantages due to its superiority over the
exfoliated counterpart and natural integration with the substrate but the
problem of attaining magnetism persists. Here, we report synthesis and analysis
of a heterostructure coupling epitaxial graphene with a regular lattice of
magnetic atoms formed by Eu intercalation. The magnetization measurements
reveal easy-plane 2D magnetism in the material, with the transition temperature
controlled by low magnetic fields. The emerging negative magnetoresistance and
anomalous Hall effect point at spin polarization of the carriers in graphene.
In the paramagnetic phase, the magnetoresistance in graphene exhibits critical
exponential behavior of the induced magnetic state. The intercalation does not
compromise the parental electronic structure - quantum oscillations in the
resistivity manifest low-mass carriers in graphene. The results are set against
those for an isostructural material based on intercalated nonmagnetic Sr.
Overall, the study expands the family of 2D magnets and establishes a
prospective material for graphene-based spintronics.

</details>


### [238] [Probing imbalanced Weyl nodes in two-dimensional anisotropic Weyl semimetal via optical conductivity](https://arxiv.org/abs/2508.09011)
*Suheel Ahmad Malik,M. A. H. Ahshan,SK Firoz Islam*

Main category: cond-mat.mes-hall

TL;DR: 研究了具有一对韦尔节点的二维各向异性半金属的电子能带结构和光学性质。


<details>
  <summary>Details</summary>
Motivation: 研究倾斜半狄拉克材料中的韦尔节点，探测由倾斜引起的节点之间的能量不平衡。

Method: 通过理论研究了具有一对韦尔节点的倾斜半狄拉克型能谱描述的二维各向异性半金属的电子能带结构和光学性质。

Result: 倾斜沿二次方向可以引起节点之间的能量不平衡。各向异性带间光学电导率可以通过在近零频率下激发两个不同化学势下的电子来探测节点的不平衡。半经典玻尔兹曼输运理论揭示了倾斜可以将半狄拉克材料从半金属相转变为金属相。节点处的拓扑间隙可以通过光学激发来探测。

Conclusion: 倾斜各向异性半狄拉克材料中的韦尔节点不平衡可以被光学激发探测，并且即使在节点处打开拓扑间隙，由于体仍然无间隙，也不能将SD材料转换为Chern拓扑相。

Abstract: We present a theoretical investigation of the electronic band structure and
optical properties of a two-dimensional anisotropic semimetal that is described
by a tilted semi-Dirac type spectrum with a pair of Weyl nodes. We observe that
a tilt along the quadratic direction can give rise to an energy imbalance
between these nodes, contrary to the effect of tilt along the linear direction.
We investigate the optical response of such system subjected to an external AC
bias, aiming to probe the energy imbalance between the nodes. We show that the
anisotropic interband optical conductivity gives a clear signature of
imbalanced nodes by exciting electrons at two different chemical potentials at
near zero frequency indicating, and the difference between these two chemical
potentials is the direct measure of the energy imbalance. Subsequently, we also
investigate the intraband DC conductivity by using the semi-classical Boltzmann
transport theory which reveals that contrary to the tilted Dirac materials,
tilt can convert semi-Dirac material from semimetallic phase to metallic phase.
Furthermore, we periodically drive the system by external time-periodic
perturbation to open up topological gap at those nodes. We also show that the
presence of imbalanced Weyl nodes would prevent the SD material from switching
to Chern topological phase even after opening topological gaps at the nodes as
the bulk remains gapless. Such state cannot be probed by the usual anomalous
Hall response as it will be overshadowed by the bulk contribution. Here, we
show that those gaps at different chemical potential can be probed by optical
excitation.

</details>


### [239] [Electrostatic gate-controlled quantum interference in a high-mobility two-dimensional electron gas at the (La$_{0.3}$Sr$_{0.7}$)(Al$_{0.65}$Ta$_{0.35}$)O$_3$/SrTiO$_3$ interface](https://arxiv.org/abs/2508.09013)
*Km Rubi,Kun Han,Huang Zhen,Michel Goiran,Duncan K. Maude,Walter Escoffier,A. Ariando*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We report quantum oscillations in magnetoresistance that are periodic in
magnetic field ($B$), observed at the interface between
(La$_{0.3}$Sr$_{0.7}$)(Al$_{0.65}$Ta$_{0.35}$)O$_3$ and SrTiO$_3$. Unlike
Shubnikov-de Haas oscillations, which appear at magnetic fields $ > 7$ T and
diminish quickly as the temperature rises, these $B$-periodic oscillations
emerge at low fields and persist up to 10 K. Their amplitude decays
exponentially with both temperature and field, specifying dephasing of quantum
interference. Increasing the carrier density through electrostatic gating
results in a systematic reduction in both the amplitude and frequency of the
oscillations, with complete suppression beyond a certain gate voltage. We
attribute these oscillations to the Altshuler-Aronov-Spivak effect, likely
arising from naturally formed closed-loop paths due to the interconnected
quasi-one-dimensional conduction channels along SrTiO$_3$ domain walls. The
relatively long phase coherence length ($\sim$ 1.8 $\mu$m at 0.1 K), estimated
from the oscillation amplitude, highlights the potential of complex oxide
interfaces as a promising platform for exploring quantum interference effects
and advancing device concepts in quantum technologies, such as mesoscopic
interferometers and quantum sensors.

</details>


### [240] [Automated Charge Transition Detection in Quantum Dot Charge Stability Diagrams](https://arxiv.org/abs/2508.09024)
*Fabian Hader,Fabian Fuchs,Sarah Fleitmann,Karin Havemann,Benedikt Scherer,Jan Vogelbruch,Lotte Geck,Stefan van Waasen*

Main category: cond-mat.mes-hall

TL;DR: This paper presents and compares methods for automatically detecting edges in charge stability diagrams to tune semiconductor quantum dots for qubits, testing them on simulated and real-world qubit data.


<details>
  <summary>Details</summary>
Motivation: Automating qubit tuning requires reliable automatic recognition of charge transition edges in charge stability diagrams, as these edges indicate the number of electrons needed for qubit functionality.

Method: The paper investigates edge detection methods, trains them with simulated data from the SimCATS framework, and compares their performance with a focus on future hardware implementation. Optimized approaches are also evaluated on experimental data.

Result: The research performs a quantitative comparison of different edge detection methods and investigates the quality of optimized approaches on experimental data from GaAs and SiGe qubit samples.

Conclusion: The study quantitatively compares edge detection methods for automated qubit tuning, validating them on simulated and experimental data from GaAs and SiGe samples.

Abstract: Gate-defined semiconductor quantum dots require an appropriate number of
electrons to function as qubits. The number of electrons is usually tuned by
analyzing charge stability diagrams, in which charge transitions manifest as
edges. Therefore, to fully automate qubit tuning, it is necessary to recognize
these edges automatically and reliably. This paper investigates possible
detection methods, describes their training with simulated data from the
SimCATS framework, and performs a quantitative comparison with a future
hardware implementation in mind. Furthermore, we investigated the quality of
the optimized approaches on experimentally measured data from a GaAs and a SiGe
qubit sample.

</details>


### [241] [Interlayer exciton condensates between second Landau level orbitals in double bilayer graphene](https://arxiv.org/abs/2508.09098)
*Zeyu Hao,A. M. Zimmerman,Kenji Watanabe,Takashi Taniguchi,Philip Kim*

Main category: cond-mat.mes-hall

TL;DR: 双层石墨烯在量子霍尔区域表现出层间激子凝聚，无论是在最低还是第二Landau能级。在第二能级，激子凝聚的形成依赖于石墨烯层内的波函数极化以增强层间相互作用。


<details>
  <summary>Details</summary>
Motivation: 本研究的目的是在量子霍尔区域中，探索两个伯纳尔堆叠双层石墨烯（BLG）异质结构中的层间相互作用和激子凝聚现象，特别是比较N=0和N=1 Landau能级下的行为。

Method: 本研究采用了库仑拖曳测量技术，并利用顶底栅和层间偏压来独立调谐两个BLG层进入最低（N=0）或第二（N=1）Landau能级（LL）轨道，并探测它们的层间QH态。

Result: 研究观察到在N=0轨道下，存在层间激子凝聚和分数QH态。在N=1轨道下，也观察到了层间激子凝聚，并且这种现象只在特定波函数极化条件下出现，表明层间库仑相互作用对N=1 EC态的形成至关重要。

Conclusion: 本研究在量子霍尔（QH）区域中，对由2.5 nm的六方氮化硼（hBN）间隔物隔开的两个伯纳尔堆叠双层石墨烯（BLG）片组成的异质结构进行了库仑拖曳测量。结果显示，当两个BLG层都占据N=0轨道时，我们观察到了整数总填充和层间分数QH态下的层间激子凝聚（ECs），这与双层单层石墨烯中的结果一致。与以往研究不同的是，当两个BLG层都占据N=1轨道时，我们也观察到了量子化的拖曳信号，表明在第二Landau能级（LL）之间形成了层间激子凝聚。通过调节层自由度，我们发现这种N=1 EC态仅在每个BLG中的N=1波函数极化到hBN界面以最大化层间库仑相互作用时出现。

Abstract: We present Coulomb-drag measurements on a heterostructure comprising two
Bernal-stacked bilayer graphene (BLG) sheets separated by a 2.5 nm hexagonal
boron nitride (hBN) spacer in the quantum Hall (QH) regime. Using top and
bottom gate control, together with an interlayer bias, we independently tune
the two BLG layers into either the lowest (N = 0) or second (N = 1) Landau
level (LL) orbital and probe their interlayer QH states. When both layers
occupy the N = 0 orbital, we observe both interlayer exciton condensates (ECs)
at integer total filling and interlayer fractional QH states, echoing the
results in double monolayer graphene. In contrast to previous studies, however,
when both BLG layers occupy the N = 1 orbital, we also observe quantized drag
signals, signifying an interlayer exciton condensate formed between the second
LLs. By tuning the layer degree of freedom, we find that this N = 1 EC state
arises only when the N = 1 wavefunction in each BLG is polarized toward the hBN
interface to maximize the interlayer Coulomb interaction.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [242] [Spatiotemporally Consistent Indoor Lighting Estimation with Diffusion Priors](https://arxiv.org/abs/2508.08384)
*Mutian Tong,Rundi Wu,Changxi Zheng*

Main category: cs.GR

TL;DR: 一种新颖的室内光照估计方法，能处理时空变化的光照，并实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 室内光照估计（尤其是在光照条件时空变化的场景下）是一个具有挑战性的问题。

Method: 利用2D扩散先验优化MLP表示的光场，并通过对预训练图像扩散模型进行微调，联合修复多个球形反射探针图来预测多个位置的光照，以实现零样本泛化。

Result: 提出的方法能够从输入视频中估计出描述时空变化光照的连续光场，并在室内光照估计任务中展现出优于基线方法的性能。

Conclusion: 该方法在室内光照估计方面表现优于现有方法，尤其在处理视频中的时空一致光照估计方面取得了显著的成果。

Abstract: Indoor lighting estimation from a single image or video remains a challenge
due to its highly ill-posed nature, especially when the lighting condition of
the scene varies spatially and temporally. We propose a method that estimates
from an input video a continuous light field describing the spatiotemporally
varying lighting of the scene. We leverage 2D diffusion priors for optimizing
such light field represented as a MLP. To enable zero-shot generalization to
in-the-wild scenes, we fine-tune a pre-trained image diffusion model to predict
lighting at multiple locations by jointly inpainting multiple chrome balls as
light probes. We evaluate our method on indoor lighting estimation from a
single image or video and show superior performance over compared baselines.
Most importantly, we highlight results on spatiotemporally consistent lighting
estimation from in-the-wild videos, which is rarely demonstrated in previous
works.

</details>


### [243] [Improving Facial Rig Semantics for Tracking and Retargeting](https://arxiv.org/abs/2508.08429)
*Dalton Omens,Allise Thurman,Jihun Yu,Ronald Fedkiw*

Main category: cs.GR

TL;DR: 本文提出了一种新的面部表演重定向方法，使用统一的骨骼绑定框架和 Simon-Says 表情校准，并通过基于隐式微分的微调来优化动画控制，以实现更高效的重定向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在将面部表演重定向到不同人物或游戏/VR 中的虚拟角色时，不同骨骼框架之间语义识别和重定向的难题。

Method: 本文提出了一种利用相同的面部模型（3DMM、FLAME、MetaHuman 等）进行源和目标脸部绑定的方法，并通过体积变形和 Simon-Says 表情集来拟合和校准面部模型。为了解决跟踪性能不佳的问题，我们还提出了一种基于隐式微分的微调方法，以优化跟踪器使用的模型，从而生成更具语义意义的动画控制。

Result: 通过使用相同的骨骼绑定框架和 Simon-Says 表情集进行校准，我们能够实现可接受的面部几何重建。然而，即使经过良好校准，跟踪性能仍然可能导致不理想的控制。通过引入基于隐式微分的微调方法，我们能够优化跟踪器使用的骨骼绑定，从而生成更具语义意义的动画控制，从而实现高效的重定向。

Conclusion: 虽然我们提出了一个有效的面部重定向框架，但仍有改进空间。未来的工作可以探索更少或无需用户交互的校准方法，并进一步研究在不同驱动和目标之间实现更鲁棒和精确的动画控制。

Abstract: In this paper, we consider retargeting a tracked facial performance to either
another person or to a virtual character in a game or virtual reality (VR)
environment. We remove the difficulties associated with identifying and
retargeting the semantics of one rig framework to another by utilizing the same
framework (3DMM, FLAME, MetaHuman, etc.) for both subjects. Although this does
not constrain the choice of framework when retargeting from one person to
another, it does force the tracker to use the game/VR character rig when
retargeting to a game/VR character. We utilize volumetric morphing in order to
fit facial rigs to both performers and targets; in addition, a carefully chosen
set of Simon-Says expressions is used to calibrate each rig to the motion
signatures of the relevant performer or target. Although a uniform set of
Simon-Says expressions can likely be used for all person to person retargeting,
we argue that person to game/VR character retargeting benefits from Simon-Says
expressions that capture the distinct motion signature of the game/VR character
rig. The Simon-Says calibrated rigs tend to produce the desired expressions
when exercising animation controls (as expected). Unfortunately, these
well-calibrated rigs still lead to undesirable controls when tracking a
performance (a well-behaved function can have an arbitrarily ill-conditioned
inverse), even though they typically produce acceptable geometry
reconstructions. Thus, we propose a fine-tuning approach that modifies the rig
used by the tracker in order to promote the output of more semantically
meaningful animation controls, facilitating high efficacy retargeting. In order
to better address real-world scenarios, the fine-tuning relies on implicit
differentiation so that the tracker can be treated as a (potentially
non-differentiable) black box.

</details>


### [244] [Hybrid Long and Short Range Flows for Point Cloud Filtering](https://arxiv.org/abs/2508.08542)
*Dasith de Silva Edirimuni,Xuequan Lu,Ajmal Saeed Mian,Lei Wei,Gang Li,Scott Schaefer,Ying He*

Main category: cs.GR

TL;DR: HybridPF filters noisy point clouds by combining short-range and long-range information using parallel encoder-decoder modules, achieving better results and faster processing than existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing point cloud filtering methods struggle with point clustering and retaining noise. This paper proposes HybridPF to address these issues by integrating both short-range and long-range information for more effective noise removal.

Method: HybridPF utilizes two parallel modules (ShortModule and LongModule), each with an Encoder-Decoder structure. ShortModule handles short-range scores ($
abla_{x}	ext{log } p(x_t)$) for fine-tuning point positions, while LongModule captures long-range velocity flows to guide the short-range trajectories. A joint loss function trains both modules end-to-end. A dynamic graph convolutional decoder is proposed to address limitations in existing decoder architectures.

Result: Experiments show that HybridPF, guided by long-range features, produces filtered point clouds with improved point distributions and convergence towards the clean surface. It achieves state-of-the-art performance and faster inference.

Conclusion: HybridPF achieves state-of-the-art results in point cloud filtering, offering faster inference speeds compared to existing methods.

Abstract: Point cloud capture processes are error-prone and introduce noisy artifacts
that necessitate filtering/denoising. Recent filtering methods often suffer
from point clustering or noise retaining issues. In this paper, we propose
Hybrid Point Cloud Filtering ($\textbf{HybridPF}$) that considers both
short-range and long-range filtering trajectories when removing noise. It is
well established that short range scores, given by $\nabla_{x}\log p(x_t)$, may
provide the necessary displacements to move noisy points to the underlying
clean surface. By contrast, long range velocity flows approximate constant
displacements directed from a high noise variant patch $x_0$ towards the
corresponding clean surface $x_1$. Here, noisy patches $x_t$ are viewed as
intermediate states between the high noise variant and the clean patches. Our
intuition is that long range information from velocity flow models can guide
the short range scores to align more closely with the clean points. In turn,
score models generally provide a quicker convergence to the clean surface.
Specifically, we devise two parallel modules, the ShortModule and LongModule,
each consisting of an Encoder-Decoder pair to respectively account for
short-range scores and long-range flows. We find that short-range scores,
guided by long-range features, yield filtered point clouds with good point
distributions and convergence near the clean surface. We design a joint loss
function to simultaneously train the ShortModule and LongModule, in an
end-to-end manner. Finally, we identify a key weakness in current displacement
based methods, limitations on the decoder architecture, and propose a dynamic
graph convolutional decoder to improve the inference process. Comprehensive
experiments demonstrate that our HybridPF achieves state-of-the-art results
while enabling faster inference speed.

</details>


### [245] [Revisiting the City Tower Project: Geometric Principles and Structural Morphology in the Works of Louis I. Kahn and Anne Tyng](https://arxiv.org/abs/2508.08561)
*Aysan Mokhtarimousavi,Michael Kleiss,Mostafa Alani,Sida Dai*

Main category: cs.GR

TL;DR: 路易斯·康的城塔项目通过其独特的四面体和八面体空间框架结构，预示了未来的空间框架结构设计，并为模块化和适应性建筑形式提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在分析城塔结构的几何形态，并探索如何利用其开发模块化和适应性建筑形式。

Method: 本研究基于分析性形状语法，首先重建了城塔的原始结构，然后基于其形态生成了新的结构配置。

Result: 研究结果揭示了四面体和八面体作为基本几何形状在创建可扩展和模块化设计方面的潜力。

Conclusion: 该研究分析了路易斯·康的城塔项目，展示了其在空间框架结构设计上的前瞻性，并提出了基于其几何框架的模块化和适应性建筑形式的潜在应用。

Abstract: This paper presents a study of computation and morphology of Louis Kahn City
Tower project. The City Tower is an unbuilt design by Louis I. Kahn and Anne
Tyng that integrates form and structure using 3D space triangular geometries.
Although never built, the City Tower geometrical framework anticipated later
developments in design of space-frame structures. Initially envisioned in the
1950s, the City Tower project is a skyscraper structure based on a tetrahedral
and octahedral space frame called Octet-Truss. The aim of this study is to
analyze the geometry of the City Tower structure and how it can be used to
develop modular and adaptable architectural forms. The study is based on an
analytical shape grammar that is used to recreate the original structure, and
later to generate new structural configurations based on the City Tower's
morphology. This study also investigates the potential applications of these
findings in architecture and reveals the possibilities of using tetrahedrons
and octahedrons as fundamental geometries for creating scalable and modular
designs and presents initial findings.

</details>


### [246] [Bio-Generative Design Morphology with Radiolaria: An application of a Nature-Based Generative Shape Grammar for Geometrical Design of Space Frames](https://arxiv.org/abs/2508.08572)
*Michael Kleiss,Seyedehaysan Mokhtarimousavi,Sida Dai,Mostafa Alani*

Main category: cs.GR

TL;DR: 本研究使用放射虫几何结构作为基础，结合四面体和八面体，通过形状语法生成了用于结构设计的空间几何和三维空间结构框架。


<details>
  <summary>Details</summary>
Motivation: 放射虫以其复杂的结构特征和几何模式为建筑设计提供了灵感来源，本研究旨在利用其几何特性进行结构设计。

Method: 本研究首先对放射虫的几何结构进行分析，并将其解剖成简化的形态来源——四面体结构。然后，将四面体与八面体结合，生成三维空间结构框架。

Result: 研究生成了三维空间结构框架的集合，并探讨了其在空间框架结构中的潜在应用。

Conclusion: 该研究展示了如何使用放射虫的几何结构作为基础，通过形状语法生成用于结构设计的空间几何。

Abstract: This paper presents a study on using Radiolaria as a basis for generation of
space-based geometry for structural design with shape grammars. Radiolaria has
been a source of inspiration for architectural design with its intricate
structural features and geometric patterns (Lim, 2012). We use the basis of the
Radiolaria geometry to create a generative shape grammar as a computational
system; then use the shape grammar to create spatial configurations for
potential applications in design of 3D space structural frames. This study
begins with the geometric analysis of Radiolaria and the dissection of its
structure and geometry into a simplified morphological source, in this case a
tetrahedral structure. Tetrahedrons are used in combination with octahedrons to
generate spatial configurations to generate 3D spatial structural frames. The
paper presents the Radiolaria spatial analysis, the shape grammar, the
collection of generated designs, and possible applications in space frame
structures.

</details>


### [247] [Exploring Palette based Color Guidance in Diffusion Models](https://arxiv.org/abs/2508.08754)
*Qianru Qiu,Jiafeng Mao,Xueting Wang*

Main category: cs.GR

TL;DR: 本研究提出了一种新的文本到图像生成方法，通过引入颜色调色板作为额外的指导，增强了对图像颜色方案的控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型难以对整个图像的颜色方案进行全面控制，尤其是在背景元素和提示中未明确提及的物体方面。本研究旨在通过引入颜色调色板作为额外的指导机制来增强颜色方案的控制能力。

Method: 提出了一种将颜色调色板作为独立于文本提示的指导机制，并将其整合到基于扩散的图像着色框架中的新方法。构建了专门的调色板-文本-图像数据集，并进行了广泛的定量和定性分析。

Result: 实验结果表明，结合颜色调色板的指导能够显著提高模型生成具有期望颜色方案的图像的能力。

Conclusion: 与现有模型相比，本研究提出的结合颜色调色板的文本到图像生成方法在生成具有期望颜色方案的图像方面具有明显优势，能够实现更可控、更精细的着色过程。

Abstract: With the advent of diffusion models, Text-to-Image (T2I) generation has seen
substantial advancements. Current T2I models allow users to specify object
colors using linguistic color names, and some methods aim to personalize
color-object association through prompt learning. However, existing models
struggle to provide comprehensive control over the color schemes of an entire
image, especially for background elements and less prominent objects not
explicitly mentioned in prompts. This paper proposes a novel approach to
enhance color scheme control by integrating color palettes as a separate
guidance mechanism alongside prompt instructions. We investigate the
effectiveness of palette guidance by exploring various palette representation
methods within a diffusion-based image colorization framework. To facilitate
this exploration, we construct specialized palette-text-image datasets and
conduct extensive quantitative and qualitative analyses. Our results
demonstrate that incorporating palette guidance significantly improves the
model's ability to generate images with desired color schemes, enabling a more
controlled and refined colorization process.

</details>


### [248] [Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination](https://arxiv.org/abs/2508.08826)
*Meng Gai,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出了一种基于学习的屏幕空间扩散间接光照估计器，结合直接光照即可生成全局光照HDR结果。该方法利用新颖的网络架构（带注意力机制和单色设计）来解决长距离间接光照捕捉问题，并在各种复杂光照和场景下进行了广泛评估，结果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了在虚拟环境中为用户提供逼真的体验，实时全局光照渲染至关重要。现有技术在利用神经网络捕捉长距离间接光照方面存在挑战。

Method: 提出了一种新颖的网络架构来预测间接光照，该网络配备了经过修改的注意机制，并通过空间几何特征聚合全局信息，同时采用了单独编码每个颜色通道的单色设计。

Result: 与以往基于学习的技术相比，该方法在处理复杂光照、捕捉远处间接光照和模拟颜色溢出方面表现出优越性，并且能够泛化到新的场景。

Conclusion: 该方法在处理复杂光照（如变色光照和环境光照）方面表现出色，能够成功捕捉远处间接光照并模拟纹理表面之间的交互反射（即颜色溢出效应），还能有效处理训练数据集中未出现的新场景。

Abstract: Real-time rendering with global illumination is crucial to afford the user
realistic experience in virtual environments. We present a learning-based
estimator to predict diffuse indirect illumination in screen space, which then
is combined with direct illumination to synthesize globally-illuminated high
dynamic range (HDR) results. Our approach tackles the challenges of capturing
long-range/long-distance indirect illumination when employing neural networks
and is generalized to handle complex lighting and scenarios.
  From the neural network thinking of the solver to the rendering equation, we
present a novel network architecture to predict indirect illumination. Our
network is equipped with a modified attention mechanism that aggregates global
information guided by spacial geometry features, as well as a monochromatic
design that encodes each color channel individually.
  We conducted extensive evaluations, and the experimental results demonstrate
our superiority over previous learning-based techniques. Our approach excels at
handling complex lighting such as varying-colored lighting and environment
lighting. It can successfully capture distant indirect illumination and
simulates the interreflections between textured surfaces well (i.e., color
bleeding effects); it can also effectively handle new scenes that are not
present in the training dataset.

</details>


### [249] [DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI](https://arxiv.org/abs/2508.08831)
*Bo-Hsun Chen,Nevindu M. Batagoda,Dan Negrut*

Main category: cs.GR

TL;DR: DiffPhysCam 是一个可微分相机模拟器，通过控制相机设置、模拟光学效果和支持校准来解决现有虚拟相机的局限性，从而增强机器人感知能力并实现从模拟到真实世界的迁移。


<details>
  <summary>Details</summary>
Motivation: 为了在视觉感知流水线中实现基于梯度的优化，并解决现有虚拟相机在内在设置控制、光学伪影捕捉和可校准参数方面的局限性，以实现从模拟到真实世界的迁移。

Method: DiffPhysCam 是一个可微分相机模拟器，通过多阶段流程提供对相机设置的细粒度控制，模拟散焦模糊等关键光学效应，并支持使用真实世界数据进行校准。

Result: DiffPhysCam 能够进行前向渲染以合成图像，以及进行逆向渲染以进行 3D 场景重建（包括网格和材质纹理优化），并能在合成图像任务中提高机器人感知性能。

Conclusion: DiffPhysCam 增强了机器人感知性能，并通过逆向渲染创建了真实场景的数字孪生，用于模拟和自动驾驶车辆导航。

Abstract: We introduce DiffPhysCam, a differentiable camera simulator designed to
support robotics and embodied AI applications by enabling gradient-based
optimization in visual perception pipelines. Generating synthetic images that
closely mimic those from real cameras is essential for training visual models
and enabling end-to-end visuomotor learning. Moreover, differentiable rendering
allows inverse reconstruction of real-world scenes as digital twins,
facilitating simulation-based robotics training. However, existing virtual
cameras offer limited control over intrinsic settings, poorly capture optical
artifacts, and lack tunable calibration parameters -- hindering sim-to-real
transfer. DiffPhysCam addresses these limitations through a multi-stage
pipeline that provides fine-grained control over camera settings, models key
optical effects such as defocus blur, and supports calibration with real-world
data. It enables both forward rendering for image synthesis and inverse
rendering for 3D scene reconstruction, including mesh and material texture
optimization. We show that DiffPhysCam enhances robotic perception performance
in synthetic image tasks. As an illustrative example, we create a digital twin
of a real-world scene using inverse rendering, simulate it in a multi-physics
environment, and demonstrate navigation of an autonomous ground vehicle using
images generated by DiffPhysCam.

</details>


### [250] [How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation](https://arxiv.org/abs/2508.08930)
*Juyeong Hwang,Seong-Eun Hon,JaeYoung Seon,Hyeongyeop Kang*

Main category: cs.GR

TL;DR: SCORE框架通过结合认知科学和AI（VLM和LLM），解决了虚拟化身头部旋转的真实感问题，实现了更自然的头部运动。


<details>
  <summary>Details</summary>
Motivation: 为了实现可信的虚拟化身，需要对自然头部旋转进行建模，但现有的算法往往只关注视觉显著刺激，忽略了驱动头部旋转的认知动机，导致虚拟化身在关注显眼物体时忽略障碍物或与任务相关的线索，降低了真实感。

Method: SCORE是一个符号化认知推理框架，它将人类头部运动的五个驱动因素（兴趣、信息寻求、安全、社会图式和习惯）编码为符号谓词。它利用视觉语言模型（VLM）感知场景，并利用大型语言模型（LLM）规划头部姿态。该框架采用混合工作流：VLM-LLM推理离线执行，然后由轻量级的FastVLM在线验证，以抑制幻觉并保持对场景动态的响应能力。

Result: SCORE框架成功实现了能够预测“看什么”以及“为什么看”的虚拟化身，能够泛化到未见的场景和多主体人群，并保持行为的可信度。

Conclusion: 该框架生成了上下文感知的头部运动，能够泛化到未见的场景和多主体人群，同时保持行为的可信度。

Abstract: Natural head rotation is critical for believable embodied virtual agents, yet
this micro-level behavior remains largely underexplored. While head-rotation
prediction algorithms could, in principle, reproduce this behavior, they
typically focus on visually salient stimuli and overlook the cognitive motives
that guide head rotation. This yields agents that look at conspicuous objects
while overlooking obstacles or task-relevant cues, diminishing realism in a
virtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning
framework for Embodied Head Rotation, a data-agnostic framework that produces
context-aware head movements without task-specific training or hand-tuned
heuristics. A controlled VR study (N=20) identifies five motivational drivers
of human head movements: Interest, Information Seeking, Safety, Social Schema,
and Habit. SCORE encodes these drivers as symbolic predicates, perceives the
scene with a Vision-Language Model (VLM), and plans head poses with a Large
Language Model (LLM). The framework employs a hybrid workflow: the VLM-LLM
reasoning is executed offline, after which a lightweight FastVLM performs
online validation to suppress hallucinations while maintaining responsiveness
to scene dynamics. The result is an agent that predicts not only where to look
but also why, generalizing to unseen scenes and multi-agent crowds while
retaining behavioral plausibility.

</details>


### [251] [VertexRegen: Mesh Generation with Continuous Level of Detail](https://arxiv.org/abs/2508.09062)
*Xiang Zhang,Yawar Siddiqui,Armen Avetisyan,Chris Xie,Jakob Engel,Henry Howard-Jenkins*

Main category: cs.GR

TL;DR: VertexRegen 是一种新的网格生成框架，可以生成不同细节级别的网格。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个新的网格生成框架，该框架可以在连续的细节级别进行生成。

Method: VertexRegen 通过学习生成模型来逆转边坍塌，即顶点分裂，从而将该过程重新表述为渐进网格。

Result: 与最先进的方法相比，VertexRegen 生成的网格质量相当，并具有随时生成的能力。

Conclusion: VertexRegen 可以在任何时候生成，并可以在任何步骤停止以产生具有不同细节级别的有效网格，从而提供灵活性。

Abstract: We introduce VertexRegen, a novel mesh generation framework that enables
generation at a continuous level of detail. Existing autoregressive methods
generate meshes in a partial-to-complete manner and thus intermediate steps of
generation represent incomplete structures. VertexRegen takes inspiration from
progressive meshes and reformulates the process as the reversal of edge
collapse, i.e. vertex split, learned through a generative model. Experimental
results demonstrate that VertexRegen produces meshes of comparable quality to
state-of-the-art methods while uniquely offering anytime generation with the
flexibility to halt at any step to yield valid meshes with varying levels of
detail.

</details>


### [252] [Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer](https://arxiv.org/abs/2508.09131)
*Zixin Yin,Xili Dai,Ling-Hao Chen,Deyu Zhou,Jianan Wang,Duomin Wang,Gang Yu,Lionel M. Ni,Heung-Yeung Shum*

Main category: cs.GR

TL;DR: ColorCtrl是一种新的无训练颜色编辑方法，利用MM-DiT的注意力机制，通过分离结构和颜色来实现精确、一致且可控的颜色编辑，优于现有方法和商业模型。


<details>
  <summary>Details</summary>
Motivation: 文本引导的图像和视频颜色编辑是一个基本但仍未解决的问题，它需要对颜色属性（包括反照率、光源颜色和环境光）进行细粒度操作，同时保持几何、材料属性和光-物质相互作用的物理一致性。现有的无训练方法虽然具有广泛的适用性，但在精确颜色控制方面存在不足，并常常在编辑和未编辑区域引入视觉不一致。

Method: ColorCtrl利用现代多模态扩散变换器（MM-DiT）的注意力机制，通过目标性地操控注意力图和值令牌来分离结构和颜色，从而实现精确一致的颜色编辑，并能对属性强度进行单词级控制。

Result: ColorCtrl能够实现精确一致的颜色编辑，并能对属性强度进行单词级控制。它仅修改提示指定的预期区域，而保持其他区域不变。在SD3和FLUX.1-dev上的实验表明，ColorCtrl在编辑质量和一致性方面均优于现有方法，并达到了最先进的性能。与商业模型相比，ColorCtrl在一致性方面表现更优。在视频模型和指令编辑模型上也展现了其优势和通用性。

Conclusion: ColorCtrl在SD3和FLUX.1-dev上进行了广泛的实验，结果表明它在编辑质量和一致性方面均优于现有的无训练方法，并达到了最先进的性能。此外，它在保持时间连贯性和编辑稳定性方面比CogVideoX等视频模型更具优势，并且能够泛化到Step1X-Edit和FLUX.1 Kontext dev等基于指令编辑的扩散模型。

Abstract: Text-guided color editing in images and videos is a fundamental yet unsolved
problem, requiring fine-grained manipulation of color attributes, including
albedo, light source color, and ambient lighting, while preserving physical
consistency in geometry, material properties, and light-matter interactions.
Existing training-free methods offer broad applicability across editing tasks
but struggle with precise color control and often introduce visual
inconsistency in both edited and non-edited regions. In this work, we present
ColorCtrl, a training-free color editing method that leverages the attention
mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By
disentangling structure and color through targeted manipulation of attention
maps and value tokens, our method enables accurate and consistent color
editing, along with word-level control of attribute intensity. Our method
modifies only the intended regions specified by the prompt, leaving unrelated
areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate
that ColorCtrl outperforms existing training-free approaches and achieves
state-of-the-art performances in both edit quality and consistency.
Furthermore, our method surpasses strong commercial models such as FLUX.1
Kontext Max and GPT-4o Image Generation in terms of consistency. When extended
to video models like CogVideoX, our approach exhibits greater advantages,
particularly in maintaining temporal coherence and editing stability. Finally,
our method also generalizes to instruction-based editing diffusion models such
as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [253] [Millisecond-scale Volatile Memory in HZO Ferroelectric Capacitors for Bio-inspired Temporal Computing](https://arxiv.org/abs/2508.08973)
*Luca Fehlings,Thomas Mikolajick,Beatriz Noheda,Erika Covi*

Main category: cs.ET

TL;DR: 研究了 HfO2 基铁电器件的残留特性，并提出了一种利用其独特界面配置实现易失性存储的器件，该器件可用于实现可控时间常数，应用于时间计算和受脑启发的硬件计算。


<details>
  <summary>Details</summary>
Motivation: 铁电器件，特别是基于 HfO2 的器件，是实现可控时间常数的优雅解决方案，可用于时间计算和受脑启发的硬件计算。

Method: 通过电气特性分析器件，研究电子机制及其与观察到的残留时间的关系，以促进对 HfO2 基铁电电容器中残留过程的进一步建模。

Result: 展示了一种利用其独特的界面配置实现易失性存储的铁电电容器堆栈，其内部电场稳定了铁电薄膜的一种极化，从而可以进行单极操作，不稳定的极化状态具有毫秒级残留。

Conclusion: 该器件的残留与极化和电刺激都相关，允许在单个器件中利用一系列时间尺度。此外，所提出材料堆栈中特意存在的缺陷界面可以深入了解 HfO2 基铁电器件的残留损失与内部偏置场之间的相互作用，这与界面成分和氧空位作为内部偏置场的可能来源有关。

Abstract: With the broad recent research on ferroelectric hafnium oxide for
non-volatile memory technology, depolarization effects in HfO2-based
ferroelectric devices gained a lot of interest. Understanding the physical
mechanisms regulating the retention of these devices provides an excellent
opportunity for device optimization both towards non-volatile memory
applications and towards real-time signal processing applications in which
controlled time constants are of paramount importance. Indeed, we argue that
ferroelectric devices, particularly HfO2-based, are an elegant solution to
realize possibly arbitrary time constants in a single scaled memory device,
which paves the way for temporal and brain-inspired computing in hardware. Here
we present a ferroelectric capacitor stack realizing volatile memory due to its
unique interface configuration. We provide electrical characterization of the
device to motivate its use for realizing time constants in hardware, followed
by an investigation of the electronic mechanisms and their possible relation to
the observed retention times to facilitate further modeling of the retention
process in HfO2-based ferroelectric capacitors. In the presented device,
internal electric fields stabilize one polarization of the ferroelectric film,
opening the possibility for unipolar operation with millisecond retention for
the unstable polarization state. We show a dependence of the retention on both
the polarization as well as the electrical stimuli, allowing us to exploit a
range of time scales in a single device. Further, the intentionally defective
interface in the presented material stack allows an insight into the interplay
between retention loss in HfO2-based ferroelectric devices and the internal
bias field, which we relate to the interface composition and the role of oxygen
vacancies as a possible source of the internal bias fields.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [254] [DiffractGPT: Atomic Structure Determination from X-ray Diffraction Patterns using Generative Pre-trained Transformer](https://arxiv.org/abs/2508.08349)
*Kamal Choudhary*

Main category: cond-mat.mtrl-sci

TL;DR: DiffractGPT是一个AI模型，可以直接从XRD图谱预测晶体结构，结合化学信息能提高准确性。


<details>
  <summary>Details</summary>
Motivation: 晶体结构测定是材料科学中的一个复杂挑战，通常需要广泛的专业知识和计算资源。本研究旨在通过开发一种AI模型来简化和加速这一过程。

Method: 本研究提出了一种名为DiffractGPT的生成式预训练transformer模型，用于直接从X射线衍射（XRD）图谱预测原子结构。模型在包含数千个原子结构及其模拟XRD图谱的JARVIS-DFT数据集上进行了训练，并针对三种情况进行了评估：仅使用XRD图谱、提供元素列表以及提供明确的化学式。

Result: 研究结果表明，在预测中加入化学信息能够显著提高模型的准确性。DiffractGPT模型在结合化学信息的情况下，能够更准确地预测晶体结构。

Conclusion: 本研究提出的DiffractGPT模型能够直接从X射线衍射（XRD）图谱预测原子结构，通过学习衍射图谱和晶体结构之间的复杂关系，实现了快速和准确的逆向设计。研究表明，结合化学信息可以显著提高预测精度，并且模型的训练过程快速简便，有助于连接计算、数据科学和实验社区，是自动化晶体结构确定的重要进展，为数据驱动的材料发现和设计提供了有力工具。

Abstract: Crystal structure determination from powder diffraction patterns is a complex
challenge in materials science, often requiring extensive expertise and
computational resources. This study introduces DiffractGPT, a generative
pre-trained transformer model designed to predict atomic structures directly
from X-ray diffraction (XRD) patterns. By capturing the intricate relationships
between diffraction patterns and crystal structures, DiffractGPT enables fast
and accurate inverse design. Trained on thousands of atomic structures and
their simulated XRD patterns from the JARVIS-DFT dataset, we evaluate the model
across three scenarios: (1) without chemical information, (2) with a list of
elements, and (3) with an explicit chemical formula. The results demonstrate
that incorporating chemical information significantly enhances prediction
accuracy. Additionally, the training process is straightforward and fast,
bridging gaps between computational, data science, and experimental
communities. This work represents a significant advancement in automating
crystal structure determination, offering a robust tool for data-driven
materials discovery and design.

</details>


### [255] [Electronic transport and Fermi surface of Weyl semimetal WTe2: quantum oscillations and first-principles study](https://arxiv.org/abs/2508.08419)
*B. M. Fominykh,A. N. Perevalova,S. T. Baidak,A. V. Lukoyanov,S. V. Naumov,E. B. Marchenkova,V. V. Marchenkov*

Main category: cond-mat.mtrl-sci

TL;DR: WTe2 exhibits unique magnetoresistivity and electronic properties explained by DFT and quantum oscillations.


<details>
  <summary>Details</summary>
Motivation: Investigate the electronic structure and transport properties of the Weyl semimetal WTe2 due to its unique physical properties and potential applications in electronics.

Method: DFT+U+SOC method for band structure calculations, experimental transport measurements (magnetoresistivity, Shubnikov-de Haas oscillations), and Lifshitz-Kosevich formalism for parameter extraction.

Result: The study confirmed WTe2's semimetallic nature, its sensitivity to U and Fermi energy, near-compensated state, and almost quadratic non-saturating magnetoresistivity. It also identified three Fermi surface pockets and determined their electronic structure parameters.

Conclusion: WTe2 is a near-compensated Weyl semimetal exhibiting almost quadratic non-saturating magnetoresistivity, violating classical Kohler's rule due to multiple scattering mechanisms and temperature-dependent carrier concentration. Shubnikov-de Haas oscillations reveal three Fermi surface pockets (two electron, one hole), consistent with calculations. Electronic structure parameters and relationships between g-factor and Berry phase were determined.

Abstract: Currently, topological semimetals are being actively investigated from both
theoretical and experimental perspectives due to their unique physical
properties, including topologically protected states, large magnetoresistivity,
and high carrier mobility, which make these materials promising for various
applications in electronics. In this work, we present experimental and
theoretical studies of the electronic structure and electronic transport in the
Weyl semimetal $WTe_2$. Band structure of $WTe_2$ was scrutinized with
DFT+U+SOC method showing the semimetallic nature and sensitivity of the
structure to the value of U and to changes in the Fermi energy. Our results
demonstrate that $WTe_2$ is in a near-compensated state and exhibits an almost
quadratic non-saturating magnetoresistivity. It is found that $WTe_2$ violates
the classical Kohler's rule, which is attributed to the coexistence of multiple
scattering mechanisms and a strong temperature dependence of the current
carrier concentration. Analysis of the Shubnikov-de Haas oscillations reveals
three distinct frequencies corresponding to two electron and one hole Fermi
surface pockets, which are well reproduced in Fermi surface calculations. Using
the Lifshitz-Kosevich formalism, we determined the electronic structure
parameters for each Fermi surface pocket. Additionally, we discuss the
relationship between the g-factor and the Berry phase extracted from quantum
oscillations.

</details>


### [256] [When Surface Dynamics Fakes Symmetry -- Oxygen on Rh(100) Revisited](https://arxiv.org/abs/2508.08474)
*Lutz Hammer,Tilman Kißlinger,Margareta Wagner,Reinhard B. Neder,Michael Schmid,Ulrike Diebold,M. Alexander Schneider*

Main category: cond-mat.mtrl-sci

TL;DR: Ordered adsorbate phases might appear disordered or have false symmetries due to fluctuations, even at low temperatures. This misinterpretation can affect understanding of surface reactivity, as shown with oxygen on Rh(100) and CO adsorption.


<details>
  <summary>Details</summary>
Motivation: demonstrate that heating a long-range ordered adsorbate phase beyond its stability temperature does not necessarily result in a disordered phase, it can also break up into heavily fluctuating ordered domains, which can lead to a wrong periodicity and a false local symmetry, potentially remaining undetected even below liquid-nitrogen temperature.

Method: quantitative low energy electron diffraction (LEED), variable-temperature scanning tunneling microscopy (STM) and density functional theory (DFT)

Result: The study demonstrates this scenario at the catalytically active Rh(100) surface covered by 1/2 monolayer (ML) of oxygen. It also shows that local symmetry can have a decisive influence on the binding energy and thus the chemical reactivity using the example of CO adsorption.

Conclusion: Heating a long-range ordered adsorbate phase beyond its stability temperature does not necessarily result in a disordered phase, it can also break up into heavily fluctuating ordered domains. Temporal and/or spatial averaging over these fluctuations may give the impression of both a wrong periodicity and a false local symmetry. This can happen even below liquid-nitrogen temperature, so that the true nature of the phase might remain undetected. Using the example of CO adsorption, we show that local symmetry can have a decisive influence on the binding energy and thus the chemical reactivity.

Abstract: Heating a long-range ordered adsorbate phase beyond its stability temperature
does not necessarily result in a disordered phase, it can also break up into
heavily fluctuating ordered domains. Temporal and/or spatial averaging over
these fluctuations may give the impression of both a wrong periodicity and a
false local symmetry. This can happen even below liquid-nitrogen temperature,
so that the true nature of the phase might remain undetected. We demonstrate
this scenario at the catalytically active Rh(100) surface covered by 1/2
monolayer (ML) of oxygen, using quantitative low energy electron diffraction
(LEED), variable-temperature scanning tunneling microscopy (STM) and density
functional theory (DFT). Using the example of CO adsorption, we show that local
symmetry can have a decisive influence on the binding energy and thus the
chemical reactivity.

</details>


### [257] [Perspective: Mitigation of structural defects during the growth of two-dimensional van der Waals chalcogenides by molecular beam epitaxy](https://arxiv.org/abs/2508.08483)
*Qihua Zhang,Maria Hilse,Stephanie Law*

Main category: cond-mat.mtrl-sci

TL;DR: MBE growth of vdW films can be improved by using a multi-step process to control nucleation and coalescence, reducing defects for better quality films.


<details>
  <summary>Details</summary>
Motivation: Wafer-scale vdW thin films and heterostructures are crucial for quantum technologies, optoelectronics, and fundamental physics, but current MBE methods result in structural defects.

Method: A multi-step MBE growth procedure is detailed, allowing rigorous control over nucleation and coalescence stages to improve film quality.

Result: The multi-step growth procedure mitigates common defects like twin/antiphase domains, spiral growth, and pyramidal growth, leading to high-quality vdW thin films.

Conclusion: The article describes a general recipe for growing highly-crystalline wafer-scale vdW thin films by MBE, mitigating defects common in co-deposition methods.

Abstract: The growth of wafer-scale van der Waals (vdW) thin films and heterostructures
by molecular beam epitaxy (MBE) is important for future applications in quantum
technologies, next generation optoelectronic devices, and fundamental physics
investigations. When grown using co-deposition methods that are typically used
for compound semiconductor MBE, vdW materials typically show a high density of
structural defects including twin or antiphase domains, spiral growth, and
pyramidal growth. These defects are caused by the relatively weak
film/substrate interaction and/or the poor wettability of typical substrates by
many vdW materials. These difficulties can be mitigated using a multi-step
growth procedure in which growth stages including nucleation and coalescence
can be rigorously controlled, resulting in high-quality deposition of vdW thin
films. This article will describe a general recipe for the growth of
highly-crystalline wafer-scale vdW thin films by MBE.

</details>


### [258] [Fully-compensated ferrimagnetic metal in the electric-field-tuned $\mathrm{Hf_2S}$ monolayer](https://arxiv.org/abs/2508.08609)
*San-Dong Guo,Alessandro Stroppa*

Main category: cond-mat.mtrl-sci

TL;DR: Researchers have found a way to create a fully-compensated ferrimagnetic metal using a 2D material (monolayer Hf2S) and an electric field, which was previously thought to be difficult.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the widespread attention given to fully-compensated ferrimagnets, which possess zero-net total magnetic moment and non-relativistic global spin splitting. However, the requirement of a gapped spin channel to achieve these properties generally limits their existence as metals. The study aims to explore an alternative route to realize fully-compensated ferrimagnetic metals.

Method: Utilizing first-principles calculations, the research analyzes monolayer Hf2S, initially a spin-degenerate 2D antiferromagnetic metal with spin-layer locking. An out-of-plane electric field is applied to induce the transition to a fully-compensated ferrimagnetic metal.

Result: The calculations confirm that monolayer Hf2S, under an applied electric field and without considering spin-orbit coupling (SOC), exhibits a zero-net total magnetic moment, spin splitting, and remains metallic. Inclusion of SOC with the electric field induces an asymmetric band structure. Thus, monolayer Hf2S becomes a fully-compensated ferrimagnetic metal.

Conclusion: The study proposes and validates a method to achieve a fully-compensated ferrimagnetic metal using monolayer Hf2S under an out-of-plane electric field, overcoming the limitation that such materials are typically gapped.

Abstract: Fully-compensated ferrimagnet has garnered widespread attention due to its
zero-net total magnetic moment and non-relativistic global spin splitting. In
general, for a fully-compensated ferrimagnet, at least one spin channel should
be gapped to ensure a zero-net total magnetic moment, which would lead to a
fully-compensated ferrimagnetic semiconductor or half-metal, and appears to
limit the existence of a fully-compensated ferrimagnetic metal. Here, we
propose to start with a spin-degenerate two-dimensional antiferromagnetic metal
with spin-layer locking and achieve a fully-compensated ferrimagnetic metal by
applying an out-of-plane electric field. Using first-principles calculations,
we have validated our proposal by taking monolayer $\mathrm{Hf_2S}$ as an
example. Without considering spin-orbit coupling (SOC), monolayer
$\mathrm{Hf_2S}$ indeed has a zero-net total magnetic moment, exhibits spin
splitting, and is metallic within a reasonable range of electric field
strength. Therefore, monolayer $\mathrm{Hf_2S}$ under an applied electric field
can indeed become a fully-compensated ferrimagnetic metal. When SOC is
included, the application of an electric field can induce an asymmetric band
structure. Our work offers an alternative route to realize the originally
forbidden fully-compensated ferrimagnetic metal, paving the way for further
exploration of fully-compensated ferrimagnetic metal.

</details>


### [259] [Momentum-Resolved Relaxation-Time Approach for Size-Dependent Conductivity in Anisotropic Metallic Films](https://arxiv.org/abs/2508.08622)
*YoungJun Lee,Jin Soo Lee,Seungjun Lee,Seoung-Hun Kang,Young-Kyun Kwon*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种新的理论框架，能够准确预测纳米尺度金属薄膜的电阻率，解决了铜互连的性能瓶颈，并发现了新的优良互连材料。


<details>
  <summary>Details</summary>
Motivation: 随着CMOS互连尺寸缩小到纳米级别，电子在表面、界面和晶界处的散射加剧，导致了严重的电导率损失，并对铜基设计提出了挑战。

Method: 本文提出了一个动量分辨弛豫时间框架，该框架将密度泛函理论与半经典玻尔兹曼输运方程相结合，用于预测金属薄膜中与尺寸相关的电阻率。通过第一性原理计算电子-声子相互作用，并使用考虑了动量依赖的平均自由路径来捕捉各向异性的表面和晶界散射，使得弛豫时间能够进行空间和方向上的变化，而无需经验拟合。

Result: 该模型成功应用于各向同性（Cu、Ag、Au）和各向异性（W、Ti2GeC）金属，与实验结果高度一致，并揭示了晶体学各向异性在输运中的关键作用。此外，研究确定了层状MAX相化合物作为有前景的超薄互连材料。

Conclusion: 本文提出的动量分辨弛豫时间框架，通过第一性原理计算电子-声子相互作用，并考虑了各向异性的表面和晶界散射，能够准确预测金属薄膜中尺寸相关的电阻率，并发现了晶体学各向异性在输运中的关键作用。研究还确定了层状MAX相化合物作为有前途的超薄互连材料。

Abstract: Shrinking CMOS interconnect dimensions to the nanometer scale intensifies
electron scattering at surfaces, interfaces, and grain boundaries, causing
severe conductivity loss and challenging copper-based designs. Here we present
a momentum-resolved relaxation time framework that integrates density
functional theory with the semiclassical Boltzmann transport equation to
predict size-dependent resistivity in metallic thin films. Electron phonon
interactions are computed from first principles, and anisotropic surface and
grain boundary scattering is captured through a momentum dependent mean free
path, allowing relaxation times to vary spatially and directionally without
empirical fitting. Applied to isotropic (Cu, Ag, Au) and anisotropic (W,
Ti$_2$GeC) metals, the model achieves excellent agreement with experiments and
uncovers the critical role of crystallographic anisotropy in transport. We
further identify layered MAX phase compounds as promising ultrathin
interconnects. This work provides a predictive, physically rigorous, and
computationally efficient route to designing high-performance conductors for
next generation nanoelectronics.

</details>


### [260] [Investigating the Degradation of LATP Solid Electrolyte in High Alkaline Li-$O_2$ Batteries](https://arxiv.org/abs/2508.08654)
*Tara P Mishra,Zhuohan Li,Meghan Shen,Maximilian Jaugstetter,Livia P Matte,Jung O. Park,Hyunjin Kim,Benjamin X Lam,Karen Bustillo,Gerbrand Ceder,Mary Scott*

Main category: cond-mat.mtrl-sci

TL;DR: LATP 固态电解质在潮湿锂氧电池中会因离子浸出和沉淀而降解，但形成的富钛层可能具有一定的保护作用。


<details>
  <summary>Details</summary>
Motivation: 为了解决全固态潮湿锂氧电池中电解质易降解的问题，本研究旨在深入理解 LATP 固态电解质的降解机理，为设计更耐用、高效的锂氧电池提供理论基础。

Method: 本研究结合了 STEM-EELS、XPS 表征技术和 DFT 计算，对 LATP 固态电解质在潮湿锂氧电池中的性能进行了分析。

Result: 研究发现，$(PO_4)^{3-}$和$Al^{3+}$离子从 LATP 电解质中浸出，并在充电过程中形成$Li_3PO_4$和$AlPO_4$沉淀，导致电池性能下降。此外，观察到富钛层在电池表面形成，并可能抑制副反应。

Conclusion: 该研究揭示了 LATP 固态电解质在碱性环境下，放电过程中$(PO_4)^{3-}$和$Al^{3+}$离子浸出，充电过程中形成$Li_3PO_4$和$AlPO_4$沉淀并累积在 LATP 表面的机理，从而导致电池性能下降。同时，研究发现富钛层可能抑制副反应。

Abstract: In this study, we address the challenge of electrolyte degradation in
all-solid-state humidified Li-$O_2$ batteries, which offer high theoretical
energy density and potential cost advantages over conventional lithium-ion
batteries. Combining STEM-EELS, and XPS characterizations with DFT
calculations, we reveal the leaching of $(PO_4)^{3+}$ and $Al^{3+}$ ions from
the $Li_{1.3}Al_{0.3}Ti_{1.7}(PO_4)_3$ (LATP) solid electrolyte upon battery
discharge, caused by the highly alkaline environment. Upon charging, the
leached ions precipitate as $Li_3PO_4$ and $AlPO_4$, which accumulate on the
LATP surface and contribute to battery degradation. A Ti-rich layer is observed
at the surface after a few cycles due to depletion of other cations. Our
findings suggest that the degradation products are formed through repeated
dissolution and precipitation in the discharge-charge cycles. Furthermore, our
results indicate that the Ti-rich layer on the LATP surface can potentially
reduce parasitic reactions. Our study provides mechanistic understanding of
LATP solid electrolyte degradation in humidified Li-$O_2$ cell, paving the way
for designing more durable and efficient Li-$O_2$ batteries.

</details>


### [261] [Load-Dependent Sliding behavior of WSe2-x solid lubricant coating](https://arxiv.org/abs/2508.08689)
*Yue Wang,Himanshu Rai,Tomas Polcar*

Main category: cond-mat.mtrl-sci

TL;DR: Tungsten diselenide coatings show better lubrication than molybdenum disulfide coatings, especially in humid conditions. Frictional heating affects load-dependence.


<details>
  <summary>Details</summary>
Motivation: Molybdenum disulfide is the most studied and applied TMD solid lubricant, but other members may have similar or even better sliding properties. Tungsten diselenide is one of the materials that has rarely been investigated in terms of tribological properties.

Method: The paper provides a comprehensive tribological characterization of substoichiometric tungsten diselenide and molybdenum disulfide coatings deposited by magnetron sputtering. The study focused on tribological properties at a macroscopic scale, particularly friction and wear dependence on applied load, and also performed nanoscale frictional assessment of worn surfaces to identify the major wear mechanisms.

Result: Substoichiometric tungsten diselenide outperformed traditional molybdenum disulfide, exhibiting much lower friction in humid air. Nanotribological experiments in the wear tracks suggest that frictional heating of the surface is the key factor causing frictional load-dependence (deviation from Amonton's law).

Conclusion: Substoichiometric tungsten diselenide outperformed traditional molybdenum disulfide, exhibiting much lower friction in humid air, suggesting lower coating sensitivity to the humid atmosphere. Frictional heating of the surface is the key factor causing frictional load-dependence (deviation from Amonton

Abstract: Transition-metal dichalcogenides (TMDs) are commonly used as solid lubricants
in various environments. Molybdenum disulfide is the most studied and applied
TMD solid lubricant, but other members may have similar or even better sliding
properties. Tungsten diselenide is one of the materials that has rarely been
investigated in terms of tribological properties. This paper provides a
comprehensive tribological characterization of substoichiometric tungsten
diselenide and molybdenum disulfide coatings deposited by magnetron sputtering.
We focused on tribological properties at a macroscopic scale, particularly
friction and wear dependence on applied load; however, a nanoscale frictional
assessment of worn surfaces was performed as well to identify the major wear
mechanisms. Substoichiometric tungsten diselenide outperformed traditional
molybdenum disulfide, exhibiting much lower friction in humid air, suggesting
lower coating sensitivity to the humid atmosphere. Moreover, a combination of
nanotribological experiments in the wear tracks with sliding under different
environmental conditions suggests that the key factor causing frictional
load-dependence (deviation from Amonton's law) is frictional heating of the
surface.

</details>


### [262] [The spontaneous Nernst coefficient of ferromagnets from the interplay of electron scattering and Berry curvature](https://arxiv.org/abs/2508.08756)
*Vittorio Basso,Adriano Di Pietro,Alessandro Sola*

Main category: cond-mat.mtrl-sci

TL;DR: A new method to derive the spontaneous Nernst coefficient for ferromagnetic metals suggests strong scattering is good and provides recipes for improvement.


<details>
  <summary>Details</summary>
Motivation: To derive the spontaneous Nernst coefficient for ferromagnetic metals and understand its relationship with material properties and band structures.

Method: The Boltzmann transport approach is employed to derive the spontaneous Nernst coefficient for ferromagnetic metals, explicitly treating the transverse current density due to Berry curvature as a Fermi surface property. A rigid two-bands model is constructed to evaluate the thermoelectric coefficients.

Result: The spontaneous Nernst coefficient is found to be proportional to the inverse of the scattering time constant, suggesting that strong scattering is beneficial for efficient spontaneous Nernst materials. A good agreement is found between the model's predictions and experimental coefficients of magnetic 3d transition metal ferromagnets.

Conclusion: The study establishes a direct connection between the spontaneous Nernst coefficient and the itinerant contribution to orbital angular momentum density, proposing recipes for maximizing the effect through electronic band structure tailoring.

Abstract: We employ the Boltzmann transport approach to derive the spontaneous Nernst
coefficient for ferromagnetic metals, explicitly treating the transverse
current density due to Berry curvature as a Fermi surface property. We find
that the spontaneous Nernst coefficient is proportional to the inverse of the
scattering time constant, implying that efficient spontaneous Nernst materials
should exhibit relatively strong scattering, a stark contrast to ordinary
Nernst materials. Furthermore, we establish a direct connection between the
strength and sign of the spontaneous Nernst coefficient and the itinerant
contribution to orbital angular momentum density arising from the Bloch bands.
Finally we construct a rigid two-bands model to evaluate the thermoelectric
coefficients by which we find a good agreement with the signs and orders of
magnitude of the experimental coefficients of magnetic 3d transition metal
ferromagnets. We finally propose some practical recipes for maximizing the
spontaneous Nernst effect through electronic band structure tailoring.

</details>


### [263] [Anomalous Sodium Insertion in Highly Oriented Graphite: Thermodynamics, Kinetics and Evidence for Two-Sided Intercalation](https://arxiv.org/abs/2508.08806)
*Chuanhai Gan,Chuanlian Xiao,Hongguang Wang,Peter A. van Aken,Rotraut Merkle,Sebastian Bette,Bettina V. Lotsch,Joachim Maier*

Main category: cond-mat.mtrl-sci

TL;DR: 钠在石墨中的嵌入需要高温才能达到平衡，温度降低会改变控制机制。尽管存在一些挑战，但通过特定方法可以实现钠的嵌入，但其电化学性能不如锂。


<details>
  <summary>Details</summary>
Motivation: 研究钠在石墨中的嵌入行为，特别是其平衡条件和控制机制。

Method: 通过对高度取向的致密石墨（HOPG）进行系统且长期的（长达2年）研究，包括化学插层（固、液、气态Na）和电化学插层（25°C），研究了钠（Na）在石墨中的嵌入行为。

Result: 在降低化学嵌入温度时，热力学控制会转变为扩散控制，最终转变为界面控制。TiO2涂层可提高电化学嵌入效率并降低界面电阻。观察到高温和低温下Na嵌入HOPG的结构差异。

Conclusion: Na在石墨中的嵌入平衡需要高温，在降低嵌入温度时，热力学控制会变为扩散控制，最后变为界面控制。TiO2涂层可避免共嵌入并降低界面电阻，但可逆电池电压低于锂或钾。高温下Na主要以双层形式嵌入石墨，低温下则出现更聚集的层。

Abstract: The difficult intercalation of sodium (Na) into graphite is studied by
systematic and long-time investigations (of up to 2 years) using highly
oriented pyrolytic graphite (HOPG). By studying chemical insertion of solid,
liquid and gaseous Na at low and high temperatures (LT, HT) as well as using
electrochemical insertion at 25 degree Celsius into uncoated and coated HOPG,
it became clear that insertion equilibrium requires HT. On decreasing chemical
intercalation temperature from HT (500 degree Celsius) to LT (25 degree
Celsius), thermodynamic control was found to change to diffusion control and
finally to interfacial control. For the electrochemical insertion, coating
(TiO2) proved advisable (to avoid co-intercalation) and efficient in reducing
the interfacial resistance. Measured saturation values were found to be not
higher than about 1 mol %. Towards room temperature higher equilibrium values
cannot be excluded but would in view of the very low driving force kinetically
be very difficult to reach. The reversible cell voltage of the saturated
composition (versus alkali metal) is distinctly lower than for the analogous
cells using lithium (Li) or potassium (K). Detailed transmission electron
microscopy (TEM) studies reveal the unexpected fact that at HT Na predominantly
enters HOPG in the form of two-sided intercalation sandwiching carbon layers
(bilayers), while at LT more highly aggregated layers appear to a comparable
degree, accompanied with the formation of higher-dimensional crystal
imperfections. The reasons for this peculiar feature and the non-monotonic
thermodynamics in the sequence Li-Na-K-Rb-Cs are discussed not only from an
energetic but also from an entropic point of view.

</details>


### [264] [Optimal Autonomous MLIP Dataset Building](https://arxiv.org/abs/2508.08864)
*Vincent G. Fletcher,Albert P. Bartók,Livia B. Pártay*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种新的机器学习原子间势（MLIP）训练数据库构建方法，使用嵌套采样（NS）和从头密度泛函理论（DFT）以及原子簇展开（ACE）架构，成功应用于镁，并实现了对不同压力和温度下的准确描述。


<details>
  <summary>Details</summary>
Motivation: 提出一种易于自动化、适合迭代学习且独立于稳定相先验知识的训练数据库构建方法，以避免对预先存在的结构数据产生偏见。

Method: 提出了一种新颖的用于构建机器学习原子间势（MLIP）模型训练数据库的方法，该方法使用嵌套采样（NS）探索构象空间并生成热力学相关的构象，然后使用从头密度泛函理论（DFT）进行评估，最后使用原子簇展开（ACE）架构拟合模型。

Result: 将该框架应用于镁，开发了一个能够准确描述 0-600 GPa 和 0-8000 K 压力和温度范围内的行为的模型，并通过计算其声子谱、弹性常数以及该区域内的压力-温度相图对其性能进行了基准测试。

Conclusion: 该框架能够以更低的计算成本生成具有鲁棒性、可转移性和通用性的 MLIPs。

Abstract: We propose a novel approach for constructing training databases for Machine
Learning Interatomic Potential (MLIP) models, specifically designed to capture
phase properties across a wide range of conditions. The framework is uniquely
appealing due to its ease of automation, its suitability for iterative
learning, and its independence from prior knowledge of stable phases, avoiding
bias towards pre-existing structural data. The approach uses Nested Sampling
(NS) to explore the configuration space and generate thermodynamically relevant
configurations, forming the database which undergoes ab-initio Density
Functional Theory (DFT) evaluation. We use the Atomic Cluster Expansion (ACE)
architecture to fit a model on the resulting database. To demonstrate the
efficiency of the framework, we apply it to magnesium, developing a model
capable of accurately describing behaviour across pressure and temperature
ranges of 0-600 GPa and 0-8000 K, respectively. We benchmark the model's
performance by calculating phonon spectra and elastic constants, as well as the
pressure-temperature phase diagram within this region. The results showcase the
power of the framework to produce robust MLIPs while maintaining
transferability and generality, for reduced computational cost.

</details>


### [265] [Ferroelectric Control of Interlayer Excitons in 3R-MoS$_{2}$ / MoSe$_{2}$ Heterostructures](https://arxiv.org/abs/2508.08911)
*Johannes Schwandt-Krause,Mohammed El Amine Miloudi,Elena Blundo,Swarup Deb,Jan-Niklas Heidkamp,Kenji Watanabe,Takashi Taniguchi,Rico Schwartz,Andreas Stier,Jonathan J. Finley,Oliver Kühn,Tobias Korn*

Main category: cond-mat.mtrl-sci

TL;DR: 范德华异质结构中的层间激子行为可通过铁电畴和栅极电压进行调控，为铁电光电器件提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 研究了二维滑动铁电材料在调控范德华异质结构激子性质方面的潜力。

Method: 结合光致发光实验、密度泛函理论和多体计算，研究了hBN包覆的3R-MoS$_2$/MoSe$_2$异质结构中层间激子与铁电畴的相互作用。

Result: 光致发光光谱显示，层间激子能量随MoS$_2$层厚度增加而发生红移，且光致发光能量的局域变化与局域铁电畴极化相关，表现出不同的畴依赖性行为。栅极电压实验证明了通过切换铁电畴可以调控层间激子能量。

Conclusion: 该研究结果表明，范德华异质结构中的层间激子可以通过局域铁电极化进行控制，为未来基于范德华异质结构的铁电光电器件奠定了基础。

Abstract: Van der Waals heterostructures, constructed by stacking two-dimensional
materials, have enabled the study of interlayer coupling between different
materials. One example is the formation of interlayer excitons in transition
metal dichalcogenide heterostructures. The integration of 2D sliding
ferroelectric materials introduces new opportunities for manipulating excitonic
properties in these systems. In this work, we investigate the interaction
between interlayer excitons and ferroelectric domains in hBN-encapsulated
3R-MoS$_2$/MoSe$_2$ heterostructures, combining photoluminescence experiments
with density functional theory and many-body calculations. Photoluminescence
spectroscopy at low temperature reveals a strong redshift of the interlayer
exciton energy with increasing MoS$_2$ layer thickness, attributed to band
renormalization and dielectric environment changes. Additionally, local
variations in photoluminescence energy correlate with local ferroelectric
domain polarization, showcasing distinct domain-dependent interlayer exciton
behavior. Gate voltage experiments further demonstrate tunable shifts in
interlayer exciton energy, driven by switching ferroelectric domains. These
results highlight the potential of interlayer excitons being controlled by
local ferroelectric polarization and establish a foundation for future
ferroelectric optoelectronic devices based on van der Waals heterostructures.

</details>


### [266] [The alloying of first-principles calculations with quasiparticle methodologies for the converged solution of the quantum many-electron states in the correlated compound Iron monoxide](https://arxiv.org/abs/2508.08941)
*Suvadip Das*

Main category: cond-mat.mtrl-sci

TL;DR: Hybrid functionals offer the best balance of accuracy and efficiency for simulating transition metal oxides like Iron monoxide.


<details>
  <summary>Details</summary>
Motivation: Finding an efficient and accurate first principles method for the assertion of physical properties of transition metal oxides, particularly correlated compounds like Iron monoxide, is momentous for the predictive modelling of physics based thermoelectric and photovoltaic devices.

Method: Benchmarking a variety of first principles methods such as the density functional theory artificially stabilized by Coulomb interactions, Hybrid functionals as well as the quasiparticle Greens function approach to self-energy interactions. Rigorous convergence of the self-consistent Dysons equations have been provided addressing the importance of initial choice of wavefunctions guided by first principles on the converged solutions and the interplay of various orbital degrees of freedom adjacent to the Fermi level.

Result: The study establishes the hybrid functional scheme as the optimal approach for the ideal trade-off between accuracy of the ground state wavefunctions and computational efficiency for large-scale simulations towards the efficient convergence of correlated electronic wavefunctions and low energy electronic properties.

Conclusion: The study establishes the hybrid functional scheme as the optimal approach for the ideal trade-off between accuracy of the ground state wavefunctions and computational efficiency for large-scale simulations towards the efficient convergence of correlated electronic wavefunctions and low energy electronic properties.

Abstract: Transition metal oxides belong to a genre of quantum materials essential for
the exploration of theoretical methods for quantifying electronic correlation.
Finding an efficient and accurate first principles method for the assertion of
such physical properties is momentous for the predictive modelling of physics
based thermoelectric and photovoltaic devices. Prior investigations have
suggested that incorporation of the so called random phase approximation for
the electronic screening interaction by adding up the electron hole pairs leads
to significant improvement in the accuracy of first principle calculations.
Nonetheless the method has seldom been adapted systematically for studying the
properties of prototypical transition metal oxides, particularly that of the
correlated compound Iron monoxide. In this work, we provide a benchmarking
study of a variety of first principles methods such as the density functional
theory artificially stabilized by Coulomb interactions, Hybrid functionals as
well as the quasiparticle Greens function approach to self-energy interactions.
A rigorous convergence of the self-consistent Dysons equations have been
provided addressing the importance of initial choice of wavefunctions guided by
first principles on the converged solutions and the interplay of various
orbital degrees of freedom adjacent to the Fermi level. It is momentous to
obtain accurate wavefunctions and many-electronic energy states for the
quantification of correlation and efficient modelling of oxide interfaces for
quantum applications. The study establishes the hybrid functional scheme as the
optimal approach for the ideal trade-off between accuracy of the ground state
wavefunctions and computational efficiency for large-scale simulations towards
the efficient convergence of correlated electronic wavefunctions and low energy
electronic properties.

</details>


### [267] [Thermoelectric Properties of Copper-based Chalcopyrite Semiconductors Cu$MX_2$ ($M$ = Al, Ga, and In; $X$ = S, Se, and Te) from First-Principles Calculations](https://arxiv.org/abs/2508.08988)
*Wu Xiong,Zhonghao Xia,Zhongjuan Han,Dong Yao,Jiangang He*

Main category: cond-mat.mtrl-sci

TL;DR: This paper uses first-principles calculations to study the thermoelectric properties of Cu$MX_2$ compounds. It finds that Cu$M$Te$_2$ compounds have high electrical conductivity and power factors, while Cu$M$Se$_2$ and Cu$M$S$_2$ compounds have lower lattice thermal conductivity. Doping is suggested as a way to further improve their performance.


<details>
  <summary>Details</summary>
Motivation: Copper-based chalcopyrite semiconductors have attracted sustained interest owing to their promising thermoelectric (TE) performance, yet the microscopic origins of their TE behavior remain incompletely understood.

Method: First-principles calculations were used to systematically investigate the thermoelectric properties of Cu$MX_2$ ($M=$ Al, Ga, and In; $X=$ S, Se, and Te). The calculated electrical conductivity, hole mobility, Seebeck coefficient, and power factor for p-type doping were compared with experimental data.

Result: The study found that for p-type doping, CuGaTe$_2$ and CuInTe$_2$ show excellent agreement between calculated and experimental TE properties. Hole mobility increases significantly as the chalcogen varies from S to Te due to weaker polar-optical-phonon scattering. Cu$M$Te$_2$ compounds exhibit high electrical conductivity and power factors. The lattice thermal conductivity of Cu$M$Se$_2$ is anomalously lower than that of Cu$M$Te$_2$ primarily due to enhanced three-phonon scattering. Cu$M$S$_2$ compounds show the steepest temperature-induced decrease in lattice thermal conductivity and attain a smaller lattice thermal conductivity than Cu$M$Se$_2$ and Cu$M$Te$_2$ at 800 K.

Conclusion: Cu$MX_2$ ($M=$ Al, Ga, and In; $X=$ S, Se, and Te) compounds have promising thermoelectric properties. Cu$M$Te$_2$ compounds exhibit high electrical conductivity and power factors due to weaker polar-optical-phonon scattering and smaller transport effective masses. Cu$M$Se$_2$ compounds show lower lattice thermal conductivity than Cu$M$Te$_2$ due to enhanced three-phonon scattering. Cu$M$S$_2$ compounds have the steepest temperature-induced decrease in lattice thermal conductivity and attain a smaller lattice thermal conductivity than Cu$M$Se$_2$ and Cu$M$Te$_2$ at 800 K. Doping is the most effective route to further improve the thermoelectric performance of Cu$MX_2$ compounds by enhancing electrical conductivity and reducing lattice thermal conductivity.

Abstract: Copper-based chalcopyrite semiconductors have attracted sustained interest
owing to their promising thermoelectric (TE) performance, yet the microscopic
origins of their TE behavior remain incompletely understood. Here, we
systematically investigate the TE properties of Cu$MX_2$ ($M=$ Al, Ga, and In;
$X=$ S, Se, and Te) using first-principles calculations. For $p$-type doping,
the calculated electrical conductivities ($\sigma$), hole mobilities ($\mu$),
Seebeck coefficients ($S$), and power factors (PFs) of CuGaTe$_2$ and
CuInTe$_2$ show excellent agreement with experimental data. At fixed
temperature and hole concentration, as $X$ varies from S to Te, the hole
mobility increases markedly due to progressively weaker polar--optical--phonon
scattering, reflecting the reduced ionic contribution to the dielectric
response in compounds with heavier chalcogens. Combined with smaller transport
effective masses, Cu$M$Te$_2$ compounds therefore exhibit high $\sigma$ and
large PFs. Across the Cu$MX_2$ family, the anomalously lower
$\kappa_{\mathrm{L}}$ of Cu$M$Se$_2$ relative to Cu$M$Te$_2$ arises primarily
from enhanced three-phonon scattering at low-frequency region. For a given $M$,
Cu$M$S$_2$ displays the steepest temperature-induced decrease in
$\kappa_{\mathrm{L}}$ and attains a smaller $\kappa_{\mathrm{L}}$ than
Cu$M$Se$_2$ and Cu$M$Te$_2$ at 800~K. Given the low band degeneracy and
comparatively modest hole mobilities of Cu$MX_2$ compounds, the most effective
routes to further improve their TE performance are to enhance $\sigma$ and
reduce $\kappa_{\mathrm{L}}$ through doping.

</details>


### [268] [Characterisation of Irradiation Damage in Fe3Cr and Fe5Cr: A Study on the Effects of Chromium Content and Temperature](https://arxiv.org/abs/2508.09018)
*Chandra Bhusan Yadav,Andrew J. London,Tonci Tadic,Ruqing Xu,Wenjun Liu,Stjepko Fazinic,Suchandrima Das*

Main category: cond-mat.mtrl-sci

TL;DR: Fe-Cr合金在辐照下的性能受Cr含量和温度的共同影响，在约300°C时出现损伤演化的转折点，Fe-3%Cr合金在低温下表现更差。


<details>
  <summary>Details</summary>
Motivation: 研究Fe-Cr二元合金在辐照损伤下的行为，以了解聚变结构材料的损伤机制。

Method: 使用Fe离子辐照Fe-3%Cr和Fe-5%Cr样品，并进行深度分辨Laue微衍射、纳米压痕和AFM分析。

Result: 辐照损伤随温度的演化呈现非单调性，在约300°C时存在一个转折点，该转折点反映了从缺陷迁移和部分恢复到溶质-缺陷团簇和空腔形成的转变。Fe-3%Cr在较低温度下表现出比Fe-5%Cr更高的应变和硬化。

Conclusion: Fe-Cr二元合金的研究揭示了Cr含量和温度如何共同影响辐照响应，为理解聚变相关合金的缺陷演化提供了新见解。

Abstract: Fe-Cr binary alloys serve as simplified model systems to study irradiation
damage relevant to fusion structural materials. Here, Fe-3%Cr and Fe-5%Cr
samples were irradiated with 4 MeV Fe ions under a dose rate of 4x10^5 dpa/s
across a linear thermal gradient (120C to 480C) in a single experiment,
enabling direct comparison of temperature and Cr content effects under
identical conditions. Depth-resolved Laue micro-diffraction (~10^4 strain
sensitivity), nanoindentation, and AFM reveal non-monotonic evolution of
lattice strain and hardness: both decrease with temperature up to ~300C, then
increase beyond. This turning point reflects a shift from enhanced defect
mobility and partial recovery to solute-defect clustering and cavity formation,
which stabilize damage. Fe-3%Cr shows consistently higher strain and hardening
than Fe-5%Cr, especially at lower temperatures. Minimal change in
post-indentation pile-up indicates limited softening or localization. These
results highlight how Cr content and temperature jointly affect irradiation
response, offering new insights into defect evolution in fusion-relevant
alloys.

</details>


### [269] [Polar Express: Rapid Functionalization of Single-Walled Carbon Nanotubes in High Dipole Moment Media](https://arxiv.org/abs/2508.09039)
*Dominik Just,Ryszard Siedlecki,Maciej Krzywiecki,Oussama Er-Riyahi,Yann Pouillon,Javier Junquera,Karolina Z. Milowska,Dawid Janas*

Main category: cond-mat.mtrl-sci

TL;DR: 溶剂影响碳纳米管光学性质，改进检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了优化荧光半导体单壁碳纳米管的光学特性，并探索溶剂环境对碳纳米管化学修饰过程的影响。

Method: 利用SIESTA的混合泛函，通过多尺度模拟研究了溶剂、分散剂和碳纳米管之间的相互作用，并系统地研究了碳纳米管在多种溶剂中的反应性。

Result: 发现溶剂和分散剂不仅影响碳纳米管化学修饰的动力学，还影响其过程。极性溶剂能引起聚合物分子在碳纳米管表面的结构重组，并增强聚合物-碳纳米管界面的电荷再分布，最终实现对碳纳米管光学性质的高度控制。

Conclusion: 通过化学修饰和溶剂工程，实现了碳纳米管光学性质的高度可控，并成功应用于胆固醇的光学检测。

Abstract: Fluorescent semiconducting single-walled carbon nanotubes (SWCNTs) hold
considerable promise for photonics. Furthermore, the optical characteristics of
the material can be significantly improved by covalent modification, which
generates new spectral features in the near-infrared region and enhances its
photoluminescence quantum yield. However, despite the dynamic development of
this research domain, the importance of the solvent environment in which the
SWCNT functionalization is conducted remains relatively unexplored. In this
work, the complex relationships between solvent, dispersant, and SWCNTs were
untangled to unravel the underlying phenomena. Through a systematic
investigation of SWCNT reactivity in a broad spectrum of solvents, supported by
multi-scale modeling enabled by our new implementation of a hybrid functional
within SIESTA, we discovered that both the solvent medium and the dispersant
enabling SWCNT solubilization affect not only the kinetics but also the course
of the covalent modification of SWCNTs. Polar solvents proved to induce
significant structural reorganization of polymer molecules on the SWCNT surface
and enhance charge redistribution at the polymer-SWCNT interface. Consequently,
we achieved a high degree of control over the optical properties of SWCNTs, and
the tailored SWCNTs enabled facile optical detection of cholesterol, a
significant risk factor for cardiovascular diseases.

</details>


### [270] [Design Rules and Discovery of Face-Sharing Hexagonal Perovskites](https://arxiv.org/abs/2508.09088)
*M. J. Swamynadhan,Gwan Yeong Jung,Pravan Omprakash,Rohan Mishra*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究为设计六方钙钛矿提供了预测框架，重点关注了硫化物在开发新颖铁电材料方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 六方晶面共享钙钛矿是一类有前景但尚未充分研究的材料。

Method: 通过比较氧化物和硫化物，基于统一的、经过电负性校正的容差因子和Shannon A位半径来映射结构偏好，从而提出稳定六方晶面共享ABX3钙钛矿的定量设计原则。

Result: 研究确定了区分六方相和竞争性立方多晶型相的明确阈值，并发现硫化物与氧化物存在显著差异，这归因于过渡金属-硫键的共价性增强，从而提供了更广泛的成分选择性。

Conclusion: 该研究提出了稳定六方晶面共享钙钛矿的设计原则，并预测了一系列稳定的ABO3和ABS3化合物，其中硫化物作为获得具有新颖铁电现象的过渡金属阳离子的准一维材料具有潜力。

Abstract: Hexagonal face-sharing perovskites are a promising but underexplored class of
materials. We propose quantitative design principles for stabilizing hexagonal
face-sharing ABX3 perovskites, based on a comparative analysis of oxides and
sulfides. By mapping structural preferences across the phase space defined by a
unified, electronegativity-corrected tolerance factor and the Shannon A-site
radius, we identify distinct thresholds that separate hexagonal phases from
competing cubic polymorphs. Our analysis reveals that sulfides differ
significantly from oxides due to the increased covalency of transition
metal-sulfur bonds, enabling broader compositional flexibility. Applying these
principles, we predict a set of thermodynamically stable ABO3 and ABS3
compounds that are likely to adopt face-sharing octahedral connectivity. These
findings establish a predictive framework for designing hexagonal perovskites,
highlighting sulfides as promising candidates for obtaining
quasi-one-dimensional materials having transition metal cations for novel
ferroic phenomena.

</details>


### [271] [Machine Learning Phonon Spectra for Fast and Accurate Optical Lineshapes of Defects](https://arxiv.org/abs/2508.09113)
*Mark E. Turiansky,John L. Lyons,Noam Bernstein*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习势能可以高效且准确地计算缺陷的光学性质。


<details>
  <summary>Details</summary>
Motivation: 研究固体的光学性质，特别是缺陷引起的光学性质（如宝石着色和量子网络中的单光子发射），其中电子-声子耦合是描述光学跃迁的关键因素。传统的计算方法计算成本高昂，限制了研究的深入。

Method: 使用机器学习势（MLIPs）来替代传统的基于第一性原理的计算方法，以预测电子-声子耦合，从而分析光学性质。通过在包含数百个原子的模拟单元格中评估所有声子模式来预测电子-声子耦合，这通常计算成本很高。研究表明，仅使用常规的第一性原理计算中的原子弛豫数据作为训练集，就可以在几乎没有精度损失的情况下进行微调。

Result: 通过机器学习势，成功克服了计算电子-声子耦合的瓶颈，实现了高效且准确的光学性质预测。研究结果能够解决诸如硅中T中心（一种重要的量子缺陷）发光光谱中的局域振动模式耦合等精细细节，并将预测结果与显式计算和实验结果进行了比较，具有高度准确性。

Conclusion: 机器学习势可以高效准确地计算缺陷的光学性质，特别是解决了电子-声子耦合的计算瓶颈。

Abstract: The optical properties of defects in solids produce rich physics, from
gemstone coloration to single-photon emission for quantum networks. Essential
to describing optical transitions is electron-phonon coupling, which can be
predicted from first principles but requires computationally expensive
evaluation of all phonon modes in simulation cells containing hundreds of
atoms. We demonstrate that this bottleneck can be overcome using machine
learning interatomic potentials with negligible accuracy loss. A key finding is
that atomic relaxation data from routine first-principles calculations suffice
as a dataset for fine-tuning, though additional data can further improve
models. The efficiency of this approach enables studies of defect vibrational
properties with high-level theory. We fine-tune to hybrid functional
calculations to obtain highly accurate spectra, comparing with explicit
calculations and experiments for various defects. Notably, we resolve fine
details of local vibrational mode coupling in the luminescence spectrum of the
T center in Si, a prominent quantum defect.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [272] [Topos Theory for Generative AI and LLMs](https://arxiv.org/abs/2508.08293)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: This paper uses topos theory to propose new LLM architectures based on category theory concepts like pullbacks and pushouts, showing the category of LLMs is a topos and suggesting a way to implement it using backpropagation.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore novel architectures for LLMs by leveraging the theoretical result that the Transformer model is a universal sequence-to-sequence function approximator and that the category of LLMs, viewed as functions, forms a topos. This approach contrasts with previous studies that focused on daisy-chained linear architectures or mixture-of-experts.

Method: The paper utilizes topos theory and universal constructions in category theory to explore novel architectures for LLMs, deriving new compositional structures from universal properties of LLM categories. These structures include pullback, pushout, (co)equalizers, exponential objects, and subobject classifiers. The theoretical validation involves proving the (co)completeness of the LLM category and establishing it as a topos.

Result: The paper theoretically validates new compositional structures derived from universal properties of LLM categories. It proves that the category of LLMs is (co)complete and forms a topos, which is a "set-like" category.

Conclusion: The paper theoretically validates new compositional structures by showing that the category of LLMs is (co)complete, and then demonstrates that this category forms a topos. It also proposes a functorial characterization of backpropagation for potential implementation.

Abstract: We propose the design of novel categorical generative AI architectures
(GAIAs) using topos theory, a type of category that is ``set-like": a topos has
all (co)limits, is Cartesian closed, and has a subobject classifier. Previous
theoretical results on the Transformer model have shown that it is a universal
sequence-to-sequence function approximator, and dense in the space of all
continuous functions with compact support on the Euclidean space of embeddings
of tokens. Building on this theoretical result, we explore novel architectures
for LLMs that exploit the property that the category of LLMs, viewed as
functions, forms a topos. Previous studies of large language models (LLMs) have
focused on daisy-chained linear architectures or mixture-of-experts. In this
paper, we use universal constructions in category theory to construct novel LLM
architectures based on new types of compositional structures. In particular,
these new compositional structures are derived from universal properties of LLM
categories, and include pullback, pushout, (co) equalizers, exponential
objects, and subobject classifiers. We theoretically validate these new
compositional structures by showing that the category of LLMs is (co)complete,
meaning that all diagrams have solutions in the form of (co)limits. Building on
this completeness result, we then show that the category of LLMs forms a topos,
a ``set-like" category, which requires showing the existence of exponential
objects as well as subobject classifiers. We use a functorial characterization
of backpropagation to define a potential implementation of an LLM topos
architecture.

</details>


### [273] [UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss](https://arxiv.org/abs/2508.08615)
*Zhichao Wang,Xinhai Chen,Qinglin Wang,Xiang Gao,Qingyang Zhang,Menghan Jia,Xiang Zhang,Jie Liu*

Main category: cs.AI

TL;DR: 提出了一种名为UGM2N的无监督、可泛化网格移动网络，通过局部几何特征学习和M-Uniform损失函数，实现了高效、准确且无网格扭结的网格自适应，能够处理多种偏微分方程和网格几何。


<details>
  <summary>Details</summary>
Motivation: 传统的网格移动技术计算复杂度高且几何灵活性差，而现有的基于监督学习的方法在跨不同偏微分方程和网格拓扑的零样本泛化方面存在挑战。

Method: 提出了一种无监督和可泛化的网格移动网络（UGM2N），通过局部几何特征学习实现无监督网格自适应，并开发了一个物理约束损失函数（M-Uniform loss）来强制节点级别的网格均等分布。

Result: 实验结果表明，该网络在方程无关泛化和几何无关的有效网格自适应方面表现出色，优于现有方法。

Conclusion: 该方法在不同偏微分方程和网格几何形状上表现出一致的优越性，并且具有可扩展到多尺度分辨率和保证无网格扭结的误差减少。

Abstract: Partial differential equations (PDEs) form the mathematical foundation for
modeling physical systems in science and engineering, where numerical solutions
demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address
this challenge by dynamically relocating mesh nodes to rapidly-varying regions,
enhancing both simulation accuracy and computational efficiency. However,
traditional approaches suffer from high computational complexity and geometric
inflexibility, limiting their applicability, and existing supervised
learning-based approaches face challenges in zero-shot generalization across
diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and
Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised
mesh adaptation through localized geometric feature learning, eliminating the
dependency on pre-adapted meshes. We then develop a physics-constrained loss
function, M-Uniform loss, that enforces mesh equidistribution at the nodal
level.Experimental results demonstrate that the proposed network exhibits
equation-agnostic generalization and geometric independence in efficient mesh
adaptation. It demonstrates consistent superiority over existing methods,
including robust performance across diverse PDEs and mesh geometries,
scalability to multi-scale resolutions and guaranteed error reduction without
mesh tangling.

</details>


### [274] [Topos Causal Models](https://arxiv.org/abs/2508.08295)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: Topos Causal Models (TCMs) use topos category properties to formalize causal inference, including interventions and equivalences, and provide an internal logic for analysis.


<details>
  <summary>Details</summary>
Motivation: The motivation is to demonstrate that the properties of topos categories, such as (co)completeness, subobject classifiers, and exponential objects, are fundamental to various applications in causal inference, offering a new categorical approach to causal modeling.

Method: The paper defines Topos Causal Models (TCMs) by exploiting properties of topos categories, including (co)completeness, subobject classifiers, and exponential objects. It proves that the category of TCMs is (co)complete, enabling causal diagrams to be solved via (co)limits and causal approximation. Interventions are modeled by subobject classifiers, and equivalences are handled by exponential objects. The internal logic of TCMs is based on a Mitchell-Benabou language with Kripke-Joyal semantics.

Result: The paper demonstrates that subobject classifiers enable a categorical formulation of causal intervention, limits and colimits allow for solving complex causal diagrams through approximation, and exponential objects facilitate reasoning about equivalence classes of operations. It proves the (co)completeness of the TCM category and shows how interventions are modeled by subobject classifiers and equivalences by exponential objects. Furthermore, it establishes the use of an internal logic for reasoning about causal models within TCMs.

Conclusion: TCMs provide a novel categorical framework for causal inference, leveraging topos properties like (co)completeness, subobject classifiers, and exponential objects to formalize interventions, solve complex causal diagrams, reason about equivalences, and utilize an internal logic for causal model analysis.

Abstract: We propose topos causal models (TCMs), a novel class of causal models that
exploit the key properties of a topos category: they are (co)complete, meaning
all (co)limits exist, they admit a subobject classifier, and allow exponential
objects. The main goal of this paper is to show that these properties are
central to many applications in causal inference. For example, subobject
classifiers allow a categorical formulation of causal intervention, which
creates sub-models. Limits and colimits allow causal diagrams of arbitrary
complexity to be ``solved", using a novel interpretation of causal
approximation. Exponential objects enable reasoning about equivalence classes
of operations on causal models, such as covered edge reversal and causal
homotopy. Analogous to structural causal models (SCMs), TCMs are defined by a
collection of functions, each defining a ``local autonomous" causal mechanism
that assemble to induce a unique global function from exogenous to endogenous
variables. Since the category of TCMs is (co)complete, which we prove in this
paper, every causal diagram has a ``solution" in the form of a (co)limit: this
implies that any arbitrary causal model can be ``approximated" by some global
function with respect to the morphisms going into or out of the diagram.
Natural transformations are crucial in measuring the quality of approximation.
In addition, we show that causal interventions are modeled by subobject
classifiers: any sub-model is defined by a monic arrow into its parent model.
Exponential objects permit reasoning about entire classes of causal
equivalences and interventions. Finally, as TCMs form a topos, they admit an
internal logic defined as a Mitchell-Benabou language with an associated
Kripke-Joyal semantics. We show how to reason about causal models in TCMs using
this internal logic.

</details>


### [275] [Diminution: On Reducing the Size of Grounding ASP Programs](https://arxiv.org/abs/2508.08633)
*HuanYu Yang,Fengming Zhu,YangFan Wu,Jianmin Ji*

Main category: cs.AI

TL;DR: A new method called 'diminution' uses a subset of the Herbrand universe to reduce the size of ground programs in ASP, significantly improving performance and reducing grounding time and file size.


<details>
  <summary>Details</summary>
Motivation: ASP is often hindered by the grounding bottleneck, where large Herbrand universes lead to excessively large ground programs, making solving difficult. This necessitates a more formal and generalizable strategy beyond ad-hoc heuristics.

Method: Introduce the notion of diminution, defined as a selected subset of the Herbrand universe used to generate a reduced ground program before solving. Formally define diminution, analyze its properties, and study the complexity of identifying it. Utilize a specific encoding that allows existing ASP solvers to evaluate candidate subsets, integrating seamlessly with current grounders via domain predicates.

Result: Extensive experiments on five benchmarks demonstrate that applying diminutions selected by the proposed strategy leads to significant performance improvements. Specifically, grounding time is reduced by up to 70% on average, and the size of grounding files decreases by up to 85%.

Conclusion: The proposed diminution strategy, implemented through a specific encoding and evaluated using off-the-shelf ASP solvers, offers a robust and general-purpose approach to alleviate the grounding bottleneck in Answer Set Programming (ASP). Extensive experiments show significant performance improvements, with reductions in grounding time of up to 70% and grounding file sizes of up to 85% on average across five benchmarks.

Abstract: Answer Set Programming (ASP) is often hindered by the grounding bottleneck:
large Herbrand universes generate ground programs so large that solving becomes
difficult. Many methods employ ad-hoc heuristics to improve grounding
performance, motivating the need for a more formal and generalizable strategy.
We introduce the notion of diminution, defined as a selected subset of the
Herbrand universe used to generate a reduced ground program before solving. We
give a formal definition of diminution, analyze its key properties, and study
the complexity of identifying it. We use a specific encoding that enables
off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates
seamlessly with existing grounders via domain predicates. In extensive
experiments on five benchmarks, applying diminutions selected by our strategy
yields significant performance improvements, reducing grounding time by up to
70% on average and decreasing the size of grounding files by up to 85%. These
results demonstrate that leveraging diminutions constitutes a robust and
general-purpose approach for alleviating the grounding bottleneck in ASP.

</details>


### [276] [An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes](https://arxiv.org/abs/2508.08297)
*Rodrigo Lankaites Pinheiro,Dario Landa-Silva,Wasakorn Laesanklang,Ademir Aparecido Constantino*

Main category: cs.AI

TL;DR: 本研究提出了一种新方法，通过结合使用昂贵的多目标算法和一个实例和高效的目标规划来解决具有相似特征的多个问题实例，从而在多目标优化中取得更好的效率和结果。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界的应用要求决策者在考虑多个相互冲突的目标时评估解决方案的质量。即使对于现代多目标算法，获得高度约束的多目标问题的良好近似集也可能很困难。在某些情况下，问题场景的多个实例在其适应度景观中表现出相似性。

Method: 提出了一种利用目标规划和高效单目标算法来解决具有相似适应度景观的多实例问题的方法，首先使用计算成本较高的多目标算法解决一个实例以获得近似集，然后解决同一问题场景的其他实例。

Result: 所提出的方法在多目标车辆路径问题带时间窗的基准实例上，能够在短时间内产生良好的结果，证明了其有效性。

Conclusion: 该方法结合了最先进的多目标算法和目标规划的效率，能够为具有相似适应度景观的问题场景找到好的折衷解决方案。

Abstract: Many real-world applications require decision-makers to assess the quality of
solutions while considering multiple conflicting objectives. Obtaining good
approximation sets for highly constrained many-objective problems is often a
difficult task even for modern multiobjective algorithms. In some cases,
multiple instances of the problem scenario present similarities in their
fitness landscapes. That is, there are recurring features in the fitness
landscapes when searching for solutions to different problem instances. We
propose a methodology to exploit this characteristic by solving one instance of
a given problem scenario using computationally expensive multiobjective
algorithms to obtain a good approximation set and then using Goal Programming
with efficient single-objective algorithms to solve other instances of the same
problem scenario. We use three goal-based objective functions and show that on
benchmark instances of the multiobjective vehicle routing problem with time
windows, the methodology is able to produce good results in short computation
time. The methodology allows to combine the effectiveness of state-of-the-art
multiobjective algorithms with the efficiency of goal programming to find good
compromise solutions in problem scenarios where instances have similar fitness
landscapes.

</details>


### [277] [LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models](https://arxiv.org/abs/2508.08300)
*Yongchao Huang*

Main category: cs.AI

TL;DR: LLM可用于自动化贝叶斯推断中的先验和似然性规范，简化贝叶斯建模过程。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯推断的广泛应用受到先验分布和似然性规范的限制，这通常需要专门的统计知识。本研究旨在探索使用大型语言模型（LLM）自动执行此过程的可行性。

Method: 提出LLM-BI（大型语言模型驱动的贝叶斯推断）概念流水线，并通过两个关于贝叶斯线性回归的实验进行概念验证。

Result: 实验证明，LLM可以根据自然语言获取先验分布，并根据高级问题描述指定整个模型结构（包括先验和似然性）。

Conclusion: LLM有潜力自动化贝叶斯建模的关键步骤，为概率编程实现自动化推理流水线提供了可能性。

Abstract: A significant barrier to the widespread adoption of Bayesian inference is the
specification of prior distributions and likelihoods, which often requires
specialized statistical expertise. This paper investigates the feasibility of
using a Large Language Model (LLM) to automate this process. We introduce
LLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline
for automating Bayesian workflows. As a proof-of-concept, we present two
experiments focused on Bayesian linear regression. In Experiment I, we
demonstrate that an LLM can successfully elicit prior distributions from
natural language. In Experiment II, we show that an LLM can specify the entire
model structure, including both priors and the likelihood, from a single
high-level problem description. Our results validate the potential of LLMs to
automate key steps in Bayesian modeling, enabling the possibility of an
automated inference pipeline for probabilistic programming.

</details>


### [278] [First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models](https://arxiv.org/abs/2508.08308)
*Chuanruo Fu,Yuncheng Du*

Main category: cs.AI

TL;DR: FATA是一种新的交互范式，让LLM先问用户补充问题，再根据用户回答给出更准确的答案，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在面对不完整或不明确的用户信息时，难以提供准确、可操作答案的问题。

Method: 提出了一种名为First Ask Then Answer (FATA)的交互范式，引导LLM在回答前主动生成补充问题，然后整合用户回答以提升回答质量。

Result: FATA在多领域基准测试中，相比基线提示（B-Prompt）平均提高了约40%的聚合指标，并且其变异系数比上下文增强型专家提示（C-Prompt）低8%，显示出更优越的稳定性。

Conclusion: FATA通过引导LLM主动生成多维度补充问题，再整合用户提供的信息，显著提高了回答的质量和相关性。它强调完整性、用户参与和单轮策略，通过LLM的推理能力帮助非专业用户构建更全面的查询。

Abstract: Large Language Models (LLMs) often struggle to deliver accurate and
actionable answers when user-provided information is incomplete or
ill-specified. We propose a new interaction paradigm, First Ask Then Answer
(FATA), in which, through prompt words, LLMs are guided to proactively generate
multidimensional supplementary questions for users prior to response
generation. Subsequently, by integrating user-provided supplementary
information with the original query through sophisticated prompting techniques,
we achieve substantially improved response quality and relevance. In contrast
to existing clarification approaches -- such as the CLAM framework oriented to
ambiguity and the self-interrogation Self-Ask method -- FATA emphasizes
completeness (beyond mere disambiguation) and user participation (inviting
human input instead of relying solely on model-internal reasoning). It also
adopts a single-turn strategy: all clarifying questions are produced at once,
thereby reducing dialogue length and improving efficiency. Conceptually, FATA
uses the reasoning power of LLMs to scaffold user expression, enabling
non-expert users to formulate more comprehensive and contextually relevant
queries. To evaluate FATA, we constructed a multi-domain benchmark and compared
it with two controls: a baseline prompt (B-Prompt) and a context-enhanced
expert prompt (C-Prompt). Experimental results show that FATA outperforms
B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient
of variation 8% lower than C-Prompt, indicating superior stability.

</details>


### [279] [What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge](https://arxiv.org/abs/2508.08344)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: KG-RAG在知识不全时推理能力弱，依赖记忆，泛化能力不一。本研究提出新的评估方法来系统性评估此问题。


<details>
  <summary>Details</summary>
Motivation: 当前的KG-RAG评估方法存在不足：现有基准测试中的问题往往可以直接从知识图谱的三元组中检索到答案，这使得模型是在进行推理还是仅仅检索答案变得不清楚。此外，不一致的评估指标和宽松的答案匹配标准进一步阻碍了有意义的比较。

Method: 提出了一种通用的基准测试构建方法和评估协议，以在知识不完整的情况下系统地评估KG-RAG方法。

Result: 实证结果表明，现有KG-RAG方法在知识缺失的情况下推理能力有限，并且在很大程度上依赖于内部记忆，其泛化能力也因设计而异。

Conclusion: 现有KG-RAG方法在知识不完整的情况下推理能力有限，并且在很大程度上依赖于内部记忆。不同KG-RAG方法在泛化能力上也存在差异，具体取决于其设计。

Abstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an
increasingly explored approach for combining the reasoning capabilities of
large language models with the structured evidence of knowledge graphs.
However, current evaluation practices fall short: existing benchmarks often
include questions that can be directly answered using existing triples in KG,
making it unclear whether models perform reasoning or simply retrieve answers
directly. Moreover, inconsistent evaluation metrics and lenient answer matching
criteria further obscure meaningful comparisons. In this work, we introduce a
general method for constructing benchmarks, together with an evaluation
protocol, to systematically assess KG-RAG methods under knowledge
incompleteness. Our empirical results show that current KG-RAG methods have
limited reasoning ability under missing knowledge, often rely on internal
memorization, and exhibit varying degrees of generalization depending on their
design.

</details>


### [280] [UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games](https://arxiv.org/abs/2508.08382)
*Timo Bertram*

Main category: cs.AI

TL;DR: UrzaGPT是一个针对卡牌游戏（如万智牌）进行优化的LLM，通过LoRA微调，能在卡牌选择方面取得比通用LLM更好的成绩，为未来开发易于更新的AI助手提供了可能。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在诸如万智牌之类的可收集卡牌游戏中表现不佳，因为它们具有部分可观测性、长期决策和不断变化的卡牌集等难题。

Method: 使用低秩适配（LoRA）对开源LLM进行微调，以处理带注释的草稿日志数据集，从而使LLM能够快速适应不同的游戏扩展。

Result: 与零样本LLM和特定领域模型相比，使用UrzaGPT进行微调的小型模型达到了66.2%的准确率，而GPT-4o的零样本准确率为43%。

Conclusion: 通过使用LLM进行草拟，可以实现高性能、通用且易于更新的草拟AI。

Abstract: Collectible card games (CCGs) are a difficult genre for AI due to their
partial observability, long-term decision-making, and evolving card sets. Due
to this, current AI models perform vastly worse than human players at CCG tasks
such as deckbuilding and gameplay. In this work, we introduce UrzaGPT, a
domain-adapted large language model that recommends real-time drafting
decisions in Magic: The Gathering. Starting from an open-weight LLM, we use
Low-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With
this, we leverage the language modeling capabilities of LLM, and can quickly
adapt to different expansions of the game. We benchmark UrzaGPT in comparison
to zero-shot LLMs and the state-of-the-art domain-specific model. Untuned,
small LLMs like Llama-3-8B are completely unable to draft, but the larger
GPT-4o achieves a zero-shot performance of 43%. Using UrzaGPT to fine-tune
smaller models, we achieve an accuracy of 66.2% using only 10,000 steps.
Despite this not reaching the capability of domain-specific models, we show
that solely using LLMs to draft is possible and conclude that using LLMs can
enable performant, general, and update-friendly drafting AIs in the future.

</details>


### [281] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: MCTS在经典规划中节点选择效率低下（O(log N)），因为搜索深度d很大。本文提出双层MCTS和树折叠技术，将节点选择时间降至摊销O(1)，提高了规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统的MCTS在节点扩展选择上存在效率瓶颈，尤其是在节点数量N很大且搜索深度d非常深（如经典规划问题）的情况下，其O(log N)的节点选择时间复杂度会成为显著的性能影响因素。

Method: 提出了一种双层MCTS修改方案，结合了从选定叶节点开始的最佳优先搜索，并为每个节点分配了与搜索深度d成比例的扩展预算，从而实现了摊销O(1)的节点选择运行时间。此外，还引入了“树折叠”技术以减少动作选择步骤并提升性能。

Result: 通过双层修改和树折叠技术，实现了节点选择的摊销O(1)运行时间，等同于传统的基于队列的开放列表，并显著提升了MCTS在经典规划问题上的性能。

Conclusion: 该研究提出了一种改进的多臂老虎机（MAB）蒙特卡洛树搜索（MCTS）算法，用于经典规划问题。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [282] [Solver-Aided Expansion of Loops to Avoid Generate-and-Test](https://arxiv.org/abs/2508.08442)
*Niklas Dewally,Özgür Akgün*

Main category: cs.AI

TL;DR: 提出了一种利用求解器优化循环展开的方法，提高了约束建模语言的编译效率。


<details>
  <summary>Details</summary>
Motivation: 传统的MiniZinc和Essence等约束建模语言在编译时需要展开循环（如量化表达式和推导式），这在大多数组合最终无关紧要时效率低下。

Method: 提出了一种避免完全枚举的新方法，利用求解器计算生成最终约束集所需的组合，而不是生成所有归纳变量组合并使用部分求值来消除冗余。

Result: 与传统的展平方法生成的模型相同，但编译速度显著提高。

Conclusion: 该方法通过使用求解器计算生成最终约束集所需的组合，避免了完全枚举，从而提高了将高级用户模型转换为求解器就绪形式的效率，特别适用于归纳变量在具有选择性先决条件的较大域上变化的情况。

Abstract: Constraint modelling languages like MiniZinc and Essence rely on unrolling
loops (in the form of quantified expressions and comprehensions) during
compilation. Standard approaches generate all combinations of induction
variables and use partial evaluation to discard those that simplify to identity
elements of associative-commutative operators (e.g. true for conjunction, 0 for
summation). This can be inefficient for problems where most combinations are
ultimately irrelevant. We present a method that avoids full enumeration by
using a solver to compute only the combinations required to generate the final
set of constraints. The resulting model is identical to that produced by
conventional flattening, but compilation can be significantly faster. This
improves the efficiency of translating high-level user models into solver-ready
form, particularly when induction variables range over large domains with
selective preconditions.

</details>


### [283] [OverFill: Two-Stage Models for Efficient Language Model Decoding](https://arxiv.org/abs/2508.08446)
*Woojeong Kim,Junxiong Wang,Jing Nathan Yan,Mohamed Abdelfattah,Alexander M. Rush*

Main category: cs.AI

TL;DR: LLM推理成本高，特别是长序列的解码延迟。OverFill将预填充（全模型）和解码（剪枝模型）分开，通过在预填充阶段增加计算量来优化延迟和准确率，相比同等大小剪枝模型有显著提升，且训练数据需求更少。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在部署时面临高昂的推理成本问题，尤其是在处理长序列时，解码阶段的延迟占主导地位。现有模型对计算特性不同的预填充和解码阶段采用统一的处理方式，未能充分优化效率。

Method: OverFill提出了一种新颖的LLM推理方法，将预填充（compute-bound）和解码（memory-bound）两个阶段分开处理。在预填充阶段，使用完整模型并行处理系统和用户输入；在解码阶段，切换到密集剪枝模型进行逐个标记的生成。

Result: 在3B-到1B的配置下，OverFill比1B剪枝模型在标准基准测试上的平均性能提高了83.2%。在8B-到3B的配置下，OverFill比3B剪枝模型平均性能提高了79.2%。OverFill在使用的训练数据量显著减少的情况下，其性能与从头开始训练的同等大小模型相当。

Conclusion: OverFill通过解耦预填充和解码阶段，在保持准确率的同时显著降低了LLM的推理成本，并提供了优于同等大小剪枝模型的性能。

Abstract: Large language models (LLMs) excel across diverse tasks but face significant
deployment challenges due to high inference costs. LLM inference comprises
prefill (compute-bound) and decode (memory-bound) stages, with decode
dominating latency particularly for long sequences. Current decoder-only models
handle both stages uniformly, despite their distinct computational profiles. We
propose OverFill, which decouples these stages to optimize accuracy-efficiency
tradeoffs. OverFill begins with a full model for prefill, processing system and
user inputs in parallel. It then switches to a dense pruned model, while
generating tokens sequentially. Leveraging more compute during prefill,
OverFill improves generation quality with minimal latency overhead. Our
3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while
the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average
across standard benchmarks. OverFill matches the performance of same-sized
models trained from scratch, while using significantly less training data. Our
code is available at https://github.com/friendshipkim/overfill.

</details>


### [284] [A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search](https://arxiv.org/abs/2508.08477)
*Joan Salvà Soler,Grégoire de Lambertye*

Main category: cs.AI

TL;DR: 该研究提出了一种基于GRASP的元启发式算法来解决触发弧旅行商问题（TA-TSP），该问题具有动态弧成本。算法结合了MIP技术和多种邻域搜索算子，在竞赛和合成数据集上均表现出色，证明了其在实时路线应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决触发弧旅行商问题（TA-TSP），该问题扩展了经典的TSP，引入了当遍历特定触发弧时会改变的动态弧成本，模拟了具有可压缩存储系统的仓库操作等场景。

Method: 提出了一种基于GRASP的元启发式算法，结合了多种构造启发式方法和多邻域局部搜索。构造阶段使用混合整数规划（MIP）技术将TA-TSP转化为一系列定制的TSP实例，改进阶段应用2-Opt、Swap和Relocate算子。

Result: 在MESS 2024竞赛实例上，算法在60秒限制内实现了0.77%和0.40%的平均最优间隙。在较小的合成数据集上，该方法产生的解决方案比同一时间限制下的Gurobi求解器好11.3%。

Conclusion: 该算法在MESS 2024竞赛实例上取得了0.77%和0.40%的最优间隙，在较小的合成数据集上比Gurobi求解器提高了11.3%，并且在MESS 2024中排名前三，证明了其在具有状态相关旅行成本的实时路线应用中的适用性。

Abstract: The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP
by introducing dynamic arc costs that change when specific \textit{trigger}
arcs are traversed, modeling scenarios such as warehouse operations with
compactable storage systems. This paper introduces a GRASP-based metaheuristic
that combines multiple construction heuristics with a multi-neighborhood local
search. The construction phase uses mixed-integer programming (MIP) techniques
to transform the TA-TSP into a sequence of tailored TSP instances, while the
improvement phase applies 2-Opt, Swap, and Relocate operators. Computational
experiments on MESS 2024 competition instances achieved average optimality gaps
of 0.77\% and 0.40\% relative to the best-known solutions within a 60-second
limit. On smaller, synthetically generated datasets, the method produced
solutions 11.3\% better than the Gurobi solver under the same time constraints.
The algorithm finished in the top three at MESS 2024, demonstrating its
suitability for real-time routing applications with state-dependent travel
costs.

</details>


### [285] [Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback](https://arxiv.org/abs/2508.08486)
*Parker Whitfill,Stewy Slocum*

Main category: cs.AI

TL;DR: LLM对齐需要评分数据而非排序数据。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM对齐技术依赖于排序或二元比较来收集偏好数据，但我们认为这种数据类型存在根本性缺陷，无法解决模型选择中的权衡问题。

Method: 我们收集了一个包含25,000个评分的数据集，这些评分是使用“支付意愿”方法获得的，并将其应用于偏好微调。

Result: 在偏好微调中加入评分反馈可以使模型优先改进关键问题，并在下游基准测试（如Arena-Hard）上优于仅使用排序反馈的方法。

Conclusion: LLM对齐技术需要优化基于偏好的目标，而这些偏好通常是通过对响应进行排序或二元选择来获取的。然而，仅依赖排序比较的方法无法系统地恢复最受偏好的模型，因为排序数据缺乏解决权衡问题的足够信息。为了解决这个问题，我们收集了一个包含25,000个评分的数据集，这些评分是使用经济学中的“支付意愿”方法获得的。实验结果表明，在偏好微调中加入评分反馈可以使模型优先改进关键问题，并在下游基准测试（如Arena-Hard）上优于仅使用排序反馈的方法。

Abstract: Alignment techniques for LLMs rely on optimizing preference-based objectives
-- where these preferences are typically elicited as ordinal, binary choices
between responses. Recent work has focused on improving label quality or
mitigating particular biases, but we identify a more fundamental limitation:
these methods collect the wrong kind of data. We prove an impossibility result:
no algorithm relying solely on ordinal comparisons can systematically recover
the most preferred model. Intuitively, ordinal data lacks the information
needed to resolve tradeoffs -- e.g., fixing a factual error on one prompt
versus improving style on another. We show that selecting the optimal model
requires recovering preferences over \emph{models} (rather than just
responses), which can only be identified given cardinal feedback about response
quality. To address this, we collect and publicly release a dataset of 25,000
cardinal judgments using willingness-to-pay elicitations, a well-established
tool from experimental economics. Empirically, we find that incorporating
cardinal feedback into preference fine-tuning allows models to prioritize
high-impact improvements and outperform ordinal-only methods on downstream
benchmarks, such as Arena-Hard.

</details>


### [286] [POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08493)
*Szymon Jakubicz,Karol Kuźniak,Jan Wawszczak,Paweł Gora*

Main category: cs.AI

TL;DR: POMO+ 通过利用初始节点来改进基于RL的车辆路径问题模型，在CVRPLIB数据集上显示出更快的收敛速度和更好的结果。


<details>
  <summary>Details</summary>
Motivation: 在包括车辆路径问题（VRP）变体在内的多种任务上，基于RL的模型POMO表现出了强大的性能，但仍有改进的空间。

Method: 我们改进了POMO，创建了一种利用初始节点以更具信息量的方式找到解决方案的方法（POMO+）。

Result: 我们对新模型进行了实验，观察到我们的解决方案收敛速度更快，并且取得了更好的结果。我们在CVRPLIB数据集上验证了我们的模型，并注意到在客户数量高达100个的问题实例中有所改进。

Conclusion: 我们希望我们在此项目中的研究能够为该领域带来进一步的进步。

Abstract: In recent years, reinforcement learning (RL) methods have emerged as a
promising approach for solving combinatorial problems. Among RL-based models,
POMO has demonstrated strong performance on a variety of tasks, including
variants of the Vehicle Routing Problem (VRP). However, there is room for
improvement for these tasks. In this work, we improved POMO, creating a method
(\textbf{POMO+}) that leverages the initial nodes to find a solution in a more
informed way. We ran experiments on our new model and observed that our
solution converges faster and achieves better results. We validated our models
on the CVRPLIB dataset and noticed improvements in problem instances with up to
100 customers. We hope that our research in this project can lead to further
advancements in the field.

</details>


### [287] [Large Language Models as Oracles for Ontology Alignment](https://arxiv.org/abs/2508.08500)
*Sviatoslav Lushnei,Dmytro Shumskyi,Severyn Shykula,Ernesto Jimenez-Ruiz,Artur d'Avila Garcez*

Main category: cs.AI

TL;DR: LLMs show promise as a cost-effective alternative to human experts for validating uncertain ontology alignments, with performance evaluated against simulated oracles.


<details>
  <summary>Details</summary>
Motivation: To address the challenges in producing high-quality correspondences in ontology alignment and reduce the cost of human involvement by using LLMs for validation where systems are uncertain.

Method: The study evaluates the performance of state-of-the-art LLMs using different ontology-driven prompt templates on OAEI matching tasks.

Result: The paper analyzes the performance of LLMs against simulated oracles with variable error rates on several OAEI matching tasks.

Conclusion: The paper explores the feasibility of using LLMs as an alternative to domain experts for validating uncertain correspondences in ontology alignment, comparing LLM performance against simulated oracles.

Abstract: Ontology alignment plays a crucial role in integrating diverse data sources
across domains. There is a large plethora of systems that tackle the ontology
alignment problem, yet challenges persist in producing highly quality
correspondences among a set of input ontologies. Human-in-the-loop during the
alignment process is essential in applications requiring very accurate
mappings. User involvement is, however, expensive when dealing with large
ontologies. In this paper, we explore the feasibility of using Large Language
Models (LLM) as an alternative to the domain expert. The use of the LLM focuses
only on the validation of the subset of correspondences where an ontology
alignment system is very uncertain. We have conducted an extensive evaluation
over several matching tasks of the Ontology Alignment Evaluation Initiative
(OAEI), analysing the performance of several state-of-the-art LLMs using
different ontology-driven prompt templates. The LLM results are also compared
against simulated Oracles with variable error rates.

</details>


### [288] [GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games](https://arxiv.org/abs/2508.08501)
*Yuchen Li,Cong Lin,Muhammad Umair Nasir,Philip Bontrager,Jialin Liu,Julian Togelius*

Main category: cs.AI

TL;DR: GVGAI-LLM是一个新的视频游戏基准测试，用于评估LLM在空间推理和规划方面的能力。它发现现有LLM存在局限性，并激发了新的研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型（LLM）的推理和解决问题能力，并解决现有LLM基准测试中缺乏多样性以及模型在空间推理和基本规划方面的局限性。

Method: GVGAI-LLM基准测试基于通用视频游戏AI框架，利用游戏描述语言，并使用ASCII字符表示游戏场景，通过有意义的步数比、步数效率和总分等可解释指标评估模型行为。

Result: 零样本评估显示，当前LLM在空间推理和基本规划方面存在持续的局限性，表现出空间和逻辑错误。结构化提示和空间接地技术可以带来部分改进，但仍有很大提升空间。

Conclusion: GVGAI-LLM基准测试揭示了LLM在空间推理和基本规划方面存在持续的局限性，尽管结构化提示和空间接地技术可以带来部分改进，但该基准仍远未被解决。该基准测试为推进语言模型能力研究提供了一个可重现的试验台，特别强调了代理行为和上下文推理。

Abstract: We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning
and problem-solving capabilities of large language models (LLMs). Built on the
General Video Game AI framework, it features a diverse collection of
arcade-style games designed to test a model's ability to handle tasks that
differ from most existing LLM benchmarks. The benchmark leverages a game
description language that enables rapid creation of new games and levels,
helping to prevent overfitting over time. Each game scene is represented by a
compact set of ASCII characters, allowing for efficient processing by language
models. GVGAI-LLM defines interpretable metrics, including the meaningful step
ratio, step efficiency, and overall score, to assess model behavior. Through
zero-shot evaluations across a broad set of games and levels with diverse
challenges and skill depth, we reveal persistent limitations of LLMs in spatial
reasoning and basic planning. Current models consistently exhibit spatial and
logical errors, motivating structured prompting and spatial grounding
techniques. While these interventions lead to partial improvements, the
benchmark remains very far from solved. GVGAI-LLM provides a reproducible
testbed for advancing research on language model capabilities, with a
particular emphasis on agentic behavior and contextual reasoning.

</details>


### [289] [SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering](https://arxiv.org/abs/2508.08529)
*Arshia Ilaty,Hossein Shirazi,Hajar Homayouni*

Main category: cs.AI

TL;DR: SynLLM框架利用LLM和结构化提示生成合成医疗数据，并在统计保真度、临床一致性和隐私保护方面进行了全面评估。结果显示，基于规则的提示在隐私和质量之间取得了最佳平衡，表明LLM在医疗数据共享方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 医疗数据的访问因隐私法规而受到限制，阻碍了医疗研究的进步。合成数据是一个有前景的替代方案；然而，生成逼真、临床有效且注重隐私的记录仍然是一个重大挑战。现有的LLM方法在系统提示策略和全面的、多维度的评估框架方面存在不足。

Method: 提出了一种名为SynLLM的模块化框架，使用20种先进的开源LLM（包括LLaMA、Mistral和GPT变体），通过结构化提示来生成高质量的合成医疗表格数据。提出了四种不同的提示类型，从示例驱动到基于规则的约束，对模式、元数据和领域知识进行编码，以在不进行模型微调的情况下控制生成。该框架包含一个全面的评估流程，对生成数据的统计保真度、临床一致性和隐私保护进行了严格评估。

Result: 在Diabetes、Cirrhosis和Stroke三个公共医疗数据集上，使用20个开源LLM对SynLLM进行了评估。结果表明，提示工程对数据质量和隐私风险有显著影响，其中基于规则的提示在隐私-质量平衡方面表现最佳。

Conclusion: LLMs在精心设计的提示和鲁棒的多指标标准指导和评估下，能够生成既有临床合理性又考虑隐私的合成医疗数据，为医疗研究中更安全、更有效的数据共享铺平了道路。

Abstract: Access to real-world medical data is often restricted due to privacy
regulations, posing a significant barrier to the advancement of healthcare
research. Synthetic data offers a promising alternative; however, generating
realistic, clinically valid, and privacy-conscious records remains a major
challenge. Recent advancements in Large Language Models (LLMs) offer new
opportunities for structured data generation; however, existing approaches
frequently lack systematic prompting strategies and comprehensive,
multi-dimensional evaluation frameworks.
  In this paper, we present SynLLM, a modular framework for generating
high-quality synthetic medical tabular data using 20 state-of-the-art
open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by
structured prompts. We propose four distinct prompt types, ranging from
example-driven to rule-based constraints, that encode schema, metadata, and
domain knowledge to control generation without model fine-tuning. Our framework
features a comprehensive evaluation pipeline that rigorously assesses generated
data across statistical fidelity, clinical consistency, and privacy
preservation.
  We evaluate SynLLM across three public medical datasets, including Diabetes,
Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt
engineering significantly impacts data quality and privacy risk, with
rule-based prompts achieving the best privacy-quality balance. SynLLM
establishes that, when guided by well-designed prompts and evaluated with
robust, multi-metric criteria, LLMs can generate synthetic medical data that is
both clinically plausible and privacy-aware, paving the way for safer and more
effective data sharing in healthcare research.

</details>


### [290] [AgriGPT: a Large Language Model Ecosystem for Agriculture](https://arxiv.org/abs/2508.08632)
*Bo Yang,Yu Zhang,Lanfei Feng,Yunkui Chen,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Yurui Li,Yuxuan Chen,Guijun Yang,Yong He,Runhe Huang,Shijian Li*

Main category: cs.AI

TL;DR: AgriGPT是面向农业领域的LLM生态系统，通过高质量数据集和先进的Tri-RAG框架，提升了模型在农业问答和推理方面的表现，并提供了全面的评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在农业领域的应用受限于缺乏领域特定模型、数据集和评估框架。AgriGPT旨在解决这些挑战，以支持广泛的农业利益相关者。

Method: AgriGPT采用多智能体可扩展数据引擎构建了Agri-342K数据集，并结合了密集检索、稀疏检索和多跳知识图谱推理的三通道检索增强生成（Tri-RAG）框架。同时，引入了AgriBench-13K基准套件进行评估。

Result: AgriGPT在领域适应性和推理方面显著优于通用LLM，并构成了一个包含数据构建、检索增强生成和领域特定评估的模块化、可扩展的LLM生态系统。

Conclusion: AgriGPT是一个专门为农业领域设计的LLM生态系统，通过构建高质量数据集（Agri-342K）和采用Tri-RAG框架，显著提升了LLM在农业领域的应用能力和推理可靠性。AgriGPT在领域适应性和推理方面优于通用LLM，为开发特定领域的LLM提供了一个可推广的框架。

Abstract: Despite the rapid progress of Large Language Models (LLMs), their application
in agriculture remains limited due to the lack of domain-specific models,
curated datasets, and robust evaluation frameworks. To address these
challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for
agricultural usage. At its core, we design a multi-agent scalable data engine
that systematically compiles credible data sources into Agri-342K, a
high-quality, standardized question-answer (QA) dataset. Trained on this
dataset, AgriGPT supports a broad range of agricultural stakeholders, from
practitioners to policy-makers. To enhance factual grounding, we employ
Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining
dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning,
thereby improving the LLM's reasoning reliability. For comprehensive
evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks
with varying types and complexities. Experiments demonstrate that AgriGPT
significantly outperforms general-purpose LLMs on both domain adaptation and
reasoning. Beyond the model itself, AgriGPT represents a modular and extensible
LLM ecosystem for agriculture, comprising structured data construction,
retrieval-enhanced generation, and domain-specific evaluation. This work
provides a generalizable framework for developing scientific and
industry-specialized LLMs. All models, datasets, and code will be released to
empower agricultural communities, especially in underserved regions, and to
promote open, impactful research.

</details>


### [291] [P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records](https://arxiv.org/abs/2508.08646)
*Naama Kashani,Mira Cohen,Uri Shaham*

Main category: cs.AI

TL;DR: A new method for selecting features from electronic health records that is personalized, learns over time, and considers costs, helping doctors make better decisions efficiently.


<details>
  <summary>Details</summary>
Motivation: Traditional feature selection methods struggle with the sparsity, heterogeneity, and patient-specific variations of EHR data, and the need to account for feature costs in clinical applications.

Method: A novel personalized, online, and cost-aware feature selection framework tailored for EHR datasets, incorporating budgetary constraints and feature variability costs for incremental feature acquisition.

Result: The framework is designed for robust and scalable performance in diverse healthcare contexts, aiming to guide physicians toward incremental acquisition of informative features within budget constraints.

Conclusion: The proposed framework offers a novel approach to feature selection for EHR data, addressing sparsity, heterogeneity, and cost-awareness in an online and personalized manner. It aims to improve diagnostic confidence and resource utilization in clinical decision-making, particularly in patient screening.

Abstract: Electronic Health Records (EHR) have revolutionized healthcare by digitizing
patient data, improving accessibility, and streamlining clinical workflows.
However, extracting meaningful insights from these complex and multimodal
datasets remains a significant challenge for researchers. Traditional feature
selection methods often struggle with the inherent sparsity and heterogeneity
of EHR data, especially when accounting for patient-specific variations and
feature costs in clinical applications. To address these challenges, we propose
a novel personalized, online and cost-aware feature selection framework
tailored specifically for EHR datasets. The features are aquired in an online
fashion for individual patients, incorporating budgetary constraints and
feature variability costs. The framework is designed to effectively manage
sparse and multimodal data, ensuring robust and scalable performance in diverse
healthcare contexts. A primary application of our proposed method is to support
physicians' decision making in patient screening scenarios. By guiding
physicians toward incremental acquisition of the most informative features
within budget constraints, our approach aims to increase diagnostic confidence
while optimizing resource utilization.

</details>


### [292] [Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training](https://arxiv.org/abs/2508.08652)
*Vishakha Lall,Yisi Liu*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Prompt-and-Check的方法，利用本地运行的开源LLM（如LLama和Mistral）通过提示来评估模拟培训中程序性沟通的合规性。实验证明，该方法无需特定任务的训练即可进行有效的上下文推理，并可用于增强培训中的反馈和评估。


<details>
  <summary>Details</summary>
Motivation: 为了在模拟培训中准确评估程序性沟通合规性，特别是在安全关键领域，遵守合规性清单反映了操作能力。

Method: 提出了一种名为Prompt-and-Check的轻量级、可部署的方法，该方法使用基于提示的推理和开源LLM，并能在消费级GPU上高效运行。通过为每个清单项目提供包含相关对话片段的提示，并仅基于转录的口头交流来评估协议是否满足了每个清单项目。

Result: 在航海领域的案例研究中，使用LLama 2 7B、LLaMA 3 8B和Mistral 7B模型在RTX 4070 GPU上运行。模型输出与专家注释的地面实况进行了比较，评估了分类准确性和一致性分数。

Conclusion: LLM的提示可以有效地进行上下文推理，而无需针对特定任务进行训练。本研究强调了LLM在培训环境中增强汇报、绩效反馈和自动化评估的实用性。

Abstract: Accurate evaluation of procedural communication compliance is essential in
simulation-based training, particularly in safety-critical domains where
adherence to compliance checklists reflects operational competence. This paper
explores a lightweight, deployable approach using prompt-based inference with
open-source large language models (LLMs) that can run efficiently on
consumer-grade GPUs. We present Prompt-and-Check, a method that uses
context-rich prompts to evaluate whether each checklist item in a protocol has
been fulfilled, solely based on transcribed verbal exchanges. We perform a case
study in the maritime domain with participants performing an identical
simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and
Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a
prompt incorporating relevant transcript excerpts is fed into the model, which
outputs a compliance judgment. We assess model outputs against expert-annotated
ground truth using classification accuracy and agreement scores. Our findings
demonstrate that prompting enables effective context-aware reasoning without
task-specific training. This study highlights the practical utility of LLMs in
augmenting debriefing, performance feedback, and automated assessment in
training environments.

</details>


### [293] [Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08659)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux,Daniele Vigo*

Main category: cs.AI

TL;DR: 通过结合图神经网络和大型邻域搜索，提出了一种新的混合优化方法来解决CVRP问题，该方法提高了解决方案的质量和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 旨在加强元启发式算法在解决带容量车辆路径问题（CVRP）方面的性能。

Method: 提出了一种迭代学习混合优化求解器，集成了节点破坏模型（一种利用图神经网络GNN的机器学习混合模型）来指导大邻域搜索（LNS）算子，以解决带容量车辆路径问题（CVRP）。

Result: 该方法减少了操作复杂性，缩小了优化过程的搜索空间，提高了解决方案质量，并证明了其在大规模实例上的可扩展性。

Conclusion: 该混合优化方法能够提升基线元启发式算法的性能，在标准CVRP基准测试中提高了解决方案质量，并且在大规模实例（多达30,000个客户节点）上证明了其可扩展性。实验评估表明，该方法能够改进不同的基线算法，在相似设置下达到更好的解决方案质量。

Abstract: In this research, we propose an iterative learning hybrid optimization solver
developed to strengthen the performance of metaheuristic algorithms in solving
the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism
integrates the proposed Node-Destroyer Model, a machine learning hybrid model
that utilized Graph Neural Networks (GNNs) such identifies and selects customer
nodes to guide the Large Neighborhood Search (LNS) operator within the
metaheuristic optimization frameworks. This model leverages the structural
properties of the problem and solution that can be represented as a graph, to
guide strategic selections concerning node removal. The proposed approach
reduces operational complexity and scales down the search space involved in the
optimization process. The hybrid approach is applied specifically to the CVRP
and does not require retraining across problem instances of different sizes.
The proposed hybrid mechanism is able to improve the performance of baseline
metaheuristic algorithms. Our approach not only enhances the solution quality
for standard CVRP benchmarks but also proves scalability on very large-scale
instances with up to 30,000 customer nodes. Experimental evaluations on
benchmark datasets show that the proposed hybrid mechanism is capable of
improving different baseline algorithms, achieving better quality of solutions
under similar settings.

</details>


### [294] [Aryabhata: An exam-focused language model for JEE Math](https://arxiv.org/abs/2508.08665)
*Ritvik Rastogi,Sachin Dharashivkar,Sandeep Varma*

Main category: cs.AI

TL;DR: Aryabhata 1.0 是一个 7B 参数的数学推理模型，针对 JEE 考试进行了优化。它在准确性和效率方面优于现有模型，并提供逐步推理。它通过 SFT 和 RLVR 进行训练，并在 JEE、MATH 和 GSM8K 基准测试中进行了评估。PW 发布了 Aryabhata 以供社区反馈，并正在培训未来的模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）取得了快速进展，但目前的模型通常不适合教育用途。

Method: Aryabhata 1.0 是通过合并强大的开放权重推理模型构建的，然后使用经过验证的链式思维 (CoT) 跟踪进行监督微调（SFT），并通过 $n$ 个最佳的拒绝采样进行管理。我们还应用了具有可验证奖励（RLVR）的强化学习，并采用了新颖的探索策略，如自适应组大小调整和温度缩放。

Result: 在分布内（JEE Main 2025）和分布外（MATH、GSM8K）基准测试中，Aryabhata 在准确性和效率方面均优于现有模型，并提供有益的逐步推理。

Conclusion: Aryabhata 1.0 在准确性和效率方面优于现有模型，并提供有益的逐步推理。我们发布 Aryabhata 作为基础模型，以推进以考试为中心、开源的小型语言模型。

Abstract: We present Aryabhata 1.0, a compact 7B parameter math reasoning model
optimized for the Indian academic exam, the Joint Entrance Examination (JEE).
Despite rapid progress in large language models (LLMs), current models often
remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong
open-weight reasoning models, followed by supervised fine-tuning (SFT) with
curriculum learning on verified chain-of-thought (CoT) traces curated through
best-of-$n$ rejection sampling. To further boost performance, we apply
reinforcement learning with verifiable rewards (RLVR) using A2C objective with
group-relative advantage estimation along with novel exploration strategies
such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both
in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K)
benchmarks, Aryabhata outperforms existing models in accuracy and efficiency,
while offering pedagogically useful step-by-step reasoning. We release
Aryabhata as a foundation model to advance exam-centric, open-source small
language models. This marks our first open release for community feedback
(https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training
future models to further improve learning outcomes for students.

</details>


### [295] [STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision](https://arxiv.org/abs/2508.08688)
*Chen Li,Han Zhang,Zhantao Yang,Fangyi Chen,Zihan Wang,Anudeepsekhar Bolimera,Marios Savvides*

Main category: cs.AI

TL;DR: STELAR-Vision 是一种新的训练框架，通过拓扑感知推理和精简输出，提高了视觉语言模型的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLMs）在处理复杂多模态任务时存在不足，并且输出冗长。现有模型过度依赖链式思考（CoT）推理，而忽略了其他有益的拓扑结构（如树或图）。

Method: STELAR-Vision 框架，包括 TopoAug（用于生成多样化拓扑结构的合成数据）和 Frugal Learning（用于在不牺牲准确性的情况下缩短输出长度）。该框架通过监督微调和强化学习对 Qwen2VL 模型进行后训练。

Result: STELAR-Vision 在 MATH-V 和 VLM-S2H 上比基础模型提高了 9.7% 的准确性，并比 Qwen2VL-72B-Instruct 提高了 7.3%。在五个 out-of-distribution 基准测试中，它在某些任务上比 Phi-4-Multimodal-Instruct 高出 28.4%，比 LLaMA-3.2-11B-Vision-Instruct 高出 13.2%。与 Chain-Only 训练相比，STELAR-Vision 在 in-distribution 数据集上整体准确性提高了 4.3%，并在所有 OOD 基准测试中表现优异。

Conclusion: STELAR-Vision 通过 TopoAug 增强训练数据，引入拓扑感知推理，并结合 Frugal Learning 优化输出长度，在 MATH-V 和 VLM-S2H 基准测试中显著提高了准确性，并在多个 out-of-distribution 任务上表现出强大的泛化能力，优于现有模型。

Abstract: Vision-language models (VLMs) have made significant strides in reasoning, yet
they often struggle with complex multimodal tasks and tend to generate overly
verbose outputs. A key limitation is their reliance on chain-of-thought (CoT)
reasoning, despite many tasks benefiting from alternative topologies like trees
or graphs. To address this, we introduce STELAR-Vision, a training framework
for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline
that enriches training with diverse topological structures. Using supervised
fine-tuning and reinforcement learning, we post-train Qwen2VL models with both
accuracy and efficiency in mind. Additionally, we propose Frugal Learning,
which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H,
STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the
larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it
outperforms Phi-4-Multimodal-Instruct by up to 28.4% and
LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong
generalization. Compared to Chain-Only training, our approach achieves 4.3%
higher overall accuracy on in-distribution datasets and consistently
outperforms across all OOD benchmarks. We have released datasets, and code will
be available.

</details>


### [296] [Simulating Generative Social Agents via Theory-Informed Workflow Design](https://arxiv.org/abs/2508.08726)
*Yuwei Yan,Jinghua Piao,Xiaochong Lan,Chenyang Shao,Pan Hui,Yong Li*

Main category: cs.AI

TL;DR: 提出了一种基于社会认知理论的 LLM 社会代理框架，包含动机、行动规划和学习模块，以提高代理的泛化能力和行为真实性。实验结果表明，该框架在复杂条件下能显著减少与真实行为数据的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 LLM 的代理大多是为特定场景设计的，缺乏统一的框架来指导其设计，这限制了它们在不同社会情境下的泛化能力和行为的一致性与真实性。

Method: 提出了一种理论驱动的框架，该框架基于社会认知理论，包含动机、行动规划和学习三个关键模块，用于指导基于 LLM 的社会代理的设计。

Result: 所提出的框架能够使 LLM 代理在复杂条件下重现现实的人类行为模式，在多个保真度指标上，与经典生成基线相比，偏差最多可降低 75%。此外，消融研究表明，移除动机、规划或学习模块会使错误增加 1.5 到 3.2 倍。

Conclusion: 该框架通过整合动机、行动规划和学习模块，使 LLM 代理能够更好地适应复杂环境并展现出更真实、更连贯的社会行为。实验证明，与传统生成模型相比，该框架能显著减少与真实世界行为数据的偏差。

Abstract: Recent advances in large language models have demonstrated strong reasoning
and role-playing capabilities, opening new opportunities for agent-based social
simulations. However, most existing agents' implementations are
scenario-tailored, without a unified framework to guide the design. This lack
of a general social agent limits their ability to generalize across different
social contexts and to produce consistent, realistic behaviors. To address this
challenge, we propose a theory-informed framework that provides a systematic
design process for LLM-based social agents. Our framework is grounded in
principles from Social Cognition Theory and introduces three key modules:
motivation, action planning, and learning. These modules jointly enable agents
to reason about their goals, plan coherent actions, and adapt their behavior
over time, leading to more flexible and contextually appropriate responses.
Comprehensive experiments demonstrate that our theory-driven agents reproduce
realistic human behavior patterns under complex conditions, achieving up to 75%
lower deviation from real-world behavioral data across multiple fidelity
metrics compared to classical generative baselines. Ablation studies further
show that removing motivation, planning, or learning modules increases errors
by 1.5 to 3.2 times, confirming their distinct and essential contributions to
generating realistic and coherent social behaviors.

</details>


### [297] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 提出了一种新的AR代理框架，通过集成记忆模块来解决现有AR代理在处理复杂、多步骤任务时遇到的问题，从而实现更个性化和上下文感知的用户体验。


<details>
  <summary>Details</summary>
Motivation: 当前AR代理在支持需要用户长期经验和偏好的复杂多步骤场景时存在不足，因为它们无法捕捉、保留和推理时空背景下的历史用户交互。

Method: 提出了一个包含感知模块、记忆模块、时空推理模块和执行器模块的记忆增强型AR代理概念框架，以解决现有AR代理在捕捉、保留和推理时空背景下的历史用户交互方面的不足。

Result: 提出了一种概念框架，包含四个相互关联的模块（感知、记忆、时空推理、执行器），并展示了其实施路线图、评估策略、目标应用和用例，以证明其跨不同领域的实际适用性。

Conclusion: 该框架旨在通过学习和适应用户的特定经验来提供个性化的任务辅助，从而克服当前AR代理在处理需要理解和利用用户长期经验和偏好的复杂多步骤场景方面的局限性。

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [298] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 本文对LLM知识编辑方法进行了分类和回顾，引入了基于功能的分类法，并结合了知识类型进行了分析，指出了现有方法的优缺点和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM知识编辑方法调查主要集中在编辑机制上，而忽略了被编辑知识的功能。因此，本文旨在提供一个更全面的视角，通过引入一种新的基于功能的分类法来组织对知识编辑方法的审查。

Method: 本文提出了一种新的基于功能的分类法，并结合现有的基于机制的分类法，对LLM的知识编辑方法进行了全面的分类和回顾。我们检查了不同机制如何应用于不同类型的知识，并分析了现有方法的优缺点。

Result: 通过将编辑机制和知识类型相结合，本文对LLM知识编辑的现状进行了全面的概述，明确了问题定义，并总结了评估任务和数据集。此外，本文还指出了现有方法的优势和局限性，并为未来的研究方向提供了建议。

Conclusion: LLM的知识编辑方法需要根据所编辑知识的类型（事实、时间、概念、常识、社会）来选择，现有方法在不同知识类型上的有效性不同，未来需要进一步研究以应对开放性挑战。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


### [299] [GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs](https://arxiv.org/abs/2508.08815)
*Roberto Barile,Claudia d'Amato,Nicola Fanizzi*

Main category: cs.AI

TL;DR: GRainsaCK是一个用于基准测试链接预测解释的软件资源，它简化了从模型训练到评估的所有任务，并且具有模块化、可扩展性和广泛的文档。


<details>
  <summary>Details</summary>
Motivation: 链接预测方法被用于预测知识图中的缺失链接，但基于嵌入的方法缺乏可理解性。解释方法通过识别支持事实来解决这个问题，但由于缺乏标准的评估协议和基准资源，对解释进行量化评估具有挑战性。

Method: 提出GRainsaCK，这是一个可重用的软件资源，可以全面简化基准测试解释的所有任务，从模型训练到沿同一评估协议的解释评估。GRainsaCK通过将主要组件实现为易于替换的函数来实现模块化和可扩展性。

Result: GRainsaCK是一个可重用的软件资源，可以全面简化基准测试解释的所有任务，并提供广泛的文档，包括教程。

Conclusion: GRainsaCK是一个可重用的软件资源，可以全面简化基准测试解释的所有任务，并提供广泛的文档，包括教程。

Abstract: Since Knowledge Graphs are often incomplete, link prediction methods are
adopted for predicting missing facts. Scalable embedding based solutions are
mostly adopted for this purpose, however, they lack comprehensibility, which
may be crucial in several domains. Explanation methods tackle this issue by
identifying supporting knowledge explaining the predicted facts. Regretfully,
evaluating/comparing quantitatively the resulting explanations is challenging
as there is no standard evaluation protocol and overall benchmarking resource.
We fill this important gap by proposing GRainsaCK, a reusable software resource
that fully streamlines all the tasks involved in benchmarking explanations,
i.e., from model training to evaluation of explanations along the same
evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by
implementing the main components as functions that can be easily replaced.
Finally, fostering its reuse, we provide extensive documentation including a
tutorial.

</details>


### [300] [Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation](https://arxiv.org/abs/2508.08816)
*Yuechen Wang,Yuming Qiao,Dan Meng,Jun Yang,Haonan Lu,Zhenyu Yang,Xudong Zhang*

Main category: cs.AI

TL;DR: E-Agent 是一个创新的多模态检索增强生成（mRAG）框架，通过智能规划和执行，显著提高了处理时效性信息的准确性和效率，并引入了 RemPlan 基准测试来评估 mRAG 规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 mRAG 方法在处理现实世界场景（如新闻分析和趋势话题）时，存在检索策略僵化和视觉信息利用不足的问题，无法克服多模态大语言模型（MLLMs）的时间限制。

Method: 提出 E-Agent 框架，包含一个 mRAG 规划器（动态协调多模态工具）和一个任务执行器（优化 mRAG 工作流）。采用一次性 mRAG 规划策略，以提高信息检索效率并减少冗余工具调用。引入 RemPlan 基准测试，包含依赖检索和独立检索的问题类型，并附带所需检索工具的注释。

Result: E-Agent 在 RemPlan 和三个已建立的基准测试中，相比最先进的 mRAG 方法，准确率提高了 13%，同时冗余搜索减少了 37%。

Conclusion: E-Agent 框架通过动态的 mRAG 规划策略和工具感知执行排序，提高了多模态检索增强生成（mRAG）在新闻分析和趋势话题等现实场景中的效率和准确性，在 RemPlan 基准测试和其他三个已建立的基准测试中，准确率提高了 13%，冗余搜索减少了 37%。

Abstract: Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising
solution to address the temporal limitations of Multimodal Large Language
Models (MLLMs) in real-world scenarios like news analysis and trending topics.
However, existing approaches often suffer from rigid retrieval strategies and
under-utilization of visual information. To bridge this gap, we propose
E-Agent, an agent framework featuring two key innovations: a mRAG planner
trained to dynamically orchestrate multimodal tools based on contextual
reasoning, and a task executor employing tool-aware execution sequencing to
implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning
strategy that enables efficient information retrieval while minimizing
redundant tool invocations. To rigorously assess the planning capabilities of
mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.
This novel benchmark contains both retrieval-dependent and
retrieval-independent question types, systematically annotated with essential
retrieval tools required for each instance. The benchmark's explicit mRAG
planning annotations and diverse question design enhance its practical
relevance by simulating real-world scenarios requiring dynamic mRAG decisions.
Experiments across RemPlan and three established benchmarks demonstrate
E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods
while reducing redundant searches by 37%.

</details>


### [301] [Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition](https://arxiv.org/abs/2508.08830)
*Mustafa Akben,Vinayaka Gude,Haya Ajjan*

Main category: cs.AI

TL;DR: MLLMs在个体情绪识别上优于人类，但人类集体智能和人机协作在整体表现和潜力上更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）日益普及，AI识别和响应人类情绪的能力对于有效的人机交互至关重要。特别是，这类系统是否能媲美甚至超越人类专家仍有待观察。然而，AI的情感智能，特别是多模态大语言模型（MLLMs），在很大程度上仍未被探索。

Method: 使用“阅读心智测验”（RMET）及其多族裔对应版本（MRMET）来评估MLLMs的情绪识别能力，并将其与人类参与者进行比较。

Result: 平均而言，MLLMs在准确识别两种测试中的情绪方面优于人类。即使在比较低、中和专家级别表现群体时，这一趋势依然存在。然而，当我们聚合独立的个体人类决策以模拟集体智能时，人类群体在性能上显著超越了聚合的MLLM预测，这凸显了群体的智慧。此外，结合人类和MLLM预测的协同方法（增强智能）实现了比单独的人类或MLLM更高的准确性。

Conclusion: 虽然MLLMs在个体层面表现出强大的情绪识别能力，但人类的集体智能和人机协作的协同潜力为实现有效的情感AI提供了最有希望的途径。

Abstract: The ability to discern subtle emotional cues is fundamental to human social
intelligence. As artificial intelligence (AI) becomes increasingly common, AI's
ability to recognize and respond to human emotions is crucial for effective
human-AI interactions. In particular, whether such systems can match or surpass
human experts remains to be seen. However, the emotional intelligence of AI,
particularly multimodal large language models (MLLMs), remains largely
unexplored. This study evaluates the emotion recognition abilities of MLLMs
using the Reading the Mind in the Eyes Test (RMET) and its multiracial
counterpart (MRMET), and compares their performance against human participants.
Results show that, on average, MLLMs outperform humans in accurately
identifying emotions across both tests. This trend persists even when comparing
performance across low, medium, and expert-level performing groups. Yet when we
aggregate independent human decisions to simulate collective intelligence,
human groups significantly surpass the performance of aggregated MLLM
predictions, highlighting the wisdom of the crowd. Moreover, a collaborative
approach (augmented intelligence) that combines human and MLLM predictions
achieves greater accuracy than either humans or MLLMs alone. These results
suggest that while MLLMs exhibit strong emotion recognition at the individual
level, the collective intelligence of humans and the synergistic potential of
human-AI collaboration offer the most promising path toward effective emotional
AI. We discuss the implications of these findings for the development of
emotionally intelligent AI systems and future research directions.

</details>


### [302] [Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation](https://arxiv.org/abs/2508.08882)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: 该研究提出了一种双代理混合框架，将数学推理分解为推理代理和编码代理，以解决单一大型语言模型在处理推理和编码任务时可能出现的认知负荷干扰问题。实验表明，这种分离设计可以提高推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前集成了工具的数学推理系统通常采用单一代理范式，由一个大型语言模型处理问题推理、代码生成和代码执行。这种设计虽然简化了协调，但可能导致认知负荷干扰，因为代理必须在长时程推理和精确程序合成之间交错进行。该研究旨在验证这一假设，并提出一种解决方案。

Method: 提出了一种双代理混合框架：一个推理代理负责逐步分解问题，一个编码代理负责代码生成和执行。训练结合了模仿学习和强化学习，其中编码代理根据匹配中间真实程序获得高奖励，根据有效执行获得较低奖励；推理代理主要通过最终答案的准确性进行优化，并利用优势估计来评估中间步骤。这种分离的角色设计减少了认知干扰，促进了推理-编码的稳定协调。

Result: 通过与推理代理和推理加编码代理的对照比较，发现后者尽管具有工具调用能力，但产生的正确推理路径明显较少。这验证了单一代理范式可能存在的认知负荷干扰问题。

Conclusion: 双代理混合框架通过分离推理和编码任务，减少了认知干扰，促进了稳定的推理-编码协调。

Abstract: Current tool-integrated mathematical reasoning systems often adopt a
single-agent paradigm, where one large language model handles problem
reasoning, code generation, and code execution in an integrated workflow. While
this design eases coordination, we hypothesize that it imposes cognitive load
interference, as the agent must interleave long-horizon reasoning with precise
program synthesis. We validate this hypothesis through a controlled comparison
between a reasoning-only agent and a reasoning-plus-code agent, finding that
the latter produces significantly fewer correct reasoning paths despite having
tool-calling capabilities. To address this, we propose a dual-agent hybrid
framework: a Reasoning Agent performs stepwise problem decomposition, and a
Code Agent handles code generation and execution. Training combines imitation
learning and reinforcement learning: the Code Agent receives strong rewards for
matching intermediate ground-truth programs and weaker rewards for valid
execution, while the Reasoning Agent is optimized chiefly via final-answer
accuracy using advantage estimation to credit intermediate steps. This
decoupled role design reduces cognitive interference and promotes stable
reasoning-coding coordination.

</details>


### [303] [Compass-Thinker-7B Technical Report](https://arxiv.org/abs/2508.08909)
*Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang*

Main category: cs.AI

TL;DR: 提出Compass-Thinker-7B模型，用更少资源实现LLM的强化学习推理，并在数学任务上取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 旨在用更少的计算资源和成本探索强化学习的潜力，为更大模型的强化学习研究提供见解。

Method: 通过一个专门设计的强化学习流程，在开源模型的基础上进行训练，并构建了一个包含30K可验证数学题的数据集，通过配置不同阶段的数据和训练设置，逐步释放模型潜力并提高训练效率。

Result: Compass-Thinker-7B模型展现出卓越的推理潜力，在数学推理任务上取得了优于同尺寸RL模型的性能，尤其在AIME2024评估中达到40%的准确率。

Conclusion: Compass-Thinker-7B模型在数学推理方面表现出色，在AIME2024评估中达到40%的准确率，优于同尺寸的RL模型，为更大模型的RL研究提供了思路。

Abstract: Recent R1-Zero-like research further demonstrates that reasoning extension
has given large language models (LLMs) unprecedented reasoning capabilities,
and Reinforcement Learning is the core technology to elicit its complex
reasoning. However, conducting RL experiments directly on hyperscale models
involves high computational costs and resource demands, posing significant
risks. We propose the Compass-Thinker-7B model, which aims to explore the
potential of Reinforcement Learning with less computational resources and
costs, and provides insights for further research into RL recipes for larger
models. Compass-Thinker-7B is trained from an open source model through a
specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k
verifiable mathematics problems for the Reinforcement Learning Pipeline. By
configuring data and training settings with different difficulty distributions
for different stages, the potential of the model is gradually released and the
training efficiency is improved. Extensive evaluations show that
Compass-Thinker-7B possesses exceptional reasoning potential, and achieves
superior performance on mathematics compared to the same-sized RL
model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B
achieves 40% accuracy.

</details>


### [304] [Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models](https://arxiv.org/abs/2508.08926)
*Wei Cai,Jian Zhao,Yuchu Jiang,Tianle Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 大型视觉语言模型（LVLM）存在“隐式推理安全”漏洞，即良性输入可能导致不安全输出。本文提出了该概念，并创建了 SSUI 数据集。研究发现，上下文学习能有效缓解此问题，凸显了改进跨模态隐式推理的必要性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在处理多模态输入时面临日益严峻的安全挑战，存在一种名为“隐式推理安全”的漏洞，即良性输入可能触发不安全的输出。

Method: 提出了隐式推理安全的概念，并创建了第一个专门针对此问题的 Safe Semantics, Unsafe Interpretations (SSUI) 数据集。通过简单的上下文学习（ICL）来减轻这些多模态威胁。

Result: 研究表明，即使是简单的上下文学习（ICL）方法，在 SSUI 数据集上的表现也显著减轻了隐式多模态威胁。

Conclusion: 改进跨模态隐式推理对于解决大型视觉语言模型（LVLM）的隐式推理安全问题至关重要。

Abstract: Large Vision-Language Models face growing safety challenges with multimodal
inputs. This paper introduces the concept of Implicit Reasoning Safety, a
vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due
to flawed or hidden reasoning. To showcase this, we developed Safe Semantics,
Unsafe Interpretations, the first dataset for this critical issue. Our
demonstrations show that even simple In-Context Learning with SSUI
significantly mitigates these implicit multimodal threats, underscoring the
urgent need to improve cross-modal implicit reasoning.

</details>


### [305] [Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty](https://arxiv.org/abs/2508.08992)
*Rui Wang,Qihan Lin,Jiayu Liu,Qing Zong,Tianshi Zheng,Weiqi Wang,Yangqiu Song*

Main category: cs.AI

TL;DR: 本研究探索了前景理论（PT）和认知标记对大型语言模型（LLM）决策行为的影响。研究设计了一个包含三个阶段的实验，并提出了一个评估框架。结果表明，PT 模型在解释 LLM 决策时并非始终可靠，尤其是在面对多样化的语言不确定性表达时。研究代码已在 GitHub 上发布。


<details>
  <summary>Details</summary>
Motivation: 探索 PT 是否适用于现代 LLM，以及认知标记（表达人类不确定性的语言）是否会影响 LLM 的决策行为。

Method: 设计了一个三阶段实验，基于经济学问卷，提出了一个更通用、更精确的评估框架来模拟 PT 模型下 LLM 的决策行为，并通过常用的大陆英语中的认知标记的经验概率值引入不确定性，然后将认知标记纳入评估框架以检验其对 LLM 决策行为的影响。

Result: LLM 的决策可能受到认知标记的影响，尤其是在不确定性以不同语言形式表达的情况下，PT 模型在该场景下的预测能力下降。

Conclusion: PT 模型在解释 LLM 的决策时并非始终可靠，尤其是在涉及多种语言形式表达不确定性时。

Abstract: Prospect Theory (PT) models human decision-making under uncertainty, while
epistemic markers (e.g., maybe) serve to express uncertainty in language.
However, it remains largely unexplored whether Prospect Theory applies to
contemporary Large Language Models and whether epistemic markers, which express
human uncertainty, affect their decision-making behaviour. To address these
research gaps, we design a three-stage experiment based on economic
questionnaires. We propose a more general and precise evaluation framework to
model LLMs' decision-making behaviour under PT, introducing uncertainty through
the empirical probability values associated with commonly used epistemic
markers in comparable contexts. We then incorporate epistemic markers into the
evaluation framework based on their corresponding probability values to examine
their influence on LLM decision-making behaviours. Our findings suggest that
modelling LLMs' decision-making with PT is not consistently reliable,
particularly when uncertainty is expressed in diverse linguistic forms. Our
code is released in https://github.com/HKUST-KnowComp/MarPT.

</details>


### [306] [Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](https://arxiv.org/abs/2508.08997)
*Sizhe Yuen,Francisco Gomez Medina,Ting Su,Yali Du,Adam J. Sobey*

Main category: cs.AI

TL;DR: 本文提出了一种内生记忆智能体框架，通过结构化记忆解决多LLM智能体记忆限制问题，在PDDL数据集和数据管道设计任务上均取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）构建的多智能体系统在解决复杂协作问题方面显示出巨大潜力，但它们面临着由上下文窗口限制引起的根本性挑战，这些限制会损害记忆一致性、角色遵循性和过程完整性。

Method: 本文提出了一种名为“内生记忆智能体”的新框架，该框架通过结构化的、与智能体输出共同演化的特定记忆来解决上下文窗口限制带来的问题。具体来说，该方法维护与角色对齐的记忆模板，以保留专业视角并专注于任务相关信息。

Result: 在PDDL数据集上的基准测试中，与现有的最先进的多智能体记忆方法相比，该方法在代币效率最高的情况下，性能提高了38.6%。在复杂的数据管道设计任务上的额外评估表明，该方法在可扩展性、可靠性、可用性、成本效益和文档记录这5个指标上均优于现有方法。

Conclusion: 通过结构化、内生化的方法解决多LLM智能体中的记忆限制问题，可以提高其在结构化规划任务上的能力。

Abstract: Multi-agent systems built on Large Language Models (LLMs) show exceptional
promise for complex collaborative problem-solving, yet they face fundamental
challenges stemming from context window limitations that impair memory
consistency, role adherence, and procedural integrity. This paper introduces
Intrinsic Memory Agents, a novel framework that addresses these limitations
through structured agent-specific memories that evolve intrinsically with agent
outputs. Specifically, our method maintains role-aligned memory templates that
preserve specialized perspectives while focusing on task-relevant information.
We benchmark our approach on the PDDL dataset, comparing its performance to
existing state-of-the-art multi-agentic memory approaches and showing an
improvement of 38.6\% with the highest token efficiency. An additional
evaluation is performed on a complex data pipeline design task, we demonstrate
that our approach produces higher quality designs when comparing 5 metrics:
scalability, reliability, usability, cost-effectiveness and documentation with
additional qualitative evidence of the improvements. Our findings suggest that
addressing memory limitations through structured, intrinsic approaches can
improve the capabilities of multi-agent LLM systems on structured planning
tasks.

</details>


### [307] [Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs](https://arxiv.org/abs/2508.09019)
*Shivam Dubey*

Main category: cs.AI

TL;DR: 该研究提出了一种新颖的端到端系统，利用机械可译性技术识别并实时减轻大语言模型中的偏见。通过训练探针识别偏见表征，并计算引导向量来引导模型生成更中性的内容，该方法在gpt2-large模型上显示出近乎完美准确率，并成功减少了有害的刻板印象。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）越来越多地融入社会系统，它们可能延续和放大有害偏见的风险已成为一个关键的安全问题。传统的偏见缓解方法通常依赖于数据过滤或事后输出调整，这些方法将模型视为不透明的黑盒子。

Method: 该方法包括两个主要阶段：1. 训练线性“探针”来识别模型内部激活中各种偏见的潜在表征。2. 利用这些发现通过对比有偏见和中性陈述的模型激活模式来计算“引导向量”，并在推理过程中添加这些向量以引导模型远离产生有害、刻板印象或有偏见的内容。

Result: 实验表明，探针可以近乎完美地识别有偏见的内容，并且偏见表征在模型的后层最为明显。激活引导技术成功地将有偏见的内容改为了更中性的替代方案。

Conclusion: 这项工作提出了一个端到端的系统，利用机械可译性技术直接在模型的内部工作来识别和减轻偏见，为构建更安全、更负责任的大语言模型提供了一种更直接、可解释的方法。

Abstract: As large language models (LLMs) become more integrated into societal systems,
the risk of them perpetuating and amplifying harmful biases becomes a critical
safety concern. Traditional methods for mitigating bias often rely on data
filtering or post-hoc output moderation, which treat the model as an opaque
black box. In this work, we introduce a complete, end-to-end system that uses
techniques from mechanistic interpretability to both identify and actively
mitigate bias directly within a model's internal workings. Our method involves
two primary stages. First, we train linear "probes" on the internal activations
of a model to detect the latent representations of various biases (e.g.,
gender, race, age). Our experiments on \texttt{gpt2-large} demonstrate that
these probes can identify biased content with near-perfect accuracy, revealing
that bias representations become most salient in the model's later layers.
Second, we leverage these findings to compute "steering vectors" by contrasting
the model's activation patterns for biased and neutral statements. By adding
these vectors during inference, we can actively steer the model's generative
process away from producing harmful, stereotypical, or biased content in
real-time. We demonstrate the efficacy of this activation steering technique,
showing that it successfully alters biased completions toward more neutral
alternatives. We present our work as a robust and reproducible system that
offers a more direct and interpretable approach to building safer and more
accountable LLMs.

</details>


### [308] [A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems](https://arxiv.org/abs/2508.09027)
*Jie Wang,Guang Wang*

Main category: cs.AI

TL;DR: 在网约车系统中，请求前的等待时间预测很重要但研究不足。本文提出FiXGBoost模型，在不知道匹配司机信息的情况下，利用需求和供给动态信息进行预测，实验证明其效果良好且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要关注请求后的等待时间预测，而忽略了请求前的等待时间预测，而后者对于乘客更有效地规划行程和提升乘客及司机体验至关重要。

Method: 提出了一种新颖的基于特征交互的XGBoost模型FiXGBoost，用于在不知道匹配司机信息的情况下预测等待时间。

Result: 通过对包含超过3000万条记录的大规模真实世界网约车数据集进行实验，证明了FiXGBoost在预测请求前乘客等待时间方面取得了良好的效果，并且具有高可解释性。

Conclusion: FiXGBoost在真实世界的网约车数据集上取得了良好的预估效果，并且具有高可解释性。

Abstract: Passenger waiting time prediction plays a critical role in enhancing both
ridesharing user experience and platform efficiency. While most existing
research focuses on post-request waiting time prediction with knowing the
matched driver information, pre-request waiting time prediction (i.e., before
submitting a ride request and without matching a driver) is also important, as
it enables passengers to plan their trips more effectively and enhance the
experience of both passengers and drivers. However, it has not been fully
studied by existing works. In this paper, we take the first step toward
understanding the predictability and explainability of pre-request passenger
waiting time in ridesharing systems. Particularly, we conduct an in-depth
data-driven study to investigate the impact of demand&supply dynamics on
passenger waiting time. Based on this analysis and feature engineering, we
propose FiXGBoost, a novel feature interaction-based XGBoost model designed to
predict waiting time without knowing the assigned driver information. We
further perform an importance analysis to quantify the contribution of each
factor. Experiments on a large-scale real-world ridesharing dataset including
over 30 million trip records show that our FiXGBoost can achieve a good
performance for pre-request passenger waiting time prediction with high
explainability.

</details>


### [309] [CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks](https://arxiv.org/abs/2508.09054)
*Debdeep Mukherjee,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Victor Martin,Thierry Josse,Jonathan Brown,Kenza Saiah*

Main category: cs.AI

TL;DR: 一种基于深度神经网络的预测性维护框架，可早期检测 CVCM 故障，准确率达 99.31%，并提供不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 早期识别故障类型对于改进维护计划、最大限度地减少停机时间和收入损失至关重要。传统的依赖于清晰信号变化的方法在早期检测这些通常不明显的故障方面存在困难。

Method: 利用深度神经网络提出一种预测性维护框架，在异常升级为故障之前对其进行分类。

Result: 在 10 个不同装置的 CVCM 故障案例上进行了验证，实现了 99.31% 的整体准确率，并在异常发生 1% 的时间内进行了检测，同时提供了 99% 置信度的不确定性估计。

Conclusion: 该方法是 ISO-17359 合规的，并且优于传统技术，实现了 99.31% 的整体准确率，并在异常开始后 1% 的时间内检测到。通过共形预测，我们提供了不确定性估计，达到了 99% 的置信度，并在各个类别之间实现了持续的覆盖。鉴于 CVCM 的全球部署，该方法具有可扩展性，并可适应其他轨道电路和铁路系统，从而提高运行可靠性。

Abstract: Track circuits are critical for railway operations, acting as the main
signalling sub-system to locate trains. Continuous Variable Current Modulation
(CVCM) is one such technology. Like any field-deployed, safety-critical asset,
it can fail, triggering cascading disruptions. Many failures originate as
subtle anomalies that evolve over time, often not visually apparent in
monitored signals. Conventional approaches, which rely on clear signal changes,
struggle to detect them early. Early identification of failure types is
essential to improve maintenance planning, minimising downtime and revenue
loss. Leveraging deep neural networks, we propose a predictive maintenance
framework that classifies anomalies well before they escalate into failures.
Validated on 10 CVCM failure cases across different installations, the method
is ISO-17359 compliant and outperforms conventional techniques, achieving
99.31% overall accuracy with detection within 1% of anomaly onset. Through
conformal prediction, we provide uncertainty estimates, reaching 99% confidence
with consistent coverage across classes. Given CVCMs global deployment, the
approach is scalable and adaptable to other track circuits and railway systems,
enhancing operational reliability.

</details>


### [310] [SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling](https://arxiv.org/abs/2508.09105)
*Shixuan Sun,Siyuan Liang,Ruoyu Chen,Jianjie Huang,Jingzhi Li,Xiaochun Cao*

Main category: cs.AI

TL;DR: RAG/MRAG模糊了内容来源，影响隐私问责。本研究提出SMA，首个来源感知成员审核机制，通过零阶优化和跨模态归因，在半黑盒设置下实现细粒度来源追踪，并能对MRAG中的图像检索进行成员推断，解决了隐私和来源审计问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）和多模态检索增强生成（MRAG）技术虽然提升了大型语言模型（LLM）的知识覆盖和上下文理解能力，但其检索和多模态融合过程模糊了内容的来源，使得现有的成员推断方法无法准确追溯生成内容的来源（预训练数据、外部检索或用户输入），从而削弱了对隐私泄露的问责能力。因此，有必要开发一种能够精细化追踪内容来源的审计机制。

Method: 该研究提出了一种称为来源感知成员审核（SMA）的新方法。SMA在一个半黑盒设置下运行，并具备检索控制能力。为了克服环境限制，SMA设计了一种基于零阶优化的归因估计机制，通过大规模扰动采样和岭回归模型来近似输入令牌对输出的影响。此外，SMA引入了跨模态归因技术，利用多模态大型语言模型（MLLM）将图像输入转换为文本描述，从而实现文本模态下的令牌级归因。

Result: SMA成功实现了对生成内容来源的细粒度归因，解决了RAG和MRAG系统中来源模糊的问题。该方法能够在半黑盒设置下，通过零阶优化和跨模态归因技术，可靠地追踪生成内容是来自预训练数据、外部检索还是用户输入。特别是，它首次实现了对MRAG系统中图像检索痕迹的成员推断，为理解和审计这些复杂生成系统的数据来源提供了关键能力。

Conclusion: 该研究提出了首个来源感知成员审核（SMA）机制，能够对生成内容进行细粒度的来源归因，解决了检索和多模态融合导致的来源模糊问题。SMA通过零阶优化和跨模态归因技术，实现了对预训练数据、外部检索或用户输入等来源的可靠追踪，特别是在多模态检索增强生成（MRAG）系统中，能够对图像检索痕迹进行成员推断，为复杂生成系统的数据来源审计提供了新的视角。

Abstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented
Generation (MRAG) significantly improve the knowledge coverage and contextual
understanding of Large Language Models (LLMs) by introducing external knowledge
sources. However, retrieval and multimodal fusion obscure content provenance,
rendering existing membership inference methods unable to reliably attribute
generated outputs to pre-training, external retrieval, or user input, thus
undermining privacy leakage accountability
  To address these challenges, we propose the first Source-aware Membership
Audit (SMA) that enables fine-grained source attribution of generated content
in a semi-black-box setting with retrieval control capabilities.To address the
environmental constraints of semi-black-box auditing, we further design an
attribution estimation mechanism based on zero-order optimization, which
robustly approximates the true influence of input tokens on the output through
large-scale perturbation sampling and ridge regression modeling. In addition,
SMA introduces a cross-modal attribution technique that projects image inputs
into textual descriptions via MLLMs, enabling token-level attribution in the
text modality, which for the first time facilitates membership inference on
image retrieval traces in MRAG systems. This work shifts the focus of
membership inference from 'whether the data has been memorized' to 'where the
content is sourced from', offering a novel perspective for auditing data
provenance in complex generative systems.

</details>


### [311] [OpenCUA: Open Foundations for Computer-Use Agents](https://arxiv.org/abs/2508.09123)
*Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y. Charles,Zhilin Yang,Tao Yu*

Main category: cs.AI

TL;DR: 提出OpenCUA，一个开源的计算机使用代理（CUA）框架，包含数据和模型，以解决最先进CUA系统不公开的问题。该框架包括注释工具、大规模数据集AgentNet和一个可扩展的训练流水线。OpenCUA-32B在OSWorld-Verified上取得了SOTA性能，优于GPT-4o，并具有良好的泛化性和可扩展性。代码、数据集和模型已发布以促进CUA研究。


<details>
  <summary>Details</summary>
Motivation: 为了应对目前最先进的计算机使用代理（CUA）系统细节不公开的现状，以及CUA日益增长的商业潜力和其在数字交互中日益增长的作用，研究社区迫切需要开放的CUA框架来研究其能力、局限性和风险。因此，提出OpenCUA框架以开放研究基础。

Method: OpenCUA是一个全面的开源框架，包含三个主要部分：1. 一个注释基础设施，用于捕获人类计算机使用演示；2. AgentNet，一个包含3个操作系统和200多个应用程序及网站的大规模计算机使用任务数据集；3. 一个可扩展的流水线，将演示转化为状态-动作对，并包含反思性的长链思考（Chain-of-Thought）推理，以支持数据规模扩展带来的性能提升。

Result: OpenCUA框架的模型在CUA基准测试中表现出强大的性能。具体而言，OpenCUA-32B在OSWorld-Verified上达到了34.8%的平均成功率，超越了OpenAI CUA（GPT-4o），并设定了开源模型的SOTA。此外，研究证实该方法具有良好的跨领域泛化能力，并且测试时的计算量增加能显著提升性能。

Conclusion: OpenCUA框架的发布旨在通过提供一个开源的、可扩展的平台来促进计算机使用代理（CUA）的研究，该平台包括注释基础设施、大规模数据集AgentNet以及可扩展的训练流水线。OpenCUA-32B在OSWorld-Verified基准测试中取得了34.8%的平均成功率，创下了开源模型的最新技术水平（SOTA），并优于OpenAI CUA（GPT-4o）。该方法在不同领域具有良好的泛化能力，并且受益于测试时计算量的增加。

Abstract: Vision-language models have demonstrated impressive capabilities as
computer-use agents (CUAs) capable of automating diverse computer tasks. As
their commercial potential grows, critical details of the most capable CUA
systems remain closed. As these agents will increasingly mediate digital
interactions and execute consequential decisions on our behalf, the research
community needs access to open CUA frameworks to study their capabilities,
limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive
open-source framework for scaling CUA data and foundation models. Our framework
consists of: (1) an annotation infrastructure that seamlessly captures human
computer-use demonstrations; (2) AgentNet, the first large-scale computer-use
task dataset spanning 3 operating systems and 200+ applications and websites;
(3) a scalable pipeline that transforms demonstrations into state-action pairs
with reflective long Chain-of-Thought reasoning that sustain robust performance
gains as data scales. Our end-to-end agent models demonstrate strong
performance across CUA benchmarks. In particular, OpenCUA-32B achieves an
average success rate of 34.8% on OSWorld-Verified, establishing a new
state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA
(GPT-4o). Further analysis confirms that our approach generalizes well across
domains and benefits significantly from increased test-time computation. We
release our annotation tool, datasets, code, and models to build open
foundations for further CUA research.

</details>


### [312] [BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://arxiv.org/abs/2508.09129)
*Xianghe Pang,Shuo Tang,Rui Ye,Yuwen Du,Yaxin Du,Siheng Chen*

Main category: cs.AI

TL;DR: BrowseMaster 是一个可扩展的框架，通过规划器-执行器代理对来解决 LLM 代理在信息检索中的局限性，它能够平衡搜索广度和推理深度，并在英语和中文的具有挑战性的基准测试中取得领先结果。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的代理在搜索广度和推理深度方面存在局限性，缓慢的、串行查询限制了相关源的覆盖范围，并且嘈杂的原始输入会破坏多步推理的连续性。

Method: 提出 BrowseMaster，一个围绕程序化增强的规划器-执行器代理对构建的可扩展框架。规划器根据任务约束制定和调整搜索策略，而执行器进行高效、有针对性的检索，为规划器提供简洁、相关的证据。

Result: BrowseMaster 提高了现有代理的搜索广度和推理深度，克服了它们之间的权衡。

Conclusion: BrowseMaster 在具有挑战性的英语和中文基准测试中始终优于开源和专有基线，在 BrowseComp-en 上达到 30.0 的分数，在 BrowseComp-zh 上达到 46.5 的分数，这表明它在复杂的、需要大量推理的、大规模信息检索任务中具有很强的能力。

Abstract: Effective information seeking in the vast and ever-growing digital landscape
requires balancing expansive search with strategic reasoning. Current large
language model (LLM)-based agents struggle to achieve this balance due to
limitations in search breadth and reasoning depth, where slow, serial querying
restricts coverage of relevant sources and noisy raw inputs disrupt the
continuity of multi-step reasoning. To address these challenges, we propose
BrowseMaster, a scalable framework built around a programmatically augmented
planner-executor agent pair. The planner formulates and adapts search
strategies based on task constraints, while the executor conducts efficient,
targeted retrieval to supply the planner with concise, relevant evidence. This
division of labor preserves coherent, long-horizon reasoning while sustaining
broad and systematic exploration, overcoming the trade-off that limits existing
agents. Extensive experiments on challenging English and Chinese benchmarks
show that BrowseMaster consistently outperforms open-source and proprietary
baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,
which demonstrates its strong capability in complex, reasoning-heavy
information-seeking tasks at scale.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [313] [Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation](https://arxiv.org/abs/2508.08257)
*Zacharias Chen,Alexa Cristelle Cahilig,Sarah Dias,Prithu Kolar,Ravi Prakash,Patrick J. Codd*

Main category: eess.SP

TL;DR: 机器人辅助手术通常会限制外科医生的感官反馈，这对于区分健康组织和肿瘤组织至关重要。本研究提出了一个多模态传感系统，结合视觉、声音和力传感器，以提高组织边界划分的准确性。实验结果表明，该方法显著提高了分类精度，为机器人手术提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助神经外科手术因其提高了灵活性、精度和手术工具控制能力，从而改善了患者的治疗效果而备受关注。然而，这些系统通常会限制外科医生自然的感官反馈，而这种反馈对于识别组织至关重要，尤其是在肿瘤学手术中，区分健康组织和肿瘤组织至关重要。虽然成像和力传感已解决感官反馈不足的问题，但探索用于精确组织边界划分的多模态传感选项的研究有限。

Method: 本研究提出的系统首先使用基于视觉的引导来估计具有视觉线索的边界位置，然后使用从接触式麦克风和力传感器获取的数据进行优化。通过交互式图形界面支持实时数据采集和可视化。

Result: 实验结果表明，多模态融合显著提高了材料分类的准确性。

Conclusion: 多模态融合显著提高了材料分类的准确性。该平台为探索手术应用中的传感器融合提供了一个可扩展的软硬件解决方案，并证明了多模态方法在实时组织边界划分方面的潜力。

Abstract: Robot-assisted neurological surgery is receiving growing interest due to the
improved dexterity, precision, and control of surgical tools, which results in
better patient outcomes. However, such systems often limit surgeons' natural
sensory feedback, which is crucial in identifying tissues -- particularly in
oncological procedures where distinguishing between healthy and tumorous tissue
is vital. While imaging and force sensing have addressed the lack of sensory
feedback, limited research has explored multimodal sensing options for accurate
tissue boundary delineation. We present a user-friendly, modular test bench
designed to evaluate and integrate complementary multimodal sensors for tissue
identification. Our proposed system first uses vision-based guidance to
estimate boundary locations with visual cues, which are then refined using data
acquired by contact microphones and a force sensor. Real-time data acquisition
and visualization are supported via an interactive graphical interface.
Experimental results demonstrate that multimodal fusion significantly improves
material classification accuracy. The platform provides a scalable
hardware-software solution for exploring sensor fusion in surgical applications
and demonstrates the potential of multimodal approaches in real-time tissue
boundary delineation.

</details>


### [314] [Hardware-friendly IR-HARQ for Polar SCL Decoders](https://arxiv.org/abs/2508.08425)
*Marwan Jalaleddine,Jiajie Li,Warren J. Gross*

Main category: eess.SP

TL;DR: 提出了一种改进的极化码 IR-HARQ 方案，通过二进制向量操作和优化的快速节点集成来解决硬件实现中的内存访问和面积开销问题，内存开销略有增加。


<details>
  <summary>Details</summary>
Motivation: 为了将极化码的应用扩展到下一代无线通信系统，必须支持增量冗余（IR）混合自动重传请求（HARQ）方案。然而，现有的 IR-HARQ 方案在硬件实现方面存在挑战，包括不规则的内存访问模式和由新型比特类型引起的大量面积开销。

Method: 将基于集合的操作转换为二进制向量操作，并引入一种新的快速节点集成方法，以提高硬件兼容性并最小化面积开销。

Result: 与不支持 IR-HARQ 的 SCL 解码相比，所提出的方案内存开销为 25-27%。

Conclusion: 所提出的方法通过将基于集合的操作转换为二进制向量操作，并引入一种新的快速节点集成方法，有效解决了现有极化码 IR-HARQ 方案在硬件实现上面临的挑战，如不规则内存访问和面积开销问题。

Abstract: To extend the applications of polar codes within next-generation wireless
communication systems, it is essential to incorporate support for Incremental
Redundancy (IR) Hybrid Automatic Repeat Request (HARQ) schemes. The baseline
IR-HARQ scheme's reliance on set-based operations leads to irregular memory
access patterns, posing significant challenges for efficient hardware
implementation. Furthermore, the introduction of new bit types increases the
number of fast nodes that are decoded without traversing the sub-tree,
resulting in a substantial area overhead when implemented in hardware. To
address these issues and improve hardware compatibility, we propose
transforming the set-based operations within the polar IR-HARQ scheme into
binary vector operations. Additionally, we introduce a new fast node
integration approach that avoids increasing the number of fast nodes, thereby
minimizing the associated area overhead. Our proposed scheme results in a
memory overhead of 25-27% compared to successive cancellation list (SCL)
decoding without IR-HARQ support.

</details>


### [315] [Tensor-Structured Bayesian Channel Prediction for Upper Mid-Band XL-MIMO Systems](https://arxiv.org/abs/2508.08491)
*Hongwei Hou,Yafei Wang,Xinping Yi,Wenjin Wang,Dirk T. M. Slock,Shi Jin*

Main category: eess.SP

TL;DR: 提出一种用于XL-MIMO系统在移动场景下信道预测的新方法，解决了近场传播和空间非平稳性问题，并提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决XL-MIMO系统在移动性、信道老化、近场传播和空间非平稳性问题导致的性能下降。

Method: 提出了一种新颖的信道预测方法，包括张量结构的信道建模（SFT和BDD域）、概率表示和贝叶斯推理算法（TS-BLI），并采用EM框架。

Result: 提出的TS-BLI算法在信道预测方面表现出优越性能，已通过近乎实际的信道模拟器得到验证。

Conclusion: 该方法在XL-MIMO和移动场景下实现了优越的信道预测性能。

Abstract: The upper mid-band balances coverage and capacity for the future cellular
systems and also embraces XL-MIMO systems, offering enhanced spectral and
energy efficiency. However, these benefits are significantly degraded under
mobility due to channel aging, and further exacerbated by the unique near-field
(NF) and spatial non-stationarity (SnS) propagation in such systems. To address
this challenge, we propose a novel channel prediction approach that
incorporates dedicated channel modeling, probabilistic representations, and
Bayesian inference algorithms for this emerging scenario. Specifically, we
develop tensor-structured channel models in both the spatial-frequency-temporal
(SFT) and beam-delay-Doppler (BDD) domains, which leverage temporal
correlations among multiple pilot symbols for channel prediction. The factor
matrices of multi-linear transformations are parameterized by BDD domain grids
and SnS factors, where beam domain grids are jointly determined by angles and
slopes under spatial-chirp based NF representations. To enable tractable
inference, we replace environment-dependent BDD domain grids with uniformly
sampled ones, and introduce perturbation parameters in each domain to mitigate
grid mismatch. We further propose a hybrid beam domain strategy that integrates
angle-only sampling with slope hyperparameterization to avoid the computational
burden of explicit slope sampling. Based on the probabilistic models, we
develop tensor-structured bi-layer inference (TS-BLI) algorithm under the
expectation-maximization (EM) framework, which reduces computational complexity
via tensor operations by leveraging the bi-layer factor graph for approximate
E-step inference and an alternating strategy with closed-form updates in the
M-step. Numerical simulations based on the near-practical channel simulator
demonstrate the superior channel prediction performance of the proposed
algorithm.

</details>


### [316] [An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets](https://arxiv.org/abs/2508.08506)
*Mehdi Zafari,Divyanshu Pandey,Rahman Doost-Mohammady*

Main category: eess.SP

TL;DR: 本文研究了在存在频率同步误差的情况下，分布式多用户波束成形（D-MUBF）在多用户MIMO系统中的性能。通过理论分析和基于RENEW massive MIMO测试台的实验，评估了频率偏移对D-MUBF性能的影响，并公开了相关数据集以供未来研究。


<details>
  <summary>Details</summary>
Motivation: 分布式多用户波束成形（D-MUBF）在时分双工（TDD）多用户多输入多输出（MU-MIMO）系统中实现面临严峻挑战，尤其是分布式接入点（APs）之间准确的空中（OTA）定时和频率同步，而本地振荡器（LO）漂移引起的残余频率偏移使得这一问题更加突出。尽管已有大量关于MU-MIMO同步的研究，但评估在分布式天线间频率同步不完美情况下D-MUBF技术的实验研究却寥寥无几。因此，本文旨在提供一个分析性和实验性的评估。

Method: 本文首先推导了信干噪比（SINR）的闭式表达式，该表达式考虑了信道特性和各接入点（AP）间载波频率偏移（CFO）的统计特性。然后，利用RENEW massive MIMO测试台进行了实验评估，收集了包含上行导频样本和上行多用户数据的数据集。最后，通过分析这些数据集，评估了D-MUBF在CFO影响下的性能，并将分析预测与实验测量结果进行了比较。

Result: 通过分析从RENEW massive MIMO测试台收集的数据集，本文评估了D-MUBF在频率同步误差（CFO）影响下的性能，并将分析预测与实验测量结果进行了比较。结果表明，该评估为理解和改进D-MUBF在实际非理想条件下的性能提供了依据。

Conclusion: 本文对分布式多用户波束成形（D-MUBF）在频率同步误差存在下的性能进行了分析和实验评估，并提供了SINR的闭式表达式。通过在RENEW massive MIMO测试台上进行的实验评估，收集了用于信道和CFO估计的上行导频样本以及用于分析D-MUBF技术的多用户上行数据。实验结果表明，D-MUBF在CFO存在下的性能与分析预测一致，并对这些数据集的未来研究利用提供了见解。

Abstract: Realizing distributed multi-user beamforming (D-MUBF) in time division duplex
(TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One
of the most fundamental challenges is achieving accurate over-the-air (OTA)
timing and frequency synchronization among distributed access points (APs),
particularly due to residual frequency offsets caused by local oscillator (LO)
drifts. Despite decades of research on synchronization for MU-MIMO, there are
only a few experimental studies that evaluate D-MUBF techniques under imperfect
frequency synchronization among distributed antennas. This paper presents an
analytical and experimental assessment of D-MUBF methods in the presence of
frequency synchronization errors. We provide closed-form expressions for
signal-to-interference-plus-noise ratio (SINR) as a function of channel
characteristics and statistical properties of carrier frequency offset (CFO)
among AP antennas. In addition, through experimental evaluations conducted with
the RENEW massive MIMO testbed, we collected comprehensive datasets across
various experimental scenarios. These datasets comprise uplink pilot samples
for channel and CFO estimation, in addition to uplink multi-user data intended
for analyzing D-MUBF techniques. By examining these datasets, we assess the
performance of D-MUBF in the presence of CFO and compare the analytical
predictions with empirical measurements. Furthermore, we make the datasets
publicly available and provide insights on utilizing them for future research
endeavors.

</details>


### [317] [Learning Zero Constellations for Binary MOCZ in Fading Channels](https://arxiv.org/abs/2508.08571)
*Anthony Joseph Perre,Parker Huggins,Alphan Sahin*

Main category: eess.SP

TL;DR: 本研究提出了两种设计用于BMOCZ的零星座的方法，其中基于神经网络的解码器可以泛化到平坦衰落信道，并且学习到的星座在性能上优于传统星座，但计算复杂度较高。


<details>
  <summary>Details</summary>
Motivation: 为了设计用于二元调制共轭倒数零（BMOCZ）的零星座。

Method: 提出两种设计零星座的方法：1.将星座设计视为多标签二分类问题，为直接零测试（DiZeT）解码器学习零位置。2.引入基于神经网络（NN）的解码器，并联合学习解码器和零星座参数。

Result: 所提出的学习到的零星座优于传统的Huffman BMOCZ星座，并且基于神经网络的解码器在计算复杂度增加的情况下实现了显著的性能提升。

Conclusion: 所提出的基于神经网络的解码器可以泛化到平坦衰落信道，并且学习到的零星座优于传统的Huffman BMOCZ星座，但是计算复杂度有所增加。

Abstract: In this work, we propose two methods to design zero constellations for binary
modulation on conjugate-reciprocal zeros (BMOCZ). In the first approach, we
treat constellation design as a multi-label binary classification problem and
learn the zero locations for a direct zero-testing (DiZeT) decoder. In the
second approach, we introduce a neural network (NN)-based decoder and jointly
learn the decoder and zero constellation parameters. We show that the NN-based
decoder can directly generalize to flat-fading channels, despite being trained
under additive white Gaussian noise. Furthermore, the results of numerical
simulations demonstrate that learned zero constellations outperform the
canonical, Huffman BMOCZ constellation, with the proposed NN-based decoder
achieving large performance gain at the expense of increased computational
complexity.

</details>


### [318] [Biomedical Signal Processing: EEG and ECG Classification with Discrete Wavelet Transforms, Energy Distribution, and Convolutional Neural Networks](https://arxiv.org/abs/2508.08602)
*Justin London*

Main category: eess.SP

TL;DR: This paper proposes a multimodal deep learning model that uses wavelet transforms and image conversion techniques (Gramian angular fields, recurrency plots, Markov transition fields) to analyze biomedical signals (ECG, EEG, human activity). The multimodal approach improves disease and disorder classification accuracy compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional manual physician analysis of biomedical signals is prone to human error, and advanced deep learning offers improved accuracy. This paper aims to enhance the accuracy of biomedical signal analysis through a multimodal deep learning approach.

Method: A multimodal deep learning model is proposed, utilizing discrete wavelet transforms for signal pre-processing and converting numerical biomedical signals into 2D and 3D images using Gramian angular fields, recurrency plots, and Markov transition fields for image processing. This framework incorporates multimodal image fusion and multimodal feature fusion.

Result: The deep learning models applied to ECG, EEG, and human activity signals using actual medical datasets, brain, and heart recordings demonstrate improved accuracy in disease and disorder classification when using a multimodal approach with wavelet transforms.

Conclusion: The multimodal approach using wavelet transforms improves the accuracy of disease and disorder classification in biomedical signal analysis.

Abstract: Biomedical signal processing extract meaningful information from
physiological signals like electrocardiograms (ECGs), electroencephalograms
(EEGs), and electromyograms (EMGs) to diagnose, monitor, and treat medical
conditions and diseases such as seizures, cardiomyopathy, and neuromuscular
disorders, respectively. Traditional manual physician analysis of electrical
recordings is prone to human error as subtle anomolies may not be detected.
Recently, advanced deep learning has significantly improved the accuracy of
biomedical signal analysis. A multi-modal deep learning model is proposed that
utilizes discrete wavelet transforms for signal pre-processing to reduce noise.
A multi-modal image fusion and multimodal feature fusion framework is utilized
that converts numeric biomedical signals into 2D and 3D images for image
processing using Gramian angular fields, recurrency plots, and Markov
transition fields. In this paper, deep learning models are applied to ECG, EEG,
and human activity signals using actual medical datasets, brain, and heart
recordings. The results demonstrate that using a multi-modal approach using
wavelet transforms improves the accuracy of disease and disorder
classification.

</details>


### [319] [Agentic Graph Neural Networks for Wireless Communications and Networking Towards Edge General Intelligence: A Survey](https://arxiv.org/abs/2508.08620)
*Yang Lu,Shengli Zhang,Chang Liu,Ruichen Zhang,Bo Ai,Dusit Niyato,Wei Ni,Xianbin Wang,Abbas Jamalipour*

Main category: eess.SP

TL;DR: 本文回顾了GNN在无线通信中的应用，并提出使用Agentic AI和LLM框架来改进GNNs的实现和应用，以应对日益复杂和动态的无线系统。


<details>
  <summary>Details</summary>
Motivation: 随着通信技术的快速发展和通信网络的复杂化，传统的被动学习框架可能无法满足日益多样化的无线系统的需求。因此，需要一种新的方法来组织和集成GNNs，以实现场景和任务感知的GNNs实现，并最终达到边缘通用智能。

Method: 本文对GNNs在无线通信和网络中的应用进行了全面的回顾，重点关注图表示与网络拓扑之间以及神经架构与无线任务之间的匹配。文章首先概述了基于著名神经架构的GNNs，然后介绍了Agentic GNNs的概念。接着，文章总结并比较了GNNs在传统系统和新兴技术中的应用，包括物理层、MAC层和网络层设计，以及集成传感与通信（ISAC）、可重构智能表面（RIS）和无小区网络架构。此外，文章还提出了一个大型语言模型（LLM）框架，作为一个智能问答代理，利用该调查作为本地知识库，以实现针对无线通信研究的GNN相关响应。

Result: 本文对GNNs在无线通信和网络中的应用进行了全面的回顾，并提出了Agentic GNNs的概念和LLM框架，为GNNs在无线通信领域的研究和应用提供了新的方向和工具。

Conclusion: 本文提出了使用Agentic AI来组织和集成GNNs，以实现面向边缘通用智能的、场景和任务感知的GNNs实现。

Abstract: The rapid advancement of communication technologies has driven the evolution
of communication networks towards both high-dimensional resource utilization
and multifunctional integration. This evolving complexity poses significant
challenges in designing communication networks to satisfy the growing
quality-of-service and time sensitivity of mobile applications in dynamic
environments. Graph neural networks (GNNs) have emerged as fundamental deep
learning (DL) models for complex communication networks. GNNs not only augment
the extraction of features over network topologies but also enhance scalability
and facilitate distributed computation. However, most existing GNNs follow a
traditional passive learning framework, which may fail to meet the needs of
increasingly diverse wireless systems. This survey proposes the employment of
agentic artificial intelligence (AI) to organize and integrate GNNs, enabling
scenario- and task-aware implementation towards edge general intelligence. To
comprehend the full capability of GNNs, we holistically review recent
applications of GNNs in wireless communications and networking. Specifically,
we focus on the alignment between graph representations and network topologies,
and between neural architectures and wireless tasks. We first provide an
overview of GNNs based on prominent neural architectures, followed by the
concept of agentic GNNs. Then, we summarize and compare GNN applications for
conventional systems and emerging technologies, including physical, MAC, and
network layer designs, integrated sensing and communication (ISAC),
reconfigurable intelligent surface (RIS) and cell-free network architecture. We
further propose a large language model (LLM) framework as an intelligent
question-answering agent, leveraging this survey as a local knowledge base to
enable GNN-related responses tailored to wireless communication research.

</details>


### [320] [Sparse Near-Field Channel Estimation for XL-MIMO via Adaptive Filtering](https://arxiv.org/abs/2508.08663)
*Vidya Bhasker Shukla,Italo Atzeni*

Main category: eess.SP

TL;DR: XL-MIMO系统在次太赫兹载波频率上的稀疏通道估计。


<details>
  <summary>Details</summary>
Motivation: 满足下一代无线应用的需求，XL-MIMO系统在次太赫兹载波频率上运行。

Method: 基于极坐标域自适应滤波的通道估计框架，称为极坐标域零吸引最小均方（PD-ZALMS）。

Result: PD-ZALMS比极坐标域匹配追踪具有更高的通道估计精度和更低的计算复杂度。

Conclusion: PD-ZALMS在低信噪比下表现优于最小二乘法估计器，并且在通道估计准确性和计算复杂度方面优于极坐标域匹配追踪。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems
operating at sub-THz carrier frequencies represent a promising solution to meet
the demands of next-generation wireless applications. This work focuses on
sparse channel estimation for XL-MIMO systems operating in the near-field (NF)
regime. Assuming a practical subarray-based architecture, we develop a NF
channel estimation framework based on adaptive filtering, referred to as
\textit{polar-domain zero-attracting least mean squares (PD-ZALMS)}. The
proposed method achieves significantly superior channel estimation accuracy and
lower computational complexity compared with the well-established polar-domain
orthogonal matching pursuit. In addition, the proposed PD-ZALMS is shown to
outperform the oracle least-squares channel estimator at low-to-moderate
signal-to-noise ratio.

</details>


### [321] [VQ-VAE Based Digital Semantic Communication with Importance-Aware OFDM Transmission](https://arxiv.org/abs/2508.08686)
*Ming Lyu,Hao Chen,Dan Wang,Chen Qiu,Guangyin Feng,Nan Ma,Xiaodong Xu*

Main category: eess.SP

TL;DR: A digital semantic communication system using VQ-VAE and importance-aware OFDM is proposed, improving efficiency and outperforming existing methods in low SNR environments.


<details>
  <summary>Details</summary>
Motivation: Most conventional deep learning-based SemCom systems focus on analog transmission and lack compatibility with practical digital communications. This paper addresses this gap by proposing a digital SemCom system.

Method: This paper proposes a digital SemCom system based on VQ-VAE, which generates a discrete codebook shared between the transmitter and receiver. The system extracts latent semantic features using VQ-VAE, matches them with the shared codebook, and transforms them into a discrete version for digital transmission. An importance-aware OFDM transmission strategy is incorporated, allocating key features near OFDM reference signals based on gradient-based methods for feature importance. The receiver rematches features with the shared codebook for error correction.

Result: Experimental results demonstrate that the proposed scheme outperforms conventional DeepSC and achieves better reconstruction performance under low SNR regions.

Conclusion: The proposed VQ-VAE based digital SemCom system with importance-aware OFDM transmission enhances SemCom performance and outperforms conventional DeepSC, especially in low SNR regions.

Abstract: Semantic communication (SemCom) significantly reduces redundant data and
improves transmission efficiency by extracting the latent features of
information. However, most of the conventional deep learning-based SemCom
systems focus on analog transmission and lack in compatibility with practical
digital communications. This paper proposes a vector quantized-variational
autoencoder (VQ-VAE) based digital SemCom system that directly transmits the
semantic features and incorporates the importance-aware orthogonal frequency
division multiplexing (OFDM) transmission to enhance the SemCom performance,
where the VQ-VAE generates a discrete codebook shared between the transmitter
and receiver. At transmitter, the latent semantic features are firstly
extracted by VQ-VAE, and then the shared codebook is adopted to match these
features, which are subsequently transformed into a discrete version to adapt
the digital transmission. To protect the semantic information, an
importance-aware OFDM transmission strategy is proposed to allocate the key
features near the OFDM reference signals, where the feature importance is
derived from the gradient-based method. At the receiver, the features are
rematched with the shared codebook to further correct errors. Finally,
experimental results demonstrate that our proposed scheme outperforms the
conventional DeepSC and achieves better reconstruction performance under low
SNR region.

</details>


### [322] [Evaluating Task Execution Performance Under Energy Measurement Overhead](https://arxiv.org/abs/2508.08757)
*Mateen Ashraf,Shahab Jahanbazi,Onel L. A. López*

Main category: eess.SP

TL;DR: 能量收集物联网设备在优化任务调度时，需要考虑能量测量的成本。不当的频率设置会使能量感知调度效果变差。存在最优频率组合能最大化任务完成率。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于，尽管能量感知（Energy-awareness）可以为能量收集（EH）物联网设备的任务执行带来性能提升，但传统上被忽略的能量测量成本可能会抵消甚至逆转这些好处。

Method: 该研究通过考虑能量测量频率和任务执行频率等操作参数，比较了能量无关（EB）和能量感知（EA）的任务决策方法，以评估它们在任务完成率方面的表现。

Result: 研究结果显示，EH-IoT设备的任务完成率可以通过调整能量测量频率和任务执行频率来优化。不当的参数选择会导致EA调度性能下降，甚至不如EB调度。

Conclusion: 该研究表明，对于能量收集（EH）物联网设备，存在一个最优的能量测量/任务执行频率组合，可以在能量感知（EA）和能量无关（EB）的调度方法中最大化任务完成率。如果这些参数选择不当，能量测量成本可能导致EA调度性能不如EB调度。

Abstract: Energy-awareness for adapting task execution behavior can bring several
benefits in terms of performance improvement in energy harvesting (EH) Internet
of Things (IoT) devices. However, the energy measurement cost of acquiring
energy information, which is traditionally ignored, can potentially neutralize
or even reverse the potential benefits. This paper highlights operational
parameters, such as energy measurement frequency and task execution frequency,
which can be tuned to improve the task execution performance of an EH-IoT
device. To this end, we consider energy-blind (EB) and energy-aware (EA) task
decision approaches and compare their task completion rate performance. We show
that, for specific hardware design parameters of an EH-IoT device, there exists
an optimal energy measurement/task execution frequency that can maximize the
task completion rate in both approaches. Moreover, if these parameters are not
chosen appropriately, then energy measurement costs can cause EA scheduling to
underperform compared to EB scheduling.

</details>


### [323] [Wideband Coplanar Waveguide MIMO Antenna for 6G Millimeter-Wave Applications with Defected Ground Structure](https://arxiv.org/abs/2508.08771)
*Atta Ullah,Daniyal Munir,Daniel Lindenschmitt,Hans D. Schotten*

Main category: eess.SP

TL;DR: 提出了一种用于6G毫米波频段（25-33.5 GHz）的新型宽带小型天线，采用CPW馈电的微带贴片结合DGS技术，实现了8.5 GHz的回波损耗宽带。


<details>
  <summary>Details</summary>
Motivation: 为了满足6G无线网络对更高频率和宽带容量的需求，特别是针对6G毫米波（mmWave）的6G毫米波（mmWave）工作频段。

Method: 采用包含缺陷地结构（DGS）的共面波导（CPW）馈电的微带贴片结构。

Result: 单个天线实现了8.5 GHz的优异回波损耗宽带性能，并提出了2x2 MIMO天线设计，包含8个单元。

Conclusion: 该研究提出了一种用于6G无线网络的新型宽带小型天线，工作频段为25 GHz至33.5 GHz。

Abstract: This research study introduces a novel small antenna with wideband capacity
for the higher frequency range. As a possible contender for 6G wireless
networks, the proposed antenna is designed to target the 6G Millimeter-Wave
(mmWave) operating bands spanning 25 GHz to 33.5 GHz. With a microstrip patch
structure fed by a coplanar waveguide (CPW) with the defected ground structure
(DGS), a single antenna is introduced and then a design of 2 x 2 MIMO antenna
is presented. The single antenna has 2 elements, while the 2 x 2 MIMO antenna
has 8 elements. It achieves remarkably well in terms of return loss of 8.5 GHz
wideband, which is anticipated to be used for several applications in 6G mmWave
technology.

</details>


### [324] [Patient-Adaptive Focused Transmit Beamforming using Cognitive Ultrasound](https://arxiv.org/abs/2508.08782)
*Wessel L. van Nierop,Oisín Nolan,Tristan S. W. Stevens,Ruud J. G. van Sloun*

Main category: eess.SP

TL;DR: 通过一种新的自适应聚焦发射方案，使用后验采样和时间扩散模型，在减少超声成像所需发射次数的同时，提高了图像质量和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有超声成像技术（如聚焦发射波束成形和非聚焦发射成像）的低帧率、运动去相关和有限的谐波成像能力等缺点。

Method: 该方法利用后验采样和时间扩散模型来感知和重建解剖结构，并据此采取行动以获取信息量最大的发射。

Result: 该方法在2D EchoNet-Dynamic数据集和3D Philips数据集上，通过主动选择聚焦的方位角平面， outperformed了随机和等距子采样，并在三种心脏超声检查中，在通用对比度比方面取得了比相同数量的发散波发射更好的性能。此外，仅用2%的发射即可估算射血分数，并且该方法对异常患者具有鲁棒性。

Conclusion: 该方法在2D EchoNet-Dynamic数据集和3D Philips数据集上，通过主动选择聚焦的方位角平面， outperformed了随机和等距子采样，并在三种心脏超声检查中，在通用对比度比方面取得了比相同数量的发散波发射更好的性能。

Abstract: Focused transmit beamforming is the most commonly used acquisition scheme for
echocardiograms, but suffers from relatively low frame rates, and in 3D, even
lower volume rates. Fast imaging based on unfocused transmits has disadvantages
such as motion decorrelation and limited harmonic imaging capabilities. This
work introduces a patient-adaptive focused transmit scheme that has the ability
to drastically reduce the number of transmits needed to produce a high-quality
ultrasound image. The method relies on posterior sampling with a temporal
diffusion model to perceive and reconstruct the anatomy based on partial
observations, while subsequently taking an action to acquire the most
informative transmits. This active perception modality outperforms random and
equispaced subsampling on the 2D EchoNet-Dynamic dataset and a 3D Philips
dataset, where we actively select focused elevation planes. Furthermore, we
show it achieves better performance in terms of generalized contrast-to-noise
ratio when compared to the same number of diverging waves transmits on three
in-house echocardiograms. Additionally, we can estimate ejection fraction using
only 2% of the total transmits and show that the method is robust to outlier
patients. Finally, our method can be run in real-time on GPU accelerators from
2023. The code is publicly available at https://tue-bmd.github.io/ulsa/

</details>


### [325] [ReQuestNet: A Foundational Learning model for Channel Estimation](https://arxiv.org/abs/2508.08790)
*Kumar Pratik,Pouriya Sadeghi,Gabriele Cesa,Sanaz Barghi,Joseph B. Soriaga,Yuanning Yu,Supratik Bhattacharjee,Arash Behboodi*

Main category: eess.SP

TL;DR: ReQuestNet is a new neural network for 5G channel estimation that simplifies the process and outperforms existing methods, especially in complex scenarios with dynamic configurations. It achieves significant gains by cleverly processing different parts of the signal and their correlations.


<details>
  <summary>Details</summary>
Motivation: To simplify the channel estimation pipeline and address limitations of legacy linear MMSE solutions by developing a novel neural architecture that handles practical wireless communication system considerations and jointly processes MIMO layers and differently precoded channels with unknown precoding.

Method: ReQuestNet, a novel neural architecture for channel estimation (CE), incorporates practical considerations like variable RBs, dynamic transmit layers, and DMRS patterns into a single model. It consists of two sub-units: CoarseNet for per-PRG, per-stream estimation, and RefinementNet for refining estimates by incorporating cross-PRG and cross-MIMO correlations.

Result: ReQuestNet significantly outperforms genie MMSE CE across a wide range of channel conditions and delay-Doppler profiles, achieving up to 10dB gain at high SNRs. It generalizes effectively to unseen channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations under dynamic PRG BS and varying transmit layer allocations.

Conclusion: ReQuestNet significantly outperforms genie MMSE CE across a wide range of channel conditions and delay-Doppler profiles, achieving up to 10dB gain at high SNRs. It also generalizes effectively to unseen channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations under dynamic PRG BS and varying transmit layer allocations.

Abstract: In this paper, we present a novel neural architecture for channel estimation
(CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network
(ReQuestNet). It incorporates several practical considerations in wireless
communication systems, such as ability to handle variable number of resource
block (RB), dynamic number of transmit layers, physical resource block groups
(PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a
single unified model, thereby, drastically simplifying the CE pipeline. Besides
it addresses several limitations of the legacy linear MMSE solutions, for
example, by being independent of other reference signals and particularly by
jointly processing MIMO layers and differently precoded channels with unknown
precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet
followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive
(Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet
channel estimate by incorporating correlations across differently precoded
PRGs, and correlation across multiple input multiple output (MIMO) channel
spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet
significantly outperforms genie minimum mean squared error (MMSE) CE across a
wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB
gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen
channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations
under dynamic PRG BS and varying transmit layer allocations.

</details>


### [326] [Iterative Distortion Cancellation Algorithms for Single-Sideband Systems](https://arxiv.org/abs/2508.08796)
*Jun Dong,Tianwai Bo,Zhuo Wang,Haolei Gao,Zhongwei Tan,Yi Dong*

Main category: eess.SP

TL;DR: 提出了一种迭代失真消除算法，用于解决Kramers-Kronig接收机中的双边带微扰信号失真问题，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了数字式地减轻双边带微扰信号幅度对Kramers-Kronig接收机的影响，同时不修改物理层结构。

Method: 提出了一种迭代失真消除算法，利用KK关系进行初始信号判决并重建由微扰信号引起的失真。

Result: 实验测试表明，该算法将对微扰信号幅度的容忍度提高了10% Vπ，并使80公里光纤传输的接收机灵敏度提高了1dB以上。

Conclusion: 该算法通过迭代失真消除，在不改变物理层结构的情况下，有效抑制了双边带微扰信号幅度对Kramers-Kronig接收机的影响，提高了接收机对微扰信号幅度的容忍度（最高达10% Vπ），并在80公里光纤传输中将接收机灵敏度提高了1dB以上。

Abstract: We propose an iterative distortion cancellation algorithm to digitally
mitigate the impact of double-sideband dither signal amplitude from the
automatic bias control module on Kramers-Kronig receivers without modifying
physical layer structures. The algorithm utilizes the KK relation for initial
signal decisions and reconstructs the distortion caused by dither signals.
Experimental tests in back-to-back showed it improved tolerance to dither
amplitudes up to 10% V{\pi}. For 80-km fiber transmission, the algorithm
increased the receiver sensitivity by more than 1 dB, confirming the
effectiveness of the proposed distortion cancellation method.

</details>


### [327] [Trajectory-adaptive Beam Shaping: Towards Beam-Management-Free Near-field Communications](https://arxiv.org/abs/2508.08894)
*Sicong Ye,Yulan Gao,Ming Xiao,Peng Wang,Marios Poulakis,Ulrik Imberg*

Main category: eess.SP

TL;DR: TABS是一种无需实时波束管理的新型波束成形技术，通过使波束沿用户轨迹传播来提高性能并降低开销。


<details>
  <summary>Details</summary>
Motivation: 为了解决在毫米波和太赫兹频段中，由于路径损耗和波束失配风险增加（尤其是在近场通信中）而导致的传统波束管理的高计算和信令开销问题。

Method: 提出了一种新颖的轨迹自适应波束成形（TABS）方法，通过塑造电磁波前沿以跟随用户预定义轨迹，无需进行实时波束管理。借鉴光学中自加速光束的原理，TABS能够沿着对应用户运动的预定义曲线路径集中能量，而无需进行实时的波束重构。此外，还引入了一个专门的量化指标来表征TABS框架下的性能。

Result: 仿真结果表明，TABS在链路性能、开销降低和实现复杂度方面均优于传统方法。

Conclusion: TABS在链路性能、开销降低和实现复杂度方面优于传统方法。

Abstract: The quest for higher wireless carrier frequencies spanning the
millimeter-wave (mmWave) and Terahertz (THz) bands heralds substantial
enhancements in data throughput and spectral efficiency for next-generation
wireless networks. However, these gains come at the cost of severe path loss
and a heightened risk of beam misalignment due to user mobility, especially
pronounced in near-field communication. Traditional solutions rely on extremely
directional beamforming and frequent beam updates via beam management, but such
techniques impose formidable computational and signaling overhead. In response,
we propose a novel approach termed trajectory-adaptive beam shaping (TABS) that
eliminates the need for real-time beam management by shaping the
electromagnetic wavefront to follow the user's predefined trajectory. Drawing
inspiration from self-accelerating beams in optics, TABS concentrates energy
along pre-defined curved paths corresponding to the user's motion without
requiring real-time beam reconfiguration. We further introduce a dedicated
quantitative metric to characterize performance under the TABS framework.
Comprehensive simulations substantiate the superiority of TABS in terms of link
performance, overhead reduction, and implementation complexity.

</details>


### [328] [Scalable RIS-Aided Beamforming Strategies for Near-Field MU-MISO via Multi-Antenna Feeder](https://arxiv.org/abs/2508.08993)
*Giulia Torcolacci,Malte Schellmann,Davide Dardari*

Main category: eess.SP

TL;DR: 本文提出了一种 AT-RIS 架构，用于 RIS 辅助的近场 MU 通信，并分析了对角线和非对角线 T-RIS 架构的性能。研究发现，对角线 AT-RIS 在扩展性、公平性和所需信道状态信息方面具有优势，尤其是在 UE 密度增加的情况下，使其成为有前景的解决方案。


<details>
  <summary>Details</summary>
Motivation: 近场通信和 RIS 技术的发展，以及多用户通信在这些场景下的挑战。

Method: 本文提出了一种用于可重构智能表面 (RIS) 辅助的多用户 (MU) 近场通信的模块化波束成形框架，该框架基于一种集成了有源多天线馈线 (AMAF) 阵列和透射式 RIS (T-RIS) 的新型天线架构，称为 AT-RIS。该解耦实现了 AMAF 和 T-RIS 域中的协同且独立可配置的设计，支持具有不同复杂性-性能权衡的灵活策略。分析了几种实现方式，包括对角线和非对角线 T-RIS 架构，以及基于聚焦、最小均方误差和特征模式分解的预编码方案。

Result: 仿真结果表明，非对角线方案在 UE 数量有限且角度可分离性高的情况下可最大化总和速率，但在 UE 密度增加时公平性和可扩展性受限。相比之下，对角线 T-RIS 配置（特别是提出的基于聚焦的方案和均匀馈电侧功率分配）提供了稳健、公平且可扩展的性能，且所需的信道状态信息最少。研究结果强调了 UE 角度可分离性的关键影响，并揭示了频谱效率、复杂性和公平性之间固有的权衡。

Conclusion: 非对角线方案在 UE 数量有限且角度可分离性高的情况下可最大化总和速率，但在 UE 密度增加时公平性和可扩展性受限。相比之下，对角线 T-RIS 配置（特别是提出的基于聚焦的方案和均匀馈电侧功率分配）提供了稳健、公平且可扩展的性能，且所需的信道状态信息最少。研究结果强调了 UE 角度可分离性的关键影响，并揭示了频谱效率、复杂性和公平性之间固有的权衡，使对角线 AT-RIS 架构成为可扩展近场 MU 多输入单输出系统的实用解决方案。

Abstract: This paper investigates a modular beamforming framework for reconfigurable
intelligent surface (RIS)-aided multi-user (MU) communications in the
near-field regime, built upon a novel antenna architecture integrating an
active multi-antenna feeder (AMAF) array with a transmissive RIS (T-RIS),
referred to as AT-RIS. This decoupling enables coordinated yet independently
configurable designs in the AMAF and T-RIS domains, supporting flexible
strategies with diverse complexity-performance trade-offs. Several
implementations are analyzed, including diagonal and non-diagonal T-RIS
architectures, paired with precoding schemes based on focusing, minimum mean
square error, and eigenmode decomposition. Simulation results demonstrate that
while non-diagonal schemes maximize sum rate in scenarios with a limited number
of User Equipments (UEs) and high angular separability, they exhibit fairness
and scalability limitations as UE density increases. Conversely, diagonal T-RIS
configurations, particularly the proposed focusing-based scheme with uniform
feeder-side power allocation, offer robust, fair, and scalable performance with
minimal channel state information. The findings emphasize the critical impact
of UEs' angular separability and reveal inherent trade-offs among spectral
efficiency, complexity, and fairness, positioning diagonal AT-RIS architectures
as practical solutions for scalable near-field MU multiple-input single-output
systems.

</details>


### [329] [Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information](https://arxiv.org/abs/2508.09020)
*Maria Cecilia Fernández Montefiore,Gustavo González,F. Javier López-Martínez,Fernando Gregorio*

Main category: eess.SP

TL;DR: 本研究提出了一种改进的 SINR 统计近似方法，用于 MU-MIMO DL 系统，该系统具有不完美的 CSIT，并在 RSMA MIMO DL 系统中进行了验证，证明了其准确性。


<details>
  <summary>Details</summary>
Motivation: 理解发射机处具有不完美信道状态信息（CSIT）的 MU-MIMO 系统的性能仍然是下一代无线网络中的一个关键挑战。在此背景下，SINR 的准确统计建模对于实现 MU 系统的可处理性能分析至关重要。

Method: 提出了一种用于具有不完美 CSIT 的下行链路（DL）MU-MIMO 系统的 SINR 的改进统计近似。

Result: 所提出的模型在具有过时 CSIT 的RSMA MIMO DL 系统中进行了评估。结果表明，在各种系统配置（包括用户数量、天线数量和 CSIT 过时程度的变化）中，该模型都具有出色的准确性。

Conclusion: 所提出的近似模型保留了现有方法（例如，基于 Gamma 的近似）的分析简单性，同时克服了它们的局限性，特别是低估了 SINR 方差。

Abstract: Understanding the performance of multi-user multiple-input multiple-output
(MU-MIMO) systems under imperfect channel state information at the transmitter
(CSIT) remains a critical challenge in next-generation wireless networks. In
this context, accurate statistical modeling of the
signal-to-interference-plus-noise ratio (SINR) is essential for enabling
tractable performance analysis of multi-user systems. This paper presents an
improved statistical approximation of the SINR for downlink (DL) MU-MIMO
systems with imperfect CSIT. The proposed model retains the analytical
simplicity of existing approaches (e.g., Gamma-based approximations) while
overcoming their limitations, particularly the underestimation of SINR
variance. We evaluate the proposed approximation in the context of
Rate-Splitting Multiple Access (RSMA)-enabled MIMO DL systems with outdated
CSIT. The results demonstrate excellent accuracy across a wide range of system
configurations, including varying numbers of users, antennas, and degrees of
CSIT staleness.

</details>


### [330] [Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins](https://arxiv.org/abs/2508.09055)
*Lorenzo Cazzella,Francesco Linsalata,Mahdi Maleki,Damiano Badini,Matteo Matteucci,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 无线通信系统可通过信道绘制技术构建空间一致的无线信道图。本研究提出Chartwin，将信道绘制与动态数字网络孪生（DNTs）相结合，通过半监督学习实现了高效的信道绘制和定位，定位误差在几米范围内。


<details>
  <summary>Details</summary>
Motivation: 为了让无线通信系统能够有效地执行各种通信任务，需要空间上一致的无线信道表示。信道绘制作为一种有效的无监督学习技术，旨在实现局部和全局一致的无线电地图。

Method: 提出Chartwin，整合了定位导向的信道绘制与动态数字网络孪生（DNTs），并采用半监督学习方法。

Result: 在扩展城市环境中，静态DNT实现了约4.5米的定位误差，动态DNT实现了约6米的定位误差，证明了DNT辅助的信道绘制和定位的有效性。

Conclusion: 该研究提出了Chartwin，一个将定位导向的信道绘制与动态数字网络孪生（DNTs）相结合的案例研究，并在考虑的扩展城市环境中，利用半监督信道绘制构建了空间一致的无线信道图，实现了显著的定位性能。

Abstract: Wireless communication systems can significantly benefit from the
availability of spatially consistent representations of the wireless channel to
efficiently perform a wide range of communication tasks. Towards this purpose,
channel charting has been introduced as an effective unsupervised learning
technique to achieve both locally and globally consistent radio maps. In this
letter, we propose Chartwin, a case study on the integration of
localization-oriented channel charting with dynamic Digital Network Twins
(DNTs). Numerical results showcase the significant performance of
semi-supervised channel charting in constructing a spatially consistent chart
of the considered extended urban environment. The considered method results in
$\approx$ 4.5 m localization error for the static DNT and $\approx$ 6 m in the
dynamic DNT, fostering DNT-aided channel charting and localization.

</details>


### [331] [Spectral Efficiency Considerations for 6G](https://arxiv.org/abs/2508.09117)
*Joseph Boccuzzi*

Main category: eess.SP

TL;DR: 该论文提出了一个新的无线资源利用效率（RUE）指标，以评估6G网络中的无线资源利用情况，并通过比较不同的网络部署和分析影响因素，展示了其改进潜力，并提出了支持6G和AI-RAN的下一代RAN架构。


<details>
  <summary>Details</summary>
Motivation: 随着无线连接向6G演进，在提供更高吞吐量、更低延迟和更高可靠性的同时，实现高效率变得越来越重要。现有的效率指标（如频谱效率SE和能量效率EE）可能无法完全捕捉无线资源的利用情况，因此需要引入新的系统指标来衡量无线资源（频谱、接入方式、时隙、数据符号等）的利用效率，以满足未来6G的需求。

Method: 该研究量化了无线资源利用效率（RUE），并将其应用于比较典型蜂窝网络和无蜂窝大规模MIMO（Multiple-Input Multiple-Output）部署的系统性能。通过分析影响频谱效率（SE）的因素（包括5G无线资源、实际限制和实现损失），以及研究增加传输带宽（BW）的好处，来论证RUE的有效性。

Result: 通过对5G无线接入技术配置的分析，该论文展示了其无线资源利用效率（RUE）为47%，表明在定义6G时存在显著的改进空间。研究中还对实际限制假设与商业化部署的5G多用户MIMO（MU-MIMO）测量结果进行了比较，并表征了频谱效率（SE）损失，为采用机器学习（ML）技术的先进算法提供了指导。此外，研究还描述了支持6G和AI-RAN的下一代RAN（无线接入网）架构。

Conclusion: 该论文介绍了一种新的系统指标——无线资源利用效率（RUE），用于量化未来6G网络中可用无线资源（频谱、接入方式、时隙、数据符号等）的利用效率。通过比较典型蜂窝网络和无蜂窝大规模MIMO部署的系统性能，证明了引入RUE的必要性。研究表明，在所分析的5G无线接入技术配置中，RUE为47%，表明在定义6G时有很大的改进空间。此外，论文还讨论了影响频谱效率（SE）的因素，包括5G无线资源、实际限制（如信道矩阵秩亏缺）和实现损失（SINR退化），并研究了将传输带宽（BW）从100MHz增加到1.6GHz的好处，最后描述了一个支持6G和AI-RAN的下一代RAN架构。

Abstract: As wireless connectivity continues to evolve towards 6G, there is an
ever-increasing demand to not only deliver higher throughput, lower latency,
and improved reliability, but also do so as efficiently as possible. To this
point, the term efficiency has been quantified through applications to Spectral
Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new
system metric called Radio Resource Utilization Efficiency (RUE). This metric
quantifies the efficiency of the available radio resources (Spectrum, Access
Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We
compare the system performance of Typical Cellular and Cell-Free Massive MIMO
deployments as a vehicle to demonstrate the need for this new metric. We begin
by providing a concise treatment of items impacting SE by introducing three
categories: 5G Radio Resources, Practical Limitations (such as channel matrix
rank deficiency) and Implementation Losses (SINR degradation). For the example
Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47%
(revealing significant room for improvement when defining 6G). Practical
limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO)
measurements conducted in a commercialized deployment. SE losses are
characterized to offer guidance to advanced algorithms employing Machine
Learning (ML) based techniques. We present the benefits of increasing the
transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next
Generation RAN architecture that can support 6G and AI-RAN.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [332] [Humanoid Robot Acrobatics Utilizing Complete Articulated Rigid Body Dynamics](https://arxiv.org/abs/2508.08258)
*Gerald Brantner*

Main category: cs.RO

TL;DR: Humanoid robots can now do acrobatics! We designed a new control system that uses the robot's full physics model, avoiding tricky approximations, making them perform complex moves like flips and twists, as shown in simulations.


<details>
  <summary>Details</summary>
Motivation: Humanoid robots' ability to perform highly dynamic, human-level acrobatic motions is a long-standing challenge due to the complexity of planning and controlling high-degree-of-freedom systems using explicit equations of motion. Existing methods like linearization and model approximations yield suboptimal performance.

Method: This paper presents a control architecture that combines trajectory optimization and whole-body control, using a matching model abstraction to bridge the gap between planning and execution. This approach conditions the control on the unabbreviated equations of motion for articulated rigid body models, overcoming limitations of linearization and model approximations.

Result: The system's effectiveness in enabling acrobatic maneuvers, including constraint and posture behaviors, has been analyzed in simulation.

Conclusion: The proposed control architecture enables humanoid robots to execute dynamic acrobatic maneuvers by addressing the complexities of high degrees-of-freedom and leveraging the full equations of motion through a matching model abstraction.

Abstract: Endowing humanoid robots with the ability to perform highly dynamic motions
akin to human-level acrobatics has been a long-standing challenge. Successfully
performing these maneuvers requires close consideration of the underlying
physics in both trajectory optimization for planning and control during
execution. This is particularly challenging due to humanoids' high
degree-of-freedom count and associated exponentially scaling complexities,
which makes planning on the explicit equations of motion intractable. Typical
workarounds include linearization methods and model approximations. However,
neither are sufficient because they produce degraded performance on the true
robotic system. This paper presents a control architecture comprising
trajectory optimization and whole-body control, intermediated by a matching
model abstraction, that enables the execution of acrobatic maneuvers, including
constraint and posture behaviors, conditioned on the unabbreviated equations of
motion of the articulated rigid body model. A review of underlying modeling and
control methods is given, followed by implementation details including model
abstraction, trajectory optimization and whole-body controller. The system's
effectiveness is analyzed in simulation.

</details>


### [333] [Koopman Operator Based Linear Model Predictive Control for Quadruped Trotting](https://arxiv.org/abs/2508.08259)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 利用 Koopman 算子理论改进 LMPC，用于四足机器人运动控制，实现了高精度跟踪和扰动抑制。


<details>
  <summary>Details</summary>
Motivation: 在线最优控制对于四足机器人适应不断变化的输入和条件至关重要，而传统的 LMPC 方法由于模型线性化存在误差。

Method: 使用 Koopman 算子创建四足系统的线性模型，该模型保留了运动方程的非线性特性，然后利用 LMPC 解决了该模型。

Result: 通过 Koopman 算子和 LMPC，在四足机器人上实现了高保真的跟踪和扰动抑制。

Conclusion: 本文提出了一种使用 Koopman 算子理论来实现 LMPC 的方法，并成功应用于四足机器人实现了高保真跟踪和扰动抑制，这是该领域的首次尝试。

Abstract: Online optimal control of quadruped robots would enable them to adapt to
varying inputs and changing conditions in real time. A common way of achieving
this is linear model predictive control (LMPC), where a quadratic programming
(QP) problem is formulated over a finite horizon with a quadratic cost and
linear constraints obtained by linearizing the equations of motion and solved
on the fly. However, the model linearization may lead to model inaccuracies. In
this paper, we use the Koopman operator to create a linear model of the
quadrupedal system in high dimensional space which preserves the nonlinearity
of the equations of motion. Then using LMPC, we demonstrate high fidelity
tracking and disturbance rejection on a quadrupedal robot. This is the first
work that uses the Koopman operator theory for LMPC of quadrupedal locomotion.

</details>


### [334] [Forecast-Driven MPC for Decentralized Multi-Robot Collision Avoidance](https://arxiv.org/abs/2508.08264)
*Hadush Hailu,Bruk Gebregziabher,Prudhvi Raj*

Main category: cs.RO

TL;DR: eIFP-MPC通过引入碰撞时间启发式、成本导向路径点选择和MPC，改进了IFP，解决了其在对称环境下的缺点，提高了在密集动态场景下的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的迭代预测规划器（IFP）虽然在去中心化、无通信的设置下具有轻量、可扩展和反应迅速的优点，但在对称配置下表现不佳，容易发生碰撞和死锁。因此需要一种改进方法来增强其鲁棒性和路径一致性，特别是在密集和动态的环境中。

Method: 提出eIFP-MPC，对IFP进行了优化和扩展，通过引入基于碰撞时间（TTC）的启发式方法来改进威胁优先级排序，通过基于成本的路径点选择来稳定路径生成，并通过整合模型预测控制（MPC）来确保动态可行性，从而在保持IFP效率的同时提高其适应性和稳定性。

Result: eIFP-MPC在对称和高密度场景的广泛模拟中，显著减少了振荡，确保了无碰撞运动，并提高了轨迹效率，证明了通过优化可以增强几何规划器的性能，使其在复杂的、大规模的多代理环境中能够稳健运行。

Conclusion: eIFP-MPC通过优化威胁优先级、成本导向的路径点选择和模型预测控制，显著提高了IFP在密集动态环境下的鲁棒性和路径一致性，解决了IFP在对称配置下的不足，能在复杂多机器人环境中实现高效、无碰撞的运动。

Abstract: The Iterative Forecast Planner (IFP) is a geometric planning approach that
offers lightweight computations, scalable, and reactive solutions for
multi-robot path planning in decentralized, communication-free settings.
However, it struggles in symmetric configurations, where mirrored interactions
often lead to collisions and deadlocks. We introduce eIFP-MPC, an optimized and
extended version of IFP that improves robustness and path consistency in dense,
dynamic environments. The method refines threat prioritization using a
time-to-collision heuristic, stabilizes path generation through cost-based
via-point selection, and ensures dynamic feasibility by incorporating model
predictive control (MPC) into the planning process. These enhancements are
tightly integrated into the IFP to preserve its efficiency while improving its
adaptability and stability. Extensive simulations across symmetric and
high-density scenarios show that eIFP-MPC significantly reduces oscillations,
ensures collision-free motion, and improves trajectory efficiency. The results
demonstrate that geometric planners can be strengthened through optimization,
enabling robust performance at scale in complex multi-agent environments.

</details>


### [335] [emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands](https://arxiv.org/abs/2508.08269)
*Sagar Verma*

Main category: cs.RO

TL;DR: 为肌腱驱动机器人手开发了首个大规模EMG到肌腱控制数据集和基于扩散模型的预测方法，以克服传统控制学习的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于肌腱驱动机器人手缺乏直接的运动捕捉数据到肌腱控制的映射，以及现有视觉跟踪方法的局限性，学习控制策略变得复杂且昂贵。虽然表面肌电信号（sEMG）是捕捉手部运动的廉价替代方案，但从sEMG信号映射到肌腱控制仍然是一个重大挑战。

Method: 提出了一种基于扩散模型的回归方法，用于从表面肌电信号（sEMG）预测肌腱控制信号。该方法利用了扩展自emg2pose数据集的新数据集（emg2tendon），该数据集包含193名受试者、370小时的记录和29种不同的手势，并使用MyoSuite MyoHand模型推导肌腱控制信号。

Result: 构建了一个大规模的肌电信号到肌腱控制的数据集（emg2tendon），并提供了三个基线回归模型来展示其效用。提出的扩散模型在肌腱控制预测方面表现出潜力，为肌腱驱动的机器人手提供了可扩展和准确的控制解决方案。

Conclusion: 本研究介绍了首个用于机器人手的大规模肌电信号到肌腱控制的数据集（emg2tendon），并提出了基于扩散模型的肌腱控制预测方法，为驱动灵巧的机器人手提供了可扩展且准确的肌腱控制基础。

Abstract: Tendon-driven robotic hands offer unparalleled dexterity for manipulation
tasks, but learning control policies for such systems presents unique
challenges. Unlike joint-actuated robotic hands, tendon-driven systems lack a
direct one-to-one mapping between motion capture (mocap) data and tendon
controls, making the learning process complex and expensive. Additionally,
visual tracking methods for real-world applications are prone to occlusions and
inaccuracies, further complicating joint tracking. Wrist-wearable surface
electromyography (sEMG) sensors present an inexpensive, robust alternative to
capture hand motion. However, mapping sEMG signals to tendon control remains a
significant challenge despite the availability of EMG-to-pose data sets and
regression-based models in the existing literature.
  We introduce the first large-scale EMG-to-Tendon Control dataset for robotic
hands, extending the emg2pose dataset, which includes recordings from 193
subjects, spanning 370 hours and 29 stages with diverse gestures. This dataset
incorporates tendon control signals derived using the MyoSuite MyoHand model,
addressing limitations such as invalid poses in prior methods. We provide three
baseline regression models to demonstrate emg2tendon utility and propose a
novel diffusion-based regression model for predicting tendon control from sEMG
recordings. This dataset and modeling framework marks a significant step
forward for tendon-driven dexterous robotic manipulation, laying the groundwork
for scalable and accurate tendon control in robotic hands.
https://emg2tendon.github.io/

</details>


### [336] [A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems](https://arxiv.org/abs/2508.08473)
*Hossein B. Jond*

Main category: cs.RO

TL;DR: 提出了一种新的群体行为模型，通过使用相对位置、速度和局部密度，并由两个可调参数控制，实现了灵活、无碰撞的行为，并能通过自适应控制参数调整，在群体和集群行为之间实现节能的相变。


<details>
  <summary>Details</summary>
Motivation: 现有的模型（如 Vicsek 和 Cucker-Smale）缺乏碰撞避免，而 Olfati-Saber 模型强制执行严格的编队，这限制了它们在群体机器人技术中的应用。本研究旨在解决这些限制。

Method: 该模型使用相对位置、速度和局部密度，并由空间偏移和动能偏移两个可调参数进行调节，以控制代理动力学。

Result: 该模型实现了空间灵活、无碰撞的行为，能够反映自然群体动力学，并能通过自适应控制参数调整，在群体和集群行为之间实现节能的相变。

Conclusion: 该模型为现实世界中的多机器人系统，特别是自主空中群体，提供了强大的基础。

Abstract: Collective behaviors such as swarming and flocking emerge from simple,
decentralized interactions in biological systems. Existing models, such as
Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber
model imposes rigid formations, limiting their applicability in swarm robotics.
To address these limitations, this paper proposes a minimal yet expressive
model that governs agent dynamics using relative positions, velocities, and
local density, modulated by two tunable parameters: the spatial offset and
kinetic offset. The model achieves spatially flexible, collision-free behaviors
that reflect naturalistic group dynamics. Furthermore, we extend the framework
to cognitive autonomous systems, enabling energy-aware phase transitions
between swarming and flocking through adaptive control parameter tuning. This
cognitively inspired approach offers a robust foundation for real-world
applications in multi-robot systems, particularly autonomous aerial swarms.

</details>


### [337] [Evaluation of an Autonomous Surface Robot Equipped with a Transformable Mobility Mechanism for Efficient Mobility Control](https://arxiv.org/abs/2508.08303)
*Yasuyuki Fujii,Dinh Tuan Tran,Joo-Ho Lee*

Main category: cs.RO

TL;DR: 为了提高水面机器人的能源效率和机动性，研究人员开发了一种可变形的移动机制，并进行了实地实验。


<details>
  <summary>Details</summary>
Motivation: 为了提高自主水面机器人在长期水环境监测中的机动性和能源效率。

Method: 提出了一种可变形移动机制，并设计了两种控制模式：保持定点和行驶。

Result: 在往返任务中，与保持定点模式相比，行驶模式可减少 10% 的能耗，并缩短 5% 的总行程时间。

Conclusion: 该研究开发并评估了一种可变形水面机器人移动机制，该机制具有两种控制模式：保持定点和行驶，以提高能源效率和机动性。

Abstract: Efficient mobility and power consumption are critical for autonomous water
surface robots in long-term water environmental monitoring. This study develops
and evaluates a transformable mobility mechanism for a water surface robot with
two control modes: station-keeping and traveling to improve energy efficiency
and maneuverability. Field experiments show that, in a round-trip task between
two points, the traveling mode reduces power consumption by 10\% and decreases
the total time required for travel by 5\% compared to the station-keeping mode.
These results confirm the effectiveness of the transformable mobility mechanism
for enhancing operational efficiency in patrolling on water surface.

</details>


### [338] [Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators](https://arxiv.org/abs/2508.08328)
*Qiwei Liang,Boyang Cai,Rongyi He,Hui Li,Tao Teng,Haihan Duan,Changxin Huang,Runhao Zeng*

Main category: cs.RO

TL;DR: DQ-Bench是一个用于评估动态抓取的基准，DQ-Net是一个师生框架，可以从有限的感知线索中推断抓取配置，并在动态抓取任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注静态物体抓取，忽视了动态目标抓取的挑战，限制了其在物流分拣和人机协作等动态场景中的应用。因此，需要一个能够评估动态抓取的基准和相应的方法。

Method: 提出了一种名为DQ-Net的紧凑型师生框架，用于从有限的感知线索中推断抓取配置。教师网络利用特权信息来全面模拟目标的静态几何属性和动态运动特征，并集成抓取融合模块来为运动规划提供鲁棒的指导。学生网络则利用目标掩码、深度图和本体感觉状态进行双视角时域建模，以实现闭环动作输出。

Result: DQ-Net在DQ-Bench基准上进行了广泛的实验，证明了其在多种任务设置下对动态物体抓取的鲁棒性，并且在成功率和响应速度方面均显著优于基线方法。

Conclusion: DQ-Net在DQ-Bench上实现了鲁棒的动态物体抓取，在成功率和响应速度方面均显著优于基线方法。

Abstract: Quadrupedal robots with manipulators offer strong mobility and adaptability
for grasping in unstructured, dynamic environments through coordinated
whole-body control. However, existing research has predominantly focused on
static-object grasping, neglecting the challenges posed by dynamic targets and
thus limiting applicability in dynamic scenarios such as logistics sorting and
human-robot collaboration. To address this, we introduce DQ-Bench, a new
benchmark that systematically evaluates dynamic grasping across varying object
motions, velocities, heights, object types, and terrain complexities, along
with comprehensive evaluation metrics. Building upon this benchmark, we propose
DQ-Net, a compact teacher-student framework designed to infer grasp
configurations from limited perceptual cues. During training, the teacher
network leverages privileged information to holistically model both the static
geometric properties and dynamic motion characteristics of the target, and
integrates a grasp fusion module to deliver robust guidance for motion
planning. Concurrently, we design a lightweight student network that performs
dual-viewpoint temporal modeling using only the target mask, depth map, and
proprioceptive state, enabling closed-loop action outputs without reliance on
privileged data. Extensive experiments on DQ-Bench demonstrate that DQ-Net
achieves robust dynamic objects grasping across multiple task settings,
substantially outperforming baseline methods in both success rate and
responsiveness.

</details>


### [339] [CRADLE: Conversational RTL Design Space Exploration with LLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.08709)
*Lukas Krupp,Maximilian Schöffel,Elias Biehl,Norbert Wehn*

Main category: cs.RO

TL;DR: CRADLE 是一个基于 LLM 多代理系统的对话框架，用于 RTL 设计空间探索，可实现用户引导的流程和内部自我验证、纠正、优化，并在 FPGA 资源最小化方面取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的 RTL 设计空间探索方法较为僵化，CRADLE 旨在提供一种更灵活、用户可引导的流程。

Method: CRADLE 是一个利用基于 LLM 的多代理系统进行 RTL 设计空间探索的对话框架，通过生成器-批评者代理系统实现，并包含内部自我验证、纠正和优化功能。

Result: 在 RTLLM 基准测试中，CRADLE 在 LUT 和 FF 的使用量上平均分别实现了 48% 和 40% 的显著降低。

Conclusion: CRADLE 在 FPGA 资源最小化方面取得了显著成效，平均在所有基准设计中 LUT 和 FF 的使用量分别减少了 48% 和 40%。

Abstract: This paper presents CRADLE, a conversational framework for design space
exploration of RTL designs using LLM-based multi-agent systems. Unlike existing
rigid approaches, CRADLE enables user-guided flows with internal
self-verification, correction, and optimization. We demonstrate the framework
with a generator-critic agent system targeting FPGA resource minimization using
state-of-the-art LLMs. Experimental results on the RTLLM benchmark show that
CRADLE achieves significant reductions in resource usage with averages of 48%
and 40% in LUTs and FFs across all benchmark designs.

</details>


### [340] [DeepFleet: Multi-Agent Foundation Models for Mobile Robots](https://arxiv.org/abs/2508.08574)
*Ameya Agaskar,Sriram Siva,William Pickering,Kyle O'Brien,Charles Kekeh,Ang Li,Brianna Gallo Sarker,Alicia Chua,Mayur Nemade,Charun Thattai,Jiaming Di,Isaac Iyengar,Ramya Dharoor,Dino Kirouani,Jimmy Erskine,Tamir Hegazy,Scott Niekum,Usman A. Khan,Federico Pecora,Joseph W. Durham*

Main category: cs.RO

TL;DR: DeepFleet是用于大规模机器人集群协调和规划的底层模型，其中RC和GF模型最有前途光明。


<details>
  <summary>Details</summary>
Motivation: 介绍DeepFleet，这是一套为大规模移动机器人集群的支持协调和规划而设计的底层模型。

Method: 本文介绍了DeepFleet，这是一套为大规模移动机器人集群的支持协调和规划而设计的底层模型。这些模型在仓库机器人集群的移动数据上进行训练，包括机器人位置、目标和交互。DeepFleet包含四种架构：以机器人为中心的（RC）模型，一个在个体机器人邻域上运行的自回归决策变换器；机器人-楼层（RF）模型，一个在机器人与仓库楼层之间具有交叉注意力的变换器；图像-楼层（IF）模型，将卷积编码应用于整个机器人集群的多通道图像表示；以及图-楼层（GF）模型，将时间注意与用于空间关系的图神经网络相结合。

Result: RC和GF模型更有前途，它们都使用异步机器人状态更新并结合机器人交互的局部结构。这些模型可以有效地利用更大规模的仓库操作数据集。

Conclusion: 机器人为中心和图-楼模型更有前途，它们都使用异步机器人状态更新并结合机器人交互的局部结构。

Abstract: We introduce DeepFleet, a suite of foundation models designed to support
coordination and planning for large-scale mobile robot fleets. These models are
trained on fleet movement data, including robot positions, goals, and
interactions, from hundreds of thousands of robots in Amazon warehouses
worldwide. DeepFleet consists of four architectures that each embody a distinct
inductive bias and collectively explore key points in the design space for
multi-agent foundation models: the robot-centric (RC) model is an
autoregressive decision transformer operating on neighborhoods of individual
robots; the robot-floor (RF) model uses a transformer with cross-attention
between robots and the warehouse floor; the image-floor (IF) model applies
convolutional encoding to a multi-channel image representation of the full
fleet; and the graph-floor (GF) model combines temporal attention with graph
neural networks for spatial relationships. In this paper, we describe these
models and present our evaluation of the impact of these design choices on
prediction task performance. We find that the robot-centric and graph-floor
models, which both use asynchronous robot state updates and incorporate the
localized structure of robot interactions, show the most promise. We also
present experiments that show that these two models can make effective use of
larger warehouses operation datasets as the models are scaled up.

</details>


### [341] [AZRA: Extending the Affective Capabilities of Zoomorphic Robots using Augmented Reality](https://arxiv.org/abs/2508.08507)
*Shaun Macdonald,Salma ElSayed,Mark McGill*

Main category: cs.RO

TL;DR: AZRA是一个AR框架，通过增加情感表达和交互方式，增强了拟人机器人的情感能力，使其更适合家庭使用。


<details>
  <summary>Details</summary>
Motivation: 为了促进用户与拟人机器人之间更具活力和细致的情感互动和关系，但现有拟人机器人的情感互动通常过于简单且短暂，限制了其在家中被使用的潜力。

Method: 提出了一种名为AZRA的新型增强现实（AR）框架，通过计算模型来模拟机器人的情绪反应、日常情绪、不断变化的个性和需求。该框架通过面部表情、灯光、声音、思想气泡等新颖的情感显示，以及语音、触摸、接近度、注视等交互方式来增强拟人机器人（如Petit Qoobo）的情感能力。

Result: 展示了AZRA框架如何增强Petit Qoobo机器人，使其能够展现更丰富的情感表达和更具深度的交互，从而为用户提供更具吸引力和更持久的情感陪伴。

Conclusion: AZRA框架能够扩展 the 拟人机器人的情感能力，而无需进行物理修改，为用户与机器人之间更具活力和细致的情感互动和关系提供了可能。该框架支持快速参与式原型设计，并能增强现有机器人，对未来拟人机器人的发展具有重要意义。

Abstract: Zoomorphic robots could serve as accessible and practical alternatives for
users unable or unwilling to keep pets. However, their affective interactions
are often simplistic and short-lived, limiting their potential for domestic
adoption. In order to facilitate more dynamic and nuanced affective
interactions and relationships between users and zoomorphic robots we present
AZRA, a novel augmented reality (AR) framework that extends the affective
capabilities of these robots without physical modifications. To demonstrate
AZRA, we augment a zoomorphic robot, Petit Qoobo, with novel emotional displays
(face, light, sound, thought bubbles) and interaction modalities (voice, touch,
proximity, gaze). Additionally, AZRA features a computational model of emotion
to calculate the robot's emotional responses, daily moods, evolving personality
and needs. We highlight how AZRA can be used for rapid participatory
prototyping and enhancing existing robots, then discuss implications on future
zoomorphic robot development.

</details>


### [342] [Large Scale Robotic Material Handling: Learning, Planning, and Control](https://arxiv.org/abs/2508.09003)
*Filippo A. Spinelli,Yifan Zhai,Fang Nan,Pascal Egli,Julian Nubert,Thilo Bleumer,Lukas Miller,Ferdinand Hofmann,Marco Hutter*

Main category: cs.RO

TL;DR: 该研究提出了一个用于大规模物料搬运任务的自动化框架，利用强化学习优化抓取和运动控制，并在实际操作中取得了优于人类的表现。


<details>
  <summary>Details</summary>
Motivation: 为了实现诸如货物卸载、废物分类、建筑和拆除等行业中重复性高、劳动密集且有安全风险的大规模物料搬运任务的自动化。

Method: 提出了一种包含环境感知、堆料攻击点选择、路径规划和运动控制的综合框架，并重点介绍了两个基于强化学习的模块：一个用于选择最佳抓取点的攻击点规划器，以及一个用于处理欠驱动抓取器运动的鲁棒轨迹跟踪控制器。

Result: 该系统在精度、可重复性和操作安全性方面均优于人类操作员，并成功实现了大规模物料搬运任务的首次完整自动化。

Conclusion: 该框架通过了在40吨物料搬运机上的真实世界实验验证，证明了其在处理大规模物料搬运任务方面的有效性，提高了精度、可重复性和操作安全性。

Abstract: Bulk material handling involves the efficient and precise moving of large
quantities of materials, a core operation in many industries, including cargo
ship unloading, waste sorting, construction, and demolition. These repetitive,
labor-intensive, and safety-critical operations are typically performed using
large hydraulic material handlers equipped with underactuated grippers. In this
work, we present a comprehensive framework for the autonomous execution of
large-scale material handling tasks. The system integrates specialized modules
for environment perception, pile attack point selection, path planning, and
motion control. The main contributions of this work are two reinforcement
learning-based modules: an attack point planner that selects optimal grasping
locations on the material pile to maximize removal efficiency and minimize the
number of scoops, and a robust trajectory following controller that addresses
the precision and safety challenges associated with underactuated grippers in
movement, while utilizing their free-swinging nature to release material
through dynamic throwing. We validate our framework through real-world
experiments on a 40 t material handler in a representative worksite, focusing
on two key tasks: high-throughput bulk pile management and high-precision truck
loading. Comparative evaluations against human operators demonstrate the
system's effectiveness in terms of precision, repeatability, and operational
safety. To the best of our knowledge, this is the first complete automation of
material handling tasks on a full scale.

</details>


### [343] [Developing a Calibrated Physics-Based Digital Twin for Construction Vehicles](https://arxiv.org/abs/2508.08576)
*Deniz Karanfil,Daniel Lindmark,Martin Servin,David Torick,Bahram Ravani*

Main category: cs.RO

TL;DR: A digital twin of a wheel loader was created and calibrated with sensor data, accurately simulating forces for better construction automation planning.


<details>
  <summary>Details</summary>
Motivation: To develop a calibrated digital twin of a wheel loader for automated diagnostics, operation optimization, and pre-planning simulations, ultimately enhancing automation capabilities in construction.

Method: A digital twin of a wheel loader was developed by integrating a high-fidelity digital model (physics-based multibody dynamic model in AGX Dynamics) with the physical vehicle. The digital model was calibrated using sensor data from the actual wheel loader.

Result: The calibrated digital twin successfully estimated the magnitude of forces on the wheel loader's bucket base with high accuracy, demonstrating the effectiveness of the high-fidelity simulation.

Conclusion: The calibrated digital twin accurately estimates forces on the bucket base, enabling high-fidelity simulations for realistic planning and automation of construction operations.

Abstract: This paper presents the development of a calibrated digital twin of a wheel
loader. A calibrated digital twin integrates a construction vehicle with a
high-fidelity digital model allowing for automated diagnostics and optimization
of operations as well as pre-planning simulations enhancing automation
capabilities. The high-fidelity digital model is a virtual twin of the physical
wheel loader. It uses a physics-based multibody dynamic model of the wheel
loader in the software AGX Dynamics. Interactions of the wheel loader's bucket
while in use in construction can be simulated in the virtual model. Calibration
makes this simulation of high-fidelity which can enhance realistic planning for
automation of construction operations. In this work, a wheel loader was
instrumented with several sensors used to calibrate the digital model. The
calibrated digital twin was able to estimate the magnitude of the forces on the
bucket base with high accuracy, providing a high-fidelity simulation.

</details>


### [344] [Autonomous Mobile Plant Watering Robot : A Kinematic Approach](https://arxiv.org/abs/2508.08607)
*Justin London*

Main category: cs.RO

TL;DR: A new autonomous robot waters plants using advanced vision, a robotic arm, and LIDAR, overcoming limitations of existing technologies.


<details>
  <summary>Details</summary>
Motivation: Existing agricultural robots for watering are expensive and have limited mobility and/or functionality. There is a need for a more capable and autonomous solution.

Method: The robot utilizes a 6-DOF manipulator on a 4WD chassis, Jetson Nano and Arduino microcontrollers, a real-sense camera with YOLOv5 for plant detection, and LIDAR for navigation. It employs a soil moisture sensor for precise watering and can track watered plants without a pre-defined path.

Result: The paper provides the Denavit-Hartenberg (DH) Table, forward kinematics, differential driving kinematics, and inverse kinematics, along with simulation and experiment results demonstrating the robot's capabilities.

Conclusion: The paper introduces a novel autonomous mobile plant watering robot that uses a 6-DOF manipulator, computer vision with YOLOv5 and Pl@ntNet-300K dataset for plant detection, and LIDAR for navigation and collision avoidance. It can autonomously water plants with appropriate amounts of water by inserting a soil moisture sensor. The robot's kinematics and simulation/experiment results are provided.

Abstract: Plants need regular and the appropriate amount of watering to thrive and
survive. While agricultural robots exist that can spray water on plants and
crops such as the , they are expensive and have limited mobility and/or
functionality. We introduce a novel autonomous mobile plant watering robot that
uses a 6 degree of freedom (DOF) manipulator, connected to a 4 wheel drive
alloy chassis, to be able to hold a garden hose, recognize and detect plants,
and to water them with the appropriate amount of water by being able to insert
a soil humidity/moisture sensor into the soil. The robot uses Jetson Nano and
Arduino microcontroller and real sense camera to perform computer vision to
detect plants using real-time YOLOv5 with the Pl@ntNet-300K dataset. The robot
uses LIDAR for object and collision avoideance and does not need to move on a
pre-defined path and can keep track of which plants it has watered. We provide
the Denavit-Hartenberg (DH) Table, forward kinematics, differential driving
kinematics, and inverse kinematics along with simulation and experiment results

</details>


### [345] [Communication Efficient Robotic Mixed Reality with Gaussian Splatting Cross-Layer Optimization](https://arxiv.org/abs/2508.08624)
*Chenxuan Liu,He Li,Zongze Li,Shuai Wang,Wei Xu,Kejiang Ye,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.RO

TL;DR: 该研究提出了一种名为GSMR的框架，通过利用高斯喷溅（GS）模型减少机器人混合现实（RoboMR）系统中的通信成本。为进一步优化，提出了GSCLO框架，通过联合优化内容切换和功率分配来最小化损失函数，并使用APO算法加速求解。实验结果表明，该方法在各种机器人和场景下均优于现有技术，实现了低通信成本和改进的GS性能。


<details>
  <summary>Details</summary>
Motivation: 实现机器人混合现实（RoboMR）系统的低成本通信是一个挑战，因为需要通过无线信道上传高分辨率图像。

Method: 提出了一种名为GSMR（高斯喷溅机器人混合现实）的框架，通过调用GS模型的“内存”来渲染逼真的视图，从而减少了对高分辨率图像上传的需求。在此基础上，提出了一种名为GSCLO（高斯喷溅跨层优化）的框架，通过联合优化内容切换（决定是否上传图像）和功率分配（调整内容配置）来最小化新导出的GSMR损失函数。该GSCLO问题由加速惩罚优化（APO）算法解决，其计算复杂度比传统的分支定界和搜索算法降低了10倍以上。

Result: 实验证明，所提出的GSMR和GSCLO方法在各种场景下，针对轮式和腿式机器人，与现有基准相比，在多种指标上均实现了显著改进。

Conclusion: 该研究首次实现了机器人混合现实（RoboMR）的超低通信成本，并发现数据混合可用于提高动态场景下的高斯喷溅（GS）性能。

Abstract: Realizing low-cost communication in robotic mixed reality (RoboMR) systems
presents a challenge, due to the necessity of uploading high-resolution images
through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR
(GSMR), which enables the simulator to opportunistically render a
photo-realistic view from the robot's pose by calling ``memory'' from a GS
model, thus reducing the need for excessive image uploads. However, the GS
model may involve discrepancies compared to the actual environments. To this
end, a GS cross-layer optimization (GSCLO) framework is further proposed, which
jointly optimizes content switching (i.e., deciding whether to upload image or
not) and power allocation (i.e., adjusting to content profiles) across
different frames by minimizing a newly derived GSMR loss function. The GSCLO
problem is addressed by an accelerated penalty optimization (APO) algorithm
that reduces computational complexity by over $10$x compared to traditional
branch-and-bound and search algorithms. Moreover, variants of GSCLO are
presented to achieve robust, low-power, and multi-robot GSMR. Extensive
experiments demonstrate that the proposed GSMR paradigm and GSCLO method
achieve significant improvements over existing benchmarks on both wheeled and
legged robots in terms of diverse metrics in various scenarios. For the first
time, it is found that RoboMR can be achieved with ultra-low communication
costs, and mixture of data is useful for enhancing GS performance in dynamic
scenarios.

</details>


### [346] [ZS-Puffin: Design, Modeling and Implementation of an Unmanned Aerial-Aquatic Vehicle with Amphibious Wings](https://arxiv.org/abs/2508.08690)
*Zhenjiang Wang,Yunhua Jiang,Zikun Zhen,Yifan Jiang,Yubin Tan,Wubin Wang*

Main category: cs.RO

TL;DR: 受海雀启发，设计了一种两栖机翼无人飞行器-水下航行器（UAAV），它能在空中和水下运行，并使用CPG优化了拍动运动，环境友好。


<details>
  <summary>Details</summary>
Motivation: 为了应对介质差异对飞行器推进系统带来的挑战，并减少对海洋生物的干扰，实现环境友好。

Method: 设计了一种基于固定翼结构的两栖机翼，该机翼具有单一的俯仰自由度，无需额外部件，能在空中产生升力，在水下充当拍动翼进行推进。引入了人工中心模式发生器（CPG）来优化拍动运动的平稳性。

Result: 展示了该概念的原型、设计细节和实际应用。

Conclusion: 提出了一种具有两栖机翼的无人飞行器-水下航行器（UAAV），该机翼能够同时在空中和水下运行，并受到海雀双功能机翼的启发。

Abstract: Unmanned aerial-aquatic vehicles (UAAVs) can operate both in the air and
underwater, giving them broad application prospects. Inspired by the
dual-function wings of puffins, we propose a UAAV with amphibious wings to
address the challenge posed by medium differences on the vehicle's propulsion
system. The amphibious wing, redesigned based on a fixed-wing structure,
features a single degree of freedom in pitch and requires no additional
components. It can generate lift in the air and function as a flapping wing for
propulsion underwater, reducing disturbance to marine life and making it
environmentally friendly. Additionally, an artificial central pattern generator
(CPG) is introduced to enhance the smoothness of the flapping motion. This
paper presents the prototype, design details, and practical implementation of
this concept.

</details>


### [347] [OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing](https://arxiv.org/abs/2508.08706)
*Zhengxue Cheng,Yiqian Zhang,Wenkang Zhang,Haoyu Li,Keyu Wang,Li Song,Hengdi Zhang*

Main category: cs.RO

TL;DR: 本文提出了OmniVTLA，一个集成了触觉感知的机器人操作模型。通过双路径触觉编码器和ObjTac数据集，OmniVTLA在拾取-放置任务中显著提高了成功率和效率，并生成了更优的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型在机器人操控方面展现了潜力，但由于触觉传感器异质性和数据获取困难，它们忽略了触觉感知的重要性，在接触丰富的任务中表现不佳。为了解决这个问题，本文提出了OmniVTLA。

Method: 本文提出了OmniVTLA新架构，其特点是采用了双路径触觉编码器框架，利用预训练的ViT和SA-ViT来增强对多种触觉传感器的感知能力。此外，引入了ObjTac数据集，该数据集包含56个物体、10个类别的三模态（文本、视觉、触觉）样本，用于训练语义对齐的触觉编码器。

Result: 在拾取-放置任务中，OmniVTLA的成功率分别比基线模型高出21.9%（使用夹爪时达到96.9%）和6.2%（使用灵巧手时达到100%）。此外，与现有的VLA模型相比，OmniVTLA显著缩短了任务完成时间，并通过触觉感知生成了更平滑的轨迹。

Conclusion: OmniVTLA通过整合触觉感知，在机器人操作任务中取得了显著的性能提升，成功率和效率均优于现有基线模型。

Abstract: Recent vision-language-action (VLA) models build upon vision-language
foundations, and have achieved promising results and exhibit the possibility of
task generalization in robot manipulation. However, due to the heterogeneity of
tactile sensors and the difficulty of acquiring tactile data, current VLA
models significantly overlook the importance of tactile perception and fail in
contact-rich tasks. To address this issue, this paper proposes OmniVTLA, a
novel architecture involving tactile sensing. Specifically, our contributions
are threefold. First, our OmniVTLA features a dual-path tactile encoder
framework. This framework enhances tactile perception across diverse
vision-based and force-based tactile sensors by using a pretrained vision
transformer (ViT) and a semantically-aligned tactile ViT (SA-ViT). Second, we
introduce ObjTac, a comprehensive force-based tactile dataset capturing
textual, visual, and tactile information for 56 objects across 10 categories.
With 135K tri-modal samples, ObjTac supplements existing visuo-tactile
datasets. Third, leveraging this dataset, we train a semantically-aligned
tactile encoder to learn a unified tactile representation, serving as a better
initialization for OmniVTLA. Real-world experiments demonstrate substantial
improvements over state-of-the-art VLA baselines, achieving 96.9% success rates
with grippers, (21.9% higher over baseline) and 100% success rates with
dexterous hands (6.2% higher over baseline) in pick-and-place tasks. Besides,
OmniVTLA significantly reduces task completion time and generates smoother
trajectories through tactile sensing compared to existing VLA.

</details>


### [348] [Towards Safe Imitation Learning via Potential Field-Guided Flow Matching](https://arxiv.org/abs/2508.08707)
*Haoran Ding,Anqing Duan,Zezhou Sun,Leonel Rozo,Noémie Jaquier,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: PF2MP是一种新的方法，它通过结合势场来提高模仿学习中运动生成的安全性，特别是在有障碍物的环境中。


<details>
  <summary>Details</summary>
Motivation: 当前深度生成模型（特别是扩散和流匹配模型）在通过模仿学习学习复杂策略方面显示出巨大潜力，但生成的运动的安全性，特别是在具有固有障碍物的复杂环境中，仍然被忽视。

Method: 提出了一种名为PF2MP的新方法，该方法同时从成功的演示中学习任务策略并提取与障碍物相关的信息（表示为势场）。

Result: PF2MP在模拟和现实世界环境中都得到了评估，证明了其在任务空间和关节空间控制方面的有效性。实验结果表明，与基线策略相比，PF2MP提高了安全性，显著减少了碰撞。

Conclusion: PF2MP通过在推理时利用学习到的势场来调节流匹配向量场，实现了在不影响任务成功率的情况下提高了运动安全性，尤其是在非结构化和障碍物丰富的环境中。

Abstract: Deep generative models, particularly diffusion and flow matching models, have
recently shown remarkable potential in learning complex policies through
imitation learning. However, the safety of generated motions remains
overlooked, particularly in complex environments with inherent obstacles. In
this work, we address this critical gap by proposing Potential Field-Guided
Flow Matching Policy (PF2MP), a novel approach that simultaneously learns task
policies and extracts obstacle-related information, represented as a potential
field, from the same set of successful demonstrations. During inference, PF2MP
modulates the flow matching vector field via the learned potential field,
enabling safe motion generation. By leveraging these complementary fields, our
approach achieves improved safety without compromising task success across
diverse environments, such as navigation tasks and robotic manipulation
scenarios. We evaluate PF2MP in both simulation and real-world settings,
demonstrating its effectiveness in task space and joint space control.
Experimental results demonstrate that PF2MP enhances safety, achieving a
significant reduction of collisions compared to baseline policies. This work
paves the way for safer motion generation in unstructured and obstaclerich
environments.

</details>


### [349] [Boosting Action-Information via a Variational Bottleneck on Unlabelled Robot Videos](https://arxiv.org/abs/2508.08743)
*Haoyu Zhang,Long Cheng*

Main category: cs.RO

TL;DR: 该研究提出一种新框架，通过最大化潜在动作与真实动作间的互信息，解决了从无标签视频演示学习中的控制性能问题，并在实验中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从无标签视频演示中学习时，倾向于编码与真实机器人动作互信息较少的潜在动作，导致控制性能不佳。

Method: 利用变分信息瓶颈（variational information bottleneck）来提取与动作相关的表示，同时去除与任务无关的信息，并显式地最大化潜在动作和真实动作之间的互信息。

Result: 实验结果表明，该方法显著增强了互信息，并持续提高了策略性能，在模拟和真实机器人环境中均得到了验证。

Conclusion: 该方法通过最大化潜在动作和真实动作之间的互信息，显著提高了策略性能。

Abstract: Learning from demonstrations (LfD) typically relies on large amounts of
action-labeled expert trajectories, which fundamentally constrains the scale of
available training data. A promising alternative is to learn directly from
unlabeled video demonstrations. However, we find that existing methods tend to
encode latent actions that share little mutual information with the true robot
actions, leading to suboptimal control performance. To address this limitation,
we introduce a novel framework that explicitly maximizes the mutual information
between latent actions and true actions, even in the absence of action labels.
Our method leverage the variational information-bottleneck to extract
action-relevant representations while discarding task-irrelevant information.
We provide a theoretical analysis showing that our objective indeed maximizes
the mutual information between latent and true actions. Finally, we validate
our approach through extensive experiments: first in simulated robotic
environments and then on real-world robotic platforms, the experimental results
demonstrate that our method significantly enhances mutual information and
consistently improves policy performance.

</details>


### [350] [Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT](https://arxiv.org/abs/2508.08748)
*Muhammad A. Muttaqien,Tomohiro Motoda,Ryo Hanai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的机器人拾放方法，利用视觉提示和模仿学习，提高了在复杂零售环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 便利店的机器人拾放任务由于物体密集、遮挡以及物体属性（如颜色、形状、大小、纹理）的变化而面临挑战，这使得轨迹规划和抓取变得复杂。

Method: 本研究提出了一种利用注释引导的视觉提示的感知-行动管道，并使用ACT（Action Chunking with Transformers）作为模仿学习算法来预测机器人动作序列。

Result: 在抓取准确性和适应性方面取得了改进。

Conclusion: 该系统在零售环境中提高了抓取准确性和适应性。

Abstract: Robotic pick-and-place tasks in convenience stores pose challenges due to
dense object arrangements, occlusions, and variations in object properties such
as color, shape, size, and texture. These factors complicate trajectory
planning and grasping. This paper introduces a perception-action pipeline
leveraging annotation-guided visual prompting, where bounding box annotations
identify both pickable objects and placement locations, providing structured
spatial guidance. Instead of traditional step-by-step planning, we employ
Action Chunking with Transformers (ACT) as an imitation learning algorithm,
enabling the robotic arm to predict chunked action sequences from human
demonstrations. This facilitates smooth, adaptive, and data-driven
pick-and-place operations. We evaluate our system based on success rate and
visual analysis of grasping behavior, demonstrating improved grasp accuracy and
adaptability in retail environments.

</details>


### [351] [Robot can reduce superior's dominance in group discussions with human social hierarchy](https://arxiv.org/abs/2508.08767)
*Kazuki Komura,Kumi Ozaki,Seiji Yamada*

Main category: cs.RO

TL;DR: 机器人可能有助于平衡讨论中的发言时间，但效果尚不显著。未来可探索机器人行为的精细调控以实现此目标。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索具有社会层级关系的机器人代理是否能够减少上级的主导地位，并促进讨论中各参与者发言的公平性。

Method: 本研究招募了30名具有上下级关系的医生和学生作为参与者，并设计了机器人干预实验。实验设置了三种条件：1）机器人根据社会层级鼓励发言（干预组）；2）机器人平均干预所有参与者（对照组）；3）无机器人干预（无行动组）。机器人通过“跟随”行为（如回应语音）和“鼓励”行为（如提示发言时间少的成员发言）来促进参与的公平性。

Result: 实验结果显示，机器人行为可能对参与者的发言时间产生影响，但不同机器人行为条件之间未发现显著差异。然而，研究结果提示，有可能在不降低上级满意度的情况下影响发言时间。

Conclusion: 虽然机器人行为可能影响发言时间，但未能明确证明其有效性。然而，研究表明，通过控制机器人的参与行为，有可能在不降低高层满意度的情况下，抑制优势者的主导地位，促进参与的公平性。

Abstract: This study investigated whether robotic agents that deal with social
hierarchical relationships can reduce the dominance of superiors and equalize
participation among participants in discussions with hierarchical structures.
Thirty doctors and students having hierarchical relationship were gathered as
participants, and an intervention experiment was conducted using a robot that
can encourage participants to speak depending on social hierarchy. These were
compared with strategies that intervened equally for all participants without
considering hierarchy and with a no-action. The robots performed follow
actions, showing backchanneling to speech, and encourage actions, prompting
speech from members with less speaking time, on the basis of the hierarchical
relationships among group members to equalize participation. The experimental
results revealed that the robot's actions could potentially influence the
speaking time among members, but it could not be conclusively stated that there
were significant differences between the robot's action conditions. However,
the results suggested that it might be possible to influence speaking time
without decreasing the satisfaction of superiors. This indicates that in
discussion scenarios where experienced superiors are likely to dominate,
controlling the robot's backchanneling behavior could potentially suppress
dominance and equalize participation among group members.

</details>


### [352] [Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors](https://arxiv.org/abs/2508.08896)
*Haoyu Zhao,Linghao Zhuang,Xingyue Zhao,Cheng Zeng,Haoran Xu,Yuming Jiang,Jun Cen,Kexiang Wang,Jiayan Guo,Siteng Huang,Xin Li,Deli Zhao,Hua Zou*

Main category: cs.RO

TL;DR: AffordDex是一个新颖的框架，通过两阶段训练，学习了一个通用的抓取策略，该策略具有对运动先验和物体可供性的内在理解。它通过模仿人类运动来学习自然运动，并通过识别不合适的接触区域和使用师生蒸馏来优化特定物体实例的抓取。


<details>
  <summary>Details</summary>
Motivation: 先前的方法过于关注低级抓握稳定性指标，忽略了对下游操作至关重要的、可供性感知的定位和类似人类的姿势。

Method: 该框架采用两阶段训练：第一阶段，轨迹模仿器在大量人类手部运动语料库上进行预训练，以灌输自然的运动先验；第二阶段，残差模块通过我们的负可供性感知分割（NAA）模块（识别功能上不合适接触区域）和特权师生蒸馏过程（确保最终的基于视觉的策略高度成功）来指导，以适应特定物体实例。

Result: 实验证明，AffordDex 不仅实现了通用的灵巧抓取，而且在姿势上非常像人类，在接触位置上也功能合适。

Conclusion: AffordDex 在已见、未见甚至全新类别的物体上均显著优于最先进的基线，实现了通用的灵巧抓取，并且在姿势上非常像人类，在接触位置上功能合适。

Abstract: A dexterous hand capable of generalizable grasping objects is fundamental for
the development of general-purpose embodied AI. However, previous methods focus
narrowly on low-level grasp stability metrics, neglecting affordance-aware
positioning and human-like poses which are crucial for downstream manipulation.
To address these limitations, we propose AffordDex, a novel framework with
two-stage training that learns a universal grasping policy with an inherent
understanding of both motion priors and object affordances. In the first stage,
a trajectory imitator is pre-trained on a large corpus of human hand motions to
instill a strong prior for natural movement. In the second stage, a residual
module is trained to adapt these general human-like motions to specific object
instances. This refinement is critically guided by two components: our Negative
Affordance-aware Segmentation (NAA) module, which identifies functionally
inappropriate contact regions, and a privileged teacher-student distillation
process that ensures the final vision-based policy is highly successful.
Extensive experiments demonstrate that AffordDex not only achieves universal
dexterous grasping but also remains remarkably human-like in posture and
functionally appropriate in contact location. As a result, AffordDex
significantly outperforms state-of-the-art baselines across seen objects,
unseen instances, and even entirely novel categories.

</details>


### [353] [Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion](https://arxiv.org/abs/2508.08982)
*Seungeun Rho,Kartik Garg,Morgan Byrd,Sehoon Ha*

Main category: cs.RO

TL;DR: SDAX是一个新框架，通过无监督技能发现和自适应探索，使四足机器人在无需大量人工干预的情况下，学会了爬行、攀爬、跳跃和越过墙壁等敏捷运动技能，并在真实硬件上得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为使 the legged 机器人能够学习克服各种障碍物的敏捷运动行为，需要进行探索。然而，这种探索具有挑战性，并且通常需要大量的奖励工程、专家演示或课程学习，所有这些都会限制泛化能力。

Method: 提出了一种名为SDAX的新型学习框架，该框架利用无监督技能发现来自主获取克服障碍物的多样化技能，并通过双层优化过程动态调节训练过程中的探索水平。

Result: SDAX使四足机器能够获得高度敏捷的行为，包括爬行、攀爬、跳跃以及执行从垂直墙壁跳下等复杂动作。

Conclusion: SDAX框架成功使四足机器人在现实世界中获得了敏捷的运动能力，包括爬行、攀爬、跳跃和越过垂直墙壁等复杂动作。

Abstract: Exploration is crucial for enabling legged robots to learn agile locomotion
behaviors that can overcome diverse obstacles. However, such exploration is
inherently challenging, and we often rely on extensive reward engineering,
expert demonstrations, or curriculum learning - all of which limit
generalizability. In this work, we propose Skill Discovery as Exploration
(SDAX), a novel learning framework that significantly reduces human engineering
effort. SDAX leverages unsupervised skill discovery to autonomously acquire a
diverse repertoire of skills for overcoming obstacles. To dynamically regulate
the level of exploration during training, SDAX employs a bi-level optimization
process that autonomously adjusts the degree of exploration. We demonstrate
that SDAX enables quadrupedal robots to acquire highly agile behaviors
including crawling, climbing, leaping, and executing complex maneuvers such as
jumping off vertical walls. Finally, we deploy the learned policy on real
hardware, validating its successful transfer to the real world.

</details>


### [354] [Rational Inverse Reasoning](https://arxiv.org/abs/2508.08983)
*Ben Zandonati,Tomás Lozano-Pérez,Leslie Pack Kaelbling*

Main category: cs.RO

TL;DR: RIR框架通过贝叶斯程序归纳，让机器人像人一样，仅从一次演示就能学会并泛化复杂任务。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人模仿学习方法需要大量数据并且泛化能力差，无法像人类一样从单次不完美的演示中学习。这是因为机器人无法恢复智能行为潜在的结构化程序（包括高层目标、子任务分解和执行约束），而这正是人类能够快速泛化的关键。

Method: RIR框架利用分层生成模型来推断行为背后的潜在程序。该方法将少样本模仿学习视为贝叶斯程序归纳：一个视觉-语言模型迭代地提出结构化符号任务假设，同时一个带规划器的推理方案根据观察到的演示在该假设下的可能性对每个假设进行评分。这个循环产生一个简洁、可执行的程序后验。

Result: RIR框架在专门用于测试单样本和少样本泛化的连续操控任务上进行了评估。结果表明，仅用一次演示，RIR就能推断出目标任务结构，并泛化到新颖的设置，表现优于最先进的视觉-语言模型基线。

Conclusion: RIR框架通过贝叶斯程序归纳，实现了少样本模仿学习，能够从少量演示中推断出潜在的程序结构，并在连续操控任务中展现出优于现有视觉-语言模型基线的效果，尤其在物体姿态、数量、几何形状和布局等方面的泛化能力。

Abstract: Humans can observe a single, imperfect demonstration and immediately
generalize to very different problem settings. Robots, in contrast, often
require hundreds of examples and still struggle to generalize beyond the
training conditions. We argue that this limitation arises from the inability to
recover the latent explanations that underpin intelligent behavior, and that
these explanations can take the form of structured programs consisting of
high-level goals, sub-task decomposition, and execution constraints. In this
work, we introduce Rational Inverse Reasoning (RIR), a framework for inferring
these latent programs through a hierarchical generative model of behavior. RIR
frames few-shot imitation as Bayesian program induction: a vision-language
model iteratively proposes structured symbolic task hypotheses, while a
planner-in-the-loop inference scheme scores each by the likelihood of the
observed demonstration under that hypothesis. This loop yields a posterior over
concise, executable programs. We evaluate RIR on a suite of continuous
manipulation tasks designed to test one-shot and few-shot generalization across
variations in object pose, count, geometry, and layout. With as little as one
demonstration, RIR infers the intended task structure and generalizes to novel
settings, outperforming state-of-the-art vision-language model baselines.

</details>


### [355] [Generation of Real-time Robotic Emotional Expressions Learning from Human Demonstration in Mixed Reality](https://arxiv.org/abs/2508.08999)
*Chao Wang,Michael Gienger,Fan Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一种在混合现实中利用专家演示，通过流匹配技术为机器人生成逼真、多样且自主的情感表达的框架。


<details>
  <summary>Details</summary>
Motivation: 在机器人与人类交互中，表达性行为对于有效传达其情绪状态至关重要。

Method: 利用基于流匹配的生成过程，从混合现实中的专家人类演示中学习。

Result: 该系统能够将专家的面部表情、头部运动和上半身手势映射到相应的机器人组件（包括眼睛、耳朵、脖子和手臂），并生成连贯多样的行为。

Conclusion: 该框架能够根据给定的情绪状态，实时生成自主的、逼真的、多样的机器人情感表达。

Abstract: Expressive behaviors in robots are critical for effectively conveying their
emotional states during interactions with humans. In this work, we present a
framework that autonomously generates realistic and diverse robotic emotional
expressions based on expert human demonstrations captured in Mixed Reality
(MR). Our system enables experts to teleoperate a virtual robot from a
first-person perspective, capturing their facial expressions, head movements,
and upper-body gestures, and mapping these behaviors onto corresponding robotic
components including eyes, ears, neck, and arms. Leveraging a
flow-matching-based generative process, our model learns to produce coherent
and varied behaviors in real-time in response to moving objects, conditioned
explicitly on given emotional states. A preliminary test validated the
effectiveness of our approach for generating autonomous expressions.

</details>


### [356] [GeoVLA: Empowering 3D Representations in Vision-Language-Action Models](https://arxiv.org/abs/2508.09071)
*Lin Sun,Bin Xie,Yingfei Liu,Hao Shi,Tiancai Wang,Jiale Cao*

Main category: cs.RO

TL;DR: GeoVLA是一个创新的视觉-语言-动作（VLA）框架，通过整合3D几何信息显著提高了机器人在现实世界中的操控能力和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖2D视觉输入，忽视了3D物理世界的几何信息，限制了机器人的空间感知和适应性。GeoVLA旨在通过整合3D信息来改进机器人操控能力。

Method: GeoVLA框架整合了2D图像和语言指令，并通过定制的点编码器Point Embedding Network处理深度图转换成的点云，生成3D几何嵌入。这些嵌入与视觉-语言嵌入拼接后，通过3D增强的动作专家进行处理，生成精确的动作序列。

Result: GeoVLA在模拟和现实世界环境中表现出优越的性能和鲁棒性。

Conclusion: GeoVLA在需要高度适应性、尺度感知和视点不变性的现实世界任务中表现出卓越的鲁棒性，并在LIBERO和ManiSkill2模拟基准上取得了最先进的成果。

Abstract: Vision-Language-Action (VLA) models have emerged as a promising approach for
enabling robots to follow language instructions and predict corresponding
actions.However, current VLA models mainly rely on 2D visual inputs, neglecting
the rich geometric information in the 3D physical world, which limits their
spatial awareness and adaptability. In this paper, we present GeoVLA, a novel
VLA framework that effectively integrates 3D information to advance robotic
manipulation. It uses a vision-language model (VLM) to process images and
language instructions,extracting fused vision-language embeddings. In parallel,
it converts depth maps into point clouds and employs a customized point
encoder, called Point Embedding Network, to generate 3D geometric embeddings
independently. These produced embeddings are then concatenated and processed by
our proposed spatial-aware action expert, called 3D-enhanced Action Expert,
which combines information from different sensor modalities to produce precise
action sequences. Through extensive experiments in both simulation and
real-world environments, GeoVLA demonstrates superior performance and
robustness. It achieves state-of-the-art results in the LIBERO and ManiSkill2
simulation benchmarks and shows remarkable robustness in real-world tasks
requiring height adaptability, scale awareness and viewpoint invariance.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [357] [Playing Atari Space Invaders with Sparse Cosine Optimized Policy Evolution](https://arxiv.org/abs/2508.08526)
*Jim O'Connor,Jay B. Nash,Derin Gezgin,Gary B. Parker*

Main category: cs.NE

TL;DR: SCOPE是一种通过离散余弦变换（DCT）和稀疏化来减小游戏状态输入空间的进化策略，在《太空侵略者》游戏中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 进化方法在游戏领域面临挑战，因为视频游戏具有巨大的状态空间，导致策略需要更大的参数量，从而不成比例地增加了搜索空间的大小，降低了收敛速度。

Method: SCOPE利用离散余弦变换（DCT）作为伪注意力机制，将输入状态转换为系数矩阵，然后通过截断和稀疏化该矩阵来减少输入维度，同时保留原始输入中的高能量特征。

Result: 在Atari游戏《太空侵略者》任务中，使用SCOPE的CMA-ES算法的性能优于其他进化方法（OpenAI-ES, HyperNEAT）和强化学习方法（DQN, A3C）。

Conclusion: SCOPE通过将输入大小减少53%（从33,600减少到15,625），并使用稀疏DCT系数的双线性仿射映射来学习策略动作，在Atari游戏《太空侵略者》任务中，与包括OpenAI-ES和HyperNEAT在内的未修改输入状态的进化方法以及DQN和A3C等简单强化学习方法相比，表现更优。

Abstract: Evolutionary approaches have previously been shown to be effective learning
methods for a diverse set of domains. However, the domain of game-playing poses
a particular challenge for evolutionary methods due to the inherently large
state space of video games. As the size of the input state expands, the size of
the policy must also increase in order to effectively learn the temporal
patterns in the game space. Consequently, a larger policy must contain more
trainable parameters, exponentially increasing the size of the search space.
Any increase in search space is highly problematic for evolutionary methods, as
increasing the number of trainable parameters is inversely correlated with
convergence speed. To reduce the size of the input space while maintaining a
meaningful representation of the original space, we introduce Sparse Cosine
Optimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine
Transform (DCT) as a pseudo attention mechanism, transforming an input state
into a coefficient matrix. By truncating and applying sparsification to this
matrix, we reduce the dimensionality of the input space while retaining the
highest energy features of the original input. We demonstrate the effectiveness
of SCOPE as the policy for the Atari game Space Invaders. In this task, SCOPE
with CMA-ES outperforms evolutionary methods that consider an unmodified input
state, such as OpenAI-ES and HyperNEAT. SCOPE also outperforms simple
reinforcement learning methods, such as DQN and A3C. SCOPE achieves this result
through reducing the input size by 53% from 33,600 to 15,625 then using a
bilinear affine mapping of sparse DCT coefficients to policy actions learned by
the CMA-ES algorithm.

</details>
