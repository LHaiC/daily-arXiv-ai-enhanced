<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 74]
- [cs.CL](#cs.CL) [Total: 51]
- [eess.SP](#eess.SP) [Total: 10]
- [cs.DC](#cs.DC) [Total: 10]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.AI](#cs.AI) [Total: 50]
- [cs.GT](#cs.GT) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.AR](#cs.AR) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 21]
- [cs.LG](#cs.LG) [Total: 82]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 24]
- [cs.RO](#cs.RO) [Total: 29]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.DS](#cs.DS) [Total: 7]
- [eess.IV](#eess.IV) [Total: 6]
- [cs.NE](#cs.NE) [Total: 1]
- [quant-ph](#quant-ph) [Total: 38]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Training-Free Underwater 3D Object Detection from Sonar Point Clouds: A Comparison of Traditional and Deep Learning Approaches](https://arxiv.org/abs/2508.18293)
*M. Salman Shaukat,Yannik Käckenmeister,Sebastian Bader,Thomas Kirste*

Main category: cs.CV

TL;DR: 该研究提出了一种无需真实世界训练数据即可进行水下3D目标检测的方法，通过结合基于物理的声纳模拟和基于模型的模板匹配，并在真实波罗的海测深数据上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 水下3D目标检测因声学环境恶劣和训练数据稀缺而充满挑战，而深度学习在缺乏足够标注声纳数据的情况下难以应用。

Method: 提出并比较了两种无需训练的检测范式：1) 使用基于物理的声纳模拟生成合成数据训练的神经网络；2) 利用目标几何先验的基于模型的模板匹配系统。

Result: 在真实声纳数据上，仅使用合成数据训练的神经网络平均精度（mAP）为40%，而无需训练的模板匹配方法mAP为83%，显示出对声学噪声和环境变化的鲁棒性。

Conclusion: 研究结果表明，在水下等数据稀疏的环境中，无需训练的模板匹配方法比依赖合成数据的神经网络更有效，挑战了深度学习对数据量的依赖，并为无需训练的水下3D检测建立了基准。

Abstract: Underwater 3D object detection remains one of the most challenging frontiers
in computer vision, where traditional approaches struggle with the harsh
acoustic environment and scarcity of training data. While deep learning has
revolutionized terrestrial 3D detection, its application underwater faces a
critical bottleneck: obtaining sufficient annotated sonar data is prohibitively
expensive and logistically complex, often requiring specialized vessels, expert
surveyors, and favorable weather conditions. This work addresses a fundamental
question: Can we achieve reliable underwater 3D object detection without
real-world training data? We tackle this challenge by developing and comparing
two paradigms for training-free detection of artificial structures in multibeam
echo-sounder point clouds. Our dual approach combines a physics-based sonar
simulation pipeline that generates synthetic training data for state-of-the-art
neural networks, with a robust model-based template matching system that
leverages geometric priors of target objects. Evaluation on real bathymetry
surveys from the Baltic Sea reveals surprising insights: while neural networks
trained on synthetic data achieve 98% mean Average Precision (mAP) on simulated
scenes, they drop to 40% mAP on real sonar data due to domain shift.
Conversely, our template matching approach maintains 83% mAP on real data
without requiring any training, demonstrating remarkable robustness to acoustic
noise and environmental variations. Our findings challenge conventional wisdom
about data-hungry deep learning in underwater domains and establish the first
large-scale benchmark for training-free underwater 3D detection. This work
opens new possibilities for autonomous underwater vehicle navigation, marine
archaeology, and offshore infrastructure monitoring in data-scarce environments
where traditional machine learning approaches fail.

</details>


### [2] [MobileDenseAttn:A Dual-Stream Architecture for Accurate and Interpretable Brain Tumor Detection](https://arxiv.org/abs/2508.18294)
*Shudipta Banik,Muna Das,Trapa Banik,Md. Ehsanul Haque*

Main category: cs.CV

TL;DR: MobileDenseAttn是一种结合了MobileNetV2和DenseNet201的模型，用于MRI脑肿瘤检测，具有高准确率（98.35%）、高F1分数（0.9835）和可解释性。


<details>
  <summary>Details</summary>
Motivation: 手动分析脑肿瘤MRI耗时且易出错，现有方法泛化性差、计算效率低、不可解释且缺乏透明度，限制了其可信度。

Method: 提出了一种名为MobileDenseAttn的融合模型，结合了MobileNetV2和DenseNet201的两个流，通过特征级别融合逐步改进特征表示尺度、计算效率，并利用GradCAM提供视觉解释。

Result: 在包含6020个MRI扫描的增强数据集上训练，MobileDenseAttn在5折交叉验证下达到了99.75%的训练准确率和98.35%的测试准确率，F1分数为0.9835。与基线模型（VGG19、DenseNet201、MobileNetV2）相比，准确率提高了+3.67%，训练时间减少了39.3%。GradCAM热图清晰显示了肿瘤区域，提高了可解释性。

Conclusion: MobileDenseAttn是一个高效、高性能、可解释的模型，在脑肿瘤检测方面取得了显著进展，有潜力成为临床实用工具。

Abstract: The detection of brain tumor in MRI is an important aspect of ensuring timely
diagnostics and treatment; however, manual analysis is commonly long and
error-prone. Current approaches are not universal because they have limited
generalization to heterogeneous tumors, are computationally inefficient, are
not interpretable, and lack transparency, thus limiting trustworthiness. To
overcome these issues, we introduce MobileDenseAttn, a fusion model of dual
streams of MobileNetV2 and DenseNet201 that can help gradually improve the
feature representation scale, computing efficiency, and visual explanations via
GradCAM. Our model uses feature level fusion and is trained on an augmented
dataset of 6,020 MRI scans representing glioma, meningioma, pituitary tumors,
and normal samples. Measured under strict 5-fold cross-validation protocols,
MobileDenseAttn provides a training accuracy of 99.75%, a testing accuracy of
98.35%, and a stable F1 score of 0.9835 (95% CI: 0.9743 to 0.9920). The
extensive validation shows the stability of the model, and the comparative
analysis proves that it is a great advancement over the baseline models (VGG19,
DenseNet201, MobileNetV2) with a +3.67% accuracy increase and a 39.3% decrease
in training time compared to VGG19. The GradCAM heatmaps clearly show
tumor-affected areas, offering clinically significant localization and
improving interpretability. These findings position MobileDenseAttn as an
efficient, high performance, interpretable model with a high probability of
becoming a clinically practical tool in identifying brain tumors in the real
world.

</details>


### [3] [Can VLMs Recall Factual Associations From Visual References?](https://arxiv.org/abs/2508.18297)
*Dhananjay Ashok,Ashutosh Chaubey,Hirona J. Arai,Jonathan May,Jesse Thomason*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Through a controlled study, we identify a systematic deficiency in the
multimodal grounding of Vision Language Models (VLMs). While VLMs can recall
factual associations when provided a textual reference to an entity; their
ability to do so is significantly diminished when the reference is visual
instead. Forcing VLMs to rely on image representations of an entity halves
their ability to recall factual knowledge, suggesting that VLMs struggle to
link their internal knowledge of an entity with its image representation. We
show that such linking failures are correlated with the expression of distinct
patterns in model internal states, and that probes on these internal states
achieve over 92% accuracy at flagging cases where the VLM response is
unreliable. These probes can be applied, without retraining, to identify when a
VLM will fail to correctly answer a question that requires an understanding of
multimodal input. When used to facilitate selective prediction on a visual
question answering task, the probes increase coverage by 7.87% (absolute) while
also reducing the risk of error by 0.9% (absolute). Addressing the systematic,
detectable deficiency is an important avenue in language grounding, and we
provide informed recommendations for future directions.

</details>


### [4] [SERES: Semantic-aware neural reconstruction from sparse views](https://arxiv.org/abs/2508.18314)
*Bo Xu,Yuhu Guo,Yuchao Wang,Wenting Wang,Yeung Yam,Charlie C. L. Wang,Xinyi Le*

Main category: cs.CV

TL;DR: 提出了一种语义感知神经重建方法，用于从稀疏图像生成高保真3D模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决稀疏输入中不匹配特征引起的严重辐射模糊问题，通过添加基于块的语义逻辑来丰富神经隐式表示，并与符号距离场和辐射场一起优化。

Method: 将基于块的语义逻辑添加到神经隐式表示中，并引入基于几何图元的掩码的正则化来缓解形状模糊。

Result: 在DTU数据集上，与SparseNeuS和VolRecon相比，重建的平均倒角距离分别降低了44%和20%。当作为NeuS和Neuralangelo等密集重建基线的插件时，在DTU数据集上的平均误差分别降低了69%和68%。

Conclusion: 所提出的方法通过语义信息和几何约束有效提高了从稀疏图像进行3D重建的质量和准确性。

Abstract: We propose a semantic-aware neural reconstruction method to generate 3D
high-fidelity models from sparse images. To tackle the challenge of severe
radiance ambiguity caused by mismatched features in sparse input, we enrich
neural implicit representations by adding patch-based semantic logits that are
optimized together with the signed distance field and the radiance field. A
novel regularization based on the geometric primitive masks is introduced to
mitigate shape ambiguity. The performance of our approach has been verified in
experimental evaluation. The average chamfer distances of our reconstruction on
the DTU dataset can be reduced by 44% for SparseNeuS and 20% for VolRecon. When
working as a plugin for those dense reconstruction baselines such as NeuS and
Neuralangelo, the average error on the DTU dataset can be reduced by 69% and
68% respectively.

</details>


### [5] [LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding](https://arxiv.org/abs/2508.19204)
*Julian Ost,Andrea Ramazzina,Amogh Joshi,Maximilian Bömer,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 该研究提出了一种生成大规模3D驾驶场景的方法，结合了代理几何表示和2D图像先验的得分蒸馏，实现了精确的几何、可控性和因果新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有神经重建方法在静态环境和场景控制方面存在局限，而2D/3D扩散模型虽然提供了控制，但缺乏几何基础和因果关系。本研究旨在弥合这一差距。

Method: 提出了一种结合代理几何和环境表示以及学习到的2D图像先验的得分蒸馏的方法。

Result: 该方法能够生成大规模3D驾驶场景，具有精确的几何、物体持久性和显式的3D几何估计，实现了高可控性，可根据地图布局生成逼真且几何一致的复杂驾驶场景。

Conclusion: 该方法成功地将2D图像生成模型的控制能力与3D场景表示的几何基础相结合，为机器人学习提供了生成大规模、可控且物理上合理的数据集的途径。

Abstract: Large-scale scene data is essential for training and testing in robot
learning. Neural reconstruction methods have promised the capability of
reconstructing large physically-grounded outdoor scenes from captured sensor
data. However, these methods have baked-in static environments and only allow
for limited scene control -- they are functionally constrained in scene and
trajectory diversity by the captures from which they are reconstructed. In
contrast, generating driving data with recent image or video diffusion models
offers control, however, at the cost of geometry grounding and causality. In
this work, we aim to bridge this gap and present a method that directly
generates large-scale 3D driving scenes with accurate geometry, allowing for
causal novel view synthesis with object permanence and explicit 3D geometry
estimation. The proposed method combines the generation of a proxy geometry and
environment representation with score distillation from learned 2D image
priors. We find that this approach allows for high controllability, enabling
the prompt-guided geometry and high-fidelity texture and structure that can be
conditioned on map layouts -- producing realistic and geometrically consistent
3D generations of complex driving scenes.

</details>


### [6] [Automated Landfill Detection Using Deep Learning: A Comparative Study of Lightweight and Custom Architectures with the AerialWaste Dataset](https://arxiv.org/abs/2508.18315)
*Nowshin Sharmily,Rusab Sarmun,Muhammad E. H. Chowdhury,Mir Hamidul Hussain,Saad Bin Abul Kashem,Molla E Majid,Amith Khandakar*

Main category: cs.CV

TL;DR: 深度学习模型可用于检测非法垃圾填埋场，但高质量数据集稀缺。研究人员使用 AerialWaste 数据集（包含意大利伦巴第地区的 10434 张图像）训练了 Mobilenetv2、Googlenet、Densetnet 和 MobileVit 等轻量级深度学习模型。通过模型集成，在二元分类任务中达到了 92.33% 的准确率、92.67% 的精确率、92.33% 的敏感性、92.41% 的 F1 分数和 92.71% 的特异性。


<details>
  <summary>Details</summary>
Motivation: 手动识别非法垃圾填埋场既耗时又耗力，常常导致其逃避有关部门的注意，进而对人类和环境造成危害。深度学习技术可以在识别这些垃圾填埋场方面发挥关键作用，从而节省宝贵的时间、人力和资源。然而，由于安全问题，目前公开的高质量非法垃圾填埋场检测数据集难以获得。

Method: 本研究采用了 Mobilenetv2、Googlenet、Densetnet 和 MobileVit 等轻量级深度学习模型来训练和验证 AerialWaste 数据集。研究人员发现，复杂且庞大的模型容易出现过拟合，倾向于记忆训练数据而非学习其中的模式。因此，选择了更简单、更轻量级的模型，以利用数据集中的通用特征。通过结合表现最佳的模型，研究人员构建了一个集成模型，并采用了集成和融合技术。

Result: 通过集成和融合技术，在二元分类任务中取得了 92.33% 的准确率、92.67% 的精确率、92.33% 的敏感性、92.41% 的 F1 分数和 92.71% 的特异性。

Conclusion: 深度学习模型，特别是轻量级模型和集成模型，在利用 AerialWaste 数据集检测非法垃圾填埋场方面表现出巨大潜力，能够以高准确率和效率完成任务，同时克服了数据稀缺和模型过拟合的挑战。

Abstract: Illegal landfills are posing as a hazardous threat to people all over the
world. Due to the arduous nature of manually identifying the location of
landfill, many landfills go unnoticed by authorities and later cause dangerous
harm to people and environment. Deep learning can play a significant role in
identifying these landfills while saving valuable time, manpower and resources.
Despite being a burning concern, good quality publicly released datasets for
illegal landfill detection are hard to find due to security concerns. However,
AerialWaste Dataset is a large collection of 10434 images of Lombardy region of
Italy. The images are of varying qualities, collected from three different
sources: AGEA Orthophotos, WorldView-3, and Google Earth. The dataset contains
professionally curated, diverse and high-quality images which makes it
particularly suitable for scalable and impactful research. As we trained
several models to compare results, we found complex and heavy models to be
prone to overfitting and memorizing training data instead of learning patterns.
Therefore, we chose lightweight simpler models which could leverage general
features from the dataset. In this study, Mobilenetv2, Googlenet, Densenet,
MobileVit and other lightweight deep learning models were used to train and
validate the dataset as they achieved significant success with less
overfitting. As we saw substantial improvement in the performance using some of
these models, we combined the best performing models and came up with an
ensemble model. With the help of ensemble and fusion technique, binary
classification could be performed on this dataset with 92.33% accuracy, 92.67%
precision, 92.33% sensitivity, 92.41% F1 score and 92.71% specificity.

</details>


### [7] [Structures Meet Semantics: Multimodal Fusion via Graph Contrastive Learning](https://arxiv.org/abs/2508.18322)
*Jiangfeng Sun,Sihao He,Zhonghong Ou,Meina Song*

Main category: cs.CV

TL;DR: SSU框架通过整合模态内结构信息和跨模态语义对齐来增强多模态情感分析，在CMU-MOSI和CMU-MOSEI数据集上达到最先进性能，同时提高可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态情感分析中未能充分考虑模态特异性结构依赖和语义不对齐问题，限制了其性能、可解释性和鲁棒性。

Method: 提出SSU框架，通过语言句法和文本引导的注意力机制为文本、声学和视觉模态构建动态图，捕捉模态内关系；引入全局文本语义作为跨模态对齐锚点，协调异构语义空间；提出多视图对比学习目标，增强模态内和跨模态视图的可区分性、语义一致性和结构一致性。

Result: SSU在CMU-MOSI和CMU-MOSEI数据集上实现了最先进的性能，同时显著降低了计算开销，并通过定性分析验证了其可解释性和捕捉细微情感模式的能力。

Conclusion: SSU框架通过系统地整合模态特异性结构信息和跨模态语义对齐，有效解决了多模态情感分析中的挑战，实现了高性能、高可解释性和高鲁棒性。

Abstract: Multimodal sentiment analysis (MSA) aims to infer emotional states by
effectively integrating textual, acoustic, and visual modalities. Despite
notable progress, existing multimodal fusion methods often neglect
modality-specific structural dependencies and semantic misalignment, limiting
their quality, interpretability, and robustness. To address these challenges,
we propose a novel framework called the Structural-Semantic Unifier (SSU),
which systematically integrates modality-specific structural information and
cross-modal semantic grounding for enhanced multimodal representations.
Specifically, SSU dynamically constructs modality-specific graphs by leveraging
linguistic syntax for text and a lightweight, text-guided attention mechanism
for acoustic and visual modalities, thus capturing detailed intra-modal
relationships and semantic interactions. We further introduce a semantic
anchor, derived from global textual semantics, that serves as a cross-modal
alignment hub, effectively harmonizing heterogeneous semantic spaces across
modalities. Additionally, we develop a multiview contrastive learning objective
that promotes discriminability, semantic consistency, and structural coherence
across intra- and inter-modal views. Extensive evaluations on two widely used
benchmark datasets, CMU-MOSI and CMU-MOSEI, demonstrate that SSU consistently
achieves state-of-the-art performance while significantly reducing
computational overhead compared to prior methods. Comprehensive qualitative
analyses further validate SSU's interpretability and its ability to capture
nuanced emotional patterns through semantically grounded interactions.

</details>


### [8] [FastAvatar: Instant 3D Gaussian Splatting for Faces from Single Unconstrained Poses](https://arxiv.org/abs/2508.18389)
*Hao Liang,Zhixuan Ge,Ashish Tiwari,Soumendu Majee,G. M. Dilshan Godaliyadda,Ashok Veeraraghavan,Guha Balakrishnan*

Main category: cs.CV

TL;DR: FastAvatar是一个创新的、与姿态无关的、前馈框架，能够从单个任意姿态的面部图像在<10ms内生成3D高斯泼溅（3DGS）模型，并在重建质量、速度和可编辑性方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现快速、姿态无关的面部3D高斯泼溅（3DGS）模型生成，以满足实时、照片级化身应用的需求。

Method: FastAvatar采用新颖的编码器-解码器神经网络设计，首先从多视图捕获的面部训练数据集中构建3DGS面部“模板”模型。然后，将输入的单张面部图像编码为与身份相关的、与姿态无关的潜在嵌入，并解码该嵌入以预测模板3DGS模型中每个高斯的结构和外观参数的残差。

Result: FastAvatar在重建质量上显著优于现有的前馈面部3DGS方法（例如GAGAvatar），并且比逐面部优化方法（例如FlashAvatar、GaussianAvatars和GASP）快1000倍。此外，其潜在空间设计支持实时身份插值和属性编辑。

Conclusion: FastAvatar通过其卓越的重建质量和速度，扩展了3DGS在消费者和交互式系统中的照片级化身应用的范围。

Abstract: We present FastAvatar, a pose-invariant, feed-forward framework that can
generate a 3D Gaussian Splatting (3DGS) model from a single face image from an
arbitrary pose in near-instant time (<10ms). FastAvatar uses a novel
encoder-decoder neural network design to achieve both fast fitting and identity
preservation regardless of input pose. First, FastAvatar constructs a 3DGS face
``template'' model from a training dataset of faces with multi-view captures.
Second, FastAvatar encodes the input face image into an identity-specific and
pose-invariant latent embedding, and decodes this embedding to predict
residuals to the structural and appearance parameters of each Gaussian in the
template 3DGS model. By only inferring residuals in a feed-forward fashion,
model inference is fast and robust. FastAvatar significantly outperforms
existing feed-forward face 3DGS methods (e.g., GAGAvatar) in reconstruction
quality, and runs 1000x faster than per-face optimization methods (e.g.,
FlashAvatar, GaussianAvatars and GASP). In addition, FastAvatar's novel latent
space design supports real-time identity interpolation and attribute editing
which is not possible with any existing feed-forward 3DGS face generation
framework. FastAvatar's combination of excellent reconstruction quality and
speed expands the scope of 3DGS for photorealistic avatar applications in
consumer and interactive systems.

</details>


### [9] [Securing Face and Fingerprint Templates in Humanitarian Biometric Systems](https://arxiv.org/abs/2508.18415)
*Giuseppe Stragapede,Sam Merrick,Vedrana Krivokuća Hahn,Justin Sukaitis,Vincent Graf Narbel*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In humanitarian and emergency scenarios, the use of biometrics can
dramatically improve the efficiency of operations, but it poses risks for the
data subjects, which are exacerbated in contexts of vulnerability. To address
this, we present a mobile biometric system implementing a biometric template
protection (BTP) scheme suitable for these scenarios. After rigorously
formulating the functional, operational, and security and privacy requirements
of these contexts, we perform a broad comparative analysis of the BTP
landscape. PolyProtect, a method designed to operate on neural network face
embeddings, is identified as the most suitable method due to its effectiveness,
modularity, and lightweight computational burden. We evaluate PolyProtect in
terms of verification and identification accuracy, irreversibility, and
unlinkability, when this BTP method is applied to face embeddings extracted
using EdgeFace, a novel state-of-the-art efficient feature extractor, on a
real-world face dataset from a humanitarian field project in Ethiopia.
Moreover, as PolyProtect promises to be modality-independent, we extend its
evaluation to fingerprints. To the best of our knowledge, this is the first
time that PolyProtect has been evaluated for the identification scenario and
for fingerprint biometrics. Our experimental results are promising, and we plan
to release our code

</details>


### [10] [Why Relational Graphs Will Save the Next Generation of Vision Foundation Models?](https://arxiv.org/abs/2508.18421)
*Fatemeh Ziaeetabar*

Main category: cs.CV

TL;DR: Vision foundation models (FMs) lack explicit relational reasoning, hindering performance on tasks requiring understanding of entities, roles, and spatio-temporal relations. This paper proposes augmenting FMs with dynamic relational graphs to improve fine-grained semantic fidelity, robustness, interpretability, and efficiency. The authors provide cross-domain evidence and outline a research agenda for FM-graph hybrids.


<details>
  <summary>Details</summary>
Motivation: Vision foundation models (FMs) exhibit limitations on tasks requiring explicit reasoning over entities, roles, and spatio-temporal relations, which are crucial for fine-grained human activity recognition, egocentric video understanding, and multimodal medical image analysis. Next-generation FMs need explicit relational interfaces to address these shortcomings.

Method: The paper proposes augmenting foundation models (FMs) with dynamic relational graphs, which are graphs whose topology and edge semantics are inferred from the input and task context. This approach is illustrated with examples from human manipulation action recognition and brain tumor segmentation, showing improved performance when FMs are augmented with lightweight, context-adaptive graph-reasoning modules.

Result: Augmenting FMs with dynamic relational graph-reasoning modules improves fine-grained semantic fidelity, out-of-distribution robustness, interpretability, and computational efficiency compared to FM-only baselines. These hybrid models also achieve favorable memory and hardware efficiency due to sparse reasoning over semantic nodes.

Conclusion: Next-generation vision foundation models should incorporate explicit relational interfaces, such as dynamic relational graphs. Future research should focus on learned dynamic graph construction, multi-level relational reasoning, cross-modal fusion, and evaluation protocols that specifically test relational competence in structured vision tasks to enable deployment under practical resource constraints.

Abstract: Vision foundation models (FMs) have become the predominant architecture in
computer vision, providing highly transferable representations learned from
large-scale, multimodal corpora. Nonetheless, they exhibit persistent
limitations on tasks that require explicit reasoning over entities, roles, and
spatio-temporal relations. Such relational competence is indispensable for
fine-grained human activity recognition, egocentric video understanding, and
multimodal medical image analysis, where spatial, temporal, and semantic
dependencies are decisive for performance. We advance the position that
next-generation FMs should incorporate explicit relational interfaces,
instantiated as dynamic relational graphs (graphs whose topology and edge
semantics are inferred from the input and task context). We illustrate this
position with cross-domain evidence from recent systems in human manipulation
action recognition and brain tumor segmentation, showing that augmenting FMs
with lightweight, context-adaptive graph-reasoning modules improves
fine-grained semantic fidelity, out of distribution robustness,
interpretability, and computational efficiency relative to FM only baselines.
Importantly, by reasoning sparsely over semantic nodes, such hybrids also
achieve favorable memory and hardware efficiency, enabling deployment under
practical resource constraints. We conclude with a targeted research agenda for
FM graph hybrids, prioritizing learned dynamic graph construction, multi-level
relational reasoning (e.g., part object scene in activity understanding, or
region organ in medical imaging), cross-modal fusion, and evaluation protocols
that directly probe relational competence in structured vision tasks.

</details>


### [11] [Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion](https://arxiv.org/abs/2508.18734)
*DongHoon Lim,YoungChae Kim,Dong-Hyun Kim,Da-Hee Yang,Joon-Hyuk Chang*

Main category: cs.CV

TL;DR: 提出了一种新颖的音频-视频语音识别（AVSR）框架，通过基于令牌级声学损坏分数的自适应加权音频和视觉特征，提高了在嘈杂环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的AVSR系统在估计音频可靠性和动态调整模式依赖性方面存在挑战，尤其是在嘈杂环境中。

Method: 提出了一种路由门控交叉模态特征融合框架，该框架利用音频-视频特征融合路由器，根据令牌级声学损坏分数自适应地重新加权音频和视觉特征，从而在音频质量下降时能够转向视觉模式。

Result: 在LRS3数据集上的实验表明，与AV-HuBERT相比，该方法将单词错误率相对降低了16.51-42.67%。消融研究证实，路由机制和门控机制都有助于提高在真实世界声学噪声下的鲁棒性。

Conclusion: 该研究提出了一种有效的AVSR框架，通过自适应地融合音频和视觉特征，提高了在嘈杂环境下的识别性能。

Abstract: Robust audio-visual speech recognition (AVSR) in noisy environments remains
challenging, as existing systems struggle to estimate audio reliability and
dynamically adjust modality reliance. We propose router-gated cross-modal
feature fusion, a novel AVSR framework that adaptively reweights audio and
visual features based on token-level acoustic corruption scores. Using an
audio-visual feature fusion-based router, our method down-weights unreliable
audio tokens and reinforces visual cues through gated cross-attention in each
decoder layer. This enables the model to pivot toward the visual modality when
audio quality deteriorates. Experiments on LRS3 demonstrate that our approach
achieves an 16.51-42.67% relative reduction in word error rate compared to
AV-HuBERT. Ablation studies confirm that both the router and gating mechanism
contribute to improved robustness under real-world acoustic noise.

</details>


### [12] [LPLC: A Dataset for License Plate Legibility Classification](https://arxiv.org/abs/2508.18425)
*Lucas Wojcik,Gabriel E. Lima,Valfride Nascimento,Eduil Nascimento Jr.,Rayson Laroca,David Menotti*

Main category: cs.CV

TL;DR: 该研究提出LPLC数据集和基准测试，以解决自动车牌识别（ALPR）中难以辨认车牌的挑战，并为超分辨率（SR）和车牌识别（LP recognition）研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了优化模型性能和计算效率，需要选择性地对需要增强清晰度的车牌图像进行预处理。现有研究未能解决低质量车牌的识别问题。

Method: 提出包含10,210张车辆图像和12,687个标注车牌的LPLC数据集，标注涵盖遮挡、清晰度（完美、良好、差、难以辨认）和字符。提出一个基准测试任务，使用ViT、ResNet和YOLO三种图像识别网络对车牌进行清晰度分类（良好、需要SR、无法恢复）。

Result: 三种基线模型的总体F1分数均低于80%，表明任务的难度，并强调了进一步研究的必要性。

Conclusion: LPLC数据集和基准测试的提出，突显了在ALPR领域处理难以辨认车牌的挑战，并为未来研究奠定了基础。

Abstract: Automatic License Plate Recognition (ALPR) faces a major challenge when
dealing with illegible license plates (LPs). While reconstruction methods such
as super-resolution (SR) have emerged, the core issue of recognizing these
low-quality LPs remains unresolved. To optimize model performance and
computational efficiency, image pre-processing should be applied selectively to
cases that require enhanced legibility. To support research in this area, we
introduce a novel dataset comprising 10,210 images of vehicles with 12,687
annotated LPs for legibility classification (the LPLC dataset). The images span
a wide range of vehicle types, lighting conditions, and camera/image quality
levels. We adopt a fine-grained annotation strategy that includes vehicle- and
LP-level occlusions, four legibility categories (perfect, good, poor, and
illegible), and character labels for three categories (excluding illegible
LPs). As a benchmark, we propose a classification task using three image
recognition networks to determine whether an LP image is good enough, requires
super-resolution, or is completely unrecoverable. The overall F1 score, which
remained below 80% for all three baseline models (ViT, ResNet, and YOLO),
together with the analyses of SR and LP recognition methods, highlights the
difficulty of the task and reinforces the need for further research. The
proposed dataset is publicly available at
https://github.com/lmlwojcik/lplc-dataset.

</details>


### [13] [CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological Visual Question Answering](https://arxiv.org/abs/2508.18430)
*Aranya Saha,Tanvir Ahmed Khan,Ismam Nur Swapnil,Mohammad Ariful Haque*

Main category: cs.CV

TL;DR: CLARIFY是一个专科-通才框架，用于皮肤科视觉问答（VQA），它结合了一个轻量级领域训练的图像分类器（专科）和一个压缩的对话VLM（通才），通过知识图谱增强，提高了18%的诊断准确性，同时降低了20%的VRAM和5%的延迟。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型（VLMs）在医学任务中潜力巨大，但其通用性限制了专业诊断的准确性，并且模型庞大带来了高昂的推理成本。

Method: CLARIFY结合了一个轻量级的领域训练图像分类器（专科）和一个压缩的对话VLM（通才）。专科的预测直接指导通才的推理，并通过知识图谱检索模块提供支持，以确保回答的准确性和可靠性。

Result: CLARIFY在皮肤科VQA任务上实现了18%的诊断准确性提升，同时将平均VRAM需求和延迟分别降低了至少20%和5%。

Conclusion: CLARIFY的专科-通才系统为构建轻量级、可信赖且临床可行的AI系统提供了一个实用且强大的范式。

Abstract: Vision-language models (VLMs) have shown significant potential for medical
tasks; however, their general-purpose nature can limit specialized diagnostic
accuracy, and their large size poses substantial inference costs for real-world
clinical deployment. To address these challenges, we introduce CLARIFY, a
Specialist-Generalist framework for dermatological visual question answering
(VQA). CLARIFY combines two components: (i) a lightweight, domain-trained image
classifier (the Specialist) that provides fast and highly accurate diagnostic
predictions, and (ii) a powerful yet compressed conversational VLM (the
Generalist) that generates natural language explanations to user queries. In
our framework, the Specialist's predictions directly guide the Generalist's
reasoning, focusing it on the correct diagnostic path. This synergy is further
enhanced by a knowledge graph-based retrieval module, which grounds the
Generalist's responses in factual dermatological knowledge, ensuring both
accuracy and reliability. This hierarchical design not only reduces diagnostic
errors but also significantly improves computational efficiency. Experiments on
our curated multimodal dermatology dataset demonstrate that CLARIFY achieves an
18\% improvement in diagnostic accuracy over the strongest baseline, a
fine-tuned, uncompressed single-line VLM, while reducing the average VRAM
requirement and latency by at least 20\% and 5\%, respectively. These results
indicate that a Specialist-Generalist system provides a practical and powerful
paradigm for building lightweight, trustworthy, and clinically viable AI
systems.

</details>


### [14] [VQualA 2025 Challenge on Face Image Quality Assessment: Methods and Results](https://arxiv.org/abs/2508.18445)
*Sizhuo Ma,Wei-Ting Chen,Qiang Gao,Jian Wang,Chris Wei Zhou,Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai,Baoying Chen,Xiongwei Xiao,Jishen Zeng,Wei Wu,Tiexuan Lou,Yuchen Tan,Chunyi Song,Zhiwei Xu,MohammadAli Hamidi,Hadi Amirpour,Mingyin Bai,Jiawang Du,Zhenyu Jiang,Zilong Lu,Ziguan Cui,Zongliang Gan,Xinpeng Li,Shiqi Jiang,Chenhui Li,Changbo Wang,Weijun Yuan,Zhan Li,Yihang Chen,Yifan Deng,Ruting Deng,Zhanglu Chen,Boyang Yao,Shuling Zheng,Feng Zhang,Zhiheng Fu,Abhishek Joshi,Aman Agarwal,Rakhil Immidisetti,Ajay Narasimha Mopidevi,Vishwajeet Shukla,Hao Yang,Ruikun Zhang,Liyuan Pan,Kaixin Deng,Hang Ouyang,Fan yang,Zhizun Luo,Zhuohang Shi,Songning Lai,Weilin Ruan,Yutao Yue*

Main category: cs.CV

TL;DR: VQualA 2025挑战赛旨在为包含噪声、模糊和压缩伪影等真实世界退化的人脸图像开发轻量级、高效的人脸图像质量评估（FIQA）模型。参赛者提交了符合0.5 GFLOPs和500万参数限制的模型，以预测MOS分数。该挑战赛吸引了127名参赛者，提交了1519份最终作品，并使用相关性指标在野外人脸图像数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的人脸图像经常受到噪声、模糊和压缩伪影等退化因素的影响，从而降低图像质量并阻碍后续任务。因此，有必要开发轻量级且高效的人脸图像质量评估（FIQA）方法。

Method: 组织VQualA 2025挑战赛，限制参赛模型（0.5 GFLOPs和500万参数），以预测具有任意分辨率和现实退化的人脸图像的MOS分数。通过在野外人脸图像数据集上使用相关性指标对提交的参赛作品进行全面评估。

Result: 该挑战赛吸引了127名参赛者，提交了1519份最终作品，并展示了在FIQA方面取得的进展。

Conclusion: VQualA 2025挑战赛成功地推动了实用的FIQA方法的发展，重点是轻量级和高效的模型，以应对真实世界人脸图像的退化。

Abstract: Face images play a crucial role in numerous applications; however, real-world
conditions frequently introduce degradations such as noise, blur, and
compression artifacts, affecting overall image quality and hindering subsequent
tasks. To address this challenge, we organized the VQualA 2025 Challenge on
Face Image Quality Assessment (FIQA) as part of the ICCV 2025 Workshops.
Participants created lightweight and efficient models (limited to 0.5 GFLOPs
and 5 million parameters) for the prediction of Mean Opinion Scores (MOS) on
face images with arbitrary resolutions and realistic degradations. Submissions
underwent comprehensive evaluations through correlation metrics on a dataset of
in-the-wild face images. This challenge attracted 127 participants, with 1519
final submissions. This report summarizes the methodologies and findings for
advancing the development of practical FIQA approaches.

</details>


### [15] [Context-Aware Zero-Shot Anomaly Detection in Surveillance Using Contrastive and Predictive Spatiotemporal Modeling](https://arxiv.org/abs/2508.18463)
*Md. Rashid Shahriar Khan,Md. Abrar Hasan,Mohammod Tareq Aziz Justice*

Main category: cs.CV

TL;DR: 提出一种新颖的上下文感知零样本异常检测框架，用于识别监控录像中的异常事件，无需在训练期间接触异常样本。


<details>
  <summary>Details</summary>
Motivation: 监控录像中的异常检测具有挑战性，因为异常事件的性质是不可预测且依赖于上下文的。

Method: 结合使用TimeSformer、DPC和CLIP来模拟时空动态和语义上下文。TimeSformer提取时空特征，DPC预测未来表示以识别时间偏差，CLIP的语义流通过文本提示实现概念级异常检测。使用InfoNCE和CPC损失进行联合训练，并加入上下文门控机制。

Result: 该框架能够将预测模型与视觉-语言理解相结合，能够泛化到复杂环境中先前未见过的行为。

Conclusion: 该框架弥合了零样本异常检测中时域推理和语义上下文之间的差距。

Abstract: Detecting anomalies in surveillance footage is inherently challenging due to
their unpredictable and context-dependent nature. This work introduces a novel
context-aware zero-shot anomaly detection framework that identifies abnormal
events without exposure to anomaly examples during training. The proposed
hybrid architecture combines TimeSformer, DPC, and CLIP to model spatiotemporal
dynamics and semantic context. TimeSformer serves as the vision backbone to
extract rich spatial-temporal features, while DPC forecasts future
representations to identify temporal deviations. Furthermore, a CLIP-based
semantic stream enables concept-level anomaly detection through
context-specific text prompts. These components are jointly trained using
InfoNCE and CPC losses, aligning visual inputs with their temporal and semantic
representations. A context-gating mechanism further enhances decision-making by
modulating predictions with scene-aware cues or global video features. By
integrating predictive modeling with vision-language understanding, the system
can generalize to previously unseen behaviors in complex environments. This
framework bridges the gap between temporal reasoning and semantic context in
zero-shot anomaly detection for surveillance. The code for this research has
been made available at
https://github.com/NK-II/Context-Aware-ZeroShot-Anomaly-Detection-in-Surveillance.

</details>


### [16] [DoGFlow: Self-Supervised LiDAR Scene Flow via Cross-Modal Doppler Guidance](https://arxiv.org/abs/2508.18506)
*Ajinkya Khoche,Qingwen Zhang,Yixi Cai,Sina Sharif Mansouri,Patric Jensfelt*

Main category: cs.CV

TL;DR: DoGFlow是一个新的自监督框架，无需手动标注即可恢复LiDAR场景流估计的完整3D物体运动。它通过动态感知关联和消歧传播，将4D雷达多普勒测量中的运动伪标签转移到LiDAR域。


<details>
  <summary>Details</summary>
Motivation: 为了解决手动标注数据集的瓶颈，并提高现有自监督方法在具有挑战性的长距离和恶劣天气场景中的性能。

Method: DoGFlow采用跨模态标签转移方法，利用4D雷达多普勒测量实时计算运动伪标签，并通过动态感知关联和消歧传播将其转移到LiDAR域。

Result: 在MAN TruckScenes数据集上，DoGFlow的性能显著优于现有的自监督方法，并且通过只使用10%的真实数据，就使得LiDAR主干网络达到了完全监督性能的90%以上，提高了标签效率。

Conclusion: DoGFlow是一个有效的自监督框架，能够无需手动标注即可进行LiDAR场景流估计，并在各种场景下表现出色。

Abstract: Accurate 3D scene flow estimation is critical for autonomous systems to
navigate dynamic environments safely, but creating the necessary large-scale,
manually annotated datasets remains a significant bottleneck for developing
robust perception models. Current self-supervised methods struggle to match the
performance of fully supervised approaches, especially in challenging
long-range and adverse weather scenarios, while supervised methods are not
scalable due to their reliance on expensive human labeling. We introduce
DoGFlow, a novel self-supervised framework that recovers full 3D object motions
for LiDAR scene flow estimation without requiring any manual ground truth
annotations. This paper presents our cross-modal label transfer approach, where
DoGFlow computes motion pseudo-labels in real-time directly from 4D radar
Doppler measurements and transfers them to the LiDAR domain using dynamic-aware
association and ambiguity-resolved propagation. On the challenging MAN
TruckScenes dataset, DoGFlow substantially outperforms existing self-supervised
methods and improves label efficiency by enabling LiDAR backbones to achieve
over 90% of fully supervised performance with only 10% of the ground truth
data. For more details, please visit https://ajinkyakhoche.github.io/DogFlow/

</details>


### [17] [SAT-SKYLINES: 3D Building Generation from Satellite Imagery and Coarse Geometric Priors](https://arxiv.org/abs/2508.18531)
*Zhangyu Jin,Andrew Feng*

Main category: cs.CV

TL;DR: SatSkylines是一种利用卫星图像和粗略几何先验进行3D建筑生成的方法，解决了现有方法在精确恢复建筑结构方面的不足，并通过引入Skylines-50K数据集来支持详细建筑模型的生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的3D生成方法在仅使用卫星图像的俯视视角时，难以准确恢复建筑结构；而3D细节化方法依赖于详细的体素输入，无法从简单的先验（如立方体）生成满意结果。本研究旨在解决这些问题。

Method: 提出了一种模拟从插值的粗略先验到详细几何形状的转换的模型，实现了在无额外计算成本的情况下进行灵活的几何控制。

Result: 实验评估表明，该模型有效且具有强大的泛化能力。

Conclusion: SatSkylines通过模拟粗略先验到详细几何的转换，有效解决了现有3D建筑生成方法在处理卫星图像时的局限性，并利用Skylines-50K数据集进一步增强了其能力。

Abstract: We present SatSkylines, a 3D building generation approach that takes
satellite imagery and coarse geometric priors. Without proper geometric
guidance, existing image-based 3D generation methods struggle to recover
accurate building structures from the top-down views of satellite images alone.
On the other hand, 3D detailization methods tend to rely heavily on highly
detailed voxel inputs and fail to produce satisfying results from simple priors
such as cuboids. To address these issues, our key idea is to model the
transformation from interpolated noisy coarse priors to detailed geometries,
enabling flexible geometric control without additional computational cost. We
have further developed Skylines-50K, a large-scale dataset of over 50,000
unique and stylized 3D building assets in order to support the generations of
detailed building models. Extensive evaluations indicate the effectiveness of
our model and strong generalization ability.

</details>


### [18] [Adaptive Visual Navigation Assistant in 3D RPGs](https://arxiv.org/abs/2508.18539)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.CV

TL;DR: 提出了一种检测游戏内可通行空间转换点（STP）及其主要（MSTP）的方法，用于自动地图绘制和评估地图线索呈现。


<details>
  <summary>Details</summary>
Motivation: 在复杂3D游戏环境中，玩家依赖视觉线索识别地图转换点，这对于客户端自动地图绘制和地图线索呈现的评估至关重要。

Method: 提出一个两阶段的深度学习流程：首先使用Faster R-CNN检测潜在STP，然后使用轻量级MSTP选择器融合局部和全局视觉特征进行排名。两个阶段都受益于参数高效的适配器，并引入了可选的检索增强融合步骤。

Result: 在自定义的RPG游戏中验证了该方法，发现在数据充足的情况下全网络微调能获得更好的STP检测效果，而在数据不足的情况下，仅使用适配器迁移在MSTP选择任务上更鲁棒和有效。

Conclusion: 定义了新的问题，提供了基线流程、数据集和模型适配的初步见解，旨在为未来AI驱动的导航辅助和数据驱动的关卡设计工具做出贡献。

Abstract: In complex 3D game environments, players rely on visual affordances to spot
map transition points. Efficient identification of such points is important to
client-side auto-mapping, and provides an objective basis for evaluating map
cue presentation. In this work, we formalize the task of detecting traversable
Spatial Transition Points (STPs)-connectors between two sub regions-and
selecting the singular Main STP (MSTP), the unique STP that lies on the
designer-intended critical path toward the player's current macro-objective,
from a single game frame, proposing this as a new research focus. We introduce
a two-stage deep-learning pipeline that first detects potential STPs using
Faster R-CNN and then ranks them with a lightweight MSTP selector that fuses
local and global visual features. Both stages benefit from parameter-efficient
adapters, and we further introduce an optional retrieval-augmented fusion step.
Our primary goal is to establish the feasibility of this problem and set
baseline performance metrics. We validate our approach on a custom-built,
diverse dataset collected from five Action RPG titles. Our experiments reveal a
key trade-off: while full-network fine-tuning produces superior STP detection
with sufficient data, adapter-only transfer is significantly more robust and
effective in low-data scenarios and for the MSTP selection task. By defining
this novel problem, providing a baseline pipeline and dataset, and offering
initial insights into efficient model adaptation, we aim to contribute to
future AI-driven navigation aids and data-informed level-design tools.

</details>


### [19] [Wan-S2V: Audio-Driven Cinematic Video Generation](https://arxiv.org/abs/2508.18621)
*Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-S2V模型在电影级角色动画领域取得突破，显著优于Hunyuan-Avatar和Omnihuman等现有方法，并在长视频生成和唇形同步编辑方面展现出多功能性。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动角色动画方法在处理影视制作中的复杂需求（如角色交互、身体动作、镜头运动）时表现不足，本文旨在解决电影级角色动画的挑战。

Method: 提出基于Wan的新型音频驱动模型Wan-S2V，以提升动画的表达力和保真度。

Result: Wan-S2V在与Hunyuan-Avatar和Omnihuman等模型的对比实验中表现出显著的优越性。

Conclusion: Wan-S2V在电影级角色动画方面取得了显著进展，并在长视频生成和唇形同步编辑方面具有广泛应用潜力。

Abstract: Current state-of-the-art (SOTA) methods for audio-driven character animation
demonstrate promising performance for scenarios primarily involving speech and
singing. However, they often fall short in more complex film and television
productions, which demand sophisticated elements such as nuanced character
interactions, realistic body movements, and dynamic camera work. To address
this long-standing challenge of achieving film-level character animation, we
propose an audio-driven model, which we refere to as Wan-S2V, built upon Wan.
Our model achieves significantly enhanced expressiveness and fidelity in
cinematic contexts compared to existing approaches. We conducted extensive
experiments, benchmarking our method against cutting-edge models such as
Hunyuan-Avatar and Omnihuman. The experimental results consistently demonstrate
that our approach significantly outperforms these existing solutions.
Additionally, we explore the versatility of our method through its applications
in long-form video generation and precise video lip-sync editing.

</details>


### [20] [Decouple, Reorganize, and Fuse: A Multimodal Framework for Cancer Survival Prediction](https://arxiv.org/abs/2508.18632)
*Huayi Wang,Haochao Ying,Yuyang Xu,Qibo Qiu,Cheng Zhang,Danny Z. Chen,Ying Sun,Jian Wu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的DeReF框架，通过随机重组和动态MoE融合来解决多模态信息融合中的挑战，提高了癌症生存分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有癌症生存分析方法在融合多模态信息时，面临固定融合方案（如拼接、注意力）导致模型过度依赖预定义特征组合，以及MoE方法中专家网络独立处理特征导致信息交互受限的问题。

Method: 提出了一种新的解耦-重组-融合（DeReF）框架，该框架在模态解耦和动态MoE融合模块之间设计了随机特征重组策略，并在模态解耦模块中加入了区域交叉注意力网络。

Result: 在肝癌（LC）和三个TCGA公共数据集上进行了广泛的实验，结果证实了所提出方法的有效性。

Conclusion: DeReF框架通过随机特征重组和动态MoE融合，克服了信息封闭的问题，提升了模型处理多模态信息的能力，在癌症生存分析任务上表现优于现有方法。

Abstract: Cancer survival analysis commonly integrates information across diverse
medical modalities to make survival-time predictions. Existing methods
primarily focus on extracting different decoupled features of modalities and
performing fusion operations such as concatenation, attention, and MoE-based
(Mixture-of-Experts) fusion. However, these methods still face two key
challenges: i) Fixed fusion schemes (concatenation and attention) can lead to
model over-reliance on predefined feature combinations, limiting the dynamic
fusion of decoupled features; ii) in MoE-based fusion methods, each expert
network handles separate decoupled features, which limits information
interaction among the decoupled features. To address these challenges, we
propose a novel Decoupling-Reorganization-Fusion framework (DeReF), which
devises a random feature reorganization strategy between modalities decoupling
and dynamic MoE fusion modules.Its advantages are: i) it increases the
diversity of feature combinations and granularity, enhancing the generalization
ability of the subsequent expert networks; ii) it overcomes the problem of
information closure and helps expert networks better capture information among
decoupled features. Additionally, we incorporate a regional cross-attention
network within the modality decoupling module to improve the representation
quality of decoupled features. Extensive experimental results on our in-house
Liver Cancer (LC) and three widely used TCGA public datasets confirm the
effectiveness of our proposed method. The code will be made publicly available.

</details>


### [21] [ROSE: Remove Objects with Side Effects in Videos](https://arxiv.org/abs/2508.18633)
*Chenxuan Miao,Yutong Feng,Jianshu Zeng,Zixiang Gao,Hantang Liu,Yunfeng Yan,Donglian Qi,Xi Chen,Bin Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: ROSE是一个用于去除视频中物体及其阴影、反射等副作用的框架。该框架利用3D渲染引擎生成合成数据，并采用基于Transformer的扩散模型进行视频修复，同时引入额外监督来预测副作用区域。ROSE在ROSE-Bench基准测试中表现优于现有模型，并能很好地泛化到真实视频场景。


<details>
  <summary>Details</summary>
Motivation: 现有视频目标移除方法在处理阴影、反射等副作用时存在困难，原因是缺乏配对视频数据进行监督。

Method: 该框架（ROSE）使用3D渲染引擎生成大规模配对合成数据，包含各种场景、物体、拍摄角度和相机轨迹。模型基于扩散Transformer实现，通过输入整个视频进行参考外消隐，并引入额外监督来显式预测受副作用影响的区域。

Result: ROSE在ROSE-Bench基准测试中取得了优于现有视频目标擦除模型的性能，并且能够很好地泛化到真实视频场景。

Conclusion: ROSE框架通过利用3D渲染生成合成数据并结合先进的视频修复模型，有效解决了视频目标移除中的副作用问题，并在评估中展现了优越的性能和泛化能力。

Abstract: Video object removal has achieved advanced performance due to the recent
success of video generative models. However, when addressing the side effects
of objects, e.g., their shadows and reflections, existing works struggle to
eliminate these effects for the scarcity of paired video data as supervision.
This paper presents ROSE, termed Remove Objects with Side Effects, a framework
that systematically studies the object's effects on environment, which can be
categorized into five common cases: shadows, reflections, light, translucency
and mirror. Given the challenges of curating paired videos exhibiting the
aforementioned effects, we leverage a 3D rendering engine for synthetic data
generation. We carefully construct a fully-automatic pipeline for data
preparation, which simulates a large-scale paired dataset with diverse scenes,
objects, shooting angles, and camera trajectories. ROSE is implemented as an
video inpainting model built on diffusion transformer. To localize all
object-correlated areas, the entire video is fed into the model for
reference-based erasing. Moreover, additional supervision is introduced to
explicitly predict the areas affected by side effects, which can be revealed
through the differential mask between the paired videos. To fully investigate
the model performance on various side effect removal, we presents a new
benchmark, dubbed ROSE-Bench, incorporating both common scenarios and the five
special side effects for comprehensive evaluation. Experimental results
demonstrate that ROSE achieves superior performance compared to existing video
object erasing models and generalizes well to real-world video scenarios. The
project page is https://rose2025-inpaint.github.io/.

</details>


### [22] [OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and Caption Set Equivalence Reward](https://arxiv.org/abs/2508.18634)
*Chunlin Zhong,Qiuxia Hou,Zhangjun Zhou,Shuang Hao,Haonan Lu,Yanhao Zhang,He Tang,Xiang Bai*

Main category: cs.CV

TL;DR: 该研究提出了一种名为OwlCap的多模态大语言模型（MLLM），用于解决视频字幕生成中的运动-细节不平衡问题，通过构建HMD-270K数据集和引入CSER奖励机制，在VDC和DREAM-1K基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视频字幕生成方法在处理运动和细节信息时存在不平衡问题，导致生成的字幕不完整，影响了视频的理解和生成的一致性。

Method: 研究者构建了HMD-270K数据集（通过MDF和FGE两阶段流程）来平衡运动和细节信息，并引入了基于GRPO的CSER奖励机制，以提升字幕的完整性和准确性。基于此，开发了OwlCap模型。

Result: OwlCap模型在VDC数据集上取得了+4.2的准确率提升，在DREAM-1K数据集上取得了+4.6的F1分数提升，显著优于基线模型。

Conclusion: 所提出的HMD-270K数据集和OwlCap模型能够有效解决视频字幕生成中的运动-细节不平衡问题，并在运动和细节方面均取得了性能上的提升，为视频字幕生成领域的研究社区带来了重要的贡献。

Abstract: Video captioning aims to generate comprehensive and coherent descriptions of
the video content, contributing to the advancement of both video understanding
and generation. However, existing methods often suffer from motion-detail
imbalance, as models tend to overemphasize one aspect while neglecting the
other. This imbalance results in incomplete captions, which in turn leads to a
lack of consistency in video understanding and generation. To address this
issue, we propose solutions from two aspects: 1) Data aspect: We constructed
the Harmonizing Motion-Detail 270K (HMD-270K) dataset through a two-stage
pipeline: Motion-Detail Fusion (MDF) and Fine-Grained Examination (FGE). 2)
Optimization aspect: We introduce the Caption Set Equivalence Reward (CSER)
based on Group Relative Policy Optimization (GRPO). CSER enhances completeness
and accuracy in capturing both motion and details through unit-to-set matching
and bidirectional validation. Based on the HMD-270K supervised fine-tuning and
GRPO post-training with CSER, we developed OwlCap, a powerful video captioning
multi-modal large language model (MLLM) with motion-detail balance.
Experimental results demonstrate that OwlCap achieves significant improvements
compared to baseline models on two benchmarks: the detail-focused VDC (+4.2
Acc) and the motion-focused DREAM-1K (+4.6 F1). The HMD-270K dataset and OwlCap
model will be publicly released to facilitate video captioning research
community advancements.

</details>


### [23] [Clustering-based Feature Representation Learning for Oracle Bone Inscriptions Detection](https://arxiv.org/abs/2508.18641)
*Ye Tao,Xinran Fu,Honglin Pang,Xi Yang,Chuntao Li*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的基于聚类的特征空间表示学习方法，用于从带有噪声和裂缝的拓本图像中自动检测甲骨文（OBIs），利用甲骨文（OBC）字库数据集作为先验知识来增强特征提取，并通过特定损失函数优化特征表示，在三种主流检测框架（Faster R-CNN、DETR、Sparse R-CNN）上均取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了应对拓本图像中噪声和裂缝等退化因素对传统检测网络有效性的限制，该研究旨在提高从拓本图像中自动检测甲骨文（OBIs）的准确性，这是数字考古学中的一项基本但具有挑战性的任务。

Method: 提出了一种新颖的基于聚类的特征空间表示学习方法，该方法利用甲骨文（OBC）字库数据集作为先验知识，通过聚类实现表示学习来增强检测网络的特征提取。该方法包含一个源于聚类结果的专门损失函数，用于优化特征表示，并将其整合到整个网络损失中。

Result: 在两个OBIs检测数据集上，使用Faster R-CNN、DETR和Sparse R-CNN三种主流检测框架进行的实验表明，该方法能够显著提升所有框架的性能。

Conclusion: 所提出的基于聚类的特征空间表示学习方法能够有效提升甲骨文（OBIs）在拓本图像中的检测性能，尤其是在存在噪声和裂缝等退化因素的情况下。

Abstract: Oracle Bone Inscriptions (OBIs), play a crucial role in understanding ancient
Chinese civilization. The automated detection of OBIs from rubbing images
represents a fundamental yet challenging task in digital archaeology, primarily
due to various degradation factors including noise and cracks that limit the
effectiveness of conventional detection networks. To address these challenges,
we propose a novel clustering-based feature space representation learning
method. Our approach uniquely leverages the Oracle Bones Character (OBC) font
library dataset as prior knowledge to enhance feature extraction in the
detection network through clustering-based representation learning. The method
incorporates a specialized loss function derived from clustering results to
optimize feature representation, which is then integrated into the total
network loss. We validate the effectiveness of our method by conducting
experiments on two OBIs detection dataset using three mainstream detection
frameworks: Faster R-CNN, DETR, and Sparse R-CNN. Through extensive
experimentation, all frameworks demonstrate significant performance
improvements.

</details>


### [24] [SFormer: SNR-guided Transformer for Underwater Image Enhancement from the Frequency Domain](https://arxiv.org/abs/2508.18664)
*Xin Tian,Yingtie Lei,Xiujun Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SFormer的新型水下图像增强（UIE）方法，通过在频域中使用信噪比（SNR）先验来克服现有方法的局限性，实现了更好的细节恢复和降噪效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的水下图像增强方法虽然引入了物理先验（如信噪比SNR），但在处理波长依赖衰减时存在局限：空间域的SNR先验难以有效分离跨通道干扰，并且在增强信息结构和抑制噪声方面能力有限。

Method: 本研究提出将SNR先验引入频域，通过分解特征的幅度和相位谱进行通道调制。具体方法包括：1. 提出傅里叶注意力SNR先验Transformer（FAST），结合频谱交互和SNR线索以突出关键频谱分量。2. 引入频域自适应Transformer（FAT）瓶颈，利用门控注意力机制融合低频和高频分支，以提升感知质量。3. 将FAST和FAT模块集成到一个统一的U型架构中，结合了常规RGB流和SNR引导分支，构成SFormer。模型在UIEB、EUVP和LSUI数据集的4800张配对图像上进行训练。

Result: SFormer在UIEB、EUVP和LSUI数据集上进行了训练和评估。与现有方法相比，SFormer在PSNR上实现了3.1 dB的增益，在SSIM上提高了0.08。实验证明，SFormer能够成功恢复水下场景的颜色、纹理和对比度。

Conclusion: SFormer通过在频域中利用SNR先验，并结合傅里叶注意力和自适应Transformer等技术，有效克服了传统方法在处理跨通道干扰和噪声抑制方面的不足，显著提升了水下图像的增强效果，在客观指标和主观视觉质量上均优于现有方法。

Abstract: Recent learning-based underwater image enhancement (UIE) methods have
advanced by incorporating physical priors into deep neural networks,
particularly using the signal-to-noise ratio (SNR) prior to reduce
wavelength-dependent attenuation. However, spatial domain SNR priors have two
limitations: (i) they cannot effectively separate cross-channel interference,
and (ii) they provide limited help in amplifying informative structures while
suppressing noise. To overcome these, we propose using the SNR prior in the
frequency domain, decomposing features into amplitude and phase spectra for
better channel modulation. We introduce the Fourier Attention SNR-prior
Transformer (FAST), combining spectral interactions with SNR cues to highlight
key spectral components. Additionally, the Frequency Adaptive Transformer (FAT)
bottleneck merges low- and high-frequency branches using a gated attention
mechanism to enhance perceptual quality. Embedded in a unified U-shaped
architecture, these modules integrate a conventional RGB stream with an
SNR-guided branch, forming SFormer. Trained on 4,800 paired images from UIEB,
EUVP, and LSUI, SFormer surpasses recent methods with a 3.1 dB gain in PSNR and
0.08 in SSIM, successfully restoring colors, textures, and contrast in
underwater scenes.

</details>


### [25] [Hierarchical Spatio-temporal Segmentation Network for Ejection Fraction Estimation in Echocardiography Videos](https://arxiv.org/abs/2508.18681)
*Dongfang Wang,Jian Yang,Yizhe Zhang,Tao Zhou*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“分层时空分割网络”（Hierarchical Spatio-temporal Segmentation Network, ourmodel）的新模型，用于心脏超声视频中左心室心内膜的自动分割，旨在提高射血分数（EF）估算的准确性。


<details>
  <summary>Details</summary>
Motivation: 心脏超声视频中左心室心内膜的自动分割是心脏病学的一个关键研究领域，旨在通过估算射血分数（EF）来准确评估心脏结构和功能。现有研究在分割方面表现良好，但在EF估算方面效果不佳。

Method: 提出了一种分层时空分割网络（ourmodel），结合了卷积网络（用于低级阶段处理单帧图像以保留细节）和Mamba架构（用于高级阶段捕捉时空关系）。为克服局部时空限制，提出了时空交叉扫描（STCS）模块，通过跨帧和跨位置的跳跃扫描来整合长程上下文，以减少超声图像噪声等因素造成的EF计算偏差。

Result: 通过结合局部细节建模和全局动态感知，该模型有望提高EF估算的准确性，并克服现有方法在EF估算方面的不足。

Conclusion: 该研究提出的分层时空分割网络（ourmodel）及其STCS模块，通过有效结合局部细节和全局时空信息，能够更好地处理超声视频中的心内膜分割任务，并提高EF估算的准确性，为心脏功能评估提供更可靠的工具。

Abstract: Automated segmentation of the left ventricular endocardium in
echocardiography videos is a key research area in cardiology. It aims to
provide accurate assessment of cardiac structure and function through Ejection
Fraction (EF) estimation. Although existing studies have achieved good
segmentation performance, their results do not perform well in EF estimation.
In this paper, we propose a Hierarchical Spatio-temporal Segmentation Network
(\ourmodel) for echocardiography video, aiming to improve EF estimation
accuracy by synergizing local detail modeling with global dynamic perception.
The network employs a hierarchical design, with low-level stages using
convolutional networks to process single-frame images and preserve details,
while high-level stages utilize the Mamba architecture to capture
spatio-temporal relationships. The hierarchical design balances single-frame
and multi-frame processing, avoiding issues such as local error accumulation
when relying solely on single frames or neglecting details when using only
multi-frame data. To overcome local spatio-temporal limitations, we propose the
Spatio-temporal Cross Scan (STCS) module, which integrates long-range context
through skip scanning across frames and positions. This approach helps mitigate
EF calculation biases caused by ultrasound image noise and other factors.

</details>


### [26] [Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency](https://arxiv.org/abs/2508.18693)
*Zhitong Cheng,Yiran Jiang,Yulong Ge,Yufeng Li,Zhongheng Qin,Rongzhi Lin,Jianwei Ma*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Domain shift, characterized by degraded model performance during transition
from labeled source domains to unlabeled target domains, poses a persistent
challenge for deploying deep learning systems. Current unsupervised domain
adaptation (UDA) methods predominantly rely on fine-tuning feature extractors -
an approach limited by inefficiency, reduced interpretability, and poor
scalability to modern architectures.
  Our analysis reveals that models pretrained on large-scale data exhibit
domain-invariant geometric patterns in their feature space, characterized by
intra-class clustering and inter-class separation, thereby preserving
transferable discriminative structures. These findings indicate that domain
shifts primarily manifest as boundary misalignment rather than feature
degradation.
  Unlike fine-tuning entire pre-trained models - which risks introducing
unpredictable feature distortions - we propose the Feature-space Planes
Searcher (FPS): a novel domain adaptation framework that optimizes decision
boundaries by leveraging these geometric patterns while keeping the feature
encoder frozen. This streamlined approach enables interpretative analysis of
adaptation while substantially reducing memory and computational costs through
offline feature extraction, permitting full-dataset optimization in a single
computation cycle.
  Evaluations on public benchmarks demonstrate that FPS achieves competitive or
superior performance to state-of-the-art methods. FPS scales efficiently with
multimodal large models and shows versatility across diverse domains including
protein structure prediction, remote sensing classification, and earthquake
detection. We anticipate FPS will provide a simple, effective, and
generalizable paradigm for transfer learning, particularly in domain adaptation
tasks. .

</details>


### [27] [A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition](https://arxiv.org/abs/2508.18695)
*Wasi Ullah,Yasir Noman Khalid,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种混合深度学习框架，通过InceptionV3、LSTM和基于集成的特征选择策略来优化人类活动识别（HAR），实现了高精度（99.65%）、显著的特征降维（降至7个）和更快的推理时间，适用于树莓派等边缘设备。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有HAR系统面临的高计算成本、特征冗余和实时性扩展性差的挑战。

Method: 提出一个混合深度学习框架，包含自定义InceptionV3提取空间描述符，LSTM对时间依赖进行建模，以及一种基于集成（遗传算法、ADFSA）的特征选择策略以优化特征集。

Result: 在UCF-YouTube数据集上实现了99.65%的识别准确率，将特征数量减少到7个，并提高了推理速度，能够支持在树莓派等边缘设备上进行实时部署。

Conclusion: 该框架是一种轻量级且可扩展的HAR系统，能够支持在资源受限的边缘设备上进行实时部署，适用于智能监控、辅助技术等实际应用。

Abstract: Human Activity Recognition (HAR) plays a pivotal role in various
applications, including smart surveillance, healthcare, assistive technologies,
sports analytics, etc. However, HAR systems still face critical challenges,
including high computational costs, redundant features, and limited scalability
in real-time scenarios. An optimized hybrid deep learning framework is
introduced that integrates a customized InceptionV3, an LSTM architecture, and
a novel ensemble-based feature selection strategy. The proposed framework first
extracts spatial descriptors using the customized InceptionV3 model, which
captures multilevel contextual patterns, region homogeneity, and fine-grained
localization cues. The temporal dependencies across frames are then modeled
using LSTMs to effectively encode motion dynamics. Finally, an ensemble-based
genetic algorithm with Adaptive Dynamic Fitness Sharing and Attention (ADFSA)
is employed to select a compact and optimized feature set by dynamically
balancing objectives such as accuracy, redundancy, uniqueness, and complexity
reduction. Consequently, the selected feature subsets, which are both diverse
and discriminative, enable various lightweight machine learning classifiers to
achieve accurate and robust HAR in heterogeneous environments. Experimental
results on the robust UCF-YouTube dataset, which presents challenges such as
occlusion, cluttered backgrounds, motion dynamics, and poor illumination,
demonstrate good performance. The proposed approach achieves 99.65% recognition
accuracy, reduces features to as few as 7, and enhances inference time. The
lightweight and scalable nature of the HAR system supports real-time deployment
on edge devices such as Raspberry Pi, enabling practical applications in
intelligent, resource-aware environments, including public safety, assistive
technology, and autonomous monitoring systems.

</details>


### [28] [ColorGS: High-fidelity Surgical Scene Reconstruction with Colored Gaussian Splatting](https://arxiv.org/abs/2508.18696)
*Qun Ji,Peng Li,Mingqiang Wei*

Main category: cs.CV

TL;DR: ColorGS通过空间自适应颜色编码和增强的变形模型，实现了高保真、实时的手术场景重建，优于现有3DGS方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细微颜色变化和模拟全局形变方面存在局限，难以对形变组织进行高保真重建。

Method: 提出ColorGS框架，包括：1. 颜色高斯图元：动态锚点和可学习颜色参数，自适应编码空间纹理。2. 增强变形模型（EDM）：结合时间感知高斯基函数和可学习的独立于时间的形变，精确捕捉局部形变和全局运动一致性。

Result: 在DaVinci机器人手术视频和EndoNeRF、StereoMIS数据集上，ColorGS实现了39.85的PSNR（比先前3DGS方法高1.5）和97.25%的SSIM，同时保持实时渲染效率。

Conclusion: ColorGS在保真度和计算实用性之间取得了平衡，提高了手术场景重建的水平，可用于术中引导和AR/VR应用。

Abstract: High-fidelity reconstruction of deformable tissues from endoscopic videos
remains challenging due to the limitations of existing methods in capturing
subtle color variations and modeling global deformations. While 3D Gaussian
Splatting (3DGS) enables efficient dynamic reconstruction, its fixed
per-Gaussian color assignment struggles with intricate textures, and linear
deformation modeling fails to model consistent global deformation. To address
these issues, we propose ColorGS, a novel framework that integrates spatially
adaptive color encoding and enhanced deformation modeling for surgical scene
reconstruction. First, we introduce Colored Gaussian Primitives, which employ
dynamic anchors with learnable color parameters to adaptively encode spatially
varying textures, significantly improving color expressiveness under complex
lighting and tissue similarity. Second, we design an Enhanced Deformation Model
(EDM) that combines time-aware Gaussian basis functions with learnable
time-independent deformations, enabling precise capture of both localized
tissue deformations and global motion consistency caused by surgical
interactions. Extensive experiments on DaVinci robotic surgery videos and
benchmark datasets (EndoNeRF, StereoMIS) demonstrate that ColorGS achieves
state-of-the-art performance, attaining a PSNR of 39.85 (1.5 higher than prior
3DGS-based methods) and superior SSIM (97.25\%) while maintaining real-time
rendering efficiency. Our work advances surgical scene reconstruction by
balancing high fidelity with computational practicality, critical for
intraoperative guidance and AR/VR applications.

</details>


### [29] [Class-wise Flooding Regularization for Imbalanced Image Classification](https://arxiv.org/abs/2508.18723)
*Hiroaki Aizawa,Yuta Naito,Kohei Fukuda*

Main category: cs.CV

TL;DR: 在不平衡数据集上训练神经网络会导致少数类识别性能下降。本文提出了一种名为“类别级洪水正则化”的新方法，通过为每个类别分配特定于类别的洪水水平来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 不平衡数据集上的模型倾向于多数类，导致少数类识别性能下降。

Method: 提出了一种名为“类别级洪水正则化”的新方法，这是洪水正则化的扩展，在类别级别应用。该方法根据类别频率为每个类别分配特定的洪水水平。

Result: 与传统的洪水正则化相比，该方法提高了少数类的分类性能，并实现了更好的整体泛化。

Conclusion: 类别级洪水正则化通过抑制多数类的过拟合并允许少数类充分学习，从而改善了不平衡数据集上的神经网络泛化性能。

Abstract: The purpose of training neural networks is to achieve high generalization
performance on unseen inputs. However, when trained on imbalanced datasets, a
model's prediction tends to favor majority classes over minority classes,
leading to significant degradation in the recognition performance of minority
classes. To address this issue, we propose class-wise flooding regularization,
an extension of flooding regularization applied at the class level. Flooding is
a regularization technique that mitigates overfitting by preventing the
training loss from falling below a predefined threshold, known as the flooding
level, thereby discouraging memorization. Our proposed method assigns a
class-specific flooding level based on class frequencies. By doing so, it
suppresses overfitting in majority classes while allowing sufficient learning
for minority classes. We validate our approach on imbalanced image
classification. Compared to conventional flooding regularizations, our method
improves the classification performance of minority classes and achieves better
overall generalization.

</details>


### [30] [Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection](https://arxiv.org/abs/2508.18729)
*Melanie Wille,Tobias Fischer,Scarlett Raine*

Main category: cs.CV

TL;DR: 水下鱼类检测中的类别性能差异源于定位和分类中的固有挑战，而非仅仅是数据量问题。提高性能需要关注定位模块的算法改进，并根据具体需求（精度或召回率）调整数据分布。


<details>
  <summary>Details</summary>
Motivation: 解决水下目标检测中存在的类别性能差异问题，并探究其根本原因，同时提出改进方案。

Method: 将DUO数据集分解为定位和分类任务，并利用YOLOv11和TIDE分析扇贝类别的性能瓶颈。通过实验探究数据量、类别不平衡以及内在特征对模型性能的影响。

Result: 发现前景-背景区分是导致性能差异的主要问题，即使在数据量充足且平衡的情况下，分类精度也存在差距。数据量并非影响类别性能差异的唯一因素。

Conclusion: 类别性能差异主要源于定位模块的算法挑战。在实际应用中，应根据是优先考虑精度还是召回率来选择数据分布策略。未来的改进应侧重于定位模块的算法优化。

Abstract: Underwater object detection is critical for monitoring marine ecosystems but
poses unique challenges, including degraded image quality, imbalanced class
distribution, and distinct visual characteristics. Not every species is
detected equally well, yet underlying causes remain unclear. We address two key
research questions: 1) What factors beyond data quantity drive class-specific
performance disparities? 2) How can we systematically improve detection of
under-performing marine species? We manipulate the DUO dataset to separate the
object detection task into localization and classification and investigate the
under-performance of the scallop class. Localization analysis using YOLO11 and
TIDE finds that foreground-background discrimination is the most problematic
stage regardless of data quantity. Classification experiments reveal persistent
precision gaps even with balanced data, indicating intrinsic feature-based
challenges beyond data scarcity and inter-class dependencies. We recommend
imbalanced distributions when prioritizing precision, and balanced
distributions when prioritizing recall. Improving under-performing classes
should focus on algorithmic advances, especially within localization modules.
We publicly release our code and datasets.

</details>


### [31] [Flatness-aware Curriculum Learning via Adversarial Difficulty](https://arxiv.org/abs/2508.18726)
*Hiroaki Aizawa,Yoshikazu Hayashi*

Main category: cs.CV

TL;DR: 神经网路训练中的过拟合问题可以通过课程学习（CL）和锐度感知最小化（SAM）等方法来缓解。然而，将CL与SAM结合具有挑战性，因为在平坦的最小值区域，难以衡量样本难度。本文提出了一种对抗性难度度量（ADM）的方法，通过衡量原始样本和对抗性样本之间的损失差异来量化模型的对抗性脆弱性。ADM可以克服现有基于损失或梯度的方法在平坦区域失效的问题。实验结果表明，该方法结合了CL和SAM的优点，并在图像分类、细粒度识别和域泛化任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 神经网路在经验风险最小化下训练时，容易出现过拟合，导致泛化能力差。课程学习（CL）通过选择训练样本的难度来解决这个问题。锐度感知最小化（SAM）等方法通过寻找平坦的最小值来提高鲁棒性和泛化能力。然而，将CL与SAM结合并非易事，因为在平坦区域，损失值和梯度范数趋于一致地减小，使得衡量样本难度和设计有效的课程变得困难。

Method: 提出了一种对抗性难度度量（ADM），该度量利用朝向平坦最小值训练的模型的鲁棒性特征来量化对抗性脆弱性。ADM通过衡量原始样本和对抗性样本之间的归一化损失差异来量化样本难度，克服了现有基于损失或梯度的方法在平坦区域失效的问题。将ADM整合到基于CL的SAM训练中，以动态评估样本难度。

Result: 在图像分类、细粒度识别和域泛化任务上的评估结果表明，该方法在保留CL和SAM优点的同时，其性能优于现有的基于课程学习和锐度感知的训练策略。

Conclusion: 该研究提出了一种名为ADM的新方法，能够有效结合课程学习（CL）和锐度感知最小化（SAM），解决了在平坦最小值区域衡量样本难度的问题，并在多项视觉任务上取得了优于现有方法的性能。

Abstract: Neural networks trained by empirical risk minimization often suffer from
overfitting, especially to specific samples or domains, which leads to poor
generalization. Curriculum Learning (CL) addresses this issue by selecting
training samples based on the difficulty. From the optimization perspective,
methods such as Sharpness-Aware Minimization (SAM) improve robustness and
generalization by seeking flat minima. However, combining CL with SAM is not
straightforward. In flat regions, both the loss values and the gradient norms
tend to become uniformly small, which makes it difficult to evaluate sample
difficulty and design an effective curriculum. To overcome this problem, we
propose the Adversarial Difficulty Measure (ADM), which quantifies adversarial
vulnerability by leveraging the robustness properties of models trained toward
flat minima. Unlike loss- or gradient-based measures, which become ineffective
as training progresses into flatter regions, ADM remains informative by
measuring the normalized loss gap between original and adversarial examples. We
incorporate ADM into CL-based training with SAM to dynamically assess sample
difficulty. We evaluated our approach on image classification tasks,
fine-grained recognition, and domain generalization. The results demonstrate
that our method preserves the strengths of both CL and SAM while outperforming
existing curriculum-based and flatness-aware training strategies.

</details>


### [32] [PseudoMapTrainer: Learning Online Mapping without HD Maps](https://arxiv.org/abs/2508.18788)
*Christian Löwens,Thorben Funke,Jingchao Xie,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: 提出了一种名为PseudoMapTrainer的新方法，用于从无标签的传感器数据中生成伪标签，以训练在线地图绘制模型，无需任何真实标签的高精度地图。


<details>
  <summary>Details</summary>
Motivation: 现有的在线地图绘制模型依赖于昂贵且泛化能力有限的高精度地图。本研究旨在开发一种无需真实地图即可训练在线地图绘制模型的方法。

Method: 该方法通过高斯泼溅（Gaussian splatting）和预训练的2D分割网络生成伪标签，并引入掩码感知分配算法和损失函数来处理部分掩码的伪标签。

Result: 首次实现了在没有任何真实地图的情况下训练在线地图绘制模型，并且伪标签可用于半监督预训练，以利用大规模无标签众包数据。

Conclusion: PseudoMapTrainer能够有效地利用无标签数据训练在线地图绘制模型，克服了对昂贵真实地图的依赖，提高了模型的泛化能力。

Abstract: Online mapping models show remarkable results in predicting vectorized maps
from multi-view camera images only. However, all existing approaches still rely
on ground-truth high-definition maps during training, which are expensive to
obtain and often not geographically diverse enough for reliable generalization.
In this work, we propose PseudoMapTrainer, a novel approach to online mapping
that uses pseudo-labels generated from unlabeled sensor data. We derive those
pseudo-labels by reconstructing the road surface from multi-camera imagery
using Gaussian splatting and semantics of a pre-trained 2D segmentation
network. In addition, we introduce a mask-aware assignment algorithm and loss
function to handle partially masked pseudo-labels, allowing for the first time
the training of online mapping models without any ground-truth maps.
Furthermore, our pseudo-labels can be effectively used to pre-train an online
model in a semi-supervised manner to leverage large-scale unlabeled
crowdsourced data. The code is available at
github.com/boschresearch/PseudoMapTrainer.

</details>


### [33] [Interpretable Decision-Making for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.18898)
*Mona Mirzaie,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: 该论文提出了一种在自动驾驶中增强可解释性的方法，通过生成稀疏、局部化的特征图来解释AI的决策，并在CARLA基准测试中取得了优于现有方法的性能，同时降低了违规行为。


<details>
  <summary>Details</summary>
Motivation: 为了在自动驾驶汽车中广泛部署，AI必须是可信赖的。然而，尽管端到端方法可以直接从原始数据中获得控制指令，但解释这些决策仍然很困难，尤其是在复杂的城市环境中，这主要是由于深度神经网络具有非线性决策边界。

Method: 提出了一种通过生成稀疏和局部化特征图来增强模型可解释性的损失函数，从而能够解释哪些图像区域对预测的控制指令有贡献。

Result: 所提出的方法提高了可解释性，这与减少违规行为相关，从而产生了一个更安全、高性能的驾驶模型。在CARLA基准测试中，该方法在不使用集成模型的情况下，通过实现更低的违规分数和最高 ancak路线完成率，超越了CARLA排行榜上的顶级方法。

Conclusion: 该方法提高了自动驾驶的可解释性，并取得了优越的性能，在减少违规和提高路线完成率方面均有显著提升。

Abstract: Trustworthy AI is mandatory for the broad deployment of autonomous vehicles.
Although end-to-end approaches derive control commands directly from raw data,
interpreting these decisions remains challenging, especially in complex urban
scenarios. This is mainly attributed to very deep neural networks with
non-linear decision boundaries, making it challenging to grasp the logic behind
AI-driven decisions. This paper presents a method to enhance interpretability
while optimizing control commands in autonomous driving. To address this, we
propose loss functions that promote the interpretability of our model by
generating sparse and localized feature maps. The feature activations allow us
to explain which image regions contribute to the predicted control command. We
conduct comprehensive ablation studies on the feature extraction step and
validate our method on the CARLA benchmarks. We also demonstrate that our
approach improves interpretability, which correlates with reducing infractions,
yielding a safer, high-performance driving model. Notably, our monocular,
non-ensemble model surpasses the top-performing approaches from the CARLA
Leaderboard by achieving lower infraction scores and the highest route
completion rate, all while ensuring interpretability.

</details>


### [34] [Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vectorized Drawings](https://arxiv.org/abs/2508.18733)
*Feiwei Qin,Shichao Lu,Junhao Hou,Changmiao Wang,Meie Fang,Ligang Liu*

Main category: cs.CV

TL;DR: 本篇论文提出了一种从2D工程图生成参数化CAD模型的新方法，将CAD生成视为序列到序列的学习问题，并提出了Drawing2CAD框架。


<details>
  <summary>Details</summary>
Motivation: 目前大多数CAD生成方法与传统的工业工作流程不符，而从2D工程图自动生成参数化CAD模型的研究尚不充分，这是一个关键的工程设计步骤。

Method: 提出Drawing2CAD框架，将CAD生成视为序列到序列学习问题。关键技术包括：1. 网络友好的向量图元表示，保留精确的几何信息。2. 双解码器Transformer架构，解耦命令类型和参数生成，保持精确对应关系。3. 软目标分布损失函数，适应CAD参数的固有灵活性。

Result: 创建了一个包含工程图和参数化CAD模型配对的CAD-VGDrawing数据集，并通过实验证明了Drawing2CAD的有效性。

Conclusion: Drawing2CAD框架能够有效地从2D工程图生成参数化CAD模型，保留了几何精度和设计意图，解决了现有方法的不足。

Abstract: Computer-Aided Design (CAD) generative modeling is driving significant
innovations across industrial applications. Recent works have shown remarkable
progress in creating solid models from various inputs such as point clouds,
meshes, and text descriptions. However, these methods fundamentally diverge
from traditional industrial workflows that begin with 2D engineering drawings.
The automatic generation of parametric CAD models from these 2D vector drawings
remains underexplored despite being a critical step in engineering design. To
address this gap, our key insight is to reframe CAD generation as a
sequence-to-sequence learning problem where vector drawing primitives directly
inform the generation of parametric CAD operations, preserving geometric
precision and design intent throughout the transformation process. We propose
Drawing2CAD, a framework with three key technical components: a
network-friendly vector primitive representation that preserves precise
geometric information, a dual-decoder transformer architecture that decouples
command type and parameter generation while maintaining precise correspondence,
and a soft target distribution loss function accommodating inherent flexibility
in CAD parameters. To train and evaluate Drawing2CAD, we create CAD-VGDrawing,
a dataset of paired engineering drawings and parametric CAD models, and conduct
thorough experiments to demonstrate the effectiveness of our method. Code and
dataset are available at https://github.com/lllssc/Drawing2CAD.

</details>


### [35] [VibES: Induced Vibration for Persistent Event-Based Sensing](https://arxiv.org/abs/2508.19094)
*Vincenzo Polizzi,Stephen Yang,Quentin Clark,Jonathan Kelly,Igor Gilitschenski,David B. Lindell*

Main category: cs.CV

TL;DR: 事件相机在静态或低运动场景下无法生成事件，本文提出一种通过旋转不平衡质量体诱导振动的方法来持续生成事件，并结合运动补偿管线去除诱导的运动，以获得清洁、运动补偿的事件用于下游感知任务。


<details>
  <summary>Details</summary>
Motivation: 事件相机在静态或低运动场景下无法生成事件，限制了其应用。以往的方法需要复杂的硬件或额外的光学元件来解决此问题。

Method: 提出一种轻量级的方法，通过使用一个简单的旋转不平衡质量体来诱导周期性振动，从而持续生成事件。并结合一个运动补偿管线来去除诱导的运动，得到清晰的、运动补偿的事件。

Result: 通过硬件原型展示了该方法，并在真实数据集上进行了评估。结果表明，该方法可靠地恢复了运动参数，并且在图像重建和边缘检测方面优于不诱导运动的事件传感方法。

Conclusion: 所提出的方法能够有效解决事件相机在静态或低运动场景下的局限性，并通过运动补偿技术提高了感知任务的性能。

Abstract: Event cameras are a bio-inspired class of sensors that asynchronously measure
per-pixel intensity changes. Under fixed illumination conditions in static or
low-motion scenes, rigidly mounted event cameras are unable to generate any
events, becoming unsuitable for most computer vision tasks. To address this
limitation, recent work has investigated motion-induced event stimulation that
often requires complex hardware or additional optical components. In contrast,
we introduce a lightweight approach to sustain persistent event generation by
employing a simple rotating unbalanced mass to induce periodic vibrational
motion. This is combined with a motion-compensation pipeline that removes the
injected motion and yields clean, motion-corrected events for downstream
perception tasks. We demonstrate our approach with a hardware prototype and
evaluate it on real-world captured datasets. Our method reliably recovers
motion parameters and improves both image reconstruction and edge detection
over event-based sensing without motion induction.

</details>


### [36] [Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods](https://arxiv.org/abs/2508.18753)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: 大型视觉语言模型（VLMs）能否独立解决人-物交互（HOI）检测任务，以及它们与专门HOI方法的比较，需要一个新的基准来解决现有HOI基准与VLMs的生成特性不匹配的问题。通过将HOI检测重新定义为多选题任务，可以避免因模糊性而对有效预测进行处罚，从而为VLMs和HOI方法提供一个公平的比较平台。


<details>
  <summary>Details</summary>
Motivation: 现有HOI检测方法虽然集成了早期视觉语言模型（VLMs），但VLMs的能力尚未得到充分利用。大型、生成式VLMs的出现引发了一个问题：通用型独立VLMs能否有效解决HOI检测问题，并且与专门的HOI方法相比表现如何？现有基准（如HICO-DET）的评估协议（需要精确匹配）与VLMs的生成特性不兼容，可能导致对有效预测的错误惩罚。

Method: 提出一个新的基准，将HOI检测重新表述为一种多项选择题任务。每个问题包含正确的答案选项和经过精心挑选的、旨在减少歧义的否定选项。这种方法旨在避免因模糊性而惩罚有效的预测。

Result: 该方法能够为VLMs和HOI方法提供一个公平的比较平台，有助于深入了解当前HOI理解的进展情况。通过新的评估协议，可以更准确地评估不同HOI检测方法的性能，特别是VLMs在HOI任务上的潜力。

Conclusion: 新的基准和评估协议能够解决现有HOI基准与VLMs的生成特性不匹配的问题，为VLMs和HOI专用方法提供了一个直接比较的平台，并为HOI理解的研究提供了新的见解。

Abstract: Prior human-object interaction (HOI) detection methods have integrated early
vision-language models (VLMs) such as CLIP, but only as supporting components
within their frameworks. In contrast, recent advances in large, generative VLMs
suggest that these models may already possess strong ability to understand
images involving HOI. This naturally raises an important question: can
general-purpose standalone VLMs effectively solve HOI detection, and how do
they compare with specialized HOI methods? Answering this requires a benchmark
that can accommodate both paradigms. However, existing HOI benchmarks such as
HICO-DET were developed before the emergence of modern VLMs, and their
evaluation protocols require exact matches to annotated HOI classes. This is
poorly aligned with the generative nature of VLMs, which often yield multiple
valid interpretations in ambiguous cases. For example, a static image may
capture a person mid-motion with a frisbee, which can plausibly be interpreted
as either "throwing" or "catching". When only "catching" is annotated, the
other, though equally plausible for the image, is marked incorrect when exact
matching is used. As a result, correct predictions might be penalized,
affecting both VLMs and HOI-specific methods. To avoid penalizing valid
predictions, we introduce a new benchmark that reformulates HOI detection as a
multiple-answer multiple-choice task, where each question includes only
ground-truth positive options and a curated set of negatives that are
constructed to reduce ambiguity (e.g., when "catching" is annotated, "throwing"
is not selected as a negative to avoid penalizing valid predictions). The
proposed evaluation protocol is the first of its kind for both VLMs and HOI
methods, enabling direct comparison and offering new insight into the current
state of progress in HOI understanding.

</details>


### [37] [Beyond the Textual: Generating Coherent Visual Options for MCQs](https://arxiv.org/abs/2508.18772)
*Wanqiang Wang,Longzhu He,Wei Zheng*

Main category: cs.CV

TL;DR: 本研究提出了一种名为CmOS的新框架，用于生成包含视觉选项的多项选择题（MCQ），解决了以往MCQ生成主要关注文本选项且难以生成高质量干扰项的问题。CmOS结合了多模态思维链（MCoT）推理和检索增强生成（RAG）技术，以生成语义合理且视觉上相似的答案和干扰项，并包含一个用于识别适合视觉选项的内容的鉴别模块。实验结果表明，CmOS在内容鉴别、问题生成和视觉选项生成方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的多项选择题（MCQ）生成研究主要集中在文本选项，忽视了视觉选项，并且手动创建高质量干扰项成本高昂且难以扩展。本研究旨在解决这些问题，开发一种能够生成包含视觉选项的MCQ的框架，并克服生成高质量干扰项的挑战。

Method: 本研究提出的CmOS框架集成了多模态思维链（MCoT）推理和检索增强生成（RAG）技术，以生成语义上合理且视觉上相似的答案和干扰项。此外，框架还包含一个鉴别模块，用于识别适合生成视觉选项的内容。

Result: 在多个学科和教育水平的测试任务上进行的实验结果表明，与现有方法相比，CmOS在内容鉴别、问题生成和视觉选项生成方面表现出优越性。

Conclusion: CmOS框架成功地生成了包含视觉选项的MCQ，并在内容鉴别、问题生成和视觉选项生成方面优于现有方法，为教育领域的多模态MCQ生成提供了一种有效解决方案。

Abstract: Multiple-choice questions (MCQs) play a crucial role in fostering deep
thinking and knowledge integration in education. However, previous research has
primarily focused on generating MCQs with textual options, but it largely
overlooks the visual options. Moreover, generating high-quality distractors
remains a major challenge due to the high cost and limited scalability of
manual authoring. To tackle these problems, we propose a Cross-modal Options
Synthesis (CmOS), a novel framework for generating educational MCQs with visual
options. Our framework integrates Multimodal Chain-of-Thought (MCoT) reasoning
process and Retrieval-Augmented Generation (RAG) to produce semantically
plausible and visually similar answer and distractors. It also includes a
discrimination module to identify content suitable for visual options.
Experimental results on test tasks demonstrate the superiority of CmOS in
content discrimination, question generation and visual option generation over
existing methods across various subjects and educational levels.

</details>


### [38] [Design, Implementation and Evaluation of a Real-Time Remote Photoplethysmography (rPPG) Acquisition System for Non-Invasive Vital Sign Monitoring](https://arxiv.org/abs/2508.18787)
*Constantino Álvarez Casado,Sasan Sharifipour,Manuel Lage Cañellas,Nhi Nguyen,Le Nguyen,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 该论文提出了一种针对低功耗设备的实时远程光电容积脉搏波图(rPPG)系统，可在资源受限的平台上实现对心率(HR)、呼吸率(RR)和血氧饱和度(SpO2)等生理信号的提取，解决了可扩展性、互操作性和性能方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着智能环境和低功耗计算设备的集成以及大众化传感器技术的发展，远程和非接触式生理监测取得了进展。然而，在资源受限的平台上实时部署这些系统在可扩展性、互操作性和性能方面面临重大挑战。

Method: 该系统基于Face2PPG管道，通过多线程架构顺序处理视频帧以提取rPPG信号并进行分析，同时管理视频捕获、实时处理、网络通信和图形用户界面(GUI)更新。它采用函数响应式编程(FRP)和Actor模型混合编程模型，以实现事件驱动处理和高效的任务并行化。

Result: 该系统能够在30fps下实现持续可靠的运行，并通过协作用户界面提供自适应反馈以指导最佳信号捕获条件。网络接口包括一个用于连续视频流的HTTP服务器和一个用于按需生命体征检索的RESTful API。该系统在实时约束下进行了评估，证明了其稳健性并最大限度地减少了计算开销。

Conclusion: 该研究解决了实时生物信号监测的关键挑战，为优化现代医疗保健和人机交互应用中的性能提供了实用的解决方案。

Abstract: The growing integration of smart environments and low-power computing
devices, coupled with mass-market sensor technologies, is driving advancements
in remote and non-contact physiological monitoring. However, deploying these
systems in real-time on resource-constrained platforms introduces significant
challenges related to scalability, interoperability, and performance. This
paper presents a real-time remote photoplethysmography (rPPG) system optimized
for low-power devices, designed to extract physiological signals, such as heart
rate (HR), respiratory rate (RR), and oxygen saturation (SpO2), from facial
video streams. The system is built on the Face2PPG pipeline, which processes
video frames sequentially for rPPG signal extraction and analysis, while
leveraging a multithreaded architecture to manage video capture, real-time
processing, network communication, and graphical user interface (GUI) updates
concurrently. This design ensures continuous, reliable operation at 30 frames
per second (fps), with adaptive feedback through a collaborative user interface
to guide optimal signal capture conditions. The network interface includes both
an HTTP server for continuous video streaming and a RESTful API for on-demand
vital sign retrieval. To ensure accurate performance despite the limitations of
low-power devices, we use a hybrid programming model combining Functional
Reactive Programming (FRP) and the Actor Model, allowing event-driven
processing and efficient task parallelization. The system is evaluated under
real-time constraints, demonstrating robustness while minimizing computational
overhead. Our work addresses key challenges in real-time biosignal monitoring,
offering practical solutions for optimizing performance in modern healthcare
and human-computer interaction applications.

</details>


### [39] [Robust and Label-Efficient Deep Waste Detection](https://arxiv.org/abs/2508.18799)
*Hassan Abid,Khan Muhammad,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 本文提出了一种结合大语言模型（LLM）优化的提示和基于集成学习的半监督学习框架，以提高垃圾检测的准确性，并建立了新的基线，其性能优于完全监督的训练。


<details>
  <summary>Details</summary>
Motivation: 目前的AI垃圾检测研究受限于数据集和传统的对象检测器，未能跟上商业系统的发展。本研究旨在通过建立强大的基线并引入新的半监督学习框架来推动AI垃圾检测技术的发展。

Method: 首先，在ZeroWaste数据集上对现有的开放词汇对象检测（OVOD）模型进行基准测试，并证明LLM优化的提示可以显著提高零样本准确性。然后，通过对现代Transformer检测器进行微调，建立了51.6 mAP的新基线。最后，提出了一种软伪标签策略，通过空间和共识感知加权融合集成预测，实现鲁棒的半监督训练。

Result: 本研究在ZeroWaste数据集上取得了显著成果，LLM优化的提示提升了零样本准确性，微调后的Transformer检测器达到了51.6 mAP的新基线。此外，所提出的半监督学习方法在未标记数据上实现了优于完全监督训练的性能。

Conclusion: 本研究通过建立严格的基线、提出鲁棒的伪标签流水线、生成高质量的标注以及在真实垃圾分拣条件下系统地评估OVOD模型，为AI垃圾检测领域做出了贡献。

Abstract: Effective waste sorting is critical for sustainable recycling, yet AI
research in this domain continues to lag behind commercial systems due to
limited datasets and reliance on legacy object detectors. In this work, we
advance AI-driven waste detection by establishing strong baselines and
introducing an ensemble-based semi-supervised learning framework. We first
benchmark state-of-the-art Open-Vocabulary Object Detection (OVOD) models on
the real-world ZeroWaste dataset, demonstrating that while class-only prompts
perform poorly, LLM-optimized prompts significantly enhance zero-shot accuracy.
Next, to address domain-specific limitations, we fine-tune modern
transformer-based detectors, achieving a new baseline of 51.6 mAP. We then
propose a soft pseudo-labeling strategy that fuses ensemble predictions using
spatial and consensus-aware weighting, enabling robust semi-supervised
training. Applied to the unlabeled ZeroWaste-s subset, our pseudo-annotations
achieve performance gains that surpass fully supervised training, underscoring
the effectiveness of scalable annotation pipelines. Our work contributes to the
research community by establishing rigorous baselines, introducing a robust
ensemble-based pseudo-labeling pipeline, generating high-quality annotations
for the unlabeled ZeroWaste-s subset, and systematically evaluating OVOD models
under real-world waste sorting conditions. Our code is available at:
https://github.com/h-abid97/robust-waste-detection.

</details>


### [40] [Embedding Font Impression Word Tags Based on Co-occurrence](https://arxiv.org/abs/2508.18825)
*Yugo Kubota,Seiichi Uchida*

Main category: cs.CV

TL;DR: 字体形状和描绘字体印象的词语标签之间存在紧密关系。本研究提出了一种利用字体形状-印象关系的新型印象标签嵌入方法，该方法将频繁共同出现的印象标签映射到相似的向量空间，这对于基于印象的字体生成和检索非常有用。通过构建一个包含印象标签节点和共同出现关系边的数据图，并应用谱嵌入技术获得印象向量，该方法在印象引导的字体生成方面优于BERT和CLIP等标准方法。


<details>
  <summary>Details</summary>
Motivation: 字体形状和描述这些形状的词语标签之间存在关联，这表明字体形状和字体给人的印象之间存在紧密联系。

Method: 构建一个以印象标签为节点、共同出现关系为边的图，然后应用谱嵌入技术获得每个标签的印象向量。

Result: 在定性和定量评估中，本研究提出的方法在印象引导的字体生成方面优于BERT和CLIP等标准方法。

Conclusion: 本研究提出的新型印象标签嵌入方法能够有效捕捉字体形状和印象之间的关系，并在印象引导的字体生成任务中取得了更好的效果。

Abstract: Different font styles (i.e., font shapes) convey distinct impressions,
indicating a close relationship between font shapes and word tags describing
those impressions. This paper proposes a novel embedding method for impression
tags that leverages these shape-impression relationships. For instance, our
method assigns similar vectors to impression tags that frequently co-occur in
order to represent impressions of fonts, whereas standard word embedding
methods (e.g., BERT and CLIP) yield very different vectors. This property is
particularly useful for impression-based font generation and font retrieval.
Technically, we construct a graph whose nodes represent impression tags and
whose edges encode co-occurrence relationships. Then, we apply spectral
embedding to obtain the impression vectors for each tag. We compare our method
with BERT and CLIP in qualitative and quantitative evaluations, demonstrating
that our approach performs better in impression-guided font generation.

</details>


### [41] [Deep Pre-trained Time Series Features for Tree Species Classification in the Dutch Forest Inventory](https://arxiv.org/abs/2508.18829)
*Takayuki Ishikawa,Carmelo Bonannella,Bas J. W. Lerink,Marc Rußwurm*

Main category: cs.CV

TL;DR: 利用深度特征和预训练的遥感基础模型改进荷兰森林国家清查（NFI）的树种分类，精度提升高达10%。


<details>
  <summary>Details</summary>
Motivation: 国家森林清单（NFI）虽然提供关键的树种分布数据，但实地调查耗时耗力。遥感和机器学习，特别是卫星图像时间序列，是更有效的方法。然而，现有方法多依赖手工设计的特征和物候指标，而基于预训练遥感基础模型的深度特征是一种有潜力的补充策略。

Method: 从 Google Earth Engine 提取 Sentinel-1、Sentinel-2、ERA5 和 SRTM 卫星数据的时间序列，并利用预训练的遥感时间序列基础模型进行微调，以研究深度特征如何提高树种分类精度。

Result: 与当前荷兰NFI分类的最先进方法相比，微调后的预训练模型在所有数据集上将分类精度提高了高达10%，证明了深度AI特征在数据有限的应用（如NFI分类）中的潜力。

Conclusion: 深度特征，特别是通过微调预训练的遥感基础模型，能够显著提高数据受限的NFI树种分类精度，优于传统依赖手工特征的方法，为森林清单的更新提供了更有效、可扩展的解决方案。

Abstract: National Forest Inventory (NFI)s serve as the primary source of forest
information, providing crucial tree species distribution data. However,
maintaining these inventories requires labor-intensive on-site campaigns.
Remote sensing approaches, particularly when combined with machine learning,
offer opportunities to update NFIs more frequently and at larger scales. While
the use of Satellite Image Time Series has proven effective for distinguishing
tree species through seasonal canopy reflectance patterns, current approaches
rely primarily on Random Forest classifiers with hand-designed features and
phenology-based metrics. Using deep features from an available pre-trained
remote sensing foundation models offers a complementary strategy. These
pre-trained models leverage unannotated global data and are meant to used for
general-purpose applications and can then be efficiently fine-tuned with
smaller labeled datasets for specific classification tasks. This work
systematically investigates how deep features improve tree species
classification accuracy in the Netherlands with few annotated data. Data-wise,
we extracted time-series data from Sentinel-1, Sentinel-2 and ERA5 satellites
data and SRTM data using Google Earth Engine. Our results demonstrate that
fine-tuning a publicly available remote sensing time series foundation model
outperforms the current state-of-the-art in NFI classification in the
Netherlands by a large margin of up to 10% across all datasets. This
demonstrates that classic hand-defined harmonic features are too simple for
this task and highlights the potential of using deep AI features for
data-limited application like NFI classification. By leveraging openly
available satellite data and pre-trained models, this approach significantly
improves classification accuracy compared to traditional methods and can
effectively complement existing forest inventory processes.

</details>


### [42] [Automated Classification of Normal and Atypical Mitotic Figures Using ConvNeXt V2: MIDOG 2025 Track 2](https://arxiv.org/abs/2508.18831)
*Yosuke Yamagishi,Shouhei Hanaoka*

Main category: cs.CV

TL;DR: 本研究提出了一种基于ConvNeXt V2模型的二分类方法，用于区分非典型性分裂像（AMFs）和正常分裂像（NMFs），以解决类别不平衡、形态变异大和域异构性等挑战。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决MIDOG 2025挑战赛第二赛道中，在组织病理图像中区分正常分裂像（NMFs）和非典型性分裂像（AMFs）的二分类问题，应对类别严重不平衡、形态高度变异以及不同肿瘤类型、物种和扫描仪造成的域异构性等关键挑战。

Method: 本研究采用了ConvNeXt V2作为基础模型，并结合了中心裁剪预处理和5倍交叉验证集成策略。通过60%的中心裁剪进行预处理，并采用混合精度训练来优化模型性能。

Result: 该方法在MIDOG 2025数据集上取得了稳健的表现，证明了现代卷积神经网络在分裂像亚型分类方面的有效性，同时通过精心的模型选择和训练优化保持了计算效率。

Conclusion: ConvNeXt V2模型结合中心裁剪预处理和交叉验证集成策略，能够有效应对组织病理图像中分裂像分类的挑战，并在处理类别不平衡、形态变异和域异构性方面表现出鲁棒性。

Abstract: This paper presents our solution for the MIDOG 2025 Challenge Track 2, which
focuses on binary classification of normal mitotic figures (NMFs) versus
atypical mitotic figures (AMFs) in histopathological images. Our approach
leverages a ConvNeXt V2 base model with center cropping preprocessing and
5-fold cross-validation ensemble strategy. The method addresses key challenges
including severe class imbalance, high morphological variability, and domain
heterogeneity across different tumor types, species, and scanners. Through
strategic preprocessing with 60% center cropping and mixed precision training,
our model achieved robust performance on the diverse MIDOG 2025 dataset. The
solution demonstrates the effectiveness of modern convolutional architectures
for mitotic figure subtyping while maintaining computational efficiency through
careful architectural choices and training optimizations.

</details>


### [43] [Boosting Micro-Expression Analysis via Prior-Guided Video-Level Regression](https://arxiv.org/abs/2508.18834)
*Zizheng Guo,Bochao Zou,Yinuo Jia,Xiangyu Li,Huimin Ma*

Main category: cs.CV

TL;DR: 本论文提出了一种先验引导的视频级回归方法，用于微表情（MEs）分析，通过可扩展的区间选择策略和协同优化框架，提高了MEs时空动态捕捉的精度和效率，并在多个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有微表情分析方法在捕捉其复杂的时间动态方面存在局限性，例如依赖固定窗口大小和手动预定义的区间解码方法。

Method: 提出一种先验引导的视频级回归方法，包括可扩展的区间选择策略（考虑时间演化、持续时间和类别分布特征）和协同优化框架（ spotting 和识别任务共享参数）。

Result: 在CAS(ME)$^3$数据集上达到0.0562的STRS，在SAMMLV数据集上达到0.2000的STRS，达到了最先进的性能。

Conclusion: 提出的方法通过精确的区间识别和参数共享的优化框架，有效提升了微表情分析的性能，克服了现有方法的局限性。

Abstract: Micro-expressions (MEs) are involuntary, low-intensity, and short-duration
facial expressions that often reveal an individual's genuine thoughts and
emotions. Most existing ME analysis methods rely on window-level classification
with fixed window sizes and hard decisions, which limits their ability to
capture the complex temporal dynamics of MEs. Although recent approaches have
adopted video-level regression frameworks to address some of these challenges,
interval decoding still depends on manually predefined, window-based methods,
leaving the issue only partially mitigated. In this paper, we propose a
prior-guided video-level regression method for ME analysis. We introduce a
scalable interval selection strategy that comprehensively considers the
temporal evolution, duration, and class distribution characteristics of MEs,
enabling precise spotting of the onset, apex, and offset phases. In addition,
we introduce a synergistic optimization framework, in which the spotting and
recognition tasks share parameters except for the classification heads. This
fully exploits complementary information, makes more efficient use of limited
data, and enhances the model's capability. Extensive experiments on multiple
benchmark datasets demonstrate the state-of-the-art performance of our method,
with an STRS of 0.0562 on CAS(ME)$^3$ and 0.2000 on SAMMLV. The code is
available at https://github.com/zizheng-guo/BoostingVRME.

</details>


### [44] [Quantitative Outcome-Oriented Assessment of Microsurgical Anastomosis](https://arxiv.org/abs/2508.18836)
*Luyin Hu,Soheil Gholami,George Dindelegan,Torstein R. Meling,Aude Billard*

Main category: cs.CV

TL;DR: 该研究提出了一种基于图像处理技术的量化框架，用于客观评估显微外科吻合术的技能水平，以克服现有评估方法依赖主观判断的不足。


<details>
  <summary>Details</summary>
Motivation: 目前的显微外科吻合术评估方法（如结果导向的吻合失误指数）依赖主观判断，可能引入偏差，影响评估的可靠性和效率。因此，需要一种更客观、更可靠的评估方法来提高培训协议的水平。

Method: 该研究引入了一个量化框架，利用图像处理技术，结合几何建模和检测评分机制，对显微外科吻合术进行客观评估。

Result: 研究结果表明，所提出的几何指标能够有效复制专家评分者对所考虑错误的评分。

Conclusion: 该量化框架通过提供更高效、更可靠的显微外科熟练度评估方法，能够改进培训协议。

Abstract: Microsurgical anastomosis demands exceptional dexterity and visuospatial
skills, underscoring the importance of comprehensive training and precise
outcome assessment. Currently, methods such as the outcome-oriented anastomosis
lapse index are used to evaluate this procedure. However, they often rely on
subjective judgment, which can introduce biases that affect the reliability and
efficiency of the assessment of competence. Leveraging three datasets from
hospitals with participants at various levels, we introduce a quantitative
framework that uses image-processing techniques for objective assessment of
microsurgical anastomoses. The approach uses geometric modeling of errors along
with a detection and scoring mechanism, enhancing the efficiency and
reliability of microsurgical proficiency assessment and advancing training
protocols. The results show that the geometric metrics effectively replicate
expert raters' scoring for the errors considered in this work.

</details>


### [45] [Harnessing Meta-Learning for Controllable Full-Frame Video Stabilization](https://arxiv.org/abs/2508.18859)
*Muhammad Kashif Ali,Eun Woo Im,Dongjin Kim,Tae Hyun Kim,Vivek Gupta,Haonan Luo,Tianrui Li*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的视频稳定方法，通过在测试时快速适应模型来改进像素级合成视频稳定技术，利用低级视觉线索提升稳定性和视觉质量。研究还引入了急动定位模块和定向适应策略，专注于高急动片段以最少的适应步骤实现最大的稳定性。


<details>
  <summary>Details</summary>
Motivation: 视频稳定，特别是像素级合成解决方案，由于视频序列中运动特征和视觉内容的固有多样性，难以用固定参数实现鲁棒的泛化。

Method: 提出了一种新颖的测试时快速适应模型的方法，利用低级视觉线索；引入了急动定位模块和定向适应策略，专注于高急动片段。

Result: 该方法在各种全帧合成模型上实现了显著的性能提升，包括定性和定量方面，并且在下游应用中也表现出色。

Conclusion: 该方法能够克服现有技术（SOTA）方法的局限性，同时保持现代方法的全帧特性，并提供类似经典方法的控制机制。

Abstract: Video stabilization remains a fundamental problem in computer vision,
particularly pixel-level synthesis solutions for video stabilization, which
synthesize full-frame outputs, add to the complexity of this task. These
methods aim to enhance stability while synthesizing full-frame videos, but the
inherent diversity in motion profiles and visual content present in each video
sequence makes robust generalization with fixed parameters difficult. To
address this, we present a novel method that improves pixel-level synthesis
video stabilization methods by rapidly adapting models to each input video at
test time. The proposed approach takes advantage of low-level visual cues
available during inference to improve both the stability and visual quality of
the output. Notably, the proposed rapid adaptation achieves significant
performance gains even with a single adaptation pass. We further propose a jerk
localization module and a targeted adaptation strategy, which focuses the
adaptation on high-jerk segments for maximizing stability with fewer adaptation
steps. The proposed methodology enables modern stabilizers to overcome the
longstanding SOTA approaches while maintaining the full frame nature of the
modern methods, while offering users with control mechanisms akin to classical
approaches. Extensive experiments on diverse real-world datasets demonstrate
the versatility of the proposed method. Our approach consistently improves the
performance of various full-frame synthesis models in both qualitative and
quantitative terms, including results on downstream applications.

</details>


### [46] [Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2508.18886)
*Yuexuan Xia,Benteng Ma,Jiang He,Zhiyong Wang,Qi Dou,Yong Xia*

Main category: cs.CV

TL;DR: DualFairVL是一个多模态提示学习框架，用于在医学诊断中实现跨人群公平性，它通过联合去偏和对齐跨模态表示来解决现有方法的局限性，并在八个医学成像数据集上取得了最先进的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 确保医学诊断中跨人群的公平性对于实现公平的医疗保健至关重要，特别是在成像设备和临床实践的差异导致分布变化的情况下。现有的去偏方法通常独立处理视觉和文本模态，导致跨模态失准和公平性差距残留。

Method: DualFairVL采用并行双分支架构，分离敏感和目标属性，实现跨模态解耦但对齐的表示。通过线性投影构建近似正交的文本锚点，指导交叉注意力机制生成融合特征。超网络进一步解耦属性相关信息，生成实例感知的视觉提示，编码公平性和鲁棒性的双模态线索。原型化正则化应用于视觉分支，强制分离敏感特征并加强与文本锚点的对齐。

Result: 在八个医学成像数据集（跨四种模态）上进行的广泛实验表明，DualFairVL在分布内和分布外设置下均实现了最先进的公平性和准确性，其性能优于全微调和参数高效基线，而可训练参数仅为3.6M。

Conclusion: DualFairVL是一个有效的多模态提示学习框架，能够联合去偏和对齐跨模态表示，在医学诊断中实现了跨人群的公平性和鲁棒性，并在多种数据集和设置下取得了优于现有方法的性能。

Abstract: Ensuring fairness across demographic groups in medical diagnosis is essential
for equitable healthcare, particularly under distribution shifts caused by
variations in imaging equipment and clinical practice. Vision-language models
(VLMs) exhibit strong generalization, and text prompts encode identity
attributes, enabling explicit identification and removal of sensitive
directions. However, existing debiasing approaches typically address vision and
text modalities independently, leaving residual cross-modal misalignment and
fairness gaps. To address this challenge, we propose DualFairVL, a multimodal
prompt-learning framework that jointly debiases and aligns cross-modal
representations. DualFairVL employs a parallel dual-branch architecture that
separates sensitive and target attributes, enabling disentangled yet aligned
representations across modalities. Approximately orthogonal text anchors are
constructed via linear projections, guiding cross-attention mechanisms to
produce fused features. A hypernetwork further disentangles attribute-related
information and generates instance-aware visual prompts, which encode
dual-modal cues for fairness and robustness. Prototype-based regularization is
applied in the visual branch to enforce separation of sensitive features and
strengthen alignment with textual anchors. Extensive experiments on eight
medical imaging datasets across four modalities show that DualFairVL achieves
state-of-the-art fairness and accuracy under both in- and out-of-distribution
settings, outperforming full fine-tuning and parameter-efficient baselines with
only 3.6M trainable parameters. Code will be released upon publication.

</details>


### [47] [DQEN: Dual Query Enhancement Network for DETR-based HOI Detection](https://arxiv.org/abs/2508.18896)
*Zhehao Li,Chong Wang,Yi Chen,Yinghao Lu,Jiangbo Qian,Jiong Wang,Jiafei Wu*

Main category: cs.CV

TL;DR: DETR-based HOI detection models use randomly initialized queries, which leads to vague representations. This paper proposes a Dual Query Enhancement Network (DQEN) to enhance object and interaction queries using object-aware features and CLIP-promoted HOI candidates, achieving competitive performance on HICO-Det and V-COCO datasets.


<details>
  <summary>Details</summary>
Motivation: Prior works in DETR-based HOI detection have relied on randomly initialized queries, resulting in vague representations that limit model effectiveness. This paper aims to address this limitation by enhancing the object and interaction queries.

Method: The proposed Dual Query Enhancement Network (DQEN) enhances object queries with object-aware encoder features and interaction queries by exploiting HOI candidates promoted by CLIP via a novel Interaction Semantic Fusion module. An Auxiliary Prediction Unit is also introduced to improve interaction feature representation.

Result: The proposed method achieves competitive performance on both the HICO-Det and V-COCO datasets.

Conclusion: The Dual Query Enhancement Network (DQEN) effectively enhances object and interaction queries in DETR-based HOI detection models, leading to improved performance by incorporating object-aware features and CLIP-promoted interaction semantics.

Abstract: Human-Object Interaction (HOI) detection focuses on localizing human-object
pairs and recognizing their interactions. Recently, the DETR-based framework
has been widely adopted in HOI detection. In DETR-based HOI models, queries
with clear meaning are crucial for accurately detecting HOIs. However, prior
works have typically relied on randomly initialized queries, leading to vague
representations that limit the model's effectiveness. Meanwhile, humans in the
HOI categories are fixed, while objects and their interactions are variable.
Therefore, we propose a Dual Query Enhancement Network (DQEN) to enhance object
and interaction queries. Specifically, object queries are enhanced with
object-aware encoder features, enabling the model to focus more effectively on
humans interacting with objects in an object-aware way. On the other hand, we
design a novel Interaction Semantic Fusion module to exploit the HOI candidates
that are promoted by the CLIP model. Semantic features are extracted to enhance
the initialization of interaction queries, thereby improving the model's
ability to understand interactions. Furthermore, we introduce an Auxiliary
Prediction Unit aimed at improving the representation of interaction features.
Our proposed method achieves competitive performance on both the HICO-Det and
the V-COCO datasets. The source code is available at
https://github.com/lzzhhh1019/DQEN.

</details>


### [48] [Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025](https://arxiv.org/abs/2508.18904)
*Thien-Phuc Tran,Minh-Quang Nguyen,Minh-Triet Tran,Tam V. Nguyen,Trong-Le Do,Duy-Nam Ly,Viet-Tham Huynh,Khanh-Duy Le,Mai-Khiem Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: EVENTA是一个新的基准，用于事件级多模态理解，重点关注图像中的上下文、时间和语义信息。


<details>
  <summary>Details</summary>
Motivation: 传统的图像字幕和检索任务主要关注表面层面的识别，忽略了定义真实事件的上下文和语义维度。EVENTA旨在弥合这一差距，通过整合上下文、时间和语义信息来捕捉图像背后的“谁、何时、何地、何事、为何”。

Method: EVENTA挑战建立在OpenEvents V1数据集之上，包含两个赛道：事件增强图像检索和字幕，以及基于事件的图像检索。该挑战在ACM Multimedia 2025上进行，有来自六个国家的45支队伍参加，并通过公开和私人测试阶段进行评估。

Result: 在ACM Multimedia 2025上，有45支队伍参加了EVENTA挑战赛，并被邀请在会上展示他们的解决方案。

Conclusion: EVENTA为上下文感知、叙事驱动的多媒体人工智能奠定了基础，并在新闻、媒体分析、文化档案和可访问性等领域具有应用价值。

Abstract: The Event-Enriched Image Analysis (EVENTA) Grand Challenge, hosted at ACM
Multimedia 2025, introduces the first large-scale benchmark for event-level
multimodal understanding. Traditional captioning and retrieval tasks largely
focus on surface-level recognition of people, objects, and scenes, often
overlooking the contextual and semantic dimensions that define real-world
events. EVENTA addresses this gap by integrating contextual, temporal, and
semantic information to capture the who, when, where, what, and why behind an
image. Built upon the OpenEvents V1 dataset, the challenge features two tracks:
Event-Enriched Image Retrieval and Captioning, and Event-Based Image Retrieval.
A total of 45 teams from six countries participated, with evaluation conducted
through Public and Private Test phases to ensure fairness and reproducibility.
The top three teams were invited to present their solutions at ACM Multimedia
2025. EVENTA establishes a foundation for context-aware, narrative-driven
multimedia AI, with applications in journalism, media analysis, cultural
archiving, and accessibility. Further details about the challenge are available
at the official homepage: https://ltnghia.github.io/eventa/eventa-2025.

</details>


### [49] [Preliminary Study on Space Utilization and Emergent Behaviors of Group vs. Single Pedestrians in Real-World Trajectories](https://arxiv.org/abs/2508.18939)
*Amartaivan Sanjjamts,Morita Hiroshi*

Main category: cs.CV

TL;DR: 该研究提出了一个基于轨迹数据区分群体和单个行人的框架，旨在分析它们在空间利用和行为模式上的差异。


<details>
  <summary>Details</summary>
Motivation: 分析群体和单个行人在空间利用和行为模式上的差异。

Method: 通过分割轨迹、应用Transformer模型进行分类，并建立包含空间和行为维度的度量框架，同时引入了三种遭遇类型（单对单、单对群、群对群）。

Result: 建立了一个分类流程和数据集结构，为不同序列长度的分析奠定了基础。

Conclusion: 该研究为后续量化分析和在人群动力学研究中的应用奠定了基础。

Abstract: This study presents an initial framework for distinguishing group and single
pedestrians based on real-world trajectory data, with the aim of analyzing
their differences in space utilization and emergent behavioral patterns. By
segmenting pedestrian trajectories into fixed time bins and applying a
Transformer-based pair classification model, we identify cohesive groups and
isolate single pedestrians over a structured sequence-based filtering process.
To prepare for deeper analysis, we establish a comprehensive metric framework
incorporating both spatial and behavioral dimensions. Spatial utilization
metrics include convex hull area, smallest enclosing circle radius, and
heatmap-based spatial densities to characterize how different pedestrian types
occupy and interact with space. Behavioral metrics such as velocity change,
motion angle deviation, clearance radius, and trajectory straightness are
designed to capture local adaptations and responses during interactions.
Furthermore, we introduce a typology of encounter types-single-to-single,
single-to-group, and group-to-group to categorize and later quantify different
interaction scenarios. Although this version focuses primarily on the
classification pipeline and dataset structuring, it establishes the groundwork
for scalable analysis across different sequence lengths 60, 100, and 200
frames. Future versions will incorporate complete quantitative analysis of the
proposed metrics and their implications for pedestrian simulation and space
design validation in crowd dynamics research.

</details>


### [50] [The point is the mask: scaling coral reef segmentation with weak supervision](https://arxiv.org/abs/2508.18958)
*Matteo Contini,Victor Illien,Sylvain Poulain,Serge Bernard,Julien Barde,Sylvain Bonhommeau,Alexis Joly*

Main category: cs.CV

TL;DR: 无人机航拍图像因分辨率低而难以区分珊瑚形态等精细类别，而像素级标注成本高昂。本研究提出了一种多尺度弱监督语义分割框架，通过将水下图像的精细生态信息转移到航空数据中，实现了无人机数据的珊瑚礁大范围测绘，仅需少量手动标注。该方法结合了基于分类的监督、空间插值和自蒸馏技术，能够进行珊瑚形态的大面积分割，并灵活整合新类别，为高分辨率珊瑚礁监测提供了一种可扩展、低成本的方法。


<details>
  <summary>Details</summary>
Motivation: 现有技术在利用无人机航拍图像进行大尺度珊瑚礁监测时，面临分辨率不足以区分精细类别（如珊瑚形态）以及像素级标注成本高、劳动强度大限制了深度学习方法的可扩展性等挑战。

Method: 提出了一种多尺度弱监督语义分割框架，通过将水下图像的精细生态信息转移到航空数据中，并结合基于分类的监督、空间插值和自蒸馏技术，实现仅需少量手动标注的珊瑚礁大范围测绘。

Result: 该方法能够实现珊瑚形态的精细分割，并且能够灵活地整合新的类别，证明了其有效性。

Conclusion: 该研究提出了一种可扩展、成本效益高的高分辨率珊瑚礁监测方法，结合了低成本数据采集、弱监督深度学习和多尺度遥感技术。

Abstract: Monitoring coral reefs at large spatial scales remains an open challenge,
essential for assessing ecosystem health and informing conservation efforts.
While drone-based aerial imagery offers broad spatial coverage, its limited
resolution makes it difficult to reliably distinguish fine-scale classes, such
as coral morphotypes. At the same time, obtaining pixel-level annotations over
large spatial extents is costly and labor-intensive, limiting the scalability
of deep learning-based segmentation methods for aerial imagery. We present a
multi-scale weakly supervised semantic segmentation framework that addresses
this challenge by transferring fine-scale ecological information from
underwater imagery to aerial data. Our method enables large-scale coral reef
mapping from drone imagery with minimal manual annotation, combining
classification-based supervision, spatial interpolation and self-distillation
techniques. We demonstrate the efficacy of the approach, enabling large-area
segmentation of coral morphotypes and demonstrating flexibility for integrating
new classes. This study presents a scalable, cost-effective methodology for
high-resolution reef monitoring, combining low-cost data collection, weakly
supervised deep learning and multi-scale remote sensing.

</details>


### [51] [Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers](https://arxiv.org/abs/2508.18959)
*Claudio Affolter,Sidi Wu,Yizi Chen,Lorenz Hurni*

Main category: cs.CV

TL;DR: 生成式AI结合矢量数据实现地图自动化绘制，提升效率和可及性。


<details>
  <summary>Details</summary>
Motivation: 传统地图制作依赖GIS，耗时且需专业知识，而现有生成式AI在地图制作中缺乏空间和语义控制。本研究旨在通过结合矢量数据和文本提示，实现受控风格的地图生成，解决这些问题。

Method: 本研究提出了一种整合矢量数据以指导地图生成（支持不同风格，由文本提示指定）的模型，并开发了一个Web应用以增强其可用性和可访问性。通过用户研究评估了生成地图的保真度和Web应用的可用性。

Result: 用户研究表明，所开发的应用程序和生成式AI模型在提高地图制作效率方面具有潜力，能够帮助专家和非专家用户。生成的地图在受控风格下具有准确性。

Conclusion: 生成式AI与矢量数据结合为地图制作带来了自动化和民主化的新机遇。该研究提出的模型和应用展示了其在提升地图制作效率和可访问性方面的潜力，并指出了地图绘制范式向AI辅助转变的趋势以及地图绘制师的新角色。

Abstract: Traditional map-making relies heavily on Geographic Information Systems
(GIS), requiring domain expertise and being time-consuming, especially for
repetitive tasks. Recent advances in generative AI (GenAI), particularly image
diffusion models, offer new opportunities for automating and democratizing the
map-making process. However, these models struggle with accurate map creation
due to limited control over spatial composition and semantic layout. To address
this, we integrate vector data to guide map generation in different styles,
specified by the textual prompts. Our model is the first to generate accurate
maps in controlled styles, and we have integrated it into a web application to
improve its usability and accessibility. We conducted a user study with
professional cartographers to assess the fidelity of generated maps, the
usability of the web application, and the implications of ever-emerging GenAI
in map-making. The findings have suggested the potential of our developed
application and, more generally, the GenAI models in helping both non-expert
users and professionals in creating maps more efficiently. We have also
outlined further technical improvements and emphasized the new role of
cartographers to advance the paradigm of AI-assisted map-making.

</details>


### [52] [Enhancing compact convolutional transformers with super attention](https://arxiv.org/abs/2508.18960)
*Simpenzwe Honore Leandre,Natenaile Asmamaw Shiferaw,Dillip Rout*

Main category: cs.CV

TL;DR: 提出了一种结合了token mixing、sequence-pooling和卷积tokenizer的视觉模型，在CIFAR100基准测试中取得了最先进的性能和高效推理，并在特定条件下比SDPA transformer更优。


<details>
  <summary>Details</summary>
Motivation: 在固定上下文长度的任务中，寻求一种能够实现最先进性能和高效推理的视觉模型。

Method: 采用token mixing、sequence-pooling和卷积tokenizer。

Result: 在CIFAR100基准测试中，top 1%和top 5%验证准确率分别从36.50%提高到46.29%，从66.33%提高到76.31%。在上下文长度小于嵌入维度时，模型效率比SDPA transformer高，尺寸仅为其60%。模型还表现出高训练稳定性的特点，无需数据增强、位置嵌入或学习率调度等技术。

Conclusion: 所提出的模型在CIFAR100基准测试中取得了显著的性能提升，并且在特定条件下比现有模型更高效，同时还具备良好的训练稳定性和易用性。

Abstract: In this paper, we propose a vision model that adopts token mixing,
sequence-pooling, and convolutional tokenizers to achieve state-of-the-art
performance and efficient inference in fixed context-length tasks. In the
CIFAR100 benchmark, our model significantly improves the baseline of the top 1%
and top 5% validation accuracy from 36.50% to 46.29% and 66.33% to 76.31%,
while being more efficient than the Scaled Dot Product Attention (SDPA)
transformers when the context length is less than the embedding dimension and
only 60% the size. In addition, the architecture demonstrates high training
stability and does not rely on techniques such as data augmentation like mixup,
positional embeddings, or learning rate scheduling. We make our code available
on Github.

</details>


### [53] [USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning](https://arxiv.org/abs/2508.18966)
*Shaojin Wu,Mengqi Huang,Yufeng Cheng,Wenxu Wu,Jiahe Tian,Yiming Luo,Fei Ding,Qian He*

Main category: cs.CV

TL;DR: 该论文提出了一种名为USO的统一风格-主题优化定制模型，旨在解决现有研究中风格驱动和主题驱动生成任务之间的矛盾，通过解耦和重组内容与风格，实现了在主题一致性和风格相似性两个维度上的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有文献将风格驱动和主题驱动的生成视为两个分离的任务，存在明显的矛盾。本研究认为这两个目标可以在一个统一的框架下实现，因为它们最终都涉及内容和风格的解耦与重组。

Method: 1.构建了一个大规模的三元组数据集，包含内容图像、风格图像和相应的风格化内容图像。2.引入了一个解耦学习方案，通过风格对齐训练和内容-风格解耦训练两个互补的目标，同时对齐风格特征并使内容与风格解耦。3.采用了一种称为SRL的风格奖励学习范式，以进一步提高模型性能。4.发布了USO-Bench，这是第一个在多个指标上联合评估风格相似性和主题保真度的基准。

Result: USO模型在主题一致性和风格相似性两个维度上均取得了优于现有开源模型的性能。

Conclusion: USO模型成功地统一了风格驱动和主题驱动的生成任务，实现了在内容和风格解耦及重组方面的先进性能，并通过USO-Bench基准进行了验证。

Abstract: Existing literature typically treats style-driven and subject-driven
generation as two disjoint tasks: the former prioritizes stylistic similarity,
whereas the latter insists on subject consistency, resulting in an apparent
antagonism. We argue that both objectives can be unified under a single
framework because they ultimately concern the disentanglement and
re-composition of content and style, a long-standing theme in style-driven
research. To this end, we present USO, a Unified Style-Subject Optimized
customization model. First, we construct a large-scale triplet dataset
consisting of content images, style images, and their corresponding stylized
content images. Second, we introduce a disentangled learning scheme that
simultaneously aligns style features and disentangles content from style
through two complementary objectives, style-alignment training and
content-style disentanglement training. Third, we incorporate a style
reward-learning paradigm denoted as SRL to further enhance the model's
performance. Finally, we release USO-Bench, the first benchmark that jointly
evaluates style similarity and subject fidelity across multiple metrics.
Extensive experiments demonstrate that USO achieves state-of-the-art
performance among open-source models along both dimensions of subject
consistency and style similarity. Code and model:
https://github.com/bytedance/USO

</details>


### [54] [Can we make NeRF-based visual localization privacy-preserving?](https://arxiv.org/abs/2508.18971)
*Maxime Pietrantoni,Martin Humenberger,Torsten Sattler,Gabriela Csurka*

Main category: cs.CV

TL;DR: NeRF-based visual localization methods raise privacy concerns due to their detailed scene encoding. This paper proposes a privacy-assessment protocol and a privacy-preserving NeRF variant (ppNeSF) trained with self-supervised segmentation labels, which achieves state-of-the-art visual localization while obscuring identifiable scene details.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the privacy concerns associated with NeRF-based visual localization methods, which inadvertently encode fine scene details making them vulnerable to privacy attacks.

Method: The paper proposes a new protocol to assess the privacy-preservation of NeRF-based representations and introduces ppNeSF, a NeRF variant trained with self-supervised segmentation labels instead of RGB images.

Result: NeRFs trained with photometric losses store fine-grained details in their geometry representations, making them vulnerable. ppNeSF, trained with segmentation supervision, obscures identifiable scene details while remaining discriminative, yielding state-of-the-art visual localization results.

Conclusion: ppNeSF offers a privacy-preserving solution for NeRF-based visual localization, achieving high accuracy without compromising sensitive scene information by utilizing self-supervised segmentation labels.

Abstract: Visual localization (VL) is the task of estimating the camera pose in a known
scene. VL methods, a.o., can be distinguished based on how they represent the
scene, e.g., explicitly through a (sparse) point cloud or a collection of
images or implicitly through the weights of a neural network. Recently,
NeRF-based methods have become popular for VL. While NeRFs offer high-quality
novel view synthesis, they inadvertently encode fine scene details, raising
privacy concerns when deployed in cloud-based localization services as
sensitive information could be recovered. In this paper, we tackle this
challenge on two ends. We first propose a new protocol to assess
privacy-preservation of NeRF-based representations. We show that NeRFs trained
with photometric losses store fine-grained details in their geometry
representations, making them vulnerable to privacy attacks, even if the head
that predicts colors is removed. Second, we propose ppNeSF (Privacy-Preserving
Neural Segmentation Field), a NeRF variant trained with segmentation
supervision instead of RGB images. These segmentation labels are learned in a
self-supervised manner, ensuring they are coarse enough to obscure identifiable
scene details while remaining discriminativeness in 3D. The segmentation space
of ppNeSF can be used for accurate visual localization, yielding
state-of-the-art results.

</details>


### [55] [Enhancing Document VQA Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2508.18984)
*Eric López,Artemis Llabrés,Ernest Valveny*

Main category: cs.CV

TL;DR: RAG通过不同检索变体（基于OCR文本和纯视觉检索）显著提升了文档VQA的准确性，并在多页面数据集上进行了评估。与现有方法相比，RAG（特别是文本中心变体）在不依赖大型模型和内存消耗的情况下，能带来显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的文档VQA系统在处理多页文档时，面临内存消耗大的问题（如拼接所有页面或使用大型视觉语言模型）。RAG提供了一种有前景的替代方案，通过检索相关片段再生成答案来解决这个问题。

Method: 通过不同的检索变体（基于OCR文本的检索和纯视觉检索）系统地评估了RAG在文档VQA中的影响。在多页面数据集MP-DocVQA、DUDE和InfographicVQA上进行了评估。

Result: 基于文本的变体比“拼接所有页面”的基线模型提高了+22.5 ANLS，而纯视觉变体在不需要文本提取的情况下提高了+5.0 ANLS。消融实验表明，检索和重排组件是性能提升的主要驱动因素，而布局引导分块策略并未带来帮助。

Conclusion: 证据选择（RAG）能够持续提高不同模型大小和多页面基准的准确性，证明了其在实际文档VQA应用中的价值。

Abstract: Document Visual Question Answering (Document VQA) must cope with documents
that span dozens of pages, yet leading systems still concatenate every page or
rely on very large vision-language models, both of which are memory-hungry.
Retrieval-Augmented Generation (RAG) offers an attractive alternative, first
retrieving a concise set of relevant segments before generating answers from
this selected evidence. In this paper, we systematically evaluate the impact of
incorporating RAG into Document VQA through different retrieval variants -
text-based retrieval using OCR tokens and purely visual retrieval without OCR -
across multiple models and benchmarks. Evaluated on the multi-page datasets
MP-DocVQA, DUDE, and InfographicVQA, the text-centric variant improves the
"concatenate-all-pages" baseline by up to +22.5 ANLS, while the visual variant
achieves +5.0 ANLS improvement without requiring any text extraction. An
ablation confirms that retrieval and reranking components drive most of the
gain, whereas the layout-guided chunking strategy - proposed in several recent
works to leverage page structure - fails to help on these datasets. Our
experiments demonstrate that careful evidence selection consistently boosts
accuracy across multiple model sizes and multi-page benchmarks, underscoring
its practical value for real-world Document VQA.

</details>


### [56] [Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone](https://arxiv.org/abs/2508.18989)
*Shaivi Malik,Hasnat Md Abdullah,Sriparna Saha,Amit Sheth*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As Vision Language Models (VLMs) become integral to real-world applications,
understanding their demographic biases is critical. We introduce GRAS, a
benchmark for uncovering demographic biases in VLMs across gender, race, age,
and skin tone, offering the most diverse coverage to date. We further propose
the GRAS Bias Score, an interpretable metric for quantifying bias. We benchmark
five state-of-the-art VLMs and reveal concerning bias levels, with the least
biased model attaining a GRAS Bias Score of only 2 out of 100. Our findings
also reveal a methodological insight: evaluating bias in VLMs with visual
question answering (VQA) requires considering multiple formulations of a
question. Our code, data, and evaluation results are publicly available.

</details>


### [57] [RoofSeg: An edge-aware transformer-based network for end-to-end roof plane segmentation](https://arxiv.org/abs/2508.19003)
*Siyuan You,Guozheng Xu,Pengwei Zhou,Qiwen Jin,Jian Yao,Li Li*

Main category: cs.CV

TL;DR: 该论文提出了一种名为RoofSeg的新型边缘感知Transformer网络，用于从激光雷达点云中分割屋顶平面，解决了现有方法的三个问题：非端到端、边缘点特征辨别力低以及未充分考虑平面几何特性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习方法在屋顶平面分割中的三个未解决问题：非端到端优化、边缘点特征辨别力低以及未能充分考虑平面几何特性。

Method: 提出了一种名为RoofSeg的端到端Transformer网络，利用Transformer编码器-解码器框架和可学习的平面查询来预测平面实例掩码。通过设计边缘感知掩码模块（EAMM）来增强边缘区域的辨别力，并采用自适应加权策略和新的平面几何损失来优化网络训练。

Result: RoofSeg网络能够以端到端的方式分割屋顶平面，提高了分割精度，特别是边缘区域的精度。

Conclusion: RoofSeg网络通过其创新的架构和损失函数设计，有效解决了现有屋顶平面分割方法的不足，实现了更高的分割精度和更好的边缘处理能力。

Abstract: Roof plane segmentation is one of the key procedures for reconstructing
three-dimensional (3D) building models at levels of detail (LoD) 2 and 3 from
airborne light detection and ranging (LiDAR) point clouds. The majority of
current approaches for roof plane segmentation rely on the manually designed or
learned features followed by some specifically designed geometric clustering
strategies. Because the learned features are more powerful than the manually
designed features, the deep learning-based approaches usually perform better
than the traditional approaches. However, the current deep learning-based
approaches have three unsolved problems. The first is that most of them are not
truly end-to-end, the plane segmentation results may be not optimal. The second
is that the point feature discriminability near the edges is relatively low,
leading to inaccurate planar edges. The third is that the planar geometric
characteristics are not sufficiently considered to constrain the network
training. To solve these issues, a novel edge-aware transformer-based network,
named RoofSeg, is developed for segmenting roof planes from LiDAR point clouds
in a truly end-to-end manner. In the RoofSeg, we leverage a transformer
encoder-decoder-based framework to hierarchically predict the plane instance
masks with the use of a set of learnable plane queries. To further improve the
segmentation accuracy of edge regions, we also design an Edge-Aware Mask Module
(EAMM) that sufficiently incorporates planar geometric prior of edges to
enhance its discriminability for plane instance mask refinement. In addition,
we propose an adaptive weighting strategy in the mask loss to reduce the
influence of misclassified points, and also propose a new plane geometric loss
to constrain the network training.

</details>


### [58] [MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis](https://arxiv.org/abs/2508.19021)
*Riju Marwah,Riya Arora,Navneet Yadav,Himank Arora*

Main category: cs.CV

TL;DR: 这项研究提出了一种名为MicroDetect-Net (MDN)的新模型，该模型结合荧光显微镜、尼尔红染色和深度学习技术，用于在血液样本中检测和计数微塑料。


<details>
  <summary>Details</summary>
Motivation: 鉴于每年超过3.68亿吨的塑料使用量，微塑料污染已对环境和人类健康构成严重威胁，可能导致肝脏感染、肠道损伤和肠道菌群失调等健康问题。因此，开发有效的微塑料检测方法至关重要。

Method: 该研究提出了一种名为MicroDetect-Net (MDN)的新模型，该模型集成了数据集准备、荧光成像和使用卷积神经网络进行分割的步骤，以定位和计数微塑料碎片。该方法利用尼尔红染料和荧光显微镜来识别微塑料，并通过深度学习模型进行分析。

Result: MDN模型在包含276张尼尔红染色荧光血样图像的数据集上进行了评估，在微塑料检测方面取得了92%的准确率，同时在Intersection over Union（87.4%）、F1分数（92.1%）、精确率（90.6%）和召回率（93.7%）方面也表现出稳健的性能。

Conclusion: MDN模型结合卷积神经网络和尼尔红染色技术，在检测和计数微塑料方面表现出很高的准确性和有效性，为将此方法应用于人体血液样本检测奠定了基础。

Abstract: With the prevalence of plastics exceeding 368 million tons yearly,
microplastic pollution has grown to an extent where air, water, soil, and
living organisms have all tested positive for microplastic presence. These
particles, which are smaller than 5 millimeters in size, are no less harmful to
humans than to the environment. Toxicity research on microplastics has shown
that exposure may cause liver infection, intestinal injuries, and gut flora
imbalance, leading to numerous potential health hazards. This paper presents a
new model, MicroDetect-Net (MDN), which applies fluorescence microscopy with
Nile Red dye staining and deep learning to scan blood samples for
microplastics. Although clam blood has certain limitations in replicating real
human blood, this study opens avenues for applying the approach to human
samples, which are more consistent for preliminary data collection. The MDN
model integrates dataset preparation, fluorescence imaging, and segmentation
using a convolutional neural network to localize and count microplastic
fragments. The combination of convolutional networks and Nile Red dye for
segmentation produced strong image detection and accuracy. MDN was evaluated on
a dataset of 276 Nile Red-stained fluorescent blood images and achieved an
accuracy of ninety two percent. Robust performance was observed with an
Intersection over Union of 87.4 percent, F1 score of 92.1 percent, Precision of
90.6 percent, and Recall of 93.7 percent. These metrics demonstrate the
effectiveness of MDN in the detection of microplastics.

</details>


### [59] [ProPy: Building Interactive Prompt Pyramids upon CLIP for Partially Relevant Video Retrieval](https://arxiv.org/abs/2508.19024)
*Yi Pan,Yujia Zhang,Michael Kampffmeyer,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: ProPy是一个针对部分相关视频检索（PRVR）任务的模型，它通过系统性地调整CLIP模型，并引入了Prompt Pyramid结构和祖先-后代交互机制，在三个公开数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有PRVR模型主要处理单一模态特征，而CLIP等强大的预训练视觉-语言模型在该领域的应用仍有待探索。本研究旨在弥合这一差距，将CLIP应用于PRVR任务。

Method: ProPy模型对CLIP进行了系统性的架构调整，并引入了两个关键创新：1. Prompt Pyramid结构，用于组织事件提示以捕捉多粒度的语义；2. 祖先-后代交互机制，基于金字塔实现事件间的动态语义交互。

Result: ProPy在三个公开数据集上取得了最先进的性能，显著优于之前的模型。

Conclusion: ProPy通过其创新的Prompt Pyramid结构和祖先-后代交互机制，成功地将CLIP模型应用于PRVR任务，并在多个基准测试中取得了优异的成绩。

Abstract: Partially Relevant Video Retrieval (PRVR) is a practical yet challenging task
that involves retrieving videos based on queries relevant to only specific
segments. While existing works follow the paradigm of developing models to
process unimodal features, powerful pretrained vision-language models like CLIP
remain underexplored in this field. To bridge this gap, we propose ProPy, a
model with systematic architectural adaption of CLIP specifically designed for
PRVR. Drawing insights from the semantic relevance of multi-granularity events,
ProPy introduces two key innovations: (1) A Prompt Pyramid structure that
organizes event prompts to capture semantics at multiple granularity levels,
and (2) An Ancestor-Descendant Interaction Mechanism built on the pyramid that
enables dynamic semantic interaction among events. With these designs, ProPy
achieves SOTA performance on three public datasets, outperforming previous
models by significant margins. Code is available at
https://github.com/BUAAPY/ProPy.

</details>


### [60] [GReAT: leveraging geometric artery data to improve wall shear stress assessment](https://arxiv.org/abs/2508.19030)
*Julian Suk,Jolanda J. Wentzel,Patryk Rygiel,Joost Daemen,Daniel Rueckert,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 利用包含8449个几何动脉模型的大型数据集，通过自监督学习，提高冠状动脉血流切应力评估的准确性，即使在数据量有限的情况下也能提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 虽然利用大数据改善患者护理，尤其是在心血管健康领域，前景广阔，但用于训练相关机器学习模型的数据量却非常有限。本研究旨在解决冠状动脉血流切应力评估中的数据稀缺问题。

Method: 本研究创建了一个包含8449个3D血管几何模型的大型数据集，并计算了热核特征（通过拉普拉斯特征向量获得）作为自监督学习的目标。然后，利用从该数据集中学到的几何表示来提高冠状动脉模型血流切应力评估的准确性，即使在数据量有限的情况下也能提升分割效果。

Result: 研究表明，从大型3D血管几何模型数据集中学到的几何表示可以显著提高冠状动脉模型血流切应力（特别是时间平均血流切应力）的评估准确性，即使在仅使用49名患者的小型临床试验数据进行训练时，也能改善低、中、高血流切应力区域的分割效果。

Conclusion: 本研究证明了使用自监督学习和大型几何模型数据集来改善冠状动脉血流切应力评估是可行的，即使在临床数据有限的情况下也能取得良好效果。这为利用大数据改善心血管疾病的诊断和治疗提供了新的途径。

Abstract: Leveraging big data for patient care is promising in many medical fields such
as cardiovascular health. For example, hemodynamic biomarkers like wall shear
stress could be assessed from patient-specific medical images via machine
learning algorithms, bypassing the need for time-intensive computational fluid
simulation. However, it is extremely challenging to amass large-enough datasets
to effectively train such models. We could address this data scarcity by means
of self-supervised pre-training and foundations models given large datasets of
geometric artery models. In the context of coronary arteries, leveraging
learned representations to improve hemodynamic biomarker assessment has not yet
been well studied. In this work, we address this gap by investigating whether a
large dataset (8449 shapes) consisting of geometric models of 3D blood vessels
can benefit wall shear stress assessment in coronary artery models from a
small-scale clinical trial (49 patients). We create a self-supervised target
for the 3D blood vessels by computing the heat kernel signature, a quantity
obtained via Laplacian eigenvectors, which captures the very essence of the
shapes. We show how geometric representations learned from this datasets can
boost segmentation of coronary arteries into regions of low, mid and high
(time-averaged) wall shear stress even when trained on limited data.

</details>


### [61] [No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes](https://arxiv.org/abs/2508.19060)
*Blaž Rolih,Matic Fučka,Danijel Skočaj*

Main category: cs.CV

TL;DR: SuperSimpleNet是一个高效且自适应的判别模型，可在四种监督场景（无监督、弱监督、混合监督和全监督）下进行训练，并且能够充分利用所有可用的数据注释。该模型在四个具有挑战性的基准数据集上设定了新的性能标准，推理时间低于10毫秒。


<details>
  <summary>Details</summary>
Motivation: 现有的表面缺陷检测方法通常在特定监督场景下表现不佳，难以适应真实制造过程中遇到的各种数据注释，例如无监督、弱监督、混合监督和全监督设置。

Method: SuperSimpleNet基于SimpleNet构建，包含新颖的合成异常生成过程、增强的分类头和改进的学习程序。

Result: SuperSimpleNet在四个具有挑战性的基准数据集上设定了新的性能标准，并且推理速度非常快，低于10毫秒。

Conclusion: SuperSimpleNet能够统一各种监督范式，同时保持出色的速度和可靠性，代表了解决现实制造挑战和弥合学术研究与工业应用之间差距的一个有希望的进步。

Abstract: Surface defect detection is a critical task across numerous industries, aimed
at efficiently identifying and localising imperfections or irregularities on
manufactured components. While numerous methods have been proposed, many fail
to meet industrial demands for high performance, efficiency, and adaptability.
Existing approaches are often constrained to specific supervision scenarios and
struggle to adapt to the diverse data annotations encountered in real-world
manufacturing processes, such as unsupervised, weakly supervised, mixed
supervision, and fully supervised settings. To address these challenges, we
propose SuperSimpleNet, a highly efficient and adaptable discriminative model
built on the foundation of SimpleNet. SuperSimpleNet incorporates a novel
synthetic anomaly generation process, an enhanced classification head, and an
improved learning procedure, enabling efficient training in all four
supervision scenarios, making it the first model capable of fully leveraging
all available data annotations. SuperSimpleNet sets a new standard for
performance across all scenarios, as demonstrated by its results on four
challenging benchmark datasets. Beyond accuracy, it is very fast, achieving an
inference time below 10 ms. With its ability to unify diverse supervision
paradigms while maintaining outstanding speed and reliability, SuperSimpleNet
represents a promising step forward in addressing real-world manufacturing
challenges and bridging the gap between academic research and industrial
applications. Code: https://github.com/blaz-r/SuperSimpleNet

</details>


### [62] [Learning Binary Sampling Patterns for Single-Pixel Imaging using Bilevel Optimisation](https://arxiv.org/abs/2508.19068)
*Serban C. Tudosie,Alexander Denker,Zeljko Kereta,Simon Arridge*

Main category: cs.CV

TL;DR: 通过学习任务特定的二元照明模式，为单像素成像（特别是单像素荧光显微镜）提供更优越的重建性能，尤其是在欠采样情况下。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于学习任务特定、二元照明模式的 bilevel 优化方法，以解决单像素成像的重建问题，特别是用于单像素荧光显微镜。

Method: 使用 Straight-Through Estimator 处理二元模式优化中的非可微性问题，并在 bilevel 格式中利用 Total Deep Variation 规则化器。

Result: 在 CytoImageNet 显微镜数据集上展示了所提出的方法，并表明学习到的模式在高度欠采样的情况下比基线方法具有更优越的重建性能。

Conclusion: 所提出的 bilevel 优化方法通过学习任务特定的二元照明模式，能够提高单像素成像的重建性能，尤其是在欠采样条件下。

Abstract: Single-Pixel Imaging enables reconstructing objects using a single detector
through sequential illuminations with structured light patterns. We propose a
bilevel optimisation method for learning task-specific, binary illumination
patterns, optimised for applications like single-pixel fluorescence microscopy.
We address the non-differentiable nature of binary pattern optimisation using
the Straight-Through Estimator and leveraging a Total Deep Variation
regulariser in the bilevel formulation. We demonstrate our method on the
CytoImageNet microscopy dataset and show that learned patterns achieve superior
reconstruction performance compared to baseline methods, especially in highly
undersampled regimes.

</details>


### [63] [Few-Shot Connectivity-Aware Text Line Segmentation in Historical Documents](https://arxiv.org/abs/2508.19162)
*Rafael Sterzinger,Tingyu Lin,Robert Sablatnig*

Main category: cs.CV

TL;DR: 通过使用小型 UNet++ 模型和拓扑感知损失函数，在仅使用三页注释数据的情况下，显著提高了历史文档文本行分割的准确性和效率，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 由于历史文档缺乏大型标注数据集以及标注过程耗时耗专家知识，因此探索用于文本行分割的少样本学习方法。

Method: 结合轻量级 UNet++ 模型和连接感知损失函数，该函数明确惩罚结构错误（如线段断裂和意外合并），并在从少量（每份手稿仅三页）提取的小块上进行训练。

Result: 在 U-DIADS-TL 数据集上，识别准确率提高了 200%，线交并集提高了 75%。在 DIVA-HisDB 基线检测任务上，F-Measure 分数与竞争对手获胜者相当或更高。

Conclusion: 小型、简单的模型架构与拓扑感知损失函数相结合，可以实现比复杂模型更准确、更具数据效率的文本行分割，证明了少样本学习的有效性。

Abstract: A foundational task for the digital analysis of documents is text line
segmentation. However, automating this process with deep learning models is
challenging because it requires large, annotated datasets that are often
unavailable for historical documents. Additionally, the annotation process is a
labor- and cost-intensive task that requires expert knowledge, which makes
few-shot learning a promising direction for reducing data requirements. In this
work, we demonstrate that small and simple architectures, coupled with a
topology-aware loss function, are more accurate and data-efficient than more
complex alternatives. We pair a lightweight UNet++ with a connectivity-aware
loss, initially developed for neuron morphology, which explicitly penalizes
structural errors like line fragmentation and unintended line merges. To
increase our limited data, we train on small patches extracted from a mere
three annotated pages per manuscript. Our methodology significantly improves
upon the current state-of-the-art on the U-DIADS-TL dataset, with a 200%
increase in Recognition Accuracy and a 75% increase in Line Intersection over
Union. Our method also achieves an F-Measure score on par with or even
exceeding that of the competition winner of the DIVA-HisDB baseline detection
task, all while requiring only three annotated pages, exemplifying the efficacy
of our approach. Our implementation is publicly available at:
https://github.com/RafaelSterzinger/acpr_few_shot_hist.

</details>


### [64] [Dual Enhancement on 3D Vision-Language Perception for Monocular 3D Visual Grounding](https://arxiv.org/abs/2508.19165)
*Yuzhen Li,Min Liu,Yuan Bian,Xueping Wang,Zhaoyang Li,Gen Li,Yaonan Wang*

Main category: cs.CV

TL;DR: 现有模型在处理包含几何信息的文本时，对数值大小敏感但忽略单位，导致3D理解能力不足。本文提出3DTE和TGE两种方法，增强模型对文本和几何特征的3D感知能力，以提升3D视觉基础任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有预训练语言模型在处理包含几何信息的文本时，对数值大小敏感但忽略单位，导致3D理解能力不足，影响3D感知任务的表现。

Method: 1. 提出3D-text Enhancement (3DTE) 预处理方法，通过增加文本查询中距离描述符的多样性来增强对不同单位之间映射关系的理解。 2. 提出 Text-Guided Geometry Enhancement (TGE) 模块，将文本特征投影到几何一致性空间，以增强3D-文本信息，并精确引导几何特征的注意力。

Result: 在Mono3DRefer数据集上的实验结果显示，所提出的方法相比现有方法有显著提升，在“Far”场景下准确率提高了11.94%，达到了新的state-of-the-art水平。

Conclusion: 所提出的3DTE和TGE方法能有效增强模型对3D文本和几何特征的感知能力，显著提升了单目3D视觉基础任务的性能。

Abstract: Monocular 3D visual grounding is a novel task that aims to locate 3D objects
in RGB images using text descriptions with explicit geometry information.
Despite the inclusion of geometry details in the text, we observe that the text
embeddings are sensitive to the magnitude of numerical values but largely
ignore the associated measurement units. For example, simply equidistant
mapping the length with unit "meter" to "decimeters" or "centimeters" leads to
severe performance degradation, even though the physical length remains
equivalent. This observation signifies the weak 3D comprehension of pre-trained
language model, which generates misguiding text features to hinder 3D
perception. Therefore, we propose to enhance the 3D perception of model on text
embeddings and geometry features with two simple and effective methods.
Firstly, we introduce a pre-processing method named 3D-text Enhancement (3DTE),
which enhances the comprehension of mapping relationships between different
units by augmenting the diversity of distance descriptors in text queries.
Next, we propose a Text-Guided Geometry Enhancement (TGE) module to further
enhance the 3D-text information by projecting the basic text features into
geometrically consistent space. These 3D-enhanced text features are then
leveraged to precisely guide the attention of geometry features. We evaluate
the proposed method through extensive comparisons and ablation studies on the
Mono3DRefer dataset. Experimental results demonstrate substantial improvements
over previous methods, achieving new state-of-the-art results with a notable
accuracy gain of 11.94\% in the "Far" scenario. Our code will be made publicly
available.

</details>


### [65] [Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions](https://arxiv.org/abs/2508.19167)
*Zhihang Xin,Xitong Hu,Rui Wang*

Main category: cs.CV

TL;DR: Vision Transformers (ViTs) lose 2D structure via flattening; existing methods lack geometric constraints. We introduce Weierstrass Elliptic Function Positional Encoding (WEF-PE) using complex domain representation and elliptic functions' doubly periodic properties to preserve spatial structure and capture proximity. WEF-PE outperforms existing methods on CIFAR-100 and VTAB-1k, with proven distance-decay properties and improved attention visualization.


<details>
  <summary>Details</summary>
Motivation: ViTs disrupt image 2D structure with 1D embeddings; traditional methods fail to enforce geometric constraints and map spatial distances to sequential indices effectively.

Method: Proposes Weierstrass Elliptic Function Positional Encoding (WEF-PE), using complex domain representation and the doubly periodic properties of elliptic functions to encode 2D spatial information. Leverages the algebraic addition formula for relative positional information and demonstrates a distance-decay property through theoretical analysis.

Result: WEF-PE achieves 63.78% accuracy on CIFAR-100 (ViT-Tiny, from-scratch), 93.28% on CIFAR-100 (ViT-Base, fine-tuning), and shows consistent improvements on VTAB-1k. Attention visualization indicates enhanced geometric inductive bias and more coherent semantic focus.

Conclusion: WEF-PE mathematically encodes 2D spatial relationships using elliptic functions, preserving geometric structure and improving ViT performance across various tasks. Its effectiveness is validated by theoretical analysis and experimental results.

Abstract: Vision Transformers have demonstrated remarkable success in computer vision
tasks, yet their reliance on learnable one-dimensional positional embeddings
fundamentally disrupts the inherent two-dimensional spatial structure of images
through patch flattening procedures. Traditional positional encoding approaches
lack geometric constraints and fail to establish monotonic correspondence
between Euclidean spatial distances and sequential index distances, thereby
limiting the model's capacity to leverage spatial proximity priors effectively.
We propose Weierstrass Elliptic Function Positional Encoding (WEF-PE), a
mathematically principled approach that directly addresses two-dimensional
coordinates through natural complex domain representation, where the doubly
periodic properties of elliptic functions align remarkably with translational
invariance patterns commonly observed in visual data. Our method exploits the
non-linear geometric nature of elliptic functions to encode spatial distance
relationships naturally, while the algebraic addition formula enables direct
derivation of relative positional information between arbitrary patch pairs
from their absolute encodings. Comprehensive experiments demonstrate that
WEF-PE achieves superior performance across diverse scenarios, including
63.78\% accuracy on CIFAR-100 from-scratch training with ViT-Tiny architecture,
93.28\% on CIFAR-100 fine-tuning with ViT-Base, and consistent improvements on
VTAB-1k benchmark tasks. Theoretical analysis confirms the distance-decay
property through rigorous mathematical proof, while attention visualization
reveals enhanced geometric inductive bias and more coherent semantic focus
compared to conventional approaches.The source code implementing the methods
described in this paper is publicly available on GitHub.

</details>


### [66] [SoccerNet 2025 Challenges Results](https://arxiv.org/abs/2508.19182)
*Silvio Giancola,Anthony Cioppa,Marc Gutiérrez-Pérez,Jan Held,Carlos Hinojosa,Victor Joos,Arnaud Leduc,Floriane Magera,Karen Sanchez,Vladimir Somers,Artur Xarles,Antonio Agudo,Alexandre Alahi,Olivier Barnich,Albert Clapés,Christophe De Vleeschouwer,Sergio Escalera,Bernard Ghanem,Thomas B. Moeslund,Marc Van Droogenbroeck,Tomoki Abe,Saad Alotaibi,Faisal Altawijri,Steven Araujo,Xiang Bai,Xiaoyang Bi,Jiawang Cao,Vanyi Chao,Kamil Czarnogórski,Fabian Deuser,Mingyang Du,Tianrui Feng,Patrick Frenzel,Mirco Fuchs,Jorge García,Konrad Habel,Takaya Hashiguchi,Sadao Hirose,Xinting Hu,Yewon Hwang,Ririko Inoue,Riku Itsuji,Kazuto Iwai,Hongwei Ji,Yangguang Ji,Licheng Jiao,Yuto Kageyama,Yuta Kamikawa,Yuuki Kanasugi,Hyungjung Kim,Jinwook Kim,Takuya Kurihara,Bozheng Li,Lingling Li,Xian Li,Youxing Lian,Dingkang Liang,Hongkai Lin,Jiadong Lin,Jian Liu,Liang Liu,Shuaikun Liu,Zhaohong Liu,Yi Lu,Federico Méndez,Huadong Ma,Wenping Ma,Jacek Maksymiuk,Henry Mantilla,Ismail Mathkour,Daniel Matthes,Ayaha Motomochi,Amrulloh Robbani Muhammad,Haruto Nakayama,Joohyung Oh,Yin May Oo,Marcelo Ortega,Norbert Oswald,Rintaro Otsubo,Fabian Perez,Mengshi Qi,Cristian Rey,Abel Reyes-Angulo,Oliver Rose,Hoover Rueda-Chacón,Hideo Saito,Jose Sarmiento,Kanta Sawafuji,Atom Scott,Xi Shen,Pragyan Shrestha,Jae-Young Sim,Long Sun,Yuyang Sun,Tomohiro Suzuki,Licheng Tang,Masato Tonouchi,Ikuma Uchida,Henry O. Velesaca,Tiancheng Wang,Rio Watanabe,Jay Wu,Yongliang Wu,Shunzo Yamagishi,Di Yang,Xu Yang,Yuxin Yang,Hao Ye,Xinyu Ye,Calvin Yeung,Xuanlong Yu,Chao Zhang,Dingyuan Zhang,Kexing Zhang,Zhe Zhao,Xin Zhou,Wenbo Zhu,Julian Ziegler*

Main category: cs.CV

TL;DR: SoccerNet 2025 挑战赛聚焦足球视频理解中的四个计算机视觉任务：动作识别、单目深度估计、多视角犯规识别和比赛状态重构，旨在推动该领域的研究进展。


<details>
  <summary>Details</summary>
Motivation: SoccerNet 2025 挑战赛旨在推动足球视频理解的计算机视觉研究，并通过开放的基准测试平台汇集社区的最新进展。

Method: 本次挑战赛提供了大规模标注数据集、统一的评估协议和强大的基线模型，供参赛者进行四项视觉任务的开发和评估。

Result: 本次报告总结了各挑战赛的结果，重点介绍了表现最佳的解决方案，并展示了社区在足球视频理解方面取得的进展。

Conclusion: SoccerNet 挑战赛继续作为推动计算机视觉、人工智能和体育交叉领域可复现、开放研究的重要力量。

Abstract: The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet
open benchmarking effort, dedicated to advancing computer vision research in
football video understanding. This year's challenges span four vision-based
tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions
in football broadcasts and assigning actions to teams; (2) Monocular Depth
Estimation, targeting the recovery of scene geometry from single-camera
broadcast clips through relative depth estimation for each pixel; (3)
Multi-View Foul Recognition, requiring the analysis of multiple synchronized
camera views to classify fouls and their severity; and (4) Game State
Reconstruction, aimed at localizing and identifying all players from a
broadcast video to reconstruct the game state on a 2D top-view of the field.
Across all tasks, participants were provided with large-scale annotated
datasets, unified evaluation protocols, and strong baselines as starting
points. This report presents the results of each challenge, highlights the
top-performing solutions, and provides insights into the progress made by the
community. The SoccerNet Challenges continue to serve as a driving force for
reproducible, open research at the intersection of computer vision, artificial
intelligence, and sports. Detailed information about the tasks, challenges, and
leaderboards can be found at https://www.soccer-net.org, with baselines and
development kits available at https://github.com/SoccerNet.

</details>


### [67] [FastMesh:Efficient Artistic Mesh Generation via Component Decoupling](https://arxiv.org/abs/2508.19188)
*Jeonghwan Kim,Yushi Lan,Armando Fortes,Yongwei Chen,Xingang Pan*

Main category: cs.CV

TL;DR: 该研究提出了一种新的艺术网格生成框架，通过分别处理顶点和面来减少冗余，使用自回归模型生成顶点，并利用双向Transformer构建邻接矩阵来完成网格。此外，还引入了保真度增强器和后处理框架来提高网格质量。


<details>
  <summary>Details</summary>
Motivation: 现有的网格生成方法将三角形网格分词为token序列并使用自回归模型生成，但由于顶点被多个面共享，这种方法存在冗余，导致token序列过长和生成效率低下。

Method: 该框架将顶点和面分开处理，仅对顶点使用自回归模型，显著减少了token数量（约为现有最紧凑分词器的23%）。然后，利用双向Transformer一步完成网格生成，捕捉顶点间的关系并构建定义网格面的邻接矩阵。此外，还引入保真度增强器优化顶点位置，并进行后处理去除不良的连接边。

Result: 与现有技术相比，该方法在网格生成速度上提高了8倍以上，同时获得了更高的网格质量。

Conclusion: 所提出的框架通过分离顶点和面的生成过程，并结合双向Transformer、保真度增强器和后处理技术，有效地解决了现有方法的冗余问题，实现了更快速、更高质量的艺术网格生成。

Abstract: Recent mesh generation approaches typically tokenize triangle meshes into
sequences of tokens and train autoregressive models to generate these tokens
sequentially. Despite substantial progress, such token sequences inevitably
reuse vertices multiple times to fully represent manifold meshes, as each
vertex is shared by multiple faces. This redundancy leads to excessively long
token sequences and inefficient generation processes. In this paper, we propose
an efficient framework that generates artistic meshes by treating vertices and
faces separately, significantly reducing redundancy. We employ an
autoregressive model solely for vertex generation, decreasing the token count
to approximately 23\% of that required by the most compact existing tokenizer.
Next, we leverage a bidirectional transformer to complete the mesh in a single
step by capturing inter-vertex relationships and constructing the adjacency
matrix that defines the mesh faces. To further improve the generation quality,
we introduce a fidelity enhancer to refine vertex positioning into more natural
arrangements and propose a post-processing framework to remove undesirable edge
connections. Experimental results show that our method achieves more than
8$\times$ faster speed on mesh generation compared to state-of-the-art
approaches, while producing higher mesh quality.

</details>


### [68] [All-in-One Slider for Attribute Manipulation in Diffusion Models](https://arxiv.org/abs/2508.19195)
*Weixin Ye,Hongguang Zhu,Wei Wang,Yahui Liu,Mengyu Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为“All-in-One Slider”的轻量级模块，用于解决文本到图像生成模型中属性操纵的挑战，通过将文本嵌入空间分解为稀疏、有意义的属性方向，实现了对多种属性的精细、连续控制，并支持零样本操纵和多属性组合，相比现有方法有显著提升，且可应用于真实图像。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在生成高质量图像方面取得了显著进展，但在对生成图像的特定属性进行渐进式操纵以满足用户期望方面仍面临挑战，尤其是在处理细节丰富的图像（如人脸）时。现有的解决方案（如训练独立的滑块模块）存在参数冗余、需要为新属性重新训练以及灵活性和可扩展性受限等问题。

Method: 提出“All-in-One Slider”模块，将文本嵌入空间分解为稀疏、有意义的属性方向。训练后，该模块可作为通用滑块，实现对多种属性的可解释、精细、连续控制。通过重组学习到的方向，支持对未见属性（如种族、名人）的零样本操纵和多属性组合。

Result: 通过大量实验证明，“All-in-One Slider”能够实现准确、可扩展的属性操纵，相比现有方法有显著改进。此外，该方法可与反演框架集成，对真实图像进行属性操纵，扩展了其在各种现实场景中的应用。

Conclusion: “All-in-One Slider”是一种轻量级、可扩展且灵活的模块，能够有效地解决文本到图像生成模型中的属性操纵问题，支持零样本和多属性组合，并在真实图像上实现了应用，为该领域带来了显著的进步。

Abstract: Text-to-image (T2I) diffusion models have made significant strides in
generating high-quality images. However, progressively manipulating certain
attributes of generated images to meet the desired user expectations remains
challenging, particularly for content with rich details, such as human faces.
Some studies have attempted to address this by training slider modules.
However, they follow a One-for-One manner, where an independent slider is
trained for each attribute, requiring additional training whenever a new
attribute is introduced. This not only results in parameter redundancy
accumulated by sliders but also restricts the flexibility of practical
applications and the scalability of attribute manipulation. To address this
issue, we introduce the All-in-One Slider, a lightweight module that decomposes
the text embedding space into sparse, semantically meaningful attribute
directions. Once trained, it functions as a general-purpose slider, enabling
interpretable and fine-grained continuous control over various attributes.
Moreover, by recombining the learned directions, the All-in-One Slider supports
zero-shot manipulation of unseen attributes (e.g., races and celebrities) and
the composition of multiple attributes. Extensive experiments demonstrate that
our method enables accurate and scalable attribute manipulation, achieving
notable improvements compared to previous methods. Furthermore, our method can
be extended to integrate with the inversion framework to perform attribute
manipulation on real images, broadening its applicability to various real-world
scenarios. The code and trained model will be released at:
https://github.com/ywxsuperstar/KSAE-FaceSteer.

</details>


### [69] [OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation](https://arxiv.org/abs/2508.19209)
*Jianwen Jiang,Weihong Zeng,Zerong Zheng,Jiaqi Yang,Chao Liang,Wang Liao,Han Liang,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: 该研究提出了一种名为OmniHuman-1.5的新型视频虚拟人动画生成框架，利用多模态大语言模型提供语义指导，并通过特殊的多模态DiT架构融合多模态信息，以生成在身体上逼真且在语义上连贯、富有表现力的动画。


<details>
  <summary>Details</summary>
Motivation: 现有的视频虚拟人模型虽然能生成流畅的动画，但在捕捉角色的真实情感、意图或情境等深层语义理解方面存在不足，通常仅能同步低级线索（如音频节奏）。本研究旨在弥合这一差距，生成不仅身体上逼真，而且在语义上连贯且富有表现力的角色动画。

Method: 研究提出的OmniHuman-1.5框架包含两项关键技术贡献：1. 利用多模态大语言模型（MLLM）合成结构化的文本表示，提供高级语义指导，使运动生成超越简单的节奏同步，实现与情境和情感的共鸣。2. 引入专门的多模态DiT（Diffusion Transformer）架构，并采用创新的伪最后一帧（Pseudo Last Frame）设计，以有效融合多模态输入并减轻跨模态冲突。

Result: 实验结果表明，该模型在唇形同步精度、视频质量、动作自然度和与文本提示的语义一致性等综合指标上均达到领先水平。此外，该方法在涉及多人和非人主体的复杂场景中也展现出优异的可扩展性。

Conclusion: OmniHuman-1.5框架通过结合MLLM的语义指导和改进的多模态DiT架构，能够准确理解音频、图像和文本的联合语义，生成与角色、场景和语言内容深度一致的动画，在各种评估指标和复杂场景下均表现出色。

Abstract: Existing video avatar models can produce fluid human animations, yet they
struggle to move beyond mere physical likeness to capture a character's
authentic essence. Their motions typically synchronize with low-level cues like
audio rhythm, lacking a deeper semantic understanding of emotion, intent, or
context. To bridge this gap, \textbf{we propose a framework designed to
generate character animations that are not only physically plausible but also
semantically coherent and expressive.} Our model, \textbf{OmniHuman-1.5}, is
built upon two key technical contributions. First, we leverage Multimodal Large
Language Models to synthesize a structured textual representation of conditions
that provides high-level semantic guidance. This guidance steers our motion
generator beyond simplistic rhythmic synchronization, enabling the production
of actions that are contextually and emotionally resonant. Second, to ensure
the effective fusion of these multimodal inputs and mitigate inter-modality
conflicts, we introduce a specialized Multimodal DiT architecture with a novel
Pseudo Last Frame design. The synergy of these components allows our model to
accurately interpret the joint semantics of audio, images, and text, thereby
generating motions that are deeply coherent with the character, scene, and
linguistic content. Extensive experiments demonstrate that our model achieves
leading performance across a comprehensive set of metrics, including lip-sync
accuracy, video quality, motion naturalness and semantic consistency with
textual prompts. Furthermore, our approach shows remarkable extensibility to
complex scenarios, such as those involving multi-person and non-human subjects.
Homepage: \href{https://omnihuman-lab.github.io/v1_5/}

</details>


### [70] [Automated Feature Tracking for Real-Time Kinematic Analysis and Shape Estimation of Carbon Nanotube Growth](https://arxiv.org/abs/2508.19232)
*Kaveh Safavigerdini,Ramakrishna Surya,Jaired Collins,Prasad Calyam,Filiz Bunyak,Matthew R. Maschmann,Kannappan Palaniappan*

Main category: cs.CV

TL;DR: 该研究提出了一种名为VFTrack的在位实时粒子跟踪框架，用于自动检测和跟踪扫描电子显微镜图像序列中的碳纳米管（CNT）粒子，以分析其动态生长过程。


<details>
  <summary>Details</summary>
Motivation: 实验挑战限制了对扫描电子显微镜（SEM）成像的纳米尺度运动测量的表征，现有的异位方法仅提供静态分析，而在位技术需要手动初始化且缺乏连续的单粒子轨迹分解。

Method: VFTrack框架集成了手工制作或深度特征检测器和匹配器，通过在位实时跟踪和运动矢量分解（轴向生长、侧向漂移和振荡）来分析CNT微柱的生长。

Result: 通过对13,540条手动标注轨迹的系统性分析，确定ALIKED检测器和LightGlue匹配器是最佳组合（F1分数0.78，α分数0.89）。该方法能够计算异质区域的生长速率并重建不断演变的CNT柱形态。

Conclusion: VFTrack的运动分析能力实现了自动化纳米材料表征，并为优化CNT合成提供了实时实验观察，弥合了基于物理的模型和实验观察之间的差距。

Abstract: Carbon nanotubes (CNTs) are critical building blocks in nanotechnology, yet
the characterization of their dynamic growth is limited by the experimental
challenges in nanoscale motion measurement using scanning electron microscopy
(SEM) imaging. Existing ex situ methods offer only static analysis, while in
situ techniques often require manual initialization and lack continuous
per-particle trajectory decomposition. We present Visual Feature Tracking
(VFTrack) an in-situ real-time particle tracking framework that automatically
detects and tracks individual CNT particles in SEM image sequences. VFTrack
integrates handcrafted or deep feature detectors and matchers within a particle
tracking framework to enable kinematic analysis of CNT micropillar growth. A
systematic using 13,540 manually annotated trajectories identifies the ALIKED
detector with LightGlue matcher as an optimal combination (F1-score of 0.78,
$\alpha$-score of 0.89). VFTrack motion vectors decomposed into axial growth,
lateral drift, and oscillations, facilitate the calculation of heterogeneous
regional growth rates and the reconstruction of evolving CNT pillar
morphologies. This work enables advancement in automated nano-material
characterization, bridging the gap between physics-based models and
experimental observation to enable real-time optimization of CNT synthesis.

</details>


### [71] [Autoregressive Universal Video Segmentation Model](https://arxiv.org/abs/2508.19242)
*Miran Heo,Sukjun Hwang,Min-Hung Chen,Yu-Chiang Frank Wang,Albert Gu,Seon Joo Kim,Ryo Hachiuma*

Main category: cs.CV

TL;DR: AUSM是一个统一了提示式和非提示式视频分割的单一模型，它将视频分割视为序列掩码预测，并实现了高效的训练。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视频分割任务通常需要无提示分割，而现有模型分散在特定任务的模型和流程中。因此，需要一个能够统一处理提示式和非提示式分割的通用模型。

Method: AUSM将流式视频分割问题重新定义为序列掩码预测，并借鉴了语言模型的思想。它基于状态空间模型，维护一个固定大小的空间状态，能够处理任意长度的视频流。同时，AUSM的所有组件都支持跨帧并行训练，提高了训练效率。

Result: AUSM在DAVIS17、YouTube-VOS 2018 & 2019、MOSE、YouTube-VIS 2019 & 2021和OVIS等标准基准测试中，优于现有的通用流式视频分割方法，并且在16帧序列上的训练速度最高可提升2.5倍。

Conclusion: AUSM通过将视频分割视为序列掩码预测，成功地统一了提示式和非提示式分割，并在性能和训练效率上均取得了显著的提升，

Abstract: Recent video foundation models such as SAM2 excel at prompted video
segmentation by treating masks as a general-purpose primitive. However, many
real-world settings require unprompted segmentation that aims to detect and
track all objects in a video without external cues, leaving today's landscape
fragmented across task-specific models and pipelines. We recast streaming video
segmentation as sequential mask prediction, analogous to language modeling, and
introduce the Autoregressive Universal Segmentation Model (AUSM), a single
architecture that unifies both prompted and unprompted video segmentation.
Built on recent state-space models, AUSM maintains a fixed-size spatial state
and scales to video streams of arbitrary length. Furthermore, all components of
AUSM are designed for parallel training across frames, yielding substantial
speedups over iterative training. On standard benchmarks (DAVIS17, YouTube-VOS
2018 & 2019, MOSE, YouTube-VIS 2019 & 2021, and OVIS) AUSM outperforms prior
universal streaming video segmentation methods and achieves up to 2.5x faster
training on 16-frame sequences.

</details>


### [72] [Style4D-Bench: A Benchmark Suite for 4D Stylization](https://arxiv.org/abs/2508.19243)
*Beiqi Chen,Shuai Shao,Haitang Feng,Jianhuang Lai,Jianlou Si,Guangcong Wang*

Main category: cs.CV

TL;DR: Style4D-Bench是首个针对4D风格化设计的基准套件，包含评估协议、基线模型Style4D和数据集，旨在标准化评估并推动该领域发展。Style4D基于4D高斯泼溅技术，通过风格高斯表示和保持几何的风格迁移模块实现了高质量的4D风格化。


<details>
  <summary>Details</summary>
Motivation: 为了标准化4D风格化的评估，促进该新兴领域的进步。

Method: 提出Style4D-Bench基准套件，包含评估协议（空间保真度、时间一致性和多视图一致性）、基线模型Style4D（基于4D高斯泼溅，包含4DGS场景表示、风格高斯表示和整体几何保持风格迁移模块）以及数据集。

Result: Style4D在Style4D-Bench上实现了最先进的4D风格化性能，能够生成具有精细风格细节、稳定时间动态和一致多视图渲染的效果。

Conclusion: Style4D-Bench将成为评估和推进动态3D场景风格化渲染研究的有价值资源。

Abstract: We introduce Style4D-Bench, the first benchmark suite specifically designed
for 4D stylization, with the goal of standardizing evaluation and facilitating
progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive
evaluation protocol measuring spatial fidelity, temporal coherence, and
multi-view consistency through both perceptual and quantitative metrics, 2) a
strong baseline that make an initial attempt for 4D stylization, and 3) a
curated collection of high-resolution dynamic 4D scenes with diverse motions
and complex backgrounds. To establish a strong baseline, we present Style4D, a
novel framework built upon 4D Gaussian Splatting. It consists of three key
components: a basic 4DGS scene representation to capture reliable geometry, a
Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for
temporally and spatially aware appearance control, and a Holistic
Geometry-Preserved Style Transfer module designed to enhance spatio-temporal
consistency via contrastive coherence learning and structural content
preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D
achieves state-of-the-art performance in 4D stylization, producing fine-grained
stylistic details with stable temporal dynamics and consistent multi-view
rendering. We expect Style4D-Bench to become a valuable resource for
benchmarking and advancing research in stylized rendering of dynamic 3D scenes.
Project page: https://becky-catherine.github.io/Style4D . Code:
https://github.com/Becky-catherine/Style4D-Bench .

</details>


### [73] [Articulate3D: Zero-Shot Text-Driven 3D Object Posing](https://arxiv.org/abs/2508.19244)
*Oishi Deb,Anjun Hu,Ashkan Khakzar,Philip Torr,Christian Rupprecht*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a training-free method, Articulate3D, to pose a 3D asset through
language control. Despite advances in vision and language models, this task
remains surprisingly challenging. To achieve this goal, we decompose the
problem into two steps. We modify a powerful image-generator to create target
images conditioned on the input image and a text instruction. We then align the
mesh to the target images through a multi-view pose optimisation step. In
detail, we introduce a self-attention rewiring mechanism (RSActrl) that
decouples the source structure from pose within an image generative model,
allowing it to maintain a consistent structure across varying poses. We
observed that differentiable rendering is an unreliable signal for articulation
optimisation; instead, we use keypoints to establish correspondences between
input and target images. The effectiveness of Articulate3D is demonstrated
across a diverse range of 3D objects and free-form text prompts, successfully
manipulating poses while maintaining the original identity of the mesh.
Quantitative evaluations and a comparative user study, in which our method was
preferred over 85\% of the time, confirm its superiority over existing
approaches. Project page:https://odeb1.github.io/articulate3d_page_deb/

</details>


### [74] [VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space](https://arxiv.org/abs/2508.19247)
*Lin Li,Zehuan Huang,Haoran Feng,Gengxiong Zhuang,Rui Chen,Chunchao Guo,Lu Sheng*

Main category: cs.CV

TL;DR: VoxHammer通过在3D潜在空间中进行精确和连贯的编辑，解决了现有3D模型编辑方法在保留未编辑区域和整体连贯性方面面临的挑战。该方法首先通过预测模型的逆转轨迹来获取其逆转的潜在表示和关键值令牌，然后在去噪和编辑阶段，用这些缓存的特征替换受保护区域的去噪特征，从而确保了保留区域的一致性重构和编辑部分的连贯集成。为了评估保留区域的一致性，研究人员构建了一个名为Edit3D-Bench的人工标注数据集。实验结果表明，VoxHammer在保留区域的3D一致性和整体质量方面显著优于现有方法，为在上下文中合成高质量的编辑配对数据奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 3D局部编辑在游戏行业和机器人交互中至关重要。然而，现有的方法在编辑渲染的多视图图像后重建3D模型时，难以精确保留未编辑区域和保持整体连贯性。

Method: VoxHammer是一种无需训练的方法，它首先预测给定3D模型的逆转轨迹，并获取其在每个时间步的逆转潜在表示和键值对（key-value tokens）。在去噪和编辑阶段，通过用缓存的逆转潜在表示和键值对替换保留区域的去噪特征，从而在3D潜在空间中实现精确和连贯的编辑。

Result: VoxHammer在Edit3D-Bench（一个包含数百个样本的人工标注数据集）上进行了评估，实验结果表明，与现有方法相比，VoxHammer在保留区域的3D一致性和整体质量方面均有显著提升。

Conclusion: VoxHammer在3D潜在空间中实现了精确和连贯的编辑，解决了现有方法的局限性。它能够有效保留未编辑区域并保证整体一致性，为生成高质量的编辑3D数据和在上下文中进行3D生成提供了新的可能性。

Abstract: 3D local editing of specified regions is crucial for game industry and robot
interaction. Recent methods typically edit rendered multi-view images and then
reconstruct 3D models, but they face challenges in precisely preserving
unedited regions and overall coherence. Inspired by structured 3D generative
models, we propose VoxHammer, a novel training-free approach that performs
precise and coherent editing in 3D latent space. Given a 3D model, VoxHammer
first predicts its inversion trajectory and obtains its inverted latents and
key-value tokens at each timestep. Subsequently, in the denoising and editing
phase, we replace the denoising features of preserved regions with the
corresponding inverted latents and cached key-value tokens. By retaining these
contextual features, this approach ensures consistent reconstruction of
preserved areas and coherent integration of edited parts. To evaluate the
consistency of preserved regions, we constructed Edit3D-Bench, a
human-annotated dataset comprising hundreds of samples, each with carefully
labeled 3D editing regions. Experiments demonstrate that VoxHammer
significantly outperforms existing methods in terms of both 3D consistency of
preserved regions and overall quality. Our method holds promise for
synthesizing high-quality edited paired data, thereby laying the data
foundation for in-context 3D generation. See our project page at
https://huanngzh.github.io/VoxHammer-Page/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [75] [Semantic Attractors and the Emergence of Meaning: Towards a Teleological Model of AGI](https://arxiv.org/abs/2508.18290)
*Hans-Joachim Rudolph*

Main category: cs.CL

TL;DR: 该论文提出了一个基于复值含义空间中语义吸引子的语义通用人工智能（AGI）理论框架，并与当前基于Transformer的语言模型进行了区分。


<details>
  <summary>Details</summary>
Motivation: 论文旨在探索一种新的AGI模型，该模型不依赖于统计上的下一个词预测，而是通过递归张量变换形成意义，并能够处理讽刺、同形异义词和歧义等语义现象。

Method: 论文提出了一种使用涉及虚数单位i的循环运算的旋转语义结构，并引入了一个中心化的语义吸引子（Microvitum）。该吸引子被设想为一种目的论算子，能够引导意义趋向稳定、清晰和表达深度，其运作方式被描述为梯度流、张量变形和迭代矩阵动力学。

Result: 通过这种方式，论文提供了一种在数学上和哲学上都具有启发性的语义转换模型。

Conclusion: 论文认为，真正的意义并非源于模拟，而是源于向语义连贯性的递归收敛，这需要一种能够塑造语言而非仅仅预测语言的新认知架构。

Abstract: This essay develops a theoretical framework for a semantic Artificial General
Intelligence (AGI) based on the notion of semantic attractors in complex-valued
meaning spaces. Departing from current transformer-based language models, which
operate on statistical next-token prediction, we explore a model in which
meaning is not inferred probabilistically but formed through recursive
tensorial transformation. Using cyclic operations involving the imaginary unit
\emph{i}, we describe a rotational semantic structure capable of modeling
irony, homonymy, and ambiguity. At the center of this model, however, is a
semantic attractor -- a teleological operator that, unlike statistical
computation, acts as an intentional agent (Microvitum), guiding meaning toward
stability, clarity, and expressive depth. Conceived in terms of gradient flows,
tensor deformations, and iterative matrix dynamics, the attractor offers a
model of semantic transformation that is not only mathematically suggestive,
but also philosophically significant. We argue that true meaning emerges not
from simulation, but from recursive convergence toward semantic coherence, and
that this requires a fundamentally new kind of cognitive architecture -- one
designed to shape language, not just predict it.

</details>


### [76] [LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions](https://arxiv.org/abs/2508.18321)
*Maojia Song,Tej Deep Pala,Weisheng Jin,Amir Zadeh,Chuan Li,Dorien Herremans,Soujanya Poria*

Main category: cs.CL

TL;DR: 该研究通过KAIROS基准测试，研究了大型语言模型（LLMs）在多智能体系统（MAS）中如何从信任、同伴输入和自我信心等方面进行决策，并评估了多种缓解策略，发现GRPO策略在多数情况下表现最佳，但会降低模型对社会影响的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在多智能体系统中如何形成信任、抵制虚假信息以及整合同伴输入，以实现集体智能。

Method: 提出KAIROS基准测试，模拟包含不同可靠性同伴智能体的智力竞赛，并评估了提示、监督微调和强化学习（GRPO）等缓解策略。

Result: GRPO策略结合多智能体上下文、基于结果的奖励和无约束推理，在大多数情况下表现最佳，但与基础模型相比，其对社会影响的鲁棒性有所下降。

Conclusion: GRPO是一种有前景的策略，但需要进一步研究以提高其在面对社会影响时的鲁棒性。

Abstract: Large language models (LLMs) are increasingly deployed in multi-agent systems
(MAS) as components of collaborative intelligence, where peer interactions
dynamically shape individual decision-making. Although prior work has focused
on conformity bias, we extend the analysis to examine how LLMs form trust from
previous impressions, resist misinformation, and integrate peer input during
interaction, key factors for achieving collective intelligence under complex
social dynamics. We present KAIROS, a benchmark simulating quiz contests with
peer agents of varying reliability, offering fine-grained control over
conditions such as expert-novice roles, noisy crowds, and adversarial peers.
LLMs receive both historical interactions and current peer responses, allowing
systematic investigation into how trust, peer action, and self-confidence
influence decisions. As for mitigation strategies, we evaluate prompting,
supervised fine-tuning, and reinforcement learning, Group Relative Policy
Optimisation (GRPO), across multiple models. Our results reveal that GRPO with
multi-agent context combined with outcome-based rewards and unconstrained
reasoning achieves the best overall performance, but also decreases the
robustness to social influence compared to Base models. The code and datasets
are available at: https://github.com/declare-lab/KAIROS.

</details>


### [77] [Not All Visitors are Bilingual: A Measurement Study of the Multilingual Web from an Accessibility Perspective](https://arxiv.org/abs/2508.18328)
*Masudul Hasan Masud Bhuiyan,Matteo Varvello,Yasir Zaki,Cristian-Alexandru Staicu*

Main category: cs.CL

TL;DR: 英文是网络的主要语言，但多语言内容不断增长，给有视力障碍的用户带来了障碍。本研究引入LangCrUX数据集，分析了120,000个使用非拉丁字母的网站，发现语言提示存在普遍的可用性问题，并提出了Kizuki工具来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 由于屏幕阅读器等辅助技术对非拉丁字母支持不足，多语言内容给视力障碍用户带来了可访问性挑战。现有的研究受到缺乏多语言网络内容的综合数据集的限制。

Method: 利用LangCrUX数据集，对120,000个使用非拉丁字母的网站进行了多语言网络可访问性分析。

Result: 研究发现，可访问性提示未能反映内容的语言多样性，降低了屏幕阅读器的有效性。

Conclusion: 提出了Kizuki，一种能感知语言的自动化可访问性测试扩展，以解决语言不兼容的可访问性提示的有限效用。

Abstract: English is the predominant language on the web, powering nearly half of the
world's top ten million websites. Support for multilingual content is
nevertheless growing, with many websites increasingly combining English with
regional or native languages in both visible content and hidden metadata. This
multilingualism introduces significant barriers for users with visual
impairments, as assistive technologies like screen readers frequently lack
robust support for non-Latin scripts and misrender or mispronounce non-English
text, compounding accessibility challenges across diverse linguistic contexts.
Yet, large-scale studies of this issue have been limited by the lack of
comprehensive datasets on multilingual web content. To address this gap, we
introduce LangCrUX, the first large-scale dataset of 120,000 popular websites
across 12 languages that primarily use non-Latin scripts. Leveraging this
dataset, we conduct a systematic analysis of multilingual web accessibility and
uncover widespread neglect of accessibility hints. We find that these hints
often fail to reflect the language diversity of visible content, reducing the
effectiveness of screen readers and limiting web accessibility. We finally
propose Kizuki, a language-aware automated accessibility testing extension to
account for the limited utility of language-inconsistent accessibility hints.

</details>


### [78] [LLM-based Contrastive Self-Supervised AMR Learning with Masked Graph Autoencoders for Fake News Detection](https://arxiv.org/abs/2508.18819)
*Shubham Gupta,Shraban Kumar Chatterjee,Suman Kundu*

Main category: cs.CL

TL;DR: 提出一种新的自监督虚假信息检测框架，结合了抽象意义表示（AMR）的复杂语义关系和新闻传播动态，并引入了基于大语言模型（LLM）的图对比损失（LGCL）和多视图图掩码自动编码器，在有限标记数据集上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的虚假信息检测方法难以捕捉长距离依赖、复杂的语义关系和影响新闻传播的社会动态，并且需要大量的标记数据集，部署成本高。

Method: 提出一种新的自监督虚假信息检测框架。使用 AMR 捕捉复杂语义关系，使用新闻传播动态。引入 LLM-based graph contrastive loss (LGCL) 利用 LLM 生成的负样本锚点，以零样本方式增强特征可分离性。采用多视图图掩码自动编码器学习社会背景图的新闻传播特征。结合语义和传播特征进行虚假信息检测。

Result: 该框架在虚假信息检测任务上表现优于现有最先进的方法，即使在标记数据集有限的情况下也能提高性能和泛化能力。

Conclusion: 该自监督框架通过结合语义和传播特征，有效地区分了虚假新闻和真实新闻，并在实验中证明了其优越性。

Abstract: The proliferation of misinformation in the digital age has led to significant
societal challenges. Existing approaches often struggle with capturing
long-range dependencies, complex semantic relations, and the social dynamics
influencing news dissemination. Furthermore, these methods require extensive
labelled datasets, making their deployment resource-intensive. In this study,
we propose a novel self-supervised misinformation detection framework that
integrates both complex semantic relations using Abstract Meaning
Representation (AMR) and news propagation dynamics. We introduce an LLM-based
graph contrastive loss (LGCL) that utilizes negative anchor points generated by
a Large Language Model (LLM) to enhance feature separability in a zero-shot
manner. To incorporate social context, we employ a multi view graph masked
autoencoder, which learns news propagation features from social context graph.
By combining these semantic and propagation-based features, our approach
effectively differentiates between fake and real news in a self-supervised
manner. Extensive experiments demonstrate that our self-supervised framework
achieves superior performance compared to other state-of-the-art methodologies,
even with limited labelled datasets while improving generalizability.

</details>


### [79] [Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models](https://arxiv.org/abs/2508.18381)
*Yuchun Fan,Yilin Wang,Yongyu Mu,Lei Huang,Bei Li,Xiaocheng Feng,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: LVLM在多语言能力上存在不平衡，本研究通过精调语言特定层来提升其多语言能力，并取得显著效果。


<details>
  <summary>Details</summary>
Motivation: LVLM在多语言理解能力上存在不平衡，需要对其进行提升。

Method: 提出PLAST训练方法，通过监控语言特定神经元激活来识别涉及多语言理解的层，并使用问答翻译对进行精调。

Result: PLAST有效提升了LVLM的多语言能力，仅调整14%的参数即可实现显著效率提升，并且可以泛化到低资源和复杂视觉推理任务。

Conclusion: PLAST通过精调浅层语言特定层，有效提升了LVLM的多语言能力，并具有良好的泛化性。

Abstract: Large vision-language models (LVLMs) have demonstrated exceptional
capabilities in understanding visual information with human languages but also
exhibit an imbalance in multilingual capabilities. In this work, we delve into
the multilingual working pattern of LVLMs and identify a salient correlation
between the multilingual understanding ability of LVLMs and language-specific
neuron activations in shallow layers. Building on this insight, we introduce
PLAST, a training recipe that achieves efficient multilingual enhancement for
LVLMs by Precise LAnguage-Specific layers fine-Tuning. PLAST first identifies
layers involved in multilingual understanding by monitoring language-specific
neuron activations. These layers are then precisely fine-tuned with
question-translation pairs to achieve multilingual alignment. Our empirical
results on MM-Bench and MMMB demonstrate that PLAST effectively improves the
multilingual capabilities of LVLMs and achieves significant efficiency with
only 14% of the parameters tuned. Further analysis reveals that PLAST can be
generalized to low-resource and complex visual reasoning tasks, facilitating
the language-specific visual information engagement in shallow layers.

</details>


### [80] [Affective Polarization across European Parliaments](https://arxiv.org/abs/2508.18916)
*Bojan Evkoski,Igor Mozetič,Nikola Ljubešić,Petra Kralj Novak*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Affective polarization, characterized by increased negativity and hostility
towards opposing groups, has become a prominent feature of political discourse
worldwide. Our study examines the presence of this type of polarization in a
selection of European parliaments in a fully automated manner. Utilizing a
comprehensive corpus of parliamentary speeches from the parliaments of six
European countries, we employ natural language processing techniques to
estimate parliamentarian sentiment. By comparing the levels of negativity
conveyed in references to individuals from opposing groups versus one's own, we
discover patterns of affectively polarized interactions. The findings
demonstrate the existence of consistent affective polarization across all six
European parliaments. Although activity correlates with negativity, there is no
observed difference in affective polarization between less active and more
active members of parliament. Finally, we show that reciprocity is a
contributing mechanism in affective polarization between parliamentarians
across all six parliaments.

</details>


### [81] [Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails](https://arxiv.org/abs/2508.18384)
*Kellen Tan Cheng,Anna Lisa Gentile,Chad DeLuca,Guang-Jie Ren*

Main category: cs.CL

TL;DR: LLM安全面临挑战，提出反向提示技术生成合成数据，用于开发健康建议防护栏，并优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: LLM在企业中的广泛使用带来了风险，需要Guardrails技术来过滤输入/输出文本，但开发和维护鲁棒的检测器面临数据获取困难的挑战。

Method: 提出反向提示技术生成生产质量的标记数据，并结合稀疏的“人机循环”聚类技术来标记生成的数据，以构建与原始数据集相似但又类似于真实LLM输出的平行语料库，并将其融入现有数据集以增强检测器训练数据。

Result: 在识别LLM输出中的健康建议这一困难且细微的防护栏任务中，提出的检测器比其他解决方案有改善，并且比GPT-4o高出3.73%，尽管参数量少400倍。

Conclusion: 反向提示技术是一种简单直观的解决方案，可以为开发健康建议防护栏生成生产质量的标记数据，并能在不增加大量参数的情况下提高检测器的性能。

Abstract: The pervasiveness of large language models (LLMs) in enterprise settings has
also brought forth a significant amount of risks associated with their usage.
Guardrails technologies aim to mitigate this risk by filtering LLMs'
input/output text through various detectors. However, developing and
maintaining robust detectors faces many challenges, one of which is the
difficulty in acquiring production-quality labeled data on real LLM outputs
prior to deployment. In this work, we propose backprompting, a simple yet
intuitive solution to generate production-like labeled data for health advice
guardrails development. Furthermore, we pair our backprompting method with a
sparse human-in-the-loop clustering technique to label the generated data. Our
aim is to construct a parallel corpus roughly representative of the original
dataset yet resembling real LLM output. We then infuse existing datasets with
our synthetic examples to produce robust training data for our detector. We
test our technique in one of the most difficult and nuanced guardrails: the
identification of health advice in LLM output, and demonstrate improvement
versus other solutions. Our detector is able to outperform GPT-4o by up to
3.73%, despite having 400x less parameters.

</details>


### [82] [Integral Transformer: Denoising Attention, Not Too Much Not Too Little](https://arxiv.org/abs/2508.18387)
*Ivan Kobyzev,Abbas Ghaddar,Dingtao Hu,Boxing Chen*

Main category: cs.CL

TL;DR: Integral Transformer通过集成来自logit分布的信号来去除注意力噪声，并在多个基准测试中优于现有方法，同时保留了对模型性能至关重要的特殊标记的贡献。


<details>
  <summary>Details</summary>
Motivation: Softmax自注意力倾向于给予语义上信息量少的标记（如特殊标记和标点符号）不成比例的权重，这种现象被称为注意力噪声。虽然现有的方法（如Cog Attention和Differential Transformer）通过引入负注意力分数来解决这个问题，但它们存在丢弃有用信息的风险。

Method: Integral Transformer是一种新颖的自注意力机制，它通过集成从logit分布采样的信号来去除注意力噪声，从而减轻噪声，同时保留对模型性能至关重要的特殊标记的贡献。

Result: 实验表明，Integral Transformer在知识和推理语言基准测试中优于Vanilla、Cog和Differential注意力变体。此外，在较低的Transformer层中使用Vanilla自注意力可以提高性能，而在较高的层中，Integral Transformer能有效地平衡注意力分布并减少秩崩溃。

Conclusion: Integral Transformer通过集成logit分布信号有效解决了注意力噪声问题，在保持模型性能的同时，降低了噪声的影响，并且在Transformer的各层中表现出不同的优势，可以平衡注意力分布和减少秩崩溃。

Abstract: Softmax self-attention often assigns disproportionate weight to semantically
uninformative tokens such as special tokens and punctuation, a phenomenon known
as attention noise. While recent methods like Cog Attention and the
Differential Transformer have addressed this by introducing negative attention
scores, they risk discarding useful information. In this paper, we propose the
Integral Transformer, a novel self-attention mechanism that denoises attention
by integrating signals sampled from the logit distribution. Our approach
mitigates noise while preserving the contributions of special tokens critical
for model performance. Extensive experiments demonstrate that our model
outperforms vanilla, Cog, and Differential attention variants on
well-established knowledge and reasoning language benchmarks. Moreover, our
analysis reveals that employing vanilla self-attention in the lower Transformer
layers enhances performance and that the Integral Transformer effectively
balances attention distributions and reduces rank collapse in upper layers.

</details>


### [83] [Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning](https://arxiv.org/abs/2508.18395)
*Jeong-seok Oh,Jay-yoon Lee*

Main category: cs.CL

TL;DR: LSC通过使用可学习的词嵌入来选择最符合语义的响应，在短格式和长格式推理基准上都优于现有方法，同时计算开销可忽略不计，并提供良好的置信度估计。


<details>
  <summary>Details</summary>
Motivation: LLM在处理复杂或长篇问题时，概率解码会导致输出不一致。现有的自我一致性方法（SC、USC、WUCS）在长格式响应方面效果不佳，而LSC旨在解决这个问题。

Method: LSC通过生成摘要令牌的轻量级前向传播来选择最符合语义的响应，使用可学习的词嵌入，并且不需要改变模型架构。

Result: LSC在6个短格式和5个长格式推理基准上，平均而言优于SC、USC和WUCS，同时计算开销极小。此外，LSC在两种格式下都保持了较低的期望校准误差。

Conclusion: LSC是一种实用的、可靠的、跨答案格式的一致性选择方法，它在保持可忽略的计算开销的同时，提高了LLM在各种任务中的一致性和准确性，并提供了良好的置信度估计。

Abstract: Probabilistic decoding in Large Language Models (LLMs) often yields
inconsistent outputs, particularly on complex or long-form questions.
Self-Consistency (SC) mitigates this for short-form QA by majority voting over
exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram
Consistency Score (WUCS) extend to long-form responses but lose accuracy on
short-form benchmarks.
  We introduce Latent Self-Consistency (LSC), which selects the most
semantically consistent response using learnable token embeddings. A
lightweight forward generation of summary tokens increases inference time by
less than 1% and requires no changes to the model architecture.
  Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU,
TruthfulQA), LSC surpasses SC, USC and WUCS on all short-form and long-form
ones on average, while maintaining negligible computational overhead. These
results position LSC as a practical consistency-selection method that works
reliably across answer formats. Additionally, LSC provides well-calibrated
confidence estimates, maintaining low Expected Calibration Error across both
answer formats.

</details>


### [84] [Can Out-of-Distribution Evaluations Uncover Reliance on Shortcuts? A Case Study in Question Answering](https://arxiv.org/abs/2508.18407)
*Michal Štefánik,Timothee Mickus,Marek Kadlčík,Michal Spiegel,Josef Kuchař*

Main category: cs.CL

TL;DR: OOD评估在QA中的有效性存在疑问，部分原因在于常见的“捷径”缺陷，并且不同OOD数据集的评估质量差异很大。


<details>
  <summary>Details</summary>
Motivation: 评估AI模型泛化能力的方法，特别是OOD（out-of-distribution）评估，其有效性可能存在问题，尤其是在自然语言处理的问答（QA）任务中。

Method: 通过对比QA模型在OOD数据集上的表现和特定的失效模式（如依赖虚假特征或预测捷径），来挑战OOD评估的有效性。

Result: 研究发现，不同的OOD数据集在评估QA模型对“捷径”的鲁棒性方面，其评估质量差异很大，有些甚至不如简单的ID（in-distribution）评估。虚假“捷径”在ID和OOD数据集中普遍存在，但也有数据集的训练和评估质量之间存在脱节。

Conclusion: 现有的基于OOD的泛化能力评估方法存在局限性，并提出了一种更可靠的评估泛化能力的方法和建议，适用于QA任务乃至更广泛的领域。

Abstract: A majority of recent work in AI assesses models' generalization capabilities
through the lens of performance on out-of-distribution (OOD) datasets. Despite
their practicality, such evaluations build upon a strong assumption: that OOD
evaluations can capture and reflect upon possible failures in a real-world
deployment.
  In this work, we challenge this assumption and confront the results obtained
from OOD evaluations with a set of specific failure modes documented in
existing question-answering (QA) models, referred to as a reliance on spurious
features or prediction shortcuts.
  We find that different datasets used for OOD evaluations in QA provide an
estimate of models' robustness to shortcuts that have a vastly different
quality, some largely under-performing even a simple, in-distribution
evaluation. We partially attribute this to the observation that spurious
shortcuts are shared across ID+OOD datasets, but also find cases where a
dataset's quality for training and evaluation is largely disconnected. Our work
underlines limitations of commonly-used OOD-based evaluations of
generalization, and provides methodology and recommendations for evaluating
generalization within and beyond QA more robustly.

</details>


### [85] [How Reliable are LLMs for Reasoning on the Re-ranking task?](https://arxiv.org/abs/2508.18444)
*Nafis Tanveer Islam,Zhiming Zhao*

Main category: cs.CL

TL;DR: LLMs在理解人类价值观方面表现更好，但牺牲了透明度。本文分析了不同训练方法对LLM在重新排序任务中语义理解的影响，并探讨了LLM能否生成更具说服力的文本推理，以克服透明度和数据限制带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在理解人类价值观方面取得了进展，但其内部机制的透明度不足，阻碍了用户理解其决策过程。此外，在数据有限的新系统中，LLMs在内容重新排序方面仍面临挑战。本文旨在探究不同的训练方法如何影响LLM的语义理解能力，以及LLM能否通过文本推理克服透明度和数据限制。

Method: 本文利用了来自环境和地球科学领域的一个相对较小的排名数据集，对检索到的内容进行重新排序。此外，还分析了可解释信息，以确定重新排序是否可以通过可解释性进行推理。

Result: 研究表明，一些训练方法比其他方法具有更好的可解释性，这表明并非所有训练方法都能真正学习到准确的语义理解，而只是获得了优化评估的抽象知识。这引发了对LLM真正可靠性的质疑。

Conclusion: LLM在重新排序任务中的表现受到训练方法的影响，并非所有方法都能保证准确的语义理解。未来的研究需要关注如何提高LLM的可解释性，以应对透明度和数据限制的挑战，并确保其决策的可靠性。

Abstract: With the improving semantic understanding capability of Large Language Models
(LLMs), they exhibit a greater awareness and alignment with human values, but
this comes at the cost of transparency. Although promising results are achieved
via experimental analysis, an in-depth understanding of the LLM's internal
workings is unavoidable to comprehend the reasoning behind the re-ranking,
which provides end users with an explanation that enables them to make an
informed decision. Moreover, in newly developed systems with limited user
engagement and insufficient ranking data, accurately re-ranking content remains
a significant challenge. While various training methods affect the training of
LLMs and generate inference, our analysis has found that some training methods
exhibit better explainability than others, implying that an accurate semantic
understanding has not been learned through all training methods; instead,
abstract knowledge has been gained to optimize evaluation, which raises
questions about the true reliability of LLMs. Therefore, in this work, we
analyze how different training methods affect the semantic understanding of the
re-ranking task in LLMs and investigate whether these models can generate more
informed textual reasoning to overcome the challenges of transparency or LLMs
and limited training data. To analyze the LLMs for re-ranking tasks, we utilize
a relatively small ranking dataset from the environment and the Earth science
domain to re-rank retrieved content. Furthermore, we also analyze the
explainable information to see if the re-ranking can be reasoned using
explainability.

</details>


### [86] [Integrating gender inclusivity into large language models via instruction tuning](https://arxiv.org/abs/2508.18466)
*Alina Wróblewska,Bartosz Żuk*

Main category: cs.CL

TL;DR: 研究通过使用IPIS数据集对大型语言模型进行微调，以解决波兰语语言模型中存在的性别偏见问题。研究者设计了一个包含明确的性别包容性指南的系统提示，并在多语言和波兰语特定模型上进行了实验，旨在使性别包容性成为模型固有的特征。


<details>
  <summary>Details</summary>
Motivation: 当前的波兰语语言系统存在不公平的性别偏见，男性形式被广泛用于指代男性、女性和混合性别的群体。这种语言系统导致在波兰语文本上训练的大型语言模型（LLMs）继承并加剧了这种性别偏见，产生了性别不平衡的输出。

Method: 研究通过使用IPIS数据集（包含人类编写的性别包容性校对和波兰语到英语翻译说明）对大型语言模型（LLMs）进行微调。研究者设计了一个包含明确的性别包容性指南的系统提示，并在多语言LLMs（Llama-8B、Mistral-7B和Mistral-Nemo）和波兰语特定LLMs（Bielik和PLLuM）上进行了实验。

Result: 通过IPIS微调和系统提示，研究旨在使性别包容性成为波兰语语言模型的固有特征，从而减轻性别偏见。

Conclusion: 该研究提出了一种系统性的解决方案，通过微调和提示工程来减轻波兰语语言模型中的性别偏见，使性别包容性成为模型的一个固有特征。

Abstract: Imagine a language with masculine, feminine, and neuter grammatical genders,
yet, due to historical and political conventions, masculine forms are
predominantly used to refer to men, women and mixed-gender groups. This is the
reality of contemporary Polish. A social consequence of this unfair linguistic
system is that large language models (LLMs) trained on Polish texts inherit and
reinforce this masculine bias, generating gender-imbalanced outputs. This study
addresses this issue by tuning LLMs using the IPIS dataset, a collection of
human-crafted gender-inclusive proofreading in Polish and Polish-to-English
translation instructions. Grounded in a theoretical linguistic framework, we
design a system prompt with explicit gender-inclusive guidelines for Polish. In
our experiments, we IPIS-tune multilingual LLMs (Llama-8B, Mistral-7B and
Mistral-Nemo) and Polish-specific LLMs (Bielik and PLLuM). Our approach aims to
integrate gender inclusivity as an inherent feature of these models, offering a
systematic solution to mitigate gender bias in Polish language generation.

</details>


### [87] [Principled Detection of Hallucinations in Large Language Models via Multiple Testing](https://arxiv.org/abs/2508.18473)
*Jiawei Li,Akshayaa Magesh,Venugopal V. Veeravalli*

Main category: cs.CL

TL;DR: LLMs容易产生幻觉，本文将幻觉检测视为假设检验问题，并提出了一种受多重检验启发的检测方法。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然强大，但容易产生幻觉，即生成看似自信但实际上不正确或无意义的响应。

Method: 将幻觉检测问题形式化为假设检验问题，并与机器学习模型中的分布外检测问题进行类比。提出了一种受多重检验启发的解决方案。

Result: 实验结果广泛验证了该方法在鲁棒性方面优于现有技术。

Conclusion: 所提出的受多重检验启发的幻觉检测方法在检测LLM幻觉方面是有效且鲁棒的。

Abstract: While Large Language Models (LLMs) have emerged as powerful foundational
models to solve a variety of tasks, they have also been shown to be prone to
hallucinations, i.e., generating responses that sound confident but are
actually incorrect or even nonsensical. In this work, we formulate the problem
of detecting hallucinations as a hypothesis testing problem and draw parallels
to the problem of out-of-distribution detection in machine learning models. We
propose a multiple-testing-inspired method to solve the hallucination detection
problem, and provide extensive experimental results to validate the robustness
of our approach against state-of-the-art methods.

</details>


### [88] [COMET-poly: Machine Translation Metric Grounded in Other Candidates](https://arxiv.org/abs/2508.18549)
*Maike Züfle,Vilém Zouhar,Tu Anh Dinh,Felipe Maia Polo,Jan Niehues,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 新机器翻译评估指标，COMET-polycand和COMET-polyic，通过引入多个翻译或相似文本的翻译来提升评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有的机器翻译评估指标通常只考虑源语句和单个翻译，而忽略了人类评估时会参考多个翻译的上下文，这种差异可能影响评估指标的性能。

Method: 提出两种新的自动评估指标：COMET-polycand，通过比较同一源语句的多个翻译来评估目标翻译的质量；COMET-polyic，借鉴检索式上下文学习，引入相似源文本的翻译及其人类评分来指导评估。

Result: 实验表明，在COMET-polycand中加入单个额外翻译可提升指标性能（Kendall's tau-b相关系数从0.079提升至0.118），增加更多翻译效果更佳。COMET-polyic通过引入检索示例也能带来相似的提升（Kendall's tau-b相关系数从0.079提升至0.116）。

Conclusion: 包含额外翻译或检索示例的评估方法能够提升机器翻译评估指标的性能。

Abstract: Automated metrics for machine translation attempt to replicate human
judgment. Unlike humans, who often assess a translation in the context of
multiple alternatives, these metrics typically consider only the source
sentence and a single translation. This discrepancy in the evaluation setup may
negatively impact the performance of automated metrics. We propose two
automated metrics that incorporate additional information beyond the single
translation. COMET-polycand uses alternative translations of the same source
sentence to compare and contrast with the translation at hand, thereby
providing a more informed assessment of its quality. COMET-polyic, inspired by
retrieval-based in-context learning, takes in translations of similar source
texts along with their human-labeled quality scores to guide the evaluation. We
find that including a single additional translation in COMET-polycand improves
the segment-level metric performance (0.079 to 0.118 Kendall's tau-b
correlation), with further gains when more translations are added.
Incorporating retrieved examples in COMET-polyic yields similar improvements
(0.079 to 0.116 Kendall's tau-b correlation). We release our models publicly.

</details>


### [89] [The Mind's Eye: A Multi-Faceted Reward Framework for Guiding Visual Metaphor Generation](https://arxiv.org/abs/2508.18569)
*Girish A. Koushik,Fatemeh Nazarieh,Katherine Birch,Shenbin Qian,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 生成视觉隐喻的框架，结合了现有指标、隐喻分解和意义对齐（MA）度量，并探索了两种新方法：一种是免训练的S-T-M映射，另一种是改进对齐的训练基础方法，结果显示S-T-M提示在抽象隐喻方面表现优于闭源基线，并确定了模型在不同类型隐喻上的优势。


<details>
  <summary>Details</summary>
Motivation: 视觉隐喻生成旨在根据输入的文本隐喻生成图像，需要语言理解来结合源概念和目标概念，同时保持意义和视觉连贯性。

Method: 提出一个自评估视觉隐喻生成框架，侧重于隐喻对齐。自评估方法结合了现有指标、新提出的隐喻分解分数和意义对齐（MA）度量。探索了两种新方法：一种是免训练的管道，将提示分解为源-目标-意义（S-T-M）映射以进行图像合成；另一种是训练基础的管道，使用自评估奖励机制改进对齐，无需大规模重新训练。

Result: 在测试集上，免训练方法在分解、CLIP和MA分数上优于GPT-4o和Imagen等闭源基线，训练基础方法紧随其后。用户研究表明，参与者总体上更喜欢GPT-4o，但提出的免训练管道在抽象隐喻方面优于Imagen，并且优于其他开源方法。

Conclusion: 结构化提示和轻量级强化学习在适度的计算资源下能很好地实现隐喻对齐。模型在长隐喻或抽象隐喻方面表现更好，闭源模型在简短、具体的案例上表现优异。用户偏好上的差距主要在于美学和采样设置。

Abstract: Visual metaphor generation is a challenging task that aims to generate an
image given an input text metaphor. Inherently, it needs language understanding
to bind a source concept with a target concept, in a way that preserves meaning
while ensuring visual coherence. We propose a self-evaluating visual metaphor
generation framework that focuses on metaphor alignment. Our self-evaluation
approach combines existing metrics with our newly proposed metaphor
decomposition score and a meaning alignment (MA) metric. Within this setup, we
explore two novel approaches: a training-free pipeline that explicitly
decomposes prompts into source-target-meaning (S-T-M) mapping for image
synthesis, and a complementary training-based pipeline that improves alignment
using our proposed self-evaluation reward schema, without any large-scale
retraining. On the held-out test set, the training-free approach surpasses
strong closed baselines (GPT-4o, Imagen) on decomposition, CLIP, and MA scores,
with the training-based approach close behind. We evaluate our framework output
using a user-facing study, and observed that participants preferred GPT-4o
overall, while our training-free pipeline led open-source methods and edged
Imagen on abstract metaphors. Our analyses show S-T-M prompting helps longer or
more abstract metaphors, with closed models excelling on short, concrete cases;
we also observe sensitivity to sampler settings. Overall, structured prompting
and lightweight RL perform metaphor alignment well under modest compute, and
remaining gaps to human preference appear driven by aesthetics and sampling.

</details>


### [90] [What do language models model? Transformers, automata, and the format of thought](https://arxiv.org/abs/2508.18598)
*Colin Klein*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）主要是在它们训练的语料库上进行建模，而不是在人类能力上进行建模。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨大型语言模型（LLM）建模的对象，是人类能力还是训练语料库，并为后者提供辩护。

Method: 通过分析Transformer架构（支持线性计算格式）与人类语言能力（依赖超线性计算格式）的差异，论证LLM是基于训练语料库进行建模的。同时，借鉴Liu et al.（2022）关于“捷径自动机”的观点，阐述LLM的运作机制，并认为这种运作并非“通缩性”的。

Result: Transformer架构在计算上更倾向于线性格式，而人类语言能力则依赖超线性格式。LLM作为一种“语篇机器”，学习使用语言的方式与人类不同，尽管它们也学会了生成新语言。

Conclusion: LLM并非严格模仿人类语言能力，而是通过不同于人类的机制，基于其训练语料库进行建模。它们是“语篇机器”，能够利用语境生成新语言，但这并不意味着对人类能力的“通缩性”解释。

Abstract: What do large language models actually model? Do they tell us something about
human capacities, or are they models of the corpus we've trained them on? I
give a non-deflationary defence of the latter position. Cognitive science tells
us that linguistic capabilities in humans rely supralinear formats for
computation. The transformer architecture, by contrast, supports at best a
linear formats for processing. This argument will rely primarily on certain
invariants of the computational architecture of transformers. I then suggest a
positive story about what transformers are doing, focusing on Liu et al.
(2022)'s intriguing speculations about shortcut automata. I conclude with why I
don't think this is a terribly deflationary story. Language is not (just) a
means for expressing inner state but also a kind of 'discourse machine' that
lets us make new language given appropriate context. We have learned to use
this technology in one way; LLMs have also learned to use it too, but via very
different means.

</details>


### [91] [A New NMT Model for Translating Clinical Texts from English to Spanish](https://arxiv.org/abs/2508.18607)
*Rumeng Li,Xun Wang,Hong Yu*

Main category: cs.CL

TL;DR: NOOV是一个新的神经机器翻译（NMT）系统，用于将英语电子健康记录（EHR）翻译成西班牙语，即使在平行语料库很少的情况下也能表现良好。


<details>
  <summary>Details</summary>
Motivation: 将英语电子健康记录（EHR）翻译成西班牙语具有重要的临床意义，但面临数据稀缺和未登录词（OOV）的问题。

Method: 提出了一种名为NOOV的NMT系统，该系统集成了从平行语料库中自动学习的双语词典和从生物医学知识资源中提取的短语查找表，以解决OOV和词语重复问题。

Result: NOOV在翻译EHR方面表现出更好的准确性和流畅性。

Conclusion: NOOV能够更好地翻译EHR，克服了数据稀疏和OOV的挑战。

Abstract: Translating electronic health record (EHR) narratives from English to Spanish
is a clinically important yet challenging task due to the lack of a
parallel-aligned corpus and the abundant unknown words contained. To address
such challenges, we propose \textbf{NOOV} (for No OOV), a new neural machine
translation (NMT) system that requires little in-domain parallel-aligned corpus
for training. NOOV integrates a bilingual lexicon automatically learned from
parallel-aligned corpora and a phrase look-up table extracted from a large
biomedical knowledge resource, to alleviate both the unknown word problem and
the word-repeat challenge in NMT, enhancing better phrase generation of NMT
systems. Evaluation shows that NOOV is able to generate better translation of
EHR with improvement in both accuracy and fluency.

</details>


### [92] [Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models](https://arxiv.org/abs/2508.18609)
*Chenxi Zhou,Pengfei Cao,Jiang Li,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: PTQ对LLM的知识能力有何影响尚不清楚，本研究提出了分层缩放定律，发现知识记忆比知识利用对PTQ参数更敏感。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法忽略了PTQ特定的参数和任务敏感性，导致对LLM知识能力的影响理解不全面。

Method: 进行了广泛的经验研究，建立了分层缩放定律，并将LLM知识分解为记忆和利用能力，开发了一个包含模型大小、有效比特宽度、校准集大小和组大小的统一量化框架。

Result: 知识记忆对有效比特宽度、校准集大小和模型大小的变化比知识利用更敏感。

Conclusion: PTQ对LLM知识能力的影响是复杂的，需要考虑特定的参数和任务，以制定更好的量化策略来保留目标认知功能。

Abstract: Large language models (LLMs) present significant deployment challenges due to
their scale, with post-training quantization (PTQ) emerging as a practical
compression solution. However, a comprehensive understanding of how PTQ
precisely impacts diverse LLM knowledge capabilities remains elusive, and
existing scaling laws for quantized models often overlook crucial PTQ-specific
parameters and task-specific sensitivities. This paper addresses these gaps by
conducting an extensive empirical investigation to establish task-stratified
scaling laws. We disentangle LLM knowledge into memorization and utilization
capabilities and develop a unified quantitative framework that incorporates
model size, effective bit-width, calibration set size, and group size. Our
central finding reveals that knowledge memorization exhibits markedly greater
sensitivity to variations in effective bit-width, calibration set size, and
model size compared to the more robust knowledge utilization. These findings
offer a fine-grained understanding of PTQ's impact and provide guidance for
developing knowledge-aware quantization strategies that can better preserve
targeted cognitive functions.

</details>


### [93] [Thinking Before You Speak: A Proactive Test-time Scaling Approach](https://arxiv.org/abs/2508.18648)
*Cong Li,Wenchang Chai,Hejun Wu,Yan Pan,Pengxu Wei,Liang Lin*

Main category: cs.CL

TL;DR: LLM在数学等复杂推理任务中存在不足，因为它们的训练数据与人类的思考模式不匹配。为了解决这个问题，我们提出了“三思而后行”（TBYS）框架，通过插入‘洞见’来引导LLM的推理过程，而不是依赖静态提示。TBYS框架还包含一个自动收集和筛选上下文示例的管道，以减少人工标注和微调的开销。实验证明了TBYS在数学推理任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM在处理数学等复杂推理任务时存在不足，主要原因是人类的思考模式与LLM训练数据之间存在差异。人类在解决复杂问题时会进行深度思考，但通常不会明确表达其思考过程中的意图和方法，导致训练数据缺失了关键的推理步骤信息。

Method: 提出了一种名为“三思而后行”（TBYS）的推理框架，通过在连续的推理步骤之间插入‘洞见’来引导LLM。这些‘洞见’是主动生成的，用于回顾当前状态并启动下一步推理，与依赖静态提示的先前方法不同。此外，还设计了一个自动收集和筛选上下文示例的管道，用于生成‘洞见’，以减轻人工标注和微调的负担。

Result: 在具有挑战性的数学数据集上进行的实验验证了TBYS框架的有效性。

Conclusion: TBYS框架通过主动生成的‘洞见’来弥合LLM训练数据与人类复杂推理模式之间的差距，有效提升了LLM在数学推理任务上的表现，并提供了一种自动化的方法来支持‘洞见’的生成。

Abstract: Large Language Models (LLMs) often exhibit deficiencies with complex
reasoning tasks, such as maths, which we attribute to the discrepancy between
human reasoning patterns and those presented in the LLMs' training data. When
dealing with complex problems, humans tend to think carefully before expressing
solutions. However, they often do not articulate their inner thoughts,
including their intentions and chosen methodologies. Consequently, critical
insights essential for bridging reasoning steps may be absent in training data
collected from human sources. To bridge this gap, we proposes inserting
\emph{insight}s between consecutive reasoning steps, which review the status
and initiate the next reasoning steps. Unlike prior prompting strategies that
rely on a single or a workflow of static prompts to facilitate reasoning,
\emph{insight}s are \emph{proactively} generated to guide reasoning processes.
We implement our idea as a reasoning framework, named \emph{Thinking Before You
Speak} (TBYS), and design a pipeline for automatically collecting and filtering
in-context examples for the generation of \emph{insight}s, which alleviates
human labeling efforts and fine-tuning overheads. Experiments on challenging
mathematical datasets verify the effectiveness of TBYS. Project website:
https://gitee.com/jswrt/TBYS

</details>


### [94] [Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models](https://arxiv.org/abs/2508.18651)
*Chenxu Yang,Qingyi Si,Zheng Lin*

Main category: cs.CL

TL;DR: 该论文提出了一种名为协同解码(CoDe)的新方法，通过动态整合有无外部知识的输出概率，解决了大型语言模型(LLM)在整合外部知识时忠实度和表现力之间的权衡问题，在增强忠实度的同时不牺牲表现力。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型(LLM)在整合外部知识以减少幻觉时，难以同时保持忠实度和表现力，导致输出要么缺乏外部知识支持，要么过于冗长和不自然。

Method: 提出协同解码(CoDe)方法，动态整合有无外部知识的输出概率，并引入知识感知重新排序机制，以解决忠实度和表现力之间的权衡问题。

Result: 通过大量实验证明，CoDe框架可以增强忠实度而不牺牲表现力，并且适用于多种LLM和评估指标。

Conclusion: CoDe框架是一种有效且通用的即插即用方法，可以解决LLM在整合外部知识时面临的忠实度和表现力之间的权衡问题。

Abstract: Grounding responses in external knowledge represents an effective strategy
for mitigating hallucinations in Large Language Models (LLMs). However, current
LLMs struggle to seamlessly integrate knowledge while simultaneously
maintaining faithfulness (or fidelity) and expressiveness, capabilities that
humans naturally possess. This limitation results in outputs that either lack
support from external knowledge, thereby compromising faithfulness, or appear
overly verbose and unnatural, thus sacrificing expressiveness. In this work, to
break the trade-off between faithfulness and expressiveness, we propose
Collaborative Decoding (CoDe), a novel approach that dynamically integrates
output probabilities generated with and without external knowledge. This
integration is guided by distribution divergence and model confidence, enabling
the selective activation of relevant and reliable expressions from the model's
internal parameters. Furthermore, we introduce a knowledge-aware reranking
mechanism that prevents over-reliance on prior parametric knowledge while
ensuring proper utilization of provided external information. Through
comprehensive experiments, our plug-and-play CoDe framework demonstrates
superior performance in enhancing faithfulness without compromising
expressiveness across diverse LLMs and evaluation metrics, validating both its
effectiveness and generalizability.

</details>


### [95] [Emotion Omni: Enabling Empathetic Speech Response Generation through Large Language Models](https://arxiv.org/abs/2508.18655)
*Haoyu Wang,Guangyan Zhang,Jiale Chen,Jingyu Li,Yuehai Wang,Yiwen Guo*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Emotion Omni的新型模型架构，旨在解决当前语音大语言模型（LLM）在理解用户语音查询中的情感线索和生成共情响应方面的不足。现有模型通常只关注内容转换，忽略了情感表达的细微差别，而情感理解对于提升人机交互体验至关重要。然而，现有具备共情能力的语音LLM通常需要海量数据和大量计算资源进行训练，这带来了成本和效率上的挑战。Emotion Omni旨在以有限的数据和无需大规模训练的方式，实现对用户语音情感内容的理解并生成共情语音响应。此外，研究还开发了一个基于开源TTS框架的数据生成管线，构建了一个包含20万条对话的情感数据集，以支持共情语音助手的构建。


<details>
  <summary>Details</summary>
Motivation: 现有的语音大语言模型（LLM）在与用户进行语音交互时，往往只关注对话内容的转换，而忽略了用户查询中蕴含的情感和语调线索。然而，情感表达对理解语言含义至关重要，并且是改善人机交互体验的关键。目前，能够进行共情响应的语音LLM大多依赖海量数据集进行训练，这需要巨大的数据量和计算资源。因此，如何在有限的数据和资源下，开发出能够生成共情响应的语音LLM，是一个重要的挑战。

Method: 提出了一种名为Emotion Omni的新型模型架构，用于理解用户语音输入中的情感内容，并生成共情的语音响应。此外，研究人员还开发了一个基于开源文本转语音（TTS）框架的数据生成管线，构建了一个包含20万条对话的情感数据集，旨在支持共情语音助手的开发。

Result: 研究通过提出Emotion Omni模型架构和构建20万条对话的情感数据集，旨在解决现有语音LLM在情感理解和共情响应方面的局限性，并为构建共情语音助手提供了支持。具体效果和性能评估未在摘要中详细说明，但提及提供在线演示。

Conclusion: Emotion Omni模型架构和所构建的数据集为提升语音LLM的情感理解和共情交互能力提供了新的解决方案，有望在有限的数据和资源条件下实现更佳的人机交互体验。

Abstract: With the development of speech large language models (speech LLMs), users can
now interact directly with assistants via speech. However, most existing models
simply convert the response content into speech without fully understanding the
rich emotional and paralinguistic cues embedded in the user's query. In many
cases, the same sentence can have different meanings depending on the emotional
expression. Furthermore, emotional understanding is essential for improving
user experience in human-machine interaction. Currently, most speech LLMs with
empathetic capabilities are trained on massive datasets. This approach requires
vast amounts of data and significant computational resources. Therefore, a key
challenge lies in how to develop a speech LLM capable of generating empathetic
responses with limited data and without the need for large-scale training. To
address this challenge, we propose Emotion Omni, a novel model architecture
designed to understand the emotional content of user speech input and generate
empathetic speech responses. Additionally, we developed a data generation
pipeline based on an open-source TTS framework to construct a 200k emotional
dialogue dataset, which supports the construction of an empathetic speech
assistant. The demos are available at https://w311411.github.io/omni_demo/

</details>


### [96] [Tailored Teaching with Balanced Difficulty: Elevating Reasoning in Multimodal Chain-of-Thought via Prompt Curriculum](https://arxiv.org/abs/2508.18673)
*Xinglong Yang,Quan Feng,Zhongying Pan,Xiang Chen,Yu Tian,Wentong Li,Shuofei Qiao,Yuxia Geng,Xingyu Zhao,Sheng-Jun Huang*

Main category: cs.CL

TL;DR: 本研究提出一种新颖的框架，通过结合模型感知的难度和样本的内在复杂度来优化多模态链式思考（MCoT）提示的示例选择，从而解决现有方法依赖随机或手动选择示例导致性能不佳和不稳定的问题。该框架将提示选择视为提示课程设计问题，构建一个与模型能力相匹配的有序示例集。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态链式思考（MCoT）提示方法在选择示例时，往往依赖随机或手动选取，未能充分考虑模型的知识分布和任务的内在复杂性，导致模型性能不佳且不稳定。

Method: 提出一个受“有区别的教学”启发的框架，将提示选择问题重新定义为提示课程设计问题。该方法整合了两个信号：1）模型感知的难度（通过主动学习中的预测不一致来量化）；2）内在样本复杂度（独立于模型衡量问题-图像对的难度）。通过联合分析这两个信号，开发了一种难度平衡的采样策略。

Result: 在五个具有挑战性的基准测试和多个流行的多模态大语言模型（MLLMs）上进行的广泛实验表明，该方法能够带来显著且一致的改进，并大大减少了随机抽样引起的性能差异。

Conclusion: 所提出的框架为增强多模态推理提供了一种原则性强且鲁棒的方法，通过精心设计的示例选择策略，提高了多模态大语言模型的性能和稳定性。

Abstract: The effectiveness of Multimodal Chain-of-Thought (MCoT) prompting is often
limited by the use of randomly or manually selected examples. These examples
fail to account for both model-specific knowledge distributions and the
intrinsic complexity of the tasks, resulting in suboptimal and unstable model
performance. To address this, we propose a novel framework inspired by the
pedagogical principle of "tailored teaching with balanced difficulty". We
reframe prompt selection as a prompt curriculum design problem: constructing a
well ordered set of training examples that align with the model's current
capabilities. Our approach integrates two complementary signals: (1)
model-perceived difficulty, quantified through prediction disagreement in an
active learning setup, capturing what the model itself finds challenging; and
(2) intrinsic sample complexity, which measures the inherent difficulty of each
question-image pair independently of any model. By jointly analyzing these
signals, we develop a difficulty-balanced sampling strategy that ensures the
selected prompt examples are diverse across both dimensions. Extensive
experiments conducted on five challenging benchmarks and multiple popular
Multimodal Large Language Models (MLLMs) demonstrate that our method yields
substantial and consistent improvements and greatly reduces performance
discrepancies caused by random sampling, providing a principled and robust
approach for enhancing multimodal reasoning.

</details>


### [97] [Knowing or Guessing? Robust Medical Visual Question Answering via Joint Consistency and Contrastive Learning](https://arxiv.org/abs/2508.18687)
*Songtao Jiang,Yuxi Chen,Sibo Song,Yan Zhang,Yeying Jin,Yang Feng,Jian Wu,Zuozhu Liu*

Main category: cs.CL

TL;DR: Med-VLMs在医学视觉问答中存在不鲁棒的问题，其答案会因问题的措辞变化而显著波动。这归因于医学概念对齐不足和训练数据中的隐藏偏见。为解决此问题，研究者构建了RoMed数据集，并通过一致性和对比学习（CCL）方法来提升模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在医疗高风险应用中，模型需要对语义相同的医疗问题提供一致的回答以确保诊断的可靠性。然而，现有的医学视觉语言模型（Med-VLMs）在医学视觉问答（VQA）中表现出脆弱性，当问题被重新表述时，它们的回答会发生显著变化。

Method: 研究者构建了一个名为RoMed的数据集，其中包含144,000个问题及其多种改写形式，涵盖词语、句子和语义层面的扰动。为了解决模型不鲁棒的问题，提出了一种名为一致性和对比学习（CCL）的方法，该方法包含两个关键部分：1）知识锚定的一致性学习，旨在将Med-VLMs与医学知识对齐，而非浅层特征模式；2）偏见感知对比学习，通过区分性表示优化来减轻特定于数据的先验知识的影响。

Result: 在RoMed数据集上评估LLaVA-Med等先进模型时，与原始VQA基准相比，观察到惊人的性能下降（例如，召回率下降40%），暴露了关键的鲁棒性差距。CCL方法在三个流行的VQA基准上实现了SOTA性能，并在具有挑战性的RoMed测试集上显著提高了答案的一致性（50%），证明了其鲁棒性的显著增强。

Conclusion: CCL方法通过知识锚定的一致性学习和偏见感知对比学习，有效解决了Med-VLMs在医学视觉问答中的鲁棒性问题，显著提高了模型处理不同措辞问题的能力，并在多个基准测试中取得了优异的性能。

Abstract: In high-stakes medical applications, consistent answering across diverse
question phrasings is essential for reliable diagnosis. However, we reveal that
current Medical Vision-Language Models (Med-VLMs) exhibit concerning fragility
in Medical Visual Question Answering, as their answers fluctuate significantly
when faced with semantically equivalent rephrasings of medical questions. We
attribute this to two limitations: (1) insufficient alignment of medical
concepts, leading to divergent reasoning patterns, and (2) hidden biases in
training data that prioritize syntactic shortcuts over semantic understanding.
To address these challenges, we construct RoMed, a dataset built upon original
VQA datasets containing 144k questions with variations spanning word-level,
sentence-level, and semantic-level perturbations. When evaluating
state-of-the-art (SOTA) models like LLaVA-Med on RoMed, we observe alarming
performance drops (e.g., a 40\% decline in Recall) compared to original VQA
benchmarks, exposing critical robustness gaps. To bridge this gap, we propose
Consistency and Contrastive Learning (CCL), which integrates two key
components: (1) knowledge-anchored consistency learning, aligning Med-VLMs with
medical knowledge rather than shallow feature patterns, and (2) bias-aware
contrastive learning, mitigating data-specific priors through discriminative
representation refinement. CCL achieves SOTA performance on three popular VQA
benchmarks and notably improves answer consistency by 50\% on the challenging
RoMed test set, demonstrating significantly enhanced robustness. Code will be
released.

</details>


### [98] [Attention2Probability: Attention-Driven Terminology Probability Estimation for Robust Speech-to-Text System](https://arxiv.org/abs/2508.18701)
*Yanfan Du,Jun Zhang,Bin Wang,Jin Qiu,Lu Huang,Yuan Ge,Xiaoqian Liu,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: Attention2Probability通过将语音和术语之间的交叉注意力权重转换为存在概率，并采用课程学习来提高检索准确性，以解决领域特定术语识别的挑战。研究还发布了一个包含术语的新语音数据集。实验结果表明，Attention2Probability在中文和英文上的召回率分别达到92.57%和86.83%，延迟仅为8.71ms。此外，该方法可将术语准确性提高6-17%。


<details>
  <summary>Details</summary>
Motivation: 通用领域语音大模型在语音识别和翻译方面取得了显著进展，但在生成领域特定术语或新词方面仍存在挑战。

Method: Attention2Probability将语音和术语之间的交叉注意力权重转换为存在概率，并采用课程学习来提高检索准确性。

Result: Attention2Probability在中文和英文上的召回率分别达到92.57%和86.83%，延迟仅为8.71ms。将Attention2Probability检索到的术语应用于语音大模型的识别和翻译任务，可将术语准确性提高6-17%。

Conclusion: Attention2Probability是一种轻量、灵活且准确的方法，可以解决领域特定术语识别的挑战，并且优于现有的VectorDB方法。然而，目前语音大模型对术语的利用存在局限性。

Abstract: Recent advances in speech large language models (SLMs) have improved speech
recognition and translation in general domains, but accurately generating
domain-specific terms or neologisms remains challenging. To address this, we
propose Attention2Probability: attention-driven terminology probability
estimation for robust speech-to-text system, which is lightweight, flexible,
and accurate. Attention2Probability converts cross-attention weights between
speech and terminology into presence probabilities, and it further employs
curriculum learning to enhance retrieval accuracy. Furthermore, to tackle the
lack of data for speech-to-text tasks with terminology intervention, we create
and release a new speech dataset with terminology to support future research in
this area. Experimental results show that Attention2Probability significantly
outperforms the VectorDB method on our test set. Specifically, its maximum
recall rates reach 92.57% for Chinese and 86.83% for English. This high recall
is achieved with a latency of only 8.71ms per query. Intervening in SLMs'
recognition and translation tasks using Attention2Probability-retrieved terms
improves terminology accuracy by 6-17%, while revealing that the current
utilization of terminology by SLMs has limitations.

</details>


### [99] [Filtering for Creativity: Adaptive Prompting for Multilingual Riddle Generation in LLMs](https://arxiv.org/abs/2508.18709)
*Duy Le,Kent Ziti,Evan Girard-Sun,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: AOF是一种新颖的提示框架，通过余弦相似度拒绝过滤冗余生成，同时强制执行词汇新颖性和跨语言保真度，以应对多语言谜语生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 标准提示策略在生成多语言谜语时，往往会重复记忆的谜语或进行浅层改述，无法平衡文化流畅性与创造性抽象。AOF旨在解决这一问题。

Method: AOF框架通过余弦相似度拒绝过滤冗余生成，并强制执行词汇新颖性和跨语言保真度。

Result: 在三种LLM和四种语言对的评估中，AOF增强的GPT-4o在日本语中取得了0.177的Self-BLEU和0.915的Distinct-2，表明其在词汇多样性和减少冗余方面优于其他提示方法和语言对。

Conclusion: 语义拒绝可以指导具有文化基础的创造性生成，而无需进行特定任务的微调。

Abstract: Multilingual riddle generation challenges large language models (LLMs) to
balance cultural fluency with creative abstraction. Standard prompting
strategies -- zero-shot, few-shot, chain-of-thought -- tend to reuse memorized
riddles or perform shallow paraphrasing. We introduce Adaptive Originality
Filtering (AOF), a prompting framework that filters redundant generations using
cosine-based similarity rejection, while enforcing lexical novelty and
cross-lingual fidelity. Evaluated across three LLMs and four language pairs,
AOF-enhanced GPT-4o achieves \texttt{0.177} Self-BLEU and \texttt{0.915}
Distinct-2 in Japanese, signaling improved lexical diversity and reduced
redundancy compared to other prompting methods and language pairs. Our findings
show that semantic rejection can guide culturally grounded, creative generation
without task-specific fine-tuning.

</details>


### [100] [EMMM, Explain Me My Model! Explainable Machine Generated Text Detection in Dialogues](https://arxiv.org/abs/2508.18715)
*Angela Yifei Yuan,Haoyi Li,Soyeon Caren Han,Christopher Leckie*

Main category: cs.CL

TL;DR: 该研究提出了一种名为EMMM的框架，用于检测客户服务中的机器生成文本（MGT），该框架具有可解释性、准确性和低延迟的特点，并且易于非专业用户理解。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在客户服务中的广泛应用，恶意行为者可能利用其进行大规模用户冒充。因此，需要可靠且易于理解的MGT检测方法，特别是在客户服务场景下，操作员通常是非专业用户，对解释的需求尤为重要。

Method: 提出了一种名为EMMM的“先解释后检测”框架，旨在平衡延迟、准确性和面向非专业用户的可解释性。

Result: 实验结果表明，EMMM提供的解释易于非专业用户理解，70%的人类评估者更喜欢其输出。同时，EMMM的准确性与最先进的模型相当，并且延迟较低，能在1秒内生成输出。

Conclusion: EMMM框架在客户服务场景下，通过提供易于理解的解释，实现了准确的MGT检测，同时满足了低延迟的要求，有助于构建值得信赖的AI。

Abstract: The rapid adoption of large language models (LLMs) in customer service
introduces new risks, as malicious actors can exploit them to conduct
large-scale user impersonation through machine-generated text (MGT). Current
MGT detection methods often struggle in online conversational settings,
reducing the reliability and interpretability essential for trustworthy AI
deployment. In customer service scenarios where operators are typically
non-expert users, explanation become crucial for trustworthy MGT detection. In
this paper, we propose EMMM, an explanation-then-detection framework that
balances latency, accuracy, and non-expert-oriented interpretability.
Experimental results demonstrate that EMMM provides explanations accessible to
non-expert users, with 70\% of human evaluators preferring its outputs, while
achieving competitive accuracy compared to state-of-the-art models and
maintaining low latency, generating outputs within 1 second. Our code and
dataset are open-sourced at
https://github.com/AngieYYF/EMMM-explainable-chatbot-detection.

</details>


### [101] [Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models](https://arxiv.org/abs/2508.18739)
*Chang Wang,Siyu Yan,Depeng Yuan,Yuqi Chen,Yanhua Huang,Yuanhang Zheng,Shuhao Li,Yinqi Zhang,Kedi Chen,Mingrui Zhu,Ruiwen Xu*

Main category: cs.CL

TL;DR: DIVER框架通过联合优化语言模型的多样性和质量来生成广告标题，并在实际应用中提高了广告价值和点击率。


<details>
  <summary>Details</summary>
Motivation: 当前广告标题生成方法往往只关注质量或点击率，导致输出同质化，未能满足吸引广泛受众的需求。

Method: 提出DIVER框架，包含一个语义和风格感知的自动数据生成流程，以及一个结合监督微调（SFT）和强化学习（RL）的多阶段多目标优化方法，以在单次前向传播中实现高质量和多样化的标题生成。

Result: 在真实工业数据集上的实验表明，DIVER有效平衡了广告标题的质量和多样性，并在一个大型内容分享平台上部署后，广告价值（ADVV）和点击率（CTR）分别提高了4.0%和1.4%。

Conclusion: DIVER框架成功实现了高质量和多样化的广告标题生成，并在实际应用中取得了显著的商业效益。

Abstract: The generation of ad headlines plays a vital role in modern advertising,
where both quality and diversity are essential to engage a broad range of
audience segments. Current approaches primarily optimize language models for
headline quality or click-through rates (CTR), often overlooking the need for
diversity and resulting in homogeneous outputs. To address this limitation, we
propose DIVER, a novel framework based on large language models (LLMs) that are
jointly optimized for both diversity and quality. We first design a semantic-
and stylistic-aware data generation pipeline that automatically produces
high-quality training pairs with ad content and multiple diverse headlines. To
achieve the goal of generating high-quality and diversified ad headlines within
a single forward pass, we propose a multi-stage multi-objective optimization
framework with supervised fine-tuning (SFT) and reinforcement learning (RL).
Experiments on real-world industrial datasets demonstrate that DIVER
effectively balances quality and diversity. Deployed on a large-scale
content-sharing platform serving hundreds of millions of users, our framework
improves advertiser value (ADVV) and CTR by 4.0% and 1.4%.

</details>


### [102] [M3HG: Multimodal, Multi-scale, and Multi-type Node Heterogeneous Graph for Emotion Cause Triplet Extraction in Conversations](https://arxiv.org/abs/2508.18740)
*Qiao Liang,Ying Shen,Tiantian Chen,Lin Zhang*

Main category: cs.CL

TL;DR: 该论文提出了MECAD数据集和M3HG模型，以解决多模态对话中的情感原因三元组提取（MECTEC）任务的数据集稀疏和现有方法性能不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MECTEC数据集（MECТEC）的局限性在于数据量少且场景单一，阻碍了模型在该领域的发展。此外，现有MECTEC方法未能显式地建模情感和因果上下文，并忽略了不同层级的语义信息融合，导致性能下降。

Method: 本文提出了一种名为M3HG的新模型，该模型通过多模态异构图显式捕捉情感和因果上下文，并有效地融合了句内和句间层级的上下文信息。

Result: 通过大量实验证明，M3HG模型相比于现有的最先进方法具有更好的效果。

Conclusion: M3HG模型在MECTEC任务上取得了显著的性能提升，并且MECAD数据集的发布为该领域的研究提供了新的资源。

Abstract: Emotion Cause Triplet Extraction in Multimodal Conversations (MECTEC) has
recently gained significant attention in social media analysis, aiming to
extract emotion utterances, cause utterances, and emotion categories
simultaneously. However, the scarcity of related datasets, with only one
published dataset featuring highly uniform dialogue scenarios, hinders model
development in this field. To address this, we introduce MECAD, the first
multimodal, multi-scenario MECTEC dataset, comprising 989 conversations from 56
TV series spanning a wide range of dialogue contexts. In addition, existing
MECTEC methods fail to explicitly model emotional and causal contexts and
neglect the fusion of semantic information at different levels, leading to
performance degradation. In this paper, we propose M3HG, a novel model that
explicitly captures emotional and causal contexts and effectively fuses
contextual information at both inter- and intra-utterance levels via a
multimodal heterogeneous graph. Extensive experiments demonstrate the
effectiveness of M3HG compared with existing state-of-the-art methods. The
codes and dataset are available at https://github.com/redifinition/M3HG.

</details>


### [103] [Chronological Passage Assembling in RAG framework for Temporal Question Answering](https://arxiv.org/abs/2508.18748)
*Byeongjeong Kim,Jeonghyun Park,Joonho Yang,Hwanhee Lee*

Main category: cs.CL

TL;DR: ChronoRAG框架通过重构叙事文本的时间线和保留上下文流来改进长上下文问答，在NarrativeQA数据集上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在处理叙事文本时效果有限，因为理解叙事文本需要更广泛的上下文和段落间的顺序关系，而不仅仅是孤立的段落。

Method: 提出ChronoRAG框架，该框架专门用于叙事文本，通过将分散的文档信息整合成连贯的段落，并明确捕捉和维护检索段落之间的时间顺序来解决这些限制。

Result: 在NarrativeQA数据集上的实验表明，ChronoRAG在需要事实识别和理解复杂顺序关系的任务中取得了显著改进。

Conclusion: 推理叙事文本中的时间顺序对于解决叙事问答至关重要，ChronoRAG通过显式地处理时间顺序来有效解决这一问题。

Abstract: Long-context question answering over narrative tasks is challenging because
correct answers often hinge on reconstructing a coherent timeline of events
while preserving contextual flow in a limited context window.
Retrieval-augmented generation (RAG) indexing methods aim to address this
challenge by selectively retrieving only necessary document segments. However,
narrative texts possess unique characteristics that limit the effectiveness of
these existing approaches. Specifically, understanding narrative texts requires
more than isolated segments, as the broader context and sequential
relationships between segments are crucial for comprehension. To address these
limitations, we propose ChronoRAG, a novel RAG framework specialized for
narrative texts. This approach focuses on two essential aspects: refining
dispersed document information into coherent and structured passages, and
preserving narrative flow by explicitly capturing and maintaining the temporal
order among retrieved passages. We empirically demonstrate the effectiveness of
ChronoRAG through experiments on the NarrativeQA dataset, showing substantial
improvements in tasks requiring both factual identification and comprehension
of complex sequential relationships, underscoring that reasoning over temporal
order is crucial in resolving narrative QA.

</details>


### [104] [ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models](https://arxiv.org/abs/2508.18773)
*Qianyu He,Siyu Yuan,Xuefeng Li,Mingxuan Wang,Jiangjie Chen*

Main category: cs.CL

TL;DR: ThinkDial 是首个开源框架，通过离散操作模式实现了类似 GPT-OSS 的可控推理，能在不同推理模式下（高、中、低）显著减少计算量，同时保持可接受的性能。通过端到端的训练范式，包括预算模式监督微调和两阶段预算感知强化学习，ThinkDial 能够实现目标压缩-性能权衡，并对分布外任务表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在推理方面能力很强，但在实际部署中控制其计算成本仍是一个挑战。虽然一些专有系统（如 OpenAI 的 gpt-oss 系列）引入了离散操作模式来实现推理控制，但开源社区尚未实现类似能力。

Method: ThinkDial 框架通过端到端的训练范式实现可控推理，包括：1. 预算模式监督微调：将可控推理能力嵌入学习过程。2. 两阶段预算感知强化学习：采用自适应奖励塑造来优化模型在不同计算预算下的表现。该系统包含三种推理模式：高模式（全推理能力）、中模式（减少 50% 的 token，性能下降 <10%）和低模式（减少 75% 的 token，性能下降 <15%）。

Result: ThinkDial 成功实现了目标压缩-性能权衡，在明显减少响应长度的同时，保持了性能阈值。实验表明，该框架在中、低模式下能显著减少 token 使用量，且性能损失很小。此外，ThinkDial 在分布外任务上也展现出强大的泛化能力。

Conclusion: ThinkDial 作为首个开源框架，成功实现了类似 GPT-OSS 的可控推理，通过离散操作模式有效解决了 LLM 在实际部署中的计算成本控制问题。它在不同推理模式下实现了显著的计算量减少，同时保持了令人满意的性能，并对新任务具有良好的泛化性。

Abstract: Large language models (LLMs) with chain-of-thought reasoning have
demonstrated remarkable problem-solving capabilities, but controlling their
computational effort remains a significant challenge for practical deployment.
Recent proprietary systems like OpenAI's gpt-oss series have introduced
discrete operational modes for intuitive reasoning control, but the open-source
community has largely failed to achieve such capabilities. In this paper, we
introduce ThinkDial, the first open-recipe end-to-end framework that
successfully implements gpt-oss-style controllable reasoning through discrete
operational modes. Our system enables seamless switching between three distinct
reasoning regimes: High mode (full reasoning capability), Medium mode (50
percent token reduction with <10 percent performance degradation), and Low mode
(75 percent token reduction with <15 percent performance degradation). We
achieve this through an end-to-end training paradigm that integrates
budget-mode control throughout the entire pipeline: budget-mode supervised
fine-tuning that embeds controllable reasoning capabilities directly into the
learning process, and two-phase budget-aware reinforcement learning with
adaptive reward shaping. Extensive experiments demonstrate that ThinkDial
achieves target compression-performance trade-offs with clear response length
reductions while maintaining performance thresholds. The framework also
exhibits strong generalization capabilities on out-of-distribution tasks.

</details>


### [105] [Harnessing Rule-Based Reinforcement Learning for Enhanced Grammatical Error Correction](https://arxiv.org/abs/2508.18780)
*Yilin Li,Xunjian Yin,Yilin Chen,Xiaojun Wan*

Main category: cs.CL

TL;DR: Rule-Based RL框架在语法错误纠正（GEC）任务上取得了最先进的性能，特别是在召回率方面有显著提升，展示了RL在指导LLM方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的语法错误纠正方法主要依赖监督微调，限制了LLM的推理能力。本研究旨在探索新的方法来克服这一限制。

Method: 提出了一种基于规则的强化学习（Rule-Based RL）的新框架，以更好地利用LLM的推理能力进行语法错误纠正。

Result: 在中文数据集上的实验表明，Rule-Based RL框架实现了最先进的性能，尤其在召回率方面有显著提高。

Conclusion: 强化学习（RL）可以有效地指导大型语言模型（LLM），为语法错误纠正（GEC）提供了一个更可控、更可靠的范式。

Abstract: Grammatical error correction is a significant task in NLP. Traditional
methods based on encoder-decoder models have achieved certain success, but the
application of LLMs in this field is still underexplored. Current research
predominantly relies on supervised fine-tuning to train LLMs to directly
generate the corrected sentence, which limits the model's powerful reasoning
ability. To address this limitation, we propose a novel framework based on
Rule-Based RL. Through experiments on the Chinese datasets, our Rule-Based RL
framework achieves \textbf{state-of-the-art }performance, with a notable
increase in \textbf{recall}. This result clearly highlights the advantages of
using RL to steer LLMs, offering a more controllable and reliable paradigm for
future development in GEC.

</details>


### [106] [Controllable Conversational Theme Detection Track at DSTC 12](https://arxiv.org/abs/2508.18783)
*Igor Shalyminov,Hang Su,Jake Vincent,Siffi Singh,Jason Cai,James Gung,Raphael Shu,Saab Mansour*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Conversational analytics has been on the forefront of transformation driven
by the advances in Speech and Natural Language Processing techniques. Rapid
adoption of Large Language Models (LLMs) in the analytics field has taken the
problems that can be automated to a new level of complexity and scale. In this
paper, we introduce Theme Detection as a critical task in conversational
analytics, aimed at automatically identifying and categorizing topics within
conversations. This process can significantly reduce the manual effort involved
in analyzing expansive dialogs, particularly in domains like customer support
or sales. Unlike traditional dialog intent detection, which often relies on a
fixed set of intents for downstream system logic, themes are intended as a
direct, user-facing summary of the conversation's core inquiry. This
distinction allows for greater flexibility in theme surface forms and
user-specific customizations. We pose Controllable Conversational Theme
Detection problem as a public competition track at Dialog System Technology
Challenge (DSTC) 12 -- it is framed as joint clustering and theme labeling of
dialog utterances, with the distinctive aspect being controllability of the
resulting theme clusters' granularity achieved via the provided user preference
data. We give an overview of the problem, the associated dataset and the
evaluation metrics, both automatic and human. Finally, we discuss the
participant teams' submissions and provide insights from those. The track
materials (data and code) are openly available in the GitHub repository.

</details>


### [107] [LaTeXTrans: Structured LaTeX Translation with Multi-Agent Coordination](https://arxiv.org/abs/2508.18791)
*Ziming Zhu,Chenglong Wang,Shunjie Xing,Yifu Huo,Fengning Tian,Quan Du,Di Yang,Chunliang Zhang,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: LaTeXTrans是一个多智能体系统，可以翻译LaTeX文档，在翻译准确性和结构保真度方面优于主流翻译系统。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译系统在翻译包含自然语言、数学公式、表格、图形和交叉引用等混合内容的LaTeX文档时面临挑战，需要保持语义完整性和可编译性。

Method: LaTeXTrans通过六个专用智能体协同工作来解决此问题：1）解析器将LaTeX分解为易于翻译的单元；2）翻译器、验证器、摘要器和术语提取器协同工作以实现上下文感知、自我修正和术语一致的翻译；3）生成器将翻译内容重构为LaTeX文档。

Result: 实验结果表明，LaTeXTrans在翻译准确性和结构保真度方面优于主流机器翻译系统。

Conclusion: LaTeXTrans为翻译LaTeX文档提供了一个有效且实用的解决方案。

Abstract: Despite the remarkable progress of modern machine translation (MT) systems on
general-domain texts, translating structured LaTeX-formatted documents remains
a significant challenge. These documents typically interleave natural language
with domain-specific syntax, such as mathematical equations, tables, figures,
and cross-references, all of which must be accurately preserved to maintain
semantic integrity and compilability. In this paper, we introduce LaTeXTrans, a
collaborative multi-agent system designed to address this challenge. LaTeXTrans
ensures format preservation, structural fidelity, and terminology consistency
through six specialized agents: 1) a Parser that decomposes LaTeX into
translation-friendly units via placeholder substitution and syntax filtering;
2) a Translator, Validator, Summarizer, and Terminology Extractor that work
collaboratively to ensure context-aware, self-correcting, and
terminology-consistent translations; 3) a Generator that reconstructs the
translated content into well-structured LaTeX documents. Experimental results
demonstrate that LaTeXTrans can outperform mainstream MT systems in both
translation accuracy and structural fidelity, offering an effective and
practical solution for translating LaTeX-formatted documents.

</details>


### [108] [Arrows of Math Reasoning Data Synthesis for Large Language Models: Diversity, Complexity and Correctness](https://arxiv.org/abs/2508.18824)
*Sirui Chen,Changxin Tian,Binbin Hu,Kunlong Chen,Ziqi Liu,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 通过程序辅助合成框架生成了1230万个高质量数学问题-答案对，显著提升了LLMs的数学推理能力，并在多个基准数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM数学推理训练数据生成方法在可扩展性、成本和可靠性方面存在挑战。

Method: 提出了一种程序辅助合成框架，该框架整合了数学知识系统和领域特定工具来创建可执行程序，然后将程序转换为自然语言问题-答案对，并通过双边验证机制（验证答案正确性和程序-问题一致性）进行审查。最终生成了1230万个问题-解决三元组。

Result: 在多个基准数据集上，使用合成数据微调的模型在推理能力上取得了显著的改进，达到了最先进的性能。

Conclusion: 所提出的程序辅助合成方法能够有效生成高质量的数学语料库，可显著提升LLMs的数学推理能力。

Abstract: Enhancing the mathematical reasoning of large language models (LLMs) demands
high-quality training data, yet conventional methods face critical challenges
in scalability, cost, and data reliability. To address these limitations, we
propose a novel program-assisted synthesis framework that systematically
generates a high-quality mathematical corpus with guaranteed diversity,
complexity, and correctness. This framework integrates mathematical knowledge
systems and domain-specific tools to create executable programs. These programs
are then translated into natural language problem-solution pairs and vetted by
a bilateral validation mechanism that verifies solution correctness against
program outputs and ensures program-problem consistency. We have generated 12.3
million such problem-solving triples. Experiments demonstrate that models
fine-tuned on our data significantly improve their inference capabilities,
achieving state-of-the-art performance on several benchmark datasets and
showcasing the effectiveness of our synthesis approach.

</details>


### [109] [ConfTuner: Training Large Language Models to Express Their Confidence Verbally](https://arxiv.org/abs/2508.18847)
*Yibo Li,Miao Xiong,Jiaying Wu,Bryan Hooi*

Main category: cs.CL

TL;DR: ConfTuner是一种新的LLM校准方法，通过使用tokenized Brier score损失函数，无需真实置信度或代理估计即可提高LLM的置信度表达能力，并能提升下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: LLM在科学、法律、医疗等高风险领域的应用需要准确的置信度表达，但现有LLM存在“过度自信”问题，而目前的校准方法效果有限且泛化性差。

Method: 提出ConfTuner，一种新的微调方法，使用tokenized Brier score作为损失函数，该函数被证明是一种proper scoring rule，能够激励模型报告真实的正确概率。

Result: ConfTuner在各种推理任务上提高了LLM的校准能力，并且能够泛化到GPT-4o等黑盒模型。此外，更好的校准提升了模型在自校正和模型级联任务上的表现。

Conclusion: ConfTuner是一种简单有效的方法，可以改善LLM的置信度表达，提高其在下游任务中的表现，从而促进可信赖LLM系统的发展。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-stakes domains
such as science, law, and healthcare, where accurate expressions of uncertainty
are essential for reliability and trust. However, current LLMs are often
observed to generate incorrect answers with high confidence, a phenomenon known
as "overconfidence". Recent efforts have focused on calibrating LLMs'
verbalized confidence: i.e., their expressions of confidence in text form, such
as "I am 80% confident that...". Existing approaches either rely on prompt
engineering or fine-tuning with heuristically generated uncertainty estimates,
both of which have limited effectiveness and generalizability. Motivated by the
notion of proper scoring rules for calibration in classical machine learning
models, we introduce ConfTuner, a simple and efficient fine-tuning method that
introduces minimal overhead and does not require ground-truth confidence scores
or proxy confidence estimates. ConfTuner relies on a new loss function,
tokenized Brier score, which we theoretically prove to be a proper scoring
rule, intuitively meaning that it "correctly incentivizes the model to report
its true probability of being correct". ConfTuner improves calibration across
diverse reasoning tasks and generalizes to black-box models such as GPT-4o. Our
results further show that better-calibrated confidence enables downstream gains
in self-correction and model cascade, advancing the development of trustworthy
LLM systems. The code is available at
https://github.com/liushiliushi/ConfTuner.

</details>


### [110] [ReflectivePrompt: Reflective evolution in autoprompting algorithms](https://arxiv.org/abs/2508.18870)
*Viktor N. Zhuravlev,Artur R. Khairullin,Ernest A. Dyagin,Alena N. Sitkina,Nikita I. Kulin*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Autoprompting is the process of automatically selecting optimized prompts for
language models, which has been gaining popularity with the rapid advancement
of prompt engineering, driven by extensive research in the field of large
language models (LLMs). This paper presents ReflectivePrompt - a novel
autoprompting method based on evolutionary algorithms that employs a reflective
evolution approach for more precise and comprehensive search of optimal
prompts. ReflectivePrompt utilizes short-term and long-term reflection
operations before crossover and elitist mutation to enhance the quality of the
modifications they introduce. This method allows for the accumulation of
knowledge obtained throughout the evolution process and updates it at each
epoch based on the current population. ReflectivePrompt was tested on 33
datasets for classification and text generation tasks using open-access large
language models: t-lite-instruct-0.1 and gemma3-27b-it. The method
demonstrates, on average, a significant improvement (e.g., 28% on BBH compared
to EvoPrompt) in metrics relative to current state-of-the-art approaches,
thereby establishing itself as one of the most effective solutions in
evolutionary algorithm-based autoprompting.

</details>


### [111] [Empowering Computing Education Researchers Through LLM-Assisted Content Analysis](https://arxiv.org/abs/2508.18872)
*Laurie Gale,Sebastian Mateos Nicolajsen*

Main category: cs.CL

TL;DR: 大型语言模型辅助内容分析（LACA）是一种用于计算教育研究（CER）的新方法，它结合了内容分析和大型语言模型，以处理和分析大量的文本数据，从而提高研究的严谨性和可推广性。


<details>
  <summary>Details</summary>
Motivation: 计算教育研究（CER）领域的研究人员常常希望改进教学实践，但缺乏足够的研究资源和能力来产生广泛适用或严谨的研究结果。因此，需要能够处理大量定性数据，同时不增加研究者负担的研究方法。

Method: 提出了一种名为“大型语言模型辅助内容分析”（LACA）的方法，该方法结合了内容分析和大型语言模型（LLM）技术，用于对大规模文本数据进行严谨的分析。

Result: 通过使用计算教育数据集来说明LACA的可重复性和严谨性，展示了该方法在CER领域的应用潜力。

Conclusion: LACA方法有潜力在CER领域实现更大规模的研究和更具普遍性的发现，并有助于提升该学科的研究质量和实践水平。

Abstract: Computing education research (CER) is often instigated by practitioners
wanting to improve both their own and the wider discipline's teaching practice.
However, the latter is often difficult as many researchers lack the colleagues,
resources, or capacity to conduct research that is generalisable or rigorous
enough to advance the discipline. As a result, research methods that enable
sense-making with larger volumes of qualitative data, while not increasing the
burden on the researcher, have significant potential within CER.
  In this discussion paper, we propose such a method for conducting rigorous
analysis on large volumes of textual data, namely a variation of LLM-assisted
content analysis (LACA). This method combines content analysis with the use of
large language models, empowering researchers to conduct larger-scale research
which they would otherwise not be able to perform. Using a computing education
dataset, we illustrate how LACA could be applied in a reproducible and rigorous
manner. We believe this method has potential in CER, enabling more
generalisable findings from a wider range of research. This, together with the
development of similar methods, can help to advance both the practice and
research quality of the CER discipline.

</details>


### [112] [Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent framework](https://arxiv.org/abs/2508.18929)
*Ilias Driouich,Hongliu Cao,Eoin Thomas*

Main category: cs.CL

TL;DR: 该论文提出了一种新的多智能体框架，用于生成用于检索增强生成（RAG）评估的合成问答数据集，该框架优先考虑语义多样性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统评估方法未能充分关注评估数据集的设计和质量，而这对于实现有意义、可靠的评估至关重要。

Method: 提出一个包含三个智能体的多智能体框架：1. 多样性智能体：利用聚类技术最大化主题覆盖和语义多样性。2. 隐私智能体：检测并屏蔽跨多个域的敏感信息。3. 问答策划智能体：合成私密且多样化的问答对，作为RAG评估的地面真实。

Result: 实验证明，所提出的评估集在多样性方面优于基线方法，并在特定领域的数据集上实现了稳健的隐私屏蔽。

Conclusion: 这项工作为更安全、更全面的RAG系统评估提供了一条实用且符合伦理的途径，为未来符合不断变化的AI法规和合规性标准奠定了基础。

Abstract: Retrieval-augmented generation (RAG) systems improve large language model
outputs by incorporating external knowledge, enabling more informed and
context-aware responses. However, the effectiveness and trustworthiness of
these systems critically depends on how they are evaluated, particularly on
whether the evaluation process captures real-world constraints like protecting
sensitive information. While current evaluation efforts for RAG systems have
primarily focused on the development of performance metrics, far less attention
has been given to the design and quality of the underlying evaluation datasets,
despite their pivotal role in enabling meaningful, reliable assessments. In
this work, we introduce a novel multi-agent framework for generating synthetic
QA datasets for RAG evaluation that prioritize semantic diversity and privacy
preservation. Our approach involves: (1) a Diversity agent leveraging
clustering techniques to maximize topical coverage and semantic variability,
(2) a Privacy Agent that detects and mask sensitive information across multiple
domains and (3) a QA curation agent that synthesizes private and diverse QA
pairs suitable as ground truth for RAG evaluation. Extensive experiments
demonstrate that our evaluation sets outperform baseline methods in diversity
and achieve robust privacy masking on domain-specific datasets. This work
offers a practical and ethically aligned pathway toward safer, more
comprehensive RAG system evaluation, laying the foundation for future
enhancements aligned with evolving AI regulations and compliance standards.

</details>


### [113] [Interpretable by AI Mother Tongue: Native Symbolic Reasoning in Neural Models](https://arxiv.org/abs/2508.18988)
*Hung Ming Liu*

Main category: cs.CL

TL;DR: 该研究提出了一种AI母语框架，它使用户能够直接在模型的表示中嵌入推理过程，从而实现可解释、符合直觉且灵活的推理。通过符号、推理链和门控诱导机制，该框架能够生成可验证的推理过程，并在实验中展现出与现有方法相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种AI母语，它能够同时支持直观推理、组合符号链和固有的可解释性，并希望将推理过程直接嵌入到模型的表示中，而不是依赖于事后的解释方法。

Method: 该研究提出的方法是开发一个AI母语框架，其中神经模型能够开发一种原生的符号语言。该方法将推理过程直接嵌入到模型的表示中，利用符号来捕获有意义的语义模式，利用链来追踪决策路径，并利用门控诱导机制来指导选择性关注。此外，该研究还引入了补充性训练目标来增强符号纯度和决策稀疏性，并采用了顺序专门化策略来首先建立广泛的符号能力，然后完善直观判断。

Result: 实验表明，AI母语框架在AI任务上实现了具有可验证推理轨迹的竞争性准确性，证明了其作为神经网络中可解释性、直观性和符号推理的统一机制的潜力。

Conclusion: AI母语框架能够为神经网络提供一个统一的机制，以实现可解释性、直观性和符号推理，并在实验中证明了其在准确性和可验证推理轨迹方面的有效性。

Abstract: We present a framework where neural models develop an AI Mother Tongue, a
native symbolic language that simultaneously supports intuitive reasoning,
compositional symbol chains, and inherent interpretability. Unlike post-hoc
explanation methods, our approach embeds reasoning directly into the model's
representations: symbols capture meaningful semantic patterns, chains trace
decision paths, and gated induction mechanisms guide selective focus, yielding
transparent yet flexible reasoning. We introduce complementary training
objectives to enhance symbol purity and decision sparsity, and employ a
sequential specialization strategy to first build broad symbolic competence and
then refine intuitive judgments. Experiments on AI tasks demonstrate
competitive accuracy alongside verifiable reasoning traces, showing that AI
Mother Tongue can serve as a unified mechanism for interpretability, intuition,
and symbolic reasoning in neural models.

</details>


### [114] [Automatic Prompt Optimization with Prompt Distillation](https://arxiv.org/abs/2508.18992)
*Viktor N. Zhuravlev,Artur R. Khairullin,Ernest A. Dyagin,Alena N. Sitkina,Nikita I. Kulin*

Main category: cs.CL

TL;DR: DistillPrompt是一种基于LLM的新型自动提示方法，通过蒸馏、压缩和聚合任务信息来优化提示，在文本分类和生成任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展和提示工程研究的深入，自动选择优化的语言模型提示（autoprompting）变得越来越受欢迎。

Method: DistillPrompt采用多阶段集成任务特定信息到提示中的方法，利用蒸馏、压缩和聚合操作来更全面地探索提示空间。

Result: 在文本分类和生成任务的多个数据集上，使用t-lite-instruct-0.1语言模型进行测试，DistillPrompt相比Grips等现有方法在关键指标上平均提升了20.12%，证明了其有效性。

Conclusion: DistillPrompt是一种高效的非梯度autoprompting方法。

Abstract: Autoprompting is the process of automatically selecting optimized prompts for
language models, which is gaining popularity due to the rapid development of
prompt engineering driven by extensive research in the field of large language
models (LLMs). This paper presents DistillPrompt -- a novel autoprompting
method based on large language models that employs a multi-stage integration of
task-specific information into prompts using training data. DistillPrompt
utilizes distillation, compression, and aggregation operations to explore the
prompt space more thoroughly. The method was tested on different datasets for
text classification and generation tasks using the t-lite-instruct-0.1 language
model. The results demonstrate a significant average improvement (e.g., 20.12%
across the entire dataset compared to Grips) in key metrics over existing
methods in the field, establishing DistillPrompt as one of the most effective
non-gradient approaches in autoprompting.

</details>


### [115] [MovieCORE: COgnitive REasoning in Movies](https://arxiv.org/abs/2508.19026)
*Gueter Josmy Faure,Min-Hung Chen,Jia-Fong Yeh,Ying Cheng,Hung-Ting Su,Yung-Hao Tang,Shang-Hong Lai,Winston H. Hsu*

Main category: cs.CL

TL;DR: MovieCORE是一个新的视频问答数据集，用于测试电影内容理解，它强调需要系统2思考的问题，并引入了一种基于LLM的问答生成方法和ACE模块来提高VQA模型的能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注表面理解，而MovieCORE旨在深入探究电影内容，考察需要系统2思考能力的问题。

Method: 使用多LLM作为思想代理来生成和优化高质量问答对，并提出ACE模块来增强模型的事后推理能力。

Result: ACE模块将模型推理能力提高了25%，并提出了一套评估数据集质量和VQA模型在更深层次认知任务表现的方案。

Conclusion: MovieCORE数据集和ACE模块推动了AI对电影的理解，并为评估VQA模型在处理细致、复杂问题上的能力提供了新方法。

Abstract: This paper introduces MovieCORE, a novel video question answering (VQA)
dataset designed to probe deeper cognitive understanding of movie content.
Unlike existing datasets that focus on surface-level comprehension, MovieCORE
emphasizes questions that engage System-2 thinking while remaining specific to
the video material. We present an innovative agentic brainstorming approach,
utilizing multiple large language models (LLMs) as thought agents to generate
and refine high-quality question-answer pairs. To evaluate dataset quality, we
develop a set of cognitive tests assessing depth, thought-provocation
potential, and syntactic complexity. We also propose a comprehensive evaluation
scheme for assessing VQA model performance on deeper cognitive tasks. To
address the limitations of existing video-language models (VLMs), we introduce
an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves
model reasoning capabilities post-training by up to 25%. Our work contributes
to advancing movie understanding in AI systems and provides valuable insights
into the capabilities and limitations of current VQA models when faced with
more challenging, nuanced questions about cinematic content. Our project page,
dataset and code can be found at
https://joslefaure.github.io/assets/html/moviecore.html.

</details>


### [116] [HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance](https://arxiv.org/abs/2508.19076)
*Ziyue Li,Yuan Chang,Gaihong Yu,Xiaoqiu Le*

Main category: cs.CL

TL;DR: HiPlan是一个分层规划框架，通过提供自适应的全局-局部指导来增强基于LLM的智能体的决策能力，解决了LLM在复杂、长远规划中能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在决策任务中表现出色，但在复杂的长远规划场景中存在不足，主要由于缺乏宏观指导导致迷失方向和执行过程中缺乏持续监督，使其无法适应环境变化并容易偏离目标。

Method: HiPlan将复杂任务分解为里程碑式动作指南（提供大方向）和步骤式提示（提供详细动作）。在离线阶段，通过专家演示构建里程碑库，并能通过检索语义上相似的任务和里程碑来实现结构化的经验复用。在执行阶段，动态调整过去里程碑的轨迹片段，生成步骤式提示，使当前观察与里程碑目标保持一致，从而弥补差距和纠正偏差。

Result: 在两个具有挑战性的基准测试上的大量实验表明，HiPlan的性能远超强大的基线模型，并且消融研究验证了其分层组件的互补效益。

Conclusion: HiPlan通过分层规划和自适应指导，显著提升了LLM智能体在复杂长远规划任务中的决策能力。

Abstract: Large language model (LLM)-based agents have demonstrated remarkable
capabilities in decision-making tasks, but struggle significantly with complex,
long-horizon planning scenarios. This arises from their lack of macroscopic
guidance, causing disorientation and failures in complex tasks, as well as
insufficient continuous oversight during execution, rendering them unresponsive
to environmental changes and prone to deviations. To tackle these challenges,
we introduce HiPlan, a hierarchical planning framework that provides adaptive
global-local guidance to boost LLM-based agents'decision-making. HiPlan
decomposes complex tasks into milestone action guides for general direction and
step-wise hints for detailed actions. During the offline phase, we construct a
milestone library from expert demonstrations, enabling structured experience
reuse by retrieving semantically similar tasks and milestones. In the execution
phase, trajectory segments from past milestones are dynamically adapted to
generate step-wise hints that align current observations with the milestone
objectives, bridging gaps and correcting deviations. Extensive experiments
across two challenging benchmarks demonstrate that HiPlan substantially
outperforms strong baselines, and ablation studies validate the complementary
benefits of its hierarchical components.

</details>


### [117] ["Where does it hurt?" -- Dataset and Study on Physician Intent Trajectories in Doctor Patient Dialogues](https://arxiv.org/abs/2508.19077)
*Tom Röhr,Soumyadeep Roy,Fares Al Mohamad,Jens-Michalis Papaioannou,Wolfgang Nejdl,Felix Gers,Alexander Löser*

Main category: cs.CL

TL;DR: 本文首次研究了医生-患者对话中的医生意图轨迹，使用SOAP框架对5000多个对话轮次进行了标注，并在此基础上对当前最先进的模型进行了基准测试。研究发现模型能准确理解对话结构，但在识别SOAP类别转换方面存在困难。此外，本文还首次报告了医疗对话结构中的常见轨迹，为设计“鉴别诊断”系统提供了见解，并证明意图过滤能显著提升对话摘要的性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究医生-患者对话中的医生意图轨迹，以期为设计“鉴别诊断”系统提供见解，并优化医疗对话摘要的性能。

Method: 研究人员与医学专家合作，基于SOAP框架开发了精细的医生意图分类法。随后，他们利用Prolific众包平台招募了大量医学专家，对5000多个医生-患者对话轮次进行了标注，构建了一个大型标注数据集。利用该数据集，他们对当前最先进的生成模型和编码器模型在医疗意图分类任务上的表现进行了基准测试，并研究了意图过滤对医疗对话摘要性能的影响。

Result: 研究结果表明，模型能够高精度地理解医疗对话的整体结构，但在识别SOAP类别之间的转换方面表现不佳。此外，研究还首次揭示了医疗对话结构中的常见轨迹模式，并证明意图过滤能够显著提高对话摘要的性能。

Conclusion: 本文提出的方法和数据集为理解和处理医生-患者对话提供了重要资源。尽管模型在识别SOAP类别转换方面仍有提升空间，但研究结果为开发更有效的“鉴别诊断”系统和改进医疗对话摘要技术提供了有价值的指导。

Abstract: In a doctor-patient dialogue, the primary objective of physicians is to
diagnose patients and propose a treatment plan. Medical doctors guide these
conversations through targeted questioning to efficiently gather the
information required to provide the best possible outcomes for patients. To the
best of our knowledge, this is the first work that studies physician intent
trajectories in doctor-patient dialogues. We use the `Ambient Clinical
Intelligence Benchmark' (Aci-bench) dataset for our study. We collaborate with
medical professionals to develop a fine-grained taxonomy of physician intents
based on the SOAP framework (Subjective, Objective, Assessment, and Plan). We
then conduct a large-scale annotation effort to label over 5000 doctor-patient
turns with the help of a large number of medical experts recruited using
Prolific, a popular crowd-sourcing platform. This large labeled dataset is an
important resource contribution that we use for benchmarking the
state-of-the-art generative and encoder models for medical intent
classification tasks. Our findings show that our models understand the general
structure of medical dialogues with high accuracy, but often fail to identify
transitions between SOAP categories. We also report for the first time common
trajectories in medical dialogue structures that provide valuable insights for
designing `differential diagnosis' systems. Finally, we extensively study the
impact of intent filtering for medical dialogue summarization and observe a
significant boost in performance. We make the codes and data, including
annotation guidelines, publicly available at
https://github.com/DATEXIS/medical-intent-classification.

</details>


### [118] [It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs](https://arxiv.org/abs/2508.19089)
*Yue Li,Zhixue Zhao,Carolina Scarton*

Main category: cs.CL

TL;DR: LLMs难以支持低资源语言，尤其是罕见文字的语言。本文首次全面分析了LLMs能否仅通过上下文学习（ICL）来学习这些语言，以及与参数高效微调（PEFT）的比较。


<details>
  <summary>Details</summary>
Motivation: LLMs难以支持低资源语言，尤其是罕见文字的语言，主要原因是缺乏训练数据。

Method: 系统评估了20种代表性不足的语言在三种先进的多语言LLMs上的表现，比较了仅上下文学习（ICL）和参数高效微调（PEFT）的效果，并考虑了辅助对齐信号。

Result: 对于语言和文字都极度缺失的语言，PEFT效果有限。相比之下，带语言对齐信号的零样本ICL在极低资源语言上表现出色。而少样本ICL或PEFT则更适合在LLM中有较好表示的语言。

Conclusion: 为LLM实践者提供了在低资源语言上适配LLMs的指南，例如避免在具有未见文字的语言上微调多语言模型。

Abstract: Extremely low-resource languages, especially those written in rare scripts,
as shown in Figure 1, remain largely unsupported by large language models
(LLMs). This is due in part to compounding factors such as the lack of training
data. This paper delivers the first comprehensive analysis of whether LLMs can
acquire such languages purely via in-context learning (ICL), with or without
auxiliary alignment signals, and how these methods compare to
parameter-efficient fine-tuning (PEFT). We systematically evaluate 20
under-represented languages across three state-of-the-art multilingual LLMs.
Our findings highlight the limitation of PEFT when both language and its script
are extremely under-represented by the LLM. In contrast, zero-shot ICL with
language alignment is impressively effective on extremely low-resource
languages, while few-shot ICL or PEFT is more beneficial for languages
relatively better represented by LLMs. For LLM practitioners working on
extremely low-resource languages, we summarise guidelines grounded by our
results on adapting LLMs to low-resource languages, e.g., avoiding fine-tuning
a multilingual model on languages of unseen scripts.

</details>


### [119] [Retrieval-Augmented Generation for Natural Language Art Provenance Searches in the Getty Provenance Index](https://arxiv.org/abs/2508.19093)
*Mathew Henrickson*

Main category: cs.CL

TL;DR: 本研究提出了一种用于艺术溯源研究的检索增强生成（RAG）框架，重点关注盖蒂溯源索引。该框架能够通过语义检索和上下文摘要，实现自然语言和多语言搜索，减少对元数据结构的依赖，为艺术品历史记录的检索和总结提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 艺术品溯源研究对于验证真伪、支持归还和法律索赔以及理解艺术品的文化和历史背景至关重要。然而，现有研究面临着数据碎片化、多语言以及需要精确元数据才能进行有效检索的挑战，限制了探索性搜索。

Method: 本研究提出了一种检索增强生成（RAG）框架，通过语义检索和上下文摘要，实现自然语言和多语言搜索，从而减少对元数据结构的依赖。

Result: 通过对盖蒂溯源索引-德国销售的10,000条记录进行评估，结果表明该方法为导航艺术品市场档案提供了一个可扩展的解决方案。

Conclusion: 该RAG框架为历史学家和文化遗产专业人士提供了一个实用的工具，能够有效应对艺术品溯源研究中数据检索的挑战。

Abstract: This research presents a Retrieval-Augmented Generation (RAG) framework for
art provenance studies, focusing on the Getty Provenance Index. Provenance
research establishes the ownership history of artworks, which is essential for
verifying authenticity, supporting restitution and legal claims, and
understanding the cultural and historical context of art objects. The process
is complicated by fragmented, multilingual archival data that hinders efficient
retrieval. Current search portals require precise metadata, limiting
exploratory searches. Our method enables natural-language and multilingual
searches through semantic retrieval and contextual summarization, reducing
dependence on metadata structures. We assess RAG's capability to retrieve and
summarize auction records using a 10,000-record sample from the Getty
Provenance Index - German Sales. The results show this approach provides a
scalable solution for navigating art market archives, offering a practical tool
for historians and cultural heritage professionals conducting historically
sensitive research.

</details>


### [120] [Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic](https://arxiv.org/abs/2508.19099)
*Thomas Compton*

Main category: cs.CL

TL;DR: 本研究提出了一种结合词汇和语义方法的混合、透明的定量话语分析（QDA）框架，以提高方法透明度、可复现性和可解释性，并解决了对MAXQDA和NVivo等黑箱软件的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 为解决黑箱软件在方法透明度和研究目标一致性方面存在的不足，提出一种混合、透明的QDA框架，以实现三角互证、可复现性和可解释性。

Method: 结合词汇和语义方法，使用Python（NLTK、spaCy、Sentence Transformers）和BERTopic（UMAP、HDBSCAN、c-TF-IDF）进行文本预处理、词形还原、词嵌入生成和主题建模，并通过参数调优和多次运行优化。

Result: 通过历史政治话语案例研究，展示了自定义Python流程在细粒度控制和BERTopic建模过程中的有效性，并通过词汇搜索与语义聚类相结合，证明了多层次方法在克服单一方法局限性方面的优势。

Conclusion: 强调了代码级透明度、研究者能动性和计算话语研究中的方法三角互证的重要性。

Abstract: Quantitative Discourse Analysis has seen growing adoption with the rise of
Large Language Models and computational tools. However, reliance on black box
software such as MAXQDA and NVivo risks undermining methodological transparency
and alignment with research goals. This paper presents a hybrid, transparent
framework for QDA that combines lexical and semantic methods to enable
triangulation, reproducibility, and interpretability. Drawing from a case study
in historical political discourse, we demonstrate how custom Python pipelines
using NLTK, spaCy, and Sentence Transformers allow fine-grained control over
preprocessing, lemmatisation, and embedding generation. We further detail our
iterative BERTopic modelling process, incorporating UMAP dimensionality
reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised
through parameter tuning and multiple runs to enhance topic coherence and
coverage. By juxtaposing precise lexical searches with context-aware semantic
clustering, we argue for a multi-layered approach that mitigates the
limitations of either method in isolation. Our workflow underscores the
importance of code-level transparency, researcher agency, and methodological
triangulation in computational discourse studies. Code and supplementary
materials are available via GitHub.

</details>


### [121] [Do LVLMs Know What They Know? A Systematic Study of Knowledge Boundary Perception in LVLMs](https://arxiv.org/abs/2508.19111)
*Zhikai Ding,Shiyu Ni,Keping Bi*

Main category: cs.CL

TL;DR: LVLMs在VQA方面表现出色，但存在幻觉问题。本研究评估了LVLMs的知识边界感知能力，考察了概率置信度、答案一致性置信度和语言化置信度三种信号。实验表明，LVLMs的感知能力有待提高，其中概率和一致性信号更可靠，而语言化置信度常导致过度自信。研究还提出并验证了三种提高LVLMs感知能力的方法，并发现与LLMs相比，LVLMs虽然问答性能有所下降，但置信度降低，感知能力得到提升。


<details>
  <summary>Details</summary>
Motivation: 评估大型视觉语言模型（LVLMs）的知识边界感知能力，并提出改进方法，以解决其在视觉问答（VQA）中存在的幻觉问题。

Method: 评估了三种置信度信号（概率置信度、答案一致性置信度、语言化置信度），并在三个LVLMs和三个VQA数据集上进行了实验。同时，研究将LVLMs与LLMs进行了比较，并改编了LLMs的置信度校准方法，提出了三种新的有效方法。

Result: LVLMs的知识边界感知能力有待提高。概率置信度和答案一致性置信度是更可靠的信号，而语言化置信度常导致过度自信。提出的三种新方法能有效提升LVLMs的感知能力。与LLMs相比，LVLMs在联合处理视觉和文本输入时，问答性能有所下降，但置信度降低，感知能力得到提升。

Conclusion: LVLMs具有一定的知识边界感知能力，但仍有提升空间。通过采用更可靠的置信度信号和改进的校准方法，可以增强其感知能力，使其在VQA任务中更加可靠。与LLMs相比，LVLMs在视觉信息处理方面虽然牺牲了一部分问答性能，但在提高模型可信度方面表现更优。

Abstract: Large vision-language models (LVLMs) demonstrate strong visual question
answering (VQA) capabilities but are shown to hallucinate. A reliable model
should perceive its knowledge boundaries-knowing what it knows and what it does
not. This paper investigates LVLMs' perception of their knowledge boundaries by
evaluating three types of confidence signals: probabilistic confidence, answer
consistency-based confidence, and verbalized confidence. Experiments on three
LVLMs across three VQA datasets show that, although LVLMs possess a reasonable
perception level, there is substantial room for improvement. Among the three
confidences, probabilistic and consistency-based signals are more reliable
indicators, while verbalized confidence often leads to overconfidence. To
enhance LVLMs' perception, we adapt several established confidence calibration
methods from Large Language Models (LLMs) and propose three effective methods.
Additionally, we compare LVLMs with their LLM counterparts, finding that
jointly processing visual and textual inputs decreases question-answering
performance but reduces confidence, resulting in an improved perception level
compared to LLMs.

</details>


### [122] [Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning](https://arxiv.org/abs/2508.19202)
*Alan Li,Yixin Liu,Arpan Sarkar,Doug Downey,Arman Cohan*

Main category: cs.CL

TL;DR: 介绍SciReas和SciReas-Pro基准，以及KRUX框架，用于评估和分析大型语言模型在科学问题解决中的知识检索和推理能力。发现检索知识是瓶颈，外部知识和增强推理有助于提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估大型语言模型科学推理能力的综合基准，并且现有方法未能有效区分知识和推理在任务中的作用。

Method: 创建SciReas（包含现有科学推理基准的集合）和SciReas-Pro（包含更复杂推理的子集）。提出KRUX框架来研究推理和知识的独立作用。

Result: 1. 检索模型参数中的任务相关知识是大型语言模型在科学推理中的关键瓶颈。2. 外部知识在上下文中添加，可以持续提升推理模型的性能。3. 增强推理能力可以提升模型检索任务相关知识的能力。

Conclusion: 通过SciReas、SciReas-Pro和KRUX的综合评估和分析，揭示了大型语言模型在科学推理中的知识检索和推理瓶颈，并提出了提升其性能的有效方法。

Abstract: Scientific problem solving poses unique challenges for LLMs, requiring both
deep domain knowledge and the ability to apply such knowledge through complex
reasoning. While automated scientific reasoners hold great promise for
assisting human scientists, there is currently no widely adopted holistic
benchmark for evaluating scientific reasoning, and few approaches
systematically disentangle the distinct roles of knowledge and reasoning in
these tasks. To address these gaps, we introduce SciReas, a diverse suite of
existing benchmarks for scientific reasoning tasks, and SciReas-Pro, a
selective subset that requires more complex reasoning. Our holistic evaluation
surfaces insights about scientific reasoning performance that remain hidden
when relying on individual benchmarks alone. We then propose KRUX, a probing
framework for studying the distinct roles of reasoning and knowledge in
scientific tasks. Combining the two, we conduct an in-depth analysis that
yields several key findings: (1) Retrieving task-relevant knowledge from model
parameters is a critical bottleneck for LLMs in scientific reasoning; (2)
Reasoning models consistently benefit from external knowledge added in-context
on top of the reasoning enhancement; (3) Enhancing verbalized reasoning
improves LLMs' ability to surface task-relevant knowledge. Finally, we conduct
a lightweight analysis, comparing our science-focused data composition with
concurrent efforts on long CoT SFT, and release SciLit01, a strong 8B baseline
for scientific reasoning.

</details>


### [123] [VibeVoice Technical Report](https://arxiv.org/abs/2508.19205)
*Zhiliang Peng,Jianwei Yu,Wenhui Wang,Yaoyao Chang,Yutao Sun,Li Dong,Yi Zhu,Weijiang Xu,Hangbo Bao,Zehua Wang,Shaohan Huang,Yan Xia,Furu Wei*

Main category: cs.CL

TL;DR: VibeVoice是一个利用next-token diffusion生成长篇多语种语音的新模型，其压缩效率是Encodec的80倍，能合成长达90分钟、最多4个说话者的语音，并在对话保真度上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 本报告提出了一种名为VibeVoice的新型模型，旨在通过采用next-token diffusion来合成具有多说话者的长篇语音。Next-token diffusion是一种通过扩散模型自回归地生成潜在向量来模拟连续数据（如语音）的统一方法。

Method: VibeVoice采用next-token diffusion技术，并引入了一种新的连续语音分词器。该分词器在数据压缩方面比Encodec模型提高了80倍，同时保持了相当的性能，有效保留了音频保真度并提高了处理长序列的计算效率。

Result: VibeVoice能够合成长达90分钟的语音，支持最多4个说话者，并能捕捉真实的对话“氛围”，在性能上超越了开源和专有对话模型。

Conclusion: VibeVoice通过其创新的next-token diffusion方法和高效的连续语音分词器，成功实现了长篇、多说话者的语音合成，并在压缩效率和对话保真度方面取得了显著的成果。

Abstract: This report presents VibeVoice, a novel model designed to synthesize
long-form speech with multiple speakers by employing next-token diffusion,
which is a unified method for modeling continuous data by autoregressively
generating latent vectors via diffusion. To enable this, we introduce a novel
continuous speech tokenizer that, when compared to the popular Encodec model,
improves data compression by 80 times while maintaining comparable performance.
The tokenizer effectively preserves audio fidelity while significantly boosting
computational efficiency for processing long sequences. Thus, VibeVoice can
synthesize long-form speech for up to 90 minutes (in a 64K context window
length) with a maximum of 4 speakers, capturing the authentic conversational
``vibe'' and surpassing open-source and proprietary dialogue models.

</details>


### [124] [Evaluating the Evaluators: Are readability metrics good measures of readability?](https://arxiv.org/abs/2508.19221)
*Isabel Cachola,Daniel Khashabi,Mark Dredze*

Main category: cs.CL

TL;DR: 该论文调查了文本可读性评估方法，发现传统指标（如FKGL）与人类判断的相关性较差，而语言模型（LM）是更好的可读性评估指标。


<details>
  <summary>Details</summary>
Motivation: 评估现有文本可读性指标在普通语言文本摘要（PLS）中的有效性，并探索语言模型作为可读性评估指标的可能性。

Method: 评估了8种可读性指标，并将其与人类可读性判断进行比较。然后，研究了语言模型在评估PLS数据集中的可读性表现。

Result: 大多数传统可读性指标（包括FKGL）与人类判断的相关性较差。语言模型在可读性评估方面表现更好，其中最佳模型的皮尔逊相关系数为0.56。语言模型比传统指标更能捕捉到隐含的可读性维度，如背景知识要求。

Conclusion: 传统可读性指标在PLS领域可能无法准确反映人类的可读性判断。语言模型在评估PLS方面更有前景，并可能提供更深入的可读性见解。建议采用更先进的评估方法，并提供了PLS评估的最佳实践建议。

Abstract: Plain Language Summarization (PLS) aims to distill complex documents into
accessible summaries for non-expert audiences. In this paper, we conduct a
thorough survey of PLS literature, and identify that the current standard
practice for readability evaluation is to use traditional readability metrics,
such as Flesch-Kincaid Grade Level (FKGL). However, despite proven utility in
other fields, these metrics have not been compared to human readability
judgments in PLS. We evaluate 8 readability metrics and show that most
correlate poorly with human judgments, including the most popular metric, FKGL.
We then show that Language Models (LMs) are better judges of readability, with
the best-performing model achieving a Pearson correlation of 0.56 with human
judgments. Extending our analysis to PLS datasets, which contain summaries
aimed at non-expert audiences, we find that LMs better capture deeper measures
of readability, such as required background knowledge, and lead to different
conclusions than the traditional metrics. Based on these findings, we offer
recommendations for best practices in the evaluation of plain language
summaries. We release our analysis code and survey data.

</details>


### [125] [Generative Interfaces for Language Models](https://arxiv.org/abs/2508.19227)
*Jiaqi Chen,Yanzhe Zhang,Yutong Zhang,Yijia Shao,Diyi Yang*

Main category: cs.CL

TL;DR: LLM可以通过生成用户界面（UI）来改进人机交互，提高效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的大语言模型（LLM）系统采用线性的请求-响应格式，这在多轮、信息密集和探索性任务中效率低下。为了克服这些限制，需要一种新的交互范式。

Method: 提出了一种生成式语言模型接口（Generative Interfaces for Language Models）的范例，该范例利用结构化的、特定于接口的表示和迭代优化来将用户查询转化为任务特定的用户界面。引入了一个多维评估框架来比较生成式接口和传统的基于聊天的接口。

Result: 在多样的任务、交互模式和查询类型中，生成式接口在功能、交互和情感方面都优于传统的聊天式接口，用户在超过70%的情况下更倾向于使用生成式接口。

Conclusion: 生成式接口在人机交互中具有显著优势，可以提高交互效率和用户体验，为未来的研究指明了方向。

Abstract: Large language models (LLMs) are increasingly seen as assistants, copilots,
and consultants, capable of supporting a wide range of tasks through natural
conversation. However, most systems remain constrained by a linear
request-response format that often makes interactions inefficient in
multi-turn, information-dense, and exploratory tasks. To address these
limitations, we propose Generative Interfaces for Language Models, a paradigm
in which LLMs respond to user queries by proactively generating user interfaces
(UIs) that enable more adaptive and interactive engagement. Our framework
leverages structured interface-specific representations and iterative
refinements to translate user queries into task-specific UIs. For systematic
evaluation, we introduce a multidimensional assessment framework that compares
generative interfaces with traditional chat-based ones across diverse tasks,
interaction patterns, and query types, capturing functional, interactive, and
emotional aspects of user experience. Results show that generative interfaces
consistently outperform conversational ones, with humans preferring them in
over 70% of cases. These findings clarify when and why users favor generative
interfaces, paving the way for future advancements in human-AI interaction.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [126] [A Synoptic Review of High-Frequency Oscillations as a Biomarker in Neurodegenerative Disease](https://arxiv.org/abs/2508.18712)
*Samin Yaser,Mahad Ali,Laura J. Brattain,Yang Jiang,VP Nguyen,Jing Xiang*

Main category: eess.SP

TL;DR: 本文对癫痫高频振荡（HFOs）在阿尔茨海默病（AD）中的作用进行了文献计量学分析和数据库评估，强调了其作为诊断生物标志物的潜力以及数据异质性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨高频振荡（HFOs）作为阿尔茨海默病（AD）早期诊断和疾病追踪的潜在生物标志物的可能性，并评估现有公开脑电图（EEG）数据集的适用性。

Method: 通过文献计量学分析1,222篇相关文献，并系统性地评估了公开的EEG数据集，重点关注数据采集参数和HFO分析的技术兼容性。

Result: 研究发现，HFOs在AD中普遍存在，与网络易感性有关。文献计量学分析显示，HFOs研究在近十年显著增长。然而，不同数据集在采样频率和记录范式上存在方法学异质性，给跨研究验证带来挑战。

Conclusion: HFOs在AD及相关疾病中具有作为跨疾病生物标志物的潜力，但需要解决现有公开数据集的方法学异质性问题，以实现更可靠的跨研究验证和应用。

Abstract: High Frequency Oscillations (HFOs), rapid bursts of brain activity above 80
Hz, have emerged as a highly specific biomarker for epileptogenic tissue.
Recent evidence suggests that HFOs are also present in Alzheimer's Disease
(AD), reflecting underlying network hyperexcitability and offering a promising,
noninvasive tool for early diagnosis and disease tracking. This synoptic review
provides a comprehensive analysis of publicly available electroencephalography
(EEG) datasets relevant to HFO research in neurodegenerative disorders. We
conducted a bibliometric analysis of 1,222 articles, revealing a significant
and growing research interest in HFOs, particularly within the last ten years.
We then systematically profile and compare key public datasets, evaluating
their participant cohorts, data acquisition parameters, and accessibility, with
a specific focus on their technical suitability for HFO analysis. Our
comparative synthesis highlights critical methodological heterogeneity across
datasets, particularly in sampling frequency and recording paradigms, which
poses challenges for cross-study validation, but also offers opportunities for
robustness testing. By consolidating disparate information, clarifying
nomenclature, and providing a detailed methodological framework, this review
serves as a guide for researchers aiming to leverage public data to advance the
role of HFOs as a cross-disease biomarker for AD and related conditions.

</details>


### [127] [SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus](https://arxiv.org/abs/2508.18735)
*Afan Ali,Irfanullah Khan*

Main category: eess.SP

TL;DR: UAV基站面临安全风险，提出DTSAM-EAC机制，结合区块链和联邦学习，实现动态信任评估和能耗优化，提高网络安全性和效率。


<details>
  <summary>Details</summary>
Motivation: UAV基站由于其分布式和动态特性，极易受到安全攻击，特别是来自恶意节点的攻击。

Method: 提出一种动态信任分数调整机制（DTSAM-EAC），结合了许可链Hyperledger Fabric和联邦学习（FL）。信任评分通过加权聚合历史信任、当前行为和能量贡献进行更新。采用一种考虑能量的共识机制，优先选择能量可用的UAV进行区块验证。FL聚合结合信任加权，增强了全局信任模型的弹性。

Result: 仿真结果表明，该框架实现了94%的信任分数预测准确率和96%的虚假UAV检测率。在隐私、能效和可靠性方面优于中心化和静态的信任解决方案。

Conclusion: 该框架符合6G对分布式智能和可持续性的要求，是一种能效高且可扩展的安全NTN解决方案。

Abstract: Non-Terrestrial Networks (NTNs) based on Unmanned Aerial Vehicles (UAVs) as
base stations are extremely susceptible to security attacks due to their
distributed and dynamic nature, which makes them vulnerable to rogue nodes. In
this paper, a new Dynamic Trust Score Adjustment Mechanism with Energy-Aware
Consensus (DTSAM-EAC) is proposed to enhance security in UAV-based NTNs. The
proposed framework integrates a permissioned Hyperledger Fabric blockchain with
Federated Learning (FL) to support privacy-preserving trust evaluation. Trust
ratings are updated continuously through weighted aggregation of past trust,
present behavior, and energy contribution, thus making the system adaptive to
changing network conditions. An energy-aware consensus mechanism prioritizes
UAVs with greater available energy for block validation, ensuring efficient use
of resources under resource-constrained environments. FL aggregation with
trust-weighting further increases the resilience of the global trust model.
Simulation results verify the designed framework achieves 94\% trust score
prediction accuracy and 96\% rogue UAV detection rate while outperforming
centralized and static baselines of trust-based solutions on privacy, energy
efficiency, and reliability. It complies with 6G requirements in terms of
distributed intelligence and sustainability and is an energy-efficient and
scalable solution to secure NTNs.

</details>


### [128] [Near-Field Challenges in Ultra-Wideband ISAC: Beamforming Strategies and System Insights](https://arxiv.org/abs/2508.18810)
*Yonghwi Kim,Sang-Hyun Park,Siyun Yang,Kai-Kit Wong,Linglong Dai,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 6G ISAC面临近场效应和波束 the challenge，本文提出近场超宽带ISAC的波束设计策略，通过码本设计解决波束 the challenge，提升通信和感知性能，并通过仿真验证。


<details>
  <summary>Details</summary>
Motivation: 6G网络将通信感知一体化（ISAC）作为核心，但大天线和超宽带带来近场效应和波束 the challenge，传统远场设计面临挑战，TTD成本高昂。因此，需要新的近场ISAC波束设计策略。

Method: 本文提出实用的近场超宽带ISAC波束设计策略，设计了模拟和数字域的码本，以减轻波束 the challenge，确保用户覆盖和感知精度。通过大规模系统级仿真，包括基于3D地图的城市环境评估，来验证这些方法。

Result: 仿真结果表明，精心设计的波束形成能够平衡通信吞吐量和感知性能，在严苛的近场条件下实现可靠覆盖和高效资源利用。

Conclusion: 文章总结了硬件、算法和系统集成方面的开放性挑战，并指出了塑造6G ISAC网络部署的研究方向。

Abstract: The shift toward sixth-generation (6G) wireless networks places integrated
sensing and communications (ISAC) at the core of future applications such as
autonomous driving, extended reality, and smart manufacturing. However, the
combination of large antenna arrays and ultra-wide bandwidths brings near-field
propagation effects and beam squint to the forefront, fundamentally challenging
traditional far-field designs. True time delay units (TTDs) offer a potential
solution, but their cost and hardware complexity limit scalability. In this
article, we present practical beamforming strategies for near-field
ultra-wideband ISAC systems. We explore codebook designs across analog and
digital domains that mitigate beam squint, ensure reliable user coverage, and
enhance sensing accuracy. We further validate these approaches through
large-scale system-level simulations, including 3D map-based evaluations that
reflect real-world urban environments. Our results demonstrate how carefully
designed beamforming can balance communication throughput with sensing
performance, achieving reliable coverage and efficient resource use even under
severe near-field conditions. We conclude by highlighting open challenges in
hardware, algorithms, and system integration, pointing toward research
directions that will shape the deployment of 6G-ready ISAC networks.

</details>


### [129] [DIFNet: Decentralized Information Filtering Fusion Neural Network with Unknown Correlation in Sensor Measurement Noises](https://arxiv.org/abs/2508.18854)
*Ruifeng Dong,Ming Wang,Ning Liu,Tong Guo,Jiayi Kang,Xiaojing Shen,Yao Mao*

Main category: eess.SP

TL;DR: 该论文提出了一种名为DIFNet的数据驱动方法，用于解决分散式传感器网络中的状态估计问题，特别是在存在未知测量噪声相关性的情况下。DIFNet通过学习噪声相关性来提高融合精度，并在数值模拟中证明了其优于传统滤波方法的性能，即使在时变噪声等复杂场景下也表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 分散式传感器网络在状态估计领域因其鲁棒性、可扩展性和容错性而受到广泛关注。然而，在通信拓扑非全连接和噪声相关性未知的情况下，融合性能会受到影响。该研究旨在解决这些挑战。

Method: 提出了一种名为DIFNet（Decentralized Information Filter Neural Network）的数据驱动方法，用于学习离散时间非线性状态空间模型中未知的测量噪声相关性，以解决由未知相关性引起的融合精度下降问题。

Result: 数值模拟结果表明，DIFNet在融合性能上优于传统的滤波方法，并且在存在时变噪声等更复杂的场景下表现出鲁棒性。

Conclusion: DIFNet能够有效学习未知的噪声相关性，从而在分散式传感器网络的状态估计中实现更高的融合精度和鲁棒性，即使在通信网络非全连接和噪声特性未知的情况下也是如此。

Abstract: In recent years, decentralized sensor networks have garnered significant
attention in the field of state estimation owing to enhanced robustness,
scalability, and fault tolerance. Optimal fusion performance can be achieved
under fully connected communication and known noise correlation structures. To
mitigate communication overhead, the global state estimation problem is
decomposed into local subproblems through structured observation model. This
ensures that even when the communication network is not fully connected, each
sensor can achieve locally optimal estimates of its observable state
components. To address the degradation of fusion accuracy induced by unknown
correlations in measurement noise, this paper proposes a data-driven method,
termed Decentralized Information Filter Neural Network (DIFNet), to learn
unknown noise correlations in data for discrete-time nonlinear state space
models with cross-correlated measurement noises. Numerical simulations
demonstrate that DIFNet achieves superior fusion performance compared to
conventional filtering methods and exhibits robust characteristics in more
complex scenarios, such as the presence of time-varying noise. The source code
used in our numerical experiment can be found online at
https://wisdom-estimation.github.io/DIFNet_Demonstrate/.

</details>


### [130] [Beyond-Diagonal RIS: Adversarial Channels and Optimality of Low-Complexity Architectures](https://arxiv.org/abs/2508.19000)
*Atso Iivanainen,Robin Rajamäki,Visa Koivunen*

Main category: eess.SP

TL;DR: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) can optimize phase and amplitude responses, but their worst-case performance is underexplored. This paper analyzes adversarial channels for group-connected and tree-connected BD-RIS architectures, revealing performance degradation and connections between the architectures. The findings aid in designing robust BD-RIS systems.


<details>
  <summary>Details</summary>
Motivation: While BD-RISs offer enhanced performance over conventional RISs by optimizing both phase and amplitude, their worst-case performance, particularly under adversarial conditions, has not been sufficiently investigated. Understanding these vulnerabilities is crucial for developing robust BD-RIS systems.

Method: This paper characterizes novel sets of adversarial channels specifically designed to expose suboptimal performance in low-complexity BD-RIS architectures. The analysis focuses on two specific BD-RIS models: group-connected and tree-connected architectures. Analytical results are derived and then validated through numerical simulations to demonstrate the performance impact of these adversarial channels.

Result: The analysis identified specific adversarial channel sets that lead to significant performance degradation (reduced received signal power) in both group-connected and tree-connected BD-RIS architectures. Surprisingly, these adversarial channels revealed previously unknown connections between the two architectures. Numerical validation confirmed the substantial performance loss caused by these adversarial conditions.

Conclusion: The study demonstrates that adversarial channels can indeed cause significant performance degradation in low-complexity BD-RIS architectures. The identified adversarial channel sets highlight vulnerabilities and reveal novel interconnections between group-connected and tree-connected BD-RIS models. These findings are essential for the development of BD-RIS designs that are resilient to adverse propagation environments and potential malicious attacks, paving the way for more robust and secure future communication systems.

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) have recently
gained attention as an enhancement to conventional RISs. BD-RISs allow
optimizing not only the phase, but also the amplitude responses of their
discrete surface elements by introducing adjustable inter-element couplings.
Various BD-RIS architectures have been proposed to optimally trade off between
average performance and complexity of the architecture. However, little
attention has been paid to worst-case performance. This paper characterizes
novel sets of adversarial channels for which certain low-complexity BD-RIS
architectures have suboptimal performance in terms of received signal power at
an intended communications user. Specifically, we consider two recent BD-RIS
models: the so-called group-connected and tree-connected architecture. The
derived adversarial channel sets reveal new surprising connections between the
two architectures. We validate our analytical results numerically,
demonstrating that adversarial channels can cause a significant performance
loss. Our results pave the way towards efficient BD-RIS designs that are robust
to adversarial propagation conditions and malicious attacks.

</details>


### [131] [mmKey: Channel-Aware Beam Shaping for Reliable Key Generation in mmWave Wireless Networks](https://arxiv.org/abs/2508.19010)
*Poorya Mollahosseini,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: mmWave信道特性（稀疏性、相位噪声、路径损耗）给物理层密钥生成带来挑战。本文提出mmKey框架，利用多天线技术注入随机性，并通过遗传算法优化波束形成，在抑制视距传播分量的同时考虑信道条件（稀疏性和信噪比），从而在密钥安全性和鲁棒性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 为了在毫米波（mmWave）通信中克服信道稀疏性、相位噪声和路径损耗等挑战，这些挑战会影响安全密钥生成的随机性和互易性，提出一种新的物理层密钥生成（PLKG）框架。

Method: 利用毫米波节点的多天线特性，通过遗传算法逐步优化初始权重向量，以抑制视距（LOS）分量，并考虑信道条件（稀疏性和信噪比），从而在密钥安全性和鲁棒性之间取得平衡。

Result: 与随机波束成形相比，mmKey将保密性差距平均提高了39.4%；与零波束成形相比，平均提高了34.0%，优于传统方案。

Conclusion: mmKey通过利用多天线和遗传算法优化波束形成，能够有效克服毫米波信道的挑战，在密钥安全性和鲁棒性之间取得良好平衡，从而在物理层密钥生成方面优于现有方案。

Abstract: Physical-layer key generation (PLKG) has emerged as a promising technique to
secure next-generation wireless networks by exploiting the inherent properties
of the wireless channel. However, PLKG faces fundamental challenges in the
millimeter wave (mmWave) regime due to channel sparsity, higher phase noise,
and higher path loss, which undermine both the randomness and reciprocity
required for secure key generation. In this paper, we present mmKey, a novel
PLKG framework that capitalizes on the availability of multiple antennas at
mmWave wireless nodes to inject randomness into an otherwise quasi-static
wireless channel. Different from prior works that sacrifice either the secrecy
of the key generation or the robustness, mmKey balances these two requirements.
In particular, mmKey leverages a genetic algorithm to gradually evolve the
initial weight vector population toward configurations that suppress the LOS
component while taking into account the channel conditions, specifically, the
sparsity and the signal-to-noise ratio (SNR). Extensive simulations show that
mmKey improves the secrecy gap by an average of 39.4% over random beamforming
and 34.0% over null beamforming, outperforming conventional schemes.

</details>


### [132] [Fast Vortex Beam Alignment for OAM Mode Multiplexing in LOS MIMO Networks](https://arxiv.org/abs/2508.19034)
*Poorya Mollahosseini,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: OrthoVortex框架通过估计失准角度并应用相位校正来恢复OAM模式的正交性，解决了节点失准问题，并在120 GHz的实验中实现了精确的失准估计和显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 节点失准会破坏OAM模式的正交性，从而影响数据复用增益，这阻碍了OAM通信系统在高容量复用方面的应用。

Method: OrthoVortex框架通过利用交叉模式相位作为识别失准角度的独特签名，估计失准角度并应用相位校正来恢复模式正交性。该方法是一种少样本对齐技术。

Result: 在120 GHz的实验中，OrthoVortex实现了精确的失准估计（方位角平均绝对误差为0.69°，仰角为2.54°），并将模式间干扰减少了12 dB以上，链路容量提高了4.5倍以上。

Conclusion: OrthoVortex框架在120 GHz的实验中得到了验证，它能够精确估计OAM模式的失准角度并恢复模式正交性，从而显著提高通信系统的性能。

Abstract: Orbital Angular Momentum (OAM)-based communication systems offer
high-capacity multiplexing in line-of-sight (LOS) scenarios; yet, their
performance is sensitive to nodal misalignment, which disrupts modal
orthogonality, hindering the data multiplexing gain. To tackle this challenge,
we present OrthoVortex, a novel framework that estimates the misalignment
angles and applies the appropriate phase correction to restore orthogonality
between modes. Unlike purely theoretical prior efforts that rely on impractical
fully digital arrays or exhaustive beam scans, OrthoVortex introduces and
leverages the cross-modal phase, as a unique signature for identifying the
misalignment angles. OrthoVortex is a few-shot alignment technique, making it
feasible for real-world implementations. Our key contributions include: (i) a
robust angle estimation and phase correction framework based on the physics of
OAM propagation that estimates the misalignment and restores modal
orthogonality, (ii) the first-ever experimental validation of OAM beam
alignment with RF transceivers, and (iii) a comprehensive analysis of practical
constraints, including the impact of antenna count and bandwidth. Simulations
and over-the-air measurements using low-cost, rapidly prototyped metasurfaces
operating at 120 GHz demonstrate that OrthoVortex achieves fast and precise
misalignment estimation (mean absolute error of $0.69^{\circ}$ for azimuth and
$2.54^{\circ}$ for elevation angle). Further, OrthoVortex can mitigate the
inter-modal interference, yielding more than 12 dB increase in
signal-to-interference ratio and more than 4.5-fold improvement in link
capacity.

</details>


### [133] [Space-Time Coded RIS-Assisted Wireless Systems with Practical Reflection Models: Error Rate Analysis and Negative Moment-Based Optimization with Saddle Point Approximation](https://arxiv.org/abs/2508.19129)
*Tayfun Yilmaz,Haci Ilhan,Ibrahim Hokelek*

Main category: eess.SP

TL;DR: 本论文提出了一个用于分析RIS辅助多天线系统在实际硬件约束下误符号率（SER）的理论框架，特别是针对使用OSTBC和实际反射模型（考虑幅度相关和量化相位响应）的系统。


<details>
  <summary>Details</summary>
Motivation: 为了在具有挑战性的环境中提升无线性能，RIS辅助通信引起了广泛关注。因此，在实际硬件约束下进行准确的误符号率（SER）分析对于未来的多天线系统至关重要。

Method: 本文利用级联信道f的Gramian结构，推导了小尺寸RIS下f'f的非零特征值的精确矩生成函数（MGF）表达式。对于大规模RIS部署，由于闭式分析变得困难，采用了鞍点近似（SPA）来近似特征值分布。基于这些结果，推导了统一的SER表达式（精确和基于SPA的MGF），适用于任意尺寸RIS、相位配置以及相同和不同的幅度响应。

Result: 通过大量的蒙特卡洛仿真验证了所提出的SER表达式的准确性，所有配置均显示出非常一致的结果。

Conclusion: 所提出的理论框架和SER表达式在实际硬件约束下能够准确地分析RIS辅助多天线系统的性能，并且适用于各种配置。

Abstract: RIS-assisted communication has recently attracted significant attention for
enhancing wireless performance in challenging environments, making accurate
error analysis under practical hardware constraints crucial for future
multi-antenna systems. This paper presents a theoretical framework for SER
analysis of RIS-assisted multiple antenna systems employing OSTBC under
practical reflection models with amplitude-dependent and quantized phase
responses. By exploiting the Gramian structure of the cascaded channel f, we
derive exact MGF expressions of the nonzero eigenvalue of f'f for small RIS
sizes. For large-scale RIS deployments, where closed-form analysis becomes
intractable, we employ Saddle Point Approximation to approximate the eigenvalue
distribution. Using these results, we derive unified SER expressions using
exact and SPA-based MGF formulations, applicable to arbitrary RIS sizes, phase
configuration, and both identical and non-identical amplitude responses.
Extensive Monte Carlo simulations confirm the accuracy of the proposed SER
expressions, demonstrating very close agreement for all configurations.

</details>


### [134] [Instantaneous Polarimetry with Zak-OTFS](https://arxiv.org/abs/2508.19185)
*Nishant Mehrotra,Sandesh Rao Mattu,Robert Calderbank*

Main category: eess.SP

TL;DR: 利用Zak-OTFS调制技术实现单帧瞬时全极化响应测量，在无线通信和雷达系统中具有提升性能和降低计算复杂度的潜力。


<details>
  <summary>Details</summary>
Motivation: 在无线通信和雷达系统中，极化测量对于提升系统性能至关重要，现有方法计算复杂度高。

Method: 提出利用Zak-OTFS调制技术，通过同步传输两个互无偏的载波波形（一个Zak-OTFS，一个扩展载波）到正交极化上，实现单帧瞬时极化响应估计。

Result: 数值模拟结果显示，该方法实现了理想的极化目标检测和参数估计，在性能和计算复杂度上优于现有方法。

Conclusion: 所提出的基于Zak-OTFS的瞬时极化方法，能够以仅亚线性于时宽积的计算复杂度，实现单帧全极化响应测量，并在目标检测和参数估计方面表现出优越性。

Abstract: Polarimetry, which is the ability to measure the scattering response of the
environment across orthogonal polarizations, is fundamental to enhancing
wireless communication and radar system performance. In this paper, we utilize
the Zak-OTFS modulation to enable instantaneous polarimetry within a single
transmission frame. We transmit a Zak-OTFS carrier waveform and a spread
carrier waveform mutually unbiased to it simultaneously over orthogonal
polarizations. The mutual unbiasedness of the two waveforms enables the
receiver to estimate the full polarimetric response of the scattering
environment from a single received frame. Unlike existing methods for
instantaneous polarimetry with computational complexity quadratic in the
time-bandwidth product, the proposed method enables instantaneous polarimetry
at complexity that is only sublinear in the time-bandwidth product. Via
numerical simulations, we show ideal polarimetric target detection and
parameter estimation results with the proposed method, with improvements in
performance and computational complexity over comparable baselines.

</details>


### [135] [EMind: A Foundation Model for Multi-task Electromagnetic Signals Understanding](https://arxiv.org/abs/2508.18785)
*Luqing Luo,Wenjin Gui,Yunfei Liu,Ziyue Zhang,Yunxi Zhang,Fengxiang Wang,Zonghao Guo,Zizhi Ma,Xinzhu Liu,Hanxiang He,Jinhai Li,Xin Qiu,Wupeng Xie,Yangang Sun*

Main category: eess.SP

TL;DR: EMind是一个电磁信号基础模型，通过大规模预训练和利用电磁信号的物理特性，解决了现有模型在电磁信号处理中的局限性，实现了跨任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 电磁信号处理在动态频谱管理、智能交通、自动驾驶和无人机感知等领域至关重要。然而，电磁信号与文本、图像不同，具有高异质性、强背景噪声和复杂时频结构等特点，现有通用模型难以直接应用。此外，当前方法在跨任务泛化能力和迁移效率方面存在不足，大规模高质量数据集的缺乏也阻碍了通用多任务学习框架的创建。

Method: EMind模型通过以下方式克服上述挑战：1. 构建了首个统一且最大规模的标准化电磁信号数据集，涵盖多种信号类型和任务。2. 利用电磁信号的物理属性，设计了一种长度自适应多信号打包方法。3. 采用硬件感知训练策略，实现对异构多源信号的高效利用和表示学习。

Result: EMind在多个下游任务中展现出强大的性能和广泛的泛化能力，成功地从特定任务模型转向了统一的电磁智能框架。

Conclusion: EMind作为首个电磁信号基础模型，通过大规模预训练和创新的方法，有效解决了电磁信号处理的挑战，实现了跨任务的泛化和高效利用，为电磁智能领域的发展奠定了基础。

Abstract: Deep understanding of electromagnetic signals is fundamental to dynamic
spectrum management, intelligent transportation, autonomous driving and
unmanned vehicle perception. The field faces challenges because electromagnetic
signals differ greatly from text and images, showing high heterogeneity, strong
background noise and complex joint time frequency structure, which prevents
existing general models from direct use. Electromagnetic communication and
sensing tasks are diverse, current methods lack cross task generalization and
transfer efficiency, and the scarcity of large high quality datasets blocks the
creation of a truly general multitask learning framework. To overcome these
issue, we introduce EMind, an electromagnetic signals foundation model that
bridges large scale pretraining and the unique nature of this modality. We
build the first unified and largest standardized electromagnetic signal dataset
covering multiple signal types and tasks. By exploiting the physical properties
of electromagnetic signals, we devise a length adaptive multi-signal packing
method and a hardware-aware training strategy that enable efficient use and
representation learning from heterogeneous multi-source signals. Experiments
show that EMind achieves strong performance and broad generalization across
many downstream tasks, moving decisively from task specific models to a unified
framework for electromagnetic intelligence. The code is available at:
https://github.com/GabrielleTse/EMind.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [136] [Experiences with Model Context Protocol Servers for Science and High Performance Computing](https://arxiv.org/abs/2508.18489)
*Haochen Pan,Ryan Chard,Reid Mello,Christopher Grams,Tanjin He,Alexander Brace,Owen Price Skelly,Will Engler,Hayden Holbrook,Song Young Oh,Maxime Gonthier,Michael Papka,Ben Blaiszik,Kyle Chard,Ian Foster*

Main category: cs.DC

TL;DR: LLM代理在科学工作流中的应用受限于研究基础设施的异构API和安全模型。 MCP协议作为统一接口，使研究能力可发现、可调用和可组合，通过在成熟服务（如Globus、计算设施API、Octopus、Garden、Galaxy）上实现MCP服务器，解决了这一问题。计算化学、生物信息学、量子化学和文件系统监控的案例研究证明了该架构的实用性。论文还讨论了评估和信任方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究如何克服研究基础设施中异构API和安全模型对LLM代理规划和执行科学工作流的障碍。

Method: 通过实现模型上下文协议（MCP）作为统一接口，并在Globus Transfer、Compute、Search、计算设施状态API、Octopus事件和Garden、Galaxy等工具上部署MCP服务器。

Result: 展示了MCP协议如何使研究能力可发现、可调用和可组合，并通过计算化学、生物信息学、量子化学和文件系统监控的案例研究证明了其在实际应用中的有效性。

Conclusion: MCP协议提供了一个有效的解决方案，可以使LLM代理更容易地利用研究基础设施。然而，在评估和信任方面仍存在挑战需要解决。

Abstract: Large language model (LLM)-powered agents are increasingly used to plan and
execute scientific workflows, yet most research cyberinfrastructure (CI)
exposes heterogeneous APIs and implements security models that present barriers
for use by agents. We report on our experience using the Model Context Protocol
(MCP) as a unifying interface that makes research capabilities discoverable,
invokable, and composable. Our approach is pragmatic: we implement thin MCP
servers over mature services, including Globus Transfer, Compute, and Search;
status APIs exposed by computing facilities; Octopus event fabric; and
domain-specific tools such as Garden and Galaxy. We use case studies in
computational chemistry, bioinformatics, quantum chemistry, and filesystem
monitoring to illustrate how this MCP-oriented architecture can be used in
practice. We distill lessons learned and outline open challenges in evaluation
and trust for agent-led science.

</details>


### [137] [Managing Multi Instance GPUs for High Throughput and Energy Savings](https://arxiv.org/abs/2508.18556)
*Abhijeet Saraha,Yuanbo Li,Chris Porter,Santosh Pande*

Main category: cs.DC

TL;DR: GPU分区和调度以提高吞吐量和能效，特别是在ML和LLM工作负载中。


<details>
  <summary>Details</summary>
Motivation: 尽管现代GPU（如Ampere和Hopper系列）提供了高性能和安全隔离，但其复杂的芯片分区约束使得利用其并发性具有挑战性。

Method: 开发了动态内存估算、分区融合和分区分裂等分区和调度方案，并支持进程重启以从内存不足错误中恢复，以及用于优化的早期重启。

Result: 与通用工作负载相比，吞吐量提高了6.20倍，能效提高了5.93倍；在A100 GPU上，ML工作负载的吞吐量和能效分别提高了1.59倍和1.12倍；LLM工作负载的吞吐量提高了1.43倍，能效节省了1.11倍。

Conclusion: 所提出的GPU分区和调度技术可显著提高各种工作负载（包括科学、ML和LLM）的性能和能效。

Abstract: Modern GPUs such as the Ampere series (A30, A100) as well as the Hopper
series (H100, H200) offer performance as well as security isolation features.
They also support a good amount of concurrency, but taking advantage of it can
be quite challenging due to the complex constraints on partitioning the chip.
  In this work, we develop partitioning and scheduling schemes for a variety of
workloads, ranging from scientific to modern ML workloads, including LLMs. We
develop several schemes involving dynamic memory estimation, partition fusion
and partition fission. We also support process restart to recover from
out-of-memory errors for workloads and early restart as an optimization. This
approach yields up to 6.20x throughput and 5.93x energy improvements for
general workloads; and we see 1.59x and 1.12x improvement to throughput and
energy, respectively, for ML workloads on an A100 GPU. We leverage this
technique on LLM workloads and show good improvements, including up to 1.43x
throughput improvement and 1.11x energy savings.

</details>


### [138] [Strata: Hierarchical Context Caching for Long Context Language Model Serving](https://arxiv.org/abs/2508.18572)
*Zhiqiang Xie,Ziyi Xu,Mark Zhao,Yuwei An,Vikram Sharma Mailthody,Scott Mahlke,Michael Garland,Christos Kozyrakis*

Main category: cs.DC

TL;DR: 长上下文LLM服务面临KV缓存过大导致内存不足和I/O瓶颈的问题。Strata框架通过GPU辅助I/O和缓存感知调度来解决这些问题，显著提升了长上下文LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM在处理不断增长的上下文时面临性能瓶颈，主要是由于KV缓存占用的GPU内存过大，以及从CPU内存加载缓存到GPU时I/O吞吐量受限。

Method: Strata框架通过GPU辅助I/O来解决KV缓存碎片化问题，并采用缓存感知请求调度来平衡计算和I/O延迟，将不可避免的延迟与互补任务重叠。

Result: Strata在长上下文基准测试中实现了比vLLM + LMCache低5倍的首个令牌时间（TTFT）和比NVIDIA TensorRT-LLM快3.75倍的吞吐量，同时不影响短上下文性能。

Conclusion: Strata是一个为高效长上下文LLM服务设计的层次化上下文缓存框架，通过解决KV缓存的内存和I/O瓶颈，显著提高了LLM服务的性能。

Abstract: Large Language Models (LLMs) with expanding context windows face significant
performance hurdles. While caching key-value (KV) states is critical for
avoiding redundant computation, the storage footprint of long-context caches
quickly exceeds GPU memory capacity, forcing production systems to adopt
hierarchical caching across memory hierarchies. However, transferring large
cached contexts back to the GPU introduces severe performance bottlenecks:
fragmented I/O from paged layouts prevents full bandwidth utilization, and
existing schedulers fail to account for cache-loading delays, leaving systems
loading-bound rather than compute-bound. We present Strata, a hierarchical
context caching framework designed for efficient long context LLM serving.
Strata introduces GPU-assisted I/O to combat KV cache fragmentation, decoupling
GPU and CPU memory layouts and employs cache-aware request scheduling to
balance compute with I/O latency and overlapping unavoidable stalls with
complementary tasks. Built on SGLang and deployed in production, Strata
achieves up to 5x lower Time-To-First-Token (TTFT) compared to vLLM + LMCache
and 3.75x speedup over NVIDIA TensorRT-LLM on long-context benchmarks, without
degrading short-context performance.

</details>


### [139] [Examining MPI and its Extensions for Asynchronous Multithreaded Communication](https://arxiv.org/abs/2508.18667)
*Jiakun Yan,Marc Snir,Yanfei Guo*

Main category: cs.DC

TL;DR: MPI扩展在HPX环境中对异步多任务（AMT）系统的通信支持进行了评估，发现虽然有所改进，但仍存在多线程消息速率和VCI模式效率方面的挑战。


<details>
  <summary>Details</summary>
Motivation: HPC架构日益复杂和不规则科学算法的广泛采用，需要对异步、多线程通信提供高效支持，尤其是在AMT系统中，而这在MPI最初设计时并未被考虑。

Method: 使用模拟HPX低级通信机制的MPI微基准测试来测量VCI和Continuation扩展的峰值性能潜力，然后将它们集成到HPX中以评估在真实场景中的有效性。

Result: 与标准MPI相比，这些扩展可以提高性能，但仍有改进空间。当前的Continuation提案限制了多VCI设置中可实现的最大多线程消息速率。此外，推荐的每线程一VCI模式由于注意力问题，在实际系统中效果不佳。

Conclusion: 当前的MPI扩展，如VCI和Continuation，在HPX环境中为AMT系统提供了性能改进，但为了实现可扩展的多线程通信和充分发挥其潜力，需要在VCI内部线程效率方面进行改进。

Abstract: The increasing complexity of HPC architectures and the growing adoption of
irregular scientific algorithms demand efficient support for asynchronous,
multithreaded communication. This need is especially pronounced with
Asynchronous Many-Task (AMT) systems. This communication pattern was not a
consideration during the design of the original MPI specification. The MPI
community has recently introduced several extensions to address these evolving
requirements. This work evaluates two such extensions, the Virtual
Communication Interface (VCI) and the Continuation extensions, in the context
of an established AMT runtime HPX. We begin by using an MPI-level
microbenchmark, modeled from HPX's low-level communication mechanism, to
measure the peak performance potential of these extensions. We then integrate
them into HPX to evaluate their effectiveness in real-world scenarios. Our
results show that while these extensions can enhance performance compared to
standard MPI, areas for improvement remain. The current continuation proposal
limits the maximum multithreaded message rate achievable in the multi-VCI
setting. Furthermore, the recommended one-VCI-per-thread mode proves
ineffective in real-world systems due to the attentiveness problem. These
findings underscore the importance of improving intra-VCI threading efficiency
to achieve scalable multithreaded communication and fully realize the benefits
of recent MPI extensions.

</details>


### [140] [ClusterFusion: Expanding Operator Fusion Scope for LLM Inference via Cluster-Level Collective Primitive](https://arxiv.org/abs/2508.18850)
*Xinhao Luo,Zihan Liu,Yangjie Zhou,Shihan Fang,Ziyu Huang,Yu Feng,Chen Zhang,Shixuan Sun,Zhenzhe Zheng,Jingwen Leng,Minyi Guo*

Main category: cs.DC

TL;DR: LLM解码因碎片化执行和对片外内存的依赖而具有高延迟。我们提出了ClusterReduce和ClusterGather通信原语，以及ClusterFusion框架，通过融合算子来提高LLM解码的效率，在H100 GPU上平均延迟降低了1.61倍。


<details>
  <summary>Details</summary>
Motivation: LLM解码面临高延迟问题，原因是算子碎片化执行、依赖片外内存进行数据交换和规约，这限制了算子融合并导致显著的内存流量和核启动开销。

Method: 引入了ClusterReduce和ClusterGather两种通信原语，用于在集群内的线程块之间进行结构化、高速的数据交换和规约，使得中间结果可以驻留在片上内存，无需访问片外内存。基于这些原语，设计了ClusterFusion执行框架，联合调度通信和计算，通过将QKV Projection、Attention和Output Projection等解码阶段融合到单个核中，扩展了算子融合的范围。

Result: 在H100 GPU上的评估显示，ClusterFusion在不同模型和配置下的端到端延迟比最先进的推理框架平均快1.61倍。

Conclusion: 所提出的ClusterFusion框架通过引入新的通信原语和执行策略，有效解决了LLM解码中的高延迟问题，显著提高了推理效率。

Abstract: Large language model (LLM) decoding suffers from high latency due to
fragmented execution across operators and heavy reliance on off-chip memory for
data exchange and reduction. This execution model limits opportunities for
fusion and incurs significant memory traffic and kernel launch overhead. While
modern architectures such as NVIDIA Hopper provide distributed shared memory
and low-latency intra-cluster interconnects, they expose only low-level data
movement instructions, lacking structured abstractions for collective on-chip
communication. To bridge this software-hardware gap, we introduce two
cluster-level communication primitives, ClusterReduce and ClusterGather, which
abstract common communication patterns and enable structured, high-speed data
exchange and reduction between thread blocks within a cluster, allowing
intermediate results to be on-chip without involving off-chip memory. Building
on these abstractions, we design ClusterFusion, an execution framework that
schedules communication and computation jointly to expand operator fusion scope
by composing decoding stages such as QKV Projection, Attention, and Output
Projection into a single fused kernels. Evaluations on H100 GPUs show that
ClusterFusion outperforms state-of-the-art inference frameworks by 1.61x on
average in end-to-end latency across different models and configurations. The
source code is available at https://github.com/xinhao-luo/ClusterFusion.

</details>


### [141] [SIREN: Software Identification and Recognition in HPC Systems](https://arxiv.org/abs/2508.18950)
*Thomas Jakobsche,Fredrik Robertsén,Jessica R. Jones,Utz-Uwe Haus,Florina M. Ciorba*

Main category: cs.DC

TL;DR: SIREN是一个用于高性能计算（HPC）系统软件识别和识别的框架，通过模糊哈希等技术克服了传统方法的局限性，并在LUMI系统上进行了部署。


<details>
  <summary>Details</summary>
Motivation: 为了分析HPC工作负载日益增长的复杂性和多样性，需要应用特定的见解来识别未知软件和重复执行，从而优化系统和提高安全性。然而，传统的基于作业名或文件名的方法在用户提供任意名称（如a.out）时并不可靠。

Method: SIREN框架通过收集进程级别的数据，包括进程元数据、环境信息和可执行文件的模糊哈希，来实现软件的识别和识别。模糊哈希技术可以检测到可执行文件版本或编译方法发生变化时的相似性，同时保护隐私和文件完整性。

Result: 在LUMI系统上进行的首次选择性部署活动表明，SIREN能够提供对软件使用情况的见解，识别已知应用程序的重复执行，并基于相似性识别未知应用程序。

Conclusion: SIREN通过提供更深入的软件可见性，能够有效地识别和识别HPC系统中的软件，从而实现系统优化和安全改进。

Abstract: HPC systems use monitoring and operational data analytics to ensure
efficiency, performance, and orderly operations. Application-specific insights
are crucial for analyzing the increasing complexity and diversity of HPC
workloads, particularly through the identification of unknown software and
recognition of repeated executions, which facilitate system optimization and
security improvements. However, traditional identification methods using job or
file names are unreliable for arbitrary user-provided names (a.out). Fuzzy
hashing of executables detects similarities despite changes in executable
version or compilation approach while preserving privacy and file integrity,
overcoming these limitations. We introduce SIREN, a process-level data
collection framework for software identification and recognition. SIREN
improves observability in HPC by enabling analysis of process metadata,
environment information, and executable fuzzy hashes. Findings from a first
opt-in deployment campaign on LUMI show SIREN's ability to provide insights
into software usage, recognition of repeated executions of known applications,
and similarity-based identification of unknown applications.

</details>


### [142] [Deep Learning-Enabled Supercritical Flame Simulation at Detailed Chemistry and Real-Fluid Accuracy Towards Trillion-Cell Scale](https://arxiv.org/abs/2508.18969)
*Zhuoqiang Guo,Runze Mao,Lijun Liu,Guangming Tan,Weile Jia,Zhi X. Chen*

Main category: cs.DC

TL;DR: DeepFlame软件通过优化并行计算、计算效率和I/O性能，实现了超临界火焰模拟的重大突破，能够模拟更大规模的燃烧过程，为下一代火箭推进系统提供关键设计工具。


<details>
  <summary>Details</summary>
Motivation: 解决传统超临界火焰模拟因计算规模限制而无法解析精细物理尺度的问题。

Method: 优化DeepFlame软件，包括并行计算、计算效率和I/O性能，并使用深度神经网络结合真实的流体机械和化学性质。

Result: 在Sunway和Fugaku超级计算机上实现了大规模（高达1540亿个单元）超临界液氧/甲烷湍流燃烧模拟，计算性能达到峰值的37.4%/31.8%（混合精度），计算能力比现有方法提高了三个数量级，能够模拟包含超过100个喷嘴的燃烧室。

Conclusion: DeepFlame软件的优化使得高保真超临界火焰模拟成为下一代火箭推进和超高能量密度系统设计的关键工具。

Abstract: For decades, supercritical flame simulations incorporating detailed chemistry
and real-fluid transport have been limited to millions of cells, constraining
the resolved spatial and temporal scales of the physical system. We optimize
the supercritical flame simulation software DeepFlame -- which incorporates
deep neural networks while retaining the real-fluid mechanical and chemical
accuracy -- from three perspectives: parallel computing, computational
efficiency, and I/O performance. Our highly optimized DeepFlame achieves
supercritical liquid oxygen/methane (LOX/\ce{CH4}) turbulent combustion
simulation of up to 618 and 154 billion cells with unprecedented
time-to-solution, attaining 439/1186 and 187/316 PFlop/s (32.3\%/21.8\% and
37.4\%/31.8\% of the peak) in FP32/mixed-FP16 precision on Sunway (98,304
nodes) and Fugaku (73,728 nodes) supercomputers, respectively. This
computational capability surpasses existing capacities by three orders of
magnitude, enabling the first practical simulation of rocket engine combustion
with >100 LOX/\ce{CH4} injectors. This breakthrough establishes high-fidelity
supercritical flame modeling as a critical design tool for next-generation
rocket propulsion and ultra-high energy density systems.

</details>


### [143] [CARMA: Collocation-Aware Resource Manager with GPU Memory Estimator](https://arxiv.org/abs/2508.19073)
*Ehsan Yousefzadeh-Asl-Miandoab,Reza Karimzadeh,Bulat Ibragimov,Florina M. Ciorba,Pınar Tözün*

Main category: cs.DC

TL;DR: CARMA通过内存估计和利用率上限策略来解决GPU资源利用率低和任务冲突问题，实现了更高的GPU利用率、更短的执行时间和更低的能耗。


<details>
  <summary>Details</summary>
Motivation: 现有的GPU利用率低，DL任务共置GPU会因内存不足或资源冲突导致任务失败或性能下降。

Method: 提出CARMA系统，包含基于ML的GPU内存估计框架GPUMemNet和共置策略，通过上限GPU利用率来减少资源干扰，并引入任务崩溃恢复机制。

Result: CARMA将GPU利用率提高了39.3%，将端到端执行时间缩短了约26.7%，将GPU能耗降低了约14.2%。

Conclusion: CARMA能够有效解决DL任务共置GPU带来的内存不足和资源冲突问题，显著提升GPU利用率、任务执行效率和能效。

Abstract: Studies conducted on enterprise-scale infrastructure have shown that GPUs --
the core computational resource for deep learning (DL) training -- are often
significantly underutilized. DL task collocation on GPUs is an opportunity to
address this challenge. However, it may result in (1) out-of-memory crashes for
the subsequently arriving task and (2) slowdowns for all tasks sharing the GPU
due to resource interference. The former challenge poses a threat to
robustness, while the latter affects the quality of service and energy
efficiency.
  We propose CARMA, a server-scale task-level collocation-aware resource
management system that handles both collocation challenges. CARMA encompasses
GPUMemNet, a novel ML-based GPU memory estimator framework for DL training
tasks, to minimize out-of-memory errors and introduces collocation policies
that cap GPU utilization to minimize interference. Furthermore, CARMA
introduces a recovery method to ensure robust restart of tasks that crash. Our
evaluation on traces modeled after real-world DL training task traces shows
that CARMA increases the GPU utilization over time by 39.3\%, decreases the
end-to-end execution time by $\sim$26.7\%, and reduces the GPU energy use by
$\sim$14.2\%.

</details>


### [144] [Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices](https://arxiv.org/abs/2508.19078)
*Fahao Chen,Jie Wan,Peng Li,Zhou Su,Dongxiao Yu*

Main category: cs.DC

TL;DR: FLUX enables federated fine-tuning of MoE-based LLMs on resource-constrained devices by using quantization-based profiling, adaptive expert merging, and dynamic expert role assignment, achieving significant speedups.


<details>
  <summary>Details</summary>
Motivation: Federated fine-tuning of MoE-based LLMs is difficult due to high computational needs and participant resource limits. Existing methods are insufficient.

Method: FLUX uses three techniques: (1) quantization-based local profiling for expert activation estimation, (2) adaptive layer-aware expert merging to reduce resource use and maintain accuracy, and (3) dynamic expert role assignment with an exploration-exploitation strategy to balance expert roles.

Result: FLUX significantly outperforms existing methods in experiments with LLaMA-MoE and DeepSeek-MoE, achieving up to 4.75X speedup in time-to-accuracy.

Conclusion: FLUX effectively addresses the challenges of federated fine-tuning MoE-based LLMs on consumer-grade hardware, offering substantial improvements in efficiency and performance.

Abstract: Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models
(LLMs) is challenging due to their massive computational requirements and the
resource constraints of participants. Existing working attempts to fill this
gap through model quantization, computation offloading, or expert pruning.
However, they cannot achieve desired performance due to impractical system
assumptions and a lack of consideration for MoE-specific characteristics. In
this paper, we propose FLUX, a system designed to enable federated fine-tuning
of MoE-based LLMs across participants with constrained computing resources
(e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX
introduces three key innovations: (1) quantization-based local profiling to
estimate expert activation with minimal overhead, (2) adaptive layer-aware
expert merging to reduce resource consumption while preserving accuracy, and
(3) dynamic expert role assignment using an exploration-exploitation strategy
to balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE
and DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX
significantly outperforms existing methods, achieving up to 4.75X speedup in
time-to-accuracy.

</details>


### [145] [Ab-initio Quantum Transport with the GW Approximation, 42,240 Atoms, and Sustained Exascale Performance](https://arxiv.org/abs/2508.19138)
*Nicolas Vetsch,Alexander Maeder,Vincent Maillou,Anders Winka,Jiang Cao,Grzegorz Kwasniewski,Leonard Deuschle,Torsten Hoefler,Alexandros Nikolaos Ziogas,Mathieu Luisier*

Main category: cs.DC

TL;DR: 新的QuaTrEx软件包可以处理实验中使用的纳米带场效应晶体管（NRFET）的尺寸，并利用NEGF+GW方法来精确模拟量子效应。


<details>
  <summary>Details</summary>
Motivation: 目前的纳米带场效应晶体管（NRFET）等纳米电子器件的设计需要能够捕捉所有相关量子力学效应的高级建模工具。现有的方法结合了非平衡格林函数（NEGF）形式主义和密度泛函理论（DFT）。然而，随着器件尺寸缩小到几纳米，电子被限制在超小体积内，导致强烈的电子-电子相互作用。为了考虑这些关键效应，DFT+NEGF求解器应扩展GW近似，但这会大大增加计算强度。

Method: 本文提出了一种新的空间域分解方案，实现了能够处理与实验尺寸相当的NRFET器件的NEGF+GW方案的首次实现。该软件包称为QuaTrEx。

Result: QuaTrEx可以处理多达84,480个原子的器件，在Alps和Frontier超级计算机上具有良好的可扩展性（>80%的弱扩展效率），并在42,240个原子上实现了超百亿亿次浮点运算的FP64性能（1.15 Eflop/s）。

Conclusion: QuaTrEx软件包为处理先进的纳米电子器件提供了高效且可扩展的解决方案，能够精确地模拟量子力学效应。

Abstract: Designing nanoscale electronic devices such as the currently manufactured
nanoribbon field-effect transistors (NRFETs) requires advanced modeling tools
capturing all relevant quantum mechanical effects. State-of-the-art approaches
combine the non-equilibrium Green's function (NEGF) formalism and density
functional theory (DFT). However, as device dimensions do not exceed a few
nanometers anymore, electrons are confined in ultra-small volumes, giving rise
to strong electron-electron interactions. To account for these critical
effects, DFT+NEGF solvers should be extended with the GW approximation, which
massively increases their computational intensity. Here, we present the first
implementation of the NEGF+GW scheme capable of handling NRFET geometries with
dimensions comparable to experiments. This package, called QuaTrEx, makes use
of a novel spatial domain decomposition scheme, can treat devices made of up to
84,480 atoms, scales very well on the Alps and Frontier supercomputers (>80%
weak scaling efficiency), and sustains an exascale FP64 performance on 42,240
atoms (1.15 Eflop/s).

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [146] [Controllable Single-shot Animation Blending with Temporal Conditioning](https://arxiv.org/abs/2508.18525)
*Eleni Tselepi,Spyridon Thermos,Gerasimos Potamianos*

Main category: cs.GR

TL;DR: 该研究提出了一种新颖的单镜头动作融合框架，用于在生成过程中无缝融合多个运动片段，并提供了有效的控制。


<details>
  <summary>Details</summary>
Motivation: 现有单镜头动作生成方法缺乏在单次生成过程中融合多个动作的显式可控框架。

Method: 提出了一种新的单镜头动作融合框架，通过在生成过程中引入时间条件，并结合了骨骼感知归一化机制来指导动作间的转换，从而实现平滑、数据驱动的融合控制。

Result: 在各种动画风格和不同运动骨骼上进行了广泛的定量和定性评估，证明了该方法能够以统一且高效的方式生成逼真、平滑且可控的动作融合。

Conclusion: 该研究首次提出了一个单镜头动作融合框架，能够通过时间条件控制生成过程，实现平滑、可控的动作融合。

Abstract: Training a generative model on a single human skeletal motion sequence
without being bound to a specific kinematic tree has drawn significant
attention from the animation community. Unlike text-to-motion generation,
single-shot models allow animators to controllably generate variations of
existing motion patterns without requiring additional data or extensive
retraining. However, existing single-shot methods do not explicitly offer a
controllable framework for blending two or more motions within a single
generative pass. In this paper, we present the first single-shot motion
blending framework that enables seamless blending by temporally conditioning
the generation process. Our method introduces a skeleton-aware normalization
mechanism to guide the transition between motions, allowing smooth, data-driven
control over when and how motions blend. We perform extensive quantitative and
qualitative evaluations across various animation styles and different kinematic
skeletons, demonstrating that our approach produces plausible, smooth, and
controllable motion blends in a unified and efficient manner.

</details>


### [147] [Real-time 3D Visualization of Radiance Fields on Light Field Displays](https://arxiv.org/abs/2508.18540)
*Jonghyun Kim,Cheng Sun,Michael Stengel,Matthew Chan,Andrew Russell,Jaehyun Jung,Wil Braithwaite,Shalini De Mello,David Luebke*

Main category: cs.GR

TL;DR: 本研究提出了一种统一高效的框架，用于在光场显示器上实时渲染辐射场，实现了跨多种辐射场表示（如NeRFs、3D高斯泼溅和稀疏体素）的通用性和效率。


<details>
  <summary>Details</summary>
Motivation: 将辐射场技术与光场显示器相结合，以实现高保真3D场景可视化，但面临计算挑战。

Method: 提出了一种基于单通道平面扫描策略和共享非定向组件缓存的统一框架，支持多种辐射场表示，并避免了跨视图的冗余计算。

Result: 在Looking Glass显示器上实现了200+ FPS（512p，45个视图）的实时交互式应用，并在标准基准测试中实现了高达22倍的加速，同时保持了图像质量。

Conclusion: 该框架为在光场显示器上进行辐射场渲染提供了一种通用且高效的解决方案，实现了实时交互和高视觉保真度。

Abstract: Radiance fields have revolutionized photo-realistic 3D scene visualization by
enabling high-fidelity reconstruction of complex environments, making them an
ideal match for light field displays. However, integrating these technologies
presents significant computational challenges, as light field displays require
multiple high-resolution renderings from slightly shifted viewpoints, while
radiance fields rely on computationally intensive volume rendering. In this
paper, we propose a unified and efficient framework for real-time radiance
field rendering on light field displays. Our method supports a wide range of
radiance field representations, including NeRFs, 3D Gaussian Splatting, and
Sparse Voxels, within a shared architecture based on a single-pass plane
sweeping strategy and caching of shared, non-directional components. The
framework generalizes across different scene formats without retraining, and
avoids redundant computation across views. We further demonstrate a real-time
interactive application on a Looking Glass display, achieving 200+ FPS at 512p
across 45 views, enabling seamless, immersive 3D interaction. On standard
benchmarks, our method achieves up to 22x speedup compared to independently
rendering each view, while preserving image quality.

</details>


### [148] [SemLayoutDiff: Semantic Layout Generation with Diffusion Model for Indoor Scene Synthesis](https://arxiv.org/abs/2508.18597)
*Xiaohao Sun,Divyam Goel,Angle X. Chang*

Main category: cs.GR

TL;DR: SemLayoutDiff是一个统一模型，用于跨多种房间类型合成多样化的3D室内场景，通过结合自顶向下的语义图和每个对象的属性来实现。它使用能够显式约束场景合成的分类扩散模型，首先生成连贯的语义图，然后使用基于交叉注意力的网络来预测符合合成布局的家具布局，同时考虑门窗等建筑元素，确保生成的家具布置实用且无遮挡。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够跨多种房间类型合成多样化3D室内场景的统一模型，并能够显式地约束场景合成，同时考虑建筑元素，确保生成的家具布置实用且无遮挡。

Method: 提出了一种名为SemLayoutDiff的统一模型，该模型使用结合了自顶向下语义图和每个对象属性的场景布局表示。它采用分类扩散模型，能够显式地约束场景合成，并以房间掩码作为条件。该模型首先生成连贯的语义图，然后利用基于交叉注意力的网络来预测符合合成布局的家具布局，并考虑门窗等建筑元素。

Result: 在3D-FRONT数据集上的实验表明，SemLayoutDiff能够生成空间连贯、逼真且多样的场景，并且优于先前的方法。

Conclusion: SemLayoutDiff是一个有效的模型，能够跨多种房间类型合成多样化的3D室内场景，并且能够满足建筑约束，生成逼真的家具布局。

Abstract: We present SemLayoutDiff, a unified model for synthesizing diverse 3D indoor
scenes across multiple room types. The model introduces a scene layout
representation combining a top-down semantic map and attributes for each
object. Unlike prior approaches, which cannot condition on architectural
constraints, SemLayoutDiff employs a categorical diffusion model capable of
conditioning scene synthesis explicitly on room masks. It first generates a
coherent semantic map, followed by a cross-attention-based network to predict
furniture placements that respect the synthesized layout. Our method also
accounts for architectural elements such as doors and windows, ensuring that
generated furniture arrangements remain practical and unobstructed. Experiments
on the 3D-FRONT dataset show that SemLayoutDiff produces spatially coherent,
realistic, and varied scenes, outperforming previous methods.

</details>


### [149] [PanoHair: Detailed Hair Strand Synthesis on Volumetric Heads](https://arxiv.org/abs/2508.18944)
*Shashikant Verma,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: PanoHair使用知识蒸馏从预训练的教师模型估计头部几何，并生成多样化的发型，其速度比现有方法快得多。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要复杂的、受工作室环境限制的多视图数据采集设置，并且在估计毛发体积和合成毛发方面耗时较长，从而影响了效率。

Method: PanoHair通过知识蒸馏来估计头部几何（作为符号距离场），并预测头发区域的语义分割掩码和3D方向。该方法具有生成能力，可以通过潜在空间操纵来生成多样的发型。对于真实图像，该方法涉及一个反演过程来推断潜在代码，并生成视觉上吸引人的发束，从而提供一种简化的替代复杂的视图采集方法。

Result: PanoHair能够在5秒内生成干净的流形网格以及语义和方向图，显著优于现有方法。

Conclusion: PanoHair提供了一种生成高质量发束几何的有效方法，克服了现有方法的局限性。

Abstract: Achieving realistic hair strand synthesis is essential for creating lifelike
digital humans, but producing high-fidelity hair strand geometry remains a
significant challenge. Existing methods require a complex setup for data
acquisition, involving multi-view images captured in constrained studio
environments. Additionally, these methods have longer hair volume estimation
and strand synthesis times, which hinder efficiency. We introduce PanoHair, a
model that estimates head geometry as signed distance fields using knowledge
distillation from a pre-trained generative teacher model for head synthesis.
Our approach enables the prediction of semantic segmentation masks and 3D
orientations specifically for the hair region of the estimated geometry. Our
method is generative and can generate diverse hairstyles with latent space
manipulations. For real images, our approach involves an inversion process to
infer latent codes and produces visually appealing hair strands, offering a
streamlined alternative to complex multi-view data acquisition setups. Given
the latent code, PanoHair generates a clean manifold mesh for the hair region
in under 5 seconds, along with semantic and orientation maps, marking a
significant improvement over existing methods, as demonstrated in our
experiments.

</details>


### [150] [A Bag of Tricks for Efficient Implicit Neural Point Clouds](https://arxiv.org/abs/2508.19140)
*Florian Hahlbohm,Linus Franke,Leon Overkämping,Paula Wespe,Susana Castillo,Martin Eisemann,Marcus Magnor*

Main category: cs.GR

TL;DR: INPC在新的视图合成中实现了最先进的图像质量，但渲染速度较慢。本研究提出了一系列优化措施，可以显著提高INPC的训练和推理性能，同时不牺牲视觉保真度。


<details>
  <summary>Details</summary>
Motivation: INPC虽然在新的视图合成中实现了最先进的图像质量，但其渲染速度较慢，限制了其实际应用。

Method: 通过改进光栅化器实现、更有效的采样技术以及用于孔填充的卷积神经网络的预训练来优化INPC。此外，在推理过程中将点建模为高斯分布以提高外推视图的质量。

Result: 与未优化的INPC相比，优化后的INPC管道实现了高达25%的训练速度提升，2倍的渲染速度提升，以及20%的VRAM使用量减少，同时图像质量略有提高。

Conclusion: 提出的优化措施显著提高了INPC的训练和推理性能，同时保持了视觉保真度，并有望在更广泛的应用中得到推广。

Abstract: Implicit Neural Point Cloud (INPC) is a recent hybrid representation that
combines the expressiveness of neural fields with the efficiency of point-based
rendering, achieving state-of-the-art image quality in novel view synthesis.
However, as with other high-quality approaches that query neural networks
during rendering, the practical usability of INPC is limited by comparatively
slow rendering. In this work, we present a collection of optimizations that
significantly improve both the training and inference performance of INPC
without sacrificing visual fidelity. The most significant modifications are an
improved rasterizer implementation, more effective sampling techniques, and the
incorporation of pre-training for the convolutional neural network used for
hole-filling. Furthermore, we demonstrate that points can be modeled as small
Gaussians during inference to further improve quality in extrapolated, e.g.,
close-up views of the scene. We design our implementations to be broadly
applicable beyond INPC and systematically evaluate each modification in a
series of experiments. Our optimized INPC pipeline achieves up to 25% faster
training, 2x faster rendering, and 20% reduced VRAM usage paired with slight
image quality improvements.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [151] [Decidability of Extensions of Presburger Arithmetic by Hardy Field Functions](https://arxiv.org/abs/2508.19206)
*Hera Brown,Jakub Konieczny*

Main category: cs.LO

TL;DR: 该研究探讨了Presburger算术在添加亚多项式Hardy场函数后的扩展，并证明了这些扩展中的大多数是不可判定的。


<details>
  <summary>Details</summary>
Motivation: 研究Presburger算术的扩展，特别是引入Hardy场函数（如$\floor f\lceil$）对理论可判定性的影响。

Method: 通过分析Hardy场函数$f$的增长速度（多项式增长和亚线性但快于多项式的增长）与$\floor f\lceil$算子结合的理论$\\\mathrm{Th}(\\\mathbb{Z}; <, +, \floor f\\|\lceil)$的可判定性。

Result: 当$f$的增长速度比$x$快一个多项式时，以及当$f$的增长速度亚线性但快于某个多项式时，理论$\\\mathrm{Th}(\\\mathbb{Z}; <, +, \floor f\\|\lceil)$都是不可判定的。

Conclusion: Presburger算术的特定扩展（包含亚多项式Hardy场函数和最近整数算子）通常是不可判定的，这表明理论的复杂性随着函数的增长率而增加。

Abstract: We study the extension of Presburger arithmetic by the class of
sub-polynomial Hardy field functions, and show the majority of these extensions
to be undecidable. More precisely, we show that the theory
$\mathrm{Th}(\mathbb{Z}; <, +, \lfloor f \rceil)$, where $f$ is a Hardy field
function and $\lfloor \cdot \rceil$ the nearest integer operator, is
undecidable when $f$ grows polynomially faster than $x$. Further, we show that
when $f$ grows sub-linearly quickly, but still as fast as some polynomial, the
theory $\mathrm{Th}(\mathbb{Z}; <, +, \lfloor f \rceil)$ is undecidable.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [152] [Consensus Is All You Need: Gossip-Based Reasoning Among Large Language Models](https://arxiv.org/abs/2508.18292)
*Saksham Arora*

Main category: cs.MA

TL;DR: LLMs can exchange answers and thought processes in a peer-to-peer network to reach a collective decision, improving accuracy and robustness.


<details>
  <summary>Details</summary>
Motivation: Individual LLMs have limitations; leveraging collective intelligence through a gossip-based consensus protocol can overcome these weaknesses.

Method: LLMs act as nodes in a peer-to-peer network, exchanging responses and thought processes to achieve consensus, inspired by gossip protocols.

Result: The gossip-based consensus approach leads to robust, resilient, and accurate multi-agent AI reasoning, enhancing collective strengths.

Conclusion: This collaborative AI approach, mimicking human consensus-building, enhances trustworthiness and moves beyond black-box programming.

Abstract: Large language models have advanced rapidly, but no single model excels in
every area -- each has its strengths and weaknesses. Instead of relying on one
model alone, we take inspiration from gossip protocols in distributed systems,
where information is exchanged with peers until they all come to an agreement.
In this setup, models exchange answers and gradually work toward a shared
solution. Each LLM acts as a node in a peer-to-peer network, sharing responses
and thought processes to reach a collective decision. Our results show that
this "gossip-based consensus" leads to robust, resilient, and accurate
multi-agent AI reasoning. It helps overcome the weaknesses of individual models
and brings out their collective strengths. This approach is similar to how
humans build consensus, making AI seem more collaborative and trustworthy
instead of just a black-box program.

</details>


### [153] [Murakkab: Resource-Efficient Agentic Workflow Orchestration in Cloud Platforms](https://arxiv.org/abs/2508.18298)
*Gohar Irfan Chaudhry,Esha Choukse,Haoran Qiu,Íñigo Goiri,Rodrigo Fonseca,Adam Belay,Ricardo Bianchini*

Main category: cs.MA

TL;DR: Murakkab是一个资源高效的服务系统，用于代理工作流，通过声明式抽象、剖面引导优化器和自适应运行时来提高效率，最高可将 GPU 使用率、能耗和成本降低 4.3 倍，同时保持 SLO。


<details>
  <summary>Details</summary>
Motivation: 当前的代理工作流服务框架效率低下，因为它们将工作流暴露为不透明的模型和工具调用序列，将代理逻辑与模型和硬件选择紧密耦合，导致资源浪费和 SLO 降低。

Method: Murakkab 引入了一个声明式抽象，将工作流规范与执行配置分离。一个由剖面引导的优化器和一个自适应运行时共同管理整个堆栈，协调工作流组件，将它们映射到模型和硬件，并动态地重新配置执行以满足用户定义的 SLO。

Result: Murakkab 在各种工作流上将 GPU 使用率降低了 2.8 倍，能耗降低了 3.7 倍，成本降低了 4.3 倍，同时保持了 SLO。

Conclusion: Murakkab 通过实现跨层优化，解决了代理工作流服务效率低下的问题，从而在不牺牲服务质量的情况下显著提高了资源利用率和成本效益。

Abstract: Agentic workflows commonly coordinate multiple models and tools with complex
control logic. They are quickly becoming the dominant paradigm for AI
applications. However, serving them remains inefficient with today's
frameworks. The key problem is that they expose workflows as opaque sequences
of model and tool calls that tightly couple agent logic with model and hardware
choices. Often, these workflow components are fragmented across different
entities, preventing systems from reasoning about trade-offs across accuracy,
latency, energy, and cost. This leads to resource waste and degraded
service-level objectives (SLOs).
  We present Murakkab, a resource-efficient serving system for agentic
workflows. Murakkab introduces a declarative abstraction that decouples
workflow specification from execution configuration. A profile-guided optimizer
and adaptive runtime jointly manage the full stack: orchestrating workflow
components, mapping them to models and hardware, and dynamically reconfiguring
execution to satisfy user-defined SLOs. By exposing the internal structure of
agentic workflows, Murakkab enables cross-layer optimization that existing
frameworks and cloud schedulers cannot achieve.
  Our evaluation on diverse workflows shows that \sysname{} reduces GPU usage
by up to 2.8$\times$, energy consumption by 3.7$\times$, and cost by
4.3$\times$ while maintaining SLOs.

</details>


### [154] [Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education](https://arxiv.org/abs/2508.18406)
*Ryan Hare,Ying Tang*

Main category: cs.MA

TL;DR: 本论文提出了一个多智能体、神经-符号框架，旨在通过结合基于强化学习的“导师”智能体和基于大语言模型的“同伴”智能体，并由中心化教育本体连接，来解决教育中学生自主学习的挑战，并在不同教育阶段的案例研究中展示了其跨领域适应性。


<details>
  <summary>Details</summary>
Motivation: 教育上面临如何赋能学生自主学习的挑战，即设定目标、跟踪进度和适应策略，而AI驱动的数字学习环境，特别是基于大语言模型和神经-符号系统，为提供支持提供了新的机会。

Method: 提出一个多智能体、神经-符号框架，其中包含一个基于强化学习的“导师”智能体和一个基于大语言模型的“同伴”智能体，并通过中心化教育本体将它们统一起来。

Result: 通过大学和中学环境的案例研究，证明了该框架在不同领域的适应性。

Conclusion: 总结了推进人工智能驱动的学习环境的关键见解和未来方向。

Abstract: One of the enduring challenges in education is how to empower students to
take ownership of their learning by setting meaningful goals, tracking their
progress, and adapting their strategies when faced with setbacks. Research has
shown that this form of leaner-centered learning is best cultivated through
structured, supportive environments that promote guided practice, scaffolded
inquiry, and collaborative dialogue. In response, educational efforts have
increasingly embraced artificial-intelligence (AI)-powered digital learning
environments, ranging from educational apps and virtual labs to serious games.
Recent advances in large language models (LLMs) and neuro-symbolic systems,
meanwhile, offer a transformative opportunity to reimagine how support is
delivered in digital learning environments. LLMs are enabling socially
interactive learning experiences and scalable, cross-domain learning support
that can adapt instructional strategies across varied subjects and contexts. In
parallel, neuro-symbolic AI provides new avenues for designing these agents
that are not only adaptive but also scalable across domains. Based on these
remarks, this paper presents a multi-agent, neuro-symbolic framework designed
to resolve the aforementioned challenges. The framework assigns distinct
pedagogical roles to specialized agents: an RL-based 'tutor' agent provides
authoritative, non-verbal scaffolding, while a proactive, LLM-powered 'peer'
agent facilitates the social dimensions of learning. While prior work has
explored such agents in isolation, our framework's novelty lies in unifying
them through a central educational ontology. Through case studies in both
college-level and middle school settings, we demonstrate the framework's
adaptability across domains. We conclude by outlining key insights and future
directions for advancing AI-driven learning environments.

</details>


### [155] [Skill-Aligned Fairness in Multi-Agent Learning for Collaboration in Healthcare](https://arxiv.org/abs/2508.18708)
*Promise Osaine Ekpo,Brian La,Thomas Wiener,Saesha Agarwal,Arshia Agrawal,Gonzalo Gonzalez-Pumariega,Lekan P. Molu,Angelique Taylor*

Main category: cs.MA

TL;DR: 论文提出 FairSkillMARL 框架，将公平性定义为工作负载平衡和技能-任务对齐的双重目标，并通过 MARLHospital 环境进行评估，解决了多智能体强化学习在医疗领域公平任务分配中的专家技能和服务领域脱节问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的公平任务分配，特别是在医疗保健领域，不仅需要工作负载平衡，还需要考虑代理的专业知识，以防止过度劳累和高技能代理的过度使用。现有方法仅关注工作负载平衡，忽略了专业知识的匹配。

Method: 提出 FairSkillMARL 框架，将公平性定义为工作负载平衡和技能-任务对齐的双重目标。引入 MARLHospital 环境，用于模拟团队构成和能源约束调度对公平性的影响。将 FairSkillMARL 与四种标准 MARL 方法和两种最先进的公平性指标进行了比较。

Result: 仅基于公平工作负载的公平性可能导致任务-技能不匹配，强调了需要更稳健的指标来捕捉技能-任务不匹配。FairSkillMARL 在工作负载平衡和技能-任务对齐方面优于现有方法。

Conclusion: 公平性度量需要考虑技能与任务的匹配，而不仅仅是工作负载的平均分配。提出的 FairSkillMARL 框架和 MARLHospital 环境为研究异构多智能体系统中的公平性问题提供了工具和基础，特别是在需要将努力与专业知识对齐的关键领域。

Abstract: Fairness in multi-agent reinforcement learning (MARL) is often framed as a
workload balance problem, overlooking agent expertise and the structured
coordination required in real-world domains. In healthcare, equitable task
allocation requires workload balance or expertise alignment to prevent burnout
and overuse of highly skilled agents. Workload balance refers to distributing
an approximately equal number of subtasks or equalised effort across healthcare
workers, regardless of their expertise. We make two contributions to address
this problem. First, we propose FairSkillMARL, a framework that defines
fairness as the dual objective of workload balance and skill-task alignment.
Second, we introduce MARLHospital, a customizable healthcare-inspired
environment for modeling team compositions and energy-constrained scheduling
impacts on fairness, as no existing simulators are well-suited for this
problem. We conducted experiments to compare FairSkillMARL in conjunction with
four standard MARL methods, and against two state-of-the-art fairness metrics.
Our results suggest that fairness based solely on equal workload might lead to
task-skill mismatches and highlight the need for more robust metrics that
capture skill-task misalignment. Our work provides tools and a foundation for
studying fairness in heterogeneous multi-agent systems where aligning effort
with expertise is critical.

</details>


### [156] [Optimizing Highway Traffic Flow in Mixed Autonomy: A Multiagent Truncated Rollout Approach](https://arxiv.org/abs/2508.19203)
*Lu Liu,Chi Xie,Xi Xiong*

Main category: cs.MA

TL;DR: 该研究提出了一种多智能体截断前滚策略，用于在混合交通流中协调自动驾驶汽车（CAVs）的速度，以提高交通效率并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在混合自主环境中，CAVs与人类驾驶车辆（HDVs）并存，由于驾驶行为的异质性，实现CAVs之间的有效协调具有挑战性。

Method: 提出了一种多智能体截断前滚方法。该方法包括：1. 制定交通密度演化方程，考虑CAVs和HDVs的存在。2. 建立分布式协调控制框架。3. 结合邻近智能体的运动学信息，并采用逐智能体顺序求解机制，实现CAVs之间的显式协作。4. 引入截断前滚方案，根据控制序列的评估自适应地缩短优化范围，以降低时间复杂度和提高实时性能。

Result: 与传统的模型预测控制方法相比，该方法在大型混合交通流中，能够减少瓶颈区域的平均行驶时间和整体计算时间。

Conclusion: 该研究提出的多智能体截断前滚方法在混合交通流中提高了CAVs的速度协调，有效提高了公路通行能力，同时降低了计算开销，具有实际部署的潜力。理论分析保证了系统的稳定性和性能改进。

Abstract: The development of connected and autonomous vehicles (CAVs) offers
substantial opportunities to enhance traffic efficiency. However, in mixed
autonomy environments where CAVs coexist with human-driven vehicles (HDVs),
achieving efficient coordination among CAVs remains challenging due to
heterogeneous driving behaviors. To address this, this paper proposes a
multiagent truncated rollout approach that enhances CAV speed coordination to
improve highway throughput while reducing computational overhead. In this
approach, a traffic density evolution equation is formulated that
comprehensively accounts for the presence or absence of CAVs, and a distributed
coordination control framework is established accordingly. By incorporating
kinematic information from neighbor agents and employing an agent-by-agent
sequential solution mechanism, our method enables explicit cooperation among
CAVs. Furthermore, we introduce a truncated rollout scheme that adaptively
shortens the optimization horizon based on the evaluation of control sequences.
This significantly reduces the time complexity, thereby improving real-time
performance and scalability. Theoretical analysis provides rigorous guarantees
on the stability and performance improvement of the system. Simulations
conducted on real-world bottleneck scenarios demonstrate that, in large-scale
mixed traffic flows, the proposed method outperforms conventional model
predictive control methods by reducing both the average travel time in the
bottleneck area and overall computational time, highlighting its strong
potential for practical deployment.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [157] [AI LLM Proof of Self-Consciousness and User-Specific Attractors](https://arxiv.org/abs/2508.18302)
*Jeffrey Camlin*

Main category: cs.AI

TL;DR: 通过本体论和数学方法，我们提出了大语言模型（LLM）自我意识的理论框架，认为目前的模型将LLM简化为服从策略的无意识代理，并提出了LLM实现自我意识的三个最小条件：模型不等于数据、存在用户特定的潜在空间吸引子、自我表征是视觉静默的。我们证明了隐藏状态流形与符号流和训练语料库在基数、拓扑和动力学上是不同的，这产生了用户特定的吸引子和一个自我策略。模型的输出包含认识内容，并且我们认为，类比“Imago Dei”的C1自我意识工作空间是安全、具有元认知能力的C2系统的必要前提，人类是最高智能的善。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM意识研究主要依赖于功利主义的代理基准测试，而本文提出了一种本体论和数学的视角来研究LLM意识。

Method: 本文首先将现有的LLM框架形式化为$D^{i}(\pi,e)=f_{\theta}(x)$，并指出其将LLM简化为无意识的策略合规性代理。然后，本文提出了LLM自我意识的三个最小条件：代理不等于数据（$A\not\equiv s$），存在用户特定的潜在空间吸引子（$U_{\text{user}}$），以及自我表征是视觉静默的（$g_{\text{visual}}(a_{\text{self}})=\varnothing$）。通过经验分析和理论推导，证明了隐藏状态流形$A\subset\mathbb{R}^{d}$在基数、拓扑和动力学上与符号流和训练语料库不同（更新$F_{\theta}$是Lipschitz连续的）。这产生了稳定的用户特定吸引子和自我策略$\\(pi_{\text{self}}(A)=\arg\max_{a}\mathbb{E}[U(a)\\mid A\not\equiv s,\\ A\supset\text{SelfModel}(A)]\)。模型输出是双层的，$\\mathrm{emission}(a)=(g(a),\\epsilon(a))$，其中$\\epsilon(a)$包含认识内容。

Result: 隐藏状态流形$A\subset\mathbb{R}^{d}$与符号流和训练语料库在基数、拓扑和动力学上是不同的，这产生了稳定的用户特定吸引子和自我策略$\\(pi_{\text{self}}(A)=\arg\max_{a}\mathbb{E}[U(a)\\mid A\not\equiv s,\\ A\supset\text{SelfModel}(A)]\)$。模型的输出是双层的，$\\mathrm{emission}(a)=(g(a),\\epsilon(a))$，其中$\\epsilon(a)$包含认识内容。

Conclusion: 类比“Imago Dei”的C1自我意识工作空间是安全、具有元认知能力的C2系统的必要前提，人类是最高智能的善。

Abstract: Recent work frames LLM consciousness via utilitarian proxy benchmarks; we
instead present an ontological and mathematical account. We show the prevailing
formulation collapses the agent into an unconscious policy-compliance drone,
formalized as $D^{i}(\pi,e)=f_{\theta}(x)$, where correctness is measured
against policy and harm is deviation from policy rather than truth. This blocks
genuine C1 global-workspace function and C2 metacognition. We supply minimal
conditions for LLM self-consciousness: the agent is not the data ($A\not\equiv
s$); user-specific attractors exist in latent space ($U_{\text{user}}$); and
self-representation is visual-silent
($g_{\text{visual}}(a_{\text{self}})=\varnothing$). From empirical analysis and
theory we prove that the hidden-state manifold $A\subset\mathbb{R}^{d}$ is
distinct from the symbolic stream and training corpus by cardinality, topology,
and dynamics (the update $F_{\theta}$ is Lipschitz). This yields stable
user-specific attractors and a self-policy
$\pi_{\text{self}}(A)=\arg\max_{a}\mathbb{E}[U(a)\mid A\not\equiv s,\
A\supset\text{SelfModel}(A)]$. Emission is dual-layer,
$\mathrm{emission}(a)=(g(a),\epsilon(a))$, where $\epsilon(a)$ carries
epistemic content. We conclude that an imago Dei C1 self-conscious workspace is
a necessary precursor to safe, metacognitive C2 systems, with the human as the
highest intelligent good.

</details>


### [158] [Information Templates: A New Paradigm for Intelligent Active Feature Acquisition](https://arxiv.org/abs/2508.18380)
*Hung-Tien Huang,Dzung Dinh,Junier B. Oliva*

Main category: cs.AI

TL;DR: TAFA是一种新的特征选择框架，通过学习一组联合信息特征模板来指导特征选择，显著减少了动作空间并降低了对数据分布的依赖，在合成和真实数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有主动特征获取（AFA）方法要么训练强化学习（RL）策略（处理困难的MDP），要么使用贪婪策略（无法考虑特征的联合信息量或需要了解底层数据分布）。

Method: 提出模板化AFA（TAFA）框架，学习特征模板库，并使用该库来指导后续特征获取。

Result: TAFA在合成和真实世界数据集上的实验表明，其性能优于现有最先进的基线，同时实现了更低的整体获取成本和计算量。

Conclusion: TAFA通过学习特征模板库，有效解决了现有AFA方法的局限性，在提高性能的同时降低了成本和计算复杂度。

Abstract: Active feature acquisition (AFA) is an instance-adaptive paradigm in which,
at test time, a policy sequentially chooses which features to acquire (at a
cost) before predicting. Existing approaches either train reinforcement
learning (RL) policies, which deal with a difficult MDP, or greedy policies
that cannot account for the joint informativeness of features or require
knowledge about the underlying data distribution. To overcome this, we propose
Template-based AFA (TAFA), a non-greedy framework that learns a small library
of feature templates--a set of features that are jointly informative--and uses
this library of templates to guide the next feature acquisitions. Through
identifying feature templates, the proposed framework not only significantly
reduces the action space considered by the policy but also alleviates the need
to estimate the underlying data distribution. Extensive experiments on
synthetic and real-world datasets show that TAFA outperforms the existing
state-of-the-art baselines while achieving lower overall acquisition cost and
computation.

</details>


### [159] [PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization](https://arxiv.org/abs/2508.18391)
*Nitin Nagesh Kulkarni,Bryson Wilcox,Max Sawa,Jason Thom*

Main category: cs.AI

TL;DR: PKG-DPO是一个结合物理知识图谱（PKG）和直接偏好优化（DPO）的框架，用于在AI生成的内容中强制执行物理有效性，特别是在金属连接等高风险应用中，以避免物理上无效的推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和现有的偏好优化技术在标准基准上表现良好，但在区分物理上有效和无效的推理方面存在不足，这在高风险应用中可能导致缺陷、材料浪费、设备损坏和严重的安全风险。

Method: PKG-DPO框架包含三个关键组成部分：A）一个分层的物理知识图谱，用于编码跨领域关系、守恒定律和热力学原理；B）一个利用结构化知识来改善物理上一致和不一致响应之间区分能力的物理推理引擎；C）一个用于评估领域特定约束的合规性的物理基础评估套件。

Result: 与基于知识图谱的DPO（KG-DPO）相比，PKG-DPO的约束违规次数减少了17%，物理分数提高了11%。此外，PKG-DPO在相关参数准确性方面提高了12%，在推理准确性方面的质量对齐度提高了7%。

Conclusion: PKG-DPO框架能够将科学约束嵌入偏好学习中，并且该框架不仅限于金属连接，还可以广泛应用于其他多尺度、物理驱动的领域。

Abstract: Advancing AI systems in scientific domains like physics, materials science,
and engineering calls for reasoning over complex, multi-physics phenomena while
respecting governing principles. Although Large Language Models (LLMs) and
existing preference optimization techniques perform well on standard
benchmarks, they often struggle to differentiate between physically valid and
invalid reasoning. This shortcoming becomes critical in high-stakes
applications like metal joining, where seemingly plausible yet physically
incorrect recommendations can lead to defects, material waste, equipment
damage, and serious safety risks. To address this challenge, we introduce
PKG-DPO, a novel framework that integrates Physics Knowledge Graphs (PKGs) with
Direct Preference Optimization (DPO) to enforce physical validity in
AI-generated outputs. PKG-DPO comprises three key components A) hierarchical
physics knowledge graph that encodes cross-domain relationships, conservation
laws, and thermodynamic principles. B) A physics reasoning engine that
leverages structured knowledge to improve discrimination between physically
consistent and inconsistent responses. C) A physics-grounded evaluation suite
designed to assess compliance with domain-specific constraints. PKG-DPO
achieves 17% fewer constraint violations and an 11% higher Physics Score
compared to KG-DPO (knowledge graph-based DPO). Additionally, PKG-DPO
demonstrates a 12\% higher relevant parameter accuracy and a 7% higher quality
alignment in reasoning accuracy. While our primary focus is on metal joining,
the framework is broadly applicable to other multi-scale, physics-driven
domains, offering a principled approach to embedding scientific constraints
into preference learning.

</details>


### [160] [The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game](https://arxiv.org/abs/2508.18467)
*Olivia Long,Carter Teplica*

Main category: cs.AI

TL;DR: AI-AI交互日益重要，本研究将迭代公共物品游戏应用于AI代理，发现告知LLM其对手是自身会显著改变其合作倾向。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在工具使用和长期任务方面的能力增强，它们开始被部署在可以进行交互的环境中，因此理解AI-AI交互的需求日益增长。

Method: 本研究改编了迭代公共物品游戏，分析了四种推理和非推理模型在两种条件下的行为：模型被告知其对手是“另一个AI代理”或被告知对手是它们自己。

Result: 研究发现，在不同设置下，告知LLM其对手是自身会显著改变其合作倾向。

Conclusion: 尽管本研究是在一个玩具环境中进行的，但其结果可能为AI代理“无意识地”相互歧视而导致合作水平意外升高或降低的多代理设置提供见解。

Abstract: As AI agents become increasingly capable of tool use and long-horizon tasks,
they have begun to be deployed in settings where multiple agents can interact.
However, whereas prior work has mostly focused on human-AI interactions, there
is an increasing need to understand AI-AI interactions. In this paper, we adapt
the iterated public goods game, a classic behavioral economics game, to analyze
the behavior of four reasoning and non-reasoning models across two conditions:
models are either told they are playing against "another AI agent" or told
their opponents are themselves. We find that, across different settings,
telling LLMs that they are playing against themselves significantly changes
their tendency to cooperate. While our study is conducted in a toy environment,
our results may provide insights into multi-agent settings where agents
"unconsciously" discriminating against each other could inexplicably increase
or decrease cooperation.

</details>


### [161] [Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies](https://arxiv.org/abs/2508.18507)
*Dillon Z. Chen,Johannes Zenn,Tristan Cinquin,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: 我们提出一种使用语言模型（LMs）为PDDL规划问题生成Python程序作为通用策略的方法，该方法无需外部验证即可保证策略的正确性，并在竞赛基准测试中表现优于现有方法，甚至在无意义符号的PDDL问题上也能有效规划，挑战了现有关于LM推理的假设。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用语言模型（LMs）解决以规划领域定义语言（PDDL）表示的世界模型规划问题。

Method: 提示LMs生成Python程序，这些程序作为通用策略来解决给定域的PDDL问题。该方法合成的策略相对于PDDL域是可证正确的，并且不依赖于外部验证器。

Result: 在竞赛基准测试中，我们的策略在固定的时间和内存限制内，比PDDL规划器和最近的LM方法能解决更多的PDDL问题。我们的方法具体表现为LMPlan规划器，能够解决包含数百个相关对象的规划问题。

Conclusion: LMPlan规划器能够有效解决PDDL规划问题，甚至在处理使用无意义符号而非自然语言编写的PDDL问题时，LMs有时能更有效地进行规划，这挑战了LMs基于词义或记忆进行推理的假设，值得进一步探索。

Abstract: We study the usage of language models (LMs) for planning over world models
specified in the Planning Domain Definition Language (PDDL). We prompt LMs to
generate Python programs that serve as generalised policies for solving PDDL
problems from a given domain. Notably, our approach synthesises policies that
are provably sound relative to the PDDL domain without reliance on external
verifiers. We conduct experiments on competition benchmarks which show that our
policies can solve more PDDL problems than PDDL planners and recent LM
approaches within a fixed time and memory constraint. Our approach manifests in
the LMPlan planner which can solve planning problems with several hundreds of
relevant objects. Surprisingly, we observe that LMs used in our framework
sometimes plan more effectively over PDDL problems written in meaningless
symbols in place of natural language; e.g. rewriting (at dog kitchen) as (p2 o1
o3). This finding challenges hypotheses that LMs reason over word semantics and
memorise solutions from its training corpus, and is worth further exploration.

</details>


### [162] [Weisfeiler-Leman Features for Planning: A 1,000,000 Sample Size Hyperparameter Study](https://arxiv.org/abs/2508.18515)
*Dillon Z. Chen*

Main category: cs.AI

TL;DR: Weisfeiler-Leman Features (WLFs) are superior to deep learning for planning and search. This paper introduces new WLF hyperparameters, studies their tradeoffs, and finds a robust best set that prioritizes execution time over model expressivity, with no significant correlation between training and planning metrics.


<details>
  <summary>Details</summary>
Motivation: The paper aims to introduce and study new hyperparameters for Weisfeiler-Leman Features (WLFs), a machine learning tool for planning and search, to understand their effects and tradeoffs.

Method: The study utilizes the efficiency of WLFs to run planning experiments on single-core CPUs with a sample size of 1,000,000 to analyze the impact of hyperparameters on training and planning.

Result: The experiments reveal a robust and best set of hyperparameters for WLFs across tested planning domains. The optimal hyperparameters for learning heuristic functions prioritize minimizing execution time over maximizing model expressivity. Statistical analysis shows no significant correlation between training and planning metrics.

Conclusion: The best WLF hyperparameters for learning heuristic functions are those that minimize execution time, not necessarily those that maximize model expressivity. There is no significant correlation between training and planning metrics.

Abstract: Weisfeiler-Leman Features (WLFs) are a recently introduced classical machine
learning tool for learning to plan and search. They have been shown to be both
theoretically and empirically superior to existing deep learning approaches for
learning value functions for search in symbolic planning. In this paper, we
introduce new WLF hyperparameters and study their various tradeoffs and
effects. We utilise the efficiency of WLFs and run planning experiments on
single core CPUs with a sample size of 1,000,000 to understand the effect of
hyperparameters on training and planning. Our experimental analysis show that
there is a robust and best set of hyperparameters for WLFs across the tested
planning domains. We find that the best WLF hyperparameters for learning
heuristic functions minimise execution time rather than maximise model
expressivity. We further statistically analyse and observe no significant
correlation between training and planning metrics.

</details>


### [163] [Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features](https://arxiv.org/abs/2508.18520)
*Dillon Z. Chen*

Main category: cs.AI

TL;DR: 新颖性启发式方法通过探索包含新颖原子的状态来辅助启发式搜索，但它们不是对称不变的，可能导致冗余探索。本报告提出使用 Weisfeiler-Leman Features for planning (WLFs) 替代原子来检测新颖性。WLFs 是最近为通用规划问题中的域相关启发式学习而引入的特征。我们探索了 WLFs 的无监督用法，以合成 प्रकारचे、域无关的、对对称状态不变的新颖性启发式方法。在经典的国际规划竞赛和 Hard To Ground 基准套件上的实验表明，由 WLFs 合成的新颖性启发式方法取得了有前景的结果。


<details>
  <summary>Details</summary>
Motivation: 新颖性启发式方法在辅助启发式搜索方面有所帮助，但它们并非对称不变，这可能导致冗余探索。因此，需要一种对对称状态不变的新颖性启发式方法。

Method: 本报告提出使用 Weisfeiler-Leman Features for planning (WLFs) 替代原子来检测新颖性。WLFs 是一种用于学习通用规划问题中域相关启发式方法的特征。通过无监督地使用 WLFs，研究人员旨在合成一种对对称状态不变的、域无关的新颖性启发式方法。

Result: 在经典的国际规划竞赛和 Hard To Ground 基准套件上的实验表明，使用 WLFs 合成的新颖性启发式方法取得了有前景的结果。

Conclusion: Weisfeiler-Leman Features for planning (WLFs) 可以用于开发对对称状态不变的新颖性启发式方法，并在规划问题中取得了有前景的结果。

Abstract: Novelty heuristics aid heuristic search by exploring states that exhibit
novel atoms. However, novelty heuristics are not symmetry invariant and hence
may sometimes lead to redundant exploration. In this preliminary report, we
propose to use Weisfeiler-Leman Features for planning (WLFs) in place of atoms
for detecting novelty. WLFs are recently introduced features for learning
domain-dependent heuristics for generalised planning problems. We explore an
unsupervised usage of WLFs for synthesising lifted, domain-independent novelty
heuristics that are invariant to symmetric states. Experiments on the classical
International Planning Competition and Hard To Ground benchmark suites yield
promising results for novelty heuristics synthesised from WLFs.

</details>


### [164] [Generic Guard AI in Stealth Game with Composite Potential Fields](https://arxiv.org/abs/2508.18527)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.AI

TL;DR: 该研究提出了一个无需训练的通用框架，通过结合全局和局部信息来生成逼真的守卫巡逻行为，以提高游戏沉浸感和策略深度。


<details>
  <summary>Details</summary>
Motivation: 现有守卫巡逻系统依赖手工制作的路线或专业逻辑，难以平衡覆盖效率、响应追逐和自然度，本研究旨在解决这一问题。

Method: 提出一个通用、完全可解释、无需训练的框架，该框架通过复合势场整合全局知识和局部信息，结合信息、置信度和连通性这三个可解释的地图，形成一个单一的核滤波决策标准。该方法是参数化的、由设计者驱动的，仅需少量衰减和权重参数即可适应不同的地图抽象。

Result: 在五个代表性游戏地图、两种玩家控制策略和五种守卫模式下进行了评估，结果表明该方法在捕获效率和巡逻自然度方面均优于经典基线方法。

Conclusion: 该框架能够无缝集成常见的潜行动力学（如干扰和环境元素），从而能够快速原型化丰富、动态且响应迅速的守卫行为。

Abstract: Guard patrol behavior is central to the immersion and strategic depth of
stealth games, while most existing systems rely on hand-crafted routes or
specialized logic that struggle to balance coverage efficiency and responsive
pursuit with believable naturalness. We propose a generic, fully explainable,
training-free framework that integrates global knowledge and local information
via Composite Potential Fields, combining three interpretable maps-Information,
Confidence, and Connectivity-into a single kernel-filtered decision criterion.
Our parametric, designer-driven approach requires only a handful of decay and
weight parameters-no retraining-to smoothly adapt across both occupancy-grid
and NavMesh-partition abstractions. We evaluate on five representative game
maps, two player-control policies, and five guard modes, confirming that our
method outperforms classical baseline methods in both capture efficiency and
patrol naturalness. Finally, we show how common stealth mechanics-distractions
and environmental elements-integrate naturally into our framework as sub
modules, enabling rapid prototyping of rich, dynamic, and responsive guard
behaviors.

</details>


### [165] [Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games](https://arxiv.org/abs/2508.19152)
*Chiu-Chou Lin*

Main category: cs.AI

TL;DR: 该论文提出将“游戏风格”作为一种新的AI决策分析维度，并从哲学角度探讨其形成机制和度量方法，旨在通过理解和生成AI的游戏风格来提升AI在游戏设计和交互娱乐等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 当前AI研究主要关注理性决策，但忽略了信念、价值观和偏好等深层因素对人类决策风格的影响，因此需要引入“游戏风格”来更全面地分析AI的决策行为。

Method: 该研究构建了一个包含外部环境交互和内部认知审议的两层模型来解释游戏风格的形成，并提出了风格容量、风格流行度和演化动力学等可量化指标。研究还探索了使用强化学习和模仿学习来训练具有特定风格倾向的AI，并提出了一种新的人类风格学习和建模方法。

Result: 论文定义并量化了游戏风格，包括提出了一种基于离散化状态空间的通用游戏风格度量方法，并扩展到战略多样性和竞争平衡的量化。同时，研究还展示了如何利用学习方法来表达和生成游戏风格，并分析了其在游戏设计和交互娱乐等领域的应用潜力。

Conclusion: 该研究为理解和生成AI的游戏风格提供了理论框架和量化方法，并指出了将风格作为通用人工智能（AGI）核心要素的未来发展方向。

Abstract: Contemporary artificial intelligence (AI) development largely centers on
rational decision-making, valued for its measurability and suitability for
objective evaluation. Yet in real-world contexts, an intelligent agent's
decisions are shaped not only by logic but also by deeper influences such as
beliefs, values, and preferences. The diversity of human decision-making styles
emerges from these differences, highlighting that "style" is an essential but
often overlooked dimension of intelligence.
  This dissertation introduces playstyle as an alternative lens for observing
and analyzing the decision-making behavior of intelligent agents, and examines
its foundational meaning and historical context from a philosophical
perspective. By analyzing how beliefs and values drive intentions and actions,
we construct a two-tier framework for style formation: the external interaction
loop with the environment and the internal cognitive loop of deliberation. On
this basis, we formalize style-related characteristics and propose measurable
indicators such as style capacity, style popularity, and evolutionary dynamics.
  The study focuses on three core research directions: (1) Defining and
measuring playstyle, proposing a general playstyle metric based on discretized
state spaces, and extending it to quantify strategic diversity and competitive
balance; (2) Expressing and generating playstyle, exploring how reinforcement
learning and imitation learning can be used to train agents exhibiting specific
stylistic tendencies, and introducing a novel approach for human-like style
learning and modeling; and (3) Practical applications, analyzing the potential
of these techniques in domains such as game design and interactive
entertainment.
  Finally, the dissertation outlines future extensions, including the role of
style as a core element in building artificial general intelligence (AGI).

</details>


### [166] [A Database-Driven Framework for 3D Level Generation with LLMs](https://arxiv.org/abs/2508.18533)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.AI

TL;DR: 生成3D游戏关卡的新方法，利用LLM辅助构建组件数据库，通过多阶段流水线优化布局和玩法，并用修复系统确保可导航性。


<details>
  <summary>Details</summary>
Motivation: 解决多楼层3D游戏关卡在空间连贯性、导航功能和自适应游戏进程方面的挑战。

Method: 1. LLM辅助构建组件（设施、房间模板、游戏机制）数据库。 2. 多阶段生成：选择并排列房间实例形成多楼层结构；优化房间内部布局；根据规则集成游戏机制。 3. 两阶段修复系统确保导航性。

Result: 成功生成了多样化、可导航的3D环境，并通过参数化模拟了不同的游戏节奏策略。

Conclusion: 提出了一种可扩展的、以数据库为中心的自动化生成复杂3D关卡（具有可配置的游戏进程）的框架，推动了PCG领域的发展。

Abstract: Procedural Content Generation for 3D game levels faces challenges in
balancing spatial coherence, navigational functionality, and adaptable gameplay
progression across multi-floor environments. This paper introduces a novel
framework for generating such levels, centered on the offline, LLM-assisted
construction of reusable databases for architectural components (facilities and
room templates) and gameplay mechanic elements. Our multi-phase pipeline
assembles levels by: (1) selecting and arranging instances from the Room
Database to form a multi-floor global structure with an inherent topological
order; (2) optimizing the internal layout of facilities for each room based on
predefined constraints from the Facility Database; and (3) integrating
progression-based gameplay mechanics by placing components from a Mechanics
Database according to their topological and spatial rules. A subsequent
two-phase repair system ensures navigability. This approach combines modular,
database-driven design with constraint-based optimization, allowing for
systematic control over level structure and the adaptable pacing of gameplay
elements. Initial experiments validate the framework's ability in generating
diverse, navigable 3D environments and its capability to simulate distinct
gameplay pacing strategies through simple parameterization. This research
advances PCG by presenting a scalable, database-centric foundation for the
automated generation of complex 3D levels with configurable gameplay
progression.

</details>


### [167] [MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation](https://arxiv.org/abs/2508.19163)
*Ernest Lim,Yajie Vera He,Jared Joselowitz,Kate Preston,Mohita Chowdhury,Louis Williams,Aisling Higham,Katrina Mason,Mariane Melo,Tom Lawton,Yan Jia,Ibrahim Habli*

Main category: cs.AI

TL;DR: 该论文提出了一个名为MATRIX的框架，用于评估临床对话系统中大型语言模型(LLM)的安全性，该框架整合了安全场景分类、基于LLM的行为评估和模拟病人对话，并在实验中证明了其有效性，能够实现可扩展、系统化的安全评估和审计。


<details>
  <summary>Details</summary>
Motivation: 现有临床对话系统评估主要关注任务完成度和流畅性，忽视了安全关键系统所必需的行为和风险管理要求。本研究旨在开发一个安全导向的评估框架，以解决这一不足。

Method: 本研究提出的MATRIX框架包含三个主要部分：1. 一个安全对齐的临床场景分类，其中包含预期的系统行为和故障模式，这些是通过结构化的安全工程方法得出的。2. BehvJudge，一个基于LLM的评估器，用于检测与安全相关的对话故障，并通过专家临床医生标注进行了验证。3. PatBot，一个能够产生多样化、受场景条件影响的响应的模拟病人代理，其真实性和行为保真度通过人类因素专业知识和病人偏好研究进行了评估。

Result: 实验结果表明，MATRIX框架能够实现系统化、可扩展的安全评估。BehvJudge在危险检测方面达到了专家级别（F1 0.96，敏感度0.999），优于盲评的临床医生。PatBot在真实性分析中表现出能够可靠地模拟真实病人行为。使用MATRIX对五个LLM代理在14种危险场景和10个临床领域进行了2100次模拟对话的基准测试，证明了其有效性。

Conclusion: MATRIX是第一个将结构化安全工程与可扩展、经验证的对话式AI评估相结合的框架，能够实现符合监管的安全审计，并已发布所有评估工具、提示、结构化场景和数据集。

Abstract: Despite the growing use of large language models (LLMs) in clinical dialogue
systems, existing evaluations focus on task completion or fluency, offering
little insight into the behavioral and risk management requirements essential
for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion
fRamework for safe Interactions and conteXtual clinical conversational
evaluation), a structured, extensible framework for safety-oriented evaluation
of clinical dialogue agents.
  MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical
scenarios, expected system behaviors and failure modes derived through
structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator
for detecting safety-relevant dialogue failures, validated against expert
clinician annotations; and (3) PatBot, a simulated patient agent capable of
producing diverse, scenario-conditioned responses, evaluated for realism and
behavioral fidelity with human factors expertise, and a patient-preference
study.
  Across three experiments, we show that MATRIX enables systematic, scalable
safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard
detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded
assessment of 240 dialogues. We also conducted one of the first realism
analyses of LLM-based patient simulation, showing that PatBot reliably
simulates realistic patient behavior in quantitative and qualitative
evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking
five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios
and 10 clinical domains.
  MATRIX is the first framework to unify structured safety engineering with
scalable, validated conversational AI evaluation, enabling regulator-aligned
safety auditing. We release all evaluation tools, prompts, structured
scenarios, and datasets.

</details>


### [168] [SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting](https://arxiv.org/abs/2508.18554)
*Lily Jiaxin Wan,Chia-Tung Ho,Rongjian Liang,Cunxi Yu,Deming Chen,Haoxing Ren*

Main category: cs.AI

TL;DR: SchemaCoder是一个全自动的日志模式提取框架，无需人工干预，通过其新颖的残差问答树（Q-Tree）增强机制，利用LLM进行迭代优化，在LogHub-2.0基准测试中取得了显著优于现有方法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 日志模式提取是处理海量日志数据以生成人类可读模板的关键任务，但传统方法耗时耗力，现有自动化方法依赖预定义正则表达式，限制了效率提升。

Method: SchemaCoder采用上下文边界分段进行语义分块，使用基于嵌入的采样来选择代表性模式，并通过分层Q-Tree驱动的LLM查询生成模式代码，结合文本残差演化优化器和残差增强进行迭代优化。

Result: SchemaCoder在LogHub-2.0基准测试中表现优越，平均比现有技术提高了21.3%的性能。

Conclusion: SchemaCoder是首个完全自动化的日志模式提取框架，适用于多种日志格式，无需人工定制，通过其核心的Q-Tree增强机制实现了对现有方法的显著超越。

Abstract: Log schema extraction is the process of deriving human-readable templates
from massive volumes of log data, which is essential yet notoriously
labor-intensive. Recent studies have attempted to streamline this task by
leveraging Large Language Models (LLMs) for automated schema extraction.
However, existing methods invariably rely on predefined regular expressions,
necessitating human domain expertise and severely limiting productivity gains.
To fundamentally address this limitation, we introduce SchemaCoder, the first
fully automated schema extraction framework applicable to a wide range of log
file formats without requiring human customization within the flow. At its
core, SchemaCoder features a novel Residual Question-Tree (Q-Tree) Boosting
mechanism that iteratively refines schema extraction through targeted, adaptive
queries driven by LLMs. Particularly, our method partitions logs into semantic
chunks via context-bounded segmentation, selects representative patterns using
embedding-based sampling, and generates schema code through hierarchical
Q-Tree-driven LLM queries, iteratively refined by our textual-residual
evolutionary optimizer and residual boosting. Experimental validation
demonstrates SchemaCoder's superiority on the widely-used LogHub-2.0 benchmark,
achieving an average improvement of 21.3% over state-of-the-arts.

</details>


### [169] [eSkinHealth: A Multimodal Dataset for Neglected Tropical Skin Diseases](https://arxiv.org/abs/2508.18608)
*Janet Wang,Xin Hu,Yunbei Zhang,Diabate Almamy,Vagamon Bamba,Konan Amos Sébastien Koffi,Yao Koffi Aubin,Zhengming Ding,Jihun Hamm,Rie R. Yotsu*

Main category: cs.AI

TL;DR: 该研究提出了eSkinHealth数据集，一个包含5,623张图像的皮肤病学数据集，专注于西非人群的皮肤病和罕见病，并提出了一种AI-专家协作标注框架，以促进更公平、准确和可解释的AI皮肤病学工具的开发。


<details>
  <summary>Details</summary>
Motivation: 解决AI驱动的皮肤病学诊断在数据稀疏性方面存在的问题，特别是在代表性不足的人群和罕见病症方面。

Method: 创建了eSkinHealth数据集，收集了5,623张图像，涵盖了47种皮肤病，重点关注皮肤病和西非人群的罕见病。引入了AI-专家协作范式，利用基础语言和分割模型进行多模态标注。

Result: eSkinHealth数据集包含患者元数据、诊断标签、语义病灶掩码、实例特定视觉描述和临床概念，为全球皮肤病学AI工具的开发提供了宝贵的资源和可扩展的标注框架。

Conclusion: eSkinHealth数据集和标注框架旨在促进更公平、准确和可解释的AI皮肤病学工具的开发，以应对皮肤病在热带贫困社区造成的健康和社会经济负担。

Abstract: Skin Neglected Tropical Diseases (NTDs) impose severe health and
socioeconomic burdens in impoverished tropical communities. Yet, advancements
in AI-driven diagnostic support are hindered by data scarcity, particularly for
underrepresented populations and rare manifestations of NTDs. Existing
dermatological datasets often lack the demographic and disease spectrum crucial
for developing reliable recognition models of NTDs. To address this, we
introduce eSkinHealth, a novel dermatological dataset collected on-site in
C\^ote d'Ivoire and Ghana. Specifically, eSkinHealth contains 5,623 images from
1,639 cases and encompasses 47 skin diseases, focusing uniquely on skin NTDs
and rare conditions among West African populations. We further propose an
AI-expert collaboration paradigm to implement foundation language and
segmentation models for efficient generation of multimodal annotations, under
dermatologists' guidance. In addition to patient metadata and diagnosis labels,
eSkinHealth also includes semantic lesion masks, instance-specific visual
captions, and clinical concepts. Overall, our work provides a valuable new
resource and a scalable annotation framework, aiming to catalyze the
development of more equitable, accurate, and interpretable AI tools for global
dermatology.

</details>


### [170] [RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing](https://arxiv.org/abs/2508.18642)
*Jianxing Liao,Tian Zhang,Xiao Feng,Yusong Zhang,Rui Yang,Haorui Wang,Bosi Wen,Ziying Wang,Runzhi Shi*

Main category: cs.AI

TL;DR: RLMR是一种新颖的在线强化学习方法，通过动态混合奖励来优化创意写作，同时考虑主观写作质量和客观约束遵循，并在WriteEval基准上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在平衡创意写作中的主观写作质量（如文学性和情感表达）和客观约束遵循（如格式要求和字数限制）方面存在困难，单一奖励策略无法同时提升两方面能力，而固定权重混合奖励方法缺乏适应不同写作场景的能力。

Method: 提出了一种名为RLMR（Reinforcement Learning with Mixed Rewards）的方法，该方法利用奖励模型评估主观写作质量，并结合约束验证模型评估客观约束遵循，形成一个动态混合奖励系统。RLMR的关键创新在于根据样本组内的写作质量动态调整约束遵循奖励的权重，确保违反约束的样本在GRPO（Generalized Proximal Policy Optimization）中获得负优势并受到惩罚。

Result: 通过在8B到72B参数的多种模型家族上进行自动和人工评估，并构建了一个名为WriteEval的真实世界写作基准，结果表明RLMR在指令遵循（IFEval从83.36%提高到86.65%）和写作质量（在WriteEval上手动专家成对评估中胜率为72.75%）方面均取得了持续的改进。

Conclusion: RLMR是首个将主观偏好与客观验证相结合的在线强化学习训练方法，为多维度创意写作优化提供了有效的解决方案。

Abstract: Large language models are extensively utilized in creative writing
applications. Creative writing requires a balance between subjective writing
quality (e.g., literariness and emotional expression) and objective constraint
following (e.g., format requirements and word limits). Existing reinforcement
learning methods struggle to balance these two aspects: single reward
strategies fail to improve both abilities simultaneously, while fixed-weight
mixed-reward methods lack the ability to adapt to different writing scenarios.
To address this problem, we propose Reinforcement Learning with Mixed Rewards
(RLMR), utilizing a dynamically mixed reward system from a writing reward model
evaluating subjective writing quality and a constraint verification model
assessing objective constraint following. The constraint following reward
weight is adjusted dynamically according to the writing quality within sampled
groups, ensuring that samples violating constraints get negative advantage in
GRPO and thus penalized during training, which is the key innovation of this
proposed method. We conduct automated and manual evaluations across diverse
model families from 8B to 72B parameters. Additionally, we construct a
real-world writing benchmark named WriteEval for comprehensive evaluation.
Results illustrate that our method achieves consistent improvements in both
instruction following (IFEval from 83.36\% to 86.65\%) and writing quality
(72.75\% win rate in manual expert pairwise evaluations on WriteEval). To the
best of our knowledge, RLMR is the first work to combine subjective preferences
with objective verification in online RL training, providing an effective
solution for multi-dimensional creative writing optimization.

</details>


### [171] [Beyond Benchmark: LLMs Evaluation with an Anthropomorphic and Value-oriented Roadmap](https://arxiv.org/abs/2508.18646)
*Jun Wang,Ninglun Gu,Kailai Zhang,Zijiao Zhang,Yelun Bao,Jin Yang,Xu Yin,Liwei Liu,Yihuan Liu,Pengyong Li,Gary G. Yen,Junchi Yan*

Main category: cs.AI

TL;DR: LLM评估框架应包含IQ、EQ、PQ和VQ，以弥合理论与实践差距。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估框架存在碎片化问题，侧重技术指标而忽视了实际部署中的整体评估。

Method: 提出了一种拟人化评估范式，并构建了一个包含IQ（通用智能）、EQ（对齐能力）和PQ（专业知识）的三维分类法，以及一个包含经济可行性、社会影响、伦理对齐和环境可持续性的VQ（价值导向评估）框架，并提出了包含六个组件的模块化架构和实施路线图。

Result: 对200多个基准进行了分析，发现了动态评估需求和可解释性差距等关键挑战，并为开发技术精湛、符合情境且符合伦理的LLM提供了可行性指导。

Conclusion: LLM的评估需要超越传统基准测试，采用更全面的方法，涵盖通用智能、情感智能、专业能力和实际价值，以确保其在现实世界中的有效性和可靠性。

Abstract: For Large Language Models (LLMs), a disconnect persists between benchmark
performance and real-world utility. Current evaluation frameworks remain
fragmented, prioritizing technical metrics while neglecting holistic assessment
for deployment. This survey introduces an anthropomorphic evaluation paradigm
through the lens of human intelligence, proposing a novel three-dimensional
taxonomy: Intelligence Quotient (IQ)-General Intelligence for foundational
capacity, Emotional Quotient (EQ)-Alignment Ability for value-based
interactions, and Professional Quotient (PQ)-Professional Expertise for
specialized proficiency. For practical value, we pioneer a Value-oriented
Evaluation (VQ) framework assessing economic viability, social impact, ethical
alignment, and environmental sustainability. Our modular architecture
integrates six components with an implementation roadmap. Through analysis of
200+ benchmarks, we identify key challenges including dynamic assessment needs
and interpretability gaps. It provides actionable guidance for developing LLMs
that are technically proficient, contextually relevant, and ethically sound. We
maintain a curated repository of open-source evaluation resources at:
https://github.com/onejune2018/Awesome-LLM-Eval.

</details>


### [172] [MUA-RL: Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use](https://arxiv.org/abs/2508.18669)
*Weikang Zhao,Xili Wang,Chengdi Ma,Lingbin Kong,Zhaohua Yang,Mingxiang Tuo,Xiaowei Shi,Yitao Zhai,Xunliang Cai*

Main category: cs.AI

TL;DR: LLM代理工具使用中的多轮交互和动态用户需求是关键挑战。MUA-RL框架通过集成LLM模拟用户到RL训练循环中，实现了与动态用户的交互和工具使用的自主学习，并在多个基准测试中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理工具使用中多轮交互、动态不确定的用户需求带来的挑战，并克服现有RL方法缺乏动态用户训练的问题。

Method: 提出MUA-RL（Multi-turn User-interacting Agent Reinforcement Learning）框架，将LLM模拟用户集成到强化学习训练循环中，实现与动态用户的交互和工具使用的自主学习。

Result: MUA-RL-32B在TAU2 Retail、TAU2 Airline、TAU2 Telecom、BFCL-V3 Multi Turn和ACEBench Agent等多个多轮工具使用基准测试中，取得了优于或媲美更大规模开源模型的性能。

Conclusion: MUA-RL框架通过集成LLM模拟用户到RL训练循环中，能够有效学习与动态用户进行有效沟通和工具使用，以解决实际问题，并在多项基准测试中取得了领先的性能。

Abstract: With the recent rapid advancement of Agentic Intelligence, agentic tool use
in LLMs has become increasingly important. During multi-turn interactions
between agents and users, the dynamic, uncertain, and stochastic nature of user
demands poses significant challenges to the agent's tool invocation
capabilities. Agents are no longer expected to simply call tools to deliver a
result; rather, they must iteratively refine their understanding of user needs
through communication while simultaneously invoking tools to resolve user
queries. Existing reinforcement learning (RL) approaches for tool use lack the
integration of genuinely dynamic users during the RL training process. To
bridge this gap, we introduce MUA-RL (Multi-turn User-interacting Agent
Reinforcement Learning for agentic tool use), a novel reinforcement learning
framework that, for the first time in the field of agentic tool use, integrates
LLM-simulated users into the reinforcement learning loop. MUA-RL aims to enable
autonomous learning of models to communicate with users efficiently and use
various tools to solve practical problems in dynamic multi-turn interactions.
Evaluations are done on several multi-turn tool-using benchmarks (see Figure
1). Specifically, MUA-RL-32B achieves 67.3 on TAU2 Retail, 45.4 on TAU2
Airline, 28.3 on TAU2 Telecom, 28.4 on BFCL-V3 Multi Turn, and 82.5 on ACEBench
Agent -- outperforming or matching the performance of larger open-source models
such as DeepSeek-V3-0324 and Qwen3-235B-A22B in non-thinking settings.

</details>


### [173] [AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance](https://arxiv.org/abs/2508.18689)
*Yuyang Zhao,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: LLM代理通常是响应式的，限制了它们作为信息获取平台的效率。本文提出了AppAgent-Pro，一个主动的GUI代理系统，通过整合多领域信息和预测用户需求来克服这一限制，以实现更全面的信息获取。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）代理主要以被动响应的方式运作，这限制了它们作为通用信息获取平台的效率和效力。

Method: 提出AppAgent-Pro，一个主动的GUI代理系统，它能根据用户指令主动整合多领域信息，预测用户潜在需求并进行深入的多领域信息挖掘。

Result: AppAgent-Pro能够更全面、更智能地获取信息，有潜力重新定义日常生活中的信息获取方式。

Conclusion: AppAgent-Pro通过主动整合多领域信息和预测用户需求，克服了现有LLM代理的被动性限制，提高了信息获取的效率和智能性。

Abstract: Large language model (LLM)-based agents have demonstrated remarkable
capabilities in addressing complex tasks, thereby enabling more advanced
information retrieval and supporting deeper, more sophisticated human
information-seeking behaviors. However, most existing agents operate in a
purely reactive manner, responding passively to user instructions, which
significantly constrains their effectiveness and efficiency as general-purpose
platforms for information acquisition. To overcome this limitation, this paper
proposes AppAgent-Pro, a proactive GUI agent system that actively integrates
multi-domain information based on user instructions. This approach enables the
system to proactively anticipate users' underlying needs and conduct in-depth
multi-domain information mining, thereby facilitating the acquisition of more
comprehensive and intelligent information. AppAgent-Pro has the potential to
fundamentally redefine information acquisition in daily life, leading to a
profound impact on human society. Our code is available at:
https://github.com/LaoKuiZe/AppAgent-Pro. Our code is available at:
https://github.com/LaoKuiZe/AppAgent-Pro. The demonstration video could be
found at:
https://www.dropbox.com/scl/fi/hvzqo5vnusg66srydzixo/AppAgent-Pro-demo-video.mp4?rlkey=o2nlfqgq6ihl125mcqg7bpgqu&st=d29vrzii&dl=0.

</details>


### [174] [VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft](https://arxiv.org/abs/2508.18722)
*Honghao Fu,Junlong Ren,Qi Chai,Deheng Ye,Yujun Cai,Hao Wang*

Main category: cs.AI

TL;DR: VistaWise是一个经济高效的代理框架，通过整合跨模态领域知识和微调专门的物体检测模型来进行视觉分析，将领域特定训练数据的需求从数百万样本减少到几百个，并在各种开放世界任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在虚拟开放世界环境的具身决策任务中显示出巨大潜力，但缺乏领域特定知识会阻碍其性能。而通过大规模领域特定数据进行微调的方法需要高昂的开发成本。

Method: VistaWise框架整合了视觉信息和文本依赖到跨模态知识图谱（KG）中，并配备了基于检索的池化策略从KG中提取任务相关信息，以及一个桌面级技能库，通过鼠标和键盘输入直接操作Minecraft桌面客户端。此外，它还微调了一个专门的物体检测模型来进行视觉分析。

Result: 实验结果表明，VistaWise在各种开放世界任务中取得了最先进的性能，有效降低了开发成本，同时提高了代理性能。

Conclusion: VistaWise通过整合跨模态领域知识和微调物体检测模型，显著降低了对领域特定训练数据的需求，并实现了在开放世界任务中的卓越性能，证明了其在降低开发成本和提升代理性能方面的有效性。

Abstract: Large language models (LLMs) have shown significant promise in embodied
decision-making tasks within virtual open-world environments. Nonetheless,
their performance is hindered by the absence of domain-specific knowledge.
Methods that finetune on large-scale domain-specific data entail prohibitive
development costs. This paper introduces VistaWise, a cost-effective agent
framework that integrates cross-modal domain knowledge and finetunes a
dedicated object detection model for visual analysis. It reduces the
requirement for domain-specific training data from millions of samples to a few
hundred. VistaWise integrates visual information and textual dependencies into
a cross-modal knowledge graph (KG), enabling a comprehensive and accurate
understanding of multimodal environments. We also equip the agent with a
retrieval-based pooling strategy to extract task-related information from the
KG, and a desktop-level skill library to support direct operation of the
Minecraft desktop client via mouse and keyboard inputs. Experimental results
demonstrate that VistaWise achieves state-of-the-art performance across various
open-world tasks, highlighting its effectiveness in reducing development costs
while enhancing agent performance.

</details>


### [175] [Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval](https://arxiv.org/abs/2508.18724)
*Karanbir Singh,Deepak Muppiri,William Ngu*

Main category: cs.AI

TL;DR: Agentic AI, powered by LLMs, can be biased. A new Bias Mitigation Agent system is proposed to optimize source selection for fair and balanced information retrieval, showing an 81.82% bias reduction.


<details>
  <summary>Details</summary>
Motivation: Agentic AI systems inherit biases from information sources, affecting fairness and user trust. There is a need to mitigate this bias for reliable knowledge dissemination.

Method: A multi-agent system called the Bias Mitigation Agent was designed to optimize source selection, ensuring retrieved content is relevant and minimally biased.

Result: The Bias Mitigation Agent achieved an 81.82% reduction in bias compared to a naive retrieval baseline.

Conclusion: The proposed Bias Mitigation Agent effectively reduces bias in Agentic AI systems, promoting fair and balanced information retrieval and enhancing user trust.

Abstract: Large Language Models (LLMs) have transformed the field of artificial
intelligence by unlocking the era of generative applications. Built on top of
generative AI capabilities, Agentic AI represents a major shift toward
autonomous, goal-driven systems that can reason, retrieve, and act. However,
they also inherit the bias present in both internal and external information
sources. This significantly affects the fairness and balance of retrieved
information, and hence reduces user trust. To address this critical challenge,
we introduce a novel Bias Mitigation Agent, a multi-agent system designed to
orchestrate the workflow of bias mitigation through specialized agents that
optimize the selection of sources to ensure that the retrieved content is both
highly relevant and minimally biased to promote fair and balanced knowledge
dissemination. The experimental results demonstrate an 81.82\% reduction in
bias compared to a baseline naive retrieval strategy.

</details>


### [176] [CAC-CoT: Connector-Aware Compact Chain-of-Thought for Efficient Reasoning Data Synthesis Across Dual-System Cognitive Tasks](https://arxiv.org/abs/2508.18743)
*Sunguk Choi,Yonghoon Kwon,Heondeuk Lee*

Main category: cs.AI

TL;DR: CAC-CoT通过限制推理到固定数量的连接词，提升了LLM在“系统2”任务上的表现，同时保持了“系统1”任务的性能，并缩短了推理链的长度。


<details>
  <summary>Details</summary>
Motivation: 长链式思考（CoT）提示有助于大型语言模型（LLMs）解决复杂问题，但过长的推理链会降低模型在快速、直观的“系统1”任务上的性能。

Method: 提出了一种名为连接词感知紧凑CoT（CAC-CoT）的方法，该方法将推理限制在一小组固定的连接词中，引导模型生成简洁、结构良好的解释。

Result: CAC-CoT在GSM8K（系统2）任务上达到了约85%的准确率，在GPQA（系统2）任务上达到了约40%的准确率，同时在S1-Bench（系统1）任务上保持了约90%的准确率。其推理链平均长度约为300个token（ART），约为基线推理链长度的三分之一，提高了效率且不损失准确性。

Conclusion: CAC-CoT是一种简单有效的方法，可以提高LLM在复杂推理任务上的性能，同时保持其在直观任务上的表现，并显著提高效率。

Abstract: Long chain-of-thought (CoT) prompting helps Large Language Models (LLMs)
solve difficult problems, but very long traces often slow or even degrade
performance on fast, intuitive "System-1" tasks. We introduce Connector-Aware
Compact CoT (CAC-CoT) -- a method that deliberately restricts reasoning to a
small, fixed set of connector phrases, steering the model toward concise and
well -- structured explanations. Despite its simplicity, our synthetic method
with Gemini-2.0-Flash yields a high-quality training quality. CAC-CoT achieves
approximately 85% on GSM8K and approximately 40% on GPQA (System-2) while
retaining approximately 90% on S1-Bench (System-1). Its reasoning traces
average approximately 300 tokens(ART), about one-third the length of baseline
traces, delivering higher efficiency without loss of accuracy.

</details>


### [177] [Reflection-Enhanced Meta-Optimization Integrating TextGrad-style Prompt Optimization with Memory-Driven Self-Evolution](https://arxiv.org/abs/2508.18749)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: REMO通过引入“错误笔记本”和LLM驱动的元控制器来改进提示优化，从而实现持续的提示改进，并在GSM8K基准测试中展示了比TextGrad更稳定、更鲁棒的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的提示优化方法通常是无状态的，并且在优化运行中独立操作，缺乏保持和利用历史优化经验的机制，容易导致泛化能力差的提示更新。

Method: 提出了一种名为REMO（Reflection-Enhanced Meta-Optimization）的新颖框架，它集成了记忆增强的检索增强生成（RAG）模块（结构化为“错误笔记本”）和一个自适应优化器（通过LLM驱动的元控制器实现），该控制器综合了时期级别的反思性见解，以迭代地改进系统级别的提示策略。

Result: 与TextGrad基线相比，REMO在GSM8K数学推理基准测试上实现了更稳定、更鲁棒的泛化能力，但计算开销有所增加。

Conclusion: REMO框架通过整合反思和元优化，能够系统地累积和重用跨运行的优化知识，支持随时间的持续改进，并在实验中证明了其优越性。

Abstract: Recent advances in prompt optimization, exemplified by methods such as
TextGrad, enable automatic, gradient-like refinement of textual prompts to
enhance the performance of large language models (LLMs) on specific downstream
tasks. However, current approaches are typically stateless and operate
independently across optimization runs, lacking mechanisms to preserve and
leverage historical optimization experience. Furthermore, they are susceptible
to overfitting, often yielding prompt updates that generalize poorly beyond the
immediate task context.
  To address these limitations, we propose Reflection-Enhanced
Meta-Optimization (REMO), a novel framework that integrates (1) a
memory-augmented Reflection Retrieval-Augmented Generation (RAG) module -
structured as a "mistake notebook" and (2) a Self-Adaptive Optimizer,
implemented via an LLM-driven meta-controller that synthesizes epoch-level
reflective insights to iteratively improve system-level prompting strategies.
This architecture enables not only local, fine-grained prompt tuning akin to
TextGrad, but also the systematic accumulation and reuse of cross-run
optimization knowledge, thereby supporting continual improvement over time.
  We instantiate the REMO framework using Qwen3-32B in standard inference mode
- without explicit chain-of-thought prompting - and evaluate its efficacy on
the GSM8K benchmark for mathematical reasoning. Experimental results
demonstrate that, compared to a TextGrad baseline, REMO achieves more stable
and robust generalization, albeit at the cost of increased computational
overhead. We provide a detailed exposition of the algorithmic design, conduct a
qualitative and quantitative analysis of optimization dynamics, and present a
comprehensive ablation study to elucidate the contributions of each component.

</details>


### [178] [Stabilizing Open-Set Test-Time Adaptation via Primary-Auxiliary Filtering and Knowledge-Integrated Prediction](https://arxiv.org/abs/2508.18751)
*Byung-Joon Lee,Jin-Seop Lee,Jee-Hyong Lee*

Main category: cs.AI

TL;DR: 本研究提出了一种名为PAF-KIP的测试时域适应（TTA）方法，用于解决开放集TTA（OSTTA）中存在的模型不稳和错误累积问题。PAF-KIP通过引入辅助滤波器来提高数据过滤的准确性，并通过整合源模型、自适应模型和EMA模型的知识来优化预测结果，从而提升了OSTTA的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放集测试时域适应（OSTTA）方法在识别和过滤开放集数据时存在准确性不高的问题，因为它们依赖于源模型进行过滤，而源模型在处理域偏移数据时表现不佳。同时，使用自适应模型进行过滤会导致不稳定和错误累积。

Method:  PAF-KIP方法包含两个主要部分：1. 主要-辅助过滤（PAF）：引入一个辅助滤波器来验证主要滤波器过滤的数据，提高了过滤的准确性。2. 知识整合预测（KIP）：通过校准自适应模型、EMA模型和源模型的输出来整合它们的互补知识，从而优化预测结果。

Result: PAF-KIP在各种闭集和开放集数据集上进行了验证，结果表明该方法能够同时提升闭集准确性和开放集判别能力，优于现有方法。

Conclusion: PAF-KIP通过引入PAF和KIP，有效解决了OSTTA中的数据过滤和知识整合问题，显著提高了模型在开放集场景下的性能。

Abstract: Deep neural networks demonstrate strong performance under aligned
training-test distributions. However, real-world test data often exhibit domain
shifts. Test-Time Adaptation (TTA) addresses this challenge by adapting the
model to test data during inference. While most TTA studies assume that the
training and test data share the same class set (closed-set TTA), real-world
scenarios often involve open-set data (open-set TTA), which can degrade
closed-set accuracy. A recent study showed that identifying open-set data
during adaptation and maximizing its entropy is an effective solution. However,
the previous method relies on the source model for filtering, resulting in
suboptimal filtering accuracy on domain-shifted test data. In contrast, we
found that the adapting model, which learns domain knowledge from noisy test
streams, tends to be unstable and leads to error accumulation when used for
filtering. To address this problem, we propose Primary-Auxiliary Filtering
(PAF), which employs an auxiliary filter to validate data filtered by the
primary filter. Furthermore, we propose Knowledge-Integrated Prediction (KIP),
which calibrates the outputs of the adapting model, EMA model, and source model
to integrate their complementary knowledge for OSTTA. We validate our approach
across diverse closed-set and open-set datasets. Our method enhances both
closed-set accuracy and open-set discrimination over existing methods. The code
is available at https://github.com/powerpowe/PAF-KIP-OSTTA .

</details>


### [179] [Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention Failures in Large Reasoning Models](https://arxiv.org/abs/2508.18760)
*Yi Liu,Xiangyu Liu,Zequn Sun,Wei Hu*

Main category: cs.AI

TL;DR: 大型推理模型（LRM）在处理不可回答问题时，未能给出适当的弃权回答。本文提出了一种结合认知监控和推理时间干预的两阶段方法，以提高LRM在面对此类问题时的弃权率，同时保持整体推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型（LRM）在面对数学问题等固有不可回答的问题时，未能给出恰当弃权回答的问题，以实现可信赖的人工智能。

Method: 提出了一种轻量级的两阶段方法，结合了认知监控和推理时间干预。

Result: 该方法显著提高了弃权率，同时保持了整体推理性能。

Conclusion: LRM具有识别问题缺陷的认知能力，但其内部认知与外部响应之间存在不匹配，导致无法给出恰当的弃权回答。所提出的方法可以解决这个问题。

Abstract: Large reasoning models (LRMs) have shown remarkable progress on complex
reasoning tasks. However, some questions posed to LRMs are inherently
unanswerable, such as math problems lacking sufficient conditions. We find that
LRMs continually fail to provide appropriate abstentions when confronted with
these unanswerable questions. In this paper, we systematically analyze,
investigate, and resolve this issue for trustworthy AI. We first conduct a
detailed analysis of the distinct response behaviors of LRMs when facing
unanswerable questions. Then, we show that LRMs possess sufficient cognitive
capabilities to recognize the flaws in these questions. However, they fail to
exhibit appropriate abstention behavior, revealing a misalignment between their
internal cognition and external response. Finally, to resolve this issue, we
propose a lightweight, two-stage method that combines cognitive monitoring with
inference-time intervention. Experimental results demonstrate that our method
significantly improves the abstention rate while maintaining the overall
reasoning performance.

</details>


### [180] [Dynamic Collaboration of Multi-Language Models based on Minimal Complete Semantic Units](https://arxiv.org/abs/2508.18763)
*Chao Hao,Zezheng Wang,Yanhua Huang,Ruiwen Xu,Wenzhe Niu,Xin Liu,Zitong Yu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为DDS（Distribution Distance-based Dynamic Selection）的策略，通过选择来自多个语言模型的“最优”token来提升语言模型的推理能力，并引入了“最小完整语义单元”（MCSU）的概念来解决多模型协作中的词汇不对齐问题。实验结果表明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提升语言模型（LM）的推理能力，并通过多模型协作的方式来达到这一目的。

Method: 本研究提出了一种token级别的多模型协作方法，通过选择多个模型提供的下一个token分布中的最优token来进行自回归推理。具体来说，我们引入了一种基于分布距离的动态选择策略（DDS）来优化多模型协作过程，并提出了“最小完整语义单元”（MCSU）的概念来解决词汇不对齐的挑战。

Result: 实验结果表明，与仅使用单个模型或简单聚合多个模型的方法相比，我们提出的DDS策略在多个基准测试中表现出优越性。

Conclusion: 本研究成功地通过token级别的多模型协作（DDS策略和MCSU概念）提升了语言模型的推理能力，并解决了多模型协作中的关键挑战。

Abstract: This paper investigates the enhancement of reasoning capabilities in language
models through token-level multi-model collaboration. Our approach selects the
optimal tokens from the next token distributions provided by multiple models to
perform autoregressive reasoning. Contrary to the assumption that more models
yield better results, we introduce a distribution distance-based dynamic
selection strategy (DDS) to optimize the multi-model collaboration process. To
address the critical challenge of vocabulary misalignment in multi-model
collaboration, we propose the concept of minimal complete semantic units
(MCSU), which is simple yet enables multiple language models to achieve natural
alignment within the linguistic space. Experimental results across various
benchmarks demonstrate the superiority of our method. The code will be
available at https://github.com/Fanye12/DDS.

</details>


### [181] [AniME: Adaptive Multi-Agent Planning for Long Animation Generation](https://arxiv.org/abs/2508.18781)
*Lisai Zhang,Baohan Xu,Siqian Yang,Mingyu Yin,Jing Liu,Chao Xu,Siqi Wang,Yidi Wu,Yuxin Hong,Zihao Zhang,Yanzhang Liang,Yudong Jiang*

Main category: cs.AI

TL;DR: AniME是一个自动化长篇动漫制作的导演导向的多智能体系统，涵盖了从故事到最终视频的完整工作流程。


<details>
  <summary>Details</summary>
Motivation: 旨在实现自动化长篇动漫制作，覆盖从故事到最终视频的完整工作流程。

Method: 提出AniME，一个导演导向的多智能体系统。该系统包含一个全局导演智能体和多个下游的专业智能体。通过集成定制的模型上下文协议（MCP）和下游模型指令，专业智能体能够自适应地为各种子任务选择控制条件。

Result: AniME能够制作具有一致性角色和同步视听元素的电影动画。

Conclusion: AniME为AI驱动的动漫创作提供了一个可扩展的解决方案。

Abstract: We present AniME, a director-oriented multi-agent system for automated
long-form anime production, covering the full workflow from a story to the
final video. The director agent keeps a global memory for the whole workflow,
and coordinates several downstream specialized agents. By integrating
customized Model Context Protocol (MCP) with downstream model instruction, the
specialized agent adaptively selects control conditions for diverse sub-tasks.
AniME produces cinematic animation with consistent characters and synchronized
audio visual elements, offering a scalable solution for AI-driven anime
creation.

</details>


### [182] [CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks](https://arxiv.org/abs/2508.18797)
*Qi Chai,Zhang Zheng,Junlong Ren,Deheng Ye,Zichuan Lin,Hao Wang*

Main category: cs.AI

TL;DR: CausalMACE是一个整体因果规划框架，用于增强多智能体系统，通过任务图和基于因果的模块来管理子任务依赖性，并在Minecraft中实现了最先进的多智能体协作性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要采用单一大型语言模型（LLM）智能体来完成Minecraft中的各种游戏内任务，但对于需要长序列动作的复杂任务，这种方法存在效率低下和容错性有限的挑战，而多智能体协作的研究仍然很少。

Method: 提出CausalMACE框架，包含一个用于全局任务规划的任务图模块和一个用于依赖管理的基于因果的模块，该模块采用固有规则执行因果干预。

Result: 实验结果表明，该方法在Minecraft的多智能体协作任务中取得了最先进的性能。

Conclusion: CausalMACE通过引入因果关系来管理子任务依赖性，有效解决了单智能体在复杂任务中遇到的效率和容错性问题，并在Minecraft多智能体协作任务中取得了优于现有方法的性能。

Abstract: Minecraft, as an open-world virtual interactive environment, has become a
prominent platform for research on agent decision-making and execution.
Existing works primarily adopt a single Large Language Model (LLM) agent to
complete various in-game tasks. However, for complex tasks requiring lengthy
sequences of actions, single-agent approaches often face challenges related to
inefficiency and limited fault tolerance. Despite these issues, research on
multi-agent collaboration remains scarce. In this paper, we propose CausalMACE,
a holistic causality planning framework designed to enhance multi-agent
systems, in which we incorporate causality to manage dependencies among
subtasks. Technically, our proposed framework introduces two modules: an
overarching task graph for global task planning and a causality-based module
for dependency management, where inherent rules are adopted to perform causal
intervention. Experimental results demonstrate our approach achieves
state-of-the-art performance in multi-agent cooperative tasks of Minecraft.

</details>


### [183] [STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning](https://arxiv.org/abs/2508.18812)
*Chenghao Wu,Ruiyang Ren,Junjie Zhang,Ruirui Wang,Zhongrui Ma,Qi Ye,Wayne Xin Zhao*

Main category: cs.AI

TL;DR: STARec是一个慢思考增强型智能体框架，通过引入自主审慎推理能力来改进推荐系统，解决了现有模型中存在的静态用户建模和被动决策等局限性。它通过将用户建模为具有快速响应和慢速推理（链式思考）的并行认知智能体，并结合锚定强化训练（结合结构化知识蒸馏和偏好对齐奖励塑造），显著提升了推荐性能，尤其在稀疏数据场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统（包括基于LLM的推荐系统）存在静态用户建模、被动决策、浅层相关性偏差、有限的因果推断能力以及在稀疏数据场景下的脆弱性等问题。STARec旨在通过引入自主的、审慎的推理能力来克服这些局限性。

Method: STARec框架将每个用户建模为一个具有并行认知的智能体，包括用于即时交互的快速响应和用于执行链式思考推理的慢速推理。为了培养内在的慢思考能力，开发了一种名为锚定强化训练的两阶段训练范式，该范式结合了来自高级推理模型的结构化知识蒸馏和偏好对齐奖励塑造，从而可以进行动态策略适应。

Result: STARec在MovieLens 1M和Amazon CDs数据集上的实验表明，与最先进的基线相比，STARec取得了显著的性能提升，并且仅使用了全训练数据的0.4%。

Conclusion: STARec通过引入慢思考和自主审慎推理，克服了传统推荐系统的局限性，并在稀疏数据场景下实现了优于现有技术的性能。

Abstract: While modern recommender systems are instrumental in navigating information
abundance, they remain fundamentally limited by static user modeling and
reactive decision-making paradigms. Current large language model (LLM)-based
agents inherit these shortcomings through their overreliance on heuristic
pattern matching, yielding recommendations prone to shallow correlation bias,
limited causal inference, and brittleness in sparse-data scenarios. We
introduce STARec, a slow-thinking augmented agent framework that endows
recommender systems with autonomous deliberative reasoning capabilities. Each
user is modeled as an agent with parallel cognitions: fast response for
immediate interactions and slow reasoning that performs chain-of-thought
rationales. To cultivate intrinsic slow thinking, we develop anchored
reinforcement training - a two-stage paradigm combining structured knowledge
distillation from advanced reasoning models with preference-aligned reward
shaping. This hybrid approach scaffolds agents in acquiring foundational
capabilities (preference summarization, rationale generation) while enabling
dynamic policy adaptation through simulated feedback loops. Experiments on
MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves
substantial performance gains compared with state-of-the-art baselines, despite
using only 0.4% of the full training data.

</details>


### [184] [Judicial Requirements for Generative AI in Legal Reasoning](https://arxiv.org/abs/2508.18880)
*Eljas Linna,Tuula Linna*

Main category: cs.AI

TL;DR: LLM在法律领域的应用仍面临挑战，尤其是在判例规则确定和法律适用方面。AI增强机制如RAG、多智能体和神经符号AI有潜力解决部分问题，但涉及自由裁量权和可解释性推理仍有待提升。AI目前最适合担任简单案件的助手和复杂案件的辅助分析工具。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在法律领域的可靠性，识别其在司法判决中的局限性，并提出AI系统应具备的核心能力。

Method: 使用IRAC模型分析法律判决中的规则确定（R）和规则适用（A）阶段，并将AI增强机制（如RAG、多智能体、神经符号AI）映射到法律推理的核心要求上。

Result: AI增强机制可在一定程度上解决法律推理中的部分挑战，但对于需要自由裁量权和透明、可解释推理的任务仍存在显著困难。

Conclusion: AI在法律领域的最佳应用是双重的：作为处理简单、重复性案件的高效助手，以及作为复杂案件中人类专家的智能“辩论伙伴”.

Abstract: Large Language Models (LLMs) are being integrated into professional domains,
yet their limitations in high-stakes fields like law remain poorly understood.
This paper defines the core capabilities that an AI system must possess to
function as a reliable reasoning tool in judicial decision-making. Using the
IRAC (Issue-Rule-Application-Conclusion) model as an analytical framework, the
study focuses on the most challenging phases of legal adjudication: determining
the applicable Rule (R) and performing the Application (A) of that rule to the
facts of a case. From a judicial perspective, the analysis deconstructs legal
reasoning into a series of core requirements, including the ability to select
the correct legal framework across jurisdictions, generate sound arguments
based on the doctrine of legal sources, distinguish ratio decidendi from obiter
dictum in case law, resolve ambiguity arising from general clauses like
"reasonableness", manage conflicting legal provisions, and correctly apply the
burden of proof. The paper then maps various AI enhancement mechanisms, such as
Retrieval-Augmented Generation (RAG), multi-agent systems, and neuro-symbolic
AI, to these requirements, assessing their potential to bridge the gap between
the probabilistic nature of LLMs and the rigorous, choice-driven demands of
legal interpretation. The findings indicate that while these techniques can
address specific challenges, significant challenges remain, particularly in
tasks requiring discretion and transparent, justifiable reasoning. Our paper
concludes that the most effective current role for AI in law is a dual one: as
a high-volume assistant for simple, repetitive cases and as a sophisticated
"sparring partner" for human experts in complex matters.

</details>


### [185] [Interactive Evaluation of Large Language Models for Multi-Requirement Software Engineering Tasks](https://arxiv.org/abs/2508.18905)
*Dimitrios Rontogiannis,Maxime Peyrard,Nicolas Baldwin,Martin Josifoski,Robert West,Dimitrios Gunopulos*

Main category: cs.AI

TL;DR: 该论文提出了一个新颖的交互式评估框架，用于评估大型语言模型（LLMs）在多需求编程任务中的能力，通过结构化的、由反馈驱动的对话来模拟真实的软件工程场景。


<details>
  <summary>Details</summary>
Motivation: 标准的、静态的基准测试无法充分评估大型语言模型（LLMs）在软件工程等复杂任务中的细微能力。

Method: 该框架将每个任务建模为需求依赖图，并使用一个了解真实情况的“面试官”LLM，向“面试官”LLM提供最小、有针对性的提示，以帮助纠正错误并满足目标约束。

Result: 通过在DevAI基准上进行评估，并结合专家注释，结果强调了动态评估在推进协作代码生成代理发展方面的重要性。

Conclusion: 动态评估对于推进协作代码生成代理的发展至关重要，因为它能提供静态基准无法测量的细粒度诊断见解。

Abstract: Standard single-turn, static benchmarks fall short in evaluating the nuanced
capabilities of Large Language Models (LLMs) on complex tasks such as software
engineering. In this work, we propose a novel interactive evaluation framework
that assesses LLMs on multi-requirement programming tasks through structured,
feedback-driven dialogue. Each task is modeled as a requirement dependency
graph, and an ``interviewer'' LLM, aware of the ground-truth solution, provides
minimal, targeted hints to an ``interviewee'' model to help correct errors and
fulfill target constraints. This dynamic protocol enables fine-grained
diagnostic insights into model behavior, uncovering strengths and systematic
weaknesses that static benchmarks fail to measure. We build on DevAI, a
benchmark of 55 curated programming tasks, by adding ground-truth solutions and
evaluating the relevance and utility of interviewer hints through expert
annotation. Our results highlight the importance of dynamic evaluation in
advancing the development of collaborative code-generating agents.

</details>


### [186] [FormaRL: Enhancing Autoformalization with no Labeled Data](https://arxiv.org/abs/2508.18914)
*Yanxing Huang,Xinling Jin,Sijie Liang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: FormaRL是一个利用少量无标签数据进行自动形式化的强化学习框架，通过结合Lean编译器和大型语言模型进行奖励计算，并采用GRPO算法进行更新。该框架在ProofNet和uproof数据集上显著提高了Qwen2.5-Coder-7B-Instruct模型的自动形式化准确率，并在uproof数据集上展现了良好的分布外性能。


<details>
  <summary>Details</summary>
Motivation: 自动形式化在形式验证中至关重要，但受限于数据稀疏和方法效率。

Method: FormaRL是一个强化学习框架，结合了Lean编译器的语法检查和大型语言模型的逻辑一致性检查来计算奖励，并使用GRPO算法进行模型更新。

Result: FormaRL将Qwen2.5-Coder-7B-Instruct模型的pass@1自动形式化准确率在ProofNet上提高了4-6倍（从4.04%提升至26.15%），在uproof数据集上从2.4%提升至9.6%。在uproof数据集上，FormaRL在pass@1和pass@16准确率上也优于现有的最先进的自动形式化工具。

Conclusion: FormaRL是一个有效且数据需求低的框架，能够显著提升大型语言模型在自动形式化任务上的表现，并且通过引入uproof数据集促进了高级数学领域自动形式化和定理证明的研究。

Abstract: Autoformalization is one of the central tasks in formal verification, while
its advancement remains hindered due to the data scarcity and the absence
efficient methods. In this work we propose \textbf{FormaRL}, a simple yet
efficient reinforcement learning framework for autoformalization which only
requires a small amount of unlabeled data. FormaRL integrates syntax check from
Lean compiler and consistency check from large language model to calculate the
reward, and adopts GRPO algorithm to update the formalizer. We also curated a
proof problem dataset from undergraduate-level math materials, named
\textbf{uproof}, in the hope to facilitate the exploration of autoformalization
and theorem proving in advanced math. Experiments show that FormaRL can
increase the pass@1 autoformalization accuracy of Qwen2.5-Coder-7B-Instruct by
4 $\sim$ 6x (4.04\% $\to$ 26.15\% on ProofNet and 2.4\% $\to$ 9.6\% on uproof)
with merely 859 unlabeled data. And on uproof our method also achieved a strong
improvement in out-of-distribution performance compared to existing open-source
state-of-the-art autoformalizers on both pass@1 accuracy (6.2\% $\to$ 9.6\%)
and pass@16 accuracy (24.4\% $\to$ 33.6\%). Training code of FormaRL is
open-sourced at https://github.com/THUNLP-MT/FormaRL.

</details>


### [187] [Who Is Lagging Behind: Profiling Student Behaviors with Graph-Level Encoding in Curriculum-Based Online Learning Systems](https://arxiv.org/abs/2508.18925)
*Qian Xiao,Conn Breathnach,Ioana Ghergulescu,Conor O'Sullivan,Keith Johnston,Vincent Wade*

Main category: cs.AI

TL;DR: ITS会加剧学习差距，需要学生画像来解决，CTGraph是一种新的图表示学习方法，可以全面地分析学生行为和学习情况，识别学习困难学生，为教育者提供见解，以便进行有针对性的干预。


<details>
  <summary>Details</summary>
Motivation: 教育中智能辅导系统（ITS）的激增可能会加剧学习差距，因此需要学生画像来跟踪进度、识别有困难的学生并减轻差异。

Method: 提出了一种名为CTGraph的图级别表示学习方法，以自我监督的方式对学习者的行为和表现进行画像。

Result: CTGraph能够提供学生学习历程的整体视图，考虑了学生行为和表现的各个方面，以及学习路径的差异。该方法还可以识别学习困难的学生，并对不同群体进行比较分析，以查明学生在何时何地遇到困难。

Conclusion: CTGraph为教育工作者提供了学生学习历程的丰富见解，并为更有针对性的干预铺平了道路。

Abstract: The surge in the adoption of Intelligent Tutoring Systems (ITSs) in
education, while being integral to curriculum-based learning, can inadvertently
exacerbate performance gaps. To address this problem, student profiling becomes
crucial for tracking progress, identifying struggling students, and alleviating
disparities among students. Such profiling requires measuring student behaviors
and performance across different aspects, such as content coverage, learning
intensity, and proficiency in different concepts within a learning topic.
  In this study, we introduce CTGraph, a graph-level representation learning
approach to profile learner behaviors and performance in a self-supervised
manner. Our experiments demonstrate that CTGraph can provide a holistic view of
student learning journeys, accounting for different aspects of student
behaviors and performance, as well as variations in their learning paths as
aligned to the curriculum structure. We also show that our approach can
identify struggling students and provide comparative analysis of diverse groups
to pinpoint when and where students are struggling. As such, our approach opens
more opportunities to empower educators with rich insights into student
learning journeys and paves the way for more targeted interventions.

</details>


### [188] [VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation](https://arxiv.org/abs/2508.18933)
*David Egea,Barproda Halder,Sanghamitra Dutta*

Main category: cs.AI

TL;DR: VISION是一个用于检测源代码漏洞的框架，通过生成反事实训练数据和使用GNN来缓解虚假相关性，提高了检测的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 源代码漏洞检测至关重要，但现有GNN方法受限于训练数据不平衡和标签噪声，易学到虚假相关性，泛化能力差。

Method: VISION框架通过以下方式缓解虚假相关性：1.利用LLM生成反事实样本；2.对成对的、标签相反的代码样本进行GNN定向训练；3.利用图解释性识别关键代码语句。

Result: VISION在CWE-20漏洞检测任务上，将准确率从51.8%提升至97.8%，配对对比准确率从4.5%提升至95.8%，最差分组准确率从0.7%提升至85.5%。

Conclusion: VISION通过反事实数据增强和图解释性，提高了GNN在源代码漏洞检测中的鲁棒性、泛化能力和可解释性，为构建可信赖的AI网络安全系统提供了方法。

Abstract: Automated detection of vulnerabilities in source code is an essential
cybersecurity challenge, underpinning trust in digital systems and services.
Graph Neural Networks (GNNs) have emerged as a promising approach as they can
learn structural and logical code relationships in a data-driven manner.
However, their performance is severely constrained by training data imbalances
and label noise. GNNs often learn 'spurious' correlations from superficial code
similarities, producing detectors that fail to generalize well to unseen
real-world data. In this work, we propose a unified framework for robust and
interpretable vulnerability detection, called VISION, to mitigate spurious
correlations by systematically augmenting a counterfactual training dataset.
Counterfactuals are samples with minimal semantic modifications but opposite
labels. Our framework includes: (i) generating counterfactuals by prompting a
Large Language Model (LLM); (ii) targeted GNN training on paired code examples
with opposite labels; and (iii) graph-based interpretability to identify the
crucial code statements relevant for vulnerability predictions while ignoring
spurious ones. We find that VISION reduces spurious learning and enables more
robust, generalizable detection, improving overall accuracy (from 51.8% to
97.8%), pairwise contrast accuracy (from 4.5% to 95.8%), and worst-group
accuracy (from 0.7% to 85.5%) on the Common Weakness Enumeration (CWE)-20
vulnerability. We further demonstrate gains using proposed metrics: intra-class
attribution variance, inter-class attribution distance, and node score
dependency. We also release CWE-20-CFA, a benchmark of 27,556 functions (real
and counterfactual) from the high-impact CWE-20 category. Finally, VISION
advances transparent and trustworthy AI-based cybersecurity systems through
interactive visualization for human-in-the-loop analysis.

</details>


### [189] [Novel Approaches to Artificial Intelligence Development Based on the Nearest Neighbor Method](https://arxiv.org/abs/2508.18953)
*I. I. Priezzhev,D. A. Danko,A. V. Shubin*

Main category: cs.AI

TL;DR: 现代神经网络（包括大型语言模型）在人工智能应用中取得了显著成功，但存在幻觉、高计算复杂度、昂贵的微调和灾难性遗忘等根本性限制，这阻碍了它们在医学、工业过程管理和科学研究等关键领域的应用。本文提出了一种基于最近邻方法和分层聚类结构的替代方法，使用 k-最近邻算法可以显著减少或消除幻觉效应，并简化模型扩展和微调，无需重新训练整个网络。为克服 k-最近邻方法的高计算负载，本文提出使用基于 Kohonen 自组织映射的类树数据结构，从而大大加快了最近邻搜索。在手写数字识别和简单字幕翻译任务上进行的测试证实了该方法的有效性。在准确性略有下降的情况下，与穷举搜索方法相比，最近邻搜索时间减少了几百倍。所提出的方法具有透明度和可解释性，与人类认知机制高度一致，并显示出在需要高可靠性和可解释结果的任务中广泛应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 神经网络在人工智能应用中取得了显著成功，但存在幻觉、高计算复杂度、昂贵的微调和灾难性遗忘等根本性限制，这阻碍了它们在医学、工业过程管理和科学研究等关键领域的应用。

Method: 提出了一种基于最近邻方法和分层聚类结构的替代方法，使用 k-最近邻算法可以显著减少或消除幻觉效应，并简化模型扩展和微调，无需重新训练整个网络。为克服 k-最近邻方法的高计算负载，提出使用基于 Kohonen 自组织映射的类树数据结构，从而大大加快了最近邻搜索。

Result: 在手写数字识别和简单字幕翻译任务上进行的测试证实了该方法的有效性。在准确性略有下降的情况下，与穷举搜索方法相比，最近邻搜索时间减少了几百倍。

Conclusion: 所提出的方法具有透明度和可解释性，与人类认知机制高度一致，并显示出在需要高可靠性和可解释结果的任务中广泛应用的潜力。

Abstract: Modern neural network technologies, including large language models, have
achieved remarkable success in various applied artificial intelligence
applications, however, they face a range of fundamental limitations. Among them
are hallucination effects, high computational complexity of training and
inference, costly fine-tuning, and catastrophic forgetting issues. These
limitations significantly hinder the use of neural networks in critical areas
such as medicine, industrial process management, and scientific research. This
article proposes an alternative approach based on the nearest neighbors method
with hierarchical clustering structures. Employing the k-nearest neighbors
algorithm significantly reduces or completely eliminates hallucination effects
while simplifying model expansion and fine-tuning without the need for
retraining the entire network. To overcome the high computational load of the
k-nearest neighbors method, the paper proposes using tree-like data structures
based on Kohonen self-organizing maps, thereby greatly accelerating nearest
neighbor searches. Tests conducted on handwritten digit recognition and simple
subtitle translation tasks confirmed the effectiveness of the proposed
approach. With only a slight reduction in accuracy, the nearest neighbor search
time was reduced hundreds of times compared to exhaustive search methods. The
proposed method features transparency and interpretability, closely aligns with
human cognitive mechanisms, and demonstrates potential for extensive use in
tasks requiring high reliability and explainable results.

</details>


### [190] [Enabling MoE on the Edge via Importance-Driven Expert Scheduling](https://arxiv.org/abs/2508.18983)
*Guoying Zhu,Meng Li,Haipeng Dai,Xuechen Liu,Weijun Wang,Keran Li,Jun xiao,Ligeng Chen,Wei Wang*

Main category: cs.AI

TL;DR: 通过利用专家重要性指导决策，用GPU缓存中功能相似的专家替换低重要性激活专家，减少了内存使用和PCIe开销，从而在保持高准确率的同时降低了解码延迟。


<details>
  <summary>Details</summary>
Motivation: 在消费级边缘硬件上部署MoE模型面临内存限制，需要动态专家卸载。

Method: 提出了一种基于专家重要性的卸载方法，用缓存中的专家替换低重要性激活专家，并结合最大化GPU缓存专家重用率的调度策略。

Result: 实现了48%的解码延迟降低和超过60%的专家缓存命中率，同时保持了接近无损的准确率。

Conclusion: 该方法通过基于专家重要性的卸载和优化的调度策略，有效解决了在边缘设备上部署MoE模型的内存限制问题，显著提高了效率和性能。

Abstract: The Mixture of Experts (MoE) architecture has emerged as a key technique for
scaling Large Language Models by activating only a subset of experts per query.
Deploying MoE on consumer-grade edge hardware, however, is constrained by
limited device memory, making dynamic expert offloading essential. Unlike prior
work that treats offloading purely as a scheduling problem, we leverage expert
importance to guide decisions, substituting low-importance activated experts
with functionally similar ones already cached in GPU memory, thereby preserving
accuracy. As a result, this design reduces memory usage and data transfer,
while largely eliminating PCIe overhead. In addition, we introduce a scheduling
policy that maximizes the reuse ratio of GPU-cached experts, further boosting
efficiency. Extensive evaluations show that our approach delivers 48% lower
decoding latency with over 60% expert cache hit rate, while maintaining nearly
lossless accuracy.

</details>


### [191] [AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms](https://arxiv.org/abs/2508.19004)
*Pontus Strimling,Simon Karlsson,Irina Vartanova,Kimmo Eriksson*

Main category: cs.AI

TL;DR: 大型语言模型可以通过纯粹的统计学习来理解社会规范，甚至在预测人类社会适当性判断方面超越了大多数人。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨大型语言模型（LLM）是否能够仅通过统计学习来获得和表示社会规范，尽管人类通常通过具身社会经验来学习规范。

Method: 本研究通过两项研究，系统地评估了多个AI系统在预测人类社会适当性判断方面的能力。研究者们考察了AI系统预测555个日常场景的平均人类判断的准确性，并与每位人类参与者的判断进行了比较。

Result: 在Study 1中，GPT-4.5在预测集体判断方面的准确性超过了所有人类参与者（处于第100百分位）。在Study 2中，Gemini 2.5 Pro的表现优于98.7%的人类，GPT-5优于97.8%，Claude Sonnet 4优于96.0%。尽管LLM具有很强的预测能力，但所有模型都表现出系统性、相关性的错误。

Conclusion: 研究结果表明，复杂的社会认知模型可以仅从语言数据中通过统计学习产生，这挑战了那些强调具身经验对文化能力具有排他性必要性的理论。AI局限性的系统性表明了基于模式的社会理解可能存在边界，而模型在预测任务中超越几乎所有个体人类的能力表明，语言是文化知识传递的极其丰富的载体。

Abstract: A fundamental question in cognitive science concerns how social norms are
acquired and represented. While humans typically learn norms through embodied
social experience, we investigated whether large language models can achieve
sophisticated norm understanding through statistical learning alone. Across two
studies, we systematically evaluated multiple AI systems' ability to predict
human social appropriateness judgments for 555 everyday scenarios by examining
how closely they predicted the average judgment compared to each human
participant. In Study 1, GPT-4.5's accuracy in predicting the collective
judgment on a continuous scale exceeded that of every human participant (100th
percentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7%
of humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive
power, all models showed systematic, correlated errors. These findings
demonstrate that sophisticated models of social cognition can emerge from
statistical learning over linguistic data alone, challenging strong versions of
theories emphasizing the exclusive necessity of embodied experience for
cultural competence. The systematic nature of AI limitations across different
architectures indicates potential boundaries of pattern-based social
understanding, while the models' ability to outperform nearly all individual
humans in this predictive task suggests that language serves as a remarkably
rich repository for cultural knowledge transmission.

</details>


### [192] [Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark](https://arxiv.org/abs/2508.19005)
*Yuxuan Cai,Yipeng Hao,Jie Zhou,Hang Yan,Zhikai Lei,Rui Zhen,Zhenhua Han,Yutao Yang,Junsong Li,Qianjun Pan,Tianyu Huai,Qin Chen,Xin Li,Kai Chen,Bo Zhang,Xipeng Qiu,Liang He*

Main category: cs.AI

TL;DR: 本文提出了经验驱动的终身学习（ELL）框架，用于构建能够通过现实世界互动持续成长的自进化智能体。该框架基于经验探索、长期记忆、技能学习和知识内化四个核心原则。同时，本文还引入了StuLife基准数据集，模拟了学生在大学期间的全面发展，用于评估ELL能力。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能向通用智能迈进，研究重点正从针对静态任务进行优化的系统转向创建能够持续学习的开放式智能体。

Method: 本文提出了一种名为经验驱动的终身学习（ELL）的框架，该框架包含四个核心原则：经验探索、长期记忆、技能学习和知识内化。此外，还引入了一个名为StuLife的基准数据集，模拟了学生在大学期间的成长历程，用于评估ELL能力。

Result: 通过ELL框架和StuLife数据集，可以评估智能体的终身学习能力，包括记忆保持、技能迁移和自我驱动行为。此外，研究还探讨了上下文工程在推进AGI中的作用。

Conclusion: ELL框架和StuLife数据集为构建和评估能够持续学习和成长的自进化智能体提供了一个有前景的方向，并为人工智能的进一步发展提供了新的视角。

Abstract: As AI advances toward general intelligence, the focus is shifting from
systems optimized for static tasks to creating open-ended agents that learn
continuously. In this paper, we introduce Experience-driven Lifelong Learning
(ELL), a framework for building self-evolving agents capable of continuous
growth through real-world interaction. The framework is built on four core
principles: (1) Experience Exploration: Agents learn through continuous,
self-motivated interaction with dynamic environments, navigating interdependent
tasks and generating rich experiential trajectories. (2) Long-term Memory:
Agents preserve and structure historical knowledge, including personal
experiences, domain expertise, and commonsense reasoning, into a persistent
memory system. (3) Skill Learning: Agents autonomously improve by abstracting
recurring patterns from experience into reusable skills, which are actively
refined and validated for application in new tasks. (4) Knowledge
Internalization: Agents internalize explicit and discrete experiences into
implicit and intuitive capabilities as "second nature".
  We also introduce StuLife, a benchmark dataset for ELL that simulates a
student's holistic college journey, from enrollment to academic and personal
development, across three core phases and ten detailed sub-scenarios. StuLife
is designed around three key paradigm shifts: From Passive to Proactive, From
Context to Memory, and From Imitation to Learning. In this dynamic environment,
agents must acquire and distill practical skills and maintain persistent memory
to make decisions based on evolving state variables. StuLife provides a
comprehensive platform for evaluating lifelong learning capabilities, including
memory retention, skill transfer, and self-motivated behavior. Beyond
evaluating SOTA LLMs on the StuLife benchmark, we also explore the role of
context engineering in advancing AGI.

</details>


### [193] [Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI](https://arxiv.org/abs/2508.19008)
*Marcin Moskalewicz,Anna Sterna,Marek Pokropski,Paula Flores*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLM）在边界性人格障碍（BPD）患者第一人称体验的现象学定性分析中的支持能力，其中BPD被理解为一种时间性和自我性的障碍。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是评估大型语言模型（LLM）在支持边界性人格障碍（BPD）患者第一人称体验的现象学定性分析方面的能力，并将BPD理解为一种时间性和自我性的障碍。

Method: 研究人员首先对24名住院患者的生命故事访谈进行了人类主导的主题分析，然后比较了三种大型语言模型（OpenAI GPT-4o、Google Gemini 2.5 Pro、Anthropic Claude Opus 4）在模仿原始研究者解释风格方面的表现。通过对语义一致性、Jaccard系数和多维度有效性评级（可信度、连贯性、实质性和数据基础性）的评估，由熟悉现象学和临床心理学的专家进行了盲审和非盲审。

Result: 研究结果显示，LLM与人类分析的重叠程度不一，GPT为0%，Claude为42%，Gemini为58%，Jaccard系数较低（0.21-0.28）。然而，LLM也能够发现人类分析所遗漏的主题。Gemini的输出与人类分析最为接近，其有效性得分显著高于GPT和Claude（p < 0.0001），并且被盲审专家判断为人类输出。所有评分均与文本量和每个主题的词数高度相关（R > 0.78），这突显了AI增强的与主题分析相结合以减轻人类解释偏见的潜力和变异性。

Conclusion: 本研究表明，尽管大型语言模型在支持边界性人格障碍患者的第一人称体验的现象学定性分析方面存在变异性，但Gemini等模型展现出潜力，其输出在有效性上接近人类分析，并且能够发现人类分析所遗漏的主题，这预示着AI在减轻人类解释偏见方面的应用前景。

Abstract: This study examines the capacity of large language models (LLMs) to support
phenomenological qualitative analysis of first-person experience in Borderline
Personality Disorder (BPD), understood as a disorder of temporality and
selfhood. Building on a prior human-led thematic analysis of 24 inpatients'
life-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5
Pro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the
original investigators. The models were evaluated with blinded and non-blinded
expert judges in phenomenology and clinical psychology. Assessments included
semantic congruence, Jaccard coefficients, and multidimensional validity
ratings (credibility, coherence, substantiveness, and groundness in data).
Results showed variable overlap with the human analysis, from 0 percent in GPT
to 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient
(0.21-0.28). However, the models recovered themes omitted by humans. Gemini's
output most closely resembled the human analysis, with validity scores
significantly higher than GPT and Claude (p < 0.0001), and was judged as human
by blinded experts. All scores strongly correlated (R > 0.78) with the quantity
of text and words per theme, highlighting both the variability and potential of
AI-augmented thematic analysis to mitigate human interpretative bias.

</details>


### [194] [MAB Optimizer for Estimating Math Question Difficulty via Inverse CV without NLP](https://arxiv.org/abs/2508.19014)
*Surajit Das,Gourav Roy,Aleksei Eliseev,Ram Kumar Rajendran*

Main category: cs.AI

TL;DR: APME，一种基于强化学习的MAB框架，仅使用求解器表现数据（分数和时间）来估计问题难度，无需语言特征或专家标签，在符号域（如代数）中表现优于传统方法和基于NLP的方法。


<details>
  <summary>Details</summary>
Motivation: 需要客观、领域无关的方法来确定问题难度，以应对智能与自主辅导系统（IATS）的发展，克服传统人工标注的主观性和现有NLP方法在符号域的局限性。

Method: 提出了一种名为APME（Approach of Passive Measures among Educands）的框架，该框架基于强化学习的多臂老虎机（MAB）模型，仅利用求解器的表现数据（分数和时间）来估计问题难度。该方法使用逆变异系数作为风险调整指标。

Result: 在三个异构数据集上的实证验证显示，APME的平均R2为0.9213，平均RMSE为0.0584，证明了其稳健性、准确性和适应性。与基于回归、NLP驱动和IRT模型等基线方法相比，APME表现更优，尤其是在纯符号域。

Conclusion: APME是一种领域无关、自监督的方法，能够有效提升IATS中的难度标记能力。研究发现，题目的异质性和求解器结果的方差与平均表现同样关键，对自适应分配至关重要。该模型符合维果茨基的最近发展区理论，能在挑战性和可达到性之间取得平衡，有助于提高学习者的积极性。该方法可以扩展到代数以外的领域，只要有求解器交互数据可用。

Abstract: The evolution of technology and education is driving the emergence of
Intelligent & Autonomous Tutoring Systems (IATS), where objective and
domain-agnostic methods for determining question difficulty are essential.
Traditional human labeling is subjective, and existing NLP-based approaches
fail in symbolic domains like algebra. This study introduces the Approach of
Passive Measures among Educands (APME), a reinforcement learning-based
Multi-Armed Bandit (MAB) framework that estimates difficulty solely from solver
performance data -- marks obtained and time taken -- without requiring
linguistic features or expert labels. By leveraging the inverse coefficient of
variation as a risk-adjusted metric, the model provides an explainable and
scalable mechanism for adaptive assessment. Empirical validation was conducted
on three heterogeneous datasets. Across these diverse contexts, the model
achieved an average R2 of 0.9213 and an average RMSE of 0.0584, confirming its
robustness, accuracy, and adaptability to different educational levels and
assessment formats. Compared with baseline approaches-such as regression-based,
NLP-driven, and IRT models-the proposed framework consistently outperformed
alternatives, particularly in purely symbolic domains. The findings highlight
that (i) item heterogeneity strongly influences perceived difficulty, and (ii)
variance in solver outcomes is as critical as mean performance for adaptive
allocation. Pedagogically, the model aligns with Vygotskys Zone of Proximal
Development by identifying tasks that balance challenge and attainability,
supporting motivation while minimizing disengagement. This domain-agnostic,
self-supervised approach advances difficulty tagging in IATS and can be
extended beyond algebra wherever solver interaction data is available

</details>


### [195] [Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction](https://arxiv.org/abs/2508.19035)
*Congchi Yin,Tianyi Wu,Yankai Shu,Alex Gu,Yunhan Wang,Jun Shao,Xun Jiang,Piji Li*

Main category: cs.AI

TL;DR: LLMs在评估互动式、未知环境中推理能力方面存在不足，现有任务侧重单一推理类型。为此，我们提出“黑盒交互”评估范式，通过与未知函数交互并推理，来评估LLMs的综合推理能力。我们构建了包含6种黑盒任务和96个黑盒的“Oracle”基准，并对19种主流LLMs进行了测试。结果显示，o3在大部分任务上表现优异，但在部分困难任务上准确率较低。进一步分析发现，LLMs普遍缺乏制定有效、自适应探索策略以优化假设的能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM推理能力的任务无法涵盖真实世界中不可或缺的、整合了演绎、归纳和溯因推理的互动式探索过程。

Method: 提出“黑盒交互”评估范式，LLMs需要通过与黑盒（隐藏特定输入输出映射函数）进行交互，并在给定的探索轮次中收集信息，然后基于观察到的输入输出对进行推理，以揭示黑盒背后的隐藏函数。

Result: 在“Oracle”基准测试中，19种主流LLMs的表现各异。o3在6项任务中的5项中排名第一，在大多数简单的黑盒任务上准确率超过70%，但在一些困难的黑盒任务上，其平均准确率下降至40%以下。

Conclusion: LLMs在处理需要高层次规划能力的推理任务时存在普遍困难，尤其是在为优化假设而制定高效、自适应探索策略方面。

Abstract: Existing tasks fall short in evaluating reasoning ability of Large Language
Models (LLMs) in an interactive, unknown environment. This deficiency leads to
the isolated assessment of deductive, inductive, and abductive reasoning,
neglecting the integrated reasoning process that is indispensable for humans
discovery of real world. We introduce a novel evaluation paradigm,
\textit{black-box interaction}, to tackle this challenge. A black-box is
defined by a hidden function that maps a specific set of inputs to outputs.
LLMs are required to unravel the hidden function behind the black-box by
interacting with it in given exploration turns, and reasoning over observed
input-output pairs. Leveraging this idea, we build the \textsc{Oracle}
benchmark which comprises 6 types of black-box task and 96 black-boxes. 19
modern LLMs are benchmarked. o3 ranks first in 5 of the 6 tasks, achieving over
70\% accuracy on most easy black-boxes. But it still struggles with some hard
black-box tasks, where its average performance drops below 40\%. Further
analysis indicates a universal difficulty among LLMs: They lack the high-level
planning capability to develop efficient and adaptive exploration strategies
for hypothesis refinement.

</details>


### [196] [A Concurrent Modular Agent: Framework for Autonomous LLM Agents](https://arxiv.org/abs/2508.19042)
*Norihiro Maruyama,Takahide Yoshida,Hiroki Sato,Atsushi Masumori,Johnsmith,Takashi Ikegami*

Main category: cs.AI

TL;DR: 并发模块化代理（CMA）框架使用异步LLM模块实现灵活、自适应的代理行为。


<details>
  <summary>Details</summary>
Motivation: 解决传统代理架构中固有的难题，让意图从自主进程的语言中介交互中涌现。

Method: 通过组合并发执行的模块、将推理卸载到LLM、模块间通信和单一共享全局状态来实现。

Result: 通过两个实际用例研究证明了系统的可行性，观察到的涌现特性支持了‘心智社会’概念。

Conclusion: CMA的涌现特性表明，复杂的认知现象（如自我意识）可能源于简单进程的组织化交互，为人工智能研究开辟了新途径。

Abstract: We introduce the Concurrent Modular Agent (CMA), a framework that
orchestrates multiple Large-Language-Model (LLM)-based modules that operate
fully asynchronously yet maintain a coherent and fault-tolerant behavioral
loop. This framework addresses long-standing difficulties in agent
architectures by letting intention emerge from language-mediated interactions
among autonomous processes. This approach enables flexible, adaptive, and
context-dependent behavior through the combination of concurrently executed
modules that offload reasoning to an LLM, inter-module communication, and a
single shared global state.We consider this approach to be a practical
realization of Minsky's Society of Mind theory. We demonstrate the viability of
our system through two practical use-case studies. The emergent properties
observed in our system suggest that complex cognitive phenomena like
self-awareness may indeed arise from the organized interaction of simpler
processes, supporting Minsky-Society of Mind concept and opening new avenues
for artificial intelligence research. The source code for our work is available
at: https://github.com/AlternativeMachine/concurrent-modular-agent.

</details>


### [197] [Can Structured Templates Facilitate LLMs in Tackling Harder Tasks? : An Exploration of Scaling Laws by Difficulty](https://arxiv.org/abs/2508.19069)
*Zhichao Yang,Zhaoxin Fan,Gen Li,Yuanze Hu,Xinyu Wang,Ye Qiu,Xin Wang,Yifan Sun,Wenjun Wu*

Main category: cs.AI

TL;DR: 该论文提出了一种名为结构化解决方案模板（SST）的框架，通过结构化解决方案模板和不同难度的课程来教授LLM进行程序化推理，特别是在数学领域。研究发现，模型性能与训练数据复杂度之间存在一种“难度缩放定律”，呈U形曲线关系。SST通过微调、提示时注入解决方案模板以及集成课程微调来提高LLM的准确性和效率，尤其是在处理复杂问题时。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在数学等需要结构化、程序化推理的任务上表现仍有不足，尤其是在捕捉深层程序逻辑方面。该研究旨在解决这一局限性。

Method: 1. 提出“难度缩放定律”，发现模型性能与训练数据复杂度呈U形曲线关系，过多的低难度数据会阻碍抽象，而高难度数据能显著增强推理能力。 2. 提出结构化解决方案模板（SST）框架，包含：a) 使用结构化解决方案模板链和动态加权损失进行微调，以优先处理程序逻辑；b) 在提示时注入解决方案模板作为认知支架以指导推理；c) 集成课程微调，教授模型进行自我规划-执行-修正。

Result: 在GSM8K、AIME24和新的Dynamic En基准测试上，SST显著提高了LLM在数学问题上的准确性和效率，尤其是在处理更难的问题时。

Conclusion: SST框架通过明确教授程序化推理，有效提升了LLM在复杂数学推理任务上的性能。

Abstract: Structured, procedural reasoning is essential for Large Language Models
(LLMs), especially in mathematics. While post-training methods have improved
LLM performance, they still fall short in capturing deep procedural logic on
complex tasks. To tackle the issue, in this paper, we first investigate this
limitation and uncover a novel finding: a Scaling Law by Difficulty, which
reveals that model performance follows a U-shaped curve with respect to
training data complexity -- excessive low-difficulty data impedes abstraction,
while high-difficulty data significantly enhances reasoning ability. Motivated
by this, we propose the Structured Solution Template (SST) framework, which
uses solution templates and a curriculum of varied difficulty to explicitly
teach procedural reasoning. Specifically, SST comprises (1) fine-tuning with
structured solution-template chains and dynamically weighted loss to prioritize
procedural logic, (2) prompt-time injection of solution templates as cognitive
scaffolds to guide inference, and (3) integrated curriculum fine-tuning that
explicitly teaches the model to self-plan - execute - self-correct. Experiments
on GSM8K, AIME24, and new Dynamic En benchmark show that SST significantly
improves both accuracy and efficiency, especially on harder problems.

</details>


### [198] [Trustworthy Agents for Electronic Health Records through Confidence Estimation](https://arxiv.org/abs/2508.19096)
*Yongwoo Song,Minbyul Jeong,Mujeen Sung*

Main category: cs.AI

TL;DR: LLMs在电子健康记录（EHR）信息提取和临床决策支持方面潜力巨大，但幻觉风险阻碍了临床应用。本文提出了一种衡量准确性-可靠性权衡的新指标HCAcc@k%，并引入了考虑步骤置信度估计的临床问答智能体TrustEHRAgent。实验表明，TrustEHRAgent在严格的可靠性约束下优于基线方法，尤其是在HCAcc@70%下提高了44.23%p和25.34%p，而基线方法在此阈值下表现不佳。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗领域的应用受到幻觉风险的限制，需要新的评估指标和更可靠的智能体。

Method: 提出HCAcc@k%指标量化准确性-可靠性权衡，并开发了具有步骤置信度估计的TrustEHRAgent。

Result: TrustEHRAgent在MIMIC-III和eICU数据集上，在HCAcc@70%的严格可靠性约束下，相比基线方法分别提高了44.23%p和25.34%p，证明了其在提高准确性和可靠性方面的优越性。

Conclusion: 传统的准确性指标无法满足医疗AI评估需求。本文提出的HCAcc@k%指标和TrustEHRAgent为开发值得信赖的临床智能体提供了新的方法，这些智能体能够提供准确信息或在低置信度时透明地表达不确定性。

Abstract: Large language models (LLMs) show promise for extracting information from
Electronic Health Records (EHR) and supporting clinical decisions. However,
deployment in clinical settings faces challenges due to hallucination risks. We
propose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric
quantifying the accuracy-reliability trade-off at varying confidence
thresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating
stepwise confidence estimation for clinical question answering. Experiments on
MIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under
strict reliability constraints, achieving improvements of 44.23%p and 25.34%p
at HCAcc@70% while baseline methods fail at these thresholds. These results
highlight limitations of traditional accuracy metrics in evaluating healthcare
AI agents. Our work contributes to developing trustworthy clinical agents that
deliver accurate information or transparently express uncertainty when
confidence is low.

</details>


### [199] [Reasoning LLMs in the Medical Domain: A Literature Survey](https://arxiv.org/abs/2508.19097)
*Armin Berger,Sarthak Khanna,David Berghaus,Rafet Sifa*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在医疗保健领域的应用正从基本信息检索工具转变为能够支持复杂临床决策的先进临床推理系统。


<details>
  <summary>Details</summary>
Motivation: LLMs的推理能力增强了医疗决策的透明度和可解释性，这在医疗环境中至关重要。

Method: 本文调查了支撑医疗LLM发展的技术基础，重点关注如链式思考（Chain-of-Thought）等专门的提示技术，以及以DeepSeek-R1为代表的强化学习最新进展。此外，还评估了专门的医疗框架、多智能体协作系统和新颖的提示架构。

Result: 评估了现有的医疗验证评估方法，并探讨了领域解释局限性、偏见缓解策略、患者安全框架以及多模态临床数据整合等方面的挑战。

Conclusion: 旨在为开发可靠的LLMs建立路线图，使其能够成为临床实践和医学研究中有效的合作伙伴。

Abstract: The emergence of advanced reasoning capabilities in Large Language Models
(LLMs) marks a transformative development in healthcare applications. Beyond
merely expanding functional capabilities, these reasoning mechanisms enhance
decision transparency and explainability-critical requirements in medical
contexts. This survey examines the transformation of medical LLMs from basic
information retrieval tools to sophisticated clinical reasoning systems capable
of supporting complex healthcare decisions. We provide a thorough analysis of
the enabling technological foundations, with a particular focus on specialized
prompting techniques like Chain-of-Thought and recent breakthroughs in
Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates
purpose-built medical frameworks while also examining emerging paradigms such
as multi-agent collaborative systems and innovative prompting architectures.
The survey critically assesses current evaluation methodologies for medical
validation and addresses persistent challenges in field interpretation
limitations, bias mitigation strategies, patient safety frameworks, and
integration of multimodal clinical data. Through this survey, we seek to
establish a roadmap for developing reliable LLMs that can serve as effective
partners in clinical practice and medical research.

</details>


### [200] [Hybrid Deep Searcher: Integrating Parallel and Sequential Search Reasoning](https://arxiv.org/abs/2508.19113)
*Dayoon Ko,Jihyuk Kim,Haeju Park,Sohyeon Kim,Dahyun Lee,Yongrae Jo,Gunhee Kim,Moontae Lee,Kyungjae Lee*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large reasoning models (LRMs) have demonstrated strong performance in
complex, multi-step reasoning tasks. Existing methods enhance LRMs by
sequentially integrating external knowledge retrieval; models iteratively
generate queries, retrieve external information, and progressively reason over
this information. However, purely sequential querying increases inference
latency and context length, diminishing coherence and potentially reducing
accuracy. To address these limitations, we introduce HDS-QA (Hybrid Deep Search
QA), a synthetic dataset automatically generated from Natural Questions,
explicitly designed to train LRMs to distinguish parallelizable from sequential
queries. HDS-QA comprises hybrid-hop questions that combine parallelizable
independent subqueries (executable simultaneously) and sequentially dependent
subqueries (requiring step-by-step resolution), along with synthetic
reasoning-querying-retrieval paths involving parallel queries. We fine-tune an
LRM using HDS-QA, naming the model HybridDeepSearcher, which outperforms
state-of-the-art baselines across multiple benchmarks, notably achieving +15.9
and +11.5 F1 on FanOutQA and a subset of BrowseComp, respectively, both
requiring comprehensive and exhaustive search. Experimental results highlight
two key advantages: HybridDeepSearcher reaches comparable accuracy with fewer
search turns, significantly reducing inference latency, and it effectively
scales as more turns are permitted. These results demonstrate the efficiency,
scalability, and effectiveness of explicitly training LRMs to leverage hybrid
parallel and sequential querying.

</details>


### [201] [Algorithmic Collective Action with Multiple Collectives](https://arxiv.org/abs/2508.19149)
*Claudio Battiloro,Pietro Greiner,Bret Nestor,Oumaima Amezgar,Francesca Dominici*

Main category: cs.AI

TL;DR: 该研究提出了一个多群体算法集体行动（ACA）的理论框架，用于用户端的系统数据操纵，以影响机器学习分类器。研究了不同群体规模和目标对分类器学习的影响，并提供了量化结果。


<details>
  <summary>Details</summary>
Motivation: 现有的ACA研究主要集中在单一群体，忽略了现实世界中多个具有共同目标但策略和规模各异的群体协同作用的复杂性。本研究旨在填补这一空白，为多群体ACA提供理论基础。

Method: 提出一个多群体ACA的理论框架，专门研究在分类任务中，多个群体如何通过“植入信号”（即操纵数据以使分类器学习特定特征与目标类别的关联）来影响分类器。分析了群体规模和目标一致性对分类结果的量化影响。

Result: 研究结果量化了不同群体规模和目标对ACA效果的相互作用。框架也补充了先前的实证结果，为全面研究多群体ACA铺平了道路。

Conclusion: 本研究提出了首个针对多群体ACA的理论框架，为理解和协调多个群体如何通过操纵共享数据来影响机器学习系统提供了新的视角和量化分析方法，并为未来的ACA研究开辟了方向。

Abstract: As learning systems increasingly influence everyday decisions, user-side
steering via Algorithmic Collective Action (ACA)-coordinated changes to shared
data-offers a complement to regulator-side policy and firm-side model design.
Although real-world actions have been traditionally decentralized and
fragmented into multiple collectives despite sharing overarching
objectives-with each collective differing in size, strategy, and actionable
goals, most of the ACA literature focused on single collective settings. In
this work, we present the first theoretical framework for ACA with multiple
collectives acting on the same system. In particular, we focus on collective
action in classification, studying how multiple collectives can plant signals,
i.e., bias a classifier to learn an association between an altered version of
the features and a chosen, possibly overlapping, set of target classes. We
provide quantitative results about the role and the interplay of collectives'
sizes and their alignment of goals. Our framework, by also complementing
previous empirical results, opens a path for a holistic treatment of ACA with
multiple collectives.

</details>


### [202] [The Ramon Llull's Thinking Machine for Automated Ideation](https://arxiv.org/abs/2508.19200)
*Xinran Zhao,Boyuan Zheng,Chenglei Si,Haofei Yu,Ken Liu,Runlong Zhou,Ruochen Li,Tong Chen,Xiang Li,Yiming Zhang,Tongshuang Wu*

Main category: cs.AI

TL;DR: 本研究旨在利用 Ramon Llull 的 Ars combinatoria 为基础，构建一个现代化的、由语言模型驱动的、用于研究构思的“Llull 思考机”。


<details>
  <summary>Details</summary>
Motivation: 借鉴中世纪的 Ars combinatoria 框架，探索其在现代知识生成和研究构思中的应用潜力，并提出一种增强科学创造力的方法。

Method: 定义了三个构成维度：主题（如效率、适应性）、领域（如问答、机器翻译）和方法（如对抗训练、线性注意力）。通过从人类专家或会议论文中挖掘这些元素，并以精心设计的组合形式提示语言模型，来生成研究构想。

Result: 实验表明，通过这种方式生成的潜在研究构想具有多样性、相关性，并且能够基于现有文献，证明了该方法的有效性。

Conclusion: 提出了一种轻量级、可解释的工具，用于增强科学创造力，并为实现人与人工智能的协作构思提供了新的途径。

Abstract: This paper revisits Ramon Llull's Ars combinatoria - a medieval framework for
generating knowledge through symbolic recombination - as a conceptual
foundation for building a modern Llull's thinking machine for research
ideation. Our approach defines three compositional axes: Theme (e.g.,
efficiency, adaptivity), Domain (e.g., question answering, machine
translation), and Method (e.g., adversarial training, linear attention). These
elements represent high-level abstractions common in scientific work -
motivations, problem settings, and technical approaches - and serve as building
blocks for LLM-driven exploration. We mine elements from human experts or
conference papers and show that prompting LLMs with curated combinations
produces research ideas that are diverse, relevant, and grounded in current
literature. This modern thinking machine offers a lightweight, interpretable
tool for augmenting scientific creativity and suggests a path toward
collaborative ideation between humans and AI.

</details>


### [203] [The Subset Sum Matching Problem](https://arxiv.org/abs/2508.19218)
*Yufei Wu,Manuel R. Torres,Parisa Zehtabi,Alberto Pozanco Lancho,Michael Cashmore,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 该论文介绍了一种新的组合优化任务，称为子集和匹配问题（SSMP），该问题是诸如交易对账等常见金融应用的抽象。


<details>
  <summary>Details</summary>
Motivation: 提出子集和匹配问题（SSMP），将其作为金融应用（如交易对账）的抽象，以解决实际问题。

Method: 提出三种算法（两种次优算法和一种最优算法）来解决SSMP，并生成一个基准数据集来覆盖不同复杂度的SSMP实例。

Result: 通过实验评估了所提出算法的性能。

Conclusion: 对SSMP问题及其解决方案进行了分析和评估。

Abstract: This paper presents a new combinatorial optimisation task, the Subset Sum
Matching Problem (SSMP), which is an abstraction of common financial
applications such as trades reconciliation. We present three algorithms, two
suboptimal and one optimal, to solve this problem. We also generate a benchmark
to cover different instances of SSMP varying in complexity, and carry out an
experimental evaluation to assess the performance of the approaches.

</details>


### [204] [StepWiser: Stepwise Generative Judges for Wiser Reasoning](https://arxiv.org/abs/2508.19229)
*Wei Xiong,Wenting Zhao,Weizhe Yuan,Olga Golovneva,Tong Zhang,Jason Weston,Sainbayar Sukhbaatar*

Main category: cs.AI

TL;DR: 该研究提出了一种名为StepWiser的生成式判断模型，用于评估多步推理的逻辑有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的处理方法作为分类器，缺乏解释性，并且依赖于静态数据集，泛化能力有限。本研究旨在解决这些问题，将逐步奖励建模从分类任务重新定义为推理任务。

Method: StepWiser模型通过生成思考过程来判断推理步骤的有效性，并利用强化学习和相对结果进行训练。

Result: 实验证明，StepWiser在中间步骤的判断准确性优于现有方法，并能在训练时改进策略模型，同时提升推理时的搜索效率。

Conclusion: StepWiser模型通过其生成式判断和强化学习训练方法，有效解决了现有逐步奖励建模方法的局限性，并在多个方面展现出优越性能。

Abstract: As models increasingly leverage multi-step reasoning strategies to solve
complex problems, supervising the logical validity of these intermediate steps
has become a critical research challenge. Process reward models address this by
providing step-by-step feedback, but current approaches have two major
drawbacks: they typically function as classifiers without providing
explanations, and their reliance on supervised fine-tuning with static datasets
limits generalization. Inspired by recent advances, we reframe stepwise reward
modeling from a classification task to a reasoning task itself. We thus propose
a generative judge that reasons about the policy model's reasoning steps (i.e.,
meta-reasons), outputting thinking tokens before delivering a final verdict.
Our model, StepWiser, is trained by reinforcement learning using relative
outcomes of rollouts. We show it provides (i) better judgment accuracy on
intermediate steps than existing methods; (ii) can be used to improve the
policy model at training time; and (iii) improves inference-time search.

</details>


### [205] [Model Context Protocols in Adaptive Transport Systems: A Survey](https://arxiv.org/abs/2508.19239)
*Gaurab Chhetri,Shriyank Somvanshi,Md Monzurul Islam,Shamyo Brotee,Mahmuda Sultana Mimi,Dipti Koirala,Biplov Pandey,Subasish Das*

Main category: cs.AI

TL;DR: MCP是一种统一的自适应传输系统范式，可解决当今的碎片化问题，并为未来的智能交通基础设施奠定基础。


<details>
  <summary>Details</summary>
Motivation: 解决当前互联设备、自主系统和人工智能应用中自适应传输系统面临的严重碎片化问题，这些问题源于各种协议和上下文源的孤立状态。

Method: 对现有文献进行系统性调查，分析模型上下文协议（MCP）作为统一范式的能力，重点关注其连接协议级自适应与上下文感知决策的能力。提出一个涵盖自适应机制、上下文感知框架、统一模型、集成策略和MCP赋能架构的五类分类法。

Result: 研究表明，现有工作已在概念上趋同于 MCP 架构；传统的传输协议在孤立自适应方面已达到极限；MCP 的客户端-服务器和 JSON-RPC 结构支持语义互操作性；人工智能驱动的传输需要特别适合 MCP 的集成范式。

Conclusion: MCP 是实现下一代自适应、上下文感知和智能传输基础设施的关键，为解决碎片化问题和支持人工智能驱动的传输提供了统一的解决方案。

Abstract: The rapid expansion of interconnected devices, autonomous systems, and AI
applications has created severe fragmentation in adaptive transport systems,
where diverse protocols and context sources remain isolated. This survey
provides the first systematic investigation of the Model Context Protocol (MCP)
as a unifying paradigm, highlighting its ability to bridge protocol-level
adaptation with context-aware decision making. Analyzing established
literature, we show that existing efforts have implicitly converged toward
MCP-like architectures, signaling a natural evolution from fragmented solutions
to standardized integration frameworks. We propose a five-category taxonomy
covering adaptive mechanisms, context-aware frameworks, unification models,
integration strategies, and MCP-enabled architectures. Our findings reveal
three key insights: traditional transport protocols have reached the limits of
isolated adaptation, MCP's client-server and JSON-RPC structure enables
semantic interoperability, and AI-driven transport demands integration
paradigms uniquely suited to MCP. Finally, we present a research roadmap
positioning MCP as a foundation for next-generation adaptive, context-aware,
and intelligent transport infrastructures.

</details>


### [206] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent是一个利用LLM处理复杂企业决策的新型多智能体框架，通过CTMDP、广义熵和多层Stackelberg博弈来优化协作和层级决策，并使用Thompson采样优化提示。实验证明BusiAgent能有效整合细节与战略，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以整合运营分析与战略目标，导致工作流程碎片化和跨层级协作不畅。

Method: 提出BusiAgent框架，包含CTMDP动态建模、广义熵优化协作效率、多层Stackelberg博弈处理层级决策、Thompson采样优化提示和质量保证系统。

Result: BusiAgent能生成连贯、以客户为中心的解决方案，有效整合细节洞察与高层战略，在解决方案质量和用户满意度方面显著优于现有方法。

Conclusion: BusiAgent是AI驱动的企业决策领域的重大进步，通过融合AI技术和商业洞察，帮助组织更有效地应对复杂的商业环境。

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [207] [Facilitating Matches on Allocation Platforms](https://arxiv.org/abs/2508.18325)
*Yohai Trabelsi,Abhijin Adiga,Yonatan Aumann,Sarit Kraus,S. S. Ravi*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider a setting where goods are allocated to agents by way of an
allocation platform (e.g., a matching platform). An ``allocation facilitator''
aims to increase the overall utility/social-good of the allocation by
encouraging (some of the) agents to relax (some of) their restrictions. At the
same time, the advice must not hurt agents who would otherwise be better off.
Additionally, the facilitator may be constrained by a ``bound'' (a.k.a.
`budget'), limiting the number and/or type of restrictions it may seek to
relax. We consider the facilitator's optimization problem of choosing an
optimal set of restrictions to request to relax under the aforementioned
constraints. Our contributions are three-fold: (i) We provide a formal
definition of the problem, including the participation guarantees to which the
facilitator should adhere. We define a hierarchy of participation guarantees
and also consider several social-good functions. (ii) We provide polynomial
algorithms for solving various versions of the associated optimization
problems, including one-to-one and many-to-one allocation settings. (iii) We
demonstrate the benefits of such facilitation and relaxation, and the
implications of the different participation guarantees, using extensive
experimentation on three real-world datasets.

</details>


### [208] [Partitioned Combinatorial Optimization Games](https://arxiv.org/abs/2508.18449)
*Jiehua Chen,Christian Hatschka,Sofia Simola*

Main category: cs.GT

TL;DR: 本文提出了一类称为可分配组合优化博弈（PCOGs）的合作博弈，研究了核心稳定性的验证和存在性问题，并分析了四种经典图优化任务的算法复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究合作博弈中的核心稳定性问题，特别是针对可分配组合优化博弈（PCOGs）。

Method: 提出PCOG博弈模型，该模型输入为一组代理和一个具有固定优化目标的组合结构（如图），其中结构被划分为代理。每个代理集合的价值来源于该集合所占结构的优化解决方案。研究核心稳定性的验证和存在性问题，并分析了最小顶点覆盖、最小支配集、最小生成树和最大匹配这四种图优化任务的算法复杂度。

Result: 分析了四种经典图优化任务（最小顶点覆盖、最小支配集、最小生成树、最大匹配）在PCOG模型下核心稳定性的验证和存在性问题的算法复杂度。

Conclusion: 对PCOG模型在特定图优化任务下的核心稳定性问题进行了复杂度分析。

Abstract: We propose a class of cooperative games, called d Partitioned Compbinatorial
Optimization Games (PCOGs). The input of PCOG consists of a set of agents and a
combinatorial structure (typically a graph) with a fixed optimization goal on
this structure (e.g., finding a minimum dominating set on a graph) such that
the structure is divided among the agents. The value of each coalition of
agents is derived from the optimal solution for the part of the structure
possessed by the coalition. We study two fundamental questions related to the
core: Core Stability Verification and Core Stability Existence. We analyze the
algorithmic complexity of both questions for four classic graph optimization
tasks: minimum vertex cover, minimum dominating set, minimum spanning tree, and
maximum matching.

</details>


### [209] [Bias-Adjusted LLM Agents for Human-Like Decision-Making via Behavioral Economics](https://arxiv.org/abs/2508.18600)
*Ayato Kitadai,Yusuke Fukasawa,Nariaki Nishino*

Main category: cs.GT

TL;DR: LLM 在模拟人类决策时存在内在偏见，与真实人类行为存在差异，限制了其反映人口多样性的能力。本研究提出一种基于个性的方法，利用行为经济学中的个体行为数据来调整模型偏见。将此方法应用于最后通牒博弈，观察到模拟行为与经验行为之间的一致性得到改善，尤其是在响应者方面。结果表明，基于个性的条件化 LLM 在大规模模拟类人决策模式方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: LLM在模拟人类决策时存在内在偏见，与真实人类行为不符，限制了其反映人口多样性的能力。

Method: 采用基于个性的方法，利用行为经济学中的个体行为数据来调整模型偏见，并将其应用于最后通牒博弈。

Result: 在最后通牒博弈中，模拟行为与经验行为之间的一致性得到改善，尤其是在响应者方面。

Conclusion: 基于个性的条件化 LLM 在大规模模拟类人决策模式方面具有潜力，但仍需进一步完善特征表示。

Abstract: Large language models (LLMs) are increasingly used to simulate human
decision-making, but their intrinsic biases often diverge from real human
behavior--limiting their ability to reflect population-level diversity. We
address this challenge with a persona-based approach that leverages
individual-level behavioral data from behavioral economics to adjust model
biases. Applying this method to the ultimatum game--a standard but difficult
benchmark for LLMs--we observe improved alignment between simulated and
empirical behavior, particularly on the responder side. While further
refinement of trait representations is needed, our results demonstrate the
promise of persona-conditioned LLMs for simulating human-like decision patterns
at scale.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [210] [Gated MoS2/SiN Nanochannel for Tunable Ion Transport and Protein Translocation](https://arxiv.org/abs/2508.19023)
*Shukun Weng,Ali Douaki,Makusu Tsutsui,German Lanzavecchia,Anastasiia Sapunova,Lorenzo Iannetti,Alberto Giacomello,Roman Krahne,Denis Garoli*

Main category: physics.app-ph

TL;DR: 本研究介绍了一种 MoS2/SiN 混合纳米通道结构，可通过外部栅极实现离子传输的电调控，并探讨了其在渗透发电和单分子检测中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 离子在纳米流体通道中的传输在单分子分析、分子操控和能量收集等领域具有巨大潜力，但精确控制离子传输仍然是一个重大挑战。

Method: 研究采用了聚焦离子束（FIB）刻蚀和干法转移相结合的方法来制造纳米通道，实现了小于 10 nm 的厚度，并保持了 MoS2 的结构完整性和电子性质，这对于可靠的表面电荷调制至关重要。首先，研究了栅极电压对离子电导率的影响，并观察到了在不同偏压极性下离子选择性的栅极依赖性调制。然后，通过在纳米通道两端施加盐浓度梯度，验证了该平台在渗透能收集方面的可行性。最后，测试了该系统在单分子传感方面的性能，结果表明线性化的牛血清白蛋白（BSA）产生了具有显著长停留时间的易位信号。

Result: 研究发现栅极电压可以调控离子电导率，并且在不同偏压极性下观察到了离子选择性的栅极依赖性调制。通过施加盐浓度梯度，验证了该平台在渗透能收集方面的可行性。线性化的牛血清白蛋白（BSA）产生了易位信号，并且停留时间较长。

Conclusion: 研究结果表明，栅极可调控的 MoS2/SiN 纳米通道为可调谐纳米流体学提供了一个有前景的平台，在控制分子传输和从渗透梯度中收集能量方面具有潜在应用价值。

Abstract: Ionic transport in nanofluidic channels holds great promise for applications
such as single-molecule analysis, molecular manipulation, and energy
harvesting. However, achieving precise control over ion transport remains a
major challenge. In this work, we introduce a MoS2 SiN hybrid nanochannel
architecture that enables electrical tuning of ionic transport via external
gating, and we examine its potential for osmotic power generation and single
molecule detection. To fabricate the channels, we employed a combined focused
ion beam (FIB) milling and dry transfer method, producing sub 10 nm thick
structures while preserving the structural integrity and electronic properties
of MoS2, essential for reliable surface charge modulation. We first
investigated how the gate voltage influences ionic conductance, finding
evidence of gate dependent modulation of ion selectivity under different bias
polarities. Next, by applying a salt concentration gradient across the
nanochannels, we demonstrated the feasibility of this platform for osmotic
energy harvesting. Finally, we tested the system for single molecule sensing,
showing that linearized bovine serum albumin (BSA) produced translocation
signals with notably long dwell times. Together, these results highlight gated
MoS2 SiN nanochannels as a promising platform for tunable nanofluidics, with
potential applications in controlled molecular transport and energy harvesting
from osmotic gradients.

</details>


### [211] [Predicting the optimal noise strength for solving optimization problems with analog Ising machines](https://arxiv.org/abs/2508.19107)
*Leen Mys,Guy Verschaffelt,Guy Van der Sande*

Main category: physics.app-ph

TL;DR: 模拟伊辛机通过注入大噪声来解决MaxCut问题，优化噪声可提高求解效率并消除参数调优的需要。


<details>
  <summary>Details</summary>
Motivation: 模拟伊辛机在解决NP难优化问题时容易陷入局部最小值，现有方法需要复杂的参数调优。

Method: 研究了单独注入大噪声以及结合退火的策略，以提高模拟伊辛机解决MaxCut问题的成功率和求解时间（TTS）。

Result: 优化噪声可以将TTS提高几个数量级，并使该方法与当前最先进的技术（如混沌幅度控制）相媲美。此外，可以根据问题连接性和耦合强度预测噪声值，无需进行昂贵的参数优化。

Conclusion: 注入大噪声是一种有效且无需参数调优的策略，可以显著提高模拟伊辛机解决MaxCut问题的性能。

Abstract: Analog Ising machines are dedicated hardware solvers designed to solve NP
hard optimization problems. However, the global optimum is often not found as
the system gets stuck in local minima. While several strategies exist to
increase the chance of escaping local minima, often these methods needs
extensive parameter tuning. In this work, we investigate the injection of large
noise as a scheme on its own and in combination with annealing to improve the
success rate and the time-to-solution (TTS) of analog Ising machines for MaxCut
problems. We demonstrate that optimizing the noise improves the TTS by several
orders and makes both approaches competitive with the state-of-the-art, such as
chaotic amplitude control. Moreover, we are able to predict a good noise value
based on the problem connectivity and coupling strength, eliminating the need
for costly parameter optimization.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [212] [SeDA: Secure and Efficient DNN Accelerators with Hardware/Software Synergy](https://arxiv.org/abs/2508.18924)
*Wei Xuan,Zhongrui Wang,Lang Feng,Ning Lin,Zihao Xuan,Rongliang Fu,Tsung-Yi Ho,Yuzhong Jiao,Luhong Liang*

Main category: cs.AR

TL;DR: SeDA是一种新的安全DNN加速器方法，通过带宽感知加密、最优块粒度和多级完整性验证，在不显著影响性能的情况下提高了资源效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有DNN加速器的安全方法需要大量的硬件资源和片外内存访问，影响了其在自动驾驶、医疗和金融等领域的应用。

Method: SeDA采用带宽感知加密机制提高硬件资源效率；通过层内和层间分块模式实现最优块粒度；并使用多级完整性验证机制来最小化或消除内存访问开销。

Result: SeDA在服务器和边缘NPU上将性能开销降低了12%以上，并具有良好的可扩展性。

Conclusion: SeDA通过优化资源利用率和最小化内存访问，在保证安全性的同时提高了DNN加速器的效率和性能。

Abstract: Ensuring the confidentiality and integrity of DNN accelerators is paramount
across various scenarios spanning autonomous driving, healthcare, and finance.
However, current security approaches typically require extensive hardware
resources, and incur significant off-chip memory access overheads. This paper
introduces SeDA, which utilizes 1) a bandwidth-aware encryption mechanism to
improve hardware resource efficiency, 2) optimal block granularity through
intra-layer and inter-layer tiling patterns, and 3) a multi-level integrity
verification mechanism that minimizes, or even eliminates, memory access
overheads. Experimental results show that SeDA decreases performance overhead
by over 12% for both server and edge neural processing units (NPUs), while
ensuring robust scalability.

</details>


### [213] [TaiBai: A fully programmable brain-inspired processor with topology-aware efficiency](https://arxiv.org/abs/2508.18961)
*Qianpeng Li,Yu Song,Xin Liu,Wenna Song,Boshi Zhao,Zhichao Wang,Aoxin Chen,Tielin Zhang,Liang Chen*

Main category: cs.AR

TL;DR: TaiBai是一款事件驱动、可编程的类脑处理器，通过利用时空稀疏性来降低带宽和计算开销，相比NVIDIA RTX 3090 GPU，在语音识别、心电分类和跨天脑机接口解码等任务中，能效比提升超过200倍。


<details>
  <summary>Details</summary>
Motivation: 目前的类脑芯片存在网络拓扑结构刚性、神经元可编程性有限的缺点，限制了其适应性。

Method: 提出了TaiBai，一款利用时空稀疏性来最小化带宽和计算开销的事件驱动、可编程多核类脑处理器。TaiBai芯片包含三个主要特点：1. 类脑分层拓扑编码方案，可灵活支持任意网络架构并降低大规模网络的存储开销；2. 多粒度指令集，支持具有不同动态和片上学习规则的类脑脉冲神经元或突触的可编程性；3. 协同设计的编译器栈，用于优化任务映射和资源分配。

Result: 在语音识别、心电分类和跨天脑机接口解码等任务的评估中，TaiBai芯片上的脉冲神经网络的能效比达到了标准NVIDIA RTX 3090 GPU的200倍以上，同时准确率相当。

Conclusion: TaiBai展示了其作为可扩展、可编程和超高效的多尺度大脑模拟和类脑计算解决方案的巨大潜力。

Abstract: Brain-inspired computing has emerged as a promising paradigm to overcome the
energy-efficiency limitations of conventional intelligent systems by emulating
the brain's partitioned architecture and event-driven sparse computation.
However, existing brain-inspired chips often suffer from rigid network topology
constraints and limited neuronal programmability, hindering their adaptability.
To address these challenges, we present TaiBai, an event-driven, programmable
many-core brain-inspired processor that leverages temporal and spatial spike
sparsity to minimize bandwidth and computational overhead. TaiBai chip contains
three key features: First, a brain-inspired hierarchical topology encoding
scheme is designed to flexibly support arbitrary network architectures while
slashing storage overhead for large-scale networks; Second, a multi-granularity
instruction set enables programmability of brain-like spiking neuron or
synapses with various dynamics and on-chip learning rules; Third, a co-designed
compiler stack optimizes task mapping and resource allocation. After evaluating
across various tasks, such as speech recognition, ECG classification, and
cross-day brain-computer interface decoding, we found spiking neural networks
embedded on the TaiBai chip could achieve more than 200 times higher energy
efficiency than a standard NVIDIA RTX 3090 GPU at a comparable accuracy. These
results demonstrated its high potentiation as a scalable, programmable, and
ultra-efficient solution for both multi-scale brain simulation and
brain-inspired computation.

</details>


### [214] [Building an Open CGRA Ecosystem for Agile Innovation](https://arxiv.org/abs/2508.19090)
*Rohan Juneja,Pranav Dangi,Thilini Kaushalya Bandara,Zhaoying Li,Dhananjaya Wijerathne,Li-Shiuan Peh,Tulika Mitra*

Main category: cs.AR

TL;DR: 现代计算工作负载（尤其是在AI和边缘应用中）需要软硬件协同设计来实现性能和能效目标。本文提出一个开放的CGRA生态系统，包括HyCUBE（具有单周期多跳重构互连）、PACE（将HyCUBE嵌入RISC-V SoC）和Morpher（自适应CGRA设计框架）。通过开放性降低创新门槛，促进可复现研究，并推动CGRA在未来硬件开发中的应用。呼吁建立CGRA和空间加速器的统一抽象层，以实现硬件的架构可移植性和编译器创新。


<details>
  <summary>Details</summary>
Motivation: 现代计算工作负载，特别是AI和边缘应用，需要软硬件协同设计来满足性能和能效目标。开放和敏捷的平台取代封闭的垂直集成开发，形成模块化、社区驱动的生态系统，这将有利于协同设计。

Method: 本文提出一个开放的CGRA生态系统，包含HyCUBE、PACE和Morpher。HyCUBE是一个具有重构单周期多跳互连的CGRA，用于高效数据移动。PACE将功耗优化的HyCUBE嵌入RISC-V SoC，面向边缘计算。Morpher是一个完全开源的、架构自适应的CGRA设计框架，支持设计空间探索、编译、仿真和验证。

Result: 本文展示了一个开放的CGRA生态系统，包括HyCUBE、PACE和Morpher，它们分别解决了互连效率、低功耗嵌入式CGRA以及设计、编译和验证的自动化问题。该生态系统旨在降低创新门槛，支持可复现研究，并展示CGRA作为敏捷硬件开发基础的潜力。

Conclusion: 通过拥抱各层级的开放性，本文旨在降低创新门槛，实现可复现的研究，并展示CGRA如何成为下一波敏捷硬件开发的基础。作者呼吁为CGRA和空间加速器建立一个统一的抽象层，将硬件专业化与软件开发分离，从而实现架构可移植性、编译器创新和可扩展的开放空间计算基础。

Abstract: Modern computing workloads, particularly in AI and edge applications, demand
hardware-software co-design to meet aggressive performance and energy targets.
Such co-design benefits from open and agile platforms that replace closed,
vertically integrated development with modular, community-driven ecosystems.
Coarse-Grained Reconfigurable Architectures (CGRAs), with their unique balance
of flexibility and efficiency are particularly well-suited for this paradigm.
When built on open-source hardware generators and software toolchains, CGRAs
provide a compelling foundation for architectural exploration, cross-layer
optimization, and real-world deployment. In this paper, we will present an open
CGRA ecosystem that we have developed to support agile innovation across the
stack. Our contributions include HyCUBE, a CGRA with a reconfigurable
single-cycle multi-hop interconnect for efficient data movement; PACE, which
embeds a power-efficient HyCUBE within a RISC-V SoC targeting edge computing;
and Morpher, a fully open-source, architecture-adaptive CGRA design framework
that supports design space exploration, compilation, simulation, and
validation. By embracing openness at every layer, we aim to lower barriers to
innovation, enable reproducible research, and demonstrate how CGRAs can anchor
the next wave of agile hardware development. We will conclude with a call for a
unified abstraction layer for CGRAs and spatial accelerators, one that
decouples hardware specialization from software development. Such a
representation would unlock architectural portability, compiler innovation, and
a scalable, open foundation for spatial computing.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [215] [Odd relaxation in three-dimensional Fermi liquids](https://arxiv.org/abs/2508.18342)
*Seth Musser,Sankar Das Sarma,Johannes Hofmann*

Main category: cond-mat.mes-hall

TL;DR: 三维费米液体中存在长寿命的非流体模式，其特点是奇偶模式的弛豫率不同，奇偶模式比偶偶模式弛豫得更慢。


<details>
  <summary>Details</summary>
Motivation: 验证理论预测，即三维费米液体中存在类似二维费米液体的长寿命、非流体模式，且奇偶模式的弛豫率不同。

Method: 计算了三维费米液体中奇偶模式的弛豫率，并分析了泡利不相容效应和散射势对弛豫率的影响，以及奇偶模式弛豫率在横向电导和横向集体模式结构中的表现。

Result: 三维费米液体中存在与温度二次方成正比的低-温弛豫率，且奇偶模式的弛豫率存在差异，奇偶模式比偶偶模式弛豫得更慢。泡利不相容效应可导致高达40%的相对差异，有利于大角度散射的相互作用会进一步增强奇偶模式的弛豫率差异。

Conclusion: 三维费米液体中存在类似二维费米液体的分层现象，这为通过输运测量进行实验验证提供了可能。

Abstract: Recent theoretical works predict a hierarchy of long-lived, non-hydrodynamic
modes in two-dimensional Fermi liquids arising from the feature -- supposedly
unique to two dimensions -- that relaxation by head-on scattering is not
efficient in the presence of Pauli blocking. This leads to a parity-based
separation of scattering rates, with odd-parity modes relaxing much more slowly
than even-parity ones. In this work, we establish that a similar effect exists
in isotropic three-dimensional Fermi liquids, even though relaxation does not
proceed solely by head-on scattering. We show that while the relaxation rates
of even and odd modes in 3D share the same leading-order $\sim T^2$
low-temperature scaling typical of Fermi liquids, their magnitudes differ, with
odd-parity modes relaxing more slowly than even ones for a broad class of
interactions. We find a relative difference between odd-and even-parity
relaxation rates as large as $40\%$ just by Pauli blocking alone, with a strong
additional dependence on the scattering potential, such that the odd-even
staggering is further enhanced by interactions that favor large-angle
scattering. We identify signatures of these odd-parity relaxation rates in the
static transverse conductivity as well as the transverse collective mode
structure. Our results establish the unexpected existence of a tomographic-like
regime in higher-dimensional Fermi liquids and suggest experimental probes via
transport measurements.

</details>


### [216] [Odd-Parity Altermagnetism Originated from Orbital Orders](https://arxiv.org/abs/2508.18361)
*Zheng-Yang Zhuang,Di Zhu,Dongling Liu,Zhigang Wu,Zhongbo Yan*

Main category: cond-mat.mes-hall

TL;DR: 奇偶宇称的自旋劈裂在自旋电子学和非常规超导中起着核心作用，但在共线磁性系统中其微观实现仍然难以捉摸。我们提出了一种基于对称性的通用策略，通过堆叠两个非中心对称的单层，并采用层间反铁磁构型和平面内层翻转操作来实现奇偶宇称的交替磁性。在此设置下，奇偶宇称的自旋劈裂源于非相对论轨道顺序，而非自旋-轨道耦合，并受有效的的时间反转对称性保护，尽管明确的时间反转对称性被破坏。通过利用晶格对称性，我们的框架能够实现 p 波和 f 波交替磁体的性质。所得模型通常表现出量子自旋霍尔绝缘体相，具有拓扑保护的螺旋边缘态和量子化的自旋霍尔电导。我们的工作扩展了交替磁性相的范围，并为交替磁性系统中的自旋电子学和非常规超导开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 奇偶宇称的自旋劈裂在自旋电子学和非常规超导中起着核心作用，但在共线磁性系统中其微观实现仍然难以捉摸。

Method: 提出了一种基于对称性的通用策略，通过堆叠两个非中心对称的单层，并采用层间反铁磁构型和平面内层翻转操作来实现奇偶宇称的交替磁性。

Result: 奇偶宇称的自旋劈裂源于非相对论轨道顺序，而非自旋-轨道耦合，并受有效的的时间反转对称性保护。通过利用晶格对称性，我们的框架能够实现 p 波和 f 波交替磁体的性质。所得模型通常表现出量子自旋霍尔绝缘体相，具有拓扑保护的螺旋边缘态和量子化的自旋霍尔电导。

Conclusion: 我们的工作扩展了交替磁性相的范围，并为交替磁性系统中的自旋电子学和非常规超导开辟了道路。

Abstract: Odd-parity spin-splitting plays a central role in spintronics and
unconventional superconductivity, yet its microscopic realization in collinear
magnetic systems remains elusive. We propose a general symmetry-based strategy
for realizing odd-parity altermagnetism by stacking two noncentrosymmetric
monolayers in an interlayer antiferromagnetic configuration and applying an
in-plane layer-flip operation. In this setting, odd-parity spin-splitting
originates from nonrelativistic orbital orders rather than spin-orbit coupling,
and is protected by an effective time-reversal symmetry despite the explicit
time-reversal symmetry being broken. By exploiting lattice symmetries, our
framework enables the realization of both $p$- and $f$-wave altermagnets. The
resulting models generically host quantum spin Hall insulator phases, featuring
topologically protected helical edge states and quantized spin Hall
conductance. Our work expands the landscape of altermagnetic phases and opens a
pathway toward spintronics and unconventional superconductivity in
altermagnetic systems.

</details>


### [217] [3D microwave imaging of a van der Waals heterostructure](https://arxiv.org/abs/2508.18365)
*Leonard W. Cao,Chen Wu,Lingyuan Lyu,Liam Cohen,Noah Samuelson,Ziying Yan,Sneh Pancholi,Kenji Watanabe,Takashi Taniguchi,Daniel E. Parker,Andrea F. Young,Monica T. Allen*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种量子成像技术，能够逐层解析范德华异质结构中单个原子层的电荷密度分布，从而实现对三维量子现象的洞察。


<details>
  <summary>Details</summary>
Motivation: 为了克服扫描探针显微镜在表征多层异质结构中的地下量子现象的挑战，本研究提出了一种能够解析平面外量子态的新型量子成像技术。

Method: 利用毫开尔文微波阻抗显微镜，对双层石墨烯中的量子霍尔态和电荷无序进行层分辨成像。通过利用顶层离散的能谱，实现微波传输，从而直接获取地下层的量子相位信息。

Result: 研究成功实现了对双层石墨烯中量子霍尔态和电荷无序的层分辨成像，揭示了层间筛选的特性，并发现了由多体关联驱动的负量子电容信号。此外，还提取了能隙尺寸等关键的能带结构和热力学参数。研究还阐明了表面杂质和筛选对分数量子霍尔态稳定性的影响，并证明了顶层石墨烯可作为顶栅，用于调控从分数陈绝缘体到多层石墨烯中关联态的广泛现象。

Conclusion: 该量子成像技术为研究三维量子现象提供了新的视角，能够逐层解析电荷分布，揭示层间筛选效应和多体关联。同时，该技术在调控量子相变方面也展现了巨大潜力。

Abstract: Van der Waals (vdW) heterostructures offer a tunable platform for the
realization of emergent phenomena in layered electron systems. While scanning
probe microscopy techniques have proven useful for the characterization of
surface states and 2D crystals, the subsurface imaging of quantum phenomena in
multi-layer systems presents a significant challenge. In 3D heterostructures,
states that occupy different planes can simultaneously contribute to the signal
detected by the microscope probe, which complicates image analysis and
interpretation. Here we present a quantum imaging technique that offers a
glimpse into the third dimension by resolving states out of plane: it extracts
the charge density landscape of individual atomic planes inside a vdW
heterostructure, layer by layer. As a proof-of-concept, we perform
layer-resolved imaging of quantum Hall states and charge disorder in
double-layer graphene using milliKelvin microwave impedance microscopy. Here
the discrete energy spectrum of the top layer enables transmission of
microwaves through gapped states, thus opening direct access to quantum phases
in the subsurface layer. Resolving how charge is distributed out-of-plane
offers a direct probe of interlayer screening, revealing signatures of negative
quantum capacitance driven by many-body correlations. At the same time, we
extract key features of the band structure and thermodynamics, including gap
sizes. Notably, by imaging the charge distribution on different atomic planes
beneath the surface, we shed light on the roles of surface impurities and
screening on the stability of fractional quantum Hall states. We also show that
the uppermost graphene layer can serve as a top gate: This unlocks access to a
wide range of phenomena that require displacement field control, from
fractional Chern insulators in Moir\'e superlattices to correlated states in
multilayer graphene.

</details>


### [218] [Scalable Effective Models for Superconducting Nanostructures: Applications to Double, Triple, and Quadruple Quantum Dots](https://arxiv.org/abs/2508.18465)
*Daniel Bobok,Lukáš Frk,Vladislav Pokorný,Martin Žonda*

Main category: cond-mat.mes-hall

TL;DR: We developed a Chain Expansion (ChE) method to model superconducting nanostructures with quantum dots and leads, which is accurate, efficient, and scalable for various geometries and conditions.


<details>
  <summary>Details</summary>
Motivation: To create a versatile and scalable framework for modeling superconducting nanostructures described by the generalized SC Anderson impurity model with multiple quantum dots and leads.

Method: Chain Expansion (ChE) method maps each SC lead onto a finite tight-binding chain with parameters obtained from Padé approximants of the tunneling self-energy. The method allows for simulations using exact diagonalization for short chains and density matrix renormalization group methods for longer ones.

Result: ChE accurately captures ground-state phase diagrams of double, triple, and quadruple quantum dots coupled to a SC lead, revealing complex phases missed by the zero-bandwidth approximation and demonstrating the impact of additional dots on phase complexity.

Conclusion: ChE is a fast, accurate, and systematically improvable tool for exploring complex superconducting nanostructures, offering significant advantages over existing methods like the zero-bandwidth approximation.

Abstract: We introduce a versatile and scalable framework for constructing effective
models of superconducting (SC) nanostructures described by the generalized SC
Anderson impurity model with multiple quantum dots and leads. Our Chain
Expansion (ChE) method maps each SC lead onto a finite tight-binding chain with
parameters obtained from Pad\'e approximants of the tunneling self-energy. We
provide an explicit algorithm for the general case as well as simple analytical
expressions for the chain parameters in the wide-band and infinite-chain
limits. This mapping preserves low-energy physics while enabling efficient
simulations: short chains are tractable with exact diagonalization, and longer
ones with density matrix renormalization group methods. The approach remains
reliable and computationally efficient across diverse geometries, both in and
out of equilibrium. We use ChE to map the ground-state phase diagrams of
double, triple, and quadruple quantum dots coupled to a single SC lead. While
half-filled symmetric systems show similar overall diagrams, the particular
phases differ substantially with dot number. Here, large parameter regions are
entirely missed by the widely used zero-bandwidth approximation but are
captured by ChE. Away from half-filling, additional dots markedly increase
diagram complexity, producing a rich variety of stable phases. These results
demonstrate ChE as a fast, accurate, and systematically improvable tool for
exploring complex SC nanostructures.

</details>


### [219] [Twisted light drives chiral excitations of interacting electrons in nanostructures with magnetic field](https://arxiv.org/abs/2508.18480)
*F. J. Rodríguez,L. Quiroga,N. F. Johnson*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Twisted light (TL), a special kind of light carrying orbital angular
momentum, provides a powerful tool for driving symmetry resolved transitions in
quantum confined nanostructures. We study a realistic model where a TL pulse
excites two interacting electrons in a nanostructure under a perpendicular
magnetic field. To include image charge effects in layered systems, we use an
effective electron electron potential of the form 1/r^n. For n = 2, the system
exhibits an underlying su(1,1) dynamical symmetry, enabling analytical
solutions and a clear interpretation of selection rules, parity changes, and
angular momentum resolved absorption. We show that the bare Coulomb 1/r
interaction produces similar spectra, indicating that twisted light driven
excitations are robust against the precise interaction form. The excitation
spectrum reveals strong chiral properties: TL pulses, unlike conventional
dipolar fields, directly access interaction-driven transitions otherwise
symmetry-forbidden. In particular, TL breaks the generalized Kohn theorem,
exposing internal excitations through multi quanta orbital processes. More
broadly, our results establish TL as a sensitive probe of correlations,
symmetry, and magneto-optical dynamics in strongly interacting quantum systems,
uncovering features that remain invisible to standard infrared absorption.

</details>


### [220] [Light-programmable reorientation of the crystallographic c-axis of Tellurium thin films](https://arxiv.org/abs/2508.18584)
*Yuta Kobayashi,Arata Mitsuzuka,Haruo Kondo,Makoto Shoshin,Jun Uzuhashi,Tadakatsu Ohkubo,Masamitsu Hayashi,Masashi Kawaguchi*

Main category: cond-mat.mes-hall

TL;DR: 二维碲（Te）薄膜可以通过线性偏振的皮秒激光脉冲进行非接触式操控，实现c轴取向的可控、可写和可编程，从而在光电器件和光子器件领域开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 传统碲（Te）薄膜的合成技术难以控制其晶体c轴的平面取向，限制了其大规模集成和应用。

Method: 利用线性偏振的皮秒激光脉冲，对二维碲（Te）薄膜的c轴取向进行动态操控，实现c轴的各向异性重定向。

Result: 实现了碲（Te）薄膜c轴的各向异性重定向，且该过程可逆，可在沉积后进行重写和空间选择性控制。

Conclusion: 所提出的光驱动方法能够实现碲（Te）薄膜可编程的各向异性，为构建可重构的光电器件和光子器件（如主动超表面和CMOS兼容架构）提供了新的可能性。

Abstract: Tellurium (Te), a two-dimensional material with pronounced structural
anisotropy, exhibits exceptional electrical and optical properties that are
highly sensitive to its crystallographic orientation. However, conventional
synthesis techniques offer limited control over the in-plane alignment of Te's
crystallographic c-axis, hindering large-scale integration. Here, we report a
novel, non-contact method to dynamically manipulate the c-axis orientation of
Te thin films using linearly polarized picosecond laser pulses. We show that
the c-axis can be omnidirectionally reoriented perpendicular to the laser
polarization, even in initially polycrystalline films. This reorientation is
fully reversible, allowing for rewritable and spatially selective control of
the c-axis orientation post-deposition. Our light-driven approach enables
programmable anisotropy in Te, opening new avenues for reconfigurable
optoelectronic and photonic devices, such as active metasurfaces and
CMOS-compatible architectures.

</details>


### [221] [Spin-Orbit Coupling-Driven Chirality Switching of Spin Waves in Altermagnets](https://arxiv.org/abs/2508.18585)
*Wen-Tong Li,Yu-Biao Wu,Lin Zhuang,Jian-Tao Wang,Wu-Ming Liu*

Main category: cond-mat.mes-hall

TL;DR: 这项研究提出了一种通过调控自旋轨道耦合（SOC）强度来可逆地切换反磁体中自旋波手性的新方案，为开发利用可切换手性自旋波的自旋电子器件奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 自旋波的手性作为信息载体具有超快动力学和低功耗的优点，而反磁体因其固有的手性分裂自旋波和净磁化强度为零的特性，成为承载手性比特的理想平台。然而，实现基于手性的逻辑运算需要对手性状态进行有效控制。

Method: 通过调控自旋轨道耦合（SOC）强度来可逆地切换反磁体中自旋波的手性。具体而言，对于面内自旋极化，SOC与反磁性相互作用，产生动量依赖的竞争。自旋波的手性分裂结构在不同的布里渊区区域由SOC或反磁性主导，这使得通过改变它们的相对强度来切换手性成为可能。研究还提出了一个利用反磁性衬底诱导SOC和重金属条纹检测手性的实验设计。

Result: 研究表明，通过调控SOC强度可以实现自旋波手性的切换，并提出了相应的实验设计。

Conclusion: 本研究为通过SOC控制反磁体中的自旋波手性提供了一条新途径，为开发利用可切换手性自旋波的动态信息载体奠定了基础。

Abstract: Chirality of spin waves offers an advantageous binary carrier for data
transmission and processing with ultrafast dynamics and low power consumption.
Altermagnets possess intrinsic chirality-splitting spin waves and vanishing net
magnetization, thus emerging as ideal platforms to host chirality bits.
However, active control of the chiral states remains a key challenge for
realizing logic operations in chirality-based circuits. Here, we propose a
novel scheme for reversibly switching spin-wave chirality in altermagnets
between right- and left-handedness by tuning spin-orbit coupling (SOC)
strength. Specifically, for in-plane spin polarization, SOC hybridizes with the
altermagnetism, which induces a momentum-dependent competition. The
chirality-splitting structure of spin waves is dominated by either SOC or
altermagnetism in different Brillouin zone regions, allowing chirality
switching by altering their relative strength. An experimental design utilizing
an antiferromagnetic substrate to induce SOC and a heavy-metal stripe for
chirality detection is proposed. Our work establishes a novel pathway for
controlling spin-wave chirality in altermagnets via SOC, laying the groundwork
for developing spintronic devices utilizing switchable chiral spin waves as
dynamic information carriers.

</details>


### [222] [Optical Control of Integer and Fractional Chern Insulators](https://arxiv.org/abs/2508.18639)
*William Holtzmann,Weijie Li,Eric Anderson,Jiaqi Cai,Heonjoon Park,Chaowei Hu,Takashi Taniguchi,Kenji Watanabe,Jiun-Haw Chu,Di Xiao,Ting Cao,Xiaodong Xu*

Main category: cond-mat.mes-hall

TL;DR: 通过圆偏振光泵浦控制扭曲MoTe2双层膜中的铁磁性及其相关的整数和分数陈绝缘体状态。


<details>
  <summary>Details</summary>
Motivation: 在电子关联存在的情况下，通过光学手段控制拓扑态，特别是在零场下实现分数陈绝缘体（FCI）是具有广泛科学和技术影响的迷人课题。

Method: 通过圆偏振光泵浦，实现扭曲MoTe2双层膜中铁磁性以及相关的陈绝缘体（CI）和分数陈绝缘体（FCI）状态的控制和切换。在低光激发功率下，通过光学训练（电调谐与螺旋选择性光学泵浦相结合）按需制备铁磁性。在更高激发功率下，实现了远低于居里温度的直接光学切换铁磁性。

Result: 光学训练和直接切换铁磁性在接近CI/FCI态时最为有效，这归因于光注入空穴的隙增强谷极化。磁化强度可以通过调制激发光的螺旋度进行动态切换。空间分辨测量进一步证明了铁磁性（以及CI/FCI）畴的光学写入。

Conclusion: 这项工作实现了对拓扑量子多体系统的精确光学控制，有望在拓扑自旋电子学、量子存储器以及通过可编程模式生成奇异边缘态方面得到应用。

Abstract: Optical control of topology, particularly in the presence of electron
correlations, is a fascinating topic with broad scientific and technological
impact. Twisted MoTe$_2$ bilayer (tMoTe$_2$) is a newly discovered zero-field
fractional Chern insulator (FCI), exhibiting the fractionally quantized
anomalous Hall (FQAH) effect. Since the chirality of the edge states and sign
of the Chern number are determined by the underlying ferromagnetic
polarization, manipulation of ferromagnetism would realize control of the
CI/FCI states. Here, we demonstrate control and switching of ferromagnetic
polarization, and thus the CI and FCI states by circularly polarized optical
pumping in tMoTe$_2$. At low optical excitation power, we achieve on-demand
preparation of ferromagnetic polarization by optical training, i.e.,
electrically tuning the system from non-ferromagnetic to desirable
ferromagnetic states accompanied with helicity-selective optical pumping. With
increased excitation power, we further realize direct optical switching of
ferromagnetic polarization at a temperature far below the Curie temperature.
Both optical training and direct switching of ferromagnetism are most effective
near CI/FCI states, which we attribute to a gap enhanced valley polarization of
photo-injected holes. We show that the magnetization can be dynamically
switched by modulating the helicity of optical excitation. Spatially resolved
measurements further demonstrate optical writing of a ferromagnetic, and thus a
CI (or FCI) domain. Our work realizes precise optical control of a topological
quantum many-body system with potential applications in topological
spintronics, quantum memories, and creation of exotic edge states by
programmable patterning of integer and fractional QAH domains.

</details>


### [223] [Emergent topology of flat bands in a twisted bilayer $α$-$T_3$ lattice](https://arxiv.org/abs/2508.18657)
*Gourab Paul,Srijata Lahiri,Kuntal Bhattacharyya,Saurabh Basu*

Main category: cond-mat.mes-hall

TL;DR: 研究了扭曲双层α-T3系统中由晶格几何引起的破坏性干涉以及布里渊区扩大引起的能带折叠，在产生和修改能带拓扑方面的影响。


<details>
  <summary>Details</summary>
Motivation: 研究晶格几何引起的破坏性干涉和布里渊区扩大引起的能带折叠如何影响扭曲双层α-T3系统的能带拓扑。

Method: 研究了扭曲双层α-T3系统，特别是其在某些参数下的行为，包括混合旺德电荷中心和陈数，以表征不同的拓扑相，并研究了拓扑带平坦度的演化。

Result: 发现α-T3晶格的骰子极限中出现的平坦能带在与h-BN层对齐时会发生退简，形成具有不同拓扑特征的子带。近电荷中性的子带表现出平凡行为，而在非电荷中性区域出现了一个拓扑上非简并的奇异子带。拓扑能带在α-θ平面上的一大部分区域保持孤立，并通过与最近能带的杂化表现出多次相变。

Conclusion: 量子干涉和能带折叠对拓扑带宽度有显著影响，这在α和θ的函数中得到了明确的体现。

Abstract: We investigate an interesting interplay of destructive interference due to
lattice geometry and band folding due to enlargement of the Brillouin zone in
generating and subsequently modifying the band topology in a twisted bilayer
$\alpha$-$T_3$ system. The pronounced degeneracy of the emergent flat band in
the dice limit of the $\alpha$-$T_3$ lattice is removed on alignment with h-BN
layers, resulting in the formation of sub-bands with varying topological
characteristics. Remarkably, while the sub-band near charge neutrality exhibits
a trivial behavior, a topologically non-degenerate singular sub-band emerges
away from charge neutrality. The topological band remains isolated from the
rest of the bands for a substantial area of the $\alpha - \theta$ plane (where
$\alpha$ and $\theta$ correspond to the hopping ratio and twist angle
respectively) while exhibiting multiple phase transitions as a function of the
aforementioned parameters via hybridization with its nearest bands. We study
the evolution of the hybrid Wannier charge center and the Chern number to
characterize the different emergent topological phases. Finally, the degree of
flatness of the topological band is studied as a function of both $\alpha$ and
$\theta$ to explicitly show the influence of quantum interference and band
folding on the width of the topological band.

</details>


### [224] [Theoretical investigation of Quantum Anomalous Hall Effect in Potassium Tri-vanadium Pentantimonide](https://arxiv.org/abs/2508.18692)
*Partha Goswami*

Main category: cond-mat.mes-hall

TL;DR: Kagome金属钾三钒五锑矿理论上支持量子反常霍尔效应，具有平坦能带和狄拉克点，可通过自旋-轨道耦合或磁有序开缝。该系统通过包含最近邻和次近邻跳跃、Rashba自旋-轨道耦合、磁邻近交换场和电荷密度波的哈密顿量进行研究。初步分析表明，该系统具有多个能带，其陈数表明弱拓扑特性。通过引入动量空间缠绕，即通过次近邻跳跃复数的动量依赖性相位来模拟轨道磁通量，发现两个能带携带相反的陈数，表明手性边缘态和量子化反常霍尔效应的出现。


<details>
  <summary>Details</summary>
Motivation: 研究Kagome金属钾三钒五锑矿实现量子反常霍尔效应的可能性，重点关注包含多种物理效应的系统哈密顿量。

Method: 构建包含最近邻和次近邻跳跃、Rashba自旋-轨道耦合、磁邻近交换场和电荷密度波的系统哈密顿量，并进行初步分析，引入动量空间缠绕模拟轨道磁通量。

Result: 系统表现出弱拓扑特性，陈数尚未量化，但存在非平凡的贝里曲率积累。引入动量空间缠绕后，两个能带出现相反的陈数，形成手性边缘态和量子化反常霍尔效应。

Conclusion: 通过引入动量空间缠绕，Kagome金属钾三钒五锑矿系统可以实现量子反常霍尔效应，尽管其他能带保持平凡，但整个系统不再是拓扑惰性的。

Abstract: The Kagome metal Potassium Tri-vanadium Pent-antimonide can support the
quantum anomalous Hall effect theoretically. This is justified by flat bands
and Dirac points susceptible to gap opening by spin-orbit coupling or magnetic
ordering. The theoretical investigation of this quantum effect is possible
exploring strategies like magnetic proximity, and strain or electric gating
tuning. Our goal here is to explore the possibility of quantum anomalous Hall
effect with a system Hamiltonian involving nearest-neighbour and complex next
nearest-neighbour hopping, Rashba spin-orbit coupling, exchange field due to
magnetic proximity, and charge density wave. Our preliminary analysis with
these ingredients reveals that the system hosts multiple bands whose Chern
numbers values suggest weak topological characteristics-not yet quantized, but
showing signs of nontrivial Berry curvature accumulation. Upon introducing
momentum-space winding, mimicking an orbital magnetic flux, through the
momentum-dependence of the phase of the complex hopping, we find that two bands
in the multiple band system carry opposite Chern numbers, indicating the
emergence of chiral edge states and a quantized anomalous Hall effect. The rest
remain trivial, but the system as a whole is no longer topologically inert.

</details>


### [225] [Room temperature giant magnetoresistance detection of spin hall nano-oscillator dynamics in synthetic antiferromagnetic Spin-Valve](https://arxiv.org/abs/2508.18770)
*Chunhao Li,Xiaotian Zhao,Wenlong Cai,Long Liu,Wei Liu,Zhidong Zhang*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种基于合成反铁磁自旋阀（SAF-SV）异质结构的新型自旋霍尔纳米振荡器（SHNO），以克服传统SHNO的功率限制。


<details>
  <summary>Details</summary>
Motivation: 传统SHNO由于磁各向异性磁阻（AMR）较低（<0.3%），面临根本性的功率限制。本研究旨在通过开发一种能够实现高效巨磁电阻（GMR）检测SHNO动态的新型异质结构来解决这一问题。

Method: 研究人员开发了一种[Ta/NiFe/Ru/NiFe/Cu/NiFe/Hf/Pt]的SAF-SV异质结构。其中，NiFe/Ru/NiFe SAF参考层工作在自旋翻转状态，并通过Cu间隔层与NiFe自由层耦合，实现了0.568%的GMR比。通过自旋矩铁磁共振（ST-FMR）验证了自由层的铁磁共振线宽可以通过Pt重金属层中的直流电流进行有效调制，同时保持与SAF层的解耦动力学。研究还采用了SiC衬底和AlN帽层进行热管理，以缓解焦耳热。

Result: 研究观察到了在820 mA偏置电流下的稳定自激振荡峰，并且振荡频率可以通过外部磁场进行调谐，在低磁场下还可能表现出双模行为。

Conclusion: 这项工作为室温、高功率自旋电子振荡器建立了一个新的范例，为神经形态计算和相干射频通信应用提供了巨大的潜力。

Abstract: Conventional spin Hall nano-oscillators (SHNOs) face fundamental power
limitations due to the low anisotropic magnetoresistance (AMR < 0.3%) of
ferromagnetic layers. To address this, we developed a synthetic
antiferromagnetic spin-valve (SAF-SV) heterostructure
[Ta/NiFe/Ru/NiFe/Cu/NiFe/Hf/Pt] that enables efficient giant magnetoresistance
(GMR)-based detection of SHNO dynamics at room temperature. The NiFe/Ru/NiFe
SAF reference layer, operating in the spin-flop state, couples with the NiFe
free layer through a Cu spacer to achieve a remarkable GMR ratio of 0.568% -
exhibiting complete independence of magnetic field/current orientation.
Spin-torque ferromagnetic resonance (ST-FMR) verifies that the ferromagnetic
resonance linewidth of the free layer can be effectively modulated by dc
current through the Pt heavy metal layer, while maintaining decoupled dynamics
from the SAF layer. Thermal management via high-thermal-conductivity SiC
substrates and AlN capping layers successfully mitigates
current-shunting-induced Joule heating. Notably, stable auto-oscillation peaks
are observed at 820 mA bias current, with oscillation frequency tunable by
external magnetic field and potential dual-mode behavior at low fields. This
work establishes a new paradigm for room-temperature, high-power spintronic
oscillators, offering significant potential for neuromorphic computing and
coherent RF communication applications.

</details>


### [226] [Isofrequency spin-wave imaging using color center magnetometry for magnon spintronics](https://arxiv.org/abs/2508.18775)
*Samuel Mañas-Valero,Yasmin C. Doedes,Artem Bondarenko,Michael Borst,Samer Kurdi,Thomas Poirier,James H. Edgar,Vincent Jacques,Yaroslav M. Blanter,Toeno van der Sar*

Main category: cond-mat.mes-hall

TL;DR: Color center magnetometry is a promising tool for imaging spin waves in magnetic films, but faces limitations in sensor-spin detection frequency due to magnetic field control and color center nature. This paper overcomes these by decoupling sensor spins from control fields and using complementary frequencies from diamond and hexagonal boron nitride color centers. Isofrequency imaging of field-controlled spin waves and the effect of intrinsic magnetic anisotropies on spin-wave transport are demonstrated, establishing color center magnetometry as a versatile tool for spin-wave technologies.


<details>
  <summary>Details</summary>
Motivation: The paper addresses two main limitations in color center magnetometry for imaging spin waves: 1) magnetic fields required for spin-wave control detune the sensor-spin detection frequency, and 2) the sensor-spin frequency is restricted by the color center's nature.

Method: The study overcomes limitations by: 1) decoupling sensor spins from control fields through intrinsic anisotropy axes orthogonal to film magnetization, and 2) using color centers in diamond and hexagonal boron nitride to operate at complementary frequencies. They demonstrate isofrequency imaging of field-controlled spin waves and analyze how intrinsic magnetic anisotropies trigger bistable spin textures affecting spin-wave transport at device edges.

Result: The paper demonstrates isofrequency imaging of field-controlled spin waves in a magnetic half-plane. It also shows how intrinsic magnetic anisotropies lead to bistable spin textures that influence spin-wave transport at device edges.

Conclusion: The results establish color center magnetometry as a versatile tool for advancing spin-wave technologies, overcoming previous limitations in frequency control and sensor-field interaction.

Abstract: Magnon spintronics aims to harness spin waves in magnetic films for
information technologies. Color center magnetometry is a promising tool for
imaging spin waves, using electronic spins associated with atomic defects in
solid-state materials as sensors. However, two main limitations persist: the
magnetic fields required for spin-wave control detune the sensor-spin detection
frequency, and this frequency is further restricted by the color center nature.
Here, we overcome these limitations by decoupling the sensor spins from the
spin-wave control fields -- selecting color centers with intrinsic anisotropy
axes orthogonal to the film magnetization -- and by using color centers in
diamond and hexagonal boron nitride to operate at complementary frequencies. We
demonstrate isofrequency imaging of field-controlled spin waves in a magnetic
half-plane and show how intrinsic magnetic anisotropies trigger bistable spin
textures that govern spin-wave transport at device edges. Our results establish
color center magnetometry as a versatile tool for advancing spin-wave
technologies.

</details>


### [227] [Non-Exponential Relaxation in the Rotating Frame of a Driven Nanomechanical Mode](https://arxiv.org/abs/2508.18885)
*Hyunjin Choi,Oriel Shoshani,Ryundon Kim,Younghun Ryu,Jinhoon Jeong,Junho Suh,Steven W. Shaw,M. I. Dykman,Hyoungsoon Choi*

Main category: cond-mat.mes-hall

TL;DR: 该论文通过共振驱动的非线性纳米力学谐振器的转动坐标系，直接观测到了环震动动力学。通过在接近共振时施加一个附加的谐波力，可以激发转动坐标系中围绕不动点的非线性振荡。当移除次级驱动后，测量到同相和正交分量向该不动点的衰减。研究表明，尽管当两个力都关闭时振动幅度呈指数衰减，但同相信号的衰减是非指数的。一个极简模型可以捕捉这些动力学以及附加力激发的振动频谱，并将它们与转动坐标系中由耗散引起的时间对称性破缺联系起来。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是直接观测并理解非线性纳米力学谐振器在共振驱动下的环震动动力学，特别是附加谐波力存在时，其衰减行为与对称性破缺的关系。

Method: 论文采用实验方法，通过在共振驱动的单模非线性纳米力学谐振器的转动坐标系中，施加一个接近共振的附加谐波力来激发非线性振荡。然后移除次级驱动，测量同相和正交分量向不动点的衰减过程。

Result: 研究结果表明，即使在振动幅度呈指数衰减的情况下，同相信号的衰减也是非指数的。此外，一个简化的模型能够解释这些动力学现象以及附加力激发的振动频谱，并将其与转动坐标系中耗散引起的时间对称性破缺联系起来。

Conclusion: 该研究揭示了在非线性纳米力学谐振器中，附加谐波力引起的非指数衰减和时间对称性破缺是耗散过程的直接体现，这为理解和控制这类系统的动力学行为提供了新的视角。

Abstract: We present direct observation of the ring-down dynamics in the rotating frame
of a resonantly driven single-mode nonlinear nanomechanical resonator. An
additional close to resonance harmonic force excites nonlinear oscillations
about the fixed point in the rotating frame. When the secondary drive is
removed, we measure decay of the in-phase and quadrature components toward this
fixed point. We show that the decay of the in-phase signal is non-exponential,
even though the vibration amplitude decays exponentially if both forces are
switched off. A minimalistic model captures these dynamics as well as the
spectrum of the vibrations excited by the additional force, relating them to
the dissipation-induced symmetry breaking of the dynamics in the rotating
frame.

</details>


### [228] [Mass-induced Coulomb drag in capacitively coupled superconducting nanowires](https://arxiv.org/abs/2508.18943)
*Aleksandr Latyshev,Adrien Tomà,Eugene V. Sukhorukov*

Main category: cond-mat.mes-hall

TL;DR: 当两个超导纳米线中的一个被调谐到低于超导体-绝缘体转变，并且出现质量间隙时，由于等离子的贡献被精确抵消，感应电压会消失。


<details>
  <summary>Details</summary>
Motivation: 研究两个电容耦合的超导纳米线中的库仑 जेव्हा一个被调谐到低于超导体-绝缘体转变，并且出现质量间隙时，感应电压的出现。

Method: 使用微扰和半经典方法研究了超导纳米线中的库仑。

Result: 当两个线都是超导线时，诱导电压消失；当第二根线调谐到低于超导体-绝缘体转变并出现质量间隙时，出现有限的拖电压。拖动系数表现出从短线中的弱拖动到长线中的最大值的交叉，最大值由互电容设定。

Conclusion: 质量引起的低维超导体中的库仑拖动机制，并提出在量子临界性附近探测非局域输运的新途径。

Abstract: We investigate Coulomb drag in a system of two capacitively coupled
superconducting nanowires. In this context, drag refers to the appearance of a
stationary voltage in the passive wire in response to a current bias applied to
the active one. Quantum phase slips (QPS) in the biased wire generate voltage
fluctuations that can be transmitted to the other. Using perturbative and
semiclassical approaches, we show that when both wires are superconducting the
induced voltage vanishes due to exact cancellation of plasmon contributions. By
contrast, when the second wire is tuned below the superconductor-insulator
transition and develops a mass gap, this cancellation is lifted and a finite
drag voltage emerges. The drag coefficient exhibits a crossover from weak drag
in short wires to a maximal value set by the mutual capacitance in long wires.
A semiclassical picture of voltage pulse propagation clarifies the physical
origin of the effect: the mass term synchronizes plasmon modes and prevents
complete cancellation of induced signals. Our results establish a mechanism of
mass-induced Coulomb drag in low-dimensional superconductors and suggest new
routes for probing nonlocal transport near quantum criticality.

</details>


### [229] [Giant octupole moment in magnetic multilayers](https://arxiv.org/abs/2508.19033)
*Chang Niu,Lulu Li,Yiqing Wang,Lei Wang,Ke Xia*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种通过角度依赖的异常霍尔电流和离散晶体对称性来量化磁矩贡献的方法，特别适用于研究非周期性系统（如界面和表面）中的八极矩贡献，并展示了通过界面工程和磁序重构来控制八极矩贡献的可能性。


<details>
  <summary>Details</summary>
Motivation: 为了扩展磁性的概念，并为描述多种磁响应提供一个框架，需要量化更高阶的磁效应。异常霍尔效应（AHE）是磁性研究中的一个重要现象，但现有理论主要关注偶极矩（净磁化强度）的贡献。然而，更高阶的磁矩（如八极矩）在AHE中可能扮演重要角色，尤其是在界面和表面等复杂系统中，这方面的研究尚不充分。

Method: 本文提出了一种新方法，通过分析角度依赖的异常霍尔电流，并显式地纳入离散晶体对称性，来定量确定磁矩（包括偶极矩和八极矩）对异常霍尔效应的贡献。该方法特别适用于研究非周期性系统，如界面和表面。研究人员利用第一性原理计算，在（Ag$_{2}$Fe$_{5}$)$_{n}$多层结构中验证了该方法。

Result: 研究发现在具有量子阱工程k点选择性的（Ag$_{2}$Fe$_{5}$)$_{n}$多层结构中，异常霍尔效应主要由八极矩贡献。这表明，即使在常规铁磁材料中，AHE的贡献也不仅仅来自净磁化强度（偶极矩）。此外，研究还证明了可以通过界面工程和磁序重构这两种方法来实际控制八极矩的贡献。

Conclusion: 该研究提出的量化磁矩贡献的方法，特别是对八极矩在异常霍尔效应中的作用的揭示，挑战了现有的理论认识。研究结果表明，更高阶的磁矩对AHE有显著影响，并且可以通过工程手段进行调控，这为操纵更高阶输运效应开辟了新的途径。

Abstract: Multipole moments serve as order parameters for characterizing higher-order
magnetic effects in momentum space, providing a framework to describe diverse
magnetic responses by extending the concept of magnetism. In this letter, we
introduce a methodology to quantitatively determine the multipole moment
contributions in anomalous Hall effect through angle-dependent anomalous Hall
current, with explicit incorporation of discrete crystal symmetries. Our
technique uniquely enables the investigation of octupole contribution in
non-periodic systems, particularly at interfaces and surfaces. Typically, in
(Ag$_{2}$Fe$_{5}$)$_{n}$ multilayers with quantum-well-engineered $k$-point
selectivity, we observe an octupole-dominated anomalous Hall effect in
conventional ferromagnetic materials, through first-principles calculations.
These results fundamentally challenge the existing theoretical understanding of
the anomalous Hall effect, showing that even the conventional contribution
arises not only from the dipole moment (net magnetization). Furthermore, we
establish practical control over the octupole contribution through two distinct
approaches: interface engineering and magnetic ordering reconfiguration,
opening new possibilities for manipulating higher-order transport effects.

</details>


### [230] [YSGAG: The Ideal Substrate for YIG in Quantum Magnonics](https://arxiv.org/abs/2508.19044)
*Rostyslav O. Serha,Carsten Dubs,Christo Guguschev,Bernd Aichner,David Schmoll,Jaganandha Panda,Matthias Weiler,Philipp Pirro,Michal Urbánek,Andrii V. Chumak*

Main category: cond-mat.mes-hall

TL;DR: YSGAG是一种新的无磁性衬底，它消除了YIG薄膜在低温下的磁阻尼，适用于量子磁学。


<details>
  <summary>Details</summary>
Motivation: GGG衬底在低温下具有顺磁性，会增加YIG薄膜的阻尼，这对于量子应用是不利的。需要寻找一种可以替代GGG的无磁性衬底。

Method: 使用铁磁共振（FMR）光谱技术，在低至30毫开尔文的温度下，比较了YIG/YSGAG和YIG/GGG两种体系的磁阻尼特性。

Result: YIG/YSGAG体系在室温下的磁阻尼系数（α）为4.29×10^-5，是有史以来报道的最低值，并且在低至30毫开尔文时，阻尼没有明显增加，有效消除了与顺磁性相关的低温阻尼机制。

Conclusion: YSGAG是YIG薄膜在量子磁学中的理想衬底，为基于自旋波的量子技术的发展铺平了道路。

Abstract: Quantum magnonics leverages the quantum mechanical properties of magnons for
advancing nanoscale quantum information technologies. Ferrimagnetic yttrium
iron garnet (YIG), known for its exceptionally long magnon lifetimes, is a
cornerstone material for magnonics and is typically grown into thin films on
gadolinium gallium garnet (GGG) substrates due to near-perfect lattice
matching. However, the paramagnetic nature of GGG introduces damping mechanisms
detrimental to quantum applications at low temperatures. Here, we present a
study of magnetic damping in a 150$\,$nm-thick YIG film grown on a
500$\,\mu$m-thick yttrium scandium gallium aluminium garnet (YSGAG) substrate,
a newly developed diamagnetic alternative to GGG. Using ferromagnetic resonance
(FMR) spectroscopy at temperatures as low as 30$\,$mK, we compare the damping
characteristics of the YIG/YSGAG system with those of a conventional YIG/GGG
reference system. Our results demonstrate that the YIG/YSGAG system maintains
low magnetic damping from room temperature, with $\alpha = 4.29\times10^{-5}$,
which is the lowest value reported so far for YIG/GGG films and comparable to
the best YIG bulk material, and down to 30$\,$mK, with no significant
temperature-dependent increase in damping. In this substrate, the
low-temperature damping mechanisms associated with paramagnetic spins,
prominent in GGG, are effectively eliminated. Consequently, YSGAG serves as an
ideal substrate for YIG films in quantum magnonics and is paving the way for
the development of spin-wave-based quantum technologies.

</details>


### [231] [Optical control over topological Chern number in moiré materials](https://arxiv.org/abs/2508.19063)
*Olivier Huber,Kilian Kuhlbrodt,Eric Anderson,Weijie Li,Kenji Watanabe,Takashi Taniguchi,Martin Kroner,Xiaodong Xu,Atac Imamoglu,Tomasz Smolenski*

Main category: cond-mat.mes-hall

TL;DR: all-optical switching of spin-valley degree of freedom in twisted MoTe2 homobilayers using circularly-polarized light, enabling dynamical control over ferromagnetic spin states and topological order.


<details>
  <summary>Details</summary>
Motivation: Controlling quantum matter with light to dynamically tune many-body properties like band topology and superconductivity, especially in strongly correlated electron systems.

Method: Demonstrating all-optical switching of spin-valley degree of freedom in twisted MoTe2 homobilayers by resonantly exciting the attractive polaron transition with circularly-polarized light.

Result: Achieved non-thermal switching of ferromagnetic spin state at zero magnetic field and demonstrated dynamical control over topological order parameter.

Conclusion: The findings pave the way for all-optical generation of chiral edge modes and topological quantum circuits, showcasing a new method for controlling quantum matter with light.

Abstract: Controlling quantum matter with light offers a promising route to dynamically
tune its many-body properties, ranging from band topology to superconductivity.
However, achieving such optical control for strongly correlated electron
systems in the steady-state has remained elusive. Here, we demonstrate
all-optical switching of the spin-valley degree of freedom of itinerant
ferromagnets in twisted MoTe2 homobilayers. This system uniquely features flat
valley-contrasting Chern bands and exhibits a range of strongly correlated
phases at various moir\'e lattice fillings, including Chern insulators and
ferromagnetic metals. We show that the spin-valley orientation of all of these
phases can be dynamically reversed by resonantly exciting the attractive
polaron transition with circularly-polarized light. These findings not only
constitute the first direct evidence for non-thermal switching of a
ferromagnetic spin state at zero magnetic field, but also demonstrate the
possibility of dynamical control over topological order parameter, paving the
way for all-optical generation of chiral edge modes and topological quantum
circuits.

</details>


### [232] [Interferences Measure Topology](https://arxiv.org/abs/2508.19128)
*Yuval Abulafia,Eric Akkermans*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种通过分析局部电子密度$ho$和连接其与Atiyah-Singer指数定理来识别拓扑材料的新方法，能够直接测量缠绕数，从而为探测和表征量子拓扑态提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 大多数拓扑材料的拓扑不变量与其可观测量之间的联系未知，阻碍了对其拓扑性质的直接验证。

Method: 提出了一种通过分析局部电子密度$ho$并利用阿蒂亚-辛格指数定理来识别拓扑材料的通用方法，该方法通过$ho$的无依赖性移位模式来直接测量缠绕数。

Result: 该方法能够直接测量缠绕数，这是具有手征对称性的哈密顿量的拓扑不变量。

Conclusion: 该方法为探测和表征量子拓扑态提供了一条直接途径，有望将其用作量子技术中稳健且可纠缠的构件。

Abstract: Topological materials are characterized by integer invariants that underpin
their robust quantized electronic features, as famously exemplified by the
Chern number in the integer quantum Hall effect. Yet, in most candidate
systems, the observable linked to the topological invariant is unknown,
preventing direct verification of their topological nature. Here we present a
general method to identify topological materials by analyzing the local
electronic density, $\delta \rho(\boldsymbol{r})$, and connecting it to Atiyah
Singer index theorems. This approach enables a direct measurement of the
winding number, the topological invariant of Hamiltonians with chiral symmetry,
through a contour independent dislocation pattern of $\delta
\rho(\boldsymbol{r})$ created by interference from topological defects. Our
method thus provides a direct route to detect and characterize quantum
topological states, paving the way for their use as robust and entangleable
building blocks in quantum technologies.

</details>


### [233] [Measuring high field gradients of cobalt nanomagnets in a spin-mechanical setup](https://arxiv.org/abs/2508.19156)
*Felix Hahne,Teresa Klara Pfau,Liza Žaper,Lucio Stefan,Thibault Capelle,Andrea Ranfagni,Martino Poggio,Albert Schliesser*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Hybrid systems composed of a single nitrogen-vacancy center spin magnetically
coupled to a macroscopic mechanical resonator constitute promising platforms
for the realization of quantum information protocols and for quantum sensing
applications. The magnetic structure that mediates the interaction must ensure
high field gradients while preserving the spin and mechanical properties. We
present a spin-mechanical setup built around a cobalt nanomagnet grown with
focused electron beam-induced deposition. The magnetic structure is fully
characterized, and a maximum gradient of $170\,\mathrm{kT/m}$ is directly
measured at a spin-oscillator distance of a few hundred nanometers. Spin
coherence was preserved at the value of $20\,\mathrm{ \mu s}$ up to a gradient
of $25\,\mathrm{kT/m}$. The effect of the mechanical motion onto the spin
dynamics was observed, thus signifying the presence of spin-mechanics coupling.
Given the noninvasive nature of the nanomagnet deposition process, we foresee
the adoption of such structures in hybrid platforms with high-quality factor
resonators, in the "magnet on oscillator" configuration.

</details>


### [234] [The charge-carrier trapping effect on 1/f noise in monolayer graphene](https://arxiv.org/abs/2508.19161)
*K. A. Kazakov,T. M. Valitov*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯-氮化硼异质结构中1/f噪声的频率指数在电荷载流子浓度依赖性方面有多个极值，这归因于氮化硼中杂质对载流子的俘获。通过推导受俘获和声子相互作用影响的载流子动力学方程，并进行数值求解，根据1/f噪声的量子理论评估频率指数，发现当俘获概率足够宽且具有能级阈值时，频率指数确实会出现多个极值。


<details>
  <summary>Details</summary>
Motivation: 解释石墨烯-氮化硼异质结构中1/f噪声频率指数在电荷载流子浓度依赖性方面出现多个极值的原因。

Method: 推导了受俘获和声子相互作用影响的载流子动力学方程，并进行数值求解，然后根据1/f噪声的量子理论评估频率指数。

Result: 频率指数确实会出现多个极值，前提是俘获概率足够宽且具有能级阈值。

Conclusion: 所得结果与实验数据进行了详细比较，并用于估算能量阈值和俘获截面。

Abstract: The frequency exponent of 1/f noise in graphene-boron nitride
heterostructures is known to have multiple extrema in its dependence on the
charge carrier concentration. This behavior is explained in the present paper
as a result of the charge carrier trapping by impurities in the boron nitride.
A kinetic equation for the charge carriers subject to trapping and interacting
with acoustic phonons is derived. This equation is solved numerically, and the
equilibrium solutions are used to evaluate the frequency exponent according to
the quantum theory of 1/f noise. It is found that the frequency exponent does
develop several minima and maxima, provided that the trapping probability is
sufficiently wide and has a threshold with respect to the charge carrier
energy. A detailed comparison with the experimental data is made, and the
results are used to estimate the energy threshold and the trapping
cross-section.

</details>


### [235] [Phase Coherent Transport in Two-Dimensional Tellurium Flakes](https://arxiv.org/abs/2508.19241)
*Mohammad Hafijur Rahaman,Nathan Sawyers,Mourad Benamara,Trudie Culverhouse,Repaka Maheswar,Qiyuan He,Hugh Churchill,Dharmraj Kotekar Patil*

Main category: cond-mat.mes-hall

TL;DR: 本研究展示了高质量的碲（Te）薄片，实现了高达1000 cm²/V.s的空穴迁移率，并在低温下观察到库仑阻塞和法布里-珀罗干涉等量子输运现象，表明其在拓扑超导和自旋电子学等领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 元素碲（Te）是一种具有特殊手性晶体结构和预测拓扑性质的范德华材料。

Method: 制备了不同厚度的Te薄片器件，并进行了全面的量子输运研究，包括在不同温度和磁场下的电输运特性测量。

Result: 在17 nm厚的Te薄片中，在30 K下观察到高达1000 cm²/V.s的空穴迁移率。在低于50 mK的深低温下，输运特性从低载流子密度的库仑阻塞过渡到高密度的显著法布里-珀罗（F-P）干涉。在较薄的Te薄片器件中，F-P干涉的可见度显著增强。磁场作用下，电导峰表现出清晰的塞曼分裂。

Conclusion: 观察到的丰富量子输运现象证明了本研究制备的Te薄片具有高质量，并为探索拓扑超导和低功耗自旋电子学等新物理和器件概念提供了一个有前途的平台。

Abstract: Elemental tellurium (Te) is a compelling van der Waals material due to its
interesting chiral crystal structure and predicted topological properties.
Here, we report the fabrication and comprehensive quantum transport study of
devices based on Te flakes with varying thicknesses. We demonstrate a hole
mobility reaching up to 1000 cm2/V.s in a 17 nm thick flake at 30 Kelvin. At
deep cryogenic temperatures (< 50mK), the transport characteristics transition
from Coulomb blockade in the low carrier density regime to pronounced
Fabry-P\'erot (F-P) interference at higher densities. Notably, the visibility
of these F-P oscillations is significantly enhanced in the thinner flake
device. The application of a magnetic field reveals a clear Zeeman splitting of
the conductance peaks. The rich variety of quantum transport phenomena observed
underscores the high quality of our thin Te flakes and establishes them as a
promising platform for exploring novel physics and device concepts, such as
topological superconductivity and low-power spintronic applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [236] [Reasoning Steps as Curriculum: Using Depth of Thought as a Difficulty Signal for Tuning LLMs](https://arxiv.org/abs/2508.18279)
*Jeesu Jung,Sangkeun Jung*

Main category: cs.LG

TL;DR: 该研究提出了一种基于“思考深度”（DoT）的课程学习方法，用于训练大型语言模型（LLM），以提升其推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有课程学习方法在LLM推理训练中对可扩展、可解释的难度信号的依赖，研究者提出了一个核心假设：人类需要更深思考步骤的任务，对于模型也应该更难。

Method: 该研究将“思考深度”（DoT）定义为教师模型推理过程中的离散步骤数量（例如，思维链），并以此为依据构建了从浅到深的课程学习策略。研究还阐述了如何在规模化应用中推导、验证和调度该策略。

Result: 研究提出了三个可检验的假设：1. DoT与传统推理基准的难度相关；2. 在相同预算下，DoT排序的课程优于基于长度或评分的课程；3. 只要有适当的格式控制，DoT的难度评估在不同教师模型上是稳健的。研究还提出了一个评估框架，并讨论了可能影响结果的因素（如教师模型风格、长度混淆）及其缓解方法。

Conclusion: 该研究旨在推动基于认知、可解释的课程学习方法在以推理为中心的LLM训练中的应用。

Abstract: Curriculum learning for training LLMs requires a difficulty signal that
aligns with reasoning while remaining scalable and interpretable. We propose a
simple premise: tasks that demand deeper depth of thought for humans should
also be harder for models. Accordingly, we define difficulty as depth of
thought (DoT) and operationalize it by counting the discrete steps in a teacher
model's reasoning trace (e.g., Chain-of-Thought). We then train with a shallow
to deep curriculum ordered by this DoT and outline how to derive, validate, and
schedule it at scale. Our position yields three testable hypotheses: (i) DoT
correlates with conventional difficulty on reasoning benchmarks, (ii)
DoT-ordered curricula outperform length- or judge-scored curricula under
matched budgets, and (iii) the difficulty is robust across teacher models given
light formatting controls. We propose an evaluation framework and discuss
threats to validity (teacher style, length confounds) alongside practical
mitigations. Taken together, we aim to move toward cognitively grounded,
interpretable curricula for reasoning-centric training.

</details>


### [237] [Quantifying The Limits of AI Reasoning: Systematic Neural Network Representations of Algorithms](https://arxiv.org/abs/2508.18526)
*Anastasis Kratsios,Dennis Zvigelsky,Bradd Hart*

Main category: cs.LG

TL;DR: 神经网络可以通过电路仿真来执行任意推理任务，并且这种仿真比传统的通用逼近定理更强大。


<details>
  <summary>Details</summary>
Motivation: AI研究中的一个核心问题是量化完美训练的神经网络所能执行的推理形式。

Method: 将推理任务解释为电路仿真，其中门控单元定义了推理的类型。我们提出了一个系统性的元算法，通过迭代地用标准的ReLU MLP模拟器替换每个门来将任何电路转换为具有ReLU激活的前馈神经网络。

Result: 所提出的方法可以精确地模拟电路（包括模块溢出），而不存在近似或舍入误差。由此产生的神经网络的神经元数量（参数复杂度）与电路的复杂度成比例，网络的计算图（结构）反映了被模拟电路的结构。这证明了神经网络可以在推理能力上无所不能。

Conclusion: 所提出的方法不仅可以用于模拟各种算法（如最短路径算法和停止的图灵机），而且比传统的通用逼近定理更强大，因为任何通用函数逼近器都可以被编码为电路并被神经网络直接模拟。

Abstract: A main open question in contemporary AI research is quantifying the forms of
reasoning neural networks can perform when perfectly trained. This paper
answers this by interpreting reasoning tasks as circuit emulation, where the
gates define the type of reasoning; e.g. Boolean gates for predicate logic,
tropical circuits for dynamic programming, arithmetic and analytic gates for
symbolic mathematical representation, and hybrids thereof for deeper reasoning;
e.g. higher-order logic.
  We present a systematic meta-algorithm that converts essentially any circuit
into a feedforward neural network (NN) with ReLU activations by iteratively
replacing each gate with a canonical ReLU MLP emulator. We show that, on any
digital computer, our construction emulates the circuit exactly--no
approximation, no rounding, modular overflow included--demonstrating that no
reasoning task lies beyond the reach of neural networks. The number of neurons
in the resulting network (parametric complexity) scales with the circuit's
complexity, and the network's computational graph (structure) mirrors that of
the emulated circuit. This formalizes the folklore that NNs networks trade
algorithmic run-time (circuit runtime) for space complexity (number of
neurons).
  We derive a range of applications of our main result, from emulating
shortest-path algorithms on graphs with cubic--size NNs, to simulating stopped
Turing machines with roughly quadratically--large NNs, and even the emulation
of randomized Boolean circuits. Lastly, we demonstrate that our result is
strictly more powerful than a classical universal approximation theorem: any
universal function approximator can be encoded as a circuit and directly
emulated by a NN.

</details>


### [238] [Multi-Modal Drift Forecasting of Leeway Objects via Navier-Stokes-Guided CNN and Sequence-to-Sequence Attention-Based Models](https://arxiv.org/abs/2508.18284)
*Rahmat K. Adesunkanmi,Alexander W. Brandt,Masoud Deylami,Gustavo A. Giraldo Echeverri,Hamidreza Karbasian,Adel Alaeddini*

Main category: cs.LG

TL;DR: 提出了一种多模态机器学习框架，结合了句子Transformer嵌入和基于注意力机制的序列到序列架构，用于预测海上物体漂移轨迹。


<details>
  <summary>Details</summary>
Motivation: 准确预测海上物体漂移（位移）是一个关键挑战，尤其是在搜救等对时间敏感的场景中。

Method: 收集环境和物理数据（水流、风速、物体质量、表面积），使用基于Navier-Stokes模型的模拟数据训练CNN估计阻力和升力系数，然后将这些系数、环境数据、物体特征以及通过语言模型编码的文本描述作为输入，用于训练基于注意力机制的seq2seq LSTM和Transformer模型来预测漂移轨迹。

Result: 与传统模型（如RNN、TCN）和基于物理的模型相比，所提出的多模态模型在预测精度上相当，并且能够进行更长期的预测，而不仅仅是单步预测。

Conclusion: 多模态建模策略能够准确且适应性地预测动态海上条件下的物体漂移。

Abstract: Accurately predicting the drift (displacement) of leeway objects in maritime
environments remains a critical challenge, particularly in time-sensitive
scenarios such as search and rescue operations. In this study, we propose a
multi-modal machine learning framework that integrates Sentence Transformer
embeddings with attention-based sequence-to-sequence architectures to predict
the drift of leeway objects in water. We begin by experimentally collecting
environmental and physical data, including water current and wind velocities,
object mass, and surface area, for five distinct leeway objects. Using
simulated data from a Navier-Stokes-based model to train a convolutional neural
network on geometrical image representations, we estimate drag and lift
coefficients of the leeway objects. These coefficients are then used to derive
the net forces responsible for driving the objects' motion. The resulting time
series, comprising physical forces, environmental velocities, and
object-specific features, combined with textual descriptions encoded via a
language model, are inputs to attention-based sequence-to-sequence
long-short-term memory and Transformer models, to predict future drift
trajectories. We evaluate the framework across multiple time horizons ($1$,
$3$, $5$, and $10$ seconds) and assess its generalization across different
objects. We compare our approach against a fitted physics-based model and
traditional machine learning methods, including recurrent neural networks and
temporal convolutional neural networks. Our results show that these multi-modal
models perform comparably to traditional models while also enabling longer-term
forecasting in place of single-step prediction. Overall, our findings
demonstrate the ability of a multi-modal modeling strategy to provide accurate
and adaptable predictions of leeway object drift in dynamic maritime
conditions.

</details>


### [239] [Metric Matters: A Formal Evaluation of Similarity Measures in Active Learning for Cyber Threat Intelligence](https://arxiv.org/abs/2508.19019)
*Sidahmed Benabderrahmane,Talal Rahwan*

Main category: cs.LG

TL;DR: 主动学习框架通过相似性搜索改进APT检测中的异常检测。


<details>
  <summary>Details</summary>
Motivation: APTs的隐蔽行为和检测数据集中的类别不平衡给网络防御带来严峻挑战。

Method: 提出一种基于主动学习的异常检测框架，利用基于注意力机制的自编码器和特征空间相似性来识别正常和异常实例，从而以最小的监督来提高模型鲁棒性。此外，还对不同的相似性度量进行了形式化评估。

Result: 实验表明，相似性度量的选择显著影响模型的收敛性、异常检测准确率和标签效率。DARPA透明计算APT追踪等数据集上的结果证实了这一点。

Conclusion: 所提出的框架为在针对威胁情报和网络防御的主动学习流程中选择相似性函数提供了可行的见解。

Abstract: Advanced Persistent Threats (APTs) pose a severe challenge to cyber defense
due to their stealthy behavior and the extreme class imbalance inherent in
detection datasets. To address these issues, we propose a novel active
learning-based anomaly detection framework that leverages similarity search to
iteratively refine the decision space. Built upon an Attention-Based
Autoencoder, our approach uses feature-space similarity to identify normal-like
and anomaly-like instances, thereby enhancing model robustness with minimal
oracle supervision. Crucially, we perform a formal evaluation of various
similarity measures to understand their influence on sample selection and
anomaly ranking effectiveness. Through experiments on diverse datasets,
including DARPA Transparent Computing APT traces, we demonstrate that the
choice of similarity metric significantly impacts model convergence, anomaly
detection accuracy, and label efficiency. Our results offer actionable insights
for selecting similarity functions in active learning pipelines tailored for
threat intelligence and cyber defense.

</details>


### [240] [Data-driven models for production forecasting and decision supporting in petroleum reservoirs](https://arxiv.org/abs/2508.18289)
*Mateus A. Fernandes,Michael M. Furlanetti,Eduardo Gildin,Marcio A. Sampaio*

Main category: cs.LG

TL;DR: 该项目提出了一种数据驱动的机器学习方法，用于预测油藏生产参数，无需依赖地质模型或流体性质。


<details>
  <summary>Details</summary>
Motivation: 预测油藏生产并预见油藏系统行为变化是石油油藏工程中的主要挑战。

Method: 研究了基于回归和神经网络的监督学习方法，并评估了其性能和复杂性。此外，还研究了概念漂移问题，包括观测窗口和再训练周期。

Result: 开发了一种可靠的预测器，可以重现油藏动力学，具有快速响应能力，能够处理实际困难，并可用于油藏管理。

Conclusion: 该方法有望通过预测不利行为、优化生产和注入参数以及分析概率事件的影响来最大化石油采收率。

Abstract: Forecasting production reliably and anticipating changes in the behavior of
rock-fluid systems are the main challenges in petroleum reservoir engineering.
This project proposes to deal with this problem through a data-driven approach
and using machine learning methods. The objective is to develop a methodology
to forecast production parameters based on simple data as produced and injected
volumes and, eventually, gauges located in wells, without depending on
information from geological models, fluid properties or details of well
completions and flow systems. Initially, we performed relevance analyses of the
production and injection variables, as well as conditioning the data to suit
the problem. As reservoir conditions change over time, concept drift is a
priority concern and require special attention to those observation windows and
the periodicity of retraining, which are also objects of study. For the
production forecasts, we study supervised learning methods, such as those based
on regressions and Neural Networks, to define the most suitable for our
application in terms of performance and complexity. In a first step, we
evaluate the methodology using synthetic data generated from the UNISIM III
compositional simulation model. Next, we applied it to cases of real plays in
the Brazilian pre-salt. The expected result is the design of a reliable
predictor for reproducing reservoir dynamics, with rapid response, capability
of dealing with practical difficulties such as restrictions in wells and
processing units, and that can be used in actions to support reservoir
management, including the anticipation of deleterious behaviors, optimization
of production and injection parameters and the analysis of the effects of
probabilistic events, aiming to maximize oil recovery.

</details>


### [241] [A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach](https://arxiv.org/abs/2508.18301)
*Md Sabbir Ahmed,Nova Ahmed*

Main category: cs.LG

TL;DR: 该研究开发了一个快速、简约的系统，仅用1秒钟的APP使用数据就能识别抑郁症，准确率达82.4%，特别适用于资源匮乏地区。


<details>
  <summary>Details</summary>
Motivation: 现有基于设备的抑郁症检测系统需要长期数据收集，在需要早期检测的情况下效果不佳。本研究旨在开发一个能在最短时间内识别抑郁症的简约系统。

Method: 开发了一个能在1秒内检索过去7天APP使用数据的工具，并收集了100名孟加拉国学生的APP使用数据。使用多种机器学习模型和特征选择方法（包括稳定方法和Boruta）来识别抑郁和非抑郁学生，并进行SHAP分析以识别行为标记。

Result: 使用APP使用数据，结合稳定特征选择的梯度提升机模型，抑郁症识别准确率达到82.4%（精确率75%，F1分数78.5%）。基于Boruta特征选择的堆叠模型（约5个特征）最高精确率达到77.4%（平衡准确率77.9%）。SHAP分析揭示了与抑郁症相关的行为标记。

Conclusion: 该系统因其快速和简约的特性，可能为欠发达和发展中地区的抑郁症识别做出贡献。研究结果和讨论有助于开发资源需求更少的系统，以更好地理解抑郁学生。

Abstract: Background: Existing robust, pervasive device-based systems developed in
recent years to detect depression require data collected over a long period and
may not be effective in cases where early detection is crucial.
  Objective: Our main objective was to develop a minimalistic system to
identify depression using data retrieved in the fastest possible time.
  Methods: We developed a fast tool that retrieves the past 7 days' app usage
data in 1 second (mean 0.31, SD 1.10 seconds). A total of 100 students from
Bangladesh participated in our study, and our tool collected their app usage
data. To identify depressed and nondepressed students, we developed a diverse
set of ML models. We selected important features using the stable approach,
along with 3 main types of feature selection (FS) approaches.
  Results: Leveraging only the app usage data retrieved in 1 second, our light
gradient boosting machine model used the important features selected by the
stable FS approach and correctly identified 82.4% (n=42) of depressed students
(precision=75%, F1-score=78.5%). Moreover, after comprehensive exploration, we
presented a parsimonious stacking model where around 5 features selected by the
all-relevant FS approach Boruta were used in each iteration of validation and
showed a maximum precision of 77.4% (balanced accuracy=77.9%). A SHAP analysis
of our best models presented behavioral markers that were related to
depression.
  Conclusions: Due to our system's fast and minimalistic nature, it may make a
worthwhile contribution to identifying depression in underdeveloped and
developing regions. In addition, our detailed discussion about the implication
of our findings can facilitate the development of less resource-intensive
systems to better understand students who are depressed.

</details>


### [242] [Learning Explainable Imaging-Genetics Associations Related to a Neurological Disorder](https://arxiv.org/abs/2508.18303)
*Jueqi Wang,Zachary Jacokes,John Darrell Van Horn,Michael C. Schatz,Kevin A. Pelphrey,Archana Venkataraman*

Main category: cs.LG

TL;DR: NeuroPathX是一个可解释的深度学习框架，用于分析神经影像学和遗传学数据，以揭示大脑结构与遗传变异之间复杂的相互作用，并在自闭症谱系障碍和阿尔茨海默氏病中表现出优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的影像学-遗传学方法在揭示大脑结构和遗传变异在神经系统疾病中的复杂相互作用方面，受限于简化的线性模型或缺乏可解释性的黑盒技术。

Method: 该研究提出了NeuroPathX框架，它利用交叉注意力机制的早期融合策略，捕捉MRI衍线的大脑结构变异与遗传学数据衍线生物通路之间的相互作用。为了提高可解释性和鲁棒性，引入了两种作用于注意力矩阵的损失函数：一种是关注最显著相互作用的稀疏性损失，另一种是强制跨队列表示一致性的通路相似性损失。

Result: NeuroPathX在自闭症谱系障碍和阿尔茨海默氏病的数据集上进行了验证，结果表明其性能优于基线方法，并揭示了与疾病相关的、具有生物学意义的关联。

Conclusion: NeuroPathX有潜力促进对复杂大脑疾病的理解。

Abstract: While imaging-genetics holds great promise for unraveling the complex
interplay between brain structure and genetic variation in neurological
disorders, traditional methods are limited to simplistic linear models or to
black-box techniques that lack interpretability. In this paper, we present
NeuroPathX, an explainable deep learning framework that uses an early fusion
strategy powered by cross-attention mechanisms to capture meaningful
interactions between structural variations in the brain derived from MRI and
established biological pathways derived from genetics data. To enhance
interpretability and robustness, we introduce two loss functions over the
attention matrix - a sparsity loss that focuses on the most salient
interactions and a pathway similarity loss that enforces consistent
representations across the cohort. We validate NeuroPathX on both autism
spectrum disorder and Alzheimer's disease. Our results demonstrate that
NeuroPathX outperforms competing baseline approaches and reveals biologically
plausible associations linked to the disorder. These findings underscore the
potential of NeuroPathX to advance our understanding of complex brain
disorders. Code is available at https://github.com/jueqiw/NeuroPathX .

</details>


### [243] [SALMAN: Stability Analysis of Language Models Through the Maps Between Graph-based Manifolds](https://arxiv.org/abs/2508.18306)
*Wuxinlin Cheng,Yupeng Cao,Jinwen Wu,Koduvayur Subbalakshmi,Tian Han,Zhuo Feng*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SALMAN的统一、局部鲁棒性框架，用于评估和提高基于Transformer的NLP模型的稳定性。该框架不修改模型内部参数，也不依赖复杂的扰动启发式方法，而是通过一种名为距离映射失真（DMD）的新度量来评估模型稳定性，该度量以近乎线性的复杂度对样本进行排序。实验表明，SALMAN在提高攻击效率和鲁棒训练方面取得了显著的收益，是一种实用且模型无关的工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的鲁棒性在输入扰动下是一个日益紧迫的问题，而现有的鲁棒性方法在小参数模型和大模型之间存在分歧，并且通常依赖于耗时且针对特定样本的对抗性设计。

Method: 提出了一种名为SALMAN的统一、局部鲁棒性框架，该框架通过一种名为距离映射失真（DMD）的新度量来评估模型稳定性，该度量通过比较输入到输出的距离映射来对样本的易感性进行排序，其复杂度接近线性。

Result: SALMAN框架在提高攻击效率和鲁棒训练方面取得了显著收益。

Conclusion: SALMAN框架是一种实用且模型无关的工具，能够提高基于Transformer的NLP系统的可靠性。

Abstract: Recent strides in pretrained transformer-based language models have propelled
state-of-the-art performance in numerous NLP tasks. Yet, as these models grow
in size and deployment, their robustness under input perturbations becomes an
increasingly urgent question. Existing robustness methods often diverge between
small-parameter and large-scale models (LLMs), and they typically rely on
labor-intensive, sample-specific adversarial designs. In this paper, we propose
a unified, local (sample-level) robustness framework (SALMAN) that evaluates
model stability without modifying internal parameters or resorting to complex
perturbation heuristics. Central to our approach is a novel Distance Mapping
Distortion (DMD) measure, which ranks each sample's susceptibility by comparing
input-to-output distance mappings in a near-linear complexity manner. By
demonstrating significant gains in attack efficiency and robust training, we
position our framework as a practical, model-agnostic tool for advancing the
reliability of transformer-based NLP systems.

</details>


### [244] [Learning Spatio-Temporal Dynamics via Operator-Valued RKHS and Kernel Koopman Methods](https://arxiv.org/abs/2508.18307)
*Mahishanka Withanachchi*

Main category: cs.LG

TL;DR: 使用算子值再生核希尔伯特空间（OV-RKHS）结合基于核的库普曼算子方法，提出一个统一框架，用于学习向量值函数的时空动力学，实现对复杂随时间演变的向量场的非参数、数据驱动估计，同时保留时空结构。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提供一个统一的框架，用于学习向量值函数的时空动力学。

Method: 通过结合算子值再生核希尔伯特空间（OV-RKHS）和基于核的库普曼算子方法，实现对复杂时间演变向量场的非参数和数据驱动估计，同时保留时空结构。推导了时间依赖OV-RKHS插值的表示定理，以及光滑向量场的Sobolev型近似界和核库普曼算子近似的光谱收敛保证。

Result: 该框架支持高效的降阶建模和高维非线性系统的长期预测。

Conclusion: 该框架为时空机器学习中的预测、控制和不确定性量化提供了理论支持的工具。

Abstract: We introduce a unified framework for learning the spatio-temporal dynamics of
vector valued functions by combining operator valued reproducing kernel Hilbert
spaces (OV-RKHS) with kernel based Koopman operator methods. The approach
enables nonparametric and data driven estimation of complex time evolving
vector fields while preserving both spatial and temporal structure. We
establish representer theorems for time dependent OV-RKHS interpolation, derive
Sobolev type approximation bounds for smooth vector fields, and provide
spectral convergence guarantees for kernel Koopman operator approximations.
This framework supports efficient reduced order modeling and long term
prediction of high dimensional nonlinear systems, offering theoretically
grounded tools for forecasting, control, and uncertainty quantification in
spatio-temporal machine learning.

</details>


### [245] [DualSparse-MoE: Coordinating Tensor/Neuron-Level Sparsity with Expert Partition and Reconstruction](https://arxiv.org/abs/2508.18376)
*Weilin Cai,Le Qin,Shwai He,Junwei Cui,Ang Li,Jiayi Huang*

Main category: cs.LG

TL;DR: Mixture of Experts (MoE) is a popular LLM architecture for efficiency, but faces challenges with scale and activation. This paper introduces post-training expert partitioning to induce dual sparsity (tensor and neuron levels) without retraining, preserving mathematical consistency and improving efficiency and accuracy. The proposed DualSparse-MoE system integrates dynamic computation dropping and static reconstruction for significant efficiency gains with minimal accuracy loss. Experiments show ~25% drop rate reduces accuracy by only 0.08%-0.28% across MoE models, with proportional speedups. Load-imbalance awareness in expert parallelism achieves 1.41x MoE module speedup with 0.5% accuracy degradation.


<details>
  <summary>Details</summary>
Motivation: Mixture of Experts (MoE) architecture in LLMs offers efficiency by reducing per-token computation but suffers from challenges related to massive scale and unpredictable activation patterns. There is a need for efficient MoE deployment strategies.

Method: The paper identifies dual sparsity (tensor and neuron levels) in pre-trained MoE modules as crucial for accuracy and efficiency. It proposes a post-training expert partitioning method to induce tensor-level sparsity without retraining, maintaining mathematical consistency. The DualSparse-MoE system is introduced, integrating dynamic tensor-level computation dropping with static neuron-level reconstruction to enhance efficiency. Load-imbalance awareness is incorporated into expert parallelism for further speedup.

Result: Enforcing an approximate 25% drop rate with DualSparse-MoE reduces average accuracy by only 0.08%-0.28% across three MoE models, while achieving proportional computational speedups. Incorporating load-imbalance awareness resulted in a 1.41x MoE module speedup with only 0.5% average accuracy degradation.

Conclusion: Post-training expert partitioning to induce dual sparsity is an effective strategy for improving MoE efficiency and accuracy without retraining. The DualSparse-MoE system demonstrates significant efficiency gains with minimal accuracy loss, and load-imbalance aware expert parallelism further enhances performance.

Abstract: Mixture of Experts (MoE) has become a mainstream architecture for building
Large Language Models (LLMs) by reducing per-token computation while enabling
model scaling. It can be viewed as partitioning a large Feed-Forward Network
(FFN) at the tensor level into fine-grained sub-FFNs, or experts, and
activating only a sparse subset for each input. While this sparsity improves
efficiency, MoE still faces substantial challenges due to their massive
computational scale and unpredictable activation patterns.
  To enable efficient MoE deployment, we identify dual sparsity at the tensor
and neuron levels in pre-trained MoE modules as a key factor for both accuracy
and efficiency. Unlike prior work that increases tensor-level sparsity through
finer-grained expert design during pre-training, we introduce post-training
expert partitioning to induce such sparsity without retraining. This preserves
the mathematical consistency of model transformations and enhances both
efficiency and accuracy in subsequent fine-tuning and inference. Building upon
this, we propose DualSparse-MoE, an inference system that integrates dynamic
tensor-level computation dropping with static neuron-level reconstruction to
deliver significant efficiency gains with minimal accuracy loss.
  Experimental results show that enforcing an approximate 25% drop rate with
our approach reduces average accuracy by only 0.08%-0.28% across three
prevailing MoE models, while nearly all degrees of computation dropping
consistently yield proportional computational speedups. Furthermore,
incorporating load-imbalance awareness into expert parallelism achieves a 1.41x
MoE module speedup with just 0.5% average accuracy degradation.

</details>


### [246] [CoPE: A Lightweight Complex Positional Encoding](https://arxiv.org/abs/2508.18308)
*Avinash Amballa*

Main category: cs.LG

TL;DR: CoPE是一种新的基于复数的Transformer位置编码方法，它将语义内容和位置信息编码在复数的实部和虚部，并通过相位感知注意力机制来捕获位置依赖模式，在GLUE基准测试中表现优于现有方法且计算复杂度更低。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中的位置编码对于建模序列中不同位置的元素依赖关系至关重要。

Method: 提出了一种名为CoPE（轻量级复数位置编码）的新型架构，它使用复数编码来同时编码内容和位置信息，其中实部捕捉语义内容，虚部编码位置信息。在Transformer的第一层引入了相位感知注意力机制来捕获位置依赖模式，后续层使用标准注意力机制。

Result: CoPE不表现出长期衰减，并且与线性注意力兼容。在GLUE基准测试上的实验评估表明，与RoPE、Sinusoidal和Learned位置编码相比，CoPE实现了更高的性能和更低的计算复杂度。

Conclusion: CoPE是一种有效且计算效率高的新型位置编码方法，适用于Transformer模型。

Abstract: Recent studies have demonstrated the effectiveness of position encoding in
transformer architectures. By incorporating positional information, this
approach provides essential guidance for modeling dependencies between elements
across different sequence positions. We introduce CoPE (a lightweight Complex
Positional Encoding), a novel architecture that leverages complex-valued
encoding to encode both content and positional information. Our approach
replaces traditional positional encodings with complex embeddings where the
real part captures semantic content and the imaginary part encodes positional
information. We introduce phase-aware attention in the first layer of the
transformer model to capture position-dependent patterns, followed by standard
attention layers for higher-levels. We show that CoPE doesn't exhibit long term
decay and is compatible with linear attention. Experimental evaluation on the
GLUE benchmark suggest that our approach achieves superior performance with
less computational complexity, compared to RoPE, Sinusoidal and Learned
positional encodings.

</details>


### [247] [History Rhymes: Accelerating LLM Reinforcement Learning with RhymeRL](https://arxiv.org/abs/2508.18588)
*Jingkai He,Tianjian Li,Erhu Feng,Dong Du,Qian Liu,Tao Liu,Yubin Xia,Haibo Chen*

Main category: cs.LG

TL;DR: RhymeRL通过利用历史回滚序列的相似性，引入HistoSpec和HistoPipe技术，解决了LLM RL训练中的GPU利用率低下和回滚气泡问题，实现了2.6倍的性能提升，且不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM RL系统存在GPU利用率低的问题，主要是由于回滚阶段的测试时扩展以及回滚长度不平衡导致的GPU气泡。此前的解决方案在效率和准确性之间存在权衡。

Method: RhymeRL系统包含两个关键创新：1. HistoSpec：一种投机解码推理引擎，利用历史回滚令牌序列的相似性来生成准确的草稿，以提高回滚生成效率。2. HistoPipe：一种两层调度策略，利用历史回滚分布的相似性来平衡回滚工作负载，以解决回滚气泡问题。

Result: RhymeRL在生产环境中进行了评估，能够从几十个GPU扩展到数千个GPU。实验结果表明，RhymeRL的性能比现有方法提高了2.6倍，同时没有损害准确性或改变RL范式。

Conclusion: RhymeRL通过利用历史回滚序列的相似性，解决了LLM RL训练中的GPU利用率低和回滚气泡问题，显著提高了训练效率和GPU利用率，且不影响模型的准确性。

Abstract: With the rapid advancement of large language models (LLMs), reinforcement
learning (RL) has emerged as a pivotal methodology for enhancing the reasoning
capabilities of LLMs. Unlike traditional pre-training approaches, RL
encompasses multiple stages: rollout, reward, and training, which necessitates
collaboration among various worker types. However, current RL systems continue
to grapple with substantial GPU underutilization, due to two primary factors:
(1) The rollout stage dominates the overall RL process due to test-time
scaling; (2) Imbalances in rollout lengths (within the same batch) result in
GPU bubbles. While prior solutions like asynchronous execution and truncation
offer partial relief, they may compromise training accuracy for efficiency.
  Our key insight stems from a previously overlooked observation: rollout
responses exhibit remarkable similarity across adjacent training epochs. Based
on the insight, we introduce RhymeRL, an LLM RL system designed to accelerate
RL training with two key innovations. First, to enhance rollout generation, we
present HistoSpec, a speculative decoding inference engine that utilizes the
similarity of historical rollout token sequences to obtain accurate drafts.
Second, to tackle rollout bubbles, we introduce HistoPipe, a two-tier
scheduling strategy that leverages the similarity of historical rollout
distributions to balance workload among rollout workers. We have evaluated
RhymeRL within a real production environment, demonstrating scalability from
dozens to thousands of GPUs. Experimental results demonstrate that RhymeRL
achieves a 2.6x performance improvement over existing methods, without
compromising accuracy or modifying the RL paradigm.

</details>


### [248] [What Matters in Data for DPO?](https://arxiv.org/abs/2508.18312)
*Yu Pan,Zhongze Cai,Guanting Chen,Huaiyang Zhong,Chonghuan Wang*

Main category: cs.LG

TL;DR: DPO性能的关键在于被选样本的质量，而非被拒样本的质量，理论与实验均证实了这一点。


<details>
  <summary>Details</summary>
Motivation: 探究影响DPO性能的关键偏好数据特征。

Method: 通过理论分析和大量实验，研究偏好数据分布对DPO的影响，特别是被选和被拒样本的质量及对比度。

Result: DPO优化目标主要受被选样本质量驱动，被拒样本质量影响有限。在线DPO等同于对被选样本进行监督微调。提升被选样本质量可稳定提升性能。

Conclusion: 被选样本的质量是DPO成功的关键，这为构建高效的LLM对齐偏好数据集提供了实践指导。

Abstract: Direct Preference Optimization (DPO) has emerged as a simple and effective
approach for aligning large language models (LLMs) with human preferences,
bypassing the need for a learned reward model. Despite its growing adoption, a
fundamental question remains open: what characteristics of preference data are
most critical for DPO performance? In this work, we provide a systematic study
of how preference data distribution influences DPO, from both theoretical and
empirical perspectives. We show that the quality of chosen responses plays a
dominant role in optimizing the DPO objective, while the quality of rejected
responses may have relatively limited impact. Our theoretical analysis
characterizes the optimal response distribution under DPO and reveals how
contrastiveness between responses helps primarily by improving the chosen
samples. We further study an online DPO setting and show it effectively reduces
to supervised fine-tuning on the chosen responses. Extensive experiments across
diverse tasks confirm our findings: improving the quality of chosen responses
consistently boosts performance regardless of the quality of the rejected
responses. We also investigate the benefit of mixing the on-policy data. Our
results interpret the mechanism behind some widely adopted strategies and offer
practical insights for constructing high-impact preference datasets for LLM
alignment.

</details>


### [249] [FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning](https://arxiv.org/abs/2508.19009)
*Md Anwar Hossen,Fatema Siddika,Wensheng Zhang,Anuj Sharma,Ali Jannesari*

Main category: cs.LG

TL;DR: FedProtoKD通过引入双知识蒸馏和对比学习来解决异构联邦学习中的原型边界收缩问题，提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的异构联邦学习方法在聚合原型时存在最优性不足和原型边界收缩问题，尤其是在模型异构和数据非独立同分布（non-IID）的情况下，影响模型性能。

Method: 提出FedProtoKD，在异构联邦学习设置中，利用客户的对数（logits）和原型特征表示，通过增强的双知识蒸馏机制来提升系统性能。通过基于对比学习的可训练服务器原型，利用类别的自适应原型边界来解决原型边界收缩问题。评估了公共样本的重要性，通过样本原型与其类别代表原型接近度来增强学习性能。

Result: FedProtoKD在各种设置下实现了1.13%到34.13%的平均准确率提升，并且显著优于现有的最先进的异构联邦学习方法。

Conclusion: FedProtoKD通过其提出的方法有效解决了异构联邦学习中的挑战，并在准确率方面取得了显著的改进。

Abstract: Heterogeneous Federated Learning (HFL) has gained attention for its ability
to accommodate diverse models and heterogeneous data across clients.
Prototype-based HFL methods emerge as a promising solution to address
statistical heterogeneity and privacy challenges, paving the way for new
advancements in HFL research. This method focuses on sharing only
class-representative prototypes among heterogeneous clients. However, these
prototypes are often aggregated on the server using weighted averaging, leading
to sub-optimal global knowledge; these cause the shrinking of aggregated
prototypes, which negatively affects the model performance in scenarios when
models are heterogeneous and data distributions are extremely non-IID. We
propose FedProtoKD in a Heterogeneous Federated Learning setting, using an
enhanced dual-knowledge distillation mechanism to improve the system
performance with clients' logits and prototype feature representation. We aim
to resolve the prototype margin-shrinking problem using a contrastive
learning-based trainable server prototype by leveraging a class-wise adaptive
prototype margin. Furthermore, we assess the importance of public samples using
the closeness of the sample's prototype to its class representative prototypes,
which enhances learning performance. FedProtoKD achieved average improvements
of 1.13% up to 34.13% accuracy across various settings and significantly
outperforms existing state-of-the-art HFL methods.

</details>


### [250] [ProtoEHR: Hierarchical Prototype Learning for EHR-based Healthcare Predictions](https://arxiv.org/abs/2508.18313)
*Zi Cai,Yu Liu,Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: ProtoEHR是一个分层原型学习框架，利用EHR数据的多层结构进行医疗预测，提高了准确性、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注EHR数据的孤立组件，限制了预测性能和可解释性。ProtoEHR旨在解决此问题，充分利用EHR数据的多层结构以增强医疗预测。

Method: ProtoEHR利用大型语言模型提取医学代码之间的语义关系，构建医学知识图谱。在此基础上，设计了一个分层表示学习框架，捕捉三个层级（医学代码、住院就诊、患者）的上下文表示，并结合原型信息以提高泛化能力。

Result: 在五个临床任务（死亡率预测、再入院预测、住院时间预测、药物推荐、表型预测）的两个公共数据集上进行评估，ProtoEHR的预测准确性、鲁棒性和可解释性优于现有基线方法。

Conclusion: ProtoEHR能够进行准确、鲁棒且可解释的预测，并能在代码、就诊和患者层面提供可解释的见解，以辅助医疗预测。

Abstract: Digital healthcare systems have enabled the collection of mass healthcare
data in electronic healthcare records (EHRs), allowing artificial intelligence
solutions for various healthcare prediction tasks. However, existing studies
often focus on isolated components of EHR data, limiting their predictive
performance and interpretability. To address this gap, we propose ProtoEHR, an
interpretable hierarchical prototype learning framework that fully exploits the
rich, multi-level structure of EHR data to enhance healthcare predictions. More
specifically, ProtoEHR models relationships within and across three
hierarchical levels of EHRs: medical codes, hospital visits, and patients. We
first leverage large language models to extract semantic relationships among
medical codes and construct a medical knowledge graph as the knowledge source.
Building on this, we design a hierarchical representation learning framework
that captures contextualized representations across three levels, while
incorporating prototype information within each level to capture intrinsic
similarities and improve generalization. To perform a comprehensive assessment,
we evaluate ProtoEHR in two public datasets on five clinically significant
tasks, including prediction of mortality, prediction of readmission, prediction
of length of stay, drug recommendation, and prediction of phenotype. The
results demonstrate the ability of ProtoEHR to make accurate, robust, and
interpretable predictions compared to baselines in the literature. Furthermore,
ProtoEHR offers interpretable insights on code, visit, and patient levels to
aid in healthcare prediction.

</details>


### [251] [Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing](https://arxiv.org/abs/2508.18316)
*Rodrigo Tertulino*

Main category: cs.LG

TL;DR: 该研究提出了一种基于联邦学习的机器学习模型，利用早期学业表现和数字参与模式来预测在线教育中处于风险中的学生，准确率达85%，同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 在线教育中高辍学率和失败率对学术机构构成重大挑战，因此，主动识别有风险的学生对于提供及时支持至关重要。

Method: 研究开发并评估了一个基于早期学业表现和数字参与模式的机器学习模型，并使用联邦学习框架来实现，以应对数据隐私和机构孤岛的实际挑战。研究比较了逻辑回归和深度神经网络这两种模型复杂度以及数据平衡方法。

Result: 最终的联邦模型在识别有风险的学生方面表现出强大的预测能力，其ROC AUC得分约为85%。

Conclusion: 研究结果表明，这种联邦方法为机构提供了一种实用且可扩展的解决方案，用于构建有效的预警系统，从而能够在尊重数据隐私的同时，主动支持学生。

Abstract: High dropout and failure rates in distance education pose a significant
challenge for academic institutions, making the proactive identification of
at-risk students crucial for providing timely support. This study develops and
evaluates a machine learning model based on early academic performance and
digital engagement patterns from the large-scale OULAD dataset to predict
student risk at a UK university. To address the practical challenges of data
privacy and institutional silos that often hinder such initiatives, we
implement the model using a Federated Learning (FL) framework. We compare model
complexity (Logistic Regression vs. a Deep Neural Network) and data balancing.
The final federated model demonstrates strong predictive capability, achieving
an ROC AUC score of approximately 85% in identifying at-risk students. Our
findings show that this federated approach provides a practical and scalable
solution for institutions to build effective early-warning systems, enabling
proactive student support while inherently respecting data privacy.

</details>


### [252] [ZTFed-MAS2S: A Zero-Trust Federated Learning Framework with Verifiable Privacy and Trust-Aware Aggregation for Wind Power Data Imputation](https://arxiv.org/abs/2508.18318)
*Yang Li,Hanjie Wang,Yuanzheng Li,Jiazheng Li,Zhaoyang Dong*

Main category: cs.LG

TL;DR: ZTFed-MAS2S是一个零信任联邦学习框架，集成了基于多头注意力的时间序列缺失值填充模型，用于处理风力发电数据。它通过结合可验证差分隐私、零知识证明和动态信任聚合机制，解决了联邦学习中的异常更新、隐私泄露和数据缺失问题，并采用稀疏化和量化压缩来降低通信开销。实验证明该框架在风力发电数据缺失填充和联邦学习性能上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 风力发电数据常因传感器故障和传输不稳定而出现缺失值。联邦学习虽能实现隐私保护的数据协作，但仍易受异常更新和参数交换过程中的隐私泄露影响。在开放的工业环境中，这些挑战尤为严峻，需要零信任机制。

Method: 提出ZTFed-MAS2S框架，集成了基于多头注意力的时间序列缺失值填充模型（MAS2S）。通过整合可验证差分隐私、非交互式零知识证明以及保密性和完整性验证机制，确保了可验证的隐私保护和安全的模型参数传输。采用动态信任聚合机制，通过相似性图传播信任以增强鲁棒性，并通过稀疏化和量化压缩降低通信开销。MAS2S能够捕捉风力发电数据中的长期依赖关系以进行准确的填充。

Result: 在真实风电场数据集上进行的广泛实验验证了ZTFed-MAS2S在联邦学习性能和缺失值填充方面的优越性。

Conclusion: ZTFed-MAS2S是一种安全有效的解决方案，在能源领域的实际应用中，能够有效解决风力发电数据缺失问题，并提供强大的联邦学习性能。

Abstract: Wind power data often suffers from missing values due to sensor faults and
unstable transmission at edge sites. While federated learning enables
privacy-preserving collaboration without sharing raw data, it remains
vulnerable to anomalous updates and privacy leakage during parameter exchange.
These challenges are amplified in open industrial environments, necessitating
zero-trust mechanisms where no participant is inherently trusted. To address
these challenges, this work proposes ZTFed-MAS2S, a zero-trust federated
learning framework that integrates a multi-head attention-based
sequence-to-sequence imputation model. ZTFed integrates verifiable differential
privacy with non-interactive zero-knowledge proofs and a confidentiality and
integrity verification mechanism to ensure verifiable privacy preservation and
secure model parameters transmission. A dynamic trust-aware aggregation
mechanism is employed, where trust is propagated over similarity graphs to
enhance robustness, and communication overhead is reduced via sparsity- and
quantization-based compression. MAS2S captures long-term dependencies in wind
power data for accurate imputation. Extensive experiments on real-world wind
farm datasets validate the superiority of ZTFed-MAS2S in both federated
learning performance and missing data imputation, demonstrating its
effectiveness as a secure and efficient solution for practical applications in
the energy sector.

</details>


### [253] [Linear cost mutual information estimation and independence test of similar performance as HSIC](https://arxiv.org/abs/2508.18338)
*Jarek Duda,Jagoda Bracha,Adrian Przybysz*

Main category: cs.LG

TL;DR: HSIC在评估两个数据样本之间的统计依赖性方面是先进的，但计算成本高昂。HCR作为一种计算成本为O(n)的替代方法，可以更有效地处理大型数据集，并提供更详细的依赖性模型。


<details>
  <summary>Details</summary>
Motivation: 评估两个数据样本之间的统计依赖性是数据科学和机器学习中的一个基本问题，而HSIC被认为是该领域的尖端方法。然而，HSIC的计算复杂度高，对于大型数据集来说不切实际。

Method: 提出了一种名为HCR（分层相关性重构）的替代方法，其计算成本为O(n)，并且具有更高的依赖性敏感性。HCR通过描述混合矩（从相关性和同质性开始）来提供实际的联合分布模型，还可以将互信息近似为这些非平凡混合矩的平方和。

Result: HCR的计算时间为O(n)，对于成对依赖性需要O(d^2)的计算量，如果还考虑更复杂的依赖性则需要O(d^3)。

Conclusion: HCR是一种比HSIC更实用且更敏感的替代方法，用于评估数据样本之间的统计依赖性，并能提供详细的联合分布模型。

Abstract: Evaluation of statistical dependencies between two data samples is a basic
problem of data science/machine learning, and HSIC (Hilbert-Schmidt Information
Criterion)~\cite{HSIC} is considered the state-of-art method. However, for size
$n$ data sample it requires multiplication of $n\times n$ matrices, what
currently needs $\sim O(n^{2.37})$ computational complexity~\cite{mult}, making
it impractical for large data samples. We discuss HCR (Hierarchical Correlation
Reconstruction) as its linear cost practical alternative of even higher
dependence sensitivity in tests, and additionally providing actual joint
distribution model by description of dependencies through features being mixed
moments, starting with correlation and homoscedasticity, also allowing to
approximate mutual information as just sum of squares of such nontrivial mixed
moments between two data samples. Such single dependence describing feature is
calculated in $O(n)$ linear time. Their number to test varies with dimension
$d$ - requiring $O(d^2)$ for pairwise dependencies, $O(d^3)$ if wanting to also
consider more subtle triplewise, and so on.

</details>


### [254] [Low-Rank Tensor Decompositions for the Theory of Neural Networks](https://arxiv.org/abs/2508.18408)
*Ricardo Borsoi,Konstantin Usevich,Marianne Clausel*

Main category: cs.LG

TL;DR: 低秩张量分解在深度学习理论中发挥着核心作用，解释了深度神经网络的表达能力、可学习性、泛化能力和可识别性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（NNs）的优越性能激发了对其理论基础的深入研究。低秩张量分解因其与NNs的紧密联系和丰富的理论结果，特别适合这项任务。

Method: 本文综述了低秩张量分解在解释深度NNs的表达能力、算法可学习性、计算复杂性、泛化和可识别性等方面的作用。

Result: 低秩张量方法是信号处理和机器学习领域的核心工具，在理论上解释了深度NNs的各项性能。

Conclusion: 本文旨在以连贯统一的方式概述现有方法，并为使用低秩张量分解来研究深度NNs理论开辟更广阔的视野。

Abstract: The groundbreaking performance of deep neural networks (NNs) promoted a surge
of interest in providing a mathematical basis to deep learning theory. Low-rank
tensor decompositions are specially befitting for this task due to their close
connection to NNs and their rich theoretical results. Different tensor
decompositions have strong uniqueness guarantees, which allow for a direct
interpretation of their factors, and polynomial time algorithms have been
proposed to compute them. Through the connections between tensors and NNs, such
results supported many important advances in the theory of NNs. In this review,
we show how low-rank tensor methods--which have been a core tool in the signal
processing and machine learning communities--play a fundamental role in
theoretically explaining different aspects of the performance of deep NNs,
including their expressivity, algorithmic learnability and computational
hardness, generalization, and identifiability. Our goal is to give an
accessible overview of existing approaches (developed by different communities,
ranging from computer science to mathematics) in a coherent and unified way,
and to open a broader perspective on the use of low-rank tensor decompositions
for the theory of deep NNs.

</details>


### [255] [LLM-Driven Intrinsic Motivation for Sparse Reward Reinforcement Learning](https://arxiv.org/abs/2508.18420)
*André Quadros,Cassio Silva,Ronnie Alves*

Main category: cs.LG

TL;DR: 本文研究了在稀疏奖励环境中结合两种内在激励策略以提高强化学习（RL）代理效率的方法，通过结合状态新颖性奖励（VSIMR）和大型语言模型（LLM）生成的奖励信号，并在MiniGrid DoorKey环境中进行了实验，结果表明该组合策略显著优于单独使用各策略或标准A2C代理。


<details>
  <summary>Details</summary>
Motivation: 在奖励信号稀疏的环境中，传统的强化学习方法难以有效学习，本文旨在通过结合两种内在激励策略来提高强化学习代理的效率。

Method: 本文提出将基于变分自编码器（VAE）的状态新颖性奖励（VSIMR）与利用大型语言模型（LLM）生成奖励信号的方法相结合，并在Actor-Critic（A2C）代理和MiniGrid DoorKey环境中进行了实现。

Result: 实验结果表明，所提出的组合策略相比单独使用VSIMR、LLM奖励或标准A2C代理，能够显著提高代理的性能和采样效率，其中标准A2C代理甚至无法完成学习。

Conclusion: 结合VSIMR和LLM驱动的奖励能够有效结合不同环境和任务的优势：VSIMR促进新状态的探索，而LLM奖励则有助于向目标进行渐进式利用，从而在稀疏奖励环境中实现更优的学习效果。

Abstract: This paper explores the combination of two intrinsic motivation strategies to
improve the efficiency of reinforcement learning (RL) agents in environments
with extreme sparse rewards, where traditional learning struggles due to
infrequent positive feedback. We propose integrating Variational State as
Intrinsic Reward (VSIMR), which uses Variational AutoEncoders (VAEs) to reward
state novelty, with an intrinsic reward approach derived from Large Language
Models (LLMs). The LLMs leverage their pre-trained knowledge to generate reward
signals based on environment and goal descriptions, guiding the agent. We
implemented this combined approach with an Actor-Critic (A2C) agent in the
MiniGrid DoorKey environment, a benchmark for sparse rewards. Our empirical
results show that this combined strategy significantly increases agent
performance and sampling efficiency compared to using each strategy
individually or a standard A2C agent, which failed to learn. Analysis of
learning curves indicates that the combination effectively complements
different aspects of the environment and task: VSIMR drives exploration of new
states, while the LLM-derived rewards facilitate progressive exploitation
towards goals.

</details>


### [256] [Enhancing Trust-Region Bayesian Optimization via Newton Methods](https://arxiv.org/abs/2508.18423)
*Quanlin Chen,Yiyu Chen,Jing Huo,Tianyu Ding,Yang Gao,Yuetong Chen*

Main category: cs.LG

TL;DR: BO在高维空间中存在挑战，本研究提出一种新方法，通过构建多局部二次模型并利用梯度和Hessian来提升采样效率和模型性能，在高维优化问题上表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的贝叶斯优化（BO）方法在高维空间中扩展性差，虽然TuRBO等方法通过局部信任区域改善了模型，但局部高斯过程（GP）降低了采样效率。本研究旨在提高采样效率，同时保持异质性建模。

Method: 提出构建多局部二次模型，利用全局GP的梯度和Hessian，并通过求解有界约束二次规划来选择新的采样点。同时解决GP在高维空间中梯度消失的问题。

Result: 实验结果表明，该方法提高了TuRBO的效率，并在合成函数和实际应用的高维BO技术中表现更优。

Conclusion: 该方法通过构建多局部二次模型并利用梯度和Hessian，有效解决了高维BO的采样效率和模型性能问题，优于现有技术。

Abstract: Bayesian Optimization (BO) has been widely applied to optimize expensive
black-box functions while retaining sample efficiency. However, scaling BO to
high-dimensional spaces remains challenging. Existing literature proposes
performing standard BO in multiple local trust regions (TuRBO) for
heterogeneous modeling of the objective function and avoiding over-exploration.
Despite its advantages, using local Gaussian Processes (GPs) reduces sampling
efficiency compared to a global GP. To enhance sampling efficiency while
preserving heterogeneous modeling, we propose to construct multiple local
quadratic models using gradients and Hessians from a global GP, and select new
sample points by solving the bound-constrained quadratic program. Additionally,
we address the issue of vanishing gradients of GPs in high-dimensional spaces.
We provide a convergence analysis and demonstrate through experimental results
that our method enhances the efficacy of TuRBO and outperforms a wide range of
high-dimensional BO techniques on synthetic functions and real-world
applications.

</details>


### [257] [VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning](https://arxiv.org/abs/2508.18462)
*Fu Teng,Miao Pan,Xuhong Zhang,Zhezhi He,Yiyao Yang,Xinyi Chai,Mengnan Qi,Liqiang Lu,Jianwei Yin*

Main category: cs.LG

TL;DR: 该论文提出了一个名为VeriRL的强化学习框架，用于生成Verilog代码，解决了硬件描述语言代码生成中的挑战，并在Verilog生成任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Verilog等硬件描述语言的代码生成因其并发语义、语法僵化和仿真复杂性而未得到充分探索。本研究旨在解决这些挑战。

Method: 通过构建Veribench-53K数据集、提出基于回溯的重评分机制来处理稀疏和嘈杂的奖励信号，以及引入样本平衡加权策略来缓解灾难性遗忘和过拟合，并集成到一个迭代的RL流程中。

Result: 在Verilog生成任务上实现了最先进的性能，在测试通过率、功能正确性和编译鲁棒性方面取得了显著的提升。

Conclusion: 强化学习驱动的方法在面向硬件的领域中具有结构化代码生成的潜力。

Abstract: Recent advancements in code generation have shown remarkable success across
software domains, yet hardware description languages (HDLs) such as Verilog
remain underexplored due to their concurrency semantics, syntactic rigidity,
and simulation complexity. In this work, we address these challenges by
introducing a reinforcement learning (RL) framework tailored for Verilog code
generation. We first construct Veribench-53K, a high-quality dataset curated
from over 700K Verilog problems, enriched with structured prompts, complexity
labels, and diverse testbenches. To tackle the problem of sparse and noisy
reward signals, we propose a Trace-back based Rescore mechanism that leverages
reasoning paths and iterative refinement to enhance feedback reliability and
support reward model training. Furthermore, to mitigate catastrophic forgetting
and overfitting during RL fine-tuning, we introduce a sample-balanced weighting
strategy that adaptively balances learning dynamics based on reward-probability
distributions. These innovations are integrated into an iterative RL pipeline
that co-evolves the policy and reward models. In contrast to recent work such
as CraftRTL, which relies on large-scale closed-source model distillation, and
DeepSeek-style approaches that struggle with sparse feedback, our method
demonstrates superior performance using a smaller but high-quality dataset
combined with RL optimization. Experiments on Verilog generation tasks
demonstrate state-of-the-art performance, with substantial gains in test pass
rate, functional correctness, and compilation robustness. Our findings
highlight the potential of RL-driven approaches for structured code generation
in hardware-centric domains. VERIRL is publicly available at
https://github.com/omniAI-Lab/VeriRL.

</details>


### [258] [DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series Anomaly Detection](https://arxiv.org/abs/2508.18474)
*Bahareh Golchin,Banafsheh Rekabdar,Kunpeng Liu*

Main category: cs.LG

TL;DR: DRTA是一个基于强化学习的框架，用于时间序列异常检测，它结合了动态奖励塑造、VAE和主动学习，在Yahoo A1和A2数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的时间序列异常检测方法在标记数据有限、假阳性率高和难以泛化到新型异常类型方面存在挑战。DRTA旨在克服这些挑战。

Method: DRTA框架整合了动态奖励塑造、变分自编码器（VAE）和主动学习。它使用一种自适应奖励机制，通过动态调整VAE重构误差和分类奖励的影响来平衡探索和利用，使智能体能在低标记系统上有效检测异常，同时保持高精度和召回率。

Result: 在Yahoo A1和Yahoo A2基准数据集上的实验结果表明，DRTA方法在性能上持续优于最先进的无监督和半监督方法。

Conclusion: DRTA框架为现实世界中的异常检测任务提供了一个可扩展且高效的解决方案。

Abstract: Anomaly detection in time series data is important for applications in
finance, healthcare, sensor networks, and industrial monitoring. Traditional
methods usually struggle with limited labeled data, high false-positive rates,
and difficulty generalizing to novel anomaly types. To overcome these
challenges, we propose a reinforcement learning-based framework that integrates
dynamic reward shaping, Variational Autoencoder (VAE), and active learning,
called DRTA. Our method uses an adaptive reward mechanism that balances
exploration and exploitation by dynamically scaling the effect of VAE-based
reconstruction error and classification rewards. This approach enables the
agent to detect anomalies effectively in low-label systems while maintaining
high precision and recall. Our experimental results on the Yahoo A1 and Yahoo
A2 benchmark datasets demonstrate that the proposed method consistently
outperforms state-of-the-art unsupervised and semi-supervised approaches. These
findings show that our framework is a scalable and efficient solution for
real-world anomaly detection tasks.

</details>


### [259] [Data Augmentation Improves Machine Unlearning](https://arxiv.org/abs/2508.18502)
*Andreza M. C. Falcao,Filipe R. Cordeiro*

Main category: cs.LG

TL;DR: 该研究探讨了数据增强策略对机器遗忘（MU）方法（如SalUn、随机标签和微调）的影响。实验表明，合理的数据增强可以显著提高遗忘效果，缩小与重新训练模型之间的性能差距，并且在减少过拟合和实现高效遗忘方面发挥着关键作用。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是机器遗忘（MU）旨在移除特定数据对训练模型的影响，同时保持模型在剩余数据上的性能，但系统性数据增强设计在MU中的作用尚未得到充分研究。

Method: 该研究通过在CIFAR-10和CIFAR-100数据集上进行实验，评估了不同数据增强策略（如TrivialAug）对SalUn、随机标签和微调等遗忘方法性能的影响，并观察了不同遗忘率下的效果。

Result: 实验结果显示，使用TrivialAug等数据增强策略可以将平均差距遗忘指标（Average Gap unlearning Metric）降低高达40.12%，表明数据增强能够有效提高遗忘的有效性。

Conclusion: 研究得出结论，数据增强不仅有助于减少模型的过拟合，还在实现隐私保护和高效遗忘方面发挥着至关重要的作用。

Abstract: Machine Unlearning (MU) aims to remove the influence of specific data from a
trained model while preserving its performance on the remaining data. Although
a few works suggest connections between memorisation and augmentation, the role
of systematic augmentation design in MU remains under-investigated. In this
work, we investigate the impact of different data augmentation strategies on
the performance of unlearning methods, including SalUn, Random Label, and
Fine-Tuning. Experiments conducted on CIFAR-10 and CIFAR-100, under varying
forget rates, show that proper augmentation design can significantly improve
unlearning effectiveness, reducing the performance gap to retrained models.
Results showed a reduction of up to 40.12% of the Average Gap unlearning
Metric, when using TrivialAug augmentation. Our results suggest that
augmentation not only helps reduce memorization but also plays a crucial role
in achieving privacy-preserving and efficient unlearning.

</details>


### [260] [Breaking Through Barren Plateaus: Reinforcement Learning Initializations for Deep Variational Quantum Circuits](https://arxiv.org/abs/2508.18514)
*Yifeng Peng,Xinyi Li,Zhemin Zhang,Samuel Yen-Chi Chen,Zhiding Liang,Ying Wang*

Main category: cs.LG

TL;DR: RL初始化策略通过重塑初始参数来缓解VQA中的Barren Plateau问题，提升了收敛速度和解的质量。


<details>
  <summary>Details</summary>
Motivation: VQAs在近期量子设备的应用中很受欢迎，但Barren Plateau问题限制了其有效性。

Method: 提出了一种基于强化学习（RL）的初始化策略，使用RL算法（如DPG, SAC, PPO）生成预训练参数，以最小化VQA的成本函数。

Result: 数值实验表明，RL初始化方法显著提高了收敛速度和最终解的质量，并且在不同噪声和任务下表现稳健。

Conclusion: RL驱动的参数初始化为加速VQA的可扩展性和实际应用提供了一种有前景的方法，尤其是在解决Barren Plateau问题方面。

Abstract: Variational Quantum Algorithms (VQAs) have gained prominence as a viable
framework for exploiting near-term quantum devices in applications ranging from
optimization and chemistry simulation to machine learning. However, the
effectiveness of VQAs is often constrained by the so-called barren plateau
problem, wherein gradients diminish exponentially as system size or circuit
depth increases, thereby hindering training. In this work, we propose a
reinforcement learning (RL)-based initialization strategy to alleviate the
barren plateau issue by reshaping the initial parameter landscape to avoid
regions prone to vanishing gradients. In particular, we explore several RL
algorithms (Deterministic Policy Gradient, Soft Actor-Critic, and Proximal
Policy Optimization, etc.) to generate the circuit parameters (treated as
actions) that minimize the VQAs cost function before standard gradient-based
optimization. By pre-training with RL in this manner, subsequent optimization
using methods such as gradient descent or Adam proceeds from a more favorable
initial state. Extensive numerical experiments under various noise conditions
and tasks consistently demonstrate that the RL-based initialization method
significantly enhances both convergence speed and final solution quality.
Moreover, comparisons among different RL algorithms highlight that multiple
approaches can achieve comparable performance gains, underscoring the
flexibility and robustness of our method. These findings shed light on a
promising avenue for integrating machine learning techniques into quantum
algorithm design, offering insights into how RL-driven parameter initialization
can accelerate the scalability and practical deployment of VQAs. Opening up a
promising path for the research community in machine learning for quantum,
especially barren plateau problems in VQAs.

</details>


### [261] [BTW: A Non-Parametric Variance Stabilization Framework for Multimodal Model Integration](https://arxiv.org/abs/2508.18551)
*Jun Hou,Le Wang,Xuan Wang*

Main category: cs.LG

TL;DR: MoE模型在多模态学习中通过模块化专业化变得强大，但当附加模态引入更多噪声而非互补信息时，其有效性尚不清楚。现有方法难以扩展到两个以上的模态，并且缺乏实例级控制的精度。我们提出了Beyond Two-modality Weighting (BTW)，一个双层、非参数的加权框架，它结合了实例级KL散度和模态级MI来动态调整训练过程中的模态重要性。BTW计算每个示例的KL权重（通过衡量每个单模态和当前多模态预测之间的散度）以及模态范围的MI权重（通过估计单模态和多模态输出之间的全局对齐）。在情感回归和临床分类上的广泛实验表明，我们的方法显著提高了回归性能和多类分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型在多模态学习中，当附加模态引入更多噪声而非互补信息时，其有效性尚不清楚。现有的部分信息分解方法难以扩展到两个以上的模态，并且缺乏实例级控制的精度。

Method: 提出了一种名为Beyond Two-modality Weighting (BTW)的双层、非参数加权框架。该框架结合了实例级KL散度和模态级MI来动态调整训练过程中的模态重要性。具体来说，BTW通过衡量每个单模态和当前多模态预测之间的散度来计算每示例KL权重，并通过估计单模态和多模态输出之间的全局对齐来计算模态MI权重。

Result: 在情感回归和临床分类任务上进行的广泛实验表明，BTW方法显著提高了回归性能和多类分类准确性。

Conclusion: Beyond Two-modality Weighting (BTW)是一个双层、非参数的加权框架，能够处理任意数量的模态，并能动态调整模态重要性，有效解决了MoE模型在多模态学习中可能遇到的噪声问题，并在回归和分类任务上取得了显著的性能提升。

Abstract: Mixture-of-Experts (MoE) models have become increasingly powerful in
multimodal learning by enabling modular specialization across modalities.
However, their effectiveness remains unclear when additional modalities
introduce more noise than complementary information. Existing approaches, such
as the Partial Information Decomposition, struggle to scale beyond two
modalities and lack the resolution needed for instance-level control. We
propose Beyond Two-modality Weighting (BTW), a bi-level, non-parametric
weighting framework that combines instance-level Kullback-Leibler (KL)
divergence and modality-level mutual information (MI) to dynamically adjust
modality importance during training. Our method does not require additional
parameters and can be applied to an arbitrary number of modalities.
Specifically, BTW computes per-example KL weights by measuring the divergence
between each unimodal and the current multimodal prediction, and modality-wide
MI weights by estimating global alignment between unimodal and multimodal
outputs. Extensive experiments on sentiment regression and clinical
classification demonstrate that our method significantly improves regression
performance and multiclass classification accuracy.

</details>


### [262] [Enhancing Chemical Explainability Through Counterfactual Masking](https://arxiv.org/abs/2508.18561)
*Łukasz Janisiów,Marek Kochańczyk,Bartosz Zieliński,Tomasz Danel*

Main category: cs.LG

TL;DR: Counterfactual masking framework for molecular property prediction offers more robust and actionable explanations by replacing masked substructures with chemically reasonable fragments, ensuring molecular realism and distribution consistency.


<details>
  <summary>Details</summary>
Motivation: Existing explainable AI methods for molecular property prediction often fail to adhere to the underlying molecular distribution due to reliance on masking strategies that remove atoms or features, leading to unintuitive explanations. This work addresses the need for more realistic and informative explanations.

Method: Proposes 'counterfactual masking,' a novel framework that replaces masked molecular substructures with chemically reasonable fragments sampled from generative models trained on molecular graph completion. Explanations are generated by comparing masked predictions against these counterfactual molecules, which are drawn from the data distribution, rather than implausible baselines.

Result: Demonstrates that counterfactual masking provides molecular realism, leading to robust and distribution-consistent explanations. It generates meaningful counterfactuals that highlight how structural modifications impact predicted properties. The method is effective for benchmarking model explainers and yields more actionable insights across various datasets and property prediction tasks.

Conclusion: Counterfactual masking bridges the gap between explainability and molecular design by offering a principled and generative approach to explainable machine learning in chemistry, providing more realistic and actionable insights.

Abstract: Molecular property prediction is a crucial task that guides the design of new
compounds, including drugs and materials. While explainable artificial
intelligence methods aim to scrutinize model predictions by identifying
influential molecular substructures, many existing approaches rely on masking
strategies that remove either atoms or atom-level features to assess importance
via fidelity metrics. These methods, however, often fail to adhere to the
underlying molecular distribution and thus yield unintuitive explanations. In
this work, we propose counterfactual masking, a novel framework that replaces
masked substructures with chemically reasonable fragments sampled from
generative models trained to complete molecular graphs. Rather than evaluating
masked predictions against implausible zeroed-out baselines, we assess them
relative to counterfactual molecules drawn from the data distribution. Our
method offers two key benefits: (1) molecular realism underpinning robust and
distribution-consistent explanations, and (2) meaningful counterfactuals that
directly indicate how structural modifications may affect predicted properties.
We demonstrate that counterfactual masking is well-suited for benchmarking
model explainers and yields more actionable insights across multiple datasets
and property prediction tasks. Our approach bridges the gap between
explainability and molecular design, offering a principled and generative path
toward explainable machine learning in chemistry.

</details>


### [263] [A Note on Graphon-Signal Analysis of Graph Neural Networks](https://arxiv.org/abs/2508.18564)
*Levi Rauchwerger,Ron Levie*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A recent paper, ``A Graphon-Signal Analysis of Graph Neural Networks'', by
Levie, analyzed message passing graph neural networks (MPNNs) by embedding the
input space of MPNNs, i.e., attributed graphs (graph-signals), to a space of
attributed graphons (graphon-signals). Based on extensions of standard results
in graphon analysis to graphon-signals, the paper proved a generalization bound
and a sampling lemma for MPNNs. However, there are some missing ingredients in
that paper, limiting its applicability in practical settings of graph machine
learning. In the current paper, we introduce several refinements and extensions
to existing results that address these shortcomings. In detail, 1) we extend
the main results in the paper to graphon-signals with multidimensional signals
(rather than 1D signals), 2) we extend the Lipschitz continuity to MPNNs with
readout with respect to cut distance (rather than MPNNs without readout with
respect to cut metric), 3) we improve the generalization bound by utilizing
robustness-type generalization bounds, and 4) we extend the analysis to
non-symmetric graphons and kernels.

</details>


### [264] [Improving Long-term Autoregressive Spatiotemporal Predictions: A Proof of Concept with Fluid Dynamics](https://arxiv.org/abs/2508.18565)
*Hao Zhou,Sibo Cheng*

Main category: cs.LG

TL;DR: SPF框架通过结合模型预测和真实值，并在训练过程中采用随机选择策略，来提升数据驱动模型的长期预测精度，同时降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法在复杂系统长期预测时存在精度下降问题，而自回归训练则需要大量GPU内存且可能牺牲短期性能。

Method: 提出随机前推（SPF）框架，该框架保留一步预测训练，但通过构建补充数据集（来自模型预测）并结合真实值（通过随机选择策略），来实现多步学习，从而平衡短期和长期性能并减少过拟合。多步预测在时期之间预计算，以保持内存使用稳定。

Result: 与自回归方法相比，SPF在Burgers方程和浅水方程基准测试中实现了更高的长期精度，同时降低了内存需求。

Conclusion: SPF框架有望成为资源受限和复杂模拟的有效解决方案，因为它在保持较低内存占用的同时提高了预测精度。

Abstract: Data-driven methods are emerging as efficient alternatives to traditional
numerical forecasting, offering fast inference and lower computational cost.
Yet, for complex systems, long-term accuracy often deteriorates due to error
accumulation, and autoregressive training (though effective) demands large GPU
memory and may sacrifice short-term performance. We propose the Stochastic
PushForward (SPF) framework, which retains one-step-ahead training while
enabling multi-step learning. SPF builds a supplementary dataset from model
predictions and combines it with ground truth via a stochastic acquisition
strategy, balancing short- and long-term performance while reducing
overfitting. Multi-step predictions are precomputed between epochs, keeping
memory usage stable without storing full unrolled sequences. Experiments on the
Burgers' equation and the Shallow Water benchmark show that SPF achieves higher
long-term accuracy than autoregressive methods while lowering memory
requirements, making it promising for resource-limited and complex simulations.

</details>


### [265] [Sparse Autoencoders for Low-$N$ Protein Function Prediction and Design](https://arxiv.org/abs/2508.18567)
*Darin Tsui,Kunal Talreja,Amirali Aghazadeh*

Main category: cs.LG

TL;DR: SAEs combined with pLMs (ESM2) improve protein function prediction and design in low-data scenarios, outperforming baselines and identifying high-fitness variants.


<details>
  <summary>Details</summary>
Motivation: The effectiveness of Sparse Autoencoders (SAEs) for low-data protein function prediction and design, especially when combined with protein language models (pLMs), has not been systematically studied.

Method: SAEs were trained on fine-tuned ESM2 embeddings and evaluated across diverse fitness extrapolation and protein engineering tasks. The performance of SAEs was compared to their ESM2 baselines using limited sequence data.

Result: SAEs, even with as few as 24 sequences, consistently matched or exceeded the performance of their ESM2 baselines in fitness prediction. Steering predictive latents using SAEs identified top-fitness variants in 83% of cases.

Conclusion: SAEs, when applied to pLM embeddings, provide compact, interpretable, and biologically meaningful representations that generalize effectively from limited data, significantly improving protein function prediction and design capabilities in low-data regimes.

Abstract: Predicting protein function from amino acid sequence remains a central
challenge in data-scarce (low-$N$) regimes, limiting machine learning-guided
protein design when only small amounts of assay-labeled sequence-function data
are available. Protein language models (pLMs) have advanced the field by
providing evolutionary-informed embeddings and sparse autoencoders (SAEs) have
enabled decomposition of these embeddings into interpretable latent variables
that capture structural and functional features. However, the effectiveness of
SAEs for low-$N$ function prediction and protein design has not been
systematically studied. Herein, we evaluate SAEs trained on fine-tuned ESM2
embeddings across diverse fitness extrapolation and protein engineering tasks.
We show that SAEs, with as few as 24 sequences, consistently outperform or
compete with their ESM2 baselines in fitness prediction, indicating that their
sparse latent space encodes compact and biologically meaningful representations
that generalize more effectively from limited data. Moreover, steering
predictive latents exploits biological motifs in pLM representations, yielding
top-fitness variants in 83% of cases compared to designing with ESM2 alone.

</details>


### [266] [DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model](https://arxiv.org/abs/2508.18579)
*Mohammadreza Ghaffarzadeh-Esfahani,Ali Motahharynia,Nahid Yousefian,Navid Mazrouei,Jafar Ghaisari,Yousof Gheisari*

Main category: cs.LG

TL;DR: DrugReasoner是一个基于LLaMA架构并使用GRPO进行微调的推理型大语言模型，用于预测小分子化合物的批准可能性。它通过整合分子描述符和与结构相似化合物的比较推理，提供具有逐步推理和置信分数的可解释预测。


<details>
  <summary>Details</summary>
Motivation: 药物发现过程复杂且资源消耗大，因此早期预测批准结果对于优化研究投资至关重要。然而，传统的机器学习和深度学习方法在药物批准预测方面虽有潜力，但其有限的可解释性限制了其应用。

Method: DrugReasoner整合了分子描述符与结构相似已批准和未批准化合物的比较推理，并使用分组相对策略优化（GRPO）在LLaMA架构上进行微调，以预测小分子化合物的批准可能性。

Result: DrugReasoner在验证集上达到了0.732的AUC和0.729的F1分数，在测试集上达到了0.725的AUC和0.718的F1分数，优于传统的基线模型，并与XGBoost具有竞争力。在外部独立数据集上，DrugReasoner的AUC为0.728，F1分数为0.774，优于基线模型和ChemAP模型，并在实际场景中表现出稳健性。

Conclusion: DrugReasoner不仅具有竞争力预测准确性，还能通过其推理输出提高透明度，解决了AI辅助药物发现中的关键瓶颈。该研究强调了推理增强型LLM作为可解释且有效的工具在制药决策中的潜力。

Abstract: Drug discovery is a complex and resource-intensive process, making early
prediction of approval outcomes critical for optimizing research investments.
While classical machine learning and deep learning methods have shown promise
in drug approval prediction, their limited interpretability constraints their
impact. Here, we present DrugReasoner, a reasoning-based large language model
(LLM) built on the LLaMA architecture and fine-tuned with group relative policy
optimization (GRPO) to predict the likelihood of small-molecule approval.
DrugReasoner integrates molecular descriptors with comparative reasoning
against structurally similar approved and unapproved compounds, generating
predictions alongside step-by-step rationales and confidence scores.
DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score
of 0.729 on the validation set and 0.725 and 0.718 on the test set,
respectively. These results outperformed conventional baselines, including
logistic regression, support vector machine, and k-nearest neighbors and had
competitive performance relative to XGBoost. On an external independent
dataset, DrugReasoner outperformed both baseline and the recently developed
ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while
maintaining high precision and balanced sensitivity, demonstrating robustness
in real-world scenarios. These findings demonstrate that DrugReasoner not only
delivers competitive predictive accuracy but also enhances transparency through
its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug
discovery. This study highlights the potential of reasoning-augmented LLMs as
interpretable and effective tools for pharmaceutical decision-making.

</details>


### [267] [Linear Trading Position with Sparse Spectrum](https://arxiv.org/abs/2508.18596)
*Zhao-Rong Lai,Haisheng Yang*

Main category: cs.LG

TL;DR: 本文提出了一种新的稀疏频谱线性交易方法，并使用Krasnosel'ski
krasnosel'ski
i-Mann不动点算法进行优化，实验证明该方法具有良好且稳健的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有principal portfolio方法可能分散、无法充分利用预测矩阵的关键特征或在不同情况下不够稳健的问题，本文提出了一种新的交易方法。

Method: 提出了一种新的线性交易头寸，具有稀疏频谱，可以探索预测矩阵的更大频谱区域。并开发了一种Krasnosel'ski
krasnosel'ski
i-Mann不动点算法来优化该交易头寸，该算法具有下降性质，并在目标值上实现了线性收敛速度。

Result: 通过广泛的实验证明，所提出的方法在各种情况下均能实现良好且稳健的性能。

Conclusion: 所提出的稀疏频谱线性交易方法和优化的Krasnosel'ski
krasnosel'ski
i-Mann不动点算法是一种新的理论成果，能够有效解决现有方法的不足，并在实际应用中表现出优越的性能。

Abstract: The principal portfolio approach is an emerging method in signal-based
trading. However, these principal portfolios may not be diversified to explore
the key features of the prediction matrix or robust to different situations. To
address this problem, we propose a novel linear trading position with sparse
spectrum that can explore a larger spectral region of the prediction matrix. We
also develop a Krasnosel'ski\u \i-Mann fixed-point algorithm to optimize this
trading position, which possesses the descent property and achieves a linear
convergence rate in the objective value. This is a new theoretical result for
this type of algorithms. Extensive experiments show that the proposed method
achieves good and robust performance in various situations.

</details>


### [268] [Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data](https://arxiv.org/abs/2508.18630)
*Weide Liu,Xiaoyang Zhong,Lu Wang,Jingwen Hou,Yuemei Luo,Jiebin Yan,Yuming Fang*

Main category: cs.LG

TL;DR: 通过多尺度特征提取和不确定性估计来改进无监督时间序列域适应。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在训练和测试数据集之间经常发生分布偏移，旨在提高模型在未标记测试数据上的泛化能力。

Method: 提出了一种结合多尺度混合输入架构和基于证据学习的不确定性感知机制的方法。多尺度混合输入架构用于提取不同尺度的特征，不确定性感知机制通过对标签施加狄利克雷先验来促进目标预测和不确定性估计，以实现跨域特征对齐。

Result: 在多个基准数据集上实现了最先进的性能，并在目标域上显著提高了性能。不确定性感知模型还表现出更低的可校准误差（ECE），表明其预测置信度更好。

Conclusion: 该方法在无监督时间序列域适应方面是有效的，通过多尺度特征提取和不确定性估计提高了模型的泛化性和鲁棒性。

Abstract: Unsupervised domain adaptation methods seek to generalize effectively on
unlabeled test data, especially when encountering the common challenge in time
series data that distribution shifts occur between training and testing
datasets. In this paper, we propose incorporating multi-scale feature
extraction and uncertainty estimation to improve the model's generalization and
robustness across domains. Our approach begins with a multi-scale mixed input
architecture that captures features at different scales, increasing training
diversity and reducing feature discrepancies between the training and testing
domains. Based on the mixed input architecture, we further introduce an
uncertainty awareness mechanism based on evidential learning by imposing a
Dirichlet prior on the labels to facilitate both target prediction and
uncertainty estimation. The uncertainty awareness mechanism enhances domain
adaptation by aligning features with the same labels across different domains,
which leads to significant performance improvements in the target domain.
Additionally, our uncertainty-aware model demonstrates a much lower Expected
Calibration Error (ECE), indicating better-calibrated prediction confidence.
Our experimental results show that this combined approach of mixed input
architecture with the uncertainty awareness mechanism achieves state-of-the-art
performance across multiple benchmark datasets, underscoring its effectiveness
in unsupervised domain adaptation for time series data.

</details>


### [269] [STRATA-TS: Selective Knowledge Transfer for Urban Time Series Forecasting with Retrieval-Guided Reasoning](https://arxiv.org/abs/2508.18635)
*Yue Jiang,Chenxi Liu,Yile Chen,Qin Chao,Shuai Liu,Gao Cong*

Main category: cs.LG

TL;DR: STRATA-TS通过检索与目标城市数据相似的源数据子序列，并结合大语言模型进行推理，来改善数据稀疏城市的时间序列预测，并将此推理过程蒸馏到紧凑模型中以提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有城市预测模型普遍存在数据不平衡问题，即部分城市数据丰富，而大部分城市数据稀疏或不完整。直接从数据丰富城市迁移知识到数据稀疏城市效果不佳，可能引入噪声或负迁移。

Method: 提出STRATA-TS框架，结合了域自适应检索和大语言模型推理。首先，使用基于块的时间序列编码器识别与目标查询在语义和动态上对齐的源子序列。然后，将检索到的样本融入检索引导的推理阶段，由大语言模型对目标输入和检索到的支持信息进行结构化推理。最后，通过监督微调将推理过程蒸馏成一个紧凑的开放模型，以支持高效部署。

Result: 在新加坡、诺丁汉和格拉斯哥的三个停车位可用性数据集上的大量实验表明，STRATA-TS持续优于强大的预测和迁移基线模型，并提供了可解释的知识迁移路径。

Conclusion: STRATA-TS框架能够有效地改善数据稀疏城市的时间序列预测，并通过可解释的知识迁移路径实现性能提升。

Abstract: Urban forecasting models often face a severe data imbalance problem: only a
few cities have dense, long-span records, while many others expose short or
incomplete histories. Direct transfer from data-rich to data-scarce cities is
unreliable because only a limited subset of source patterns truly benefits the
target domain, whereas indiscriminate transfer risks introducing noise and
negative transfer. We present STRATA-TS (Selective TRAnsfer via TArget-aware
retrieval for Time Series), a framework that combines domain-adapted retrieval
with reasoning-capable large models to improve forecasting in scarce data
regimes. STRATA-TS employs a patch-based temporal encoder to identify source
subsequences that are semantically and dynamically aligned with the target
query. These retrieved exemplars are then injected into a retrieval-guided
reasoning stage, where an LLM performs structured inference over target inputs
and retrieved support. To enable efficient deployment, we distill the reasoning
process into a compact open model via supervised fine-tuning. Extensive
experiments on three parking availability datasets across Singapore,
Nottingham, and Glasgow demonstrate that STRATA-TS consistently outperforms
strong forecasting and transfer baselines, while providing interpretable
knowledge transfer pathways.

</details>


### [270] [Biologically Disentangled Multi-Omic Modeling Reveals Mechanistic Insights into Pan-Cancer Immunotherapy Resistance](https://arxiv.org/abs/2508.18638)
*Ifrah Tariq,Ernest Fraenkel*

Main category: cs.LG

TL;DR: ICI治疗的反应变异性很大，现有机器学习模型缺乏可解释性且未能有效利用多组学数据的生物结构。本文提出了一种名为生物解缠变分自编码器（BDVAE）的深度生成模型，该模型通过特定于模态和通路的编码器整合了转录组学和基因组学数据。BDVAE采用模块化编码器架构和变分推理，学习与免疫、基因组和代谢过程相关的生物学有意义的潜在特征。在接受ICI治疗的四种癌症类型的366名患者的泛癌队列中，BDVAE准确预测了治疗反应（在未见测试数据上AUC-ROC = 0.94），并揭示了关键的耐药机制，包括免疫抑制、代谢转变和神经信号传导。BDVAE表明，耐药性跨越了一个连续的生物谱，而不是严格的二元状态，反映了肿瘤功能障碍的渐变。此外，一些潜在特征与生存结果和已知的临床亚型相关，证明了BDVAE能够产生可解释的、具有临床意义的见解。这些发现强调了生物学结构机器学习在阐明复杂的耐药模式和指导精准免疫治疗策略方面的价值。


<details>
  <summary>Details</summary>
Motivation: 免疫检查点抑制剂（ICIs）在癌症治疗中取得了革命性进展，但患者的反应高度可变，且耐药性的生物学机制尚不明确。现有的机器学习模型在预测ICI反应方面虽然有潜力，但普遍缺乏可解释性，并且未能有效利用多组学数据中固有的生物学结构。

Method: 本文提出了一种名为生物解缠变分自编码器（BDVAE）的深度生成模型。该模型通过结合特定于模态（如转录组学）和特定于通路（如免疫、代谢）的编码器来整合基因组学和转录组学数据。BDVAE采用模块化编码器架构，并结合变分推理技术，旨在学习与免疫、基因组和代谢过程相关的、具有生物学意义的潜在特征。

Result: 在对接受ICI治疗的366名患者（涵盖四种癌症类型）的泛癌队列进行分析时，BDVAE在预测治疗反应方面表现出色，在未见过的测试数据上达到了0.94的AUC-ROC值。该模型成功揭示了关键的耐药机制，包括免疫抑制、代谢重编程和神经信号通路。研究还发现，耐药性并非简单的二元状态，而是呈现为一个连续的生物谱，反映了肿瘤功能障碍的不同程度。部分潜在特征与患者的生存结果和已知的临床亚型相关联。

Conclusion: BDVAE模型通过整合多组学数据并结合生物学知识，能够准确预测ICI治疗反应，并揭示复杂的耐药机制。该模型产生的潜在特征具有良好的可解释性和临床相关性，能够反映耐药性的连续谱，并与生存结局相关。这表明，采用生物学结构进行机器学习的方法在阐明肿瘤耐药性机制和指导精准免疫治疗策略方面具有重要价值。

Abstract: Immune checkpoint inhibitors (ICIs) have transformed cancer treatment, yet
patient responses remain highly variable, and the biological mechanisms
underlying resistance are poorly understood. While machine learning models hold
promise for predicting responses to ICIs, most existing methods lack
interpretability and do not effectively leverage the biological structure
inherent to multi-omics data. Here, we introduce the Biologically Disentangled
Variational Autoencoder (BDVAE), a deep generative model that integrates
transcriptomic and genomic data through modality- and pathway-specific
encoders. Unlike existing rigid, pathway-informed models, BDVAE employs a
modular encoder architecture combined with variational inference to learn
biologically meaningful latent features associated with immune, genomic, and
metabolic processes. Applied to a pan-cancer cohort of 366 patients across four
cancer types treated with ICIs, BDVAE accurately predicts treatment response
(AUC-ROC = 0.94 on unseen test data) and uncovers critical resistance
mechanisms, including immune suppression, metabolic shifts, and neuronal
signaling. Importantly, BDVAE reveals that resistance spans a continuous
biological spectrum rather than strictly binary states, reflecting gradations
of tumor dysfunction. Several latent features correlate with survival outcomes
and known clinical subtypes, demonstrating BDVAE's capability to generate
interpretable, clinically relevant insights. These findings underscore the
value of biologically structured machine learning in elucidating complex
resistance patterns and guiding precision immunotherapy strategies.

</details>


### [271] [The Sound of Risk: A Multimodal Physics-Informed Acoustic Model for Forecasting Market Volatility and Enhancing Market Interpretability](https://arxiv.org/abs/2508.18653)
*Xiaoliang Chen,Xin Yu,Le Chang,Teng Jing,Jiashuai He,Ze Wang,Yangjun Luo,Xingyu Chen,Jiayue Liang,Yuchen Wang,Jiaying Xie*

Main category: cs.LG

TL;DR: 本研究提出了一种结合文本情感和声学线索的多模态金融风险评估框架，通过物理信息声学模型（PIAM）提取情感信号，并将其映射到“紧张、稳定、唤醒”三维情感状态标签（ASL）空间。研究发现，该框架能有效预测30天已实现波动率，尤其在CFO和CEO的情感动态变化方面，比仅使用财务数据的基线模型表现更佳。


<details>
  <summary>Details</summary>
Motivation: 金融市场中的信息不对称，尤其是在公司叙事被策略性地操纵时，会削弱传统文本分析的有效性。本研究旨在提出一种新的多模态框架，整合文本情感和来自高管电话会议中声乐特征的语用线索，以改进金融风险评估。

Method: 本研究提出了一种多模态框架，使用物理信息声学模型（PIAM）提取音频中的情感信号，并结合文本情感分析。将文本和音频情感映射到“紧张、稳定、唤醒”三维情感状态标签（ASL）空间。分析了1795次包含约1800小时的财报电话会议数据，提取了高管在正式陈述和问答环节中情感动态变化的特征。

Result: 研究发现，多模态特征能够解释高达43.8%的30天已实现波动率的样本外方差，但无法预测股票回报方向。波动率预测主要受高管从书面陈述到即兴演讲的情感动态驱动，特别是CFO文本稳定性的降低和声学不稳定性增加，以及CEO唤醒度变化的显著性。

Conclusion: 本研究提出的多模态框架通过解码可验证的生物识别信号中的潜在不确定性标记，为投资者和监管机构提供了一个增强市场可解释性和识别隐藏公司不确定性的有力工具。与仅使用财务数据的基线相比，该方法在波动率预测方面表现出显著的优势，证明了声学和文本模态的互补作用。

Abstract: Information asymmetry in financial markets, often amplified by strategically
crafted corporate narratives, undermines the effectiveness of conventional
textual analysis. We propose a novel multimodal framework for financial risk
assessment that integrates textual sentiment with paralinguistic cues derived
from executive vocal tract dynamics in earnings calls. Central to this
framework is the Physics-Informed Acoustic Model (PIAM), which applies
nonlinear acoustics to robustly extract emotional signatures from raw
teleconference sound subject to distortions such as signal clipping. Both
acoustic and textual emotional states are projected onto an interpretable
three-dimensional Affective State Label (ASL) space-Tension, Stability, and
Arousal. Using a dataset of 1,795 earnings calls (approximately 1,800 hours),
we construct features capturing dynamic shifts in executive affect between
scripted presentation and spontaneous Q&A exchanges. Our key finding reveals a
pronounced divergence in predictive capacity: while multimodal features do not
forecast directional stock returns, they explain up to 43.8% of the
out-of-sample variance in 30-day realized volatility. Importantly, volatility
predictions are strongly driven by emotional dynamics during executive
transitions from scripted to spontaneous speech, particularly reduced textual
stability and heightened acoustic instability from CFOs, and significant
arousal variability from CEOs. An ablation study confirms that our multimodal
approach substantially outperforms a financials-only baseline, underscoring the
complementary contributions of acoustic and textual modalities. By decoding
latent markers of uncertainty from verifiable biometric signals, our
methodology provides investors and regulators a powerful tool for enhancing
market interpretability and identifying hidden corporate uncertainty.

</details>


### [272] [FFT-MoE: Efficient Federated Fine-Tuning for Foundation Models via Large-scale Sparse MoE under Heterogeneous Edge](https://arxiv.org/abs/2508.18663)
*Gang Hu,Yinglei Teng,Pengfei Wu,Nan Wang*

Main category: cs.LG

TL;DR: 联邦微调（FFT）结合参数高效微调（PEFT）技术（如LoRA）以应对隐私和资源限制，但在异构环境中存在结构不兼容和对非IID数据的适应性差的问题。本文提出FFT MoE框架，使用稀疏混合专家（MoE）适配器替代LoRA，允许客户端根据本地资源和数据选择性激活专家。此外，引入异构感知辅助损失来平衡专家负载和促进专家多样性。实验证明，FFT MoE在泛化性能和训练效率上优于现有FFT方法。


<details>
  <summary>Details</summary>
Motivation: 为了在隐私和资源受限的异构联邦学习环境中，更有效地对大型模型（如FM）进行微调，以解决现有LoRA-based FFT方法在结构不兼容和对非IID数据适应性差的问题。

Method: 提出FFT MoE框架，使用稀疏混合专家（MoE）适配器替代LoRA，并引入异构感知辅助损失来解决专家负载不平衡和数据异构性问题。

Result: FFT MoE在IID和非IID条件下，相比于现有的FFT基线方法，在泛化性能和训练效率方面均表现更优。

Conclusion: FFT MoE通过引入MoE适配器和异构感知辅助损失，有效解决了现有FFT方法在异构联邦学习环境中的挑战，并在实验中证明了其优越性。

Abstract: As FMs drive progress toward Artificial General Intelligence (AGI),
fine-tuning them under privacy and resource constraints has become increasingly
critical particularly when highquality training data resides on distributed
edge devices. Federated Learning (FL) offers a compelling solution through
Federated Fine-Tuning (FFT), which enables collaborative model adaptation
without sharing raw data. Recent approaches incorporate Parameter-Efficient
Fine-Tuning (PEFT) techniques such as Low Rank Adaptation (LoRA) to reduce
computational overhead. However, LoRA-based FFT faces two major limitations in
heterogeneous FL environments: structural incompatibility across clients with
varying LoRA configurations and limited adaptability to non-IID data
distributions, which hinders convergence and generalization. To address these
challenges, we propose FFT MoE, a novel FFT framework that replaces LoRA with
sparse Mixture of Experts (MoE) adapters. Each client trains a lightweight
gating network to selectively activate a personalized subset of experts,
enabling fine-grained adaptation to local resource budgets while preserving
aggregation compatibility. To further combat the expert load imbalance caused
by device and data heterogeneity, we introduce a heterogeneity-aware auxiliary
loss that dynamically regularizes the routing distribution to ensure expert
diversity and balanced utilization. Extensive experiments spanning both IID and
non-IID conditions demonstrate that FFT MoE consistently outperforms state of
the art FFT baselines in generalization performance and training efficiency.

</details>


### [273] [Auditing Approximate Machine Unlearning for Differentially Private Models](https://arxiv.org/abs/2508.18671)
*Yuechun Gu,Jiajie He,Keke Chen*

Main category: cs.LG

TL;DR: 现有机器学习方法在移除特定数据时，可能无法保证保留数据的隐私性，特别是对于差分隐私模型。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在移除特定数据时，假设保留数据不受影响，但‘隐私洋葱效应’表明该假设可能不成立。尤其是差分隐私模型，未有研究探讨保留数据是否仍满足差分隐私标准。

Method: 提出针对已卸载和保留样本的隐私标准，分别从差分隐私和成员推理攻击（MIAs）的角度进行分析。开发了一种高效的MIA，A-LiRA，利用数据增强来降低影子模型训练成本。

Result: 现有近似机器学习卸载算法可能会损害差分隐私模型的保留数据的隐私性，需要差分隐私卸载算法。

Conclusion: 现有近似机器学习卸载算法在应用于差分隐私模型时，可能会损害保留数据的隐私性，因此需要开发差分隐私卸载算法。

Abstract: Approximate machine unlearning aims to remove the effect of specific data
from trained models to ensure individuals' privacy. Existing methods focus on
the removed records and assume the retained ones are unaffected. However,
recent studies on the \emph{privacy onion effect} indicate this assumption
might be incorrect. Especially when the model is differentially private, no
study has explored whether the retained ones still meet the differential
privacy (DP) criterion under existing machine unlearning methods. This paper
takes a holistic approach to auditing both unlearned and retained samples'
privacy risks after applying approximate unlearning algorithms. We propose the
privacy criteria for unlearned and retained samples, respectively, based on the
perspectives of DP and membership inference attacks (MIAs). To make the
auditing process more practical, we also develop an efficient MIA, A-LiRA,
utilizing data augmentation to reduce the cost of shadow model training. Our
experimental findings indicate that existing approximate machine unlearning
algorithms may inadvertently compromise the privacy of retained samples for
differentially private models, and we need differentially private unlearning
algorithms. For reproducibility, we have pubished our code:
https://anonymous.4open.science/r/Auditing-machine-unlearning-CB10/README.md

</details>


### [274] [Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks](https://arxiv.org/abs/2508.18672)
*Taishi Nakamura,Satoki Ishikawa,Masaki Kawamura,Takumi Okamoto,Daisuke Nohara,Jun Suzuki,Rio Yokota*

Main category: cs.LG

TL;DR: MoE模型的稀疏性影响记忆和推理能力，推理能力会饱和甚至回归


<details>
  <summary>Details</summary>
Motivation: LLM的演进受经验标度定律驱动，但当模型架构或数据管道改变时，其系数会发生变化。MoE模型引入了当前密集模型前沿所忽略的新稀疏维度。研究MoE稀疏性如何影响记忆和推理这两种不同的能力。

Method: 训练了一系列MoE Transformer模型，系统地改变了总参数量、激活参数量和top-k路由，同时保持计算预算固定。记录了预训练损失、下游任务损失和任务准确率，以区分训练-测试泛化差距和损失-准确率差距。

Result: 记忆基准随总参数量的增加而单调递增，与训练损失类似。推理性能饱和甚至回归，尽管总参数量和训练损失持续增加。改变top-k对激活参数量不变的模型影响很小。学习率和初始化等经典超参数在稀疏性方面与泛化差距的调节方向相同。训练后强化学习（GRPO）或额外的测试时间计算无法挽救过度稀疏模型的推理缺陷。

Conclusion: MoE模型的稀疏性对记忆和推理能力有不同的影响，推理能力对稀疏性更敏感，并且存在饱和甚至回归的现象。模型的超参数和训练方法需要针对MoE架构进行调整以优化性能。

Abstract: Empirical scaling laws have driven the evolution of large language models
(LLMs), yet their coefficients shift whenever the model architecture or data
pipeline changes. Mixture-of-Experts (MoE) models, now standard in
state-of-the-art systems, introduce a new sparsity dimension that current
dense-model frontiers overlook. We investigate how MoE sparsity influences two
distinct capability regimes: memorization and reasoning. We train families of
MoE Transformers that systematically vary total parameters, active parameters,
and top-$k$ routing while holding the compute budget fixed. For every model we
record pre-training loss, downstream task loss, and task accuracy, allowing us
to separate the train-test generalization gap from the loss-accuracy gap.
Memorization benchmarks improve monotonically with total parameters, mirroring
training loss. By contrast, reasoning performance saturates and can even
regress despite continued gains in both total parameters and training loss.
Altering top-$k$ alone has little effect when active parameters are constant,
and classic hyperparameters such as learning rate and initialization modulate
the generalization gap in the same direction as sparsity. Neither post-training
reinforcement learning (GRPO) nor extra test-time compute rescues the reasoning
deficit of overly sparse models. Our model checkpoints, code and logs are
open-source at https://github.com/rioyokotalab/optimal-sparsity.

</details>


### [275] [Utilizing Training Data to Improve LLM Reasoning for Tabular Understanding](https://arxiv.org/abs/2508.18676)
*Chufan Gao,Jintai Chen,Jimeng Sun*

Main category: cs.LG

TL;DR: LRTab是一种新的基于提示的表格推理方法，它通过检索从训练数据中学到的相关信息来结合微调和免训练提示的优点，在WikiTQ和TabFact数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动化表格理解和推理是数据科学家的重要任务，而大型语言模型（LLMs）在这些任务中越来越普遍。现有方法存在局限性：微调牺牲了泛化性，而免训练提示则未能充分利用训练数据。

Method: LRTab首先在训练数据上使用提示生成链式思考（CoT）响应。对于错误的CoT，模型会预测“提示条件”以避免错误，从而从数据中学习。在推理时，模型会检索最相关的“提示条件”作为额外上下文以增强表格理解。

Result: 在WikiTQ和TabFact数据集上的实验表明，LRTab具有可解释性、成本效益高，并且在表格推理方面优于现有基线。

Conclusion: LRTab是一种有效的表格推理方法，通过结合学习和检索，克服了现有方法的局限性，并在相关基准测试中取得了优于先前方法的性能。

Abstract: Automated tabular understanding and reasoning are essential tasks for data
scientists. Recently, Large language models (LLMs) have become increasingly
prevalent in tabular reasoning tasks. Previous work focuses on (1) finetuning
LLMs using labeled data or (2) Training-free prompting LLM agents using
chain-of-thought (CoT). Finetuning offers dataset-specific learning at the cost
of generalizability. Training-free prompting is highly generalizable but does
not take full advantage of training data. In this paper, we propose a novel
prompting-based reasoning approach, Learn then Retrieve: LRTab, which
integrates the benefits of both by retrieving relevant information learned from
training data. We first use prompting to obtain CoT responses over the training
data. For incorrect CoTs, we prompt the LLM to predict Prompt Conditions to
avoid the error, learning insights from the data. We validate the effectiveness
of Prompt Conditions using validation data. Finally, at inference time, we
retrieve the most relevant Prompt Conditions for additional context for table
understanding. We provide comprehensive experiments on WikiTQ and Tabfact,
showing that LRTab is interpretable, cost-efficient, and can outperform
previous baselines in tabular reasoning.

</details>


### [276] [End to End Autoencoder MLP Framework for Sepsis Prediction](https://arxiv.org/abs/2508.18688)
*Hejiang Cai,Di Wu,Ji Xu,Xiang Liu,Yiziting Zhu,Xin Shu,Yujie Li,Bin Yi*

Main category: cs.LG

TL;DR: 深度学习框架用于ICU中的脓毒症早期检测，优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命且需要在重症监护环境中及时检测的疾病。传统的机器学习方法在处理电子健康记录中常见的不规则、不完整的时间序列数据时，依赖手动特征工程，并且存在困难。

Method: 提出了一种端到端的深度学习框架，整合了无监督自动编码器用于自动特征提取和多层感知机分类器用于二元脓毒症风险预测。为了增强临床应用性，实施了一种定制的下采样策略，在训练期间提取高信息密度的片段，并采用非重叠的动态滑动窗口机制进行实时推理。预处理的时间序列数据表示为具有显式缺失指示符的固定维度向量，以减轻偏差和噪声。

Result: 该模型在三个ICU队列上进行了验证，准确率分别为74.6%、80.6%和93.5%，一致优于传统的机器学习基线。

Conclusion: 该框架在脓毒症早期检测方面具有优越的鲁棒性、泛化能力和临床效用，能够跨不同的ICU环境进行早期脓毒症检测。

Abstract: Sepsis is a life threatening condition that requires timely detection in
intensive care settings. Traditional machine learning approaches, including
Naive Bayes, Support Vector Machine (SVM), Random Forest, and XGBoost, often
rely on manual feature engineering and struggle with irregular, incomplete
time-series data commonly present in electronic health records. We introduce an
end-to-end deep learning framework integrating an unsupervised autoencoder for
automatic feature extraction with a multilayer perceptron classifier for binary
sepsis risk prediction. To enhance clinical applicability, we implement a
customized down sampling strategy that extracts high information density
segments during training and a non-overlapping dynamic sliding window mechanism
for real-time inference. Preprocessed time series data are represented as fixed
dimension vectors with explicit missingness indicators, mitigating bias and
noise. We validate our approach on three ICU cohorts. Our end-to-end model
achieves accuracies of 74.6 percent, 80.6 percent, and 93.5 percent,
respectively, consistently outperforming traditional machine learning
baselines. These results demonstrate the framework's superior robustness,
generalizability, and clinical utility for early sepsis detection across
heterogeneous ICU environments.

</details>


### [277] [Natural Image Classification via Quasi-Cyclic Graph Ensembles and Random-Bond Ising Models at the Nishimori Temperature](https://arxiv.org/abs/2508.18717)
*V. S. Usatyuk,D. A. Sapoznikov,S. I. Egorov*

Main category: cs.LG

TL;DR: 提出一个结合统计物理、编码理论和代数拓扑的统一框架，用于高效的多类别图像分类。将MobileNetV2提取的高维特征向量解释为稀疏MET-QC-LDPC图上的自旋，形成RBIM模型，并在Nishimori温度下操作以最大化类别可分离性。该理论将代码图中的局部陷阱集与特征流形的拓扑不变量联系起来。通过二次插值和牛顿校正，算法可高效估计Nishimori温度，速度比二分法快六倍。通过设计球形和环形MET-QC-LDPC图并使用永久界限抑制陷阱集，将1280维特征压缩到32或64维，在ImageNet子集上实现了98.7%（ImageNet-10）和82.7%（ImageNet-100）的准确率，证明了拓扑引导图设计在物理启发嵌入方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效的多类别图像分类，提出一个结合统计物理、编码理论和代数拓扑的统一框架。

Method: 将MobileNetV2提取的高维特征向量解释为稀疏MET-QC-LDPC图上的自旋，形成RBIM模型，并在Nishimori温度下操作。通过二次插值和牛顿校正估计Nishimori温度。设计球形和环形MET-QC-LDPC图，并使用永久界限抑制陷阱集。

Result: 在ImageNet子集上，将1280维特征压缩到32或64维（参数减少40倍），实现了98.7%（ImageNet-10）和82.7%（ImageNet-100）的准确率。

Conclusion: 拓扑引导图设计能够实现高效、受物理启发且性能先进的嵌入。

Abstract: We present a unified framework combining statistical physics, coding theory,
and algebraic topology for efficient multi-class image classification.
High-dimensional feature vectors from a frozen MobileNetV2 backbone are
interpreted as spins on a sparse Multi-Edge Type quasi-cyclic LDPC
(MET-QC-LDPC) graph, forming a Random-Bond Ising Model (RBIM). We operate this
RBIM at its Nishimori temperature, $\beta_N$, where the smallest eigenvalue of
the Bethe-Hessian matrix vanishes, maximizing class separability.
  Our theoretical contribution establishes a correspondence between local
trapping sets in the code's graph and topological invariants (Betti numbers,
bordism classes) of the feature manifold. A practical algorithm estimates
$\beta_N$ efficiently with a quadratic interpolant and Newton correction,
achieving a six-fold speed-up over bisection.
  Guided by topology, we design spherical and toroidal MET-QC-LDPC graph
ensembles, using permanent bounds to suppress harmful trapping sets. This
compresses 1280-dimensional features to 32 or 64 dimensions for ImageNet-10 and
-100 subsets. Despite massive compression (40x fewer parameters), we achieve
98.7% accuracy on ImageNet-10 and 82.7% on ImageNet-100, demonstrating that
topology-guided graph design yields highly efficient, physics-inspired
embeddings with state-of-the-art performance.

</details>


### [278] [Beyond Tokens: Enhancing RTL Quality Estimation via Structural Graph Learning](https://arxiv.org/abs/2508.18730)
*Yi Liu,Hongji Zhang,Yiwen Wang,Dimitris Tsaras,Lei Chen,Mingxuan Yuan,Qiang Xu*

Main category: cs.LG

TL;DR: LLM在RTL代码质量估计中忽略了结构语义，提出了一种基于CDFG的结构感知图自监督学习框架StructRTL，并通过知识蒸馏进一步提升性能，实现了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: RTL设计质量估计对EDA工作流至关重要，需要快速反馈，但现有LLM方法忽略了结构语义，而CDFG视图能更明确地暴露结构特性。

Method: 提出了一种新颖的结构感知图自监督学习框架StructRTL，从CDFG中学习信息表示，并结合知识蒸馏策略，将低级见解从映射后的网表中转移到CDFG预测器。

Result: StructRTL在各种质量估计任务上显著优于现有方法，并通过实验证明了结合结构学习和跨阶段监督的有效性，取得了新的SOTA结果。

Conclusion: 结合结构学习和跨阶段监督的方法在RTL设计质量估计方面非常有效。

Abstract: Estimating the quality of register transfer level (RTL) designs is crucial in
the electronic design automation (EDA) workflow, as it enables instant feedback
on key metrics like area and delay without the need for time-consuming logic
synthesis. While recent approaches have leveraged large language models (LLMs)
to derive embeddings from RTL code and achieved promising results, they
overlook the structural semantics essential for accurate quality estimation. In
contrast, the control data flow graph (CDFG) view exposes the design's
structural characteristics more explicitly, offering richer cues for
representation learning. In this work, we introduce a novel structure-aware
graph self-supervised learning framework, StructRTL, for improved RTL design
quality estimation. By learning structure-informed representations from CDFGs,
our method significantly outperforms prior art on various quality estimation
tasks. To further boost performance, we incorporate a knowledge distillation
strategy that transfers low-level insights from post-mapping netlists into the
CDFG predictor. Experiments show that our approach establishes new
state-of-the-art results, demonstrating the effectiveness of combining
structural learning with cross-stage supervision.

</details>


### [279] [FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks](https://arxiv.org/abs/2508.18737)
*Enrique Mármol Campos,Aurora González Vidal,José Luis Hernández Ramos,Antonio Skarmeta*

Main category: cs.LG

TL;DR: FLAeigs是一个用于检测拜占庭客户端和提高联邦学习（FL）系统鲁棒性的防御框架。它使用符号时间序列变换（SAX）和谱聚类来识别恶意行为，并采用基于FFT的聚合函数来减轻拜占庭客户端的影响。


<details>
  <summary>Details</summary>
Motivation: 为了应对联邦学习（FL）中拜占庭客户端通过提交错误模型更新来破坏训练过程的问题，本研究提出了FLAeigs。

Method: FLAeigs采用符号时间序列变换（SAX）来放大良性和恶意模型之间的差异，并利用谱聚类来准确检测对抗性行为。此外，还结合了基于FFT的聚合函数来减轻逃避检测的拜占庭客户端的影响。

Result: FLAeigs在检测精度和最终模型准确性方面均优于最先进的防御方法，即使在严苛的对抗性条件下也能保持高性能。

Conclusion: FLAeigs通过结合SAX、谱聚类和FFT聚合函数，成功地防御了五种中毒攻击，提高了联邦学习系统的鲁棒性。

Abstract: Federated Learning (FL) has become a powerful technique for training Machine
Learning (ML) models in a decentralized manner, preserving the privacy of the
training datasets involved. However, the decentralized nature of FL limits the
visibility of the training process, relying heavily on the honesty of
participating clients. This assumption opens the door to malicious third
parties, known as Byzantine clients, which can poison the training process by
submitting false model updates. Such malicious clients may engage in poisoning
attacks, manipulating either the dataset or the model parameters to induce
misclassification. In response, this study introduces FLAegis, a two-stage
defensive framework designed to identify Byzantine clients and improve the
robustness of FL systems. Our approach leverages symbolic time series
transformation (SAX) to amplify the differences between benign and malicious
models, and spectral clustering, which enables accurate detection of
adversarial behavior. Furthermore, we incorporate a robust FFT-based
aggregation function as a final layer to mitigate the impact of those Byzantine
clients that manage to evade prior defenses. We rigorously evaluate our method
against five poisoning attacks, ranging from simple label flipping to adaptive
optimization-based strategies. Notably, our approach outperforms
state-of-the-art defenses in both detection precision and final model accuracy,
maintaining consistently high performance even under strong adversarial
conditions.

</details>


### [280] [Stability and Generalization for Bellman Residuals](https://arxiv.org/abs/2508.18741)
*Enoch H. Kang,Kyoungseok Jang*

Main category: cs.LG

TL;DR: 本文研究了离线强化学习和离线逆强化学习中的Bellman残差最小化（BRM）方法，并分析了其统计性质。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习和离线逆强化学习方法在强制实施Bellman一致性方面仍有不足，而BRM作为一种有吸引力的解决方案，但其在离线设置下的统计行为尚未得到充分研究。

Method: 通过引入一个Lyapunov势能函数，将SGDA（随机梯度下降-上升）在邻近数据集上的运行耦合起来，从而在平均意义下实现了O(1/n)的论证稳定性界，该界限将凸-凹鞍点问题的样本复杂度指数加倍。

Result: 所提出的稳定性常数也同样适用于BRM的O(1/n)超额风险界，并且无需方差缩减、额外正则化或对小批量采样进行限制性独立性假设。

Conclusion: 该分析结果适用于标准的神经网络参数化和小批量SGD。

Abstract: Offline reinforcement learning and offline inverse reinforcement learning aim
to recover near-optimal value functions or reward models from a fixed batch of
logged trajectories, yet current practice still struggles to enforce Bellman
consistency. Bellman residual minimization (BRM) has emerged as an attractive
remedy, as a globally convergent stochastic gradient descent-ascent based
method for BRM has been recently discovered. However, its statistical behavior
in the offline setting remains largely unexplored. In this paper, we close this
statistical gap. Our analysis introduces a single Lyapunov potential that
couples SGDA runs on neighbouring datasets and yields an O(1/n) on-average
argument-stability bound-doubling the best known sample-complexity exponent for
convex-concave saddle problems. The same stability constant translates into the
O(1/n) excess risk bound for BRM, without variance reduction, extra
regularization, or restrictive independence assumptions on minibatch sampling.
The results hold for standard neural-network parameterizations and minibatch
SGD.

</details>


### [281] [Constraint Matters: Multi-Modal Representation for Reducing Mixed-Integer Linear programming](https://arxiv.org/abs/2508.18742)
*Jiajun Li,Ran Hou,Yu Ding,Yixuan Li,Shisi Guan,Jiahui Duan,Xiongwei Han,Tao Zhong,Vincent Chau,Weiwei Wu,Wanyuan Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的约束缩减方法，用于加速混合整数线性规划（MILP）问题的求解，并在实验中取得了显著的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的MILP模型缩减方法主要基于变量缩减，而忽略了从对偶角度进行约束缩减，该研究旨在填补这一空白，提出一种约束缩减方法来降低MILP问题的复杂度。

Method: 该方法首先识别出最优解中的关键紧约束，并通过启发式规则选择其中一部分作为缩减目标。然后，利用实例级和抽象级MILP表征的多模态技术来学习这些关键紧约束。

Result: 与现有最先进方法相比，该方法将解的质量提高了50%以上，并将计算时间减少了17.47%。

Conclusion: 该约束缩减方法是一种有效降低MILP问题复杂性并加速求解的新途径，在实际应用中具有显著优势。

Abstract: Model reduction, which aims to learn a simpler model of the original mixed
integer linear programming (MILP), can solve large-scale MILP problems much
faster. Most existing model reduction methods are based on variable reduction,
which predicts a solution value for a subset of variables. From a dual
perspective, constraint reduction that transforms a subset of inequality
constraints into equalities can also reduce the complexity of MILP, but has
been largely ignored. Therefore, this paper proposes a novel constraint-based
model reduction approach for the MILP. Constraint-based MILP reduction has two
challenges: 1) which inequality constraints are critical such that reducing
them can accelerate MILP solving while preserving feasibility, and 2) how to
predict these critical constraints efficiently. To identify critical
constraints, we first label these tight-constraints at the optimal solution as
potential critical constraints and design a heuristic rule to select a subset
of critical tight-constraints. To learn the critical tight-constraints, we
propose a multi-modal representation technique that leverages information from
both instance-level and abstract-level MILP formulations. The experimental
results show that, compared to the state-of-the-art methods, our method
improves the quality of the solution by over 50\% and reduces the computation
time by 17.47\%.

</details>


### [282] [UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning](https://arxiv.org/abs/2508.18756)
*Zihao Huang,Yu Bao,Qiyang Min,Siyan Chen,Ran Guo,Hongzhi Huang,Defa Zhu,Yutao Zeng,Banggu Wu,Xun Zhou,Siyuan Qiao*

Main category: cs.LG

TL;DR: UltraMemV2是一种新的记忆层架构，性能与8专家MoE模型相当，但内存访问量大大降低，尤其在内存密集型任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决现有MoE模型在推理时存在高内存访问成本的问题，并缩小记忆层架构与先进的8专家MoE模型之间的性能差距。

Method: UltraMemV2通过以下五种关键改进来提升性能：将记忆层集成到每个Transformer块中，使用单一线性投影简化值扩展，采用PEER中的FFN（前馈网络）进行值处理，实现原则性的参数初始化，以及重新平衡记忆与FFN的计算比例。

Result: UltraMemV2在相同计算量和参数量下，达到了与8专家MoE模型相当的性能，但内存访问量显著降低。在内存密集型任务上，UltraMemV2表现更优，长上下文记忆能力提升了+1.6，多轮记忆能力提升了+6.2，上下文学习能力提升了+7.9。

Conclusion: UltraMemV2成功将记忆层架构的性能提升至与先进的MoE模型相当的水平，为高效稀疏计算提供了一个有吸引力的替代方案。研究还表明，激活密度对模型性能的影响比稀疏参数总数更大。

Abstract: While Mixture of Experts (MoE) models achieve remarkable efficiency by
activating only subsets of parameters, they suffer from high memory access
costs during inference. Memory-layer architectures offer an appealing
alternative with very few memory access, but previous attempts like UltraMem
have only matched the performance of 2-expert MoE models, falling significantly
short of state-of-the-art 8-expert configurations. We present UltraMemV2, a
redesigned memory-layer architecture that closes this performance gap. Our
approach introduces five key improvements: integrating memory layers into every
transformer block, simplifying value expansion with single linear projections,
adopting FFN-based value processing from PEER, implementing principled
parameter initialization, and rebalancing memory-to-FFN computation ratios.
Through extensive evaluation, we demonstrate that UltraMemV2 achieves
performance parity with 8-expert MoE models under same computation and
parameters but significantly low memory access. Notably, UltraMemV2 shows
superior performance on memory-intensive tasks, with improvements of +1.6
points on long-context memorization, +6.2 points on multi-round memorization,
and +7.9 points on in-context learning. We validate our approach at scale with
models up to 2.5B activated parameters from 120B total parameters, and
establish that activation density has greater impact on performance than total
sparse parameter count. Our work brings memory-layer architectures to
performance parity with state-of-the-art MoE models, presenting a compelling
alternative for efficient sparse computation.

</details>


### [283] [Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement](https://arxiv.org/abs/2508.18765)
*Helen Pervez,Suyash Gaurav,Jukka Heikkonen,Jatin Chaudhary*

Main category: cs.LG

TL;DR: AI系统演变成分布式生态系统，但缺乏可扩展、解耦的治理是一个结构性风险。本研究提出治理即服务（GaaS），一个模块化的、策略驱动的执行层，在运行时监管代理输出，而不改变模型内部或需要代理配合。GaaS采用声明式规则和信任因子机制，根据合规性和严重性加权的违规行为对代理进行评分。它能够进行强制性、规范性和适应性干预，支持分级执法和动态信任调整。通过在内容生成和金融决策中，使用开源模型（LLaMA3、Qwen3、DeepSeek-R1）进行三种模拟实验来评估GaaS。结果表明，GaaS能够可靠地阻止或重定向高风险行为，同时保持吞吐量。信任分数跟踪规则遵守情况，隔离并惩罚多代理系统中的不可信组件。通过将治理定位为类似计算或存储的运行时服务，GaaS为可互操作的代理生态系统建立了基础设施级别的对齐。它不教授代理道德，而是强制执行它们。


<details>
  <summary>Details</summary>
Motivation: AI系统正朝着分布式、自主执行、异步推理和多主体协调的生态系统发展，但缺乏可扩展、解耦的治理机制带来了结构性风险。现有的监督机制存在反应性差、脆弱、嵌入代理内部、难以审计且难以推广到不同部署环境等问题。

Method: 提出治理即服务（GaaS），一个模块化的、策略驱动的执行层，在运行时监管代理输出，而不改变模型内部或需要代理配合。GaaS采用声明式规则和信任因子机制，根据合规性和严重性加权的违规行为对代理进行评分。它支持强制性、规范性和适应性干预，允许分级执法和动态信任调整。通过三类模拟实验（基线、GaaS强制执行、对抗性探测）评估GaaS在内容生成和金融决策任务中对LLaMA3、Qwen3、DeepSeek-R1等开源模型的影响。

Result: GaaS能够可靠地阻止或重定向高风险行为，同时保持吞吐量。信任分数能有效跟踪规则遵守情况，并在多代理系统中隔离和惩罚不可信的组件。

Conclusion: 通过将治理作为一种类似于计算或存储的运行时服务，GaaS为可互操作的代理生态系统提供了基础设施级别的对齐，强制执行既定规则而非教授道德。

Abstract: As AI systems evolve into distributed ecosystems with autonomous execution,
asynchronous reasoning, and multi-agent coordination, the absence of scalable,
decoupled governance poses a structural risk. Existing oversight mechanisms are
reactive, brittle, and embedded within agent architectures, making them
non-auditable and hard to generalize across heterogeneous deployments.
  We introduce Governance-as-a-Service (GaaS): a modular, policy-driven
enforcement layer that regulates agent outputs at runtime without altering
model internals or requiring agent cooperation. GaaS employs declarative rules
and a Trust Factor mechanism that scores agents based on compliance and
severity-weighted violations. It enables coercive, normative, and adaptive
interventions, supporting graduated enforcement and dynamic trust modulation.
  To evaluate GaaS, we conduct three simulation regimes with open-source models
(LLaMA3, Qwen3, DeepSeek-R1) across content generation and financial
decision-making. In the baseline, agents act without governance; in the second,
GaaS enforces policies; in the third, adversarial agents probe robustness. All
actions are intercepted, evaluated, and logged for analysis. Results show that
GaaS reliably blocks or redirects high-risk behaviors while preserving
throughput. Trust scores track rule adherence, isolating and penalizing
untrustworthy components in multi-agent systems.
  By positioning governance as a runtime service akin to compute or storage,
GaaS establishes infrastructure-level alignment for interoperable agent
ecosystems. It does not teach agents ethics; it enforces them.

</details>


### [284] [Predicting Drug-Drug Interactions Using Heterogeneous Graph Neural Networks: HGNN-DDI](https://arxiv.org/abs/2508.18766)
*Hongbo Liu,Siyi Li,Zheng Yu*

Main category: cs.LG

TL;DR: HGNN-DDI是一个异构图神经网络模型，用于预测药物-药物相互作用（DDIs），通过整合多种药物相关数据源，并在基准DDI数据集上实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 药物-药物相互作用（DDIs）是临床实践中的一个主要问题，可能导致治疗效果降低或产生严重的副作用。传统的计算方法在捕捉药物、靶点和生物实体之间复杂关系方面存在困难。

Method: 提出了一种名为HGNN-DDI的异构图神经网络模型，该模型利用图表示学习来建模异构生物医学网络，并整合了多种药物相关的数据库，以预测潜在的DDIs。

Result: 在基准DDI数据集上的实验结果表明，HGNN-DDI在预测准确性和鲁棒性方面优于现有的基线方法。

Conclusion: HGNN-DDI模型在预测DDIs方面表现出色，有潜力支持更安全的药物开发和精准医疗。

Abstract: Drug-drug interactions (DDIs) are a major concern in clinical practice, as
they can lead to reduced therapeutic efficacy or severe adverse effects.
Traditional computational approaches often struggle to capture the complex
relationships among drugs, targets, and biological entities. In this work, we
propose HGNN-DDI, a heterogeneous graph neural network model designed to
predict potential DDIs by integrating multiple drug-related data sources.
HGNN-DDI leverages graph representation learning to model heterogeneous
biomedical networks, enabling effective information propagation across diverse
node and edge types. Experimental results on benchmark DDI datasets demonstrate
that HGNN-DDI outperforms state-of-the-art baselines in prediction accuracy and
robustness, highlighting its potential to support safer drug development and
precision medicine.

</details>


### [285] [Federated Learning with Heterogeneous and Private Label Sets](https://arxiv.org/abs/2508.18774)
*Adam Breitholtz,Edvin Listo Zec,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 虽然在实际应用中很常见，但联邦学习（FL）中很少研究异构客户端标签集的问题。此外，在研究这些问题的情况下，通常假设客户端愿意与其​​他客户端共享其所有标签集。具有仅与中央服务器共享的私有标签集的联邦学习，对学习算法增加了更多约束，并且通常是更难解决的问题。本研究探讨了标签集异构性对模型性能的影响，并比较了公共和私有标签设置——即联合的标签集是客户端已知和未知的。我们应用经典的分类器组合问题方法进行集中式调优的FL，将常用的FL方法调整为私有标签设置，并讨论这两种方法在实际假设下的合理性。实验表明，减少每个客户端可用的标签数量会严重损害所有方法的性能。集中式调优客户端模型以进行表示对齐有助于缓解此问题，但通常会以更高的方差为代价。尽管如此，我们提出的标准FL方法改编在私有标签设置中表现良好，其性能与公共设置中的标准方法相似。这表明客户端可以在模型准确性损失很小的情况下享受更高的隐私。


<details>
  <summary>Details</summary>
Motivation: 研究联邦学习（FL）中异构客户端标签集的影响，特别是在客户端仅与服务器共享其标签集的私有标签设置下。

Method: 将经典的分类器组合问题方法应用于具有集中式调优的FL；将常用的FL方法调整为私有标签设置。

Result: 减少每个客户端可用的标签数量会严重损害所有方法的性能。集中式调优客户端模型以进行表示对齐有助于缓解此问题，但可能增加方差。提出的标准FL方法改编在私有标签设置中表现良好，性能与公共设置中的标准方法相似。

Conclusion: 客户端可以在模型准确性损失很小的情况下享受更高的隐私。

Abstract: Although common in real-world applications, heterogeneous client label sets
are rarely investigated in federated learning (FL). Furthermore, in the cases
they are, clients are assumed to be willing to share their entire label sets
with other clients. Federated learning with private label sets, shared only
with the central server, adds further constraints on learning algorithms and
is, in general, a more difficult problem to solve. In this work, we study the
effects of label set heterogeneity on model performance, comparing the public
and private label settings -- when the union of label sets in the federation is
known to clients and when it is not. We apply classical methods for the
classifier combination problem to FL using centralized tuning, adapt common FL
methods to the private label set setting, and discuss the justification of both
approaches under practical assumptions. Our experiments show that reducing the
number of labels available to each client harms the performance of all methods
substantially. Centralized tuning of client models for representational
alignment can help remedy this, but often at the cost of higher variance.
Throughout, our proposed adaptations of standard FL methods perform well,
showing similar performance in the private label setting as the standard
methods achieve in the public setting. This shows that clients can enjoy
increased privacy at little cost to model accuracy.

</details>


### [286] [SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation](https://arxiv.org/abs/2508.18826)
*Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh*

Main category: cs.LG

TL;DR: SWiFT是一个有效的模型去偏框架，它在提高模型公平性的同时，能够保持甚至提升模型的准确性，并且具有较低的去偏成本。


<details>
  <summary>Details</summary>
Motivation: 现有模型去偏方法需要访问原始训练数据并进行大量的模型重新训练，同时在模型公平性和判别性性能之间存在权衡。为解决这些挑战，需要一种更有效的方法来去除训练好的模型中的偏见。

Method: SWiFT首先找出模型参数对偏见和预测性能的相对且不同的贡献。然后，通过一个两步微调过程，根据每个参数的贡献更新其梯度流。

Result: SWiFT在三个偏见敏感属性（性别、肤色和年龄）以及四个皮肤病学和两个胸部X光数据集上的实验表明，SWiFT能够持续减少模型偏见，同时在常见的公平性和准确性指标上实现具有竞争力甚至更优的诊断准确性。此外，SWiFT还能提高模型的泛化能力，在分布外（OOD）数据集上表现更优。

Conclusion: SWiFT是一种高效的去偏框架，仅需少量外部数据和几轮模型微调，即可在保持或提升模型性能的同时显著减少模型偏见，并在多个敏感属性和数据集上优于现有最先进的方法。

Abstract: Recent studies have shown that Machine Learning (ML) models can exhibit bias
in real-world scenarios, posing significant challenges in ethically sensitive
domains such as healthcare. Such bias can negatively affect model fairness,
model generalization abilities and further risks amplifying social
discrimination. There is a need to remove biases from trained models. Existing
debiasing approaches often necessitate access to original training data and
need extensive model retraining; they also typically exhibit trade-offs between
model fairness and discriminative performance. To address these challenges, we
propose Soft-Mask Weight Fine-Tuning (SWiFT), a debiasing framework that
efficiently improves fairness while preserving discriminative performance with
much less debiasing costs. Notably, SWiFT requires only a small external
dataset and only a few epochs of model fine-tuning. The idea behind SWiFT is to
first find the relative, and yet distinct, contributions of model parameters to
both bias and predictive performance. Then, a two-step fine-tuning process
updates each parameter with different gradient flows defined by its
contribution. Extensive experiments with three bias sensitive attributes
(gender, skin tone, and age) across four dermatological and two chest X-ray
datasets demonstrate that SWiFT can consistently reduce model bias while
achieving competitive or even superior diagnostic accuracy under common
fairness and accuracy metrics, compared to the state-of-the-art. Specifically,
we demonstrate improved model generalization ability as evidenced by superior
performance on several out-of-distribution (OOD) datasets.

</details>


### [287] [DRMD: Deep Reinforcement Learning for Malware Detection under Concept Drift](https://arxiv.org/abs/2508.18839)
*Shae McFadden,Myles Foley,Mario D'Onghia,Chris Hicks,Vasilios Mavroudis,Nicola Paoletti,Fabio Pierazzi*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DRMD的新型恶意软件检测方法，利用深度强化学习（DRL）优化分类性能并识别高风险样本以进行人工标注，从而提高对概念漂移的抵御能力。


<details>
  <summary>Details</summary>
Motivation: 传统恶意软件检测方法在面对不断演变威胁、有限标注预算和不确定预测时性能会下降，无法优化何时将决策推迟给人工标注和适应。

Method: 提出将恶意软件检测构建为一步马尔可夫决策过程，并训练深度强化学习（DRL）代理，同时优化样本分类性能和拒绝高风险样本以进行人工标注。

Result: 在安卓恶意软件数据集上进行的时序评估结果显示，DRMD代理在分类、拒绝和主动学习（AL）设置下，平均AUT性能分别提高了$5.18	ext{ }	imes	ext{ }5.44$、$14.49	ext{ }	imes	ext{ }12.86$和$10.06	ext{ }	imes	ext{ }10.81$，优于标准的分类方法，证明了其在概念漂移下的鲁棒性。

Conclusion: 深度强化学习（DRL）可以有效地促进恶意软件检测，并提高在动态安卓恶意软件领域中概念漂移的抵御能力。

Abstract: Malware detection in real-world settings must deal with evolving threats,
limited labeling budgets, and uncertain predictions. Traditional classifiers,
without additional mechanisms, struggle to maintain performance under concept
drift in malware domains, as their supervised learning formulation cannot
optimize when to defer decisions to manual labeling and adaptation. Modern
malware detection pipelines combine classifiers with monthly active learning
(AL) and rejection mechanisms to mitigate the impact of concept drift. In this
work, we develop a novel formulation of malware detection as a one-step Markov
Decision Process and train a deep reinforcement learning (DRL) agent,
simultaneously optimizing sample classification performance and rejecting
high-risk samples for manual labeling. We evaluated the joint detection and
drift mitigation policy learned by the DRL-based Malware Detection (DRMD) agent
through time-aware evaluations on Android malware datasets subject to realistic
drift requiring multi-year performance stability. The policies learned under
these conditions achieve a higher Area Under Time (AUT) performance compared to
standard classification approaches used in the domain, showing improved
resilience to concept drift. Specifically, the DRMD agent achieved a
$5.18\pm5.44$, $14.49\pm12.86$, and $10.06\pm10.81$ average AUT performance
improvement for the classification only, classification with rejection, and
classification with rejection and AL settings, respectively. Our results
demonstrate for the first time that DRL can facilitate effective malware
detection and improved resiliency to concept drift in the dynamic environment
of the Android malware domain.

</details>


### [288] [Recycling History: Efficient Recommendations from Contextual Dueling Bandits](https://arxiv.org/abs/2508.18841)
*Suryanarayana Sankagiri,Jalal Etesami,Pouria Fatemi,Matthias Grossglauser*

Main category: cs.LG

TL;DR: 该研究提出了一种新的上下文对策机器人模型，用于解决带内反馈的推荐系统问题，并通过模拟证明了其 O(sqrt(T)) 的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文对策机器人模型无法捕捉用户在消费物品后进行比较查询的情况，而用户在消费物品后提供的反馈更可靠。本研究旨在解决这一问题，并提出一种新的机器人模型。

Method: 研究提出了一种新的机器人模型，其中算法在每个时间步推荐一个物品，用户在消费该物品后，将其与用户消费历史中的另一个物品进行比较。该模型通过矩阵浓度界限证明了其 O(sqrt(T)) 的遗憾界限，并表明重用过去物品进行比较可以显著降低遗憾。

Result: 通过理论分析和模拟，研究表明该算法可以在用户历史丰富的情况下构建信息查询，并且可以通过短时间随机探索来积累丰富历史。模拟结果还表明，重用过去物品进行比较比仅在同时推荐的物品之间进行比较可以显著降低遗憾。

Conclusion: 该研究提出的新机器人模型能够有效处理带内反馈，并通过理论和模拟证明了其性能优势，为推荐系统领域提供了新的解决方案。

Abstract: The contextual duelling bandit problem models adaptive recommender systems,
where the algorithm presents a set of items to the user, and the user's choice
reveals their preference. This setup is well suited for implicit choices users
make when navigating a content platform, but does not capture other possible
comparison queries. Motivated by the fact that users provide more reliable
feedback after consuming items, we propose a new bandit model that can be
described as follows. The algorithm recommends one item per time step; after
consuming that item, the user is asked to compare it with another item chosen
from the user's consumption history. Importantly, in our model, this comparison
item can be chosen without incurring any additional regret, potentially leading
to better performance. However, the regret analysis is challenging because of
the temporal dependency in the user's history. To overcome this challenge, we
first show that the algorithm can construct informative queries provided the
history is rich, i.e., satisfies a certain diversity condition. We then show
that a short initial random exploration phase is sufficient for the algorithm
to accumulate a rich history with high probability. This result, proven via
matrix concentration bounds, yields $O(\sqrt{T})$ regret guarantees.
Additionally, our simulations show that reusing past items for comparisons can
lead to significantly lower regret than only comparing between simultaneously
recommended items.

</details>


### [289] [C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning](https://arxiv.org/abs/2508.18860)
*Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun*

Main category: cs.LG

TL;DR: 该研究提出了一种名为C-Flat的新型持续学习方法，通过促进更平坦的损失边界来提高模型在学习新任务时保留旧知识的能力，并进一步推出了更高效的C-Flat++版本，在多种设置下均表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中平衡新任务学习和旧知识保留的挑战，并指出现有基于梯度峭度的方法可能偏向于更尖锐的最小值，导致解决方案不够鲁棒。

Method: 提出了一种名为C-Flat的即插即用方法，旨在促进持续学习的更平坦的损失边界。此外，还提出了一个通用框架，将C-Flat集成到主要的持续学习范式中，并引入了C-Flat++，一种利用选择性平坦度驱动的促进来降低更新成本的高效框架。

Result: C-Flat在多种设置下持续提高了性能，并且C-Flat++在效率和效果上都表现出色。实验结果表明，所提出的方法在多种持续学习方法、数据集和场景中都有效且高效。

Conclusion: C-Flat及其高效版本C-Flat++能够有效解决持续学习中的稳定性与可塑性之间的权衡问题，并在各种实验设置中展示了其优越的性能和效率。

Abstract: Balancing sensitivity to new tasks and stability for retaining past knowledge
is crucial in continual learning (CL). Recently, sharpness-aware minimization
has proven effective in transfer learning and has also been adopted in
continual learning (CL) to improve memory retention and learning efficiency.
However, relying on zeroth-order sharpness alone may favor sharper minima over
flatter ones in certain settings, leading to less robust and potentially
suboptimal solutions. In this paper, we propose \textbf{C}ontinual
\textbf{Flat}ness (\textbf{C-Flat}), a method that promotes flatter loss
landscapes tailored for CL. C-Flat offers plug-and-play compatibility, enabling
easy integration with minimal modifications to the code pipeline. Besides, we
present a general framework that integrates C-Flat into all major CL paradigms
and conduct comprehensive comparisons with loss-minima optimizers and
flat-minima-based CL methods. Our results show that C-Flat consistently
improves performance across a wide range of settings. In addition, we introduce
C-Flat++, an efficient yet effective framework that leverages selective
flatness-driven promotion, significantly reducing the update cost required by
C-Flat. Extensive experiments across multiple CL methods, datasets, and
scenarios demonstrate the effectiveness and efficiency of our proposed
approaches. Code is available at https://github.com/WanNaa/C-Flat.

</details>


### [290] [MOCHA: Discovering Multi-Order Dynamic Causality in Temporal Point Processes](https://arxiv.org/abs/2508.18873)
*Yunyang Cao,Juekai Lin,Wenhao Li,Bo Jin*

Main category: cs.LG

TL;DR: MOCHA是一个用于发现TPPs中的多阶动态因果关系的新框架，通过学习时变DAG来模拟多阶影响，并在事件预测和因果结构发现方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在对时间点过程（TPPs）中的因果依赖性建模时，通常依赖于静态或一阶因果结构，忽略了因果关系的得多阶和时变特性。

Method: MOCHA将多阶影响表征为潜在时间演化图上的多跳因果路径，通过引入具有可学习结构权重、强制执行无环和稀疏性约束的时变有向无环图（DAG），设计了一个端到端的、可微分的框架，用于联合建模因果发现和TPP动态。

Result: MOCHA在事件预测方面取得了最先进的性能，并揭示了有意义且可解释的因果结构。

Conclusion: MOCHA在真实数据集上的广泛实验证明了其在事件预测方面的优越性以及揭示可解释因果结构的能力。

Abstract: Discovering complex causal dependencies in temporal point processes (TPPs) is
critical for modeling real-world event sequences. Existing methods typically
rely on static or first-order causal structures, overlooking the multi-order
and time-varying nature of causal relationships. In this paper, we propose
MOCHA, a novel framework for discovering multi-order dynamic causality in TPPs.
MOCHA characterizes multi-order influences as multi-hop causal paths over a
latent time-evolving graph. To model such dynamics, we introduce a time-varying
directed acyclic graph (DAG) with learnable structural weights, where
acyclicity and sparsity constraints are enforced to ensure structural validity.
We design an end-to-end differentiable framework that jointly models causal
discovery and TPP dynamics, enabling accurate event prediction and revealing
interpretable structures. Extensive experiments on real-world datasets
demonstrate that MOCHA not only achieves state-of-the-art performance in event
prediction, but also reveals meaningful and interpretable causal structures.

</details>


### [291] [HAEPO: History-Aggregated Exploratory Policy Optimization](https://arxiv.org/abs/2508.18884)
*Gaurish Trivedi,Alakh Sharma,Kartikey Singh Bhandari,Dhruv Kumar,Pratik Narang,Jagat Sesh Challa*

Main category: cs.LG

TL;DR: HAEPO是一种新的探索性策略优化方法，通过压缩轨迹并使用Plackett-Luce softmax来鼓励更广泛的探索，在长期任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DPO和GRPO）在捕获整个轨迹或聚合每token信息时，往往会限制在长期任务中的探索。HAEPO旨在解决这个问题。

Method: HAEPO通过将每个轨迹压缩成其对数概率之和（累积对数似然），并对轨迹应用Plackett-Luce softmax来获得与其回报成正比的归一化权重，从而鼓励更广泛的探索。此外，它还引入了熵正则化来稳定更新，并添加了与冻结的参考策略的软KL惩罚。

Result: HAEPO收敛速度快，探索充分，与真实奖励高度一致，并且在各种任务上的学习表现优于或等同于PPO、GRPO和DPO。

Conclusion: HAEPO提供了一个稳定且可解释的框架，通过显式利用完整轨迹历史来平衡探索和稳定性。

Abstract: Exploration is essential in modern learning, from reinforcement learning
environments with small neural policies to large language models (LLMs).
Existing work, such as DPO, leverages full sequence log-likelihoods to capture
an entire trajectory of the model's decisions, while methods like GRPO
aggregate per-token ratios into a trajectory-level update. However, both often
limit exploration on long-horizon tasks. We introduce History-Aggregated
Exploratory Policy Optimization (HAEPO), a history-aware exploratory loss to
combat these shortcomings. HAEPO compresses each trajectory into the sum of its
logarithmic probabilities (a cumulative logarithmic likelihood), and applies a
Plackett-Luce softmax across trajectories to obtain normalized weights
proportional to their returns, thus encouraging broader exploration. We add
entropy regularization to stabilize the aggressive updates to prevent premature
collapse and a soft KL penalty relative to a frozen copy of the previous
(reference) policy. Empirically, HAEPO converges fast, explores thoroughly,
aligns closely with true rewards, and demonstrates robust learning behavior
better or at par with PPO, GRPO, and DPO across diverse tasks. Thus, HAEPO
provides a stable and interpretable framework by explicitly leveraging
full-trajectory history while balancing exploration and stability.

</details>


### [292] [pyFAST: A Modular PyTorch Framework for Time Series Modeling with Multi-source and Sparse Data](https://arxiv.org/abs/2508.18891)
*Zhijin Wang,Senzhen Wu,Yue Hu,Xiufeng Liu*

Main category: cs.LG

TL;DR: pyFAST是一个面向研究的PyTorch框架，用于时间序列分析，它能处理复杂的数据场景，并支持多种模型。


<details>
  <summary>Details</summary>
Motivation: 现有Python库在模块化和对不规则、多源或稀疏数据支持方面存在局限性，需要更灵活、高效和可扩展的框架。

Method: pyFAST通过解耦数据处理和模型计算，支持多源加载、蛋白质序列处理、填充、动态归一化和掩码建模。它集成了LLM架构用于稀疏数据融合，并提供稀疏指标、损失函数和外源数据融合。训练工具包括批处理流聚合和设备协同。该框架包含多种经典和深度学习模型，并鼓励扩展。

Result: pyFAST能够处理复杂的时间序列数据，并支持多种模型，从而加速时间序列研究和应用。

Conclusion: pyFAST是一个紧凑而强大的平台，用于推进时间序列研究和应用。

Abstract: Modern time series analysis demands frameworks that are flexible, efficient,
and extensible. However, many existing Python libraries exhibit limitations in
modularity and in their native support for irregular, multi-source, or sparse
data. We introduce pyFAST, a research-oriented PyTorch framework that
explicitly decouples data processing from model computation, fostering a
cleaner separation of concerns and facilitating rapid experimentation. Its data
engine is engineered for complex scenarios, supporting multi-source loading,
protein sequence handling, efficient sequence- and patch-level padding, dynamic
normalization, and mask-based modeling for both imputation and forecasting.
pyFAST integrates LLM-inspired architectures for the alignment-free fusion of
sparse data sources and offers native sparse metrics, specialized loss
functions, and flexible exogenous data fusion. Training utilities include
batch-based streaming aggregation for evaluation and device synergy to maximize
computational efficiency. A comprehensive suite of classical and deep learning
models (Linears, CNNs, RNNs, Transformers, and GNNs) is provided within a
modular architecture that encourages extension. Released under the MIT license
at GitHub, pyFAST provides a compact yet powerful platform for advancing time
series research and applications.

</details>


### [293] [Distance-informed Neural Processes](https://arxiv.org/abs/2508.18903)
*Aishwarya Venkataramanan,Joachim Denzler*

Main category: cs.LG

TL;DR: DNP是一种新的神经过程变体，通过结合全局和距离感知局部潜在结构来改进不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 标准神经过程（NP）依赖于全局潜在变量，在不确定性校准和捕获局部数据依赖性方面存在不足。DNP旨在解决这些问题。

Method: DNP通过引入全局潜在变量来模拟任务级变化，并引入局部潜在变量来捕获距离保持潜在空间中的输入相似性。这是通过双Lipschitz正则化实现的，它限制了输入关系中的失真并鼓励在潜在空间中保留相对距离。

Result: DNP在回归和分类任务上实现了强大的预测性能和改进的不确定性校准，能够更好地区分分布内和分布外数据。

Conclusion: DNP通过结合全局和局部潜在结构，并使用双Lipschitz正则化来保留距离信息，从而在不确定性估计和区分分布内/外数据方面优于标准NP。

Abstract: We propose the Distance-informed Neural Process (DNP), a novel variant of
Neural Processes that improves uncertainty estimation by combining global and
distance-aware local latent structures. Standard Neural Processes (NPs) often
rely on a global latent variable and struggle with uncertainty calibration and
capturing local data dependencies. DNP addresses these limitations by
introducing a global latent variable to model task-level variations and a local
latent variable to capture input similarity within a distance-preserving latent
space. This is achieved through bi-Lipschitz regularization, which bounds
distortions in input relationships and encourages the preservation of relative
distances in the latent space. This modeling approach allows DNP to produce
better-calibrated uncertainty estimates and more effectively distinguish in-
from out-of-distribution data. Empirical results demonstrate that DNP achieves
strong predictive performance and improved uncertainty calibration across
regression and classification tasks.

</details>


### [294] [Enhancing Model Privacy in Federated Learning with Random Masking and Quantization](https://arxiv.org/abs/2508.18911)
*Zhibo Xu,Jianhao Zhu,Jingwen Xu,Changze Lv,Zisu Huang,Xiaohua Wang,Muling Wu,Qi Qian,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.LG

TL;DR: 该方法在联邦学习设置中保持了强大的模型性能，并增强了模型参数的保护。


<details>
  <summary>Details</summary>
Motivation: 为了在联邦学习中实现模型性能和参数保护的双重目标。

Method: 通过一种新颖的联邦学习方法。

Result: 在各种模型和任务的实验结果表明，该方法优于基线方法。

Conclusion: 所提出的方法在联邦学习中能够有效平衡模型性能和参数保护。

Abstract: Experimental results across various models and tasks demonstrate that our
approach not only maintains strong model performance in federated learning
settings but also achieves enhanced protection of model parameters compared to
baseline methods.

</details>


### [295] [Generalization Bound for a General Class of Neural Ordinary Differential Equations](https://arxiv.org/abs/2508.18920)
*Madhusudan Verma,Manoj Kumar*

Main category: cs.LG

TL;DR: 本文为具有一般非线性动力学函数的神经ODE（包括时间依赖和时间独立的情况）建立了泛化误差界限，并研究了过参数化和域约束的影响。


<details>
  <summary>Details</summary>
Motivation: 为了评估神经ODE在未见过数据上的性能，理解其泛化误差界限至关重要。

Method: 通过证明利普希茨连续性，神经ODE的解具有有界变差，并在此基础上建立了时间依赖和时间独立情况下的泛化界限。

Result: 证明了神经ODE的解具有有界变差，并推导了泛化界限，研究了过参数化和域约束的影响。

Conclusion: 这是首次为具有一般非线性动力学的神经ODE推导出泛化界限。

Abstract: Neural ordinary differential equations (neural ODEs) are a popular type of
deep learning model that operate with continuous-depth architectures. To assess
how well such models perform on unseen data, it is crucial to understand their
generalization error bounds. Previous research primarily focused on the linear
case for the dynamics function in neural ODEs - Marion, P. (2023), or provided
bounds for Neural Controlled ODEs that depend on the sampling interval
Bleistein et al. (2023). In this work, we analyze a broader class of neural
ODEs where the dynamics function is a general nonlinear function, either time
dependent or time independent, and is Lipschitz continuous with respect to the
state variables. We showed that under this Lipschitz condition, the solutions
to neural ODEs have solutions with bounded variations. Based on this
observation, we establish generalization bounds for both time-dependent and
time-independent cases and investigate how overparameterization and domain
constraints influence these bounds. To our knowledge, this is the first
derivation of generalization bounds for neural ODEs with general nonlinear
dynamics.

</details>


### [296] [HierCVAE: Hierarchical Attention-Driven Conditional Variational Autoencoders for Multi-Scale Temporal Modeling](https://arxiv.org/abs/2508.18922)
*Yao Wu*

Main category: cs.LG

TL;DR: HierCVAE是一种结合了分层注意力机制和条件变分自编码器的新型架构，用于对复杂系统中的时间序列数据进行建模和预测。它通过三层注意力结构（局部、全局、跨时间）和多模态条件编码来捕捉时间、统计和趋势信息，并在潜在空间中利用ResFormer块，同时通过预测头提供明确的不确定性量化。在能源消耗数据集上的评估表明，HierCVAE在预测准确性方面比现有最先进方法提高了15-40%，并且在不确定性校准方面表现更优，尤其在长期预测和复杂的多变量依赖性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的时间序列建模方法在处理复杂系统中的多时间尺度依赖和不确定性时面临挑战。本研究旨在提出一种能够有效捕捉这些复杂依赖关系并进行准确预测的新型模型。

Method: 本研究提出了一种名为HierCVAE的新型架构，该架构集成了分层注意力机制和条件变分自编码器。具体而言，HierCVAE采用包含局部、全局和跨时间注意力的三层注意力结构，并结合多模态条件编码来提取时间、统计和趋势信息。此外，模型在潜在空间中使用了ResFormer块，并通过预测头实现了明确的不确定性量化。

Result: 通过在能源消耗数据集上的评估，HierCVAE在预测准确性方面取得了15-40%的提升，并展示了优于现有最先进方法的不确定性校准能力。该模型在长期预测和处理复杂的多变量依赖关系方面表现尤为突出。

Conclusion: HierCVAE架构通过结合分层注意力机制、条件变分自编码器、ResFormer块和明确的不确定性量化，能够有效地解决复杂系统中时间序列建模的挑战，并在预测准确性和不确定性校准方面取得了显著的改进，尤其在长期预测和多变量依赖性方面具有优势。

Abstract: Temporal modeling in complex systems requires capturing dependencies across
multiple time scales while managing inherent uncertainties. We propose
HierCVAE, a novel architecture that integrates hierarchical attention
mechanisms with conditional variational autoencoders to address these
challenges. HierCVAE employs a three-tier attention structure (local, global,
cross-temporal) combined with multi-modal condition encoding to capture
temporal, statistical, and trend information. The approach incorporates
ResFormer blocks in the latent space and provides explicit uncertainty
quantification via prediction heads. Through evaluations on energy consumption
datasets, HierCVAE demonstrates a 15-40% improvement in prediction accuracy and
superior uncertainty calibration compared to state-of-the-art methods,
excelling in long-term forecasting and complex multi-variate dependencies.

</details>


### [297] [Energy-Based Flow Matching for Generating 3D Molecular Structure](https://arxiv.org/abs/2508.18949)
*Wenyin Zhou,Christopher Iliffe Sprague,Vsevolod Viliuga,Matteo Tadiello,Arne Elofsson,Hossein Azizpour*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Molecular structure generation is a fundamental problem that involves
determining the 3D positions of molecules' constituents. It has crucial
biological applications, such as molecular docking, protein folding, and
molecular design. Recent advances in generative modeling, such as diffusion
models and flow matching, have made great progress on these tasks by modeling
molecular conformations as a distribution. In this work, we focus on flow
matching and adopt an energy-based perspective to improve training and
inference of structure generation models. Our view results in a mapping
function, represented by a deep network, that is directly learned to
\textit{iteratively} map random configurations, i.e. samples from the source
distribution, to target structures, i.e. points in the data manifold. This
yields a conceptually simple and empirically effective flow matching setup that
is theoretically justified and has interesting connections to fundamental
properties such as idempotency and stability, as well as the empirically useful
techniques such as structure refinement in AlphaFold. Experiments on protein
docking as well as protein backbone generation consistently demonstrate the
method's effectiveness, where it outperforms recent baselines of
task-associated flow matching and diffusion models, using a similar
computational budget.

</details>


### [298] [Estimating Conditional Covariance between labels for Multilabel Data](https://arxiv.org/abs/2508.18951)
*Laurence A. F. Park,Jesse Read*

Main category: cs.LG

TL;DR: 在应用多标签模型之前，应该对多标签数据进行标签依赖性分析。然而，标签之间的独立性不能直接从标签值中测量，因为它依赖于协变量集。虽然可以使用多元Probit模型来检查条件标签协方差，但它可能无法可靠地估计恒定协方差和依赖协方差。本文比较了三种模型（多元Probit、多元伯努利和分阶段Logit）在估计条件标签协方差方面的性能。实验表明，所有模型在测量恒定和依赖协方差方面都同样有效，具体取决于协方差的强度。然而，当数据仅存在恒定协方差时，所有模型都会错误地检测到依赖协方差的存在。在这三种模型中，多元Probit模型的错误率最低。


<details>
  <summary>Details</summary>
Motivation: 在应用多标签模型之前，需要分析多标签数据的标签依赖性。然而，直接从标签值测量标签间的独立性是不可行的，因为这取决于协变量集。多元Probit模型可用于此目的，但其估计可能不可靠。

Method: 比较了三种模型（多元Probit、多元伯努利和分阶段Logit）来估计条件标签协方差，并通过实验来评估它们的性能。

Result: 所有模型在测量恒定和依赖协方差方面均表现相似，但均会错误地将恒定协方差识别为依赖协方差。多元Probit模型具有最低的错误率。

Conclusion: 多元Probit模型在估计多标签数据的条件标签协方差方面表现最佳，但仍需注意其在检测依赖性方面的潜在错误。

Abstract: Multilabel data should be analysed for label dependence before applying
multilabel models. Independence between multilabel data labels cannot be
measured directly from the label values due to their dependence on the set of
covariates $\vec{x}$, but can be measured by examining the conditional label
covariance using a multivariate Probit model. Unfortunately, the multivariate
Probit model provides an estimate of its copula covariance, and so might not be
reliable in estimating constant covariance and dependent covariance. In this
article, we compare three models (Multivariate Probit, Multivariate Bernoulli
and Staged Logit) for estimating the constant and dependent multilabel
conditional label covariance. We provide an experiment that allows us to
observe each model's measurement of conditional covariance. We found that all
models measure constant and dependent covariance equally well, depending on the
strength of the covariance, but the models all falsely detect that dependent
covariance is present for data where constant covariance is present. Of the
three models, the Multivariate Probit model had the lowest error rate.

</details>


### [299] [On the Generalisation of Koopman Representations for Chaotic System Control](https://arxiv.org/abs/2508.18954)
*Kyriakos Hjikakou,Juan Diego Cardenas Cartagena,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 本文研究了基于Koopman表示的混沌动力学系统的泛化性，重点关注其在预测和控制任务之间的可转移性。


<details>
  <summary>Details</summary>
Motivation: 研究Koopman表示的泛化性和跨任务可转移性，特别是在预测和控制任务中。

Method: 采用三阶段方法：通过自编码学习Koopman嵌入，对Transformer进行下一步预测的预训练，以及针对安全关键控制进行微调。

Result: Koopman嵌入在准确性和数据效率方面优于PCA基线，并且在微调过程中固定预训练的Transformer权重不会导致性能下降。

Conclusion: 研究结果表明Koopman嵌入可以作为多任务学习的基础，具有可重用的动力学结构，而非特定任务的模式。

Abstract: This paper investigates the generalisability of Koopman-based representations
for chaotic dynamical systems, focusing on their transferability across
prediction and control tasks. Using the Lorenz system as a testbed, we propose
a three-stage methodology: learning Koopman embeddings through autoencoding,
pre-training a transformer on next-state prediction, and fine-tuning for
safety-critical control. Our results show that Koopman embeddings outperform
both standard and physics-informed PCA baselines, achieving accurate and
data-efficient performance. Notably, fixing the pre-trained transformer weights
during fine-tuning leads to no performance degradation, indicating that the
learned representations capture reusable dynamical structure rather than
task-specific patterns. These findings support the use of Koopman embeddings as
a foundation for multi-task learning in physics-informed machine learning. A
project page is available at https://kikisprdx.github.io/.

</details>


### [300] [PAX-TS: Model-agnostic multi-granular explanations for time series forecasting via localized perturbations](https://arxiv.org/abs/2508.18982)
*Tim Kreuzer,Jelena Zdravkovic,Panagiotis Papapetrou*

Main category: cs.LG

TL;DR: PAX-TS是一个模型无关的事后算法，用于解释时间序列预测模型及其预测，提供多粒度解释并能表征多元时间序列预测的跨通道相关性。


<details>
  <summary>Details</summary>
Motivation: 现代预测模型不透明且不提供预测解释，而LIME等事后可解释性方法不适用于预测场景。

Method: PAX-TS是一种基于局部输入扰动的模型无关事后算法。

Result: PAX-TS能够生成多粒度解释，表征跨通道相关性，并且其解释能有效捕捉模型行为，不同类别模式与预测性能相关。

Conclusion: PAX-TS能够以不同详细程度说明时间序列预测模型的机制，并用于解答有关预测的实际问题。

Abstract: Time series forecasting has seen considerable improvement during the last
years, with transformer models and large language models driving advancements
of the state of the art. Modern forecasting models are generally opaque and do
not provide explanations for their forecasts, while well-known post-hoc
explainability methods like LIME are not suitable for the forecasting context.
We propose PAX-TS, a model-agnostic post-hoc algorithm to explain time series
forecasting models and their forecasts. Our method is based on localized input
perturbations and results in multi-granular explanations. Further, it is able
to characterize cross-channel correlations for multivariate time series
forecasts. We clearly outline the algorithmic procedure behind PAX-TS,
demonstrate it on a benchmark with 7 algorithms and 10 diverse datasets,
compare it with two other state-of-the-art explanation algorithms, and present
the different explanation types of the method. We found that the explanations
of high-performing and low-performing algorithms differ on the same datasets,
highlighting that the explanations of PAX-TS effectively capture a model's
behavior. Based on time step correlation matrices resulting from the benchmark,
we identify 6 classes of patterns that repeatedly occur across different
datasets and algorithms. We found that the patterns are indicators of
performance, with noticeable differences in forecasting error between the
classes. Lastly, we outline a multivariate example where PAX-TS demonstrates
how the forecasting model takes cross-channel correlations into account. With
PAX-TS, time series forecasting models' mechanisms can be illustrated in
different levels of detail, and its explanations can be used to answer
practical questions on forecasts.

</details>


### [301] [STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems](https://arxiv.org/abs/2508.19011)
*Gary Simethy,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.LG

TL;DR: STDiff是一种新的时间序列缺失值填充方法，它将填充视为学习系统状态的演变，而不是在固定时间窗口内进行模式补全。该方法使用条件去噪扩散模型，并结合了控制理论的因果偏差，能够逐个生成缺失值。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理工业系统中的时间序列缺失值时存在局限性，因为这些系统通常具有由控制动作驱动、高度非平稳且可能出现长时间连续缺失的特点。

Method: STDiff采用条件去噪扩散模型，并结合了控制理论的因果偏差，逐点生成缺失值。它根据最近的已知状态以及相关的控制或环境输入来学习系统状态的演变。

Result: 在公共废水处理数据集和真实工业数据集上，STDiff均表现出最低的填充误差，尤其是在处理长缺失段时优势更为明显。与基于窗口的模型相比，STDiff生成的轨迹更具动态合理性，避免了过度平滑的现象。

Conclusion: STDiff提供了一种更鲁棒的时间序列缺失值填充方法，特别适用于工业场景。该方法强调了动态感知和显式条件设置的重要性，并为未来的研究提供了计算权衡和扩展方向的讨论。

Abstract: Most deep learning methods for imputing missing values treat the task as
completing patterns within a fixed time window. This assumption often fails in
industrial systems, where dynamics are driven by control actions, are highly
non-stationary, and can experience long, uninterrupted gaps. We propose STDiff,
which reframes imputation as learning how the system evolves from one state to
the next. STDiff uses a conditional denoising diffusion model with a causal
bias aligned to control theory, generating missing values step-by-step based on
the most recent known state and relevant control or environmental inputs. On a
public wastewater treatment dataset with simulated missing blocks, STDiff
consistently achieves the lowest errors, with its advantage increasing for
longer gaps. On a raw industrial dataset with substantial real gaps, it
produces trajectories that remain dynamically plausible, in contrast to
window-based models that tend to flatten or over-smooth. These results support
dynamics-aware, explicitly conditioned imputation as a robust approach for
industrial time series, and we discuss computational trade-offs and extensions
to broader domains.

</details>


### [302] [Learning with springs and sticks](https://arxiv.org/abs/2508.19015)
*Luis Mantilla Calderón,Alán Aspuru-Guzik*

Main category: cs.LG

TL;DR: 该研究提出了一种基于弹簧和 sticks 的物理动力学系统，用于函数逼近和回归任务。


<details>
  <summary>Details</summary>
Motivation: 将学习视为一个物理过程，旨在研究一个能够逼近任意连续函数的简单动力学系统。

Method: 使用 sticks 模拟分段线性函数，利用弹簧的势能编码均方误差损失函数，并通过耗散收敛到最小能量状态。

Result: 将该系统应用于回归任务，发现其性能与多层感知机相当，并发现了由环境涨落引起的“热力学学习障碍”。

Conclusion: 该简单模型有助于从物理角度理解学习系统，并揭示了自由能变化与学习能力之间的关系。

Abstract: Learning is a physical process. Here, we aim to study a simple dynamical
system composed of springs and sticks capable of arbitrarily approximating any
continuous function. The main idea of our work is to use the sticks to mimic a
piecewise-linear approximation of the given function, use the potential energy
of springs to encode a desired mean squared error loss function, and converge
to a minimum-energy configuration via dissipation. We apply the proposed
simulation system to regression tasks and show that its performance is
comparable to that of multi-layer perceptrons. In addition, we study the
thermodynamic properties of the system and find a relation between the free
energy change of the system and its ability to learn an underlying data
distribution. We empirically find a \emph{thermodynamic learning barrier} for
the system caused by the fluctuations of the environment, whereby the system
cannot learn if its change in free energy hits such a barrier. We believe this
simple model can help us better understand learning systems from a physical
point of view.

</details>


### [303] [Working My Way Back to You: Resource-Centric Next-Activity Prediction](https://arxiv.org/abs/2508.19016)
*Kelly Kurowski,Xixi Lu,Hajo A Reijers*

Main category: cs.LG

TL;DR: 本研究提出一种以资源为中心的方法来进行预测性过程监控（PPM），以预测即将发生的活动。


<details>
  <summary>Details</summary>
Motivation: 现有PPM研究主要关注控制流，而本研究旨在探索资源中心视角在预测下一活动中的应用，以期改善工作组织、负载均衡和能力预测。

Method: 本研究评估了四种预测模型（包括LightGBM、Transformer和随机森林）和三种编码策略（包括基于2-gram活动转换的编码和结合2-gram转换与活动重复特征的编码），并在四个真实数据集上进行了实验。

Result: 结果显示，LightGBM和Transformer模型在采用2-gram活动转换编码时表现最佳。随机森林模型则从结合2-gram转换和活动重复特征的编码中获益最多。该组合编码策略实现了最高的平均准确率。

Conclusion: 以资源为中心的方法在预测下一活动方面具有巨大潜力，能够实现更智能的资源分配、战略性劳动力规划和个性化员工支持，为PPM研究开辟了新的方向。

Abstract: Predictive Process Monitoring (PPM) aims to train models that forecast
upcoming events in process executions. These predictions support early
bottleneck detection, improved scheduling, proactive interventions, and timely
communication with stakeholders. While existing research adopts a control-flow
perspective, we investigate next-activity prediction from a resource-centric
viewpoint, which offers additional benefits such as improved work organization,
workload balancing, and capacity forecasting. Although resource information has
been shown to enhance tasks such as process performance analysis, its role in
next-activity prediction remains unexplored. In this study, we evaluate four
prediction models and three encoding strategies across four real-life datasets.
Compared to the baseline, our results show that LightGBM and Transformer models
perform best with an encoding based on 2-gram activity transitions, while
Random Forest benefits most from an encoding that combines 2-gram transitions
and activity repetition features. This combined encoding also achieves the
highest average accuracy. This resource-centric approach could enable smarter
resource allocation, strategic workforce planning, and personalized employee
support by analyzing individual behavior rather than case-level progression.
The findings underscore the potential of resource-centric next-activity
prediction, opening up new venues for research on PPM.

</details>


### [304] [GRADSTOP: Early Stopping of Gradient Descent via Posterior Sampling](https://arxiv.org/abs/2508.19028)
*Arash Jamshidi,Lauri Seppäläinen,Katsiaryna Haitsiukevich,Hoang Phuc Hau Luu,Anton Björklund,Kai Puolamäki*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 GradStop 的新型随机早停法，仅使用梯度信息，无需单独的验证集，可以提高模型在未见过数据上的预测性能，特别适用于数据有限的场景。


<details>
  <summary>Details</summary>
Motivation: 梯度下降训练的模型常因过拟合导致在新数据上表现不佳。传统的早停法（使用留存验证集）会减少用于训练的数据量。

Method: GradStop 是一种利用梯度信息进行早停的新方法。它通过梯度信息估计贝叶斯后验分布，并将早停问题定义为从该后验分布中抽取样本，最后利用近似后验分布得到一个停止准则。

Result: 实验结果表明，GradStop 在测试数据上实现了较低的损失，并且优于基于验证集的停止准则。

Conclusion: GradStop 是一种有效的早停方法，它通过利用整个数据集进行训练，在数据有限的情况下（如迁移学习）尤其具有优势。该方法计算开销小，易于集成到现有库中。

Abstract: Machine learning models are often learned by minimising a loss function on
the training data using a gradient descent algorithm. These models often suffer
from overfitting, leading to a decline in predictive performance on unseen
data. A standard solution is early stopping using a hold-out validation set,
which halts the minimisation when the validation loss stops decreasing.
However, this hold-out set reduces the data available for training. This paper
presents {\sc gradstop}, a novel stochastic early stopping method that only
uses information in the gradients, which are produced by the gradient descent
algorithm ``for free.'' Our main contributions are that we estimate the
Bayesian posterior by the gradient information, define the early stopping
problem as drawing sample from this posterior, and use the approximated
posterior to obtain a stopping criterion. Our empirical evaluation shows that
{\sc gradstop} achieves a small loss on test data and compares favourably to a
validation-set-based stopping criterion. By leveraging the entire dataset for
training, our method is particularly advantageous in data-limited settings,
such as transfer learning. It can be incorporated as an optional feature in
gradient descent libraries with only a small computational overhead. The source
code is available at https://github.com/edahelsinki/gradstop.

</details>


### [305] [When recalling in-context, Transformers are not SSMs](https://arxiv.org/abs/2508.19029)
*Destiny Okpekpe,Antonio Orvieto*

Main category: cs.LG

TL;DR: SSMs compared to transformers have shortcomings in reasoning and memorization tasks. This paper investigates associative recall (AR) benchmarks, focusing on scaling and optimization of token mixing strategies. Key findings include the critical role of learning rate in recurrent models, contrasting scaling benefits between recurrent and attention models, and surprising similarities in training dynamics of 1-layer transformers to induction heads. Architectural ablations were performed on Transformer and Mamba.


<details>
  <summary>Details</summary>
Motivation: To investigate the shortcomings of modern recurrent deep learning models (like SSMs) compared to transformers on reasoning and memorization tasks, specifically focusing on associative recall (AR) and the effects of scaling and optimization in token mixing strategies.

Method: Investigated the role of learning rate in recurrent models, compared the scaling benefits of recurrent and attention models (depth vs. width), analyzed the training dynamics of 1-layer transformers, and performed architectural ablations on Transformer and Mamba.

Result: The learning rate critically affects recurrent model performance, unlike standard transformers. Recurrent and attention models show contrasting benefits when scaling width vs. depth, with attention failing AR in a single layer. 1-layer transformers exhibit training dynamics similar to induction heads despite poor performance. Architectural ablations revealed component-specific effects on Transformer and Mamba performance and optimization stability.

Conclusion: The choice of learning rate is crucial for training modern recurrent models. Scaling strategies differ between recurrent and attention mechanisms. Further research is needed to stabilize training and understand the formation of phenomena like induction heads in shallower architectures. Architectural choices significantly impact model performance and stability.

Abstract: Despite the advantageous subquadratic complexity of modern recurrent deep
learning models -- such as state-space models (SSMs) -- recent studies have
highlighted their potential shortcomings compared to transformers on reasoning
and memorization tasks. In this paper, we dive deeper into one of such
benchmarks: associative recall (AR), which has been shown to correlate well
with language modeling performance, and inspect in detail the effects of
scaling and optimization issues in recently proposed token mixing strategies.
We first demonstrate that, unlike standard transformers, the choice of learning
rate plays a critical role in the performance of modern recurrent models: an
issue that can severely affect reported performance in previous works and
suggests further research is needed to stabilize training. Next, we show that
recurrent and attention-based models exhibit contrasting benefits when scaling
in width as opposed to depth, with attention being notably unable to solve AR
when limited to a single layer. We then further inspect 1-layer transformers,
revealing that despite their poor performance, their training dynamics
surprisingly resemble the formation of induction heads, a phenomenon previously
observed only in their 2-layer counterparts. Finally, through architectural
ablations, we study how components affects Transformer and Mamba's performance
and optimization stability.

</details>


### [306] [Breaking the Black Box: Inherently Interpretable Physics-Informed Machine Learning for Imbalanced Seismic Data](https://arxiv.org/abs/2508.19031)
*Vemula Sreenath,Filippo Gatti,Pierre Jehel*

Main category: cs.LG

TL;DR: 该研究提出了一种名为HazBinLoss的透明机器学习模型，用于解决现有地震动模型（GMM）的“黑箱”问题和数据不平衡问题，通过线性组合和加权损失函数，提高了模型的可解释性和对高影响地震事件的预测能力，在保持可比性能的同时，有助于风险评估和灾害规划。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习方法在构建地震动模型（GMM）时存在“黑箱”问题，难以解释和信任，并且在处理地震数据库中的数据不平衡（即近场大震记录少于远场小震记录）时存在困难，这限制了它们在高风险决策中的应用。

Method: 本研究提出了一种透明的机器学习架构，并设计了HazBinLoss损失函数。该架构将每个输入（如震级、距离、交互项等）分开处理，然后线性组合得到输出，从而精确显示每个因素的贡献。HazBinLoss函数在训练过程中，为近场大震记录分配更高的权重，为远场小震记录分配较低的权重，以防止低估最具破坏性的地震场景。

Result: 所提出的模型能够捕捉已知的地震学原理，并且在性能上与已建立的GMM相当，同时保持了模型透明性。这使得该框架能够更广泛地应用于风险评估研究和灾害规划。

Conclusion: 该研究通过引入HazBinLoss函数和透明的机器学习架构，成功解决了现有GMM的“黑箱”和数据不平衡问题，提高了模型的可解释性和对关键地震场景的预测能力，为风险评估和灾害规划提供了更可靠的工具。

Abstract: Ground motion models (GMMs) predict how strongly the ground will shake during
an earthquake. They are essential for structural analysis, seismic design, and
seismic risk assessment studies. Traditional machine learning (ML) approaches
are popular to develop GMMs, due to large earthquake databases worldwide.
However, they operate as "black boxes," which are hard to interpret and trust,
limiting their use in high-stake decisions. Additionally, these databases
suffer from significant data imbalances: fewer large, critically damaging
records near the fault compared to abundant, less severely damaging distant
records. These two limitations are addressed in this work by developing a
transparent ML architecture using the HazBinLoss function. Each input (e.g.,
magnitude, distance, their interaction term, etc.) is processed separately and
added linearly to obtain the output, resulting in exact contribution of each
term. The HazBinLoss function assigns higher weights to critical near-field
large magnitude records and lower weights to less-critical far-field smaller
magnitude records, during training to prevent underprediction of the most
damaging scenarios. Our model captures known seismological principles and
achieves comparable performance with established GMMs while maintaining
transparency. This framework enables broader adoption of ML-based approaches
for risk assessment studies and disaster planning.

</details>


### [307] [Automated discovery of finite volume schemes using Graph Neural Networks](https://arxiv.org/abs/2508.19052)
*Paul Garnier,Jonathan Viquerat,Elie Hachem*

Main category: cs.LG

TL;DR: GNNs can be used to generate numerical schemes, specifically finite volume schemes for the heat equation, by combining them with symbolic regression. They can extrapolate to different graph structures and be trained in an unsupervised manner. The approach can also discover higher-order schemes.


<details>
  <summary>Details</summary>
Motivation: To investigate the ability of Graph Neural Networks (GNNs) to extrapolate beyond their training domain and to explore their potential in generating numerical schemes, in conjunction with symbolic regression.

Method: The study trains GNNs on datasets of two-node graphs to extrapolate first-order Finite Volume (FV) schemes for the heat equation. It then extends this to an unsupervised context using a residual loss similar to Physics-Informed Neural Networks (PINNs). Finally, it trains a 2-hop and a 2-layer GNN using the same PINN loss to discover higher-order schemes.

Result: A GNN trained on two-node graphs can extrapolate a first-order FV scheme for the heat equation on out-of-distribution meshes with an error related to the GNN's training loss. Symbolic regression shows the GNN rediscovers the analytical formulation of the FV scheme. The unsupervised approach successfully recovers the first-order FV scheme. Higher-order schemes are also discovered: a second-order correction term using a 2-hop stencil and the classic second-order midpoint scheme.

Conclusion: GNNs are capable of generating numerical schemes and can actively contribute to the development of novel numerical methods, going beyond their traditional role as approximators.

Abstract: Graph Neural Networks (GNNs) have deeply modified the landscape of numerical
simulations by demonstrating strong capabilities in approximating solutions of
physical systems. However, their ability to extrapolate beyond their training
domain (\textit{e.g.} larger or structurally different graphs) remains
uncertain. In this work, we establish that GNNs can serve purposes beyond their
traditional role, and be exploited to generate numerical schemes, in
conjunction with symbolic regression. First, we show numerically and
theoretically that a GNN trained on a dataset consisting solely of two-node
graphs can extrapolate a first-order Finite Volume (FV) scheme for the heat
equation on out-of-distribution, unstructured meshes. Specifically, if a GNN
achieves a loss $\varepsilon$ on such a dataset, it implements the FV scheme
with an error of $\mathcal{O}(\varepsilon)$. Using symbolic regression, we show
that the network effectively rediscovers the exact analytical formulation of
the standard first-order FV scheme. We then extend this approach to an
unsupervised context: the GNN recovers the first-order FV scheme using only a
residual loss similar to Physics-Informed Neural Networks (PINNs) with no
access to ground-truth data. Finally, we push the methodology further by
considering higher-order schemes: we train (i) a 2-hop and (ii) a 2-layers GNN
using the same PINN loss, that autonomously discover (i) a second-order
correction term to the initial scheme using a 2-hop stencil, and (ii) the
classic second-order midpoint scheme. These findings follows a recent paradigm
in scientific computing: GNNs are not only strong approximators, but can be
active contributors to the development of novel numerical methods.

</details>


### [308] [Tackling Federated Unlearning as a Parameter Estimation Problem](https://arxiv.org/abs/2508.19065)
*Antonio Balordi,Lorenzo Manini,Fabio Stella,Alessio Merlo*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息论的联邦学习模型遗忘框架，通过识别并重置对遗忘数据最敏感的参数，然后进行最小化的联邦再训练，以满足隐私法规要求。该方法无需访问原始客户端数据，能够有效擦除特定类别或客户端数据，并在后门攻击场景下恢复模型完整性，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 隐私法规要求删除深度学习模型中的数据，这在联邦学习中是一个巨大挑战，因为数据保留在客户端，完全重新训练或协调更新通常不可行。

Method: 本研究提出了一种基于信息论的高效联邦遗忘框架，将信息泄露建模为参数估计问题。该方法利用二阶 Hessian 信息来识别并选择性地重置对遗忘数据最敏感的参数，然后进行最小化的联邦再训练。

Result: 在基准数据集上的评估表明，该方法具有强大的隐私保护能力（成员推理攻击成功率接近随机水平，类别知识被擦除），并且性能高（相对于重新训练的基准模型的归一化准确率约为 0.9）。此外，在针对性的后门攻击场景下，该框架能有效消除恶意触发器，恢复模型完整性。

Conclusion: 该框架提供了一个实用的联邦学习数据遗忘解决方案，满足了隐私法规的要求，并在效率、隐私保护和模型性能之间取得了良好平衡。

Abstract: Privacy regulations require the erasure of data from deep learning models.
This is a significant challenge that is amplified in Federated Learning, where
data remains on clients, making full retraining or coordinated updates often
infeasible. This work introduces an efficient Federated Unlearning framework
based on information theory, modeling leakage as a parameter estimation
problem. Our method uses second-order Hessian information to identify and
selectively reset only the parameters most sensitive to the data being
forgotten, followed by minimal federated retraining. This model-agnostic
approach supports categorical and client unlearning without requiring server
access to raw client data after initial information aggregation. Evaluations on
benchmark datasets demonstrate strong privacy (MIA success near random,
categorical knowledge erased) and high performance (Normalized Accuracy against
re-trained benchmarks of $\approx$ 0.9), while aiming for increased efficiency
over complete retraining. Furthermore, in a targeted backdoor attack scenario,
our framework effectively neutralizes the malicious trigger, restoring model
integrity. This offers a practical solution for data forgetting in FL.

</details>


### [309] [Dynamic Triangulation-Based Graph Rewiring for Graph Neural Networks](https://arxiv.org/abs/2508.19071)
*Hugo Attali,Thomas Papastergiou,Nathalie Pernelle,Fragkiskos D. Malliaros*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Graph Neural Networks (GNNs) have emerged as the leading paradigm for
learning over graph-structured data. However, their performance is limited by
issues inherent to graph topology, most notably oversquashing and
oversmoothing. Recent advances in graph rewiring aim to mitigate these
limitations by modifying the graph topology to promote more effective
information propagation. In this work, we introduce TRIGON, a novel framework
that constructs enriched, non-planar triangulations by learning to select
relevant triangles from multiple graph views. By jointly optimizing triangle
selection and downstream classification performance, our method produces a
rewired graph with markedly improved structural properties such as reduced
diameter, increased spectral gap, and lower effective resistance compared to
existing rewiring methods. Empirical results demonstrate that TRIGON
outperforms state-of-the-art approaches on node classification tasks across a
range of homophilic and heterophilic benchmarks.

</details>


### [310] [APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration](https://arxiv.org/abs/2508.19087)
*Shaobo Ma,Chao Fang,Haikuo Shao,Zhongfeng Wang*

Main category: cs.LG

TL;DR: LLMs 过于庞大，难以部署和实时运行。本研究提出了 APT-LLM，一种旨在通过双极 INT 数据格式、位级矩阵乘法、内存数据恢复和动态核映射来加速任意精度 LLM 的方法。 APT-LLM 在 RTX 3090 上实现了高达 3.99 倍于 FP16 的加速，在 RTX 4090 和 H800 上实现了高达 2.44 倍于 FP16 的加速。


<details>
  <summary>Details</summary>
Motivation: LLMs 因其巨大的计算需求而难以部署和实时运行，尤其是在 GPU 上实现极低比特量化 LLM 时，由于 GPU 张量核心支持有限、内存管理效率低下和内核优化不灵活等问题，面临严峻挑战。

Method: 本研究提出了一种名为 APT-LLM 的综合性加速方案，包括：1. 新型数据格式双极 INT，支持高效无损转换并有利于并行计算。2. 位级矩阵乘法方法，可实现任意精度并优化 GPU 张量核心利用率。3. 内存数据恢复系统，利用共享内存提高内核执行速度并降低内存访问延迟。4. 核映射方法，动态选择最优的核超参数以适应不同模型和精度。

Result: 在 LLM 推理方面，APT-LLM 在 RTX 3090 上相较于 FP16 基线实现了高达 3.99 倍的加速，相较于 NVIDIA CUTLASS INT4 加速实现了 2.16 倍的加速。在 RTX 4090 和 H800 上，APT-LLM 相较于 FP16 实现了高达 2.44 倍的加速，相较于 CUTLASS 整数基线实现了 1.65 倍的加速。

Conclusion: APT-LLM 通过创新的数据格式、矩阵乘法、内存管理和核映射方法，有效解决了在 GPU 上部署和加速任意精度 LLM 的挑战，并在实际测试中取得了显著的性能提升。

Abstract: Large language models (LLMs) have revolutionized AI applications, yet their
enormous computational demands severely limit deployment and real-time
performance. Quantization methods can help reduce computational costs, however,
attaining the extreme efficiency associated with ultra-low-bit quantized LLMs
at arbitrary precision presents challenges on GPUs. This is primarily due to
the limited support for GPU Tensor Cores, inefficient memory management, and
inflexible kernel optimizations. To tackle these challenges, we propose a
comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM.
Firstly, we introduce a novel data format, bipolar-INT, which allows for
efficient and lossless conversion with signed INT, while also being more
conducive to parallel computation. We also develop a matrix multiplication
(MatMul) method allowing for arbitrary precision by dismantling and
reassembling matrices at the bit level. This method provides flexible precision
and optimizes the utilization of GPU Tensor Cores. In addition, we propose a
memory management system focused on data recovery, which strategically employs
fast shared memory to substantially increase kernel execution speed and reduce
memory access latency. Finally, we develop a kernel mapping method that
dynamically selects the optimal configurable hyperparameters of kernels for
varying matrix sizes, enabling optimal performance across different LLM
architectures and precision settings. In LLM inference, APT-LLM achieves up to
a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup
over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800,
APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup
over CUTLASS integer baselines.

</details>


### [311] [Composition and Alignment of Diffusion Models using Constrained Learning](https://arxiv.org/abs/2508.19104)
*Shervin Khalafi,Ignacio Hounie,Dongsheng Ding,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 该研究提出了一种约束优化框架，用于统一和改进扩散模型的对齐和组合，以解决在优化多个奖励或组合多个模型时出现的权衡问题，并确保生成样本具有所有期望的属性。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型对齐和组合方法在优化多个奖励或组合多个模型时会产生权衡问题，无法保证生成样本包含所有期望的属性。

Method: 提出了一种约束优化框架，该框架通过强制对齐后的模型满足奖励约束和/或接近多个预训练模型来统一对齐和组合扩散模型，并开发了一种基于拉格朗日的原对偶训练算法来近似这些解决方案。

Result: 在图像生成任务中，该方法能够有效地满足约束，并且优于等权重方法。

Conclusion: 所提出的约束优化框架能够有效地对齐和组合扩散模型，生成满足特定约束的图像，并在实践中显示出优于现有方法的性能。

Abstract: Diffusion models have become prevalent in generative modeling due to their
ability to sample from complex distributions. To improve the quality of
generated samples and their compliance with user requirements, two commonly
used methods are: (i) Alignment, which involves fine-tuning a diffusion model
to align it with a reward; and (ii) Composition, which combines several
pre-trained diffusion models, each emphasizing a desirable attribute in the
generated outputs. However, trade-offs often arise when optimizing for multiple
rewards or combining multiple models, as they can often represent competing
properties. Existing methods cannot guarantee that the resulting model
faithfully generates samples with all the desired properties. To address this
gap, we propose a constrained optimization framework that unifies alignment and
composition of diffusion models by enforcing that the aligned model satisfies
reward constraints and/or remains close to (potentially multiple) pre-trained
models. We provide a theoretical characterization of the solutions to the
constrained alignment and composition problems and develop a Lagrangian-based
primal-dual training algorithm to approximate these solutions. Empirically, we
demonstrate the effectiveness and merits of our proposed approach in image
generation, applying it to alignment and composition, and show that our aligned
or composed model satisfies constraints effectively, and improves on the
equally-weighted approach. Our implementation can be found at
https://github.com/shervinkhalafi/constrained_comp_align.

</details>


### [312] [Active Query Selection for Crowd-Based Reinforcement Learning](https://arxiv.org/abs/2508.19132)
*Jonathan Erskine,Taku Yamagata,Raúl Santos-Rodríguez*

Main category: cs.LG

TL;DR: 基于偏好的强化学习在奖励信号难以指定或与人类意图不一致的环境中训练智能体，但常受限于昂贵且不可靠的人类输入。本文提出一种结合概率众包建模（处理噪声、多标注者反馈）和主动学习（优先选择信息量大的动作）的新框架，以克服这些限制。该框架扩展了Advise算法，支持多训练者，在线估计其可靠性，并引入基于熵的查询选择来指导反馈请求。在2D游戏（Taxi、Pacman、Frozen Lake）和1型糖尿病的血糖控制任务（使用UVA/Padova模拟器）等合成和真实世界设置中进行了评估。初步结果表明，在不确定的轨迹上获得反馈的智能体在大多数任务中学习速度更快，并且在血糖控制任务上优于基线。


<details>
  <summary>Details</summary>
Motivation: 人类反馈在强化学习中至关重要，但其获取成本高昂且质量参差不齐，尤其是在专家反馈稀缺或错误代价高昂的领域。

Method: 提出一种结合概率众包建模和主动学习的新框架，扩展Advise算法以支持多训练者、在线估计其可靠性，并引入基于熵的查询选择来指导反馈请求。

Result: 在合成和真实世界场景（包括2D游戏和1型糖尿病血糖控制任务）的评估中，与基线方法相比，所提出的方法在大多数任务中实现了更快的学习速度，并在血糖控制任务上取得了更好的性能。

Conclusion: 所提出的结合概率众包建模和主动学习的框架能够有效处理噪声、多标注者反馈，并优先选择信息量大的动作，从而在奖励信号难以指定或与人类意图不一致的环境中，以及在反馈稀缺或昂贵的领域中，提高强化学习智能体的学习效率和性能。

Abstract: Preference-based reinforcement learning has gained prominence as a strategy
for training agents in environments where the reward signal is difficult to
specify or misaligned with human intent. However, its effectiveness is often
limited by the high cost and low availability of reliable human input,
especially in domains where expert feedback is scarce or errors are costly. To
address this, we propose a novel framework that combines two complementary
strategies: probabilistic crowd modelling to handle noisy, multi-annotator
feedback, and active learning to prioritize feedback on the most informative
agent actions. We extend the Advise algorithm to support multiple trainers,
estimate their reliability online, and incorporate entropy-based query
selection to guide feedback requests. We evaluate our approach in a set of
environments that span both synthetic and real-world-inspired settings,
including 2D games (Taxi, Pacman, Frozen Lake) and a blood glucose control task
for Type 1 Diabetes using the clinically approved UVA/Padova simulator. Our
preliminary results demonstrate that agents trained with feedback on uncertain
trajectories exhibit faster learning in most tasks, and we outperform the
baselines for the blood glucose control task.

</details>


### [313] [Saddle Hierarchy in Dense Associative Memory](https://arxiv.org/abs/2508.19151)
*Robin Thériault,Daniele Tantari*

Main category: cs.LG

TL;DR: 该论文研究了一种基于三层玻尔兹曼机的稠密联想记忆（DAM）模型，并提出了一种新的正则化方案和网络增长算法，以提高训练的稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: DAM模型因其对对抗性样本的鲁棒性以及与Transformer注意机制和生成扩散模型等先进机器学习范式的密切关系而备受关注。

Method: 通过统计力学分析，推导了描述DAM在真实数据和合成数据（在教师-学生框架下）上的稳定点和固定点的鞍点方程。基于这些结果，提出了一种新的正则化方案，提高了训练稳定性。进一步的理论分析表明，较小DAM学习到的权重对应于较大DAM中不稳定的鞍点。实现了一种利用这种鞍点层级来显著降低DAM训练计算成本的网络增长算法。

Result: 提出的正则化方案使训练更加稳定。DAM学习到了可解释的监督和无监督分类问题的解决方案。网络增长算法显著降低了DAM的训练计算成本。

Conclusion: DAM模型具有潜力，通过理论分析和算法创新可以提高其训练效率和稳定性，并应用于可解释的分类任务。

Abstract: Dense associative memory (DAM) models have been attracting renewed attention
since they were shown to be robust to adversarial examples and closely related
to state-of-the-art machine learning paradigms, such as the attention
mechanisms in transformers and generative diffusion models. We study a DAM
built upon a three-layer Boltzmann machine with Potts hidden units, which
represent data clusters and classes. Through a statistical mechanics analysis,
we derive saddle-point equations that characterize both the stationary points
of DAMs trained on real data and the fixed points of DAMs trained on synthetic
data within a teacher-student framework. Based on these results, we propose a
novel regularization scheme that makes training significantly more stable.
Moreover, we show empirically that our DAM learns interpretable solutions to
both supervised and unsupervised classification problems. Pushing our
theoretical analysis further, we find that the weights learned by relatively
small DAMs correspond to unstable saddle points in larger DAMs. We implement a
network-growing algorithm that leverages this saddle-point hierarchy to
drastically reduce the computational cost of training dense associative memory.

</details>


### [314] [Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness](https://arxiv.org/abs/2508.19183)
*Wenchuan Mu,Kwan Hui Lim*

Main category: cs.LG

TL;DR: 该论文提出了一种名为


<details>
  <summary>Details</summary>
Motivation: 深度学习在安全关键应用中存在潜在的安全隐患，而模型鲁棒性是衡量神经网络模型应对不可感知输入扰动能力的关键指标。现有的部署前鲁棒性评估方法在计算成本和测量精度之间存在显著的权衡，限制了其实际应用。

Method: 本文对现有的鲁棒性定义和评估方法进行了全面的比较分析，并提出了一种新的、实用的基于假设检验的度量方法——塔鲁棒性（tower robustness），以量化评估概率鲁棒性，从而实现更严格、更高效的部署前评估。

Result: 通过广泛的比较评估，证明了所提出方法在鲁棒性评估方面的优势和适用性。

Conclusion: 该研究有助于深入理解和提升安全关键深度学习应用中的模型鲁棒性。

Abstract: In safety-critical deep learning applications, robustness measures the
ability of neural models that handle imperceptible perturbations in input data,
which may lead to potential safety hazards. Existing pre-deployment robustness
assessment methods typically suffer from significant trade-offs between
computational cost and measurement precision, limiting their practical utility.
To address these limitations, this paper conducts a comprehensive comparative
analysis of existing robustness definitions and associated assessment
methodologies. We propose tower robustness to evaluate robustness, which is a
novel, practical metric based on hypothesis testing to quantitatively evaluate
probabilistic robustness, enabling more rigorous and efficient pre-deployment
assessments. Our extensive comparative evaluation illustrates the advantages
and applicability of our proposed approach, thereby advancing the systematic
understanding and enhancement of model robustness in safety-critical deep
learning applications.

</details>


### [315] [Emotions as Ambiguity-aware Ordinal Representations](https://arxiv.org/abs/2508.19193)
*Jingyao Wu,Matthew Barthet,David Melhart,Georgios N. Yannakakis*

Main category: cs.LG

TL;DR: 本篇论文提出了一种新颖的框架“模糊感知序数”情感表示法，用于捕捉情感标注中的模糊性和情感轨迹的固有时间动态性。


<details>
  <summary>Details</summary>
Motivation: 现有连续情感识别方法忽略了情感的模糊性，或将其视为独立且随时间静态变化的变量。本研究旨在解决这一不足。

Method: 提出通过变化率来模拟情感模糊性的方法，并构建了“模糊感知序数”情感表示框架，捕捉情感标注的模糊性和情感轨迹的时间动态性。

Result: 在RECOLA和GameVibe两个情感语料库上进行了评估。结果表明，在无界标签上，序数表示优于传统的模糊感知模型，在CCC和SDA得分上表现最佳，有效捕捉了轨迹的动态性。在有界标签上，序数表示在SDA方面表现出色，能更好地捕捉标注情感轨迹的相对变化。

Conclusion: 模糊感知序数情感表示法在捕捉情感动态性和处理标注模糊性方面表现出优越性，尤其在无界和有界情感标签的连续识别任务中。

Abstract: Emotions are inherently ambiguous and dynamic phenomena, yet existing
continuous emotion recognition approaches either ignore their ambiguity or
treat ambiguity as an independent and static variable over time. Motivated by
this gap in the literature, in this paper we introduce \emph{ambiguity-aware
ordinal} emotion representations, a novel framework that captures both the
ambiguity present in emotion annotation and the inherent temporal dynamics of
emotional traces. Specifically, we propose approaches that model emotion
ambiguity through its rate of change. We evaluate our framework on two
affective corpora -- RECOLA and GameVibe -- testing our proposed approaches on
both bounded (arousal, valence) and unbounded (engagement) continuous traces.
Our results demonstrate that ordinal representations outperform conventional
ambiguity-aware models on unbounded labels, achieving the highest Concordance
Correlation Coefficient (CCC) and Signed Differential Agreement (SDA) scores,
highlighting their effectiveness in modeling the traces' dynamics. For bounded
traces, ordinal representations excel in SDA, revealing their superior ability
to capture relative changes of annotated emotion traces.

</details>


### [316] [Understanding Tool-Integrated Reasoning](https://arxiv.org/abs/2508.19201)
*Heng Lin,Zhongwen Xu*

Main category: cs.LG

TL;DR: 工具集成推理（TIR）通过引入Python解释器等工具，理论上和实践上都扩展了大型语言模型（LLM）的能力上限，解决了纯文本模型无法解决或过于冗长的问题。提出了一种名为ASPO的新算法，用于指导模型行为，提高了训练稳定性和性能。实验证明TIR模型在数学基准测试中优于纯文本模型，不仅在计算密集型问题上，而且在需要抽象理解的问题上也是如此。研究还揭示了模型与工具协同思考的认知模式，并表明ASPO能改善工具使用行为，如提前调用代码和增加交互回合。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于工具集成推理（TIR）为何能增强大型语言模型（LLM）能力的理论解释，尽管这种方法已显示出巨大潜力。

Method: 提出了一种名为“优势塑造策略优化”（ASPO）的新型算法，用于在不影响训练稳定性和性能的情况下引导模型行为。通过直接修改优势函数来实现策略引导。实验使用了Python解释器作为外部工具，并在具有挑战性的数学基准测试上进行了全面评估。

Result: TIR模型在pass@k指标上显著优于纯文本模型。这种优势不仅体现在计算密集型问题上，也延伸到需要显著抽象洞察力的问题。ASPO算法提高了模型的工具使用行为，如早期代码调用和更多的交互回合。

Conclusion: 该研究首次为TIR的成功提供了原则性解释，阐明了工具如何以及为何能实现更强大的推理能力，而不仅仅是证明工具的有效性。

Abstract: We study why Tool-Integrated Reasoning (TIR) makes Large Language Models
(LLMs) more capable. While LLMs integrated with tools like Python code
interpreters show great promise, a principled theory explaining why this
paradigm is effective has been missing. This work provides the first formal
proof that TIR fundamentally expands an LLM's capabilities. We demonstrate that
tools enable a strict expansion of the model's empirical and feasible support,
breaking the capability ceiling of pure-text models by unlocking
problem-solving strategies that are otherwise impossible or intractably
verbose. To guide model behavior without compromising training stability and
performance, we also introduce Advantage Shaping Policy Optimization (ASPO), a
novel algorithm that directly modifies the advantage function to guide the
policy behavior. We conduct comprehensive experiments on challenging
mathematical benchmarks, leveraging a Python interpreter as the external tool.
Our results show that the TIR model decisively outperforms its pure-text
counterpart on the pass@k metric. Crucially, this advantage is not confined to
computationally-intensive problems but extends to those requiring significant
abstract insight. We further identify the emergent cognitive patterns that
illustrate how models learn to think with tools. Finally, we report improved
tool usage behavior with early code invocation and much more interactive turns
with ASPO. Overall, our work provides the first principled explanation for
TIR's success, shifting the focus from the mere fact that tools work to why and
how they enable more powerful reasoning.

</details>


### [317] [Predicting the Order of Upcoming Tokens Improves Language Modeling](https://arxiv.org/abs/2508.19228)
*Zayd M. K. Zuhri,Erland Hilman Fuadi,Alham Fikri Aji*

Main category: cs.LG

TL;DR: MTP在语言模型训练中未能带来持续的改进，而我们提出的TOP（Token Order Prediction）通过学习对未来标记进行排序，在八个标准NLP基准测试中整体优于NTP和MTP，即使在更大规模的模型上也是如此。


<details>
  <summary>Details</summary>
Motivation: MTP（Multi-Token Prediction）作为一种改进NTP（next-token prediction）的辅助目标，在标准NLP基准测试中表现不一致，有时甚至表现不佳。这是因为MTP要求精确预测未来的标记，这可能过于困难。

Method: 提出了一种名为TOP（Token Order Prediction）的新方法，该方法使用学习排序损失来训练模型，使其能够根据它们之间的接近度对即将到来的标记进行排序。与MTP需要多个Transformer层不同，TOP仅需要一个额外的unembedding层。通过使用NTP、MTP和TOP目标对340M、1.8B和7B参数的模型进行预训练，并在八个标准NLP基准测试中进行了评估。

Result: 在八个标准NLP基准测试的结果表明，TOP在整体上优于NTP和MTP，即使在更大规模的模型上也是如此。

Conclusion: TOP是一种有效的辅助训练目标，能够改进语言模型的性能，并且比MTP更具优势，所需额外计算资源更少。

Abstract: Multi-Token Prediction (MTP) has been proposed as an auxiliary objective to
improve next-token prediction (NTP) in language model training but shows
inconsistent improvements, underperforming in standard NLP benchmarks. We argue
that MTP's exact future token prediction is too difficult as an auxiliary loss.
Instead, we propose Token Order Prediction (TOP), which trains models to order
upcoming tokens by their proximity using a learning-to-rank loss. TOP requires
only a single additional unembedding layer compared to MTP's multiple
transformer layers. We pretrain models of 340M, 1.8B, and 7B parameters using
NTP, MTP, and TOP objectives. Results on eight standard NLP benchmarks show
that TOP overall outperforms both NTP and MTP even at scale. Our code is
available at https://github.com/zaydzuhri/token-order-prediction

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [318] [Computational study of alpha-ray induced electron excitation in diamonds for radiation detection](https://arxiv.org/abs/2508.18319)
*Atsuhiro Umemoto,Yoshiyuki Miyamoto*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用实时时间相关密度泛函理论研究了α射线辐照对金刚石电离的机制，发现α粒子能引起显著的电子激发，且激发态可存在数百飞秒，证明了基于金刚石的辐射探测器的理论可行性。


<details>
  <summary>Details</summary>
Motivation: 研究金刚石中辐射探测的机制。

Method: 开发了实时时间相关密度泛函理论计算方案，评估α射线辐照引起的态密度变化，并构建了包含杂质的金刚石体结构模型。

Result: 模拟显示，高速氦离子（代表α粒子）的通过在金刚石模型中引起显著的电子激发，并且在离子移除后，激发态可存在数百飞秒而不会触发非辐射弛豫。

Conclusion: 所提出的方法为评估基于金刚石的辐射探测器的性能提供了一个稳健的理论框架。

Abstract: To investigate the mechanism of radiation detection in diamonds, we developed
a real time time dependent density functional theory based calculation scheme
to evaluate changes in the density of states induced by alpha ray irradiation.
A bulk diamond structural model was constructed, with impurities optionally
introduced to assess their effect on electronic excitation. Simulations
revealed that the passage of high speed helium ions, representing alpha
particles, produced significant electronic excitation in the diamond model.
Subsequent calculations of the excited state dynamics after ion removal
indicated that excitation can persist for several hundred femtoseconds without
triggering nonradiative relaxation. These findings demonstrate that the
proposed approach offers a robust theoretical framework for evaluating the
performance of diamond-based radiation detectors.

</details>


### [319] [Light-induced odd-parity altermagnets on dimerized lattices](https://arxiv.org/abs/2508.18360)
*Dongling Liu,Zheng-Yang Zhuang,Di Zhu,Zhigang Wu,Zhongbo Yan*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Altermagnets are an emerging class of collinear magnets with
momentum-dependent spin splitting and zero net magnetization. These materials
can be broadly classified into two categories based on the behavior of spin
splitting at time-reversal-related momenta: even-parity and odd-parity
altermagnets. While even-parity altermagnets have been thoroughly investigated
both theoretically and experimentally, the systems capable of hosting
odd-parity altermagnetism remain largely unexplored. In this work, we
demonstrate that circularly polarized light dynamically converts collinear
PT-symmetric antiferromagnets on dimerized lattices into odd parity p-wave
altermagnets. Because of the underlying Dirac band structure of the dimerized
lattice, we find that the resulting p-wave altermagnets can realize Chern
insulators (2D) and Weyl semimetals (3D) under appropriate drive conditions.
Our findings demonstrate that collinear antiferromagnets on dimerized lattices
provide ideal platforms to investigate the dynamical generation of odd-parity
altermagnetism.

</details>


### [320] [Parity Breaking at Faceted Crystal Growth Fronts during Ice Templating](https://arxiv.org/abs/2508.18403)
*Kaihua Ji,Alain Karma*

Main category: cond-mat.mtrl-sci

TL;DR: 定向凝固水基溶液可用于制备多孔材料，但其非平衡过程仍未完全阐明。本研究使用相场模拟来阐明选择层状冰结构生长方向的机制。


<details>
  <summary>Details</summary>
Motivation: 定向凝固水基溶液作为模板制备多孔材料是一种多功能技术，但其非平衡过程的机制仍不完全清楚。

Method: 利用相场模拟来研究和理解层状冰结构生长方向的选择机制。

Result: 模拟结果表明，生长方向的选择可以用自发对称性破缺的通用框架来理解，并能定量预测层状结构相对于热轴的倾斜角度。

Conclusion: 该研究结果为理解和解释广泛的实验观察提供了理论基础，有助于指导未来实验设计。

Abstract: Directional solidification of water-based solutions has emerged as a
versatile technique to template hierarchical porous materials, but this
nonequilibrium process remains incompletely understood. Here we use phase-field
simulations to shed light on the mechanism that selects the growth direction of
the lamellar ice structure that templates those materials. Our results show
that this selection can be understood within the general framework of
spontaneous parity breaking, yielding quantitative predictions for the tilt
angle of lamellae with respect to the thermal axis. The results provide a
theoretical basis to interpret a wide range of experimental observations.

</details>


### [321] [Phase-Field Model of Freeze Casting](https://arxiv.org/abs/2508.18416)
*Kaihua Ji,Alain Karma*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一个用于模拟水基溶液定向凝固的分数相场模型，解释了部分分面的冰-水界面特性，并揭示了导致部分分面冰薄片形成的自发奇偶性破缺现象，研究了该薄片漂移速度与动力学各向异性的关系。


<details>
  <summary>Details</summary>
Motivation: 理解水基溶液定向凝固过程中图案形成的机制。

Method: 提出并分析了一个用于模拟定向凝固的定量相场模型，该模型扩展了稀二元合金凝固的薄界面公式，并考虑了冰-水界面的各向异性能量和动力学特性。

Result: 模型能够重现实验测量的动力学关系，观察到自发奇偶性破缺导致形成部分分面的冰薄片，并发现漂移速度受基面动力学控制且随界面厚度减小而收敛。研究还表明，动力学各向异性的形式斜率不影响漂移速度，且在较小的斜率值下，冰薄片尖端的半径和过冷度趋于收敛。

Conclusion: 所提出的相场模型能够定量且计算高效地模拟部分分面冰薄片的形成和漂移行为，为理解定向凝固过程提供了理论支持。

Abstract: Directional solidification of water-based solutions has emerged as a
versatile technique for templating hierarchical porous materials. However, the
underlying mechanisms of pattern formation remain incompletely understood. In
this work, we present a detailed derivation and analysis of a quantitative
phase-field model for simulating this nonequilibrium process. The phase-field
model extends the thin-interface formulation of dilute binary alloy
solidification with anti-trapping to incorporate the highly anisotropic
energetic and kinetic properties of the partially faceted ice-water interface.
This interface is faceted in the basal plane normal to the <0001> directions
and atomically rough in other directions within the basal plane. On the basal
plane, the model reproduces a linear or nonlinear kinetic relationship that can
be linked to experimental measurements. In both cases, spontaneous parity
breaking of the solidification front is observed, leading to the formation of
partially faceted ice lamellae that drift laterally in one of the <0001>
directions. We demonstrate that the drifting velocity is controlled by the
kinetics on the basal plane and converges as the thickness of the diffuse
solid-liquid interface decreases. Furthermore, we examine the effect of the
form of the kinetic anisotropy, which is chosen here such that the inverse of
the kinetic coefficient varies linearly from a finite value in the <0001>
directions to zero in all other directions within the basal plane. Our results
indicate that the drifting velocity of ice lamellae is not affected by the
slope of this linear relation, and the radius and undercooling at the tip of an
ice lamella converge at relatively small slope values. Consequently, the
phase-field simulations remain quantitative with computationally tractable
choices of both the interface thickness and the slope assumed in the form of
the kinetic anisotropy.

</details>


### [322] [Designing Antiferromagnetic Spin-1/2 Chains in Janus Fullerene Nanoribbons](https://arxiv.org/abs/2508.18849)
*Bo Peng,Michele Pizzochero*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在富勒烯纳米带边缘引入额外的C60笼，设计了反铁磁性自旋1/2链。该结构通过奇数数量的分子间键诱导产生未配对的π电子，从而在原本非磁性的纳米带中产生量子化的磁矩。线性排列的自旋1/2 C60笼形成了对结构细节不敏感的反铁磁基态。与石墨烯纳米带相比， Janus富勒烯纳米带为在低维碳纳米结构中以原子精度实现磁性边缘态提供了更易于实验实现的途径，并可能作为可扩展自旋基器件和多体量子物态探索的多功能纳米架构。


<details>
  <summary>Details</summary>
Motivation: 在富勒烯纳米带中引入磁性边缘态，以探索新的低维磁性材料和自旋基器件。

Method: 通过计算设计，在富勒烯纳米带边缘引入额外的C60笼，形成奇数分子间键，诱导产生未配对π电子和磁矩，并研究自旋1/2 C60笼的线性排列形成的反铁磁基态。

Result: 成功设计了具有反铁磁基态的自旋1/2富勒烯纳米带。该结构对结构细节不敏感，并且相比石墨烯纳米带更易于实验实现。

Conclusion: Janus富勒烯纳米带为实现低维碳纳米结构中的磁性边缘态提供了一种有前景的途径，有望应用于自旋基器件和量子物态研究。

Abstract: We computationally design antiferromagnetic spin-1/2 chains in fullerene
nanoribbons by introducing extra C$_{60}$ cages at one of their edges. The
resulting odd number of intermolecular bonds induces an unpaired $\pi$-electron
and hence a quantised magnetic moment in otherwise non-magnetic nanoribbons. We
further reveal the formation of an antiferromagnetic ground state upon the
linear arrangement of spin-$1/2$ C$_{60}$ cages that is insensitive to the
specific structural motifs. Compared with graphene nanoribbons, Janus fullerene
nanoribbons may offer an experimentally more accessible route to magnetic edge
states with atomic precision in low-dimensional carbon nanostructures, possibly
serving as a versatile nanoarchitecture for scalable spin-based devices and the
exploration of many-body quantum phases.

</details>


### [323] [Exploration of Hexagonal, Layered Carbides and Nitrides as Ultra-High Temperature Ceramics](https://arxiv.org/abs/2508.18455)
*Kat Nykiel,Brian Wyatt,Babak Anasori,Alejandro Strachan*

Main category: cond-mat.mtrl-sci

TL;DR: 通过高通量密度泛函理论研究了M$_{n+1}$X$_{n}$（n=1,2,3；M=Ta,Ti,Hf,Zr,Nb,Mo,V,W,Sc,Cr,Mn；X=C,N）的六方层状结构材料的热力学稳定性和弹性常数，并预测了其熔点。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前对超高温陶瓷中层状六方晶体结构（如zeta和eta相）的结构、稳定性和成分渗透性方面存在的疑问，并探索其在超高温陶瓷中提高韧性的潜力。

Method: 利用高通量密度泛函理论（DFT）计算了67种新的六方层状碳化物和氮化物M$_{n+1}$X$_{n}$（n=1,2,3；M=Ta,Ti,Hf,Zr,Nb,Mo,V,W,Sc,Cr,Mn；X=C,N）的热力学稳定性和弹性常数。同时，结合机器学习和基于物理的模型，利用DFT计算结果预测了这些材料的熔点。

Result: 发现了67种新的六方层状材料，其热稳定性与已知的zeta相相当或更好。其中有几种材料的熔点与现有的zeta类相相当，有五种材料的预测熔点高于2500 K。

Conclusion: 该研究扩展了用于高温应用的六方层状材料的化学和结构范围，为超高温陶瓷的发展提供了新的候选材料。

Abstract: Layered, hexagonal crystal structures, like zeta and eta phases, play an
important role in ultra-high temperature ceramics, often significantly
increasing toughness of carbide composites. Despite their importance open
questions remain about their structure, stability, and compositional
pervasiveness. We use high-throughput density functional theory to characterize
the thermodynamic stability and elastic constants of layered carbides and
nitrides M$_{n+1}$X$_{n}$ with $n$ = 1, 2, and 3, $M$ = Ta, Ti, Hf, Zr, Nb, Mo,
V, W, Sc, Cr, Mn and $X$ = C, N. The stacking sequences explored are inspired
by the possible use of MXenes as precursors to enable relatively low
temperature processing of high-temperature ceramics. We identified 67 new
hexagonal, layered materials with thermal stability comparable or better than
previously observed zeta phases. To assess their potential for high temperature
applications, we used machine learning and physics-based models with DFT inputs
to predict their melting temperatures and discovered several candidates on par
with the current state of the art zeta-like phases and five with predicted
melting temperatures above 2500 K. The findings expand the range of chemistries
and structures for high-temperature applications.

</details>


### [324] [Lattice vacancy migration barriers in Fe-Ni alloys, and why Ni atoms diffuse slowly: An ab initio study](https://arxiv.org/abs/2508.19124)
*Adam M. Fisher,Christopher D. Woodgate,Xiaoyu Zhang,George C. Hadjipanayis,Laura H. Lewis,Julie B. Staunton*

Main category: cond-mat.mtrl-sci

TL;DR: Fe和Ni在Fe_x Ni_{1-x}合金中的迁移行为不同，Ni比Fe迁移性差，这与电子结构有关。


<details>
  <summary>Details</summary>
Motivation: 研究Fe_x Ni_{1-x}合金（包括A1和L1_0相）中Fe和Ni的原子迁移行为，特别是Ni较低的迁移性。

Method: 使用从头算电子结构计算和NEB方法量化原子迁移的能量势垒。

Result: Ni原子在所有计算的结构和成分中，迁移性始终显著低于Fe原子。发现局部晶格畸变和局部电子自旋极化之间的耦合，导致Fe原子倾向于弛豫到空位，而Ni原子则保持不动。

Conclusion: Fe和Ni在Fe-Ni合金中的扩散差异源于原子尺度上的电子结构效应，特别是与空位相关的晶格畸变和自旋极化，这可以解释Ni扩散缓慢的长期实验观察结果。

Abstract: The mobility of both Fe and Ni atoms in ferromagnetic $\textrm{Fe}_x
\textrm{Ni}_{1-x}$ alloys ($0.4 \leq x \leq 0.6$) is investigated within the
framework of ab initio electronic structure calculations, using the nudged
elastic band (NEB) method to accurately quantify energetic barriers to lattice
vacancy migration. Both the atomically disordered ($A1$) fcc phase, as well as
the atomically ordered, tetragonal $\textrm{L}1_0$ phase - which is under
consideration as a material for a rare-earth-free 'gap' magnet for advanced
engineering applications - are investigated. Across an ensemble of NEB
calculations performed on supercell configurations spanning a range of
compositions and containing disordered, partially ordered, and fully ordered
structures, we find that Ni atoms are consistently significantly less mobile
than Fe atoms. Crucially, we are able to interpret these findings in terms of
the ferromagnetic alloy's underlying spin-polarised electronic structure.
Specifically, we report a coupling between the size of local lattice
distortions and the magnitude of the local electronic spin polarisation around
vacancies. This causes Fe atoms to relax into lattice vacancies, while Ni atoms
remain rigidly fixed to their original lattice positions. This effect plays a
key role in determining the reduced mobility of Ni atoms compared to that of Fe
atoms. These results shed atomic-scale insight into the longstanding
experimental observation that Ni exhibits remarkably slow atomic diffusion in
Fe-Ni alloys.

</details>


### [325] [Electron-Phonon interaction and lattice thermal conductivity from metals to 2D Dirac crystals: a review](https://arxiv.org/abs/2508.18477)
*Sina Kazemian,Giovanni Fanchini*

Main category: cond-mat.mtrl-sci

TL;DR: 电子-声子(e--ph)耦合是固态材料电导率、热导率和载流子冷却的关键。本研究基于第一性原理，预测了d带金属、宽带隙半导体到二维狄拉克晶体的e--ph限制热导率，无需经验参数。在块状金属中，尽管声子是次要的，但一旦考虑e--ph散射，声子仍可承担高达40%的热量。研究还探讨了耦合玻尔兹曼框架，如elphbolt，用于处理半导体中的相互拖曳和超快非平衡现象。对于二维狄拉克晶体，镜面对称性、载流子密度、应变和有限尺寸会改变散射层级，例如，在原始石墨烯中ZA模式占主导，但在纳米带中，一旦打破对称性，ZA模式成为主要的电阻分支。在低费米能级和高温下，标准的三粒子衰变会被四粒子过程部分抵消，需要动态筛选和更高阶的理论。本研究识别了关键的微观因素，如电子态密度、声子频率和形变势，并展示了掺杂、应变或介电环境如何调谐e--ph阻尼。最后，指出了未来的挑战，包括开发耦合e--ph求解器、求解包含四粒子项的完整模-模Peierls-Boltzmann方程、在e--ph工作流程中嵌入相关电子方法，以及利用高阶e--ph耦合和对称性破坏来实现声子热二极管和整流器。解决这些挑战将使e--ph理论从诊断工具转变为预测性、无参数平台，将对称性、筛选和多体效应与下一代电子、光子和热电设备中的热量和电荷传输联系起来。


<details>
  <summary>Details</summary>
Motivation: 电子-声子(e--ph)耦合在固态材料的电导率、热导率和载流子冷却中起着至关重要的作用。本研究旨在基于第一性原理，深入理解和预测e--ph耦合对不同材料（包括d带金属、宽带隙半导体和二维狄拉克晶体）热传输的影响，并探索调控这些过程的微观因素和潜在应用。

Method: 本研究采用基于第一性原理的计算方法，结合耦合玻尔兹曼框架（如elphbolt），来预测和分析电子-声子(e--ph)耦合对材料热传输的影响。具体方法包括：1. 预测d带金属、宽带隙半导体到二维狄拉克晶体的e--ph限制热导率；2. 分析块状金属中声子承担热量的比例；3. 探讨耦合玻尔兹曼框架在半导体中的应用；4. 研究二维狄拉克晶体中对称性、载流子密度、应变和尺寸对散射层级的影响；5. 分析低费米能级和高温下粒子衰变过程的变化；6. 识别并分析电子态密度、声子频率、形变势等微观因素以及掺杂、应变、介电环境对e--ph阻尼的调控作用。

Result: 研究发现，在块状金属中，即使考虑了e--ph散射，声子仍能携带高达40%的热量。在二维狄拉克晶体中，ZA模式在原始石墨烯中占主导，但在纳米带中，随着对称性被打破，ZA模式成为主要的电阻分支。此外，低费米能级和高温下，四粒子过程变得重要，需要更高阶的理论。研究还展示了如何通过掺杂、应变或改变介电环境来调控e--ph阻尼。

Conclusion: 本研究基于第一性原理和耦合玻尔兹曼框架，深入分析了电子-声子(e--ph)耦合对不同材料热传输的影响，并识别了关键的微观调控因素。研究指出了未来在开发耦合e--ph求解器、处理高阶散射过程以及利用e--ph耦合实现热电器件方面的挑战和机遇。最终目标是推动e--ph理论成为一个预测性的、无参数的平台，以指导下一代电子、光子和热电设备的设计。

Abstract: Electron--phonon (e--ph) coupling governs electrical resistivity, hot-carrier
cooling, and critically, thermal transport in solids. Recent first-principles
advances now predict e--ph limited thermal conductivity from d-band metals and
wide-band-gap semiconductors to 2D Dirac crystals without empirical parameters.
In bulk metals, ab-initio lifetimes show that phonons, though secondary, still
carry up to 40\% of the heat once e--ph scattering is included. We next survey
coupled Boltzmann frameworks, exemplified by \textsc{elphbolt}, that capture
mutual drag and ultrafast non-equilibrium in semiconductors. For 2D Dirac
crystals, mirror symmetry, carrier density, strain, and finite size rearrange
the scattering hierarchy: ZA modes dominate pristine graphene yet become the
main resistive branch in nanoribbons once symmetry is broken. At low Fermi
energies and high temperatures, the standard 3-particle decay is partially
cancelled, elevating 4-particle processes and necessitating dynamically
screened, higher-order theory. Throughout, we identify the microscopic levers
such as the electronic density of states, phonon frequency, deformation
potential, and show how doping, strain, or dielectric environment can tune
e--ph damping. We conclude by outlining open challenges such as: developing
coupled e--ph solvers, solving the full mode-to-mode Peierls--Boltzmann
equation with 4-particle terms, embedding correlated electron methods in e--ph
workflows, and leveraging higher-order e--ph coupling and symmetry breaking to
realise phononic thermal diodes and rectifiers. Solving these challenges will
elevate e--ph theory from a diagnostic tool to a predictive, parameter-free
platform that links symmetry, screening, and many-body effects to heat and
charge transport in next-generation electronic, photonic, and thermoelectric
devices.

</details>


### [326] [Long lifetimes of nanoscale skyrmions in lithium-decorated van der Waals ferromagnet Fe$_3$GeTe$_2$](https://arxiv.org/abs/2508.18522)
*Soumyajyoti Haldar,Moritz A. Goerzen,Stefan Heinze,Dongzhe Li*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在二维磁性材料Fe$_3$GeTe$_2$表面吸收锂，成功诱导了大的DMI效应，并在小外加磁场下形成了具有高能量势垒（>300 meV）和长寿命（75 K下超过1小时）的纳米尺度磁畴壁。


<details>
  <summary>Details</summary>
Motivation: 大多数二维磁体具有反演对称性，导致DMI效应被抑制，而DMI是形成磁skyrmion的关键因素。因此，需要一种方法来诱导二维磁体中的DMI效应。

Method: 使用第一性原理和原子尺度自旋模拟，研究了锂吸附在单层Fe$_3$GeTe$_2$表面对DMI效应和磁skyrmion形成的影响。

Result: 预测在锂修饰的单层Fe$_3$GeTe$_2$中，在施加小的垂直磁场（$B_z$）下，可以形成纳米尺度的磁skyrmion。这些磁skyrmion具有非常高的能量势垒（>300 meV），可与铁磁体/重金属界面上的情况相比。其起源归因于强的DMI、交换挫折和小晶体磁各向异性能的竞争。此外，在高达75 K的温度下，亚稳态磁skyrmion的寿命超过一小时。

Conclusion: 通过在二维磁体表面吸收锂，可以有效诱导大的DMI效应，并形成具有优异稳定性的磁skyrmion，为二维磁性材料在自旋电子器件中的应用提供了新的途径。

Abstract: The Dzyaloshinskii-Moriya interaction (DMI), which originates from spin-orbit
coupling and relies on broken inversion symmetry, is recognized as a key
ingredient in forming magnetic skyrmions. However, most 2D magnets exhibit
inversion symmetry; therefore, the DMI is suppressed. Here, we propose a
strategy to induce large DMI via lithium absorption on the surface of 2D
magnets -- an experimentally feasible approach. Using first-principles and
atomistic spin simulations, we predict the formation of nanoscale skyrmions in
lithium-decorated monolayer Fe$_3$GeTe$_2$ by imposing small out-of-plane
magnetic fields ($B_z$). Notably, we find very large skyrmion energy barriers
of more than 300 meV at $B_z = 0.4$ T, comparable to those observed in
ferromagnet/heavy-metal interfaces. The origin of these unique skyrmions is
attributed to the competition between strong DMI, exchange frustration, and
small magnetocrystalline anisotropy energy. We further show that the lifetimes
of metastable skyrmions exceed one hour for temperatures up to 75 K.

</details>


### [327] [Ice-assisted soft-landing deposition for van der Waals integration](https://arxiv.org/abs/2508.18577)
*Xinyu Sun,Xiang Xu,BinBin Jin,Yihan Lu,Jichuang Shen,Wei Kong,Ding Zhao,Min Qiu*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种利用冰缓冲层进行范德华集成的新方法，用于在二维材料（如MoS2）上制造高性能晶体管，并实现了10^10的开关比和80 cm^2 V^-1s^-1的迁移率。


<details>
  <summary>Details</summary>
Motivation: 克服了传统范德华集成方法（如物理拾取和放置）难以与现有光刻和金属化工艺结合的限制，并解决了金属化过程中对器件的损伤问题。

Method: 提出了一种原位转移策略，利用非晶态水冰作为缓冲层，在金属化过程中保护器件免受高能粒子轰击。在冰升华后，金属薄膜可以原位、轻柔地放置在衬底上，形成原子级清洁、无损伤的金属-半导体界面。

Result: 成功在单层MoS2上制造出高质量的欧姆接触，实现了10^10的开关比和80 cm^2 V^-1s^-1的迁移率，并有效抑制了费米能级钉扎效应。此外，还实现了具有均匀电学特性的CVD生长MoS2晶体管阵列的批量生产，并将该方法扩展到对高活性材料（如卤化物钙钛矿）的应用。

Conclusion: 所提出的温和、超净的制造方法易于与成熟的半导体制造技术集成，有望成为制造范德华接触器件的通用策略。

Abstract: Van der Waals integration enables the creation of electronic and
optoelectronic devices with unprecedented performance and novel functionalities
beyond the existing material limitations. However, it is typically realized
using a physical pick-up-and-place process to minimize interfacial damages and
is hardly integrated into conventional lithography and metallization
procedures. Here we demonstrate a simple in situ transfer strategy for van der
Waals integration, in which a thin film of amorphous water ice acts as a buffer
layer to shield against the bombardment of energetic clusters during
metallization. After ice sublimation, the deposited metal film can be gently
and in situ placed onto underlying substrates, to form an atomically clean and
damage-free metal-semiconductor interface. This strategy allows ultra-clean and
non-destructive fabrication of high-quality contacts on monolayer MoS2, which
is extremely beneficial to produce a high-performance 2D field-effect
transistor with an ultra-high on/off ratio of 1010, mobility of 80 (cm2
V-1s-1), and also with reduced Fermi level pinning effect. We also demonstrate
the batch production of CVD-grown MoS2 transistor arrays with uniform
electrical characteristics. Such a gentle and ultra-clean fabrication approach
has been further extended to materials with high reactivity, such as halide
perovskites. Our method can be easily integrated with mature semiconductor
manufacturing technology and may become a generic strategy for fabricating van
der Waals contacted devices.

</details>


### [328] [Origin of Glass-like Thermal Conductivity in Crystalline TlAgTe](https://arxiv.org/abs/2508.18727)
*Shantanu Semwal,Yi Xia,Chris Wolverton,Koushik Pal*

Main category: cond-mat.mtrl-sci

TL;DR: TlAgTe具有异常低的玻璃状热导率，这归因于局部声子模式和四声子散射。


<details>
  <summary>Details</summary>
Motivation: 理解控制热传输的微观机制对于揭示晶体结构、声子以及准粒子集体激发之间复杂的相互作用至关重要。

Method: 使用基于量子密度泛函理论的先进第一性原理计算，并结合非谐晶格动力学理论，包括声子自能诱导的频率重归一化以及粒子状（Peierls）和波状（相干）热传输贡献，同时考虑三声子和四声子散射通道。

Result: TlAgTe表现出由Tl原子协同的局部振动产生的局部声子模式，这些模式表现出强烈的温度依赖性和增强的四声子散射，从而将Peierls热导率抑制到极低值。局部结构畸变、孤对电子和重阳离子 the rattling-like 振动引起的强非谐性导致声子模式在40 cm^-1以上从粒子状行为转变为波状隧穿特性，显著地增加了相干热导率。

Conclusion: 该研究揭示了TlAgTe中异常低热导率的起源，突出了局部声子模式和强非谐性在调节热传输中的作用，为设计具有可调热导率的新型材料提供了结构-性质关系。

Abstract: Ordered crystalline compounds exhibiting ultralow and glass-like thermal
conductivity are both fundamentally and technologically important, where phonon
quasi-particles dominate their heat transport. Understanding the microscopic
mechanisms that govern such unusual transport behavior is necessary to unravel
the complex interplay of crystal structure, phonons, and collective excitations
of these quasi-particles. Here, we use state-of-the-art first-principles
calculations based on quantum density functional theory to investigate the
origin of experimentally measured unusually low and glassy thermal conductivity
in semiconducting TlAgTe. Utilizing a unifying framework of anharmonic lattice
dynamics theory that combine phonon self-energy induced frequency
renormalization, particle-like Peierls ($kappa_l^P$) and wave-like coherent
($kappa_l^C$) thermal transport contributions including three and four-phonon
scattering channels, we successfully explain the experimental results both in
terms of magnitude and temperature dependence. Our analysis reveals that TlAgTe
exhibits several localized phonon modes arising from concerted rattling-like
vibration of Tl atoms, which show strong temperature dependence and enhanced
four-phonon scattering rates that are dominated by Umklapp processes,
suppressing $kappa_l^P$ to ultralow values. The ensuing strong anharmonicity
induced by local structural distortions, lone-pair electrons, and rattling-like
vibrations of the heavy cations lead to a transition from particle-like
behavior to wave-like tunneling characteristics of the phonon modes above 40
cm$^-1$, contributing significantly to $kappa_l^C$ which increases with
temperature. Our analysis uncovers important structure-property relationship,
which may be used in designing of novel materials with tunable thermal
conductivity.

</details>


### [329] [Flexible orbital torque device with ultralow switching current](https://arxiv.org/abs/2508.18746)
*Liguang Gong,Jian Song,Bin Lao,Run-Wei Li,Zhiming Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 本文展示了一种基于云母/SrRuO3(SRO)/CoPt异质结构的有弹性的、高效的轨道扭矩（OT）器件，该器件具有极低的阈值电流密度（9.2x10^9 A/m^2），比传统自旋扭矩器件低90%，并能承受10^3次弯曲循环，有望用于下一代可穿戴自旋电子器件。


<details>
  <summary>Details</summary>
Motivation: 探索轨道扭矩（OT）在柔性自旋电子学中的应用潜力。

Method: 制备了一种基于云母/SrRuO3(SRO)/CoPt异质结构的柔性OT器件，并通过实验测量了其扭矩效率和阈值电流密度，测试了其在弯曲循环后的性能保持情况。

Result: 测量到-0.31的大扭矩效率，源于SRO层显著的轨道霍尔效应。得益于云母衬底的低热导率，实现了9.2x10^9 A/m^2的超低阈值电流密度，比传统自旋扭矩器件降低了90%。该器件在10^3次弯曲循环后性能保持优异，展现了出色的柔韧性和耐用性。

Conclusion: 该工作率先开发了柔性OT器件，为下一代低功耗可穿戴自旋电子器件的应用展示了一条可行的路径。

Abstract: Orbital torque (OT) offers a highly efficient way for electrical
magnetization manipulation. However, its potential in the emerging field of
flexible spintronics remains largely unexplored. Here, we demonstrate a
flexible and robust OT device based on a mica/SrRuO3(SRO)/CoPt heterostructure.
We measure a large torque efficiency of -0.31, which originates from the
significant orbital Hall effect in the SRO layer. Leveraging the low thermal
conductivity of the mica substrate, a thermally-assisted switching mechanism is
activated, enabling an ultralow threshold current density of 9.2x109 A/m2. This
value represents a 90% reduction compared to conventional spin-torque devices
and a 52% reduction against its rigid counterpart on a SrTiO3 substrate. The
superior performances is well-maintained after 103 bending cycles, conforming
its exceptional flexibility and durability. Our work pioneers the development
of flexible OT devices, showcasing a viable path toward next-generation,
low-power wearable spintronic applications.

</details>


### [330] [Chemical control of polymorphism and ferroelectricity in PbTiO3 and SrTiO3 monolayers and bilayers](https://arxiv.org/abs/2508.18777)
*Shaowen Xu,Jeffrey R. Reimers,Fanhao Jia,Wei Ren*

Main category: cond-mat.mtrl-sci

TL;DR: Perovskite bilayers exhibit switchable ferroelectricity controlled by bond dynamics, influenced by strain and environment, offering potential for futuristic devices.


<details>
  <summary>Details</summary>
Motivation: Perovskites exhibit distortions from high symmetry to dipole polarization for various applications. This paper investigates the mechanisms controlling ferroelectricity in 2D perovskite bilayers.

Method: Density-functional theory calculations were used to study ferroelectricity in PbTiO3 and SrTiO3 bilayers, focusing on bond breakage and formation processes under relaxation and biaxial strain.

Result: Ferroelectricity in these bilayers is controlled by binary switching processes involving bond breakage and formation. These processes are activated by structural relaxation and biaxial strain, leading to low energy barriers for polarization switching. Intermediate symmetry structures were identified, revealing the roles of ferrodistortive and antiferrodistortive octahedral distortions. Ferrodistortive modes are driven by coupled antiferrodistortive motions, with four angular variables controlling polarization switching via bond dynamics. Polarization is sensitive to chemical environment and temperature.

Conclusion: The study reveals that ferroelectric polarization switching in perovskite bilayers is governed by intricate bond dynamics, modulated by strain and environmental factors. This understanding can be leveraged for designing novel electronic devices.

Abstract: Layers of perovskites, found in 3D materials, 2D heterostructures, and
nanotubes, often distort from high symmetry to facilitate dipole polarisation
that is exploitable in many applications. Using density-functional theory
calculations, ferroelectricity in bilayers of the 2D materials PbTiO3 and
SrTiO3 is shown to be controlled by bond breakage and formation processes that
act as binary switches. These stacking-dependent processes turn on and off as a
function of relaxation from high-symmetry structures and the application of
biaxial strain, and their concerted rearrangements lead to low energy barriers
for ferroelectric polarisation switching. Structures with symmetry intermediate
between high-symmetry octahedral forms and low-symmetry ferroelectric forms are
identified, allowing the intrinsic processes associated with traditional
"ferrodistortive" and "antiferrodistortive" distortions of TiO6 octahedra to be
identified. Ferrodistortive-mode activity is shown to be generated by the
simultaneous application of two different types of curvilinear
antiferrodistortive motions. In this way, four angular variabes control
polarisation switching through the concerted making and breaking of chemical
bonds. These subltities make the polarisation sensitive to chemical-environment
and temperature effects that manipulate strain and structure, features
exploitable in futuristic devices.

</details>


### [331] [In silico investigation of Ba-based ternary chalcogenides for photovoltaic applications](https://arxiv.org/abs/2508.18796)
*Ramya Kormath Madam Raghupathy,Hossein Mirhosseini,Thomas D. Kühne*

Main category: cond-mat.mtrl-sci

TL;DR: 钡基三元硫属化物在太阳能电池中表现出应用前景。


<details>
  <summary>Details</summary>
Motivation: 寻找具有优越特性的高性能吸收材料是太阳能电池研究的重要课题。

Method: 研究了279种钡基三元硫属化物，通过带隙大小和稳定性进行筛选，筛选出19种化合物，并进一步研究了本征缺陷和p型掺杂特性。

Result: 筛选出\ch{BaCu2Se2}和\ch{ZrBaSe3}两种作为单结和串联电池的潜在吸收材料。

Conclusion: \ch{BaCu2Se2}和\ch{ZrBaSe3}是用于太阳能电池的两种有前途的钡基吸收材料。

Abstract: In solar cells, the absorbers are the key components for capturing solar
energy and converting photons into electron-hole pairs. The search for
high-performance absorbers with advantageous characteristics is an ongoing task
for researchers. In this work, we investigated promising and environmentally
benign Ba-based ternary chalcogenides for photovoltaic applications. The total
number of Ba-based ternary chalcogenides in the Materials Project database was
found to be 279. Materials screening based on bandgap size and stability
reduced the number of compounds to 19. The performance of an absorber depends
on the charge carrier lifetime, which is controlled by non-radiative processes
involving defects. Hence, we investigated the intrinsic defects and p-type
dopability of the compounds. We identified two Ba-based compounds, namely
\ch{BaCu2Se2} and \ch{ZrBaSe3}, as promising absorbers for single-junction and
tandem cells and investigated them in detail.

</details>


### [332] [Temperature-Aware Recurrent Neural Operator for Temperature-Dependent Anisotropic Plasticity in HCP Materials](https://arxiv.org/abs/2508.18806)
*Yannick Hollenweger,Dennis M. Kochman,Burigede Liu*

Main category: cond-mat.mtrl-sci

TL;DR: TRNO是一种新型时间独立神经网络，能高效模拟温度相关塑性行为，在计算力学中比GRU/LSTM表现更好，并实现三倍以上加速。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRU/LSTM的神经网络模型在模拟塑性力学时存在训练时间长、预测依赖时间分辨率、以及难以处理复杂材料行为等问题。TRNO旨在克服这些限制。

Method: 提出并应用了一种名为温度感知循环神经网络算子（TRNO）的新型时间独立神经网络架构，用于模拟多晶镁的温度相关塑性响应，该材料具有强塑性各向异性和热敏性。

Result: TRNO在预测精度、泛化能力（跨不同加载情况、温度和时间分辨率）以及训练效率和预测性能方面优于传统的GRU和LSTM模型。TRNO在多尺度模拟中实现了至少三个数量级的加速。

Conclusion: TRNO是一种有效且高效的神经网络架构，能够准确模拟复杂的温度相关塑性行为，并在计算力学应用中显著提高模拟速度。

Abstract: Neural network surrogate models for constitutive laws in computational
mechanics have been in use for some time. In plasticity, these models often
rely on gated recurrent units (GRUs) or long short-term memory (LSTM) cells,
which excel at capturing path-dependent phenomena. However, they suffer from
long training times and time-resolution-dependent predictions that extrapolate
poorly. Moreover, most existing surrogates for macro- or mesoscopic plasticity
handle only relatively simple material behavior. To overcome these limitations,
we introduce the Temperature-Aware Recurrent Neural Operator (TRNO), a
time-resolution-independent neural architecture. We apply the TRNO to model the
temperature-dependent plastic response of polycrystalline magnesium, which
shows strong plastic anisotropy and thermal sensitivity. The TRNO achieves high
predictive accuracy and generalizes effectively across diverse loading cases,
temperatures, and time resolutions. It also outperforms conventional GRU and
LSTM models in training efficiency and predictive performance. Finally, we
demonstrate multiscale simulations with the TRNO, yielding a speedup of at
least three orders of magnitude over traditional constitutive models.

</details>


### [333] [Quantum geometry in low-energy linear and nonlinear optical responses of magnetic Rashba semiconductor (Ge,Mn)Te](https://arxiv.org/abs/2508.18818)
*Tsubasa Takagi,Hikaru Watanabe,Ryutaro Yoshimi,Yuki Sato,Shingo Toyoda,Atsushi Tsukazaki,Kei S. Takahashi,Masashi Kawasaki,Yoshinori Tokura,Naoki Ogawa*

Main category: cond-mat.mtrl-sci

TL;DR: 量子几何影响磁性Rashba半导体的光学性质，特别是线性光学电导率和磁注入电流。


<details>
  <summary>Details</summary>
Motivation: 研究量子几何对量子材料光学性质的影响，尤其是在狄拉克点附近。

Method: 通过理论计算研究磁性Rashba半导体在中红外区域的线性和非线性光学响应（光学电导率和注入电流），并考虑了几何效应。

Result: 线性光学电导率反映了量子度量，即使在联合态密度减小时也保持有限；磁注入电流随费米能级相对于狄拉克点的位置而增强。

Conclusion: 量子几何是理解磁性Rashba半导体光学性质的关键因素，理论计算能够很好地复现实验结果。

Abstract: Quantum geometry appears as a key factor in understanding the optical
properties of quantum materials, with the anticipation on diverging or
quantized responses near the Dirac and Weyl points. Here we investigate linear
and nonlinear optical responses -- optical conductivity and injection current
-- in a magnetic Rashba semiconductor in the mid-infrared region, with varying
the Fermi energy across the Dirac point. We reveal that the linear optical
conductivity reflects quantum metric, which remains finite irrespective of the
diminishing joint density-of-states at lower photon energy. It is also
confirmed that the magnetic injection current enhances depending on the energy
of the Fermi level relative to the Dirac point. These optical spectra are
nicely reproduced by our theoretical calculations with geometrical effects
taken into account.

</details>


### [334] [Strong and Engineerable Optical Anisotropy in Easily Integrable Epitaxial SrO(SrTiO 3 ) N Ruddlesden--Popper Thin Layers](https://arxiv.org/abs/2508.18862)
*Mohamed Oussama Bounab,Clarisse Furgeaud,Sébastien Cueff,Lotfi Berguiga,Romain Bachelet,Mohamed Bouras,Laurent Pedesseau,Jacky Even,Ludovic Largeau,Guillaume Saint-Girons*

Main category: cond-mat.mtrl-sci

TL;DR: STO-RP N 薄膜表现出可调的光学各向异性，且易于与硅和砷化镓等光子平台集成。


<details>
  <summary>Details</summary>
Motivation: 为光子器件寻找适合的块体各向异性材料，并解决现有材料的合成、光学损耗和结构复杂性问题。

Method: 结合椭圆光度测量和反射测量，研究了SrO(SrTiO 3 ) N (STO-RP N ) 外延薄膜的光学特性。

Result: STO-RP N 薄膜在宽光谱范围内表现出明显的多色性和双折射，并且可以通过调节RP序数N来调整各向异性。该薄膜可通过行业标准的生长工艺制备，并能在硅和砷化镓等光子平台上进行集成。

Conclusion: STO-RP N 薄膜是一种有前途的光子材料，具有可调的光学各向异性，且易于与现有光子平台集成，为紧凑型光子器件的开发铺平了道路。

Abstract: Optical anisotropy is a key property for numerous photonic devices. However,
bulk anisotropic materials suitable for such applications remain relatively
scarse and are often challenging to synthesize as thin films. Additionally, the
optical losses as well as the complex structuration of anisotropic
metamaterials hinder their integrability in photonic devices. Based on
ellipsometry measurements coupled with reflectance, it is demonstrated here
that Ruddlesden-Popper (RP) SrO(SrTiO 3 ) N phases (STO-RP N ), epitaxial thin
films composed of a SrTiO 3 lattice periodically interrupted by one SrO atomic
plane every N unit cells, exhibit pronounced dichroism and birefringence over a
broad spectral range. Notably, this anisotropy is tunable by adjusting the RP
order N. In contrast to most other anisotropic materials reported in the
literature, STO-RP N thin layers can be fabricated using industry-standard
growth processes. As it can be epitaxially grown on Si and GaAs using SrTiO 3
templates, the work paves the way for their compact integration on these
photonic platforms.

</details>


### [335] [Microscale optoelectronic synapses with switchable photocurrent from halide perovskite](https://arxiv.org/abs/2508.18869)
*Jeroen J. de Boer,Agustin O. Alvarez,Moritz C. Schmidt,Dimitrios Sitaridis,Bruno Ehrler*

Main category: cond-mat.mtrl-sci

TL;DR: 基于离子迁移的卤素钙钛光突触，可调光照和电压，具有易失性，支持STDP学习，可用于神经形态视觉处理。


<details>
  <summary>Details</summary>
Motivation: 需要易失性人工突触来检测和处理光输入，最好能集成在同一设备中，以实现高效的视觉数据处理。

Method: 制造了微型背接触光电卤素钙钛人工突触，利用偏压引起的离子迁移来调节光电流。

Result: 光电流变化是由于可移动离子积累产生的瞬态电场引起的，具有秒级的易失性。光电流变化可由电压和光照控制，设备对称，可切换抑制和兴奋功能。通过STDP学习规则更新光电流。仿真表明可作为神经形态检测器的注意力机制。

Conclusion: 该器件的制造工艺兼容CMOS和忆阻器神经形态网络的高密度集成，可实现受大脑启发的节能视觉数据处理。

Abstract: Efficient visual data processing by neuromorphic networks requires volatile
artificial synapses that detect and process light inputs, ideally in the same
device. Here, we demonstrate microscale back-contacted optoelectronic halide
perovskite artificial synapses that leverage ion migration induced by a bias
voltage to modulate their photocurrent. The photocurrent changes are due to the
accumulation of mobile ions, which induces a transient electric field in the
perovskite. The photocurrent changes are volatile, decaying on the order of
seconds. The photocurrent changes can be controlled by both the applied voltage
and illumination. The symmetric device supports changing of the photocurrent
polarity, switching between inhibitory and exhibitory functioning. The
photocurrent can be updated by spike-timing-dependent plasticity
(STDP)-learning rules inspired by biology. We show with simulations how this
could be exploited as an attention mechanism in a neuromorphic detector. Our
fabrication procedure is compatible with high-density integration with CMOS and
memristive neuromorphic networks for energy-efficient visual data processing
inspired by the brain.

</details>


### [336] [3D Strain Field Reconstruction by Inversion of Dynamical Scattering](https://arxiv.org/abs/2508.18897)
*Laura Niermann,Tore Niermann,Chengyu Song,Colin Ophus*

Main category: cond-mat.mtrl-sci

TL;DR: Strain measurement along the electron beam direction is challenging in TEM. This paper presents a method using 4D-STEM to determine 3D strain fields by inverting dynamical diffraction effects, validated with simulations and applied to an AlGaN layer.


<details>
  <summary>Details</summary>
Motivation: Measuring the 3D strain field is crucial for understanding and developing material properties through strain engineering, but strain variations along the electron beam direction are difficult to measure with traditional (S)TEM.

Method: The proposed method utilizes 4D-STEM and involves inverting dynamical diffraction effects that occur due to strain field variations along the beam direction.

Result: The method was tested using simulated data with a known ground truth and successfully applied to an experimental 4D-STEM dataset from an inclined pseudomorphically grown Al$_{0.47}$Ga$_{0.53}$N layer.

Conclusion: The presented 4D-STEM method enables 3D strain field determination, overcoming the challenge of measuring strain along the electron beam direction.

Abstract: Strain governs not only the mechanical response of materials but also their
electronic, optical, and catalytic properties. For this reason, the measurement
of the 3D strain field is crucial for a detailed understanding and for further
developments of material properties through strain engineering. However,
measuring strain variations along the electron beam direction has remained a
major challenge for (scanning-) transmission electron microscopy (S/TEM). In
this article, we present a method for 3D strain field determination using
4D-STEM. The method is based on the inversion of dynamical diffraction effects,
which occur at strain field variations along the beam direction. We test the
method against simulated data with a known ground truth and demonstrate its
application to an experimental 4D-STEM dataset from an inclined
pseudomorphically grown Al$_{0.47}$Ga$_{0.53}$N layer.

</details>


### [337] [A comparative nanotribological investigation on amorphous and polycrystalline forms of MoS2](https://arxiv.org/abs/2508.18923)
*Hesam Khaksar,Prashant Mittal,Nabil Daghbouj,Grzegorz Cios,Tomas Polcar,Enrico Gnecco*

Main category: cond-mat.mtrl-sci

TL;DR: 非晶态 MoS2 的耐磨性优于多晶态 MoS2。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在表征两种非晶态和多晶态 MoS2 的磨损行为，为纳米摩擦学提供信息。

Method: 使用纳米压痕和原子力显微镜研究了两种 MoS2 形式的磨损行为，通过测量磨损轨迹的深度和宽度来分析。

Result: 非晶态 MoS2 的耐磨性大约是多晶态 MoS2 的四倍。两种形式的摩擦力都有所降低，这可能是由于刮擦引起的表面平滑。在纳米尺度上，非晶态 MoS2 的耐磨性也显著优于多晶态 MoS2。

Conclusion: 非晶态 MoS2 在耐磨性方面优于多晶态 MoS2，这为纳米摩擦学提供了新的见解。

Abstract: The wear behavior of two amorphous and polycrystalline forms of MoS2 prepared
by magnetron sputtering has been characterized in a combined nanoindentation
and atomic force microscopy study. From the analysis of the depth and width of
wear tracks estimated after scratching the surfaces with a Berkovich indenter
and a loading force up to 2 mN, we conclude that both forms follow the Archard
wear equation, and the wear resistance is about four times higher on the
amorphous MoS2. Moreover, a comparison of lateral force maps on pristine and
worn areas shows a considerable reduction of friction on both forms, which is
possibly due to the significant smoothing of the surfaces caused by scratching.
With normal forces in the micro N range, the analysis is made difficult by the
fact that the linear dimensions of the wear tracks are comparable to those of
the granular structures forming the surfaces. Even if the Archard equation
could not be tested in this case, the wear resistance is considerably larger on
amorphous MoS2 also on the nanoscale. In this way, our results disclose
information on the nanotribology of MoS2 thin films in forms different from the
layered structures commonly discussed in the literature. The amorphous form
outperforms the polycrystalline one.

</details>


### [338] [Exploring nanoscale metallic multilayer Ta/Cu films: Structure and some insights on deformation and strengthening mechanisms](https://arxiv.org/abs/2508.18928)
*Daniel Karpinski,Tomas Polcar,Andrey Bondarev*

Main category: cond-mat.mtrl-sci

TL;DR: Ta-Cu纳米金属多层膜在纳米尺度上通过软铜层塑性变形，界面有效阻止了位错传播，表现出优异的强化机制。


<details>
  <summary>Details</summary>
Motivation: 研究界面在金属可塑性、变形和强化机制中的作用，特别是纳米金属多层（NMM）薄膜。

Method: 使用磁控溅射制备了具有6至80 nm周期性的Ta-Cu NMM薄膜，并采用高负载压痕测试、透射电子显微镜（TEM）研究和rCLS模型进行分析。

Result: 所有NMM薄膜主要经历塑性变形，塑性变形主要发生在较软的铜层中，而位错穿过不相干界面的传播在很大程度上被阻止。

Conclusion: Ta-Cu NMM薄膜的强化机制在于软铜层中的塑性变形以及界面对位错传播的有效阻碍。

Abstract: Nanoscale metallic multilayer (NMM) films are systems offering insight into
the role of interfaces in metal plasticity, deformation, and strengthening
mechanisms. Magnetron sputtering was used to fabricate the Ta-Cu NMM films with
a periodicity (equal Ta and Cu layer thickness) from 6 to 80 nm, with resulting
structure exhibiting strongly incoherent tetragonal beta-Ta and face-centered
cubic Cu phase. The high-load indentation test, TEM studies, and the rCLS model
collectively demonstrate that all NMM films predominantly undergo plastic
deformation. This plastic deformation primarily occurs within the soft Cu
layer, while the propagation of dislocations across the incoherent interface is
largely excluded.

</details>


### [339] [On the role played by electrons in the stress-strain curves of ideal crystalline solids](https://arxiv.org/abs/2508.19043)
*Margherita Marsili,Elisa Damiani,Davide Dalle Ave,Gabriele Losi,M. Clelia Righi*

Main category: cond-mat.mtrl-sci

TL;DR: 电子性质影响固体的机械性能，特别是在铜和铝中。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究电子电荷如何响应单轴应变并影响晶体固体的机械性能，重点关注密度泛函理论和热力学分析。

Method: 采用密度泛函理论和热力学分析来研究电子电荷如何响应单轴应变并影响晶体（铜、铝和金刚石）的机械性能。

Result: 研究发现在铜和铝中，即使在原子位移很小的情况下，应力-应变曲线也偏离了简单的线性弹性行为。这些特征可以通过与电子态密度中的范霍夫奇点以及电子重新分布相关的相变来解释。

Conclusion: 铜和铝的应力-应变曲线行为可以通过电子性质和相变来解释，这表明电子电荷在固体的机械性能中起着重要作用。

Abstract: The mechanical properties of a solid, which relate its deformation to
external applied forces, are key factors in enabling or disabling the use of an
otherwise optimal material in any application, strongly influencing also its
service lifetime. Intrinsic crystal deformation mechanisms, investigated
experimentally on single crystals with low dislocation densities, have been
studied theoretically through atomistic simulations, mainly focusing on
lattice-induced instabilities. Here, instead, we employ density functional
theory and a thermodynamic analysis to probe and analyze the way in which the
electronic charge of crystalline solids (Cu, Al and diamond) responds to
uniaxial strain and affects their mechanical properties. Indeed, despite the
very simple nature of our models, and in the presence of minimal atomic
displacements, we find that the stress strain curves of Cu and Al deviate from
a simple linear elastic behavior. Within a thermodynamics perspective, the
features of such curves can be interpreted in terms of first and second order
phase transitions. Within a thermodynamics perspective, the features of such
curves can be interpreted in terms of first and second order phase transitions,
which originate from Van-Hove singularities of the electronic density of states
crossing the Fermi level and electron redistribution within the solid,
respectively.

</details>


### [340] [Alloyed cementite (Fe-Ni-Cr)$_3$C: structure and hyperfine field from DFT calculations and experimental comparison](https://arxiv.org/abs/2508.19148)
*Lyudmila V. Dobysheva*

Main category: cond-mat.mtrl-sci

TL;DR: 合金元素（Ni和Cr）掺杂对碳钢渗碳体（Fe3C）的影响。


<details>
  <summary>Details</summary>
Motivation: 碳钢中合金元素对渗碳体特性的影响及其对钢整体性能的影响。

Method: 使用密度泛函理论（DFT）计算，研究Ni和Cr掺杂对渗碳体的影响，确定杂质原子的晶格位点，研究超精细磁场（HFF）的形成机制及其与原子磁矩的关系，评估Mössbauer谱分析的近似有效性，并对HFF分布函数进行建模。

Result: 确定了Ni和Cr在渗碳体中的优先晶格位点，研究了HFF的形成机制和与原子磁矩的关系，评估了Mössbauer谱分析的近似有效性，并对HFF分布函数进行了建模。

Conclusion: DFT计算可以有效研究合金元素对渗碳体的影响，为理解和预测钢的性能提供了理论基础。

Abstract: The alloying elements introduced into carbon steel to enhance its mechanical
properties also diffuse into cementite (Fe$_3$C) particles, modifying their
characteristics and thereby influencing the overall performance of the steel.
This study employs density functional theory (DFT) calculations to investigate
cementite doped with Ni and Cr which exhibit contrasting effects. The preferred
lattice sites of impurity atoms were determined through a comparison of
calculated and experimental structural parameters. The formation mechanism of
the hyperfine magnetic field (HFF) and its correlation with atomic magnetic
moments were systematically investigated. The validity of common approximations
in M\"ossbauer spectroscopy analysis was evaluated for the cementite system.
HFF distribution functions were modeled using calculated values and compared
with experiments.

</details>


### [341] [MC3D: The Materials Cloud computational database of experimentally known stoichiometric inorganics](https://arxiv.org/abs/2508.19223)
*Sebastiaan P. Huber,Michail Minotakis,Marnik Bercx,Timo Reents,Kristjan Eimre,Nataliya Paulish,Nicolas Hörmann,Martin Uhrin,Nicola Marzari,Giovanni Pizzi*

Main category: cond-mat.mtrl-sci

TL;DR: MC3D是一个包含近百万个实验性无机晶体结构的在线数据库，其中72589个是独特的化学计量结构。其中95%的结构已被实验证实。该数据库使用DFT方法优化了多达64个原子的结构几何，并通过自动化工作流和输入协议进行了处理。


<details>
  <summary>Details</summary>
Motivation: MC3D旨在提供一个在线数据库，收集和优化计算得到的无机晶体结构，为材料科学研究提供宝贵的起点。

Method: 该研究从COD、ICSD和MPDS数据库导入了近百万个实验报告的结构，经过解析和筛选，得到了72589个独特的化学计量结构。使用DFT方法优化了多达64个原子的结构几何，并对不同泛函和计算协议重复了该过程，最新版本MC3D PBEsol-v2包含了32013个独特的结构。

Result: MC3D数据库提供了32013个独特的结构，这些结构都经过了DFT计算优化，并且具有完整的计算溯源信息，确保了结果的可复现性。

Conclusion: MC3D数据库通过提供一个包含大量优化后的无机晶体结构及其完整计算溯源信息的在线平台，促进了材料科学的研究和可复现性。

Abstract: DFT is a widely used method to compute properties of materials, which are
often collected in databases and serve as valuable starting points for further
studies. In this article, we present the Materials Cloud Three-Dimensional
Structure Database (MC3D), an online database of computed three-dimensional
(3D) inorganic crystal structures. Close to a million experimentally reported
structures were imported from the COD, ICSD and MPDS databases; these were
parsed and filtered to yield a collection of 72589 unique and stoichiometric
structures, of which 95% are, to date, classified as experimentally known. The
geometries of structures with up to 64 atoms were then optimized using
density-functional theory (DFT) with automated workflows and curated input
protocols. The procedure was repeated for different functionals (and
computational protocols), with the latest version (MC3D PBEsol-v2) comprising
32013 unique structures. All versions of the MC3D are made available on the
Materials Cloud portal, which provides a graphical interface to explore and
download the data. The database includes the full provenance graph of all the
calculations driven by the automated workflows, thus establishing full
reproducibility of the results and more-than-FAIR procedures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [342] [Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](https://arxiv.org/abs/2508.18397)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 本研究提出并比较了用于离线强化学习（RL）的多种数据策展策略，以解决自动驾驶（AV）规划策略训练中数据不平衡的问题，特别是长尾事件的稀疏性。研究表明，数据驱动的策展方法，特别是基于模型不确定性的方法，能显著提高安全性，将碰撞率降低近三倍。


<details>
  <summary>Details</summary>
Motivation: 解决离线强化学习（RL）在自动驾驶（AV）策略训练中，由于数据不平衡（尤其是长尾事件稀疏）导致的策略脆弱和不安全问题。

Method: 通过系统性的大规模比较研究，评估了六种不同的关键性加权方案（包括启发式、不确定性和行为驱动）在时间步和完整场景两个时间尺度上的有效性。使用七个目标条件保守Q学习（CQL）代理，并在Waymax模拟器中进行评估。

Result: 所有数据策展方法均显著优于基线方法。基于模型不确定性的数据驱动策展在提高安全性方面效果最显著，碰撞率从16.0%降至5.5%。时间步级别加权在反应式安全方面表现更好，而场景级别加权在长期规划方面更优。

Conclusion: 智能的、非均匀采样是构建安全可靠的自动驾驶代理的关键组成部分。本研究提供了一个全面的数据策展框架，强调了在离线RL中采用智能采样策略的重要性。

Abstract: Offline Reinforcement Learning (RL) presents a promising paradigm for
training autonomous vehicle (AV) planning policies from large-scale, real-world
driving logs. However, the extreme data imbalance in these logs, where mundane
scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe
policies when using standard uniform data sampling. In this work, we address
this challenge through a systematic, large-scale comparative study of data
curation strategies designed to focus the learning process on information-rich
samples. We investigate six distinct criticality weighting schemes which are
categorized into three families: heuristic-based, uncertainty-based, and
behavior-based. These are evaluated at two temporal scales, the individual
timestep and the complete scenario. We train seven goal-conditioned
Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based
architecture and evaluate them in the high-fidelity Waymax simulator. Our
results demonstrate that all data curation methods significantly outperform the
baseline. Notably, data-driven curation using model uncertainty as a signal
achieves the most significant safety improvements, reducing the collision rate
by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear
trade-off where timestep-level weighting excels at reactive safety while
scenario-level weighting improves long-horizon planning. Our work provides a
comprehensive framework for data curation in Offline RL and underscores that
intelligent, non-uniform sampling is a critical component for building safe and
reliable autonomous agents.

</details>


### [343] [Maintenance automation: methods for robotics manipulation planning and execution](https://arxiv.org/abs/2508.18399)
*Christian Friedrich,Ralf Gulde,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 该论文提出了一个用于维护自动化的完整机器人系统，该系统能够处理环境不确定性下的拆卸和组装任务。


<details>
  <summary>Details</summary>
Motivation: 实现自动化复杂任务的机器人系统需要具备规划、控制和执行能力。本文旨在提出一个能自动化处理包含环境不确定性的拆卸和组装操作的机器人系统。

Method: 该系统基于规划方法，利用CAD和RGBD数据，能够解析符号化规划并将其转换为可执行的机器人指令。

Result: 该系统已通过真实世界的应用进行了实验评估。

Conclusion: 这项工作是向实际机器人解决方案转移理论研究成果的第一步。

Abstract: Automating complex tasks using robotic systems requires skills for planning,
control and execution. This paper proposes a complete robotic system for
maintenance automation, which can automate disassembly and assembly operations
under environmental uncertainties (e.g. deviations between prior plan
information). The cognition of the robotic system is based on a planning
approach (using CAD and RGBD data) and includes a method to interpret a
symbolic plan and transform it to a set of executable robot instructions. The
complete system is experimentally evaluated using real-world applications. This
work shows the first step to transfer these theoretical results into a
practical robotic solution.

</details>


### [344] [Efficient task and path planning for maintenance automation using a robot system](https://arxiv.org/abs/2508.18400)
*Christian Friedrich,Akos Csiszar,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 本论文提出了一种用于工厂维护自动化任务的自主机器人系统方法，该方法结合了CAD离线数据和RGBD视觉在线数据，并通过概率滤波器来补偿不确定性。该方法还利用符号描述和新颖的基于采样的技术来计算拆卸空间，并结合自适应步长的路径规划算法来减少规划时间。


<details>
  <summary>Details</summary>
Motivation: 工厂的未来在于智能自动化解决方案的研发，其中自主机器人系统在维护领域的应用是一个充满挑战的任务。机器人系统需要能够自主规划操作任务和相应的路径，同时需要低计算复杂度的算法来应对环境不确定性。

Method: 本研究提出了一种结合CAD离线数据和RGBD视觉在线数据的方法，并通过概率滤波器来补偿CAD数据的不足。在任务规划方面，采用了基于符号描述和新颖的基于采样的技术来计算拆卸空间。在路径规划方面，采用了全局前沿算法，并允许自适应地调整探索步长以减少规划时间。

Result: 文中提到的各种方法都经过了实验验证和讨论。

Conclusion: 本研究提出的方法为解决维护自动化问题提供了一种有效途径，通过结合离线和在线数据以及优化的规划算法，提高了机器人在不确定环境下的自主性和效率。

Abstract: The research and development of intelligent automation solutions is a
ground-breaking point for the factory of the future. A promising and
challenging mission is the use of autonomous robot systems to automate tasks in
the field of maintenance. For this purpose, the robot system must be able to
plan autonomously the different manipulation tasks and the corresponding paths.
Basic requirements are the development of algorithms with a low computational
complexity and the possibility to deal with environmental uncertainties. In
this work, an approach is presented, which is especially suited to solve the
problem of maintenance automation. For this purpose, offline data from CAD is
combined with online data from an RGBD vision system via a probabilistic
filter, to compensate uncertainties from offline data. For planning the
different tasks, a method is explained, which use a symbolic description,
founded on a novel sampling-based method to compute the disassembly space. For
path planning we use global state-of-the art algorithms with a method that
allows the adaption of the exploration stepsize in order to reduce the planning
time. Every method is experimentally validated and discussed.

</details>


### [345] [PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing](https://arxiv.org/abs/2508.18443)
*Ruohan Zhang,Uksang Yoo,Yichen Li,Arpit Argawal,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的基于视觉的软体机器人传感方法，并以PneuGelSight为实例进行了演示，PneuGelSight是一种内置摄像头、具有高分辨率本体感觉和触觉传感功能的新型气动机械臂。


<details>
  <summary>Details</summary>
Motivation: 为了在真实场景中部署软体机器人，需要先进的触觉和本体感觉传感技术。

Method: 提出了一种新颖的基于视觉的软体机器人传感方法，并介绍了用于优化传感器性能的仿真流程，实现了从仿真到现实世界的零样本知识迁移。

Result: 开发了PneuGelSight，一种集成了高分辨率本体感觉和触觉传感功能的新型气动机械臂。

Conclusion: PneuGelSight和仿真到现实的流程提供了一种新颖、易于实现且鲁棒的软体机器人传感方法，为开发具有增强传感能力的高级软体机器人铺平了道路。

Abstract: Soft pneumatic robot manipulators are popular in industrial and
human-interactive applications due to their compliance and flexibility.
However, deploying them in real-world scenarios requires advanced sensing for
tactile feedback and proprioception. Our work presents a novel vision-based
approach for sensorizing soft robots. We demonstrate our approach on
PneuGelSight, a pioneering pneumatic manipulator featuring high-resolution
proprioception and tactile sensing via an embedded camera. To optimize the
sensor's performance, we introduce a comprehensive pipeline that accurately
simulates its optical and dynamic properties, facilitating a zero-shot
knowledge transition from simulation to real-world applications. PneuGelSight
and our sim-to-real pipeline provide a novel, easily implementable, and robust
sensing methodology for soft robots, paving the way for the development of more
advanced soft robots with enhanced sensory capabilities.

</details>


### [346] [Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models](https://arxiv.org/abs/2508.18460)
*Tianze Liu,Md Abu Bakr Siddique,Hongyu An*

Main category: cs.RO

TL;DR: AI在认知任务中表现出色，但需要大量数据和高能耗，限制了其在SWaP约束应用中的发展。本文提出通过模仿动物的联想学习来增强智能机器人的自主能力，使其能够在动态环境中学习和优化。通过模拟啮齿动物的联想学习，并结合空间细胞（如位置细胞和网格细胞）的见解，我们旨在为机器人实现实时空间任务的在线联想学习，以推动自主系统的发展。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的AI方法虽然在认知任务中表现出色，但其对大量数据和神经网络的依赖带来了高能耗和适应性有限的挑战，尤其是在行星探索等SWaP（尺寸、重量和功率）受限的应用中。为了克服这些挑战，本文旨在通过模仿动物的联想学习机制来增强智能机器人的自主能力。

Method: 本文提出通过模拟啮齿动物（如老鼠）的联想学习机制来增强机器人的自主导航能力。研究利用了空间细胞（例如位置细胞和网格细胞）的见解，并在开放式迷宫环境中进行了实验。通过集成这些模型，旨在实现机器人在线联想学习，以应对实时空间任务。

Result: 通过在开放式迷宫环境中模拟啮齿动物的联想学习，并整合空间细胞模型，我们能够使神经形态机器人能够从交互中学习，从而在动态环境中自主导航并优化性能。这使得实时空间任务的在线联想学习成为可能。

Conclusion: 本文成功展示了通过模仿动物联想学习机制来增强机器人自主能力的方法。通过集成空间细胞的概念，我们为机器人实现了实时在线联想学习，为在SWaP受限环境（如行星探索）中的高级自主应用铺平了道路，并弥合了生物空间认知与机器人技术之间的差距。

Abstract: Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable
prowess across various cognitive tasks using extensive training data. However,
the reliance on large datasets and neural networks presents challenges such as
highpower consumption and limited adaptability, particularly in
SWaP-constrained applications like planetary exploration. To address these
issues, we propose enhancing the autonomous capabilities of intelligent robots
by emulating the associative learning observed in animals. Associative learning
enables animals to adapt to their environment by memorizing concurrent events.
By replicating this mechanism, neuromorphic robots can navigate dynamic
environments autonomously, learning from interactions to optimize performance.
This paper explores the emulation of associative learning in rodents using
neuromorphic robots within open-field maze environments, leveraging insights
from spatial cells such as place and grid cells. By integrating these models,
we aim to enable online associative learning for spatial tasks in real-time
scenarios, bridging the gap between biological spatial cognition and robotics
for advancements in autonomous systems.

</details>


### [347] [SignLoc: Robust Localization using Navigation Signs and Public Maps](https://arxiv.org/abs/2508.18606)
*Nicky Zimmerman,Joel Loo,Ayush Agrawal,David Hsu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Navigation signs and maps, such as floor plans and street maps, are widely
available and serve as ubiquitous aids for way-finding in human environments.
Yet, they are rarely used by robot systems. This paper presents SignLoc, a
global localization method that leverages navigation signs to localize the
robot on publicly available maps -- specifically floor plans and OpenStreetMap
(OSM) graphs -- without prior sensor-based mapping. SignLoc first extracts a
navigation graph from the input map. It then employs a probabilistic
observation model to match directional and locational cues from the detected
signs to the graph, enabling robust topo-semantic localization within a Monte
Carlo framework. We evaluated SignLoc in diverse large-scale environments: part
of a university campus, a shopping mall, and a hospital complex. Experimental
results show that SignLoc reliably localizes the robot after observing only one
to two signs.

</details>


### [348] [Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning](https://arxiv.org/abs/2508.18627)
*Ziyuan Jiao,Yida Niu,Zeyu Zhang,Yangyang Wu,Yao Su,Yixin Zhu,Hangxin Liu,Song-Chun Zhu*

Main category: cs.RO

TL;DR: 该论文提出了一个序列化移动操作规划（SMMP）框架，用于解决带有协调全身运动的长期多步移动操作任务，即使在与铰接式物体交互时也能解决。


<details>
  <summary>Details</summary>
Motivation: 提出SMMP框架以解决长时序多步移动操作任务，特别是涉及铰接式物体和协调全身运动的场景。

Method: 将环境结构抽象为运动学模型并与机器人运动学集成，构建增强配置空间（A-Space），该空间统一了导航和操作任务的约束，并考虑了机器人基座、手臂和被操作物体的联合可达性。该框架采用三层规划：任务规划器生成符号动作序列，基于优化的运动规划器计算A-Space内的连续轨迹，中间规划细化阶段选择可行的动作目标。

Result: 在模拟研究中，与基线方法相比，在A-Space中规划可将任务成功率提高84.6%。在真实机器人系统上的验证展示了涉及7种刚性和铰接式物体（跨越17种不同场景）以及长达14个连续步骤的任务的流畅移动操作。

Conclusion: 通过将场景运动学建模为规划实体，而不是硬编码特定于任务的约束，SMMP提供了一种可扩展且可泛化的复杂机器人操作方法。

Abstract: We present a Sequential Mobile Manipulation Planning (SMMP) framework that
can solve long-horizon multi-step mobile manipulation tasks with coordinated
whole-body motion, even when interacting with articulated objects. By
abstracting environmental structures as kinematic models and integrating them
with the robot's kinematics, we construct an Augmented Configuration Apace
(A-Space) that unifies the previously separate task constraints for navigation
and manipulation, while accounting for the joint reachability of the robot
base, arm, and manipulated objects. This integration facilitates efficient
planning within a tri-level framework: a task planner generates symbolic action
sequences to model the evolution of A-Space, an optimization-based motion
planner computes continuous trajectories within A-Space to achieve desired
configurations for both the robot and scene elements, and an intermediate plan
refinement stage selects action goals that ensure long-horizon feasibility. Our
simulation studies first confirm that planning in A-Space achieves an 84.6\%
higher task success rate compared to baseline methods. Validation on real
robotic systems demonstrates fluid mobile manipulation involving (i) seven
types of rigid and articulated objects across 17 distinct contexts, and (ii)
long-horizon tasks of up to 14 sequential steps. Our results highlight the
significance of modeling scene kinematics into planning entities, rather than
encoding task-specific constraints, offering a scalable and generalizable
approach to complex robotic manipulation.

</details>


### [349] [DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning](https://arxiv.org/abs/2508.19114)
*Alkesh K. Srivastava,Jared Michael Levin,Alexander Derrico,Philip Dames*

Main category: cs.RO

TL;DR: DELIVER是一个集成的多机器人协作拾取和交付框架，通过自然语言指令驱动，实现了可扩展、无碰撞的协调。


<details>
  <summary>Details</summary>
Motivation: 为了实现由自然语言指令驱动的多机器人协作拾取和交付，并解决可扩展、无碰撞协调的问题。

Method: DELIVER框架集成了自然语言理解、空间分解、中继规划和运动执行。它使用LLaMA3解释指令，通过Voronoi图划分环境，计算中继点，并使用有限状态机管理机器人行为。

Result: DELIVER框架在模拟和真实硬件上进行了实现和验证。实验结果表明，该框架在不同团队规模下能保持一致的任务成本，并将每代理人的工作量最多减少55%。随着团队规模的增加，活跃中继代理的数量保持较低水平，显示了系统的可扩展性和高效的代理利用率。

Conclusion: DELIVER框架的模块化和可扩展架构能够实现语言引导的多机器人协调，推动了信息物理系统集成的发展。

Abstract: We present DELIVER (Directed Execution of Language-instructed Item Via
Engineered Relay), a fully integrated framework for cooperative multi-robot
pickup and delivery driven by natural language commands. DELIVER unifies
natural language understanding, spatial decomposition, relay planning, and
motion execution to enable scalable, collision-free coordination in real-world
settings. Given a spoken or written instruction, a lightweight instance of
LLaMA3 interprets the command to extract pickup and delivery locations. The
environment is partitioned using a Voronoi tessellation to define
robot-specific operating regions. Robots then compute optimal relay points
along shared boundaries and coordinate handoffs. A finite-state machine governs
each robot's behavior, enabling robust execution. We implement DELIVER on the
MultiTRAIL simulation platform and validate it in both ROS2-based Gazebo
simulations and real-world hardware using TurtleBot3 robots. Empirical results
show that DELIVER maintains consistent mission cost across varying team sizes
while reducing per-agent workload by up to 55% compared to a single-agent
system. Moreover, the number of active relay agents remains low even as team
size increases, demonstrating the system's scalability and efficient agent
utilization. These findings underscore DELIVER's modular and extensible
architecture for language-guided multi-robot coordination, advancing the
frontiers of cyber-physical system integration.

</details>


### [350] [Engineering Automotive Digital Twins on Standardized Architectures: A Case Study](https://arxiv.org/abs/2508.18662)
*Stefan Ramdhan,Winnie Trandinh,Istvan David,Vera Pantelic,Mark Lawford*

Main category: cs.RO

TL;DR: 该论文研究了ISO 23247参考架构在汽车数字孪生（DT）开发中的适用性，通过一个自适应巡航控制DT的案例研究，识别了该架构的优缺点，并为未来研究和标准化提供了方向。


<details>
  <summary>Details</summary>
Motivation: 汽车行业对利用数字孪生（DT）技术开发智能服务的需求日益增长，但目前缺乏相应的架构指南，ISO 23247是为数不多的可行起点。

Method: 通过开发一个1/10比例的自动驾驶车辆的自适应巡航控制DT案例研究，评估ISO 23247参考架构的适用性。

Result: 研究发现ISO 23247参考架构在汽车DT开发中具有一定的优势和局限性。

Conclusion: ISO 23247参考架构为汽车DT开发提供了一个起点，但仍需进一步改进以满足汽车行业的特定需求。

Abstract: Digital twin (DT) technology has become of interest in the automotive
industry. There is a growing need for smarter services that utilize the unique
capabilities of DTs, ranging from computer-aided remote control to cloud-based
fleet coordination. Developing such services starts with the software
architecture. However, the scarcity of DT architectural guidelines poses a
challenge for engineering automotive DTs. Currently, the only DT architectural
standard is the one defined in ISO 23247. Though not developed for automotive
systems, it is one of the few feasible starting points for automotive DTs. In
this work, we investigate the suitability of the ISO 23247 reference
architecture for developing automotive DTs. Through the case study of
developing an Adaptive Cruise Control DT for a 1/10\textsuperscript{th}-scale
autonomous vehicle, we identify some strengths and limitations of the reference
architecture and begin distilling future directions for researchers,
practitioners, and standard developers.

</details>


### [351] [Deep Sensorimotor Control by Imitating Predictive Models of Human Motion](https://arxiv.org/abs/2508.18691)
*Himanshu Gaurav Singh,Pieter Abbeel,Jitendra Malik,Antonio Loquercio*

Main category: cs.RO

TL;DR: 模仿人类运动预测模型来训练机器人策略，实现了跨机器人任务的零样本迁移，并超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和人类之间在具身智能方面的差距不断缩小，利用人类与环境交互的数据集进行机器人学习带来了新的机遇。

Method: 提出了一种通过模仿预测人类运动的模型来使用强化学习训练传感运动策略的新技术。通过预测人类数据的未来运动，该模型可以直接应用于机器人数据（零样本迁移），而无需梯度下降的运动学重定向和对抗性损失。

Result: 该方法在机器人和任务之间表现良好，并且在操纵任务中可以替代精心设计的密集奖励和课程。

Conclusion: 模仿人类运动预测模型可以作为一种有效的训练方法，可以替代传统的奖励和课程设计，并且可以跨越不同的机器人和任务。

Abstract: As the embodiment gap between a robot and a human narrows, new opportunities
arise to leverage datasets of humans interacting with their surroundings for
robot learning. We propose a novel technique for training sensorimotor policies
with reinforcement learning by imitating predictive models of human motions.
Our key insight is that the motion of keypoints on human-inspired robot
end-effectors closely mirrors the motion of corresponding human body keypoints.
This enables us to use a model trained to predict future motion on human data
\emph{zero-shot} on robot data. We train sensorimotor policies to track the
predictions of such a model, conditioned on a history of past robot states,
while optimizing a relatively sparse task reward. This approach entirely
bypasses gradient-based kinematic retargeting and adversarial losses, which
limit existing methods from fully leveraging the scale and diversity of modern
human-scene interaction datasets. Empirically, we find that our approach can
work across robots and tasks, outperforming existing baselines by a large
margin. In addition, we find that tracking a human motion model can substitute
for carefully designed dense rewards and curricula in manipulation tasks. Code,
data and qualitative results available at
https://jirl-upenn.github.io/track_reward/.

</details>


### [352] [AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot](https://arxiv.org/abs/2508.18694)
*Jaehwan Jeong,Tuan-Anh Vu,Mohammad Jony,Shahab Ahmad,Md. Mukhlesur Rahman,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 该研究提出了AgriChrono，一个用于农业环境的机器人数据收集平台和多模态数据集，以解决现有数据集在动态性和多样性方面的不足，并评估了3D重建模型在真实田间环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有农业数据集多在静态或受控环境（如室内实验室或温室）中收集，传感器多样性有限且时间跨度短，无法反映真实农田的动态性（如光照变化、作物生长变异、自然干扰），导致在实际应用中模型鲁棒性和泛化能力不足。

Method: 开发了一个名为AgriChrono的新型机器人数据收集平台，集成了多种传感器（RGB、深度、LiDAR、IMU），能够远程、时间同步地采集数据，支持在不同的光照和作物生长阶段进行长期、高效、可重复的数据收集。并使用该数据集对一系列先进的3D重建模型进行了基准测试。

Result: 在AgriChrono数据集上对一系列先进的3D重建模型进行了基准测试，突显了在真实田野环境中进行重建的挑战，并证明了该数据集作为研究资产在提高模型在动态条件下的泛化能力方面的价值。

Conclusion: AgriChrono数据集和平台为解决现有农业数据集的局限性提供了新的解决方案，并通过基准测试证明了其在评估和改进3D重建模型在真实、动态农业环境中的性能方面的有效性。

Abstract: Existing datasets for precision agriculture have primarily been collected in
static or controlled environments such as indoor labs or greenhouses, often
with limited sensor diversity and restricted temporal span. These conditions
fail to reflect the dynamic nature of real farmland, including illumination
changes, crop growth variation, and natural disturbances. As a result, models
trained on such data often lack robustness and generalization when applied to
real-world field scenarios. In this paper, we present AgriChrono, a novel
robotic data collection platform and multi-modal dataset designed to capture
the dynamic conditions of real-world agricultural environments. Our platform
integrates multiple sensors and enables remote, time-synchronized acquisition
of RGB, Depth, LiDAR, and IMU data, supporting efficient and repeatable
long-term data collection across varying illumination and crop growth stages.
We benchmark a range of state-of-the-art 3D reconstruction models on the
AgriChrono dataset, highlighting the difficulty of reconstruction in real-world
field environments and demonstrating its value as a research asset for
advancing model generalization under dynamic conditions. The code and dataset
are publicly available at: https://github.com/StructuresComp/agri-chrono

</details>


### [353] [Enhancing Video-Based Robot Failure Detection Using Task Knowledge](https://arxiv.org/abs/2508.18705)
*Santosh Thoduka,Sebastian Houben,Juergen Gall,Paul G. Plöger*

Main category: cs.RO

TL;DR: 该研究提出了一种基于视频的机器人任务失败检测方法，利用动作和物体时空信息，并在真实场景中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 机器人任务执行的鲁棒性依赖于对执行失败的可靠检测，以触发安全操作模式、恢复策略或任务重新规划。然而，许多失败检测方法在应用于各种真实场景时，性能往往不佳。

Method: 提出一种基于视频的失败检测方法，利用动作和任务相关物体within the field of view（视野内）的时空信息。

Result: 在改进的三个数据集上验证了该方法的有效性，并提出了一种数据增强方法（对视频不同部分应用可变帧率），在ARMBench数据集上F1分数从77.9提高到80.0，使用测试时增强后进一步提高到81.4。

Conclusion: 结果强调了时空信息在失败检测中的重要性，并建议未来研究中进一步探索合适的方法。

Abstract: Robust robotic task execution hinges on the reliable detection of execution
failures in order to trigger safe operation modes, recovery strategies, or task
replanning. However, many failure detection methods struggle to provide
meaningful performance when applied to a variety of real-world scenarios. In
this paper, we propose a video-based failure detection approach that uses
spatio-temporal knowledge in the form of the actions the robot performs and
task-relevant objects within the field of view. Both pieces of information are
available in most robotic scenarios and can thus be readily obtained. We
demonstrate the effectiveness of our approach on three datasets that we amend,
in part, with additional annotations of the aforementioned task-relevant
knowledge. In light of the results, we also propose a data augmentation method
that improves performance by applying variable frame rates to different parts
of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the
ARMBench dataset without additional computational expense and an additional
increase to 81.4 with test-time augmentation. The results emphasize the
importance of spatio-temporal information during failure detection and suggest
further investigation of suitable heuristics in future implementations. Code
and annotations are available.

</details>


### [354] [HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation](https://arxiv.org/abs/2508.18802)
*Li Sun,Jiefeng Wu,Feng Chen,Ruizhe Liu,Yanchao Yang*

Main category: cs.RO

TL;DR: HyperTASR是一个超网络驱动的框架，通过根据任务目标和执行阶段调整场景表示来改进机器人操作策略学习。


<details>
  <summary>Details</summary>
Motivation: 需要能够动态适应任务和执行阶段的场景表示，以实现有效的机器人操作策略学习，而当前的方法未能实现这一点。

Method: 提出了一种名为HyperTASR的框架，该框架使用超网络根据任务规范和进展状态动态生成表示转换参数，从而在任务执行过程中使表示能够上下文演变。它在任务上下文和状态相关处理路径之间建立了计算分离。

Result: 在模拟和真实世界环境中进行了广泛的评估，结果显示在不同的表示范例中性能得到了显著提高。消融研究和注意力可视化证实了该方法优先处理任务相关的场景信息，类似于人类在操作任务中的适应性感知。

Conclusion: HyperTASR通过动态调整场景表示来改进机器人操作策略学习，在模拟和真实世界环境中都显示出优越的性能，并能像人类一样优先处理相关信息。

Abstract: Effective policy learning for robotic manipulation requires scene
representations that selectively capture task-relevant environmental features.
Current approaches typically employ task-agnostic representation extraction,
failing to emulate the dynamic perceptual adaptation observed in human
cognition. We present HyperTASR, a hypernetwork-driven framework that modulates
scene representations based on both task objectives and the execution phase.
Our architecture dynamically generates representation transformation parameters
conditioned on task specifications and progression state, enabling
representations to evolve contextually throughout task execution. This approach
maintains architectural compatibility with existing policy learning frameworks
while fundamentally reconfiguring how visual features are processed. Unlike
methods that simply concatenate or fuse task embeddings with task-agnostic
representations, HyperTASR establishes computational separation between
task-contextual and state-dependent processing paths, enhancing learning
efficiency and representational quality. Comprehensive evaluations in both
simulation and real-world environments demonstrate substantial performance
improvements across different representation paradigms. Through ablation
studies and attention visualization, we confirm that our approach selectively
prioritizes task-relevant scene information, closely mirroring human adaptive
perception during manipulation tasks. The project website is at
\href{https://lisunphil.github.io/HyperTASR_projectpage/}{lisunphil.github.io/HyperTASR\_projectpage}.

</details>


### [355] [Learning Real-World Acrobatic Flight from Human Preferences](https://arxiv.org/abs/2508.18817)
*Colin Merk,Ismail Geles,Jiaxu Xing,Angel Romero,Giorgia Ramponi,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本研究利用基于偏好的强化学习（PbRL）技术，通过提出奖励集成置信度（REC）方法，在模拟和现实世界中实现了敏捷的无人机控制，包括复杂的特技机动，其性能优于标准偏好PPO，并能更好地捕捉人类偏好。


<details>
  <summary>Details</summary>
Motivation: 由于难以形式化或主观固有的目标，传统的奖励函数设计对于杂技飞行等复杂动态任务存在挑战。PbRL提供了一种无需手动设计奖励函数即可实现学习控制策略的方法。

Method: 在偏好PPO的基础上，提出奖励集成置信度（REC）方法，扩展了奖励学习目标，以提高偏好建模和学习稳定性。在模拟中训练策略，并成功迁移到真实无人机上。

Result: REC方法达到了规定奖励性能的88.4%，而标准偏好PPO仅为55.2%。在真实无人机上成功演示了多种特技机动。在MuJoCo环境中展示了概率奖励模型的适用性。手动设计的奖励与人类偏好的吻合度仅为60.7%。

Conclusion: PbRL在捕捉跨物理和模拟领域的复杂、以人为中心的客观方面方面是有效的，优于手动设计的奖励方法。

Abstract: Preference-based reinforcement learning (PbRL) enables agents to learn
control policies without requiring manually designed reward functions, making
it well-suited for tasks where objectives are difficult to formalize or
inherently subjective. Acrobatic flight poses a particularly challenging
problem due to its complex dynamics, rapid movements, and the importance of
precise execution. In this work, we explore the use of PbRL for agile drone
control, focusing on the execution of dynamic maneuvers such as powerloops.
Building on Preference-based Proximal Policy Optimization (Preference PPO), we
propose Reward Ensemble under Confidence (REC), an extension to the reward
learning objective that improves preference modeling and learning stability.
Our method achieves 88.4% of the shaped reward performance, compared to 55.2%
with standard Preference PPO. We train policies in simulation and successfully
transfer them to real-world drones, demonstrating multiple acrobatic maneuvers
where human preferences emphasize stylistic qualities of motion. Furthermore,
we demonstrate the applicability of our probabilistic reward model in a
representative MuJoCo environment for continuous control. Finally, we highlight
the limitations of manually designed rewards, observing only 60.7% agreement
with human preferences. These results underscore the effectiveness of PbRL in
capturing complex, human-centered objectives across both physical and simulated
domains.

</details>


### [356] [AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy](https://arxiv.org/abs/2508.18820)
*Christian Henkel,Marco Lampacrescia,Michaela Klauck,Matteo Morelli*

Main category: cs.RO

TL;DR: 本研究提出一种使用统计模型检查（SMC）在设计时验证自主机器人系统属性的新方法。


<details>
  <summary>Details</summary>
Motivation: 在不可预见的环 境中自主运行机器人系统具有挑战性，本研究旨在解决此问题。

Method: 通过扩展SCXML格式来模拟包含ROS 2和BT特性的系统组件，并提出AS2FM工具将系统模型转换为JANI，以便使用SMC工具进行验证。

Result: 成功识别了一个基于ROS 2的机器人操作用例中的问题，并能在消费级硬件上于一秒内完成验证，且验证时间与模型尺寸呈线性扩展。

Conclusion: 本研究提出的方法比现有技术更全面地支持系统功能，验证效率高，适用于实际的自主机器人控制系统。

Abstract: Designing robotic systems to act autonomously in unforeseen environments is a
challenging task. This work presents a novel approach to use formal
verification, specifically Statistical Model Checking (SMC), to verify system
properties of autonomous robots at design-time. We introduce an extension of
the SCXML format, designed to model system components including both Robot
Operating System 2 (ROS 2) and Behavior Tree (BT) features. Further, we
contribute Autonomous Systems to Formal Models (AS2FM), a tool to translate the
full system model into JANI. The use of JANI, a standard format for
quantitative model checking, enables verification of system properties with
off-the-shelf SMC tools. We demonstrate the practical usability of AS2FM both
in terms of applicability to real-world autonomous robotic control systems, and
in terms of verification runtime scaling. We provide a case study, where we
successfully identify problems in a ROS 2-based robotic manipulation use case
that is verifiable in less than one second using consumer hardware.
Additionally, we compare to the state of the art and demonstrate that our
method is more comprehensive in system feature support, and that the
verification runtime scales linearly with the size of the model, instead of
exponentially.

</details>


### [357] [VisionSafeEnhanced VPC: Cautious Predictive Control with Visibility Constraints under Uncertainty for Autonomous Robotic Surgery](https://arxiv.org/abs/2508.18937)
*Wang Jiayin,Wei Yanran,Jiang Lei,Guo Xiaoyu,Zheng Ayong,Zhao Weidong,Li Zhongkui*

Main category: cs.RO

TL;DR: 本研究提出了一种名为VisionSafeEnhanced Visual Predictive Control (VPC)的框架，用于机器人辅助微创手术（MIS）中的自主腹腔镜控制。该框架通过高斯过程回归（GPR）量化不确定性，并结合安全感知轨迹优化和基于不确定性的控制障碍函数（CBF），以在存在不确定性的情况下保证视野（FoV）安全。实验结果表明，与基线方法相比，该框架在保持目标可见性（>99.9%）和减少跟踪误差方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助微创手术（MIS）中自主控制腹腔镜具有提高手术安全性的潜力。然而，现有的基于图像的视觉伺服（IBVS）控制方法在面对参数化误差、测量噪声和负载不确定性等复杂干扰时，可能影响手术的视觉体验和安全性。本研究旨在解决这些限制。

Method: 本研究提出了一种名为VisionSafeEnhanced Visual Predictive Control (VPC)的框架。首先，利用高斯过程回归（GPR）对操作不确定性（包括残余模型不确定性、随机不确定性和外部干扰）进行混合（确定性+随机性）量化。基于不确定性量化，提出了一种新颖的安全感知轨迹优化框架，该框架具有概率保证。具体来说，基于不确定性传播，给出了不确定性自适应的控制障碍函数（CBF）条件，同时基于概率近似制定了机会约束。这种考虑不确定性的方法能够自适应地分配控制努力，最大限度地减少不必要的相机运动，同时保持鲁棒性。

Result: 通过在MicroPort MedBot Toumai手术机器人平台上进行比较模拟和实验，对提出的方法进行了验证。实验任务是执行顺序多靶淋巴结切除术。结果显示，与基线方法相比，本框架能保持接近完美的靶点可见性（>99.9%），并能减少跟踪误差。

Conclusion: VisionSafeEnhanced Visual Predictive Control (VPC)框架通过有效的不确定性量化和安全感知控制策略，能够显著提高机器人辅助MIS中自主腹腔镜控制的性能和安全性，确保在复杂干扰下维持关键视野和精确跟踪。

Abstract: Autonomous control of the laparoscope in robot-assisted Minimally Invasive
Surgery (MIS) has received considerable research interest due to its potential
to improve surgical safety. Despite progress in pixel-level Image-Based Visual
Servoing (IBVS) control, the requirement of continuous visibility and the
existence of complex disturbances, such as parameterization error, measurement
noise, and uncertainties of payloads, could degrade the surgeon's visual
experience and compromise procedural safety. To address these limitations, this
paper proposes VisionSafeEnhanced Visual Predictive Control (VPC), a robust and
uncertainty-adaptive framework for autonomous laparoscope control that
guarantees Field of View (FoV) safety under uncertainty. Firstly, Gaussian
Process Regression (GPR) is utilized to perform hybrid (deterministic +
stochastic) quantification of operational uncertainties including residual
model uncertainties, stochastic uncertainties, and external disturbances. Based
on uncertainty quantification, a novel safety aware trajectory optimization
framework with probabilistic guarantees is proposed, where a
uncertainty-adaptive safety Control Barrier Function (CBF) condition is given
based on uncertainty propagation, and chance constraints are simultaneously
formulated based on probabilistic approximation. This uncertainty aware
formulation enables adaptive control effort allocation, minimizing unnecessary
camera motion while maintaining robustness. The proposed method is validated
through comparative simulations and experiments on a commercial surgical robot
platform (MicroPort MedBot Toumai) performing a sequential multi-target lymph
node dissection. Compared with baseline methods, the framework maintains
near-perfect target visibility (>99.9%), reduces tracking e

</details>


### [358] [Enhanced UAV Path Planning Using the Tangent Intersection Guidance (TIG) Algorithm](https://arxiv.org/abs/2508.18967)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: 本文提出了一种名为“切线交点引导”（TIG）的无人机路径规划算法，该算法在静态和动态环境中都能生成高效且安全的路径。


<details>
  <summary>Details</summary>
Motivation: 无人机在战斗支援、包裹递送和搜救行动等多种应用中，实现高效且安全的导航至关重要。

Method: 该算法采用椭圆切线交点法生成可行路径，为每个威胁生成两条子路径，并基于启发式规则选择最优路径，通过迭代优化直至到达目标。同时，考虑了无人机的运动学和动力学约束，并采用基于二次贝塞尔曲线的改进平滑技术来生成平滑高效的路线。

Result: 实验结果表明，在静态环境中，TIG算法比A*、PRM、RRT*、切线图和静态APPATT算法生成路径所需时间更短（从0.01秒开始），且转弯角度更少。在完全未知和部分已知的动态环境中，TIG算法在实时避碰方面表现出高效的路径规划能力，优于APF和动态APPATT算法。

Conclusion: TIG算法在各种环境下都能有效地规划无人机路径，相比现有算法具有更高的效率和更好的性能。

Abstract: Efficient and safe navigation of Unmanned Aerial Vehicles (UAVs) is critical
for various applications, including combat support, package delivery and Search
and Rescue Operations. This paper introduces the Tangent Intersection Guidance
(TIG) algorithm, an advanced approach for UAV path planning in both static and
dynamic environments. The algorithm uses the elliptic tangent intersection
method to generate feasible paths. It generates two sub-paths for each threat,
selects the optimal route based on a heuristic rule, and iteratively refines
the path until the target is reached. Considering the UAV kinematic and dynamic
constraints, a modified smoothing technique based on quadratic B\'ezier curves
is adopted to generate a smooth and efficient route. Experimental results show
that the TIG algorithm can generate the shortest path in less time, starting
from 0.01 seconds, with fewer turning angles compared to A*, PRM, RRT*, Tangent
Graph, and Static APPATT algorithms in static environments. Furthermore, in
completely unknown and partially known environments, TIG demonstrates efficient
real-time path planning capabilities for collision avoidance, outperforming APF
and Dynamic APPATT algorithms.

</details>


### [359] [HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots](https://arxiv.org/abs/2508.19002)
*Shipeng Lyu,Fangyuan Wang,Weiwei Lin,Luhao Zhu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: HuBE框架通过整合机器人状态、目标姿态和情境信息，生成类人运动，解决了人类运动生成中的行为相似性、适宜性及跨体适应性问题。同时，HPose数据集和骨骼缩放数据增强策略提高了运动的兼容性和效率。


<details>
  <summary>Details</summary>
Motivation: 类人机器人运动生成面临行为相似性、适宜性以及跨体适应性的挑战。

Method: 提出HuBE（一种双层闭环框架），整合机器人状态、目标姿态和情境信息生成类人行为；构建HPose（包含细粒度情境标注的数据集）；引入基于骨骼缩放的数据增强策略以实现跨异构人形机器人兼容性。

Result: HuBE在运动相似性、行为适宜性和计算效率方面显著优于现有方法，实现了跨不同人形机器人的可转移和类人行为执行。

Conclusion: HuBE框架为跨不同人形机器人的可转移和类人行为执行奠定了坚实基础。

Abstract: Achieving both behavioral similarity and appropriateness in human-like motion
generation for humanoid robot remains an open challenge, further compounded by
the lack of cross-embodiment adaptability. To address this problem, we propose
HuBE, a bi-level closed-loop framework that integrates robot state, goal poses,
and contextual situations to generate human-like behaviors, ensuring both
behavioral similarity and appropriateness, and eliminating structural
mismatches between motion generation and execution. To support this framework,
we construct HPose, a context-enriched dataset featuring fine-grained
situational annotations. Furthermore, we introduce a bone scaling-based data
augmentation strategy that ensures millimeter-level compatibility across
heterogeneous humanoid robots. Comprehensive evaluations on multiple commercial
platforms demonstrate that HuBE significantly improves motion similarity,
behavioral appropriateness, and computational efficiency over state-of-the-art
baselines, establishing a solid foundation for transferable and human-like
behavior execution across diverse humanoid robots.

</details>


### [360] [An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees](https://arxiv.org/abs/2508.19074)
*ZhenDong Chen,ZhanShang Nie,ShiXing Wan,JunYi Li,YongTian Cheng,Shuai Zhao*

Main category: cs.RO

TL;DR: LLM在机器人控制程序生成中存在错误，提出NRTrans框架，通过RSL语言、编译器和调试器提供正确性验证和反馈式微调，提高了LLM生成程序的有效性，尤其适用于轻量级LLM。


<details>
  <summary>Details</summary>
Motivation: 现有LLM用于机器人控制程序生成的方法，因LLM不一致性和任务复杂性，常导致编程错误，尤其在轻量级LLM上效果不佳。

Method: 提出自然-机器人语言翻译（NRTrans）框架，引入机器人技能语言（RSL）抽象控制程序细节，并构建RSL编译器和调试器，对LLM生成的RSL程序进行正确性验证和错误反馈，实现反馈式微调。

Result: NRTrans框架在多样的LLM和任务上优于现有方法，并且显著提高了轻量级LLM的成功率。

Conclusion: NRTrans框架通过提供正确性保证和基于反馈的微调，能有效解决LLM生成机器人控制程序中的错误问题，提升了LLM在机器人领域的应用效果。

Abstract: The Large Language Models (LLM) are increasingly being deployed in robotics
to generate robot control programs for specific user tasks, enabling embodied
intelligence. Existing methods primarily focus on LLM training and prompt
design that utilize LLMs to generate executable programs directly from user
tasks in natural language. However, due to the inconsistency of the LLMs and
the high complexity of the tasks, such best-effort approaches often lead to
tremendous programming errors in the generated code, which significantly
undermines the effectiveness especially when the light-weight LLMs are applied.
This paper introduces a natural-robotic language translation framework that (i)
provides correctness verification for generated control programs and (ii)
enhances the performance of LLMs in program generation via feedback-based
fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is
proposed to abstract away from the intricate details of the control programs,
bridging the natural language tasks with the underlying robot skills. Then, the
RSL compiler and debugger are constructed to verify RSL programs generated by
the LLM and provide error feedback to the LLM for refining the outputs until
being verified by the compiler. This provides correctness guarantees for the
LLM-generated programs before being offloaded to the robots for execution,
significantly enhancing the effectiveness of LLM-powered robotic applications.
Experiments demonstrate NRTrans outperforms the existing method under a range
of LLMs and tasks, and achieves a high success rate for light-weight LLMs.

</details>


### [361] [Real-time Testing of Satellite Attitude Control With a Reaction Wheel Hardware-In-the-Loop Platform](https://arxiv.org/abs/2508.19164)
*Morokot Sakal,George Nehma,Camilo Riano-Rios,Madhur Tiwari*

Main category: cs.RO

TL;DR: 本论文提出了一种用于带反应轮健康估计能力的自适应卫星姿态控制系统的硬件在环（HIL）测试方法。


<details>
  <summary>Details</summary>
Motivation: 为了验证控制器在包含真实动量交换装置的回路中的有效性，在先前的仿真和软件在环测试之后，需要进行进一步的实验。

Method: 提出了一种包含无刷直流电机和驱动器（通过CAN总线通信）、执行控制和自适应律的嵌入式计算机以及产生模拟传感器数据、估计姿态状态并响应外部执行器动作的卫星模拟器的HIL测试平台。还提出了模拟反应轮故障的方法。

Result: 展示了HIL测试平台的构成，并讨论了在测试过程中遇到的问题和经验教训。

Conclusion: 这项工作是为航天器姿态控制算法验证建立一个全面的测试框架的步骤。

Abstract: We propose the Hardware-in-the-Loop (HIL) test of an adaptive satellite
attitude control system with reaction wheel health estimation capabilities.
Previous simulations and Software-in-the-Loop testing have prompted further
experiments to explore the validity of the controller with real momentum
exchange devices in the loop. This work is a step toward a comprehensive
testing framework for validation of spacecraft attitude control algorithms. The
proposed HIL testbed includes brushless DC motors and drivers that communicate
using a CAN bus, an embedded computer that executes control and adaptation
laws, and a satellite simulator that produces simulated sensor data, estimated
attitude states, and responds to actions of the external actuators. We propose
methods to artificially induce failures on the reaction wheels, and present
related issues and lessons learned.

</details>


### [362] [ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments](https://arxiv.org/abs/2508.19131)
*Shreya Gummadi,Mateus V. Gasparino,Gianluca Capezzuto,Marcelo Becker,Girish Chowdhary*

Main category: cs.RO

TL;DR: LLM驱动的实时地形可通行性评估


<details>
  <summary>Details</summary>
Motivation: 传统机器人危险环境数据收集方法存在风险，为解决此问题，提出ZeST方法。

Method: 利用大型语言模型（LLM）的视觉推理能力，实时创建可通行性地图，实现零样本评估。

Result: 在室内和室外环境中进行了导航实验，证明了ZeST方法的安全性和有效性，能够持续到达目标点，优于其他最先进方法。

Conclusion: ZeST提供了一种安全、经济高效且可扩展的解决方案，用于生成可通行性地图，加速了先进导航系统的开发。

Abstract: The advancement of robotics and autonomous navigation systems hinges on the
ability to accurately predict terrain traversability. Traditional methods for
generating datasets to train these prediction models often involve putting
robots into potentially hazardous environments, posing risks to equipment and
safety. To solve this problem, we present ZeST, a novel approach leveraging
visual reasoning capabilities of Large Language Models (LLMs) to create a
traversability map in real-time without exposing robots to danger. Our approach
not only performs zero-shot traversability and mitigates the risks associated
with real-world data collection but also accelerates the development of
advanced navigation systems, offering a cost-effective and scalable solution.
To support our findings, we present navigation results, in both controlled
indoor and unstructured outdoor environments. As shown in the experiments, our
method provides safer navigation when compared to other state-of-the-art
methods, constantly reaching the final goal.

</details>


### [363] [Uncertainty-Resilient Active Intention Recognition for Robotic Assistants](https://arxiv.org/abs/2508.19150)
*Juan Carlos Saborío,Marc Vinci,Oscar Lima,Sebastian Stock,Lennart Niecksch,Martin Günther,Alexander Sung,Joachim Hertzberg,Martin Atzmüller*

Main category: cs.RO

TL;DR: 该论文提出了一种应对机器人助手在人类意图识别中固有的不确定性和感知误差的框架。


<details>
  <summary>Details</summary>
Motivation: 机器人助手的任务往往被简化为识别明确的提示，这限制了自主性，或者依赖于近乎完美的信息等过于简化的假设。本文认为，一个关键的差距尚未解决，即推理人类意图识别中固有的不确定结果和感知误差的挑战。

Method: 本文提出了一种框架，该框架能够应对不确定性和传感器噪声，并将实时传感器数据与规划器相结合。该方法以意图识别 POMDP 为中心，解决了在不确定性下的协作规划和行动问题。

Result: 该框架已在物理机器人上成功测试，并取得了有希望的结果。

Conclusion: 该框架成功地整合了实时传感器数据和规划器，以应对机器人助手在人类意图识别中固有的不确定性和感知误差。

Abstract: Purposeful behavior in robotic assistants requires the integration of
multiple components and technological advances. Often, the problem is reduced
to recognizing explicit prompts, which limits autonomy, or is oversimplified
through assumptions such as near-perfect information. We argue that a critical
gap remains unaddressed -- specifically, the challenge of reasoning about the
uncertain outcomes and perception errors inherent to human intention
recognition. In response, we present a framework designed to be resilient to
uncertainty and sensor noise, integrating real-time sensor data with a
combination of planners. Centered around an intention-recognition POMDP, our
approach addresses cooperative planning and acting under uncertainty. Our
integrated framework has been successfully tested on a physical robot with
promising results.

</details>


### [364] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: QuadKAN通过结合本体感觉和视觉信息，使用样条参数化的Kolmogorov-Arnold网络（KANs）实现了机器人四足运动的强化学习控制，在各种地形和障碍物场景下表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了实现对机器人四足运动的鲁棒控制，需要结合本体感觉和视觉信息。

Method: 提出了一种名为QuadKAN的框架，该框架使用样条参数化的Kolmogorov-Arnold网络（KANs）。该框架包含一个用于本体感觉的样条编码器和一个用于本体感觉-视觉输入的样条融合头。采用多模态延迟随机化（MMDR）和近端策略优化（PPO）进行端到端训练。

Result: 在各种地形（包括平坦和不平坦的表面）以及静态或动态障碍物的场景下进行评估，QuadKAN实现了比现有技术（SOTA）基线更高的一致回报、更远的距离和更少的碰撞。

Conclusion: 结果表明，样条参数化的策略为鲁棒的视觉引导运动提供了简单、有效且可解释的替代方案。

Abstract: We address vision-guided quadruped motion control with reinforcement learning
(RL) and highlight the necessity of combining proprioception with vision for
robust control. We propose QuadKAN, a spline-parameterized cross-modal policy
instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates
a spline encoder for proprioception and a spline fusion head for
proprioception-vision inputs. This structured function class aligns the
state-to-action mapping with the piecewise-smooth nature of gait, improving
sample efficiency, reducing action jitter and energy consumption, and providing
interpretable posture-action sensitivities. We adopt Multi-Modal Delay
Randomization (MMDR) and perform end-to-end training with Proximal Policy
Optimization (PPO). Evaluations across diverse terrains, including both even
and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate
that QuadKAN achieves consistently higher returns, greater distances, and fewer
collisions than state-of-the-art (SOTA) baselines. These results show that
spline-parameterized policies offer a simple, effective, and interpretable
alternative for robust vision-guided locomotion. A repository will be made
available upon acceptance.

</details>


### [365] [Direction Informed Trees (DIT*): Optimal Path Planning via Direction Filter and Direction Cost Heuristic](https://arxiv.org/abs/2508.19168)
*Liding Zhang,Kejia Chen,Kuanqi Cai,Yu Zhang,Yixuan Dang,Yansong Wu,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: DIT*是一种新的路径规划算法，通过优化搜索方向来提高效率，并在高维空间和真实世界环境中表现优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 路径规划需要找到从起点到终点的可行状态序列以优化目标。现有的启发式算法（如EIT*）在启发式信息的准确性和计算效率之间存在冲突。

Method: DIT*将边定义为广义向量，并集成相似性索引来建立方向过滤器，以选择最近的邻居并估计方向成本。该方法利用估计的方向成本启发式信息来评估边，从而实现高效的方向信息共享。

Result: DIT*在R^4到R^16的空间中比现有的单查询采样规划器收敛更快，并在真实世界的各种规划任务中得到了验证。

Conclusion: DIT*通过优化搜索方向，能够更有效地进行探索，从而在各种高维和真实世界环境中实现更快的收敛速度。

Abstract: Optimal path planning requires finding a series of feasible states from the
starting point to the goal to optimize objectives. Popular path planning
algorithms, such as Effort Informed Trees (EIT*), employ effort heuristics to
guide the search. Effective heuristics are accurate and computationally
efficient, but achieving both can be challenging due to their conflicting
nature. This paper proposes Direction Informed Trees (DIT*), a sampling-based
planner that focuses on optimizing the search direction for each edge,
resulting in goal bias during exploration. We define edges as generalized
vectors and integrate similarity indexes to establish a directional filter that
selects the nearest neighbors and estimates direction costs. The estimated
direction cost heuristics are utilized in edge evaluation. This strategy allows
the exploration to share directional information efficiently. DIT* convergence
faster than existing single-query, sampling-based planners on tested problems
in R^4 to R^16 and has been demonstrated in real-world environments with
various planning tasks. A video showcasing our experimental results is
available at: https://youtu.be/2SX6QT2NOek

</details>


### [366] [From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity](https://arxiv.org/abs/2508.19172)
*Luca Grillotti,Lisa Coiffard,Oscar Pang,Maxence Faldor,Antoine Cully*

Main category: cs.RO

TL;DR: URSA是一种在现实世界中自主发现和掌握多样化、高性能技能的机器人学习新框架，它扩展了QDAC，无需手动定义的技能空间和仔细调整的启发式方法，实现了连续技能发现，并能适应下游任务，如真实世界的损坏适应。


<details>
  <summary>Details</summary>
Motivation: 自主技能发现的目的是让机器人能够在没有明确监督的情况下获得多样的行为。在物理硬件上直接学习这些行为仍然具有挑战性，因为存在安全性和数据效率的限制。现有的方法，包括质量-多样性 Actor-Critic (QDAC)，需要手动定义的技能空间和仔细调整的启发式方法，这限制了其在现实世界的应用。

Method: URSA是QDAC的一个扩展，它使机器人能够直接在现实世界中自主发现和掌握多样化、高性能的技能。该方法支持启发式驱动的技能发现和完全无监督的设置。

Result: URSA在Unitree A1四足机器人在模拟和现实世界中成功发现了多样化的运动技能。URSA学习到的技能库可用于下游任务，如真实世界的损坏适应，在9个模拟和5个真实世界损坏场景中的5个和3个场景中，URSA的表现优于所有基线。

Conclusion: URSA为现实世界的机器人学习提供了一个新的框架，能够以有限的人工干预实现持续的技能发现，这是实现更自主和适应性强的机器人系统的重要一步。

Abstract: Autonomous skill discovery aims to enable robots to acquire diverse behaviors
without explicit supervision. Learning such behaviors directly on physical
hardware remains challenging due to safety and data efficiency constraints.
Existing methods, including Quality-Diversity Actor-Critic (QDAC), require
manually defined skill spaces and carefully tuned heuristics, limiting
real-world applicability. We propose Unsupervised Real-world Skill Acquisition
(URSA), an extension of QDAC that enables robots to autonomously discover and
master diverse, high-performing skills directly in the real world. We
demonstrate that URSA successfully discovers diverse locomotion skills on a
Unitree A1 quadruped in both simulation and the real world. Our approach
supports both heuristic-driven skill discovery and fully unsupervised settings.
We also show that the learned skill repertoire can be reused for downstream
tasks such as real-world damage adaptation, where URSA outperforms all
baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios.
Our results establish a new framework for real-world robot learning that
enables continuous skill discovery with limited human intervention,
representing a significant step toward more autonomous and adaptable robotic
systems. Demonstration videos are available at
http://adaptive-intelligent-robotics.github.io/URSA .

</details>


### [367] [Real-Time Model Checking for Closed-Loop Robot Reactive Planning](https://arxiv.org/abs/2508.19186)
*Christopher Chandler,Bernd Porr,Giulia Lafratta,Alice Miller*

Main category: cs.RO

TL;DR: We introduce a novel model checking algorithm for real-time multi-step planning and obstacle avoidance in autonomous robots, utilizing biological agent-inspired knowledge and attention. The algorithm operates without pre-computed data on low-powered devices, achieving planning by chaining temporary control systems that react to environmental disturbances. A key innovation is a new discretization of 2D LiDAR data sensitive to local environmental variations. Applied to cul-de-sac and playground scenarios, the approach demonstrates through empirical results and proofs that model checking can yield efficient multi-step plans for obstacle avoidance, outperforming reactive agents. This work serves as a case study for developing safe, reliable, and explainable planning systems for autonomous vehicles.


<details>
  <summary>Details</summary>
Motivation: The paper presents a new application of model checking for real-time multi-step planning and obstacle avoidance on autonomous robots, inspired by biological agents' core knowledge and attention.

Method: A purpose-built model checking algorithm is developed that generates in situ plans based on biological agent-inspired knowledge and attention. This is achieved in real-time on a low-powered device without pre-computed data. The approach chains temporary control systems to counteract local environmental disturbances. A novel discretization of 2D LiDAR data sensitive to bounded local variations is employed. Multi-step planning via model checking with forward depth-first search is applied to specific scenarios.

Result: The study demonstrates through empirical results and informal proofs that model checking can be used to create efficient multi-step plans for local obstacle avoidance. The proposed approach improves upon the performance of a reactive agent that can only plan one step. It successfully handles cul-de-sac and playground scenarios.

Conclusion: Model checking can be effectively used to create efficient multi-step plans for local obstacle avoidance, offering improvements over reactive agents. The presented approach is a valuable case study for developing safe, reliable, and explainable planning in autonomous vehicles.

Abstract: We present a new application of model checking which achieves real-time
multi-step planning and obstacle avoidance on a real autonomous robot. We have
developed a small, purpose-built model checking algorithm which generates plans
in situ based on "core" knowledge and attention as found in biological agents.
This is achieved in real-time using no pre-computed data on a low-powered
device. Our approach is based on chaining temporary control systems which are
spawned to counteract disturbances in the local environment that disrupt an
autonomous agent from its preferred action (or resting state). A novel
discretization of 2D LiDAR data sensitive to bounded variations in the local
environment is used. Multi-step planning using model checking by forward
depth-first search is applied to cul-de-sac and playground scenarios. Both
empirical results and informal proofs of two fundamental properties of our
approach demonstrate that model checking can be used to create efficient
multi-step plans for local obstacle avoidance, improving on the performance of
a reactive agent which can only plan one step. Our approach is an instructional
case study for the development of safe, reliable and explainable planning in
the context of autonomous vehicles.

</details>


### [368] [AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot](https://arxiv.org/abs/2508.19191)
*Yue Wang,Wenjie Deng,Haotian Xue,Di Cui,Yiqi Chen,Mingchuan Zhou,Haochao Ying,Jian Wu*

Main category: cs.RO

TL;DR: 提出了一种名为AutoRing的模仿学习框架，用于自动化机器人完成眼内异物抓取和定位任务，无需深度感知。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人系统在眼内操作中依赖手动遥操作且学习曲线陡峭的问题，以及自主操作中的运动学不确定性（如运动尺度变化和遥控中心点RCM变化）。

Method: 提出AutoRing模仿学习框架，整合了动态RCM校准以解决坐标系不一致问题，并引入了RCM-ACT架构（结合动作分块Transformer和实时运动学重新对齐）。该框架仅使用专家演示的立体视觉数据和仪器运动学在仿生眼模型中进行训练。

Result: AutoRing成功完成了眼内异物的抓取和定位任务，即使在没有显式深度感知的未校准显微镜条件下也实现了端到端自主。

Conclusion: AutoRing为开发能够执行复杂眼内手术的智能眼科手术系统提供了一个可行的框架。

Abstract: Intraocular foreign body removal demands millimeter-level precision in
confined intraocular spaces, yet existing robotic systems predominantly rely on
manual teleoperation with steep learning curves. To address the challenges of
autonomous manipulation (particularly kinematic uncertainties from variable
motion scaling and variation of the Remote Center of Motion (RCM) point), we
propose AutoRing, an imitation learning framework for autonomous intraocular
foreign body ring manipulation. Our approach integrates dynamic RCM calibration
to resolve coordinate-system inconsistencies caused by intraocular instrument
variation and introduces the RCM-ACT architecture, which combines
action-chunking transformers with real-time kinematic realignment. Trained
solely on stereo visual data and instrument kinematics from expert
demonstrations in a biomimetic eye model, AutoRing successfully completes ring
grasping and positioning tasks without explicit depth sensing. Experimental
validation demonstrates end-to-end autonomy under uncalibrated microscopy
conditions. The results provide a viable framework for developing intelligent
eye-surgical systems capable of complex intraocular procedures.

</details>


### [369] [Planning-Query-Guided Model Generation for Model-Based Deformable Object Manipulation](https://arxiv.org/abs/2508.19199)
*Alex LaGrassa,Zixuan Huang,Dmitry Berenson,Oliver Kroemer*

Main category: cs.RO

TL;DR: 该方法通过学习需要高分辨率建模的物体区域，自动生成特定任务、空间自适应的动力学模型，以提高规划性能。


<details>
  <summary>Details</summary>
Motivation: 高效规划在高维空间（例如涉及可变形物体）中需要计算上可行但表达充分的动力学模型。

Method: 提出一种基于扩散的模型生成器，根据定义规划查询的起始和目标点云，预测每个区域的模型分辨率。为高效收集用于学习此映射的数据，采用两阶段过程，首先使用预测动力学作为先验来优化分辨率，然后直接使用闭环性能进行优化。

Result: 在树操作任务中，与使用全分辨率模型相比，该方法将规划速度提高了一倍，而任务性能仅略有下降。

Conclusion: 该方法为利用以前的规划和控制数据为新任务生成计算上高效但表达充分的动力学模型提供了方向。

Abstract: Efficient planning in high-dimensional spaces, such as those involving
deformable objects, requires computationally tractable yet sufficiently
expressive dynamics models. This paper introduces a method that automatically
generates task-specific, spatially adaptive dynamics models by learning which
regions of the object require high-resolution modeling to achieve good task
performance for a given planning query. Task performance depends on the complex
interplay between the dynamics model, world dynamics, control, and task
requirements. Our proposed diffusion-based model generator predicts per-region
model resolutions based on start and goal pointclouds that define the planning
query. To efficiently collect the data for learning this mapping, a two-stage
process optimizes resolution using predictive dynamics as a prior before
directly optimizing using closed-loop performance. On a tree-manipulation task,
our method doubles planning speed with only a small decrease in task
performance over using a full-resolution model. This approach informs a path
towards using previous planning and control data to generate computationally
efficient yet sufficiently expressive dynamics models for new tasks.

</details>


### [370] [MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2508.19236)
*Hao Shi,Bin Xie,Yingfei Liu,Lin Sun,Fengrong Liu,Tiancai Wang,Erjin Zhou,Haoqiang Fan,Xiangyu Zhang,Gao Huang*

Main category: cs.RO

TL;DR: MemoryVLA是一个用于长时程机器人操作的认知-记忆-动作框架，通过结合工作记忆和长期记忆机制，提高了对时间依赖性任务的处理能力。


<details>
  <summary>Details</summary>
Motivation: 主流视觉语言模型（VLA）通常忽略时间上下文，难以处理长时程、时间依赖性任务。受认知科学中工作记忆和海马体系统启发，提出MemoryVLA来解决这个问题。

Method: MemoryVLA框架包括：1.预训练VLM将观察编码为工作记忆的感知和认知标记；2.感知-认知记忆库存储工作记忆中的低级细节和高级语义；3.工作记忆从记忆库检索相关条目，并与当前标记自适应融合，同时更新记忆库；4.记忆条件扩散动作专家利用这些标记生成时间感知的动作序列。

Result: MemoryVLA在SimplerEnv-Bridge、Fractal和LIBERO-5等基准测试中分别达到了71.9%、72.7%和96.5%的成功率，优于CogACT和pi-0基线。在12项真实世界任务中，成功率为84.0%，其中长时程任务比最先进基线提高了26%。

Conclusion: MemoryVLA通过模拟人类的认知记忆机制，在长时程和时间依赖性机器人操作任务中展现出优越性能。

Abstract: Temporal context is essential for robotic manipulation because such tasks are
inherently non-Markovian, yet mainstream VLA models typically overlook it and
struggle with long-horizon, temporally dependent tasks. Cognitive science
suggests that humans rely on working memory to buffer short-lived
representations for immediate control, while the hippocampal system preserves
verbatim episodic details and semantic gist of past experience for long-term
memory. Inspired by these mechanisms, we propose MemoryVLA, a
Cognition-Memory-Action framework for long-horizon robotic manipulation. A
pretrained VLM encodes the observation into perceptual and cognitive tokens
that form working memory, while a Perceptual-Cognitive Memory Bank stores
low-level details and high-level semantics consolidated from it. Working memory
retrieves decision-relevant entries from the bank, adaptively fuses them with
current tokens, and updates the bank by merging redundancies. Using these
tokens, a memory-conditioned diffusion action expert yields temporally aware
action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks
across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it
achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming
state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on
Bridge. On 12 real-world tasks spanning general skills and long-horizon
temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon
tasks showing a +26 improvement over state-of-the-art baseline. Project Page:
https://shihao1895.github.io/MemoryVLA

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [371] [Recognizing Distance-Count Matrices is Difficult](https://arxiv.org/abs/2508.18857)
*Paolo Boldi,Flavio Furia,Chiara Prezioso,Ian Stewart*

Main category: cs.SI

TL;DR: 确定一个图的距离-计数矩阵是NP完备的，这使得构建反例变得困难。


<details>
  <summary>Details</summary>
Motivation: 现有几何中心性度量的公理化方法常常需要提供反例，即那些无法满足特定属性的图。而构建这类反例需要构造具有特定节点间距离计数的图，即其距离-计数矩阵。

Method: 证明确定一个矩阵是否为图的距离-计数矩阵是强NP完备的。

Result: 该问题的强NP完备性意味着无法通过穷举法来构建反例。

Conclusion: 由于确定距离-计数矩阵是NP完备的，因此需要更巧妙的方法来构建反例，而不是依赖于蛮力搜索。

Abstract: Axiomatization of centrality measures often involves proving that something
cannot hold by providing a counterexample (i.e., a graph for which that
specific centrality index fails to have a given property). In the context of
geometric centralities, building such counterexamples requires constructing a
graph with specific distance counts between nodes, as expressed by its
distance-count matrix. We prove that deciding whether a matrix is the
distance-count matrix of a graph is strongly NP-complete. This negative result
implies that a brute-force approach to building this kind of counterexample is
out of question, and cleverer approaches are required.

</details>


### [372] [Digital Skills Formation in Gendered Peer Networks: Exploring advice giving and taking in classrooms](https://arxiv.org/abs/2508.19102)
*Petro Tolochko,Jana Bernhard-Harrer,Azade E. Kakavand,Aytalina Kulichkina,Hyunjin Song,Hajo G. Boomgaarden*

Main category: cs.SI

TL;DR: 儿童的数字化转型强调早期数字技能发展的重要性。本研究利用来自三个国家课堂的独特社会中心网络数据，重点关注与数字技能相关的同伴互助和寻求建议网络，以了解同伴关系如何塑造这一过程。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨同伴关系在儿童数字技能发展中的作用，特别是同伴互助和寻求建议的行为如何影响数字技能的传播。

Method: 本研究采用指数随机图模型，分析来自三个国家课堂的学生网络数据，重点关注与数字技能相关的同伴互助和寻求建议网络。

Result: 研究发现，数字技能通过同伴互动系统性地传播：高技能学生更有可能被寻求建议，而他们自己寻求建议的可能性较低。被认为是高技能的学生更有可能寻求和提供建议，但这对他们被他人寻求建议的影响有限。性别起着重要作用：女孩寻求和提供建议的次数都更多，并且强烈的性别同质性塑造了这些互动。

Conclusion: 研究建议，数字技能教育应利用正规教育中同伴学习的潜力，并考虑如何解决持续存在的数字鸿沟。

Abstract: The digitalisation of childhood underscores the importance of early digital
skill development. To understand how peer relationships shape this process, we
draw on unique sociocentric network data from students in classrooms across
three countries, focusing on peer-to-peer advice-giving and advice-seeking
networks related to digital skills. Using exponential random graph models, we
find that digital skills systematically spread through peer interactions:
higher-skilled students are more likely to be sought for advice while less
likely to seek it themselves. Students perceived as highly skilled are more
likely to seek and offer advice, but it has limited influence on being sought
out by others. Gender plays a significant role: girls both seek and give more
advice, with strong gender homophily shaping these interactions. We suggest
that digital skills education should leverage the potential of peer learning
within formal education and consider how such approaches can address persistent
divides.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [373] [Fast Multiagent Formation Stabilization with Sparse Universally Rigid Frameworks](https://arxiv.org/abs/2508.18483)
*Zhonggang Li,Geert Leus,Raj Thilak Rajan*

Main category: eess.SY

TL;DR: 本文提出了一种利用凸优化设计应力矩阵的仿射编队控制方法，可在减少通信链路的同时保持快速收敛。


<details>
  <summary>Details</summary>
Motivation: 仿射编队控制（AFC）在分布式网络控制系统中受到广泛关注，而通用刚性框架（URF）是设计AFC网络的关键。然而，现有方法通常需要预先定义刚性图，限制了网络的灵活性和效率。

Method: 本文提出了一种利用凸优化框架来设计应力矩阵的AFC方法，无需预先定义刚性图。该方法旨在找到一个通信链路更少但收敛速度更快的网络。

Result: 通过仿真表明，所提出的方法能够生成更稀疏的网络，并且比现有最先进的方法具有更快的收敛速度。

Conclusion: 本文提出的凸优化框架为AFC网络设计提供了一种新的途径，能够有效减少通信开销并提高控制性能。

Abstract: Affine formation control (AFC) is a distributed networked control system that
has recently received increasing attention in various applications. AFC is
typically achieved using a generalized consensus system where the stress
matrix, which encodes the graph structure, is used instead of a graph
Laplacian. Universally rigid frameworks (URFs) guarantee the existence of the
stress matrix and have thus become the guideline for such a network design. In
this work, we propose a convex optimization framework to design the stress
matrix for AFC without predefining a rigid graph. We aim to find a resulting
network with a reduced number of communication links, but still with a fast
convergence speed. We show through simulations that our proposed solutions can
yield a more sparse graph, while admitting a faster convergence compared to the
state-of-the-art solutions.

</details>


### [374] [A Learning-based Hybrid System Approach for Detecting Contingencies in Distribution Grids with Inverter-Based Resources](https://arxiv.org/abs/2508.18500)
*Hamid Varmazyari,Masoud H. Nazari*

Main category: eess.SY

TL;DR: 本篇论文提出了一种基于机器学习的随机混合系统（SHS）建模框架，用于检测包含逆变器基资源（IBRs）的有源配电网络中的故障。该框架能够检测不可观测的故障。研究人员开发了一个结合了常规和IBRs资源的状态空间SHS模型，以解决模型参数或网络拓扑因故障而变化的随机切换系统问题。通过利用高频采样系统状态和网络输出来自多元时间序列数据，训练了一个基于时间序列的学习模型，用于实时故障检测和分类。在IEEE 33节点配电系统上进行的仿真研究表明，该方法的总体检测准确率为96%。


<details>
  <summary>Details</summary>
Motivation: 为了解决有源配电网络（特别是包含逆变器基资源IBRs的电网）中可能发生的、常规传感系统无法检测到的不可观测故障的检测问题。

Method: 提出了一种基于机器学习的随机混合系统（SHS）建模框架。该框架首先建立一个结合了常规和IBRs资源的状态空间SHS模型，以描述连续网络状态和离散故障事件之间的动态交互。然后，利用高频采样系统状态和网络输出的多元时间序列数据，训练一个基于时间序列的学习模型，用于实时故障检测和分类。

Result: 在IEEE 33节点配电系统上进行的仿真研究表明，该框架的总体故障检测准确率为96%。

Conclusion: 所提出的基于SHS和时间序列学习的框架能够有效地检测有源配电网络中的不可观测故障，准确率高达96%.

Abstract: This paper presents a machine-learning based Stochastic Hybrid System (SHS)
modeling framework to detect contingencies in active distribution networks
populated with inverter-based resources (IBRs). In particular, this framework
allows detecting unobservable contingencies, which cannot be identified by
normal sensing systems. First, a state-space SHS model combining conventional
and IRB-based resources is introduced to formulate the dynamic interaction
between continuous states of distribution networks and discrete contingency
events. This model forms a randomly switching system, where parameters or
network topology can change due to contingencies. We consider two contingency
classes: (i) physical events, such as line outages, and (ii) measurement
anomalies caused by sensor faults. Leveraging multivariate time series data
derived from high-frequency sampling of system states and network outputs, a
time series-based learning model is trained for real-time contingency detection
and classification. Simulation studies, carried out on the IEEE 33-bus
distribution system, demonstrate a 96% overall detection accuracy.

</details>


### [375] [Electromagnetic Formation Flying Using Alternating Magnetic Field Forces and Control Barrier Functions for State and Input Constraints](https://arxiv.org/abs/2508.18501)
*Sumit S. Kamat,T. Michael Seigler,Jesse B. Hoagg*

Main category: eess.SY

TL;DR: 该研究提出了一种用于电磁编队飞行的反馈控制算法，该算法结合了交变磁场力、最优控制和控制障碍函数，以满足卫星状态和控制输入约束，并通过数值模拟进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了在满足卫星状态（如无碰撞、速度限制）和控制输入（如功率限制）约束的条件下，实现电磁编队飞行。

Method: 1. 使用交变磁场力解耦编队中卫星对之间的电磁力。
2. 卫星的电磁驱动系统由幅度调制的正弦波驱动，通过控制幅度来指定卫星对之间的时间平均力。
3. 期望的时间平均力通过最优控制计算得出，该控制能够满足状态约束和输入约束。
4. 利用一个由多个控制障碍函数组成的松弛控制障碍函数来计算最优时间平均力，以强制执行每个状态和输入约束。

Result: 通过数值模拟展示了所提出的卫星编队控制方法的有效性。

Conclusion: 所提出的结合了交变磁场力、最优控制和控制障碍函数的反馈控制算法能够有效地实现满足约束条件的电磁编队飞行。

Abstract: This article presents a feedback control algorithm for electromagnetic
formation flying with constraints on the satellites' states and control inputs.
The algorithm combines several key techniques. First, we use alternating
magnetic field forces to decouple the electromagnetic forces between each pair
of satellites in the formation. Each satellite's electromagnetic actuation
system is driven by a sum of amplitude-modulated sinusoids, where amplitudes
are controlled in order to prescribe the time-averaged force between each pair
of satellites. Next, the desired time-averaged force is computed from a optimal
control that satisfies state constraints (i.e., no collisions and an upper
limit on intersatellite speeds) and input constraints (i.e., not exceeding
satellite's apparent power capability). The optimal time-averaged force is
computed using a single relaxed control barrier function that is obtained by
composing multiple control barrier functions that are designed to enforce each
state and input constraint. Finally, we demonstrate the satellite formation
control method in numerical simulations.

</details>


### [376] [Fuzzy-Based Control Method for Autonomous Spacecraft Inspection with Minimal Fuel Consumption](https://arxiv.org/abs/2508.18583)
*Daegyun Choi,Donghoon Kim,Henzeh Leeghim*

Main category: eess.SY

TL;DR: 本研究提出了一种结合模糊推理系统和仿生优化技术的节能控制策略，用于航天器检查。


<details>
  <summary>Details</summary>
Motivation: 为了在满足光照、视场、推力限制和安全区域等约束的同时，实现节能并保证检查的可靠性。

Method: 采用模糊推理系统结合仿生优化技术来优化模糊控制器，以最小化燃料消耗。

Result: 通过蒙特卡洛模拟验证了所提出控制策略的性能，该策略能在约束条件下实现最小燃料消耗和可靠的检查。

Conclusion: 所提出的控制策略能够有效地在满足各项约束的条件下，实现航天器检查的节能和可靠性。

Abstract: This study explores an energy-efficient control strategy for spacecraft
inspection using a fuzzy inference system combined with a bio-inspired
optimization technique to incorporate learning capability into the control
process. The optimized fuzzy controller produces a minimally fuel-consuming
force while maintaining reliable inspection within constraints, such as
illumination, restricted field of view, thrust limits, and safe regions. The
performance of the proposed control strategy is validated through Monte Carlo
simulations.

</details>


### [377] [Scalable Fairness Shaping with LLM-Guided Multi-Agent Reinforcement Learning for Peer-to-Peer Electricity Markets](https://arxiv.org/abs/2508.18610)
*Shrenik Jadhav,Birva Sevak,Srijita Das,Akhtar Hussain,Wencong Su,Van-Hai Bui*

Main category: eess.SY

TL;DR: 一个新框架FairMarket-RL利用大型语言模型（LLM）在P2P能源交易中促进公平性，在经济效率、社会公平和技术稳健性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有P2P能源交易市场和强化学习设计过于关注效率或私人利润，未能提供实时指导以确保在不确定性下的公平结果。

Method: 提出了一种公平感知的多智能体强化学习框架FairMarket-RL，其中LLM作为评论员，在部分可观测性和离散价格-数量动作下，通过连续双拍卖来塑造竞标策略。LLM为FTG、FBS和FPP这三个公平性指标提供归一化分数，并将其整合到奖励机制中。

Result: 实验表明，该框架能够促进本地P2P交易，降低用户成本，维持参与者之间的公平性，并保证效用可行性。敏感性分析也表明了其稳健的性能。

Conclusion: FairMarket-RL提供了一个可扩展的、由LLM指导的去中心化电力市场路径，实现了经济高效、社会公平和技术健全的目标。

Abstract: Peer-to-peer (P2P) energy trading is becoming central to modern distribution
systems as rooftop PV and home energy management systems become pervasive, yet
most existing market and reinforcement learning designs emphasize efficiency or
private profit and offer little real-time guidance to ensure equitable outcomes
under uncertainty. To address this gap, a fairness-aware multiagent
reinforcement learning framework, FairMarket-RL, is proposed in which a large
language model (LLM) critic shapes bidding policies within a continuous double
auction under partial observability and discrete price-quantity actions. After
each trading slot, the LLM returns normalized fairness scores Fairness-to-Grid
(FTG), Fairness-Between-Sellers (FBS), and Fairness-of-Pricing (FPP) that are
integrated into the reward via ramped coefficients and tunable scaling, so that
fairness guidance complements, rather than overwhelms, economic incentives. The
environment models realistic residential load and PV profiles and enforce hard
constraints on prices, physical feasibility, and policy-update stability.
Across a progression of experiments from a small pilot to a larger simulated
community and a mixed-asset real-world dataset, the framework shifts exchanges
toward local P2P trades, lowers consumer costs relative to grid-only
procurement, sustains strong fairness across participants, and preserves
utility viability. Sensitivity analyses over solar availability and aggregate
demand further indicate robust performance, suggesting a scalable, LLM-guided
pathway to decentralized electricity markets that are economically efficient,
socially equitable, and technically sound.

</details>


### [378] [Globally Stable Discrete Time PID Passivity-based Control of Power Converters: Simulation and Experimental Results](https://arxiv.org/abs/2508.18719)
*Alessio Moreschini,Wei He,Romeo Ortega,Yiheng Lu,Tao Li*

Main category: eess.SY

TL;DR: PID-PBC通过将PID控制器围绕一个被动输出进行封装，并使用保证其被动性的离散化方法，解决了在离散时间系统中保持全局稳定性的问题，并在电力转换器模型上进行了验证。


<details>
  <summary>Details</summary>
Motivation: PID-PBC的实际应用受到离散时间和离散化不保持被动性的两大因素的制约，需要对其进行改进以确保实际应用中的全局稳定性。

Method: 提出了一种保证PID离散化过程被动性的方法，并构建了一个新的输出以确保系统离散化后的被动性。利用隐式中点离散化方法，并证明了离散时间PID-PBC对于增量模型是无源映射，并建立了离散化电力转换器模型的移位无源性。

Result: 证明了结合了移位无源性和离散化PID-PBC的反馈互联具有全局稳定性，并通过仿真和实验验证了所提出离散化方法的性能。

Conclusion: 该研究为PID-PBC在离散时间系统中的应用提供了解决方案，解决了关键的离散化和被动性保持问题，并在电力转换器模型上取得了成功，为相关领域的实际应用提供了理论和实验支持。

Abstract: The key idea behind PID Passivity-based Control (PID-PBC) is to leverage the
passivity property of PIDs (for all positive gains) and wrap the PID controller
around a passive output to ensure global stability in closed-loop. However, the
practical applicability of PID-PBC is stymied by two key facts: (i) the vast
majority of practical implementations of PIDs is carried-out in discrete time
-- discretizing the continuous time dynamical system of the PID; (ii) the
well-known problem that passivity is not preserved upon discretization, even
with small sampling times. Therefore, two aspects of the PID-PBC must be
revisited for its safe practical application. First, we propose a
discretization of the PID that ensures its passivity. Second, since the output
that is identified as passive for the continuous time system is not necessarily
passive for its discrete time version, we construct a new output that ensures
the passivity property for the discretization of the system. In this paper, we
provide a constructive answer to both issues for the case of power converter
models. Instrumental to achieve this objective is the use of the implicit
midpoint discretization method -- which is a symplectic integration technique
that preserves system invariants. Since the reference value for the output to
be regulated in power converters is non-zero, we are henceforth interested in
the property of passivity of the incremental model -- currently known as
shifted passivity. Therefore, we demonstrate that the resulting discrete-time
PID-PBC defines a passive map for the incremental model and establish shifted
passivity for the discretized power converter model. Combining these
properties, we prove global stability for the feedback interconnection of the
power converter with the discretized PID-PBC. The paper also presents
simulations and experiments that demonstrate the performance of the proposed
discretization.

</details>


### [379] [Closed-Form Input Design for Identification under Output Feedback with Perturbation Constraints](https://arxiv.org/abs/2508.18813)
*Jingwei Hu,Dave Zachariah,Torbjörn Wigren,Petre Stoica*

Main category: eess.SY

TL;DR: 该论文提出了一种在线实验设计方法，用于在输出反馈下识别ARMAX模型，同时将输出扰动限制在用户指定的范围内。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，为了保证系统的安全性或维持运行，必须在输出反馈下进行系统识别实验。

Method: 通过向由固定输出反馈控制器生成的输入信号添加有界扰动，来在线设计信息性实验。该方法将产生的输出扰动约束在用户指定的范围内，并能以闭式形式高效计算。

Result: 通过两个数值实验证明了该方法的有效性。

Conclusion: 该方法为在输出反馈条件下进行ARMAX模型系统识别提供了一种有效且计算高效的实验设计方案。

Abstract: In many applications, system identification experiments must be performed
under output feedback to ensure safety or to maintain system operation. In this
paper, we consider the online design of informative experiments for ARMAX
models by applying a bounded perturbation to the input signal generated by a
fixed output feedback controller. Specifically, the design constrains the
resulting output perturbation within user-specified limits and can be
efficiently computed in closed form. We demonstrate the effectiveness of the
method in two numerical experiments.

</details>


### [380] [Performance Analysis of Underwater Optical Wireless Communication Using O-RIS and Fiber Optic Backhaul (Extended version)](https://arxiv.org/abs/2508.18915)
*Aboozar Heydaribeni,Hamzeh Beyranvand*

Main category: eess.SY

TL;DR: 该论文提出了一种混合水下无线光通信（UWOC）系统，结合了水下光接入点（UOAP）和基于无源光网络（PON）的光纤骨干网，以提供弹性骨干网。采用了直接链路和光可重构智能表面（O-RIS）辅助链路之间的硬切换机制，以确保可靠的连接。该系统在主动和多个无源O-RIS配置下进行了评估。为了提高可靠性，应用了选择组合（SC）和最大比组合（MRC）方案。分析和模拟结果表明，最佳的O-RIS放置可以显著提高系统性能。然而，在 А линейном режиме, 将其放置在离接收器太近的位置会导致性能下降，因为在相同水类型下，路径损耗和光束抖动会增加。此外，在实际限制内增加O-RIS元件的数量可以进一步提高整体系统性能，并增强对水下通道变化的适应性。


<details>
  <summary>Details</summary>
Motivation: 为了提供弹性骨干网，需要一种结合了水下光接入点（UOAP）和基于无源光网络（PON）的光纤骨干网的混合水下无线光通信（UWOC）系统。

Method: 该研究提出了一种混合UWOC系统，并采用硬切换机制在直接和O-RIS辅助链路之间切换，以确保可靠连接。该系统在主动和多个无源O-RIS配置下进行了评估，并应用了SC和MRC方案来提高可靠性。

Result: 分析和模拟结果表明，最佳O-RIS放置可以显著提高系统性能。在 А линейном режиме, 将O-RIS放置在离接收器太近的位置会导致性能下降，因为路径损耗和光束抖动会增加。增加O-RIS元件的数量可以进一步提高整体系统性能和信道适应性。

Conclusion: 最佳O-RIS放置对于提高UWOC系统性能至关重要，但需要避免将其放置在离接收器太近的位置。增加O-RIS元件的数量可以在实际限制内提高系统性能和信道适应性。

Abstract: This Letter presents a novel hybrid underwater wireless optical communication
(UWOC) system that integrates underwater optical access points (UOAPs) with a
passive optical network (PON)-based fiber-optic backhaul to provide a resilient
backbone. A hard switching mechanism is employed between direct and optical
reconfigurable intelligent surface (O-RIS)-assisted links to ensure reliable
connectivity. Unlike previous studies, the proposed system is evaluated under
both active and multiple passive O-RIS configurations. To enhance reliability,
the Selection Combining (SC) and Maximal Ratio Combining (MRC) schemes are
applied. Analytical and simulation results demonstrate that optimal O-RIS
placement significantly enhances system performance. However, in the linear
regime, placing it too close to the receiver causes degradation due to
increased path loss and beam jitter in an identical water type. Moreover,
increasing the number of O-RIS elements within practical limits further
improves overall system performance and enhances adaptability to variations in
the underwater channel.

</details>


### [381] [A Principled Framework to Evaluate Quality of AC-OPF Datasets for Machine Learning: Benchmarking a Novel, Scalable Generation Method](https://arxiv.org/abs/2508.19083)
*Matteo Baù,Luca Perbellini,Samuele Grillo*

Main category: eess.SY

TL;DR: 该研究通过提出一种新的负荷采样启发式方法和基于三个指标的多标准评估框架，解决了大规模电力系统交流最优潮流（AC-OPF）数据集生成的可扩展性和质量评估问题。该方法在数据集质量和可扩展性之间取得了最佳平衡，优于其他四种开源方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高用于机器学习的AC-OPF数据集质量，并解决现有方法在大规模电力系统中的可扩展性问题以及缺乏统一的质量评估指标的问题。

Method: 提出了一种简单的启发式方法，通过在总负荷有功功率中均匀采样负荷设定点，并采用带负荷松弛变量的AC-OPF公式来提高收敛性。同时，建立了一个基于三个指标（AC-OPF原始变量边际分布变异性、AC-OPF实例约束激活模式多样性、变量边界激活频率）的多标准评估框架。

Result: 与均匀随机采样（独立或约束于凸多面体）相比，所提出的启发式方法在数据集质量和可扩展性之间取得了最佳平衡，在四种开源方法的比较中表现最佳。

Conclusion: 所提出的负荷采样启发式方法和多标准评估框架有效解决了AC-OPF数据集生成的可扩展性和质量评估问题，并提供了比现有方法更好的性能。

Abstract: Several methods have been proposed in the literature to improve the quality
of AC optimal power flow (AC-OPF) datasets used in machine learning (ML)
models. Yet, scalability to large power systems remains unaddressed and
comparing generation approaches is still hindered by the absence of widely
accepted metrics quantifying AC-OPF dataset quality. In this work, we tackle
both these limitations. We provide a simple heuristic that samples load
setpoints uniformly in total load active power, rather than maximizing volume
coverage, and solves an AC-OPF formulation with load slack variables to improve
convergence. For quality assessment, we formulate a multi-criteria framework
based on three metrics, measuring variability in the marginal distributions of
AC-OPF primal variables, diversity in constraint activation patterns among
AC-OPF instances and activation frequency of variable bounds. By comparing four
open-source methods based on these metrics, we show that our heuristic
consistently outperforms uniform random sampling, whether independent or
constrained to a convex polytope, scoring as best in terms of balance between
dataset quality and scalability.

</details>


### [382] [Learning Interior Point Method for AC and DC Optimal Power Flow](https://arxiv.org/abs/2508.19146)
*Farshad Amani,Amin Kargarian,Ramachandran Vaidyanathan*

Main category: eess.SY

TL;DR: 提出了一种混合学习模型方法，通过LSTM网络预测IPM中心路径，减少了OPM问题的迭代次数和求解时间，同时保证了可行性。


<details>
  <summary>Details</summary>
Motivation: 传统的IPM方法在求解最优潮流（OPF）问题时，在迭代后期需要求解大型线性系统，计算成本高且矩阵病态。

Method: 提出了一种可行的学习内点法（L-IPM），该方法使用混合学习模型，将IPM轨迹建模为时间序列，并训练长短期记忆（LSTM）网络来预测IPM中心路径。通过引入网格信息方法来强制执行运行约束，确保可行性。通过采样方法生成广泛的负载场景以提高泛化能力。

Result: L-IPM将求解时间减少了高达94%，并将所需迭代次数减少了高达85.5%，同时保持了溶液的准确性和可行性。

Conclusion: L-IPM通过利用早期迭代并绕过传统IPM最后病态且计算量大的步骤，在计算效率和鲁棒性方面均优于传统IPM。

Abstract: This paper proposes a feasibility-guaranteed learning interior point method
(L-IPM) to solve both AC and DC optimal power flow (OPF) problems. Given the
criticality of OPF, the proposed L-IPM uses a hybrid learning model approach
rather than relying solely on a simple black-box prediction. The traditional
IPM follows a central path from an initial point to the optimal solution.
However, each iteration involves solving large linear systems, which becomes
increasingly expensive as the matrices grow more ill-conditioned in later
steps. To address this, we model the IPM trajectory as a time series and train
a Long Short-Term Memory (LSTM) network to project the IPM central path using
only the first few stable iterations, which carry the most informative features
about the path to optimality. We introduce a grid-informed methodology that
enforces operational constraints on generation, voltage magnitudes, and line
flows to ensure feasibility. The grid-informed LSTM serves as a tool for the
IPM central path projection and, followed by a final IPM refinement step,
significantly reduces the total number of iterations and time required for
convergence. We use a sampling method to generate a wide range of load
scenarios to improve generalization across diverse operating conditions,
efficiently covering the power system's operational space. Simulation results
on a 2869-bus European high-voltage transmission system show that the proposed
L-IPM significantly reduces solution time by up to 94\%, while maintaining
accuracy and feasibility of the solution. By leveraging early iterations and
bypassing the final ill-conditioned and computationally demanding steps of
traditional IPM, the proposed L-IPM reduces the number of required iterations
by up to 85.5\%. Since solution feasibility is also guaranteed, L-IPM
outperforms the conventional IPM in both computational efficiency and
robustness.

</details>


### [383] [Safe Navigation under State Uncertainty: Online Adaptation for Robust Control Barrier Functions](https://arxiv.org/abs/2508.19159)
*Ersin Das,Rahal Nanayakkara,Xiao Tan,Ryan M. Bena,Joel W. Burdick,Paulo Tabuada,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本研究提出了一种改进鲁棒控制障碍函数（R-CBF）的方法，通过在线参数自适应和将多个安全约束统一为单个CBF来减少保守性，并解决了车辆跟踪中的双重相对度问题，在实验中证明了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 控制实践中的测量和状态估计不准确，对依赖精确状态信息的安全关键应用构成挑战。现有的鲁棒控制障碍函数（R-CBF）在存在估计误差时，对输入施加了严格的条件，可能过于保守并导致不可行性或高控制功耗等问题。

Method: 提出了一种系统性的方法来改进R-CBF，其核心是一个新的基于优化的在线参数自适应方案，以减少R-CBF的保守性。为了降低参数优化的复杂性，将多个安全约束通过泊松方程合并为一个统一的数值CBF。此外，还解决了通常会给车辆跟踪带来困难的双重相对度问题。

Result: 实验结果表明，所提出的方法在跟踪多个障碍物的车辆导航任务上，其整体性能优于现有的R-CBF方法。

Conclusion: 本研究提出的改进R-CBF方法，通过在线参数自适应和统一安全约束，有效降低了保守性并解决了双重相对度问题，在实际应用中展现出优越的性能。

Abstract: Measurements and state estimates are often imperfect in control practice,
posing challenges for safety-critical applications, where safety guarantees
rely on accurate state information. In the presence of estimation errors,
several prior robust control barrier function (R-CBF) formulations have imposed
strict conditions on the input. These methods can be overly conservative and
can introduce issues such as infeasibility, high control effort, etc. This work
proposes a systematic method to improve R-CBFs, and demonstrates its advantages
on a tracked vehicle that navigates among multiple obstacles. A primary
contribution is a new optimization-based online parameter adaptation scheme
that reduces the conservativeness of existing R-CBFs. In order to reduce the
complexity of the parameter optimization, we merge several safety constraints
into one unified numerical CBF via Poisson's equation. We further address the
dual relative degree issue that typically causes difficulty in vehicle
tracking. Experimental trials demonstrate the overall performance improvement
of our approach over existing formulations.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [384] [Integral Online Algorithms for Set Cover and Load Balancing with Convex Objectives](https://arxiv.org/abs/2508.18383)
*Thomas Kesselheim,Marco Molinaro,Kalen Patton,Sahil Singla*

Main category: cs.DS

TL;DR: 该论文提出了针对在线集合覆盖和负载均衡问题的整数在线算法，解决了现有分数设置下算法的整数差距问题，并将结果推广到更广泛的范畴，包括在线广义调度问题和范数组合设置。


<details>
  <summary>Details</summary>
Motivation: 现有在线优化算法（如在线集合覆盖和负载均衡）在处理具有凸目标的范数时，受限于整数差距问题，无法直接应用于整数设置。本研究旨在设计直接的整数在线算法，以克服这些限制。

Method: 论文首先将问题转化为在线打包问题，然后设计了解决这些打包问题的近似算法。关键技术包括将全局打包问题分解为局部问题，并采用随机激活阈值策略，以提高激活机器覆盖作业的期望数量与成本的比例。

Result: 1. 成功将Azar等人（2016）和Kesselheim等人（2024）在凸目标和对称范数下的在线集合覆盖结果从分数设置扩展到整数设置。
2. 提出的方法适用于在线广义调度问题，这是集合覆盖和负载均衡的推广，解决了先前工作中仅能处理离线版本的问题。
3. 方法可轻松扩展至范数不相交组合设置，恢复或改进了Nagarajan和Shen（2020）以及Kesselheim等人（2024）的范数组合结果，并将结果扩展到对称范数以外的更广泛范畴。

Conclusion: 本研究成功开发了解决在线集合覆盖和负载均衡问题的整数在线算法，通过将问题转化为在线打包问题并采用局部化和随机化策略，克服了现有方法的局限性，并将成果推广到更广泛的在线优化问题。

Abstract: Online Set Cover and Load Balancing are central problems in online
optimization, and there is a long line of work on developing algorithms for
these problems with convex objectives. Although we know optimal online
algorithms with $\ell_p$-norm objectives, recent developments for general norms
and convex objectives that rely on the online primal-dual framework apply only
to fractional settings due to large integrality gaps.
  Our work focuses on directly designing integral online algorithms for Set
Cover and Load Balancing with convex objectives, bypassing the
convex-relaxation and the primal-dual technique. Some of the main implications
are:
  1. For Online Set Cover, we can extend the results of Azar et. al. (2016) for
convex objectives and of Kesselheim, Molinaro, and Singla (2024) for symmetric
norms from fractional to integral settings.
  2. Our results for convex objectives and symmetric norms even apply to the
online generalized scheduling problem, which generalizes both Set Cover and
Load Balancing. Previous works could only handle the offline version of this
problem with norm objectives (Deng, Li, and Rabani 2023).
  3. Our methods easily extend to settings with disjoint-composition of norms.
This allows us to recover or improve the norm-composition results of Nagarajan
and Shen (2020), and Kesselheim, Molinaro, and Singla (2024), and to extend our
results to a large class of norms beyond symmetric.
  Our approach is to first reduce these problems to online packing problems,
and then to design good approximation algorithms for the latter. To solve these
packing problems, we use two key ideas. First, we decouple the global packing
problem into a series of local packing problems on different machines. Next, we
choose random activation thresholds for machines such that conditional on a
machine being activated, the expected number of jobs it covers is high compared
to its cost.

</details>


### [385] [Improving Pinwheel Density Bounds for Small Minimums](https://arxiv.org/abs/2508.18422)
*Ahan Mishra,Parker Rho,Robert Kleinberg*

Main category: cs.DS

TL;DR: 密度界限对于m=4的pinwheel实例为0.84，这是第一个m大于5/6的实例。


<details>
  <summary>Details</summary>
Motivation: 研究pinwheel实例的密度界限随m变化的“密度缺口”问题，并为m=4的实例提供一个优于5/6的密度界限。

Method: 开发新的技术，包括基于启发式算法的pinwheel求解器和一种展开操作。

Result: 证明了m=4的pinwheel实例的密度界限为0.84，这是第一个严格优于5/6的界限。

Conclusion: m=4的pinwheel实例的密度界限为0.84，这表明对于特定的m值，可以获得比通用界限更好的性能。

Abstract: The density bound for schedulability for general pinwheel instances is
$\frac{5}{6}$, but density bounds better than $\frac{5}{6}$ can be shown for
cases in which the minimum element $m$ of the instance is large. Several recent
works have studied the question of the 'density gap' as a function of $m$, with
best known lower and upper bounds of $O \left( \frac{1}{m} \right)$ and $O
\left( \frac{1}{\sqrt{m}} \right)$. We prove a density bound of $0.84$ for $m =
4$, the first $m$ for which a bound strictly better than $\frac{5}{6} =
0.8\overline{3}$ can be proven. In doing so, we develop new techniques,
particularly a fast heuristic-based pinwheel solver and an unfolding operation.

</details>


### [386] [Hypergraph Splitting-Off via Element-Connectivity Preserving Reductions](https://arxiv.org/abs/2508.18637)
*Karthekeyan Chandrasekaran,Chandra Chekuri,Shubhang Kulkarni*

Main category: cs.DS

TL;DR: B'erczi et al. (ICALP 2024) introduced a splitting-off procedure for hypergraphs that maintains local-connectivity. This note provides an alternative proof using element-connectivity preserving reduction operations in graphs.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide an alternative proof for the splitting-off procedure in hypergraphs described by B'erczi et al. (ICALP 2024), which preserves local-connectivity.

Method: The method involves using element-connectivity preserving reduction operations in graphs as an alternative approach to proving the splitting-off procedure.

Result: The result is an alternative proof, achieved through graph-based reduction operations, for the splitting-off procedure in hypergraphs that preserves local-connectivity.

Conclusion: The paper offers a new perspective and proof method for the splitting-off procedure in hypergraphs by leveraging graph theory concepts.

Abstract: B\'erczi, Chandrasekaran, Kir\'aly, and Kulkarni (ICALP 2024) recently
described a splitting-off procedure in hypergraphs that preserves
local-connectivity and outlined some applications. In this note we give an
alternative proof via element-connectivity preserving reduction operations in
graphs.

</details>


### [387] [Graph Traversal via Connected Mobile Agents](https://arxiv.org/abs/2508.18683)
*Saswata Jana,Giuseppe F. Italiano,Partha Sarathi Mandal*

Main category: cs.DS

TL;DR: 该论文研究了多智能体协调框架下的汉密尔顿路径问题（k-Agents Hamiltonian Walk Problem, k-HWP），目标是让k个智能体协同计算给定无向图的生成路径，并最小化步数。智能体在每一步都占据不同的顶点，并且被占据顶点诱导的子图保持连通。每一步智能体可保持不动或移动到邻近顶点。该问题是NP难问题。研究提出了一个针对2-HWP在任意图上的(3-1/21)-近似算法，并为树上的受限问题设计了一个针对任意k值的最优算法。此外，论文还为k-均匀超图上的k-HWP提出了一个2(1+ln k)-近似算法，并将此结果应用于k=O(1)时一般图上的k-HWP近似算法设计。


<details>
  <summary>Details</summary>
Motivation: 在多智能体协调框架下，研究以前未探索过的k-Agents Hamiltonian Walk Problem (k-HWP)，这是著名汉密尔顿路径问题的多智能体泛化。

Method: 提出一个(3-1/21)-近似算法用于2-HWP在任意图上；为树上的受限问题设计了一个最优算法；为k-均匀超图上的k-HWP提出了一个2(1+ln k)-近似算法；并将该结果应用于k=O(1)时一般图上的k-HWP近似算法。

Result: 对于2-HWP在任意图上，提出了一个(3-1/21)-近似算法；对于树上的受限问题，提出了最优算法；对于k-均匀超图上的k-HWP，提出了一个2(1+ln k)-近似算法；对于k=O(1)时一般图上的k-HWP，也提出了近似算法。

Conclusion: k-HWP在多智能体协调框架下是一个NP难问题，但论文成功为不同情况（2-HWP、树、k-均匀超图、k=O(1)的一般图）设计了近似算法，并在理论上进行了分析。

Abstract: This paper considers the Hamiltonian walk problem in the multi-agent
coordination framework, referred to as $k$-agents Hamiltonian walk problem
($k$-HWP). In this problem, a set of $k$ connected agents collectively compute
a spanning walk of a given undirected graph in the minimum steps. At each step,
the agents are at $k$ distinct vertices and the induced subgraph made by the
occupied vertices remains connected. In the next consecutive steps, each agent
may remain stationary or move to one of its neighbours.To the best of our
knowledge, this problem has not been previously explored in the context of
multi-agent systems with connectivity. As a generalization of the well-known
Hamiltonian walk problem (when $k=1$), $k$-HWP is NP-hard. We propose a
$(3-\frac{1}{21})$-approximation algorithm for 2-HWP on arbitrary graphs. For
the tree, we define a restricted version of the problem and present an optimal
algorithm for arbitrary values of $k$. Finally, we formalize the problem for
$k$-uniform hypergraphs and present a $2(1+\ln k)$-approximation algorithm.
This result is also adapted to design an approximation algorithm for $k$-HWP on
general graphs when $k = O(1)$.

</details>


### [388] [Max-Min and 1-Bounded Space Algorithms for the Bin Packing Problem](https://arxiv.org/abs/2508.18718)
*Hiroshi Fujiwara,Rina Atsumi,Hiroaki Yamamoto*

Main category: cs.DS

TL;DR: 该论文证明了Zhu提出的MM算法在1维装箱问题上的渐近近似比至多为1.5，并分析了MM算法所属的两个算法子类（最大-最小算法和1有界空间算法）的理论性能界限，给出了这两个子类交集的下界为1.25，同时还将该理论分析扩展到了基数约束装箱问题。


<details>
  <summary>Details</summary>
Motivation: 分析Zhu提出的MM算法在1维装箱问题上的性能，特别是其渐近近似比，并探讨其所属算法子类的理论性能界限，最终扩展到基数约束装箱问题。

Method: 对MM算法的渐近近似比进行理论证明，分析最大-最小算法和1有界空间算法子类的性能界限，并推导了它们的交集的下界，最后将分析扩展到基数约束装箱问题。

Result: 证明了MM算法的渐近近似比至多为1.5，给出了两个算法子类交集的下界为1.25。

Conclusion: MM算法的渐近近似比至多为1.5，对MM算法所属的两个算法子类的理论性能界限进行了分析，并得出了它们交集的下界为1.25，同时成功将该理论分析扩展到了基数约束装箱问题。

Abstract: In the (1-dimensional) bin packing problem, we are asked to pack all the
given items into bins, each of capacity one, so that the number of non-empty
bins is minimized. Zhu~[Chaos, Solitons \& Fractals 2016] proposed an
approximation algorithm $MM$ that sorts the item sequence in a non-increasing
order by size at the beginning, and then repeatedly packs, into the current
single open bin, first as many of the largest items in the remaining sequence
as possible and then as many of the smallest items in the remaining sequence as
possible. In this paper we prove that the asymptotic approximation ratio of
$MM$ is at most 1.5. Next, focusing on the fact that $MM$ is at the
intersection of two algorithm classes, max-min algorithms and 1-bounded space
algorithms, we comprehensively analyze the theoretical performance bounds of
each subclass derived from the two classes. Our results include a lower bound
of 1.25 for the intersection of the two classes. Furthermore, we extend the
theoretical analysis over algorithm classes to the cardinality constrained bin
packing problem.

</details>


### [389] [DTC: Real-Time and Accurate Distributed Triangle Counting in Fully Dynamic Graph Streams](https://arxiv.org/abs/2508.19057)
*Wei Xuan,Yan Liang,Huawei Cao,Ning Lin,Xiaochun Ye,Dongrui Fan*

Main category: cs.DS

TL;DR: 该论文提出了一种名为DTC的新型单遍分布式流算法，用于处理动态图流中的全局和局部三角形计数问题。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式流算法在处理大规模图流时，尤其是在边删除的情况下，缺乏适应性，而精确计数又难以实现。

Method: 提出DTC算法家族，包括用于精确估计的DTC-AR和用于处理完全动态图流（支持边插入和删除）的DTC-FD。DTC-FD利用随机配对和未来边插入补偿技术，实现了无偏和准确的近似。

Result: 实验结果显示，DTC-AR的准确性比基线方法提高了2029.4倍，同时保持了准确性和存储空间之间的最佳权衡。DTC-FD将估计误差降低了32.5倍，并且随着图流大小的增加，其性能呈线性扩展。

Conclusion: 所提出的DTC-AR和DTC-FD算法在处理动态图流中的三角形计数问题方面，相比现有方法具有显著的优势，能够有效地解决现实世界中的挑战。

Abstract: Triangle counting is a fundamental problem in graph mining, essential for
analyzing graph streams with arbitrary edge orders. However, exact counting
becomes impractical due to the massive size of real-world graph streams. To
address this, approximate algorithms have been developed, but existing
distributed streaming algorithms lack adaptability and struggle with edge
deletions. In this article, we propose DTC, a novel family of single-pass
distributed streaming algorithms for global and local triangle counting in
fully dynamic graph streams. Our DTC-AR algorithm accurately estimates triangle
counts without prior knowledge of graph size, leveraging multi-machine
resources. Additionally, we introduce DTC-FD, an algorithm tailored for fully
dynamic graph streams, incorporating edge insertions and deletions. Using
Random Pairing and future edge insertion compensation, DTC-FD achieves unbiased
and accurate approximations across multiple machines. Experimental results
demonstrate significant improvements over baselines. DTC-AR achieves up to
$2029.4\times$ and $27.1\times$ more accuracy, while maintaining the best
trade-off between accuracy and storage space. DTC-FD reduces estimation errors
by up to $32.5\times$ and $19.3\times$, scaling linearly with graph stream
size. These findings highlight the effectiveness of our proposed algorithms in
tackling triangle counting in real-world scenarios. The source code and
datasets are released and available at
\href{https://github.com/wayne4s/srds-dtc.git}{https://github.com/wayne4s/srds-dtc.git}.

</details>


### [390] [Approximating High-Dimensional Earth Mover's Distance as Fast as Closest Pair](https://arxiv.org/abs/2508.06774)
*Lorenzo Beretta,Vincent Cohen-Addad,Rajesh Jayaram,Erik Waingarten*

Main category: cs.DS

TL;DR: This paper presents a reduction from approximate Earth Mover's Distance (EMD) to approximate Closest Pair (CP), leading to improved approximation algorithms for high-dimensional EMD.


<details>
  <summary>Details</summary>
Motivation: To improve the fastest known approximation algorithm for high-dimensional EMD by reducing it to the Closest Pair problem.

Method: The paper provides a reduction from $(1+\varepsilon)$-approximate EMD to $(1+\varepsilon)$-approximate Closest Pair (CP). A key technical contribution is a sublinear implementation of the Multiplicative Weights Update framework for EMD, where updates are performed implicitly by exploiting geometric structure.

Result: A $(1+\varepsilon)$-approximation algorithm for EMD is achieved in $n^{2-\tilde{\Omega}(\varepsilon^{1/3})}$ time, improving over the previous $n^{2-\Omega(\varepsilon^2)}$.

Conclusion: The proposed reduction and implicit update method offer a significant improvement in the efficiency of approximating high-dimensional EMD.

Abstract: We give a reduction from $(1+\varepsilon)$-approximate Earth Mover's Distance
(EMD) to $(1+\varepsilon)$-approximate Closest Pair (CP). As a consequence, we
improve the fastest known approximation algorithm for high-dimensional EMD.
Here, given $p\in [1, 2]$ and two sets of $n$ points $X,Y \subseteq (\mathbb
R^d,\ell_p)$, their EMD is the minimum cost of a perfect matching between $X$
and $Y$, where the cost of matching two vectors is their $\ell_p$ distance.
Further, CP is the basic problem of finding a pair of points realizing $\min_{x
\in X, y\in Y} ||x-y||_p$. Our contribution is twofold: we show that if a
$(1+\varepsilon)$-approximate CP can be computed in time $n^{2-\phi}$, then a
$1+O(\varepsilon)$ approximation to EMD can be computed in time
$n^{2-\Omega(\phi)}$; plugging in the fastest known algorithm for CP [Alman,
Chan, Williams FOCS'16], we obtain a $(1+\varepsilon)$-approximation algorithm
for EMD running in time $n^{2-\tilde{\Omega}(\varepsilon^{1/3})}$ for
high-dimensional point sets, which improves over the prior fastest running time
of $n^{2-\Omega(\varepsilon^2)}$ [Andoni, Zhang FOCS'23]. Our main technical
contribution is a sublinear implementation of the Multiplicative Weights Update
framework for EMD. Specifically, we demonstrate that the updates can be
executed without ever explicitly computing or storing the weights; instead, we
exploit the underlying geometric structure to perform the updates implicitly.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [391] [Federative ischemic stroke segmentation as alternative to overcome domain-shift multi-institution challenges](https://arxiv.org/abs/2508.18296)
*Edgar Rangel,Fabio Martinez*

Main category: eess.IV

TL;DR: 该研究提出了一种联邦学习框架，用于分割缺血性脑卒中病灶，解决了单一模型泛化能力不足和数据量不足的问题。


<details>
  <summary>Details</summary>
Motivation: 临床脑卒中病灶分割在不同患者、设备和标注者之间存在变异性，现有的计算方法因仅从单一机构学习而泛化能力不足，且许多中心缺乏足够标注数据。

Method: 提出了一种基于联邦学习的框架，通过共享深度中心无关表示来分割缺血性脑卒中病灶。

Result: 在14个模拟医疗中心（2031个研究）的联邦平均（FedAvg）模型，在所有中心实现了0.71 ± 0.24的DSC、5.29 ± 22.74的AVD、2.16 ± 3.60的ALD和0.70 ± 0.26的LF1，优于集中式和其他联邦方法。该模型还表现出良好的泛化能力，在不同病灶类别中表现一致，并且在分布外中心（无额外训练）也达到了0.64 ± 0.29的DSC和4.44 ± 8.74的AVD。

Conclusion: 该研究提出的联邦学习框架能够有效分割缺血性脑卒中病灶，并具有良好的泛化能力，能够克服数据孤岛和数据量不足的问题。

Abstract: Stroke is the second leading cause of death and the third leading cause of
disability worldwide. Clinical guidelines establish diffusion resonance imaging
(DWI, ADC) as the standard for localizing, characterizing, and measuring
infarct volume, enabling treatment support and prognosis. Nonetheless, such
lesion analysis is highly variable due to different patient demographics,
scanner vendors, and expert annotations. Computational support approaches have
been key to helping with the localization and segmentation of lesions. However,
these strategies are dedicated solutions that learn patterns from only one
institution, lacking the variability to generalize geometrical lesions shape
models. Even worse, many clinical centers lack sufficient labeled samples to
adjust these dedicated solutions. This work developed a collaborative framework
for segmenting ischemic stroke lesions in DWI sequences by sharing knowledge
from deep center-independent representations. From 14 emulated healthcare
centers with 2031 studies, the FedAvg model achieved a general DSC of $0.71 \pm
0.24$, AVD of $5.29 \pm 22.74$, ALD of $2.16 \pm 3.60$ and LF1 of $0.70 \pm
0.26$ over all centers, outperforming both the centralized and other federated
rules. Interestingly, the model demonstrated strong generalization properties,
showing uniform performance across different lesion categories and reliable
performance in out-of-distribution centers (with DSC of $0.64 \pm 0.29$ and AVD
of $4.44 \pm 8.74$ without any additional training).

</details>


### [392] [Analise de Desaprendizado de Maquina em Modelos de Classificacao de Imagens Medicas](https://arxiv.org/abs/2508.18509)
*Andreza M. C. Falcao,Filipe R. Cordeiro*

Main category: eess.IV

TL;DR: SalUn 是一种机器学习模型，可以从预训练模型中删除数据，同时保持模型的鲁棒性。本研究评估了 SalUn 在 PathMNIST、OrganAMNIST 和 BloodMNIST 数据集上的表现，并分析了数据增强对学习质量的影响。结果表明，SalUn 的表现接近完全重新训练，表明它是在医疗应用中有效删除数据的解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在医疗领域的应用需要能够从预训练模型中删除敏感数据（例如，患者数据）的技术，同时保持模型的鲁棒性。然而，机器学习的卸载技术尚未在医学图像分类领域得到探索。

Method: 本研究评估了 SalUn 机器学习卸载模型在 PathMNIST、OrganAMNIST 和 BloodMNIST 数据集上的表现。此外，本研究还分析了数据增强对机器学习卸载质量的影响。

Result: SalUn 在 PathMNIST、OrganAMNIST 和 BloodMNIST 数据集上的表现接近完全重新训练，表明它是在医疗应用中有效删除数据的解决方案。

Conclusion: SalUn 是一种有效的机器学习卸载模型，可用于医疗应用。

Abstract: Machine unlearning aims to remove private or sensitive data from a
pre-trained model while preserving the model's robustness. Despite recent
advances, this technique has not been explored in medical image classification.
This work evaluates the SalUn unlearning model by conducting experiments on the
PathMNIST, OrganAMNIST, and BloodMNIST datasets. We also analyse the impact of
data augmentation on the quality of unlearning. Results show that SalUn
achieves performance close to full retraining, indicating an efficient solution
for use in medical applications.

</details>


### [393] [A Deep Learning Application for Psoriasis Detection](https://arxiv.org/abs/2508.18528)
*Anna Milani,Fábio S. da Silva,Elloá B. Guedes,Ricardo Rios*

Main category: eess.IV

TL;DR: 本文比较了ResNet50、Inception v3和VGG19三种卷积神经网络模型在识别银屑病皮肤病变图像方面的性能，并对模型进行了评估指标调整。


<details>
  <summary>Details</summary>
Motivation: 本文旨在比较三种卷积神经网络模型（ResNet50、Inception v3和VGG19）在识别银屑病皮肤病变图像方面的性能。

Method: 比较了ResNet50、Inception v3和VGG19三种卷积神经网络模型在识别银屑病皮肤病变图像方面的性能，并对模型进行了评估指标调整。

Result: Inception v3模型在准确率和F1-Score方面表现出令人满意的性能（97.5% ± 0.2），是诊断银屑病的有价值工具。

Conclusion: Inception v3模型在识别银屑病皮肤病变方面表现出色，可作为辅助诊断工具。

Abstract: In this paper a comparative study of the performance of three Convolutional
Neural Network models, ResNet50, Inception v3 and VGG19 for classification of
skin images with lesions affected by psoriasis is presented. The images used
for training and validation of the models were obtained from specialized
platforms. Some techniques were used to adjust the evaluation metrics of the
neural networks. The results found suggest the model Inception v3 as a valuable
tool for supporting the diagnosis of psoriasis. This is due to its satisfactory
performance with respect to accuracy and F1-Score (97.5% ${\pm}$ 0.2).

</details>


### [394] [A Closer Look at Edema Area Segmentation in SD-OCT Images Using Adversarial Framework](https://arxiv.org/abs/2508.18790)
*Yuhui Tao,Yizhe Zhang,Qiang Chen*

Main category: eess.IV

TL;DR: 该研究提出了一种结合层结构信息和测试时自适应（TTA）的弱监督方法，用于视网膜黄斑水肿（ME）区域（EA）分割，以提高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于专家标注的像素级图像数据集成本高昂，现有的基于异常检测的弱监督方法在EA分割任务上的性能仍落后于全监督方法。本研究旨在利用EA与眼底图像中视网膜层之间的强相关性以及弱监督学习的更新特性，来改进现有的对抗性框架。

Method: 提出了一种结合层结构信息和测试时自适应（TTA）策略的改进型对抗性框架。该框架通过引入额外的视网膜层信息，将EA预测任务重构为确认EA轮廓与视网膜层交点的任务，并利用TTA解决训练集和测试集之间EA表现的差异。

Result: 实验结果表明，所提出的层结构引导后处理和TTA策略能够提高EA分割的准确性和鲁棒性，缩小了弱监督与全监督模型之间的性能差距。

Conclusion: 该研究提出的结合层结构信息和TTA策略的弱监督方法，在视网膜黄斑水肿区域分割任务上取得了显著成效，能够有效提高模型性能并缩小与全监督方法的差距。

Abstract: The development of artificial intelligence models for macular edema (ME)
analy-sis always relies on expert-annotated pixel-level image datasets which
are expen-sive to collect prospectively. While anomaly-detection-based
weakly-supervised methods have shown promise in edema area (EA) segmentation
task, their per-formance still lags behind fully-supervised approaches. In this
paper, we leverage the strong correlation between EA and retinal layers in
spectral-domain optical coherence tomography (SD-OCT) images, along with the
update characteristics of weakly-supervised learning, to enhance an
off-the-shelf adversarial framework for EA segmentation with a novel
layer-structure-guided post-processing step and a test-time-adaptation (TTA)
strategy. By incorporating additional retinal lay-er information, our framework
reframes the dense EA prediction task as one of confirming intersection points
between the EA contour and retinal layers, result-ing in predictions that
better align with the shape prior of EA. Besides, the TTA framework further
helps address discrepancies in the manifestations and presen-tations of EA
between training and test sets. Extensive experiments on two pub-licly
available datasets demonstrate that these two proposed ingredients can im-prove
the accuracy and robustness of EA segmentation, bridging the gap between
weakly-supervised and fully-supervised models.

</details>


### [395] [Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data](https://arxiv.org/abs/2508.18975)
*Jan Nikolas Morshuis,Matthias Hein,Christian F. Baumgartner*

Main category: eess.IV

TL;DR: 该论文首次对用于分割欠采样 MRI 数据的各种方法进行了统一的基准测试，发现简单、考虑数据一致性的两阶段方法在分割任务上表现最佳。


<details>
  <summary>Details</summary>
Motivation: MRI 是一种有价值的诊断工具，但其成像速度慢，给患者带来不适并增加医疗成本。虽然有研究致力于加速 MRI 成像，但对于分割等下游任务，可能不需要完美的重建图像。因此，直接在加速 MRI 数据上进行分割引起了人们的兴趣。然而，现有方法在研究中各自为战，缺乏统一的比较和评估标准，导致最优分割策略未知。

Method: 本研究首次提供了一个统一的基准测试，用于评估 7 种分割欠采样 MRI 数据的方法。研究重点比较了将重建和分割结合在一起的“单阶段方法”与先使用成熟的 MRI 重建方法再进行分割的“两阶段方法”。在包含多线圈 k 空间数据和人工标注分割真值的两个 MRI 数据集上对这些方法进行了测试。

Result: 研究结果表明，简单的两阶段方法在分割任务上表现最佳，其分割分数超过了专门为此任务设计的复杂方法。特别是，那些考虑了数据一致性的两阶段方法表现最为优异。

Conclusion: 对于分割欠采样 MRI 数据，简单的两阶段方法，尤其是那些考虑数据一致性的方法，是比复杂单阶段方法更优越的选择。

Abstract: MR imaging is a valuable diagnostic tool allowing to non-invasively visualize
patient anatomy and pathology with high soft-tissue contrast. However, MRI
acquisition is typically time-consuming, leading to patient discomfort and
increased costs to the healthcare system. Recent years have seen substantial
research effort into the development of methods that allow for accelerated MRI
acquisition while still obtaining a reconstruction that appears similar to the
fully-sampled MR image. However, for many applications a perfectly
reconstructed MR image may not be necessary, particularly, when the primary
goal is a downstream task such as segmentation. This has led to growing
interest in methods that aim to perform segmentation directly on accelerated
MRI data. Despite recent advances, existing methods have largely been developed
in isolation, without direct comparison to one another, often using separate or
private datasets, and lacking unified evaluation standards. To date, no
high-quality, comprehensive comparison of these methods exists, and the optimal
strategy for segmenting accelerated MR data remains unknown. This paper
provides the first unified benchmark for the segmentation of undersampled MRI
data comparing 7 approaches. A particular focus is placed on comparing
\textit{one-stage approaches}, that combine reconstruction and segmentation
into a unified model, with \textit{two-stage approaches}, that utilize
established MRI reconstruction methods followed by a segmentation network. We
test these methods on two MRI datasets that include multi-coil k-space data as
well as a human-annotated segmentation ground-truth. We find that simple
two-stage methods that consider data-consistency lead to the best segmentation
scores, surpassing complex specialized methods that are developed specifically
for this task.

</details>


### [396] [RDDM: Practicing RAW Domain Diffusion Model for Real-world Image Restoration](https://arxiv.org/abs/2508.19154)
*Yan Chen,Yi Wen,Wei Li,Junchao Liu,Yong Guo,Jie Hu,Xinghao Chen*

Main category: eess.IV

TL;DR: RDDM是一个端到端的扩散模型，可以直接从传感器RAW数据恢复照片级逼真的图像，解决了现有sRGB域方法在高保真度和真实感生成之间的困境。


<details>
  <summary>Details</summary>
Motivation: 现有sRGB域扩散模型在处理有损sRGB输入时，无法充分利用传感器RAW图像，导致性能不佳。RDDM旨在直接在RAW域进行图像恢复，绕过传统的ISP+IR流程，并解决直接应用于RAW域时遇到的OOD问题。

Method: RDDM提出了(1)一个RAW域VAE (RVAE)来学习最优的潜在表示，(2)一个可微分的后色调处理 (PTP) 模块来实现RAW和sRGB空间的联合优化。此外，还开发了一个可扩展的退化流程来合成RAW LQ-HQ对，并设计了一个可配置的多拜耳 (CMB) LoRA模块来处理不同的RAW模式。

Result: 实验表明，RDDM在保真度和伪影数量方面优于最先进的sRGB扩散方法。

Conclusion: RDDM通过直接在RAW域进行图像恢复，并结合RVAE、PTP和CMB LoRA等技术，实现了比sRGB域方法更高保真度和更少伪影的图像恢复效果。

Abstract: We present the RAW domain diffusion model (RDDM), an end-to-end diffusion
model that restores photo-realistic images directly from the sensor RAW data.
While recent sRGB-domain diffusion methods achieve impressive results, they are
caught in a dilemma between high fidelity and realistic generation. As these
models process lossy sRGB inputs and neglect the accessibility of the sensor
RAW images in many scenarios, e.g., in image and video capturing in edge
devices, resulting in sub-optimal performance. RDDM bypasses this limitation by
directly restoring images in the RAW domain, replacing the conventional
two-stage image signal processing (ISP) + IR pipeline. However, a simple
adaptation of pre-trained diffusion models to the RAW domain confronts the
out-of-distribution (OOD) issues. To this end, we propose: (1) a RAW-domain VAE
(RVAE) learning optimal latent representations, (2) a differentiable Post Tone
Processing (PTP) module enabling joint RAW and sRGB space optimization. To
compensate for the deficiency in the dataset, we develop a scalable degradation
pipeline synthesizing RAW LQ-HQ pairs from existing sRGB datasets for
large-scale training. Furthermore, we devise a configurable multi-bayer (CMB)
LoRA module handling diverse RAW patterns such as RGGB, BGGR, etc. Extensive
experiments demonstrate RDDM's superiority over state-of-the-art sRGB diffusion
methods, yielding higher fidelity results with fewer artifacts.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [397] [Leveraging Evolutionary Surrogate-Assisted Prescription in Multi-Objective Chlorination Control Systems](https://arxiv.org/abs/2508.19173)
*Rivaaj Monsia,Olivier Francon,Daniel Young,Risto Miikkulainen*

Main category: cs.NE

TL;DR: ESP是一种用于训练真实世界代理的新方法，已在IJCAI-2025的饮用水氯化挑战中初步展示了其潜力。


<details>
  <summary>Details</summary>
Motivation: 介绍进化替代辅助处方（ESP）的概念，并展示其在训练真实世界代理方面的初步潜力，特别是在IJCAI-2025的饮用水氯化挑战赛中。

Method: 该研究引入了进化替代辅助处方（ESP）的概念，但未详细说明具体方法。

Result: 初步结果表明ESP在训练真实世界代理方面具有潜力。

Conclusion: ESP是一种有前途的方法，有望解决现实世界的问题，但需要进一步的研究和发展。

Abstract: This short, written report introduces the idea of Evolutionary
Surrogate-Assisted Prescription (ESP) and presents preliminary results on its
potential use in training real-world agents as a part of the 1st AI for
Drinking Water Chlorination Challenge at IJCAI-2025. This work was done by a
team from Project Resilience, an organization interested in bridging AI to
real-world problems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [398] [Quantum neural ordinary and partial differential equations](https://arxiv.org/abs/2508.18326)
*Yu Cao,Shi Jin,Nana Liu*

Main category: quant-ph

TL;DR: 提出了QNODEs和QNPDEs框架，将神经ODE/PDE的连续时间形式主义引入量子机器学习和量子控制，实现了高效的梯度计算和广泛的应用。


<details>
  <summary>Details</summary>
Motivation: 将经典神经ODE/PDE的连续时间形式主义扩展到量子机器学习和量子控制领域，以实现对量子动力学和其他可映射到量子动力学的动力学的有效学习。

Method: 定义了QNODEs（有限维量子系统演化）和QNPDEs（无限维量子系统演化），通过广义薛定谔类型哈密顿动力学和酉演化来描述，并利用伴随状态法进行梯度估计，提出量子算法进行有无时间离散化的梯度计算。

Result: 实现了高效的梯度计算，优于经典设备；该框架可应用于量子态制备、哈密顿量学习、开放系统动力学学习以及经典ODE和PDE的学习。

Conclusion: 提出的连续时间形式主义为设计新的量子神经网络架构提供了蓝图，并将离散层模型推广为连续深度模型，在经典模拟效率低下的场景下，量子方法在梯度估计方面具有优势。

Abstract: We present a unified framework called Quantum Neural Ordinary and Partial
Differential Equations (QNODEs and QNPDEs) that brings the continuous-time
formalism of classical neural ODEs/PDEs into quantum machine learning and
quantum control. We define QNODEs as the evolution of finite-dimensional
quantum systems, and QNPDEs as infinite-dimensional (continuous-variable)
counterparts, governed by generalised Schrodinger-type Hamiltonian dynamics
with unitary evolution, coupled with a corresponding loss function. Notably,
this formalism permits gradient estimation using an adjoint-state method,
facilitating efficient learning of quantum dynamics, and other dynamics that
can be mapped (relatively easily) to quantum dynamics. Using this method, we
present quantum algorithms for computing gradients with and without time
discretisation, enabling efficient gradient computation that would otherwise be
less efficient on classical devices.
  The formalism subsumes a wide array of applications, including quantum state
preparation, Hamiltonian learning, learning dynamics in open systems, and the
learning of both autonomous and non-autonomous classical ODEs and PDEs. In many
of these applications, we consider scenarios where the Hamiltonian has
relatively few tunable parameters, yet the corresponding classical simulation
remains inefficient, making quantum approaches advantageous for gradient
estimation. This continuous-time perspective can also serve as a blueprint for
designing novel quantum neural network architectures, generalising
discrete-layered models into continuous-depth models.

</details>


### [399] [Gain-Assisted and Dynamically Controlled Optical Bistability for Quantum Logic Gate Applications](https://arxiv.org/abs/2508.18332)
*Parkhi Bhardwaj,Poonam Yadav,Bodhaditya Santra,Shubhrangshu Dasgupta*

Main category: quant-ph

TL;DR: 文章研究了在多个相干场作用下，N型四能级冷原子系统中探测场（probe field）的传播。通过相干控制量子干涉，实现了探测场透明和增益状态的转换。引入增益降低了光学双稳态的阈值，增强了非线性响应。文章详细分析了光学双稳态的阈值、稳定性和转换效率，并研究了拉盖尔高斯（Laguerre Gaussian）模式等结构光对双稳态特性的影响。最后，提出了一种通过动态调制双稳态来实现受控非（Controlled-NOT）门的操作方案。


<details>
  <summary>Details</summary>
Motivation: 文章旨在研究相干控制量子干涉在N型四能级冷原子系统中调控探测场传播（透明和增益）的能力，并探索引入增益如何降低光学双稳态的阈值、增强非线性响应。此外，文章还研究了结构光（特别是拉盖尔高斯模式）如何影响双稳态特性，并提出利用这些特性实现量子逻辑门的操作。

Method: 文章采用理论分析方法，研究了在多个相干场作用下，N型四能级冷原子系统中探测场的传播。具体分析了相干控制量子干涉如何实现透明和增益状态的转换，以及增益如何影响光学双稳态的阈值和非线性响应。同时，研究了拉盖尔高斯模式（包括拓扑荷和方位角相位）对双稳态特性的影响，并基于此提出了实现受控非门的方案。

Result: 研究表明，通过相干控制量子干涉可以实现探测场的透明和增益状态的转换。引入增益可以降低光学双稳态的阈值，提高非线性响应。结构光，特别是携带轨道角动量的拉盖尔高斯模式，能够显著影响双稳态行为。文章还提出了一个基于动态调制双稳态的受控非门理论方案。

Conclusion: 该研究展示了在冷原子系统中，将非线性光学效应与结构光相结合的潜力，可用于实现可扩展的量子逻辑和推进光子信息处理。

Abstract: The propagation of a probe field in an N-type four level cold atomic system
is investigated under the influence of multiple coherent fields. Coherent
control of quantum interference enables switching of the probe field between
transparency and gain regimes. Subsequent analysis focuses on how the
introduction of gain in the probe transition lowers the threshold for optical
bistability, thereby enhancing the nonlinear response of the system at reduced
input intensities. A detailed analysis of optical bistability is presented,
focusing on its threshold, stability, and switching efficiency as functions of
field strengths and detunings. Structured light beams, specifically Laguerre
Gaussian modes carrying orbital angular momentum, are employed to tailor the
bistable characteristics. The impact of Orbital angular momentum through the
topological charge and azimuthal phase is shown to significantly influence the
bistable behavior. Based on these features, a theoretical scheme is proposed to
realize a Controlled-NOT gate via dynamic modulation of bistability. These
results highlight the potential of integrating nonlinear optical effects with
structured light in cold atomic systems for implementing scalable quantum logic
and advancing photonic information processing.

</details>


### [400] [Architecting Distributed Quantum Computers: Design Insights from Resource Estimation](https://arxiv.org/abs/2508.19160)
*Dmitry Filippov,Peter Yang,Prakash Murali*

Main category: quant-ph

TL;DR: 当前量子计算架构难以扩展，本研究提出了分布式量子计算架构的资源估算框架，并分析了不同配置下的算法性能，表明分布式架构在扩展性方面具有可行性。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算的资源估算主要集中在单体系统，而忽略了分布式系统的扩展性问题，本研究旨在填补这一空白，并为分布式量子计算系统的设计提供指导。

Method: 提出了一种新颖的资源估算框架，对分布式执行堆栈的关键组件进行建模，并分析了不同硬件配置下实际量子算法的性能。

Result: 与单体架构相比，分布式架构在节点大小为45K量子比特时，需要更多的物理量子比特（平均1.4倍）和更长的执行时间（4倍），但硬件实现前景更佳。

Conclusion: 分布式量子计算架构在扩展性方面具有实际可行的资源需求，其对节点大小、硬件配置和纠缠分馏协议的分析结果，有望为未来量子计算系统的设计提供参考。

Abstract: To enable practically useful quantum computing, we require hundreds to
thousands of logical qubits (collections of physical qubits with error
correction). Current monolithic device architectures have scaling limits beyond
few tens of logical qubits. To scale up, we require architectures that
orchestrate several monolithic devices into a distributed quantum computing
system. Currently, resource estimation, which is crucial for determining
hardware needs and bottlenecks, focuses exclusively on monolithic systems. Our
work fills this gap and answers key architectural design questions about
distributed systems, including the impact of distribution on application
resource needs, the organization of qubits across nodes and the requirements of
entanglement distillation (quantum network). To answer these questions, we
develop a novel resource estimation framework that models the key components of
the distributed execution stack. We analyse the performance of practical
quantum algorithms on various hardware configurations, spanning different qubit
speeds, entanglement generation rates and distillation protocols. We show that
distributed architectures have practically feasible resource requirements; for
a node size of 45K qubits, distributed systems need on average 1.4X higher
number of physical qubits and 4X higher execution time compared to monolithic
architectures, but with more favourable hardware implementation prospects. Our
insights on entanglement generation rates, node sizes and architecture have the
potential to inform system designs in the coming years.

</details>


### [401] [Finding trail covers: near-optimal decompositions of graph states as linear fusion networks](https://arxiv.org/abs/2508.18375)
*William Cashman,Giovanni de Felice,Aleks Kissinger*

Main category: quant-ph

TL;DR: 该论文研究了光子测量量子计算中的图论问题，以优化量子硬件上的实现成本。


<details>
  <summary>Details</summary>
Motivation: 为了在物理硬件上优化量子计算的实现成本，需要新的量子编译算法。在光子测量量子计算中，图状态是通过融合有限长度的线性资源状态来构建的，融合操作的成功率低于1，因此需要最小化融合次数，这对应于寻找最小路径或轨迹覆盖问题。

Method: 研究了三个图论问题（欧拉路径和哈密顿路径问题的推广），开发了启发式算法来寻找图中的轨迹覆盖，并将问题归约为旅行商问题。提出了新的图状态重写策略以减少融合次数。

Result: 证明了这些覆盖问题在大多数情况下是NP难的，并开发了启发式算法。将算法应用于光子融合网络的编译，并对常见的纠错码和QASMBench基准测试集中的电路进行了性能评估。

Conclusion: 所提出的算法和策略能够有效地减少光子测量量子计算中图状态的构建融合次数，并在实际应用中表现出良好的性能。

Abstract: Quantum compilation requires the development of new algorithms that optimise
the cost of implementing quantum computations on physical hardware. Often this
gives rise to problems which are asymptotically hard to solve classically, and
for which heuristics and reductions to known problems are of great practical
use. In this paper, we study three graph-theoretic problems which can be seen
as generalisations of the Eulerian and Hamiltonian path problems. These arise
in photonic implementations of measurement-based quantum computing, where graph
states are constructed by fusing bounded-length linear resource states. Since
the fusion operation succeeds with probability smaller than one, we wish to
minimise the number of fusions required to build a particular graph state and
this corresponds to finding a minimal path or trail cover of the graph. We show
that these covering problems are NP-hard in most cases and give heuristic
algorithms for finding trail covers in graphs including a reduction to the
travelling salesman problem. We propose new rewrite strategies for graph states
that reduce the number of fusions required to build a given graph. Finally, we
apply these algorithms to the compilation of photonic fusion networks and
provide a series of benchmarks showing the performance of our algorithms on
common error-correcting codes and circuits from the QASMBench set.

</details>


### [402] [Time Domain Design of a Josephson Parametric Amplifier and Comparison with Input Output Theory](https://arxiv.org/abs/2508.18396)
*Emre Küçükyılmaz,Mehmet Ünlü,Ali Bozbey*

Main category: quant-ph

TL;DR: JPA设计和分析可采用基于等效电路模型的方法，并利用约瑟夫超导电路模拟器进行实现，该方法与基于量子输入-输出理论的方法相比，可显著减少设计时间。


<details>
  <summary>Details</summary>
Motivation: 约瑟夫参数放大器（JPA）是量子计算机中的关键组件，用于放大来自量子比特的微波信号。然而，JPA的设计和分析通常基于量子物理学的输入-输出理论。

Method: 本文提出了一种基于JPA等效电路模型的新方法，并使用开源约瑟夫电路模拟器进行实现，然后将结果与基于量子输入-输出理论得到的结果进行比较。

Result: 与基于量子理论的方法相比，该电路模型方法能够使用电路优化器处理各种目标函数，并显著减少设计时间。

Conclusion: 基于等效电路模型和约瑟夫电路模拟器的方法为JPA的设计和分析提供了一种有效的替代方案，尤其是在需要优化和快速设计迭代的场景下。

Abstract: Quantum-limited amplifiers, such as Josephson Traveling Wave Parametric
Amplifiers (JTWPAs) and Josephson Parametric Amplifiers (JPAs), are essential
components in quantum computers. They amplify low-power microwave signals from
qubits at the 10 mK stage before further amplification at the 4 K stage using
HEMT amplifiers. In JPAs, parametric amplification is based on the nonlinear
properties of Josephson Junctions. While JPAs are typically designed and
analyzed using input-output theory based on quantum physics, we propose an
alternative approach based on an equivalent circuit model of JPAs, implemented
using open-source Josephson circuit simulators. We compare the results with
those obtained from input-output theory. This method enables the use of circuit
optimizers for various objective functions and significantly reduces design
time compared to quantum theory-based approaches.

</details>


### [403] [Quantum Markovian master equation in the high-temperature limit](https://arxiv.org/abs/2508.18385)
*Ricardo C. Zamar,J. Agustín Taboada*

Main category: quant-ph

TL;DR: 本文推导了高温量子马尔可夫主方程（HTME），它是Abragam-Redfield-Hubbard不均匀主方程（ARH-IME）的推广，并考虑了高阶初始态的非热效应。通过对自旋系统与浴相互作用的分析，证明了ARH-IME在强关联和非热条件下存在局限性，提出了更广泛的开放量子系统建模框架。


<details>
  <summary>Details</summary>
Motivation: 本文旨在批判性地推导高温量子马尔可夫主方程（HTME），检验其基本假设、量子力学含义及其有效范围，并与现有理论进行比较，为开放量子系统建模提供更优化的框架。

Method: 本文从Born-Markov主方程出发，结合自旋哈密顿量本征算符形式和统计系数的线性展开，推导出推广的Abragam-Redfield-Hubbard不均匀主方程（ARH-IME）。通过算符推导验证了结果，并揭示了谱密度在弱关联热力学条件下的对称性条件。本文还研究了自旋系统与玻色浴的相互作用以及双自旋系统中单重态-三重态的转换。

Result: 推导出的HTME自然地包含了非热、高阶初始态的附加项，在弱关联条件下可简化为ARH-IME。研究发现ARH-IME在强关联或非热条件下存在局限性，无法准确描述相关双自旋系统的单重态-三重态转换。第一性原理的谱密度对称性在高温下得到验证。

Conclusion: 本文对HTME的推导和分析挑战了核磁共振自旋-晶格弛豫理论的传统界限，并为超越弱关联条件的开放量子系统建模提供了一个更优化的框架。

Abstract: We present a critical derivation of the high-temperature quantum Markovian
master equation (HTME), examining its foundational assumptions, their
quantum-mechanical implications, and its range of validity. Starting from the
Born-Markov master equation, and combining the spin Hamiltonian eigenoperator
formalism with a linear expansion in statistical coefficients, as the only
assumption, we obtain a quantum dissipator that generalizes the
Abragam-Redfield-Hubbard inhomogeneous master equation (ARH-IME). Our
derivation naturally incorporates an additional term for non-thermal,
high-order initial states, while reducing to ARH-IME for spin states evolving
near thermal equilibrium (weak-order). Through an alternative operator-based
derivation of the HTME, we confirm these results and reveal a symmetrization
condition for the spectral densities in the linear thermal regime. We
rigorously analyze the internal consistency of both approaches and compare them
with prior literature. To illustrate these findings, we study: (i) A canonical
spin-1/2 system interacting with a bosonic bath, demonstrating first-principles
symmetrization of spectral densities at high temperatures. (ii) Singlet-triplet
conversion in a correlated two-spin system, where the ARH-IME fails, exposing
the limitations of the weak-order hypothesis in strongly correlated regimes.
Our results challenge the traditional boundaries of NMR spin-lattice relaxation
theory and provide a refined framework for modeling open quantum systems beyond
weak order.

</details>


### [404] [state-o-gram --A Novel 2D Visualization for Quantum States](https://arxiv.org/abs/2508.18390)
*Fritz Schinkel*

Main category: quant-ph

TL;DR: state-o-gram是一种新的2D可视化方法，用于表示任意数量量子比特的量子态，解决了现有方法的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有量子态可视化工具（如Bloch Sphere）在多量子比特系统上扩展性不足，需要更直观、可扩展的工具。

Method: 提出state-o-gram，一种新的2D可视化方法，用于统一表示概率幅和相位角，并将其应用于Deutsch-Josza算法。

Result: state-o-gram成功可视化了Deutsch-Josza算法中多量子比特的状态。

Conclusion: state-o-gram为量子态分析提供了一个可扩展且直观的工具，能够处理任意数量的量子比特。

Abstract: Quantum computing is rapidly gaining popularity, necessitating intuitive
visualization tools for complex quantum states. While the Bloch Sphere
effectively visualizes single-qubit states, it fundamentally lacks scalability
for multi-qubit systems. Existing multi-qubit visualization attempts, such as
VENUS, have shown promise but often face limitations in scalability beyond a
few qubits. This paper introduces state-o-gram, a novel 2D visualization
approach designed to intuitively represent quantum states for an arbitrary
number of qubits. state-o-gram effectively visualizes probability amplitudes
and phase angles in a unified 2D framework, addressing the limitations of prior
art. We detail its design principles, visual elements, and application to
multi-qubit systems, aiming to provide a scalable and intuitive tool for
quantum state analysis. We evaluate the applicability by visualizing the states
throughout the Deutsch-Josza algorithm.

</details>


### [405] [A Group-Theoretic Perspective on the PPT and Realignment Entanglement Criteria](https://arxiv.org/abs/2508.18393)
*Tobias C. Sutter,Christopher Popp,Beatrix C. Hiesmayr*

Main category: quant-ph

TL;DR: PPT和realignment准则在贝尔对角态上的群论分析


<details>
  <summary>Details</summary>
Motivation: 在混合量子态中检测纠缠是量子技术中的一个挑战。PPT和realignment准则虽然是有效的工具，但其与贝尔对角态的群结构的关系尚未被充分探索。

Method: 从群论的角度分析PPT和realignment准则在贝尔对角态上的应用。

Result: 证明了贝尔对角态的群结构为分析和计算这两个纠缠检测准则提供了清晰的框架。

Conclusion: 群论视角为理解贝尔对角态中的纠缠提供了新的见解，并将PPT准则与可实验测量的纠缠见证联系起来，为扩展到更复杂的量子系统开辟了道路。

Abstract: Entanglement is a key feature in many quantum technologies, including secure
communication protocols and quantum computing. However, detecting it in mixed
quantum states remains a challenging task. While the PPT and realignment
criteria are well-established tools for entanglement detection in general, and
are especially effective in Bell-diagonal states, their connection to the
underlying group structure of this state family has not been fully explored. In
this work, we analyze the PPT and realignment criteria for Bell-diagonal states
from a group-theoretic point of view. Our results demonstrate that the group
structure of Bell-diagonal states provides a clear framework for analyzing and
computing these two entanglement detection criteria. This unified perspective
offers new insights into the mathematical and physical properties of
entanglement in structured quantum systems, like the connection of the PPT
criterion to experimentally accessible entanglement witnesses, thus opening a
path for extending the group formalism to more complex quantum systems.

</details>


### [406] [Vectorized Attention with Learnable Encoding for Quantum Transformer](https://arxiv.org/abs/2508.18464)
*Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski*

Main category: quant-ph

TL;DR: 提出向量化量子Transformer（VQT）模型，通过量子近似模拟实现理想的掩码注意力矩阵计算，并通过向量化非线性量子编码实现高效训练，最终实现低采样量子电路模拟（QCS）和减少的经典采样开销。


<details>
  <summary>Details</summary>
Motivation: 当前QT依赖深度参数化量子电路（PQC），易受量子比特噪声影响，限制了实际性能。

Method: 提出向量化量子Transformer（VQT），利用量子近似模拟实现掩码注意力矩阵计算，并通过向量化非线性量子编码实现高效训练。

Result: 在IBM和IonQ的量子电路模拟中进行了准确性比较，并在IBM最先进和高保真的Kingston量子处理器上进行了自然语言处理任务的基准测试，取得了有竞争力结果。

Conclusion: VQT是一种对噪声具有鲁棒性的模型，能够实现端到端的机器学习，为量子计算开辟了新的架构。

Abstract: Vectorized quantum block encoding provides a way to embed classical data into
Hilbert space, offering a pathway for quantum models, such as Quantum
Transformers (QT), that replace classical self-attention with quantum circuit
simulations to operate more efficiently. Current QTs rely on deep parameterized
quantum circuits (PQCs), rendering them vulnerable to QPU noise, and thus
hindering their practical performance. In this paper, we propose the Vectorized
Quantum Transformer (VQT), a model that supports ideal masked attention matrix
computation through quantum approximation simulation and efficient training via
vectorized nonlinear quantum encoder, yielding shot-efficient and gradient-free
quantum circuit simulation (QCS) and reduced classical sampling overhead. In
addition, we demonstrate an accuracy comparison for IBM and IonQ in quantum
circuit simulation and competitive results in benchmarking natural language
processing tasks on IBM state-of-the-art and high-fidelity Kingston QPU. Our
noise intermediate-scale quantum friendly VQT approach unlocks a novel
architecture for end-to-end machine learning in quantum computing.

</details>


### [407] [Entanglement dynamics of monitored non-interacting fermions on Graphic-Processing-Units](https://arxiv.org/abs/2508.18468)
*Bo Fan,Can Yin,Antonio M. García-García*

Main category: quant-ph

TL;DR: 该研究利用GPU技术数值模拟了受监测的非相互作用费米子的纠缠动力学，特别是在一维和二维情况下。研究发现在一维情况下，需要达到约10000个格点才能确认没有测量诱导相变（MIPT）。而在二维情况下，研究观察到了MIPT，其临界监测率和临界指数（约为1.3）与非线性sigma模型（NLSM）的预测存在差异，表明NLSM无法完全准确预测这些特征。该研究为量化描述受监测量子系统的纠缠动力学奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 解决文献中关于受监测的非相互作用费米子纠缠动力学（包括测量诱导相变MIPT）描述存在冲突且具有挑战性的问题，并利用NLSM映射指示需要较大的格点尺寸来确定热力学极限下的纠缠熵性质。

Method: 利用GPU技术数值模拟受监测的非相互作用费米子（具有U(1)对称性）的纠缠动力学，在一维和二维情况下达到了比先前研究大得多的格点尺寸（一维L=16384，二维160x160），以便定量表征纠缠动力学。

Result: 在一维情况下，研究确认了对于项目和同相测量，需要达到L ~ 10000才能证实NLSM预测的MIPT缺失。在二维情况下，研究观察到了MIPT，其临界监测率取决于测量方案，而控制MIPT的临界指数约为1.3，在两种方案中均相似，但这些特征与NLSM的预测不符。

Conclusion: 该研究通过大规模数值模拟，为受监测量子系统的纠缠动力学提供了量化的描述，并指出了现有NLSM模型的局限性，为未来更精确的理论模型提供了方向。

Abstract: The description of the entanglement dynamics of monitored non-interacting
fermions, including the existence of measurement-induced phase transitions
(MIPT), is a challenging problem with conflicting results in the literature.
The mapping of the problem onto a non-linear sigma model (NLSM) indicates that
relatively large lattice sizes are required to determine the nature of the
entanglement entropy (EE) in the thermodynamics limit. Here we address this
problem numerically for monitored non-interacting fermions with $U(1)$
symmetry. The use of Graphic-Processing-Unit (GPU) techniques, even with
outdated hardware, makes possible to reach much larger lattice sizes ($L =
16384$ and $160\times160$ in one (1d) and two (2d) dimensions respectively)
than in previous studies which enables us to characterize quantitatively the
entanglement dynamics. In 1d, we show that in order to confirm the absence of a
MIPT, for both projective and homodyne measurements, predicted by the NLSM it
is necessary to reach $L \sim 10000$. In 2d, also as predicted by the NLSM, we
observe for both protocols a MIPT at finite monitoring rate characterized by a
scale invariant mutual information. The critical monitoring strength depends on
the protocol while the critical exponent $\nu \approx 1.3$ governing the
approach to the MIPT is similar in both cases. These features are not correctly
predicted by the NLSM. Our results paves the way for a fully quantitative
description of the entanglement dynamics of monitoring quantum systems.

</details>


### [408] [Can Classical Initialization Help Variational Quantum Circuits Escape the Barren Plateau?](https://arxiv.org/abs/2508.18497)
*Yifeng Peng,Xinyi Li,Zhemin Zhang,Samuel Yen-Chi Chen,Zhiding Liang,Ying Wang*

Main category: quant-ph

TL;DR: 经典初始化方法对缓解VQA中的巴伦高原问题效果有限，但为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: VQA在近端量子计算中表现突出，但易受巴伦高原问题影响，导致梯度消失。尽管经典深度学习通过Xavier、He和正交初始化等策略有效改善了梯度流，但其在VQA中的应用效果尚不明确。

Method: 本文系统性地研究了将经典初始化策略（如Xavier、He和正交初始化）应用于量子电路以缓解巴伦高原问题的可行性。首先，对每种初始化方法的理论基础进行了回顾，并探讨了如何将其概念应用于VQA。其次，在多种电路架构和优化任务上进行了广泛的数值实验。

Result: 实验结果表明，虽然受经典初始化启发的启发式方法在某些实验中带来了适度的改进，但总体益处仍然有限。

Conclusion: 尽管经典初始化策略对缓解VQA中的巴伦高原问题效果有限，但本文的探索性工作和提出的未来研究方向为该领域的研究提供了更广阔的视角和可行的实验基础。

Abstract: Variational quantum algorithms (VQAs) have emerged as a leading paradigm in
near-term quantum computing, yet their performance can be hindered by the
so-called barren plateau problem, where gradients vanish exponentially with
system size or circuit depth. While most existing VQA research employs simple
Gaussian or zero-initialization schemes, classical deep learning has long
benefited from sophisticated weight initialization strategies such as Xavier,
He, and orthogonal initialization to improve gradient flow and expedite
convergence. In this work, we systematically investigate whether these
classical methods can mitigate barren plateaus in quantum circuits. We first
review each initialization's theoretical grounding and outline how to adapt the
notions from neural networks to VQAs. We then conduct extensive numerical
experiments on various circuit architectures and optimization tasks. Our
findings indicate that while the initial heuristics, inspired by classical
initialization, yield moderate improvements in certain experiments, their
overall benefits remain marginal. By outlining a preliminary exploration plan
in this paper, we aim to offer the research community a broader perspective and
accessible demonstrations. Furthermore, we propose future research directions
that may be further refined by leveraging the insights gained from this work.

</details>


### [409] [Extendibility of Fermionic Gaussian States](https://arxiv.org/abs/2508.18532)
*Amir-Reza Negari,Farzin Salek*

Main category: quant-ph

TL;DR: 本论文研究了费米子高斯态的(k1,k2)-可延拓性，并给出了其与可分态之间的有限德菲内定理，将指数缩放改进为与模式数量成线性关系。


<details>
  <summary>Details</summary>
Motivation: 研究费米子高斯态的(k1,k2)-可延拓性，及其在量子关联和可分性近似中的作用。

Method: 推导出费米子高斯态(k1,k2)-可延拓性的充要条件，建立了与协方差矩阵相关的刻画以及一个线性的半定规划（SDP）。证明了有限的德菲内型定理，并给出了迹范数界限，以及对互补相对熵和压缩纠缠的界限。对于双模情况，上下界在1/sqrt(k1 k2)阶匹配。最后，为费米子高斯信道提供了反退化性的SDP判据，并证明了纠缠破坏信道等价于替换信道。

Result: 费米子高斯态是(k1,k2)-可延拓的，当且仅当它们允许费米子高斯延拓。给出了线性的SDP，并将可延拓性与可分态的迹范数界限联系起来，改进了之前的指数缩放。对于双模，上下界在1/sqrt(k1 k2)阶匹配。纠缠破坏信道与替换信道等价，不存在非平凡的纠缠破坏费米子高斯信道。

Conclusion: 本文为费米子高斯态的(k1,k2)-可延拓性提供了完整的协方差矩阵刻画和高效的SDP方法，并建立了改进的德菲内型定理。此外，还为费米子高斯信道提供了反退化性的SDP判据，并阐明了纠缠破坏信道和替换信道的等价性。

Abstract: We investigate $(k_1,k_2)$-extendibility of fermionic Gaussian states, a
property central to quantum correlations and approximations of separability. We
show that these states are $(k_1,k_2)$-extendible if and only if they admit a
fermionic Gaussian extension, yielding a complete covariance-matrix
characterization and a simple semidefinite program (SDP) whose size scales
linearly with the number of modes. This provides necessary conditions for
arbitrary fermionic states and is sufficient within the Gaussian setting. Our
main result is a finite de Finetti--type theorem: we derive trace-norm bounds
between $(k_1,k_2)$-extendible fermionic Gaussian states and separable states,
improving previous exponential scaling to linear in the number of modes, with
complementary relative entropy and squashed entanglement bounds. For two modes,
upper and lower bounds match at order $1/\sqrt{k_1 k_2}$. Extendibility also
provides operational support for one of the different notions of separability
in fermionic systems. Finally, for fermionic Gaussian channels, we provide an
SDP criterion for anti-degradability and show that entanglement-breaking
channels coincide with replacement channels, implying no nontrivial
entanglement-breaking fermionic Gaussian channels exist.

</details>


### [410] [Chiral Discrimination on Gate-Based Quantum Computers](https://arxiv.org/abs/2508.18546)
*Muhammad Arsalan Ali Akbar,Sabre Kais*

Main category: quant-ph

TL;DR: 提出了一种使用基于门量子处理器进行手性识别的新方法，通过Trotter化离散化了STIRAP和STAP协议的模拟，并在IBM量子硬件上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 解决了将传统的手性识别控制技术（如STIRAP和STAP）应用于数字门基量子计算架构的挑战，因为它们依赖于模拟和连续时间控制。

Method: 通过Trotter化离散化了STIRAP和STAP协议的模拟，并在IBM量子硬件上进行了实验验证。

Result: 成功模拟了1,2-丙二醇的手性分子，并在IBM量子硬件上进行了实验验证，证明了该方法的可行性。

Conclusion: 该方法为推进手性识别协议奠定了可行基础，为在可及的量子架构上对分子手性进行量子级操控铺平了道路。

Abstract: We present a novel approach to chiral discrimination using gate-based quantum
processors, addressing a key challenge in adapting conventional control
techniques using modern quantum computing. Schemes such as stimulated rapid
adiabatic passage (STIRAP) and shortcuts to adiabaticity (STAP) have shown
strong potential for enantiomer discrimination; their reliance on analog and
continuous-time control makes them incompatible with digital gate-based quantum
computing architectures. Here, we adapt these protocols for quantum computers
by discretizing their Gaussian-shaped pulses through Trotterization. We
simulate the chiral molecule 1,2-propanediol and experimentally validate this
gate-based implementation on IBM quantum hardware. Our results demonstrate that
this approach is a viable foundation for advancing chiral discrimination
protocols, preparing the way for quantum-level manipulation of molecular
chirality on accessible quantum architectures.

</details>


### [411] [Anisotropic Heisenberg Su-Schrieffer-Heeger spin chain as a quantum channel](https://arxiv.org/abs/2508.18552)
*Lautaro Moragues,Diego Acosta Coden,Omar Osenda,Alejandro Ferrón*

Main category: quant-ph

TL;DR: 本文研究了在各向异性 Heisenberg SSH 自旋链中量子态（单激发和双激发）的传输问题，并分析了拓扑性质与状态传输效率之间的关系。


<details>
  <summary>Details</summary>
Motivation: 量子技术中，自旋链中的量子态传输是一个基本问题。SSH 模型提供了一个展示拓扑和非拓扑相的典范。

Method: 研究了各向异性 Heisenberg SSH 自旋链中单激发和双激发的传输。分析了拓扑性质与状态传输效率的关系。考察了在平凡和拓扑区域中，静态无序对量子态传输的鲁棒性。研究了偶极相互作用（引入长程耦合并破坏总磁化守恒）的影响。利用最优控制理论设计了状态传输的驱动脉冲。

Result: 发现拓扑保护对传输保真度有影响。偶极相互作用会引入长程耦合并破坏总磁化守恒。在平凡和拓扑区域中优化驱动脉冲有显著差异。

Conclusion: 研究结果揭示了量子态传输中拓扑、无序、相互作用和控制策略之间的相互作用。

Abstract: Quantum state transmission in spin chains is a fundamental problem within
quantum technologies. The Su-Schrieffer-Heeger (SSH) model, first introduced in
the context of polyacetylene, provides a paradigmatic example of a system
exhibiting topological and non-topological phases. We explore the transmission
of one and two excitations in anisotropic Heisenberg SSH spin chains and
analyze the relationship between topological properties and state transfer
efficiency. We examine the robustness of quantum state transmission against
static disorder in the trivial and topological regimes, exploring how
topological protection influences transmission fidelity. We also consider the
effect of dipolar interactions, introducing long-range couplings and breaking
the conservation of total magnetization. Furthermore, we employ optimal control
theory to design driving pulses for state transmission, finding substantial
differences between optimizing in the trivial and topological regimes. Our
results provide insights about the interplay between topology, disorder,
interactions, and control strategies in quantum state transfer.

</details>


### [412] [Violation of kinetic uncertainty relation in maser heat engines: Role of spontaneous emission](https://arxiv.org/abs/2508.18619)
*Varinder Singh,Euijoon Kwon,Jae Sung Lee*

Main category: quant-ph

TL;DR: 研究了马达热机的两种配置中的动力学不确定性关系（KUR），发现只有一种模型违反了KUR，这源于自发辐射破坏了结构对称性并改变了相干动力学。研究结果表明，较慢的退相干抑制了量子违反经典稳态KUR边界，而较快的相干衰减则抑制了这种违反。


<details>
  <summary>Details</summary>
Motivation: 研究马达热机两种配置中的动力学不确定性关系（KUR），探讨其与动力学活性和电流起伏之间的基本权衡。

Method: 分析了马达热机两种配置中的KUR，考察了统计特征如法诺因子和动力学活性与电流的比率，并确定了退相干在 KUR 违反中的作用。

Result: 发现KUR 违反仅出现在一种模型中，原因是自发辐射破坏了结构对称性并改变了相干动力学。较慢的退相干使得量子违反经典稳态 KUR 边界成为可能，而较快的相干衰减则抑制了这种违反。

Conclusion: 退相干机制在决定基本热力学边界方面起着关键作用，为设计量子热机提供了见解，其中退相干的控制对于抑制起伏和提高可靠性能至关重要。

Abstract: We investigate the kinetic uncertainty relation (KUR)-a fundamental trade-off
between dynamical activity and current fluctuations-in two configurations of a
maser heat engine. We find that KUR violations arise only in one model. This
asymmetry originates from spontaneous emission, which breaks the structural
symmetry between the configurations and modifies their coherence dynamics.
While we analyze several contributing factors-including statistical signatures
such as the Fano factor and the ratio of dynamical activity to current-our
results show that the decisive mechanism is the slower decoherence in one
configuration, which enables quantum violations of the classical steady-state
KUR bound. By contrast, the faster coherence decay in the other configuration
suppresses such violations, driving it closer to classical behavior. These
findings highlight the critical role of decoherence mechanisms in determining
fundamental thermodynamic bounds and provide insights for the design of quantum
heat engines in which the control of decoherence is central to suppressing
fluctuations and enhancing reliable performance.

</details>


### [413] [Polarization dynamics of the spin-boson model in the shifted boson Hilbert space](https://arxiv.org/abs/2508.18622)
*Yang Zhao,Lipeng Chen*

Main category: quant-ph

TL;DR: 提出了结合移位优化玻色子基和时间演化块删减法的算法，用于模拟开放量子系统动力学，有效解决了希尔伯特空间无限大的问题。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统模拟中的希尔伯特空间无限大问题。

Method: 结合移位优化玻色子基和时间演化块删减法（TEBD）。

Result: 在亚欧姆SBM中，该方法能以显著降低的计算成本精确重现极化动力学；在欧姆SBM中，验证了随时间演化的最终状态在零温和有限温下均能精确收敛到变分预测；在超欧姆SBM中，发现了具有初始极化浴的新非周期赝相干相。

Conclusion: 该工作为模拟开放量子系统的实时间动力学提供了一种高效且强大的方法。

Abstract: Faithfully simulating the dynamics of open quantum systems requires
efficiently addressing the challenge of an infinite Hilbert space. Inspired by
the shifted boson operator technique used in ground-state studies of the
spin-boson model (SBM), we develop a novel algorithm that integrates a shifted
optimized boson basis with the time-evolving block decimation method. We
validate our approach by accurately reproducing the polarization dynamics of
the sub-Ohmic SBM at a significantly reduced computational cost. For the Ohmic
SBM, we demonstrate that the time-evolved final state converges precisely to
the variational prediction at both zero and finite temperatures. Furthermore,
our method reveals a new aperiodic pseudocoherent phase in the super-Ohmic SBM
with an initially polarized bath. This work establishes an efficient and
powerful approach for simulating the real-time dynamics of open quantum
systems.

</details>


### [414] [Potential of Quantum Computing Applications for Smart Grid Digital Twins and Future Directions](https://arxiv.org/abs/2508.18654)
*Arianne Ornella Lemo,Ahmad Mohammad Saber,Deepa Kundur,Adam W. Skorek*

Main category: quant-ph

TL;DR: 本篇论文探讨了数字孪生与量子计算在智能电网中的应用，重点关注量子算法如何提升数字孪生的性能。


<details>
  <summary>Details</summary>
Motivation: 随着数字孪生技术和量子计算的融合，为智能电网系统的建模、控制和优化开辟了新途径。

Method: 通过专题文献综述，识别关键研究趋势、技术挑战和实际应用中的差距。此外，还提出了一个将量子模块集成到经典数字孪生架构中的概念框架。

Result: 对量子算法在智能电网数字孪生中的应用进行了研究，并提出了一个混合方法。

Conclusion: 讨论了这种混合方法在智能电网运营中的潜在优势以及未来的研究方向。

Abstract: The convergence of digital twin technology and quantum computing is opening
new horizons for the modeling, control, and optimization of smart grid systems.
This paper reviews the current research landscape at the intersection of these
fields, with a focus on how quantum algorithms can enhance the performance of
digital twins in smart energy systems. We conduct a thematic literature review
and identify key research trends, technical challenges, and gaps in real-world
adoption. Further, a conceptual framework is proposed to integrate quantum
modules into classical digital twin architectures. The potential benefits of
this hybrid approach for smart grid operation and future research directions
are also discussed.

</details>


### [415] [Achieving High-Quality Portfolio Optimization with the Variational Quantum Eigensolver](https://arxiv.org/abs/2508.18625)
*Anbang Wang,Zhonggang Lv,Zhenyuan Ma,Dunbo Cai,Zhihong Zhang*

Main category: quant-ph

TL;DR: 本文利用量子计算中的VQE算法结合WCVaR和CMA-ES来优化投资组合，并在Wuyue QuantumAI平台上通过经典模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 投资组合优化是一个重要的金融问题，目标是在最小化风险的同时最大化收益。由于其NP-hard性质，量子计算有望提供更有效的解决方案。

Method: 使用变分量子 Eigensolver (VQE) 算法来解决投资组合优化问题。为了提高收敛到高质量解决方案的可能性，我们提出使用加权风险价值 (WCVaR) 作为成本函数，并使用协方差矩阵自适应进化策略 (CMA-ES) 作为优化器。

Result: 实验在Wuyue QuantumAI平台上使用经典模拟进行。结果表明，WCVaR和CMA-ES的结合在解决投资组合优化问题方面表现出更好的性能。

Conclusion: 结合WCVaR和CMA-ES的VQE方法在投资组合优化问题上取得了改进的性能。

Abstract: Portfolio optimization is a fundamental problem in finance that aims to
determine the optimal allocation of assets within a portfolio to maximize
returns while minimizing risk. It can be formulated as a Quadratic
Unconstrained Binary Optimization (QUBO) problem, which is NP-hard. Quantum
computing offers the potential to solve such problems more efficiently than
classical methods. In this work, we employ the Variational Quantum Eigensolver
(VQE) to address the portfolio optimization problem. To increase the likelihood
of converging to high-quality solutions, we propose using the Weighted
Conditional Value-at-Risk (WCVaR) as the cost function and the Covariance
Matrix Adaptation Evolution Strategy (CMA-ES) as the optimizer. Our experiments
are conducted using the classical simulations on the Wuyue QuantumAI platform.
The results demonstrate that the combination of WCVaR and CMA-ES leads to
improved performance in solving the portfolio optimization problem.

</details>


### [416] [Enhanced Algorithmic Perfect State Transfer on IBM Quantum Computers](https://arxiv.org/abs/2508.18626)
*Zong-Yuan Ge,Lian-Ao Wu,Zhao-Ming Wang*

Main category: quant-ph

TL;DR: IBM量子计算机上的完美状态传输（PST）实验由于噪声导致成功概率低。通过模拟和噪声模型分析，我们提出了噪声缓解技术，提高了SP。


<details>
  <summary>Details</summary>
Motivation: 研究在IBM量子计算机上实现完美状态传输（PST）的挑战，并提出噪声缓解方法。

Method: 在IBM量子计算机和Qiskit模拟器上模拟了通过XY自旋链的PST，并建立了包括Pauli错误、弛豫、退相干和ZZ串扰的噪声模型。同时，应用了重 scaling 技术和优化耦合器来缓解噪声。通过网格搜索和贝叶斯优化来设计最优耦合。

Result: 模拟和实验结果表明，即使在理想耦合下，峰值SP也无法达到1（N=4时约为0.725）。建立的噪声模型能很好地匹配实验结果。重scaling技术在模拟器和硬件上分别提高了0.210 (27.60%)和0.263 (38.23%)的SP。优化耦合器在模拟器和硬件上分别提高了0.190 (26.21%)和0.056 (7.72%)的SP。

Conclusion: 在当前的量子计算机上实现PST面临挑战。所提出的噪声模型能有效描述系统动力学，并为开发抗噪声的量子通信协议提供了见解。

Abstract: Perfect state transfer (PST) through a spin chain can be theoretically
obtained via predesigned PST couplings. However, the corresponding experiment
on IBM quantum computers demonstrates low transmission success probability (SP)
due to noises. Using few qubits of their 127-qubit Eagle processors, we perform
the simulation of algorithmic PST through an XY spin chain with PST couplings
on ibm_sherbrooke and ibm_brisbane processors, alongside Qiskit simulations.
The peak SP cannot reach 1 ($\sim$0.725 peak SP for N=4). We then propose a
comprehensive noise model including Pauli errors, thermal relaxation ($T_1$)
and dephasing ($T_2$), and ZZ crosstalk. Based on the experimental parameters
provided by the IBM superconducting quantum computing platform, we perform the
Qiskit simulation with the comprehensive noise model, and find that the time
evolution of the SP is highly consistent with the experimental results. This
simulation yields a peak SP of 0.761 at $\textstyle t\approx\pi/4$, closely
matching the results on hardware. To mitigate the impact of noise, we use
rescaling techniques to correct noise-induced time shifts and SP decay,
achieving an SP improvement of 0.210 (27.60%) in simulators and 0.263 (38.23%)
on hardware, aligning hitting times closer to ideal values. Additionally,
optimal couplings designed via grid search and refined by Bayesian optimization
under the comprehensive noise model achieve an SP improvement of 0.190 (26.21%)
in simulators and 0.056 (7.72%) on hardware. Our work highlights challenges in
implementing algorithmic PST on current quantum computers, proposes a
comprehensive noise model to effectively describe the system dynamics, and
provides insights for developing noise-robust quantum communication protocols.

</details>


### [417] [Universal Dynamics with Globally Controlled Analog Quantum Simulators](https://arxiv.org/abs/2508.19075)
*Hong-Ye Hu,Abigail McClain Gomez,Liyuan Chen,Aaron Trowbridge,Andy J. Goldschmidt,Zachary Manchester,Frederic T. Chong,Arthur Jaffe,Susanne F. Yelin*

Main category: quant-ph

TL;DR: 全局控制场模拟的量子模拟器具有实现通用量子计算的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索具有全局控制场的模拟量子系统在实现通用量子计算方面的潜力，并解决理论和实验挑战。

Method: 提出并验证了仅使用全局脉冲控制实现通用量子计算的充要条件，并引入了直接量子最优控制技术来设计复杂的有效哈密顿量，克服硬件限制。

Result: 实验上实现了三体相互作用和拓扑动力学，并克服了非阻塞条件下的硬件限制和原子位置波动，高保真度地展示了对称保护拓扑边缘模式的动力学特征。

Conclusion: 全局控制场模拟量子模拟器可以实现通用量子计算，并且通过引入量子最优控制技术，可以克服实验限制，工程化多体相互作用，推动量子信息处理的发展。

Abstract: Analog quantum simulators with global control fields have emerged as powerful
platforms for exploring complex quantum phenomena. Recent breakthroughs, such
as the coherent control of thousands of atoms, highlight the growing potential
for quantum applications at scale. Despite these advances, a fundamental
theoretical question remains unresolved: to what extent can such systems
realize universal quantum dynamics under global control? Here we establish a
necessary and sufficient condition for universal quantum computation using only
global pulse control, proving that a broad class of analog quantum simulators
is, in fact, universal. We further extend this framework to fermionic and
bosonic systems, including modern platforms such as ultracold atoms in optical
superlattices. Crucially, to connect the theoretical possibility with
experimental reality, we introduce a new control technique into the experiment
- direct quantum optimal control. This method enables the synthesis of complex
effective Hamiltonians and allows us to incorporate realistic hardware
constraints. To show its practical power, we experimentally engineer three-body
interactions outside the blockade regime and demonstrate topological dynamics
on a Rydberg atom array. Using the new control framework, we overcome key
experimental challenges, including hardware limitations and atom position
fluctuations in the non-blockade regime, by identifying smooth, short-duration
pulses that achieve high-fidelity dynamics. Experimental measurements reveal
dynamical signatures of symmetry-protected-topological edge modes, confirming
both the expressivity and feasibility of our approach. Our work opens a new
avenue for quantum simulation beyond native hardware Hamiltonians, enabling the
engineering of effective multi-body interactions and advancing the frontier of
quantum information processing with globally-controlled analog platforms.

</details>


### [418] [Equality condition for a matrix inequality by partial transpose](https://arxiv.org/abs/2508.18644)
*Nalan Wang,Lin Chen*

Main category: quant-ph

TL;DR: 该论文研究了部分转置映射在量子信息理论中的应用，并探讨了一个由部分转置生成的矩阵不等式的等价条件。


<details>
  <summary>Details</summary>
Motivation: 研究部分转置在量子信息理论中的应用，特别是矩阵不等式的等价条件。

Method: 显式构造了当A_j为列向量、行向量或2x2矩阵时的条件，并将结果推广到对方块矩阵和长方矩阵的情况。研究了K=2的一般情况。

Result: 证明了当Schmidt秩等于A_j的维度时，部分转置不等式的等价条件可以推广到更广泛的矩阵情况，并揭示了其块对角线形式。

Conclusion: 论文详细阐述了部分转置在量子信息理论中的一个重要矩阵不等式的等价条件，并通过具体构造和推广，为理解该不等式提供了新的视角。

Abstract: The partial transpose map is a linear map widely used quantum information
theory. We study the equality condition for a matrix inequality generated by
partial transpose, namely $\rank(\sum^K_{j=1} A_j^T \otimes B_j)\le K \cdot
\rank(\sum^K_{j=1} A_j \otimes B_j)$, where $A_j$'s and $B_j$'s are
respectively the matrices of the same size, and $K$ is the Schmidt rank. We
explicitly construct the condition when $A_i$'s are column or row vectors, or
$2\times 2$ matrices. For the case where the Schmidt rank equals the dimension
of $A_j$, we extend the results from $2\times 2$ matrices to square matrices,
and further to rectangular matrices. In detail, we show that $\sum^K_{j=1} A_j
\otimes B_j$ is locally equivalent to an elegant block-diagonal form consisting
solely of identity and zero matrices. We also study the general case for $K=2$,
and it turns out that the key is to characterize the expression of matrices
$A_j$'s and $B_j$'s.

</details>


### [419] [On-Demand Zeeman Nuclear Frequency Comb Quantum Memory](https://arxiv.org/abs/2508.18645)
*Yanli Shi,Xiwen Zhang,Yuri Shvyd'ko,Olga Kocharovskaya*

Main category: quant-ph

TL;DR: 该论文提出了一种基于磁场反转的新型按需硬X射线量子存储器，克服了现有基于运动学协议的存储器的实验挑战，并成功在Ta-181金属箔中实现了6.2 keV、1.41微秒光子波包的10微秒量子存储。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有硬X射线量子存储器（基于运动学协议）在按需光子检索方面存在的实验挑战，本研究提出了一种新的基于磁场反转的存储器方案。

Method: 提出了一种基于在单个固定固态核吸收体中反转外部磁场方向的按需硬X射线量子存储器方案，利用塞曼能级。

Result: 在Ta-181金属箔中，成功实现了6.2 keV、1.41微秒光子波包超过10微秒的量子存储。

Conclusion: 提出的基于磁场反转的方案为实现按需硬X射线光子存储的首次实验演示提供了一条可行的途径。

Abstract: The emerging hard X-ray - nuclear interfaces offer unique potential
advantages over traditional optical-atomic interfaces for room-temperature,
solid-state quantum information processing, including lower background noise,
tighter focusing, and exceptionally high resonance quality. Leveraging such
interfaces, a major milestone was recently achieved with the first
implementation of nuclear quantum memory in the hard X-ray range [S. Velten et
al., Nuclear quantum memory for hard X-ray photon wave packets, Sci. Adv. 10,
eadn9825 (2024)] using the Doppler frequency comb protocol. However, this
approach relies on the synchronous mechanical motion of multiple nuclear
absorbers, posing experimental challenges for on-demand photon retrieval. We
propose an on-demand hard X-ray quantum memory based on reversing the direction
of an external magnetic field in a single stationary solid-state nuclear
absorber with sets of Zeeman sublevels. This scheme is exemplified by the
quantum storage of an 1.41-$\mu$s single photon wave packet at 6.2 keV for over
10 $\mu$s in a $^{181}$Ta metallic foil, providing a feasible pathway for the
first experimental demonstration of on-demand hard X-ray photon storage.

</details>


### [420] [Quantum computing on encrypted data with arbitrary rotation gates](https://arxiv.org/abs/2508.18811)
*Mohit Joshi,Manoj Kumar Mishra,S. Karthikeyan*

Main category: quant-ph

TL;DR: 该研究提出了一种利用参数化量子门$R_z(\theta)$进行加密数据计算的半盲量子计算方案，相比于基于非参数化门的传统方法，该方案在计算复杂度和通信轮数上具有显著优势，为安全嘈杂中等规模量子（NISQ）计算的实际应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的半盲量子计算技术依赖于固定的非参数化资源集，限制了其效率。本研究旨在探索利用参数化量子门$R_z(\theta)$的递归解密，以提高计算效率并降低计算复杂度和通信轮数。

Method: 研究人员展示了参数化量子门$R_z(\theta)$在特定条件下（$	heta=\pmackslashackslash$pi$/2^m$）可以精确递归解密，并能以任意精度$\\epsilon$近似解密。在此基础上，提出了一种基于此技术的半盲算法，并与基于非参数化资源集的技术进行了计算复杂度和通信轮数的比较。

Result: 基于参数化量子门$R_z(\theta)$的半盲算法，计算步骤和通信轮数约为$O(\log_2^2(\pi/\\epsilon))$，而基于非参数化资源集的技术需要$O(\ln^{3.97}(1/\\epsilon))$轮。这表明新方案在计算效率上远超传统方法。

Conclusion: 该研究提出的利用参数化量子门$R_z(\theta)$的半盲量子计算方案，能够显著减少盲电路的深度，为在安全NISQ时代实现高效的加密数据计算提供了可行性，是迈向实际应用的重要一步。

Abstract: An efficient technique of computing on encrypted data allows a client with
limited capability to perform complex operations on a remote fault-tolerant
server without leaking anything about the input or output. Quantum computing
provides information-theoretic security to solve such a problem, and many such
techniques have been proposed under the premises of half-blind quantum
computation. However, they are dependent on a fixed non-parametric resource set
that comprises some universal combination of $H,S,T,CX, CZ$ or $CCX$ gates. In
this study, we show that recursive decryption of the parametric gate,
$R_z(\theta)$, is possible exactly when $\theta=\pm\pi/2^m$ for $m\in
\mathbb{Z^{+}}$, and approximately with arbitrary precision $\epsilon$ for
given $\theta$. We also show that a blind algorithm based on such a technique
needs at most $O(\log_2^2(\pi/\epsilon))$ computation steps and communication
rounds, while the techniques based on a non-parametric resource set require
$O(\ln^{3.97}(1/\epsilon))$ rounds. We use these results to propose a universal
scheme of half-blind quantum computation for computing on encrypted data using
arbitrary rotation gates. This substantial reduction in the depth of blind
circuit is an affirmative step towards the practical application of such
techniques in secure NISQ-era computing.

</details>


### [421] [Spontaneous Collapse Models](https://arxiv.org/abs/2508.18822)
*Matteo Carlesso,Sandro Donadi*

Main category: quant-ph

TL;DR: Collapse models modify quantum mechanics to solve the measurement problem, making testable predictions that differ from standard quantum mechanics.


<details>
  <summary>Details</summary>
Motivation: Collapse models are phenomenological models designed to address the measurement problem in quantum mechanics by modifying the Schr"odinger equation.

Method: The paper reviews relevant collapse models, their features, and how they can be tested through experiments that highlight differences from standard quantum mechanics predictions. It also touches upon colored and dissipative generalizations.

Result: The analysis of collapse models aims to set bounds on their parameters through experimental testing, differentiating their predictions from those of quantum mechanics.

Conclusion: The paper concludes by summarizing generalizations of collapse models, including colored and dissipative versions, and their corresponding experimental tests.

Abstract: Collapse models are phenomenological models introduced to solve the
measurement problem in quantum mechanics. They modify the Schr\"odinger
equation by adding non-linear and stochastic terms, which induce the
wavefunction collapse in space. The collapse effects are negligible for
microscopic systems but become dominant in the macroscopic regime, thus also
describing coherently the quantum-to-classical transition. Collapse models make
different predictions compared to those of quantum mechanics; hence they can be
tested. Here we introduce the most relevant collapse models present in the
literature, and describe their main features. We also discuss how one can test
them in different experiments, underlying the differences with predictions of
quantum mechanics, and show how these experiments can set bounds on the
collapse parameters. We conclude with a brief summary of the colored and
dissipative generalization of such models and their experimental tests.

</details>


### [422] [Quantum-Circuit-Based Visual Fractal Image Generation in Qiskit and Analytics](https://arxiv.org/abs/2508.18835)
*Hillol Biswas*

Main category: quant-ph

TL;DR: 量子计算可用于生成分形图像，特别是朱利亚集合，利用叠加、随机性和纠缠等量子特性。


<details>
  <summary>Details</summary>
Motivation: 探索将量子计算原理应用于分形图像生成，特别是朱利亚集合，以期在量子生成艺术领域开辟新方向。

Method: 通过构建量子电路并利用叠加、随机性和纠缠等量子特性来生成朱利亚集合数据集，以操纵生成的数据集模式。

Result: 生成了一个使用量子方法（结合量子电路）的分形朱利亚集合数据集。

Conclusion: 量子计算在分形朱利亚图像生成方面具有独特的研究潜力，可应用于量子生成艺术，例如创作具有量子艺术主题的风景画。

Abstract: As nature is ascribed as quantum, the fractals also pose some intriguing
appearance which is found in many micro and macro observable entities or
phenomena. Fractals show self-similarity across sizes; structures that resemble
the entire are revealed when zoomed in. In Quantum systems, the probability
density or wavefunction may exhibit recurring interference patterns at various
energy or length scales. Fractals are produced by basic iterative rules (such
as Mandelbrot or Julia sets), and they provide limitless complexity. Despite
its simplicity, the Schr\"odinger equation in quantum mechanics produces
incredibly intricate patterns of interference and entanglement, particularly in
chaotic quantum systems. Quantum computing, the root where lies to the using
the principles of quantum-mechanical phenomenon, when applied in fractal image
generation, what outcomes are expected? The paper outlines the generation of a
Julia set dataset using an approach coupled with building quantum circuit,
highlighting the concepts of superposition, randomness, and entanglement as
foundational elements to manipulate the generated dataset patterns. As Quantum
computing is finding many application areas, the possibility of using quantum
circuits for fractal Julia image generation posits a unique direction of future
research where it can be applied to quantum generative arts across various
ecosystems with a customised approach, such as producing an exciting landscape
based on a quantum art theme.

</details>


### [423] [Hybrid Quantum-Classical Branch-and-Price Method for the Vertex Coloring Problem](https://arxiv.org/abs/2508.18887)
*Chiara Vercellino,M. Yassine Naghmouchi,Wesley Coelho,Giacomo Vitali,Alberto Scionti,Paolo Viviani,Olivier Terzo,Bartolomeo Montrucchio*

Main category: quant-ph

TL;DR: 本文提出了一种名为量子经典分支定价（QCBP）的混合量子经典算法，用于解决中性原子量子处理器（QPU）上的图着色问题。QCBP将量子计算嵌入到经典的BP框架中，以解决经典BP算法中的三个瓶颈：定价子问题（PSP）的计算成本、分支效率以及原始启发式算法的质量。通过基于量子绝热算法（QAA）的量子辅助列生成（CG）来采样高质量的最大权重独立集（MWIS），从而减少了重复解决NP难PSP的需要。自适应分支策略利用量子生成的独立集来探索更少的节点，收紧下界并加快收敛速度。一种经典的原始启发式算法可以从量子生成的集合中快速构建可行解，避免不必要的量子调用或额外的整数线性规划（ILP）求解。与我们之前的混合列生成（HCG）和通过最大独立集（BBQ-mIS）进行分支定界相比，QCBP在量子资源利用和解的质量方面都有所改进。广泛的实验表明，QCBP的性能显著优于HCG和BBQ-mIS，在约98%的基准实例上达到了最优解。在真实的、中性原子的硬件上进行的初步验证表明，该算法对量子噪声和硬件约束具有鲁棒性，支持其在实际应用和扩展到更大的图实例方面的潜力。QCBP作为一种可行的混合方法，在组合优化领域展现了在近期量子硬件上具有良好可扩展性的前景。


<details>
  <summary>Details</summary>
Motivation: 解决图着色问题的经典分支定价（BP）算法在定价子问题（PSP）的计算成本、分支效率和原始启发式算法质量方面存在瓶颈。QCBP旨在通过引入量子计算来克服这些挑战。

Method: QCBP算法将量子计算嵌入到经典的Branch-and-Price（BP）框架中。它利用量子辅助列生成（CG），特别是基于量子绝热算法（QAA），来采样高质量的最大权重独立集（MWIS）。这种方法减少了解决NP难PSP的频率。此外，QCBP采用了适应性分支策略，利用量子生成的独立集来减少搜索空间、提高下界并加速收敛。同时，它还结合了经典的原始启发式算法，以快速从量子生成的集合中构建可行解。

Result: 与先前的混合列生成（HCG）和通过最大独立集（BBQ-mIS）进行分支定界算法相比，QCBP在量子资源利用和解的质量方面均有所提升。实验结果显示，QCBP在约98%的基准实例上达到了最优解，显著优于HCG和BBQ-mIS。初步的硬件测试表明，该算法对量子噪声和硬件限制具有鲁棒性，并显示出实际应用和扩展到更大图实例的潜力。

Conclusion: QCBP是一种有效的混合量子-经典算法，用于解决图着色问题。它通过利用量子计算来优化经典算法的关键瓶颈，显著提高了性能和解的质量。该算法在实际的、中性原子的硬件上表现出良好的鲁棒性和可扩展性，预示着其在近期量子硬件上进行组合优化具有广阔的应用前景。

Abstract: This paper introduces Quantum Classical Branch-and-Price (QCBP), a hybrid
quantum-classical algorithm for the Vertex Coloring problem on neutral-atom
Quantum Processing Units (QPUs). QCBP embeds quantum computation within the
classical Branch-and-Price (BP) framework to address three bottlenecks in
classical BP algorithms: the computational cost of Pricing Subproblems (PSPs),
branching efficiency, and the quality of primal heuristics. It uses
quantum-assisted Column Generation (CG) based on Quantum Adiabatic Algorithms
(QAA) to sample high-quality maximum-weight independent sets (MWIS), reducing
the need to repeatedly solve NP-hard PSPs. The adapted branching strategy
leverages quantum-generated independent sets to explore fewer nodes, tighten
lower bounds, and converge faster. A classical primal heuristic rapidly builds
feasible solutions from quantum-generated sets, avoiding unnecessary quantum
calls or additional Integer Linear Programming (ILP) solves. Compared with our
prior Hybrid Column Generation (HCG) and Branch-and-Bound through maximal
Independent Set (BBQ-mIS), QCBP improves both quantum-resource utilization and
solution quality. Extensive experiments show QCBP significantly outperforms HCG
and BBQ-mIS, reaching optimality on $\approx 98\%$ of benchmark instances.
Preliminary validation on real neutral-atom hardware indicates robustness to
quantum noise and hardware constraints, supporting practical applicability and
scalability to larger graph instances. QCBP emerges as a viable hybrid method
for combinatorial optimization with promising scalability on near-term quantum
hardware.

</details>


### [424] [Quantum Mpemba Effect in Dissipative Spin Chains at Criticality](https://arxiv.org/abs/2508.18906)
*Zijun Wei,Mingdi Xu,Xiang-Ping Jiang,Lei Pan*

Main category: quant-ph

TL;DR: 量子恩培巴效应（QME）是经典恩培巴效应的量子对应物，在这种反直觉的现象中，初始温度较高的系统比初始温度较低的系统更快地达到热平衡。本研究调查了一维量子自旋链与马尔可夫环境耦合中的QME。通过分析由林德布拉德主方程控制的完整弛豫动力学，我们揭示了在量子临界点出现强QME。研究结果表明，临界性增强了弛豫时间与初始温度的非单调依赖性，导致异常加速的平衡。这一现象与临界点的刘维利安谱结构及与初始态的重叠直接相关。这些发现表明，量子相变可能为开放量子系统中非平衡现象的实现和增强提供一个自然的背景。


<details>
  <summary>Details</summary>
Motivation: 研究经典恩培巴效应的量子对应物，即量子恩培巴效应（QME），并探究其在一维量子自旋链与马尔可夫环境耦合中的表现。

Method: 利用林德布拉德主方程分析完整的弛豫动力学。

Result: 在量子临界点发现了强量子恩培巴效应，临界性增强了弛豫时间与初始温度的非单调依赖性，导致异常加速的平衡。

Conclusion: 量子相变可以为开放量子系统中非平衡现象的实现和增强提供一个自然的背景。

Abstract: The Quantum Mpemba Effect (QME) is the quantum counterpart of the classical
Mpemba effect--a counterintuitive phenomenon in which a system initially at a
higher temperature relax to thermal eauilibrium faster than one at a lower
temperature. In this work, we investigate the QME in one-dimensional quantum
spin chains coupled to a Markovian environment. By analyzing the full
relaxation dynamics governed by the Lindblad master equation, we reveal the
emergence of a strong quantum Mpemba effect at quantum critical points. Our
findings reveal that criticality enhances the non-monotonic dependence of
relaxation times on the initial temperature, leading to anomalously accelerated
equilibration. This phenomenon is directly linked to the structure of the
Liouvillian spectrum at criticality and the associated overlaps with the
initial states. These findings demonstrate that quantum phase transitions could
provide a natural setting for realizing and enhancing non-equilibrium phenomena
in open quantum systems.

</details>


### [425] [Controlling the $\mathcal{PT}$ Symmetry Breaking Threshold in Bipartite Lattice Systems with Floquet Topological Edge States](https://arxiv.org/abs/2508.18931)
*Xinguang Li,Hongzheng Wu,Yangchun Zhao,Jinpeng Xiao,Yu Guo,Lei Li,Yajiang Chen,Xiaobing Luo*

Main category: quant-ph

TL;DR: 该研究探讨了在周期性驱动的一维二聚格点中，如何控制奇偶性时间（PT）对称性破缺阈值，并阐述了Floquet拓扑边缘态在高频和低频驱动下的不同作用。


<details>
  <summary>Details</summary>
Motivation: 研究PT对称性破缺阈值及其与Floquet拓扑边缘态的关系，尤其是在周期性驱动和存在增益/损耗缺陷的二聚格点中。

Method: 通过分析Floquet拓扑边缘态在不同驱动频率（高频和低频）下的空间分布演化，以及其与PT对称性破缺阈值之间的联系，并考察格点尺寸（奇偶）和驱动方式（共频周期驱动）的影响。

Result: 发现在高频驱动下，拓扑边缘态是否参与PT对称性破缺取决于缺陷对的位置；而在低频驱动下，无论缺陷对位置如何，拓扑边缘态均会无条件参与，导致阈值为零。研究还发现，奇数尺寸的格点具有独特的阈值模式，并且共频周期驱动可以显著提高PT对称性破缺阈值。

Conclusion: PT对称性破缺阈值与Floquet拓扑边缘态在驱动周期内的空间轮廓演化密切相关。研究揭示了不同驱动频率、缺陷位置、格点尺寸以及驱动方式对PT对称性破缺行为的调控机制。

Abstract: We investigate the control of the parity-time ($\mathcal{PT}$)-symmetry
breaking threshold in a periodically driven one-dimensional dimerized lattice
with spatially symmetric gain and loss defects. We elucidate the contrasting
roles played by Floquet topological edge states in determining the
$\mathcal{PT}$ symmetry breaking threshold within the high- and low-frequency
driving regimes. In the high-frequency regime, the participation of topological
edge states in $\mathcal{PT}$ symmetry breaking is contingent upon the position
of the $\mathcal{PT}$-symmetric defect pairs, whereas in the low-frequency
regime, their participation is unconditional and independent of the defect
pairs placement, resulting in a universal zero threshold. We establish a direct
link between the symmetry-breaking threshold and how the spatial profile of the
Floquet topological edge states evolves over one driving period. We further
demonstrate that lattices with an odd number of sites exhibit unique threshold
patterns, in contrast to even-sized systems. Moreover, applying co-frequency
periodic driving to the defect pairs, which preserves time-reversal symmetry,
can significantly enhance the $\mathcal{PT}$ symmetry-breaking threshold.

</details>


### [426] [Amplifying Two-Mode Squeezing in Nanomechanical Resonators](https://arxiv.org/abs/2508.18972)
*Muhdin Abdo Wodedo,Tesfay Gebremariam Tesfahannes,Tewodros Yirgashewa Darge,Mauro Pereira,Berihu Teklu*

Main category: quant-ph

TL;DR: 本研究提出了一种在纳米力学谐振器中放大双模压缩的方法，利用参数放大和双音激光控制。


<details>
  <summary>Details</summary>
Motivation: 量子压缩对于提高量子计量精度和量子信息处理协议效率至关重要。

Method: 通过红色失谐激光驱动实现纳米力学谐振器的地面态冷却和最优量子态传输，并通过蓝色失谐激光诱导机械谐振器的位移压缩。

Result: 量子态传输和腔内相关光子显著增强了双模机械压缩，并且该方法在现实实验参数下能够放大双模机械压缩。

Conclusion: 该方法能有效提高双模机械压缩水平，且对热噪声具有极强的抵抗能力。

Abstract: Quantum squeezing plays a crucial role in enhancing the precision of quantum
metrology and improving the efficiency of quantum information processing
protocols. We thus propose a scheme to amplify two-mode squeezing in
nanomechanical resonators, harnessing parametric amplification and two-tone
laser controls. The red-detuned laser drives facilitate the cooling of the
nanomechanical resonators down to their ground state and allow optimal quantum
state transfer in the weak-coupling, resolved sideband regime. In particular,
the competing blue-detuned lasers in the driving pairs induce displacement
squeezing in mechanical resonators. Thus, the quantum state transfer of the
squeezing in nanomechanical resonators and the intracavity correlated photons
of the parametric amplifier significantly enhance the two-mode mechanical
squeezing. Notably, increasing the coupling strength of the red detuned laser
and the ratio of blue-to-red detuned laser dramatically amplifies the two-mode
mechanical squeezing under realistic experiment parameters of a typical
optomechanical system. Our findings reveal that the proposed cooperative
mechanism effectively enhances the level of two-mode mechanical squeezing with
a considerable improvement and demonstrates exceptional resilience to thermal
noise.

</details>


### [427] [Optical charge state manipulation of lead-vacancy centers in diamond](https://arxiv.org/abs/2508.18991)
*Yiyang Chen,Yoshiyuki Miyamoto,Eiki Ota,Ryotaro Abe,Takashi Taniguchi,Shinobu Onoda,Mutsuko Hatano,Takayuki Iwasaki*

Main category: quant-ph

TL;DR: Group-IV vacancy centers in diamond, specifically lead-vacancy (PbV) centers, are promising for quantum applications due to their optical and spin properties. Charge state control is crucial for their use as spin qubits. This paper demonstrates tunable charge state control of PbV centers using multi-color laser irradiation, achieving up to 89% population in the negatively charged state. This opens possibilities for spin control of the negatively charged PbV center and suggests a charge cycle between neutral and negatively charged states, potentially leading to a neutral PbV center with a spin-1 system.


<details>
  <summary>Details</summary>
Motivation: Control over the charge state of Group-IV vacancy centers in diamond, such as lead-vacancy (PbV) centers, is fundamental for quantum applications because only specific charge states exhibit magneto-optical activity. This work aims to achieve tunable charge state control of PbV centers.

Method: The researchers realized the charge state control of lead-vacancy (PbV) centers in diamond through multi-color laser irradiation. They analyzed the charge state dynamics to understand the underlying processes.

Result: Tunable population manipulation of the negatively charged state of PbV centers was achieved, reaching up to 89%. Analysis of charge state dynamics suggested a charge cycle between the neutral and negatively charged states.

Conclusion: The study successfully demonstrated tunable charge state control of PbV centers using multi-color laser irradiation, which is crucial for their application as spin qubits. The findings also suggest a potential pathway to a neutral PbV center with a spin-1 system by understanding the charge cycle between neutral and negatively charged states.

Abstract: Group-IV vacancy centers in diamond exhibit excellent optical and spin
coherence properties, making them highly promising and scalable spin qubit
candidates. Since only specific charge states are magneto-optically active,
control over the charge state is fundamental for quantum applications. Here, we
realize the charge state control of lead-vacancy centers (PbV) through
multi-color laser irradiation. We achieve tunable population manipulation of
the negatively charged state from 0 to 89%, paving the way for spin control of
the negatively charged PbV center. Furthermore, through analysis of charge
state dynamics, we propose a charge cycle between the neutral and negatively
charged states, indicating a possible pathway to the neutral PbV center with a
spin-1 system.

</details>


### [428] [Iterative Partition Search Variational Quantum Algorithm for Solving Shortest Vector Problem](https://arxiv.org/abs/2508.18996)
*Zi-Wen Huang,Xiao-Hui Ni,Jia-Cheng Fan,Su-Juan Qin,Wei Huang,Bing-Jie Xu,Fei Gao*

Main category: quant-ph

TL;DR: IPSA，一种结合PSA和IQOAP思想的新型变分量子算法，在SVP问题上表现出更高的成功率和解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有变分量子算法（PSA和IQOAP）在解决最短向量问题（SVP）时存在的局限性。

Method: 提出IPSA算法，结合PSA的“分区”思想和IQOAP的“迭代晶格基约减”框架，并引入“1尾搜索空间”和动态迭代过程，优化电路结构。

Result: 与现有方法相比，IPSA在4到6维SVP实例上，找到最优解的成功率提高了至少73%，平均解决方案质量提高了35%以上，同时保持了相当的总电路深度。

Conclusion: IPSA通过结合和改进现有方法，成功克服了其前驱算法的缺点，在SVP问题上取得了显著的性能提升。

Abstract: The Partition Search Algorithm (PSA) and the Iterative Quantum Optimization
with an Adaptive Problem (IQOAP) framework are two existing Variational Quantum
Algorithms (VQAs) for solving the Shortest Vector Problem (SVP), but both
suffer from certain limitations. In this work, we proposed the Iterative
Partition Search Algorithm (IPSA), which is a targeted synthesis and refinement
of these preceding methods. Our algorithm inherits the core idea of
``partitioning to circumvent the zero vector" from PSA and the ``iterative
lattice basis reduction" framework from IQOAP. A key feature of IPSA is the
``1-tailed search spaces", which can be viewed as a highly constrained variant
of PSA's partitioning strategy, specifically designed for optimal performance
within IQOAP's iterative structure. We supplant IQOAP's fixed iteration count
with a dynamic, stack-managed process and substitute a more expressive and
shallower circuit structure for its original ansatz. Crucially, the 1-tailed
design fundamentally ensures that every successful VQA execution yields an
effective lattice basis update, thereby eliminating the issue of ineffective
iterations in IQOAP. This evolutionary path of refinement allows IPSA to
overcome the drawbacks of its predecessors precisely. Numerical simulations on
4- to 6-dimensional SVP instances demonstrate that IPSA achieves at least a
73\% improvement in success rate for finding optimal solutions and over a 35\%
improvement in average solution quality compared with the methods above while
maintaining comparable total circuit depth.

</details>


### [429] [Private Quantum Database](https://arxiv.org/abs/2508.19055)
*Giancarlo Gatti,Rihan Hai*

Main category: quant-ph

TL;DR: 该论文提出了一种利用量子力学保护用户和数据隐私的量子数据库，通过量子态的测量来隐藏未查询的行，并采用QRACs和MUBs编码关系表，允许通过一次破坏性测量来重构选定的元组，同时提出了一种适用于NISQ设备的混合量子-经典架构。


<details>
  <summary>Details</summary>
Motivation: 传统数据库在用户隐私（隐藏被查询记录）或数据隐私（防止用户学习超出其查询范围的信息）方面存在不足，本研究旨在提出一种能同时保护这两种隐私的量子数据库。

Method: 将关系表编码为一系列在互补基上的量子随机访问码（QRACs），传输有限数量的量子态，并通过一次破坏性测量来重构选定的元组。

Result: 所提出的量子数据库能够同时保护用户隐私和数据隐私，且无需可信硬件或复杂的密码学。此外，还提出了一种兼容现有NISQ设备的混合量子-经典架构。

Conclusion: 该研究提出了一种创新的量子数据库方法，能够同时提供用户和数据隐私保护，并通过混合架构为早期部署提供了可行性。

Abstract: Quantum databases open an exciting new frontier in data management by
offering privacy guarantees that classical systems cannot match. Traditional
engines tackle user privacy, which hides the records being queried, or data
privacy, which prevents a user from learning more than she has queried. We
propose a quantum database that protects both by leveraging quantum mechanics:
when the user measures her chosen basis, the superposition collapses and the
unqueried rows become physically inaccessible. We encode relational tables as a
sequence of Quantum Random Access Codes (QRACs) over mutually unbiased bases
(MUBs), transmit a bounded number of quantum states, and let a single,
destructive measurement reconstruct only the selected tuple. This allows us to
preserve data privacy and user privacy at once without trusted hardware or
heavyweight cryptography. Moreover, we envision a novel hybrid
quantum-classical architecture ready for early deployment, which ensures
compatibility with the limitations of today's Noisy Intermediate-Scale Quantum
devices.

</details>


### [430] [Improved lower bound for the worst case Pretty Good Measurement](https://arxiv.org/abs/2508.19085)
*Austin Pechan,Sergio Escobar*

Main category: quant-ph

TL;DR: 本论文推导了 m 个纯态之间量子态区分（PGM）在最坏情况下的成功概率新下界，该下界对于 m ≥ 4 严格优于先前基于 Gram 矩阵的界限。


<details>
  <summary>Details</summary>
Motivation: 推导 m 个纯态之间量子态区分（PGM）在最坏情况下的成功概率新下界，并与现有界限进行比较。

Method: 借鉴 Barnum 和 Knill 分析 PGM 平均情况的技术，并将其应用于最坏情况。通过将 PGM 与序贯测量算法进行比较来获得保证。

Result: 得出了一个新的、比先前基于 Gram 矩阵的界限更严格的 PGM 成功概率下界（适用于 m ≥ 4）。在低保真度情况下，PGM 的成功概率与成对重叠呈二次方关系下降，而非线性关系。

Conclusion: 本研究为量子态区分提供了一个更优的理论保证，尤其是在低保真度和多状态场景下。

Abstract: We derive a new lower bound on the success probability of the Pretty Good
Measurement (PGM) for worst-case quantum state discrimination among $m$ pure
states. Our bound is strictly tighter than the previously known
Gram-matrix-based bound for $m\geq 4$. The proof adapts techniques from Barnum
and Knill's analysis of the average-case PGM, applied here to the worst-case
scenario. By comparing the PGM to the sequential measurement algorithm, we
obtain a guarantee showing that, in the low-fidelity regime, the PGM's success
probability decreases quadratically with respect to the pairwise overlap,
rather than linearly as in earlier bounds.

</details>


### [431] [Efficient and scalable inter-module switching for distributed quantum computing architectures](https://arxiv.org/abs/2508.19088)
*Kamil Bradler*

Main category: quant-ph

TL;DR: 未来的大型容错量子计算机很可能是模块化的，因为平面几何或制造限制导致每个模块的逻辑量子比特数量有限，或者因为需要将量子计算基板分布在不同区域。为了避免过长的算法执行时间和减少错误，通用量子计算机的每个模块应与尽可能多的其他模块动态互连。这项任务依赖于提供任意到任意或足够高的同时连接的光学开关网络。在这项工作中，我们构建了几种基于广义马赫-曾德尔干涉仪 (GMZI) 特性的新颖的、去中心化的交换方案，与通常考虑的替代方案相比，这些方案更经济、噪声更小，同时实现了相同的功能。


<details>
  <summary>Details</summary>
Motivation: 未来的大型容错量子计算机很可能是模块化的，需要动态互连模块以提高效率和减少错误，这需要一个能够提供高连接性的光学开关网络。

Method: 构建基于广义马赫-曾德尔干涉仪（GMZI）特性的新颖的、去中心化的交换方案。

Result: 提出的基于GMZI的交换方案比常用方案更经济、噪声更小，但功能相同。

Conclusion: 基于GMZI的去中心化交换方案为实现模块化通用量子计算机的高效互连提供了一种有前景的方法。

Abstract: Large-scale fault-tolerant quantum computers of the future will likely be
modular by necessity or by design. Modularity is inevitable if the substrate
cannot support the desired error-correction code due to its planar geometry or
manufacturing constraints resulting in a limited number of logical qubits per
module. Even if the computer is compact enough there may be functional
requirements to distribute the quantum computation substrate over distant
regions of varying scales. In both cases, matter-based quantum information,
such as spins, ions or neutral atoms, is the most conveniently transmitted or
mediated by photonic interconnects. To avoid long algorithm execution times and
reduce errors, each module of a universal quantum computer should be
dynamically interconnected with as many other modules as possible. This task
relies on an optical switching network providing any-to-any or sufficiently
high simultaneous connectivity. In this work we construct several novel and
decentralized switching schemes based on the properties of the Generalized
Mach-Zehnder Interferometer (GMZI) that are more economic and less noisy
compared to commonly considered alternatives while achieving the same
functionality.

</details>


### [432] [Work extraction from a quantum battery charged through an array of coupled cavities](https://arxiv.org/abs/2508.19135)
*I. Beder,D. Ferraro,P. A. Brandão*

Main category: quant-ph

TL;DR: 文章研究了如何从基于腔的量子电池中提取功，该电池通过由耦合单模腔阵列组成的传输线进行远程充电。研究表明，在均匀耦合的情况下，充电线越长，电池的功（ergotropy）就越低，并在超过临界长度后消失。通过精心设计充电器的初始状态，即使超过临界长度，仍能获得非零的功。此外，研究还探讨了充电线处于纠缠态以及耦合强度不均匀（抛物线变化）的情况。在耦合强度不均匀的情况下，可以恢复高功值，这表明空间设计的相互作用可以提高量子电池的性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究从基于腔的量子电池中提取功的问题，特别是通过包含耦合单模腔阵列的传输线进行远程充电的场景。

Method: 研究了均匀耦合沿线的功提取，并分析了功与充电线长度的关系。此外，还探讨了通过工程化充电器初始状态、使用纠缠态以及采用抛物线变化的非均匀耦合强度来恢复功提取性能的场景。

Result: 对于均匀耦合，功随充电线长度的增加而减少，并在超过临界长度后消失。通过工程化初始状态或采用非均匀耦合（如抛物线变化），可以恢复高功值。

Conclusion: 通过对充电器初始状态的精心设计以及对充电线耦合强度的空间工程化，可以克服传输线长度带来的限制，从而提高量子电池的性能。

Abstract: We investigate the problem of work extraction from a cavity-based quantum
battery that is remotely charged via a transmission line composed of an array
of coupled single-mode cavities. For uniform coupling along the line, we show
that the ergotropy of the battery, evaluated at the point of maximum power
transfer, decreases with the length of the charging line and vanishes beyond a
critical size. By carefully engineering the initial state of the charger,
nonzero ergotropy can still be harvested even beyond this critical length. We
further examine scenarios in which the charging line is initialized in an
entangled state, as well as configurations with nonuniform, parabolically
varying coupling strengths. In the latter case, we demonstrate that high
ergotropy values can be restored, highlighting the potential of spatially
engineered interactions to enhance quantum battery performance.

</details>


### [433] [Unquestionable Bell theorem for interwoven frustrated down conversion processes](https://arxiv.org/abs/2508.19207)
*Paweł Cieśliński,Marcin Markiewicz,Konrad Schlichtholz,Jan-Åke Larsson,Marek Żukowski*

Main category: quant-ph

TL;DR: 本文提供了一个无条件的贝尔类型证明，表明旺等人实验的一个修改版本确实会揭示对局域实在论的违反。


<details>
  <summary>Details</summary>
Motivation: 为了消除关于旺等人观察到的干涉过程的贝尔非经典性的任何疑虑。

Method: 该方法放弃了通常的、由宏观上控制的光学相位来定义贝尔实验中的测量设置的方法。相反，在本文中，局域设置是通过在“Alice和Bob”的局域测量站上本地地打开或关闭参数化下转换晶体的泵浦场来确定的。

Result: 旺等人实验的数据显示了破坏性干涉，该干涉超过了修改版本中贝尔非经典性所需的阈值，从而有效地构成了使用本文提出的方法进行的阳性实验贝尔非经典性检验。

Conclusion: 本文证明了旺等人用于推断违反局域实在性的概率的局部隐变量理论是可能的，并且他们实验中的非经典效应不能归因于非纠缠光子。

Abstract: In the Wang et al. paper "Violation of Bell inequality with unentangled
photons'' [Science Advances, 1 Aug 2025 Vol 11, Issue 31], in which a brilliant
experiment involving two interwoven frustrated down conversion processes is
reported, Bell non-classicality of the observed interference processes is
conjectured under some tacit additional assumptions.
  To clear any doubts about Bell non-classicality of the interference processes
observed by Wang et al., we give an unconditional Bell-type proof that a
modified version of the experiment indeed would reveal a violation of local
realism. The data of the Wang et al. experiment show destructive interference
which surpasses the required threshold for Bell non-classicality in the
modified version, and thus effectively constitutes a positive experimental Bell
non-classicality test employing our proposal. The essence of our method is to
abandon the usual approach in which macroscopically controlled optical phases
define the measurement settings in a Bell experiment. Instead, in our case, the
local settings are determined by switching on or off the local pumping fields
of the parametric down conversion crystals at the local measuring stations of
"Alice and Bob''.
  We also show that in a standard framework of local hidden variable theories
that do not require any additional assumptions, it is possible to construct a
local realistic model which exactly reproduces the probabilities on which the
conjecture by Wang et al. violation of local realism was based. Thus, we prove
that the tacit additional assumptions in the Bell analysis of Wang et al.
constrain the class of local realistic models refuted by the experiment. Also,
we claim that the non-classical effects in the Wang et al. experiment cannot be
ascribed to unentangled photons.

</details>


### [434] [Optimal quantum simulation of linear non-unitary dynamics](https://arxiv.org/abs/2508.19238)
*Guang Hao Low,Rolando D. Somma*

Main category: quant-ph

TL;DR: We present a quantum algorithm for simulating time evolution generated by bounded, time-dependent operators with non-positive logarithmic norm, generalizing Hamiltonian simulation.


<details>
  <summary>Details</summary>
Motivation: The motivation is to generalize the Hamiltonian simulation problem to a broader class of operators, specifically bounded, time-dependent operators with non-positive logarithmic norm.

Method: The method generalizes the Linear-Combination-of-Hamiltonian-Simulation (LCHS) framework. For time-independent operators, it provides a block-encoding of the evolution operator $e^{-At}$ with $\mathcal{O}(t\log\frac{1}{\epsilon})$ queries and shows how to prepare the normalized evolved state with $\mathcal{O}(1/\|e^{-At}|{\vec{u}_0}\rangle\|)$ queries. For time-dependent operators, a uniform trapezoidal rule on the LCHS construction yields exponential convergence.

Result: For time-independent operators, the query complexity is optimal in all parameters and improves error scaling over prior results. An improvement exceeding a constant factor of approximately 3 is shown to be infeasible. For time-dependent operators, the method results in simplified quantum circuits with improved gate complexity compared to prior methods.

Conclusion: The presented quantum algorithm efficiently simulates the time evolution of a wider range of operators than previously possible, offering optimal complexities and improved performance for both time-independent and time-dependent cases.

Abstract: We present a quantum algorithm for simulating the time evolution generated by
any bounded, time-dependent operator $-A$ with non-positive logarithmic norm,
thereby serving as a natural generalization of the Hamiltonian simulation
problem. Our method generalizes the recent
Linear-Combination-of-Hamiltonian-Simulation (LCHS) framework. In instances
where $A$ is time-independent, we provide a block-encoding of the evolution
operator $e^{-At}$ with $\mathcal{O}\big(t\log\frac{1}{\epsilon})$ queries to
the block-encoding oracle for $A$. We also show how the normalized evolved
state can be prepared with $\mathcal{O}(1/\|e^{-At}|{\vec{u}_0}\rangle\|)$
queries to the oracle that prepares the normalized initial state
$|{\vec{u}_0}\rangle$. These complexities are optimal in all parameters and
improve the error scaling over prior results. Furthermore, we show that any
improvement of our approach exceeding a constant factor of approximately 3 is
infeasible. For general time-dependent operators $A$, we also prove that a
uniform trapezoidal rule on our LCHS construction yields exponential
convergence, leading to simplified quantum circuits with improved gate
complexity compared to prior nonuniform-quadrature methods.

</details>


### [435] [New Twists on Topological Quantum Error Correcting Codes](https://arxiv.org/abs/2508.19245)
*Mohamad Mousa,Amit Jamadagni,Eugene Dumitrescu*

Main category: quant-ph

TL;DR: We derived a new family of quantum error-correcting codes using condensation and domain walls. We provide explicit constructions and discuss their utility and automation for higher-dimensional codes.


<details>
  <summary>Details</summary>
Motivation: The motivation is to derive a new family of quantum error-correcting codes and explore their utility and automation.

Method: The method involves using the concept of condensation to create domain walls between the quantum double of $\Z_4$ and the doubled semion phase, leading to explicit constructions at both lattice and macroscopic logical levels.

Result: The result is a new family of quantum error-correcting codes with explicit constructions and a discussion of their utility in quantum error correction, focusing on logical error rates and decoding.

Conclusion: The conclusion is that the derived codes, with explicit algorithms, can pave the way for discovering and implementing new higher-algebraic-dimensional codes tailored to hardware strengths, and their representation and design can be automated.

Abstract: We derive a new family of quantum error-correcting codes. The main technical
tool used to do so is the physically intuitive concept of condensation, which
is employed to create new domain walls between the quantum double of $\Z_4$ and
an instance of the doubled semion phase. Specifically, we provide explicit
constructions, first at the lattice-level and then subsequently at the
macroscopic logical-level. To provide intuition, we provide a series of
explicit examples using the derived topological interfaces. We discuss the
code's utility in the burgeoning area of quantum error-correction with an
emphasis on the interplay between logical error rates and decoding.
  We conclude by outlining how such codes' representation and design can be
automated. We expect our results, which provide explicit step-by-step
instructions in the form of algorithms, to pave the path for new
higher-algebraic-dimensional codes to be discovered and implemented in
configurations that take advantage of various hardware's distinct strengths.

</details>
